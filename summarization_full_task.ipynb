{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization - Full task 'keep it simple'\n",
    "\n",
    "Scientific papers summarization task divided into x steps:\n",
    "\n",
    "Step 1: Cited text spans identification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/priscillaburity/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/priscillaburity/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/priscillaburity/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/priscillaburity/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Download the dataset\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "# For regular expressions\n",
    "import re\n",
    "# For handling string\n",
    "import string\n",
    "# For performing mathematical operations\n",
    "import math\n",
    "# Importing spacy\n",
    "import spacy\n",
    "# Importing json to read input\n",
    "import json\n",
    "# Importing rouge for evaluation\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import html\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import statistics as stats\n",
    "import time\n",
    "\n",
    "from scipy import spatial\n",
    "from sent2vec.vectorizer import Vectorizer\n",
    "\n",
    "# for turn text into sentences\n",
    "import nltk.data\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import html\n",
    "from lxml import etree\n",
    "import unidecode\n",
    "\n",
    "from scipy import stats as s\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import nltk \n",
    "import glob, os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.etree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "plot_dims = (16, 16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# url = \"https://cs.stanford.edu/~myasu/projects/scisumm_net/scisummnet_release1.1__20190413.zip\"\n",
    "# response = requests.get(url)\n",
    "# with zipfile.ZipFile(io.BytesIO(response.content)) as zipObj:\n",
    "#     # Extract all the contents of zip file in different directory\n",
    "#     zipObj.extractall(\"nlp_data\")\n",
    "#     print(\"File is unzipped in nlp_data folder\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.5.0-py3-none-any.whl (192 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (1.19.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (0.5.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.0-cp37-cp37m-macosx_10_6_intel.whl (68 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (1.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (0.0.6)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: dill in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/lib/python3.7/site-packages (from datasets) (0.23)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata->datasets) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->datasets) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: tqdm, xxhash, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.57.0\n",
      "    Uninstalling tqdm-4.57.0:\n",
      "      Successfully uninstalled tqdm-4.57.0\n",
      "Successfully installed datasets-1.5.0 tqdm-4.49.0 xxhash-2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pip\n",
    "# from pip._internal import main as pipmain\n",
    "\n",
    "# pipmain(['install', 'datasets'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Download and parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "DATA_DIR = \"data/nlp_data/scisummnet_release1.1__20190413/top1000_complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all raw text, break all papers into two parts -- Abstract and rest of document\n",
    "#first get all filepaths\n",
    "xmlfiles = []\n",
    "citations = []\n",
    "golden_summaries = []\n",
    "for subdir, dirs, files in os.walk(DATA_DIR):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "        if filepath.endswith(\".xml\"):\n",
    "            xmlfiles.append(filepath)\n",
    "        if filepath.endswith(\".json\"):\n",
    "            citations.append(filepath)\n",
    "        if filepath.endswith(\".txt\"):\n",
    "            golden_summaries.append(filepath)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next parse all XML documents\n",
    "\n",
    "def parse_xml_abstract(fp):\n",
    "    \"\"\" parse an XML journal article into an abstract and the rest of the text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(fp)\n",
    "    except Exception as e:\n",
    "        return \"\",\"\",str(e)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    ab = []\n",
    "    bod = []\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == \"ABSTRACT\":\n",
    "            for block in child:\n",
    "                ab.append(block.text)\n",
    "        else:\n",
    "            for block in child:\n",
    "                bod.append(block.text)\n",
    "                \n",
    "    #convert from list --> string\n",
    "    abstract = \"\\n\".join(ab)\n",
    "    body = \"\\n\".join(bod)\n",
    "    \n",
    "    #decode html entities\n",
    "    abstract = html.unescape(abstract)\n",
    "    body = html.unescape(body)\n",
    "    \n",
    "    return abstract,body,\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>body</th>\n",
       "      <th>citations</th>\n",
       "      <th>golden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We present a method for extracting parts of ob...</td>\n",
       "      <td>We present a method of extracting parts of obj...</td>\n",
       "      <td>[Berland and Charniak (1999) use Hearst style ...</td>\n",
       "      <td>Finding Parts In Very Large Corpora\\nWe presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We describe a series of five statistical model...</td>\n",
       "      <td>We describe a series of five statistical model...</td>\n",
       "      <td>[The program takes the output of char_align (C...</td>\n",
       "      <td>The Mathematics Of Statistical Machine Transla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Previous work has shown that Chinese word segm...</td>\n",
       "      <td>Word segmentation is considered an important f...</td>\n",
       "      <td>[Chinese word segmentation is done by the Stan...</td>\n",
       "      <td>Optimizing Chinese Word Segmentation for Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We examine the viability of building large pol...</td>\n",
       "      <td>Polarity lexicons are large lists of phrases t...</td>\n",
       "      <td>[Recent work in this area includes Velikovich ...</td>\n",
       "      <td>The viability of web-derived polarity lexicons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extracting semantic relationships between enti...</td>\n",
       "      <td>Extraction of semantic relationships between e...</td>\n",
       "      <td>[They use two kinds of features: syntactic one...</td>\n",
       "      <td>Combining Lexical Syntactic And Semantic Featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>In statistical machine translation, correspond...</td>\n",
       "      <td>In statistical machine translation, correspond...</td>\n",
       "      <td>[In addition, Niessen and Ney (2004) decompose...</td>\n",
       "      <td>Statistical Machine Translation With Scarce Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>We have developed a new program called alignin...</td>\n",
       "      <td>Aligning parallel texts has recently received ...</td>\n",
       "      <td>[There have been quite a number of recent pape...</td>\n",
       "      <td>Robust Bilingual Word Alignment For Machine Ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>We present an approach to pronoun resolution b...</td>\n",
       "      <td>Pronoun resolution is a difficult but vital pa...</td>\n",
       "      <td>[, We follow the closed track setting where sy...</td>\n",
       "      <td>Bootstrapping Path-Based Pronoun Resolution\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>We use logical inference techniques for recogn...</td>\n",
       "      <td>Recognising textual entailment (RTE) is the ta...</td>\n",
       "      <td>[However, this method does not work for realwo...</td>\n",
       "      <td>Recognising Textual Entailment With Logical In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>This paper deals with two important ambiguitie...</td>\n",
       "      <td>The problem with successful resolution of ambi...</td>\n",
       "      <td>[The state of the art is a supervised algorith...</td>\n",
       "      <td>Corpus Based PP Attachment Ambiguity Resolutio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               abstract  \\\n",
       "0     We present a method for extracting parts of ob...   \n",
       "1     We describe a series of five statistical model...   \n",
       "2     Previous work has shown that Chinese word segm...   \n",
       "3     We examine the viability of building large pol...   \n",
       "4     Extracting semantic relationships between enti...   \n",
       "...                                                 ...   \n",
       "1004  In statistical machine translation, correspond...   \n",
       "1005  We have developed a new program called alignin...   \n",
       "1006  We present an approach to pronoun resolution b...   \n",
       "1007  We use logical inference techniques for recogn...   \n",
       "1008  This paper deals with two important ambiguitie...   \n",
       "\n",
       "                                                   body  \\\n",
       "0     We present a method of extracting parts of obj...   \n",
       "1     We describe a series of five statistical model...   \n",
       "2     Word segmentation is considered an important f...   \n",
       "3     Polarity lexicons are large lists of phrases t...   \n",
       "4     Extraction of semantic relationships between e...   \n",
       "...                                                 ...   \n",
       "1004  In statistical machine translation, correspond...   \n",
       "1005  Aligning parallel texts has recently received ...   \n",
       "1006  Pronoun resolution is a difficult but vital pa...   \n",
       "1007  Recognising textual entailment (RTE) is the ta...   \n",
       "1008  The problem with successful resolution of ambi...   \n",
       "\n",
       "                                              citations  \\\n",
       "0     [Berland and Charniak (1999) use Hearst style ...   \n",
       "1     [The program takes the output of char_align (C...   \n",
       "2     [Chinese word segmentation is done by the Stan...   \n",
       "3     [Recent work in this area includes Velikovich ...   \n",
       "4     [They use two kinds of features: syntactic one...   \n",
       "...                                                 ...   \n",
       "1004  [In addition, Niessen and Ney (2004) decompose...   \n",
       "1005  [There have been quite a number of recent pape...   \n",
       "1006  [, We follow the closed track setting where sy...   \n",
       "1007  [However, this method does not work for realwo...   \n",
       "1008  [The state of the art is a supervised algorith...   \n",
       "\n",
       "                                                 golden  \n",
       "0     Finding Parts In Very Large Corpora\\nWe presen...  \n",
       "1     The Mathematics Of Statistical Machine Transla...  \n",
       "2     Optimizing Chinese Word Segmentation for Machi...  \n",
       "3     The viability of web-derived polarity lexicons...  \n",
       "4     Combining Lexical Syntactic And Semantic Featu...  \n",
       "...                                                 ...  \n",
       "1004  Statistical Machine Translation With Scarce Re...  \n",
       "1005  Robust Bilingual Word Alignment For Machine Ai...  \n",
       "1006  Bootstrapping Path-Based Pronoun Resolution\\nW...  \n",
       "1007  Recognising Textual Entailment With Logical In...  \n",
       "1008  Corpus Based PP Attachment Ambiguity Resolutio...  \n",
       "\n",
       "[1009 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create DF with papers and citations\n",
    "\n",
    "raw_cols = []\n",
    "golden = []\n",
    "for fpn in range(len(xmlfiles)):\n",
    "    ab,bod,err = parse_xml_abstract(xmlfiles[fpn])\n",
    "    if err:\n",
    "        #print(fp, err)\n",
    "        continue\n",
    "    f = open(citations[fpn]) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    only_text = []\n",
    "    for entry in data:\n",
    "        only_text.append(entry['clean_text'])\n",
    "#     print(only_text)\n",
    "    \n",
    "    f2 = open(golden_summaries[fpn],\"r+\") \n",
    "    golden = f2.read()\n",
    "\n",
    "    \n",
    "    raw_cols.append([ab,bod,only_text, golden])\n",
    "\n",
    "df = pd.DataFrame(raw_cols, columns=[\"abstract\",\"body\",\"citations\", \"golden\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Cited text spans identification\n",
    "\n",
    "Finding the top x sentences in the body that have the largest similarity (as per ROUGE score) with the citations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1 - Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT BEING USED\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkQuality(sentence):\n",
    "    \n",
    "    '''Check the quality of body sentences, to classify each of them as eligible (or not) to be a cited text span'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    \n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    length = len(tokenized_text)\n",
    "    alpha = 0\n",
    "    nonAlpha = 0\n",
    "    found = 0\n",
    "    nonFound = 0\n",
    "    upper = 0\n",
    "    stop = 0\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    for token in tokenized_text:\n",
    "        #print(token)\n",
    "        if len(token)==1:\n",
    "            if token.isalpha():\n",
    "                # count number of single alpha chars\n",
    "                alpha+=1\n",
    "            else:\n",
    "                # count number of not single non-alpha chars\n",
    "                nonAlpha+=1\n",
    "        else:\n",
    "            if(token.lower() in stop_words):\n",
    "                # count number of stop words\n",
    "                stop+=1\n",
    "            else:\n",
    "                lemma = lemmatizer.lemmatize(token.lower())\n",
    "                # count number of Synsets for alpha tokens\n",
    "                if token.isalpha():\n",
    "                    if (len(wn.synsets(lemma))>0):\n",
    "                        found+=1 # alpha tokens that have Synsets\n",
    "                    else:\n",
    "                        nonFound+=1 # alpha tokens that dont have Synsets\n",
    "                else:\n",
    "                    nonAlpha+=1 #non alpha tokens\n",
    "    \n",
    "    # calculate shares \n",
    "    alphaS = alpha/length\n",
    "    nonAlphaS = nonAlpha/length\n",
    "    foundS = found/length\n",
    "    nonFoundS = nonFound/length\n",
    "#     upperS = upper/length\n",
    "    stopS = stop/length\n",
    "    \n",
    "    good_quality = True\n",
    "    \n",
    "    if(nonFoundS>0.2):\n",
    "        good_quality = False\n",
    "    if(foundS<0.1):\n",
    "        good_quality = False\n",
    "    if(alphaS>0.2):\n",
    "        good_quality = False\n",
    "    if(nonAlphaS>0.5):\n",
    "        good_quality = False\n",
    "    if len(tokenized_text)< 6:\n",
    "        good_quality = False\n",
    "    \n",
    "    if (\"equation\" in sentence.lower()) | (\"section\" in sentence.lower()) | (\"table\" in sentence.lower()) | (\"figure\" in sentence.lower()) | (\"=\" in sentence) | (\">\" in sentence) | (\"<\" in sentence) | (\"p(\" in sentence.lower()):\n",
    "        good_quality = False\n",
    "    \n",
    "    # remove sentences that has dates\n",
    "    match = re.match(r'.*([1-3][0-9]{3})', sentence)\n",
    "    if match is not None:\n",
    "        good_quality = False \n",
    "        \n",
    "    return good_quality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cited_text_spans_ids(df,n_sent = 3):\n",
    "\n",
    "    '''Find (n_sent) body sentences most similar to citation sentences \n",
    "    inputs: \n",
    "        df: dataframe with simularity scores between each body sentence and citation \n",
    "        n_set: number of body sentences to output\n",
    "    output:\n",
    "        list of best ranked body sentetences ids\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    # empty list where we'll store best scored body sentences \n",
    "    body_sent_all_ids = []\n",
    "    body_sent_id = []\n",
    "     \n",
    "    # create an empty dataframe (num rows = num sentences in citations;  num col = n_sent)\n",
    "    # we'll store here the body sentences ids with largest similarity\n",
    "    sim_df_max = pd.DataFrame(0.0, index=[j for j in range(len(citations_sentences))], columns= [j for j in range(n_sent)])\n",
    "    \n",
    "    for ns in range(n_sent):\n",
    "        # get the indexes that maximize similarity for each column (i.e., for each citation sentence)    \n",
    "        sim_df_max[ns] = sim_df.idxmax(axis=0, skipna=True)\n",
    "        # reset the largest values to zero, so we can retreive other top values in the loop\n",
    "        sim_df[ns][sim_df_max[ns]] = 0\n",
    "\n",
    "    \n",
    "    # loop over the number of body sentences we want to retrieve\n",
    "    for ns in range(n_sent): \n",
    "        # turn all columns into a list of best scored body sentences ids  \n",
    "        li = sim_df_max[ns].tolist() \n",
    "        body_sent_all_ids = body_sent_all_ids + li\n",
    "    \n",
    "#     print(body_sent_all_ids)\n",
    "    for ns in range(n_sent):   \n",
    "        # append best scored sentence id over all citations sentences\n",
    "        best_sent_id_single = int(s.mode(body_sent_all_ids)[0])\n",
    "        body_sent_id.append(best_sent_id_single)\n",
    "        # reset the largest values to zero, so we can retreive other top values in the loop                    \n",
    "        body_sent_all_ids = list(filter(lambda a: a != best_sent_id_single, body_sent_all_ids)) \n",
    "#         print(body_sent_all_ids)\n",
    "#         if len(body_sent_all_ids) == 0:\n",
    "#             break\n",
    "\n",
    "    return body_sent_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2 - Select 'x' body sentences to \"represent\" citations as model inputs - i.e., find cited text spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an empty column in the original dataframe, in which we'll store the cited text spans for each paper \n",
    "df['cited_text_spans'] = \"\"\n",
    "\n",
    "## instantiate nlp tools to read the data\n",
    "# vectorizer = Vectorizer() - NOT BEING USED - USED FOR COSINE SIMILARITY\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "## instantiate rouge score\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# start time to keep track of the timing\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 secs to run: 28.13043522834778\n",
      "1 secs to run: 4.362665891647339\n",
      "2 secs to run: 3.230881929397583\n",
      "3 secs to run: 2.4237399101257324\n",
      "4 secs to run: 1.165165901184082\n",
      "5 secs to run: 3.8589978218078613\n",
      "6 secs to run: 5.2412028312683105\n",
      "7 secs to run: 2.140411853790283\n",
      "8 secs to run: 1.009371042251587\n",
      "9 secs to run: 5.661731958389282\n",
      "10 secs to run: 2.139131784439087\n",
      "11 secs to run: 5.031651973724365\n",
      "12 secs to run: 0.4275538921356201\n",
      "13 secs to run: 2.17665696144104\n",
      "16 secs to run: 5.0010199546813965\n",
      "17 secs to run: 3.8418338298797607\n",
      "18 secs to run: 0.5897881984710693\n",
      "19 secs to run: 2.9185030460357666\n",
      "20 secs to run: 2.1462759971618652\n",
      "22 secs to run: 2.7976250648498535\n",
      "23 secs to run: 2.9503540992736816\n",
      "24 secs to run: 2.71140193939209\n",
      "25 secs to run: 2.8566532135009766\n",
      "26 secs to run: 1.1282789707183838\n",
      "27 secs to run: 1.2745771408081055\n",
      "28 secs to run: 1.9119617938995361\n",
      "29 secs to run: 1.844172716140747\n",
      "30 secs to run: 2.220937967300415\n",
      "31 secs to run: 2.7689101696014404\n",
      "33 secs to run: 5.754034042358398\n",
      "34 secs to run: 1.6619017124176025\n",
      "36 secs to run: 0.6760129928588867\n",
      "37 secs to run: 3.2139153480529785\n",
      "38 secs to run: 4.137537002563477\n",
      "39 secs to run: 3.4057559967041016\n",
      "40 secs to run: 2.3621320724487305\n",
      "41 secs to run: 2.6921169757843018\n",
      "42 secs to run: 2.57856822013855\n",
      "43 secs to run: 5.783003807067871\n",
      "44 secs to run: 2.8790221214294434\n",
      "45 secs to run: 3.885242223739624\n",
      "46 secs to run: 0.41968727111816406\n",
      "47 secs to run: 4.030821084976196\n",
      "48 secs to run: 2.5155348777770996\n",
      "49 secs to run: 2.133606195449829\n",
      "50 secs to run: 5.109308958053589\n",
      "51 secs to run: 0.29652881622314453\n",
      "52 secs to run: 3.1915130615234375\n",
      "53 secs to run: 4.386413097381592\n",
      "54 secs to run: 3.2136731147766113\n",
      "55 secs to run: 3.039994955062866\n",
      "56 secs to run: 3.975919246673584\n",
      "57 secs to run: 3.0594611167907715\n",
      "58 secs to run: 0.6520977020263672\n",
      "59 secs to run: 2.0014891624450684\n",
      "60 secs to run: 4.8325278759002686\n",
      "61 secs to run: 3.8241097927093506\n",
      "62 secs to run: 0.46228504180908203\n",
      "63 secs to run: 2.4684898853302\n",
      "64 secs to run: 1.7916250228881836\n",
      "65 secs to run: 2.859998941421509\n",
      "66 secs to run: 1.9611120223999023\n",
      "67 secs to run: 1.7898459434509277\n",
      "68 secs to run: 3.1653146743774414\n",
      "70 secs to run: 4.137554883956909\n",
      "71 secs to run: 2.543564796447754\n",
      "72 secs to run: 2.112504005432129\n",
      "73 secs to run: 3.568726062774658\n",
      "74 secs to run: 2.9657092094421387\n",
      "75 secs to run: 2.460289239883423\n",
      "76 secs to run: 6.092701196670532\n",
      "77 secs to run: 2.1194839477539062\n",
      "78 secs to run: 1.95809006690979\n",
      "79 secs to run: 0.35089707374572754\n",
      "80 secs to run: 2.3428380489349365\n",
      "81 secs to run: 2.673444986343384\n",
      "82 secs to run: 1.226646900177002\n",
      "83 secs to run: 2.3106942176818848\n",
      "84 secs to run: 3.344113349914551\n",
      "85 secs to run: 0.9172279834747314\n",
      "86 secs to run: 3.1990609169006348\n",
      "87 secs to run: 3.593961000442505\n",
      "88 secs to run: 1.1070778369903564\n",
      "90 secs to run: 2.2763471603393555\n",
      "91 secs to run: 0.7947251796722412\n",
      "92 secs to run: 2.840707302093506\n",
      "93 secs to run: 1.6604108810424805\n",
      "94 secs to run: 2.0442230701446533\n",
      "95 secs to run: 3.043691873550415\n",
      "96 secs to run: 4.3558878898620605\n",
      "97 secs to run: 2.1704981327056885\n",
      "98 secs to run: 2.8721020221710205\n",
      "99 secs to run: 2.233898162841797\n",
      "100 secs to run: 2.465787172317505\n",
      "101 secs to run: 3.7488210201263428\n",
      "102 secs to run: 1.6857860088348389\n",
      "103 secs to run: 1.6376502513885498\n",
      "104 secs to run: 3.846440076828003\n",
      "105 secs to run: 3.945723056793213\n",
      "106 secs to run: 1.7923431396484375\n",
      "107 secs to run: 2.519383192062378\n",
      "108 secs to run: 0.2980642318725586\n",
      "109 secs to run: 3.0782415866851807\n",
      "110 secs to run: 2.4645700454711914\n",
      "111 secs to run: 3.84458065032959\n",
      "112 secs to run: 2.4417951107025146\n",
      "113 secs to run: 3.2950940132141113\n",
      "114 secs to run: 0.5019998550415039\n",
      "115 secs to run: 0.6544110774993896\n",
      "116 secs to run: 2.9787750244140625\n",
      "117 secs to run: 1.4796440601348877\n",
      "118 secs to run: 3.311290979385376\n",
      "119 secs to run: 1.0660130977630615\n",
      "120 secs to run: 1.7503340244293213\n",
      "121 secs to run: 3.293355941772461\n",
      "122 secs to run: 2.479212760925293\n",
      "123 secs to run: 2.262421131134033\n",
      "125 secs to run: 3.4695799350738525\n",
      "126 secs to run: 4.316267013549805\n",
      "127 secs to run: 1.9961040019989014\n",
      "128 secs to run: 2.739475965499878\n",
      "129 secs to run: 3.7307348251342773\n",
      "130 secs to run: 3.416254997253418\n",
      "131 secs to run: 2.2704601287841797\n",
      "132 secs to run: 0.9474751949310303\n",
      "133 secs to run: 2.0563299655914307\n",
      "134 secs to run: 1.04302978515625\n",
      "135 secs to run: 1.8175220489501953\n",
      "137 secs to run: 2.2053439617156982\n",
      "140 secs to run: 2.7285969257354736\n",
      "141 secs to run: 2.3856711387634277\n",
      "142 secs to run: 1.5837249755859375\n",
      "143 secs to run: 2.2927119731903076\n",
      "144 secs to run: 3.630229949951172\n",
      "145 secs to run: 1.1285021305084229\n",
      "146 secs to run: 2.037785053253174\n",
      "147 secs to run: 1.8918731212615967\n",
      "148 secs to run: 3.109476089477539\n",
      "149 secs to run: 2.014508008956909\n",
      "150 secs to run: 3.5532970428466797\n",
      "151 secs to run: 1.8603899478912354\n",
      "152 secs to run: 2.4600989818573\n",
      "153 secs to run: 2.7935521602630615\n",
      "154 secs to run: 1.4838449954986572\n",
      "155 secs to run: 2.392548084259033\n",
      "156 secs to run: 1.1796889305114746\n",
      "157 secs to run: 2.2158701419830322\n",
      "158 secs to run: 2.9254860877990723\n",
      "159 secs to run: 2.1249637603759766\n",
      "160 secs to run: 5.89065408706665\n",
      "161 secs to run: 1.253890037536621\n",
      "162 secs to run: 0.1799910068511963\n",
      "163 secs to run: 3.2841598987579346\n",
      "164 secs to run: 0.3569772243499756\n",
      "165 secs to run: 3.1875808238983154\n",
      "166 secs to run: 1.6220052242279053\n",
      "167 secs to run: 3.0364320278167725\n",
      "168 secs to run: 2.3539042472839355\n",
      "169 secs to run: 2.429082155227661\n",
      "170 secs to run: 2.022629737854004\n",
      "171 secs to run: 2.7829339504241943\n",
      "173 secs to run: 3.001634120941162\n",
      "174 secs to run: 3.6307878494262695\n",
      "175 secs to run: 5.085638999938965\n",
      "176 secs to run: 3.274468183517456\n",
      "177 secs to run: 5.479840040206909\n",
      "178 secs to run: 1.3631389141082764\n",
      "179 secs to run: 2.5378873348236084\n",
      "180 secs to run: 2.742799997329712\n",
      "181 secs to run: 1.1022820472717285\n",
      "182 secs to run: 1.393110990524292\n",
      "184 secs to run: 2.803433895111084\n",
      "185 secs to run: 3.0851268768310547\n",
      "186 secs to run: 1.9201133251190186\n",
      "187 secs to run: 2.419058084487915\n",
      "188 secs to run: 3.898625135421753\n",
      "189 secs to run: 1.7561290264129639\n",
      "190 secs to run: 0.617988109588623\n",
      "191 secs to run: 0.6047298908233643\n",
      "192 secs to run: 2.0929579734802246\n",
      "193 secs to run: 2.026895761489868\n",
      "194 secs to run: 3.522939920425415\n",
      "195 secs to run: 1.4588570594787598\n",
      "196 secs to run: 3.2318918704986572\n",
      "197 secs to run: 0.5481407642364502\n",
      "198 secs to run: 1.8547298908233643\n",
      "199 secs to run: 3.132390022277832\n",
      "200 secs to run: 4.163006067276001\n",
      "202 secs to run: 2.7709882259368896\n",
      "203 secs to run: 2.2666900157928467\n",
      "204 secs to run: 1.5417749881744385\n",
      "205 secs to run: 2.311798095703125\n",
      "206 secs to run: 0.5004651546478271\n",
      "207 secs to run: 1.885472059249878\n",
      "208 secs to run: 1.267608880996704\n",
      "209 secs to run: 2.3551156520843506\n",
      "210 secs to run: 0.9261350631713867\n",
      "211 secs to run: 2.5241870880126953\n",
      "212 secs to run: 2.163203001022339\n",
      "213 secs to run: 2.3804078102111816\n",
      "214 secs to run: 5.961463689804077\n",
      "215 secs to run: 2.205026865005493\n",
      "218 secs to run: 3.7534687519073486\n",
      "219 secs to run: 0.9027349948883057\n",
      "220 secs to run: 2.49499773979187\n",
      "221 secs to run: 2.687380790710449\n",
      "222 secs to run: 3.555704116821289\n",
      "223 secs to run: 2.4986088275909424\n",
      "224 secs to run: 5.002058982849121\n",
      "225 secs to run: 1.7678520679473877\n",
      "226 secs to run: 0.9634270668029785\n",
      "227 secs to run: 2.407384157180786\n",
      "228 secs to run: 2.540337085723877\n",
      "229 secs to run: 2.447748899459839\n",
      "230 secs to run: 1.509984016418457\n",
      "231 secs to run: 2.470568895339966\n",
      "232 secs to run: 2.0409631729125977\n",
      "233 secs to run: 1.0564701557159424\n",
      "234 secs to run: 2.012237071990967\n",
      "235 secs to run: 1.8153977394104004\n",
      "236 secs to run: 0.9948506355285645\n",
      "237 secs to run: 2.6160330772399902\n",
      "238 secs to run: 3.031014919281006\n",
      "239 secs to run: 5.634068012237549\n",
      "240 secs to run: 2.114750862121582\n",
      "241 secs to run: 1.1604909896850586\n",
      "242 secs to run: 1.5619699954986572\n",
      "244 secs to run: 0.40024495124816895\n",
      "245 secs to run: 3.14223313331604\n",
      "246 secs to run: 1.3732857704162598\n",
      "247 secs to run: 4.729626893997192\n",
      "248 secs to run: 1.8356530666351318\n",
      "249 secs to run: 2.206178903579712\n",
      "250 secs to run: 1.8575999736785889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 secs to run: 2.060123920440674\n",
      "252 secs to run: 1.9044857025146484\n",
      "254 secs to run: 2.537628173828125\n",
      "255 secs to run: 2.8769469261169434\n",
      "256 secs to run: 2.3430020809173584\n",
      "257 secs to run: 0.8989849090576172\n",
      "258 secs to run: 3.7345449924468994\n",
      "259 secs to run: 2.6130452156066895\n",
      "260 secs to run: 1.8566510677337646\n",
      "261 secs to run: 3.3355231285095215\n",
      "262 secs to run: 2.650179862976074\n",
      "263 secs to run: 0.9806771278381348\n",
      "264 secs to run: 1.0814580917358398\n",
      "265 secs to run: 5.024857997894287\n",
      "266 secs to run: 3.0833122730255127\n",
      "267 secs to run: 4.600793123245239\n",
      "268 secs to run: 1.707157850265503\n",
      "271 secs to run: 2.099086046218872\n",
      "272 secs to run: 2.3056159019470215\n",
      "273 secs to run: 2.7642109394073486\n",
      "274 secs to run: 4.489665985107422\n",
      "276 secs to run: 1.8544440269470215\n",
      "277 secs to run: 2.2864692211151123\n",
      "278 secs to run: 5.149523019790649\n",
      "279 secs to run: 1.9749019145965576\n",
      "280 secs to run: 2.926088809967041\n",
      "281 secs to run: 4.641844987869263\n",
      "282 secs to run: 1.4609088897705078\n",
      "283 secs to run: 1.2407448291778564\n",
      "284 secs to run: 1.3244762420654297\n",
      "285 secs to run: 4.134295225143433\n",
      "286 secs to run: 2.717121124267578\n",
      "287 secs to run: 3.4841020107269287\n",
      "288 secs to run: 1.5094537734985352\n",
      "289 secs to run: 4.699155807495117\n",
      "290 secs to run: 2.216320037841797\n",
      "291 secs to run: 3.863624095916748\n",
      "292 secs to run: 0.6968898773193359\n",
      "293 secs to run: 2.0504400730133057\n",
      "294 secs to run: 3.407283306121826\n",
      "295 secs to run: 2.4847280979156494\n",
      "296 secs to run: 2.754276990890503\n",
      "297 secs to run: 4.823785066604614\n",
      "298 secs to run: 3.078892707824707\n",
      "299 secs to run: 1.6145949363708496\n",
      "300 secs to run: 3.8789010047912598\n",
      "301 secs to run: 1.4548311233520508\n",
      "302 secs to run: 2.837718963623047\n",
      "303 secs to run: 2.881948947906494\n",
      "304 secs to run: 2.734251022338867\n",
      "305 secs to run: 2.3807199001312256\n",
      "306 secs to run: 2.608750820159912\n",
      "307 secs to run: 3.3779947757720947\n",
      "308 secs to run: 2.0987930297851562\n",
      "309 secs to run: 1.7386608123779297\n",
      "310 secs to run: 2.4062469005584717\n",
      "311 secs to run: 1.845836877822876\n",
      "312 secs to run: 0.2623162269592285\n",
      "313 secs to run: 2.1654720306396484\n",
      "314 secs to run: 3.78348708152771\n",
      "315 secs to run: 5.788779973983765\n",
      "316 secs to run: 1.4317340850830078\n",
      "317 secs to run: 3.446035861968994\n",
      "319 secs to run: 2.421602725982666\n",
      "320 secs to run: 0.7743360996246338\n",
      "321 secs to run: 4.631531000137329\n",
      "322 secs to run: 2.634075880050659\n",
      "323 secs to run: 2.1771438121795654\n",
      "324 secs to run: 1.6307930946350098\n",
      "325 secs to run: 2.3536572456359863\n",
      "326 secs to run: 1.6750178337097168\n",
      "327 secs to run: 0.21009516716003418\n",
      "328 secs to run: 3.857954978942871\n",
      "330 secs to run: 2.251070976257324\n",
      "331 secs to run: 2.887253761291504\n",
      "332 secs to run: 2.6112289428710938\n",
      "333 secs to run: 1.9311821460723877\n",
      "334 secs to run: 2.210113048553467\n",
      "335 secs to run: 3.85691499710083\n",
      "336 secs to run: 0.1548159122467041\n",
      "337 secs to run: 2.1629228591918945\n",
      "338 secs to run: 2.0915791988372803\n",
      "339 secs to run: 2.5053062438964844\n",
      "340 secs to run: 2.370702028274536\n",
      "341 secs to run: 2.7959790229797363\n",
      "342 secs to run: 2.212825298309326\n",
      "343 secs to run: 2.518733263015747\n",
      "344 secs to run: 2.799042224884033\n",
      "345 secs to run: 1.8916900157928467\n",
      "346 secs to run: 76.13192486763\n",
      "347 secs to run: 3.147581100463867\n",
      "348 secs to run: 1.4333560466766357\n",
      "349 secs to run: 1.7049601078033447\n",
      "350 secs to run: 2.7453949451446533\n",
      "352 secs to run: 1.945925235748291\n",
      "353 secs to run: 1.8781108856201172\n",
      "354 secs to run: 1.8617019653320312\n",
      "355 secs to run: 3.085761785507202\n",
      "357 secs to run: 2.8735580444335938\n",
      "358 secs to run: 2.8383398056030273\n",
      "359 secs to run: 1.8105878829956055\n",
      "360 secs to run: 2.7633368968963623\n",
      "361 secs to run: 1.5125491619110107\n",
      "362 secs to run: 3.551168918609619\n",
      "363 secs to run: 4.853711843490601\n",
      "364 secs to run: 3.808483123779297\n",
      "366 secs to run: 2.772665023803711\n",
      "367 secs to run: 5.6999077796936035\n",
      "368 secs to run: 3.834857940673828\n",
      "369 secs to run: 2.1324520111083984\n",
      "370 secs to run: 6.78369402885437\n",
      "371 secs to run: 2.9868500232696533\n",
      "372 secs to run: 1.34517502784729\n",
      "373 secs to run: 1.7413740158081055\n",
      "374 secs to run: 2.4231481552124023\n",
      "375 secs to run: 5.1283042430877686\n",
      "376 secs to run: 3.9512109756469727\n",
      "377 secs to run: 1.4634110927581787\n",
      "378 secs to run: 2.9639549255371094\n",
      "379 secs to run: 0.7947292327880859\n",
      "380 secs to run: 1.8118271827697754\n",
      "381 secs to run: 3.06648588180542\n",
      "382 secs to run: 5.812160968780518\n",
      "383 secs to run: 1.7245869636535645\n",
      "384 secs to run: 2.127995014190674\n",
      "385 secs to run: 3.56141996383667\n",
      "386 secs to run: 3.7226979732513428\n",
      "387 secs to run: 2.8890340328216553\n",
      "388 secs to run: 3.166698932647705\n",
      "389 secs to run: 3.180431842803955\n",
      "390 secs to run: 1.1216132640838623\n",
      "391 secs to run: 2.190281391143799\n",
      "392 secs to run: 1.9888670444488525\n",
      "393 secs to run: 3.7912590503692627\n",
      "394 secs to run: 3.736379861831665\n",
      "395 secs to run: 1.965918779373169\n",
      "396 secs to run: 1.620487928390503\n",
      "397 secs to run: 2.1626088619232178\n",
      "398 secs to run: 1.7192659378051758\n",
      "400 secs to run: 2.194153070449829\n",
      "401 secs to run: 2.9180569648742676\n",
      "402 secs to run: 1.5728399753570557\n",
      "403 secs to run: 1.117412805557251\n",
      "404 secs to run: 3.202946662902832\n",
      "405 secs to run: 3.2056188583374023\n",
      "406 secs to run: 1.7864782810211182\n",
      "407 secs to run: 1.6139981746673584\n",
      "408 secs to run: 2.569121837615967\n",
      "409 secs to run: 1.2620818614959717\n",
      "410 secs to run: 1.665125846862793\n",
      "411 secs to run: 2.531683921813965\n",
      "412 secs to run: 81.84305787086487\n",
      "413 secs to run: 20.922545194625854\n",
      "414 secs to run: 14.127063989639282\n",
      "415 secs to run: 2000.624626159668\n",
      "416 secs to run: 0.2452530860900879\n",
      "419 secs to run: 3.558994770050049\n",
      "420 secs to run: 12.445887088775635\n",
      "421 secs to run: 13.381518125534058\n",
      "422 secs to run: 21.25158667564392\n",
      "423 secs to run: 6.484190940856934\n",
      "424 secs to run: 8.781710147857666\n",
      "425 secs to run: 13.753752708435059\n",
      "426 secs to run: 9.044593811035156\n",
      "428 secs to run: 16.07329511642456\n",
      "429 secs to run: 20.105390071868896\n",
      "430 secs to run: 7.543344020843506\n",
      "431 secs to run: 14.026726007461548\n",
      "432 secs to run: 3.087879180908203\n",
      "433 secs to run: 0.9648830890655518\n",
      "434 secs to run: 3.777355909347534\n",
      "435 secs to run: 4.554855823516846\n",
      "436 secs to run: 8.738680839538574\n",
      "437 secs to run: 7.826833009719849\n",
      "438 secs to run: 17.1265971660614\n",
      "439 secs to run: 7.618952035903931\n",
      "440 secs to run: 7.338404178619385\n",
      "441 secs to run: 5.073141098022461\n",
      "442 secs to run: 12.23068904876709\n",
      "443 secs to run: 5.912959098815918\n",
      "444 secs to run: 2.2091119289398193\n",
      "445 secs to run: 3.9595789909362793\n",
      "446 secs to run: 10.163072109222412\n",
      "447 secs to run: 3.3434979915618896\n",
      "448 secs to run: 9.071500062942505\n",
      "449 secs to run: 15.90383529663086\n",
      "450 secs to run: 6.804065942764282\n",
      "451 secs to run: 8.690335988998413\n",
      "452 secs to run: 3.121070146560669\n",
      "453 secs to run: 11.404067039489746\n",
      "454 secs to run: 3.7564828395843506\n",
      "456 secs to run: 10.71945595741272\n",
      "457 secs to run: 9.694152116775513\n",
      "458 secs to run: 6.1424150466918945\n",
      "459 secs to run: 4.482909917831421\n",
      "460 secs to run: 15.340703248977661\n",
      "461 secs to run: 4.798513889312744\n",
      "462 secs to run: 7.344180345535278\n",
      "463 secs to run: 6.336405038833618\n",
      "464 secs to run: 8.80790400505066\n",
      "465 secs to run: 7.2856340408325195\n",
      "466 secs to run: 6.4245710372924805\n",
      "467 secs to run: 11.257840156555176\n",
      "468 secs to run: 3.9780969619750977\n",
      "469 secs to run: 8.196572303771973\n",
      "470 secs to run: 10.343268871307373\n",
      "471 secs to run: 9.222608089447021\n",
      "472 secs to run: 7.950951814651489\n",
      "473 secs to run: 2.2095448970794678\n",
      "474 secs to run: 9.03220796585083\n",
      "475 secs to run: 5.815064907073975\n",
      "476 secs to run: 6.336530923843384\n",
      "477 secs to run: 4.818272113800049\n",
      "478 secs to run: 10.0435209274292\n",
      "479 secs to run: 2.2717440128326416\n",
      "480 secs to run: 2.008650779724121\n",
      "481 secs to run: 6.244895935058594\n",
      "482 secs to run: 8.501584768295288\n",
      "483 secs to run: 6.033946752548218\n",
      "484 secs to run: 3.8284811973571777\n",
      "485 secs to run: 6.5641961097717285\n",
      "486 secs to run: 5.77623987197876\n",
      "487 secs to run: 8.573554992675781\n",
      "488 secs to run: 4.91635799407959\n",
      "489 secs to run: 1.3805909156799316\n",
      "490 secs to run: 7.373196840286255\n",
      "491 secs to run: 4.4133360385894775\n",
      "492 secs to run: 7.221996068954468\n",
      "493 secs to run: 6.754619121551514\n",
      "494 secs to run: 6.850955009460449\n",
      "495 secs to run: 7.474884986877441\n",
      "496 secs to run: 6.696072816848755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 secs to run: 15.453811883926392\n",
      "498 secs to run: 6.077391147613525\n",
      "499 secs to run: 5.901822805404663\n",
      "500 secs to run: 5.828765869140625\n",
      "503 secs to run: 13.142293930053711\n",
      "504 secs to run: 12.653347730636597\n",
      "505 secs to run: 6.062422752380371\n",
      "506 secs to run: 7.952393293380737\n",
      "507 secs to run: 6.793191909790039\n",
      "508 secs to run: 1.9990131855010986\n",
      "509 secs to run: 6.670324087142944\n",
      "510 secs to run: 7.85126805305481\n",
      "511 secs to run: 3.3511030673980713\n",
      "512 secs to run: 5.045431137084961\n",
      "513 secs to run: 4.448401927947998\n",
      "514 secs to run: 7.111703157424927\n",
      "515 secs to run: 1.8103091716766357\n",
      "516 secs to run: 13.122345924377441\n",
      "517 secs to run: 4.104737997055054\n",
      "518 secs to run: 9.793962001800537\n",
      "519 secs to run: 4.446645975112915\n",
      "520 secs to run: 6.732348918914795\n",
      "521 secs to run: 5.522266864776611\n",
      "522 secs to run: 4.918154954910278\n",
      "523 secs to run: 6.670363187789917\n",
      "524 secs to run: 2.787013053894043\n",
      "525 secs to run: 7.267153024673462\n",
      "526 secs to run: 10.260302782058716\n",
      "527 secs to run: 5.091728210449219\n",
      "528 secs to run: 7.178795099258423\n",
      "529 secs to run: 11.098300218582153\n",
      "530 secs to run: 10.107569932937622\n",
      "531 secs to run: 5.452003717422485\n",
      "532 secs to run: 6.489515781402588\n",
      "533 secs to run: 10.87412714958191\n",
      "535 secs to run: 3.403898000717163\n",
      "536 secs to run: 3.7974257469177246\n",
      "537 secs to run: 11.5070641040802\n",
      "538 secs to run: 9.644056797027588\n",
      "539 secs to run: 9.664015054702759\n",
      "540 secs to run: 4.027907848358154\n",
      "541 secs to run: 9.843029022216797\n",
      "542 secs to run: 12.184550046920776\n",
      "543 secs to run: 3.1377668380737305\n",
      "544 secs to run: 7.480109214782715\n",
      "545 secs to run: 5.2092368602752686\n",
      "546 secs to run: 5.8714330196380615\n",
      "547 secs to run: 6.598674774169922\n",
      "548 secs to run: 7.051275014877319\n",
      "549 secs to run: 2.267158031463623\n",
      "550 secs to run: 2.3561179637908936\n",
      "551 secs to run: 6.3108837604522705\n",
      "552 secs to run: 5.311011075973511\n",
      "553 secs to run: 8.783877849578857\n",
      "555 secs to run: 6.289766788482666\n",
      "556 secs to run: 1.9255120754241943\n",
      "558 secs to run: 6.20268702507019\n",
      "559 secs to run: 3.5722579956054688\n",
      "560 secs to run: 6.090556859970093\n",
      "561 secs to run: 5.167709112167358\n",
      "563 secs to run: 2.549316883087158\n",
      "564 secs to run: 7.840800046920776\n",
      "565 secs to run: 2.1325089931488037\n",
      "566 secs to run: 4.80094575881958\n",
      "567 secs to run: 4.522539138793945\n",
      "568 secs to run: 5.808074951171875\n",
      "569 secs to run: 6.537474870681763\n",
      "570 secs to run: 8.962839126586914\n",
      "572 secs to run: 1.23294997215271\n",
      "573 secs to run: 3.2783451080322266\n",
      "574 secs to run: 3.0773589611053467\n",
      "575 secs to run: 4.512234926223755\n",
      "576 secs to run: 6.397955656051636\n",
      "577 secs to run: 5.471328020095825\n",
      "578 secs to run: 2.409385919570923\n",
      "579 secs to run: 4.607294321060181\n",
      "580 secs to run: 3.41452693939209\n",
      "581 secs to run: 4.947839021682739\n",
      "582 secs to run: 4.505170822143555\n",
      "583 secs to run: 12.652397155761719\n",
      "584 secs to run: 11.665536165237427\n",
      "585 secs to run: 5.4090940952301025\n",
      "586 secs to run: 11.623777151107788\n",
      "587 secs to run: 9.007943153381348\n",
      "588 secs to run: 1.8745973110198975\n",
      "589 secs to run: 5.126639127731323\n",
      "590 secs to run: 8.039057731628418\n",
      "591 secs to run: 9.532558679580688\n",
      "592 secs to run: 4.084312200546265\n",
      "593 secs to run: 5.671690940856934\n",
      "594 secs to run: 7.427401065826416\n",
      "595 secs to run: 5.748751163482666\n",
      "596 secs to run: 5.446011066436768\n",
      "597 secs to run: 8.445892095565796\n",
      "598 secs to run: 2.669743061065674\n",
      "601 secs to run: 3.6511590480804443\n",
      "602 secs to run: 4.566825866699219\n",
      "603 secs to run: 2.70485520362854\n",
      "604 secs to run: 6.124402046203613\n",
      "605 secs to run: 5.145826101303101\n",
      "606 secs to run: 4.358255863189697\n",
      "607 secs to run: 5.583601236343384\n",
      "608 secs to run: 2.3353850841522217\n",
      "609 secs to run: 1.2901036739349365\n",
      "610 secs to run: 6.390260934829712\n",
      "611 secs to run: 2.8623509407043457\n",
      "612 secs to run: 5.682673215866089\n",
      "613 secs to run: 6.174326181411743\n",
      "614 secs to run: 5.766539096832275\n",
      "615 secs to run: 7.674606084823608\n",
      "616 secs to run: 6.133180141448975\n",
      "617 secs to run: 6.555742025375366\n",
      "618 secs to run: 4.006216049194336\n",
      "619 secs to run: 4.2034642696380615\n",
      "620 secs to run: 5.118366956710815\n",
      "621 secs to run: 1.3650610446929932\n",
      "622 secs to run: 7.671510934829712\n",
      "623 secs to run: 5.473725318908691\n",
      "624 secs to run: 2.812335968017578\n",
      "625 secs to run: 6.104833126068115\n",
      "626 secs to run: 4.906182765960693\n",
      "627 secs to run: 5.88466215133667\n",
      "629 secs to run: 4.500445127487183\n",
      "630 secs to run: 3.971719980239868\n",
      "631 secs to run: 12.762452840805054\n",
      "632 secs to run: 4.490457057952881\n",
      "633 secs to run: 9.173640251159668\n",
      "634 secs to run: 7.5503013134002686\n",
      "635 secs to run: 6.445266246795654\n",
      "636 secs to run: 6.452800989151001\n",
      "637 secs to run: 12.990158796310425\n",
      "638 secs to run: 4.505861043930054\n",
      "639 secs to run: 6.08734393119812\n",
      "640 secs to run: 10.628381967544556\n",
      "641 secs to run: 4.898649215698242\n",
      "642 secs to run: 2.869696855545044\n",
      "643 secs to run: 8.722007036209106\n",
      "644 secs to run: 4.28740382194519\n",
      "646 secs to run: 8.821316003799438\n",
      "647 secs to run: 6.807497978210449\n",
      "648 secs to run: 5.772747039794922\n",
      "649 secs to run: 3.6432178020477295\n",
      "650 secs to run: 2.8235349655151367\n",
      "651 secs to run: 1.1321640014648438\n",
      "652 secs to run: 12.328907012939453\n",
      "654 secs to run: 1.8526289463043213\n",
      "655 secs to run: 10.58393120765686\n",
      "656 secs to run: 9.085810899734497\n",
      "657 secs to run: 2.2831687927246094\n",
      "658 secs to run: 8.099771738052368\n",
      "659 secs to run: 6.875237703323364\n",
      "660 secs to run: 6.322861194610596\n",
      "661 secs to run: 7.439275026321411\n",
      "662 secs to run: 6.962055921554565\n",
      "663 secs to run: 7.767362117767334\n",
      "664 secs to run: 6.42716908454895\n",
      "666 secs to run: 4.1095521450042725\n",
      "668 secs to run: 6.041254281997681\n",
      "669 secs to run: 6.143020153045654\n",
      "670 secs to run: 6.347253084182739\n",
      "671 secs to run: 3.767058849334717\n",
      "672 secs to run: 0.6649460792541504\n",
      "673 secs to run: 4.7642881870269775\n",
      "676 secs to run: 7.257795095443726\n",
      "677 secs to run: 4.4053990840911865\n",
      "678 secs to run: 4.074356317520142\n",
      "679 secs to run: 3.6915178298950195\n",
      "680 secs to run: 1.5371990203857422\n",
      "681 secs to run: 7.335878133773804\n",
      "682 secs to run: 5.449787855148315\n",
      "683 secs to run: 5.218986988067627\n",
      "685 secs to run: 7.683608055114746\n",
      "686 secs to run: 5.545839071273804\n",
      "688 secs to run: 10.465987920761108\n",
      "689 secs to run: 5.014150142669678\n",
      "690 secs to run: 11.589818716049194\n",
      "691 secs to run: 5.005078077316284\n",
      "692 secs to run: 4.867319822311401\n",
      "693 secs to run: 3.267083168029785\n",
      "694 secs to run: 3.3708879947662354\n",
      "695 secs to run: 6.533900022506714\n",
      "697 secs to run: 3.44724702835083\n",
      "698 secs to run: 8.314389944076538\n",
      "699 secs to run: 11.304924011230469\n",
      "701 secs to run: 3.5393710136413574\n",
      "702 secs to run: 5.733123064041138\n",
      "703 secs to run: 3.635918140411377\n",
      "704 secs to run: 4.388088941574097\n",
      "705 secs to run: 8.436939239501953\n",
      "706 secs to run: 13.826614141464233\n",
      "707 secs to run: 4.305714845657349\n",
      "708 secs to run: 5.179271936416626\n",
      "709 secs to run: 7.308019161224365\n",
      "710 secs to run: 10.67127513885498\n",
      "712 secs to run: 4.463939666748047\n",
      "713 secs to run: 6.617433071136475\n",
      "714 secs to run: 7.238463878631592\n",
      "715 secs to run: 3.2212579250335693\n",
      "716 secs to run: 5.460801839828491\n",
      "717 secs to run: 3.744771957397461\n",
      "718 secs to run: 4.66553807258606\n",
      "719 secs to run: 2.0800158977508545\n",
      "720 secs to run: 5.015039920806885\n",
      "721 secs to run: 9.146847009658813\n",
      "722 secs to run: 2.5976998805999756\n",
      "723 secs to run: 6.717933893203735\n",
      "724 secs to run: 7.5476319789886475\n",
      "725 secs to run: 2.890846014022827\n",
      "726 secs to run: 6.406947135925293\n",
      "727 secs to run: 3.7258102893829346\n",
      "728 secs to run: 2.4932680130004883\n",
      "729 secs to run: 6.447461843490601\n",
      "730 secs to run: 4.19849705696106\n",
      "731 secs to run: 7.248948812484741\n",
      "732 secs to run: 11.045223236083984\n",
      "733 secs to run: 2.0360944271087646\n",
      "734 secs to run: 7.068403959274292\n",
      "736 secs to run: 9.825770139694214\n",
      "737 secs to run: 3.1902310848236084\n",
      "738 secs to run: 2.5584609508514404\n",
      "739 secs to run: 2.3022260665893555\n",
      "740 secs to run: 8.17511796951294\n",
      "741 secs to run: 2.7654221057891846\n",
      "742 secs to run: 6.519837856292725\n",
      "743 secs to run: 5.0995001792907715\n",
      "744 secs to run: 2.289754867553711\n",
      "745 secs to run: 4.156759023666382\n",
      "746 secs to run: 3.3621180057525635\n",
      "747 secs to run: 1.3424713611602783\n",
      "748 secs to run: 4.71494197845459\n",
      "749 secs to run: 2.4341118335723877\n",
      "750 secs to run: 6.683255195617676\n",
      "751 secs to run: 7.331264019012451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752 secs to run: 5.737820863723755\n",
      "753 secs to run: 4.277793884277344\n",
      "754 secs to run: 3.040787935256958\n",
      "755 secs to run: 1.8602628707885742\n",
      "756 secs to run: 2.8907718658447266\n",
      "757 secs to run: 1.2062771320343018\n",
      "758 secs to run: 7.110020160675049\n",
      "759 secs to run: 7.560359954833984\n",
      "760 secs to run: 3.8448331356048584\n",
      "761 secs to run: 5.7879040241241455\n",
      "762 secs to run: 6.350590944290161\n",
      "763 secs to run: 4.932146787643433\n",
      "764 secs to run: 6.655853986740112\n",
      "765 secs to run: 5.526532888412476\n",
      "766 secs to run: 6.086905002593994\n",
      "767 secs to run: 15.919641256332397\n",
      "768 secs to run: 3.0078530311584473\n",
      "769 secs to run: 16.33520197868347\n",
      "771 secs to run: 6.354634046554565\n",
      "772 secs to run: 7.39616322517395\n",
      "773 secs to run: 13.423966884613037\n",
      "774 secs to run: 8.502994060516357\n",
      "776 secs to run: 6.017320156097412\n",
      "777 secs to run: 12.162474870681763\n",
      "778 secs to run: 8.662278890609741\n",
      "779 secs to run: 4.291236877441406\n",
      "780 secs to run: 3.385303020477295\n",
      "781 secs to run: 4.774903774261475\n",
      "782 secs to run: 9.638061046600342\n",
      "783 secs to run: 2.835947036743164\n",
      "784 secs to run: 6.467288017272949\n",
      "785 secs to run: 6.552630186080933\n",
      "786 secs to run: 5.5114030838012695\n",
      "787 secs to run: 8.168698072433472\n",
      "788 secs to run: 3.531475782394409\n",
      "789 secs to run: 3.178197145462036\n",
      "790 secs to run: 3.8569369316101074\n",
      "791 secs to run: 2.879601240158081\n",
      "792 secs to run: 5.439340114593506\n",
      "793 secs to run: 6.829397916793823\n",
      "794 secs to run: 6.974093198776245\n",
      "795 secs to run: 3.9905149936676025\n",
      "796 secs to run: 4.4218690395355225\n",
      "797 secs to run: 2.886829137802124\n",
      "798 secs to run: 6.065858840942383\n",
      "799 secs to run: 3.839829921722412\n",
      "800 secs to run: 2.697794198989868\n",
      "801 secs to run: 1.816021203994751\n",
      "802 secs to run: 6.659351825714111\n",
      "805 secs to run: 6.663811206817627\n",
      "806 secs to run: 6.967638969421387\n",
      "807 secs to run: 5.141402959823608\n",
      "808 secs to run: 5.77028489112854\n",
      "809 secs to run: 7.955662965774536\n",
      "810 secs to run: 7.5204548835754395\n",
      "811 secs to run: 7.578089952468872\n",
      "812 secs to run: 6.430275917053223\n",
      "813 secs to run: 5.397148847579956\n",
      "814 secs to run: 5.364098072052002\n",
      "815 secs to run: 5.4903318881988525\n",
      "816 secs to run: 1.9019880294799805\n",
      "817 secs to run: 8.985385179519653\n",
      "818 secs to run: 8.690191268920898\n",
      "819 secs to run: 9.96600079536438\n",
      "820 secs to run: 3.3262779712677\n",
      "821 secs to run: 6.848412990570068\n",
      "822 secs to run: 5.6968770027160645\n",
      "823 secs to run: 3.40290904045105\n",
      "824 secs to run: 5.715890169143677\n",
      "825 secs to run: 9.855529069900513\n",
      "826 secs to run: 8.576472043991089\n",
      "827 secs to run: 5.762906074523926\n",
      "828 secs to run: 4.026231050491333\n",
      "830 secs to run: 5.0720720291137695\n",
      "831 secs to run: 5.118685960769653\n",
      "832 secs to run: 1.0118651390075684\n",
      "833 secs to run: 5.092919111251831\n",
      "834 secs to run: 3.779853105545044\n",
      "836 secs to run: 6.8896238803863525\n",
      "837 secs to run: 6.397036075592041\n",
      "838 secs to run: 5.729530096054077\n",
      "839 secs to run: 5.473311901092529\n",
      "840 secs to run: 3.4113831520080566\n",
      "841 secs to run: 2.0529348850250244\n",
      "842 secs to run: 6.4483418464660645\n",
      "843 secs to run: 3.182802200317383\n",
      "844 secs to run: 2.2680490016937256\n",
      "845 secs to run: 6.512541055679321\n",
      "846 secs to run: 3.1420400142669678\n",
      "847 secs to run: 3.975144147872925\n",
      "848 secs to run: 1.085400104522705\n",
      "849 secs to run: 5.598327159881592\n",
      "850 secs to run: 2.9569530487060547\n",
      "851 secs to run: 4.868053197860718\n",
      "852 secs to run: 4.120976209640503\n",
      "853 secs to run: 6.617106199264526\n",
      "854 secs to run: 0.9028189182281494\n",
      "855 secs to run: 2.6394996643066406\n",
      "856 secs to run: 2.6051368713378906\n",
      "857 secs to run: 8.241500854492188\n",
      "858 secs to run: 10.88259506225586\n",
      "859 secs to run: 2.181394100189209\n",
      "860 secs to run: 3.596971035003662\n",
      "861 secs to run: 4.51789116859436\n",
      "862 secs to run: 6.975198268890381\n",
      "863 secs to run: 10.499271869659424\n",
      "864 secs to run: 4.435920715332031\n",
      "865 secs to run: 5.653455018997192\n",
      "866 secs to run: 3.505347967147827\n",
      "868 secs to run: 3.7091000080108643\n",
      "869 secs to run: 3.6139602661132812\n",
      "871 secs to run: 3.672297954559326\n",
      "872 secs to run: 2.5458691120147705\n",
      "873 secs to run: 7.862630128860474\n",
      "874 secs to run: 8.404528141021729\n",
      "875 secs to run: 3.4733760356903076\n",
      "876 secs to run: 5.039223909378052\n",
      "877 secs to run: 9.54413390159607\n",
      "878 secs to run: 2.6095259189605713\n",
      "879 secs to run: 1.5140008926391602\n",
      "880 secs to run: 2.639224052429199\n",
      "881 secs to run: 11.874248027801514\n",
      "883 secs to run: 2.4983909130096436\n",
      "884 secs to run: 7.349085807800293\n",
      "885 secs to run: 5.3564159870147705\n",
      "886 secs to run: 4.220834016799927\n",
      "887 secs to run: 2.9497759342193604\n",
      "888 secs to run: 2.33626127243042\n",
      "889 secs to run: 6.583667039871216\n",
      "890 secs to run: 8.615247011184692\n",
      "891 secs to run: 4.95933985710144\n",
      "892 secs to run: 2.569700002670288\n",
      "893 secs to run: 5.9878318309783936\n",
      "894 secs to run: 7.79871678352356\n",
      "895 secs to run: 5.366609811782837\n",
      "896 secs to run: 12.872743844985962\n",
      "899 secs to run: 3.563455104827881\n",
      "900 secs to run: 6.021603107452393\n",
      "901 secs to run: 2.0527360439300537\n",
      "902 secs to run: 4.7991578578948975\n",
      "903 secs to run: 8.235167980194092\n",
      "904 secs to run: 10.699371099472046\n",
      "905 secs to run: 3.1459851264953613\n",
      "906 secs to run: 10.325804948806763\n",
      "907 secs to run: 5.764603853225708\n",
      "908 secs to run: 6.4021806716918945\n",
      "909 secs to run: 1.7379779815673828\n",
      "910 secs to run: 6.070749998092651\n",
      "911 secs to run: 5.1134867668151855\n",
      "912 secs to run: 3.3586690425872803\n",
      "913 secs to run: 3.216042995452881\n",
      "914 secs to run: 4.016812086105347\n",
      "915 secs to run: 2.6095480918884277\n",
      "916 secs to run: 6.532297134399414\n",
      "917 secs to run: 2.663403034210205\n",
      "918 secs to run: 3.4929590225219727\n",
      "919 secs to run: 3.2584609985351562\n",
      "920 secs to run: 8.768559217453003\n",
      "921 secs to run: 1.4796900749206543\n",
      "922 secs to run: 9.610503911972046\n",
      "923 secs to run: 3.522364854812622\n",
      "924 secs to run: 9.733234882354736\n",
      "926 secs to run: 6.420833110809326\n",
      "927 secs to run: 3.148510217666626\n",
      "928 secs to run: 4.677590847015381\n",
      "929 secs to run: 6.4638659954071045\n",
      "930 secs to run: 5.4065330028533936\n",
      "931 secs to run: 2.508957862854004\n",
      "932 secs to run: 6.450242042541504\n",
      "933 secs to run: 4.1906797885894775\n",
      "934 secs to run: 2.349567174911499\n",
      "935 secs to run: 2.6074259281158447\n",
      "936 secs to run: 3.4727590084075928\n",
      "937 secs to run: 4.384911060333252\n",
      "938 secs to run: 3.7235193252563477\n",
      "939 secs to run: 4.998944997787476\n",
      "940 secs to run: 11.702836990356445\n",
      "941 secs to run: 4.751183986663818\n",
      "942 secs to run: 5.198500871658325\n",
      "943 secs to run: 0.28456807136535645\n",
      "944 secs to run: 8.017996072769165\n",
      "945 secs to run: 7.241188049316406\n",
      "946 secs to run: 6.518963098526001\n",
      "947 secs to run: 12.888813018798828\n",
      "948 secs to run: 8.87501311302185\n",
      "949 secs to run: 4.653085231781006\n",
      "950 secs to run: 13.463603973388672\n",
      "951 secs to run: 4.48546290397644\n",
      "952 secs to run: 6.434097051620483\n",
      "953 secs to run: 8.124962091445923\n",
      "954 secs to run: 6.434704065322876\n",
      "955 secs to run: 2.456089735031128\n",
      "956 secs to run: 8.479569911956787\n",
      "957 secs to run: 7.590595006942749\n",
      "958 secs to run: 7.772430181503296\n",
      "959 secs to run: 4.816622972488403\n",
      "960 secs to run: 6.889766216278076\n",
      "961 secs to run: 4.926170110702515\n",
      "962 secs to run: 5.489048719406128\n",
      "963 secs to run: 9.196213960647583\n",
      "964 secs to run: 6.951993703842163\n",
      "965 secs to run: 3.1244521141052246\n",
      "966 secs to run: 5.7255401611328125\n",
      "967 secs to run: 4.798799991607666\n",
      "968 secs to run: 6.049817085266113\n",
      "969 secs to run: 7.0427491664886475\n",
      "970 secs to run: 6.984885931015015\n",
      "971 secs to run: 10.56949496269226\n",
      "972 secs to run: 5.528345108032227\n",
      "973 secs to run: 4.825441122055054\n",
      "974 secs to run: 4.087423801422119\n",
      "975 secs to run: 2.8572158813476562\n",
      "976 secs to run: 5.809921979904175\n",
      "977 secs to run: 8.550433874130249\n",
      "978 secs to run: 7.459748983383179\n",
      "979 secs to run: 6.275986194610596\n",
      "980 secs to run: 7.975539922714233\n",
      "981 secs to run: 4.883548021316528\n",
      "982 secs to run: 7.537078142166138\n",
      "983 secs to run: 5.5424041748046875\n",
      "984 secs to run: 5.39570689201355\n",
      "986 secs to run: 4.73210072517395\n",
      "987 secs to run: 10.304458141326904\n",
      "988 secs to run: 4.138206958770752\n",
      "989 secs to run: 7.280457973480225\n",
      "990 secs to run: 6.494989633560181\n",
      "991 secs to run: 4.654731035232544\n",
      "992 secs to run: 2.9105207920074463\n",
      "994 secs to run: 1.5482358932495117\n",
      "995 secs to run: 6.373143196105957\n",
      "996 secs to run: 2.0642433166503906\n",
      "997 secs to run: 5.25844407081604\n",
      "998 secs to run: 8.861373901367188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 secs to run: 2.5979416370391846\n",
      "1000 secs to run: 5.411471843719482\n",
      "1001 secs to run: 8.889000177383423\n",
      "1002 secs to run: 8.704251289367676\n",
      "1003 secs to run: 9.018835067749023\n",
      "1004 secs to run: 6.599794149398804\n",
      "1005 secs to run: 3.939152717590332\n",
      "1006 secs to run: 11.757780075073242\n",
      "1007 secs to run: 2.949416160583496\n",
      "1008 secs to run: 13.22401213645935\n"
     ]
    }
   ],
   "source": [
    "for paper_id in df.index: # [i for i in df.index if i >79]:\n",
    "    \n",
    "    body_sentences = []\n",
    "    \n",
    "    # split body into sentences\n",
    "    body_sentences_tok = df.body[paper_id].replace(\"et al.\", \"et al\").replace(\"e.g.\", \"eg\").replace(\"eg.\", \"eg\").replace(\"i.e.\", \"ie\").replace(\"ie.\", \"ie\")\n",
    "    body_sentences_tok = body_sentences_tok.replace(\".1\", \". \").replace(\".2\", \". \").replace(\".3\", \".\").replace(\".4\", \". \").replace(\".5\", \". \").replace(\".6\", \". \").replace(\".7\", \". \").replace(\".8\", \". \").replace(\".9\", \". \")\n",
    "\n",
    "    # tokenize body sentences\n",
    "    body_sentences_tok = tokenizer.tokenize(body_sentences_tok)\n",
    "        \n",
    "    # truncate too large body sentences (larger than 512 throws an error - rare cases) and remove \"?\"\n",
    "    body_sentences_tok = [s.replace(\"?\", \"\") for s in body_sentences_tok if len(s) <= 512]\n",
    "    \n",
    "    # remove papers that are too small even before quality check\n",
    "    if len(body_sentences_tok) < 10:\n",
    "        continue\n",
    "        \n",
    "    # get citations sentences (discarding empty entries)\n",
    "    citations_sentences = list(filter(None, df.citations[paper_id]))\n",
    "    \n",
    "    # clean citations\n",
    "    for c in range(len(citations_sentences)):\n",
    "        citations_sentences[c] = re.sub(r\"\\s\\([A-Z][a-z]+,\\s[A-Z][a-z]?\\.[^\\)]*,\\s\\d{4}\\)\", \"\", citations_sentences[c])\n",
    "    \n",
    "#     print(paper_id, \"size after quality check:\", len(body_sentences_tok))\n",
    "    \n",
    "    # truncate the center of the body for large bodies\n",
    "    if len(body_sentences_tok) > 300:\n",
    "        body_sentences_tok = body_sentences_tok[:150] + body_sentences_tok[-150:]\n",
    "#         print(\"truncated\", paper_id, \"new size:\", len(body_sentences_tok))\n",
    "        \n",
    "    # find body sentences with quality\n",
    "    for i in range(len(body_sentences_tok)):\n",
    "        if len(body_sentences_tok[i])>0:\n",
    "            if checkQuality(body_sentences_tok[i]):\n",
    "                body_sentences.append(body_sentences_tok[i])\n",
    "                \n",
    "#     print(\"step 1 done\")\n",
    "\n",
    "    # create an empty dataframe (num rows = num sentences in body;  num col = num sentences in citations)\n",
    "    sim_df = pd.DataFrame(0.0, index=[j for j in range(len(body_sentences))], columns=[j for j in range(len(citations_sentences))])\n",
    "\n",
    "# #     # vectorize body sentences\n",
    "# #     vectorizer.bert(body_sentences)\n",
    "# #     vectors_bert_body = vectorizer.vectors\n",
    "\n",
    "# #     # vectorize citations sentences\n",
    "# #     vectorizer.bert(citations_sentences)\n",
    "# #     vectors_bert_citations = vectorizer.vectors\n",
    "\n",
    "#     print(\"step 2 done\")\n",
    "\n",
    "    # nested loop: over body sentences and citations sentences\n",
    "    for body_sentence_id in range(len(body_sentences)):\n",
    "        for citation_sentence_id in range(len(citations_sentences)):\n",
    "            # fill empty dataframe with sim measure\n",
    "#             sim_df[citation_sentence_id][body_sentence_id] = spatial.distance.cosine(vectors_bert_body[body_sentence_id], vectors_bert_citations[citation_sentence_id])\n",
    "            scores = scorer.score(body_sentences[body_sentence_id],citations_sentences[citation_sentence_id] )\n",
    "            sim_df[citation_sentence_id][body_sentence_id] = 100*scores['rouge2'][2]\n",
    "    \n",
    "        \n",
    "#     print(\"step 3 done\")\n",
    "    # get selected body sentences ids - if rouge 2 doesnt work (usually because it yields too many socre =0), \n",
    "    # retry with rouge 1\n",
    "    try:\n",
    "        sent_ids = cited_text_spans_ids(sim_df,3)\n",
    "        \n",
    "    except: \n",
    "        for body_sentence_id in range(len(body_sentences)):\n",
    "            for citation_sentence_id in range(len(citations_sentences)):\n",
    "            # fill empty dataframe with sim measure\n",
    "#             sim_df[citation_sentence_id][body_sentence_id] = spatial.distance.cosine(vectors_bert_body[body_sentence_id], vectors_bert_citations[citation_sentence_id])\n",
    "                scores = scorer.score(body_sentences[body_sentence_id],citations_sentences[citation_sentence_id] )\n",
    "                sim_df[citation_sentence_id][body_sentence_id] = 100*scores['rouge1'][2]\n",
    "#             print(body_sentence_id,citation_sentence_id,100*scores['rouge1'][2]  )\n",
    "        sent_ids = cited_text_spans_ids(sim_df,3)\n",
    "  \n",
    "    \n",
    "#     print(\"step 4 done\")\n",
    "    # fill our large/original dataframe with the best scored body sentences \n",
    "    df.cited_text_spans[paper_id] = [body_sentences[b] for b in sent_ids]\n",
    "    \n",
    "    # keep track of time to run \n",
    "    if paper_id % 250 == 0:\n",
    "        print(paper_id, \"secs to run:\", time.time() - start)\n",
    "        start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"df.pkl\")\n",
    "# df = pd.read_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3 - Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The work was motivated by the needs of the ILEX system for generating descriptions of museum artefacts (in particular, 20th Century jewellery) [Mellish et al 98].', 'This paper presents some initial experiments using stochastic search methods for aspects of text planning.', 'In this task, one is given a set of facts all of which should be included in a text and a set of relations between facts, some of which can be included in the text.']\n",
      "------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Mellish et al (1998) investigate the problem of determining a discourse tree for a set of elementary speech acts which are partially constrained by rhetorical relations.',\n",
       " 'Mellish et al (1998) (and subsequently Karamanis and Manurung 2002) advocate genetic algorithms as an alternative to exhaustively searching for the optimal ordering of descriptions of museum artefacts.',\n",
       " 'Following previous work (Mellish et al, 1998) we used a single fitness function that scored candidates based on their coherence.',\n",
       " 'The genetic algorithms of Mellish et al (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose.',\n",
       " 'For example, the measure from (Mellish et al, 1998) looks at the entire discourse up to the current transition for some of their cost factors.',\n",
       " 'Mellish et al (1998) advocate stochastic search as an alternative to exhaustively examining the search space.',\n",
       " 'As in the case of Mellish et al (1998) we construct an acceptable ordering rather than the best possible one.',\n",
       " 'Mellish et al (1998) made the point that even this restricted approach would soon become intractable with more than a small set of facts when one allows weak RST relations such as Joint and Elaboration into the model.',\n",
       " 'In the late 1990s, Chris Mellish implemented the first stochastic text planner (Mellish et al 1998).',\n",
       " 'The evaluation function of Mellish et al (1998) also was calculated over a sum of local features of the tree, although a wider set of features were involved.',\n",
       " 'For instance, the evaluation function of Mellish et al (1998) assigned +3 for each instance of subject-repetition.',\n",
       " 'Genetic algorithms are also used in [Mellish et al, 1998] where the authors state the problem of given a set of facts to convey and a set of rhetorical relations that can be used to link them together, how one can arrange this material so as to yield the best possible text.',\n",
       " 'Mellish et al (1998) advocate stochastic search methods for document structuring.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check quality of cited text spans\n",
    "# pick any number up to the total number of papers  \n",
    "paper_id = 80 \n",
    "\n",
    "print(df.cited_text_spans[paper_id])\n",
    "print('------')\n",
    "list(filter(None, df.citations[paper_id]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data size: 1009\n",
      "Number of papers with no cited text spans: 67\n",
      "Share (%) of papers with no cited text spans: 6.640237859266601\n"
     ]
    }
   ],
   "source": [
    "# check the number of papers with no cited text spans\n",
    "# -> this can occur because some papers are too small, or have few sentences considered of high quality, \n",
    "#   and were discarded\n",
    "\n",
    "# pick any number up to the total number of papers  \n",
    "size_all_data = df.shape[0]\n",
    "size_no_data = df[df.cited_text_spans == \"\"].shape[0]\n",
    "print(\"Full data size:\", size_all_data)\n",
    "print(\"Number of papers with no cited text spans:\", size_no_data)\n",
    "print(\"Share of papers with no cited text spans (%):\", 100*size_no_data/size_all_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Prepare data for train and inference \n",
    "\n",
    "In this step we will do the following:\n",
    " \n",
    "Step 2.1 - Define model inputs and 'labels' \\\n",
    "Step 2.2 - Clean the data (important specially if we are summarizing the body)\n",
    "Step 2.3 - Divide the data into train, validation and test \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1 - Define model inputs and 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract', 'body', 'citations', 'golden', 'cited_text_spans', 'model_input', 'model_output']\n",
      "---------\n",
      "We present a method for extracting parts of objects from wholes (e.g. \"speedometer\" from \"car\"). Given a very large corpus our method finds part words with 55% accuracy for the top 50 words as ranked by the system. The part list could be scanned by an end-user and added to an existing ontology (such as WordNet), or used as a part of a rough semantic lexicon.We present a method of extracting parts of objects from wholes (eg\n",
      "\"speedometer\" from \"car\"). Our first goal is to find lexical patterns that tend to indicate part-whole relations. In this paper we use the more colloquial \"part-of\" terminology.\n"
     ]
    }
   ],
   "source": [
    "# create a new df named data in case you mess it up\n",
    "data = df.copy()\n",
    "data['model_input'] = ''\n",
    "data['model_output'] = ''\n",
    "\n",
    "# inputs - body only? abstract + cts?\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data['model_input'][i] = data['abstract'][i].replace(\"\\n\", \" \") + \" \".join(data['cited_text_spans'][i])\n",
    "    \n",
    "# output  \n",
    "data['model_output'] = data['golden'] \n",
    "\n",
    "# sanity checks\n",
    "print(list(data))\n",
    "print(\"---------\")\n",
    "print(data['model_input'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1 - Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA:\n",
    "# we can use the checkQuality function to select only those input sentences with high quality\n",
    "\n",
    "def cleanInput(df, truncate_center = 300000):\n",
    "    \n",
    "    ''' Clean input so that low quality sentences don't feed the model\n",
    "        \n",
    "        Inputs: \n",
    "            \n",
    "            df: model data. It has to have a column named 'model_input' \n",
    "        \n",
    "            truncate_center: If the number of sentences in model input is larger than 'truncate_center', \n",
    "                truncate the center of model input - i.e., get only the \n",
    "                first and last x (= truncate_center/2) sentences.\n",
    "        \n",
    "        Output: df with 'cleaned' 'model_input' column \n",
    "        \n",
    "     '''\n",
    "    \n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    \n",
    "    for paper_id in df.index:\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        input_sentences = []\n",
    "\n",
    "        # split input into sentences\n",
    "        input_sentences_tok = df.model_input[paper_id].replace(\"et al.\", \"et al\").replace(\"e.g.\", \"eg\").replace(\"eg.\", \"eg\").replace(\"i.e.\", \"ie\").replace(\"ie.\", \"ie\")\n",
    "        input_sentences_tok = input_sentences_tok.replace(\".1\", \". \").replace(\".2\", \". \").replace(\".3\", \".\").replace(\".4\", \". \").replace(\".5\", \". \").replace(\".6\", \". \").replace(\".7\", \". \").replace(\".8\", \". \").replace(\".9\", \". \")\n",
    "\n",
    "        # tokenize input sentences\n",
    "        input_sentences_tok = tokenizer.tokenize(input_sentences_tok)\n",
    "\n",
    "        # truncate too large input sentences (larger than 512 throws an error - rare cases) and remove \"?\"\n",
    "        input_sentences_tok = [s.replace(\"?\", \"\") for s in input_sentences_tok if len(s) <= 512]\n",
    "        \n",
    "        \n",
    "        # truncate the center of the body for large bodies\n",
    "        if len(input_sentences_tok) > truncate_center:\n",
    "            input_sentences_tok = input_sentences_tok[:int(truncate_center/2)] + input_sentences_tok[-int(truncate_center/2):]\n",
    "\n",
    "        # find input sentences with quality\n",
    "        for i in range(len(input_sentences_tok)):\n",
    "            if len(input_sentences_tok[i])>0:\n",
    "                if checkQuality(input_sentences_tok[i]):\n",
    "                    input_sentences.append(input_sentences_tok[i])\n",
    "\n",
    "        # fill our large/original dataframe with the cleaned input sentences \n",
    "        df.model_input[paper_id] = \" \".join(input_sentences)\n",
    "        \n",
    "        # keep track of time to run \n",
    "        if paper_id % 50 == 0:\n",
    "#             print(paper_id, \"secs to run:\", time.time() - start)\n",
    "            start = time.time()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>body</th>\n",
       "      <th>citations</th>\n",
       "      <th>golden</th>\n",
       "      <th>cited_text_spans</th>\n",
       "      <th>model_input</th>\n",
       "      <th>model_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We present a method for extracting parts of ob...</td>\n",
       "      <td>We present a method of extracting parts of obj...</td>\n",
       "      <td>[Berland and Charniak (1999) use Hearst style ...</td>\n",
       "      <td>Finding Parts In Very Large Corpora\\nWe presen...</td>\n",
       "      <td>[We present a method of extracting parts of ob...</td>\n",
       "      <td>We present a method for extracting parts of ob...</td>\n",
       "      <td>Finding Parts In Very Large Corpora\\nWe presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We describe a series of five statistical model...</td>\n",
       "      <td>We describe a series of five statistical model...</td>\n",
       "      <td>[The program takes the output of char_align (C...</td>\n",
       "      <td>The Mathematics Of Statistical Machine Transla...</td>\n",
       "      <td>[Like Brown et al, they consider only the simu...</td>\n",
       "      <td>We describe a series of five statistical model...</td>\n",
       "      <td>The Mathematics Of Statistical Machine Transla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Previous work has shown that Chinese word segm...</td>\n",
       "      <td>Word segmentation is considered an important f...</td>\n",
       "      <td>[Chinese word segmentation is done by the Stan...</td>\n",
       "      <td>Optimizing Chinese Word Segmentation for Machi...</td>\n",
       "      <td>[In order to contrast with the simple maximum ...</td>\n",
       "      <td>Previous work has shown that Chinese word segm...</td>\n",
       "      <td>Optimizing Chinese Word Segmentation for Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We examine the viability of building large pol...</td>\n",
       "      <td>Polarity lexicons are large lists of phrases t...</td>\n",
       "      <td>[Recent work in this area includes Velikovich ...</td>\n",
       "      <td>The viability of web-derived polarity lexicons...</td>\n",
       "      <td>[Thus, even though the web-derived lexicon is ...</td>\n",
       "      <td>We examine the viability of building large pol...</td>\n",
       "      <td>The viability of web-derived polarity lexicons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extracting semantic relationships between enti...</td>\n",
       "      <td>Extraction of semantic relationships between e...</td>\n",
       "      <td>[They use two kinds of features: syntactic one...</td>\n",
       "      <td>Combining Lexical Syntactic And Semantic Featu...</td>\n",
       "      <td>[We build Maximum Entropy models for extractin...</td>\n",
       "      <td>Extracting semantic relationships between enti...</td>\n",
       "      <td>Combining Lexical Syntactic And Semantic Featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>In statistical machine translation, correspond...</td>\n",
       "      <td>In statistical machine translation, correspond...</td>\n",
       "      <td>[In addition, Niessen and Ney (2004) decompose...</td>\n",
       "      <td>Statistical Machine Translation With Scarce Re...</td>\n",
       "      <td>[In statistical machine translation, correspon...</td>\n",
       "      <td>In statistical machine translation, correspond...</td>\n",
       "      <td>Statistical Machine Translation With Scarce Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>We have developed a new program called alignin...</td>\n",
       "      <td>Aligning parallel texts has recently received ...</td>\n",
       "      <td>[There have been quite a number of recent pape...</td>\n",
       "      <td>Robust Bilingual Word Alignment For Machine Ai...</td>\n",
       "      <td>[Brown et al estimate t(fle) on the basis of a...</td>\n",
       "      <td>We have developed a new program called alignin...</td>\n",
       "      <td>Robust Bilingual Word Alignment For Machine Ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>We present an approach to pronoun resolution b...</td>\n",
       "      <td>Pronoun resolution is a difficult but vital pa...</td>\n",
       "      <td>[, We follow the closed track setting where sy...</td>\n",
       "      <td>Bootstrapping Path-Based Pronoun Resolution\\nW...</td>\n",
       "      <td>[The noun-pronoun path coreference can be used...</td>\n",
       "      <td>We present an approach to pronoun resolution b...</td>\n",
       "      <td>Bootstrapping Path-Based Pronoun Resolution\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>We use logical inference techniques for recogn...</td>\n",
       "      <td>Recognising textual entailment (RTE) is the ta...</td>\n",
       "      <td>[However, this method does not work for realwo...</td>\n",
       "      <td>Recognising Textual Entailment With Logical In...</td>\n",
       "      <td>[Another attractive property of a model builde...</td>\n",
       "      <td>We use logical inference techniques for recogn...</td>\n",
       "      <td>Recognising Textual Entailment With Logical In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>This paper deals with two important ambiguitie...</td>\n",
       "      <td>The problem with successful resolution of ambi...</td>\n",
       "      <td>[The state of the art is a supervised algorith...</td>\n",
       "      <td>Corpus Based PP Attachment Ambiguity Resolutio...</td>\n",
       "      <td>[The current statistical state-of-the art meth...</td>\n",
       "      <td>This paper deals with two important ambiguitie...</td>\n",
       "      <td>Corpus Based PP Attachment Ambiguity Resolutio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               abstract  \\\n",
       "0     We present a method for extracting parts of ob...   \n",
       "1     We describe a series of five statistical model...   \n",
       "2     Previous work has shown that Chinese word segm...   \n",
       "3     We examine the viability of building large pol...   \n",
       "4     Extracting semantic relationships between enti...   \n",
       "...                                                 ...   \n",
       "1004  In statistical machine translation, correspond...   \n",
       "1005  We have developed a new program called alignin...   \n",
       "1006  We present an approach to pronoun resolution b...   \n",
       "1007  We use logical inference techniques for recogn...   \n",
       "1008  This paper deals with two important ambiguitie...   \n",
       "\n",
       "                                                   body  \\\n",
       "0     We present a method of extracting parts of obj...   \n",
       "1     We describe a series of five statistical model...   \n",
       "2     Word segmentation is considered an important f...   \n",
       "3     Polarity lexicons are large lists of phrases t...   \n",
       "4     Extraction of semantic relationships between e...   \n",
       "...                                                 ...   \n",
       "1004  In statistical machine translation, correspond...   \n",
       "1005  Aligning parallel texts has recently received ...   \n",
       "1006  Pronoun resolution is a difficult but vital pa...   \n",
       "1007  Recognising textual entailment (RTE) is the ta...   \n",
       "1008  The problem with successful resolution of ambi...   \n",
       "\n",
       "                                              citations  \\\n",
       "0     [Berland and Charniak (1999) use Hearst style ...   \n",
       "1     [The program takes the output of char_align (C...   \n",
       "2     [Chinese word segmentation is done by the Stan...   \n",
       "3     [Recent work in this area includes Velikovich ...   \n",
       "4     [They use two kinds of features: syntactic one...   \n",
       "...                                                 ...   \n",
       "1004  [In addition, Niessen and Ney (2004) decompose...   \n",
       "1005  [There have been quite a number of recent pape...   \n",
       "1006  [, We follow the closed track setting where sy...   \n",
       "1007  [However, this method does not work for realwo...   \n",
       "1008  [The state of the art is a supervised algorith...   \n",
       "\n",
       "                                                 golden  \\\n",
       "0     Finding Parts In Very Large Corpora\\nWe presen...   \n",
       "1     The Mathematics Of Statistical Machine Transla...   \n",
       "2     Optimizing Chinese Word Segmentation for Machi...   \n",
       "3     The viability of web-derived polarity lexicons...   \n",
       "4     Combining Lexical Syntactic And Semantic Featu...   \n",
       "...                                                 ...   \n",
       "1004  Statistical Machine Translation With Scarce Re...   \n",
       "1005  Robust Bilingual Word Alignment For Machine Ai...   \n",
       "1006  Bootstrapping Path-Based Pronoun Resolution\\nW...   \n",
       "1007  Recognising Textual Entailment With Logical In...   \n",
       "1008  Corpus Based PP Attachment Ambiguity Resolutio...   \n",
       "\n",
       "                                       cited_text_spans  \\\n",
       "0     [We present a method of extracting parts of ob...   \n",
       "1     [Like Brown et al, they consider only the simu...   \n",
       "2     [In order to contrast with the simple maximum ...   \n",
       "3     [Thus, even though the web-derived lexicon is ...   \n",
       "4     [We build Maximum Entropy models for extractin...   \n",
       "...                                                 ...   \n",
       "1004  [In statistical machine translation, correspon...   \n",
       "1005  [Brown et al estimate t(fle) on the basis of a...   \n",
       "1006  [The noun-pronoun path coreference can be used...   \n",
       "1007  [Another attractive property of a model builde...   \n",
       "1008  [The current statistical state-of-the art meth...   \n",
       "\n",
       "                                            model_input  \\\n",
       "0     We present a method for extracting parts of ob...   \n",
       "1     We describe a series of five statistical model...   \n",
       "2     Previous work has shown that Chinese word segm...   \n",
       "3     We examine the viability of building large pol...   \n",
       "4     Extracting semantic relationships between enti...   \n",
       "...                                                 ...   \n",
       "1004  In statistical machine translation, correspond...   \n",
       "1005  We have developed a new program called alignin...   \n",
       "1006  We present an approach to pronoun resolution b...   \n",
       "1007  We use logical inference techniques for recogn...   \n",
       "1008  This paper deals with two important ambiguitie...   \n",
       "\n",
       "                                           model_output  \n",
       "0     Finding Parts In Very Large Corpora\\nWe presen...  \n",
       "1     The Mathematics Of Statistical Machine Transla...  \n",
       "2     Optimizing Chinese Word Segmentation for Machi...  \n",
       "3     The viability of web-derived polarity lexicons...  \n",
       "4     Combining Lexical Syntactic And Semantic Featu...  \n",
       "...                                                 ...  \n",
       "1004  Statistical Machine Translation With Scarce Re...  \n",
       "1005  Robust Bilingual Word Alignment For Machine Ai...  \n",
       "1006  Bootstrapping Path-Based Pronoun Resolution\\nW...  \n",
       "1007  Recognising Textual Entailment With Logical In...  \n",
       "1008  Corpus Based PP Attachment Ambiguity Resolutio...  \n",
       "\n",
       "[1009 rows x 7 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cleanInput(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1 - Divide the data into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "\n",
    "train_pct = 0.9\n",
    "test_pct = 0.05\n",
    "\n",
    "data = data.sample(len(data), random_state=20)\n",
    "train_sub = int(len(data) * train_pct)\n",
    "test_sub = int(len(data) * test_pct) + train_sub\n",
    "\n",
    "train_df = data[0:train_sub]\n",
    "test_df = data[train_sub:test_sub]\n",
    "val_df = data[test_sub:]\n",
    "\n",
    "train_input = list(train_df['model_input'])\n",
    "test_input = list(test_df['model_input'])\n",
    "val_input = list(val_df['model_input'])\n",
    "\n",
    "train_output = list(train_df['model_output'])\n",
    "test_output = list(test_df['model_output'])\n",
    "val_output = list(val_df['model_output'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Summarize with Pegasus pre-trained (no fine-tuning)\n",
    "    \n",
    "In this step we will do the following:\n",
    " \n",
    "Step 3.1 - Instantiate the model\\\n",
    "Step 3.2 - Instatiate the metric of interest \\\n",
    "Step 3.3 - Compute the summaries and evaluate\\\n",
    "Step 3.4 - Check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 - Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-arxiv')\n",
    "# The PEGASUS Model with a language modeling head. Can be used for summarization. \n",
    "# This model inherits from PreTrainedModel. \n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-arxiv')\n",
    "\n",
    "# OTHER OPTIONS BELOW"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTHER OPTIONS: Possible pre-trained models\n",
    "![image.png](attachment:image.png)\n",
    "Source: https://pub.towardsai.net/summarization-using-pegasus-model-with-the-transformers-library-553cd0dc5c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 - Instatiate the metric of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate rouge score\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 - Compute the summaries and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 44.34317111968994\n",
      "5 239.66406273841858\n",
      "10 2360.4596979618073\n",
      "15 1247.7168469429016\n",
      "20 1448.5269758701324\n",
      "25 1564.9284858703613\n",
      "30 1561.796327829361\n",
      "35 1390.7896890640259\n",
      "40 1363.4726889133453\n",
      "45 1314.8136219978333\n",
      "50 1587.2738020420074\n"
     ]
    }
   ],
   "source": [
    "#INFERENCE\n",
    "\n",
    "## Sample with no fine-tunning \n",
    "\n",
    "import time\n",
    "\n",
    "# create empry lists to store rouge scores\n",
    "r1_precision = []\n",
    "r2_precision = []\n",
    "rL_precision = []\n",
    "\n",
    "r1_recall = []\n",
    "r2_recall = []\n",
    "rL_recall = []\n",
    "\n",
    "r1_fmeasure = []\n",
    "r2_fmeasure = []\n",
    "rL_fmeasure = []\n",
    "\n",
    "# start counting seconds to keep track of time \n",
    "start = time.time()\n",
    "\n",
    "# loop over validation set\n",
    "for sample_id in range(len(val_abs)):\n",
    "    \n",
    "    # get input (body OR abstract + cited text spans) - scisummnet uses abstract, we want to use body\n",
    "    sample_input = val_input[sample_id]\n",
    "    \n",
    "    # tokenize it\n",
    "    inputs = tokenizer([sample_input], max_length=1024, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    # 'max_length': Pad to a maximum length specified with the argument max_length \n",
    "    # or to the maximum acceptable input length for the model if that argument is not provided.\n",
    "\n",
    "    # generate Summary\n",
    "    summary_ids = model.generate(inputs['input_ids'])\n",
    "    \n",
    "    # decode summary\n",
    "    sample_output = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    \n",
    "    # get reference (gold) summary \n",
    "    sample_reference = val_output[sample_id]\n",
    "    \n",
    "    #calculate rouge score\n",
    "    scores = scorer.score(str(sample_reference), str(sample_output))\n",
    "    \n",
    "    r1_precision.append(scores['rouge1'][0])\n",
    "    r1_recall.append(scores['rouge1'][1])\n",
    "    r1_fmeasure.append(scores['rouge1'][2])\n",
    "    \n",
    "    r2_precision.append(scores['rouge2'][0])\n",
    "    r2_recall.append(scores['rouge2'][1])\n",
    "    r2_fmeasure.append(scores['rouge2'][2])\n",
    "    \n",
    "    rL_precision.append(scores['rougeL'][0])\n",
    "    rL_recall.append(scores['rougeL'][1])\n",
    "    rL_fmeasure.append(scores['rougeL'][2])\n",
    "    \n",
    "    if sample_id % 5 == 0:\n",
    "        print(sample_id, time.time() - start)\n",
    "        start = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_id = 1\n",
    "# sample_input = val_body[sample_id].replace(\"\\n\", \" \") + \" \".join(val_cts[sample_id])\n",
    "# inputs = tokenizer([sample_input], max_length=10000, return_tensors='pt', truncation=True, padding=True)\n",
    "# print(inputs)\n",
    "# print(len(inputs['input_ids'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 R1        R2        RL\n",
      "precision  0.519368  0.287738  0.409259\n",
      "recall     0.373165  0.197254  0.289334\n",
      "fmeasure   0.398449  0.213798  0.309245\n"
     ]
    }
   ],
   "source": [
    "# compute score statistics\n",
    "\n",
    "all_socores = {'R1': [stats.mean(r1_precision), stats.mean(r1_recall), stats.mean(r1_fmeasure)],\n",
    "        'R2': [stats.mean(r2_precision), stats.mean(r2_recall), stats.mean(r2_fmeasure)],\n",
    "        'RL': [stats.mean(rL_precision), stats.mean(rL_recall), stats.mean(rL_fmeasure)]      \n",
    "        }\n",
    "\n",
    "all_socores_df = pd.DataFrame(all_socores, columns = ['R1', 'R2', 'RL'], index=['precision','recall','fmeasure'])\n",
    "\n",
    "print(all_socores_df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Fine-Tune Pegasus pre-trained\n",
    "\n",
    "In this step we will do the following:\n",
    " \n",
    "Step 4.1 - Instantiate the model (the same as in step 3, so I'll skip it) \\\n",
    "Step 4.2 - Define metrics of interest \\\n",
    "Step 4.3 - Tokenize text data and wrap it into a torch Dataset \\\n",
    "Step 4.4 - Train and evaluate the model \\\n",
    "Step 4.5 - Save the model \\\n",
    "Step 4.6 - Instantiate the fine-tuned model \\\n",
    "Step 4.7 - Compute the summaries and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 - Instantiate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 - Define metrics of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric\n",
    "from datasets import load_dataset, load_metric\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Ignore pad token for loss: Replace -100 in the labels as we can't decode them.\n",
    "    #     if data_args.ignore_pad_token_for_loss:\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results from ROUGE\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3 - Tokenize text data and wrap it into a torch Dataset\n",
    "\n",
    "Since we gonna use Trainer from Transformers library, it expects our dataset as a torch.utils.data.Dataset, so we made a simple class that implements __len__() method that returns number of samples, and __getitem__() method to return a data sample at a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize \n",
    "\n",
    "train_encodings = tokenizer(train_input, max_length=1024, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_input, max_length=1024, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_input, max_length=1024, truncation=True, padding=True)\n",
    "\n",
    "train_decodings = tokenizer(train_output, max_length=1024, truncation=True, padding=True)\n",
    "val_decodings = tokenizer(val_output, max_length=1024, truncation=True, padding=True)\n",
    "test_decodings = tokenizer(test_output, max_length=1024, truncation=True, padding=True)\n",
    "\n",
    "# wrap it into a torch Dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "class ourDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, decodings):\n",
    "        self.encodings = encodings\n",
    "        self.decodings = decodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.decodings['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "#         print(item)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "train_dataset = ourDataset(train_encodings, train_decodings)\n",
    "val_dataset = ourDataset(val_encodings, val_decodings)\n",
    "test_dataset = ourDataset(test_encodings, test_decodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4 - Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 1:41:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-4c149ed3e4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# define Training Arguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,   # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    logging_steps=20 ,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    predict_with_generate = True     # whether to use generate to calculate generative metrics (ROUGE, BLEU). \n",
    "\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,                     # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    tokenizer = tokenizer,           # the instantiated ðŸ¤— Transformers tokenizer to be trained  \n",
    "    args=training_args,              # training arguments, defined above\n",
    "    train_dataset=train_dataset,     # training dataset\n",
    "    eval_dataset=val_dataset,        # evaluation dataset\n",
    "    compute_metrics=compute_metrics  # pass metric function\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.5 - Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fine_tuned')\n",
    "tokenizer.save_pretrained('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.6 - Instantiate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the new model\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained('fine_tuned')\n",
    "# The PEGASUS Model with a language modeling head. Can be used for summarization. \n",
    "# This model inherits from PreTrainedModel. \n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.7 - Compute the summaries and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERENCE\n",
    "\n",
    "## With fine-tunning \n",
    "\n",
    "# create empry lists to store rouge scores\n",
    "r1_precision = []\n",
    "r2_precision = []\n",
    "rL_precision = []\n",
    "\n",
    "r1_recall = []\n",
    "r2_recall = []\n",
    "rL_recall = []\n",
    "\n",
    "r1_fmeasure = []\n",
    "r2_fmeasure = []\n",
    "rL_fmeasure = []\n",
    "\n",
    "# start counting seconds to keep track of time \n",
    "start = time.time()\n",
    "\n",
    "# loop over validation set\n",
    "for sample_id in range(len(val_abs)):\n",
    "    \n",
    "    # get input (body OR abstract + cited text spans) - scisummnet uses abstract, we want to use body\n",
    "    sample_input = val_input[sample_id]\n",
    "    \n",
    "    # tokenize it\n",
    "    inputs = tokenizer([sample_input], max_length=1024, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    # 'max_length': Pad to a maximum length specified with the argument max_length \n",
    "    # or to the maximum acceptable input length for the model if that argument is not provided.\n",
    "\n",
    "    # generate Summary\n",
    "    summary_ids = model.generate(inputs['input_ids'])\n",
    "    \n",
    "    # decode summary\n",
    "    sample_output = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    \n",
    "    # get reference (gold) summary \n",
    "    sample_reference = val_output[sample_id]\n",
    "    \n",
    "    #calculate rouge score\n",
    "    scores = scorer.score(str(sample_reference), str(sample_output))\n",
    "    \n",
    "    r1_precision.append(scores['rouge1'][0])\n",
    "    r1_recall.append(scores['rouge1'][1])\n",
    "    r1_fmeasure.append(scores['rouge1'][2])\n",
    "    \n",
    "    r2_precision.append(scores['rouge2'][0])\n",
    "    r2_recall.append(scores['rouge2'][1])\n",
    "    r2_fmeasure.append(scores['rouge2'][2])\n",
    "    \n",
    "    rL_precision.append(scores['rougeL'][0])\n",
    "    rL_recall.append(scores['rougeL'][1])\n",
    "    rL_fmeasure.append(scores['rougeL'][2])\n",
    "    \n",
    "    if sample_id % 5 == 0:\n",
    "        print(sample_id, time.time() - start)\n",
    "        start = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute score statistics\n",
    "\n",
    "all_socores = {'R1': [stats.mean(r1_precision), stats.mean(r1_recall), stats.mean(r1_fmeasure)],\n",
    "        'R2': [stats.mean(r2_precision), stats.mean(r2_recall), stats.mean(r2_fmeasure)],\n",
    "        'RL': [stats.mean(rL_precision), stats.mean(rL_recall), stats.mean(rL_fmeasure)]      \n",
    "        }\n",
    "\n",
    "all_socores_df = pd.DataFrame(all_socores, columns = ['R1', 'R2', 'RL'], index=['precision','recall','fmeasure'])\n",
    "\n",
    "print(all_socores_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
