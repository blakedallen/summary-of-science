{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, PegasusConfig\n",
    "import matplotlib.pyplot as plt\n",
    "from rouge_score import rouge_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals\n",
    "MAX_LENGTH = 1024\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1004</td>\n",
       "      <td>A major obstacle to the construction ofa pro...</td>\n",
       "      <td>Parallel texts have been used in a number of...</td>\n",
       "      <td>A compilation of parallel texts offered in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-1006</td>\n",
       "      <td>This paper proposes a way to improve the tran...</td>\n",
       "      <td>Recently, various dialogue translation syste...</td>\n",
       "      <td>We plan to improve the accuracy obtained so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00-1008</td>\n",
       "      <td>This paper describes an application of APE (t...</td>\n",
       "      <td>The purpose of the Atlas project is to enlarg...</td>\n",
       "      <td>Computer dialogue is now used at production st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00-1009</td>\n",
       "      <td>In this paper we describe an implemented fram...</td>\n",
       "      <td>In this paper we present a linguistically mot...</td>\n",
       "      <td>From this viewpoint, research on paraphrasing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00-1011</td>\n",
       "      <td>This paper reports on a large-scale, end-toen...</td>\n",
       "      <td>One major goal of information extraction (IE)...</td>\n",
       "      <td>For example, Aone and Ramos-Santacruz (2000) p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>W99-0904</td>\n",
       "      <td>We present in this paper an unsupervised meth...</td>\n",
       "      <td>Development of electronic morphological resou...</td>\n",
       "      <td>Next along the spectrum of orthographic simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>W99-0905</td>\n",
       "      <td>This paper presents an unsupervised method fo...</td>\n",
       "      <td>Choosing the correct translation of a content...</td>\n",
       "      <td>For comparable corpora, previous bilingual sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>W99-0909</td>\n",
       "      <td>In this paper we report on an unsupervised a...</td>\n",
       "      <td>In this paper we discuss a potential solutio...</td>\n",
       "      <td>Watkinson and Manandhar (1999) present an unsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>X93-1018</td>\n",
       "      <td>This paper presents results from a study comp...</td>\n",
       "      <td>In evaluating the state of technology for ext...</td>\n",
       "      <td>It may be noted that \"correctly\" is a problema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>X96-1031</td>\n",
       "      <td>Over the past few years, HNC has developed a ...</td>\n",
       "      <td>While the current MatchPlus learning law has ...</td>\n",
       "      <td>As such a matrix reduction, we utilized a lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4273 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id                                           abstract  \\\n",
       "0     A00-1004    A major obstacle to the construction ofa pro...   \n",
       "1     A00-1006   This paper proposes a way to improve the tran...   \n",
       "2     A00-1008   This paper describes an application of APE (t...   \n",
       "3     A00-1009   In this paper we describe an implemented fram...   \n",
       "4     A00-1011   This paper reports on a large-scale, end-toen...   \n",
       "...        ...                                                ...   \n",
       "4268  W99-0904   We present in this paper an unsupervised meth...   \n",
       "4269  W99-0905   This paper presents an unsupervised method fo...   \n",
       "4270  W99-0909    In this paper we report on an unsupervised a...   \n",
       "4271  X93-1018   This paper presents results from a study comp...   \n",
       "4272  X96-1031   Over the past few years, HNC has developed a ...   \n",
       "\n",
       "                                                   body  \\\n",
       "0       Parallel texts have been used in a number of...   \n",
       "1       Recently, various dialogue translation syste...   \n",
       "2      The purpose of the Atlas project is to enlarg...   \n",
       "3      In this paper we present a linguistically mot...   \n",
       "4      One major goal of information extraction (IE)...   \n",
       "...                                                 ...   \n",
       "4268   Development of electronic morphological resou...   \n",
       "4269   Choosing the correct translation of a content...   \n",
       "4270    In this paper we discuss a potential solutio...   \n",
       "4271   In evaluating the state of technology for ext...   \n",
       "4272   While the current MatchPlus learning law has ...   \n",
       "\n",
       "                                              citations  \n",
       "0     A compilation of parallel texts offered in a s...  \n",
       "1     We plan to improve the accuracy obtained so fa...  \n",
       "2     Computer dialogue is now used at production st...  \n",
       "3     From this viewpoint, research on paraphrasing ...  \n",
       "4     For example, Aone and Ramos-Santacruz (2000) p...  \n",
       "...                                                 ...  \n",
       "4268  Next along the spectrum of orthographic simila...  \n",
       "4269  For comparable corpora, previous bilingual sen...  \n",
       "4270  Watkinson and Manandhar (1999) present an unsu...  \n",
       "4271  It may be noted that \"correctly\" is a problema...  \n",
       "4272  As such a matrix reduction, we utilized a lear...  \n",
       "\n",
       "[4273 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define data directory\n",
    "import os\n",
    "DATA_DIR = \"./data/aan_data\"\n",
    "\n",
    "#load our 10k data into a dataframe\n",
    "papers = []\n",
    "filenames = [] #keep a reference for later transformations\n",
    "\n",
    "abstracts2, bodys2, cits2, files2 = [],[],[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    for f in files:\n",
    "        fn = root+\"/\"+f\n",
    "        if \"abstract\" in fn:            \n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "\n",
    "            new_list = [''.join(file[i*4:(i+1)*4]) for i in range(int(len(file)/4))]\n",
    "            list_no_n = [item.replace('\\n','').replace('- ','').replace(\"\\'\", \"\") for item in new_list]\n",
    "\n",
    "            string = ''\n",
    "            for item in list_no_n:\n",
    "                string = string + item            \n",
    "            abstracts2.append(string)\n",
    "            files2.append(f.split('_')[1].split('.')[0])\n",
    "            \n",
    "        elif \"body\" in fn:\n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "\n",
    "            new_list = [''.join(file[i*4:(i+1)*4]) for i in range(int(len(file)/4))]\n",
    "            \n",
    "            list_no_n = [item.replace('\\n','').replace('- ','').replace(\"\\'\", \"\") for item in new_list]\n",
    "            #list_no_n = [item for item in new_list]\n",
    "            string = ''\n",
    "            for item in list_no_n:\n",
    "                string = string + item            \n",
    "            bodys2.append(string)\n",
    "        \n",
    "        elif \"CS\" in fn:\n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "            string = [''.join(file) for i in file]\n",
    "            if len(string) > 0: \n",
    "                string = [''.join(file) for i in file][0].replace('\\n','').replace('- ','').replace(\"\\'\", \"\")\n",
    "            cits2.append(string)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #    with open(fn) as jsonfile:\n",
    "    #        d = json.load(jsonfile)\n",
    "    #    papers.append(d)\n",
    "    #    filenames.append(f)\n",
    "\n",
    "    \n",
    "    \n",
    "df2 = pd.DataFrame({'paper_id':files2,'abstract':abstracts2,'body':bodys2,'citations':cits2})\n",
    "df2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body</th>\n",
       "      <th>citations</th>\n",
       "      <th>cited text spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00-1004</td>\n",
       "      <td>A major obstacle to the construction ofa pro...</td>\n",
       "      <td>Parallel texts have been used in a number of...</td>\n",
       "      <td>A compilation of parallel texts offered in a s...</td>\n",
       "      <td>Parallel texts have been used in a number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00-1006</td>\n",
       "      <td>This paper proposes a way to improve the tran...</td>\n",
       "      <td>Recently, various dialogue translation syste...</td>\n",
       "      <td>We plan to improve the accuracy obtained so fa...</td>\n",
       "      <td>If we want to make a conversation proceed smoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00-1008</td>\n",
       "      <td>This paper describes an application of APE (t...</td>\n",
       "      <td>The purpose of the Atlas project is to enlarg...</td>\n",
       "      <td>Computer dialogue is now used at production st...</td>\n",
       "      <td>The purpose of the Atlas project is to enlarg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00-1009</td>\n",
       "      <td>In this paper we describe an implemented fram...</td>\n",
       "      <td>In this paper we present a linguistically mot...</td>\n",
       "      <td>From this viewpoint, research on paraphrasing ...</td>\n",
       "      <td>In this paper we present a linguistically mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00-1011</td>\n",
       "      <td>This paper reports on a large-scale, end-toen...</td>\n",
       "      <td>One major goal of information extraction (IE)...</td>\n",
       "      <td>For example, Aone and Ramos-Santacruz (2000) p...</td>\n",
       "      <td>One major goal of information extraction (IE)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>W99-0904</td>\n",
       "      <td>We present in this paper an unsupervised meth...</td>\n",
       "      <td>Development of electronic morphological resou...</td>\n",
       "      <td>Next along the spectrum of orthographic simila...</td>\n",
       "      <td>Development of electronic morphological resou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>W99-0905</td>\n",
       "      <td>This paper presents an unsupervised method fo...</td>\n",
       "      <td>Choosing the correct translation of a content...</td>\n",
       "      <td>For comparable corpora, previous bilingual sen...</td>\n",
       "      <td>Choosing the correct translation of a content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>W99-0909</td>\n",
       "      <td>In this paper we report on an unsupervised a...</td>\n",
       "      <td>In this paper we discuss a potential solutio...</td>\n",
       "      <td>Watkinson and Manandhar (1999) present an unsu...</td>\n",
       "      <td>In this paper we discuss a potential solutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>X93-1018</td>\n",
       "      <td>This paper presents results from a study comp...</td>\n",
       "      <td>In evaluating the state of technology for ext...</td>\n",
       "      <td>It may be noted that \"correctly\" is a problema...</td>\n",
       "      <td>In evaluating the state of technology for ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>X96-1031</td>\n",
       "      <td>Over the past few years, HNC has developed a ...</td>\n",
       "      <td>While the current MatchPlus learning law has ...</td>\n",
       "      <td>As such a matrix reduction, we utilized a lear...</td>\n",
       "      <td>While the current MatchPlus learning law has ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4208 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id                                           abstract  \\\n",
       "0     A00-1004    A major obstacle to the construction ofa pro...   \n",
       "1     A00-1006   This paper proposes a way to improve the tran...   \n",
       "2     A00-1008   This paper describes an application of APE (t...   \n",
       "3     A00-1009   In this paper we describe an implemented fram...   \n",
       "4     A00-1011   This paper reports on a large-scale, end-toen...   \n",
       "...        ...                                                ...   \n",
       "4203  W99-0904   We present in this paper an unsupervised meth...   \n",
       "4204  W99-0905   This paper presents an unsupervised method fo...   \n",
       "4205  W99-0909    In this paper we report on an unsupervised a...   \n",
       "4206  X93-1018   This paper presents results from a study comp...   \n",
       "4207  X96-1031   Over the past few years, HNC has developed a ...   \n",
       "\n",
       "                                                   body  \\\n",
       "0       Parallel texts have been used in a number of...   \n",
       "1       Recently, various dialogue translation syste...   \n",
       "2      The purpose of the Atlas project is to enlarg...   \n",
       "3      In this paper we present a linguistically mot...   \n",
       "4      One major goal of information extraction (IE)...   \n",
       "...                                                 ...   \n",
       "4203   Development of electronic morphological resou...   \n",
       "4204   Choosing the correct translation of a content...   \n",
       "4205    In this paper we discuss a potential solutio...   \n",
       "4206   In evaluating the state of technology for ext...   \n",
       "4207   While the current MatchPlus learning law has ...   \n",
       "\n",
       "                                              citations  \\\n",
       "0     A compilation of parallel texts offered in a s...   \n",
       "1     We plan to improve the accuracy obtained so fa...   \n",
       "2     Computer dialogue is now used at production st...   \n",
       "3     From this viewpoint, research on paraphrasing ...   \n",
       "4     For example, Aone and Ramos-Santacruz (2000) p...   \n",
       "...                                                 ...   \n",
       "4203  Next along the spectrum of orthographic simila...   \n",
       "4204  For comparable corpora, previous bilingual sen...   \n",
       "4205  Watkinson and Manandhar (1999) present an unsu...   \n",
       "4206  It may be noted that \"correctly\" is a problema...   \n",
       "4207  As such a matrix reduction, we utilized a lear...   \n",
       "\n",
       "                                       cited text spans  \n",
       "0       Parallel texts have been used in a number of...  \n",
       "1     If we want to make a conversation proceed smoo...  \n",
       "2      The purpose of the Atlas project is to enlarg...  \n",
       "3      In this paper we present a linguistically mot...  \n",
       "4      One major goal of information extraction (IE)...  \n",
       "...                                                 ...  \n",
       "4203   Development of electronic morphological resou...  \n",
       "4204   Choosing the correct translation of a content...  \n",
       "4205    In this paper we discuss a potential solutio...  \n",
       "4206   In evaluating the state of technology for ext...  \n",
       "4207   While the current MatchPlus learning law has ...  \n",
       "\n",
       "[4208 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = open(\"cited_spans_full1.txt\",\"r+\") \n",
    "  \n",
    "text = file1.read()\n",
    "text = text.split('\\n')\n",
    "\n",
    "paper_ids, cts = [], []\n",
    "for i in text:\n",
    "    if i != '':\n",
    "        p = i.split('@@')\n",
    "        paper_ids.append(p[0])\n",
    "        cts.append(p[1])\n",
    "\n",
    "dfcts = pd.DataFrame({'paper_id':paper_ids,\n",
    "             'cited text spans':cts})\n",
    "\n",
    "df = df2.merge(dfcts, on='paper_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset and tokenizer building\n",
    "#load our 10k data into a dataframe\n",
    "#limit = 10\n",
    "#papers = []\n",
    "#for root, dirs, files in os.walk(\"./data/mini_10k\"):\n",
    "#    for f in files:\n",
    "#        fn = root+\"/\"+f\n",
    "#        with open(fn) as jsonfile:\n",
    "#            d = json.load(jsonfile)\n",
    "#        papers.append(d)\n",
    "#        \n",
    "#        if len(papers) >= limit:\n",
    "#            break\n",
    "#    if len(papers) >= limit:\n",
    "#        break\n",
    "#df = pd.DataFrame(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our rouge scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our pretrained model\n",
    "model_name = 'google/pegasus-large'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "config = PegasusConfig.from_pretrained(model_name, output_hidden_states=True, output_attentions=True)  \n",
    "pt_model = PegasusForConditionalGeneration.from_pretrained(model_name, config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "#example batch (size 1)\n",
    "batch = tokenizer(df.body[3], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['sequences', 'encoder_attentions', 'encoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'decoder_hidden_states'])\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "#example pretrained generation with keys\n",
    "out = pt_model.generate(return_dict_in_generate=True, **batch)\n",
    "print(out.keys())\n",
    "print(len(out[\"encoder_hidden_states\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "#example batch (size 1)\n",
    "batch2 = tokenizer(df.citations[3], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "print(batch2.keys())\n",
    "out2 = pt_model.generate(return_dict_in_generate=True, **batch2)\n",
    "\n",
    "#example batch (size 1)\n",
    "batch3 = tokenizer(df['cited text spans'][3], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "print(batch3.keys())\n",
    "out3 = pt_model.generate(return_dict_in_generate=True, **batch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionAttention(nn.Module):\n",
    "    def __init__(self,  vocab_size=32000, input_size=1024, target_size=256):\n",
    "        super(AttentionAttention, self).__init__()\n",
    "        \n",
    "        #edit this to manipulate the network:\n",
    "        #attn head1\n",
    "        self.ah1_1 = nn.Linear(input_size, target_size)\n",
    "        self.ah1_2 = nn.Linear(target_size, target_size//2)\n",
    "        self.ah1_3 = nn.Linear(target_size//2, target_size//4)\n",
    "        #self.ah1_4 = nn.Linear(target_size//4, target_size//8)\n",
    "        \n",
    "        #attn head1\n",
    "        self.ah2_1 = nn.Linear(input_size, target_size)\n",
    "        self.ah2_2 = nn.Linear(target_size, target_size//2)\n",
    "        self.ah2_3 = nn.Linear(target_size//2, target_size//4)\n",
    "        \n",
    "        #embedding head\n",
    "        self.ah3_1 = nn.Linear(input_size, target_size)\n",
    "        self.ah3_2 = nn.Linear(target_size, target_size//2)\n",
    "        self.ah3_3 = nn.Linear(target_size//2, target_size//4)\n",
    "        \n",
    "        #compression head \n",
    "        \n",
    "        \n",
    "        #output head\n",
    "        self.fc_out = nn.Linear(target_size//4, vocab_size)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, out, citations, cts):\n",
    "        \n",
    "        #initialize a random tensor as our 'shallow' attn\n",
    "        shallow_attn = torch.rand((1024,1024), requires_grad=True).to(device)\n",
    "        shallow_attn2 = torch.rand((1024,1024), requires_grad=True).to(device)\n",
    "        shallow_attn3 = torch.rand((1024,1024), requires_grad=True).to(device)\n",
    "        \n",
    "        #we're going to focus on the first N^2 attn layers\n",
    "        num_layers = 2\n",
    "        num_attentions = 2\n",
    "        \n",
    "        for i,attn in enumerate(out[\"encoder_attentions\"]):\n",
    "            if i >= num_layers:\n",
    "                break\n",
    "            \n",
    "            for j,block in enumerate(attn[0]):\n",
    "                attn = torch.tensor(block).to(device)\n",
    "                \n",
    "                #add our attention to the noise mask\n",
    "                shallow_attn = shallow_attn.add(attn)\n",
    "                \n",
    "                #edit this to manipulate the attention\n",
    "                #manipulate attention\n",
    "                #shallow_attn = torch.einsum(\"ab,cd->bc\", shallow_attn, attn)\n",
    "                #shallow_attn = torch.einsum(\"ab,cd->ad\", shallow_attn, attn)\n",
    "                \n",
    "                if j >= num_attentions:\n",
    "                    break\n",
    "                    \n",
    "        for i,attn2 in enumerate(citations[\"encoder_attentions\"]):\n",
    "            if i >= num_layers:\n",
    "                break\n",
    "            \n",
    "            for j,block in enumerate(attn[0]):\n",
    "                attn2 = torch.tensor(block).to(device)\n",
    "                \n",
    "                #add our attention to the noise mask\n",
    "                shallow_attn2 = shallow_attn2.add(attn2)\n",
    "                \n",
    "                #edit this to manipulate the attention\n",
    "                #manipulate attention\n",
    "                #shallow_attn = torch.einsum(\"ab,cd->bc\", shallow_attn, attn)\n",
    "                #shallow_attn = torch.einsum(\"ab,cd->ad\", shallow_attn, attn)\n",
    "                \n",
    "                if j >= num_attentions:\n",
    "                    break\n",
    "                    \n",
    "    \n",
    "        for i,attn3 in enumerate(cts[\"encoder_attentions\"]):\n",
    "            if i >= num_layers:\n",
    "                break\n",
    "            \n",
    "            for j,block in enumerate(attn[0]):\n",
    "                attn3 = torch.tensor(block).to(device)\n",
    "                \n",
    "                #add our attention to the noise mask\n",
    "                shallow_attn3 = shallow_attn3.add(attn3)\n",
    "                \n",
    "                #edit this to manipulate the attention\n",
    "                #manipulate attention\n",
    "                #shallow_attn = torch.einsum(\"ab,cd->bc\", shallow_attn, attn)\n",
    "                #shallow_attn = torch.einsum(\"ab,cd->ad\", shallow_attn, attn)\n",
    "                \n",
    "                if j >= num_attentions:\n",
    "                    break\n",
    "                    \n",
    "        \n",
    "        #values,indices = torch.sort(global_attn)\n",
    "        \n",
    "        #learn from shallow_attn\n",
    "        \n",
    "        x1 = F.relu(self.ah1_1(shallow_attn))\n",
    "        x1 = F.relu(self.ah1_2(x1))\n",
    "        x1 = F.relu(self.ah1_3(x1))\n",
    "        #x1 = F.relu(self.ah1_4(x1))\n",
    "        \n",
    "        x2 = F.relu(self.ah2_1(shallow_attn2))\n",
    "        x2 = F.relu(self.ah2_2(x2))\n",
    "        x2 = F.relu(self.ah2_3(x2))\n",
    "        \n",
    "        #x1 = F.relu(self.ah1_4(x1))\n",
    "        x3 = F.relu(self.ah3_1(shallow_attn3))\n",
    "        x3 = F.relu(self.ah3_2(x3))\n",
    "        x3 = F.relu(self.ah3_3(x3))\n",
    "        #x1 = F.relu(self.ah1_4(x1))\n",
    "        #cited head\n",
    "        \n",
    "        #learn from raw attn\n",
    "#         raw_attn = out[\"encoder_attentions\"][-1][0][-1]\n",
    "#         x2 = F.relu(self.ah2_1(raw_attn))\n",
    "#         x2 = F.relu(self.ah2_2(x2))\n",
    "#         x2 = F.relu(self.ah2_3(x2))\n",
    "        \n",
    "#         #learn from embeds\n",
    "#         last_embed = out[\"encoder_hidden_states\"][-1][0]\n",
    "#         x3 = F.relu(self.eh1_1(last_embed))\n",
    "#         x3 = F.relu(self.eh1_2(x3))\n",
    "#         x3 = F.relu(self.eh1_3(x3))\n",
    "                \n",
    "#         #concatenate all heads\n",
    "#         #print(x1.shape, x2.shape, x3.shape)\n",
    "        x_concat = torch.cat((x1,x2,x3), 1)\n",
    "    \n",
    "        \n",
    "        #print(x_concat.shape)\n",
    "\n",
    "        #x_input = h1+h2\n",
    "        #print(x_input.shape)\n",
    "        x = F.relu(self.fc_out(x1))\n",
    "        \n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = AttentionAttention(vocab_size=tokenizer.vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-b323f6be871a>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn = torch.tensor(block).to(device)\n",
      "<ipython-input-33-b323f6be871a>:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn2 = torch.tensor(block).to(device)\n",
      "<ipython-input-33-b323f6be871a>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn3 = torch.tensor(block).to(device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 96103])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3 = aa.forward(out, out2, out3)\n",
    "o3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary2tensor(summary, batch_size=1, vocab_size=32000):\n",
    "    z = torch.zeros(batch_size,vocab_size).to(device)\n",
    "    for i,wid in enumerate(summary):   \n",
    "        z[i][wid] = 1.0 \n",
    "    return z\n",
    "\n",
    "\n",
    "def pred2tensor(pred):\n",
    "    ids = []\n",
    "    for r in pred:\n",
    "        idx = torch.argmax(r)\n",
    "        ids.append(idx)\n",
    "    return torch.tensor(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for param in aa.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(aa.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "ntokens = tokenizer.vocab_size\n",
    "\n",
    "for i in range(len(papers)):\n",
    "    \n",
    "    batch = tokenizer(df.fulltext[i], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    out = pt_model.generate(return_dict_in_generate=True, **batch)\n",
    "    \n",
    "    cts_batch = tokenizer(df.cts[i], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    citations_batch = tokenizer(df.citations[i], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        pred = aa.forward(out,  cts_batch['input_ids'][0], citations_batch['input_ids'][0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    y = tokenizer(df.summary[i], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    y = y[\"input_ids\"]\n",
    "    y = summary2tensor(y, batch_size=1024, vocab_size=tokenizer.vocab_size)\n",
    "    #print(pred.shape, y.shape)\n",
    "    #print(pred)\n",
    "    loss = loss_fn(pred, y)\n",
    "    print(\"{} {}\".format(i, loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgt_text = tokenizer.batch_decode(ids, skip_special_tokens=True)\n",
    "#print(\" \".join(tgt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save state\n",
    "torch.save(aa.state_dict(), \"data/aa_derek_model.state\")\n",
    "\n",
    "#save params\n",
    "torch.save(aa, \"data/aa_derek_model.param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(pred):\n",
    "    ids = []\n",
    "    for x in pred:\n",
    "        pred_id = torch.argmax(x)\n",
    "        ids.append(pred_id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-b323f6be871a>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn = torch.tensor(block).to(device)\n",
      "<ipython-input-33-b323f6be871a>:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn2 = torch.tensor(block).to(device)\n",
      "<ipython-input-33-b323f6be871a>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn3 = torch.tensor(block).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffolk Suffolk $30.00 sold Suffolk Suffolk sai upbeat sold Suffolk Suffolk aisles Suffolk SEN Suffolk Suffolk Suffolk sold Suffolk Darn sold Suffolk sold sold upbeat Suffolk Suffolk sold trifle sold sold sold sold sold sold Suffolk sai sold Suffolk Suffolk Suffolk Suffolk Suffolk Darn Suffolk sai sold foal foal upbeat sold prorated Suffolk Suffolk sold sai Suffolk Darn Suffolk sold Suffolk trifle Suffolk Suffolk Converse sold upbeat sold Suffolk Suffolk sold Darn sold Darn Mix Darn Suffolk Suffolk Suffolk sold sold Converse Suffolk Suffolk Darn Suffolk sold sold Darn Suffolk Darn aisles sold sold sold Suffolk sold sold sai sold Suffolk sai Darn Suffolk Suffolk Suffolk Suffolk Suffolk constrained foal sold Suffolk Darn Suffolk Suffolk Suffolk Darn sold sold upbeat sold brooke Suffolk Suffolk SEN Suffolk foal sold sold upbeat sold Suffolk Suffolk Suffolk Suffolk Suffolk Suffolk Suffolk upbeat sold Suffolk sold foal Suffolk Suffolk Suffolk sold Suffolk Suffolk Suffolk sold Suffolk Darn Zimbabwean Suffolk Suffolk upbeat sold Darn sold sold sold trifle Suffolk sold sold Sanford sold Suffolk sold Suffolk sold transcripts Suffolk Suffolk sold sai sold Suffolk Suffolk Converse Suffolk clashes sold sold Suffolk Suffolk Suffolk Darn sold sold Darn Suffolk sold sold clashes Suffolk Darn upbeat foal sold Suffolk Suffolk foal Suffolk upbeat sold Suffolk foal sold $30.00 trifle sold transcripts upbeat sold Suffolk Suffolk Suffolk Suffolk Suffolk foal Suffolk sold $30.00 Suffolk upbeat Suffolk sold foal sold sold Suffolk Suffolk sold Suffolk exclusion Darn foal Suffolk Suffolk sold upbeat Suffolk sold sold foal sold Suffolk sold upbeat Suffolk upbeat Suffolk Darn sold Suffolk Suffolk sold sold Suffolk prorated clashes upbeat sold sold Suffolk Put sold Darn Suffolk Suffolk sold Suffolk Suffolk sold Converse Suffolk sold Suffolk Suffolk Darn Suffolk Darn Suffolk sold Suffolk prorated Darn sai Suffolk upbeat upbeat Suffolk Suffolk sold Suffolk sold Darn Suffolk sold upbeat sold Suffolk foal foal sold sold sold Suffolk Suffolk sold sold Suffolk Suffolk sold Suffolk foal sold sold sold Mix trifle Suffolk Suffolk trifle upbeat trifle Suffolk sold Darn sold Darn Suffolk Darn Suffolk sold Suffolk sold Suffolk sold clashes Suffolk sai Darn sold Suffolk Suffolk foal sold sai Suffolk Suffolk Suffolk Suffolk sold sold upbeat Darn upbeat foal trifle sold Suffolk Suffolk sold foal Darn Suffolk foal sold sold trifle Suffolk Suffolk sold sold sold sold aisles sold sold foal upbeat sold Darn sold bat upbeat sold Suffolk Suffolk Suffolk sold Flexible Suffolk foal Darn sold Darn foal Suffolk Darn sold Darn Suffolk sold foal upbeat Suffolk Darn Suffolk foal upbeat Suffolk sold Suffolk Darn Darn Suffolk Suffolk sold Suffolk constrained upbeat trifle Suffolk Darn foal upbeat sold sold sold sold Suffolk sold Suffolk foal Suffolk sold sold foal sold Suffolk Suffolk sold Suffolk sold Suffolk sold Suffolk sold Suffolk Suffolk Suffolk Suffolk Darn Suffolk $30.00 Suffolk sold aisles Suffolk Suffolk foal sold foal trifle Suffolk Sanford Suffolk sold sold sold Suffolk Suffolk upbeat sold Suffolk Suffolk Suffolk sold Suffolk Darn Darn Suffolk sold Suffolk sold upbeat foal Darn Suffolk Mix Suffolk transcripts Suffolk sold Converse sold Suffolk Darn upbeat Suffolk upbeat sold Suffolk Suffolk Darn sold Suffolk Suffolk sold sold Suffolk Suffolk Darn Suffolk Suffolk Darn foal sold sold bat assimilation foal foal sold Suffolk trifle sold constrained Suffolk Suffolk sold sold Suffolk Suffolk sold sold Suffolk trifle Darn Suffolk upbeat Suffolk Suffolk sold Suffolk Suffolk sold Suffolk Sanford Suffolk Suffolk ITO Suffolk Suffolk sold Suffolk Darn sold Suffolk Suffolk Suffolk sai sold Suffolk Suffolk Suffolk Suffolk sold sold Rubber sold trifle upbeat Suffolk sold sold sold sold Converse upbeat trifle Darn trifle sold Darn Suffolk Suffolk Suffolk sold Darn sold Suffolk foal Suffolk Suffolk Suffolk sold sold $30.00 sold sold sai Suffolk Darn sold Suffolk sold Suffolk Suffolk sold sold Darn Americas sold Darn Suffolk foal sold sold sold upbeat sold sold sold Suffolk Suffolk sold Suffolk foal Suffolk sold Sanford sai Suffolk Suffolk Suffolk Suffolk sold sold Suffolk $30.00 sai Suffolk sold sold sai Darn foal sold Suffolk sold sai Suffolk sold Suffolk sold Suffolk foal Suffolk Darn Suffolk Suffolk Suffolk upbeat Darn sold Darn Darn Suffolk sold Suffolk sold Suffolk foal sold sold Suffolk sold sold sold sold Suffolk Suffolk Suffolk Suffolk trifle sold sai sold Darn sold Suffolk clashes Suffolk Suffolk Suffolk sold Suffolk Suffolk sold Suffolk sold Suffolk Suffolk sold Suffolk Suffolk upbeat trifle Suffolk sold foal foal Suffolk Suffolk sold Darn upbeat sold Converse Suffolk Suffolk sold upbeat Suffolk Suffolk Suffolk sold sold Suffolk trifle sold clashes clashes Suffolk upbeat sold sold sold Darn Suffolk clashes sold Suffolk sold Suffolk Suffolk Suffolk sold Suffolk upbeat trifle Suffolk sold sold sold Darn Suffolk Suffolk sold Suffolk Darn Suffolk Darn prorated sai Suffolk Suffolk transcripts Mix upbeat Suffolk Darn Suffolk upbeat sold sold upbeat sold Americas transcripts Suffolk sai sai sold Suffolk Suffolk sold bat Suffolk upbeat sold sold foal Suffolk sold Suffolk sold upbeat upbeat Darn Suffolk foal sold prorated Suffolk sold Suffolk sold Suffolk Suffolk foal Suffolk sold sold sold foal foal Suffolk Suffolk Darn sold bat Suffolk sold trifle Suffolk sold Suffolk Suffolk sold sold Suffolk sold sai sold sai Darn Suffolk Suffolk Darn Suffolk Suffolk foal sold Suffolk sold Suffolk bat sold sold Darn sold Suffolk Converse foal foal Darn upbeat Sanford Suffolk prorated Suffolk foal Darn Suffolk Darn sold sold Suffolk sold sold Suffolk sold Darn clashes sold Darn Suffolk sold upbeat Put sold Suffolk foal Suffolk Suffolk Darn clashes foal Darn prorated sold Suffolk sold sold sold sold Suffolk Suffolk foal Suffolk aisles Suffolk Suffolk Suffolk sold foal Suffolk miniatures Suffolk Suffolk sold Darn Suffolk Suffolk Suffolk upbeat Suffolk trifle sold Suffolk sold Maker upbeat trifle Suffolk Suffolk Suffolk sold Suffolk sold sold Darn sold sold sold $30.00 bat Darn sai Suffolk trifle sai sold Suffolk Suffolk Suffolk Darn Suffolk upbeat Suffolk sai trifle Darn Suffolk transcripts SEN Suffolk upbeat Suffolk trifle Darn trifle sold foal Suffolk sold Suffolk bat Suffolk Suffolk Suffolk Suffolk sold sold Suffolk antipsychotic Suffolk sold Suffolk sold Suffolk sold Suffolk clashes trifle sold sold Put bat sold Suffolk Darn Suffolk Suffolk sai upbeat Suffolk Darn sold sold sold sold Darn Darn clashes sold sold Suffolk Put Darn sai Darn sold sold Suffolk sold sold Converse\n"
     ]
    }
   ],
   "source": [
    "#example generate summary from fulltext\n",
    "summary, fulltext, cits, cts1 = df.abstract[4], df.body[4], df.citations[4], df['cited text spans'][4]\n",
    "batch = tokenizer(fulltext, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "out = pt_model.generate(return_dict_in_generate=True, **batch)\n",
    "\n",
    "\n",
    "batch2 = tokenizer(cits, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "out2 = pt_model.generate(return_dict_in_generate=True, **batch2)\n",
    "batch3 = tokenizer(cts1, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "out3 = pt_model.generate(return_dict_in_generate=True, **batch3)\n",
    "\n",
    "\n",
    "\n",
    "pred = aa.forward(out, out2, out3)\n",
    "ids = decode_output(pred)\n",
    "tgt_text = tokenizer.batch_decode(ids, skip_special_tokens=True)\n",
    "tgt_text = \" \".join(tgt_text)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.07462686567164178, recall=0.0008947745168217609, fmeasure=0.0017683465959328027),\n",
       " 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_text = \" \".join(tgt_text)\n",
    "\n",
    "score = scorer.score(tgt_text, summary)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
