A Joint Source-Channel Model For Machine Transliteration
Most foreign names are transliterated into Chinese, Japanese or Korean with approximate phonetic equivalents.
The transliteration is usually achieved through intermediate phonemic mapping.
This paper presents a new framework that allows direct orthographical mapping (DOM) between two different languages, through a joint source-channel model, also called n-gram transliteration model (TM).
With the n-gram TM model, we automate the orthographic alignment process to derive the aligned transliteration units from a bilingual dictionary.
The n-gram TM under the DOM framework greatly reduces system development effort and provides a quantum leap in improvement in transliteration accuracy over that of other state-of-the-art machine learning algorithms.
The modeling framework is validated through several experiments for English-Chinese language pair.
We find that English-to-Chinese transliteration without Chinese phonemes outperforms that with Chinese phonemes.
Our grapheme-based approach, which treats transliteration as statistical machine translation problem under monotonic constraint, aims to obtain a direct orthographical mapping (DOM) to reduce possible errors introduced in multiple conversions.
Phoneme-based approaches are usually not good enough, because name entities have various etymological origins and transliterations are not always decided by pronunciations.
Many transliterated words are proper names, whose pronunciation rules may vary depending on the language of origin.
Our direct orthographic mapping, making use of individual Chinese graphemes, tends to overcome the problem and model the character choice directly.
