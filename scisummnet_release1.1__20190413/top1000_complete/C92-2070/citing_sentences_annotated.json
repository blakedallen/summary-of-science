[
  {
    "citance_No": 1, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "(1991), Chouekand Lusignan (1985), Clear (1989), Dagan et al (1991), Gale et al (to appear), Hearst (1991), Lesk (1986), Smadja and McKeown (1990), Walker (1987), Veronis and Ide (1990), Yarowsky (1992), Zemik (1990, 1991)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "Recently, Yarowsky (1992) has found a way to extend our use of the Bayesian techniques by training on the Roget &apos; s Thesaurus (Chapman, 1977) 2 and G-rolier &apos; s Encyclopedia (1991) instead of the Canadian Hansards, thus circumventing many of the objections to our use of the Hansards", 
    "clean_text": "Recently, Yarowsky (1992) has found a way to extend our use of the Bayesian techniques by training on the Roget's Thesaurus (Chapman, 1977) 2 and G-rolier's Encyclopedia (1991) instead of the Canadian Hansards, thus circumventing many of the objections to our use of the Hansards.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "Yarowsky (1992) inputs a 100-word context surrounding a polysemous word and scores each of the 1042 Roget Categories by: 1[ P r (w lRoget Categoryi) w in context The program can also be run in a mode where it takes unrestricted text as input and tags each word with its most likely Roget Category", 
    "clean_text": "Yarowsky (1992) inputs a 100-word context surrounding a polysemous word and scores each of the 1042 Roget Categories by: 1[ P r (w lRoget Categoryi) w in context The program can also be run in a mode where it takes unrestricted text as input and tags each word with its most likely Roget Category.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "Table 1 shows the performance of Yarowsky (1992) on twelve words which have been previously discussed in the literature", 
    "clean_text": "Table 1 shows the performance of Yarowsky (1992) on twelve words which have been previously discussed in the literature.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "In fact, both Black (1988) and Yarowsky (1992) report 72% performance on this very same word", 
    "clean_text": "In fact, both Black (1988) and Yarowsky (1992) report 72% performance on this very same word.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "In fact, Yarowsky (1992) falls below the baseline for one of the twelve words (issue), although perhaps, we needn &apos; t be too concerned about this one deviation", 
    "clean_text": "In fact, Yarowsky (1992) falls below the baseline for one of the twelve words (issue), although perhaps, we needn't be too concerned about this one deviation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P92-1032", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "William A., Gale | Kenneth Ward, Church | David, Yarowsky", 
    "raw_text": "Table 2: The Baseline Word Baseline Yarowsky (1992) issue 96% 94% duty 87% 96% galley 83% 99% star 83% 96% taste 74% 93% bass 70% 99% slug 62% 97% sentence 62% 98% interest 60% 72% mole 59% 99% cone 51% 77% bow 48% 91% AVERAGE 70% 92% As mentioned previously, the test words in Tables 1 and 2 were selected from the literature on polysemy, and therefore, tend to focus on the more difficult cases", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "A97-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Alessandro, Cucchiarelli | Paola, Velardi", 
    "raw_text": "Semantic tags are assigned from on-line thesaura like WordNet (Basili et al 1996) (Resnik, 1995), Roget &apos; s categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992) 1", 
    "clean_text": "Semantic tags are assigned from on-line thesauras like WordNet (Basili et al 1996) (Resnik, 1995), Roget's categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992) 1.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P05-1005", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Upali Sathyajith, Kohomban | Wee Sun, Lee", 
    "raw_text": "However, their approach did not use the fact that the primes are common for words, and training data can hence be reused. Yarowsky (1992) used Roget? s Thesaurus categories as classes for word senses", 
    "clean_text": "Yarowsky (1992) used Roget's Thesaurus categories as classes for word senses.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W97-0208", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yorick, Wilks | Mark, Stevenson", 
    "raw_text": "(Gale, Church, and Yarowsky, 1992)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W97-0208", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yorick, Wilks | Mark, Stevenson", 
    "raw_text": "The best examples of this approach has been the resent work of Yarowsky (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995)", 
    "clean_text": "The best examples of this approach has been the resent work of Yarowsky (Yarowsky, 1992), (Yarowsky, 1993), (Yarowsky, 1995).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W97-0208", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yorick, Wilks | Mark, Stevenson", 
    "raw_text": "Much of the research in this area has been compromised by the fact that researchers have focussed on lexical ambiguities that are not true word sense distinctions, such as words translated ifferently across two languages (Gale, Church, and Yarowsky, 1992) or homophones~ (Yarowsky, 1993)", 
    "clean_text": "Much of the research in this area has been compromised by the fact that researchers have focused on lexical ambiguities that are not true word sense distinctions, such as words translated differently across two languages (Gale, Church, and Yarowsky, 1992) or homophones (Yarowsky, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W97-0208", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yorick, Wilks | Mark, Stevenson", 
    "raw_text": "Pragmatic domain codes can be used to disambiguate (usually nominal) senses, as was shown by (Bruce and Guthrie, 1992) and (Yarowsky, 1992)", 
    "clean_text": "Pragmatic domain codes can be used to disambiguate (usually nominal) senses, as was shown by (Bruce and Guthrie, 1992) and (Yarowsky, 1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W97-0208", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yorick, Wilks | Mark, Stevenson", 
    "raw_text": "(Gale, Church, and Yarowsky, 1992), (Yarowsky, 1993), (Schfitze, 1992)) and our system is a true tagging algorithm, operating on free text", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W97-0213", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Philip, Resnik", 
    "raw_text": "Some clusters of studies have used common test suites, most notably the 2094-word Hne data of Leacock et al (1993), shared by Lehman (1994) and Mooney (1996) and evaluated on the system of Gale, Church and Yarowsky (1992)", 
    "clean_text": "Some clusters of studies have used common test suites, most notably the 2094-word Hne data of Leacock et al (1993), shared by Lehman (1994) and Mooney (1996) and evaluated on the system of Gale, Church and Yarowsky (1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W07-2096", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "David, Pinto | Paolo, Rosso | H&eacute;ctor, Jim&eacute;nez-Salazar", 
    "raw_text": "Yarowsky (Yarowsky, 1992) used instead thesauri for their experiments", 
    "clean_text": "Yarowsky (Yarowsky, 1992) used instead thesauri for their experiments.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P98-2180", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Stephen D., Richardson | William B., Dolan | Lucy, Vanderwende", 
    "raw_text": "The massive network of inverted semrel structures contained in MindNet invalidates the criticism leveled against dictionary-based methods by Yarowsky (1992) and Ide and Veronis (1993) that LKBs created from MRDs provide spotty coverage of a language at best", 
    "clean_text": "The massive network of inverted semrel structures contained in MindNet invalidates the criticism leveled against dictionary-based methods by Yarowsky (1992) and Ide and Veronis (1993) that LKBs created from MRDs provide spotty coverage of a language at best.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P98-2180", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Stephen D., Richardson | William B., Dolan | Lucy, Vanderwende", 
    "raw_text": "Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts (e.g., Brown et al 1992, Yarowsky 1992), as well as in similar predicate argument structure contexts (e.g., Grishman and Sterling 1994)", 
    "clean_text": "Syntagmatic strategies for determining similarity have often been based on statistical analyses of large corpora that yield clusters of words occurring in similar bigram and trigram contexts (e.g., Brown et al 1992, Yarowsky 1992), as well as in similar predicate argument structure contexts (e.g., Grishman and Sterling 1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W11-1102", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Xuchen, Yao | Benjamin, van Durme", 
    "raw_text": "As in prior work including B& amp; L, we rely on the intuition that the senses of words are hinted at by their contextual information (Yarowsky, 1992) .From the perspective of a generative process, neigh boring words of a target are generated by the target? s underlying sense.2 Both LDA and HDP define graphical models that generate collections of discrete data", 
    "clean_text": "As in prior work including B&L, we rely on the intuition that the senses of words are hinted at by their contextual information (Yarowsky, 1992). From the perspective of a generative process, neighboring words of a target are generated by the target's underlying sense.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W99-0508", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Nancy M., Ide", 
    "raw_text": "It ~s well known that the most nagging issue for word sense disamblguanon (WSD) Is the definmon of just what a word sense is At its base, the problem Is a philosophical and linguistic one that is far from being resolved However, work in automated language processing has led to effotts to flnd practical means to dlstmgmsh word senses, at least to the degree that they are useful for natural anguage processing tasks such as summarization, document retrieval, and machine translataon Several criteria have been suggested and exploited to automatically determine the sense of a word m context (see Ide and V6roms, 1998), including syntactic behavior, semantic and pragmatic knowledge, and especially in more recent empirical studies, word co-occurrence within syntactic relations (e g, Hearst, 1991, Yarowsky, 1993), words co-occurring m global context (e g, Gale et al 1993, Yarowsky, 1992 Schutze, 1992, 1993), etc No clear criteria have emerged, however, and the problem continues to loom large for WSD work The notion that cross-hngual comparison can be useful fol sense dlsamblguauon has served as a basis for some recent work on WSD Foi example, Brown et al (1991) and Gale et al (1992a, 1993) used the parallel, aligned Hansard Corpus of Canadian Parhamentary debates foi WSD, and Dagan et al (1991) and Dagan and Ital (1994) used monohngual corpora of Hebrew and German and a bilingual dictionary These studies rely on the assumption that the mapping between words and word senses vanes significantly among languages For example, the word duty in Englisht~anslates into French as devoir m ~tsobhgatlon sense, and tmpOt m ~ts tax sense By determining the translation 52, .. -., .~eqmvalentot duty in a parallel French text, the correct sense of the Enghsh word is identified These studies exploit th~s lnformatmn m order to gather co-occurrence data for the different senses, which ts then used to dtsamb~guate n w texts In related work, Dywk (1998) used patterns of translational relatmns in an EnghshNorwegianparalle! corpus (ENPC, Oslo Umverslty) to define semantic propemes uch as synonymy ,ambtgmty, vagueness, and semantic helds and suggested a derivation otsemantic representations for signs (eg, lexemes) ,captunngsemantmrelatmnshlps such as hyponymy etc ,fiom such translatmnal relatmns Recently, Resnlk and Yarowsky (1997) suggested that fol the purposes ot WSD, the different senses of a wo~d could be detelmlned by considering only sense d~stmctmns that are lextcahzed cross-hngmstlcally In particular, they propose that some set of target languages be ~dent~fied, and that the sense d~stmctmns to be considered for language processing appllcatmns and evaluatmn be restricted to those that are reahzed lexlcally in some minimum subset of those languages This idea would seem to p~ovtde an answer, at least m part, to the problem of determining different senses of a word mtumvely, one assumes that ff another language lexlcahzes a word m two or more ways, there must be a conceptual monvatmn If we look at enough languages, we would be likely to fred the s~gmficant lexlcal differences that dehmtt different senses of a word However ,th~ssuggestmn raises several questions Fo~ instance, ~t ~s well known that many amb~gumes are preserved across languages (for example, the FrenchtntdrYt and the Enghsh interest) ,especmlly languages that are relatively closely related Assuming this problem can be overcome, should differences found m closely related languages be given lesser (or greater) weight than those found m more distantly related languages 9 More generally, which languages hould be considered for this exermse 9 All languages 9 Closely related languages9 Languages from different language famlhes &apos;~ A mixture of the two 9 How many languages, and of which types, would be& quot; enough& quot; to provide adequate lnfotmanon tot this purpose~ There ts also the questmn ot the crlterm that would be used to estabhsh that a sense distinction is& quot ;lexlcahzedcross-hngu~stmally& quot; How consistent must the d~stlnCtlOn be 9 Does it mean that two concepts are expressed by mutually non-lntetchangeable lexmal items in some slgmficant number ot other languages, or need tt only be the case that the option ot a different lexlcahzatlon exists m a certain percentage of cases 9 Anotherconslderatmn ts where the cross-hngual mformatlon to answer these questmns would come from Usingbdmgual dictionaries would be extremely tedmus and error-prone ,g~ven the substantial d~vergence among d~ctlonanes in terms of the kinds and degree of sense dlstmctmns they make Resmk and Yalowsky (1997) suggest EutoWordNet (Vossen, 1998) as a possible somce of mformatmn, but, given that EuroWordNet s pttmatdy a lexmon and not a corpus, ~t is subject to many of the same objections as for bl-hngual dictionaries An alternative would be to gather the reformation from parallel ,ahgned corp ma Unlike bilingual and muttt-hngual dictionaries ,translatmneqmvalentsxn parallel texts a~e determined by experienced translatols, who evaluate ach instance ot a word &apos; s use m context rather than as a part of the meta-hngmst~c actlvlty of classifying senses for mclusmn in a dictionary However, at present very few parallel ahgned corpora exist The vast majority ot these are bl-texts ,mvolwng only two languages, one of which is very often English Ideally, a serious 53 evaluation of Resnik and Yarowsky &apos; s proposal would include parallel texts m languages from several different language families, and, to maximally ensure that the word m question is used in the exact same sense across languages, ~t would be preferable that the same text were used over all languages in the study The only currently avadable parallel corpora for more than two languages are Olwell &apos; s Nmeteen Eighty-Four (Erjavec and Ide, 1998), Plato &apos; s Repubhc (Erjavec, et al 1998), the MULTEXT Journal .o/ the Commt.~ston corpus (Ide and V6roms, 1994), and the Bible (Resnlk, et al m press) It is likely that these corpora do not provide enough appropriate data to reliably determine sense distinctions Also, ~t Is not clear how the lexlcahzatlon of sense distractions across languages I affected by genre, domain, style, etc Thls paper attempts to provide some prehmlnary answers to the questions outhned above, In order to eventually determine the degree to which the use of parallel data ts vmble to determine sense distinctions, and, ff so, the ways in which th~s reformation might be used Given the lack of lalge parallel texts across multiple languages, the study is necessarily hmlted, however, close exammanon of a small sample of parallel data can, as a first step, provide the basis and dlrectmn for more extensive studies 1 Methodology", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
