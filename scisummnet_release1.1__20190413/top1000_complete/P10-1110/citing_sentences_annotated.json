[
  {
    "citance_No": 1, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "In this paper, we follow the line of investigation started by Huang and Sagae (2010) and apply dynamic programming to (projective) transition-based dependency parsing (Nivre, 2008)", 
    "clean_text": "In this paper, we follow the line of investigation started by Huang and Sagae (2010) and apply dynamic programming to (projective) transition-based dependency parsing (Nivre, 2008).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "While our general approach is the same as the one of Huang and Sagae (2010), we depart from their framework by not representing the computations of a parser as a graph-structured stack in the sense of Tomita (1986)", 
    "clean_text": "While our general approach is the same as the one of Huang and Sagae (2010), we depart from their framework by not representing the computations of a parser as a graph-structured stack in the sense of Tomita (1986).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "Two examples of feature functions are the word form associated with the topmost and second-topmost node on the stack; adopting the notation of Huang and Sagae (2010), we will write these functions as s0: w and s1: w, respectively", 
    "clean_text": "Two examples of feature functions are the word form associated with the topmost and second-topmost node on the stack; adopting the notation of Huang and Sagae (2010), we will write these functions as s0: w and s1: w, respectively.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "In the following, we take this second approach, which is also the approach of Huang and Sagae (2010)", 
    "clean_text": "In the following, we take this second approach, which is also the approach of Huang and Sagae (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "Huang and Sagae (2010) use this quantity to order the items in a beam search on top of their dynamic programming method", 
    "clean_text": "Huang and Sagae (2010) use this quantity to order the items in a beam search on top of their dynamic programming method.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "Alternatively, we can also use the more involved calculation employed by Huang and Sagae (2010), which allows them to get rid of the left-con text vector from their items.1 4.5 Compatibility", 
    "clean_text": "Alternatively, we can also use the more involved calculation employed by Huang and Sagae (2010), which allows them to get rid of the left context vector from their items.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "Thefeature models that are used in practical systems are considerably more complex, and not all of them are 1The essential idea in the calculation by Huang and Sagae (2010) is to delegate (in the computation of the Viterbi score) the scoring of sh transitions to the inference rules for la/ra", 
    "clean_text": "The essential idea in the calculation by Huang and Sagae (2010) is to delegate (in the computation of the Viterbi score) the scoring of sh transitions to the inference rules for la/ra.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "The basic idea behind our technique is the same as the one implemented by Huang and Sagae (2010 )forthe special case of the arc-standard model, but in stead of their graph-structured stack representation we use a tabulation akin to Lang? s approach to the simulation of pushdown automata (Lang, 1974)", 
    "clean_text": "The basic idea behind our technique is the same as the one implemented by Huang and Sagae (2010) for the special case of the arc-standard model, but instead of their graph-structured stack representation we use a tabulation akin to Lang's approach to the simulation of pushdown automata (Lang, 1974).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P11-1068", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Kuhlmann | Carlos, G&oacute;mez-Rodr&iacute;guez | Giorgio, Satta", 
    "raw_text": "However, Huang and Sagae (2010) have provided evidence that the use of dynamic programming on top of a transition-based dependency parser can improve accuracy even without exhaustive search. The trade off between expressivity of the feature mod els on the one hand and the efficiency of the search on the other is a topic that we find worth investigating", 
    "clean_text": "However, Huang and Sagae (2010) have provided evidence that the use of dynamic programming on top of a transition-based dependency parser can improve accuracy even without exhaustive search.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P12-1110", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jun, Hatori | Takuya, Matsuzaki | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "To handle the increased computational complexity, we adopt the incremental parsing framework with dynamic programming (Huang and Sagae, 2010), and propose an efficient method of character-based decoding over candidate structures", 
    "clean_text": "To handle the increased computational complexity, we adopt the incremental parsing framework with dynamic programming (Huang and Sagae, 2010), and propose an efficient method of character-based decoding over candidate structures.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P12-1110", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jun, Hatori | Takuya, Matsuzaki | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "The incremental framework of our model is based on the joint POS tagging and dependency parsing model for Chinese (Hatori et al, 2011), which is an extension of the shift-reduce dependency parser with dynamic programming (Huang and Sagae, 2010)", 
    "clean_text": "The incremental framework of our model is based on the joint POS tagging and dependency parsing model for Chinese (Hatori et al, 2011), which is an extension of the shift-reduce dependency parser with dynamic programming (Huang and Sagae, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P12-1110", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jun, Hatori | Takuya, Matsuzaki | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "The feature set of our model is fundamentally a com bi nation of the features used in the state-of-the-art joint segmentation and POS tagging model (Zhang and Clark, 2010) and dependency parser (Huang and Sagae, 2010), both of which are used as baseline models in our experiment", 
    "clean_text": "The feature set of our model is fundamentally a combination of the features used in the state-of-the-art joint segmentation and POS tagging model (Zhang and Clark, 2010) and dependency parser (Huang and Sagae, 2010), both of which are used as baseline models in our experiment.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P12-1110", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jun, Hatori | Takuya, Matsuzaki | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "W21, and T01? 05 are taken from Zhang and Clark (2010), and P01? P28 are taken from Huang and Sagae (2010)", 
    "clean_text": "W21, and T01? 05 are taken from Zhang and Clark (2010), and P01? P28 are taken from Huang and Sagae (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P12-1110", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jun, Hatori | Takuya, Matsuzaki | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "Dep?: the state-of-the-art dependency parser by Huang and Sagae (2010)", 
    "clean_text": "Dep?: the state-of-the-art dependency parser by Huang and Sagae (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D11-1109", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Zhenghua, Li | Min, Zhang | Wanxiang, Che | Ting, Liu | Wenliang, Chen | Haizhou, Li", 
    "raw_text": "Following the setup of Duan et al (2007), Zhang and Clark (2008b) and HuangandSagae (2010), we split CTB5 into training (secs 001 815 and 1001-1136), development (secs 886-931and 1148-1151), and test (secs 816-885 and 1137 1147) sets", 
    "clean_text": "Following the setup of Duan et al (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001 815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137 1147) sets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D11-1109", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Zhenghua, Li | Min, Zhang | Wanxiang, Che | Ting, Liu | Wenliang, Chen | Haizhou, Li", 
    "raw_text": "H& amp; S10 refers to the results of Huang and Sagae (2010)", 
    "clean_text": "H&S10 refers to the results of Huang and Sagae (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P14-2128", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ji, Ma | Yue, Zhang | Jingbo, Zhu", 
    "raw_text": "denote HuangandSagae (2010) and Zhang and Nivre (2011), respectively", 
    "clean_text": "In particular, \"Huang 10\" and \"Zhang 11\" denote Huang and Sagae (2010) and Zhang and Nivre (2011), respectively.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W11-0906", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jinho D., Choi | Martha, Palmer", 
    "raw_text": "Since our algorithm is transition-based, many existing techniques such as k-best ranking (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010) designed to improve transition-based parsing can be applied", 
    "clean_text": "Since our algorithm is transition-based, many existing techniques such as k-best ranking (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010) designed to improve transition-based parsing can be applied.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "S12-1073", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hao, Xiong | Qun, Liu", 
    "raw_text": "We implement three transition-based dependency parsers with three different parsing algorithms: Nivre? s arc standard, Nivre? s arc eager (see Nivre (2004) for a comparison between the two Nivre algorithms), and Liang? s dynamic algorithm (Huang and Sagae, 2010)", 
    "clean_text": "We implement three transition-based dependency parsers with three different parsing algorithms: Nivre's arc standard, Nivre's arc eager (see Nivre (2004) for a comparison between the two Nivre algorithms), and Liang's dynamic algorithm (Huang and Sagae, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D12-1029", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Daniel, Fern&Atilde;&iexcl;ndez-Gonz&Atilde;&iexcl;lez | Carlos, G&oacute;mez-Rodr&iacute;guez", 
    "raw_text": "This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al2004), McDonald et al2005), Martins et al2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can betrained directly from annotated data and produce ac curate analyses very efficiently", 
    "clean_text": "This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al2004), McDonald et al2005), Martins et al2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce ac curate analyses very efficiently.", 
    "keep_for_gold": 0
  }
]
