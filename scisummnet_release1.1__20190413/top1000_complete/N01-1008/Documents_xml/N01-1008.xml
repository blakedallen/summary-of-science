<PAPER>
  <S sid="0">Text And Knowledge Mining For Coreference Resolution</S>
  <ABSTRACT>
    <S sid="1" ssid="1">AND (y is one of the hypernyms of x) AND AND (z is SYNONYM of y) AND AND (z is SYNONYM of anaphor) then Cast_in_Chain(Anaphor,antecedent) (Riloff and Jones 1999) note that the performance of the mutual bootstrapping algorithm can deteriorate rapidly if erroneous rules are entered.</S>
    <S sid="2" ssid="2">To make the algorithm more robust we use the same solution by introducing a second level of bootrapping. outer level, called most reliable based on semantic consistency and discard all the others before restarting the mutual bootstrapping loop again.</S>
    <S sid="3" ssid="3">In our experiments we have retained only those rules for which the new performance, given by the F-measure was larger than the median of the past four loops.</S>
    <S sid="4" ssid="4">The formula for the van Rijsbergen's F-measure combines precision the recall = 6 Evaluation To measure the performance of COCKTAIL we have trained the system on 30 MUC-6 and MUC-7 texts and tested it on the remaining 30 documents.</S>
    <S sid="5" ssid="5">computed the the Fperformance measures have been obtained automatically using the MUC-6 coreference scoring program (Vilain et al. 1995).</S>
    <S sid="6" ssid="6">Table 4 lists the results.</S>
    <S sid="7" ssid="7">Precision Recall F-measure rules 87.1% 61.7% 72.3% rules combined 91.3% 58.6% 71.8% +bootstrapping 92.0% 73.9% 81.9% Table 4: Bootstrapping effect on COCKTAIL Table 4 shows that the seed set of rules had good precision but poor recall.</S>
    <S sid="8" ssid="8">By combining the rules with the entropy-based measure, we obtained further enhancement in precision, but the recall dropped.</S>
    <S sid="9" ssid="9">The application of the bootstrapping methodology determined an enhancement of recall, and thus of the F-measure.</S>
    <S sid="10" ssid="10">In the future we intend to compare the overall effect of rules that recognize referential expressions on the overall performance of the system.</S>
    <S sid="11" ssid="11">7 Conclusion We have introduced a new data-driven method for corefresolution, implemented in the system.</S>
    <S sid="12" ssid="12">Unlike other knowledge-poor methods for corefresolution (Baldwin 1997) (Mitkov 1998), COCKits most performant rules through massive data, generated by its component.</S>
    <S sid="13" ssid="13">Furthermore, by using an entropy-based method we determine the best partition of corefering expressions chains. rules are learned by applying a bootstrapping methodology that uncovers additional semantic consistency data.</S>
    <S sid="14" ssid="14">References Breck Baldwin.</S>
    <S sid="15" ssid="15">1997.</S>
    <S sid="16" ssid="16">CogNIAC: high precision coreference with limited knowledge and linguistic resources.</S>
  </ABSTRACT>
  <SECTION title="1 Background" number="1">
    <S sid="17" ssid="1">Reference resolution is an important task for discourse or dialogue processing systems since identity relations between anaphoric textual entities and their antecedents is a prerequisite to the understanding of text or conversation.</S>
    <S sid="18" ssid="2">Traditionally, coreference resolution has been performed by combining linguistic and cognitive knowledge of language.</S>
    <S sid="19" ssid="3">Linguistic information is provided mostly by syntactic and semantic modeling of language whereas cognitive information is incorporated in computational models of discourse.</S>
    <S sid="20" ssid="4">Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988).</S>
    <S sid="21" ssid="5">The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone.</S>
    <S sid="22" ssid="6">Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf.</S>
    <S sid="23" ssid="7">(Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)).</S>
    <S sid="24" ssid="8">For example, COGNIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference.</S>
    <S sid="25" ssid="9">In our work, we approached the coreference resolution problem by trying to determine how much more knowledge is required to supplement the abovementioned knowledge-poor methods and how to derive that knowledge.</S>
    <S sid="26" ssid="10">To this end we (1) analyze the data to find what types of anaphor-antecedent pairs are most popular in real-world texts; (2) devise knowledge-minimalist rules for handling the majority of those popular cases; and (3) discover what supplementary knowledge is needed for remaining, more difficult cases.</S>
    <S sid="27" ssid="11">To analyze coreference data we use a corpus of annotated texts.</S>
    <S sid="28" ssid="12">To devise minimalist coreference resolution rules we consider (1) strong indicators of cohesion, such as repetitions, name aliases or appositions; and (2) gender, number and class agreements.</S>
    <S sid="29" ssid="13">WordNet (Miller 1995), the vast semantic knowledge base, provides suplementary knowledge in the form of semantic consistency between coreferring nouns.</S>
    <S sid="30" ssid="14">Additional semantic consistency knowledge is generated by a bootstrapping mechanism when our coreference resolution system, COCKTAIL', processes new texts.</S>
    <S sid="31" ssid="15">This bootstrapping mechanism inspired by the technique presented in (Riloff and Jones 1999) targets one of the most problematic forms of knowledge needed for coreference resolution: the semantic consistency of corefering nominals.</S>
    <S sid="32" ssid="16">The rest of the paper is organized as follows.</S>
    <S sid="33" ssid="17">Section 2 discusses our text mining methodology for analysing the data and devising knowledgeminimalist rules for resolving the most popular coreference cases.</S>
    <S sid="34" ssid="18">Section 3 presents the knowledgemining components of COCKTAIL that use WordNet for deriving semantic consistency as well as gender information.</S>
    <S sid="35" ssid="19">Section 4 presents an entropy-based method for optimally combining coreference rules and Section 5 presents the bootstrapping mechanism.</S>
    <S sid="36" ssid="20">Section 6 reports and discusses the experimental results while Section 7 summarizes the conclusions. of a nominal, or a disjunct of two or three of them, as illustrated in Table 2.</S>
    <S sid="37" ssid="21">The gender attributes may have the values: Gender attributes are assigned by the two following heuristics: Heuristic 1 If a collocation fom a WordNet synset contains the word male, the expression G for the whole sysnet is m. If the collocation contains the words female or woman, G= f .</S>
    <S sid="38" ssid="22">Heuristic 2 Consider the first four words from the synset gloss.</S>
    <S sid="39" ssid="23">If any of the gloss words have been assigned gender information, propagate the same information to the defined synset as well.</S>
    <S sid="40" ssid="24">Each hyponym of the concept {person, individual, human}, categorized as PERSON has expression G initialized to f V m, since all lexemes represent persons, that can be either males or females.</S>
    <S sid="41" ssid="25">Whenever one of the two heuristics previously defined can be applied at any node S from this subhierarchy, three operations take place: t&gt; Operation 1: We update G with the new expression brough forward by the heuristic. t&gt; Operation 2: We propagate all the expression to the hyponyms of S; t&gt; Operation 3: We revisit the whole PERSON subhierarchy, in search for concepts D that are defined with glosses that use any of the words from synset S or any word from any of its hyponyms.</S>
    <S sid="42" ssid="26">Whenever we find such a word, we update its G expression to G(S).</S>
    <S sid="43" ssid="27">We also note that many words are polysemous, thus a word w may have multiple senses under the PERSON sub-hierarchy and moreover, each sense might have a different G expression.</S>
    <S sid="44" ssid="28">In this case, all words from the synsets containing w receive the disjunct of the gender attributes corresponding to each sense of w. Mining semantic information from WordNet We used the WordNet knowledge base to mine patterns of WordNet paths that connect pairs of coreferring nouns from the annotated chains.</S>
    <S sid="45" ssid="29">The paths are combinations of any of the following WordNet 6A polysemous noun has multiple semantic senses and therefore has multiple entries in the WordNet dictionary.</S>
    <S sid="46" ssid="30">To determine the confidence of the path we consider three factors: *Factor fi has only two values.</S>
    <S sid="47" ssid="31">It is set to 1 when another coreference chain contains elements in the same NPs as the anaphor and the anetcedent.</S>
    <S sid="48" ssid="32">For example, if NPi is &amp;quot;the professor's son&amp;quot; and NP2 is &amp;quot;his father&amp;quot;, the semantic consistency between father and professor is more likely, given that his and son corefer.</S>
    <S sid="49" ssid="33">Otherwise, fi is set to 0.</S>
    <S sid="50" ssid="34">*Factor f2 favors (a) relations that are considered &amp;quot;stronger&amp;quot; (e.g.</S>
    <S sid="51" ssid="35">SYNONYMY, GLOSS); and (b) shorter paths.</S>
    <S sid="52" ssid="36">For this purpose we assign the following weights to each relation considered: W(SYNONYM) = 1.0; w(IS-A) = 0.9; w(GLoss) = 0.9; w(IN-GLoss) = 0.3; w(HAs-PART) = 0.7; w(MoRPHo-DERIVATION) = 0.6; and W(COLLIDESENSE) = 0.5.</S>
    <S sid="53" ssid="37">When computing the f2 factor, we assume that whenever at least two relations of the same kind repeat, we should consider the sequence of relations equivalent to a single relation, having the weight devided by the length of the sequence.</S>
    <S sid="54" ssid="38">If we denote by rir&#8222;i the number of different relation types encountered in a path, and rirsame(rel) denotes the number of links of type rel in a sequence, then we define f2 with the formula: *Factor h is a semantic measure operating on a conceptual space.</S>
    <S sid="55" ssid="39">When searching for a lexico-semantic path, a search space SS is created, which contains all WordNet content words that can be reached from the candidate antecedent or the anaphor in at most five combinations of the seven relations used by the third filter.</S>
    <S sid="56" ssid="40">We denote by N the total number of nouns and verbs in the search space.</S>
    <S sid="57" ssid="41">C represents the number of nouns and verbs that can be reached by both nominals.</S>
    <S sid="58" ssid="42">In addition rirtotal is the number of concepts along all paths established, whereas (Riloff and Jones 1999) note that the performance of the mutual bootstrapping algorithm can deteriorate rapidly if erroneous rules are entered.</S>
    <S sid="59" ssid="43">To make the algorithm more robust we use the same solution by introducing a second level of bootrapping.</S>
    <S sid="60" ssid="44">The outer level, called meta-bootstrapping identifies the most reliable k rules based on semantic consistency and discard all the others before restarting the mutual bootstrapping loop again.</S>
    <S sid="61" ssid="45">In our experiments we have retained only those rules for which the new performance, given by the F-measure was larger than the median of the past four loops.</S>
    <S sid="62" ssid="46">The formula for the van Rijsbergen's F-measure combines the precision P with the recall R in F =</S>
  </SECTION>
  <SECTION title="6 Evaluation" number="2">
    <S sid="63" ssid="1">To measure the performance of COCKTAIL we have trained the system on 30 MUC-6 and MUC-7 texts and tested it on the remaining 30 documents.</S>
    <S sid="64" ssid="2">We computed the precision, the recall and the Fmeasure.</S>
    <S sid="65" ssid="3">The performance measures have been obtained automatically using the MUC-6 coreference scoring program (Vilain et al. 1995).</S>
    <S sid="66" ssid="4">Table 4 lists the results.</S>
    <S sid="67" ssid="5">Table 4 shows that the seed set of rules had good precision but poor recall.</S>
    <S sid="68" ssid="6">By combining the rules with the entropy-based measure, we obtained further enhancement in precision, but the recall dropped.</S>
    <S sid="69" ssid="7">The application of the bootstrapping methodology determined an enhancement of recall, and thus of the F-measure.</S>
    <S sid="70" ssid="8">In the future we intend to compare the overall effect of rules that recognize referential expressions on the overall performance of the system.</S>
  </SECTION>
  <SECTION title="7 Conclusion" number="3">
    <S sid="71" ssid="1">We have introduced a new data-driven method for coreference resolution, implemented in the COCKTAIL system.</S>
    <S sid="72" ssid="2">Unlike other knowledge-poor methods for coreference resolution (Baldwin 1997) (Mitkov 1998), COCKTAIL filters its most performant rules through massive training data, generated by its AUTOTAG-COFtEF component.</S>
    <S sid="73" ssid="3">Furthermore, by using an entropy-based method we determine the best partition of corefering expressions in coreference chains.</S>
    <S sid="74" ssid="4">New rules are learned by applying a bootstrapping methodology that uncovers additional semantic consistency data.</S>
  </SECTION>
</PAPER>
