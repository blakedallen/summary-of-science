[
  {
    "citance_No": 1, 
    "citing_paper_id": "W12-3108", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Eleftherios, Avramidis", 
    "raw_text": "This contribution has been built based on the data released for the Quality Estimation task of the Workshop on Machine Translation (WMT) 2012 (Callison-Burch et al, 2012)", 
    "clean_text": "This contribution has been built based on the data released for the Quality Estimation task of the Workshop on Machine Translation (WMT) 2012 (Callison-Burch et al, 2012).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W12-4204", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ond&#x159;ej, Bojar | Dekai, Wu", 
    "raw_text": "The two-scale scoring for adequacy and fluency used in NIST evaluation has been abandoned by some evaluation campaigns, most notably the WMT shared task series, see Koehn and Monz (2006) through Callison-Burch et al (2012) 1", 
    "clean_text": "The two-scale scoring for adequacy and fluency used in NIST evaluation has been abandoned by some evaluation campaigns, most notably the WMT shared task series, see Koehn and Monz (2006) through Callison-Burch et al (2012) 1.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W12-4204", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ond&#x159;ej, Bojar | Dekai, Wu", 
    "raw_text": "Callison-Burch et al (2012) report? for several automatic metrics on the whole WMT12 English-to-Czech dataset, the best of which correlates at?= 0.18", 
    "clean_text": "Callison-Burch et al (2012) report for several automatic metrics on the whole WMT12 English-to-Czech dataset, the best of which correlates at?= 0.18.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W12-4204", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ond&#x159;ej, Bojar | Dekai, Wu", 
    "raw_text": "The only common metric is METEOR and it reaches 0.16 on the whole WMT12set.7 In line with our observation, Czech-to-English correlations reported by Callison-Burch et al (2012) are higher: the best metric achieves 0.28 and aver ages 0.25 across four source languages", 
    "clean_text": "In line with our observation, Czech-to-English correlations reported by Callison-Burch et al (2012) are higher: the best metric achieves 0.28 and aver ages 0.25 across four source languages.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W12-4204", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ond&#x159;ej, Bojar | Dekai, Wu", 
    "raw_text": "On the other hand, it is quite possible that the WMT-style rankings taken asthe gold standard are of a disputable quality themselves, see Section 3.1 or the detailed report on inter annotator agreement and a long discussion on interpreting the rankings in Callison-Burch et al (2012)", 
    "clean_text": "On the other hand, it is quite possible that the WMT-style rankings taken as the gold standard are of a disputable quality themselves, see Section 3.1 or the detailed report on inter annotator agreement and a long discussion on interpreting the rankings in Callison-Burch et al (2012).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W12-4204", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ond&#x159;ej, Bojar | Dekai, Wu", 
    "raw_text": "of7It is possible that Callison-Burch et al (2012) use some what different METEOR settings apart from the different subset of the data", 
    "clean_text": "It is possible that Callison-Burch et al (2012) use some what different METEOR settings apart from the different subset of the data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W12-3114", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Erwan, Moreau | Carl, Vogel", 
    "raw_text": "Neverthe less, in the context of this Quality Evaluation Shared task (see (Callison-Burch et al, 2012) for a detailed description) we have also used supervised learning as a final stage, in order to submit results which can be compared to other methods (see? 4) .We investigate the use of various similarity measures for evaluating the quality of machine translated sentences", 
    "clean_text": "Nevertheless, in the context of this Quality Evaluation Shared task (see (Callison-Burch et al, 2012) for a detailed description) we have also used supervised learning as a final stage, in order to submit results which can be compared to other methods (see? 4). We investigate the use of various similarity measures for evaluating the quality of machine translated sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W12-3114", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Erwan, Moreau | Carl, Vogel", 
    "raw_text": "Table 2 shows the best results among the configurations we have tested (expressed using the official evaluation measures, see (Callison-Burch et al, 2012) for details)", 
    "clean_text": "Table 2 shows the best results among the configurations we have tested (expressed using the official evaluation measures, see (Callison-Burch et al, 2012) for details).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W12-3114", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Erwan, Moreau | Carl, Vogel", 
    "raw_text": "The TCD-M5P-resources-only submission ranked 5th (among 17) in the ranking task, and 5th among 19 (tied with two other systems) in the scoring task (Callison-Burch et al, 2012) .Unfortunately the TCD-M5P-all submission contained an error.13 Below are the official results for TCD-M5P-resources-only and the corrected results for TCD-M5P-all :13In four cases in which Google n-grams formed the reference data, the scores were computed using the wrong language (Spanish instead of English) as the reference", 
    "clean_text": "The TCD-M5P-resources-only submission ranked 5th (among 17) in the ranking task, and 5th among 19 (tied with two other systems) in the scoring task (Callison-Burch et al, 2012). Unfortunately the TCD-M5P-all submission contained an error.13 Below are the official results for TCD-M5P-resources-only and the corrected results for TCD-M5P-all: In four cases in which Google n-grams formed the reference data, the scores were computed using the wrong language (Spanish instead of English) as the reference.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W12-3115", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Meritxell, Gonz&aacute;lez | Llu&iacute;s, M&agrave;rquez | Daniele, Pighin", 
    "raw_text": "The WMT 2012 shared task on QE for MT (Callison-Burch et al, 2012) required participants to score and rank a set of automatic English to Spanish translations output by a state of-the-art phrase based machine translation system", 
    "clean_text": "The WMT 2012 shared task on QE for MT (Callison-Burch et al, 2012) required participants to score and rank a set of automatic English to Spanish translations output by a state of-the-art phrase based machine translation system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-3115", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Meritxell, Gonz&aacute;lez | Llu&iacute;s, M&agrave;rquez | Daniele, Pighin", 
    "raw_text": "An analysis of the Pearson correlation of the baseline features (Callison-Burch et al, 2012) 1 with human quality assessments shows that the two strongest individual predictors of post-editing effort are the n-gram language model perplexities estimated on source and target sentences", 
    "clean_text": "An analysis of the Pearson correlation of the baseline features (Callison-Burch et al, 2012) with human quality assessments shows that the two strongest individual predictors of post-editing effort are the n-gram language model perplexities estimated on source and target sentences.", 
    "keep_for_gold": 0
  }
]
