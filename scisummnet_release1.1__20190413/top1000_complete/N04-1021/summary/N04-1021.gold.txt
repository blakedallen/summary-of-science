A Smorgasbord Of Features For Statistical Machine Translation
We describe a methodology for rapid experimentation in statistical machine translation which we use to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation.
Feature values were combined in a log-linear model to select the highest scoring candidate translation from an n-best list.
Feature weights were optimized directly against the BLEU evaluation metric on held-out data.
We present results for a small selection of features at each level of syntactic representation.
At the 2003 Johns Hopkins summer workshop on statistical machine translation, a large number of features were tested to discover which ones could improve a state-of-the-art translation system, and the only feature that produced a 'truly significant improvement' was the Model 1 score.
The effects of integrating syntactic structure into a state-of-the-art statistical machine translation system are investigated.
