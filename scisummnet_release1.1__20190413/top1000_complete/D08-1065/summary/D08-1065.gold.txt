Lattice Minimum Bayes-Risk Decoding for Statistical Machine Translation
We present Minimum Bayes-Risk (MBR) decoding over translation lattices that compactly encode a huge number of translation hypotheses.
We describe conditions on the loss function that will enable efficient implementation of MBR decoders on lattices.
We introduce an approximation to the BLEU score (Papineni et al., 2001) that satisfies these conditions.
The MBR decoding under this approximate BLEU is realized using Weighted Finite State Automata.
Our experiments show that the Lattice MBR decoder yields moderate, consistent gains in translation performance over N-best MBR decoding on Arabic-to-English, Chinese-to-English and English-to-Chinese translation tasks.
We conduct a range of experiments to understand why Lattice MBR improves upon N-best MBR and study the impact of various parameters on MBR performance.
We consider Taylor approximations to the logarithm of BLEU.
We extend MBR to word lattices, which improves performance over k-best list MBR.
The log-BLEU function must be modified slightly to yield a linear Taylor approximation: we replace the clipped n-gram count with the product of an n gram count and an n-gram indicator function.
We compute expected feature values by intersecting the translation lattice with a lattices for each n-gram t.
