Multi-Source Transfer of Delexicalized Dependency Parsers
We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data.
We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers.
We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser.
Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers.
The projected parsers from our system result in state-of-the-art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.
We show that part-of-speech tags contain significant amounts of information for unlabeled dependency parsing.
We demonstrate an alternative to grammar induction by projecting reference parse trees from languages that have annotations to ones that are resource-poor.
Tree banks in other languages can still serve as a kind of proxy for learning which features generally transfer useful in formation.
We demonstrate that projecting from a single oracle chosen language can lead to good parsing performance.
