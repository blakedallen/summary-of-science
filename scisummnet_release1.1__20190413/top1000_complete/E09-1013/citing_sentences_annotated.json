[
  {
    "citance_No": 1, 
    "citing_paper_id": "C10-2029", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Georgiana, Dinu | Mirella, Lapata", 
    "raw_text": "More related to our work are (Brody and Lapata, 2009) or (Toutanova and Johnson, 2008) who use LDA-based models which induce latent variables from task-specific data rather than from simple documents", 
    "clean_text": "More related to our work are (Brody and Lapata, 2009) or (Toutanova and Johnson, 2008) who use LDA-based models which induce latent variables from task-specific data rather than from simple documents.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "C10-2029", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Georgiana, Dinu | Mirella, Lapata", 
    "raw_text": "251 (Brody and Lapata, 2009) apply such a model for word sense induction on a set of 35 target nouns", 
    "clean_text": "(Brody and Lapata, 2009) apply such a model for word sense induction on a set of 35 target nouns.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-1034", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Thang, Nguyen | Yuening, Hu | Jordan, Boyd-Graber", 
    "raw_text": "Theoretically, their latent variable formulation has served as a foundation for more robust models of other linguistic phenomena (Brody and Lapata, 2009) .Modern topic models are formulated as a latent variable model", 
    "clean_text": "Theoretically, their latent variable formulation has served as a foundation for more robust models of other linguistic phenomena (Brody and Lapata, 2009).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D11-1091", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kirk, Roberts | Sanda M., Harabagiu", 
    "raw_text": "Tiered clustering is a discrete clustering method, as opposed to methods such as (Brody and Lapata, 2009) that assign a distribution of word senses to each word instance", 
    "clean_text": "Tiered clustering is a discrete clustering method, as opposed to methods such as (Brody and Lapata, 2009) that assign a distribution of word senses to each word instance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P14-1137", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Deyi, Xiong | Min, Zhang", 
    "raw_text": "We set the hyper parameters?= 0.1 and? 0= 1.0 following Lau et al (2012) .We extracted pseudo documents from a? 10-word window centered on the corresponding word token for each word type following Brody and Lapata (2009)", 
    "clean_text": "We extracted pseudo documents from a 10-word window centered on the corresponding word token for each word type following Brody and Lapata (2009).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-2094", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ricardo, Martin-Brualla | Enrique, Alfonseca | Marius, Pa&scedil;ca | Keith, Hall | Enrique, Robledo-Arnuncio | Massimiliano, Ciaramita", 
    "raw_text": "This introduces the complication of choosing the right number of possible senses, hence a Bayesian approach to WSI was proposed which deals with this problem within a principled generative framework (Brody and Lapata, 2009)", 
    "clean_text": "This introduces the complication of choosing the right number of possible senses, hence a Bayesian approach to WSI was proposed which deals with this problem within a principled generative framework (Brody and Lapata, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D11-1097", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Diarmuid, &Oacute; S&eacute;aghdha | Anna, Korhonen", 
    "raw_text": "Topic models have also been applied to other classes of semantic task, for example word sense disambiguation (Li et al., 2010), word sense induction (Brody and Lapata, 2009) and modelling human judgements of semantic association (Griffiths et al, 2007)", 
    "clean_text": "Topic models have also been applied to other classes of semantic task, for example word sense disambiguation (Li et al., 2010), word sense induction (Brody and Lapata, 2009) and modelling human judgements of semantic association (Griffiths et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W10-4173", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zhengyan, He | Yang, Song | Houfeng, Wang", 
    "raw_text": "LDA model has also been applied to WSI (Brody and Lapata, 2009)", 
    "clean_text": "LDA model has also been applied to WSI (Brody and Lapata, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P10-1044", 
    "citing_paper_authority": 44, 
    "citing_paper_authors": "Alan, Ritter | Mausam,  | Oren, Etzioni", 
    "raw_text": "Our particular model, LinkLDA, has been applied to a few NLP tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (Yano et al, 2009), modeling topic-aligned articles in different languages (Mimno et al, 2009), and word sense induction (Brody and Lapata, 2009)", 
    "clean_text": "Our particular model, LinkLDA, has been applied to a few NLP tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (Yano et al, 2009), modeling topic-aligned articles in different languages (Mimno et al, 2009), and word sense induction (Brody and Lapata, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P11-1154", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Jey Han, Lau | Karl, Grieser | David, Newman | Timothy, Baldwin", 
    "raw_text": "It has been demonstrated to be highly effective in a wide range of tasks, including multi document summarisation (Haghighi and Vanderwende, 2009), word sense discrimination (Brody and Lapata, 2009), sentiment analysis (Titov and McDonald, 2008), information retrieval (Wei and Croft, 2006) and image labelling (Feng and Lapata, 2010)", 
    "clean_text": "It has been demonstrated to be highly effective in a wide range of tasks, including multi document summarisation (Haghighi and Vanderwende, 2009), word sense discrimination (Brody and Lapata, 2009), sentiment analysis (Titov and McDonald, 2008), information retrieval (Wei and Croft, 2006) and image labelling (Feng and Lapata, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2069", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jey Han, Lau | David, Newman | Sarvnaz, Karimi | Timothy, Baldwin", 
    "raw_text": "In the short time since its inception, topic modelling (Blei et al, 2003) has become a mainstream technique for tasks as diverse as multi document summarisation (Haghighi and Vanderwende, 2009), word sense discrimination (Brody and Lapata, 2009), sentiment analysis (Titov and McDonald, 2008) and information retrieval (Wei and Croft, 2006)", 
    "clean_text": "In the short time since its inception, topic modelling (Blei et al, 2003) has become a mainstream technique for tasks as diverse as multi document summarisation (Haghighi and Vanderwende, 2009), word sense discrimination (Brody and Lapata, 2009), sentiment analysis (Titov and McDonald, 2008) and information retrieval (Wei and Croft, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-3305", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Keith, Stevens", 
    "raw_text": "Later, Brody and Lapata (2009) combined different feature sets using a probabilistic Word Sense Induction model and found that only some combinations produced an improved system", 
    "clean_text": "Later, Brody and Lapata (2009) combined different feature sets using a probabilistic Word Sense Induction model and found that only some combinations produced an improved system.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-3305", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Keith, Stevens", 
    "raw_text": "We consider three latent models: the SingularValue Decomposition (SVD) (Schu ?tze, 1998), Non negative Matrix Factorization (NMF) (Vande Cruysand Apidianaki, 2011), and Latent Dirichlet Allocation (Brody and Lapata, 2009)", 
    "clean_text": "We consider three latent models: the Singular Value Decomposition (SVD) (Schu?tze, 1998), Non-negative Matrix Factorization (NMF) (Vande Cruysand Apidianaki, 2011), and Latent Dirichlet Allocation (Brody and Lapata, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N10-1012", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "David, Newman | Jey Han, Lau | Karl, Grieser | Timothy, Baldwin", 
    "raw_text": "Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008)", 
    "clean_text": "Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "E12-1060", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Jey Han, Lau | Paul, Cook | Diana, McCarthy | David, Newman | Timothy, Baldwin", 
    "raw_text": "Building on the work of Brody and Lapata (2009) and others, we approach WSI via topic modelling? using La tent Dirichlet Allocation (LDA: Blei et al (2003)) and derivative approaches? and use the topic model to determine the appropriate sense granularity", 
    "clean_text": "Building on the work of Brody and Lapata (2009) and others, we approach WSI via topic modelling - using Latent Dirichlet Allocation (LDA: Blei et al (2003)) and derivative approaches - and use the topic model to determine the appropriate sense granularity.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "E12-1060", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Jey Han, Lau | Paul, Cook | Diana, McCarthy | David, Newman | Timothy, Baldwin", 
    "raw_text": "In the remainder of this section, we refer to Brody and Lapata (2009) as BL, and Yao and Durme (2011) as YVD", 
    "clean_text": "In the remainder of this section, we refer to Brody and Lapata (2009) as BL, and Yao and Durme (2011) as YVD.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D10-1073", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Ioannis P., Klapaftis | Suresh, Manandhar", 
    "raw_text": "In their work, they model the target word instances as samples from amultinomial distribution over senses which are successively characterized as distributions over words (Brody and Lapata, 2009)", 
    "clean_text": "In their work, they model the target word instances as samples from a multinomial distribution over senses which are successively characterized as distributions over words (Brody and Lapata, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D10-1073", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Ioannis P., Klapaftis | Suresh, Manandhar", 
    "raw_text": "Klapaftis& amp; Manandhar (2008) developed agraph-based sense induction method, in which vertices correspond to collocations related to the target word and edges between vertices are drawn ac 753 System Performance (%) HRGs 87.6 (Brody and Lapata, 2009) 87.3 (Niu et al, 2007) 86.8 (Klapaftis and Manandhar, 2008) 86.4 HAC 86.0 CWU 85.1 CWW 84.7 (Pedersen, 2007) 84.5 MFS 80.9 Table 3: HRGs against recent methods& amp ;baselines.cording to the co-occurrence frequency of the corresponding collocations", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W11-1102", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Xuchen, Yao | Benjamin, van Durme", 
    "raw_text": "Results are shown through comparison against Latent Dirich let Allocation (LDA), a parametric Bayesian model employed by Brody and Lapata (2009) for this task", 
    "clean_text": "Results are shown through comparison against Latent Dirichlet Allocation (LDA), a parametric Bayesian model employed by Brody and Lapata (2009) for this task.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W11-1102", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Xuchen, Yao | Benjamin, van Durme", 
    "raw_text": "Brody and Lapata (2009) (B& amp; L herein) showed that the parametric Bayesian model, Latent Dirichlet Allocation (LDA), could be successfully employed for this task, as compared to previous results published for the WSI component of SemEval 20071 (Agirre and Soroa, 2007)", 
    "clean_text": "Brody and Lapata (2009) (B&L herein) showed that the parametric Bayesian model, Latent Dirichlet Allocation (LDA), could be successfully employed for this task, as compared to previous results published for the WSI component of SemEval 2007 (Agirre and Soroa, 2007).", 
    "keep_for_gold": 0
  }
]
