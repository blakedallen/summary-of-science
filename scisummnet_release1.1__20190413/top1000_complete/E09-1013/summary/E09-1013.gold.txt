Bayesian Word Sense Induction
Sense induction seeks to automatically identify word senses directly from a corpus.
A key assumption underlying previous work is that the context surrounding an ambiguous word is indicative of its meaning.
Sense induction is thus typically viewed as an unsupervised clustering problem where the aim is to partition a word's contexts into different classes, each representing a word sense.
Our work places sense induction in a Bayesian context by modeling the contexts of the ambiguous word as samples from a multinomial distribution over senses which are in turn characterized as distributions over words.
The Bayesian framework provides a principled way to incorporate a wide range of features beyond lexical co-occurrences and to systematically assess their utility on the sense induction task.
The proposed approach yields improvements over state-of-the-art systems on a benchmark dataset.
Our latent variable formulation serves as a foundation for more robust models of other linguistic phenomena.
We extract pseudo documents from a 10-word window centered on the corresponding word token for each word type.
We combine different feature sets using a probabilistic Word Sense Induction model and find that only some combinations produced an improved system.
