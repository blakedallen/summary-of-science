[
  {
    "citance_No": 1, 
    "citing_paper_id": "P05-1023", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "James B., Henderson | Ivan, Titov", 
    "raw_text": "(Taskaretal., 2004) suggested a method for maximal margin parsing which employs the dynamic programming approach to decoding and parameter estimation problems", 
    "clean_text": "(Taskar et al., 2004) suggested a method for maximal margin parsing which employs the dynamic programming approach to decoding and parameter estimation problems.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1022", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "David, Hall | Greg, Durrett | Dan, Klein", 
    "raw_text": "Previous work has also used surface features in their parsers, but the focus has been on machine learning methods (Taskar et al, 2004), latent annotations (Petrov and Klein, 2008a; Petrov and Klein, 2008b), or implementation (Finkel et al, 2008)", 
    "clean_text": "Previous work has also used surface features in their parsers, but the focus has been on machine learning methods (Taskar et al, 2004), latent annotations (Petrov and Klein, 2008a; Petrov and Klein, 2008b), or implementation (Finkel et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W06-2936", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Nobuyuki, Shimizu", 
    "raw_text": "Let us define x to be a generic sequence of input tokens together with their POS tags and other morphological features, and y to be a generic dependency structure, that is, a set of edges for x. We use the terminology in (Taskar et al, 2004) for a generic structured output prediction, and define a part", 
    "clean_text": "We use the terminology in (Taskar et al, 2004) for a generic structured output prediction, and define a part.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W06-3603", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "We follow Taskar et al (2004) and Turian and Melamed (2005) in training and testing on? 15word sentences in the English Penn Treebank (Taylor et al, 2003)", 
    "clean_text": "We follow Taskar et al (2004) and Turian and Melamed (2005) in training and testing on? 15word sentences in the English Penn Treebank (Taylor et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W06-3603", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "To situate our results in the literature, we compare our results to those reported by Taskar et al (2004) and Turian and Melamed (2005) for their discriminative parsers, which were also trained and tested on? 15 word sentences", 
    "clean_text": "To situate our results in the literature, we compare our results to those reported by Taskar et al (2004) and Turian and Melamed (2005) for their discriminative parsers, which were also trained and tested on 15 word sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W06-3603", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "% Turian and Melamed (2005) 87.13 86.47 87.80 Bikel (2004) 88.30 87.85 88.75 Taskar et al (2004) 89.12 89.10 89.14 our parser 89.40 89.26 89.55 Table 2 Profile of an NP training iteration, given in seconds, using an AMD Opteron 242 (64-bit, 1.6Ghz)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P07-1080", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "It is expensive to train R P F1 Bikel, 2004 87.9 88.8 88.3 Taskar et al, 2004 89.1 89.1 89.1 NN method 89.1 89.2 89.1 Turian and Melamed, 2006 89.3 89.6 89.4 MF method 89.3 90.7 90.0 Charniak, 2000 90.0 90.2 90.1 Table 1: Percentage labeled constituent recall (R), precision (P), combination of both (F1) on the testing set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P07-1080", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "the MF approximation on the whole WSJ corpus, so instead we use only sentences of length at most 15, as in (Taskar et al, 2004) and (Turian and Melamed, 2006)", 
    "clean_text": "It is expensive to train the MF approximation on the whole WSJ corpus, so instead we use only sentences of length at most 15, as in (Taskar et al, 2004) and (Turian and Melamed, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W05-0407", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Alessandro, Moschitti | Bonaventura, Coppola | Daniele, Pighin | Roberto, Basili", 
    "raw_text": "An other interesting model for parsing re-ranking based on tree kernel is presented in (Taskar et al, 2004)", 
    "clean_text": "An other interesting model for parsing re-ranking based on tree kernel is presented in (Taskar et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W05-0407", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Alessandro, Moschitti | Bonaventura, Coppola | Daniele, Pighin | Roberto, Basili", 
    "raw_text": "A refinement of such technique was presented in (Taskar et al, 2004)", 
    "clean_text": "A refinement of such technique was presented in (Taskar et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W08-2102", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Xavier, Carreras | Michael John, Collins | Terry, Koo", 
    "raw_text": "Taskar et al (2004) describe a max-margin approach; however, in this work training sentences were limited to be of 15 words or less", 
    "clean_text": "Taskar et al (2004) describe a max-margin approach; however, in this work training sentences were limited to be of 15 words or less.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "For example, Taskar et al (2004) took several months to train on the? 15 word sentences in the English Penn Treebank (Dan Klein ,p.c.)", 
    "clean_text": "For example, Taskar et al (2004) took several months to train on the 15 word sentences in the English Penn Treebank (Dan Klein, p.c.).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "We follow Taskar et al (2004) in training and testing on? 15 word sentences in the English Penn Treebank (Taylor et al, 2003)", 
    "clean_text": "We follow Taskar et al (2004) in training and testing on 15 word sentences in the English Penn Treebank (Taylor et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "To situate our results in the literature, we compare our results to those reported by Taskar et al (2004) and Turian and Melamed (2005) for their discriminative parsers, which were also trained and tested on? 15 word sentences", 
    "clean_text": "To situate our results in the literature, we compare our results to those reported by Taskar et al (2004) and Turian and Melamed (2005) for their discriminative parsers, which were also trained and tested on 15 word sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "F1 Turian and Melamed (2005) 86.47 87.80 87.13 Bikel (2004) 87.85 88.75 88.30 Taskar et al (2004) 89.10 89.14 89.12 kitchen sink 89.26 89.55 89.40 parser (Bikel, 2004) 8, the only one that we wereable to train and test under exactly the same experimental conditions (including the use of POStags from the tagger of Ratnaparkhi (1996))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "Collins and Roark (2004) and Taskar et al (2004) beat the generative baseline only after using the standard trick of using the output from a generative model as a feature", 
    "clean_text": "Collins and Roark (2004) and Taskar et al (2004) beat the generative baseline only after using the standard trick of using the output from a generative model as a feature.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D08-1091", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Slav, Petrov | Dan, Klein", 
    "raw_text": "Additionally, we exploit the flexibility of the discriminative framework both to improve the treatment of unknown words as well as to include span features (Taskar et al, 2004), giving the benefit of some input features integrally in our dynamic program", 
    "clean_text": "Additionally, we exploit the flexibility of the discriminative framework both to improve the treatment of unknown words as well as to include span features (Taskar et al, 2004), giving the benefit of some input features integrally in our dynamic program.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D08-1091", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Slav, Petrov | Dan, Klein", 
    "raw_text": "In re ranking, one can incorporate any such features, of course, but even in our dynamic programming approach it is possible to include features that decompose along the dynamic program structure, as shown by Taskar et al (2004)", 
    "clean_text": "In re ranking, one can incorporate any such features, of course, but even in our dynamic programming approach it is possible to include features that decompose along the dynamic program structure, as shown by Taskar et al (2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D08-1091", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Slav, Petrov | Dan, Klein", 
    "raw_text": "We use non-local span features, which condition on properties of input spans (Taskar et al, 2004)", 
    "clean_text": "We use non-local span features, which condition on properties of input spans (Taskar et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D08-1024", 
    "citing_paper_authority": 74, 
    "citing_paper_authors": "David, Chiang | Yuval, Marton | Philip, Resnik", 
    "raw_text": "This is the approach taken by Taskar et al (2004), but their approach assumes that the loss function can be decomposed into local loss functions", 
    "clean_text": "This is the approach taken by Taskar et al (2004), but their approach assumes that the loss function can be decomposed into local loss functions.", 
    "keep_for_gold": 0
  }
]
