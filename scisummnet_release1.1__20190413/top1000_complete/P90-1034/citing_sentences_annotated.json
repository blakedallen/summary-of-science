[
  {
    "citance_No": 1, 
    "citing_paper_id": "C04-1165", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Kyoko, Kanzaki | Eiko, Yamamoto | Qing, Ma | Hitoshi, Isahara", 
    "raw_text": "Hindle (1990) used noun-verb syntactic relations, and Hatzivassiloglou and McKeown (1993) used coordinated adjective-adjective modifier pairs", 
    "clean_text": "Hindle (1990) used noun-verb syntactic relations, and Hatzivassiloglou and McKeown (1993) used coordinated adjective-adjective modifier pairs.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P07-1057", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Samuel, Brody", 
    "raw_text": "Hindle (1990) uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns", 
    "clean_text": "Hindle (1990) uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "C04-1111", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Patrick, Pantel | Deepak, Ravichandran | Eduard, Hovy", 
    "raw_text": "The second class of algorithms uses co occurrence statistics (Hindle 1990, Lin 1998)", 
    "clean_text": "The second class of algorithms uses co occurrence statistics (Hindle 1990, Lin 1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P06-1100", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Marco, Pennacchiotti | Patrick, Pantel", 
    "raw_text": "NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005) ,semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990)", 
    "clean_text": "NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W02-1107", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Kyoko, Kanzaki | Qing, Ma | Masaki, Murata | Hitoshi, Isahara", 
    "raw_text": "To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures (Hindle 1990, Hatzivassiloglou 1993 and Tokunaga 1995), response time to associate synonyms and antonyms in psychological experiments (Gross 1989), or extracting related words automatically from corpora (Grefensette 1994)", 
    "clean_text": "To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures (Hindle 1990, Hatzivassiloglou 1993 and Tokunaga 1995), response time to associate synonyms and antonyms in psychological experiments (Gross 1989), or extracting related words automatically from corpora (Grefensette 1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C04-1036", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Maayan, Zhitomirsky-Geffet | Ido, Dagan", 
    "raw_text": "Distributional Similarity has been an active re search area for more than a decade (Hindle, 1990), (Ruge, 1992), (Grefenstette, 1994), (Lee, 1997), (Lin, 1998), (Dagan et al, 1999), (Weeds and Weir, 2003)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C04-1036", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Maayan, Zhitomirsky-Geffet | Ido, Dagan", 
    "raw_text": "Probably the most widely used association weight function is (point-wise) Mutual Information (MI) (Church et al., 1990), (Hindle, 1990), (Lin, 1998), (Dagan, 2000), defined by:) () (), (log), (2fPwPfwPfwMI= A known weakness of MI is its tendency to assign high weights for rare features", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C04-1116", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Akiko, Murakami | Tetsuya, Nasukawa", 
    "raw_text": "Our method is similar to (Hindle, 1990), (Lin, 1998), and (Gasperin, 2001) in the use of dependency relation ships as the word features", 
    "clean_text": "Our method is similar to (Hindle, 1990), (Lin, 1998), and (Gasperin, 2001) in the use of dependency relationships as the word features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C00-2104", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Barry, Schiffman | Kathleen R., McKeown", 
    "raw_text": "Hindle (1990) classified nouns on the basis of co-occurring patterns of subject verb and verb-object pairs", 
    "clean_text": "Hindle (1990) classified nouns on the basis of co-occurring patterns of subject verb and verb-object pairs.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W04-1216", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Shaojun, Zhao", 
    "raw_text": "For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc. Many methods have been proposed to compute distributional similarity between words ,e.g., (Hindle, 1990), (Pereira et al 1993), (Grefenstette 1994) and (Lin 1998)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N09-3007", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ting, Qian | Benjamin, van Durme | Lenhart K., Schubert", 
    "raw_text": "glish nouns first appeared in Hindle (1990)", 
    "clean_text": "The method of using distributional patterns in a large text corpus to find semantically related English nouns first appeared in Hindle (1990).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P08-2008", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Dmitriy, Dligach | Martha, Palmer", 
    "raw_text": "Hindle (1990) grouped nouns into thesaurus-like lists based on the similarity of their syntactic con texts", 
    "clean_text": "Hindle (1990) grouped nouns into thesaurus-like lists based on the similarity of their syntactic con texts.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P06-1072", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Noah A., Smith | Jason M., Eisner", 
    "raw_text": "The only difference is that we 5See also work on partial parsing as a task in its own right: Hindle (1990) inter alia", 
    "clean_text": "The only difference is that we also work on partial parsing as a task in its own right: Hindle (1990) inter alia.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-1101", 
    "citing_paper_authority": 69, 
    "citing_paper_authors": "Rion, Snow | Daniel, Jurafsky | Andrew Y., Ng", 
    "raw_text": "3.2 (m, n) -cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity ,i.e., the idea that two words with similar meanings will beused in similar contexts (Hindle, 1990)", 
    "clean_text": "The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts (Hindle, 1990).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "E99-1013", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rila, Mandala | Takenobu, Tokunaga | Hozumi, Tanaka", 
    "raw_text": "Our syntactic-relation-based thesaurus i based on the method proposed by Hindle (1990), although Hindle did not apply it to information retrieval", 
    "clean_text": "Our syntactic-relation-based thesaurus is based on the method proposed by Hindle (1990), although Hindle did not apply it to information retrieval.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P98-2127", 
    "citing_paper_authority": 333, 
    "citing_paper_authors": "Dekang, Lin", 
    "raw_text": "When the value of Ilw, r, w &apos; ll is unknown, we assume that A and C are conditionally independent given B. The probability of A, B and C co occurring is estimated by PMLE (B) PMLE (A [B) PMLE (C [B), where PMLE is the maximum likelihood estimation of a probability distribution and P.LE (B)= I I*,*,* l l &apos; P., ~E (AIB)= I I*,~,* l l &apos; P, LE (CIB)= When the value of Hw, r ,w~H is known, we can obtain PMLE (A, B, C) directly: PMLE (A, B, C)= [[w, r ,wll/ [[*,, *H Let I (w, r, w~) denote the amount information contained in Hw, r ,w~]] =c. Its value can be corn769 simgindZe (Wl, W2)=~ &apos;~ (r, w )eTCwl) NTCw2) Are {subj.of.obj-of} min (I (Wl, r, w), I (w2, r, w) )simHindte, (Wl, W2)=~, (r, w )eT (w, )nT (w2) min (I (wl, r, w), I (w2, r, w))] T (Wl) NT (w2) Isimcosine (Wl, W2) =x/IZ (w~) l ?lZ (w2) l 2x IT (wl )nZ (w2) l simDice (Wl, W2) =iT (wl )l+lT (w2) IsimJacard (Wl, W2)= T (wl) OT (w2) l T (wl)+ T (w2) l-IT (Wl )rlT (w2) l Figure 1: Other Similarity Measuresputed as follows: I (w, r, w &apos;)=_ Iog (PMLE (B) PMLE (A] B) PMLE (CIB)) -( -log PMLE (A, B, C)) log IIw, r ,wfl ?ll*, r, *ll- IIw, r, *llxll*, r, w &apos; ll It is worth noting that I (w, r, w &apos;) is equal to the mutual information between w and w &apos; (Hindle, 1990)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P98-2127", 
    "citing_paper_authority": 333, 
    "citing_paper_authors": "Dekang, Lin", 
    "raw_text": "In (Hindle, 1990), a small set of sample results are presented", 
    "clean_text": "In (Hindle, 1990), a small set of sample results are presented.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W12-3201", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Dragomir R., Radev | Amjad, Abu-Jbara", 
    "raw_text": "1990 Hindle (1990) classified nouns on the basis of co-occurring patterns of subject verb and verb-object pairs.", 
    "clean_text": "Hindle (1990) classified nouns on the basis of co-occurring patterns of subject verb and verb-object pairs.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P06-1045", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Masato, Hagiwara | Yasuhiro, Ogawa | Katsuhiko, Toyama", 
    "raw_text": "However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much cons id eration on the language models such as Latent Semantic Indexing (Deerwester et al, 1990) and Probabilistic LSI (Hofmann, 1999) and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition. For example, Hindle (1990) used co occurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information. Lin (1998) also proposed an information theory based similarity metric, using a broad-coverage parser and extracting wider range of grammatical relationship including modifications, but he didn? t further investigate what kind of relationships actually had important contributions to acquisition, either", 
    "clean_text": "For example, Hindle (1990) used co-occurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P06-1015", 
    "citing_paper_authority": 74, 
    "citing_paper_authors": "Patrick, Pantel | Marco, Pennacchiotti", 
    "raw_text": "To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990)", 
    "clean_text": "To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990).", 
    "keep_for_gold": 0
  }
]
