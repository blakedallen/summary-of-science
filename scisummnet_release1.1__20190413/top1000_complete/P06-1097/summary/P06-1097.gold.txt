Semi-Supervised Training For Statistical Word Alignment
We introduce a semi-supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word-alignment quality on a small, manually word-aligned sub-corpus.
We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality.
If human-aligned data is available, the EMD algorithm provides higher baseline alignments than GIZA++ that have led to better MT performance.
We combine a generative model of word alignment with a log-linear discriminative model trained on a small set of hand aligned sentences.
We pose the problem of alignment as a search problem in log-linear space with features coming from the IBM alignment models.
We propose an EMD algorithm for doing word alignment which applies a discriminative step at every iteration of the traditional Expectation-Maximization algorithm used in IBM models.
