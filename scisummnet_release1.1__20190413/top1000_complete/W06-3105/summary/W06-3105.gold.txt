Why Generative Phrase Models Underperform Surface Heuristics
We investigate why weights from generative models underperform heuristic estimates in phrase-based machine translation.
We first propose a simple generative, phrase-based model and verify that its estimates are inferior to those given by surface statistics.
The performance gap stems primarily from the addition of a hidden segmentation variable, which increases the capacity for overfitting during maximum likelihood training with EM.
In particular, while word level models benefit greatly from re-estimation, phrase-level models do not: the crucial difference is that distinct word alignments cannot all be correct, while distinct segmentations can.
Alternate segmentations rather than alternate alignments compete, resulting in increased determinization of the phrase table, decreased generalization, and decreased final BLEU score.
We also show that interpolation of the two methods can result in a modest increase in BLEU score.
We try a different generative phrase translation model analogous to IBM word-translation Model 3 (Brown et al., 1993), and again find that the standard model outperforms their generative model.
We explore estimation using EM of phrase pair probabilities under a conditional translation model based on the original source-channel formulation.
We conclude that segmentation variables in the generative translation model lead to overfitting while attaining higher likelihood of the training data than the heuristic estimator.
