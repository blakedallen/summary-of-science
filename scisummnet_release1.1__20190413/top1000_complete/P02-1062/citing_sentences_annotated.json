[
  {
    "citance_No": 1, 
    "citing_paper_id": "P02-1034", 
    "citing_paper_authority": 111, 
    "citing_paper_authors": "Michael John, Collins | Nigel, Duffy", 
    "raw_text": "We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a))", 
    "clean_text": "We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P02-1034", 
    "citing_paper_authority": 111, 
    "citing_paper_authors": "Michael John, Collins | Nigel, Duffy", 
    "raw_text": "In contrast, the parameter estimation methods in this paper have a strong theoretical basis (see (Cristianini and Shawe-Taylor 2000) chapter 2 and (Freund& amp; Schapire 1999) for statistical theory underlying the perceptron) .For related work on the voted perceptron algorithm applied to NLP problems, see (Collins 2002a) and (Collins 2002b)", 
    "clean_text": "For related work on the voted perceptron algorithm applied to NLP problems, see (Collins 2002a) and (Collins 2002b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P02-1034", 
    "citing_paper_authority": 111, 
    "citing_paper_authors": "Michael John, Collins | Nigel, Duffy", 
    "raw_text": "(Collins 2002a) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels", 
    "clean_text": "(Collins 2002a) describes experiments on the same named-entity dataset as in this paper, but using explicit features rather than kernels.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P02-1034", 
    "citing_paper_authority": 111, 
    "citing_paper_authors": "Michael John, Collins | Nigel, Duffy", 
    "raw_text": "(Collins 2002b) describes how the voted per ceptron can be used to train maximum-entropy style taggers, and also gives a more thorough discussion of the theory behind the perceptron algorithm applied to ranking tasks", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P13-1022", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Reranking using an averaged perceptron (Collins, 2002a) has been successfully applied to a variety of NLP tasks", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "I08-4025", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Dong, Song | Anoop, Sarkar", 
    "raw_text": "The true segmentation can now be compared with the N-best list in order to train an averaged per ceptron algorithm (Collins, 2002a)", 
    "clean_text": "The true segmentation can now be compared with the N-best list in order to train an averaged perceptron algorithm (Collins, 2002a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "I08-4025", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Dong, Song | Anoop, Sarkar", 
    "raw_text": "However, due to the computational issues with the voted perceptron, the averaged per ceptron algorithm (Collins, 2002a) is used instead", 
    "clean_text": "However, due to the computational issues with the voted perceptron, the averaged perceptron algorithm (Collins, 2002a) is used instead.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "I08-4025", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Dong, Song | Anoop, Sarkar", 
    "raw_text": "To reduce the time complexity, we adapted the lazy update proposed in (Collins, 2002b), which was also used in (Zhang and Clark, 2007)", 
    "clean_text": "To reduce the time complexity, we adapted the lazy update proposed in (Collins, 2002b), which was also used in (Zhang and Clark, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N10-1112", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Kevin, Gimpel | Noah A., Smith", 
    "raw_text": "For all objectives, we use the same standard set of feature templates, following Kazama and Torisawa (2007) with additional token shape like those in Collins (2002b) and simple gazetteer features", 
    "clean_text": "For all objectives, we use the same standard set of feature templates, following Kazama and Torisawa (2007) with additional token shape like those in Collins (2002b) and simple gazetteer features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N10-1112", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Kevin, Gimpel | Noah A., Smith", 
    "raw_text": "We compared soft max-margin to several baselines: the structured perceptron (Collins, 2002a), 1-best MIRA with cost-augmented inference (Crammer et al., 2006), CLL, max-margin, risk, and our Jensen risk bound (JRB) introduced above", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W03-0435", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Fien, De Meulder | Walter, Daelemans", 
    "raw_text": "This approach has been used earlier by (Collins, 2002)", 
    "clean_text": "This approach has been used earlier by (Collins, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P09-1032", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Eyal, Beigman | Beata, Beigman Klebanov", 
    "raw_text": "predict correctly the label of a test instance xN+1 is bounded by 2N+1EN+1 [d+D?] 2 where D= D (w,?,?)=?? Ni=1? 2 i. This result is used to explain the convergence of weighted or voted perceptron algorithms (Collins, 2002a)", 
    "clean_text": "This result is used to explain the convergence of weighted or voted perceptron algorithms (Collins, 2002a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "D08-1082", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Wei, Lu | Hwee Tou, Ng | Wee Sun, Lee | Luke, Zettlemoyer", 
    "raw_text": "The detailed algorithm can be found in (Collins, 2002)", 
    "clean_text": "The detailed algorithm can be found in (Collins, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W06-3607", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Heng, Ji | Cynthia, Rudin | Ralph, Grishman", 
    "raw_text": "Collins (2002) augmented a baseline NE tagger with a re-ranker that used only local, NE-oriented features", 
    "clean_text": "Collins (2002) augmented a baseline NE tagger with a re-ranker that used only local, NE-oriented features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "N09-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph P., Turian | James, Bergstra | Yoshua, Bengio", 
    "raw_text": "From Collins (2002)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "N09-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph P., Turian | James, Bergstra | Yoshua, Bengio", 
    "raw_text": "From Collins (2002)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W03-0424", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "James R., Curran | Stephen, Clark", 
    "raw_text": "These gazetteers are used for predicates applied to the current, previous and next word in the window. Collins (2002) includes a number of interesting con textual predicates for NER", 
    "clean_text": "Collins (2002) includes a number of interesting contextual predicates for NER.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W03-0424", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "James R., Curran | Stephen, Clark", 
    "raw_text": "Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes", 
    "clean_text": "Collins (2002) also describes a mapping from words to word types which groups words with similar orthographic forms into classes.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W03-0424", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "James R., Curran | Stephen, Clark", 
    "raw_text": "Our maximum entropy tagger employs Gaussian smoothing which allows a large number of sparse, but informative, features to be used without overfitting. Using a wider context window than 2 words may improve performance; a re ranking phase using global features may also improve performance (Collins, 2002)", 
    "clean_text": "Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "Each shape replaces characters by their types (case sensitive letters, digits, and punctuation), and deletes repeated types ?e.g., Confidence and 2,664,098 are respectively mapped to Aa and 0,0+,0+ (Collins, 2002b)", 
    "clean_text": "Each shape replaces characters by their types (case sensitive letters, digits, and punctuation), and deletes repeated types - e.g., Confidence and 2,664,098 are respectively mapped to Aa and 0,0+,0+ (Collins, 2002b).", 
    "keep_for_gold": 0
  }
]
