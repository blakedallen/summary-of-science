Factored Translation Models
We present an extension of phrase-based statistical machine translation models that enables the straight-forward integration of additional annotation at the word-level - may it be linguistic markup or automatically generated word classes.
In a number of experiments we show that factored translation models lead to better translation performance, both in terms of automatic scores, as well as more grammatical coherence.
Any way to enforce linguistic constraints will result in a reduced need for data, and ultimately in more complete models, given the same amount of data.
We also propose frameworks for the simultaneous use of different word-level representations.
We propose a tight integration of morpho syntactic information into the translation model, where lemma and morphological information are translated separately, and this information is combined on the output side to generate the translation.
We generalise the phrase-based model's representation of the word from a string to a vector, allowing additional features such as part-of-speech and morphology to be associated with, or even to replace, surface forms during search.
Factored translation models facilitate a more data-oriented approach to agreement modeling.
