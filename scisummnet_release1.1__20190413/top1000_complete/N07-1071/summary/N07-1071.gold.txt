ISP: Learning Inferential Selectional Preferences
Semantic inference is a key component for advanced natural language understanding.
However, existing collections of automatically acquired inference rules have shown disappointing results when used in applications such as textual entailment and question answering.
This paper presents ISP, a collection of methods for automatically learning admissible argument values to which an inference rule can be applied, which we call inferential selectional preferences, and methods for filtering out incorrect inferences.
We evaluate ISP and present empirical evidence of its effectiveness.
Context-sensitive extensions of DIRT focus on making DIRT rules context-sensitive by attaching appropriate semantic classes to the X and Y slots of an inference rule.
We build a set of semantic classes using WordNet in one case and CBC clustering algorithm in the other; for each rule, we use the overlap of the fillers found in the input corpus as an indicator of the correct semantic classes.
We augment each relation with its selectional preferences, i.e. fine-grained entity types of two arguments, to handle polysemy.
