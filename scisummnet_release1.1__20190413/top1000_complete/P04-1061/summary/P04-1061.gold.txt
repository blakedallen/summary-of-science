Corpus-Based Induction Of Syntactic Structure: Models Of Dependency And Constituency
We present a generative model for the unsupervised learning of dependency structures.
We also describe the multiplicative combination of this dependency model with a model of linear constituency.
The product model outperforms both components on their respective evaluation metrics, giving the best published figures for unsupervised dependency parsing and unsupervised constituency parsing.
We also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.
Our contributions include the generative Dependency Model with Valence (DMV).
We argue that consistent syntactic representations are desirable in the evaluation of unsupervised syntactic parsers.
