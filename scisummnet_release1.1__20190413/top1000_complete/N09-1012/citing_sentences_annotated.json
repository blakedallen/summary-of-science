[
  {
    "citance_No": 1, 
    "citing_paper_id": "D10-1117", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn", 
    "raw_text": "Headden III et al (2009) showed that performance could be improved by including high frequency words as well as tag sin their model", 
    "clean_text": "Headden III et al (2009) showed that performance could be improved by including high frequency words as well as tags in their model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D10-1117", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn", 
    "raw_text": "The final base distribution over CFG-DMV rules (Psh) is inspired by the skip-head smoothing model of Headden III et al (2009)", 
    "clean_text": "The final base distribution over CFG-DMV rules (Psh) is inspired by the skip-head smoothing model of Headden III et al (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D10-1117", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn", 
    "raw_text": "On the |w|? 10 test set al the TSG-DMVs are second only to the L-EVG model of Headden III et al (2009)", 
    "clean_text": "On the |w| \u2264 10 test set all the TSG-DMVs are second only to the L-EVG model of Headden III et al. (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D10-1117", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn", 
    "raw_text": "Attach-Right 38.4 31.7 EM (Klein and Manning, 2004) 46.1 35.9 Dirichlet (Cohen et al, 2008) 46.1 36.9 LN (Cohen et al, 2008) 59.4 40.5 SLN, TIE V& amp; N (Cohen and Smith, 2009) 61.3 41.4DMV (Headden III et al, 2009) 55.7? =8.0 DMV smoothed (Headden III et al, 2009) 61.2? =1.2 EVG smoothed (Headden III et al, 2009) 65.0? =5.7 L-EVG smoothed (Headden III et al, 2009) 68.8? =4.5 Less is More (Spitkovsky et al, 2010a) 56.2 44.1 Leap Frog (Spitkovsky et al, 2010a) 57.1 45.0 Viterbi EM (Spitkovsky et al, 2010b) 65.3 47.9 Hypertext Markup (Spitkovsky et al, 2010c) 69.3 50.4Adaptor Grammar (Cohen et al, 2010) 50.2 TSG-DMV (Pcfg) 65.9? =2.4 53.1? =2.4 TSG-DMV (Pcfg, Psh) 65.1? =2.2 51.5? =2.0 LexTSG-DMV (Plcfg, Pcfg) 67.2? =1.4 55.2? =2.2 LexTSG-DMV (Plcfg, Pcfg, Psh) 67.7? =1.5 55.7? =2.0 Supervised MLE (Cohen and Smith, 2009) 84.5 68.8Table 4: Mean and variance for the head attachment accuracy of our TSG-DMV models (highlighted) with varying back off paths, and many other high performing models. Citations indicate where the model and result were re ported", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D10-1117", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn", 
    "raw_text": "This graph indicates that the improvements in the posterior probability of the model are correlated with the evaluation, though the correlation is not as high as we might require in order to use LLH as a model selection criteria similar to Headden III et al (2009)", 
    "clean_text": "This graph indicates that the improvements in the posterior probability of the model are correlated with the evaluation, though the correlation is not as high as we might require in order to use LLH as a model selection criteria similar to Headden III et al (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P13-1028", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "David, Mare&#x10D;ek | Milan, Straka", 
    "raw_text": "Headden III et al (2009) introduce the Extended Valence Grammar and add lexicaliza tion and smoothing", 
    "clean_text": "Headden III et al (2009) introduce the Extended Valence Grammar and add lexicalization and smoothing.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D12-1028", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Zden&#x11B;k, &#x17D;abokrtsk&yacute; | David, Mare&#x10D;ek", 
    "raw_text": "In DMV (Klein and Manning, 2004) and in the extended model EVG (Headden III et al2009), there is a STOP sign indicating that no more dependents in a given direction will be generated", 
    "clean_text": "In DMV (Klein and Manning, 2004) and in the extended model EVG (Headden III et al., 2009), there is a STOP sign indicating that no more dependents in a given direction will be generated.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "We follow an approach similar to the widely-referenced DMV model (Klein and Manning, 2004), which forms the basis of the current state-of-the-art unsupervised grammar induction model (Headden III et al, 2009)", 
    "clean_text": "We follow an approach similar to the widely-referenced DMV model (Klein and Manning, 2004), which forms the basis of the current state-of-the-art unsupervised grammar induction model (Headden III et al, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "We find, however, that we outperform PGI by an average margin of 7.2%, demonstrating the benefits of explicit rule specification. An additional point of comparison is the lexi calized unsupervised parser of Headden III et al (2009), which yields the current state-of-the-art unsupervised accuracy on English at 68.8%", 
    "clean_text": "An additional point of comparison is the lexicalized unsupervised parser of Headden III et al (2009), which yields the current state-of-the-art unsupervised accuracy on English at 68.8%.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "3 Headden III et al (2009) 68.8-", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "Note that we do not rely on rule-specific expectation informationas they do, instead requiring only a single expectation constraint parameter.4 Model Stability It is commonly acknowledge din the literature that unsupervised grammar induction methods exhibit sensitivity to initialization. As in the previous section, we find that the pres4As explained in Section 5, having a single expectation parameter is motivated by our focus on parsing with universal rules.ence of linguistic rules greatly reduces this sensitivity: for HDP-DEP, the standard deviation over five randomly initialized runs with the English-specificrules is 1.5%, compared to 4.5% for the parser developed by Headden III et al (2009) and 8.0% for DMV (Klein and Manning, 2004)", 
    "clean_text": "As in the previous section, we find that the presence of linguistic rules greatly reduces this sensitivity: for HDP-DEP, the standard deviation over five randomly initialized runs with the English-specific rules is 1.5%, compared to 4.5% for the parser developed by Headden III et al. (2009) and 8.0% for DMV (Klein and Manning, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "In future work we intend to study ways to bridge this gap by 1) incorporating more sophisticated linguistically-driven gram mar rule sets to guide induction, 2 )lexicalizing the model, and 3) combining our constraint-based approach with richer unsupervised models (e.g., Headden III et al (2009)) to benefit from their complementary strengths", 
    "clean_text": "In future work we intend to study ways to bridge this gap by 1) incorporating more sophisticated linguistically-driven grammar rule sets to guide induction, 2) lexicalizing the model, and 3) combining our constraint-based approach with richer unsupervised models (e.g., Headden III et al (2009)) to benefit from their complementary strengths.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-1911", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "David, Marecek | Zden&#x11B;k, &#x17D;abokrtsk&yacute;", 
    "raw_text": "5In DMV (Klein and Manning, 2004) and in the extended model EVG (Headden III et al, 2009), there is a STOP sign indicating that no more dependents in a given direction will begenerated", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W12-0701", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mohammad Sadegh, Rasooli | Heshaam, Faili", 
    "raw_text": "In Headden III et al (2009), by using the lexical values with the frequency more than 100 and defining tied probabilistic context free grammar (PCFG) and Dirichlet priors, the ac curacy is improved", 
    "clean_text": "In Headden III et al (2009), by using the lexical values with the frequency more than 100 and defining tied probabilistic context free grammar (PCFG) and Dirichlet priors, the accuracy is improved.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P10-2036", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Jennifer, Gillenwater | Kuzman, Ganchev | Jo&atilde;o, Gra&ccedil;a | Fernando, Pereira | Ben, Taskar", 
    "raw_text": "For better comparison with previous work we implemented three model extensions, borrowed from Headden III et al (2009)", 
    "clean_text": "For better comparison with previous work we implemented three model extensions, borrowed from Headden III et al (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P10-2036", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Jennifer, Gillenwater | Kuzman, Ganchev | Jo&atilde;o, Gra&ccedil;a | Fernando, Pereira | Ben, Taskar", 
    "raw_text": "We fix?= 1/3, which is a crude approximation to the value learned by Headden III et al (2009)", 
    "clean_text": "We fix \u03bb = 1/3, which is a crude approximation to the value learned by Headden III et al. (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P10-2036", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Jennifer, Gillenwater | Kuzman, Ganchev | Jo&atilde;o, Gra&ccedil;a | Fernando, Pereira | Ben, Taskar", 
    "raw_text": "Headden III et al (2009) also implement a sort of parameter tying for the E-DMV through a learning a back off distribution on child probabilities", 
    "clean_text": "Headden III et al (2009) also implement a sort of parameter tying for the E-DMV through a learning a back off distribution on child probabilities.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P10-2036", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Jennifer, Gillenwater | Kuzman, Ganchev | Jo&atilde;o, Gra&ccedil;a | Fernando, Pereira | Ben, Taskar", 
    "raw_text": "Rows 2 and 3 are taken from Cohen et al (2008) and Cohen and Smith (2009), and row 5 from Headden III et al (2009)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "N12-1069", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Kevin, Gimpel | Noah A., Smith", 
    "raw_text": "We include selected results on this same test set: Shared LN= Cohen and Smith (2009), L-EVG= Headden III et al (2009), Feature DMV= Berg-Kirkpatrick et al (2010), LexTSG DMV= Blunsom and Cohn (2010), Posterior Reg", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
