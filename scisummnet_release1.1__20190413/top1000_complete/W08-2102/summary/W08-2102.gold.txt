TAG Dynamic Programming and the Perceptron for Efficient Feature-Rich Parsing
We describe a parsing approach that makes use of the perceptron algorithm, in conjunction with dynamic programming methods, to recover full constituent-based parse trees.
The formalism allows a rich set of parse-tree features, including PCFG-based features, bigram and trigram dependency features, and surface features.
A severe challenge in applying such an approach to full syntactic parsing is the efficiency of the parsing algorithms involved.
We show that efficient training is feasible, using a Tree Adjoining Grammar (TAG) based parsing formalism.
A lower-order dependency parsing model is used to restrict the search space of the full model, thereby making it efficient.
Experiments on the Penn WSJ treebank show that the model achieves state-of-the-art performance, for both constituent and dependency accuracy.
Many edges can be ruled out beforehand based on the marginals computed from a simpler parsing model (Carreras et al2008).
