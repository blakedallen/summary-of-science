[
  {
    "citance_No": 1, 
    "citing_paper_id": "P09-1039", 
    "citing_paper_authority": 54, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Eric P., Xing", 
    "raw_text": "For scalability (and noting that some of the models require O (|V|? |A|) constraints and variables, which, when A= V 2, grows cubically with the number of words), we first prune the base graph by running a simple algorithm that ranks thek-best candidate parents for each word in the sentence (we set k= 10); this reduces the number of candidate arcs to |A| =kn.11 This strategy is similar to the one employed by Carreras et al (2008) to prune the search space of the actual parser", 
    "clean_text": "This strategy is similar to the one employed by Carreras et al (2008) to prune the search space of the actual parser.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P13-1104", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Jinho D., Choi | Andrew, McCallum", 
    "raw_text": "The Time column show how many seconds per sentence each parser takes.7 Approach UAS LAS Time Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 0.04 Zhang and Nivre (2011) 92.9 91.8 0.03 Bohnet and Nivre (2012) 93.38 92.44 0.4 McDonald et al (2005) 90.9 Mcdonald and Pereira (2006) 91.5 Sagae and Lavie (2006) 92.7 Koo and Collins (2010) 93.04 Zhang and McDonald (2012) 93.06 91.86 Martins et al (2010) 93.26 Rush et al (2010) 93.8 Koo et al (2008) 93.16 Carreras et al (2008) 93.54 Bohnet and Nivre (2012) 93.67 92.68 Suzuki et al (2009) 93.79bt= 80 ,bd= 80, m= 0.88 92.96 91.93 0.009bt= 80 ,bd= 64, m= 0.88 92.96 91.93 0.009bt= 80 ,bd= 32, m= 0.88 92.96 91.94 0.009bt= 80 ,bd= 16, m= 0.88 92.96 91.94 0.008bt= 80 ,bd= 8, m= 0.88 92.89 91.87 0.006bt= 80 ,bd= 4, m= 0.88 92.76 91.76 0.004bt= 80 ,bd= 2, m= 0.88 92.56 91.54 0.003bt= 80 ,bd= 1, m= 0.88 92.26 91.25 0.002bt= 1 ,bd= 1, m= 0.88 92.06 91.05 0.002Table 4: Parsing accuracies and speeds on the English evaluation set, excluding tokens containing only punctuation", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W12-3412", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph, Le Roux | Benoit, Favre | Alexis, Nasr | Seyed Abolghasem, Mirroshandel", 
    "raw_text": "Thisapproach can be seen as trade-off between phrase based re ranking experiments (Collins, 2000) and the approach of Carreras et al (2008) where a discriminative model is used to score lexical features representing unlabelled dependencies in the Tree Adjoining Grammar formalism", 
    "clean_text": "This approach can be seen as trade-off between phrase based reranking experiments (Collins, 2000) and the approach of Carreras et al (2008) where a discriminative model is used to score lexical features representing unlabelled dependencies in the Tree Adjoining Grammar formalism.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W12-3412", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph, Le Roux | Benoit, Favre | Alexis, Nasr | Seyed Abolghasem, Mirroshandel", 
    "raw_text": "Our system also compares favourably with the system of Carreras et al (2008) that relies on a more complex generative model, namely Tree Adjoining Grammars, and the system of Suzuki et al (2009) that makes use of external data (unannotated text)", 
    "clean_text": "Our system also compares favourably with the system of Carreras et al (2008) that relies on a more complex generative model, namely Tree Adjoining Grammars, and the system of Suzuki et al (2009) that makes use of external data (unannotated text).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C10-1007", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Shane, Bergsma | Colin, Cherry", 
    "raw_text": "Carreras et al (2008) use coarse-to-fine pruning with dependency parsing, but in that case, a graph based dependency parser provides the coarse pass, with the fine pass being a far-more-expensive tree adjoining grammar", 
    "clean_text": "Carreras et al (2008) use coarse-to-fine pruning with dependency parsing, but in that case, a graph based dependency parser provides the coarse pass, with the fine pass being a far-more-expensive tree adjoining grammar.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P12-2001", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Xiao, Chen | Chunyu, Kit", 
    "raw_text": "System F1 (%) EX (%) Single Charniak (2000) 89.70 Berkeley parser 89.87 36.7 Bod (2003) 90.70 Carreras et al (2008) 91.1 Re-scoring Collins (2000) 89.70 Charniak and Johnson (2005) 91.02 The parser of Charniak and Johnson 91.40 43.54 Huang (2008) 91.69 43.5 Combination Fossum and Knight (2009) 92.4 Zhang et al (2009) 92.3 Petrov (2010) 91.85 41.9 Self-training Zhang et al (2009) (s.t.+combo) 92.62 Huang et al (2010) (single) 91.59 40.3 Huang et al (2010) (combo) 92.39 43.1 Our single 91.86 40.89 Our combo 92.80 41.60 Table 4: Performance comparison on the English test settion search algorithm (Kiefer, 1953)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P13-1043", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Muhua, Zhu | Yue, Zhang | Wenliang, Chen | Min, Zhang | Jingbo, Zhu", 
    "raw_text": "2.2? Petrov& amp; Klein (2007) 6.2 Carreras et al (2008) Unk This Paper Baseline 100.7 Baseline+Padding 89.5 Baseline+Padding+Semi 46.8Table 9: Comparison of running times on the English test set, where the time for loading model sis excluded", 
    "clean_text": "2.2? Petrov& amp; Klein (2007) 6.2 Carreras et al (2008) Unk This Paper Baseline 100.7 Baseline+Padding 89.5 Baseline+Padding+Semi 46.8 Table 9: Comparison of running times on the English test set, where the time for loading model sis excluded.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D12-1133", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Bernd, Bohnet | Joakim, Nivre", 
    "raw_text": "The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al (2010) 93.26 Koo et al (2008)? 93.16 Carreras et al (2008)? 93.5 Suzuki et al (2009)? 93.79 Baseline (k= 1) ,b1= 40 89.42 92.79 91.71 97.28 Bestdev setting ,b1= 40 89.75 93.03 91.92 97.40 Adding G ,b1= 40 90.12 93.38 92.44 97.33 Adding G+C ,b1= 80? 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P10-1001", 
    "citing_paper_authority": 64, 
    "citing_paper_authors": "Terry, Koo | Michael John, Collins", 
    "raw_text": "?: see main text. Suzuki et al (2009) and phrase-structure annotations in the case of Carreras et al (2008)", 
    "clean_text": "Suzuki et al (2009) and phrase-structure annotations in the case of Carreras et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "E12-1009", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Bernd, Bohnet | Jonas, Kuhn", 
    "raw_text": "Parser UAS LAS (McDonald et al 2005) 90.9 (McDonald and Pereira, 2006) 91.5 (Huang and Sagae, 2010) 92.1 (Zhang and Nivre, 2011) 92.9 (Koo and Collins, 2010) 93.04 (Martins et al 2010) 93.26 T (baseline) 92.7 G2a (baseline) 92.89 T2a 92.94 91.87 T2ab 93.16 92.08 T2ab3a 93.20 92.10 T2ab3b 93.23 92.15 T2ab3c 93.17 92.10 T2ab3abc+ 93.39 92.38 G2a+ 93.1 (Koo et al 2008)? 93.16 (Carreras et al 2008)? 93.5 (Suzuki et al 2009)? 93.79 Table 2: English Attachment Scores for the Penn2Malt conversion of the Penn Treebank for the test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N10-1003", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Slav, Petrov", 
    "raw_text": "Our model leverages multiple automatically learned latent variable grammars, which differ only in the seed of the random number generator used to initialize the EM learning al Type all sentences Parser LP LR EX ENGLISH-WSJ This Paper 92.0 91.7 41.9 SI N G LE Charniak (2000) 89.9 89.5 37.2 Petrov and Klein (2007) 90.2 90.1 36.7Carreras et al (2008) 91.4 90.7 R E Charniak et al (2005) 91.8 91.2 44.8 Huang (2008) 92.2 91.2 43.5 SE LF Huang and Harper (2009) 91.37 91.57 39.37 McClosky et al (2006) 92.5 92.1 45.3 CO M BO Sagae and Lavie (2006) 93.2 91.0 Fossum and Knight (2009) 93.2 91.7 Zhang et al (2009) 93.3 92.0 ENGLISH-BROWN This Paper 86.5 86.3 35.8 SI N G Charniak (2000) 82.9 82.9 31.7 Petrov and Klein (2007) 83.9 83.8 29.6 R E Charniak et al (2005) 86.1 85.2 36.8 GERMAN This Paper 84.5 84.0 51.2 SI N G Petrov and Klein (2007) 80.0 80.2 42.4 Petrov and Klein (2008) 80.6 80.8 43.9 Table 2: Final test set accuracies for English and German", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D10-1001", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "Alexander M., Rush | David, Sontag | Michael John, Collins | Tommi, Jaakkola", 
    "raw_text": "Over 80% of the examples converge in 5 iterations or fewer; over 90% converge in 10 iterations or fewer. We compare the accuracy of the dual decomposition approach to two baselines: first, Model 1; and second, a naive integration method that enforces the hard constraint that Model 1 must only consider de 11We use a reimplementation that is a slight modification of Collins Model 1, with very similar performance, and which uses the TAG formalism of Carreras et al (2008)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "D12-1106", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Annie, Louis | Ani, Nenkova", 
    "raw_text": "(Carreras et al., 2008) and edge annotation (Huang, 2008)", 
    "clean_text": "(Carreras et al., 2008) and edge annotation (Huang, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D12-1044", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Sampath, Kannan | Emily, Pitler | Mitchell P., Marcus", 
    "raw_text": "Many edges can be ruled out beforehand, either based on the distance in the sentence between the two words (Eisner and Smith, 2010), the predictions of a local ranker (Mar tins et al2009), or the marginals computed from a simpler parsing model (Carreras et al2008)", 
    "clean_text": "Many edges can be ruled out beforehand, either based on the distance in the sentence between the two words (Eisner and Smith, 2010), the predictions of a local ranker (Martins et al2009), or the marginals computed from a simpler parsing model (Carreras et al2008).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D09-1021", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Xavier, Carreras | Michael John, Collins", 
    "raw_text": "The key idea in our approach is to allow highly flexible reordering operations, in combination with a discriminative model that can condition on rich features of the source-language input string. Our approach builds on a variant of tree adjoining grammar (TAG; (Joshi and Schabes, 1997)) (specifically, the formalism of (Carreras et al, 2008))", 
    "clean_text": "The key idea in our approach is to allow highly flexible reordering operations, in combination with a discriminative model that can condition on rich features of the source-language input string. Our approach builds on a variant of tree adjoining grammar (TAG; (Joshi and Schabes, 1997)) (specifically, the formalism of (Carreras et al, 2008)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D09-1021", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Xavier, Carreras | Michael John, Collins", 
    "raw_text": "Our work builds on the variant of tree adjoining grammar (TAG) introduced by (Carreras et al., 2008)", 
    "clean_text": "Our work builds on the variant of tree adjoining grammar (TAG) introduced by (Carreras et al., 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D09-1021", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Xavier, Carreras | Michael John, Collins", 
    "raw_text": "To continue our ex ample, the resulting entry would be as follows: es gibt? S NP there VP is To give a more formal description of how syn tactic structures are derived for phrases, first note that each parse tree t is mapped to a TAGderivation using the method described in (Carreras et al, 2008)", 
    "clean_text": "To continue our example, the resulting entry would be as follows: es gibt? S NP there VP is To give a more formal description of how syn tactic structures are derived for phrases, first note that each parse tree t is mapped to a TAG derivation using the method described in (Carreras et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D10-1002", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Zhongqiang, Huang | Mary P., Harper | Slav, Petrov", 
    "raw_text": "8Our ST-Reg grammars are trained in the same way as in Type Parser LP LR EX S IN G L E Charniak (2000) 89.9 89.5 37.2 Petrov and Klein (2007) 90.2 90.1 36.7Carreras et al (2008) 91.4 90.7 R E Charniak and Johnson (2005) 91.8 91.2 44.8 Huang (2008) 92.2 91.2 43.5 S E L F Huang and Harper (2009) 8 91.6 91.1 40.4 McClosky et al (2006) 92.5 92.1 45.3 C O M B O Petrov (2010) 92.0 91.7 41.9Sagae and Lavie (2006) 93.2 91.0 Fossum and Knight (2009) 93.2 91.7 Zhang et al (2009) 93.3 92.0 This Paper Best Single 91.8 91.4 40.3 Best Product 92.7 92.2 43.1 Table 7: Final test set accuracies on WSJ.Although our models are based on purely generative PCFG grammars, our best product model performs competitively to the self-trained two-step discriminative re ranking parser of McClosky et al (2006), which makes use of many non-local rerank ing features", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
