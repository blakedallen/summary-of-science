[
  {
    "citance_No": 1, 
    "citing_paper_id": "W02-0108", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kalina, Bontcheva | Hamish, Cunningham | Valentin, Tablan | Diana, Maynard | Oana, Hamza", 
    "raw_text": "If evaluated against the requirements for teaching environments discussed in (Loper and Bird, 2002), GATE covers them all quite well", 
    "clean_text": "If evaluated against the requirements for teaching environments discussed in (Loper and Bird, 2002), GATE covers them all quite well.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W02-0108", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kalina, Bontcheva | Hamish, Cunningham | Valentin, Tablan | Diana, Maynard | Oana, Hamza", 
    "raw_text": "However, other such modules ,e.g., those from NLTK (Loperand Bird, 2002), can be used for such assignments", 
    "clean_text": "However, other such modules, e.g., those from NLTK (Loper and Bird, 2002), can be used for such assignments.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P13-1135", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Jason R., Smith | Herv&eacute;, Saint-Amand | Magdalena, Plamada | Philipp, Koehn | Chris, Callison-Burch | Adam, Lopez", 
    "raw_text": "We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk", 
    "clean_text": "We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P06-4018", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Steven, Bird", 
    "raw_text": "NLTK, the Natural Language Toolkit, is a suite of Python modules providing many NLP data types, processing tasks, corpus samples and readers, together with animated algorithms, tutorials, and problem sets (Loper and Bird, 2002)", 
    "clean_text": "NLTK, the Natural Language Toolkit, is a suite of Python modules providing many NLP data types, processing tasks, corpus samples and readers, together with animated algorithms, tutorials, and problem sets (Loper and Bird, 2002).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D10-1005", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jordan, Boyd-Graber | Philip, Resnik", 
    "raw_text": "Note that this does not use the supervised framework 4For English and German documents in all experiments, we removed stop words (Loper and Bird, 2002), stemmed words (Porter and Boulton, 1970), and created a vocabulary of the most frequent 5000 words per language (this vocabulary limit was mostly done to ensure that the dictionary-based bridge was of manageable size)", 
    "clean_text": "For English and German documents in all experiments, we removed stop words (Loper and Bird, 2002), stemmed words (Porter and Boulton, 1970), and created a vocabulary of the most frequent 5000 words per language (this vocabulary limit was mostly done to ensure that the dictionary-based bridge was of manageable size).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W08-0201", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Jason, Baldridge | Katrin, Erk", 
    "raw_text": "We have not yet used the Natural Language Toolkit (Loper and Bird, 2002) (see Section 3.1) in this course", 
    "clean_text": "We have not yet used the Natural Language Toolkit (Loper and Bird, 2002) (see Section 3.1) in this course.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "S12-1102", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Claudia, Becerra | Sergio, Jimenez | Alexander F., Gelbukh", 
    "raw_text": "Finally, all texts were lemmatized using Porter? s stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002)", 
    "clean_text": "Finally, all texts were lemmatized using Porter's stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W11-0505", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Byung-Gyu, Ahn | Benjamin, van Durme | Chris, Callison-Burch", 
    "raw_text": "We strip unnecessary HTML tags and Wiki templates with mwlib5 and split sentences with NLTK (Loper and Bird, 2002)", 
    "clean_text": "We strip unnecessary HTML tags and Wiki templates with mwlib5 and split sentences with NLTK (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W05-0102", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Justine, Cassell | Matthew, Stone", 
    "raw_text": "Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al, 2003) toolkits", 
    "clean_text": "Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al, 2003) toolkits.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W11-1417", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Arthur, Ward | Diane J., Litman | Maxine, Eskenazi", 
    "raw_text": "We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002)", 
    "clean_text": "We use a simple path distance similarity measure, as implemented in NLTK (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D10-1039", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Hugo, Hernault | Danushka, Bollegala | Mitsuru, Ishizuka", 
    "raw_text": "We use three types of features: Word pairs, production rules from the parse tree, as well as features encoding the lexico-syntactic context at the border be tween two units of text (Soricut and Marcu, 2003) .Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002) .Figure 1 shows the parse tree for a sentence composed of two discourse units, which serve as arguments of a discourse relation we want to generate afeature vector from", 
    "clean_text": "Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W08-0208", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Steven, Bird | Ewan, Klein | Edward, Loper | Jason, Baldridge", 
    "raw_text": "The Natural Language Toolkit, or NLTK, was developed to give a broad range of students access to the core knowledge and skills of NLP (Loper and Bird, 2002)", 
    "clean_text": "The Natural Language Toolkit, or NLTK, was developed to give a broad range of students access to the core knowledge and skills of NLP (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P11-1026", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Yuening, Hu | Jordan, Boyd-Graber | Brianna, Satinoff", 
    "raw_text": "Tokenization ,lemmatization, and stop word removal was performed using the Natural Language Toolkit (Loper and Bird, 2002)", 
    "clean_text": "Tokenization ,lemmatization, and stop word removal was performed using the Natural Language Toolkit (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-4019", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Olivier, Blanc | Matthieu, Constant", 
    "raw_text": "Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management.All the operations described below are implemented in C++ independent modules which interact with each others through XML streams", 
    "clean_text": "Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W07-2066", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "George, Dahl | Anne-Marie, Frassica | Richard, Wicentowski", 
    "raw_text": "To identify content words, we used the NLTK-Lite tagger to assign a part of speech to each word (Loper and Bird, 2002)", 
    "clean_text": "To identify content words, we used the NLTK-Lite tagger to assign a part of speech to each word (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W05-0111", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Elizabeth D., Liddy | Nancy J., McCracken", 
    "raw_text": "For the NL processing, the Natural Language Toolkit (NL Toolkit or NLTK), developed at the University of Pennsylvania by Loper and Bird (2002), and available for download from Source Forge at http: //nltk.sourceforge.net/ was used", 
    "clean_text": "For the NL processing, the Natural Language Toolkit (NL Toolkit or NLTK), developed at the University of Pennsylvania by Loper and Bird (2002), and available for download from Source Forge at http: //nltk.sourceforge.net/ was used.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W11-2703", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Charles, Greenbacker | Sandra, Carberry | Kathleen F., McCoy", 
    "raw_text": "The corpus is easily loaded with NLTK (Loper and Bird, 2002) using these Python commands: from nltk.corpus import PlaintextCorpusReader LGSroot= &apos; ./LGSummaryCorpus/summaries &apos; corpus= PlaintextCorpusReader (LGSroot, &apos;.* &apos;) AcknowledgmentsThis work was supported in part by the National Institute on Disability and Rehabilitation Researchunder Grant No", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W05-0101", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Marti A., Hearst", 
    "raw_text": "In the end I decided to require the students to learn python because I wanted to use NLTK, the Natural Language Toolkit (Loper and Bird, 2002)", 
    "clean_text": "In the end I decided to require the students to learn python because I wanted to use NLTK, the Natural Language Toolkit (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "S10-1025", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Richard, Wicentowski | Maria, Kelly | Rachel, Lee", 
    "raw_text": "3.2.1 ResourcesThe SWAT-E system used the English Web1T 5gram corpus (Brants and Franz, 2006), the Spanish section of the Web1T European 5-gram corpus (Brants and Franz, 2009), Roget? s on line thesaurus 1, NLTK? s implementation of the Lancaster Stemmer (Loper and Bird, 2002), Google? s on line English-Spanish dictionary 2, and SpanishDict? s on line dictionary 3. We formed a single Spanish-", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P04-3031", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Steven, Bird | Edward, Loper", 
    "raw_text": "The Natural Language Toolkit (NLTK) was developed in conjunction with a computational linguistics course at the University of Pennsylvania in 2001 (Loper and Bird, 2002)", 
    "clean_text": "The Natural Language Toolkit (NLTK) was developed in conjunction with a computational linguistics course at the University of Pennsylvania in 2001 (Loper and Bird, 2002).", 
    "keep_for_gold": 0
  }
]
