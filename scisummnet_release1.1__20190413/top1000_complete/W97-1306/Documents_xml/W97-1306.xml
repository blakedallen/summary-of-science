<PAPER>
  <S sid="0">CogNIAC: High Precision Coreference With Limited Knowledge And Linguistic Resources</S>
  <ABSTRACT>
    <S sid="1" ssid="1">This paper presents a high precision pronoun resolution system that is capable of greater than 90% precision with 60% and better recall for some pronouns.</S>
    <S sid="2" ssid="2">It is suggested that the system is resolving a sub-set of anaphors that do not require general world knowledge or sophisticated linguistic processing for successful resolution.</S>
    <S sid="3" ssid="3">The system does this by being very sensitive to ambiguity, and only resolving pronouns when very high confidence rules have been satisfied.</S>
    <S sid="4" ssid="4">The system is capable of 'noticing' ambiguity because it requires that there be a unique antecedent within a salience ranking, and the salience rankings are not total orders, i.e. two or more antecedents can be equally salient.</S>
    <S sid="5" ssid="5">Given the nature of the systems rules, it is very likely that they are largely domain independent and that they reflect processing strategies used by humans for general language comprehension.</S>
    <S sid="6" ssid="6">The system has been evaluated in two distinct experiments which support the overall validity of the approach.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction:" number="1">
    <S sid="7" ssid="1">Pronoun resolution is one of the 'classic' computational linguistics problems.</S>
    <S sid="8" ssid="2">It is also widely considered to be inherently an A.I. complete' task-meaning that resolution of pronouns requires full world knowledge and inference.</S>
    <S sid="9" ssid="3">CogNIAC is a pronoun resolution engine designed around the assumption that there is a sub-class of anaphora that does not require general purpose reasoning.</S>
    <S sid="10" ssid="4">The kinds of information CogNIAC does require includes: sentence detection, part-of-speech tagging, simple noun phrase recognition, basic semantic category information like, gender, number, and in one configuration, partial parse trees.</S>
    <S sid="11" ssid="5">What distinguishes CogNIAC from algorithms that use similar sorts of information is that it will not resolve a pronoun in circumstances of ambiguity.</S>
    <S sid="12" ssid="6">Crucially, ambiguity is a function of how much knowledge an understander has.</S>
    <S sid="13" ssid="7">Since CogNIAC does not have as rich a representation of world knowledge as humans, it finds much more ambiguity in texts than humans do.</S>
    <S sid="14" ssid="8">2 A path to high precision pronominal resolution-- avoid guesswork in ambiguous contexts: It is probably safe to say that few referring pronouns are conveyed without the speaker/writer having an antecedent in mind.</S>
    <S sid="15" ssid="9">Ambiguity occurs when the perceiver cannot recover from the context what conveyer has in mind.</S>
    <S sid="16" ssid="10">I have found myself uttering pronouns which the hearer has no chance of recovering the antecedent to because they are not attending to the same part of the external environment, &amp;quot;He sure looks familiar&amp;quot;, or in text I am so focused on the context of what I am writing that use a pronoun to refer to a highly salient concept for me, but the antecedent may completely evade a reader without my familiarity with the topic.</S>
    <S sid="17" ssid="11">Of course it is possible to explicitly leave the reader hanging as in, &amp;quot;Earl and Dave were working together when suddenly he fell into the threshing machine.&amp;quot; Humans, unlike most coreference algorithms, notice such cases of ambiguity and can then ask for clarification or at least grumble about how we cannot climb into the writers head to figure out what they meant.</S>
    <S sid="18" ssid="12">But in that grumble we have articulated the essence of the problem--we don't have sufficient knowledge to satisfy ourselves that an antecedent has been found.</S>
    <S sid="19" ssid="13">Pronoun resolution systems have extremely limited knowledge sources, they cannot access a fraction of human common sense knowledge.</S>
    <S sid="20" ssid="14">To appreciate this consider the following text with grammatical tags replacing words with pronouns and names left in place: The city council VERBGROUP the women NP CC they VB NN Mariana VBD PP Sarah TO VB herself PP DT MD NN Without lexical knowledge a human attempting to resolve the pronouns is in much the knowledge impoverished position of the typical coreference algorithm.</S>
    <S sid="21" ssid="15">It is no surprise that texts with so little information provided in them tend to be more ambiguous than the texts in fleshed out form.</S>
    <S sid="22" ssid="16">The conclusion to draw from this example is that the limiting factor in CogNIAC is knowledge sources, not an artificial restriction on domains or kinds of coreference.</S>
    <S sid="23" ssid="17">This point will be resumed in the discussion section when what the consequences of fuller knowledge sources would be on CogNIAC.</S>
    <S sid="24" ssid="18">For noun phrase anaphora, gathering semantically possible antecedents amounts to running all the noun phrases in a text through various databases for number and gender, and perhaps then a classifier that determines whether a noun phrase is a company, person or place'.</S>
    <S sid="25" ssid="19">This set of candidate antecedents rarely has more than 5 members when some reasonable locality constraints are adhered to, and this set almost always contains the actual antecedent.</S>
    <S sid="26" ssid="20">The remainder of the coreference resolution process amounts to picking the right entity from this set.</S>
    <S sid="27" ssid="21">For the kinds of data considered here (narratives and newspaper articles) there is a rarely a need for general world knowledge in assembling the initial set of possible antecedents for pronouns.</S>
    <S sid="28" ssid="22">This does not address the issue of inferred antecedents, event reference, discourse deixis and many other sorts of referring phenomenon which clearly require the use of world knowledge but are beyond the scope of this work.</S>
    <S sid="29" ssid="23">As it happens, recognizing the possible antecedents of these pronouns is within the capabilities of current knowledge sources.</S>
    <S sid="30" ssid="24">Better knowledge sources could be used to reduce the space of possible antecedents.</S>
    <S sid="31" ssid="25">For example the well known [Winograd 19721 alternation: The city council refused to give the women a permit because they {feared/advocated} violence.</S>
    <S sid="32" ssid="26">There are two semantically possible antecedents to they: The city council, and the women.</S>
    <S sid="33" ssid="27">The problem is picking the correct one.</S>
    <S sid="34" ssid="28">Dependent on verb choice, they strongly prefers one antecedent to the other.</S>
    <S sid="35" ssid="29">Capturing this generalization requires a sophisticated theory of verb meaning as relates to pronoun resolution.</S>
    <S sid="36" ssid="30">Speaking anecdotally, these kinds of resolutions happen quite often in text.</S>
    <S sid="37" ssid="31">CogNIAC recognizes knowledge intensive coreference and does not attempt to resolve such instances.</S>
    <S sid="38" ssid="32">I The named entity task at MUC-6 used a similar classification task and the best system performance was 96% precision/97% recall.</S>
    <S sid="39" ssid="33">Fortunately not all instances of pronominal anaphora require world knowledge for successful resolution.</S>
    <S sid="40" ssid="34">In lieu of full world knowledge, CogNIAC uses regularities of English usage in an attempt to mimic strategies used by humans when resolving pronouns.</S>
    <S sid="41" ssid="35">For example, the syntax of a sentence highly constrains a reflexive pronoun's antecedent.</S>
    <S sid="42" ssid="36">Also if there is just one possible antecedent in entire the prior discourse, then that entity is nearly always the correct antecedent.</S>
    <S sid="43" ssid="37">CogNIAC consists of a set of such observations implemented in Perl.</S>
    <S sid="44" ssid="38">CogNIAC has been used with a range of linguistic resources, ranging from scenarios where almost no linguistic processing of the text is done at all to partial parse trees being provided.</S>
    <S sid="45" ssid="39">At the very least, there must be sufficient linguistic resources to recognize pronouns in the text and the space of candidate antecedents must be identified.</S>
    <S sid="46" ssid="40">For the first experiment the text has been part of speech tagged and basal noun phrases have been identified with 11' (i.e. noun phrases that have no nested noun phrases) as shown below: [ Mariana/NNP ] motioned/VBD for/IN [ Sarah/NNP] to/TO seatNB [herself/PRP ] on/IN [ a/DT twoseater/NN lounge/NN ] In addition, finite clauses were identified (by hand for experiment 1) and various regular expressions are used to identify subjects, objects and what verbs take as arguments for the purposes of coreference restrictions.</S>
    <S sid="47" ssid="41">With this level of linguistic annotation, nearly all the parts of CogNIAC can be used to resolve pronouns.</S>
    <S sid="48" ssid="42">The core rules of CogNIAC are given below, with their performance on training data provided (200 pronouns of narrative text).</S>
    <S sid="49" ssid="43">In addition, examples where the rules successfully apply have been provided for most of the rules with the relevant anaphors and antecedents in boldface.</S>
    <S sid="50" ssid="44">The term 'possible antecedents' refers to the set of entities from the discourse that are compatible with an anaphor's gender, number and coreference restrictions (i.e. non-reflexive pronouns cannot corefer with the other arguments of its verb/preposition etc.)</S>
    <S sid="51" ssid="45">.</S>
    <S sid="52" ssid="46">Mariana motioned for Sarah to seat herself on a two-seater lounge. sentence, then pick i as the antecedent: 114 correct, and 2 incorrect.</S>
    <S sid="53" ssid="47">Rupert Murdock's News Corp. confirmed his interest in buying back the ailing New York Post.</S>
    <S sid="54" ssid="48">But analysts said that if he winds up bidding for the paper,.... possessive pronoun and there is a single exact string match i of the possessive in the prior sentence, then pick i as the antecedent: 4 correct, and 1 incorrect.</S>
    <S sid="55" ssid="49">After he was dry, Joe carefully laid out the damp towel in front of his locker.</S>
    <S sid="56" ssid="50">Travis went over to his locker, took out a towel and started to dry off.</S>
    <S sid="57" ssid="51">5) Unique Current Sentence: If there is a single possible antecedent in the read-in portion of the current sentence, then pick i as the antecedent: 21 correct, and 1 incorrect.</S>
    <S sid="58" ssid="52">Like a large bear, he sat motionlessly in the lounge in one of the faded armchairs, watching Constantin.</S>
    <S sid="59" ssid="53">After a week Constantin tired of reading the old novels in the bottom shelf of the bookcase-somewhere among the gray well thumbed pages he had hoped to find a message from one of his predecessors</S>
  </SECTION>
  <SECTION title="6) Unique Subject/ Subject Pronoun:" number="2">
    <S sid="60" ssid="1">If the subject of the prior sentence contains a single possible antecedent i, and the anaphor is the subject of the current sentence, then pick i as the antecedent: 11 correct, and 0 incorrect.</S>
    <S sid="61" ssid="2">Besides, if he provoked Malek, uncertainties were introduced, of which there were already far too many.</S>
    <S sid="62" ssid="3">He noticed the supervisor enter the lounge ...</S>
    <S sid="63" ssid="4">The method of resolving pronouns within CogNIAC works as follows: Pronouns are resolved left-to-right in the text.</S>
    <S sid="64" ssid="5">For each pronoun, the rules are applied in the presented order.</S>
    <S sid="65" ssid="6">For a given rule, if an antecedent is found, then the appropriate annotations are made to the text and no more rules are tried for that pronoun, otherwise the next rule is tried.</S>
    <S sid="66" ssid="7">If no rules resolve the pronoun, then it is left unresolved.</S>
    <S sid="67" ssid="8">These rules are individually are high precision rules, and collectively they add up to reasonable recall.</S>
    <S sid="68" ssid="9">The precision is 97% (121/125) and the recall is 60% (121/201) for 198 pronouns of training data.</S>
  </SECTION>
  <SECTION title="3 Evaluation:" number="3">
    <S sid="69" ssid="1">The Naive Algorithm [Hobbs 1976] works by specifying a total order on noun phrases in the prior discourse and comparing each noun phrase against the selectional restrictions (i.e. gender, number) of the anaphor, and taking the antecedent to be the first one to satisfy them.</S>
    <S sid="70" ssid="2">The specification of the ordering constitutes a traversal order of the syntax tree of the anaphors clause and from there to embedding clauses and prior clauses.</S>
    <S sid="71" ssid="3">The Winograd sentences, with either verb, would yield the following ordering of possible antecedents: The city council &gt; the women The algorithm would resolve they to The city council.</S>
    <S sid="72" ssid="4">This is incorrect on one choice of verb, but the algorithm does not integrate the verb information into the salience ranking.</S>
    <S sid="73" ssid="5">In comparison, none of the six rules of CogNIAC would resolve the pronoun.</S>
    <S sid="74" ssid="6">Rules have been tried that resolved a subject pronoun of a nested clause with the subject of the dominating clause, but no configuration has been found that yielded sufficient precision2.</S>
    <S sid="75" ssid="7">Consequently, they is not resolved'.</S>
    <S sid="76" ssid="8">The naive algorithm has some interesting properties.</S>
    <S sid="77" ssid="9">First it models relative salience as relative depth in a search space.</S>
    <S sid="78" ssid="10">For two candidate antecedents a and b, if a is encountered before b in the search space, then a is more salient than b.</S>
    <S sid="79" ssid="11">Second, the relative saliency of all candidate antecedents is totally ordered, that is, for any two candidate antecedents a and b , a is more salient than b xor b is more salient than a.</S>
    <S sid="80" ssid="12">2 In experiment 2, discussed below, the rule 'subject same clause' would resolve they to the city council, but it was added to the MUC-6 system without testing, and has shown itself to not be a high precision rule.</S>
    <S sid="81" ssid="13">CogNIAC shares several features of the Naive Algorithm: circumstances of many possible antecedents, and will not resolve pronouns in such cases.</S>
    <S sid="82" ssid="14">The Naive Algorithm has no means of noting ambiguity and will resolve a pronoun as long as there is at least one possible antecedent.</S>
    <S sid="83" ssid="15">Perhaps the most convincing reason to endorse partially ordered salience rankings is that salience distinctions fade as the discourse moves on.</S>
    <S sid="84" ssid="16">Earl was working with Ted the other day.</S>
    <S sid="85" ssid="17">He fell into the threshing machine.</S>
    <S sid="86" ssid="18">Earl was working with Ted the other day.</S>
    <S sid="87" ssid="19">All of the sudden, the cows started making a ruckus.</S>
    <S sid="88" ssid="20">The noise was unbelievable.</S>
    <S sid="89" ssid="21">He fell into the threshing machine.</S>
    <S sid="90" ssid="22">In the first example 'He' takes `Earl' as antecedent, which is what rule 6, Unique Subject/Subject Pronoun, would resolve the pronoun to.</S>
    <S sid="91" ssid="23">However in the second example, the use of `He' is ambiguous--a distinction that existed before is now gone.</S>
    <S sid="92" ssid="24">The Naive Algorithm would still maintain a salience distinction between 'Earl' and `Ted', where CogNIAC has no rule that makes a salience distinction between subject and object of a sentence which has two intervening sentences.</S>
    <S sid="93" ssid="25">The closest rule would be Unique in Discourse, rule 1, which does not yield a unique antecedent.</S>
    <S sid="94" ssid="26">CogNIAC has been evaluated in two different contexts.</S>
    <S sid="95" ssid="27">The goal of the first experiment was to establish relative performance of CogNIAC to Hobbs' Naive Algorithm--a convenient benchmark that allows indirect comparison to other algorithms.</S>
    <S sid="96" ssid="28">The second experiment reports results on Wall Street Journal data.</S>
    <S sid="97" ssid="29">The chosen domain for comparison with Hobbs' Naive Algorithm was narrative texts about two persons of the same gender told from a third person perspective.</S>
    <S sid="98" ssid="30">The motivation for this data was that we wanted to maximize the ambiguity of resolving pronouns.</S>
    <S sid="99" ssid="31">Only singular third person pronouns were considered.</S>
    <S sid="100" ssid="32">The text was pre-processed with a part-of-speech tagger over which basal noun phrases were delimited and finite clauses and their relative nesting were identified by machine.</S>
    <S sid="101" ssid="33">This pre-processing was subjected to hand correction in order to make comparison with Hobbs as fair as possible since that was an entirely hand executed algorithm, but CogNIAC was otherwise machine run and scored.</S>
    <S sid="102" ssid="34">Errors were not chained, i.e. in left-to-right processing of the text, earlier mistakes were corrected before processing the next noun phrase.</S>
    <S sid="103" ssid="35">Since the Naive Algorithm resolves all pronouns, two lower precision rules were added to rules 1-6) for comparisons sake.</S>
    <S sid="104" ssid="36">The rules are: The last two rules are lower precision than the first six, but perform well enough to merit their inclusion in a 'resolve all pronouns' configuration.</S>
    <S sid="105" ssid="37">Rule 7 performed reasonably well with 77% precision in training (10/13 correct for 201 pronouns), and rule 8 performed with 65% precision in training (44/63 correct).</S>
    <S sid="106" ssid="38">The first six rules each had a precision of greater than 90% for the training data with the exception of rule 4 which had a precision of 80% for 5 resolutions.</S>
    <S sid="107" ssid="39">The summary performance of the Naive Algorithm and CogNIAC (including all 8 rules) for the first 100 or so pronouns in three narrative texts are: Results for 298 third person pronouns in text about two same gender people.</S>
    <S sid="108" ssid="40">Since both the Naive Algorithm and the resolve all pronouns configuration of CogNIAC are required to resolve all pronouns, precision and recall figures are not appropriate.</S>
    <S sid="109" ssid="41">Instead % correct figures are given.</S>
    <S sid="110" ssid="42">The high precision version of CogNIAC is reported with recall (number correct/number of instances of coreference) and precision (number correct/number of guesses) measures.</S>
    <S sid="111" ssid="43">The conclusion to draw from these results is: if forced to commit to all anaphors, CogNIAC performs comparably to the Naive Algorithm.</S>
    <S sid="112" ssid="44">Lappin and Leass 3 Rule 7 is based on the primitives of Centering Theory (Grosz, Joshi and Weinstein '86).</S>
    <S sid="113" ssid="45">The Cb of an utterance is the highest ranked NP (Ranking being: Subject &gt; All other NPs) from the prior finite clause realized anaphorically in the current finite clause.</S>
    <S sid="114" ssid="46">Please see Baldwin '95 for a full discussion of the details of the rule.</S>
    <S sid="115" ssid="47">1994 correctly resolved 86% of 360 pronouns in computer manuals.</S>
    <S sid="116" ssid="48">Lapin and Leass run Hobbs' algorithm on the their data and the Naive Algorithm is correct 82% of the time--4% worse.</S>
    <S sid="117" ssid="49">This allows indirect comparison with CogNIAC, with the suggestive conclusion that the resolve all pronouns configuration of CogNIAC, like the Naive Algorithm, is at least in the ballpark of more modern approaches&amp; The breakdown of the individual rules is as follows: Performance of individual rules in Experiment 1.</S>
    <S sid="118" ssid="50">Note the high precision of rules 1 - 6).</S>
    <S sid="119" ssid="51">Recall = #correct/#actual, Precision = #correct/#guessed Far more interesting to consider is the performance of the high precision rules 1 through 6.</S>
    <S sid="120" ssid="52">The first four rules perform quite well at 96% precision (148/154) and 50% recall (148/298).</S>
    <S sid="121" ssid="53">Adding in rules 5 and 6 resolves a total of 190 pronouns correctly, with only 16 mistakes, a precision of 92% and recall of 64%.</S>
    <S sid="122" ssid="54">This contrasts strongly with the resolve-all-pronouns results of 78%.</S>
    <S sid="123" ssid="55">The last two rules, 7 and 8 performed quite badly on the test data.</S>
    <S sid="124" ssid="56">Despite their poor performance, CogNIAC still remained comparable to the Naive Algorithm.</S>
    <S sid="125" ssid="57">3.2.2 Experiment 2-- All pronouns in MUC-6 evaluation: CogNIAC was used as the pronoun component in the University Pennsylvania's coreference entry5 in the MUC-6 evaluation.</S>
    <S sid="126" ssid="58">Pronominal anaphora constitutes 17% of coreference annotations in the evaluation data used.</S>
    <S sid="127" ssid="59">The remaining instances of anaphora included common noun anaphora and coreferent instances of proper nouns.</S>
    <S sid="128" ssid="60">As a result being part of a larger system, changes were made to CogNIAC to make it fit in better with the other components of the overall system in addition to adding rules that were specialized for the new kinds of pronominal anaphora.</S>
    <S sid="129" ssid="61">These changes include: 4 This is not to say that RAP was not an advancement of the state of the art.</S>
    <S sid="130" ssid="62">A significant aspect of that research is that both RAP and the Naive Algorithm were machine executed--the Naive Algorithm was not machine executed in either the Hobbs 76 paper or in the evaluation in this work.</S>
    <S sid="131" ssid="63">A total of thirty articles were used in the formal evaluation, of which I chose the first fifteen for closer analysis.</S>
    <S sid="132" ssid="64">The remaining fifteen were retained for future evaluations.</S>
    <S sid="133" ssid="65">The performance of CogNIAC was as follows: The precision (73%) is quite a bit worse than that encountered in the narrative.</S>
    <S sid="134" ssid="66">The performance of the individual rules was quite different from the narrative texts, as shown in the table below: The results for CogNIAC for all pronouns in the first 15 articles of the MUC-6 evaluation.</S>
    <S sid="135" ssid="67">Upon closer examination approximately 75% of the errors were due to factors outside the scope of the CogNIAC pronominal resolution component.</S>
    <S sid="136" ssid="68">Software problems accounted for 20% of the incorrect cases, another 30% were due to semantic errors like misclassification of a noun phrase into person or company, singular/plural etc.</S>
    <S sid="137" ssid="69">The remaining errors were due to incorrect noun phrase identification, failure to recognize pleonastic-it or other cases where there is no instance of an antecedent.</S>
    <S sid="138" ssid="70">However, 25% of the errors were due directly to the rules of CogNIAC being plain wrong.</S>
  </SECTION>
  <SECTION title="4 Discussion:" number="4">
    <S sid="139" ssid="1">CogNIAC is both an engineering effort and a different approach to information processing in variable knowledge contexts.</S>
    <S sid="140" ssid="2">Each point is addressed in turn.</S>
    <S sid="141" ssid="3">A question raised by a reviewer asked whether there was any use for high precision coreference given that it is not resolving as much coreference as other methods.</S>
    <S sid="142" ssid="4">In the first experiment, the high precision version of CogNIAC correctly resolved 62% of the pronouns as compared to the resolve all pronouns version which resolved 79% of them--a 27% loss of overall recall.</S>
    <S sid="143" ssid="5">The answer to this question quite naturally depends on the application coreference is being used in.</S>
    <S sid="144" ssid="6">Some examples follow.</S>
    <S sid="145" ssid="7">Information retrieval is characterized as a process by which a query is used to retrieve relevant documents from a text database.</S>
    <S sid="146" ssid="8">Queries are typically natural language based or Boolean expressions.</S>
    <S sid="147" ssid="9">Documents are retrieved and ranked for relevance using various string matching techniques with query terms in a document and the highest scoring documents are presented to the user first.</S>
    <S sid="148" ssid="10">The role that coreference resolution might play in information retrieval is that retrieval algorithms that a) count the number of matches to a query term in a document, or b) count the proximity of matches to query terms, would benefit by noticing alternative realizations of the terms like 'he' in place 'George Bush'.</S>
    <S sid="149" ssid="11">In such an application, high precision coreference would be more useful than high recall coreference if the information retrieval engine was returning too many irrelevant documents but getting a reasonable number of relevant documents.</S>
    <S sid="150" ssid="12">The coreference would only help the scores of presumably relevant documents, but at the expense of missing some relevant documents.</S>
    <S sid="151" ssid="13">A higher recall, lower precision algorithm would potentially add more irrelevant documents.</S>
    <S sid="152" ssid="14">A direct application of the &amp;quot;ambiguity noticing&amp;quot; ability of CogNIAC is in checking the coherence of pronoun use in text for children and English as a second language learners.</S>
    <S sid="153" ssid="15">Ambiguous pronoun use is a substantial problem for beginning writers and language learners.</S>
    <S sid="154" ssid="16">CogNIAC could scan texts as they are being written and evaluate whether there was sufficient syntactic support from the context to resolve the pronoun--if not, then the user could be notified of a potentially ambiguous use.</S>
    <S sid="155" ssid="17">It is not clear that CogNIAC's current levels of performance could support such an application, but it is a promising application.</S>
    <S sid="156" ssid="18">Information extraction amounts to filling in template like data structures from free text.</S>
    <S sid="157" ssid="19">Typically the patterns which are used to fill the templates are hand built.</S>
    <S sid="158" ssid="20">The latest MUC-6 evaluation involved management changes at companies.</S>
    <S sid="159" ssid="21">A major problem in information extraction is the fact that the desired information can be spread over many sentences in the text and coreference resolution is essential to relate relevant sentences to the correct individuals, companies etc.</S>
    <S sid="160" ssid="22">The MUC-6 coreference task was developed with the idea that it would aid information extraction technologies.</S>
    <S sid="161" ssid="23">The consequences for an incorrectly resolved pronoun can be devastating to the final template filling task--one runs the risk of conflating information about one individual with another.</S>
    <S sid="162" ssid="24">High precision coreference appears to be a natural candidate for such applications.</S>
    <S sid="163" ssid="25">CogNIAC effectively circumscribes those cases where coreference can be done with high confidence and those cases that require greater world knowledge, but how might CogNIAC be a part of a more knowledge rich coreference application?</S>
    <S sid="164" ssid="26">CogNIAC as a set of seven or so high precision rules would act as an effective filter on what a more knowledge rich application would have to resolve.</S>
    <S sid="165" ssid="27">But the essential component behind CogNIAC is not the rules themselves, but the control structure of behind its coreference resolution algorithm.</S>
    <S sid="166" ssid="28">This control structure could control general inference techniques as well.</S>
    <S sid="167" ssid="29">An interesting way to look at CogNIAC is as a search procedure.</S>
    <S sid="168" ssid="30">The Naive Algorithm can be over simplified as depth first search over parse trees.</S>
    <S sid="169" ssid="31">Depth first search is also a perfectly reasonable control structure for an inference engine-- as it is with PROLOG.</S>
    <S sid="170" ssid="32">The search structure of CogNIAC could be characterized as parallel iterative deepening with solutions being accepted only if a unique solution is found to the depth of the parallel search.</S>
    <S sid="171" ssid="33">But there is not enough room in this paper to explore the general properties of CogNIAC's search and evaluation strategy.</S>
    <S sid="172" ssid="34">Another angle on CogNIAC's role with more robust knowledge sources is to note that the recall limitations of CogNIAC for the class of pronouns/data considered are due to insufficient filtering mechanisms on candidate antecedents.</S>
    <S sid="173" ssid="35">There is not a need to expand the space of candidate antecedents with additional knowledge, but rather eliminate semantically plausible antecedents with constraints from verb knowledge and other sources of constraints currently not available to the system.</S>
    <S sid="174" ssid="36">However, there are classes of coreference that require strong knowledge representation to assemble the initial set of candidate antecedents.</S>
    <S sid="175" ssid="37">This includes the realm of inferred definites &amp;quot;I went to the house and opened the door&amp;quot; and synonymy between definite common nouns as in &amp;quot;the tax' and 'the levy.</S>
    <S sid="176" ssid="38">Hobbs 1976 ultimately rejects the Naive Algorithm as a stand-alone solution to the pronoun resolution problem.</S>
    <S sid="177" ssid="39">In that rejection he states: The naive algorithm does not work.</S>
    <S sid="178" ssid="40">Anyone can think of examples where it fails.</S>
    <S sid="179" ssid="41">In these cases it not only fails; it gives no indication that it has failed and offers no help in finding the real antecedent.</S>
    <S sid="180" ssid="42">Hobbs then articulates a vision of what the appropriate technology is, which entails inference over an encoding of world knowledge.</S>
    <S sid="181" ssid="43">But is world knowledge inherent in resolving all pronouns as Hobbs skepticism seems to convey?</S>
    <S sid="182" ssid="44">It has not been clear up to this point whether any anaphora can be resolved with high confidence given that there are clear examples which can only be resolved with sophisticated world knowledge, e.g. the Winograd city council sentences.</S>
    <S sid="183" ssid="45">But the results from the first and second experiments demonstrate that it is possible to have respectable recall with very high precision (greater than 90%) for some kinds of pronominal resolution.</S>
    <S sid="184" ssid="46">However, good performance does not necessarily falsify Hobbs' skepticism.</S>
    <S sid="185" ssid="47">The high precision component of CogNIAC still makes mistakes, 8-9% error for the first experiment--it is harder to evaluate the second experiment.</S>
    <S sid="186" ssid="48">If it were the case that integration of world knowledge would have prevented those errors, then Hobbs' skepticism still holds since CogNIAC has only minimized the role of world knowledge, not eliminated it.</S>
    <S sid="187" ssid="49">In looking at the mistakes made in the second experiment, there were no examples that appeared to be beyond the scope of further improving the syntactic rules or expanding the basic categorization of noun phrases into person, company or place.</S>
    <S sid="188" ssid="50">For the data considered so far, there does appear to be a class of anaphors that can be reliably recognized and resolved with non-knowledge intensive techniques.</S>
    <S sid="189" ssid="51">Whether this holds in general remains an open question, but it is a central design assumption behind the system.</S>
    <S sid="190" ssid="52">A more satisfying answer to Hobbs' skepticism is contained in the earlier suggestive conjecture that world knowledge facilitates anaphora by eliminating ambiguity.</S>
    <S sid="191" ssid="53">This claim can be advanced to say that world knowledge comes into play in those cases of anaphora that do not fall under the purview of rules 1 through 7 and their refinements.</S>
    <S sid="192" ssid="54">If this is correct, then the introduction of better world knowledge sources will help in the recall of the system rather than the precision.</S>
    <S sid="193" ssid="55">Ultimately, the utility of CogNIAC is a function of how it performs.</S>
    <S sid="194" ssid="56">The high precision rules of CogNIAC performed very well, greater than 90% precision with good recall for the first experiment.</S>
    <S sid="195" ssid="57">In the second experiment, components other than the rules of CogNIAC began to degrade the performance of the system unduly.</S>
    <S sid="196" ssid="58">But there is promise in the high precision core of CogNIAC across varied domains.</S>
  </SECTION>
  <SECTION title="5 The future of CogNIAC:" number="5">
    <S sid="197" ssid="1">CogNIAC is currently the common noun and pronoun resolution component of the University of Pennsylvania's coreference resolution software and general NLP software (Camp).</S>
    <S sid="198" ssid="2">This paper does not address the common noun coreference aspects of the system but there are some interesting parallels with pronominal coreference.</S>
    <S sid="199" ssid="3">Some changes planned include the following sorts of coreference: The processing of split antecedents, John called Mary.</S>
    <S sid="200" ssid="4">They went to a movie.</S>
    <S sid="201" ssid="5">This class of coreference is quite challenging because the plural anaphor 'they' must be able to collect a set of antecedents from the prior discourse--but how far should it look back, and once it has found two antecedents, should it continue to look for more?</S>
    <S sid="202" ssid="6">Event reference is a class of coreference that will also prove to be quite challenging.</S>
    <S sid="203" ssid="7">For example: The computer won the match.</S>
    <S sid="204" ssid="8">It was a great triumph.</S>
    <S sid="205" ssid="9">The antecedent to 'It' could be any of 'The computer', 'the match' or the event of winning.</S>
    <S sid="206" ssid="10">The space of ambiguity will certainly grow substantially when events are considered as candidate antecedents.</S>
    <S sid="207" ssid="11">Currently the system uses no verb semantics to try and constrain possible coreference.</S>
    <S sid="208" ssid="12">While the Winograd sentences are too difficult for current robust lexical semantic systems, simpler generalizations about what can fill an argument are possible, consider: The price of aluminum rose today due to large purchases by ALCOA Inc.</S>
    <S sid="209" ssid="13">It claimed that it was not trying to corner the market.</S>
    <S sid="210" ssid="14">Since 'It' is an argument to 'claimed' , a verb that requires that its subject be animate, we can eliminate 'The price of aluminum' and 'today' from consideration, leaving `ALCOA Inc.' as the sole singular antecedent from the prior sentence.</S>
    <S sid="211" ssid="15">Work has been done along these lines by Dagan '90.</S>
  </SECTION>
  <SECTION title="6 Acknowledgments:" number="6">
    <S sid="212" ssid="1">I would like to thank my advisors Ellen Prince and Aravind Joshi for their support.</S>
    <S sid="213" ssid="2">Also the comments of two anonymous reviewers proved quite helpful.</S>
  </SECTION>
</PAPER>
