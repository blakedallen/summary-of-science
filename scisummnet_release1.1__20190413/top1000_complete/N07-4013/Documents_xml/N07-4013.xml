<PAPER>
  <S sid="0">TextRunner: Open Information Extraction on the Web</S>
  <ABSTRACT/>
  <SECTION title="1 Introduction" number="1">
    <S sid="1" ssid="1">Traditional information extraction systems have focused on satisfying precise, narrow, pre-specified requests from small, homogeneous corpora.</S>
    <S sid="2" ssid="2">In contrast, the TEXTRUNNER system demonstrates a new kind of information extraction, called Open Information Extraction (OIE), in which the system makes a single, data-driven pass over the entire corpus and extracts a large set of relational tuples, without requiring any human input.</S>
    <S sid="3" ssid="3">(Banko et al., 2007) TEXTRUNNER is a fullyimplemented, highly scalable example of OIE.</S>
    <S sid="4" ssid="4">TEXTRUNNER's extractions are indexed, allowing a fast query mechanism.</S>
    <S sid="5" ssid="5">Our first public demonstration of the TEXTRUNNER system shows the results of performing OIE on a set of 117 million web pages.</S>
    <S sid="6" ssid="6">It demonstrates the power of TEXTRUNNER in terms of the raw number of facts it has extracted, as well as its precision using our novel assessment mechanism.</S>
    <S sid="7" ssid="7">And it shows the ability to automatically determine synonymous relations and objects using large sets of extractions.</S>
    <S sid="8" ssid="8">We have built a fast user interface for querying the results.</S>
  </SECTION>
  <SECTION title="2 Previous Work" number="2">
    <S sid="9" ssid="1">The bulk of previous information extraction work uses hand-labeled data or hand-crafted patterns to enable relation-specific extraction (e.g., (Culotta et al., 2006)).</S>
    <S sid="10" ssid="2">OIE seeks to avoid these requirements for human input.</S>
    <S sid="11" ssid="3">Shinyama and Sekine (Shinyama and Sekine, 2006) describe an approach to &#8220;unrestricted relation discovery&#8221; that does away with many of the requirements for human input.</S>
    <S sid="12" ssid="4">However, it requires clustering of the documents used for extraction, and thus scales in quadratic time in the number of documents.</S>
    <S sid="13" ssid="5">It does not scale to the size of the Web.</S>
    <S sid="14" ssid="6">For a full discussion of previous work, please see (Banko et al., 2007), or see (Yates and Etzioni, 2007) for work relating to synonym resolution.</S>
  </SECTION>
  <SECTION title="3 Open IE in TEXTRUNNER" number="3">
    <S sid="15" ssid="1">OIE presents significant new challenges for information extraction systems, including Automation of relation extraction, which in traditional information extraction uses handlabeled inputs.</S>
    <S sid="16" ssid="2">Corpus Heterogeneity on the Web, which makes tools like parsers and named-entity taggers less accurate because the corpus is different from the data used to train the tools.</S>
    <S sid="17" ssid="3">Scalability and efficiency of the system.</S>
    <S sid="18" ssid="4">Open IE systems are effectively restricted to a single, fast pass over the data so that they can scale to huge document collections.</S>
    <S sid="19" ssid="5">In response to these challenges, TEXTRUNNER includes several novel components, which we now summarize (see (Banko et al., 2007) for details).</S>
  </SECTION>
  <SECTION title="1." number="4">
    <S sid="20" ssid="1">The TEXTRUNNER extractor makes a single pass over all documents, tagging sentences with part-of-speech tags and nounphrase chunks as it goes.</S>
    <S sid="21" ssid="2">For each pair of noun phrases that are not too far apart, and subject to several other constraints, it applies a classifier described below to determine whether or not to extract a relationship.</S>
    <S sid="22" ssid="3">If the classifier deems the relationship trustworthy, a tuple of the form t = (ei, rj, ek) is extracted, where ei, ek are entities and rj is the relation between them.</S>
    <S sid="23" ssid="4">For example, TEXTRUNNER might extract the tuple (Edison, invented, light bulbs).</S>
    <S sid="24" ssid="5">On our test corpus (a 9 million document subset of our full corpus), it took less than 68 CPU hours to process the 133 million sentences.</S>
    <S sid="25" ssid="6">The process is easily parallelized, and took only 4 hours to run on our cluster.</S>
  </SECTION>
  <SECTION title="2." number="5">
    <S sid="26" ssid="1">While full parsing is too expensive to apply to the Web, we use a parser to generate training examples for extraction.</S>
    <S sid="27" ssid="2">Using several heuristic constraints, we automatically label a set of parsed sentences as trustworthy or untrustworthy extractions (positive and negative examples, respectively).</S>
    <S sid="28" ssid="3">The classifier is trained on these examples, using features such as the part of speech tags on the words in the relation.</S>
    <S sid="29" ssid="4">The classifier is then able to decide whether a sequence of POS-tagged words is a correct extraction with high accuracy.</S>
  </SECTION>
  <SECTION title="3." number="6">
    <S sid="30" ssid="1">Because TEXTRUNNER has no pre-defined relations, it may extract many different strings representing the same relation.</S>
    <S sid="31" ssid="2">Also, as with all information extraction systems, it can extract multiple names for the same object.</S>
    <S sid="32" ssid="3">The RESOLVER system performs an unsupervised clustering of TEXTRUNNER's extractions to create sets of synonymous entities and relations.</S>
    <S sid="33" ssid="4">RESOLVER uses a novel, unsupervised probabilistic model to determine the probability that any pair of strings is co-referential, given the tuples that each string was extracted with.</S>
    <S sid="34" ssid="5">(Yates and Etzioni, 2007)</S>
  </SECTION>
  <SECTION title="4." number="7">
    <S sid="35" ssid="1">TEXTRUNNER builds an inverted index of the extracted tuples, and spreads it across a cluster of machines.</S>
    <S sid="36" ssid="2">This architecture supports fast, interactive, and powerful relational queries.</S>
    <S sid="37" ssid="3">Users may enter words in a relation or entity, and TEXTRUNNER quickly returns the entire set of extractions matching the query.</S>
    <S sid="38" ssid="4">For example, a query for &#8220;Newton&#8221; will return tuples like (Newton, invented, calculus).</S>
    <S sid="39" ssid="5">Users may opt to query for all tuples matching synonyms of the keyword input, and may also opt to merge all tuples returned by a query into sets of tuples that are deemed synonymous.</S>
  </SECTION>
  <SECTION title="4 Experimental Results" number="8">
    <S sid="40" ssid="1">On our test corpus of 9 million Web documents, TEXTRUNNER extracted 7.8 million well-formed tuples.</S>
    <S sid="41" ssid="2">On a randomly selected subset of 400 tuples, 80.4% were deemed correct by human reviewers.</S>
    <S sid="42" ssid="3">We performed a head-to-head comparison with a state-of-the-art traditional information extraction system, called KNOWITALL.</S>
    <S sid="43" ssid="4">(Etzioni et al., 2005) On a set of ten high-frequency relations, TEXTRUNNER found nearly as many correct extractions as KNOWITALL (11,631 to 11,476), while reducing the error rate of KNOWITALL by 33% (18% to 12%).</S>
  </SECTION>
  <SECTION title="Acknowledgements" number="9">
    <S sid="44" ssid="1">This research was supported in part by NSF grants IIS-0535284 and IIS-0312988, DARPA contract NBCHD030010, ONR grant N0001405-1-0185 as well as gifts from Google, and carried out at the University of Washington&#8217;s Turing Center.</S>
  </SECTION>
</PAPER>
