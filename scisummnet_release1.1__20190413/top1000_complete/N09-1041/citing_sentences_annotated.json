[
  {
    "citance_No": 1, 
    "citing_paper_id": "E12-1022", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jean-Yves, Delort | Enrique, Alfonseca", 
    "raw_text": "In TOPICSUM (Haghighi and Vanderwende, 2009), each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster", 
    "clean_text": "In TOPICSUM (Haghighi and Vanderwende, 2009), each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "E12-1022", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jean-Yves, Delort | Enrique, Alfonseca", 
    "raw_text": "In the context of summarization, this distinction helps to identify the important pieces of information in a collection. Models that use more structure in the rep re sentation of documents have also been proposed for generating more coherent and less redundant summaries, such as HIERSUM (Haghighi and Vanderwende, 2009) and TTM (Celikyilmaz and Hakkani-Tur, 2011)", 
    "clean_text": "Models that use more structure in the representation of documents have also been proposed for generating more coherent and less redundant summaries, such as HIERSUM (Haghighi and Vanderwende, 2009) and TTM (Celikyilmaz and Hakkani-Tur, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "E12-1022", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jean-Yves, Delort | Enrique, Alfonseca", 
    "raw_text": "2In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence", 
    "clean_text": "In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "E12-1022", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jean-Yves, Delort | Enrique, Alfonseca", 
    "raw_text": "Once this is done, one of the learned collections can be used to generate the summary that best approximates this collection, using the greedy algorithm described by Haghighiand Vanderwende (2009)", 
    "clean_text": "Once this is done, one of the learned collections can be used to generate the summary that best approximates this collection, using the greedy algorithm described by Haghighiand Vanderwende (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "E12-1022", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jean-Yves, Delort | Enrique, Alfonseca", 
    "raw_text": "The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over sin 219gle words (unigrams)", 
    "clean_text": "The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over single words (unigrams).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P12-2011", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jean-Yves, Delort | Guillermo, Garrido | Enrique, Alfonseca | Katja, Filippova", 
    "raw_text": "This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization", 
    "clean_text": "This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P11-2086", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Samuel, Brody | Paul B., Kantor", 
    "raw_text": "Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009)", 
    "clean_text": "Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D11-1105", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Peng, Li | Yinglin, Wang | Wei, Gao | Jing, Jiang", 
    "raw_text": "The most relevant work is by (Haghighi and Vanderwende, 2009) on exploring content models for multi-document summarization", 
    "clean_text": "The most relevant work is by (Haghighi and Vanderwende, 2009) on exploring content models for multi-document summarization.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D11-1105", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Peng, Li | Yinglin, Wang | Wei, Gao | Jing, Jiang", 
    "raw_text": "content model proposed by Haghighi and Vanderwende (2009)", 
    "clean_text": "Entity-aspect model is similar with 'HIERSUM' content model proposed by Haghighi and Vanderwende (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D11-1105", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Peng, Li | Yinglin, Wang | Wei, Gao | Jing, Jiang", 
    "raw_text": "proposed by (Haghighi and Vanderwende, 2009)", 
    "clean_text": "In this baseline, we directly compare our method with \"HIERSUM\" proposed by (Haghighi and Vanderwende, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N12-1018", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rebecca, Mason | Eugene, Charniak", 
    "raw_text": "8One could also think of this as a version of the KLSum summarization system (Haghighi and Vanderwende, 2009) that stops after one sentence", 
    "clean_text": "One could also think of this as a version of the KLSum summarization system (Haghighi and Vanderwende, 2009) that stops after one sentence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W11-1605", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Annie, Louis | Ani, Nenkova", 
    "raw_text": "In more recent work, Haghighi and Vanderwende (2009) built a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt", 
    "clean_text": "In more recent work, Haghighi and Vanderwende (2009) built a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "N10-1012", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "David, Newman | Jey Han, Lau | Karl, Grieser | Timothy, Baldwin", 
    "raw_text": "Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008)", 
    "clean_text": "Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P11-1050", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Asli, Celikyilmaz | Dilek, Hakkani-T&uuml;r", 
    "raw_text": "The following models are used as benchmark: (i) PYTHY (Toutanova et al, 2007): Utilizes human generated summaries to train a sentence ranking system using a classifier model; (ii) HIERSUM (Haghighi and Vanderwende, 2009): Based on hierarchical topic models", 
    "clean_text": "The following models are used as benchmark: (i) PYTHY (Toutanova et al, 2007): Utilizes human generated summaries to train a sentence ranking system using a classifier model; (ii) HIERSUM (Haghighi and Vanderwende, 2009): Based on hierarchical topic models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W11-0507", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Rebecca, Mason | Eugene, Charniak", 
    "raw_text": "Haghighi and Vanderwende (2009) demonstrated that these models can improve the quality of generic multi-document summaries oversimpler surface models", 
    "clean_text": "Haghighi and Vanderwende (2009) demonstrated that these models can improve the quality of generic multi-document summaries over simpler surface models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W11-0507", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Rebecca, Mason | Eugene, Charniak", 
    "raw_text": "We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries", 
    "clean_text": "We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W11-0507", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Rebecca, Mason | Eugene, Charniak", 
    "raw_text": "and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009)", 
    "clean_text": "This idea was first presented by Daume and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W11-0507", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Rebecca, Mason | Eugene, Charniak", 
    "raw_text": "We asked users to select which summary was better for the following ques 5Haghighi and Vanderwende (2009) presented a version ofHIERSUM that models documents as a bag of bi grams, and provides results comparable to PYTHY", 
    "clean_text": "Haghighi and Vanderwende (2009) presented a version of HIERSUM that models documents as a bag of bigrams, and provides results comparable to PYTHY.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W11-0507", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Rebecca, Mason | Eugene, Charniak", 
    "raw_text": "These results confirm that our objective noticablyimproves the content of extractive summaries by selecting sentences that contain less document-specific 6These are based on the manual evaluation questions from DUC 2007, and are the same questions asked in Haghighi and Vanderwende (2009)", 
    "clean_text": "These are based on the manual evaluation questions from DUC 2007, and are the same questions asked in Haghighi and Vanderwende (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D10-1007", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Michael, Paul | ChengXiang, Zhai | Roxana, G&icirc;rju", 
    "raw_text": "Such mod els also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009)", 
    "clean_text": "Such models also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009).", 
    "keep_for_gold": 0
  }
]
