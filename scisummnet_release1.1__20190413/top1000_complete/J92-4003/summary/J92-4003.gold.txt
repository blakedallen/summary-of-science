Class-Based N-Gram Models Of Natural Language
We address the problem of predicting a word from previous words in a sample of text.
In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words.
We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics.
We propose a window method introducing the concept of semantic stickiness of two words as the relatively frequent close occurrence between them (less than 500 words distance).
