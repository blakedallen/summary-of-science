First-Order Probabilistic Models for Coreference Resolution
Traditional noun phrase coreference resolution systems represent features only of pairs of noun phrases.
In this paper, we propose a machine learning method that enables features over sets of noun phrases, resulting in a first-order probabilistic model for coreference.
We outline a set of approximations that make this approach practical, and apply our method to the ACE coreference dataset, achieving a 45% error reduction over a comparable method that only considers features of pairs of noun phrases.
This result demonstrates an example of how a first-order logic representation can be incorporated into a probabilistic model and scaled efficiently.
We present a system which uses an online learning approach to train a classifier to judge whether two entities are coreferential or not.
We introduce a first-order probabilistic model which implements features over sets of mentions and thus operates directly on entities.
