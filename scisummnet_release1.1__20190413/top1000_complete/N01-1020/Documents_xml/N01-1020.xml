<PAPER>
  <S sid="0">Multipath Translation Lexicon Induction Via Bridge Languages</S>
  <ABSTRACT>
    <S sid="1" ssid="1">6: Multipath Translation Induction language word), so the system's performance is lower than the Section 3 results.</S>
    <S sid="2" ssid="2">Since all available dictionaries are incomplete, it is difficult to decide which set of English words to compare against.</S>
    <S sid="3" ssid="3">Table 6 presents results for different choices of word coverage: the subset of existing pairs for English-Spanish, the union over all languages, and the intersection of all languages.</S>
    <S sid="4" ssid="4">Trends across subsets are relatively consistent.</S>
    <S sid="5" ssid="5">As an illustration, Table 7 shows consensus formation on English-Norweigian and English-Portuguese translation mappings via multiple bridge languages.</S>
    <S sid="6" ssid="6">Note that the English-French dictionary used here has no entry for &amp;quot;bait&amp;quot;, preventing its use as a bridge language for this word.</S>
    <S sid="7" ssid="7">As can be seen in Table 6, the distance-based combination methods are more successful at combining the different proposals than the rank-N combinations.</S>
    <S sid="8" ssid="8">One possible explanation for this is that rankbased classifiers pick the candidate with the best allaround distance, while distance-based combinations choose the single best candidate.</S>
    <S sid="9" ssid="9">Choosing the best all-around performer is detrimental when cognates exist for some languages but not for others.</S>
    <S sid="10" ssid="10">English Bridge language Bridge Word Target Word Score Rank bay (NORWEGIAN) Danish German Dutch bugt bucht baai bukt bukt baug (bow) bukt 1 1 1 1 25 2 1.5 2.5 distance-based method: bukt 1 1 rank-based method: bukt 27 1 (PORTUGUESE) bait Italian esca isca .5 1 nada (nothing) 3 54 Spanish carnada corneta (trumpet) 2 1 nada 3 12 isca 3.5 153 Romanian nada, nada (nothing) 0.5 1 isca 3.5 153 French N/A N/A N/A N/A distance-based method: isca 0.5 1 nada 0.5 2 rank-based method: nada 67 1 isca 307 20 Table 7: End-to-End Multipath Translation Induction The performance of an oracle, if allowed to choose the correct translation if it appears within the top-N in any language, would provide an upper bound for the performance of the combination methods.</S>
    <S sid="11" ssid="11">Results for such oracles are also reported in Table 6.</S>
    <S sid="12" ssid="12">The methods corresponding to &amp;quot;oracle-1&amp;quot; and &amp;quot;distance&amp;quot; are choosing from the same set of proposed targets, and the &amp;quot;distance&amp;quot; method achieves performance close to that of the oracle (77 vs. 82.8).</S>
    <S sid="13" ssid="13">6 Path Differences This section investigates the effect of different pathway configurations on the performance of the final multi-path system by examining the following situations: &#8226; English to Portuguese, using the other Romance languages as bridges.</S>
    <S sid="14" ssid="14">&#8226; English to Norwegian, using the Germanic languages as bridges.</S>
    <S sid="15" ssid="15">&#8226; English to Ukrainian, using the Slavic languages as bridges.</S>
    <S sid="16" ssid="16">&#8226; Portuguese to English, using the Germanic languages and French as bridges.</S>
    <S sid="17" ssid="17">The results of these experiments are shown in Taen=English, pt=Portuguese, fr=French, it=Italian, es=Spanish, ro=Romanian, du=Dutch, no=Norwegian, de=German, da=Danish, cz=Czech, uk=Ukrainian, po=Polish, sr=Serbian, ru=Russian The data sets used in these experiments were apthe same size as those used in the previous experiment 1100-1300 translation word Dictionaries for Russian and Ukrainian were converted into romanized pronunciation dictionaries.</S>
    <S sid="18" ssid="18">There are three observations which can be made from the multipath results.</S>
    <S sid="19" ssid="19">1.</S>
    <S sid="20" ssid="20">Adding more pathways usually results in an accuracy improvement.</S>
    <S sid="21" ssid="21">When there is a drop in accuracy on the cognate vocabulary by adding an additional bridge language there tends to be an improvement in accuracy on the full vocabulary due to significantly more cognate pathways (yielding greater coverage).</S>
    <S sid="22" ssid="22">2.</S>
    <S sid="23" ssid="23">It is difficult to substantially improve upon the performance of the single closest bridge language, especially when they are as close as enes-pt.</S>
    <S sid="24" ssid="24">Improvements on performance relative to the single best ranged from 2% to 20%.</S>
    <S sid="25" ssid="25">3.</S>
    <S sid="26" ssid="26">Several mediocre pathways can be combined to improve performance.</S>
    <S sid="27" ssid="27">Though it is always better to find one high-performing pathway, it is often possible to get good performance from the combination of several, less well-performing pathways (e.g. en-[sr po]-uk vs. en-ru-uk).</S>
    <S sid="28" ssid="28">In Table 8 &amp;quot;Cvg&amp;quot; or cognate coverage is the percentage words in the source language for which any of the bridge languages contains a cognate to the target translation.</S>
    <S sid="29" ssid="29">Italian and French bridges, for example, offer additional translation pathways to Portuguese which augment the Spanish pathways.</S>
    <S sid="30" ssid="30">Path Accuracy on Full Vocab Accuracy Cvg Cognate Vocab en-es-pt 58.7 86.7 65.5 en-it-pt 44.0 85.4 31.9 en-fr-pt 30.6 74.3 24.8 en-[fr it]-pt 41.2 79.4 42.2 en-[fr it es]-pt 60.2 84.2 70.3 en-da-no 71.9 92.4 75.4 en-du-no 36.1 76.7 39.8 en-de-no 36.1 74.7 38.9 en-[du de]-no 42.3 72.2 54.3 en-[da du de]-no 77.0 87.5 87.4 en-ru-uk 48.8 89.0 44.7 en-po-uk 38.1 87.8 31.9 en-sr-uk 31.9 86.7 30.8 en-[sr po]-uk 45.0 82.0 50.3 en-[ru sr po]-uk 58.4 74.6 71.0 pt-du-en 29.1 69.0 38.4 pt-fr-en 28.1 84.0 24.2 pt-de-en 25.3 68.4 32.1 pt-[de fr]-en 36.5 72.5 48.5 pt-[de fr du]-en 47.0 69.7 66.6 Table 8: Translation Accuracy via Different Bridge Language Paths (using L-A model) Using all languages together improves coverage, although this often does not improve performance over using the best single bridge language.</S>
    <S sid="31" ssid="31">As a final note, Table 9 shows the cross-language translation rates for some of the investigated languages.</S>
    <S sid="32" ssid="32">When translating from English to one of the Romance languages, using Spanish as the bridge language achieves the highest accuracy; and using Russian as the bridge language achieves the best performance when translating from English to the Slavic languages.</S>
    <S sid="33" ssid="33">However, note that using English alone without a bridge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary.</S>
    <S sid="34" ssid="34">7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition.</S>
    <S sid="35" ssid="35">Satta and Henderson (1997) propose a transformation learning method for generic string transduction.</S>
    <S sid="36" ssid="36">Brill and Moore (2000) propose an alternative string distance metric and learning algorithm.</S>
    <S sid="37" ssid="37">While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates.</S>
    <S sid="38" ssid="38">Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names.</S>
    <S sid="39" ssid="39">Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates.</S>
    <S sid="40" ssid="40">Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak).</S>
    <S sid="41" ssid="41">Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison.</S>
    <S sid="42" ssid="42">Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998).</S>
    <S sid="43" ssid="43">While restricted to single language transliteration, it very effectively used intermediary phonological models to bridge direct lexical borrowing across distant languages.</S>
    <S sid="44" ssid="44">8 Conclusion The experiments reported in this paper extend prior research in a number of directions.</S>
    <S sid="45" ssid="45">The novel probabilistic paradigm for inducing translation lexicons for words from unaligned word lists is introduced.</S>
    <S sid="46" ssid="46">The set of languages on which we demonstrate these methods is broader than previously examined.</S>
    <S sid="47" ssid="47">Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.</S>
    <S sid="48" ssid="48">There are a number of open questions.</S>
    <S sid="49" ssid="49">The first is whether there exists a better string transformation algorithm to use in the induction step.</S>
    <S sid="50" ssid="50">One possible area of investigation is to use larger dictionaries and assess how much better stochastic transducers, and distance metrics derived from them, perform with more training data.</S>
    <S sid="51" ssid="51">Another option is to investigate the use of multi-vowel or multi-consonant compounds which better reflect the underlying phonetic units, using an more sophisticated edit distance measure.</S>
    <S sid="52" ssid="52">In this paper, we explore ways of using cognate pairs to create translation lexicons.</S>
    <S sid="53" ssid="53">It is an interesting research question as to whether we can augment these methods with translation probabilities estimated from statistical frequency information gleaned from loosely aligned or unaligned bilingual corpora for non-cognate pairs.</S>
    <S sid="54" ssid="54">Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates.</S>
    <S sid="55" ssid="55">The techniques presented here are useful for language pairs where an on-line translation lexicon does not already exist, including the large majority of the world's lower-density languages.</S>
    <S sid="56" ssid="56">For language pairs with existing translation lexicons, these methods can help improve coverage, especially for technical vocabulary and other more recent borrowings which are often cognate but frequently missing from existing dictionaries.</S>
    <S sid="57" ssid="57">In both cases, the great potential of English -x Romance Accuracy on Cognate Vocab (35-68%) TL Bridge Language pt it es fr ro 0 pt (100) 85.6 86.7 74.3 72.1 79.4 it 83.7 (100) 85.1 75.5 82.1 78.0 es 85.8 84.0 (100) 78.1 82.1 79.3 fr 73.9 75.5 76.7 (100) 75.2 78.7 ro 72.8 84.4 82.8 76.1 (100) 78.3 av 78.2 82.0 82.2 75.7 77.7 78.4 English -x Romance Accuracy on Full Vocab TL Bridge Language pt it es fr ro 0 pt (100) 42.6 58.7 29.8 28.4 23.1 it 42.0 (100) 45.6 33.8 34.8 21.3 es 57.5 44.3 (100) 31.8 29.7 22.5 fr 30.7 35.2 32.7 (100) 33.3 24.9 ro 28.5 35.7 30.5 35.0 (100) 23.9 av 39.2 39.0 41.2 32.0 31.0 22.6 English -x Slavic Accuracy on Cognate Vocab TL Bridge Language cz ru pl sr uk 0 cz (100) 70.3 81.4 81.0 81.4 75.0 ru 72.7 (100) 84.1 80.3 87.3 73.9 pl 81.2 85.7 (100) 84.5 88.2 78.2 sr 85.7 82.9 85.8 (100) 85.5 76.7 uk 83.6 89.1 87.9 86.0 (100) 73.9 av 80.2 81.5 84.2 82.7 85.2 75 English -x Slavic Accuracy on Full Vocab TL Bridge Language cz ru pl sr uk 0 cz (100) 20.5 25.5 27.3 25.4 12.0 ru 23.3 (100) 29.9 27.3 47.1 13.4 pl 27.6 30.3 (100) 27.8 36.8 15.0 sr 31.0 29.6 29.4 (100) 33.1 18.5 uk 27.0 48.7 38.0 31.4 (100) 15.7 av 27 31.7 30.2 28 35.2 14.6 Table 9: Accuracy of English to TL (Target Language) via One Bridge Language (using L-A model) (0 = direct mapping no bridge) this work is the ability to leverage a single bilingual dictionary into translation lexicons for its entire language family, without any additional resources beyond raw wordlists for the other languages in the family.</S>
    <S sid="58" ssid="58">9 Acknowledgements The authors would like to thank the following people for their insightful comments and feedback on drafts of this work: Radu Florian, Jan Hajie, Ellen Riloff, Charles Schafer, and Richard Wicentowski.</S>
    <S sid="59" ssid="59">Thanks also to the Johns Hopkins NLP lab in general for the productive and stimulating environment.</S>
    <S sid="60" ssid="60">References E. Brill and R. Moore.</S>
    <S sid="61" ssid="61">2000.</S>
    <S sid="62" ssid="62">An improved errorfor noisy channel spelling correction.</S>
    <S sid="63" ssid="63">ACL, 286-293.</S>
    <S sid="64" ssid="64">P.F.</S>
    <S sid="65" ssid="65">Brown, S.A. Della Pietra, V.J.</S>
    <S sid="66" ssid="66">Della Pietra, and R. Mercer.</S>
    <S sid="67" ssid="67">1993.</S>
    <S sid="68" ssid="68">The mathematics of statistical translation.</S>
    <S sid="69" ssid="69">Linguistics, 19(2):263-311.</S>
    <S sid="70" ssid="70">Buck.</S>
    <S sid="71" ssid="71">1949.</S>
    <S sid="72" ssid="72">A of Selected Synonyms in the Principal Indo-European Languages.</S>
    <S sid="73" ssid="73">Chicago:University of Chicago Press.</S>
    <S sid="74" ssid="74">H-H. Chen, S-J.</S>
    <S sid="75" ssid="75">Huang, Y-W. Ding, and S-C. Tsai.</S>
    <S sid="76" ssid="76">1998.</S>
    <S sid="77" ssid="77">Proper name translation in cross-language retrieval. of ACL/COLING, pages 232-236.</S>
    <S sid="78" ssid="78">Chen.</S>
    <S sid="79" ssid="79">1993.</S>
    <S sid="80" ssid="80">Aligning sentences in bilingual corusing lexical information. of ACL, pages 9-16.</S>
    <S sid="81" ssid="81">M. Covington.</S>
    <S sid="82" ssid="82">1998.</S>
    <S sid="83" ssid="83">Aligning multiple languages historical comparison. of COLING- 275-280.</S>
    <S sid="84" ssid="84">J. Hajie, J. Hric, and V. Kubori.</S>
    <S sid="85" ssid="85">2000.</S>
    <S sid="86" ssid="86">Cesilko : Machine translation between closely related lanof ANLP, 7-12.</S>
    <S sid="87" ssid="87">Jelinek.</S>
    <S sid="88" ssid="88">1997.</S>
    <S sid="89" ssid="89">Methods for Speech Press.</S>
    <S sid="90" ssid="90">Z. Kirshner.</S>
    <S sid="91" ssid="91">1982.</S>
    <S sid="92" ssid="92">A dependency based analysis of english for the purpose of machine translation.</S>
    <S sid="93" ssid="93">Explizite Beschreibung der Sprache und automa- Textbearbeitung, Knight and J. Graehl.</S>
    <S sid="94" ssid="94">1998.</S>
    <S sid="95" ssid="95">Machine transliter- Linguistics, E. Ristad and P. Yianilos.</S>
    <S sid="96" ssid="96">1998.</S>
    <S sid="97" ssid="97">Learning string distance.</S>
    <S sid="98" ssid="98">Trans.</S>
    <S sid="99" ssid="99">PAMI, G. Satta and J. Henderson.</S>
    <S sid="100" ssid="100">1997.</S>
    <S sid="101" ssid="101">String transforlearning. of ACL/EACL, 444- 451.</S>
    <S sid="102" ssid="102">M. Simard, G.F. Foster, and P. Isabelle.</S>
    <S sid="103" ssid="103">1992.</S>
    <S sid="104" ssid="104">Using cognates to align sentences in bilingual corpora.</S>
  </ABSTRACT>
  <SECTION title="" number="1">
    <S sid="105" ssid="1">within an edit-distance of 3) from the remaining word-pairs as training data.</S>
    <S sid="106" ssid="2">Train on those pairs.</S>
    <S sid="107" ssid="3">For this set of experiments, Portuguese was chosen as the target language and Spanish, French, Italian and Romanian the source languages (Figure 2).</S>
    <S sid="108" ssid="4">The Spanish-Portuguese dictionary contained 1000 word pairs, while the others contained 900 pairs.</S>
    <S sid="109" ssid="5">10(9)fold cross-validation experiments were performed in each case.</S>
    <S sid="110" ssid="6">The number of training pairs for the adaptive methods which remained after filtering out unlikely cognate pairs ranged from 621 (for Spanish) to 232 (for Romanian).</S>
    <S sid="111" ssid="7">For the purpose of evaluation, we constrained the candidate test set to have exactly one translation per source word.</S>
    <S sid="112" ssid="8">However, this property was not used to improve candidate alignment (e.g. via the pigeonhole principle).</S>
    <S sid="113" ssid="9">Table 1 shows results for different candidate distance functions for Spanish-Portuguese and FrenchPortuguese translation induction.</S>
    <S sid="114" ssid="10">The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.</S>
    <S sid="115" ssid="11">The other three methods are variants of Levenshtein distance where the costs for edit operations have been modified.</S>
    <S sid="116" ssid="12">In L-V, the substitution operations between vowels are changed from 1 to 0.5.</S>
    <S sid="117" ssid="13">Two adaptively trained variants, L-S and L-A, are shown in the last two lines of Table 1.</S>
    <S sid="118" ssid="14">The weights in these two systems were produced by filtering the probabilities obtained from the stochastic transducer into three weight classes: 0.5, 0.75, and 1.</S>
    <S sid="119" ssid="15">Identity substitutions were assigned a cost of zero.</S>
    <S sid="120" ssid="16">For L-S, the cost matrix was separately trained for each language pair, and for L-A, it was trained collectively over all the Romance languages.</S>
    <S sid="121" ssid="17">Table 2 shows some of the highest probability consonant-to-consonant edit operations computed by the stochastic transducer (S).</S>
    <S sid="122" ssid="18">Most of these topranking derived transformations have been observed to be relatively low distance by either linguistic analysis of historical sound changes or by phonological classification, notably: nasal sonorants (&amp;quot;n&amp;quot; , unvoiced stops (&amp;quot;p&amp;quot;, &amp;quot;f&amp;quot;), and voiced stops (&amp;quot;c&amp;quot;, &amp;quot;g&amp;quot;, &amp;quot;t&amp;quot;, &amp;quot;d&amp;quot;).</S>
    <S sid="123" ssid="19">Other pairs are derivationally reasonable: (&amp;quot;b&amp;quot; , &amp;quot;v&amp;quot;), (&amp;quot;x&amp;quot; , &amp;quot;s&amp;quot;) and (&amp;quot;s&amp;quot; , &amp;quot;c&amp;quot;); while some may be noise: (&amp;quot;g&amp;quot;, &amp;quot;n&amp;quot;) and (&amp;quot;g&amp;quot;, &amp;quot;v&amp;quot;).</S>
    <S sid="124" ssid="20">Not shown are vowel-to-vowel substitutions which in general were the most highly ranked; also not shown are tight correspondences between accented and unaccented vowel variants which were also learned by the stochastic transducer.</S>
    <S sid="125" ssid="21">As can be observed from Table 1, pure Levenshtein distance (L) works surprisingly well.</S>
    <S sid="126" ssid="22">Dynamic adaptation via the stochastic transducers (S) also gives a notable boost on French-Portuguese (increasing cognate accuracy from 66% to 79%) but offer little improvement for Spanish-Portuguese (perhaps because pure Levenshtein needs no diffusion for relatively close languages while more complex mappings benefit from training).</S>
    <S sid="127" ssid="23">Similarly, a slight improvment is observed for Romanian-Portuguese under S, but no improvement for Italian-Portuguese.</S>
    <S sid="128" ssid="24">Also, empirical evidence suggests that the best method is achieved through learning weights with stochastic transducers and then using these weights in the L-S framework. for each word o E 0 for each bridge language B Translate o b E B Vt E T, Calculate D(b,t) Rank t by D(b,t) Score t using information from all bridges Select highest scored t Produce mapping o t Two scoring methods were investigated for the above algorithm: one based on rank and the other on distance.</S>
    <S sid="129" ssid="25">The rank-based scoring method takes each proposed target and combines the rank of that proposal across all classifiers, and chooses the translation with the lowest resulting rank (rank 1 is the best proposed translation).</S>
    <S sid="130" ssid="26">Since including all the hypothesized translations regardless of ranking performed poorly, we only include the ones with a ranking lower than some threshold N. The distance-based scoring method selects the hypothesized target word with the smallest distance from a translation in any of the bridge languages.</S>
    <S sid="131" ssid="27">We also tested one alternative dist-rank which uses ranks (as described above) to break ties in the distance-based method, with similar performance.</S>
    <S sid="132" ssid="28">In Table 6, we present the results obtained by applying different combination algorithms for the pathway from English to Portuguese using one of the other Romance languages (Spanish, Italian, French, and Romanian) as bridges and compare with the single best path (English-Spanish-Portuguese).</S>
    <S sid="133" ssid="29">These results are presented for unrestricted matching on the full dictionary lexicon (1097 words in each language)2.</S>
    <S sid="134" ssid="30">This is a more difficult task than that used for direct induction (selecting between 100 and 900 potential translation candidates for each sourcelanguage word), so the system's performance is lower than the Section 3 results.</S>
    <S sid="135" ssid="31">Since all available dictionaries are incomplete, it is difficult to decide which set of English words to compare against.</S>
    <S sid="136" ssid="32">Table 6 presents results for different choices of word coverage: the subset of existing pairs for English-Spanish, the union over all languages, and the intersection of all languages.</S>
    <S sid="137" ssid="33">Trends across subsets are relatively consistent.</S>
    <S sid="138" ssid="34">As an illustration, Table 7 shows consensus formation on English-Norweigian and English-Portuguese translation mappings via multiple bridge languages.</S>
    <S sid="139" ssid="35">Note that the English-French dictionary used here has no entry for &amp;quot;bait&amp;quot;, preventing its use as a bridge language for this word.</S>
    <S sid="140" ssid="36">As can be seen in Table 6, the distance-based combination methods are more successful at combining the different proposals than the rank-N combinations.</S>
    <S sid="141" ssid="37">One possible explanation for this is that rankbased classifiers pick the candidate with the best allaround distance, while distance-based combinations choose the single best candidate.</S>
    <S sid="142" ssid="38">Choosing the best all-around performer is detrimental when cognates exist for some languages but not for others.</S>
    <S sid="143" ssid="39">The performance of an oracle, if allowed to choose the correct translation if it appears within the top-N in any language, would provide an upper bound for the performance of the combination methods.</S>
    <S sid="144" ssid="40">Results for such oracles are also reported in Table 6.</S>
    <S sid="145" ssid="41">The methods corresponding to &amp;quot;oracle-1&amp;quot; and &amp;quot;distance&amp;quot; are choosing from the same set of proposed targets, and the &amp;quot;distance&amp;quot; method achieves performance close to that of the oracle (77 vs. 82.8).</S>
  </SECTION>
  <SECTION title="6 Path Differences" number="2">
    <S sid="146" ssid="1">This section investigates the effect of different pathway configurations on the performance of the final multi-path system by examining the following situations: The results of these experiments are shown in Table 8.3 3Key: en=English, pt=Portuguese, fr=French, it=Italian, es=Spanish, ro=Romanian, du=Dutch, no=Norwegian, de=German, da=Danish, cz=Czech, uk=Ukrainian, po=Polish, sr=Serbian, ru=Russian The data sets used in these experiments were approximately the same size as those used in the previous experiment 1100-1300 translation word pairs.</S>
    <S sid="147" ssid="2">Dictionaries for Russian and Ukrainian were converted into romanized pronunciation dictionaries.</S>
    <S sid="148" ssid="3">There are three observations which can be made from the multipath results.</S>
    <S sid="149" ssid="4">In Table 8 &amp;quot;Cvg&amp;quot; or cognate coverage is the percentage words in the source language for which any of the bridge languages contains a cognate to the target translation.</S>
    <S sid="150" ssid="5">Italian and French bridges, for example, offer additional translation pathways to Portuguese which augment the Spanish pathways.</S>
    <S sid="151" ssid="6">Using all languages together improves coverage, although this often does not improve performance over using the best single bridge language.</S>
    <S sid="152" ssid="7">As a final note, Table 9 shows the cross-language translation rates for some of the investigated languages.</S>
    <S sid="153" ssid="8">When translating from English to one of the Romance languages, using Spanish as the bridge language achieves the highest accuracy; and using Russian as the bridge language achieves the best performance when translating from English to the Slavic languages.</S>
    <S sid="154" ssid="9">However, note that using English alone without a bridge language when translating to the Romance languages still achieves reasonable performance, due to the substantial French and Latinate presence in English vocabulary.</S>
  </SECTION>
  <SECTION title="7 Related Work" number="3">
    <S sid="155" ssid="1">Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition.</S>
    <S sid="156" ssid="2">Satta and Henderson (1997) propose a transformation learning method for generic string transduction.</S>
    <S sid="157" ssid="3">Brill and Moore (2000) propose an alternative string distance metric and learning algorithm.</S>
    <S sid="158" ssid="4">While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates.</S>
    <S sid="159" ssid="5">Other methods have been demonstrated for building bilingual dictionaries using simple heuristic rules includes Kirschner (1982) for English/Czech dictionaries and Chen (1998) for Chinese/English proper names.</S>
    <S sid="160" ssid="6">Tiedemann (1999) improves on these alignment seedings by learning all-or-nothing rules for detecting Swedish/English cognates.</S>
    <S sid="161" ssid="7">Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak).</S>
    <S sid="162" ssid="8">Covington (1998) uses an algorithm based on heuristic orthographic changes to find cognate words for purposes of historical comparison.</S>
    <S sid="163" ssid="9">Perhaps the most comprehensive study of word alignment via string transduction methods was pioneered by Knight and Graehl (1998).</S>
    <S sid="164" ssid="10">While restricted to single language transliteration, it very effectively used intermediary phonological models to bridge direct lexical borrowing across distant languages.</S>
  </SECTION>
  <SECTION title="8 Conclusion" number="4">
    <S sid="165" ssid="1">The experiments reported in this paper extend prior research in a number of directions.</S>
    <S sid="166" ssid="2">The novel probabilistic paradigm for inducing translation lexicons for words from unaligned word lists is introduced.</S>
    <S sid="167" ssid="3">The set of languages on which we demonstrate these methods is broader than previously examined.</S>
    <S sid="168" ssid="4">Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.</S>
    <S sid="169" ssid="5">There are a number of open questions.</S>
    <S sid="170" ssid="6">The first is whether there exists a better string transformation algorithm to use in the induction step.</S>
    <S sid="171" ssid="7">One possible area of investigation is to use larger dictionaries and assess how much better stochastic transducers, and distance metrics derived from them, perform with more training data.</S>
    <S sid="172" ssid="8">Another option is to investigate the use of multi-vowel or multi-consonant compounds which better reflect the underlying phonetic units, using an more sophisticated edit distance measure.</S>
    <S sid="173" ssid="9">In this paper, we explore ways of using cognate pairs to create translation lexicons.</S>
    <S sid="174" ssid="10">It is an interesting research question as to whether we can augment these methods with translation probabilities estimated from statistical frequency information gleaned from loosely aligned or unaligned bilingual corpora for non-cognate pairs.</S>
    <S sid="175" ssid="11">Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates.</S>
    <S sid="176" ssid="12">The techniques presented here are useful for language pairs where an on-line translation lexicon does not already exist, including the large majority of the world's lower-density languages.</S>
    <S sid="177" ssid="13">For language pairs with existing translation lexicons, these methods can help improve coverage, especially for technical vocabulary and other more recent borrowings which are often cognate but frequently missing from existing dictionaries.</S>
    <S sid="178" ssid="14">In both cases, the great potential of this work is the ability to leverage a single bilingual dictionary into translation lexicons for its entire language family, without any additional resources beyond raw wordlists for the other languages in the family.</S>
  </SECTION>
  <SECTION title="9 Acknowledgements" number="5">
    <S sid="179" ssid="1">The authors would like to thank the following people for their insightful comments and feedback on drafts of this work: Radu Florian, Jan Hajie, Ellen Riloff, Charles Schafer, and Richard Wicentowski.</S>
    <S sid="180" ssid="2">Thanks also to the Johns Hopkins NLP lab in general for the productive and stimulating environment.</S>
  </SECTION>
</PAPER>
