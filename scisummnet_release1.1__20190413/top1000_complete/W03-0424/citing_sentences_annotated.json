[
  {
    "citance_No": 1, 
    "citing_paper_id": "P13-2118", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Will, Radford | James R., Curran", 
    "raw_text": "We use the C& amp; C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters", 
    "clean_text": "We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W07-1009", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Beatrice, Alex | Barry, Haddow | Claire, Grover", 
    "raw_text": "Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (hereafter referred to as C& amp; C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004)", 
    "clean_text": "Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W07-1009", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Beatrice, Alex | Barry, Haddow | Claire, Grover", 
    "raw_text": "As the vanilla C& amp; C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER", 
    "clean_text": "As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C10-2041", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Brian, Harrington", 
    "raw_text": "The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation. As an example of the usefulness of information integration, consider the monk -asylumexample, taken from the rg dataset (de scribed in Section 5.1)", 
    "clean_text": "The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P05-1003", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Andrew E., Smith | Trevor, Cohn | Miles, Osborne", 
    "raw_text": "These are based on those found in (Curran and Clark, 2003)", 
    "clean_text": "These are based on those found in (Curran and Clark, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W07-1019", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Barry, Haddow | Michael, Matthews", 
    "raw_text": "The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based", 
    "clean_text": "The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W07-1019", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Barry, Haddow | Michael, Matthews", 
    "raw_text": "The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain", 
    "clean_text": "The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P05-1045", 
    "citing_paper_authority": 219, 
    "citing_paper_authors": "Jenny Rose, Finkel | Trond, Grenager | Christopher D., Manning", 
    "raw_text": "Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document", 
    "clean_text": "Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W04-1217", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jenny Rose, Finkel | Shipra, Dingare | Huy, Nguyen | Malvina, Nissim | Christopher D., Manning | Gail, Sinclair", 
    "raw_text": "2.2.4 Abstracts A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999))", 
    "clean_text": "A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W06-2703", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Claire, Grover | Michael, Matthews | Richard, Tobin", 
    "raw_text": "We trained the C& amp; C maximum entropy tagger (Curran and Clark, 2003) using default settings to obtain 24 Orig Tok1 Tok2 training# sentences 18,546eval# sentences 3,856 training# tokens 492,465 540,046 578,661eval# tokens 101,028 110, 352 117, 950 Precision 65.14% 62.36% 61.39% Recall 67.35% 64.24% 63.24% F1 66.23% 63.27% 62.32% Table 1: NER Results for Different Tokenisations of the BioNLP corpus NER models for the original tokenisation (Orig), a retokenisation using the first TXMtokeniser (Tok1) and a retokenisation using the finer-grained secondTXM tokeniser (Tok2) (see Section 4)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W06-0701", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ben, Hachey | Gabriel, Murray | David, Reitter", 
    "raw_text": "Furtherlinguistic markup is added using the morpha lem matiser (Minnen et al, 2000) and the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7", 
    "clean_text": "Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "S10-1074", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Claire, Grover | Richard, Tobin | Beatrice, Alex | Kate, Byrne", 
    "raw_text": "Part-of-speech (POS) tagging is done using the C& amp; C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000)", 
    "clean_text": "Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "S10-1074", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Claire, Grover | Richard, Tobin | Beatrice, Alex | Kate, Byrne", 
    "raw_text": "We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C& amp; C maximum entropy NER tagger (Curran and Clark, 2003b)", 
    "clean_text": "We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W04-1907", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Claire, Grover | Ben, Hachey | Ian, Hughson", 
    "raw_text": "We use different strategies for the identification of the two classes of entities: for the domain-specific ones weuse hand-crafted LT TTT rules, while for the non domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on theMUC-7 data set", 
    "clean_text": "We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non domain-specific ones we use the C&C named entity tagger (Curran and Clark, 2003) trained on the MUC-7 data set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W08-0603", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Barry, Haddow", 
    "raw_text": "The part-of-speech tagging uses the Curran& amp; Clark maximum entropyMarkovmodel tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages areall rule-based", 
    "clean_text": "The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W04-1007", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ben, Hachey | Claire, Grover", 
    "raw_text": "We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non-domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the MUC7 data set", 
    "clean_text": "We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non-domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the MUC7 data set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W08-1809", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Kisuh, Ahn | Bonnie Lynn, Webber", 
    "raw_text": "For this we have used the C& amp; C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics", 
    "clean_text": "For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P06-1141", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Vijay, Krishnan | Christopher D., Manning", 
    "raw_text": "Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document", 
    "clean_text": "Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "E09-1070", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Joel, Nothman | Tara, Murphy | James R., Curran", 
    "raw_text": "By training the C& amp; C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER.Our Wikipedia-derived corpora exceed the performance of non-corresponding training and test sets by up to 11% F -score, and can be engineered to automatically produce models consistent with various NE-annotation schema", 
    "clean_text": "By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "E09-1070", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Joel, Nothman | Tara, Murphy | James R., Curran", 
    "raw_text": "We trained the C& amp; C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus", 
    "clean_text": "We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus.", 
    "keep_for_gold": 0
  }
]
