[
  {
    "citance_No": 1, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "approach to unsupervised parsing, called U-DOP (Bod 2006)", 
    "clean_text": "While Klein and Manning's approach may be described as an \"all-substrings\" approach to unsupervised parsing, an even richer model consists of an \"all-subtrees\" approach to unsupervised parsing, called U-DOP (Bod 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "Bod (2006) reports 82.9% unlabeled f-score on the same WSJ10 as used by Klein and Manning (2002, 2004)", 
    "clean_text": "Bod (2006) reports 82.9% unlabeled f-score on the same WSJ10 as used by Klein and Manning (2002, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "While we do not achieve as high an f-score as the UML-DOP model in Bod (2006), we will show that U-DOP* can operate without subtree sampling, and that the model can be trained on corpora that are two orders of magnitude larger than in Bod (2006)", 
    "clean_text": "While we do not achieve as high an f-score as the UML-DOP model in Bod (2006), we will show that U-DOP* can operate without subtree sampling, and that the model can be trained on corpora that are two orders of magnitude larger than in Bod (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "We will use the same all subtrees methodology as in Bod (2006), but now by applying the efficient and consistent DOP* based estimator", 
    "clean_text": "We will use the same all subtrees methodology as in Bod (2006), but now by applying the efficient and consistent DOP* based estimator.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "This is a huge reduction compared to Bod (2006) where 402 the number of subtrees of all trees increases with the Catalan number, and only ad hoc sampling could make the method work", 
    "clean_text": "This is a huge reduction compared to Bod (2006) where the number of subtrees of all trees increases with the Catalan number, and only ad hoc sampling could make the method work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "Note that the direct conversion of parse forests into a PCFG reduction also allows us to efficiently implement the maximum likelihood extension of U-DOP known as UML-DOP (Bod 2006)", 
    "clean_text": "Note that the direct conversion of parse forests into a PCFG reduction also allows us to efficiently implement the maximum likelihood extension of U-DOP known as UML-DOP (Bod 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "To evaluate U-DOP* against UML-DOP and other unsupervised parsing models, we started out with three corpora that are also used in Klein and Manning (2002, 2004) and Bod (2006): Penn? s WSJ10 which contains 7422 sentences? 10 words after removing empty elements and punctuation, the German NEGRA10 corpus and the Chinese Treebank CTB10 both containing 2200+ sentences? 10 words after removing punctuation", 
    "clean_text": "To evaluate U-DOP* against UML-DOP and other unsupervised parsing models, we started out with three corpora that are also used in Klein and Manning (2002, 2004) and Bod (2006): Penn's WSJ10 which contains 7422 sentences ? 10 words after removing empty elements and punctuation, the German NEGRA10 corpus and the Chinese Treebank CTB10 both containing 2200+ sentences ? 10 words after removing punctuation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "All trees in the test set were binarized beforehand, in the same way as in Bod (2006)", 
    "clean_text": "All trees in the test set were binarized beforehand, in the same way as in Bod (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "Table 1 shows the f-scores for U-DOP* and UML-DOP against the f-scores for U-DOP reported in Bod (2006), the CCM model in Klein and Manning (2002), the DMV dependency model in Klein and Manning (2004) and their combined model DMV+CCM", 
    "clean_text": "Table 1 shows the f-scores for U-DOP* and UML-DOP against the f-scores for U-DOP reported in Bod (2006), the CCM model in Klein and Manning (2002), the DMV dependency model in Klein and Manning (2004) and their combined model DMV+CCM.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "Bod (2006) reports that an unbinarized tree bank grammar achieves an average 72.3% f-score on WSJ sentences? 40 words, while the binarized version achieves only 64.6% f-score", 
    "clean_text": "Bod (2006) reports that an unbinarized treebank grammar achieves an average 72.3% f-score on WSJ sentences ? 40 words, while the binarized version achieves only 64.6% f-score.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "While a similar result was obtained in Bod (2006), the absolute difference between unsupervised parsing and the tree bank grammar was extremely small in Bod (2006): 1.8%, while the difference in table 5 is 7.2%, corresponding to 19.7% error reduction", 
    "clean_text": "While a similar result was obtained in Bod (2006), the absolute difference between unsupervised parsing and the treebank grammar was extremely small in Bod (2006): 1.8%, while the difference in table 5 is 7.2%, corresponding to 19.7% error reduction.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W07-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "between a sentence and a corpus of previous sentence-structures (Bod 2006b)", 
    "clean_text": "DOP maximizes what has been called the 'structural analogy' between a sentence and a corpus of previous sentence-structures (Bod 2006b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W07-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "Although several alternative versions of U DOP have been proposed (e.g. Bod 2006a, 2007), we will stick to the computation of the MPSD for the current paper", 
    "clean_text": "Although several alternative versions of U DOP have been proposed (e.g. Bod 2006a, 2007), we will stick to the computation of the MPSD for the current paper.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W09-1108", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Dmitry, Davidov | Roi, Reichart | Ari, Rappoport", 
    "raw_text": "These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U) DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here", 
    "clean_text": "These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U) DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P07-3008", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Bart, Cramer", 
    "raw_text": "Still, Klein and Manning (2002) and Bod (2006) stick to tag-based models", 
    "clean_text": "Still, Klein and Manning (2002) and Bod (2006) stick to tag-based models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C08-1042", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "William P., Headden III | David, McClosky | Eugene, Charniak", 
    "raw_text": "Bod (2006) describes an unsupervised system within the Data-Oriented-Parsing frame work", 
    "clean_text": "Bod (2006) describes an unsupervised system within the Data-Oriented-Parsing frame work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W09-1120", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Roi, Reichart | Ari, Rappoport", 
    "raw_text": "els (Bod, 2006a; Bod, 2006b), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) that we use in this work", 
    "clean_text": "These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) that we use in this work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D10-1067", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Roi, Reichart | Ari, Rappoport", 
    "raw_text": "Interestingly, the results reported for other constituency models (the CCM model (Klein and Manning, 2002) and the U-DOP model (Bod, 2006a; Bod, 2006b)) are reported when the parser is trained on its test corpus even if the sentences is that corpus are of bounded length (e.g. WSJ10)", 
    "clean_text": "Interestingly, the results reported for other constituency models (the CCM model (Klein and Manning, 2002) and the U-DOP model (Bod, 2006a; Bod, 2006b)) are reported when the parser is trained on its test corpus even if the sentences is that corpus are of bounded length (e.g. WSJ10).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D11-1118", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Valentin I., Spitkovsky | Hiyan, Alshawi | Angel, Chang | Daniel, Jurafsky", 
    "raw_text": "parts of-speech induction methods exist, justifying the focus on grammar induction with supervised part-of speech tags (Bod, 2006), pace (Cramer, 2007)", 
    "clean_text": "For some time, multipoint performance degradations caused by switching to automatically induced word categories have been interpreted as indications that \"good enough\" parts-of-speech induction methods exist, justifying the focus on grammar induction with supervised part-of-speech tags (Bod, 2006), pace (Cramer, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P09-1041", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Gregory, Druck | Gideon S., Mann | Andrew, McCallum", 
    "raw_text": "The best performing combination attains accuracy of 66.7% on WSJ10, but the worst attains accuracy of 32.5% .Finally, Seginer (2007) and Bod (2006 )approach unsupervised parsing by constructing novel syntactic models", 
    "clean_text": "Finally, Seginer (2007) and Bod (2006) approach unsupervised parsing by constructing novel syntactic models.", 
    "keep_for_gold": 0
  }
]
