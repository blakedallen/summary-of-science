Deterministic Dependency Parsing Of English Text
This paper presents a deterministic dependency parser based on memory-based learning, which parses English text in linear time.
When trained and evaluated on the Wall Street Journal section of the Penn Treebank, the parser achieves a maximum attachment score of 87.1%.
Unlike most previous systems, the parser produces labeled dependency graphs, using as arc labels a combination of bracket labels and grammatical role labels taken from the Penn Treebank II annotation scheme.
The best overall accuracy obtained for identifying both the correct head and the correct arc label is 86.0%, when restricted to grammatical role labels (7 labels), and 84.4% for the maximum set (50 labels).
We propose a variant of the model of Yamada and Matsumoto that reduces the complexity, from the worst case quadratic to linear.
Our deterministic shift/reduce classifier-based dependency parsing approach offers state-of-the-art accuracy with high efficiency due to a greedy search strategy.
