Learning to Translate with Source and Target Syntax
Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years.
These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language.
But progress has been slower on translation models that are able to learn the relationship between the grammars of both the source and target language.
We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a simple approach that uses both source and target syntax for significant improvements in translation accuracy.
We obtain significant improvement over his hierarchical baseline by using syntactic parse trees on both source and target sides to induce fuzzy (not exact) tree-to-tree rules and by also allowing syntactically mismatched substitutions.
We show that the integration of syntactic information on both sides tends to decrease translation quality because the systems be come too restrictive.
