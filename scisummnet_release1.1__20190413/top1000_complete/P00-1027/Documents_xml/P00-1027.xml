<PAPER>
  <S sid="0">Minimally Supervised Morphological Analysis By Multimodal Alignment</S>
  <ABSTRACT>
    <S sid="1" ssid="1">with genetic algorithms.</S>
    <S sid="2" ssid="2">Workshop on Empirical Learning of NLP Tasks.</S>
    <S sid="3" ssid="3">K. Koskenniemi, 1983.</S>
    <S sid="4" ssid="4">A general computation model word-form recognition and production.</S>
    <S sid="5" ssid="5">11, of General Linguistics. of Helsinki.</S>
    <S sid="6" ssid="6">C.X.</S>
    <S sid="7" ssid="7">Ling, 1994.</S>
    <S sid="8" ssid="8">Learning the past tense of English verbs: The symbolic pattern associator vs. connecmodels.</S>
    <S sid="9" ssid="9">Art.</S>
    <S sid="10" ssid="10">Intel.</S>
    <S sid="11" ssid="11">Res., R. Mooney and M. Califf, 1995.</S>
    <S sid="12" ssid="12">Induction of firstorder decision lists: Results on learning the past of English verbs.</S>
    <S sid="13" ssid="13">Art.</S>
    <S sid="14" ssid="14">Intel.</S>
    <S sid="15" ssid="15">Res., K. Oflazer and S. Nirenburg, 1999.</S>
    <S sid="16" ssid="16">Practical bootof morphological analyzers. of the Conference on Natural Language Learning.</S>
    <S sid="17" ssid="17">D. Rumelhart and J. McClelland, 1986.</S>
    <S sid="18" ssid="18">On learning the past tense of English verbs.</S>
    <S sid="19" ssid="19">In J. McClel- D. Rumelhart, and the Group, Parallel distributed processing: Explorations in the of cognition, 2.</S>
    <S sid="20" ssid="20">MIT Press.</S>
    <S sid="21" ssid="21">P. Theron and I. Cloete, 1997.</S>
    <S sid="22" ssid="22">Automatic acquisition two-level morphological rules. of the Fifth Conference on Applied Natural Language Propages 103-110.</S>
    <S sid="23" ssid="23">A. Voutilainen, 1995.</S>
    <S sid="24" ssid="24">Morphological disambiguation.</S>
    <S sid="25" ssid="25">In F. Karlsson, A. Voutilainen, J. Heikkila, and A.</S>
    <S sid="26" ssid="26">(eds.) grammar - A language independent system for parsing unrestricted text, pages 165-284.</S>
    <S sid="27" ssid="27">The Hague: Mouton de Gruyter.</S>
  </ABSTRACT>
  <SECTION title="1 Task Definition" number="1">
    <S sid="28" ssid="1">This paper presents an original and successful algorithm for the nearly unsupervised induction of inflectional morphological analyzers, with a focus on highly irregular forms not typically handled by other morphology induction algorithms.</S>
    <S sid="29" ssid="2">It is useful to consider this task as three separate steps: The target output of Step 1 is an inflection-root mapping such as shown in Table 1, with optional columns giving the hypothesized stem change and suffix analysis as well as part of speech.</S>
    <S sid="30" ssid="3">This suffix-focused transformational model is not, as given, sufficient for languages with prefixal, infixal and reduplicative morphologies.</S>
    <S sid="31" ssid="4">But it is remarkably productive across Indo-European languages in its current form and can be extended to other affixational schema when appropriate.</S>
    <S sid="32" ssid="5">For many applications, once the vocabulary list achieves sufficiently broad coverage, this alignment table effectively becomes a morphological analyzer simply by table lookup (independent of necessary contextual ambiguity resolution).</S>
    <S sid="33" ssid="6">While the probabilistic analyzer trained in Step 2 remains useful for previously unseen words, such words are typically quite regular and most of the difficult substance of the lemmatization problem can often be captured by a large root+Posinflection mapping table and a simple transducer to handle residual forms.</S>
    <S sid="34" ssid="7">This is not the case for agglutinative languages such as Turkish or Finnish, or for very highly inflected languages such as Czech, where sparse data becomes an issue.</S>
    <S sid="35" ssid="8">But for many languages, and to a quite practical degree, inflectional morphological analysis and generation can be viewed primarily as an alignment task on a broad coverage wordlist.</S>
    <S sid="36" ssid="9">Thus, while this paper will discuss our implementation of a stand-alone probabilistic analyzer and retraining process in Steps 2 and 3, the challenge of large-coverage inflection-root alignment expressed in Step 1 is the core of this work.</S>
    <S sid="37" ssid="10">In further clarification of the task description, the morphological induction described in this paper assumes, and is based on, only the following limited set of (often optional) available resources: (a) A table (such as Table 2) of the inflectional parts of speech of the given language, along with a list of the canonical suffixes for each part of speech.</S>
    <S sid="38" ssid="11">These suffixes not only serve as mnemonic tags for the POS labels, but they can also be used to obtain a noisy set of candidate examples for each part of speech.' the given language is useful to the extraction of context similarity features.</S>
    <S sid="39" ssid="12">(f) If available, the various distance/similarity tables generated by this algorithm on previously studied languages can be useful as seed information, especially if these languages are closely related (e.g.</S>
    <S sid="40" ssid="13">Spanish and Italian).</S>
  </SECTION>
  <SECTION title="2 Related Work" number="2">
    <S sid="41" ssid="1">There is a rich tradition of supervised and unsupervised learning in the domain of morphology.</S>
    <S sid="42" ssid="2">Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively.</S>
    <S sid="43" ssid="3">Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems and affixes.</S>
    <S sid="44" ssid="4">Brent and de Marcken both have used a minimum description length framework, with the primary goal of inducing lexemes from boundaryless speech-like streams.</S>
    <S sid="45" ssid="5">Goldsmith specifically sought to induce suffix paradigm classes (e.g.</S>
    <S sid="46" ssid="6">NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing vs. ted.tion) from raw text.</S>
    <S sid="47" ssid="7">However, handling of irregular words was largely excluded from this work, as Goldsmith assumed a strictly concatenative morphology without models for stem changes.</S>
    <S sid="48" ssid="8">Morphology induction in agglutenative languages such as Turkish and Finnish presents a problem similar to parsing or segmenting a sentence, given the long strings of affixations allowed and the relatively free affix order.</S>
    <S sid="49" ssid="9">Voutilainen (1995) has approached this problem in a finitestate framework, and Hakkani-Thr et al. (2000) have done so using a trigram tagger, with the assumption of a concatenative affixation model.</S>
    <S sid="50" ssid="10">The two-level model of morphology (Koskenniemi, 1983) has been extremely successful in manually capturing the morphological processes of the world's languages.</S>
    <S sid="51" ssid="11">The context sensitive stem-change models used in this current paper have been partially inspired by this framework.</S>
    <S sid="52" ssid="12">For example, a two-level equivalent capturing happy + er = happier is y:i &lt;=&gt; p:p _, quite similar in spirit and function to our probabilistic model P(y&#8212;xil...app, +er).</S>
    <S sid="53" ssid="13">Theron and Cloete (1997) sought to learn a 2-level rule set for English, Xhosa and Afrikaans by supervision from 0(4000) aligned inflection-root pairs extracted from dictionaries.</S>
    <S sid="54" ssid="14">Single character insertion and deletions were allowed, and the learned rules supported both prefixation and suffixation.</S>
    <S sid="55" ssid="15">Their supervised learning approach could be applied directly to the aligned pairs induced in this paper.</S>
    <S sid="56" ssid="16">Finally, Oflazer and Nirenburg (1999) have developed a framework to learn two-level morphological analyzers from interactive supervision in a Elicit-Build-Test loop under the Boas project.</S>
    <S sid="57" ssid="17">Humans provide as-needed feedback regarding errors and omissions.</S>
    <S sid="58" ssid="18">Recently applied to Polish, the model also assumes concatenative morphology and treats non-concatenative irregular forms through table lookup.</S>
    <S sid="59" ssid="19">Thus there is a notable gap in the research literature for induction of analyzers for irregular morphological processes, including significant stem changing.</S>
    <S sid="60" ssid="20">The algorithm described below directly addresses this gap, while successfully inducing more regular analyses without supervision as well.</S>
  </SECTION>
  <SECTION title="3 Lemma Alignment by Frequency Similarity" number="3">
    <S sid="61" ssid="1">The motivating dilemma behind our approach to morphological alignment is the question of how one determines that the past tense of sing is sang and not singed.</S>
    <S sid="62" ssid="2">The pairing sing&#8212;x singed requires only simple concatenation with the canonical suffix, +ed, and singed is indeed a legal word in our vocabulary (the past tense of singe).</S>
    <S sid="63" ssid="3">And while few irregular verbs have a true word occupying the slot that would be generated by a regular morphological rule, a large corpus is filled with many spelling mistakes or dysfluencies such as taked (observed with a frequency of 1), and such errors can wreak havoc in na&#239;ve alignment-based methods.</S>
    <S sid="64" ssid="4">How can we overcome this problem?</S>
    <S sid="65" ssid="5">Relative corpus frequency is one useful evidence source.</S>
    <S sid="66" ssid="6">Observe in Table 3 that in an 80 million word collection of newswire text the relative frequency distribution of sang/sing is 1427/1204 (or 1.19/1), which indicates a reasonably close frequency match, while the singed/sing ratio is 0.007/1, a substantial disparity.</S>
    <S sid="67" ssid="7">However, simply looking for close relative frequencies between an inflection and its candidate root is inappropriate, given that some inflections are relatively rare and expected to occur much less frequently than the root form.</S>
    <S sid="68" ssid="8">Thus in order to be able to rank the sang/sing and singed/sing candidates effectively, it is necessary to be able to quantify how well each fits (or deviates from) expected frequency distributions.</S>
    <S sid="69" ssid="9">To do so, we use simple non-parametric statistics to calculate the probability of a particularvBD ratio by examining how frequently other such ratios in a similar range have been seen in the corpus.</S>
    <S sid="70" ssid="10">Figure 1 illustrates such a histogram (based on the log of the ratios to focus more attention on the extrema).</S>
    <S sid="71" ssid="11">The histogram is then smoothed and normalized as an approximation of the probability density function for this estimator ( g ( vvBBD ) ) which we can then use to quantify to what extent a given candidate log( ) such as /og(sang/sing)=.17, fits our empirically motivated expectations.</S>
    <S sid="72" ssid="12">The relative position of the candidate pairings on the graph suggests that this estimator is indeed informative given the task of ranking potential root-inflection pairings.</S>
    <S sid="73" ssid="13">However, estimating these distributions presents a problem given that the true alignments (and hence frequency ratios) between inflections The third alignment similarity function considers overall stem edit distance using a weighted Levenshtein measure.</S>
    <S sid="74" ssid="14">In morphological systems worldwide, vowels and vowel clusters are relatively mutable through morphological processes, while consonants generally tend to have a lower probability of change during inflection.</S>
    <S sid="75" ssid="15">Rather than treating all string edits as equal, a cost matrix of the form shown in Table 6 is utilized, with initial distance costs 61=v-v, 62=v+-v+, 63=c- c and 64=c-v+, initially set to (0.5, 0.6, 1.0, 0.98), a relatively arbitrary assignment reflecting this tendency.</S>
    <S sid="76" ssid="16">However, as subsequent algorithm iterations proceed, this matrix is re-estimated with empirically observed character-to-character stem-change probabilities from the algorithm's current best weighted alignments. a o ue m n ... a 0 61.</S>
    <S sid="77" ssid="17">62 64 64 &#8226;&#8226;&#8226; More optimally, the initial state of this matrix could be seeded with values partially borrowed from previously trained matrices from other related languages.</S>
    <S sid="78" ssid="18">Alternately, the initial distances could be set partially sensitive to phonological similarities, with dist(/d/,/t/) &lt; dist(/d/,/f/) for example, although this particular distinction emerges readily via iterative re-estimation from the baseline model.</S>
  </SECTION>
  <SECTION title="6 Lemma Alignment by Morphological Transformation Probabilities" number="4">
    <S sid="79" ssid="1">The goal of this research is not only to extract an accurate table of inflection-root alignments, but also to generalize this mapping function via a generative probabilistic model.</S>
    <S sid="80" ssid="2">The following section describes the creation of this model, as well as how the context-sensitive probability of each morphological transformation can be used as the fourth alignment similarity measure.</S>
    <S sid="81" ssid="3">At each iteration of the algorithm, this probabilistic mapping function is trained on the table output of the previous iteration, equivalent to the information in Table 1 (e.g.</S>
    <S sid="82" ssid="4">&lt;root,inflection&gt; pairs with optional part-of-speech tags, confidence scores and stemchange+suffix analysis) .6 From this output, we cluster the observed stem changes by the variable-length root context in which they were applied, as illustrated in Table 7.</S>
    <S sid="83" ssid="5">First note that because the triple of &lt;root&gt; + &lt;stemchange&gt; + &lt;suffix&gt; uniquely determines a resulting inflection, one can effectively compute P(inflection I root, suffix, POS) by P(stemchange I root, suffix, POS), i.e. for any root=-ya, suffix=+o- and inflection=-0a, Using statistics such as shown in Table 7, it is thus possible to compute the generation (or alignment) probability for an inflection given root and suffix using the simple interpolated backoff model in (1) where Ai is a function of the relative sample size of the conditioning event, and lastk(root) indicates the final k characters of the root.</S>
    <S sid="84" ssid="6">We only backoff to the extent necessary.</S>
    <S sid="85" ssid="7">Furthermore, note that for English (and most inflections in Spanish), the stem changes observed when adding suffixes are independent of part of speech (i.e.</S>
    <S sid="86" ssid="8">+8 behaves the same on suffixation for both nouns and verbs), so these probabilities can often be further simplified by deleting the conditioning variable POS, as illustrated in (2).</S>
    <S sid="87" ssid="9">We have further generalized these variablelength context models via a full hierarchicallysmoothed trie architecture, allowing robust specialization to very long root contexts if sample sizes are sufficient.</S>
    <S sid="88" ssid="10">6.1 Baseline Model for Morphological Transformation Probabilities On the first iteration, no inflection/root pairs are available for estimating the above models.</S>
    <S sid="89" ssid="11">As prior knowledge is not available regarding a &#8212;x stem-change probabilities, an assumption is made that the cost of each is proportional to the previously described Levenshtein distance between a and /3, with the cost of a change increasing geometrically as the distance from the end of the root increases.</S>
    <S sid="90" ssid="12">The rate of this cost increase ultimately depends on the tendency of the language to allow word-internal spelling changes (as in Spanish or Arabic), or strongly favor changes at the point of affixation (as in English).</S>
    <S sid="91" ssid="13">The primary goal of iterative retraining is to refine the core morphological transformation model, which not only serves as one of the four similarity models, but is also a primary deliverable of the learning process.</S>
    <S sid="92" ssid="14">As subsequent iterations proceed, the stemchange probability models are retrained on the output of the prior iteration, weighting each training example with its alignment confidence, and filtering out a &#8212;x /3 changes without a minimum level of support to help reduce noise.</S>
    <S sid="93" ssid="15">The final stem-change probabilities then are an interpolation with the trained model Pi and the initial baseline (P0) model described in Section 6.1: P( c &#8212;x 13 I root, suffix, POS) = Ai P0( a &#8212;x /3 I suffix) + (1 &#8212; Ai) Pi( a &#8212;x /3 I root, suffix, POS) The Levenshtein distance models are reestimated as observed in Section 5, while the context similarity model can be improved through better self-learned lemmatization of the modelled context words.</S>
    <S sid="94" ssid="16">7 Lemma Alignment by Model Combination and the Pigeonhole Principle As shown empirically below, no single model is sufficiently effective on its own.</S>
    <S sid="95" ssid="17">We applied traditional classifier combination techniques to merge the four models' scores, scaling each to achieve compatible dynamic range.</S>
    <S sid="96" ssid="18">The Frequency, Levenshtein and Context similarity models retain equal relative weight as training proceeds, while the Morphological Transformation (MorphTrans) similarity model increases in relative weight as it becomes better trained.</S>
    <S sid="97" ssid="19">Table 8 demonstrates the combined measures in action, showing the relative rankings of candidate roots for the inflections took, shook and juegan by the four similarity models after the first iteration (in Columns 2-4).</S>
    <S sid="98" ssid="20">The overall consensus similarity measure at the end of Iteration 1 is shown in Column 1.7 Note that even though only one of the four estimators independently ranked shake as the most likely root of shook, after only the first iteration the consensus choice is correct.</S>
    <S sid="99" ssid="21">The final column of Table 8 shows the retrained MorphTrans similarity measure after convergence.</S>
    <S sid="100" ssid="22">Based on training evidence from the confidently aligned pairs took/take, shook/shake and undertook/undertake from previous iterations, the probability of ake&#8212;xook has increased significantly, further increasing the confidence in the overall alignments at convergence (not shown), but not changing the previously correct ranking in these cases.</S>
    <S sid="101" ssid="23">The final alignment constraint that we pursued was based on the pigeonhole principle.</S>
    <S sid="102" ssid="24">This principle suggests that for a given part of speech, a root should not have more than one inflection nor should multiple inflections in the same part of speech share the same root.</S>
    <S sid="103" ssid="25">There are, of course, exceptions to this tendency, such as travelled/traveled and dreamed! dreamt, which are observed as variant forms of their respected roots.</S>
    <S sid="104" ssid="26">71n addition to the consensus similarity score in subcolumn 2, subcolumn 3 shows the average of the ranks of the candidate root given the inflection and the ranks of the candidate inflection given the root.</S>
    <S sid="105" ssid="27">This bidirectional average ranking score favors cases where attraction between root and inflection is mutual, and disfavors cases where higher ranked competition exists for a root's attentions, effectively capturing a weak form of the pigeonhole principle.</S>
    <S sid="106" ssid="28">Thus it was used as the primary ranking criteria (over raw similarity score). shake .00149 5.5 1 shake .854 share .073 shoo .500 shoot .002593 shake .465578 shoot .00126 9.3 2 shave .323 ship .068 shoot .333 shoo .002593 shoot .001296 ship .00104 16.3 3 shape .210 shift .062 shoe .310 shock .000096 shoo .001296 shatter .00061 18.9 4 shore .194 shop .060 shake .290 short .000096 shock .000048 shop .00094 19.8 5 shower .184 shake .058 shop .236 shout .000095 short .000048 shut .00081 20.6 6 shoot .162 shut .052 shout .236 ... ... shove .000048 shun .00039 20.7 7 shock .154 shoot .051 show .236 shake .000003 shore .000048 The extent to which such overlaps should be penalized depends on the probability of seeing variant inflections in the morphology, but for Spanish and English this is relatively low.</S>
    <S sid="107" ssid="29">We exploited the pigeonhole principle in two ways simultaneously.</S>
    <S sid="108" ssid="30">The first is a greedy algorithm, in which candidates are aligned in order of decreasing score, and when the the first-choice root for a given inflection has already been taken by another inflection of the same part of speech, the algorithm continues until a free slot is found.</S>
    <S sid="109" ssid="31">The exception is when the highest ranking free form is several orders of magnitude lower than the first choice; here the first-choice alignment is assumed to be correct, but a variant form.</S>
  </SECTION>
  <SECTION title="8 Empirical Evaluation" number="5">
    <S sid="110" ssid="1">Current empirical evaluation of this work focuses on its accuracy in analyzing the often highly irregular past tense of English verbs.</S>
    <S sid="111" ssid="2">Consistent with prior empirical studies in this field, evaluation was performed on a test set of 3888 inflected words, including 128 highly irregular inflections, 1877 cases where the past tense was formed by simple concatenative suffixation, and 1883 inflections exhibiting a non-concatenative stem change such as gemination or elision.</S>
    <S sid="112" ssid="3">In execution, for each test inflected form, the analysis algorithm was free to consider alignment to any word in the corpus which had been identified as a potential root verb by the part-of-speech tagging process or occurrence in a dictionaryderived rootlist, not just those roots in the test set.</S>
    <S sid="113" ssid="4">It is thus a more challenging evaluation than testing simple alignment accuracy between two clean and extraneous-entry-free wordlists.</S>
    <S sid="114" ssid="5">Table 9 shows the performance of several of the investigated similarity measures.</S>
    <S sid="115" ssid="6">Frequency similarity (FS), enhanced Levenshtein (LS), and Context similarity (CS) alone achieve only 10%, 31% and 28% overall accuracy respectively.</S>
    <S sid="116" ssid="7">However, the hypothesis that these measures model independent and complementary evidence sources is supported by the roughly additive combined accuracy of 71.6%.8 The final performance of the full converged CS+FS+LS+MS model at 99.2% accuracy on the full test set, and 99.7% accuracy on inflections requiring analysis beyond simple concatenative suffixation, is quite remarkable given that the algorithm had absolutely no &lt;inflection,root&gt; examples as training data, and had no prior inventory of stem changes available, with only a slight statistical bias in favor of shorter stem changes with smaller Levenshtein distance, and with the minimal search-simplifying assumption in all the models that candidate alignments must begin with a the same VC * prefix.9 Given a starting point where all single character X-+17 changes at the point of suffixation are equally likely, the processes of elison (e-+e), gemination (e.g.</S>
    <S sid="117" ssid="8">E-xd in the context of d), and y-xi shift (in the context of a preceding consonant, not vowel) all emerge by the end of the first iteration with high probability in their appropriate contexts, and low probability elsewhere.</S>
    <S sid="118" ssid="9">Table 10 shows how each of the models perform on a randomly-selected 30% of the highly irregular forms, with correctly selected roots identified in bold.</S>
    <S sid="119" ssid="10">The residual errors are primarily of three types: Two inflections, went and ate, were not alignable with their correct roots due to different first character.</S>
    <S sid="120" ssid="11">The largest class of errors are due to the pigeonhole principle strongly disfavoring two inflections from sharing the same root.10 9To put the Table 9 results in perspective, Mooney and Calif (1995) achieved 82.5% overall accuracy using a fully supervised decision list learner trained on 250 paired past-tense/root verb pairs (in plain text form).</S>
    <S sid="121" ssid="12">Although they don't breakdown this performance by word type, their included FOILDL program trained from 250 pairs and applied to our evaluation set achieved 100% accuracy on the pairs with simple +ed concatenation, 84% accuracy on stem changing (non-concat) pairs and 5% accuracy on the highly irregular pairs, with 89% overall accuracy.</S>
    <S sid="122" ssid="13">Other available supervised learning results (e.g.</S>
    <S sid="123" ssid="14">Ling; Rumelhart and McClelland) are only given for phonological word representations.</S>
    <S sid="124" ssid="15">While not directly comparable with our text-based data, their performance is significantly worse than Mooney and Calif's FOILDL on common phonological paired data, suggesting that FOILDL is a generally competitive reference point for our results.</S>
    <S sid="125" ssid="16">19This was previously noted in the case of dream dreamed and dreamt, or burned burned and burnt, with the higher probability analysis typically occupying the root slot and the lower probability form typically forced to seek alignment elsewhere.</S>
    <S sid="126" ssid="17">Indeed, the pigeonhole principle is the most problematic of all the The remaining errors typically are due to sparse statistics for the lower frequency irregular forms.</S>
    <S sid="127" ssid="18">Mappings such as slew slay are particularly difficult because, with a corpus frequency of only 4, there is too little data to estimate a good context profile or an effectively discriminatory frequency profile.</S>
    <S sid="128" ssid="19">Enlarging the raw corpus size should improve performance in both of these cases.</S>
  </SECTION>
  <SECTION title="9 Conclusion" number="6">
    <S sid="129" ssid="1">This paper has presented an original algorithm capable of inducing the accurate morphological analysis of even highly irregular verbs, starting with no paired &lt;inflection,root&gt; examples for training and no prior seeding of legal morphological transformations.</S>
    <S sid="130" ssid="2">It does so by treating morphological analysis predominantly as an alignment task in a large corpus, performing the effective collaboration of four original similarity measures based on expected frequency distributions, context, morphologically-weighted Levenshtein similarity and an iteratively bootstrapped model of affixation and stem-change probabilities.</S>
    <S sid="131" ssid="3">This constitutes a significant achievement in that previous approaches to morphology acquisition have either focused on unsupervised induction of quasiregular concatenative affixation, or handled irregular forms with fully supervised training.</S>
    <S sid="132" ssid="4">In contrast, this paper's essentially unsupervised algorithm achieves over 80% accuracy on the most highly irregular forms, and 99.7% accuracy on analyses requiring some stem change, outperforming Mooney and Califf's fully supervised learning algorithm overall and on both of these measures. alignment principles used, as it creates nearly as many problems as it fixes.</S>
    <S sid="133" ssid="5">The overall performance advantage is slightly in its favor (with 59 misalignments avoided for 50 problems created), but the cost of this approach is borne heavily by the irregular verbs, and a probabilistic model of when variant forms should be expected/allowed is necessary to fix these cases while preserving the advantages of the principle in downweighting clashing analyses in the more regular verbs.</S>
    <S sid="134" ssid="6">Test True (Convg) CS+FS+LS+MS (Itr 1) CS+FS+LS CS+FS LS only Word Root Score (Itr 1) (Itr 1) (Itr 1) got get go 1.30 go go go gut knew know know 1.35 know know know know took take take 1.50 take take take toot blew blow blow 1.80 blow blow blow blow became become become 2.35 become become become become made make make 2.40 make make make mate clung cling cling 2.55 cling cling cling cling drew draw draw 2.65 draw draw draw draw swore swear swear 2.80 swear swear swear store wore wear wear 3.10 wear wear wear wire came come come 3.55 come come come come thought think think 3.60 think think think thump flung fling fling 4.60 fling fling fling fling brought bring bring 5.35 bring bring bring brighten strove strive strive 5.85 strive strive straddle strive stuck stick stick 6.00 stick stick stabilize stock swept sweep sweep 6.20 sweep sweep sweep swap shone shine shine 6.55 shine shine shine shine woke wake wake 6.95 wake wake wind wake clove cleave cleave 7.35 cleave cleave cleave close bore bear bear 7.75 bear bar bear bare meant mean mean 8.20 mean mean manage mount lent lend lend 9.25 lend lend lend lend slew slay slit 10.06 slit slight slight slow struck strike strike 11.60 strike strike strike strut bought buy buy 12.20 buy buy buy bound bit bite bite 13.60 bite bite betray bet dove dive dive 17.25 dive dive dash dive burnt burn burp 17.30 burp burp burp burn went go want 18.29 want want want want caught catch catch 18.35 catch cut catch cough dealt deal deal 21.45 deal deal disagree deal</S>
  </SECTION>
</PAPER>
