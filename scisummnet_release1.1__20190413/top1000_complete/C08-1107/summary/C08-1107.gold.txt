Learning Entailment Rules for Unary Templates
Most work on unsupervised entailment rule acquisition focused on rules between templates with two variables, ignoring unary rules - entailment rules between templates with a single variable.
In this paper we investigate two approaches for unsupervised learning of such rules and compare the proposed methods with a binary rule learning method.
The results show that the learned unary rule-sets outperform the binary rule-set.
In addition, a novel directional similarity measure for learning entailment, termed Balanced-Inclusion, is the best performing measure.
We propose a unary template, which is defined as a template consisting of one argument slot and one predicate phrase.
We use the distributional similarity of arguments to detect unary template entailment.
Two approaches for unsupervised learning of unary rules (i.e. between templates with a single variable) are investigated. In (Zhao et al, 2009), a pivot approach for extracting paraphrase patterns from bilingual parallel corpora is presented, while in (Callison-Burch,2008) the quality of paraphrase extraction from parallel corpora is improved by requiring that phrases and their paraphrases have the same syntactic type. Our approach is different from theirs in many respects: their goal is paraphrase extraction, while we are extracting directional entailment rules; as textual resources for pattern extraction they use parallel corpora (using patterns in another language as pivots), while we rely on monolingual Wikipedia revisions (taking benefit from its increasing size); the para phrases they extract are more similar to DIRT, while our approach allows to focus on the acquisition of rules for specific phenomena frequent in entailment pairs, and not covered by other resources.
We try identifying the entailment relation between lexical-syntactic templates using WeedsPrec, but observed that it tends to promote unreliable relations involving infrequent templates.
