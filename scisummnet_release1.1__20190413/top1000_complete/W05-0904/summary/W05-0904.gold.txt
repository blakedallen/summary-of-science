Syntactic Features For Evaluation Of Machine Translation
Automatic evaluation of machine translation, based on computing n-gram similarity between system output and human reference translations, has revolutionized the development of MT systems.
We explore the use of syntactic information, including constituent labels and head-modier dependencies, in computing similarity between output and reference.
Our results show that adding syntactic information to the evaluation metric improves both sentence-level and corpus-level correlation with human judgments.
we measure the syntactic similarity between MT output and reference translation.
we used syntactic structure and dependency information to go beyond the surface level matching.
