Automatic sense prediction for implicit discourse relations in text
We present a series of experiments on automatically identifying the sense of implicit discourse relations, i.e. relations that are not marked with a discourse connective such as “but” or “because”.
We work with a corpus of implicit relations present in newspaper text and report results on a test set that is representative of the naturally occurring distribution of senses.
We use several linguistically informed features, including polarity tags, Levin verb classes, length of verb phrases, modality, context, and lexical features.
In addition, we revisit past approaches using lexical pairs from unannotated text as features, explain some of their shortcomings and propose modifications.
Our best combination of features outperforms the baseline from data intensive approaches by 4% for comparison and 16% for contingency.
Although on Comparison relation there is only as light improvement (+1.07%), our two best systems both got around 10% improvements of f score over a state-of-the-art system in (Pitler et al, 2009a).
Our analysis shows that the top word pairs (ranked by information gain) all contain common functional words, and are not at all the semantically-related content words that were imagined.
