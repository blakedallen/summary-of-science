<PAPER>
  <S sid="0">WordNet::Similarity - Measuring The Relatedness Of Concepts</S>
  <ABSTRACT>
    <S sid="1" ssid="1">WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets).</S>
    <S sid="2" ssid="2">It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet.</S>
    <S sid="3" ssid="3">These measures are implemented as Perl modules which take as input two concepts, and return a numeric value that represents the degree to which they are similar or related.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="4" ssid="1">WordNet::Similarity implements measures of similarity and relatedness that are all in some way based on the structure and content of WordNet.</S>
    <S sid="5" ssid="2">Measures of similarity use information found in an is&#8211; a hierarchy of concepts (or synsets), and quantify how much concept A is like (or is similar to) concept B.</S>
    <S sid="6" ssid="3">For example, such a measure might show that an automobile is more like a boat than it is a tree, due to the fact that automobile and boat share vehicle as an ancestor in the WordNet noun hierarchy.</S>
    <S sid="7" ssid="4">WordNet is particularly well suited for similarity measures, since it organizes nouns and verbs into hierarchies of is&#8211;a relations.</S>
    <S sid="8" ssid="5">In version 2.0, there are nine separate noun hierarchies that include 80,000 concepts, and 554 verb hierarchies that are made up of 13,500 concepts.</S>
    <S sid="9" ssid="6">Is&#8211;a relations in WordNet do not cross part of speech boundaries, so similarity measures are limited to making judgments between noun pairs (e.g., cat and dog) and verb pairs (e.g., run and walk).</S>
    <S sid="10" ssid="7">While WordNet also includes adjectives and adverbs, these are not organized into is&#8211;a hierarchies so similarity measures can not be applied.</S>
    <S sid="11" ssid="8">However, concepts can be related in many ways beyond being similar to each other.</S>
    <S sid="12" ssid="9">For example, a wheel is a part of a car, night is the opposite of day, snow is made up of water, a knife is used to cut bread, and so forth.</S>
    <S sid="13" ssid="10">As such WordNet provides relations beyond is&#8211;a, including has&#8211;part, is&#8211;made&#8211;of, and is&#8211;an&#8211;attribute&#8211;of.</S>
    <S sid="14" ssid="11">In addition, each concept is defined by a short gloss that may include an example usage.</S>
    <S sid="15" ssid="12">All of this information can be brought to bear in creating measures of relatedness.</S>
    <S sid="16" ssid="13">As a result these measures tend to be more flexible, and allow for relatedness values to be assigned across parts of speech (e.g., the verb murder and the noun gun).</S>
    <S sid="17" ssid="14">This paper continues with an overview of the measures supported in WordNet::Similarity, and then provides a brief description of how the package can be used.</S>
    <S sid="18" ssid="15">We close with a summary of research that has employed WordNet::Similarity.</S>
  </SECTION>
  <SECTION title="2 Similarity Measures" number="2">
    <S sid="19" ssid="1">Three of the six measures of similarity are based on the information content of the least common subsumer (LCS) of concepts A and B.</S>
    <S sid="20" ssid="2">Information content is a measure of the specificity of a concept, and the LCS of concepts A and B is the most specific concept that is an ancestor of both A and B.</S>
    <S sid="21" ssid="3">These measures include res (Resnik, 1995), lin (Lin, 1998), and jcn (Jiang and Conrath, 1997).</S>
    <S sid="22" ssid="4">The lin and jcn measures augment the information content of the LCS with the sum of the information content of concepts A and B themselves.</S>
    <S sid="23" ssid="5">The lin measure scales the information content of the LCS by this sum, while jcn takes the difference of this sum and the information content of the LCS.</S>
    <S sid="24" ssid="6">The default source for information content for concepts is the sense&#8211;tagged corpus SemCor.</S>
    <S sid="25" ssid="7">However, there are also utility programs available with WordNet::Similarity that allow a user to compute information content values from the Brown Corpus, the Penn Treebank, the British National Corpus, or any given corpus of raw text.</S>
    <S sid="26" ssid="8">Three similarity measures are based on path lengths between a pair of concepts: lch (Leacock and Chodorow, 1998), wup (Wu and Palmer, 1994), and path. lch finds the shortest path between two concepts, and scales that value by the maximum path length found in the is&#8211;a hierarchy in which they occur. wup finds the depth of the LCS of the concepts, and then scales that by the sum of the depths of the individual concepts.</S>
    <S sid="27" ssid="9">The depth of a concept is simply its distance to the root node.</S>
    <S sid="28" ssid="10">The measure path is a baseline that is equal to the inverse of the shortest path between two concepts.</S>
    <S sid="29" ssid="11">WordNet::Similarity supports two hypothetical root nodes that can be turned on and off.</S>
    <S sid="30" ssid="12">When on, one root node subsumes all of the noun concepts, and another subsumes all of the verb concepts.</S>
    <S sid="31" ssid="13">This allows for similarity measures to be applied to any pair of nouns or verbs.</S>
    <S sid="32" ssid="14">If the hypothetical root nodes are off, then concepts must be in the same physical hierarchy for a measurement to be taken.</S>
  </SECTION>
  <SECTION title="3 Measures of Relatedness" number="3">
    <S sid="33" ssid="1">Measures of relatedness are more general in that they can be made across part of speech boundaries, and they are not limited to considering is-a relations.</S>
    <S sid="34" ssid="2">There are three such measures in the package: hso (Hirst and St-Onge, 1998), lesk (Banerjee and Pedersen, 2003), and vector (Patwardhan, 2003).</S>
    <S sid="35" ssid="3">The hso measures classifies relations in WordNet as having direction, and then establishes the relatedness between two concepts A and B by finding a path that is neither too long nor that changes direction too often.</S>
    <S sid="36" ssid="4">The lesk and vector measures incorporate information from WordNet glosses.</S>
    <S sid="37" ssid="5">The lesk measure finds overlaps between the glosses of concepts A and B, as well as concepts that are directly linked to A and B.</S>
    <S sid="38" ssid="6">The vector measure creates a co&#8211;occurrence matrix for each word used in the WordNet glosses from a given corpus, and then represents each gloss/concept with a vector that is the average of these co&#8211;occurrence vectors.</S>
  </SECTION>
  <SECTION title="4 Using WordNet::Similarity" number="4">
    <S sid="39" ssid="1">WordNet::Similarity can be utilized via a command line interface provided by the utility program similarity.pl.</S>
    <S sid="40" ssid="2">This allows a user to run the measures interactively.</S>
    <S sid="41" ssid="3">In addition, there is a web interface that is based on this utility.</S>
    <S sid="42" ssid="4">WordNet::Similarity can also be embedded within Perl programs by including it as a module and calling its methods.</S>
    <S sid="43" ssid="5">The utility similarity.pl allows a user to measure specific pairs of concepts when given in word#pos#sense form.</S>
    <S sid="44" ssid="6">For example, car#n#3 refers to the third WordNet noun sense of car.</S>
    <S sid="45" ssid="7">It also allows for the specification of all the possible senses associated with a word or word#pos combination.</S>
    <S sid="46" ssid="8">For example, in Figure 1, the first command requests the value of the lin measure of similarity for the second noun sense of car (railway car) and the first noun sense of bus (motor coach).</S>
    <S sid="47" ssid="9">The second command will return the score of the pair of concepts that have the highest similarity value for the nouns car and bus.</S>
    <S sid="48" ssid="10">In the third command, the &#8211;allsenses switch causes the similarity measurements of all the noun senses of car to be calculated relative to the first noun sense of bus.</S>
    <S sid="49" ssid="11">WordNet::Similarity is implemented with Perl&#8217;s object oriented features.</S>
    <S sid="50" ssid="12">It uses the WordNet::QueryData package (Rennie, 2000) to create an object representing WordNet.</S>
    <S sid="51" ssid="13">There are a number of methods available that allow for the inclusion of existing measures in Perl source code, and also for the development of new measures.</S>
    <S sid="52" ssid="14">When an existing measure is to be used, an object of that measure must be created via the new() method.</S>
    <S sid="53" ssid="15">Then the getRelatedness() method can be called for a pair of word senses, and this will return the relatedness value.</S>
    <S sid="54" ssid="16">For example, the program in Figure 2 creates an object of the lin measure, and then finds the similarity between the first sense of the noun car (automobile) and the second sense of the noun bus (network bus).</S>
    <S sid="55" ssid="17">WordNet::Similarity enables detailed tracing that shows a variety of diagnostic information specific to each of the different kinds of measures.</S>
    <S sid="56" ssid="18">For example, for the measures that rely on path lengths (lch, wup, path) the tracing shows all the paths found between the concepts.</S>
    <S sid="57" ssid="19">Tracing for the information content measures (res, lin, jcn) includes both the paths between concepts as well as the least common subsumer.</S>
    <S sid="58" ssid="20">Tracing for the hso measure shows the actual paths found through WordNet, while the tracing for lesk shows the gloss overlaps in WordNet found for the two concepts and their nearby relatives.</S>
    <S sid="59" ssid="21">The vector tracing shows the word vectors that are used to create the gloss vector of a concept.</S>
  </SECTION>
  <SECTION title="5 Software Architecture" number="5">
    <S sid="60" ssid="1">Similarity.pm is the super class of all modules, and provides general services used by all of the measures such as validation of synset identifier input, tracing, and caching of results.</S>
    <S sid="61" ssid="2">There are four modules that provide all of the functionality required by any of the supported measures: PathFinder.pm, ICFinder.pm, DepthFinder.pm, and LCSFinder.pm.</S>
    <S sid="62" ssid="3">PathFinder.pm provides getAllPaths(), which finds all of the paths and their lengths between two input synsets, and getShortestPath() which determines the length of the shortest path between two concepts.</S>
    <S sid="63" ssid="4">ICFinder.pm includes the method IC(), which gets the information content value of a synset. probability() and getFrequency() find the probability and frequency count of a synset based on whatever corpus has been used to compute information content.</S>
    <S sid="64" ssid="5">Note that these values are pre&#8211;computed, so these methods are simply reading from an information content file.</S>
    <S sid="65" ssid="6">DepthFinder.pm provides methods that read values that have been pre&#8211;computed by the wnDepths.pl utility.</S>
    <S sid="66" ssid="7">This program finds the depth of every synset in WordNet, and also shows the is&#8211;a hierarchy in which a synset occurs.</S>
    <S sid="67" ssid="8">If a synset has multiple parents, then each possible depth and home hierarchy is returned.</S>
    <S sid="68" ssid="9">The depth of a synset is returned by getDepthOfSynset() and getTaxonomyDepth() provides the maximum depth for a given is&#8211;a hierarchy.</S>
    <S sid="69" ssid="10">LCSFinder.pm provides methods that find the least common subsumer of two concepts using three different criteria.</S>
    <S sid="70" ssid="11">These are necessary since there is multiple inheritance of concepts in WordNet, and different LCS can be selected for a pair of concepts if one or both of them have multiple parents in an is&#8211;a hiearchy. getLCSbyIC() chooses the LCS for a pair of concepts that has the highest information content, getLCSbyDepth() selects the LCS with the greatest depth, and getLCSbyPath() selects the LCS that results in the shortest path.</S>
  </SECTION>
  <SECTION title="6 Related Work" number="6">
    <S sid="71" ssid="1">Our work with measures of semantic similarity and relatedness began while adapting the Lesk Algorithm for word sense disambiguation to WordNet (Banerjee and Pedersen, 2002).</S>
    <S sid="72" ssid="2">That evolved in a generalized approach to disambiguation based on semantic relatedness (Patwardhan et al., 2003) that is implemented in the SenseRelate package (http://senserelate.sourceforge.net), which utilizes WordNet::Similarity.</S>
    <S sid="73" ssid="3">The premise behind this algorithm is that the sense of a word can be determined by finding which of its senses is most related to the possible senses of its neighbors.</S>
    <S sid="74" ssid="4">WordNet::Similarity has been used by a number of other researchers in an interesting array of domains.</S>
    <S sid="75" ssid="5">(Zhang et al., 2003) use it as a source of semantic features for identifying cross&#8211;document structural relationships between pairs of sentences found in related documents.</S>
    <S sid="76" ssid="6">(McCarthy et al., 2004) use it in conjunction with a thesaurus derived from raw text in order to automatically identify the predominent sense of a word.</S>
    <S sid="77" ssid="7">(Jarmasz and Szpakowicz, 2003) compares measures of similarity derived from WordNet and Roget&#8217;s Thesaurus.</S>
    <S sid="78" ssid="8">The comparisons are based on correlation with human relatedness values, as well as the TOEFL synonym identification tasks.</S>
    <S sid="79" ssid="9">(Baldwin et al., 2003) use WordNet::Similarity to provide an evaluation tool for multiword expressions that are identified via Latent Semantic Analysis.</S>
    <S sid="80" ssid="10">(Diab, 2003) combines a number of similarity measures that are then used as a feature in the disambiguation of verb senses.</S>
  </SECTION>
  <SECTION title="7 Availability" number="7">
    <S sid="81" ssid="1">WordNet::Similarity is written in Perl and is freely distributed under the Gnu Public License.</S>
    <S sid="82" ssid="2">It is available from the Comprehensive Perl Archive Network (http://search.cpan.org/dist/WordNet-Similarity) and via SourceForge, an Open Source development platform (http://wn-similarity.sourceforge.net).</S>
  </SECTION>
  <SECTION title="8 Acknowledgements" number="8">
    <S sid="83" ssid="1">WordNet::Similarity was preceeded by the distance.pl program, which was released in June 2002.</S>
    <S sid="84" ssid="2">This was converted into the object oriented WordNet::Similarity package, which was first released in April 2003 as version 0.03.</S>
    <S sid="85" ssid="3">The most current version as of this writing is 0.07, which was released in March 2004.</S>
    <S sid="86" ssid="4">The distance.pl program and all versions of WordNet::Similarity up to and including 0.06 were designed and implemented by Siddharth Patwardhan as a part of his Master&#8217;s thesis at the University of Minnesota, Duluth.</S>
    <S sid="87" ssid="5">Version 0.07 was designed and implemented by Jason Michelizzi as a part of his Master&#8217;s thesis.</S>
    <S sid="88" ssid="6">The lesk measure in WordNet::Similarity was originally designed and implemented by Satanjeev Banerjee, who developed this measure as a part of his Master&#8217;s thesis at the University of Minnesota, Duluth.</S>
    <S sid="89" ssid="7">Thereafter Siddharth Patwardhan ported this measure to WordNet::Similarity.</S>
    <S sid="90" ssid="8">This work has been partially supported by a National Science Foundation Faculty Early CAREER Development award (#0092784), and by a Grant-in-Aid of Research, Artistry and Scholarship from the Office of the Vice President for Research and the Dean of the Graduate School of the University of Minnesota.</S>
  </SECTION>
</PAPER>
