<PAPER>
  <S sid="0">Tree-To-String Alignment Template For Statistical Machine Translation</S>
  <ABSTRACT>
    <S sid="1" ssid="1">We present a novel translation model on alignment template (TAT) which describes the alignment between a source parse tree and a target string.</S>
    <S sid="2" ssid="2">A TAT is capable of generating both terminals and non-terminals and performing reordering at both low and high levels.</S>
    <S sid="3" ssid="3">The model is linguistically syntaxbased because TATs are extracted automatically from word-aligned, source side parsed parallel texts.</S>
    <S sid="4" ssid="4">To translate a source sentence, we first employ a parser to produce a source parse tree and then apply TATs to transform the tree into a target string.</S>
    <S sid="5" ssid="5">Our experiments show that the TAT-based model significantly outperforms Pharaoh, a state-of-the-art decoder for phrase-based models.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="6" ssid="1">Phrase-based translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004), which go beyond the original IBM translation models (Brown et al., 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations.</S>
    <S sid="7" ssid="2">In phrase-based models, phrases are usually strings of adjacent words instead of syntactic constituents, excelling at capturing local reordering and performing translations that are localized to from that paper: a source string fJ1 = f1, ... ,fj, ... , fJ is to be translated into a target string eI1 = el, ... , ei, ... , eI.</S>
    <S sid="8" ssid="3">Here, I is the length of the target string, and J is the length of the source string. substrings that are common enough to be observed on training data.</S>
    <S sid="9" ssid="4">However, a key limitation of phrase-based models is that they fail to model reordering at the phrase level robustly.</S>
    <S sid="10" ssid="5">Typically, phrase reordering is modeled in terms of offset positions at the word level (Koehn, 2004; Och and Ney, 2004), making little or no direct use of syntactic information.</S>
    <S sid="11" ssid="6">Recent research on statistical machine translation has lead to the development of syntax-based models.</S>
    <S sid="12" ssid="7">Wu (1997) proposes Inversion Transduction Grammars, treating translation as a process of parallel parsing of the source and target language via a synchronized grammar.</S>
    <S sid="13" ssid="8">Alshawi et al. (2000) represent each production in parallel dependency tree as a finite transducer.</S>
    <S sid="14" ssid="9">Melamed (2004) formalizes machine translation problem as synchronous parsing based on multitext grammars.</S>
    <S sid="15" ssid="10">Graehl and Knight (2004) describe training and decoding algorithms for both generalized tree-to-tree and tree-to-string transducers.</S>
    <S sid="16" ssid="11">Chiang (2005) presents a hierarchical phrasebased model that uses hierarchical phrase pairs, which are formally productions of a synchronous context-free grammar.</S>
    <S sid="17" ssid="12">Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insert grammar, a version of synchronous grammars defined on dependency trees.</S>
    <S sid="18" ssid="13">All these approaches, though different in formalism, make use of synchronous grammars or tree-based transduction rules to model both source and target languages.</S>
    <S sid="19" ssid="14">Another class of approaches make use of syntactic information in the target language alone, treating the translation problem as a parsing problem.</S>
    <S sid="20" ssid="15">Yamada and Knight (2001) use a parser in the target language to train probabilities on a set of operations that transform a target parse tree into a source string.</S>
    <S sid="21" ssid="16">Paying more attention to source language analysis, Quirk et al. (2005) employ a source language dependency parser, a target language word segmentation component, and an unsupervised word alignment component to learn treelet translations from parallel corpus.</S>
    <S sid="22" ssid="17">In this paper, we propose a statistical translation model based on tree-to-string alignment template which describes the alignment between a source parse tree and a target string.</S>
    <S sid="23" ssid="18">A TAT is capable of generating both terminals and non-terminals and performing reordering at both low and high levels.</S>
    <S sid="24" ssid="19">The model is linguistically syntax-based because TATs are extracted automatically from word-aligned, source side parsed parallel texts.</S>
    <S sid="25" ssid="20">To translate a source sentence, we first employ a parser to produce a source parse tree and then apply TATs to transform the tree into a target string.</S>
    <S sid="26" ssid="21">One advantage of our model is that TATs can be automatically acquired to capture linguistically motivated reordering at both low (word) and high (phrase, clause) levels.</S>
    <S sid="27" ssid="22">In addition, the training of TAT-based model is less computationally expensive than tree-to-tree models.</S>
    <S sid="28" ssid="23">Similarly to (Galley et al., 2004), the tree-to-string alignment templates discussed in this paper are actually transformation rules.</S>
    <S sid="29" ssid="24">The major difference is that we model the syntax of the source language instead of the target side.</S>
    <S sid="30" ssid="25">As a result, the task of our decoder is to find the best target string while Galley&#8217;s is to seek the most likely target tree.</S>
  </SECTION>
  <SECTION title="2 Tree-to-String Alignment Template" number="2">
    <S sid="31" ssid="1">A tree-to-string alignment template z is a triple T, 5, A), which describes the alignment A between a source parse tree T = T(FJ' 1 ) 2 and a target string 5 = E&#65533;' is also composed of both terminals (target words) and non-terminals (placeholders).</S>
    <S sid="32" ssid="2">An alignment A is defined as a subset of the Cartesian product of source and target symbol positions: 2We use T(&#183;) to denote a parse tree.</S>
    <S sid="33" ssid="3">To reduce notational overhead, we use T(z) to represent the parse tree in z.</S>
    <S sid="34" ssid="4">Similarly, S(z) denotes the string in z.</S>
    <S sid="35" ssid="5">In the following, we formally describe how to introduce tree-to-string alignment templates into probabilistic dependencies to model Pr(ei|fJ1 ) 3.</S>
    <S sid="36" ssid="6">In a first step, we introduce the hidden variable T(fJ1 ) that denotes a parse tree of the source senNext, another hidden variable D is introduced to detach the source parse tree T (fJ1 ) into a sequence of K subtrees T 1K with a preorder transversal.</S>
    <S sid="37" ssid="7">We assume that each subtree Tk produces a target string 5k.</S>
    <S sid="38" ssid="8">As a result, the sequence of subtrees T&#65533;1K produces a sequence of target strings &#65533;5K1 , which can be combined serially to generate the target sentence ei.</S>
    <S sid="39" ssid="9">We assume that Pr(e,|D,T(fJ1 ),fJ1) = Pr(&#65533;5K1|T&#65533;1K) because ei is actually generated by the derivation of &#65533;5K1 .</S>
    <S sid="40" ssid="10">Note that we omit an explicit dependence on the detachment D to avoid notational overhead.</S>
    <S sid="41" ssid="11">3The notational convention will be as follows.</S>
    <S sid="42" ssid="12">We use the symbol Pr(&#183;) to denote general probability distribution with no specific assumptions.</S>
    <S sid="43" ssid="13">In contrast, for model-based probability distributions, we use generic symbol p(&#183;).</S>
    <S sid="44" ssid="14">To further decompose Pr(&#732;S |T&#732;), the tree-tostring alignment template, denoted by the variable z, is introduced as a hidden variable.</S>
    <S sid="45" ssid="15">&#8658; X3 X4 of China &#8658; economic X4 of China &#8658; economic development of China Following Och and Ney (2002), we base our model on log-linear framework.</S>
    <S sid="46" ssid="16">Hence, all knowledge sources are described as feature functions that include the given source string fJ1 , the target string eI1, and hidden variables.</S>
    <S sid="47" ssid="17">The hidden variable T(fJ1 ) is omitted because we usually make use of only single best output of a parser.</S>
    <S sid="48" ssid="18">As we assume that all detachment have the same probability, the hidden variable D is also omitted.</S>
    <S sid="49" ssid="19">As a result, the model we actually adopt for experiments is limited because the parse, detachment, and TAT application sub-models are simplified.</S>
    <S sid="50" ssid="20">For our experiments we use the following seven feature functions 4 that are analogous to default feature set of Pharaoh (Koehn, 2004).</S>
    <S sid="51" ssid="21">To simplify the notation, we omit the dependence on the hidden variables of the model.</S>
    <S sid="52" ssid="22">Therefore, the TAT-based translation model can be decomposed into four sub-models: Figure 2 shows how TATs work to perform translation.</S>
    <S sid="53" ssid="23">First, the input source sentence is parsed.</S>
    <S sid="54" ssid="24">Next, the parse tree is detached into five subtrees with a preorder transversal.</S>
    <S sid="55" ssid="25">For each subtree, a TAT is selected and applied to produce a string.</S>
    <S sid="56" ssid="26">Finally, these strings are combined serially to generate the translation (we use X to denote the non-terminal): 4When computing lexical weighting features (Koehn et al., 2003), we take only terminals into account.</S>
    <S sid="57" ssid="27">If there are no terminals, we set the feature value to 1.</S>
    <S sid="58" ssid="28">We use lex(&#183;) to denote lexical weighting.</S>
    <S sid="59" ssid="29">We denote the number of TATs used for decoding by K and the length of target string by L</S>
  </SECTION>
  <SECTION title="3 Training" number="3">
    <S sid="60" ssid="1">To extract tree-to-string alignment templates from a word-aligned, source side parsed sentence pair hT (fJ1 ), eI1, Ai, we need first identify TSAs (TreeString-Alignment) using similar criterion as suggested in (Och and Ney, 2004).</S>
    <S sid="61" ssid="2">A TSA is a triple Usually, we can extract a very large amount of TATs from training data using the above rules, making both training and decoding very slow.</S>
    <S sid="62" ssid="3">Therefore, we impose three restrictions to reduce the magnitude of extracted TATs: This constraint requires that both the first and last symbols in the target string must be aligned to some source symbols.</S>
    <S sid="63" ssid="4">Table 1 shows the TATs extracted from the TSA in Figure 3 with h = 2 and c = 2.</S>
    <S sid="64" ssid="5">As we restrict that T(fj2 j1 ) must be a subtree of T(fJ1 ), TATs may be treated as syntactic hierarchical phrase pairs (Chiang, 2005) with tree structure on the source side.</S>
    <S sid="65" ssid="6">At the same time, we face the risk of losing some useful non-syntactic phrase pairs.</S>
    <S sid="66" ssid="7">For example, the phrase pair +{' AOL ALA H President Bush made can never be obtained in form of TAT from the TSA in Figure 3 because there is no subtree for that source string.</S>
  </SECTION>
  <SECTION title="4 Decoding" number="4">
    <S sid="67" ssid="1">We approach the decoding problem as a bottom-up beam search.</S>
    <S sid="68" ssid="2">To translate a source sentence, we employ a parser to produce a parse tree.</S>
    <S sid="69" ssid="3">Moving bottomup through the source parse tree, we compute a list of candidate translations for the input subtree rooted at each node with a postorder transversal.</S>
    <S sid="70" ssid="4">Candidate translations of subtrees are placed in stacks.</S>
    <S sid="71" ssid="5">Figure 4 shows the organization of candidate translation stacks.</S>
    <S sid="72" ssid="6">A candidate translation contains the following information: A TAT z is usable to a parse tree T if and only if T(z) is rooted at the root of T and covers part of nodes of T. Given a parse tree T, we find all usable TATs.</S>
    <S sid="73" ssid="7">Given a usable TAT z, if T(z) is equal to T, then 5(z) is a candidate translation of T. If T(z) covers only a portion of T, we have to compute a list of candidate translations for T by replacing the non-terminals of 5(z) with candidate translations of the corresponding uncovered subtrees.</S>
    <S sid="74" ssid="8">For example, when computing the candidate translations for the tree rooted at node 8, the TAT used in Figure 5 covers only a portion of the parse tree in Figure 4.</S>
    <S sid="75" ssid="9">There are two uncovered subtrees that are rooted at node 2 and node 7 respectively.</S>
    <S sid="76" ssid="10">Hence, we replace the third symbol with the candidate translations in stack 2 and the first symbol with the candidate translations in stack 7.</S>
    <S sid="77" ssid="11">At the same time, the feature values and probabilities are also accumulated for the new candidate translations.</S>
    <S sid="78" ssid="12">To speed up the decoder, we limit the search space by reducing the number of TATs used for each input node.</S>
    <S sid="79" ssid="13">There are two ways to limit the TAT table size: by a fixed limit (tatTable-limit) of how many TATs are retrieved for each input node, and by a probability threshold (tatTable-threshold) that specify that the TAT probability has to be above some value.</S>
    <S sid="80" ssid="14">On the other hand, instead of keeping the full list of candidates for a given node, we keep a top-scoring subset of the candidates.</S>
    <S sid="81" ssid="15">This can also be done by a fixed limit (stack-limit) or a threshold (stack-threshold).</S>
    <S sid="82" ssid="16">To perform recombination, we combine candidate translations that share the same leading and trailing bigrams in each stack.</S>
  </SECTION>
  <SECTION title="5 Experiments" number="5">
    <S sid="83" ssid="1">Our experiments were on Chinese-to-English translation.</S>
    <S sid="84" ssid="2">The training corpus consists of 31,149 sentence pairs with 843,256 Chinese words and 949, 583 English words.</S>
    <S sid="85" ssid="3">For the language model, we used SRI Language Modeling Toolkit (Stolcke, 2002) to train a trigram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998) on the 31,149 English sentences.</S>
    <S sid="86" ssid="4">We selected 571 short sentences from the 2002 NIST MT Evaluation test set as our development corpus, and used the 2005 NIST MT Evaluation test set as our test corpus.</S>
    <S sid="87" ssid="5">We evaluated the translation quality using the BLEU metric (Papineni et al., 2002), as calculated by mteval-v11b.pl with its default setting except that we used case-sensitive matching of n-grams.</S>
    <S sid="88" ssid="6">The baseline system we used for comparison was Pharaoh (Koehn et al., 2003; Koehn, 2004), a freely available decoder for phrase-based translation models: We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule &#8220;diagand&#8221; described in (Koehn et al., 2003) to obtain a single many-to-many word alignment for each sentence pair.</S>
    <S sid="89" ssid="7">After that, we used some heuristics, which including rule-based translation of numbers, dates, and person names, to further improve the alignment accuracy.</S>
    <S sid="90" ssid="8">Given the word-aligned bilingual corpus, we obtained 1, 231, 959 bilingual phrases (221, 453 used on test corpus) using the training toolkits publicly released by Philipp Koehn with its default setting.</S>
    <S sid="91" ssid="9">To perform minimum error rate training (Och, 2003) to tune the feature weights to maximize the system&#8217;s BLEU score on development set, we used optimizeV5IBMBLEU.m (Venugopal and Vogel, 2005).</S>
    <S sid="92" ssid="10">We used default pruning settings for Pharaoh except that we set the distortion limit to 4.</S>
    <S sid="93" ssid="11">On the same word-aligned training data, it took us about one month to parse all the 31,149 Chinese sentences using a Chinese parser written by Deyi Xiong (Xiong et al., 2005).</S>
    <S sid="94" ssid="12">The parser was trained on articles 1 &#8722; 270 of Penn Chinese Treebank version 1.0 and achieved 79.4% (F1 measure) as well as a 4.4% relative decrease in error rate.</S>
    <S sid="95" ssid="13">Then, we performed TAT extraction described in section 3 with h = 3 and c = 5 and obtained 350,575 TATs (88,066 used on test corpus).</S>
    <S sid="96" ssid="14">To run our decoder Lynx on development and test corpus, we set tatTable-limit = 20, tatTable-threshold = 0, stack-limit = 100, and stack-threshold = 0.00001.</S>
    <S sid="97" ssid="15">Table 2 shows the results on test set using Pharaoh and Lynx with different feature settings.</S>
    <S sid="98" ssid="16">The 95% confidence intervals were computed using Zhang&#8217;s significance tester (Zhang et al., 2004).</S>
    <S sid="99" ssid="17">We modified it to conform to NIST&#8217;s current definition of the BLEU brevity penalty.</S>
    <S sid="100" ssid="18">For Pharaoh, eight features were used: distortion model d, a trigram language model lm, phrase translation probabilities O(f|e) and O(e|f), lexical weightings lex(f|e) and lex(e|f), phrase penalty pp, and word penalty wp.</S>
    <S sid="101" ssid="19">For Lynx, seven features described in section 2 were used.</S>
    <S sid="102" ssid="20">We find that Lynx outperforms Pharaoh with all feature settings.</S>
    <S sid="103" ssid="21">With full features, Lynx achieves an absolute improvement of 0.006 over Pharaoh (3.1% relative).</S>
    <S sid="104" ssid="22">This difference is statistically significant (p &lt; 0.01).</S>
    <S sid="105" ssid="23">Note that Lynx made use of only 88,066 TATs on test corpus while 221, 453 bilingual phrases were used for Pharaoh.</S>
    <S sid="106" ssid="24">The feature weights obtained by minimum error rate training for both Pharaoh and Lynx are shown in Table 3.</S>
    <S sid="107" ssid="25">We find that &#966;(f|e) (i.e. h2) is not a helpful feature for Lynx.</S>
    <S sid="108" ssid="26">The reason is that we use only a single non-terminal symbol instead of assigning phrasal categories to the target string.</S>
    <S sid="109" ssid="27">In addition, we allow the target string consists of only non-terminals, making translation decisions not always based on lexical evidence.</S>
    <S sid="110" ssid="28">It is interesting to use bilingual phrases to strengthen the TAT-based model.</S>
    <S sid="111" ssid="29">As we mentioned before, some useful non-syntactic phrase pairs can never be obtained in form of TAT because we restrict that there must be a corresponding parse tree for the source phrase.</S>
    <S sid="112" ssid="30">Moreover, it takes more time to obtain TATs than bilingual phrases on the same training data because parsing is usually very time-consuming.</S>
    <S sid="113" ssid="31">Given an input subtree T (Fj&#65533; j&#65533; ), if Fj&#65533; j&#65533; is a string of terminals, we find all bilingual phrases that the source phrase is equal to Fj&#65533; j&#65533; .</S>
    <S sid="114" ssid="32">Then we build a TAT for each bilingual phrase (fJ, 1 , A): the tree of the TAT is T (Fj&#65533; j&#65533; ), the string is eI, 1 , and the alignment is A.</S>
    <S sid="115" ssid="33">If a TAT built from a bilingual phrase is the same with a TAT in the TAT table, we prefer to the greater translation probabilities.</S>
    <S sid="116" ssid="34">Table 4 shows the effect of using bilingual phrases for Lynx.</S>
    <S sid="117" ssid="35">Note that these bilingual phrases are the same with those used for Pharaoh.</S>
    <S sid="118" ssid="36">We also conducted an experiment on large data to further examine our design philosophy.</S>
    <S sid="119" ssid="37">The training corpus contains 2.6 million sentence pairs.</S>
    <S sid="120" ssid="38">We used all the data to extract bilingual phrases and a portion of 800K pairs to obtain TATs.</S>
    <S sid="121" ssid="39">Two trigram language models were used for Lynx.</S>
    <S sid="122" ssid="40">One was trained on the 2.6 million English sentences and another was trained on the first 1/3 of the Xinhua portion of Gigaword corpus.</S>
    <S sid="123" ssid="41">We also included rule-based translations of named entities, dates, and numbers.</S>
    <S sid="124" ssid="42">By making use of these data, Lynx achieves a BLEU score of 0.2830 on the 2005 NIST Chinese-to-English MT evaluation test set, which is a very promising result for linguistically syntax-based models.</S>
  </SECTION>
  <SECTION title="6 Conclusion" number="6">
    <S sid="125" ssid="1">In this paper, we introduce tree-to-string alignment templates, which can be automatically learned from syntactically-annotated training data.</S>
    <S sid="126" ssid="2">The TAT-based translation model improves translation quality significantly compared with a stateof-the-art phrase-based decoder.</S>
    <S sid="127" ssid="3">Treated as special TATs without tree on the source side, bilingual phrases can be utilized for the TAT-based model to get further improvement.</S>
    <S sid="128" ssid="4">It should be emphasized that the restrictions we impose on TAT extraction limit the expressive power of TAT.</S>
    <S sid="129" ssid="5">Preliminary experiments reveal that removing these restrictions does improve translation quality, but leads to large memory requirements.</S>
    <S sid="130" ssid="6">We feel that both parsing and word alignment qualities have important effects on the TATbased model.</S>
    <S sid="131" ssid="7">We will retrain the Chinese parser on Penn Chinese Treebank version 5.0 and try to improve word alignment quality using log-linear models as suggested in (Liu et al., 2005).</S>
  </SECTION>
  <SECTION title="Acknowledgement" number="7">
    <S sid="132" ssid="1">This work is supported by National High Technology Research and Development Program contract &#8220;Generally Technical Research and Basic Database Establishment of Chinese Platform&#8221;(Subject No.</S>
    <S sid="133" ssid="2">2004AA114010).</S>
    <S sid="134" ssid="3">We are grateful to Deyi Xiong for providing the parser and Haitao Mi for making the parser more efficient and robust.</S>
    <S sid="135" ssid="4">Thanks to Dr. Yajuan Lv for many helpful comments on an earlier draft of this paper.</S>
  </SECTION>
</PAPER>
