<PAPER>
  <S sid="0" ssid="0">Automatic Acquisition of Domain Knowledge for Information Extraction Roman Yangarber, Ralph Grishman Past Tapanainen Courant  Inst i tute of Conexor oy Mathemat ica l  Sciences Helsinki, F in land New York University {roman [ grishman}@cs, nyu.</S>
  <S sid="1" ssid="1">Tapanainen@conexor.</S>
  <S sid="2" ssid="2">fi Si!ja Ituttunen University of Helsinki F inland sihuttun@ling.helsinki.fi Abstract In developing an Infbrmation Extraction tIE) system tbr a new class of events or relations, one of the major tasks is identifying the many ways in which these events or relations may be ex- pressed in text.</S>
  <S sid="3" ssid="3">This has generally involved the manual analysis and, in some cases, the anno- tation of large quantities of text involving these events.</S>
  <S sid="4" ssid="4">This paper presents an alternative ap- proach, based on an automatic discovery pro- cedure, ExDIsCO, which identifies a set; of rele- wmt documents and a set of event patterns from un-annotated text, starting from a small set of "seed patterns."</S>
  <S sid="5" ssid="5">We evaluate ExDIScO by com- paring the pertbrmance of discovered patterns against that of manually constructed systems on actual extraction tasks.</S>
  <S sid="6" ssid="6">0 Introduct ion Intbrmation Extraction is the selective xtrac- tion of specified types of intbrmation from nat- ural language text.</S>
  <S sid="7" ssid="7">The intbrmation to be extracted may consist of particular semantic classes of objects (entities), relationships among these entities, and events in which these entities participate.</S>
  <S sid="8" ssid="8">The extraction system places this intbrmation into a data base tbr retrieval and subsequent processing.</S>
  <S sid="9" ssid="9">In this paper we shall be concerned primar- ily with the extraction of intbrmation about events.</S>
  <S sid="10" ssid="10">In the terminology which has evolved tiom the Message Understanding Conferences (muc, 1995; muc, 1993), we shall use the term subject domain to refer to a broad class of texts, such as business news, and tile term scenario to refer to tile specification of tile particular events to be extracted.</S>
  <S sid="11" ssid="11">For example, the "Manage- ment Succession" scenario for MUC-6, which we shall refer to throughout this paper, involves in- formation about corporate executives tarting and leaving positions.</S>
  <S sid="12" ssid="12">The fundamental problem we face in port- ing an extraction system to a new scenario is to identify the many ways in which intbrmation about a type of event may be expressed in the text;.</S>
  <S sid="13" ssid="13">Typically, there will be a few common tbrms of expression which will quickly come to nfind when a system is being developed.</S>
  <S sid="14" ssid="14">How- ever, the beauty of natural language (and the challenge tbr computational linguists) is that there are many variants which an imaginative writer cast use, and which the system needs to capture.</S>
  <S sid="15" ssid="15">Finding these variants may involve studying very large amounts of text; in the sub- ject domain.</S>
  <S sid="16" ssid="16">This has been a major impediment to the portability and performance of event ex- traction systems.</S>
  <S sid="17" ssid="17">We present; in this paper a new approach to finding these variants automatically flom a large corpus, without the need to read or amLo- tate the corpus.</S>
  <S sid="18" ssid="18">This approach as been evalu- ated on actual event extraction scenarios.</S>
  <S sid="19" ssid="19">In the next section we outline the strncture of our extraction system, and describe the discov- ery task in the context of this system.</S>
  <S sid="20" ssid="20">Sections 2 and 3 describe our algorithm for pattern dis- covery; section 4 describes our experimental re- sults.</S>
  <S sid="21" ssid="21">This is tbllowed by comparison with prior work and discussion in section 5.</S>
  <S sid="22" ssid="22">1 The Extract ion System In the simplest terms, an extraction system identifies patterns within the text, and then mat)s some constituents of these patterns into data base entries.</S>
  <S sid="23" ssid="23">(This very simple descrip- lion ignores the problems of anaphora nd in- tersentential inference, which must be addressed by any general event extraction system.)</S>
  <S sid="24" ssid="24">AI- though these l)atterns could in principle be stated in terms of individual words, it is much 940 easier to state them in terms of larger SylltaC- tic constituents, uch as noun phrases and verb groups.</S>
  <S sid="25" ssid="25">Consequently, extraction ormally con- sists of an analysis of the l;e.xt in terms of general linguistic structures and dolnain-specifio con- structs, tbllowed by a search for the scenario- specific patterns.</S>
  <S sid="26" ssid="26">It is possible to build these constituent struc- tures through a flfll syntactic analysis of the text, and the discovery procedure we describe below woul(1 be applicable to such an architec- ture.</S>
  <S sid="27" ssid="27">Howe, ver, for re&amp;sellS of slme,(t , coverage, and system rolmstness, the more (:ommon ap- t)roa(:h at present is to peribrni a t)artial syn- tactic analysis using a cascade of finite-state transducers.</S>
  <S sid="28" ssid="28">This is the at)t)roa(:h used by our e.xtraction system (Grishman, 1995; Yangarber and Grishman, 1998).</S>
  <S sid="29" ssid="29">At; the heart of our syslxan is a regular ex- pression pattern matcher which is Cal)al)le of matching a set of regular exl)ressions against a partially-analyzed text and producing addi- tional annotations on the text.</S>
  <S sid="30" ssid="30">This core draws on a set of knowledge bases of w~rying degrees of domain- and task-specificity.</S>
  <S sid="31" ssid="31">The lexicon in- cludes both a general English dictionary and definitions of domain and scenario terms.</S>
  <S sid="32" ssid="32">The concept base arranges the domain terms into a semantic hierarchy.</S>
  <S sid="33" ssid="33">The predicate base.</S>
  <S sid="34" ssid="34">de- s(ribes the, logical structure of I;he events to be extracl;od.</S>
  <S sid="35" ssid="35">Fire pattern ])ase consists of sets of patterns (with associated actions), whi(;h make r(;ferollCO to information Kern the other knowl- e(lge bases.</S>
  <S sid="36" ssid="36">Some t)attorn sots, su(:h as those for n(mn and verb groups, are broadly apl)licable , wlfile other sets are spe(:ifio to the scenario.</S>
  <S sid="37" ssid="37">V~Ze, have previously (Yangarl)er and Grish- man, 1.997) (lescrit)ed a user interface which supt)orts the rapid cust;omization of the extrac- tion system to a new scenario.</S>
  <S sid="38" ssid="38">This interface allows the user to provide examples of role- wmt events, which are automatically converted into the appropriate patterns and generalized to cover syntactic variants (passive, relative clause, etc.).</S>
  <S sid="39" ssid="39">Through this internee, the user can also generalize l;he pattern semanti(ally (to (:over a broader class of words) and modify the concet)t base and lexicon as needed.</S>
  <S sid="40" ssid="40">Given an appro- priate set; of examples, thereibre, it; has become possible to adapt the extraction system quite ral)idly.</S>
  <S sid="41" ssid="41">However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.</S>
  <S sid="42" ssid="42">Reducing this cost is essential for enhanced system portability; this is the problem addressed by the current research.</S>
  <S sid="43" ssid="43">Ilow can we automatically discover a suitable set; of candidate patterns or examples (patterns which at least have a high likelihood of being relevant to the scenario)?</S>
  <S sid="44" ssid="44">The basic idea is to look for linguistic patterns which apt)ear with relatively high frequency in relevant documents.</S>
  <S sid="45" ssid="45">While there has been prior research oll idea|i- lying the primary lexical t)atterns of a sublan- guage or cortms (Orishman et al, 1986; Riloff, 1996), the task here is more complex, since we are tyt)ically not provided in advance with a sub-corpus of relevmlt passages; these passages must themselves be tbund as part of t;t1(; discov- ery i)rocedure.</S>
  <S sid="46" ssid="46">The difficulty is that one of the l)est imlic~tions of the relevance of the passages is t)recisely the t)resence of these constructs.</S>
  <S sid="47" ssid="47">Bo- (:ause of this (:ircularity, we l)ropose to a(:quire.</S>
  <S sid="48" ssid="48">the constructs and t)assagos in tandem.</S>
  <S sid="49" ssid="49">2 ExDISCO: the  D iscovery  P rocedure We tirst outline ExDIsco ,  our procedure for discovery of oxl,raction patterns; details of some of the stops arc l)rcse, nted in the section which follows, and an earlier t)~q)er on our at)l)roach (Yang~u:bcr ot al., 2000).</S>
  <S sid="50" ssid="50">ExDIscO is mi ml- supervised 1)rocedure: the training (:ortms does not need to t)e amlotated with the specific event intbrmatkm to be.</S>
  <S sid="51" ssid="51">e.xtracted, or oven with infor- mation as to whi(;h documents in the (orpus are relevant o the scenario.</S>
  <S sid="52" ssid="52">i7tlo only intbrmation the user must provide, as described below, is a small set of seed patterns regarding the s(:enario.</S>
  <S sid="53" ssid="53">Starting with this seed, the system automati- (:ally pertbnns a repeated, automatic expansion of the pattern set.</S>
  <S sid="54" ssid="54">This is analogous to the pro- cess of automatic t;enn expansion used in s()me information retrieval systems, where, the terlns Dora the most relewmt doculncnts are added to the user query and then a new retriewfl is imrformed.</S>
  <S sid="55" ssid="55">However, by expanding in terms of 1)atl;erns rather than individual terms, a more precise expansion is possit)le.</S>
  <S sid="56" ssid="56">This process pro- coeds as tbllows: 0.</S>
  <S sid="57" ssid="57">We stm:t with a large, corlms of documents in the domain (which have not been anne- 941 tared or classified in any way) and an initial "seed" of scenario patterns selected by the user - -  a small set of patterns whose pres- ence reliably indicates thai; the document is relevant o the scenario.</S>
  <S sid="58" ssid="58">The pattern set is used to divide the cor- tins U into a set of relewmt documents, R (which contain at; least one instance of one of the patterns), and a set of non-relevant documents R = U - R. 2.</S>
  <S sid="59" ssid="59">Search tbr new candidate patterns: ?</S>
  <S sid="60" ssid="60">automatically convert each document in the eorIms into a set of candidate patterns, one for each clause ?</S>
  <S sid="61" ssid="61">rank patterns by the degree to which their distribution is correlated with docmnent relevance (i.e., appears with higher frequency in relevant docu- ments than in non-relewmt ones).</S>
  <S sid="62" ssid="62">Add the highest ranking pattern to the pat- tern set.</S>
  <S sid="63" ssid="63">(Optionally, at this point, we may present he pattern to the user for review.)</S>
  <S sid="64" ssid="64">Use the new pattern set; to induce a new split of the corpus into relevant and non- relevant documents.</S>
  <S sid="65" ssid="65">More precisely, docu- ments will now be given a relevance confi- dence measure; documents containing one of the initial seed patterns will be given a score of 1, while documents which arc added to the relevant cortms through newly discovered patterns will be given a lower score.</S>
  <S sid="66" ssid="66">I/,epeat the procedure (from step 1) until some iteration limit is reached, or no more patterns can be added.</S>
  <S sid="67" ssid="67">3 Methodo logy 3.1 Pre-processing: Syntact ic Analysis Before at)plying ExDIsco ,  we pre-proeessed the cortms using a general-purpose d pendency parser of English.</S>
  <S sid="68" ssid="68">The parser is based on the FDG tbrmalism (Tapanainen and Jgrvi- hen, 1997) and developed by the Research Unit for Multilingual Language Technology at the University of Helsinki, and Conexor Oy.</S>
  <S sid="69" ssid="69">The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S>
  <S sid="70" ssid="70">We used a corlms of 9,224 articles from the Wall Street; Journal.</S>
  <S sid="71" ssid="71">The parsed arti- cles yielded a total of 440,000 clausal tuples, of which 215,000 were distinct.</S>
  <S sid="72" ssid="72">3.2 Normal izat ion We applied a name recognition module prior to parsing, and replaced each name with a token describing its (:lass, e.g.</S>
  <S sid="73" ssid="73">C-Person, C-Company, etc.</S>
  <S sid="74" ssid="74">We collapsed together all numeric expres- sions, currency wflues, dates, etc., using a single token to designate ach of these classes.</S>
  <S sid="75" ssid="75">Lastly, the parser performed syntactic normalization to transtbrm such variants ms the various passive and relative clauses into a common tbrm.</S>
  <S sid="76" ssid="76">3.3 General izat ion and Concept Classes Because tuples may not repeat with sufficient frequency to obtain reliable statistics, each tu- ple is reduced to a set of pints: e.g., a verb- object pair, a subject-object pair, etc.</S>
  <S sid="77" ssid="77">Each pair is used as a generalized pattern during the can- didate selection stage.</S>
  <S sid="78" ssid="78">Once we have identitied pairs which are relevant o the scenario, we use them to gather the set; of words for the miss- ing role(s) (tbr example, a class of verbs which occur with a relevant subject-ot@ct pair: "com- pany {hire/fire/expel...} person").</S>
  <S sid="79" ssid="79">3.4 Pat tern  Discovery We (-onducte(1 exi)eriments in several scenarios within news domains such as changes in cor- porate ownership, and natural disasters.</S>
  <S sid="80" ssid="80">Itere we present results on the "Man~geme.nt Suc- cession" and "Mergers/Acquisitions" cenarios.</S>
  <S sid="81" ssid="81">ExDIsco  was seeded with lninimal pattern sets, namely: Subject Verb Direct Object C-Company C-At)point C-Person C-Person C-Resign ibr the Mmmgement task, and Subject Verb Direct Object * C-Buy C-Conlt)any C-Company merge * for Acquisitions.</S>
  <S sid="82" ssid="82">Here C-Company and C- Person denote semantic classes containing named entities of the corresponding types.</S>
  <S sid="83" ssid="83">C- Appoint denotes the list of verbs { appoint, elect, promote, name, nominate}, C-Resign = { re- sign, depart, quit }, and C-Buy = { buy , pur- chase }.</S>
  <S sid="84" ssid="84">942 ])uring ~ single iter~tion, we conqmt(; the score, Seere(p), for each cm~(lidate 1)attern p, using (;he fornmla~: S, :o  ,  ,@)  = IH n l~l IHI - 1,,~ IHn  ~.1 (:t) where 12.</S>
  <S sid="85" ssid="85">(Icnotes (;h(, lclewmt subsc(; of docu- ments, mid I t=  It(p) the, ( locmnents imttching p, as above; the Iirst (;erm a(:(:ounts for the con- (lition~fl t)robabil ity of relev;m(e oil p~ and |;11(; second tbr its support .</S>
  <S sid="86" ssid="86">We further impose two support criteria: we distrust such frequent pat- (;,~.,-.~ w]le,:e I1~ n UI &gt; ,~IUI, ,~ uninforn,,~tive, mid rare patte.rns [or which I1] r-I ]~.1 &lt; fl as noise.</S>
  <S sid="87" ssid="87">2 At the end ot (.aeh il;eratiol~, the sysl;em selects the pal;tern with the highest Sco/d(p)~ and adds it (;o (;lie seed scl;.</S>
  <S sid="88" ssid="88">The (to(:un~enl;s which t;he winning t)~(;t;ern hits are added (;o t;111(; relevant set.</S>
  <S sid="89" ssid="89">The  t)al;l;(;rn s(;areh is then r(;sl;m:l;(;d. 3.5 Document  Re- rank ing Th(: above is a simt)lifi(;~l;ion of (;he a,(:tual pro- cedlll(}~ in severa] r(,st)e((;s. Only generalized t)ntl;erns are (:onsidered fi)r (:audi(t~my, with one or mot(, slol;s fill(:(1 wi(;h wihl-cmds.</S>
  <S sid="90" ssid="90">In comput ing the score of th(, ge, n- (;raliz(:d ]);tttern, w(: do not take into (onsi(h:r- ;i,1;i()11 all possible va,hw, s of the, wil(1-(m:d role.</S>
  <S sid="91" ssid="91">?e instea.d (:()llS(;raJll (;he wild-(:ar(l to thos(~ wd- u(:s wlli(:h l;ht,llls(;lv(;s ill (;llrH ]l;tV(: high scores.</S>
  <S sid="92" ssid="92">Th(:se v~du(:s l;lw, n |)e(:on~e lllClll])(;lS of }/.</S>
  <S sid="93" ssid="93">II(:W (:lass, whi(:h is l)rOdu(:ed in (;:tlldClll with the wimfing 1)att(:rn.</S>
  <S sid="94" ssid="94">])o(umel~tS reh:wm(e is s(-ored (m ~ s(;ah: l)e- (;ween 0 and 1.</S>
  <S sid="95" ssid="95">Tlm seed t)atterns a.re a.</S>
  <S sid="96" ssid="96">(:cet)ted ~,s trut]~; the do(mlw, nts (;hey mat(:]1 hnve rcle- vmme 1.</S>
  <S sid="97" ssid="97">On i(;er;~tion i + 1, e~mh t)a(;tern p is assigned a precision measure, t)ase(l on the rel- (:Vall(;e of |;11(; (locllnlelfl;s i|; 111a, l;(;ll(,,q: ~ ".d~(d) (~) f f , , :d  +~ (v)  - -  IH(v) l ,~.</S>
  <S sid="98" ssid="98">(,,) where l~,eli(d) is the re, levmlce of 1;11(: doeunmn(; fiom t;t1(, previous iteration, ~md l I(p) is the set of documents where p matched, in general, if K is a classifier (:onsisting of ~ set of l)al;terns, w(, define H (K)  as the st:l; of documents  where all ~similar to that used in (liiloff, 1996) ~W(: used ,:-- 0.1 and fl = 2. of t)~d;terns p C K m~l;(:h, mid the "cunmlative" precision of K as 1 ~ 1~4~(a,) (3) P~.~d +~(1() = IH U()I &lt;.</S>
  <S sid="99" ssid="99">(K) Once the wimfing pa,l;l;ern is accepted, the rel- ewmee of the documents is re-adjusted.</S>
  <S sid="100" ssid="100">For (;~mh document  d which is matched by some subset of l;he currently accet)t(d pntterns, we can view thai; sul)s(,t; of  l)~tterns as ~ classitier Kd = {pj}.</S>
  <S sid="101" ssid="101">These  patterns (tel;ermilm the new reh;wmce score of the document  as J~, "~l,~ " ( ,0  : 111~x (:tc,,.1,*(,O,v,.,;, .~" (K , ) )  (~:) This ensures tha.</S>
  <S sid="102" ssid="102">(; l;he rclewmce score grows monotonical ly, and only when there is sufliei(mt positive evidence, as (;he i)ntterns in etle(:I; vote "conjmmtively" on the (loculncnl;s. We also tr ied an alternative, ::disjun(:tive" voting scheme, with weights wlfich accounts tbr vm:intion in support of the p~ttterns, J,.,.1, (d) .</S>
  <S sid="103" ssid="103">~ "~ I I  (1 - ~,.~,.c~(p))"", (5) ~c K(d) where t;11(, weights ,wp arc (tetint;d using the tel- ewm(:(: of the (loeuments, a,s the total  SUl)l)or(; which the pa, I;I;ern p receives: % = log ~ l;.d,(d) dE 11 (p) and ;,7 is (;11( largest weight.</S>
  <S sid="104" ssid="104">The  r(,cursive for- nmb~s (apl;m:e (;he mul;u~fl dependency of t)~t- terns ~md documents;  this re-computat ion ~md growing of precision and relevmlce rmlks is the core of the t)rocedure.</S>
  <S sid="105" ssid="105">:~ 4 Resu l ts 4 .1  Event  Ext ract ion lhe, most nal;ma.l measme of eflecl;iveness of our discovery procedure is the performmme of ml ex- tract ion systmn using the, discovered t)~tterns.</S>
  <S sid="106" ssid="106">However, il; is not 1)ossil)le to apply this reel;- rio direei;ly because the discovered t)al;terns lack some of the information required tbr entries ill :{V(.</S>
  <S sid="107" ssid="107">did not el)serve a significam; diflerencc in 1)crfi)r- lIiHl[CO, bet, ween the two tormulas 4 alt(t 5 in o111" experi- in(mrs; the results whit:h tbllow use 5.</S>
  <S sid="108" ssid="108">943 the pattern base: information about the event type (predicate) associated with the pattern, and the mapping from pattern elements to pred- icate arguments.</S>
  <S sid="109" ssid="109">We have evaluated ExDIsco by manually incorporating the discovered pat- terns into the Proteus knowledge bases and run- ning a full MUC-style evaluation.</S>
  <S sid="110" ssid="110">We started with our extraction system, Pro- tens, which was used in MUC-6 in 1995, and has undergone continual improvements since the MUC evaluation.</S>
  <S sid="111" ssid="111">We removed all the scenario-specific clause and nominalization pat- terns.</S>
  <S sid="112" ssid="112">4 We then reviewed all the patterns which were generated by the ExDIsco,  deleting those which were not relewmt to the task, or which did not correspond irectly to a predicate al- ready implemented tbr this task)  The remain- ing pat;terns were augmented with intbnnation about the corresponding predicate, and the re- lation between the pattern and the predicate alguments, a The resulting variants of Proteus were applied to the formal training corpus and the (hidden) formal test corpus for MUC-6, and the output evaluated with the MUC scorer.</S>
  <S sid="113" ssid="113">The results on the training corpus are: Pattern Base Recall Precision Seed 38 83 Ex I ) Isco 62 80 Union 69 __79 Manual-MUC ~ 71 L~1.9~ Manual-NOW 6(3~ 79 L7!~z[)_t_j and on the test cortms: 4There are also a few noun phrase patterns which can give rise to scenario events.</S>
  <S sid="114" ssid="114">For example, "Mr Smith, former president of IBM", may produce an event record where l%ed Smith left IBM.</S>
  <S sid="115" ssid="115">These patterns were left in Proteus for all the runs, and they make some contribu- tion to the relatively high baseline scores obtained using just the seed event patterns.</S>
  <S sid="116" ssid="116">~ExD~sco f und patterns which were relevant to the task lint could not be easily aceomodated in Proteus.</S>
  <S sid="117" ssid="117">For instance "X remained as president" could be rele- vant, particularly in the case of a merger creating anew corporate ntity, but Proteus was not equipped to trun- dle such iIfformation, and has not yet been extended to incorporate such patterns.</S>
  <S sid="118" ssid="118">6As with all clause-level patterns in Proteus, these patterns m-e automatically generalized tohandle syntac- tic wniants uch as passive, relative clause, etc.</S>
  <S sid="119" ssid="119">Pattern Base Recall Precision F Seed 27 74 39.58 ExDIsco 52 72 60.16 Union 57 73 63.56 Manual-NOW -- 56 75 6404.</S>
  <S sid="120" ssid="120">The tables show the recall and precision mea- sures for the patterns, with F-measure being the harmonic mean of the two.</S>
  <S sid="121" ssid="121">The Seed pat- tern base consists of just the initial pattern set, given in the table on the previous page.</S>
  <S sid="122" ssid="122">~ib this we added the patterns which the system discov- ered automatically after about 100 iterations, producing the pattern set called ExDIsco.</S>
  <S sid="123" ssid="123">For comparison, M anual-MUC is the pattern base lnanually develot)ed on the MUC-6 training corpus-1)repared over the course of 1 month of full-time work by at least one computational linguist (during which the 100-document train- ing corpus was studied in detail).</S>
  <S sid="124" ssid="124">The last row, Manual-now, shows the current pertbrmance of the Proteus system.</S>
  <S sid="125" ssid="125">The base called Ultiolt con- tains the union of ExDIScO and Manual-Now.</S>
  <S sid="126" ssid="126">We find these results very encouraging: Pro- teus performs better with the patterns discov- ered by ExI)IscO than it did after one month of manual tinting and development; in fact, this perfi)rmance is close to current levels, which are the result of substantial additional devel- opmeut.</S>
  <S sid="127" ssid="127">These results umst be interpreted, however, with several caveats.</S>
  <S sid="128" ssid="128">First, Proteus performance depends on many fimtors besides the event patterns, such as the quality of name re, cognition, syntactic mmlysis, anaphora reso~ lution, inferencing, etc.</S>
  <S sid="129" ssid="129">Several of these were improved since the MUC formal evaluation, so some of the gain over the MUC formal evalua- tion score is attritmtable to these factors.</S>
  <S sid="130" ssid="130">How~ ever, all of the other scores are comparable in these regards.</S>
  <S sid="131" ssid="131">Second, as we noted above, the patterns were reviewed and augmented manu- ally, so the overall procedure is not entirely au- tomatic.</S>
  <S sid="132" ssid="132">However, the review and augmenta- tion process took little time, as compared to the manual corpus analysis and development of the pattern base.</S>
  <S sid="133" ssid="133">4.2 Text  f i l ter ing We can obtain a second measure of pertbr- mance by noting that, in addition to growing the tmttern set, ExDIsco  also grows the rele- 944 0.9 0.8 0.7 0.6 0.5 _ .</S>
  <S sid="134" ssid="134">T ~ ~ : : ~  T ;!</S>
  <S sid="135" ssid="135">g~t : -  il %i [!]</S>
  <S sid="136" ssid="136">7 [!J Legend: Management/Test ?</S>
  <S sid="137" ssid="137">.-{~ ...... ManagemenVl-raie - :*: -- MUC-6 ?</S>
  <S sid="138" ssid="138">0.2 0.4 0.6 0.8 Recall Figure l: Management Suc(cssion 0.9 0.8 0.7 0.6 0.5 L_~/r Legend: Acquisition 0.2 0.4 0.6 Recall 0.8 Figme 2: Mergers/A(:quisitions vance rankings of documents.</S>
  <S sid="139" ssid="139">The latter cnn be evahlated irectly, wil;hollt human intervention.</S>
  <S sid="140" ssid="140">We tested Exl)IsC, o ~tgainst wo cor])orn: th(; 100 documents from MUC-6 tbrmal training, a:nd the 100 documents from the MUC-6 for- mal test (both are contained anlong the 10,000 ExDIsoO training set) r. Figure 1 shows recall t)]otted against precision on the two corpora, over 100 iterations, starting with the seed pat- te, nls in section 3.d.</S>
  <S sid="141" ssid="141">This view on the discovery procedure is closely related to the MUC %ext- till;ering" task, in which the systems are jlulged at the ]evel of doc,wm, e,nt.s rather thmt event slots.</S>
  <S sid="142" ssid="142">It; is interesting to (:omt)m:e Exl)IsCOs results with how other MUC-6 part]tit)ants performed on the MUC-b   test cortms , shown anonymously.</S>
  <S sid="143" ssid="143">ExDIscO attains values within the range of the MUC participald;S, all of which were either heavily-supervised or m~mually coded systems.</S>
  <S sid="144" ssid="144">II; is important to bear in mind that Ex I ) I sco had no benefit of training material, or any in- tbrmation beyond the seed pattern set.</S>
  <S sid="145" ssid="145">Figure 2 shows the 1)ertbrmance, of text fil- tering on the Acquisition task, again, given the seed in section 3.4.</S>
  <S sid="146" ssid="146">ExDisco  was trained on |;lie same WSJ eorlms, and tested against a set of 200 documents.</S>
  <S sid="147" ssid="147">We retrieved this set using keyword-based IR, search, and judged their rel- evance by halId.</S>
  <S sid="148" ssid="148">rThesc judgements constituted the truth which was used only for evaluation, not visible to ExDISCO 5 Discuss ion The development of a w~riety of information extra(:tion systems over the last decade has demonstrated their feasibility but also the lim- itations on their portability and t)erformance.</S>
  <S sid="149" ssid="149">Prcl)aring good t)atterns tbr these syste, ms re- quires (:onsiderable skill, and achieving good (:overage requires |;lie analysis of a large amount of text.</S>
  <S sid="150" ssid="150">These t)rol)lems h~ve t)een impedinmnts to the -wide].</S>
  <S sid="151" ssid="151">use of extraction systenls.</S>
  <S sid="152" ssid="152">These dit[iculties have stimulate.d resear(h on 1)attel .</S>
  <S sid="153" ssid="153">n a ( : ( lu i s i t ion .</S>
  <S sid="154" ssid="154">So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S>
  <S sid="155" ssid="155">These techniques may re- duce the level of systeln expertise required to develop a new extraction N)plieation, but they do not lessen the lmrden of studying a large cor- lms in order to .find relevant candidates.</S>
  <S sid="156" ssid="156">The prior work most closely related to our own is that of (R.ilotf, 1996), who also seeks to lmild pattenls automatically without the need to annotate a corpus with the information to be extracted.</S>
  <S sid="157" ssid="157">Itowever, her work ditfers trom 01217 own in several i lnportant respects.</S>
  <S sid="158" ssid="158">First, her patterns identit~y phrases that fill individual slots in the template, without specifying how these slots may be combined at a later stage into complete templates.</S>
  <S sid="159" ssid="159">In contrast, our pro- cedure discovers complete, multi-slot event pat- 945 terns.</S>
  <S sid="160" ssid="160">Second, her procedure relies on a cort)us in which |;tie documents have been classified for relevance by hand (it was applied to the MUC-3 task, tbr which over 1500 classified documents are available), whereas ExDIsco requires no manual relevance judgements.</S>
  <S sid="161" ssid="161">While classify- ing documents tbr relevance is much easier than annotating docunlents with the information to be extracted, it; is still a significant ask, and places a limit on |:tie size of the training corpus that can be effectively used.</S>
  <S sid="162" ssid="162">Our research as demonstrated that for the studied scenarios automatic pattern discovery Call yield extraction perfi)rmance colnt)arabh~ to that obtained through extensive corpus anal- ysis.</S>
  <S sid="163" ssid="163">There are many directions in which the work reported here needs to be extended: ?</S>
  <S sid="164" ssid="164">nsing larger training corpora, in order to find less frequent exanlplcs, and in that way hopefully exceeding the i)erfornlancc of our best hand-trained system ?</S>
  <S sid="165" ssid="165">cat)luring the word classes which are gen- erated as a by-product of our pattern dis- covery 1)rocedure (in a manner similar to (Riloff and ,Jones, 1999)) and using them to discover less frequent )atterns in subse- quent iterations - evaluating the effectiveness of the discov- cry procedure on other scenarios.</S>
  <S sid="166" ssid="166">In par- titular, we need to be able to identi[y top- its which cast be most effbctively charac- terized by clause-level patterns (as was the case tbr the business domain), and topics which can be better characterized by other means.</S>
  <S sid="167" ssid="167">wouM also like to understand how the topic clusters (of documents and patterns) which are developed by our pro- cedure line up with pre-specified scenarios.</S>
  <S sid="168" ssid="168">References David Fisher, Stephen Soderland, Joseph Mc- Carthy, Fangfang Feng, and Wendy Lelmert.</S>
  <S sid="169" ssid="169">Description of the UMass system as used fbr MUC-6.</S>
  <S sid="170" ssid="170">Sixth Message Un- dcrstandin9 Conf.</S>
  <S sid="171" ssid="171">(MUC-6), Columbia, MD, November.</S>
  <S sid="172" ssid="172">Morgan Kauflnann.</S>
  <S sid="173" ssid="173">R.alph Grishman.</S>
  <S sid="174" ssid="174">The NYU systenl tbr MUC-6, or wheres the syntax?</S>
  <S sid="175" ssid="175">Sixth Message Understanding Conf.</S>
  <S sid="176" ssid="176">(MUC- 6), pages 167 176, Columl)ia, MD, Novem- ber.</S>
  <S sid="177" ssid="177">Morgan Kauflnann.</S>
  <S sid="178" ssid="178">W. Lehnert, C. Cardie, D. Fisher, J. McCarthy, E. Riloff, and S. Soderland.</S>
  <S sid="179" ssid="179">Univer- sity of nlassachusetts: MUC-4 test results and analysis.</S>
  <S sid="180" ssid="180">Fourth Message Un- der.standing Con.</S>
  <S sid="181" ssid="181">[., McLean, VA, June.</S>
  <S sid="182" ssid="182">Mor- gan Kauflnaml.</S>
  <S sid="183" ssid="183">Scott Miller, Michael Crystal, Heidi Fox, Lance II,amshaw, R,ichard Schwartz, Rebecca Stone, Rall)h Weischedel, and the Annota- tion Group.</S>
  <S sid="184" ssid="184">Algorithms that learn to extract intbrmation; BBN: Description of the SIFT systenl as used for MUC-7.</S>
  <S sid="185" ssid="185">7th Mc.ssagc Understanding Co~:f., FMrfax, VA. 1993.</S>
  <S sid="186" ssid="186">Proceedings of the F~ifth Message UTz.- derstanding Confer(race (MUC-5), Baltimore, MD, August.</S>
  <S sid="187" ssid="187">Morgan Kauflnann.</S>
  <S sid="188" ssid="188">PTveeedings of the Sixth Message U~I,- derstav, ding Conference (MUC-6), Colmnt)ia, MD, November.</S>
  <S sid="189" ssid="189">Morgan Kauflnaml.</S>
  <S sid="190" ssid="190">Ellen Rilotf and Rosie Jones.</S>
  <S sid="191" ssid="191">Learn- ing dictionaries for infbrmation extraction by multi-level bootstrat)ping.</S>
  <S sid="192" ssid="192">16th Natl Corderenee on Art~i[icial Intelli9enee (AAA I 99), Orlando, Florida.</S>
  <S sid="193" ssid="193">Automatically generating extraction patterns from m~tagged text.</S>
  <S sid="194" ssid="194">I3th Natl Co~~:f. on Art~ificial Intel- ligence (AAAI-96).</S>
  <S sid="195" ssid="195">The AAAI Press/MIT Press.</S>
  <S sid="196" ssid="196">l?asi ])~panainen a d Time .J/h:vinen.</S>
  <S sid="197" ssid="197">A non-t)rojectivc dependency parser.</S>
  <S sid="198" ssid="198">on Applied Nataral Language P~v- cessiu9, pages 64-71, Washington, D.C. ACL.</S>
  <S sid="199" ssid="199">Roman Yangarber and RalI)h Grishman.</S>
  <S sid="200" ssid="200">Customization of intbrmation extraction sys- tems.</S>
  <S sid="201" ssid="201">In Paola Velardi, editor, I~ttl Work- shop on Lexically Driven I~7:forrnation Extrac- tion, Frascati, Italy.</S>
  <S sid="202" ssid="202">Universith di Roma.</S>
  <S sid="203" ssid="203">Roman Yangarl)er and Ralph Grishman.</S>
  <S sid="204" ssid="204">NYU: Description of thc Protens/PET sys- tem as used tbr MUC-7 ST.</S>
  <S sid="205" ssid="205">In 7th Message Understanding Conference, Columbia, MD.</S>
  <S sid="206" ssid="206">Roman Yangarl)er, Ralph Grishman, Past Tapanainen, and Silja Huttunen.</S>
  <S sid="207" ssid="207">Un- supervised discovery of scenario-level pat- terns tbr information extraction.</S>
  <S sid="208" ssid="208">Co~@ on Applied Nataral Langaage Process- tug (ANLP-NAACL), Seattle, WA.</S>
</PAPER>
