Joint Unsupervised Coreference Resolution with Markov Logic
Machine learning approaches to coreference resolution are typically supervised, and require expensive labeled data.
Some unsupervised approaches have been proposed (e.g., Haghighi and Klein (2007)), but they are less accurate.
In this paper, we present the first unsupervised approach that is competitive with supervised ones.
This is made possible by performing joint inference across mentions, in contrast to the pairwise classification typically used in supervised methods, and by using Markov logic as a representation language, which enables us to easily express relations like apposition and predicate nominals.
On MUC and ACE datasets, our model outperforms Haghigi and Kleinâ€™s one using only a fraction of the training data, and often matches or exceeds the accuracy of state-of-the-art supervised models.
We empirically report that global approaches achieve performance better than the ones based on incrementally processing a text.
Our method is based on the entity-mention model.
In the predicate nominative construction, the object of a copular verb (forms of the verb be) is constrained to corefer with its subject.
