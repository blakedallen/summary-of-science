<PAPER>
  <S sid="0">CorMet: A Computational Corpus-Based Conventional Metaphor Extraction System</S>
  <ABSTRACT>
    <S sid="1" ssid="1">CorMet is a corpus-based system for discovering metaphorical mappings between concepts.</S>
    <S sid="2" ssid="2">It does this by finding systematic variations in domain-specific selectional preferences, which are inferred from large, dynamically mined Internet corpora.</S>
    <S sid="3" ssid="3">Metaphors transfer structure from a source domain to a target domain, making some concepts in the target domain metaphorically equivalent to concepts in the source domain.</S>
    <S sid="4" ssid="4">The verbs that select for a concept in the source domain tend to select for its metaphorical equivalent in the target domain.</S>
    <S sid="5" ssid="5">This regularity, detectable with a shallow linguistic analysis, is used to find the metaphorical interconcept mappings, which can then be used to infer the existence of higher-level conventional metaphors.</S>
    <S sid="6" ssid="6">Most other computational metaphor systems use small, hand-coded semantic knowledge bases and work on a few examples.</S>
    <S sid="7" ssid="7">Although CorMet&#8217;s only knowledge base is WordNet (Fellbaum 1998) it can find the mappings constituting many conventional metaphors and in some cases recognize sentences instantiating those mappings.</S>
    <S sid="8" ssid="8">CorMet is tested on its ability to find a subset of the</S>
  </ABSTRACT>
  <SECTION title="" number="1">
    <S sid="9" ssid="1">CorMet is a corpus-based system for discovering metaphorical mappings between concepts.</S>
    <S sid="10" ssid="2">It does this by finding systematic variations in domain-specific selectional preferences, which are inferred from large, dynamically mined Internet corpora.</S>
    <S sid="11" ssid="3">Metaphors transfer structure from a source domain to a target domain, making some concepts in the target domain metaphorically equivalent to concepts in the source domain.</S>
    <S sid="12" ssid="4">The verbs that select for a concept in the source domain tend to select for its metaphorical equivalent in the target domain.</S>
    <S sid="13" ssid="5">This regularity, detectable with a shallow linguistic analysis, is used to find the metaphorical interconcept mappings, which can then be used to infer the existence of higher-level conventional metaphors.</S>
    <S sid="14" ssid="6">Most other computational metaphor systems use small, hand-coded semantic knowledge bases and work on a few examples.</S>
    <S sid="15" ssid="7">Although CorMet&#8217;s only knowledge base is WordNet (Fellbaum 1998) it can find the mappings constituting many conventional metaphors and in some cases recognize sentences instantiating those mappings.</S>
    <S sid="16" ssid="8">CorMet is tested on its ability to find a subset of the Master Metaphor List (Lakoff, Espenson, and Schwartz 1991).</S>
  </SECTION>
  <SECTION title="1." number="2">
    <S sid="17" ssid="1">Lakoff (1993) argues that rather than being a rare form of creative language, some metaphors are ubiquitous, highly structured, and relevant to cognition.</S>
    <S sid="18" ssid="2">To date, there has been no robust, broadly applicable computational metaphor interpretation system, a gap this article is intended to take a first step toward filling.</S>
    <S sid="19" ssid="3">Most computational models of metaphor depend on hand-coded knowledge bases and work on a few examples.</S>
    <S sid="20" ssid="4">CorMet is designed to work on a larger class of metaphors by extracting knowledge from large corpora without drawing on any handcoded knowledge sources besides WordNet.</S>
    <S sid="21" ssid="5">A method for computationally interpreting metaphorical language would be useful for NLP.</S>
    <S sid="22" ssid="6">Although metaphorical word senses can be cataloged and treated as just another part of the lexicon, this kind of representation ignores regularities in polysemy.</S>
    <S sid="23" ssid="7">A conventional metaphor may have a very large number of linguistic manifestations, which makes it useful to model the metaphor&#8217;s underlying mechanisms.</S>
    <S sid="24" ssid="8">CorMet is not capable of interpreting any manifestation of conventional metaphor but is a step toward such a system.</S>
    <S sid="25" ssid="9">CorMet analyzes large corpora of domain-specific documents and learns the selectional preferences of the characteristic verbs of each domain.</S>
    <S sid="26" ssid="10">A selectional preference is a verb&#8217;s predilection for a particular type of argument in a particular role.</S>
    <S sid="27" ssid="11">For instance, the object of the verb pour is generally a liquid.</S>
    <S sid="28" ssid="12">Any noun that pour takes as an an object is likely to be intended as a liquid, either metaphorically or literally.</S>
    <S sid="29" ssid="13">CorMet finds conventional metaphors by finding systematic differences in selectional preferences between domains.</S>
    <S sid="30" ssid="14">For instance, if CorMet were to find a sentence like Funds poured into his bank account in a document from the FINANCE domain, it could infer that in that domain, pour has a selection preference for financial assets in its subject.</S>
    <S sid="31" ssid="15">By comparing this selectional preference with pour&#8217;s selectional preferences in the LAB domain, CorMet can infer a metaphorical mapping from money to liquids.</S>
    <S sid="32" ssid="16">By finding sets of co-occuring interconcept mappings (like the above mapping and a mapping from investments to containers, for instance), Cormet can articulate the higher-order structure of conceptual metaphors.</S>
    <S sid="33" ssid="17">Note that Cormet is designed to detect higherorder conceptual metaphors by finding some of the sentences embodying some of the interconcept mappings constituting the metaphor of interest but is not designed to be a tool for reliably detecting all instances of a particular metaphor.</S>
    <S sid="34" ssid="18">CorMet&#8217;s domain-specific corpora are obtained from the Internet.</S>
    <S sid="35" ssid="19">In this context, a domain is a set of related concepts, and a domain-specific corpus is a set of documents relevant to those concepts.</S>
    <S sid="36" ssid="20">CorMet&#8217;s input parameters are two domains between which to search for interconcept mappings and, for each domain, a set of characteristic keywords.</S>
    <S sid="37" ssid="21">CorMet is tested on its ability to find a subset of the Master Metaphor List (Lakoff, Espenson, and Schwartz 1991), a manually compiled catalog of metaphor.</S>
    <S sid="38" ssid="22">CorMet works on domains that are specific and concrete (e.g., the domain of finance, but not that of actions).</S>
    <S sid="39" ssid="23">CorMet&#8217;s discrimination is relatively coarse: It measures trends in selectional preferences across many documents, so common mappings are discernible.</S>
    <S sid="40" ssid="24">CorMet considers the selectional preferences only of verbs, on the theory that they are generally more selectively restrictive than nouns or adjectives.</S>
    <S sid="41" ssid="25">It is worth noting that WordNet, CorMet&#8217;s primary knowledge source, implicitly encodes some of the metaphors CorMet is intended to find; Peters and Peters (2000) use WordNet to find many artifact/cognition metaphors.</S>
    <S sid="42" ssid="26">Also, WordNet enumerates some metaphorical senses of some verbs.</S>
    <S sid="43" ssid="27">CorMet does not use any of WordNet&#8217;s information about verbs and ignores regularities in the distribution of noun homonyms that could be used to find some metaphors.</S>
    <S sid="44" ssid="28">The article is organized as follows: Section 2 describes the mechanisms by which conventional metaphors are detected.</S>
    <S sid="45" ssid="29">Section 3 walks through CorMet&#8217;s process in two examples.</S>
    <S sid="46" ssid="30">Section 4 describes how the system&#8217;s performance is evaluated against the Master Metaphor List (Lakoff, Espenson, and Schwartz 1991), and Section 5 covers select related work.</S>
  </SECTION>
  <SECTION title="2." number="3">
    <S sid="47" ssid="1">Ideally, CorMet could draw on a large quantity of manually vetted, highly representative domain-specific documents.</S>
    <S sid="48" ssid="2">The precompiled corpora available on-line (Kucera 1992; Marcus, Santorini, and Marcinkiewicz 1993) do not span enough subjects.</S>
    <S sid="49" ssid="3">Other on-line data sources include the Internet&#8217;s hierarchically structured indices, such as Yahoo&#8217;s ontology (www.yahoo.com) and Google&#8217;s (www.google.com).</S>
    <S sid="50" ssid="4">Each index entry contains a small number of high-quality links to relevant Web pages, but this is not helpful, because CorMet requires many documents, and those documents need not be of more than moderate quality.</S>
    <S sid="51" ssid="5">Searching the Internet for domain-specific text seems to be the only way to obtain sufficiently large, diverse corpora.</S>
    <S sid="52" ssid="6">CorMet obtains documents by submitting queries to the Google search engine.</S>
    <S sid="53" ssid="7">There are two types of queries: one to fetch any domain-specific documents and another to fetch domain-specific documents that contain a particular verb.</S>
    <S sid="54" ssid="8">The first kind of query consists of a conjunction of from two to five randomly selected domain keywords.</S>
    <S sid="55" ssid="9">Domain keywords are words characteristic of a domain, supplied by the user as an input.</S>
    <S sid="56" ssid="10">For the FINANCE domain, a reasonable set of keywords is stocks, bonds, NASDAQ, Dow, investment, finance.</S>
    <S sid="57" ssid="11">Each query incorporates only a few keywords in order to maximize the number of distinct possible queries.</S>
    <S sid="58" ssid="12">Queries for domain-specific documents containing a particular verb are composed of a conjunction of domain-specific terms and a disjunction of forms of the verb that are more likely to be verbs than other parts of speech.</S>
    <S sid="59" ssid="13">For the verb attack, for instance, acceptable forms are attacked and attacking, but not attack and attacks, which are more likely to be nouns.</S>
    <S sid="60" ssid="14">The syntactic categories in which a word form appears are determined by reference to WordNet.</S>
    <S sid="61" ssid="15">Some queries for the verb attack in the FINANCE domain are: Queries return links to up to 10,000 documents, of which CorMet fetches and analyzes no more than 3,000.</S>
    <S sid="62" ssid="16">In the 13 domains studied, about 75% of these documents are relevant to the domain of interest (as measured through a randomly chosen, handevaluated sample of 100 documents per domain), so the noise is substantial.</S>
    <S sid="63" ssid="17">The documents are processed to remove embedded scripts and HTML tags.</S>
    <S sid="64" ssid="18">The mined documents are parsed with the apple pie parser (Sekine and Grishman 1995).</S>
    <S sid="65" ssid="19">Case frames are extracted from parsed sentences using templates; for instance, (S (NP &amp; OBJ) (VP (were  |was  |got  |get) (VP WORDFORM-PASSIVE)) is used to extract roles for passive, agentless sentences (where WORDFORM-PASSIVE is replaced by a passive form of the verb under analysis).</S>
    <S sid="66" ssid="20">Learning the selectional preferences for a verb in a domain is expensive in terms of time, so it is useful to find a small set of important verbs in each domain.</S>
    <S sid="67" ssid="21">CorMet seeks information about verbs typical of a domain, because these verbs are more likely to figure in metaphors in which that domain is the metaphor&#8217;s source.</S>
    <S sid="68" ssid="22">Besiege, for instance, is characteristic of the MILITARY domain and appears in many instances of the MILITARY &#8594; MEDICINE mapping, such as The antigens besieged the virus.</S>
    <S sid="69" ssid="23">To find domain-characteristic verbs, CorMet dynamically obtains a large sample of domain-relevant documents, decomposes them into a bag-of-words representation, stems the words with an implementation of the Porter (1980) stemmer, and finds the ratio of occurrences of each word stem to the total number of stems in the domain corpus.</S>
    <S sid="70" ssid="24">The frequency of each stem in the corpus is compared to its frequency in general English (as recorded in an English-language frequency dictionary [Kilgarriff 2003]).</S>
    <S sid="71" ssid="25">The 400 verb stems with the highest relative frequency (computed as a ratio of the stem&#8217;s frequency in the domain to its frequency in the English frequency dictionary) are considered characteristic.</S>
    <S sid="72" ssid="26">CorMet treats any word form that may be a verb (according to WordNet) as though it is a verb, which biases CorMet toward verbs with common nominal homonyms.</S>
    <S sid="73" ssid="27">Word stems that have high relative frequency in more than one domain, like e-mail and download, are eliminated on the suspicion that they are more characteristic of documents on the Internet in general than of a substantive domain.</S>
    <S sid="74" ssid="28">Table 1 lists the 20 highest-scoring stems in the LAB and FINANCE domains.</S>
    <S sid="75" ssid="29">There are three constraints on CorMet&#8217;s selectional-preference-learning algorithm.</S>
    <S sid="76" ssid="30">First, it must tolerate noise, because complex sentences are often misparsed, and the case frame extractor is error prone.</S>
    <S sid="77" ssid="31">Second, it should be able to work around WordNet&#8217;s lacunae.</S>
    <S sid="78" ssid="32">Finally, there should be a reasonable metric for comparing the similarity between selectional preferences.</S>
    <S sid="79" ssid="33">CorMet first uses the selectional-preference-learning algorithm described in Resnik (1993), then clustering over the results.</S>
    <S sid="80" ssid="34">Resnik&#8217;s algorithm takes a set of words observed in a case slot (e.g., the subject of pour or the indirect object of give) and finds the WordNet nodes that best characterize the selectional preferences of that slot.</S>
    <S sid="81" ssid="35">(Note that WordNet nodes are treated as categories subcategorizing their descendants.)</S>
    <S sid="82" ssid="36">A case slot has a preference for a WordNet node to the extent that that node, or one of its descendants, is more likely to appear in that case slot than it is to appear at random.</S>
    <S sid="83" ssid="37">An overall measure of the choosiness of a case slot is selectional-preference strength, SR(p), defined as the relative entropy of the posterior probability P(c|p) and the prior probability P(c) (where P(c) is the a priori probability of the appearance of a WordNet node c, or one of its descendants, and P(c|p) is the probability of that node or one of its descendants appearing in a case slot p.) Recall that the relative entropy of two distributions X and Y, D(X||Y), is the inefficiency incurred by using an encoding optimal for Y to encode X.</S>
    <S sid="84" ssid="38">The degree to which a case slot selects for a particular node is measured by selectional association.</S>
    <S sid="85" ssid="39">In effect, the selectional associations divide up the selectional preference strength for a case slot among that slot&#8217;s possible fillers.</S>
    <S sid="86" ssid="40">Selectional association is defined as To compute &#923;R(p, c), what is needed is a distribution over word classes, but what is observed in the corpus is a distribution over word forms.</S>
    <S sid="87" ssid="41">Resnik&#8217;s algorithm works around this problem by approximating a word class distribution from the word form distribution.</S>
    <S sid="88" ssid="42">For each word form observed filling a case slot, credit is divided evenly among all of that word form&#8217;s possible senses (and their ancestors in WordNet).</S>
    <S sid="89" ssid="43">Although Resnik&#8217;s algorithm makes no explicit attempt at sense disambiguation, greater activation tends to accumulate in those nodes that best characterize a predicate&#8217;s selectional preferences.</S>
    <S sid="90" ssid="44">CorMet uses Resnik&#8217;s algorithm to learn domain-specific selection preferences.</S>
    <S sid="91" ssid="45">It often finds different selectional preferences for predicates whose preferences should, intuitively, be the same.</S>
    <S sid="92" ssid="46">In the MILITARY domain, the object of assault selects strongly for fortification but not social group, whereas the selectional preferences for the object of attack are the opposite.</S>
    <S sid="93" ssid="47">Taking the cosine of the selectional preferences of these two case slots (one of many possible similarity metrics) gives a surprisingly low score.</S>
    <S sid="94" ssid="48">In order to facilitate more accurate judgments of selectional-preference similarity, CorMet finds clusters of WordNet nodes that, although not as accurate, allow more meaningful comparisons of selectional preferences.</S>
    <S sid="95" ssid="49">Clusters are built using the nearest-neighbor clustering algorithm (Jain, Murty, and Flynn 1999).</S>
    <S sid="96" ssid="50">A predicate&#8217;s selectional preferences are represented as vectors whose nth element represents the selectional association of the nth WordNet node for that predicate.</S>
    <S sid="97" ssid="51">The similarity function used is the dot product of the two selectional-preference vectors.</S>
    <S sid="98" ssid="52">Empirically, the level of granularity obtained by running nearest-neighbor clustering twice (i.e., clustering over the sets of nodes constituting selectional preferences, then clustering over the clusters) produces the most conceptually coherent clusters.</S>
    <S sid="99" ssid="53">There are typically fewer than 100 second-order clusters (i.e., clusters of clusters) per domain.</S>
    <S sid="100" ssid="54">In the LAB domain there are 54 second-order clusters, and in the FINANCE domain there are 67.</S>
    <S sid="101" ssid="55">The time complexity of searching for metaphorical interconcept mappings between two domains is proportional to the number of pairs of salient domain objects, so it is more efficient to search over pairs of salient clusters than over the more numerous individual salient nodes.</S>
    <S sid="102" ssid="56">Table 2 shows a MILITARY cluster.</S>
    <S sid="103" ssid="57">These clusters are helpful for finding verbs with similar, but not identical, selectional preferences.</S>
    <S sid="104" ssid="58">Although attack, for instance, does not select for fortification, it does select for other elements of fortification&#8217;s cluster, such as building and defensive structure.</S>
    <S sid="105" ssid="59">The fundamental limitation of WordNet with respect to selectional-preference learning is that it fails to exhaust all possible lexical relationships.</S>
    <S sid="106" ssid="60">WordNet can hardly be blamed: The task of recording all possible relationships between all English words is prohibitively large, if not infinite.</S>
    <S sid="107" ssid="61">Nevertheless, there are many words that intuitively should have a common parent but do not.</S>
    <S sid="108" ssid="62">For instance, liquid body substance and water should both be hyponyms of liquid, but in WordNet their shallowest common ancestor is substance.</S>
    <S sid="109" ssid="63">One of the descendants of substance is solid, so there is no single node that represents all liquids.</S>
    <S sid="110" ssid="64">Li and Abe (1998) describe another method of corpus-driven selectional-preference learning that finds a tree cut of WordNet for each case slot.</S>
    <S sid="111" ssid="65">A tree cut is a set of The elements of a cluster of WordNet nodes characteristic of the MILITARY domain. nodes that specifies a partition of the ontology&#8217;s leaf nodes, where a node stands for all the leaf nodes descended from it.</S>
    <S sid="112" ssid="66">The method chooses among possible tree cuts according to minimum-description-length criteria.</S>
    <S sid="113" ssid="67">The description length of a tree cut representation is the sum of the size of the tree cut itself (i.e., the minimum number of nodes specifying the partition) and the space required for representing the observed data with that tree cut.</S>
    <S sid="114" ssid="68">For CorMet&#8217;s purposes, the problem with this approach is that it is difficult to find clusters of (possibly hypernymically related) nodes representing a selectional preference using its results (because the tree cut includes exactly one node on each path from each leaf node to the root).</S>
    <S sid="115" ssid="69">There are similar objections to similar approaches such as that of Carroll and McCarthy (2000).</S>
    <S sid="116" ssid="70">Polarity is a measure of the directionality and magnitude of structure transfer between two concepts or two domains.</S>
    <S sid="117" ssid="71">Nonzero polarity exists when language characteristic of a concept from one domain is used in a different domain of a different concept.</S>
    <S sid="118" ssid="72">The kind of characteristic language CorMet can detect is limited to verbal selectional preferences.</S>
    <S sid="119" ssid="73">Say CorMet is searching for a mapping between the concepts liquids (characteristic of the LAB domain) and assets (characteristic of the FINANCE domain), as illustrated in Figure 1.</S>
    <S sid="120" ssid="74">There are verbs in LAB that strongly select for liquids, such as pour, flow, and freeze.</S>
    <S sid="121" ssid="75">In FINANCE, these verbs select for assets.</S>
    <S sid="122" ssid="76">In FINANCE there are verbs that strongly select for assets such as spend, invest, and tax.</S>
    <S sid="123" ssid="77">In the LAB domain, these verbs select for nothing in particular.</S>
    <S sid="124" ssid="78">This suggests that liquid is the source concept and asset is the target concept, which implies that LAB and FINANCE are the source and target domains, respectively.</S>
    <S sid="125" ssid="79">CorMet computes the overall polarity between two domains (as opposed to between two concepts) by summing over the polarity between each pair of high-salience concepts from the two domains of interest.</S>
    <S sid="126" ssid="80">Interconcept polarity is defined as follows: Let &#945; be the set of case slots in domain X with the strongest selectional preference for the node cluster A.</S>
    <S sid="127" ssid="81">Let &#946; be the set of case slots in domain Y with the strongest selectional preferences for the node cluster B.</S>
    <S sid="128" ssid="82">The degree of structure flow from A in X to B in Y is computed as the degree to which the predicates &#945; select for the nodes B in Y, or selection strength(Y, &#945;, B).</S>
    <S sid="129" ssid="83">Structure flow in the opposite direction is selection strength(X, &#946;,A).</S>
    <S sid="130" ssid="84">The definition of selection strength(Domain, case slots, node cluster) is the average of the selectionalpreference strengths of the predicates in case slots for the nodes in node cluster in Domain.</S>
    <S sid="131" ssid="85">The polarity for &#945; and &#946; is the difference in the two quantities.</S>
    <S sid="132" ssid="86">If the polarity is near zero, there is not much structure flow and no evidence for a metaphoric mapping.</S>
    <S sid="133" ssid="87">In some cases a difference in selectional preferences between domains does not indicate the presence of a metaphor.</S>
    <S sid="134" ssid="88">To take a fictitious but illustrative example, say Asymmetric structure transfer between LAB and FINANCE.</S>
    <S sid="135" ssid="89">Predicates from LAB that select for liquids are transferred to FINANCE and select for money.</S>
    <S sid="136" ssid="90">On the other hand, predicates from FINANCE that select for money are transferred to LAB and do not select for liquids. that in the LAB domain the subject of sit has a preference for chemists whereas in the FINANCE domain it has a preference for investment bankers.</S>
    <S sid="137" ssid="91">The difference in selectional preferences is caused by the fact that chemists are the kind of person more likely to appear in LAB documents and investment bankers in FINANCE ones.</S>
    <S sid="138" ssid="92">Instances like this are easy to filter out because their polarity is zero.</S>
    <S sid="139" ssid="93">A verb is treated as characteristic of a domain X if it is at least twice as frequent in the domain corpus as it is in general English and it is at least one and a half times as frequent in domain X as in the contrasting domain Y (these ratios were chosen empirically).</S>
    <S sid="140" ssid="94">Pour, for instance, occurs three times as often in FINANCE and twentythree times as often in LAB as it does in general English.</S>
    <S sid="141" ssid="95">Since it is nearly eight times as frequent in LAB as in FINANCE, it is considered characteristic of the former.</S>
    <S sid="142" ssid="96">This heuristic resolves the confusion than can be caused by the ubiquity of certain conventional metaphors&#8212;the high density of metaphorical uses of pour in FINANCE could otherwise make it seem as though pour is characteristic of that domain.</S>
    <S sid="143" ssid="97">A verb with weak selectional preferences (e.g., exist) is a bad choice for a characteristic predicate even if it occurs disproportionately often in a domain.</S>
    <S sid="144" ssid="98">Highly selective verbs are more useful because violations of their selectional preferences are more informative.</S>
    <S sid="145" ssid="99">For this reason a predicate&#8217;s salience to a domain is defined as its selectional-preference strength times the ratio of its frequency in the domain to its frequency in English.</S>
    <S sid="146" ssid="100">Literal and metaphorical selectional preferences may coexist in the same domain.</S>
    <S sid="147" ssid="101">Consider the selectional preferences of pour in the chemical and financial domains.</S>
    <S sid="148" ssid="102">In the LAB domain, pour is mostly used literally: People pour liquids.</S>
    <S sid="149" ssid="103">There are occasional metaphorical uses (e.g., Funding is pouring into basic proteomics research), but the literal sense is more common.</S>
    <S sid="150" ssid="104">In FINANCE, pour is mostly used metaphorically, although there are occasionally literal uses (e.g., Today oil poured into the new Turkmenistan pipeline).</S>
    <S sid="151" ssid="105">Algorithms 1&#8211;3 show pseudocode for finding metaphoric mappings between concepts. comment: Find mappings from concepts in domain1 to concepts in domain2 or vice versa Domain 1 Clusters +&#8212; GET BEST CLUSTERS(domain1) Domain 2 Clusters +&#8212; GET BEST CLUSTERS(domain2) for each Concept 1 E Domain 1 Clusters for each Concept 2 E Domain 2 Clusters polarity from 1 to 2 +&#8212; INTER CONCEPT POLARITY(Concept 1,Concept 2,domain1, domain2) polarity from 2 to 1 +&#8212; INTER CONCEPT POLARITY(Concept 2,Concept 1,domain2, domain1) if ABSOLUTE VALUE(polarity from 1 to 2 &#8722; polarity from 2 to 1) &lt; C1 then return (0); if polarity from 1 to 2 &gt; C2 and polarity from 2 to 1 &gt; C2 According to the thematic-relation hypothesis (Grubner 1976), many domains are conceived of in terms of physical objects moving along paths between locations in space.</S>
    <S sid="152" ssid="106">In the money domain, assets are mapped to objects and asset holders are mapped to locations.</S>
    <S sid="153" ssid="107">In the idea domain, ideas are mapped to objects, minds are mapped to locations, and communications are mapped to paths.</S>
    <S sid="154" ssid="108">Axioms of inference from the target domain usually become available for reasoning about the source domain, unless there is an aspect of the source domain that specifically contradicts them.</S>
    <S sid="155" ssid="109">For instance, in the domain of material objects, a thing moved from point X to point Y is no longer at X, but in the idea domain, it exists at both locations.</S>
    <S sid="156" ssid="110">Thematically related metaphors may consistently co-occur in the same sentences.</S>
    <S sid="157" ssid="111">For example, the metaphors LIQUID &#8594; MONEY and CONTAINERS &#8594; INSTITUTIONS often co-occur, as in the sentence Capital flowed into the new company.</S>
    <S sid="158" ssid="112">Conversely, cooccurring metaphors are often components of a single metaphorical conceptualization.</S>
    <S sid="159" ssid="113">A metaphorical mapping is therefore more credible when it is a component of a system of mappings.</S>
    <S sid="160" ssid="114">In CorMet, systematicity measures a metaphorical mapping&#8217;s tendency to co-occur with other mappings.</S>
    <S sid="161" ssid="115">The systematicity score for a mapping X is defined as the number of strong, distinct mappings co-occurring with X.</S>
    <S sid="162" ssid="116">This measure goes only a little way toward capturing the extent to which a metaphor exhibits the structure described in the thematic-relations hypothesis, but extending CorMet to find the entities that correspond to objects, locations, and paths is beyond the scope of this article.</S>
    <S sid="163" ssid="117">CorMet computes a confidence measure for each metaphor it discovers.</S>
    <S sid="164" ssid="118">Confidence is a function of three things.</S>
    <S sid="165" ssid="119">The more verbs mediating a metaphor (as attack and assault mediate ENEMY &#8594; DISEASE in The antigen attacked the virus and Chemotherapy assaults the tumor), the more credible it is.</S>
    <S sid="166" ssid="120">Strongly unidirectional structure flow from source domain to target makes a mapping more credible.</S>
    <S sid="167" ssid="121">Finally, a mapping is more likely to be correct if it systematically co-occurs with other mappings.</S>
    <S sid="168" ssid="122">The confidence measure should not be interpreted as a probability of correctness: The data available for calibrating such a distribution are inadequate.</S>
    <S sid="169" ssid="123">The weights of each factor, empirically assigned plausible values, are given in Table 3.</S>
    <S sid="170" ssid="124">The confidence measure is intended to wrap all the available evidence about a metaphor&#8217;s credibility into one number.</S>
    <S sid="171" ssid="125">A principled way of doing this is desirable, but unfortunately there are not enough data to make meaningful use of machinelearning techniques to find the best set of components and weights.</S>
    <S sid="172" ssid="126">There is substantial arbitrariness in the confidence rating: The components used and the weights they are assigned could easily be different and are best considered guesses that give reasonable results.</S>
  </SECTION>
  <SECTION title="3." number="4">
    <S sid="173" ssid="1">This section provides a walk-through of the derivation and analysis of the concept mapping LIQUID &#8594; MONEY and components of the interconcept mapping WAR &#8594; MEDICINE.</S>
    <S sid="174" ssid="2">In the interests of brevity only representative samples of CorMet&#8217;s data are shown.</S>
    <S sid="175" ssid="3">See Mason (2002) for a more detailed account.</S>
    <S sid="176" ssid="4">CorMet&#8217;s inputs are two domain sets of characteristic keywords for each domain (Table 4).</S>
    <S sid="177" ssid="5">The keywords must characterize a cluster in the space of Internet documents, but CorMet is relatively insensitive to the particular keywords.</S>
    <S sid="178" ssid="6">It is difficult to find keywords characterizing a cluster centering on money alone, so keywords for a more general domain, FINANCE, are provided.</S>
    <S sid="179" ssid="7">It is also difficult to characterize a cluster of documents mostly about liquids.</S>
    <S sid="180" ssid="8">Chemical-engineering articles and hydrographic encyclopedias tend to pertain to the highly technical aspects of liquids instead of their everyday behavior.</S>
    <S sid="181" ssid="9">Documents related to laboratory work are targeted on the theory that most references to liquids in a corpus dedicated to the manipulation and transformation of different states of matter are likely to be literal and will not necessarily be highly technical.</S>
    <S sid="182" ssid="10">Tables 5 and 6 show the top 20 characteristic verbs for LAB and FINANCE, respectively.</S>
    <S sid="183" ssid="11">CorMet finds the selectional preferences of all of the characteristic predicates&#8217; case slots.</S>
    <S sid="184" ssid="12">A sample of the selectional preferences of the top 20 verbs in LAB and FINANCE are shown in Tables 7 and 8, respectively.</S>
    <S sid="185" ssid="13">The leftmost columns of these two tables have the (stemmed form of the) characteristic verb and the thematic role characterized.</S>
    <S sid="186" ssid="14">The right-hand sides have clusters of characteristic nodes.</S>
    <S sid="187" ssid="15">The numbers associated with the nodes are the bits of uncertainty about the identity of a word x resolved by the fact that x fills the given case slot, or P(x +&#8212; N) &#8722; P(x +&#8212; N|case slot(x)) (where x +&#8212; N is read as x is N or a hyponym of N).</S>
    <S sid="188" ssid="16">All of the 400 possible mappings between the top 20 concepts (clusters) from the two domains are examined.</S>
    <S sid="189" ssid="17">Each possible mapping is evaluated in terms of polarity, the number of frames instantiating the mapping, and the systematic co-occurrence of that mapping with different, highly salient mappings.</S>
    <S sid="190" ssid="18">The best mappings for LAB x FINANCE are shown in Table 9.</S>
    <S sid="191" ssid="19">Mappings are expressed in abbreviated form for clarity, with only the most recognizable (if not necessarily the most salient) node of each concept displayed.</S>
    <S sid="192" ssid="20">The foremost mapping characterizes money in terms of liquid, the mapping for which the two domains were selected.</S>
    <S sid="193" ssid="21">The second represents a somewhat less intuitive mapping from liquids to institutions.</S>
    <S sid="194" ssid="22">This metaphor is driven primarily by institutions&#8217; capacity to dissolve.</S>
    <S sid="195" ssid="23">Of course, this mapping is incorrect insofar as solids undergo dissolution, not liquids.</S>
    <S sid="196" ssid="24">CorMet made this mistake because of faulty thematic-role identification; it frequently failed to distinguish between the different thematic roles played by the subjects in sentences like The company dissolved and The acid dissolved the compound.</S>
    <S sid="197" ssid="25">The third mapping characterizes communication as a liquid.</S>
    <S sid="198" ssid="26">This was not the mapping the author had in mind when he chose the domains, but it is intuitively plausible: One speaks of information flowing as readily as of money flowing.</S>
    <S sid="199" ssid="27">That this mapping appears in a search not targeted to it reflects this metaphor&#8217;s strength.</S>
    <S sid="200" ssid="28">It also illustrates a source of error in inferring the existence of conventional metaphors between domains from the existence of interconcept mappings.</S>
    <S sid="201" ssid="29">The fourth mapping is from containers to organizations.</S>
    <S sid="202" ssid="30">This mapping complements the first one: As liquids flow into containers, so money flows into organizations.</S>
    <S sid="203" ssid="31">Another good mapping, not present here, is money flows into equities and investments.</S>
    <S sid="204" ssid="32">CorMet misses this mapping because, at the level of concepts, money and equities are conflated.</S>
    <S sid="205" ssid="33">This happens because they are near relatives in the WordNet ontology and because there is very high overlap between the predicates selecting for them.</S>
    <S sid="206" ssid="34">Compare the mappings CorMet derived with the Master Metaphor List&#8217;s (Lakoff, Espenson, and Schwartz 1991) characterization of the MONEY IS A LIQUID metaphor: The Master Metaphor List also describes INVESTMENTS ARE CONTAINERS FOR MONEY, as exemplified in the following: CorMet has found mappings that can reasonably be construed as corresponding to these metaphors.</S>
    <S sid="207" ssid="35">Compare the mappings from the Master Metaphor List with frames mined by this system and identified as instantiating liquid &#8594; income, shown in Table 10.</S>
    <S sid="208" ssid="36">It is important to note that although CorMet can list the case frames that have driven the derivation of a particular high-level mapping, it is designed to discover highlevel mappings, not interpret or even recognize particular instances of metaphorical language.</S>
    <S sid="209" ssid="37">Just as in the Master Metaphor List, there are frames in the CorMet listing in which money and equities are characterized as liquids, are moved as liquids (i.e., pouring earnings and pumping reserves) and change state as liquids (i.e., melting stocks, dissolving stakes, evaporating profits, frozen money).</S>
    <S sid="210" ssid="38">This subsection describes the search for mappings between the MEDICINE and MILITARY domains.</S>
    <S sid="211" ssid="39">The domain keywords for MEDICINE and MILITARY are shown in Table 11.</S>
    <S sid="212" ssid="40">The characteristic verbs of the MILITARY and MEDICINE domains are given in Tables 12 and 13, respectively.</S>
    <S sid="213" ssid="41">Their selectional preferences are given in Tables 14 and 15, respectively.</S>
    <S sid="214" ssid="42">The highest-quality mappings between the MILITARY and MEDICINE domains are shown in Table 16.</S>
    <S sid="215" ssid="43">This pair of domains produces more mappings than the the LAB and FINANCE pair.</S>
    <S sid="216" ssid="44">Many source concepts from the MILITARY domain are mapped to body parts.</S>
    <S sid="217" ssid="45">The heterogeneity of the source concepts seems to be driven by the heterogeneity of possible military targets.</S>
    <S sid="218" ssid="46">Similarly, many source concepts are mapped to drugs.</S>
    <S sid="219" ssid="47">The case frames supporting this mapping suggest that this is because of the heterogeneity of military aggressors (fortifications do not generally fall into this category; this mapping is an error caused by the frame extractor&#8217;s frequent confusion of subject and object).</S>
    <S sid="220" ssid="48">These mappings can be interpreted as indicating that things that are attacked map to body parts and things that attack map to drugs.</S>
    <S sid="221" ssid="49">The mapping fortification &#8594; illness represents the mapping of targetable strongholds to disease.</S>
    <S sid="222" ssid="50">Illnesses are conceived of as fortifications besieged by treatment.</S>
    <S sid="223" ssid="51">Compare this with the Master Metaphor List&#8217;s characterization of TREATING ILLNESS IS FIGHTING A WAR: CorMet&#8217;s results can reasonably be interpreted as matching all of the mappings from the Master Metaphor List except winning-is-a-cure and defeat-is-dying.</S>
    <S sid="224" ssid="52">CorMet&#8217;s failure to find this mapping is caused by the fact that win, lose, and their synonyms do not have high salience in the MILITARY domain, which may be a reflection of the ubiquity of win and lose outside of that domain.</S>
    <S sid="225" ssid="53">Table 17 shows sample frames from which the body part &#8594; {fortification, vehicle, military action, region, skilled worker} mapping was derived.</S>
  </SECTION>
  <SECTION title="4." number="5">
    <S sid="226" ssid="1">This section describes the evaluation of CorMet against a gold standard, specifically, by determining how many of the metaphors in a subset of the Master Metaphor List (Lakoff, Espenson, and Schwartz 1991) can be discovered by CorMet given a characterization of the relevant source and target domains.</S>
    <S sid="227" ssid="2">The final evaluation of the correspondence between the mappings CorMet discovers and the Master Metaphor List entry is necessarily done by hand.</S>
    <S sid="228" ssid="3">This is a highly subjective method of evaluation; a formal, objective evaluation of correctness would be preferable, but at present no such metric is available.</S>
    <S sid="229" ssid="4">The Master Metaphor List is the basis for evaluation because it is composed of manually verified metaphors common in English.</S>
    <S sid="230" ssid="5">The test set is restricted to those elements of the Master Metaphor List with concrete source and target domains.</S>
    <S sid="231" ssid="6">This requirement excludes many important conventional metaphors, such as EVENTS ARE ACTIONS.</S>
    <S sid="232" ssid="7">About a fifth of the Master Metaphor List meets this constraint.</S>
    <S sid="233" ssid="8">This fraction is surprisingly small: It turns out that the bulk of the Master Metaphor List consists of subtle refinements of a few highly abstract metaphors.</S>
    <S sid="234" ssid="9">The concept pairs and corresponding domain pairs for the target metaphors in the Master Metaphor List are given in Table 18.</S>
    <S sid="235" ssid="10">A mapping discovered by CorMet is considered correct if submappings specified in the Master Metaphor List are nearly all present with high salience and incorrect submappings are present with comparatively low salience.</S>
    <S sid="236" ssid="11">The mappings discovered that best represent the targeted metaphors are shown in Table 19.</S>
    <S sid="237" ssid="12">Some of these test cases are marked successes.</S>
    <S sid="238" ssid="13">For instance, ECONOMIC HARM IS PHYSICAL INJURY seems to be captured by the mapping from the loss-3 cluster to the harm-1 cluster.</S>
    <S sid="239" ssid="14">CorMet found reasonable mappings in 10 of 13 cases attempted.</S>
    <S sid="240" ssid="15">This implies 77% accuracy, although in light of the small test and the subjectivity of judgment, this number must not be taken too seriously.</S>
    <S sid="241" ssid="16">Some test cases were disappointing.</S>
    <S sid="242" ssid="17">CorMet found no mapping between THEORY and ARCHITECTURE.</S>
    <S sid="243" ssid="18">This seems to be an artifact of the low-quality corpora obtained for these domains.</S>
    <S sid="244" ssid="19">The documents intended to be relevant to architecture were often about zoning or building policy, not the structure of buildings.</S>
    <S sid="245" ssid="20">For theory, many documents were calls for papers or about university department policy.</S>
    <S sid="246" ssid="21">It is unsurprising that there are no particular mappings between two sets of miscellaneous administrative and policy documents.</S>
    <S sid="247" ssid="22">The weakness of the ARCHITECTURE corpus also prevented CorMet from discovering any BODY &#8594; ARCHITECTURE mappings.</S>
    <S sid="248" ssid="23">Accuracy could be improved by refining the process by which domain-specific corpora are obtained to eliminate administrative documents or by requiring documents to have a higher density of domain-relevant terms.</S>
    <S sid="249" ssid="24">Is it meaningful when CorMet finds a mapping, or will it find a mapping between any pair of domains?</S>
    <S sid="250" ssid="25">To answer this question, CorMet was made to search for mappings between randomly selected pairs of domains.</S>
    <S sid="251" ssid="26">Table 20 lists a set of arbitrarily selected domain pairs and the strength of the polarization between them.</S>
    <S sid="252" ssid="27">In all cases, the polarization is zero.</S>
    <S sid="253" ssid="28">This can be interpreted as an encouraging lack of false positives.</S>
    <S sid="254" ssid="29">Another perspective is that CorMet should have found mappings between some of these pairs, such as MEDICINE and SOCIETY, on the theory that societies can be said to sicken, die, or heal.</S>
    <S sid="255" ssid="30">Although this is certainly a valid conventional metaphor, it seems to be less prominent than those metaphors that CorMet did discover.</S>
  </SECTION>
  <SECTION title="5." number="6">
    <S sid="256" ssid="1">Two of the most broadly effective computational models of metaphor are Fass (1991) and Martin (1990), in both of which metaphors are detected through selectionalpreference violations and interpreted using an ontology.</S>
    <S sid="257" ssid="2">They are distinguished from CorMet in that they work on both novel and conventional metaphors and rely on declarative hand-coded knowledge bases.</S>
    <S sid="258" ssid="3">Fass (1991) describes Met*, a system for interpreting nonliteral language that builds on Wilks (1975) and Wilks (1978).</S>
    <S sid="259" ssid="4">Met* discriminates among metonymic, metaphorical, literal, and anomalous language.</S>
    <S sid="260" ssid="5">It is a component of collative semantics, a semantics for natural language processing that has been implemented in the program meta5 (Fass, 1986, 1987, 1988).</S>
    <S sid="261" ssid="6">Met* treats metonymy as a way of referring to one thing by means of another and metaphor as a way of revealing an interesting relationship between two entities.</S>
    <S sid="262" ssid="7">In Met*, a verb&#8217;s selectional preferences are represented as a vector of types.</S>
    <S sid="263" ssid="8">The verb drink&#8217;s preference for an animal subject and a liquid object are represented as (animal, drink, liquid).</S>
    <S sid="264" ssid="9">Metaphorical interpretations are made by finding a sense vector in Met*&#8217;s knowledge base whose elements are hypernyms of both the preferred argument types and the actual arguments.</S>
    <S sid="265" ssid="10">For example, the car drinks gasoline maps to the vector (car, drink, gasoline).</S>
    <S sid="266" ssid="11">But car is not a hypernym of animal, so Met* searches for a metaphorical interpretation, coming up with (thing, use, energy source).</S>
    <S sid="267" ssid="12">Martin (1990) describes the Metaphor Interpretation, Denotation, and Acquisition System (MIDAS), a computational model of metaphor interpretation.</S>
    <S sid="268" ssid="13">MIDAS has been integrated with the Unix Consultant (UC), a program that answers English questions about using Unix.</S>
    <S sid="269" ssid="14">UC tries to find a literal answer to each question with which it is presented.</S>
    <S sid="270" ssid="15">If violations of literal selectional preference make this impossible, UC calls on MIDAS to search its hierarchical library of conventional metaphors for one that explains the anomaly.</S>
    <S sid="271" ssid="16">If no such metaphor is found, MIDAS tries to generalize a known conventional metaphor by abstracting its components to the most-specific senses that encompass the question&#8217;s anomalous language.</S>
    <S sid="272" ssid="17">MIDAS then records the most concrete metaphor descended from the new, general metaphor that provides an explanation for the query&#8217;s language.</S>
    <S sid="273" ssid="18">MIDAS is driven by the idea that novel metaphors are derived from known, existing ones.</S>
    <S sid="274" ssid="19">The hierarchical structure of conventional metaphor is a regularity not captured by other computational approaches.</S>
    <S sid="275" ssid="20">Although MIDAS can quickly understand novel metaphors that are the descendants of metaphors in its memory, it cannot interpret compound metaphors or detect intermetaphor relationships besides inheritance.</S>
    <S sid="276" ssid="21">INVESTMENTS &#8594; CONTAINERS and MONEY &#8594; WATER, for instance, are clearly related, but not in a way that MIDAS can represent.</S>
    <S sid="277" ssid="22">Since not all novel metaphors are descendants of common conventional metaphors, MIDAS&#8217;s coverage is limited.</S>
    <S sid="278" ssid="23">MetaBank (Martin 1994) is an empirically derived knowledge base of conventional metaphors designed for use in natural language applications.</S>
    <S sid="279" ssid="24">MetaBank starts with a knowledge base of metaphors based on the Master Metaphor List.</S>
    <S sid="280" ssid="25">MetaBank can search a corpus for one metaphor or scan a large corpus for any metaphorical content.</S>
    <S sid="281" ssid="26">The search for a target metaphor is accomplished by choosing a set of probe words associated with that metaphor and finding sentences with those words, which are then manually sorted as literal, examples of the target metaphor, examples of a different metaphor, unsystematic homonyms, or something else.</S>
    <S sid="282" ssid="27">MetaBank compiles statistics on the frequency of conventional metaphors and the usefulness of the probe words.</S>
    <S sid="283" ssid="28">MetaBank has been used to study container metaphors in a corpus of UNIX-related e-mail and to study metaphor distributions in the Wall Street Journal.</S>
    <S sid="284" ssid="29">Peters and Peters (2000) mine WordNet for patterns of systematic polysemy by finding pairs of WordNet nodes at a relatively high level in the ontology (but still below the root nodes) whose descendants share a set of common word forms.</S>
    <S sid="285" ssid="30">The nodes publication and publisher, for instance, have paper, newspaper, and magazine as common descendants.</S>
    <S sid="286" ssid="31">This is a metonymic relationship; the system can also capture metaphoric relationships, as in the nodes supporting structure and theory, among whose common descendants are (for example) framework, foundation, and base.</S>
    <S sid="287" ssid="32">Peters and Peters&#8217; system found many metaphoric relationships between node pairs that were descendants of the unique beginners artifact and cognition.</S>
    <S sid="288" ssid="33">Goatly (1997) describes a set of linguistic cues of metaphoricality beyond selectional-preference violations, such as metaphorically speaking and, surprisingly, literally.</S>
    <S sid="289" ssid="34">These cues are generally ambiguous (except for metaphorically speaking) but could usefully be incorporated into computational approaches to metaphor.</S>
  </SECTION>
  <SECTION title="6." number="7">
    <S sid="290" ssid="1">CorMet embodies a method for semiautomatically finding metaphoric mappings between concepts, which can then be used to infer conventionally metaphoric relationships between domains.</S>
    <S sid="291" ssid="2">It can sometimes identify metaphoric language, if it manifests as a common selectional-preference gradient between domains, but is far from being able to recognize metaphoric language in general.</S>
    <S sid="292" ssid="3">CorMet differs from other computational approaches to metaphor in requiring no manually compiled knowledge base besides WordNet.</S>
    <S sid="293" ssid="4">It has successfully found some of the conventional metaphors on the Master Metaphor List.</S>
    <S sid="294" ssid="5">CorMet uses gradients in selectional preferences learned from dynamically mined, domain-specific corpora to identify metaphoric mappings between concepts.</S>
    <S sid="295" ssid="6">It is reasonably accurate despite the noisiness of many of its components.</S>
    <S sid="296" ssid="7">CorMet demonstrates the viability of a computational, corpus-based approach to conventional metaphor but requires more work before it can constitute a viable NLP tool.</S>
  </SECTION>
</PAPER>
