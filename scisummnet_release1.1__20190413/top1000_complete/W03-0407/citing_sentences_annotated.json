[
  {
    "citance_No": 1, 
    "citing_paper_id": "D12-1131", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Alexander M., Rush | Michael John, Collins | Roi, Reichart | Amir, Globerson", 
    "raw_text": "3We do not run self-training for POS tagging as it has been shown unuseful for this application (Clark et al 2003)", 
    "clean_text": "We do not run self-training for POS tagging as it has been shown unuseful for this application (Clark et al 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P05-1044", 
    "citing_paper_authority": 92, 
    "citing_paper_authors": "Noah A., Smith | Jason M., Eisner", 
    "raw_text": "paradigm in which a small amount of labeled data is available (see ,e.g., Clark et al (2003))", 
    "clean_text": "paradigm in which a small amount of labeled data is available (see, e.g., Clark et al (2003)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P07-1078", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Roi, Reichart | Ari, Rappoport", 
    "raw_text": "Indeed, (Clark et al, 2003) applied self training to POS-tagging with poor results, and (Charniak, 1997) applied it to a generative statistical PCFG parser trained on a large seed set (40K sentences), without any gain in performance", 
    "clean_text": "Indeed, (Clark et al, 2003) applied self training to POS-tagging with poor results, and (Charniak, 1997) applied it to a generative statistical PCFG parser trained on a large seed set (40K sentences), without any gain in performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P10-2038", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anders, S&oslash;gaard", 
    "raw_text": "Clark et al (2003) reported positive results with little labeled training data but negative results when the amount of labeled training data increased; the same seems to be the case in Wang et al (2007) who use co-training of two diverse POS taggers", 
    "clean_text": "Clark et al (2003) reported positive results with little labeled training data but negative results when the amount of labeled training data increased; the same seems to be the case in Wang et al (2007) who use co-training of two diverse POS taggers.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "N09-2054", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Zhongqiang, Huang | Vladimir, Eidelman | Mary P., Harper", 
    "raw_text": "Clark et al (2003) reported positive results with little labeled training data but negative results when the amount of labeled training data increases", 
    "clean_text": "Clark et al (2003) reported positive results with little labeled training data but negative results when the amount of labeled training data increases.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "N06-1020", 
    "citing_paper_authority": 88, 
    "citing_paper_authors": "David, McClosky | Eugene, Charniak | Mark, Johnson", 
    "raw_text": "Clark et al (2003) applies self-training to POS-tagging and reports the same outcomes", 
    "clean_text": "Clark et al (2003) applies self-training to POS-tagging and reports the same outcomes.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-2146", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Shulamit, Umansky-Pesin | Roi, Reichart | Ari, Rappoport", 
    "raw_text": "Interestingly, previous works did not succeed in improving POS tagging performance using self-training (Clark et al, 2003)", 
    "clean_text": "Interestingly, previous works did not succeed in improving POS tagging performance using self-training (Clark et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P10-1036", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jonathan K., Kummerfeld | Jessika, Roesner | Tim, Dawborn | James, Haggerty | James R., Curran | Stephen, Clark", 
    "raw_text": "Clark et al (2003) were unable to improve the accuracy of POS tagging using self-training. In contrast, McClosky et al (2006a) report improved accuracy through self-training for a two stage parser and re-ranker", 
    "clean_text": "Clark et al (2003) were unable to improve the accuracy of POS tagging using self-training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "H05-1107", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Chenhai, Xi | Rebecca, Hwa", 
    "raw_text": "Co-training has been applied to a number of NLP applications ,including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001)", 
    "clean_text": "Co-training has been applied to a number of NLP applications, including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P10-3016", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rasoul, Samad Zadeh Kaljahi", 
    "raw_text": "Referenceresolution (Ng and Cardie 2003), POS tagging (Clark et al, 2003), and parsing (McClosky et al, 2006) were shown to be benefited from self-training", 
    "clean_text": "Reference resolution (Ng and Cardie 2003), POS tagging (Clark et al, 2003), and parsing (McClosky et al, 2006) were shown to be benefited from self-training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W11-0223", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Antonio, Jimeno Yepes | Alan R., Aronson", 
    "raw_text": "For self-training we use the definition by (Clark et al., 2003):? a tagger that is retrained on its own labeled cache on each round?", 
    "clean_text": "For self-training we use the definition by (Clark et al., 2003): a tagger that is retrained on its own labeled cache on each round.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D10-1069", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Slav, Petrov | Pi-Chuan, Chang | Michael, Ringgaard | Hiyan, Alshawi", 
    "raw_text": "Steedman et al (2003) and Clark et al (2003) present co-training procedures for parsers and taggers respectively, which are effective when only very little labeled data is available", 
    "clean_text": "Steedman et al (2003) and Clark et al (2003) present co-training procedures for parsers and taggers respectively, which are effective when only very little labeled data is available.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W11-0412", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Md. Faisal Mahbub, Chowdhury | Alberto, Lavelli", 
    "raw_text": "According to Clark et al (2003), self-training is a procedure in which? a tagger is retrained on its own labeled cache at each round?", 
    "clean_text": "According to Clark et al (2003), self-training is a procedure in which a tagger is retrained on its own labeled cache at each round.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W04-2405", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "In natural language learning, co-training was applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), and others, and was generally found to bring improvement over the case when no additional unlabeled data are used. One important aspect of co-training consists in the relation between the views used in learning", 
    "clean_text": "In natural language learning, co-training was applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), and others, and was generally found to bring improvement over the case when no additional unlabeled data are used.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W04-2405", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "Moreover, (Clark et al, 2003) show that a naive co-training process that does not explicitly seek to maximize agreement on unlabelled data canlead to similar performance, at a much lower computational cost", 
    "clean_text": "Moreover, (Clark et al, 2003) show that a naive co-training process that does not explicitly seek to maximize agreement on unlabelled data can lead to similar performance, at a much lower computational cost.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W04-2405", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "(Clark et al, 2003) provide a different definition: self-training is performed using? a tagger that is retrained on its own labeled cache on each round?", 
    "clean_text": "(Clark et al, 2003) provide a different definition: self-training is performed using a tagger that is retrained on its own labeled cache on each round.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W04-2405", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "However, as theoretically shown in (Abney, 2002), and then empirically in (Clark et al,2003), co-training still works under a weaker independence assumption, and the results we obtain concur with these previous observations", 
    "clean_text": "However, as theoretically shown in (Abney, 2002), and then empirically in (Clark et al,2003), co-training still works under a weaker independence assumption, and the results we obtain concur with these previous observations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P09-1027", 
    "citing_paper_authority": 30, 
    "citing_paper_authors": "Xiaojun, Wan", 
    "raw_text": "Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001)", 
    "clean_text": "Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "E12-1017", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Rishav, Bhowmick | Kemal, Oflazer | Behrang, Mohit | Nathan, Schneider | Noah A., Smith", 
    "raw_text": "Following Clark et al (2003), we applied self training as described in Algorithm 1, with theperceptron as the supervised learner", 
    "clean_text": "Following Clark et al (2003), we applied self training as described in Algorithm 1, with the perceptron as the supervised learner.", 
    "keep_for_gold": 0
  }
]
