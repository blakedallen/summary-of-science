<PAPER>
  <S sid="0">Synchronous Binarization For Machine Translation</S>
  <ABSTRACT>
    <S sid="1" ssid="1">Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output, but are often very computationally intensive.</S>
    <S sid="2" ssid="2">The complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large.</S>
    <S sid="3" ssid="3">We devise a linear-time algorithm for factoring syntactic re-orderings by binarizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of a state-of-the-art syntax-based machine translation system.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="4" ssid="1">Several recent syntax-based models for machine translation (Chiang, 2005; Galley et al., 2004) can be seen as instances of the general framework of synchronous grammars and tree transducers.</S>
    <S sid="5" ssid="2">In this framework, both alignment (synchronous parsing) and decoding can be thought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right hand side of a grammar rule.</S>
    <S sid="6" ssid="3">To alleviate this problem, we investigate bilingual binarization to factor the synchronous grammar to a smaller branching factor, although it is not guaranteed to be successful for any synchronous rule with arbitrary permutation.</S>
    <S sid="7" ssid="4">In particular: &#8226; We develop a technique called synchronous binarization and devise a fast binarization algorithm such that the resulting rule set allows efficient algorithms for both synchronous parsing and decoding with integrated n-gram language models.</S>
    <S sid="8" ssid="5">&#8226; We examine the effect of this binarization method on end-to-end machine translation quality, compared to a more typical baseline method.</S>
    <S sid="9" ssid="6">&#8226; We examine cases of non-binarizable rules in a large, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules.</S>
    <S sid="10" ssid="7">Melamed (2003) discusses binarization of multitext grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing.</S>
    <S sid="11" ssid="8">One way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) (Wu, 1997) and the binary synchronous context-free grammar (SCFG) employed by the Hiero system (Chiang, 2005) to model the hierarchical phrases.</S>
    <S sid="12" ssid="9">In contrast, the rule extraction method of Galley et al. (2004) aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses.</S>
    <S sid="13" ssid="10">This approach results in rules with many nonterminals, making good binarization techniques critical.</S>
    <S sid="14" ssid="11">Suppose we have the following SCFG, where superscripts indicate reorderings (formal definitions of SCFGs can be found in Section 2): VP held a meeting, juxing le huitan PP with Sharon, yu Shalong Decoding can be cast as a (monolingual) parsing problem since we only need to parse the sourcelanguage side of the SCFG, as if we were constructing a CFG projected on Chinese out of the SCFG.</S>
    <S sid="15" ssid="12">The only extra work we need to do for decoding is to build corresponding target-language (English) subtrees in parallel.</S>
    <S sid="16" ssid="13">In other words, we build synchronous trees when parsing the source-language input, as shown in Figure 1.</S>
    <S sid="17" ssid="14">To efficiently decode with CKY, we need to binarize the projected CFG grammar.'</S>
    <S sid="18" ssid="15">Rules can be binarized in different ways.</S>
    <S sid="19" ssid="16">For example, we could binarize the first rule left to right or right to left:</S>
  </SECTION>
  <SECTION title="S NP VPP-VP VPP-VP PP VP" number="2">
    <S sid="20" ssid="1">We call those intermediate symbols (e.g.</S>
    <S sid="21" ssid="2">VPP-VP) virtual nonterminals and corresponding rules virtual rules, whose probabilities are all set to 1.</S>
    <S sid="22" ssid="3">These two binarizations are no different in the translation-model-only decoding described above, just as in monolingual parsing.</S>
    <S sid="23" ssid="4">However, in the source-channel approach to machine translation, we need to combine probabilities from the translation model (an SCFG) with the language model (an ngram), which has been shown to be very important for translation quality (Chiang, 2005).</S>
    <S sid="24" ssid="5">To do bigram-integrated decoding, we need to augment each chart item (X, i, j) with two target-language boundary words u and v to produce a bigram-item like u X v \ , following the dynamic program(i j ming algorithm of Wu (1996).</S>
    <S sid="25" ssid="6">Now the two binarizations have very different effects.</S>
    <S sid="26" ssid="7">In the first case, we first combine NP with PP: where p and q are the scores of antecedent items.</S>
    <S sid="27" ssid="8">This situation is unpleasant because in the targetlanguage NP and PP are not contiguous so we cannot apply language model scoring when we build the VNP-PP item.</S>
    <S sid="28" ssid="9">Instead, we have to maintain all four boundary words (rather than two) and postpone the language model scoring till the next step where VNP-PP is combined with C held &#183;&#183;&#183; meeting l /I to form an S item.</S>
  </SECTION>
  <SECTION title="2 VP 4" number="3">
    <S sid="29" ssid="1">We call this binarization method monolingual binarization since it works only on the source-language projection of the rule without respecting the constraints from the other side.</S>
    <S sid="30" ssid="2">This scheme generalizes to the case where we have n nonterminals in a SCFG rule, and the decoder conservatively assumes nothing can be done on language model scoring (because target-language spans are non-contiguous in general) until the real nonterminal has been recognized.</S>
    <S sid="31" ssid="3">In other words, targetlanguage boundary words from each child nonterminal of the rule will be cached in all virtual nonterminals derived from this rule.</S>
    <S sid="32" ssid="4">In the case of m-gram integrated decoding, we have to maintain 2(m &#8722; 1) boundary words for each child nonterminal, which leads to a prohibitive overall complexity of O(|w|3+2n(m&#8722;1)), which is exponential in rule size (Huang et al., 2005).</S>
    <S sid="33" ssid="5">Aggressive pruning must be used to make it tractable in practice, which in general introduces many search errors and adversely affects translation quality.</S>
    <S sid="34" ssid="6">In the second case, however: Here since PP and VP are contiguous (but swapped) in the target-language, we can include the language model score by adding Pr(with  |meeting), and the resulting item again has two boundary words.</S>
    <S sid="35" ssid="7">Later we add Pr(held  |Powell) when the resulting item is combined with &#65533; Powell &#65533;&#65533;&#65533; Powell form an S item.</S>
    <S sid="36" ssid="8">As illustrated in Figure 2, VPP-VP has contiguous spans on both source and target sides, so that we can generate a binary-branching SCFG: In this case m-gram integrated decoding can be done in O(|w|3+4(m&#8722;1)) time which is much lowerorder polynomial and no longer depends on rule size (Wu, 1996), allowing the search to be much faster and more accurate facing pruning, as is evidenced in the Hiero system of Chiang (2005) where he restricts the hierarchical phrases to be a binary SCFG.</S>
    <S sid="37" ssid="9">The benefit of binary grammars also lies in synchronous parsing (alignment).</S>
    <S sid="38" ssid="10">Wu (1997) shows that parsing a binary SCFG is in O(|w|6) while parsing SCFG is NP-hard in general (Satta and Peserico, 2005).</S>
    <S sid="39" ssid="11">The same reasoning applies to tree transducer rules.</S>
    <S sid="40" ssid="12">Suppose we have the following tree-to-string rules, following Galley et al. (2004): where the reorderings of nonterminals are denoted by variables xi.</S>
    <S sid="41" ssid="13">Notice that the first rule has a multi-level lefthand side subtree.</S>
    <S sid="42" ssid="14">This system can model nonisomorphic transformations on English parse trees to &#8220;fit&#8221; another language, for example, learning that the (S (V O)) structure in English should be transformed into a (V S O) structure in Arabic, by looking at two-level tree fragments (Knight and Graehl, 2005).</S>
    <S sid="43" ssid="15">From a synchronous rewriting point of view, this is more akin to synchronous tree substitution grammar (STSG) (Eisner, 2003).</S>
    <S sid="44" ssid="16">This larger locality is linguistically motivated and leads to a better parameter estimation.</S>
    <S sid="45" ssid="17">By imagining the left-hand-side trees as special nonterminals, we can virtually create an SCFG with the same generative capacity.</S>
    <S sid="46" ssid="18">The technical details will be explained in Section 3.2.</S>
    <S sid="47" ssid="19">In general, if we are given an arbitrary synchronous rule with many nonterminals, what are the good decompositions that lead to a binary grammar?</S>
    <S sid="48" ssid="20">Figure 2 suggests that a binarization is good if every virtual nonterminal has contiguous spans on both sides.</S>
    <S sid="49" ssid="21">We formalize this idea in the next section.</S>
  </SECTION>
  <SECTION title="2 Synchronous Binarization" number="4">
    <S sid="50" ssid="1">A synchronous CFG (SCFG) is a context-free rewriting system for generating string pairs.</S>
    <S sid="51" ssid="2">Each rule (synchronous production) rewrites a nonterminal in two dimensions subject to the constraint that the sequence of nonterminal children on one side is a permutation of the nonterminal sequence on the other side.</S>
    <S sid="52" ssid="3">Each co-indexed child nonterminal pair will be further rewritten as a unit.2 We define the language L(G) produced by an SCFG G as the pairs of terminal strings produced by rewriting exhaustively from the start symbol.</S>
    <S sid="53" ssid="4">As shown in Section 3.2, terminals do not play an important role in binarization.</S>
    <S sid="54" ssid="5">So we now write rules in the following notation: where each Xi is a variable which ranges over nonterminals in the grammar and &#960; is the permutation of the rule.</S>
    <S sid="55" ssid="6">We also define an SCFG rule as n-ary if its permutation is of n and call an SCFG n-ary if its longest rule is n-ary.</S>
    <S sid="56" ssid="7">Our goal is to produce an equivalent binary SCFG for an input n-ary SCFG.</S>
    <S sid="57" ssid="8">2In making one nonterminal play dual roles, we follow the definitions in (Aho and Ullman, 1972; Chiang, 2005), originally known as Syntax Directed Translation Schema (SDTS).</S>
    <S sid="58" ssid="9">An alternative definition by Satta and Peserico (2005) allows co-indexed nonterminals taking different symbols in two dimensions.</S>
    <S sid="59" ssid="10">Formally speaking, we can construct an equivalent SDTS by creating a cross-product of nonterminals from two sides.</S>
    <S sid="60" ssid="11">See (Satta and Peserico, 2005, Sec.</S>
    <S sid="61" ssid="12">4) for other details.</S>
    <S sid="62" ssid="13">However, not every SCFG can be binarized.</S>
    <S sid="63" ssid="14">In fact, the binarizability of an n-ary rule is determined by the structure of its permutation, which can sometimes be resistant to factorization (Aho and Ullman, 1972).</S>
    <S sid="64" ssid="15">So we now start to rigorously define the binarizability of permutations.</S>
    <S sid="65" ssid="16">A permuted sequence is a permutation of consecutive integers.</S>
    <S sid="66" ssid="17">For example, (3, 5, 4) is a permuted sequence while (2, 5) is not.</S>
    <S sid="67" ssid="18">As special cases, single numbers are permuted sequences as well.</S>
    <S sid="68" ssid="19">A sequence a is said to be binarizable if it is a permuted sequence and either This is a recursive definition.</S>
    <S sid="69" ssid="20">Each binarizable permuted sequence has at least one hierarchical binarization pattern.</S>
    <S sid="70" ssid="21">For instance, the permuted sequence (2, 3, 5, 4) is binarizable (with two possible binarization patterns) while (2, 4,1, 3) is not (see Figure 3).</S>
    <S sid="71" ssid="22">An SCFG is said to be binarizable if the permutation of each synchronous production is binarizable.</S>
    <S sid="72" ssid="23">We denote the class of binarizable SCFGs as bSCFG.</S>
    <S sid="73" ssid="24">This set represents an important subclass of SCFG that is easy to handle (parsable in O(|w|6)) and covers many interesting longer-than-two rules.3 Proof.</S>
    <S sid="74" ssid="25">Once we decompose the permutation of n in the original rule into binary permutations, all that remains is to decorate the skeleton binary parse with nonterminal symbols and attach terminals to the skeleton appropriately.</S>
    <S sid="75" ssid="26">We explain the technical details in the next section.</S>
  </SECTION>
  <SECTION title="3 Binarization Algorithms" number="5">
    <S sid="76" ssid="1">We have reduced the problem of binarizing an SCFG rule into the problem of binarizing its permutation.</S>
    <S sid="77" ssid="2">This problem can be cast as an instance of synchronous ITG parsing (Wu, 1997).</S>
    <S sid="78" ssid="3">Here the parallel string pair that we are parsing is the integer sequence (1...n) and its permutation (7r(1)...7r(n)).</S>
    <S sid="79" ssid="4">The goal of the ITG parsing is to find a synchronous tree that agrees with the alignment indicated by the permutation.</S>
    <S sid="80" ssid="5">In fact, as demonstrated previously, some permutations may have more than one binarization patterns among which we only need one.</S>
    <S sid="81" ssid="6">Wu (1997, Sec.</S>
    <S sid="82" ssid="7">7) introduces a non-ambiguous ITG that prefers left-heavy binary trees so that for each permutation there is a unique synchronous derivation (binarization pattern).</S>
    <S sid="83" ssid="8">However, this problem has more efficient solutions.</S>
    <S sid="84" ssid="9">Shapiro and Stephens (1991, p. 277) informally present an iterative procedure where in each pass it scans the permuted sequence from left to right and combines two adjacent sub sequences whenever possible.</S>
    <S sid="85" ssid="10">This procedure produces a left-heavy binarization tree consistent with the unambiguous ITG and runs in O(n2) time since we need n passes in the worst case.</S>
    <S sid="86" ssid="11">We modify this procedure and improve circle in Figure 4), which can be binarized only by analyzing interactions between rules.</S>
    <S sid="87" ssid="12">Below is a simple example: it into a linear-time shift-reduce algorithm that only needs one pass through the sequence.</S>
    <S sid="88" ssid="13">The (unique) binarization tree bi(a) for a binarizable permuted sequence a is recursively defined as follows: For example, the binarization tree for (2, 3, 5, 4) is [[2, 3], (5, 4)], which corresponds to the binarization pattern in Figure 3(a).</S>
    <S sid="89" ssid="14">We use [] and () for straight and inverted combinations respectively, following the ITG notation (Wu, 1997).</S>
    <S sid="90" ssid="15">The rightmost split ensures left-heavy binary trees.</S>
    <S sid="91" ssid="16">The skeleton binarization algorithm is an instance of the widely used left-to-right shift-reduce algorithm.</S>
    <S sid="92" ssid="17">It maintains a stack for contiguous subsequences discovered so far, like 2-5, 1.</S>
    <S sid="93" ssid="18">In each iteration, it shifts the next number from the input and repeatedly tries to reduce the top two elements on the stack if they are consecutive.</S>
    <S sid="94" ssid="19">See Algorithm 1 for details and Figure 5 for an example.</S>
    <S sid="95" ssid="20">260 Proof.</S>
    <S sid="96" ssid="21">&#8212;*: it is obvious that if the algorithm succeeds then a is binarizable using the binarization pattern recovered.</S>
    <S sid="97" ssid="22">+&#8212;: by a complete induction on n, the length of a.</S>
    <S sid="98" ssid="23">Base case: n = 1, trivial.</S>
    <S sid="99" ssid="24">Assume it holds for all n' &lt; n. If a is binarizable, then let a = (b; c) be its rightmost binarizable split.</S>
    <S sid="100" ssid="25">By the induction hypothesis, the algorithm succeeds on the partial input b, reducing it to the single element on the stack and recovering its binarization tree bi(b).</S>
    <S sid="101" ssid="26">Let c = c2).</S>
    <S sid="102" ssid="27">If is binarizable and triggers our binarizer to make a straight combination of (b; must be true that nation.</S>
    <S sid="103" ssid="28">We claim that c2 must be binarizable in this situation.</S>
    <S sid="104" ssid="29">So, (b, right of the rightmost binarizable split (b; c), which is a contradiction.</S>
    <S sid="105" ssid="30">A similar contradiction will arise if b and can make an inverted concatenation.</S>
    <S sid="106" ssid="31">Therefore, the algorithm will scan through the whole c as if from the empty stack.</S>
    <S sid="107" ssid="32">By the induction hypothesis again, it will reduce c into s[1] on the stack and recover its binarization tree bi(c).</S>
    <S sid="108" ssid="33">Since b and c are combinable, the algorithm reduces s[0] and s[1] in the last step, forming the binari zation tree for a, which is either [bi(b), bi(c)] or (bi(b), bi(c)). based on the property of permutations, it c2) is a valid straight concatec2) is a binarizable split to the are exactly n shifts and at most reductions, and n&#8722;1 O(1) time.</S>
    <S sid="109" ssid="34">The running time of Algorithm 1 is linear in n, the length of the input sequence.</S>
    <S sid="110" ssid="35">This is because there each shift or reduction takes Without loss of generality, we have discussed how to binarize synchronous productions involving only nonterminals through binarizing the corresponding skeleton permutations.</S>
    <S sid="111" ssid="36">We still need to tackle a few technical problems in the actual system.</S>
    <S sid="112" ssid="37">First, we are dealing with tree-to-string transducer rules.</S>
    <S sid="113" ssid="38">We view each left-hand side subtree as a monolithic nonterminal symbol and factor each transducer rule into two SCFG rules: one from the root nonterminal to the subtree, and the other from the subtree to the leaves.</S>
    <S sid="114" ssid="39">In this way we can uniquely reconstruct the tree-to-string derivation using the two-step SCFG deri vation.</S>
    <S sid="115" ssid="40">For example, Algorithm 1 The Linear-time Binarization Algorithm consider the following tree-to-string rule: DT x2:NN the We create a specific nonterminal, say, T859, which is a unique identifier for the left-hand side subtree and generate the following two SCFG rules: Second, besides synchronous nonterminals, terminals in the two languages can also be present, as in the above example.</S>
    <S sid="116" ssid="41">It turns out we can attach the terminals to the skeleton parse for the synchronous nonterminal strings quite freely as long as we can uniquely reconstruct the original rule from its binary parse tree.</S>
    <S sid="117" ssid="42">In order to do so we need to keep track of sub-alignments including both aligned nonterminals and neighboring terminals.</S>
    <S sid="118" ssid="43">When binarizing the second rule above, we first run the skeleton algorithm to binarize the underlying permutation (1, 3, 2) to its binarization tree [1, (3, 2)].</S>
    <S sid="119" ssid="44">Then we do a post-order traversal to the skeleton tree, combining Chinese terminals (one at a time) at the leaf nodes and merging English terminals greedily at internal nodes: A pre-order traversal of the decorated binarization tree gives us the following binary SCFG rules: where the virtual nonterminals are: Analogous to the &#8220;dotted rules&#8221; in Earley parsing for monolingual CFGs, the names we create for the virtual nonterminals reflect the underlying sub-alignments, ensuring intermediate states can be shared across different tree-to-string rules without causing ambiguity.</S>
    <S sid="120" ssid="45">The whole binarization algorithm still runs in time linear in the number of symbols in the rule (including both terminals and nonterminals).</S>
  </SECTION>
  <SECTION title="4 Experiments" number="6">
    <S sid="121" ssid="1">In this section, we answer two empirical questions.</S>
    <S sid="122" ssid="2">It has been shown by Shapiro and Stephens (1991) and Wu (1997, Sec.</S>
    <S sid="123" ssid="3">4) that the percentage of binarizable cases over all permutations of length n quickly approaches 0 as n grows (see Figure 6).</S>
    <S sid="124" ssid="4">However, for machine translation, it is more meaningful to compute the ratio of binarizable rules extracted from real text.</S>
    <S sid="125" ssid="5">Our rule set is obtained by first doing word alignment using GIZA++ on a Chinese-English parallel corpus containing 50 million words in English, then parsing the English sentences using a variant of Collins parser, and finally extracting rules using the graph-theoretic algorithm of Galley et al. (2004).</S>
    <S sid="126" ssid="6">We did a &#8220;spectrum analysis&#8221; on the resulting rule set with 50,879,242 rules.</S>
    <S sid="127" ssid="7">Figure 6 shows how the rules are distributed against their lengths (number of nonterminals).</S>
    <S sid="128" ssid="8">We can see that the percentage of non-binarizable rules in each bucket of the same length does not exceed 25%.</S>
    <S sid="129" ssid="9">Overall, 99.7% of the rules are binarizable.</S>
    <S sid="130" ssid="10">Even for the 0.3% nonbinarizable rules, human evaluations show that the majority of them are due to alignment errors.</S>
    <S sid="131" ssid="11">It is also interesting to know that 86.8% of the rules have monotonic permutations, i.e. either taking identical or totally inverted order.</S>
    <S sid="132" ssid="12">We did experiments on our CKY-based decoder with two binarization methods.</S>
    <S sid="133" ssid="13">It is the responsibility of the binarizer to instruct the decoder how to compute the language model scores from children nonterminals in each rule.</S>
    <S sid="134" ssid="14">The baseline method is monolingual left-to-right binarization.</S>
    <S sid="135" ssid="15">As shown in Section 1, decoding complexity with this method is exponential in the size of the longest rule and since we postpone all the language model scorings, pruning in this case is also biased. system bleu monolingual binarization 36.25 synchronous binarization 38.44 To move on to synchronous binarization, we first did an experiment using the above baseline system without the 0.3% non-binarizable rules and did not observe any difference in BLEU scores.</S>
    <S sid="136" ssid="16">So we safely move a step further, focusing on the binarizable rules only.</S>
    <S sid="137" ssid="17">The decoder now works on the binary translation rules supplied by an external synchronous binarizer.</S>
    <S sid="138" ssid="18">As shown in Section 1, this results in a simplified decoder with a polynomial time complexity, allowing less aggressive and more effective pruning based on both translation model and language model scores.</S>
    <S sid="139" ssid="19">We compare the two binarization schemes in terms of translation quality with various pruning thresholds.</S>
    <S sid="140" ssid="20">The rule set is that of the previous section.</S>
    <S sid="141" ssid="21">The test set has 116 Chinese sentences of no longer than 15 words.</S>
    <S sid="142" ssid="22">Both systems use trigram as the integrated language model.</S>
    <S sid="143" ssid="23">Figure 7 demonstrates that decoding accuracy is significantly improved after synchronous binarization.</S>
    <S sid="144" ssid="24">The number of edges proposed during decoding is used as a measure of the size of search space, or time efficiency.</S>
    <S sid="145" ssid="25">Our system is consistently faster and more accurate than the baseline system.</S>
    <S sid="146" ssid="26">We also compare the top result of our synchronous binarization system with the state-of-theart alignment-template approach (ATS) (Och and Ney, 2004).</S>
    <S sid="147" ssid="27">The results are shown in Table 1.</S>
    <S sid="148" ssid="28">Our system has a promising improvement over the ATS system which is trained on a larger data-set but tuned independently.</S>
  </SECTION>
  <SECTION title="5 Conclusion" number="7">
    <S sid="149" ssid="1">Modeling reorderings between languages has been a major challenge for machine translation.</S>
    <S sid="150" ssid="2">This work shows that the majority of syntactic reorderings, at least between languages like English and Chinese, can be efficiently decomposed into hierarchical binary reorderings.</S>
    <S sid="151" ssid="3">From a modeling perspective, on the other hand, it is beneficial to start with a richer representation that has more transformational power than ITG or binary SCFG.</S>
    <S sid="152" ssid="4">Our work shows how to convert it back to a computationally friendly form without harming much of its expressiveness.</S>
    <S sid="153" ssid="5">As a result, decoding with n-gram models can be fast and accurate, making it possible for our syntax-based system to overtake a comparable phrase-based system in BLEU score.</S>
    <S sid="154" ssid="6">We believe that extensions of our technique to more powerful models such as synchronous tree-adjoining grammar (Shieber and Schabes, 1990) is an interesting area for further work.</S>
    <S sid="155" ssid="7">Acknowledgments Much of this work was done when H. Zhang and L. Huang were visiting USC/ISI.</S>
    <S sid="156" ssid="8">The authors wish to thank Wei Wang, Jonathan Graehl and Steven DeNeefe for help with the experiments.</S>
    <S sid="157" ssid="9">We are also grateful to Daniel Marcu, Giorgio Satta, and Aravind Joshi for discussions.</S>
    <S sid="158" ssid="10">This work was partially supported by NSF ITR IIS-09325646 and NSF ITR IIS-0428020.</S>
  </SECTION>
</PAPER>
