Dependency Parsing by Belief Propagation
We formulate dependency parsing as a graphical model with the novel ingredient of global constraints.
We show how to apply loopy belief propagation (BP), a simple and effective tool for approximate learning and inference.
As a parsing algorithm, BP is both asymptotically and empirically efficient.
Even with second-order features or latent variables, which would make exact parsing considerably slower or NP-hard, BP needs only O(n3) time with a small constant factor.
Furthermore, such features significantly improve parse accuracy over exact first-order methods.
Incorporating additional features would increase the runtime additively rather than multiplicatively.
We can encapsulate common dynamic programming algorithms within special-purpose factors to efficiently globally constrain variable configurations.
DEP-TREE is a global combinatorial factor which attaches to all Link (i, j) variables and similarly contributes a factor of 1 iff the configuration of Link variables forms a valid projective dependency graph.
