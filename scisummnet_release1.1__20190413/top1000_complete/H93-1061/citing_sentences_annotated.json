[
  {
    "citance_No": 1, 
    "citing_paper_id": "W00-1326", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "David, Martinez | Eneko, Agirre", 
    "raw_text": "Since the papers were published, word sense disambiguation has moved to deal with fine grained sense distinctions from widely recognized semantic lexical resources; ontologies like Sensus, Cyc, EDR, WordNet, EuroWordNet, etc. or machine-readable dictionaries like OALDC, Webster &apos; s, LDOCE, etc. This is due, in part, to the availability of public hand-tagged material ,e.g. SemCor (Miller et al, 1993) and the DSO collection (Ng& amp; Lee, 1996)", 
    "clean_text": "This is due, in part, to the availability of public hand-tagged material, e.g. SemCor (Miller et al, 1993) and the DSO collection (Ng & Lee, 1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1025", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jey Han, Lau | Paul, Cook | Diana, McCarthy | Spandana, Gella | Timothy, Baldwin", 
    "raw_text": "This is important because word sense distributions are typically skewed (Kilgarriff, 2004), and systems do far better when they take bias into ac count (Agirre and Martinez, 2004) .Typically, word frequency distributions are estimated with respect to a sense-tagged corpus such as SemCor (Miller et al, 1993), a 220,000 word corpus tagged with WordNet (Fellbaum, 1998) senses", 
    "clean_text": "Typically, word frequency distributions are estimated with respect to a sense-tagged corpus such as SemCor (Miller et al, 1993), a 220,000 word corpus tagged with WordNet (Fellbaum, 1998) senses.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W07-2090", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rada, Mihalcea | Andras, Csomai | Massimiliano, Ciaramita", 
    "raw_text": "We base our experiment son SemCor (Miller et al, 1993), a balanced ,semantically annotated dataset, with all content words manually tagged by trained lexicographers. The input to the disambiguation algorithm consists of raw text", 
    "clean_text": "We base our experiments on SemCor (Miller et al, 1993), a balanced, semantically annotated dataset, with all content words manually tagged by trained lexicographers.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D09-1046", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Katrin, Erk | Diana, McCarthy", 
    "raw_text": "The sentences that we use from the GWS dataset were originally extracted from the English SENSEVAL-3 lexical sample task (Mihalcea et al, 2004) (hereafter SE-3) and SemCor (Miller et al, 1993)", 
    "clean_text": "The sentences that we use from the GWS dataset were originally extracted from the English SENSEVAL-3 lexical sample task (Mihalcea et al, 2004) (hereafter SE-3) and SemCor (Miller et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P07-1123", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Rada, Mihalcea | Carmen, Banea | Janyce, Wiebe", 
    "raw_text": "In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al, 1993) and their manual translations into Romanian.3 The corpus consists of roughly 11,000 sentences, with approximately 250,000 tokens on each side", 
    "clean_text": "In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al, 1993) and their manual translations into Romanian.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W06-3814", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Eneko, Agirre | David, Martinez | Oier, L&oacute;pez de Lacalle | Aitor, Soroa", 
    "raw_text": "Existing hand annotated corpora like SemCor (Miller et al, 1993), which is annotated with WordNet senses (Fellbaum, 1998) allow for a small improvement over the simple most frequent sense heuristic, as attested in the all words track of the last Senseval competition (Snyder and Palmer, 2004)", 
    "clean_text": "Existing hand annotated corpora like SemCor (Miller et al, 1993), which is annotated with WordNet senses (Fellbaum, 1998) allow for a small improvement over the simple most frequent sense heuristic, as attested in the all words track of the last Senseval competition (Snyder and Palmer, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W07-2074", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Eneko, Agirre | Oier, L&oacute;pez de Lacalle", 
    "raw_text": "To train the classifiers for the all-words task we just used Semcor (Miller et al, 1993)", 
    "clean_text": "To train the classifiers for the all-words task we just used Semcor (Miller et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P10-1138", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Celina, Santamar&iacute;a | Julio, Gonzalo | Javier, Artiles", 
    "raw_text": "This is roughly comparable with most frequent sense figures in standard annotated corpora such as Semcor (Miller et al, 1993) and the Senseval/Semeval data sets, which suggests that diversity may not play a major role in the current Google ranking algorithm", 
    "clean_text": "This is roughly comparable with most frequent sense figures in standard annotated corpora such as Semcor (Miller et al, 1993) and the Senseval/Semeval data sets, which suggests that diversity may not play a major role in the current Google ranking algorithm.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P05-2006", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Marta, Tatu", 
    "raw_text": "Cor text collection (Miller et al, 1993), a subset of the Brown corpus manually tagged with WordNet senses (37,176 sentences in 352 newspaper articles)", 
    "clean_text": "Cor text collection (Miller et al, 1993), a subset of the Brown corpus manually tagged with WordNet senses (37,176 sentences in 352 newspaper articles).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W06-1670", 
    "citing_paper_authority": 35, 
    "citing_paper_authors": "Massimiliano, Ciaramita | Yasemin, Altun", 
    "raw_text": "To this ex tent, we cast the supersense tagging problem as a sequence labeling task and train a discriminative Hidden Markov Model (HMM), based on that of Collins (2002), on the manually annotated Semcor corpus (Miller et al, 1993)", 
    "clean_text": "To this extent, we cast the supersense tagging problem as a sequence labeling task and train a discriminative Hidden Markov Model (HMM), based on that of Collins (2002), on the manually annotated Semcor corpus (Miller et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W06-1670", 
    "citing_paper_authority": 35, 
    "citing_paper_authors": "Massimiliano, Ciaramita | Yasemin, Altun", 
    "raw_text": "We experimented with the following data-sets3. The Semcor corpus (Miller et al, 1993), a fraction of the Brown corpus (Kuc? era and Francis, 1967) which has been manually annotated withWordnet synset labels", 
    "clean_text": "The Semcor corpus (Miller et al, 1993), a fraction of the Brown corpus (Kucera and Francis, 1967) which has been manually annotated with Wordnet synset labels.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W09-2420", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Eneko, Agirre | Oier, L&oacute;pez de Lacalle | Christiane, Fellbaum | Andrea, Marchetti | Antonio, Toral | Piek, Vossen", 
    "raw_text": "Most of current all-words generic supervised WSD systems take SemCor (Miller et al, 1993) as their source corpus ,i.e. they are trained on SemCorexamples and then applied to new examples", 
    "clean_text": "Most of current all-words generic supervised WSD systems take SemCor (Miller et al, 1993) as their source corpus, i.e. they are trained on SemCor examples and then applied to new examples.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "E09-1064", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Shachar, Mirkin | Ido, Dagan | Eyal, Shnarch", 
    "raw_text": "This includes sense ranks in WordNet, SemCor statistics (Miller et al, 1993), and similarity scores and rankings in Lin? s resources", 
    "clean_text": "This includes sense ranks in WordNet, SemCor statistics (Miller et al, 1993), and similarity scores and rankings in Lin's resources.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W09-2403", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Judita, Preiss | Jon, Dehdari | Josh, King | Dennis, Mehay", 
    "raw_text": "We propose a number of novel approaches to WSD, but also demonstrate the importance of ahighly accurate lemmatizer and part of speech tagger to the English all words task of S??????? -3.1 We present our enriched most frequent sense 1Unless specified otherwise, we use WordNet 1.7.1 (Milleret al, 1990) and the associated sense annotated SemCorcor pus (Miller et al, 1993) (translated to WordNet 1.7.1 by Rada Mihalcea)", 
    "clean_text": "Unless specified otherwise, we use WordNet 1.7.1 (Milleret al, 1990) and the associated sense annotated SemCor corpus (Miller et al, 1993) (translated to WordNet 1.7.1 by Rada Mihalcea).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "S12-1014", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sanja, Fidler | Wesley, May | Afsaneh, Fazly | Sven, Dickinson | Suzanne, Stevenson", 
    "raw_text": "ImCor dataset by associating images from the Corel database with text from the SemCor corpus (Miller et al, 1993)", 
    "clean_text": "ImCor dataset by associating images from the Corel database with text from the SemCor corpus (Miller et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W07-2061", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Radu, Ion | Dan, Tufi&scaron;", 
    "raw_text": "Coarse-grained English All-Words LexPar and SynWSD were trained on an 1 million words corpus comprising the George Orwell? s 1984 novel and the SemCor corpus (Miller et al, 1993) .Both texts have been POS-tagged (with MULTEXT East compliant POS tags) and lemmatized and the result was carefully checked by human judges to en sure a correct annotation", 
    "clean_text": "Coarse-grained English All-Words LexPar and SynWSD were trained on an 1 million words corpus comprising the George Orwell's 1984 novel and the SemCor corpus (Miller et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P06-1013", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Samuel, Brody | Roberto, Navigli | Mirella, Lapata", 
    "raw_text": "Then, we present a detailed comparison of their performance on SemCor (Miller et al, 1993) .Next, we introduce our system combination methods and report on our evaluation experiments", 
    "clean_text": "Then, we present a detailed comparison of their performance on SemCor (Miller et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P10-1135", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ashwin, Ittoo | Gosse, Bouma", 
    "raw_text": "In the super vised approaches in Girju et al (2003) and Girjuet al (2006), lexical patterns expressing part whole relations between WordNet concept pairs are manually extracted from 20,000 sentences of the L.A Times and SemCor corpora (Milleretal., 1993), and used to generate a training corpus, with manually-annotated positive and negative examples of part-whole relations", 
    "clean_text": "A Times and SemCor corpora (Milleretal., 1993), and used to generate a training corpus, with manually-annotated positive and negative examples of part-whole relations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "C04-1162", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Rada, Mihalcea | Paul, Tarau | Elizabeth, Figa", 
    "raw_text": "We are using a subset of the SemCor texts (Miller et al, 1993)? five randomly selected files covering different topics: news, sports, entertainment, law, and debates? as well as the data set provided for the English all words task during SENSEVAL-2", 
    "clean_text": "We are using a subset of the SemCor texts (Miller et al, 1993) - five randomly selected files covering different topics: news, sports, entertainment, law, and debates - as well as the data set provided for the English all words task during SENSEVAL-2.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W06-2503", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Diana, McCarthy", 
    "raw_text": "We contrast the performance of first sense heuristics i) from SemCor (Miller et al, 1993) and ii) derived automatically from the BNC following (McCarthy et al, 2004) and also iii) an upper-bound first sense heuristic extracted from the test data", 
    "clean_text": "We contrast the performance of first sense heuristics i) from SemCor (Miller et al, 1993) and ii) derived automatically from the BNC following (McCarthy et al, 2004) and also iii) an upper-bound first sense heuristic extracted from the test data.", 
    "keep_for_gold": 0
  }
]
