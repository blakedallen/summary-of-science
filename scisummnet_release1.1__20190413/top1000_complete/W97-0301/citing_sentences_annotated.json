[
  {
    "citance_No": 1, 
    "citing_paper_id": "W12-2035", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Joseph, Chang | Shih-ting, Huang | Mei-hua, Chen | Jian-Cheng, Wu | Yi-Chun, Chen | Jason S., Chang", 
    "raw_text": "In this section, we investigate the performance of two maximum entropy classifiers (Ratnaparkhi, 1997), one for determining whether a noun phrase has a determiner or not and the other for selecting the appropriate determiner if one is needed", 
    "clean_text": "In this section, we investigate the performance of two maximum entropy classifiers (Ratnaparkhi, 1997), one for determining whether a noun phrase has a determiner or not and the other for selecting the appropriate determiner if one is needed.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P06-2048", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mark, Hopkins | Jonas, Kuhn", 
    "raw_text": "There are two canonical parsers that fall into this category: the decision-tree parser of (Mager man, 1995), and the maximum-entropy parser of (Ratnaparkhi, 1997)", 
    "clean_text": "There are two canonical parsers that fall into this category: the decision-tree parser of (Magerman, 1995), and the maximum-entropy parser of (Ratnaparkhi, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W06-2002", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mark, Hopkins | Jonas, Kuhn", 
    "raw_text": "of our framework is the maximum-entropy parser of Ratnaparkhi (Ratnaparkhi, 1997)", 
    "clean_text": "The closest relative of our framework is the maximum-entropy parser of Ratnaparkhi (Ratnaparkhi, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W11-1007", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Bing, Xiang | Niyu, Ge | Abraham, Ittycheriah", 
    "raw_text": "The Chinese parse trees are produced by a maximum entropy based parser (Ratnaparkhi,1997)", 
    "clean_text": "The Chinese parse trees are produced by a maximum entropy based parser (Ratnaparkhi, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W05-1506", 
    "citing_paper_authority": 97, 
    "citing_paper_authors": "Liang, Huang | David, Chiang", 
    "raw_text": "We demonstrate this by comparing our k-best lists to those in (Ratnaparkhi,1997), (Collins, 2000) and the parallel work by Charniak and Johnson (2005) in several ways, including oracle re ranking and average number of found parses", 
    "clean_text": "We demonstrate this by comparing our k-best lists to those in (Ratnaparkhi,1997), (Collins, 2000) and the parallel work by Charniak and Johnson (2005) in several ways, including oracle reranking and average number of found parses.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W05-1506", 
    "citing_paper_authority": 97, 
    "citing_paper_authors": "Liang, Huang | David, Chiang", 
    "raw_text": "Ratnaparkhi (1997) introduced the idea of oracle re ranking: suppose there exists a perfect re ranking scheme that magically picks the best parse that has the highest F-score among the top k parses for each sentence", 
    "clean_text": "Ratnaparkhi (1997) introduced the idea of oracle re ranking: suppose there exists a perfect re ranking scheme that magically picks the best parse that has the highest F-score among the top k parses for each sentence.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W05-1506", 
    "citing_paper_authority": 97, 
    "citing_paper_authors": "Liang, Huang | David, Chiang", 
    "raw_text": "100) parses for section 23, compared to (Charniak and Johnson, 2005), (Collins, 2000) and (Ratnaparkhi, 1997)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W03-1025", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Xiaoqiang, Luo", 
    "raw_text": "A maximum entropy parser (Ratnaparkhi, 1997) parser is then built and tested", 
    "clean_text": "A maximum entropy parser (Ratnaparkhi, 1997) parser is then built and tested.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W03-1025", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Xiaoqiang, Luo", 
    "raw_text": "The maximum entropy parser (Ratnaparkhi, 1997 )isused in this study, for it offers the flexibility of integrating multiple sources of knowledge into a model", 
    "clean_text": "The maximum entropy parser (Ratnaparkhi, 1997) is used in this study, for it offers the flexibility of integrating multiple sources of knowledge into a model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W03-1025", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Xiaoqiang, Luo", 
    "raw_text": "The maximum entropy parser (Ratnaparkhi, 1997) parses a sentence in three phases: (1) it first tags the input sentence", 
    "clean_text": "The maximum entropy parser (Ratnaparkhi, 1997) parses a sentence in three phases: (1) it first tags the input sentence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P02-1025", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Peng, Xu | Ciprian, Chelba | Frederick, Jelinek", 
    "raw_text": "The SLM was trained on 20M words of WSJ text automatically parsed using the parser in (Ratnaparkhi, 1997), bi narized and enriched with headwords and NT/POStag information as explained in Section 2.2 and Section 3", 
    "clean_text": "The SLM was trained on 20M words of WSJ text automatically parsed using the parser in (Ratnaparkhi, 1997), binarized and enriched with headwords and NT/POS tag information as explained in Section 2.2 and Section 3.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W01-0521", 
    "citing_paper_authority": 84, 
    "citing_paper_authors": "Daniel, Gildea", 
    "raw_text": "The techniques of Charniak (1997), Collins (1997), and Ratnaparkhi (1997) achieved roughly comparable results using the same sets of training and test data", 
    "clean_text": "The techniques of Charniak (1997), Collins (1997), and Ratnaparkhi (1997) achieved roughly comparable results using the same sets of training and test data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W01-0521", 
    "citing_paper_authority": 84, 
    "citing_paper_authors": "Daniel, Gildea", 
    "raw_text": "The probability models of Charniak (1997), Magerman (1995) and Ratnaparkhi (1997 )dier in their details but are based on similar features", 
    "clean_text": "The probability models of Charniak (1997), Magerman (1995) and Ratnaparkhi (1997) dier in their details but are based on similar features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P07-1071", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ronan, Collobert | Jason, Weston", 
    "raw_text": "We focus our experimental study on the semantic role labeling problem (Palmer et al,2005): being able to give a semantic role to a syn1Even though some parsers effectively exhibit linear behavior in sentence length (Ratnaparkhi, 1997), fast statistical parsers such as (Henderson, 2004) still take around 1.5 seconds for sentences of length 35 in tests that we made", 
    "clean_text": "Even though some parsers effectively exhibit linear behavior in sentence length (Ratnaparkhi, 1997), fast statistical parsers such as (Henderson, 2004) still take around 1.5 seconds for sentences of length 35 in tests that we made.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P06-2009", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ming-Wei, Chang | Quang, Do | Dan, Roth", 
    "raw_text": "(Ratnaparkhi, 1997), in that the classifiers are trained on individual decisions rather than on the overall quality of the parser, and chained to yield the global structure", 
    "clean_text": "This is a true pipeline approach, as was done in other successful parsers, e.g. (Ratnaparkhi, 1997), in that the classifiers are trained on individual decisions rather than on the overall quality of the parser, and chained to yield the global structure.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P06-2089", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Kenji, Sagae | Alon, Lavie", 
    "raw_text": "Finally, our parser is in many ways similar to the parser of Ratnaparkhi (1997)", 
    "clean_text": "Finally, our parser is in many ways similar to the parser of Ratnaparkhi (1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P06-2089", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Kenji, Sagae | Alon, Lavie", 
    "raw_text": "In the probabilistic LR model, probabilities are assigned to tree 696 Precision Recall F-score Time (min) Best-First Classifier-Based (this paper) 88.1 87.8 87.9 17 Deterministic (MaxEnt) (this paper) 85.4 84.8 85.1 &lt; 1 Charniak& amp; Johnson (2005) 91.3 90.6 91.0 Unk Bod (2003) 90.8 90.7 90.7 145* Charniak (2000) 89.5 89.6 89.5 23 Collins (1999) 88.3 88.1 88.2 39 Ratnaparkhi (1997) 87.5 86.3 86.9 Unk Tsuruoka& amp; Tsujii (2005): deterministic 86.5 81.2 83.8 &lt; 1* Tsuruoka& amp; Tsujii (2005): search 86.8 85.0 85.9 2* Sagae& amp; Lavie (2005) 86.0 86.1 86.0 11* Table 1: Summary of results on labeled precision and recall of constituents, and time required to parse the test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "N03-1028", 
    "citing_paper_authority": 136, 
    "citing_paper_authors": "Fei, Sha | Fernando, Pereira", 
    "raw_text": "On the application side, (log) linear parsing models have the potential to supplant the currently dominant lexicalized PCFG models for parsing by allowing much richer feature sets and simpler smoothing, while avoiding the label bias problem that may have hindered earlier classifier-based parsers (Ratnaparkhi, 1997)", 
    "clean_text": "On the application side, (log) linear parsing models have the potential to supplant the currently dominant lexicalized PCFG models for parsing by allowing much richer feature sets and simpler smoothing, while avoiding the label bias problem that may have hindered earlier classifier-based parsers (Ratnaparkhi, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P10-2005", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Bing, Xiang | Yonggang, Deng | Bowen, Zhou", 
    "raw_text": "The English parse tree used for the syntactic reordering was produced by a maximum entropy based parser (Ratnaparkhi, 1997)", 
    "clean_text": "The English parse tree used for the syntactic reordering was produced by a maximum entropy based parser (Ratnaparkhi, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P02-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Antal, van den Bosch | Sabine, Buchholz", 
    "raw_text": "Chunks as a separate level have also been used in Collins (1996) and Ratnaparkhi (1997)", 
    "clean_text": "Chunks as a separate level have also been used in Collins (1996) and Ratnaparkhi (1997).", 
    "keep_for_gold": 0
  }
]
