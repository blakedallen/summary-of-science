A Linear Observed Time Statistical Parser Based On Maximum Entropy Models
This paper presents a statistical parser for natural language that obtains a parsing accuracy--roughly 87% precision and 86% recall--which surpasses the best previously published results on the Wall St. Journal domain.
The parser itself requires very little human intervention, since the information it uses to make parsing decisions is specified in a concise and simple manner, and is combined in a fully automatic way under the maximum entropy framework.
The observed running time of the parser on a test sentence is linear with respect to the sentence length.
Furthermore, the parser returns several scored parses for a sentence, and this paper shows that a scheme to pick the best parse from the 20 highest scoring parses could yield a dramatically higher accuracy of 93% precision and recall.
We introduce the idea of oracle re-ranking: suppose there exists a perfect re-ranking scheme that magically picks the best parse that has the highest F-score among the top k parses for each sentence.
We take a pipeline approach in that the classifiers are trained on individual decisions rather than on the overall quality of the parser, and chained to yield the global structure.
