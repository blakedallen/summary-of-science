[
  {
    "citance_No": 1, 
    "citing_paper_id": "P09-1081", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Asli, Celikyilmaz | Marcus, Thint | Zhiheng, Huang", 
    "raw_text": "Recent research indicates that using labeled and unlabeled data in semi-supervised learning (SSL) environment ,withan emphasis on graph-based methods, can improve the performance of information extraction from data for tasks such as question classification (Tri et al, 2006), web classification (Liu et al., 2006), relation extraction (Chen et al, 2006), passage-retrieval (Otterbacher et al, 2009), various natural language processing tasks such as part of-speech tagging, and named-entity recognition (Suzuki and Isozaki, 2008), word-sense disam 719biguation (Niu et al, 2005), etc. We consider situations where there are much more unlabeled data, XU, than labeled data, XL ,i.e. ,nLnU. We construct a textual entailment (TE) module by extracting features from each paired question and answer sentence and designing a classifier with a novel yet feasible graph based SSL method", 
    "clean_text": "Recent research indicates that using labeled and unlabeled data in semi-supervised learning (SSL) environment, with an emphasis on graph-based methods, can improve the performance of information extraction from data for tasks such as question classification (Tri et al, 2006), web classification (Liu et al., 2006), relation extraction (Chen et al, 2006), passage-retrieval (Otterbacher et al, 2009), various natural language processing tasks such as part of-speech tagging, and named-entity recognition (Suzuki and Isozaki, 2008), word-sense disambiguation (Niu et al, 2005), etc.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W09-1119", 
    "citing_paper_authority": 59, 
    "citing_paper_authors": "Lev, Ratinov | Dan, Roth", 
    "raw_text": "NER proves to be a knowledge intensive task, and it was reassuring to observe that System Resources Used F1+ LBJ-NER Wikipedia, Nonlocal Features, Word-class Model 90.80 (Suzuki and Isozaki, 2008) Semi-supervised on 1G word unlabeled data 89.92 (Ando and Zhang, 2005) Semi-supervised on 27M word unlabeled data 89.31 (Kazama and Torisawa, 2007a) Wikipedia 88.02 (Krishnan and Manning, 2006) Non-local Features 87.24 (Kazama and Torisawa, 2007b) Non-local Features 87.17+ (Finkel et al, 2005) Non-local Features 86.86 Table 7: Results for CoNLL03 data reported in the literature", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "N09-1059", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Ryohei, Sasano | Daisuke, Kawahara | Sadao, Kurohashi", 
    "raw_text": "Suzuki and Isozaki (2008) provided evidence that the use of more unlabeled data in semi supervised learning could improve the performance of NLP tasks, such as POS tagging, syntactic chunking, and named entities recognition. There are several methods to extract useful information from very large corpora", 
    "clean_text": "Suzuki and Isozaki (2008) provided evidence that the use of more unlabeled data in semi supervised learning could improve the performance of NLP tasks, such as POS tagging, syntactic chunking, and named entities recognition.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D09-1058", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "We describe an extension of semi supervised structured conditional models (SS-SCMs) to the dependency parsing problem, whose framework is originally proposed in (Suzuki and Isozaki, 2008) .Moreover, we introduce two extensions related to dependency parsing: The first extension is to combine SS-SCMs with an other semi-supervised approach, describe din (Koo et al, 2008)", 
    "clean_text": "We describe an extension of semi supervised structured conditional models (SS-SCMs) to the dependency parsing problem, whose framework is originally proposed in (Suzuki and Isozaki, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D09-1058", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "This paper introduces an alternative method for semi-supervised learning for dependency parsing. Our approach basically follows a framework pro posed in (Suzuki and Isozaki, 2008)", 
    "clean_text": "Our approach basically follows a framework proposed in (Suzuki and Isozaki, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D09-1058", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "Note that it is possible to iterate the method? steps 2 and 3 can be repeated multiple times (Suzuki and Isozaki, 2008)? but in our experiments we only performed these steps once", 
    "clean_text": "Note that it is possible to iterate the method steps 2 and 3 can be repeated multiple times (Suzuki and Isozaki, 2008) but in our experiments we only performed these steps once.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D09-1058", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "We follow a similar approach to that of (Suzuki and Isozaki, 2008) in partitioning f (x, y), where the k different feature vectors correspond to different feature types or feature templates", 
    "clean_text": "We follow a similar approach to that of (Suzuki and Isozaki, 2008) in partitioning f (x, y), where the k different feature vectors correspond to different feature types or feature templates.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D09-1058", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "This paper has described an extension of the semi-supervised learning approach of (Suzuki and Isozaki, 2008) to the dependency parsing problem. In addition, we have described extensions that in corporate the cluster-based features of Koo et al (2008), and that allow the use of second-order parsing models", 
    "clean_text": "This paper has described an extension of the semi-supervised learning approach of (Suzuki and Isozaki, 2008) to the dependency parsing problem.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P10-2038", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anders, S&oslash;gaard", 
    "raw_text": "Suzuki and Isozaki (2008 )introducea semi-supervised extension of conditional random fields that combines supervised and unsupervised probability models by so-called MDF parameter estimation, which reduces error on Wall Street Journal (WSJ) standard splits by about 7% relative to their supervised baseline", 
    "clean_text": "Suzuki and Isozaki (2008) introduce a semi-supervised extension of conditional random fields that combines supervised and unsupervised probability models by so-called MDF parameter estimation, which reduces error on Wall Street Journal (WSJ) standard splits by about 7% relative to their supervised baseline.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P10-2038", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anders, S&oslash;gaard", 
    "raw_text": "22-24 was 4.2%, which is comparable to related work in the literature ,e.g. Suzuki and Isozaki (2008) (7%) and Spoustova et al (2009) (4? 5%)", 
    "clean_text": "22-24 was 4.2%, which is comparable to related work in the literature, e.g. Suzuki and Isozaki (2008) (7%) and Spoustova et al (2009) (4-5%).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "In comparison, there are 79 templates in (Suzuki and Isozaki, 2008)", 
    "clean_text": "In comparison, there are 79 templates in (Suzuki and Isozaki, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "This approach is taken by (Miller et. al. 2004), (Wong and Ng 2007), (Suzuki and Isozaki 2008), and (Koo et .al., 2008), as well as this paper", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "Wong and Ng (2007) and Suzuki and Isozaki (2008) are similar in that they run a baseline discriminative classifier on unlabeled data to generate pseudo examples, which are then used to train a different type of classifier for the same problem", 
    "clean_text": "Wong and Ng (2007) and Suzuki and Isozaki (2008) are similar in that they run a baseline discriminative classifier on unlabeled data to generate pseudo examples, which are then used to train a different type of classifier for the same problem.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "Suzuki and Isozaki (2008), on the other hand, used the automatically labeled corpus to train HMMs", 
    "clean_text": "Suzuki and Isozaki (2008), on the other hand, used the automatically labeled corpus to train HMMs.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "Although the method in (Suzuki and Isozaki 2008) is quite general, it is hard to see how it can be applied to the query classification problem", 
    "clean_text": "Although the method in (Suzuki and Isozaki 2008) is quite general, it is hard to see how it can be applied to the query classification problem.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C10-1100", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Emily, Pitler | Shane, Bergsma | Dekang, Lin | Kenneth Ward, Church", 
    "raw_text": "unlabeled data can cause an equally predictable improvement in classification performance, with out the cost of labeling data. Suzuki and Isozaki (2008) also found a log linear relationship between unlabeled data (up to a billion words) and performance on three NLP tasks", 
    "clean_text": "Suzuki and Isozaki (2008) also found a log linear relationship between unlabeled data (up to a billion words) and performance on three NLP tasks.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D09-1134", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Xiao, Li", 
    "raw_text": "Another approach (Suzuki and Isozaki, 2008) embeds a joint probability model (HMM in their 1We slightly modify the notation here to be consistent with the rest of the paper", 
    "clean_text": "Another approach (Suzuki and Isozaki, 2008) embeds a joint probability model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D10-1019", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Xian, Qian | Qi, Zhang | Yaqian, Zhou | Xuanjing, Huang | Lide, Wu", 
    "raw_text": "We compare our hybrid CRFs with pipeline and candidate re ranking methods (Shi and Wang, 2007) Table 4: Comparison with other systems on shallow parsing task Method F1 Additional Re sources Cross-Product CRFs 93.88 Hybrid CRFs 94.31 SVM combination 93.91 (Kudo and Mat sumo to, 2001) Voted Perceptrons 93.74 none (Carreras and Marquez, 2003) ETL (Milidiu et al, 2008) 92.79 (Wu et al, 2006) 94.21 Extended features such as token features ,affixesHySOL 94.36 17M words unlabeled (Suzuki et al, 2007 )dataASO-semi 94.39 15M words unlabeled (Ando and Zhang, 2005) data (Zhang et al, 2002) 94.17 full parser output (Suzuki and Isozaki, 2008) 95.15 1G words unlabeled data using the same evaluation metrics as shallow parsing", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P12-2076", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kenji, Imamura | Kuniko, Saito | Kugatsu, Sadamitsu | Hitoshi, Nishikawa", 
    "raw_text": "Incorporating binary and real features yields arough approximation of generative models in semi supervised CRFs (Suzuki and Isozaki, 2008)", 
    "clean_text": "Incorporating binary and real features yields a rough approximation of generative models in semi supervised CRFs (Suzuki and Isozaki, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P11-1037", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Xiaohua, Liu | Shaodian, Zhang | Furu, Wei | Ming, Zhou", 
    "raw_text": "Suzuki and Isozaki (2008) is one such example", 
    "clean_text": "Suzuki and Isozaki (2008) is one such example.", 
    "keep_for_gold": 0
  }
]
