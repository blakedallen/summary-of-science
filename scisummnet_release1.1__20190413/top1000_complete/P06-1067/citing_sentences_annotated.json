[
  {
    "citance_No": 1, 
    "citing_paper_id": "N07-1008", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Abraham, Ittycheriah | Salim, Roukos", 
    "raw_text": "various translation models such as a block inventory with the following three varieties: 1) the unigram block count, 2) a model 1 score p (si|ti) on the phrase-pair, and 3) a model 1 score for the other direction p (ti|si),? a target word count penalty feature |T|,? a phrase count feature,? a distortion model (Al-Onaizan and Papineni, 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P12-1050", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Arianna, Bisazza | Marcello, Federico", 
    "raw_text": "Lexicalized distortion models predict the jump from the last translated word to the next one, with a class for each possible jump length (Al-Onaizan and Papineni, 2006), or bin of lengths (Green et al, 2010)", 
    "clean_text": "Lexicalized distortion models predict the jump from the last translated word to the next one, with a class for each possible jump length (Al-Onaizan and Papineni, 2006), or bin of lengths (Green et al, 2010).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D09-1105", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Roy W., Tromble | Jason M., Eisner", 
    "raw_text": "The decoders also rely on search error, in the form of limited reordering windows, for both efficiency and translation qual ity. Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni (2006) showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score (Papineni et al., 2002) of at best 69%? and that only when restricted to keep most words very close to their source positions", 
    "clean_text": "Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni (2006) showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score (Papineni et al., 2002) of at best 69% and that only when restricted to keep most words very close to their source positions.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D09-1105", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Roy W., Tromble | Jason M., Eisner", 
    "raw_text": "This is similar to the oracle ordering used by Al-Onaizan and Papineni (2006), but differs in the handling of unaligned words", 
    "clean_text": "This is similar to the oracle ordering used by Al-Onaizan and Papineni (2006), but differs in the handling of unaligned words.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C10-1050", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Katsuhiko, Hayashi | Hajime, Tsukada | Katsuhito, Sudoh | Kevin, Duh | Seiichi, Yamamoto", 
    "raw_text": "means Al-Onaizan and Papineni (2006)? s algorithm.chine translation model", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W08-0405", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christoph, Tillmann", 
    "raw_text": "Since we are using the distortion model in (Al-Onaizan and Papineni, 2006) the entire last source phrase interval needs to be stored", 
    "clean_text": "Since we are using the distortion model in (Al-Onaizan and Papineni, 2006) the entire last source phrase interval needs to be stored.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C08-1027", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jakob, Elming", 
    "raw_text": "As mentioned by (Al-Onaizan and Papineni,2006), it can be problematic that these deterministic choices are beyond the scope of optimization and can not be undone by the decoder", 
    "clean_text": "As mentioned by (Al-Onaizan and Papineni, 2006), it can be problematic that these deterministic choices are beyond the scope of optimization and cannot be undone by the decoder.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D08-1041", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Fei, Huang | Ahmad, Emami | Imed, Zitouni", 
    "raw_text": "Our baseline MT decoder is a phrase-based decoder as described in (Al-Onaizan and Papineni 2006)", 
    "clean_text": "Our baseline MT decoder is a phrase-based decoder as described in (Al-Onaizan and Papineni 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P07-1091", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "Chi-Ho, Li | Minghui, Li | Dongdong, Zhang | Mu, Li | Ming, Zhou | Yi, Guan", 
    "raw_text": "As pointed out in (Al-Onaizan and Papineni, 2006), these strategies make hard decisions in reordering which can not be undone during decoding", 
    "clean_text": "As pointed out in (Al-Onaizan and Papineni, 2006), these strategies make hard decisions in reordering which cannot be undone during decoding.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W08-0406", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jakob, Elming", 
    "raw_text": "As mentioned by (Al-Onaizan and Papineni,2006), it can be problematic that these deterministic choices are beyond the scope of optimization and can not be undone by the decoder", 
    "clean_text": "As mentioned by (Al-Onaizan and Papineni,2006), it can be problematic that these deterministic choices are beyond the scope of optimization and cannot be undone by the decoder.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2095", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sameer, Maskey | Steven, Rennie | Bowen, Zhou", 
    "raw_text": "We th entrained the lexicalized reordering model that produced distortion costs based on the number of words that are skipped on the target side, in a manner similar to (Al-Onaizan and Papineni, 2006)", 
    "clean_text": "We then trained the lexicalized reordering model that produced distortion costs based on the number of words that are skipped on the target side, in a manner similar to (Al-Onaizan and Papineni, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P07-1090", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Hendra, Setiawan | Min-Yen, Kan | Haizhou, Li", 
    "raw_text": "Other further generalizations of orientation include the global prediction model (Nagata et al, 2006) and distortion model (Al-Onaizan and Papineni, 2006)", 
    "clean_text": "Other further generalizations of orientation include the global prediction model (Nagata et al, 2006) and distortion model (Al-Onaizan and Papineni, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P09-1105", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Fei, Huang", 
    "raw_text": "The MT system is a phrase based SMT system as described in (Al-Onaizanand Papineni, 2006)", 
    "clean_text": "The MT system is a phrase based SMT system as described in (Al-Onaizanand Papineni, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D08-1063", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Imed, Zitouni | Radu, Florian", 
    "raw_text": "This assumption is realistic: while truly parallel data (humanly created) might be inshort supply or harder to acquire, adapting statistical machine translation (SMT) systems from one language-pair to another is not as challenging as it used to be (Al-Onaizan and Papineni, 2006)", 
    "clean_text": "This assumption is realistic: while truly parallel data (humanly created) might be in short supply or harder to acquire, adapting statistical machine translation (SMT) systems from one language-pair to another is not as challenging as it used to be (Al-Onaizan and Papineni, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D08-1063", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Imed, Zitouni | Radu, Florian", 
    "raw_text": "The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006)", 
    "clean_text": "The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "N10-1129", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Spence, Green | Michel, Galley | Christopher D., Manning", 
    "raw_text": "To remedy these deficiencies, Al-Onaizan and Papineni (2006) proposed a lexicalized, generative distortion model", 
    "clean_text": "To remedy these deficiencies, Al-Onaizan and Papineni (2006) proposed a lexicalized, generative distortion model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "C10-1126", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Karthik, Visweswariah | Jiri, Navratil | Jeffrey S., Sorensen | Vijil, Chenthamarakshan | Nanda, Kambhatla", 
    "raw_text": "Other models (Tillman, 2004), (Al-Onaizan and Papineni, 2006) generalize this to include lexical dependencies on the source", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C10-1126", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Karthik, Visweswariah | Jiri, Navratil | Jeffrey S., Sorensen | Vijil, Chenthamarakshan | Nanda, Kambhatla", 
    "raw_text": "Thelexicalized distortion model was used as described in (Al-Onaizan and Papineni, 2006) with a window width of up to 5 and a maximum number of skipped (not covered) words during decoding of 2", 
    "clean_text": "The lexicalized distortion model was used as described in (Al-Onaizan and Papineni, 2006) with a window width of up to 5 and a maximum number of skipped (not covered) words during decoding of 2.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D07-1029", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Fei, Huang | Kishore, Papineni", 
    "raw_text": "These include phrase-based statistical MT systems (Al-Onaizan and Papineni, 2006) (Block) and (Hewavitharana et al., 2005) (CMU SMT), a direct translation model (DTM) system (Ittycheriah and Roukos, 2007) and ahierarchical phrased-based MT system (Hiero) (Chiang, 2005)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D08-1089", 
    "citing_paper_authority": 81, 
    "citing_paper_authors": "Michel, Galley | Christopher D., Manning", 
    "raw_text": "In future work, we plan to extend the parameterization of our models to not only predict phrase orientation, but also the length of each displacement as in (Al-Onaizan and Papineni, 2006)", 
    "clean_text": "In future work, we plan to extend the parameterization of our models to not only predict phrase orientation, but also the length of each displacement as in (Al-Onaizan and Papineni, 2006).", 
    "keep_for_gold": 0
  }
]
