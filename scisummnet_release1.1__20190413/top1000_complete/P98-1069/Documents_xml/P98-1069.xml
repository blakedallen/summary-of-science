<PAPER>
  <S sid="0">An IR Approach for Translating New Words from Nonparallel Comparable Texts</S>
  <ABSTRACT/>
  <SECTION title="1 Introduction" number="1">
    <S sid="1" ssid="1">In recent years, there is a phenomenal growth in the amount of online text material available from the greatest information repository known as the World Wide Web.</S>
    <S sid="2" ssid="2">Various traditional information retrieval(IR) techniques combined with natural language processing(NLP) techniques have been re-targeted to enable efficient access of the WWW&#8212;search engines, indexing, relevance feedback, query term and keyword weighting, document analysis, document classification, etc.</S>
    <S sid="3" ssid="3">Most of these techniques aim at efficient online search for information already on the Web.</S>
    <S sid="4" ssid="4">Meanwhile, the corpus linguistic community regards the WWW as a vast potential of corpus resources.</S>
    <S sid="5" ssid="5">It is now possible to download a large amount of texts with automatic tools when one needs to compute, for example, a list of synonyms; or download domain-specific monolingual texts by specifying a keyword to the search engine, and then use this text to extract domain-specific terms.</S>
    <S sid="6" ssid="6">It remains to be seen how we can also make use of the multilingual texts as NLP resources.</S>
    <S sid="7" ssid="7">In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation(Brown et al., 1993; Brown et al., 1991; Gale and Church, 1993; Church, 1993; Simard et al., 1992), large amount of human effort and time has been invested in collecting parallel corpora of translated texts.</S>
    <S sid="8" ssid="8">Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts.</S>
    <S sid="9" ssid="9">This type of texts are known as nonparallel corpora.</S>
    <S sid="10" ssid="10">Such nonparallel, monolingual texts should be much more prevalent than parallel texts.</S>
    <S sid="11" ssid="11">However, previous attempts at using nonparallel corpora for terminology translation were constrained by the inadequate availability of same-domain, comparable texts in electronic form.</S>
    <S sid="12" ssid="12">The type of nonparallel texts obtained from the LDC or university libraries were often restricted, and were usually out-of-date as soon as they became available.</S>
    <S sid="13" ssid="13">For new word translation, the timeliness of corpus resources is a prerequisite, so is the continuous and automatic availability of nonparallel, comparable texts in electronic form.</S>
    <S sid="14" ssid="14">Data collection effort should not inhibit the actual translation effort.</S>
    <S sid="15" ssid="15">Fortunately, nowadays the World Wide Web provides us with a daily increase of fresh, up-to-date multilingual material, together with the archived versions, all easily downloadable by software tools running in the background.</S>
    <S sid="16" ssid="16">It is possible to specify the URL of the online site of a newspaper, and the start and end dates, and automatically download all the daily newspaper materials between those dates.</S>
    <S sid="17" ssid="17">In this paper, we describe a new method which combines IR and NLP techniques to extract new word translation from automatically downloaded English-Chinese nonparallel newspaper texts.</S>
  </SECTION>
  <SECTION title="2 Encountering new words" number="2">
    <S sid="18" ssid="1">To improve the performance of a machine translation system, it is often necessary to update its bilingual lexicon, either by human lexicographers or statistical methods using large corpora.</S>
    <S sid="19" ssid="2">Up until recently, statistical bilingual lexicon compilation relies largely on parallel corpora.</S>
    <S sid="20" ssid="3">This is an undesirable constraint at times.</S>
    <S sid="21" ssid="4">In using a broad-coverage English-Chinese MT system to translate some text recently, we discovered that it is unable to translate Mel! liougan which occurs very frequently in the text.</S>
    <S sid="22" ssid="5">Other words which the system cannot find in its 20,000-entry lexicon include proper names such as the Taiwanese president Lee Teng-Hui, and the Hong Kong Chief Executive Tung CheeHwa.</S>
    <S sid="23" ssid="6">To our disappointment, we cannot locate any parallel texts which include such words since they only start to appear frequently in recent months.</S>
    <S sid="24" ssid="7">A quick search on the Web turned up archives of multiple local newspapers in English and Chinese.</S>
    <S sid="25" ssid="8">Our challenge is to find the translation of 1.,133 I liougan and other words from this online nonparallel, comparable corpus of newspaper materials.</S>
    <S sid="26" ssid="9">We choose to use issues of the English newspaper Hong Kong Standard and the Chinese newspaper Mingpao, from Dec.12,97 to Dec.31,97, as our corpus.</S>
    <S sid="27" ssid="10">The English text contains about 3 Mb of text whereas the Chinese text contains 8.8 Mb of 2 byte character texts.</S>
    <S sid="28" ssid="11">So both texts are comparable in size.</S>
    <S sid="29" ssid="12">Since they are both local mainstream newspapers, it is reasonable to assume that their contents are comparable as well.</S>
    <S sid="30" ssid="13">Unlike in parallel texts, the position of a word in a text does not give us information about its translation in the other language.</S>
    <S sid="31" ssid="14">(Rapp, 1995; Fung and McKeown, 1997) suggest that a content word is closely associated with some words in its context.</S>
    <S sid="32" ssid="15">As a tutorial example, we postulate that the words which appear in the context ofMet, Iliougan should be similar to the words appearing in the context of its English translation, flu.</S>
    <S sid="33" ssid="16">We can form a vector space model of a word in terms of its context word indices, similar to the vector space model of a text in terms of its constituent word indices (Salton and Buckley, 1988; Salton and Yang, 1973; Croft, 1984; Turtle and Croft, 1992; Bookstein, 1983; Korfhage, 1995; Jones, 1979).</S>
    <S sid="34" ssid="17">The value of the i-th dimension of a word vector W is f if the i-th word in the lexicon appears f times in the same sentences as W. Left columns in Table 1 and Table 2 show the list of content words which appear most frequently in the context of flu and Africa respectively.</S>
    <S sid="35" ssid="18">The right column shows those which occur most frequently in the context of bv,g.</S>
    <S sid="36" ssid="19">We can see that the context of At is more similar to that of flu than to that of Africa.</S>
  </SECTION>
  <SECTION title="4 Bilingual lexicon as seed words" number="3">
    <S sid="37" ssid="1">So the first clue to the similarity between a word and its translation number of common words in their contexts.</S>
    <S sid="38" ssid="2">In a bilingual corpus, the &amp;quot;common word&amp;quot; is actually a bilingual word pair.</S>
    <S sid="39" ssid="3">We use the lexicon of the MT system to &amp;quot;bridge&amp;quot; all bilingual word pairs in the corpora.</S>
    <S sid="40" ssid="4">These word pairs are used as seed words.</S>
    <S sid="41" ssid="5">We found that the contexts of flu and 'MI Iliougan share 233 &amp;quot;common&amp;quot; context words, whereas the contexts of Africa and W&#8222;Iff Iliougan share only 121 common words, even though the context of flu has 491 unique words and the context of Africa has 328 words.</S>
    <S sid="42" ssid="6">In the vector space model, W[flu] and W[liougan] has 233 overlapping dimensions, whereas there are 121 overlapping dimensions between W[flu] and W [Africa].</S>
    <S sid="43" ssid="7">The flu example illustrates that the actual ranking of the context word frequencies provides a second clue to the similarity between a bilingual word pair.</S>
    <S sid="44" ssid="8">For example, virus ranks very high for both flu and ME Iliougan and is a strong &amp;quot;bridge&amp;quot; between this bilingual word pair.</S>
    <S sid="45" ssid="9">This leads us to use the term frequency(TF) measure.</S>
    <S sid="46" ssid="10">The TF of a context word is defined as the frequency of the word in the context of W. (e.g.</S>
    <S sid="47" ssid="11">TF of virus in flu is 26, in MM. is 147).</S>
    <S sid="48" ssid="12">However, the TF of a word is not independent of its general usage frequency.</S>
    <S sid="49" ssid="13">In an extreme case, the function word the appears most frequently in English texts and would have the highest TF in the context of any W. In our HKStandard/Mingpao corpus, Hong Kong is the most frequent content word which appears everywhere.</S>
    <S sid="50" ssid="14">So in the flu example, we would like to reduce the significance of Hong Kong's TF while keeping that of virus.</S>
    <S sid="51" ssid="15">A common way to account for this difference is by using the inverse document frequency(IDF).</S>
    <S sid="52" ssid="16">Among the variants of IDF, we choose the following representation from (Jones, 1979):</S>
  </SECTION>
  <SECTION title="6 Ranking translation candidates" number="4">
    <S sid="53" ssid="1">Next, a ranking algorithm is needed to match the unknown word vectors to their counterparts in the other language.</S>
    <S sid="54" ssid="2">A ranking algorithm selects the best target language candidate for a source language word according to direct comparison of some similarity measures (Frakes and Baeza-Yates, 1992).</S>
    <S sid="55" ssid="3">We modify the similarity measure proposed by (Salton and Buckley, 1988) into the following SO: where maxn = ni the maximum frequency of any word in the corpus the total number of occurrences of word i in the corpus SO(We, We) = where wic = wie = (wieX wie) VELiwic2 x ELiwie2 TFic TFie The IDF of virus is 1.81 and that of Hong Kong is 1.23 in the English text.</S>
    <S sid="56" ssid="4">The IDF of WS is 1.92 and that of Hong Kong is 0.83 in Chinese.</S>
    <S sid="57" ssid="5">So in both cases, virus is a stronger &amp;quot;bridge&amp;quot; for biglliougan than Hong Kong.</S>
    <S sid="58" ssid="6">Hence, for every context seed word i, we assign a word weighting factor (Salton and Buckley, 1988) w = TFiw x IDFi where TFiw is the TF of word i in the context of word W. The updated vector space model of word W has wi in its i-th dimension.</S>
    <S sid="59" ssid="7">The ranking of the 20 words in the contexts of W,,,f3 Iliougan is rearranged by this weighting factor as shown in Table3.</S>
    <S sid="60" ssid="8">Variants of similarity measures such as the above have been used extensively in the IR community (Frakes and Baeza-Yates, 1992).</S>
    <S sid="61" ssid="9">They are mostly based on the Cosine Measure of two vectors.</S>
    <S sid="62" ssid="10">For different tasks, the weighting factor might vary.</S>
    <S sid="63" ssid="11">For example, if we add the IDF into the weighting factor, we get the following measure Si: where wic = TFic x IDF, wie = TFie x IDFi In addition, the Dice and Jaccard coefficients are also suitable similarity measures for document comparison (Frakes and Baeza-Yates, 1992).</S>
    <S sid="64" ssid="12">We also implement the Dice coefficient into similarity measure S2: where wic = TFie x IDFi Si is often used in comparing a short query with a document text, whereas S2 is used in comparing two document texts.</S>
    <S sid="65" ssid="13">Reasoning that our objective falls somewhere in between&#8212;we are comparing segments of a document, we also multiply the above two measures into a third similarity measure S3.</S>
  </SECTION>
  <SECTION title="7 Confidence on seed word pairs" number="5">
    <S sid="66" ssid="1">In using bilingual seed words such asN,Et /virus as &amp;quot;bridges&amp;quot; for terminology translation, the quality of the bilingual seed lexicon naturally affects the system output.</S>
    <S sid="67" ssid="2">In the case of European language pairs such as French-English, we can envision using words sharing common cognates as these &amp;quot;bridges&amp;quot;.</S>
    <S sid="68" ssid="3">Most importantly, we can assume that the word boundaries are similar in French and English.</S>
    <S sid="69" ssid="4">However, the situation is messier with English and Chinese.</S>
    <S sid="70" ssid="5">First, segmentation of the Chinese text into words already introduces some ambiguity of the seed word identities.</S>
    <S sid="71" ssid="6">Secondly, English-Chinese translations are complicated by the fact that the two languages share very little stemming properties, or part-of-speech set, or word order.</S>
    <S sid="72" ssid="7">This property causes every English word to have many Chinese translations and vice versa.</S>
    <S sid="73" ssid="8">In a source-target language translation scenario, the translated text can be &amp;quot;rearranged&amp;quot; and cleaned up by a monolingual language model in the target language.</S>
    <S sid="74" ssid="9">However, the lexicon is not very reliable in establishing &amp;quot;bridges&amp;quot; between nonparallel English-Chinese texts.</S>
    <S sid="75" ssid="10">To compensate for this ambiguity in the seed lexicon, we introduce a confidence weighting to each bilingual word pair used as seed words.</S>
    <S sid="76" ssid="11">If a word ie is the k&#8212;th candidate for word ic, then wite wite /ki.</S>
    <S sid="77" ssid="12">The similarity scores then become S4 and S5 and S6 = S4 x S5: We also experiment with other combinations of the similarity scores such as S7 = SO x S5.</S>
    <S sid="78" ssid="13">All similarity measures S3 &#8212; S7 are used in the experiment for finding a translation for ME &#8226;</S>
  </SECTION>
  <SECTION title="8 Results" number="6">
    <S sid="79" ssid="1">In order to apply the above algorithm to find the translation for blgt, I liougan from the HKStandard/Mingpao corpus, we first use a script to select the 118 English content words which are not in the lexicon as possible candidates.</S>
    <S sid="80" ssid="2">Using similarity measures S3&#8212; S7, the highest ranking candidates of MS are shown in Table 6.</S>
    <S sid="81" ssid="3">S6 and S7 appear to be the best similarity measures.</S>
    <S sid="82" ssid="4">We then test the algorithm with S7 on more Chinese words which are not found in the lexicon but which occur frequently enough in the Mingpao texts.</S>
    <S sid="83" ssid="5">A statistical new word extraction tool can be used to find these words.</S>
    <S sid="84" ssid="6">The unknown Chinese words and their English counterparts, as well as the occurrence frequencies of these words in HKStandard/Mingpao are shown in Table 4.</S>
    <S sid="85" ssid="7">Frequency numbers with a * indicates that this word does not occur frequent enough to be found.</S>
    <S sid="86" ssid="8">Chinese words with a * indicates that it is a word with segmentation and translation ambiguities.</S>
    <S sid="87" ssid="9">For example, 44: (Lam) could be a family name, or part of another word meaning forest.</S>
    <S sid="88" ssid="10">When it is used as a family name, it could be transliterated into Lam in Cantonese or Lin in Mandarin.</S>
    <S sid="89" ssid="11">Disregarding all entries with a * in the above table, we apply the algorithm to the rest of the Chinese unknown words and the 118 English unknown words from HKStandard.</S>
    <S sid="90" ssid="12">The output is ranked by the similarity scores.</S>
    <S sid="91" ssid="13">The highest ranking translated pairs are shown in Table 5.</S>
    <S sid="92" ssid="14">The only Chinese unknown words which are not correctly translated in the above list are ik6 fl/ Lunar and MR / Yeltsin 1 .</S>
    <S sid="93" ssid="15">Tung/CheeHwa is a pair of collocates which is actually the full name of the Chief Executive.</S>
    <S sid="94" ssid="16">Poultry in Chinese is closely related to flu because the Chinese name for bird flu is poultry flu.</S>
    <S sid="95" ssid="17">In fact, almost all unambiguous Chinese new words find their translations in the first 100 of the ranked list.</S>
    <S sid="96" ssid="18">Six of the Chinese words have correct translation as their first candidate.</S>
  </SECTION>
  <SECTION title="9 Related work" number="7">
    <S sid="97" ssid="1">Using vector space model and similarity measures for ranking is a common approach in IR for query/text and text/text comparisons (Salton and Buckley, 1988; Salton and Yang, 1973; Croft, 1984; Turtle and Croft, 1992; Bookstein, 1983; Korfhage, 1995; Jones, 1979).</S>
    <S sid="98" ssid="2">This approach has also been used by (Dagan and Itai, 1994; Gale et al., 1992; Shfitze, 1992; Gale et al., 1993; Yarowsky, 1995; Gale and Church, 1994) for sense disambiguation between multiple usages of the same word.</S>
    <S sid="99" ssid="3">Some of the early statistical terminology translation methods are (Brown et al., 1993; Wu and Xia, 1994; Dagan and Church, 1994; Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996; Kay and Roscheisen, 1993; Fung and Church, 1994; Fung, 1995b).</S>
    <S sid="100" ssid="4">These algorithms all require parallel, translated texts as input.</S>
    <S sid="101" ssid="5">Attempts at exploring nonparallel corpora for terminology translation are very few (Rapp, 1995; Fung, 1995a; Fung and McKeown, 1997).</S>
    <S sid="102" ssid="6">Among these, (Rapp, 1995) proposes that the association between a word and its close collocate is preserved in any language. and (Fung and McKeown, 1997) suggests that the associations between a word and many seed words are also preserved in another language.</S>
    <S sid="103" ssid="7">In this paper, we have demonstrated that the associations between a word and its context seed words are well-preserved in nonparallel, comparable texts of different languages.</S>
  </SECTION>
  <SECTION title="10 Discussions" number="8">
    <S sid="104" ssid="1">Our algorithm is the first to have generated a collocation bilingual lexicon, albeit small, from a nonparallel, comparable corpus.</S>
    <S sid="105" ssid="2">We have shown that the algorithm has good precision, but the recall is low due to the difficulty in extracting unambiguous Chinese and English words.</S>
    <S sid="106" ssid="3">Better results can be obtained when the following changes are made: We will test the precision and recall of the algorithm on a larger set of unknown words.</S>
  </SECTION>
  <SECTION title="11 Conclusions" number="9">
    <S sid="107" ssid="1">We have devised an algorithm using context seed word TF/IDF for extracting bilingual lexicon from nonparallel, comparable corpus in English-Chinese.</S>
    <S sid="108" ssid="2">This algorithm takes into account the reliability of bilingual seed words and is language independent.</S>
    <S sid="109" ssid="3">This algorithm can be applied to other language pairs such as English-French or English-German.</S>
    <S sid="110" ssid="4">In these cases, since the languages are more similar linguistically and the seed word lexicon is more reliable, the algorithm should yield better results.</S>
    <S sid="111" ssid="5">This algorithm can also be applied in an iterative fashion where high-ranking bilingual word pairs can be added to the seed word list, which in turn can yield more new bilingual word pairs.</S>
  </SECTION>
</PAPER>
