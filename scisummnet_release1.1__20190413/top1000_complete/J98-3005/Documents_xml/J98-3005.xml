<PAPER>
  <S sid="0">Generating Natural Language Summaries From Multiple On-Line Sources</S>
  <ABSTRACT>
    <S sid="1" ssid="1">We present a methodology for summarization of news about current events in the form of briefings that include appropriate background (historical) information.</S>
    <S sid="2" ssid="2">The system that we developed, SUMMONS, uses the output of systems developed for the DARPA Message Understanding Conferences to generate summaries of multiple documents on the same or related events, presenting similarities and differences, contradictions, and generalizations among sources of information.</S>
    <S sid="3" ssid="3">We describe the various components of the system, showing how information from multiple articles is combined, organized into a paragraph, and finally, realized as English sentences.</S>
    <S sid="4" ssid="4">A feature of our work is the extraction of descriptions of entities such as people and places for reuse to enhance a briefing.</S>
  </ABSTRACT>
  <SECTION title="" number="1">
    <S sid="5" ssid="1">We present a methodology for summarization of news about current events in the form of briefings that include appropriate background (historical) information.</S>
    <S sid="6" ssid="2">The system that we developed, SUMMONS, uses the output of systems developed for the DARPA Message Understanding Conferences to generate summaries of multiple documents on the same or related events, presenting similarities and differences, contradictions, and generalizations among sources of information.</S>
    <S sid="7" ssid="3">We describe the various components of the system, showing how information from multiple articles is combined, organized into a paragraph, and finally, realized as English sentences.</S>
    <S sid="8" ssid="4">A feature of our work is the extraction of descriptions of entities such as people and places for reuse to enhance a briefing.</S>
  </SECTION>
  <SECTION title="1." number="2">
    <S sid="9" ssid="1">One of the major problems with the Internet is the abundance of information and the resulting difficulty for a typical computer user to read all existing documents on a specific topic.</S>
    <S sid="10" ssid="2">Even within the domain of current news, the user's task is infeasible.</S>
    <S sid="11" ssid="3">There exist now more than 100 sources of live newswire on the Internet, mostly accessible through the World-Wide Web (Berners-Lee 1992).</S>
    <S sid="12" ssid="4">Some of the most popular sites include news agencies and television stations like Reuters News (Reuters 1996), CNN's Web (CNN 1996), and ClariNet's e.News on-line newspaper (ClariNet 1996), as well as on-line versions of print media such as the New York Times on the Web edition (NYT 1996).</S>
    <S sid="13" ssid="5">For the typical user, it is nearly impossible to go through megabytes of news every day to select articles he wishes to read.</S>
    <S sid="14" ssid="6">Even when the user can actually select all news relevant to the topic of interest, he will still be faced with the problem of selecting a small subset that he can actually read in a limited time from the immense corpus of news available.</S>
    <S sid="15" ssid="7">Hence, there is a need for search and selection services, as well as for summarization facilities.</S>
    <S sid="16" ssid="8">, There currently exist more than 40 search and selection services on the WorldWide Web, such as DEC's Altavista (Altavista 1996), Lycos (Lycos 1996), and DejaNews (DejaNews 1997), all of which allow keyword searches for recent news.</S>
    <S sid="17" ssid="9">However, only recently have there been practical results in the area of summarization.</S>
    <S sid="18" ssid="10">Summaries can be used to determine if any of the retrieved articles are relevant (thereby allowing the user to avoid reading those that are not) or can be read in place of the articles to learn about information of interest to the user.</S>
    <S sid="19" ssid="11">Existing summarization systems (e.g., Preston and Williams 1994; Cuts 1994; NetSumm 1996; Kupiec, Pedersen, and Chen 1995; Rau, Brandow, and Mitze, 1994) typically use statistical techniques to extract relevant sentences from a news article.</S>
    <S sid="20" ssid="12">This domain-independent approach produces a summary of a single article at a time, which can indicate to the user what the article is about.</S>
    <S sid="21" ssid="13">In contrast, our work focuses on generation of a summary that briefs the user on information in which he has indicated interest.</S>
    <S sid="22" ssid="14">Such briefings pull together information of interest from multiple sources, aggregating information to provide generalizations, similarities, and differences across articles, and changes in perspective across time.</S>
    <S sid="23" ssid="15">Briefings do not necessarily fully summarize the articles retrieved, but they update the user on information he has specified is of interest.</S>
    <S sid="24" ssid="16">We present a system, called SUMMONS' (McKeown and Radev 1995; Radev 1996; Radev and McKeown 1997), shown in Figure 1, which introduces novel techniques in the following areas: As can be expected from a knowledge-based summarization system, SUMMONS works in a restricted domain.</S>
    <S sid="25" ssid="17">We have chosen the domain of news on terrorism for several reasons.</S>
    <S sid="26" ssid="18">First, there is already a large body of related research projects in information extraction, knowledge representation, and text planning in the domain of terrorism.</S>
    <S sid="27" ssid="19">For example, earlier systems developed under the DARPA Message Understanding Conference (MUC) were in the terrorist domain, and thus, we can build on these systems without having to start from scratch.</S>
    <S sid="28" ssid="20">The domain is important to a variety of users, including casual news readers, journalists, and security analysts.</S>
    <S sid="29" ssid="21">Finally, SUMMONS is being developed as part of a general environment for illustrated briefing over live multimedia information (Aho et al. 1997).</S>
    <S sid="30" ssid="22">Of all MUC system domains, terrorism is more likely to have a variety of related images than other domains that were explored, such as mergers and acquisitions or management succession.</S>
    <S sid="31" ssid="23">In order to extract information of interest to the user, SUMMONS makes use of components from several MUC systems.</S>
    <S sid="32" ssid="24">The output of such modules is in the form of SUMMONS architecture. templates that represent certain pieces of information found in the source news articles, such as victims, perpetrators, or type of event.</S>
    <S sid="33" ssid="25">By relying on these systems, the task we have addressed to date is happily more restricted than direct summarization of full text.</S>
    <S sid="34" ssid="26">This has allowed us to focus on issues related to the combination of information in the templates and the generation of text to express them.</S>
    <S sid="35" ssid="27">In order to port our system to other domains, we would need to develop new templates and the information extraction rules required for them.</S>
    <S sid="36" ssid="28">While this is a task we leave to those working in the information extraction field, we note that there do exist tools for semi-automatically acquiring such rules (Lehnert et al. 1993; Fisher et al.</S>
    <S sid="37" ssid="29">1995).</S>
    <S sid="38" ssid="30">This helps to alleviate the otherwise knowledge-intensive nature of the task.</S>
    <S sid="39" ssid="31">We are working on the development of tools for domain-independent types of information extraction.</S>
    <S sid="40" ssid="32">For example, our work on extracting descriptions of individuals and organizations and representing them in a formalism that facilitates reuse of the descriptions in summaries can be used in any domain.</S>
    <S sid="41" ssid="33">In the remainder of this section, we highlight the novel techniques of SUMMONS and explain why they are important for our work.</S>
    <S sid="42" ssid="34">With a few exceptions (cf.</S>
    <S sid="43" ssid="35">Section 2), all existing summarizers provide summaries of single articles by extracting sentences from them.</S>
    <S sid="44" ssid="36">If such systems were applied to a series of articles, they might be able to extract sentences that have words in common with the other articles, but they would be unable to indicate how sentences that were extracted from different articles were similar.</S>
    <S sid="45" ssid="37">Moreover, they would certainly not be able to indicate significant differences between articles.</S>
    <S sid="46" ssid="38">In contrast, our work focuses on processing of information from multiple sources to highlight agreements and contradictions as part of the summary.</S>
    <S sid="47" ssid="39">Given the omnipresence of on-line news services, one can expect that any interesting news event will be covered by several, if not most of them.</S>
    <S sid="48" ssid="40">If different sources present the same information, the user clearly only needs to have access to one of them.</S>
    <S sid="49" ssid="41">Practically, this assumption doesn't hold, as different sources provide updates from a different perspective and at different times.</S>
    <S sid="50" ssid="42">An intelligent summarizer's task, therefore, is to attain as much information from the multiple sources as possible, combine it, and present it in a concise form to the user.</S>
    <S sid="51" ssid="43">For example, if two sources of information report a different number of casualties in a particular incident, SUMMONS will report the contradiction and attribute the contradictory information to its sources, rather than select one of the contradictory pieces without the other.</S>
    <S sid="52" ssid="44">An inherent problem to summarizers based on sentence extraction is the lack of discourse-level fluency in the output.</S>
    <S sid="53" ssid="45">The extracted sentences fit together only in the case they are adjacent in the source document.</S>
    <S sid="54" ssid="46">Because SUMMONS uses language generation techniques to determine the content and wording of the summary based on information extracted from input articles, it has all necessary information to produce a fluent surface summary.</S>
    <S sid="55" ssid="47">We show how the summary generated using symbolic techniques can be enhanced so that it includes descriptions of entities (such as people, places, or organizations) it contains.</S>
    <S sid="56" ssid="48">If a user tunes in to news on a given event several days after the first report, references to and descriptions of the event, people, and organizations involved may not be adequate.</S>
    <S sid="57" ssid="49">We collect such descriptions from on-line sources of past news and represent them using our generation formalism for reuse in later generation of summaries.</S>
    <S sid="58" ssid="50">The following section positions our research in the context of prior work in the area.</S>
    <S sid="59" ssid="51">Section 3 describes the system architecture that we have developed for the summarization task.</S>
    <S sid="60" ssid="52">The next two sections describe in more detail how a base summary is generated from multiple source articles and how the base summary is extended using descriptions extracted from on-line sources.</S>
    <S sid="61" ssid="53">Section 6 describes the current status of our system.</S>
    <S sid="62" ssid="54">We conclude this article in Sections 7 and 8 by describing some directions for future work in symbolic summarization of heterogeneous sources.</S>
  </SECTION>
  <SECTION title="2." number="3">
    <S sid="63" ssid="1">Previous work related to summarization falls into three main categories.</S>
    <S sid="64" ssid="2">In the first, full text is accepted as input and some percentage of the text is produced as output.</S>
    <S sid="65" ssid="3">Typically, statistical approaches, augmented with keyword or phrase matching, are used to lift from the article full sentences that can serve as a summary.</S>
    <S sid="66" ssid="4">Most of the work in this category produces a summary for a single article, although there are a few exceptions.</S>
    <S sid="67" ssid="5">The other two categories correspond to the two stages of processing that would have to be carried out if sentence extraction were not used: analysis of the input document to identify information that should appear in a summary and generation of a textual summary from a set of facts that are to be included.</S>
    <S sid="68" ssid="6">In this section, we first present work on sentence extraction, next turn to work on identifying information in an article that should appear in a summary, and conclude with work on generation of summaries from data, showing how this task differs from the more general language generation task.</S>
    <S sid="69" ssid="7">This is a systems-oriented perspective on summarization-related work, focusing on techniques that have been implemented for the task.</S>
    <S sid="70" ssid="8">There is also a large body of work on the nature of abstracting from a library science point of view (Borko 1975).</S>
    <S sid="71" ssid="9">This work distinguishes between different types of abstracts, most notably, indicative abstracts that tell what an article is about, and informative abstracts, that include major results from the article and can be read in place of it.</S>
    <S sid="72" ssid="10">SUMMONS generates summaries that are informative in nature.</S>
    <S sid="73" ssid="11">Research in psychology and education also focuses on how to teach people to write summaries (e.g., Endres-Niggemeyer 1993; Rothkegel 1993).</S>
    <S sid="74" ssid="12">This type of work can aid the development of summarization systems by providing insights into the human process of summarization that could be simulated in systems.</S>
    <S sid="75" ssid="13">To allow summarization in arbitrary domains, researchers have traditionally applied statistical techniques (Luhn 1958; Paice 1990; Preston and Williams 1994; Rau, Brandow, and Mitze 1994).</S>
    <S sid="76" ssid="14">This approach can be better termed extraction rather than summarization, since it attempts to identify and extract key sentences from an article using statistical techniques that locate important phrases using various statistical measures.</S>
    <S sid="77" ssid="15">This has been successful in different domains (Preston and Williams 1994) and is, in fact, the approach used in recent commercial summarizers (Apple [Boguraev and Kennedy 1997], Microsoft, and in)(ight).</S>
    <S sid="78" ssid="16">Rau, Brandow, and Mitze (1994) report that statistical summaries of individual news articles were rated lower by evaluators than summaries formed by simply using the lead sentence or two from the article.</S>
    <S sid="79" ssid="17">This follows the principle of the &amp;quot;inverted pyramid&amp;quot; in news writing, which puts the most salient information in the beginning of the article and leaves elaborations for later paragraphs, allowing editors to cut from the end of the text without compromising the readability of the remaining text.</S>
    <S sid="80" ssid="18">Paice (1990) also notes that problems for this approach center around the fluency of the resulting summary.</S>
    <S sid="81" ssid="19">For example, extracted sentences may accidentally include pronouns that have no previous reference in the extracted text or, in the case of extracting several sentences, may result in incoherent text when the extracted sentences are not consecutive in the original text and do not naturally follow one another.</S>
    <S sid="82" ssid="20">Paice describes techniques for modifying the extracted text to replace unresolved references.</S>
    <S sid="83" ssid="21">Summaries that consist of sentences plucked from texts have been shown to be useful indicators of content, but they are often judged to be highly unreadable (Brandow, Mitze, and Rau 1990).</S>
    <S sid="84" ssid="22">A more recent approach (Kupiec, Pedersen, and Chen 1995) uses a corpus of articles with summaries to train a statistical summarization system.</S>
    <S sid="85" ssid="23">During training, the system uses abstracts of existing articles to identify the features of sentences that are typically included in abstracts.</S>
    <S sid="86" ssid="24">In order to avoid problems noted by Paice, the system produces an itemized list of sentences from the article thus eliminating the implication that these sentences function together coherently as a full paragraph.</S>
    <S sid="87" ssid="25">As with the other statistical approaches, this work is aimed at summarization of single articles.</S>
    <S sid="88" ssid="26">Work presented at the 1997 ACL Workshop on Intelligent Scalable Text Summarization primarily focused on the use of sentence extraction.</S>
    <S sid="89" ssid="27">Alternatives to the use of frequency of key phrases included the identification and representation of lexical chains (Halliday and Hasan 1976) to find the major themes of an article followed by the extraction of one or two sentences per chain (Barzilay and Elhadad 1997), training over the position of summary sentences in the full article (Hovy and Lin 1997), and the construction of a graph of important topics to identify paragraphs that should be extracted (Mitra, Singhal, and Buckley 1997).</S>
    <S sid="90" ssid="28">While most of the work in this category focuses on summarization of single articles, early work is beginning to emerge on summarization across multiple documents.</S>
    <S sid="91" ssid="29">In ongoing work at Carnegie Mellon, Carbonell (personal communication) is developing statistical techniques to identify similar sentences and phrases across articles.</S>
    <S sid="92" ssid="30">The aim is to identify sentences that are representative of more than one article.</S>
    <S sid="93" ssid="31">Mani and Bloedorn (1997) link similar words and phrases from a pair of articles using WordNet (Miller et al. 1990) semantic relations.</S>
    <S sid="94" ssid="32">They show extracted sentences from the two articles side by side in the output.</S>
    <S sid="95" ssid="33">While useful in general, sentence extraction approaches cannot handle the task that we address, aggregate summarization across multiple documents, since this requires reasoning about similarities and differences across documents to produce generalizations or contradictions at a conceptual level.</S>
    <S sid="96" ssid="34">Work in summarization using symbolic techniques has tended to focus more on identifying information in text that can serve as a summary (Young and Hayes 1985; Rau 1988; Hahn 1990) than on generating the summary, and often relies heavily on domain-dependent scripts (DeJong 1979; Tait 1983).</S>
    <S sid="97" ssid="35">The DARPA message understanding systems (MUC 1992), which process news articles in specific domains to extract specified types of information, also fall within this category.</S>
    <S sid="98" ssid="36">As output, work of this type produces templates that identify important pieces of information in the text, representing them as attribute-value pairs that could be part of a database entry.</S>
    <S sid="99" ssid="37">The message understanding systems, in particular, have been developed over a long period, have undergone repeated evaluation and development, including moves to new domains, and as a result, are quite robust.</S>
    <S sid="100" ssid="38">They are impressive in their ability to handle large quantities of free-form text as input.</S>
    <S sid="101" ssid="39">As stand-alone systems, however, they do not address the task of summarization since they do not combine and rephrase extracted information as part of a textual summary.</S>
    <S sid="102" ssid="40">A recent approach to symbolic summarization is being carried out at Cambridge University on identifying strategies for summarization (Sparck Jones 1993).</S>
    <S sid="103" ssid="41">This work studies how various discourse processing techniques (e.g., rhetorical structure relations) can be used to both identify important information and form the actual summary.</S>
    <S sid="104" ssid="42">While promising, this work does not involve an implementation as of yet, but provides a framework and strategies for future work.</S>
    <S sid="105" ssid="43">Marcu (1997) uses a rhetorical parser to build rhetorical structure trees for arbitrary texts and produces a summary by extracting sentences that span the major rhetorical nodes of the tree.</S>
    <S sid="106" ssid="44">In addition to domain-specific information extraction systems, there has also been a large body of work on identifying people and organizations in text through proper noun extraction.</S>
    <S sid="107" ssid="45">These are domain-independent techniques that can also be used to extract information for a summary.</S>
    <S sid="108" ssid="46">Techniques for proper noun extraction include the use of regular grammars to delimit and identify proper nouns (Mani et al. 1993; Paik et al.</S>
    <S sid="109" ssid="47">1994), the use of extensive name lists, place names, titles and &amp;quot;gazetteers&amp;quot; in conjunction with partial grammars in order to recognize proper nouns as unknown words in close proximity to known words (Cowie et al. 1992; Aberdeen et al.</S>
    <S sid="110" ssid="48">1992), statistical training to learn, for example, Spanish names, from on-line corpora (Ayuso et al. 1992), and the use of concept-based pattern matchers that use semantic concepts as pattern categories as well as part-of-speech information (VVeischedel et al.</S>
    <S sid="111" ssid="49">1993; Lehnert et al. 1993).</S>
    <S sid="112" ssid="50">In addition, some researchers have explored the use of both local context surrounding the hypothesized proper nouns (McDonald 1993; Coates-Stephens 1991) and the larger discourse context (Mani et al. 1993) to improve the accuracy of proper noun extraction when large known-word lists are not available.</S>
    <S sid="113" ssid="51">In a way similar to this research, our work also aims at extracting proper nouns without the aid of large word lists.</S>
    <S sid="114" ssid="52">We use a regular grammar encoding part-of-speech categories to extract certain text patterns (descriptions) and we use WordNet (Miller et al. 1990) to provide semantic filtering.</S>
    <S sid="115" ssid="53">Another system, called MURAX (Kupiec 1993), is similar to ours from a different perspective.</S>
    <S sid="116" ssid="54">MURAX also extracts information from a text to serve directly in response to a user question.</S>
    <S sid="117" ssid="55">MURAX uses lexicosyntactic patterns, collocational analysis, along with information retrieval statistics, to find the string of words in a text that is most likely to serve as an answer to a user's wh-query Ultimately, this approach could be used to extract information on items of interest in a user profile, where each question may represent a different point of interest.</S>
    <S sid="118" ssid="56">In our work, we also reuse strings (i.e., descriptions) as part of the summary, but the string that is extracted may be merged, or regenerated, as part of a larger textual summary.</S>
    <S sid="119" ssid="57">Summarization of data using symbolic techniques has met with more success than summarization of text.</S>
    <S sid="120" ssid="58">Summary generation is distinguished from the more traditional language generation problem by the fact that summarization is concerned with conveying the maximal amount of information within minimal space.</S>
    <S sid="121" ssid="59">This goal is achieved through two distinct subprocesses, conceptual and linguistic summarization.</S>
    <S sid="122" ssid="60">Conceptual summarization is a form of content selection.</S>
    <S sid="123" ssid="61">It must determine which concepts out of a large number of concepts in the input should be included in the summary.</S>
    <S sid="124" ssid="62">Linguistic summarization is concerned with expressing that information in the most concise way possible.</S>
    <S sid="125" ssid="63">We have worked on the problem of summarization of data within the context of three separate systems.</S>
    <S sid="126" ssid="64">STREAK (Robin and McKeown 1993; Robin 1994; Robin and McKeown 1995) generates summaries of basketball games, using a revision-based approach to summarization.</S>
    <S sid="127" ssid="65">It builds a first draft using fixed information that must appear in the summary (e.g., in basketball summaries, the score and who won and lost is always present).</S>
    <S sid="128" ssid="66">In a second pass, it uses revision rules to opportunistically add in information, as allowed by the form of the existing text.</S>
    <S sid="129" ssid="67">Using this approach, information that might otherwise appear as separate sentences gets added in as modifiers of the existing sentences, or new words that can simultaneously convey both pieces of information are selected.</S>
    <S sid="130" ssid="68">PLANDoc (McKeown, Kukich, and Shaw 1994a; McKeown, Robin, and Kukich 1995; Shaw 1995) generates summaries of the activities of telephone planning engineers, using linguistic summarization both to order its input messages and to combine them into single sentences.</S>
    <S sid="131" ssid="69">Focus has been on the combined use of conjunction, ellipsis, and paraphrase to result in concise, yet fluent reports (Shaw 1995).</S>
    <S sid="132" ssid="70">ZEDDoc (Passormeau et al. 1997; Kukich et al.</S>
    <S sid="133" ssid="71">1997) generates Web traffic summaries for advertisement management software.</S>
    <S sid="134" ssid="72">It makes use of an ontology over the domain to combine information at the conceptual level.</S>
    <S sid="135" ssid="73">All of these systems take tabular data as input.</S>
    <S sid="136" ssid="74">The research focus has been on linguistic summarization.</S>
    <S sid="137" ssid="75">SUMMONS, on the other hand, focuses on conceptual summarization of both structured and full-text data.</S>
    <S sid="138" ssid="76">At least four previous systems developed elsewhere use natural language to summarize quantitative data, including ANA (Kukich 1983), SEMTEX (Rosner 1987), FOG (Bourbeau et al. 1990), and LFS (Iordanskaja et al.</S>
    <S sid="139" ssid="77">1994).</S>
    <S sid="140" ssid="78">All of these use some forms of conceptual and linguistic summarization and the techniques can be adapted for our current work on summarization of multiple articles.</S>
    <S sid="141" ssid="79">In related work, Dalianis and Hovy (1993) have also looked at the problem of summarization, identifying eight aggregation operators (e.g., conjunction around noun phrases) that apply during generation to create more concise text.</S>
  </SECTION>
  <SECTION title="3." number="4">
    <S sid="142" ssid="1">The overall architecture of our summarization system given earlier in Figure 1 draws on research in software agents (Genesereth and Ketchpel 1994) to allow connections to a variety of different types of data sources.</S>
    <S sid="143" ssid="2">Facilities are used to provide a transparent interface to heterogeneous data sources that run on several machines and may be written in different programming languages.</S>
    <S sid="144" ssid="3">Currently, we have incorporated facilities to various live news streams, the CIA World Factbook, and past newspaper archives.</S>
    <S sid="145" ssid="4">The architecture allows for the incorporation of additional facilitators and data sources as our work progresses.</S>
    <S sid="146" ssid="5">The system extracts data from the different sources and then combines it into a conceptual representation of the summary.</S>
    <S sid="147" ssid="6">The summarization component, shown on the left side of the figure, consists of a base summary generator, which combines information from multiple input articles and organizes that information using a paragraph planner.</S>
    <S sid="148" ssid="7">The structured conceptual representation of the summary is passed to the lexical chooser, shown at the bottom of the diagram.</S>
    <S sid="149" ssid="8">The lexical chooser also receives input from the World Factbook and possible descriptions of people or organizations to augment the base summary The full content is then passed through a sentence generator, implemented using the FUF / SURGE language generation system (Elhadad 1993; Robin 1994).</S>
    <S sid="150" ssid="9">FUF is a functional unification formalism that uses a large systemic grammar of English, called SURGE, to fill in syntactic constraints, build a syntactic tree, choose closed class words, and eventually linearize the tree as a sentence.</S>
    <S sid="151" ssid="10">The right side of the figure shows how proper nouns and their descriptions are extracted from past news.</S>
    <S sid="152" ssid="11">An entity extractor identifies proper nouns in the past newswire archives, along with descriptions.</S>
    <S sid="153" ssid="12">Descriptions are then categorized using the WordNet hierarchy.</S>
    <S sid="154" ssid="13">Finally, an FD or functional description (Elhadad 1993) for the description is generated so that it can be reused in fluent ways in the final summary FDs mix functional, semantic, syntactic, and lexical information in a recursive attribute-value format that serves as the basic data structure for all information within FUF /SURGE.</S>
  </SECTION>
  <SECTION title="4." number="5">
    <S sid="155" ssid="1">SUMMONS produces a summary from sets of templates that contain the salient facts reported in the input articles and that are produced by the message understanding systems.</S>
    <S sid="156" ssid="2">These systems extract specific pieces of information from a given news article.</S>
    <S sid="157" ssid="3">An example of a template produced by MUC systems and used in our system is shown in Figures 2 and 3.</S>
    <S sid="158" ssid="4">To test our system, we used the templates produced by systems participating in MUC-4 (MUC 1992) as input.</S>
    <S sid="159" ssid="5">MUC-4 systems operate on the terrorist domain and extract information by filling fields such as perpetrator, victim, and type of event, for a total number of 25 fields per template.</S>
    <S sid="160" ssid="6">In addition, we filled the same template forms by hand from current news articles for further testing.</S>
    <S sid="161" ssid="7">Currently, work is under way in our group on the building of an information extraction module similar to the ones used in the MUC conferences, which we will later use as an input to SUMMONS.</S>
    <S sid="162" ssid="8">We are basing our implementation on the tools developed at the University of Massachusetts (Fisher et al. 1995).</S>
    <S sid="163" ssid="9">The resulting system will not only be able to generate summaries from preparsed templates but will also produce summaries directly from raw text by merging the message understanding component with the current version of SUMMONS.</S>
    <S sid="164" ssid="10">Our work provides a methodology for developing summarization systems, identifies planning operators for combining information in a concise summary, and uses empirically collected phrases to mark summarized material.</S>
    <S sid="165" ssid="11">We have collected a corpus of newswire summaries that we used as data for developing the planning operators and for gathering a large set of lexical constructions used in summarization.</S>
    <S sid="166" ssid="12">This Reuters reported that 18 people were killed in a Jerusalem bombing Sunday.</S>
    <S sid="167" ssid="13">The next day, a bomb in Tel Aviv killed at least 10 people and wounded 30 according to Israel radio.</S>
    <S sid="168" ssid="14">Reuters reported that at least 12 people were killed and 105 wounded.</S>
    <S sid="169" ssid="15">Later the same day, Reuters reported that the radical Muslim group Hamas had claimed responsibility for the act. corpus will eventually aid in a full system evaluation.</S>
    <S sid="170" ssid="16">Since news articles often summarize previous reports of the same event, our corpus also includes short summaries of previous articles.</S>
    <S sid="171" ssid="17">We used this corpus to develop both the content planner (i.e., the module that determines what information to include in the summary) and the linguistic component (i.e., the module that determines the words and surface syntactic form of the summary) of our system.</S>
    <S sid="172" ssid="18">We used the corpus to identify planning operators that are used to combine information; this includes techniques for linking information together in a related way (e.g., identifying changes, similarities, trends) as well as making generalizations.</S>
    <S sid="173" ssid="19">We also identified phrases that are used to mark summaries and used these to build the system lexicon.</S>
    <S sid="174" ssid="20">An example summary produced by the system is shown in Figure 4.</S>
    <S sid="175" ssid="21">This paragraph summarizes four articles about two separate terrorist acts that took place in Israel in March of 1996 using two different planning operators.</S>
    <S sid="176" ssid="22">While the system we report on is fully implemented, our work is undergoing continuous development.</S>
    <S sid="177" ssid="23">Currently, the system includes eight different planning operators, a testbed of 200 input templates grouped into sets on the same event, and can produce fully lexicalized summaries for approximately half of the cases (the rest of the templates were either not complete or the information extracted in them was irrelevant to the task).</S>
    <S sid="178" ssid="24">We haven't performed an evaluation beyond the testbed.</S>
    <S sid="179" ssid="25">Our work provides a methodology for increasing the vocabulary size and the robustness of the system using a collected corpus, and moreover, it shows how summarization can be used to evaluate the message understanding systems, identifying future research directions that would not be pursued under the current MUC evaluation cycle.2 Due to inherent difficulties in the summarization task, our work is a substantial first step and provides the framework for a number of different research directions.</S>
    <S sid="180" ssid="26">The rest of this section describes the summarizer, specifying the planning operators used for summarization as well as a detailed discussion of the summarization algorithm showing how summaries of different length are generated.</S>
    <S sid="181" ssid="27">We provide examples of the summarization markers we collected for the lexicon and show the demands that summarization creates for interpretation.</S>
    <S sid="182" ssid="28">The summarization component of SUMMONS is based on the traditional language generation system architecture (McKeown 1985; McDonald and Pustejovsky 1986; Hovy 1988).</S>
    <S sid="183" ssid="29">A typical language generator is divided into two main components, a 2 Participating systems in the DARPA message understanding program are evaluated on a regular basis.</S>
    <S sid="184" ssid="30">Participants are given a set of training text to tune their systems over a period of time and their systems are tested on unseen text at follow-up conferences. content planner, which selects information from an underlying knowledge base to include in a text, and a linguistic component, which selects words to refer to concepts contained in the selected information and arranges those words, appropriately inflecting them, to form an English sentence.</S>
    <S sid="185" ssid="31">The content planner produces a conceptual representation of text meaning (e.g., a frame, a logical form, or an internal representation of text) and typically does not include any linguistic information.</S>
    <S sid="186" ssid="32">The linguistic component uses a lexicon and a grammar of English to realize the conceptual representation into a sentence.</S>
    <S sid="187" ssid="33">The lexicon contains the vocabulary for the system and encodes constraints about when each word can be used.</S>
    <S sid="188" ssid="34">As shown in Figure 1, the content planner used by SUMMONS determines what information from the input MUC templates should be included in the summary using a set of planning operators that are specific to summarization and, to some extent, to the terrorist domain.</S>
    <S sid="189" ssid="35">Its linguistic component determines the phrases and surface syntactic form of the summary.</S>
    <S sid="190" ssid="36">The linguistic component consists of a lexical chooser, which determines the high-level sentence structure of each sentence and the words that realize each semantic role, and the FUF /SURGE (Elhadad 1991; Elhadad 1993) sentence generator.</S>
    <S sid="191" ssid="37">Input to SUMMONS is a set of templates, where each template represents the information extracted from one or more articles by a message understanding system.</S>
    <S sid="192" ssid="38">However, we constructed by hand an additional set of templates that include also terrorist events that have taken place after the period of time covered in MUC-4, such as the World Trade Center bombing, the Hebron Mosque massacre and more recent incidents in Israel, as well as the disaster in Oklahoma City.</S>
    <S sid="193" ssid="39">These incidents were not handled by the original message understanding systems.</S>
    <S sid="194" ssid="40">We also created by hand a set of templates unrelated to real newswire articles, which we used for testing some techniques of our system.</S>
    <S sid="195" ssid="41">We enriched the templates for all these cases by adding four slots: the primary source, the secondary source, and the times at which both sources made their reports.'</S>
    <S sid="196" ssid="42">We found having the source of the report immensely useful for discovering and reporting contradictions and generalizations, because often different reports of an event are in conflict.</S>
    <S sid="197" ssid="43">Also, source information can indicate the level of confidence of the report, particularly when reported information changes over time.</S>
    <S sid="198" ssid="44">For example, if several secondary sources all report the same facts for a single event, citing multiple primary sources, it is more likely that this is the way the event really happened, while if there are many contradictions between reports, it is likely that the facts are not yet fully known.</S>
    <S sid="199" ssid="45">Members of our research group are currently working on event tracking (Aho et al. 1997).</S>
    <S sid="200" ssid="46">Their prototype uses pattern-matching techniques to track changes to on-line news sources and provide a live feed of articles that relate to a changing event.</S>
    <S sid="201" ssid="47">SUMMONS's summarization component generates a base summary, which contains facts extracted from the input set of articles.</S>
    <S sid="202" ssid="48">The base summary is later enhanced with additional facts from on-line structured databases with descriptions of individuals extracted from previous news to produce the extended summary.</S>
    <S sid="203" ssid="49">The base summary is a paragraph consisting of one or more sentences, where the length of the summary is controlled by a variable input parameter.</S>
    <S sid="204" ssid="50">In the absence of a specific user model, the base summary is produced.</S>
    <S sid="205" ssid="51">Otherwise, the extended summary (base summary with added descriptions of entities) is generated instead.</S>
    <S sid="206" ssid="52">Similarly, the default is that the summary contains references to contradictory and updated information.</S>
    <S sid="207" ssid="53">However, if the user profile makes it explicit, only the latest and the most trusted (as per the user's preference of sources) facts are included.</S>
    <S sid="208" ssid="54">SUMMONS rates information in terms of importance, where information that appears in only one article is given a lower rating and information that is synthesized from multiple articles is rated more highly.</S>
    <S sid="209" ssid="55">Development of the text generation component of SUMMONS was made easier because of the language generation tools and framework available at Columbia University.</S>
    <S sid="210" ssid="56">No changes in the FUF sentence generator were needed.</S>
    <S sid="211" ssid="57">In addition, the lexical chooser and content planner were based on the design used in the PLANDoc automated documentation system described in Section 2.3.</S>
    <S sid="212" ssid="58">In particular, we used FUF to implement the lexical chooser, representing the lexicon as a grammar as we have done in many previous systems (Elhadad 1993; Robin 1994; McKeown, Robin, and Tanenblatt 1993; Feiner and McKeown 1991).</S>
    <S sid="213" ssid="59">The main effort in porting the approach to SUMMONS was in identifying the words and phrases needed for the domain.</S>
    <S sid="214" ssid="60">The content planner features several stages.</S>
    <S sid="215" ssid="61">It first groups news articles together, identifies commonalities between them, and notes how the discourse influences wording by setting realization flags, which denote such discourse features as &amp;quot;similarity&amp;quot; and &amp;quot;contradiction.&amp;quot; Realization flags (McKeown, Kukich, and Shaw 1994b) guide the choice of connectives in the generation stage.</S>
    <S sid="216" ssid="62">Before lexical choice, SUMMONS maps the templates into FDs that are expected as input to FUF and uses a domain ontology (derived from the ontologies represented in the message understanding systems) to enrich the input.</S>
    <S sid="217" ssid="63">For example, grenades and bombs are both explosives, while diplomats and civilians are both considered to be human targets.</S>
    <S sid="218" ssid="64">In order to produce plausible and understandable summaries, we used available online corpora as models, including the Wall Street Journal and current newswire from Reuters and the Associated Press.</S>
    <S sid="219" ssid="65">The corpus of summaries is 2.5 MB in size.</S>
    <S sid="220" ssid="66">We have manually grouped 300 articles in threads related to single events or series of similar events.</S>
    <S sid="221" ssid="67">From the corpora collected in this way, we extracted manually, and after careful investigation, several hundred language constructions that we found relevant to the types of summaries we want to produce.</S>
    <S sid="222" ssid="68">In addition to the summary cue phrases collected from the corpus, we also tried to incorporate as many phrases as possible that have relevance to the message understanding conference domain.</S>
    <S sid="223" ssid="69">Due to domain variety, such phrases were essentially scarce in the newswire corpora and we needed to collect them from other sources (e.g., modifying templates that we acquired from the summary corpora to provide a wider coverage).</S>
    <S sid="224" ssid="70">Since one of the features of a briefing is conciseness, we have tried to assemble small paragraph summaries that, in essence, describe a single event and the change of perception of the event over time, or a series of related events with no more than a few sentences.</S>
    <S sid="225" ssid="71">The main point of departure for SUMMONS from previous work is in the stage of identifying what information to include and how to group it together, as well as the use of a corpus to guide this and later processes.</S>
    <S sid="226" ssid="72">In PLANDoc, successive items to summarize are very similar and the problem is to form a grouping that puts the most similar items together, allowing the use of conjunction and ellipsis to delete repetitive material.</S>
    <S sid="227" ssid="73">For summarizing multiple news articles, the task is almost the opposite; we need to find the differences from one article to the next, identifying how the reported facts have changed.</S>
    <S sid="228" ssid="74">Thus, the main problem was the identification of summarization strategies, which indicate how information is linked together to form a concise and cohesive summary.</S>
    <S sid="229" ssid="75">As we have found in other work (Robin 1994), what information is included is often dependent on the language available to make concise additions.</S>
    <S sid="230" ssid="76">Thus, using a corpus summary was critical to identifying the different summaries possible.</S>
    <S sid="231" ssid="77">We have developed a set of heuristics derived from the corpora that decide what types of simple sentences constitute a summary, in what order they need to be listed, as well as the ways in which simple sentences are combined into more complex ones.</S>
    <S sid="232" ssid="78">In addition, we have specified which summarization-specific phrases are to be included in different types of summaries.</S>
    <S sid="233" ssid="79">The system identifies a preeminent set of templates from the input to the MUC system.</S>
    <S sid="234" ssid="80">This set needs to contain a large number of similar fields.</S>
    <S sid="235" ssid="81">If this holds, we can merge the set into a simpler structure, keeping the common features and marking the distinct features as Elhadad (1993) and McKeown, Kukich, and Shaw (1994b) suggest.</S>
    <S sid="236" ssid="82">At each step, a summary operator is selected based on existing similarities between articles in the database.</S>
    <S sid="237" ssid="83">This operator is then applied to the input templates, resulting in a new template that combines, or synthesizes, information from the old.</S>
    <S sid="238" ssid="84">Each operator is independent of the others and several can be applied in succession to the input templates.</S>
    <S sid="239" ssid="85">Each of the seven major operators is further subdivided to cover various modifications to its input.</S>
    <S sid="240" ssid="86">Figure 5 shows part of the rules for the Contradiction operator.</S>
    <S sid="241" ssid="87">Given two templates, if INCIDENT.LOCATION is the same, the time of first report is before time of second report, the report sources are different, and at least one other slot differs in value, apply the contradiction operator to combine the templates.</S>
    <S sid="242" ssid="88">A summary operator encodes a means for linking information in two different templates.</S>
    <S sid="243" ssid="89">Often it results in the synthesis of new information.</S>
    <S sid="244" ssid="90">For example, a generalization may be formed from two independent facts.</S>
    <S sid="245" ssid="91">Alternatively, since we are summarizing reports written over time, highlighting how knowledge of the event changed is important and, therefore, summaries sometimes must identify differences between reports.</S>
    <S sid="246" ssid="92">A description of the operators we identified in our corpus follows, accompanied by an example of system output for each operator.</S>
    <S sid="247" ssid="93">Each example primarily summarizes two or three input templates, as this is the result of applying a single operator once.</S>
    <S sid="248" ssid="94">More complex summaries can be produced by applying multiple operators on the same input, as shown in the examples; see Figures 6 to 11 in Section 4.5.</S>
    <S sid="249" ssid="95">4.3.1 Change of Perspective.</S>
    <S sid="250" ssid="96">When an initial report gets a fact wrong or has incomplete information, the change is usually included in the summary.</S>
    <S sid="251" ssid="97">In order for the &amp;quot;change of perspective&amp;quot; operator to apply, the SOURCE field must be the same, while the value of another field changes so that it is not compatible with the original value.</S>
    <S sid="252" ssid="98">For example, if the number of victims changes, we know that the first report was wrong if the number goes down, while the source had incomplete information (or additional people died) if the number goes up.</S>
    <S sid="253" ssid="99">The first two sentences from the following example were generated using the change of perspective operator.</S>
    <S sid="254" ssid="100">The initial estimate of &amp;quot;at least 10 people&amp;quot; killed in the incident becomes &amp;quot;at least 12 people.&amp;quot; Similarly, the change in the number of wounded people is also reported.</S>
    <S sid="255" ssid="101">March 4th, Reuters reported that a bomb in Tel Aviv killed at least 10 people and wounded 30.</S>
    <S sid="256" ssid="102">Later the same day, Reuters reported that at least 12 people were killed and 105 wounded.</S>
    <S sid="257" ssid="103">4.3.2 Contradiction.</S>
    <S sid="258" ssid="104">When two sources report conflicting information about the same event, a contradiction arises.</S>
    <S sid="259" ssid="105">In the absence of values indicating the reliability of the sources, a summary cannot report either of them as true, but can indicate that the facts are not clear.</S>
    <S sid="260" ssid="106">The number of sources that contradict each other can indicate the level of confusion about the event.</S>
    <S sid="261" ssid="107">Note that the current output of the message understanding systems does not include sources.</S>
    <S sid="262" ssid="108">However, SUMMONS uses this feature to report disagreement between output by different systems.</S>
    <S sid="263" ssid="109">A summary might indicate that one of the sources determined that 20 people were killed, while the other source determined that only 5 were indeed killed.</S>
    <S sid="264" ssid="110">The difference between this example and the previous one on change of perspective is the source of the update.</S>
    <S sid="265" ssid="111">If the same source announces a change, then we know that it is reporting a change in the facts.</S>
    <S sid="266" ssid="112">Otherwise, an additional source presents information that is not necessarily more correct than the information presented by the earlier source and we can therefore conclude that we have a contradiction.</S>
    <S sid="267" ssid="113">The afternoon of February 26, 1993, Reuters reported that a suspected bomb killed at least six people in the World Trade Center.</S>
    <S sid="268" ssid="114">However, Associated Press announced that exactly five people were killed in the blast.</S>
    <S sid="269" ssid="115">4.3.3 Addition.</S>
    <S sid="270" ssid="116">When a subsequent report indicates that additional facts are known, this is reported in a summary.</S>
    <S sid="271" ssid="117">Additional results of the event may occur after the initial report or additional information may become known.</S>
    <S sid="272" ssid="118">The operator determines this by the way the value of a template slot changes.</S>
    <S sid="273" ssid="119">Since the former template doesn't contain a value for the perpetrator slot and the latter contains information about claimed responsibility, we can apply the addition operator.</S>
    <S sid="274" ssid="120">On Monday, a bomb in Tel Aviv killed at least 10 people and wounded 30 according to Israel radio.</S>
    <S sid="275" ssid="121">Later the same day, Reuters reported that the radical Muslim group Hamas had claimed responsibility for the act.</S>
    <S sid="276" ssid="122">4.3.4 Refinement.</S>
    <S sid="277" ssid="123">In subsequent reports a more general piece of information may be refined.</S>
    <S sid="278" ssid="124">Thus, if an event is originally reported to have occurred in New York City, the location might later be specified as a particular borough of the city.</S>
    <S sid="279" ssid="125">Similarly, if a terrorist group is identified as Palestinian, later the exact name of the terrorist group may be determined.</S>
    <S sid="280" ssid="126">Since the update is assigned a higher value of &amp;quot;importance,&amp;quot; it will be favored over the original article in a shorter summary.</S>
    <S sid="281" ssid="127">Unlike the previous example, there was a value for the perpetrator slot in the first template, while the second one further elaborates on it, identifying the perpetrator more specifically.</S>
    <S sid="282" ssid="128">Example 4 On Monday, Reuters announced that a suicide bomber killed at least 10 people in Tel Aviv.</S>
    <S sid="283" ssid="129">Later the same day, Reuters reported that the Islamic fundamentalist group Hamas claimed responsibility.</S>
    <S sid="284" ssid="130">4.3.5 Agreement.</S>
    <S sid="285" ssid="131">If two sources have the same values for a specific slot, this will heighten the reader's confidence in their veracity and thus, agreement between sources is usually reported.</S>
    <S sid="286" ssid="132">Example 5 The morning of March 1st 1994, UPI reported that a man was kidnapped in the Bronx.</S>
    <S sid="287" ssid="133">Later, this was confirmed by Reuters.</S>
    <S sid="288" ssid="134">4.3.6 Superset/Generalization.</S>
    <S sid="289" ssid="135">If the same event is reported from different sources and all of them have incomplete information, it is possible to combine information from them to produce a more complete summary.</S>
    <S sid="290" ssid="136">This operator is also used to aggregate multiple events as shown in the example.</S>
    <S sid="291" ssid="137">Reuters reported that 18 people were killed in a Jerusalem bombing Sunday.</S>
    <S sid="292" ssid="138">The next day, a bomb in Tel Aviv killed at least 10 people and wounded 30 according to Israel radio.</S>
    <S sid="293" ssid="139">A total of at least 28 people were killed in the two terrorist acts in Israel over the last two days.</S>
    <S sid="294" ssid="140">It should be noted that in this example, the third sentence will not be generated if there is a restriction on the length of the summary.</S>
    <S sid="295" ssid="141">4.3.7 Trend.</S>
    <S sid="296" ssid="142">There is a trend if two or more articles reflect similar patterns over time.</S>
    <S sid="297" ssid="143">Thus, we might notice that three consecutive bombings occurred at the same location and summarize them into a single sentence.</S>
    <S sid="298" ssid="144">This is the third terrorist act committed by Hamas in four weeks.</S>
    <S sid="299" ssid="145">4.3.8 No Information.</S>
    <S sid="300" ssid="146">Since we are interested in conveying information about the primary and secondary sources of a certain piece of news, and since these are generally trusted sources of information, we ought also to pay attention to the lack of information from a certain source when such is expected to be present.</S>
    <S sid="301" ssid="147">For example, it might be the case that a certain news agency reports a terrorist act in a given country, but the authorities of that country don't give out any information.</S>
    <S sid="302" ssid="148">Since there is an infinite number of sources that might not confirm a given fact (or the system will not have access to the appropriate templates), we have included this operator only as an illustration of a concept that further highlights the domain-specificity of the system.</S>
    <S sid="303" ssid="149">Two bombs exploded in Baghdad, Iraqi dissidents reported Friday.</S>
    <S sid="304" ssid="150">There was no confirmation of the incidents by the Iraqi National Congress.</S>
    <S sid="305" ssid="151">The algorithm used in the system to sort, combine, and generalize the input templates is described in the following subsections.</S>
    <S sid="306" ssid="152">4.4.1 Input.</S>
    <S sid="307" ssid="153">At this stage, the system receives a set of templates from the message understanding conferences or a similar set of templates from a related domain.</S>
    <S sid="308" ssid="154">All templates are described as lists of attribute! value pairs (as shown later in Figure 7).</S>
    <S sid="309" ssid="155">These pairs (with the exception of the source information) are defined in the MUC-4 guidelines. message understanding system for the site submitting the template if it is not present in the input template.</S>
    <S sid="310" ssid="156">Note that since the current message understanding systems do not extract the source, this is the most specific we can be for such cases.</S>
    <S sid="311" ssid="157">We are experimenting with some techniques to automate the preprocessing stage.</S>
    <S sid="312" ssid="158">Our preliminary impressions show that by restricting SUMMONS to templates in which at least five or six slots are filled, we can eliminate most of the irrelevant templates. tween templates, which will trigger certain operators.</S>
    <S sid="313" ssid="159">Since slots are matched among templates in chronological order, there is only one sequence in which they can be applied.</S>
    <S sid="314" ssid="160">Such patterns trigger reordering of the templates and modification of their individual importance values.</S>
    <S sid="315" ssid="161">As an example, if two templates are combined with the refinement operator, the importance value of the combined template will be greater than the sum of the individual importance of the constituent templates.</S>
    <S sid="316" ssid="162">At the same time, the values of these two templates are lowered (still keeping a higher value on the later one, which is assumed to be the more correct of the two).</S>
    <S sid="317" ssid="163">All templates directly extracted from the MUC output are assigned an initial importance value of 100.</S>
    <S sid="318" ssid="164">Currently, with each application of an operator, we lower the value of a contributing individual template by 20 points and give any newly produced template that combines information from already existing contributing templates a value greater than the sum of the values of the contributing templates after those values have been updated.</S>
    <S sid="319" ssid="165">Furthermore, some operators reduce the importance values of existing templates even further (e.g., the refinement operator reduces the importance of chronologically earlier templates by additional increments of 20 points because they contain outdated information).</S>
    <S sid="320" ssid="166">Thus, the final summary will contain only the combined template if there are restrictions on length.</S>
    <S sid="321" ssid="167">Otherwise, text corresponding to the constituent templates will also be generated.</S>
    <S sid="322" ssid="168">The value of the importance of the template corresponds also to the position in the summary paragraph, as more important templates will be generated first.</S>
    <S sid="323" ssid="169">Each new template contains information indicating whether its constituent templates are obsolete and thus no longer needed.</S>
    <S sid="324" ssid="170">Also, at this stage the coverage vector (a data structure that keeps track of which templates have already been combined and which ones are still to be considered in applying operators) is updated to point to the templates that are still active and can be further combined.</S>
    <S sid="325" ssid="171">This way we make sure that all templates still have a chance of participating in the actual summary.</S>
    <S sid="326" ssid="172">The resulting templates are combined into small paragraphs according to the event or series of events that they describe.</S>
    <S sid="327" ssid="173">Each paragraph is then realized by the linguistic component.</S>
    <S sid="328" ssid="174">Each set of templates produces a single paragraph.</S>
    <S sid="329" ssid="175">4.4.4 Discourse Planning.</S>
    <S sid="330" ssid="176">Given the relative importance of the templates included in the database after the heuristic combination stage, the content planner organizes the presentation of information within a paragraph.</S>
    <S sid="331" ssid="177">It looks at consecutive templates in the database, marked as separate paragraphs from the previous stage, and assigns values to &amp;quot;realization switches&amp;quot; that control local choices such as tense and voice.</S>
    <S sid="332" ssid="178">They also govern the presence or absence of certain constituents to avoid repetition of constituents and to satisfy anaphora constraints.</S>
    <S sid="333" ssid="179">This subsection describes how the algorithm is applied to a set of four templates by tracing the computational process that transforms the raw source into a final natural language summary.</S>
    <S sid="334" ssid="180">Excerpts from the four input news articles are shown in Figure 6.</S>
    <S sid="335" ssid="181">The four news articles are transformed into four templates that correspond to four separate accounts of two related events and will be included in the set of templates from which the template combiner will work.</S>
    <S sid="336" ssid="182">Only the relevant fields are shown.</S>
    <S sid="337" ssid="183">Let's now consider the four templates in the order that they appear in the list of templates.</S>
    <S sid="338" ssid="184">These templates are shown in Figures 7 to 10.</S>
    <S sid="339" ssid="185">They are generated manually from the input newswire texts.</S>
    <S sid="340" ssid="186">Information about the primary and secondary sources of information is added (PRIMSOURCE and SECSOURCE) .</S>
    <S sid="341" ssid="187">The differences in the templates (which will trigger certain operators) are shown in bold face.</S>
    <S sid="342" ssid="188">The summary generated by the system was shown earlier in Figure 4 and is repeated here in Figure 11.</S>
    <S sid="343" ssid="189">The first two sentences are generated from template one.</S>
    <S sid="344" ssid="190">The subsequent sentences are generated using different operators that are triggered according to changing values for certain attributes in the three remaining templates.</S>
    <S sid="345" ssid="191">As previous templates didn't contain information about the perpetrator, SUMMONS applies the refinement operator to generate the fourth sentence.</S>
    <S sid="346" ssid="192">Sentence three is generated using the change of perspective operator, as the number of victims reported in articles two and three is different.</S>
    <S sid="347" ssid="193">The description for Hamas (&amp;quot;radical Muslim group&amp;quot;) was added by the extraction generator (see Section 5).</S>
    <S sid="348" ssid="194">Typically, a description is included in the source text and should be extracted by the message understanding system.</S>
    <S sid="349" ssid="195">In cases in which a description doesn't appear or is not extracted, SUMMONS generates a description from the database of extracted descriptions.</S>
    <S sid="350" ssid="196">We are currently working on an algorithm that Template for article three. will select the best description based on such parameters as the user model (what information has already been presented to the user?</S>
    <S sid="351" ssid="197">), the attitude towards the entity (is it favorable?</S>
    <S sid="352" ssid="198">), or a historical model that describes the changes in the profile of a person over the period of time (what was the previous occupation of the person who is being described?).</S>
    <S sid="353" ssid="199">Template for article four.</S>
    <S sid="354" ssid="200">Reuters reported that 18 people were killed in a Jerusalem bombing Sunday.</S>
    <S sid="355" ssid="201">The next day, a bomb in Tel Aviv killed at least 10 people and wounded 30 according to Israel radio.</S>
    <S sid="356" ssid="202">Reuters reported that at least 12 people were killed and 105 wounded.</S>
    <S sid="357" ssid="203">Later the same day, Reuters reported that the radical Muslim group Hamas had claimed responsibility for the act.</S>
  </SECTION>
  <SECTION title="5." number="6">
    <S sid="358" ssid="1">When a summary refers to an entity (person, place, or organization), it can make use of descriptions extracted by the MUC systems.</S>
    <S sid="359" ssid="2">Problems arise when information needed for the summary is either missing from the input article(s) or not extracted by the information extraction system.</S>
    <S sid="360" ssid="3">In such cases, the information may be readily available in other current news stories, in past news, or in on-line databases.</S>
    <S sid="361" ssid="4">If the summarization system can find the needed information in other on-line sources, then it can produce an improved summary by merging information extracted from the input articles with information from the other sources (Radev and McKeown 1997).</S>
    <S sid="362" ssid="5">In the news domain, a summary needs to refer to people, places, and organizations and provide descriptions that clearly identify the entity for the reader.</S>
    <S sid="363" ssid="6">Such descriptions may not be present in the original text that is being summarized.</S>
    <S sid="364" ssid="7">For example, the American pilot Scott O'Grady, downed in Bosnia in June of 1995, was unknown to the American public prior to the incident.</S>
    <S sid="365" ssid="8">To a reader who tuned into news on this event days later, descriptions from the initial articles might be more useful.</S>
    <S sid="366" ssid="9">A summarizer that has access to different descriptions will be able to select the description that best suits both the reader and the series of articles being summarized.</S>
    <S sid="367" ssid="10">Similarly, in the example in Section 4, if the user hasn't been informed about what Hamas is and no description is available in the source template, older descriptions in the FD format can be retrieved and used.</S>
    <S sid="368" ssid="11">In this section, we describe an enhancement to the base summarization system, called the profile manager, which tracks prior references to a given entity by extracting descriptions for later use in summarization.</S>
    <S sid="369" ssid="12">The component includes the entity extractor and description extractor modules shown in Figure 1 and has the following features: As a result, SUMMONS will be able to combine descriptions from articles appearing only a few minutes before the ones being summarized with descriptions from past news in a permanent storage for future use.</S>
    <S sid="370" ssid="13">Since the profile manager constructs a lexicalized, syntactic FD from the extracted description, the generator can reuse the description in new contexts, merging it with other descriptions, into a new grammatical sentence.</S>
    <S sid="371" ssid="14">This would not be possible if only canned strings were used, with no information about their internal structure.</S>
    <S sid="372" ssid="15">Thus, in addition to collecting a knowledge source that provides identifying features of individuals, the profile manager also provides a lexicon of domain-appropriate phrases that can be integrated with individual words from a generator's lexicon to produce summary wording in a flexible fashion.</S>
    <S sid="373" ssid="16">We have extended the profile manager by semantically categorizing descriptions using WordNet, so that a generator can more easily determine which description is relevant in different contexts.</S>
    <S sid="374" ssid="17">The profile manager can also be used in a real-time fashion to monitor entities and the changes of descriptions associated with them over the course of time.</S>
    <S sid="375" ssid="18">The rest of this section discusses the stages involved in the collection and reuse of descriptions.</S>
    <S sid="376" ssid="19">In this subsection, we describe the description management module of SUMMONS shown in Figure 1.</S>
    <S sid="377" ssid="20">We explain how entity names and descriptions for them are extracted from old newswire and how these descriptions are converted to FDs for surface generation. an initial set of descriptions, we used a 1.7 MB corpus containing Reuters newswire from February to June of 1995.</S>
    <S sid="378" ssid="21">Later, we used a Web-based interface that allowed anyone on the Internet to type in an entity name and force a robot to search for documents containing mentions of the entity and extract the relevant descriptions.</S>
    <S sid="379" ssid="22">These descriptions are then also added to the database.</S>
    <S sid="380" ssid="23">At this stage, search is limited to the database of retrieved descriptions only, thus reducing search time, as no connections will be made to external news sources at the time of the query.</S>
    <S sid="381" ssid="24">Only when a suitable stored description cannot be found will the system initiate search of additional text. dictionary.</S>
    <S sid="382" ssid="25">This resulted in a list of 421 unique entity names that we used for the automatic description extraction stage.</S>
    <S sid="383" ssid="26">All 421 entity names retrieved by the system are indeed proper nouns.</S>
    <S sid="384" ssid="27">5.1.2 Extraction of Descriptions.</S>
    <S sid="385" ssid="28">There are two occasions on which we extract descriptions using finite-state techniques.</S>
    <S sid="386" ssid="29">The first case is when the entity that we want to describe was already extracted automatically (see Section 5.1.1) and exists in the database of descriptions.</S>
    <S sid="387" ssid="30">The second case is when we want a description to be retrieved in real time based on a request from the generation component.</S>
    <S sid="388" ssid="31">In the first stage, the profile manager generates finite-state representations of the entities that need to be described.</S>
    <S sid="389" ssid="32">These full expressions are used as input to the description extraction module, which uses them to find candidate sentences in the corpus for extracting descriptions.</S>
    <S sid="390" ssid="33">Since the need for a description may arise at a later time than when the entity was found and may require searching new text, the description finder must first locate these expressions in the text.</S>
    <S sid="391" ssid="34">These representations are fed to CREP, which extracts noun phrases on either side of the entity (either pre-modifiers or appositions) from the news corpus.</S>
    <S sid="392" ssid="35">The finite-state grammar for noun phrases that we use represents a variety of different syntactic structures for both pre-modifiers and appositions.</S>
    <S sid="393" ssid="36">Thus, they may range from a simple noun (e.g., &amp;quot;president Bill Clinton&amp;quot;) to a much longer expression (e.g., &amp;quot;Gilberto Rodriguez Orejuela, the head of the Cali cocaine cartel&amp;quot;).</S>
    <S sid="394" ssid="37">Other forms of descriptions, such as relative clauses, are the focus of ongoing implementation.</S>
    <S sid="395" ssid="38">Table 2 shows some of the different patterns retrieved.</S>
    <S sid="396" ssid="39">For example, when the profile manager has retrieved the description the political arm of the Irish Republican Army for Sinn Fein, it looks at the head noun in the description NP (arm), which we manually added to the list of trigger words to be categorized as an organization (see next subsection).</S>
    <S sid="397" ssid="40">It is important to notice that even though WordNet typically presents problems with disambiguation of words retrieved from arbitrary text, we don't have any trouble disambiguating arm in this case due to the constraints on the context in which it appears (as an apposition describing an entity).</S>
    <S sid="398" ssid="41">5.1.3 Categorization of Descriptions.</S>
    <S sid="399" ssid="42">We use WordNet to group extracted descriptions into categories.</S>
    <S sid="400" ssid="43">For the head noun of the description NP, we try to find a WordNet hypernym that can restrict the semantics of the description.</S>
    <S sid="401" ssid="44">Currently, we identify concepts such as &amp;quot;profession,&amp;quot; &amp;quot;nationality,&amp;quot; and &amp;quot;organization.&amp;quot; Each of these concepts is triggered by one or more words (which we call trigger terms) in the description.</S>
    <S sid="402" ssid="45">Table 2 shows some examples of descriptions and the concepts under which they are classified based on the WordNet hypernyms for some trigger words.</S>
    <S sid="403" ssid="46">For example, all of the following triggers in the list (minister, head, administrator, and commissioner) can be traced up to leader in the WordNet hierarchy.</S>
    <S sid="404" ssid="47">We have currently a list of 75 such trigger words that we have compiled manually. we create a new profile in a database of profiles.</S>
    <S sid="405" ssid="48">We keep information about the surface string that is used to describe the entity in newswire (e.g., Addis Ababa), the source of the description and the date that the entry has been made in the database (e.g., &amp;quot;reuters95_06_25&amp;quot;).</S>
    <S sid="406" ssid="49">In addition to these pieces of metainformation, all retrieved descriptions and their frequencies are also stored.</S>
    <S sid="407" ssid="50">Currently, our system doesn't have the capability of matching references to the same entity that use different wordings.</S>
    <S sid="408" ssid="51">As a result, we keep separate profiles for each of the following: Robert Dole, Dole, and Bob Dole.</S>
    <S sid="409" ssid="52">We use each of these strings as the key in the database of descriptions.</S>
    <S sid="410" ssid="53">Figure 12 shows the profile associated with the key John Major.</S>
    <S sid="411" ssid="54">It can be seen that four different descriptions have been used in the parsed corpus to describe John Major.</S>
    <S sid="412" ssid="55">Two of the four are common and are used in SUMMONS, whereas the other two result from incorrect processing by POS and/ or CREP.</S>
    <S sid="413" ssid="56">The database of profiles is updated every time a query retrieves new descriptions matching a certain key.</S>
    <S sid="414" ssid="57">When presenting an entity to the user, the content planner of a language generation system may decide to include some background information about it if the user has Generated FD for Silvio Berlusconi. not previously seen the entity.</S>
    <S sid="415" ssid="58">When the extracted information doesn't contain an appropriate description, the system can use some descriptions retrieved by the profile manager. the extracted descriptions in the generation of summaries, we have developed a module that converts finite-state descriptions retrieved by the description extractor into functional descriptions that we can use directly in generation.</S>
    <S sid="416" ssid="59">A description retrieved by the system is shown in Figure 13.</S>
    <S sid="417" ssid="60">The corresponding FD is shown in Figure 14. semantics, the profile manager can prefer to generate one over another based on semantic features.</S>
    <S sid="418" ssid="61">This is useful if a summary discusses events related to one description associated with the entity more than the others.</S>
    <S sid="419" ssid="62">For example, when an article concerns Bill Clinton on the campaign trail, then the description democratic presidential candidate is more appropriate.</S>
    <S sid="420" ssid="63">On the other hand, when an article concerns an international summit of world leaders, then the description U.S. President is more appropriate.</S>
  </SECTION>
  <SECTION title="6." number="7">
    <S sid="421" ssid="1">Currently, our system can produce simple summaries consisting of one- to three- sentence paragraphs, which are limited to the MUC domain and to a few additional events for which we have manually created MUC-like templates.</S>
    <S sid="422" ssid="2">We have also implemented the modules to connect to the World Factbook.</S>
    <S sid="423" ssid="3">We have converted all ontologies related to the MUC and the Factbook into FDs.</S>
    <S sid="424" ssid="4">The user model, which would allow users to specify preferred sources of information, frequency of briefings, etc., hasn't been fully implemented yet.</S>
    <S sid="425" ssid="5">A problem that we haven't addressed is related to the clustering of articles according to their relevance to a specific event.</S>
    <S sid="426" ssid="6">This is an area that requires further research.</S>
    <S sid="427" ssid="7">Another such area is the development of algorithms for grouping together articles that belong to the same topic.</S>
    <S sid="428" ssid="8">Finally, one of our main topics for future work is the development of techniques that can generate summary updates.</S>
    <S sid="429" ssid="9">To do this, we must make use of a discourse model that represents the content and wording of summaries that have already been presented to the user.</S>
    <S sid="430" ssid="10">When generating an update, the summarizer must avoid repeating content and, at the same time, must be able to generate references to entities and events that were previously described.</S>
    <S sid="431" ssid="11">At the current stage, the description generator has the following coverage: person's profile with the profile of the organization of which he is a member.</S>
    <S sid="432" ssid="12">We should note that extensive research in this field exists and we plan to make use of one of the proposed methods (Wacholder, Ravin, and Choi 1997) to solve this problem.</S>
    <S sid="433" ssid="13">An important issue is portability of SUMMONS to other domains.</S>
    <S sid="434" ssid="14">There are no a priori restrictions in our approach that would limit SUMMONS to template-based inputs (and hence, shallow knowledge representation schemes without recursion).</S>
    <S sid="435" ssid="15">It would be interesting to determine the actual number of different representation schemes for news in general.</S>
    <S sid="436" ssid="16">Since there exist systems that can learn extraction rules for unrestricted domains (Lehnert et al. 1993), the information extraction doesn't seem to present any fundamental bottleneck either.</S>
    <S sid="437" ssid="17">Rather the questions are: how many man-hours are required to convert to each new domain? and how many of the rules from one domain are applicable to each new domain?</S>
    <S sid="438" ssid="18">There are no clear answers to these questions.</S>
    <S sid="439" ssid="19">The library of planning operators used in SUMMONS is extensible and can be ported to other domains, although it is likely that new operators will be needed.</S>
    <S sid="440" ssid="20">In addition, new vocabulary will also be needed.</S>
    <S sid="441" ssid="21">The authors plan to perform a portability analysis and report on it in the future.</S>
    <S sid="442" ssid="22">Given that no alternative approaches to conceptual summarization of multiple articles exist, we have found it very hard to perform an adequate evaluation of the summaries generated by SUMMONS.</S>
    <S sid="443" ssid="23">We consider several potential evaluations: qualitative (user satisfaction and readability) and task-based.</S>
    <S sid="444" ssid="24">In a task-based evaluation, one set of judges would have access to the full set of articles, while another set of evaluators would have the summaries generated by SUMMONS.</S>
    <S sid="445" ssid="25">The task would involve decision making (e.g., deciding whether the same organization has been involved in multiple incidents).</S>
    <S sid="446" ssid="26">The time for decision making will be plotted against the accuracy of the answers provided by the judges from the two sets.</S>
    <S sid="447" ssid="27">A third set of judges might have access to summaries generated by summarizers based on sentence extraction from multiple documents.</S>
    <S sid="448" ssid="28">Similar evaluation techniques have been proposed for singledocument summarizers (Jing et al. 1998).</S>
  </SECTION>
  <SECTION title="7." number="8">
    <S sid="449" ssid="1">The prototype system that we have developed serves as the springboard for research in a variety of directions.</S>
    <S sid="450" ssid="2">First and foremost is the need to use statistical techniques to increase the robustness and vocabulary of the system.</S>
    <S sid="451" ssid="3">Since we were looking for phrasings that mark summarization in a full article that includes other material as well, for a first pass we found it necessary to do a manual analysis in order to determine which phrases were used for summarization.</S>
    <S sid="452" ssid="4">In other words, we knew of no automatic way of identifying summary phrases.</S>
    <S sid="453" ssid="5">However, having an initial seed set of summary phrases might allow us to automate a second pass analysis of the corpus by looking for variant patterns of the ones we have found.</S>
    <S sid="454" ssid="6">By using automated, statistical techniques to find additional phrases, we could increase the size of the lexicon and use the additional phrases to identify new summarization strategies to add to our stock of operators.</S>
    <S sid="455" ssid="7">Our summary generator could be used both for evaluating message understanding systems by using the summaries to highlight differences between systems and for identifying weaknesses in the current systems.</S>
    <S sid="456" ssid="8">We have already noted a number of drawbacks with the current output, which makes summarization more difficult, giving the generator less information to work with.</S>
    <S sid="457" ssid="9">For example, it is only sometimes indicated in the output that a reference to a person, place, or event is identical to an earlier reference; there is no connection across articles; the source of the report is not included.</S>
    <S sid="458" ssid="10">Finally, the structure of the template representation is somewhat shallow, being closer to a database record than a knowledge representation.</S>
    <S sid="459" ssid="11">This means that the generator's knowledge of different features of the event and relations between them is somewhat shallow.</S>
    <S sid="460" ssid="12">One of the more important current goals is to increase coverage of the system by providing interfaces to a large number of on-line sources of news.</S>
    <S sid="461" ssid="13">We would ideally want to build a comprehensive and shareable database of profiles that can be queried over the World-Wide Web.</S>
    <S sid="462" ssid="14">The database will have a defined interface that will allow for systems such as SUMMONS to connect to it.</S>
    <S sid="463" ssid="15">Another goal of our research is the generation of evolving summaries that continuously update the user on a given topic of interest.</S>
    <S sid="464" ssid="16">In that case, the system will have a model containing all prior interaction with the user.</S>
    <S sid="465" ssid="17">To avoid repetitiveness, such a system will have to resort to using different descriptions (as well as referring expressions) to address a specific entity.'</S>
    <S sid="466" ssid="18">We will be investigating an algorithm that will select a proper ordering of multiple descriptions referring to the same person within the same discourse.</S>
    <S sid="467" ssid="19">After we collect a series of descriptions for each possible entity, we need to decide how to select among them.</S>
    <S sid="468" ssid="20">There are two scenarios.</S>
    <S sid="469" ssid="21">In the first one, we have to pick one single description from the database that best fits the summary we are generating.</S>
    <S sid="470" ssid="22">In the second scenario, the evolving summary, we have to generate a sequence of descriptions, which might possibly view the entity from different perspectives.</S>
    <S sid="471" ssid="23">We are investigating algorithms that will decide the order of generation of the different descriptions.</S>
    <S sid="472" ssid="24">Among the factors that will influence the selection and ordering of descriptions, we can note the user's interests, his knowledge of the entity, and the focus of the summary (e.g., democratic presidential candidate for Bill Clinton, versus U.S. president).</S>
    <S sid="473" ssid="25">We can also select one description over another based on how recently they have been included in the database, whether or not one of them has been used in a summary already, whether the summary is an update to an earlier summary, and whether another description from the same category has been used already.</S>
    <S sid="474" ssid="26">We have yet to decide under what circumstances a description needs to be generated at all.</S>
    <S sid="475" ssid="27">We are interested in implementing existing algorithms or designing our own that will match different instances of the same entity appearing in different syntactic forms, e.g., to establish that PLO is an alias for the Palestine Liberation Organization.</S>
    <S sid="476" ssid="28">We will investigate using co-occurrence information to match acronyms to full organization names as well as alternative spellings of the same name.</S>
    <S sid="477" ssid="29">We will also look into connecting the current interface with news available on the Internet and with an existing search engine such as Lycos, AltaVista, or Yahoo.</S>
    <S sid="478" ssid="30">We can then use the existing indices of all Web documents mentioning a given entity as a news corpus on which to perform the extraction of descriptions.</S>
  </SECTION>
  <SECTION title="8." number="9">
    <S sid="479" ssid="1">Our prototype system demonstrates the feasibility of generating briefings of a series of domain-specific news articles on the same event, highlighting changes over time as well as similarities and differences among sources and including some historical information about the participants.</S>
    <S sid="480" ssid="2">The ability to automatically provide summaries of heterogeneous material will critically help in the effective use of the Internet in order to avoid overload with information.</S>
    <S sid="481" ssid="3">We show how planning operators can be used to synthesize summary content from a set of templates, each representing a single article.</S>
    <S sid="482" ssid="4">These planning operators are empirically based, coming from analysis of existing summaries, and allow for the generation of concise briefings.</S>
    <S sid="483" ssid="5">Our framework allows for experimentation with summaries of different lengths and for the combination of multiple, independent summary operators to produce more complex summaries with added descriptions.</S>
  </SECTION>
  <SECTION title="Acknowledgments" number="10">
    <S sid="484" ssid="1">This work was partially supported by NSF grants GER-90-24069, IRI-96-19124, IRI-96-18797, and CDA-96-25374, as well as a grant from Columbia University's Strategic Initiative Fund sponsored by the Provost's Office.</S>
    <S sid="485" ssid="2">The authors are grateful to the following people for their invaluable comments during the writing of the paper and at presentations of work related to the content of the paper: Alfred Aho, Shih-Fu Chang, Eleazar Eskin, Vasileios Hatzivassiloglou, Alejandro Jaimes, Hongyan Jing, Judith Klavans, Min-Yen Kan, Carl Sable, Eric Siegel, John Smith, Nina Wacholder, Kazi Zaman as well as the anonymous reviewers and the editors of the special issue on natural language generation.</S>
  </SECTION>
</PAPER>
