Part-Of-Speech Tagging In Context
We present a new HMM tagger that exploits context on both sides of a word to be tagged, and evaluate it in both the unsupervised and supervised case.
Along the way, we present the first comprehensive comparison of unsupervised methods for part-of-speech tagging, noting that published results to date have not been comparable across corpora or lexicons.
Observing that the quality of the lexicon greatly impacts the accuracy that can be achieved by the algorithms, we present a method of HMM training that improves accuracy when training of lexical probabilities is unstable.
Finally, we show how this new tagger achieves state-of-the-art results in a supervised, non-training intensive framework.
While replicating earlier experiments, we discover that performance was highly dependent on cleaning tag dictionaries using statistics gleaned from the tokens.
We show that he expectation maximization algorithm for bi tag HMMs is efficient and quite effective for acquiring accurate POS taggers given only a lexicon (tag dictionary) and certain favorable conditions.
We observe that earlier unsupervised HMM-EM results were artificially high due to use of Optimized Lexicons, in which only frequent-enough analyses of each word were kept.
