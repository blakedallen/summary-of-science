<PAPER>
  <S sid="0" ssid="0">Effects of Adjective Orientation and Gradability on Sentence Subjectivity Vas i le ios  Hatz ivass i log lou Depar tment  o1 Computer  Sc ience Co lumbia  Un ivers i l y New York,  NY  10027 vh@cs ,  co lumbia ,  edu Janyce  M.  Wiebe Depar tment  o f  Computer  Sc ience New Mex ico  State Un ivers i ty Las  Cruces ,  NM 88003 w iebe@cs ,  nmsu.</S>
  <S sid="1" ssid="1">edu Abstract Subjectivity is a pragmatic, sentence-level feature that has important implications for texl processing applica- lions such as information exlractiou and information ic- lricwd.</S>
  <S sid="2" ssid="2">We study tile elfeels of dymunic adjectives, se- mantically oriented adjectives, and gradable ad.ieclivcs on a simple subjectivity classiiicr, and establish lhat lhcy arc strong predictors of subjectivity.</S>
  <S sid="3" ssid="3">A novel train- able mclhod thai statistically combines two indicators of gradability is presented and ewlhlalcd, complementing exisling automatic Icchniques for assigning orientation labels.</S>
  <S sid="4" ssid="4">1 I n t roduct ion In recent years, computalional tcchniqt,es for the deter- mination of &amp;:deal semantic features have been proposed and ewdualed.</S>
  <S sid="5" ssid="5">Such features include sense, register, do- main spccilicity, pragmatic restrictions on usage, scnlan- lic markcdncss, and orientation, as well as automatically ictcnlifiecl links between words (e.g., semantic rclalcd- hess, syllollynly, antonylny, and tneronymy).</S>
  <S sid="6" ssid="6">Aulomal- ically learning features of this type from hugc corpora allows the construction or augmentation of lexicons, and the assignment of scmanlic htbcls lo words and phrases in running text.</S>
  <S sid="7" ssid="7">This information in turn can bc used to help dcterlninc addilional features at the It?teal, clause, sentence, or document level.</S>
  <S sid="8" ssid="8">Tiffs paper explores lira benelits that some lexical fea- tures of adjectives offer lor the prediction of a contexlual sentence-level feature, suOjectivity.</S>
  <S sid="9" ssid="9">Subjectivity in nat- ural language re[crs to aspects of language used to ex- press opinions and ewfluations.</S>
  <S sid="10" ssid="10">The computatiomtl task addressed here is to distinguish sentences used to present opinions and other tbrms of subjectivity (suOjective sen- tences, e.g., "At several different layers, its a fascinating title") from sentences used to objectively present factual information (objective sentences, e.g., "Bell industries Inc. increased its quarterly to 10 cents from 7 cents a share").</S>
  <S sid="11" ssid="11">Much research in discourse processing has focused on task-oriented and insmmtional dialogs.</S>
  <S sid="12" ssid="12">The task ad- dressed here comes to the fore in other genres, especially news reporting and lnternet lorums, in which opinions of various agents are expressed and where subjectivity judgements couht help in recognizing inllammatory rues- sages ("llanles) and mining online sources for product reviews.</S>
  <S sid="13" ssid="13">()thor (asks for whicll subjectivity recognition is potentially very useful include infornmtion extraction and information retrieval.</S>
  <S sid="14" ssid="14">Assigning sub.icctivity labels to documents or portions of documents is an example of non-topical characteri?ation f information.</S>
  <S sid="15" ssid="15">Current in- formation extraction and rolricval lechnology focuses al- most exclusively on lhe subject matter of the documcnls.</S>
  <S sid="16" ssid="16">Yet, additiomtl components of a document inllucncc its relevance to imrlicuhu ?</S>
  <S sid="17" ssid="17">users or tasks, including, for ex- alnple, the evidential slatus el: lhc material presented, and attitudes adopted in fawn" or against a lmrticular person, event, or posilion (e.g., articles on a presidenlial cam- paign wrillen to promote a specific candidate).</S>
  <S sid="18" ssid="18">In sum- marization, subjectivity judgmcnls could be included in documcllt proiilcs to augment aulomatically produced docunacnt summaries, and to hel l) the user make rele- vance judgments when using a search engine.</S>
  <S sid="19" ssid="19">()thor work on sub.iectivity (Wicbc et al., 1999; Bruce and Wicbc, 2000) has established a positive and statisti- cally signilicant correlation with the presence of adiec- lives.</S>
  <S sid="20" ssid="20">?incc the mere presence of one or iDoic adjectives is useful for prcdicling (hat a scntcrtce is subjective we investigate ill this paper (lie cflccts of additional cxical scmanlic lcalurcs of adjectives that can be automatically learned from corpora.</S>
  <S sid="21" ssid="21">We consider two such l%atures: se- mantic orientation, which represents an ewdualivc har- acterization of a words deviation from the norm for its semantic group (e.g., beauti/ul is positively oriented, as opposed to ugly); and gradability, which characterizes a words ability to express a property in wlrying degrees.</S>
  <S sid="22" ssid="22">In lira remainder of this paper, we [irst address adjec- tive orientation in Section 2, summarizing a previously published method for automatically separating oriented adjectives into positive and negative classes.</S>
  <S sid="23" ssid="23">Then, Sec- tion 3 presents a novel method for learning gradablc ad- jectives using a largo corpus and a statistical feature com- bination naodel.</S>
  <S sid="24" ssid="24">In Section 4, we review earlier exper- iments on testing subjectivity using wuious fcatt, res as predictors, and then present comparative analyses of the effects that orientation and gradability have on our abil- ity to Inedict sentence subjectivity from adjectives.</S>
  <S sid="25" ssid="25">Wc show that both give us higher-quality features for recog- nizing st@icctive sentences, and conclude by discussing future extensions to Ibis work.</S>
  <S sid="26" ssid="26">299 Ct Number of Number of Average nnmber Ratio o1 average adjectives in links in of links for Accuracy test set (IAc~l) test set (IL~I) each adjective group frequencies 730 2,568 7.04 78.08% 1.8699 516 2,159 8.37 82.56% 1.9235 369 1,742 9.44 87.26% 1.3486 236 1,238 10.49 92.37% 1.4040 Table 1: Evaluation o1 the adjective orientation classification and labeling methods (from (Hatzivassiloglou and McK- eown, 1997)).</S>
  <S sid="27" ssid="27">2 Semantic Orientation The semantic orientation or polarity of a word indicates the direction the word deviates flom the norm for its se- mantic group or lexicalfield (Lehrer, 1974).</S>
  <S sid="28" ssid="28">It is an eval- uative characteristic (Battistella, 1990) of the meaning of the word which restricts its usage to appropriate prag- matic contexts.</S>
  <S sid="29" ssid="29">Words that encode a desirable state (e.g., beautiful, unbiased) have a positive orientation, while words that represent undesirable states have a negative orientation.</S>
  <S sid="30" ssid="30">Within tile particular syntactic lass o1 ad- jectives, orientation can be expressed as the ability of an adjective to ascribe in general a positive or negative qual- ity to the modified item, making it better or worse than a similar unmodilied item.</S>
  <S sid="31" ssid="31">Most antonymous adjectives can be contrasted on the basis of orientation (e.g., beautil)d-ugly); similarly, nearly synonymous terms are often distinguished by dill fcrent orientations (e.g., simple-siml)listic).</S>
  <S sid="32" ssid="32">While ori- entation applies to many adjectives, there are also those that have no orientation, typically as members of groups of complementary, qualitative terms (Lyons, 1977) (e.g., domestic, medical, or red).</S>
  <S sid="33" ssid="33">Since orientation is inher- ently connected with cwduative judgements, it appears to be a promising feature for predicting subjectivity.</S>
  <S sid="34" ssid="34">Hatzivassiloglou and McKeown (1997) presented a method for autonmtically assigning a + or - orientation label to adjectives known to have some semantic orien- tation.</S>
  <S sid="35" ssid="35">Their method is based on information extracted fiom conjunctions between adjectives in a large corpus I because orientation constrains the use of the words in specific contexts (e.g., compare corrupt and brutal with *corrupt but brutal), observed conjunctions of adjectives can be exploited to inler whether the conjoined words are of the same or different orientation.</S>
  <S sid="36" ssid="36">Using a shallow parser on a 21 million word corpus of Wall Street Jour- nal articles, Hatzivassiloglou and McKeown developed and trained a log-linear statistical model that predicts whether any two adjectives have the same orientation with 82% accuracy.</S>
  <S sid="37" ssid="37">The predicted links o1 same or dil L ferent orientation are automatically assigned a strength value (essentially, a confidence stimate) by tile model, and induce a graph that can be partitioned with a clus- tering algorithm into components so that all words in the same component belong to the same orientation class.</S>
  <S sid="38" ssid="38">Once the classes have been determined, flequency infor- mation is used to assign positive or negative labels to each class (there are slightly fewer positive terms, but with a significantly higher rate of occurrence than nega- tive terms).</S>
  <S sid="39" ssid="39">Hatzivassiloglou and McKeown applied their method to 1,336 (657 positive and 679 negative) adjectives which were all the oriented adjectives appearing in the corpus 20 times or more.</S>
  <S sid="40" ssid="40">Orientation labels were assigned to these adjectives by hand.</S>
  <S sid="41" ssid="41">I Subsequent validation of the initial selection and label assignment steps with indepen- dent human judges showed an agreement of 89% tor tile first step and 97% for the second step, establishing that orientation is a fairly objective semantic property.</S>
  <S sid="42" ssid="42">Be- cause the accuracy ol the method depends on the den- sity of conjunctions per adjective, Hatzivassiloglou and MeKeown tested separately their algorithm for adjectives appearing in at least 2, 3, 4, or 5 conjunctions in the co l pus; their results are shown in Table I.</S>
  <S sid="43" ssid="43">In this paper, we use the model labels assigned by hand by Hatzivassiloglou and McKeown, and tile labels automatically obtained by their method and reported in (Hatzivassiloglou and McKeown, 1997) with the follow- ing extension: An adjective that appears in k conjunc- tions will receive (possibly different) labels when ana- lyzed together with all adjectives appearing in at least 2, 3 .</S>
  <S sid="44" ssid="44">k conjunctions; since performance generally in- creases with the number of conjunctions per adjective, we select as the orientation label the one assigned by the experi,nent t,sing the highest applicable conjunctions threshold.</S>
  <S sid="45" ssid="45">Overall, we have labels for 730 adjectives 2, with a prediction accuracy of 81.51%.</S>
  <S sid="46" ssid="46">3 Gradability Gradability (or grading) (Sapir, 1944; Lyons, 1977, p. 27 I) is the semantic property that enables a word to par- ticipate in comparative constructs and to accept mod- ifying expressions that act as intensitiers or diminish- ers.</S>
  <S sid="47" ssid="47">Gradable adjectives express properties in varying degrees ot strength, relative to a norm either explicitly ISome adjectives with unclem; mnbiguous, or conlexl,-dependenl orientation were excluded.</S>
  <S sid="48" ssid="48">2Those appearing in the corpus in two conjunctions or inore, since some conjunction data nlust be left out to hain the link prediction algo- rithm.</S>
  <S sid="49" ssid="49">300 cold Unmodilied by grading words Moditied by grading words civil Unmodilied by grading words Modified by grading words Uninllected 392 20 1,296 1 Inllected for degree 18 0 0 0 litble 2: Extracted wdues of gradability indicators, i.e., frequencies of the word with or without he specitied intlection or moditication, for two adjectives, one gradable (cold) and one primarily non-gradable (civil).</S>
  <S sid="50" ssid="50">The frequencies were compt, ted liom the 1987 Wall Street Journal corpus.</S>
  <S sid="51" ssid="51">mentioned or implicitly supplied by the modilied noun (for example, asmall planet is usually much larger thart a large house; cf.</S>
  <S sid="52" ssid="52">the distinction between absolute and tel- alive adjectives made by Katz (1972, p. 254)).</S>
  <S sid="53" ssid="53">This rel- ativism in the interpetation of gradable words indicates that gradability is likely to be a good predictor ?71 subjec- tivity.</S>
  <S sid="54" ssid="54">3.1 Indicators ofgradability Most gradable words appear at least several times in a large corpt, s either in forms inflected for degree (i.e., comparative and superlative), or in tile context of grading modilicrs such as veo,.</S>
  <S sid="55" ssid="55">However, non-gradable words may also occasionally appear in such contexts or forms under exceptional circumstances.</S>
  <S sid="56" ssid="56">For example, ve O, dead can be used tk)r emphasis, and re&amp;let am~ re&amp;let (as in "her lhce became redder and redder") can be used to indicate a progression of coloring, qb distinguish be- tween truly gradablc adjectives and non-gradable adjec- tives in these exceptional contexts, we have developed a trainable log-linear statistical model that lakes into ac- count tile number of times an ad.iective has been observed in a form or context indicating gradability relative to the number of limes it has been seen in non-gradable con- texts.</S>
  <S sid="57" ssid="57">We use a shallow parser to retrieve from a large corpus tagged for part-of-speech with Churchs PARTS tagger (Church, 1988) all adjectives and their modifiers.</S>
  <S sid="58" ssid="58">Al- though the most common use of an adverb modifying an adjective is to function as an intensilier or diminisher (Quirk et al., 1985, p. 445), adverbs can also add to tile semantic ontent of the adjectival phrase instead of pro- viding a grading effect (e.g., immediately available, po- litically vuhmrable), or function as cmphasizers, adding to the force o1 tile base adjective and not lo its degree (e.g., virtually impossible; compare *re O, impossible).</S>
  <S sid="59" ssid="59">Therefore, we compiled by hand a list of 73 adverbs and noun phrases (such as a little, exceedingly, somewhat, and veo) that are fiequently used as grading moditicrs.</S>
  <S sid="60" ssid="60">The number of times each adjective appears mod ilied by a term form this list becomes a first indicator of gradabil- ity.</S>
  <S sid="61" ssid="61">To detect inflected forms o1 adjectives (which, in 15&gt; glish, always indicate gradability st, bject to the excel&gt; tions discussed earlier), we have implemented an auto- matic lnorphology analysis component.</S>
  <S sid="62" ssid="62">This program recognizes several irregular forms (e.g., good-better- best) and strips tile grading suffixes -er and -est Dora regularly inllected adjectives, producing a list of candi- date base forms that if inflected would yield tilt origi- nal adjective (e.g., bigger produces three potential forms, big, bigg, and bigge).</S>
  <S sid="63" ssid="63">The frequency of these candi- date base words is checked against ile corpus, and tile form with signilicantly higher frequency is selected.</S>
  <S sid="64" ssid="64">To guard against cases of base adjective forms that end in -er or-est (e.g., sih,er), the original word is also included alllong tile candidates.</S>
  <S sid="65" ssid="65">The total number of times this procedure is successfully applied for each adjective be- comes a second indicator of gradability.</S>
  <S sid="66" ssid="66">3.2 l )etermlnlng radabil l ty The presence or absence of each of the above two indica- tors results in a 2 x 2 frequency table IBr each adjective; examples for one gradable and one non-gradable adjec- tive are given in "lhble 2.</S>
  <S sid="67" ssid="67">"lb convert lhese four numbers to a single decision on tile gradability of tile ad.iective, we use a log-linear model.</S>
  <S sid="68" ssid="68">Ix)g-linear models (Nantnef and l)ufly, 1989) construct a linear combination (weighted sum) of the predictor wlriables 1~, i=1 and relate it to the actual response H. (in this case, 0 for non-gmdable and 1 for gradable) via the so-called logis- tic trcm,sJbrmation, 1~- I -t- eJ Maximum likelihood estimates for the coefficients fli are obtained from training samples for which the correct response H, is known, using the iterative reweighted non- linear least squares algorithm (Bates and Watts, 1988).</S>
  <S sid="69" ssid="69">This statistical model is particularly suited for model- ing variables with a "yes"-"no" (binary) value, because, unlike linear models, it captures the dependency of IFs variance on its mean (Santner and Dully, 1989).</S>
  <S sid="70" ssid="70">We normalize the counts for the two indicators of g,adability, and the cot, at otjoint occurrences of both in- tleetion and modilication by grading moditiers, by divid- ing with the total frequency of the adjective in the corpus.</S>
  <S sid="71" ssid="71">In this manner, we obtain three real-valued predictors 301 Classitied as gradable: acceptable accurate afraid aware busy careful cautious el~eap creative critical dangerous different disappointing equal fair fanfiliar far favorable formal free frequent good grand inadequate intense interesting legitimate likely positive professional reasonable rich short-term significant slow solid sophisticated sound speculative thin tight tough uucertain widespread worth Classilied as non-gradable: additional alleged alternative annual antitrust automatic ertain criminal cumulative daily deputy domestic ldcrly false linaneial first-quarter full hefty illegal institutional internal egislative long-distance military min imum monthly moral national official one-time other outstanding present prior prospective punitive regional scientific secondary sexual subsidiary taxable three-nmnth three-year total tremendous two-year unfifir unsolicited upper vohmtary white wholesale world-wide wrong Figure 1: Automatically obtained classification of a sample of 100 adjectives as gradable or not.</S>
  <S sid="72" ssid="72">Correct decisions (according to the COBU1LD-based reference model) are indicated in bold.</S>
  <S sid="73" ssid="73">,  3 for the log-linear model.</S>
  <S sid="74" ssid="74">We also con- sider a modilied model, where any adjective for which any occurrence of simultaneous inflection and modilica- tion has been detected is automatically labeled gradable; the remaining two predictors are used to classify the ad- jectives that do not fullill this condition.</S>
  <S sid="75" ssid="75">This modilica- tion is motivated by the fact that observing an adjective in such a context offers a very high likelihood o1 grad- ability.</S>
  <S sid="76" ssid="76">3.3 Experimental results We extracted from the 1987 Wall Street Journal corpus (21 million words) all adjectives with a frequency o1 300 or more; this produced a collection of 496 words.</S>
  <S sid="77" ssid="77">Grad- ability labels specifying whether each word is gradable or not were manually assigned, using tim designations of the Collins COBUILD (Collins Birmingham Univer- sity International Language Database) dictionary (Sin- clair, 1987).</S>
  <S sid="78" ssid="78">COBUILD marks each sense of each adjec- tive with one of the labels QUALIT, CLASSIF, or COLOR, corresponding to gradable, non-gradable, and color ad- jectives.</S>
  <S sid="79" ssid="79">In cases where COBUILD supplies conflicting labels for different senses of a word, we either omitted that word or, if a sense were predominant, gave it the label of that sense.</S>
  <S sid="80" ssid="80">In some cases, the word did not appear in COBUILD; these typically were descriptive compounds peci[ic to the domain (e.g., anti-takeover, over-the-coullter) and were in most cases marked as non- gradable adjectives.</S>
  <S sid="81" ssid="81">Overall, 453 of tile 496 adjeclives (91.33%) were assigned gradability labels by hand, while the remaining 53 words were discarded because they were misclassitied as adjectives by the part-ol:speech tagger (e.g., such) or because they coukt not be assigned a unique gradability label in accordance with COBUILD.</S>
  <S sid="82" ssid="82">Out of these words, 235 (51.88%) were manually classi- lied as gradable adjectives, and 218 (48.12%) were clas- silied as non-gradablc adjectives.</S>
  <S sid="83" ssid="83">Following the methodology of the preceding subsec- tion, we recovered the inflection and modilication indica- tors for these 453 adjectives, and trained both the unmod- ified and modilied log-linear models rcpcatedly, using a randomly selected subset ol 300 adjectives for training and 100 adjectives for testing.</S>
  <S sid="84" ssid="84">The entire cycle of se- lecting random test and training sets, fitting the models coefficients, making predictions, and evaluating the pre- dicted gradability labels is repeated 100 times, to ensure that the ewtluation is not affected by a lucky (or unlucky) partition of the data between training and test sets.</S>
  <S sid="85" ssid="85">This procedure yields over the 453 adjectives gradability clas- sifications with an average precision o1 93.55% and av- erage recall o1 82.24% (in terms of the gradable words reported or recovered, respectively).</S>
  <S sid="86" ssid="86">The overall accu- racy of the predicted gradability labels is 87.97%.</S>
  <S sid="87" ssid="87">These results were obtained with the modified log-linear model, which slightly ot, tperformed the model that uses all three predictors (in that case, we obtained an average precision of 93.86%, average recall ol 81.70%, and average over- all accuracy o1 87.70%).</S>
  <S sid="88" ssid="88">Figure I lists the gradability labels that were automatically assigned to one of the 100 random test sets ttsing the moditied prediction algorithm.</S>
  <S sid="89" ssid="89">We also assigned automatically labels to the entire set of 453 adjectives, using 4-fold cross-validation (repeatedly training on three-fourths of tim 453 adjectives and test- ing on the rest).</S>
  <S sid="90" ssid="90">This resulted in precision of 94.15%, recall of 82.13%, and accuracy of 88.08% for the entire adjective set.</S>
  <S sid="91" ssid="91">4 Subjectivity The main motivation for the present paper is to examine the effect that information about an adjectives semantic orientation and gradability has on its probability of oc- curring in a subjective sentence (and hence on its quality as a subjectivity predictor).</S>
  <S sid="92" ssid="92">We tirst review related work on subjectivity recognition and then present our results.</S>
  <S sid="93" ssid="93">4.1 Previous work on subjectivity recognition In work by Wiebc, Bruce, and OHara (Wiebe ct al., 1999; Bruce and Wicbe, 2000), a corpus of 1,001 sen- tences 3 of the Wall Street Journal TreeBank Corpus 3Conlpoutld sentences were manually segmented into their con- juncts, and each conjtmct treated as a scparale sentence.</S>
  <S sid="94" ssid="94">302 (Marcus et al., 1993) was nlanually annotated with sub- jeciivity chlssifications.</S>
  <S sid="95" ssid="95">Specifically, each sentence was assigned a subjective or objective classitication, accord- ing to concensus lags derived by a slalistical analysis of lhe chisses assigned by three human judges (see (Wiebe et al., 1999) for further infornmtion).</S>
  <S sid="96" ssid="96">The total nulnber of subjective sentences in lhe data is 486, and the total number of objeclive sentences i 515.</S>
  <S sid="97" ssid="97">Bruce and Wiebe (2000) performed a statistical anal- ysis of the assigned classitications, linding lhat ac(iec- tivcs are statistically signilicantly and positively corre- lated with subjective sentences in the corpus on the basis (, .</S>
  <S sid="98" ssid="98">The proba- of the log-likelihood ratio test statistic -,2 bility of a sentence being subjective, simply given din!</S>
  <S sid="99" ssid="99">there is at least one adjective in lhe sentellee, is 56%, even though there are more objective than subjective sen- lences in the corpus.</S>
  <S sid="100" ssid="100">In addition, Bruce and Wicbe iden- tiffed a type of adjective that is indicative of subjective sentences: those Quirk et al.</S>
  <S sid="101" ssid="101">(1985) term dynamic, which "denote qualities that a,e thoughl to be subjecl to con- trol by the possessor" (p. 434).</S>
  <S sid="102" ssid="102">IZxamples are "kind" and "careful".</S>
  <S sid="103" ssid="103">Bruce and Wiebe nianually applied synlactic tests to identify dynamic adjectives in hall of the corpus nlentioned above.</S>
  <S sid="104" ssid="104">We inclutle such adjectives in the anal- ysis below, to assess whether additional lexical seinantic features associated with subjectivity hel I ) improve pro- dictability.</S>
  <S sid="105" ssid="105">(1999) developed an automatic system to perform st, bjectivily lagging.</S>
  <S sid="106" ssid="106">In 10-fold cross valida- lion experiments applied to the corpus described above, a probabilislic lassilier oblaincd an average accuracy on subjectivity lagging of 72.17%, nlorc Ihan 20 perccnlage poinls higher than the baseline accuracy obtained by al- ways choosing tile nlore frcquent class.</S>
  <S sid="107" ssid="107">A binary feature is included for each of lhe lbllowing: lhe presence in lhe sentence of a plollotln, an adjective, a cardinal number, a modal other fllan will, and an adverb other than #lot.</S>
  <S sid="108" ssid="108">They also inchlded a binary feature representing whether or not the sentence begins a new lxuagraph, l:inally, a feature was included representing co-occurrence of word tokens and punciuation marks with tile sul~jective and ob- jective classilicfition.</S>
  <S sid="109" ssid="109">An analysis of the system showed that the adjective [cature was imporlant to realizing the inlprovolncnts over lllO baseline accuracy, in this ])apci, we use lhe performance of the simple adjcclive fealtue as a baseline, and identify higher quality adjeclive features based on gradability and orienlalion.</S>
  <S sid="110" ssid="110">4.2 Or ientat ion and gradabi l i ty  as subjectivity predictors: Results We measure the precision of a simple prediction method for subjectivity: a sonlence is classilicd as subjcclivc il at least one nlonlbor of a set of adjectives N occurs in 1he sontonco, alld objeclive otherwise.</S>
  <S sid="111" ssid="111">By wirying 1tlo sot (e.g., all adjeclives, only gradable adjectives, only nega- tively orienied adjectives, etc.)</S>
  <S sid="112" ssid="112">we call assess the t, seful- heSS of ihe additional knowledge for predicting subjec- livity.</S>
  <S sid="113" ssid="113">For the present study, we use tile set of all adjectives automatically identified in tile corpt, s by Wiebc et al.</S>
  <S sid="114" ssid="114">(1999) (Section 4.1 ); the set of dynamic adjectives Ill,{Inu- ally identified by Bruce and Wiebe (2000) (Section 4.1); tile set of scnmntic orientation labels assigned by Hatzi- vassiloglou and McKeown (1997), both manually and automatically with our extension described in Section 2; and the set of gradability labels, both manually and att- tomatically assigned according to the revised log-linear model of Section 3.</S>
  <S sid="115" ssid="115">We calculate restllts (shown in hi- ble 3) for each of lhese sets of all adjectives, dynamic, oriented and gradable adjectives, as well as for unions and intersections of lhose sets.</S>
  <S sid="116" ssid="116">Nole fliat these four sets have been extracted lrom comparable but different cor- pora (different years of the Wall Street Journal), therefore sometimes adjectives in one corpus may not be present in the other corpus, reducing the size of intersection sets.</S>
  <S sid="117" ssid="117">Also, for gradability, we worked with a sample set of 100 adjectives rather than all possible adjectives we could automatically calcuhtte gladabiliiy vahles for, since our goal in the present work is to measure correlations be- tween these sets and sul~jeciivity, rather than building a system for predicling subjectivity for as many ac[iectives as possible.</S>
  <S sid="118" ssid="118">In Table 3, the second cohmm identifies 8, the set of ac[iective types in question.</S>
  <S sid="119" ssid="119">The third cohimn gives the number of subjective sentences that contain one or more instances of members of S, and the fourth colunul gives lhe same ligure for ol~jective sentences.</S>
  <S sid="120" ssid="120">Therefore these two cohinuls together specify lhe coverage of tlm subjectivity indicator examined.</S>
  <S sid="121" ssid="121">The lifth cohimn gives 111c onditional probability that a sentence is subjective.</S>
  <S sid="122" ssid="122">givell that (tile of iilorc illstatices of ti/enlbcl+S of +5; ap- pears.</S>
  <S sid="123" ssid="123">This is a precishm inetrie that assesses feature quality: if inslances of &lt;"7 appear, how likely is the son- tence to be subjective?</S>
  <S sid="124" ssid="124">The last two colunuls contrast the observed conditional probability with the a priori prob- ability of subjective sentellees (i.e., chalice; sixth col- ulnn) and with the probability assigned by the baseline all-adjectives model (i.e., the lirst row in the table; sev- enth colunm).</S>
  <S sid="125" ssid="125">The nlost striking aspect of these results is lhat all sets involviug dynamic adiectives positive or negative po- larity, or gradability are better predictors of sul~jective sentenccs than the class of adjectives as a whole, lqve of the sets are at least 25 points better (LI4, LI6, L21, L23, and L24); four others are at least 20 points better (L2, L9, L13, and 1,15); and live others are at least 15 points better (L4, LI I, 1,18, L20, and 1,22).</S>
  <S sid="126" ssid="126">In most of these cases, the difference between these predictors and all adjectives i  statistically signiticant 4 fit the 5% level or less; ahnost all of these predictors offer statistically sig- nificantly better than even odds in predicting subjectivity correctly.</S>
  <S sid="127" ssid="127">In nlany cases where statistical signilicance Iwe applied achi-square l st Oll the 2 x 2 cross-classificalion able (Fleiss, 1981).</S>
  <S sid="128" ssid="128">Adjeclive Set S # Subj Sents with (s G ,5) + Dyn Adjs fq S of L5.</S>
  <S sid="129" ssid="129"># Obj Sents l(Subj Sent I Significance with (s G ,5) + (~ e S) +) Against maiority Against all adjs All Adjectives 403 321 0.56 0.0041 N/A Dynamic Adjectives 92 32 0.74 1.1989 ?</S>
  <S sid="130" ssid="130">1.0 - r  1..6369 - 10 -4 Pol+, man 138 87 0.61 0.0007 0.1546 Pol- ,  man 79 37 0.67 0.0001 0.0158 Pol+ U Pol- ,  man 197 114 0.63 6.91.91 ?</S>
  <S sid="131" ssid="131">10 -~ 0.0260 Grad, man 193 115 0.63 1.9633 ?</S>
  <S sid="132" ssid="132">10 -~ 0.0440 Not Grad, man 172 147 0.54 0.1084 0.6496 to1+, auto 121 79 0.60 0.0026 0.2537 Pol- ,  auto 61 21 0.74 1.1635 ?</S>
  <S sid="133" ssid="133">10 -~ 0.0017 PoI+ U Io1--, auto 170 95 0.64 8.5888 - 10 -~ 0.0202 Grad, auto 30 14 0.68 0.0166 0.1418 Not Grad, auto 63 51 0.55 0.2079 0.9363 51 19 0.73 0.0001 0.0081 8.0397.10 -~ Dyn Adjs 71 S of L6.</S>
  <S sid="134" ssid="134">39 8 0.83 l)yn Adjs 71 S of L I0.</S>
  <S sid="135" ssid="135">50 19 0.72 0.0002 0.0103 Dyn Adjs 71 S ofLl  I 7 2 0.78 0.1582 0.3220 Grad 71 Pol+, man 90 58 0.61 0.0070 0.2891 Grad 71 Pol-,  man 35 I6 0.69 0.0080 0.09711 Grad 71 (Pol+ U Pol-), man 119 71 0.63 0.0005 0.1000 Grad fl Pol+, auto 13 6 0.68 0.1376 0.3833 Grad n Pol-,  auto 2 0 1.00 0.4556 0.5838 Grad 71 (Pol+ U Pol-), auto 15 6 0.71 0.0636 0.2255 l)yn Adjs N S o1 L22.</S>
  <S sid="136" ssid="136">4 0 1.00 0.1203 0.2019 I)yn Adjs (1 ,_"; of L19.</S>
  <S sid="137" ssid="137">24 5 0.83 0.0006 0.0070 Key: (s G ,5)+: one or more instances of members ofS.</S>
  <S sid="138" ssid="138">Ib/+: positive polarity, l b l - :  negalive polarity.</S>
  <S sid="139" ssid="139">GtzM: gradable.</S>
  <S sid="140" ssid="140">Matt: manually identilied.</S>
  <S sid="141" ssid="141">Auto: automalically identified.</S>
  <S sid="142" ssid="142">Table 3: Subjectivity prediction results.</S>
  <S sid="143" ssid="143">4.3671.. 10 -4 could not established this is due to small counts, caused by the small size of the set of adjectives automatically labeled for gradability.</S>
  <S sid="144" ssid="144">It is also important to note that, in most cases, tile automatically-classified adjectives are comparable or better predictors of subjective sentences than the manually-assigned ones.</S>
  <S sid="145" ssid="145">Comparing tile automatically generated classes with the manually identilied ones, the positive polarity set decreases by 1 percentage point (L3 and L8), while the negative polarity set increases by 7 points (L4 and L9), and the gradable sot increases by 5 percentage points (L6 and LI 1).</S>
  <S sid="146" ssid="146">Among the intersection sets, in two cases the results are lower for tile computer- generated sets (Ll 3/LI 5 and L 14/L 16), but in tile other 4 eases, the results are higher (LI 7/L20, L 18/L21, L19/L2, L24/L23).</S>
  <S sid="147" ssid="147">Finally, the table shows that, in most cases, pro- dictability improves or at worst remains essentially tile same as additional lexical features are considered.</S>
  <S sid="148" ssid="148">For tile set of dynamic adjectives, the predictability is 74% (L2), and improves in 4 of the 6 cases in which it is in- tersected with other sets (LI4, L l6, L23, and L24).</S>
  <S sid="149" ssid="149">For the other two (L 13 and LI 5), predictability is only 1 or 2 points lower (not statistically significant).</S>
  <S sid="150" ssid="150">For the man- ually assigned polarity and gradability sets, in one case predictability is lower (L17 &lt; L6), but in the other cases it remains the same or improves.</S>
  <S sid="151" ssid="151">The results are even better for the automatically assigned polarity and grad- ability sets: predictability improves when both features are considered in all but one case, when predictability remains the same (L20 &gt; L8; L21 &gt; L9; L22 &gt; LI0; and LI 1 _&lt; L20, L21, and L22).</S>
  <S sid="152" ssid="152">5 Conclusion and Future Work This paper presents an analysis of different adjective fea- tures for predicting subjectivity, showing that tlmy are more precise than those previously used for this task.</S>
  <S sid="153" ssid="153">Wc establish that lexical semantic features uch as seman- tic orientation and gradability determine in large part the subjectivity status of sentences in which they appear.</S>
  <S sid="154" ssid="154">We also present an automatic meflmd for extracting radabil- ity values reliably, complementing earlier work on se- mantic orientation and dynamic adjectives.</S>
  <S sid="155" ssid="155">In addition to finding more precise features for auto- marie subjectivity recognition, this kind of analysis could help efforts to encode subjective features in ontologies such as those described in (Knight and Luk, 1994; Ma- hesh and Nirenburg, 1995; Hovy, 1998).</S>
  <S sid="156" ssid="156">These on- tologies are useful for many NLP tasks, such as ma- chine translation, word-sense disambiguation, and gen- eration.</S>
  <S sid="157" ssid="157">Some subjective features are included in exist- ing ontologies (for example, Mikrokosmos (Mahesh and 304 Nirenburg, 1995) includes atlitude slots).</S>
  <S sid="158" ssid="158">Our corpus- based methods could help in idenlifying more or exlend- ing their coverage.</S>
  <S sid="159" ssid="159">To be able to use automatic subjectivily recognition in texl-processing applications, good ch,cs o1 sub.iccliv- ity mttst be found.</S>
  <S sid="160" ssid="160">The features developed in lhis paper are not only good clues of subjectivity, lhey can be Men- tilied automatically from corpora (see (Hatzivassiloglou and McKeown, 1997), and Section 3 in the present pa- per).</S>
  <S sid="161" ssid="161">In fact, the results in "Iable 3 show that the pre- dictability of the automatically determined gradability and polarity sets is better than or at least comparable to the predictability of the manually determined sets.</S>
  <S sid="162" ssid="162">Thus, tile oriented and gradable adjectives in the particular ap- plication genre can be idenlified fo," use in subjectivity recognition.</S>
  <S sid="163" ssid="163">Ou, efforts in this paper are largely exploratory, aim- ing to establish correlations among tim wlrious features examined.</S>
  <S sid="164" ssid="164">In related work, we have begun to incorporale the features developed herc into systems for recognizing flames and mining reviews in lnternel forums, extend- ing subjectivity judgments froth the sentence to the doc- ument level.</S>
  <S sid="165" ssid="165">In addition, we are seeking ways lo extend the orientation and gradability methods o that individual word occurrences, rather than word lypes, are character- ized as oriented or gradable.</S>
  <S sid="166" ssid="166">We also pla n l{7 incorpo- rate the new features presented here in machine learning models for tile prediction of subjectivity (e.g., (Wiebe ct al., 1999)) and lest lheir interaclions wilh olhcr proposed features.</S>
  <S sid="167" ssid="167">Acknowledglnents This research was SUl~ported in part by the National Sci- ence Foundation under grant number IIS-9817434, and by |he Of lice of Nawtl Research under grant number N00014-95-1-0776.</S>
  <S sid="168" ssid="168">Any opinions, tindings, or recom- mendations a,e those of tile authors, and do not neces- sarily rellect the views of the above agencies.</S>
  <S sid="169" ssid="169">References I)ouglas M. Bates and 1)onald G. Watts.</S>
  <S sid="170" ssid="170">NoMi~&gt; ear Regression Analysis and its Applicatiolls.</S>
  <S sid="171" ssid="171">Wiley, New York.</S>
  <S sid="172" ssid="172">Edwin L. Battistella.</S>
  <S sid="173" ssid="173">Markedness: 7he Evahiative Siq~etwtructure qfLanguage.</S>
  <S sid="174" ssid="174">State University of New York Press, Albany, New York.</S>
  <S sid="175" ssid="175">Rebecca Bruce and ,lanyce Wiebe.</S>
  <S sid="176" ssid="176">Recognizing subjectivity: A case study of rllanual tagging.</S>
  <S sid="177" ssid="177">Natural Language E, gineering, 6(2).</S>
  <S sid="178" ssid="178">Kenneth W. Church.</S>
  <S sid="179" ssid="179">A stochastic paris p,ogranl and noun phrase parser for unrestricted text.</S>
  <S sid="180" ssid="180">In Pro- ceedings of the Second Co,ference o, Applied Natu- ral Language Processing (ANLP-88), pages 136-143, Austin, Texas, February.</S>
  <S sid="181" ssid="181">Association for Computa- tional Linguistics.</S>
  <S sid="182" ssid="182">Statistical Methods for Rates and lmportions.</S>
  <S sid="183" ssid="183">Wiley, New York, 2rid edition.</S>
  <S sid="184" ssid="184">Vasileios Hatzivassiloglou and Kathlcen R. McKeown.</S>
  <S sid="185" ssid="185">Predicting tile semantic orientation of adjec- tives.</S>
  <S sid="186" ssid="186">In Pmeeedi,gs o[ the 35th Annual Meeting q/ the ACL and the 8th Col!/erence o/ rite Europeall Ch(q)ter of the ACL, pages 174-181, Madrid, Spain, July.</S>
  <S sid="187" ssid="187">Association re," Computational Linguistics.</S>
  <S sid="188" ssid="188">Combining and slandardizing large-scale practical ontologies for machine lransla- lion and other uses.</S>
  <S sid="189" ssid="189">In Proceedings of the 1st Interna- tional Conference on Language Resources and Evaht- alien (LREC), Granada, Spain.</S>
  <S sid="190" ssid="190">Jerrold J. Kalz.</S>
  <S sid="191" ssid="191">Sema,tic Theory.</S>
  <S sid="192" ssid="192">Harper and Row, New York.</S>
  <S sid="193" ssid="193">Kevin Knight and Steve K. Luk.</S>
  <S sid="194" ssid="194">Building a large- scale knowledge base liw machine hanslation.</S>
  <S sid="195" ssid="195">Ill Pro- ceedi,gs o[" the 12th Natio,al Co,ference o, Artifi- cial l,telli,q,e, ce (AAAI-94), w)lume 1, pages 773-778, Sealtlc, Washinglon, July-Augt, st. American Associ- ation for Artificial Intelligence.</S>
  <S sid="196" ssid="196">Adrienne Lehrer.</S>
  <S sid="197" ssid="197">Sema, tic l,}elds and Lexical Structztre.</S>
  <S sid="198" ssid="198">North Holland, Amster&amp;tm and New York.</S>
  <S sid="199" ssid="199">Sema,tics, volume 1.</S>
  <S sid="200" ssid="200">Cambridge University Press, Cambridge, England.</S>
  <S sid="201" ssid="201">K. Mahesh and S. Nirenburg.</S>
  <S sid="202" ssid="202">A siluated ontol- ogy for practical NLP.</S>
  <S sid="203" ssid="203">In Pmceedi,gs of the Work- shol~ oil Basic Ontological Issues in Knowledge Shar- ing, 14th lntenmtio,al.loi, t Co,ference oil Artificial Intelligence (LICAI-95), MontrEal, Canada, Augusl.</S>
  <S sid="204" ssid="204">Milchell E /Vlarcus, Beatrice Santorini, and Mary Ann Marcinkiewicz.</S>
  <S sid="205" ssid="205">Building a large aunotaled cor- pus of Fmglish: the Penn Treebank.</S>
  <S sid="206" ssid="206">Coml;tttatioltal Lin,~?uistics, 19(2):313-330, June.</S>
  <S sid="207" ssid="207">I~tandolph Quirk, Sidney Grecnbaum, Geoffrey l,eech, alld Jall Svartvik.</S>
  <S sid="208" ssid="208">A Complvhe,sive Grammar elthe English l.cmguage.</S>
  <S sid="209" ssid="209">Longman, London and New York.</S>
  <S sid="210" ssid="210">Sanlner and Diane E. l)uffy.</S>
  <S sid="211" ssid="211">The Statis- tical Analysis of Discrete Data.</S>
  <S sid="212" ssid="212">Springer-Verlag, New York.</S>
  <S sid="213" ssid="213">()n grading: A study ill semantics.</S>
  <S sid="214" ssid="214">l~hilosol;hy qfScie,ce, 2:93-116.</S>
  <S sid="215" ssid="215">Reprinted in (Sapir, 1949).</S>
  <S sid="216" ssid="216">Selected Wiqtings i, Language, Culture and Personality.</S>
  <S sid="217" ssid="217">University of California Press, Be,keley, California.</S>
  <S sid="218" ssid="218">Edited by David G. Mat&gt; delbat, m. John M. Sinclair (editor in chiet).</S>
  <S sid="219" ssid="219">Collins COBU1LD English Language Dictionary.</S>
  <S sid="220" ssid="220">Collins, London.</S>
  <S sid="221" ssid="221">J. Wiebe, R. Bruce, and T. OHara.</S>
  <S sid="222" ssid="222">Develop- ment and use of a gold standard ata set for subjec- tivity classilieations.</S>
  <S sid="223" ssid="223">In Proceedings of tile 37th An- total Meeting of the Association for Computational Li,guistics (ACL-99), pages 246-253, Universily of Maryhmd, June.</S>
</PAPER>
