{"id": "http://arxiv.org/abs/math/0205093v1", "guidislink": true, "updated": "2002-05-09T09:58:00Z", "updated_parsed": [2002, 5, 9, 9, 58, 0, 3, 129, 0], "published": "2002-05-09T09:58:00Z", "published_parsed": [2002, 5, 9, 9, 58, 0, 3, 129, 0], "title": "Poisson Process Partition Calculus with applications to Exchangeable\n  models and Bayesian Nonparametrics", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0205046%2Cmath%2F0205062%2Cmath%2F0205135%2Cmath%2F0205300%2Cmath%2F0205293%2Cmath%2F0205017%2Cmath%2F0205093%2Cmath%2F0205231%2Cmath%2F0205331%2Cmath%2F0205027%2Cmath%2F0205180%2Cmath%2F0205161%2Cmath%2F0205058%2Cmath%2F0205143%2Cmath%2F0205090%2Cmath%2F0205308%2Cmath%2F0205001%2Cmath%2F0205280%2Cmath%2F0205281%2Cmath%2F0205023%2Cmath%2F0205041%2Cmath%2F0205045%2Cmath%2F0205230%2Cmath%2F0205269%2Cmath%2F0205109%2Cmath%2F0205221%2Cmath%2F0205278%2Cmath%2F0205138%2Cmath%2F0205332%2Cmath%2F0205106%2Cmath%2F0205173%2Cmath%2F0205322%2Cmath%2F0205206%2Cmath%2F0205113%2Cmath%2F0205319%2Cmath%2F0205329%2Cmath%2F0205186%2Cmath%2F0205047%2Cmath%2F0205130%2Cmath%2F0205240%2Cmath%2F0205052%2Cmath%2F0205298%2Cmath%2F0205242%2Cmath%2F0205042%2Cmath%2F0205315%2Cmath%2F0205214%2Cmath%2F0205134%2Cmath%2F0205246%2Cmath%2F0205227%2Cmath%2F0205006%2Cmath%2F0205123%2Cmath%2F0205220%2Cmath%2F0205044%2Cmath%2F0205038%2Cmath%2F0205015%2Cmath%2F0205144%2Cmath%2F0205215%2Cmath%2F0205222%2Cmath%2F0205297%2Cmath%2F0205158%2Cmath%2F0205255%2Cmath%2F0205131%2Cmath%2F0205284%2Cmath%2F0205321%2Cmath%2F0205177%2Cmath%2F0205166%2Cmath%2F0205098%2Cmath%2F0205054%2Cmath%2F0205034%2Cmath%2F0205273%2Cmath%2F0205307%2Cmath%2F0205224%2Cmath%2F0205266%2Cmath%2F0205314%2Cmath%2F0205226%2Cmath%2F0205236%2Cmath%2F0205290%2Cmath%2F0205151%2Cmath%2F0205336%2Cmath%2F0205127%2Cmath%2F0205235%2Cmath%2F0205184%2Cmath%2F0205210%2Cmath%2F0205126%2Cmath%2F0205035%2Cmath%2F0205250%2Cmath%2F0205024%2Cmath%2F0205049%2Cmath%2F0205051%2Cmath%2F0205142%2Cmath%2F0205233%2Cmath%2F0205059%2Cmath%2F0205108%2Cmath%2F0205003%2Cmath%2F0205119%2Cmath%2F0205234%2Cmath%2F0205275%2Cmath%2F0205037%2Cmath%2F0205089%2Cmath%2F0205252%2Cmath%2F0205261&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Poisson Process Partition Calculus with applications to Exchangeable\n  models and Bayesian Nonparametrics"}, "summary": "This article discusses the usage of a partiton based Fubini calculus for\nPoisson processes. The approach is an amplification of Bayesian techniques\ndeveloped in Lo and Weng for gamma/Dirichlet processes. Applications to models\nare considered which all fall within an inhomogeneous spatial extension of the\nsize biased framework used in Perman, Pitman and Yor. Among some of the\nresults; an explicit partition based calculus is then developed for such\nmodels, which also includes a series of important exponential change of measure\nformula. These results are applied to obtain results for Levy-Cox models,\nidentities related to the two-parameter Poisson-Dirichlet process and other\nprocesses, generalisations of the Markov-Krein correspondence, calculus for\nextended Neutral to the Right processes, among other things.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0205046%2Cmath%2F0205062%2Cmath%2F0205135%2Cmath%2F0205300%2Cmath%2F0205293%2Cmath%2F0205017%2Cmath%2F0205093%2Cmath%2F0205231%2Cmath%2F0205331%2Cmath%2F0205027%2Cmath%2F0205180%2Cmath%2F0205161%2Cmath%2F0205058%2Cmath%2F0205143%2Cmath%2F0205090%2Cmath%2F0205308%2Cmath%2F0205001%2Cmath%2F0205280%2Cmath%2F0205281%2Cmath%2F0205023%2Cmath%2F0205041%2Cmath%2F0205045%2Cmath%2F0205230%2Cmath%2F0205269%2Cmath%2F0205109%2Cmath%2F0205221%2Cmath%2F0205278%2Cmath%2F0205138%2Cmath%2F0205332%2Cmath%2F0205106%2Cmath%2F0205173%2Cmath%2F0205322%2Cmath%2F0205206%2Cmath%2F0205113%2Cmath%2F0205319%2Cmath%2F0205329%2Cmath%2F0205186%2Cmath%2F0205047%2Cmath%2F0205130%2Cmath%2F0205240%2Cmath%2F0205052%2Cmath%2F0205298%2Cmath%2F0205242%2Cmath%2F0205042%2Cmath%2F0205315%2Cmath%2F0205214%2Cmath%2F0205134%2Cmath%2F0205246%2Cmath%2F0205227%2Cmath%2F0205006%2Cmath%2F0205123%2Cmath%2F0205220%2Cmath%2F0205044%2Cmath%2F0205038%2Cmath%2F0205015%2Cmath%2F0205144%2Cmath%2F0205215%2Cmath%2F0205222%2Cmath%2F0205297%2Cmath%2F0205158%2Cmath%2F0205255%2Cmath%2F0205131%2Cmath%2F0205284%2Cmath%2F0205321%2Cmath%2F0205177%2Cmath%2F0205166%2Cmath%2F0205098%2Cmath%2F0205054%2Cmath%2F0205034%2Cmath%2F0205273%2Cmath%2F0205307%2Cmath%2F0205224%2Cmath%2F0205266%2Cmath%2F0205314%2Cmath%2F0205226%2Cmath%2F0205236%2Cmath%2F0205290%2Cmath%2F0205151%2Cmath%2F0205336%2Cmath%2F0205127%2Cmath%2F0205235%2Cmath%2F0205184%2Cmath%2F0205210%2Cmath%2F0205126%2Cmath%2F0205035%2Cmath%2F0205250%2Cmath%2F0205024%2Cmath%2F0205049%2Cmath%2F0205051%2Cmath%2F0205142%2Cmath%2F0205233%2Cmath%2F0205059%2Cmath%2F0205108%2Cmath%2F0205003%2Cmath%2F0205119%2Cmath%2F0205234%2Cmath%2F0205275%2Cmath%2F0205037%2Cmath%2F0205089%2Cmath%2F0205252%2Cmath%2F0205261&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This article discusses the usage of a partiton based Fubini calculus for\nPoisson processes. The approach is an amplification of Bayesian techniques\ndeveloped in Lo and Weng for gamma/Dirichlet processes. Applications to models\nare considered which all fall within an inhomogeneous spatial extension of the\nsize biased framework used in Perman, Pitman and Yor. Among some of the\nresults; an explicit partition based calculus is then developed for such\nmodels, which also includes a series of important exponential change of measure\nformula. These results are applied to obtain results for Levy-Cox models,\nidentities related to the two-parameter Poisson-Dirichlet process and other\nprocesses, generalisations of the Markov-Krein correspondence, calculus for\nextended Neutral to the Right processes, among other things."}, "authors": ["Lancelot F. James"], "author_detail": {"name": "Lancelot F. James"}, "author": "Lancelot F. James", "arxiv_comment": "54 pages", "links": [{"href": "http://arxiv.org/abs/math/0205093v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0205093v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60G57; 60G09", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0205093v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0205093v1", "journal_reference": null, "doi": null, "fulltext": "Poisson Process Partition Calculus with applications to\nExchangeable models and Bayesian Nonparametrics.\n\narXiv:math/0205093v1 [math.PR] 9 May 2002\n\nLancelot F. James1\nThe Hong Kong University of Science and Technology\n(May 29, 2018)\nThis article discusses the usage of a partiton based Fubini calculus for Poisson processes. The approach is an\namplification of Bayesian techniques developed in Lo and Weng for gamma/Dirichlet processes. Applications to\nmodels are considered which all fall within an inhomogeneous spatial extension of the size biased framework used\nin Perman, Pitman and Yor. Among some of the results; an explicit partition based calculus is then developed\nfor such models, which also includes a series of important exponential change of measure formula. These results\nare then applied to solve the mostly unknown calculus for spatial L\u00e9vy-Cox moving average models. The analysis\nthen proceeds to exploit a structural feature of a scaling operation which arises in Brownian excursion theory.\nFrom this a series of new mixture representations and posterior characterizations for large classes of random\nmeasures, including probability measures, are given. These results are applied to yield new results/identities\nrelated to the large class of two-parameter Poisson-Dirichlet models. The results also yields easily perhaps the\nmost general and certainly quite informative characterizations of extensions of the Markov-Krein correspondence\nexhibited by the linear functionals of Dirichlet processes. This article then defines a natural extension of Doksum's\nNeutral to the Right priors (NTR) to a spatial setting. NTR models are practically synonymous with exponential\nfunctions of subordinators and arise in Bayesian non-parametric survival models. It is shown that manipulation of\nthe exponential formulae makes what has been otherwise formidable analysis transparent. Additional interesting\nresults related to the Dirichlet process and other measures are developed. Based on practical considerations,\ncomputational procedures which are extensions of the Chinese restaurant process are also developed.\n\nContents\n1 Introduction\n1.1 Basic principles and motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2 Notation and preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n2\n3\n5\n\n2 Poisson Process Partition Calculus\n2.1 Basic tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2 Supporting results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3 Chinese restaurant like approximation methods . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n7\n7\n9\n11\n\n3 Size-biased generalizations of completely random measures\n3.1 Disintegrations and posterior distributions . . . . . . . . . . . . . . . .\n3.2 Cumulants and moment representations . . . . . . . . . . . . . . . . .\n3.3 Updating and moment formulae . . . . . . . . . . . . . . . . . . . . . .\n3.4 A simple proof for the almost sure discreteness of size-biased measures\n\n13\n14\n16\n18\n20\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n1\nAMS 2000 subject classifications. Primary 62G05; secondary 62F15.\nKeywords and phrases. Bayesian Nonparametrics, Brownian excursions, Chinese restaurant process, exchangeable partition\nprobability functions, inhomogeneous Poisson process, L\u00e9vy-Cox models, multiplicative intensity models, Neutral to the right\nprocesses, generalised gamma processes, two-parameter Poisson-Dirichlet\n\n\f2\n\nPoisson Process Calculus\n\n4 Intensity rate mixture models, L\u00e9vy moving averages and shot-noise processes\n21\n4.1 Posterior characterizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.2 Simulating the posterior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n5 Analysis of a Scaling operation which arises in Brownian Excursion\n5.1 Mixture representations for general processes . . . . . . . . . . . . . . .\n5.2 Duality of mixture representations and posterior distributions . . . . . .\n5.3 Results for P D(\u03b1, \u03b8) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5.3.1 Distributional properties of PD\u03b1,\u03b8 (d\u03bc|\u03b7) . . . . . . . . . . . . . .\n5.3.2 Identities for P D(\u03b1, \u03b8) . . . . . . . . . . . . . . . . . . . . . . . .\n5.4 Results for the Dirichlet Process and generalised gamma process . . . .\n\ntheory\n. . . . .\n. . . . .\n. . . . .\n. . . . .\n. . . . .\n. . . . .\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n24\n27\n30\n32\n32\n33\n35\n\n6 Distributions of joint linear functionals of P; variations of the Markov-Moment problem 37\n6.1 Joint Cauchy-Stieltjes transforms and Laplace functionals . . . . . . . . . . . . . . . . . . . . 37\n6.2 A remark on moment calculations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n7 Posterior Calculus for Extended Neutral to the Right processes\n39\n7.1 Definition of Extended NTR processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n7.2 Posterior distributions and moment formulae . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n7.3 Absolute continuity of general Beta,Beta-Neutral/Stacy models to a canonical Beta processs\nor Dirichlet process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n8 Posterior Distributions of Normalised processes and Poisson-Kingman models\n47\n8.1 Posterior characterizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n8.2 Mixture models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n\n1\n\nIntroduction\n\nThis paper discusses the active usage of a Poisson process partition based Fubini calculus to solve a variety\nof problems. That is, a method which will be used to solve problems associated with large classes of random\npartitions p := {C1 , . . . , Cn(p) } of the integers {1, . . . , n}. The method is based on the formal statement\nof two results, which are known in various levels of generality, concerning a Laplace functional change of\nmeasure and a partition based Fubini representation. In terms of technique, this is an amplification of the\nmethods discussed in Lo and Weng (1989)[see also Lo (1984)] for a class of Bayesian nonparametric weighted\ngamma process mixture models. The idea to choose a Poisson process framework was based on suggestions\nfrom Jim Pitman. The utility of the approach is demonstrated by its application to a suite of problems\nwhich are within the general size-biased framework of Pitman, Perman and Yor (1992, Section 4), with\nnow a spatial inhomogeneous component. Methodologically this article may be viewed as a treatment of\ncombinatorial stochastic processes from a Bayesian (infinite-dimensional calculus) technical viewpoint.\nA key role in the works of Lo (1984) and Lo and Weng (1989), is played by a partition distribution on the\nintegers {1, . . . , n} which is a variant of Ewens sampling formula [see Ewens (1972) and Antoniak (1974)] associated with the Poisson-Dirichlet partition distribution. One particular feature is that posterior quantities\nwritten with respect to a Blackwell and MacQueen (1973) urn scheme can be further simplified to calculations which amount to sums over partitions p of {1, . . . , n}. This makes p what I term a separating class.\nThe methodology discussed there amounts to a partition based Fubini calculus for Dirichlet[see Ferguson\n\n\fJames\n\n3\n\n(1973, 1974), Freedman (1963) and Fabius (1963)] and gamma processes. Pitman (1996), extends the description of the Blackwell-MacQueen sampling from the Dirichlet process to a large class of species sampling\nrandom measures. Importantly, he develops ideas surrounding the two-parameter Poisson-Dirichlet family of\ndistributions in a Bayesian context. This provides a nice bridge to related work, where the two-parameter\nfamily appears, in for instance Pitman (1995a, b, 1997a, 1999), Pitman, Perman and Yor (1992), Pitman and\nYor (1992, 1997, 2001). Those works are non-Bayesian and center around topics such as Brownian excursion\ntheory and Kingman's theory of partition structures as developed in Aldous (1985) and Pitman (1995a).\nReturning to a Bayesian setting, Ishwaran and James (2001a) recently develop the calculus for a class of\nspecies sampling mixture models analogous to and extending the model of Lo (1984), based on the work of\nPitman (1995a, 1996).\nThe interest here is to extend these ideas to other random measures, not necessarily mixture models,\nvia more general partition structures. The question of how indeed to obtain information via as yet possibly\nunknown partition structures related to classes of random measures suggests that one may need considerable\nexpertise in combinatorial calculations. Here, this issue is circumvented by usage of what is referred to as a\nPoisson Process Partition Calculus. Note that Poisson Palm calculus is employed in Pitman, Perman and\nYor (1992) and Pitman and Yor (1992). [See also Fitzsimmons, Pitman and Yor (1992)]. The intersection\nwith those results manifests itself in section 5.\nOne may infer from Lo (1984) and Lo and Weng (1989), that Bayesian infinite-dimensional calculus is a\ncalculus based on the disintegration of joint product structures on abstract spaces which exploits properties of\npartitions p or some other separating class. Examples of other separating classes, which will not be discussed,\nare the s-path models found in Brunner and Lo (1989) and the classification based methods for generalised\nDirichlet stick-breaking models discussed in Ishwaran and James (2001b). Specifically these ideas are applied\nto classes of boundedly finite random measures, say \u03bc , on complete and separable spaces[see Daley and VereJones (1986)] which are linked to Poisson random measures. I will mention early that this is not synonymous\nwith the notion of stochastic integration which suggests simply a marginalization over the infinite-dimensional\ncomponent; although these types of ideas will play a role. Here the primary interest is in the derivation and\nvarious characterizations of the joint strucuture in terms of an infinite-dimensional posterior law of \u03bc and\nits marginal components. A key aspect of disintegration of measures on Polish spaces is the availabilty of\na well defined Fubini's theorem. The notion of Bayesian models and disintegrations is made quite clear in\nLe Cam (1986, Chapter 12). The term Bayesian is meant primarily in terms of technique. The treatment\nof problems is more in line with a broader point of view such as in Kingman (1975) rather than Ferguson\n(1973). Of course I shall cover quite thoroughly models which arise in Bayesian nonparametrics. Readily\naccessible general disussions on disintegrations of measures may be found in Pollard (2001) and Kallenberg\n(1997). See also Blackwell and Maitra (1984) , Dellacherie and Meyer (1978), and Pachl (1978). Additionally,\nDaley and Vere-Jones (1988), Matthes, Kerstan and Mecke (1978) and Kallenberg (1986) provide details\nabout Fubini's theorem for random measures cast within the language of Palm calculus.\n\n1.1\n\nBasic principles and motivation\n\nFor motivation the typical but rich mixture model setup is described. Let K denote a non-negative integrable\nkernel on a complete and separable space X \u00d7 Y and let \u03bc denote a boundedly finite discrete random measure\non Y. A mixture model is defined as follows\nZ\n(1)\nf (X|\u03bc) :=\nK(X|Y )\u03bc(dY ).\nY\n\n\f4\n\nPoisson Process Calculus\n\nfor X varying in X . When \u03bc is a Dirichlet process, a two-parameter Poisson-Dirichlet process or a weighted\ngamma process then we are in the setting described earlier . When K is chosen to be a density such as a normal\nkernel and \u03bc is a probability measure then f is a random density. This presents one way to describe random\nmeasures over spaces of densities and is analogous to the idea behind classical density estimation where one\nconvolves an empirical distribution function with a kernel. A similar construct holds for random hazard rates\nwhich might be useful in models in a multiplicative intensity setting. However, the fact that the kernel may be\nspecified rather arbitrarily leads to the description of a large body of models which appear in nonparametric\nstatistics, spatial modelling and general inverse problems. Letting K(Aij , Y ) := I{Y \u2208 Ai,j } corresponds\nto partially observed models such as interval censoring,right censoring, double censoring described, from\na fequentist viewpoint, in Turnbull (1976) and Groeneboom and Wellner (1992). See Lindsay (1995) and\nGroeneboom (1996) for much more general models. As discussed in Lo (1984) and Lo and Weng(1989)\none can induce specific shapes such as the class of monotone densities or hazards via a uniform kernel or\ncompletely monotone models via mixtures of exponential kernels. In statistical terms, when \u03bc is a probability\nmeasure P , the general mixture model has an interpretation where X|Y, P is K(X|Y ) and Y |P is missing\ninformation with distribution P . In spatial statistics, Wolpert and Ickstadt (1998b) propose to specify \u03bc as\na L\u00e9vy random field where (1) may represent the intensity of a Poisson process. Brix (1999) proposes a\nclass of generalized gamma shot-noise processes which is a flexible class of such models. Such models are\nused rather than a raw L\u00e9vy-Cox process to introduce spatial dependence. The term L\u00e9vy-moving average\nprocess has been used in analogy to Gaussian moving averages where an example is a model of the form\nR\nK(x \u2212 y)\u03bc(dy) or more specifically\nZ t\n(2)\ne(s\u2212t) \u03bc(ds)\n0\n\nwhich is reminiscent of a stationary Ornstein-Uhlenbeck process. Barndorff-Nielsen and Shepard (2001)\npropose the usage of non-Gaussian Ornstein-Uhlenbeck processes which also can be viewed as a mixture\nrepresentation where \u03bc is a L\u00e9vy process. See also Le Cam (1961) for an early mathematical discussion\nof random measures and shot-noise models. While such models are indeed rich in terms of flexibility and\ndiversity in terms of applications, many questions remain open about their properties. Suppose that now\none has the joint product measure of {X1 , . . . , Xn , \u03bc}\n(3)\n\nP(d\u03bc)\n\nn Z\nY\n\ni=1\n\nK(Xi |Yi )\u03bc(dYi )\n\nY\n\nwhich arises in a variety of contexts. The quantity above represents one possible disintegration of the joint\nstrucuture {X1 , . . . , Xn , \u03bc}. Most often direct evaluation of {X1 , . . . , Xn , \u03bc} is not simple or practically\nimplementable. Stripping away the kernel K one is left with the joint product structure, {Y1 , . . . , Yn ; \u03bc}\nwhich due to versatility of an available Fubini's theorem becomes the main object of interest. That is\nknowledge of this structure reduces the problem of the mixture model above to a special case of a cadre of\npossibilities. Hence the goal is to find the following disintegration\n(4)\n\nP(d\u03bc)\n\nn\nY\n\n\u03bc(dYi ) := P(d\u03bc|Y)M\u03bc (dY1 , . . . , dYn )\n\ni=1\n\nwhere M\u03bc is a possibly sigma-finite joint moment measure of Y and P(d\u03bc|Y) can be thought of as the\nposterior distribution of \u03bc|Y. However, the result is best understood and its utility is revealed by an equivalent\n\n\fJames\n\n5\n\nstatement via Fubini's theorem,\n(5)\n\nZ\n\ng(Y, \u03bc)\n\nn\nY\n\n\u03bc(dYi )P(d\u03bc) :=\n\ni=1\n\nZ\n\ng(Y, \u03bc)P(d\u03bc|Y)M\u03bc (dY1 , . . . , dYn )\n\nfor g an integrable or positive function. As is certainly known it is sufficient to check for g specified to be\nan indicator of appropriate cylinder sets or other characterizing function. The structure M\u03bc (dY1 , . . . , dYn )\nis an urn-type structure that can be generated sequentially via conditional moment measures. If \u03bc is a\nprobability measure the notion of conditional moment measures is synonymous with the notion of Bayesian\nprediction rules. However the exchangeable urn structure becomes a bit un-wieldly and one seeks a further\ndisintegration of Y. A natural one is based on the often quite informative decomposition Y := (Y\u2217 , p) where\nY\u2217 = {Y1 , . . . , Yn(p) } are the unique random values given a random partition p of the integers {1, . . . , n}.\nIn other words the joint (sigma-finite) measure admits a disintegration in terms of a conditional measure on\nits unique values and a measure on p. Neither of which need be a proper probability measure.\nThe main point boils down to the following basic principles; suppose that a random measure \u03bc\u2217 is some\nfunction of \u03bc , i.e. \u03bc\u2217 = g(\u03bc). Then via (5) its posterior law, marginal law and partition strucuture can all be\nderived from those corresponding aspects of \u03bc. This is of course provided that one has explicit information\nabout \u03bc. The utility of such a procedure for \u03bc is then amplified by its richness. That is, a measure of how\nmany interesting processes \u03bc\u2217 can it capture. The interesting aspect of this is that the measure of richness of\n\u03bc must correspond to the simplicity of its posterior laws, marginal moment and partition strucutures, while\nstill being informative. The structures must indeed act in a way like canonical basis functions. In other words\ncomplex structures can be derived from simple ones. The Poisson random measure, N , emerges as a natural\ncandidate given its prevalence in various theories of random measures and its basic connections (via the\nPoisson random variable and Bell's number) to random partitions of the integers. Albeit there is a duality\nto an approach using combinatorial arguments, an exploitation of the Poisson random measure analogue of\n(5), with a further partition disintegration, allows one to proceed in a pure framework of disintegration of\nmeasures to directly derive many aspects of large classes of measures \u03bc.\nP\nThe notation p will be used to denote the sum over all partitions of the integers {1, . . . , n}. As is\nwell known[see Rota (1964)], this sum is equivalent to Bell's number. For papers which discuss the natural\nrelationships of the Poisson process/random variable to partitions, see for instance Constantine and Savits\n(1994), Pitman (1997b), Constantine (1999) and Di Nardo and Senato (2001). The papers by Constantine and\nSavits (1994) and Constantine (1999), and references therein, are certainly related to this one. Constantine\nand Savits (1994) discuss methods to evaluate identity/moment formulae for compound Poisson processes\nvia Faa Di Bruno's formula. Certainly one can infer from Theorem 2.1 of Constantine and Savits (1994) that\nP\nmany of the formulae here, expressed in terms of p , can be re-expressed in tems of infinite-sum notation\nrelated to Dobinski's formula or more obviously cycle notation.\n\n1.2\n\nNotation and preliminaries\n\nAgain let p = {C1 , . . . , Cn(p) } denote a partition of size n(p) of the integers {1, . . . , n}, let ej,n denote the\ncardinality of each cell Cj for j = 1, . . . , n(p). This partition structure is related to a description of general\nanalogues of a Chinese restaurant scheme to generate partitions described in terms of a sequential seating of\ncustomers[see Aldous (1985), Pitman (1996) and Kerov (1998)]. The results will be closely connected to such\na structure generated from the exchangeable partition probability function (EPPF) (partition distribution).\nSee Pitman (1995a,b, 1996) for a thorough description of the EPPF concept. Additionally, for r > 1, let\n\n\f6\n\nPoisson Process Calculus\n\npr = {C1,r , . . . , Cn(pr ),r } denote a partition of {1, 2 . . . , r}, where Ci,r denotes the current configuration of\ntable i after r customers have been seated and ei,r denotes the number of customers seated at Ci,r . The\npartition pr+1 then denotes the (updated) one step larger partition on {1, 2, . . . , r + 1}.\nNow specific notation is given for models which shall be looked at in some detail. That is, for the twoparameter Poisson-Dirichlet models and closely connected generalised gamma family of random measures.\nIn addition notation is given for a general spatial variation of the Beta process of Hjort (1990). First, we\nbriefly describe the two-parameter Poisson-Dirichlet class of models. See Pitman and Yor (1997) and Pitman\n(1996) for more details. Let (Zi ) denote a collection of iid random variables whose distribution is a diffuse\nprobability measure H and independently of (Zi ), let (Pi ) denote a collection of ranked probabilities which\nsum to one and have a two-parameter Poisson-Dirichlet distribution denoted as P D(\u03b1, \u03b8) with parameter\nvalues 0 \u2264 \u03b1 < 1 and \u03b8 > \u2212\u03b1. The corresponding random probability measure has a representation,\n(6)\n\nP\u03b1,\u03b8 (*) :=\n\n\u221e\nX\n\nPi \u03b4Zi (*).\n\ni=1\n\nThe law of P\u03b1,\u03b8 , denoted PD\u03b1,\u03b8 (dP |H) is uniquely associated with its prediction rule and exchangeable\npartition probability function (EPPF) given as,\n(7)\n\nIP{Yn+1 \u2208 * |Y1 , . . . , Yn } =\n\nn(p)\nX (ej,n \u2212 \u03b1)\n\u03b8 + n(p)\u03b1\nH(*) +\n\u03b4Yj\u2217 (*),\n\u03b8+n\n\u03b8+n\nj=1\n\nand,\n(8)\n\nP D(p|\u03b1, \u03b8) =\n\n\u0010Q\nn(p)\u22121\nj=1\n\n\u0011 \u0010Q\n\u0011\nn(p)\n(\u03b8 + \u03b1 j)\nj=1 \u0393(ej \u2212 \u03b1)\n.\nQn\u22121\nj=1 (\u03b8 + j)\n\nThe extreme cases are the normalised stable law process P\u03b1,0 and the Dirichlet process, P0,\u03b8 with shape\nparameter \u03b8H. The laws of the (Pi ) and Ewens sampling EPPF formula for the Dirichlet process are denoted\nas P D(\u03b8) and P D(p|\u03b8). Similarly for the stable process write P D(\u03b1) and P D(p|\u03b1). Now for b \u2265 0 the rich\nfamily of generalized gamma random measures [see Brix (1999)] is generated by the L\u00e9vy measure\n(9)\n\n\u03c1\u03b1,b (ds) =\n\n1\ns\u2212\u03b1\u22121 e\u2212bs ds,\n\u0393(1 \u2212 \u03b1)\n\nwhich includes the stable law subordinator, b = 0, gamma processs subordinator \u03b1 = 0, and the inverseGaussian law, \u03b1 = .5, b > 0, among others. The notation \u03c1\u03b1 := \u03c1\u03b1,0 will be reserved for the stable law and\nthe choice \u03b8\u03c10,1 will be used to generate the Dirichlet process family of models. The general subordinator\nhas increments which have a distribution belonging to an exponential family of distributions with a power\nvariance function, introduced by Tweedie (1984) and further discussed in Hougaard (1986), Bar-Lev and Enis\n(1996), and Jorgensen (1997). See K\u00fcchler and Sorensen (1997). Classes of compound Poisson process models\nbased on this distribution are discussed in Aalen (1992), Lee and Whitmore (1993) and Hougaard, Lee and\nWhitmore (1997). Lastly, a spatial version of Hjort's (1990) (two-parameter) Beta process corresponds to\nthe L\u00e9vy process generated by the inhomogeneous L\u00e9vy measure,\n(10)\n\nu\u22121 (1 \u2212 u)c(s)\u22121 duA0 (ds, dx)\n\nfor (u, s, x) \u2208 (0, 1] \u00d7 (0, \u221e) \u00d7 X . The quantity c(s) is a decreasing function on (0, \u221e) and A0 is a hazard\nmeasure. The symbols G(a, b), \u03b2(a, b) will be used to denote gamma and beta random variables respectively.\nG(dx|a, b) will denote a gamma density.\n\n\fJames\n\n7\n\nSome other references connected to the Poisson-Dirichlet family, not mentioned later, include McCloskey (1965),\nEngen (1978), Carlton (1999), Donnelly and Tavar\u00e9 (1987), Gyllenberg and Koski (2001). See the article by\nEwens and Tavar\u00e9 (1997) for a discussion of the wide applicability of the two-parameter model. See also\nPitman (1995b), which will be referenced later.\n\n2\n\nPoisson Process Partition Calculus\n\nLet N denote an inhomogeneous Poisson process (measure) on a complete and separable space X with\n(diffuse) mean measure \u03bd(*). That is, the Laplace functional of N is of the form\n\u001b\n\u001a Z\nZ\nf (x)N (dx) P(dN |\u03bd)\nexp \u2212\nLN (f |\u03bd) =\nX\nM\n\u0013\n\u0012 Z\n\u2212f (x)\n)\u03bd(dx)\n= exp \u2212 (1 \u2212 e\nX\n\nfor non-negative functions f \u2208 BM (X ) on (X , B(X )) where BM (X ) denotes the collection of measurable\nfunctions of bounded support on X . See Daley and Vere-Jones (1988) for a description of these concepts.\nFor brevity we use the shorthand notation of the type,\n\u001b\n\u001a Z\n\u2212N (f )\nf (x)N (dx) .\ne\n= exp \u2212\nX\n\nThe exposition of this paper centers around the utilization of disintegration results related to the joint\nmeasure\nn\nY\n(11)\nP(dN |\u03bd) N (dXi ),\ni=1\n\nwhere (11) represents a disintegration of the joint product measure of {X1 , . . . , Xn , N }. Moreover, the collection X={X1 , . . . , Xn } can be considered as conditionally independent given N . However importantly once\nintegration is done over N the collection X will usually consist of tied values. It follows that one can always\n\u2217\n} denotes the unique values and p dictates which variables\nrepresent X = (X\u2217 , p) where X\u2217 = {X1\u2217 , . . . , Xn(p)\n\u2217\nare equal according to the relationship Xi = Xj if and only if i \u2208 Cj . The main purpose of this section is to\ndescribe two results concerning the Poisson process which are fashioned as tools to be tailor-made to solve a\nvariety of problems in an expeditious manner.\n\n2.1\n\nBasic tools\n\nFirst an (exponential) change of measure or disintegration formulae based on Laplace functionals is given\nbelow. Such an operation is commonly called exponential tilting.\nLemma 2.1 For non-negative functions f \u2208 BM (X ) on (X , B(X )) and g on (M, B(M))\nZ\nZ\ng(N )P(dN |e\u2212f \u03bd),\ng(N )e\u2212N (f ) P(dN |\u03bd) = LN (f |\u03bd)\nM\n\nM\n\nwhere P(dN |e\n\n\u2212f\n\n\u03bd) is the law of a Poisson Process with intensity\ne\u2212f (x) \u03bd(dx).\n\nIn other words the following absolute continuity result holds,\n(12)\n\ne\u2212N (f ) P(dN |\u03bd) = LN (f |\u03bd)P(dN |e\u2212f \u03bd).\n\n\f8\n\nPoisson Process Calculus\n\nProof. By the unicity of of Laplace functionals for random measures on X it suffices to check this\nresult for the case g(N ) = e\u2212N (h) . Thus it follows that,\nZ\nZ\ne\u2212N (f +h) P(dN |\u03bd) = LN (f |\u03bd)\nM\n\ne\u2212N (h) Pf (dN )\nM\n\nwhere for the time being Pf denotes some law on N . Simple algebra shows that\nZ\nLN (f + h|\u03bd)\ne\u2212N (h) Pf (dN ) =\nLN (f |\u03bd)\nM\nand hence Pf (dN ) := P(dN |e\u2212f \u03bd) which concludes the result.\n\nremark 1. Lemma 2.1 is a simple functional extension, mod the Gaussian and drift component, of an\nanalogous result for L\u00e9vy processes on R or more generally Rd which may be found in K\u00fcchler and Sorenson\n(1997) Proposition 2.1.3. The utility of Lemma 2.1 will be demonstrated throughout. Poisson processes with\nlaws described by P(dN |e\u2212f \u03bd) can be found in Pitman and Yor (1992)[See Section 5 of this manuscript].\n\nremark 2. Naturally Lemma 2.1 extends to the following somewhat more vague generalisation; Suppose that \u03bc is a random measure with Laplace functional L\u03bc , then given the setup in Lemma 2.1 with \u03bc in\nplace of N , e\u2212\u03bc(f ) P(d\u03bc) = L\u03bc (f )Pf (d\u03bc) where Pf is characterized by its Laplace functional\nZ\nL\u03bc (f + h)\ne\u2212\u03bc(h) Pf (d\u03bc) =\n.\nL\u03bc (f )\nM\nOne can replace the argument with characteristic functionals.\nResults which identify the disintegration of (11) in terms of the posterior distribution of the Poisson\nprocess and the marginal joint measure\n#\nZ \"Y\nn\n(13)\nN (dXi ) P(dN |\u03bd)\nM (dX1 , . . . , dXn ) =\nM\n\ni=1\n\nare well known in the literature via Palm calculus for Poisson processes. The quantity M in (13) is also known\nas the joint moment measure. These existing results are customized in Lemma 2.2 below where emphasis is\nplaced on the partition structure.\nLemma 2.2 Let g be a non-negative or integrable function on X n \u00d7 M, then for each n \u2265 1,\n\uf8ee\n\uf8f9\nZ\nZ\nn(p)\nn(p)\nn\nXZ\nY\nY\nX\n\u2217\n\uf8f0\n\uf8fb\n\u2217\n(14)\n\u03bd(dXj\u2217 ),\n\u03b4Xj )P(dN |\u03bd)\ng(X , p, N +\ng(x, N ) N (dxi )P(dN |\u03bd) =\nM\u00d7X n\n\ni=1\n\np\n\nwith\n(15)\n\nZ\n\nM\n\nX n(p)\n\nM\n\nn(p)\n\u2217\n\ng(X , p, N +\n\nX\n\n\u03b4\n\nXj\u2217\n\n)P(dN |\u03bd) =\n\nj=1\n\nZ\n\ng(X\u2217 , p, N )P(dN |\u03bd, X).\n\nM\n\nj=1\n\nThe moment measure M is also expressible via the conditional moment measures as,\n\uf8ee\n\uf8f9\nn(pi\u22121 )\nn\nY\nX\n\uf8f0\u03bd(dXi ) +\n\u03b4Xj\u2217 (dXi )\uf8fb\n(16)\nM (dX) = \u03bd(dX1 )\ni=2\n\nj=1\n\nj=1\n\n\fJames\n\n9\n\nremark 3. It is of course true that Lemma 2.2 is not entirely novel. However, the partition representation that is used is certainly not readily seen in the literature. Moreover, it has been tailor made to\nassume its present purpose as a general tool. One way to deduce the partition representation is to examine\ncarefully Daley and Vere-Jones (1988),[equation (5.517), Lemma 5.2.VI, and the discussion on page 192]. A\nsimple minded but informative approach is to simply refer back to the case of Poisson random variables. For\nclarity and also to showcase what is believed to be interesting side results involving partly Lemma 2.1 we\nprove this result in its entirety in the next section using alternate means.\n\n2.2\n\nSupporting results\n\nNote that Lemma 2.1 implies the following result for each bounded set B,\n\u001b\n\u001a Z\nZ\nZ\n(17)\ne\u2212f (X) \u03bd(dx).\nf (x)N (dx) P(dN |\u03bd) = LN (f |\u03bd)\nN (B) exp \u2212\nB\n\nX\n\nM\n\nThis is reminiscent of the expression which appears in Lemma 10.6 in Kallenberg (1986) and perhaps\nmore clearly in Proposition 12.1.V in Daley and Vere-Jones (1998). That is, the expression (17) identifies\nthe conditional Laplace functional of the Poisson process given one observation[see Daley and Vere-Jones\n(1988), p. 458]. A point to note is that in contrast to Daley and Vere-Jones (1988) Proposition 12.I.V, this\nresult is not obtained by taking derivatives. This suggests that Lemma 2.1 can be used repeatedly to obtain\nthe conditional Laplace functional given n observations. Thus providing an alternative to an argument using\nrepeatedly say Lemma 12.1.V. The general dual of Lemma 12.1.V. can be deduced from Remark 2 as follows;\nSuppose that \u03bc is an random measure(as in Remark 2) with finite 1st moment measure, say m\u03bc , then\n(18)\n\nZ\n\nM\n\n\u03bc(B)e\n\n\u2212\u03bc(f )\n\nP(d\u03bc) = L\u03bc (f )\n\nZ Z\nB\n\n\u03bc(dx)Pf (d\u03bc) := L\u03bc (f )\n\nM\n\nZ\n\nr(f |x)m\u03bc (dx)\n\nB\n\nfor some function r determined by the second expression. That is, the evaluation of\nHence the conditional Laplace functional of \u03bc|x is\n\nR R\nB\n\nM\n\n\u03bc(dx)Pf (d\u03bc).\n\nL\u03bc (f |x) := L\u03bc (f )r(f |x).\nThis general form can be applied repeatedly to (conditional) random measures \u03bc|x1 , . . . , xi etc, where the\nrequirement is the existence of a finite conditional measure m\u03bc (*|x1 , . . . , xi ). All such results can be deduced\nfrom an argument similar to what is used in Proposition 2.1 below.\n\nremark 4. A result for general \u03bc is quite applicable. As an example consider finite random mixtures\nof infinitely divisible random variables. That is,\n(19)\n\nm\nX\n\nWk,m \u03b4Zk\n\nk=1\n\nwhere Wk,m are iid infinitely divisible random variables and Zk are iid random variables. Such models can\nbe used as approximations to many of the models discussed here. The emphasis on the change of measure\ninterpretation should also prove useful. In fact, for such an infinitely divisible class the results in Section 3\napply with small modification.\n\n\f10\n\nPoisson Process Calculus\n\nremark 5. James (2001a, b) using the analogue of Lemma 2.1 for weighted gamma and generalised\nweighted gamma process obtained their posterior characterizations in this manner without any specific\nmention of Poisson proceses. The idea for this approach is based on an extension of the arguments in Lo and\nWeng (1989). In Section 3 it is shown that Lemma 2.1 actually implies these analogues.\nProposition 2.1 Lemma 2.1 implies that the conditional Laplace functional of N |X1 , . . . , Xn based on the\nmodel is,\n\uf8f9\n\uf8ee\nn(p)\nY\n\u2217\ne\u2212f (Xj ) \uf8fb\n(20)\nLN (f |\u03bd) \uf8f0\nj=1\n\nProof. The result proceeds by induction. Let s, f \u2208 BM (X ) and choose g(N ) =\n\nR\n\ns(v)N (dv). The\ncase for n = 1 follows from (17). For general n = r it follows from Lemma 2.1 that the conditional Laplace\nfunctional of N given (Xr , Xr+1 ) is determined by the expression\n\uf8ee\n\uf8f9\uf8ee\n\uf8f9\nZ\nn(pr )\nn(pr )\nY\nX\n\u2217\nLN (f |\u03bd) \uf8f0\ne\u2212f (Xj ) \uf8fb \uf8f0 s(xr+1 )e\u2212f (Xr+1 ) \u03bd(dXr+1 ) +\ns(Xj\u2217 )\uf8fb\nX\n\nj=1\n\nX\n\nj=1\n\n\u2217\n} and is set to be one\nNow define a function t(Xr+1 ) to be e\u2212f (Xr+1 ) if Xr+1 is not equal to {X1\u2217 , . . . , Xn(p\nr)\notherwise. Then,\n\uf8f9\n\uf8ee\nZ\nZ\nn(pr )\nn(pr )\nX\nX\ns(Xj\u2217 ).\n\u03b4Xj\u2217 (dXr+1 )\uf8fb =\ns(xr+1 )e\u2212f (Xr+1 ) \u03bd(dXr+1 ) +\ns(xr+1 )t(Xr+1 ) \uf8f0\u03bd(dXr+1 ) +\nX\n\nX\n\nj=1\n\nj=1\n\nHence, the conditional Laplace functional is,\n\uf8f9\n\uf8f9\n\uf8ee\n\uf8ee\nn(pr+1 )\nn(pr )\nY\nY\n\u2217\n\u2217\n(21)\ne\u2212f (Xj ) \uf8fb\ne\u2212f (Xj ) \uf8fb t(Xr+1 ) = LN (f |\u03bd) \uf8f0\nLN (f |\u03bd) \uf8f0\nj=1\n\nj=1\n\nas desired.\n\nremark 6. The proof of Proposition 2.2 below follows closely an unpublished proof by Albert Y. Lo\nfor the case of gamma processes. That is, it is an alternate proof for Lemma 2 in Lo (1984) which yields\nthe appropriate partition representation for integrals with respect to a Blackwell-MacQueen urn distribution\nderived from a Dirichlet process. The style of proof exploits properties of partitions similar to those stated\nin Pitman (1995a, Proposition 10). In particular see (24) below. See also the proof of Lemma 5 in Hansen\nand Pitman (2001) for general species sampling models. Details in the proof of Proposition 2.2 translate into\ngeneralizations of a weighted Chinese restaurant algorithm given in the next section. Proposition 2.1 and 2.2\ncombine to yield Lemma 2.2.\nProposition 2.2 For i = 1, . . . , n, let gi be non-negative functions in BM (X ) then,\n\uf8ee\n\uf8f9\n#\nZ \"Y\nn Z\nX n(p)\nY\nYZ\n\u2217\n\uf8f0\ngi (xi )N (dxi ) P(dN |\u03bd) =\ngi (xj )\uf8fb \u03bd(dx\u2217j ).\n(22)\nM\n\nEquivalently, M (dX) =\n\ni=1\n\nX\n\nQn(p)\nj=1\n\np\n\n\u03bd(dXj\u2217 ).\n\nj=1\n\nX\n\ni\u2208Cj\n\n\fJames\n\n11\n\nProof. The proof of (22) proceeds by induction. Case n = 1 is obvious, Now suppose it is true for\nn = r. Let pr+1 denote a partition of {1, . . . , r + 1} , and define for each r > 0,\n\uf8ee\n\uf8f9\nn(pr ) Z\nY\nY\n\uf8f0\n\u03c6g (pr ) =\ngi (x\u2217j )\uf8fb \u03bd(dx\u2217j )\n(23)\nX\n\nj=1\n\ni\u2208Cj,r\n\nIt follows that \u03c6g (pr+1 ) is\n\n\u03c6g (pr )\n\nZ\n\ngr+1 (v)\u03bd(dv)\n\nY\n\nif n(pr+1 ) = n(pr ) + 1, otherwise if the index r+1 is in an existing cell/table Ci,r then it is equivalent to\nZ\n\u03c6g (pr )\ngr+1 (v)\u03c0g (dv|Ci,r )\nY\n\nwhere\n\ni\ng\n(v)\n\u03bd(dv)\nl\nl\u2208Ci,r\ni\n\u03c0g (dv|Ci,r ) = R hQ\ng\n(v)\n\u03bd(dv)\nl\u2208Ci,r l\nY\nhQ\n\nfor i = 1, . . . , n(pr ). Note that this implies that,\n\uf8ee\n\uf8f9\nZ\nn(pr ) Z\nX\nX\nX\n\u03c6g (pr ) \uf8f0 gr+1 (v)\u03bd(dv) +\n\u03c6g (pr+1 ) =\ngr+1 (v)\u03c0g (dv|Ci,r )\uf8fb .\n(24)\npr+1\n\nX\n\npr\n\ni=1\n\nX\n\nNow by (simple algebra) and the induction hypothesis on r it follows that,\n\uf8ee\n\uf8f9\"\n#\nZ\nZ\nn(pr )\nr\nX\nY\nX\n\u2217\n\uf8f0 gr+1 (v)\u03bd(dv) +\ngi (Xi ) M (dXr ).\ngr+1 (Xj )\uf8fb\n\u03c6g (pr+1 ) =\npr+1\n\nXn\n\nX\n\nj=1\n\ni=1\n\ni\nh\nPn(p )\nNow utilizing the fact that, M (dXr+1 ) = \u03bd(dXr+1 ) + j=1r \u03b4Xj\u2217 (dXr+1 ) M (dXr ), concludes the proof.\n\nremark 7. Of course (22) in its most basic form leads to well-known results for moments and cumulants of a Poisson random variable. For instance, setting gi to be indicators of a bounded set A yields,\nX\nn(p)\nE(N (A)n ) =\n\u03bd(A)\n.\np\n\nWhere N (A) is a Poisson random variable with mean measure \u03bd(A).\n\n2.3\n\nChinese restaurant like approximation methods\n\nIn this section a new algorithm for approximating complex integrals and in fact posterior distributions is described. This algorithm works by sequentially sampling from a partition distribution and structurally behaves\nsimilar to the Chinese restaurant process seating algorithm discussed in Aldous (1985), Pitman (1996) and\nKerov (1998). In particular, the proposed scheme is influenced by the weighted Chinese restaurant(WCR)\nprocedure developed in Lo, Brunner and Chan (1996) [see also Brunner, Chan, James and Lo (2001)] for\nmixtures of Dirichlet process and weighted gamma process posterior models. Ishwaran and James (2001a)\nsubsequently generalise the WCR to include the class of species sampling mixture models. The essence of all\nthese algorithms will be revisted in this section.\n\n\f12\n\nPoisson Process Calculus\nNotice that the left hand side of (22),\nX n(p)\nYZ\n\n(25)\n\np\n\nj=1\n\nX\n\n\uf8ee\n\uf8f0\n\nY\n\ni\u2208Cj\n\n\uf8f9\n\ngi (x\u2217j )\uf8fb \u03bd(dx\u2217j ),\n\nP\nis a function of partitions of the form, p t(p). This result is analogous to Lo (1984) where he points out\nthat complex multiple integrals with respect to a Blackwell-MacQueen urn are equivalent to considerably\nmore manageable sums over partitions. However, it is known that the compexity of the number of partitions\nbehaves like Bell's number as n increases and hence one needs some method to approximate such quantities.\nIn order to further illustrate a connection to a Chinese restaurant we introduce the following expressions;\n\uf8ee\n\uf8f9\nn(p) Z\nn(p)\nY\nY\nX\nY\n\uf8f0\n\u0393(ej \u2212 \u03b1)\nK(Xi |Yj\u2217 )\uf8fb \u03b7(dYj\u2217 ),\n(26)\n\u03b8n(p)\nj=1\n\nj=1\n\np\n\nand\n\n(27)\n\nX\n\nP D(p|\u03b1, \u03b8)\n\nn(p) Z\n\nY\n\nj=1\n\np\n\nY\n\n\uf8ee\n\uf8f0\n\nY\n\nY\n\ni\u2208Cj\n\ni\u2208Cj\n\n\uf8f9\n\nK(Xi |Yj\u2217 )\uf8fb H(dYj\u2217 ).\n\nThe expressions above may arise respectively from a generalized gamma mixture model and a two-parameter\nPoisson-Dirichlet process mixture model. The first expresssion (26) appears in James (2001b) and reduces\nto an expression for the gamma process in Lo and Weng (1989) and James (2001a). The latter expression\nappears in Ishwaran and James (2001a) and extends the analogous result for the the Dirichlet process in\nLo (1984). That is, the latter corresponds to the marginal likelihood of X|Y when Y1 , . . . , Yn |P are iid P ,\nthe law of P is P\u03b1,\u03b8 (dP |H). Allowing for more flexibility in the interpretation of gi and \u03bd these terms can\nbe written as special cases of (25). Consequently, an understanding of the mechanism behind the WCR\nalgorithm as outlined in Brunner, Chan and Lo (1996) translates into a general algorithm which is now\ndescribed. From (24) set\n\uf8ee\n\uf8f9\nZ\nn(pr ) Z\nX\nl(r) = \uf8f0 gr+1 (v)\u03bd(dx) +\ngr+1 (x)\u03c0g (dx|Ci,r )\uf8fb .\n(28)\nX\n\nX\n\ni=1\n\nThe procedure relies on a method to generate partitions p based on the following rule, described in terms of\ncustomers entering a restaurant,\nAlgorithm 1 Step 1: Seat the first customer to a table with probability l(0)/l(0) = 1.\nStep (r + 1): Given pr , customer r + 1 sits at table Cj,r with probability\nZ\n\u22121\nIP(pr+1 |pr ) = l(r)\ngr+1 (x)\u03c0g (dx|Cj,r ),\nX\n\nwhere pr+1 = pr \u222a {r + 1 \u2208 Ci,r } for i = 1, . . . , n(pr ). Otherwise, customer r + 1 sits at a new table\nwith probability\nZ\nIP(pr+1 |pr ) = l(r)\u22121\n\ngr+1 (x)\u03bd(dx).\n\nX\n\nThe completion of Step n produces a p = {C1 , . . . , Cn(p) } = pn , where now p is drawn from a density\nq(p|g) whose form is described in the Lemma 2.3.\n\n\fJames\n\n13\n\nLemma 2.3 The n-step seating algorithm results in a partition p drawn from a density/distribution given\nby q(p|g) that satisfies,\n\uf8ee\n\uf8f9\nn(p) Z\nY\nY\n\uf8f0\nI(p|g)q(p|g) =\ngi (Xj\u2217 )\uf8fb \u03bd(dXj\u2217 ),\nj=1\n\nwhere I(p|g) =\n\nQn\n\nr=1 l(r\n\nX\n\ni\u2208Cj\n\n\u2212 1).\n\nProof. As in the proof of Proposition 2.2, define \u03c6g (pr ) from (23). Now note carefully that,\n\u03c6g (pr )\u03c0g (dXj\u2217 |Cj,r ) = \u03bd(dXj\u2217 )\n\nY\n\ngi (Xj\u2217 ) \u00d7\n\ni\u2208Cj,r\n\nYZ\nl6=j\n\nY\n\ngi (u)\u03bd(du).\n\ni\u2208Cl,r\n\nHence it follows that if pr+1 = pr \u222a {r + 1 \u2208 Cj,r }, then\n(29)\n\nZ\n\ngr+1 (u)\u03c0g (du|Cj,r ) =\n\n\u03c6g (pr+1 )\n\u03c6g (pr )\n\nand IP(pr+1 |pr ) =\n\n\u03c6g (pr+1 )\n.\nl(r)\u03c6g (pr )\n\nA similar argument for pr+1 forming a new table shows that (29) holds in general. Now notice that since\npr+1 contains all the information in pr , the product rule of probability gives\nq(pn |g) = IP(p1 )\n\nn\u22121\nY\nr=1\n\nIP(pr+1 |pr ) =\n\n\u03c6g (pn )\n,\nI(p|g)\n\nwhere IP(p1 ) = \u03c6g (p1 )/l(0) = 1. Now setting p = pn yields the desired result.\nNow to approximate terms such as (25), draw an iid sample, say p(1) , . . . , p(B) , of size B from q(p|g) and\nPB\nuse B \u22121 b=1 I(p(b) |g). The Chinese restaurant algorithm to generate a draw from P D(p|\u03b1, \u03b8) is recovered\nR\nR\nby setting l(r) = \u03b8 + r, X gr+1 (x)\u03bd(dx) := \u03b8 + n(pr )\u03b1, and X gr+1 (x)\u03c0g (dx|Ci,r ) := ei,r \u2212 \u03b1. In other words\nunder this specification q(p|g) = P D(p|\u03b1, \u03b8).\n\nremark 8. The algorithm above is an example of a sequential importance sampling procedure. The\nefficient Dirichlet process algorithm discussed in MachEachern, Clyde and Liu (1999) can be seen as a special\ncase of the WCR when using a binomial kernel. The Chinese restaurant process structure however is not\nemphasized in that work. There are also analogous MCMC methods which can now readily be deduced from\nthe descriptions given in Brunner, Chan, and Lo (1996) or Ishwaran and James (2001a). See Ishwaran and\nJames (2001b) and Ishwaran, James and Sun (2001) for applications and ideas for other algorithms.\n\n3\n\nSize-biased generalizations of completely random measures\n\nIn this section it is shown how specific applications of Lemma 2.1 and 2.2 yield explicit disintegration results\nfor a class of random measures which includes completely random measures. One feature of the analysis\nreveals that cumulants assume in many respects the role played by the EPPF in posterior calculus for\nrandom probability measures. The present construction is influenced by section 4 of Pitman, Perman and\nYor (1992). The results will be applied throughout.\n\n\f14\n\nPoisson Process Calculus\n\nLet N denote a Poisson process on an arbitrary Polish space X = S \u00d7 Y with intensity \u03bd(ds, dy) =\n\u03c1(ds|y)\u03b7(dy) for \u03c1 a L\u00e9vy measure on the Polish space S depending on y in a fairly arbitrary way and \u03b7 a\nsigma-finite (non-atomic) measure on Y. Denote the law of N as P(dN |\u03c1, \u03b7). As in Pitman, Perman and Yor\n(1992, section 4) let h denote an arbitrary strictly positive function on S. Furthermore it is assumed that\nh, \u03c1, \u03b7 are selected such that for each bounded set B in Y,\nZ Z\n(30)\nmin (h(s), 1)\u03c1(ds|y)\u03b7(dy) < \u221e.\nB\n\nS\n\nNow define a random measure \u03bc on Y such that it may be represented in a distributional sense as,\nZ\n(31)\n\u03bc(dy) =\nh(s)N (ds, dy).\nS\n\nThe law of \u03bc is denoted as P(d\u03bc|\u03c1, \u03b7). When \u03c1 does not depend on y, then write \u03c1(ds|y) := \u03c1(ds). Similar\nto Tsilevich, Vershik and Yor (2001) the term homogeneous will sometimes be applied to this special case of\n\u03c1 and \u03bc. In the case that S = (0, \u221e) and h(s) := s then following Kingman (1967, 1993) \u03bc is a completely\nrandom measure without a deterministic component.\n\nremark 9. Related to completely random measures, Ferguson and Klass (1972) discuss constructions\nfor the class of L\u00e9vy processes on (0, \u221e) without a Gaussian component but allowing for fixed points of\ndiscontinuity. See also Wolpert and Ickstadt (1998a,b), Brix (1999) for recent applications of completely\nrandom measures to spatial statistics. The condition (30) gaurantees that \u03bc in (31) is a boundedly finite\nmeasure in the language of Daley and Vere-Jones (1988, Definition 6.1.I.). Theorem 6.3.VIII of that work\ndiscusses the representation of completely random measures. Kallenberg (1997, chapter 10) describes conditions under which Poisson functionals are finite. Certain aspects of the presentation below are of course\nimplicit in Kallenberg (1986).\nThe Laplace functional for \u03bc can be represented as follows\n\u0013\n\u0012 Z Z\n\u2212g(y)h(s)\n(32)\n(1 \u2212 e\n)\u03c1(ds|y)\u03b7(dy) .\nL\u03bc (g) = exp \u2212\nY\n\nS\n\nAs in Pitman, Perman and Yor (1992) the notation T := \u03bc(Y) will be used to denote an almost surely\nfinite total mass.\n\n3.1\n\nDisintegrations and posterior distributions\n\nDefine, the following moments with respect to the measure \u03c1(s|y) as for each fixed n and y,\nZ\nZ\nn\nn\nh(s) \u03c1(ds).\nh(s) \u03c1(ds|y) and \u03ban (\u03c1) =\n\u03ban (\u03c1|y) =\nS\n\nS\n\n\u0003\nNote that, m\u03bc (dv|\u03c1, \u03b7) = S h(s)\u03c1(ds|v) \u03b7(dv) denotes the first moment measure of \u03bc.\nQ\nNow similar to the case of Poisson processes let P(d\u03bc|\u03c1, \u03b7) ni=1 \u03bc(dYi ) represent a disintegration of\nthe joint product measure of {Y1 , . . . , Yn , \u03bc}; where further {Y1 , . . . , Yn } can be viewed as conditionally\nindependent given \u03bc. The techniques in Section 2 will now be applied to identify the disintegration which\ndescribes the posterior distribution of \u03bc given {Y1 , . . . , Yn }, and the marginal joint measure of {Y1 , . . . , Yn }\nand its corresponding disintegration (Y\u2217 , p). A description of the posterior law of \u03bc will now be given. The\nresult will then be justified in Theorem 3.1.\n\u0002R\n\n\fJames\n\n15\n\nNow for each n, let P(d\u03bc|\u03c1, \u03b7, Y) denote the conditional law of \u03bc corresponding to the random measure,\nn(p)\n\n(33)\n\nX\n\n\u03bc(*) +\n\nh(Jj,n )\u03b4Yj\u2217 (*)\n\nj=1\n\nwhere Jj,n are independent random variables each with (conditional) distribution depending on Yj\u2217 ,\ne\n\ne\n\nIP(Jj,n \u2208 ds|\u03c1, Yj\u2217 ) = R\n\n(34)\n\nh(s) j,n \u03c1(ds|Yj\u2217 )\nh(s) j,n \u03c1(ds|Yj\u2217 )\n=\nej,n\n\u2217\n\u03baej,n (\u03c1|Yj\u2217 )\n\u03c1(du|Yj )\nS h(u)\n\nand chosen independently of \u03bc which is P(d\u03bc|\u03c1, \u03b7).\nThe corresponding(conditional) moment measure and Laplace functional for (34) are given by\nn(p)\n\n(35)\n\nX\n\nm\u03bc (dv|\u03c1, \u03b7, Y) = m\u03bc (dv|\u03c1, \u03b7) +\n\nE[h(Jj,n )|Yj\u2217 ]\u03b4Yj\u2217 (dv)\n\nj=1\n\nand\nL\u03bc (g|\u03c1, \u03b7, Y) = L\u03bc (g|\u03c1, \u03b7)\n\n(36)\n\nn(p) Z \u221e\nY\n0\n\nj=1\n\n\u2217\n\ne\u2212g(Yj )h(s) IP(Jj,n \u2208 ds|\u03c1, Yj\u2217 )\n\nThe joint marginal measure of Y is expressible as\nM\u03bc (dY|\u03c1, \u03b7) = m\u03bc (dY1 |\u03c1, \u03b7)\n\nn\nY\n\nm\u03bc (dYi |\u03c1, \u03b7, Y1 , . . . , Yi\u22121 ).\n\ni=2\n\nTheorem 3.1 Suppose that \u03bc is a random measure defined by (32) and assume that \u03ban (\u03c1|y) < \u221e for each\nfixed y. Let g be a non-negative or integrable function on Y n \u00d7 M, then for each n \u2265 1,\n(37)\n\nZ\n\ng(Y, \u03bc)\n\nM\u00d7Y n\n\nn\nY\n\n\u03bc(dYi )P(d\u03bc|\u03c1, \u03b7) =\n\nZ\n\ng(Y, \u03bc)P(d\u03bc|\u03c1, \u03b7, Y)M\u03bc (dY|\u03c1, \u03b7).\n\nM\u00d7Y n\n\ni=1\n\nThe expressions in (37) are equivalent to,\nXZ\n\n(38)\n\nY n(p)\n\np\n\nand M\u03bc (dY|\u03c1, \u03b7) :=\n\nQn(p)\nj=1\n\n\u0014Z\n\nM\n\n\u0015 n(p)\nY\n\u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 )\ng(Y\u2217 , p, \u03bc)P(d\u03bc|\u03c1, \u03b7, Y)\nj=1\n\n\u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 )\n\nProof. First by definition, M\u03bc is completely determined by\nZ\n\nYn\n\n\"\n\nn\nY\n\n#\n\ng\u0303i (Yi ) M\u03bc (dY|\u03c1, \u03b7) =\n\ni=1\n\nZ\n\nM\u00d7Y n\n\nfor g\u0303i in BM (Y). But this is equivalent to\n#\" n Z\n\"n\nZ\nY\nY\ng\u0303i (Yi )\nM\u00d7Y n\n\ni=1\n\ni=1\n\n0\n\n\u221e\n\n\"\n\nn\nY\n\ni=1\n\n#\n\ng\u0303i (Yi )\n\nn\nY\n\n\u03bc(dYi )P(d\u03bc|\u03c1, \u03b7)\n\ni=1\n\n#\n\nh(si )N (dsi , dYi ) P(dN |\u03c1, \u03b7).\n\n\f16\n\nPoisson Process Calculus\n\nA direct application of Lemma 2.2, or Proposition 2.2, yields all the desired forms of M\u03bc . This is seen\nimmediately by setting gi (xi ) = h(si )g\u0303i (yi ) and replacing \u03bd(dx) with \u03c1(ds|y)\u03b7(dy). Now it simply remains\nto show that the conditional Laplace functional of \u03bc is (36). Since the form of the marginal measure M\u03bc\nis established, Lemma 2.2 now shows that the conditional Laplace functional is obtained by using the fact\nR R\nthat \u03bc(g) := Y S h(s)g(y)N (ds, dy) and replacing f (x\u2217j ) in Proposition 2.1 with g(yj\u2217 )h(sj ). Hence, the\nconditional Laplace functional of \u03bc is equivalent to,\n\u0014Z\n\u0015 n(p)\nZ\nY\n(39)\nIP(J \u0303j,n \u2208 ds|\u03c1, \u03b7, Yj\u2217 ).\ne\u2212\u03bc(g) P(dN |\u03c1, \u03b7, s, Y\u2217 )\nS n(p)\n\n3.2\n\nM\n\nj=1\n\nCumulants and moment representations\n\nThe joint marginal measure M\u03bc disintegrates into\n\uf8f9\n\uf8ee\nn(p)\nn(p)\nY\nY\n\u03b7(dYj\u2217 ),\n\u03baej,n (\u03c1|Yj\u2217 )\uf8fb\nM\u03bc (dY|\u03c1, \u03b7) = \uf8f0\nj=1\n\nj=1\n\nwhich shows that the possibly sigma-finite measure of Y, disintegrates into an appropriate joint measure of\n(Y\u2217 , p). Such structures will play a fundamental role throughout. As a simple application the joint structure\ncan be used to obtain expressions for the moments of the corresponding random variable \u03bc(B), for B finite,\nas follows,\nX n(p)\nYZ\nn\nE[\u03bc(B) |\u03c1, \u03b7] :=\n(40)\n\u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 )\nB\n\nj=1\n\np\n\nwhich corresponds to the classical relationship between moments and cumulants. Additionally for integrable\nlinear functionals \u03bc(fi ), one might be interested in calculating the joint moments,\n#\n# Z \" q n Z\n\" q\nl\nYY\nY\nnl\nfl (yi,l )\u03bc(dyi,l ) P(d\u03bc|\u03c1, \u03b7)\n(\u03bc(fl )) |\u03c1, \u03b7 =\nE\nM\n\nl=1\n\nl=1 i=1\n\nY\n\nPq\n\nfor integers ni such that without loss of generality n = l=1 nl . An application of Theorem 3.1 easily yields,\n\" q\n#\n\" q\n#\nX n(p)\nY\nYZ\nY l\nnl\nej,n\nE\n=\n\u03baej,n (\u03c1|u)\n(\u03bc(fl ))\n(41)\nfl (u) \u03b7(du)\nl=1\n\np\n\nj=1\n\nY\n\nl=1\n\nPq\n\nwhere elj,n , satisfying ej,n := l=1 elj,n , denotes the number of indices associated with fl in Cj . Suppose that\nE[T n |\u03c1, \u03b7] < \u221e, then an important case of (40) is,\nE[T n |\u03c1, \u03b7] :=\n\n(42)\n\nX n(p)\nY\np\n\n\u03baei,n (\u03a9) =\n\ni=1\n\nX n(p)\nYZ\np\n\nj=1\n\nY\n\n\u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 ).\n\nThe consequences of this representation will play a major role in Section 5.\n\nExample [1]. As an important example consider the generalised gamma Levy measure \u03c1\u03b1,b for\nb > 0. In this case the Jj,n are G(ej,n \u2212 \u03b1, b),\n(43)\n\nn(p)\n\nn(p)\n\nY\n\nY\n\ni=1\n\n\u03baei,n (\u03c1\u03b1,b ) :=\n\nj=1\n\nn(p)\n\n\u0393(ej,n \u2212 \u03b1)b\n\n\u2212(ej,n \u2212\u03b1)\n\n:= b\n\n\u2212(n\u2212n(p)\u03b1)\n\nY\n\nj=1\n\n\u0393(ej,n \u2212 \u03b1),\n\n\fJames\n\n17\n\nand hence\n\nn(p)\nn\n\n(44)\n\nE[\u03bc(B) |\u03c1\u03b1,b , \u03b7] := b\n\n\u2212n\n\nX\n\nb\n\nn(p)\u03b1\n\n[\u03b7(B)]\n\nn(p)\n\nY\n\n\u0393(ej,n \u2212 \u03b1)\n\nj=1\n\np\n\nWhen \u03b1 := 0 and b = 1 this expression combined with (40) corresponds to the gamma process with\nshape measure \u03b7. In this case, where \u03b7(Y) = \u03b8 is finite, it follows that normalising the expression (43)\nby E[T n |\u03c10,1 , \u03b7] yields the EPPF, P D(p|\u03b8) of the Dirichlet process PD0,\u03b8 (dP |H). Otherwise in the unnormalised case one obtains expressions for the generalised gamma random measure in Brix (1999). In the\nweighted version of this model, discussed in James (2001b), set b := b(Yj\u2217 ), which reduces to expressions for\nthe weighted gamma process when \u03b1 = 0 in Lo and Weng(1989). Note that although dividing by E[T n |\u03c1\u03b1,b , \u03b7]\nyields a proper distribution for p it is not an EPPF except for the case of the Dirichlet process.\n\nExample [2].\n(45)\n\nFor the Beta process, with parameters c, Ao ,the Jj,n |Yj\u2217 are B(ej,n , c(Yj\u2217 )). Hence,\n\n\u03baej,n (\u03c1|Yj\u2217 ) :=\n\n\u0393(ej,n )\u0393(c(Yj\u2217 ))\n,\n\u0393(ej,n + c(Yj\u2217 ))\n\nand E[Jj,n |Yj\u2217 ] :=\n\n\u03ba1+ej,n (\u03c1|Yj\u2217 )\nej,n\n:=\n\u03baej,n (\u03c1|Yj\u2217 )\nej,n + c(Yj\u2217 )\n\nThese types of integrable operations identify joint distributional structures for (Y\u2217 , p) which have product\nform. This fact is summarized in the next result. The result is important for applications of mixture models\nwhere Y again are missing values and not observables. The result will also play a significant role in Section\n5.\nQn R\nCorollary 3.1 Let i=1 Y g\u0303i (Yi )\u03bc(dYi ) be an integrable function of P(d\u03bc|\u03c1, \u03b7), then there exists a condi\u2217\ntional distribution of Y|p such that the unique values {Y1\u2217 , . . . , Yn(p)\n} are independent with distribution\n\uf8ee\n\nIP(dYj\u2217 |\u03c1, \u03b7, g\u0303) \u221d \uf8f0\n\nY\n\ni\u2208Cj\n\n\uf8f9\n\ng\u0303i (Yj\u2217 )\uf8fb \u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 ).\n\ni\nQn(p) R hQ\n\u2217\ng\u0303\n(Y\n)\n\u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 ). If the integrability conand p has a distribution proportional to j=1 Y\ni\nj\ni\u2208Cj\ndition still holds when the (g\u0303i ) are equal to one, then\n(46)\n\nIP(dYj\u2217 |\u03c1, \u03b7) \u221d \u03baej,n (\u03c1|Yj\u2217 )\u03b7(dYj\u2217 ),\n\nQn(p)\nthe distribution of p, is proportional to j=1 \u03baej,n (\u03a9). In the homogeneous case the integrability condition holds only if \u03b7 is a finite measure. When \u03b7 is a finite measure it follows also that the unique values\n\u2217\nY1\u2217 , . . . , Yn(p)\nare iid \u03b7(*)/\u03b7(Y) := H(*).\nHereafter, based on (46) and Theorem 3.1, denote a joint law (conditional on p) of {(Jj,n , Yj\u2217 )} as\nn(p)\n\n(47)\n\nIP(dJ, dY\u2217 |\u03c1, \u03b7) :=\n\nY\n\nIP(dJj,n |\u03c1, Yj\u2217 )IP(dYj\u2217 |\u03c1, \u03b7).\n\nj=1\n\nIt follows that there exists joint laws of N, J, Y\u2217 |p denoted as\n(48)\n\nP(dN, dJ, dY\u2217 |\u03c1, \u03b7) := P(dN |\u03c1, \u03b7, J, Y\u2217 )IP(dJ, dY\u2217 |\u03c1, \u03b7) := P(dN, dJ|\u03c1, \u03b7, Y\u2217 )IP(dY\u2217 |\u03c1, \u03b7)\n\n\f18\n\nPoisson Process Calculus\n\nand also a joint law of \u03bc, Y given p denoted as\nn(p)\n\nP(d\u03bc, dY\u2217 |\u03c1, \u03b7) := P(d\u03bc|\u03c1, \u03b7, Y)\n\n(49)\n\nY\n\nIP(dYj\u2217 |\u03c1, \u03b7).\n\nj=1\n\n3.3\n\nUpdating and moment formulae\n\nThis section presents a series of important exponential based updating (change of measure) formulae which\nwill be used throughout.\nProposition 3.1 (Updating and moment formulae I) Let N denote a Poisson process with law P(dN |\u03c1, \u03b7).\nIn addition, let f denote a positive function on S \u00d7 Y. Suppose that w(\u03bc) is a positive integrable function of\n\u03bc, such that it is representable as w(\u03bc) = e\u2212N (f ) . Then,\n(i)\nw(\u03bc)P(d\u03bc|\u03c1, \u03b7) = P(d\u03bc|e\u2212f \u03c1, \u03b7)E[w(\u03bc)|\u03c1, \u03b7] := P(d\u03bc|e\u2212f \u03c1, \u03b7)LN (f |\u03c1, \u03b7).\n(ii) If \u03ban (e\u2212f \u03c1|y) < \u221e then for each n,\nw(\u03bc)\n\nn\nY\n\n\u03bc(dYi )P(d\u03bc|\u03c1, \u03b7) = P(d\u03bc|e\u2212f \u03c1, \u03b7, Y)LN (f |\u03c1, \u03b7)M\u03bc (dY|e\u2212f \u03c1, \u03b7)\n\ni=1\n\n(iii) If \u03ban (\u03c1|y) < \u221e holds then,\nw(\u03bc)P(d\u03bc|\u03c1, \u03b7, Y) = P(d\u03bc|e\u2212f \u03c1, \u03b7, Y)E[w(\u03bc)|\u03c1, \u03b7, Y]\nand\nLN (f |\u03c1, \u03b7)M\u03bc (dY|e\u2212f \u03c1, \u03b7) := E[w(\u03bc)|\u03c1, \u03b7, Y]M\u03bc (dY|\u03c1, \u03b7),\ni\nQn(p) hR\n\u2217\nwhere E[w(\u03bc)|\u03c1, \u03b7, Y] := LN (f |\u03c1, \u03b7) j=1 S e\u2212f (s,Yj ) IP(J \u0303j,n \u2208 ds|Yj\u2217 , \u03c1) .\n\nProof. As in Lemma 2.1, it suffices to show that the two sides in statement (i) have the same Laplace\nfunctional. An application of Lemma 2.1, combined with the fact that \u03bc is a functional of N implies that\nZ\nZ\nZ\n(50)\ne\u2212\u03bc(g) P(d\u03bc|e\u2212f \u03c1, \u03b7)E[w(\u03bc)|\u03c1, \u03b7]\ne\u2212\u03bc(g) e\u2212N (f ) P(dN |\u03c1, \u03b7) :=\ne\u2212\u03bc(g) w(\u03bc)P(d\u03bc|\u03c1, \u03b7) =\nM\n\nM\n\nM\n\nwhich yields statement (i). The result in statement (ii) is obtained by replacing e\u2212\u03bc(g) in (39) with e\u2212\u03bc(g) e\u2212N (f )\nand applying Lemma 2.1 to the inner integral.\n\nProposition 3.2 (Updating and moment formulae II) Suppose that f in Proposition 3.1 is replaced by\nP\nQ\n \u0303\nfn = ni=1 f \u0303i , for postive integrable functions f \u0303i , this implies that w(\u03bc) := ni=1 wi (\u03bc) where wi (\u03bc) = e\u2212N (fi ) .\nQn\nNow with respect to the the joint model P(d\u03bc|\u03c1, \u03b7) i=1 wi (\u03bc)\u03bc(dYi ), the following additional formulae are\ngiven;(all expressions are assumed to be finite)\n(i)\nn\nn\nY\nY\nLN (f \u0303i |e\u2212fi\u22121 \u03c1, \u03b7) := E[ wi (\u03bc)|\u03c1, \u03b7],\nLN (fn |\u03c1, \u03b7) := LN (f1 |\u03c1, \u03b7)\ni=2\n\nwhere fi :=\n\nPi\n\n \u0303\nj=1 fj .\n\ni=1\n\n\fJames\n\n19\n\n(ii) The expresssion below are equivalent.\nE[wi (\u03bc)|e\u2212fi\u22121 \u03c1, \u03b7, Yi\u22121 )]m\u03bc (dYi |e\u2212fi \u03c1, \u03b7, Yi\u22121 ),\nE[wi (\u03bc)|e\u2212fi\u22121 \u03c1, \u03b7, Yi )]m\u03bc (dYi |e\u2212fi\u22121 \u03c1, \u03b7, Yi\u22121 ).\n(iii) The above statements coupled with Proposition 3.1 imply that the marginal calculation,\nZ\n\nM\n\n\"\n\nn\nY\n\ni=1\n\n#\n\nwi (\u03bc)\u03bc(dYi ) P(d\u03bc|\u03c1, \u03b7)\n\nis equivalent to the following formulae,\nLN (fn |\u03c1, \u03b7)M\u03bc (dY|e\u2212fn \u03c1, \u03b7),\nE[w(\u03bc)|\u03c1, \u03b7, Y]M\u03bc (dY|\u03c1, \u03b7),\nE[w1 (\u03bc)|\u03c1, \u03b7]m\u03bc (dY1 |e\u2212f1 \u03c1, \u03b7)\n\nn\nY\n\nE[wi (\u03bc)|e\u2212fi\u22121 \u03c1, \u03b7, Yi\u22121 )]m\u03bc (dYi |e\u2212fi \u03c1, \u03b7, Yi\u22121 ),\n\ni=2\n\nE[w1 (\u03bc)|\u03c1, \u03b7, Y1 ]m\u03bc (dY1 |\u03c1, \u03b7)\n\nn\nY\n\nE[wi (\u03bc)|e\u2212fi\u22121 \u03c1, \u03b7, Yi )]m\u03bc (dYi |e\u2212fi\u22121 \u03c1, \u03b7, Yi\u22121 ).\n\ni=2\n\nremark 10.\nA notable special case of Proposition 3.1 (i) was established in Lo and Weng (1989)[see also Lo(1982)\nand James (2001a)] for the weighted gamma process. In Lo and Weng (1989, Proposition 3.1), the statement\nproceeds as follows\nProposition 3.1, Lo and Weng (1989) 1 Let G\u03b7,\u03b2 denote the law of a weighted gamma process with\nshape \u03b7 and weight \u03b2(*), then for each positive g\nZ\n\nM\n\ng(\u03bc)e\n\n\u2212\u03bc(f )\n\nG\u03b7,\u03b2 (d\u03bc) = LG\u03b7,\u03b2 (f )\n\nZ\n\ng(\u03bc)G\u03b7,\u03b2 \u2217 (d\u03bc),\n\nM\n\nwhere \u03b2 \u2217 = \u03b2/(1 + \u03b2f ).\nThis result establishes the absolute continuity of weighted gamma processes and identifies the specific\ndensities. In other words the result of Lo and Weng (1989, Proposition 3.1) includes the quasi-invariance\nresult for the gamma process recently established independently in Tsilevich, Vershik and Yor (2001, Theorem\n3.1). The applications considered by Tsilevich, Vershik and Yor (2001) are vastly different from Lo and Weng\n(1989) and it is not surprising that this result emerges in another context. The development of the exponential\nformulae used here are directly inspired by Lo and Weng (1989, Proposition 3.1).\n\n\f20\n\nPoisson Process Calculus\n\n3.4\n\nA simple proof for the almost sure discreteness of size-biased measures\n\nIn this section a Fubini argument is used to establish the almost sure discreteness of \u03bc with law P(d\u03bc|\u03c1, \u03b7).\nThis will include a simple alternative proof for the class of completely random measures as discussed in\nKingman (1993, Chapter 10). Kingman' s result is based on a modification of Blackwell's (1973) argument\nfor the Dirichlet process. The present technique is based on the approach of Berk and Savage (1979) and Lo\nand Weng (1989) for the Dirichlet process and weighted gamma process respectively. The only requirement\nI will need is that \u03bc admits a disintegration, has a 1st moment measure, or is absolutely continuous with\nrespect to the law of another measure \u03bc\u2217 which has one. The latter case of course will yield the result for\nthe stable law. Measurability issues vanish on Polish spaces. The idea is to apply a 1-step disintegration of\n\u03bc(dx)P(d\u03bc|\u03c1, \u03b7). For the arguments below it suffices to show that the result holds over all bounded sets B,\ni.e. sets such that \u03b7(B) < \u221e so without loss of generality we can assume that \u03b7 is a finite measure.\nProposition 3.3 (Almost sure discreteness of measures) Suppose that \u03bc is P(d\u03bc|\u03c1, \u03b7) such that \u03bc has a 1st\nmoment measure m\u03bc (*|\u03c1, \u03b7). Otherwise suppose that their exists a measure \u03bc\u2217 which admits a 1st moment\nmeasure and satisfies the absolute continuity relationship,\nP(d\u03bc|\u03c1, \u03b7) := g(\u03bc\u2217 )P(d\u03bc\u2217 |\u03c1\u2217 , \u03b7),\n\n(51)\n\nfor some positive integrable function g. Then \u03bc is almost surely discrete. That is,\nZ\n(52)\n\u03bc({x : \u03bc({x}) = 0})P(d\u03bc|\u03c1, \u03b7) := 0\nM\n\nProof. Using a disintegration argument,\nZ\n\nM\n\n\u03bc({x : \u03bc{x} = 0})P(d\u03bc|\u03c1, \u03b7) :=\n\nZ \u0014Z\n\nM\n\n\u0015\nI{x : \u03bc({x}) = 0}P(d\u03bc|\u03c1, \u03b7, x) m\u03bc (dx|\u03c1, \u03b7)\n\nFrom Theorem 3.1 the law of \u03bc taken with respect to the inner term(that is given x) is the same as\n\u03bc(*) + h(J)\u03b4x (*)\nwhere h(J) is strictly postive and J has law \u221d h(s)\u03c1(ds|x) for almost all x. But since \u03bc is not negative it\nfollows that\n\u03bc({x}) + h(J)\u03b4x ({x}) \u2265 h(J) > 0.\nfor almost all x with respect to m\u03bc . Hence the inner term is zero which concludes the result. If again \u03bc does\nnot admit such a disintegration, apply the result to the random measure \u03bc\u2217 , with for instance L\u00e9vy measure\ne\u2212gh \u03c1, or some other operation, and use the absolute continuity of measures.\n\nremark 11. This method also implies the almost sure discretenes of the measures in Section 5.\nBeyond the mild restriction to Polish spaces, I believe this is the most general result of this type. The\nabsolute continuity in (51) coupled with the existence of such \u03bc\u2217 , for instance via Proposition 3.1, seems to\nexhaust the possibilities.\n\n\fJames\n\n4\n\n21\n\nIntensity rate mixture models, L\u00e9vy moving averages and shotnoise processes\n\nIn this section analysis for the class of mixture of hazards models as discussed in the introduction, otherwise\nknown as L\u00e9vy-Cox moving average models, is given. Very little is known about the posterior structure of such\nmodels with a notable exception being the case of mixtures of weighted gamma processes which is discussed\nin various degrees of generality in Dykstra and Laud (1981), Lo (1982), Lo and Weng (1989). Wolpert and\nIckstadt (1998a) and James (2001a) consider semiparametric extensions of this model. Full partition based\nposterior analysis ina a general multiplicative setting is given in Lo and Weng (1989) and James (2001a).\nOne consequence of the absence of a general analysis of this model is the unavailabilty of computational\nprocedures which sample from the updated or posterior based models. As mentioned in the introduction\nsuch models are currently used in Spatial statistical applications and survival analysis. An interesting class\nof models which fits into this framework is the generalised gamma process proposed in Brix (1999). Wolpert\nand Ickstadt (1998b) propose models based on arbitrary L\u00e9vy processes. The analysis here includes these\nmodels as well as mixture models based on the general size-biased random measures described in section 3.\nConsider the random hazard or intensity rate,\n(53)\n\n\u03bb(t|\u03bc) =\n\nZ\n\nK(t|v)\u03bc(dv),\n\nY\n\nwhere K denotes a known (\u03c4, \u03b7)-integrable kernel on a Polish space X \u00d7 Y and \u03bc is modelled as a random\nmeasure with law P(d\u03bc|\u03c1, \u03b7). The representation in (53) defines a large class of random measures \u03bb which\nare not independent increment processes.\nIn this section explicit posterior characteristics of \u03bc and hence \u03bb based on the multiplicative intensity\nlikelihood,\n\"n Z\n#\nY\nL(X|\u03bc)P(d\u03bc|\u03c1, \u03b7) =\n(54)\nK(Xi |Yi )\u03bc(dYi ) e\u2212\u03bc(fK ) P(d\u03bc|\u03c1, \u03b7)\nY\n\ni=1\n\nare derived where, fK (v) =\n\n\u0002R\n\nS\n\n\u0003\nY (s)K(s|v)\u03c4 (ds) .\n\nHere Xi are observations in a (Polish space) region X and Yi can be viewed as missing observations\non Y. Y (s) is a non-negative predictable function which for many applications in event history analysis\ndenotes the number of observed individuals still at risk just before time s. An important point is that the\nstructural form of L(X|\u03bc) remains the same under right censoring and left filtering [see Jacod(1975) and\nAndersen, Borgan, Gill and Keiding (1993)]. If Y (s) = 1 then the model may correspond to the likelihood\nof an inhomogeneous Poisson process with intensity rate \u03bb(t|\u03bc). One purpose of the development of Lemma\n2.1 is to handle the exponential term in (54). Thus mimicking the application of Lo and Weng (1989,\nProposition 3.1). Proposition 3.1 and Theorem 3.1 in this paper readily yield the desired results. Moreover\nthe appearance of the exponential term combined with Proposition 3.1 show that analysis of this model only\nrequires the weaker condition,\n(55)\n\n\u03ban (e\u2212fK \u03c1|y) =\n\nZ\n\n\u221e\n\nn\n\ne\u2212fK (y)s h(s) \u03c1(ds|y) < \u221e.\n\n0\n\nThe condition (55) will be assumed throughout this section and now for instance admits analysis for the\nstable law \u03c1\u03b1,0 , via Proposition 3.1.\n\n\f22\n\nPoisson Process Calculus\n\nAn application of Proposition 3.1 combined with Corollary 3.1 show that the marginal likelihood is,\n\uf8ee\n\uf8f9\nZ\nX n(p)\nY\nYZ\n\uf8f0\nL(X|\u03bc)P(d\u03bc|\u03c1, \u03b7) = L\u03bc (fK |\u03c1, \u03b7)\nK(Xi |Yj\u2217 )\uf8fb \u03baej,n (e\u2212fK \u03c1|Yj\u2217 )\u03b7(dYj\u2217 ).\n(56)\nM\n\n4.1\n\np\n\nj=1\n\nY\n\ni\u2208Cj\n\nPosterior characterizations\n\nExplicit posterior characterizations are now given which follows immediately from the Theorem 3.1, Corollary\n3.1 and Proposition 3.1. (Note that it is assumed throughout that all relevant integrals are finite).\nTheorem 4.1 The posterior distribution of Y, \u03bc|X based on the model (54) is representable as,\n\uf8ee\n\uf8f9\nn(p)\nY\n\u03c0(dY, d\u03bc|X) \u221d P(d\u03bc|e\u2212fK \u03c1, \u03b7, Y) \uf8f0\nIP(dYi\u2217 |e\u2212fK \u03c1, \u03b7, K)\uf8fb \u03c0(p|X),\ni=1\n\nwhere \u03c0(p|X) \u221d\n\nQn(p) R hQ\nj=1\n\nY\n\ni\n\u2217\nK(X\n|Y\n)\n\u03baej,n (e\u2212fK \u03c1|Yj\u2217 )\u03b7(dYj\u2217 ) is a (posterior) distribution of p|X.\ni\nj\ni\u2208Cj\n\nSimilar to Lo and Weng (1989, Theorem 4.2), Theorem 4.1 implies for instance that the posterior expectation of the intensity, \u03bb|Y, is\n(57)\n\nE[\u03bb(t|\u03bc)|Y] =\n\nZ\n\nn(p)\n\nK(t|v)\u03ba1 (e\u2212fK \u03c1|v)\u03b7(dv) +\n\nY\n\nX\nj=1\n\nK(t|Yj\u2217 )\n\n\u03ba1+ej,n (e\u2212fK \u03c1|Yj\u2217 )\n\u03baej,n (e\u2212fK \u03c1|Yj\u2217 )\n\nand hence the posterior expection given X is ,\n\uf8f6\n\uf8eb\nn(p) Z\nX Z\nX\n\u03ba1+ej,n (e\u2212fK \u03c1|v)\n\uf8ed K(t|v)\u03ba1 (\u03c1fK |v)\u03b7(dv) +\n\u03c0(dv|Cj )\uf8f8 \u03c0(p|X).\n(58) E[\u03bb(t|\u03bc)|X] =\nK(t|v)\n\u2212fK \u03c1|v)\n(e\n\u03ba\ne\nY\nY\nj,n\np\nj=1\n\nExample [Generalised gamma process]. A brief description of the results related to the usage of\na generalised gamma process with intensity \u03c1\u03b1,b (ds)\u03b7(dy) as in Brix (1999) are given. Note in particular\nthat the result holds for the stable case b = 0. The posterior distribution of \u03bc given Y is denoted as\nP(d\u03bc|e\u2212fK \u03c1\u03b1,b , \u03b7, Y). That is, Jj,n given Yj\u2217 are independent G(ej,n \u2212 \u03b1, b + fK (Yi\u2217 )), and \u03bc is now a weighted\ngeneralised gamma process with Laplace function\n\u001a\n\u001b\nZ\n1\n\u03b1\n\u03b1\nexp \u2212\n[(b + fK (v) + g(v)) \u2212 (b + fK (v)) ]\u03b7(dv)\n\u03b1 Y\nThe joint moment measure of Y can be expressed as,\n\uf8f6\n\uf8eb\nn(p)\nn(p)\nY\nY\n\u2212(e \u2212\u03b1)\n(59)\n(b + fK (Yj\u2217 )) j,n\n\u03b7(dYj\u2217 )\n\u0393(ej,n \u2212 \u03b1)\uf8f8\nM\u03bc (dY|e\u2212fK \u03c1\u03b1,b , \u03b7) = \uf8ed\nj=1\n\nj=1\n\nwhich generalizes an expression for the weighted gamma process, see Lo and Weng (1989) and James (2001a).\nSee James (2001b) for more details related to the generalised gamma model.\n\n\fJames\n\n23\n\nremark 12. Note that from a practical point of view the distribution of Jj,n based on P(d\u03bc|e\u2212fK \u03c1, \u03b7, Y)\nmay not always be easy to simulate. If however the moment condition in Theorem 3.1 holds then one can use\nan alternative characterization of the posterior based on P(d\u03bc|\u03c1, \u03b7, Y). In that case one does not marginalize\nover the exponential term but instead works with the measure,\ne\u2212\u03bc(fK ) P(d\u03bc|\u03c1, \u03b7, Y)\n\nremark 13. James (2001a) gives results for semi-parametric weighted Gamma process mixture models under more complex multiplicative intensity structures. That is for cases where the kernel K depends\non a Euclidean parameter \u03c8 and where for instance there may be several independent Poisson processes.\nA careful examination of that work, coupled with with the results given here provides an obvious way to\nobtain the corresponding result for the general processes. A notable wrinkle is that the Laplace functionals\nwill depend on \u03c8. A discussion of this is omitted for brevity.\n4.2\n\nSimulating the posterior\n\nHere the algorithm discussed in Section 2.3 is applied to this setting to demonstrate a possible approach\nto approximate posterior quantities. Again MCMC based methods can also be deduced from the algorithm\nbelow. First set,\nl(r|K) =\n\nZ\n\nKr+1 (Xr+1 |v)\u03ba1 (e\n\n\u2212fK\n\n\u03c1|v)\u03b7(dv) +\n\nY\n\nn(pr ) Z\n\nX\nj=1\n\nKr+1 (Xr+1 |v)\nY\n\n\u03ba1+ej,r (e\u2212fK \u03c1|v)\n\u03c0(dv|Cj,r ),\n\u03baej,r (e\u2212fK \u03c1|v)\n\nR\nwhere in particular , l(0|K) = Y Kr+1 (Xr+1 |v)\u03ba1 (e\u2212fK \u03c1|v)\u03b7(dv).\nOne can now use the variant of the WCR described in Section 2.3 with the seating rule: Given pr ,\ncustomer r + 1 sits at table Cj,r with probability\n\u22121\n\nIP(pr+1 |pr ) = l(r|K)\n\nZ\n\nKr+1 (Xr+1 |v)\n\nY\n\n\u03ba1+ej,r (e\u2212fK \u03c1|v)\n\u03c0(dv|Cj,r )\n\u03baej,r (e\u2212fK \u03c1|v)\n\nwhere pr+1 = pr \u222a {r + 1 \u2208 Ci,r } for i = 1, . . . , n(pr ). Otherwise, customer r + 1 sits at a new table with\nprobability\nZ\nIP(pr+1 |pr ) = l(r|K)\n\n\u22121\n\nK(Xr+1 |v)\u03ba1 (e\u2212fK \u03c1|v)\u03b7(dv).\n\nY\n\nThe completion of Step n produces a p = {C1 , . . . , Cn(p) } = pn , where now, from Lemma 2.3, p is drawn\nfrom the density q(p|K) which satisfies,\n\uf8ee\n\uf8f9\nn(p) Z\nY\nY\n\uf8f0\nK(Xi |Yj\u2217 )\uf8fb \u03baej,n (e\u2212fK \u03c1|Yj\u2217 )\u03b7(dYj\u2217 ),\nI(p|K)q(p|K) =\nj=1\n\nY\n\ni\u2208Cj\n\nThis fact, together with Theorem 4.1, implies that for any integrable function t(p),\nP\nX\np t(p)I(p|K)q(p|K)\nt(p)\u03c0(p|X) = P\n(60)\n.\np I(p|K)q(p|K)\np\n\nThe expression (60) and Theorem 4.1 now suggest a method to approximate the posterior law P (d\u03bc|X)\n\n\f24\n\nPoisson Process Calculus\n1. Using the seating algorithm above, draw B iid random partitions p = {C1 , . . . , Cn(p) } from q(p|K)\n2. Use the value of p to draw Yj\u2217 independently from \u03c0(dYj\u2217 |Cj ) for j = 1, . . . , n(p). This yields\n\u2217\nY\u2217 = (Y1\u2217 , . . . , Yn(p)\n).\n3. Using the current value of (Y\u2217 , p), approximate a draw from the random measure\nn(p)\n\n(61)\n\n\u03bcfK (*) +\n\nX\n\nh(Jj,n )\u03b4Yj\u2217 (*),\n\nj=1\n\nwhich is distributed as P(d\u03bc|e\u2212fK \u03c1, \u03b7, Y).\n4. To approximate the posterior law of a functional g(\u03bc), run the previous steps B times independently obtaining values \u03bc(b) with importance weights I(p(b) ), for b = 1 . . . , B. Approximate the law,\nP (g(\u03bc) \u2208 *|X), with\nPB\n(b)\n(b)\nb=1 I{g(\u03bc ) \u2208 *} I(p |K)\n(62)\n.\nPB\n(b)\nb=1 I(p |K)\nIf one only needs to approximate moments, or an integration which yields a t(p) in closed form, for\ninstance the likelihood, then steps 2 and 3 can be eliminated and one can replace (62) with\n(63)\n\nPB\n\nt(p(b) ) I(p(b) |K)\n.\nPB\n(b)\nb=1 I(p |K)\n\nb=1\n\nremark 14. Note that in (61) the main difficulty is to approximate a draw from \u03bcfK . Brix (1999)\ndiscusses methods on how to approximate a generalized gamma process P(d\u03bc|\u03c1\u03b1,b , \u03b7). It should be straightforward to extend this to a P(d\u03bc|e\u2212fK \u03c1\u03b1,b , \u03b7). See also Wolpert and Ickstadt (1998b) for some possible ideas\nin the general setting. I believe that the mixture representations given in the next section may also be useful\nin this regard.\n\n5\n\nAnalysis of a Scaling operation which arises in Brownian Excursion theory\n\nThe previous section describes applications of various exponential change of measure operations. As shown\nfrom Lemma 2.1 this operation results in a change of measure from a Poisson process with intensity \u03bd to\nanother Poisson process law with intensity e\u2212f \u03bd. An important aspect of that is one can still apply directly\nLemma 2.2 to the transformed Poisson law, which yields the various results in the previous section. In\nparticular this operation transforms processes \u03bc which do not admit moment measures to ones which do.\nAn important example is the stable law which is transformed to a form of weighted generalised gamma\nprocess. Another important operation, besides the exponential change of measure, is a type of scaling, which\narises for instance in Brownian excursion theory[see for instance Pitman and Yor (1992, 1997, 2001)]. This\noperation no longer preserves the Poisson nature of N or similarly the structure of the biased models \u03bc. This\nin itself does not present a major obstacle as one could still apply Lemma 2.2 to the Poisson law first. The\nlaw resulting from the scaling operation may not have an obviously understandable form. However, indeed\nhidden in a scaling operation is an exponential form via a gamma integral identity. This identity has been\nused frequently in various contexts. Here, a slightly different variation will be used, where the exponential\n\n\fJames\n\n25\n\nchange of measure idea will be applied internally leading to a variety of interesting consequences. As an\nimportant special case we look at the P D(\u03b1, \u03b8) model. In general, analysis of the simple scaling structure\nleads to results quite related to Pitman and Yor (1992, 1997, 2001). [See also Perman, Pitman and Yor\n(1992), Section 4]. In particular see Pitman and Yor (1992) Section 3.\n\nremark 15. It will become quite clear to the experts,on excursion theory and such matters, that\nthe overlap with Pitman and Yor (1992, Section 3) is hardly coincidental. Although this was not my initial\nmotivation. Some of the results given below amplify on Pitman and Yor (1992, Theorem 3.1 and especially\nRemarks 3.3 and 3.4). This section may be viewed as extensions of their Section 3. Given the new results\nI obtain for the P D(\u03b1, \u03b8), among other things, the present exposition should clearly provide new insights,\nfor the experts, into matters of which I myself have no expertise. Again applications of Lemma 2.1 and\nProposition 3.1 play a fundamental role.\n\nremark 16. In this section it is assumed that \u03b7 satisifies the integrability condition in Corollary 3.1\nwhen g\u0303 := 1. That is when \u03c1 is homogeoneous then \u03b7 := cH for some scalar c. For the Dirichlet process\n\u03b7 := \u03b8H but is not to be confused with \u03b8 used below to mimic the scaling operation associated with P D(\u03b1, \u03b8)\nfor \u03b1 > 0.\nThe present analysis yields new mixture representations of random measures N and \u03bc. What is most\nimportant is how they arise within the context of the scaling operation. [The reader should again note Pitman\nand Yor (1992, Remark 3.4)]. This leads to an analogous representations of random probability measures\ndefined as,\nR\nh(s)N (ds, *)\n\u03bc(*)\n\u03bc(*)\nR\nP (*) =\n:=\n(64)\n= S\n\u03bc(Y)\nT\nh(u)N\n(du,\nY)\nS\n\nwhose law is determined by an appropriate law on N . That is either a Poison law or a scaled Poisson law to\nbe described below. In addition various characterizations of the the posterior distributions of N ,\u03bc, and P are\nobtained. These results are applied to obtain general identities and representations for the two-parameter\nfamily with parameters 0 < \u03b1 < 1, \u03b8 > \u2212\u03b1. This extends an identity given for the case P D(\u03b1, \u03b1) in Pitman\nand Yor (2001).\nIt is known that the general PD\u03b1,\u03b8 (dP |H) cannot directly be defined via normalization of an independent\nincrement process. The exceptions are the Dirichlet process and the Stable law process. Pitman and Yor\n(1997),[see also Tsilevich, Vershik and Yor (2000)] establish the following relationship. Let P D\u03b1,\u03b8 (d\u03bc|\u03b7)\ndenote a law of \u03bc such that its normalisation results in a Poisson-Dirichlet random probability measure,with\nlaw denoted as PD\u03b1,\u03b8 (P |H). In particular PD\u03b1,0 (d\u03bc|\u03b7) := P(d\u03bc|\u03c1\u03b1 , \u03b7) is the Stable process. From Pitman\nand Yor (1997), [see in particular Tsilevich, Vershik and Yor (2000) where this form is taken], it follows that\nfor 0 < \u03b1 < 1, \u03b8 > \u2212\u03b1,\n(65)\n\nPD\u03b1,\u03b8 (d\u03bc|\u03b7) = c\u03b1,\u03b8 T \u2212\u03b8 PD\u03b1,0 (d\u03bc|\u03b7),\n\nwhere c\u03b1,\u03b8 is a normalizing constant. Pitman and Yor (1997) describe various results concerning the P D(\u03b1, \u03b8)\nlaw of the (Pi ), related to this fact. Notably, Proposition 21, Proposition 22, and Proposition 33. In particular\nthey show that if the sequence (Pi ) is P D(\u03b1, \u03b8) then\n(66)\n\nP D(\u03b1, \u03b8) =\n\nZ\n\n0\n\n\u221e\n\nP D(\u03b1|t)\u03b3\u03b1,\u03b8 (dt)\n\n\f26\n\nPoisson Process Calculus\n\nwhere P D(\u03b1|t) denotes the conditional Poisson-Kingman[see section 8] law of P D(\u03b1) conditioned on T ,\nR\u221e\n\u2212\u03b8\n\u03b3\u03b1,\u03b8 (dt) = c\u22121\nf\u03b1 (t), c\u03b1,\u03b8 = E[T \u2212\u03b8 ] = 0 t\u2212\u03b8 f\u03b1 (t) is the normalising constant and f\u03b1 (t) denotes the\n\u03b1,\u03b8 t\ndensity of a stable law random variable which is the distribution of T . Tsilevich, Verhsik and Yor (2000)\nusing (65) in combination with the following gamma identity for \u03b8 > 0,\nT \u2212\u03b8 :=\n\n(67)\n\n1\n\u0393(\u03b8)\n\nZ\n\n\u221e\n\nv \u03b8\u22121 e\u2212vT dv,\n\n0\n\nestablish quite remarkably and simply a two-parameter extension of the Markov-Krein correspondence via\nthe Laplace functional of a stable law.[Their result will be extended in a general fashion in Section 6]. This\nidentity is also used in Perman, Pitman and Yor (1992) and Pitman and Yor (1997) among other places. The\nresults discussed above are used primarily to deduce properties related to the normalized process \u03bc(*)/T .\nThat is, equivalently the P D(\u03b1, \u03b8) family. The interest here however is in another characterization of the law\nP\u03b1,\u03b8 (d\u03bc|\u03b7) which allows more direct usage of it and of course implies results for the normalized process and\nsynonymously P D(\u03b1, \u03b8). The method relies on using the identity (67) conditioning on various transformed\ndensities for V rather than T which will lead to a variety of interesting results. This analysis will be applied\nto general processes, \u03bc and N , subject to the same type of scaling operation. For all \u03b8 > \u2212\u03b1, in particular\nthe case \u2212\u03b1 < \u03b8 \u2264 0, the same identity (67) will be used for each fixed n,\n1\n\u0393(n)\n\n(68)\n\nZ\n\n\u221e\n\nT n v n\u22121 e\u2212vT dv := 1,\n\n0\n\nwhere the main point now is to work with T n rather than its reciprocal, and otherwise use the fact that the\nleft hand-side of (68) is one. Now assuming that\n(69)\n\nE[T \u2212\u03b8 |\u03c1, \u03b7] :=\n\nZ\n\nT \u2212\u03b8 P(dN |\u03c1, \u03b7) :=\n\nM\n\nZ\n\nT \u2212\u03b8 P(d\u03bc|\u03c1, \u03b7) < \u221e\n\nM\n\nconsider the equality of laws,\n(70)\n\nP\u0303(dN |\u03c1, \u03b7, \u03b8) :=\n\nT \u2212\u03b8 P(d\u03bc|\u03c1, \u03b7)\nT \u2212\u03b8 P(dN |\u03c1, \u03b7)\n,\nand,\nP\u0303(d\u03bc|\u03c1,\n\u03b7,\n\u03b8)\n:=\nE[T \u2212\u03b8 |\u03c1, \u03b7]\nE[T \u2212\u03b8 |\u03c1, \u03b7]\n\nR\nFor each fixed v, let E[e\u2212vT |\u03c1, \u03b7] := M e\u2212vT P(dN |\u03c1, \u03b7) denote the Laplace transform of T taken relative\nto P(dN |\u03c1, \u03b7). The following relationship will prove useful and allows analysis for the case \u2212\u03b1 < \u03b8 \u2264 0.\nSuppose that for n \u2265 1,\n(71)\n\nn\n\nE[T |\u03c1, \u03b7, \u03b8 + n] :=\n\nZ\n\nT n P\u0303(dN |\u03c1, \u03b7, \u03b8 + n) =\n\nM\n\nE[T \u2212\u03b8 |\u03c1, \u03b7]\n<\u221e\nE[T \u2212(\u03b8+n) |\u03c1, \u03b7]\n\nthen\n(72)\n\nP\u0303(dN |\u03c1, \u03b7, \u03b8) :=\n\nT n P\u0303(d\u03bc|\u03c1, \u03b7, \u03b8 + n)\nT n P\u0303(dN |\u03c1, \u03b7, \u03b8 + n)\n,\nand\nP\u0303(d\u03bc|\u03c1,\n\u03b7,\n\u03b8)\n:=\n.\nE[T n |\u03c1, \u03b7, \u03b8 + n]\nE[T n |\u03c1, \u03b7, \u03b8 + n]\n\nAdditionally, denote the laws of P taken relative to P(*|\u03c1, \u03b7) and P\u0303(dN |\u03c1, \u03b7, \u03b8) as P(dP |\u03c1, \u03b7) and P\u0303(dP |\u03c1, \u03b7, \u03b8)\nrespectively. When \u03c1 does not depend on y and \u03b7 := cH, then\n(73)\n\nP :=\n\n\u221e\nX\ni=1\n\nPi \u03b4Zi\n\n\fJames\n\n27\n\nwhere the sequence (Pi ) is independent of (Zi ) which are iid H. In that case the analysis of P is in principle\nequivalent to the analysis of (Pi ). That is the P models are special cases of species sampling models [See\nPitman (1996), Hansen and Pitman (2001) and Ishwaran and James (2001a)]. Hence, for instance, the results\nof Perman, Pitman and Yor (1992) and Pitman (1995b), concerning the EPPF etc.; can be applied to this\nsetting to obtain information about P . When \u03c1 depends on y, then one can still represent P in the form\n(73). However the independence property between (Pi ) and (Zi ) no longer holds. It will become clear that\nif interest is simply the marginal distributional properties of the (Pi ) then the results of Pitman, Perman\nand Yor (1992) and Pitman (1995b) can be applied using \u03a9 rather than \u03c1. At any rate, a different analysis\nwill be used here which is based primarily on information contained in the random measures N and \u03bc which\nwill yield relevant information about the (Pi ) etc. This is useful even in the species sampling case where the\nEPPF may be intractable or does not easily convey information about P .\n\nremark 17. Although the emphasis seems to be on the scaled laws P\u0303(*|\u03c1, \u03b7, \u03b8+n) this is only partially\nthe case. In particular it should be clear that the negative moment conditions (69) and (71) do not hold\nin general. This is the case for a gamma process, which could be denoted as P0,\u03b8 (d\u03bc|\u03b7), and hence it is\nnot a proper P\u0303(d\u03bc|\u03c1, \u03b7, \u03b8). The forthcoming discussion investigates properties of general N and \u03bc based on\nmanipulation of both (67) and (68). The results below related to P\u0303(*|\u03c1, \u03b7, \u03b8 + n) hold provided (69) and (71)\nare true.\n\n5.1\n\nMixture representations for general processes\n\nThe results follow from the proof of Theorem 5.1 below.\nProposition 5.1 The follwing identities hold which have various implications.\n(i)For n > 0,\n\uf8f9\n\uf8ee\nY\nX Z \u221e n(p)\n\uf8f0\n\u03baej,n (e\u2212vh \u03a9)\uf8fb v n\u22121 E[e\u2212vT |\u03c1, \u03b7]dv,\n(74)\n\u0393(n) :=\np\n\n0\n\nj=1\n\nR\u221e\n\nwhich is equivalent to, 0 E[T n |e\u2212vh \u03a9, \u03b7]v n\u22121 E[e\u2212vT |\u03c1, \u03b7]dv.\n(ii) Statement (i) implies that there exist a joint distribution of V, p given by,\n\n(75)\n\n\u03c0n,0 (dv, p|\u03c1, \u03b7) :=\n\nhQ\nn(p)\nj=1\n\ni\n\u03baej,n (e\u2212vh \u03a9) v n\u22121 E[e\u2212vT |\u03c1, \u03b7]dv\n\u0393(n)\n\n(iii) Suppose that (71) holds for \u03b8 + n > 0 then, \u0393(\u03b8 + n)E[T \u2212(\u03b8+n) |\u03c1, \u03b7] :=\nidentifies a random variable V on (0, \u221e) with density,\n(76)\n\n\u03c0\u03b8+n (dv|\u03c1, \u03b7) :=\n\nAdditionally, E[T n |\u03c1, \u03b7, \u03b8 + n] :=\nthat V, p has joint density,\n\nR\u221e\n0\n\n0\n\nv \u03b8+n\u22121 E[e\u2212vT |\u03c1, \u03b7]dv, which\n\nv \u03b8+n\u22121 E[e\u2212vT |\u03c1, \u03b7]dv\n\u0393(\u03b8 + n)E[T \u2212(\u03b8+n) |\u03c1, \u03b7]\n\nE[T n |e\u2212vh \u03a9, \u03b7]\u03c0\u03b8+n (dv). Hence there exists a random variable V such\n\n\u2212(\u03b8+n)\n\n(77)\n\nR\u221e\n\n.\n\n\u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7) :=\n\n\uf8ee\n\nn(p)\n\n\uf8f9\n\nE[T\n|\u03c1, \u03b7] \uf8f0\n\u03baej,n (e\u2212vh \u03a9)\uf8fb \u03c0\u03b8+n (dv)\nE[T \u2212\u03b8 |\u03c1, \u03b7]\nj=1\nY\n\n\f28\n\nPoisson Process Calculus\n\n(iv) The marginal distribution of p in (75) and (77) is given by,\n\uf8f9\n\uf8ee\nZ\nn(p)\nE[T \u2212(\u03b8+n)|\u03c1, \u03b7] \u221e \uf8f0 Y\n\u03c0\u03b8+n,\u03b8 (p|\u03c1, \u03b7) :=\n\u03baej,n (e\u2212vh \u03a9)\uf8fb \u03c0\u03b8+n (dv)\n(78)\nE[T \u2212\u03b8 |\u03c1, \u03b7]\n0\nj=1\n\nremark 18. The formula \u03c0n,0 (p) derived from (78) corresponds to the EPPF formula given in Pitman\n(1995b, Corollary 6 formula (32)), when h(s) := s \u2208 (0, \u221e) and \u03c1 is homogeneous. Pitman (1995b) uses the\nidentity (67) applied to T \u2212n . Indeed it will be stated formally that (78) are EPPF formulas which can be\nseen as an extension of Pitman's result.\nThe next result identifies P\u0303(dN |\u03c1, \u03b7, \u03b8) and in fact arbitrary Poisson laws P(dN |\u03c1, \u03b7) as a mixture\nrelative to Poisson random measures N \u2217 with conditional(given V) laws P(dN |e\u2212vh \u03c1, \u03b7). Moreover since\nthe conditional law on N \u2217 has moments the result also contains mixture representations of \u03bc of the type\nPn(p)\nN \u2217 + j=1 \u03b4Jj,n ,Yj\u2217 . The marginal distribution of N \u2217 actually depends on n.\n\nTheorem 5.1 (Poisson Mixture representations) (i) For \u03b8 > 0, the law P\u0303(dN |\u03c1, \u03b8, \u03b7) defined in (70) is\nexpressible as the following mixture,\nZ \u221e\nP\u0303(dN |\u03c1, \u03b8, \u03b7) :=\n(79)\nP(dN |e\u2212vh \u03c1, \u03b7)\u03c0\u03b8 (dv|\u03c1, \u03b7).\n0\n\nThis indicates that N |V = v has a Poisson law P(dN |e\u2212vh \u03c1, \u03b7) with intensity e\u2212vh(s) \u03c1(ds|y)\u03b7(dy) and V is\na random variable on (0, \u221e) with density \u03c0\u03b8 (dv|\u03c1, \u03b7). Equivalently the Laplace function of N is,\nZ \u221e\nLN (f |\u03c1, \u03b7, \u03b8) :=\n(80)\nLN (f |e\u2212vh \u03c1, \u03b7)\u03c0\u03b8 (dv|\u03c1, \u03b7)\n0\n\n[Compare statement (i) with Pitman and Yor (1992, Remarks 3.3, 3.4)]\n(ii) For each n > 0, a Poisson law P(dN |\u03c1, \u03b7) can be represented as,\nXZ\n(81)\nP(dN |\u03c1, \u03b7) :=\nP(dN, dJ, dY\u2217 |e\u2212vh \u03c1, \u03b7)\u03c0n,0 (dv, p|\u03c1, \u03b7)\np\n\nS n(p) \u00d7Y n(p) \u00d7R+\n\nThat is from, (48),the random measure N can be represented as\nn(p)\n\nN\u2217 +\n\n(82)\n\nX\n\n\u03b4(Jj,n ,Yj\u2217 ) ,\n\nj=1\n\nwhere given V, p with law \u03c0n,0 (dv, p|\u03c1, \u03b7), N \u2217 is conditionally independent of J, Y\u2217 , with distribution P(dN |e\u2212vh \u03c1, \u03b7, \u03c1).\nThe random variables (J, Y\u2217 ) given V, p have distribution IP(dJ, dY\u2217 |e\u2212vh \u03c1, \u03b7) as in (47).\n(iii) For \u03b8 + n > 0,this includes \u2212\u03b1 < \u03b8 \u2264 0, the law P\u0303(dN |\u03c1, \u03b7, \u03b8) is equivalent to,\nXZ\n(83)\nP(dN, dJ, dY\u2217 |e\u2212vh \u03c1, \u03b7)\u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7).\np\n\nS n(p) \u00d7Y n(p) \u00d7R+\n\nThat is, N can be represented as (82) except that the distribution of V, p is \u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7). When \u03b8 := 0\nstatement (iii) reduces to statement (ii).\n\n\fJames\n\n29\n\nProof. For the result in (i), it suffices to evaluate the Laplace functional of P\u0303 defined in (70). That\nis,\nE[T \u2212\u03b8 |\u03c1, \u03b7]\n\nZ\n\ne\u2212N (f ) P\u0303(dN |\u03c1, \u03b7, \u03b8) :=\n\nZ\n\ne\u2212N (f ) T \u2212\u03b8 P(dN |\u03c1, \u03b7).\n\nM\n\nM\n\nNow apply the identity (67) to see that the right hand side is equal to\nZ \u221e\n1\n(84)\nv \u03b8\u22121 E[e\u2212N (f ) e\u2212vT |\u03c1, \u03b7]dv.\n\u0393(\u03b8) 0\nAn application of Lemma 2.1 and dividing through by E[T \u2212\u03b8 |\u03c1, \u03b7] now show that the Laplace functional of\nP\u0303(dN |\u03c1, \u03b7, \u03b8) is,\nZ \u221e\nv \u03b8\u22121 E[e\u2212vT |\u03c1, \u03b7]dv\n(85)\n,\nE[e\u2212N (f ) |e\u2212vh \u03c1, \u03b7]\nE[T \u2212\u03b8 |\u03c1, \u03b7]\u0393(\u03b8)\n0\nas desired. For (ii), use (68) as follows\n(86)\n\n\u0393(n)LN (f |\u03c1, \u03b7) :=\n\n\u221e\n\nZ\n\nE[T n e\u2212N (f ) e\u2212vT |\u03c1, \u03b7]v n\u22121 dv.\n\n0\n\nR Qn\nNoting that T n := Y n i=1 \u03bc(dYi ), the result follows immediately by an application of (ii) in Proposition\n3.1 and Corollary 3.1. Statement (iii) follows by first applying (i) to P\u0303(dN |\u03c1, \u03b7, \u03b8 + n) in (72) and then\napplying (ii) to P(dN |e\u2212vh \u03c1, \u03b7).\n\nremark 19. A clear distinction between a Poisson law P(dN |\u03c1, \u03b7) and the law on N defined as\nP\u0303(dN |\u03c1, \u03b7, \u03b8) was used above. This distinction was made because the conditions and techniques used to\nderive the results were slightly different. Hereafter, for some brevity, the notation \u03b8 will be used for all\nobjects. When \u03b8 is set equal to zero (when applicable) this will correspond to results for the Poisson based\nlaws of N , \u03bc, and P and their corresponding mixing laws.\n\nCorollary 5.1 (Mixture representations for \u03bc) The results (i),(ii), (iii) in Theorem 5.1 imply analogous\nresults for P\u0303(d\u03bc|\u03c1, \u03b7, \u03b8) and P(d\u03bc|\u03c1, \u03b7).\n(i)For \u03b8 > 0,\nZ \u221e\nP\u0303(d\u03bc|\u03c1, \u03b7, \u03b8) :=\nP(d\u03bc|e\u2212vh \u03c1, \u03b7)\u03c0\u03b8 (dv|\u03c1, \u03b7)\n0\n\n(ii) For n \u2265 1 and \u03b8 + n > 0, including \u2212\u03b1 < \u03b8 \u2264 0, Statement (ii) and (iii) in Theorem 5.1 implies that,\nfor each n > 0 the random measures \u03bc with distribution P(d\u03bc|\u03c1, \u03b7) or P\u0303(d\u03bc|\u03c1, \u03b7, \u03b8) can be represented as,\nn(p)\n\n(87)\n\n\u03bc\u2217 +\n\nX\n\nh(Jj,n )\u03b4Yj\u2217 ,\n\nj=1\n\nwhere \u03bc\u2217 |V, p is P(d\u03bc|e\u2212vh \u03c1), and (Jj,n , Yj\u2217 )|V, p are conditionally independent of \u03bc\u2217 with distribution\nIP(dJ, dY\u2217 |e\u2212vh \u03c1, \u03b7). The distribution of V, p is \u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7).\n(iii) Equivalently these results yield the following expressions for the respective Laplace functionals. For \u03b8 > 0,\nZ \u221e\n(88)\nL\u03bc (g|\u03c1, \u03b7, \u03b8) :=\nL\u03bc (g|e\u2212vh \u03c1)\u03c0\u03b8 (dv|\u03c1, \u03b7),\n0\n\n\f30\n\nPoisson Process Calculus\n\nand for \u03b8 + n > 0,n \u2265 1,\n(89)\n\nL\u03bc (g|\u03c1, \u03b7, \u03b8) :=\n\nXZ\n\n\u221e\n\nL\u03bc (g|e\u2212vh \u03c1, \u03b7, p)\u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7),\n\n0\n\np\n\nwhere\nL\u03bc (g|e\u2212vh \u03c1, \u03b7, p) :=\n\nZ\n\nn(p)\n\nL\u03bc (g|e\u2212vh \u03c1, \u03b7, Y)\n\nY n(p)\n\nY\n\nIP(dYj\u2217 |e\u2212vh \u03c1, \u03b7)\n\nj=1\n\nSetting \u03b8 = 0 in (89) yields an identity for the Laplace functional of P(d\u03bc|\u03c1, \u03b7).\nNow mixture representations for P are given. First set,\np\u2217n :=\n\n\u03bc\u2217 (Y)\nT\u2217\n:=\nP\nP\nn(p)\nn(p)\n\u03bc\u2217 (Y) + j=1 h(Jj,n )\nT \u2217 + j=1 h(Jj,n )\n\nand define a random probability measure as\n\nP \u2217 (*) :=\n\n\u03bc\u2217 (*)\n\u03bc\u2217 (*)\n.\n:=\n\u2217\n\u03bc (Y)\nT\u2217\n\nProposition 5.2 (Mixture representations for random probability measures)\n(i) If \u03b8 > 0 then the random probability measure,\nZ \u221e\n(90)\nP\u0303(dP |\u03c1, \u03b7, \u03b8) :=\nP(dP |e\u2212vh \u03c1, \u03b7)\u03c0\u03b8 (dv|\u03c1, \u03b7)\n0\n\n(ii) If P is P\u0303(dP |\u03c1, \u03b7, \u03b8) or P(dP |\u03c1, \u03b7) then for each n \u2265 1 and \u03b8 + n > 0, it is equivalent in distribution to\nthe random probability measure\nPn(p)\n\u2217\nj=1 h(Jj,n )\u03b4Yj (*)\n\u2217 \u2217\n\u2217\n(91)\npn P (*) + (1 \u2212 pn ) Pn(p)\nj=1 h(Jj,n )\nwith distribution specified by statement (ii) Corollary 5.1.\n\n5.2\n\nDuality of mixture representations and posterior distributions\n\nIn this section Y1 , . . . , Yn |P are iid random variables with distribution P . That is, this implies the joint model\nQ\nfor Y|P , is ni=1 P (dYi ). The law of P is either P(dP |\u03c1, \u03b7) or P\u0303(dP |\u03c1, \u03b7, \u03b8). The interest is in obtaining\nposterior distributions of N , \u03bc and hence P and relevant information about the marginal structure of Y.\nDefine a conditional distribution of V |Y as,\n\uf8f9\n\uf8ee\nn(p)\nY\n\u03baej,n (e\u2212vh \u03c1|Yj\u2217 )\uf8fb \u03c0\u03b8+n (dv)\n(92)\n\u03c0\u03b8+n (dv|p, Y\u2217 ) \u221d \uf8f0\nj=1\n\nwhen \u03c1 does not depend on y, then the distribution of V |Y only depends on p and (92) reduces to\n\uf8f9\n\uf8ee\nn(p)\nY\n\u03baej,n (e\u2212vh \u03c1)\uf8fb \u03c0\u03b8+n (dv).\n\u03c0\u03b8+n (dv|p, Y\u2217 ) \u221d \uf8f0\n(93)\nj=1\n\n\fJames\n\n31\n\nTheorem 5.2 (i) The marginal distribution of Y is\n\uf8f9\n\uf8ee\nZ \u221e n(p)\nY\n\uf8f0\nIP(dYj\u2217 |e\u2212vh \u03c1, \u03b7)\uf8fb \u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7).\n(94)\n\u03c0(dY) :=\n0\n\nj=1\n\nThis implies that the quantity \u03c0\u03b8+n,\u03b8 (p|\u03c1, \u03b7) is an EPPF. When \u03c1 does not depend on y then the marginal\ndistribution of Y is expressible as\nn(p)\n\n(95)\n\n\u03c0(dY) := \u03c0\u03b8+n,\u03b8 (p|\u03c1, \u03b7)\n\nY\n\nH(dYj\u2217 ).\n\nj=1\n\n(ii) Statement (i) combined with Theorem 5.1 imply that the posterior distribution of N , \u03bc given Y is identical\nto the mixtures,\nZ\nZ\n\u2212vh\n\u2217\n\u2217\n(96)\nP(d\u03bc|e\u2212vh \u03c1, \u03b7, Y\u2217 )\u03c0\u03b8+n (dv|p, Y\u2217 )\nP(dN, dJ|e\n\u03c1, \u03b7, Y )\u03c0\u03b8+n (dv|p, Y );\nR+ \u00d7S n(p)\n\nR+\n\nrespectively.\n(iii) Statement (ii) implies that the posterior distribution of P is determined by either of the laws in (96).\nCombined with the mixture representations this implies that the distribution of P given Y is equivalent to\nthe distribution of the random measure\nPn(p)\n\u2217\nj=1 h(Jj,n )\u03b4Yj (*)\n\u2217 \u2217\n\u2217\npn P (*) + (1 \u2212 pn ) Pn(p)\n(97)\nj=1 h(Jj,n )\n\nwhere the distributions of \u03bc\u2217 and (Jj,n ) given V ,Y is specified by P(d\u03bc|e\u2212vh \u03c1, \u03b7, Y\u2217 ) and V |Y is \u03c0\u03b8+n (dv|p, Y\u2217 )\n\nProof. Given the mixture representations in Theorem 5.1, the result follows by an appeal to Fubini's\ntheorem which identifies the posterior laws of N ,\u03bc, P as mixtures relative to the marginal distribution of\nR\nY. That is, for instance P(dN ) := Y n P(dN |Y)\u03c0(dY). (More formally one could evaluate the Laplace\nfunctional of N on both sides). Hence it suffices to identify the marginal distribution of Y and then apply\na simple algebraic rearrangement in the mixture representations of N given in statements (ii) and (iii) of\nTheorem 5.1. The identification of \u03c0(dY) is straightforward.\nThe conclusion that \u03c0\u03b8+n,\u03b8 (p|\u03c1, \u03b7) is an EPPF perhaps requires further discussion as the technique I\nused may be a bit unfamiliar. Essentially from the theory of exchangeability if Y1 , . . . , Yn |P are iid P then\nthe marginal distribution of Y = (Y\u2217 , p) is exchangeable. Hence once the unique values Y\u2217 are exposed an\nintegration with respect to \u03b7 leaves only a marginal dsitribution of p which must be an EPPF regardless\n\u2217\nof whether or not the unique {Y1\u2217 , . . . , Yn(p)\n} are iid H. That is regardless of whether or not P is a species\nsampling model as described in Pitman (1996). What is lost is the 1-1 correspondence between (p, H) and the\nrandom probability measure P . For instance, it is conceivable that the EPPF P D(p|\u03b1, \u03b8) could be embedded\n\u2217\nin a model P which is not P\u03b1,\u03b8 (dP |H). In that case the Y1\u2217 , . . . , Yn(p)\ncannot be iid H. In other words an\nEPPF can always be found by working with a P model, finding the joint marginal distribution of Y, and\nthen marginalizing over the unique values. This is obvious when P is a species sampling model. However, it\nis a simple matter to verify the addition rules given in Pitman (1995a,b, 1996) for an EPPF by applying the\nBayesian idea of a prediction rule. In particular for each n evaluate,\nE[P (Y)|Y] := E[p\u2217n |Y] + E[(1 \u2212 p\u2217n )|Y] := 1.\nProper manipulation of the middle expression will yield the obvious rules.\n\n\f32\n\nPoisson Process Calculus\n\n5.3\n\nResults for P D(\u03b1, \u03b8)\n\nA description of the PD\u03b1,\u03b8 (d\u03bc|\u03b7) laws is now given. Throughout this section the notation \u03bcL , TL etc will be\nused to denote the (conditional law) of \u03bc, T depending on a random variable L.\n5.3.1\n\nDistributional properties of PD\u03b1,\u03b8 (d\u03bc|\u03b7)\n\nCorollary 5.2 (i) If N is P(dN |\u03c1\u03b1 , \u03b7) and h(s) := s, then for \u03b8 > 0, P\u0303(dN |\u03c1\u03b1 , \u03b7, \u03b8) is such that N |V = is\na Poisson random measure with intensity,\n\u03c1\u03b1,v (ds)\u03b7(dy) := e\u2212vs \u03c1\u03b1 (ds)\u03b7(dy)\n\n(98)\n\ncorresponding to the L\u00e9vy measure of a generalised gamma process. The density of V is\n\u03c4\u03b8 (dv|\u03c1) :=\n\n(99)\n\n\u03b1\n1\nv \u03b8\u22121 e\u2212Kv dv.\nc\u03b1,\u03b8 \u0393(\u03b8)\n\nBy a change of variable the distribution of L := V \u03b1 has a gamma distribution with parameters ( \u03b1\u03b8 , K), That\nis, L is G( \u03b1\u03b8 , K). The factor K is determined in part by the total mass of \u03b7. It can be dispensed with by\nre-scaling.\n\nremark 20. Now the connection to Pitman and Yor (1992, section 3, p. 335-336) should be more\ntransparent.[See also Pitman and Yor (2001, Theorem 3)]. The exponential law arises by setting K = 1(or\nby rescaling L) and the choice of \u03b8 = \u03b1.\n\nProposition 5.3 Corollary 5.2 implies that the distribution of PD\u03b1,\u03b8 (d\u03bc|\u03b7) with respect to the mixing distribution of L is,\nZ \u221e\nPD\u03b1,\u03b8 (d\u03bc|\u03b7) :=\nP(d\u03bc|\u03c1\u03b1,L1/\u03b1 , \u03b7)G(dL|\u03b8/\u03b1, K)\n(100)\n0\n\nIn other words \u03bc|L is a generalized gamma random measure with L\u00e9vy measure \u03c1\u03b1,L1/\u03b1 (ds)\u03b7(dy) and L is\na gamma random variable with parameters ( \u03b1\u03b8 , K). When K = 1 and \u03b8 = \u03b1, L is a standard exponential\nrandom variable. The Laplace functional of PD\u03b1,\u03b8 (d\u03bc|\u03b7) can be expressed as,\nZ\nZ \u221e\n\u2212\u03bc(g)\n(101)\ne\nPD\u03b1,\u03b8 (d\u03bc|\u03b7) :=\nL\u03bc (g|L, \u03b1)G(dL|\u03b8/\u03b1, K)\n0\n\nM\n\nwhere\n1\n\u2212\u03b1\n\nL\u03bc (g|L, \u03b1) := e\n\nR\n\nY\n\n1\n\n\u03b1\n\n(g(y)+L \u03b1 ) \u03b7(dy) KL\n\ne\n\nis the conditional Laplace functional of \u03bc given L.\n(ii) Furthermore, suppose that conditioned on L, \u03bc is multiplied by L1/\u03b1 . Then the unconditional law of\nL1/\u03b1 \u03bcL is given by its Laplace functional,\n(102)\n\nE[e\u2212L\n\n1/\u03b1\n\n\u03bcL (g)\n\n] :=\n\nZ\n\n\u221e\n\nL\u03bc (L1/\u03b1 g|L, \u03b1)G(dL|\u03b8/\u03b1, K) :=\n\n0\n\n(iii) Statement (ii) implies that the distribution of L1/\u03b1 TL is G(\u03b8).\n\n\u0014Z\n\nY\n\n\u0015\u2212\u03b8/\u03b1\n\u03b1\n(g(y) + 1) H(dy)\n\n\fJames\n\n33\n\nremark 21. Statement (iii) should be compared with T of Pitman and Yor (1997, Proposition 21).\nNote that the explicit expression for the Laplace functional in (ii) is obtained via Brix's (1999) expression\nfor the generalised gamma measure.\nNow noting that,\nn(p)\n\nn(p)\n\nY\n\n(103)\n\n\u03baej,n (e\u2212vh \u03a9) := v \u2212(n\u2212n(p)\u03b1) \u03b7(Y)n(p)\n\nY\n\n\u0393(ej,n \u2212 \u03b1),\n\nj=1\n\nj=1\n\nthe results below are easily deduced.\nProposition 5.4 (i) For all \u03b8 > \u2212\u03b1 and n \u2265 1, the PD\u03b1,\u03b8 (d\u03bc|\u03b7) law is representable as the random\nmeasure,\nn(p)\nX\n(104)\nJj,n \u03b4Yj\u2217 (*)\n\u03bc\u2217 (*) +\nj=1\n\n\u2217\n\nwhere \u03bc given a random variable L is a generalised gamma random measure with intensity \u03c1\u03b1,L1/\u03b1 (ds)\u03b7(dy).\nThe (Jj,n ) given (L, Y\u2217 ) are independent of \u03bc\u2217 with respective Gamma distributions G(ej,n \u2212 \u03b1, L1/\u03b1 ). L\ngiven p is G(n(p) + \u03b8/\u03b1, K) for some constant K. In particular by cancellation one can set K = \u03b1 or K = 1.\n\u2217\n} are iid \u03b7(*)/\u03b7(Y) := H(*).\nConditionally independent of L, {Y1\u2217 , . . . , Yn(p)\n(ii) The distribution of p is the EPPF, P D(p|\u03b1, \u03b8). In addition the marginal law of \u03bc\u2217 |p is PD\u03b1,\u03b8+n(p)\u03b1 (d\u03bc|\u03b7),\nwhich follows since similar to (101) its Laplace functional is\nZ \u221e\n(105)\nL\u03bc (g|L, \u03b1)G(dL|n(p) + \u03b8/\u03b1, K)\n0\n\n(iii) Hence the random probability measure\n\u03bc\u2217 (*)\n\u03bc\u2217 (Y)\ngiven p is PD\u03b1,\u03b8+n(p)\u03b1 (dP |H). Denote the random probability measure with this law as P\u03b1,\u03b8+n(p)\u03b1 .\n(iv) Given L, p, the random variables Gj,n := L1/\u03b1 Jj,n are independent G(ej,n \u2212 \u03b1) independent of L and\n\u03bc\u2217 . Moreover given p the distribution of L1/\u03b1 \u03bc\u2217L is given by the Laplace functional\n\u0014Z\n\nY\n\n\u0015\u2212(\u03b8+n(p)\u03b1)/\u03b1\n\u03b1\n(g(y) + 1) H(dy)\n\nand L1/\u03b1 TL\u2217 given p has distribution G(\u03b8 + n(p)\u03b1)\n\nremark 22. Suppose that K = 1, and n = 1, then in particular for the stable case PD\u03b1,0 (d\u03bc|\u03b7), it\nfollows that L is exponential (1). For the PD\u03b1,\u03b1 (d\u03bc|\u03b7), L is G(2, 1).\n5.3.2\n\nIdentities for P D(\u03b1, \u03b8)\n\nThe propositions above are now applied to derive an alternate representation for the distribution of the\ngeneral P D(\u03b1, \u03b8) and related models. This, in particular generalizes the right-hand side of the construction\nof a P D(\u03b1, \u03b1) model given in Pitman and Yor (2001, Example 8, eq. (33)) to previously unknown ones for\nthe general P D(\u03b1, \u03b8) model.\n\n\f34\n\nPoisson Process Calculus\nNotice that using the change of variable u = vs, e\u2212vs \u03c1\u03b1 (ds) transforms to the Levy measure\nv \u03b1 e\u2212u \u03c1\u03b1 (du)\n\n(106)\n\nwhich yields the equivalence of the sets\nZ \u221e\nZ\n(107)\n{y :\ne\u2212vs \u03c1\u03b1 (ds) \u2264 x} := {u :\ny\n\ne\u2212s \u03c1\u03b1 (ds) \u2264 x/v \u03b1 }.\n\nu\n\nDefine,\n\u039b\u22121 (x) := inf{u :\n\n(108)\n\n\u221e\n\nZ\n\n\u221e\n\ne\u2212s \u03c1\u03b1 (ds) \u2264 x},\n\nu\n\nPj\n\nand set \u0393j := i=1 Ei for (Ei ) a collection of independent standard exponential random variables. In additon\ndefine for all \u03b8 > 0\n\u221e\nX\n(109)\n\u039b\u22121 (\u0393j /L)\n\u03a3\u03b8/\u03b1 :=\nj=1\n\nwhere L is a G(\u03b8/\u03b1) random variable, independent of (Ei ). Now using the change of variable L = V \u03b1 , (107)\nand Proposition 5.3, 5.4, it is easy to see from an application of Khintchine's (1937) Inverse L\u00e9vy method,[see\nalso Ferguson and Klass (1972), Wolpert and Ickstadt (1998b), Sato (1999), Rosinski (2001), and Banjevic,\nIshwaran and Zarepour (2002)], that the following identities hold;\nProposition 5.5 (Distributional representations for P D(\u03b1, \u03b8)) Choose 0 < \u03b1 < 1,\n(i) then for \u03b8 > 0,the distribution of the sequence\n\n(110)\n\n(\u039b\u22121 (\u0393j /L)/\u03a3\u03b8/\u03b1;\n\nj = 1, 2, . . .),\n\nis P D(\u03b1, \u03b8).\n(ii) Let (Zj ) denote an iid sequence with distribution H chosen idependently of L and (Ej ). If \u03b8 > 0, then\nequivalent to (i), the random probability measure,\n(111)\n\nP\u03b1,\u03b8 (*) :=\n\n\u221e\nX\n\u039b\u22121 (\u0393j /L)\nj=1\n\n\u03a3\u03b8/\u03b1\n\n\u03b4Zj (*)\n\nis PD\u03b1,\u03b8 (dP |H).\n(iii) For all \u03b8 > \u2212\u03b1 and n \u2265 1, a PD\u03b1,\u03b8 (dP |H) random probability measure is representable as,\nPn(p)\n\u2217\n\u03a3n(p)+\u03b8/\u03b1\nj=1 Jj,n \u03b4Yj (*)\nP\u03b1,\u03b8 (*) :=\n(112)\nP\u03b1,\u03b8+n(p)\u03b1 (*) +\nPn(p)\nPn(p)\n\u03a3n(p)+\u03b8/\u03b1 + j=1 Jj,n\n\u03a3n(p)+\u03b8/\u03b1 + j=1 Jj,n\nP\u221e\nwhere, for clarity, \u03a3n(p)+\u03b8/\u03b1 := j=1 \u039b\u22121 (\u0393j /L). L|p is gamma distributed with parameters (n(p)+ \u03b8/\u03b1, 1),\n(Jj,n )|L, p are respectively independent G(ej,n \u2212 \u03b1, L1/\u03b1 ) and (Yj\u2217 )|p are iid H. Note that (Jj,n ) are not\nindependent of \u03a3n(p)+\u03b8/\u03b1\nNow to obtain another representation of P\u03b1,\u03b8 , which also serves to directly recover Pitman's (1996)\ndescription of the posterior distribution. Notice from Proposition 5.3 and 5.4 that given p the following\nequivalence in distribution holds for each n \u2265 1;\n(113)\n\nG\u03b8+n(p)\u03b1\nL1/\u03b1 TL\n:=\n.\nPn(p)\nPn(p)\n1/\u03b1\n1/\u03b1\nL TL + L\nG\u03b8+n(p)\u03b1 + j=1 Gj,n\nj=1 Jj,n\n\n\fJames\n\n35\n\n[This is also true for n=0 by Proposition 5.3] The key point is that the quantity above is independent of the\nmixing distribution on L for all n. Moreover, L1/\u03b1 TL := G\u03b8+n(p)\u03b1 is G(\u03b8 + n(p)\u03b1) and independent of the\ngamma random varibles (Gj,n ) as defined in Proposition 5.4. Hence the following result,\nProposition 5.6 For all \u03b8 > \u2212\u03b1,\nP\u03b1,\u03b8 (*) := pn P\u03b1,\u03b8+n(p)\u03b1 (*) + (1 \u2212 pn )\n\n(114)\nwhere\n\npn :=\n\nPn(p)\n\nj=1 Gj,n \u03b4Yj\nPn(p)\nj=1 Gj,n\n\n\u2217\n\n(*)\n\nG\u03b8+n(p)\u03b1\n.\nPn(p)\nG\u03b8+n(p)\u03b1 + j=1 Gj,n\n\nGiven p the quantity above does not depend on the mixing distribution L. Hence given Y = (Y\u2217 , p) the posterior distribution of a P which is PD\u03b1,\u03b8 (dP |H) is immediately seen to be equivalent to the random measure\non the right of (114) when (Yj\u2217 ) and p are fixed. This corresponds exactly with the posterior distribution\ndescribed in Pitman (1996)\n\nremark 23. It is certainly obvious that one could use Pitman's (1996) posterior characterization\nto obtain the simple mixture representation in proposition 5.6. The main point however is really how the\nprevious descriptions (which are less obvious) led up to this result. Moreover, none of the arguments appealed\nto the stick-breaking representation of PD\u03b1,\u03b8 (dP |H).\n\nremark 24. The analysis of the P D(\u03b1, \u03b8) models revealed various independence structures via a\nsimple transformation. In general this will not be the case but there are certainly many instances where an\nappropriate transformation of the (Jj,n ) will render them independent of \u03bc\u2217 and the mixing distribution\non V . Such an operation should simplify the analysis. One might try this with the intensities described in\nPitman and Yor (2001).\nremark 25. I wonder what if any interpretation does an adjustment to the left hand-side of Pitman\nand Yor (2001, Theorem 3, eq. (19)) have when \u01eb0 is replaced by what one might guess from Proposition 5.3\nto be a G(\u03b8/\u03b1) random variable\n5.4\n\nResults for the Dirichlet Process and generalised gamma process\n\nResults for the gamma process with shape \u03b7(*) := \u03b8H(*), that is PD0,\u03b8 (d\u03bc|\u03b7), follow by using \u03c10,1 in place\nof \u03c1\u03b1 . In this case T is G(\u03b8), and\nn(p)\n\nn(p)\n\n(115)\n\nY\n\nj=1\n\n\u03baej,n (e\u2212vh \u03a9) := (1 + v)\u2212n \u03b8n(p)\n\nY\n\nj=1\n\nWhich yields readily,\nProposition 5.7\n(116)\n\n\u03c0n;0 (dv, p) := P D(p|\u03b8)\u03c4\u03b8;n (dv)\n\n\u0393(ej,n ).\n\n\f36\n\nPoisson Process Calculus\n\nwhere\n\u2212(n+\u03b8) n\u22121\n\n(117)\n\n\u03c4\u03b8;n (dv) :=\n\n\u0393(\u03b8 + n)(1 + v)\n\u0393(\u03b8)\n\nv\n\ndv\n\nwhich implies that V and p are independent. Note the density \u03c4\u03b8;n (dv) is well defined provided \u03b8 > 0.\n(ii) The (Jj,n )|V, p are independent G(ej,n , 1 + V ) and the distribution of \u03bc\u2217 |V, p is a (simple) weighted\ngamma process, i.e. has intensity \u03c10,1+V \u03b8H, and is independent of p.\n(iii) Hence it follows that given V and p\n\uf8ee\n\nn(p)\n\n(V + 1) \uf8f0\u03bc\u2217 (*) +\n\n(118)\n\nX\nj=1\n\n\uf8f9\n\nJj,n \u03b4Yj\u2217 \uf8fb\n\nis a mixture of gamma processes independent of V . That is additionally given Y\u2217 , the measure in (118) is\nPn(p)\na gamma process with shape \u03b8H(*) + j=1 ej,n \u03b4Yj\u2217 (*). This fact serves to recover the well-known result of\nFerguson (1973) for the posterior distribution of the Dirichlet process.\n\nremark 26. It is not so surprising that the gamma/Dirichlet model is such that the mixing distribution V and p are independent. It is also perhaps true, given the properties of P D(\u03b8), that this is the only\nspecies sampling model with this property.\nThe arguments above may be applied to the generalised gamma model with intensity \u03c1\u03b1,b . In this case,\nfrom section 3, it follows that,\nn(p)\n\nn(p)\n\n(119)\n\nY\n\n\u03baej,n (e\u2212vh \u03a9) := (v + b)\u2212(n\u2212n(p)\u03b1) \u03b8n(p)\n\nY\n\n\u0393(ej,n \u2212 \u03b1)\n\nj=1\n\nj=1\n\nwhere it is assumed that \u03b7(Y) := \u03b8. This leads to, a joint density of V, p specified as\n\uf8ee\n\n\uf8f9\n\nn(p)\n\n(120)\n\n\u03b8n(p) \uf8f0\n\nY\n\nj=1\n\n\u0393(ej,n \u2212 \u03b1)\uf8fb\n\n(v + b)\u2212n+n(p)\u03b1 v n\u22121 e\u2212[(v+b)\n\u0393(n)\n\n\u03b1\n\n\u2212b\u03b1 ]K\n\ndv\n\nIn addition the (Jj,n )|V, p are G(ej,n \u2212 \u03b1, b + V ) and \u03bc\u2217 |V, p is a generalised gamma process with L\u00e9vy\nmeasure \u03c1\u03b1,b+V . Hence (b + V )Jj,n are G(ej,n \u2212 \u03b1). The Laplace functional of (V + b)\u03bc\u2217 |V, p is\n(121)\n\ne\n\n1\n\u2212\u03b1\n(v+b)\u03b1\n\nR\n\nY\n\n[(g(y)+1)\u03b1 \u22121]\u03b7(dy)\n\nremark 27. In order to incorporate larger classes of models for P one could use a weighted Poisson\nlaw\n(122)\n\nQ(dN |\u03c1, \u03b7) :=\n\nw(N )P(dN |\u03c1, \u03b7)\nE[w(N )]\n\nfor an arbitrary integrable function w. This will be used in Section 8.\n\n\fJames\n\n6\n\n37\n\nDistributions of joint linear functionals of P; variations of the\nMarkov-Moment problem\n\nThis section is a continuation of the previous one. Here, it is shown that the joint Cauchy-Stieltljes transform\nof linear functionals of P , which are P\u0303(dP |\u03c1, \u03b7, \u03b8) and P(dP |\u03c1, \u03b7), is equivalent to expressions involving the\nLaplace functional of random measures V \u03bcV . The precise meaning of V \u03bcV will be clear from the context\nbelow. The method of proof, given the results in the the previous section, is an easy extension of the beautiful\napproach used by Tsilevich, Vershik and Yor (2000) for the Dirichlet process and the general P\u03b1,\u03b8 (dP |H)\nfamily. The results given here represents the most general ones that I know of. More importantly the explicit\nrelationship between P and V \u03bcV is a new insight. See Kerov (1998) for many implications of this type of\nresult.\nR\nLet fl denote real-valued functions on Y and define P fl = Y fl (y)P (dy) for l = 1, . . . , q. In addition let\nzl for l = 1, . . . , q denote non-negative scalars. In this section the calculation of the following transform(in\nrelation to Laplace functionals of V \u03bcV ) is discussed;\nZ\n1\nPq\n(123)\nP\u0303(dP |\u03c1, \u03b7, \u03b8)\nM\u2217 1 +\nl=1 zl P fl\n\nfor all \u03b8 > \u2212\u03b1. Again when \u03b8 = 0 this coincides with the P(dP |\u03c1, \u03b7) laws. The quantity characterizes the\njoint distribution of (P f1 , . . . , P fq ). Kerov and Tsilevich (1998) in the case of P\u03b1,\u03b8 (dP |H) used combinatorial\narguments to obtain the moment expressions in the case of the Dirichlet and two-parameter models to yield\nextensions of the Markov-Krein identity for (P f1 , . . . , P fq ). Their results extend the work of Cifarelli and\nR\nRegazzini (1990) for the case of the distribution of the mean functional, yP (dy), when P has a Dirichlet\nprocess law. The mean case is also discussed in Diaconis and Kemperman (1996) where in addition the result\nfor the joint distribution of functionals like (P f1 , . . . , P fq ) was proposed as an open problem. Tsilevich (1997)\nestablishes the case for the mean with respect to the general two-parameter processes. These results used hard\nanalytic techiques which would not be easily extendable to a general scenario. However, recently Tsilevich,\nVershik and Yor (2000) devise a beautiful simple proof of the corresponding result in the case of the Dirichlet\nprocess and the general two-parameter extension via Laplace functionals. Given the results in section 5.1 it\nis a simple matter to extend their result to the general class of probability measure P\u0303(dP |\u03b7, \u03c1, \u03b8). That is,\nfollowing closely their approach, relationships between and the Laplace functional of V \u03bcV are established.\nThe results below follow by rewriting\n1+\nand applying Corollary 5.1.\n\n6.1\n\n1\nPq\n\nl=1 zl P fl\n\n:=\n\nT+\n\nT\nPq\n\nl=1 zl \u03bc(fl )\n\nJoint Cauchy-Stieltjes transforms and Laplace functionals\n\nProposition 6.1 For \u03b8 > 0,\n(124)\nwhere\n\nZ\n\n1+\nM\u2217\n\nq\nX\nl=1\n\nzl P fl\n\n!\u2212\u03b8\n\nq\nX\nP\u0303(dP |\u03c1, \u03b7, \u03b8) := LV \u03bcV (\nzl fl |\u03c1, \u03b7, \u03b8)\nl=1\n\nZ\nq\nX\nLV \u03bcV (\nzl fl |\u03c1, \u03b7, \u03b8) :=\nl=1\n\n0\n\n\u221e\n\nL\u03bc (v\n\nq\nX\nl=1\n\nzl fl |e\u2212vh \u03c1, \u03b7)\u03c0\u03b8 (dv|\u03c1, \u03b7)\n\n\f38\n\nPoisson Process Calculus\n\nProposition 6.2 For \u03b8 + n > 0 and n \u2265 1,\n(i)\nZ\n\nM\u2217\n\n1+\n\nq\nX\n\nzl P fl\n\nl=1\n\n!\u2212(\u03b8+n)\n\nP\u0303(dP |\u03c1, \u03b7, \u03b8) :=\n\nXZ\n\n\u221e\n\nL\u03bc (v\n\n0\n\np\n\nq\nX\n\nzl fl |e\u2212vh \u03c1, \u03b7, p)\u03c0\u03b8+n,\u03b8 (dv, p|\u03c1, \u03b7)\n\nl=1\n\n(ii) The expressions in (i) are equal to;\nXZ\np\n\nY n(p)\n\n\"Z\n\n\u221e\n\nL\u03bc (v\n\n0\n\nq\nX\n\n#\n\nzl fl |e\u2212vh \u03c1, \u03b7, p, Y\u2217 )\u03c0\u03b8+n,\u03b8 (dv|\u03c1, \u03b7, p, Y\u2217 ) \u03c0(dY)\n\nl=1\n\nwhich indicates that the posterior Cauchy-Stieltjes transform,\nZ\n\n1+\n\nM\u2217\n\nq\nX\nl=1\n\nzl P fl\n\n!\u2212(\u03b8+n)\n\nP\u0303(dP |\u03c1, \u03b7, \u03b8, Y)\n\nis equal to,\nZ\n\n(125)\n\n\u221e\n\nL\u03bc (v\n\n0\n\nq\nX\n\nzl fl |e\u2212vh \u03c1, \u03b7, p, Y\u2217 )\u03c0\u03b8+n,\u03b8 (dv|\u03c1, \u03b7, p, Y\u2217 )\n\nj=1\n\nNote again the various relationships to the (posterior) laws of V \u03bcV .\nNow setting g(y) :=\nyields,\n\nPq\n\nl=1 zl fl (y)\n\nin the Laplace transform of L1/\u03b1 \u03bcL in statement (ii) of Proposition (5.3)\n\"Z\n\nY\n\n#\u2212\u03b8/\u03b1\n\u03b1\nq\nX\nzl fl (y) + 1) H(dy)\n(\nl=1\n\nHence the result of Tsilevich, Vershik and Yor (2000) for the P\u03b1,\u03b8 (dP |H) family is recovered. However the\nrelationship to L1/\u03b1 \u03bcL is not noted in their work.\n\n6.2\n\nA remark on moment calculations\n\nAs mentioned previously, Kerov and Tsilevich (1998) used nontrivial combinatorial arguments to calculate\nthe joint moments of (P f1 , . . . , P fq ) in the case of P\u03b1,\u03b8 (dP |H). Here similar to Ishwaran and James (2001a)\nfor species sampling models it is demonstrated that one can easily obtain the relevant moment calculations\nby using Theorem 5.2. This calculation will only be presented for the case where \u03c1 does not depend on y,\nThe task is to calculate\n\" q\n# Z \" q n Z\n#\nl\nY\nYY\nE\n(P fl )nl =\nfl (yi,l ) P (dyi,l ) P\u0303(dP |\u03c1, \u03b7, \u03b8)\nM\n\nl=1\n\nl=1 i=1\n\nY\n\nNow analogous to (41) an application of Theorem 5.2 yields the result\n(126)\n\nE\n\n\" q\nY\n\nl=1\n\nnl\n\n(P (fl ))\n\n#\n\n=\n\nX\np\n\n\u03c0\u03b8+n,\u03b8 (p|\u03c1, \u03b7)\n\nn(p) Z\n\nY\n\nj=1\n\nY\n\n\" q\nY\n\nl=1\n\nfl\n\nelj,n\n\n#\n\n(u) H(du)\n\n\fJames\n\n7\n\n39\n\nPosterior Calculus for Extended Neutral to the Right processes\n\nIn this section I focus on the concept of neutral to the right processes(NTR) originally proposed in Doksum\n(1974). The Dirichlet process is the most notable member of this class. Here, a new natural extension\nof the NTR concept to more abstract spaces is given. It is then shown how Proposition 3.1 can be used\nto yield the most transparent and simplest posterior analysis of such models. This includes the case of\nsurvival data models subject to right censoring when a NTR prior is used or synonymously when L\u00e8vy\nprocess priors are used to model the cumulative hazard. Additionally, using Proposition 3.1 a change of\nmeasure formula is established which relates Beta/Dirichlet processes to their more complex Beta/BetaNeutral(Stacy) generalizations.\n\nremark 28. Doksum (1974, Theorem 3.1) establishes essentially a 1-1 correspondence between NTR\nprocesses and exponential functions of subordinators. See below for explict details. This fact seems not to\nbe widely noticed by probabilists investigating problems where models under the latter description arise.\nOne consequence is that the calculus that is described below for NTR's can be exploited in other areas\nbesides Bayesian nonparametrics. Here I will omit the drift component. It is a simple matter to make\nadjustments starting from the obvious modification of Lemma 2.1. (see Remark 2). Doksum (1974, Corollary\n3.2), establishes the almost sure discreteness of NTR's under the condition that the drift component is zero.\nremark 29. The notation \u039b will be used in this section to denote a random cumulative hazard\nmeasure. The dependence of quantities F0 , A0 on \u03c1, \u03b7 will be supressed. The arguments (s),(t) will be used\nto denote time as is usual in survival analysis. The argument (u) plays the role of (s) in the previous sections.\nFirst the orginal definition proposed by Doksum is given\n\nDefinition 1. (Doksum (1974)) A random distribution function F on the positive real line is said\nto be neutral to the right if for each k > 1 t1 < t2 . . . < tk , there exists non-negative independent random\nvariables V1 , . . . , Vk such that the vectors satisfy,\n(127)\n\nL{(F (t1 ), F (t2 ) \u2212 F (t1 ), F (tk ) \u2212 F (tk\u22121 ))} = L{(V1 , V2 (1 \u2212 V1 ), . . . , Vk\n\nk\nY\n\n(1 \u2212 Vi ))},\n\nj=1\n\nwhere L denotes the law.\nIn the special case where F is a Dirichlet process with shape \u03b8F0 (*) then each increment F (tk ) \u2212 F (tk \u2212\n1) is B(\u03b8F0 ((tk\u22121 , tk ]); \u03b8[1 \u2212 F0 ((tk\u22121 , tk ]). Doksum discusses various equivalences and implications of this\ndefinition. From Theorem 3.1 of Doksum it follows that F is a NTR process if and only if for t \u2265 0,\n(128)\n\nS(t) = 1 \u2212 F (t) = e\u2212Z(t) ,\n\nwhere Z is an increasing Levy process satisfying Z(0) = 0 and limn\u2192\u221e Z(t) = \u221e . The analysis here will\nconsider subordinators Z without a drift component. In other words Z, is a completely random measure on\n(0, \u221e) with associated intensity \u03c1z (du|y)\u03b7(dy) for (u, y) \u2208 (0, \u221e) \u00d7 (0, \u221e). Ferguson (1974) shows that a\nDirichlet process with finite shape measure, \u03b8F0 (*), results if\n(129)\n\n\u03c1z (du|y)\u03b7(dy) =\n\n1\ne\u2212u\u03b8F0 (y,\u221e) du\u03b8F0 (dy)\n1 \u2212 e\u2212u\n\n\f40\n\nPoisson Process Calculus\n\nIt follows from the theory of product integration that an NTR process can also be represented as\nS(t) =\n\n(130)\n\n(1 \u2212 \u039b(du))\nu\u2264t\n\nwhere \u039b denotes a cumulative hazard which is further modelled as a completely random measure with\nintensity \u03c1\u039b (u|y)ds\u03b7(dy) for (u, y) \u2208 (0, 1] \u00d7 (0, \u221e). The symbol , denotes the product integral which has\nplayed a primary role in survival analysis. In particular the Kaplan-Meier estimator for S, Kaplan and Meier\n(1958), is obtained by replacing \u039b by its empirical counterpart, the Nelson-Aalen estimator. See the text\nby Andersen, Borgan, Gill and Keiding (1993) for further elaboration. Gill and Johansen (1990) discuss in\ndetail the properties of the product integral. The product integral is also expressible as,\n(1 \u2212 \u039b(dv, Y)) = exp(\u2212\u039bc (t))\n\n(131)\n\nY\n\n(1 \u2212 \u039bd (v)) ,\n\n[0,t]\n\n[0,t]\n\nwhere \u039bc denotes the continuous part of \u039b. Suppressing the dependence on \u03c1, \u03b7, E[\u039b(t)] = A0 (t) where A0\ndenotes a prior cumulative hazard specification. It follows that,\n(132)\n\n(1 \u2212 E[\u039b(du)]) := e\u2212Ao (t) .\n\nE[S(t)] := 1 \u2212 F0 (t) =\nu\u2264t\n\nThe restriction of the jumps of the process to [0, 1] ensures that \u039b is an element in the space of cumulative\nhazards and hence S is a proper survival function. Hjort (1990) first proposed working directly with L\u00e9vy\npriors on the space of cumulative hazards which is more in line with the frequentist counting process analysis\nof event-history models [See Aalen(1975, 1978) and Andersen, Borgan, Gill and Keiding (1993)]. Hjort (1990)\nshows that if \u039b is specified to be a Beta process then it is a conjugate model with respect to right censoring.\nHjort (1990, section 7A), under a Beta process specification for \u039b in (130), also defines a class of generalised\nDirichlet processes on R+ . He shows that the Dirichlet process is a special case of this model by setting\nc(s) = \u03b8F0 ([s, \u221e)). In summary, Bayesian nonparametric methods for the simple survival setting subject\nto censoring have been discussed following the framework of Ferguson's (1973, 1974) (see also Freedman\n(1963) and Fabius (1964)) Dirichlet process in the works of Doksum (1974), Susarla and van Ryzin (1976),\nBlum and Susarla (1977), Ferguson and Phadia (1979), Lo (1993), Doss (1994), and Walker and Muliere\n(1997) among others. The methods discussed above operate by placing a Dirichlet or more general NTR\nprior on the unknown survival or distribtuion function. An alternative but essentially equivalent approach\ninvolves working with priors on the cumulative hazard measure discussed in Hjort (1990), Lo (1993) and most\nrecently Kim (1999). However, unlike the simplicity of the Dirichlet process discussed in Ferguson (1973,\n1974) for complete data models, the technical aspects of these models appear to be formidable. Moreover, the\ntechnical arguments used do not easily extend to more complex settings. In particular, the prior to posterior\ncharacterizations given in Ferguson and Phadia (1979)(see also Doksum (1974)), are only developed for\ndistribution functions on the real line. In addition very little is known about the marginal and partition\nbased structures. It will be shown that an alternate representation makes the calculus for NTR processes\nindeed straightforward.\nNote importantly that there is a 1-1 correspondence between each Z and \u039b. Formally, the L\u00e9vy measure\nof Z arises as the image of \u03c1\u039b (du|y)\u03b7(dy) via the map (u, y) to (\u2212 log(1 \u2212 u), y). For further discussion\nsee Dey (1999) and Dey, Erickson and Ramamoorthi (2000). An important consequence, which has not\n\n\fJames\n\n41\n\nbeen exploited in this context, is the following identity, which holds in distribution for each n where N is\nP(dN |\u03c1\u039b , \u03b7). Define for v > 0,\n(133)\nf \u0303v\u2212 (u, y) := \u2212I{v > y} log(1 \u2212 u)\nthen,\n(134)\n\n \u0303\n\nS(v\u2212) := eZ(v\u2212) := e\u2212N (fv\u2212 ) ,\n\nwhere the law of N is P(dN |\u03c1\u039b , \u03b7).\n\n7.1\n\nDefinition of Extended NTR processes\n\nSuppose that (Ti , Xi ) denotes a marked pair of random variables on R+ \u00d7 X with distribution F (ds, dx). In\nthis section an answer is provided to the open question of how to extend an NTR process from R+ to more\ngeneral marked Polish spaces. This provides for instance a new class of Bayesian models for multivariate\nsurvival models. While indeed it is easy to extend Z or \u039b to more abstract spaces, the representation in (128)\nor (130) do not immediately suggest an obvious extension for F . The Dirichlet process which is defined over\nabitrary spaces is a notable exception. However, James and Kwon (2000) recently propose a method which\nextends the Beta-Neutral prior of Lo (1993), and by virtue of the equivalences, the Beta-Stacy process in\nMuliere and Walker (1997) and Beta distribution function discussed in Hjort (1990, section 7A), to a spatial\nsetting. A general definition can be deduced from elements of their construction. A definition for F on R+ \u00d7X\nis facilitated by the usage of its associated hazard measure on R+ \u00d7 X . From Last and Brandt (1995, A5.3),\nit follows that such a measure always exists and is defined by,\n\u039b(ds, dx) := I{t > 0}\n\n(135)\n\nF (ds, dx)\n.\nS(s\u2212)\n\nIn particular, \u039b(ds, X ) := \u039b(ds) and hence\nS(s\u2212) :=\n\n(136)\n\n(1 \u2212 \u039b(du, X )) .\nu<s\n\nAn extended NTR is defined as,\n\nDefinition 2. (Extended Neutral to the Right Process) Let \u039b denote a completely random measure\nwith intensity \u03c1\u039b (du|s)\u03b7(ds, dx) for (u, s, x) \u2208 (0, 1] \u00d7 (0, \u221e) \u00d7 X . Furthermore, the intensity measures is\nchosen such that\n\u0014Z 1\n\u0015\nA0 (ds, dx) := E[\u039b(ds, dx)|\u03c1\u039b , \u03b7] :=\nu\u03c1\u039b (du|s) \u03b7(ds, dx)\n0\n\nis a hazard measure. [Denote the marginal cumulative hazard A0 (ds, X ) := A0 (ds)]. Then an Extended\nNeutral to the Right process on R+ \u00d7 X is defined for t > 0 and each B,an arbitrary measurable set in X ,\nZ t\nZ t\nS(s\u2212)\u039b(ds, B) :=\nF (t, B) :=\n(137)\n(1 \u2212 \u039b(du)) \u039b(ds, B)\n0\n\n0\n\nu<s\n\nIn particular, F (ds, dx) := S(s\u2212)\u039b(ds, dx). The law of F is denoted PN (dF |\u03c1\u039b , \u03b7). The random quantities\nS(s\u2212) and \u039b(ds, dx) are independent for each s and arbitrary x and\n(138)\n\nE[F (ds, dx)] := E[S(s\u2212)]E[\u039b(ds, dx)] := e\u2212A0 (s) A0 (ds, dx) := F0 (ds, dx).\n\n\f42\n\nPoisson Process Calculus\n\nremark 30. The definition of an extended neutral to the right process yields, as a special case, a\nclass of random probability measures on arbitrary spaces X , defined as\nZ \u221e\nF (dx) :=\n(139)\nS(s\u2212)\u039b(ds, dx).\n0\n\nFor instance this expression offers another identity for a Dirichlet process on X .\n\nremark 31. The definition is expressed in terms of \u039b rather than Z extended to R+ \u00d7 X due to the\nnatural interpretation of a hazard measure. For instance a description of F (ds, dx) is not easily seen using\nZ. Nonetheless for each \u039b and F in R+ \u00d7 X one can associate a Z on R+ \u00d7 X with again the Levy measure\nof Z arising as the image of \u03c1\u039b (du|y)\u03b7(dy, dx) via the map (u, y) to (\u2212 log(1 \u2212 u), y).\n\nremark 32. When B = X it is obvious that F (*, X ) is an NTR. In addition, due to the complete\nrandomness properties of \u039b, F satisfies,\nL{(F (t1 , B), F (t2 , B) \u2212 F (t1 , B), F (tk , B) \u2212 F (tk\u22121 , B))} = L{(V1,B , V2,B (1 \u2212 V1 ), . . . , Vk,B\n\nk\nY\n\n(1 \u2212 Vi ))},\n\nj=1\n\nwhere for each j, Vj := Vj,B + Vj,B c and Vi:B is independent of Vj,C for i 6= j and B, C arbitrary. A posterior\nprocess will be called an extended NTR process if the NTR properties are preserved.\n\n7.2\n\nPosterior distributions and moment formulae\n\nQ\nNow suppose that one observes n-iid observations (Ti , Xi ) from ni=1 F (dTi , dXi ) and consider the following\njoint models,\n#\n#\n\" n\n\"n\nY\nY\n(140)\nF (dTi , dXi ) P(d\u039b|\u03c1\u039b , \u03b7).\nF (dTi , dXi ) PN (dF |\u03c1\u039b , \u03b7) and\ni=1\n\ni=1\n\nHere we will work with \u039b, and the equivalent expression\n#\n\"n\nY\n(141)\nS(Ti \u2212)\u039b(dTi , dXi ) .\ni=1\n\nIf one assumes the classical univariate right censoring applied to the marked data as in Huang and Louis\n(1998) then the likelihood under censoring takes the form\n\"m\n#\n#\" n\nY\nY\nS(Ti \u2212)\u039b(dTi , dXi )\n(142)\nS(Cl \u2212)\nl=1\n\ni=1\n\nwhere C1 , . . . , Cm denote m independent censoring times which indicate that there are random variables\nTn+1 , . . . , Tm+n where it is only known that they exceed the respective censored times. Under this assumption\nno information for the marks associated with the censored points Tn+1 , . . . , Tm+n is available.\nThe primary focus will be to deduce the posterior distribtion of both F and \u039b and related characteristics\nof the marginal distribution of (T1 , X1 ), . . . , (Tn , Xn ). This will complete the necessary disintegration which\nwill allow one to apply both the (extended) models for \u039b and F to a large class of data structures beyond\nunivariate right censoring. In fact it will become clear from the form of (141) that analysis of right censoring\ndata for NTR is really the same affair as analysis of the complete data model.\n\n\fJames\n\n43\n\nFirst, for i = 1, . . . , n define \u1ef8Ti \u2212 (s) := I{Ti > s} and similarly for l = 1, . . . , m define \u1ef8Cl \u2212 (s) := I{Cl >\ns}. In addition for i = 1 . . . , n define f \u0303Ti \u2212 satisfying,\n \u0303\n\n(1 \u2212 u)\u1ef8Ti \u2212 (s) := e\u2212fTi \u2212 (u,s) ,\n\n(143)\n\nand for l = 1, . . . , m,let f \u0303Cl \u2212 be defined similarly. Then for each (n, m) \u2265 0\n(1 \u2212 u)Yn,m (s) := e\u2212fn,m (u,s)\n\n(144)\n\nP\nP\n \u0303\nwhere Yn,m (s) := ni=1 \u1ef8Ti \u2212 (s) + m\nl=1 \u1ef8Cl \u2212 (s). The quantities fn,m , f are special cases of the functions\ndefined in Proposition 3.1 and 3.2. It follows from the identity in (134) that\n(145)\n\n \u0303\n\nS(Ti \u2212) := e\u2212N (fTi \u2212 )\n\nand\n\nn\nY\n\nS(Ti \u2212) = e\u2212N (fn )\n\ni=1\n\nwhere N is P(dN |\u03c1\u039b , \u03b7). Now the likelihood (142) can be rewritten as\nn\nY\n\ne\u2212N (fn,m )\n\n(146)\n\n\u039b(dTi , dXi )\n\ni=1\n\nThis representation, (146), in combination with Proposition 3.1 and Theorem 3.1 yields the posterior distributions for \u039b, F , Z subject to possible right censorship.\nTheorem 7.1 The posterior distribution of \u039b given the model (142) is P(d\u039b|e\u2212fn,m \u03c1\u039b , \u03b7, T, X). That is, \u039b\nis equivalent in distribution to the random measure\nn(p)\n\n(147)\n\n\u039b(*|Yn,m ) +\n\nX\n\nJj,n \u03b4Tj\u2217 ,Xj\u2217 (*),\n\nj=1\n\nwhere the law of \u039b(*|Yn,m ) is P(d\u039b|e\u2212fn,m \u03c1, \u03b7) indicating that its intensity measure is,\nYn,m (s)\n\n(148)\n\n(1 \u2212 u)\n\n\u03c1\u039b (du|s)\u03b7(ds, dv).\n\nThe Jj,n are (conditionally) mutually independent random variables with distribution, for each j, depending\non Tj\u2217 , Yn,m (Tj\u2217 ), defined as in (32) as,\nY\n\n(149)\n\n\u2212fn,m\n\nIP(Jj,n \u2208 du|e\n\n\u03c1\u039b , Tj\u2217 )\n\n(T \u2217 )\n\nuej ,n (1 \u2212 u) n,m j \u03c1\u039b (du|Tj\u2217 )\n:=\n,\n\u03baej ,n (e\u2212fn,m \u03c1\u039b |Tj\u2217 )\n\nand are conditionally independent of \u039b(*|Yn,m ).\n(ii) The posterior distribution of F is still an extended NTR with distribution PN (dF |e\u2212fn,m \u03c1\u039b , \u03b7, T, X)\ndetermined by replacing the random measure \u039b with (147).\n(iii) A posterior distribution of Z is equivalent to the law of the random measure\nn(p)\n\nZ(*|Yn,m ) +\n\nX\n\n(1 \u2212 e\u2212Jj,n )\u03b4Tj\u2217 ,Xj\u2217 (*),\n\nj=1\n\nwhere the L\u00e9vy measure of Z(*|Yn,m ) arises as the image of (1 \u2212 u)Yn,m (s) \u03c1\u039b (du|s)\u03b7(ds, dx) via the map (u, s)\nto (\u2212 log(1 \u2212 u), s)\n\n\f44\n\nPoisson Process Calculus\n\nWhen m := 0, the results correspond to a complete data model.\n\nProof. First set \u03bc := \u039b, and w(\u039b) := e\u2212N (fn,m ) . Now apply statement (ii) of Proposition 3.1.\nremark 33. Theorem 7.1 serves to extend the results for the univariate setting to a spatial setting.\nThe previous works for the univariate setting do not use explicitly a partition based representation. More\nimportantly the method of proof, which is new, is quite transparent.\nremark 34. Note also that due to the non-atomic nature(continuity) of \u03b7(ds) the quantity Yn,m (s)\nin (148) can be replaced by\nm\nn\nX\nX\n+\nI{s \u2264 Ti } +\nI{s \u2264 Cl }.\nYn,m\n(s) :=\ni=1\n\nl=1\n\nIn other words calculations with respect to \u039b(*|Yn,m ) should be understood to be equivalent to those with\n+\nrespect to \u039b(*|Yn,m\n). This does not apply to the distribution of the jumps (Jj,n ).\n\nLittle is known in general about the explicit joint moment structure of Neutral to the Right models. The\nresults in Doksum (1974) are rather vague. In recent works expressions for the mean and variance are given.\nThe formulae in Proposition 3.2 can be used to easily obtain various equivalent expressions which goes well\n \u0303\nbeyond a variance calculation. This is seen by setting wi (\u039b) := e\u2212N (fTi \u2212) for i = 1, . . . , n , and other obvious\nequivalences. For brevity, I will only present a result which yields the relevant joint structure and EPPF for\nthese models. Such results do not appear in the literature mentioned above.\nDefine,\nZ \u221eZ 1\nY + (s)\n(150)\n\u00c3n,m (\u221e) :=\n(1 \u2212 (1 \u2212 u) n,m )\u03c1\u039b (du|s)\u03b7(ds)\n0\n\n0\n\nIn addition for i = 1, . . . , n and m \u2265 0 define,\nZ tZ\nAi\u22121,m (t) :=\n(151)\n0\n\n1\n\n+\nYi\u22121,m\n(s)\n\nu(1 \u2212 u)\n\n\u03c1\u039b (du|s)\u03b7(ds).\n\n0\n\nWhen m = 0, denote Ai\u22121,m as Ai\u22121 . Now recall that,\nZ 1\nY\n(T \u2217 )\n(152)\nuej,n (1 \u2212 u) n,m j \u03c1\u039b (du|Tj\u2217 ),\n\u03baej,n (e\u2212fn,m \u03c1\u039b |Tj\u2217 ) =\n0\n\nQn\nQm\nProposition 7.1 (i) For m > 0, the (prior) mean calcuation for [ l=1 S(Cl \u2212)] i=1 S(Ti \u2212) is\n# m\n\" n\nY\nY\n\u2212Ai\u22121 (Ti )\n\u2212N (fn,m )\n\u2212\u00c3n,m (\u221e)\n\u2212Ao (T1 )\n(153)\ne\u2212An,l\u22121 (Cl )\ne\nE[e\n|\u03c1\u039b , \u03b7] = e\n=e\ni=2\n\nl=1\n\n(ii) When m = 0, the joint marginal distribution of ((Ti , Xi )) can be expressed as\n\uf8ee\n\uf8f9\nn(p)\nY Y\n\u2217\n\uf8f0\n(154)\ne\u2212Ai\u22121 (Tj ) \uf8fb \u03baej,n (e\u2212fn \u03c1\u039b |Tj\u2217 )\u03b7(dTj\u2217 , dXj\u2217 )\nj=1\n\ni\u2208Cj\n\nAdjustments for the censored case are obvious.\n(iii) From statement (i) it follows that the corresponding EPPF has the form,\n\uf8ee\n\uf8f9\nZ\nn(p)\nY Y\n\u2217\n\uf8f0\n(155)\ne\u2212Ai\u22121 (Tj ) \uf8fb \u03baej,n (e\u2212fn \u03c1\u039b |Tj\u2217 )\u03b7(dTj\u2217 )\nT n(p) j=1\n\ni\u2208Cj\n\n\fJames\n\n45\n\nProposition 7.2 Using an algebraic rearrangement the joint marginal distribution and EPPF can be rewritten respectively as,\nn(p)\n\n\u03c0(p|\u03c1\u039b , T\u2217 )\n\n(156)\n\nY\n\nF0 (dTj\u2217 , dXj\u2217 )and\n\nj=1\n\nZ\n\nT\n\nn(p)\n\n\u03c0(p|\u03c1\u039b , T\u2217 )\nn(p)\n\nY\n\nF0 (dTj\u2217 ).\n\nj=1\n\nWhere,\nn(p)\n\n(157)\n\n\u03c0(p|\u03c1\u039b , T\u2217 ) :=\n\nY\n\nj=1\n\nhQ\n\ni\n\u2212Ai\u22121 (Tj\u2217 )\n\u03baej,n (e\u2212fn \u03c1\u039b |Tj\u2217 )\ne\ni\u2208Cj\n\u2217\n\ne\u2212A0 (Tj ) \u03ba1 (\u03c1\u039b |Tj\u2217 )\n\nremark 35. Naturally if one were interested in actually generating such partitions etc, then a modification of the algorithm in Section 2.3 can be used. For this one could use expressions for the prediciton\nrule or conditional moment measures which are readily obtainable from an application of Proposition 3.2\ncombined with Theorem 7.1.\nremark 36. The propositions above combined with Theorem 7.1 yield expressions for the posterior\ndisintegrations. It is now straightforward to obtain posterior characterizations for mixtures of extended NTR\nmodels based on kernels (Ki ). This framework allows for much more complex structures than right censoring.\nI have not seen general mixtures of NTR models proposed in the literature.\n\n7.3\n\nAbsolute continuity of general Beta,Beta-Neutral/Stacy models to a canonical Beta processs or Dirichlet process\n\nThe general construction of the extended NTR models is an extension of (presently unpublshed work) James\nand Sehyug Kwon (2000). In that work the authors extend Lo's (1993) Beta-Neutral survival and cumulative\nhazard processes to the spatial setting. Lo (1993) derives these based on the following explict construction\nfor the hazard\nZ t\n\u03bc\u03c4 (ds)\n\u039b\u03c4,\u03b2 (t) :=\n(158)\n,\n\u03bc\n([s,\n\u221e))\n+ \u03bc\u03b2 ([s, \u221e))\n\u03c4\n0\nwhere \u03bc\u03c4 ,\u03bc\u03b2 are independent gamma processes with shape measure \u03c4 and \u03b2 on R+ , which as noted in Lo\n(1993) yields an explicit contruction of Hjort's (1990) Beta cumulative hazard process. James and Kwon\n(2000) extend this definition by simply extending the gamma processes to a spatial setting. Moreover they\nshow that such models can be always derived from a Dirichlet process on an even larger space. In other words\ntake a two parameter gamma process, say \u03bc\u03c4,\u03b2 , on R+ \u00d7 X \u00d7 {0, 1}, such that \u03bc\u03c4,\u03b2 (ds, dx, {1}) := \u03bc\u03c4 (ds, dx)\netc. A corresponding Dirichlet process can be defined as\n(159)\n\nP\u03c4,\u03b2 (ds, dx, \u2206) :=\n\n\u03bc\u03c4,\u03b2 (ds, dx, \u2206)\n.\n\u03bc\u03c4,\u03b2 (R+ \u00d7 X \u00d7 {0, 1})\n\nThen the extension of James and Kwon (2000) can be deduced from the extended Beta-Neutral hazard\nmeasure,\n\u03bc\u03c4,\u03b2 (ds, dx, {1})\n(160)\n\u039b\u03c4,\u03b2 (ds, dx) :=\n\u03bc\u03c4,\u03b2 ([s, \u221e) \u00d7 X \u00d7 {0, 1})\n\n\f46\n\nPoisson Process Calculus\n\nwhere \u03c4 and \u03b2 are now measures on R+ \u00d7 X . If \u03b2 is set to zero in (160) then the corresponding (extended)\nNeutral to the Right process is a Dirichlet process with shape parameter \u03c4 which, without loss of generality,\nis set to \u03b8F0 . By virtue of the essential equivalence of the Beta-Neutral process to the Beta-Stacy process of\nWalker and Muliere (1997) and the Beta distribtion function of Hjort (1990, Section 7A), the procedure of\nJames and Kwon (2000) includes these models as well. In addition they showed that the (posterior) conjugacy\nof the Beta-type models on R+ is preserved under the right censored data spatial model discussed earlier.\nHowever their technique relied on very special properties of the Dirichlet process which is quite different\nthan what has been presented in the previous sections. Here a new result is established which shows how one\nmay transform a Dirichlet process or simple Beta process to a more general one via a change of measure. A\nconsequence is that the calculus for such models follows from the calculus for the Dirichlet process plus an\napplication of Proposition 3.1.\nRecall that a Beta process on R+ with parameters c(s) and A0 (ds, dx) yields a Dirichlet process if and\nonly if c(s) := \u03b8F0 ([s, \u221e)). Such a Beta process can be thought of as a canonical Beta process.\nProposition 7.3 Let P(d\u039b|c, Ao ) denote the law of a Beta process with parameters c and A0 (ds, dx). Let Z\ndenote the corresponding L\u00e9vy process defined via the map (u, y) to (\u2212 log(1 \u2212 u), y) and define a decreasing\nfunction \u03b2 on R+ such that,\nZ\n\u221e\n\nT\u03b2 :=\n\n\u03b2(v)Z(dv) < \u221e.\n\n0\n\nThen the following disintegration holds\ne\u2212T\u03b2 P(d\u039b|c, A0 ) := P(d\u039b|c + \u03b2, A0 )E[e\u2212T\u03b2 ]\n\n(161)\nwhere \u2212 log E[e\u2212T\u03b2 ] is\nZ\n\n(162)\n\n0\n\n\u221e\n\nZ\n\n1\n\n(1 \u2212 (1 \u2212 u)\u03b2(s) )u\u22121 (1 \u2212 u)c(s)\u22121 duA0 (ds).\n\n0\n\nThe proof follows by using the alternate representation\nT\u03b2 := e\u2212N (f\u03b2 )\n\n(163)\n\nwhere f\u03b2 (u, s) := \u2212\u03b2(s) log(1 \u2212 u) and N has a Poisson law corresponding to P(d\u039b|c, Ao ). An interesting\nfeature of this result is that one can obtain quite easily an alternate expression for the EPPF of a BetaNeutral/Stacy model by first applying the result for a Dirichlet process. That is,\nProposition 7.4 Suppose that F is a NTR process determined by the Beta process with parameters c\u2217 :=\n\u03b8F0 + \u03b2, then the EPPF is given by,\n(164)\n\nP D(p|\u03b8)\n\nn(p) Z \u221e\nY\nj=1\n\n0\n\n\u0014\n\n\u0015\n\u0393(ej,n + \u03b8F0 ([y, \u221e)))\u0393(\u03b8F0 ([y, \u221e)) + \u03b2(y))\nF0 (dy).\n\u0393(\u03b8F0 ([y, \u221e)))\u0393(ej,n + \u03b8F0 ([y, \u221e)) + \u03b2(y))\n\nremark 37. The change of measure in Proposition 7.3 can of course be extended easily to non-Beta\nprocesses. In general, the updated law corresponds to a random hazard measure with L\u00e9vy measure e\u2212f\u03b2 \u03c1.\nNote that much more general choices of f\u03b2 can be used via Proposition 3.1.\n\n\fJames\n\n47\n\nremark 38. The correspondence between the Beta-Stacy process of Walker and Muliere (1997) and\nHjort's (1990, section 7A) process is noted explicitly in Dey (1999) and Dey, Ericson, and Ramamoorthi (2000). The equivalence between the Beta-Neutral process and Hjort's(1990) process was noted in Lo\n(1993). Given the gaps in the literature it is apparent that Beta-Neutral processes are not as well known as\ntheir equivalent counterparts. This seems to be caused by the title of Lo (1993) which concerns a Censored\nData Bayesian Bootstrap.\n\nremark 39. NTR processes seem to arise naturally in coalescent theory. See in particular Pitman(1999, Proposition 26) which is not a Dirichlet process. Similar types of processes with drift appear\nin Bertoin (2001).\n\n8\n\nPosterior Distributions of Normalised processes and PoissonKingman models\n\nIn this section I briefly discuss calculations for probability measures P defined using the weighted Poisson\ndistribution Q(dN |\u03c1, \u03b7) which are more in line with the results and methods used in Perman, Pitman and\nYor (1992) and Pitman and Yor (1992) and Pitman (1995b). Here descriptions of pertinent quantities will\n \u0303 One will see that the forms of the results appear quite\nbe given in terms of the biased jumps denoted as J.\ndifferent than Section 5. For completion the definition of Poisson-Kingman models based on length biased\nsampling presented in Pitman (1995b) is given,\nDefinition 8.1 (Pitman (1995b)) Let Pi = (Ji /T ) be a ranked discrete distribution derived from the ranked\npoints of a Poisson Process with L\u00e9vy density \u03c1 (not depending on y) of random lengths J1 \u2265 J2 \u2265 * * * \u2265 0\nby normalizing their lengths by their sum which is T . Let (P\u0303j ) be a size-biased permutation of (Pi ) and let\nJ\u0303j = (T P\u0303j ) be the corresponding size-biased permutation of the ranked lengths (Ji ). The law of the sequence\n(Pi ) will be called the Poisson-Kingman distribution with L\u00e9vy density \u03c1, and denoted P K(\u03c1). Denote by\nP K(\u03c1|t) the regular conditional distributioon of (Pi ) given (T = t) constructed above. For a probability\ndistribution \u03b3 on (0, \u221e), let\nZ\n\u221e\n\n(165)\n\nP K(\u03c1|t)\u03b3(dt)\n\nP K(\u03c1, \u03b3) :=\n\n0\n\nbe the distribution on the space of (Pi ),[which is the space of decreasing sequences of positive real numbers\nwith sum 1]. Call P K(\u03c1, \u03b3) the Poisson-Kingman distribution with L\u00e9vy density \u03c1 and mixing distribution\n\u03b3 .\nPitman (1995b), points out that knowledge of the conditional law P K(\u03c1|t) allows one to generate explicit\nresults for distributions P K(\u03c1, \u03b3), in particular the corresponding EPPF, by simply mixing over different\ncandidate densities, \u03b3(dt), for T . The case of the two parameter Poisson-Dirichlet family is explained in\ndetail in Pitman (1995b) as mentioned in section 5.\nThe introduction of the measure Q(dN |\u03c1, \u03b7) serves to incorporate fully the Poisson-Kingman idea while\nmaintaining the approach of Poisson calculus at the level of N . Some properties of this class, which shall\nbecome clear in the next section are now described. When \u03c1 is homogeneous and w(N ) := w(N (*, Y)) then\nP is a species sampling model. Additionally when w(N ) := g(T ) and h(s) := s \u2208 (0, \u221e) then the random\natoms of P , (Pi ) are P K(\u03c1, \u03b3). In that case\n(166)\n\n\u03b3(dt) :=\n\ng(t)fT (dt)\nE[g(T )|\u03c1, \u03b7]\n\n\f48\n\nPoisson Process Calculus\n\nwhere g is nonegative and integrable but otherwise arbitrary, fT denotes the density of T with respect to\nP(dN |\u03c1, \u03b7). In other words the change of measure at N via Q(dN |\u03c1, \u03b7) induces the appropriate change of\nmeasure at the level of the PK measure etc. The results below follow from a straightforward application of\nLemma 2.2, details are omitted.\n\n8.1\n\nPosterior characterizations\n\nIn the theorem below it is stated that the posterior law of P |Y, denoted as P(dP |Y), corresponds to the\nlaw of a random measure defined as,\nn(p)\n\nPn\u2217 (*)\n\n(167)\n\n:= Rn(p) P (*) + (1 \u2212 Rn(p) )\n\nX\nj=1\n\nwhere, Rn(p)\n\nh\ni\nPn(p)\n:= T / T + j=1\nh(J\u0303j ) ,\n\nh(J\u0303j )\n\u03b4Yj\u2217 (*),\nPn(p)\nh(\nJ\u0303\n)\nj\nj=1\n\nTheorem 8.1 Let {Y1 , . . . , Yn } be iid P where the prior law of P is determined by the weighted Poisson\nmeasure Q(dN |\u03c1, \u03b7). Then, the posterior distribution of P |Y is equivalent to the distribution of the random\nmeasure Pn\u2217 defined in (167) whose law is now determined by the joint probability measure\n\uf8eb\n\nn(p)\n\n(168) Q(dN, J\u0303 \u2208 ds|Y, h) \u221d w(N +\n\nX\nj=1\n\n\u03b4sj ,Yj\u2217 )P(dN |\u03c1, \u03b7)\uf8edT +\n\nn(p)\n\nX\nj=1\n\n\uf8f6\u2212n\n\nh(sj )\uf8f8\n\nn(p)\n\nY\n\nh(sj )ej,n \u03c1(dsj |Yj\u2217 )\n\nj=1\n\nThe marginal distribution of {Y1 , . . . , Yn } corresponds to the un-normalised term on the right hand side of\nQn(p)\n(168), integrated over P(dN |\u03c1, \u03b7), and multiplied by i=1 \u03b7(dYi\u2217 ).\n\nremark 40. Notice that the expression above remains complicated even if W (N ) is replaced by 1.\nThe result is more in line with Pitman, Perman and Yor (1992) and Pitman (1995b). In comparison with\nsection 5 the law of the random measure Pn\u2217 is a bit more complex as it is decribed via the biased jumps\nJ \u0303 which have a much more complex (non-independent) joint distribution. Under moment conditions other\nforms of the posterior are easily obtained.\nNow letting\nn(p)\n\n(169)\n\nTn(p) := T \u2212\n\nX\n\nh(sj )\n\nj=1\n\nit is quite clear that one can gain further interpretation by adapting the descriptions given in Perman, Pitman\nand Yor (1992, section 4) and Pitman (1995b). Note in particular when n = 1, and w(N ) := g(T ) and \u03c1 is\nhomogeneous an evaluation of the expectation of P reveals the structural distributions,\n(170)\n\nIPg (J\u03031 \u2208 ds, T1 \u2208 dt1 ) =\n\ng(t1 + s)fT (t1 )dt1 h(s)\u03a9(s)ds\ng(t1 + s)\n=\nIP(J\u03031 \u2208 ds, T1 \u2208 dt1 )\n(t1 + s) E[g(T )]\nE[g(T )]\n\nA suitable change of variable yields\n(171)\n\nIPg (T \u2208 dt, T1 \u2208 dt1 ) =\n\ng(t)fT (t)\ng(t)\nIP(T \u2208 dt, T1 \u2208 dt) =\nIP(T1 \u2208 dt1 |T = t)\nE[g(T )]\nE[g(T )]\n\n\fJames\n\n49\n\nand more generally for each n,\n\u0001\n\nIPg p, J \u2208 ds, Tn(p) \u2208 dt =\n\ng(t +\n\nPn(p)\nj=1\n\nh(sj ))\n\nE[g(T )]\n\n\u0001\nIP p, J \u2208 ds, Tn(p) \u2208 dt .\n\n\u0001\nThe joint distributions IP(J\u03031 \u2208 ds, T1 \u2208 dt1 ) and IP p, J \u2208 ds, Tn(p) \u2208 dt are given in Pitman (1995b)\nand Perman, Pitman and Yor (1992). One can for instance obtain formulae for the joint distribtuion of\n(T, T1 , . . . , Tn ) via (g(t)/E[g(T )]) IP(T \u2208 dt, T1 \u2208 dt1 , . . . , Tn \u2208 dtn ) using Perman, Pitman and Yor (1992,\nTheoerem 2.1). All of these facts correspond with the P K(\u03c1, \u03b3) concept. See additionally Pitman and Yor\n(1997, Proposition 47).\nCombining the description in Pitman (1995b, Lemma 5 and equation(30)) with Theorem 8.1 the next\nresult follows.\nCorollary 8.1 Suppose that w(N +\n\nPn(p)\nj=1\n\n\u03b4sj ,Yj\u2217 ) := w(N ;\n\na joint law of of p, J\u0303, Y\u2217 is defined as;\n(172)\n\n1\nE[w(N )]\n\n\"Z\n\nw(N ;\n\nM\n\nPn(p)\nj=1\n\n(T +\n\nPn(p)\nj=1\n\n#n(p)\n\u03b4sj )P(dN |\u03c1, \u03b7) Y\n\nPn(p)\nj=1\n\nn\n\nh(sj ))\n\n\u03b4sj ) does not depend on Y \u2217 for all n. Then\n\nh(sj )ej,n \u03c1(dsj |Yj\u2217 )\u03b7(dYj\u2217 ).\n\nj=1\n\nAs a consequence, the distribution of Y|J\u0303, Tn(p) , p is conditionally independent of Tn(p) such that the sequence\n\u2217\n{Y1 , . . . , Yn } consists of n(p) unique values {Y1\u2217 , . . . , Yn(p)\n} which are independent with distribution\nIP(dYj\u2217 |J \u0303j , p)) \u221d \u03c1(J\u0303j |Yj\u2217 )\u03b7(dYj\u2217 ).\n\n(173)\n\nfor j = 1, . . . , n(p). Additionally the joint distribution of J\u0303, p is\n(174)\n\n1\nIP(J\u0303 \u2208 ds, p) =\nE[w(N )]\n\n\"Z\n\nw(N ;\n\nPn(p)\nj=1\n\n(T +\n\nM\n\nIf additionally \u03c1 is homogeneous then\n\n#n(p)\n\u03b4sj )P(dN |\u03c1, \u03b7) Y\n\nPn(p)\nj=1\n\nh(sj ))\n\nn\n\nh(sj )ej,n\n\nj=1\n\nZ\n\n\u03c1(dsj |y)\u03b7(dy).\n\nY\n\nn(p)\n\n(175)\n\nIP(dY) = p\u03c1 (e1 , . . . , en(p) )\n\nY\n\nH(dYj\u2217 ),\n\nj=1\n\nwhere, the EPPF is\n(176)\n\n1\np\u03c1 (e1 , . . . , en(p) ) =\nE[w(N )]\n\nZ\n\nM\u00d7S n(p)\n\nw(N ;\n\nPn(p)\nj=1\n\nQn(p)\nh(sj )ej,n \u03c1(dsj )\n\u03b4sj )P(dN |\u03c1, \u03b7) j=1\n\u0011\n\u0010\n.\nn\nPn(p)\nT + j=1 h(sj )\n\n\u2217\nMoreover for every n, the joint distribution of the unique values of {Y1 , . . . , Yn }|p, that is {Y1\u2217 , . . . , Yn(p)\n},\nare now iid H. If W (N ) := g(T ) then the EPPF is;\n\uf8ee\n\uf8f9\nPn(p)\nQn(p)\nZ\ng(t + j=1\nsj )fT (t)dt j=1\nh(sj )ej,n \u03c1(dsj )\n\uf8f0\n\uf8fb.\n\u0010\n\u0011n\n(177)\nPn(p)\nR+ \u00d7S n(p)\nt + j=1 h(sj )\n\nWhen h(s) = s \u2208 (0, \u221e) and g(T ) = 1, the expression in (177) corresponds exactly with equation (31) of\nPitman (1995b).\n\n\f50\n\nPoisson Process Calculus\n\nremark 41. One could simply apply a Fubini argument to Theorem 8.1 to deduce the existence of the\nrelevant joint distributions. However, without any interpretation gained via Pitman, Perman and Yor (1992)\nand Pitman (1995b) the result is somewhat vacuous. Again some of those interpretations may also be of\ninterests to practicing Bayesians statisticians as it certainly goes beyond the usual mean/variance assessment\nto compare different random probability measures.\n\nremark 42. The results above serve also to add to the explicit formulae given in Pitman (1995b)\nfor the length biased case. Note that one could apply (67) to obtain alternate representations for the EPPF\nas in Pitman (1995b, Corollary 6). An additional interesting feature of Corollary 8.1 is the conditional\nindependence result in (173).\n8.2\n\nMixture models\n\nTheorem 8.1 and its corollary can certainly handle structures of the form\n(178)\n\nQ(dN |\u03c1, \u03b7)\n\nn Z\nY\n\ni=1\n\nK(Xi |Yi )P (dYi )\nY\n\nA description of the relevant posterior laws is presented below,\nTheorem 8.2 The posterior distribution of Y, P |X based on the model (54) is representable as,\n\uf8f9\n\uf8ee\nn(p)\nY\nIP(dYj\u2217 |J\u0303, p, X)\uf8fb IP(J\u0303 \u2208 ds, p|X),\nIP(dY, dP |X) \u221d P(dP |Y) \uf8f0\ni=1\n\nwhere a conditional distribution of Y|J\u0303, p, X is given such that the sequence {Y1 , . . . , Yn } consists of n(p)\n\u2217\nunique values Y\u2217 = {Y1\u2217 , . . . , Yn(p)\n} which are independent with respective distributions,\n\n(179)\n\ni\n\u2217\nK\n(X\n|Y\n)\nIP(dYj\u2217 |J \u0303j , p)\ni\ni\nj\ni\u2208Cj\n\u2217\ni\nh\nIP(dYj |J\u0303, p, X) = R Q\n.\n\u2217 ) IP(dY \u2217 |J \u0303 , p)\nK\n(X\n|Y\nj\ni\ni j\nj\ni\u2208Cj\nY\nhQ\n\ni\nQn(p) R hQ\n\u2217\n\u2217  \u0303\nfor j = 1, . . . , n(p). In addition IP(J\u0303 \u2208 ds, p|X) \u221d IP(J\u0303 \u2208 ds, p) j=1 Y\ni\u2208Cj K(Xi |Yj ) IP(dYj |Jj , p)\n\nIt follows that when \u03c1 does not depend on y (179) does not depend on J\u0303,T. Hence in that case posterior\ncharacterizations of P, Y do not differ in form from the results in Lo (1984) and Ishwaran and James (2001a).\nThe general case however is a different mattter entirely.\n\n9. Acknowledgements.\nI wish to express my deep gratitude to Professor Jim Pitman for encouraging me to look at this problem in\nthe Poisson generality in which it appears. Without his gentle persistent nudging and advice this manuscript\nmay not have been written. I thank him for his mentorship despite the fact that at the commencement of\nthis project we had never met. The essence of the technique and style which I use, I have learned from my\nteacher Albert Y. Lo. I thank him for his steady influence and encouragement and always reminding me\nto think simply. I also mention that the general style of Fubini calculus presented here was developed over\nconversations between Albert Lo and Lucien Le Cam, of which I have benefitted from. I wish to thank Dr.\n\n\fJames\n\n51\n\nC.K. Lim for inspiring me. I wish to thank also Professors Kallenberg, Paulauskas and Talagrand for fielding\nmy somewhat vague questions on the existence of a L\u00e9vy-Khinchine result in quite abstract spaces. I hope\nthey understand now that I was curious if there was such a general analogue of Lemma 2.1. and what one\nmight do with it.\n\nReferences\nAalen, O. O. (1975). Statistical inference for a family of counting processes. Ph.D. Thesis. University of\nCalifornia, Berkeley.\nAalen, O. O. (1978). Nonparametric inference for a family of counting processes. Ann. Statist. 6 535-545.\nAalen, O. O. (1992). Modelling hetoregeneity in survival analysis by the compund Possion distribution.\nAnnals of Applied Probability 2 951-972.\nAldous, D. J. (1985). Exchangeability and related topics. In \u00c9cole d'\u00c9t\u00e9 de Probabilit\u00e9s de Saint-Flour XII\n(P. L. Hennequin, editor). Springer Lecture Notes in Mathematics, Vol. 1117.\nAndersen, P. K., Borgan, O. , Gill, R. D. and Keiding, N. (1993). Statistical Models Based On\nCounting Processes. Springer-Verlag, New York.\nAntoniak, C. E. (1974). Mixtures of Dirichlet processes with applications to Bayesian nonparametric\nproblems. Ann. Statist. 2 1152-1174.\nBanjevic, D., Ishwaran, H. and Zarepour, M. (2002). A recursive method for functionals of Poisson\nprocesses. To appear in Bernoulli.\nBar-Lev, S.K. and Enis, P. (1986). Reproducibility and natural exponential families with power variance\nfunctions. Ann. Statist. 14 1507-1522.\nBarndorff-Nielsen, O.E. and Shephard, N. (2001). Normal modified stable processes. Preprint.\nBerk, R. and Savage , I. R. (1979). Dirichlet processes produce discrete measures: an elementary proof.\nContributions to Statistics, Jaroslav Hajek Memorial Volume. Edited by Jana Jure\u010dkova. Reidel,\nDordrecht-Boston, Mass.-London. pp. 25-31.\nBertoin, J. (2001). Homogeneous fragmentation processes. Probab. Theory Related Fields 121 301\u2013318.\nBlackwell, D. (1973). Discreteness of Ferguson selections. Ann. Statist. 1 356-358.\nBlackwell, D. and MacQueen, J. B. (1973). Ferguson distributions via P\u00f3lya urn schemes. Ann. Statist.\n1 353-355.\nBlackwell, D. and Maitra A. (1984). Factorization of probability measures and absolutely measurable\nsets. Proc. Amer. Math. Soc. 92 251-254.\nBlum, J. and Susarla, V. (1977). On the posterior distribution of a Dirichlet process given random right\ncensored data. Stochastic Process. Appl 5 207-211.\nBrix, A. (1999). Generalized Gamma measures and shot-noise Cox processes. Adv. in Appl. Probab. 31\n929-953.\nBrunner, L. J., Chan, A. T., James, L. F. and Lo, A. Y. (2001). Weighted Chinese restaurant processes\nand Bayesian mixture models. preprint.\nBrunner, L. J. and Lo, A. Y. (1989). Bayes methods for a symmetric unimodal density and its mode.\nAnn. Statist. 17 1550-1566.\nCarlton, M.A. (1999). Applications of the Two-Parameter Poisson Dirichlet distribution. Ph.D. Thesis.\nUniveristy of California, Los Angeles. Dept. of Statistics.\nCifarelli, D.M. and Regazzini, E. (1990). Some remarks on the distribution of the means of a Dirichlet\nprocess. Ann. Statist. 18 429-442.\nConstantine, G. M. (1999). Identities over set partitions. Discrete Mathematics 204 155-162.\nConstantine, G. M. and Savits, T. H. (1994). A stochastic process interpretation of partition identities.\nSiam J. Discrete Math. 7 194-202.\n\n\f52\n\nPoisson Process Calculus\n\nDaley, D. J. and Vere-Jones, D. (1988). An Introduction to the Theory of Point Processes. Springer-Verlag,\nNew York.\nDellacherie, C and Meyer, P. A. (1978). Probabilities and Potential. Amsterdam\nDey, J. (1999). Some Properties and Characterizations of Neutral-to-the-Right Priors and Beta Processes.\nPh.D. Thesis. Michigan State University.\nDey, J, Erickson, R.V. and Ramamoorthi, R.V. (2000). Neutral to right priors- A review. Preprint.\nDi Nardo, E. and Senato, D. (2001). Umbral nature of the Poisson random variables. In Algebraic\nCombinatorics Computer Science: A Tribute to Gian-Carlo Rota Springer 245-267.\nDiaconis, P. and Kemperman, J. (1996). Some new tools for Dirichlet priors. Bayesian Statistics 5 (J.M.\nBernardo, J.O. Berger, A.P. Dawid and A.F.M. Smith eds.), Oxford University Press, pp. 97-106.\nDoksum, K. A. (1974). Tailfree and neutral random probabilities and their posterior distributions. Ann.\nProbab 2 183-201.\nDonnelly, P. and Tavar\u00e9, S. (1987). The population genealogy of the infinitely-many neutral alleles\nmodel. J. Math. Biol. 25 381-391.\nDoss, H. (1994). Bayesian nonparametric estimation for incomplete data via successive substitution sampling. Ann. Statist. 22 1763-1786.\nDykstra, R. L. and Laud, P. W. (1981). A Bayesian nonparametric approach to reliability. Ann. Statist.\n9 356-367.\nEngen, S. (1978). Stochastic Abundance Models with Emphasis on Biological Communities and Species\nDiversity. Chapman and Hall\nEwens, W. J. (1972). The sampling theory of selectively neutral alleles. Theor. Popul. Biol. 3 87-112.\nEwens, W. and Tavar\u00e9, S. (1997). Multivariate Ewens distribution. In Discrete Multivariate Distributions\n(S. Kotz and N. Balakrishnan, eds.). Wiley, New York.\nFerguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. Ann. Statist. 1 209-230.\nFerguson, T. S. (1974). Prior distributions on spaces of probability measures. Ann. Statist. 2 615-629.\nFerguson, T. S. and Klass, M. J. (1972). A representation of independent increment processes without\nGaussian components. Ann. Math. Statist. 43 1634-1643.\nFerguson, T. S. and Phadia, E. (1979). Bayesian nonparametric estimation based on censored data.\nAnn. Statist. 7 163-186.\nFreedman, D. A. (1963). On the asymptotic behaviour of Bayes estimates in the discrete case. Ann. Math.\nStatist 34 1386-1403.\nFitzsimmons, P., Pitman, J. and Yor, M. (1992). Markovian bridges: construction, Palm interpretation\nand splicing, In Seminar on stochastic process 1992 Editors Cinlar, Chung, Sharpe. Birkhauser,\nBoston. 101-135..\nGill, R. D. and Johansen, S. (1990). Survey of product-integration with a view towards applications in\nsurvival analysis. Ann. Statist. 18 1501-1555.\nGroeneboom, P. (1996). Lectures on inverse problems. Lectures on probability theory and statistics\n(Saint-Flour, 1994), 67\u2013164, Lecture Notes in Math., 1648, Springer, Berlin.\nGroeneboom, P. and Wellner, J. A. (1992). Information bounds and nonparametric maximum likelihood estimation. DMV Seminar, 19. Birkhauser Verlag, Basel.\nGyllenberg, M, and Koski, T. (2001). Probabilistic models for bacterial taxonomy. International Statistical Review 69 249-276.\nHansen, B. and Pitman, J. (2000). Prediction rules for exchangeable sequences related to species sampling.\nStatist. Prob. Letters 46 251-256.\nHjort, N. L. (1990). Nonparametric Bayes estimators based on Beta processes in models for life history\ndata. Ann. Statist. 18 1259-1294.\nHougaard, P. (1986). Survival models for heterogeneous populations derived from stable distributions.\nBiometrika 73 387-396.\nHougaard, P., Lee, M. L. and Whitmore, G. (1997). Analysis of overdispersed count data by mixtures\nof Poisson variables and Poisson processes. Biometrics 53 1225-1238.\n\n\fJames\n\n53\n\nHuang, Y. and Louis, T. A. (1998). Nonparametric estimation of the joint distribution of survival time\nand mark variables. Biometrika 85 785-798.\nIshwaran, H. and James, L. F. (2001a). Generalized weighted Chinese restaurant processes for species\nsampling models. Manuscript.\nIshwaran, H. and James, L. F. (2001b). Gibbs sampling methods for stick-breaking priors. J. Amer. Stat.\nAssoc 161-173.\nIshwaran, H., James, L. F. and Sun, J. (2001). Bayesian model selection in finite mixtures by marginal\ndensity decompositions. J. Amer. Stat. Assoc 96 1316-1332.\nJacod, J. (1975). Multivariate point processes: predictable projection, Radon-Nikodym derivatives, representation of martingales. Z. Wahrsch. verw. Gebiete 35 1-37.\nJames, L. F. and Kwon, S. (2000). A Bayesian nonparametric approach for the joint distribution of\nsurvival time and mark variables under univariate censoring. Unpublished manuscript.\nJames, L. F. (2001a). Bayesian calculus for Gamma processes with applications to semiparametric models.\nTo appear in Sankhy\u0101 Ser. A.\nJames, L. F. (2001b). An analysis of weighted generalised gamma process mixture models. Unpublished\nnotes.\nJorgensen, B. (1997). The Theory of Dispersion Models. Monographs on Statistics and Applied Probability,\n76.. Chapman and Hall, London.\nKallenberg, O. (1986). Random Measures, 4th Ed. Akademie-Verlag and Academic Press, Berlin and\nLondon.\nKallenberg, O. (1997). Foundations of modern probability. Probability and its Applications. Springer-Verlag,\nNew York.\nKaplan, E. L. and Meier, P. (1958). Nonparametric estimation from incomplete observations. J. Amer.\nStatist. Assoc. 53 457-481.\nKerov, S. (1998). Interlacing measures. Amer. Math. Soc. Transl. 181 35-83.\nKerov, S. and Tsilevich, N. V. (1998). The Markov-Krein correspondence in several dimensions. POMI\npreprint No. 283, Steklov Institute of Mathematics, St. Petersburg.\nKhintchine, A. Ya. (1937). Sur theorie der unbeschrankt teilbaren Verteilungsgesetze. Mat. Sb. 44 79-119.\nKim, Y. (1999). Nonparametric Bayesian estimators for counting processes. Ann. Statist. 27 562-588.\nKingman, J. F. C. (1993). Poisson Processes. Oxford University Press, Oxford.\nKingman, J. F. C. (1975). Random discrete distributions. J. Royal Statist. Soc., Series B 37 1-22.\nKingman, J. F. C. (1967). Completely random measures. Pacific J. Math. 21 59-78.\nK\u00fcchler, U. and Sorenson, M. (1997). Exponential Families of Stochastic Processes. Springer-Verlag,\nNew York.\nLe Cam, L. (1986). Asymptotic Methods in Statistical Decision Theory. Springer-Verlag, New York.\nLe Cam, L. (1961). A stochastic description of precipitation. In 1961 Proc. 4th Berkeley Sympos. Math.\nStatist. and Prob., Vol. III Univ. California Press, Berkeley Calif. 165-186.\nLee, M.L.T. and Whitmore, G. (1993). Stochastic processes directed by randomized time. Journal of\nApplied Probability 30 302-314.\nLast, G. and Brandt, A. (1995). Marked Point Proceses on the Real Line: The Dynamic Approach.\nSpringer, New York.\nLindsay, B. (1995). Mixture models: theory, geometry, and applications. NSF-CBMS Regional Conference\nSeries in Probability and Statistics, Volume 5. Institute for Mathematical Statistics: Hayward, CA,\nHayward, CA.\nLo, A. Y. (1982). Bayesian nonparametric statistical inference for Poisson point processes. Z. Wahrsch.\nverw. Gebiete 59 55-66.\nLo, A. Y. (1984). On a class of Bayesian nonparametric estimates: I. Density estimates. Ann. Statist. 12\n351-357.\nLo, A. Y. (1993). A Bayesian bootstrap for censored data. Ann. Statist. 21 100\u2013123.\n\n\f54\n\nPoisson Process Calculus\n\nLo, A. Y. and Weng, C. S. (1989). On a class of Bayesian nonparametric estimates: II. Hazard rates\nestimates. Ann. Inst. Stat. Math 41 227-245.\nLo, A.Y., Brunner, L.J. and Chan, A.T. (1996). Weighted Chinese restaurant processes and Bayesian\nmixture model. Research Report Hong Kong University of Science and Technology.\nMacEachern, S. N., Clyde, M. and Liu, J. S. (1999). Sequential importance sampling for nonparametric\nBayes models: the next generation. Canadian J. Statist. 27 251-267.\nMatthes, K. Kerstan, J., and Mecke, J. (1978). Infinitely Divisible Point Processes. English Edition.\nWiley, Chichester.\nMcCloskey, J. W. (1965). A Model for the Distribution of Individuals by Species in an Environment.\nPh.D. Thesis. Michigan State University.\nPachl, J. K. (1978). Disintegration and compact measures. Math. Scand. 43 157-168.\nPerman, M., Pitman, J. and Yor, M. (1992). Size-biased sampling of Poisson point processes and\nexcursions. Probab. Theory Related Fields 92 21-39.\nPitman, J. (1995a). Exchangeable and partially exchangeable random partitions. Probab. Theory Related\nFields 102 145-158.\nPitman, J. (1995b). Poisson-Kingman partitions. Available at www.stat.berkeley.edu/users/pitman\nPitman, J. (1996). Some developments of the Blackwell-MacQueen urn scheme. In Statistics, Probability\nand Game Theory (T.S. Ferguson, L.S. Shapley and J.B. MacQueen, eds.) 245-267. IMS Lecture\nNotes-Monograph series, Vol 30.\nPitman, J. (1997a). Partition structures derived from Brownian motion and stable subordinators. Bernoulli\n3 79-96.\nPitman, J. (1997b). Some probabilistic aspects of set partitions. Amer. Math. Monthly, 201-209.\nPitman, J. (1999). Coalescents with multiple collisions. Ann. Probab 27 1870-1902.\nPitman, J. and Yor, M. (1992). Arcsine laws and interval partitions derived from a stable subordinator.\nProc. London Math. Soc. 65 326\u2013356.\nPitman, J. and Yor, M. (1997). The two-parameter Poisson-Dirichlet distribution derived from a stable\nsubordinator. Ann. Probab. 25 855-900.\nPitman, J. and Yor, M. (2001). On the distribution of ranked heights of excursions of a Brownian bridge.\nAnn. Probab. 29 361-384.\nPollard, D. (2001). User's Guide to Measure Thoeretic Probability. Cambridge University Press\nRosinski, J. (2001). Series representations of L\u00e9vy processes from the perspective of point processes. In L\u00e9vy\nProcesses: Theory and Applications. Eds. Brandorff-Nielsen, Mikosch, and Resnick, pp. 401-415.\nBirkhauser, Boston..\nRota, G-C. (1964). The number of partitions of a set. American Mathematical Monthly 71 498-504.\nSato, K. (1999). L\u00e9vy Processes and Infinitely Divisible proceses. Cambridge University Press, Cambridge,\nUK.\nSusarla, V. and Van Ryzin, J. (1976). Nonparametric Bayesian estimation of survival curves from incomplete observations. J. Amer. Statist. Assoc 71 897-902.\nTsilevich, N. V. (1997). Distribution of the mean value for certain random measures. POMI preprint No.\n240, Steklov Institute of Mathematics, St. Petersburg. English translation in Journal of Mathematical Sciences, vol. 96 (1999), No. 5, pp. 3616-3623..\nTsilevich, N. V., Vershik, A. M, and Yor, M. (2001). An infinite-dimensional analogue of the Lebesque\nmeasure and distinguished properties of the gamma process. J. Funct. Anal 185 274-296.\nTsilevich, N. V., Vershik, A. M, and Yor, M. (2000). Distingusihed properties of the gamma process\nand related topics, Pr\u00e9publication du Laboratoire de Probabilit\u00e9s et Mod\u00e8les Al\u00e9atoires no. 575,\nMars 2000.\nTurnbull, B. W. (1976). The empirical distribution function with arbitrarily grouped, censored and truncated data. J. Roy. Statist. Soc. Ser. B 38 290-295.\n\n\fJames\n\n55\n\nTweedie, M.C.K. (1984). An index which distinguishes between some important exponential families.\nIn Statistics: Applications and New Directions Eds. J.K. Ghosh and J. Roy, pp. 579-604. Indian\nStatistical Institute, Calcutta.\nWalker, S. and Muliere, P. (1997). Beta-Stacy processes and a generalization of the P\u00f3lya-urn scheme.\nAnn. Statist. 25 1762-1780.\nWolpert, R. L. and Ickstadt, K. (1988a). Poisson/Gamma random field models for spatial statistics.\nBiometrika 85 251-267.\nWolpert, R. L. and Ickstadt, K. (1998b). Simulation of L\u00e9vy random fields. In Practical Nonparametric\nand Semiparametric Bayesian Statistics (D. Dey, P. Mueller and D. Sinha, eds.) 227-241. Springer\nLecture Notes.\n\nLancelot F. James\nThe Hong Kong University of Science and Technology\nDepartment of Information Systems and Management\nClear Water Bay, Kowloon\nHong Kong\nlancelot@ust.hk\n\n\f"}