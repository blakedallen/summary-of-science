{"id": "http://arxiv.org/abs/1108.2356v1", "guidislink": true, "updated": "2011-08-11T09:25:33Z", "updated_parsed": [2011, 8, 11, 9, 25, 33, 3, 223, 0], "published": "2011-08-11T09:25:33Z", "published_parsed": [2011, 8, 11, 9, 25, 33, 3, 223, 0], "title": "Impact of Frequentist and Bayesian Methods on Survey Sampling Practice:\n  A Selective Appraisal", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.2895%2C1108.4019%2C1108.5762%2C1108.2535%2C1108.2647%2C1108.1039%2C1108.3266%2C1108.3269%2C1108.6174%2C1108.3376%2C1108.3671%2C1108.4841%2C1108.1147%2C1108.4047%2C1108.2379%2C1108.2702%2C1108.1950%2C1108.1690%2C1108.2823%2C1108.4647%2C1108.1325%2C1108.6239%2C1108.1062%2C1108.4722%2C1108.1275%2C1108.1898%2C1108.1307%2C1108.3859%2C1108.2402%2C1108.1938%2C1108.0310%2C1108.1791%2C1108.6202%2C1108.1645%2C1108.1957%2C1108.2048%2C1108.0715%2C1108.2069%2C1108.6015%2C1108.2962%2C1108.5468%2C1108.1861%2C1108.1155%2C1108.4885%2C1108.2345%2C1108.0284%2C1108.4547%2C1108.2103%2C1108.4463%2C1108.4999%2C1108.3334%2C1108.5384%2C1108.1785%2C1108.4924%2C1108.3548%2C1108.5936%2C1108.2200%2C1108.6217%2C1108.3715%2C1108.2841%2C1108.5032%2C1108.3321%2C1108.3192%2C1108.5592%2C1108.4295%2C1108.2356%2C1108.6252%2C1108.1650%2C1108.3901%2C1108.3538%2C1108.1473%2C1108.5862%2C1108.5841%2C1108.4773%2C1108.4343%2C1108.4855%2C1108.1011%2C1108.3899%2C1108.1660%2C1108.2251%2C1108.2501%2C1108.0591%2C1108.0985%2C1108.1265%2C1108.0643%2C1108.5450%2C1108.5664%2C1108.5781%2C1108.4264%2C1108.1680%2C1108.4080%2C1108.1603%2C1108.5091%2C1108.5956%2C1108.6055%2C1108.1802%2C1108.0795%2C1108.4853%2C1108.4239%2C1108.1543%2C1108.1552&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Impact of Frequentist and Bayesian Methods on Survey Sampling Practice:\n  A Selective Appraisal"}, "summary": "According to Hansen, Madow and Tepping [J. Amer. Statist. Assoc. 78 (1983)\n776--793], \"Probability sampling designs and randomization inference are widely\naccepted as the standard approach in sample surveys.\" In this article, reasons\nare advanced for the wide use of this design-based approach, particularly by\nfederal agencies and other survey organizations conducting complex large scale\nsurveys on topics related to public policy. Impact of Bayesian methods in\nsurvey sampling is also discussed in two different directions: nonparametric\ncalibrated Bayesian inferences from large samples and hierarchical Bayes\nmethods for small area estimation based on parametric models.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.2895%2C1108.4019%2C1108.5762%2C1108.2535%2C1108.2647%2C1108.1039%2C1108.3266%2C1108.3269%2C1108.6174%2C1108.3376%2C1108.3671%2C1108.4841%2C1108.1147%2C1108.4047%2C1108.2379%2C1108.2702%2C1108.1950%2C1108.1690%2C1108.2823%2C1108.4647%2C1108.1325%2C1108.6239%2C1108.1062%2C1108.4722%2C1108.1275%2C1108.1898%2C1108.1307%2C1108.3859%2C1108.2402%2C1108.1938%2C1108.0310%2C1108.1791%2C1108.6202%2C1108.1645%2C1108.1957%2C1108.2048%2C1108.0715%2C1108.2069%2C1108.6015%2C1108.2962%2C1108.5468%2C1108.1861%2C1108.1155%2C1108.4885%2C1108.2345%2C1108.0284%2C1108.4547%2C1108.2103%2C1108.4463%2C1108.4999%2C1108.3334%2C1108.5384%2C1108.1785%2C1108.4924%2C1108.3548%2C1108.5936%2C1108.2200%2C1108.6217%2C1108.3715%2C1108.2841%2C1108.5032%2C1108.3321%2C1108.3192%2C1108.5592%2C1108.4295%2C1108.2356%2C1108.6252%2C1108.1650%2C1108.3901%2C1108.3538%2C1108.1473%2C1108.5862%2C1108.5841%2C1108.4773%2C1108.4343%2C1108.4855%2C1108.1011%2C1108.3899%2C1108.1660%2C1108.2251%2C1108.2501%2C1108.0591%2C1108.0985%2C1108.1265%2C1108.0643%2C1108.5450%2C1108.5664%2C1108.5781%2C1108.4264%2C1108.1680%2C1108.4080%2C1108.1603%2C1108.5091%2C1108.5956%2C1108.6055%2C1108.1802%2C1108.0795%2C1108.4853%2C1108.4239%2C1108.1543%2C1108.1552&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "According to Hansen, Madow and Tepping [J. Amer. Statist. Assoc. 78 (1983)\n776--793], \"Probability sampling designs and randomization inference are widely\naccepted as the standard approach in sample surveys.\" In this article, reasons\nare advanced for the wide use of this design-based approach, particularly by\nfederal agencies and other survey organizations conducting complex large scale\nsurveys on topics related to public policy. Impact of Bayesian methods in\nsurvey sampling is also discussed in two different directions: nonparametric\ncalibrated Bayesian inferences from large samples and hierarchical Bayes\nmethods for small area estimation based on parametric models."}, "authors": ["J. N. K. Rao"], "author_detail": {"name": "J. N. K. Rao"}, "author": "J. N. K. Rao", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/10-STS346", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1108.2356v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.2356v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in at http://dx.doi.org/10.1214/10-STS346 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.2356v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.2356v1", "journal_reference": "Statistical Science 2011, Vol. 26, No. 2, 240-256", "doi": "10.1214/10-STS346", "fulltext": "Statistical Science\n2011, Vol. 26, No. 2, 240\u2013256\nDOI: 10.1214/10-STS346\nc Institute of Mathematical Statistics, 2011\n\narXiv:1108.2356v1 [stat.ME] 11 Aug 2011\n\nImpact of Frequentist and Bayesian\nMethods on Survey Sampling Practice:\nA Selective Appraisal1\nJ. N. K. Rao\n\nAbstract. According to Hansen, Madow and Tepping [J. Amer. Statist.\nAssoc. 78 (1983) 776\u2013793], \"Probability sampling designs and randomization inference are widely accepted as the standard approach in sample surveys.\" In this article, reasons are advanced for the wide use of\nthis design-based approach, particularly by federal agencies and other\nsurvey organizations conducting complex large scale surveys on topics\nrelated to public policy. Impact of Bayesian methods in survey sampling\nis also discussed in two different directions: nonparametric calibrated\nBayesian inferences from large samples and hierarchical Bayes methods\nfor small area estimation based on parametric models.\nKey words and phrases: Bayesian pseudo-empirical likelihood, designbased approach, hierarchical Bayes methods, model-dependent approach,\nmodel-assisted methods, Polya posterior, small area estimation.\nbased approach. Neyman's approach was almost universally accepted by practicing survey statisticians\nSample surveys have long been conducted to ob- and it also inspired various important theoretical\ntain reliable estimates of finite population descrip- contributions, mostly motivated by practical and eftive parameters, such as totals, means, ratios and ficiency considerations. In this paper I will first proquantiles, and associated standard errors and nor- vide some highlights of the design-based approach,\nmal theory intervals with large enough sample sizes. for handling sampling errors, to demonstrate its sigProbability-sampling designs and randomization (re- nificant impact on survey sampling practice, espepeated sampling) inference, also called the design- cially on the production of official statistics (Secbased approach, played a dominant role, especially tions 2 and 3.1).\nin the production of official statistics, ever since the\nModel-dependent approaches (Section 3.2) that\npublication of the landmark paper by Neyman (1934) lead to conditional inferences more relevant and apwhich laid the theoretical foundations of the design- pealing than repeated sampling inferences have also\nbeen advanced (Brewer, 1963; Royall, 1970). Unfortunately, for large samples such approaches may\nJ. N. K. Rao is Distinguished Research Professor,\nperform very poorly under model misspecifications;\nSchool of Mathematics and Statistics, Carleton\neven small model deviations can cause serious probUniversity, Ottawa, Ontario K1S 5B6, Canada e-mail:\nlems (Hansen, Madow and Tepping, 1983). On the\njrao@math.carleton.ca.\n1\nDiscussed in 10.1214/11-STS346A, 10.1214/11-STS346B\nother hand, model-dependent approaches can play\nand 10.1214/11-STS346C; rejoinder at\na vital role in small area (domain) estimation, where\n10.1214/11-STS346REJ.\nthe area-specific sample sizes are very small or even\nzero and make the design-based area-specific direct\nThis is an electronic reprint of the original article\npublished by the Institute of Mathematical Statistics in estimation either very unreliable or not feasible. Demand for reliable small area statistics has greatly inStatistical Science, 2011, Vol. 26, No. 2, 240\u2013256. This\ncreased in recent years and to meet this growing dereprint differs from the original in pagination and\ntypographic detail.\nmand, federal statistical agencies and other survey\n1. INTRODUCTION\n\n1\n\n\f2\n\nJ. N. K. RAO\n\norganizations are currently paying considerable attention to producing small area statistics using models and methods that can \"borrow strength\" across\nareas. Hierarchical Bayes (HB) model-dependent methods are particularly attractive in small area estimation because of their ability to handle complex\nmodeling and provide \"exact\" inferences on desired\nparameters (Section 5). I will highlight some HB\ndevelopments in small area estimation that seem to\nhave a significant impact on survey practice. I will\nalso discuss the role of nonparametric Bayesian methods for inferences, based on large area-specific sample sizes, especially those providing Bayesian inferences that can be also justified under the designbased framework (Section 4.2).\nModels are needed, regardless of the approach used,\nto handle nonsampling errors that include measurement errors, coverage errors and missing data due to\nnonresponse. In the design-based approach, a combined design and modeling approach is used to minimize the reliance on models, in contrast to fully\nmodel-dependent approaches (Section 3.4).\nFor simplicity, I will focus on descriptive parameters, but survey data are also increasingly used for\nanalytical purposes, in particular, to study relationships and making inferences on model parameters\nunder assumed super-population models. For example, social and health scientists are interested in fitting linear and logistic regression models to survey\ndata and then making inferences on the model parameters taking account of the survey design features (Section 3.3).\n2. DESIGN-BASED APPROACH: EARLY\nLANDMARK CONTRIBUTIONS\nIn this section I will highlight some early landmark contributions to the design-based approach\nthat had major impact on survey practice. Prior to\nNeyman (1934), sampling was implemented either\nby \"balanced\" sampling through purposive selection or by probability sampling with equal inclusion\nprobabilities. Such a method was called the \"representative method.\" Bowley (1926) studied stratified random sampling with proportional sample size\nallocation, leading to a representative sample with\nequal inclusion probabilities. Neyman (1934) broke\nthrough this restrictive setup by relaxing the condition of equal inclusion probabilities and introducing the ideas of efficiency and optimal sample size\nallocation in his theory of stratified random sampling. He also demonstrated that balanced purposive sampling may perform poorly if the underlying\n\nmodel assumptions are violated. Neyman proposed\nnormal theory confidence intervals for large samples\nsuch that the frequency of errors in the confidence\nstatements based on all possible stratified random\nsamples that could be drawn does not exceed the\nlimit prescribed in advance \"whatever the unknown\nproperties of the finite population.\" He broadened\nthe definition of representative method by calling\nany method of sampling that satisfies the above frequency statement as representative. It is interesting to note that Neyman advocated distribution-free\ndesign-based inferences for survey sampling in contrast to his own fundamental work on parametric\ninference, including the Neyman\u2013Pearson theory of\nhypothesis testing and confidence intervals.\nThe possibility of developing efficient probability\nsampling designs by minimizing total cost subject\nto a specified precision of an estimator or maximizing precision for a given cost, taking account of operational considerations, and making distributionfree inferences (point estimation, variance estimation and large sample confidence intervals) through\nthe design-based approach were soon recognized.\nThis, in turn, led to a significant increase in the\nnumber and type of surveys taken by probability\nsampling and covering large populations. In the early\nstages, the primary focus was on sampling errors.\nI now list a few important post-Neyman theoretical developments in the design-based approach. As\nearly as 1937, Mahalanobis used multistage sampling designs for crop surveys in India. His classic\n1944 paper (Mahalanobis, 1944) presents a rigorous\ntheoretical setup and a generalized approach to the\nefficient design of sample surveys of different crops\nin Bengal, India, with emphasis on variance and\ncost functions. Mahalanobis considered a geographical region of finite area and defined a field consisting\nof \"a finite number, say, N0 , of basic cells arranged\nin a definite space or geographic order together with\na single value (or a set of values in the multivariate\ncase) of z for each basic cell,\" where z is the variable\nof interest (say, crop yield). Under this setup, he\nstudied four different probability sampling designs\nfor selecting a sample of cells (called quads): unitary unrestricted, unitary configurational, zonal unrestricted and zonal configurational. In modern terminology, the four designs correspond to simple random sampling, stratified random sampling, singlestage cluster sampling and single-stage stratified cluster sampling, respectively. He developed realistic cost\nfunctions depending on particular situations. He also\nextended the theoretical setup to subsampling of\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nclusters (which he named as two-stage sampling).\nWe refer the reader to Murthy (1964) for a detailed\naccount of the 1944 paper and other contributions of\nMahalanobis to sample surveys. Hall (2003) provides\na scholarly historical account of the pioneering contributions of Mahalanobis to the early development\nof survey sampling in India. Mahalanobis was instrumental in establishing the National Sample Survey\nof India and the famous Indian Statistical Institute.\nSurvey statisticians at the U.S. Census Bureau,\nunder the leadership of Morris Hansen, made fundamental contributions to survey sampling theory and\npractice during the period 1940\u20131970, and many of\nthose methods are still widely used in practice. This\nperiod is regarded as the golden era of the Census\nBureau. Hansen and Hurwitz (1943) developed the\nbasic theory of stratified two-stage cluster sampling\nwith one cluster or primary sampling unit (PSU)\nwithin each stratum drawn with probability proportional to a size measure (PPS) and then subsampled\nat a rate that ensures self-weighting (equal overall\nprobabilities of selection). This method provides approximately equal interviewer work loads which are\ndesirable in terms of field operations. It can also lead\nto significant variance reduction by controlling the\nvariability arising from unequal PSU sizes without\nactually stratifying by size and thus allowing stratification on other variables to further reduce the variance. The Hansen\u2013Hurwitz method, with some modifications, has been widely used for designing largescale socio-economic, health and agricultural surveys throughout the world. Many large-scale surveys\nare repeated over time, such as the monthly Current\nPopulation Survey (CPS), and rotation sampling\nwith partial replacement of ultimate units (e.g., households) is used to reduce response burden. Hansen\net al. (1955) developed simple but efficient composite estimators under rotation sampling in the context of stratified multistage sampling. Rotation sampling and composite estimation are widely used in\nlarge-scale surveys.\nPrior to the 1950s, the primary focus was on estimating totals, means and ratios for the whole population and large planned subpopulations such as US\nstates or provinces in Canada. Woodruff (1952) developed a unified design-based approach for constructing confidence intervals on quantiles using only the\nestimated distribution function and the associated\nstandard error. This ingenious method is applicable\nto general probability sampling designs and performs\nwell in terms of coverage probabilities in many cases.\n\n3\n\nWoodruff intervals can also be used to obtain standard errors of estimated quantiles (Rao and Wu,\n1987; Francisco and Fuller, 1991). Because of those\nfeatures, the Woodruff method had a significant impact on survey practice. However, the method should\nnot be treated as a black box for constructing confidence intervals on quantiles, because it can perform\npoorly in some practical situations. For example, it\nperformed very poorly under stratified random sampling when the population is stratified by a concomitant variable x highly correlated with the variable of interest y (Kovar, Rao and Wu, 1988). The\nfailure of the Woodruff method in this case stems\nfrom the fact that the standard error of the estimated distribution function at the quantile will be too\nsmall due to zero contributions to the standard error from most strata. Kovar, Rao and Wu (1988)\nshowed that the bootstrap method for stratified random sampling performs better than the Woodruff\nmethod in this case, but in other situations the Woodruff method is better.\nAttention was also given to inferences for unplanned subpopulations (also called domains) such as\nage\u2013sex groups within a state. Hartley (1959) and\nDurbin (1958) developed simple, unified theories for\ndomain estimation applicable to general designs, requiring only existing formulae for population totals\nand means.\nAfter the consolidation of basic design-based sampling theory, Hansen et al. (1951) and others paid attention to measurement errors in surveys. They developed basic theories under additive measurement\nerror models with minimal model assumptions on\nthe observed responses treated as random variables.\nTotal variance of an estimator is decomposed into\nsampling variance, simple response variance and correlated response variance (CRV) due to interviewers.\nThe CRV was shown to dominate the total variance when the number of interviewers is small, and\nthe 1950 U.S. Census interviewer variance validation study showed that this component is indeed\nlarge for small areas. Partly for this reason, selfenumeration by mail was first introduced in the 1960\nU.S. Census to reduce the CRV component. Earlier,\nMahalanobis (1946) developed the method of interpenetrating subsamples (called replicated sampling\nby Deming, 1960) and used it extensively in largescale surveys in India for assessing both sampling\nand interviewer errors. By assigning the subsamples\nat random to interviewers, the total variance can be\nestimated and interviewer differences assessed.\n\n\f4\n\nJ. N. K. RAO\n\nIt should be clear from the above brief description\nof early developments that much of the basic sampling theory was developed by official statisticians or\nthose closely associated with official statistics. Theory was driven by the need to solve real problems\nand often theory was not challenging enough to attract academic researchers to survey sampling. As\na result, university researchers paid little attention\nto survey sampling in those days with few exceptions\n(e.g., Iowa State University under the leadership of\nCochran, Jessen and Hartley).\n3. SOME RECENT DESIGN-BASED AND\nNON-BAYESIAN DEVELOPMENTS\n3.1 Model-Assisted Approach\nWe first give a brief account of the model-assisted\napproach that uses a working model to find efficient\nestimators. However, the associated inferences are\ndesign-based. Consider a finite population U consisting of N elements labeled 1, . . . , N with associated values y1 , . . . , yN of a variable of interest y.\nUnder a probability sampling design, the inclusion\nprobabilities \u03c01 , . . . , \u03c0N are all strictlyPpositive and\na basic estimator of the total Y = i\u2208U yi is of\nP\nthe form \u0176 = i\u2208s di yi , where s denotes a sample and di = \u03c0i\u22121 are the so-called design weights\n(Horvitz and Thompson, 1952; Narain, 1951). For\nexample, in the Neyman stratified random sampling\ndesign, the design weights are equal to the inverse\nof the sampling fractions within strata and vary\nacross strata, while in the Hansen et al. two-stage\ncluster sampling design, the design weights are all\nequal. Design unbiasedness of estimators is not insisted upon (contrary to statements in some papers\non inferential issues of sampling theory) because it\n\"often results in much larger MSE than necessary\"\n(Hansen, Madow and Tepping, 1983). Instead, design consistency is deemed necessary for large samples. Strategies (design and estimation) that appeared reasonable are entertained (accounting for costs)\nand relative properties are carefully studied by analytical and/or empirical methods, mainly through\nthe comparison of mean squared error (MSE) or anticipated MSE under plausible population models on\nthe variables yi treated as random variables. This is\nessentially the basis of the repeated sampling (or\ndesignbased) approach.\nIn recent years, a model-assisted repeated sampling approach has received the attention of survey\n\npractitioners. In this approach, a working population model is used to find efficient design-consistent\nestimators. For example, suppose the working model\nis a linear regression model of the form\n(1)\n\nyi = x\u2032i \u03b2 + \u03b5i ;\n\ni = 1, . . . , N,\n\nwith model errors \u03b5i assumed to be uncorrelated\nwith mean zero and variance proportional to a known\nconstant qi , where xi is a vector of auxiliary variables with known population total X. Under model (1), the best linear unbiased estimator (BLUE)\nof the model parameter \u03b2, based on the census values {(yi , xi ); i \u2208 U }, is given by the \"census\" regression coefficient\n\u0013\n\u0013\u22121 \u0012X\n\u0012X\nxi yi /qi .\nxi x\u2032i /qi\nB=\ni\u2208U\n\ni\u2208U\n\nA predictor of yi under the working model is then\ngiven by \u0177i = x\u2032i B\u0302 for i = 1, . . . , N where B\u0302 is the\ndesign-weighted estimator of B:\n\u0012X\n\u0013\u22121 \u0012X\n\u0013\ndi xi x\u2032i /qi\ndi xi yi /qi .\nB\u0302 =\ni\u2208s\n\ni\u2208s\n\nP\n\nP\nBy writing the total as Y = i\u2208U \u0177i + i\u2208U ei where\nei = yi \u2212 \u0177i denotes the prediction\na designP error, P\nbased estimator of Y is given by i\u2208U \u0177i + i\u2208s di ei .\nWe can express this estimator as a generalized regression (GREG) estimator\n(2)\n\n\u0176gr = \u0176 + B\u0302 \u2032 (X \u2212 X\u0302),\n\nP\nwhere X\u0302 = i\u2208s di xi (S\u00e4rndal, Swensson and Wretman, 1992). The GREG estimator (2) is designconsistent regardless of the validity of the working\nmodel (Robinson and Sarndal, 1983) under certain\nregularity conditions provided X is precisely correct. If the working model provides a good fit to the\ndata, then the residuals ei should be less variable\nthan the response values yi and the GREG estimator is likely to be significantly more efficient than\nthe basic design-weighted estimator \u0176 .\nThe estimator\n(2) may also be expressed as a weighP\nted sum i\u2208s wi yi , where wi = di gi with\n\u0013\u22121\n\u0012X\n\u2032\n\u2032\n(3) gi = 1 + (X \u2212 X\u0302)\nxi qi\u22121 .\ndi xi xi /qi\ni\u2208s\n\nThe adjustment factors gi , popularly known\nP as the gweights, ensure the calibration property i\u2208s wi xi =\nX so that the GREG estimator when applied to the\nsample values xi agrees with the known total X.\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nThis property is attractive to the user when the vector X contains user-specified totals.\nThe assumption of a working linear regression model (1) can be relaxed by adopting more flexible\nworking models. For example, Breidt, Claeskens and\nOpsomer (2005) proposed a nonparametric modelassisted approach based on a penalized spline (Pspline) regression working model and showed that\nthe resulting estimators are design-consistent and\nmore efficient than the usual GREG estimators based on linear regression working models when the\nlatter are incorrectly specified. Also, the P-spline\nmodel-assisted estimators were shown to be approximately as efficient as the GREG estimators when\nthe linear regression working model is correctly specified. The P-spline approach can be easily implemented using existing estimation packages for GREG\nbecause the underlying model is closely related to\na linear regression model. It offers a wider scope for\nthe model-assisted approach because it makes minimal assumptions on the regression of y on x without\nassuming a specific parametric form.\nUnder the model-assisted approach, design-consistent variance estimators are obtained either by a Taylor linearization method or by a resampling method\n(when applicable), provided the probability sampling\ndesign ensures strictly positive joint inclusion probabilities \u03c0ij , i 6= j. Using the estimator and associated\nstandard error, asymptotically valid normal theory\nintervals are obtained regardless of the validity of\nthe working model.\nMost large-scale surveys are multipurpose and observe multiple variables of interest, and the same\nworking model may not hold for all the variables\nof interest. In that case, a model-assisted approach\nmay lead to possibly different gi and hence different\ncalibration weights wi associated with the variables,\nthat is, the calibration weights are of the form wij\nassociated with the variable j and sample unit i.\nHowever, survey users prefer to use a common\nweight wi for all variables of interest. This is often accomplished by minimizing a suitable distance\nmeasure between di and wi for i \u2208 s subject\nto userP\nspecified calibration constraints, say, i\u2208s wi zi = Z,\nwithout appealing to any working model, where Z is\nthe vector of known totals associated with the userspecified variables z. For example, a chi-squared distance measure leads to common calibration\nweights wi of the form di gi where gi is given by (3)\nwith xi replaced by zi (Deville and Sarndal, 1992).\nThus, calibration estimation in this case corresponds\n\n5\n\nto using model-assisted estimation based on a linear\nregression model (1) with zi as the vector of predictor variables. Calibration estimation has attracted\nthe attention of users due to its ability to produce\ncommon calibration weights and accommodate an\narbitrary number of user-specified calibration (or\nbenchmark) constraints, for example, calibration to\nthe marginal counts of several post-stratification variables. Several national statistical agencies have developed software designed to compute calibration\nweights: GES (Statistics Canada), LIN WEIGHT\n(Statistics Netherlands), CALMAR (INSEE, France)\nand CLAN97 (Statistics Sweden). Sarndal (2007)\nsays, \"Calibration has established itself as an important methodological instrument in large-scale production of statistics.\" Brakel and Bethlehem (2008)\nnoted that the use of common calibration weights for\nestimation in multipurpose surveys makes the calibration method \"very attractive to produce timely\nofficial releases in a regular production environment.\"\nUnfortunately, the model-free calibration approach\ncan lead to erroneous inferences for some of the response variables, even in fairly large samples if the\nunderlying working linear regression model uses an\nincorrect or incomplete set of auxiliary variables, unlike the model-assisted approach that uses a working\nmodel obtained after some model checking. For example, suppose that the underlying model is a quadratic regression model of y on x and the distribution of x is highly skewed. Also, suppose that the\nuser-specified calibration constraints are the known\npopulation size N and the known population total X. In this case, the calibration estimator of the\ntotal Y under simple random sampling is the familiar simple linear regression estimator with x as\nthe predictor variable. On the other hand, a modelassisted estimator under the quadratic regression\nworking model is given by a multiple linear regression estimator with x1 = x and x2 = x2 as the predictor variables, assuming the total of x2 is also\nknown. Rao, Jocelyn and Hidiroglou (2003) demonstrated that the coverage performance of the normal\ntheory interval associated with the calibration estimator is poor even in fairly large samples, unlike\nthe coverage performance of the normal theory intervals associated with the model-assisted estimator.\nThe coverage performance depends on the skewness\nof the residuals from the fitted model and in the\ncase of calibration estimation the skewness of residuals after fitting simple linear regression remains\nlarge, whereas the skewness of residuals after fitting\n\n\f6\n\nJ. N. K. RAO\n\nquadratic regression is small even if y and x are\nhighly skewed. This simple example demonstrates\nthat the population structure does matter in designbased inferences and that it should be taken into account through a model-assisted approach based on\nsuitable working models. But the model-assisted approach has the practical limitation that the weight wi\nmay vary across variables in surveys with multiple\nvariables of interest, unlike in the calibration approach. Also, for complex working models, such as\nthe P-spline, all the population values of the predictor variables should be known in order to implement\nthe model-assisted approach.\nThe model-assisted approach is essentially designbased, unlike the model-dependent approach (Section 3.2) that can provide conditional inferences referring to the particular sample, s, of units selected.\nSuch conditional inferences may be more relevant\nand appealing than the unconditional repeated sampling inferences used in the design-based approach.\n3.2 Model-Dependent Approach\nThe frequentist model-dependent approach to inference assumes that the population structure obeys\na specified population model and that the same model holds for the sample, that is, no sample selection\nbias with respect to the assumed population model.\nSampling design features are often incorporated into\nthe model to reduce or eliminate the sample selection bias (see Section 3.3 for some difficulties to implement this in practice). Typically, distributional\nassumptions are avoided by focusing on point estimation, variance estimation and associated normal\ntheory confidence intervals, as in the case of designbased inferences. As a result, models used specify\nonly the mean function and the variance function\nof the variable of interest, y.We refer the reader to\nValliant, Dorfman and Royall (2000) for an excellent\naccount of the model-dependent approach.\nAs noted in Section 1, model-dependent strategies\nmay perform poorly in large samples when the population model is not correctly specified; even small\ndeviations from the assumed model that are not\neasily detectable through routine model checking\ncan cause serious problems. In the Hansen, Madow\nand Tepping (1983) example of an incorrectly specified population model, the best linear unbiased prediction (BLUP) estimator of the mean is not design consistent under their stratified simple random\nsampling design with near optimal sample allocation (commonly used to handle highly skewed populations such as business populations). As a result,\n\nmodel-dependent confidence intervals exhibited poor\nperformance: for n = 100, coverage was around 70%\ncompared to nominal level of 95%, while coverage for\nmodel-assisted intervals was 94.4%. To get around\nthis difficulty, Little (1983) proposed restricting attention to models that hold for the sample and for\nwhich the BLUP estimator is design consistent. For\nexample, in the Hansen, Madow and Tepping (1983)\nexample, the BLUP of the mean under a model with\nmeans differing across strata is identical to the traditional stratified mean which is design consistent. But\nit seems not possible even to find a suitable model\nunder which the widely used combined ratio estimator of the mean under the stratified random sampling is the BLUP estimator. The combined ratio\nestimator is a model-assisted estimator under a ratio working model with a common slope. It allows\na large number of strata with few sample units from\neach stratum and yet remains design consistent, unlike the separate ratio estimator which is the BLUP\nestimator under a ratio model with separate slopes\nacross strata: E(yhi |xhi ) = \u03b2h xhi , V (yhi |xhi ) = \u03c3 2 xhi ,\nwhere yhi and xhi denote the values of the variable\nof interest y and an auxiliary variable x for the unit i\nin stratum h. Moreover, the BLUP estimator under\nthis model requires the knowledge of the strata population means X\u0304h , whereas the combined ratio estimator requires only the overall population mean X\u0304.\nIt is also not clear how one proceeds to formulate\nsuitable models for general sampling designs that\nlead to design-consistent BLUP estimators. Further,\nthe main focus has been on point estimation and it\nis not clear how one should proceed with variance\nestimation and setting up confidence intervals that\nhave repeated sampling validity. In this context, Pfeffermann (2008) says, \"I presume that these are\nsupposed to be computed under the corrected model\nas well. Are we guaranteed that they are sufficiently\naccurate under the model? Do we need to robustify\nthem separately?\" Little (2008), in his rejoinder to\nPfeffermann's comment, says that he advocates using some replication method for variance estimation\nand then appealing to normal approximation for\nconfidence intervals. Clearly, further work is needed\nto address the above issues. Note that if parametric\nassumptions are made, such as normality of model\nerrors, then it is possible to make exact Bayesian inferences by introducing suitable priors on the model\nparameters (Section 4).\nSome recent work on the model-dependent approach focused on avoiding misspecification of the\nmean function E(y|x) = m(x) by using P-spline mod-\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nels. Zheng and Little (2003, 2005) studied single\nstage PPS sampling using a P-spline model, based on\nthe size measure x used in PPS sampling, to represent the regression function m(x), and a specified\nfunction of the size measure as the variance function. In a simulation study, they compared the performance of the usual linear GREG estimator and\nthe P-spline model-based estimators, not necessarily\ndesign-consistent, and showed that the P-spline model-based estimators are generally more efficient than\nthe GREG or the NHT estimator in terms of design\nMSE even for large samples. However, the simulation study did not consider model-assisted estimators corresponding to their P-spline model. The simulations also showed that the design-bias for their Pspline estimators is minor, even though the estimators are not design-consistent, and hence the authors\nconclude that \"design consistency may not be of\nparamount importance.\" On the other hand, in the\nBreidt, Claeskens and Opsomer (2005) simulation\nstudy, their model-assisted P-spline estimator is sometimes much better, and never worse, than the corresponding P-spline model-based estimator under\nstratified random sampling. The latter estimator is\nnot design-consistent under the P-spline model considered by Breidt, Claeskens and Opsomer (2005).\nAs noted above, a main advantage of the frequentist model-dependent approach is that it leads to inferences conditional on the selected sample of units,\ns, unlike the unconditional design-based approach.\nHowever, it is possible to develop a conditional model-assisted approach that allows us to restrict the\nreference set of samples to a \"relevant\" subset of\nall possible samples specified by the design. Conditionally valid inferences for large samples can then\nbe obtained. Rao (1992) and Casady and Valliant\n(1993) developed an \"optimal\" linear regression estimator that is asymptotically valid under the conditional setup.\nWe refer the reader to Kalton (2002) for compelling arguments for favoring design-based approaches\n(possibly model-assisted and/or conditional) to handle sampling errors. Smith (1994) named the traditional repeated sampling inference as \"procedural\ninference\" and argued that procedural inference is\nthe correct approach for surveys in the public domain.\n3.3 Analysis of Complex Survey Data\nData collected from large-scale socio-economic,\nhealth and other surveys are being extensively used\nfor analysis purposes, such as inferences on the re-\n\n7\n\ngression parameters of linear and logistic regression\npopulation models. Ignoring the survey design features and using standard methods can lead to erroneous inferences on model parameters because of\nsample selection bias caused by informative sampling. It is tempting to expand the models by including among the predictors all the design variables\nthat define the selection process at the various levels and then ignore the design and apply standard\nmethods to the expanded model. The main difficulties with this approach, advocated by some leading\nresearchers, are the following, among others (Pfeffermann and Sverchkov, 2003): (1) Not all design\nvariables may be known or accessible to the analyst.\n(2) Too many design variables can lead to difficulties in making inferences from the expanded models.\n(3) The expanded model may no longer be of scientific interest to the analyst.\nThe design-based approach can provide asymptotically valid repeated sampling inferences without changing the analyst model. A unified approach\nbased on survey-weighted estimating equations leads\nto design-consistent estimators of the \"census\" or finite population parameters, which in turn estimate\nthe associated model parameters. Further, using resampling methods for variance estimation, such as\nthe jackknife and the bootstrap for survey data,\nasymptotically valid design-based inferences on the\ncensus parameters can be implemented. The same\nmethods may also be applicable for inference on the\nmodel parameters, in many cases of large-scale surveys. In the other cases, it is necessary to estimate\nthe model variance of the census parameters from\nthe sample. The estimate of the total variance is\nthen given by the sum of this estimate and the resampling variance estimate.\nIn practice, the data file would contain for each sampled unit the variables of interest and predictor variables, final weights after adjustment for unit nonresponse and the corresponding replication weights,\nfor example, bootstrap weights. The analyst can use\nsoftware that handles survey weights (such as SAS)\nto obtain point estimates from the final weights and\nthe corresponding point estimates for each bootstrap replicate using bootstrap weights. The variability of the bootstrap point estimates provides asymptotically valid standard errors for designs commonly\nused in large-scale surveys. Details of the methods\nare not provided due to space limitations, but the\nreader is referred to Rao (2005, Section 6) for a succinct account of analysis of survey data using resampling methods for variance estimation and nor-\n\n\f8\n\nJ. N. K. RAO\n\nmal theory confidence intervals. Design-based approach using resampling methods is extensively used\nin practice and software is also available (e.g., WesVar, Stata).\nThe design-based approach has also been applied\nto make inferences on the regression parameters and\nthe variance parameters of multilevel models from\ndata obtained from multistage sampling designs corresponding to the levels of the model. For example,\nin an education study of students, schools (first-stage units or clusters) may be selected with probabilities proportional to school size and students (secondstage units) within selected schools by stratified random sampling. Again, ignoring the sampling design\nand using traditional methods for multilevel models that ignore the design can lead to erroneous inferences in the presence of sample selection bias.\nIn the design-based approach, estimation of variance parameters of the model is more difficult than\nthat of regression parameters and the necessary information for estimating variance parameters is often not provided in public-use data files which typically report only the final weight for each sample unit. Widely used design-based methods have\nbeen proposed in the literature (e.g., Pfeffermann et\nal., 1998, and Rabe-Hesketh and Skrondal, 2006) to\nhandle variance parameters that require the weights\nwithin sampled clusters in addition to the weights\nassociated with the clusters. Some of those methods can be implemented using the Stata program\ngllamm. Unfortunately, the resulting estimators of\nvariance parameters may not be design-model consistent when the sample sizes within clusters are\nsmall, even for two-level linear models. Korn and\nGraubard (2003) demonstrated the bias problem and\nproposed a different method for simple two-level or\nthree-level models involving only a common mean\nas the fixed effect. This method first obtains the\ncensus parameters and then estimates those parameters. It worked well in empirical studies even for\nsmall within-cluster sample sizes. Rao, Verret and\nHidiroglou (2010) proposed a weighted estimating\nequations (WEE) approach for general two-level linear models that uses within-cluster joint inclusion\nprobabilities, similar to Korn and Graubard (2003).\nThe WEE method leads to design-model consistent\nestimators of variance parameters even for small\nwithin-cluster sample sizes, provided the number of\nsample clusters is large. It performed well in empirical studies compared to the other methods proposed in the literature. Rao, Verret and Hidiroglou\n\n(2010) also proposed a unified approach based on\na weighted log-composite likelihood that can handle generalized linear multilevel models and small\nwithin-cluster sample sizes. This method is currently\nunder investigation.\nA drawback of the design-based approach to the\nanalysis of survey data is that it may lead to loss in\nefficiency when the final weights vary considerably\nacross the sampling units. Alternative approaches\nthat can reduce the variability of the weights and\nthus lead to more efficient estimators have also been\nproposed (e.g., Pfeffermann and Sverchkov, 2003;\nFuller, 2009, Chapter 6). We refer the reader to Pfeffermann (1993) and Rao et al. (2010) for overviews\non the role of sampling weights in the analysis of\nsurvey data.\n3.4 Nonsampling Errors\nSurvey practitioners have to rely on models, regardless of the approach used, to handle nonsampling errors that include measurement errors, coverage errors and missing data due to unit nonresponse and item nonresponse. In the design-based\napproach, a combined design and modeling approach\nis used to minimize the reliance on models, in contrast to fully model-dependent approaches that will\nhave similar difficulties noted in the previous subsections. As mentioned in Section 1, Hansen et al.\n(1951) studied measurement errors under minimal\nmodel assumptions on the observed responses treated as random variables, and their discovery that\nthe correlated response variance due to interviewers dominates the total variance when the number\nof interviewers is small led to the adoption of self\nenumeration by mail in the 1960 U.S. Census.\nInference in the presence of missing survey data,\nparticularly item nonresponse, has attracted a lot\nof attention; see Little and Rubin (2002) for an excellent account of missing data methods. To handle item nonresponse, imputation of missing data\nis often used because of its practical advantages. In\nthe design-based approach, traditional weighted estimators of a total or a mean are computed from\nthe completed data set, leading to an imputed estimator. Often imputed values are generated from an\nimputation model assumed to hold for the respondents under a missing at random (MAR) response\nmechanism. Under this setup, the imputed estimator is unbiased or asymptotically unbiased under the\ncombined design and model set up. Reiter, Raghunathan and Kinney (2006) demonstrated the importance of incorporating sampling design features into\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nthe imputation model in order to make the model\nhold for the sample and then for the respondents\nunder the assumed MAR response mechanism. An\nalternative approach avoids imputation models but\nassumes a model for the response mechanism. For\nexample, a popular method consists of forming imputation classes (according to the values of estimated response probabilities under a specified response model) and assuming that the missing values\nare missing completely at random (MCAR) within\nclasses. The missing values are then imputed by selecting donors at random from the observed values\nwithin classes. It may be also possible to develop\nimputation methods that make an imputed estimator doubly robust in the sense that it is valid either\nunder an assumed imputation model or under an\nassumed response mechanism (e.g., see Haziza and\nRao, 2006). Doubly robust estimation has attracted\nconsiderable attention in the nonsurvey literature\n(see, e.g., Cao, Tsiatis and Davidian, 2009).\nVariance estimation under imputation for missing\nsurvey data has attracted a lot of attention because\ntreating the imputed values as if observed and then\napplying standard variance formulae can often lead\nto serious underestimation because the additional\nvariability due to estimating the missing values is\nnot taken into account. Methods that can lead to\nasymptotically valid variance estimators under single imputation for missing data have been proposed\nunder the above setups. We refer the reader to Kim\nand Rao (2009) for a unified approach to variance\nestimation under the imputation model approach,\nand to Haziza (2009) for an excellent overview of\nimputation for survey data and associated methods\nfor inference. Rubin (1987) proposed multiple imputation to account for the underestimation when applying standard formulae treating the imputed values as if observed. Under this approach, M (\u2265 2)\nimputed values are generated for a missing item,\nleading to M completed data sets. Rubin recommends the use of traditional design-based estimators and variance estimators, computed from each\nof the completed data sets, although multiple imputation ideas are based on a Bayesian perspective: \"We restrict attention to standard scientific\nsurveys and standard complete data statistics\" (Rubin, 1987, page 113). Multiple imputation estimator \u0176MI of a total Y is taken as the average of the M\nestimators \u0176I1 , . . . , \u0176IM , and its estimator of variance is given by vMI = v\u0304M + (1 + M \u22121 )bM , where v\u0304M\nis the average of the M na\u0131\u0308ve variance estimators\n\n9\n\nP\n2\nvI1 , . . . , vIM and bM =(M \u22121)\u22121 M\nm=1 (\u0176Im \u2212 \u0176MI ) .\nRubin gives design-based conditions for \"proper imputation\" that ensure the repeated sampling validity of the estimator \u0176MI and the associated variance\nestimator vMI under a posited response mechanism.\nUnfortunately, there are some difficulties in developing imputation methods satisfying Rubin's conditions for \"proper imputation\" with complex survey\ndata (see, e.g., Kim et al., 2006). Nevertheless, multiple imputation shows how Bayesian ideas can be\nintegrated to some extent with the traditional design-based approach that is widely used in practice.\n4. BAYESIAN APPROACHES\nThis section provides an account of both parametric and nonparametric Bayesian (and pseudoBayesian) approaches to inference from survey data,\nfocusing on descriptive finite population parameters.\n4.1 Parametric Bayesian Approach\nAs noted in Section 3.2, the frequentist modeldependent approach mostly avoided distributional\nassumptions by specifying only the mean function\nand the variance function of the variable of interest. Under a specified distribution on the assumed\nmodel, Bayesian inferences can be easily implemented, provided the model holds for the sample. Royall\nand Pfeffermann (1982) studied Bayesian inference\non the population mean assuming normality and flat\n(diffuse) priors on the parameters of a linear regression model. Their focus was on the posterior mean\nand the posterior variance and, hence, results were\nsimilar to those of Royall (1970) without the normality assumption and priors on model parameters.\nHowever, exact credible intervals on the mean and\nother parameters of interest can be obtained conditional on the observed data, using a parametric\nBayesian setup. It can be implemented even under complex modeling, using powerful Monte Carlo\nMarkov chain (MCMC) methods to simulate samples from the posterior distributions of interest. Scott\nand Smith (1969) obtained the posterior mean and\nthe posterior variance of the population mean under linear models with random effects, normality\nand diffuse priors on the model parameters. Their\nposterior mean is also the BLUP estimator without\nthe normality assumption when the variance parameters of the model are known. In the frequentist approach, estimates of variance parameters are substituted in the BLUP to get the empirical BLUP\n\n\f10\n\nJ. N. K. RAO\n\n(EBLUP) estimator which is different (but close to)\nto the posterior mean. However, the Bayesian approach also provides the posterior variance which is\ntypically different from the estimated mean squared\nprediction error (MSPE) of the EBLUP estimator;\nseveral different methods of estimating MSPE have\nbeen proposed in the context of small area estimation (Rao, 2003, Chapter 7). A simulation study by\nBellhouse and Rao (1986) showed that any gain in\nefficiency of the posterior mean (or the BLUP) over\ntraditional design-based estimators is likely to be\nsmall in practice. However, by regarding the clusters\nas small areas of interest, the Scott\u2013Smith approach\nprovides models linking the small areas and the resulting estimators of small area means can lead to\nsignificant efficiency gains over direct area-specific\nestimators. Random cluster effect models are now\nextensively used to construct efficient small area estimators by \"borrowing strength\" across small areas using auxiliary information (Section 5). It may\nbe noted that the empirical Bayes (EB) approach\nto inference from random cluster effect models is\nsimilar to EBLUP, but it can handle general parametric random cluster effect models and does not\nrequire the linearity assumption used in the BLUP\nmethod. The EB approach is essentially frequentist,\nunlike the Bayesian approach that requires the specification of priors on the model parameters. It may\nbe more appropriate to name \"empirical Bayes\" as\n\"empirical best\" without changing the abbreviation\nEB (Jiang and Lahiri, 2006).\nSedransk (1977) studied regression models with random slopes \u03b21 , . . . , \u03b2L \u223ci.i.d. N (\u03bd, \u03c3\u03b22 ), using a prior\ndistribution on \u03bd specified as N (\u03b20 , \u03c302 ). He then\nfollowed the Scott and Smith (1969) approach and\nobtained posterior mean and posterior variance of\nthe finite population total. He applied the method\nto data on banks from the U.S. Federal Reserve\nBoard to estimate a current monetary total making\nuse of extensive historical data to specify the values of \u03b20 , \u03c302 and thus arrive at an informative\nprior which in turn leads to more efficient posterior inferences compared to those based on a noninformative prior, provided the informative prior is\ncorrectly specified. Malec and Sedransk (1985) extended Scott\u2013Smith results to three-stage sampling.\nNandram, Sedransk and Smith (1997) applied the\nBayesian approach to obtain order-restricted estimators of the age composition of a population of Atlantic cod, using MCMC methods. Sedransk (2008)\nlists possible uses of parametric Bayesian methods\nfor sample surveys, including the above application\n\nto estimation from establishment surveys, \"optimal\"\nsample allocation and small area estimation from data pooled from independent surveys (see Section 5).\nPfeffermann, Moura and Silva (2006) report an interesting application of the Bayesian approach to\nmake inferences from multilevel models under informative sampling. In this case, the multilevel sample\nmodel induced by informative sampling is more complicated than the corresponding population model\nand, as a result, frequentist methods are difficult to\nimplement. On the other hand, the authors show\nthat the Bayesian approach, using noninformative\npriors on the model parameters indexing the sample model and applying MCMC methods, is efficient\nand convenient for handling such complex sample\nmodels, although computer intensive. This application is an example where the Bayesian approach offers computational advantage over the corresponding frequentist approach.\n4.2 Nonparametric Bayesian Approaches\nFor multipurpose large-scale surveys, parametric\nBayesian methods based on distributional assumptions have limited value because of the difficulties\nin validating the parametric assumptions. It may be\nmore appealing to use a nonparametric Bayesian approach, but this requires the specification of a nonparametric likelihood function based on the full sample data {(i, yi ), i \u2208 s} and a prior distribution on\nthe parametric vector (y1 , . . . , yN ). The likelihood\nfunction based on the full sample data, however,\nis noninformative in the sense that all possible unobserved values of the parameter vector have the\nsame likelihood function (Godambe, 1966). One way\nout of this difficulty is to take a Bayesian route\nby assuming an informative (exchangeable) prior on\nthe N -dimensional parameter vector and combine it\nwith the noninformative likelihood (Ericson, 1969;\nBinder, 1982) to get an informative posterior, but\ninferences do not depend on the sample design; Ericson argued that an exchangeable prior assumption\nmay be reasonable under simple random sampling.\nEricson (1969) focused on the posterior mean and\nthe posterior variance of the population mean \u0232\nwhich approximately agree, under prior vagueness,\nwith the usual formulae under the design-based approach. In the case of stratified sampling with known\nstrata differences, priors within strata are assumed\nto be exchangeable.\nMeeden and Vardeman (1991) used a Polya posterior (PP) over the unobserved, assuming that \"unseen are like the seen\" (equivalent to exchangeabil-\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nity). In this case, the posterior \"does not arise from\na single prior distribution\" (Meeden, 1995) and, hence, it is called a pseudo-posterior. It is also similar\nto the Bayesian bootstrap (Rubin, 1981; Lo, 1988).\nThe Polya posterior is a flexible tool and methods\nbased on PP have reasonable design-based properties under simple random sampling. PP approach\npermits Bayesian interval estimation for the mean\nand any other parameters of interest through simulation of many finite populations from PP. The general interval estimation feature of the PP approach\nis attractive. Meeden (1995) extended the PP approach to utilize auxiliary population information\n(x1 , . . . , xN ) by making a strong prior assumption\nthat the ratios ri = yi /xi are exchangeable and obtained point and interval estimators for the population median. Empirical results under simple random sampling are given to show that the resulting\nBayesian intervals perform well in terms of designbased coverage. Lazar, Meeden and Nelson (2008)\ndeveloped a constrained Polya posterior to generate simulated populations that are consistent with\nthe known population mean of an auxiliary variable x, using MCMC methods. This approach permits the use of known population auxiliary information and leads to more efficient Bayesian inferences.\nNelson and Meeden (1998) adapted PP to incorporate prior knowledge that the population median belongs to some interval. Meeden (1999) studied twostage cluster sampling (balanced case) and his twostage PP-based results for the posterior mean and\nthe posterior variance are very close to standard\ndesign-based results, but it is not clear how readily Meeden's approach extends to the unbalanced\ncase with unequal cluster sizes. Although the PP approach is attractive and seems to provide calibrated\nBayesian inferences at least for some simple sampling designs, it is unlikely to be used in the production of official statistics because of the underlying assumption that \"unseen are like the seen\" and\neach case needs to be studied carefully to develop\nsuitable PP. Also, it is not clear how this method\ncan handle complex designs, such as stratified multistage sampling designs, or even single stage unequal\nprobability sampling without replacement with nonnegligible sampling fractions, and provide designcalibrated Bayesian inferences. Nevertheless, the PP\napproach may be useful for some specialized surveys\nand when inferences are desired on a variety of finite\npopulation parameters associated with the variable\nof interest y or prior knowledge on the parameters\n\n11\n\nis available, as in the case of Nelson and Meeden\n(1998).\nAn alternative approach is to start with an informative likelihood based on reduced data. For example, under simple random sampling, it may be\nreasonable to suppress the labels i from the full\ndata {(i, yi ), i \u2208 s} and use the likelihood based on\nthe reduced data {yi , i \u2208 s}; see Hartley and Rao\n(1968) and Royall (1968). On the other hand, for\nstratified random sampling, labels within strata are\nsuppressed but strata labels are retained because of\nknown strata differences. Hartley and Rao (1968)\nproposed a \"scale-load\" approach for inference on\nthe mean \u0232 . Under this approach, the y-values are\nassumed to belong to a finite set of possible values\n{h1 , . . . , hD } for some finite D (unspecified). Then Nt\nis the scale load of ht and the population mean is expressed\nP in terms of the scale loads as \u0232 =\nN \u22121 D\nt=1 Nt ht . Reduced sample data under simple random sampling without replacement is represented by the sample scale loads nt , t = 1, . . . , D,\nand the resulting likelihood function is the hypergeometric likelihood L(N1 , . . . , ND ). If the sampling\nfraction is negligible, then the likelihood is simply\nthe multinomial likelihood which is the same as the\nempirical likelihood (EL) of Owen (1988). In the case of stratified random sampling, the likelihood function is the product of hyper-geometric likelihoods\ncorresponding to the different strata h = 1, . . . , L.\nHartley and Rao focused primarily on design-based inferences, but also briefly studied Bayesian inference under simple random sampling using a compound-multinomial prior on the scale loads N1 , . . . ,\nND . Hoadley (1969) obtained the compound-multinomial prior, denoted CMtn(Nd ; \u03bdd , d = 1, . . . , D), by\nfirst assuming that the finite population {yi , i=1, . . . ,\nN } is a random sample from an infinite population\nwith unknown probabilities pd = P (yi = hd ), d =\n1, . . . , D, and then using a Dirichlet prior with parameters \u03bdd (>0) on the probabilities pd , d=1, . . . , D.\nThe posterior distribution of Nd \u2212 nd , d = 1, . . . , D,\ngiven the data nd , d = 1, . . . , D, is the compound\nmultinomial CMtn(Nd \u2212 nd ; \u03bdd + nd , d = 1, . . . , D).\nUsing this posterior distribution, Hartley and Rao\n(1968) obtained the posterior mean and the posterior variance of the population mean \u0232 . Under a diffuse prior with the vd close to zero, the results are\nidentical to those of Ericson (1969). However, there\nare fundamental differences in the two approaches in\nthe sense that under exchangeability the conditional\ndistribution of the sample scale loads nd , given the\n\n\f12\n\nJ. N. K. RAO\n\npopulation scale loads Nd , is equal to the hypergeometric likelihood of Hartley\u2013Rao for any sampling design, whereas in the Hartley\u2013Rao approach\nthis conditional distribution and the resulting posterior of the Nd are derived under simple random\nsampling, and hence depend on the sampling design.\nRao and Ghangurde (1972) studied Bayesian optimal sample allocation, by minimizing the expected\nposterior variance of the mean, for stratified simple random sampling and some other cases including\ntwo-phase sampling to handle the nonresponse problem. Attention was given to data-based priors obtained by combining diffuse priors with likelihoods\nbased on pilot samples.\nAitkin (2008) used the scale-load framework and\nobtained Bayesian intervals on the population mean\nunder simple random sampling, by using a compound-multinomial prior with vd =0 on the observed\nscale loads nd > 0 and then simulating a large number of samples from the resulting posterior distribution. This approach is similar to the simulation approach used by Meeden and Vardeman (1991), but\nthe posterior intervals depend on the design via the\nlikelihood function. As in the case of Meeden and\nVardman, the simulation method can be applied to\nother parameters of interest. Also, the simulation\nmethod readily extends to stratified simple random\nsampling.\nThe scale-load approach is promising but somewhat limited in applicability, in the sense that the\nscale-load likelihoods cannot be obtained easily for\ncomplex sampling designs. To handle complex sampling designs, Rao and Wu (2010) used a pseudo-EL\napproach, proposed by Wu and Rao (2006), to obtain \"calibrated\" pseudo-Bayesian intervals in the\nsense that the intervals have asymptotically correct\ndesignbased coverage probabilities. The pseudo-EL\napproach uses the survey weights and the design effect (via the effective sample size n\u2217 ) in defining the\nprofile pseudo-EL\nfunction for the mean \u03b8 = \u0232 . Let\nP\nd \u0303i (s) = di / j\u2208s dj be the normalized weights and\nn\u2217 = n/(deff), where deff is the ratio P\nof the estimated variance of the weighted mean i\u2208s d \u0303i (s)yi\nto the estimate of the variance under simple random sampling. Then the profile pseudo empirical\nlog-likelihood function for \u03b8 is given by\nX\n(4)\nd \u0303i (s) log{p\u0302i (\u03b8)},\nlPEL (\u03b8) = n\u2217\ni\u2208s\n\nP\nwhere theP\np\u0302i (\u03b8) maximize Pi\u2208s d \u0303i (s) log pi subject\nto pi > 0, i\u2208s pi = 1 and\ni\u2208s pi yi = \u03b8. We refer\n\nthe reader to Rao and Wu (2009) for an overview of\nEL methods used for inference from survey data.\nBy combining the profile pseudo-EL function for\nthe population mean from (4) with a flat prior on the\nmean, one can get pseudo-Bayesian intervals that\nhave asymptotically correct design-based coverage\nprobabilities. Also, it may be easier to specify informative priors on the mean if historical information\non the mean is available. The proposed approach can\nincorporate known auxiliary population information\nin the construction of pseudo-Bayesian intervals using the basic design weights or using weights already\ncalibrated by the known auxiliary information. The\nlatter is more appealing because, in practice, data\nfiles report the calibrated weights. One limitation of\nthe Rao\u2013Wu method for complex designs is that the\npseudo-EL depends on the design effects which may\nnot be readily available. Lazar (2003) proposed the\nBayesian profile EL approach for the case of independent and identically distributed (i.i.d.) observations.\nIt should be noted that even in the i.i.d. case\na \"matching\" prior on the mean that provides higher\norder coverage accuracy for the intervals does not\nexist when using the nonparametric Bayesian profileEL (Fang and Mukerjee, 2006). Therefore, the main\nadvantage of the approach is to get \"exact\" pseudoBayesian intervals that are also calibrated in the\nsense of first order coverage accuracy in the designbased framework.\n5. SMALL AREA ESTIMATION: HB\nAPPROACH\nMethods for small area (or domain) estimation\nhave received much attention in recent years due\nto growing demand for reliable small area statistics.\nTraditional area-specific direct estimation methods\n(either design-based or model based or Bayesian)\nare not suitable in the small area context because\nof small (or even zero) area-specific sample sizes. As\na result, it is necessary to use indirect estimation\nmethods that borrow information across related areas through linking models based on survey data and\nauxiliary information, such as recent census data\nand current administrative records. Advocates of\ndesign-based methods indeed acknowledge the need\nfor models in small area estimation. For example,\nHansen, Madow and Tepping (1983) remark, \"If the\nassumed model accurately represents the state of nature, useful inferences can be based on quite small\nsamples at least for certain models.\"\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nLinking models based on linear mixed models and\ngeneralized linear mixed models with random small\narea effects are currently used extensively, in conjunction with empirical best linear unbiased prediction (EBLUP), parametric empirical Bayes (EB)\nand hierarchical Bayes (HB) methods for estimation\nof small area means and other small area parameters of interest. A detailed treatment of small area\nestimation methods is given in Rao (2003). We focus\nhere on HB methods to highlight the significant impact of Bayesian methods on small area estimation.\nIn the HB approach, model parameters are treated\nas random variables and assigned a prior distribution. Typically, noninformative priors are used, but\none must make sure that the resulting posteriors\nare proper because some priors on the variance parameters can lead to improper posteriors (see Rao,\n2003, Section 10.2.4, for a discussion on the choice\nof priors). The posterior distribution of a small area\nparameter of interest is then obtained from the prior\nand the likelihood function generated from the data\nand the assumed model. Typically, closed-form expressions for desired posterior distributions do not\nexist, but powerful MCMC methods are now available for simulating samples from the desired posterior distribution and then computing the desired\nposterior summaries. Rao (2003, Chapter 10) gives\na detailed account of the HB methods in the small\narea context; see also the review paper by Datta\n(2009), Section 3.\nA significant advantage of the HB approach is that\nit is straightforward and the inferences are \"exact,\"\nunlike in the EB approach. Moreover, it can handle\ncomplex small area models using MCMC methods.\nAvailability of powerful MCMC methods and software, such as WinBUGS, also makes HB attractive\nto the user. Extensive HB model diagnostic tools are\nalso available, but some of the default HB modelchecking measures that are widely used may not be\nnecessarily good for detecting model deviations. For\nexample, the commonly used posterior predictive pvalue (PPP) for checking goodness of fit may not\nbe powerful enough to detect nonnormality of random effects (Sinharay and Stern, 2003) because this\nmeasure makes \"double use\" of data in the sense of\nfirst generating values from the predictive posterior\ndistribution and then calculating the p-value. Bayarri and Castellanos (2007) say, \"Double use of the\ndata can result in an extreme conservatism of the resulting p-values.\" Alternative measures, such as the\n\n13\n\npartial PPP and the conditional PPP (Bayarri and\nBerger, 2000), attempt to avoid double use of data,\nbut those measures are more difficult to implement\nthan the PPP, especially for the small area models. Browne and Draper (2001) suggested the use of\nprior-free, frequentist methods in the model exploration phase and then the HB for inference based\non the selected models using possibly diffuse priors\non the model parameters. However, many Bayesians\nmay not agree with this suggestion because of the\norientation of frequentist tests of goodness of fit to\nrejecting null hypotheses, as noted by a referee.\nTo illustrate the HB approach for small area estimation, we focus on a basic area-level model with\ntwo components, a sampling model and a linking\nmodel, requiring only area-specific (direct) designbased estimators \u0233iw of small area means \u0232i and associated area-level covariates zi (i = 1, . . . , m). The\nlinking model is of the form g(\u0232i ) = zi\u2032 \u03b2 + vi , where\nthe random effects vi \u223ci.i.d. N (0, A) and g(*) is a specified link function. The sampling model assumes that\ng(\u0233iw ) = g(\u0232i ) + \u1ebdi , where the sampling errors \u1ebdi |\u0232i\nare assumed to be independent N (0, Di ) with known\nsampling variances Di . The assumptions of zero mean\nsampling errors and known sampling variances may\nbe both quite restrictive in practice. The first difficulty may be circumvented by using the sampling\nmodel \u0233iw = \u0232i + ei , where the sampling errors ei are\nassumed to be independent normal with zero means,\nwhich simply says that the direct estimators are design unbiased or nearly design unbiased, as in the\ncase of a GREG estimator, for large overall sample size. The second assumption of known sampling\nvariances is more problematic and the usual practice\nto get around this problem is to model the estimated\nsampling variances (using generalized variance functions) and then treat the resulting smoothed estimates as the true variances Di . Bell (2008) studied\nthe sensitivity of small area inferences to errors in\nthe specification of the true variances. The original model, called the Fay\u2013Herriot (FH) model, is\na matched model in the sense that the sampling\nmodel matches the linking model and the combined\nmodel is simply a special case of a linear mixed\nmodel. On the other hand, the alternative sampling\nmodel is not necessarily matched to the linking motirdel and in this case the two models are \"mismatched.\" For simplicity, we focus on the matched\ncase, but the HB approach readily extends to the\nmore complex case of mismatched models and also\n\n\f14\n\nJ. N. K. RAO\n\nto models that allow the sampling variance to depend on the area mean \u0232i (You and Rao, 2002).\nAttractive features of area level models are that\nthe sampling design is taken into account through\nthe direct estimators \u0233iw and that the direct estimators and the associated area level covariates are more\nreadily available to the users than the corresponding\nunit level sample data. For example, the U.S. Small\nArea Income and Poverty Estimation (SAIPE) Program used the FH model to estimate county level\npoverty counts of school-age children by employing direct estimates for sampled counties from the\nCurrent Population Survey and associated county\nlevel auxiliary information from tax records, food\nstamps programs and other administrative sources\n(see Rao, 2003, Chapter 7, for details). Bayesians\nhave used the area level models extensively through\nthe HB approach, in spite of the limitations mentioned above, because of their practical advantages\n(Rao, 2003, Chapter 10).\nIn the HB approach, a flat prior on the model\nparameters \u03b2 and A is often specified as f (\u03b2, A) \u221d\nf (A) and f (A) \u221d 1, and the resulting posterior summaries (means, variances and credible intervals) for\nthe means \u0232i are obtained. Bell (1999) studied matched models in the context of estimating the proportion of school-age children in poverty at the state\nlevel in the US, using the survey proportions \u0233iw =\npiw based on the Current Population Survey (CPS)\ndata for 1989\u20131993 and area level covariates zi related to \u0232i = Pi . Bell found that the maximum likelihood (ML) and restricted ML (REML) estimates\nof A turned out to be zero for the first four years\n(1989\u20131992) and the resulting EB estimates of state\npoverty rates attached zero weight to the direct estimate piw regardless of the CPS state sample sizes ni\n(number of households). This problem with EB based on ML or REML can be circumvented by using the HB approach. Bell used the above flat prior\nand obtained the posterior mean which always attached nonzero weight to the direct estimate. Further, the posterior variance is well behaved (smallest for California with the largest ni ), unlike the\nestimated mean squared prediction error (MSPE)\nof the EB estimator. It is possible, however, to develop EB methods that always lead to nonzero estimates of A. Morris (2006) proposed to multiply\nthe residual likelihood function of A by the factor\nA and maximize this adjusted likelihood function.\nThe resulting estimator of A is always positive and\ngets around the difficulty with REML. Li and Lahiri\n\n(2010) used an adjusted profile likelihood function\nwhich also leads to positive estimates of A. They\nalso established asymptotic consistency of the estimator and obtained a nearly unbiased estimator of\nthe mean squared prediction error (MSPE) of the\nassociated EB estimator of \u0232i .\nDatta, Rao and Smith (2005) studied frequentist\nproperties of HB by deriving a moment-matching\nprior on A, in the sense that the resulting posterior variance is nearly unbiased for the MSPE of the\nHB estimator of the small area mean. The momentmatching prior is given by\n(5)\n\nm\nX\nf (A) \u221d (A + Di )\n(A + Dl )\u22122 .\n2\n\nl=1\n\nThis prior depends collectively on the sampling variances Dl for all the areas as well as on the areaspecific sampling varianceDi . Note that the matching prior is designed for inference on area i and,\nhence, its dependence on Di should not be problematic. The matching prior (5) reduces to the flat prior\nf (A) \u221d 1 in the special case of equal sampling variances Di = D. However, in the application considered by Bell (1999), max Di / min Di is as large as 20.\nGanesh and Lahiri (2008) derived a single matching\nprior such that a weighted posterior variance over\nthe areas tracks the corresponding weighted MSPE\nfor specified weights. By letting the weights be one\nfor area i and zero for the remaining areas, the resulting prior is identical to (5). Datta (2008) has\nshown that the previous moment-matching priors\nalso ensure matching property for interval estimation in the sense that the coverage probability of\nthe credible interval tracks the corresponding coverage probability of the normal interval based on\nthe EB estimator and its estimated MSPE. Further\nwork on matching priors in the context of small area\nestimation would be useful.\nMismatched models are often more realistic for\npractical applications, as they allow flexibility in formulating the linking model. A recent application of\nHB under mismatched models is to the estimation\nof adult literacy levels for all states and counties in\nthe US, using data from the National Assessment of\nAdult Literacy and literacy-related auxiliary data\n(Mohadjer et al., 2007). Bizier et al. (2008) used\nmismatched models and the HB approach to produce estimates of disability rates for health regions\nand selected municipalities in Canada.\nA variety of applications of HB under complex\nmodeling have been reported in the literature (see\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\n\nRao, 2003, Chapter 10, for work prior to 2003). Nandram and Choi (2005) and Nandram, Cox and Choi\n(2005) studied extensions of HB to handle nonignorable nonresponse and applied the methods to data\nfrom the National Health and Nutrition Examination Survey (NHANES III) to produce small area\nestimates. Raghunathan et al. (2007) applied the\nHB approach to combine data from two independent\nsurveys [Behavioral Risk Factor Surveillance System\n(BRFSS) and the National Health Interview Survey\n(NHIS)] for the years 1997\u20132000 to produce yearly\nprevalence estimates at the county level for six outcomes. BRFSS is a large telephone survey covering\nalmost all US counties, but the nonresponse rates\nare high and also nontelephone households are not\ncovered. On the other hand, NHIS is a smaller personal interview survey with lower nonresponse rates\nand covers nontelephone households. In this application, direct survey weighted county estimates of proportions from the two surveys were transformed using the inverse sine transformation and the sampling\nvariances were taken as (4\u00f1d )\u22121 , where \u00f1d denotes\nthe effective sample size for a particular domain d\n(calculated as the actual domain sample size nd divided by the estimated design effect which is the\nratio of the estimated variance under the given design to the binomial estimated variance). The resulting sampling model was then combined with a suitable linking model to obtain county estimates of the\nprevalence rates, using diffuse proper priors on the\nmodel parameters and MCMC. This application attempts to account for possible noncoverage bias and\nobtain efficient county estimates by combining data\nfrom two independent surveys. It may be noted that\nthe model used here is an extension of the basic FH\narea level model and the application demonstrates\nhow design-based and Bayesian approaches can be\nfruitfully integrated in small area estimation.\nHB methods studied in the literature have been\nlargely parametric, based on specified distributions\nfor the data. However, Meeden (2003) extended his\nnoninformative Bayesian approach, based on the Polya posterior (PP), to small area estimation in some\nsimple cases. Extension of this approach to handle\ncomplex models is not likely to be easy in practice.\n6. CONCLUDING REMARKS\nI have provided an appraisal of the role of Bayesian\nand frequentist methods in sample surveys. My opinion is that for domains (subpopulations) with sufficiently large samples, a traditional design-based fre-\n\n15\n\nquentist approach that makes effective use of auxiliary information, through calibration or assistance\nfrom working models, will remain as the preferred\napproach in the large-scale production of official statistics from complex surveys. Nonsampling errors\ncan be handled using a combined design and model\napproach with minimal use of models. But the designbased approach, using survey weights, is not a panacea even for large samples and yet \"many people\nask too much of the weights\" (Lohr, 2007), prompting statements like, \"Survey weighting is a mess\"\n(Gelman, 2007). As Lohr (2007) noted, survey weighting is not a mess as long as the weighting is not\nstretched to a limit as in the case of a very large\nnumber of post-stratified cells leading to very small\nor even zero cell sample sizes, thus making weighting\nat the cell level unstable or even not feasible (Gelman, 2007). Alternative weighting methods can be\nused in those situations to get around this problem.\nFor example, by calibrating to the marginal counts\nof the post-stratification variables instead of the cell\ncounts leads to a calibration estimator with stable weights which should perform well for estimating population totals or means. Also, the resulting\nweights do not depend on the response values, thus\nensuring internal consistency, unlike the hierarchical regression method proposed by Gelman (2007)\nbased on models involving random effects.\nRecent work on nonparametric Bayesian methods\nthat can be used for both Bayesian and design-based\ninferences looks promising, at least for some specialized surveys. For small area estimation, the hierarchical Bayes (HB) approach offers a lot of promise\nbecause of its ability to handle complex small area\nmodels and provide \"exact\" inferences. However, the\nchoice of noninformative priors that can provide frequentist validity is not likely to be easy in practice\nwhen complex modeling is involved. Also, caution\nneeds to be exercised in the routine use of popular\nHB model-checking methods.\nACKNOWLEDGMENTS\nThis research was supported by a grant from the\nNatural Sciences and Engineering Research Council\nof Canada. My thanks are due to an associate editor and two referees for constructive comments and\nsuggestions.\nREFERENCES\nAitkin, M. (2008). Applications of the Bayesian bootstrap in\nfinite population inference. J. Off. Statist. 24 21\u201351.\n\n\f16\n\nJ. N. K. RAO\n\nBayarri, M. J. and Berger, J. O. (2000). p values for composite null models. J. Amer. Statist. Assoc. 95 1127\u20131142,\n1157\u20131170. MR1804239\nBayarri, M. J. and Castellanos, M. E. (2007). Bayesian\nchecking of the second levels of hierarchical models. Statist.\nSci. 22 322\u2013343. MR2416808\nBell, W. R. (1999). Accounting for uncertainty about\nvariances in small area estimation. In Bull. Int. Statist.\nInst.: 52nd Session. Available at www.census.govt/hhes/\nwww/saipe under \"Publications.\"\nBell, W. R. (2008). Examining sensitivity of small area inferences to uncertainty about sampling error variances. In\nProceedings of the Survey Research Methods Section 327\u2013\n333. Amer. Statist. Assoc., Alexandria, VA.\nBellhouse, D. R. and Rao, J. N. K. (1986). On the efficiency of prediction estimators in two-stage sampling.\nJ. Statist. Plann. Inference 13 269\u2013281. MR0835612\nBinder, D. A. (1982). Nonparametric Bayesian models for\nsamples from finite populations. J. Roy. Statist. Soc. Ser.\nB 44 388\u2013393. MR0693238\nBizier, V., You, Y., Veilleux, L. and Grodin, C. (2008).\nModel-based approach to small area estimation of disability count and rate using data from the 2006 participation\nand activity limitation survey. Technical report, Household\nSurvey Methods Division, Statistics Canada.\nBowley, A. L. (1926). Measurement of the precision attained\nin sampling. Bull. Int. Statist. Inst. 22, Supplement to Liv\n1 6\u201362.\nvan den Brakel, J. A. and Bethlehem, J. (2008). Modelbased estimation for official statistics. Discussion Paper\n08002, Statistics Netherlands.\nBreidt, F. J., Claeskens, G. and Opsomer, J. D. (2005).\nModel-assisted estimation for complex surveys using penalised splines. Biometrika 92 831\u2013846. MR2234189\nBrewer, K. R. W. (1963). Ratio estimation and finite populations: Some results deducible from the assumption of an\nunderlying stochastic process. Austral. J. Statist. 5 93\u2013105.\nMR0182078\nBrowne, W. J. and Draper, D. (2001). A comparison of\nBayesian and likelihood-based methods for fitting multilevel models. Technical report, Institute for Education,\nLondon, England.\nCao, W., Tsiatis, A. and Davidian, M. (2009). Improving\nefficiency and robustness of the doubly robust estimators\nfor a population mean with incomplete data. Biometrika\n96 723\u2013734.\nCasady, R. J. and Valliant, R. (1993). Conditional properties of post-stratified estimators under normal theory. Survey Methodol. 19 183\u2013192.\nDatta, G. S. (2008). Private communication.\nDatta, G. S. (2009). Model-based approach to small area\nestimation. In Handbook of Statistics: Sample Surveys: Inference and Analysis 29B (D. Pfeffermann and C. R. Rao,\neds.) 251\u2013288. North-Holland, Amsterdam.\nDatta, G. S., Rao, J. N. K. and Smith, D. D. (2005).\nOn measuring the variability of small area estimators\nunder a basic area level model. Biometrika 92 183\u2013196.\nMR2158619\nDeming, W. E. (1960). Sample Design in Business Research.\nWiley, New York. MR0120753\n\nDeville, J.-C. and S\u00e4rndal, C.-E. (1992). Calibration estimators in survey sampling. J. Amer. Statist. Assoc. 87\n376\u2013382. MR1173804\nDurbin, J. (1958). Sampling theory for estimates based on\nfewer individuals than the number selected. Bull. Inst. Internat. Statist. 36 113\u2013119. MR0117821\nEricson, W. A. (1969). Subjective Bayesian models in sampling finite populations. J. Roy. Statist. Soc. Ser. B 31\n195\u2013233. MR0270494\nFang, K.-T. and Mukerjee, R. (2006). Empirical-type likelihoods allowing posterior credible sets with frequentist validity: Higher-order asymptotics. Biometrika 93 723\u2013733.\nMR2261453\nFrancisco, C. A. and Fuller, W. A. (1991). Quantile estimation with a complex survey design. Ann. Statist. 19\n454\u2013469. MR1091862\nFuller, W. A. (2009). Sampling Statistics. Wiley, Hoboken,\nNJ.\nGanesh, N. and Lahiri, P. (2008). A new class of average moment matching priors. Biometrika 95 514\u2013520.\nMR2521597\nGelman, A. (2007). Struggles with survey weighting and regression modeling. Statist. Sci. 22 153\u2013164. MR2408951\nGodambe, V. P. (1966). A new approach to sampling from\nfinite populations. I. Sufficiency and linear estimation.\nJ. Roy. Statist. Soc. Ser. B 28 310\u2013319. MR0216720\nHall, P. (2003). A short prehistory of the bootstrap. Statist.\nSci. 18 158\u2013167. MR2026077\nHansen, M. H. and Hurwitz, W. N. (1943). On the theory\nof sampling from finite populations. Ann. Math. Statist. 14\n333\u2013362. MR0009832\nHansen, M. H., Hurwitz, W. N., Marks, E. S. and\nMauldin, W. P. (1951). Response errors in surveys.\nJ. Amer. Statist. Assoc. 46 147\u2013190.\nHansen, M. H., Hurwitz, W. N., Nisselson, H. and Steinberg, J. (1955). The redesign of the census current population survey. J. Amer. Statist. Assoc. 50 701\u2013719.\nHansen, M. H., Madow, W. G. and Tepping, B. J. (1983).\nAn evaluation of model-dependent and probability sampling inferences in sample surveys. J. Amer. Statist. Assoc.\n78 776\u2013793.\nHartley, H. O. (1959). Analytical studies of survey data.\nIn Volume in Honor of Corrado Gini 1\u201332. Instituto di\nStatistica, Rome.\nHartley, H. O. and Rao, J. N. K. (1968). A new estimation\ntheory for sample surveys. Biometrika 55 547\u2013557.\nHaziza, D. (2009). Imputation and inference in the presence of missing data. In Sample Surveys: Design, Methods and Applications. Handbook of Statist. 29 215\u2013246.\nElsevier/North-Holland, Amsterdam. MR2654640\nHaziza, D. and Rao, J. N. K. (2006). A nonresponse model\napproach to inference under imputation for missing survey\ndata. Survey Methodol. 32 53\u201364.\nHoadley, B. (1969). The compound multinomial distribution and Bayesian analysis of categorical data from finite populations. J. Amer. Statist. Assoc. 64 216\u2013229.\nMR0240916\nHorvitz, D. G. and Thompson, D. J. (1952). A generalization of sampling without replacement from a finite universe. J. Amer. Statist. Assoc. 47 663\u2013685. MR0053460\n\n\fBAYESIAN METHODS ON SURVEY SAMPLING\nJiang, J. and Lahiri, P. (2006). Mixed model prediction and\nsmall area estimation. Test 15 1\u201396. MR2252522\nKalton, G. (2002). Models in practice of survey sampling.\nJ. Off. Statist. 18 129\u2013154.\nKim, J. K. and Rao, J. N. K. (2009). A unified approach\nto linearization variance estimation from survey data after\nimputation for item nonresponse. Biometrika 96 917\u2013932.\nKim, J. K., Brick, J. M., Fuller, W. A. and Kalton, G.\n(2006). On the bias of the multiple-imputation variance\nestimator in survey sampling. J. R. Stat. Soc. Ser. B Stat.\nMethodol. 68 509\u2013521. MR2278338\nKorn, E. L. and Graubard, B. I. (2003). Estimating variance components by using survey data. J. R. Stat. Soc.\nSer. B Stat. Methodol. 65 175\u2013190. MR1959830\nKovar, J. G., Rao, J. N. K. and Wu, C. F. J. (1988).\nBootstrap and other methods to measure errors in survey\nestimates. Canad. J. Statist. 16 25\u201345. MR0997120\nLazar, N. A. (2003). Bayesian empirical likelihood.\nBiometrika 90 319\u2013326. MR1986649\nLazar, R., Meeden, G. and Nelson, D. (2008). A noninformative Bayesian approach to finite population sampling using auxiliary variables. Survey Methodol. 34 51\u201364.\nLi, H. and Lahiri, P. (2010). An adjusted maximum likelihood method for solving small area estimation problems.\nJ. Multivariate Anal. 101 882\u2013892. MR2584906\nLittle, R. J. A. (1983). Estimating a finite population mean\nfrom unequal probability samples. J. Amer. Statist. Assoc.\n78 596\u2013604.\nLittle, R. J. (2008). Weighting and prediction in sample surveys. Calcutta Statist. Assoc. Bull. 60 147\u2013167.\nMR2553424\nLittle, R. J. A. and Rubin, D. B. (2002). Statistical Analysis with Missing Data, 2nd ed. Wiley, Hoboken, NJ.\nMR1925014\nLo, A. Y. (1988). A Bayesian bootstrap for a finite population. Ann. Statist. 16 1684\u20131695. MR0964946\nLohr, S. L. (2007). Comment: Struggles with survey weighting and regression modeling. Statist. Sci. 22 175\u2013178.\nMR2408955\nMahalanobis, P. C. (1944). On large scale sample surveys.\nPhil. Trans. Roy. Soc. B 231 329\u2013351.\nMahalanobis, P. C. (1946). Recent experiments in statistical sampling in the Indian Statistical Institute. J. Roy.\nStatist. Soc. 109 325\u2013378.\nMalec, D. and Sedransk, J. (1985). Bayesian inference\nfor finite population parameters in multistage cluster sampling. J. Amer. Statist. Assoc. 80 897\u2013902. MR0819590\nMeeden, G. (1995). Median estimation using auxiliary information. Survey Methodol. 21 71\u201377.\nMeeden, G. (1999). A noninformative Bayesian approach for\ntwo-stage cluster sampling. Sankhy\u0101 Ser. B 61 133\u2013144.\nMR1720718\nMeeden, G. (2003). A noninformative Bayesian approach to\nsmall area estimation. Survey Methodol. 29 19\u201324.\nMeeden, G. and Vardeman, S. (1991). A noninformative\nBayesian approach to interval estimation in finite population sampling. J. Amer. Statist. Assoc. 86 972\u2013980.\nMR1146345\nMohadjer, L., Rao, J. N. K., Liu, B., Krenzyke, T. and\nVan de Kerckhove, W. (2007). Hierarchical Bayes small\n\n17\n\narea estimates of adult literacy using unmatched sampling\nand linking models. In Proceedings of the Survey Research\nMethods Section 3203\u20133209. Amer. Statist. Assoc., Alexandria, VA.\nMorris, C. E. (2006). Mixed model prediction and small area\nestimation. Test 15 72\u201376.\nMurthy, M. N. (1964). On Mahalanobis' contributions to\nthe development of sample survey theory and methods. In\nContributions to Statistics (C. R. Rao, ed.) 283\u2013316. Statistical Publishing Society, Calcutta, India.\nNandram, B. and Choi, J. W. (2005). Hierarchical Bayesian\nnonignorable nonresponse regression models for small area:\nAn application to the NHANES data. Survey Methodol. 31\n73\u201384.\nNandram, B., Cox, L. H. and Choi, J. W. (2005). Bayesian\nanalysis of nonignorable missing categorical data: An application to bone mineral density and family income. Survey\nMethodol. 31 213\u2013225.\nNandram, B., Sedransk, J. and Smith, S. J. (1997). Orderrestricted Bayesian estimation of the age composition of\na population of Atlantic cod. J. Amer. Statist. Assoc. 92\n33\u201340.\nNarain, R. D. (1951). On sampling without replacement\nwith varying probabilities. J. Indian Soc. Agric. Statistics\n3 169\u2013174. MR0045354\nNelson, D. and Meeden, G. (1998). Using prior information\nabout population quantiles in finite population sampling.\nSankhy\u0101 Ser. A 60 426\u2013445. MR1718840\nNeyman, J. (1934). On the two different approaches of the\nrepresentative method: The method of stratified sampling\nand the method of purposive selection. J. Roy. Statist. Soc.\n97 558\u2013606.\nOwen, A. B. (1988). Empirical likelihood ratio confidence\nintervals for a single functional. Biometrika 75 237\u2013249.\nMR0946049\nPfeffermann, D. (1993). The role of sampling weights when\nmodeling survey data. Internat. Statist. Rev. 61 317\u2013337.\nPfeffermann, D. (2008). Discussion. Calcutta Statist. Assoc. Bull. 60 170\u2013175. MR2750142\nPfeffermann, D. and Sverchkov, M. Y. (2003). Fitting\ngeneralized linear models under informative sampling. In\nAnalysis of Survey Data (Southampton, 1999). Wiley Ser.\nSurv. Methodol. (R. Chambers and C. J. Shinner, eds.)\n175\u2013195. Wiley, Chichester. MR1978851\nPfeffermann, D., Moura, F. A. S. and Silva, P. L. N.\n(2006). Multi-level modelling under informative sampling.\nBiometrika 93 943\u2013959. MR2285081\nPfeffermann, D., Skinner, C. J., Holmes, D. J., Goldstein, H. and Rasbash, J. (1998). Weighting for unequal\nselection probabilities in multilevel models. J. R. Stat. Soc.\nSer. B Stat. Methodol. 60 23\u201356. MR1625668\nRabe-Hesketh, S. and Skrondal, A. (2006). Multilevel\nmodelling of complex survey data. J. Roy. Statist. Soc. Ser.\nA 169 805\u2013827. MR2291345\nRaghunathan, T. E., Xie, D., Schenker, N., Parsons, V. L., Davis, W. W., Dodd, K. W. and\nFeuer, E. J. (2007). Combining information from two surveys to estimate county-level prevalence rates of cancer risk\nfactors and screening. J. Amer. Statist. Assoc. 102 474\u2013486.\nMR2370848\n\n\f18\n\nJ. N. K. RAO\n\nRao, J. N. K. (1992). Estimating totals and distribution\nfunctions using auxiliary information at the estimation\nstage. In Proceedings of the Workshop on Uses of Auxiliary Information in Surveys. Statistics Sweden.\nRao, J. N. K. (2003). Small Area Estimation. Wiley, Hoboken, NJ. MR1953089\nRao, J. N. K. (2005). Interplay between sample survey theory and practice: An appraisal. Survey Methodol. 31 117\u2013\n138.\nRao, J. N. K. and Ghangurde, P. D. (1972). Bayesian optimization in sampling finite populations. J. Amer. Statist.\nAssoc. 67 439\u2013443. MR0314161\nRao, J. N. K. and Wu, C. F. J. (1987). Methods for standard errors and confidence intervals from sample survey\ndata: Some recent work. In Proceedings of the 46th Session\nof the International Statistical Institute, Vol. 3 (Tokyo,\n1987) 52 5\u201321. MR1027183\nRao, J. N. K. and Wu, C. (2009). Empirical likelihood methods. In Handbook of Statistics-Sample Surveys: Inference\nand Analysis 29B (D. Pfeffermann and C. R. Rao, eds.)\n189\u2013208. North-Holland, Amsterdam. MR2668352\nRao, J. N. K. and Wu, C. (2010). Bayesian pseudo empirical\nlikelihood intervals for complex surveys. J. Roy. Statist.\nSoc. Ser. B 72 533\u2013544.\nRao, J. N. K., Jocelyn, W. and Hidiroglou, M. A. (2003).\nConfidence interval coverage probabilities for regression\nestimators in uni-phase and two-phase sampling. J. Off.\nStatist. 19 17\u201330.\nRao, J. N. K., Verret, F. and Hidiroglou, M. A. (2010).\nA weighted estimating equations approach to inference for\ntwo-level models from survey data. In Proc. Survey Sec.\nStatistical Society of Canada Annual Meeting. May 2010,\nQu\u00e9bec, Canada.\nRao, J. N. K., Hidiroglou, M., Yung, W. and Kovacevic, M. (2010). Role of weights in descriptive and analytical inference from survey data: An overview. J. Ind. Soc.\nAgric. Statist. 64 129\u2013135.\nReiter, J. P., Raghunathan, T. E. and Kinney, S. K.\n(2006). The importance of modeling the sampling design\nin multiple imputation for missing data. Survey Methodol.\n32 143\u2013149.\nRobinson, P. M. and S\u00e4rndal, C.-E. (1983). Asymptotic\nproperties of the generalized regression estimator in probability sampling. Sankhy\u0101 Ser. B 45 240\u2013248. MR0748468\nRoyall, R. M. (1968). An old approach to finite population\nsampling theory. J. Amer. Statist. Assoc. 63 1269\u20131279.\n\nRoyall, R. M. (1970). On finite population sampling theory\nunder certain linear regression models. Biometrika 57 377\u2013\n387.\nRoyall, R. M. and Pfeffermann, D. (1982). Balanced\nsamples and robust Bayesian inference in finite population\nsampling. Biometrika 69 401\u2013409. MR0671978\nRubin, D. B. (1981). The Bayesian bootstrap. Ann. Statist.\n9 130\u2013134. MR0600538\nRubin, D. B. (1987). Multiple Imputation for Nonresponse in\nSurveys. Wiley, New York. MR0899519\nSarndal, C.-E. (2007). The calibration approach in survey\ntheory and practice. Survey Methodol. 33 99\u2013119.\nS\u00e4rndal, C.-E., Swensson, B. and Wretman, J. (1992).\nModel Assisted Survey Sampling. Springer, New York.\nMR1140409\nScott, A. J. and Smith, T. M. F. (1969). Estimation in\nmulti-stage surveys. J. Amer. Statist. Assoc. 76 681\u2013689.\nSedransk, J. (1977). Sampling problems in the estimation\nof the money supply. J. Amer. Statist. Assoc. 72 516\u2013521.\nSedransk, J. (2008). Assessing the value of Bayesian methods for inference about finite population quantities. J. Off.\nStatist. 24 495\u2013506.\nSinharay, S. and Stern, H. S. (2003). Posterior predictive\nmodel checking in hierarchical models. J. Statist. Plann.\nInference 111 209\u2013221. MR1955882\nSmith, T. M. F. (1994). Sample surveys 1975-90; an age of\nreconciliation. Int. Statist. Rev. 62 5\u201334.\nValliant, R., Dorfman, A. H. and Royall, R. M. (2000).\nFinite Population Sampling and Inference: A Prediction\nApproach. Wiley-Interscience, New York. MR1784794\nWoodruff, R. S. (1952). Confidence intervals for medians\nand other position measures. J. Amer. Statist. Assoc. 47\n635\u2013646. MR0050845\nWu, C. and Rao, J. N. K. (2006). Pseudo-empirical likelihood ratio confidence intervals for complex surveys. Canad.\nJ. Statist. 34 359\u2013375. MR2328549\nYou, Y. and Rao, J. N. K. (2002). Small area estimation\nusing unmatched sampling and linking models. Canad. J.\nStatist. 30 3\u201315. MR1907674\nZheng, H. and Little, R. J. A. (2003). Penalized spline\nmodel-based estimation of the finite populations total from\nprobability-proportional-to-size samples. J. Off. Statist. 19\n99\u2013117.\nZheng, H. and Little, R. J. A. (2005). Inference for the\npopulation total from probability proportional-to-size samples based on predictions from a penalized spline nonparametric model. J. Off. Statist. 21 1\u201320.\n\n\f"}