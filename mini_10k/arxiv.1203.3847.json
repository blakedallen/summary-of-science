{"id": "http://arxiv.org/abs/1203.3847v1", "guidislink": true, "updated": "2012-03-17T09:17:21Z", "updated_parsed": [2012, 3, 17, 9, 17, 21, 5, 77, 0], "published": "2012-03-17T09:17:21Z", "published_parsed": [2012, 3, 17, 9, 17, 21, 5, 77, 0], "title": "Handwritten digit Recognition using Support Vector Machine", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.5175%2C1203.1286%2C1203.5294%2C1203.6327%2C1203.3992%2C1203.0560%2C1203.0186%2C1203.0301%2C1203.5350%2C1203.0254%2C1203.1049%2C1203.2015%2C1203.3092%2C1203.5982%2C1203.4929%2C1203.6179%2C1203.6268%2C1203.5392%2C1203.1018%2C1203.6427%2C1203.0874%2C1203.4742%2C1203.1166%2C1203.2011%2C1203.1618%2C1203.3547%2C1203.3989%2C1203.5858%2C1203.2093%2C1203.5112%2C1203.0007%2C1203.4931%2C1203.0042%2C1203.6526%2C1203.2608%2C1203.3198%2C1203.3707%2C1203.5493%2C1203.3688%2C1203.1517%2C1203.6722%2C1203.5485%2C1203.2939%2C1203.6624%2C1203.1732%2C1203.1310%2C1203.0829%2C1203.5746%2C1203.3899%2C1203.5072%2C1203.1959%2C1203.6583%2C1203.5039%2C1203.6585%2C1203.2394%2C1203.3847%2C1203.2638%2C1203.0547%2C1203.3838%2C1203.4708%2C1203.3183%2C1203.0783%2C1203.5328%2C1203.5005%2C1203.2639%2C1203.4034%2C1203.0427%2C1203.4243%2C1203.6588%2C1203.0821%2C1203.3488%2C1203.3160%2C1203.6196%2C1203.3236%2C1203.1218%2C1203.3333%2C1203.5437%2C1203.1094%2C1203.2749%2C1203.1003%2C1203.2537%2C1203.6533%2C1203.3724%2C1203.4316%2C1203.6058%2C1203.0733%2C1203.2242%2C1203.3297%2C1203.4662%2C1203.1342%2C1203.1983%2C1203.4453%2C1203.6320%2C1203.5602%2C1203.0348%2C1203.5971%2C1203.0715%2C1203.2732%2C1203.3486%2C1203.0098%2C1203.5665&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Handwritten digit Recognition using Support Vector Machine"}, "summary": "Handwritten Numeral recognition plays a vital role in postal automation\nservices especially in countries like India where multiple languages and\nscripts are used Discrete Hidden Markov Model (HMM) and hybrid of Neural\nNetwork (NN) and HMM are popular methods in handwritten word recognition\nsystem. The hybrid system gives better recognition result due to better\ndiscrimination capability of the NN. A major problem in handwriting recognition\nis the huge variability and distortions of patterns. Elastic models based on\nlocal observations and dynamic programming such HMM are not efficient to absorb\nthis variability. But their vision is local. But they cannot face to length\nvariability and they are very sensitive to distortions. Then the SVM is used to\nestimate global correlations and classify the pattern. Support Vector Machine\n(SVM) is an alternative to NN. In Handwritten recognition, SVM gives a better\nrecognition result. The aim of this paper is to develop an approach which\nimprove the efficiency of handwritten recognition using artificial neural\nnetwork", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.5175%2C1203.1286%2C1203.5294%2C1203.6327%2C1203.3992%2C1203.0560%2C1203.0186%2C1203.0301%2C1203.5350%2C1203.0254%2C1203.1049%2C1203.2015%2C1203.3092%2C1203.5982%2C1203.4929%2C1203.6179%2C1203.6268%2C1203.5392%2C1203.1018%2C1203.6427%2C1203.0874%2C1203.4742%2C1203.1166%2C1203.2011%2C1203.1618%2C1203.3547%2C1203.3989%2C1203.5858%2C1203.2093%2C1203.5112%2C1203.0007%2C1203.4931%2C1203.0042%2C1203.6526%2C1203.2608%2C1203.3198%2C1203.3707%2C1203.5493%2C1203.3688%2C1203.1517%2C1203.6722%2C1203.5485%2C1203.2939%2C1203.6624%2C1203.1732%2C1203.1310%2C1203.0829%2C1203.5746%2C1203.3899%2C1203.5072%2C1203.1959%2C1203.6583%2C1203.5039%2C1203.6585%2C1203.2394%2C1203.3847%2C1203.2638%2C1203.0547%2C1203.3838%2C1203.4708%2C1203.3183%2C1203.0783%2C1203.5328%2C1203.5005%2C1203.2639%2C1203.4034%2C1203.0427%2C1203.4243%2C1203.6588%2C1203.0821%2C1203.3488%2C1203.3160%2C1203.6196%2C1203.3236%2C1203.1218%2C1203.3333%2C1203.5437%2C1203.1094%2C1203.2749%2C1203.1003%2C1203.2537%2C1203.6533%2C1203.3724%2C1203.4316%2C1203.6058%2C1203.0733%2C1203.2242%2C1203.3297%2C1203.4662%2C1203.1342%2C1203.1983%2C1203.4453%2C1203.6320%2C1203.5602%2C1203.0348%2C1203.5971%2C1203.0715%2C1203.2732%2C1203.3486%2C1203.0098%2C1203.5665&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Handwritten Numeral recognition plays a vital role in postal automation\nservices especially in countries like India where multiple languages and\nscripts are used Discrete Hidden Markov Model (HMM) and hybrid of Neural\nNetwork (NN) and HMM are popular methods in handwritten word recognition\nsystem. The hybrid system gives better recognition result due to better\ndiscrimination capability of the NN. A major problem in handwriting recognition\nis the huge variability and distortions of patterns. Elastic models based on\nlocal observations and dynamic programming such HMM are not efficient to absorb\nthis variability. But their vision is local. But they cannot face to length\nvariability and they are very sensitive to distortions. Then the SVM is used to\nestimate global correlations and classify the pattern. Support Vector Machine\n(SVM) is an alternative to NN. In Handwritten recognition, SVM gives a better\nrecognition result. The aim of this paper is to develop an approach which\nimprove the efficiency of handwritten recognition using artificial neural\nnetwork"}, "authors": ["Anshuman Sharma"], "author_detail": {"name": "Anshuman Sharma"}, "author": "Anshuman Sharma", "arxiv_comment": "7 page", "links": [{"href": "http://arxiv.org/abs/1203.3847v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.3847v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.3847v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.3847v1", "journal_reference": null, "doi": null, "fulltext": "Handwritten digit Recognition using Support\nVector Machine\nAnshuman Sharma\n(anshuman515@gmail.com)\nAbstract: Handwritten Numeral recognition plays a vital role in postal automation services especially in\ncountries like India where multiple languages and scripts are used Discrete Hidden Markov Model (HMM)\nand hybrid of Neural Network (NN) and HMM are popular methods in handwritten word recognition\nsystem. The hybrid system gives better recognition result due to better discrimination capability of the NN.\nA major problem in handwriting recognition is the huge variability and distortions of patterns. Elastic\nmodels based on local observations and dynamic programming such HMM are not efficient to absorb this\nvariability. But their vision is local. But they cannot face to length variability and they are very sensitive to\ndistortions. Then the SVM is used to estimate global correlations and classify the pattern. Support Vector\nMachine (SVM) is an alternative to NN. In Handwritten recognition, SVM gives a better recognition result.\nThe aim of this paper is to develop an approach which improve the efficiency of handwritten recognition\nusing artificial neural network\nKeyword: Handwriting recognition, Support Vector Machine, Neural Network\n1. Introduction\nHandwritten Recognition refers to the process of\ntranslating images of hand-written, typewritten, or\nprinted digits into a format understood by user for\nthe purpose of editing, indexing/searching, and a\nreduction in storage size. Handwritten recognition\nsystem is having its own importance and it is\nadoptable in various fields such as online\nhandwriting recognition on computer tablets,\nrecognize zip codes on mail for postal mail\nsorting, processing bank check amounts, numeric\nentries in forms filled up by hand and so on. There\nare two distinct handwriting recognition domains;\nonline and offline, which are differentiated by the\nnature of their input signals. In offline system,\nstatic representation of a digitized document is\nused in applications such as cheque, form, mail or\ndocument processing. On the other hand, online\nhandwriting recognition (OHR) systems rely on\ninformation acquired during the production of the\nhandwriting. They require specific equipment that\nallows the capture of the trajectory of the writing\ntool. Mobile communication systems such as\nPersonal Digital Assistant (PDA), electronic pad\nand smart-phone have online handwriting\nrecognition interface integrated in them.\nTherefore, it is important to further improve on\nthe recognition performances for these\napplications while trying to constrain space for\nparameter storage and improving processing\nspeed. Figure 1 shows an online handwritten\nWord recognition system. Many current systems\nuse Discrete Hidden Markov Model based\nrecognizer or a hybrid of Neural Network (NN)\n\nand Hidden Markov Model (HMM) for the\nrecognition\n\nOnline information captured by the input device\nfirst needs to go through some filtration,\npreprocessing and normalization processes. After\n\n1\n\n\fnormalization, the writing is usually segmented\ninto basic units (normally character or part of\ncharacter) and each segment is classified and\nlabeled. Using HMM search algorithm in the\ncontext of a language model, the most likely word\npath is then returned to the user as the intended\nstring [1]. Segmentation process can be performed\nin various ways. However, observation probability\nfor each segment is normally obtained by using a\nneural network (NN) and a Hidden Markov Model\n(HMM) estimates the probabilities of transitions\nwithin a resulting word path. This research aims\nto investigate the usage of support vector\nmachines (SVM) in place of NN in a hybrid\nSVM/HMM recognition system. The main\nobjective is to further improve the recognition\nrate[6,7] by using support vector machine (SVM)\nat the segment classification level. This is\nmotivated by successful earlier work by\nGanapathiraju in a hybrid SVM/HMM speech\nrecognition (SR) system and the work by\nBahlmann [8] in OHR. Ganapathiraju obtained\nbetter recognition rate Compared to hybrid\nNN/HMM SR system. In this work, SVM is first\ndeveloped and used to tra zin an OHR system\nusing character databases. SVM with probabilistic\noutput are then developed for use in the hybrid\nsystem. Eventually, the SVM will be integrated\nwith the HMM module for word recognition.\nPreliminary results of using SVM for character\nrecognition are given and compared with results\nusing NN reported by Poisson [9]. The following\ndatabases were used: IRONOFF, UNIPEN and the\nmixture IRONOFF-UNIPEN databases.\n2. Existing Techniques\n2.1 Modified discrimination function\n(MQDF) Classifier\nG. S. Lehal and Nivedan Bhatt [10] designed a\nrecognition system for handwritten Devangari\nNumeral using Modified discrimination function\n(MQDF) classifier. A recognition rate and a\nconfusion rate were obtained as 89% and 4.5%\nrespectively.\n2.2 Neural Network on Devenagari Numerals\nR. Bajaj, L. Dey, S. Chaudhari [11] used neural\nnetwork based classification scheme. Numerals\nwere represented by feature vectors of three types.\nThree different neural classifiers had been used\nfor classification of these numerals. Finally, the\noutputs of\nthe three classifiers were combined using a\nconnectionist scheme. A 3-layer MLP was used\nfor implementing the classifier for segment-based\nfeatures. Their work produced recognition rate of\n89.68%.\n2.3 Gaussian Distribution Function\n\nR. J. Ramteke et.al applied classifiers on 2000\nnumerals images obtained from different\nindividuals of different professions. The results of\nPCA, correlation coefficient and perturbed\nmoments are an experimental success as\ncompared to MIs. This research produced 92.28%\nrecognition rate by considering 77 feature\ndimensions.\n2.4 Fuzzy classifier on Hindi Numerals\nM. Hanmandlu, A.V. Nath, A.C. Mishra and V.K.\nMadasu used fuzzy membership function for\nrecognition of Handwritten Hindi Numerals and\nproduce 96% recognition rate. To recognize the\nunknown numeral set, an exponential variant of\nfuzzy membership function was selected and it\nwas constructed using the normalized vector\ndistance.\n2.5 Multilayer Perceptron\nUjjwal Bhattacharya, B. B. Chaudhuri [11] used a\ndistinct MLP classifier. They worked on\nDevanagari, Bengali and English handwritten\nnumerals. A back propagation (BP) algorithm was\nused for training the MLP classifiers. It provided\n99.27% and 99.04% recognition accuracies on the\noriginal training and test sets of Devanagari\nnumeral database, respectively.\n2.6 Quadratic classifier for Devanagari\nNumerals\nU. Pal, T. Wakabayashi, N. Sharma and F.\nKimura [14] developed a modified quadratic\nclassifier for recognition of offline handwritten\nnumerals of six popular Indian scripts; viz. They\nhad used 64 dimensional features for high-speed\nrecognition. A five-fold cross validation technique\nhas been used for result computation and obtained\n99.56% accuracy from Devnagari scripts,\nrespectively.\n3. Proposed Approach\n3.1 Support Vector Machine (SVM)\nSVM in its basic form implement two class\nclassifications. It has been used in recent years as\nan alternative to popular methods such as neural\nnetwork. The advantage of SVM, is that it takes\ninto account both experimental data and structural\nbehavior for better generalization capability based\non the principle of structural risk minimization\n(SRM). Its formulation approximates SRM\nprinciple by maximizing the margin\nof class separation, the reason for it to be known\nalso as large margin classifier. The basic SVM\nformulation is for linearly separable datasets. It\ncan be used for nonlinear datasets by indirectly\nmapping the nonlinear inputs into to linear feature\nspace where the maximum Margin decision\nfunction is approximated. The mapping is done by\nusing a kernel function. Multi class classification\n2\n\n\fcan be performed by modifying the 2 class\nscheme. The objective of recognition is to\ninterpret a sequence of numerals taken from the\ntest set. The architecture of proposed system is\ngiven in fig. 3.The SVM (binary classifier) is\napplied to multi class numeral recognition\nproblem by using one-versus-rest type method.\nThe SVM is trained with the training samples\nusing linear kernel. Classifier performs its\nfunction in two phases; Training and Testing. [29]\nAfter preprocessing and Feature Extraction\nprocess, Training is performed by considering the\nfeature vectors which are stored in the form of\nmatrices. Result of training is used for testing the\nnumerals. Algorithm for Training is given in\nalgorithm.\n3.2 Statistical Learning Theory\nSupport Vector Machines have been developed by\nVapnik in the framework of Statistical Learning\nTheory [13]. In statistical learning theory (SLT),\nthe problem of classification in supervised\nlearning is formulated as follows:\nWe are given a set of l training data and its class,\n{(x1,y1)...(xl,yl)} in Rn \u00d7 R sampled according to\nunknown joint probability distribution P(x,y)\ncharacterizing how the classes are spread in Rn\n\u00d7 R. To measure the performance of the classifier,\na loss function L(y,f(x)) is defined as follows:\n\nL(y,f(x)) is zero if f classifies x correctly, one\notherwise. On average, how f performs can be\ndescribed by the Risk functional:\nERM principle states that given the training set\nand a set of possible classifiers in the hypothesis\nspace F, we Should choose f \u2282 F that minimizes\nRemp(f). However, which generalizes well to\nunseen data due to over fitting phenomena.\nRemp(f) is a poor, over-optimistic approximation\nof R(f), the true risk. Neural network classifier\nrelies on ERM principle. The normal practice to\nget a more realistic estimate of generalization\nerror, as in neural network is to divide the\navailable data into training and test set. Training\nset is used to find a Classifier with minimal\nempirical error (optimize the weight of an MLP\nneural networks) while the test set is used to find\n\nminimal Remp(f) and choose the final classifier\nwith minimal generalization error. However, to do\nthat requires designing and training potentially\nlarge number of individual classifiers. Using SLT,\nwe do not need to do that. Generalization error\ncan be directly minimized by minimizing an upper\nbound of the risk functional R(f).\nThe bound given below holds for any distribution\nP(x,y) with probability of at least 1- \u03b7 :\n\nwhere the parameter h denotes the so called VC\n(Vapnik-Chervonenkis) dimension. \u03c6 is the\nconfidence term defined by Vapnik [10] as :\n\nERM is not sufficient to find good classifier\nbecause even with small Remp(f), when h is large\ncompared to l, \u03c6\nwill be large, so R(f) will also be large, ie: not\noptimal. We actually need to minimize\nRemp(f)and \u03c6 at the same time, a process which is\ncalled structural risk\nMinimization (SRM). By SRM, we do not need\ntest set for model selection anymore. Taking\ndifferent sets of classifiers F1, F2 ... with known\nh1, h2 ... we can select f\nfrom one of the set with minimal Remp(f),\ncompute\nand choose a classifier with minimal R(f).No\nmore evaluation on test set needed, at least in\ntheory. However, we still have to train potentially\nvery large\nnumber of individual classifiers. To avoid this, we\nwant to make h tunable (ie: to cascade a potential\nclassifier Fi with VC dimension = h and choose\nan optimal f from an optimal Fi in a single\noptimization step. This is done in large margin\nclassification.\n3.3 SVM formulations\nSVM is realized from the above SLT framework.\nThe simplest formulation of SVM is linear, where\nthe decision hyper plane lies in the space of the\ninput data x.\n\nthe generalization error (error rate on the Test set).\nIf we have different sets of classifier hypothesis\nspace F1, F2 ... e.g. MLP neural networks with\ndifferent topologies, we can select a classifier\nfrom each hypothesis space (each topology) with\n3\n\n\fsystem, the characters are processed to extract\nfeatures that uniquely represent properties of the\ncharacter. Based on normalized central moments,\na set of seven moment invariants is derived.\nFurther, the resultant image was thinned and\nseven moments were extracted. Thus we had 14\nfeatures (7 original and 7 thinned), which are\napplied as features for recognition using Gaussian\nDistribution Function. To increase the success\nrate, the new features need to be extracted by\napplying Affine Invariant Moment method.\n4.2 Affine Moment Invariants\nThe Affine Moment Invariants were derived by\nmeans of the theory of algebraic invariants. Full\nderivation and comprehensive discussion on the\nproperties of invariants can be found. Four\nfeatures can be computed for character\nrecognition. Thus overall 18 features have been\nused for Support Vector Machine.\n\nIn this case the hypothesis space is a subset of all\nhyper planes of the form: f(x) = w\u22c5x +b. SVM\nfinds an optimal hyper plane as the solution to the\nlearning Problem which is geometrically the\nfurthest from both classes since that will\ngeneralize best for future unseen data.\nThere are two ways of finding the optimal\ndecision hyper plane. The first is by finding a\nplane that bisects the two closest points of the two\nconvex hulls defined by the set of points of each\nclass, as shown in figure 2. The second is by\nmaximizing the margin between two supporting\nplanes as shown in figure 3.\nBoth methods will produce the same optimal\ndecision plane and the same set of points that\nsupport the solution (the closest points on the two\nconvex hulls in figure 2 or the points on the two\nparallel supporting planes in figure 3). These are\ncalled the support vectors.\n4. Feature Extraction\n4.1 Moment Invariants\nThe moment invariants (MIs) [1] are used to\nevaluate seven distributed parameters of a\nnumeral image. In any character Recognition\n\n5. Experiment\n5.1 Data Set Description\nIn this paper, the UCI Machine learning data set\nare\nused.\nThe UCI\nMachine\nLearning\nRepository is a collection of databases, domain\ntheories, and data generators that are used by the\nmachine learning community for the empirical\nanalysis of machine learning algorithms. One of\nthe available datasets is the Optical Recognition\nof the Handwritten Digits Data Set. The dataset of\nhandwritten assamese characters by collecting\nsamples from 45 writers is created. Each writer\ncontributed 52 basic characters, 10 numerals and\n121 assamese conjunct consonants. The total\nnumber of entries corresponding to each writer is\n183 (= 52 characters + 10 numerals + 121\nconjunct consonants). The total number of\nsamples in the dataset is 8235 ( = 45 \u00d7 183 ).\nThe handwriting samples were collected on an\niball 8060U external digitizing tablet connected to\na laptop using its cordless digital stylus pen. The\ndistribution of the dataset consists of 45 folders.\nThis file contains information about the character\nid (ID), character name (Label) and actual shape\nof the character (Char).\nIn the raw Optdigits data, digits are represented as\n32x32 matrices. They are also available in a preprocessed form in which digits have been divided\ninto non-overlapping blocks of 4x4 and the\nnumber of on pixels have been counted in each\nblock. This generated 8x8 input matrices where\neach element is an integer in the range 0.16.\n\n4\n\n\fof each factor found during the discriminant\nanalysis is plotted in a pie graph for easy visual\ninspection.\n\nFig4 - Sample digits extracted from the raw\nOptdigits dataset.\n\nOnce the analysis is complete, we can test its\nclassification ability in the testing data set. The\ngreen rows have been correctly identified by the\ndiscriminant space Euclidean distance classifier.\nWe can see that it correctly identifies 98% of the\ntesting data. The testing and training data set are\ndisjoint and independent.\n\n5.2 Data Preprocessing\nFor the experiments using SVM, example isolated\ncharacters are preprocessed and 7 local features\nfor each point of the spatially resample online\nsignal were extracted. For each example character\nthere are 350 feature values as input to the SVM.\nWe use SVM with RBF kernel, since RBF kernel\nhas been shown to generally give better\nrecognition result [7]. Grid search was done to\nfind the best values for the C and gamma\nin the original RBF kernel\n(representing\nformulation) for the final SVM models and by\nthat, C = 8 and gamma =\n\nwere chosen.\nFig.6: Using the default values in the\napplication\n\n5.4 Experimental Results\n5.4.1 Test application Analysis\nThe test application accompanying the source\ncode can perform the recognition of handwritten\ndigits. To do so, open the application (preferably\noutside Visual Studio, for better performance).\nClick on the menu File and select Open. This will\nload some entries from the Optdigits dataset into\nthe application.\n\nFig.5: Optdigits\napplication\n\ndata\n\nloaded\n\ninto\n\n5.5 Results\nAfter the analysis has been completed and\nvalidated, we can use it to classify the new digits\ndrawn directly in the application. The bars on the\nright show the relative response for each of the\ndiscriminant functions. Each class has a\ndiscriminant function that outputs a closeness\nmeasure for the input point. The classification is\nbased on which function produces the maximum\noutput.\n\nthe\n\nTo perform the analysis, click the Run Analysis\nbutton. Please be aware that it may take some\ntime. After the analysis is complete, the other tabs\nin the sample application will be populated with\nthe analysis' information. The level of importance\n\nFig 6: We can see the analysis also performs\nrather well on completely new and previously\nunseen data.\n\n5\n\n\fExperiments were performed on different samples\nhaving mixed scripting languages on numerals\nusing single hidden layer.\n\nFig 7: Graph Representation between HMM and\nSVM\n\n102%\n100%\nAccuracy\n\n98%\n\n94%\n\nHidden Markov Model\n\n92%\n90%\n382\n\n380\n\n387\n\n377\n\n376\n\n387\n\n389\n\n88%\n389\n\non UCI datasets\n\nSupport Vector\nMachine\n\n380\n\nTable 1: Detail Recognition performance of SVM\n\n96%\n\nData Set\n\nTable 2: Detail Recognition performance of SVM\nand HMM on UCI datasets\n\nTable 3: Recognition Rate of Each Numeral in\nDATASET.\nIt is observed that recognition rate using SVM is\nhigher than Hidden Markov Model. However, free\nparameter storage for SVM model is significantly\nhigher. The memory space required for SVM will\nbe the number of support vectors multiply by the\nnumber of feature values (in this case 350). This\nis significantly large compared to HMM which\nonly need to store the weight. HMM needs less\nspace due to the weight-sharing scheme.\nHowever, in SVM, space saving can be achieved\nby storing only the original online signals and the\npenup/ pen-down status in a compact manner.\nDuring recognition, the model will be expanded\ndynamically as required. Table 3 shows the\ncomparison of recognition rates between HMM\nand SVM using all three databases. SVM clearly\noutperforms in all three isolated character cases.\nThe result for the isolated character cases above\nindicates that the recognition rate for the hybrid\nword recognizer could be improved by using\nSVM instead of HMM. Thus, we are currently\nimplementing word recognizer using both HMM\nand SVM and comparing their performance.\n\n6. Conclusion\nHandwriting recognition is a challenging field in\nthe machine learning and this work identifies\nSupport Vector Machines as a potential solution.\nThe number of support vectors can be reduced by\nselecting better C and gamma parameter values\nthrough a finer grid search and by reduced set\nselection Work on integrating the SVM character\nrecognition framework into the HMM based word\nrecognition framework is on the way. In the\nhybrid system, word preprocessing and\nnormalization needs to be done before SVM is\nthen used for character hypothesis recognition and\nword likelihood computation using HMM. It is\nenvisaged that, due to SVM's better\ndiscrimination capability, word recognition rate\nwill be better than in a HMM hybrid system.\nREFRENCES: [1] Sandip Kaur, \" Recognition of Handwritten\nDevanagri Script using Feature Based on Zernike\nMoments and Zoning and Neural Network\nClassifier\", A M. Tech. Thesis Report, Panjabi\nUniversity, Patiala, 2004, pp.\n[2] Gaurav Jain, Jason Ko, \"Handwritten Digits\nRecognition\", Multimedia Systems, Project\nReport, University of Toronto, November 21,\n2008, pp. 1-3.\n[3] Scott D. Connell, R.M.K. Sinha, Ani1 K. Jain\n\"Recognition\nof\nUnconstrained\nOn-Line\nDevanagari Characters\", 2000, IEEE.\n[4] A.K. Jain, Robert P.W.Duin, Jianchang Mao, \"\nStatistical Pattern Recognition: A Review\", IEEE\nTrans. PAMI, Vol.22, No. 1, 2000.\n[5] Anuj Sharma, \"Online Handwritten Gurmukhi\nCharacter Recognition\", A Ph. D. Thesis report,\nSchool of [6] Shubhangi D.C., P.S.Hiremath,\n\"Multi-Class SVM Classifier for English\nHandwritten Digit Recognition using Manual\nClass Segmentation\", Proc. Int'l Conf. on\nAdvances in Computing. Communication and\nControl (ICAC3'09) 2009, pp. 353-356.\n6\n\n\f[6] Sabri A. Mahmoud and Sameh M. Awaida,\n\"Recognition Of Off-Line Handwritten Arabic\n(Indian) Numerals Using Multi-Scale Features\nAnd Support Vector Machines Vs. Hidden\nMarkov Models\" The Arabian Journal For\nScience And Engineering, Volume 34, Number\n2b, October , 2009,Pp. 430-444.\n[7] A.Borji, and M. Hamidi, \"Support Vector\nMachine for Persian Font Recognition\",\nInternational Journal of Intelligent Systems and\nTechnologies, Summer 2007, pp. 184-187\n[8] C. Vasantha Lakshmi, Ritu Jain, C.\nPatvardhan, \"Handwritten Devanagari Numerals\nRecognition With Higher Accuracy\", Proc. of\nIEEE Int. Conf. on\nComputational Intelligence and Multimidia\nApplication, 2007, pp 255-259.\n[9] U.Bhattacharya, B.B.Chaudhari, \"Handwritten\nNumeral Databases of Indian Scripts and\nMultistage Recognition of Mixed Numerals\",\nIEEE Trans. on PAMI, Vol.31, No.3, 2009,\npp.444-457.\n[10] U. Pal, T. Wakabayashi, N. Sharma and F.\nKimura, \"Handwritten Numeral Recognition of\nSix Popular Indian Scripts\", Proc. 9th ICDAR,\nCuritiba, Brazil, Vol.2 (2007),749-753.\n[11] Christopher M. Bishop, \"Pattern Recognition\nand Machine Learning\", Springer Publication,\nSingapore, 2006, Pp. 1-3, 308-320.\n\n7\n\n\f"}