{"id": "http://arxiv.org/abs/1202.4134v1", "guidislink": true, "updated": "2012-02-19T07:54:48Z", "updated_parsed": [2012, 2, 19, 7, 54, 48, 6, 50, 0], "published": "2012-02-19T07:54:48Z", "published_parsed": [2012, 2, 19, 7, 54, 48, 6, 50, 0], "title": "On the Implications of Lookahead Search in Game Playing", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.6633%2C1202.0151%2C1202.3746%2C1202.2506%2C1202.3678%2C1202.1504%2C1202.5971%2C1202.2873%2C1202.5853%2C1202.3762%2C1202.6095%2C1202.2745%2C1202.2575%2C1202.5084%2C1202.4146%2C1202.6323%2C1202.2554%2C1202.5289%2C1202.4595%2C1202.0421%2C1202.4551%2C1202.5126%2C1202.3063%2C1202.3606%2C1202.1915%2C1202.3989%2C1202.0613%2C1202.5795%2C1202.3096%2C1202.6302%2C1202.0159%2C1202.2256%2C1202.1638%2C1202.2996%2C1202.6425%2C1202.3005%2C1202.5520%2C1202.6301%2C1202.1923%2C1202.2070%2C1202.1346%2C1202.5827%2C1202.0044%2C1202.3686%2C1202.3658%2C1202.2234%2C1202.4134%2C1202.5710%2C1202.1440%2C1202.3644%2C1202.1074%2C1202.4185%2C1202.0815%2C1202.4126%2C1202.3455%2C1202.1185%2C1202.4215%2C1202.5235%2C1202.3782%2C1202.2915%2C1202.3939%2C1202.4898%2C1202.3369%2C1202.1264%2C1202.5458%2C1202.1095%2C1202.6470%2C1202.0011%2C1202.3923%2C1202.1649%2C1202.4045%2C1202.4980%2C1202.2325%2C1202.4296%2C1202.0714%2C1202.5269%2C1202.1205%2C1202.0399%2C1202.0739%2C1202.0188%2C1202.4492%2C1202.1525%2C1202.5794%2C1202.4407%2C1202.0423%2C1202.0467%2C1202.3435%2C1202.4927%2C1202.2559%2C1202.2395%2C1202.2505%2C1202.5061%2C1202.2539%2C1202.2098%2C1202.3393%2C1202.5394%2C1202.6259%2C1202.2321%2C1202.2627%2C1202.3404%2C1202.3057&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On the Implications of Lookahead Search in Game Playing"}, "summary": "Lookahead search is perhaps the most natural and widely used game playing\nstrategy. Given the practical importance of the method, the aim of this paper\nis to provide a theoretical performance examination of lookahead search in a\nwide variety of applications.\n  To determine a strategy play using lookahead search}, each agent predicts\nmultiple levels of possible re-actions to her move (via the use of a search\ntree), and then chooses the play that optimizes her future payoff accounting\nfor these re-actions. There are several choices of optimization function the\nagents can choose, where the most appropriate choice of function will depend on\nthe specifics of the actual game - we illustrate this in our examples.\nFurthermore, the type of search tree chosen by computationally-constrained\nagent can vary. We focus on the case where agents can evaluate only a bounded\nnumber, $k$, of moves into the future. That is, we use depth $k$ search trees\nand call this approach {\\em k-lookahead search}.\n  We apply our method in five well-known settings: AdWord auctions; industrial\norganization (Cournot's model); congestion games; valid-utility games and\nbasic-utility games; cost-sharing network design games. We consider two\nquestions. First, what is the expected social quality of outcome when agents\napply lookahead search? Second, what interactive behaviours can be exhibited\nwhen players use lookahead search?", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.6633%2C1202.0151%2C1202.3746%2C1202.2506%2C1202.3678%2C1202.1504%2C1202.5971%2C1202.2873%2C1202.5853%2C1202.3762%2C1202.6095%2C1202.2745%2C1202.2575%2C1202.5084%2C1202.4146%2C1202.6323%2C1202.2554%2C1202.5289%2C1202.4595%2C1202.0421%2C1202.4551%2C1202.5126%2C1202.3063%2C1202.3606%2C1202.1915%2C1202.3989%2C1202.0613%2C1202.5795%2C1202.3096%2C1202.6302%2C1202.0159%2C1202.2256%2C1202.1638%2C1202.2996%2C1202.6425%2C1202.3005%2C1202.5520%2C1202.6301%2C1202.1923%2C1202.2070%2C1202.1346%2C1202.5827%2C1202.0044%2C1202.3686%2C1202.3658%2C1202.2234%2C1202.4134%2C1202.5710%2C1202.1440%2C1202.3644%2C1202.1074%2C1202.4185%2C1202.0815%2C1202.4126%2C1202.3455%2C1202.1185%2C1202.4215%2C1202.5235%2C1202.3782%2C1202.2915%2C1202.3939%2C1202.4898%2C1202.3369%2C1202.1264%2C1202.5458%2C1202.1095%2C1202.6470%2C1202.0011%2C1202.3923%2C1202.1649%2C1202.4045%2C1202.4980%2C1202.2325%2C1202.4296%2C1202.0714%2C1202.5269%2C1202.1205%2C1202.0399%2C1202.0739%2C1202.0188%2C1202.4492%2C1202.1525%2C1202.5794%2C1202.4407%2C1202.0423%2C1202.0467%2C1202.3435%2C1202.4927%2C1202.2559%2C1202.2395%2C1202.2505%2C1202.5061%2C1202.2539%2C1202.2098%2C1202.3393%2C1202.5394%2C1202.6259%2C1202.2321%2C1202.2627%2C1202.3404%2C1202.3057&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Lookahead search is perhaps the most natural and widely used game playing\nstrategy. Given the practical importance of the method, the aim of this paper\nis to provide a theoretical performance examination of lookahead search in a\nwide variety of applications.\n  To determine a strategy play using lookahead search}, each agent predicts\nmultiple levels of possible re-actions to her move (via the use of a search\ntree), and then chooses the play that optimizes her future payoff accounting\nfor these re-actions. There are several choices of optimization function the\nagents can choose, where the most appropriate choice of function will depend on\nthe specifics of the actual game - we illustrate this in our examples.\nFurthermore, the type of search tree chosen by computationally-constrained\nagent can vary. We focus on the case where agents can evaluate only a bounded\nnumber, $k$, of moves into the future. That is, we use depth $k$ search trees\nand call this approach {\\em k-lookahead search}.\n  We apply our method in five well-known settings: AdWord auctions; industrial\norganization (Cournot's model); congestion games; valid-utility games and\nbasic-utility games; cost-sharing network design games. We consider two\nquestions. First, what is the expected social quality of outcome when agents\napply lookahead search? Second, what interactive behaviours can be exhibited\nwhen players use lookahead search?"}, "authors": ["Vahab Mirrokni", "Nithum Thain", "Adrian Vetta"], "author_detail": {"name": "Adrian Vetta"}, "author": "Adrian Vetta", "links": [{"href": "http://arxiv.org/abs/1202.4134v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1202.4134v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1202.4134v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1202.4134v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "On the Implications of Lookahead Search in Game Playing\nVahab Mirrokni\u2217, Nithum Thain\u2020 and Adrian Vetta\u2021\nOctober 31, 2018\n\narXiv:1202.4134v1 [cs.GT] 19 Feb 2012\n\nAbstract. Lookahead search is perhaps the most natural and widely used game playing\nstrategy. Given the practical importance of the method, the aim of this paper is to provide a\ntheoretical performance examination of lookahead search in a wide variety of applications.\nTo determine a strategy play using lookahead search, each agent predicts multiple levels\nof possible re-actions to her move (via the use of a search tree), and then chooses the play\nthat optimizes her future payoff accounting for these re-actions. There are several choices of\noptimization function the agents can choose, where the most appropriate choice of function will\ndepend on the specifics of the actual game - we illustrate this in our examples. Furthermore,\nthe type of search tree chosen by computationally-constrained agent can vary. We focus on the\ncase where agents can evaluate only a bounded number, k, of moves into the future. That is,\nwe use depth k search trees and call this approach k-lookahead search.\nWe apply our method in five well-known settings: AdWord auctions; industrial organization\n(Cournot's model); congestion games; valid-utility games and basic-utility games; cost-sharing\nnetwork design games. We consider two questions. First, what is the expected social quality\nof outcome when agents apply lookahead search? Second, what interactive behaviours can be\nexhibited when players use lookahead search?\nMyopic game playing (whose corresponding equilibria are Nash equilibria), where each player\ncan only foresee the immediate effect of her own actions, is the special case of 1-lookahead\nsearch. Thus, for the first question, it is natural to ask whether social outcomes improve when\nplayers use more foresight than in myopic behaviour. The answer depends on the game played:\n(i) In Adword auctions (or generalized second-price auctions), we show that 2-lookahead game\nplaying results in outcomes that are always optimal to within a constant factor; in contrast,\nmyopic game play can produce arbitrarily poor equilibrium outcomes.\n(ii) For the Cournot game, applying 2-lookahead leads to a 12.5% increase in output and a\n5.5% increase in social surplus compared with myopic competition. Similar bounds arise as\nthe length k of foresight increases.\n(iii) For congestion games, as with myopic game playing, lookahead search leads to constant\nfactor qualitative guarantees.\n(iv) For basic-utility games, on the other hand, whilst myopic game playing always leads to\nconstant factor approximations, additional foresight can lead to arbitrarily bad solutions!\n(v) In a simple Shapley network design game, qualitative guarantees improve with the length\nof foresight.\nRegarding the second question, a variety of interesting game playing characteristics also\narise with lookahead search. Stackelberg leader-follower behaviours can be induced when the\nplayers have asymmetric computational power. For example, Stackelberg equilibria can be produced in the Cournot game. Lookahead search can also generate \"uncoordinated\" cooperative\nbehaviour! An example of this is shown for the Shapely network design game.\n\n\u2217\n\nGoogle Research, Google. Email: mirrokni@google.com\nOxford-Man Institute, University of Oxford. Email: nithum@gmail.com\n\u2021\nDepartment of Mathematics and Statistics, and School of Computer Science, McGill University.\nvetta@math.mcgill.ca\n\u2020\n\n0\n\nEmail:\n\n\f1\n\n1. Introduction\nOur goal here is not to prescribe how games should be played. Rather, we wish to analyse how\ngames actually are played. To wit we consider the strategy of lookahead search, described by Pearl\n[58] in in his classical book on heuristic search as being used by \"almost all game-playing programs\".\nTo understand the lookahead method and the reasons for its ubiquity in practice, consider an agent\ntrying to decide upon a move in a game. Essentially, her task is to evaluate each of her possible moves\n(and then select the best one). Equivalently, if she know the values of each child node in the game tree\nthen she can calculate the value of the current node. However, the values of the child nodes may also\nbe unknown! Recall two prominent ways to deal with this. Firstly, crude estimates based upon local\ninformation could be used to assign values to the children; this is approach taken by best response\ndynamics. Secondly, the values of the children can be determined recursively by finding the values\nof the grandchildren. At its computation extreme, this latter approach in a finite game is Zermelo's\nalgorithm - assign values to the leaf nodes1 of the game tree and apply backwards induction to find\nthe value of the current node.\nBoth these approaches are special cases of lookahead search: choose a local search tree T rooted\nat the current node in the game tree; valuations (or estimates thereof) are given to leaf nodes of T ;\nvaluations for internal tree nodes are then derived using the values of a node's immediate descendants\nvia backwards induction; a move is then selected corresponding to the value assigned the root. For\nbest response dynamics the search tree is simply the star graph consisting of the root node and its\nchildren. With unbounded computational power, the search tree becomes the complete (remaining)\ngame tree used by Zermelo's algorithm.\nWe remark that the actual shape of the search tree T is chosen dynamically. For example, if local\ninformation is sufficient to provide a reliable estimate for a current leaf node w then there is no need\nto grow T beyond w. If not, longer branches rooted at w need to be added to T . Thus, despite our\ndescription in terms of \"backwards induction\", lookahead search is a very forward looking procedure.\nSubject to our computational abilities, we search further forward only if we think it will help evaluate\na game node. Indeed, in our opinion, it is this forward looking aspect that makes lookahead search\nsuch a natural method, especially for humans and for dynamic (or repeated) games.2\nInterestingly, the lookahead method was formally proposed as long ago as 1950 by Shannon [68],\nwho considered it a practical way for machines to tackle complex problems that require \"general\nprinciples, something of the nature of judgement, and considerable trial and error, rather than a\nstrict, unalterable computing process\". To illustrate the method, Shannon described in detail how it\ncould be applied by a computer to play chess. The choice of chess as an example is not a surprise:\nas described the lookahead approach is particularly suited to game-playing. It should be emphasised\nagain, however, that this approach is natural for all computationally constrained agents, not just for\ncomputers. Lookahead search is an instinctive strategic method utilised by human beings as well.\nFor example, Shannon's work was in part inspired by De Groot's influential psychology thesis [31] on\nhuman chess players. De Groot found that all players (of whatever standard) used essentially the same\nthought process - one based upon a lookahead heuristic. Stronger players were better at evaluating\npositions and at deciding how to grow (prune or extend) the search tree but the underlying approach\nwas always the same.\nDespite its widespread application, there has been little theoretical examination of the consequences\nof decision making determined by the use of local search trees. The goal of this paper is to begin\nsuch a theoretical analysis. Specifically, what are the quantitative outcomes and dynamics in various\ngames when players use lookahead search?\n\n1Often\n\nthe values of the leaf nodes will be true values rather than estimates, for example when they correspond to\nend positions in a game.\n2 In contrast, strategies that are prescribed by axiomatic principles, equilibrium constraints, or notions of regret are\nmuch less natural for dynamic game players.\n\n\f2\n\n1.1. Lookahead Search: The Model.\nHaving given an informal presentation, let's now formally describe the lookahead method. Here we\nconsider games with sequential moves that have complete information. These assumptions will help\nsimplify some of the underlying issues, but the lookahead approach can easily be applied to games\nwithout these properties.\nWe have a strategic game G(P, S, {\u03b1i : i \u2208 P}). Here P is the set of n players, Si is the set of\npossible strategies for i \u2208 P, S = (S1 \u00d7 S2 . . . \u00d7 Sn ) is the strategy space, and \u03b1i : S \u2192 R is the payoff\nfunction for player i \u2208 P. A state s\u0304 = (s1 , s2 , . . . , sn ) is a vector of strategies si \u2208 Si for each player\ni \u2208 P.\nSuppose player i \u2208 P is about to decide upon a move. Recall, with lookahead search, she wishes to\nassign a value to her current state node s\u0304 \u2208 S that corresponds to the highest value of a child node.\nTo do this she selects a search tree Ti over the set of states of the game rooted at s\u0304. For each leaf\nnode  \u0304l in Ti , player i then assigns a valuation \u03a0j,l\u0304 = \u03b1j ( \u0304l) for each player j. Valuations for internal\nnodes in Ti are then calculated by induction as follows: if player p is destined to move at game node\nv\u0304 then his valuation of the node is given by\n\u03a0p,v\u0304 = max [rp,v\u0304 + \u03a0p,\u016b ].\nu\u2208C(v\u0304)\n\nHere, C(v\u0304) denotes the set of children of v\u0304 in Ti , and rp,v\u0304 is some additional payoff received by player\np at node v\u0304. Should p choose the child \u016b\u2217 \u2208 C(v\u0304) then assume any non-moving player j 6= p places\na value of \u03a0j,v\u0304 = rj,v\u0304 + \u03a0j,\u016b\u2217 on node v\u0304. Then given values for children of the root node s\u0304 of Ti ,\nplayer i is thus able to compute the lookahead payoff \u03a0i,s\u0304 which she uses to select a move to play at\ns\u0304. [The method is defined in an analogous manner if players seek to minimise rather than maximise\ntheir \"payoffs\".]\nAfter i has moved, suppose player j is then called upon to move. He applies the same procedure\nbut on a local search tree Tj rooted at the new game node. Note that j's move may not be the move\nanticipated by i in her analysis. For example, suppose all the players use 2-lookahead search. Then\nplayer i calculates on the basis that player j will use a 1-lookahead search tree Tj0 when he moves \u2013\nbecause for computational purposes it is necessary that Tj0 \u2286 Ti . But when he moves player j actually\nuses the 2-lookahead search tree Tj and this tree goes beyond the limits of Ti .\n1.2. Lookahead Search: The Practicalities.\nObserve that there is still a great deal of flexibility in how the players implement the model. This\nversatility, we would argue, is a major strength (and another reason underlying its ubiquity) and not\na weakness of the method. For example, it accords well with Simon's belief, discussed in Section 1.4,\nthat behaviours should be adaptable. We now give some examples of this adaptability and highlight\nthose aspects that we analyse in this paper.\n\u2022 Dynamic Search Trees. Recall that search trees may be constructed dynamically. Thus, the\nexact shape of the search tree utilized will be heavily influenced by the current game node, and the\nexperience and learning abilities of the players. Whilst clearly important in determining gameplay and\noutcomes, these influences are a distraction from our focal point, namely, computation and dynamics\nin games in which players use lookahead search strategies. Therefore, we will simply assume here that\neach Ti is a breadth first search tree of depth ki . Implicitly, ki is dependent on the computational\nfacilities of player i.\n\u2022 Evaluation Functions. Different players may evaluate leaf nodes in different ways. To evaluate\ninternal nodes, as described above, we make the standard assumption that they use a max (or min)\nfunction. This need not be the case. For example, a risk-averse player may give a higher value to a\nnode (that it does not own) with many high value children than to a node with few high value children\n\u2013 we do not consider such players here.\n\u2022 Internal Rewards or Not: Path Model vs Leaf Model. We distinguish between two broad\nclasses of game that fit in this framework but are conceptually quite different. In the first category,\npayoffs are determined only by outcomes at the end of game. Valuations at leaf nodes in the local\n\n\f3\n\nsearch trees are then just estimates of the what the final outcome will be if the game reaches that\npoint. Clearly chess falls into this category. In the second category, payoffs can be accumulated over\ntime - thus different paths with the same endpoints may give different payoffs to each player. Repeated\ngames, such as industrial games over multiple time periods, can be modelled as a single game in this\ncategory. The first category is modelled by setting all internal rewards rp,v\u0304 = 0. Thus what matters\nin decision making is simply the initial (estimated) valuations a player puts on the leaf nodes. We\ncall this the leaf (payoff ) model as an agent then strives to reach a leaf of Ti with as high a value as\npossible. The second category arises when the internal rewards, rp,v\u0304 , can be non-zero. Each agent\nthen wishes to traverse paths that allow for high rewards along the way. More specifically, in this\nmodel, called the path (payoff ) model, the internal reward is rp,v\u0304 = \u03b1p (v\u0304).\n\u2022 Order of Moves: Worst-Case vs Average-Case. In multiplayer games, the order in which\nthe players move may not be fixed. This adds additional complexity to the decision making process,\nas the local search tree will change depending upon the order in which players move. Here, we will\nexamine two natural approaches a player may use in this situation: worst case lookahead and average\ncase lookahead. In the former situation, when making a move, a risk-averse player will assume that\nthe subsequent moves are made by different players chosen by an adversary to minimize that player's\npayoff. In the latter case, the player will assume that each subsequent move is made by a player chosen\nuniformly at random; we allow players to make consecutive moves. In both cases, to implement the\nmethod the player must perform calculations for multiple search trees. This is necessary to either find\nthe worst-case or perform expectation calculations.\n1.3. Techniques and Results.\nWe want to understand the social quality of outcomes that arise when computationally-bounded agents\nuse k-lookahead search to optimise their expected or worst-case payoff over the next k moves. Two\nnatural ways we do this are via equilibria and via the study of game dynamics. To explain these\napproaches, consider the following definition. Given a lookahead payoff function, \u03a0i,s\u0304 , a lookahead\nbest-response move for player i, at a state s\u0304 \u2208 S, is a strategy si maximising her lookahead payoff,\nthat is, \u2200s0i \u2208 Si : \u03a0i,s\u0304 \u2265 \u03a0i,(s\u0304\u2212i ,s0i ) . [A move s0i for player i, at a state s\u0304 \u2208 S, is lookahead improving\nif \u03a0i,s\u0304 \u2264 \u03a0i,(s\u0304\u2212i ,s0i ) .] A lookahead equilibrium is then a collection of strategies such that each player is\nplaying her lookahead best-response move for that collection of strategies. Our focus here is on pure\nstrategies. Then, given a social value for each state, the coordination ratio (or price of anarchy) of\nlookahead equilibria is the worst possible ratio between the social value of a lookahead equilibrium and\nthe optimal global social value.\nTo analyse the dynamics of lookahead best-response moves, we examine the expected social value\nof states on polynomial length random walks on the lookahead state graph, G. This graph has a node\nfor each state s \u2208 S and an edge from s\u0304 to a state t\u0304 with a label i \u2208 P if the only difference between\ns\u0304 and t\u0304 is that player i changes strategy from si to ti , where ti is the lookahead best response move\nat s\u0304. The coordination ratio of lookahead dynamics is the worst possible ratio between the expected\nsocial value of states on a polynomially long random walk on G and the optimal global social value.\nFor practical reasons, we are usually more interested in the dynamics of lookahead best-response\nmoves than in equilibria. For example, as with other equilibrium concepts, lookahead best-response\nmoves may not lead to lookahead equilibria. Indeed, such equilibria may not even exist. Typically,\nthough, the methods used to bound the coordination ratio for k-lookahead equilibria can be combined\nwith other techniques to bound the coordination ratio for k-lookahead dynamics. We show how to\ndo this for congestions games in Section 4; see also Goemans et al. [30] for several examples with\nrespect to 1-lookahead dynamics. Consequently, for both simplicity and brevity, most of the results\nwe give here concern the coordination ratio for lookahead equilibria. We are particularly interested in\ndiscovering when lookahead equilibria guarantee good social solutions, and how outcomes vary with\ndifferent levels of foresight (k). We perform our analyses for an assortment of games including an\nAdWord auction game, the Cournot game, congestion games, valid-utility games, and a cost-sharing\nnetwork design game.\n\n\f4\n\nWe begin, in Section 2, by considering strategic bidding in an AdWord generalised second-price\nauction, and studying the social values of the allocations in the resulting equilibria. In particular, we\nshow that 2-lookahead game playing results in the optimal outcome or a constant-factor approximate\noutcome under the leaf and path models, respectively. This is in contrast to 1-lookahead (myopic)\ngame playing which can result in arbitrarily poor equilibrium outcomes, and shows that more forwardthinking bidders would produce efficient outcomes.\nSecond, in Section 3, we examine the Cournot duopoly game. Here two firms compete in producing\na good consumed by a set of buyers via the choice of production quantities. We study equilibria of\nthese simple games resulting from k-lookahead search. The equilibria of these simple games for myopic\ngame playing, k = 1, is well-understood. For k > 1, however, firms produce over 10% more than if\nthey were competing myopically; this is better for society as it leads to around a 5% increase in social\nsurplus. Surprisingly, the optimal level of foresight for society is k = 2. Furthermore, we show that\nStackelberg behaviours arise as a special case of lookahead search where the firms have asymmetric\ncomputational abilities.\nThird, in Section 4, we examine congestion games with linear latency functions, and study the\naverage of delay of players in those games. We show that 2-lookahead game playing results in constantfactor approximate solutions. In particular, the coordination ratio of lookahead dynamics is a constant.\nThese guarantees are similar to those obtained via 1-lookahead.\nFourth, in Section 4.1, we consider two classes of resource sharing games, known as valid-utility\nand basic-utility games. For both of these games, we show that lookahead game playing may result\nin very poor solutions. For\n\u221avalid-utility games, we show k-lookahead can give a coordination ratio for\nlookahead dynamics of \u0398( n). Myopic game play can also give very poor solutions [30], but additional\nforesight does not significantly improve outcomes in the worst case. For basic-utility games, however,\nmyopic game dynamics give a constant coordination ratio [30] whereas we show that 2-lookahead game\nplaying may result in o(1)-approximate social welfare with the leaf model. Thus, additional foresight\nin games need not lead to better outcomes, as is traditionally assumed in decision theory.\nFinally, in Section 5, we present a simple example of a cost-sharing network design game that\nillustrates how the use of lookahead search can encourage cooperative behaviour (and better outcomes)\nwithout a coordination mechanism.\nObserve that our results show that lookahead search has different effects depending upon the game.\nIt would be interested to study further which game structures lead to more beneficial outcomes when\nlonger foresight is used, and which game structures lead to more detrimental outcomes.\n1.4. Background and Related Work.\nThis work is best viewed within the setting of bounded rationality pioneered by Herb Simon. In\nRational Choice Theory a rational agent (or economic man) makes decisions via utility maximisation.\nWhilst the non-existence of economic man is not in doubt, rationality remains a central assumption in\neconomic thought. This is typically justified using an as if as expounded by Friedman [26]: whether\npeople are actually rationality or not is unimportant provided their actions can be viewed in a way\nthat is consistent with rational decision making - that is, provided agents act as if they are rational.3\nFriedman concluded that a model should be judged by it predictive value rather than by the realism\nof its assumptions. On this scale rationality often (but not always) does very well.\nHowever, motivated by considerations of computational power and predictive ability, Simon [69]\nargued that \"the task is to replace the global rationality of economic man with a kind of rational\nbehaviour that is compatible with the access to information and the computational capacities that are\nactually possessed by organisms, including man, in the kinds of environments in which such organisms\nexist\". He argued that, instead of optimising, agents apply heuristics in decision making. An example\nof this being the satisficing heuristic: agents search for feasible solutions, stopping when then discover\n3For\n\nexample, a consumer whose purchasing strategy allocates fixed proportions of her budget to specific\ngoods (regardless of price levels) can be viewed as rational consumer with a Cobb-Douglas utility function!\n\n\f5\n\nan outcome that achieves an aspired level of satisfaction4. We remark that the use of a search phase\nprovides a fundamental distinction between rational and boundedly rational agents. For rational\nagents the search is irrelevant as they will anyway make an optimal choice given the constraints of\nthe problem. For agents of bounded rationality the form of the search can heavily influence decision\nmaking.\nInterestingly, De Groot's work on chess players also heavily influenced Simon's general thinking on\ncognitive science.5 This is exemplified in his famous book with Newell on human problem solving [57],\nwhere humans are viewed as information processing systems.\nThe label bounded rationality is currently used in a number of disparate areas some of which actually\ngo against the main thrust of Simon's original ideas; see Selten [64] and Rubenstein [59] for some\ndiscussion on this point. Two schools of thought developed by psychologists, experimental economists,\nand behavioural economists are, however, well worth mentioning here. First, the Heuristics and Biases\nprogram espoused by Kahneman and Tversky and, second, the Fast and Frugal Heuristics program\nespoused by Gigerenzer. Whilst both programs agree that humans routinely use simple heuristics in\ndecision making, their philosophical outlooks are very different. The former program primarily looks\nfor outcomes (caused by the use of heuristics) in violation of subjective excepted utility theory, and\nviews such biases as a sign of irrationality likely to lead to poor decision making. In contrast, the\nlatter program views the use of heuristics as natural and, in principle, entirely compatible with good\ndecision making. For example, simple heuristics may be more robust to environmental changes and\nactually outperform methods based upon subjective excepted utility maximisation. As with the work\nof Simon, for the fast and frugal heuristics school, the actual quality of an heuristic is assumed to be\ndependent upon the search - how to search and when to stop searching - and the choice of decision rule\nafter the search is terminated. Clearly, the lookahead heuristic can be viewed in this light: there is a\nsearch (via a local search tree), there is a \"stopping rule\" (determined, for example, by computational\nconstraints and by the expertise of the player), and there is a decision rule (backwards induction).\nThe value of lookahead search in decision-making has been examined by the artificial intelligence\ncommunity [55]; for examples in effective diagnostics and real-time planning see [40] and [63]. Lookahead search is also related to the sequential thinking framework in game theory [52, 73]. However,\ncompared to these works and the research carried out by the two schools above, our focus is more\ntheoretical and less experimental and psychological. Specifically, we desire quantitative performance\nguarantees for our heuristics.\nOur research is also related to works on the price of anarchy in a game, and convergence of game\ndynamics to approximately optimal solutions [50, 30] and to sink equilibria [30, 21]. Numerous articles\nstudy the convergence rate of best-response dynamics to approximately optimal solutions [15, 23, 4, 9].\nFor example, polynomial-time bounds has been proven for the speed of convergence to approximately\noptimal solutions for approximate Nash dynamics in a large class of potential games [4], and for\nlearning-based regret-minimisation dynamics for valid-utility games [9]. Our work differs from all\nthe above as none of them capture lookahead dynamics. In another line of work, convergence of\nbest-response dynamics to (approximate) equilibria and the complexity of game dynamics and sink\nequilibria have been studied [22, 1, 14, 72, 21, 49], but our paper does not focus on these types of\ndynamics or convergence to equilibria.\nMotivated by concerns of stability, convergence, and predictability of equilibria and game dynamics,\nvarious equilibrium concepts other than Nash equilibria have been studied in the economics literature.\nAmong them are correlated equilibria [2], stable equilibria [44], stochastic adjustment models [38],\nstrategy subsets closed under rational behaviour (CURB set) [6], iterative elimination of dominated\nstrategies, the set of undominated strategies, etc. Convergence and strategic stability of equilibria in\nevolutionary game theory is also an important subject of study. Many other game-theoretic models\nhave been proposed to capture the self-interested behaviour of agents. As well as best-response\n4Over time, and depending upon what is found in the search, this aspiration level may be changed.\n5In fact, Simon sent his student George Baylor to help translate De Groot's work into English.\n\n\f6\n\ndynamics, noisy best-response dynamics [20, 79, 51], where players occasionally make mistakes, and\nsimultaneous Nash dynamics [7], where all players change their strategies simultaneously, are both\nwell-studied. In many other models the effect of learning algorithms [80] is examined, for example,\nregret minimisation dynamics [25, 32, 33, 10, 8, 9, 19] and fictitious play [11]. In most of these studies\nthe most important factor is the stability of equilibria, and not measurements of the social value of\nequilibria. Furthermore, most of them are motivated by theoretical game theoretic concepts rather\nthan practical game-playing, and none of the above works consider lookahead search.\n2. Generalised Second-Price Auctions\nFor our first example, we apply the lookahead model to generalised second-price (GSP) auctions.\nOur main results are that outcomes are provably good when agents use additional foresight; in contrast,\nmyopic behaviour can produce very poor outcomes.\nThe auction set-up is as follows. There are T slots with click-through rates c1 > c2 > ... > cT > 0,\nthat is, higher indexed slots have lower click-through rates. There are n players bidding for these\nslots, each with a private valuation v i . Each player i makes a bid bi . Slots are then allocated via a\ngeneralised second price auction. Denote the jth highest bid in the descending bid sequence by bj ,\nwith corresponding valuation vj . The jth best slot, for j \u2264 T , is assigned to the jth highest bidder\nwho is charged a price equal to bj+1 . The T highest bidders are called the \"winners\". According to\nthe pricing mechanism, if bidder i were to get slot t in the final assignment, then he would get utility\nuit = (v i \u2212 bt+1 )ct . We denote a player i's utility if he bids bi by ui (bi ) (the other players bids are\nimplicit inputs for ui ).\nThis auction is used in the context of keyword ad auctions (e.g, Google AdWords) for sponsored\nsearch. Given the continuous nature of bids in the GSP auction, the best response of each bidder i\nfor any vector of bids by other bidders corresponds to a range of bid values that will result in the\nsame outcome from i's perspective. Among these set of bid values, we focus on a specific bid value\nbi , called the balanced bid [13]. The balanced bid bi is a best-response bid that is as high as possible\nsuch that player i cannot be harmed by a player with a better slot undercutting him, i.e. bidding just\nbelow him. It is easy to calculate that for player i in slot t, 1 \u2264 t < T , the only balanced bid is\nbi = (1 \u2212\n\nct\nct\n)v i +\nbt+1 .\nct\u22121\nct\u22121\n\nAn important property of balanced bidding is that each \"losing\" player i (one not assigned a slot)\nshould bid truthfully, that is bi = v i . To see this add dummy slots with ct = 0 if t > T . The player\nwho wins the top slot should also bid truthfully under balanced bidding. Balanced bidding is the most\ncommonly used bidding strategy [13, 48]. For some intuition behind this, note that balanced bidding\nhas several desirable properties. For a competitive firm, bidding high obviously increases the chance\nof obtaining a good slot. Within a slot this also has the benefit of pushing up the price a competitor\npays without affecting the price paid by the firm. On the other hand, bidding high increases the upper\nbound on the price the firm may pay, leading to the possibility that the firm may end up paying a high\nprice for one of the less desirable slots. Balanced bidding eliminates the possibility that a change in\nbid from a higher bidder can hurt the firm. (Clearly, it is impossible to obtain such a guarantee with\nrespect to a lower bidder.) Thus, balanced bidding provides some of the benefits of high bidding at\nless risk. Balanced bidding naturally converges to Nash equilibria unlike other bidding strategies such\nas altruistic bidding or competitor busting [13]. Moreover, the other bidding strategies would require\nsome discretization of players' strategy space in order to analyse the best response dynamics [13, 48].\nConsequently, balanced bidding is the most natural strategy choice for our analysis.\nFor this auction problem, we consider only the leaf model. The leaf model seems more natural\nthan the path model for a single auction as players are interested in the final allocation output by the\nauction (there are no intermediary payoffs). We analyse both worst-case and average-case lookahead;\ndepending upon the level of risk-aversion of the agents both cases seem natural in auction settings.\n\n\f7\n\nLet player i's lookahead payoff (or utility) at bid bi with respect to player j, denoted by uij (bi ), be\nplayer i's payoff (or utility) after player j makes a best-response move. In the worst-case lookahead\nmodel, we define player i's lookahead payoff for a vector b\u0304 of bids as \u03a0i,b\u0304 = \u0169i (bi ) = minj uij (bi ). In\nthe average-case lookahead model, player i's lookahead payoff \u03a0i,b\u0304 for a bid vector b\u0304 is \u03a0i,b\u0304 = \u016bi (bi ) =\n1 P\nij i\ni\ni\nj u (b ). Changing strategy from bid b to bid b\u0304 is a lookahead improving move if lookahead\nn\nutility increases, i.e., \u016bi (b\u0304i ) > \u0169i (bi ). We are at a lookahead equilibrium if no player has a lookahead\nimproving move.\nIt is known that the social welfare of Nash equilibria for myopic game playing can be arbitrarily\nbad [13] unless we disallow over-bidding [46]. Here, we prove the advantage of additional foresight by\nshowing that 2-lookahead equilibria have much better social welfare. In particular, we show that all\nsuch equilibria are optimal in the worst-case lookahead model, and all such equilibria are constantfactor approximate solutions in the average-case lookahead model.\n2.1. Worst-Case Lookahead.\nOur proof for the worst-case lookahead model can be seen as a generalisation of the proof of [12] for\na slightly different model. We start by proving a useful lemma in this context.\nLemma 2.1. Consider the worst-case lookahead model with the leaf model. Label the players so that\nplayer i is in slot i, and suppose there is a player t such that v t < v t+1 . Then player t myopically\nprefers slot t + 1 to slot t.\nProof. Suppose not. Then, as player t does not myopically prefer slot t + 1 we have\n(vt \u2212 bt+1 )ct \u2265 (vt \u2212 bt+2 )ct+1\nct+1\nct (vt+1\n\n\u2212 bt+2 ). Plugging this in gives\nBy definition, bt+1 = vt+1 \u2212\n\u0012\n\u0013\n\u0012\n\u0013\nct \u2212 ct+1\nct+1\nct+1\nct+1\n(vt \u2212 bt+2 )ct+1 \u2264 vt \u2212\nvt+1 \u2212\nbt+2 ct <\nvt \u2212\nbt+2 ct = (vt \u2212 bt+2 )ct+1\nct\nct\nct\nct\nThus we obtain our desired contradiction. Note that the strict inequality above follows directly from\nthe fact that v t < v t+1 .\n\u0003\nAn equilibrium is output truthful if the slots are assigned to the same bidders as they would be if\nbidders were to bid truthfully. It is easy to verify that an an allocation optimizes solcial welfare if\nand only if it is output truthful. Thus to prove 2-lookahead equilibria are socially optimal it suffices\nto show they are output truthful.\nTheorem 2.2. For GSP auctions, any 2-lookahead equilibrium gives optimal social welfare in the\nworst-case, leaf model.\nProof. We proceed by contradiction. Consider a non-output-truthful 2-lookahead equilibrium. Again,\nlabel the players so that the player i is in slot i. Amongst all the winning players, take the one with\nthe lowest valuation, vi . First suppose that vi is not amongst the T highest valuations. Then, there is\na losing player with a higher value than vi . But this player is bidding his value, as a result of balanced\nbidding. Consequently, player i's utility must be negative, a contradiction.\nThus, we may assume that vi is amongst the T highest valuations; specifically it must have exactly\nthe T th highest valuation. We will show that player i moving into slot T is a lookahead improving\nmove. Notice that the lookahead value for player i staying in slot i is at most the myopic value of\nstaying in that slot. This follows as the choice of a player two slots below i cannot improve the utility\nof player i (neither in terms of price nor slot position), but only could make it worse. Hence, it suffices\nto show that the lookahead value of changing slots is better than the myopic value of staying in slot i.\nBy several applications of Lemma 2.1, we see that player i myopically prefers slot T to slot i.\nHowever, in moving to slot T , player i will still make a balanced bid. Thus, no other winning player\nmay reduce i's utility by undercutting him. Also, no losing player j wants to move to a winning slot as\n\n\f8\n\nthey can only be left with negative utility - since j cannot then be amongst the T highest valuations.\nSo moving to slot T is a lookahead improving move for player i.\nIf player i were originally in slot T , then the entire argument can be applied with regards to slots\n1 to T \u2212 1. Inductively, we then conclude that in any non-output-truthful equilibrium, there is a\nlookahead improving move, which is a contradiction. This gives us the desired result.\n\u0003\n2.2. Average Case Lookahead.\nNext, we consider the average-case lookahead model. and show that the above theorem does not hold\nfor this case.\nTheorem 2.3. In GSP auctions, there exist 2-lookahead equilibria that are not output-truthful in the\naverage-case, leaf model.\nProof. Consider the following example with n = T = 4. Let the click-through rates be c1 = 35, c2 =\n26, c3 = 25, and c4 = 20. Let the valuations be v1 = 82, v2 = 83, v3 = 100, v4 = 93. Starting with the\nhighest slot and working to the lowest, let bidder i bid the balanced bid for slot i. It can be verified\nthat this turns out to be a non-output-truthful equilibria.\n\u0003\nDespite this negative result, 2-lookahead equilibria cannot have arbitrarily bad social welfare.\nTheorem 2.4. In GSP auctions, the coordination ratio of 2-lookahead equilibria is constant in the\naverage-case, leaf model.\nProof. Suppose that we are at an equilibrium. Let vi\u2217 be the ith highest valuation, let player i\u2217 denote\nthe corresponding player, let bi\u2217 denote their bid, and ci\u2217 be the click through rate of the slot they\ncurrently occupy. We recall that vi denotes thePplayer in slot i and it has click through rate ci and bid\nbi . The social utility\nof a set A of players is i\u2208A vi ci . Thus, by the above definitions, the optimal\nP\n\u2217\nsocial utility is i vi ci .\nNow, choose \u03b1, \u03b2 < 1 such that (1\u2212\u03b1)2 > m\u03b2. Let I be the set of indices i that satisfy both vi < \u03b1vi\u2217\nand ci\u2217 < \u03b2ci . Note that for all i \u2208\n/ I the pair of players vi , vi\u2217 contribute at least min{\u03b1, \u03b2}vi\u2217 ci to\nOPT. So if I is empty, then we have achieved a constant coordination ratio. We may thus suppose I\nis not empty and choose i \u2208 I.\nConsider ci\u2217 \u22121 . As we assume \"balanced\" bidding,\nbi\u2217 \u2265 (1 \u2212\n\nci\u2217\nci\u2217 \u22121\n\n)vi\u2217\n\nSince bi\u2217 < bi < vi < \u03b1vi\u2217 by assumption, we have ci\u2217 \u22121 <\nfollowing claim.\nClaim 2.5. For all i \u2208 I, we have ci+1 \u2264\n\n1\n\u2217\n1\u2212\u03b1 ci .\n\nChoose m > 1. We first prove the\n\nci\nm.\n\nci\nProof. Suppose ci+1 > m\n, for some i \u2208 I. We will show that player i\u2217 moving into slot i is then\nlookahead improving. Consider his lookahead utility for staying put. Ignoring a repeat move for\nplayer i\u2217 , which occurs with probability n1 , player i\u2217 's utility in every other circumstance is at most\nci\u2217 \u22121 vi\u2217 , as other players can improve his position by at most one. On the other hand, if player i\u2217\nmoves into slot i then his lookahead utility is at least ci+1 (vi\u2217 \u2212 bi ); he wins at least slot i + 1 and pays\nat most his bid. If player i is chosen to repeat his move then his utility is the same for both cases (as\nhe will then simply play a best response move). Thus, it is enough for us to show that\n\nci+1 (vi\u2217 \u2212 bi ) > ci\u2217 \u22121 vi\u2217\n\n\f9\n\nHowever bi < vi < \u03b1vi\u2217 and putting this together with the above inequalities gives\nci\nci+1 (vi\u2217 \u2212 bi ) >\n(1 \u2212 \u03b1)vi\u2217\nm\n\u03b2\n\u2265\nci vi\u2217\n1\u2212\u03b1\n\u03b2\nci vi\u2217\n\u2265\n1\u2212\u03b1\n1\n>\nci\u2217 vi\u2217\n1\u2212\u03b1\n> ci\u2217 \u22121 vi\u2217\nWe are now done, by our choice of \u03b1 and \u03b2, and have shown that player i\u2217 moving into slot i is a\nlookahead improving move. This contradicts the fact we are at an equilibria.\n\u0003\nci\nThus we have established that for all i \u2208 I, ci+1 < m\n. Thus, we can bound the optimal social\nm\nutility contributed by the slots i \u2208 I by m\u22121 ci0 vi0 \u2217 where i0 = mini\u2208I i.\nNow if 1 \u2208\n/ I then we have achieved our constant coordination ratio since then either c1 v1 > \u03b1c1 v1\u2217\nor c1\u2217 v1\u2217 \u2265 \u03b2c1 v1\u2217 . Hence, we are guaranteed at least min{\u03b1, \u03b2}c1 v1\u2217 \u2265 min{\u03b1, \u03b2}ci0 vi0 \u2217 , that is, a\nleast a constant factor of the social utility from all the slots in I in the optimal allocation. So we\nsuppose 1 \u2208 I.\nm\nChoose \u03b11 = m\u22121\n\u03b1 and consider the player currently in slot 2. By this choice of \u03b11 , we ensure that\nthis player does not have value more than \u03b11 v1\u2217 . To see this, recall the player is bidding in a balanced\nmanner and so, by Claim 2.5, his bid b2 satisfies\n\nv2 \u2265 b2 \u2265 (1 \u2212\n\nc2\n1\n)v2 \u2265 (1 \u2212 )v2\nc1\nm\n\nOn the other hand, as 1 \u2208 I we have\nb1 = v1 \u2264 \u03b1v1\u2217\nm\nThus, we must have v2 \u2264 m\u22121\n\u03b1v1\u2217 = \u03b11 v1\u2217 or the second player would win the first slot.\nNow let \u0393 be the set of players with value at least \u03b11 v1\u2217 . Choose some constant \u03b3. If |\u0393| < \u03b3n,\nthen player 1\u2217 's lookahead utility for moving into slot one is at least (1 \u2212 \u03b3)(1 \u2212 \u03b11 )v1\u2217 c1 . If player 1\u2217\nstays put, ignoring a repeat move for player 1\u2217 , which occurs with probability n1 , player i\u2217 's utility in\nevery other circumstance is at most\n\n1\n\u03b2\nc1\u2217 v1\u2217 <\nc1 v1\u2217\n1\u2212\u03b1\n1\u2212\u03b1\nSince player 1\u2217 's utility is the same for both cases when a repeated move occurs and since we can\nchoose \u03b2 sufficiently small (i.e, \u03b2 < (1 \u2212 \u03b3)(1 \u2212 \u03b1)(1 \u2212 \u03b11 )), player 1\u2217 will improve by moving into slot\n1 in this case, contradicting the fact that we are at an equilibrium.\nThus, we may suppose |\u0393| > \u03b3n. Let i1 = maxi\u2208\u0393 i. Then the players in \u0393 contribute at least\n\u03b3n\u03b11 v1\u2217 ci1 to the social utility. Take a constant \u03b4 and suppose that ci1 \u2265 \u03b4 cn1 . Then the players in \u0393\nwould contribute at least \u03b3\u03b4\u03b11 c1 v1\u2217 . Again, this a constant fraction of social utility that is contributed\nin the optimal allocation by player 1\u2217 which, in turn, is a constant factor of the optimal social utility\nof the slots in I. Thus, we would achieve a constant factor of the optimal social utility.\nSo we may assume ci1 < \u03b4 cn1 . Consider player i1 . His lookahead utility for staying in place, ignoring\nthe case of a repeated move, is at most\nc1\u2217 \u22121 v1\u2217 <\n\nci1 \u22121 vi1 \u2264\n\n1\n1 \u03b4\n1 \u03b4\nci1 vi1 \u2264\nc1 vi1 \u2264\nc1 vi\u2217\n1\u2212\u03b1\n1\u2212\u03b1n\n1\u2212\u03b1n\n\nWe may assume that player v1 \u2264 (1\u2212\u000f)\u03b11 v1\u2217 , for some constant \u000f, otherwise we are done. Therefore,\nif player i1 moves to slot 1 then he will earn at least \u000fc1 v1\u2217 provided that player 1 makes the next\nmove. This occurs with probability 1/n, and so his total lookahead utility, ignoring a repeated move,\n\n\f10\n\nis at least n\u000f c1 v1\u2217 . Thus by choosing \u03b4 \u2264 (1 \u2212 \u03b1)\u000f, it follows that the coordination ratio is constant in\nthe average case model.\n\u0003\n\n3. Industrial Organisation: Cournot Competition\nNext we consider the classical game theoretic topic of duopolistic competition. Economists have\nconsidered a number of alternative models for market competition [75], prominent amongst them is\nthe Cournot model [17]. Our main result here is that the social surplus increases when firms are not\nmyopic; surprisingly, social welfare is actually maximized when firms use 2-lookahead.\nThe Cournot model assumes players sell identical, nondifferentiated goods, and studies competition\nin terms of quantity (rather than price). Each player takes turns choosing some quantity of good to\nproduce, qi , and pays some marginal cost to produce it, c. The price for the good is then set as a\nfunction of the quantities produced by both players, P (qi + qj ) = (a \u2212 qi \u2212 qj ), for some constant a > c.\nOn turn l, each player i makes profit: \u03a0li (qi , qj ) = qi (a \u2212 qi \u2212 qj \u2212 c). In this form, the model then\nhas only has one equilibrium, called the Cournot equilibrium, where qi = (a \u2212 c)/3 for each player. At\nequilibrium, each player make a profit of \u03a0i (qi , qj ) = qi (1 \u2212 2qi ). The consumer surplus is 2qi2 and the\nsocial surplus is then 2qi (1 \u2212 qi ).\n\n3.1. Production under Lookahead Search.\nWe analyse this game when players apply k-lookahead search. In industrial settings it is natural to\nassume that payoffs are collected over time (as in a repeated game); thus, we focus upon the path\nmodel. We define this model inductively. In a k-step lookahead path model, each player i's utility is\nthe sum of his utilities in the current turn and the k \u2212 1 subsequent turns. He models the quantities\nchosen in the subsequent turns as though the player acting during those turns were playing the game\nwith a smaller lookahead. More specifically, he assumes that the player acting in the t'th subsequent\nturn chooses their quantity to maximise their utility under a k \u2212t lookahead model. In order to rewrite\nthis rigorously, let \u03c0li be the contribution to his utility that player i expects on the lth subsequent\nturn (and \u03c00i be the contribution to his utility that player i expects on his current turn), let \u03c0lj be\nthe contribution to player j's utility that player i expects on the l'th subsequent turn, and let qli\n(respectively, qlj ) be the quantity that player i expects to choose (respectively, expects his opponent\nto choose) under this model.\nP\ni\nThen in the path model, player i's expected utility function is \u03a0i = k\u22121\nt=0 \u03c0t . Player j's expected\nP\nk\u22121 j\nj\nutility function on player i's turn is \u03a0 = t=0 \u03c0t . Our aim now is to determine the quantities that\nplayer i expects to be chosen by both players in the subsequent turns and, thereby, determine the\nquantity he chooses this turn and the utility he expects to garner. To facilitate the discussion, it\nshould be noted that unless noted otherwise, any reference to a \"turn\" refers to a turn during player\ni's calculation and not an actual game turn.\nTo simplify our analysis, we will define ql to be the quantity chosen on turn l by whichever player\nis acting and \u03a0l to be the expected utility that that player garners from turn l to turn k. So \u03a00 = \u03a0i ,\nP\nj\ngarnered from turn l to turn k by the player who\n\u03a01 = k\u22121\nt=1 \u03c0t , etc. We define \u03a0l to be the utility\nPk\u22121 i\nj\ndoes not act during turn l. So \u03a00 = \u03a0 , \u03a01 = t=1 \u03c0t , etc. It is clear that on each turn l, the active\nplayer is trying to maximise \u03a0l .\nWe are now ready to compute these quantities and utilities recursively. We may assume that a = 1\nand c = 0. By our definition above, we have that \u03a0k = qk (1 \u2212 qk \u2212 qk\u22121 ) and \u03a0k = qk\u22121 (1 \u2212 qk \u2212 qk\u22121 ).\nOur definition also gives us the recursive formula for l < k that \u03a0l = ql (1 \u2212 ql \u2212 ql\u22121 ) + \u03a0l+1 and\n\u03a0l = ql\u22121 (1 \u2212 ql \u2212 ql\u22121 ) + \u03a0l+1 . Note that in each of these formulas, \u03a0l and \u03a0l are each functions of\nqt for t \u2265 l; ql\u22121 is in fact fixed on the previous turn and is, therefore, not a variable in \u03a0l . It is now\npossible to calculate ql recursively.\n\n\f11\n\nLemma 3.1. The form of ql is \u03b2l \u2212 \u03b1l ql\u22121 , where \u03b2k = \u03b1k = \u03b2k\u22121 = 12 , \u03b1k\u22121 =\n\u03b2l =\n\n1\n3\n\nand, for l < k \u2212 1,\n\n2 \u2212 \u03b2l+1 + \u03b1l+1 \u03b2l+2 \u2212 \u03b1l+1 \u03b1l+2 \u03b2l+1\n1\n, \u03b1l =\n2\n2 \u03b1\n4 \u2212 2\u03b1l+1 \u2212 \u03b1l+1 \u03b1l+2\n4 \u2212 2\u03b1l+1 \u2212 \u03b1l+1\nl+2\n\nProof. We proceed by inducting down from qk . Consider qk which is the active player's choice on the\nfinal turn. As it is the final turn, he is acting myopically and so will choose qk so as to maximise\n1\u2212qk\u22121\n\u03a0k = qk (1 \u2212 qk \u2212 qk\u22121 ). This parobala as a function of qk is maximised when qk =\n. Doing\n2\na similar calculation for \u03a0k\u22121 = qk\u22121 (1 \u2212 qk\u22121 \u2212 qk\u22122 ) + \u03a0k gives us the desired values for \u03b2k\u22121 and\n\u03b1k\u22121 . We now assume the lemma for all l > L and try to prove it for qL . Recall the recursive formula\n\u03a0L = qL (1 \u2212 qL \u2212 qL\u22121 ) + \u03a0L+1 . Taking the derivative of this with respect to qL and setting it all\nequal to zero gives us\n\u2202qL+1\n\u2202\u03a0L+2 \u2202qL+2\n\u2202qL+1\nqL \u2212\nqL+2 +\n0 = (1 \u2212 2qL \u2212 qL\u22121 ) + (1 \u2212 2qL \u2212 qL+1 ) \u2212\n\u2202qL\n\u2202qL\n\u2202qL+2 \u2202qL\nThe last term of the above sum is zero, since qL+2 is chosen so that\nthe inductive hypothesis into the above equation and simplify, we get\n\n\u2202\u03a0L+2\nqL+2\n\n= 0. Thus, if we plug in\n\n2\n2 \u2212 \u03b2L+1 + \u03b1L+1 \u03b2L+2 \u2212 \u03b1L+1 \u03b2L+2 \u2212 \u03b1L+1 \u03b1L+2 \u03b2L+1 = (4 \u2212 2\u03b1L+1 \u2212 \u03b1L+1\n\u03b1L+2 )qL \u2212 qL\u22121\n\nThis gives us the desired result.\n\n\u0003\n\nOur goal is now to calculate q0 as this will tell us the quantity that player i actually chooses\non his turn. From the above lemma, we can calculate q0 if we can determine \u03b10 and \u03b20 . Using\nnumerical methods on the above recursive formula, we see that as k \u2192 \u221e, \u03b10 decreases towards a\nlimit of 0.2955977 . . . and \u03b20 approaches a limit of 0.4790699 . . .. These values also converge quite\nquickly; they both converge to within 0.0001 of the limiting value for k \u2265 10. Thus, at a lookahead\nequilibrium, player i will choose qi \u2248 .0.4790699\u22120.2955977qj and player j, symmetrically, will choose\nqj \u2248 0.4790699 \u2212 0.2955977qi . So each player will choose a quantity q \u2248 0.369767. which is more than\nin the myopic equilibrium. Indeed, it is easy to show that for every k \u2265 2, each player will produce\nmore than the myopic equilibrium. This is illustrated in Figure 1. Observe the quantity produced\ndoes not change monotonically with the length of foresight k, but it does increase significantly if\nnon-myopic lookahead is applied at all. Consequently, in the path model looking ahead is better for\nsociety overall but worse for each individual firm's profitability (as the increase in sales is outweighed\nby the consequent reduction in price).\n\nFigure 1. How output varies with foresight k\n\n\f12\n\nTheorem 3.2. For Cournot games under the path model, output at a k-lookahead equilibrium peaks\nat k = 2 with output 12.5% larger than at a myopic equilibrium (k = 1). As foresight increases, output\nis 10.9% larger in the limit. The associated rises in social surplus are 5.5% and 4.9%, respectively,\n3.2. Stackelberg Behaviour.\nWe could also analyse this game under the leaf model, but this model is both less realistic here and\ntrivial to analyse. However, it is interesting to note that for the leaf model with asymmetric lookahead,\nwhere player i has 2-lookahead and player j has 1-lookahead, we get the same equilibrium as the classic\nStackelberg model for competition. Thus, the use of lookahead search can generate leader-follower\nbehaviours.\n\n4. Unsplittable Selfish Routing\nNow consider the unsplittable selfish routing game. We show that any 2-lookahead equilibrium has\na constant coordination ratio. We then show how to derive a similar result for 2-lookahead dynamics.\nFor this game we have a directed graph G = (V, E) and a set of n agents. Agent i wants to route 1\nunit of flow from a source si to a destination ti . Each agent i chooses an si \u2212ti path Pi and these paths\ntogether generate a flow f . We assume that there is a linear latency P\nfunction \u03bbe (fe ) = ae fe + be on\neach edge edge e \u2208 E. The total latency of P\na flow f is denoted l(f ) = e\u2208E \u03bbe (fP\ne )fe = (ae fe + be )fe .\nThe latency of player i is denoted li (f ) = e\u2208Pi ae fe + be ; observe that l(f ) = i\u2208U li (f ). For this\ngame, we consider 2-lookahead in both the leaf and path models, under the average-case lookahead\nmodel.\nRecall, in the leaf model, a player i's move from a flow f to a flow f 0 is lookahead improving if\nE(li (f 00 )|f 0 ) > E(li (f 00 )|f ) where f 00 is the flow obtained after the next player (chosen uniformly at\nrandom amongst all the players) makes a (myopic) best response. In the path model a player i's move\nfrom a flow f to a flow f 0 is lookahead improving if 12 li (f 0 ) + 12 E(li (f 00 )|f 0 ) > 12 li (f ) + 12 E(f 00 |f ) where\nf 00 is as above.\nTheorem 4.1. \u221aIn the average-case 2-lookahead leaf model, the coordination ratio for an equilibrium\nis at most (1 + 5)2 .\nProof. This proof adapts the result in [3] to our setting. Let f be any flow at a lookahead equilibrium\nand f \u2217 be an optimal flow. Suppose player i is taking path Pj in flow f and path Pj\u2217 in flow f \u2217 . Let\nJ(e) be the set of players using edge e in the flow f and let J \u2217 (e) be the same for f \u2217 .\nAt a lookahead equilibrium, player j doesn't want to move from Pj to Pj\u2217 . This means that after\na random/worst case next move, the strategy Pj has a higher (expected) payoff than the strategy\nPj\u2217 . In particular, it must the case that the best possible outcome resulting from from choosing Pj\nhas a higher (expected) payoff than the worst possible outcome resulting from the strategy Pj\u2217 . In\nthe former case, the best possible outcome is that the next player had also been using the path Pj\nbut then moves completely off the path. Similarly, in the latter case, the worst possible outcome is\nthat the next player had not been using any edge on the path Pj\u2217 but then changes strategy and also\nselects the path Pj\u2217 entirely. Thus we must have:\n\nX\ne\u2208Pj\u2217\n\nae (fe + 2) + be \u2265\n\nX\ne\u2208Pj\n\nae fe + be \u2212\n\nX\ne\u2208Pj :fe \u22652\n\nae\n\n\f13\n\nSumming over all players j, we obtain\n\uf8eb\nXX\nj\n\nae (fe + 2) + be \u2265\n\nX\n\n\uf8f6\nX\n\nae fe + be \u2212\n\n\uf8ed\n\ne\u2208Pj\u2217\n\nj\n\n=\n\nae fe + be \u2212\n\nX\n\nX\n\nj\n\ne\u2208Pj :fe \u22652\n\ne\u2208E j\u2208J(e)\n\nX\n\n=\n\u2265\n\nae\n\nae fe\n\ne\u2208Pj :fe \u22652\n\nX\n\n(ae fe + be )fe \u2212\n\ne\u2208Pj :fe \u22652\n\ne\u2208E\n\nX1\n\n\u2265\n\nX\n\n(ae fe + be )fe \u2212\n\ne\u2208E\n\nX\n\nae \uf8f8\n\ne\u2208Pj :fe \u22652\n\ne\u2208Pj\n\nX X\n\nX\n\n2\n1X\n\n1\nae fe2\n2\n\n(ae fe + be )fe\n\ne\u2208E\n\n=\n\n2\n\n\u03bbe (fe )\n\ne\u2208E\n\nRearranging gives and applying the Cauchy-Schwartz inequality6 produces\nXX\n1X\n\u03bbe (fe ) \u2264\nae (fe + 2) + be\n2\nj e\u2208Pj\u2217\ne\u2208E\nX\n=\n(ae (fe + 2) + be )fe\u2217\ne\u2208E\n\n\u2264\n\nX\n\nae fe fe\u2217 + (2ae + be )fe\u2217\n\ne\u2208E\n\n\u2264\n\nX\n\nae fe fe\u2217 + 2\u03bbe (fe\u2217 )\n\ne\u2208E\n\n\u2264\n\nsX\n\nae fe2\n\n*\n\nsX\n\ne\u2208E\n\n\u2264\n\nsX\n\nae fe\u2217 2 + 2\n\ne\u2208E\n\n\u03bbe (fe ) *\n\nsX\n\ne\u2208E\n\nX\n\n\u03bbe (fe\u2217 )\n\ne\u2208E\n\n\u03bbe (fe\u2217 ) + 2\n\ne\u2208E\n\nX\n\n\u03bbe (fe\u2217 )\n\ne\u2208E\n\nqP\n\nP e \u03bbe (fe\u2217)\ne \u03bbe (fe )\n\nand observe that \u03c12 is the coordination ratio, given we choose the worst\n\u221a\nlookahead equilibrium f . Consequently, 21 \u03c12 \u2264 \u03c1 + 2. Solving gives \u03c1 \u2264 1 + 5 as desired.\n\u0003\nSet \u03c1 =\n\nNext we consider the lookahead dynamics and study coordination ratio for the lookahead dynamics.\nTheorem 4.2. In the average-case 2-lookahead model, the coordination ratio for lookahead dynamics\nis a constant for the leaf model.\nProof. We follow a similar approach to Theorem 4.1 in [30] and start by proving some sub-lemmas.\nLemma 4.3. If player i makes a lookahead improving move from path Pi to Pi0 which changes the\nflow from f to fi0 then li (fi0 ) \u2264 2li (f ) + n1 l(f ).\n6For\n\nany two vectors x and y, we have xT y \u2264\n\n\u221a\n\nxT x *\n\np\n\nyT y.\n\n\f14\n\nProof. So player i's lookahead cost with fi0 is less than his cost with f . Moreover, we can lower bound\nthe lookahead cost of fi0 by the quantity\nX fe\nfe\n(ae fe + be ) + (1 \u2212 )(ae (fe + 1) + be )\nn\nn\n0\n\ne\u2208Pi\n\n=\n\nX\n\nae (fe + 1) + be \u2212\n\ne\u2208Pi0\n\n\u2265\n\nX\n\n(1 \u2212\n\n1\n)ae (fe + 1) + be\nn\n\n(1 \u2212\n\n1\n)(ae (fe + 1) + be )\nn\n\ne\u2208Pi0\n\n\u2265\n\nX\n\nfe\nae\nn\n\ne\u2208Pi0\n\n= (1 \u2212\n\n1\n)li (fi0 )\nn\n\nThis would be the cost incurred if the randomly selected next player j avoids any edge e that player\ni is on (either by moving away from e or not moving onto e). Using similar reasoning, we may upper\nbound the cost to player i of sticking with Pi by\nX fe\nfe\n(ae fe + be ) + (1 \u2212 )(ae (fe + 1) + be )\nn\nn\n\ne\u2208Pi\n\n=\n\nX\ne\u2208Pi\n\n\u2264\n\nX\n\nfe\n)ae\nn\nX\n2ae fe + be\n\u2264\n\n(ae fe + be ) + (1 \u2212\nae (fe + 1) + be\n\ne\u2208Pi\n\ne\u2208Pi\n\n\u2264 2li (f )\nHere we assumed the next player j selects every edge e that player i is on (either by staying on e or\n1\nby moving onto e). Therefore, li (fi0 ) \u2264 2(1 + n\u22121\n)li (f ) which implies the statement in the lemma. \u0003\nApplying Lemma 4.3 with Lemma 4.2 in [30], we get:\nLemma 4.4. If agent i changes his path from Pi to Pi0 , changing the flow from f to fi0 , then l(fi0 ) \u2264\nl(f ) + (d + 1)li (fi0 ) \u2212 li (f ). In particular, if agent i makes a lookahead improving move then l(fi0 ) \u2264\n(1 + n1 )l(f ) + 3li (f ).\nNow, applying Lemma 4.4 with Lemma 4.3 in [30].\nLemma 4.5. Let f be the current flow. Suppose we chose a player at random and they make a\nlookahead best response resulting in flow f 0 . Then E(li (f 0 )|f ) \u2264 (1 + n4 )l(f ).\nFinally, we prove the following lemma which will imply the statement of the theorem.\nLemma 4.6. Let f be the current flow. Suppose we chose a player at random and they make a\n1\nlookahead best response resulting in flow f 0 . Then either E(l(f 0 )|f ) \u2264 (1 \u2212 2n\n)l(f ) or l(f ) < (6 +\n\u221a\n37)OP T .\nProof. Suppose player i changes his path from Pj to Pj0 resulting in the flow changing from f to fi0 .\nP\nThus E(l(f 0 )|f ) = n1 i l(fi0 ).\n\n\f15\n\nCase 1:\n\n0\ni 4li (fi )\n\nP\n\n\u2264\n\nP\n\ni li (f )\n\nE(l(f 0 )|f ) =\n\u2264\n\n1X 0\nl(fi )\nn\ni\n1X\nl(f ) + li (fi0 ) \u2212 li (f ) +\nn\ni\n\n\u2264\n\u2264\n\nX\n\nae fi,e\n\ne\u2208Pi0 \u2212Pi\n\n1X\nl(f ) + 2li (fi0 ) \u2212 li (f )\nn\ni\n1X\n1\nl(f ) + li (f ) \u2212 li (f )\nn\n2\ni\n\n= (1 \u2212\n\n1\n)l(f )\n2n\n\nP\nP\n0\nCase 2:\ni 4li (fi ) >\ni li (f ) = l(f )\n\u2217\nLet f be the optimal flow and let Pi\u2217 be player i's path in this flow. Let J \u2217 (e) be the set of\nplayers on edge e in f \u2217 . Since Pi0 is a lookahead best response, we may apply Lemma 4.3 to see that\nli (fi0 ) \u2264 2li (f \u2217 ) + n1 l(f \u2217 ). Thus\nX\nX\n1\nl(f ) < 4\nli (fi0 ) \u2264 4\n2li (f \u2217 ) + l(f \u2217 )\nn\ni\ni\nX\nXX\n\u2217\n= 12\nli (f ) = 12\nae fe\u2217 + be\ni\n\n\u2264 12\n\ni\n\nX X\n\ne\u2208E\n\nae (fe + 1) + be\n\ne\u2208E i\u2208J\u2217(e)\n\n= 12\n\nX\n\nae fe fe\u2217 be fe\u2217 + ae fe\u2217\n\ne\u2208E\n\np\n\u2264 12 l(f )l(f \u2217 ) + l(f \u2217 )\nwhere the last inequality follows from Cauchy-Schwartz. Thus, if we set x =\nbe transformed into the inequality x2 \u2264 12x + 1.\n\nq\n\nl(f )\nOP T ,\n\nthe above can\n\u0003\n\nThe remainder of the proof of Theorem 4.2 follows by applying the above lemmas as shown in\n[30].\n\u0003\n4.1. Valid Utility Games.\nHere is a bad example for the path model (a slightly modified example applies to the leaf model). It\napplies for any number t of lookahead moves. Take a Steiner Set System S(2, k, n). For example, these\nexist with n = q 2 + q + 1 and k = q + 1. Let each subset in the system induce a \"sub-game\" - thus each\npair of players are together in exactly one subgame. Consequently, each player is in n\u22121\nk\u22121 = q + 1 = k\ng g\nsubgames, and n games in total. The strategy set of a player i in subgame g is {yi , xi,1 , xgi,2 , . . . , xgi,k }.\nIt has one nice strategy and k naughty strategies: player i always gets one point\nP for playing the nice\nstrategy yig , but gets two points for playing a naughty strategy xgi,li provided j lj = i mod k, where\nthe sum is over all players j who are playing a strategy xgj,lj - we call i the winner of subgame g in\nthe case.\nThus a player i who moves next can guarantee k points by playing ys but can guarantee 2k points\nby playing xg s to win all k subgames it is in. Moreover, the player can lose at most one game in\neach subsequent time period. This follows as the next t = k players share exactly one game each with\nplayer i. Thus the player, in the worst case receives 2k + 2(k \u2212 1) + * * * + 4 + 2 = k(k + 1) in the next\nk moves. This is greater than the k 2 payoff from playing only ys.\n\n\f16\n\nConsider then the dynamics of this game under k-lookahead search. Over time, at any state of\nplay, the total value of the game will be 2n; in each of the n subgames all the players are behaving\nnaughtily. The optimal value however is n(k + 1); in each subgame, k \u2212 1 of the players are nice and\none is naughty. So we have shown:\nLemma 4.7. For valid utility\ngames, in the path model the coordination ratio of k-lookahead dynamics\nt+1\n1\u221a\nis at least k+1\nn.\n\u0003\n=\n\u2265\n2\n2\n2\n4.2. Basic Utility Games.\nFor basic utility games, good guarantees can be obtained for the path model. More interestingly, for\nthe leaf model lookahead equilibria can be extremely bad, even for 2-lookahead equilibria.\nLemma 4.8. In basic utility games, the coordination ratio of 2-lookahead equilibria can be arbitrarily\nbad in the leaf model.\nProof. Consider the following symmetric 2-player game. Let each player have a groundset {B, T, G}.\nA feasible strategy consists of playing at most one action in the groundset. We create a submodular\nsocial function using the table\n\u2205\nB\nT G\nB 6\n6\n6 1\nT \u03ba-9 \u03ba-9 7 4\nG \u03ba-5 \u03ba-10 8 5\nSet \u03b3(\u2205, \u2205) = 0. Then let the ijth entry of the matrix, \u03b4ij , be the marginal value of adding action i\nwhen action j is being played by the other player. For example, \u03b3(B, \u2205) = \u03b3(\u2205, \u2205) + \u03b4B,\u2205 = 0 + 6 = 6.\nSimilarly, \u03b3(B, B) = 12, \u03b3(T, \u2205) = \u03ba \u2212 9, \u03b3(G, \u2205) = \u03ba \u2212 5, \u03b3(B, G) = \u03ba \u2212 4, \u03b3(B, T ) = \u03ba \u2212 3, \u03b3(T, T ) =\n\u03ba \u2212 2, \u03b3(T, G) = \u03ba \u2212 1, \u03b3(G, G) = \u03ba.\nWe need to extend this definition to all subsets. Suppose that Player 1 is currently choosing S1 and\nPlayer 2 is currently choosing S2 . To complete the definition of \u03b3, we say that the marginal value of\nadding action i to the subset S = S1 \u222a S2 , is \u03b4i,S = minj\u2208S1 \u222aS2 \u03b4ij .\nNote that this is true if i is added to S1 and if i is added to S2 . This processes produces a submodular\nsocial function. The payoff functions are then defined in accordance with the Vickrey condition.\nClearly, as the players are constrained to play singleton actions, the optimal solution \u03a9 = {G, G}\nhas value \u03ba. We claim that {B, B}, with social value 12, is the only equilibrium in the leaf model.\nThus, for any \u03ba, we can be a factor \u03a9(\u03ba) away from the optimal social value.\nTo prove this, first suppose that Player 1 plays B. According to the Vickrey condition, the best\nresponse of Player 2 is to play T (she needs to choose \u2217 maximize \u03b3(B, \u2217)). The payoff to player 1 is\nthen \u03b3(B, T ) \u2212 \u03b3(\u2205, T ) = (\u03ba \u2212 3) \u2212 (\u03ba \u2212 9) = 6. Second suppose that Player 1 plays T . According\nto the Vickrey condition, the best response of Player 2 is to play G (she needs to maximize \u03b3(T, \u2217)).\nThe payoff to player 1 is then \u03b3(T, G) \u2212 \u03b3(\u2205, G) = (\u03ba \u2212 1) \u2212 (\u03ba \u2212 5) = 4. Finally suppose that\nPlayer 1 plays G. According to the Vickrey condition, the best response of Player 2 is to play G\n- observe this must be the case as (G, G) is the optimal solution. The payoff to player 1 is then\n\u03b3(G, G) \u2212 \u03b3(\u2205, G) = \u03ba \u2212 (\u03ba \u2212 5) = 5.\nThus, with 2-lookahead, Player 1 will always think it in his interest to play B. (Note that in the\nleaf model, it is irrelevant for Player 1 what strategy Player 2 is currently playing.) By a symmetric\nargument, Player 2 will always think it in her interest to play B.\n\u0003\n5. Shapley Network Design Games\nFor our final example we show that the use of lookahead search may allow for \"uncoordinated\"\ncooperative behaviours. By looking ahead, a player may select a cooperative move whose consequence\ncan be to induce other players to also make cooperative moves. We give a very simple illustration\nof this behaviour. Consider the following Shapley network design game: Given a network, there is a\nsingle source s and a single sink t. We have n players, each wanting to route from s to t. There are N\n\n\f17\n\npaths (where N may be exponential) to choose from. The cost of any link is equally shared between\nthose players that use it. The coordination ratio is then easily seen to be at least n. However, the\ncoordination ratio improves by a factor k, when the players use k-lookahead search.\nTheorem 5.1. The coordination ratio of k-lookahead dynamics for Shapley network design games in\nthe leaf model is at most n/k.\nProof. We present the proof for the worst-case lookahead model. The proof for the average-case model\nuses the same idea. Assume the players are currently choosing the paths {P\u03041 , P\u03042 , . . . , P\u0304n }. Consider\nthe depth k tree when the players move in the order 1, 2, . . . , k. Take a decision node for player k \u2212 1.\nThis has N children that are decision nodes for player k. Let the paths chosen by player k at these\nnodes be Q1 , Q2 , . . . , QN , respectively. Suppose that in response to this move, player k \u2212 1 chooses\nthe path Pj . We claim that Pj = Qj .\nX\nX\nce\nce\nc(P, T 0 ) =\n+\nne\nne\ne\u2208P \u2229Qj \u2229Pj\ne\u2208P/(Qj \u222aPj )\nX\nX\nce\nce\n+\n+\nne + 1\nne \u2212 1\ne\u2208(P \u2229Qj )/Pj\ne\u2208(P \u2229Pj )/Qj\n\u0013\n\u0012\nX\nce\nce\n\u2212\n= c(P, T ) \u2212\nne ne + 1\ne\u2208(P \u2229Qj )/Pj\n\u0013\n\u0012\nX\nce\nce\n\u2212\n+\nne \u2212 1 ne\ne\u2208(P \u2229Pj )/Qj\n\nThus\n0\n\nc(Qj , T ) = c(Qj , T ) \u2212\n\n\u0013\nX \u0012 ce\nce\n\u2212\nne ne + 1\n\ne\u2208Qj /Pj\n\nNow since c(Qj , T ) \u2264 c(P, T ) we have\n\u0013\nce\nce\n\u2212\nne ne + 1\ne\u2208(P \u2229Qj )/Pj\n\u0013\n\u0012\nX\nce\nce\n+\n\u2212\nne \u2212 1 ne\ne\u2208(P \u2229Pj )/Qj\n\u0012\n\u0013\nX\nce\nce\n\u2265 c(Qj , T ) \u2212\n\u2212\nne ne + 1\ne\u2208(P \u2229Qj )/Pj\n\u0012\n\u0013\nX\nce\nce\n\u2212\n+\nne \u2212 1 ne\ne\u2208(P \u2229Pj )/Qj\n\u0012\n\u0013\nX\nce\nce\n\u2265 c(Qj , T ) \u2212\n\u2212\nne ne + 1\ne\u2208(P \u2229Qj )/Pj\n\u0013\nX \u0012 ce\nce\n\u2265 c(Qj , T ) \u2212\n\u2212\nne ne + 1\n\nc(P, T 0 ) = c(P, T ) \u2212\n\nX\n\n\u0012\n\ne\u2208Qj /Pj\n\n0\n\n= c(Qj , T )\nThis proves the claim. Applying induction, we see that each player 1, . . . , k will play the same\nstrategy P \u2217 , and thus, receive the same payoff. Let's take the worst case choice for players 2, . . . , k\nfrom the point of view of player 1. If P \u2217 = P SP , the shortest s \u2212 t path, then each of the k chosen\nplayers will have a cost of at most\n\n\f18\n\nc(P SP )\nopt\n\u2264\nk\nk\n\u2217\nSP\nThus, if P 6= P , then player 1 can guarantee himself a cost of at most\napplies for all players so, in an equilibrium, the total cost is at most, nk opt.\n\nopt\nk .\n\nThis argument\n\u0003\n\nReferences\n[1] H. Ackermann, H. R\u00f6glin, and B. V\u00f6cking, \"On the impact of combinatorial structure on congestion games\", Journal\nof the ACM, 55(6), 2008.\n[2] R. Aumann, \"Subjectivity and correlation in randomized strategies\", Journal of Mathematical Economics, 1, pp6796, 1974.\n[3] B. Awerbuch, Y. Azar and A. Epstein, \"The price of routing unsplittable flow\", Proceedings of the 37th Annual\nACM Symposium on Theory of Computing (STOC), 2005.\n[4] B. Awerbuch, Y. Azar, A. Epstein, V. Mirrokni, and A. Skopalik, \"Fast convergence to nearly-optimal solutions in\npotential games\", Proceedings of the 9th ACM Conference on Electronic Commerce (EC), pp264\u2013273, 2008.\n[5] B. Awerbuch and R. Kleinberg, \"Online linear optimization and adaptive routing\", Journal of Computer and System\nSciences, 74(1), pp97-114, 2008.\n[6] K. Basu and J. Weibull, \"Strategy Subsets Closed Under Rational Behaviour\", Papers 479, Stockholm - International\nEconomic Studies.\n[7] P. Berenbrink, T. Friedetzky, L. Goldberg, P. Goldberg, Z. Hu, and R. Martin, \"Distributed selfish load balancing\",\nProceedings of the 17th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp354-363, 2006.\n[8] A. Blum, E. Even-Dar, and K. Ligett, \"Routing without regret: on convergence to Nash equilibria of regretminimizing algorithms in routing games\", Proceedings of the 21st Annual ACM Symposium on Principles of Distributed Computing (PODC), pp45-52, 2006.\n[9] A. Blum, M. Hajiaghayi, K. Ligett and A. Roth, \"Regret minimization and the price of total anarchy\", Proceedings\nof the 40th Annual ACM Symposium on Theory of Computing (STOC), pp373-382, 2008.\n[10] A. Blum and Y. Mansour, \"Learning, regret minimization and correlated equilibria\", In Algorithmic Game Theory,\nN. Nisan, T. Roughgarden, E. Tardos, V. V. Vazirani (eds.), pp79-102, Cambridge University Press, 2007.\n[11] G. Brown, \"Iterative solutions of games by fictitious play\", in Activity Analysis of Production and Allocation,\nT. Koopmans (ed.), pp374-376, Wiley, 1951.\n[12] T. Bu, X. Deng, X., Q. Qi, \"Forward looking Nash equilibrium for keyword auction\", Information Processing Letters,\n105(2), pp41-46, 2008.\n[13] M. Cary, A. Das, B. Edelman, I. Giotis, K. Heimerl, A. Karlin, C. Mathieu and M. Schwarz, \"Greedy bidding\nstrategies for keyword auctions\", Proceedings of the ACM International Conference on Electronic Commerce (EC),\n2007.\n[14] S. Chien and A. Sinclair, \"Convergence to approximate Nash equilibria in congestion games\", Proceedings of the\n18th ACM-SIAM Symposium on Discrete Algorithms (SODA), pp169-178, 2007.\n[15] G. Christodolou, V. Mirrokni, and A. Sidiropolous, \"Convergence and approximation in potential games\", Proceedings of the 18th Annual Symposium on Theoretical Aspects of Computer Science (STACS), pp349-360, 2006.\n[16] J. Conlisk, \"Why Bounded Rationality?\", Journal of Economic Literature, 34(2), pp669-700, 1996.\n[17] A. Cournot, Recherces sur les Principes Math\u00e9matiques de la Th\u00e9orie des Richesse, Paris, 1838.\n[18] B. Edelman, M. Ostrovsky and M. Schwarz, \"Internet advertising and the generalised second-price auction: selling\nbillions of dollars worth of keywords\", American Economic Review, 97(1), pp 242-259, 2007.\n[19] E. Even-Dar, Y. Mansour, and U. Nadav, \"On the convergence of regret minimization dynamics in concave games\",\nProceedings of the 41st Annual ACM Symposium on Theory of Computing (STOC), 2009.\n[20] G. Ellison, \"Learning, Local Interaction, and Coordination\", Econometrica, 61, pp1047-1071, 1993.\n[21] A. Fabrikant and C. Papadimitriou, \"The complexity of game dynamics: BGP oscillations, sink equlibria, and\nbeyond\", Proceedings of the 19th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp844-853,\n2008.\n[22] A. Fabrikant, C. Papadimitriou, and K. Talwar, \"The complexity of pure Nash equilibria\", Proceedings of the 36th\nAnnual ACM Symposium on Theory of Computing (STOC), pp604-612, 2004.\n[23] A. Fanelli, M. Flammini, and L. Moscardelli, \"The speed of convergence in congestion games under best-response\ndynamics\", Proc. of the 35th International Colloquium on Automata, Languages and Programming (ICALP), pp796807, 2008.\n[24] L. Fortnow and R. Santhanam, \"Bounding rationality by discounting time\", Proceedings of The First Symposium\non Innovations in Computer Science (ICS), 2010.\n[25] D. Foster and R. Vohra, \"Calibrated learning and correlated equilibrium\", Games and Economic Behavior, 21,\npp40-55, 1997.\n\n\f19\n\n[26] M. Friedman, \"The methodology of positive economics\", in Essays in Positive Economics, M. Friedman, University\nof Chicago Press, pp3-43, 1953.\n[27] R. Gibbons, A Primer in Game Theory, Harvester Wheatsheaf, 1992.\n[28] G. Gigerenzer and R. Selten (eds), Bounded Rationality: the Adaptive Toolbox, MIT Press, 2001.\n[29] M. Goemans, L. Li, V. Mirrokni, and M. Thottan, \"Market sharing games applied to content distribution in ad-hoc\nnetworks\", MOBIHOC, 2004.\n[30] M. Goemans, V. Mirrokni and A. Vetta, \"Sink equilibria and convergence\", Proceedings of the 46th Symposium on\nthe Foundations of Computer Science (FOCS), pp142-154, 2005.\n[31] A. de Groot, Thought and Choice in Chess, 2nd Edition, Mouton, 1978. [Original Version: Het denken van den\nSchaker, een experimenteel-psychologische studie, Ph.D. thesis, University of Amsterdam, 1946.]\n[32] S. Hart and A. Mas-Colell, \"A simple adaptive procedure leading to correlated equilibrium\", Econometrica, 68(5),\npp1127-1150, 2000.\n[33] S. Hart \"Adaptive Heuristics\", Econometrica, 73(5), pp1401-1430, 2005.\n[34] P. Jehiel, \"Limited horizon forecast in repeated alternate games\", Journal of Economic Theory, 67, pp497-519,\n1995.\n[35] D. Kahneman, \"Maps of bounded rationality: psychology for behavioral economics\", The American Economic\nReview, 93(5), pp1449-1475, 2003.\n[36] D. Kahneman, P. Slovic and A. Tversky (eds), Judgement under Uncertainty: Heuristics and Biases, pp201-208,\nCambridge University Press, 1982.\n[37] D. Kahneman and A. Tversky, \"The simulation heursitic\", in Judgement under Uncertainty: Heuristics and Biases,\nD. Kahneman, P. Slovic and A. Tversky (eds), pp201-208, Cambridge University Press, 1982.\n[38] M. Kandori, G. Mailath and R. Rob, \"Learning, mutuation, and long-run equilibria in games\", Econometrica, 61,\npp29-56, 1993.\n[39] J. de Kleer and O. Raiman, \"How to diagnose with very little information\", Fourth International Workshop on\nPrinciples of Diagnosis, pp. 160-165, 1993.\n[40] J. de Kleer, O. Raiman and M. Shirley, \"One step lookahead is pretty good\", in Readings in Model-Based Diagnosis,\nW. Hamscher, L. Console, and J. de Kleer (eds), pp138-142, Morgan Kaufmann, 1992.\n[41] G. Klein, \"Developing expertise in decision making\", Thinking and Reasoning, 3(4), pp337-352, 1997.\n[42] G. Klein, Sources of Power: How People make Decisions, MIT Press, 1998.\n[43] R. Kleinberg, G. Piliouras and E. Tardos, \"Multiplicative updates outperform generic no-regret learning in congestion games\", Proceedings of the 41st Annual ACM Symposium on Theory of Computing (STOC), 2009.\n[44] E. Kohlberg and J. Mertens, \"On the strategic stability of equilibria\", Econometrica, 54(5), pp1003-1037, 1986.\n[45] E. Koutsoupias and C. Papadimitriou, \"Worst-case equilibria\", STACS, 1999.\n[46] R. Leme and E. Tardos, \"Pure and Bayes-Nash price of anarchy for generalized second price auction\", FOCS, 2010.\n[47] B. Lipman, \"Information processing and bounded rationality: a survey\", The Canadian Journal of Economics,\n28(1), pp42-67, 1995.\n[48] E. Markakis and O. Telelis, \"Discrete strategies in keyword auctions and their inefficiency for locally aware bidders\",\nWINE, 2010.\n[49] V. Mirrokni and A. Skopalik, \"On the complexity of Nash dynamics and sink equilibria\", Proceedings of the ACM\nInternational Conference on Electronic Commerce (EC), 2009.\n[50] V. Mirrokni and A. Vetta, \"Convergence issues in competitive games\", Proceedings of the 7th International Workshop\non Approximation Algorithms for Combinatorial Optimization Problems (APPROX), pp183-194, 2004.\n[51] A. Montanari and A. Saberi, Convergence to equilibrium in local interaction games and ising models, Technical\nReport, arXiv:0812.0198, CoRR, 2008.\n[52] R. Nagel, \"Unraveling in guessing games: an experimental study\",The American Economic Review, 85(5), pp13131326, 1995.\n[53] D. Nau, \"Pathology on game trees: a summary of results\", Proceedings of the National Conference on Artificial\nIntelligence (AAAI), pp102-104, 1980.\n[54] D. Nau, \"An investigation of the causes of pathology in games\", Artificial Intelligence, 19, 257-278, 1982.\n[55] D. Nau, \"Decision quality as a function of search depth on game trees\", Journal of the ACM, 30(4), pp687-708,\n1983.\n[56] D. Nau, \"Pathology on game trees revisited, and an alternative to minimaxing\", Artificial Intelligence, 21, pp221244, 1983.\n[57] A. Newell and H. Simon, Human Problem Solving, Prentice-Hall, 1972.\n[58] J. Pearl, Heuristics: Intelligent Search Strategies for Computer Problem Solving, Addison-Wesley, 1984.\n[59] A. Rubenstein, Modeling Bounded Rationality, MIT Press, 1998.\n[60] S. Russell and P. Norvig, Artificial Intelligence: A Modern Approach, 2nd Edition, Prentice-Hall, 2002.\n[61] L. Savage, The Foundation of Statistics, Wiley, 1954.\n[62] T. Sargent, Bounded Rationality in Macroeconomics, Clarendon Press, 1993.\n\n\f20\n\n[63] E. Sefer and U. Kuter and D. Nau, \"Real-time A* Search with Depth-k Lookahead\", Proceedings of the International\nSymposium on Combinatorial Search, 2009.\n[64] R. Selten, \"What is bounded rationality?\", in Bounded Rationality: the Adaptive Toolbox, G. Gigerenzer and R.\nSelten (eds), MIT Press, pp13-36, 2001.\n[65] R. Selten, \"Boundedly Rational Qualitative Reasoning on Comparative Statics\", in Advances in Understanding\nStrategic Behavior: Game Theory, Experiments and Bounded Rationality, Steffen Huck (ed.), Palgrave Macmillan,\npp1-8, 2004.\n[66] A. Sen, \"Rational fools: a critique of the behavioral foundations of economic theory\", Philosophy and Public Affairs,\n6(4), pp317-344, 1977.\n[67] A. Sen, \"Internal consistency of choice\", Econometrica, 61(3), pp495-521, 1993.\n[68] C. Shannon, \"Programming a computer for playing chess\", Philosophical Magazine, Series 7, 41(314), pp256-275,\n1950.\n[69] H. Simon, \"A behavioral model of rational choice\", Psychological Review, 63, pp129-138, 1955.\n[70] H. Simon, \"Rational choice and the structure of the environment\", Psychological Review, 63, pp129-138, 1956.\n[71] H. Simon, The Sciences of the Artificial, 3rd edition, MIT Press, 1996.\n[72] A. Skopalik and B. V\u00f6cking, \"Inapproximability of pure Nash equilibria\", Proceedings of the 40th Annual ACM\nSymposium on Theory of Computing (STOC), pp355-364, 2008.\n[73] D. Stahl and P. Wilson, \"Experimental evidence on players' models of other players\", Journal of Economic Behavior\nand Organization, 25(3), pp309-327, 1994.\n[74] D. Stahl and P. Wilson, \"On players' models of other players: theory and experimental evidence, Games and\nEconomic Behavior, 10(1), pp218-254, 1995.\n[75] J. Tirole, The Theory of Industrial Organization, MIT Press, 1988.\n[76] A. Tversky and D. Kahneman, \"Judgement under uncertainty: heuristics and biases\", Science, 185(4157), pp11241131, 1974.\n[77] H. Varian, \"Position auctions\", International Journal of Industrial Organization, 25, pp1163-1178, 2007.\n[78] A. Vetta, \"Nash equilibria in competitive societies, with applications to facility location, traffic routing and auctions\", Proceedings of 43rd Symposium on Foundations of Computer Science (FOCS), pp416-425, 2002.\n[79] H. Young, \"The evolution of conventions\", Econometrica, 61, pp57-84, 1993.\n[80] H. Young, Strategic learning and its limits, Oxford University Press, 2004.\n\n\f"}