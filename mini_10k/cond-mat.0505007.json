{"id": "http://arxiv.org/abs/cond-mat/0505007v2", "guidislink": true, "updated": "2007-05-04T18:51:59Z", "updated_parsed": [2007, 5, 4, 18, 51, 59, 4, 124, 0], "published": "2005-04-30T04:34:11Z", "published_parsed": [2005, 4, 30, 4, 34, 11, 5, 120, 0], "title": "Eigenfunction Statistics of Complex Systems: A Common Mathematical\n  Formulation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0505202%2Ccond-mat%2F0505720%2Ccond-mat%2F0505300%2Ccond-mat%2F0505709%2Ccond-mat%2F0505111%2Ccond-mat%2F0505186%2Ccond-mat%2F0505114%2Ccond-mat%2F0505582%2Ccond-mat%2F0505457%2Ccond-mat%2F0505341%2Ccond-mat%2F0505134%2Ccond-mat%2F0505193%2Ccond-mat%2F0505129%2Ccond-mat%2F0505588%2Ccond-mat%2F0505179%2Ccond-mat%2F0505500%2Ccond-mat%2F0505019%2Ccond-mat%2F0505222%2Ccond-mat%2F0505245%2Ccond-mat%2F0505388%2Ccond-mat%2F0505221%2Ccond-mat%2F0505369%2Ccond-mat%2F0505208%2Ccond-mat%2F0505026%2Ccond-mat%2F0505680%2Ccond-mat%2F0505315%2Ccond-mat%2F0505147%2Ccond-mat%2F0505033%2Ccond-mat%2F0505162%2Ccond-mat%2F0505167%2Ccond-mat%2F0505516%2Ccond-mat%2F0505699%2Ccond-mat%2F0505301%2Ccond-mat%2F0505334%2Ccond-mat%2F0505078%2Ccond-mat%2F0505376%2Ccond-mat%2F0505171%2Ccond-mat%2F0505677%2Ccond-mat%2F0505337%2Ccond-mat%2F0505038%2Ccond-mat%2F0505592%2Ccond-mat%2F0505655%2Ccond-mat%2F0505436%2Ccond-mat%2F0505007%2Ccond-mat%2F0505660%2Ccond-mat%2F0505531%2Ccond-mat%2F0505069%2Ccond-mat%2F0505644%2Ccond-mat%2F0505373%2Ccond-mat%2F0505717%2Ccond-mat%2F0505068%2Ccond-mat%2F0505063%2Ccond-mat%2F0505753%2Ccond-mat%2F0505180%2Ccond-mat%2F0505224%2Ccond-mat%2F0505054%2Ccond-mat%2F0505358%2Ccond-mat%2F0505206%2Ccond-mat%2F0505735%2Ccond-mat%2F0505659%2Ccond-mat%2F0505725%2Ccond-mat%2F0505601%2Ccond-mat%2F0505030%2Ccond-mat%2F0505131%2Ccond-mat%2F0505656%2Ccond-mat%2F0505490%2Ccond-mat%2F0505466%2Ccond-mat%2F0505460%2Ccond-mat%2F0505628%2Ccond-mat%2F0505276%2Ccond-mat%2F0505409%2Ccond-mat%2F0505480%2Ccond-mat%2F0505708%2Ccond-mat%2F0505483%2Ccond-mat%2F0505482%2Ccond-mat%2F0505232%2Ccond-mat%2F0505145%2Ccond-mat%2F0505379%2Ccond-mat%2F0505771%2Ccond-mat%2F0505138%2Ccond-mat%2F0505303%2Ccond-mat%2F0505110%2Ccond-mat%2F0505204%2Ccond-mat%2F0505252%2Ccond-mat%2F0505198%2Ccond-mat%2F0505405%2Ccond-mat%2F0505441%2Ccond-mat%2F0505501%2Ccond-mat%2F0505641%2Ccond-mat%2F0505478%2Ccond-mat%2F0505576%2Ccond-mat%2F0505537%2Ccond-mat%2F0505634%2Ccond-mat%2F0505310%2Ccond-mat%2F0505624%2Ccond-mat%2F0505052%2Ccond-mat%2F0505324%2Ccond-mat%2F0505589%2Ccond-mat%2F0505097%2Ccond-mat%2F0505130%2Ccond-mat%2F0505263&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Eigenfunction Statistics of Complex Systems: A Common Mathematical\n  Formulation"}, "summary": "We derive a common mathematical formulation for the eigenfunction statistics\nof Hermitian operators, represented by a multi-parametric probability density.\nThe system-information in the formulation enters through two parameters only,\nnamely, system size and the complexity parameter, a function of all system\nparameter including size. The behavior is contrary to the eigenvalue statistics\nwhich is sensitive to complexity parameter only and shows a single parametric\nscaling. The existence of a mathematical formulation, of both eigenfunctions\nand eigenvalues, common to a wide range of complex systems indicates the\npossibility of a similar formulation for many physical properties. This also\nsuggests the possibility to classify them in various universality classes\ndefined by complexity parameter.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0505202%2Ccond-mat%2F0505720%2Ccond-mat%2F0505300%2Ccond-mat%2F0505709%2Ccond-mat%2F0505111%2Ccond-mat%2F0505186%2Ccond-mat%2F0505114%2Ccond-mat%2F0505582%2Ccond-mat%2F0505457%2Ccond-mat%2F0505341%2Ccond-mat%2F0505134%2Ccond-mat%2F0505193%2Ccond-mat%2F0505129%2Ccond-mat%2F0505588%2Ccond-mat%2F0505179%2Ccond-mat%2F0505500%2Ccond-mat%2F0505019%2Ccond-mat%2F0505222%2Ccond-mat%2F0505245%2Ccond-mat%2F0505388%2Ccond-mat%2F0505221%2Ccond-mat%2F0505369%2Ccond-mat%2F0505208%2Ccond-mat%2F0505026%2Ccond-mat%2F0505680%2Ccond-mat%2F0505315%2Ccond-mat%2F0505147%2Ccond-mat%2F0505033%2Ccond-mat%2F0505162%2Ccond-mat%2F0505167%2Ccond-mat%2F0505516%2Ccond-mat%2F0505699%2Ccond-mat%2F0505301%2Ccond-mat%2F0505334%2Ccond-mat%2F0505078%2Ccond-mat%2F0505376%2Ccond-mat%2F0505171%2Ccond-mat%2F0505677%2Ccond-mat%2F0505337%2Ccond-mat%2F0505038%2Ccond-mat%2F0505592%2Ccond-mat%2F0505655%2Ccond-mat%2F0505436%2Ccond-mat%2F0505007%2Ccond-mat%2F0505660%2Ccond-mat%2F0505531%2Ccond-mat%2F0505069%2Ccond-mat%2F0505644%2Ccond-mat%2F0505373%2Ccond-mat%2F0505717%2Ccond-mat%2F0505068%2Ccond-mat%2F0505063%2Ccond-mat%2F0505753%2Ccond-mat%2F0505180%2Ccond-mat%2F0505224%2Ccond-mat%2F0505054%2Ccond-mat%2F0505358%2Ccond-mat%2F0505206%2Ccond-mat%2F0505735%2Ccond-mat%2F0505659%2Ccond-mat%2F0505725%2Ccond-mat%2F0505601%2Ccond-mat%2F0505030%2Ccond-mat%2F0505131%2Ccond-mat%2F0505656%2Ccond-mat%2F0505490%2Ccond-mat%2F0505466%2Ccond-mat%2F0505460%2Ccond-mat%2F0505628%2Ccond-mat%2F0505276%2Ccond-mat%2F0505409%2Ccond-mat%2F0505480%2Ccond-mat%2F0505708%2Ccond-mat%2F0505483%2Ccond-mat%2F0505482%2Ccond-mat%2F0505232%2Ccond-mat%2F0505145%2Ccond-mat%2F0505379%2Ccond-mat%2F0505771%2Ccond-mat%2F0505138%2Ccond-mat%2F0505303%2Ccond-mat%2F0505110%2Ccond-mat%2F0505204%2Ccond-mat%2F0505252%2Ccond-mat%2F0505198%2Ccond-mat%2F0505405%2Ccond-mat%2F0505441%2Ccond-mat%2F0505501%2Ccond-mat%2F0505641%2Ccond-mat%2F0505478%2Ccond-mat%2F0505576%2Ccond-mat%2F0505537%2Ccond-mat%2F0505634%2Ccond-mat%2F0505310%2Ccond-mat%2F0505624%2Ccond-mat%2F0505052%2Ccond-mat%2F0505324%2Ccond-mat%2F0505589%2Ccond-mat%2F0505097%2Ccond-mat%2F0505130%2Ccond-mat%2F0505263&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We derive a common mathematical formulation for the eigenfunction statistics\nof Hermitian operators, represented by a multi-parametric probability density.\nThe system-information in the formulation enters through two parameters only,\nnamely, system size and the complexity parameter, a function of all system\nparameter including size. The behavior is contrary to the eigenvalue statistics\nwhich is sensitive to complexity parameter only and shows a single parametric\nscaling. The existence of a mathematical formulation, of both eigenfunctions\nand eigenvalues, common to a wide range of complex systems indicates the\npossibility of a similar formulation for many physical properties. This also\nsuggests the possibility to classify them in various universality classes\ndefined by complexity parameter."}, "authors": ["Pragya Shukla"], "author_detail": {"name": "Pragya Shukla"}, "author": "Pragya Shukla", "arxiv_comment": "16 Figures, Several Changes, Many new sections and figures included,\n  conclusion slightly changed", "links": [{"href": "http://arxiv.org/abs/cond-mat/0505007v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0505007v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0505007v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0505007v2", "journal_reference": null, "doi": null, "fulltext": "arXiv:cond-mat/0505007v2 [cond-mat.stat-mech] 4 May 2007\n\nEigenfunction Statistics of Complex Systems: A Common Mathematical\nFormulation\nPragya Shukla\nDepartment of Physics, Indian Institute of Technology, Kharagpur, India.\n(Dated: July 7, 2018)\nWe derive a common mathematical formulation for the eigenfunction statistics of Hermitian operators, represented by a multi-parametric probability density. The system-information in the formulation enters through two parameters only, namely, system size and the complexity parameter, a\nfunction of all system parameter including size. The behavior is contrary to the eigenvalue statistics\nwhich is sensitive to complexity parameter only and shows a single parametric scaling.\nThe existence of a mathematical formulation, of both eigenfunctions and eigenvalues, common to\na wide range of complex systems indicates the possibility of a similar formulation for many physical\nproperties. This also suggests the possibility to classify them in various universality classes defined\nby complexity parameter.\nPACS numbers: PACS numbers: 05.45+b, 03.65 sq, 05.40+j\n\nI.\n\nINTRODUCTION\n\nThe eigenfunction correlations of various generators of dynamics contain a wealth of information about the system\ne.g. localized or delocalized nature of the dynamics, decay rate etc. Recently the correlations were shown to be\nrelevant for description of fluctuations of physical properties e.g. conductance in mesoscopic systems, peak-height\nstatistics in coulomb blockade regime of quantum dots [1, 2]. The correlations may vary from level to level or fluctuate\nin different realizations of a complex system. The strong fluctuations of eigenfunctions are already known to be the\nhallmark of many critical point studies e.g. metal-insulator transition in disorder systems [3], spin glass [4], and stock\nmarket fluctuations [5] etc. Recent studies have revealed existence of the fluctuations in a wider range of complex\nsystems e.g. in the area of quantum information, nanotechnology[2] and complex networks etc. [6]. As a consequence,\na detailed information about the eigenfunction statistics of complex systems is very important and desirable.\nDuring recent years, many attempts have been made to statistically formulate the eigenfunction correlations of\ncomplex systems; see, for example, [1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]. One of the main tools used\nin this context is the random matrix approach which can briefly be described as follows (see [8] for details). The\npresence of complicated interactions (among its various sub-units) in the system under investigation often makes it\nimpossible to exactly determine the relevant operator e.g. in a matrix representation. The elements (some or all)\nof the operator in the representation can then be best described by a probability distribution. This permits one to\nreplace the operator by an ensemble of the operators which is supposed to describe the generic properties and is\nreferred as random matrix model of the operator. (In this paper, we focus on systems where complicated interactions,\nof any origin, lead to a partial or full randomization, of the operator, thus, allowing one to use a random matrix\napproach).\nThe choice of an appropriate random matrix model for a system is sensitive to its physical conditions (i.e nature\nand degree of interactions in various sub-units, symmetry and topological conditions, dimensionality etc.). This\nis because the distribution parameters of each matrix element depend on the interactions between related basis\nstates (or parts of the system) which in turn are governed by system-conditions. In past, this has motivated an\nintroduction of a variety of random matrix ensembles as models for a wide range of complex systems e.g. nuclei,\natoms, molecules, disordered and chaotic systems, quantum chromodynamics, elastomechanics, electrodynamics (see\nreviews [1, 8, 9, 20, 22, 23, 24, 26, 27] and references therein for details), mathematical areas such as Riemann\nzeta function, enumeration problems in geometry and fluctuations in random permutations [25], biological systems\n[28], stock markets [5], atmospheric sciences [29] etc [30]. For example, the systems with delocalized wave dynamics\n(extended throughout the system) and antiunitary symmetries can be well modeled by Wigner-Dyson ensembles; the\nlatter are the Hermitian ensembles with Gaussian distributed matrix elements, with ratio of diagonal to off-diagonal\nvariance \u03b1 = 2, (originally introduced by Cartan [31], later developed by Wigner and Dyson to model compound\nnuclei and other systems) [8, 9]. The cases with partially violated anti-unitary symmetries can be well-modeled by\nDyson's Brownian ensembles (BE) [8, 32] (see section VI also). The ensembles with arbitrary \u03b1 (6= 2) [33], banded\n\n\f2\n\nmatrices [23, 34] (elements with non-zero variance within a band around main diagonal) and sparse matrices (with\nmany elements with zero variance) have been successfully used to model statistical properties of the energy levels\nand eigenfunctions of systems with localized wave dynamics (e.g. quasi one dimensional wires and disordered systems\nof higher dimensions, chiral systems) [3, 10, 20, 35, 36]. During last decade, many new ensembles were introduced\nto model the systems with unitary symmetries e.g. block form matrices for the cases with parity violation and precompound nuclei, chiral ensembles for systems with chiral symmetry in quantum chromodynamics [9, 26], C and CI\nensembles for cases with particle/hole structures [9, 37], superconductivity etc [37]. The non-Hermitian operators\ne.g. scattering matrices [1, 8, 27], transfer matrices [27] or correlation matrices (appearing in time-series analysis e.g.\nstock market [5], brain [28], atmospheric studies [29]) can similarly be modeled by circular ensembles [1, 8], Ginibre\nensembles [38] and their more generic forms [39, 40]. (The breadth of the subject is such that it is not possible to\ngive a detailed account of all ensembles or include all references here).\nThe applicability of random matrix ensembles to complex systems has been under investigation for past few decades.\nThe validity of the models, however, has been extensively verified in context of the eigenvalue fluctuation only; see\nreviews [1, 8, 9, 20, 22, 26, 28, 29, 41, 42, 43] and references therein. The validity in the domain of eigenfunction\nfluctuations is so far mostly studied either in ergodic regime of the wavefunctions (see [1, 9, 12, 13, 14, 16, 17, 18, 19, 44]\nfor some original papers and reviews) or for quasi 1-d systems [10] and specific cases e.g. disordered systems [3]. The\ngrowing technological demands as well as the observations of hitherto unknown features among eigenfunctions (e.g.\nmultifractal structures at critical points) of a wide range of complex systems (for example, see [3, 4, 35, 45, 46])\nhave made it imperative to seek the statistical information in higher dimensions and beyond ergodic regime. This\nmotivates us to pursue the present study. It is also desirable to explore the possibilities of any connection among\nthe critical point behavior of the eigenfunctions of different complex systems. One way to show the connection is by\ndescribing their various measures by a common mathematical formulation if possible. A recent study [49, 50, 51],\nhas shown the existence of a similar formulation for the case of level-statistics where system information enters\nthrough a single parameter, basically a function of all system parameters. The well-known connection between the\nstatistics of eigenfunctions and eigenvalues in non-ergodic regime [3] motivates us to seek a similar formulation for\nthe eigenfunctions too. Such a formulation can also be useful in deriving the measure of one complex system from\nanother.\nThe paper is organized as follows. The section II contains a brief revision of the single parametric formulation of\nthe multi-parametric probability density of matrix elements for a wide range of complex systems (see [49] for details).\nThe section III describes the derivation of the complexity parameter governed diffusion equation for the eigenfunction\ncomponents (of the same eigenfunction or different ones) which is used in section IV to study the distribution of some\nof the important fluctuation measures. The other measures can also be derived following the same route. Although,\nthe diffusion approach seems to complicate the calculation by introducing a dependence on the initial conditions,\nhowever, as discussed in section IV, the statistics of the system can be recovered by integrating over all physically\nallowed initial conditions. The approach has an extra advantage: it provides a common analytical base for the\nsystems which can be modeled by our ensemble (given below by eq.(1,2)) The section IV briefly discusses the role of\ncomplexity parameter in various transitions induced due to change in system-specifics. The section V contains details\nof the numerical verification of our analytical claims. We conclude in section VI by summarizing our main results and\ntheir potential applications.\nII.\n\nSINGLE PARAMETRIC FORMULATION OF THE MATRIX ELEMENTS PROBABILITY DENSITY\n\nThe eigenvalues and eigenfunctions of an operator, say H, of a system can be obtained by solving the eigenvalue\nequation HUi = \u03bbi Ui (with Ui and \u03bbi as the eigenfunction and corresponding eigenvalue respectively) and any other\nphysical information can then be deduced, in principle, from this knowledge. In the case of a complex system, however,\nthe exact form of an operator e.g Hamiltonian may not be known or it may be far too complicated to solve. To deal\nwith such a situation, one has to make a statistical hypotheses, known as maximum entropy hypothesis, for H [47]:\na sufficiently complicated system can be described by a matrix which is as random as possible under the conditions\ncompatible with the nature of the dynamics as well as the symmetry requirements. Thus if the symmetries and the\nnature of the operation is approximately known in a basis space preserving the symmetries, it can be modeled by an\nensemble of full or sparse random matrices in that basis. For example, an equal probability of dynamics in each region\nof a specific space suggests a uniform spread of the eigenfunctions\nin the entire associated basis space. The operator\nP\nin such a basis will therefore be a full matrix, hk|H|li = i \u03bbi Uki Uli being of the same order for all combinations of\n\n\f3\n\nbasis vectors |ki, |li (with Uki as the k th component of eigenvector Ui ). On the other hand, the dynamics localized\nin a space leads to variation of the eigenfunction intensities in the associated basis and the operator will be a sparse\nmatrix.\nIt is clear from the above that, contrary to eigenvalues, the eigenfunction statistics depends on the basis in which\nthe matrix is represented. The knowledge however is still relevant because (i) it can provide important information\nabout the system dynamics in a given basis-space of interest, (ii) it is also possible to define a relevant basis to\nrepresent an operator: it is the basis in which the constraints on the operator appear in a natural way. For example,\nfor the time-reversal invariant systems with integer angular momentum, the relevant basis is the one in which their\nHamiltonians are simultaneously expressed as real-symmetric matrices [24].\nIn this paper, we consider a prototype distribution which can model a wide range of complex systems, namely, an\nensemble of Hermitian matrices H, each of size N , described by a Gaussian probability density\n\n\u03c1(H, h, b) = Cexp[\u2212\n\n\u03b2\nX\n\nN\nX\n\ns=1 k,l=1;k\u2264l\n\n(1/2hkl;s ).(Hkl;s \u2212 bkl;s )2 ]\n\n(1)\n\nHere |ki, |li are unit vectors of the arbitrary basis of size N , chosen to represent H with Hkl \u2261 hk|H|li. The subscript\n\"s\" refers to the components of Hkl , \u03b2 as their total number (\u03b2 = 1 for real variable, \u03b2 = 2 for the complex one),\n2\nC as the normalization constant, h as the variance matrix with hkl;s = hHkl;s\ni and b as the mean value matrix\nwith hHkl;s i = bkl;s . Our choice of Hermitian nature of the ensemble restricts the present discussion to the class of\nsystems with conservative dynamics. Following maximum entropy hypothesis, the above ensemble can well-describe\nthe distribution of the operators for which the average behavior of the matrix elements and their variances is known.\nBased on the complexity of the system, the elements of the parametric matrices h, b can have various functional forms\ne.g. exponential, power law etc. For example, the limit hkl;s \u2192 0, corresponds to non-random nature of Hkl . The\n2\nlimit hkl;s \u2192 \u03b3, bkl;s \u2192 0 for all {k, l, s} gives the density for a Wigner-Dyson ensemble [8]: \u03c1(H) \u221d e\u2212TrH . The\nlimit hkl;s \u2192 [\u03b1d \u03b4kl + \u03b1o (1 \u2212 \u03b4kl )], bkl;s \u2192 0 for all {k, l, s} gives the density for a Rosenzweig-Porter ensemble [33];\n(note Brownian ensembles have the same density-form too, see section VI). A band matrix ensemble [10, 20, 23, 34]\nwith Gaussian distributed matrix elements and band length t can be obtained by substituting hkl;s \u2192 0, bkl;s \u2192 0 if\n|k \u2212 l| > t and hkl;s \u221d a(|k \u2212 l|) for |k \u2212 l| \u2264 t with various possible forms of function a e.g. exponential, rectangular\netc. Similarly other ensembles with uncorrelated matrix elements, some of them with Gaussian randomness and others\nnon-random, can be represented by appropriate choice of h and b parameters [50].\nThe eq.(1) is applicable for the cases with mutually independent matrix elements, with no condition imposed on\ntheir moments higher than 2nd order. Here we briefly mention only two such cases, namely, disordered systems and\nmixed dynamical systems; (the application to other cases e.g. algebraic or algorithmic complexity [55] will be discussed\nelsewhere). During recent past, specific cases of eq.(1) have been extensively used to model the energy level statistics\nof disordered system within independent electron approximation; (the latter results in independent matrix elements\nof the Hamiltonian). One such example is the power law random banded matrix (PRBM) ensemble (each hkl with\na power law dependence on the distance from the diagonal) [34] which has been shown to be a good model for the\nlevel-statistics of Anderson Hamiltonian (AH) [3]. The ensemble (1) was also used recently to prove, analytically as\nwell as numerically, the single parameter scaling of the level-statistics of Anderson Hamiltonian and its mapping to\nsingle parametric Brownian ensembles [50]. (Later, in this paper, AH, BE and PRBM cases are also used to verify\nour analytical predictions for the eigenfunction statistics).\nAnother potential application of eq.(1) is to systems with mixed dynamics where, similar to disorder, KAM tori lead\nto a localization of dynamics [48]. The connection of quantum systems in classically chaotic and integrable regime\nto Wigner-Dyson ensembles and Poisson ensembles, respectively, is already well-established [24, 41, 52, 53]. In past,\nit has been suggested that a mixed Hamiltonian (or time-evolution operator) in a relevant basis should appear as a\nblock diagonal matrix, each block being associated with an isolated region of the classical phase space [24, 52, 54].\nIn cases, where a chaotic region can be decomposed in nearly, but not completely isolated subregions, blocks are\nexpected to be connected through small but non-zero matrix elements. The average size of these matrix elements i.e\nthe quantum constraints will be related to flux connecting different regions i.e to classical information. We further\nsuggest that the regimes with stable islands can be modeled by the blocks with non-random elements (e.g. zero\nvariance and non-zero mean). The chaotic regimes can be modeled by blocks with randomly distributed elements\n(e.g. same non-zero variance for all elements or only within a band). Based on nature of the dynamics, a chaotic block\nmay further contain hierarchy of random and non-random sub-blocks; various diagonal blocks may also be correlated.\n\n\f4\n\nEq.(1) can then be applied to model the Hamiltonian by choosing the matrix element variances appropriate to the\nblock in which they appear.\nEq.(1) can not serve as a good model for the cases with correlated matrix elements. For example, particle-particle\ninteractions in nuclei [1, 7, 21, 22] and electron-electron interaction in disordered systems can lead to correlations\namong elements of the Hamiltonian [1, 51]; the correlation coefficients depend on various system parameters. In\ngeneral, such cases can occur when the interaction (described by H) between any two basis states is influenced by\nthe other states. In past, consideration of particle correlations in nuclei led to introduction of embedded ensembles\n[7, 9, 21]; however no significant progress has been made so far in dealing analytically with these ensembles.\nIn general, an increase of constraints on the system-dynamics subjects higher moments of the matrix elements to\ncertain specific conditions. This motivates us to consider an alternative ensemble, namely, maximum entropy ensemble\nwith restricted higher moments. Within maximum entropy hypothesis, the probability density for such cases turns\nout to be non-Gaussian [51]: \u03c1\u0303(H) = C\u03c1(H) where\n\uf8f9\n\uf8ee\n\u0013\n\u0012Y\n\u03b2 Y\nn\nY\nX\nr\nHip jp ;s \uf8fb\n(2)\nbp(r)\nexp \uf8f0\u2212\n\u03c1(H) =\ns=1 r=1\n\np(r)\n\nip jp\n\nwith C as a normalization constant. Here each Hjk is expressed in terms of its \u03b2 components, (\u03b2 = 1 for the realP\nsymmetric matrices and \u03b2 = 2 for the complex Hermitian case): Hjk \u2261 \u03b2s=1 (i)s\u22121 Hjk;s . Here symbol p(r) refers to\na combination of r matrix elements chosen from Q\na set of total M\u0303 = N (N + 1)/2 of them; note the terms present in a\ngiven combination need not be all different. The r ip jp implies a product over r terms present in the pth combination\nQ\nP\nwith coefficient bp(r) as a measure of their correlation: h r ip ,jp Hip jp ;s i = \u2202logC\np(r) is a sum over all possible\n\u2202bp(r) . The\n\ncombinations (total (M\u0303 )r ) of r elements chosen from a set of total M\u0303 = N (N + 1)/2 of them.\nThe potential use of eq.(2) to disordered systems with e-e interaction is discussed in [51]. Here we briefly discuss\nfew more examples.\nThe systems\nwith chiral symmetry can be modeled by Hermitian ensembles with block form\n\u0013\n\u0012\n0\nW\n\u2217\n, with W as a matrix of size N . Here, due to Hk\u2032 ,l = Hl,k\nmatrices H =\n\u2032 for 1 \u2265 k, l \u2265 N (with\nW+ 0\n\u2032\n\u2032\nk \u2261 k + N, l \u2261 l + N ), the correlations between these elements are subjected to condition:\nhHk\u2032 ,l Hl,k\u2032 i = h|Hk\u2032 ,l |2 i = h|Hl,k\u2032 |2 i,\nhHk,l i = hHk\u2032 ,l\u2032 i\n\n(3)\n\nHowever, due to Hk,l = Hk\u2032 ,l\u2032 = 0, all other matrix elements are uncorrelated. For a simple explanation, let us restrict\nto a case of real matrix W with Gaussian distributed elements. The ensemble can then be represented by eq.(2) with\nn = 2 or equivalently by density,\n\uf8ee\n\uf8f9\nX\nX\n\u03c1(H, a, b) = Cexp \uf8f0\u2212\nbijkl Hij Hkl \u2212\nakl Hkl \uf8fb ,\n(4)\ni\u2264j,k\u2264l\n\nkl\n\nwith following conditions on a and b:\n\nbk\u2032 ,l,l,k\u2032 = bk\u2032 ,l,k\u2032 ,l = bl,k\u2032 ,l,k\u2032 ,\nak\u2032 ,l = al,k\u2032 ,\nakl = ak\u2032 ,l\u2032 = 0,\n\n(5)\n\nNote, b parameters corresponding to other pairs of elements (both or at least one in diagonal blocks) diverge due\nto zero correlation between elements in such pairs. The cases with other types of correlated blocks can similarly be\nmodeled by applying appropriate conditions on the b parameters which correspond to combinations of matrix elements\nappearing in opposite\n\u0013 example, the ensemble C describes the cases with particle-hole symmetry with a\n\u0012 blocks. For\nA\nB\n([37] for details). Now the correlations between various elements must be subjected\nHamiltonian H =\nB + \u2212AT\n\u2217\nto conditions Hk\u2032 ,l = Hl,k\n\u2032 , Hk,l = \u2212Hl\u2032 ,k\u2032 ; this implies another set of non-zero correlations (besides those given by\neq.(3)): hHk,l Hl\u2032 ,k\u2032 i = \u2212h|Hk,l |2 i = \u2212h|Hl\u2032 ,k\u2032 |2 i. For Gaussian distributed real matrices A and B, the case can again\n\n\f5\n\nbe modeled by eq.(4) however now b parameters for other pairs (besides those given in eq.(5)) can also be finite and\nsatisfy the equality: (i)\u03b1bk,l,l\u2032 ,k\u2032 = bk,l,k,l = bl\u2032 ,k\u2032 ,l\u2032 ,k\u2032 ; (ii)bk,l,k\u2032 ,l = bk,l,l,k\u2032 = alphabl\u2032 ,k\u2032 ,l,k\u2032 = \u03b1bl\u2032 ,k\u2032 ,k\u2032 ,l with \u03b1 = \u22121.\nRecently it was shown [49, 51] that the distribution \u03c1 for both cases (eqs.(1,2)) appear as the non-equilibrium\nstages of a Brownian type diffusion process in the matrix-space, evolving with respect to a single parameter which is\na function of the distribution parameters of the ensemble: ...\n\u2202\u03c1\n= L+ \u03c1\n\u2202Y\n\n(6)\n\nwith\nL\u00b1 =\n\nX\n\nk,l;s\n\n\u0015\n\u0014\n\u2202\ngkl \u2202\n\u00b1 \u03b3Hkl;s\n\u2202Hkl;s 2 \u2202Hkl;s\n\n(7)\n\nwhere gkl = 1 + \u03b4kl . The variable Y is the parameter governing the evolution of matrix elements subjected to various\nsystem conditions. For case (1),\n\uf8ee \u2032\n\uf8f9\n\u03b2\nYY\n1\nY =\u2212\nln \uf8f0\n(8)\n|xkl;s | |bkl;s |2 \uf8fb + C0\n2M \u03b3\ns=1\nk\u2264l\n\nQ\u2032\n\nimplying a product over non-zero bkl;s and xkl;s = 1 \u2212 (2 \u2212 \u03b4kl )\u03b3hkl;s , C0 as a constant determined by the\nwith\ninitial distribution, M as the number of all non-zero parameters xkl;s and bkl;s . The parameter \u03b3 is arbitrary, giving\nthe freedom to choose the end of the evolution; the limhkl;s \u2192 \u03b3, bkl;s \u2192 0 for all k, l gives Y \u2192 \u221e and the steady\nstate (a Wigner-Dyson ensemble). The distribution parameters being indicators of the complexity of the system, Y\ncan be termed as the complexity parameter [49]. Some examples of the calculation of Y from eq.(8) are discussed in\n[49] (for banded ensembles) and in [50] (for Anderson Hamiltonian). The Y in case of a mixed system can similarly\nbe calculated if one knows the details of the mixed dynamics.\nIn general, the form of parameter Y for eq.(2) is quite complicated; its details can be found in [51]. However, for\ncase (4), that is the Gaussian version of case (2), Y can be given as\nXZ\nXZ\nY =\ndakl X +\ndbijkl X + constant\n(9)\nkl\n\nijkl\n\nP\nP\nwhere summation is implied over the distribution parameters with finite values only, and, X = [ kl fkl + ijkl fijkl ]\u22121\nP\nP\nwith fkl = \u03b3akl \u2212 2[ mn anm bklmn + amn bklnm ], fijkl = [\u03b3bijkl \u2212 2 mn bijnm bklmn ]. For further clarification we refer\nthe reader to [51] where an example, namely, the modelling of lowest Landau level of a disordered quantum Hall\nsystem by eq.(4) and calculation of corresponding Y is discussed.\nIt is easy to solve eq.(6) for arbitrary initial condition, say H0 at Y = Y0 ,: \u03c1(H, Y |H0 , Y0 ) \u221d exp[\u2212(\u03b1/2)Tr(H \u2212\n\u03b7H0 )2 ] with \u03b1 = \u03b3(1 \u2212 \u03b7 2 )\u22121 and \u03b7 = e\u2212\u03b3Y . The\nR probability density of H can now be extracted by integrating over an\nensemble of initial conditions: \u03c1(H, Y \u2212 Y0 ) = \u03c1(H, Y |H0 , Y0 )\u03c1(H0 , Y0 )dH0 . It is often useful to study the statistics\nof the perturbed Hamiltonian H in the eigenfunction basis of unperturbed Hamiltonian H0 . Thus if the eigenfunctions\nP 2\nof H0 are chosen as the basis vectors |ki, |li etc, and, the initial distribution is given by \u03c1(H0 ) \u221d exp[\u2212(1/2) j H0;jj\n],\nthe eigenvalue equation U H = \u039bU can be used to transform \u03c1(H) from matrix space to eigenvalue-eigenvector space\n{\u03bb, U }:\n\uf8f9\n\uf8ee\nN\nN\nX\nY\nX\n(10)\n\u03bb2j \u2212 (\u03b3\u03bc/2)\n|\u03bbk \u2212 \u03bbl |2 |Ujk |2 |Ujl |2 \uf8fb\n\u03c1(H, Y ) \u221d\n|\u03bbk \u2212 \u03bbl |\u03b2 exp \uf8f0\u2212(\u03b3/2)\nk,l;k<l\n\nj=1\n\nk<l\n\nwhere \u03bc = [e2\u03b3(Y \u2212Y0 ) \u2212 1]\u22121 .\nAs indicated by eqs.(6) and (10), the ensemble densities for various complex systems (i.e. different h, b matrices)\nundergo a similar evolution as a function of Y . The Y -governed flow for the joint distribution of the desired eigenfunctions components and eigenvalues can be obtained, in principle, by integrating either eq.(6) or eq.(10) over all the\nundesired ones; however it is easier to integrate eq.(6). To explain the technique, we consider some of the important\ncases in this paper.\n\n\f6\n\nIII.\n\nDIFFUSION EQUATION FOR EIGENFUNCTION COMPONENTS AND RELATED\nEIGENVALUES\n\nThe k th component Ukl of an eigenstate Ul is a measure of the contribution of k th basis state to the eigenstate.\nExperimental observations of complex systems indicate the level to level variations as well as sample to sample\nfluctuations of the contribution. As a result, the knowledge of average behavior of the components is not enough and\none needs to study their distribution. In this section, we consider the joint probability distributions of a few relevant\ncombinations of the components of the operator H. The basis chosen for the representation of the eigenfunctions\nis the one in which the matrix elements of H have distribution (1) (or (2)). We use following notation in reference\nto various correlations: For a joint distribution Prs , the subscripts r and s refer to the number of components of\neach eigenvector and the number of eigenvectors considered, respectively. For example, for a joint distribution of n\ncomponents of m eigenvectors along with their eigenvalues, r = n and s = m.\nA.\n\nJoint Distribution of a Given Component of All Eigenfunctions and Eigenvalues\n\nIt is often relevant to know the influence of a particular basis state on the system dynamics at various energies\nand with varying complexity of the system. The information can be obtained by a knowledge of the distribution\nof the same component of various eigenfunctions and its Y governed evolution. For example, let us calculate the\njoint distribution of a given component of all eigenvectors and the eigenvalues. Let P1N (Z, E, Y ) be the probability,\nat a given Y , of finding the j th component Ujn of the eigenfunctions Un of H between zjn and zjn + dzjn and the\neigenvalues \u03bbn between en and en + den for n = 1 \u2192 N (with Z \u2261 {zjn }, E \u2261 {en }) . It can be expressed as an\naverage over entire ensemble \u03c1:\n\nP1N (Z, E, Y ) =\n\nZ\n\nfN (Z, E, U, \u03bb) \u03c1(H, Y ) dH\n\n(11)\n\nQr\n\u2217\n\u2217\n\u2212 Ujn\n)\u03b4(en \u2212 \u03bbn ). The Y dependent evolution equation for P1N\nwith fr (Z, E, U, \u03bb) = n=1 \u03b4(zjn \u2212 Ujn )\u03b4 \u03b2\u22121 (zjn\ncan now be derived by connecting the parametric derivatives of P1N to its derivatives with respect to eigenvectors.\nThe steps can briefly be described as follows: As Y -dependence of P1N comes only through \u03c1, one can write\nZ\nZ\n\u2202P1N\n= dHfN L+ \u03c1 = dH\u03c1 L\u2212 fN + \u03b3\u0303P1N\n(12)\n\u2202Y\nwith \u03b3\u0303 = \u03b2N (N + 1)\u03b3/2. Eq.(12) is obtained, first, by differentiating eq.(11) with respect to Y , then using eq.(6),\nfollowed by partial integration. Due to \u03b4-function nature of fN , its derivatives with respect to matrix elements can\nfurther be reduced to the derivatives with respect to Z and E,\n\"\n#\nN\n\u2217\nX\n\u2202Ujn\n\u2202\u03bbn \u2202fN\n\u2202Ujn \u2202fN\n\u2202fN\n\u2202fN\n=\u2212\n+\n+\n\u2217\n\u2202Hkl;s\n\u2202Hkl;s \u2202en\n\u2202Hkl;s \u2202zjn\n\u2202Hkl;s \u2202zjn\nn=1\n\n(13)\n\nThe 2nd derivative of fN can now be obtained from eq.(13) (see [49]). The substitution of eq.(13) in eq.(12) helps as\nthe derivatives with respect to zjn and en can be taken out of the integral. It can further be simplified by a knowledge\nof the effect of a small perturbation of H on its eigenvalues and eigenvectors; the related results are given in Appendix\nB (see [49] for the details). Using the relations, eq.(12) can be rewritten as\n\u2202P\n= (LZ + L\u2217Z ) P + LE P\n\u2202Y\nwhere P = C1 P1N , C1 = e\u2212\u03b3\u0303Y , and\n\n(14)\n\n\f7\n\nLZ\n\nLE\n\nN\nX\n\n#\n\u2202\n\u2202\n2\nzjn zjm + zjn ,\n\u2217 |zjm | \u2212 \u2202z\n\u2202zjn\njm\nn,m=1;n6=m\n\uf8ee\n\uf8f9\nX \u2202\nX\n\u2202\n\u03b2\n\uf8f0\u03b3en +\n\uf8fb.\n=\n+\n\u2202e\ne\n\u2212\ne\n\u2202e\nn\nm\nn\nn\nn\n\n\u03b22\n=\n4\n\n\u2202\n1\n(en \u2212 em )2 \u2202zjn\n\n\"\n\n(15)\n\nm;m6=n\n\nwhere L\u2217Z implies the complex conjugate of LZ ; note LZ = L\u2217Z for \u03b2 = 1 case. Eq.(14) describes the Y -governed\ndiffusion of a given component of all eigenvectors and all eigenvalues. Its P\nsolution depends on the choice of initial\n\u2212(1/2)\n\nH2\n\n0;jj\nj\ncondition H0 . In the diagonal representation of H0 (taking \u03c1(H0 ) \u221d e\n, the solution can be given as\n\uf8f9\n\uf8ee\nN\nN\nX\nY\nX\ne2j \u2212 (\u03bc/2)\n(16)\n|en \u2212 em |2 |Ujn |2 |Ujm |2 \uf8fb\nP1N \u221d\n|ek \u2212 el |\u03b2 exp \uf8f0\u2212(1/2)\n\nm<n\n\nj=1\n\nk,l;k<l\n\nwith \u03bc same as in eq.(10). (Note, the above result can directly be obtained from eq.(10) too).\nB.\n\nJoint Distribution of all Components of A given Eigenfunction and its Eigenvalue\n\nThe distribution of the components of a specific eigenstate contains information about various basis states contributing to the state which in turn determines its spread. Proceeding along the same lines as for P1N , the diffusion\nequation for the joint probability PN 1 of the components Unk , n = 1 \u2192 N , of an eigenvector Uk and the corresponding\neigenvalue \u03bbk can also be obtained. The evolution of\nPN 1 (Zk , ek , Y ) =\n\nZ\n\nf \u0303k \u03c1(H, Y ) dH,\n\n(17)\n\nwith f \u0303k = \u03b4(Zk \u2212 Uk )\u03b4 \u03b2\u22121 (Zk\u2217 \u2212 Uk\u2217 )\u03b4(ek \u2212 \u03bbk ), can again be shown to be described by\n\u2202PN 1\n= Fk + Fk\u2217 + Lek PN 1\n\u2202Y\nwhere Fk = (\u03b2 2 /4)\n\nP2\n\nq=1\n\n(18)\n\nLqk with\nL1k =\n\n\u0003\n\u2202 \u0002\nznk Q02\nnn;k\n\u2202znk\nn=1\nN\nX\n\n\u22022\n12\n\u2217 Qmn;k ,\n\u2202z\n\u2202z\nnk\nmk\nm,n=1\n\u0015\n\u0014\n\u2202\n\u2202P\n01\n=\n+ \u03b2Qnn;k\n\u03b3ek P +\n\u2202ek\n\u2202ek\n\nL2k =\nLek PN 1\n\nN\nX\n\n(19)\n\nand\nQrs\nmn;k =\n\n\u2217 r\nX Z (znj zmj\n)\nPN 2 d\u03c4j .\n(ek \u2212 ej )s\n\n(20)\n\nj;j6=k\n\nHere d\u03c4j \u2261 dej d\u03b2 Zj with d\u03b2 Z \u2261 dZdZ \u2217 and PN 2 = PN 2 (Zk , Zj , ek , ej ) is the joint probability of all components of\nthe two eigenvectors Zj \u2261 {znj } and Zk \u2261 {znk } (n = 1 \u2192 N ) alongwith their eigenvalues ej and ek , respectively:\nZ\n(21)\nf \u0303k f \u0303j \u03c1(H, Y ) dH.\nPN 2 =\n\n\f8\n\nThe presence of eigenvalue-eigenfunction correlations in exponent of \u03c1(H) (e.g. eq.(10)) as well as the terms of type\n(ej \u2212 ek )\u22122 in the denominator of eq.(20) makes it difficult to write Fk (in eq.(18)) as a function of PN 1 (Zk , ek ). To\nwrite eq.(18) in a closed form, it is necessary to approximate Qrs\nmn;k (Appendix A):\n\u2212s\n1\u2212r s/2\n\u2217\nQrs\n\u03c7 [\u03b4mn \u2212 zmk\nznk ]r PN 1\nmn;k \u2248 Dk (N \u2212 1)\n\n(22)\n\nwith Dk as the local mean level spacing at energy ek . Here \u03c7 = 1 for \u03bc < \u03b6kd , \u03c7 \u223c (\u03bc/\u03b6kd ) for \u03bc > \u03b6kd with \u03b6 as the\nensemble averaged localization length of the eigenfunction Uk and d as the system-dimension. The length \u03b6 enters in\nthe formulation due to its relation with typical intensity of a wavefunction: |Unk |2 \u2261 |znk |2 \u223c \u03b6k\u2212d\nThe substitution of eq.(22) in eq.(19) helps to write Fk in terms of PN 1 , thus reducing the evolution equation (18)\nfor PN 1 in a closed form:\n\nFk\n\n#\n\"\nN\nX \u2202h2\n\u03b22 X \u2202\n=\n+ h1\n\u2217\n4D2 n=1 \u2202znk m \u2202zmk\n\n(23)\n\n\u2217\nwith h1 = (N \u2212 1)\u03c7znk PN 1 , h2 = \u03c7(\u03b4mn \u2212 znk zmk\n)PN 1 .\n\nC.\n\nJoint Distribution of all components of q Eigenfunctions and their eigenvalues\n\nFor certain physical properties e.g susceptibility, a knowledge of the correlations among two (or more) eigenvectors\nat two different space points may be required. The fluctuations of such correlations can be determined by the joint\nprobability density PN q of the components Unk (n = 1 \u2192 N ) of q eigenvectors Uk (k = 1 \u2192 q) where\nPN q (Z1 , Z2 , ..Zq , Y ) =\n\nZ Y\nq\n\nf \u0303k \u03c1(H, Y ) dH,\n\n(24)\n\nk=1\n\nProceeding exactly as in previous two cases, the Y -governed diffusion of PN q can be shown to be described as\nq h\ni\nX\n\u2202PN q\n=\nF\u0303k + F\u0303k\u2217 + Lek PN q\n\u2202Y\n\n(25)\n\nk=1\n\nwhere\nF\u0303k\n\nq\n\u03b22 X\n= Fk +\n4\n\nl=1;6=k\n\nN\nX\n\n\u0015\n\u0014\n\u22022\nznk zml\nPN q .\n\u2202znk \u2202zml (ek \u2212 el )2\nm,n=1\n\n(26)\n\nNote although Fk , L1k , L2k are still defined as in eqs.(18, 19) however the definition of Q is now slightly altered\nwith PN (q+1) replacing PN 2 in eq.(20). Here PN (q+1) is the joint probability density of q + 1 eigenfunctions, namely,\nZ1 , Z2 , .., Zq alongwith Zj (with j > q). Similar to previous case, the integral Q can again be approximated so as to\nPq\n\u2212s\n1\u2212r s/2\n\u2217\nexpress Fk in terms of PN q : Qrs\n\u03c7 [\u03b4mn \u2212 l=1 zml\nznl ]r PN q . Here again \u03c7 = 1 for \u03bc < \u03b6kd and\nmn;k \u2248 Dk (N \u2212 1)\nd\nd\n\u03c7 \u223c (\u03bc/\u03b6 ) for \u03bc > \u03b6k .\nThe above approximation for Q leaves the expression for Fk in the same form as in eq.(23) however now h1 =\nP\n\u2217\n\u03c7(N \u2212 1)PN q , and, h2 = \u03c7(\u03b4mn \u2212 ql=1 zml\nznl )PN q . The substitution of Fk in F\u0303k gives the latter as a function of PN q\nwhich in turn reduces eq.(26) in a closed form for PN q . The equation can then be used, by integrating over undesired\ncomponents, to obtain the distributions of various combinations of eigenfunction components.\n\n\f9\n\nIV.\n\nDIFFUSION EQUATION FOR FLUCTUATION MEASURES OF EIGENFUNCTIONS\n\nThe ensemble average of any measure of the eigenfunction correlations can be expressed in terms of P ( P \u221d Prq\nfor a correlation function of r components of q eigenstates). For example, the average of a measure, say C, describing\nthe correlation among a set X of eigenfunction components can be written as\nZ \u221e\nhC(X; Y )i =\nC(X; Y )P (X; Y )dX.\n(27)\n0\n\nwhere h.i denotes an averaging over various realizations of the sample. However the strength of the reproducible\nfluctuations of the correlations in different realizations of same complex system is of the order of the averages. As a\nconsequence, a knowledge of just the averages is not enough and it is necessary to know the distributions of correlations.\nThe Y -governed evolution of the distribution PC of a measure C can be obtained by an integration of the undesired\nvariables in eq.(14) (or eq.(18), eq.(25) as per requirement). As examples, we derive the evolution equations for few\nimportant measures in this section. The involved integrals are, however, quite tedious and analytical approximations\nseem necessary to reduce the equation in a closed form. As a check on our results, we study the Y \u2192 \u221e limit of\neach measure. This limit corresponds to the flow of ensemble (1) (and ensemble (2)) to its steady state, that is, a\nWigner-Dyson Ensemble. As a consequence, each measure is expected to evolve to its Wigner-Dyson limit as Y \u2192 \u221e.\nWe verify our results numerically too; the details are given in section VI.\nA.\n\nDistribution of Local Eigenfunction Intensity\n\nThe distribution function of the local eigenfunction intensity i.e. the eigenfunction intensity u at a given basis state,\nPN\nsay n can be defined as Pu (u, e) = h k=1 \u03b4(u \u2212 N |znk |2 )\u03b4(e \u2212 ek )i. The diffusion of Pu as a function of \u039b can be\nobtained from either eq.(14) with P \u221d P1N or eq.(18). For technical simplification, however, we choose the former\nand first study the evolution of the distribution P11 (x, e) of an eigenfunction component x = N 1/2 znk = (u1/2 ) at an\nenergy e, defined as\nZ\nP11 (x, x\u2217 , e) = h\u03b4x\u03b2 \u03b4e i = \u03b4x\u03b2 \u03b4e P1N (Z, E, Y ) dE d\u03b2 Z\n(28)\n\n\u221a\n\u221a \u2217\nwhere \u03b4x\u03b2 = \u03b4(x \u2212 N znk )\u03b4 \u03b2\u22121 (x\u2217 \u2212 N znk\n) and \u03b4e = \u03b4(e \u2212 ek ) and d\u03c4 \u2261 dEd\u03b2 Z. The diffusion equation for P11 (x, e)\ncan be obtained by integrating eq.(14), with P \u221d P1N , over the variables ej and znj , j = 1 \u2192 N ,\n\u0014 2\n\u0015\n\u2202P11\n\u2202 G1\n\u03b22\n\u2202(xG0 ) \u2202(x\u2217 G0 )\n2\n+ Le P11\n=\n+\n+\n\u2202Y\n4\n\u2202x\u2202x\u2217\n\u2202x\n\u2202x\u2217\n\n(29)\n\nwhere\n\nGr (x, e) \u2261\n\nX Z\n\nj;j6=k\n\n\u03b4x\u03b2 \u03b4e\n\n|znj |2r\nP1N d\u03c4,\n(ek \u2212 ej )2\n\n(30)\n\nR\nwith r = 0, 1 and \u03b4x\u03b2 \u03b4e [LE P1N ] dE d\u03b2 Z = Le P11 .\nEq.(29) describes the sensitivity of the local intensity distribution to the energy scale e as well as various system\nparameters. As discussed in appendix A (see eq.(A7)), Gr can be approximated as\nGr \u2248 \u03bc\u03c70 (N \u2212 1)1\u2212r (N \u2212 |x|2 )r P11 (x)/Dk2\n\n(31)\n\nwith \u03c70 = \u03bc\u22121 for \u03bc|x|2 < 1 and \u03c70 \u223c |x|2 for \u03bc|x|2 > 1 where \u03bc = [e2\u03b3(Y \u2212Y0 ) \u2212 1]\u22121 and Dk as the local mean level\nspacing at energy ek . A substitution Rof approximated Gr in eq.(29) and an integration over e gives the energy-averaged\nlocal intensity distribution Px (x) = P11 (x, e)de:\n\n\f10\n\n\u0014\n\u0015\n\u2202Px\n\u03b2 2 \u2202 2 [h2 (x)Px ] \u2202[h1 (x)Px ] \u2202[h1 (x\u2217 )Px ]\n2\n=\n+\n+\n\u2202\u039bu\n4\n\u2202x\u2202x\u2217\n\u2202x\n\u2202x\u2217\n\n(32)\n\nwith h2 (x) = \u03c70 (N \u2212 x2 ), h1 (x) = \u03c70 (N \u2212 1)x. Here \u039bu = \u03bc\u039b with \u039b = (Y \u2212 Y0 )/Dk2 . Eq.(32) suggests that the\nevolution of Px is governed by a rescaled parameter \u039bu instead of Y .\n2\n2\nFor cases |x|2 << N (thus \u039bu = \u039b), the above equation can easily be solved: Px (x, \u039b|x0 ) \u221d e\u2212\u03b2|x\u2212\u03b3x0| /2(1\u2212\u03b3 )\nx\nwith \u03b3 = e\u2212\u03b2N \u039b/2 and Px0 (x0 ) as the initial distribution. The steady state limit \u2202P\n\u2202\u039b \u2192 0 of eq.(32) occurs at\n2\n\u039b \u2192 \u221e. The solution in this limit corresponds to Wigner-Dyson case i.e. Px (x, \u039b \u2192 \u221e) \u221d e\u2212\u03b2|x| /2 or, equivalently,\n(\u03b2\u22122)/2 \u2212\u03b2u/2\n2\nPorter-Thomas distribution Pu (u, \u039b \u2192 \u221e) \u221d u\ne\n[1, 8](using u = |x| , which gives Pu = Px (2|x|)\u22121 ).\nIt is desirable to know the solution Px of eq.(32), or alternatively, Pu for finite, non-zero \u039bu and all ranges of u. In the\ndiagonal representation of H0 , which corresponds to an initial distribution Pu0 (u0 , \u039b = 0) = N \u22121 [\u03b4(u\u22121)+(N \u22121)\u03b4(u)],\neq.(32) gives following short range behavior of Pu :\ni\n\u0001\n\u221a\ne\u2212\u03b2u/2 h\n\u03ba\n\u22121/2\nu<\n1+\n(\u03b2 + 2)/\u03b2 \u2212 (\u03b2 + 2) u + \u03b2u/2 + ..\n\u223c\u03ba\n\u0393(\u03b2/2)\n2\nh\n\u0010\n\u0011i\n1\n\u03ba\n< \u22121\n\u2248 (\u03b2u/2)\u03b2/2\u22121\nexp (\u03b2/2) \u2212u + u2 + ...\n\u03ba\u22121/2 <\n\u223cu\u223c\u03ba\n\u0393(\u03b2/2)\n2\n\nPu = (\u03b2u/2)\u03b2/2\u22121\n\n(33)\n(34)\n\nwhere \u03ba = e\u22122\u03b2N \u039b (note \u03ba \u2248 \u03bc in large Y -limit and for Dk2 \u223c (\u03b2N )\u22121 ) .\nThe tail behavior of a distribution has a significant influence on its moments and the related physical properties.\nThe asymptotic analysis of eq.(32) shows Pu (u) to be a broad distribution:\n\"\n\nPu (u) \u2243 exp \u2212\u03b1u0 u\n\n1/2\n\n\u2212\n\nM\nX\n\nn=1\n\nn\n\n#\n\n\u03b1un ln (\u03bau)\n\n\u22121\nu>\n\u223c\u03ba\n\n(35)\n\nHere the coefficients are sensitive to system-specifics: \u03b1u0 \u2243 4q1 \u03b2 \u22121 (e\u03b2N \u039bu \u2212 1), \u03b1u1 \u2243 \u2212N/4, \u03b1u2 \u2243 (N \u03b2/16)e\u03b2N \u039bu ,\n\u03b1un;n>2 \u2243 (\u22121)n (\u03bdn \u03b2 2 N/4)e2\u03b2N \u039bu with \u03bdn decreasing as n increases. The decreasing coefficients alongwith alternate\n\u00b1 signs lead to near-cancellation of higher order terms (with n > 2) in the exponent. Consequently, the tail is\ndominated by a log-normal behavior for the systems with large, finite \u039b-strengths and a weaker than exponential\ndecay in \u039b \u2192 0 limit.\nEq.(35) indicates the existence of a log-normal asymptotic tail for the local eigenfunction intensity of any complex\nsystem with finite, non-zero \u039bu . A log-normal behavior of P (u) suggests a power-law behavior of its moments:\nhuq i \u221d N \u2212dq [17]. Here dq is an effective dimension which can be different from a spatial dimension d. The form of\nPu (u) at finite \u039b is therefore fixed by a spectrum of scaling exponents (as the moments can be used to recreate the\ndistribution); the situation is termed as multifractal scaling. Further, as shown later, a log-normal tail of P(u) results\nin the similar behavior of the distributions of other related correlations and physical properties. Such a behavior\nhas already been indicated for the physical properties e.g. conductance, density of states, local density of states and\nrelaxation time etc. of disordered systems [3].\nThe significance of above P (u)-formulation is that here system dependence (other than size) enters only through\none parameter, namely, \u039b. This being valid for any complex system, modeled by eq.(1) (and eq.(2)), is thus applicable\nfor disordered systems too. It is therefore relevant to compare our result with those obtained for disordered systems\nusing other techniques (using renormalization group theory approach for dimension d = 2 + \u01eb, \u01eb < 1 [43], and, by using\n1/2\nBerezinski and Abrikosov-Ryzkhin techniques for strictly d = 1 cases [8, 11, 57]; the techniques predict a e\u2212\u03b11 u\ntail for d = 1, a log-normal tail for d = 2 and a log-cube tail for d = 3 case. However our technique predicts a\nlog-polynomial behavior however dominated by log-normal term for all dimensions.\nB.\n\nInverse Participation Ratio (IPR)\n\nP\n2q\nThe q th order inverse participation ratio Iq of an eigenvector, say Uk , is defined as Iq (k) = N\nj=1 |Ujk | . The\nphysical meaning of Iq can be illustrated by two limiting cases: (i) an eigenfunction with identical components\n\n\f11\n\nUjk = N \u22121/2 corresponds to Iq (k) = N 1\u2212q , and, (ii) an eigenfunction with only one non-zero component (say\nnth ) which gives Ujk = \u03b4nk and Iq (k) = 1. The case (i) corresponds to completely ergodic eigenfunctions covering\nrandomly but uniformly the whole sample of volume V . The case (ii) corresponds to a wavefunction localized in\nthe neighborhood of a single basis state. Thus Iq , in general, is related to reciprocal of the number of components\nsignificantly different from zero and contains information about spread of a wavefunction in the basis space. For\nexample, for a d-dimensional exponentially localized state, I2 \u223c (a/\u03b6)d , where a and \u03b6 are the lattice constant\nand localization length, respectively. Consequently, the typical value of I2 is a frequently used characteristic of the\neigenfunction localization [3]: I2typ = exphlnI2 i \u2248 N \u2212D2 with D2 a system dependent scaling exponent (also known\nas correlation dimension).\nR\nth\n1\u2212q \u221e\n2q\n\u03b2\nThe\nensemble\naverage\nof\nI\nis\nrelated\nto\nq\nmoment\nof\nthe\ndistribution\nP\n(x):\nhI\ni\n=\nN\nq\nx\nq\n0 |x| Px (x)d x =\nR\nIq PIq dIq , The average inverse participation ratios can therefore provide information about the scaling exponents.\nAs a consequence, it is useful to know the effect of changing system parameters on hIq i. Due to P (u) decay for the\nranges \u03bcu >\n\u223c 1, major contribution to hIq i comes from the region \u03bcu \u2264 1. From eq.(32), it can be shown that\n\u2202hIq i\n\u2248 q\u03b1hIq\u22121 i \u2212 qthIq i.\n\u2202\u039b\n\n(36)\n\nwhere \u03b1 = 2q + \u03b2 \u2212 2, t = N \u03b2 + 2q \u2212 2. Eq.(36) depends on two parameters, namely \u039b and t which results in a\ndifferent power law behavior for each hIq i,\n\"\n\nhIq (\u039b)i = e\u2212qt\u039b hIq (0)i + \u03b1\n\nZ\n\n0\n\n\u039b\n\n#\n\nhIq\u22121 (r)ieqtr dr .\n\n(37)\n\nFor \u039b \u2192 \u221e, eq.(37) gives a correct steady state limit, namely, Wigner-Dyson behavior: hIq i \u2192 \u03b1t hIq\u22121 i or hIq i =\n(2q)! 1\u2212q\nfor \u03b2 = 1 and hIq i = q!N 1\u2212q for \u03b2 = 2. For finite nonzero \u039b, hIq i can be determined if hIq\u22121 (\u039b)i as\n2q q! N\nwell as some past information about the system (to choose it as an initial state which will give hIq (0)i) is known.\nFor example, for the systems where completely localized wavefunction dynamics is a valid physical possibility (e.g.\ndisordered systems, mixed systems etc.), it can be chosen as the initial state which corresponds to hIq (0)i = 1; this\ngives hI1 (\u039b)i = 1, hIq (\u039b)i \u2248 e\u2212q\u03b2N \u039b for q < N .\nIn general, the IPR fluctuations reflect the level to level variations of the spatial structure of eigenfunctions. In\na complex system e.g. nano-system, however, the sample to sample fluctuations of the eigenfunctions also manifest\nthemselves through IPR fluctuations which makes a knowledge of the Iq -distribution over whole ensemble of samples\nrelevant. The distribution\nPIq of Iq of an eigenfunction, say Zk , with the components {znk }k=1,..N is related to\nR\nP\nP \u221d PN 1 : PIq (Iq ) = \u03b4Iq PN1 (Zk , ek , Y) dek d\u03c4k with \u03b4Iq \u2261 \u03b4(Iq \u2212 n |znk |2q ) and the volume element d\u03c4k same\nas in eq.(20). The Y governed evolution of PIq can therefore be obtained from Eq.(18) for P \u221d PN 1 :\n\u2202PIq\n\u03b22\n=\n(X1 + X2 ) + X3\n\u2202Y\n4\nwhere X3 =\n\nR\n\n\u03b4Iq [LE PN 1 ]d\u03c4k = 0 and\nZ\nX1 =\n\u03b4Iq [L1k + L\u22171k ] dek d\u03b2 Zk\nZ\n4 \u2202\n=\nIq \u03b4Iq F1 d\u03c4k ,\n\u03b2 \u2202Iq\nZ\nX2 = 2 \u03b4Iq L2k d\u03c4k\nZ\nZ\n4q(2q + \u03b2 \u2212 2) \u2202\n8q 2 \u2202 2\nF\nd\u03c4\n\u2212\n\u03b4\n\u03b4Iq F3 d\u03c4k\n=\nk\nIq 2\n\u03b2 2 \u2202Iq2\n\u03b22\n\u2202Iq\n\n(38)\n\n(39)\n(40)\n(41)\n(42)\n\n\f12\n\ni\nh\nP\nP\n2(q\u22121) 12\n2(q\u22121)\n\u2217\n02\u2217\nQnn;k where\n|znk |2(q\u22121) znk\nzmk Q12\nwith F1 = Q02\nmn;k and F3 =\nnn;k + Qnn;k , F2 =\nn |znk |\nm,n |zmk |\n\nL1k , L2k and Qmn;k are given by eqs.(19, 20). Using the approximate form (22) for Qrs\nmn;k , F 's can further be reduced:\nF1 \u2248 q\u03c7(N \u2212 1)/D2\n\uf8ee\n!2 \uf8f9\nX\n\u03c7 \uf8f0X\nF2 \u2248\n|znk |2(2q\u22121) \u2212\n|znk |2q \uf8fb PN 1\nD2 n\nn\n\u0003\n\u03c7 X\u0002\n2q\u22122\n2q\n|znk |\n\u2212 |znk | PN 1 .\nF3 \u2248\n2\nD n\n\n(43)\n\nwhere \u03c7 = 1 for \u03bc < \u03b6kd and \u03c7 \u223c \u03bc/\u03b6kd for \u03bc > \u03b6kd .\nIn general, the fluctuations of different moments (or measures) of the eigenfunction intensity need not be mutually\nindependent. We can therefore define the joint distribution of two measures, say, h1 (z), h2 (z):\nZ\n(44)\nPh1 ,h2 (h1 , h2 ) = \u03b4[h1 \u2212 h1 (z)]\u03b4[h2 \u2212 h2 (z)]PN 1 dek d\u03b2 Zk\nThe above definition along with the equality\ngives\nZ\n\n\u03b4Iq\n\n\"\nX\nn\n\n|znk |\n\n2(2q\u22121)\n\n#\n\nP\n\nn\n\n|znk |2(2q\u22121) =\n\nPN 1 dek d\u03b2 Zk \u2248\n\nZ\n\nP\n\nm,n\n\n|zmk |2q |znk |2(q\u22121) \u2212\n\nIq Iq\u22121 PIq,q\u22121 (Iq , Iq\u22121 )dIq\u22121 \u2212\n\ntyp\n\u2248 Iq\u22121\nIq PIq \u2212 Wqtyp PIq\n\nZ\n\nP\n\nm,n;m6=n\n\n|zmk |2q |znk |2(q\u22121)\n\nW PIq ,W (Iq , W )dW\n(45)\n\nwhere Wq is a measure of the correlation between the intensities localized at two different basis sates: Wq =\nP\n2q\n2(q\u22121)\n. The 2nd equality in eq.(45) is obtained from first by replacing Iq\u22121 and W by their\nm,n;m6=n |zmk | |znk |\ntypical values; the superscript typ over a variable R indicates its typical value: Rtyp = exphlnRi.) Using eqs.(44,45),\nthe terms X1 and X2 can be rewritten as the functions of Iq and PIq which in turn leads to\n\u0003\n\u0003\n\u2202PIq\n\u2202 \u0002 typ\n\u2202 2 \u0002 typ\nIq\u22121 Iq \u2212 Wqtyp \u2212 Iq2 PIq \u2212\n\u2248 2q\n\u03b1Iq\u22121 \u2212 tIq PIq\n2\n\u2202\u039bip\n\u2202Iq\n\u2202Iq\n\n(46)\n\nwith \u03b1, t same as in eq.(36) and\n\n\u039bip = q\u03c7\u039b.\n(47)\nR\nNote, the above equation alongwith the definition hIq i = Iq PIq dIq again leads to eq.(36).\nThe behavior of PIq in different Iq regimes can now be probed by analyzing eq.(46), using completely localized\neigenstates as the initial state. The behavior varies from an exponential decay for small-Iq regime to log-power law\ndecay for asymptotic tail regime of Iq :\n\u22121 typ\nIq <\nPIq \u2243 exp [\u2212\u03b1i0 Iq ]\n\u223c e Iq\n\" M\n#\nX\nn\n\u22121\ntyp\n\u2243 Iq exp \u2212\n\u03b1in ln (Iq /Iq )\nn=1\n\n(48)\n\u22121 typ\nIq >\n\u223c e Iq\n\n(49)\n\ntyp n\n) /(2qIqtyp )n (valid for q < N ) and M as a large\nwith e \u2248 2.72, \u03b1i0 \u2248 t(1 \u2212 e\u2212t\u039bip )\u22121 /2q and \u03b1in \u223c (\u22121)n 2(Iq\u22121\ninteger. Note the alternate \u00b1 signs of terms with increasing powers lead to convergence of the series in the exponent.\nHowever the tail is dominated by increasingly higher powers of the logarithmic term as Iq increases above its typical\ntyp\nvalue. For example, for e\u22121 Iqtyp < Iq <\n\u223c Iq , n = 1 dominates the exponent and PIq behaves as a power-law. Similarly,\ntyp\nthe tail shows a log-normal decay for regime Iqtyp < Iq <\n\u223c eIq .\n\n\f13\n\nEq.(46) depends on more than one parameter, namely, \u039bip as well as size-dependent parameters (appearing through\nt). This suggests an absence of single parameter scaling in IPR distributions. However, as suggested by eqs.(48, 49),\nit seems possible to define a single parameter locally (that is, different single parameters governing different IPR\nregimes). Further note that the asymptotic behavior of PIq is sensitive to \u039b-strength and is therefore system-specific.\nThis result also agrees with the NLSM-result obtained for disordered systems [17].\n.\nC.\n\nPair-Function w(r,r')\n\nThe measure contains important information about the spatial correlations between components of an eigenfunction\nZj at two different basis points of the sample and at an energy e: w(n, m) = |znj zmj |2 ; (equivalently w(r, r\u2032 ) =\n|zj (r)zj (r\u2032 )|2 in a continuous basis e.g. coordinate space r). In the localized phase, the asymptotic behavior of\nlnw(r, r\u2032 ) at |r \u2212 r\u2032 )| \u2192 \u221e determines the rate of exponential decay of the eigenfunction amplitude. It is also useful\nfor many physical applications e.g. in determination of the form factor of resonance scattering in the complex nuclei\nor the resonance conductance\nPof the quantum dot with point contacts in the coulomb blockade regime [15].\nThe distribution Pw,e = h j \u03b4(w \u2212 |znj zmj |2 )\u03b4(e \u2212 ej )i of the correlation between nth and mth components of an\nP R\neigenfunction, at an energy e, is related to PN 1 : Pw (w, e) = j \u03b4w \u03b4e,j PN1 (Zj , ej , Y) d\u03c4j with \u03b4w \u2261 \u03b4(w\u2212|znj zmj |2 )\nand d\u03c4j same as in eq.(20). Consequently, its rate of change with respect to Y can be determined by eq.(18),\n\u2202Pw\n\u03b22\n= N Le Pw +\n(A1 + A2 )\n\u2202Y\n4\n\n(50)\n\nwhere\nZ\n\u0003\n\u0002\n4X \u2202\n02\nw \u03b4w \u03b4e,j Q02\nnn;j + Qmm;j d\u03c4j\n\u03b2 j \u2202w\nZ\nZ\n\u0002\n\u0003\n8 X \u22022\n4X \u2202\n\u03b2\n= 2\nw\n\u03b4\n\u03b4\n[F\n+\nF\n]\nde\nd\nZ\n\u2212\n\u03b4w \u03b4e,j F1 + 2\u03b2 \u22121 F2 d\u03c4j\nw e,j\n1\n2\nj\nj\n2\n\u03b2 j \u2202w\n\u03b2 j \u2202w\n\nA1 =\n\n(51)\n\nA2\n\n(52)\n\n2 12\n\u2217\n12\n\u2217\n12\nwith F1 = |zmj |2 Q12\nnn;j + |znj | Qmm;j and F2 =Rznj zmj Qnm;j + znj zmj Qmn;j . Eq.(50) is derived by first using eq.(18),\nfollowed by repeated partial integration. Note \u03b4w \u03b4e,j [LE PN 1 ]dej dZj = N Le Pw . Within approximation (20) for Qs,\nA1 , A2 can further be simplified which on substitution in eq.(50) give the diffusion of Pw in a closed form:\n\n\u2202Pw\n\u22022\n\u2202\n=\n[w(\u03a91 \u2212 4w)] Pw \u2212\n[\u03a92 \u2212 bw] + N Le Pw\n\u2202\u039bw\n\u2202w2\n\u2202w\n\n(53)\n\ntyp\nwhere \u03a91 = |zmj |2typ + |znj |2typ + 2|znj |2typ \u03b4nm = 2(1 + \u03b4nm )utyp\n= exp[hlnuj i] as the typical local intensity of\nj , with uj\nth\n2\n2\n2\nthe j eigenfunction, \u03a92 = (\u03b2/2)[|zmj |typ + |znj |typ + (4/\u03b2)|znj |typ \u03b4nm ] = (\u03b2 + 2\u03b4nm )utyp\nj , \u039bw = 2\u03c7\u039b and b = \u03b2N + 2.\nThe last term on the right of eq.(53) can be removed by an integration over energy e, leaving us with an evolution\nequation for\nP energy-averaged Pw . Note the energy averaging of eq.(53) for case n = m corresponds to eq.(46) for\nP (I2 ) (as n w(n, n) = I2 ).\nExploiting the similarity of the form of energy-averaged eq.(53) to eq.(46), the behavior of Pw (w) in different regimes\ncan again be given by eqs.(48,49) after following replacements (everywhere in the equations): Iq \u2192 w, \u03b1in \u2192 \u03b1wn\n\u2212b\u039bw \u22121\n) /4. Thus Pw (w) decays exponentially for\nwhere \u03b1wn \u223c (\u22121)n 21\u22122n \u03a9n2 (wtyp )\u2212n for n >\n\u223c 1 and \u03b1w0 \u2248 b(1 \u2212 e\ntyp\n> typ\nsmall w ranges (w <\nw\n/e):\nP\n\u2243\nexp\n[\u2212\u03b1\nw].\nIt\nshows\na\npower-law\nbehavior for regimes e\u22121 wtyp >\nw\nw0\n\u223cw\u223cw\n\u223c\n> typ\nPw \u2243 w\u22121 e\u2212\u03b1w1 ln(\u03baw) , a log-normal decay for regimes wtyp >\n\u223c w \u223c ew . Such a behavior was predicted by non-linear\nsigma model studies of quasi 1-d disordered wires too [3].\nEq.(53) can be used to study the behavior\nR of various moments of the distribution of pair-correlation. For example,\nfor average behavior of w, that is, hwi = wPw (w; \u039b) dw, eq.(53) gives its \u039b evolution. The evolution equation turns\nout to be of the same form as eq.(36) (with q = 2) with following replacements: hIq i\u0002\u2192 hwi, \u03b1 \u2192 \u03a92 and 2\u039b \u2192\u0003 \u039bw\n(note hIq\u22121 i = 1, t \u2192 b for q = 2). It can be solved to show that hw(\u039bw )i = e\u2212b\u039bw hw(0)i + (\u03a92 /b)(eb\u039bw \u2212 1) . A\n\n\f14\n\nchoice of hw(0)i = \u03b4ml (corresponding to localized regime) gives hw(\u039bw )i = \u03b4ml e\u2212b\u039bw + (\u03a92 /b)(1 \u2212 e\u2212b\u039bw ) \u2248 (1 \u2212 \u03ba)/N\nwhich is analogous to the result obtained for disordered systems (by NLSM techniques); see [3].\nD.\n\nCorrelation Between Eigenfunctions At Two Different Energies\n\nCritical point studies of many systems indicate the presence of multifractal structures among eigenfunctions. The\nmultifractality suggests that the wavefunction is effectively located in a vanishingly small fraction of the system\nvolume. However such extremely sparse wavefunctions can exhibit strong correlations if they belong to neighboring\nenergy levels; the correlations therefore preserve the level-repulsion despite the sparsity of the wavefunction. Thus, for a\ncomplete analysis of level-statistics and associated physical properties, a knowledge of correlations among eigenfunction\nis very important. The correlations are also used in the analysis of many other physical properties e.g. for the\nmeasurement of the linear response of the system, or, to determine the fluctuations of matrix elements of some\noperator in a given basis. This information is useful in studies of the effect of a particular interaction on the statistical\nproperties of the system e.g. effect of electron-electron interaction on a single particle disordered system.\nThe correlations between components of two eigenfunctions at different energies can be described as \u03c3(n, m, ek , el ) =\n|znk zml |2 ) (equivalently, in a continuous basis: \u03c3(r, r\u2032 , e, e\u2032 ) = |\u03c8e (r)\u03c8e\u2032 (r\u2032 )|2 ). The distribution P\u03c3 of the correlation \u03c3 = |znk znl |2 between nth and mth components of the\u0010 eigenfunctions\nZk and Zl , respectively, is related to\n\u0011\nP R\nQ\nwith\n\u03b4\u03c3 \u2261 \u03b4(\u03c3 \u2212 |znk zml |2 ), d\u03c4j same as in\nPN 2 : P\u03c3 (\u03c3, e, \u03c9) = k,l \u03b4\u03c3 \u03b4e,k \u03b4e+\u03c9,l PN2 (Zk , Zl , ek , el , Y)\nd\u03c4\nj\nj=k,l\neq.(20), and, \u03c9 = |ek \u2212 el | as the energy difference between two states. Using eq.(25) and proceeding as in the case\nof Pw , the diffusion of P\u03c3 (\u03c3) can be shown to be described by the equation\n\u0015\n\u0014 2 h\ni\ni\n\u2202 h\n\u2202P\u03c3\n\u2202\n(\n\u03a9\u0303\n\u2212\nb\u03c3)\n+\nL\n+\nL\n\u03c3(\n\u03a9\u0303\n\u2212\n\u03c3)\n\u2212\n=\ne\ne+\u03c9 P\u03c3\n2\n1\n\u2202\u039b\u03c3\n\u2202\u03c3 2\n\u2202\u03c3\n\n(54)\n\n2\nwhere \u039b\u03c3 = 2\u03c7\u039b, \u03a9\u03031 = (|zsl |2 typ + |zrk |2 typ + 2|zrk |2 typ \u03b4kl \u03b4rs ), \u03a9\u03032 = [\u03b2(|zrk |2 typ + |zsltyp\n) + 4|zrk |2 typ \u03b4kl \u03b4rs ]/2 and\nb = \u03b2N + 2). Note eq.(53) is a special case of the above equation (as P (w) \u2261 P (\u03c3) for k = l).\nThe energy averaging of eq.(54) once again leads to an equation similar in form to eq.(46). Exploiting the analogy,\n< \u22121 \u03c3 typ ), (ii) \u2243 \u03c3 \u22121 exp[\u2212\u03b1\u03c31 ln(\u03c3/\u03c3 typ )]\nwe again get three different regimes for P\u03c3 (\u03c3):\n\u0002 (i) \u22432 exp [\u2212\u03b1\n\u0003\u03c30 \u03c3] (fortyp\u03c3 \u223c e typ\n\u22121 typ >\ntyp\n\u22121\ntyp\n>\n(for e \u03c3\nand (iii) \u2243 \u03c3 exp \u2212\u03b1\u03c32 ln (\u03c3/\u03c3 ) for e\u03c3 \u03c3 >\nwhere \u03b1\u03c30 \u2248 b(1 \u2212 e\u2212b\u039b\u03c3 )\u22121 /4 and\n\u223c\u03c3\u223c\u03c3\n\u223c\u03c3\n\u03b1\u03c3n \u223c (\u22121)n 21\u22122n \u03a9\u0303n2 (\u03c3 typ )\u2212n for n >\n\u223c 1.\nThe \u039b dependence of average behavior of h\u03c3i can now be derived by multiplying eq.(54) by \u03c3 and then integrating\nover \u03c3; the equation again turn out to be same as the q = 2 case of eq.(36) after following\ni\nh replacements: hIq i \u2192 h\u03c3i,\n\n\u03b1 \u2192 \u03a9\u03032 and 2\u039b \u2192 \u039b\u03c3 . Solving the so-obtained evolution equation gives h\u03c3(\u039b\u03c3 )i = e\u2212b\u039b\u03c3 h\u03c3(0)i + (\u03a9\u03032 /b)(eb\u039b\u03c3 \u2212 1) .\n\nThe choice of a localized initial state (e.g. an insulator at \u039b\u03c3 = 0) corresponds to h\u03c3(0)i = 0 which gives h\u03c3(\u039b)i \u2248\n\u03b2\n\u2212\u03b2\u039b\n).\nN (1 \u2212 e\n\u2217\n\u2217\nIn this paper, we have considered only two point correlations. The other correlations e.g. hzrk\nzrl zsk zsl\ni related\n4\n4\nto linear response of the system or, higher order ones e.g. h|zrk | |zsk | i related to IPR fluctuations, can similarly be\ndetermined using eq.(25).\nE.\n\nLocal Density of States \u03c1(e, j)\n\nP\nThe local density of states or the spectral function, defined as \u03c1(e, j) = n |Ujn )|2 \u03b4(e\u2212en ), is an important measure\nof localization. This is because it counts the eigenstates Un having appreciable overlap with (or equivalently, located\nclose to) the site j. Note this is distinct from the global density of states \u03c1(e) which counts all the eigenstates at the\nenergy e irrespective of their location in space. The measure \u03c1(e, j) is of special interest as it gives information about\nthe decay of a specific unperturbed state into other states due to interaction. The width of the LDOS defines the\neffective \"life-time\" of the unperturbed basis state. Its distribution is an experimentally accessible quantity related\nto the position and form of NMR line [3].\n\n\f15\n\nR\ndensity P\u03c1 (\u03c1) of \u03c1(e, j) is related to P1N : P\u03c1 (\u03c1) = \u03b4\u03c1 P1N (E, Z, Y) dE d\u03b2 Z where \u03b4\u03c1 = \u03b4(\u03c1 \u2212\nPThe probability\n2\nn |zjn | \u03b4(e \u2212 en )) (note here Z \u2261 {zjn }n=1,..N ). The diffusion of P\u03c1 due to changing system parameters can again\nbe studied with the help of eq.(14) for P1N .\n\u2202P\u03c1\n= LE P\u03c1 + B + B \u2217\n\u2202Y\n\n(55)\n\nR\n2\nnd\n2\nform of B is obtained from the 1st by a substitution\nwith B = B \u2217 = \u03b4\u03c1 Lz P1N d\u03b2 ZdE = \u2202\u2202\u03c1F21 + \u03b22 \u2202F\n\u2202\u03c1 . Here the 2\nof three terms of Lz (eq.(15)) in the integral, and, a subsequent partial integration which gives\n\uf8ee\n\uf8f9\nZ\nX |zjn |2 |zjm |2\nF1 =\n\u03b4\u03c1 \uf8f0\n\u03b4(e \u2212 en ) (1 \u2212 \u03b4(e \u2212 em ))\uf8fb P1N d\u03b2 ZdE\n(56)\n(en \u2212 em )2\nm,n;m6=n\n\uf8ee\n\uf8f9\nZ\nX |zjm |2 \u2212 |zjn |2\nF2 =\n\u03b4\u03c1 \uf8f0\n\u03b4(e \u2212 en )\uf8fb P1N d\u03b2 ZdE\n(57)\n(en \u2212 em )2\nm,n;m6=n\n\nAs in the case of the integrals Q and G (see Appendix A), the dominant P\ncontribution to the integrals F1 and F2\ncomes from the regions where the exponent term in P1N , that is f = (\u03bc/2) m<n |en \u2212 em |2 |Ujn |2 |Ujm |2 < 1. This\ncan occur under two conditions:\n(1) \u03bch\u03c3i < 1: Here \u03c3 = |Ujn |2 |Ujm |2 describes the correlation between two different eigenfunction components in\nthe same basis state. Under the condition, a neighborhood of the order of mean level spacing can contribute to the\nintegral over e-variables i.e |en \u2212 em |2 \u223c D2 ,\n(2) \u03bch\u03c3i \u2265 1: In this case, f \u226b 1 only for those regions where |en \u2212 em |2 \u223c D2 /(\u03bch\u03c3i). Note however in both cases,\nalmost entire eigenfunction space can contribute to the integral.\nThus F1 and F2 can be approximated as F1 \u2248 \u03c7D\u22122 [\u03c1(1 \u2212 \u03c1)P\u03c1 ] and F2 \u2248 N \u03c7D\u22122 [\u03c1 \u2212 h\u03c1i] P\u03c1 where \u03c7 = 1 if\n>\n\u03bch\u03c3i <\n\u223c 1 and \u03c7 \u223c \u03bch\u03c3i for \u03bch\u03c3i \u223c 1. The approximate forms of F1 and F2 can now be used to rewrite B as a function\nof P\u03c1 which on substitution in eq.(55) gives the diffusion equation for P\u03c1 :\n\u2202P\u03c1\n\u22022\n\u03b2N \u2202\n= Le P\u03c1 + 2 [\u03c1(1 \u2212 \u03c1)] P\u03c1 +\n[\u03c1 \u2212 h\u03c1i] P\u03c1\n\u2202\u039b\u03c1\n\u2202\u03c1\n2 \u2202\u03c1\n\n(58)\n\nwhere \u039b\u03c1 = \u03c7\u039b. Note that the above equation is analogous in form as the eqs.(46, 53, 54) of PIq , Pw and P\u03c3 ,\nrespectively. This similarity is reflected in both short as well as long-range behavior\nof P\u03c1 : \u0003(i) \u2243 exp [\u2212\u03b1\u03c10 \u03c1] (for\n\u0002\n\u22121 >\ntyp\n\u22121\n> \u03c1typ ), and, (iii) \u2243 \u03c1\u22121 exp \u2212\u03b13 ln2 (\u03ba\u03c1) for (\u03c3 > \u03ba\u22121 ) where\n\u03c1 <\n\u03c1\n),\n(ii)\n\u2243\n\u03c1\nexp\u2212\u03b1\nln(\u03ba\u03c1)\n(for\n\u03ba\n\u03c1\n\u03c11\n1\n\u223c\n\u223c \u223c\n\u223c\n\u03b1\u03c10 \u2248 b(1 \u2212 e\u2212b\u039b\u03c1 )\u22121 /4 and \u03b1\u03c1n \u223c (\u22121)n 21\u22122n (\u03c1typ )\u2212n .\n.\nV.\n\nTHE PARAMETER \u039b\n\nThe set of Eqs.(14,18,25) provides a common mathematical formulation for the eigenfunction-statistics of various\ncomplex systems modeled by eqs.(1,2); here the information about the system enters only through Y . As shown\nexplicitly in [49], the same Y also enters in the common mathematical formulation of the eigenvalue-statistics of\nensemble (1) (and (2), see [51]); this is implied by eqs.(14,18,25) too. However, as discussed in [49, 51], the evolution\nof the nth order eigenvalue correlations (n > 1) as a function of Y , is abrupt in large N -limit; a smooth crossover can\nonly be seen in terms of a rescaled parameter \u039be where\n\u039be (e, Y ) = \u039b =\n\nY \u2212 Y0\nD\u03b62\n\n(59)\n\nwith D\u03b6 (e, Y ) = D(\u03b6/L)d as the local mean level spacing, D(e, Y ) as the mean level spacing of the full spectrum and \u03b6\nas the correlation/localization length for a d-dimensional system of length L (N = Ld ), at an energy e and parameter\n\n\f16\n\nY (with Y0 as its initial value). Thus \u039be for various systems e.g disordered systems, mixed systems, systems with chiral\nor particle-hole symmetry etc. can be calculated by a prior knowledge of system parameters; (e.g. see [50] for the\ncalculation for Anderson and Brownian ensembles). As \u039be increases from zero to infinity, the level-statistics changes\nfrom its initial state (with Y = Y0 ) to that of Wigner-Dyson ensemble. For example, let the initial state corresponds\nto insulator limit of disordered systems or integrable limit of mixed systems; both limits show Poisson level-statistics\n[3, 9, 42, 52, 53]. A variation of system parameters changes \u039b from zero, causing diffusion of levels towards WignerDyson steady state. According to \u039b formulation, the level-statistics, for the system parameters resulting in finite \u039b,\nis then an intermediate point of Poisson \u2192 Wigner-Dyson transition. The prediction is in agreement with previous\nworks on the two systems [3, 20, 50, 52, 53]; (note Wigner-Dyson statistics corresponds to metal and chaotic limits\nof disordered and mixed systems, respectively [24, 42]).\nFor later reference, it is worth reviewing the role of \u039be , that is, \u039b in locating the critical point of level statistics.\nAs both |Y \u2212 Y0 | as well as the local mean level density are functions of N , the latter can affect \u039b significantly. As a\nconsequence, the size N plays a crucial role in determining the level statistics in the critical regime. For finite systems,\nthe eigenvalue statistics smoothly approaches one of the two end points, namely, \u039b \u2192 0 or \u039b \u2192 \u221e, with increasing\nsystem size. The variation of \u039b in infinite systems, however, may lead to an abrupt transition of the statistics, with\nits critical point given by the condition \u039b = size independent (see ref.[17] for the definition of a critical distribution).\nThe finite, non-zero \u039b strength, say \u039bcritical , at the critical point, results in an eigenvalue-statistics different from\nthe two end points. Note, however, that the existence of a critical point or its absence depends on the relative sizedependencies of |Y \u2212 Y0 | and the local mean level spacing. If the size-dependence of D\u03b62 remains different from that\nof |Y \u2212 Y0 | under all complexity conditions, \u039b will never achieve a finite non-zero value in infinite size limit. As a\nconsequence, such a system will not show a critical behavior of eigenvalue-statistics. For example, as discussed in [50]\nfor a d-dimensional Anderson Hamiltonian of linear size L, \u039b turns out to be size-independent only for d > 2. The\n\u039b-formulation, therefore, indicates the lack of metal-insulator transition for dimensions d \u2264 2 which is in agreement\nwith several studies of previous years.\nThe connection of the eigenvalue fluctuations to those of eigenfunctions suggested \u039b as the evolution parameter\nfor the eigenfunctions correlations (of order n > 1) too. As shown in section III, the evolution parameters \u039bmeasure\nof various eigenfunction fluctuation measures are indeed functions of \u039b: \u039bmeasure = f (\u039b). Here f (\u039b) \u221d \u039b on short\nlength scales and f (\u039b) \u223c \u039be\u2212\u03b1\u039b in the tail regime.\nThe parameter \u039b, being a function of the distribution parameters of the matrix elements, is sensitive to changes in\nthe system parameters; this is due to latter's influence on the uncertainties associated with system-interactions. Some\nexamples of such system parameters are disorder, dimensionality, boundary and topological conditions, system size etc.\nFor example, the presence of disorder randomizes the interactions, with degree of disorder affecting the distribution\nparameters h, b and consequently \u039b. The dependence of \u039b on the dimensionality and boundary conditions originates\nfrom their influence on the basis connectivity i.e degree of sparsity of the matrix which is reflected in the distribution\nparameters h, b. For example, for nearest neighbor hopping and hard wall boundary conditions in d-dimensions, the\nmatrix element Hjk 6= 0 only if j = |k \u00b1 Ld\u22121 | (with L as linear size). The variance hjk of the distribution \u03c1(Hjk ) is\ntherefore finite only for j = k or |j = k \u00b1 Ld\u22121 | and is zero for all other j, k. The information about dimensionality in\n\u039b also enters through the local mean level spacing which depends on the correlation volume \u03b6 d . (See also [50] where\nthe dependence of \u039b on system parameters is explained by considering an example of Anderson Hamiltonian).\nThe system size N is another important parameter which affects the evolution of the measures significantly. As\nshown in section IV, it appears independently as well as through \u039bmeasure in the evolution equations which suggests\na two parametric dependence, namely, \u039bmeasure and N (separately) of these measures. As a consequence, even at the\ncritical point of level statistics, the eigenfunction statistics remains sensitive to size N . This in turn results in a multifractal behavior of the eigenfunctions at the critical point of any complex system, modeled by eqs.(1,2). The scaling\nexponents at the critical point, referred as critical exponents or multifractal dimensions, depend on system parameters.\nIn finite size systems, changing system parameters can change \u039b (and therefore \u039bmeasure ) continuously between 0\nand \u221e which may lead to intermediate stages of varying degree of multifractality. However, the physically interesting\ncases usually correspond to infinite sizes where \u039b takes only three possible values, namely, \u039b = 0, \u221e, \u039bcritical ; for\nthese cases therefore only one multifractal stage, that is at the critical point corresponding to \u039bcritical , can exist. As\n\u039bcritical is sensitive to system-specifics, the critical (multifractal) exponents can vary from system to system. Note,\nas already mentioned above, the occurrence of critical point and, therefore, a multifractal behavior of eigenstates is\nnot a necessary feature of all infinite size complex systems.\nThe \u039b-governed diffusion equations, derived in section IV, are valid for arbitrary initial conditions at \u039b = 0 (which\nimplies \u039bx = 0) and their solutions Px (X, \u039bx |X0 , 0) describe the probability of the measure, say X, at \u039bx for a given\n\n\f17\n\ninitial state of X = X0 . Thus P is subjected to an initial constraint lim\u039b \u2192 0P (X, \u039bx |X0 , 0) = \u03b4(X \u2212 X0 ). By\nintegration of the solution over the distribution of initial values P0 (X0 , 0), one can recover P (X, \u039bx ), that is, the\ndistribution of measure X for a system with complexity parameter strength \u039b:\nZ\nP (X, \u039bx ) = P (X, \u039bx |X0 , 0)P0 (X0 , 0)dX0 .\n(60)\nThe eq.(60) implies that the statistics evolved in \"time\" \u039bx is sensitive to the collective behavior of system parameters contributing to \u039bx and the initial distribution only. The latter can always be chosen same for the systems\noperating in the matrix spaces of similar type e.g. same symmetry conditions; (the initial values of their Y parameters need not be equal). Thus if both A,B operate in the matrix spaces of same type, their behavior at the system\nparameter strengths which lead to \u039bx,A = \u039bx,B = t would also be same (although they may show different behavior\nbetween 0 < \u039bx,A , \u039bx,B < t). This implies a great deal of universality among systems of widely different origins of\ncomplexity. For example, consider the cases of a three dimensional disordered system, say A, and a clean, closed\nquantum dot, say B. In the first case, \u039bx,A = \u039bx,disorder is a function of disorder, hopping strength, dimensionality,\nboundary condition etc. In the case of a dot, \u039bx,B = \u039bx,dot is a function of shape as well as size. It is well-known that,\nin strong disorder limit and for circular shape, respectively, both systems show localized wavefunction dynamics and\nsame statistical behavior of the eigenfunctions and eigenvalues of the Hamiltonians. Reducing the degree of disorder\nor change of shape of the dot from circle to stadium type results in a transition from localized to delocalized dynamics\nof the wavefunctions. The statistics in the intermediate stages during the transition for each case is governed by\nthe respective \u039bx strengths. If, however, the \u039bx,dot = \u039bx,disorder at some shape parameter and disorder strength,\nrespectively, our analysis predicts a same statistical behavior for both systems. The implication can also be extended\nto classical systems e.g. stock market fluctuations which are analyzed by statistical studies of the correlation matrix\nof stocks [5]. (Note, the correlation matrices of classical systems are, in general, non-Hermitian; however, as shown\nin [40], the \u039b formulation remains valid for non-Hermitian version of eq.(1)). Here a very weak interaction among\ncertain stocks due to various socio-economic conditions results in a localized dynamics of the eigenfunctions. The\nchanging conditions may lead to a more homogenized interaction of some of the stocks, thus introducing a transition\nfrom localized to delocalized wave dynamics. In this case, \u039b is a function of the socio-economic parameters (SEP).\nHowever if \u039bx,stock = \u039bx,dot for some combinations of SEP and dot parameters, respectively, the spectral and strength\nfluctuations in correlation matrix of the stock market and the Hamiltonian of quantum dot will show same behavior.\nNote the analogy of statistical behavior of the eigenvalues and eigenfunctions among the three systems, mentioned\nabove, has already been numerically verified in delocalized waves limit \u039b \u2192 \u221e [1, 3, 5]. .\nThe above universality makes \u039b formulation useful as it can be exploited to obtain the statistics of a complex system\nif the same information is available about another system (under same symmetry conditions) by another method.\nFor example, for Anderson type disordered Hamiltonian, the distributions of many measures are known by non-linear\nsigma model techniques. The formulations can then be used for the complex systems e.g stock markets undergoing a\ntransition from localized \u2192 delocalized wave dynamics; one just needs to replace \u039b(Anderson) by that of the system.\nThe formulation can also be used to search for the system conditions leading to a critical state or multifractal\nwavefunctions of various complex systems. For example, the suggested modelling of mixed systems by eq.(1) would\nimply the possible existence of a critical point of level-statistics in the systems and multifractal eigenstates. The\nintuition suggests that the occurrence of such a point may correspond to breaking of the last KAM curve, thus allowing\nclassical diffusion or delocalization of the dynamics above the critical point and localization below it; however it needs\nto be further explored. The critical \u039b can then given by the critical value of system parameter leading to last KAM\ncurve breaking.\nVI.\n\nNUMERICAL ANALYSIS\n\nFor numerical analysis, we choose three different ensembles (for both cases \u03b2 = 1, 2); the choice is dictated by\nthe reason (i) the ensembles are prototype models of many physical systems related to different areas [3, 8, 9, 35],\n(ii) a comparative study of the eigenvalue fluctuations of these systems has already been carried out, with their \u039b\nparameters and other results given in [49]:\n(i) Critical Anderson ensemble (AE):\n(a) Time-Reversal case AEt : we analyze cubic (d = 3) Anderson lattice of linear size L (N = Ld ) with a Gaussian\nsite disorder (of variance W 2 /12, W = 4.05 and mean zero), same for each site, an isotropic random hopping between\n\n\f18\n\nnearest neighbors with hard wall boundary conditions [3, 50]. The ensemble density in this case can be described by\neq.(1) with hkk = W 2 /12, hkl = f (kl)/12, bkl = 0 where f (kl) = 1 for {k, l} pairs representing hopping, f (kl) \u2192 0\nfor all {k, l} values corresponding to disconnected sites. A substitution of above values in eq.(8) gives Y which\nsubsequently gives \u039b by eq.(59): (see eq.(19) of [49]),\n\u039ba (E, Y ) = |\u03b1 \u2212 \u03b10 |F 2 \u03b6 2d L\u2212d \u03b3 \u22121\n\n(61)\n\n2\n\nwith \u03b1 \u2212 \u03b10 = 1.36 and F (E) = 0.26e\u2212E /5 (see section V of [49]). (Note, for later reference, F (E) is the mean level\ndensity: F (E) = (N D)\u22121 ).\n(b) Broken Time-Reversal case AEnt : we analyze cubic (d = 3) Anderson lattice of linear size L (N = Ld ) with a\nGaussian site disorder (of variance W 2 /12, W = 21.3 and mean zero), same for each site, an isotropic non-random\nhopping t = 1 between nearest neighbors with periodic boundary conditions [3, 50]. The time-reversal symmetry\nis broken by applying an Aharnov Bohm flux \u03c6 which gives rise to a nearest neighbor hopping Hkl = exp(i\u03c6) for\nall k, l values related to the nearest-neighbor pairs [58]. The flux \u03c6 is chosen to be non-random in nature, that is,\nhcos2 (\u03c6)i = W1 = 0, < sin2 (\u03c6) >= W2 = 0 and hcos(\u03c6)i = t1 = 1, < sin(\u03c6) >= t2 = 1. The ensemble density in this\ncase can again be described by eq.(1) with hkk = W 2 /12, bkk = 0, hkl;s = Ws = 0, bkl;s = ts f (kl; s) where f (kl; s) = 1\nfor {k, l} pairs representing hopping, f (kl; s) \u2192 0 for all {k, l} values corresponding to disconnected sites. The \u039b for\n2\nthis case is still given by eq.(61) (except for a factor \u03b2 \u22121 ); however now \u03b1 \u2212 \u03b10 = 5.43, F (E) = 0.016e\u2212E /400 (see\nsection V of [49]).\n(ii) Critical Power Law Random Banded Ensemble (critical PRBM or PE): As mentioned in section II, PRBM\nensemble was introduced as a possible model for the level statistics of Anderson Hamiltonian [34]. It is defined\nas the ensemble of random Hermitian matrices with matrix elements Hij as independently distributed Gaussian\nvariables with zero mean i.e < Hij >= 0 and a power-law decay of the variances away from the diagonal [3, 10, 34]:\n< |Hij;s |2 >= a(|i \u2212 j|) with function a(r) decaying as r increases.\n\u0002\n\u0003\u22121\n\u22121\nThe PRBM ensemble with specific choice < |Hij;s |2 >= Gij\n1 + (|i \u2212 j|/b)2\n, Gij = \u03b2(2 \u2212 \u03b4ij ) and Gij = 1/2\n(referred as critical PRBM or PE in this paper) leads to a critical behavior of eigenfunction and eigenvalue statistics\nat arbitrary values of the parameter b and is believed to show all the key features of the Anderson critical point,\nincluding multifractality of eigenfunctions and the fractional spectral compressibility [3, 34]. The ensemble density\n\u0002\n\u0003\u22121\n\u22121\nin this case corresponds to eq.(1) with bkl = 0, and, hkl;s = Gkl\n1 + (|k \u2212 l|/p)2\n. The corresponding \u039b can be\nshown to be given by (see section VI of [49]),\n2\n2 \u22121\n\u039bp (p, E) = \u03b1\u22121\n.\np f (p)F (E)\u03b6 N\n\n(62)\n\nPN\nwhere \u03b1p = 2N (N + 2 \u2212 \u03b2), f (p) = r=1 (N \u2212 r)ln|1 + (p/r)2 |.\n(iii) Critical Brownian Ensemble (BE): A Brownian ensemble can be described as a non-stationary state of the matrix\nelements undergoing a cross-over due to a random perturbation of a stationary ensemble by another\n\u221a one [8, 11, 32, 49].\nFor example, in the case of Hermitian operators, a Brownian ensemble H can be given as H = f (H0 + \u03bbV ) (with\nf = (1 \u2212 \u03bb2 )\u22121 ); here V is a random perturbation of strength \u03bb, taken from a stationary ensemble [37] e.g. WignerDyson ensemble, and applied to an initial stationary state H0 (see also [11]). Here we consider a specific class of\nBEs, namely, those appearing during a transition from Poisson \u2192 Wigner-Dyson ensemble, caused by a perturbation\nof the former by the latter (that is, taking H0 , V as Poisson and Wigner-Dyson ensemble respectively). As, in\nabove two cases, this transition also results in a change of localized eigenstates to delocalized ones. The BEs related\nto the Poisson \u2192 Wigner-Dyson transition can be described by a N \u00d7 N ensemble H represented by eq.(1) with\n2\n2\nmean hHkl i = bkl = 0, the variance hHkk;s\ni = hkk;s = (2\u03b3)\u22121 and hHkl;s\ni = hkl;s = [4\u03b3(1 + \u03bc)]\u22121 for k 6= l. with\n2 \u22121\n(1 + \u03bc) = (\u03bb f ) ; here H = H0 for \u03bb \u2192 0 or \u03bc \u2192 \u221e. As mentioned in section II, the ensemble density in this\ncase has the same form as for Rosenzweig-Porter (RP) ensemble [33]; it can also describe an ensemble of Anderson\nHamiltonians with very long range, isotropic, random hopping. Further, as discussed in [49], the special case \u03bc = cN 2\n2\ncorresponds to the critical BEs; their mean level density is given as F (E) = (\u03c0)\u22121/2 e\u2212E and\n2\n\n\u039bb (E) = (1/4c\u03c0\u03b3)e\u2212E .\n\n(63)\n\nOur aim is to show that the behavior of an eigenfunction fluctuation measure of AE, BE and PE is analogous\nat system parameters which lead to a same \u039bmeasure value for all the three cases. Using the latter as a condition,\nwe can obtain the desired system parameters in each case (that is, p for PE and c for BE for a given AE). As \u039b\n\n\f19\n\nfor the three cases is energy dependent, the fluctuation measures should be compared at precisely a given value of\nenergy. For numerical analysis, however, one needs to consider averages over an energy range \u2206E which should be\nsufficiently large in order to improve the statistics. On the other hand, choice of a very large \u2206E will lead to mixing\nof different statistics (in a range \u2206\u039b \u221d \u03b4E). As a consequence, one needs to consider an optimized range of \u2206E. In\nour simulations, we analyze large ensembles of about 1400 matrices of size N = 2197. We choose \u2206E to be about\n10% of the bandwidth, at the band center E = 0 which gives approximately 3 \u00d7 105 levels for each case. As the chosen\n\u2206E corresponds to a 1 % variation of the density of states, it avoids mixing of different statistics.\nAs discussed in previous section, the eigenfunction fluctuations are influenced by both \u039b as well as system size N .\nTo compare \u039bmeasure dependence of a fluctuation measure (of eigenfunctions), therefore, same system size should be\ntaken for all systems under consideration. As examples, here we consider distributions of three measures, namely,\nlocal eigenfunction intensity Pu (u), inverse participation ratio PI (I2 ) and pair correlation function Pw (w) for the three\nsystems under time-reversal symmetry (\u03b2 = 1) i.e . AEt , BEt , PEt . As, for Pu ,\n\u03bc(Y \u2212 Y0 )\u03b6 2d\n\u039bu =\n\u2248\nN 2 D2\n\n\u0012\n\nF\nI2typ\n\n\u00132\n\n,\n\n(64)\n\n(with \u03b6 d \u2248 (I2typ )\u22121 ), the BE and PE analogs for the intensity distribution of AEt can be obtained by the condition\ntyp\ntyp\ntyp\nI2,a\n/Fa = I2,b\n/Fb = I2,p\n/Fp . This requires a prior information about I2typ . Our numerical study for various sizes\n \u0303 \u2212D2 with I \u0303 and D2 system dependent. The numerical\nof the three systems shows that, for each case, I2typ \u2248 IN\ntyp\ninformation about I2 and F can now be used to obtain the parameters p and c for PE and BE analogs of AEt for\nPu case (i.e PE and BE with the ratio I2typ /F same as for AE); we find p = 0.4, c = 0.02. The figure 1 shows the\ndistribution Pu (u\u2032 ), u\u2032 = [lnu \u2212 hlnui]/hln2 ui, for the BEt case (c = 0.02) and PEt case (p = 0.4) along with AEt\ncase; the close agreement among the three cases confirms our theoretical prediction. This is also confirmed by the\ncomparison of PI (lnI2 ) and Pw (lnw) for the three systems, shown in figure 3 and figure 5, respectively. Here again\nthe parameters p and c for PE and BE analogs for both measures are obtained by the relation \u039bI,a = \u039bI,b = \u039bI,p\n(similarly for w).\nThe above numerical analysis is repeated also for the case of AE in a magnetic field and its BE and PE analog; the\nresults for the three measures, shown in figures 2,4 and 6, further support our claim: the eigenfunction fluctuations\nof different complex systems show same behavior if their complexity parameters and sizes are equal. It is worth\nreminding that behavior of the eigenvalue fluctuations is governed only by the related complexity parameter (that is,\nno independent influence of size). The details of analytical and numerical evidence about the eigenvalue statistics are\nalready published in [49, 50, 51]. However for the sake of completeness and to convince the reader, we include here\nthe numerical analysis of an eigenvalue fluctuation measure, namely, nearest neighbor spacing distribution P (S) for\nthe three system (for both \u03b2 = 1, 2 cases) at parametric values leading to \u039be,a = \u039be,b = \u039be,c (where \u039be = \u039b); the\nplots shown in figures 7,8 reconfirm the claim about eigenvalue statistics.\nVII.\n\nCONCLUSION\n\nIn the end, we summarize our main results. Our analysis of the eigenfunction correlations of complex systems\nindicates a two parameter dependence, namely, complexity parameter \u039b and system size N , of the distributions of\neigenfunction components. The independent appearance of size parameter (besides through \u039b) seems to suggest a\nlack of finite size scaling in eigenfunction distributions and an absence of their critical limit. This is in contrast\nwith the behavior of eigenvalue distribution which shows a single parametric scaling as well as a critical limit if the\ncondition limN \u2192 \u221e \u039b = finite is satisfied by the system. Note the above implies the size-dependence of eigenfunction\ncorrelations at the critical point of level-statistics too.\nWe have also studied the distribution of a few important measures of eigenfunction correlations e.g. local density\nof states, pair correlation function etc. We find that the form of complexity parameter governing an eigenfunction\nfluctuation measure is sensitive to its nature (e.g. \u039bu for local intensity distribution, \u039bI for inverse participation\nratio distribution etc). This is again different from the eigenvalue fluctuations (except for level density) which are\nall governed by the same complexity parameter, namely, \u039be = \u039b. Our analysis indicates a log-normal behavior of\nthe asymptotic tails of the distributions at finite \u039b-strength. In context of disordered systems, a similar behavior\nwas predicted by other studies using different techniques e.g. Berezinski and Abrikosov-Ryzkhin technique (for\n\n\f20\n\none dimension) and by non-linear sigma model (for higher dimensions) [3]. However the complexity parameter\nformulation suggests the existence of such a tail-behavior and multifractal eigenfunctions for almost any complex\nsystem, irrespective of the origin of complexity, if the parameter N \u039bmeasure is finite. A recent numerical study of the\neigenfunction of the correlation matrix of stock prices confirms the suggestion in case of stock market [5, 28]. As finite\n\u039b corresponds to the critical point condition in infinite size systems, a log-normal tail-behavior seems to be associated\nwith the existence of a critical point (and vice-verse). The above study can thus be used to search and predict the\ncritical stages of other complex systems e.g. stock market, brain etc.\nIn this paper, we have considered the cases modeled by generalized Gaussian ensembles with uncorrelated matrix\nelements as well as a wide range of non-Gaussian ensembles with correlated matrix elements. The latter are suitable\nmodels, for example, for disordered systems with varying degree of particle-particle interactions. In context of disordered systems, therefore, we expect a same statistical behavior of a measure for both the cases, namely, with or\nwithout particle interactions, if the strengths of their parameters \u039bmeasure are equal. This suggests the sensitivity of\nthe statistical behavior of a disordered system to degree of its complexity only (measured by complexity parameter),\nirrespective of the origin. The statement is expected to be valid for correlated and uncorrelated cases of other complex\nsystems too. This in turn would indicate the existence of an infinite family of universality classes, parametrized by\n\u039b, of statistical behavior among complex systems.\nAPPENDIX A: CALCULATION OF INTEGRALS Qrs\nmn;k AND Gr\n\nThe integral Qrs\nmn;k defined by eq.(20) can be rewritten in terms of \u03c1(H) as\nQrs\nmn;k\n\n\u2217 r\nX Z (Unj Umj\n)\n=\nf \u0303k \u03c1(H, Y ) dH\n(\u03bbk \u2212 \u03bbj )s\n\n(A1)\n\nj;j6=k\n\nTo express Q in terms of PN 1 , it is necessary to write \u03c1(H) in eigenvalue-eigenvector space i.e. {\u03bb, U } space.\nThe steps can briefly be given as follows. The solution of eq.(6) for arbitrary initial condition, say H0 at Y = Y0\ncan be given as \u03c1(H, Y |H0 , Y0 ) \u221d exp[\u2212(\u03b1/2)Tr(H \u2212 \u03b7H0 )2 ] with \u03b1 = \u03b3(1 \u2212 \u03b7 2 )\u22121 and \u03b7 = e\u2212\u03b3Y . Without loss of\ngenerality, the basis space for H can be chosen as the eigenvector space of H0 ; The initial ensemble H0 inP\nthis basis\n\u2212\n\nN\n\nH2\n\n0;jj\nj=1\n.\nconsists of diagonal matrices. For simplification, consider the initial distribution given by \u03c1(H0 ) \u221d e\nUsing eigenvalue equation U H = \u039bU , \u03c1(H, Y |H0 , Y0 ) can be transformed from matrix space to eigenvalue-eigenvector\nspace {\u03bb, U } which followed by an integration over ensemble H0 gives\n\n\u03c1(H, Y ) \u221d\n\nN\nY\n\nk,l;k<l\n\n\uf8ee\n\n|\u03bbk \u2212 \u03bbl |\u03b2 exp \uf8f0\u2212(1/2)\n\nN\nX\nj=1\n\n\u03bb2j \u2212 (\u03bc/2)\n\nX\nk<l\n\n\uf8f9\n\n2\n2\uf8fb\n|\u03bbk \u2212 \u03bbl |2 Ujk\nUjl\n\n(A2)\n\nwhere \u03bc = (e2\u03b7(Y \u2212Y0 ) \u2212 1)\u22121 .\nQ Q\nA substitution of eq.(A2) for \u03c1 in eq.(A1) and using dH = j k<l |\u03bbk \u2212 \u03bbl |\u03b2 d\u03bbj dUj , gives Q as a function of\n{U, \u039b} variables. As eq.(A2) indicates, the behavior of Qrs\nmn;k is significantly influenced by the term R \u2261 \u03bc|\u03bbk \u2212\nPN\n2\n2\n2\n\u03bbj |\nn=1 |Unk | |Unj | present in the exponent of \u03c1. Consequently, for a given Y , the dominant contribution to the\nintegrals over the variables Uj and \u03bbj in eq.(A1) comes from those regions which lead to R \u2192 0. Also note that\nthe eigenvalue-eigenfunction correlations appear in \u03c1 only through R. The limit R \u2192 0 therefore allows a mutually\nindependent integration over \u03bbj and Unj variables. As the typical local intensity |Unk |2typical \u223c \u03b6k\u2212d with \u03b6k as the\nlocalization length of the eigenfunction Uk (d as system-dimension), this implies R \u223c \u03bc\u03b6k\u2212d |\u03bbk \u2212 \u03bbj |2 . Consequently,\nthe regions of variable \u03bbj and Unj which contribute to integral depend on mutual competition between \u03bc and \u03b6kd :\n(i) for \u03bc < \u03b6kd , almost entire region of Unj can contribute to integral (due to 0 < |Unj |2 < 1). However only a small\nneighborhood of the order of local mean level spacing, i.e |\u03bbk \u2212 \u03bbj | \u2243 Dk around \u03bbk , contributes to \u03bbj integration.\nHere Dk is the local mean level spacing at eigenvalue \u03bbk . As a consequence, an approximation of repulsion term\n\n\f21\n\n|\u03bbk \u2212 \u03bbj | \u2248 Dk alongwith the relation\n\nPN\n\nk=1\n\n\u2217\nUnk Umk\n= \u03b4mn (due to unitary nature of U ) gives\n\nN\n\u2217 r\n\u2217 r\nX\n(Unj Umj\n)\n[\u03b4mn \u2212 Unk Umk\n]\n=\n(\u03bbk \u2212 \u03bbj )s\n(N \u2212 1)r\u22121 Dks\n\n(A3)\n\nj=1;6=k\n\nHere r = 0, 1 only. \u03c7 = 1, Dk is the local mean level spacing at eigenvalue \u03bbk .\n(ii) for \u03bc > \u03b6kd , the significant contribution comes from the regions of \u03bbj where |\u03bbj \u2212 \u03bbk | \u223c Dk [\u03b6kd /\u03bc]1/2 . Here\nagain, as a typical |Unj |2 \u223c \u03b6 \u2212d < 1, the entire region of Uj can contribute to the integral. Consequently one can\napproximate\n\u0012 \u0013s/2\nN\n\u2217 r\n\u2217 r\nX\n(Unj Umj\n)\n\u03bc\n[\u03b4mn \u2212 Unk Umk\n]\n=\ns\nd\ns\nr\u22121\n(\u03bbk \u2212 \u03bbj )\n(N \u2212 1) Dk\n\u03b6k\n\n(A4)\n\nj=1;6=k\n\n(One may also consider the contribution from regions where |Unj |2 < (\u03bc|Unk |2 Dk2 )\u22121 however it is weaker than the\nabove).\nBy substituting approximations (A3,A4) in eq.(A1), Qrs\nmn;k can be written as (for r = 0, 1 only):\ns/2\nQrs\nmn;k \u2248 \u03c7\n\n\u2217\n(\u03b4mn \u2212 zmk\nznk )r\nPN 1 (Zk , ek )\nr\u22121\n(N \u2212 1) Ds\n\n(A5)\n\nwhere \u03c7 = 1 for \u03bc < \u03b6kd and \u03c7 = \u03bc/\u03b6kd for \u03c7 > \u03bc/\u03b6kd .\nThe integral Gr (see eq.(30) can also be rewritten in terms of \u03c1(H) and can similarly be approximated:\n\nGr (x, e) \u2261\n\nX Z\n\n\u03b4x\u03b2 \u03b4e\n\nj;j6=k\n\n|Unj |2r\n\u03c1 dH\n(\u03bbk \u2212 \u03bbj )2\n\n(A6)\n\nThe dominant contribution in this case comes from those regions of integration over Uj and \u03bbj which lead to R\u0303 \u2261\nP\nR\u0303\n\u03bc|Unk |2 j |\u03bbk \u2212 \u03bbj |2 |Unj |2 present in the exponent of \u03c1. (Note, unlike the dominating term R in Qrs\nmn;k case,\n\u221a\ncontains only a single component of the k th eigenfunction, namely, Unk , and, the latter takes a fixed value x/ N .)\nConsequently, for a given Y , Gr depends on the mutual competition between \u03bc and x. Reasoning as in the case of\nQrs\nmn;k , Gr can be approximated as\nGr \u2248 \u03bc\u03c70 (N \u2212 1)1\u2212r (N \u2212 |x|2 )r P11 (x)/D2\n\n(A7)\n\nwith \u03c70 = \u03bc\u22121 for \u03bc|x|2 < 1 and \u03c70 \u223c |x|2 for \u03bc|x|2 > 1.\nAPPENDIX B: EFFECT OF MATRIX ELEMENTS PERTURBATIONS ON EIGENVALUES AND\nEIGENFUNCTIONS\n\nP2\ns\u22121\nConsider the perturbation of a Hermitian matrix H with matrix elements\nHkl;s , eigenvalues\ns=1 (i)\nPHkl \u2261\nH\nU\n=\n\u03bb\nU\nalong with the\n\u03bbn and eigenfunctions Un , n = 1, 2, ..N . By\nusing\nthe\neigenvalue\nequation\nnm\nmj\nn\nnj\nm\nP\n\u2217\northo-normal condition on eigenvectors i.e.\nj Unj Umj = \u03b4mn , it can be shown that\n\u2202\u03bbn\n\u22121\n= 2gkl\nUkn Uln\n\u2202Hkl;s\nis\u22121 X\n1\n\u2202Unj\n\u2217\n\u2217\n=\nUnm (Ukm\nUln + (\u22121)s+1 Ulm\nUkj ).\n\u2202Hkl;s\ngkl\n\u03bbj \u2212 \u03bbm\nm6=j\n\n(B1)\n\n\f22\n\nThe details of the steps used in derivation of eq.(B1) can be found in [49].\nThe set of equations (B1) can further be used to show following relations:\nX\n\nk,l,s;k\u2264l\n\nX\n\nk;l,s;k\u2264l\n\n\u2202\u03bbn\nHkl;s = \u03bbn\n\u2202Hkl;s\n\n(B2)\n\n\u2202Unj\nHkl;s = 0,\n\u2202Hkl;s\n\n(B3)\n(B4)\n\nand,\nX\n\nk,l,s;k\u2264l\n\nX\nUnj\ngkl \u2202 2 Unj\n= \u2212\n2\n2 \u2202Hkl;s\n(\u03bbj \u2212 \u03bbm )2\n\n(B5)\n\nm6=j\n\nX\n\ngkl\n\n\u2202\u03bbi \u2202Unj\n= 0\n\u2202Hkl;s \u2202Hkl;s\n\n(B6)\n\nX\n\ngkl\n\nUni Unj\n\u2202Uni \u2202Upj\n= \u2212\u03b2\n(1 \u2212 \u03b4ij )\u03b4np\n\u2202Hkl;s \u2202Hkl;s\n(\u03bbi \u2212 \u03bbj )2\n\n(B7)\n\nX\n\ngkl\n\nk,l,s;k\u2264l\n\nk,l,s;k\u2264l\n\nk,l,s;k\u2264l\n\n\u2217\n\u2217\nX Unm Upm\n\u2202Uni \u2202Upj\n= \u03b2\n\u03b4ij\n\u2202Hkl;s \u2202Hkl;s\n(\u03bbj \u2212 \u03bbm )2\n\n(B8)\n\nm6=j\n\n[1] Y.Alhassid, Rev. Mod. Phys. 72, 895, (2000).\n[2] Supriyo Datta, Electronic Transport in Mesoscopic Systems, (Cambridge University Press, Cambridge, 1995);\nD.K.Ferry and S.M.Goodnick Transport in Nanostructures, (Cambridge University Press, Cambridge, 1997).\n[3] Ya.M.Blanter and A.D.Mirlin, Phys. Rev. E 55, 6514 (1997). Ya.V.Fyodorov and A.D.Mirlin, Phys. Rev.B 55, R16001\n(1997). Ya.M.Blanter, A.D.Mirlin and B.A.Muzykantskii, Phys. Rev. Lett. 78, 2449 (1997). F. Evers and A.D. Mirlin,\nPhys. Rev. B, 58, 321, (1998).\n[4] K.Binder and A.P.Young, Rev. Mod. Phys., 58, 801, (1986).\n[5] V. Plerou, P. Gopikrishnan, B. Rosenow, L. A. Nunes Amaral and H. Eugene Stanley, Phys. Rev. Lett. 83, 1471, 1474\n(1999); J.Kwapien, S.Drozdz and P.Oswiecimka, Acta Physica Polonica B, 36, 2423, (2005).\n[6] M.A.M. de Aguiar and Y.Bar-Yam, Phys. Rev. E, 71, 016106 92005).\n[7] T.A.Brody, J.Flores, J.B.French, P.A.Mello, A.Pandey and S.S.M. Wong, Rev. Mod. Phys. 53, 385, (1981).\n[8] M.L.Mehta,Random Matrices, (Academic Press, New York, 1991); C.E.Porter, Statistical Theory of Spectra: Fluctuations (Academic Press, New York, 1965); F.Haake, Quantum Signatures of Chaos (Springer, Berlin, 1991).\n[9] T.Guhr, G.A.Muller-Groeling and H.A. Weidenmuller, Phys. Rep. V299, 189, (1998).\n[10] Y.V.Fyodorov and A.D.Mirlin, Int. J. Mod. Phys.B, 8, 3795, (1994).\n[11] B.L.Altshuler and V.N.Prigodin, JETP Lett., 47, 43, (1988); Sov. Phys. JETP, 68, 198, (1998).\n[12] J.B.French, V.K.B.Kota, A.Pandey and S.Tomsovic, Ann. Phys. (N.Y.), 181, 198, (1988).\n[13] V.I.Falko and K.B.Efetov, Phys. Rev. B, 50, 11267, (1994); Phys. Rev. Lett. 77, 912, (1996).\n[14] S.A. Van Langer, P.A. Brouwer and C.W.J. Beenakker, Phys. Rev. E 55, R1, (1997); Y. Alhassid, J.N.Hormuzdiar and\nN.Whelan, Phys. Rev. B, 58, 4866, (1998). K. Zyczkowski and G. Lenz, Z. Phys. B, 82, 299, (1991); E. Kogan and M.\nKaveh, Phys. Rev. B, 51, 164100, (1995). E. Kanzeiper and V. Freilikher, Phys. Rev. B, 54, 8737, (1996).\n[15] V.N.Prigodin, B.L.Altshuler, K.B.Efetov and S.Iida, Phys. Rev. Lett. 72, 546, (1994); V.N.Prigodin, Phys. Rev. Lett. 74,\n1566, (1995).\n[16] K.Muller, B. Mehlig, F. Milde and M. Schreiber, Phys. Rev. Lett. 78, 215, (1997).\n[17] M.Janssen, Phys. Rep. 295, 1, (1998).\n[18] M.V.Berry, J.Phys.A: Math. Gen. 10, 2083, (1977); E.J.Heller, Phys. Rev. Lett., 53, 1515, (1984); E.B.Bogomolny, Physica\n31D, 169, (1988); G.Casati and L.Molinary, Prog. Theor. Phys. Suppl. 98, 287, (1989).\n[19] P.Leboeuf and A.Voros, J.Phys.A: Math. Gen. 23, 1765, (1990); P. Leboeuf and P. Shukla, J. Phys. A: Math. Gen. 29,\n4827, (1996); P. Shukla, J. Phys. A: Math. Gen. 30, 6313, (1997).\n\n\f23\n\n[20]\n[21]\n[22]\n[23]\n\n[24]\n[25]\n\n[26]\n\n[27]\n[28]\n[29]\n[30]\n[31]\n[32]\n[33]\n[34]\n[35]\n[36]\n[37]\n[38]\n[39]\n\n[40]\n[41]\n[42]\n[43]\n[44]\n[45]\n[46]\n[47]\n[48]\n[49]\n[50]\n[51]\n[52]\n[53]\n[54]\n[55]\n[56]\n[57]\n[58]\n\nF. Izrailev, Physics Reports, 196, 299, (1990).\nJ.B.French and S.S.M. Wong, Phys. Lett., 33B, 449, (1970); O. Bohigas and J. Flores, Phys. Lett. 34B, 241, (1971).\nV.K.B. Kota, Phys. rep. 347, 223, (2001); L.Benet and H.A. Weidenmuller, J.Phys.A: Math. Gen. 36, 3569, (2003).\nE. Wigner, Ann. Math. 62, 548, (1955); 65, 203 (1957); T.H.Seligman, J.J.M.Verbaarschot and M. Zirnbauer, Phys. Rev.\nLett. 53, 215, (1984). G. Casati, B. V.Chirikov, I. Guarneri and F.Izrailev, Phys. Rev. E 48, R1613 (1993). G. Casati,\nL.Molinari and F.M.Izrailev, Phys. Rev. Lett. 64, 1851 (1990). K.Zyczkowski, M.Kus, M.Lewenstein and F.Izrailev, Phys.\nRev. A 45, 811 (1992).\nO. Bohigas, S. Tomsovic and D.Ullmo, Physics Reports, 223, 43, (1993).\nH.L.Montgomery, Analytic Number Theory, Proceeding of the Symposium on Pure Mathematics, (Am. Math. Soc., Providence RI), 24, 181, (1972); A. Odlyzko, The 1020 th Zero of the Reimann Zeta Function and 70 Million of its Neighbors, AT\n& T Preprint; M .V.Berry, Nonlinearity, 1, 399, (1988); C.Itzykson and J.-B. Zuber, Comm. Math. Phys. 134, 197, (1990);\nM. Kontsevich, Comm. Math. Phys. 147, 1, (1992); D. Aldous and P.Diaconis, Bull. Am. Math. Soc. 36, 413, (1999).\nE.V.Shuryak and J.J.M. Verbeerschot, Nucl. Phys. A, 560, 306, (1993); T.H.Verbaarschot and I.Zahed. Phys.Rev.Lett.\n70, 3853 (1993); J.J.M.Verbaarschot, Phys. rev. Lett. 72, 2531 (1994); Nucl. Phys. B, 426, 559 (1994); G. Akemann,\nP.H.Damgaard, U.Magnea and S.Nishigaki, Nucl. Phys. B, 487, 721, (1997).\nC.W.Beenakker, Rev. Mod. Phys, 69, 731, (1997).\nJ.Kwapien, S.Drozdz and A.A.Ionnides, Phys. Rev. E 62, 5557 (2000).\nM.S.Santhanam and P.K.Patra, Phys. Rev. E, 64, 016102 (2001).\nMany new applications and several other references of random matrix theory can be found by searching the cond-mat\narchives.\nE. Cartan, Ab. Math. Sem. Univ. Hamburg V11 116 (1935).\nF.Dyson, J. Math. Phys. 3, 1191 (1962).\nN. Rosenzweig and C.E.Porter, Phys. Rev. 120, 1698 (1960).\nMirlin et.al, Phys. Rev. E, 54, 3221 (1996).\nA.M.Garcia-Garcia and J.C.Osborn, Nuc. Phys. A, 770, 141, (2006).\nJ.A.Mendez-Bermudez, T.Kottos and D.Cohen, Phys. Rev. E, 73, 036204, (2006).\nA. Altland and M.R.Zirnbauer, Phys. Rev. B 55, 1142, (1997).\nJ. Ginibre, J. Math. Phys. 6, 440 (1965).\nJ. Feinberg and A.Zee, Phys. Rev. E 59, 6433, (1999); J.T.Chalker and B.Mehlig, Phys. Rev. Lett. 81, 3367, (1998).\nY.V.Fyodorov, B.A.Khoruzhenko and H.-J. Sommers, Phys. Rev. Lett.,79, 557, (1997); Nils Lehmann and H-j Sommers,\nPhys. Rev. Lett. 67, 941, (1991).\nP.Shukla, Phys. Rev. Lett., 87, 194102, (2001).\nM.V.Berry, Proc.R.Soc. Lond. A, 400, 299, (1985); Les Houches Lecture Series, 36, 171 (1983), (ed. G.Iooss, R.H.G.\nHelleman and R.Stora), Amsterdam, North-Holland; O.Bohigas, M.J.Giannoni and C.Schmit, Phys. Rev. Lett, 52, 1,\n(1984); G. Casati, F. Valz-Gris and I.Guarneri, Lett. Nuovo Cimento 28, 279, (1980).\nN.Dupuis and G. Montambaux, Phys. Rev.B 43, 14390, (1991); D. Braun and G. Montambaux, Phys. Rev. B, 52, 13903,\n(1995).\nB.L.Altshuler, V.E.Kravtsov and I.V.Lerner, Mesoscopic Phenomena in Solids, edited by B.L.Altshuler, P.A.Lee and\nR.A.Webb (Elsevier, Amsterdam, 1991).\nH.-J. Sommers and S. Iida, Phys. Rev. E, 49, R2513, (1994); P.Shukla, Phys. Rev.E, 53, 1362, (1996).\nM.V.Berry, J.P.Keating and H.Schomerus, Proc.R.Soc. Lond. A (2000) 456, 1659\nP. Oswiecimka, J. Kwapien, S. Drozdz and A.Z.Gorski and R.Rak, physics/0606020.\nR. Balian, Nuovo Cimento Soc. Itul. Fis. B, 57, 183, (1968).\nM. Gutzwiller, Chaos in Classical and Quantum Mechanics, (Springer, Berlin, 1990).\nP.Shukla, Phys. Rev. E 62, 2098, (2000).\nP.Shukla, J. Phys.: Condens. Matter 17, 1653, (2005).\nP.Shukla, Phys. Rev. E, 71, 026266, (2005).\nM.V.Berry and M.Robnik, J.Phys.A, 17, 2413, (1984).\nM.V.Berry and M. Tabor, Proc. R. Soc. London A, 356, 37, (1977).\nT.H.Seligman, J.M.Verbaarschot and M.Zirnbauer, Phys. Rev. Lett. 53 (1984) 215.\nG. Casati, I. Guarneri and F. Valz-Gris, 30, 1586, (1984).\nV.I.Melnikov, JETP Lett. 32, 225, (1980); Sov. Phys. Solid State 22, 1398, (1980).\nA.A.Arbikosov, Solid State Commun. 37, 997, (1981).\nT.Terao, Phys. Rev. B, 56, 975, (1997).\n\n\f24\n\nIII.\n\nFIGURE CAPTION\n\nFig. 1. Distribution Pu (u\u2032 ) with u\u2032 = [lnu \u2212 hui]/hln2 ui of the local intensity of an eigenfunction near band center\nfor AEt (Cubic lattice of linear size L = 13, with hard wall boundary conditions, random hopping and time-reversal\nsymmetry) and its BE and PE analog. The parts (a) and (b) of the figure show short and long range behavior of the distypical\ntypical\ntypical\ntribution, respectively. The analogs are obtained by the relation I2,a\n/Fa (0) = I2,b\n/Fb (0) = I2,p\n/Fp (0). For\ntypical\ntypical\ntypical\nN = 2197, we find I2,a\n= 0.018, I2,b=0.02\n=, I2,p=0.4\n= 0.02, and, Fa (0) = 0.26, Fb=0.02 (0) = (\u03c0)\u22121/2 , Fp=0.4 (0) =\n0.39.\nFig. 2 The local intensity distribution for AEnt (Cubic lattice of linear size L = 13, with periodic boundary conditions, non-random hopping and no time-reversal symmetry) and its BE and PE analogs. In this case,\ntypical\ntypical\ntypical\nI2,a\n= 0.013, I2,b=0.03\n=, I2,p=0.4\n= 0.00045, and, Fa (0) = 0.016, Fb=0.03(0) = (\u03c0)\u22121/2 , Fp=0.4 (0) = for N = 2197.\nOther details are same as in figure 1.\nFig. 3. Distribution P (I2\u2032 ) of the rescaled inverse participation ratio I2\u2032 = ln[I2 /I2typ ] for AEt (same as in Figure 1(a))\nand its BE and PE analog: (a) short range behavior (lin-lin plot), (b) tail behavior (lin-log plot). Here the BE and\nPE analogs are obtained by the relation \u039bI,a = \u039bI,b = \u039bI,p . This gives a BE analog of AE different from the figure 1\nalthough PE analog remains unaffected; the reason lies in almost similar mean level density behavior near band-center\nfor the AE, PE cases.\nFig. 4. Distribution P (I2\u2032 ) of the rescaled inverse participation ratio I2\u2032 for AEnt (same as in Figure 1(b)) and its BE\nand PE analog. The other details are same as in figure 3. Note the BE analog of AE, PE in this case is different from\nthe figure 2.\nFig. 5. Distribution P (w\u2032 ) of the spatial correlation w\u2032 = lnw = ln|z1n zN n |2 between two points belonging to opposite\nend of the sample: (a) short range behavior (lin-lin plot), (b) tail behavior (lin-log plot). The cases compared here\nare AEt (same as in Figure 1(a)) and its BE and PE analog (obtained by the relation \u039bw,a = \u039bw,b = \u039bw,p ). Again\nthe BE analog of AE, PE in this case turns out to be different from the figure 1 but same as in the figure 3.\nFig. 6. Distribution P (w\u2032 ) of the spatial correlation w\u2032 for AEnt (same as in figure 2) and its BE and PE analog;\nother details are same as in figure 5. Here the BE and PE analogs are obtained by the relation \u039bw,a = \u039bw,b = \u039bw,p .\nThe BE analog of AE, PE in this case is different from the figure 2 but same as in the figure 4.\nFig. 7. Distribution P (S) of the nearest-neighbor spacing distribution S of the eigenvalues, with (a), (b) showing\nshort and long range behavior, respectively, for AEt (same as in Figure 1) and its BE and PE analog. Here the BE\nand PE analogs are obtained by the relation \u039be,a = \u039be,b = \u039be,p . Note the BE analog of AE, PE in this case is different\nfrom the figure 1 but same as in the figures 3 and 5.\nFig. 8. Distribution P (S) of the nearest-neighbor spacing distribution S for the case AEnt (same as in Figure 2) and\nits BE and PE analog (other details same as in figure 7).\n\n\fFigure 1(a)\n\nFigure 1(b)\n\n1.4\n\n10\n\nAEt\nBEt, c=0.02\nPEt, p=0.4\n\n1.2\n\n1\n\n1\n0.8\n\nP(u')\n\nP(u')\n\n0.1\n\n0.6\n\n0.01\n\n0.001\n0.4\n0.0001\n\n0.2\n0\n-2\n\n-1.5\n\n-1\n\n-0.5\n\n0\n\nu'\n\n0.5\n\n1\n\n1.5\n\n2\n\n1e-05\n-4\n\n-3\n\n-2\n\n-1\n\nu'\n\n0\n\n1\n\n2\n\n25\n\n\fFigure 2(a)\n\nFigure 2(b)\n\n1\n\n1\n\nAEnt\nBEnt, c=0.03\nPEnt, p=0.2\n\n0.9\n0.8\n\n0.1\n\n0.7\n0.01\n\nP(u')\n\nP(u')\n\n0.6\n0.5\n0.4\n\n0.001\n\n0.3\n0.2\n\n0.0001\n\n0.1\n0\n\n-2\n\n-1\n\n0\n\nu'\n\n1\n\n2\n\n1e-05\n-4\n\n-3\n\n-2\n\n-1\n\nu'\n\n0\n\n1\n\n2\n\n3\n\n26\n\n\fFigure 3(a)\n\nFigure 3(b)\n\n0.9\n\n1\n\nAEt\nBEt, c=0.1\nPEt, p=0.4\n\n0.8\n0.7\n\n0.1\n\n0.5\n\nP(I'2)\n\nP(I'2)\n\n0.6\n\n0.4\n\n0.01\n\n0.3\n0.001\n\n0.2\n0.1\n0\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\nI'2\n\n1\n\n2\n\n3\n\n4\n\n0.0001\n-6\n\n-4\n\n-2\n\n0\n\nI'2\n\n2\n\n4\n\n6\n\n8\n\n27\n\n\fFigure 4(a)\n\nFigure 4(b)\n\n1.4\n\n10\n\nAEnt\nBEnt, c=0.1\nPEnt, p=0.4\n\n1.2\n\n1\n\n0.1\n\n0.8\n\nP(I'2)\n\nP(I'2)\n\n1\n\n0.6\n\n0.01\n\n0.4\n0.001\n0.2\n0\n-3\n\n-2\n\n-1\n\n0\n\nI'2\n\n1\n\n2\n\n3\n\n0.0001\n\n-2\n\n0\n\n2\n\nI'2\n\n4\n\n6\n\n8\n\n28\n\n\fFigure 5(a)\n\nFigure 5(b)\n\n0.16\n\n1\n\nAEt\nBEt, c=0.1\nPEt, p=0.4\n\n0.14\n\n0.1\n\n0.12\n\nP(w')\n\nP(w')\n\n0.1\n0.08\n0.06\n\n0.01\n\n0.001\n\n0.04\n0.0001\n0.02\n0\n-20\n\n-15\n\n-10\n\n-5\n\n0\n\nw'\n\n5\n\n10\n\n15\n\n20\n\n1e-05\n-40\n\n-30\n\n-20\n\n-10\n\nw'\n\n0\n\n10\n\n20\n\n29\n\n\fFigure 6(a)\n\nFigure 6(b)\n\n0.25\n\nAEnt\nBEnt, c=0.1\nPEnt, p=0.4\n\n0.2\n\n0.1\n\n0.15\n\nP(w')\n\nP(w')\n\n1\n\n0.1\n\n0.05\n\n0\n-15\n\n0.01\n\n0.001\n\n0.0001\n\n-10\n\n-5\n\n0\n\nw'\n\n5\n\n10\n\n15\n\n1e-05\n-20\n\n-15\n\n-10\n\n-5\n\nw'\n\n0\n\n5\n\n10\n\n15\n\n30\n\n\fFigure 7(a)\n\n0.8\n0.7\n\nFigure 7(b)\n\n1\n\nAEt\nBEt, c=0.1\nPEt, p=0.4\n\n0.6\n\n0.1\n\nP(S)\n\nP(S)\n\n0.5\n0.4\n\n0.01\n\n0.3\n0.2\n\n0.001\n\n0.1\n0\n\n0\n\n1\n\n2\n\nS\n\n3\n\n4\n\n5\n\n0.0001\n\n0\n\n1\n\n2\n\n3\n\n4\n\nS\n\n5\n\n6\n\n7\n\n8\n\n31\n\n\fFigure 8(a)\n\n1\n0.9\n\nFigure 8(b)\n\n1\n\nAEnt\nBEnt, c=0.2\nPEnt, p=0.4\n\n0.8\n0.1\n0.7\n\nP(S)\n\nP(S)\n\n0.6\n0.5\n\n0.01\n\n0.4\n0.3\n0.001\n0.2\n0.1\n0\n\n0\n\n1\n\n2\n\nS\n\n3\n\n4\n\n5\n\n0.0001\n\n0\n\n1\n\n2\n\n3\n\nS\n\n4\n\n5\n\n6\n\n32\n\n\f"}