{"id": "http://arxiv.org/abs/1111.5528v2", "guidislink": true, "updated": "2012-08-02T12:06:15Z", "updated_parsed": [2012, 8, 2, 12, 6, 15, 3, 215, 0], "published": "2011-11-23T15:42:57Z", "published_parsed": [2011, 11, 23, 15, 42, 57, 2, 327, 0], "title": "Energy-aware scheduling under reliability and makespan constraints", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.2650%2C1111.0882%2C1111.5949%2C1111.6205%2C1111.5687%2C1111.0777%2C1111.5818%2C1111.5142%2C1111.2239%2C1111.1632%2C1111.0343%2C1111.4563%2C1111.6472%2C1111.2654%2C1111.1563%2C1111.5580%2C1111.1783%2C1111.2930%2C1111.3543%2C1111.4911%2C1111.0150%2C1111.5860%2C1111.2374%2C1111.0757%2C1111.4495%2C1111.4553%2C1111.2872%2C1111.0677%2C1111.5512%2C1111.5131%2C1111.3052%2C1111.0415%2C1111.4655%2C1111.0211%2C1111.4395%2C1111.2396%2C1111.0695%2C1111.4420%2C1111.0248%2C1111.4059%2C1111.2132%2C1111.0374%2C1111.3330%2C1111.4508%2C1111.1573%2C1111.0633%2C1111.4467%2C1111.4817%2C1111.3532%2C1111.4795%2C1111.1993%2C1111.5881%2C1111.5784%2C1111.2030%2C1111.4648%2C1111.6226%2C1111.5186%2C1111.0654%2C1111.6656%2C1111.1293%2C1111.6288%2C1111.5528%2C1111.4601%2C1111.1625%2C1111.5127%2C1111.2475%2C1111.2864%2C1111.4897%2C1111.5379%2C1111.0414%2C1111.5016%2C1111.5271%2C1111.3002%2C1111.1132%2C1111.7081%2C1111.2963%2C1111.4167%2C1111.4381%2C1111.2107%2C1111.4355%2C1111.0071%2C1111.3381%2C1111.0600%2C1111.4336%2C1111.4448%2C1111.4444%2C1111.0625%2C1111.1501%2C1111.4742%2C1111.3901%2C1111.7174%2C1111.4892%2C1111.6488%2C1111.4130%2C1111.3288%2C1111.1101%2C1111.6619%2C1111.1728%2C1111.3210%2C1111.2941%2C1111.5282&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Energy-aware scheduling under reliability and makespan constraints"}, "summary": "We consider a task graph mapped on a set of homogeneous processors. We aim at\nminimizing the energy consumption while enforcing two constraints: a prescribed\nbound on the execution time (or makespan), and a reliability threshold. Dynamic\nvoltage and frequency scaling (DVFS) is an approach frequently used to reduce\nthe energy consumption of a schedule, but slowing down the execution of a task\nto save energy is decreasing the reliability of the execution. In this work, to\nimprove the reliability of a schedule while reducing the energy consumption, we\nallow for the re-execution of some tasks. We assess the complexity of the\ntri-criteria scheduling problem (makespan, reliability, energy) of deciding\nwhich task to re-execute, and at which speed each execution of a task should be\ndone, with two different speed models: either processors can have arbitrary\nspeeds (continuous model), or a processor can run at a finite number of\ndifferent speeds and change its speed during a computation (VDD model). We\npropose several novel tri-criteria scheduling heuristics under the continuous\nspeed model, and we evaluate them through a set of simulations. The two best\nheuristics turn out to be very efficient and complementary.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.2650%2C1111.0882%2C1111.5949%2C1111.6205%2C1111.5687%2C1111.0777%2C1111.5818%2C1111.5142%2C1111.2239%2C1111.1632%2C1111.0343%2C1111.4563%2C1111.6472%2C1111.2654%2C1111.1563%2C1111.5580%2C1111.1783%2C1111.2930%2C1111.3543%2C1111.4911%2C1111.0150%2C1111.5860%2C1111.2374%2C1111.0757%2C1111.4495%2C1111.4553%2C1111.2872%2C1111.0677%2C1111.5512%2C1111.5131%2C1111.3052%2C1111.0415%2C1111.4655%2C1111.0211%2C1111.4395%2C1111.2396%2C1111.0695%2C1111.4420%2C1111.0248%2C1111.4059%2C1111.2132%2C1111.0374%2C1111.3330%2C1111.4508%2C1111.1573%2C1111.0633%2C1111.4467%2C1111.4817%2C1111.3532%2C1111.4795%2C1111.1993%2C1111.5881%2C1111.5784%2C1111.2030%2C1111.4648%2C1111.6226%2C1111.5186%2C1111.0654%2C1111.6656%2C1111.1293%2C1111.6288%2C1111.5528%2C1111.4601%2C1111.1625%2C1111.5127%2C1111.2475%2C1111.2864%2C1111.4897%2C1111.5379%2C1111.0414%2C1111.5016%2C1111.5271%2C1111.3002%2C1111.1132%2C1111.7081%2C1111.2963%2C1111.4167%2C1111.4381%2C1111.2107%2C1111.4355%2C1111.0071%2C1111.3381%2C1111.0600%2C1111.4336%2C1111.4448%2C1111.4444%2C1111.0625%2C1111.1501%2C1111.4742%2C1111.3901%2C1111.7174%2C1111.4892%2C1111.6488%2C1111.4130%2C1111.3288%2C1111.1101%2C1111.6619%2C1111.1728%2C1111.3210%2C1111.2941%2C1111.5282&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider a task graph mapped on a set of homogeneous processors. We aim at\nminimizing the energy consumption while enforcing two constraints: a prescribed\nbound on the execution time (or makespan), and a reliability threshold. Dynamic\nvoltage and frequency scaling (DVFS) is an approach frequently used to reduce\nthe energy consumption of a schedule, but slowing down the execution of a task\nto save energy is decreasing the reliability of the execution. In this work, to\nimprove the reliability of a schedule while reducing the energy consumption, we\nallow for the re-execution of some tasks. We assess the complexity of the\ntri-criteria scheduling problem (makespan, reliability, energy) of deciding\nwhich task to re-execute, and at which speed each execution of a task should be\ndone, with two different speed models: either processors can have arbitrary\nspeeds (continuous model), or a processor can run at a finite number of\ndifferent speeds and change its speed during a computation (VDD model). We\npropose several novel tri-criteria scheduling heuristics under the continuous\nspeed model, and we evaluate them through a set of simulations. The two best\nheuristics turn out to be very efficient and complementary."}, "authors": ["Guillaume Aupy", "Anne Benoit", "Yves Robert"], "author_detail": {"name": "Yves Robert"}, "author": "Yves Robert", "arxiv_comment": "22 pages. A 10 pages version should appear in HiPC'12", "links": [{"href": "http://arxiv.org/abs/1111.5528v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1111.5528v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1111.5528v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1111.5528v2", "journal_reference": null, "doi": null, "fulltext": "Energy-aware scheduling under reliability and makespan\nconstraints\n\narXiv:1111.5528v2 [cs.DS] 2 Aug 2012\n\nGuillaume Aupy\u2217\nAnne Benoit\u2217\nYves Robert\u2217\u2020\n{guillaume.aupy, anne.benoit, yves.robert}@ens-lyon.fr\nNovember 21, 2018\n\nAbstract\nWe consider a task graph mapped on a set of homogeneous processors. We aim at minimizing the energy consumption while enforcing two constraints: a prescribed bound on the execution time (or makespan), and a reliability\nthreshold. Dynamic voltage and frequency scaling (DVFS) is an approach frequently used to reduce the energy consumption of a schedule, but slowing down the execution of a task to save energy is decreasing the reliability of the\nexecution. In this work, to improve the reliability of a schedule while reducing the energy consumption, we allow for\nthe re-execution of some tasks. We assess the complexity of the tri-criteria scheduling problem (makespan, reliability,\nenergy) of deciding which task to re-execute, and at which speed each execution of a task should be done, with two\ndifferent speed models: either processors can have arbitrary speeds (C ONTINUOUS model), or a processor can run at\na finite number of different speeds and change its speed during a computation (V DD -H OPPING model). We propose\nseveral novel tri-criteria scheduling heuristics under the continuous speed model, and we evaluate them through a set\nof simulations. The two best heuristics turn out to be very efficient and complementary.\n\n\u2217 Ecole\n\nNormale Sup\u00e9rieure de Lyon, France\nof Tennessee Knoxville, USA\n\n\u2020 University\n\n1\n\n\f1\n\nIntroduction\n\nEnergy-aware scheduling has proven an important issue in the past decade, both for economical and environmental\nreasons. This holds true for traditional computer systems, not even to speak of battery-powered systems. More\nprecisely, a processor running at speed s dissipates s3 watts per unit of time [4, 6, 8], hence it consumes s3 \u00d7 d joules\nwhen operated during d units of time. To help reduce energy dissipation, processors can run at different speeds. A\nwidely used technique to reduce energy consumption is dynamic voltage and frequency scaling (DVFS), also known as\nspeed scaling [4, 6, 8]. Indeed, by lowering supply voltage, hence processor clock frequency, it is possible to achieve\nimportant reductions in power consumption; faster speeds allow for a faster execution, but they also lead to a much\nhigher (supra-linear) power consumption. There are two popular models for processor speeds. In the C ONTINUOUS\nmodel, processors can have arbitrary speeds, and can\n\u221a vary them continuously in the interval [fmin , fmax ]. This model\nis unrealistic (any possible value of the speed, say e\u03c0 , cannot be obtained), but it is theoretically appealing [6]. In the\nV DD -H OPPING model, a processor can run at a finite number of different speeds (f1 , ..., fm ). It can also change its\nspeed during a computation (hopping between different voltages, and hence speeds). Any rational speed can therefore\nbe simulated [15]. The energy consumed during the execution of one task is the sum, on each time interval with\nconstant speed f , of the energy consumed during this interval at speed f .\nEnergy-aware scheduling aims at minimizing the energy consumed during the execution of the target application.\nObviously, this goal makes sense only when coupled with some performance bound to achieve, otherwise, the optimal\nsolution always is to run each processor at the slowest possible speed. In this paper, we consider a directed acyclic\ngraph (DAG) of n tasks with precedence constraints, and the goal is to schedule such an application onto a fully\nhomogeneous platform consisting of p identical processors. This problem has been widely studied with the objective of\nminimizing the total execution time, or makespan, and it is well known to be NP-complete [7]. Since the introduction\nof DVFS, many papers have dealt with the optimization of energy consumption while enforcing a deadline, i.e., a\nbound on the makespan [4, 6, 8, 3].\nThere are many situations in which the mapping of the task graph is given, say by an ordered list of tasks to execute\non each processor, and we do not have the freedom to change the assignment of a given task. Such a problem occurs\nwhen optimizing for legacy applications, or accounting for affinities between tasks and resources, or even when tasks\nare pre-allocated [19], for example for security reasons. While it is not possible to change the allocation of a task,\nit is possible to change its speed. This technique, which consists in exploiting the slack due to workload variations,\nis called slack reclaiming [13, 18]. In our previous work [3], assuming that the mapping and a deadline are given,\nwe have assessed the impact of several speed variation models on the complexity of the problem of minimizing the\nenergy consumption. Rather than using a local approach such as backfilling [22, 18], which only reclaims gaps in the\nschedule, we have considered the problem as a whole.\nWhile energy consumption can be reduced by using speed scaling techniques, it was shown in [25, 10] that reducing\nthe speed of a processor increases the number of transient fault rates of the system; the probability of failures increases\nexponentially, and this probability cannot be neglected in large-scale computing [16]. In order to make up for the loss\nin reliability due to the energy efficiency, different models have been proposed for fault-tolerance: (i) re-execution is\nthe model under study in this work, and it consists in re-executing a task that does not meet the reliability constraint;\nit was also studied in [25, 24, 17]; (ii) replication was studied in [1, 12]; this model consists in executing the same\ntask on several processors simultaneously, in order to meet the reliability constraints; and (iii) checkpointing consists\nin \"saving\" the work done at some certain points of the work, hence reducing the amount of work lost when a failure\noccurs [14, 23].\nThis work focuses on the re-execution model, for several reasons. On the one hand, replication is too costly in\nterms of both resource usage and energy consumption: even if the first execution turns out successful (no failure\noccurred), the other executions will still have to take place. Moreover, the decision of which tasks should be replicated\ncannot be taken when the mapping is already fixed. On the other hand, checkpointing is hard to manage with parallel\nprocessors, and too costly if there are not too many failures. Altogether, it is the \"online/no-waste\" characteristic\nof the corresponding algorithms that lead us focus on re-execution. The goal is then to ensure that each task is\nreliable enough, i.e., either its execution speed is above a threshold, ensuring a given reliability of the task, or the\ntask is executed twice to enhance its reliability. There is a clear trade-off between energy consumption and reliability,\nsince decreasing the execution speed of a task, and hence the corresponding energy consumption, is deteriorating\nthe reliability. This calls for tackling the problem of considering the three criteria (makespan, reliability, energy)\n2\n\n\fsimultaneously. This tri-criteria optimization brings dramatic complications: in addition to choosing the speed of each\ntask, as in the deadline/energy bi-criteria problem, we also need to decide which subset of tasks should be re-executed\n(and then choose both execution speeds). Few authors have tackled this problem; we detail below the closest works to\nours [17, 24, 1].\nIzosinov et al. [17] study a tri-criteria optimization problem with a given mapping on heterogeneous architectures.\nHowever, they do not have any formal energy model, and they assume that the user specifies the maximum number of\nfailures per processor tolerated to satisfy the reliability constraint, while we consider any number of failures but ensure\na reliability threshold for each task. Zhu and Aydin [24] are also addressing a tri-criteria optimization problem similar\nto ours, and choose some tasks that have to be re-executed to match the reliability constraint. However, they restrict to\nthe scheduling problem on one single processor, and they consider only the energy consumption of the first execution\nof a task (best-case scenario) when re-execution is done. Finally, Assayad et al. [1] have recently proposed an off-line\ntri-criteria scheduling heuristic (TSH), which uses active replication to minimize the makespan, with a threshold on the\nglobal failure rate and the maximum power consumption. TSH is an improved critical-path list scheduling heuristic\nthat takes into account power and reliability before deciding which task to assign and to duplicate onto the next free\nprocessors. The complexity of this heuristic is unfortunately exponential in the number of processors. Future work\nwill be devoted to compare our heuristics to TSH, and hence to compare re-execution with replication.\nGiven an application with dependence constraints and a mapping of this application on a homogeneous platform,\nwe present in this paper theoretical results and tri-criteria heuristics that use re-execution in order to minimize the\nenergy consumption under the constraints of both a reliability threshold per task and a deadline bound. The first\ncontribution is a formal model for this tri-criteria scheduling problem (Section 2). The second contribution is to\nprovide theoretical results for the different speed models, C ONTINUOUS (Section 3) and V DD -H OPPING (Section 4).\nThe third contribution is the design of novel tri-criteria scheduling heuristics that use re-execution to increase the\nreliability of a system under the C ONTINUOUS model (Section 5), and their evaluation through extensive simulations\n(Section 6). To the best of our knowledge, this work is the first attempt to propose practical solutions to this tri-criteria\nproblem. Finally, we give concluding remarks and directions for future work in Section 7.\n\n2\n\nThe tri-criteria problem\n\nConsider an application task graph G = (V, E), where V = {T1 , T2 , . . . , Tn } is the set of tasks, n = |V |, and where\nE is the set of precedence edges between tasks. For 1 \u2264 i \u2264 n, task Ti has a weight wi , that corresponds to the\ncomputation requirement of the task. We also consider particular class of task graphs, such as linear chains where\nn\nE = \u222an\u22121\ni=1 {Ti \u2192 Ti+1 }, and forks with n + 1 tasks {T0 , T1 , T2 , . . . , Tn } and E = \u222ai=1 {T0 \u2192 Ti }.\nWe assume that tasks are mapped onto a parallel platform made up of p identical processors. Each processor has a\nset of available speeds that is either continuous (in the interval [fmin , fmax ]) or discrete (with m modes {f1 , * * * , fm }),\ndepending on the speed model (C ONTINUOUS or V DD -H OPPING). The goal is to minimize the energy consumed\nduring the execution of the graph while enforcing a deadline bound and matching a reliability threshold. To match the\nreliability threshold, some tasks are executed once at a speed high enough to satisfy the constraint, while some other\ntasks need to be re-executed. We detail below the conditions that are enforced on the corresponding execution speeds.\nThe problem is therefore to decide which task to re-execute, and at which speed to run each execution of a task.\nIn this section, for the sake of clarity, we assume that a task is executed at the same (unique) speed throughout\nexecution, or at two different speeds in the case of re-execution. In Section 3, we show that this strategy is indeed\noptimal for the C ONTINUOUS model; in Section 4, we show that only two different speeds are needed for the V DD H OPPING model (and we update the corresponding formulas accordingly). We now detail the three objective criteria\n(makespan, reliability, energy), and then define formally the problem.\n\n2.1\n\nMakespan\n\nThe makespan of a schedule is its total execution time. The first task is scheduled at time 0, so that the makespan\nof a schedule is simply the maximum time at which one of the processors finishes its computations. We consider a\ndeadline bound D, which is a constraint on the makespan.\n\n3\n\n\fLet Exe(wi , f ) be the execution time of a task Ti of weight wi at speed f . We assume that the cache size is adapted\nto the application, therefore ensuring that the execution time is linearly related to the frequency [14]: Exe(wi , f ) =\nwi\n(1)\nand f (2) , we always account for both\nf . When a task is scheduled to be re-executed at two different speeds f\ni\ni\nexecutions, even when the first execution is successful, and hence Exe(wi , f (1) , f (2) ) = fw(1)\n+ fw(2)\n. In other words,\nwe consider a worst-case execution scenario, and the deadline D must be matched even in the case where all tasks that\nare re-executed fail during their first execution.\n\n2.2\n\nReliability\n\nTo define the reliability, we use the fault model of Zhu et al. [25, 24]. Transient failures are faults caused by software\nerrors for example. They invalidate only the execution of the current task and the processor subject to that failure will\nbe able to recover and execute the subsequent task assigned to it (if any). In addition, we use the reliability model\nintroduced by Shatz and Wang [21], which states that the radiation-induced transient faults follow a Poisson distribution. The parameter \u03bb of the Poisson distribution is then:\nf\n\n\u2212f\n\nd \u0303 max\n\u03bb(f ) = \u03bb \u03030 e fmax \u2212fmin ,\n\n(1)\n\nwhere fmin \u2264 f \u2264 fmax is the processing speed, the exponent d \u0303 \u2265 0 is a constant, indicating the sensitivity of fault\nrates to DVFS, and \u03bb \u03030 is the average fault rate corresponding to fmax . We see that reducing the speed for energy saving\nincreases the fault rate exponentially. The reliability of a task Ti executed once at speed f is Ri (f ) = e\u2212\u03bb(f )\u00d7Exe(wi ,f ) .\nBecause the fault rate is usually very small, of the order of 10\u22126 per time unit in [5, 17], 10\u22125 in [1], we can use the\nfirst order approximation of Ri (f ) as\nwi\nwi\nd \u0303 fmax \u2212f\n= 1 \u2212 \u03bb0 e\u2212df \u00d7\n,\nRi (f ) = 1 \u2212 \u03bb(f ) \u00d7 Exe(wi , f ) = 1 \u2212 \u03bb \u03030 e fmax \u2212fmin \u00d7\nf\nf\n\n(2)\n\nd \u0303\nand \u03bb0 = \u03bb \u03030 edfmax . This equation holds if \u03b5i = \u03bb(f ) \u00d7 wfi \u001c 1. With, say, \u03bb(f ) = 10\u22125 , we\nwhere d = fmax \u2212f\nmin\nwi\n3\nneed f \u2264 10 to get an accurate approximation with \u03b5i \u2264 0.01: the task should execute within 16 minutes. In other\nwords, large (computationally demanding) tasks require reasonably high processing speeds with this model (which\nmakes full sense in practice).\nWe want the reliability Ri of each task Ti to be greater than a given threshold, namely Ri (frel ), hence enforcing\na local constraint dependent on the task Ri \u2265 Ri (frel ). If task Ti is executed only once at speed f , then the reliability\nof Ti is Ri = Ri (f ). Since the reliability increases with speed, we must have f \u2265 frel to match the reliability\nconstraint. If task Ti is re-executed (speeds f (1) and f (2) ), then the execution of Ti is successful if and only if both\nattempts do not fail, so that the reliability of Ti is Ri = 1 \u2212 (1 \u2212 Ri (f (1) ))(1 \u2212 Ri (f (2) )), and this quantity should be\nat least equal to Ri (frel ).\n\n2.3\n\nEnergy\n\nThe total energy consumption corresponds to the sum of the energy consumption of each task. Let Ei be the energy\nconsumed by task Ti . For one execution of task Ti at speed f , the corresponding energy consumption is Ei (f ) =\nExe(wi , f ) \u00d7 f 3 = wi \u00d7 f 2 , which corresponds to the dynamic part of the classical energy models of the literature [4,\n6, 8, 3]. Note that we do not take static energy into account, because all processors are up and alive during the whole\nexecution.\nIf task Ti is executed only once at speed f , then Ei = Ei (f ). Otherwise, if task Ti is re-executed at speeds f (1)\nand f (2) , it is natural to add up the energy consumed during both executions, just as we add up both execution times\nwhen enforcing the makespan deadline. Again, this corresponds to the worst-case execution scenario. We obtain\n(1)\n(2)\nEi = Ei (fi ) + Ei (fi ). Note that some authors [24] consider only the energy spent for the first execution, which\nseems unfair: re-execution comes at a price both in the deadline and inPthe energy consumption. Finally, the total\nn\nenergy consumed by the schedule, which we aim at minimizing, is E = i=1 Ei .\n\n4\n\n\f2.4\n\nOptimization problems\n\nThe two main optimization problems are derived from the two different speed models:\n\u2022 T RI -C RIT-C ONT. Given an application graph G = (V, E), mapped onto p homogeneous processors with\ncontinuous speeds, T RI -C RIT-C ONT is the problem of deciding which tasks should be re-executed and at which\nspeed each execution of a task should be processed, in order to minimize the total energy consumption E, subject\nto the deadline bound D and to the local reliability constraints Ri \u2265 Ri (frel ) for each Ti \u2208 V .\n\u2022 T RI -C RIT-V DD. This is the same problem as T RI -C RIT-C ONT, but with the V DD -H OPPING model.\nWe also introduce variants of the problems for particular application graphs: T RI -C RIT-C ONT-C HAIN is the same\nproblem as T RI -C RIT-C ONT when the task graph is a linear chain, mapped on a single processor; and T RI -C RITC ONT-F ORK is the same problem as T RI -C RIT-C ONT when the task graph is a fork, and each task is mapped on a\ndistinct processor. We have similar definitions for the V DD -H OPPING model.\n\n3\n\nC ONTINUOUS model\n\nAs stated in Section 2, we start by proving that with the C ONTINUOUS model, it is always optimal to execute a task at\na unique speed throughout its execution:\nLemma 1. With the C ONTINUOUS model, it is optimal to execute each task at a unique speed throughout its execution.\nThe idea is to consider a task whose speed changes during the execution; we exhibit a speed such that the execution\ntime of the task remains the same, but where both energy and reliability are potentially improved, by convexity of the\nfunctions.\nProof. We can assume without loss of generality that the function that gives the speed of the execution of a task is a\npiecewise-constant function. The proof of the general case is a direct corollary from the theorem that states that any\npiecewise-continuous function defined on an interval [a, b] can be uniformly approximated as closely as desired by a\npiecewise-constant function [20].\nSuppose that in the optimal solution, there is a task whose speed changes during the execution. Consider the first\ntime-step at which the change occurs: the computation begins at speed f from time t to time t0 , and then continues at\nspeed f 0 until time t00 . The total energy consumption for this task in the time interval [t, t00 ] is E = (t0 \u2212t)\u00d7f 3 +(t00 \u2212\nt0 ) \u00d7 (f 0 )3 . Moreover, the\u0010amount of work done for this task is W \u0011= (t0 \u2212 t) \u00d7 f + (t00 \u2212 t0 ) \u00d7 f 0 . The reliability of\n0\n\nthe task is exactly 1 \u2212 \u03bb0 (t0 \u2212 t) \u00d7 e\u2212df + (t00 \u2212 t0 ) \u00d7 e\u2212df + r , where r is a constant due to the reliability of the\n\nrest of the process, which is independent from what happens during [t, t00 ]. The reliability is a function that increases\n0\nwhen the function h(t, t0 , t00 , f, f 0 ) = (t0 \u2212 t) \u00d7 e\u2212df + (t00 \u2212 t0 ) \u00d7 e\u2212df decreases.\n00\nIf we run the task during the whole interval [t, t ] at constant speed fd = W/(t00 \u2212 t), the same amount of work\nis done within the same time, and the energy consumption during this interval of time becomes E 0 = (t00 \u2212 t) \u00d7 fd3 .\n0\nNote that the new speed can be expressed as fd = af + (1 \u2212 a)f 0 , where 0 < a = tt00\u2212t\n\u2212t < 1. Therefore, because\nof the convexity of the function x 7\u2192 x3 , we have E 0 < E. Similarly, since x 7\u2192 e\u2212dx is a convex function,\nh(t, t0 , t00 , fd , fd ) < h(t, t0 , t00 , f, f 0 ), and the reliability constraint is also matched. This contradicts the hypothesis of\noptimality of the first solution, and concludes the proof.\nNext we show that not only a task is executed at a single speed, but that its re-execution (whenever it occurs) is\nexecuted at the same speed as its first execution:\nLemma 2. With the C ONTINUOUS model, it is optimal to re-execute each task (whenever needed) at the same speed\n(inf)\nas its first execution, and this speed f is such that fi\n\u2264 f < \u221a12 frel , where\n(inf)\n\n\u03bb0 wi\n\ne\u22122dfi\n\n(inf) 2\n)\n\n(fi\n\n5\n\n=\n\ne\u2212dfrel\n.\nfrel\n\n(3)\n\n\fSimilarly to the proof of Lemma 1, we exhibit a unique speed for both executions, in case they differ, so that the\nexecution time remains identical but both energy and reliability are improved. If this unique speed is greater than\n(inf)\n\u221a1 frel , then it is better to execute the task only once at speed frel , and if f is lower than f\n, then the reliability\ni\n2\nconstraint is not matched.\nProof. Consider a task Ti executed a first time at speed fi , and a second time at speed fi0 > fi . Assume first that\nd = 0, i.e., the reliability of task Ti executed at speed fi is Ri (fi ) = 1 \u2212 \u03bb0 wfii . We show that executing task Ti\np\ntwice at speed f = fi fi0 improves the energy consumption while matching the deadline and reliability constraints.\nClearly the reliability constraint is matched, since 1 \u2212 \u03bb20 wi2 f12 = 1 \u2212 \u03bb20 wi2 fi1f 0 . The fact that the deadline constraint\ni\np\n2fi fi0\n0 2\nis matched is due to the fact that fi fi0 \u2265 fi +f\n\u2265 0).\n0 (by squaring both sides of the equation we obtain (fi \u2212 fi )\n2f f 0\n\ni\n\ni i\n2wi\nwi\nwi\nThen we use the fact that fd = fi +f\n0 is the minimal speed such that \u2200f \u2265 fd ,\nf < fi + fi0 . Finally, it is easy to\ni\nsee that the energy consumption is improved since 2fi fi0 \u2264 fi2 + fi02 , hence 2wi fi fi0 \u2264 wi fi2 + wi fi02 .\nIn the general case when d 6= 0, instead of having a closed form formula for the new speed f common to both\nexecutions, we have f = max(f1 , f2 ), where f1 is dictated by the reliability constraint, while f2 is dictated by the\ndeadline constraint. f1 is the solution to the equation 2(dX +ln X) = (dfi +ln fi )+(dfi0 +ln fi0 ); this equation comes\n\u2212dfi\n\nfrom the reliability constraint: the minimum speed X to match the reliability is obtained with 1 \u2212 \u03bb20 wi2 e fi\n2fi fi0\nfi +fi0\n\n\u22122dX\n\u03bb20 wi2 e X 2 .\n\n0\n\ne\u2212dfi\nfi0\n\n=\n\n(minimum speed to match the\n1\u2212\nThe deadline constraint must also be enforced, and hence f2 =\ndeadline). Then the fact that the energy does not increase comes from the convexity of this function.\nLet f be the unique speed at which the task is executed (twice). If f \u2265 \u221a12 frel , then executing the task only once\nat speed frel has a lower energy consumption and execution time, while still matching the reliability constraint. Hence\n(inf)\nit is not optimal to re-execute the task unless f < \u221a12 frel . Finally, note that f must be greater than fi\n, solution of\n(inf)\n\nEquation (3), since fi\nat the same speed.\n\nis the minimum speed such that the reliability constraint is met if task Ti is executed twice\n\nNote that both lemmas can be applied to any solution of the T RI -C RIT-C ONT problem, not just optimal solutions,\nhence all heuristics of Section 5 will assign a unique speed to each task, be it re-executed or not.\nWe are now ready to assess the problem complexity:\nTheorem 1. The T RI -C RIT-C ONT-C HAIN problem is NP-hard, but not known to be in NP.\nNote that the problem is not known to be in NP because speeds could take any real values (C ONTINUOUS model).\nThe completeness comes from SUBSET-SUM [11]. The problem is NP-hard even for a linear chain application\nmapped on a single processor (and any general DAG mapped on a single processor becomes a linear chain).\nProof. Consider the associated decision problem: given a deadline, and energy and reliability bounds, can we schedule\nthe graph to match all these bounds? Since the speeds could take any real values, the problem is not known to be in\nNP. For the completeness, we use a reduction from SUBSET-SUM [11]. Let I1 be an instance of SUBSET-SUM:\ngivenPn strictly positive integers\nPn a1 , . . . , an , and a positive integer X, does there exist a subset I of {1, . . . , n} such\nthat i\u2208I ai = X? Let S = i=1 ai .\nWe build the following instance I2 of our problem. The execution graph is a linear chain with n tasks, where:\n\u2022 task Ti has weight wi = ai ;\nmax\n\u2022 \u03bb0 = 100fmax\n;\n\u221a i ai\n1\n\u2022 fmin = \u03bb0 maxi ai fmax = 10\nfmax ;\n\u2022 frel = fmax ; d = 0.\nThe bounds on reliability, deadline and energy are:\n\u2022 Ri0 = Ri (frel ) = 1 \u2212 \u03bb0 fwreli for 1 \u2264 i \u2264 n;\nS\n\u2022 D0 = frel\n+ cfXrel , where c is the unique positive real root of the polynomial 7y 3 + 21y 2 \u2212 3y \u2212 1. Analytically,\nq\nwe derive that c = 4 27 cos 13 (\u03c0 \u2212 tan\u22121 \u221a17 ) \u2212 1 (\u2248 0.2838); but this value is irrational, so have to we encode\nit symbolically rather than numerically;\n6\n\n\f2c\n2\nfrel )2 + (S \u2212 X)frel\n.\n1+c\nClearly, the size of I2 is polynomial in the size of I1 .\n\u2022 E0 = 2X(\n\n2c\nfrel . Otherwise,\nSuppose first that instance I1 has a solution, I. For all i \u2208 I, Ti is executed twice at speed\n1\nP\nP + c ai\nai\nfor all i \u2208\n/ I, it is executed only once at speed frel . The execution time is i\u2208I\n= S\u2212X\n/ frel +\ni\u2208I 2 2c f\nfrel +\n1+c\n\nrel\n\n1+c\n= D0 . The reliability constraint is obviously met for tasks not in I. It is also met for all tasks in I, since\n2X 2cf\nrel\n2c\na2\nfrel > fmin , and two executions at fmin are sufficient to match the reliability constraint. Indeed, 1 \u2212 \u03bb20 f 2i =\nmin\n1+c\nai\nai\n0\ni\n1 \u2212 \u03bb0 farel\n\u2265\n1\n\u2212\n\u03bb\n=\nR\n.\nThe\nenergy\nconsumption\nis\nexactly\nE\n.\nAll\nbounds\nare\nrespected,\nand\ntherefore\n0 frel\n0\ni\nmaxi ai\nwe have a solution to I2 .\nP\nSuppose now that I2 has a solution. Let I = {i | Ti is executed twice in the solution}, and Y = i\u2208I ai . We\nprove in the following that necessarily Y = X, since the energy constraint E0 is respected in I2 .\nWe first point out that tasks executed only once are necessarily executed at maximum speed to match the reliability\nconstraint. Then consider the problem of minimizing the energy of a set of tasks, some executed twice, some executed\nonce at maximum speed, and assume that we have a deadline D0 to match, but no constraint on reliability or on fmin .\nWe will verify later that these additional two constraints are indeed satisfied by the optimal solution when the only\nconstraint is the deadline. Thanks to Lemma 2, for all i \u2208 I, task Ti is executed twice at the same speed. It is easy\nto see that in fact all tasks in I are executed at the same speed, otherwise we could decrease the energy consumption\nwithout modifying the execution time, by convexity of the function. Let f be the speed of execution (and re-execution)\nof task Ti , with i \u2208 I. Because the deadline is the only constraint, either Y = 0 (no tasks are re-executed), or it is\noptimal to exactly match the deadline D0 (otherwise we could just slow down all the re-executed tasks and this would\ndecrease the total energy). Hence the problem amounts to find the values of Y and f that minimize the function\n2\nE = 2Y f 2 + (S \u2212 Y )frel\n, with the constraint (S \u2212 Y )/frel + 2Y /f \u2264 D0 . First, note that if Y = 0 then\nE > E0 , and hence Y > 0 (since it corresponds to a solution of I2 ). Therefore, since the deadline is tight, we have\nf = D0 frel2Y\n\u2212(S\u2212Y ) frel , and finally the energy consumption can be expressed as\n\n\u0012\nE(Y ) =\n\n\u0013\n(2Y )3\n2\n+\n(S\n\u2212\nY\n)\nfrel\n.\n(D0 frel \u2212 (S \u2212 Y ))2\n\nWe aim at finding the minimum of this function. Let \u1ef8 =\n\nY\n\nD0 frel \u2212S . Then we have E(\u1ef8 ) =\n\n\u0010\n\n(2\u1ef8 )3\n(1+\u1ef8 )2\n\n\u0011\nS\n+ ( D0 frel\n\u2212\n\u1ef8\n)\n\u00d7\n\u2212S\n\n2\n. Differentiating, we obtain\n(D0 frel \u2212 S)frel\n\n0\n\nE (\u1ef8 ) =\n\n!\n3 \u00d7 23 \u1ef8 2\n24 \u1ef8 3\n2\n\u2212\n\u2212 1 (D0 frel \u2212 S)frel\n.\n(1 + \u1ef8 )2\n(1 + \u1ef8 )3\n\nFinally, E 0 (\u1ef8 ) = 0 if and only if\n24\u1ef8 2 (1 + \u1ef8 ) \u2212 16\u1ef8 3 \u2212 (1 + \u1ef8 )3 = 0.\n\n(4)\n\nThe only positive solution of Equation (4) is \u1ef8 = c, and therefore the unique minimum of E(Y ) is obtained for\nY = c(D0 frel \u2212 S) = X.\nNote that for Y = X, we have E = E0 , and therefore any other value of Y would not correspond to a solution.\nThere remains to check that the solution matches both constraints on fmin and on reliability, to confirm the hypothesis\non the speed of tasks that are re-executed. Using the same argument as in the first part of the proof, we see that\nthe reliability constraint is respected when a task is executed twice at fmin , and therefore we just need to check that\n2c\nf \u2265 fmin . For Y = X, we\nP have f = 1+c frel > fmin .\nAltogether, we have i\u2208I ai = Y = X, and therefore I1 has a solution. This concludes the proof.\nEven if T RI -C RIT-C ONT-C HAIN is NP-hard, we can characterize an optimal solution of the problem:\n\n7\n\n\fProposition 1. If frel < fmax , thenPin any optimal solution of T RI -C RIT-C ONT-C HAIN, either all tasks are executed\nn\nwi\n, frel ); or at least one task is re-executed, and then all tasks that are not\nonly once, at constant speed max( i=1\nD\nre-executed are executed at speed frel .\nProof. Consider an optimal schedule.\nIf all tasks are executed\nonly once, the smallest energy consumption is obtained\nPn\nPn\ni=1 wi\ni=1 wi\n. However if\n< frel , then we have to execute all tasks at speed frel\nwhen using the constant speed\nD\nD\nto match both reliability and deadline constraints.\nNow, assume that some task Ti is re-executed, and assume by contradiction, that some other task Tj is executed\nonly once at speed fj > frel . Note that the common speed fi used in both executions of Ti is smaller than frel ,\notherwise we would not need to re-execute Ti . We have fi < frel < fj , and we prove that there exist values fi0 (new\nspeed of one execution of Ti ) and fj0 (new speed of Tj ) such that fi < fi0 , frel \u2264 fj0 < fj , and the energy consumed\nwith the new speeds is strictly smaller, while the execution time is unchanged. The constraint on reliability will also be\nmet, since the speed of one execution of Ti is increased, while the speed of Tj remains above the reliability threshold.\nNote that we do not modify the speed of the re-execution of Ti (that remains fi ), and the time and energy consumption\nof this execution are not accounted for in the equations. Also, we restrict to values such that fi0 \u2264 fj0 .\nOur problem writes: do there exist \u000f, \u000f0 > 0 such that\nwi fi2 + wj fj2 > wi (fi + \u000f0 )2 + wj (fj \u2212 \u000f)2 ;\nD =\n\nwj\nwj\nwi\nwi\n+\n;\n+\n=\n0\nfi\nfj\nfi + \u000f\nfj \u2212 \u000f\n\nfi < fi + \u000f0 \u2264 fj \u2212 \u000f;\nfrel \u2264 fj \u2212 \u000f < fj .\n\u0001\nWe study the function \u03c6 : \u000f 7\u2192 wi fi2 + wj fj2 \u2212 wi (fi + \u000f0 )2 + wj (fj \u2212 \u000f)2 , and we want to prove that it is\npositive. Thanks to the deadline constraint (D is the bound on the execution time of Tj plus one execution of Ti ), we\nw fj\nw (fj \u2212\u000f)\nwi\nhave fi = Dfji\u2212w\n, and fi + \u000f0 =\n.\n= D(fij \u2212\u000f)\u2212w\nwj\nj\nj\nD\u2212 f\n\nj \u2212\u000f\n\nWe can therefore express \u03c6(\u000f) as:\n\u03c6(\u000f) =\n\nwi3 fj2\nwi3 (fj \u2212 \u000f)2\n\u2212\n+ wj fj2 \u2212 wj (fj \u2212 \u000f)2 .\n(Dfj \u2212 wj )2\n(D(fj \u2212 \u000f) \u2212 wj )2\n\nMoreover, we study the function for \u000f > 0, and because of the constraint on new speeds, \u000f \u2264 fj \u2212 frel . Another\nbound on \u000f is obtained from the fact that fi + \u000f0 \u2264 fj \u2212 \u000f, and the equality is obtained when both tasks are running at\nw +w\nw +w\nspeed i D j , thus meeting the deadline. Hence, fj \u2212 \u000f \u2265 i D j , and finally\n\u0012\n\u0013\nwi + wj\n0 < \u000f \u2264 fj \u2212 max frel ,\n.\nD\nDifferentiating, we obtain\n\u03c60 (\u000f) =\n\n2wi3 (fj \u2212 \u000f)\n2Dwi3 (fj \u2212 \u000f)2\n\u2212\n+ 2wj (fj \u2212 \u000f).\n2\n(D(fj \u2212\u000f)\u2212wj )\n(D(fj \u2212\u000f)\u2212wj )3\n\nWe are looking for \u000f such that \u03c60 (\u000f) = 0, hence obtaining the polynomial\nX3 \u2212\n\nwi3\n= 0,\nwj3\n\n(D(fj \u2212\u000f)\u2212wj )3\nD(fj \u2212\u000f)\u2212wj\n, and defining X =\n. The only real solution to\nwj\nwj4 (fj \u2212\u000f)\nwi +wj\ncorresponds to \u000f = fj \u2212 D . Therefore, the only extremum of the function \u03c6 is\n\nby multiplying each side of the equation by\nthis polynomial is X =\n\nwi\nwj ,\n\nthat\n\n8\n\n\fobtained for this value of \u000f, which corresponds to executing both tasks at the same speed. Because of the convexity\nof the energy consumption, this value corresponds to a maximum of function \u03c6 (see for instance Proposition 2 in [3]),\nsince the energy is minimized when\u0012both tasks run at\u0013the same speed. Therefore, \u03c6 is strictly increasing for 0 \u2264 \u000f \u2264\nwi + wj\nw +w\n, \u03c6 is maximal (with regards to our constraints), and \u03c6(\u000f) > 0.\nfj \u2212 i D j , and for \u000f = fj \u2212 max frel ,\nD\nw (f \u2212\u000f)\n\nj\nAltogether, this value of \u000f gives us two new speeds fi0 = D(fij \u2212\u000f)\u2212w\nand fj0 = fj \u2212 \u000f that strictly improve the\nj\nenergy consumption of the schedule, while the constraints on deadline and reliability are still enforced. However, the\noriginal schedule was supposed to be optimal, we have a contradiction, which concludes the proof.\n\nIn essence, Proposition 1 states that when dealing with a linear chain, we should firstPslow down the execution\nn\nwi\nof each task as much as possible. Then, if the deadline is not too tight, i.e., if frel > i=1\n, there remains the\nD\npossibility to re-execute some of the tasks (and of course it is NP-hard to decide which ones). Still, this general\nprinciple \"first slow-down and then re-execute\" will guide the design of type A heuristics in Section 5.\nWhile the general T RI -C RIT-C ONT problem is NP-hard even with a single processor, the particular variant T RI C RIT-C ONT-F ORK can be solved in polynomial time:\nTheorem 2. The T RI -C RIT-C ONT-F ORK problem can be solved in polynomial time.\nThe difficulty to provide an optimal algorithm for the T RI -C RIT-C ONT-F ORK problem comes from the fact that\nthe total execution time must be shared between the source of the fork, T0 , and the other tasks that all run in parallel.\nIf we know D0 , the fraction of the deadline allotted for tasks T1 , . . . , Tn once the source has finished its execution,\nthen we can decide which tasks are re-executed and all execution speeds.\nProof. We start by showing that T RI -C RIT-C ONT can be solved in polynomial time for one single task, and then for\nn independent tasks, before tackling the problem T RI -C RIT-C ONT-F ORK.\nT RI -C RIT-C ONT for a single task on one processor can be solved in polynomial time. When there is a single\ntask T of weight w, the solution depends on the deadline D:\n1. if D <\n\nw\nfmax\n\n= D(0) , then there is no solution;\n\n2. if\n\nw\nfmax\n\n3. if\n\nw\nfrel\n\n4. if\n\n\u221a\n2 2w\nfrel\n\n<D\u2264\n\n5. if\n\n2w\nf (inf)\n\n< D, then T is executed twice at speed f (inf) , the minimum energy is 2wf (inf)2 .\n\nw\nfrel\n\n\u2264D\u2264\n<D\u2264\n\n\u221a\n2 2w\nfrel\n\n= D(1) , then T is executed once at speed\n\nw\nD,\n\nthe minimum energy is w3 \u00d7\n\n1\nD2 ;\n\n2\n;\n= D(2) , then T is executed once at speed frel , the minimum energy is wfrel\n\n2w\nf (inf)\n\n= D(3) , then T is executed twice at speed\n\n2w\nD ,\n\nthe minimum energy is (2w)3 \u00d7\n\n1\nD2 ;\n\nThese results are a direct consequence from the deadline and reliability constraints. With a deadline smaller than D(0) ,\nthe task cannot be executed within the deadline, even at speed fmax . The bound D(2) comes from Lemma 2, which\nstates that we need to have enough time to execute the task twice at a speed lower than \u221a12 frel before re-executing it.\nTherefore, the task is executed only once for smaller deadlines, either at speed w/D, or at speed frel if w/D < frel .\nFor larger deadlines, the task is re-executed, either at speed 2w/D, or at speed f (inf) if 2w/D < f (inf) , since the\nre-execution speed cannot be lower than f (inf) (see Lemma 2).\nT RI -C RIT-C ONT for n independent tasks on n processors can be solved in polynomial time. For n independent\ntasks mapped on n distinct processors, decisions for each task can be made independently, and we simply solve n times\nthe previous single task problem. The minimum energy is the sum of the minimum energies obtained for each task.\n\n9\n\n\fT RI -C RIT-C ONT-F ORK. For a fork, we need to decide how to share the deadline between the source T0 of the\nfork and the other tasks (i.e., n independent tasks on n processors). We search the optimal values D1 and D2 such\nthat D1 + D2 = D, and the energy of executing T0 within deadline D1 plus the energy of executing all other tasks\nwithin D2 is minimum. Therefore, we just need to find the optimal value for D2 (since D1 = D \u2212 D2 ), and reuse\nprevious results for independent tasks.\n(0)\n(1)\n(2)\n(3)\nIndependently of D, we can define for each task Ti four values Di , Di , Di and Di , as in the case of a single\n(0)\n(0)\ntask. There is a solution if and only if max1\u2264i\u2264n Di \u2264 D2 \u2264 D \u2212 D0 . Then, the energy consumption depends\n(j)\n(j)\nupon the intervals delimited by values D \u2212 D0 and Di , for 1 \u2264 i \u2264 n and j = 1, 2, 3. Within an interval, the\n1\nenergy consumed by the source is either a constant, or a constant times (D\u2212D\n2 , and the energy consumed by task Ti\n2)\n1\n(1 \u2264 i \u2264 n) is either a constant, or a constant times D2 . All the constants are known, only dependent of Ti , and\n2\nthey are obtained by the algorithm that gives the optimal solution to T RI -C RIT-C ONT for a single task. To obtain the\n(j)\n(j)\nintervals, we sort the 4n values of Di (i > 0) and the four values of D \u2212 D0 , with j = 0, 1, 2, 3, and rename these\n4(n + 1) values as dk , with 1 \u2264 k \u2264 4(n + 1) and dk \u2264 dk+1 . Given the bounds on D2 , we consider the intervals\n(0)\n(0)\nof the form [dk , dk+1 ], with dk \u2265 max1\u2264i\u2264n Di , and dk+1 \u2264 D \u2212 D0 . On each of these intervals, the energy\n0\nK\nK\n00\n0\n00\nfunction is (D\u2212D\nare positive constants that can be obtained in polynomial time\n2 + D 2 + K , where K, K and K\n2)\n2\nby the solution to T RI -C RIT-C ONT for a single task. Finding a minimum to this function on the interval [dk , dk+1 ]\ncan be done in polynomial time:\n\u2022 the first derivative of this function is\n\n2K\n(D\u2212D2 )3\n\n\u2212\n\n2K 0\n;\nD23\n0\n\n6K\n6K\n\u2022 the function is convex on ]0, D[, indeed the second derivative of this function is (D\u2212D\n4 + D 4 , which is\n2)\n2\npositive on ]0, D[, and therefore on the interval [dk , dk+1 ], there is exactly one minimum to the energy function\n(dk > 0 and dk+1 < D);\n\n\u2022 the minimum is obtained either when the first derivative is equal to zero in the interval (i.e., if there is a solution\nto the equation 2KD23 \u2212 2K 0 (D \u2212 D2 )3 = 0 in [dk , dk+1 ]), or the minimum is reached at dk (resp. dk+1 ) if the\nfirst derivative is positive (resp. negative) on the interval.\nThere are O(n) intervals, and it takes constant time to find the minimum energy Ek within interval [dk , dk+1 ],\nas\nexplained\nabove, by solving\nh\ni one equation. Since we have partitioned the interval of possible deadlines D2 \u2208\n(0)\n(0)\nmax1\u2264i\u2264n Di , D \u2212 D0 , and obtained the minimum energy consumption in each sub-interval, the minimum\nenergy consumption for the fork graph is mink Ek , and the value of D2 is obtained where the minimum is reached.\nOnce we know the optimal value of D2 , it is easy to reconstruct the solution, following the algorithm for a single task,\nin polynomial time.\nNote that this algorithm does not provide any closed-form formula for the speeds of the tasks, and that there is an\nintricate case analysis due to the reliability constraints.\nIf we further assume that the fork is made of identical tasks (i.e., wi = w for 0 \u2264 i \u2264 n), then we can provide\na closed-form formula. However, Proposition 2 illustrates the inherent difficulty of this simple problem, with several\ncases to consider depending on the values of the deadline, and also the bounds on speeds (fmin , fmax , frel , etc.). First,\n(inf)\nsince the tasks all have the same weight wi = w, we get rid of the fi\nintroduced above, since they are all identical\n(inf)\n(inf)\n(see Equation (3)): fi\n=f\nfor 0 \u2264 i \u2264 n. Therefore we let fmin = max(fmin , f (inf) ) in the proposition\nbelow:\nProposition 2. In the optimal solution of T RI -C RIT-C ONT-F ORK with at least three identical tasks (and hence n \u2265 2),\nthere are only three possible scenarios: (i) no task is re-executed; (ii) the n successors are all re-executed but not the\nsource; (iii) all tasks are re-executed. In each scenario, the source is executed at speed fsrc (once or twice), and the\nn successors are executed at the same speed fleaf (once or twice).\n\u0014\n\u0015\n1\n\nFor a deadline D <\n\n2w\nfmax ,\n\nthere is no solution. For a deadline D \u2208\n\n(scenario (i)) and the values of fsrc and fleaf are the following:\n10\n\n3\n\n3 )2\nw (1+2n\n2w\n\u221a\nfmax , frel\n1+n\n\n, no task is re-executed\n\n\f\u2022 if\n\u2022 if\n\n\u0010\n\n1\n2w\n1\nw\n3\nfmax \u2264 D \u2264 min fmax (1 + n ), w( frel\n1\n1\nw\n1\n3\nfmax (1 + n ) \u2264 w( frel + fmax ), then\n\n\u2013 if\n\u2013 if\n\u2022 if\n\u2022 if\n\n+ n3 ) < D \u2264\n\n1\nw 1+n 3\nfrel n 13\n1\n3\n\n\u0011\n\n1\nfmax )\n\n1\n\n1\n\nw\nfmax (1\n\n+\n\nw 1+n 3\nfrel n 13\n\n2w\nfrel ,\n\n<D\u2264\n\n, then fsrc =\n\nthen fsrc =\n\n, then fsrc = fmax and fleaf =\nw\nD (1\n\nw\nDfrel \u2212w frel\n\n1\n1\n+ n ) > w( frel\n+ fmax\n), then\n1\n1\n2w\n\u2013 if w( frel + fmax )) < D \u2264 frel , then fsrc =\n\nw\nDfmax \u2212w fmax ;\n1\n\n1\n\n+ n 3 ) and fleaf =\n\nw 1+n 3\nD n 13\n\n;\n\nand fleaf = frel ;\n\nw\nfmax (1\n\n2w\nfrel\n\n<D\u2264\n\nw\nfrel\n\n1\n(1+2n 3\n\n\u221a\n\n3\n)2\n\n1+n\n\nw\nDfrel \u2212w frel\n\nand fleaf = frel ;\n\n, then fsrc = fleaf = frel .\n\nNote that for larger values of D, depending on fmin , we can move to scenarios (ii) and (iii) with partial or total\nre-execution. The case analysis becomes even more painful, but remains feasible. Intuitively, the property that all\ntasks have the same weight is the key to obtaining analytical formulas, because all tasks have the same minimum\nspeed f (inf) dictated by Equation (3).\nProof. First, we recall preliminary results:\n\u2022 if a task is executed only once at speed f , then frel \u2264 f \u2264 fmax ;\n\u2022 if a task is re-executed, then both executions are done at the same speed f , and fmin \u2264 f <\n\n\u221a1 frel .\n2\n\nBy hypothesis, all tasks are identical: the bound on re-execution speed accounts for f (inf) as in Lemma 2, since\nwe now have fmin = max(fmin , f (inf) ). Therefore, if two tasks of same weight w have the same energy consumption\nin the optimal solution, then they are executed the same number of times (once or twice) and at the same speed(s). If\n2\n2\n, then\n, then necessarily there is one execution; and if it is lower than wfrel\nthe energy is greater than or equal to wfrel\nnecessarily there are two executions.\nFirst, we prove that in any solution, the energy consumed for the execution of each successor task, also called\nleaf, is the same. If it was not the case, since each task has the same weight, and since each leaf is independent from\nthe other and only dependent on the source of the fork, if a leaf Ti is consuming more than another leaf Tj , then we\ncould execute Ti the same number of times and at the same speed than Tj , hence matching the deadline bound and the\nreliability constraint, and obtaining a better solution. Thanks to this result, we now assume that all leaves are executed\nat the same speed(s), denoted fleaf . The source task may be executed at a different speed, fsrc .\nNext, let us show that the energy consumption of the source is always greater than or equal to that of any leaf in\nany optimal solution. First, since the source and leaves have the same weight, if we invert the execution speeds of the\nsource and of the leaves, then the reliability of each task is still matched, and so is the execution time. Moreover, the\nenergy consumption is equal to the energy consumption of the source plus n times the energy consumption of any leaf\n(recall that they all consume the same amount of energy). Hence, if the energy consumption of the source is smaller\nthan the one of the leaves, permuting those execution speeds would reduce by (n \u2212 1) \u00d7 \u2206 the energy, where \u2206 is\nthe positive difference between the two energy consumptions. Thanks to this result, we can say that the source should\nnever be executed twice if the leaves are executed only once since it would mean a lower energy consumption for the\nsource (recall that n \u2265 2).\nThis result fully characterizes the shape of any optimal solution. There are only three possible scenarios: (i)\nno task is re-executed; (ii) the n successors (leaves) are all re-executed but not the source; (iii) all tasks are reexecuted. We study independently the three scenarios, i.e., we aim at determining the values of fsrc and fleaf in each\ncase. Conditions on the deadline indicate the shape of the solution, and we perform the case analysis for deadlines\n1\n\nD\u2264\n\n3\n\n3 )2\nw (1+2n\n\u221a\nfrel\n1+n\n\n.\n\nLet us assume first that the optimal solution is such that each task is executed only once (scenario (i)). From the\nproof of Theorem 1 in [3], we obtain the optimal speeds with no re-execution and without accounting for reliability;\nthey are given by the following formulas:\n\u2022 if D < f2w\n, then there is no solution, since the tasks executed at fmax exceed the deadline;\nmax\n\u2022 if\n\n2w\nfmax\n\n\u2022 if\n\nw\nfmax (1\n\n\u2264D\u2264\n1\n\nw\nfmax (1\n\n1\n\n+ n 3 ), then fsrc = fmax and fleaf =\n\n+ n 3 ) < D, then fsrc =\n\nw\nD (1\n\nw\nDfmax \u2212w fmax ;\n1\n\n1\n\n+ n 3 ) and fleaf =\n11\n\nw 1+n 3\nD n 13\n\n.\n\n\fSince there is a minimum speed frel to match the reliability constraint, there is a condition when fleaf < frel\n, then both the source and the leaves\nthat makes an amendment on some of the items. Note that in all cases, if D > f2w\nrel\nare executed at speed frel , i.e., fsrc = fleaf = frel (recall that we consider the case with no re-execution).\n1\nw\nw\n\u2264 D \u2264 fmax\n(1 + n 3 ), then we need fleaf = Dfmax\n\u2022 If f2w\n\u2212w fmax \u2265 frel , hence the condition: D \u2264\nmax\n\u0010\n\u0011\n1\nw\n1\nw\n1\nmin fmax (1 + n 3 ), w( frel + fmax ) . In this case, fsrc = fmax and fleaf = Dfmax\n\u2212w fmax .\n\u0010\n\u0011\n1\nw\n1\n1\n\u2022 If D > min fmax\n(1 + n 3 ), w( frel\n+ fmax\n) , then the previous results do not hold anymore because of the\nconstraint on the speed of the leaves. We must further differentiate cases, depending on where the minimum is\nreached.\n1\n1\n1\nw\n(1 + n 3 ) \u2264 w( frel\n+ fmax\n), then\n\u2022 If fmax\n\u2013 if\n\nw\nfmax (1\n\nw\nD (1\n\n1\n\n1\n\n+ n3 ) < D \u2264\n1\n\nw 1+n 3\nfrel n 13 , we are in the\n1\nw 1+n 3\nD n 13 ; the upper bound\n\n+ n 3 ) and fleaf =\nbound on D guarantees that fsrc \u2264 fmax ;\n\nthird case with no reliability, and therefore fsrc =\non D guarantees that fleaf \u2265 frel , while the lower\n\n1\n\n\u2022\n\nw 1+n 3\nfrel n 13\n\n2w\nfrel , then the speed of the leaves is constrained by frel , and we obtain fleaf =\n1\nw\n3\nfrel and fsrc = Dfrel\n\u2212w frel . From the lower bound on D, we obtain fsrc < n frel , and since\n1\n1\n1\nw\n1\n3\n3\nfmax (1 + n ) \u2264 w( frel + fmax ), we have fsrc < n frel \u2264 fmax .\n1\nw\n1\n1\n1\n1\n+ fmax\n), then for w( frel\n+ fmax\n) < D \u2264 f2w\n, the leaves should be executed at\nIf fmax (1 + n 3 ) > w( frel\nrel\nw\nspeed fleaf = frel , and for the source, fsrc = Dfrel \u2212w frel . Note that the lower bound on D is equivalent to\nw\nDfrel \u2212w frel < fmax , and hence the speed of the source is not exceeding fmax .\n\n\u2013 if\n\n< D \u2264\n\n, both the source and the leaves are executed at speed frel (with no re-execution).\nAs stated above, if D > f2w\nrel\nHowever, if the deadline is larger, re-execution will be used by the optimal solution (i.e., it will become scenario (ii)).\nLet us consider therefore the scenario in which leaves are re-executed, to compare the energy consumption with the\nfirst scenario. In this case, we consider an equivalent fork in which leaves are of weight 2w, and a schedule with no\nre-execution. Then the optimal solution when there is no maximum speed is:\nfsrc =\n\n1\nw\n(1 + 2n 3 ) and\nD\n\n1\n\nfleaf =\n\nw 1 + 2n 3\n.\nD n 31\n\nIf fleaf \u2265 \u221a12 frel , then there is a better solution to the original problem without re-execution. Indeed, the solution\n0\nin which the leaves (of weight w) are executed once at speed fleaf\n= max(fleaf , frel ) is such that:\n0\n\u2022 the reliability constraint is matched (fleaf \u2265 frel );\n0\n\u2265 fleaf , and fleaf corresponds to the solution with re-execution, i.e.,\n\u2022 the deadline constraint is matched (fleaf\nw/fsrc + 2w/fleaf \u2264 D);\n0\n\u2022 the energy consumption is better, as stated by Lemma 2 if fleaf\n= frel .\n1\n\u221a\n3\n1\nw\nTherefore, we are in scenario (ii) when fleaf < \u221a2 frel , i.e., D > frel 2 1+2n\n.\n1\nn3\nMoreover, depending whether fsrc \u2265 frel or fsrc < frel :\n1\n\u2022 if fsrc \u2265 frel , i.e., D \u2264 fw\n(1 + 2n 3 ), then the solution is valid;\nrel\n2w\n\u2022 if fsrc < frel , then we must in fact have fsrc = frel , and then fleaf = max( Dfrel\n\u2212w frel , fmin ).\nNote that these values do not take into account the constraints fmax and fmin . Therefore, they are lower bounds on the\nenergy consumption when the leaves are re-executed.\nFinally, we establish a bound D0 on the deadline: for larger values than D0 , we cannot guarantee that re-execution\nwill not be used by the optimal solution, and hence we will have fully characterized the cases for deadlines smaller\nthan D0 . Since we have only computed lower bounds on energy consumption for the scenario (ii), this bound will not\nbe tight. We know that the minimum energy consumption is a function decreasing with the deadline: if D > D0 , then\nany solution for D0 is a solution for D. Let us find the minimum deadline D such that the energy when the leaves are\nre-executed is smaller than the energy when no task is re-executed.\n\n12\n\n\f\u221a 1+2n 31\nAs we have seen before, necessarily if D \u2264 fw\n2 1 , then it is better to have no re-execution, i.e., D0 \u2265\nrel\nn3\n1\n1\n\u221a\n\u221a\n1\n3\n3\nw\nw\n1+2n\n1+2n\n+ \u000f. We suppose also that D \u2264 fw\n(1 + 2n 3 ), i.e., the solution with refrel 2 n 31 . Let D = frel 2 n 13\nrel\nexecution is valid (fsrc \u2265 frel ).\n\u2022 The energy consumption when the leaves are re-executed is greater than\n1\nw3\n2\n2\n3 3\nE2 = wfsrc\n+ 2nwfleaf\n=D\n2 (1 + 2n ) .\n\u2022 With no re-execution, the deadline is large enough so that each task can be executed at speed frel , and therefore\nthe energy consumption is\n\u00132\n\u0012\n1\n1+2n 3\nw3\n2\n.\n(1\n+\nn)\nE1 = (1 + n)wfrel\n= 2 (D\u2212\u000f)\n1\n2\nn3\n\nWe now check the condition E1 \u2264 E2 :\n1\n\nw3\n2\n(1 + n)\n(D \u2212 \u000f)2\n\n1 + 2n 3\nn\n\n!2\n\u2264\n\n1\n3\n\n1\nw3\n(1 + 2n 3 )3\n2\nD\n1\n\n2\n1+n\n1 + 2n 3\n\u2264\n2\n2\n(D \u2212 \u000f) n 3\nD2\n2\n\nn 3 + 2n\nD2\n\u2264\n(D \u2212 \u000f)2\n2 + 2n\n1\n\nD\u2264\n\n3\n\nw (1 + 2n 3 ) 2\n\u221a\n= D0\nfrel\n1+n\n\n1\n\nFurthermore, note that D0 < fw\n(1 + 2n 3 ) for n > 2, hence the hypothesis that fsrc \u2265 frel is valid for the\nrel\nvalues considered. Finally, if the deadline is smaller than the threshold value D0 , then we can guarantee that the\noptimal solution will not do any re-execution. However, if the deadline is larger, we do not know what happens (but it\ncan be computed as a function of fmin , fmax and frel ).\nBeyond the case analysis itself, the result of Proposition 2 is interesting: we observe that in all cases, the source task\nis executed faster than the other tasks. This shows that Proposition 1 does not hold for general DAGs, and suggests that\nsome tasks may be more critical than others. A hierarchical approach, that categorizes tasks with different priorities,\nwill guide the design of type B heuristics in Section 5.\n\n4\n\nV DD -H OPPING model\n\nContrarily to the C ONTINUOUS model, the V DD -H OPPING model uses discrete speeds. A processor can choose\namong a set {f1 , ..., fm } of possible speeds. A task can be executed at different speeds.\nPmLet \u03b1(i,j) be the time of computation of task Ti at speed fj . The\nPmexecution 3time of a task Ti is Exe(Ti ) =\n\u03b1\n,\nand\nthe\nenergy\nconsumed\nduring\nthe\nexecution\nis\nE\n=\ni\nj=1 (i,j)\nj=1 \u03b1(i,j) fj . Finally, for the reliability, the\napproximation used in Equation (2) still holds. However,\nthe\nreliability\nof\na task is now the product of the reliabilities\nQm\nfor each time interval with constant speed, hence Ri = j=1 (1 \u2212 \u03bb0 e\u2212dfj \u03b1(i,j) ). Using a first order approximation,\nwe obtain\nm\nm\nX\nX\nRi = 1 \u2212 \u03bb0\ne\u2212dfj \u03b1(i,j) = 1 \u2212 \u03bb0\nhj \u03b1(i,j) , where hj = e\u2212dfj , 1 \u2264 j \u2264 m.\n(5)\nj=1\n\nj=1\n\nWe first show that only two different speeds are needed for the execution of a task. This result was already known\nfor the bi-criteria problem makespan/energy, and it is interesting to see that reliability does not alter it:\nProposition 3. With the V DD -H OPPING model, each task is computed using at most two different speeds.\nProof. Suppose that a task is computed with three speeds, f1 \u2264 f2 \u2264 f3 , and let hj = e\u2212dfj , for j = 1, 2, 3. We\nshow that we can get rid of one of those speeds. The proof will follow by induction. Let \u03b1i be the time spent by the\nprocessor at speed fi . We aim at replacing each \u03b1i by some \u03b1i0 so that we have a better solution. The constraints write:\n13\n\n\f1. Deadline not exceeded:\n\u03b11 + \u03b12 + \u03b13 \u2265 \u03b110 + \u03b120 + \u03b130 .\n\n(6)\n\n\u03b11 f1 + \u03b12 f2 + \u03b13 f3 = \u03b110 f1 + \u03b120 f2 + \u03b130 f3 .\n\n(7)\n\n\u03b11 h1 + \u03b12 h2 + \u03b13 h3 \u2265 \u03b110 h1 + \u03b120 h2 + \u03b130 h3 .\n\n(8)\n\n\u03b11 f13 + \u03b12 f23 + \u03b13 f33 > \u03b110 f13 + \u03b120 f23 + \u03b130 f33 .\n\n(9)\n\n2. Same amount of work:\n3. Reliability preserved:\n4. Less energy spent:\nWe show that \u03b110 = \u03b11 \u2212 \u000f1 , \u03b120 = \u03b12 + \u000f1 + \u000f3 , and \u03b130 = \u03b13 \u2212 \u000f3 is a valid solution:\n0\n0\n0\n\u2022 Equation (6) is satisfied, since\n\u0012 \u03b11 + \u03b1\u00132 + \u03b13 = \u03b11 + \u03b12 + \u03b13 .\nf3 \u2212 f2\n.\n\u2022 Equation (7) gives \u000f1 = \u000f3\nf2 \u2212 f1\n0\n\u2022 Next we replace the \u03b1i and \u000fi in Equation (8) and we obtain h2 (f3 \u2212 f1 ) \u2264 h1 (f3 \u2212 f2 ) + h3 (f2 \u2212 f1 ), which\nis always true by convexity of the exponential (since hj = e\u2212dfj ).\n\u2022 Finally, Equation (9) gives us \u000f1 f13 + \u000f3 f33 > (\u000f3 + \u000f1 )f23 , which is necessarily true since f1 < f2 < f3 and\nf \u2192 f 3 is convex (barycenter).\nSince we want all the \u03b1i0 to be nonnegative, we take\n\u0013\u0013\n\u0012\n\u0013\u0013\n\u0012\n\u0012\n\u0012\nf2 \u2212 f1\nf3 \u2212 f2\nand \u000f3 = min \u03b13 , \u03b11\n.\n\u000f1 = min \u03b11 , \u03b13\nf2 \u2212 f1\nf3 \u2212 f2\nWe have either \u000f1 = \u03b11 or \u000f3 = \u03b13 , which means that \u03b110 = 0 or \u03b130 = 0, and we can indeed compute the task\nwith only two speeds, meeting the constraints and with a smaller energy.\nWe are now ready to assess the problem complexity:\nTheorem 3. The T RI -C RIT-V DD -C HAIN problem is NP-complete.\nThe proof is similar to that of Theorem 1, assuming that there are only two available speeds, fmin and fmax . Then\nwe reduce the problem from SUBSET-SUM. Note that here again, the problem turns out to be NP-hard even with one\nsingle processor (linear chain of tasks).\nProof. Consider the associated decision problem: given an execution graph, m possible speeds, a deadline, a reliability, and a bound on the energy consumption, can we find the time each task will spend at each speed such that the\ndeadline, the reliability and the bound on energy are respected? The problem is clearly in NP: given the time spent\nin each speed for each task, computing the execution time, the reliability and the energy consumption can be done in\npolynomial time. To establish the completeness, we use a reduction from SUBSET-SUM [11]. Let I1 be an instance\nof SUBSET-SUM: given\nP n strictly positive integers\nPn a1 , . . . , an , and a positive integer X, does there exist a subset I of\n{1, . . . , n} such that i\u2208I ai = X? Let S = i=1 ai .\nWe build the following instance I2 of our problem. The execution graph is a linear chain with n tasks, where:\n\u2022 task Ti has weight wi = ai ;\n\u2022 the processor can run at m = 2 different speeds, fmin and fmax ;\nfmax\n\u2022 \u03bb0 =\n;\n100\n\u221a maxi=1..n ai\n\u2022 fmin = \u03bb0 fmax maxi=1..n ai = fmax\n10 ;\n\u2022 frel = fmax ; d = 0.\nThe bounds on reliability, deadline and energy are:\n\u2022 Ri0 = Ri (frel ) = 1 \u2212 \u03bb0 fwreli for 1 \u2264 i \u2264 n;\n\u2022 D0 = f2X\n+ S\u2212X\nfmax ;\nmin\n2\n2\n\u2022 E0 = 2Xfmin + (S \u2212 X)fmax\n.\n14\n\n\fClearly, the size of I2 is polynomial in the size of I1 .\nSuppose first that instance I1 has a solution, I. For all i \u2208 I, Ti is executed\ntwice P\nat speed fmin . Otherwise, for\nP\n2 i\u2208I ai\n\u2208I\n/ ai\n= f2X\n+ S\u2212X\nall i \u2208\n/ I, it is executed at speed fmax one time only. The execution time is fmin + fimax\nfmax = D.\nmin\nThe reliability is met for all tasks not in I, since they are executed at speed frel . It is also met for all tasks in I:\nP\nP\nx2\nwi\n2\n2\n2\n. The energy consumption is E = i\u2208I 2ai fmin\n+ i\u2208I\n\u2200i \u2208 I, 1 \u2212 \u03bb20 f 2i \u2265 1 \u2212 \u03bb0 fmax\n/ ai fmax = 2Xfmin +\nmin\n\n2\n(S \u2212 X)fmax\n= E0 . All bounds are respected, and therefore the execution speeds are a solution to I2 (and each task\nkeeps a constant speed during its whole execution).\n\nSuppose now that I2 has a solution. Since we consider the V DD -H OPPING model, each execution can be run\npartly at speed fmin , and partly at speed fmax . However, tasks executed only once are necessarily executed only at\nmaximum speed to match the reliability constraint.\nP\nLet I = {i | Ti is executed twice in the solution}. Let Y = i\u2208I ai . We have 2Y = Y1 + Y2 , where Y1 is the total\nweight of each execution and re-execution (2Y ) of tasks in I that are executed at speed fmin , and Y2 the total weight\nthat is executed at speed fmax . We show that necessarily Y1 = 2X = 2Y , i.e., no part of any task in I is executed at\nspeed fmax .\n2\n2\nFirst let us show that 2X \u2264 2Y . The energy consumption of the solution of I2 is E = Y1 fmin\n+ Y2 fmax\n+ (S \u2212\n2\n2\n2\n0\n2\n2\nY )fmax = Y1 fmin + (S \u2212 Y1 + Y )fmax . By differentiating this function (with regards to Y1 , E = fmin \u2212 fmax\n< 0),\nwe can see that the minimum is reached for Y1 = 2Y (since Y1 \u2208 [0, 2Y ]). Then, for Y1 = 2Y , since the solution is\n2\n2\n) \u2264 0, and therefore X \u2264 Y .\nsuch that E \u2264 E0 , we have E \u2212 E0 = (Y \u2212 X)(2fmin\n\u2212 fmax\nNext let us show that Y1 \u2264 2X. Suppose by contradiction that Y1 > 2X, then the execution time of the solution\nY2\nY1\nS\u2212Y1 +Y\n1\n+ fmax\n+ S\u2212Y\nof I2 is D = fYmin\nfmax = fmin +\nfmax . By differentiating this function (with regards to Y1 ), we can see\n\u000f\nit is strictly increasing when Y1 goes from 2X to 2Y . However, when Y1 = 2X + \u000f, D \u2212 D0 = fmin\n+ Y f\u2212X+\u000f\n>0\nmax\n(indeed, each value of the sum is strictly positive). Hence, Y1 \u2264 2X.\nFinally, let us show that Y1 = 2X = 2Y . Since I2 is a solution, we know that E \u2264 E0 , and therefore 2X \u2212 Y1 \u2265\nf2\n(Y + X \u2212 Y1 ) fmax\n\u2265 (Y + X \u2212 Y1 ) (the last equality is only met when Y + X \u2212 Y1 = 0). Hence 2X \u2265 X + Y ,\n2\nmin\nwhich is only possible if 2X = X + Y . This gives us the final result: Y1 = 2X = 2Y (all inequalities are tight).\nP\nWe conclude that i\u2208I ai = X, and therefore I1 has a solution. This concludes the proof.\nIn the following, we propose some polynomial time heuristics to tackle the general tri-criteria problem. While\nthese heuristics are designed for the C ONTINUOUS model, they can be easily adapted to the V DD -H OPPING model\nthanks to Proposition 3.\n\n5\n\nHeuristics for T RI -C RIT-C ONT\n\nIn this section, building upon the theoretical results of Section 3, we propose some polynomial time heuristics for the\nT RI -C RIT-C ONT problem, which was shown NP-hard (see Theorem 1). Recall that the mapping of the tasks onto\nthe processors is given, and we aim at reducing the energy consumption by exploiting re-execution and speed scaling,\nwhile meeting the deadline bound and all reliability constraints.\nThe first idea is inspired by Proposition 1: first we search for the optimal solution of the problem instance without\nre-execution, a phase that we call deceleration: we slow down some tasks if it can save energy without violating one\nof the constraints. Then we refine the schedule and choose the tasks that we want to re-execute, according to some\ncriteria. We call type A heuristics such heuristics that obey this general scheme: first deceleration then re-execution.\nType A heuristics are expected to be efficient on a DAG with a low degree of parallelism (optimal for a chain).\nHowever, Proposition 2 (with fork graphs) shows that it might be better to re-execute highly parallel tasks before\ndecelerating. Therefore we introduce type B heuristics, which first choose the set of tasks to be re-executed, and\nthen try to slow down the tasks that could not be re-executed. We need to find good criteria to select which tasks to\nre-execute, so that type B heuristics prove efficient for DAGs with a high degree of parallelism. In summary, type B\nheuristics obey the opposite scheme: first re-execution then deceleration.\nFor both heuristic types, the approach for each phase can be sketched as follows. Initially, each task is executed\nonce at speed fmax . Then, let di be the finish time of task Ti in the current configuration:\n15\n\n\fdi\n- Deceleration: We select a set of tasks that we execute at speed fdec = max(frel , maxi=1..n\nfmax ), which is the\nD\nslowest possible speed meeting both the reliability and deadline constraints.\n- Re-execution: We greedily select tasks for re-execution. The selection criterion is either by decreasing weights wi ,\nor by decreasing super-weights Wi . The super-weight of a task Ti is defined as the sum of the weights of the\ntasks (including Ti ) whose execution interval is included into Ti 's execution interval. The rationale is that the\nsuper-weight of a task that we slow down is an estimation of the total amount of work that can be slowed down\ntogether with that task, hence of the energy potentially saved: this corresponds to the total slack that can be\nreclaimed.\nWe introduce further notations before listing the heuristics:\n- SUS (Slack-Usage-Sort) is a function that sorts tasks by decreasing super-weights.\nq\n\n2c\nfrel , where c = 4 27 cos 13 (\u03c0 \u2212 tan\u22121\n- ReExec is a function that tries to re-execute the current task Ti , at speed fre-ex = 1+c\n1 (\u2248 0.2838) (note that fre-ex is the optimal speed in the proof of Theorem 1). If it succeeds, it also re-executes\nat speed fre-ex all the tasks that are taken into account to compute the super-weight of Ti . Otherwise, it does\nnothing.\n- ReExec&SlowDown performs the same re-executions as ReExec when it succeeds. But if the re-execution of the\ncurrent task Ti is not possible, it slows down Ti as much as possible and does the same for all the tasks that are\ntaken into account to compute the super-weight of Ti .\nWe now detail the heuristics:\nHfmax . In this heuristic, tasks are simply executed once at maximum speed.\nHno-reex. In this heuristic, we do not allow any re-execution, and we simply consider the possible deceleration\nof the tasks. We set a uniform speed for all tasks, equal to fdec , so that both the reliability and deadline constraints\nare matched. Note that heuristics Hfmax and Hno-reex are identical except for a constant ratio on the speeds of each\n\u0010\n\u00112\nEHfmax\nfmax\n.\nTherefore,\nthe\nenergy\nratio\nis\nalways\nequal\nto\n(for instance, if fmax = 1 and fdec = 2/3,\ntask, ffmax\nEHno-reex\nfdec\ndec\nthen the energy ratio is equal to 2.25).\nA.Greedy. This is a type A heuristic, where we first set the speed of each task to fdec (deceleration). Let GreedyList be the list of all the tasks sorted according to decreasing weights wi . Each task Ti in Greedy-List is re-executed at\nspeed fre-ex whenever possible. Finally, if there remains some slack at the end of the processing, we slow down both\nexecutions of each re-executed task as much as possible.\nA.SUS-Crit. This is a type A heuristic, where we first set the speed of each task to f dec. Let List-SW be the list of\nall tasks that belong to a critical path, sorted according to SUS. We apply ReExec to List-SW (re-execution). Finally\nwe reclaim slack for re-executed tasks, similarly to the final step of A.Greedy.\nB.Greedy. This is a type B heuristic. We use Greedy-List as in heuristic A.Greedy. We try to re-execute each\ntask Ti of Greedy-List when possible. Then, we slow down both executions of each re-executed task Ti of Greedy-List\nas much as possible. Finally, we slow down the speed of each task of Greedy-List that turn out not re-executed, as\nmuch as possible.\nB.SUS-Crit. This is a type B heuristic. We use List-SW as in heuristic A.SUS-Crit. We apply ReExec to List-SW\n(re-execution). Then we run Heuristic B.Greedy.\nB.SUS-Crit-Slow. This is a type B heuristic. We use List-SW, and we apply ReExec&SlowDown (re-execution).\nThen we use Greedy-List: for each task Ti of Greedy-List, if there is enough time, we execute twice Ti at speed fre-ex\n(re-execution); otherwise, we execute Ti only once, at the slowest admissible speed.\nBest. This is simply the minimum value over the seven previous heuristics, for reference.\nThe complexity of all these heuristics is bounded by O(n4 log n), where n is the number of tasks. The most\ntime-consuming operation is the computation of List-SW (the list of all elements belonging to a critical path, sorted\naccording to SUS).\n\n6\n\nSimulations\n\nIn this section, we report extensive simulations to assess the performance of the heuristics presented in Section 5. The\nheuristics were coded in OCaml. The source code is publicly available at [2] (together with additional results that were\nomitted due to lack of space).\n16\n\n\u221a1 )\u2212\n7\n\n\f6.1\n\nSimulation settings\n\nIn order to evaluate the heuristics, we have generated DAGs using the random DAG generation library GGEN [9].\nSince GGEN does not assign a weight to the tasks of the DAGs, we use a function that gives a random float value in\nthe interval [0, 10]. Each simulation uses a DAG with 100 nodes and 300 edges. We observe similar patterns for other\nnumbers of edges, see [2] for further information.\nWe apply a critical-path list scheduling algorithm to map the DAG onto the p processors: we assign the most urgent\nready task (with largest bottom-level) to the first available processor. The bottom-level is defined as bl(Ti ) = wi if\nTi has no successor task, and bl(Ti ) = wi + max(Ti ,Tj )\u2208E bl(Tj ) otherwise.\nWe choose a reliability constant \u03bb0 = 10\u22125 [1] (we obtain identical results with other values, see below). Each\nreported result is the average on ten different DAGs with the same number of nodes and edges, and the energy consumption is normalized with the energy consumption returned by the Hno-reex heuristic. If the value is lower than 1,\nit means that we have been able to save energy thanks to re-execution.\nWe analyze the influence of three different parameters: the tightness of the deadline D, the number of processors\np, and the reliability speed frel . In fact, the absolute deadline D is irrelevant, and we rather consider the deadline\nratio D EADLINE R ATIO = DDmin , where Dmin is the execution time when executing each task once and at maximum\nspeed fmax (heuristic Hfmax ). Intuitively, when the deadline ratio is close to 1, there is almost no flexibility and it is\ndifficult to re-execute tasks, while when the deadline ratio is larger we expect to be able to slow down and re-execute\nmany tasks, thereby saving much more energy.\n\n6.2\n\nSimulation results\n\nFirst note that with a single processor, heuristics A.SUS-Crit and A.Greedy are identical, and heuristics B.SUS-Crit\nand B.Greedy are identical (by definition, the only critical path is the whole set of tasks).\nDeadline ratio. In this set of simulations, we let p \u2208 {1, 10, 50, 70} and frel = 32 fmax . Figure 1 reports results for\np = 1 and p = 50. When p = 1, we see that the results are identical for all heuristics of type A, and identical for all\nheuristics of type B. As expected from Proposition 1, type A heuristics are better (see Figure 1a). With more processors\n(10, 50, 70), the results have the same general shape: see Figure 1b with 50 processors. When D EADLINE R ATIO is\nsmall, type B heuristics are better. When D EADLINE R ATIO increases up to 1.5, type A heuristics are closer to type\nB ones. Finally, when D EADLINE R ATIO gets larger than 5, all heuristics converge towards the same result, where all\ntasks are re-executed.\nNumber of processors. In this set of simulations, we let D EADLINE R ATIO \u2208 {1.2, 1.6, 2, 2.4} and frel = 23 fmax .\nFigure 2 confirms that type A heuristics are particularly efficient when the number of processors is small, whereas\ntype B heuristics are at their best when the number of processors is large. Figure 2a confirms the superiority of type B\nheuristics for tight deadlines, as was observed in Figure 1b.\nReliability frel . In this set of simulations, we let p \u2208 {1, 10, 50, 70} and D EADLINE R ATIO \u2208 {1, 1.5, 3}. In Figure 3,\nthere are four different curves: the line at 1 corresponds to Hno-reex and Hfmax , then come the heuristics of type A\n(that all obtain exactly the same results), then B.SUS-Crit and B.Greedy that also obtain the same results, and finally\nthe best heuristic is B.SUS-Crit-Slow. Note that B.SUS-Crit and B.Greedy return the same results because they have\nthe same behavior when D EADLINE R ATIO = 1: there is no liberty of action on the critical paths. However B.SUSCrit-Slow gives better results because of the way it decelerates the important tasks that cannot be re-executed. When\nD EADLINE R ATIO is really tight (equal to 1), decreasing the value of frel from 1 to 0.9 makes a real difference with\ntype B heuristics. We observe an energy gain of 10% when the number of processors is small (10 in Figure 3a) and of\n20% with more processors (50 in Figure 3b).\nReliability constant \u03bb0 . In Figure 4, we let \u03bb0 vary from 10\u22125 to 10\u22126 , and observe very similar results throughout\nthis range of values. Note that we did not plot Hfmax in this figure to ease the readability.\n\n17\n\n\fHfmax\nHno-reex\n\nA.SUS-Crit\nA.Greedy\n\nB.SUS-Crit-Slow\nB.SUS-Crit\n\nB.Greedy\nBest\n\n2.5\n2.5\n\n2.5\n\n2\nEg / Eg_Hno-reex\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\nEg / Eg_Hno-reex\n\nEg / Eg_Hno-reex\n\n2\n\n1\n\n1.5\n\n1.5\n\n1\n\n0.5\n\n1\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n0\n10\n\n1\n\n2\n\n3\n\n4\n\nDeadlineRatio\n\n(a) 1 processor\n\n0.5\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\nDeadlineRatio\n\n(b) 50 processors\n\nFigure 1: Comparative study when the deadline ratio varies.\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n6\nDeadlineRatio\n\n7\n\n8\n\n9\n\n10\n\n1.6\n2.4\n2.2\n\n1.4\nEg / Eg_Hno-reex\n\nEg / Eg_Hno-reex\n\n2\n1.2\n\n1\n\n1.8\n1.6\n1.4\n1.2\n1\n\n0.8\n\n0.8\n0.6\n10\n\n20\n\n30\n\n40\n50\n60\n70\nNumber of Processors\n\n80\n\n90\n\n0.6\n100\n\n(a) D EADLINE R ATIO = 1.2\n\n10\n\n20\n\n30\n\n40\n50\n60\n70\nNumber of Processors\n\n(b) D EADLINE R ATIO = 2.4\n\nFigure 2: Comparative study when the number of processors p varies.\n\n18\n\n80\n\n90\n\n100\n\n\fHfmax\nHno-reex\n\nA.SUS-Crit\nA.Greedy\n\nB.SUS-Crit-Slow\nB.SUS-Crit\n\nB.Greedy\nBest\n\n2.5\n1.1\n\n1.1\n\n1.05\n\n1\n\n2\nEg / Eg_Hno-reex\n\n0.9\n\n0.95\n\nEg / Eg_Hno-reex\n\nEg / Eg_Hno-reex\n\n1\n\n0.9\n\n1.5\n\n0.85\n\n0.7\n0.1\n\n0.7\n0.6\n\n0.8\n0.75\n\n0.8\n\n0.5\n\n1\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n0.4\n\n1\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\nf_rel\n\n0.5\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nf_rel\n\n(a) D EADLINE R ATIO = 1; 10 processors\n\n(b) D EADLINE R ATIO = 1; 50 processors\n\nFigure 3: Comparative study when the reliability frel varies.\n0\n\n1\n\n2\n\n3\n\n4\n\n1.3\n\n1.3\n\n1.2\n\n1.2\n\nEg / Eg_No-reex\n\nEg / Eg_No-reex\n\n1.4\n\n5\n6\nDeadlineRatio\n1.4\n\n1.1\n1\n\n7\n\n8\n\n9\n\n10\n\n1.1\n1\n\n0.9\n\n0.9\n\n0.8\n1e-06 2e-06 3e-06 4e-06 5e-06 6e-06 7e-06 8e-06 9e-06 1e-05\nlambda\n\n0.8\n1e-06 2e-06 3e-06 4e-06 5e-06 6e-06 7e-06 8e-06 9e-06 1e-05\nlambda\n\n(a) D EADLINE R ATIO = 1.1; 50 processors\n\n(b) D EADLINE R ATIO = 1.5; 50 processors\n\nFigure 4: Comparative study when \u03bb0 varies.\n\n6.3\n\nUnderstanding the results\n\nA.SUS-Crit and A.Greedy, and B.SUS-Crit and B.Greedy, often obtain similar results, which might lead us to underestimate the importance of critical path tasks. However, the difference between B.SUS-Crit-Slow and B.SUS-Crit\nshows otherwise. Tasks that belong to a critical path must be dealt with first.\nA striking result is the impact of both the number of processors and the deadline ratio on the effectiveness of the\nheuristics. Heuristics of type A, as suggested by Proposition 1, have much better results when there is a small number\nof processors. When the number of processors increases, there is a difference between small and large deadline ratio.\nIn particular, when the deadline ratio is small, heuristics of type B have better results. Indeed, heuristics of type A\ntry to accommodate as many tasks as possible, and as a consequence, no task can be re-executed. On the contrary,\n19\n\n\fheuristics of type B try to favor some tasks that are considered as important. This is highly profitable when the deadline\nis tight.\nNote that all these heuristics take in average less than one ms to execute on one instance, which is very reasonable.\nThe heuristics that compute the critical path (*.SUS-Crit-*) are the longest, and may take up to two seconds when there\nare few processors. Indeed, the less processors, the more edges there are in the dependence graph once the task graph\nis mapped, and hence it increases the complexity of finding the critical path. However, with more than ten processors,\nthe running time never exceeds two ms.\nAltogether we have identified two very efficient and complementary heuristics, A.SUS-Crit and B.SUS-Crit-Slow.\nTaking the best result out of those two heuristics always gives the best result over all simulations.\n\n7\n\nConclusion\n\nIn this paper, we have accounted for the energy cost associated to task re-execution in a more realistic and accurate way\nthan the best-case model used in [24]. Coupling this energy model with the classical reliability model used in [21],\nwe have been able to formulate a tri-criteria optimization problem: how to minimize the energy consumed given a\ndeadline bound and a reliability constraint? The \"antagonistic\" relation between speed and reliability renders this\ntri-criteria problem much more challenging than the standard bi-criteria (makespan, energy) version. We have stated\ntwo variants of the problem, for processor speeds obeying either the C ONTINUOUS or the V DD -H OPPING model. We\nhave assessed the intractability of this tri-criteria problem, even in the case of a single processor. In addition, we have\nprovided several complexity results for particular instances.\nWe have designed and evaluated some polynomial-time heuristics for the T RI -C RIT-C ONT problem that are based\non the failure probability, the task weights, and the processor speeds. These heuristics aim at minimizing the energy\nconsumption while enforcing reliability and deadline constraints. They rely on dynamic voltage and frequency scaling\n(DVFS) to decrease the energy consumption. But because DVFS lowers the reliability of the system, the heuristics\nuse re-execution to compensate for the loss. After running several heuristics on a wide class of problem instances,\nwe have identified two heuristics that are complementary, and that together are able to produce good results on most\ninstances. The good news is that these results bring the first efficient practical solutions to the tri-criteria optimization\nproblem, despite its theoretically challenging nature. In addition, while the heuristics do not modify the mapping of\nthe application, it is possible to couple them with a list scheduling algorithm, as was done in the simulations, in order\nto solve the more general problem in which the mapping is not already given.\nFuture work involves several promising directions. On the theoretical side, it would be very interesting to prove a\ncompetitive ratio for the heuristic that takes the best out of A.SUS-Crit and B.SUS-Crit-Slow. However, this is quite\na challenging work for arbitrary DAGs, and one may try to design approximation algorithms only for special graph\nstructures, e.g., series-parallel graphs. Still, looking back at the complicated case analysis needed for an elementary\nfork-graph with identical weights (Proposition 2), we cannot underestimate the difficulty of this problem.\nWhile we have designed heuristics for the T RI -C RIT-C ONT model in this paper, we could easily adapt them to\nthe T RI -C RIT-V DD model: for a solution given by a heuristic for T RI -C RIT-C ONT, if a task should be executed at\nthe continuous speed f , then we would execute it at the two closest discrete speeds that bound f , while matching\nthe execution time and reliability for this task. There remains to quantify the performance loss incurred by the latter\nconstraints.\nFinally, we point out that energy reduction and reliability will be even more important objectives with the advent\nof massively parallel platforms, made of a large number of clusters of multi-cores. More efficient solutions to the\ntri-criteria optimization problem (makespan, energy, reliability) could be achieved through combining replication with\nre-execution. A promising (and ambitious) research direction would be to search for the best trade-offs that can\nbe achieved between these techniques that both increase reliability, but whose impact on execution time and energy\nconsumption is very different. We believe that the comprehensive set of theoretical results and simulations given in\nthis paper will provide solid foundations for further studies, and constitute a partial yet important first step for solving\nthe problem at very large scale.\nAcknowledgments. A. Benoit and Y. Robert are with the Institut Universitaire de France. This work was supported in\npart by the ANR RESCUE project.\n\n20\n\n\fReferences\n[1] I. Assayad, A. Girault, and H. Kalla. Tradeoff exploration between reliability power consumption and execution\ntime. In Proc. of Conf. on Computer Safety, Reliability and Security (SAFECOMP), Washington, DC, USA,\n2011. IEEE CS Press.\n[2] G. Aupy. Source code and data. http://gaupy.org/tri-criteria-scheduling, 2012.\n[3] G. Aupy, A. Benoit, F. Dufoss\u00e9, and Y. Robert. Reclaiming the energy of a schedule: models and algorithms.\nConcurrency and Computation: Practice and Experience, 2012. Also available as INRIA research report 7598\nat gaupy.org. Short version appeared in SPAA'11.\n[4] H. Aydin and Q. Yang. Energy-aware partitioning for multiprocessor real-time systems. In Proc. of Int. Parallel\nand Distributed Processing Symposium (IPDPS), pages 113\u2013121. IEEE CS Press, 2003.\n[5] M. Baleani, A. Ferrari, L. Mangeruca, A. Sangiovanni-Vincentelli, M. Peri, and S. Pezzini. Fault-tolerant platforms for automotive safety-critical applications. In Proc. of Int. Conf. on Compilers, Architectures and Synthesis\nfor Embedded Systems, pages 170\u2013177. ACM Press, 2003.\n[6] N. Bansal, T. Kimbrel, and K. Pruhs. Speed scaling to manage energy and temperature. Journal of the ACM,\n54(1):1 \u2013 39, 2007.\n[7] P. Brucker. Scheduling Algorithms. Springer, 2007.\n[8] J.-J. Chen and T.-W. Kuo. Multiprocessor energy-efficient scheduling for real-time tasks. In Proc. of Int. Conf.\non Parallel Processing (ICPP), pages 13\u201320. IEEE CS Press, 2005.\n[9] D. Cordeiro, G. Mouni\u00c3 c , S. Perarnau, D. Trystram, J.-M. Vincent, and F. Wagner. Random graph generation\nfor scheduling simulations. In Proc. of 3rd Int. ICST Conf. on Simulation Tools and Techniques (SIMUTools\n2010), page 10, mar 2010.\n[10] V. Degalahal, L. Li, V. Narayanan, M. Kandemir, and M. J. Irwin. Soft errors issues in low-power caches. IEEE\nTrans. Very Large Scale Integr. Syst., 13:1157\u20131166, October 2005.\n[11] M. R. Garey and D. S. Johnson. Computers and Intractability; A Guide to the Theory of NP-Completeness. W.\nH. Freeman & Co., New York, NY, USA, 1990.\n[12] A. Girault, E. Saule, and D. Trystram. Reliability versus performance for critical applications. J. Parallel Distrib.\nComput., 69:326\u2013336, March 2009.\n[13] S. Lee and T. Sakurai. Run-time voltage hopping for low-power real-time systems. In Proc. of Annual Design\nAutomation Conf. (DAC), pages 806\u2013809, 2000.\n[14] R. Melhem, D. Mosse, and E. Elnozahy. The interplay of power management and fault recovery in real-time\nsystems. IEEE Trans. on Computers, 53:2004, 2003.\n[15] S. Miermont, P. Vivet, and M. Renaudin. A Power Supply Selector for Energy- and Area-Efficient Local Dynamic Voltage Scaling. In Integrated Circuit and System Design. Power and Timing Modeling, Optimization and\nSimulation, volume 4644, pages 556\u2013565. Springer Berlin / Heidelberg, 2007.\n[16] A. J. Oliner, R. K. Sahoo, J. E. Moreira, M. Gupta, and A. Sivasubramaniam. Fault-aware job scheduling for\nBlueGene/L systems. In Proc. of Int. Parallel and Distributed Processing Symposium (IPDPS), pages 64\u201373,\n2004.\n[17] P. Pop, K. H. Poulsen, V. Izosimov, and P. Eles. Scheduling and voltage scaling for energy/reliability tradeoffs in fault-tolerant time-triggered embedded systems. In Proc. of IEEE/ACM Int. Conf. on Hardware/software\ncodesign and system synthesis (CODES+ISSS), pages 233\u2013238, 2007.\n\n21\n\n\f[18] R. B. Prathipati. Energy efficient scheduling techniques for real-time embedded systems. Master's thesis, Texas\nA&M University, May 2004.\n[19] V. J. Rayward-Smith, F. W. Burton, and G. J. Janacek. Scheduling parallel programs assuming preallocation. In\nP. Chr\u00e9tienne, E. G. Coffman Jr., J. K. Lenstra, and Z. Liu, editors, Scheduling Theory and its Applications. John\nWiley and Sons, 1995.\n[20] W. Rudin. Principles of mathematical analysis. McGraw-Hill Book Co., New York, third edition, 1976. International Series in Pure and Applied Mathematics.\n[21] S. M. Shatz and J.-P. Wang. Models and algorithms for reliability-oriented task-allocation in redundant\ndistributed-computer systems. IEEE Transactions on Reliability, 38:16\u201327, 1989.\n[22] L. Wang, G. von Laszewski, J. Dayal, and F. Wang. Towards Energy Aware Scheduling for Precedence Constrained Parallel Tasks in a Cluster with DVFS. In Proc. of CCGrid'2010, the 10th IEEE/ACM Int. Conf. on\nCluster, Cloud and Grid Computing, pages 368 \u2013377, May 2010.\n[23] Y. Zhang and K. Chakrabarty. Energy-aware adaptive checkpointing in embedded real-time systems. In Proc. of\nConf. on Design, Automation and Test in Europe (DATE), page 10918. IEEE CS Press, 2003.\n[24] D. Zhu and H. Aydin. Energy management for real-time embedded systems with reliability requirements. In\nProc. of IEEE/ACM Int. Conf. on Computer-Aided Design (ICCAD), pages 528\u2013534, 2006.\n[25] D. Zhu, R. Melhem, and D. Moss\u00e9. The effects of energy management on reliability in real-time embedded\nsystems. In Proc. of IEEE/ACM Int. Conf. on Computer-Aided Design (ICCAD), pages 35\u201340, Washington, DC,\nUSA, 2004. IEEE CS Press.\n\n22\n\n\f"}