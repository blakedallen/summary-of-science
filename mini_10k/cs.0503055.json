{"id": "http://arxiv.org/abs/cs/0503055v2", "guidislink": true, "updated": "2009-06-15T19:19:34Z", "updated_parsed": [2009, 6, 15, 19, 19, 34, 0, 166, 0], "published": "2005-03-22T20:56:51Z", "published_parsed": [2005, 3, 22, 20, 56, 51, 1, 81, 0], "title": "Optimality in Goal-Dependent Analysis of Sharing", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0503016%2Ccs%2F0503067%2Ccs%2F0503021%2Ccs%2F0503089%2Ccs%2F0503006%2Ccs%2F0503092%2Ccs%2F0503080%2Ccs%2F0503070%2Ccs%2F0503062%2Ccs%2F0503047%2Ccs%2F0503042%2Ccs%2F0503012%2Ccs%2F0503061%2Ccs%2F0503082%2Ccs%2F0503049%2Ccs%2F0503054%2Ccs%2F0503004%2Ccs%2F0503078%2Ccs%2F0503029%2Ccs%2F0503063%2Ccs%2F0503030%2Ccs%2F0503071%2Ccs%2F0503013%2Ccs%2F0503060%2Ccs%2F0503041%2Ccs%2F0503048%2Ccs%2F0503068%2Ccs%2F0503015%2Ccs%2F0503066%2Ccs%2F0503032%2Ccs%2F0503007%2Ccs%2F0503036%2Ccs%2F0503039%2Ccs%2F0503001%2Ccs%2F0503079%2Ccs%2F0503023%2Ccs%2F0503005%2Ccs%2F0503076%2Ccs%2F0503073%2Ccs%2F0503022%2Ccs%2F0503020%2Ccs%2F0503069%2Ccs%2F0503072%2Ccs%2F0503044%2Ccs%2F0503081%2Ccs%2F0503003%2Ccs%2F0503028%2Ccs%2F0503056%2Ccs%2F0503019%2Ccs%2F0503055%2Ccs%2F0503058%2Ccs%2F0503074%2Ccs%2F0503024%2Ccs%2F0503064%2Ccs%2F0503031%2Ccs%2F0503083%2Ccs%2F0503026%2Ccs%2F0503040%2Ccs%2F0503084%2Ccs%2F0503087%2Ccs%2F0503090%2Ccs%2F0503014%2Ccs%2F0503075%2Ccs%2F0503010%2Ccs%2F0503018%2Ccs%2F0503065%2Ccs%2F0503050%2Ccs%2F0503046%2Ccs%2F0503008%2Ccs%2F0503038%2Ccs%2F0503057%2Ccs%2F0503052%2Ccs%2F0503037%2Ccs%2F0503085%2Ccs%2F0503033%2Ccs%2F0503043%2Ccs%2F0503053%2Ccs%2F0503091%2Ccs%2F0503002%2Ccs%2F0503086%2Ccs%2F0503045%2Ccs%2F0503025%2Ccs%2F0503077%2Ccs%2F0411080%2Ccs%2F0411008%2Ccs%2F0411020%2Ccs%2F0411071%2Ccs%2F0411045%2Ccs%2F0411063%2Ccs%2F0411049%2Ccs%2F0411046%2Ccs%2F0411004%2Ccs%2F0411068%2Ccs%2F0411089%2Ccs%2F0411037%2Ccs%2F0411024%2Ccs%2F0411064%2Ccs%2F0411026%2Ccs%2F0411054%2Ccs%2F0411013%2Ccs%2F0411044&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Optimality in Goal-Dependent Analysis of Sharing"}, "summary": "We face the problems of correctness, optimality and precision for the static\nanalysis of logic programs, using the theory of abstract interpretation. We\npropose a framework with a denotational, goal-dependent semantics equipped with\ntwo unification operators for forward unification (calling a procedure) and\nbackward unification (returning from a procedure). The latter is implemented\nthrough a matching operation. Our proposal clarifies and unifies many different\nframeworks and ideas on static analysis of logic programming in a single,\nformal setting. On the abstract side, we focus on the domain Sharing by Jacobs\nand Langen and provide the best correct approximation of all the primitive\nsemantic operators, namely, projection, renaming, forward and backward\nunification. We show that the abstract unification operators are strictly more\nprecise than those in the literature defined over the same abstract domain. In\nsome cases, our operators are more precise than those developed for more\ncomplex domains involving linearity and freeness.\n  To appear in Theory and Practice of Logic Programming (TPLP)", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0503016%2Ccs%2F0503067%2Ccs%2F0503021%2Ccs%2F0503089%2Ccs%2F0503006%2Ccs%2F0503092%2Ccs%2F0503080%2Ccs%2F0503070%2Ccs%2F0503062%2Ccs%2F0503047%2Ccs%2F0503042%2Ccs%2F0503012%2Ccs%2F0503061%2Ccs%2F0503082%2Ccs%2F0503049%2Ccs%2F0503054%2Ccs%2F0503004%2Ccs%2F0503078%2Ccs%2F0503029%2Ccs%2F0503063%2Ccs%2F0503030%2Ccs%2F0503071%2Ccs%2F0503013%2Ccs%2F0503060%2Ccs%2F0503041%2Ccs%2F0503048%2Ccs%2F0503068%2Ccs%2F0503015%2Ccs%2F0503066%2Ccs%2F0503032%2Ccs%2F0503007%2Ccs%2F0503036%2Ccs%2F0503039%2Ccs%2F0503001%2Ccs%2F0503079%2Ccs%2F0503023%2Ccs%2F0503005%2Ccs%2F0503076%2Ccs%2F0503073%2Ccs%2F0503022%2Ccs%2F0503020%2Ccs%2F0503069%2Ccs%2F0503072%2Ccs%2F0503044%2Ccs%2F0503081%2Ccs%2F0503003%2Ccs%2F0503028%2Ccs%2F0503056%2Ccs%2F0503019%2Ccs%2F0503055%2Ccs%2F0503058%2Ccs%2F0503074%2Ccs%2F0503024%2Ccs%2F0503064%2Ccs%2F0503031%2Ccs%2F0503083%2Ccs%2F0503026%2Ccs%2F0503040%2Ccs%2F0503084%2Ccs%2F0503087%2Ccs%2F0503090%2Ccs%2F0503014%2Ccs%2F0503075%2Ccs%2F0503010%2Ccs%2F0503018%2Ccs%2F0503065%2Ccs%2F0503050%2Ccs%2F0503046%2Ccs%2F0503008%2Ccs%2F0503038%2Ccs%2F0503057%2Ccs%2F0503052%2Ccs%2F0503037%2Ccs%2F0503085%2Ccs%2F0503033%2Ccs%2F0503043%2Ccs%2F0503053%2Ccs%2F0503091%2Ccs%2F0503002%2Ccs%2F0503086%2Ccs%2F0503045%2Ccs%2F0503025%2Ccs%2F0503077%2Ccs%2F0411080%2Ccs%2F0411008%2Ccs%2F0411020%2Ccs%2F0411071%2Ccs%2F0411045%2Ccs%2F0411063%2Ccs%2F0411049%2Ccs%2F0411046%2Ccs%2F0411004%2Ccs%2F0411068%2Ccs%2F0411089%2Ccs%2F0411037%2Ccs%2F0411024%2Ccs%2F0411064%2Ccs%2F0411026%2Ccs%2F0411054%2Ccs%2F0411013%2Ccs%2F0411044&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We face the problems of correctness, optimality and precision for the static\nanalysis of logic programs, using the theory of abstract interpretation. We\npropose a framework with a denotational, goal-dependent semantics equipped with\ntwo unification operators for forward unification (calling a procedure) and\nbackward unification (returning from a procedure). The latter is implemented\nthrough a matching operation. Our proposal clarifies and unifies many different\nframeworks and ideas on static analysis of logic programming in a single,\nformal setting. On the abstract side, we focus on the domain Sharing by Jacobs\nand Langen and provide the best correct approximation of all the primitive\nsemantic operators, namely, projection, renaming, forward and backward\nunification. We show that the abstract unification operators are strictly more\nprecise than those in the literature defined over the same abstract domain. In\nsome cases, our operators are more precise than those developed for more\ncomplex domains involving linearity and freeness.\n  To appear in Theory and Practice of Logic Programming (TPLP)"}, "authors": ["Gianluca Amato", "Francesca Scozzari"], "author_detail": {"name": "Francesca Scozzari"}, "author": "Francesca Scozzari", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1017/S1471068409990111", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cs/0503055v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0503055v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "F.3.2; D.1.6", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0503055v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0503055v2", "arxiv_comment": null, "journal_reference": "Theory and Practice of Logic Programming, volume 9, issue 05, pp.\n  617-689, 2009", "doi": "10.1017/S1471068409990111", "fulltext": "arXiv:cs/0503055v2 [cs.PL] 15 Jun 2009\n\nUnder consideration for publication in Theory and Practice of Logic Programming\n\n1\n\nOptimality in goal-dependent analysis\nof Sharing\nGIANLUCA AMATO and FRANCESCA SCOZZARI\nDipartimento di Scienze\nUniversit\u00e0 di Chieti-Pescara\n(e-mail: {amato,scozzari}@sci.unich.it)\nsubmitted 16 March 2006; revised 19 March 2009; accepted 26 May 2009\n\nAbstract\nWe face the problems of correctness, optimality and precision for the static analysis of logic\nprograms, using the theory of abstract interpretation. We propose a framework with a denotational, goal-dependent semantics equipped with two unification operators for forward\nunification (calling a procedure) and backward unification (returning from a procedure).\nThe latter is implemented through a matching operation. Our proposal clarifies and unifies\nmany different frameworks and ideas on static analysis of logic programming in a single,\nformal setting. On the abstract side, we focus on the domain Sharing by Jacobs and Langen and provide the best correct approximation of all the primitive semantic operators,\nnamely, projection, renaming, forward and backward unification. We show that the abstract unification operators are strictly more precise than those in the literature defined\nover the same abstract domain. In some cases, our operators are more precise than those\ndeveloped for more complex domains involving linearity and freeness.\nKEYWORDS: Abstract interpretation, logic programming, existentially quantified substitutions, unification, matching, sharing.\n\n1 Introduction\nAbstract interpretation (Cousot and Cousot 1992) is a general theory for static\nanalysis of programs. The basic idea of abstract interpretation is to use the formal semantics of languages to analyze and verify program properties. An abstract\ninterpretation is specified by:\n\u2022 a concrete domain and a concrete semantics, inductively defined on the syntax\nof programs from a set of primitive concrete operators;\n\u2022 an abstract domain, whose elements describe the program properties we want\nto observe;\n\u2022 the primitive abstract operators on the abstract domain, which mimic the\nbehavior of the corresponding concrete operators. The abstract semantics is\ndefined from the concrete one by replacing each concrete operator with its\nabstract counterpart.\n\n\f2\n\nG. Amato and F. Scozzari\n\nAbstract interpretation has been widely used to design static analysis of logic programs. In the literature, we find many proposals for the concrete domain, the concrete semantics, the abstract domain and the abstract operators. For instance, Hans\nand Winkler (1992) focus on the abstract domains, Howe and King (2003) on the\nabstract operators, King and Longley (1995) on improving existing analysis using\na more refined concrete semantics, while Cortesi et al. (1996) propose a complete\nframework, combination of particular concrete semantics and abstract domains. In\nmany cases, the correctness of the analysis is taken for granted, since the concrete\nsemantics is not completely specified. However, when applying several of these improvements to a single analysis framework, the improved analysis may significantly\ndiffer from the original proposal, and a new proof of correctness is needed for the\noverall analysis. This is especially true for logic programming, whose basic computational mechanism, unification, is intrinsically more complex than assignment or\nmatching, used in other programming paradigms.\nThe aim of this article is mainly to clarify and unify several different proposals for\nthe goal-dependent analysis of logic programs. Inspired by the work of Cortesi et al.\n(1996), we propose a new denotational framework which combines and improves\nmany different ideas appeared in the literature. Later, we focus on the abstract\ndomain Sharing by Jacobs and Langen (1992), and we develop an analysis which is\nstrictly more precise than the others in the literature. We formally prove correctness\nof the overall analysis and optimality of all the involved abstract operators.\nWhen designing a new analysis, one needs to choose a concrete domain and semantics, an abstract domain and abstract operators. Although these choices are\nrelated, in the following we will introduce them separately, showing available alternatives, possible improvements and the contributions of this paper.\n\nConcrete domain\nTypically, concrete semantics of logic programs are defined over substitutions. However, substitutions are often too informative. For example, consider the one-clause\nprogram p(x, x) and the goal p(x, y). All of {x/y}, {y/x}, {x/u, y/u}, {x/v, y/v}\nare computed answers, corresponding to different choices of most general unifiers\nand renamed clauses. Often, especially in the case of static analysis, we are not\ninterested in making any distinction among them. Thus, it would be more natural\nto adopt a domain of equivalence classes of substitutions. Many frameworks for\nabstract interpretation of logic programs (Jacobs and Langen 1992; Marriott et al.\n1994; Levi and Spoto 2003) have adopted similar solutions for avoiding redundancy\nand causality when choosing computed answers.\nNevertheless, the standard semantics of logic programs, namely SLD resolution,\nis based on substitutions and unification. Thus, any framework for logic programming should relate, in some way, to standard substitutions, in order to prove that\nthe semantics reflects the underlying operational behavior. However, none of the\nabove frameworks formally states the correspondence between the proposed concrete domain and standard substitutions. Although this correspondence is clear\n\n\fOptimality in goal-dependent analysis of Sharing\n\n3\n\nfrom an intuitive point of view, we think that substitutions are tricky objects,\nwhere intuition often fails.\nOur contribution. We propose a new concrete domain of classes of substitutions,\ncalled existential substitutions, equipped with a set of primitive operators for projection, renaming and unification. We formally state the correspondence between\nsubstitutions and existential substitutions, and in particular between the corresponding unification operators. Moreover, we show the relationship between our\nproposal and the domain ESubst by Jacobs and Langen (1992).\nConcrete semantics\nWe are interested in goal-driven analysis of logic programs. Therefore we need a\ngoal-dependent semantics which is well suited for static analysis, i.e., a collecting\nsemantics over computed answer substitutions. Unfortunately, using a collecting\ngoal-dependent semantics may lead to a loss of precision already at the concrete\nlevel, as shown by Marriott et al. (1994). Basically, in any goal-dependent semantics,\nthe unification operator is used twice:\n\u2022 For performing parameter passing by unifying the given goal and the call\nsubstitution with the head of the chosen clause. The result is a new goal and\nan entry substitution. This operation is called forward unification.\n\u2022 For propagating back to the initial goal the exit substitution (that is, the\nresult of the sub-computation), so obtaining the answer substitution for the\ninitial goal. This operation is called backward unification 1\n\ncall substitution\n\nforward unification\n\nentry substitution\n\ncomputation\n\nbackward unification\n\nanswer substitution\n\nexit substitution\n\nFor instance, given the initial goal p(x) and the call substitution {x/f (y)}, we\nunify with the head of the clause p(z) \u2190 q(z) by computing the most general unifier {x/f (y), z/f (y)}, which, projected on the variables of the clause, is simply\n{z/f (y)}. Projection is needed in order to avoid an unbounded growing of the set\nof variables in the entry substitution. This is acceptable at the concrete level, but\n1\n\nWe follow Cortesi et al. (1996) and call these operators forward and backward unification.\nBruynooghe (1991) and Hans and Winkler (1992) use procedure entry and procedure exit.\nMuthukumar and Hermenegildo (1991) use call to entry and exit to success.\n\n\f4\n\nG. Amato and F. Scozzari\n\nnot at the abstract level, where it may lead to non-terminating analysis. The new\ngoal and entry substitution become q(z) and {z/f (y)}. Once we have obtained an\nexit substitution for the goal q(z), for instance {z/f (a)}, we have to relate this result to the original goal p(x). Thus we need a so-called backward unification, which\nallows us to conclude that {x/f (a)} is an answer for p(x) with call substitution\n{x/f (y)}.\nThe backward unification operator introduces a loss of precision, due to the fact\nthat we deal with a set of call substitutions, from which we possibly obtain a set of\nexit substitutions. Now, when we go backward to obtain the answer substitutions,\nwe may unify a call substitution with an exit substitution which does not pertain\nto the same computational path (Marriott et al. 1994).\nIt is possible to reduce the impact of this problem by using two different operators\nfor forward and backward unification (Bruynooghe 1991; Le Charlier et al. 1991).\nIn this way, backward unification can be realized using the operation of matching\nbetween substitutions.\nOur contribution. We propose a denotational goal-dependent semantics equipped\nwith two different forward and backward unification operators. Backward unification uses matching, exploiting the property that the exit substitution is more\ninstantiated than the call substitution. We prove that the concrete semantics is\ncorrect and show that the new semantics is strictly more precise than semantics\nwhich do not use matching.\nAbstract domain\nOne of the most interesting (and studied) property for logic programs is sharing.\nThe goal of (set) sharing analysis is to detect sets of variables which share a common\nvariable. For instance, in the substitution {x/f (z, a), y/g(z)} the variables x and\ny share the common variable z. Typical applications of sharing analysis are in\noptimization of unification (S\u00f8ndergaard 1986) and parallelization of logic programs\n(Hermenegildo and Rossi 1995).\nThe basic domain for set sharing analysis is Sharing, introduced in (Langen 1990;\nJacobs and Langen 1992). It is widely recognized that Sharing is not very precise,\nso that it is often combined with other domains for freeness, linearity, groundness\nor structural information (see Bagnara et al. (2005) for a comparative evaluation).\nSince this paper does not address the problem to find the best possible domain for\nset-sharing analysis, we will focus on the domain Sharing.\nAbstract operators\nOnce the concrete semantics and the abstract domain have been fixed, the next\nstep is to find suitable abstract operators which mimic the behavior of the concrete\nones. The theory of abstract interpretation ensures the existence of the optimal\n(best correct) abstract operator for each concrete operator. Although the optimal\nabstract operator enjoys a constructive characterization, this is not amenable to a\n\n\fOptimality in goal-dependent analysis of Sharing\n\n5\n\ndirect implementation. Therefore, finding an algorithm to compute optimal abstract\noperators is one of the main difficulties in any abstract interpretation project.\nWe think that there are several reasons to look for the optimal operator, instead\nof just using a correct one. In fact, one may argue that a well-design correct operator\nmay be much faster then the optimal one, and does not lose much precision in real\nprograms. Although we agree with this point, we think that knowing the optimal\nabstract operator, even if we do not plan to implement it, is useful to understand\nthe potentiality and limits of the abstract domain in use, and to guide the search for\na more precise (or more efficient) domain. Moreover, at least in the case of sharing\nanalysis, the more precise the abstract operators are, the smaller are the abstract\nobjects computed during the analysis. Therefore, it may be worth spending more\ntime in computing the abstract operators, in order to keep the abstract objects\nsimpler (and the analysis more precise).\nThe primitive concrete operators used in the semantics of logic programs are\nrenaming, projection, unification and matching. Renaming and projections are not\nproblematic at all: it is generally immediate to find their optimal abstract counterparts, which most of the time are also complete, i.e., they do not lose precision\nw.r.t. the corresponding concrete operators (Cousot and Cousot 1979; Giacobazzi\net al. 2000).\nThings are different for unification, which is a very complex operator. In fact,\ndespite several works in this field, the best correct abstraction of unification for\nthe domain SFL (King and Longley 1995), which combines sharing, freeness and\nlinearity, is still unknown. For the domain Sharing, Cortesi and Fil\u00e9 (1999) have\nshown that abstract unification defined in Jacobs and Langen (1992) is optimal.\nHowever, this result has been obtained for a concrete semantics which uses the same\nunification operator to compute both forward and backward unification.\nWe have already said that a specialized backward unification operator may improve precision at the concrete level. In turn, the improvement in precision is reflected at the abstract level, if the abstract backward unification operator is designed to mimic matching instead of standard unification. This idea is implemented\nin real abstract interpreters such as GAIA (Le Charlier et al. 1991) and PLAI\n(Muthukumar and Hermenegildo 1992). However, none of the papers which are\nbased on a specialized backward unification operator with matching (Bruynooghe\n1991; Le Charlier and Van Hentenryck 1994; Hans and Winkler 1992; Muthukumar\nand Hermenegildo 1992; King and Longley 1995) has ever proved optimality of\nthe proposed abstract operators. As we will show later, those abstract operators\nwhich involve set-sharing information (Hans and Winkler 1992; Muthukumar and\nHermenegildo 1992; King and Longley 1995) are not optimal.\nIn addition, the abstract forward unification operator can be specialized in order\nto exploit the peculiarity of this process: the variables which occur in the clause\nhead are always renamed apart w.r.t. the goal and the calling substitutions, hence\nthey are free and independent. However, this idea has never been applied before\nin the general case, but only for abstract domains which explicitly contain freeness\nand linearity information.\n\n\f6\n\nG. Amato and F. Scozzari\n\nOur contribution. We provide abstract operators for renaming, projection, forward\nunification and backward unification. We prove that all our operators are optimal\nand that renaming and projection are also complete. We show that abstract forward\nunification is able to exploit freeness and linearity information. The new backward\nand forward unification operators strictly improve over previous proposals for the\ndomain Sharing.\nAlthough freeness and linearity information are exploited by the forward abstract\nunification operator, this information is not encoded in the abstract domain, but\nis just used in the internal steps of the abstract unification algorithm. This means\nthat the algorithm cannot be immediately extended to work with more complex\ndomains, such as SFL (King and Longley 1995), retaining optimality. Nonetheless,\nthe abstract unification is able to exploit freeness and linearity better than other\nalgorithms and could be used to improve the unification operation in more complex\ndomains.\nPlan of the paper\nThe next section recalls some basic definitions and the notations about abstract\ninterpretation and substitutions. In Section 3 we define the domain of existentially\nquantified substitutions and its operators. In Sections 4 and 5 we define the concrete\nand abstract semantics. Finally, in Sections 6 and 7 we give the algorithms for computing the forward and backward abstract unification and show their correctness\nand optimality. In Section 8 we compare our framework with related work.\nThe article is a substantial expansion of (Amato and Scozzari 2002), which introduces preliminary results using standard substitutions. A partial presentation of\nexistential substitutions appeared in Amato and Scozzari (2003).\n2 Notations\nGiven a set A, let \u2118(A) be the powerset of A and \u2118f (A) be the set of finite subsets of\nm\nc\nA. Given two posets (A, \u2264A ) and (B, \u2264B ), we denote by A \u2192 B (A \u2192 B) the space of\nmonotonic (continuous) functions from A to B ordered pointwise. When an order for\nA or B is not specified, we assume the least informative order (x \u2264 y \u21d0\u21d2 x = y).\nWe also use A \u228e B to denote disjoint union and |A| for the cardinality of the set A.\nGiven complete lattices A, C, a Galois connection (Cousot and Cousot 1979)\nm\nm\nh\u03b1, \u03b3i : C \u21cc A is given by a pair of maps \u03b1 : C \u2192 A, \u03b3 : A \u2192 C such that \u03b1(c) \u2264A\na \u21d0\u21d2 c \u2264C \u03b3(a). A Galois connection is a Galois insertion when \u03b1 is onto (or\nm\nequivalently, \u03b3 is injective). We say that an abstract operator f \u03b1 : A \u2192 A is correct\nm\nw.r.t. a concrete operator f : C \u2192 C when \u2200c \u2208 C. (\u03b1\u25e6f )(c) \u2264A (f \u03b1 \u25e6\u03b1)(c), which is\nequivalent to \u2200a \u2208 A. (f \u25e6\u03b3)(a) \u2264C (\u03b3\u25e6f \u03b1 )(a) and to \u2200a \u2208 A. (\u03b1\u25e6f \u25e6\u03b3)(a) \u2264A f \u03b1 (a).\nThe abstract operator is optimal when f \u03b1 = \u03b1 \u25e6 f \u25e6 \u03b3. In this case f \u03b1 is called the\nbest correct approximation of f . When \u03b1 \u25e6 f = f \u03b1 \u25e6 \u03b1 then f \u03b1 is said to be complete,\nwhile if f \u25e6 \u03b3 = \u03b3 \u25e6 f \u03b1 then f \u03b1 is \u03b3-complete.\nIn the following, we fix a first order signature (\u03a3, \u03a0) and an infinite set of variables\nV. We assume that there are a constant symbol and a function symbol of arity at\n\n\fOptimality in goal-dependent analysis of Sharing\n\n7\n\nleast two2 . We use Terms and Atoms to denote the sets of terms and atomic formulas\n(atoms) respectively. Moreover, we call body or goal a finite sequence of atomic\nformulas, clause an object H \u2190 B where H is an atom and B is a body, program\na set of clauses. We use \u0003 for the empty body and we write H as a short form\nfor H \u2190 \u0003. We denote with Bodies, Clauses and Progs the set of bodies, clauses\nand programs respectively. Given a term t, we denote by vars(t) the set of variables\noccurring in t and by uvars(t) the subset of vars(t) whose elements appear once in\nt (e.g., uvars(f (x, y) = f (y, z)) = {x, z}). We apply vars and uvars to any syntactic\nobject, with the obvious meaning. We abuse the notation and write a syntactic\nobject o instead of the set of variables vars(o), when it is clear from the context\n(e.g., if t is a term and x \u2208 V, then x \u2208 t should be read as x \u2208 vars(t)).\nWe denote with \u01eb the empty substitution and by {x1 /t1 , . . . , xn /tn } a substitution\n\u03b8 with \u03b8(xi ) = ti 6= xi . Let dom(\u03b8) be the set {x1 , . . . , xn } and rng(\u03b8) be the set\nvars({t1 , . . . , tn }). Thus we have that vars(\u03b8) = dom(\u03b8) \u222a rng(\u03b8). Given U \u2208 \u2118f (V),\nlet \u03b8|U be the projection of \u03b8 on U , i.e., the unique substitution such that \u03b8|U (x) =\n\u03b8(x) if x \u2208 U and \u03b8|U (x) = x otherwise. We also write \u03b8|\u2212U to denote the restriction\nof \u03b8 over all variables but those in U , i.e., \u03b8|\u2212U = \u03b8|dom(\u03b8)\\U . Given \u03b81 and \u03b82 two\nsubstitutions with disjoint domains, we denote by \u03b81 \u228e \u03b82 the substitution \u03b8 such\nthat dom(\u03b8) = dom(\u03b81 ) \u222a dom(\u03b82 ) and \u03b8(x) = \u03b8i (x) if x \u2208 dom(\u03b8i ), for each\ni \u2208 {1, 2}. The application of a substitution \u03b8 to a term t is written as t\u03b8 or \u03b8(t).\nGiven two substitutions \u03b8 and \u03b4, their composition, denoted by \u03b8 \u25e6 \u03b4, is given by\n(\u03b8 \u25e6 \u03b4)(x) = \u03b8(\u03b4(x)). A substitution \u03c1 is called renaming if it is a bijection from\nV to V (this is equivalent to say that there exists a substitution \u03c1\u22121 such that\n\u03c1 \u25e6 \u03c1\u22121 = \u03c1\u22121 \u25e6 \u03c1 = \u01eb). A substitution \u03b8 is idempotent when dom(\u03b8) \u2229 rng(\u03b8) = \u2205.\nInstantiation induces a preorder on substitutions: \u03b8 is more general than \u03b4, denoted\nby \u03b4 \u2264 \u03b8, if there exists \u03c3 such that \u03c3 \u25e6 \u03b8 = \u03b4. If \u2248 is the equivalence relation\ninduced by \u2264, we say that \u03c3 and \u03b8 are equal up to renaming when \u03c3 \u2248 \u03b8. The\nset of substitutions, idempotent substitutions and renamings are denoted by Subst,\nISubst and Ren respectively.\nGiven a set of equations E, we write \u03c3 = mgu(E) to denote that \u03c3 is a most\ngeneral unifier of E such that vars(\u03c3) \u2286 vars(E). Since \u03c3 is defined up to renamings,\nwe use this notation only in cases where the choice of the actual unifier does not\nmatter. Any idempotent substitution \u03c3 is a most general unifier of the corresponding\nset of equations Eq(\u03c3) = {x = \u03c3(x) | x \u2208 dom(\u03c3)}. In the following, we will\nabuse the notation and denote by mgu(\u03c31 , . . . , \u03c3n ), when it exists, the substitution\nmgu(Eq(\u03c31 ) \u222a . . . \u222a Eq(\u03c3n )).\nIn the rest of the paper, we use: U , V , W to denote finite sets of variables;\nh, k, u, v, w, x, y, z for variables; c, s, t for term symbols or terms; a, b for constants;\ncl for clauses; \u03b7, \u03b8, \u03c3, \u03b4 for substitutions; \u03c1 for renamings. All these symbols can be\nsubscripted or superscripted.\n\n2\n\nOtherwise every term has at most one variable and the structure of terms is trivial. We need\nthis assumption in Section 8.1 and in the proofs of optimality of unification and matching.\n\n\f8\n\nG. Amato and F. Scozzari\n3 Domains of Existentially Quantified Substitutions\n\nThe first question when analyzing the behavior of logic programs is what kind\nof observable we are interested in. Undoubtedly, computed answers have played a\nprominent role, since they are the result of the process of SLD-resolution. Moreover,\nthey have several nice properties: and-compositionality, condensing and a bottomup TP -like characterization (van Emden and Kowalski 1976; Bossi et al. 1994).\nStandard semantics for logic programs, e.g., the s-semantics in (Bossi et al. 1994),\nare defined over equivalence classes of atoms modulo renaming. For example, consider the one-clause program p(x, x) and the goal p(x, y). All of p(x, x), p(y, y),\np(u, u) and p(v, v) are computed instances, corresponding to different choices of\nmost general unifiers and renamed clauses, but we are not interested in making any\ndistinction among them.\nHowever, when we consider a denotational semantics suitable for program analysis, computed answer substitutions are much more useful than computed instances,\nsince most of the domains are expressed as abstraction of sets of substitutions. As\nbefore, we are not really interested in the substitutions, but in their quotient-set\nw.r.t. a suitable equivalence relation. But in this case we cannot take renaming as\nthe relevant equivalence relation. Let us consider the substitutions corresponding to\nthe computed instances in the previous example: we obtain \u03b81 = {y/x}, \u03b82 = {x/y},\n\u03b83 = {x/u, y/u} and \u03b84 = {x/v, y/v}. Although \u03b81 and \u03b82 are equal up to renaming,\nthe same does not hold for \u03b83 and \u03b84 . Nonetheless, they essentially represent the\nsame answer, since u and v are just two different variables we chose when renaming\napart the clause p(x, x) from the goal p(x, y), and therefore are not relevant. On the\nother side, if \u03b83 and \u03b84 were computed answers for the goal q(x, y, u), they would\ncorrespond to computed instances q(u, u, u) and q(v, v, u) and therefore would be\ndefinitively different. As a consequence, the equivalence relation we need to consider\nmust be coarser than renaming, and must take into account the set of variables of\ninterest, i.e., the set of variables which appear in the goal.\nA semantics which takes into account classes of substitutions may follow three\npossible directions:\n1. it may compute only a subset of the computed answer substitutions, provided\nthat the result contains at least one substitution for each equivalence class,\ne.g., (Cortesi et al. 1996);\n2. it may compute all the computed answer substitutions, e.g., (Le Charlier et al.\n1991);\n3. it may be defined using a quotient domain of substitutions, e.g., (Marriott\net al. 1994).\nThe problem with the first two solutions is that they work by directly manipulating substitutions. It is common knowledge that this is quite tedious and error prone\n(Shepherdson 1994). This happens because substitutions are too much related to\nsyntax, so that the intuition of what should happen is often betrayed by the reality,\nwhen we need to handle problems such as variable clashes and renamings. Actually,\nat least one framework of the first kind, namely the widely used one in (Cortesi\n\n\fOptimality in goal-dependent analysis of Sharing\n\n9\n\nand Fil\u00e9 1999), has a small flaw due to an unsound treatment of variable clashes\n(this will be discussed in details in Section 8.2).\nMoreover, the first approach is generally pursued by choosing a particular most\ngeneral unifier and a fixed way of renaming apart terms and substitutions. The\nsemantics is then parametric with respect to these choices. As stated by Jacobs\nand Langen (1992), this makes difficult to compare different semantics, since each\nof them may use different conventions for mgu and renaming. We would like to\nadd that this also makes difficult to state properties of a given semantics (such\nas compositionality properties), since they only hold up to suitable equivalence\nrelations.\nFor these reasons, we think that the best solution is to move towards a domain\nof equivalence classes of substitutions. This does not mean we can avoid to work\nwith substitutions altogether, but all the difficulties which arise, such as renaming\napart and variables clashes, may be dealt with once and for all at the domain level,\nreducing the opportunities for subtle mistakes to appear.\n3.1 Yet another Domain of Existentially Quantified Substitutions\nIn the literature there are several domains of equivalence classes of substitutions:\nESubst (Jacobs and Langen 1992), ex-equations (Marriott et al. 1994) and existential Herbrand constraints (Levi and Spoto 2003). For all of them, the basic idea\nis that some variables, in a substitution or equation, are existentially quantified,\nso that their names become irrelevant. However, all these proposals depart from\nthe standard notion of substitution. As a result, the relationship between what\nthey compute and the standard set of computed answers for a goal has never been\nproved. We would like to reconcile these approaches with the standard concept of\nsubstitution: in particular, we want to prove that these domains are quotient sets\nof substitutions, w.r.t. suitable equivalence relations.\nWe begin by introducing a new equivalence relation \u223c over substitutions, which\ncaptures the extended notion of renaming which is needed to work with computed\nanswers. Inspired by the seminal paper of Palamidessi (1990), we introduce a new\ndomain Subst \u223c of classes of substitutions modulo \u223c, which will be used in the rest\nof the paper3 .\nGiven \u03b81 , \u03b82 \u2208 Subst and U \u2208 \u2118f (V), we define the preorder:\n\u03b81 \u0016U \u03b82 \u21d0\u21d2 \u2203\u03b4 \u2208 Subst.\u2200u \u2208 U. \u03b81 (u) = \u03b4(\u03b82 (u)) .\n\n(1)\n\nIntuitively, if \u03b81 \u0016U \u03b82 , then \u03b81 is an instance of \u03b82 , provided we are only interested\nin the variables in U .\nExample 3.1\nIt is easy to check that {x/a, y/u} \u0016{x,y} {y/v}, since we may choose \u03b4 = {x/a, v/u}\nin (1). Note that the same does not happen if we consider the standard ordering\n3\n\nIn Section 8.1, we will prove that Subst \u223c and the domain ESubst (Jacobs and Langen 1992)\nare isomorphic.\n\n\f10\n\nG. Amato and F. Scozzari\n\non substitutions, i.e., {x/a, y/u} 6\u2264 {y/v}. Moreover, if we enlarge the set U of\nvariables of interest, we obtain {x/a, y/u} 6\u0016{x,y,v} {y/v}.\nNote that, in Equation (1), it is important that \u03b4 is a generic substitution. If we\nrestrict \u03b4 to be idempotent, some equivalences do not hold anymore. For example,\n{x/t(u), y/t(v)} \u0016{x,y} {x/v, y/u} and this is what we intuitively want, since the\nnames of the variables u and v are not relevant. However, to prove this relation, we\nchoose \u03b4 = {u/t(v), v/t(u)} in (1), and it is not an idempotent substitution.\nProposition 3.2\n\u0016U is a preorder for any U \u2208 \u2118f (V).\nProof\nLet U \u2208 \u2118f (V). By definition, \u03b8 \u0016U \u03b8 \u21d0\u21d2 \u2203\u03b4 \u2208 Subst.\u2200v \u2208 U. \u03b8(v) = \u03b4(\u03b8(v)),\nwhich is a tautology by choosing as \u03b4 the empty substitution. Now assume \u03b81 \u0016U\n\u03b82 and \u03b82 \u0016U \u03b83 . Therefore, there exist \u03b41 and \u03b42 such that, \u2200v \u2208 U , \u03b81 (v) =\n\u03b41 (\u03b82 (v)) and \u03b82 (v) = \u03b42 (\u03b83 (v)). Therefore, \u2200v \u2208 U , it holds \u03b81 (v) = \u03b41 (\u03b82 (v)) =\n\u03b41 (\u03b42 (\u03b83 (v))). Therefore, by choosing as \u03b4 the composition \u03b41 \u25e6 \u03b42 we have that\n\u03b81 \u0016 U \u03b83 .\nThe next step is to define the relation:\n\u03b81 \u223cU \u03b82 \u21d0\u21d2 \u2203\u03c1 \u2208 Ren.\u2200v \u2208 U. \u03b81 (v) = \u03c1(\u03b82 (v)) ,\n\n(2)\n\nwhich will be proved to be the equivalence relation induced by the preorder \u0016U .\nExample 3.3\nIt is easy to check that {x/v, y/u} \u223c{x,y} \u01eb by choosing \u03c1 = {x/v, v/x, y/u, u/y}.\nNote that \u223cU is coarser than the standard equivalence relation \u2248: there is no\nrenaming \u03c1 such that \u01eb = \u03c1 \u25e6 {x/v, y/u}. As it happens for \u0016, if we enlarge the set\nof variables of interest, not all equivalences between substitutions are preserved: for\ninstance, {x/v, y/u} 6\u223c{x,y,v} \u01eb.\nLemma 3.4\nLet \u03b8 : V \u2192 V an injective map of variables. Then there exists \u03c1 \u2208 Ren such that\n\u03c1(x) = \u03b8(x) for each x \u2208 V and vars(\u03c1) = V \u222a \u03b8(V ).\nProof\nSince \u03b8 is injective, |V | = |\u03b8(V )|, from which it follows that |V \\ \u03b8(V )| = |\u03b8(V ) \\ V |.\nLet f be any bijective map from \u03b8(V )\\V to V \\\u03b8(V ), and let us define a substitution\n\u03c1 as follows:\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2\u03b8(v) if v \u2208 V\n\u03c1(v) = f (v) if v \u2208 \u03b8(V ) \\ V\n\uf8f4\n\uf8f4\n\uf8f3v\notherwise.\n\nNote that, if x \u2208 V , \u03c1(x) = \u03b8(x) by definition. Moreover, it is easy to check that \u03c1 is\nbijective, therefore, it is a renaming. Finally, vars(\u03c1) = dom(\u03c1) = V \u222a (\u03b8(V ) \\ V ) =\nV \u222a \u03b8(V ).\n\n\fOptimality in goal-dependent analysis of Sharing\n\n11\n\nProposition 3.5\nThe relation \u223cU is the equivalence relation induced by \u0016U .\nProof\nIf \u03b81 \u223cU \u03b82 there exists \u03c1 \u2208 Ren such that \u2200v \u2208 U. \u03b81 (v) = \u03c1(\u03b82 (v)). By definition of\n\u0016U , we have that \u03b81 \u0016U \u03b82 by choosing as \u03b4 in (1) the renaming \u03c1. Symmetrically,\nby choosing as \u03b4 the renaming \u03c1\u22121 (the inverse of \u03c1), it follows that \u03b82 \u0016U \u03b81 .\nNow assume that \u03b81 \u0016U \u03b82 and \u03b82 \u0016U \u03b81 . Therefore there exist \u03b4, \u03b4 \u2032 \u2208 Subst\nsuch that \u03b82 (x) = \u03b4 \u2032 (\u03b81 (x)) and \u03b81 (x) = \u03b4(\u03b82 (x)), thus \u03b82 (x) = \u03b4 \u2032 (\u03b4(\u03b82 (x))) for\neach x \u2208 U . In general, \u03b4 and \u03b4 \u2032 might not be renamings. Our goal is to build a\nrenaming \u03c1, obtained by modifying \u03b4, such that \u03b81 (x) = \u03c1(\u03b82 (x)), for each x \u2208 U .\nLet V = vars(\u03b82 (U )). Since each v \u2208 V belongs to vars(\u03b82 (x)) for some x \u2208 U ,\nit follows that (\u03b4 \u2032 \u25e6 \u03b4)(v) = v for all v \u2208 V . Therefore, \u03b4|V may be viewed as an\ninjective map from V to V. By Lemma 3.4, there exists \u03c1 \u2208 Ren such that \u03c1|V = \u03b4|V .\nTherefore, for each x \u2208 U , \u03c1(\u03b82 (x)) = \u03b4(\u03b82 (x)) = \u03b81 (x), hence \u03b81 \u223cU \u03b82 .\nIt is worth noting that \u0016U is coarser than \u2264 and that \u223cU is coarser than renaming, as shown by the following proposition.\nProposition 3.6\nGiven \u03b8 \u2208 Subst, \u03c1 \u2208 Ren and \u03b4 \u2208 Subst then \u03c1 \u25e6 \u03b8 \u223cU \u03b8 and \u03b4 \u25e6 \u03b8 \u0016U \u03b8 for each\nU \u2208 \u2118f (V).\nProof\nSimply choose \u03c1 and \u03b4 as the relevant substitutions in (1) and (2).\nNow, let ISubst \u223cU be the quotient set of ISubst w.r.t. \u223cU . We define a new\ndomain ISubst \u223c of existential substitutions as the disjoint union of all the ISubst \u223cU\nfor U \u2208 \u2118f (V), in formulas:\n]\n(3)\nISubst \u223cU .\nISubst \u223c =\nU\u2208\u2118f (V)\n\nIn the following we write [\u03b8]U for the equivalence class of \u03b8 w.r.t. \u223cU . We call\ncanonical representatives of the equivalence class [\u03b8]U \u2208 ISubst \u223c the substitutions\n\u03b8\u2032 \u2208 ISubst such that \u03b8\u2032 \u223cU \u03b8 and dom(\u03b8\u2032 ) = U . It is immediate to see that every\nexistential substitution has a canonical representative, although it is not unique.\nFor example, two canonical representatives of [{y/f (x)}]x,y,z are {y/f (h), x/h, z/k}\nand {y/f (u), x/u, z/v}. Working with canonical representatives is of great help,\nespecially in the proofs, since we are sure they have no variables of interest in the\nrange.\nBy definition of \u0016U , when \u03b8 \u0016U \u03b8\u2032 then, for all W \u2286 U , it holds that \u03b8 \u0016W \u03b8\u2032 .\nThis allows us to define a partial order \u0016 over ISubst \u223c given by:\n[\u03b8]U \u0016 [\u03b8\u2032 ]V \u21d0\u21d2 U \u2287 V \u2227 \u03b8 \u0016V \u03b8\u2032 .\n\n(4)\n\nIntuitively, [\u03b8]U \u0016 [\u03b8\u2032 ]V means that \u03b8 is an instance of \u03b8\u2032 w.r.t. the variables in V ,\nprovided that they are all variables of interest of \u03b8. It is easy to show that \u0016 is welldefined in ISubst \u223c , that is it does not depend on the choice of the representatives.\n\n\f12\n\nG. Amato and F. Scozzari\n\nNote that, although we use equivalence classes of idempotent substitutions, we\ncould build an isomorphic domain by working with equivalence classes of the set of\nU\nall the substitution. In other words, if we define Subst \u223c = U\u2208\u2118f (V) Subst \u223cU , we\nobtain the following:\nProposition 3.7\nThe posets (Subst \u223c , \u0016) and (ISubst \u223c , \u0016) are isomorphic.\nProof\nIt is enough to prove that, for each U \u2208 \u2118f (V) and \u03b8 \u2208 Subst, there exists \u03b8\u2032 \u2208\nISubst such that \u03b8 \u223cU \u03b8\u2032 . Let V = rng(\u03b8) \u2229 dom(\u03b8) and W \u2286 V such that W \u2229\n(U \u222a vars(\u03b8)) = \u2205 and |V | = |W |. Moreover, we take a renaming \u03c1 such that\nvars(\u03c1) = V \u222a W and \u03c1(V ) = W . Then, we may define a substitution \u03b8\u2032 such that\n\u03b8\u2032 = (\u03c1 \u25e6 \u03b8)|U .\nNote that dom(\u03b8\u2032 ) = (dom(\u03b8) \u222a W ) \u2229 U \u2286 dom(\u03b8) and rng(\u03b8\u2032 ) \u2286 rng(\u03b8) \\ V \u222a W .\nTherefore, dom(\u03b8\u2032 ) \u2229 rng(\u03b8\u2032 ) = \u2205, i.e., \u03b8\u2032 \u2208 ISubst. Moreover, by definition, \u03b8\u2032 \u223cU \u03b8.\nThe isomorphism between Subst \u223c and ISubst \u223c holds since a variable in rng(\u03b8) is\nconsidered not of interest if it also occurs in dom(\u03b8). Therefore {x/y, y/x} \u223c{x,y}\n{x/u, y/v}, since y and x in the range of {x/y, y/x} are just names for existential\nquantified variables. Obviously {x/y} 6\u223c{x,y} {x/u} since here y only appears in\nthe range and is therefore considered as a variable of interest.\n3.2 Operations on the new Domain\nIt is now time to define some useful operations over ISubst \u223c , which will be used\nas building blocks for the semantics to be defined further away in the paper. They\nwill also give some more insights over the structure of ISubst \u223c . To ease notation,\nwe often omit braces from the sets of variables of interest when they are given\nextensionally. So we write [\u03b8]x,y instead of [\u03b8]{x,y} and \u223cx,y,z instead of \u223c{x,y,z}.\nWhen the set of variables of interest is clear from the context or it is not relevant,\nit will be omitted. Finally, we omit the braces which enclose the bindings of a\nsubstitution when it occurs inside an equivalence class, i.e., we write [x/y]U instead\nof [{x/y}]U .\n3.2.1 Projection\nWe define an operator which projects an element of ISubst \u223c on a given set of\nvariables V , given by\n\u03c0V ([\u03c3]U ) = [\u03c3]U\u2229V ,\n\n(5)\n\nwhich can be easily proved to be well-defined. Moreover, the following properties\nhold:\n1. \u03c0U \u25e6 \u03c0V = \u03c0U\u2229V ;\n2. \u03c0U ([\u03c3]U ) = [\u03c3]U ;\n3. \u03c0V is monotonic w.r.t. \u0016.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n13\n\n3.2.2 Renaming\nAnother useful operation on classes of substitutions is renaming. We first define the\napplication of a renaming \u03c1 \u2208 Ren to a substitution \u03b8 \u2208 Subst as\n\u03c1(\u03b8) = {\u03c1(x)/\u03c1(\u03b8(x)) | x \u2208 dom(\u03b8)} .\n\n(6)\n\nIntuitively, we treat \u03b8 as a syntactic object and apply the renaming to both left\nand right hand sides. Note that \u03c1(\u03b8) can be equivalently defined as \u03c1 \u25e6 \u03b8 \u25e6 \u03c1\u22121 .\nProposition 3.8\nGiven \u03c1 \u2208 Ren and \u03b8 \u2208 Subst it holds that \u03c1(\u03b8) = \u03c1 \u25e6 \u03b8 \u25e6 \u03c1\u22121 .\nProof\nLet \u03b8\u2032 = \u03c1(\u03b8). Since y 6= \u03b8(y) for all y \u2208 dom(\u03b8), then \u03c1(y) 6= \u03c1(\u03b8(y)) by injectivity\nof \u03c1. It follows that dom(\u03b8\u2032 ) = \u03c1(dom(\u03b8)). We now prove that, for each x \u2208 V,\n\u03b8\u2032 (x) = \u03c1(\u03b8(\u03c1\u22121 (x))). We distinguish two cases.\n\u2022 If x 6\u2208 dom(\u03b8\u2032 ), it follows that x 6\u2208 \u03c1(dom(\u03b8)) and thus \u03c1\u22121 (x) 6\u2208 dom(\u03b8). As\na consequence, \u03c1(\u03b8(\u03c1\u22121 (x))) = \u03c1(\u03c1\u22121 (x)) = x = \u03b8\u2032 (x).\n\u2022 If x \u2208 dom(\u03b8\u2032 ), then y = \u03c1\u22121 (x) \u2208 dom(\u03b8) and \u03b8\u2032 (x) = \u03c1(\u03b8(y)). Therefore\n\u03c1(\u03b8(\u03c1\u22121 (x))) = \u03c1(\u03b8(y)) = \u03b8\u2032 (x).\nWe may lift this definition to classes of substitutions in the standard way as\nfollows:\n\u03c1([\u03c3]U ) = [\u03c1(\u03c3)]\u03c1(U) .\n\n(7)\n\nFor example, let \u03c3 = {x/k, y/t(z, k)}, U = {x, y, z} and consider the renaming:\n\u03c1 = {x/u, u/x, y/z, z/y, k/h, h/k} .\nIf we apply \u03c1 to [\u03c3]U we obtain \u03c1([\u03c3]U ) = [{u/h, z/t(y, h)}]u,y,z. Note that we do\nnot need to worry about variable clashes.\nTheorem 3.9\nThe renaming operation is well defined.\nProof\nIt is enough to prove monotonicity w.r.t. the preorder \u0016U . Given \u03b81 , \u03b82 \u2208 Subst\nsuch that \u03b81 \u0016U \u03b82 , we prove that \u03c1(\u03b81 ) \u0016\u03c1(U) \u03c1(\u03b82 ). By Prop. 3.8, we need to show\nthat \u03c1 \u25e6 \u03b81 \u25e6 \u03c1\u22121 \u0016\u03c1(U) \u03c1 \u25e6 \u03b82 \u25e6 \u03c1\u22121 , which is equivalent to \u03b81 \u25e6 \u03c1\u22121 \u0016\u03c1(U) \u03b82 \u25e6 \u03c1\u22121\nthanks to Prop. 3.6. By hypothesis, there exists a substitution \u03b4 \u2208 Subst such that\n\u03b81 (x) = \u03b4(\u03b82 (x)) for all x \u2208 U . Therefore, for all v \u2208 \u03c1(U ), it holds \u03b81 (\u03c1\u22121 (v)) =\n\u03b4(\u03b82 (\u03c1\u22121 (v))), which is the thesis.\nSeveral properties hold for the renaming operation:\n1.\n2.\n3.\n4.\n\n(\u03c11 \u25e6 \u03c12 )([\u03b8]V ) = \u03c11 (\u03c12 ([\u03b8]V ));\n\u03c1 is monotonic w.r.t. \u0016;\n\u03c1(\u03c0V ([\u03b8]U )) = \u03c0\u03c1(V ) (\u03c1([\u03b8]U ));\n\u03c11 ([\u03b8]U ) = \u03c12 ([\u03b8]U ) if \u03c11 |U = \u03c12 |U .\n\nWe just prove the last two, since the first is trivial and the second one immediately\nfollows from the proof of Theorem 3.9. Note that the first point implies that \u03c1 :\nISubst \u223c \u2192 ISubst \u223c is invertible.\n\n\f14\n\nG. Amato and F. Scozzari\n\nProposition 3.10\nRenaming is a congruence w.r.t. \u03c0, i.e.,\n\u03c1(\u03c0V ([\u03b8]U )) = \u03c0\u03c1(V ) (\u03c1([\u03b8]U )) .\nfor [\u03b8]U \u2208 ISubst \u223c and \u03c1 \u2208 Ren.\nProof\nBy definition \u03c1(\u03c0V ([\u03b8]U )) = \u03c1([\u03b8]U\u2229V ) = [\u03c1(\u03b8)]\u03c1(U\u2229V ) . Since \u03c1 is bijective, \u03c1(U \u2229\nV ) = \u03c1(U ) \u2229 \u03c1(V ) and therefore \u03c1(\u03c0V ([\u03b8]U )) = \u03c0\u03c1(V ) ([\u03c1(\u03b8)]\u03c1(U) ) = \u03c0\u03c1(V ) (\u03c1([\u03b8]U )),\nwhich concludes the proof.\nProposition 3.11\nRenaming only depends from the variables of interest, i.e., if \u03c11 , \u03c12 \u2208 Ren, [\u03b8]U \u2208\nISubst \u223c and \u03c11 |U = \u03c12 |U , then \u03c11 ([\u03b8]U ) = \u03c12 ([\u03b8]U ). In particular, if \u03c11 |U = id , then\n\u03c11 ([\u03b8]U ) = [\u03b8]U .\nProof\nLet us denote \u03c11 (U ) = \u03c12 (U ) by W . We need to prove that \u03c11 (\u03b8) \u223cW \u03c12 (\u03b8). It is\n\u22121\n\u22121\nobvious that \u03c1\u22121\n1 |W = \u03c12 |W . Therefore, given \u03c1 = \u03c11 \u25e6 \u03c12 , we have that for each\n\u22121\nx \u2208 W , \u03c1(\u03c12 (\u03b8)(x)) = \u03c1(\u03c12 (\u03b8(\u03c1\u22121\n2 (x)))) = \u03c11 (\u03b8(\u03c11 (x))).\n3.2.3 Unification\nGiven U, V \u2208 \u2118f (V), [\u03b81 ]U , [\u03b82 ]V \u2208 ISubst \u223c , we define the most general unifier\nbetween these two classes as the mgu of suitably chosen representatives, where\nvariables not of interest are renamed apart. In formulas:\nmgu([\u03b81 ]U , [\u03b82 ]V ) = [mgu(\u03b81\u2032 , \u03b82\u2032 )]U\u222aV\n\n(8)\n\nwhere \u03b81 \u223cU \u03b81\u2032 \u2208 ISubst, \u03b82 \u223cV \u03b82\u2032 \u2208 ISubst and (U \u222a vars(\u03b81\u2032 )) \u2229 (V \u222a vars(\u03b82\u2032 )) \u2286\nU \u2229 V . The last condition is needed to avoid variables clashes between the chosen\nrepresentatives \u03b81\u2032 and \u03b82\u2032 .\nExample 3.12\nLet \u03b81 = {x/a, y/t(v1 , v1 , v2 )} and \u03b82 = {y/t(a, v2 , v1 ), z/b}. Then\nmgu([\u03b81 ]x,y , [\u03b82 ]y,z ) = [{x/a, y/t(a, a, v), z/b}]x,y,z\nby choosing \u03b81\u2032 = \u03b81 and \u03b82\u2032 = {y/t(a, w, v), z/b}. In this case we have\n{x/a, y/t(a, a, v), z/b} \u223cx,y,z\nmgu(\u03b81\u2032 , \u03b82\u2032 ) = {x/a, y/t(a, a, v), z/b, v1/a, w/a, v2 /v} .\nWe may prove that mgu over ISubst \u223c is well defined and that mgu([\u03b81 ]U , [\u03b82 ]V ) is\nthe greatest lower bound of [\u03b81 ]U and [\u03b82 ]V w.r.t. \u0016.\nTheorem 3.13\nmgu is well-defined.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n15\n\nProof\nWe begin by proving that, given \u03b81 , \u03b81\u2032 , \u03b82 \u2208 ISubst, if \u03b81 \u223cU \u03b81\u2032 with (U \u222avars(\u03b81 ))\u2229\n(V \u222a vars(\u03b82 )) \u2286 U \u2229 V and (U \u222a vars(\u03b81\u2032 )) \u2229 (V \u222a vars(\u03b82 )) \u2286 U \u2229 V , then\nmgu(\u03b81 , \u03b82 ) \u223cU\u222aV mgu(\u03b81\u2032 , \u03b82 ). We have the following equalities:\nmgu(\u03b81 , \u03b82 )\n\u223cU\u222aV mgu(\u03b81 , \u03b82 )|U\u222aV\n= mgu(\u03b81|U , \u03b82 , \u03b81|\u2212U )|U\u222aV\n= (mgu(\u03b81 |U , \u03b82 ) \u25e6 \u03b81 |\u2212U )|U\u222aV\n= mgu(\u03b81 |U , \u03b82 )|U\u222aV .\nIn the last step, we use the fact that dom(\u03b81|\u2212U ) is disjoint from vars(\u03b81|U ) by\nidempotency of \u03b81 and it is disjoint from vars(\u03b82 ) by the assumptions (U \u222avars(\u03b81 ))\u2229\n(V \u222a vars(\u03b82 )) \u2286 U \u2229 V . Since \u03b81 \u223cU \u03b81\u2032 , there exists \u03c1 \u2208 Ren such that (\u03c1 \u25e6 \u03b81\u2032 )|U =\n\u2032\n) is an injective map of variables whose range\n\u03b81 |U . The restriction of \u03c1 to vars(\u03b81|U\nis vars(\u03b81 |U ). By applying Lemma 3.4, it follows that we may choose a \u03c1 such that\nvars(\u03c1) \u2286 \u03b81 (U ) \u222a \u03b81\u2032 (U ) \u2286 vars(\u03b81 ) \u222a vars(\u03b81\u2032 ) \u222a vars(U ). Then vars(\u03c1) \u2229 V \u2286 U . We\nhave:\nmgu(\u03b81|U , \u03b82 )|U\u222aV\n= mgu((\u03c1 \u25e6 \u03b81\u2032 )|U , \u03b82 )|U\u222aV\n= (mgu((\u03c1 \u25e6 \u03b81\u2032 )|U , \u03b82 ) \u25e6 \u03b8\u2032 )|U\u222aV\n\n[for each \u03b8\u2032 s.t. dom(\u03b8\u2032 ) \u2229 (U \u222a V ) = \u2205]\n\n= mgu((\u03c1 \u25e6 \u03b81\u2032 )|U , \u03b82 , (\u03c1 \u25e6 \u03b81\u2032 )|\u2212U )|U\u222aV\n\n[by choosing \u03b8\u2032 = (\u03c1 \u25e6 \u03b81\u2032 )|\u2212U ]\n\n= mgu(\u03c1 \u25e6 \u03b81\u2032 , \u03b82 )|U\u222aV\n= (\u03c1\u2032 \u25e6 mgu(\u03b81\u2032 , \u03b82 ))|U\u222aV\n\u223cU\u222aV mgu(\u03b81\u2032 , \u03b82 )|U\u222aV\n\u223cU\u222aV mgu(\u03b81\u2032 , \u03b82 ) .\n\n[by (Palamidessi 1990, Theorem 5.10)]\n[by Prop. 3.6]\n\nwhich proves the required property. Now, to prove the general theorem, assume\nthere are \u03b81 \u223cU \u03b81\u2032 , \u03b82 \u223cV \u03b82\u2032 with (U \u222a vars(\u03b81 )) \u2229 (V \u222a vars(\u03b82 )) \u2286 U \u2229 V and\n(U \u222a vars(\u03b81\u2032 )) \u2229 (V \u222a vars(\u03b82\u2032 )) \u2286 U \u2229 V . Then, consider a new substitution \u03b81\u2032\u2032 \u223cU \u03b81\u2032\nsuch that (U \u222a vars(\u03b81\u2032\u2032 )) \u2229 (V \u222a vars(\u03b82 )) \u2286 U \u2229 V , (U \u222a vars(\u03b81\u2032\u2032 )) \u2229 (V \u222a vars(\u03b82\u2032 )) \u2286\nU \u2229 V and we repeatedly apply the previous property, obtaining\nmgu(\u03b81 , \u03b82 ) \u223cU\u222aV mgu(\u03b81\u2032\u2032 , \u03b82 ) \u223cU\u222aV mgu(\u03b81\u2032\u2032 , \u03b82\u2032 ) \u223cU\u222aV mgu(\u03b81\u2032 , \u03b82\u2032 ) .\nNote that, in the proof, the condition (U \u222a vars(\u03b81\u2032 )) \u2229 (V \u222a vars(\u03b82\u2032 )) \u2286 U \u2229 V\nimplies that vars(\u03b81\u2032 )\u2229V \u2286 U \u2229V and vars(\u03b82\u2032 )\u2229U \u2286 U \u2229V . If we relax the condition\nto vars(\u03b81\u2032 ) \u2229 vars(\u03b82\u2032 ) \u2286 U \u2229 V then this property no longer holds and mgu ceases\nto be well defined. This is actually the origin of the flaw in (Cortesi and Fil\u00e9 1999)\nwhich we will examine in Section 8.2.\nExample 3.14\nConsider \u03b81 = {x/a} and \u03b82 = {u/b}. Assume we have a relaxed definition of mgu\nas stated above. Then, to compute mgu([\u03b81 ]x , [\u03b82 ]u,v ) we may choose \u03b81\u2032 = \u03b81 and\n\u03b82\u2032 = \u03b82 to obtain {x/a, u/b}. But with the relaxed condition we might also choose\n\n\f16\n\nG. Amato and F. Scozzari\n\n\u03b81\u2032 = {x/a, v/a} and \u03b82\u2032 = \u03b82 since it is true that vars(\u03b81\u2032 ) \u2229 vars(\u03b82\u2032 ) = \u2205. However\nmgu(\u03b81\u2032 , \u03b82\u2032 ) = {x/a, v/a, u/b} 6\u223cx,u,v {x/a, u/b}.\nTheorem 3.15\nmgu is the greatest lower bound of (ISubst \u223c , \u0016).\nProof\nIf [\u03b8]U\u222aV = mgu([\u03b81 ]U , [\u03b82 ]V ), we may assume, without loss of generality, that\n\u03b8 = mgu(\u03b81 , \u03b82 ) and \u03b81 , \u03b82 are canonical representatives. It immediately follows\nthat \u03b8 \u2264 \u03b81 and therefore \u03b8 \u0016U \u03b81 . In the same way, \u03b8 \u0016V \u03b82 .\nNow, assume [\u03b7]U\u222aV \u0016 [\u03b81 ]U and [\u03b7]U\u222aV \u0016 [\u03b82 ]V . We want to prove that [\u03b7]U\u222aV \u0016\n[\u03b8]U\u222aV . By definition of \u0016, there is a \u03c31 such that \u03b7(x) = \u03c31 (\u03b81 (x)) for each x \u2208 U .\nWe may choose \u03c31 such that dom(\u03c31 ) \u2286 rng(\u03b81 ). In the same way, there is \u03c32 such\nthat dom(\u03c32 ) \u2286 rng(\u03b82 (x)) and \u03b7(x) = \u03c32 (\u03b82 (x)) for each x \u2208 V . We may define a\nnew substitution \u03c3 such that\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2\u03c31 (\u03b81 (x)) if x \u2208 U \u222a dom(\u03c31 ),\n\u03c3(x) = \u03c32 (\u03b82 (x)) if x \u2208 V \u222a dom(\u03c32 ),\n\uf8f4\n\uf8f4\n\uf8f3x\notherwise.\nNote that this definition is correct, since the first two cases may occur simultaneously only if x \u2208 U \u2229 V , which implies \u03c31 (\u03b81 (x)) = \u03c32 (\u03b82 (x)) = \u03b7(x). It is easy to\ncheck that \u03b7 \u223cU\u222aV \u03c3 and \u03c3 = \u03c3 \u25e6 \u03b81 = \u03c3 \u25e6 \u03b82 . Therefore\n\u03b7 \u223cU\u2229V \u03c3 \u2264 mgu(\u03b81 , \u03b82 ) = \u03b8 ,\ni.e., \u03b7 \u0016U\u222aV \u03b8, which proves the thesis.\nWe now give some properties which relate the mgu with the other operations on\nISubst \u223c , namely renaming and projection.\nProposition 3.16\n\u03c1 is a congruence w.r.t. unification. In formulas, if E is a set of equations and\n[\u03b81 ]U1 , [\u03b82 ]U2 \u2208 ISubst \u223c then it holds that:\n\u2022 mgu(\u03c1(E)) = \u03c1(mgu(E))\n\u2022 \u03c1(mgu([\u03b81 ]U1 , [\u03b82 ]U2 )) = mgu(\u03c1([\u03b81 ]U1 ), \u03c1([\u03b82 ]U2 )) .\nProof\nThe first property is trivial since the unification algorithm does not depend on\nthe actual name of variables. Therefore, to prove the second property, we only\nneed to check that mgu([\u03b81 ]U1 , [\u03b82 ]U2 ) = [mgu(\u03b81\u2032 , \u03b82\u2032 )]U1 \u222aU2 (according to Eq. 8)\nimplies mgu(\u03c1([\u03b81 ]U1 ), \u03c1([\u03b82 ]U2 )) = [mgu(\u03c1(\u03b81\u2032 ), \u03c1(\u03b82\u2032 ))]\u03c1(U1 )\u222a\u03c1(U2 ) . First of all, since\n\u03b81\u2032 \u223cU1 \u03b81 , then \u03c1(\u03b81\u2032 ) \u223c\u03c1(U1 ) \u03c1(\u03b81 ), by Theorem 3.9. With the same reasoning, we\nobtain that \u03c1(\u03b82\u2032 ) \u223c\u03c1(U2 ) \u03c1(\u03b82 ). Then, we prove that (\u03c1(U1 ) \u222a vars(\u03c1(\u03b81\u2032 ))) \u2229 (\u03c1(U2 ) \u222a\nvars(\u03c1(\u03b82\u2032 ))) \u2286 \u03c1(U1 ) \u2229 \u03c1(U2 ). It is obvious that \u03c1(vars(\u03b8)) = vars(\u03c1(\u03b8)). Therefore,\nsince \u03c1 is bijective,\n(\u03c1(U1 ) \u222a vars(\u03c1(\u03b81\u2032 ))) \u2229 (\u03c1(U2 ) \u222a vars(\u03c1(\u03b82\u2032 )))\n= \u03c1((U1 \u222a vars(\u03b81\u2032 )) \u2229 (U2 \u222a vars(\u03b82\u2032 ))) \u2286 \u03c1(U1 \u2229 U2 ) = \u03c1(U1 ) \u2229 \u03c1(U2 ) .\n\n\fOptimality in goal-dependent analysis of Sharing\n\n17\n\nProposition 3.17\nGiven a set of variables V and [\u03b81 ]U1 , [\u03b82 ]U2 \u2208 ISubst \u223c , we have that\n\u03c0V (mgu(\u03c0V ([\u03b81 ]U1 ), [\u03b82 ]U2 )) = mgu(\u03c0V ([\u03b81 ]U1 ), \u03c0V ([\u03b82 ]U2 )) .\nProof\nFirst observe that \u03c0V (mgu(\u03c0V ([\u03b81 ]U1 ), [\u03b82 ]U2 ))) = [\u03b8]V \u2229((V \u2229U1 )\u222aU2 ) = [\u03b8]V \u2229(U1 \u222aU2 )\nwhere \u03b8 \u2208 mgu(\u03b81\u2032 , \u03b82\u2032 ), \u03b81\u2032 and \u03b82\u2032 are canonical representatives of [\u03b81 ]V \u2229U1 and [\u03b82 ]U2\nand vars(\u03b81\u2032 )\u2229vars(\u03b82\u2032 ) \u2286 V \u2229U1 \u2229U2 . Note that \u03b82\u2032 \u223cU2 \u03b82 and therefore \u03b82\u2032 \u223cV \u2229U2 \u03b82 .\nMoreover (vars(\u03b81\u2032 )\u222a(V \u2229U1 ))\u2229(vars(\u03b82\u2032 )\u222a(V \u2229U2 )) \u2286 V \u2229U1 \u2229U2 , and therefore \u03b81\u2032\nand \u03b82\u2032 are valid representatives to compute mgu(\u03c0V ([\u03b81 ]U1 ), \u03c0V ([\u03b82 ]U2 )) according\nto (8). Therefore [\u03b8]V \u2229(U1 \u222aU2 ) = mgu(\u03c0V ([\u03b81 ]U1 ), \u03c0V ([\u03b82 ]U2 )) and this proves the\nthesis.\nThanks to the above properties, the algebraic structure of the domain ISubst \u223c is\nvery similar to (locally finite) cylindric algebras (Henkin et al. 1971). In particular,\nif the unit element is defined as [\u01eb]\u2205 , the diagonal elements are given by the substitutions [x/y]{x,y} and cylindrification is defined as cx ([\u03b8]V ) = \u03c0V \\{x} ([\u03b8]V ), then\nthese operators satisfy the axioms defining a cylindric algebra. The fundamental\ndifference is that the underlying set ISubst \u223c is not a boolean algebra.\nIt would be possible, as in (Palamidessi 1990), to define a \"least common antiinstance\" operator which corresponds to the least upper bound in ISubst \u223c . However,\nsince it is not used in the semantic framework we are going to describe, we omit to\ndefine this operator.\n\n4 Concrete Semantics\nSince we are interested in goal-dependent analysis of logic programs, we need a\ngoal-dependent semantics which is well suited for static analysis, i.e., a collecting\nsemantics over computed answers. Unfortunately, using a collecting goal-dependent\nsemantics may lead to a loss of precision already at the concrete level, as shown\nby Marriott et al. (1994). It is possible to reduce the impact of this problem by\nusing two different operators for forward and backward unification. In particular, it\nturns out that backward unification may be realized using the operation of matching between substitutions (Bruynooghe 1991; Le Charlier et al. 1991). We follow\nthe same approach and define a new denotational framework based on existential\nsubstitutions and inspired by (Cortesi et al. 1994).\n\n4.1 Concrete Domain\nWe start to define the concrete domain for the semantics. A concrete object is\nessentially a set of existential substitutions with a fixed set of variables of interest.\nIn formulas:\nPsub = {[\u0398, U ] | \u0398 \u2286 ISubst \u223cU , U \u2208 \u2118f (V)} \u222a {\u22a5Ps , \u22a4Ps }\n\n\f18\n\nG. Amato and F. Scozzari\n\nwhere \u22a4Ps and \u22a5Ps are the top and bottom elements respectively and\n[\u03981 , U1 ] \u2291Ps [\u03982 , U2 ] \u21d0\u21d2 U1 = U2 and \u03981 \u2286 \u03982 .\nThe notation we adopt may appear clumsy, since the set of variables of interest U\nin [\u0398, U ] may be derived from \u0398. However, when we move to the abstract domain,\nwe need to explicitly keep track of this set U . By using [\u0398, U ] in Psub, we want to\nkeep a consistent notation for both concrete and abstract domains.\nIt turns out that (Psub, \u2291Ps ) is a complete lattice, and we denote by \u2294Ps its least\nupper bound, which is given by\n\u22a4Ps \u2294Ps \u03c7 = \u03c7 \u2294Ps \u22a4Ps =\u22a4Ps\n\u22a5Ps \u2294Ps \u03c7 = \u03c7 \u2294Ps \u22a5Ps =\u03c7\n(\n[\u03981 , U1 ] \u2294Ps [\u03982 , U2 ] =\n\n[\u03981 \u222a \u03982 , U1 ]\n\nif U1 = U2 ,\n\n\u22a4Ps\n\notherwise.\n\n(9)\n\nWe now define the main operations over Psub, that is: projection on a set of\nvariables, unification of an object with a single substitution and the operation\nfor matching two objects of Psub. All the operations are strict: when one of the\nargument is \u22a5Ps the result is \u22a5Ps . If no argument is \u22a5Ps and at least one of the\nargument is \u22a4Ps the result is \u22a4Ps . Therefore, in the following, we will omit the\ncases for the objects \u22a5Ps and \u22a4Ps .\nGiven [\u0398, U ] \u2208 Psub and V \u2286 V, we define the projection of [\u0398, U ] on the set of\nvariables V as\n\u03c0Ps ([\u0398, U ], V ) = [{\u03c0V ([\u03c3]U ) | [\u03c3]U \u2208 \u0398}, U \u2229 V ] .\n\n(10)\n\nThe concrete unification unif Ps : Psub \u00d7 ISubst \u2192 Psub is given by:\nunif Ps ([\u0398, U ], \u03b4) = [{mgu([\u03c3]U , [\u03b4]vars(\u03b4) ) | [\u03c3]U \u2208 \u0398}, U \u222a vars(\u03b4)].\n\n(11)\n\nThe operations \u03c0Ps and unif Ps are just the pointwise extensions of \u03c0 and mgu.\nNote that, in unif Ps , the argument \u03b4 may have variables which do not appear in\nU . This is not always the case in literature. For example, in (Cortesi and Fil\u00e9\n1999; Bagnara et al. 2005) we find a variant of unif Ps which only consider the case\nwhen vars(\u03b4) \u2286 U . When this does not happen, the same effect is obtained by first\nenlarging the set of variables of interest U , and then applying unification. Although\nnothing changes at the concrete level, this gives a loss of precision when we move\nto the abstract side, since the composition of two optimal abstract operators is\ngenerally less precise than the optimal abstract counterpart of the whole unif Ps\n(see Section 6).\nFinally, we define the matching operation. The idea is to design an operator which\nperforms unification between two substitutions [\u03b81 ]U1 and [\u03b82 ]U2 only if the process\nof unification does not instantiate the first substitution. In other words, we require\nthat if we compute mgu([\u03b81 ]U1 , [\u03b82 ]U2 ) and we only observe variables in U1 , that is\n\u03c0U1 (mgu([\u03b81 ]U1 , [\u03b82 ]U2 )), then we obtain exactly [\u03b81 ]U1 . The next proposition shows\nthis is equivalent to require that \u03b81 \u0016U1 \u2229U2 \u03b82 .\nProposition 4.1\n\n\fOptimality in goal-dependent analysis of Sharing\n\n19\n\nGiven two existential substitutions [\u03b81 ]U1 and [\u03b82 ]U2 , we have that \u03b81 \u0016U1 \u2229U2 \u03b82 iff\n[\u03b81 ]U1 = \u03c0U1 (mgu([\u03b81 ]U1 , [\u03b82 ]U2 )).\nProof\nBy Prop. 3.17 we obtain \u03c0U1 (mgu([\u03b81 ]U1 , [\u03b82 ]U2 )) = mgu(\u03c0U1 ([\u03b81 ]U1 ), \u03c0U1 ([\u03b82 ]U2 )) =\nmgu([\u03b81 ]U1 , [\u03b82 ]U1 \u2229U2 ). Since mgu is the greatest lower bound of ISubst \u223c , we have\nthat [\u03b81 ]U1 = mgu([\u03b81 ]U1 , [\u03b82 ]U1 \u2229U2 ) iff [\u03b81 ]U1 \u0016 [\u03b82 ]U1 \u2229U2 which, by definition, is\nequivalent to \u03b81 \u0016U1 \u2229U2 \u03b82 .\nWe can now define the matching operator matchPs : Psub \u00d7 Psub \u2192 Psub as follows:\nmatchPs ([\u03981 , U1 ], [\u03982 , U2 ]) = [{mgu([\u03b81 ]U1 , [\u03b82 ]U2 ) |\n\u03b81 \u0016U1 \u2229U2 \u03b82 , [\u03b81 ]U1 \u2208 \u03981 , [\u03b82 ]U2 \u2208 \u03982 }, U1 \u222a U2 ] . (12)\nThe above operator allows us to unify all the pairs of substitutions [\u03b81 ]U1 \u2208 \u03981 and\n[\u03b82 ]U2 \u2208 \u03982 , under the condition that the common variables in U1 and U2 may not\nbe further instantiated w.r.t. their values in \u03b81 .\nExample 4.2\nLet \u03981 = {[x/y]x,y } and \u03982 = {[u/x]u,x, [x/t(u)]u,x }. Then\nmatchPs ([\u03981 , {x, y}], [\u03982 , {u, x}]) = [{[x/y, u/y]x,y,u}, {x, y, u}] .\nNote that [y/t(u), x/t(u)]u,x,y , obtained by unifying [x/y]x,y with [x/t(u)]u,x , is not\nin the result of matching. This is because [x/t(u)]u,x is strictly more instantiated\nthen [x/y]x,y w.r.t. the variable x and therefore {x/y} 6\u0016x {x/t(u)}.\nProposition 4.3\nThe operations \u03c0Ps , unif Ps and matchPs are continuous over Psub.\nProof\nTrivial from their definitions. If we do not consider the element \u22a4Ps , they are\nactually additive.\n4.2 Semantics\nUsing the operators defined so far, we introduce a denotational semantics for logic\nprograms. It computes, for a given goal G, the set of computed answers for a\nprogram w.r.t. G modulo the equivalence relation \u223cvars(G) . It is a goal-dependent\ncollecting semantics (Cousot and Cousot 1994), in that it works by computing the\nset of possibly entry and exit substitutions at each point in the program.\nWe call denotation an element in the set of continuous maps:\nc\n\nDen = Atoms \u2192 Psub \u2192 Psub .\nWe have the following semantic functions:\nP : Progs \u2192 Den\nc\n\nC : Clauses \u2192 Den \u2192 Den\nc\n\nc\n\nB : Bodies \u2192 Den \u2192 Psub \u2192 Psub .\n\n(13)\n\n\f20\n\nG. Amato and F. Scozzari\n\nThe corresponding definitions4 , given d \u2208 Den and x \u2208 Psub, are:\n!\nG\nPJP K = lfp \u03bbd.\nCJclKd\nPs\ncl\u2208P\n\nCJH \u2190 BK d A \u03c7 = UbPs ((BJBKdUfPs (\u03c7, A, H)), \u03c7, H, A)\n\nBJ\u0003K d \u03c7 = \u03c7\nBJA, BK d \u03c7 = BJBKd(dA\u03c7)\ndefined by means of the following operators:\nUfPs : Psub \u00d7 Atoms \u00d7 Atoms \u2192 Psub ,\nUbPs : Psub \u00d7 Psub \u00d7 Atoms \u00d7 Atoms \u2192 Psub .\nUfPs and UbPs are respectively the forward and backward unification (Muthukumar\nand Hermenegildo 1992). They are used according to the following pattern:\n\u2022 the forward unification, in order to compute the set of entry substitutions\nUfPs (\u03c7, A, H) from the set of call substitutions \u03c7;\n\u2022 the backward unification, in order to compute the set of answer substitutions\nUbPs ((BJBKdUfPs (\u03c7, A, H)), \u03c7, H, A) starting from the set of exit substitutions\nBJBKdUfPs (\u03c7, A, H).\nThe formal definitions of UfPs and UbPs are the following:\nUfPs ([\u0398, U ], A1 , A2 ) = \u03c0Ps (unif Ps (\u03c1([\u0398, U ]), mgu(\u03c1(A1 ) = A2 )), vars(A2 )) , (14)\nwhere \u03c1 is a renaming such that \u03c1(U \u222a vars(A1 )) \u2229 vars(A2 ) = \u2205 and \u03c1([\u0398, U ]) =\n[{\u03c1([\u03c3]U ) | [\u03c3]U \u2208 \u0398}, \u03c1(U )] is the obvious lifting of renamings from ISubst \u223c to\nPsub.\nUbPs ([\u03981 , U1 ], [\u03982 , U2 ], A1 , A2 ) =\n\u03c0Ps (matchPs (\u03c1([\u03981 , U1 ]), unif Ps ([\u03982 , U2 ], mgu(\u03c1(A1 ) = A2 ))), U2 \u222a vars(A2 ))\n(15)\nwhere \u03c1 is a renaming such that \u03c1(U1 \u222a vars(A1 )) \u2229 (U2 \u222a vars(A2 )) = \u2205. If \u03c1(A1 )\nand A2 do not unify, the results for both the operations is assumed to be \u22a5Ps .\nExample 4.4\nConsider the goal p(x, y, z) with y = f (x, z) and the trivial program P with just\none clause\np(u,v,w).\nWe first compute the concrete semantics PJP K = lfp \u03bbd.CJp(u, v, w) \u2190 \u0003Kd. According to the semantic definition, we have that:\nCJp(u, v, w) \u2190 \u0003Kd = \u03bbA.\u03bb\u03c7.UbPs ((BJ\u0003KdUfPs (\u03c7, A, p(u, v, w))), \u03c7, p(u, v, w), A) .\n4\n\nHere we use the lambda notation, writing lfp \u03bbx.E(x) to denote the least fixed point of the\nfunction f given by f (x) = E(x).\n\n\fOptimality in goal-dependent analysis of Sharing\n\n21\n\nSince BJ\u0003Kd = \u03bb\u03c7.\u03c7, this is equivalent to\n\u03bbA.\u03bb\u03c7.UbPs (UfPs (\u03c7, A, p(u, v, w)), \u03c7, p(u, v, w), A) ,\nfrom which we immediately obtain the semantics of the program P :\nPJP K = \u03bbA.\u03bb\u03c7.UbPs (UfPs (\u03c7, A, p(u, v, w)), \u03c7, p(u, v, w), A) .\nWe now compute the semantics of the goal p(x, y, z) with y = f (x, z). In order to\nimprove readability, we will omit subscripts on classes of substitutions.\nPJP Kp(x, y, z)[{[y/f (x, z)]}, {x, y, z}] =\nUbPs (UfPs ([{[y/f (x, z)]}, {x, y, z}], p(x, y, z), p(u, v, w)),\n[{[y/f (x, z)]}, {x, y, z}], p(u, v, w), p(x, y, z)) .\nWe first compute the forward unification\nUfPs ([{[y/f (x, z)]}, {x, y, z}], p(x, y, z), p(u, v, w)) =\n[{[u/x\u2032 , v/f (x\u2032 , z \u2032 ), w/z \u2032 ]}, {u, v, w}] ,\nwhere we have renamed x and z to x\u2032 and z \u2032 to avoid ambiguities, although it is\nnot needed. Now we can compute the semantics of the goal.\nPJP Kp(x, y, z)[{[y/f (x, z)]}, {x, y, z}]\n= UbPs ([{[u/x\u2032 , v/f (x\u2032 , z \u2032 ), w/z \u2032 ]}, {u, v, w}], [{[y/f (x, z)]}, {x, y, z}],\np(u, v, w), p(x, y, z))\n= \u03c0Ps (matchPs ([{[u/x\u2032 , v/f (x\u2032 , z \u2032 ), w/z \u2032 ]}, {u, v, w}],\n[{[u/x, v/f (x, z), w/z, y/f (x, z)]}, {u, v, w, x, y, z}]), {x, y, z})\n= \u03c0Ps ([{[u/x, v/f (x, z), w/z, y/f (x, z)]}, {u, v, w, x, y, z}], {x, y, z})\n= [{[y/f (x, z)]}, {x, y, z}]\nThus, we have only one computed answer substitution for the goal p(x, y, z) with\ny = f (x, z), which is {y/f (x, z)}.\nTheorem 4.5\nUfPs and UbPs are well defined, in that they are independent from the choice of \u03c1.\nMoreover, they are continuous.\nProof\nContinuity is trivial from their definition, therefore we only need to prove the independence from the choice of the renaming \u03c1. We only consider the case when none\nof the arguments are \u22a5Ps or \u22a4Ps , since otherwise the result is always \u22a5Ps or \u22a4Ps .\nMoreover, note that, given atoms A1 and A2 , if \u03c11 and \u03c12 are renamings such that\n\u03c1i (vars(A1 )) \u2229 vars(A2 ) = \u2205 for i \u2208 {1, 2}, then \u03c11 (A1 ) and A2 unify iff \u03c12 (A1 ) and\nA2 unify. Therefore, we can restrict ourselves to the case where the two atoms given\nas arguments, appropriately renamed, do unify. Otherwise, the result is always \u22a5Ps .\nObserve that, by Prop. 3.16, given \u03c1 \u2208 Ren, [\u03b81 ]U1 , [\u03b82 ]U2 \u2208 ISubst \u223c , we have that\n\n\f22\n\nG. Amato and F. Scozzari\n\n\u03c1(mgu([\u03b81 ]U1 , [\u03b82 ]U2 )) = mgu(\u03c1([\u03b81 ]U1 ), \u03c1([\u03b82 ]U2 )). By definition of unif Ps , it follows\nthat \u03c1(unif Ps ([\u0398, U ], \u03b4)) = unif Ps (\u03c1([\u0398, U ]), \u03c1(\u03b4)), since vars(\u03c1(\u03b4)) = \u03c1(vars(\u03b4)).\nLet \u03c11 , \u03c12 be renamings. We first show that\n\u03c0Ps (unif Ps (\u03c11 ([\u0398, U ]), mgu(\u03c11 (A1 ) = A2 )), vars(A2 )) =\n\u03c0Ps (unif Ps (\u03c12 ([\u0398, U ]), mgu(\u03c12 (A1 ) = A2 )), vars(A2 ))\nprovided that \u03c1i (U \u222a vars(A1 )) \u2229 vars(A2 ) = \u2205, for i \u2208 {1, 2}. Let W = \u03c11 (U \u222a\nvars(A1 )) and \u03b4 = (\u03c12 \u25e6 \u03c1\u22121\n1 )|W . Then \u03b4 may be viewed as an injective map from\nV to V, since it is the composition of injective functions. By Lemma 3.4 there\nexists a renaming \u03c1 such that \u03c1|W = \u03b4 and vars(\u03c1) = vars(\u03b4) \u2286 W \u222a rng(\u03b4) \u2286\nW \u222a \u03c12 (U \u222a vars(A1 )). Observe that vars(\u03c1) \u2229 vars(A2 ) = \u2205 since, by hypothesis,\nfor each i \u2208 {1, 2} it is the case that \u03c1i (U \u222a vars(A1 )) \u2229 vars(A2 ) = \u2205. Thus the\nfollowing equivalences hold:\n\u03c0Ps (unif Ps (\u03c11 ([\u0398, U ]), mgu(\u03c11 (A1 ) = A2 )), vars(A2 ))\n= \u03c1(\u03c0Ps (unif Ps (\u03c11 ([\u0398, U ]), mgu(\u03c11 (A1 ) = A2 )), vars(A2 )))\n[since \u03c1|vars(A2 ) = id and by Prop. 3.11]\n\n= \u03c0Ps (\u03c1(unif Ps (\u03c11 ([\u0398, U ]), mgu(\u03c11 (A1 ) = A2 ))), vars(A2 ))\n[since \u03c1 is a congruence for \u03c0Ps by Prop. 3.10]\n\n= \u03c0Ps (unif Ps (\u03c1(\u03c11 ([\u0398, U ])), mgu(\u03c1(\u03c11 (A1 )) = \u03c1(A2 ))), vars(A2 ))\n[since \u03c1 is a congruence for unif Ps by Prop. 3.16]\n\n= \u03c0Ps (unif Ps (\u03c12 ([\u0398, U ]), mgu(\u03c12 (A1 )) = A2 ), vars(A2 ))\n[since (\u03c1 \u25e6 \u03c11 )|U \u222avars(A1 ) = \u03c12 |U \u222avars(A1 ) and by Prop. 3.11] .\n\nWe now show that UbPs is independent from the choice of the renaming. First of\nall, note that by Prop. 3.16 and Theorem 3.9 the following follows:\n\u03c1(matchPs ([\u03981 , U1 ], [\u03982 , U2 ])) = matchPs (\u03c1([\u03981 , U1 ]), \u03c1([\u03982 , U2 ])) .\nAssume given \u03c11 , \u03c12 \u2208 Ren such that \u03c1i (U1 \u222a vars(A1 )) \u2229 (U2 \u222a vars(A2 )) = \u2205, for\ni \u2208 {1, 2}. Let W = \u03c11 (U1 \u222a vars(A1 )) and \u03b4 = (\u03c12 \u25e6 \u03c1\u22121\n1 )|W . As shown above, there\nexists \u03c1 \u2208 Ren such that \u03c1|W = \u03b4 and vars(\u03c1) = vars(\u03b4) \u2286 W \u222a \u03c12 (U1 \u222a vars(A1 )).\nObserve that \u03b4|U2 \u222avars(A2 ) = id . Thus the following equivalences hold, where Z =\nU2 \u222a vars(A2 ):\n\u03c0Ps (matchPs (\u03c11 ([\u03981 , U1 ]), unif Ps ([\u03982 , U2 ], mgu(\u03c11 (A1 ) = A2 ))), Z)\n= \u03c1(\u03c0Ps (matchPs (\u03c11 ([\u03981 , U1 ]), unif Ps ([\u03982 , U2 ], mgu(\u03c11 (A1 ) = A2 ))), Z))\n= \u03c0Ps (matchPs (\u03c1(\u03c11 ([\u03981 , U1 ])), unif Ps (\u03c1([\u03982 , U2 ]), mgu(\u03c1(\u03c11 (A1 )) = \u03c1(A2 )))), Z)\n= \u03c0Ps (matchPs (\u03c12 ([\u03981 , U1 ]), unif Ps ([\u03982 , U2 ], mgu(\u03c12 (A1 ) = A2 ))), Z) .\nThis concludes the proof of the theorem.\nTheorem 4.6\nAll the semantic functions are well defined and continuous.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n23\n\nProof\nThe proof is trivial since the semantic functions are obtained by composition, application, projection and tupling of continuous functions. Therefore, they are continuous and compute continuous denotations. Moreover, they do not depend on the\nchoice of \u03c1 in UfPs and UbPs , as proved in Theorem 4.5.\nNote that several frameworks have been developed for logic programs, and not\nall of them use the same operators for forward and backward unification. We will\ndiscuss the benefits of our choices later, when we introduce the abstract operators,\nsince the relative merits of the different proposals mainly arise when speaking about\nabstractions.\n4.3 Correctness and Completeness\nThe semantics we have defined in this section is significant only up to the point that,\nstudying its properties, it is possible to derive some conclusions about the properties\nof the real operational behavior of logic programs. We said before that we considered\nas the relevant operational observable of our analysis the set of classes of computed\nanswers for a goal. Therefore, the best we can expect from our collecting semantics\nis that it enables us to recover the set of computed answer for each goal. Our first\ntheorem is a partial positive answer to this question.\nTheorem 4.7\n(Semantic Correctness) Given a program P and an goal G, if \u03b8 is a computed\nanswer for the goal G, then BJGK(PJP K)G[{\u01eb}, vars(G)] \u2292Ps [{[\u03b8]}, vars(G)].\nProof\nThe proof, quite long and tedious, may be found in the Appendix A.\nTherefore, we know that all the computed answers may be obtained by our semantics. However, the opposite is not true: the semantics given in this paper, although\nmore precise than a semantics which only uses unification, is not complete w.r.t.\ncomputed answers. Actually, Marriott et al. (1994, Section 5.5) give an example\nwhere a collecting goal-dependent semantics computes a substitution which is not\na computed answer. When matching is used to compute the backward unification, as\nit is the case in our framework, that example does not work anymore (see Example\n7.3).\nHowever, also with the use of matching, the collecting semantics computes substitutions which are not computed answers. Consider the program P given by the\nfollowing clauses:\np(x,y) :- q(x).\nq(x).\nWe want to compute PJP Kp(x, y)[\u0398, {x, y}] where \u0398 = {[x/y], [x/a]}. It is easy to\ncheck that\nPJP Kq(x)[\u2206, {x}] = [\u2206, {x}]\n\n\f24\n\nG. Amato and F. Scozzari\n\nfor each [\u2206, {x}] \u2208 Psub. Therefore, this implies that\nPJP Kp(x, y)[\u0398, {x, y}] = [{[x/y], [x/a], [x/a, y/a]}, {x, y}] .\nThe substitution [x/a, y/a] arises from calling q(x) with the substitution [x/a] and\nmatching the result with [x/y], which is not forbidden by matching. However, there\nis no substitution in the class of [{x/a, y/a}]x,y which is a computed answer for the\ngoal p(x, y) in the program P with entry substitution in \u0398.\nThis loss of precision is not relevant for downward-closed abstract domains, where\ngoal-dependent collecting semantics are more precise than goal-independent ones.\nThis is not the case for upward-closed abstract domain, where goal-independent semantics are more precise than goal-dependent ones. Garc\u0131\u0301a de la Banda et al. (1998)\ndeal with this topic and show several semantics which combine a goal-dependent\nand a goal-independent computation to improve precision over all the conditions.\n5 Abstract Domain and Semantics\nSeveral abstract domains have been used for analyses of sharing and aliasing. We\nuse the domain Sharing (Jacobs and Langen 1992; Cortesi and Fil\u00e9 1999) which\ncomputes set-sharing information:\nSharing = {[A, U ] | A \u2286 \u2118(U ), (A 6= \u2205 \u21d2 \u2205 \u2208 A), U \u2208 \u2118f (V)} \u222a {\u22a4Sh, \u22a5Sh } .\nIntuitively, an abstract object [A, U ] describes the relations between the variables in\nU : if S \u2208 A, the variables in S are allowed to share a common variable. For instance,\n[{{x, y}, {z}, \u2205}, {x, y, z}] represents the (equivalence classes of) substitutions where\nx and y may possibly share, while z is independent from both x and y: {x/y} and\n\u01eb are two of such substitutions while {x/z} is not.\nThe domain is ordered like Psub, with \u22a4Sh and \u22a5Sh as the greatest and least\nelement respectively, and [A1 , U1 ] \u2291Sh [A2 , U2 ] iff U1 = U2 and A1 \u2286 A2 . The least\nupper bound satisfies the following property:\n(\n[A1 \u222a A2 , U1 ] if U1 = U2 ,\n[A1 , U1 ]\u2294Sh [A2 , U2 ] =\n(16)\n\u22a4Sh\notherwise.\nTo design the abstraction from Psub to Sharing, we first define a map \u03b1Sh :\nISubst \u223c \u2192 Sharing as\n\u03b1Sh ([\u03c3]V ) = [{occ(\u03c3, y) \u2229 V | y \u2208 V}, V ] .\n\n(17)\n\nwhere occ(\u03c3, y) = {z \u2208 V | y \u2208 vars(\u03c3(z))} is the set of variables z such that\ny occurs in \u03c3(z). For instance, occ({x/t(y, z), x\u2032 /z, y \u2032 /z \u2032 }, z) = {x, x\u2032 , z}. We call\nsharing group an element of \u2118f (V).\nWe say that x is independent from y in [\u03c3]V when, given \u03b1Sh ([\u03c3]V ) = [S, U ], there\nis no X \u2208 S such that {x, y} \u2286 X. Given U \u2208 \u2118(V), we say that x is independent\nfrom U in [\u03c3]V when it is independent from y for each y \u2208 U different from x.\nFinally, x is independent in [\u03c3]V if it is independent from V in [\u03c3]V .\nProposition 5.1\n\n\fOptimality in goal-dependent analysis of Sharing\n\n25\n\nThe map \u03b1Sh : ISubst \u223c \u2192 Sharing is well defined, i.e., it does not depend on the\nchoice of representatives.\nProof\nIf \u03c3 \u223cV \u03c3 \u2032 , let \u03c1 \u2208 Ren such that \u03c3 \u2032 (x) = \u03c1(\u03c3(x)) for each x \u2208 V . Then\nocc(\u03c3 \u2032 , \u03c1(y)) \u2229 V = {z \u2208 V | \u03c1(y) \u2208 vars(\u03c3 \u2032 (z))}\n= {z \u2208 V | y \u2208 \u03c1\u22121 (vars(\u03c1(\u03c3(z))))}\n= {z \u2208 V | y \u2208 vars(\u03c3(z))}\n= occ(\u03c3, y) \u2229 V .\nTherefore, x \u2208 occ(\u03c3, y) \u2229 V iff x \u2208 occ(\u03c3 \u2032 , \u03c1(y)) \u2229 V , which proves the thesis.\nThe abstraction map may be lifted pointwise to \u03b1Sh : Psub \u2192 Sharing as follows:\n\u03b1Sh (\u22a5Ps ) =\u22a5Sh\nG\n\u03b1Sh ([\u0398, U ]) =\n\u03b1Sh ([\u03c3]U )\n\n\u03b1Sh (\u22a4Ps ) = \u22a4Sh\n(18)\n\nSh\n[\u03c3]U \u2208\u0398\n\nTo ease the notation, often we will write a sharing group as the sequence of its\nelements in any order (e.g., xyz represents {x, y, z}) and we omit the empty set\nwhen clear from the context. For example:\n\u03b1Sh ([{[\u01eb]}, {x, y, z}]) = [{x, y, z}, {x, y, z}]\n\u03b1Sh ([{[x/y, z/a]}, {x, y, z}]) = [{xy}, {x, y, z}]\n\u03b1Sh ([{[\u01eb], [x/y, z/a]}, {x, y, z}]) = [{xy, x, y, z}, {x, y, z}] .\nSince \u03b1Sh is additive, there is an induced concretization function \u03b3Sh , the right\nadjoint of \u03b1Sh , which maps each abstract object to the set of substitutions it represents:\n\u03b3Sh ([S, U ]) = [{[\u03b8]U | \u03b1Sh ([\u03b8]U ) \u2291Sh [S, U ]}, U ] .\n\n(19)\n\nNote that each abstract object represents the possible relations between variables:\na substitution in which all the variables in U are ground is always in \u03b3Sh ([A, U ]),\nindependently from A.\nProposition 5.2\nh\u03b1Sh , \u03b3Sh i : Psub \u21cc Sharing defines a Galois insertion.\nProof\nThat h\u03b1Sh , \u03b3Sh i is a Galois connection immediately follows from the fact they are\nan adjoint pair. Now, we want to prove that \u03b1Sh is onto. Given [S, V ] \u2208 Sharing\nand X \u2208 S, consider the substitution \u03b8X defined as\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2w if x \u2208 X\n\u03b8X (x) = a if x \u2208 V \\ X\n\uf8f4\n\uf8f4\n\uf8f3x otherwise.\n\nwhere w is a fresh variable not in V . It is easy to check that \u03b1Sh ([\u03b8X ]V ) = [{X}, S]\n\n\f26\n\nG. Amato and F. Scozzari\n\nand therefore \u03b1Sh ([{[\u03b8X ]V | X \u2208 S}, V ]) = [S, V ]. Moreover, we have \u03b1Sh (\u22a5Ps ) =\n\u22a5Sh and \u03b1Sh (\u22a4Ps ) = \u22a4Sh .\n5.1 The Abstract Semantics\nThe abstract semantics is obtained by replacing, in the definition of the concrete semantics in Section 4.2, the concrete domain Psub with the abstract domain Sharing\nand the basic operators, namely, least upper bound \u2294Ps , forward unification UfPs\nand backward unification UbPs with their corresponding abstract counterparts. The\nabstract least upper bound \u2294Sh has been already defined in the previous section.\nWe recall that, on the concrete side, we have defined the forward and backward\nunification operators in (14), (15) as:\nUfPs ([\u0398, U ], A1 , A2 ) = \u03c0Ps (unif Ps (\u03c1([\u0398, U ]), mgu(\u03c1(A1 ) = A2 )), vars(A2 ))\nUbPs ([\u03981 , U1 ], [\u03982 , U2 ], A1 , A2 ) =\n\u03c0Ps (matchPs (\u03c1([\u03981 , U1 ]), unif Ps ([\u03982 , U2 ], mgu(\u03c1(A1 ) = A2 ))), U2 \u222a vars(A2 ))\nThe abstract forward and backward unification operators are obtained by replacing,\nin the above definitions, the primitive operators with their abstract counterparts,\nnamely, abstract projection \u03c0Sh , abstract renaming \u03c1, abstract unification unif Sh\nand abstract matching matchSh .\nThe abstract operators behave exactly as the concrete ones on \u22a4Sh and \u22a5Sh .\nAbstract projection and renaming are defined as:\n\u03c0Sh ([A1 , U1 ], U2 ) =[{B \u2229 U2 | B \u2208 A1 }, U1 \u2229 U2 ] ,\n\u03c1([A, U ]) =[\u03c1(A), \u03c1(U )] .\n\n(20)\n(21)\n\nThe definition of the abstract versions of matching and unification is the main\nargument of the rest of this paper. Here we show some properties of completeness\nfor projection and renaming. Since the concrete and abstract operators behave in\nthe same way on top and bottom elements, here and in the following proofs we only\nconsider the case when all the arguments are different from \u22a5Ps /\u22a5Sh and \u22a4Ps /\u22a4Sh.\nTheorem 5.3\n\u03c0Sh is correct and complete w.r.t. \u03c0Ps .\nProof\nGiven [\u0398, V ] \u2208 Psub, we prove that \u03b1Sh (\u03c0Ps ([\u0398, V ], U )) = \u03c0Sh (\u03b1Sh ([\u0398, V ]), U ).\nWe first prove that, for each [\u03c6]V \u2208 ISubst \u223c , it holds that \u03c0Sh (\u03b1Sh ([\u03c6]V ), U ) =\n\u03b1Sh ([\u03c6]V \u2229U ). Actually\n\u03b1Sh ([\u03c6]V \u2229U ) = [{occ(\u03c6, z) \u2229 V \u2229 U | z \u2208 V}, V \u2229 U ]\n= \u03c0Sh ([{occ(\u03c6, z) \u2229 V | z \u2208 V}, V ], U )\n= \u03c0Sh (\u03b1Sh ([\u03c6]V ), U ) .\nThe result for the lifted \u03b1Sh follows trivially.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n27\n\nTheorem 5.4\nAbstract renaming is correct, complete and \u03b3-complete w.r.t. concrete renaming.\nProof\nFirst of all, given \u03c1 \u2208 Ren, y \u2208 V and \u03c6 \u2208 Subst, we prove that occ(\u03c1(\u03c6), \u03c1(y)) =\n\u03c1(occ(\u03c6, y)). Actually:\nocc(\u03c1(\u03c6), \u03c1(y)) = {z \u2208 V | \u03c1(y) \u2208 vars(\u03c1(\u03c6(\u03c1\u22121 (z))))}\n= {z \u2208 V | y \u2208 vars(\u03c6(\u03c1\u22121 (z)))}\n= {\u03c1(k) | k \u2208 V, y \u2208 vars(\u03c6(k))}\n\n[by letting k = \u03c1\u22121 (z)]\n\n= \u03c1(occ(\u03c6), y) .\nThen we prove that, given [\u03c6]V \u2208 Psub and \u03c1 \u2208 Ren, \u03b1Sh (\u03c1([\u03c6]V )) = \u03c1(\u03b1Sh ([\u03c6]V )).\nUsing the fact that \u03c1 as an operation over ISubst \u223c is bijective, we have:\n\u03b1Sh (\u03c1([\u03c6]V )) = [{occ(\u03c1(\u03c6), z) \u2229 \u03c1(V ) | z \u2208 V}, \u03c1(V )]\n= [{\u03c1(occ(\u03c6, \u03c1\u22121 (z)) \u2229 \u03c1(V ) | z \u2208 V}, \u03c1(V )]\n= \u03c1([occ(\u03c6, k) \u2229 V | k \u2208 V}, V ])\n\n[by letting z = \u03c1(k)]\n\n= \u03c1(\u03b1Sh ([\u03c6]V )) .\nThis property, lifted to Psub, gives the completeness of abstract renaming. Finally,\nwe need to prove that renaming is \u03b3-complete, i.e., that \u03b3Sh \u25e6 \u03c1 = \u03c1 \u25e6 \u03b3Sh .\n\u03b3Sh (\u03c1([S, V ])) = \u03b3Sh ([\u03c1(S), \u03c1(V )])\n\u0002\n\u0003\n= {[\u03b8]V | \u03b1Sh ([\u03b8]V ) \u2291Sh \u03c1(S)}, \u03c1(V )\n\u0002\n\u0003\n= {\u03c1([\u03b8]V ) | \u03b1Sh (\u03c1([\u03b8]V )) \u2291Sh \u03c1(S)}, \u03c1(V )\n\u0002\n\u0003\n= {\u03c1([\u03b8]V ) | \u03c1(\u03b1Sh ([\u03b8]V )) \u2291Sh \u03c1(S)}, \u03c1(V )\n\u0002\n\u0003\n= {\u03c1([\u03b8]V ) | \u03b1Sh ([\u03b8]V ) \u2291Sh S}, \u03c1(V )\n= \u03c1(\u03b3Sh ([S, V ])) .\n\nwhich concludes the proof of the theorem.\n6 Forward Unification\nWe briefly recall from (Cortesi and Fil\u00e9 1999; Bagnara et al. 2002) the definition\nof the standard operator unif \u2032Sh for abstract unification on Sharing. The abstract\nunification is performed between a set of sharing groups A and a single substitution\n\u03b4, under the assumption that vars(\u03b4) \u2286 U , and it is defined as follows:\nunif \u2032Sh ([A, U ], \u03b4) = [uSh (A, \u03b4), U ]\n\n(22)\n\nwhere uSh : \u2118(\u2118f (V)) \u00d7 ISubst \u2192 \u2118(\u2118f (V)) is defined by induction as follows:\nuSh (A, \u01eb) = A\nuSh (A, {x/t} \u228e \u03b8) = uSh (A \\ (rel(A, {x}) \u222a rel(A, vars(t)))\n\u222a bin(rel(A, {x})\u2217 , rel(A, vars(t))\u2217 ), \u03b8).\nThe auxiliary operators used in the definition of uSh are given by:\n\n(23)\n\n\f28\n\nG. Amato and F. Scozzari\n\u2022 the closure under union (or star union) (.)\u2217 : \u2118(\u2118f (V)) \u2192 \u2118(\u2118f (V))\n\b[\nA\u2217 =\nT | \u2205 6= T \u2208 \u2118f (A) 5 ;\n\n(24)\n\n\u2022 the extraction of relevant components rel : \u2118(\u2118f (V)) \u00d7 \u2118f (V) \u2192 \u2118(\u2118f (V)):\nrel(A, V ) = {T \u2208 A | T \u2229 V 6= \u2205} ;\n\n(25)\n\n\u2022 the binary union bin : \u2118(\u2118f (V)) \u00d7 \u2118(\u2118f (V)) \u2192 \u2118(\u2118f (V)):\nbin(A, B) = {T1 \u222a T2 | T1 \u2208 A, T2 \u2208 B} .\n\n(26)\n\nWe recall that we will often abuse the notation and write rel(A, o) for rel(A, vars(o))\nand x \u2208 o for x \u2208 vars(o) where o is any syntactic object.\nExample 6.1\nTake A = {xy, xz, y}, U = {w, x, y, z} and \u03b4 = {x/t(y, z), w/t(y)}. Note that, since\nw does not appear in A, then w is always bound to a ground term in \u03b3Sh ([A, U ]).\nWe have rel(A, x) = {xy, xz}, rel(A, y) = {xy, y}, rel(A, z) = {xz} and therefore\nuSh (A, {x/t(y, z)}) =A \\ {xy, xz, y} \u222a bin({xy, xz}\u2217 , {xy, xz, y}\u2217 )\n=bin({xy, xz, xyz}, {xy, xz, xyz, y})\n={xy, xz, xyz} .\nIf we take B = {xy, xz, xyz}, we obtain rel(B, w) = \u2205, rel(B, y) = {xy, xyz} and\ntherefore\nuSh (A, \u03b4) =uSh (B, {w/t(y)})\n=B \\ {xy, xyz} \u222a bin(\u2205, {xy, xyz}\u2217 )\n=B \\ {xy, xyz}\n={xz} .\nIt is worth noting that unif \u2032Sh is not the abstract counterpart of unif Ps , because\nunif \u2032Sh ([S, U ], \u03b4) is defined only under the condition that vars(\u03b4) \u2286 U . Since this is\nnot enough to define a goal-dependent semantics, when this solution is adopted,\nthere is the need of an operator to expand the set of variables of interest in a\nsubstitution. Let us introduce the following concrete operator:\n\u03b9Ps ([\u0398, U ], V ) = [{mgu([\u03c3]U , [\u01eb]V ) | [\u03c3]U \u2208 \u0398}, U \u222a V ] ,\n\n(27)\n\nwhose optimal abstract counterpart is simply given by:\n\u03b9Sh ([\u0398, U ], V ) = [\u0398 \u222a {{x} | x \u2208 V \\ U }, U \u222a V )] .\n\n(28)\n\nBy using \u03b9Ps , the operator unif Ps can be equivalently rewritten as:\nunif Ps ([\u0398, U ], \u03b8) = unif Ps (\u03b9Ps ([\u0398, U ], vars(\u03b8)), \u03b8) ,\n\n5\n\n(29)\n\nNote that, due to the condition T 6= \u2205, the notation A+ would be more appropriate. However,\nwe retain the notation A\u2217 for historical reasons.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n29\n\nand now, in the right hand side, \u03b9Ps ([\u0398, U ], vars(\u03b8)) is an object of the kind [\u2206, U \u222a\nvars(\u03b8)]. Therefore, a correct abstract forward unification operator for UfPs may be\nobtained as\nf\n\nU\u2032 Sh ([\u0398, U ], A1 , A2 ) = \u03c0Sh (unif \u2032Sh (\u03b9Sh (\u03c1([\u0398, U ]), vars(\u03c1(A1 )) \u222a vars(A2 )),\nmgu(\u03c1(A1 ) = A2 )), vars(A2 )) ,\n\n(30)\n\nprovided that \u03c1 is a renaming such that \u03c1(U \u222a vars(A1 )) \u2229 vars(A2 ) = \u2205. However,\nf\nU\u2032 Sh is not optimal w.r.t. UfPs .\nExample 6.2\nWe keep on Example 4.4 and compute the abstract counterpart of the concrete\nforward unification\nUfPs ([{[y/f (x, z)]}, {x, y, z}], p(x, y, z), p(u, v, w)) =\n[{[u/x, v/f (x, z), w/z]}, {u, v, w}] .\nSince the abstraction of [{[y/f (x, z)]}, {x, y, z}] is [{xy, yz}, {x, y, z}], we compute:\nf\n\nU\u2032 Sh ([{xy, yz}, {x, y, z}], p(x, y, z), p(u, v, w)) =\n\u03c0Sh ([uSh ({xy, yz, u, v, w}, {x/u, y/v, z/w}), {x, y, z, u, v, w}], {u, v, w}) =\n\u03c0Sh ([{xyuv, yzvw, xyzuvw}, {x, y, z, u, v, w}], {u, v, w}) =\n[{uv, vw, uvw}, {u, v, w}] .\nThere exists a sharing group uvw computed by the forward unification. However,\nwhen computing unif Ps (\u03b3Sh ([{xy, yz}, {x, y, z}]), {x/u, y/v, z/w}) we know that u, v\nand w are free in \u03b3Sh ([{xy, yz}, {x, y, z}]. Following (Hans and Winkler 1992),\nwe can avoid computing the star unions when considering the binding y/v in\nuSh , obtaining the smaller result [{xyuv, yzvw}, {x, y, z, u, v, w}]. If we now compute the projection on the variables {u, v, w} we obtain the entry substitution\n[{uv, vw}, {u, v, w}], with an obvious gain of precision.\nExample 6.3\nLet us consider the following unification.\nf\n\nU\u2032 Sh ([{xy, xz}, {x, y, z}], p(x, y, z), p(t(u, v), h, k)) =\n\u03c0Sh ([bin({xyh, xzk, xyzhk}, {u, v, uv}), {x, y, z, h, k, u}], {u, v, h, k}) .\nSince the term t(u, v) is linear and independent from x, following (Hans and Winkler\n1992) we can avoid to compute the star union over {xy, xz}, obtaining the abstract\nobject [bin({xyh, xzk}, {u, v, uv}), {x, y, z, h, k, u}]. If we project on {h, k, u, v} we\nobtain bin({h, k}, {u, v, uv}) against bin({h, k, hk}, {u, v, uv}). In this way, we are\nable to prove the independence of h from k.\nThese examples show that, when computing forward abstract unification by first\nenlarging the domain of variables of interest, there is a loss of precision. In fact,\nsuch a forward abstract unification operator is not optimal. We now show that it\nis possible to design an optimal operator for forward unification which is able to\n\n\f30\n\nG. Amato and F. Scozzari\n\nexploit linearity and freeness information that stems from the fact that variables\nin the third argument of UfPs are fresh. Note that we are not proposing to embed freeness and linearity information inside the domain, but only to use all the\ninformation coming from the syntax of the clauses.\n6.1 The Refined Forward Unification\nWe are going to define an abstract operator unif Sh which is correct and optimal\nw.r.t. unif Ps .\nDefinition 6.4\nThe abstract unification unif Sh : Sharing \u00d7 ISubst \u2192 Sharing is defined as\nunif Sh ([S1 , U1 ], \u03b8) = [ufSh (S1 \u222a {{x} | x \u2208 U2 }, U2 , \u03b8), U1 \u222a U2 ]\nwhere U2 = vars(\u03b8) \\ U1 and ufSh : \u2118(\u2118f (V)) \u00d7 \u2118f (V) \u00d7 ISubst \u2192 \u2118(\u2118f (V)) is defined\nas:\nufSh (S, U, \u01eb) = S\nufSh (S, U, {x/t} \u228e \u03b4) = ufSh ((S \\ (rel(S, t) \u222a rel(S, x)))\u222a\nbin(rel(S, x), rel(S, t)), U \\ {x}, \u03b4)\nufSh (S, U, {x/t}\n\n\u228e \u03b4) =\n\nufSh ((S\n\nif x \u2208 U\n\n\\ (rel(S, t) \u222a rel(S, x)))\u222a\n\nbin(rel(S, x), rel(S, Y )\u2217 )\u222a\nbin(rel(S, x)\u2217 , rel(S, Z)\u2217 )\u222a\nbin(bin(rel(S, x)\u2217 , rel(S, Z)\u2217 ), rel(S, Y )\u2217 ),\nU \\ vars({x/t}), \u03b4)\n\nif x \u2208\n/U\n\nwhere Y = uvars(t) \u2229 U , Z = vars(t) \\ Y .\nThe idea is simply to carry on, in the second argument of ufSh , the set of variables\nwhich are definitively free and to apply the optimizations for the abstract unification\nwith linear terms and free variables (Hans and Winkler 1992). Actually, while the\ncase for x \u2208 U is standard, the case for x \u2208\n/ U exploits some optimizations which\nare not found in the literature. When Z = \u2205, we obtain:\n(S \\ (rel(S, t) \u222a rel(S, x))) \u222a bin(rel(S, x), rel(S, Y )\u2217 ) ,\nwhich is the standard result when the term t is linear and independent from x.\nHowever, when Z 6= \u2205, the standard optimizations which appear, e.g., in (Hans and\nWinkler 1992), do not apply, since t cannot be proved to be linear and independent\nfrom x, and we should obtain the following standard result:\n(S \\ (rel(S, t) \u222a rel(S, x))) \u222a bin(rel(S, x)\u2217 , rel(S, t)\u2217 ) .\nWe are able to avoid some star unions by distinguishing the variables in t which are\n\"linear and independent\" (the set Y ) from the others (the set Z), and observing\nthat two sharing groups in rel(S, x) may be merged together only under the effect\nof the unification with some variable in Z. We will come back later to this topic.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n31\n\nWe can now define the forward abstract unification UfSh : Sharing \u00d7 \u2118f (V) \u00d7\nAtoms \u00d7 Atoms \u2192 Sharing. We only need to introduce the necessary renamings and\nprojections, as done for the concrete case:\nUfSh ([S1 , U1 ], A1 , A2 ) = \u03c0Sh (unif Sh (\u03c1([S1 , U1 ]), mgu(\u03c1(A1 ) = A2 )), vars(A2 )) (31)\nwith \u03c1 a renaming such that \u03c1(U1 \u222a vars(A1 )) \u2229 vars(A2 ) = \u2205.\nExample 6.5\nWe keep on Examples 4.4 and 6.2 and compute the abstract counterpart of the\nconcrete forward unification\nUfPs ([{[y/f (x, z)]}, {x, y, z}], p(x, y, z), p(u, v, w)) =\n[{[u/x, v/f (x, z), w/z]}, {u, v, w}]\nusing our optimized forward unification operator.\nUfSh ([{xy, yz}, {x, y, z}], p(x, y, z), p(u, v, w)) =\n\u03c0Sh (unif Sh ({xy, yz}, {x/u, y/v, z/w}), {u, v, w}) =\n\u03c0Sh ([{uvxy, vwyz}, {u, v, w, x, y, z}], {u, v, w}) =\n[{uv, vw}, {u, v, w}] .\nThus the optimized operator is able to prove that u and w are independent after\nthe unification.\n6.2 Correctness of Forward Unification\nWe prove that the unification operator unif Sh is correct w.r.t. the concrete operator\nunif Ps . We begin to analyze the abstract behavior of unification when the second\nargument is a substitution with only one binding. Let \u03c3 and {x/t} be the two\nsubstitutions we want to unify. In this simple case, the resultant sharing groups\ncan be easily computed by exploiting the substitution \u03b4 = mgu(x\u03c3 = t\u03c3). We show\nthat, under suitable conditions, any sharing group either belongs to \u03b1Sh ([\u03c3]U ]) or\nis of the form occ(\u03c3, occ(\u03b4, v)) \u2229 U , where v \u2208 vars(x\u03c3 = t\u03c3).\nProposition 6.6\nLet [\u03c3]U \u2208 ISubst \u223c and {x/t} \u2208 ISubst such that vars({x/t}) \u2286 U and \u03c3 and {x/t}\nunify. If \u03b1Sh ([\u03c3]U ]) \u2291Sh [S, U ] and \u03b4 = mgu(x\u03c3 = t\u03c3), we obtain:\n\u03b1Sh (mgu([\u03c3]U , [x/t]U )) \u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t)))\n\u222a {occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}, U ] .\nProof\nThe proof can be found in the Appendix as Prop. B.3\nThis result may be refined by introducing further hypotheses. We have anticipated that our abstract algorithm takes advantage of the fact that some variables\nare known to be free in order to to produce better results than standard abstract\nunification. We may be more formal.\n\n\f32\n\nG. Amato and F. Scozzari\n\nDefinition 6.7\nWe say that a variable x \u2208 V is free in [\u03b8]V when \u03b8|V (x) \u2208 V.\nNote that this definition does not depend on the choice of the representative for [\u03b8]V .\nMoreover, if x is free and independent from V in [\u03b8]V , there exists a representative\n\u2032\u2032\n\u03b8\u2032 \u223cV \u03b8 such that x \u2208\n/ vars(\u03b8\u2032 ). It is enough to take \u03b8\u2032 = \u03b8|{\u2212x}\nwhere \u03b8\u2032\u2032 is a\ncanonical representative.\nNow, we consider again Prop. 6.6, but we assume x to be free and independent\nfrom U in [\u03c3]U . A result similar to the following proposition has been already proved\nin the literature, e.g., (Hans and Winkler 1992). Since our treatment of substitutions\nis slightly different from the standard one, for the sake of completeness we present\nthe altered proof.\nProposition 6.8\nLet [\u03c3]U \u2208 ISubst \u223c and {x/t} \u2208 ISubst such that vars({x/t}) \u2286 U and \u03c3 and {x/t}\nunify. If \u03b1Sh ([\u03c3]U ) \u2291Sh [S, U ] and x is free and independent from U in [\u03c3]U , then:\n\u03b1Sh (mgu([\u03c3]U , [x/t]U ))\n\u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t))) \u222a bin(rel(S, x), rel(S, t)), U ] .\nProof\nThe proof can be found in the Appendix as Prop. B.4\nNow we analyze the case when x is not guaranteed to be free and independent\nfrom U in [\u03c3]U . We show that it is possible to consider three distinct cases depending\non the set of variables Y = {y \u2208 vars(t)|vars(\u03c3(y)) \u2286 uvars(x\u03c3 = t\u03c3)}, that is the\nset of variables y such that all the variables in vars(\u03c3(y)) appear once in x\u03c3 = t\u03c3.\nSuch variables play a special role in the unification process. Generally speaking, we\ncan form new sharing groups by merging sets from rel(S, x) and rel(S, t). Obviously,\nany new sharing group must be formed by choosing at least one element from\nrel(S, x) and at least one from rel(S, t). We show that, if we do not include any\nvariable from vars(t) \\ Y , then we may avoid to include more than one sharing\ngroup from rel(S, x). Intuitively speaking, variables from Y do not allow to merge\ndifferent sharing groups from rel(S, x) since such variables appear only once and\nthus cannot be bound to different occurrences of x.\nExample 6.9\nLet \u03c3 = {x/f (u, v)}, U = {u, v, x, y, z} and consider the binding x/f (f (y, z), z). We\nhave that Y = {y}, \u03b1Sh ([\u03c3]U ) = [S, U ] = [{ux,vx,y,z}, U ], rel(S, x) = {ux,vx}\nand rel(S, t) = {y,z}. In the standard definition of abstract unification, uvxy would\nbe one of the possible resultant sharing groups. However, since uvxy is obtained\nby joining two sharing groups in rel(S, x) and it does not contain any variable in\nvars(t) \\ Y , it cannot be generated. In fact, the result of the unification is \u03b7 =\n{x/f (f (y, z), z), u/f (y, z), v/z} and \u03b1Sh ([\u03b7]U ) = [{uxy,uvxz}, U ]. The variables u\nand v occur in the same sharing group thanks to the two occurrences of z.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n33\n\nProposition 6.10\nLet [\u03c3]U \u2208 ISubst \u223c and {x/t} \u2208 ISubst such that vars({x/t}) \u2286 U and \u03c3 and {x/t}\nunify. Given Y \u2286 vars(t) such that, for all y \u2208 Y , vars(\u03c3(y)) \u2286 uvars(x\u03c3 = t\u03c3), if\n\u03b1Sh ([\u03c3]U ) \u2291Sh [S, U ] then\n\u03b1Sh (mgu([\u03c3]U , [x/t]U )) \u2291Sh [(S \\ (rel(S, t) \u222a rel(S, x)))\n\u222a bin(rel(S, x), rel(S, Y )\u2217 ) \u222a bin(rel(S, x)\u2217 , rel(S, Z)\u2217 )\n\u222a bin(bin(rel(S, x)\u2217 , rel(S, Z)\u2217 ), rel(S, Y )\u2217 ), U ] ,\nwhere Z = vars(t) \\ Y .\nProof\nThe proof can be found in the Appendix as Prop. B.6\nNow, by combining the results from Propositions 6.8 and 6.10 we can show the\ncorrectness of unif Sh .\nTheorem 6.11\n(Correctness of unif Sh ) The unification operator unif Sh is correct w.r.t. unif Ps .\nProof\nThe proof can be found in the Appendix as Theorem B.8\n6.3 Optimality of Forward Unification\nIn this section we prove that the abstract unification operator unif Sh is optimal\nw.r.t. the concrete operator unif Ps , that is to say that, given [S1 , U1 ] \u2208 Sharing\nand \u03b8 \u2208 ISubst, it holds:\n\u03b1Sh (unif Ps (\u03b3Sh ([S1 , U1 ]), \u03b8)) \u2292Sh unif Sh ([S1 , U1 ], \u03b8).\nLet unif Sh ([S1 , U1 ], \u03b8) = [S, U ] where U = U1 \u222a vars(\u03b8). In the rest of this section,\nwe assume fixed S, S1 , U, U1 , \u03b8 as defined above.\nFor each X \u2208 S, we need to exhibit a substitution \u03b4 such that \u03b1Sh ([\u03b4]U1 ) \u2291Sh\n[S1 , U1 ] and \u03b1Sh (mgu([\u03b4]U1 , [\u03b8]U )) \u2292Sh [{X}, U ]. Any resultant sharing group is\nobtained by merging together sharing groups from S1 and variables in vars(\u03b8) \\\nU1 . We show that two sharing groups B1 and B2 may be joined by the abstract\nunification algorithm only if there are two variables x1 \u2208 B1 , x2 \u2208 B2 such that\n\u03b8(x1 ) and \u03b8(x2 ) share some variable. Actually, we need to be careful when x1 = x2 ,\nsince we need a variable which occurs at least twice in \u03b8(x1 ). More formally, given\nX \u2208 \u2118f (V) and \u03b8 \u2208 ISubst, we define a relation R\u03b8X \u2286 S1 \u00d7 S1 as follows:\nB1 R\u03b8X B2 \u21d0\u21d2 \u2203x1 \u2208 B1 \u2203x2 \u2208 B2 \u2203y. (y \u2208 vars(\u03b8(x1 )) \u2229 vars(\u03b8(x2 )) \u2229 X) \u2227\n(x1 = x2 =\u21d2 y \u2208\n/ uvars(\u03b8(x1 ))) . (32)\nWe say that X is \u03b8-connected when there exist B1 , . . . , Bn \u2208 S1 s.t. \u222a1\u2264j\u2264n Bj =\nX \u2229 U1 and B1 R\u2217\u03b8X B2 . . . R\u2217\u03b8X Bn , where R\u2217\u03b8X is the transitive closure of R\u03b8X .\n\n\f34\n\nG. Amato and F. Scozzari\n\nLemma 6.12\nFor each X \u2208 S, X is \u03b8-connected.\nProof\nThe proof can be found in the Appendix as Lemma C.4\nNow we will exploit the relation R\u03b8X in order to find a substitution \u03b4 such that the\nconcrete unification of \u03b8 with \u03b4 mimics the behavior of the abstract unification of\n\u03b8 with [S1 , U1 ]. We define a \u03b4 which has exactly the sharing groups B1 , . . . , Bn and\nwhich is obtained by instantiating \u03b8. The idea is that if B1 R\u03b8X B2 due to x1 \u2208 B1 ,\nx2 \u2208 B2 and the common variable y \u2208 \u03b8(x1 ) \u2229 \u03b8(x2 ), then the occurrences of y in\n\u03b8(x1 ) and \u03b8(x2 ) are replaced by two suitable terms which unify and merge together\nthe two sharing groups B1 and B2 .\nExample 6.13\nLet \u03b8 = {x/f (u), y/g(u)} and [S1 , U1 ] = [{xw,yz}, {w, x, y, z}]. Consider B1 =\nxw and B2 = yz. We choose the variables x \u2208 B1 and y \u2208 B2 . Since u \u2208\n\u03b8(x) \u2229 \u03b8(y), we can choose the substitution \u03b4 = {x/f (w1 ), y/g(w2 ), w/w1 , z/w2 }\nobtained from \u03b8 by replacing each occurrence of u, w, z with suitable new terms. It\nis easy to verify that \u03b8 and \u03b4 unify and that \u03b1Sh (mgu([\u03b4]{w,x,y,z} , [\u03b8]{u,w,x,y,z} )) \u2292Sh\n[{uwxyz}, {u, w, x, y, z}].\nExample 6.14\nLet \u03b8 = {x/f (u, u)} and [S1 , U1 ] = [{xw,xy,xz}, {w, x, y, z}]. Consider B1 = xw,\nB2 = xy and B3 = xz. We choose the variable x \u2208 B1 \u2229 B2 \u2229 B3 . Then u \u2208\n/\nuvars(\u03b8(x)), and we can choose as \u03b4 the substitution\n{x/f (t(w1 , w1 ), t(w2 , w3 )), w/w1 , y/w2 , z/w3 } ,\nobtained from \u03b8 by replacing each occurrence of u, w, y, z with suitable new terms.\nIt is easy to see that \u03b8 and \u03b4 unify and that \u03b1Sh (mgu([\u03b4]{w,x,y,z} , [\u03b8]{u,w,x,y,z} )) \u2292Sh\n[{uwxyz}, {u, w, x, y, z}].\nFollowing this idea we can now prove that mgu and unif Sh are optimal.\nProposition 6.15\nFor all X \u2208 S there exists [\u03b4]U1 \u2208 ISubst \u223c such that \u03b1Sh ([\u03b4]U1 \u2264Sh [S1 , U1 ] and\n\u03b1Sh (mgu([\u03b4]U1 , [\u03b8]U )) \u2292Sh [{X}, U ] .\nProof\nThe proof can be found in the Appendix as Prop. C.6\nThe optimality result for unif Sh w.r.t. unif Ps immediately follows from the above\nproposition.\nTheorem 6.16\n(Optimality of unif Sh ) unif Sh is optimal w.r.t. unif Ps .\nOptimality of unif Sh also implies the following corollary:\n\n\fOptimality in goal-dependent analysis of Sharing\n\n35\n\nCorollary 6.17\nThe result of unif Sh does not depend on the order of the bindings in its second\nargument.\n6.4 Summing Up\nWe may put together all the results of correctness, optimality and completeness\nshown so far to prove the main theorem of this section.\nTheorem 6.18\nUfSh is well defined, correct and optimal w.r.t. UfPs .\nProof\nThe proof can be found in the Appendix as Theorem C.7\nGenerally speaking, in order to obtain optimality, it is always a better choice to\nabstract a concrete operator \"as a whole\", instead of abstracting each component\nand then composing the abstract operators. According to this rule, we could think\nthat a better approximation may be reached by abstracting UfPs as a whole. However, since abstract projection/renaming is complete and \u03b3-complete, this does not\nhappen, as shown by the previous theorem. Studying the direct abstraction of this\ncomposition would still be useful to find a direct implementation which is more\nefficient than computing unif Sh and projecting later, but we do not consider this\nproblem here.\nf\nSince UfSh generates less sharing groups then U\u2032 Sh and since checking whether\na variable is in U is easy, we can expect an improvement in the efficiency of the\nf\nanalysis by replacing U\u2032 Sh with UfSh in the computation of the entry substitution.\nIf computing Y and Z at each step of ufSh seems difficult, it is always possible to\nprecompute these values before the actual analysis begins, since they depend on\nthe syntax of the program only. Moreover, in the definition of ufSh , when x \u2208 U we\nknow that rel(S, x) = {{x}}, since \u03b8 is an idempotent substitution and x \u2208\n/ U1 .\nA further optimization is obtained by replacing rel(S, Y ) with the set of all the\nsharing groups whose variables are all contained in Y . Clearly, this is a subset of\nrel(S, Y ) and it is immediate to check that the result of ufSh does not change. In\nfact, all the sharing groups in bin(rel(S, x), rel(S, Y )\u2217 ) which are not generated\nanymore, may be found in bin(rel(S, x)\u2217 , rel(S, Z)\u2217 ).\nWe said before that this operator introduces new optimizations which, to the best\nof our knowledge, are not used even in more complex domains for sharing analysis\nwhich include linearity and freeness information. We give here one example which\nshows their effects.\nExample 6.19\nLet us consider the following unification.\nUfSh ([{xw, xz, yw, yz}, {x, y, w, z}], p(x, y, w, z), p(f (u, h), f (u, k), s, t)) .\nBy applying the optimizations suggested from the unification algorithm in presence\n\n\f36\n\nG. Amato and F. Scozzari\n\nof linearity and freeness information in (Hans and Winkler 1992), we may start\nfrom the abstract object S = {xw, xz, yw, yz, u, h, k, s, t} and process the bindings\none at a time, keeping in mind that u, h, k, s, t are initially free. This means that\nin the binding x/f (u, h), the term f (u, h) is linear, and therefore we can avoid to\ncompute the star union in rel(S, x), thus obtaining:\n{k, s, t, yw, yz} \u222a bin({xw, xz}, {u, h, uh}) =\n{k, s, t, yw, yz, xwu, xwh, xzu, xzh, xwuh, xzuh} .\nHowever, after this unification, the variable u can be bound to a non-linear term.\nTherefore, when we consider the next binding y/f (u, k), according to (Hans and\nWinkler 1992), we are forced to compute all the star unions, obtaining\n{s, t} \u222a bin({yw, yz}\u2217 , ({k} \u222a bin({xw, xz}, {u, uh}))\u2217 ) \u222a {xwh, xzh} .\nFinally, in the bindings w/s and z/t we may omit all the star unions since t and s\nare free, and we get the final result\nbin({yws, yzt}\u2217 , ({k} \u222a bin({xws, xzt}, {u, uh}))\u2217 ) \u222a {xwsh, xzth} .\nObserve that we obtain the sharing group ywsztk, and thus, after projecting on\n{u, h, k, s, t}, we obtain the sharing group stk. However, when we consider the\nsecond binding, we know that k is free and independent from y, and this is enough\nto apply a new optimization. In fact, k can share with more than one sharing group\nrelated to y only if k shares with u. If we compute the abstract unification with our\nalgorithm, we obtain\n{ywsk, yztk} \u222a bin({yws, yzt}\u2217 , bin({xws, xzt}, {u, uh})\u2217 )\n\u222a bin(bin({yws, yzt}\u2217 , bin({xws, xzt}, {u, uh})\u2217 ), {k}) \u222a {xwsh, xzth}\nand when we project on {u, h, k, s, t}, the sharing group stk does not appear. In\nfact, note that any sharing group generated by\nbin(bin({yws, yzt}\u2217 , bin({xws, xzt}, {u, uh})\u2217 ), {k})\ncontains the variable u. The result does not change by permuting the order of the\nbindings. If we consider the binding y/f (u, k) before x/f (u, h), with the standard\noperators we get:\nbin({xws, xzt}\u2217 , ({h} \u222a bin({yws, yzt}, {u, uk}))\u2217 ) \u222a {ywsk, yztk}\nand, when we project on {u, h, k, s, t}, we obtain the sharing group sth, which does\nnot appear in our result.\n\n7 Matching and Backward Unification\nTo the best of our knowledge, in all the collecting denotational semantics for logic\nprograms, backward unification is performed by using unification instead of matching. This means that, instead of UbPs , the concrete semantics uses a backward\n\n\fOptimality in goal-dependent analysis of Sharing\n\n37\n\nunification operator which unifies two concrete objects in Psub with a substitution:\nb\n\nU\u2032 Ps ([\u22061 , U1 ], [\u22062 , U2 ], A1 , A2 ) =\n\u03c0Ps (unif \u2032\u2032Ps (\u03c1([\u22061 , U1 ]), [\u22062 , U2 ], mgu(\u03c1(A1 ) = A2 )), U2 \u222a vars(A2 )) , (33)\nwhere \u03c1 is a renaming such that \u03c1(U1 \u222a vars(A1 )) \u2229 (U2 \u222a vars(A2 )) = \u2205 and\nunif \u2032\u2032Ps ([\u22061 , U1 ], [\u22062 , U2 ], \u03b4) =\n[{mgu([\u03b81 ]U1 , [\u03b82 ]U2 , [\u03b4]vars(\u03b4) ) | [\u03b81 ]U1 \u2208 \u22061 , [\u03b82 ]U2 \u2208 \u22062 }, U1 \u222a U2 ] (34)\nis simply the pointwise extension of mgu over Psub. It is worth observing that\nunif \u2032\u2032Ps (\u03c1([\u22061 , U1 ]), [\u22062 , U2 ], \u03b4) is a very specific kind of unification, since \u03c1(U1 ) and\nb\nb\nU2 are disjoint. The optimal abstract operator U\u2032 Sh w.r.t. U\u2032 Ps is very similar to\nthat proposed in (Cortesi and Fil\u00e9 1999) (see Section 8.2 for further details), and\nit is given by:\nb\n\nU\u2032 Sh ([S1 , U1 ], [S2 , U2 ], A1 , A2 ) =\n\u03c0Sh (unif Sh ([\u03c1(S1 ) \u222a S2 , \u03c1(U1 ) \u222a U2 ], mgu(\u03c1(A1 ) = A2 )), U2 \u222a vars(A2 )) . (35)\nAs said before, this choice results in a loss of precision already at the concrete level,\nwhich leads to a loss of precision in the abstract counterpart. When we compute\nU\u2032 bPs ([\u22061 , U1 ], [\u22062 , U2 ], A1 , A2 ), we essentially unify all pairs \u03b81 and \u03b82 , elements\nof \u22061 and \u22062 , with \u03b4 = mgu(A1 = A2 ) (assuming we do not need renamings).\nHowever, it could be possible to consider only the pairs in which \u03b81 is an instance\nof mgu(\u03b82 , \u03b4) w.r.t. the variables of interest in U1 \u2229 U2 . If this does not hold, then \u03b81\ncannot be a success substitution corresponding to the call substitution \u03b82 , and therefore we are unifying two objects which pertain to different computational paths,\nwith an obvious loss of precision, already at the concrete level. This problem has\nbeen pointed out by Marriott et al. (1994, Section 5.5).\nWe now want to define the optimal abstract operator UbSh corresponding to UbPs .\nThis is accomplished by composing the forward unification operator unif Sh with a\nnew operator matchSh , which is the abstract counterpart of matchPs .\nDefinition 7.1\nGiven [S1 , U1 ], [S2 , U2 ] \u2208 Sharing, we define\nmatchSh ([S1 , U1 ], [S2 , U2 ]) =\n[S1\u2032 \u222a S2\u2032 \u222a {X1 \u222a X2 | X1 \u2208 S1\u2032\u2032 , X2 \u2208 (S2\u2032\u2032 )\u2217 , X1 \u2229 U2 = X2 \u2229 U1 } , U1 \u222a U2 ]\nwhere S1\u2032 = {B \u2208 S1 | B \u2229 U2 = \u2205} and S1\u2032\u2032 = S1 \\ S1\u2032 , S2\u2032 = {B \u2208 S2 | B \u2229 U1 = \u2205}\nand S2\u2032\u2032 = S2 \\ S2\u2032\nThe idea is that we may freely combine those sharing groups in S2 that have some\nvariable in common with U1 , i.e., X2 \u2208 (S2\u2032\u2032 )\u2217 , if the projection of the result on U1\nis equal to some sharing group in S1 , when projected on U2 . This means that new\naliasings between variables may arise in the concrete counterpart of S2 (the entry\nsubstitution), as long as they do not affect the variables of the exit substitution.\n\n\f38\n\nG. Amato and F. Scozzari\n\nDefinition 7.2\nThe abstract backward unification may be defined as\nUbSh ([S1 , U1 ], [S2 , U2 ], A1 , A2 ) = \u03c0Sh (matchSh (\u03c1([S1 , U1 ]),\nunif Sh ([S2 , U2 ], mgu(\u03c1(A1 ) = A2 ))), U2 \u222a vars(A2 )) . (36)\nwhere \u03c1 is a renaming such that \u03c1(U1 \u222a vars(A1 )) \u2229 (U2 \u222a vars(A2 )) = \u2205.\nExample 7.3\nLet U1 = {u, v, w}, U2 = {x, y, z}, \u03981 = {[{v/t(u, w, w)}]U1 , [{v/t(u, u, w)}]U1 }.\n\u03982 = {[{y/t(x, z, z)}]U2 , [{y/t(x, x, z)}]U2 } and \u03c1 = id . We have\nb\n\nU\u2032 Ps ([\u03981 , U1 ], [\u03982 , U2 ], p(u, v, w), p(x, y, z)) = \u03c0Ps ([\u0398, U1 \u222a U2 ], U2 ) ,\nwith [\u03b8]U1 \u222aU2 = [{y/t(x, x, x), z/x, u/x, v/t(x, x, x), w/x}]U1 \u222aU2 \u2208 \u0398. Let [S1 , U1 ] =\n\u03b1Sh ([\u03981 , U1 ]), [S2 , U2 ] = \u03b1Sh ([\u03982 , U2 ]), S1 = {uv, vw} and S2 = {xy, yz}. We obtain\nb\n\nU\u2032 Sh ([S1 , U1 ], [S2 , U2 ], p(u, v, w), p(x, y, z)) = \u03c0Sh ([S, U1 \u222a U2 ], U2 ) ,\nand xyzuvw \u2208 S. So, it seems that u, v and w may share a common variable. Note\nthat \u03b8 is obtained by unifying \u03c32 = {y/t(x, z, z)} with \u03c31 = {v/t(u, u, w)} but\n\u03c31 (v) = t(u, u, w) is not an instance of mgu(\u03c32 , mgu(p(x, y, z) = p(u, v, w)))(v) =\nt(x, z, z). Therefore, \u03c31 and \u03c32 do pertain to different computational paths. Using\nthe backward unification with matching, we obtain\nUbPs ([\u03981 , U1 ], [\u03982 , U2 ], p(u, v, w), p(x, y, z)) =\n\u03c0Ps ([{[y/t(x, z, z), u/x, v/t(x, z, z), w/z], [y/t(x, x, z), u/x, v/t(x, x, z), w/z]},\n{x, y, z, u, v, w}], {u, v, w}) ,\nwhich does not contain \u03b8. In the abstract domain, we have:\nUbSh ([S1 , U1 ], [S2 , U2 ], p(u, v, w), p(x, y, z)) =\n\u03c0Sh ([{xyuv, yzvw}, U1 \u222a U2 ], U2 ) .\nAfter the unification we know that x and z are independent. Note that the abstract\nmatching operators defined in (King and Longley 1995; Hans and Winkler 1992),\ncannot establishthis property. The algorithm in (Muthukumar and Hermenegildo\n1992) computes the same result of ours in this particular example, but since their\nmatching is partially performed by first projecting the sharing information on the\nterm positions of the calling atom and of the clause head, this does not hold in\ngeneral. For example, their algorithm states that x and z may possibly share when\nthe unification is performed between the calling atom p(t(x, y, z)) and the head\np(t(u, v, w)), where t is a function symbol, p a unary predicate and the call substitution is the same as before.\n7.1 Correctness and Optimality\nWe can prove that UbSh is actually the best correct abstraction of the backward\nconcrete unification UbPs . To prove correctness we only need to show that matchSh\n\n\fOptimality in goal-dependent analysis of Sharing\n\n39\n\nis correct w.r.t. matchPs . Correctness of UbSh will follow from the fact that UbSh is\na composition of correct abstract operators.\nTheorem 7.4\n(Correctness of matchSh ) matchSh is correct w.r.t. matchPs .\nProof\nThe proof can be found in the Appendix as Theorem D.1.\nHowever, the composition of optimal operators may fail to be optimal. Therefore,\noptimality of matchSh does not guarantee optimality of UbSh . In order to prove the\noptimality result, we need to establish two additional properties on the abstract\noperators matchSh and unif Sh . The idea is that both these operators are used in a\nvery specific way in the backward unification.\nProposition 7.5\n1. matchSh is optimal w.r.t. matchPs ;\n2. when matchPs is restricted to the case when the second argument contains a\nsingle substitution, then matchSh is complete w.r.t. the second argument, i.e.\nmatchSh ([S1 , U1 ], \u03b1Sh ([{[\u03c32 ]}, U2 ])) =\n\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ]))\n3. unif Sh is optimal in a very strong way: given [S1 , U1 ] \u2208 Sharing and \u03b8 \u2208\nISubst, there exists a substitution \u03b4 \u2208 ISubst such that \u03b1Sh ([\u03b4]U1 ) \u2291Sh [S1 , U1 ]\nand\n\u03b1Sh (unif Ps ([{[\u03b4]}, U1 ], \u03b8)) = unif Sh ([S1 , U1 ], \u03b8) .\nProof\nProofs of these properties can be found in the Appendix as Theorems D.2, D.3 and\nD.4.\nOn the last point, note that the standard definition of optimality for unif Sh only\nassures the existence of a set of substitutions \u2206 such that \u03b1Sh ([\u2206, U1 ]) \u2291Sh [S1 , U1 ]\nand \u03b1Sh (unif Ps ([\u2206, U1 ], \u03b8)) = unif Sh ([S1 , U1 ], \u03b8). However, we show that any set \u2206\ncan be reduced to a singleton. This allows us to find a single substitution to be\nused for proving the optimality result for all the resultant sharing groups. Finally,\nusing Theorem 7.4 and Prop. 7.5 we may prove the expected result.\nTheorem 7.6\nUbSh is correct and optimal w.r.t. UbPs .\nProof\nThe proof can be found in the Appendix as Theorem D.5.\nTo the best of our knowledge, this is the first abstract matching operator which\nis optimal for the corresponding concrete operator. We now give an example of\na program where the use of UfSh and UbSh gives better results than the standard\nf\nb\noperators U\u2032 Sh and U\u2032 Sh .\n\n\f40\n\nG. Amato and F. Scozzari\n\nExample 7.7\nWe keep on Examples 4.4, 6.2 and 6.5 and consider the trivial program with just one\nclause p(u, v, w) and the goal p(x, y, z) with {xy, yz}. Using our abstract operators,\nwe obtain the entry substitution {uv, vw} and the success substitution {xy, yz} (see\nEx. 6.5 and 7.3), thus proving that x and z are independent.\nWe now compute the abstract semantics of the goal p(x, y, z) with {xy, yz}. From\nExample 4.4, we have that the abstract semantics of P is\n\u03bbA.\u03bb\u03c7.UbSh (UfSh (\u03c7, A, p(u, v, w)), \u03c7, p(u, v, w), A) .\nThus, in order to compute the semantics of the goal p(x, y, z) with {xy, yz}, we\nneed to compute\nUbSh (UfSh ([{xy, yz}, {x, y, x}], p(x, y, z), p(u, v, w)),\n[{xy, yz}, {x, y, x}], p(u, v, w), p(x, y, z)) .\nFrom Example 6.5, we know that\nUfSh ([{xy, yz}, {x, y, x}], p(x, y, z), p(u, v, w)) = [{uv, vw}, {u, v, w}] ,\nfrom which we obtain (see Example 7.3):\nUbSh ([{uv, vw}, {u, v, w}], [{xy, yz}, {x, y, x}], p(u, v, w), p(x, y, z)) =\n[{xy, yz}, {x, y, z}] ,\nwhich shows that x and y are independent.\nf\nb\nIf we replace either UbSh or UfSh with U\u2032 Sh or U\u2032 Sh , then the success substitution\nwill contain the sharing group xyz. In fact, as shown in Ex. 6.2, the entry substitution in the latter case would be [{uv, vw, uvw}, {u, v, w}]. If we compute the success\nsubstitution we obtain:\nb\n\nU\u2032 Sh ([{uv, vw, uvw}, {u, v, w}], [{xy, yz}, {x, y, z}], p(u, v, w), p(x, y, z)), {x, y, z})\n= [{xy, yz, xyz}, {x, y, z}] ,\nwhich contains the sharing group xyz.\n\n7.2 Programs in Head Normal Form\nIt is worth noting that the improvement in the previous example is obtained with\na program in head normal form. Usually, when programs are in head normal form,\nthe forward and backward unification may be replaced by renamings, which are\ncomplete and do not cause any loss in precision. However, there is the need of an\nunification operator for the explicit constraints which appear in the body of the\nclauses. In general, the analyses we obtain in our framework are more precise than\nthose which can be obtained by using the standard domain Sharing by translating\nthe same program to the head normal form.\nExample 7.8\n\n\fOptimality in goal-dependent analysis of Sharing\n\n41\n\nConsider again Ex. 7.7 and the program p(u, f(s), w) \u2190 which is not in head normal\nform. Using our abstract operators, we obtain the success substitution {xy, yz}, as\nin Ex. 7.7. If we normalize the program, we obtain the clause p(u, v, w) \u2190 v = f(s).\nThe entry substitution obtained from {xy, yz} by simply renaming the variables\nx, y, z to u, v, w and introducing the new variable s is {uv, vw, s}. By using the\nstandard operator for unification, when applying the binding v/f (s) we obtain\n{uvs, vws, uvws}, and thus the success substitution will contain the sharing group\nxyz, resulting in a loss of precision.\nIt is possible to use our forward abstract unification in a normalized program\nby enlarging the set of variables of interest only when new variables are effectively\nmet, instead of adding all the variables which appear in the body of a clause once\nfor all when the entry substitution is computed. In the example above, the variable\ns can be introduced when unifying the abstract object {uv, vw} with v/f (s). Since\nunif Sh ([{uv, vw}, {u, v, w}], {v/f (s)}) = [{uvs, vws}, {u, v, w, s}], we still obtain as\nsuccess substitution {xy, yz}, thus proving that x and z are independent.\nIn the general case, translating a program in head normal form will negatively\naffect the precision of the analysis. To achieve the same precision in both cases,\nwe need to add structural information to the abstract domain (Le Charlier and\nVan Hentenryck 1994).\n8 Related Works\n8.1 Relationship with ESubst\nThe domain ESubst proposed by Jacobs and Langen (1992) uses a non standard definition of substitution. We may prove that ESubst is isomorphic to ISubst \u223c . This\nformalizes the intuition, which has never been proved before, that working with\nESubst is essentially like working with substitutions. Similar proofs may be developed for ex-equations (Marriott et al. 1994) and existential Herbrand constraints\n(Levi and Spoto 2003).\nWe now briefly recall the definition of the domain ESubst . For the sake of clarity,\nin the following, we call E-substitution the nonstandard substitution defined in\n(Jacobs and Langen 1992). An E-substitution \u03c3 is a mapping from a finite set of\nvariables dom(\u03c3) \u2286 V to Terms. This approach differs from the standard definition\nof substitutions, which are mappings from V to Terms that are almost everywhere\nthe identity. The preorder on E-substitutions is defined as follows:\n\u03c3 \u2264E \u03b8 \u21d0\u21d2 dom(\u03b8) \u2286 dom(\u03c3) \u2227 \u2200t \u2208 Terms. vars(t) \u2286 dom(\u03b8) \u21d2\n\u0001\n\u2203\u03b4 an E-substitution s.t. \u03c3t = \u03b4(\u03b8(t)) , (37)\n\nwhere the application of an E-substitution to a term is defined as usual.\nLet \u223cE be the equivalence relation on E-substitutions induced by \u2264E . The domain ESubst is defined as the set of equivalence classes of E-substitutions w.r.t.\n\u223cE , that is ESubst = {[\u03c3]\u223cE | \u03c3 is an E-substitution}. The next theorem shows\nthat ESubst is isomorphic to Subst \u223c which, as shown in Prop. 3.7, is isomorphic to\nISubst \u223c .\n\n\f42\n\nG. Amato and F. Scozzari\n\nTheorem 8.1\nESubst and Subst \u223c are isomorphic posets.\nProof\nTo each E-substitution \u03b8 we may associate a substitution \u03b8\u2032 such that \u03b8\u2032 (x) = \u03b8(x)\nif x \u2208 dom(\u03b8) and \u03b8\u2032 (x) = x otherwise. Note that, for each term t, \u03b8(t) = \u03b8\u2032 (t):\nan E-substitution and the corresponding standard substitution behave in the same\nway on terms.\nWe may prove that, if \u03b81 \u2264E \u03b82 , then \u03b81\u2032 \u0016dom(\u03b82 ) \u03b82\u2032 . By definition, if \u03b81 \u2264E \u03b82\nthen dom(\u03b82 ) \u2286 dom(\u03b81 ) and \u2200t \u2208 Terms with vars(t) \u2286 dom(\u03b82 ), there exists\nan E-substitution \u03b4 such that \u03b81 (t) = \u03b4(\u03b82 (t)). Let dom(\u03b82 ) = {x1 , . . . , xn } and\nconsider a term t such that vars(t) = {x1 , . . . , xn } (note that t exists iff there is at\nleast a term symbol of arity strictly greater than 1). By definition, there exists an\nE-substitution \u03b4 such that \u03b81 (t) = \u03b4(\u03b82 (t)), that is, for any v \u2208 dom(\u03b82 ) it holds\n\u03b81 (v) = \u03b4(\u03b82 (v)). This means that \u03b81\u2032 (v) = \u03b4 \u2032 (\u03b82\u2032 (v)) and therefore \u03b81\u2032 \u0016dom(\u03b82 ) \u03b82\u2032 .\nOn the converse, for each \u03b8 \u2208 Subst and U \u2208 \u2118f (V), we associate a corresponding\nE-substitution \u03b8\u2217U such that dom(\u03b8\u2217U ) = U and \u03b8\u2217U (v) = \u03b8(v) for each v \u2208 U .\nAs for the previous case, we have that if \u03b81 \u0016U \u03b82 , then \u03b81\u2217U \u2264E \u03b82\u2217U . First of\nall, note that dom(\u03b81\u2217U ) = U = dom(\u03b82\u2217U ). Moreover, by definition of \u0016U , there is\n\u03b4 \u2208 Subst such that \u03b81 (v) = \u03b4(\u03b82 (v)) for each v \u2208 U . Now, given a term t such\nthat vars(t) \u2286 U , we may check that \u03b81\u2217U (t) = \u03b4 \u2217vars(\u03b82 (U)) (\u03b82\u2217U (t)) and this proves\n\u03b81\u2217U \u2264E \u03b82\u2217U .\nNow, we may lift these operations to equivalence classes to obtain the function\n\u03b9 : ESubst \u2192 Subst \u223c such that\n\u03b9([\u03b8]\u223cE ) = [\u03b8\u2032 ]dom(\u03b8) .\nThe map \u03b9 is well defined: if \u03b81 \u223cE \u03b82 then dom(\u03b81 ) = dom(\u03b82 ) and, by the above\nproperty, \u03b81\u2032 \u223cdom(\u03b82 ) \u03b82\u2032 . Moreover, there is an inverse \u03b9\u22121 given by\n\u03b9\u22121 ([\u03b8]U ) = [\u03b8\u2217U ]\u223cE .\nIt is easy to check that \u03b9\u22121 is well defined: if \u03b81 \u0016U \u03b82 , then \u03b81\u2217U \u2264E \u03b82\u2217U .\nIt is immediate to check, given the properties above, that \u03b9 and \u03b9\u22121 are one the\ninverse of the other. Moreover, they are both monotonic. If [\u03b81 ]E \u2264E [\u03b82 ]E then\ndom(\u03b82 ) \u2286 dom(\u03b81 ) and \u03b81\u2032 \u0016dom(\u03b82 ) \u03b82\u2032 , i.e., \u03b9([\u03b81 ]\u223cE ) = [\u03b81\u2032 ]dom(\u03b81 ) \u0016 [\u03b82\u2032 ]dom(\u03b82 ) =\n\u03b9([\u03b82 ]\u223cE ). On the converse, if [\u03b81 ]U \u0016 [\u03b82 ]V then [\u03b81 ]V \u0016 [\u03b82 ]V and therefore\n\u03b9\u22121 ([\u03b81 ]V ) \u2264E \u03b9\u22121 ([\u03b82 ]V ). We only need to prove that \u03b9\u22121 ([\u03b81 ]U ) \u2264E \u03b9\u22121 ([\u03b81 ])V .\nThis follows from that fact that, given a term t with vars(t) \u2286 V , \u03b81\u2217U (t) = \u03b81\u2217V (t).\nIt is worth noting that the most general unifier as defined in (Jacobs and Langen\n1992) corresponds to mgu in ISubst \u223c . In formulas, given term t1 and t2 , we have\nthat\n\u03b9([mgu(t1 , t2 )]\u223cE ) = [mgu({t1 = t2 })]vars(t1 =t2 ) ,\n\n(38)\n\nwhere mgu on the left is the operator in Definition 1 of (Jacobs and Langen 1992)\nand \u03b9 : ESubst \u2192 ISubst \u223c is the isomorphism defined in the proof of Theorem 8.1.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n43\n\nTo the best of our knowledge, this is the first proof of the relationship between the\nmgu in a domain of existential substitutions and the standard mgu for substitutions.\nMoreover, it is worth noting that by adding a bottom element to ISubst \u223c and\nESubst, they turn out to be isomorphic complete lattices.\n8.2 A Case Study\nIn Section 3 we said that, in order to define a good collecting semantics for correct\nanswer substitutions, there are several possible directions. We may work with a\ndomain of existentially quantified substitutions like ISubst \u223c , or we may work with\nstandard substitutions, being careful to keep enough representatives for each equivalence class. We have already discussed the benefits of using equivalence classes.\nIn order to show the kind of problems which arise from the use of domains of substitutions, without any equivalence relation, we want to show a small flaw of the\nsemantic framework defined in (Cortesi and Fil\u00e9 1999) for the analysis of sharing,\nand widely used in several other works on program analysis such as (Bagnara et al.\n2002; Hill et al. 2004).\nThe framework is based upon the domain Rsub = (\u2118(Subst )\u00d7\u2118f (V))\u222a{\u22a4Rs , \u22a5Rs }\nwhich is a complete lattice, partially ordered as follows: \u22a4Rs is the top element, \u22a5Rs\nis the bottom element and [\u03981 , U1 ] \u2291Rs [\u03982 , U2 ] if and only if U1 = U2 and \u03981 \u2286 \u03982 .\nAn object [\u0398, U ] is a set of substitution \u0398 where the set of variables of interest U\nis explicitly provided.\nThe main operation in Rsub is the concrete unification URs : Rsub \u00d7 Rsub \u00d7\nISubst \u2192 Rsub such that:\nURs (\u22a5Rs , \u03be, \u03b4) =URs (\u03be, \u22a5Rs , \u03b4) = \u22a5Rs\nURs (\u03be, \u22a4Rs , \u03b4) =URs (\u22a4Rs , \u03be, \u03b4) = \u22a4Rs\n\nif \u03be 6= \u22a5Rs\n\nURs ([\u03981 , U1 ], [\u03982 , U2 ], \u03b4) =[{mgu(\u03c31 , \u03c32 , \u03b4) | \u03c31 \u2208 \u03981 , \u03c32 \u2208 \u03982 ,\n\n(39)\n\nvars(\u03c31 ) \u2229 vars(\u03c32 ) = \u2205}, U1 \u222a U2 ] .\nAlthough it is well defined for all the values of the domain, URs ([\u03981 , U1 ], [\u03982 , U2 ], \u03b4)\nmay be restricted to those values such that U1 \u2229 U2 = \u2205 and vars(\u03b4) \u2286 U1 \u222a U2 ,\nsince this is the only way URs is used in the semantics defined in (Cortesi and Fil\u00e9\n1999).\nThe abstract domain is the same Sharing we use in our paper, with abstraction map \u03b1Sh : Rsub \u2192 Sharing and unification USh : Sharing \u00d7 Sharing \u00d7\nISubst \u2192 Sharing defined by:\nG\n\u03b1Sh ([\u0398, U ]) =\n{\u03b1Sh ([\u03c3]U ) | \u03c3 \u2208 \u0398} ,\n(40)\nSh\n\nUSh ([\u03981 , U1 ], [\u03982 , U2 ], \u03b4) = unif Sh ([\u03981 \u222a \u03982 , U1 \u222a U2 ], \u03b4)\n\n(41)\n\nThe domain of USh is restricted to the case U1 \u2229 U2 = \u2205 and vars(\u03b4) \u2286 U1 \u222a U2 .\nBy looking at the paper, we think that, in the idea of the authors, [\u0398, U ] \u2208 Rsub\nshould have been treated as [{[\u03c3]U | \u03c3 \u2208 \u0398}, U ] \u2208 Psub is in our framework.\nHowever, the condition vars(\u03c31 ) \u2229 vars(\u03c32 ) = \u2205, introduced in URs in order to\navoid variable clashes between the two chosen substitutions, is not enough for this\n\n\f44\n\nG. Amato and F. Scozzari\n\npurpose. Actually, URs only checks that \u03c31 and \u03c32 do not have variables in common,\nwithout considering their sets of variables of reference U1 and U2 . This unification\ncan lead to counterintuitive results.\nExample 8.2\nConsider the following concrete unification:\nURs ([{{x/y}}, {x}], [{\u01eb}, {y}], \u01eb) = [{{x/y}}, {x, y}] .\n\n(42)\n\nBeing vars(\u01eb) = \u2205, the concrete unification operator allows us to unify {x/y} with\n\u01eb without renaming the variable y, which is not a variable of interest in the first\nelement but it is treated as if it was. This also causes the incorrectness of USh .\nIf we consider Eq. (42) and compute the result on the abstract side by using the\nabstract unification operator USh , we have:\n=\n\nUSh ( \u03b1Sh ([{{x/y}}, {x}]), \u03b1Sh ([{\u01eb}, {y}]), \u01eb)\nUSh (\n[{x}, {x}],\n[{y}, {y}],\n\u01eb) = [{x, y}, {x, y}] .\n\nThis is not a correct approximation of the concrete result, since:\n\u03b1Sh ([{{x/y}}, {x, y}]) = [{xy}, {x, y}] 6\u2291Sh [{x, y}, {x, y}] .\nThis counterexample proves that the abstract unification operator USh is not\ncorrect w.r.t. the concrete one URs , invalidating the Theorem 6.3 in (Cortesi and\nFil\u00e9 1999). The problem can be solved by introducing a stronger check on variable\nclashes, namely by replacing the condition vars(\u03c31 ) \u2229 vars(\u03c32 ) = \u2205 with (vars(\u03c31 ) \u222a\nU1 ) \u2229 (vars(\u03c32 ) \u222a U2 ) = \u2205 in the definition of URs , thus obtaining the following\noperator:\nU\u2217Rs ([\u03981 , U1 ], [\u03982 , U2 ], \u03b4) = [{mgu(\u03c31 , \u03c32 , \u03b4) | \u03c31 \u2208 \u03981 , \u03c32 \u2208 \u03982 ,\n(vars(\u03c31 ) \u222a U1 ) \u2229 (vars(\u03c32 ) \u222a U2 ) = \u2205}, U1 \u222a U2 ] . (43)\nU\u2217Rs\n\nBy using\ninstead of URs , the proof of Theorem 6.3 in (Cortesi and Fil\u00e9 1999)\nbecomes valid.\nTheorem 8.3\nUSh is correct w.r.t. U\u2217Rs .\nProof\nIf we look at the proof of Theorem 6.3 in (Cortesi and Fil\u00e9 1999), it appears\nthat the problem is in the base case of the inductive argument, when i = 0.\nHere, it is stated that given [A1 , U1 ] and [A2 , U2 ] in Sharing with U1 \u2229 U2 = \u2205,\n\u03c3i \u2208 \u03b3Sh ([Ai , Ui ]) for i \u2208 {1, 2} with vars(\u03c31 ) \u2229 vars(\u03c32 ) = \u2205, then it holds\nthat [{\u03c10 }, U0 ] \u2291Rs \u03b3Sh ([R0 , U0 ]) where \u03c10 = \u03c31 \u228e \u03c32 , U0 = U1 \u222a U2 and R0 =\nA1 \u222a A2 . However, the substitutions \u03c31 = {x/y} \u2208 \u03b3Sh ([{x}, {x}]) and \u03c32 = \u01eb \u2208\n\u03b3Sh ([{y}, {y}]) of the previous example make the statement false. On the contrary,\nwhen U\u2217Rs is used instead of URs , then \u03c31 and \u03c32 are required to satisfy the\ncondition (vars(\u03c31 ) \u222a U1 ) \u2229 (vars(\u03c32 ) \u222a U2 ) = \u2205. From this, it truly follows that\n[{\u03c10 }, U0 ] = [{\u03c31 \u228e \u03c32 }, U0 ] \u2291Rs \u03b3Sh ([R0 , U0 ]). The inductive case for i > 0 is identical to that in (Cortesi and Fil\u00e9 1999), since for any A, B \u2208 Rsub and \u03b4 \u2208 ISubst\nit holds that U\u2217Rs (A, B, \u03b4) \u2291Rs URs (A, B, \u03b4).\n\n\fOptimality in goal-dependent analysis of Sharing\n\n45\n\nObserver that, in order to define a real semantics for logic programs, a renaming\noperation should be introduced in the framework of Cortesi and Fil\u00e9 (1999). This\ncan be done along the line of Cortesi et al. (1994). Due to the kind of renamings\ninvolved, by replacing URs with U\u2217Rs , the semantics in (Cortesi et al. 1994) does\nnot change. Therefore this flaw does not affect the real analysis of logic programs.\n8.3 Other Related Works\n8.3.1 Backward Unification\nThe idea of using a refined operator for computing answer substitutions is not new,\nand may be traced back to the frameworks in (Bruynooghe 1991; Le Charlier and\nVan Hentenryck 1994). The abstract domains considered in these papers contain\nstructural information, freeness, groundness and pair-sharing, but no set-sharing\ninformation. Working within these frameworks, Hans and Winkler (1992) and King\nand Longley (1995) propose correct abstract operators w.r.t. matching for the domain SFL. Muthukumar and Hermenegildo (1991; 1992) use a refined algorithm for\nbackward unification in Sharing, although it is not presented in algebraic form.\nHowever, to the best of our knowledge, this is the first paper which formally introduces matching from the point of view of a collecting denotational semantics,\nderiving the abstract operator from the concrete one, and proving correctness and\noptimality. Moreover, this is the first paper which presents optimal abstract matching for a domain for set-sharing analysis (see Example 7.3).\n8.3.2 Forward/Backward Unification and PSD\nAlthough the usual goal of sharing analyses is to discover the pairs of variables which\nmay possibly share, Sharing is a domain that keeps track of set-sharing information.\nBagnara et al. (2002) propose a new domain, called PSD, which is the complete shell\n(Giacobazzi et al. 2000) of pair sharing w.r.t. Sharing. They recognize that, in an\nabstract object [S, U ], some sharing groups in S may be redundant as far as pair\nsharing is concerned. Although our forward unification is more precise than the\nstandard unification, it could be the case that they have the same precision in PSD.\nf\nThis would mean that UfSh ([S1 , U1 ], A1 , A2 ) and U\u2032 Sh ([S1 , U1 ], A1 , A2 ) only differ\nfor redundant sharing groups. However, this is not the case, and Examples 6.2, 6.3\nand 6.19 show improvements which are still significant in PSD. The same holds for\nbackward unification in Example 7.3. It is not clear whether PSD is still complete\nw.r.t. pair-sharing when our specialized operators are used.\n8.3.3 Domains with Freeness and Linearity\nAlthough the use of freeness and linearity information has been pursued in several papers, e.g., (Muthukumar and Hermenegildo 1991; Hans and Winkler 1992),\noptimal operators for these domains have never been developed. All the abstract\nunification operators for SFL, e.g., (Muthukumar and Hermenegildo 1992; Hans and\nWinkler 1992; Hill et al. 2004), when unifying with a binding {x/t} where neither\n\n\f46\n\nG. Amato and F. Scozzari\n\nx nor t are linear, does compute all the star unions. On the contrary, in ufSh we\napply an optimization which is able to avoid some sharing groups (see e.g., Example 6.19). This optimization could be integrated in a domain which explicitly\ncontains freeness and linearity information.\nActually, Hill et al. (2004) include some optimizations for the standard abstract\nunification of SFL which are similar to ours, in the case of a binding {x/t} with x\nlinear. In addition, in (Hill et al. 2004; Howe and King 2003) the authors propose to\nremove the check for independence between x and t. We think it should be possible\nto devise an optimal abstract unification for an enhanced domain including linearity\ninformation, by combining these improvements with our results.\nA first optimality result is shown in (Amato and Scozzari 2003), which is based\non a preliminary version of the framework we present here. The authors consider\ntwo domains for set-sharing and linearity (without freeness), namely the standard\nreduced product of Sharing and linearity, and the domain proposed by King (1994).\nThe paper presents the abstract operators for forward unification, which turn out\nto be optimal in the case of a single-binding substitution. These are the only operators in the literature which are strictly more precise than our optimized forward\nunification operator for Sharing.\n8.3.4 Another Optimality Proof\nCodish et al. (2000) provide an alternative approach to the analysis of sharing by\nusing set logic programs and ACI1 unification. They define abstract operators which\nare proved to be correct and optimal, and examine the relationship between set\nsubstitutions and Sharing, proving that they are essentially isomorphic. However,\nthey do not extend this correspondence to the abstract operators, so that a proof\nof optimality of UfSh w.r.t. UfPs starting from their results should be feasible but it\nis not immediate. Moreover, since they provide a goal-independent analysis, they\ndo not have different operators for forward and backward unification.\n\n9 Conclusions\nWe think that there are three major contributions in this paper.\n\u2022 We integrate the framework of Cortesi et al. (1996) with several different\nproposals appeared in the literature for goal-dependent analysis of logic programs. We give formal proofs of the correctness of the resulting analysis and\nof optimality of the abstract operators. The aim is to clarify the relationships\nbetween these proposals and to provide a clear guidance for the development\nof static analysis for logic programs.\n\u2022 We introduce a new concrete domain of equivalence classes of substitutions\nwhich address the problem of variable clashes by taking into account sets\nof variables of interest. This problem has been considered by many authors\nbut, in our opinion, none of them fully developed a corresponding theory of\nsubstitutions, in the style of Palamidessi (1990).\n\n\fOptimality in goal-dependent analysis of Sharing\n\n47\n\n\u2022 Our definition of abstract forward unification sheds new light on the role of\nfreeness and linearity information, suggesting new optimizations which can\nalso be used in more powerful domains such as SFL.\nAlthough sharing analysis with more complex domains, including freeness and\nlinearity information, will likely be more precise than the analysis performed with\nSharing in our optimized framework, we think that this article may be a guideline\nfor developing new analysis for logic programs. The main ideas contained in this\npaper are not tied to the abstract domain in use. The framework we propose may\nbe instantiated with more precise abstract domains to further improve the result of\nthe abstract analysis. Moreover, the algorithm for the abstract forward unification\ncan be easily slotted into other analysis frameworks based on different concrete\nsemantics, including goal-independent ones.\nTo the best of our knowledge, this is the first work which optimizes the abstract\nforward unification for sharing analysis using freeness and linearity information\nimplicitly, i.e., without using a domain which contains such information.\nThis is also the first work where an abstract backward unification operator using\nmatching is proved to be optimal. We have shown that, to the best of our knowledge,\nall the abstract backward unification operators proposed so far for Sharing or more\npowerful domains (Hans and Winkler 1992; King and Longley 1995; Muthukumar\nand Hermenegildo 1992) were not optimal.\nAs a future work, we think that our results could be easily generalized for designing optimal unification operators for more complex domains possibly including\nlinearity, freeness and structural information. Preliminary results have appeared in\n(Amato and Scozzari 2003). Moreover, the problem of efficiently implementing the\nrefined backward unification could be addressed.\nA Correctness of the Goal-Dependent Collecting Semantics\nIn this appendix we provide a tedious proof that the collecting semantics we define\nis correct w.r.t. computed answers. We begin by formally introducing a notation\nfor SLD-derivations, following (Lloyd 1987; Apt 1990). Given a goal G = g1 . . . gk\nand a clause cl = H \u2190 B such that vars(G) \u2229 vars(cl ) = \u2205, we write\ncl\n\nG \u2212\u2192 (g1 . . . gi\u22121 Bgi+1 . . . gk )\u03c3\n\u03c3\n\n(A1)\n\nwhen \u03c3 = mgu(gi , H). Given a goal G and a program P , an SLD-derivation of G\nin P is given by a sequence of clauses cl 1 , . . . , cl n and idempotent substitutions\n\u03c31 , . . . , \u03c3n , such that\ncl\n\ncl\n\ncl\n\n\u03c31\n\n\u03c32\n\n\u03c3n\n\nn\n2\n1\nGn ,\n* * * \u2212\u2212\u2192\nG1 \u2212\u2212\u2192\nG \u2212\u2212\u2192\n\n(A2)\n\nwhere each cl i is the renaming of a clause in P apart from G, cl 1 , . . . , cl i\u22121 . The\ngoal Gn is called the end-goal, n is the length of the derivation and (\u03c3n \u25e6 \u03c3n\u22121 \u25e6\n* * * \u25e6 \u03c32 \u25e6 \u03c31 )|vars(G) is the (partial) computed answer. An SLD-refutation is an SLDderivation with the empty end-goal (denoted by \u0003). A leftmost SLD-derivation is\nan SLD-derivation where we always rewrite the leftmost atom in the goal (i.e., such\nthat i = 1 at every step in (A1)).\n\n\f48\n\nG. Amato and F. Scozzari\n\u2217\n\nWe write G \u2212\n\u2192 G\u2032 to denote an SLD-derivation with end-goal G\u2032 and partial\n\u03c3\n\n\u2264i\n\ncomputed answer \u03c3. We also write G \u2212\u2192 G\u2032 to denote an SLD-derivation with\n\u03c3\n\nend-goal G\u2032 , partial computed answer \u03c3 and whose length is less or equal then i.\nA substitution \u03c3 is a computed answer for G in P if there is an SLD-refutation\n\u2217\nG\u2212\n\u2192 \u0003.\n\u03c3\n\nIn this appendix we will prove the relationship between the set of computed\nanswers for P and its collecting semantics PJP K.\n\nA.1 Relevant Denotations\nc\n\nWe have defined a denotation as a continuous map in Atoms \u2192 Psub \u2192 Psub. We\nnow want to characterize the denotations which may arise as the results of our\ncollecting semantics.\nDefinition A.1\nA denotation d \u2208 Den is said to be relevant when\n\u2022 d is strict, i.e., dA\u22a5Ps = \u22a5Ps ;\n\u2022 dA[\u2206, V ] is either \u22a5Ps or [\u2206\u2032 , V \u222a vars(A)] for some \u2206\u2032 .\nNote that the least denotation \u03bbA.\u03bb[\u2206, V ].\u22a5Ps is relevant. A relevant denotation is\nwell-behaved, in the sense that either it does not say anything, or gives information\nfor all and only the variables which occur in the atom A and the entry substitution\n[\u2206, V ].\nProposition A.2\nIf d is relevant, then\n1.\n2.\n3.\n4.\n\nBJBKd\u22a5Ps = \u22a5Ps ;\nBJBKd[\u2206, V ] is either \u22a5Ps or [\u2206\u2032 , V \u222a vars(B)] for some \u2206\u2032 ;\nCJH \u2190 BKd is relevant;\nPJP K is relevant.\n\nProof\nThe first two points easily follow by induction on the structure of the body B. For\nthe third point, consider the definition of C. Note that\nUfPs (x, A, H) = \u03c0Ps (unif Ps (\u03c1(x), mgu(\u03c1(A) = H)), vars(H)) .\nSince vars(\u03c1(A)) is disjoint from H by definition of \u03c1, and since we consider relevant\nmgus, then either vars(mgu(\u03c1(A) = H)) = vars(\u03c1(A)) \u222a vars(H) or mgu(\u03c1(A) =\nH) = \u22a5. In the latter case, CJH \u2190 BKdA = \u22a5Ps , otherwise UfPs (x, A, H) =\n[\u2206\u2032 , vars(H)] for some \u2206\u2032 . By the previous point, we have that BJBKd(UfPs (x, A, H))\nis either \u22a5Ps or [\u2206\u2032\u2032 , vars(H) \u222a vars(B)] for some \u2206\u2032\u2032 . In the first case, CJH \u2190\n\n\fOptimality in goal-dependent analysis of Sharing\n\n49\n\nBKdA = \u22a5Ps , otherwise, assuming x = [\u0398, V ], we have\nCJH \u2190 BKdAx = UbPs ([\u2206\u2032\u2032 , vars(H) \u222a vars(B)], x, H, A) =\n\u0010\n\u03c0Ps matchPs (\u03c1([\u2206\u2032\u2032 , vars(H) \u222a vars(B)]),\n\n\u0011\nunif Ps ([\u0398, V ], mgu(\u03c1(H) = A))), V \u222a vars(A) .\n\nFor the same reason explained above, and since we can ignore the case in which \u03c1(H)\nand A do not unify, we have that unif Ps ([\u0398, V ], mgu(\u03c1(H) = A)) = [\u0398\u2032 , V \u222avars(A)]\nand therefore\n\u03c0Ps (matchPs (\u03c1([\u2206\u2032\u2032 , vars(H) \u222a vars(B)]), [\u0398\u2032 , V \u222a vars(A)]), V \u222a vars(A)) =\n[\u0398\u2032\u2032 , V \u222a vars(A)] ,\nwhich is what we wanted to prove.\nThe forth point follows by the fact that, given the proof of the third point, CJclKd\nis relevant for each clause cl, and that least upper bound of relevant denotations\nare easily seen to be relevant.\nA.2 Unused variables\nDefinition A.3\nGiven [\u03c6]V \u2208 ISubst \u223c and\n\u0001 x \u2208 V, we say that x is unused in [\u03c6]V when [\u03c6]V =\nmgu \u03c0V \\{x} ([\u03c6]V ), [\u01eb]{x} .\n\nFirst of all, note that this definition does not depend on the choice of representatives. If a variable x is unused in [\u03c6]V , it means that [\u03c6]V does not constraint\nin any way its value. In other words, x is free and independent from all the other\nvariables in V . This is made clear by the following characterization:\nProposition A.4\nThe variable x \u2208 V is unused in [\u03c6]V iff it is free and independent in [\u03c6]V .\nProof\nIf x is free and independent in [\u03c6]V , we may assume without loss of generality that\nx\u2208\n/ vars(\u03c6). Let V \u2032 = V \\ {x}. We have that\nmgu(\u03c0V \u2032 ([\u03c6]V ), [\u01eb]{x} ) = mgu([\u03c6]V \u2032 , [\u01eb]{x} ) = [\u03c6|V \u2032 ]V = [\u03c6]V ,\nwhich proves that x is unused. On the other hand, assume \u03c6 is a canonical representative and mgu([\u03c6]V \u2032 , [\u01eb]{x} ) = [\u03c6]V . Then \u03c6|V \u2032 \u223cV \u03c6. It is obvious that x is free\nand independent in [\u03c6|V \u2032 ]V = [\u03c6]V , since x \u2208\n/ dom(\u03c6|V \u2032 ) and x \u2208\n/ rng(\u03c6).\nA.3 ISubst \u223c and composition\nThe operations described in Section 3.2 are those required to provide a collecting\nsemantics for logic programs over the domain ISubst \u223c . Note that we do not define\n\n\f50\n\nG. Amato and F. Scozzari\n\nany notion of composition, although it plays a central role with the standard substitutions. Actually, composition cannot be defined in our framework since, given\nany element of ISubst \u223c , variables not of interest are considered up to renaming\nonly, and therefore cannot be named. Nonetheless, in order to prove the equivalence between the standard semantics based on SLD-resolution and our collecting\nsemantics, we will need to relate the composition of substitutions with unification\nin ISubst \u223c .\nLemma A.5\n(Composition Lemma) Let \u03c31 , \u03c32 , \u03c33 \u2208 Subst, U, V \u2208 \u2118f (V). Then it holds that:\nmgu([\u03c33 \u25e6 \u03c32 ]U , [\u03c32 \u25e6 \u03c31 ]V ) = [\u03c33 \u25e6 \u03c32 \u25e6 \u03c31 ]U\u222aV\nprovided that:\n\u2022 dom(\u03c31 ) \u2229 U = \u2205;\n\u2022 if y \u2208 \u03c32 (\u03c31 (V )) \\ \u03c32 (\u03c31 (U \u2229 V )) then y \u2208\n/ dom(\u03c33 ) \u222a \u03c33 (\u03c32 (U )).\nProof\nLet \u03b8 \u2208 [\u03c33 \u25e6 \u03c32 ]U , \u03b7 \u2208 [\u03c32 \u25e6 \u03c31 ]V be canonical representatives such that (vars(\u03b8) \u222a\nU ) \u2229 (vars(\u03b7) \u222a V ) \u2286 U \u2229 V . By definition, there exist \u03c1, \u03c1\u2032 \u2208 Ren such that\n\u03b8 = (\u03c1\u2032 \u25e6 \u03c33 \u25e6 \u03c32 )|U and \u03b7 = (\u03c1 \u25e6 \u03c32 \u25e6 \u03c31 )|V .\nThen mgu([\u03c33 \u25e6 \u03c32 ]U , [\u03c32 \u25e6 \u03c31 ]V ) = [mgu(\u03b8, \u03b7)]U\u222aV . It holds that mgu(\u03b8, \u03b7) =\nmgu(\u03b7(Eq(\u03b8))) \u25e6 \u03b7. It follows that \u03b7(Eq(\u03b8)) = {\u03b7(x) = \u03b7(\u03b8(x)) | x \u2208 U } = {\u03b7(x) =\n\u03b8(x) | x \u2208 U } since \u03b8 is a canonical representative. If x \u2208 U \u2229 V , then \u03b7(x) =\n\u03b8(x) becomes \u03c1 \u25e6 \u03c32 \u25e6 \u03c31 (x) = \u03c1\u2032 \u25e6 \u03c33 \u25e6 \u03c32 (x) which is \u03c1 \u25e6 \u03c32 (x) = \u03c1\u2032 \u25e6 \u03c33 \u25e6 \u03c32 (x)\nsince dom(\u03c31 ) \u2229 U = \u2205 by hypothesis. Thus {\u03b7(x) = \u03b8(x) | x \u2208 U \u2229 V } and\n{\u03c1(y) = \u03c1\u2032 \u25e6 \u03c33 (y) | y \u2208 \u03c32 (U \u2229 V )} have the same set of solutions. If x \u2208\n/ V then\n{\u03b7(x) = \u03b8(x) | x \u2208 U \\ V } = {x = \u03b8(x) | x \u2208 U \\ V }.\nNow \u03b4 = {\u03c1(y)/\u03c1\u2032 \u25e6\u03c33 (y) | y \u2208 \u03c32 (U \u2229V )}\u222a{x/\u03b8(x) | x \u2208 U \\V } is an idempotent\nsubstitution. Actually, all the \u03c1(y)'s are distinct variables and different from U \\ V\ntherefore \u03b4 is a substitution. Moreover, dom(\u03b4) \u2286 vars(\u03b7(V )) \u222a (U \\ V ) is disjoint\nfrom rng(\u03b4) = vars(\u03b8(U )).\nLet \u03c1\u2032\u2032 be the substitution\n\uf8f1\n\uf8f4\n\uf8f4\u03c1\u2032 (x) if x \u2208 \u03c33 \u03c32 (U )\n\uf8f2\n\u03c1\u2032\u2032 (x) = \u03c1(x) if x \u2208 \u03c32 (\u03c31 (V )) \\ \u03c32 (\u03c31 (U \u2229 V ))\n\uf8f4\n\uf8f4\n\uf8f3x\notherwise\n\nNote that, thanks to the second hypothesis of the lemma, we are sure that the\nfirst and second case in the definition of \u03c1\u2032\u2032 may not occur together. We want to\nprove that \u03b4(\u03b7(x)) = \u03c1\u2032\u2032 (\u03c33 (\u03c32 (\u03c31 (x)))) for each x \u2208 U \u222a V . Since \u03c1\u2032\u2032 restricted\nto vars(\u03c33 (\u03c32 (\u03c31 (U \u222a V )))) is an injective map from variables to variables, by\nLemma 3.4 this implies \u03b4 \u25e6 \u03b7 \u223cU\u222aV \u03c33 \u25e6 \u03c32 \u25e6 \u03c31 , which is the statement of the\ntheorem.\nThus if x \u2208 U \\ V then \u03b7(x) = x and \u03b4(\u03b7(x)) = \u03b8(x) = \u03c1\u2032 (\u03c33 (\u03c32 (x))) =\n\u2032\u2032\n\u03c1 (\u03c33 (\u03c32 (x))) = \u03c1\u2032\u2032 (\u03c33 (\u03c32 (\u03c31 (x)))) since dom(\u03c31 ) \u2229 U = \u2205 and by definition of\n\u03c1\u2032\u2032 .\n\n\fOptimality in goal-dependent analysis of Sharing\n\n51\n\nIf x \u2208 U \u2229 V then \u03b4(\u03b7(x)) = \u03b4(\u03c1(\u03c32 (x))) since dom(\u03c31 ) \u2229 U = \u2205 and thus\n\u03b4(\u03b7(x)) = \u03c1\u2032 (\u03c33 (\u03c32 (x))), which is equal to \u03c1\u2032\u2032 (\u03c33 (\u03c32 (\u03c31 (x)))) since dom(\u03c31 ) \u2229 U = \u2205\nand by definition of \u03c1\u2032\u2032 .\nIf x \u2208 V \\ U then \u03b4(\u03b7(x)) = \u03b4(\u03c1(\u03c32 \u03c31 (x))). Let y \u2208 vars(\u03c32 (\u03c31 (x))). If we assume\nthat y \u2208 vars(\u03c32 (U \u2229 V )), then \u03b4(\u03c1(y)) = \u03c1\u2032 (\u03c33 (y)) = \u03c1\u2032\u2032 (\u03c33 (y)) by definition of\n\u03b4 and \u03c1\u2032\u2032 . If y \u2208\n/ vars(\u03c32 (U \u2229 V )) then \u03b4(\u03c1(y)) = \u03c1(y) = \u03c1\u2032\u2032 (y) = \u03c1\u2032\u2032 (\u03c33 (y)) by\n\u2032\u2032\ndefinition of \u03c1 and the second condition in the theorem. In both cases we obtain\n\u03b4(\u03c1(y)) = \u03c1\u2032\u2032 (\u03c33 ((y))) for each y \u2208 vars(\u03c32 (\u03c31 (x))). Therefore, for each x \u2208 U \u2229 V ,\n\u03b4(\u03b7(x)) = \u03b4(\u03c1(\u03c32 (\u03c31 (x)))) = \u03c1\u2032\u2032 (\u03c33 (\u03c32 (\u03c31 (x)))) and this concludes the proof.\nA.4 Proof of Correctness\nF\nLet DP be defined as \u03bbd. Ps {CJclKd | cl \u2208 P } and let DPi be the i-th iteration of\nDP with DP0 = \u03bbA.\u03bbx.\u22a5Ps . Note that DP\u03c9 = PJP K and DPi is relevant for each i.\nLemma A.6\n(Correctness Lemma) Let i \u2208 N, [\u03c6]V \u2208 ISubst \u223c , G \u2208 Bodies and P \u2208 Progs. If\n\u2217\n[\u03c6]V \u222aG = mgu([\u03c6]V , [\u01eb]G ) and G\u03c6 \u2212\n\u2192 \u0003 is a leftmost SLD-refutation, with at most\n\u03c3\ni steps, where all clauses are renamed apart from V , G, \u03c6 and the program P , then\nBJGKDPi [{[\u03c6]}, V ] \u2292Ps [{[\u03c3 \u25e6 \u03c6]}, V \u222a vars(G)].\nRemark A.7\nThe condition [\u03c6]V \u222aG = mgu([\u03c6]V , [\u01eb]G ) is used to check that the chosen representative \u03c6 does not bind any variable in vars(G) \\ V . All the variables in vars(G) \\ V\nare forced to be unused, according to Definition A.3.\nRemark A.8\nThe theorem probably holds under weaker conditions on the variables of the SLDresolution. However, proving the result in this case would be more difficult. Since\nthe obtained generalization is not very interesting, we valued that it was not worth\nthe effort.\nProof\nThe proof is by double induction on i and on the structure of the goal G. Assume\nfixed \u03a6 = {[\u03c6]V } such that [\u03c6]V \u222aG = mgu([\u03c6]V , [\u01eb]G ).\nWe start with the case i = 0. The only SLD-refutation of length 0 is the SLDderivation for the empty goal \u0003, whose computed answer substitution is \u01eb. In the\ncollecting semantics, we have BJ\u0003KDPi [{[\u03c6]}, V ] = [{[\u03c6]}, V ] = [{[\u01eb \u25e6 \u03c6]}, V ] which\nis the required result.\nIf i > 0, assume the lemma holds for all j < i and we prove it for i, by induction\non the structure of goals. The case for the empty goal has been already examined, so\nwe assume G = A, G\u2032 where A is an atom. To ease the exposition, we first consider\nthe atomic case where G\u2032 = \u0003 and then we analyze the general one.\n\u2217\n\nAtomic goal. Given the not-empty SLD-derivation G\u03c6 \u2212\n\u2192 \u0003, we may decompose\n\u03c3\nit as:\n\u03c1(cl)\n\n\u2217\n\n\u03c31\n\n\u03c32\n\nG\u03c6 \u2212\u2212\u2212\u2192 (C1 . . . Cn )\u03c1\u03c31 \u2212\u2192 \u0003\n\n\f52\n\nG. Amato and F. Scozzari\n\nwhere cl = H \u2190 C1 . . . Cn is a program clause, \u03c31 = mgu(G\u03c6, H\u03c1) and \u03c1 is a\nrenaming of cl apart from G, V , \u03c6 and the program P . Note that this implies the\nstandard renaming condition for SLD-resolutions, i.e., that \u03c1(cl) is renamed apart\nfrom G\u03c6. Since G is atomic, then\nBJGKDPi [\u03a6, V ] = DPi G[\u03a6, V ] \u2292Ps CJH \u2190 C1 . . . Cn KDPi\u22121 G[\u03a6, V ] ,\nwhich, in turn, is equal to UbPs (BJC1 . . . Cn KDPi\u22121 (UfPs ([\u03a6, V ], G, H)), [\u03a6, V ], H, G).\nWe know that\nUfPs ([{[\u03c6]}, V ], G, H) = \u03c0Ps (mgu(\u03c1\u2032 ([\u03c6]V ), [mgu(\u03c1\u2032 (G) = H)]\u03c1\u2032 (G)\u222aH ), vars(H))\nwhere \u03c1\u2032 is any renaming such that \u03c1\u2032 (vars(G)\u222aV )\u2229vars(H) = \u2205. We can choose as\n\u03c1\u2032 the renaming \u03c1\u22121 since \u03c1(vars(cl)) \u2229 vars(G) = \u2205 and \u03c1(vars(cl)) \u2229 V = \u2205 implies\nthat \u03c1\u22121 (vars(G) \u222a V ) \u2229 vars(H) = \u2205. In turn, this implies that\nmgu(\u03c1\u2032 ([\u03c6]V ), [mgu(\u03c1\u2032 (G) = H)]\u03c1\u2032 (G)\u222aH )\n=\n\n\u03c1\u22121 (mgu([\u03c6]V , [mgu(G = \u03c1(H))]G\u222a\u03c1(H) )\n\n=\n\n\u03c1\u22121 (mgu([\u03c6]V , [mgu(G = \u03c1(H))]G\u222a\u03c1(H) , [\u01eb]G ))\n\n=\n\n\u03c1\u22121 (mgu([\u03c6]V \u222aG , [mgu(G = \u03c1(H))]G\u222a\u03c1(H) )\n\n=\n\n\u03c1\u22121 ([mgu(\u03c6, mgu(G = \u03c1(H)))]V \u222aG\u222a\u03c1(H) ) .\n\nThe last pass is only valid when (V \u222a vars(G) \u222a vars(\u03c6)) \u2229 (vars(G) \u222a vars(\u03c1(H)) \u2286\n(V \u222a vars(G)) \u2229 (vars(G) \u222a vars(\u03c1(H))) = vars(G). This is the case since vars(\u03c6) \u2229\n\u03c1(vars(cl )) = \u2205, thanks to our choice of \u03c1.\nBy standard properties of substitutions, we obtain:\n\u03c1\u22121 ([mgu(\u03c6, mgu(G = \u03c1(H)))]V \u222aG\u222a\u03c1(H) )\n=\n\n\u03c1\u22121 ([mgu(G\u03c6 = (\u03c1(H))\u03c6) \u25e6 \u03c6]V \u222aG\u222a\u03c1(H) )\n\n=\n\n\u03c1\u22121 ([mgu(G\u03c6 = \u03c1(H)) \u25e6 \u03c6]V \u222aG\u222a\u03c1(H) )\n\n=\n\n\u03c1\u22121 ([\u03c31 \u25e6 \u03c6]V \u222aG\u222a\u03c1(H) ) ,\n\nsince vars(\u03c6) \u2229 vars(\u03c1(H)) = \u2205. For the same reason, \u03c31 \u25e6 \u03c6 \u223cvars(\u03c1(H)) \u03c31 . It follows\nthat\n\u03c1\u22121 (\u03c31 \u25e6 \u03c6) \u223cvars(H) \u03c1\u22121 (\u03c31 ) = \u03c1\u22121 \u25e6 \u03c31 \u25e6 \u03c1 \u223cvars(H) \u03c31 \u25e6 \u03c1 .\nTherefore UfPs ([{[\u03c6]}, V ], G, H) = [{[\u03c31 \u25e6 \u03c1]}, vars(H)] and\nUbPs (BJC1 . . . Cn KDPi\u22121 (UfPs ([\u03a6, V ], G, H)), [\u03a6, V ], H, G) \u2292Ps\nUbPs (BJC1 . . . Cn KDPi\u22121 [{[\u03c31 \u25e6 \u03c1]}, vars(H)], [\u03a6, V ], H, G) .\n\u2217\n\nNote that the SLD resolution (C1 . . . Cn )\u03c1\u03c31 \u2212\u2192 \u0003 can be seen as (C1 . . . Cn )(\u03c31 \u25e6\n\u03c32\n\n\u2217\n\n\u03c1) \u2212\u2192 \u0003. In order to apply the inductive hypothesis on the latter derivation, we\n\u03c32\n\nneed to verify that [\u03c31 \u25e6 \u03c1]vars(cl) = mgu([\u03c31 \u25e6 \u03c1]vars(H) , [\u01eb]vars(C1 ...Cn ) ). By definition \u03c31 \u25e6 \u03c1 = mgu(G\u03c6, H\u03c1) \u25e6 \u03c1. Moreover, since \u03c1(vars(cl)) \u2229 vars(G\u03c6) = \u2205 and\n\u03c1(vars(cl)) \u2229 vars(H\u03c1) = vars(H\u03c1), it follows that for all v \u2208 \u03c1(vars(cl) \\ vars(H)),\nv\u2208\n/ vars(\u03c31 ). Hence, for each v \u2208 vars(cl) \\ vars(H), \u03c31 (\u03c1(v)) = \u03c1(v). Moreover, if\n\n\fOptimality in goal-dependent analysis of Sharing\n\n53\n\n\u03c1(v) occurs in (\u03c31 \u25e6 \u03c1)(x) for some x, then \u03c1(v) occurs in \u03c1(x) and this is only possible if x = v. By Prop. A.4, this proves that mgu([\u03c31 \u25e6 \u03c1]vars(H) , [\u01eb]vars(C1 ...Cn ) ) =\n[\u03c31 \u25e6 \u03c1]vars(cl) . Thus, by inductive hypothesis, we have that:\nUbPs (BJC1 . . . Cn KDPi\u22121 [{[\u03c31 \u25e6 \u03c1]}, vars(H)], [\u03a6, V ], H, G) \u2292Ps\nUbPs ([{[\u03c32 \u25e6 \u03c31 \u25e6 \u03c1]}, vars(cl)], [\u03a6, V ], H, G) .\nWe know that unif Ps ([{[\u03c6]}, V ], mgu(\u03c1(H) = G)) = [{[\u03c31 \u25e6 \u03c6]}, V \u222a vars(G) \u222a\nvars(\u03c1(H))]. Therefore, choosing \u03c1 as the renaming for UbPs , we obtain\nmatchPs (\u03c1([{[\u03c32 \u25e6 \u03c31 \u25e6 \u03c1]}, vars(cl)]), [{[\u03c31 \u25e6 \u03c6]}, V \u222a vars(G) \u222a vars(\u03c1(H))])\n= matchPs ([{[\u03c1 \u25e6 \u03c32 \u25e6 \u03c31 ]}, vars(\u03c1(cl))]), [{[\u03c31 \u25e6 \u03c6]}, V \u222a vars(G) \u222a vars(\u03c1(H))])\n= matchPs ([{[\u03c32 \u25e6 \u03c31 ]}, vars(\u03c1(cl))]), [{[\u03c31 \u25e6 \u03c6]}, V \u222a vars(G) \u222a vars(\u03c1(H))]) .\nSince vars(\u03c1(cl))\u2229(V \u222avars(G)\u222avars(\u03c1(H))) = vars(\u03c1(H)) and \u03c32 \u25e6\u03c31 \u0016vars(\u03c1(H))\n\u03c31 \u25e6 \u03c6 (being vars(\u03c6) \u2229 vars(\u03c1(H)) = \u2205), it holds:\nmatchPs ([{[\u03c32 \u25e6 \u03c31 ]}, vars(\u03c1(cl))]), [{[\u03c31 \u25e6 \u03c6]}, V \u222a vars(G) \u222a vars(\u03c1(H))]) =\n[mgu([\u03c32 \u25e6 \u03c31 ]\u03c1(cl) , [\u03c31 \u25e6 \u03c6]V \u222aG\u222a\u03c1(H) ), V \u222a vars(G) \u222a vars(\u03c1(H))]\nWe would like to apply the Composition Lemma (Lemma A.5) to this unification.\nWe need to check that:\n\u2022 dom(\u03c6) \u2229 \u03c1(cl ) = \u2205;\n\u2022 y \u2208 \u03c31 \u03c6(V \u222a vars(G) \u222a \u03c1(H)) \\ \u03c31 \u03c6(\u03c1(H)) then y \u2208\n/ dom(\u03c32 ) \u222a \u03c32 \u03c31 (\u03c1(cl)).\nThe first property trivially follows by the hypothesis that \u03c1 renames cl apart from\n\u03c6. For the second condition, note that, since \u03c31 = mgu(G\u03c6, H\u03c1), if y \u2208 \u03c31 (\u03c6(G))\nthen y \u2208 \u03c31 (\u03c1(H)) = \u03c31 (\u03c6(\u03c1(H))). Therefore y \u2208 \u03c31 (\u03c6(V \u222a vars(G))) \\ \u03c31 (\u03c6(\u03c1(H)))\niff y \u2208 \u03c31 (\u03c6(V \\ G)) = \u03c6(V \\ G). However, since such a variable does not appear in\nthe initial goal of the SLD-resolution G\u03c6 and since the resolution is renamed apart\nfrom \u03c6, it happens that it does not appear in vars(\u03c32 ), and thus in dom(\u03c32 ). We\nnow show that y \u2208\n/ \u03c32 (\u03c31 (\u03c1(cl))). By hypothesis, y \u2208\n/ \u03c31 (\u03c6(\u03c1(cl))), and since \u03c1(cl)\nis renamed apart from \u03c6, it follows that y \u2208\n/ (\u03c31 (\u03c1(cl))). Moreover, as we have seen\nbefore, y \u2208\n/ vars(\u03c32 ), hence y \u2208\n/ vars(\u03c32 (\u03c31 (\u03c1(cl)))).\nIt turns out that we may apply the Composition Lemma (Lemma A.5) and we\nobtain\n[mgu([\u03c32 \u25e6 \u03c31 ]\u03c1(cl) , [\u03c31 \u25e6 \u03c6]V \u222aG\u222a\u03c1(H) ), V \u222a vars(G) \u222a vars(\u03c1(H))] =\n[{\u03c32 \u25e6 \u03c31 \u25e6 \u03c6}, \u03c1(cl ) \u222a V \u222a G] .\nBy projecting on G \u222a V we obtain\nBJGKDPi [\u03a6, V ] \u2292Ps [{\u03c32 \u25e6 \u03c31 \u25e6 \u03c6]}, V \u222a vars(G)] ,\nwhich concludes the proof of the atomic case.\nNon-atomic goal. In this case, decompose the (leftmost) SLD-resolution for G =\nA, G\u2032 in the following way:\n\u2217\n\n\u2217\n\n\u03c31\n\n\u03c32\n\nA\u03c6, G\u2032 \u03c6 \u2212\u2192 G\u2032 \u03c6\u03c31 \u2212\u2192 \u0003 ,\n\n(A3)\n\n\f54\n\nG. Amato and F. Scozzari\n\nwhere both the sub-derivations have length strictly less than i. Note that, since the\ncomplete derivation is renamed apart from V, G, \u03c6 and the program P , the same\nholds for the first sub-derivation. Moreover, since [\u03c6]V \u222aG = mgu([\u03c6]V , [\u01eb]G ), each\nv \u2208 A is free and independent in [\u03c6]V \u222aG , i.e., [\u03c6]V \u222aA = mgu([\u03c6]V , [\u01eb]A ). Therefore,\nwe may apply what proved in the atomic case above, obtaining\nDPi A[\u03a6, V ] \u2292Ps [{\u03c31 \u25e6 \u03c6}, V \u222a vars(A)] .\nThe second sub-derivation in (A3) is renamed apart from\n\u2022 V since the complete derivation is renamed apart from V ;\n\u2022 A and G\u2032 since the complete derivation is renamed apart from G;\n\u2022 \u03c31 \u25e6 \u03c6 since the complete derivation is renamed apart from \u03c6 and the second\npart is renamed apart from \u03c31 ;\n\u2022 P , since the complete derivation is renamed apart from P .\nMoreover, assume x \u2208 vars(G\u2032 )\\vars(V \u222aA) and x 6= y \u2208 vars(V \u222aG). By hypothesis,\n[\u03c6]V \u222aG = mgu([\u03c6]V , [\u01eb]G ), which implies that \u03c6(x) \u2208 V and \u03c6(x) \u2208\n/ vars(\u03c6(y)). Since\nvars(\u03c31 ) = W \u222a X where W is a fresh set of variables disjoint from V \u222a G and \u03c6 and\nX \u2286 vars(A\u03c6), it happens that \u03c6(x) \u2208\n/ vars(\u03c31 ). Therefore \u03c31 (\u03c6(x)) = \u03c6(x) and\n\u03c6(x) \u2208\n/ vars(\u03c31 (\u03c6(y))). This implies that [\u03c31 \u25e6 \u03c6]V \u222aG = mgu([\u03c31 \u25e6 \u03c6]V \u222aA , [\u01eb]G\u2032 ) by\nProp. A.4. This means that we may apply the inductive hypothesis on the second\nsub-derivation, obtaining:\nBJG\u2032 KDPi [{\u03c31 \u25e6 \u03c6}, V \u222a vars(A)] \u2292Ps [{\u03c32 \u25e6 \u03c31 \u25e6 \u03c6}, V \u222a vars(G)] .\nSince BJA, G\u2032 KDPi [\u03a6, V ] = BJG\u2032 KDPi (DPi A[\u03a6, V ]) by the above disequalities and\nmonotonicity of B, we obtain\nBJA, G\u2032 KDPi [\u03a6, V ] \u2292Ps [{\u03c32 \u25e6 \u03c31 \u25e6 \u03c6}, V \u222a vars(G)] .\nwhich concludes the proof.\nNow we may use standard properties of SLD-resolution together with Lemma A.6\nto prove the required correctness theorem.\nTheorem A.9\n(Semantic Correctness) Given a program P and an goal G, if \u03b8 is a computed\nanswer for the goal G, then\nBJGK(PJP K)G[{\u01eb}, vars(G)] \u2292Ps [{[\u03b8]}, vars(G)] .\nProof\nIf \u03b8 is a computed answer for a goal G, and \u03c1 is a renaming, then \u03b8\u2032 = (\u03c1\u25e6\u03b8)|vars(G) is\na computed answer too (Apt 1990) and \u03b8 \u223cvars(G) \u03b8\u2032 . Consider any such \u03b8\u2032 with the\n\u2217\nproperty that vars(\u03b8\u2032 ) \u2229 vars(P ) = \u2205 and let G \u2212\u2192\n\u0003 be a leftmost SLD-resolution\n\u2032\n\u03b8\n\n\u2217\n\nfor \u03b8\u2032 . Since there exists a leftmost SLD-resolution G \u2212\u2192\n\u0003 which is renamed apart\n\u2032\nfrom P , then, by Lemma A.6, the thesis follows.\n\n\u03b8\n\nB Correctness of Forward Unification\n\n\fOptimality in goal-dependent analysis of Sharing\n\n55\n\nLemma B.1\nGiven \u03b4, \u03c3 \u2208 Subst, v \u2208 V, it is the case that occ(\u03b4 \u25e6 \u03c3, v) = occ(\u03c3, occ(\u03b4, v)).\nProof\nBy definition, x \u2208 occ(\u03b4 \u25e6 \u03c3, v) iff v \u2208 \u03b4(\u03c3(x)), i.e., there exists w \u2208 V such that\nw \u2208 \u03c3(x) and v \u2208 \u03b4(w). In other words, x \u2208 occ(\u03b4 \u25e6 \u03c3, v) iff there exists w \u2208 V\ns.t. w \u2208 occ(\u03b4, v) and x \u2208 occ(\u03c3, w) iff x \u2208 occ(\u03c3, occ(\u03b4, v)).\nProposition B.2\nLet t \u2208 Terms, \u03c3 \u2208 Subst and U \u2208 \u2118f (V) such that vars(t) \u2286 U . Let \u03b1Sh ([\u03c3]U ) \u2291Sh\n[S, U ]. Then the following property holds:\n\u2200v \u2208 V.v \u2208 vars(t\u03c3) \u21d0\u21d2 occ(\u03c3, v) \u2229 U \u2208 rel(S, t) .\nProof\nNote that v \u2208 vars(t\u03c3) iff \u2203u \u2208 t such that v \u2208 \u03c3(u). In turn, this holds iff \u2203u \u2208 t\ns.t. u \u2208 occ(\u03c3, v) iff occ(\u03c3, v) \u2229 vars(t) 6= \u2205 iff (occ(\u03c3, v) \u2229 U ) \u2229 vars(t) 6= \u2205. Note that\nX = occ(\u03c3, v) \u2229 U \u2208 S and therefore X \u2229 vars(t) 6= \u2205 iff X \u2208 rel(S, t) by definition\nof rel.\nProposition B.3\nLet [\u03c3]U \u2208 ISubst \u223c , {x/t} \u2208 ISubst such that vars({x/t}) \u2286 U and \u03c3 and {x/t}\nunify. If \u03b1Sh ([\u03c3]U ]) \u2291Sh [S, U ] and \u03b4 = mgu(x\u03c3 = t\u03c3), we obtain:\n\u03b1Sh (mgu([\u03c3]U , [x/t]U )) \u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t)))\n\u222a {occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}, U ] .\nProof\nSince vars({x/t}) \u2286 U , we have mgu([\u03c3]U , [x/t]U ) = [mgu(\u03c3, {x/t})]U . Then, by\ndefinition of \u03b4, it holds that mgu(\u03c3, x = t) = mgu(Eq(\u03c3) \u222a x\u03c3 = t\u03c3) = mgu(x\u03c3 =\nt\u03c3) \u25e6 \u03c3 = \u03b4 \u25e6 \u03c3 (Palamidessi 1990, Prop. 6.1). Therefore, we only need to show that:\n\u03b1Sh ([\u03b4 \u25e6 \u03c3]U ) \u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t)))\n\u222a {occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}, U ] .\n\n(B1)\n\nBy definition of \u03b1Sh , we have to show that, for all v \u2208 V, occ(\u03b4 \u25e6 \u03c3, v) \u2229 U \u2208\n(S \\ (rel(S, x) \u222a rel(S, t))) \u222a {occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}. Let v \u2208 V.\nWe have the following cases:\n\u2022 v \u2208 vars(x\u03c3 = t\u03c3): by Lemma B.1, {occ(\u03b4 \u25e6 \u03c3, v) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)} =\n{occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}.\n\u2022 v\u2208\n/ vars(x\u03c3 = t\u03c3): thus v \u2208\n/ vars(\u03b4) and occ(\u03b4\u25e6\u03c3, v) = occ(\u03c3, v). We know that\nocc(\u03c3, v) \u2229 U \u2208 S, by definition of S. Moreover, we show that occ(\u03c3, v) \u2229 U \u2208\n/\nrel(S, x) \u222a rel(S, t). Since v \u2208\n/ vars(x\u03c3 = t\u03c3), we can apply Prop. B.2 twice\nto the terms x and t, and obtain occ(\u03c3, v) \u2229 U \u2208\n/ rel(S, x) \u222a rel(S, t).\nBy collecting the results of the two cases, Equation (B1) is proved.\n\n\f56\n\nG. Amato and F. Scozzari\n\nProposition B.4\nLet [\u03c3]U \u2208 ISubst \u223c , {x/t} \u2208 ISubst such that vars({x/t}) \u2286 U and \u03c3 and {x/t}\nunify. If \u03b1Sh ([\u03c3]U ) \u2291Sh [S, U ] and x is free and independent from U in [\u03c3]U , then:\n\u03b1Sh (mgu([\u03c3]U , [x/t]U ))\n\u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t))) \u222a bin(rel(S, x), rel(S, t)), U ] .\nProof\nFirst of all note that, without loss of generality, we may assume x \u2208\n/ vars(\u03c3). Then,\nby Prop.B.3, we have that:\n\u03b1Sh (mgu([\u03c3]U , [x/t]U )) \u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t)))\n\u222a {occ(\u03c3, occ(\u03b4, v)) \u2229 U |\u2208 vars(x\u03c3 = t\u03c3)}, U ] ,\nwhere \u03b4 = mgu(x\u03c3 = t\u03c3). Since x \u2208\n/ vars(\u03c3), we have that x\u03c3 = t\u03c3 is equal to\nx = t\u03c3. Moreover, x \u2208\n/ vars(t\u03c3) since x \u2208\n/ vars(t) and x \u2208\n/ vars(\u03c3) by hypothesis.\nThus \u03b4 = mgu(x = t\u03c3) = {x/t\u03c3}. It follows that vars(x\u03c3 = t\u03c3) = {x} \u222a vars(t\u03c3).\nTherefore, the following equalities hold:\n=\n=\n=\n=\n=\n\n{occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}\n{occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 {x} \u222a vars(t\u03c3)}\n{occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(t\u03c3)}\n{occ(\u03c3, {x, v}) \u2229 U | v \u2208 vars(t\u03c3)}\n{(occ(\u03c3, x) \u222a occ(\u03c3, v)) \u2229 U | v \u2208 vars(t\u03c3)}\n{({x} \u222a occ(\u03c3, v)) \u2229 U | v \u2208 vars(t\u03c3)}\n\n[since x \u2208 dom(\u03b4), occ(\u03b4, x) = \u2205]\n[since \u03b4 = {x/t\u03c3}]\n[since x \u2208\n/ vars(\u03c3)]\n\nMoreover, for each v \u2208 vars(t\u03c3), by Prop. B.2 it holds that occ(\u03c3, v) \u2229 U \u2208\nrel(S, t). Therefore, {({x}\u222aocc(\u03c3, v))\u2229U | v \u2208 vars(t\u03c3)} \u2286 bin({x}, rel(S, t)). Since\nx\u2208\n/ vars(\u03c3) and x \u2208 U , it follows that occ(\u03c3, x) = {x} and thus {x} \u2208 rel(S, x)\nbeing \u03b1Sh ([\u03c3]U ) \u2291Sh [S, U ]. As a consequence bin({x}, rel(S, t)) \u2286 bin(rel(S, x),\nrel(S, t)) from which it follows that \u03b1Sh ([mgu(Eq(\u03c3)\u222ax = t)]U ) \u2291Sh [(S\\(rel(S, x)\u222a\nrel(S, t))) \u222a bin(rel(S, x), rel(S, t)), U ].\nProposition B.5\nGiven s, t \u2208 Terms and W, Y \u2208 \u2118f (V) such that s and t unify, vars(s = t) \u2286 W and\nY \u2286 uvars(s = t), then \u03b4 = mgu(s = t) enjoys the following properties:\n1. \u2200v \u2208 vars(s). occ(\u03b4, v) \u2229 vars(s) 6= \u2205 \u21d2 occ(\u03b4, v) \u2229 vars(t) 6= \u2205 ,\n2. \u2200v \u2208 vars(s). occ(\u03b4, v) \u2229 vars(s) \u2287 {x1 , x2 } \u2227 x1 6= x2 \u21d2 occ(\u03b4, v) \u2229 Z 6= \u2205 .\nwhere Z = vars(t) \\ Y .\nProof\nWe prove the two points separately.\n1. If occ(\u03b4, v) \u2229 vars(s) 6= \u2205 then v \u2208\n/ dom(\u03b4) and therefore v \u2208 \u03b4(s). Since \u03b4 is\nan unifier for s and t, it should be v \u2208 \u03b4(t), and therefore there exists y \u2208 t\nsuch that y \u2208 occ(\u03b4, v).\n\n\fOptimality in goal-dependent analysis of Sharing\n\n57\n\n2. First of all, note that, given two terms s and t in a given signature \u03a3, the\nresult of mgu(s = t) does not change if we enlarge \u03a3 with a new constant\nsymbol. Therefore, assume without loss of generality that there is a constant\nsymbol a in the signature. The proof proceeds by contradiction.\nAssume that there exist x1 , x2 \u2208 vars(s), v \u2208 W such that x1 , x2 \u2208 occ(\u03b4, v)\nand occ(\u03b4, v) \u2229 Z = \u2205. Let \u03c3 = {x = a | x \u2208 W } and consider the substitution\n\u03b4 \u2032 = {z/(\u03b4(z))\u03c3 | z \u2208 Z}. Note that this is an idempotent substitution since it\nis ground. Now consider \u03b4 \u2032\u2032 = mgu(Eq(\u03b4) \u222a Eq(\u03b4 \u2032 )), which clearly exists and,\nby definition of \u03b4 \u2032 , is \u03b4 \u2032\u2032 = {x/a | x \u2208 vars(\u03b4(Z))} \u25e6 \u03b4. Therefore, occ(\u03b4 \u2032\u2032 , v) =\nocc(\u03b4, v) because v \u2208\n/ vars(\u03b4(Z)) being occ(\u03b4, v) \u2229 Z = \u2205.\nMoreover, \u03b4 \u2032\u2032 = mgu(Eq(\u03b4) \u222a Eq(\u03b4 \u2032 )) = mgu({s = t} \u222a Eq(\u03b4 \u2032 )) = mgu(s\u03b4 \u2032 =\nt\u03b4 \u2032 ) \u25e6 \u03b4 \u2032 = \u03b4 \u2032 \u228e mgu(s\u03b4 \u2032 = t\u03b4 \u2032 ). By definition of \u03b4 \u2032 , it holds that vars(t\u03b4 \u2032 ) \u2229\nZ = \u2205, and thus vars(t\u03b4 \u2032 ) \u2286 Y . From the definition of Y it follows that\nvars(t\u03b4 \u2032 ) \u2286 uvars(s = t), and thus vars(t\u03b4 \u2032 ) \u2286 uvars(s\u03b4 \u2032 = t\u03b4 \u2032 ), since rng(\u03b4 \u2032 ) =\n\u2205. Therefore the term t\u03b4 \u2032 is linear and independent from s\u03b4 \u2032 and occ(mgu(s\u03b4 \u2032 =\nt\u03b4 \u2032 ), v) = occ(mgu(s\u03b4 \u2032 = t\u03b4 \u2032 ) \u228e \u03b4 \u2032 , v) = occ(\u03b4, v).\nIf we apply the result for linear and independent terms, e.g., (King 2000,\nProp. 3.1), we obtain an absurd, since it is not possible that both x1 and x2\nare elements of occ(mgu(s\u03b4 \u2032 = t\u03b4 \u2032 ), v).\nThis concludes the proof.\nProposition B.6\nLet [\u03c3]U \u2208 ISubst \u223c , {x/t} \u2208 ISubst such that vars({x/t}) \u2286 U and \u03c3 and {x/t}\nunify. Given Y \u2286 vars(t) such that, for all y \u2208 Y , vars(\u03c3(y)) \u2286 uvars(x\u03c3 = t\u03c3), if\n\u03b1Sh ([\u03c3]U ) \u2291Sh [S, U ] then\n\u03b1Sh (mgu([\u03c3]U , [x/t]U )) \u2291Sh [(S \\ (rel(S, t) \u222a rel(S, x)))\n\u222a bin(rel(S, x), rel(S, Y )\u2217 ) \u222a bin(rel(S, x)\u2217 , rel(S, Z)\u2217 )\n\u222a bin(bin(rel(S, x)\u2217 , rel(S, Z)\u2217 ), rel(S, Y )\u2217 ), U ] ,\nwhere Z = vars(t) \\ Y .\nProof\nBy Prop. B.3, we have that\n\u03b1Sh (mgu([\u03c3]U , [x/t]U )) \u2291Sh [(S \\ (rel(S, x) \u222a rel(S, t)))\n\u222a {occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}, U ] ,\nwhere \u03b4 = mgu(x\u03c3 = t\u03c3). We show that\n{occ(\u03c3, occ(\u03b4, v)) \u2229 U | v \u2208 vars(x\u03c3 = t\u03c3)}\n\u2286 bin(rel(S, x), rel(S, Y )\u2217 ) \u222a bin(rel(S, x)\u2217 , rel(S, Z)\u2217 )\n\u222a bin(bin(rel(S, x)\u2217 , rel(S, Z)\u2217 ), rel(S, Y )\u2217 ) \u222a {\u2205} ,\nfrom which the thesis follows. The following equalities hold, for all v \u2208 vars(x\u03c3 =\n\n\f58\n\nG. Amato and F. Scozzari\n\nt\u03c3).\n=\n=\n\nocc(\u03c3, occ(\u03b4, v)) \u2229 U\nS\n{occ(\u03c3, w) \u2229 U | w \u2208 occ(\u03b4, v)}\nS\n{occ(\u03c3, w) \u2229 U | w \u2208 occ(\u03b4, v) \u2229 vars(x\u03c3)}\nS\n\u222a {occ(\u03c3, w) \u2229 U | w \u2208 occ(\u03b4, v) \u2229 vars(t\u03c3)}\n\n[[by partitioning the variables in occ(\u03b4, v) \u2286 vars(\u03b4) \u222a {v}]]\n\nBy applying Prop. B.5 (1) to the equation x\u03c3 = t\u03c3 we get occ(\u03b4, v) \u2229 vars(x\u03c3) 6= \u2205\niff occ(\u03b4, v) \u2229 vars(t\u03c3) 6= \u2205. Since the case occ(\u03b4, v) = \u2205 is trivial, it only remain to\nconsider the case occ(\u03b4, v) 6= \u2205 which implies occ(\u03b4, v) \u2229 vars(t\u03c3) 6= \u2205 =\n6 occ(\u03b4, v) \u2229\nS\nvars(x\u03c3). In the following, let A = {occ(\u03c3, w) \u2229 U | w \u2208 occ(\u03b4, v) \u2229 vars(x\u03c3)} and\nS\nB = {occ(\u03c3, w)\u2229U | w \u2208 occ(\u03b4, v)\u2229vars(t\u03c3)}. Note that, by Prop. B.2, occ(\u03c3, w)\u2229\nU \u2208 rel(S, {x}) if w \u2208 vars(x\u03c3) and x \u2208 U , which implies A \u2208 rel(S, {x})\u2217 . For the\nsame reason, B \u2208 rel(S, vars(t))\u2217 , i.e.,\nocc(\u03c3, occ(\u03b4, v)) \u2229 U \u2208 bin(rel(S, {x})\u2217 , rel(S, vars(t))\u2217 ) ,\nwhich is the standard result for abstract unification without considering freeness or\nlinearity. We can do better if we proceed by cases on occ(\u03b4, v) \u2229 vars(t\u03c3).\nocc(\u03b4, v) \u2229 vars(t\u03c3) \u2286 vars(\u03c3(Y )) Let Z \u2032 = vars(t\u03c3)\\vars(\u03c3(Y )) it follows that\nocc(\u03b4, v) \u2229 Z \u2032 = \u2205. Therefore, by Prop. B.5(2) applied to the terms x\u03c3 and t\u03c3,\nwe have that \u2204x1 , x2 \u2208 vars(x\u03c3) such that x1 , x2 \u2208 occ(\u03b4, v). Since occ(\u03b4, v) \u2229\nvars(x\u03c3) 6= \u2205, it follows that there exists x\u2032 \u2208 vars(x\u03c3) such that occ(\u03b4, v) \u2229\nvars(x\u03c3) = {x\u2032 }. This implies that A \u2208 rel(S, {x}). Moreover, by Prop. B.2\napplied to the set of variables Y , B \u2208 rel(S, Y )\u2217 and this proves\nocc(\u03c3, occ(\u03b4, v)) \u2229 U \u2208 bin(rel(S, {x}), rel(S, Y )\u2217 ) .\notherwise We are in the case that occ(\u03b4, v)\u2229vars(t\u03c3) * vars(\u03c3(Y )), i.e., occ(\u03b4, v)\u2229\nvars(\u03c3(Z)) 6= \u2205. Therefore, there exists w \u2208 occ(\u03b4, v) \u2229 vars(\u03c3(Z)) and using\nProp. B.2 we have that occ(\u03c3, w) \u2229 U \u2208 rel(S, Z). This implies that B \u2208 {B1 \u222a\n. . . Bn \u222a C1 \u222a . . . Cp | Bi \u2208 rel(S, Y ), n \u2265 0, Ci \u2208 rel(S, Z), p \u2265 1} = rel(S, Z)\u2217 \u222a\nbin(rel(S, Y )\u2217 , rel(S, Z)\u2217 ). As a final result we have that:\nocc(\u03c3, occ(\u03b4, v)) \u2229 U \u2208 bin(rel(S, {x})\u2217 , rel(S, Z)\u2217 \u222a bin(rel(S, Y )\u2217 , rel(S, Z)\u2217 ))\n= bin(rel(S, {x})\u2217 , rel(S, Z)\u2217 )\u222a\nbin(bin(rel(S, {x})\u2217 , rel(S, Z)\u2217 ), rel(S, Y )\u2217 ) ,\nwhich proves the theorem.\nLemma B.7\nLet [\u03c3]V \u2208 ISubst \u223c , \u03b8 \u2208 ISubst such that vars(\u03b8) \u2286 V and \u03c3 and \u03b8 unify. Assume\ngiven U \u2286 V such that, for each x \u2208 U ,\n1. x is free in [\u03c3]V ;\n2. x is independent from vars(\u03b8) in [\u03c3]V ;\n3. if x \u2208 dom(\u03b8) then x is independent in [\u03c3]V .\nIf \u03b1Sh ([\u03c3]V ) \u2291Sh [S, V ] then \u03b1Sh (mgu([\u03c3]V , [\u03b8]V )) \u2291Sh [ufSh (S, U, \u03b8), V ].\n\n\fOptimality in goal-dependent analysis of Sharing\n\n59\n\nProof\nThe proof is by induction on |dom(\u03b8)|. Assume |dom(\u03b8)| = 0, then \u03b8 = \u01eb and\n\u03b1Sh (mgu([\u03c3]V , [\u01eb]V )) = \u03b1Sh ([\u03c3]V ) \u2291Sh [S, V ] = [ufSh (S, U, \u01eb), V ].\nNow assume that it holds for |dom(\u03b8)| \u2264 n and we show it holds for |dom(\u03b8)| =\nn + 1, too. Let \u03b8 be \u03b8\u2032 \u228e {x/t}. We distinguish two cases: either x \u2208 U or x \u2208\n/ U.\n1. (x \u2208 U ) By definition of ufSh we have that\nufSh (S, U, {x/t} \u228e \u03b8\u2032 )\n= ufSh ((S \\ (rel(S, x) \u222a rel(S, t))) \u222a bin(rel(S, x), rel(S, t)), U \\ {x}, \u03b8\u2032 ) .\nSince x \u2208 U \u2229 dom(\u03b8), by hypothesis x is free and independent in [\u03c3]V . Thus\nwe can apply Prop. B.4, from which we obtain that:\n\u03b1Sh (mgu([\u03c3]V , [x/t]V ))\n\u2291Sh [S \\ (rel(S, x) \u222a rel(S, t)) \u222a bin(rel(S, x), rel(S, t)), V ] .\n\u2032\n\nLet [\u03c3 ]V = mgu([\u03c3]V , [x/t]V ) and U \u2032 = U \\ {x}. We may assume without\nloss of generality that vars(\u03c3) \u2229 U = \u2205 and we obtain \u03c3 \u2032 = mgu(Eq(\u03c3) \u222a {x =\nt}) = \u03c3 \u228e{x/t\u03c3}. Given u \u2208 U \u2032 , we have \u03c3 \u2032 (u) = \u03c3(u) = u \u2208 V, hence u is free\nin [\u03c3]V . If u 6= v \u2208 vars(\u03b8\u2032 ), then v 6= x and therefore u \u2208\n/ \u03c3 \u2032 (v) = \u03c3(v). Thus\n\u2032\n\u2032\nu is independent from vars(\u03b8 ) in [\u03c3 ]V . Moreover, if u \u2208 dom(\u03b8\u2032 ), then u 6= x,\nu\u2208\n/ t and u \u2208\n/ vars(\u03c3), and therefore u \u2208\n/ vars(\u03c3 \u2032 ) \u2286 vars(\u03c3) \u222a vars(x = t).\n\u2032\nThis means that u is independent in [\u03c3 ]U . Therefore, by inductive hypothesis,\n\u03b1Sh (mgu([\u03c3]V , [\u03b8]V )) = \u03b1Sh (mgu([\u03c3 \u2032 ]V , [\u03b8\u2032 ]V ))\n\u2291Sh [ufSh (S \u2032 , U \u2032 , \u03b8\u2032 ), V ] = [ufSh (S, U, \u03b8), V ] ,\nwhich concludes this part of the proof.\n2. (x \u2208\n/ U ) By definition of ufSh we have that:\nufSh (S, U,{x/t} \u228e \u03b8) = ufSh ((S \\ (rel(S, x) \u222a rel(S, t)))\n\u222a bin(rel(S, x), rel(S, Y )\u2217 ) \u222a bin(rel(S, x)\u2217 , rel(S, Z)\u2217 )\n\u222a bin(bin(rel(S, x)\u2217 , rel(S, Y )\u2217 ), rel(S, Z)\u2217 )), U \\ vars({x/t}), \u03b4) ,\nwhere Y = uvars(t) \u2229 U and Z = vars(t) \\ Y . Since Y \u2286 U , then for all u \u2208 Y\nand for all v \u2208 vars(x = t) with v 6= u, it is the case that v and u do not share\nvariables, i.e., v 6= u \u21d2 \u03c3(u) \u2208\n/ \u03c3(v). Therefore \u03c3(u) \u2208 uvars(x\u03c3 = t\u03c3). Then\nwe can apply Prop. B.6 to obtain\n\u03b1Sh ([\u03c3]V , [x/t]V ]) \u2291Sh (S \\ (rel(S, t) \u222a rel(S, x)))\n\u222a bin(rel(S, x), rel(S, Y )\u2217 ) \u222a bin(rel(S, x)\u2217 , rel(S, Z)\u2217 )\n\u222a bin(bin(rel(S, x)\u2217 , rel(S, Z)\u2217 ), rel(S, Y )\u2217 ), V ] .\nAgain, assume vars(\u03c3) \u2229 U = \u2205, \u03c3 \u2032 = mgu(Eq(\u03c3) \u222a {x = t}) = mgu(x\u03c3 =\nt\u03c3) \u25e6 \u03c3 and U \u2032 = U \\ vars({x/t}). Given u \u2208 U \u2032 , u \u2208\n/ vars(x = t) and\nsince u by hypothesis does not share with any variable in x = t, we have\nu \u2208\n/ vars({x\u03c3/t\u03c3}). As a result \u03c3 \u2032 (u) = \u03c3(u) = u \u2208 V. Moreover, for each\nvariable v, u \u2208 \u03c3 \u2032 (v) iff u \u2208 \u03c3(v). Therefore, if v \u2208 vars(\u03b8\u2032 ) and v 6= u, v and\n\n\f60\n\nG. Amato and F. Scozzari\nu are independent in [\u03c3 \u2032 ]V . Finally, if u \u2208 dom(\u03b8\u2032 ), then u \u2208\n/ vars(\u03c3) which\n\u2032\nimplies u \u2208\n/ vars(\u03c3 ). By inductive hypothesis we have\n\u03b1Sh (mgu([\u03c3]V , [\u03b8]V )) = \u03b1Sh (mgu([\u03c3 \u2032 ]V , [\u03b8\u2032 ]V ))\n\u2291Sh [ufSh (S \u2032 , U \u2032 , \u03b8\u2032 ), V ] = [ufSh (S, U, \u03b8), V ] ,\nwhich proves the lemma.\n\nTheorem B.8\n(Correctness of unif Sh ) The unification operator unif Sh is correct w.r.t. unif Ps .\nProof\nGiven [\u2206, V ] = unif Ps ([\u22061 , V1 ], \u03b4), we know that, if [\u03b8]V \u2208 \u2206, then\n[\u03b8]V = mgu([\u03b81 ]V1 , [\u03b4]vars(\u03b4) ) = mgu([\u03b81 ]V1 , [\u01eb]V1 \u222avars(\u03b4) , [\u03b4]vars(\u03b4) ) .\nNote that, if \u03b1Sh ([\u03b81 ]V1 ) \u2291Sh [S, V1 ], then\n\u03b1Sh (mgu([\u03b81 ]V1 , [\u01eb]V1 \u222avars(\u03b4) )) \u2291Sh [S \u222a {{x} | x \u2208 vars(\u03b4) \\ V1 }, V1 \u222a vars(\u03b4)]\nand each variable in vars(\u03b4) \\ V1 is free and independent in mgu([\u03b81 ]V1 , [\u01eb]V1 \u222avars(\u03b4) ).\nTherefore, by applying Lemma B.7, we obtain\n\u03b1Sh ([\u03b8]V ) \u2291Sh unif Sh ([S, V1 ], \u03b4) .\nThe theorem follows by the pointwise extension of \u03b1Sh to elements of Psub.\nC Optimality of Forward Unification\nWe first introduce some notations. Given [S1 , U1 ] \u2208 Sharing and \u03b8 \u2208 ISubst, let\nunif Sh ([S1 , U1 ], \u03b8) = [S, U1 \u222a vars(\u03b8)] and X \u2208 S. To ease notation, let us define\nU2 = vars(\u03b8) \\ U1 , S2 = {{x} | x \u2208 U2 }, U = U1 \u222a U2 , X1 = X \u2229 U1 and\nX2 = X \u2229 U 2 .\nWe begin by checking some properties of the unification algorithm in ufSh . To\nsimplify the notation, in the rest of this section we will use a slightly modified\nversion of the operator ufSh which uses the rule ufSh (T, V, \u01eb) = (T, V ) (instead of\nthe original rule ufSh (T, V, \u01eb) = T ). The only consequence of this modification is\nthat the new operator returns a pair whose first argument is the same as in the\noriginal operator and whose second argument is a set of variables guaranteed to be\nfree after the unification.\nRemark C.1\nGiven (T \u2032 , V \u2032 ) = ufSh (T, V, \u03b8) the following properties are easily checked from the\ndefinition:\n1. V \u2032 \u2286 V ;\n2. if x \u2208 V \u2032 \u2229 rng(\u03b8) and x \u2208 \u03b8(v), then v \u2208 V .\n3. ufSh (T, V, \u03b8 \u228e \u03b8\u2032 ) = ufSh (T \u2032 , V \u2032 , \u03b8\u2032 )\nLet [H, U ] = \u03b1Sh ([\u03b8]U ). We want to prove that each X \u2208 S is obtained as union\nof a number of sharing groups in H. However, these sharing groups cannot be joined\nfreely but only according to some conditions.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n61\n\nLemma C.2\nFor each X \u2208 S, either X \u2208 H or there are B1 , . . . , Bk \u2208 H s.t. \u222ai\u2264k Bi = X and\nfor each i \u2264 k, Bi \u2229 U1 6= \u2205.\nProof\nThe proof proceeds by induction on the number of bindings n in \u03b8. If n = 0, then\n\u03b8 = \u01eb, S = S1 \u222a S2 and H = {{x} | x \u2208 U1 \u222a U2 }. If X \u2208 S2 then X = {x} for\nS\nsome x \u2208 U2 , i.e., X \u2208 H. Otherwise, if X \u2208 S1 , then X = {{x} | x \u2208 X}. Since\nx \u2208 vars(S1 ) entails x \u2208 U1 , we may take as Bi 's the singletons {x} for each x \u2208 X\nand we have the required result.\nIf n 6= 0 then \u03b8 = \u03b8\u2032 \u228e {x/t} and ufSh (S1 \u222a S2 , U2 , \u03b8) = ufSh (T, V, {x/t}) where\n(T, V ) = ufSh (S1 \u222a S2 , U2 , \u03b8\u2032 ). Let [H \u2032 , U ] = \u03b1Sh ([\u03b8\u2032 ]U ). We distinguish the cases\nx \u2208 V and x \u2208\n/ V.\nAssume x \u2208 V . If X \u2208 T \\ (rel(T, t) \u222a rel(T, x)) then X \u2229 vars({x/t}) = \u2205.\nBy inductive hypothesis, X = B1 \u222a . . . \u222a Bh where each Bj \u2208 H \u2032 . Since Bj \u2229\nvars({x/t}) = \u2205, we have Bj \u2208 H and therefore the property is satisfied. Otherwise,\nX = A1 \u222a A2 where A1 \u2208 rel(T, x) and A2 \u2208 rel(T, t). Note that since x \u2208\n/ vars(\u03b8\u2032 ),\nthen rel(H \u2032 , x) = {{x}}. Since {x} \u2229 U1 = \u2205, it is not possible to join {x} with any\nother sharing group in H \u2032 , and therefore rel(T, x) = {{x}} and A1 = {x}. Now\nassume, without loss of generality, A2 \u2208 rel(T, y), with y \u2208 vars(t). By inductive\nhypothesis A2 = C1 \u222a . . . \u222a Ch with each Cj \u2208 H \u2032 . First of all, note that, for each\nj, either Cj \u2229 vars({x/t}) = \u2205 which entails Cj \u2208 H, or Cj = occ(\u03b8\u2032 , w) for some\nw \u2208 vars(t), which entails {x} \u222a Cj = occ(\u03b8, w) \u2208 H. Therefore, it is possible to\ntake k = h and Bj equals either to Cj or Cj \u222a {x} so that Bj \u2208 H. Since there is\nat least one index l such that y \u2208 Cl , then Cl = occ(\u03b8\u2032 , y) and x \u2208 Bl . Therefore\n\u222aj Bj = X. Moreover, either h = 1 or h > 1 and Cj \u2229 U1 6= \u2205 for each j \u2264 h.\nNow assume x \u2208\n/ V . If X \u2208 T \\ (rel(T, t) \u222a rel(T, x)) then X \u2229 vars({x/t}) = \u2205\nand everything is as for the case x \u2208 V . Otherwise, the three cases in the definition\nof ufSh may be subsumed saying that X = A1 \u222a A2 where A1 \u2208 rel(S, x)\u2217 and\nA2 \u2208 rel(S, t)\u2217 . Assume, by inductive hypothesis, that A1 = C11 \u222a . . . \u222a Ch1 where\n/ vars(\u03b8\u2032 )\neach Cj1 \u2208 H \u2032 and A2 = C12 \u222a . . . \u222a Cl2 where each Cj2 \u2208 H \u2032 . Since x \u2208\n\u2032\n1\n1\nthen rel(H , x) = {{x}}. Therefore there exists Cj such that Cj = {x}. We assume\nwithout loss of generality that C11 = {x}. As for the case with x \u2208 V , we may\ndefine Bj2 equals to either Cj2 or Cj2 \u222a {x} so that Bj2 \u2208 H. The same holds for\nall the elements of the kind Cj1 for j > 1. Moreover, there is at least one j such\nthat Cj2 = occ(\u03b8\u2032 , y) for some y \u2208 vars(t), i.e., such that x \u2208 Bj2 . Then, we have\na collection of elements Bj1 and Bj2 such that each Bj1 , Bj2 \u2208 H and whose union\ngives X. We only need to prove that Bj1 \u2229 U1 6= \u2205 and Bj2 \u2229 U1 6= \u2205 for each j.\nNote that if Cj2 \u2229 U1 6= \u2205, then Bj2 \u2229 U1 6= \u2205. Assume Cj2 \u2229 U1 = \u2205. By inductive\nhypothesis, this happens if Cj2 \u2208 rel(S, t) (otherwise Cj2 is obtained by joining\nmore than one element in H \u2032 , and therefore it must contains some variable in U1 )\n. Thus, there exists y \u2208 vars(t) such that y \u2208 Cj2 , and therefore Bj2 = Cj2 \u222a {x} and\nBj2 \u2229 U1 6= \u2205. In the same way, if Cj1 \u2229 U1 6= \u2205 the same holds for Bj1 . Note that,\ngiven Cj1 , by inductive hypothesis either Cj1 \u2208\n/ rel(S, x) and therefore Cj1 \u2229 U1 6= \u2205,\n1\n1\nor Cj \u2208 rel(S, x), and therefore x \u2208 Cj which entails again Cj1 \u2229 U1 6= \u2205.\n\n\f62\n\nG. Amato and F. Scozzari\n\nCorollary C.3\nX = {x | vars(\u03b8(x)) \u2229 X 6= \u2205}.\nProof\nBy Lemma C.2 we know X = B1 \u222a * * * \u222a BN with Bi \u2208 H. If x \u2208 X then x \u2208 Bi for\nsome i \u2264 N . Assume Bi = occ(\u03b8, w). Then w \u2208 Bi \u2286 X and w \u2208 vars(\u03b8(x)) \u2229 X. In\nthe opposite direction, assume z \u2208 vars(\u03b8(x)) \u2229 X. Since there is only one sharing\ngroup B in H such that z \u2208 B, namely B = occ(\u03b8, z), it must be the case that\nB = Bj for some j \u2208 {1, . . . , N } and therefore x \u2208 Bj \u2286 X.\nLemma C.4\nFor each X \u2208 S, X is \u03b8-connected.\nProof\nFirst note that, if X is \u03b8-connected and Y \u2286 U2 , then given \u03b8\u2032 = \u03b8 \u228e \u03b8\u2032\u2032 , it holds\nthat X \u222a Y is \u03b8\u2032 -connected.\nThe proof is by induction on the number of bindings in \u03b8. If \u03b8 = \u01eb there is nothing\nto prove since X \u2208 S1 \u222a S2 , and thus X1 \u2208 S1 .\nLet \u03b8 = \u03b8\u2032 \u228e {x/t}, [H \u2032 , U ] = \u03b1Sh ([\u03b8\u2032 ]U ), and (S, V \u2032 ) = ufSh (T, V, {x/t}) where\nf\nuSh (S1 \u222a S2 , U2 , \u03b8\u2032 ) = (T, V ).\nWe distinguish two cases according to the fact that x \u2208 V or not. Consider the\ncase x \u2208 V , which implies x \u2208 U2 . By hypothesis x \u2208\n/ vars(\u03b8\u2032 ) therefore, by Lemma\nC.2, rel(T, x) = {{x}}. Therefore S is obtained by joining to each Q \u2208 rel(T, t) the\nnew sharing group {x} and removing {x} from T . It happens that each Q \u2208 S is\n\u03b8-connected since: 1) either Q \u2208 T ; 2) or Q = Q\u2032 \u222a {x} for Q\u2032 \u2208 T and x \u2208 U2 . In\nthe first case, Q is \u03b8\u2032 -connected by inductive hypothesis, hence it is also \u03b8 connected\nand the thesis follows. In the latter case, Q\u2032 is \u03b8\u2032 -connected, and thus Q\u2032 \u222a {x} is\n\u03b8-connected since x \u2208 U2 .\nThe other case is when x \u2208\n/ V . If we take Q \u2208 S and assume Q \u2208 T \\ (rel(T, x) \u222a\nrel(T, t)), then it is \u03b8\u2032 -connected by inductive hypothesis, and thus it is \u03b8-connected.\nOtherwise, take Q = Q1 \u222a Q2 with Q1 \u2208 rel(T, x) and Q2 \u2208 rel(T, Y )\u2217 where\nY = uvars(t) \u2229 V . Given y \u2208 Y , since y \u2208 V , then for each binding x\u2032 /t\u2032 in \u03b8\u2032 ,\nif y \u2208 vars(t\u2032 ) then x\u2032 \u2208 U2 (see Remark C.1). Therefore rel(H, y) = {K} with\nK \u2286 U2 , and by Lemma C.2, the same holds for rel(T, y). This means Q2 \u2286 U2 .\nThus Q \u2229 U1 = Q1 \u2229 U1 . Since Q1 is \u03b8\u2032 -connected by inductive hypothesis, it follows\nthat Q1 is \u03b8-connected.\nNow, take Q1 \u2208 rel(T, x)\u2217 and Q2 \u2208 rel(T, Z)\u2217 , where Z = vars(t)\\Y . Thus Q1 =\nA1 \u222a . . . \u222a Ak with Ai \u2208 rel(T, x). By inductive hypothesis, Ai is \u03b8\u2032 -connected, and\ntherefore it is \u03b8-connected. It follows that for each i \u2264 k there exist B1i , . . . , Bki i \u2208 S1\nsuch that \u222aj\u2264ki Bji = Ai \u2229 U1 and Bji1 R\u2217\u03b8Ai Bji2 for j1 , j2 \u2264 ki . The same holds\nfor Q2 = C1 \u222a . . . \u222a Ch with Ci \u2208 rel(T, Z): for any Ci \u2229 U1 6= \u2205 we have that\nCi \u2229 U1 = \u222aj\u2264hi Dji with Dji1 R\u2217\u03b8Ci Dji2 for all j1 , j2 \u2264 hi .\ni\ni\nWe need to show that given any Bm\n, Dnj then Bm\nR\u2217\u03b8Q Dnj . Actually, it is enough to\ni\nshow that for each i \u2264 k, j \u2264 h such that Cj \u2229U1 6= \u2205, there are m, n s.t. Bm\nR\u03b8Q Dnj .\nSince x \u2208 Ai and x \u2208 U1 , without loss of generality we may assume that x \u2208 B1i .\n\n\fOptimality in goal-dependent analysis of Sharing\n\n63\n\nIn the other hand, although vars(t) \u2229 Cj 6= \u2205, we cannot infer that there exists any\nDnj s.t. vars(t) \u2229 Dnj 6= \u2205 since it may well happen that vars(t) \u2229 Cj \u2286 U2 although\nU1 \u2229 Cj 6= \u2205.\nAssume Cj \u2208 rel(T, z) for some z \u2208 Z \u2229 U1 . Then, we may assume without loss\nof generality that z \u2208 D1j , and B1i R\u03b8Q D1j follows from the definition of R\u03b8Q , being\nz \u2208 Q. Otherwise, Cj \u2208 rel(T, z) for some z \u2208 Z \u2229 U2 . By applying Lemma C.2, we\nhave Cj = E1 \u222a * * * \u222a Ep with Ei \u2208 H \u2032 and Ei \u2229 U1 6= \u2205 (this holds even if p = 1\nsince Cj \u2229 U1 6= \u2205). Since rel(H \u2032 , z) = {occ(\u03b8\u2032 , z)}, then occ(\u03b8\u2032 , z) \u2229 U1 6= \u2205, i.e.,\nthere exists z \u2032 \u2208 U1 such that z \u2208 vars(\u03b8\u2032 (z \u2032 )). Then z \u2032 \u2208 Cj and we may assume,\nwithout loss of generality, that z \u2032 \u2208 D1j . Again, we have B1i R\u03b8Q D1j by definition of\nR\u03b8Q .\nObserve that, if Q2 \u2229U1 6= \u2205, by symmetry and transitivity, this alone proves that\nj\u2032\ni\ni\u2032\nj \u2217\n\u2032\n\u2032\n\u2032\n\u2032\nBm\nR\u2217\u03b8X Bm\n\u2032 and Dn R\u03b8Q Dn\u2032 for each i, m, i , m and j, n, j , n . Otherwise, there is\n\u2032\ni\ni\nno Dnj and we need to prove in other ways that Bm\nR\u2217\u03b8Q Bm\n\u2032 . Since Q2 \u2229 U1 = \u2205,\n\u2032\nthen Ci \u2286 U2 for each i. This means Ci = occ(\u03b8 , y) for some y \u2208 U2 and since\nCi \u2286 U2 it follows immediately that y \u2208 V . Then, since y \u2208 Z, it must be the case\n\u2032\nthat y \u2208\n/ uvars(t) and therefore B1i R\u03b8Q B1i by definition of R\u03b8Q .\nIt remains the case Q = Q1 \u222a Q2 \u222a Q3 with Q1 \u2208 rel(T, x)\u2217 , Q2 \u2208 rel(T, Y )\u2217 and\nQ3 \u2208 rel(T, Z)\u2217 . However, this is a trivial corollary of the previous two cases, since\nwe know that Q1 \u222a Q3 is \u03b8-connected and Q2 \u2286 U2 .\nFixed X \u2208 S, our aim is to provide a substitution \u03b4 with \u03b1Sh ([\u03b4]U1 ) \u2291 [S1 , U1 ] and\n\u03b1Sh (mgu([\u03b4]U1 , [\u03b8]U )) \u2292 [{X}, U ]. By Lemma C.4, X1 = B1 \u222a . . . \u222a Bn with Bi \u2208 S1\nand Bi R\u2217\u03b8X Bj for each i, j \u2264 n (where X1 = X \u2229 U1 ). We let K1 = {B1 , . . . , Bn }.\nWe now want to define a substitution \u03b4 such that \u03b1Sh ([\u03b4]U1 ) = [K1 , U1 ]. For each\nsharing group B \u2208 K1 , let us consider a fresh variable wB . Let W = {wB | B \u2208 K1 }.\nFor each variable x, let Bx = {Bx1 , . . . , Bxk } be the set rel(K1 , x). Let N be the\nmaximum cardinality of all the Bx for x \u2208 X1 i.e., N = maxx\u2208X1 |Bx |. For each\nx \u2208 X1 , we define two terms:\nsx = t(c(wBx1 , wBx1 ), c(wBx2 , wBx2 ), . . . , c(wBxk , wBxk ), c(wBx1 , wBx1 ), . . . , c(wBx1 , wBx1 ))\n{z\n}\n{z\n} |\n|\nN \u2212 |Bx | times\n\nk = |Bx | times\n\ns\u2032x\n\n= t(c(wBx1 , wBx2 ), c(wBx2 , wBx3 ), . . . , c(wBxk , wBx1 ), c(wBx1 , wBx1 ), . . . , c(wBx1 , wBx1 ))\n{z\n}\n|\n{z\n} |\nN \u2212 |Bx | times\n\nk = |Bx | times\n\nsx , s\u2032x\n\nNote that if N = 0 then X1 = \u2205 and\nare undefined for any variable x.\nWe introduce the following notation: given a term t we distinguish different occurrences of the same variable by calling (y, n) the n-th occurrence of a variable y\nin t, where the order is lexicographic. For instance, a term f (x, g(y, y, x)) can be\nseen as the term f ((x, 1), g((y, 1), (y, 2), (x, 2))). For each y \u2208 vars(\u03b8(U1 )) \u2229 X, we\nchoose a variable xy \u2208 U1 such that y \u2208 \u03b8(xy ). Let a be a constant. We are now\nready to define the substitution \u03b4 in the following way: for each variable x \u2208 U1 ,\n\u03b4(x) is the same as \u03b8(x) with the difference that each occurrence (y, i) of a variable\ny \u2208 \u03b8(x) is replaced by tx,y,i defined as\n\u2022 tx,y,i = a if y \u2208\n/ X, else\n\n\f64\n\nG. Amato and F. Scozzari\n\u2022 tx,y,i = sx if x = xy and i = 1;\n\u2022 tx,y,i = s\u2032x otherwise.\n\nNote that, by Corollary C.3, if x \u2208 X1 , then \u03b8(x) is not ground. Therefore, by\nconstruction, dom(\u03b4) = U1 and rng(\u03b4) = W . It is easy to check that \u03b1Sh ([\u03b4]U1 ) =\n[K1 , U1 ] since given a variable wB , it appears in \u03b4(x) iff x \u2208 B and therefore\nocc(\u03b4, wB )\u2229U1 = B. For all the other variables occ(\u03b4, v) = \u2205 if v \u2208 U1 and occ(\u03b4, v) =\n{v} 6\u2286 U1 otherwise. Let us compute the value of mgu([\u03b4]U1 , [\u03b8]U ).\nLemma C.5\nmgu(\u03b4, \u03b8) = mgu{w1 = w2 | w1 , w2 \u2208 W } \u25e6 \u03c1 \u25e6 \u03b8\nwhere \u03c1 = {v/sxv | v \u2208 vars(\u03b8(U1 )) \u2229 X} \u222a {v/a | v \u2208 vars(\u03b8(U1 )) \\ X}.\nProof\nSince txv ,v,1 = sxv , by using the properties of equation sets it follows that:\nmgu(\u03b4, \u03b8) =\n=\n\nmgu({v = tx,v,i | x \u2208 U1 , (v, i) is an occurrence of v in \u03b8(x)}) \u25e6 \u03b8\nmgu(E) \u25e6 \u03c1 \u25e6 \u03b8 .\n\nwhere E = {txv ,v,1 = tx\u2032 ,v,j | x\u2032 \u2208 U1 , (v, j) is an occurrence of v in \u03b8(x\u2032 )}. Let us\ndefine a relation between variables:\nvR\u2032 u \u21d0\u21d2 \u2203y \u2208 vars(\u03b8(v)) \u2229 X. u = xy \u2227 (u = v \u21d2 y \u2208\n/ uvars(\u03b8(v)))} .\nNote that R\u2032 is not a symmetric relationship. Moreover, it depends from \u03b8 and X,\njust as R\u03b8X . However, since in this proof \u03b8 and X are fixed, we decided to omit the\nindexes in order to simplify notation. By exploiting the above definition, we can\nrewrite mgu(E) as follows:\nmgu(E) = mgu({s\u2032v = su | v, u \u2208 X1 , vR\u2032 u}) .\n\n(C1)\n\nThe above characterization shows that Eq(\u03b4) \u222a Eq(\u03b8) is solvable, since su and s\u2032v\nare terms which unify by construction. Moreover, note that\nmgu{su = s\u2032v } = mgu{wB = wB \u2032 | B \u2208 Bu \u2227 B \u2032 \u2208 Bv } .\nWe want to prove that mgu{s\u2032v = su | v, u \u2208 X1 , vR\u2032 u} = mgu{w1 = w2 | w1 , w2 \u2208\nW }. It is obvious that mgu{s\u2032v = su | v, u \u2208 X1 , vR\u2032 u} = mgu{wB = wB \u2032 | v, u \u2208\nX1 . B \u2208 Bv , B \u2032 \u2208 Bu , vR\u2032 u} = mgu{wB = wB \u2032 | B R\u0302B \u2032 } where R\u0302 is the relation\non K1 \u00d7 K1 given by\nB R\u0302B \u2032 \u21d0\u21d2 \u2203x, y \u2208 X1 . B \u2208 Bx \u2227 B \u2032 \u2208 By \u2227 xR\u2032 y .\nSince equality is transitive and reflexive, we know that\nmgu{wB = wB \u2032 | B R\u0302B \u2032 } = mgu{wB = wB \u2032 | B R\u0302\u2217 B \u2032 } ,\nwhere R\u0302\u2217 is the symmetric and transitive closure of R\u0302. We now prove that R\u0302 \u2286\nR\u03b8X \u2286 R\u0302\u2217 , from which the thesis follows by Lemma C.4.\nIf B R\u0302B \u2032 there are x, y \u2208 X1 s.t. B \u2208 Bx \u2227 B \u2032 \u2208 By \u2227 xR\u2032 y. However B \u2208 Bx iff\n\n\fOptimality in goal-dependent analysis of Sharing\n\n65\n\nx \u2208 B \u2208 S1 and B \u2032 \u2208 By iff y \u2208 B \u2032 \u2208 S1 . Now, assume z \u2208 vars(\u03b8(x)) \u2229 X and y =\nxz . Then z \u2208 vars(\u03b8(x))\u2229vars(\u03b8(y))\u2229X and this proves that BR\u03b8X B \u2032 . On the other\nside, assume BR\u03b8X B \u2032 , i.e., there are x \u2208 B, y \u2208 B \u2032 , z \u2208 vars(\u03b8(x)) \u2229 vars(\u03b8(y)) \u2229 X\ns.t. x = y =\u21d2 z \u2208\n/ uvars(\u03b8(x)). Since x \u2208 B and y \u2208 B \u2032 , then B \u2208 Bx and\n\u2032\nB \u2208 By . Since z \u2208 vars(\u03b8(U1 )) \u2229 X then xz is defined and Bxz 6= \u2205. Assume that\nx = y = xz . Then z 6\u2208 uvars(\u03b8(x)) and thus xR\u2032 y and B R\u0302B \u2032 . Otherwise, we may\nassume without loss of generality that x 6= xz . If y = xz then xR\u2032 y and thus B R\u0302B \u2032 .\nIf y 6= xz we can choose any B \u2032\u2032 \u2208 Bxz . We know that xR\u2032 xz , yR\u2032 xz and thus it\nholds that B R\u0302B \u2032\u2032 and B \u2032 R\u0302B \u2032\u2032 , from which B R\u0302\u2217 B \u2032 follows. The case y 6= xz is\nsymmetric.\nProposition C.6\n\u03b1Sh (mgu([\u03b4]U1 , [\u03b8]U )) \u2292Sh [{X}, U ] .\nProof\nFirst of all, note that mgu([\u03b4]U1 , [\u03b8]U ) = [mgu(\u03b4, \u03b8)]U since vars(\u03b8) \u2286 U . We proceed\nwith two different proofs when W = \u2205 and W 6= \u2205. If W 6= \u2205 then, according to\nLemma C.5, we can choose w\u0304 \u2208 W and define the substitution \u03c3 = {w\u2032 /w\u0304 | w\u0304 6=\nw\u2032 \u2208 W } = mgu(E). It only remains to prove that occ(\u03c3 \u25e6 \u03c1 \u25e6 \u03b8, w\u0304) \u2229 U = X.\nIt follows easily that occ(\u03c3 \u25e6 \u03c1 \u25e6 \u03b8, w\u0304) = occ(\u03c1 \u25e6 \u03b8, W ) = occ(\u03b8, vars(\u03b8(U1 )) \u2229 X) \u222a\nW ) = occ(\u03b8, vars(\u03b8(U1 )) \u2229 X) \u222a W . Since U \u2229 W = \u2205 it follows that occ(\u03c3 \u25e6 \u03c1 \u25e6\n\u03b8, w\u0304) \u2229 U = occ(\u03b8, vars(\u03b8(U1 )) \u2229 X).\nBy definition, occ(\u03b8, vars(\u03b8(U1 )) \u2229 X) = {y | vars(\u03b8(y)) \u2229 vars(\u03b8(U1 )) \u2229 X 6= \u2205}.\nThus, for any of such y, we have that vars(\u03b8(y))\u2229X 6= \u2205 and thus, by Corollary C.3,\ny \u2208 X. It follows that occ(\u03b8, vars(\u03b8(U1 )) \u2229 X) \u2286 X. For the opposite direction, by\nLemma C.2 there exist B1 , . . . , Bk \u2208 H such that \u222aBi = X and Bi \u2229 U1 6= \u2205 for\neach i. Since Bi \u2208 H, then there exists v s.t. Bi = occ(\u03b8, v). Moreover, v \u2208 X since\nv \u2208 Bi by definition of occ and \u03b8(v) = v. Since Bi \u2229 U1 6= \u2205 it follows that there\nexists y \u2208 Bi \u2229U1 such that v \u2208 \u03b8(y) \u2286 \u03b8(U1 ) and thus Bi \u2286 occ(\u03b8, vars(\u03b8(U1 ))\u2229X).\nThus X \u2286 occ(\u03b8, vars(\u03b8(U1 )) \u2229 X).\nWhen W = \u2205, mgu(E) = \u01eb and X = X2 . In this case, by Lemma C.2, X2 =\nocc(\u03b8, x) for some x \u2208 U2 . Since X2 \u2229 U1 = \u2205, then x \u2208\n/ vars(\u03b8(U1 )), i.e., x \u2208\n/ dom(\u03c1)\nand therefore occ(\u03c1 \u25e6 \u03b8, x) = occ(\u03b8, x) = X2 .\nNote that, in this proof, we worked with a signature endowed with a constant\na and term symbols c and t of arity two and N respectively. Actually, it is evident that the proof may be easily rewritten for the case when the signature has\na constant and a symbol of arity at least two. Given s of arity n, we may replace\nin \u03b4 a term t(t1 , . . . , tN ) with c(t1 , c(t2 , c(. . . , tN ))). Then, we replace c(t1 , t2 ) with\ns(t1 , t2 , a, a, . . . , a) where a is repeated n \u2212 2 times.\nTheorem C.7\nUfSh is well defined, correct and optimal w.r.t. UfPs .\n\n\f66\n\nG. Amato and F. Scozzari\n\nProof\nBy Equation (31), we need to prove that:\n\u03c0Sh (unif Sh (\u03c1([S1 , U1 ]), mgu(\u03c1(A1 ) = A2 )), vars(A2 )) =\n\u03b1Sh (\u03c0Ps (unif Ps (\u03c1(\u03b3Ps ([S1 , U1 ])), mgu(\u03c1(A1 ) = A2 )), vars(A2 ))) .\nBy Theorems 5.3 and 5.4, we know that \u03c0Sh is correct and complete and that\nabstract renaming is correct and \u03b3-complete. Moreover, by Theorem 6.16, abstract\nunification unif Sh is optimal. We have the following equalities.\n\u03b1Sh (\u03c0Ps (unif Ps (\u03c1(\u03b3Ps ([S1 , U1 ])), mgu(\u03c1(A1 ) = A2 )), vars(A2 )))\n= \u03c0Sh (\u03b1Sh (unif Ps (\u03c1(\u03b3Ps ([S1 , U1 ])), mgu(\u03c1(A1 ) = A2 )), vars(A2 ))) [by Th. 5.3]\n= \u03c0Sh (\u03b1Sh (unif Ps (\u03b3Ps (\u03c1([S1 , U1 ])), mgu(\u03c1(A1 ) = A2 ))), vars(A2 )) [by Th. 5.4]\n= \u03c0Sh (unif Sh (\u03c1([S1 , U1 ]), mgu(\u03c1(A1 ) = A2 )), vars(A2 )) .\n[by Th. 6.16]\nThus UfSh is correct and optimal w.r.t. UfPs . The fact that it is well defined (i.e.,\nit does not depend on the choice of the renaming \u03c1) is a direct consequence of\noptimality.\nD Matching\nTheorem D.1\n(Correctness of matchSh ) matchSh is correct w.r.t. matchPs .\nProof\nConsider [\u0398i , Ui ] \u2291Ps \u03b3Sh ([Si , Ui ]) for i \u2208 {1, 2} and [\u03c3]U1 \u222aU2 \u2208 matchPs ([\u03981 , U1 ],\n[\u03982 , U2 ]). We need to prove that\n\u03b1Sh ([\u03c3]U1 \u222aU2 ) \u2208 matchSh ([S1 , U1 ], [S2 , U2 ]) .\nAssume [\u03c3] = mgu([\u03c31 ], [\u03c32 ]) with [\u03c31 ] \u2208 \u03981 and [\u03c32 ] \u2208 \u03982 . Let \u03c31 and \u03c32 be two\ncanonical representatives for [\u03c31 ] and [\u03c32 ] such that vars(\u03c31 ) \u2229 vars(\u03c32 ) = U1 \u2229 U2 .\nIf \u03c31 \u0016U1 \u2229U2 \u03c32 , there exists \u03b4 \u2208 Subst such that \u03c31 (x) = \u03b4(\u03c32 (x)) for each x \u2208\nU1 \u2229U2 . We may assume, without loss of generality, that dom(\u03b4) = vars(\u03c32 (U1 \u2229U2 )).\nNow, the following equalities hold.\n\u03c3 =mgu(Eq(\u03c32 ), Eq(\u03c31 ))\n=mgu({\u03c32 (x) = \u03c32 (\u03c31 (x)) | x \u2208 U1 }) \u25e6 \u03c32\n=mgu({x = \u03c31 (x) | x \u2208 U1 \\ U2 } \u222a {\u03c31 (x) = \u03c32 (x) | x \u2208 U1 \u2229 U2 }) \u25e6 \u03c32\n[by partitioning dom(\u03c32 ), since \u03c32 (\u03c31 (x)) = \u03c31 (x) for x \u2208 U1 ]\n\n=mgu({x = \u03c31 (x) | x \u2208 U1 \\ U2 }) \u25e6 \u03b4 \u25e6 \u03c32\n\n(D1)\n\n[since \u03c31 (x) = \u03b4(\u03c32 (x)) and dom(\u03b4) = vars(\u03c32 (U1 \u2229 U2 ))]\n\n=\u03c31|U1 \\U2 \u25e6 \u03b4 \u25e6 \u03c32\n=\u03c31|U1 \\U2 \u228e (\u03b4 \u25e6 \u03c32 ) .\nNow, given a variable v, by Lemma B.1, occ(\u03c3, v) \u2229 (U1 \u222a U2 ) = (occ(\u03c31|U1 \\U2 , v) \u2229\nU1 ) \u222a (occ(\u03c32 , occ(\u03b4, v)) \u2229 U2 ). We want to prove that occ(\u03c3, v) \u2229 (U1 \u222a U2 ) \u2208\nmatchSh ([S1 , U1 ], [S2 , U2 ]).\n\n\fOptimality in goal-dependent analysis of Sharing\n\n67\n\nSince dom(\u03c3) = U1 \u222a U2 , we may assume that v \u2208\n/ U1 \u222a U2 , otherwise occ(\u03c3, v) \u2229\n\u2032\n(U1 \u222a U2 ) = \u2205. We recall that S1 = {B \u2208 S1 | B \u2229 U2 = \u2205} and S1\u2032\u2032 = S1 \\ S1\u2032 ,\nS2\u2032 = {B \u2208 S2 | B \u2229 U1 = \u2205} and S2\u2032\u2032 = S2 \\ S2\u2032 , according to Definition 7.1. We\ndistinguish two cases:\n\u2022 v \u2208\n/ rng(\u03b4), which implies v \u2208\n/ rng(\u03c31|U2 ). Note that, if v \u2208 dom(\u03b4) then\nocc(\u03c32 , occ(\u03b4, v)) = \u2205 \u2208 S2\u2032 , otherwise occ(\u03c32 , occ(\u03b4, v)) = occ(\u03c32 , v) \u2208 S2\u2032 . So,\nit always holds that occ(\u03c32 , occ(\u03b4, v)) \u2208 S2\u2032 . We now distinguish some subcases.\nIf v \u2208 rng(\u03c31 ) then occ(\u03c31|U1 \\U2 , v) = occ(\u03c31 , v). Moreover, since v \u2208 rng(\u03c31 ),\nthen v \u2208\n/ vars(\u03c32 ) and thus occ(\u03c32 , v) = {v}. We have that occ(\u03c3, v) \u2229 (U1 \u222a\nU2 ) = occ(\u03c31 , v) \u2208 S1\u2032 . Otherwise, if v \u2208 rng(\u03c32 ), then v \u2208\n/ vars(\u03c31 ) and\nocc(\u03c31 , v) = {v}. Therefore occ(\u03c3, v) \u2229 (U1 \u222a U2 ) = occ(\u03c32 , occ(\u03b4, v)) \u2208 S2\u2032 .\nOtherwise, if v \u2208\n/ rng(\u03c31 ) \u222a rng(\u03c32 ) then occ(\u03c3, v) \u2229 (U1 \u222a U2 ) = \u2205.\n\u2022 v \u2208 rng(\u03b4). We want to prove that occ(\u03c3, v) = X1 \u222a X2 where X1 = occ(\u03c31 , v)\nand X2 = occ(\u03c32 , occ(\u03b4, v)) enjoy the following properties: X1 \u2208 S1\u2032\u2032 , X2 \u2208\n\u2217\nS2\u2032\u2032 , X1 \u2229 U2 = X2 \u2229 U1 . First of all, note that occ(\u03c31|U1 \\U2 , v) \u2229 U1 = X1 \\ U2 .\nMoreover, occ(\u03c32 , occ(\u03b4, v)) \u2229 U1 = occ(\u03c32|U1 , occ(\u03b4, v)) \u2229 U1 , which in turn is\nequal to occ(\u03b4 \u25e6 \u03c32|U1 , v) \u2229 U1 = occ(\u03c31|U2 , v) \u2229 U1 = occ(\u03c31 , v) \u2229 U1 \u2229 U2 \u2287\nX1 \u2229 U2 . This proves that occ(\u03c3, v) = X1 \u222a X2 and X1 \u2229 U2 = X2 \u2229 U1 .\nWhile it is obvious that X1 \u2208 S1 and X2 \u2208 S2\u2217 , we still need to prove that\n\u2217\nX1 \u2208 S1\u2032\u2032 and X2 \u2208 S2\u2032\u2032 . For each y \u2208 occ(\u03b4, v), by definition of \u03b4 we have that\n\u2217\ny \u2208 \u03c32 (U1 \u2229 U2 ) and therefore occ(\u03c32 , y) \u2229 U1 6= \u2205. This proves that X2 \u2208 S2\u2032\u2032 .\n\u2032\u2032\nMoreover, if v \u2208 rng(\u03b4) then v \u2208 rng(\u03c31|U2 ) and thus occ(\u03c31 , v) \u2208 S1 .\nTheorem D.2\n(Weak completeness of matchSh ) The operator matchSh is optimal on the first\nargument and complete on the second one when matchPs is restricted to the case\nwhen the second argument contains a single substitution. In formulas:\nmatchSh ([S1 , U1 ], \u03b1Sh ([{\u03c32 }, U2 ])) = \u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ])) .\nfor each [{[\u03c32 ]}, U2 ] \u2208 Psub and [S1 , U1 ] \u2208 Sharing.\nProof\nSince matchSh is correct w.r.t. matchPs , it follows that:\n\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ])) \u2291Sh matchSh ([S1 , U1 ], \u03b1Sh ([{[\u03c32 ]}, U2 ])) .\nSo, we only need to prove that:\nmatchSh ([S1 , U1 ], \u03b1Sh ([{[\u03c32 ]}, U2 ])) \u2291Sh \u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ])) .\nAssume, without loss of generality, that \u03c32 is a canonical representative of [\u03c32 ]U2\nand rng(\u03c32 ) \u2229 U1 = \u2205. Take B \u2208 S, where [S, U1 \u222a U2 ] = matchSh ([S1 , U1 ], [S2 , U2 ]),\nwith [S2 , U2 ] = \u03b1Sh ([{[\u03c32 ]}, U2 ]). We have three cases.\n\u2022 If B \u2208 S1\u2032 then B \u2208 S1 and B \u2286 U1 \\ U2 . Let \u03b4 = {x/v | x \u2208 B} \u222a {x/a |\nx \u2208 vars(\u03c32 (U1 \\ B))} and \u03c31 = (\u03b4 \u25e6 \u03c32 )|U1 where v is a fresh variable. It\nfollows that dom(\u03c31 ) = U1 and rng(\u03c31 ) = {v} with occ(\u03c31 , v) = B, therefore\n\n\f68\n\nG. Amato and F. Scozzari\n[\u03c31 , U1 ] \u2291Ps \u03b3Sh ([S1 , U1 ]). Clearly \u03c31 \u0016U1 \u2229U2 \u03c32 since U1 \u2229 U2 \u2286 U1 \\ B. Let\n\u03c3 = mgu(\u03c31 , \u03c32 ). Since B \u2229 dom(\u03c32 ) = \u2205 and v is a fresh variable, it follows\nthat occ(\u03c3, v) = B, and thus B \u2208 \u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ])).\n\u2022 If B \u2208 S2\u2032 , there exists v \u2208 V such that occ(\u03c32 , v) \u2229 U2 = B. Let X =\nvars(\u03c32 (U1 ))) and take \u03b4 = {x/a | x \u2208 X}. Then \u03c31 = (\u03b4 \u25e6 \u03c32 )|U1 is such that\nocc(\u03c31 , v) \u2229 U1 = \u2205 for each v \u2208 V, therefore \u03c31 \u2208 \u03b3Sh ([S1 , U1 ]). Moreover\nmgu(\u03c32 , \u03c31 ) \u2208 matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ]). By the proof of Theorem\nD.1, Equation (D1), we have mgu(\u03c31 , \u03c32 ) = \u03b4 \u25e6 \u03c32 . Since B \u2229 U1 = \u2205, then\nv \u2208\n/ X = vars(\u03b4), and therefore occ(\u03b4 \u25e6 \u03c32 , v) \u2229 U2 = occ(\u03c32 , v) \u2229 U2 = B.\nHence B \u2208 \u03b1Sh (matchPs (\u03b3Sh\nS([S1 , U1 ]), [{[\u03c32 ]}, U2 ])).\nS\n\u2022 We now assume B = X1 \u222a X with X \u2286 S2\u2032\u2032 , X1 \u2208 S1\u2032\u2032 , X \u2229 U1 = X1 \u2229 U2 .\nThen, for each H \u2208 X, there exists vH \u2208 V such that occ(\u03c32 , vH ) \u2229 U2 = H.\nSince H \u2229 U1 6= \u2205 for each H \u2208 X, then vH \u2208 Y = vars(\u03c32 (U1 )). Consider the\nsubstitution\n\u03b4 = {vH /v | H \u2208 X} \u228e {w/a | w \u2208 Y, \u2200H \u2208 X.w 6= vH }\nfor a fresh variable v and\n\u03c31 = (\u03b4 \u25e6 \u03c32 )|U1 \u228e {x/v | x \u2208 X1 \\ U2 } .\nWe want to prove [{[\u03c31 ]}, U1 ] \u2208 \u03b3Sh ([S1 , U1 ]). By definition of \u03c31 we have that\nS\nocc(\u03c31 , v) \u2229 U1 = (occ(\u03c32 , {vH | H \u2208 X}) \u2229 U1 ) \u222a X1 \\ U2 = ( X \u2229 U1 ) \u222a\nX1 \\ U2 = X1 \u2208 S1 . Otherwise, for w 6= v we have that either occ(\u03c31 , w) =\n\u2205 when w \u2208 U1 or occ(\u03c31 , w) = occ(\u03c32 , w) which is disjoint from U1 . In\nboth cases, occ(\u03c31 , w) \u2229 U1 = \u2205 \u2208 S1 . By definition of \u03c31 , [mgu(\u03c31 , \u03c32 )] \u2208\nmatchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c32 ]}, U2 ]). Moreover, we know from (D1) that\nmgu(\u03c32 , \u03c31 ) = \u03b4 \u25e6 \u03c32 \u228e {x/v | x \u2208 X1 \\ U2 } .\nLet \u03c3 = mgu(\u03c31 , \u03c32 ). Note that occ(\u03c3, v) \u2229 (U1 \u222a U2 ) = X1 \\ U2 \u222a occ(\u03c32 , {vH |\nH \u2208 X}) \u2229 U2 . By definition of vH , occ(\u03c32 , vH ) \u2229 U2 = H, hence occ(\u03c3, v) \u2229\nS\nS\n(U1 \u222a U2 ) = (X1 \\ U2 ) \u222a X = X1 \u222a X = B.\n\nThis proves the theorem.\n\nTheorem D.3\n(Optimality of matchSh ) matchSh is optimal.\nProof\nGiven [S1 , U1 ], [S2 , U2 ] \u2208 Sharing, we have\n\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), \u03b3Sh ([S2 , U2 ])))\n= \u03b1Sh (\u2294Ps {matchPs (\u03b3Sh ([S1 , U1 ]), [{[\u03c3]}, U2 ]) | \u03b1Sh ([\u03c3]U2 ) \u2291Sh [S2 , U2 ]})\n[since matchPs is additive]\n\n= \u2294Sh {matchSh ([S1 , U1 ], [X, U2 ]) | X = \u03b1Sh ([\u03c3]U2 ) \u2291Sh [S2 , U2 ]}\n[by completeness of \u2294Sh and Theorem D.2]\n\n= matchSh ([S1 , U1 ], \u2294Sh {[X, U2 ] | X = \u03b1Sh ([\u03c3]U2 ) \u2291Sh [S2 , U2 ]}) .\n[since matchSh is additive]\n\n\fOptimality in goal-dependent analysis of Sharing\n\n69\n\nSince \u03b1Sh defines a Galois insertion, it is surjective, and therefore \u2294Sh {[X, U2 ] |\nX = \u03b1Sh ([\u03c3]U2 ) \u2291Sh [S2 , U2 ]} = [S2 , U2 ] and we obtain\n\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), \u03b3Sh ([S2 , U2 ]))) = matchSh ([S1 , U1 ], [S2 , U2 ]) ,\nwhich concludes the proof.\nTheorem D.4\n(Strong optimality of unif Sh ) Given [S1 , U1 ] \u2208 Sharing and \u03b8 \u2208 ISubst, there\nexists a substitution \u03b4 \u2208 ISubst such that \u03b1Sh ([\u03b4]U1 ) \u2291Sh [S1 , U1 ] and\n\u03b1Sh (unif Ps ([{[\u03b4]}, U1 ], \u03b8)) = unif Sh ([S1 , U1 ], \u03b8) .\nProof\nThe optimality result proved in Theorem 6.16 shows that there exists [\u03981 , U1 ] \u2291Ps\n\u03b3Sh ([S1 , U1 ]) such that \u03b1Sh (unif Ps ([\u03981 , U1 ], \u03b8)) = unif Sh ([S1 , U1 ], \u03b4). We need a\nstronger result which proves that \u03981 can be chosen as a singleton.\nAssume unif Sh ([S1 , U1 ], \u03b8) = [S, U1 \u222a U2 ] where U2 = vars(\u03b8) \\ U1 and S =\n{X 1 , . . . , X n }. Following the construction in Section C, for each X i let us define\ni\nX1i , X2i , K i , K1i , K2i , W i , six , s\u2032 x , U as in the proof of optimality for unif Sh . We\ni\nj\ni\ni\nchoose W , W such that W \u2229 W j = \u2205 if i 6= j and we denote by wB\nthe elements\ni\nof W .\nFor each y \u2208 vars(\u03b8(U1 )) \u2229 (\u222a1\u2264i\u2264n X i ), we choose a variable xy \u2208 U1 such that\ny \u2208 \u03b8(xy ). Then, we define the substitution \u03b4 in the following way: for each variables\nx \u2208 U1 , \u03b4(x) is the same as \u03b8(x), with the exception that each occurrence (y, j) of\na variable y \u2208 \u03b8(x) is replaced by tx,y,j = t(t1x,y,j , . . . , tnx,y,j ), where:\n/ X i,\n\u2022 tix,y,j = a if y \u2208\n\u2022 tix,y,j = six otherwise, if x = xy and j = 1;\ni\n\u2022 tix,y,j = s\u2032 x otherwise.\nS\nBy construction dom(\u03b4) = U1 and rng(\u03b4) = 1\u2264i\u2264n W i . It is easy to check that\nS\n\u03b1Sh ([{\u03b4}, U1 ]) = [ 1\u2264i\u2264n K1i , U1 ] \u2291Sh [S1 , U1 ]. Using the properties of the equation\nsets we can prove that\nmgu(\u03b4, \u03b8)\n=\n\nmgu({v = tx,v,j | x \u2208 U1 , (v, j) is an occurrence of v in \u03b8(x)}) \u25e6 \u03b8\n\n=\n\nmgu(E) \u25e6 \u03c1 \u25e6 \u03b8 ,\n\nwhere\n\u03c1 = {v/txv ,v,1 | v \u2208 vars(\u03b8(U1 ))} ,\nE = {tixv ,v,1 = tix\u2032 ,v,j | i \u2208 {1, . . . , n}, v \u2208 X i , x\u2032 \u2208 U1 ,\n(v, j) is an occurrence of v in \u03b8(x\u2032 )} .\nNow, each E i = {tixv ,v,1 = tix\u2032 ,v,j | x\u2032 \u2208 U1 , (v, j) is an occurrence of v in \u03b8(x\u2032 ), v \u2208\nX i } is the same equation which appears in (C1) for X = X i . Therefore, for each\ni \u2208 {1, . . . , n} such that W i 6= \u2205, we choose a single wi \u2208 W i and define \u03b7 i\n\n\f70\n\nG. Amato and F. Scozzari\n\ni\ni\nwith dom(\u03b7 i ) = W i \\ {wi } and \u03b7 i (wB\n) = wi for each wB\n\u2208 W i . If W i = \u2205, we\ni\nchoose \u03b7 = \u01eb. We know from the proof of Lemma C.5 that \u03b7 i = mgu(E i ), and\nU\nmgu(E) = \u03b7 = 1\u2264i\u2264n \u03b7 i since vars(E i ) \u2229 vars(E j ) = \u2205 for i 6= j. Therefore\n\nmgu(\u03b4, \u03b8) = \u03b7 \u25e6 \u03c1 \u25e6 \u03b8 .\n\nWe now want to prove that \u03b1Sh ([\u03b7 \u25e6 \u03c1 \u25e6 \u03b8]U1 \u222aU2 ) \u2292Ps [{X i }, U1 \u222a U2 ] for each i \u2208\n{1, . . . , n}. If X1i 6= \u2205 then W i 6= \u2205, and we have occ(\u03b7 \u25e6 \u03c1 \u25e6 \u03b8, wi ) = occ(\u03b7 i \u25e6 \u03c1 \u25e6 \u03b8, wi ).\nFollowing the proof of Lemma C.5 with X = X i , we have that occ(\u03b7 \u25e6\u03c1\u25e6\u03b8, wi )\u2229U =\nX i . When X1i = \u2205, we may choose v i \u2208 \u03b8(X2i ). In this case, occ(\u03b7 \u25e6 \u03c1 \u25e6 \u03b8, v i ) \u2229 U =\nocc(\u03b8, v i ) \u2229 U = X i as proved in Prop. C.6.\nAs for Prop. C.6, in the proof of this theorem we assume that we have term\nsymbols for each arity. However, it is possible to rewrite terms so that a constant\nsymbol and a binary term symbol suffice.\nTheorem D.5\nUbSh is correct and optimal w.r.t. UbPs .\nProof\nCorrectness immediately follows by the fact that UbPs is obtained by tupling and\ncomposition of correct semantic functions.\nBy using Theorems D.2 and D.4, it is possible to prove that\nmatchSh ([S1 , U1 ], unif Sh ([S2 , U2 ], \u03b8)) =\n\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), unif Sh (\u03b3Sh ([S2 , U2 ]), \u03b8))) ,\ni.e., that the composition of matchSh and unif Sh , as used in UbSh , is optimal.\nAssume given [S1 , U1 ] and [S2 , U2 ] \u2208 Psub and \u03b8 \u2208 ISubst. Consider [{[\u03c3]}, U2 ] \u2208\n\u03b3Sh ([S2 , U2 ]) obtained by Lemma D.4 such that unif Ps ([{[\u03c3]}, U2 ]), \u03b8) = [{[\u03b4]}, U2 \u222a\nvars(\u03b8)] and \u03b1Sh ([{[\u03b4]}, U2 \u222a vars(\u03b8)]) = unif Sh ([S2 , U2 ], \u03b8). Then, we have\nmatchSh ([S1 , U1 ], unif Sh ([S2 , U2 ], \u03b8))\n=matchSh ([S1 , U1 ], \u03b1Sh (unif Ps ([{[\u03c3]}, U2 ], \u03b8)))\n=\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), unif Ps ([{[\u03c3]}, U2 ], \u03b8)))\nby Theorem D.2, so that, in general\nmatchSh ([S1 , U1 ], unif Sh ([S2 , U2 ], \u03b8)) \u2291Sh\n\u03b1Sh (matchPs (\u03b3Sh ([S1 , U1 ]), unif Ps (\u03b3Sh ([S2 , U2 ]), \u03b8))) .\nUbPs\n\nThe proof that\nis optimal follows from this result, completeness of \u03c0Sh and\n\u03b3-completeness of \u03c1.\nReferences\nAmato, G. and Scozzari, F. 2002. Optimality in goal-dependent analysis of sharing. In Proceedings of the Joint Conference on Declarative Programming (AGP'02),\nJ. J. Moreno-Navarro and J. Mari\u00f1o-Carballo, Eds. Universidad Polit\u00e9cnica de Madrid,\nMadrid, 189\u2013205.\n\n\fOptimality in goal-dependent analysis of Sharing\n\n71\n\nAmato, G. and Scozzari, F. 2003. A general framework for variable aliasing: Towards optimal operators for sharing properties. In Logic Based Program Synthesis and\nTransformation 12th International Workshop, LOPSTR 2002, Madrid, Spain, September 17\u201320, 2002. Revised Selected Papers, M. Leuschel, Ed. Lecture Notes in Computer\nScience, vol. 2664. Springer, Berlin Heidelberg, 52\u201370.\nApt, K. R. 1990. Introduction to logic programming. In Handbook of Theoretical Computer Science, J. van Leeuwen, Ed. Vol. B: Formal Models and Semantics. Elsevier and\nThe MIT Press, 495\u2013574.\nBagnara, R., Hill, P. M., and Zaffanella, E. 2002. Set-sharing is redundant for\npair-sharing. Theoretical Computer Science 277, 1\u20132, 3\u201346.\nBagnara, R., Zaffanella, E., and Hill, P. M. 2005. Enhanced sharing analysis\ntechniques: A comprehensive evaluation. Theory and Practice of Logic Programming 5, 1\n& 2, 1\u201343.\nBossi, A., Gabbrielli, M., Levi, G., and Martelli, M. 1994. The s-semantics approach: Theory and applications. The Journal of Logic Programming 19\u201320, 149\u2013197.\nBruynooghe, M. 1991. A practical framework for the abstract interpretation of logic\nprograms. The Journal of Logic Programming 10, 1/2/3 & 4, 91\u2013124.\nCodish, M., Lagoon, V., and Bueno, F. 2000. An algebraic approach to sharing analysis\nof logic programs. The Journal of Logic Programming 42, 2 (February), 110\u2013149.\nCortesi, A. and Fil\u00e9, G. 1999. Sharing is optimal. The Journal of Logic Programming 38, 3, 371\u2013386.\nCortesi, A., Fil\u00e9, G., and Winsborough, W. W. 1994. Optimal groundness analysis\nusing propositional formulas. Tech. Rep. 94/11, Dipartimento di Matematica Pura ed\nApplicata, Universit\u00e0 di Padova.\nCortesi, A., Fil\u00e9, G., and Winsborough, W. W. 1996. Optimal groundness analysis\nusing propositional logic. The Journal of Logic Programming 27, 2, 137\u2013167.\nCousot, P. and Cousot, R. 1979. Systematic design of program analysis frameworks.\nIn Proceedings of the 6th ACM SIGACT-SIGPLAN symposium on Principles of programming languages. ACM Press, New York, NY, USA, 269\u2013282.\nCousot, P. and Cousot, R. 1992. Abstract interpretation and applications to logic\nprograms. The Journal of Logic Programming 13, 2 & 3, 103\u2013179.\nCousot, P. and Cousot, R. 1994. Higher-order abstract interpretation (and application\nto comportment analysis generalizing strictness, termination, projection and PER analysis of functional languages), invited paper. In Proceedings of the 1994 International\nConference on Computer Languages. IEEE Computer Society Press, Los Alamitos, CA,\nUSA, 95\u2013112.\nFurukawa, K., Ed. 1991. Logic Programming, Proceedings of the Eighth International\nConference. Logic Programming. The MIT Press, Cambridge, MA, USA.\nGarc\u0131\u0301a de la Banda, M. J., Marriott, K., Stuckey, P. J., and S\u00f8ndergaard, H.\n1998. Differential methods in logic program analysis. The Journal of Logic Programming 35, 1 (Apr.), 1\u201337.\nGiacobazzi, R., Ranzato, F., and Scozzari, F. 2000. Making abstract interpretations\ncomplete. Journal of the ACM 47, 2, 361\u2013416.\nHans, W. and Winkler, S. 1992.\nAliasing and groundness analysis of\nlogic programs through abstract interpretation and its safety.\nTech. Rep.\n92\u201327, Technical University of Aachen (RWTH Aachen).\nAvailable from\nhttp://sunsite.informatik.rwth-aachen.de/Publications/AIB.\nHenkin, L., Monk, J. D., and Tarski, A. 1971. Cylindric Algebras Part I. Number 115\nin Studies in Logic and the Foundations of Mathematics. North Holland, Amsterdam.\n\n\f72\n\nG. Amato and F. Scozzari\n\nHermenegildo, M. V. and Rossi, F. 1995. Strict and nonstrict independent andparallelism in logic programs: Correctness, efficiency, and compile-time conditions. The\nJournal of Logic Programming 22, 1, 1\u201345.\nHill, P. M., Zaffanella, E., and Bagnara, R. 2004. A correct, precise and efficient\nintegration of set-sharing, freeness and linearity for the analysis of finite and rational\ntree languages. Theory and Practice of Logic Programming 4, 3, 289\u2013323.\nHowe, J. M. and King, A. 2003. Three optimisations for sharing. Theory and Practice\nof Logic Programming 3, 2 (Jan.), 243\u2013257.\nJacobs, D. and Langen, A. 1992. Static analysis of logic programs for independent\nAND parallelism. The Journal of Logic Programming 13, 2 & 3, 291\u2013314.\nKing, A. 1994. A synergistic analysis for sharing and groundness which traces linearity. In Programming Languages and Systems ESOP '94, 5th European Symposium on\nProgramming Edinburg, U.K., April 1113, 1994 Proceedings, D. Sannella, Ed. Lecture\nNotes in Computer Science, vol. 788. Springer, Berlin Heidelberg, 363\u2013378.\nKing, A. 2000. Pair-sharing over rational trees. The Journal of Logic Programming 46, 12, 139\u2013155.\nKing, A. and Longley, M. 1995. Abstract matching can improve on abstract unification. Tech. Rep. 4-95*, University of Kent, Computing Laboratory, University of Kent,\nCanterbury, UK. March.\nLangen, A. 1990. Static analysis for independent And-parallelism in logic programs.\nPh.D. thesis, University of Southern California, Los Angeles, California.\nLe Charlier, B., Musumbu, K., and Van Hentenryck, P. 1991. A generic abstract\ninterpretation algorithm and its complexity analysis. See Furukawa (1991).\nLe Charlier, B. and Van Hentenryck, P. 1994. Experimental evaluation of a generic\nabstract interpretation algorithm for prolog. ACM Transactions on Programming Languages and Systems 16, 1, 35\u2013101.\nLevi, G. and Spoto, F. 2003. Pair-independence and freeness analysis through linear\nrefinement. Information and Computation 182, 1, 14\u201352.\nLloyd, J. W. 1987. Foundations of Logic Programming, Second ed. Springer, New York,\nNY, USA.\nMarriott, K., S\u00f8ndergaard, H., and Jones, N. D. 1994. Denotational abstract interpretation of logic programs. ACM Transactions on Programming Languages and\nSystems 16, 3, 607\u2013648.\nMuthukumar, K. and Hermenegildo, M. V. 1991. Combined determination of sharing\nand freeness of program variables through abstract interpretation. See Furukawa (1991),\n49\u201363.\nMuthukumar, K. and Hermenegildo, M. V. 1992. Compile-time derivation of variable\ndependency using abstract interpretation. The Journal of Logic Programming 13, 2 &\n3, 315\u2013347.\nPalamidessi, C. 1990. Algebraic properties of idempotent substitutions. In Automata,\nLanguages and Programming, 17th International Colloquium Warwick University, England, July 1620, 1990 Proceedings, M. Paterson, Ed. Lecture Notes in Computer Science,\nvol. 443. Springer, Berlin Heidelberg, 386\u2013399.\nShepherdson, J. C. 1994. The role of standardising apart in logic programming. Theoretical Computer Science 129, 143\u2013166.\nS\u00f8ndergaard, H. 1986. An application of abstract interpretation of logic programs:\nOccur check reduction. In Proc. ESOP 86, B. Robinet and R. Wilhelm, Eds. Lecture\nNotes in Computer Science, vol. 213. Springer, Berlin Heidelberg, 327\u2013338.\nvan Emden, M. H. and Kowalski, R. A. 1976. The semantics of predicate logic as a\nprogramming language. Journal of the ACM 23, 4, 733\u2013742.\n\n\f"}