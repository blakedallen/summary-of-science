{"id": "http://arxiv.org/abs/cond-mat/0311358v1", "guidislink": true, "updated": "2003-11-14T23:16:38Z", "updated_parsed": [2003, 11, 14, 23, 16, 38, 4, 318, 0], "published": "2003-11-14T23:16:38Z", "published_parsed": [2003, 11, 14, 23, 16, 38, 4, 318, 0], "title": "Automatic Coarse Graining of Polymers", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0311443%2Ccond-mat%2F0311553%2Ccond-mat%2F0311337%2Ccond-mat%2F0311083%2Ccond-mat%2F0311381%2Ccond-mat%2F0311333%2Ccond-mat%2F0311375%2Ccond-mat%2F0311038%2Ccond-mat%2F0311310%2Ccond-mat%2F0311053%2Ccond-mat%2F0311427%2Ccond-mat%2F0311498%2Ccond-mat%2F0311228%2Ccond-mat%2F0311132%2Ccond-mat%2F0311055%2Ccond-mat%2F0311500%2Ccond-mat%2F0311238%2Ccond-mat%2F0311139%2Ccond-mat%2F0311418%2Ccond-mat%2F0311544%2Ccond-mat%2F0311363%2Ccond-mat%2F0311044%2Ccond-mat%2F0311637%2Ccond-mat%2F0311519%2Ccond-mat%2F0311441%2Ccond-mat%2F0311203%2Ccond-mat%2F0311466%2Ccond-mat%2F0311087%2Ccond-mat%2F0311572%2Ccond-mat%2F0311091%2Ccond-mat%2F0311455%2Ccond-mat%2F0311330%2Ccond-mat%2F0311158%2Ccond-mat%2F0311616%2Ccond-mat%2F0311548%2Ccond-mat%2F0311475%2Ccond-mat%2F0311526%2Ccond-mat%2F0311101%2Ccond-mat%2F0311151%2Ccond-mat%2F0311102%2Ccond-mat%2F0311589%2Ccond-mat%2F0311630%2Ccond-mat%2F0311150%2Ccond-mat%2F0311079%2Ccond-mat%2F0311487%2Ccond-mat%2F0311284%2Ccond-mat%2F0311590%2Ccond-mat%2F0311651%2Ccond-mat%2F0311159%2Ccond-mat%2F0311105%2Ccond-mat%2F0311269%2Ccond-mat%2F0311409%2Ccond-mat%2F0311245%2Ccond-mat%2F0311226%2Ccond-mat%2F0311179%2Ccond-mat%2F0311268%2Ccond-mat%2F0311263%2Ccond-mat%2F0311266%2Ccond-mat%2F0311129%2Ccond-mat%2F0311516%2Ccond-mat%2F0311513%2Ccond-mat%2F0311623%2Ccond-mat%2F0311274%2Ccond-mat%2F0311122%2Ccond-mat%2F0311352%2Ccond-mat%2F0311383%2Ccond-mat%2F0311372%2Ccond-mat%2F0311014%2Ccond-mat%2F0311022%2Ccond-mat%2F0311306%2Ccond-mat%2F0311180%2Ccond-mat%2F0311532%2Ccond-mat%2F0311045%2Ccond-mat%2F0311521%2Ccond-mat%2F0311524%2Ccond-mat%2F0311412%2Ccond-mat%2F0311196%2Ccond-mat%2F0311300%2Ccond-mat%2F0311509%2Ccond-mat%2F0311321%2Ccond-mat%2F0311395%2Ccond-mat%2F0311339%2Ccond-mat%2F0311619%2Ccond-mat%2F0311015%2Ccond-mat%2F0311138%2Ccond-mat%2F0311173%2Ccond-mat%2F0311210%2Ccond-mat%2F0311629%2Ccond-mat%2F0311149%2Ccond-mat%2F0311192%2Ccond-mat%2F0311358%2Ccond-mat%2F0311209%2Ccond-mat%2F0311067%2Ccond-mat%2F0311543%2Ccond-mat%2F0311647%2Ccond-mat%2F0311020%2Ccond-mat%2F0311384%2Ccond-mat%2F0311233%2Ccond-mat%2F0311219%2Ccond-mat%2F0311559%2Ccond-mat%2F0311477&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Automatic Coarse Graining of Polymers"}, "summary": "Several recently proposed semi--automatic and fully--automatic\ncoarse--graining schemes for polymer simulations are discussed. All these\ntechniques derive effective potentials for multi--atom units or super--atoms\nfrom atomistic simulations. These include techniques relying on single chain\nsimulations in vacuum and self--consistent optimizations from the melt like the\nsimplex method and the inverted Boltzmann method. The focus is on matching the\npolymer structure on different scales. Several ways to obtain a time-scale for\ndynamic mapping are discussed additionally. Finally, similarities to other\nsimulation areas where automatic optimization are applied as well are pointed\nout.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0311443%2Ccond-mat%2F0311553%2Ccond-mat%2F0311337%2Ccond-mat%2F0311083%2Ccond-mat%2F0311381%2Ccond-mat%2F0311333%2Ccond-mat%2F0311375%2Ccond-mat%2F0311038%2Ccond-mat%2F0311310%2Ccond-mat%2F0311053%2Ccond-mat%2F0311427%2Ccond-mat%2F0311498%2Ccond-mat%2F0311228%2Ccond-mat%2F0311132%2Ccond-mat%2F0311055%2Ccond-mat%2F0311500%2Ccond-mat%2F0311238%2Ccond-mat%2F0311139%2Ccond-mat%2F0311418%2Ccond-mat%2F0311544%2Ccond-mat%2F0311363%2Ccond-mat%2F0311044%2Ccond-mat%2F0311637%2Ccond-mat%2F0311519%2Ccond-mat%2F0311441%2Ccond-mat%2F0311203%2Ccond-mat%2F0311466%2Ccond-mat%2F0311087%2Ccond-mat%2F0311572%2Ccond-mat%2F0311091%2Ccond-mat%2F0311455%2Ccond-mat%2F0311330%2Ccond-mat%2F0311158%2Ccond-mat%2F0311616%2Ccond-mat%2F0311548%2Ccond-mat%2F0311475%2Ccond-mat%2F0311526%2Ccond-mat%2F0311101%2Ccond-mat%2F0311151%2Ccond-mat%2F0311102%2Ccond-mat%2F0311589%2Ccond-mat%2F0311630%2Ccond-mat%2F0311150%2Ccond-mat%2F0311079%2Ccond-mat%2F0311487%2Ccond-mat%2F0311284%2Ccond-mat%2F0311590%2Ccond-mat%2F0311651%2Ccond-mat%2F0311159%2Ccond-mat%2F0311105%2Ccond-mat%2F0311269%2Ccond-mat%2F0311409%2Ccond-mat%2F0311245%2Ccond-mat%2F0311226%2Ccond-mat%2F0311179%2Ccond-mat%2F0311268%2Ccond-mat%2F0311263%2Ccond-mat%2F0311266%2Ccond-mat%2F0311129%2Ccond-mat%2F0311516%2Ccond-mat%2F0311513%2Ccond-mat%2F0311623%2Ccond-mat%2F0311274%2Ccond-mat%2F0311122%2Ccond-mat%2F0311352%2Ccond-mat%2F0311383%2Ccond-mat%2F0311372%2Ccond-mat%2F0311014%2Ccond-mat%2F0311022%2Ccond-mat%2F0311306%2Ccond-mat%2F0311180%2Ccond-mat%2F0311532%2Ccond-mat%2F0311045%2Ccond-mat%2F0311521%2Ccond-mat%2F0311524%2Ccond-mat%2F0311412%2Ccond-mat%2F0311196%2Ccond-mat%2F0311300%2Ccond-mat%2F0311509%2Ccond-mat%2F0311321%2Ccond-mat%2F0311395%2Ccond-mat%2F0311339%2Ccond-mat%2F0311619%2Ccond-mat%2F0311015%2Ccond-mat%2F0311138%2Ccond-mat%2F0311173%2Ccond-mat%2F0311210%2Ccond-mat%2F0311629%2Ccond-mat%2F0311149%2Ccond-mat%2F0311192%2Ccond-mat%2F0311358%2Ccond-mat%2F0311209%2Ccond-mat%2F0311067%2Ccond-mat%2F0311543%2Ccond-mat%2F0311647%2Ccond-mat%2F0311020%2Ccond-mat%2F0311384%2Ccond-mat%2F0311233%2Ccond-mat%2F0311219%2Ccond-mat%2F0311559%2Ccond-mat%2F0311477&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Several recently proposed semi--automatic and fully--automatic\ncoarse--graining schemes for polymer simulations are discussed. All these\ntechniques derive effective potentials for multi--atom units or super--atoms\nfrom atomistic simulations. These include techniques relying on single chain\nsimulations in vacuum and self--consistent optimizations from the melt like the\nsimplex method and the inverted Boltzmann method. The focus is on matching the\npolymer structure on different scales. Several ways to obtain a time-scale for\ndynamic mapping are discussed additionally. Finally, similarities to other\nsimulation areas where automatic optimization are applied as well are pointed\nout."}, "authors": ["Roland Faller"], "author_detail": {"name": "Roland Faller"}, "author": "Roland Faller", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.polymer.2003.11.053", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0311358v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0311358v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "17 pages, 5 figures", "arxiv_primary_category": {"term": "cond-mat.soft", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.soft", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.mtrl-sci", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0311358v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0311358v1", "journal_reference": "POLYMER 45(11), 3869-3876 (2004)", "doi": "10.1016/j.polymer.2003.11.053", "fulltext": "arXiv:cond-mat/0311358v1 [cond-mat.soft] 14 Nov 2003\n\nAutomatic Coarse Graining of Polymers\nRoland Faller\u2217\nDepartment of Chemical Engineering & Materials Science,\nUniversity of California-Davis, Davis, CA 95616, USA\n\nNovember 9, 2018\n\nAbstract\nSeveral recently proposed semi\u2013automatic and fully\u2013automatic coarse\u2013\ngraining schemes for polymer simulations are discussed. All these techniques derive effective potentials for multi\u2013atom units or super\u2013atoms\nfrom atomistic simulations. These include techniques relying on single\nchain simulations in vacuum and self\u2013consistent optimizations from the\nmelt like the simplex method and the inverted Boltzmann method. The focus is on matching the polymer structure on different scales. Several ways\nto obtain a time-scale for dynamic mapping are discussed additionally. Finally, similarities to other simulation areas where automatic optimization\nare applied as well are pointed out.\nKeywords: Polymer Simulations, Multi\u2013scale Techniques\n\n1\n\nIntroduction\n\nPolymers with their large variety of important length scales pose a formidable\nchallenge for computer simulations. Over the last decades various techniques to handle the problems on the different length scales separately\nhave been developed. Especially simulations in full atomistic detail [1, 2,\n3, 4, 5], and with one interaction center for each monomer [6, 7, 8] or for\neach polymer [9] have gained a lot of attention.\nMore recently it has been realized that a connection between the arising length and time scales are necessary. To this end a number of coarse\u2013\ngraining techniques have been devised [10,11,12,13,14,15,16,17,18,19,20]\nwhere simulations on more than one length scale are combined in order\nto get a better understanding of the system as a whole. It has even\nbeen proposed that simulations on both scales can be performed in one\nsingle simulation box [11, 20]. The purpose of this contribution is to critically analyze several of the most recent automatic mapping schemes for\ncoarse\u2013graining in polymer research. This comprises a technique combining atomistic single chain Monte Carlo with molecular dynamics on the\nmeso\u2013scale [10] the automatic simplex mapping technique [21, 22], and\n\u2217 Email:\n\nrfaller@ucdavis.edu\n\n1\n\n\fa number of physically inspired techniques [13, 18, 17]. All these techniques have been implemented in automatized schemes which in principle\nallow to obtain a coarse\u2013grained polymer model on the meso\u2013scale without human intervention if the atomistic simulations have been performed.\nBased on the atomistic simulations a target function has to be defined\nand optimized against in the meso\u2013scale simulation.\nTechniques which either rely on the use of lattice simulations or which\ncannot be implemented in an automatic manner have been left out on purpose in this contribution. The reader is referred to other reviews including\nsuch techniques [12, 16, 19].\nThere are many reasons for applying coarse\u2013graining schemes for polymer simulations. The overall structure of a polymer in melt or solution\noften shall be reproduced faithfully except for the local atomistic detail.\nThis improves the speed and memory requirements of the simulation and\nby that allows larger simulations or longer chains. Simulations of long\nchains are necessary but the experimentally relevant chain lengths cannot\nbe reached by atomistically detailed simulations. Even if computer speed\nincreases in the future as it did over the last decades, we are still decades\naway from doing simulations of chains with thousands monomers in a fully\natomistically detailed simulated melt. The relevant relaxation times increase by an exponent of N 3.4 with chain length N for large chains [23].\nAnd, even if it were possible to perform such simulations their usefulness\nwould be questionable as the vast amount of data would be very difficult\nto analyze as the interesting observables would be difficult to filter out. A\nlot of questions on large scales have been answered by simple bead\u2013spring\nmodels. These models are able to get interesting scaling behaviors and\nby this a lot of basic understanding. In order to get compare directly\nto experiments, however, one needs a meso\u2013scale model which does not\nrepresent generically \"a polymer\" but has an identity of a specific polymer. To this end a combination of atomistic and meso\u2013scale models which\ncan be mapped uniquely onto each other is necessary. In this case issues\nappearing on different length scales can be answered consistently.\nThe remainder of this article is organized as follows. Section 2 deals\nwith the various possibilities of static mapping, section 3 with dynamic\nmapping which has gained much less and in the end conclusions will\nbe drawn and connections to other automatic optimization techniques\nin molecular simulation will be shown.\n\n2\n2.1\n\nStatic Mapping\nThe concept of super\u2013atoms\n\nThe methods to be discussed here deal all with two length scales. Most\noften these are the atomistic scale and the meso\u2013scale. However, for\nthe methods to work this is not necessary. For the remainder of this\ncontribution an atomistic simulation is defined to be a simulation where\nall atoms are present or only the hydrogens are neglected. The latter is\noften called a united atom model. A meso\u2013scale model is defined to be\na model where a group of atoms is replaced by one interaction center.\n\n2\n\n\fThis group is typically of the size of a monomer. We call such a unit a\nsuper\u2013atom.\nThus, a part of a polymer chain comprising a few atoms (typically\n10\u201330) will be represented by one interaction center. The super\u2013atoms\nare the only interaction centers in the meso\u2013scale simulation. The interaction between super\u2013atoms has to implicitly carry the information of the\ninteractions between the atoms in their local geometrical arrangements\nimposed by the bonding. Figure 1 shows some typical examples of super\natom representation of polymers.\nThe choice of super\u2013atoms is arbitrary in principal. But there are a\nnumber of criteria which have been established. It is very effective if the\ndistance between super\u2013atoms along the chain is relatively rigidly defined\nas in that case the bonding potential is just a harmonic bond [18]. Figure 2 illustrates this using cis\u20131\u20134\u2013poly\u2013isoprene. The obvious choice of\nthe center of mass of the double bond leads to a doubly peaked bond\ndistribution whereas the choice of the super\u2013atom center being placed\nbetween atomistic monomers results in a clear single peak. Such a distribution can easily be modeled by a single Gaussian which is produced by a\nharmonic bond potential The height to width ratio of the Gaussian peak\ndefines the harmonic bond strength. The underlying reason for the two\nstrongly different distributions is that the double bond is very rigid and\ndoes not allow any torsional degrees of freedom whereas the single bonds\ncan easily flip from one torsional state to another. As the centers of mass\nof the double bond are effectively connected by single bonds and vice versa\nthe double bonds lead to the sharply peaked distribution and the different\ntorsion states of the single bonds lead to more than one peak making it\nmore difficult to model the distribution by a simple bond potential. Additionally the multiplicity of peaks would lead to an interdependence of\nbond and angle potentials.\nMoreover, it is advantageous to have the space occupied by the atoms\nrepresented in one super\u2013atom being spherical in order to avoid anisotropic\npotentials. Almost all schemes use a spherical potential to model the space\noccupied by the super\u2013atom [11,10,13,18,21]. This occupied space can in\nthe first approximation be viewed as the elliptic hull of the atoms. Generalizations to anisotropic potentials have been attempted [24]. The offset\nby the much higher complexity of the simulation can in most cases not\nbeen overcome by the only slightly higher accuracy.\nIf a single spherical potential is not satisfactory as, e.g. for diphenylcarbonate [21] or polycarbonates [10] it is more economical to use more\nthan one spherical super\u2013atom per monomer than a non\u2013spherical one.\nAbrams et al. showed that in the case of polycarbonate one needs 5\nspherical interaction center per atomistic monomer in order to get a good\nrepresentation of the underlying polymer [25] whereas 3 anisotropic beads\nhave been used by Hahn et al [24].\n\n2.2\n\nSingle chain distribution potentials\n\nTsch\u00f6p et al proposed a technique for mapping the structure of a polymer\nto a model containing much less interaction sites [10]. The model starts\nout with a detailed quantum chemical calculation of short segments of the\n\n3\n\n\fpolymer chain in order to obtain a accurate torsion potential. This quantum chemically determined distributions are then used to perform single\nchain Monte Carlo simulations in vacuum. The corresponding distributions of super\u2013atoms are recorded. The recorded distributions are bond\nlengths, bond angles and torsions. In order to accurately gain a potential\nout of these distributions they have to be weighted by the corresponding Jacobians. E.g. for the bond lengths the Jacobian is just r 2 which\nstems from the transformation from spherical to Cartesian coordinates.\nThen they are Boltzmann\u2013inverted to obtain intra\u2013molecular potentials\nbetween super atoms, i.e. a potential is derived from the distribution.\nFormally the Boltzmann inversion leads to a free energy difference but\nin vacuum this equals the potential energy. This difference will become\ncrucial in the following sections.\nV (\u03b6) = \u2212kB T ln p(\u03b6)\n\n(1)\n\nHere \u03b6 can stand for bond lengths, bond angles and torsions alike. The\ndistribution p(\u03b6) is taken after the Jacobian correction. In this way a complete set of intra\u2013molecular potentials has been obtained. It is noteworthy\nthat this potential is completely numerical. In order to be able to calculate a derivative to obtain the forces local splines or similar techniques can\nbe used to smooth it. Cross dependencies of the different potentials (e.g.\nbond and angle) are neglected for computational reasons. As explained\nabove they can be eliminated by the proper choice of mapping points.\nIn the original work, this elaborate intra\u2013molecular potential was combined with a simple repulsive Lennard Jones or WCA potential [26] to\nreproduce the density.\n\u0014\u0010 \u0011\n\u0015\n\u221a\n\u03c3 12 \u0010 \u03c3 \u00116\n6\nVW CA = 4\u01eb\n\u2212\nr < 2\u03c3.\n(2)\nr\nr\nHere \u03c3 is the interaction radius (size) of the monomer, \u01eb is the interaction\nstrength, and r is the distance between corresponding monomers.\nThis method was successful in calculating the structure factor of polycarbonates [27]. A similar approach has been applied to a simple hydrocarbon chain where the super\u2013atom center is taken as the center of mass of\nn monomers [15]. In this case the starting point was a atomistic molecular dynamics simulation. For the non\u2013bonded potential also a potential of\nmean force approach has been taken. So the radial distribution function\nof two dilute polymers is used to determine the non\u2013bonded potential.\nFor small molecules this can be used directly [11]. For polymers at small\ndistances the connectivity leads to a severe restriction on the possible conformations so a restricted pair distribution function taking connectivity\ninto account has to be used. This approach does not separate the simulations of the atomistic and the coarse\u2013grained models and bases on the\nreversible work theorem [11, 20]\nP \u2212\u03b2Ui (r)\ne\ne\u2212\u03b2W (r) = P i \u2212\u03b2U (\u221e)\n(3)\ni\nie\nwhere W is the reversible work and this can be used as a potential to\nobtain the same structure as the atomistic model. The appearance of\n\n4\n\n\fthe inverse temperature \u03b2 = (kB T )\u22121 scaled by the Boltzmann factor kB\nmakes it clear that this is valid only at the specified temperature. The\npotential U is the full potential energy of the system with the two sites\nunder focus fixed at a distance r apart. Fully detailed and mesoscopically\nmodeled particles coexist in the very same simulation. The detailed particles carry two potentials as they interact with the non\u2013detailed particles\nas if they were non\u2013detailed particles (cf. Fig. 3). Actually the two types\nof particles can even be bonded to each other in order to get the correct\npotential along a polymer chain as pointed out in reference [15] where also\nthe automatic implementation was shown.\n\n2.3\n\nSimplex\n\nRecently more direct ways of linking atomistic melt simulations and meso\u2013\nscale melt simulations have been developed. The idea is to systematically and self\u2013consistently reproduce structure and thermodynamics of\nthe atomistic simulation on the meso\u2013scale. As this is an optimization\nproblem mathematical optimization techniques can be applied directly.\nOne of the most robust although not very efficient multi\u2013dimensional optimizers is the simplex [28]. It has the advantage that it does not rely on\nany derivatives as they are very difficult to obtain in the simulation. The\nsimplex was first applied to optimizing atomistic simulation models to\nexperimental data [29]. The idea is to view the experimental observables,\ne.g. the density \u03c1, as a function f of the parameters of the simulation\nmodel Bi , e.g. the Lennard Jones parameters\n\u03c1 = f ({Bi }).\n\n(4)\n\nThis function in multi\u2013dimensional space is now optimized by the simplex technique. In order for the simplex to be applicable a single valued\nfunction with a minimum at the target has to be defined. This is easily\naccomplished by the sum of square deviations from target values\nX\nf=\n[A({\u01ebi }, {\u03c3i }) \u2212 Atarget ]2 .\n(5)\ni\n\nHere A represents any thermodynamic observable to be reproduced in this\nscheme with a target value Atarget ; {\u01ebi }, {\u03c3i } are the full set of Lennard\u2013\nJones parameters. Every function evaluation includes a complete equilibration sequence for the given parameters, a production run and the\nanalysis. In order to ensure equilibration it was made certain that no\ndrift in the observables remained and an automatic detection of equilibration was developed [29]. Very recently it has been shown that the\nderivatives of the observables with respect to the parameters of the simulation model can also be calculated and therefore more efficient optimizers\ncan be used [30].\nIn the context of polymer mapping the target functions are not experimental observables but the structure of the system. So radial distribution\nfunctions are the aim of the technique. To this end one views any point\nof the radial distribution function g(R) in the interval [Ri , Ri + 1] as a\ndifferent observable which is to be reproduced. The function to be minimized is the integral over the squared difference in radial distribution\n\n5\n\n\ffunctions [21]. If necessary a weighting function can additionally be introduced [21, 18]. An exponentially decay is a good choice as the local\nstructure around the first peak in the rdf is most crucial and most difficult to reproduce.\nZ\nf = drw(r)[g(r) \u2212 gtarget (r)]2 .\n(6)\nA drawback of the simplex technique is that it cannot use numerical potentials as a relatively small set of parameters defining the parameter\nspace is needed. The limit is typically 4\u20136 independent parameters Bi .\nAn increase in dimensionality of this space increases the need for computational resources tremendously. A good choice for such parameters are a\nLennard\u2013Jones like expansion [21, 22]\nV (R) =\n\nX Bi\nri\ni\n\n(7)\n\nwhere i has been used to span the even numbers from 6 to 12. This technique has been successful to reproduce monomers of polyisoprene [21].\nThe structure of small molecules like diphenylcarbonate could be described by this technique as well [21]. The application to polymers showed\nsome deficiencies [22] which led to the development of better suited algorithms.\n\n2.4\n\nPhysically Inspired Optimization Methods\n\nThe Iterative Boltzmann method was developed in order to circumvent\nthe problems encountered with the simplex technique [17, 18]. It is an optimization aiming at the structure of an atomistic simulation. It showed its\nstrength by being able to reproduce the structure of trans\u20131,4\u2013polyisoprene\nwhere the simplex technique failed [17, 18]. The idea is to use a physically inspired optimization technique to speed up the convergence and at\nthe same time get rid of the limitation on the number of parameters as\nimposed by the simplex technique.\nAs discussed above, in the limit of infinite dilution one could use the\npotential of mean force gained by Boltzmann inverting the pair distribution function to get an interaction potential between monomers, this would\nbe the non\u2013bonded generalization of the above described single chain approach. Similar ideas have been used to calculate potentials of mean force\n(PMF) of large particles like colloids in matrices of small particles where\nthe small particles play only the role of a homogeneous background [31,32].\nIn concentrated solutions or melts the structure is defined by an interplay\nof the PMF and the packing of atoms or monomers. It has been shown\nthat simple packing arguments can account for the largest part of local\norientation correlations in dense melts [33]. Thus, a direct calculation of\nthe potential of mean force is not correct. Still the use of the PMF idea as\na way to iteratively approach the correct potential is possible and is used\nby the iterative Boltzmann method. A melt or solution of polymers is simulated in atomistic detail to obtain a pair distribution function. For every\niteration a one\u2013to\u2013one correspondence between the effects at a distance\n\n6\n\n\fr0 and the potential V (r0 ) (or force \u2212dr V (r)|r=r0 ) at the same distance\nr is assumed. However, this is not a limitation as the iterative procedure\ntakes care of any other dependencies.\nIt becomes immediately clear from this approach that the resulting\npotential is numerical, as every single bin of the potential as a function\nof distance is optimized independently. It is possible and advantageous\nto enforce continuity by using weighted local averages. This is important\nif the function to be optimized against is relatively noisy, however, the\ncorrect way to lower the noise level is a longer atomistic simulation which\nof course can be prohibitive. Figure 4 illustrates the different stages of\na iterative Boltzmann procedure. In the beginning a starting potential\nVstart has to be guessed. Either we take the result from a similar problem\nor we start with the potential of mean force by Boltzmann inversion of\nthe target function. After this initial potential is simulated the radial\ndistribution function is obtained and the difference between this function\nand the target is determined. This leads to a correction potential which\nis the difference in free energy\n\u0012\n\u0013\ng(r)\n\u2206V (r) = \u2212kB T ln\n.\n(8)\ngtarget (r)\nThis correction potential is added and the iteration resumes until the\ndifference in g is deemed satisfactory. For polyisoprene 4 iterations were\nnecessary [17]. The final result is shown at the bottom of figure 4.\nTwo alternatives to the iterative Boltzmann technique which also rely\non a physically inspired optimization of the system have been proposed by\nAkkermans [14, 13]. The degrees of freedom of the polymer under study\nare separated into degrees of freedom of \"blobs\" and the \"bath\". The\nblobs play the role of the super\u2013atoms, the bath are all other degrees\nof freedom which have to be integrated out. Only the super\u2013atoms are\ntaken into account. The target radial distribution function is expanded\nin a basis set with the pre\u2013factors left for optimization\nX\ngtarget =\n\u03bbi ui (r)\n(9)\ni\n\nThe set of parameters \u03bb can now be viewed as dynamical parameters\nand assigned a virtual mass m(\u03bb) and a velocity. So one takes the route\nof an extended ensemble which is well known in molecular dynamics of\nconstant pressure and temperature [34, 35, 36]. A Lagrangian including\nthe \u03bb parameters is used and the simulation proceeds using this extended\nLagrangian\n~ ) + K\u03bb (~v\u03bb \u2212 U (R,\n~ \u03bb) \u2212 \u03a6\u03bb (\u03bb)\nL = K(V\n(10)\nwhere the K stands for the kinetic energies and U and \u03a6 are the respective\npotentials. Akkermans et al. showed the feasibility of this technique\nby re\u2013optimizing a Lennard\u2013Jones potential. As the dynamics of the \u03bb\nparameters turns out to be problematic the same approach without the\nvelocities can been used in a Monte Carlo procedure.\nA caveat is in order here. As all the techniques described up to now\nonly aim at the structure of the polymeric system it is not guaranteed that\nthe thermodynamic state is correctly described. This has been pointed\n\n7\n\n\fout by a number of researchers [13,37,17]. In order to avoid such problems\nan inclusion of thermodynamic properties in the optimization scheme is\nnecessary. For the pressure in the case of the inverted Boltzmann technique such a generalization is possible and works as follows [17]. After\noptimizing the structure an additional pressure correction (pc) potential\nof the form\n\u0012\n\u0013\nr\n\u2206Vpc (r) = Apc 1 \u2212\n(11)\nrcut\nis added, where A is negative if the pressure is too high and positive if it\nis too low. The rationale behind this choice is to have a constant force\nin addition to the force from the structural potential which leads to a\nconstant shift in pressure. With such an additional potential the radial\ndistribution function does not deteriorate strongly and a re\u2013optimization\nis possible. Reith et al. showed that indeed this pressure correction solved\ntheir initial problem of an unphysically high pressure [17].\n\n3\n\nDynamic Mapping\n\nSimulations in atomistic detail regularly utilize a time\u2013step of 1 femtosecond. This time\u2013step has to be about an order of magnitude shorter than\nthe fastest characteristic time of the system. As customarily the bond\nlengths are fixed using techniques like Shake [38, 39] or Rattle [40, 35]\nthe fastest time\u2013scales in atomistic molecular dynamics are bond vibrations on the order of tens of femtoseconds. With a reasonable use of\ncomputer resources one can then reach into the nano\u2013second time\u2013range.\nThis is long enough to compare to segmental dynamics in NMR experiments [5, 41] but not long enough to compare to large time\u2013scale experiments.\nThe techniques to map the statics of polymers which have been described above lead inherently to larger time\u2013scales as the fastest inherent degrees of freedom are now motions of super\u2013atoms of the size of\nmonomers. If dynamic investigations are desired one has to find a correct\nmapping of the time\u2013scales of the atomistic simulation to the meso\u2013scale.\nOtherwise dynamic experimental comparisons are impossible.\n\n3.1\n\nMapping by chain diffusion\n\nAn obvious candidate for calibrating the time\u2013scale is the chain diffusion\ncoefficient. At large enough times any polymer chain in a melt will end up\nin diffusive motion as soon as all internal degrees of freedom are relaxed.\nThis diffusion can be used to determine the time\u2013scale as long as an\nindependent mapping of the length scale is achieved. The static mapping\ndetermines the length scale; an obvious choice is the size of the monomer or\nthe distance between super\u2013atoms along the chain to obtain a length scale\nfor the coarse\u2013grained simulation [42]. If both simulations, the atomistic\nand the coarse grained can be fully equilibrated in the sense that free\ndiffusion of the whole chain is observed the two diffusion coefficients can\nbe equated and the time\u2013scale is fixed. In most cases a full free diffusion of\nthe atomistic chain can not be reached in reasonable computer time. This\n\n8\n\n\fis especially the case when the coarse\u2013grained simulation should be used\nas a means to efficiently equilibrate the structure from which atomistic\nsimulations will be started.\nNonetheless this technique can be successful. In the case of 10\u2013mers of\npolyisoprene at 413K a dynamic mapping between a fully atomistic and\na very simple coarse grained model is possible [5, 42]. Only chain stiffness\nwas used to perform the mapping. The local chain reorientation in both\nsimulations was the same after the time\u2013scales had been determined by\nthe diffusion coefficient. However, the decay times of the Rouse modes\nwere not equal which showed that the mapping by stiffness alone was too\nsimplistic.\n\n3.2 Mapping through segmental correlation times\nor Rouse model\nIt is often easier to use shorter, local, time scales to map the atomistic\nto the coarse\u2013grained length scale. This allows a mapping also if the\natomistic simulation cannot be simulated into free diffusion. Even if free\ndiffusion can be reached the statistical uncertainty of large time scales is\noften so large that a shorter time scale is a better choice for the mapping.\nCandidates for shorter time\u2013scales are decay times of higher Rouse modes.\nEven if the Rouse model is not a perfect description of the system under\nstudy such a mapping remains meaningful. In that case this time still\ncorresponds to a well defined relaxation time of a chain segment.\nIf such a chain segment consists in the extreme case of only one\nmonomer we end up with the segmental relaxation time or equivalently\nthe reorientation on the monomer scale. This time\u2013scale is very useful for\ndynamic mapping as it can be compared the time\u2013scales in NMR experiments [43].\n\n3.3\n\nDirect Mapping of the Lennard\u2013Jones time\n\nA completely different idea which is independent of the atomistic simulation is the mapping of the Lennard\u2013Jones time to real time. If one\napplies the standard Lennard\u2013Jones units where we measure lengths in \u03c3,\nthe particle diameter, energies in \u01eb the depth of the Lennard\u2013Jones potential, and masses in m the monomer mass, naturally a timescale appears\nwhich is conventionally called the Lennard\u2013Jones time [35, 36].\nr\nm\n\u03c4 =\u03c3\n(12)\n\u01eb\nThis time\u2013scale can be used to perform the mapping to the real time\u2013\nscale [44, 18].\nUsing the polyisoprene models of ref. [5] (atomistic at T = 413K) and\nref. [17, 18] (meso\u2013scale) we get the following differences in the center\u2013\nof\u2013mass diffusion coefficient for a atomistic 10\u2013mer: The Lennard\u2013Jones\ntime leads to Dcom = 16 \u00d7 10\u22126 cm2 /s [18]. If we map the diffusion coefficient directly D is obviously the atomistic result of D = 4.24\u00d710\u22126 cm2 /s.\nThis result was actually obtained by matching the center\u2013of\u2013mass motion\n\n9\n\n\fof two different models and fitting the large scale motion of the coarser\nmodel. This was necessary as even at 413 K the simulation does not move\nthe atomistic 10\u2013mers into free diffusion [5]. Recently for cis\u2013polyisoprene\na united atom model could be brought into free diffusion [43]. In this case\nresults for 8\u2013mers (D = 14 \u00d7 10\u22126 cm2 /s) have been reported which are\nclose to the results for the different trans\u2013PI\u2013models. This indicates that\nthe different mappings are not far from each other but a uncertainty of\nthe order of 2\u20135 has to be taken into account. For polyisoprene this mapping actually gives a reasonable description of the experimental diffusion\ncoefficient [43].\n\n4 Automatic Optimization \u2013 In Coarse\nGraining and Elsewhere\nPolymer coarse\u2013graining is by no means the only or even the first area\nof computer simulations where automatic optimization techniques are applied. Already in the 70s Torrie and Valleau [45, 46] proposed a Monte\nCarlo technique to simplify simulations in complex energy landscapes\nwhich can easily be implemented fully automatically [47, 48, 49]. This\nso\u2013called umbrella sampling bases on the idea that any bias in a Monte\nCarlo simulation can be used as long as it is taken into account in the\nanalysis. For sampling reasons a uniform coverage of the interesting energy area is of advantage as in that case the system does not get trapped\nin any configuration but samples the whole configuration space readily.\nUmbrella sampling has been recently combined with parallel tempering\nto get a fully automatic multicanonical parallel tempering scheme [50].\nAn idea similar in spirit to umbrella sampling is density of states Monte\nCarlo which even in its very first implementation [51,52] was a completely\nautomatic procedure. It abandons the detailed balance criterion of Monte\nCarlo in its early stages of sampling in order to get a better automatic\noptimization. This technique has since been generalized and improved in\na number of ways [53, 54, 32, 55, 56, 57, 58]. All have in common that they\naim at an automatic calculation of the free energy and in that sense the\niterative Boltzmann method discussed above is only a special case of this\nmuch broader class of techniques. It may be worthwhile to think about\nmethod transfer between the Monte Carlo calculations of the partition\nfunction as aimed by umbrella sampling or density of states Monte Carlo\nand polymer coarse graining.\nConclusively one can say that the recent efforts in automatic polymer\ncoarse\u2013graining have led to a a number of very efficient and systematic\ntechniques to map atomistic models onto meso\u2013scale models. Especially,\nthe thermodynamically inspired iterative Boltzmann technique is fast and\nreliable for a number of systems. The main drawback is still the dependence on the single state point. In the transition from the atomistic to\nthe coarse\u2013grained scale we gain a lot of efficiency but loose the generality\nof the atomistic model as the coarse\u2013grained model is optimized to the\natomistic simulation at a defined state point. Especially in an effort to\ngeneralize the coarse graining to polymer mixtures this problem becomes\n\n10\n\n\fapparent [59]\nThe state of the art in dynamic mapping is much less clear than the\nstructural optimization. As the optimized force\u2013fields up to now aim\nexclusively at the structural or thermodynamic properties the dynamic\nmapping is an ad hoc step which may or may not be successful. This is\nespecially true if solutions are to be mapped as the idea of coarse\u2013graining\nis to get rid of the solvent. However, the solvent has a marjed effect on the\ndynamics which in the coarser simulations without solvent is not present.\nTo overcome this problem and include the dynamic effects of the solvent\nwithout explicit solvent lattice\u2013Boltzmann simulations may be the way\nto go [60]. In the case of melt simulations the solvent effects are not the\nproblem but the resulting force\u2013fields are up to now not able to get all the\ncharacteristic times correct at the same time so that a lot of work remains\nto be done.\n\nAcknowledgments\nMany fruitful discussions with Markus Deserno, Juan de Pablo, Kurt\nKremer, Florian M\u00fcller\u2013Plathe, Hendrik Meyer, Dirk Reith, and Doros\nTheodorou are gratefully acknowledged. I especially want to thank Qi\nSun for some analysis of the cis\u2013PI system.\n\nReferences\n[1] Paul, W., Yoon, D. Y., Smith, G. D. J Chem Phys 1995;103(4):1702.\n[2] Moe, N. E., Ediger, M. D. Macromolecules 1996;29(16):5484.\n[3] M\u00fcller-Plathe, F. Chem Phys Lett 1996;252(5-6):419.\n[4] Antoniadis, S. J., Samara, C. T., Theodorou, D. N. Macromolecules\n1998;31(22):7944.\n[5] Faller, R., M\u00fcller-Plathe, F., Doxastakis, M., Theodorou, D. Macromolecules 2001;34(5):1436.\n[6] Grest, G. S., Kremer, K. Phys Rev A 1986;33(5):R3628.\n[7] Kremer, K., Grest, G. S. J Chem Phys 1990;92(8):5057.\n[8] Faller, R., M\u00fcller-Plathe, F., Heuer, A. Macromolecules 2000;\n33(17):6602.\n[9] Murat, M., Kremer, K. J Chem Phys 1998;108(10):4340.\n[10] Tsch\u00f6p, W., Kremer, K., Batoulis, J., B\u00fcrger, T., Hahn, O. Acta\nPolymer 1998;49(2-3):61.\n[11] McCoy, J. D., Curro, J. G. Macromolecules 1998;31(26):9362.\n[12] Baschnagel, J., Binder, K., Doruker, P., Gusev, A. A., Hahn, O.,\nKremer, K., Mattice, W. L., M\u00fcller-Plathe, F., Murat, M., Paul, W.,\nSantos, S., Suter, U. W., Tries, V. Adv Polymer Sci 2000;152:41.\n[13] Akkermans, R. L. C., Briels, W. J. J Chem Phys 2001;114(2):1020.\n[14] Akkermans, R. L. C., A structure-based coarse-grained model for\npolymer melts. Ph.D. thesis, University of Twente, 2000.\n\n11\n\n\f[15] Fukunaga, H., Takimoto, J., Doi, M. J Chem Phys 2002;\n116(18):8183.\n[16] M\u00fcller-Plathe, F. ChemPhysChem 2002;3(9):754.\n[17] Reith, D., P\u00fctz, M., M\u00fcller-Plathe, F. J Comput Chem 2003;\n24(13):1624.\n[18] Faller, R., Reith, D. Macromolecules 2003;36(14):5406.\n[19] M\u00fcller-Plathe, F. Soft Materials 2003;1(1):1.\n[20] Tsige, M., Curro, J. G., Grest, G. S., McCoy, J. D. Macromolecules\n2003;36(6):2158.\n[21] Meyer, H., Biermann, O., Faller, R., Reith, D., M\u00fcller-Plathe, F. J\nChem Phys 2000;113(15):6264.\n[22] Reith, D., Meyer, H., M\u00fcller-Plathe, F. Macromolecules 2001;\n34(7):2335.\n[23] Strobl, G., The Physics of Polymers. 2nd ed., Berlin: Springer Verlag,\n1997.\n[24] Hahn, O., Delle Site, L., Kremer, K. Macromolecular Theory and\nSimulation 2001;10(4):288.\n[25] Abrams, C. F., Kremer, K. Macromolecules 2003;36(1):260.\n[26] Weeks, J. D., Chandler, D., Andersen, H. C. J Chem Phys 1971;\n54(12):5237.\n[27] Eilhard, J., Zirkel, A., Tsch\u00f6p, W., Hahn, O., Kremer, K., Sch\u00e4rpf,\nO., Richter, D., Buchenau, U. J Chem Phys 1999;110(3):1819.\n[28] Press, W. H., Teukolsky, S. A., Vetterling, W. T., Flannery, B. P.,\nNumerical Recipes in C: The Art of Scientific Computing. 2nd ed.,\nNew York: Cambridge University Press, 1992.\n[29] Faller, R., Schmitz, H., Biermann, O., M\u00fcller-Plathe, F. J Comput\nChem 1999;20(10):1009.\n[30] Bourasseau, E., Haboudou, M., Boutin, A., Fuchs, A. H., Ungerer,\nP. J Chem Phys 2003;118(7):3020.\n[31] Engkvist, O., Karlstr\u00f6m, G. Chem Phys 1996;213(1-3):63.\n[32] Kim, E. B., Faller, R., Yan, Q., Abbott, N. L., de Pablo, J. J. J\nChem Phys 2002;117(16):7781.\n[33] M\u00fcller-Plathe, F., Schmitz, H., Faller, R. Prog Theor Phys Kyoto\nSupplements 2000;138:311.\n[34] Andersen, H. C. J Chem Phys 1980;72(4):2384.\n[35] Allen, M. P., Tildesley, D. J., Computer Simulation of Liquids. Oxford: Clarendon Press, 1987.\n[36] Frenkel, D., Smit, B., Understanding Molecular Simulation: From\nBasic Algorithms to Applications. San Diego, CA: Academic Press,\n1996.\n[37] Briels, W. J., Akkermans, R. L. C. Molecular Simulation 2002;28(12):145.\n\n12\n\n\f[38] Ryckaert, J.-P., Cicotti, G., Berendsen, H. J. C. J Comput Phys\n1977;23(3):327.\n[39] M\u00fcller-Plathe, F., Brown, D. Comput Phys Commun 1991;64(1):7.\n[40] Andersen, H. C. J Comput Phys 1983;72(1):2384.\n[41] Budzien, J., Raphael, C., Ediger, M. D., de Pablo, J. J. J Chem Phys\n2002;116(18):8209.\n[42] Faller, R., M\u00fcller-Plathe, F. Polymer 2002;43(2):621.\n[43] Doxastakis, M., Theodorou, D. N., Fytas, G., Kremer, F., Faller,\nR., M\u00fcller-Plathe, F., Hadjichristidis, N. J Chem Phys 2003;\n119(13):6883.\n[44] Reith, D., Neue Methoden zur Computersimulation von Polymersystemen auf verschiedenen L\u00e4ngenskalen und ihre Anwendung. PhD\nthesis, MPI f\u00fcr Polymerforschung and Universit\u00e4t Mainz, 2001, published at http://archimed.uni-mainz.de/pub/2001/0074.\n[45] Torrie, G. M., Valleau, J. P. Chem Phys Lett 1974;28(4):578.\n[46] Torrie, G. M., Valleau, J. P. J Comp Phys 1977;23(2):187.\n[47] Beutler, T. C., Van Gunsteren, W. F. J Chem Phys 1994;100(2):1492.\n[48] Roux, B. Comput Phys Commun 1995;91(1-3):275.\n[49] Bartels, C., Karplus, M. J Comput Chem 1997;18(12):1450.\n[50] Faller, R., Yan, Q., de Pablo, J. J. J Chem Phys 2002;116(13):5419.\n[51] Wang, F., Landau, D. P. Phys Rev Lett 2001;86(10):2050.\n[52] Wang, F., Landau, D. P. Phys Rev E 2001;64(5):056101.\n[53] Calvo, F. Mol Phys 2002;100(21):3421.\n[54] Yan, Q., Faller, R., de Pablo, J. J. J Chem Phys 2002;116(20):8745.\n[55] Faller, R., de Pablo, J. J. J Chem Phys 2003;119(8):4405.\n[56] Shell, M. S., Debenedetti, P. G., Panagiotopoulos, A. Z. J Chem\nPhys 2003;119(18):9406.\n[57] Troyer, M., Wessel, S., Alet, F. Phys Rev Lett 2003;90(12):120201(1.\n[58] Yan, Q., de Pablo, J. J. Phys Rev Lett 2003;90(3):035701.\n[59] Sun, Q., Faller, R., Automatic mapping of polymer mixtures: Polyisoprene and polystyrene, in preparation.\n[60] Ahlrichs, P., D\u00fcnweg, B. J Chem Phys 1999;111(17):8225.\n\n13\n\n\fa)\n\nb)\nC\nC\n\nC\n\nC\n\nC\n\nC\nC\n\nc)\n\nC\n\nC\n\nC\n\nC\nC\n\nC\n\nC\nC\n\nC\n\nC\n\nC\n\nC\n\nC\n\nC\n\nC\n\nC\n\nC\nC\n\nC\n\nC\n\nd)\n\nC\nC\n\nC\n\nC\nC\nC\n\nC\n\nC\n\nC\n\nFigure 1: Illustration of super\u2013atoms representing polymers. The hydrogens are\nleft out for clarity. a) Cis\u2013polyisoprene physical monomer, center of the super\natom in the middle of the double bond b) polyisoprene pseudomonomer, center\nof the super atom between two physical monomers c) Polystyrene. Super\u2013atom\ncenter on the single bond in the monomer d)Polystyrene. Super\u2013atom center in\nthe center of the ring. All the super\u2013atom centers are marked by black dots.\n\n14\n\n\f25\n\n5\n\nVbond/kBT\n\ncounts\n\n20\n15\n10\n\n0\n\n5\n0\n0.2\n\n0.3\n\n0.4\nr [nm]\n\n-5\n0.3\n\n0.5\n\n0.4\nr [nm]\n\n0.5\n\nFigure 2: Left: Bond length distributions arising from the possible choices of\nsuper\u2013atoms in cis\u2013polyisoprene of Figure 1. The single peaked solid line corresponds to the center of the super\u2013atom on the single bond between atomistic\nmonomers (Fig. 1b), the dashed line to the super\u2013atom in the center of the\ndouble bond (Fig. 1a). All histograms are normalized that the integral equals\n1. Right: Bond potentials gained by direct Boltzmann inversion of the distributions of the left hand side (same line styles). The thin broken line is a\nharmonic fit to the pseudomonomer potential. Curves were locally smoothed\nfor differentiability.\n\n15\n\n\fFigure 3: The scheme of Mc. Coy et al. uses different degrees of detail in\nthe very same simulation. The figure shows two particles which exist on both\nscales. These interact by their atomistic potentials. The atomistically detailed\ninteract with the purely mesoscopic by the mesoscopic potential as do the purely\nmesoscopic among themselves. Some of the particles are bonded to form a\npolymer.\n\n16\n\n\fFigure 4: Top: Schematic explanation of the Iterative Boltzmann procedure.\nOn the lower left hand side (step 2) different stages of the potential are shown,\non the upper right hand side (step 3) the corresponding radial distribution\nfunctions are depicted. Note that these sketches are for illustrative purposes only\nin order to emphasize the influence of the iteration. Final radial distribution\nfunctions and potentials for polyisoprene [18, 17] are shown in the bottom part\nof the figure. The target function (solid line) and the one gained by the iterative\nBoltzmann method (marked IBM\u2013optimized, dashed line) are indistinguishable.\nFor comparison a simplex optimized structure (open circles) is shown. The\nresulting potentials are in the lower part of that subfigure.\n17\n\n\f"}