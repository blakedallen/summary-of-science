{"id": "http://arxiv.org/abs/0910.5682v1", "guidislink": true, "updated": "2009-10-29T17:19:01Z", "updated_parsed": [2009, 10, 29, 17, 19, 1, 3, 302, 0], "published": "2009-10-29T17:19:01Z", "published_parsed": [2009, 10, 29, 17, 19, 1, 3, 302, 0], "title": "Word Sense Disambiguation Using English-Spanish Aligned Phrases over\n  Comparable Corpora", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0910.1139%2C0910.5735%2C0910.0017%2C0910.4221%2C0910.3316%2C0910.1820%2C0910.2797%2C0910.3260%2C0910.5473%2C0910.0287%2C0910.3387%2C0910.3753%2C0910.2085%2C0910.4946%2C0910.2288%2C0910.1130%2C0910.3738%2C0910.2222%2C0910.1329%2C0910.4607%2C0910.3090%2C0910.4121%2C0910.3390%2C0910.3942%2C0910.2129%2C0910.2950%2C0910.3391%2C0910.4958%2C0910.4174%2C0910.1631%2C0910.2803%2C0910.3780%2C0910.1137%2C0910.2078%2C0910.5016%2C0910.3783%2C0910.5505%2C0910.1900%2C0910.1589%2C0910.2547%2C0910.2143%2C0910.4872%2C0910.0859%2C0910.2685%2C0910.4581%2C0910.2536%2C0910.5439%2C0910.3315%2C0910.5061%2C0910.5258%2C0910.2573%2C0910.3159%2C0910.3056%2C0910.2157%2C0910.4938%2C0910.2629%2C0910.5383%2C0910.3873%2C0910.3654%2C0910.3138%2C0910.2569%2C0910.3517%2C0910.3116%2C0910.5028%2C0910.1164%2C0910.1965%2C0910.1996%2C0910.0281%2C0910.5682%2C0910.3423%2C0910.2822%2C0910.3354%2C0910.5627%2C0910.1629%2C0910.2795%2C0910.1836%2C0910.5536%2C0910.1212%2C0910.4024%2C0910.4278%2C0910.2068%2C0910.2824%2C0910.2102%2C0910.1943%2C0910.5073%2C0910.3822%2C0910.3009%2C0910.1386%2C0910.4187%2C0910.0179%2C0910.5189%2C0910.3275%2C0910.5276%2C0910.3582%2C0910.0165%2C0910.1499%2C0910.4927%2C0910.2664%2C0910.2949%2C0910.2040%2C0910.0820&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Word Sense Disambiguation Using English-Spanish Aligned Phrases over\n  Comparable Corpora"}, "summary": "In this paper we describe a WSD experiment based on bilingual English-Spanish\ncomparable corpora in which individual noun phrases have been identified and\naligned with their respective counterparts in the other language. The\nevaluation of the experiment has been carried out against SemCor.\n  We show that, with the alignment algorithm employed, potential precision is\nhigh (74.3%), however the coverage of the method is low (2.7%), due to\nalignments being far less frequent than we expected.\n  Contrary to our intuition, precision does not rise consistently with the\nnumber of alignments. The coverage is low due to several factors; there are\nimportant domain differences, and English and Spanish are too close languages\nfor this approach to be able to discriminate efficiently between senses,\nrendering it unsuitable for WSD, although the method may prove more productive\nin machine translation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0910.1139%2C0910.5735%2C0910.0017%2C0910.4221%2C0910.3316%2C0910.1820%2C0910.2797%2C0910.3260%2C0910.5473%2C0910.0287%2C0910.3387%2C0910.3753%2C0910.2085%2C0910.4946%2C0910.2288%2C0910.1130%2C0910.3738%2C0910.2222%2C0910.1329%2C0910.4607%2C0910.3090%2C0910.4121%2C0910.3390%2C0910.3942%2C0910.2129%2C0910.2950%2C0910.3391%2C0910.4958%2C0910.4174%2C0910.1631%2C0910.2803%2C0910.3780%2C0910.1137%2C0910.2078%2C0910.5016%2C0910.3783%2C0910.5505%2C0910.1900%2C0910.1589%2C0910.2547%2C0910.2143%2C0910.4872%2C0910.0859%2C0910.2685%2C0910.4581%2C0910.2536%2C0910.5439%2C0910.3315%2C0910.5061%2C0910.5258%2C0910.2573%2C0910.3159%2C0910.3056%2C0910.2157%2C0910.4938%2C0910.2629%2C0910.5383%2C0910.3873%2C0910.3654%2C0910.3138%2C0910.2569%2C0910.3517%2C0910.3116%2C0910.5028%2C0910.1164%2C0910.1965%2C0910.1996%2C0910.0281%2C0910.5682%2C0910.3423%2C0910.2822%2C0910.3354%2C0910.5627%2C0910.1629%2C0910.2795%2C0910.1836%2C0910.5536%2C0910.1212%2C0910.4024%2C0910.4278%2C0910.2068%2C0910.2824%2C0910.2102%2C0910.1943%2C0910.5073%2C0910.3822%2C0910.3009%2C0910.1386%2C0910.4187%2C0910.0179%2C0910.5189%2C0910.3275%2C0910.5276%2C0910.3582%2C0910.0165%2C0910.1499%2C0910.4927%2C0910.2664%2C0910.2949%2C0910.2040%2C0910.0820&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper we describe a WSD experiment based on bilingual English-Spanish\ncomparable corpora in which individual noun phrases have been identified and\naligned with their respective counterparts in the other language. The\nevaluation of the experiment has been carried out against SemCor.\n  We show that, with the alignment algorithm employed, potential precision is\nhigh (74.3%), however the coverage of the method is low (2.7%), due to\nalignments being far less frequent than we expected.\n  Contrary to our intuition, precision does not rise consistently with the\nnumber of alignments. The coverage is low due to several factors; there are\nimportant domain differences, and English and Spanish are too close languages\nfor this approach to be able to discriminate efficiently between senses,\nrendering it unsuitable for WSD, although the method may prove more productive\nin machine translation."}, "authors": ["David Fernandez-Amoros"], "author_detail": {"name": "David Fernandez-Amoros"}, "author": "David Fernandez-Amoros", "arxiv_comment": "latex2e, 8 pages, 1 figure, published in the Proceedings of\n  Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca, held during\n  the summer school EUROLAN 2005", "links": [{"href": "http://arxiv.org/abs/0910.5682v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0910.5682v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0910.5682v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0910.5682v1", "journal_reference": null, "doi": null, "fulltext": "Published in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\nWSD Using English-Spanish Aligned Phrases over Comparable Corpora\n\narXiv:0910.5682v1 [cs.CL] 29 Oct 2009\n\nDavid Fern\u00e1ndez-Amor\u00f3s\nDepartamento de Lenguajes y Sistemas Inform\u00e1ticos\nUNED, Madrid\ndavid@lsi.uned.es\n\nAbstract\nIn this paper we describe a WSD experiment based on bilingual English-Spanish\ncomparable corpora in which individual\nnoun phrases have been identified and\naligned with their respective counterparts\nin the other language. The evaluation\nof the experiment has been carried out\nagainst SemCor.\nWe show that, with the alignment algorithm employed, potential precision is\nhigh (74.3%), however the coverage of the\nmethod is low (2.7%), due to alignments\nbeing far less frequent than we expected.\nContrary to our intuition, precision does\nnot rise consistently with the number of\nalignments. The coverage is low due to\nseveral factors; there are important domain differences, and English and Spanish\nare too close languages for this approach\nto be able to discriminate efficiently between senses, rendering it unsuitable for\nWSD, although the method may prove\nmore productive in machine translation.\n\n1 Introduction\nWord Sense Disambiguation (WSD) could be defined as the task of assigning the right sense to a\nword in context given a sense inventory. This is\na problem in artificial intelligence reported at least\nsince the nineteen fifties. There is general consensus in that although it is not a very interesting ques-\n\ntion in itself in many areas (lexicography being the\nobvious exception) deeper understanding of lexical\nambiguity would greatly help to solve some applications of natural language processing and clarify new\nones still to be uncovered.\nHere we present a WSD experiment based on\nbilingual English-Spanish comparable corpora of\nnews collections in which individual noun phrases\nhave been identified and aligned to their counterparts in the other corpus. WordNet (Miller, 1995)\nis a lexical database for English which includes a\nsense inventory among many other things. This\nsense inventory relies in the synset concept. A\nsynset is a synonym set of words with a particular\nmeaning, for instance two synsets associated with\ndifferent senses of church are {church, Christian\nchurch, Christianity} and {church, church building}. An extension of WordNet is EuroWordNet\n(Vossen, 1997). EuroWordNet has a very similar\nstructure to WordNet, but comprises several European languages. In addition, there are links between\nthe concepts in different languages. The evaluation\nof the experiment has been carried out against SemCor (Francis and Kucera, 1967). SemCor is a collection of English texts which has been manually annotated with WordNet senses and for this reason has\noften been used as a test collection for WSD algorithms.\nIn a first step, the noun phrases obtained from\nthe English news articles corpus are searched for in\nSemCor. Next, we associate each of theses phrases\nwith the corresponding aligned phrases in Spanish,\ntogether with the observed alignment frequency in\nthe news collections. In this alignments, there is usu-\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\nally a cognate or at least, one word which is a direct\ntranslation of the other, but the rest of the words in\nthe phrase can give us a clue about the correct sense.\nThe most relevant factors to consider about this\nexperiment with respect to previous research are the\nfollowing:\n\u2022 Parallel vs. Comparable corpora. Many WSD\nalgorithms use a supervised approach that relies on manually tagged examples to learn a\nclassification algorithm. This manual tagging\nis very costly, leading to what has been called\nthe knowledge acquisition bottleneck. A relatively popular approach has been to use parallel texts to extract knowledge automatically.\nThe problem with parallel corpora is that it is\nalso very scarce. Comparable corpora offers\nsome of the advantages of parallel corpora with\na much higher availability but at the cost of obtaining inferior quality knowledge.\n\u2022 Phrase detection. It is not straightforward to\ndetect noun phrases in different languages. We\ndon't know how big the impact of errors in detection is for the accuracy of this approach.\n\u2022 Phrase aligning.\nAgain, the precision of\nthe alignments between phrases (about 73%),\nmight affect the performance of the system.\n\u2022 The domain problem. It is well-known that extracting knowledge in one domain and trying\nto apply it in another one is generally a bad\nidea. Ideally one should use the same domain\nfor both tasks, however, it is unlikely for large\nunrestricted domain comparable corpora to be\nwidely available in the near future.\n\u2022 It is generally accepted that one important obstacle for WSD is that cross language linguistic effort has traditionally focused on bilingual\ndictionaries and the like, which work at word\nlevel or higher and that a reliable cross language man-made tool at the sense level would\ngreatly contribute to the solution of the problem. Fortunately such resources now exist; the\nset of interlingual indices in EuroWordNet is an\nexample.\nIn the second section we discuss previous work in\nthe field together with a motivating example. In the\n\nfollowing section we describe the experiment. In the\nthird section we present the evaluation and results,\nwith several successful and unsuccessful examples\nand in the fourth section we draw our conclusions\nand suggest future work.\n\n2 Previous work\nThe basic idea, is similar to the approach in\n(Gale et al., 1993) which uses the English-French\nparallel corpus of the Canadian Hansards, although\nthe fundamental unit from which information is\nextracted is not the word but the noun phrase,\nmuch less ambiguous in general. It allows discarding the senses of individual words when translating with a bilingual dictionary. Our approach\nis more related to the work in (Dagan et al., 1991;\nDagan and Itai, 1994) which uses pairs of syntactically related words.\nThis idea that different senses of the same\nword often translate to different words in a second language was also an argument to suggest\na new method of evaluating WSD systems in\n(Resnik and Yarowsky, 1999). The paper presents\na formula to calculate the relatedness of two word\nsenses according to the translations to a second language. Another novelty is the generalization of the\nmethod to several pairs of languages instead of just\none.\nThe noun phrases in English and Spanish have been taken from work described in\n(Penas, 2002) and the alignment between them\nis explained in (L\u00f3pez-Ostenero et al., 2002;\nL\u00f3pez-Ostenero, 2002). The alignment algorithm\nused has the advantage that corpora doesn't have\nto be parallel, just comparable. The phrases were\npresented to Spanish human evaluators in the\ninteractive track of the CLEF'02 competition. The\nevaluators had to find documents in a database\nrelevant to a query in English with the aid of text\nfragments in Spanish. Using the phrases in Spanish\naligned with the phrases in the English documents\nas aid fragments considerably outperformed SYSTRAN automatic translations of the documents.\nThese good results motivated the crossover attempt\nto WSD.\nFor the sake of clarity, we sketch the procedure\nfollowed to create the dictionary of aligned phrases.\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\nThe CLEF collections used to extract the phrases\nare a Spanish corpus made of 1994 news from Spanish news agency EFE and an English corpus containing articles published by Los Angeles Times also in\n1994.\nThe first step is to identify the noun phrases. For\nSpanish, words are lemmatized and POS tagged.\nAfter that process, chunks of words fitting the following pattern are automatically considered noun\nphrases.\n(noun | adjective) (noun | adjective | preposition |\ndeterminer | conjunction )* (noun | adjective)\nOnly phrases with two or three open-class words\nare considered because the amount of longer phrases\nthat can be aligned rapidly decreases. This process\nidentified more than twenty-seven million alleged\nnoun phrases in the corpus.\nAs far as English is concerned, each word was assigned the prior most likely POS tag. The pattern\nfor identifying patterns was the same as in Spanish. More than nine million noun phrases for English\nwere identified this way.\nThe alignment has been carried out with a bilingual resource. The phrases with two open-class\nwords are aligned with two open-class word phrases\nin the other language and so on for three open-class\nword phrases. The other constraint required to align\nis that each open-class word in a phrase translates\nto an open-class word in the candidate phrase in\nthe other language. The real alignment algorithm is\nsomewhat more complicated but the details can be\nfound in the referenced articles.\nIt has been shown in these articles that the precision in recognizing noun phrases is high. The precision of the alignments has been estimated in excess\nof 73%, and the correction in the alignment correlates with the absolute frequency of the phrases, that\nis, an alignment between commoner phrases is more\nlikely to be correct.\nWe illustrate the idea with the following example1 :\nWe want to disambiguate issue, which can be\ntranslated in Spanish as: asunto, tema, n\u00famero,\nemisi\u00f3n, expedici\u00f3n, descendencia, publicar, emitir,\nexpedir, dar y promulgar. At this point we detect\nthat the context of the word indicates that it is part\n1\n\nAdapted from (L\u00f3pez-Ostenero et al., 2002)\n\nof the phrase abortion issue. This phrase has been\naligned with the phrase in Spanish tema del aborto.\nIf we were doing machine translation, we would\nbe satisfied with this translation, however, in the\nframework of WSD we would like to discard the\nsenses of issue not corresponding to the tema translation. Unfortunately, WordNet structure does not\npermit obtaining that information easily. The key\nthen, is to associate individual word senses to translations in the other language, going one step further\nfrom the word to word translation.\n\n3 The experiment\nIn this section we describe the experiment. We start\nwith the resource of the bilingual phrases and the interlingual indices (ILI) in EuroWordNet and we perform WSD in the SemCor collection.\nThe approach we have taken uses EuroWordNet\ninterlingual indices. These indices map the synsets\nfrom one EuroWordNet language to another so that,\nin the previous example, we could use them to look\nup the synsets associated with issue in Spanish and\nfind out which of them hold the word tema. One\ndrawback with this approach is that EuroWordNet\ntaxonomy is linked in English with the concepts in\nWordNet-1.5, which is a little outdated. We want\nto apply our system to the senses in WordNet-1.7.\nThis will allow the system, to be tested in the short\nterm with the latest SENSEVAL (Kilgarriff, 1998)\ncollections and thus compared with state-of-the-art\nparticipating systems. To overcome this version\nconflict we use the mappings from versions 1.5 to\n1.6 and from 1.6 to 1.7 of WordNet developed in\n(Daud\u00e9 et al., 2000; Daud\u00e9 et al., 2001).\nAs we want to disambiguate a target word, we\nfirst look at the context to determine if the word belongs to one of the phrases with alignments in our\nknowledge base. We construct a simple automaton\nto implement a detection algorithm which takes into\naccount inflectional variants. We create a forest in\nwhich trees have words as labels. Each tree contains all the phrases beginning with a certain word.\nFor each possible continuation of a phrase beginning\nwith that word we have a child node with the corresponding label. Some nodes as also labeled as acceptance nodes, marking the end of a legal phrase\n(although there might be longer phrases with the\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\nsame prefix). To detect the phrases in the text, a\nword is read and looked up in the heads of the trees\nto check for a match (two words match if their lemmas are the same). If there is a the next word is read\non and tried to match with the label of one of the\nchildren nodes, and so forth until no more matches\nare possible. If an acceptance node has been traversed then a noun phrase has been found and the\nunused portion of the input is restored to the input\nbuffer in order for the search to continue. Longer\nphrases are preferred over shorter ones in case several acceptance nodes have been traversed. This algorithm takes linear time to detect the phrases.\nIf the word belongs to a noun phrase, we traverse\nthe list of the phrases aligned with it in Spanish.\nFor every word in each Spanish phrase, we look for\nthe synsets associated with their senses and, using\nthe ILI, their associated English synsets. If any of\nthese synsets contains the target word, then the corresponding sense is kept, otherwise it is discarded.\nWe have carried out this process for all alignments, and we have possibly discarded some senses\nof the word. This way, we use these comparable\ncorpora as a resource to create a filter, since several\nsenses may remain for every word. Coverage is expected to be low, still, a high precision at discarding\nwrong senses would make it a worthwhile approach\nsince that would encourage further research, possibly scaling up to multiple pairs of languages instead\nof one.\nThe first step to prepare the experiment has consisted of automatically re-annotating SemCor. SemCor has manual annotations in SGML of lemma,\npart of speech, WordNet sense and even compound\nwords, among others, but of course the information\nabout our dictionary of phrases is not included so\nwe translated it into XML form and added, for the\nwords belonging to aligned phrases, one attribute,\nphrase, which indicates the detected phrase, and another, alignments, which shows a list of admissible\nsenses with respect to the algorithm just described,\nalong with the frequency with which the corpora allowed a particular alignment supporting that sense.\nThis information is important, because reliability of\nalignment is supposed to directly depend on its frequency.\nSo, for instance, this SemCor fragment:\n<wf cmd=\"done\" pos=\"NN\" lemma=\"number\"\n\nwnsn=\"2\"\n\nlexsn=\"1:23:00::\">number</wf>\n\n<wf cmd=\"ignore\" pos=\"IN\">of</wf>\n<wf cmd=\"done\" pos=\"NN\" lemma=\"voter\"\nwnsn=\"1\" lexsn=\"1:18:00::\">voters</wf>\n\nWould now look like this:\n<wf alignments=\"number%1:07:00:: 51\nnumber%1:10:00:: 51 number%1:10:01:: 51\nnumber%1:10:02:: 51 number%1:10:03:: 51\nnumber%1:10:04:: 51 number%1:10:05:: 51\nnumber%1:23:00:: 51\" cmd=\"done\"\nlemma=\"number\" lexsn=\"1:23:00::\"\nphrase=\"number of voters\" pos=\"NN\"\nwnsn=\"2\">number</wf>\n<wf cmd=\"ignore\" pos=\"IN\">of</wf>\n<wf cmd=\"done\" lemma=\"voter\"\nlexsn=\"1:18:00::\"\npos=\"NN\" wnsn=\"1\">\nvoters</wf>\n\nIt is interesting to note that number has eleven\nsenses in WordNet-1.7, of which now only eight are\nequally amenable to be chosen.\n\n4 Evaluation and results\nWe have evaluated this approach against SemCor.\nThis decision is supported by the fact that it is a\ntest collection whose size allows drawing more representative conclusions than from other, smallersized collections, such as those in SENSEVAL\n(Kilgarriff, 1998).\nIn the process of re-tagging the collection, out of\nthe 192840 words amenable for disambiguation in\nbrown-1 and brown-2 segments, we detected 10787\nEnglish phrases, which make up for 5.6% of the\nwords. This phrases have alignments in Spanish in\n5290 cases, so we filtered senses for this number of\nwords, 2.74% of the total. Among them, the right\nsense has remained unfiltered in 3922 cases. That\nis, the filtering process has a potential precision of\n74.33%.\nOne example in which the algorithm doesn't work\nas expected is in disambiguating friend in the phrase\nfriend of mine. The alignment in Spanish was conocido de las minas (which could be translated as acquaintance of the mines). There are two relevant observations. First of all, the Spanish phrase probably refers to a well-known flamenco festival which\nis a proper noun and should therefore not be aligned\nwith a common one. An entity recognition module,\neven one as simple as considering initial capital letters, should have ruled this alignment out. Second,\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\none has to wonder how high can the degree of overlapping between the news in both collections be.\nIt is obvious that alignment techniques need to be\nimproved. However, since these two phrases only\nwere aligned once we felt the need to test the correlation between frequency of alignments and potential precision susceptible of being achieved.\nIn order to shed some light on the subject we\nrepeated the experiment adding a threshold. This\ntime we only disambiguate words in phrases having alignments with Spanish phrases when the alignment frequency is over the threshold. Results can be\nseen in figure 1.\n100\n80\n60\n40\n20\n0\n0\n\n200\n400\n600\n800\nThreshold of alignments\n\n1000\n\nPotential Precision(%)\nAligned phrases over threshold(%)\nFigure 1: Relation between threshold, coverage and\npotential precision\n\nThe results are surprising: Potential precision does\nnot really increase with increasing threshold values.\nUp to 3000 occurrences2 , there is hardly any difference in potential precision. From there, the number\nof phrases with alignments is so low (with a threshold of 3000 occurrences the number of phrases with\nalignments in SemCor is just 38) that the information is useless. Potential precision of 100% from a\nthreshold value of 8713 until the end (8836) corresponds solely to alignments of the phrase year old,\nwhich equally support all four senses of year, so, at\nthat point the information coming from the aligned\nphrases is totally irrelevant.\nAs we can see, the coverage of the approach is\nrather low, but the method really works, even when\nalignments are only of modest quality, to say the\n2\n\nNot shown in the graphic due to the almost negligible percentage of phrases aligned\n\nleast. As a remarkable example, the noun phrase\nhead of the family was aligned eight times with the\nphrase responsable de la c\u00e1mara. Head has 132 different senses as a noun in WordNet-1.7. C\u00e1mara\ndoesn't help but responsable has two senses. One of\nthem is {autor, culpable, perpetrador, responsable}\nwhich the ILI links to the English synset {culprit,\nperpetrator}, which doesn't support any of the many\nsenses of head. However, the other sense of responsable corresponds to the synset {responsable}, linked\nby ILI to the English synset {head, chief, top dog}\nsupporting the correct sense of head in the original\nphrase.\nThe mappings between WordNet versions and the\nInterlingual indices get sometimes in the way of\nthe success. For the sake of clarity we will use\nthe sense notation in WordNet instead of the associated synsets. The sense notation refers to a\nset of lexicographer tematic files. For an illustration of both problems in one example, consider\nthe phrase art studies. It is aligned with estudios de arte (again, a reasonably related phrase,\nbut highly unsuitable as a translation). Arte has\nfour senses: arte%1:04:00:: which goes through\nILI plus the mappings to art%1:04:00::, a second\none arte%1:06:00:: which points to art%1:06:00::,\na third one, arte%1:09:00:: which ILI points to\nart%1:09:00:: but the mappings just don't map to\nanything at all, and the last sense which starts out\nas arte%1:10:00:: and ends up as art%1:10:00:: as\nexpected.\nThe mappings are not complete and therefore occasionally fail to upgrade a sense to the newer version, but it is more disturbing to verify that art and\narte are given the exact same semantic structure in\nEuroWordNet as far as the algorithm is concerned.\n\n5 Conclusions and future work\nWe had hoped that use of comparable corpora would\nhelp alleviate the knowledge acquisition bottleneck.\nThe corpora, according to the millions of noun\nphrases detected, seemed indeed bigger than many\nparallel corpora available, and the scaling possibilities are obvious, just add more years to the news\ncollections. Nevertheless, the scarceness of alignments has produced an extremely low coverage for\nthe WSD algorithm. It is thus, very unclear that\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\nbigger comparable corpora would help WSD in this\nspecific approach.\nThe domain problem has undeniably and heavily affected the experiment. The Brown Corpus of\nwhich SemCor is a portion, was compiled from texts\nprinted in 1961. The news thirty-four years later\nsurely cover different topics, many of which didn't\neven exist back in 1961. One of the alignment examples cited in (L\u00f3pez-Ostenero, 2002) is free trade\nagreement which aligns with tratado de libre comercio. Even worse is that the noun phrases present\nin SemCor hardly occur in the LAT '94 collection.\nThis is not a problem of the noun-phrase approach,\nbut a serious domain problem. The question is that\nSemCor is big enough to allow interesting conclusions to be extracted from experiments as far as\nstatistics are concerned, but very old with respect to\nmodern texts. There are more recent hand annotated\ncollections, however they are much smaller-sized\nand thus unfit for statistically relevant purposes.\nAlso, regarding domain, it is reasonable to suspect\nthat the differences between the news domain used\nto gather the phrases and the SemCor collection, a\npart of the Brown Corpus, which was collected with\nthe aim of being domain-free, might have influenced\nthe results.\nAnother interesting question regarding coverage\nis how comparable comparable corpora really are.\nOstenero reports 38% of the English two-openclass-word noun-phrases to have been aligned to\nSpanish ones so the corpora seem moderately comparable.\nThe mappings used to convert WordNet-1.5\nsynsets to version 1.7 have been assessed by their\nauthors to have a precision around 90%. Since we\nhave applied two mappings (1.5 \u2192 1.6 and 1.6 \u2192\n1.7) we can estimate the probability of correctly\nmapping a sense as being .9*.9=.81. That would\naccount for 19% of the senses disappearing in the\nprocess, so the real reduction of ambiguity due to\nthe bilingual noun-phrase approach has to be lower\nthan the overall figures apparently indicate.\nThe ILI has proven to be somewhat disappointing. In spite of being heavily advertised as one the\nof the most outstanding achievements in EuroWordNet, it turns out that the language neutral representation of nominal entries to which the ILI point is\nprecisely the nominal structure of the original En-\n\nglish WordNet-1.5. Moreover, in the Spanish nominal structure the contents of the synonyms sets differ from the English ones but the network structure\nof hypernyms and other relations is the same except when there is no equivalent concept in Spanish or the obvious linking is inapplicable. That, plus\nthe fact the the ILI is semi-automatically constructed\nand only manually revised, amounts to the English\nand Spanish nominal structures being so close that\nthe ILI coincides more often than desirable with the\nidentity function. This fact is quite clear in the sense\nfile notation, although the synset-offset number notation provides a rather awkward encoding for this\napproximation of the function f(x)=x. This may not\nbe an issue with pairs of languages other than English but in this case is a factor that requires further\nresearch.\nThe phrase detection algorithm is in its first stages\nof development and there is much room for improvement, although it is unknown if such improvements\nwill effectively help WSD.\nThe alignment technique employed is also not exempt of problems. The algorithm seems very sound\nwith respect to finding correct alignments, although\nwe suspect that there is a considerable amount of\nfalse positives. If this problem was solved, potential\nprecision could raise a bit, however it would definitely lower a coverage that is already rather tiny.\nOn the other hand there are cases in which less-thanspectacular quality alignments have proven useful\nfor the task.\nThis series of facts lead us to conclude, in the first\nplace, that although this method constitutes an a priori interesting filter in terms of precision, the rather\nlow coverage of the method produces nearly negligible results for WSD.\nApart from that conclusion, the most interesting\nresult is that, contrary to our intuition, potential precision does not rise consistently with the number\nof alignments. Since the precision of the alignments has been shown to correlate with the frequency of such alignments, the only explanation is\nthat these high-frequency alignments are not productive in terms of filtering senses due to exactly equal\nmapping of senses to words in the two languages.\nWe observed this behaviour in the case of the most\naligned phrase, year old.\nSo, in the case of English and Spanish, it was\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\neasy to predict that there would be many patholog- Acknowledgements\nical cases. For instance, the phrases containing the\nWe are indebted to Julio Gonzalo for coming up with\nword art in English align with phrases containing\nthe idea of applying the noun phrases plus the ILI\narte in Spanish, something which is not producto WSD and for his advice, and to Fernando Lopez\ntive at all, since all the senses of art can be transOstenero for his willing assistance with the bilingual\nlated as arte and so the method does not discard any\nnoun phrase resource.\nsenses. Alignments between more heterogeneous\npairs of languages may improve performance as well\nas adding together the results for comparable cor- References\npora in multiple pairs of languages. That would take\nadvantage of the reasonable hypothesis that ambigu- [Dagan and Itai1994] Ido Dagan and Alon Itai. 1994.\nWord Sense Disambiguation Using a Second Lanities will be different across different pairs of language Monolingual Corpus. Computational Linguisguages. The method may prove more productive\ntics, 20(4):563\u2013596.\nin machine translation, where many different word\nsenses may translate to the same word in the target [Dagan et al.1991] Ido Dagan, Alon Itai, and Ulrike\nSchwall. 1991. Two Languages are More Informalanguage. Of course, the alignments are not directly\ntive than One. In Proceedings of the 29th meeting of\nacceptable translations.\nthe Association for Computational Linguistics, pages\n130\u2013137.\n\nThe potential precision concept used for the evaluation is certainly somewhat fuzzy, in that reduc- [Daud\u00e9 et al.2000] J. Daud\u00e9, L. Padr\u00f3, and G. Rigau.\n2000. Mapping WordNets using structural Information of ambiguity is not specified. Potential precition. In Proceedings of the 38th Annual Meeting of\nsion is not to be confronted with actual precision,\nthe Association for Computational Linguistics (ACL),\nsince this approach only aspires to efficiently discard\nHong Kong.\nsome senses of the words, not to perform full disambiguation. Anyway, the low coverage of the method [Daud\u00e9 et al.2001] J. Daud\u00e9, L. Padr\u00f3, and G. Rigau.\n2001. A Complete WN1.5 to WN1.6 Mapping. In\nallows to discard it for WSD purposes whatever the\nProceedings of the NAACL Workshop WordNet and\nactual ambiguity reduction obtained.\nOther Lexical Resources : Applications Extensions\nand Customization, Pittsburg.\nThese aligning techniques were successfully applied for the CLEF competition [Francis and Kucera1967] S. Francis and H. Kucera.\n(L\u00f3pez-Ostenero et al., 2002), in human-computer\n1967. Computational Analysis of present-day American English. Providence, Rhode Island: Brown Uniinteraction scenario, however this success does not\nversity Press.\ncarry over to the automated WSD problem. It is\ninteresting to note, however, that since in that work [Gale et al.1993] William A. Gale, Kenneth W. Church,\nthe phrases were detected, aligned and used on the\nand David Yarowsky. 1993. A method for disambiguating word senses in a large corpus. Computers\nsame collections, there were no domain problems,\nand the Humanities, 26(5):415\u2013439.\nthus obtaining much higher coverage.\n\nSumming up, the logical future work, in order for [Kilgarriff1998] Adam Kilgarriff. 1998. SENSEVAL:\nAn exercise in evaluating word sense disambiguation\nthis approach to WSD to reach viable status, would\nprograms. In Proceedings of the International Conferideally comprise, among other things, finding large\nence on Language Resources and Evaluation (LREC),\nquantities of moderately parallel corpora in different\npages 581\u2013588, Granada, Spain.\npairs of languages (with one of them fixed as target\nlanguage), of genre and age as close to those of the [L\u00f3pez-Ostenero et al.2002] F. L\u00f3pez-Ostenero, J. Gonzalo, Pe nas Anselmo, and F. Verdejo.\n2002.\ntest collection as possible, preferably without any inNoun phrase translations for Cross-Language Docutervening mappings. The predictable much higher\nment Selection. In Cross Language Evaluation Forum\n(CLEF), number 2406 in Lecture Notes in Computer\ncoverage of the method would then foster the need to\nScience. Springer-Verlag.\nmeasure the actual degree of reduction in ambiguity.\nThe question on the usefulness of the ILI remains [L\u00f3pez-Ostenero2002] F. L\u00f3pez-Ostenero. 2002. Un Sisopen.\ntema Interactivo para la B\u00fasqueda de Informaci\u00f3n en\n\n\fPublished in the Proceedings of Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca\n\nIdiomas Desconocidos por el Usuario. Ph.D. the- [Resnik and Yarowsky1999] Philip Resnik and David\nYarowsky. 1999. Distinguishing Systems and Distinsis, Universidad Nacional de Educaci\u00f3n a Distancia\nguishing Senses: New Evaluation Methods for Word\n(UNED).\nSense Disambiguation. In Journal of Natural Lan[Miller1995] George A. Miller. 1995. WordNet: A Lexguage Engineering, volume 5(2), pages 113\u2013134.\nical Database for English. Communications of the\nACM, 38(11):39\u201341.\n[Vossen1997] Piek Vossen. 1997. Eurowordnet: A multilingual database for information retrieval. In Proceed[Penas2002] Anselmo Penas.\n2002. Website Term\nings of the DELOS workshop on Cross-language InBrowser. Un sistema interactivo y multiling\u00fce de\nformation Retrieval.\nb\u00fasqueda textual basado en t\u00e9cnicas ling\u00fc\u0131\u0301sticas.\nPh.D. thesis, Universidad Nacional de Educaci\u00f3n a\nDistancia (UNED).\n\n\f"}