{"id": "http://arxiv.org/abs/1009.2406v1", "guidislink": true, "updated": "2010-09-13T14:35:41Z", "updated_parsed": [2010, 9, 13, 14, 35, 41, 0, 256, 0], "published": "2010-09-13T14:35:41Z", "published_parsed": [2010, 9, 13, 14, 35, 41, 0, 256, 0], "title": "Adaptation of the neural network-based IDS to new attacks detection", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1009.1319%2C1009.2137%2C1009.3838%2C1009.5401%2C1009.0835%2C1009.5942%2C1009.1981%2C1009.0083%2C1009.5156%2C1009.0515%2C1009.5642%2C1009.4288%2C1009.5678%2C1009.0313%2C1009.2055%2C1009.3964%2C1009.5053%2C1009.4838%2C1009.5544%2C1009.5207%2C1009.3781%2C1009.5604%2C1009.5691%2C1009.3468%2C1009.6184%2C1009.4232%2C1009.2424%2C1009.4926%2C1009.2406%2C1009.0468%2C1009.4744%2C1009.2941%2C1009.0260%2C1009.5132%2C1009.0389%2C1009.4675%2C1009.5152%2C1009.5754%2C1009.2924%2C1009.2558%2C1009.5345%2C1009.0917%2C1009.5267%2C1009.4417%2C1009.3130%2C1009.2846%2C1009.1465%2C1009.5282%2C1009.2108%2C1009.2425%2C1009.0933%2C1009.4115%2C1009.6198%2C1009.0735%2C1009.3808%2C1009.5166%2C1009.1444%2C1009.3093%2C1009.5358%2C1009.0861%2C1009.6205%2C1009.2618%2C1009.3075%2C1009.3922%2C1009.1158%2C1009.4289%2C1009.0560%2C1009.1202%2C1009.1426%2C1009.2995%2C1009.2313%2C1009.4136%2C1009.0408%2C1009.0842%2C1009.0806%2C1009.2845%2C1009.1937%2C1009.5088%2C1009.5723%2C1009.2138%2C1009.5322%2C1009.0063%2C1009.1922%2C1009.5334%2C1009.2593%2C1009.1013%2C1009.1455%2C1009.5182%2C1009.3497%2C1009.2300%2C1009.1295%2C1009.4690%2C1009.0422%2C1009.1781%2C1009.0320%2C1009.2197%2C1009.2543%2C1009.5949%2C1009.2666%2C1009.4821%2C1009.2914&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Adaptation of the neural network-based IDS to new attacks detection"}, "summary": "In this paper we report our experiment concerning new attacks detection by a\nneural network-based Intrusion Detection System. What is crucial for this topic\nis the adaptation of the neural network that is already in use to correct\nclassification of a new \"normal traffic\" and of an attack representation not\npresented during the network training process. When it comes to the new attack\nit should also be easy to obtain vectors to test and to retrain the neural\nclassifier. We describe the proposal of an algorithm and a distributed IDS\narchitecture that could achieve the goals mentioned above.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1009.1319%2C1009.2137%2C1009.3838%2C1009.5401%2C1009.0835%2C1009.5942%2C1009.1981%2C1009.0083%2C1009.5156%2C1009.0515%2C1009.5642%2C1009.4288%2C1009.5678%2C1009.0313%2C1009.2055%2C1009.3964%2C1009.5053%2C1009.4838%2C1009.5544%2C1009.5207%2C1009.3781%2C1009.5604%2C1009.5691%2C1009.3468%2C1009.6184%2C1009.4232%2C1009.2424%2C1009.4926%2C1009.2406%2C1009.0468%2C1009.4744%2C1009.2941%2C1009.0260%2C1009.5132%2C1009.0389%2C1009.4675%2C1009.5152%2C1009.5754%2C1009.2924%2C1009.2558%2C1009.5345%2C1009.0917%2C1009.5267%2C1009.4417%2C1009.3130%2C1009.2846%2C1009.1465%2C1009.5282%2C1009.2108%2C1009.2425%2C1009.0933%2C1009.4115%2C1009.6198%2C1009.0735%2C1009.3808%2C1009.5166%2C1009.1444%2C1009.3093%2C1009.5358%2C1009.0861%2C1009.6205%2C1009.2618%2C1009.3075%2C1009.3922%2C1009.1158%2C1009.4289%2C1009.0560%2C1009.1202%2C1009.1426%2C1009.2995%2C1009.2313%2C1009.4136%2C1009.0408%2C1009.0842%2C1009.0806%2C1009.2845%2C1009.1937%2C1009.5088%2C1009.5723%2C1009.2138%2C1009.5322%2C1009.0063%2C1009.1922%2C1009.5334%2C1009.2593%2C1009.1013%2C1009.1455%2C1009.5182%2C1009.3497%2C1009.2300%2C1009.1295%2C1009.4690%2C1009.0422%2C1009.1781%2C1009.0320%2C1009.2197%2C1009.2543%2C1009.5949%2C1009.2666%2C1009.4821%2C1009.2914&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper we report our experiment concerning new attacks detection by a\nneural network-based Intrusion Detection System. What is crucial for this topic\nis the adaptation of the neural network that is already in use to correct\nclassification of a new \"normal traffic\" and of an attack representation not\npresented during the network training process. When it comes to the new attack\nit should also be easy to obtain vectors to test and to retrain the neural\nclassifier. We describe the proposal of an algorithm and a distributed IDS\narchitecture that could achieve the goals mentioned above."}, "authors": ["Przemyslaw Kukielka", "Zbigniew Kotulski"], "author_detail": {"name": "Zbigniew Kotulski"}, "author": "Zbigniew Kotulski", "arxiv_comment": "9 pages, 3 figures, 4 tables", "links": [{"href": "http://arxiv.org/abs/1009.2406v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.2406v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.2406v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.2406v1", "journal_reference": null, "doi": null, "fulltext": "Adaptation of the neural network-based IDS to new attacks detection\nPrzemys\u0142aw Kukie\u0142ka1, Zbigniew Kotulski2\nResearch and Development Department, Polish Telecom\n2\nInstitute of Telecommunications, Warsaw University of Technology\n{przemyslaw.kukielka@telekomunikacja.pl; zkotulsk@tele.pw.edu.pl}\n1\n\nAbstract. In this paper we report our experiment concerning new attacks detection by a neural\nnetwork-based Intrusion Detection System. What is crucial for this topic is the adaptation of the\nneural network that is already in use to correct classification of a new \"normal traffic\" and of an\nattack representation not presented during the network training process. When it comes to the new\nattack it should also be easy to obtain vectors to test and to retrain the neural classifier. We\ndescribe the proposal of an algorithm and a distributed IDS architecture that could achieve the\ngoals mentioned above.\nKeywords: Internet security, intrusion detection, neural network adaptation\n\n1. Introduction\nBecause of their generalization feature, neural networks are able to work with imprecise and\nincomplete data. It means that they can recognize also patterns not presented during a\nnetwork learning phase. That's why neural networks could be a good solution for detection\nof a well-known attack, which has been modified by an aggressor in order to pass through a\nfirewall system. In that case, traditional Intrusion Detection Systems (IDS), based on the\nsignatures of attacks or expert rules, may not be able to detect such a new version of this\nattack.\nUnfortunately, as it could be noticed in [1] and in the results of our research (Table 2)\nsome representation of the new attack or the normal traffic not presented during the training\nprocess cannot be properly classified by the neural network. A remedy could be adding a\nvector representing new traffic to the learning data set and to retrain the neural network.\nHowever, the blocking problem for such an approach is to obtain data that represent new\npreviously not detected attacks. We presented in this paper a proposal of an algorithm and an\nIDS architecture that allow to collect automatically new attacks-representing data and to use\nthem for retraining and updating weights and the number of hidden neurons in a distributed\nnetwork detectors based on the neural network technology.\nIn our research we focus on MLP and SVM neural networks architectures. The result of\nthe investigation is the information about the classification accuracy, represented as a number\nof false alarms and not detected attacks in comparison to the number of validation vectors. A\nnew attack and a new normal traffic representation are added to the training data set in order\nto observe their influence on improvement of the classification process for new vectors in the\ntests data set.\n\n2. Neural Network: a way of work\nAn artificial neural network is a system simulating the work of neurons in the human\nbrain. In Fig.1 is shown a diagram of a neuron's operation.\n\n1\n\n\fW1\nW2\nW3\nW4\n\nFig. 1 Artificial neuron's schema\nThe neuron consists of a number of inputs emulating dendrites of the biological neuron, an\nadder module, an activation function and one output emulating an axon of the biological\nneuron. The importance of a particular input is indicated by its weight that emulates the\nbiological neuron's synapse. The input signals are multiplied by the values of weights and\nnext the results are added in the adder block. The sum is sent to the activation block where it\nis processed by the activation function. In that way we obtain the neuron's answer Y for the\ninput signals \"xi\".\nOne neuron cannot solve a complex problem that's why the neural network composed of\nmany neurons is used. For the purpose of this work two network architectures were used:\nSVM and MLP.\nOne of the architectures that is used most frequently is the MLP (Multilayer Perceptron)\n[2], [3]. In such a network each neuron's output of the previous layer is connected with some\nneuron's input of the next layer. The MLP architecture consists of one or more hidden layers.\nThe signal is transmitted through the network in one direction from the input to the output,\nthat's why this architecture is called feedforward. The MLP network is learned with using the\nbackward propagation algorithm (BP). In order to reach better efficiency and speed of the\nlearning process it uses many types of the BP algorithm. In our research we used following\nvariants of the BP algorithm:\n3\u20444 Levenberg-Marquardt (trainln),\n3\u20444 Resilient Backpropagation (trainrp).\nFor the simulation process Matlab toolbox was used. The variants of the BP algorithm are\nfollowed by the name of the learning Matlab's function in brackets.\nThe second neural network architecture that was applied for our experiment is SVM\n(Support Vector Machine). It is the feedforward neural network that consists of two layers\n(hidden and output) and can use various types of the activation function. In the classification\ntasks, the first step of the SVM network work is to transform the nonlinearly separated input\nobservations (with usage of a kernel function) to the space where they can be lineally\nseparated. The second step of the learning phase is the maximization of the separation margin\nbetween two classes of the observations. In the simulation LibSVM implementation of the\nSVM network was used.\n\n2\n\n\f3. Input data for attacks detection\nIn the first phase of our investigation we used the KDD 99 data set as the input vectors for\ntraining and validation of the neural networks. This data set was prepared based on the data\ncollected in the DARPA (Defense Advanced Research Project Agency) intrusion detection\nevaluation program. MIT Lincoln Lab that participates in this program has set up simulation\nof typical LAN network in order to acquire raw TCP dump data [4]. They simulated LAN\nnetwork operating as a normal environment, which was infected with various types of\nattacks. The raw data was processed into connection records [5], [6]. For each connection 41\nvarious features were extracted. Each connection was labeled as the normal one or under a\nspecific type of attack. Four main categories of the attacks were simulated:\n\u0083\n\u0083\n\u0083\n\u0083\n\nDoS (Denial of Service) \u2013 An attacker tries to prevent legitimate users from using a\nservice, e.g. TCP SYN Flood, Smurf, etc.\nProbe \u2013 An attacker tries to collect information about the target host. For example:\nscanning victims in order to get knowledge of available services, operating system\nversion etc.\nU2R (User to Root) \u2013 An attacker has a local account on the victim host and tries to\ngain root privileges.\nR2L (Remote to Local) \u2013 An attacker does not have local account on a victim host\nand tries to obtain it.\n\nThe KDD 99 data set is divided in to tree subsets: 10%KDD, corrected KDD, whole KDD.\nBasic characteristics of the KDD99 data sets are shown in Table 3. The Table 3 includes the\nnumber of connections assigned to the particular class of an attack (DoS, Probe etc.).\nTable 1. KDD 99 data subsets\nDataset\n10%KDD\n\nDoS\n391458\n\nProbe\n4107\n\nU2r\n52\n\nU2l\n1126\n\nNormal\n97277\n\nCorrected\nKDD\n\n229853\n\n4166\n\n70\n\n16347\n\n60593\n\nWhole KDD\n\n3883370\n\n41102\n\n52\n\n1126\n\n972780\n\nThe 10%KDD data set is used for the training process of the IDS. It includes connections\nsimulating 22 types of attacks and the normal traffic. The Corrected KDD data set is used for\nthe testing process of the IDS. It includes additional 14 types of new attacks not presented in\n10%KDD and in Whole KDD. Thanks to them it is possible to check if the IDS is able to\ndetect a new attack not presented in the training phase.\nIn the second phase of investigation we added to the KDD 99 data set the simulation\nresults of 14 new attacks (generated with usage of Metasploit Framework) and a new normal\ntraffic (instant messaging, VoIP, audio streaming, network games). These types of the\nnetwork traffic were not presented before in the KDD 99 data set and could show how our\nproposal works for the real data.\n\n3\n\n\f4. Proposal of the IDS architecture\nThe main goal of the IDS architecture proposed in this work is to allow adapting the IDS\nsystem to correct classification of a new network traffic related to both: the normal behavior\nof the end user and to the attacks. The block diagram of the architecture is presented in Fig.\n2.\n\nfirewall/ switch /\nrouter\n\nanswer ()\n\nAlarm +\nvector\n\nIP packets\n\nSniffer\n\nAudit\nclassifier\n\nPreprocessing\n\nBase\nclassifier\n\nH&N monitor\n\nCentral module\n\nUpdate()\n\nAudit data\n\nSniffer\n\nIP packets\n\nPreprocessing\n\nAlarm +\nvector\n\nNetclassifier\n\nLAN monitor\nNet-LAN monitor\n\nFig.2 Block diagram architecture of the IDS proposal\n\nThe IDS system proposed in Fig. 2 is composed of three main modules: H&N monitor, NetLAN monitor and Central module. The role of each module is the following:\nH&N monitor\nMain task of this module is analyzing logs and host's audit data in order to find an anomaly\nevent that can be an aggressor's activity. When an attack is detected by Audit detector, the\nnetwork packet associated with it should be identified. Based on that network data, the\nKDD99 vector of the attack detected is created and is delivered with the alarm flag to Central\nmodule where it could be used to retrain Base classifier.\nNet-LAN monitor\nThis module analyses network data provided by a sniffer and transforms it to the KDD99\nvector form. The neural network is used for the classification process. It takes a decision\nwhether a current vector is related to an attack or to a normal traffic. In a case of the attack\ndetection, the alarm flag accompanied by the KDD99 vector is sent to Central module.\nBasing on this KDD99 vector it is possible to perform additional analysis and, finally, an\n4\n\n\feventual decision about classification of this alarm to the attack group or to the false alarm\ngroup is taken. For the additional analysis purpose Central module can use various methods\n(in the simplest way, by analysis of a security officer). In a case of the false alarm, the\nprovided KDD99 vector can be used to retrain Base classifier and to update all classifiers in\nall Net-LAN monitor modules.\nCentral module\nThis module obtains all alarms from distributed Net-LAN and H&N monitor modules and\npresents them to the end user of the IDS system. The second task of this module is retraining\nBase classifier with using the new learning data provided by H&N and Net-LAN monitors.\nBase classifier is the neural network that has the same architecture and weights values as\nNet-classifier in each Net-Lan monitor module. After the retraining process information\nabout the updated weighs and the new number of hidden neurons is sent to all Net-LAN\nmonitor modules.\n. An example of the network architecture that can use our solution is shown in Fig. 3.\n\nSecurity officer\nCentral\nmodule\nDMZ\nInternet\nswitch\nNet-LAN\nmonitor\n\nfirewall\nLAN\nNetwork\n\nswitch\n\nNet-LAN\nmonitor\n\nServer\n\nH& N\nmonitor\nServer\n\nComputer\n\nServer Server\n\nHoneyPot\n\nH& N\nmonitor\n\nComputer\n\nH& N monitor\n\nFig.3 The network architecture with the IDS proposal\n\nIn our work we decided that H&N monitor module is located on a honeypot system. This\nlocalization has the following advantages:\n5\n\n\f\u2022\n\n\u2022\n\nFor the honeypot system can be created specific security rules that are less restrictive\nthan the rules for other hosts in the protected network. In that case the host with the\ninstalled honeypot system can be visible for an aggressor as an easier target to attack\nthan other hosts. Thanks to this feature it is more probable than for a real production\nserver or for an end user host that the aggressor performs a new attack against it. As a\nresult we can collect the data that represent this new attack. Moreover, focusing an\naggressor's attention on the honeypot could distract him from production servers and\ncould increase other hosts safety.\nThe honeypot system only simulates some network services and the size of the\nnormal traffic destined for it is very limited. That's why it is easier to identify the\ndata related to the new attacks.\n\nThe honeypot system in our proposal is located in the DMZ (Demilitarized zone). Thanks\nto this localization in a case of taking over the honeypot control by an aggressor, the risk of a\nsuccessful attack against other host located in this internal network is lower because they are\nprotected by specific rules of a firewall. Moreover, the DMZ is less secure so it could attract\naggressors and make it easier to collect the data related to the new attacks.\nIn order to analyze all network traffic data, Net-LAN monitor should be located in each\nreal or virtual subnetwork.\n\n5. Results of tests\nOur investigation was divided in two phases. In the fist phase the accuracy of\nclassification of a new pattern by the neural network was analyzed. The goal of the second\nphase was to build the prototype of the IDS in the proposed architecture and to check its\neffectiveness concerning detection of the new attacks and the normal traffic classification.\nThe data sets used for each phase of investigation have been described in Chapter 3.\nPhase 1:\nFor the simulation we used two architectures of the neural network: MLP and SVM. For\nthe training and validation the KDD 99 data sets were used. More information about creation\nand training the neural network can be found in [7].\nDuring analysis of the tests results we noticed that both neural networks architectures\nhave a problem with classification of a new attack not presented in the learning phase.\n\u2022\n\u2022\n\nFor the MLP network the detection rate of a new attack was only 4.26% while for the\nother attacks presented during the learning phase it was 98 %. The false alarm rate\nwas 2.5%.\nFor the SVM network the detection rate of a new attack was only 18.7% while for\nthe other attacks presented during the learning phase it was 97 %. The false alarm rate\nwas 2%.\n\nIn Table 2 the accuracy of detection for each type of the new attacks from the test data\nset was presented. It could be noticed that for 17 new attacks only 2 were classified with the\ndetection rate that equals 100%.\n\n6\n\n\fTable 2. The accuracy of new attacks detection from Corrected KDD testing data set\nName of attack\nSnmpgetattack\nNamed\nXlock\nXsnoop\nSendmail\nSaint\nXterm\nMscan\nProcesstable\nPs\nApache2\nUdpstorm\nHttptunnel\nWorm\nMailbomb\nSqlattack\nSnmpguess\nSum of new attacks\n\nNumber of vectors\nin test data set\n\nAttack detection rate\n[%] (SVM)\n\nFalse alarm rate\n[%] (MLP)\n\n7741\n17\n9\n4\n17\n736\n13\n1053\n759\n16\n794\n2\n158\n2\n5000\n2\n2406\n18729\n\n0.25\n29.4\n0\n50\n47.06\n96.06\n84.61\n94.59\n77. 08\n37.5\n99.75\n50\n16.45\n0\n6.78\n100\n0.17\n18.7\n\n0.02\n52.94\n55.55\n50\n52.95\n82.2\n61.54\n7.50\n1.45\n81.25\n4.16\n100\n0.63\n0\n0.32\n100\n0.04\n4.26\n\nPhase 2:\nAs we noticed in the first phase, the SVM network better classified a new pattern. That's\nwhy for the second phase of the investigation we decided to use only this neural network's\narchitecture. The results of the tests are presented in Table 3 (new normal traffic) and Table 4\n(new attacks). The first row of each table corresponds to the situation when the new normal\ntraffic and the new attacks were not presented in the learning phase. In that situation for\nTable 3, false alarms were observed for 4 from 10 new normal vectors analyzed by Net-LAN\nmonitor module. For Table 4 it could be noticed that 4 new attacks were not detected. The\nnew attacks not detected by Net-LAN monitor were later detected by H&N monitor located\non the honeypot hosts. Thanks to it we obtain the vectors for retraining the neural networks\nin Central module and for updating Net-LAN monitor classifiers. The second row of each\ntable represents situation after this update. In both tables we observe that all the new vectors\nwere properly classified.\nTable 3. The results of Net-LAN monitor classification of the new normal traffic\nLearning data set\n(network\narchitecture)\n\nNumber of\nfalse\nalarms\n\nTest data set\n\n\u201eNaukaIbiza2009sm\n(SVM)\"\n\n\u201eTestowe_gadu3D\n\"\n\n1347\n\n\u201eNaukaDay55\"\n\n\u201eTestowe_gadu3D\n\"\n\n1328\n\nNumber of\nnot\ndetected\nattacks\n21380\n\n7\n\n21432\n\nRemarks\nFalsive alarm concerns:\n\u201esip-audio\",\" rtpaudio\", \u201e gadu-k\",\n\u201eradio\"\nAll the new normal\nvectors were properly\nclassified\n\n\fTable 4. The results of detection of the new attacks by Net-LAN monitor\nLearning data set\n(network\narchitecture)\n\nTest data set\n\n\u201eNaukaIbiza2009sm\n\"\n(SVM)\n\n\u201eTestowe+new31\"\n\nnet-klasyfikator after\nupdate (SVM)\n\n\u201eTestowe+new31\"\n\nNumber of\nfalse alarms\n1343\n\n1376\n\nNumber of\nnot detected\nattacks\n21384\n\n21292\n\nRemarks\nNot detected:\ncesarftp_mkd,\nslimp_ftp_list.,\nmailcarrier_smtp,\ngoodtech_telnet\nall new attacks\nwere properly\ndetected\n\n6. Conclusions\nFrom our investigation we noticed that the neural networks properly classified the\nnetwork traffic similar to the one presented during the learning phase. That's why they could\nbe a good solution for detection of the attacks that were modified by an aggressor in order to\ncheat intrusion detection systems. Unfortunately, the new attacks and the new normal traffic\nthat is significantly different from the one presented in the training phase cannot be classified\nwith sufficiently good accuracy. The IDS architecture that we proposed could improve\nclassification of the new network patterns. Our solution has the following advantages:\n\u2022\n\u2022\n\u2022\n\u2022\n\nIt fixes problems with obtaining training data representing a new attack or a new\nnormal traffic.\nIt adapts to new attacks detection.\nThanks to using Net- LAN classifier it is possible to react on an attack in real time\nand block it before it reaches a host under protection.\nIt adapts the system to correct classification of the normal network traffic related to a\nnew service not presented before in the training data (still it should be worked out a\nmethod of taking automatically final decision about classification of alarms in\nCentral module).\n\n.\n\nIt is important to check if adding a new vector influences negatively on the classification\naccuracy. For example in a situation when we add a new normal traffic to the learning data\nset and the number of not detected attacks increased significantly, the reason may be that the\nnew vectors can be too much similar to an attack representation. In that case a new feature\nshould be added to KDD99 vectors in order to classify reliably both traffic types.\n\nReferences\n[1] Hwang, S., Lee, T.-J., Y.-J. Lee, \u201eA three-tier IDS via Data Mining Approach\", In Proc. of the 3rd Annual\nACM Workshop on Mining Network Data (MineNet), San Diego USA, June 12 2007\n[2] Rutkowski, L.: Methods and techniques of Artificial Intelligence. PWN, Warsaw (2005). (In Polish)\n[3] Osowski, S.: The Neural Networks for Information Processing, Editorial Office of Warsaw University of\nTechnology, Warsaw (2000). (In Polish)\n\n8\n\n\f[4]Lippmann, R. Haines, J.W., Fried, D.J., Korba, J., Das, K.:The 1999 Darpa Off-Line Intrusion Detection\nEvaluation. In: Computer Networks: The International Journal of Computer and Telecommunications\nNetworking 34 (2000) 579--595. (2000)\n[5] Lee, W., Stolfo, S.J.: A Framework for Constructing Features and Models for Intrusion Detection Systems.\nIn: ACM Transactions on Information and System Security (TISSEC), 3(4):227--261 (2000).\n[6] Lee, W., Stolfo, S.J.: Data Mining Approaches for Intrusion Detection. In: Seventh USENIX Security\nSymposium (SECURITY '98), San Antonio, TX (1998)\n[7] Kukielka, P., Kotulski, Z.: Analysis of the different architectures of neural networks usage for Intrusion\nDetection Systems. In: Proceedings of the International Multiconference on Computer Science and Information\nTechnology, IMCSIT 2008, pp.807-811, IEEEXplore, (2008).\n\n9\n\n\f"}