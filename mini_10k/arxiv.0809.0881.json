{"id": "http://arxiv.org/abs/0809.0881v2", "guidislink": true, "updated": "2009-04-06T15:22:23Z", "updated_parsed": [2009, 4, 6, 15, 22, 23, 0, 96, 0], "published": "2008-09-04T19:32:01Z", "published_parsed": [2008, 9, 4, 19, 32, 1, 3, 248, 0], "title": "Reliable Eigenspectra for New Generation Surveys", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0809.0599%2C0809.1580%2C0809.3512%2C0809.0770%2C0809.3344%2C0809.4310%2C0809.2194%2C0809.0123%2C0809.2936%2C0809.3100%2C0809.2877%2C0809.0491%2C0809.1216%2C0809.1776%2C0809.2974%2C0809.2455%2C0809.3505%2C0809.4485%2C0809.3402%2C0809.3578%2C0809.3739%2C0809.0723%2C0809.1356%2C0809.1333%2C0809.2107%2C0809.3052%2C0809.5211%2C0809.3418%2C0809.2815%2C0809.2062%2C0809.5256%2C0809.0926%2C0809.2947%2C0809.1886%2C0809.4676%2C0809.3933%2C0809.0677%2C0809.1620%2C0809.3495%2C0809.1522%2C0809.1008%2C0809.1016%2C0809.2134%2C0809.1612%2C0809.3832%2C0809.3273%2C0809.4940%2C0809.2085%2C0809.1169%2C0809.2388%2C0809.1434%2C0809.5174%2C0809.3744%2C0809.1983%2C0809.1564%2C0809.2288%2C0809.4039%2C0809.5205%2C0809.0201%2C0809.5123%2C0809.0955%2C0809.3159%2C0809.5042%2C0809.4446%2C0809.1305%2C0809.4480%2C0809.0153%2C0809.0462%2C0809.1212%2C0809.4575%2C0809.0517%2C0809.4422%2C0809.4922%2C0809.1438%2C0809.1478%2C0809.0422%2C0809.4549%2C0809.1578%2C0809.4037%2C0809.1938%2C0809.1325%2C0809.1019%2C0809.4670%2C0809.0359%2C0809.4700%2C0809.1967%2C0809.0997%2C0809.1625%2C0809.0374%2C0809.4031%2C0809.0881%2C0809.4300%2C0809.2329%2C0809.0746%2C0809.1497%2C0809.0814%2C0809.4404%2C0809.3076%2C0809.0953%2C0809.1978%2C0809.2644&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Reliable Eigenspectra for New Generation Surveys"}, "summary": "We present a novel technique to overcome the limitations of the applicability\nof Principal Component Analysis to typical real-life data sets, especially\nastronomical spectra. Our new approach addresses the issues of outliers,\nmissing information, large number of dimensions and the vast amount of data by\ncombining elements of robust statistics and recursive algorithms that provide\nimproved eigensystem estimates step-by-step. We develop a generic mechanism for\nderiving reliable eigenspectra without manual data censoring, while utilising\nall the information contained in the observations. We demonstrate the power of\nthe methodology on the attractive collection of the VIMOS VLT Deep Survey\nspectra that manifest most of the challenges today, and highlight the\nimprovements over previous workarounds, as well as the scalability of our\napproach to collections with sizes of the Sloan Digital Sky Survey and beyond.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0809.0599%2C0809.1580%2C0809.3512%2C0809.0770%2C0809.3344%2C0809.4310%2C0809.2194%2C0809.0123%2C0809.2936%2C0809.3100%2C0809.2877%2C0809.0491%2C0809.1216%2C0809.1776%2C0809.2974%2C0809.2455%2C0809.3505%2C0809.4485%2C0809.3402%2C0809.3578%2C0809.3739%2C0809.0723%2C0809.1356%2C0809.1333%2C0809.2107%2C0809.3052%2C0809.5211%2C0809.3418%2C0809.2815%2C0809.2062%2C0809.5256%2C0809.0926%2C0809.2947%2C0809.1886%2C0809.4676%2C0809.3933%2C0809.0677%2C0809.1620%2C0809.3495%2C0809.1522%2C0809.1008%2C0809.1016%2C0809.2134%2C0809.1612%2C0809.3832%2C0809.3273%2C0809.4940%2C0809.2085%2C0809.1169%2C0809.2388%2C0809.1434%2C0809.5174%2C0809.3744%2C0809.1983%2C0809.1564%2C0809.2288%2C0809.4039%2C0809.5205%2C0809.0201%2C0809.5123%2C0809.0955%2C0809.3159%2C0809.5042%2C0809.4446%2C0809.1305%2C0809.4480%2C0809.0153%2C0809.0462%2C0809.1212%2C0809.4575%2C0809.0517%2C0809.4422%2C0809.4922%2C0809.1438%2C0809.1478%2C0809.0422%2C0809.4549%2C0809.1578%2C0809.4037%2C0809.1938%2C0809.1325%2C0809.1019%2C0809.4670%2C0809.0359%2C0809.4700%2C0809.1967%2C0809.0997%2C0809.1625%2C0809.0374%2C0809.4031%2C0809.0881%2C0809.4300%2C0809.2329%2C0809.0746%2C0809.1497%2C0809.0814%2C0809.4404%2C0809.3076%2C0809.0953%2C0809.1978%2C0809.2644&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We present a novel technique to overcome the limitations of the applicability\nof Principal Component Analysis to typical real-life data sets, especially\nastronomical spectra. Our new approach addresses the issues of outliers,\nmissing information, large number of dimensions and the vast amount of data by\ncombining elements of robust statistics and recursive algorithms that provide\nimproved eigensystem estimates step-by-step. We develop a generic mechanism for\nderiving reliable eigenspectra without manual data censoring, while utilising\nall the information contained in the observations. We demonstrate the power of\nthe methodology on the attractive collection of the VIMOS VLT Deep Survey\nspectra that manifest most of the challenges today, and highlight the\nimprovements over previous workarounds, as well as the scalability of our\napproach to collections with sizes of the Sloan Digital Sky Survey and beyond."}, "authors": ["Tamas Budavari", "Vivienne Wild", "Alexander S. Szalay", "Laszlo Dobos", "Ching-Wa Yip"], "author_detail": {"name": "Ching-Wa Yip"}, "author": "Ching-Wa Yip", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1111/j.1365-2966.2009.14415.x", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0809.0881v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0809.0881v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "7 pages, 3 figures, accepted to MNRAS", "arxiv_primary_category": {"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0809.0881v2", "affiliation": "The Johns Hopkins University", "arxiv_url": "http://arxiv.org/abs/0809.0881v2", "journal_reference": null, "doi": "10.1111/j.1365-2966.2009.14415.x", "fulltext": "Mon. Not. R. Astron. Soc. 000, 000\u2013000 (0000)\n\nPrinted 27 October 2018\n\n(MN LATEX style file v2.2)\n\nReliable Eigenspectra for New Generation Surveys\n\narXiv:0809.0881v2 [astro-ph] 6 Apr 2009\n\nTam\u00e1s Budav\u00e1ri1\u22c6 , Vivienne Wild2 , Alexander S. Szalay1,2 , L\u00e1szl\u00f3 Dobos3\nand Ching-Wa Yip1\n1 Department\n\nof Physics and Astronomy, The Johns Hopkins University, 3701 San Martin Drive, Baltimore, MD 21218, USA\nPlanck Institute for Astrophysics, Karl-Schwarzschild Str. 1, 85741 Garching, Germany\n3 E\u00f6tv\u00f6s Lor\u00e1nd University, Department of Physics of Complex Systems, P\u00e1zm\u00e1ny P. s\u00e9t\u00e1ny 1/A, Budapest, 1117, Hungary\n2 Max\n\n27 October 2018\n\nABSTRACT\n\nWe present a novel technique to overcome the limitations of the applicability of Principal\nComponent Analysis to typical real-life data sets, especially astronomical spectra. Our new\napproach addresses the issues of outliers, missing information, large number of dimensions\nand the vast amount of data by combining elements of robust statistics and recursive algorithms that provide improved eigensystem estimates step-by-step. We develop a generic\nmechanism for deriving reliable eigenspectra without manual data censoring, while utilising\nall the information contained in the observations. We demonstrate the power of the methodology on the attractive collection of the VIMOS VLT Deep Survey spectra that manifest most\nof the challenges today, and highlight the improvements over previous workarounds, as well\nas the scalability of our approach to collections with sizes of the Sloan Digital Sky Survey\nand beyond.\nKey words: galaxies: statistics - methods: statistical\n\n1 MOTIVATION\nAs modern telescopes collect more and more data in our exponential world, where the size of the detectors essentially follows\nMoore's law, the kind of statistical challenges astronomers face in\nanalysing the observations change dramatically in nature. We need\nalgorithms that scale well in time and complexity with the volume\nof the data, while obeying the constraints of today's computers. But\nthe large data volume is only one of the consequences of this trend.\nWith more observations in hand, the number of problematic detections also increases. In addition to the elegant mathematical theorems that work miracles on textbook examples, scientists need to\ndevelop methodologies that provide reliable results that are robust\nin the statistical sense when applied to real-life data.\nOne particular multi-variate analysis technique, which is\nwidely accepted and popular not only in astronomy but also in\ngenetics, imaging and many other fields, is Principal Component\nAnalysis (PCA). For its simple geometric meaning and straightforward implementation via Singular Value Decomposition (SVD),\nit has been utilised in many areas of the field including classification of galaxies and quasars (Francis et al. 1992; Connolly et al.\n1995; Connolly & Szalay 1999; Yip et al. 2004a,b), spectroscopic\nand photometric redshift estimation (Glazebrook, Offer, & Deeley\n1998; Budav\u00e1ri et al. 1999, 2000), sky subtraction (Wild & Hewett\n2005), and highly efficient optical spectral indicators (Wild et al.\n2007). However, direct application of the classic PCA to real data\n\n\u22c6\n\nE-mail: budavari@jhu.edu\n\nis almost always impossible; the reasons are usually three-fold:\n(1) The technique is extremely sensitive to outliers. With smaller\ndatasets, scientists would \"clean up\" the sample by completely removing the \"obvious\" outliers in one or more projections and analyse the remaining subset. The problem with this approach is that\nit is subjective, and it becomes impractical for large datasets. (2)\nAnother problem is missing measurements in the data vectors, e.g.,\npixels of a spectrum. There are various reasons for this to occur:\nstrong night sky lines, cosmic rays or simply because of the redshift\nthat yields different restframe wavelength coverage for the spectra. The application of PCA implies the assumption of a Euclidean\nmetric, but it is not clear how to calculate Euclidean distances when\ndata is missing from our observed vectors. (3) Last but not least, the\nmemory requirement of SVD is significant as the entire dataset is\nstored in memory while the decomposition is computed. For example, the Sloan Digital Sky Survey (SDSS) Data Release 6 contains\na million spectra with 4000 resolution elements each. While machines certainly exist today that have the required amount of RAM\n(\u223c 50GB), typical workstations have lesser resources. Additionally,\nin most situations, we only seek a small number of eigenvectors associated with the largest eigenvalues, and SVD computes all the\nsingular vectors in vain.\nThe optical spectra of the VIMOS VLT Deep Survey (VVDS;\nLe F\u00e8vre et al. 2005) provides an extremely attractive dataset for\ngalaxy evolution studies at high redshift, yet, due to their generally\nlow signal-to-noise ratio they are unsuitable for traditional PCA.\nIn this case, the challenge does not lie in the volume of the data\nset, rather in the natural limitations of high redshift observations.\n\n\f2\n\nBudav\u00e1ri, Wild, et al.\n\nThanks to the careful processing by the VVDS Team, the spectra\nare well calibrated and each one contains valuable information for\na PCA analysis.\nOur goal is to develop an algorithm to address all of the above\nissues in a way that is true to the spirit of the PCA and maintains\nits geometrically meaningful properties. In \u00a72 we detail the various layers of our solution to the problem, and in \u00a73 we compare\nthe performance of different techniques when applied to the VVDS\nspectra. In \u00a74 we evaluate the results of the methods and analyse\nthe emerging physical features. \u00a75 concludes our study.\n\n2 STREAMING PCA\nOur approach to the analysis is not the classical one. Instead of\nworking with a data set, we aim to formulate the problem using\nthe concept of a data stream. We want to incrementally improve\nour understanding of the properties of the data, deriving better and\nbetter eigenspectra through the incremental addition of new observations.\nWe develop an algorithm to recursively calculate the quantities\nof interest. As the first step and an illustration of the concept, we\nlook at the calculation of the sample mean,\n\u03bc=\n\nN\n1 X\nxn\nN\n\n(1)\n\nn=1\n\nwell as the new observation vector y,\n=\n\nak\n\nek\n\n=\n\nap+1\n\ny\n\np\n\n\u03b3\u03bbk ,\n\nk = 1...p\n\n(8)\n\np\n\n1\u2212\u03b3\n\n(9)\n\nIf A = UWVT then the eigensystem of the covariance C will\nhave eigenvalues of \u039b = W2 and eigenspectra equal to the\nsingular-vectors, E = U. Therefore, this formalism allows us to\nupdate the eigensystem by solving the SVD of the much smaller A\nleading to a significant decrease in computational time.\nFollowing the above procedure, one can update the truncated\neigensystem step-by-step by adding the observed spectra one-byone to build the final basis. A natural starting point for the iteration\nis to run SVD on a small subset of observation vectors first and\nproceed with the above updates from there.\n2.2 Robustness against Outliers\nBefore we turn to making the algorithm robust, to understand the\nlimitations of PCA let us first review the geometric problem that\nPCA solves. The classic procedure essentially fits a hyperplane to\nthe data, where the eigenspectra define the projection matrix onto\nthis plane. If the truncated eigensystem consists of p eigenspectra\nin the matrix Ep , the projector is Ep ETp , and the residual of the fit\nfor the nth observation vector is written as\nr n = (I \u2212 Ep ETp )y n\n\n(10)\n\nwhere {xn } are the N observation vectors. One can define a series\nof estimates as\nn\u22121\n1\n\u03bcn =\n\u03bcn\u22121 + xn\n(2)\nn\nn\n\nUsing this notation, PCA simply solves the minimization problem\n\nIt is easy to see that \u03bc1 = x1 and \u03bcN = \u03bc. This iterative formula\nis the key to our new procedure, where the best estimate of the\nsample mean at each step is\n\nwhere rn \u2261 |r n |. The sensitivity of PCA to outliers comes from\nthe fact that the sum will be dominated by the extreme values in the\ndata set.\nOver the last couple of decades, a number of improvements\nhave been proposed to overcome this issue within the framework\nof robust statistics (e.g., see Maronna, Martin & Yohai 2006, for\na concise overview). The current state-of-the-art technique introduced by Maronna (2005) is based on a robust M-estimate (Huber\n1981) of the scale, called M-scale. Here we solve the new minimisation problem\n\n\u03bc\n\n=\n\n\u03b3\u03bcprev + (1 \u2212 \u03b3)x\n\n(3)\n\n=\n\n\u03bcprev + (1 \u2212 \u03b3)y\n\n(4)\n\nwhere we introduced the centered variable y = x \u2212 \u03bcprev . The\nweight parameter \u03b3 lies between 0 and 1, and may be a function of\nboth the observation vector and the iteration step.\n\nmin\n\nN\n1 X 2\nrn\nN\n\n(11)\n\nn=1\n\nmin \u03c3 2\n2.1 Updating the Eigensystem\nThe calculation of the sample covariance matrix is essentially identical to that of the mean, except we average the outer products of\nthe vectors. Let us solve for the eigenspectra that belong to the\nlargest p eigenvalues that account for most of the sample variance.\nThis means that the Ep \u039bp ETp is a good approximation to the full\ncovariance matrix, where {\u039bp , Ep } is the truncated eigensystem.\nHence, the recursion takes the form of\nC\n\n=\n\n\u03b3Cprev + (1 \u2212 \u03b3)yy T\n\n(5)\n\n\u2248\n\n\u03b3Ep \u039bp ETp + (1 \u2212 \u03b3)yy T\n\n(6)\n\nFollowing Li et al. (2003), we write the covariance matrix as the\nproduct of some matrix A and its transpose\nC \u2248 AAT\n\n(12)\n2\n\n(7)\n\nwhere the matrix A has only (p + 1) columns, and is thus much\nsmaller than the covariance matrix. The columns of A are the constructed from the previous eigenvalues \u03bbk and eigenspectra ek , as\n\n2\n\nwhere \u03c3 is an M-scale of the residuals r , which satisfies the equation\nN\n1 X\n\u03c1\nN\nn=1\n\n\u0012\n\nrn2\n\u03c32\n\n\u0013\n\n=\u03b4\n\n(13)\n\nwhere \u03c1 is the robust function. Usually a robust \u03c1-function is bound\nand assumed to be scaled to values between \u03c1(0) = 0 and \u03c1(\u221e) = 1.\nThe parameter \u03b4 controls the breakdown point where the estimate\nexplodes due to too much outlier contamination. It is straightforward to verify that in the non-robust maximum likelihood estimation (MLE) case with \u03c1(t) = t and \u03b4 = 1, we recover the classic\nminimization problem with \u03c3 being the root mean square (RMS).\nBy implicit differentiation the robust solution yields a very\nintuitive result: the mean is a weighted average of the observation\nvectors, and the hyperplane is derived from the eigensystem of a\nweighted covariance matrix,\n\u03bc\n\n=\n\n\u0010X\n\nwn x n\n\n\u0011 . \u0010X\n\nwn\n\n\u0011\n\n(14)\n\n\fReliable eigenspectra\n=\n\nC\n\n\u03c32\n\n\u0010X\n\nwn (xn\u2212\u03bc)(xn\u2212\u03bc)T\n\n\u0011 . \u0010X\n\nwn rn2\n\n\u0011\n\n(15)\n\nwhere wn = W (rn2 /\u03c3 2 ) and W (t) = \u03c1\u2032 (t). The weight for each\nobservation vector depends on \u03c3 2 , which suggests the appropriateness of an iterative solution, where in every step we solve for the\neigenspectra and use them to calculate a new \u03c3 2 scale; see Maronna\n(2005) for details. One way to obtain the solution of eq.(13) is to\nre-write it in the intuitive form of\nN\n1 X \u22c6 2\nwn r n\nN\u03b4\n\n\u03c32 =\n\n(16)\n\nn=1\n\nwhere the weights are wn\u22c6 = W \u22c6 (rn2 /\u03c3 2 ) with W \u22c6 (t) = \u03c1(t)/t.\nAlthough, this is not the solution as the right hand side contains \u03c3 2\nitself, it can be shown that its iterative re-evaluation converges to\nthe solution.\nWe take this approach one step further. By recursively calculating the eigenspectra instead of the classic method, we can allow\nfor a simultaneous solution for the scale \u03c3 2 , as well. The recursion\nequation for the mean is formally almost identical to the classic\ncase, and we introduce new equations to propagate the weighted\ncovariance matrix and the scale,\n\u03bc\nC\n\u03c3\n\n2\n\n=\n\n\u03b31 \u03bcprev + (1 \u2212 \u03b31 )x\n\n(17)\n2\n\nT\n\n=\n\n\u03b32 Cprev + (1 \u2212 \u03b32 ) \u03c3 yy /r\n\n=\n\n2\n\u03b33 \u03c3prev\n\n2\n\n(18)\n\n\u22c6 2\n\n+ (1 \u2212 \u03b33 ) w r /\u03b4\n\n(19)\n\nwhere the \u03b3 coefficients depend on the running sums of 1, w and\nwr 2 denoted below by u, v and q, respectively.\n\u03b31 =\n\n\u03b1vprev /v\n\nwith\n\nv = \u03b1vprev + w\n\n\u03b32 =\n\n\u03b1qprev /q\n\nwith\n\nq = \u03b1qprev + wr\n\n\u03b33 =\n\n\u03b1uprev /u\n\nwith\n\nu = \u03b1uprev + 1\n\n(20)\n2\n\n(21)\n(22)\n\nThe parameter \u03b1 introduced here, which takes values between 0 and\n1, adjusts the rate at which the evolving solution of the eigenproblem forgets about past observations. It sets the characteristic width\nof the sliding window over the stream of data; in other words, the\neffective sample size.1 The value \u03b1 = 1 corresponds to the classic\ncase of infinite memory. Since our iteration starts from a non-robust\nset of eigenspectra, a procedure with \u03b1 < 1 is able to eliminate the\neffect of the initial transients. Due to the finite memory of the recursion, it is clearly disadvantagous to put the spectra on the stream\nin a systematic order; instead they should be randomized for best\nresults.\nIt is worth noting that robust \"eigenvalues\" can be computed\nfor any eigenspectra in a consistent way, which enables a meaningful comparison of the performance of various bases. To derive\na robust measure of the scatter of the data along a given eigenspectrum e, one can project the data on it, and formally solve the\nsame equation as in eq.(13) but with the residuals replaced with the\nprojected values, i.e., for the kth eigenspectrum rn = ek y n . The\nresulting \u03c3 2 value is a robust estimate of \u03bbk .\n2.3 Missing Entries in Observations\nThe other common challenge is the presence of gaps in the observations, i.e., missing entries in the data vectors. Gaps emerge for\nnumerous reasons in real-life measurements. Some cause the loss\nof random snippets while others correlate with physical properties\n1\n\nFor example, the sequence u rapidly converges to 1/(1 \u2212 \u03b1).\n\n3\n\nof the sources. An example of the latter is the wavelength coverage\nof objects at different redshifts: the observed wavelength range being fixed, the detector looks at different parts of the electromagnetic\nspectrum for different extragalactic objects.\nNow we face two separate problems. Using PCA implies that\nwe believe the Euclidean metric to be a sensible choice for our\ndata, i.e., it is a good measure of similarity. Often one needs to\nnormalize the observations so that this assumption would hold. For\nexample, if one spectrum is identical to another but the source is\nbrighter and/or closer, their distance would be large. The normalisation guarantees that they are close in the Euclidean metric. So\nfirstly, we must normalise every spectrum before it is entered into\nthe streaming algorithm. This step is difficult to do in the presence\nof incomplete data, hence we also have to \"patch\" the missing data.\nInspired by Everson & Sirovich (1995), Connolly & Szalay\n(1999) proposed a solution, where the gaps are filled by an unbiased\nreconstruction using a pre-calculated eigenbasis. A final eigenbasis\nmay be calculated iteratively by continuously filling the gaps with\nthe previous eigenbasis until convergence is reached (Yip et al.\n2004a). While Connolly & Szalay (1999) allowed for a bias in rotation only, the method has recently been extended to accommodate\na shift in the normalisation of the data vectors (Wild et al. 2007,\nLemson et al., in preparation). Of course, the new algorithm presented in this paper can use the previous eigenbasis to fill gaps in\neach input data vector as they are input, thus avoiding the need for\nmultiple iterations through the entire dataset.\nThe other problem is a consequence of the above solution.\nHaving patched the incomplete data by the current best understanding of the manifold, we have artificially removed the residuals in the\nbins of the missing entries, thus decreased the length of the residual vector. This would result in increasingly large weights being\nassigned to spectra with the largest number of empty pixels. One\nsolution is to calculate the residual vector using higher-order eigenspectra. The idea is to solve for not only the first p eigenspectra but\na larger (p+q) number of components and estimate the residuals in\nthe missing bins using the difference of the reconstructions on the\ntwo different truncated bases.\n\n3 THE VVDS SPECTRA\nThe VIMOS VLT Deep survey (VVDS) is a deep spectroscopic\nredshift survey, targetting objects with apparent magnitudes in the\nrange of 17.5 6 IAB 6 24 (Le F\u00e8vre et al. 2005). The survey is\nunique for high redshift galaxy surveys in having applied no further colour cuts to minimise contamination from stars, yielding a\nparticularly simple selection function, making it a very attractive\ndataset for statistical studies of the high redshift galaxy population.\nIn this work we make use of the spectra from the publicly available\nfirst epoch data release of the VVDS-0226-04 (VVDS-02h) field\n(Le F\u00e8vre et al. 2005). The spectra have a resolution of R = 227\nand a dispersion of 7.14\u00c5/pixel. They have a usable observed frame\nwavelength range, for our purposes, of \u223c5500-8500\u00c5.\nThe first epoch public data release contains 8981 spectroscopically observed objects in the VVDS-02h field, we select only those\nwith moderate to secure redshifts (flags 2, 3, 4, and 9) that lie in the\nredshift range 0.5 < z < 1.0. The redshift range is determined by\nthe rest-frame spectral range we have chosen for this study. The\nfinal sample contains 3485 spectra.\nThe VVDS dataset provides the ideal test for a robust PCA algorithm, because of the low signal-to-noise ratio of the spectra and\nthe significant chance that outliers exist due to incorrect redshift\n\n\f4\n\nBudav\u00e1ri, Wild, et al.\n\nFigure 1. The mean spectrum and top four eigenspectra for the VVDS galaxies. The eigenspectra have been inverted where necessary to make the physical\nfeatures easier to identify (i.e. absorption lines in absorption and emission lines in emission) Left: The result from classic PCA on 3485 spectra. Center:\nThe result from classic PCA with iterative removal of outliers. The final dataset contains 2675 spectra. Right: The result from the new iterative-robust PCA\nalgorithm.\n\ndeterminations. We have chosen the 4000\u00c5 break region to illustrate the procedure because of the obvious importance of this spectral region for galaxy evolution studies (e.g., Balogh et al. 1999;\nWild et al. 2007) and also due to the wide variety of spectral features present for the PCA to identify. Eigenspectra similar to those\ncreated in this analysis are used by Wild et al. (2008) for the identification of H\u03b4-strong galaxies in the VVDS survey.\n\n3.1 Classic and Trimmed Analysis\nTo provide a comparison for the robust algorithm, we first perform the classic PCA using an SVD algorithm. The spectra are corrected for Galactic extinction assuming a uniform E(B\u2212V)= 0.027\n(McCracken et al. 2003), moved to the galaxy rest-frame and interpolated onto a common wavelength grid. Regions of the spectra\nwith bad pixels are identified using the associated error arrays, regions with strong night sky lines are included into the mask. Each\nspectrum is normalised, by dividing by the median flux in the good\npixels, and gaps in the dataset caused by bad pixels are filled with\n\nthe median of all other spectra at that wavelength. The mean spectrum is calculated and subtracted, and PCA is then performed on\nthe residuals. The resulting mean spectrum and eigenspectra are\npresented in the first column of Figure 1.\nClearly the noise level of the eigenspectra resulting from the\nclassic PCA is high. The distribution of principal component amplitudes reveals that the signal in many of the eigenspectra is dominated by a small number of outliers. A natural way to improve on\nthis situation is through the iterative removal of these outliers based\non the principal component amplitude distributions. This procedure\nis essentially the same as the calculation of truncated statistics, e.g.,\nthe trimmed mean, when one excludes some percentage of the objects symmetrically based on their rank. For the dataset in question,\n20 iterations are required to reduce the number of 3\u03c3 outliers in the\ntop 10 eigenspectra to half a dozen, resulting in a total number of\n2675 spectra for the final PCA. For a more thorough analysis, a\nconvergence criteria can be employed to indicate when the eigenspectra cease to vary significantly (e.g., Yip et al. 2004a).\nThe resulting mean and eigenspectra from this trimmed PCA\n\n\fReliable eigenspectra\n\n5\n\nFigure 2. Left: The top six normalized eigenvalues as a function of iteration number using the classic PCA. Each eigenvalue represents the amount of\nsample variance carried by the eigenspectrum. Right: The top six normalized eigenvalues as a function of galaxy number for robust streaming PCA shown in\nvarious colours. The x-axis begins at 200, the size of the dataset used to initialise the eigenbasis. The dashed and dotted lines are runs from different random\ninitialisations that converge to the same results.\n\nare shown in the central column of Figure 1. As well as the eigenspectra being visibly less noisy, the PCA now identifies more physical features, linking together in a single eigenspectra those features\nwe know to be correlated, e.g., the Balmer Hydrogen line series in\nthe second eigenspectrum, and emission lines in the third eigenspectrum. The left hand panel of Figure 2 shows the convergence\nwith iteration number of the top six eigenvalues, which represent\nthe variance in the dataset described by each corresponding eigenspectrum. The first eigenspectra converges quickly, after only a few\niterations. The later eigenspectra converge more slowly.\nWhile this iterative procedure results in a clean set of eigenspectra, the removal of outliers based on single components can\neasily lead to the loss of information from the dataset. This occurs\nwhen more unusual spectra, which would appear in later eigenspectra, are thrown out as outliers in the top few components. Additionally, running a full PCA for multiple iterations is undeniably\nan inefficient use of computing power, especially for large samples\nlike the SDSS, where a single iteration takes about 2 days. We will\nnow describe the application of the iterative and robust PCA algorithm to the same noisy dataset, showing that the same noise free\nand physically interesting eigenspectra are recovered, more quickly\nand without the physical removal of spectra from the dataset.\n\nsize and content of the initialisation dataset and the precise method\nused to initialise \u03c3. Changes to \u03b1 and \u03b4 alter the speed of convergence and susceptibility to outliers as the algorithm proceeds in\ntime. Starting from the 201st spectrum, we input the spectra into the\nrobust streaming PCA algorithm. The right hand panel of Figure 2\nshows the progression of the eigenvalues with spectrum number in\nseparate colours from three alternative random initialisation shown\nin solid, dotted and dashed lines. We see that full convergence of\nthe top three eigenspectra is reached in less than one round of the\n3485 spectra; naturally eigenspectra which carry less of the sample\nvariance converge more slowly as they depend on the lower order\ncomponents, but in this example they still stabilise in less than two\nrounds of iterations.\nThe third column of Figure 1 shows the resulting mean and\ntop four eigenspectra. In this test case, the eigenspectra are very\nsimilar to those from the trimmed PCA but minor improvements are\napparent. It is worth noting that the PCA algorithm is completely\nindependent of the order of the bins: it has no spatial coherence.\nHence the fact that our eigenspectra are smoother than the trimmed\nbasis is already an indication of them being more robust.\n\n3.2 Robust Eigenspectra\n\n4 DISCUSSION\n\nNext we apply the streaming PCA method introduced earlier. For\nthe actual implementation, we utilise a Cauchy-type \u03c1-function:\n\nThere are two important points that an effective spectral eigenbasis\nmust obey: (1) the eigenspectra should not introduce noise into the\ndecomposition of individual galaxy spectra by being noisy themselves; (2) the top few eigenspectra must primarily describe the\nvariance in the majority of the dataset, and not be influenced by\nminority outliers. Additionally, the eigenbasis should be quick to\ncalculate and without the need for excessive memory storage.\nFigure 1 illustrates the success of robust statistics for addressing point (1). The second point becomes clear when we investigate the distribution of the principal component amplitudes of the\n3485 VVDS spectra. In Figure 3 we present the first two principal component amplitudes for the VVDS spectra using each of the\neigenbases. The overall correlation between these first two principal component amplitudes for the classic PCA indicates the failure\n\n\u03c1(t) =\n\n2\n\u03c0 t\narctan\n\u03c0\n2 c2\n\n\u0010\n\n\u0011\n\n(23)\n\nand use the scalar c to adjust the asymptotic value of the scale estimate to match the standard deviation of a Gaussian point process.\nFirst we perform a classic PCA on 200 randomly selected spectra\nto provide the initial eigenbasis, and the initial \u03c3 2 estimate (eq.19)\nis calculated from the sum of the residuals between these 200 spectra and their PCA reconstructions. We set \u03b1 = 1 \u2212 1/N where N\nis the total number of galaxies in the dataset.We also set \u03b4 = 0.5\nto maximize the breakdown point, which yields c \u2243 0.787 for our\nchoice of \u03c1-function. Our final results are robust to variations in the\n\n\f6\n\nBudav\u00e1ri, Wild, et al.\n\nFigure 3. The joint distribution of the first two principal component amplitudes for the VVDS collection of 3485 spectra using the eigenbases presented in\nFigure 1. In order to focus on the main sample of objects, the axes are scaled such that outliers are not shown. From left to right: classic PCA using SVD,\ntrimmed PCA with iterative removal of outliers, our robust PCA from the randomised streaming algorithm.\n\nof this eigenbasis to represent the variance in the majority of the\ngalaxy spectra: the basis has been influenced by outliers.\nA final, important aspect of the new algorithm is the increase\nin speed. The iterative truncation approach to classic PCA is clearly\ninefficient, although the precise increase in speed will vary depending on dataset properties. For our VVDS test case the 20 iterations\nof classic PCA take five times longer than a single iteration of the\n3485 spectra using the robust algorithm. The ratio will naturally\nchange in favour of the new technique for larger collections of spectra.\nOur robust analysis is based on a randomised algorithm, and,\nas such, it assumes that the input data entries are considered in random order both for the initial set and the stream. When this is not\nthe case, the method may develop a wrong initial representation of\nthe data, which can take many iterations to correct.\nThe sensitivity of the algorithm to this issue is primarily determined by the parameter p, i.e., the number of principal components\nkept between steps. We expect problems only when this value is\ntoo low compared to the weights assigned to the new input vectors.\nIn general, when studying an unknown dataset, we recommend that\none randomises the dataset at each iteration and solves for as many\neigenspectra as possible.\nHaving said that, we should also note that special ordering\nduring the streaming of the data might prove invaluable for studying the evolution of the eigensystem as a function of the parameter\nused for sorting the input data. However, such studies should take\nextreme care in choosing the adjustable parameters (e.g., effective\nsample size) and ensure that the observed trends are real and stable\nto initial conditions.\n\n5 SUMMARY\nWe present a novel method for performing PCA on real-life noisy\nand incomplete data. Our analysis is statistically robust, and implements the current state-of-the-art theoretical approach to generalising the classic analysis. Our streaming technique improves the\neigensystem step-by-step when new observations are considered,\n\nand allows for direct monitoring of the improvement. The convergence is controlled by a single parameter that sets the effective sample size. The relevance of this parameter becomes obvious for very\nlarge datasets such as the SDSS catalog. These large samples are\nvery much redundant in the statistical sense, i.e., often the analysis\nof a smaller subset yields as good results. Our method provides diagnostic tools to ensure convergence while enabling the selection\nof smaller effective sample sizes. The resulting eigenbasis has less\nnoise than a classic PCA, and represents the variance in the majority of the data set without being influenced by outliers. Compared\nto a common work-around for reducing the effect of outliers on\nthe eigenbasis by excluding extreme instances analoguosly to the\ntrimmed mean calculation, the new algorithm provides a noticable\nimprovement in robustness and a substantial increase in speed. A\nproduction implementation within the NVO2 Spectrum Services3\n(Dobos & Budav\u00e1ri 2008) will be released where users of the site\nand Web services can direct the result sets of queries to the robust\nPCA engine. On this site we will publish the IDL scripts used for\nillustrations in this paper.\n\n6 ACKNOWLEDGMENTS\nThe authors would like to thank the VVDS Team for making the\nspectra publicly available along with their metadata. Special thanks\nto Bianca Garilli for her help with obtaining the data. TB is grateful\nto Ricardo Maronna for his invaluable insights into robust statistics.\nThe authors acknowledge useful discussions with Gerard Lemson\nand Istv\u00e1n Csabai. This work was supported by the Gordon and\nBetty Moore Foundation via GBMF 554 and the MAGPop European Research Training Network, MRTN-CT-2004-503929. AS\nwas supported at MPA by the A. von Humbolt Foundation. TB at\nELTE and LD were partially supported by MTA97-OTKA049957NSF, NKTH:Pol\u00e1nyi, RET14/2005, KCKHA005.\n\n2\n3\n\nVisit the US National Virtual Observatory site at http://us-vo.org\nVisit the Spectrum Services at http://www.voservices.net/spectrum\n\n\fReliable eigenspectra\nReferences\nBalogh M. L., Morris S. L., Yee H. K. C., Carlberg R. G., Ellingson\nE., 1999, ApJ, 527, 54\nBudav\u00e1ri, T., Szalay, A. S., Connolly, A. J., Csabai, I., Dickinson,\nM. E., 1999, ASPC, Photometric Redshifts and the Detection\nof High Redshift Galaxies, 191, 19\nBudav\u00e1ri, T., Szalay, A. S., Connolly, A. J., Csabai, I., & Dickinson, M. 2000, AJ, 120, 1588\nConnolly, A. J., Szalay, A. S., Bershady, M. A., Kinney, A. L., &\nCalzetti, D. 1995, AJ, 110, 1071\nConnolly, A. J., Budav\u00e1ri, T., Szalay, A. S., Csabai, I., & Brunner,\nR. J. 1999, ASPC, Photometric Redshifts and the Detection of\nHigh Redshift Galaxies, 191, 13\nConnolly, A. J., & Szalay, A. S. 1999, AJ, 117, 2052\nDobos, L., & Budav\u00e1ri, T., 2008, ASP Conf. Ser., Vol. 382, The\nNational Virtual Observatory: Tools and Techniques for Astronomical Research, eds. M. J. Graham, M. J. Fitzpatrick, &\nT. A. McGlynn (San Francisco: ASP), p.147\nEverson R., & Sirovich L., 1995, J. Opt. Soc. Am. A., 12, 8\nFrancis, P. J., Hewett, P. C., Foltz, C. B., & Chaffee, F. H. 1992,\nApJ, 398, 476\nGlazebrook K., Offer A. R., Deeley K., 1998, ApJ, 492, 98\nHuber, P. J. 1981, Robust Statistics, Wiley Series in Probability and\nStatistics\nKarhunen, H. 1947, Ann. Acad. Science Fenn, Ser. A.I. 37\nLe F\u00e8vre, O., et al. 2005, A&A, 439, 845\nLi, Y., Xu, J., Morphett, L., & Jacobs, R. 2003, Proceedings of\nIEEE International Conference on Image Processing\nLo\u00e8ve, M. 1948, Processus Stochastiques et Mouvement Brownien, Hermann, Paris, France\nMaronna, R. A. 2005, Technometrics, 47, 3\nMaronna, R. A., Martin, R. D., & Yohai, V. J. 2006, Robust Statistics: Theory and Methods, Wiley Series in Probability and\nStatistics\nMcCracken H. J., Radovich M., Bertin E., Mellier Y., Dantel-Fort\nM., Le F\u00e8vre O., Cuillandre J. C., Gwyn S., Foucaud S.,\nZamorani G., 2003, A&A, 410, 17\nWild V., Hewett P. C. 2005, MNRAS, 358, 1083\nWild V., Kauffmann G., Heckman T., Charlot S., Lemson G.,\nBrinchmann J., Reichard T., Pasquali A. 2007, MNRAS, 381,\n543\nWild, V., et al. 2008, submitted to MNRAS, preprint available:\narXiv:0810.5122v1 [astro-ph]\nYip C. W., et al., 2004a, AJ, 128, 585\nYip C. W., et al., 2004b, AJ, 128, 2603\n\n7\n\n\f"}