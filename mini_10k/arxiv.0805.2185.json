{"id": "http://arxiv.org/abs/0805.2185v1", "guidislink": true, "updated": "2008-05-14T23:36:50Z", "updated_parsed": [2008, 5, 14, 23, 36, 50, 2, 135, 0], "published": "2008-05-14T23:36:50Z", "published_parsed": [2008, 5, 14, 23, 36, 50, 2, 135, 0], "title": "Path Diversity over Packet Switched Networks: Performance Analysis and\n  Rate Allocation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0805.3534%2C0805.4166%2C0805.4115%2C0805.0676%2C0805.2180%2C0805.3740%2C0805.0945%2C0805.0643%2C0805.3820%2C0805.1514%2C0805.0032%2C0805.0625%2C0805.4225%2C0805.4572%2C0805.0808%2C0805.4091%2C0805.4642%2C0805.2876%2C0805.0251%2C0805.1481%2C0805.0629%2C0805.4480%2C0805.1330%2C0805.4482%2C0805.1589%2C0805.3045%2C0805.0372%2C0805.4457%2C0805.4297%2C0805.3894%2C0805.1799%2C0805.1476%2C0805.0481%2C0805.1031%2C0805.2560%2C0805.2539%2C0805.3424%2C0805.2185%2C0805.1130%2C0805.0195%2C0805.2958%2C0805.1635%2C0805.4217%2C0805.2376%2C0805.1595%2C0805.3940%2C0805.2619%2C0805.4164%2C0805.1418%2C0805.1930%2C0805.4527%2C0805.3427%2C0805.1653%2C0805.3455%2C0805.4332%2C0805.4001%2C0805.3459%2C0805.2400%2C0805.0510%2C0805.0801%2C0805.4536%2C0805.0428%2C0805.3009%2C0805.3146%2C0805.3189%2C0805.0744%2C0805.4834%2C0805.4444%2C0805.1797%2C0805.4470%2C0805.1759%2C0805.0189%2C0805.3490%2C0805.2994%2C0805.3353%2C0805.4129%2C0805.1881%2C0805.2932%2C0805.3480%2C0805.3125%2C0805.0826%2C0805.2555%2C0805.1380%2C0805.1030%2C0805.1683%2C0805.2119%2C0805.1657%2C0805.1744%2C0805.4128%2C0805.3512%2C0805.0538%2C0805.4282%2C0805.1100%2C0805.1096%2C0805.3970%2C0805.4591%2C0805.4415%2C0805.2699%2C0805.1948%2C0805.1214%2C0805.3697&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Path Diversity over Packet Switched Networks: Performance Analysis and\n  Rate Allocation"}, "summary": "Path diversity works by setting up multiple parallel connections between the\nend points using the topological path redundancy of the network. In this paper,\n\\textit{Forward Error Correction} (FEC) is applied across multiple independent\npaths to enhance the end-to-end reliability. Network paths are modeled as\nerasure Gilbert-Elliot channels. It is known that over any erasure channel,\n\\textit{Maximum Distance Separable} (MDS) codes achieve the minimum probability\nof irrecoverable loss among all block codes of the same size. Based on the\nadopted model for the error behavior, we prove that the probability of\nirrecoverable loss for MDS codes decays exponentially for an asymptotically\nlarge number of paths. Then, optimal rate allocation problem is solved for the\nasymptotic case where the number of paths is large. Moreover, it is shown that\nin such asymptotically optimal rate allocation, each path is assigned a\npositive rate \\textit{iff} its quality is above a certain threshold. The\nquality of a path is defined as the percentage of the time it spends in the bad\nstate. Finally, using dynamic programming, a heuristic suboptimal algorithm\nwith polynomial runtime is proposed for rate allocation over a finite number of\npaths. This algorithm converges to the asymptotically optimal rate allocation\nwhen the number of paths is large. The simulation results show that the\nproposed algorithm approximates the optimal rate allocation (found by\nexhaustive search) very closely for practical number of paths, and provides\nsignificant performance improvement compared to the alternative schemes of rate\nallocation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0805.3534%2C0805.4166%2C0805.4115%2C0805.0676%2C0805.2180%2C0805.3740%2C0805.0945%2C0805.0643%2C0805.3820%2C0805.1514%2C0805.0032%2C0805.0625%2C0805.4225%2C0805.4572%2C0805.0808%2C0805.4091%2C0805.4642%2C0805.2876%2C0805.0251%2C0805.1481%2C0805.0629%2C0805.4480%2C0805.1330%2C0805.4482%2C0805.1589%2C0805.3045%2C0805.0372%2C0805.4457%2C0805.4297%2C0805.3894%2C0805.1799%2C0805.1476%2C0805.0481%2C0805.1031%2C0805.2560%2C0805.2539%2C0805.3424%2C0805.2185%2C0805.1130%2C0805.0195%2C0805.2958%2C0805.1635%2C0805.4217%2C0805.2376%2C0805.1595%2C0805.3940%2C0805.2619%2C0805.4164%2C0805.1418%2C0805.1930%2C0805.4527%2C0805.3427%2C0805.1653%2C0805.3455%2C0805.4332%2C0805.4001%2C0805.3459%2C0805.2400%2C0805.0510%2C0805.0801%2C0805.4536%2C0805.0428%2C0805.3009%2C0805.3146%2C0805.3189%2C0805.0744%2C0805.4834%2C0805.4444%2C0805.1797%2C0805.4470%2C0805.1759%2C0805.0189%2C0805.3490%2C0805.2994%2C0805.3353%2C0805.4129%2C0805.1881%2C0805.2932%2C0805.3480%2C0805.3125%2C0805.0826%2C0805.2555%2C0805.1380%2C0805.1030%2C0805.1683%2C0805.2119%2C0805.1657%2C0805.1744%2C0805.4128%2C0805.3512%2C0805.0538%2C0805.4282%2C0805.1100%2C0805.1096%2C0805.3970%2C0805.4591%2C0805.4415%2C0805.2699%2C0805.1948%2C0805.1214%2C0805.3697&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Path diversity works by setting up multiple parallel connections between the\nend points using the topological path redundancy of the network. In this paper,\n\\textit{Forward Error Correction} (FEC) is applied across multiple independent\npaths to enhance the end-to-end reliability. Network paths are modeled as\nerasure Gilbert-Elliot channels. It is known that over any erasure channel,\n\\textit{Maximum Distance Separable} (MDS) codes achieve the minimum probability\nof irrecoverable loss among all block codes of the same size. Based on the\nadopted model for the error behavior, we prove that the probability of\nirrecoverable loss for MDS codes decays exponentially for an asymptotically\nlarge number of paths. Then, optimal rate allocation problem is solved for the\nasymptotic case where the number of paths is large. Moreover, it is shown that\nin such asymptotically optimal rate allocation, each path is assigned a\npositive rate \\textit{iff} its quality is above a certain threshold. The\nquality of a path is defined as the percentage of the time it spends in the bad\nstate. Finally, using dynamic programming, a heuristic suboptimal algorithm\nwith polynomial runtime is proposed for rate allocation over a finite number of\npaths. This algorithm converges to the asymptotically optimal rate allocation\nwhen the number of paths is large. The simulation results show that the\nproposed algorithm approximates the optimal rate allocation (found by\nexhaustive search) very closely for practical number of paths, and provides\nsignificant performance improvement compared to the alternative schemes of rate\nallocation."}, "authors": ["Shervan Fashandi", "Shahab Oveis Gharan", "Amir K. Khandani"], "author_detail": {"name": "Amir K. Khandani"}, "author": "Amir K. Khandani", "arxiv_comment": "44 pages, 15 eps files. University of Waterloo Technical Report", "links": [{"href": "http://arxiv.org/abs/0805.2185v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0805.2185v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0805.2185v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0805.2185v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:0805.2185v1 [cs.NI] 14 May 2008\n\nPath Diversity over Packet Switched Networks:\nPerformance Analysis and Rate Allocation\nShervan Fashandi, Shahab Oveis Gharan and Amir K. Khandani\nElectrical and Computer Engineering Department\nUniversity of Waterloo, Waterloo, ON, Canada\nE-mail:{sfashand,shahab,khandani}@cst.uwaterloo.ca\n\nTechnical Report UW-E&CE#2008-09\nMay 2008\n\n\f1\n\nPath Diversity over Packet Switched Networks:\nPerformance Analysis and Rate Allocation\nShervan Fashandi, Shahab Oveis Gharan and Amir K. Khandani, Member, IEEE\n\nAbstract\nPath diversity works by setting up multiple parallel connections between the end points using the topological\npath redundancy of the network. In this paper, Forward Error Correction (FEC) is applied across multiple independent paths to enhance the end-to-end reliability. Network paths are modeled as erasure Gilbert-Elliot channels [1]\u2013\n[5]. It is known that over any erasure channel, Maximum Distance Separable (MDS) codes achieve the minimum\nprobability of irrecoverable loss among all block codes of the same size [6], [7]. Based on the adopted model for\nthe error behavior, we prove that the probability of irrecoverable loss for MDS codes decays exponentially for an\nasymptotically large number of paths. Then, optimal rate allocation problem is solved for the asymptotic case where\nthe number of paths is large. Moreover, it is shown that in such asymptotically optimal rate allocation, each path is\nassigned a positive rate iff its quality is above a certain threshold. The quality of a path is defined as the percentage\nof the time it spends in the bad state. Finally, using dynamic programming, a heuristic suboptimal algorithm with\npolynomial runtime is proposed for rate allocation over a finite number of paths. This algorithm converges to the\nasymptotically optimal rate allocation when the number of paths is large. The simulation results show that the\nproposed algorithm approximates the optimal rate allocation (found by exhaustive search) very closely for practical\nnumber of paths, and provides significant performance improvement compared to the alternative schemes of rate\nallocation.1\nIndex Terms\nPath diversity, Internet, MDS codes, erasure, forward error correction, rate allocation, complexity.\n\nI. I NTRODUCTION\n\nI\n\nN recent years, path diversity over the Internet has received significant attention. It has been shown\nthat path diversity has the ability to simultaneously improve the end-to-end rate and reliability [3],\n\n[8]\u2013[10]. In a dense network like the Internet, it is usually possible to find multiple independent paths\nbetween most pairs of nodes [11]\u2013[16]. A set of paths are defined to be independent if their corresponding\npacket loss and delay characteristics are independent. Clearly, disjoint paths would be independent too [3],\n1\n\nFinancial support provided by Nortel and the corresponding matching funds by the Natural Sciences and Engineering Research Council\n\nof Canada (NSERC), and Ontario Centres of Excellence (OCE) are gratefully acknowledged.\n\n\f2\n\n[4], [8], [11], [12], [17]\u2013[19]. Even when the paths are not completely disjoint, their loss and delay patterns\nmay show a high degree of independence as long as the nodes and links they share are not congestion\npoints or bottlenecks [3], [11], [12], [14], [16]\u2013[19]. In this paper, Forward Error Correction (FEC) is\napplied across multiple independent paths. Based on this model, we show that path diversity significantly\nenhances the performance of FEC.\nIn order to apply path diversity over any packet switched network, two problems need to be addressed:\ni) setting up multiple independent paths between the end-nodes, ii) utilizing the given independent paths\nto improve the end-to-end throughput and/or reliability. In this paper, we focus on the second problem\nonly. However, it should be noted that the first problem has also received significant attention in the\nliterature (see [8], [11], [12], [16], [19]\u2013[26]). In case the end-points have enough control over the path\nselection process, the centralized and distributed algorithms in references [27] and [28] can be used to find\nmultiple disjoint paths over a large connected graph. However, applying such algorithms over the Internet\nrequires modification of IP routing protocol and extra signaling between the nodes (routers). Of course,\nmodifying the traditional IP network is extremely costly. To avoid such an expense, overlay networks\nare introduced [16], [19], [29]. The basic idea of overlay networks is to equip very few nodes (smart\nnodes) with the desired new functionalities while the rest remain unchanged. The smart nodes form a\nvirtual network connected through virtual or logical links on top of the actual network. Thus, overlay\nnodes can be used as relays to set up independent paths between the end nodes [22], [24]\u2013[26], [30].\nHan et. al have experimentally studied the number of available disjoint paths in the Internet using overlay\nnetworks [11]. They have also discussed the impact of network path diversity on the performance of overlay\nnetworks [12], [21]. Reference [20] addresses the problem of distributed overlay network design based\non a game theoretical approach. Many other researchers have tried to optimize the design of overlay\nnetworks such that they offer the maximum degree of path diversity [22], [25], [26], [30]. Moreover,\nthe idea of multihoming is proposed to set up extra independent paths between the end-points [23],\n[24]. In this technique, the end users are connected to more than one Internet Service Providers (ISP's)\nsimultaneously. It is shown that combining multihoming with overlay assisted routing can improve the\nend-to-end performance considerably [24]. In the cases where the backbone network partially consists of\noptical links between the nodes, each optical fiber conveys tens of independent channels (tones). There\nhas been efforts to take advantage of this inherent physical layer diversity in optical networks [30].\nRecently, path diversity is utilized in many applications (see [4], [31]\u2013[34]). Reference [32] combines\nmultiple description coding and path diversity to improve quality of service (QoS) in video streaming.\nPacket scheduling over multiple paths is addressed in [35] to optimize the rate-distortion function of\na video stream. Reference [34] utilizes path diversity to improve the quality of Voice over IP streams.\n\n\f3\n\nAccording to [34], sending some redundant voice packets through an extra path helps the receiver buffer\nand the scheduler optimize the trade-off between the maximum tolerable delay and the packet loss\nratio [34]. In [8], multipath routing of TCP packets is applied to control the congestion with minimum\nsignaling overhead. Content Distribution Networks (CDN's) can also take advantage of path diversity\nfor performance improvement. CDN's are a special type of overlay networks consisting of Edge Servers\n(nodes) responsible for delivery of the contents from an original server to the end users [29], [36]. Current\ncommercial CDN's like Akamai use path diversity based techniques like SureRoute to ensure that the edge\nservers maintain reliable connections to the original server. Video server selection schemes are discussed\nin [22] to maximize path diversity in CDN's.\nMoreover, references [9] and [3] study the problem of rate allocation over multiple paths. Assuming\neach path follows the leaky bucket model, reference [9] shows that a water-filling scheme provides the\nminimum end-to-end delay. On the other hand, reference [3] considers a scenario of multiple senders and\na single receiver, assuming all the senders share the same source of data. The connection between each\nsender and the receiver is assumed to follow the Gilbert-Elliot model. They propose a receiver-driven\nprotocol for packet partitioning and rate allocation. The packet partitioning algorithm ensures no sender\nsends the same packet, while the rate allocation algorithm minimizes the probability of irrecoverable\nloss in the FEC scheme [3]. They only address the rate allocation problem for the case of two paths.\nA brute-force search algorithm is proposed in [3] to solve the problem. Generalization of this algorithm\nover multiple paths results in an exponential complexity in terms of the number of paths. Moreover, it\nshould be noted that the scenario of [3] is equivalent, without any loss of generality, to the case in which\nmultiple independent paths connect a pair of end-nodes as they assume the senders share the same data.\nMaximum Distance Separable (MDS) codes have been shown to be optimum in the sense that they\nachieve the maximum possible minimum distance (dmin ) among all the block codes of the same size [37].\nIndeed, any [N, K] MDS code (with block length N and K information symbols) can be successfully\nrecovered from any subset of its entries of length K or more. This property makes MDS codes favorable\nFEC schemes over the erasure channels like the Internet [38]\u2013[40]. However, the simple and practical\nencoding-decoding algorithms for such codes have quadratic time complexity in terms of the code size [41].\n\u0001\nTheoretically, more efficient (O N log2 (N) ) MDS codes can be constructed based on evaluating and\n\ninterpolating polynomials over specially chosen finite fields using Discrete Fourier Transform [42], but\nthese methods are not competitive in practice with the simpler quadratic methods except for extremely\nlarge block sizes. Recently, a family of almost-MDS codes with low encoding-decoding time complexity\n(linear in term of the code length) is proposed and shown to be practical over the erasure channels like\nthe Internet [43], [44]. In these codes, any subset of symbols of size K(1 + \u01eb) is sufficient to recover the\n\n\f4\n\noriginal K symbols with high probability [44].\nMDS codes also require alphabets of a large size. Indeed, all the known MDS codes have alphabet sizes\ngrowing at least linearly with the block length N. There is a conjecture stating that all the [N, K] MDS\ncodes over the Galois field Fq with 1 < K < N \u2212 1 have the property that N \u2264 q + 1 with two exceptions\n[37]. However, this is not an issue in the practical networking applications since the alphabet size is\nq = 2r where r is the packet size, i.e. the block size is much smaller than the alphabet size. Algebraic\ncomputation over Galois fields (Fq ) of such cardinalities is now practically possible with the increasing\nprocessing power of electronic circuits. Note that network coding schemes, recently proposed and applied\nfor content distribution over large networks, have a comparable computational complexity [45]\u2013[47].\nIn this work, we utilize path diversity to improve the performance of FEC between two end-nodes over\na general packet switched network like the Internet. The details of path setup process is not discussed\nhere. More precisely, it is assumed that L independent paths are set up by a smart overlay network or\nany other means [8], [11], [12], [16], [18]\u2013[26]. Each path is modeled by a two-state continuous time\nMarkov process called Gilbert-Elliot channel [1]\u2013[5]. Probability of irrecoverable loss (PE ) is defined as\nthe measure of FEC performance. It is known that MDS block codes have the minimum probability of error\nover our End-to-End Channel model, and over any other erasure channel with or without memory [6],\n[7]. Applying MDS codes, our analysis shows an exponential decay of PE with respect to L for the\nasymptotic case where the number of paths is large. Of course, in many practical cases, the number of\ndisjoint or independent paths between the end nodes is limitted. However, in our asymptotic analysis,\nwe have assumed that it is possible to find L independent paths between the end points even when L is\nlarge. Moreover, the optimal rate allocation problem is solved in the asymptotic case. It is seen that in\nthe asymptotically optimal rate allocation, each path is assigned a positive rate iff its quality is above a\ncertain threshold. Quality of a path is defined as the percentage of the time it spends in the bad state.\nFurthermore, using dynamic programming, a heuristic suboptimal algorithm is proposed for rate allocation\nover a finite number of paths (limitted L). Unlike the brute-force search, this algorithm has a polynomial\ncomplexity, in terms of the number of paths. It is shown that the result of this algorithm converges to the\nasymptotically optimal solution for large number of paths. Finally, the proposed algorithm is simulated\nand compared with the optimal rate allocation found by exhaustive search for practical number of paths.\nSimulation results verify the near-optimal performance of the proposed suboptimal algorithm in practical\nscenarios.\nThe rest of this paper is organized as follows. Section II describes the system model. Probability\ndistribution of the bad burst duration is discussed in section III. Performance of FEC in three cases\nof a single path, multiple identical paths, and non-identical paths are analyzed in section IV. Section V\n\n\f5\n\nFig. 1.\n\nContinuous-time two-state Markov model of the end-to-end channel\n\nstudies the rate allocation problem, and proposes a suboptimal rate allocation algorithm. Finally, section VI\nconcludes the paper.\nII. S YSTEM M ODELING\n\nAND\n\nF ORMULATION\n\nA. End-to-End Channel Model\nFrom an end to end protocol's perspective, performance of the lower layers in the protocol stack can be\nmodeled as a random channel called the end-to-end channel. Since each packet usually includes an internal\nerror detection coding (for instance a Cyclic Redundancy Check), the end-to-end channel is satisfactorily\nmodeled as an erasure channel. Delay of the end-to-end channel is strongly dependent on its packet loss\npattern, and affects the QoS considerably [48], [49].\nIn this work, the model assumed for the end-to-end channel is a two-state Markov model called GilbertElliot cell, depicted in Fig. 1. The channel spends an exponentially distributed random amount of time\nwith the mean\n\n1\n\u03bcg\n\nin the Good state. Then, it alternates to the Bad state and stays in that state for another\n\nrandom duration exponentially distributed with the mean\n\n1\n.\n\u03bcb\n\nIt is assumed that the channel state does not\n\nchange during the transmission of a given packet [4], [50], [51]. Hence, if a packet is transmitted from\nthe source at anytime during the good state, it will be received correctly. Otherwise, if it is transmitted\nduring the bad state, it will eventually be lost before reaching the destination. Therefore, the average\nprobability of error is equal to the steady state probability of being in the bad state, \u03c0b =\n\n\u03bcg\n.\n\u03bcg +\u03bcb\n\nTo have\n\na reasonably low probability of error, \u03bcg must be much smaller than \u03bcb . This model is widely used in\nthe literature for theoretical analysis where delay is not a significant factor [1]\u2013[5], [50]\u2013[52]. Despite its\nsimplicity, this model satisfactorily captures the bursty error characteristic of the end-to-end channel. More\ncomprehensive models like the hidden Markov model are introduced in [49], [53]. Although analytically\ncumbersome, such models express the dependency of loss and delay more accurately.\nB. Typical FEC Model\nA concatenated coding is used for packet transmission. The coding inside each packet can be a simple\nCyclic Redundancy Check (CRC) which enables the receiver to detect an error inside each packet. Then,\n\n\f6\nSource\n\nInternet\n\nDestination\n\nPath 1\nN1\n\nTraffic Allocator\n000000\n111111\n\n111111\n000000\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000Ni\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n000000\n111111\n\nPath i\nSi =\n\nNi\nT\n\n=\n\nNi\nN Sreq\n\n\u2264\n\nNL\nSreq =\n\nN\nT\n\nT\n\nTraffic Reassembler\n\n0000000\n1111111\n1111111\n0000000\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\nWi1111111\n0000000\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\n0000000\n1111111\nL\nX\nNi =\ni=1\nL\nX\n\nPath L\n\ni=1\n\n1\nSi\n\nN\n\n=\n\nT\nNi\n\nSi = Sreq\n\nNi Packets\n\n(a)\nFig. 2.\n\n(b)\n\nRate allocation problem: a block of N packets is being sent from the source to the destination through L independent paths over\n\nthe network during the time interval T with the required rate Sreq =\n\nN\nT\n\n. The block is distributed over the paths according to the vector\n\nN = (N1 , . . . , NL ) which corresponds to the rate allocation vector S = (S1 , . . . , SL )\n\nthe receiver can consider the end-to-end channel as an erasure channel. Other than the coding inside\neach packet, a Forward Error Correction (FEC) scheme is applied between packets. Every K packets are\nencoded to a Block of N packets where N > K to create some redundancy. The N packets of each block\nare distributed across the L available independent paths, and are received at the destination with some\nloss (erasure). The ratio of \u03b1 =\n\nN \u2212K\nN\n\ndefines the FEC overhead. A Maximum Distance Separable (MDS)\n\n[N, K] code, such as the Reed-Solomon code, can reconstruct the original K data packets at the receiver\nside if K or more of the N packets are received correctly [54]. According to the following theorem, an\nMDS code is the optimum block code we can design over any erasure channel. Although FEC imposes\nsome bandwidth overhead, it might be the only option when feedback and retransmission are not feasible\nor fast enough to provide the desirable QoS.\nDefinition I. An erasure channel is defined as the one which maps every input symbol to either itself\nor to an erasure symbol \u03be. More accurately, an arbitrary channel (memoryless or with memory) with the\ninput vector x \u2208 X N , |X | = q , the output vector y \u2208 (X \u222a {\u03be})N , and the transition probability p (y|x)\nis defined to be erasure iff it satisfies the following conditions:\n1) p (yj \u2208\n/ {xj , \u03be}| xj ) = 0, \u2200 j.\n2) Defining the erasure identifier vector e as\n\np(e|x) is independent of x.\n\n\uf8f1\n\uf8f2 1 y =\u03be\nj\nej =\n\uf8f3 0 otherwise\n\nTheorem I. A block code of size [N, K] with equiprobable codewords over an arbitrary erasure channel\n(memoryless or with memory) has the minimum probability of error (assuming optimum, i.e., maximum\nlikelihood decoding) among all block codes of the same size if that code is Maximum Distance Separable\n(MDS). The proof is given in [6], [7].\n\n\f7\n\nC. Rate Allocation Problem\nThe network is modeled as follows. L independent paths, 1, 2, . . . , L, connect the source to the destination, as indicated in Fig. 2(a). Information bits are transmitted as packets, each of a constant length\nr. Furthermore, there is a constraint on the maximum rate for each path, meaning that the i'th path can\nsupport a maximum rate of Wi packets per second. This constraint can be considered as an upperbound\nimposed by the physical characteristics of the path. As an example, [55] introduces the concept of the\nmaximum TCP-friendly bandwidth for the maximum capacity of an Internet path. Wi 's are assumed to\nbe known at the transmitter side. For a specific application and FEC scheme, we require a rate of Sreq\nP\npackets per second from the source to the destination. Obviously, we should have Sreq \u2264 Li=1 Wi to\n\nhave a feasible solution. The information packets are assumed to be coded in blocks of length N packets.\nHence, it takes T =\n\nN\nSreq\n\nseconds to transmit a block of packets. In practical scenarios with finite number\n\nof paths, the end-to-end required rate (Sreq ) is given, and the values of N and T have to be chosen based\non the feasible complexity of the MDS decoder and the delay constraint of the application, respectively.\nP\nAccording to the FEC model, we can send Ni packets through the path i as long as Li=1 Ni = N\nand\n\nNi\nT\n\n\u2264 Wi . The rate assigned to path i can be expressed as Si =\n\nNi\nT\n\n=\n\nNi\nS ,\nN req\n\nsince the transmission\n\ninstants of the Ni packets are distributed evenly over the block duration T (see Fig. 2(b)). Obviously, we\nP\nhave Li=1 Si = Sreq . The objective of rate allocation problem is to find the optimal rate allocation vector\n\nor the vector N = (N1 , * * * , NL ) which minimizes the probability of irrecoverable loss (PE ).\n\nThe above formulation of rate allocation problem is valid for any finite number of paths and any chosen\nvalues of N and T . However, in section IV where the performance of path diversity is studied for a large\nnumber of paths, and also in Theorem III where the optimality of the proposed suboptimal algorithm is\nproved for the asymptotic case, we assume that N grows linearly in terms of the number of paths, i.e.\nN = n0 L, for a fixed n0 . The reason behind this assumption is that when L grows asymptotically large,\nthe number of paths eventually exceeds the block length, if N stays fixed. Thus, L \u2212 N paths become\nuseless for the values of N larger than N. At the same time, it is assumed that the delay imposed by\nFEC, T , stays fixed with respect to L. This model results in a linearly increasing rate as the number of\npaths grows. We will later show that utilizing multiple paths, it is possible to simultaneously achieve an\nexponential decay in PE and a linear increase in rate, while the delay stays constant.\nIn this work, an irrecoverable loss is defined as the event where more than N \u2212 K packets are lost in\na block of N packets. PE denotes the probability of this event. It should be noted that this probability\nis different from the decoding error probability of a maximum likelihood decoder performed on an MDS\n[N, K] code, denoted by P{E}. Theoretically, an optimum maximum likelihood decoder of an MDS code\nmay still decode the original codeword correctly with a positive, but very small probability, if it receives\n\n\f8\n\nless than K symbols (packets). More precisely, such a decoder is able to correctly decode an MDS code\nover Fq with the probability of\n\n1\nqi\n\nafter receiving K \u2212 i correct symbols (see the proof of Theorem I\n\nin [6], [7] for more details). Of course, for Galois fields with a large cardinality, this probability is usually\nnegligible. The relationship between PE and P{E} can be summarized as follows:\nK\nX\nP{K \u2212 i Packets received correctly}\nP{E} = PE \u2212\nqi\ni=1\nK\n\n1X\nP{K \u2212 i Packets received correctly}\n\u2265 PE \u2212\nq i=1\n\u0012\n\u0013\n1\n= PE 1 \u2212\n.\nq\n\nHence, P{E} is bounded as\n\n(1)\n\n\u0013\n\u0012\n1\n\u2264 P{E} \u2264 PE .\nPE 1 \u2212\nq\n\n(2)\n\nThe reason PE is used as the measure of system performance is that while many practical low-complexity\ndecoders for MDS codes work perfectly if the number of correctly received symbols is at least K, their\nprobability of correct decoding is much less than that of maximum likelihood decoders when the number\nof correctly received symbols is less than K [54]. Thus, in the rest of this paper, PE is used as a close\napproximation of decoding error.\nIII. P ROBABILITY D ISTRIBUTION\n\nOF\n\nBAD BURSTS\n\nThe continuous random variable Bi is defined as the duration of time that the path i spends in the bad\nstate in a block duration, T . We denote the values of Bi with parameter t to emphasize that they are\nexpressed in the unit of time. In this section, we focus on one path, for example path 1. Therefore, the\nindex i can be temporarily dropped in analyzing the probability distribution function (pdf) of Bi .\nWe define the events g and b, respectively, as the channel being in the good or bad states at the start\nof a block. Then, the distribution of B can be written as\nfB (t) = fB|b (t)\u03c0b + fB|g \u03c0g .\nTo proceed further, two assumptions are made. First, it is assumed that \u03c0g \u226b \u03c0b or equivalently\n\n(3)\n1\n\u03bcg\n\n\u226b\n\n1\n.\n\u03bcb\n\nThis condition is valid for a channel with a reasonable quality. Besides, the block time T is assumed to\nbe much shorter than the average good state duration\n\n1\n,\n\u03bcg\n\ni.e. 1 \u226b \u03bcg T , such that T can contain either\n\nnone or a single interval of bad burst (see [1], [3], [4] for justification). More precisely, the probability\nof having at least two bad bursts is negligible compared to the probability of having exactly one bad\nburst. However, it should be noted that all the results of this paper except subsection IV-A remain valid\n\n\f9\nT\nEi = 3\n\n1\nSi\n\nBi\nCorrectly\nReceived\nPacket\n\nFig. 3.\n\nLost or\nIncorrect\nPacket\n\nBad\nBurst\n\nA bad burst of duration Bi happens in a block of length T . Ei = 3 packets are corrupted or lost during the interval Bi . Packets\n\nare transmitted every\n\n1\nSi\n\nseconds, where Si is the rate of path i in pkt/sec.\n\nregardless of these two assumptions. Of course, in that case, the exact probability distribution function of\nBi should be used instead of the approximation used here (refer to Remark I in subsection IV-B).\nHence, the pdf of B conditioned on the event b can be approximated as\nfB|b (t) = \u03bcb e\u2212\u03bcb t + \u03b4(t \u2212 T )e\u2212\u03bcb T\n\n(4)\n\nwhere \u03b4(u) is the Dirac delta function. (4) follows from the memoryless nature of the exponential\ndistribution, the assumption that T contains at most one bad burst, and the fact that any bad burst longer\nthan T has to be truncated at B = T .\nTo compute fB|g (t), we have\nfB|g (t) = P{B = 0|g}\u03b4(t) \u2212\n\n\u2202\nP{B > t|g}\n\u2202t\n\n(5)\n\nwhere\nP{B = 0|g} = e\u2212\u03bcg T \u2248 1 \u2212 \u03bcg T\n\n(6)\n\nand\n(a)\n\nP{B > t|g} = (1 \u2212 e\u2212\u03bcg (T \u2212t) )e\u2212\u03bcb t \u2248 \u03bcg (T \u2212 t)e\u2212\u03bcb t\n\n(7)\n\nwhere (a) results from the fact that {B > t|g} is equivalent to the initial good burst being shorter than\nT \u2212 t, and the following bad burst larger than t, and the duration T containing at most one bad burst.\nNow, combining (4), (5), (6), and (7), fB (t) can be computed.\nA. Discrete to Continuous Approximation\nTo compute the probability of irrecoverable loss (PE ), we have to find the probability of ki packets\nbeing lost out of the Ni packets transmitted through the path i, for i from 1 to L and ki from 0 to\nNi . Let us denote the number of erroneous or lost packets over the path i with the random variable Ei .\nAny two subsequent packets transmitted over the path i are\n\n1\nSi\n\nseconds apart in time, where Si is the\n\ntransmission rate over the i'th path. We observe that the probability P{Ei \u2265 ki } can be approximated with\nthe continuous counterpart P{Bi \u2265\nbad burst ( S1i \u226a\n\n1\n,\n\u03bcb\n\nki\n}\nSi\n\nwhen the inter-packet interval is much shorter than the typical\n\nor equivalently \u03bcb \u226a Si ). The necessity of this condition can be intuitively justified\n\nas follows. In case this condition does not hold, any two consecutive packets have to be transmitted\n\n\f10\n\n\u22121\n\n10\n\nSimulation Results\n\nPE\n\nTheoretical Prediction\n\n\u22122\n\n10\n\n\u22123\n\n10\n\nFig. 4.\n\n10\n\n15\n\n20\n\n25\n\u03bcbT\n\n30\n\n35\n\n40\n\nProbability of irrecoverable loss versus \u03bcb T for one path with fixed \u03bcg , T and \u03b1.\n\non two independent states of the channel. Thus, no gain would be achieved by applying diversity over\nmultiple independent paths. Figure 3 shows an example of this approximation in detail. The continuous\napproximation simplifies the mathematical analysis as discussed in section IV.\nIV. P ERFORMANCE A NALYSIS\n\nOF\n\nFEC\n\nON\n\nM ULTIPLE PATHS\n\nAssume that a rate allocation algorithm assigns Ni packets to the path i. According to the discrete to\ncontinuous approximation in subsection III-A, when the Ni packets of the FEC block are sent over path\ni, the loss count can be written as\n\nBi\nNi .\nT\n\nHence, the total ratio of lost packets is equal to\nL\nX\nBi Ni\ni=1\n\nwhere \u03c1i =\n\nSi\n,\nSreq\n\nTN\n\n=\n\nL\nX\nBi \u03c1i\ni=1\n\nT\n\n0 \u2264 \u03c1i \u2264 1, denotes the portion of the bandwidth assigned to path i. xi =\n\nBi\nT\n\nis defined\n\nas the portion of time that path i has been in the bad state (0 \u2264 xi \u2264 1). Hence, the probability of\nirrecoverable loss for an MDS code is equal to\nPE = P\n\n( L\nX\ni=1\n\nwhere \u03b1 =\n\nN \u2212K\n.\nN\n\n\u03c1i xi > \u03b1\n\n)\n\n(8)\n\nIn order to find the optimum rate allocation, PE has to be minimized with respect to\n\nthe allocation vector (\u03c1i 's), subject to the following constraints:\n\u001a\n\u001b\nPL\nWi\n0 \u2264 \u03c1i \u2264 min 1,\n,\ni=1 \u03c1i = 1\nSreq\n\n(9)\n\nwhere Wi is the bandwidth constraint on path i defined in subsection II-C. Note that since xi 's are\nproportional to Bi 's, their pdf can be easily computed based on the pdf of Bi 's.\n\n\f11\n\nA. Performance of FEC on a Single Path\nProbability of irrecoverable loss for one path is equal to\nPE = P{B > \u03b1T } = P{B > \u03b1T |b}\u03c0b + P{B > \u03b1T |g}\u03c0g\nwhere P{B > \u03b1T |b} and P{B > \u03b1T |g} can be computed as\nP{B > \u03b1T |b} =\nP{B > \u03b1T |g} =\n\nRT\n\n\u03b1T\n\nRT\n\n\u03b1T\n\nfB|b (t)dt = e\u2212\u03bcb \u03b1T ,\nfB|g (t)dt = \u03bcg (1 \u2212 \u03b1)T e\u2212\u03bcb \u03b1T\n\nwhen the assumptions in section III and equations (4) and (7) are used. Thus, we have\nPE = \u03c0b e\u2212\u03bcb \u03b1T (1 + \u03bcb (1 \u2212 \u03b1)T )\n\u0014\n\u0015\n(a)\n1\n\u2248\n+ (1 \u2212 \u03b1) T \u03bcg e\u2212\u03bcb \u03b1T\n\u03bcb\n\n(10)\n\nwhere (a) follows from the assumption that the end-to-end channel has a low probability of error ( \u03bc1g \u226b\n1\n).\n\u03bcb\n\nAs we observe, for large values of \u03bcb T , PE decays exponentially with \u03bcb T . Figure 4 shows the results\n,\nof simulating a typical scenario of streaming data between two end-points with the rate Sreq = 1000 pkt\nsec\nthe block length N = 200, and the number of information packets K = 180. These values result in a\nblock transmission time of T = 200ms. The average good burst of the end-to-end channel, \u03bcg , is selected\nsuch that \u03bcg T = 15 . However, the average bad burst, \u03bcb , varies such that \u03bcb T varies from 8 to 40, in\naccordance with the values in [3], [4]. The slope of the best linear fit (in semilog scale) to the simulation\npoints is 0.097 which is in accordance with the value of 0.100, resulted from the theoretical approximation\nin (10).\nB. Identical Paths\nWhen the paths are identical and have equal bandwidth constraints2 (Wi = W for \u2200 1 \u2264 i \u2264 L), due\nto the symmetry of the problem, the uniform rate allocation (\u03c1i = L1 ) is obviously the optimum solution.\nOf course, the solution is feasible only when we have\n\n1\nL\n\n\u2264\n\nW\n.\nSreq\n\nThen, the probability of irrecoverable\n\nloss can be simplified as\nPE = P\n\n(\n\n)\nL\n1X\nxi > \u03b1 .\nL i=1\n\nLet us define Q(x) as the probability distribution function of x. Since x is defined as x =\n\n(11)\nB\n,\nT\n\nclearly we\n\nhave Q(x) = T fB (xT ). Defining E{} as the expected value operator throughout this paper, E{x} can be\n2\n\nThe case where Wi 's are different is discussed in Remark V of subsection IV-C\n\n\f12\n\ncomputed based on Q(x). We observe that in (11), the random variable xi 's are bounded and independent.\nHence, the following well-known upperbound in large deviation theory [56] can be applied\nPE \u2264 e\u2212u(\u03b1)L\n\uf8f1\n\uf8f2 0\nfor \u03b1 \u2264 E{x}\nu(\u03b1) =\n\uf8f3 \u03bb\u03b1 \u2212 log(E{e\u03bbx }) otherwise\n\n(12)\n\nwhere the log function is computed in Neperian base, and \u03bb is the solution of the following non-linear\nequation, which is shown to be unique by Lemma I.\n\u03b1=\n\nE{xe\u03bbx }\n.\nE{e\u03bbx }\n\n(13)\n\nSince \u03bb is unique, we can define l(\u03b1) = \u03bb. Even though being an upperbound, inequality (12) is\nexponentially tight for large values of L [56]. More precisely\n.\nPE = e\u2212u(\u03b1)L\n\n(14)\n\nlog PE\n.\n= u(\u03b1). Now, we state two useful lemmas whose proofs can\nwhere the notation = means lim \u2212\nL\u2212>\u221e\nL\nbe found in the appendices A and B.\nLemma I. u(\u03b1) and l(\u03b1) have the following properties:\n1)\n\n\u2202\nl(\u03b1)\n\u2202\u03b1\n\n>0\n\n2) l (\u03b1 = 0) = \u2212\u221e\n3) l (\u03b1 = E{x}) = 0\n4) l (\u03b1 = 1) = +\u221e\n\u2202\nu(\u03b1)\n\u2202\u03b1\n\n= l(\u03b1) > 0 for \u03b1 > E{x}\nP\nLemma II. Defining y = L1 Li=1 xi , where xi 's are i.i.d. random variables as already defined, the\n.\nprobability density function of y satisfies fy (\u03b1) = e\u2212u(\u03b1)L , for all \u03b1 > E{x}.\n5)\n\nFigure 5 compares the theoretical and simulation results. We assume the block transmission time is\nT = 200ms. The block length is proportional to the number of paths as N = 20L. The average good\nburst of the end-to-end channel, \u03bcg , is selected such that \u03bcg T = 15 . The end-to-end channel has the error\nprobability of \u03c0b = 0.015. Coding overhead is changed from \u03b1 = 0.05 to \u03b1 = 0.2. The probability\nof irrecoverable loss is plotted versus the number of paths, L, in semilogarithmic scale in Fig. 5(a) for\ndifferent values of \u03b1. We observe that as L increases, log PE decays linearly which is expected noting\nequation (12). Also, Fig. 5(b) compares the slope of each plot in Fig. 5(a) with u(\u03b1). Figure 5 shows a\ngood agreement between the theory and the simulation results, and also verifies the fact that the stronger\nthe FEC code is (larger \u03b1), the higher is the gain we achieve through path diversity (larger exponent).\nRemark I. Equation (14) is a direct result of the discrete to continuous approximation in subsection III-A. Therefore, it remains valid even if the other approximations in section III do not hold. For\n\n\f13\n\n0\n\n1.8\n\n10\n\n\u22121\n\n10\n\n1.6\n\nSimulation Results\nTheoretical Prediction\n\n\u22122\n\n10\n\n1.4\n\n\u22123\n\n1.2\nExponent ( u(\u03b1) )\n\n10\n\n\u22124\n\nPE\n\n10\n\n\u03b1=0.2\n\n\u22125\n\n10\n\n\u03b1=0.175\n\u03b1=0.15\n\n\u22126\n\n10\n\n\u03b1=0.1\n\n10\n\n0.4\n\n\u03b1=0.075\n\u03b1=0.05\n\n\u22128\n\n10\n\n0.8\n0.6\n\n\u03b1=0.125\n\n\u22127\n\n1\n\n0.2\n\n\u22129\n\n10\n\n1\n\n2\n\n3\n\n4\n\n5\n6\nNumber of Paths (L)\n\n7\n\n8\n\n9\n\n0\n0.05\n\n10\n\n0.075\n\n(a)\n\n0.1\n\n0.125\n\u03b1\n\n0.15\n\n0.175\n\n0.2\n\n(b)\n\nFig. 5. (a) PE vs. L for different values of \u03b1. (b) The exponent (slope) of plot (a) for different values of \u03b1: experimental versus theoretical\nvalues.\n\nexample, if the block time contains more than one bad burst, equations (4) and (7) are no longer valid.\nHowever, equation (14) is still valid as long as the discrete to continuous approximation is used. Of course,\nin this case, the exact distributions of B and x should be used to compute u(\u03b1) and \u03bb instead of their\nsimplified versions.\nRemark II. A special case is when the block code uses all the bandwidth of the paths. In this case,\nwe have N = LW T , where W is the maximum bandwidth of each path, and T is the block duration.\nAssuming \u03b1 > E{x} is a constant independent of L, we observe that the information packet rate is\n.\n= (1 \u2212 \u03b1) W L, and the error probability is PE = e\u2212u(\u03b1)L . This shows using MDS codes\nequal to K\nT\nover multiple independent paths provides an exponential decay in the irrecoverable loss probability and a\nlinearly growing end-to-end rate in terms of the number of paths, simultaneously.\nC. Non-Identical Paths\nNow, let us assume there are J types of paths between the source and the destination, consisting of Lj\nP\nidentical paths of type j ( Jj=1 Lj = L). Without loss of generality, we assume that the paths are ordered\nPj\u22121\nP\naccording to their associated type, i.e. the paths from 1 + k=1\nLk to jk=1 Lk are of type j. We denote\n\n\u03b3j =\n\nLj\n.\nL\n\nAccording to the i.i.d. assumption, it is obvious that \u03c1i has to be the same for all paths of the\n\nsame type. \u03b7j and yj are defined as\n\u03b7j =\nPj\u22121\n\nk=1\n\nyj\n\n\u03b7j\n=\nL\u03b3j\n\nX\n\nLk <i\u2264\n\nPj\u22121\n\nk=1\n\n\u03c1i\n\nPj\n\nLk\n\nk=1\n\nX\n\nLk <i\u2264\n\nxi .\n\nPj\n\nk=1\n\nLk\n\n(15)\n\n\f14\n\u03b2\n\n. \u2212\u03b3j uj ( \u03b7jj )L\nFollowing Lemma II, we observe that fyj (\u03b2j ) = e\n. We define the sets SI , SO and ST as\n\nSI =\n\n(\n\nSO =\n\n(\n\nST =\n\nJ\nX\n\n(\u03b21 , \u03b22 , * * * , \u03b2J ) |0 \u2264 \u03b2j \u2264 1,\n\n\u03b2j > \u03b1\n\n)\n\n\u03b2j = \u03b1\n\n)\n\nj=1\n\nJ\nX\n\n(\u03b21 , \u03b22 , * * * , \u03b2J ) |0 \u2264 \u03b2j \u2264 1,\n\nj=1\n\n(\n\n(\u03b21 , \u03b22 , * * * , \u03b2J ) |\u03b7j E {xj } \u2264 \u03b2j ,\n\nJ\nX\nj=1\n\nrespectively. Hence, PE can be written as\nPE = P\n\n( J\nX\n\nyj > \u03b1\n\nj=1\n\n=\n\nZ Y\nJ\n\n\u03b2j = \u03b1\n\n)\n\n)\n\nfyj (\u03b2j )d\u03b2j\n\nSI j=1\n\n.\n=\n\nZ\n\n\u2212L\n\n\u2212L\n\n.\n= e\n\n(b)\n\n\u2212L\n\n.\n= e\n\n(c)\n\n\u2212L\n\n.\n= e\n\n(d)\n\n\u2212L\n\n.\n= e\n\n\u03b3j uj (\n\nj=1\n\ne\n\nSI\n\n(a)\n\nJ\nX\n\nmin\n\n\u03b2\u2208SI \u222aSO\n\nmin\n\n\u03b2\u2208SO\n\nmin\n\n\u03b2\u2208ST\nJ\nX\nj=1\n\nJ\nX\n\n\u03b3j uj\n\nj=1\n\nJ\nX\n\nJ\nX\n\nd\u03b2j\n\u0012\n\n\u03b3j uj\n\n\u0012\n\n\u03b2j\n\u03b7j\n\n\u03b3j uj\n\n\u0012\n\n\u03b2j\n\u03b7j\n\n\u03b2j\u22c6\n\u03b7j\n\n\u0013\n\nj=1\n\nj=1\n\n\u03b3j uj\n\n\u03b2j\n)\n\u03b7j\n\n\u0012\n\n\u03b2j\n\u03b7j\n\u0013\n\n\u0013\n\n\u0013\n\n(16)\n\nwhere (a) follows from Lemma III, (b) follows from the fact that uj (\u03b1) is a strictly increasing function\nof \u03b1, for \u03b1 > E{xj }, and (c) can be proved as follows. Let us denote the vector which minimizes the\n\u22c6\n\n\u22c6\n\nexponent over the set SO as \u03b2\u0302 . Since ST is a subset of SO , \u03b2\u0302 is either in ST or in SO \u2212ST . In the former\n\u22c6\n\ncase, (c) is obviously valid. When \u03b2\u0302 \u2208 SO \u2212ST , we can prove that 0 \u2264 \u03b2\u0302j\u22c6 \u2264 \u03b7j E{xj }, for all 1 \u2264 j \u2264 J,\nby contradiction. Let us assume the opposite is true, i.e., there is at least one index 1 \u2264 j \u2264 J such that\n0 \u2264 \u03b2\u0302j\u22c6 \u2264 \u03b7j E{xj }, and at least one other index 1 \u2264 k \u2264 J such that \u03b7k E{xk } < \u03b2\u0302k\u22c6 . Then, knowing that\nthe derivative of of uj (\u03b1) is zero for \u03b1 = E{xj } and strictly positive for \u03b1 > E{xj }, a small increase\n\u0010 \u0011\nPJ\n\u03b2\n\u22c6\n\u22c6\nin \u03b2\u0302j and an equal decrease in \u03b2\u0302k reduces the objective function, j=1 \u03b3j uj \u03b7jj , which contradicts the\n\u22c6\n\nassumption that \u03b2\u0302 is a minimum point. Knowing that 0 \u2264 \u03b2\u0302j\u22c6 < \u03b7j E{xj }, for all 1 \u2264 j \u2264 J, it is easy\n\n\f15\n\nto show that the minimum value of the objective function is zero over SO , and ST has to be an empty\nset. Defining the minimum value of the positive objective function as zero over an empty set (ST ) makes\n\u22c6\n\n(c) valid for the latter case where \u03b2\u0302 \u2208 SO \u2212 ST . Finally, applying Lemma IV results in (d) where \u03b2 \u22c6 is\ndefined in the Lemma.\nLemma III. For any continuous positive function h(x) over a convex set S, and defining H(L) as\nZ\nH(L) =\ne\u2212h(x)L dx\nS\n\nwe have\nlim \u2212\n\nL\u2192\u221e\n\nlog(H(L))\n= inf h(x) = min h(x)\nS\ncl(S)\nL\n\nwhere cl(S) denotes the closure of S (refer to [57] for the definition of the closure operator). Proof of\nLemma III can be found in appendix C.\n\u0010 \u0011\n\u03bd\u03b7\nLemma IV. There exists a unique vector \u03b2 \u22c6 with the elements \u03b2j\u22c6 = \u03b7j lj\u22121 \u03b3jj which minimizes the\nP\n\u03b2\nconvex function Jj=1 \u03b3j uj ( \u03b7jj ) over the convex set ST , where \u03bd satisfies the following condition\nJ\nX\n\n\u03b7j lj\u22121\n\nj=1\n\n\u0012\n\n\u03bd\u03b7j\n\u03b3j\n\n\u0013\n\n= \u03b1.\n\n(17)\n\nl\u22121 () denotes the inverse of the function l() defined in subsection IV-B. Proof of Lemma IV can be found\nin appendix D.\nEquation (16) is valid for any fixed value of \u03b7. To achieve the most rapid decay of PE , the exponent\nmust be maximized over \u03b7.\n\u0012 \u22c6\u0013\nJ\nX\n\u03b2j\nlog PE\n= max\n\u03b3j uj\nlim \u2212\n0\u2264\u03b7j \u22641\nL\u2192\u221e\nL\n\u03b7j\nj=1\n\n(18)\n\nwhere \u03b2 \u22c6 is defined for any value of the vector \u03b7 in Lemma IV. Theorem II solves the maximization\nproblem in (18) and identifies the asymptotically optimum rate allocation (for large number of paths).\nTheorem II. Consider a point-to-point connection over the network with L independent paths from the\nsource to the destination, each modeled as a Gilbert-Elliot cell, with a large enough bandwidth constraint3.\nThe paths are from J different types, Lj paths from the type j. Assume a block FEC of size [N, K] is\nsent during a time interval T . Let Nj denote the number of packets in a block of size N assigned to the\nP\nN\npaths of type j, such that Jj=1 Nj = N. The rate allocation vector \u03b7 is defined as \u03b7j = Nj . For fixed\nvalues of \u03b3j =\n3\n\nLj\n,\nL\n\nn0 =\n\nN\n,\nL\n\nk0 =\n\nK\n,\nL\n\nT and asymptotically large number of paths L, the optimum rate\n\nBy the term 'large enough', we mean the bandwidth constraint on a path of type j, Wj , satisfies the condition\n\nis that \u03b7j must satisfy both conditions of 0 \u2264 \u03b7j \u2264 1 and\n\u03b7j n0\nT \u03b3j\n\nNj\nT Lj\n\n=\n\n\u03b7j n0 L\nT \u03b3j L\n\n\u03b7j n0\nT \u03b3j\n\n\u2264 Wj . The reason\n\n\u2264 Wj , simultaneously. When Wj is large enough such that\n\n\u2264 Wj , the latter condition is automatically satisfied, and the optimization problem can be solved.\n\n\f16\n\n\u22121\n\n10\n\n1\nopt\n\n0.9\n\n\u03b71\n\n0.8\n\n\u03b71\n\n*\n\n\u22122\n\n10\n\n0.7\n\n\u03b7\n\n1\n\nP\n\nE\n\n0.6\n0.5\n0.4\n\n\u22123\n\n10\n\n0.3\n0.2\n0.1\n\u22124\n\n10\n\n3\n\n6\n\n9\n\n0\n\n12\n\nNumber of Paths (L)\n\n3\n\n6\n\n(a)\nFig. 6.\n\n9\n\n12\n\nNumber of Paths (L)\n\n(b)\n\n(a) PE versus L for the combination of two path types, one third from type I and the rest from type II. (b) The normalized\n\naggregated weight of type I paths in the optimal rate allocation (\u03b71opt ), compared with the value of \u03b71 which maximizes the exponent of\nequation (18) (\u03b71\u22c6 ).\n\nallocation vector \u03b7 \u22c6 can be found by solving the following optimization problem:\nmax g(\u03b7),\n\u03b7\n\ns.t.\n\nJ\nX\n\n\u03b7j = 1, 0 \u2264 \u03b7j \u2264 1\n\nj=1\n\nwhere g(\u03b7) =\n\nPJ\n\nj=1 \u03b3j uj\n\n\u0010 \u03b2\u22c6 \u0011\nj\n\n\u03b7j\n\n, and \u03b2 \u22c6 is an implicit function of \u03b7 defined in Lemma IV. The functions\n\nuj () and lj () are defined in subsections IV-B and IV-C. Solving the above optimization problem gives the\nunique solution \u03b7 \u22c6 as\n\n\u03b7j\u22c6 =\n\n\uf8f1\n\uf8f4\n0\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\nif \u03b1 \u2264 E{xj }\n\u03b3j lj (\u03b1)\notherwise\nJ\nX\n\u03b3i li (\u03b1)\n\n(19)\n\ni=1, \u03b1>E{xi }\n\nif there is at least one 1 \u2264 j \u2264 J for which \u03b1 > E{xj }. Otherwise, when \u03b1 \u2264 E{xj } for all 1 \u2264 j \u2264 J,\nthe maximum value is zero for any arbitrary rate allocation vector, \u03b7. In any case, the maximum value of\nP\nthe objective function is g(\u03b7 \u22c6 ) = Jj=1 \u03b3j uj (\u03b1) which is indeed the exponent of PE versus L. The proof\n\nof the theorem can be found in appendix E.\n\nRemark III. Theorem II can be interpreted as follows. For large values of L, adding a new type of\npath contributes to the path diversity iff the path satisfies the quality constraint \u03b1 > E{x}, where x is the\npercentage of time that the path spends in the bad state in the time interval [0, T ]. Only in this case, adding\n\n\f17\n\nthe new type of path exponentially improves the performance of the system in terms of the probability\nof irrecoverable loss.\nRemark IV. Observing the exponent coefficient corresponding to the optimum allocation vector \u03b7 \u22c6 ,\nwe can see that the typical error event occurs when the ratio of the lost packets on all types of paths is\nthe same as the total fraction of the lost packets, \u03b1. However, this is not the case for any arbitrary rate\nallocation vector \u03b7.\nRemark V. An interesting extension of Theorem II is the case where all types have identical erasure\npatterns (uj (x) = uk (x) for \u2200 1 \u2264 j, k \u2264 J and \u2200x), but different bandwidth constraints. Adopting the\nnotation of Theorem II, the bandwidth constraint on \u03b7j can be written as\n\n\u03b7j n0 L\nT \u03b3j L\n\n\u2264 Wj , where Wj is the\n\nmaximum bandwidth for a path of type j. Let us define \u03b7\u0303 \u22c6 as the allocation vector which maximizes the\nobjective function of Theorem II (g(\u03b7)), and satisfies the bandwidth constraints too. \u03b7 \u22c6 is also defined as\nthe maximizing vector for the unconstrained problem in Theorem II. According to equation (19), we have\n\u03b7j\u22c6 = \u03b3j for \u22001 \u2264 j \u2264 J. It is obvious that \u03b7\u0303 \u22c6 = \u03b7 \u22c6 if \u03b7j\u22c6 \u2264\n\n\u03b3j Wj T\nn0\n\nfor all j. In case \u03b7j\u22c6 does not satisfy\n\nthe bandwidth constraint for some j, \u03b7\u0303 \u22c6 can be found by the water-filling algorithm. More accurately, we\nhave\n\n\uf8f1\n\u03b3WT\n\uf8f4\n\uf8f2 j j\nn0\n\u03b7\u0303j\u22c6 =\n\uf8f4\n\uf8f3 \u03b3j \u03a5\n\nwhere \u03a5 can be found by imposing the condition\n\nif \u03b7\u0303j\u22c6 \u2264 \u03b3j \u03a5\nif\n\n\u03b7\u0303j\u22c6\n\nPJ\n\n(20)\n\n\u03b3j Wj T\n<\nn0\n\n\u22c6\nj=1 \u03b7\u0303j\n\n= 1. Figure 7 depicts water-filling among\n\nidentical paths with four different bandwidth constraints. Proof of equation (20) can be found in appendix F.\nFigure 6(a) shows PE of the optimum rate allocation versus L for a system consisting of two types\nof path. The optimal rate allocation is found by exhaustive search among all possible allocation vectors.\nThe block transmission time is T = 200ms. The block length is proportional to the number of paths as\nN = 20L. The average good burst, \u03bcg , is selected such that we have \u03bcg T =\n\u03b31 =\n\n1\n3\n\n1\n5\n\nfor both types of paths.\n\nof the paths (of the first type) benefit from shorter bad bursts and lower error probability of\n\n\u03c0b,1 = 0.015, and the rest (the second type) suffer from longer congestion bursts resulting in a higher\nerror probability of \u03c0b,2 = 0.025. The coding overhead is \u03b1 = 0.1. The figure depicts a linear behavior in\nsemi-logarithmic scale with the exponent of 0.403, which is comparable to 0.389 resulted from (19).\nIn the scenario of Fig. 6(a), let us denote \u03b71\u22c6 as the value of of the first element of \u03b7 in equation (19).\nObviously, \u03b71\u22c6 does not depend on L. Moreover, \u03b71opt is defined as the normalized aggregated weight of\ntype I paths in the optimal rate allocation. Figure 6(b) compares \u03b71opt with \u03b71\u22c6 for different number of paths.\nIt is observed that \u03b71opt converges rapidly to \u03b71\u22c6 as L grows. Figure 6(a) also verifies that the allocation\nvector candidate \u03b7 \u22c6 proposed by Theorem II indeed meets the optimal allocation vector for large values\nof L.\n\n\f18\nW1 T\nn0\nW3 T\nn0\n\n\u03a5\nW4 T\nn0\nW2 T\nn0\n\n\u03b71\n\u03b31\n\nFig. 7.\n\n\u03b72\n\u03b32\n\n\u03b73\n\u03b33\n\n\u03b74\n\u03b34\n\nWaterFilling algorithm over identical paths with four different bandwidth constraints.\n\nV. S UBOPTIMAL R ATE A LLOCATION\nIn order to compute the complexity of the rate allocation problem, we focus our attention on the\noriginal discrete formulation in subsection II-C. According to the model of subsection IV-C, we assume\nP\nthe available paths are from J types, Lj paths from type j, such that Jj=1 Lj = L. Obviously, all the\n\npaths from the same type should have equal rate. Therefore, the rate allocation problem is turned into\nP\nfinding the vector N = (N1 , . . . , NJ ) such that Jj=1 Nj = N, and 0 \u2264 Nj \u2264 Lj Wj T for all j. Nj\n\ndenotes the number of packets assigned to all the paths of type j. Let us temporarily assume that all paths\n\u0001\n+J\u22121\nL-dimensional\nhave enough bandwidth such that Nj can vary from 0 to N for all j. There are N J\u22121\nPJ\nnon-negative vectors of the form (N1 , . . . , NJ ) which satisfy the equation j=1 Nj = N each representing\na distinct rate allocation. Hence, the number of candidates is exponential in terms of J.\n\nFirst, we prove the problem of rate allocation is NP [58] in the sense that PE can be computed in\npolynomial time for any candidate vector N = (N1 , . . . , NJ ). Let us define PeN (k, j) as the probability\nof having more than k errors over the paths of types 1 to j for a specific allocation vector N. We also\ndefine Qj (n, k) as the probability of having exactly k errors out of the n packets sent over the paths of\ntype j. Qj (n, k) can be computed and stored for all path types and values of n and k with polynomial\ncomplexity as explained in appendices G and H. Then, the following recursive formula holds for PeN (k, j)\n\uf8f1\nNj\n\uf8f4\nX\n\uf8f4\n\uf8f2\nQj (Nj , i)PeN (k \u2212 i, j \u2212 1) if k \u2265 0\nPeN (k, j) =\ni=0\n\uf8f4\n\uf8f4\n\uf8f3 1\nif k < 0\nPeN (k, 1)\n\n=\n\nN1\nX\n\nQ1 (N1 , i).\n\n(21)\n\ni=k+1\n\nTo compute PeN (K, J) by the above recursive formula, we apply a well-known technique in the theory\nof algorithms called memoization [59]. Memoization works by storing the computed values of a recursive\nfunction in an array. By keeping this array in the memory, memoization avoids recomputing the function for\n\n\f19\n\nthe same arguments when it is called later. To compute PeN (K, J), an array of size O(KJ) is required. This\narray should be filled with the values of PeN (k, j) for 0 < k \u2264 K, and 1 \u2264 j \u2264 J. Computing PeN (k, j)\nPNj\nQj (Nj , i) are\nrequires O(K) operations assuming the values of PeN (i, j \u2212 1) and Qj (Nj , i) and i=k+1\n\nalready computed for 0 \u2264 i \u2264 k. Thus, PeN (K, J) can be computed with the complexity of O(K 2 J) if the\n\nvalues of Qj (Nj , k) are given for all Nj and 0 \u2264 k \u2264 K. Following appendix H, we note that for each\n\u0011\n\u0010\nN\nj, Qj (Nj , k) for 0 \u2264 k \u2264 K is computed offline with the complexity of O(K 2Lj ) + O Ljj K . Hence,\nthe total complexity of computing PeN (K, J) adds up to\n\u0012\n\u0013\nJ\nX\nNj\n2\n2\nO(K J) +\nO K Lj +\nK\nL\nj\nj=1\n(a)\n\n2\n\n= O(K J) +\n\nJ\nX\n\nO K 2 Lj + Nj K\n\nj=1\n\n(b)\n\n= O K 2 L + KN\n\nwhere (a) follows from the fact that\n\nNj\nLj\n\n\u0001\n\n\u0001\n(22)\n\n< Nj , and the term O(K 2 J) is omitted in (b) since we know\n\nthat J < L.\nNow, we propose a suboptimal polynomial time algorithm to estimate the best path allocation vector,\nNopt . Let us define Peopt (n, k, j) as the probability of having more than k errors for a block of length n\nover the paths of types 1 to j minimized over all possible rate allocations (N = Nopt ). First, we find a\nlowerbound P\u0302e (n, k, j) for Peopt(n, k, j) from the following recursive formula\n\uf8f1\nnj\nX\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nmin\nQj (nj , i)*\n\uf8f4\n\uf8f4\n0\u2264nj \u2264min {n,\u230aLj Wj T \u230b}\n\uf8f4\ni=0\n\uf8f4\n\uf8f2\nP\u0302e (n \u2212 nj , k \u2212 i, j \u2212 1) if k > 0\nP\u0302e (n, k, j) =\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 1\nif k \u2264 0\nP\u0302e (n, k, 1) =\n\nn\nX\n\nQ1 (n, i).\n\n(23)\n\ni=k+1\n\nUsing memoization technique, we need an array of size O(NKJ) to store the values of P\u0302e (n, k, j) for\n0 < n \u2264 N, 0 < k \u2264 K, and 1 \u2264 j \u2264 J. According to the recursive definition above, computing\nP\u0302e (n, k, j) requires O(NK) operations assuming the values of Qj (nj , i) and P\u0302e (n \u2212 nj , k \u2212 i, j \u2212 1) and\nPnj\ni=k+1 Qj (nj , i) are already computed for all i and nj . Thus, it is easy to verify that P\u0302e (N, K, J) can be\ncomputed with the complexity of O(N 2 K 2 J) when the values of Qj (nj , i) are given for all 0 < nj \u2264 n\n\nand 0 \u2264 i \u2264 K. According to appendix H, for each 1 \u2264 j \u2264 J, and for each 0 < nj \u2264 N, Qj (nj , i)\n\u0011\n\u0010\nn\nfor all 0 \u2264 i \u2264 nj is computed offline with the complexity of O(n2j Lj ) + O Ljj nj = O(n2j Lj ). Thus,\ncomputing Qj (nj , i) for all 1 \u2264 j \u2264 J, and 0 < nj \u2264 N, and 0 \u2264 i \u2264 nj , has the complexity of\n\n\f20\n\nPJ\n\nj=1\n\nPN\n\nnj =1\n\nO(n2j Lj ) = O(N 3 L). Finally, P\u0302e (N, K, J) can be computed with the total complexity of\n\nO(N 2 K 2 J + N 3 L).\nThe following lemma guarantees that P\u0302e (n, k, j) is in fact a lowerbound for Peopt (n, k, j).\nLemma V. Peopt(n, k, j) \u2265 P\u0302e (n, k, j). The proof is given in appendix I.\nThe following algorithm recursively finds a suboptimum allocation vector N\u0302 based on the lowerbound\nof Lemma V.\n(1): Initialize j \u2190 J, n \u2190 N, k \u2190 K.\n(2): Set\nN\u0302j =\n\nargmin\n\nnj\nX\n\nQj (nj , i) *\n\n0\u2264nj \u2264min {n,\u230aLj Wj T \u230b} i=0\n\nP\u0302e (n \u2212 nj , k \u2212 i, j \u2212 1)\nKj = argmax Qj (N\u0302j , i)P\u0302e (n \u2212 N\u0302j , k \u2212 i, j \u2212 1)\n0\u2264i\u2264N\u0302j\n\n(3): Update n \u2190 n \u2212 N\u0302j , k \u2190 k \u2212 Kj , j \u2190 j \u2212 1.\n(4): If j > 1 and k \u2265 0, goto (2).\nn\n(5): For m = 1 to j, set N\u0302m \u2190 \u230a \u230b.\nj\n(6): N\u0302j \u2190 N\u0302j + Rem(n, j) where Rem(a, b) denotes the remainder of dividing a by b.\nIntuitively speaking, the above algorithm tries to recursively find the typical error event (Kj 's) which\nhas the maximum contribution to the error probability, and assigns the rate allocations (N\u0302j 's) such that\nthe estimated typical error probability (P\u0302e ) is minimized. Indeed, Lemma V shows that the estimate used\nin the algorithm (P\u0302e ) is a lower-bound for the minimum achievable error probability (Peopt ). Comparing\n(23) and the step (2) of our algorithm, we observe that the values of N\u0302j and Kj can be found in O(1)\nduring the computation of P\u0302e (N, K, J). Hence, complexity of the proposed algorithm is the same as that\nof computing P\u0302e (N, K, J), O(N 2 K 2 J + N 3 L).\nThe following theorem guarantees that the output of the above algorithm converges to the asymptotically\noptimal rate allocation introduced in Theorem II of section IV-C, and accordingly, it performs optimally\nfor large number of paths.\nTheorem III. Consider a point-to-point connection over the network with L independent paths from the\nsource to the destination, each modeled as a Gilbert-Elliot cell with a large enough bandwidth constraint.\nThe paths are from J different types, Lj paths from the type j. Assume a block FEC of the size [N, K]\nis sent during an interval time T . For fixed values of \u03b3j =\nlarge number of paths (L) we have\nPJ\n.\n.\n1) P\u0302e (N, K, J) = Peopt(N, K, J) = e\u2212L j=1 \u03b3j uj (\u03b1)\n\nLj\n,\nL\n\nn0 =\n\nN\n,\nL\n\nk0 =\n\nK\n,\nL\n\nT and asymptotically\n\n\f21\n\nN\u0302j\n= \u03b7j\u22c6 + o(1)\nN\nK\n3) N\u0302j = \u03b1 + o(1) for \u03b1 > E{xj }.\n\n2)\n\nj\n\nwhere \u03b1 =\n\nk0\nn0\n\nand uj () are defined in subsections IV-B and IV-C. P\u0302e (N, K, J) is the lowerbound for\n\nPeopt (n, k, j) defined in equation (23). N\u0302j is the total number of packets assigned to the paths of type\nj by the suboptimal rate allocation algorithm. \u03b7j\u22c6 is the asymptotically optimal rate allocation given in\nequation (19). Kj is also defined in the step (2) of the algorithm. The notation f (L) = o(g(L)) means\nlimL\u2192\u221e\n\nf (L)\ng(L)\n\n= 0. The proof can be found in appendix J.\n\nThe proposed algorithm is compared with four other allocation schemes over L = 6 paths in Fig. 8.\nThe optimal method uses exhaustive search over all possible allocations. 'Best Path Allocation' assigns\neverything to the best path only, ignoring the rest. 'Equal Distribution' scheme distributes the packets\namong all paths equally. Finally, the 'Asymptotically Optimal' allocation assigns the rates based on\nequation (19). The block length and the number of information packets are assumed to be N = 100\nand K = 90, respectively. The overall rate is Sreq = 1000pkt/sec which results in T = 100ms. The\naverage good burst, \u03bcg , is selected such that we have \u03bcg T = 51 . However, quality of the paths are different\nas they have different average bad burst durations. Packet error probability of the paths are listed as\n[0.0175 \u00b1\n\n\u2206\n, 0.0175\n2\n\n\u00b1\n\n3\u2206\n, 0.0175\n2\n\n\u00b1\n\n5\u2206\n],\n2\n\nsuch that the median is fixed at 0.0175. \u2206 is also defined as a\n\nmeasure of deviation from this median. \u2206 = 0 represents the case where all the paths are identical. The\nlarger is \u2206, the more variety we have among the paths and the more diversity gain might be achieved\nusing a judicious rate allocation.\nAs seen, our suboptimal algorithm tracks the optimal algorithm so closely that the corresponding curves\nare not easily distinguishable over a wide range. However, the 'Asymptotically Optimal' rate allocation\nresults in lower performance since there is only one path from each type which makes the asymptotic\nanalysis assumptions invalid. When \u2206 = 0, 'Equal Distribution' scheme obviously coincides with the\noptimal allocation. This scheme eventually diverges from the optimal algorithm as \u2206 grows. However, it\nstill outperforms the best path allocation method as long as \u2206 is not too large. For very large values of\n\u2206, the best path dominates all the other ones, and we can ignore the rest of the paths. Hence, the best\npath allocation eventually converges to the optimal scheme when \u2206 increases.\nVI. C ONCLUSION\nIn this work, we have studied the performance of forward error correction over a block of packets sent\nthrough multiple independent paths. It is known that Maximum Distance Separable (MDS) block codes\nare optimum over our End-to-End Channel model, and any other erasure channel with or without memory,\nin the sense that their probability of error is minimum among all block codes of the same size [6], [7].\n\n\f22\n\n0.06\nOptimal Allocation\nSuboptimal Allocation\nAsymptotically Optimal Allocation\n\n0.05\n\nEqual Distribution\nBest Path Allocation\n\nPE\n\n0.04\n\n0.03\n\n0.02\n\n0.01\n\n0\n\nFig. 8.\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\u2206\n\n3\n\n3.5\n\n4\n\n4.5\n\n5\n\u22123\n\nx 10\n\nOptimal and suboptimal rate allocations are compared with equal distribution and best path allocation schemes for different values\n\nof \u2206\n\nAdopting MDS codes, the probability of irrecoverable loss, PE , is analyzed for the cases of a single path,\nmultiple identical, and multiple non-identical paths based on the discrete to continuous relaxation. When\nthere are L identical paths, PE is upperbounded using large deviation theory. This bound is shown to be\nexponentially tight in terms of L. The asymptotic analysis shows that the exponential decay of PE with L\nis still valid in the case of non-identical paths. Furthermore, the optimal rate allocation problem is solved\nin the asymptotic case where L is very large. It is seen that for the optimal rate allocation, each path\nis assigned a positive rate iff its quality is above certain threshold. The quality of a path is defined as\nthe percentage of the time it spends in the bad state. Finally, we focus on the problem of optimum rate\nallocation when L is not necessarily large. A heuristic suboptimal algorithm is proposed which computes a\nnear-optimal allocation in polynomial time. For large values of L, the result of this algorithm converges to\nthe optimal solution. Moreover, simulation results are provided which verify the validity of our theoretical\nanalyses in several practical scenarios, and also show that the proposed suboptimal algorithm approximates\nthe optimal allocation very closely.\nA PPENDIX A\nP ROOF\n\nOF\n\n1) We define the function v(\u03bb) as\nv(\u03bb) =\n\nL EMMA I\n\nE{xe\u03bbx }\n.\nE{e\u03bbx }\n\n(24)\n\nThen, the first derivative of v(\u03bb) will be\nE{x2 e\u03bbx }E{e\u03bbx } \u2212 [E{xe\u03bbx }]2\n\u2202\nv(\u03bb) =\n.\n\u2202\u03bb\n[E{e\u03bbx }]2\n\n(25)\n\n\f23\n\nAccording to Cauchy-Schwarz inequality, the following statement is always true for any two functions of\nf () and g()\n\u0012Z\n\nx\n\n\u00132 Z\nZ\n2\nf (x)g(x)dx < f (x)dx g 2 (x)dx\nx\n\n(26)\n\nx\n\np\nunless f (x) = Kg(x) for a constant K and all values of x. If we choose f (x) = x2 Q(x)ex\u03bb and\np\ng(x) = Q(x)ex\u03bb , they can not be proportional to each other for all values of x. Therefore, the numerator\nof equation (25) has to be strictly positive for all \u03bb. Since the function v(\u03bb) is strictly increasing, it has\n\nan inverse v \u22121 (\u03b1) which is also strictly increasing. Moreover, the non-linear equation v(\u03bb) = \u03b1 has a\nunique solution of the form \u03bb = v \u22121 (\u03b1) = l(\u03b1).\n2) To show that l(\u03b1 = 0) = \u2212\u221e, we prove an equivalent statement of the form lim\u03bb\u2192\u2212\u221e v(\u03bb) = 0. Since\nx is a random variable in the range [0, 1] with the probability density function Q(x), for any 0 < \u01eb < 1,\nwe can write\nR1\nxQ(x)ex\u03bb dx + \u01eb xQ(x)ex\u03bb dx\nlim v(\u03bb) = lim\nR1\n\u03bb\u2192\u2212\u221e\n\u03bb\u2192\u2212\u221e\nQ(x)ex\u03bb dx\n0\nR1\nR\u01eb\nx\u03bb\nxQ(x)dx\nxQ(x)e\ndx\n+ R\u01eb \u01eb\n\u2264 lim R0 \u01eb\nx\u03bb\n\u03bb\u2192\u2212\u221e\nQ(x)e dx\nQ(x)e(x\u2212\u01eb)\u03bb dx\n0\nR \u01eb0\nxQ(x)ex\u03bb dx\n(a)\n= lim R0 \u01eb\n\u03bb\u2192\u2212\u221e\nQ(x)ex\u03bb dx\n0\nx1 Q(x1 )e\u03bbx1\n(b)\n= lim\n\u03bb\u2192\u2212\u221e Q(x2 )e\u03bbx2\nR\u01eb\n0\n\n(27)\n\nfor some x1 , x2 \u2208 [0, \u01eb]. (a) follows from the fact that for x \u2208 [0, \u01eb], (x \u2212 \u01eb)\u03bb \u2192 +\u221e when \u03bb \u2192 \u2212\u221e,\nand (b) is a result of the mean value theorem for integration [60]. This theorem states that for every\ncontinuous function f (x) in the interval [a, b], we have\nZ b\n\u2203 x0 \u2208 [a, b] s.t.\nf (x)dx = f (x0 )[b \u2212 a].\n\n(28)\n\na\n\nEquation (27) is valid for any arbitrary 0 < \u01eb < 1. If we choose \u01eb \u2192 0, x1 and x2 are both squeezed in\nthe interval [0, \u01eb]. Thus, we have\nx1 Q(x1 )e\u03bbx1\n= lim x1 = 0\n\u01eb\u21920\n\u03bb\u2192\u2212\u221e \u01eb\u21920 Q(x2 )e\u03bbx2\n\nlim v(\u03bb) \u2264 lim lim\n\n\u03bb\u2192\u2212\u221e\n\n(29)\n\nBased on the distribution of x, v(\u03bb) is obviously non-negative for any \u03bb. Hence, the inequality in (29)\ncan be replaced by equality.\n\n3) By observing that v(\u03bb = 0) = E{x}, it is obvious that l(\u03b1 = E{x}) = 0.\n\n\f24\n\n4) To show that l(\u03b1 = 1) = +\u221e, we prove the equivalent statement of the form lim\u03bb\u2192+\u221e v(\u03bb) = 1. For\nany 0 < \u01eb < 1 and x \u2208 [1 \u2212 \u01eb, 1], (x \u2212 1 + \u01eb)\u03bb \u2192 +\u221e when \u03bb \u2192 +\u221e. Then, defining \u03b6 = 1 \u2212 \u01eb, we have\nR\u03b6\nR\u03b6\nxQ(x)ex\u03bb dx\nxQ(x)dx\n0\nlim R 1\n\u2264 lim R 1 0\n= 0.\n(30)\nx\u03bb dx\n(x\u2212\u03b6)\u03bb dx\n\u03bb\u2192+\u221e\n\u03bb\u2192+\u221e\nQ(x)e\nQ(x)e\n0\n\u03b6\n\nSince the fraction in (30) is obviously non-negative for all \u03bb, this inequality can be replaced by an equality.\n\nSimilarly, we have\n\nR\u03b6\n\nQ(x)ex\u03bb dx\n0\nlim R\n\u03bb\u2192+\u221e 1 xQ(x)ex\u03bb dx\n\u03b6\n\n\u2264 lim R 1\n\u03bb\u2192+\u221e\n\n\u03b6\n\nR\u03b6\n0\n\nQ(x)dx\n\nxQ(x)e(x\u2212\u03b6)\u03bb dx\n\n= 0.\n\nwhich can also be replaced by equality. Now, the limit of v(\u03bb) is written as\nR\u03b6\nR1\nx\u03bb\nxQ(x)e\ndx\n+\nxQ(x)ex\u03bb dx\n0\n\u03b6\nlim v(\u03bb) = lim\nR1\n\u03bb\u2192+\u221e\n\u03bb\u2192+\u221e\nQ(x)ex\u03bb dx\n0\nR1\nxQ(x)ex\u03bb dx\n(a)\n\u03b6\n= lim R 1\n\u03bb\u2192+\u221e\nQ(x)ex\u03bb dx\n0\n!\u22121\nR\u03b6\nR1\nQ(x)ex\u03bb dx + \u03b6 Q(x)ex\u03bb dx\n(b)\n0\n= lim\nR1\n\u03bb\u2192+\u221e\nxQ(x)ex\u03bb dx\n\u03b6\n!\u22121\nR1\nx\u03bb\nQ(x)e\ndx\n(c)\n\u03b6\n= lim R 1\n\u03bb\u2192+\u221e\nxQ(x)ex\u03bb dx\n\u03b6\n\u0013\u22121\n\u0012\nQ(x1 )ex1 \u03bb\n(d)\n= lim\n\u03bb\u2192+\u221e x2 Q(x2 )ex2 \u03bb\n\n(31)\n\n(32)\n\nfor some x1 , x2 \u2208 [1 \u2212 \u01eb, 1]. (a) follows from equation (30), and (b) is valid since the final result shows\nthat lim\u03bb\u2192+\u221e v(\u03bb) is finite and non-zero [60]. (c) follows from equation (31), and (d) is a result of the\nmean value theorem for integration. If we choose \u01eb \u2192 0, x1 and x2 are both squeezed in the interval\n[1 \u2212 \u01eb, 1]. Then, equation (32) turns into\n\u0012\n\u0013\u22121\n\u0013\u22121 \u0012\nQ(x1 )ex1 \u03bb\n1\nlim v(\u03bb) = lim lim\n= 1.\n= lim\n\u01eb\u21920 x2\n\u03bb\u2192+\u221e\n\u03bb\u2192+\u221e \u01eb\u21920 x2 Q(x2 )ex2 \u03bb\n5) According to equations (12) and (13), the first derivative of u(\u03b1) is\n\u2202u(\u03b1)\n\u2202l(\u03b1) E{xe\u03bbx } \u2202l(\u03b1)\n= l(\u03b1) + \u03b1\n\u2212\n= l(\u03b1).\n\u2202\u03b1\n\u2202\u03b1\nE{e\u03bbx } \u2202\u03b1\n\n\f25\n\nA PPENDIX B\nP ROOF\n\nOF\n\nL EMMA II\n\nBased on the definition of probability density function, we have\n1\nlog (fy (\u03b1))\nL\u2192\u221e\nL\n\u0013\n\u0012\n1\nP{y > \u03b1} \u2212 P{y > \u03b1 + \u03b4}\n= lim \u2212 log lim\nL\u2192\u221e\n\u03b4\u2192 0\nL\n\u03b4\n\u0013\n\u0012\nP{y > \u03b1} \u2212 P{y > \u03b1 + \u03b4}\n1\n(a)\n= lim lim \u2212 log\n\u03b4\u2192 0 L\u2192\u221e\nL\n\u03b4\n1\n\u2265 lim lim (\u2212 log (P{y > \u03b1}) + log \u03b4)\n\u03b4\u2192 0 L\u2192\u221e L\nlim \u2212\n\n(b)\n\n= u(\u03b1)\n\n(33)\n\nwhere (a) is valid since log is a continuous function, and both limitations do exist and are interchangeable.\n(b) follows from equation (14). The exponent of fy (\u03b1) can be upper-bounded as\n1\nlog (fy (\u03b1))\nL\u2192\u221e\nL\n\u2212 log (P{y > \u03b1} \u2212 P{y > \u03b1 + \u03b4}) + log \u03b4\n(a)\n= lim lim\n\u03b4\u2192 0 L\u2192\u221e\nL\n\u0001\n(b)\n\u2212 log e\u2212L(u(\u03b1)+\u01eb) \u2212 e\u2212L(u(\u03b1+\u03b4)\u2212\u01eb) + log \u03b4\n\u2264 lim lim\n\u03b4\u2192 0 L\u2192\u221e\nL \u0001\nlog 1 \u2212 e\u2212L\u03c7\n= lim lim u(\u03b1) + \u01eb \u2212\n\u03b4\u2192 0 L\u2192\u221e\nL\nlim \u2212\n\n(c)\n\n= u(\u03b1) + \u01eb\n\n(34)\n\nwhere \u03c7 = u(\u03b1 + \u03b4) \u2212 u(\u03b1) \u2212 2\u01eb. Since u(\u03b1) is a strictly increasing function (Lemma I), we can make \u03c7\npositive by choosing \u01eb small enough. (a) is valid since log is a continuous function, and both limits do\nexist and are interchangeable. (b) follows from the definition of limit if L is sufficiently large, and (c) is\na result of \u03c7 being positive. Selecting \u01eb arbitrarily small, results (33) and (34) prove the lemma.\nA PPENDIX C\nP ROOF\n\nOF\n\nL EMMA III\n\nAccording to the definition of infimum, we have\nlog(H(L))\nL\u0012\n\u0013\nZ\n\u2212L inf h(x)\n1\nS\n\u2265 lim \u2212 log e\ndx\nL\u2192\u221e\nL\nS\nlim \u2212\n\nL\u2192\u221e\n\n(a)\n\n= inf h(x).\nS\n\n(35)\n\n\f26\n\nwhere (a) follows from the fact that S is a bounded region. Since h(x) is a continuous function, it has a\nminimum in the bounded closed set cl(S) which is denoted by x\u22c6 . Due to the continuity of h(x) at x\u22c6 ,\nfor any \u01eb > 0, there is a neighborhood B(\u01eb) centered at x\u22c6 such that any x \u2208 B(\u01eb) has the property of\n|h(x) \u2212 h(x\u22c6 )| < \u01eb. Moreover, since S is a convex set, we have vol (B(\u01eb) \u2229 S) > 0 . Now, we can write\nlog(H(L))\nL\u2192\u221e\nL\u0012Z\n\u0013\n1\n\u2212Lh(x)\ne\ndx\n\u2264 lim \u2212 log\nL\u2192\u221e\nL\nS\u2229B(\u01eb)\n\u0013\n\u0012\nZ\n1\n\u2212L(h(x\u22c6 )+\u01eb)\n\u2264 lim \u2212 log e\ndx\nL\u2192\u221e\nL\nS\u2229B(\u01eb)\n= h(x\u22c6 ) + \u01eb.\nlim \u2212\n\n(36)\n\nSelecting \u01eb to be arbitrarily small, (35) and (36) prove the lemma.\nA PPENDIX D\nP ROOF\n\nOF\n\nL EMMA IV\n\nAccording to Lemma I, uj (x) is increasing and convex for \u22001 \u2264 j \u2264 J. Thus, the objective function\nP\n\u03b2\nf (\u03b2) = Jj=1 \u03b3j uj ( \u03b7jj ) is also convex, and the region ST is determined by J convex inequality constraints\n\nand one affine equality constraint. Hence, in this case, KKT conditions are both necessary and sufficient\nfor optimality [61]. In other words, if there exist constants \u03c6j and \u03bd such that\n\u03b3j \u03b2j\u22c6\nlj ( ) \u2212 \u03c6j \u2212 \u03bd = 0 \u22001 \u2264 j \u2264 J\n\u03b7j \u03b7j\n\u0002\n\u0003\n\u03c6j \u03b7E{xj } \u2212 \u03b2j\u22c6 = 0 \u22001 \u2264 j \u2264 J\n\n(37)\n(38)\n\nthen the point \u03b2 \u22c6 is a global minimum.\n\nNow, we prove that either \u03b2j\u22c6 = \u03b7j E{xj } for all 1 \u2264 j \u2264 J, or \u03b2j\u22c6 > \u03b7j E{xj } for all 1 \u2264 j \u2264 J. Let\nus assume the opposite is true, and there are at least two elements of the vector \u03b2 \u22c6 , indexed with k and\n\u22c6\nm, which have the values of \u03b2k\u22c6 = \u03b7k E{xk } and \u03b2m\n> \u03b7m E{xm }, respectively. For any arbitrary \u01eb > 0,\n\nthe vector \u03b2 \u22c6\u22c6 can be defined as below\n\n\u03b2j\u22c6\u22c6 =\n\n\uf8f1\n\uf8f4\n\u22c6\n\uf8f4\n\uf8f4\n\uf8f2 \u03b2j + \u01eb if j = k\n\n\u03b2j\u22c6 \u2212 \u01eb if j = m\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 \u03b2\u22c6\notherwise.\nj\n\n(39)\n\n\f27\n\nThen, we have\nf (\u03b2 \u22c6\u22c6 ) \u2212 f (\u03b2\u22c6 )\n\u01eb\u21920\n\u001a \u01eb \u0012 \u22c6\n\u0013\n\u0012 \u22c6\n\u0013\n\u03b2k + \u01eb\n\u03b2m \u2212 \u01eb\n1\n\u03b3k uk\n+ \u03b3m um\n= lim\n\u01eb\u21920 \u01eb\n\u03b7k\n\u03b7m\n\u0012 \u22c6 \u0013\u001b\n\u03b2m\n\u2212\u03b3m um\n\u03b7\n\u0013k\n\u0013\n\u0012 \u22c6\n\u0012 \u22c6\n\u2032\n\u03b3k\n\u03b3m\n\u03b2k + \u01eb\n\u03b2m + \u01eb\u2032\u2032\n(a)\n= lim lk\n\u2212\nlm\n\u01eb\u21920 \u03b7k\n\u03b7k\n\u03b7m\n\u03b7m\n\u0012 \u22c6\u0013\n\u03b2m\n\u03b3m\n<0\n= \u2212 lm\n\u03b7m\n\u03b7m\nlim\n\n(40)\n\nwhere \u01eb\u2032 , \u01eb\u2032\u2032 \u2208 [0, \u01eb], and (a) follows from the Taylor's theorem. Thus, moving from \u03b2 \u22c6 to \u03b2 \u22c6\u22c6 decreases\nthe function which contradicts the assumption of \u03b2 \u22c6 being the global minimum.\nOut of the remaining possibilities, the case where \u03b2j\u22c6 = \u03b7j E{xj } (\u22001 \u2264 j \u2264 J) obviously agrees with\nLemma IV for the special case of \u03bd = 0. Therefore, the lemma can be proved assuming \u03b2j\u22c6 > \u03b7j E{xj }\n(\u22001 \u2264 j \u2264 J). Then, equation (38) turns into \u03c6j = 0 (\u22001 \u2264 j \u2264 J). By rearranging equation (37) and\nP\nusing the condition Jj=1 \u03b2j = \u03b1, Lemma IV is proved.\nA PPENDIX E\nP ROOF\n\nOF\n\nT HEOREM II\n\nSketch of the proof: First, it is proved that \u03b7j\u22c6 > 0 if E{xj } < \u03b1. At the second step, we prove\nthat \u03b7j\u22c6 = 0, if E{xj } \u2265 \u03b1. Then, KKT conditions [61] are applied for the indices 1 \u2264 k \u2264 J where\nE{xk } < \u03b1 to find the maximizing allocation vector, \u03b7 \u22c6 .\nProof: The parameter \u03bd is obviously a function of the vector \u03b7. Differentiating equation (17) with\nrespect to \u03b7k results in\n\u2202\u03bd\n=\u2212\n\u2202\u03b7k\n\nvk\n\n\u0012\n\n\u0013\n\u0013\n\u0012\n\u03bd\u03b7k\n\u03bd\u03b7k \u2032 \u03bd\u03b7k\n+\nv\n\u03b3k\n\u03b3k k \u03b3k\n\u0012\n\u0013\nJ\nX\n\u03b7j2 \u2032 \u03bd\u03b7j\nv\n\u03b3 j \u03b3j\nj=1 j\n\n(41)\n\nwhere vj (x) = lj\u22121 (x), and vj\u2032 (x) denotes its derivative with respect to its argument. The objective function\ncan be simplified as\n\u0012\n\u0013\nJ\nX\n\u03b2j\u22c6\n\u03bd\u03b7j\n\u03b3j uj vj (\n) .\ng(\u03b7) =\n\u03b3j uj ( ) =\n\u03b7\n\u03b3\nj\nj\nj=1\nj=1\nJ\nX\n\n(42)\n\n\u03bd \u22c6 is defined as the value of \u03bd corresponding to \u03b7 \u22c6 . Next, we show that \u03bd \u22c6 > 0. Let us assume the\nopposite is true, i.e., \u03bd \u22c6 \u2264 0. Then, according to Lemma I, we have vj (\n\n\u03bd \u22c6 \u03b7j\n)\n\u03b3j\n\n\u2264 E{xj } for all j which\n\nresults in g(\u03b7 \u22c6) = 0. However, it is possible to achieve a positive value of g(\u03b7) by setting \u03b7j = 1 for the\n\n\f28\n\none vector which has the property of E{xj } < \u03b1, and setting \u03b7j = 0 for the rest. Thus, \u03b7 \u22c6 can not be the\nmaximal point. This contradiction proves the fact that \u03bd \u22c6 > 0.\nAt the first step, we prove that \u03b7j\u22c6 > 0 if E{xj } < \u03b1. Assume the opposite is true for an index\nP\n\u22c6\n> 0. For any arbitrary\n1 \u2264 k \u2264 J. Since Jj=1 \u03b7j\u22c6 = 1, there should be at least one index m such that \u03b7m\n\u01eb > 0, the vector \u03b7 \u22c6\u22c6 can be defined as below\n\uf8f1\n\uf8f4\n\uf8f4\nif j = k\n\uf8f4\n\uf8f2 \u01eb\n\u22c6\u22c6\n\u03b7j =\n\u03b7j\u22c6 \u2212 \u01eb if j = m\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 \u03b7\u22c6\notherwise.\nj\n\n(43)\n\n\u03bd \u22c6\u22c6 is defined as the corresponding value of \u03bd for the vector \u03b7 \u22c6\u22c6 . Based on equation (41), we can write\n\u2206\u03bd =\n\u03bd \u22c6\u22c6 \u2212 \u03bd \u22c6 =\n\u0012 \u22c6 \u22c6\u0013\n\u0012 \u22c6 \u22c6\u0013\n\u22c6\n\u03bd \u03b7m\n\u03bd \u22c6 \u03b7m\n\u03bd \u03b7m\n\u2032\nvm\n+\nvm\n\u2212 E{xk }\n\u03b3m\n\u03b3m\n\u03b3m\n\u01eb + O(\u01eb2 ).\n\u0012 \u22c6 \u22c6\u0013\nJ\n\u22c62\nX\n\u03b7j \u2032 \u03bd \u03b7j\nv\n\u03b3j j\n\u03b3j\nj=1\n\n(44)\n\nThen, we have\ng(\u03b7\u22c6\u22c6 ) \u2212 g(\u03b7\u22c6 )\n\u01eb\u21920\n\u001a \u22c62\u01eb \u22c6 \u0012 \u22c6 \u22c6 \u0013\n\u0012 \u22c6 \u22c6\u0013\n\u22c6\n1 \u03bd \u03b7k \u2032 \u03bd \u03b7k\n\u03bd \u22c62 \u03b7m\n\u03bd \u03b7m\n\u2032\n= lim\n\u01eb\u2212\n\u01eb\nvk\nvm\n\u01eb\u21920 \u01eb\n\u03b3k\n\u03b3k\n\u03b3m\n\u03b3m\n)\n\u0012 \u22c6 \u22c6\u0013\nJ\n\u22c62\nX\n\u03bd\n\u03b7\n\u03b7\nj\nj\nvj\u2032\n+ O(\u01eb2 )\n+ \u03bd \u22c6 \u2206\u03bd\n\u03b3\n\u03b3\nj\nj\nj=1\n\u001a \u0012 \u22c6 \u22c6\u0013\n\u001b\n\u03bd \u03b7m\n(a) \u22c6\n= \u03bd vm\n\u2212 E{xk }\n\u03b3m\nlim\n\n(45)\n\nwhere (a) follows from (44). If the value of (45) is positive for an index m, moving in that direction\nincreases the objective function which contradicts with the assumption of \u03b7 \u22c6 being a maximal point. If\n\u22c6\nthe value of (45) is non-positive for all indexes m whose \u03b7m\n> 0, we can write\n\u0012 \u22c6 \u22c6\u0013\nJ\nX\n\u03bd \u03b7m\n\u22c6\n=\u03b1\nE{xk } \u2265\n\u03b7m vm\n\u03b3m\nm=1\n\n(46)\n\nwhich obviously contradicts the assumption of E{xk } < \u03b1.\n\nAt the second step, we prove that \u03b7j\u22c6 = 0 if E{xj } \u2265 \u03b1. Assume the opposite is true for an index\nP\n1 \u2264 r \u2264 J. Since Jj=1 \u03b7j\u22c6 = 1, we should have \u03b7s\u22c6 < 1 for all other indices s. For any arbitrary \u01eb > 0,\n\n\f29\n\nthe vector \u03b7 \u22c6\u22c6\u22c6 can be defined as\n\n\u03b7j\u22c6\u22c6\u22c6 =\n\n\uf8f1\n\uf8f4\n\u22c6\n\uf8f4\n\uf8f4\n\uf8f2 \u03b7j \u2212 \u01eb if j = r\n\n\u03b7j\u22c6 + \u01eb if j = s\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 \u03b7\u22c6\notherwise.\nj\n\n(47)\n\n\u03bd \u22c6\u22c6\u22c6 is defined as the corresponding value of \u03bd for the vector \u03b7 \u22c6\u22c6\u22c6 . Based on equation (41), we can write\n\u2206\u03bd = \u03bd \u22c6\u22c6\u22c6 \u2212 \u03bd \u22c6\n\u0013\n\u0012\n\u001a \u0012 \u22c6 \u22c6\u0013\n\u01eb\n\u03bd \u22c6 \u03b7r\u22c6 \u2032 \u03bd \u22c6 \u03b7r\u22c6\n\u03bd \u03b7r\n= J\n+\nv\nvr\n\u03b3r\n\u03b3r r\n\u03b3r\nX \u03b7j\u22c62 \u0012 \u03bd \u22c6 \u03b7j\u22c6 \u0013\nvj\u2032\n\u03b3j\n\u03b3j\nj=1\n\u0012 \u22c6 \u22c6\u0013\n\u0012\n\u0013\u001b\n\u03bd \u03b7s\n\u03bd \u22c6 \u03b7s\u22c6 \u2032 \u03bd \u22c6 \u03b7s\u22c6\n\u2212vs\n\u2212\nvs\n+ O(\u01eb2 ).\n\u03b3s\n\u03b3s\n\u03b3s\n\n(48)\n\nThen, we have\ng(\u03b7 \u22c6\u22c6\u22c6 ) \u2212 g(\u03b7 \u22c6 )\n\u01eb\u21920\n\u001a \u22c62 \u01eb\u22c6 \u0012 \u22c6 \u22c6 \u0013\n\u0013\n\u0012\n\u03bd \u22c62 \u03b7r\u22c6 \u2032 \u03bd \u22c6 \u03b7r\u22c6\n1 \u03bd \u03b7s \u2032 \u03bd \u03b7s\n= lim\n\u01eb\u2212\n\u01eb\nv\nv\n\u01eb\u21920 \u01eb\n\u03b3s s\n\u03b3s\n\u03b3r r\n\u03b3r\n)\n\u0013\n\u0012\nJ\nX\n\u03b7j\u22c62 \u2032 \u03bd \u22c6 \u03b7j\u22c6\n2\n\u22c6\n+ O(\u01eb )\nv\n+ \u03bd \u2206\u03bd\n\u03b3j j\n\u03b3j\nj=1\n\u001a \u0012 \u22c6 \u22c6\u0013\n\u0012 \u22c6 \u22c6 \u0013\u001b\n\u03bd \u03b7r\n\u03bd \u03b7s\n(a)\n\u22c6\n= \u03bd vr\n\u2212 vs\n\u03b3r\n\u03b3s\nlim\n\n(49)\n\nwhere (a) follows from (48). If the value of (49) is positive for an index s, moving in that direction\nincreases the objective function which contradicts with the assumption of \u03b7 \u22c6 being a maximal point . If\nthe value of (49) is non-positive for all indices s whose \u03b7s\u22c6 > 0, we can write\n\u0012 \u22c6 \u22c6\u0013\n\u0012 \u22c6 \u22c6\u0013 X\nJ\n\u03bd \u03b7s\n\u03bd \u03b7r\n\u22c6\n\u2264\n\u03b7s vs\n=\u03b1\nE{xr } < vr\n\u03b3r\n\u03b3s\ns=1\n\n(50)\n\nwhich obviously contradicts the assumption of E{xr } \u2265 \u03b1.\n\nNow that the boundary points are checked, we can safely use the KKT conditions [61] for all 1 \u2264 k \u2264 J,\nwhere E{xk } < \u03b1, to find the maximizing allocation vector, \u03b7 \u22c6 .\n\u0013\n\u0013\n\u0012\n\u0012\nJ\nX\n\u03b7j\u22c62 \u2032 \u03bd \u22c6 \u03b7j\u22c62 \u2202\u03bd\n\u03bd \u22c62 \u03b7k\u22c6 \u2032 \u03bd \u22c6 \u03b7k\u22c6\n\u22c6\n\u03b6=\n+\u03bd\nv\nvj\n|\u03bd=\u03bd \u22c6\n\u03b3k k\n\u03b3k\n\u03b3\n\u03b3\n\u2202\u03b7\nj\nj\nk\nj=1\n\u0012 \u22c6 \u22c6\u0013\n\u03bd \u03b7k\n(a)\n= \u2212\u03bd \u22c6 vk\n\u03b3k\n\n(51)\n\n\f30\n\nwhere \u03b6 is a constant independent of k, and (a) follows from (41). Using the fact that\ntogether with equations (17) and (51) results in\n\u03b6 = \u2212\u03b1\u03bd \u22c6\nX\n\u03bd\u22c6 =\n\u03b3j lj (\u03b1).\n\nPJ\n\nj=1 \u03b7j\n\n= 1\n\n(52)\n\nE{xj }<\u03b1\n\nCombining equations (51) and (52) results in equation (19) and g(\u03b7 \u22c6 ) =\nA PPENDIX F\nP ROOF\n\nOF\n\nPJ\n\nj=1 \u03b3j uj (\u03b1).\n\nR EMARK V\n\nBased on the arguments similar to the ones in appendix E, it can be shown that \u03b7\u0303j\u22c6 = 0 iff E{xj } \u2265 \u03b1.\nSince all the types are identical here, this means \u03b7\u0303j\u22c6 > 0 for all j. Similar to equation (51), applying KKT\nconditions [61], gives us\n\nvj\n\n\u0012\n\n\u22c6\u0013\n\n\u03bd\u0303 \u22c6 \u03b7\u0303j\n\u03b3j\n\n=\n\n\uf8f1\n\uf8f4\n\uf8f4\n\u2212\u03b6\n\uf8f4\n\uf8f4\n\uf8f2\n\nif \u03b7\u0303j\u22c6 <\n\n\u03b3j Wj T\nn0\n(53)\n\n\uf8f4\n\uf8f4\n\uf8f4\n\u03b3WT\n\uf8f4\n\uf8f3 \u2212\u03b6 \u2212 \u03c3j if \u03b7\u0303j\u22c6 = j j\nn0\n\nwhere \u03c3j 's are non-negative parameters [61]. Putting \u03a5 =\n\nlj (\u2212\u03b6)\n\u03bd\u0303 \u22c6\n\nproves equation (20).\n\nA PPENDIX G\nD ISCRETE A NALYSIS\n\nOF\n\nO NE PATH\n\nQ(n, k, l) is defined as the probability of having exactly k errors out of the n packets sent over the path\nl. Depending on the initial state of the path l, Pg (n, k, l) and Pb (n, k, l) are defined as the probabilities\nof having k errors out of the n packets sent over this path when we start the transmission in the good or\nin the bad state, respectively. It is easy to see that\nQ(n, k, l) = \u03c0g Pg (n, k, l) + \u03c0b Pb (n, k, l).\n\n(54)\n\nPg (n, k, l) and Pb (n, k, l) can be computed from the following recursive equations\nPb (n, k, l) = \u03c0b|b Pb (n \u2212 1, k \u2212 1, l) + \u03c0g|b Pg (n \u2212 1, k \u2212 1, l)\nPg (n, k, l) = \u03c0b|g Pb (n \u2212 1, k, l) + \u03c0g|g Pg (n \u2212 1, k, l)\n\n(55)\n\nwith the initial conditions\nPg (n, k, l) = 0\n\nfor k \u2265 n\n\nPb (n, k, l) = 0\n\nfor k > n\n\nPg (n, k, l) = 0\n\nfor k < 0\n\nPb (n, k, l) = 0\n\nfor k \u2264 0\n\n(56)\n\n\f31\n\nwhere \u03c0s2 |s1 is the probability of the channel being in the state s2 \u2208 {g, b} provided that it has been in\nthe state s1 \u2208 {g, b} when the last packet was transmitted. \u03c0s2 |s1 has the following values for different\ncombinations of s1 and s2 [1]\n\u03bcg + \u03bcb\nSl\n= \u03c0g + \u03c0b e\n\u2212\n\n\u03c0g|g\n\n\u03c0b|g = 1 \u2212 \u03c0g|g\n\u03bcg + \u03bcb\nSl\n= \u03c0b + \u03c0g e\n\u2212\n\n\u03c0b|b\n\n\u03c0g|b = 1 \u2212 \u03c0b|b\n\n(57)\n\nwhere Sl denotes the transmission rate on the path l, i.e., the packets are transmitted on the path l every\n1\nSl\n\nseconds.\nAccording to the recursive equations in (55), to compute Pb (n, k, l) and Pg (n, k, l) by memoization\n\ntechnique, the functions Pb () and Pg () should be calculated at the following set of points denoted as\nS(n, k)\nS(n, k) = {(n\u2032 , k \u2032 ) | 0 \u2264 k \u2032 \u2264 k, n\u2032 \u2212 n + k \u2264 k \u2032 \u2264 n\u2032 } .\nCardinality of the set S(n, k) is of the order |S(n, k)| = O (k (n \u2212 k)). Since three operations are needed\nto compute the recursive functions Pb () and Pg () at each point, Pb (n, k, l) and Pg (n, k, l) are computable\nwith the complexity of O (k (n \u2212 k)) which give us Q(n, k, l) according to equation (54).\nA PPENDIX H\nD ISCRETE A NALYSIS\n\nOF\n\nO NE T YPE\n\nWhen there are n packets to be distributed over Lj identical paths of type j, uniform distribution is\nobviously the optimum. However, since the integer n may be indivisible by Lj , the Lj dimensional vector\nN is selected as\nNl =\n\n\uf8f1 n\n\uf8f4\n\u230a \u230b + 1 for 1 \u2264 l \u2264 Rem(n, Lj )\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 Lj\n\uf8f4\n\uf8f4\nn\n\uf8f4\n\uf8f4\n\uf8f3 \u230a \u230b\nLj\n\n(58)\n\nfor Rem(n, Lj ) < l \u2264 Lj\n\nwhere Rem(a, b) denotes the remainder of dividing a by b. N represents the closest integer vector to a\nuniform distribution.\nE N (k, l) is defined as the probability of having exactly k erasures among the n packets transmitted\nover the identical paths 1 to l with the allocation vector N. According to the definitions of Qj (n, k) and\n\n\f32\n\nE N (k, l), it is obvious that Qj (n, k) = E N (k, Lj ). E N (k, l) can be computed recursively as\nE N (k, l) =\n\nk\nX\n\nE N (k \u2212 i, l \u2212 1)Q(Nl , i, l)\n\ni=0\n\nN\n\nE (k, 1) = Q(N1 , k, 1)\n\n(59)\n\nwhere Q(Nl , i, l) is given in appendix G. Since all the paths are assumed to be identical here, Q(Nl , k, l)\nis the same for all path indices, l. According to the recursive equations in (55), the values of Q(Nl , i, l)\n\u0010\n\u0011\nfor all 0 \u2264 i \u2264 k and 1 \u2264 l \u2264 Lj can be calculated with the complexity of O(Nl k) = O Lnj k .\n\nAccording to the recursive equations in (59), computing E N (k, l) requires memoization over an array of\nsize O(kl) whose entries can be calculated with O(k) operations each. Thus, E N (k, l) is computable with\nthe complexity of O(k 2l) if Q(Nl , i, l)'s are already given. Finally, noting that Qj (n, k) = E N (k, Lj ), we\n\u0011\n\u0010\ncan compute Qj (n, k) with the overall complexity of O(k 2 Lj ) + O Lnj k .\nA PPENDIX I\nP ROOF\n\nOF\n\nL EMMA V\n\nThe lemma is proved by induction on j. The case of j = 1 is obviously true as P\u0302e (n, k, 1) =\nPeopt (n, k, 1). Let us assume this statement is true for j = 1 to J \u2212 1. Then, for j = J, we have\nP\u0302e (n, k, J)\nNJ\n(a) X\n\u2264\nQJ (NJopt , i)P\u0302e (n \u2212 NJopt , k \u2212 i, J \u2212 1)\n(b)\n\n\u2264\n\n(c)\n\n\u2264\n\ni=0\nNJ\nX\n\ni=0\nNJ\nX\n\nQJ (NJopt , i)Peopt (n \u2212 NJopt , k \u2212 i, J \u2212 1)\nopt\n\nQJ (NJopt , i)PeN (k \u2212 i, J \u2212 1)\n\ni=0\n\n(d)\n\nopt\n\n= PeN (k, J) = Peopt (n, k, J)\n\nwhere Nopt denotes the optimum allocation of n packets among the J types of paths such that the\nprobability of having more than k lost packets is minimized. (a) follows from the recursive equation (21),\nand (b) is the induction assumption. (c) comes from the definition of Peopt (n, k, l), and (d) is a result of\nequation (23).\nA PPENDIX J\nP ROOF\n\nOF\n\nT HEOREM III\n\nSketch of the proof: First, the asymptotic behavior of Qj (n, k) is analyzed, and it is shown that for\nlarge values of Lj (or equivalently L), equation (63) computes the exponent of Qj (n, k) versus L. Next,\n\n\f33\n\nwe prove the first part of the theorem by induction on J. The proof of this part is divided to two different\ncases, depending on whether\n\nK\nN\n\nis larger than E{xJ } or vice versa. Finally, the second and the third parts\n\nof the theorem are proved by induction on j while the total number of path types, J, is fixed. Again, the\nproof is divided into two different cases, depending on whether\n\nK\nN\n\nis larger than E{xj } or vice versa.\n\nProof: First, we compute the asymptotic behavior of Qj (n, k) for k > nE{xj }, and n growing\nproportionally to Lj , i.e. n = n\u2032 Lj . Here, we can apply Sanov's Theorem [56], [62] as n and k are\ndiscrete variables and n\u2032 is a constant.\nSanov's Theorem. Let X1 , X2 , . . . , Xn be i.i.d. discrete random variables from an alphabet set X\nwith the size |X | and probability mass function (pmf) Q(x). Let P denote the set of pmf's in R|X | , i.e.\nn\no\nP|X |\nP = P \u2208 R|X | | P (i) \u2265 0,\nP\n(i)\n=\n1\n. Also, let PL denote the subset of P corresponding to all\ni=1\n\npossible empirical distributions of X in L observations [62], i.e. PL = {P \u2208 P| \u2200i, LP (i) \u2208 Z}. For any\ndense and closed set [57] of pmf's E \u2286 P, the probability that the empirical distribution of L observations\nbelongs to the set E is equal to\n\u22c6\n.\nP {E} = P {E \u2229 PL } = e\u2212LD(P ||Q)\n\nwhere P\u22c6 = argmin D(P||Q) and D(P||Q) =\nP\u2208E\n\nP|X |\n\ni=1\n\n(60)\n\nP (i)\nP (i) log Q(i)\n.\n\nFocusing our attention on the main problem, assume that P is defined as the empirical distribution of\nthe number of errors in each path, i.e. for \u2200i, 1 \u2264 i \u2264 n\u2032 , P (i) shows the ratio of the total paths which\ncontain exactly i lost packets. Similarly, for \u2200i, 1 \u2264 i \u2264 n\u2032 , Q(i) denotes the probability of exactly i\npackets being lost out of the n\u2032 packets transmitted on a path of type j. The sets E and Eout are defined\nas follows\n\u2032\n\nE = {P \u2208 P|\n\nn\nX\n\niP (i) \u2265 \u03b2}\n\n(61)\n\ni=0\n\u2032\n\nEout = {P \u2208 P|\n\nn\nX\n\niP (i) = \u03b2}\n\ni=0\n\nwhere \u03b2 =\n\nk\n. Noting E and Eout are dense sets, we can compute Qj (n, k) as\nn\n(b) \u2212Lj min D (P||Q)\n(a)\n.\nP\u2208Eout\nQj (n, k) = P {Eout } = e\n\n(62)\n\nwhere (a) follows from the definition of Qj (n, k) as the probability of having exactly k errors out of the\nn packets sent over the paths of type j given in section V, and (b) results from Sanov's Theorem.\nKnowing the fact that the Kullback Leibler distance, D(P||Q), is a convex function of P and Q [63],\nwe conclude that its minimum over the convex set E either lies on an interior point which is a global\nminimum of the function over the whole set P or is located on the boundary of E. However, we know\n\n\f34\n\nthat the global minimum of Kullback Leibler distance occurs at P = Q \u2208\n/ E. Thus, the minimum of\nD(P||Q) is located on the boundary of E. This results in\n(a)\n\u2212Lj min D (P||Q)\n.\nP\u2208Eout\nQj (n, k) = e\n\u2212Lj\n\n= e\n\nk\nmin D (P||Q) (b)\n. \u2212\u03b3j Luj ( n )\nP\u2208E\n=e\n\n(63)\n\nwhere (a) and (b) follow from equations (62) and (14), respectively.\n1) We prove the first part of the theorem by induction on J. When J = 1, the statement is correct for both\ncases of\n\nK\nN\n\n> E{x1 } and\n\nK\nN\n\n\u2264 E{x1 }, recalling the fact that P\u0302e (n, k, 1) = Peopt(n, k, 1) and u1 (x) = 0\n\nfor x \u2264 E{x1 }. Now, let us assume the first part of the theorem is true for j = 1 to J \u2212 1. We prove the\nsame statement for J as well. The proof can be divided into two different cases, depending on whether\nK\nN\n\nis larger than E{xJ } or vice versa.\nK\n> E{xJ }\nN\nP J\nQJ (nJ , i)P\u0302e (N \u2212\nAccording to the definition, the value of P\u0302e (N, K, J) is computed by minimizing ni=0\n\n1.1)\n\nnJ , K \u2212 i, J \u2212 1) over nJ (see equation (23)). Now, we show that for any value of nJ , the corresponding\nterm in the minimization is asymptotically at least equal to Peopt (N, K, J). nJ can take integer values\nin the range 0 \u2264 nJ \u2264 N. We split this range into three non-overlapping intervals of 0 \u2264 nJ \u2264 \u01ebL,\n\b\n. The\n\u01ebL \u2264 nJ \u2264 N(1 \u2212 \u01eb), and N(1 \u2212 \u01eb) < nJ \u2264 N for any arbitrary constant \u01eb \u2264 min \u03b3j , 1 \u2212 K\nN\n\nreason is that equation (63) is valid in the second interval only, and we need separate analyses for the\nfirst and last intervals.\nFirst, we show the statement for \u01ebL \u2264 nJ \u2264 N(1 \u2212 \u01eb). Defining iJ = \u230anJ K\n\u230b, we have\nN\nK\n1\niJ\n=\n+ O( ),\nnJ\nN\nL\nK\n1\nK \u2212 iJ\n=\n+ O( )\nN \u2212 nJ\nN\nL\n\n(64)\n\nas \u01eb is constant, and K = O(L), N = O(L). Hence, we have\nnJ\nX\n\nQJ (nJ , i)P\u0302e (N \u2212 nJ , K \u2212 i, J \u2212 1)\n\ni=0\n\n\u2265 QJ (nJ , iJ )P\u0302e (N \u2212 nJ , K \u2212 iJ , J \u2212 1)\n\u0012\n\u0012 \u0013\u0013\nJ\nX\nK\n1\n\u2212L\n\u03b3j uj\n+O\n(a)\nN\nL\n.\n= e j=1\n\u0012 \u0013\nJ\nX\nK\n\u2212L\n\u03b3j uj\n(b)\nN\n.\n= e j=1\n\n(65)\n\n\f35\n\nwhere (a) follows from (63) and the induction assumption, and (b) follows from the fact that uj ()'s are\ndifferentiable functions according to Lemma I in subsection IV-B.\nFor 0 \u2264 nJ \u2264 \u01ebL, since \u01eb < \u03b3j , the number of packets assigned to the paths of type J is less than the\nnumber of such paths. Thus, one packet is allocated to nJ of the paths, and the rest of the paths of type\nJ are not used. Defining \u03c0b,J as the probability of a path of type J being in the bad state, we can write\n0\n1\n1\nA\n\u2212nJ log@\n\u03c0b,J .\nnJ\n=e\n(66)\nQJ (nJ , nJ ) = \u03c0b,J\nTherefore, for 0 \u2264 nJ \u2264 \u01ebL, we have\nnJ\nX\n\nQJ (nJ , i)P\u0302e (N \u2212 nJ , K \u2212 i, J \u2212 1)\n\ni=0\n\n\u2265 QJ (nJ , nJ )P\u0302e (N \u2212 nJ , K \u2212 nJ , J \u2212 1)\n\u0012\n\u0013\n\u0012\n\u0013\nJ\u22121\nX\nK \u2212 nJ\n1\n\u03b3j uj\n\u2212L\n\u2212 nJ log\nN \u2212 nJ\n\u03c0b,J\n.\nj=1\n= e\n\u0012\n\u0013\n\u0012 \u0013\nJ\u22121\nX\n1\nK\n\u2212 L\u01eb log\n\u2212L\n\u03b3j uj\n(a)\nN\n\u03c0b,J\nj=1\n\u2265 e\n\u0012 \u0013\n\u0012 \u0013\nJ\u22121\nJ\nX\nX\nK\nK\n\u2212L\n\u03b3j uj\n\u2212L\n\u03b3j uj\n(b)\nN\nN\n.\nj=1\nj=1\n= e\n\u2265e\n\nwhere (a) follows from the fact that\n\nK\u2212nJ\nN \u2212nJ\n\n\u2264\n\nK\n,\nN\n\n(67)\n\nand (b) results from the fact that we can select \u01eb arbitrarily\n\nsmall.\nFinally, we prove the statement for the case nJ > N(1 \u2212 \u01eb). In this case, we have\nnJ\nX\nQJ (nJ , i)P\u0302e (N \u2212 nJ , K \u2212 i, J \u2212 1)\ni=0\n\n\u2265 QJ (nJ , K)P\u0302e (N \u2212 nJ , 0, J \u2212 1)\n\u0013\n\u0012\nK\n\u2212L\u03b3J uJ\n(a)\nN (1 \u2212 \u01eb)\n\u2265 e\n\u0012 \u0013\nJ\nX\nK\n\u2212L\n\u03b3j uj\n(b)\nN\nj=1\n \u0307 e\n\u2265\n\nwhere (a) follows from the fact that \u01eb < 1 \u2212\n\nK\nN\n\n(68)\n\nand P\u0302e (n, 0, j) = 1, for all n and j. Setting \u01eb small\n\nenough results in (b).\nInequalities (65), (67), and (68) result in\n\u2212L\n\n \u0307 e\nP\u0302e (N, K, J) \u2265\n\nJ\nX\n\n\u03b3j uj (\u03b1)\n\nj=1\n\nCombining (69) with Lemma V proves the first part of Theorem III for the case when\n\n(69)\nK\nN\n\n> E{xJ }.\n\n\f36\n\n1.2)\n\nK\n\u2264 E{xJ }\nN\n\nK\n> E{xJ } in subsection 1.1, we show that for any value of 0 \u2264 nJ \u2264 N, the\nN\ncorresponding term of the minimization in equation (23) is asymptotically at least equal to Peopt (N, K, J).\nSimilar to the case of\n\nAgain, the range of nJ is partitioned into three non-overlapping intervals.\n\b\n, 1 , and for all nJ in the range of \u01ebL < nJ \u2264 N(1 \u2212 \u01eb),\nFor any arbitrary 0 < \u01eb < min \u03b3J , 1 \u2212 K\nN K\nwe define iJ as iJ = \u2308nJ E{xJ }\u2309. We have\niJ\nnJ\nK \u2212 iJ\nN \u2212 nJ\n\n\u0012 \u0013\n1\n= E{xJ } + O\n\u2265 E{xJ }\nL\n\u0012 \u0013\nK\n1\n<\n+O\nN\nL\n\n(70)\n\nHence,\nnJ\nX\n\nQJ (nJ , i)P\u0302e (N \u2212 nJ , K \u2212 i, J \u2212 1)\n\ni=0\n\n\u2265 QJ (nJ , iJ )P\u0302e (N \u2212 nJ , K \u2212 iJ , J \u2212 1)\n\u0012 \u0013\n\u0012\n\u0013\nJ\u22121\nX\niJ\nK \u2212 iJ\n\u2212L\u03b3J uJ\n\u2212L\n\u03b3j uj\n(a)\nnJ\nN \u2212 nJ\n.\nj=1\n= e\n\u0012\n\u0012 \u0013\u0013\n1\n\u2212L\u03b3J uJ E{xJ } + O\n(b)\nL\n*\n\u2265 e\n\u0013\u0013\n\u0012\n\u0012\nJ\u22121\nX\n1\nK\n+O\n\u2212L\n\u03b3j uj\nN\nL\nj=1\ne\n\u0012 \u0013\nJ\nX\nK\n\u2212L\n\u03b3\nu\nj\nj\n(c)\nN\n.\n= e j=1\n\n(71)\n\nwhere (a) follows from (63) and the induction assumption, and (b) is based on (70). (c) results from the\nfacts that uj ()'s are differentiable functions, and we have uJ (E{xJ }) = 0, both according to Lemma I in\nsubsection IV-B.\nFor 0 \u2264 nJ \u2264 \u01ebL, the analysis of section 1.1 and inequality (67) are still valid. For nJ > (1 \u2212 \u01eb)N, we\nset iJ = \u2308E {xJ } nJ \u2309. Now, we have\niJ \u2265 nJ E{xJ } > (1 \u2212 \u01eb)NE{xJ } \u2265 (1 \u2212 \u01eb)K.\n\n(72)\n\nThe above inequality can be written as\nK \u2212 iJ < \u01ebK < 1\n\n(73)\n\n\f37\n\nsince \u01eb <\n\n1\n.\nK\n\nNoting that K and iJ are integer values, it is concluded that K \u2264 iJ . Now, we can write\nnJ\nX\n\nQJ (nJ , i)P\u0302e (N \u2212 nJ , K \u2212 i, J \u2212 1)\n\ni=0\n\n\u2265 QJ (nJ , iJ )P\u0302e (N \u2212 nJ , K \u2212 iJ , J \u2212 1)\n(a)\n\n= QJ (nJ , iJ )\n\u0013\n\u0012\n1\n\u2212L\u03b3J uJ E {xJ } +\nnJ\n \u0307 e\n\u2265\n\u0012\n\u0013\n1\n(b)\n\u2212L\u03b3J uJ E {xJ } +\n(1 \u2212 \u01eb) N\n \u0307 e\n\u2265\n\u0012\n\u0012 \u0013\u0013\n1\n\u2212L\u03b3\n(c)\nJ uJ E {xJ } + O\n.\n.\nL\n= e\n=1\n\n(74)\n\nwhere (a) follows from the fact that K \u2264 iJ , and P\u0302e (n, k, j) = 1, for k \u2264 0. (b) and (c) result from\nnJ > (1 \u2212 \u01eb)N and uJ (E{xJ }) = 0, respectively.\nHence, inequalities (67), (71), and (74) result in\n\u2212L\n\n \u0307 e\nP\u0302e (N, K, J) \u2265\n\nJ\nX\n\n\u03b3j uj (\u03b1)\n\nj=1\n\nwhich proves the first part of Theorem III for the case of\n\nK\nN\n\n(75)\n\u2264 E{xJ } when combined with Lemma V.\n\n2) We prove the second and the third parts of the theorem by induction on j while the total number of\ntypes, J, is fixed. The proof of the statements for the base of the induction, j = J, is similar to the proof\nof the induction step, from j + 1 to j. Hence, we just give the proof for the induction step. Assume the\nsecond and the third parts of the theorem are true for m = J to j + 1. We prove the same statements for\nj. The proof is divided into two different cases, depending on whether\n\nK\nN\n\nis larger than E{xj } or vice\n\nversa.\nBefore we proceed further, it is helpful to introduce two new parameters N \u2032 and K \u2032 as\nN\u2032 = N \u2212\n\nJ\nX\n\nN\u0302j\n\nm=j+1\n\nK\n\n\u2032\n\n= K\u2212\n\nJ\nX\n\nKj .\n\nm=j+1\n\nAccording to the above definitions and the induction assumptions, it is obvious that\nK\nK\u2032\n=\n+ o(1) = \u03b1 + o(1).\n\u2032\nN\nN\n\n(76)\n\n\f38\n\nK\n> E{xj }\nN\nFirst, by contradiction, it will be shown that for small enough values of \u01eb > 0, we have N\u0302j > \u01ebN \u2032 . Let\n\n2.1)\n\nus assume the opposite is true, i.e. N\u0302j \u2264 \u01ebN \u2032 . Then, we can write\nP\u0302e (N \u2032 , K \u2032 , j)\nN\u0302j\nX\n\n(a)\n\n=\n\nP\u0302e (N \u2032 \u2212 N\u0302j , K \u2032 \u2212 i, j \u2212 1)Qj (N\u0302j , i)\n\ni=0\n\n\u2265 P\u0302e (N \u2032 \u2212 N\u0302j , K \u2032 \u2212 N\u0302j , j \u2212 1)Qj (N\u0302j , N\u0302j )\n!\nj\u22121\nX\nK \u2032 \u2212 N\u0302j\n\u03b3r ur\n\u2212L\n(b)\n.\nN \u2032 \u2212 N\u0302j\nr=1\n= Qj (N\u0302j , N\u0302j )e\n!\n\u0012\n\u0013\nJ\nX\n1\n\u2212Ln0 1 \u2212\n\u03b7r \u01eb log\n(c)\n\u03c0b,j\nr=j+1\n\u2265 e\n*\n\u0012 \u2032\u0013\nj\u22121\nX\nK\n\u03b3r ur\n\u2212L\nN\u2032\ne r=1\nj\nX\n\u03b3r ur (\u03b1)\n\u2212L\n(d)\nr=1\n \u0307\n> e\n\n(77)\n\nwhere (a) follows from equation (23) and step (2) of our suboptimal algorithm, (b) results from the first\npart of Theorem III, and (c) can be justified using arguments similar to those of inequality (67). (d) is\nobtained assuming \u01eb is small enough such that the corresponding term in the exponent is strictly less than\n\u2032\n\u2032\u0001\n= \u03b1 + o(1). The result in (77) is obviously in contradiction with the\nand also the fact that K\nL\u03b3j uj K\n\u2032\nN\nN\u2032\nfirst part of Theorem III, proving that N\u0302j > \u01ebN \u2032 .\n\nNow, we show that if N\u0302j > (1 \u2212 \u01eb)N \u2032 for arbitrarily small values of \u01eb, we should have E {xr } > \u03b1 for\nall 1 \u2264 r \u2264 j \u2212 1. In such a case, we observe\n\nN\u0302j\nN\u2032\n\n= 1 + o(1), proving the second statement of Theorem\n\nIII. To show this, let us assume N\u0302j > (1 \u2212 \u01eb)N \u2032 . Hence,\n\u2032\n\n\u2032\n\nP\u0302e (N , K , j) =\n\nN\u0302j\nX\n\nP\u0302e (N \u2032 \u2212 N\u0302j , K \u2032 \u2212 i, j \u2212 1)Qj (N\u0302j , i)\n\ni=0\n\n \u0307 P\u0302e (N \u2032 \u2212 N\u0302j , 0, j \u2212 1)Qj (N\u0302j , K \u2032 )\n\u2265\n(a)\n\n \u0307 e\u2212L\u03b3j uj\n\u2265\n\n\"\n\nK\u2032\n(1\u2212\u01eb)N \u2032\n\n\" (b)\n\n.\n= e\u2212L\u03b3j uj (\u03b1+o(1))\n\n(78)\n\nwhere (a) follows from the fact that P\u0302e (n, 0, j) = 1, for all values of n and j, and the fact that N\u0302j \u2265\n(1 \u2212 \u01eb)N \u2032 . (b) is obtained by making \u01eb arbitrarily small and using equation (76). Applying (78) and\nPj\n.\nknowing the fact that P\u0302e (N \u2032 , K \u2032 , j) = e\u2212L r=1 \u03b3r ur (\u03b1) , we conclude that E {xr } > \u03b1, for all values of\n1 \u2264 r \u2264 j \u2212 1.\n\n\f39\n\nP\u0302e (N \u2032 , K \u2032 , j) can be written as\nP\u0302e (N \u2032 , K \u2032 , j)\n=\n(a)\n\n.\n=\n\nmin\n\n0\u2264Nj \u2264N \u2032\n\nNj\nX\n\nP\u0302e (N \u2032 \u2212 Nj , K \u2032 \u2212 i, j \u2212 1)Qj (Nj , i)\n\ni=0\n\nmin\n\nmax\n\n0\u2264i\u2264Nj\n\n\u01ebN \u2032 \u2264Nj \u2264(1\u2212\u01eb)N \u2032\n\nP\u0302e (N \u2032 \u2212 Nj , K \u2032 \u2212 i, j \u2212 1)Qj (Nj , i)\n(b)\n\n.\n=\n\nmin\n\nmax\n\n\u01ebN \u2032 \u2264Nj \u2264(1\u2212\u01eb)N \u2032\n\n\u0012\n\ni\nNj\n\nE{xj }Nj <i\u2264Nj\n\n\u0013\n\nj\u22121\nX\n\n\u0012\n\nK\u2032 \u2212 i\nN \u2032 \u2212 Nj\n\n\u0013\n\n\u2212L\u03b3j uj\n\u03b3r ur\n\u2212L\nr=1\ne\nmin\nMd (i, Nj )\n\u2212L \u2032 max\n.\nE{xj }Nj <i\u2264Nj\n\u01ebN \u2264Nj \u2264(1\u2212\u01eb)N \u2032\n= e\n\u2212L max\nmin\nMc (\u03b2j , \u03bbj )\n(c)\n.\n\u01eb\u2264\u03bbj \u2264(1\u2212\u01eb)\nE{xj }\u03bbj <\u03b2j \u2264\u03bbj\n= e\n.\n\n(79)\n\nwhere Md (i, Nj ) and Mc (\u03b2j , \u03bbj ) are defined as\n\u0012 \u2032\n\u0013 X\n\u0013\nj\u22121\nK \u2212i\ni\n\u03b3r ur\n+\nMd (i, Nj ) = \u03b3j uj\nNj\nN \u2032 \u2212 Nj\nr=1\n\u0012 \u0013 X\n\u0012\n\u0013\nj\u22121\n\u03b2j\n\u03b1 \u2212 \u03b2j\nMc (\u03b2j , \u03bbj ) = \u03b3j uj\n\u03b3r ur\n+\n.\n\u03bbj\n1 \u2212 \u03bbj\nr=1\n\u0012\n\nIn (79), (a) follows from the fact that N\u0302j is bounded as \u01ebN \u2032 \u2264 N\u0302j \u2264 (1 \u2212 \u01eb)N \u2032 . (b) results from\n.\nequation (63), P\u0302e (n, k, j) being a decreasing function of k, and the fact that we have Qj (Nj , i) \u2264 1 =\nN\n\nQj (Nj , E {xj } Nj ) for i < E {xj } Nj . \u03b2j and \u03bbj are defined as \u03b2j = Ni \u2032 and \u03bbj = Nj\u2032 . (c) is a result of\n\u0001\nhaving Mc (\u03b2j , \u03bbj ) = Md (i, Nj ) + O L1 . Hence, the discrete to continuous relaxation is valid.\n\u0001\nLet us define \u03b2j\u2217 , \u03bb\u2217j as the values of (\u03b2j , \u03bbj ) which solve the max-min problem in (79). Differentiating\nMc (\u03b2j , \u03bbj ) with respect to \u03b2j and \u03bbj results in\n\u0012 \u2217\u0013\nj\u22121\nX\n\u03b2j\n\u03b3r\n\u03b3j\n\u2212\nlr (\u03b6)\n0 = \u2217 lj\n\u2217\n\u03bbj\n\u03bbj\n1 \u2212 \u03bb\u2217j\nr=1,\nE{x }<\u03b6\n\nr\n\uf8f1\n\uf8f4\n\uf8f4\nj\u22121\n\uf8f2 \u03b3 \u03b2\u2217 \u0012 \u03b2\u2217 \u0013\nX\n\u03b3r (\u03b1 \u2212 \u03b2j\u2217 )\nj j\nj\n0 = \u2212 \u22172 lj\n+\nl (\u03b6)\n\u2217 2 r\n\uf8f4\n\u03bbj\n\u03bb\u2217j\n(1\n\u2212\n\u03bb\n)\n\uf8f4\nj\nr=1,\n\uf8f3\nE{xr }<\u03b6\n\uf8fc\n\uf8f6\n\uf8eb\n\uf8f4\n\uf8f4\n\u0012 \u2217\u0013\nj\u22121\n\uf8fd\n\u2217\nX\n\uf8f7\n\uf8ec \u03b3j\n\u03b2j\n\u2202\u03b2\n\u03b3\nr\nj\n\uf8f7\n\u2217\nl\n\u2212\nl\n(\u03b6)\n|\n+\uf8ec\nr\n\uf8f8 \u2202\u03bbj \u03bbj =\u03bbj \uf8f4\n\uf8ed \u03bb\u2217 j \u03bb\u2217\n1 \u2212 \u03bb\u2217j\nj\nj\n\uf8f4\nr=1,\n\uf8fe\n\nE{xr }<\u03b6\n\n\f40\n\nwhere \u03b6 =\n\n\u03b1 \u2212 \u03b2j\u2217\n. Solving the above equations gives the unique optimum solution (\u03b2j\u2217 , \u03bb\u2217j ) as\n1 \u2212 \u03bb\u2217j\n\u03b2j\u2217 = \u03b1\u03bb\u2217j\n\u03bb\u2217j =\n\n\u03b3j lj (\u03b1)\nj\nX\nlr (\u03b1)\n\n(80)\n\nr=1,\u03b1>E{xr }\n\nHence, the integer parameters Kj , N\u0302j defined in the suboptimal algorithm have to satisfy\nand\n\nN\u0302j\nN\u2032\n\nKj\nN\u2032\n\n= \u03b2j\u2217 + o(1)\n\n= \u03bb\u2217j + o(1), respectively. Based on the induction assumption, it is easy to show that\n\n\u2032\n\nN\n=\nN\n\nj\nX\n\n\u03b3r ur (\u03b1)\n\nr=1,E{xr }<\u03b1\nJ\nX\n\n(81)\n\u03b3r ur (\u03b1)\n\nr=1,E{xr }<\u03b1\n\nwhich completes the proof for the case of E {xj } <\nK\n\u2264 E{xj }\nN\nIn this case, we show that\n\nK\n.\nN\n\n2.2)\n\nN\u0302j\nN\n\n= o(1). Defining ij = \u2308E{xj }N\u0302j \u2309, we have\n\nK \u2032 \u2212 ij\nN \u2032 \u2212 N\u0302j\n\n= \u03b1 \u2212 (E{xj } \u2212 \u03b1)\n\nN\u0302j\nN \u2032 \u2212 N\u0302j\n\n+ o(1)\n\n(82)\n\nusing equation (76). Now, we have\nP\u0302e (N \u2032 , K \u2032 , j)\n=\n\nN\u0302j\nX\n\nP\u0302e (N \u2032 \u2212 N\u0302j , K \u2032 \u2212 i, j \u2212 1)Qj (N\u0302j , i)\n\ni=0\n\n\u2265 P\u0302e (N \u2032 \u2212 N\u0302j , K \u2032 \u2212 ij , j \u2212 1)Qj (N\u0302j , ij )\n(a)\n\n.\n= e\u2212L\u03b3j uj (E{xj } + o(1)) *\n!\nj\u22121\nX\nN\u0302j\n\u03b3r ur \u03b1 \u2212 (E{xj } \u2212 \u03b1)\n\u2212L\nN \u2032 \u2212 N\u0302j\nr=1\ne\n!\nj\u22121\nX\nN\u0302j\n\u03b3r ur \u03b1 \u2212 (E{xj } \u2212 \u03b1)\n\u2212L\n.\nN \u2032 \u2212 N\u0302j\nr=1\n= e\n\n(83)\n\nwhere (a) follows from the first part of Theorem III and (63). On the other hand, according to the result\nof the first part of Theorem III, we know that\nj\u22121\nX\n\n\u03b3r ur (\u03b1)\n\u2212L\n.\nr=1\n.\nP\u0302e (N , K , j) = e\n\u2032\n\n\u2032\n\n(84)\n\n\f41\n\nAccording to Lemma I, ur (\u03b2) is an increasing function of \u03b2 for all 1 \u2264 r \u2264 j \u2212 1. Thus,\n\nPj\u22121\n\nr=1\n\n\u03b3r ur (\u03b2)\n\nis also a one-to-one increasing function of \u03b2. Noting this fact and comparing (83) and (84), we conclude\nthat\n\nN\u0302j\nN\u2032\n\n= o(1) as E {xj } \u2212 \u03b1 is strictly positive. Noting (81), we have\n\npart of Theorem III for the case of\n\nK\nN\n\nN\u0302j\nN\n\n= o(1) which proves the second\n\n\u2264 E{xj }.\nR EFERENCES\n\n[1] J.C. Bolot, S. Fosse-Parisis, and D. Towsley, \"Adaptive FEC-based error control for Internet telephony,\" in IEEE INFOCOM, Proc.\nIEEE Vol. 3, 1999, pp. 1453\u20131460.\n[2] J.C. Bolot and T. Turletti, \"Adaptive Error Control For Packet Video In The Internet,\" in Proc. IEEE International Conference on\nImage Processing, 1996, pp. 25 \u2013 28.\n[3] T. Nguyen and A. Zakhor , \"Path diversity with forward error correction (pdf) system for packet switched networks,\" in IEEE INFOCOM\nProc. IEEE Vol. 1, 2003, pp. 663\u2013 672.\n[4] T. Nguyen and A. Zakhor, \"Multiple Sender Distributed Video Streaming,\" IEEE transactions on multimedia, vol. 6, no. 2, pp. 315\u2013\n326, 2004.\n[5] F. L. Leannec, F. Toutain, and C. Guillemot, \"Packet Loss Resilient MPEG-4 Compliant Video Coding for the Internet,\" Journal of\nImage Communication, Special Issue on Real-time video over the Internet, no. 15, pp. 35\u201356, 1999.\n[6] S. Fashandi, S. Oveisgharan, and A.K. Khandani, \"Coding over an Erasure Channel with a Large Alphabet Size,\" in IEEE International\nSymposium on Information Theory, ISIT '08, 2008.\n[7] --, \"Coding over an Erasure Channel with a Large Alphabet Size,\" 2008, library and Archives Canada Technical Report UW-ECE\n#2008-06, http://cst.uwaterloo.ca/r/2008-06 Shervan.pdf.\n[8] H. Han, S. Shakkottai, C.V. Hollot, R. Srikant, and D. Towsley, \"Multi-Path TCP: A Joint Congestion Control and Routing Scheme to\nExploit Path Diversity in the Internet,\" IEEE/ACM Transactions on Networking, vol. 14, no. 6, pp. 1260 \u2013 1271, 2006.\n[9] S. Mao, S.S. Panwar, and Y.T. Hou, \"On optimal partitioning of realtime traffic over multiple paths,\" in INFOCOM 2005, Proc. IEEE\nVol. 4, 2005, pp. 2325\u20132336.\n[10] S. Fashandi, S. Oveisgharan, and A.K. Khandani, \"Path Diversity in Packet Switched Networks: Performance Analysis and Rate\nAllocation,\" in IEEE Global Telecommunications Conference, GLOBECOM '07, 2007, pp. 1840\u20131844.\n[11] J. Han, D. Watson, and F. Jahanian, \"An Experimental Study of Internet Path Diversity,\" IEEE Transactions on Dependable and Secure\nComputing, vol. 3, no. 4, pp. 273 \u2013 288, 2006.\n[12] J. Han and F. Jahanian, \"Impact of Path Diversity on Multi-homed and Overlay Networks,\" in International Conference on Dependable\nSystems and Networks, 2004, pp. 29\u201338.\n[13] N. Spring, R. Mahajan, D. Wetherall, and T. Anderson, \"Measuring ISP Topologies with Rocketfuel,\" IEEE/ACM Transactions on\nNetworking, vol. 12, no. 1, pp. 2\u2013 16, 2004.\n[14] R. Teixeira, K. Marzullo, S. Savage, and G. M. Voelker, \"In Search of Path Diversity in ISP Networks,\" in Proceedings of the 3rd\nACM SIGCOMM Conference on Internet Measurement, 2003, pp. 313 \u2013 318.\n[15] A. L. Barbasi and R. Albert, \"Emergence of Scaling in Random Networks,\" Science, vol. 286, no. 5439, pp. 509\u2013512, 1999.\n[16] David G. Andersen, Resilient Overlay Networks.\n\nMaster's Thesis, Massachusetts Institute of Technology, 2001.\n\n[17] Y. J. Liang, E. G. Steinbach, and B. Girod , \"Multi-stream Voice over IP using Packet Path Diversity,\" in IEEE Fourth Workshop on\nMultimedia Signal Processing, 2001, pp. 555\u2013560.\n[18] S. Nelakuditi, Z. Zhang, and D. H. C. Du, \"On Selection of Candidate Paths for Proportional Routing,\" Elsevier Computer Networks,\nvol. 44, no. 1, pp. 79\u2013102, 2004.\n[19] D. G. Andersen, A. C. Snoeren, and H. Balakrishnan, \"Best-path vs. Multi-path Overlay Routing,\" in Proceedings of the 3rd ACM\nSIGCOMM Conference on Internet Measurement, 2003, pp. 91 \u2013 100.\n\n\f42\n\n[20] B-G Chun, R. Fonseca, I. Stoica, and J. Kubiatowicz, \"Characterizing Selfishly Constructed Overlay Routing Networks,\" in IEEE\nINFOCOM, 2004, pp. 1329\u20131339.\n[21] J. Han, D. Watson, and F. Jahanian, \"Topology Aware Overlay Networks,\" in IEEE INFOCOM, vol. 4, 2005, pp. 2554\u2013 2565.\n[22] M. Guo, Q. Zhang, and W. Zhu , \"Selecting Path-diversified Servers in Content Distribution Networks,\" in IEEE Global Telecommunications Conference, GLOBECOM '03, vol. 6, 2003, pp. 3181\u20133185.\n[23] A. Akella, B. Maggs, S. Seshan, and A. Shaikh, \"On the Performance Benefits of Multihoming Route Control,\" IEEE/ACM Transactions\non Networking, vol. 16, no. 1, pp. 91\u2013104, 2008.\n[24] A. Akella, J. Pang, B. Maggs, S. Seshan, and A. Shaikh, \"A Comparison of Overlay Routing and Multihoming Route Control,\" in\nACM SIGCOMM, 2004, pp. 93 \u2013 106.\n[25] S. Srinivasan, Design and Use of Managed Overlay Networks. PhD Dissertation, Georgia Institute of Technology, 2007.\n[26] M. Cha, S. Moon, C. D. Park, and A. Shaikh, \"Placing Relay Nodes for Intra-Domain Path Diversity,\" in IEEE INFOCOM, 2006, pp.\n1\u201312.\n[27] David Eppstein, \"Finding the k shortest paths,\" in Proc. 35th Symp. Foundations of Computer Science, 1994, pp. 154\u2013165.\n[28] Richard G. Ogier, Vlad Rutenburg, and Nauchum Shacham, \"Distributed Algorithms for Computing Shortest Pairs of Disjoint Paths,\"\nIEEE transactions on information theory, vol. 39, no. 2, pp. 443\u2013 455, 1993.\n[29] D. Clark, W. Lehr, S. Bauer, P. Faratin, R. Sami, and J. Wroclawski, \"Overlay Networks and Future of the Internet,\" Journal of\nCommunications and Strategies, vol. 3, no. 63, pp. 1\u201321, 2006.\n[30] M. Cha, Network Support for Emerging Multimedia Streaming Services. PhD Dissertation, Korea Advanced Institute of Science and\nTechnology, 2007.\n[31] Roger Karrer, and Thomas Gross, \"Multipath Streaming in Best-Effort Networks,\" in Proc. of the IEEE International Conference on\nCommunications (ICC'03), 2003.\n[32] J.G. Apostolopoulos, T. Wong, W. Tan, and S.J. Wee, \"On Multiple Description Streaming with Content Delivery Networks,\" in IEEE\nINFOCOM, Proc. IEEE Vol. 3, 2002, pp. 1736 \u2013 1745.\n[33] \"Akamai SureRoute,\" http://www.akamai.com/dl/feature sheets/fs edge\\suite sureroute.pdf.\n[34] M. Ghanassi and P. Kabal, \"Optimizing Voice-over-IP Speech Quality Using Path Diversity,\" in IEEE 8th Workshop on Multimedia\nSignal Processing, 2006, pp. 155\u2013160.\n[35] J. Chakareski and B. Girod, \"Rate-distortion optimized packet scheduling and routing for media streaming with path diversity,\" in\nProc. IEEE Data Compression Conference, 2003, pp. 203\u2013 212.\n[36] M. Afergan, J. Wein, and A. LaMeyer, \"Experience with some Principles for Building an Internet-Scale Reliable System,\" in Proceedings\nof the Fifth IEEE International Symposium on Network Computing and Applications (NCA'06), 2006, p. 3.\n[37] Ron M. Roth, Introduction to Coding Theory, 1st ed.\n\nCambridge University Press, 2006, pp. 333\u2013351.\n\n[38] W. T. Tan and A. Zakhor, \"Video Multicast Using Layered FEC and Scalable Compression,\" IEEE Transactions on Circuits and Systems\nfor Video Technology, vol. 11, no. 3, pp. 373\u2013386, 2001.\n[39] L. Dairaine, L. Lancrica, J. Lacan, and J. Fimes, \"Content-Access QoS in Peer-to-Peer Networks Using a Fast MDS Erasure Code,\"\nElsevier Computer Communications, vol. 28, no. 15, pp. 1778\u20131790, 2005.\n[40] X. H. Peng, \"Erasure-control Coding for Distributed Networks,\" IEE Proceedings on Communications, vol. 152, pp. 1075 \u2013 1080,\n2005.\n[41] N. Alon, J. Edmonds, and M. Luby, \"Linear Time Erasure Codes with Nearly Optimal Recovery,\" in IEEE Symposium on Foundations\nof Computer Science, Proc. IEEE Vol. 3, 1995, pp. 512\u2013519.\n[42] J. Justesen , \"On the complexity of decoding Reed-Solomon codes,\" IEEE transactions on information theory, vol. 22, no. 2, pp. 237\u2013\n238, 1993.\n[43] M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. A. Spielman, \"Efficient Erasure Correcting Codes,\" IEEE Transactions on\nInformation Theory, vol. 47, no. 2, pp. 569\u2013584, 2001.\n[44] A. Shokrollahi, \"Raptor Codes,\" IEEE Transactions on Information Theory, vol. 52, no. 6, pp. 2551\u20132567, 2006.\n\n\f43\n\n[45] R. Koetter and M. Medard , \"An algebraic approach to network coding,\" IEEE transactions on Networking, vol. 11, no. 5, pp. 782\u2013\n795, 2003.\n[46] P. A. Chou, Y. Wu, and K. Jain, \"Practical Network Coding ,\" in 51st Allerton Conference on Communication, Control and Computing,\n2003.\n[47] C. Gkantsidis and P. R. Rodriguez, \"Network coding for large scale content distribution,\" in IEEE INFOCOM, Proc. IEEE Vol. 4,\n2005, pp. 2235\u20132245.\n[48] M. Yajnik, S.B. Moon, J.F. Kurose, and D.F. Towsley , \"Measurement and Modeling of the Temporal Dependence in Packet Loss,\" in\nIEEE INFOCOM Proc. IEEE Vol. 1, 1999, pp. 345\u2013352.\n[49] P. Rossi, G. Romano, F. Palmieri, and G. Iannello , \"A Hidden Markov Model for Internet Channels,\" in IEEE International Symposium\non Signal Processing and Information Technology, 2003.\n[50] W. Kellerer, E. Steinbach, P. Eisert, and B. Girod, \"A Real-Time Internet Streaming Media Testbed,\" in Proc. IEEE International\nConference on Multimedia and Expo, 2002, pp. 453\u2013 456.\n[51] X. Henocq and C. Guillemot, \"Source Adaptive Error Control for Real-time Video over the Internet,\" Numro spcial image et vido.\nHerms. Rseaux et systme rparti. Calculateurs Parallles, vol. 12, no. 3-4, 2000.\n[52] F. L. Leannec and C. Guillemot, \"Error Resilient Video Transmission over the Internet,\" in Proc. Visual Communication and Image\nProcessing, 1999.\n[53] K. Salamatian and Vaton, \"Hidden Markov Modeling for Network Communication Channels,\" in Proc. ACM SIGMETRICS, 2001, pp.\n92 \u2013 101.\n[54] Ron M. Roth, Introduction to Coding Theory, 1st ed.\n\nCambridge University Press, 2006, pp. 183\u2013204.\n\n[55] J. Padhye, V. Firoiu, D.F Towsley, and J.F. Kurose, \"Modeling TCP Reno performance: a simple model and its empirical validation,\"\nIEEE/ACM Transactions on Networking, vol. 8, no. 2, pp. 133 \u2013 145, 2000.\n[56] Amir Dembo and Ofer Zeitouni, Large Deviations Techniques and Applications, 2nd ed.\n[57] J. L. Kelley, General Topology.\n\nNew York: Springer, 1998, pp. 11\u201343.\n\nSpringer, 1975, pp. 40\u201343.\n\n[58] C. H. Papadimitriou, Computational Complexity, 1st ed.\n\nNew York: Addison Wesley, 1994.\n\n[59] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction to Algorithms, 2nd ed.\n[60] W. Rudin, Principles of Mathematical Analysis, 3rd ed.\n\nMcGraw-Hill, 1976.\n\n[61] S. Boyd and L. Vandenberghe, Convex Optimization, 1st ed.\n\nCambridge, UK: Cambridge University Press, 2004, pp. 243\u2013245.\n\n[62] T. Cover and J. Thomas, Elements of Information Theory, 1st ed.\n[63] --, Elements of Information Theory, 1st ed.\n\nMIT Press, 2001, pp. 347\u2013349.\n\nNew York: Wiley, 1991, pp. 291\u2013294.\n\nNew York: Wiley, 1991, pp. 30\u201331.\n\n\f"}