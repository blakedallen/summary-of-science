{"id": "http://arxiv.org/abs/0811.1075v2", "guidislink": true, "updated": "2008-12-05T10:34:34Z", "updated_parsed": [2008, 12, 5, 10, 34, 34, 4, 340, 0], "published": "2008-11-07T15:31:58Z", "published_parsed": [2008, 11, 7, 15, 31, 58, 4, 312, 0], "title": "Resolution Trees with Lemmas: Resolution Refinements that Characterize\n  DLL Algorithms with Clause Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0811.2539%2C0811.1018%2C0811.4337%2C0811.0820%2C0811.0853%2C0811.4082%2C0811.0618%2C0811.3819%2C0811.2724%2C0811.4042%2C0811.3722%2C0811.2688%2C0811.1526%2C0811.1981%2C0811.0593%2C0811.2147%2C0811.3179%2C0811.3782%2C0811.2113%2C0811.0931%2C0811.2172%2C0811.1284%2C0811.2146%2C0811.0560%2C0811.0196%2C0811.2035%2C0811.3446%2C0811.2255%2C0811.2235%2C0811.2203%2C0811.4231%2C0811.3207%2C0811.4553%2C0811.1883%2C0811.1439%2C0811.3833%2C0811.4123%2C0811.3325%2C0811.0207%2C0811.3216%2C0811.4389%2C0811.4586%2C0811.1217%2C0811.0859%2C0811.0983%2C0811.1132%2C0811.0956%2C0811.3780%2C0811.0391%2C0811.1012%2C0811.2195%2C0811.3723%2C0811.3188%2C0811.1931%2C0811.2469%2C0811.1021%2C0811.0906%2C0811.0767%2C0811.3957%2C0811.0242%2C0811.3407%2C0811.1064%2C0811.1731%2C0811.1759%2C0811.1094%2C0811.1075%2C0811.3198%2C0811.4525%2C0811.0999%2C0811.4178%2C0811.2325%2C0811.2490%2C0811.3035%2C0811.0044%2C0811.1537%2C0811.4487%2C0811.3392%2C0811.1541%2C0811.1158%2C0811.3307%2C0811.0809%2C0811.4559%2C0811.1325%2C0811.4650%2C0811.0439%2C0811.4397%2C0811.1613%2C0811.4306%2C0811.3085%2C0811.3569%2C0811.4239%2C0811.1691%2C0811.0101%2C0811.1392%2C0811.0238%2C0811.1166%2C0811.3481%2C0811.1482%2C0811.1109%2C0811.1201%2C0811.0205&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Resolution Trees with Lemmas: Resolution Refinements that Characterize\n  DLL Algorithms with Clause Learning"}, "summary": "Resolution refinements called w-resolution trees with lemmas (WRTL) and with\ninput lemmas (WRTI) are introduced. Dag-like resolution is equivalent to both\nWRTL and WRTI when there is no regularity condition. For regular proofs, an\nexponential separation between regular dag-like resolution and both regular\nWRTL and regular WRTI is given.\n  It is proved that DLL proof search algorithms that use clause learning based\non unit propagation can be polynomially simulated by regular WRTI. More\ngenerally, non-greedy DLL algorithms with learning by unit propagation are\nequivalent to regular WRTI. A general form of clause learning, called\nDLL-Learn, is defined that is equivalent to regular WRTL.\n  A variable extension method is used to give simulations of resolution by\nregular WRTI, using a simplified form of proof trace extensions. DLL-Learn and\nnon-greedy DLL algorithms with learning by unit propagation can use variable\nextensions to simulate general resolution without doing restarts.\n  Finally, an exponential lower bound for WRTL where the lemmas are restricted\nto short clauses is shown.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0811.2539%2C0811.1018%2C0811.4337%2C0811.0820%2C0811.0853%2C0811.4082%2C0811.0618%2C0811.3819%2C0811.2724%2C0811.4042%2C0811.3722%2C0811.2688%2C0811.1526%2C0811.1981%2C0811.0593%2C0811.2147%2C0811.3179%2C0811.3782%2C0811.2113%2C0811.0931%2C0811.2172%2C0811.1284%2C0811.2146%2C0811.0560%2C0811.0196%2C0811.2035%2C0811.3446%2C0811.2255%2C0811.2235%2C0811.2203%2C0811.4231%2C0811.3207%2C0811.4553%2C0811.1883%2C0811.1439%2C0811.3833%2C0811.4123%2C0811.3325%2C0811.0207%2C0811.3216%2C0811.4389%2C0811.4586%2C0811.1217%2C0811.0859%2C0811.0983%2C0811.1132%2C0811.0956%2C0811.3780%2C0811.0391%2C0811.1012%2C0811.2195%2C0811.3723%2C0811.3188%2C0811.1931%2C0811.2469%2C0811.1021%2C0811.0906%2C0811.0767%2C0811.3957%2C0811.0242%2C0811.3407%2C0811.1064%2C0811.1731%2C0811.1759%2C0811.1094%2C0811.1075%2C0811.3198%2C0811.4525%2C0811.0999%2C0811.4178%2C0811.2325%2C0811.2490%2C0811.3035%2C0811.0044%2C0811.1537%2C0811.4487%2C0811.3392%2C0811.1541%2C0811.1158%2C0811.3307%2C0811.0809%2C0811.4559%2C0811.1325%2C0811.4650%2C0811.0439%2C0811.4397%2C0811.1613%2C0811.4306%2C0811.3085%2C0811.3569%2C0811.4239%2C0811.1691%2C0811.0101%2C0811.1392%2C0811.0238%2C0811.1166%2C0811.3481%2C0811.1482%2C0811.1109%2C0811.1201%2C0811.0205&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Resolution refinements called w-resolution trees with lemmas (WRTL) and with\ninput lemmas (WRTI) are introduced. Dag-like resolution is equivalent to both\nWRTL and WRTI when there is no regularity condition. For regular proofs, an\nexponential separation between regular dag-like resolution and both regular\nWRTL and regular WRTI is given.\n  It is proved that DLL proof search algorithms that use clause learning based\non unit propagation can be polynomially simulated by regular WRTI. More\ngenerally, non-greedy DLL algorithms with learning by unit propagation are\nequivalent to regular WRTI. A general form of clause learning, called\nDLL-Learn, is defined that is equivalent to regular WRTL.\n  A variable extension method is used to give simulations of resolution by\nregular WRTI, using a simplified form of proof trace extensions. DLL-Learn and\nnon-greedy DLL algorithms with learning by unit propagation can use variable\nextensions to simulate general resolution without doing restarts.\n  Finally, an exponential lower bound for WRTL where the lemmas are restricted\nto short clauses is shown."}, "authors": ["Samuel R. Buss", "Jan Hoffmann", "Jan Johannsen"], "author_detail": {"name": "Jan Johannsen"}, "author": "Jan Johannsen", "links": [{"title": "doi", "href": "http://dx.doi.org/10.2168/LMCS-4(4:13)2008", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0811.1075v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0811.1075v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "F.2.2; I.2.8", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0811.1075v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0811.1075v2", "arxiv_comment": null, "journal_reference": "Logical Methods in Computer Science, Volume 4, Issue 4 (December\n  5, 2008) lmcs:860", "doi": "10.2168/LMCS-4(4:13)2008", "fulltext": "Logical Methods in Computer Science\nVol. 4 (4:13) 2008, pp. 1\u201328\nwww.lmcs-online.org\n\nSubmitted\nPublished\n\nJun. 24, 2008\nDec. 5, 2008\n\nRESOLUTION TREES WITH LEMMAS:\nRESOLUTION REFINEMENTS THAT CHARACTERIZE DLL\nALGORITHMS WITH CLAUSE LEARNING\nSAMUEL R. BUSS a , JAN HOFFMANN b , AND JAN JOHANNSEN c\na\n\nb,c\n\nDepartment of Mathematics, University of California, San Diego, La Jolla, CA 92093-0112, USA\ne-mail address: sbuss@math.ucsd.edu\nInstitut f\u00fcr Informatik, Ludwig-Maximilians Universit\u00e4t, D-80538 M\u00fcnchen, Germany\ne-mail address: {jan.hoffmann,jan.johannsen}@ifi.lmu.de\n\nAbstract. Resolution refinements called w-resolution trees with lemmas (WRTL) and\nwith input lemmas (WRTI) are introduced. Dag-like resolution is equivalent to both\nWRTL and WRTI when there is no regularity condition. For regular proofs, an exponential\nseparation between regular dag-like resolution and both regular WRTL and regular WRTI\nis given.\nIt is proved that DLL proof search algorithms that use clause learning based on unit\npropagation can be polynomially simulated by regular WRTI. More generally, non-greedy\nDLL algorithms with learning by unit propagation are equivalent to regular WRTI. A\ngeneral form of clause learning, called DLL-Learn, is defined that is equivalent to regular\nWRTL.\nA variable extension method is used to give simulations of resolution by regular WRTI,\nusing a simplified form of proof trace extensions. DLL-Learn and non-greedy DLL algorithms with learning by unit propagation can use variable extensions to simulate general\nresolution without doing restarts.\nFinally, an exponential lower bound for WRTL where the lemmas are restricted to short\nclauses is shown.\n\n1. Introduction\nAlthough the satisfiability problem for propositional logic (SAT) is NP-complete, there\nexist SAT solvers that can decide SAT on present-day computers for many formulas that\nare relevant in practice [23, 21, 20, 3, 4, 5]. The fastest SAT solvers for structured problems\nare based on the basic backtracking procedures known as DLL algorithms [9], extended\nwith additional techniques such as clause learning.\n1998 ACM Subject Classification: F.2.2, I.2.8.\nKey words and phrases: propositional proof complexity, resolution, SAT solving, DLL algoritm, clause\nlearning.\na\nSupported in part by NSF grants DMS-0400848 and DMS-0700533.\nb\nSupported in part by the Studienstiftung des deutschen Volkes (German National Merit Foundation).\n\nl\n\nLOGICAL METHODS\nIN COMPUTER SCIENCE\n\nc\nDOI:10.2168/LMCS-4 (4:13) 2008\n\nCC\n\nS. R. Buss, J. Hoffmann, and J. Johannsen\nCreative Commons\n\n\f2\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nDLL algorithms can be seen as a kind of proof search procedure since the execution of\na DLL algorithm on an unsatisfiable CNF formula yields a tree-like resolution refutation\nof that formula. Conversely, given a tree-like resolution refutation, an execution of a DLL\nalgorithm on the refuted formula can be constructed whose runtime is roughly the size of the\nrefutation. By this exact correspondence, upper and lower bounds on the size of tree-like\nresolution proofs transfer to bounds on the runtime of DLL algorithms.\nThis paper generalizes this exact correspondence to extensions of DLL by clause learning. To this end, we define natural, rule-based resolution proof systems and then prove\nthat they correspond to DLL algorithms that use various forms of clause learning. The\nmotivation for this is that the correspondence between a clause learning DLL algorithm\nand a proof system helps explain the power of the algorithm by giving a description of\nthe space of proofs which is searched by it. In addition, upper and lower bounds on proof\ncomplexity can be transferred to upper and lower bounds on the possible runtimes of large\nclasses of DLL algorithms with clause learning.\nWe introduce, in Section 3, tree-like resolution refinements using the notions of a\nresolution tree with lemmas (RTL) and a resolution tree with input lemmas (RTI). An\nRTL is a tree-like resolution proof in which every clause needs only to be derived once and\ncan be copied to be used as a leaf in the tree (i.e., a lemma) if it is used several times. As\nthe reader might guess, RTL is polynomially equivalent to general resolution.\nSince DLL algorithms use learning based on unit propagation, and since unit propagation is equivalent to input resolution (sometimes called \"trivial resolution\" [2]), it is useful\nto restrict the lemmas that are used in a RTL to those that appear as the root of input\nsubproofs. This gives rise to proof systems based on resolution trees with input lemmas\n(RTI). Somewhat surprisingly, we show that RTI can also simulate general resolution.\nA resolution proof is called regular if no variable is used as a resolution variable twice\nalong any path in the tree. Regular proofs occur naturally in the present context, since\na backtracking algorithm would never query the same variable twice on one branch of its\nexecution. It is known that regular resolution is weaker than general resolution [14, 1], but\nit is unknown whether regular resolution can simulate regular RTL or regular RTI. This\nis because, in regular RTL/RTI proofs, variables that are used for resolution to derive a\nclause can be reused on paths where this clause appears as a lemma.\nFor resolution and regular resolution, the use of a weakening rule does not increase\nthe power of the proof system (by the subsumption principle). However, for RTI and\nregular RTL proofs, the weakening rule may increase the strength of the proof system\n(this is an open question, in fact), since eliminating uses of weak inferences may require\npruning away parts of the proof that contain lemmas needed later in the proof. Accordingly,\nSection 3 also defines proof systems regWRTL and regWRTI that consist of regular RTL and\nregular RTI (respectively), but with a modified form of resolution, called \"w-resolution\",\nthat incorporates a restricted form of the weakening rule.\nIn Section 4 we propose a general framework for DLL algorithms with clause learning,\ncalled DLL-L-UP. The schema DLL-L-UP is an attempt to give a short and abstract\ndefinition of modern SAT solvers and it incorporates all common learning strategies, including all the specific strategies discussed by Beame et al. [2]. Section 5 proves that, for\nany of these learning strategies, a proof search tree can be transformed into a regular WRTI\nproof with only a polynomial increase in size. Conversely, any regular WRTI proof can be\nsimulated by a \"non-greedy\" DLL search tree with clause learning, where by \"non-greedy\"\n\n\fRESOLUTION TREES WITH LEMMAS\n\n3\n\nis meant that the algorithm can continue decision branching even after unit propagation\ncould yield a contradiction.\nIn Section 6 we give another generalization of DLL with clause learning called DLLLearn. The algorithm DLL-Learn can simulate the clause learning algorithm DLL-LUP. More precisely, we prove that DLL-Learn p-simulates, and is p-simulated by, regular\nWRTL. The DLL-Learn algorithm is very similar to the \"pool resolution\" algorithm that\nhas been introduced by Van Gelder [25] but differs from pool resolution by using the\n\"w-resolution\" inference in place of the \"degenerate\" inference used by Van Gelder (the\nterminology \"degenerate\" is used by Hertel et al. [16]). Van Gelder has shown that pool\nresolution can simulate not only regular resolution, but also any resolution refutation which\nhas a regular depth-first search tree. The latter proof system is the same as the proof\nsystem regRTL in our framework, therefore the same holds for DLL-Learn. It is unknown\nwhether DLL-Learn or DLL-L-UP can p-simulate pool resolution or vice versa.\nSections 4-6 prove the equivalence of clause learning algorithms with the two proof\nsystems regWRTI and regWRTL. Our really novel system is regWRTI: this system has the\nadvantage of using input lemmas in a manner that closely matches the range of clause\nlearning algorithms that can be used by practical DLL algorithms. In particular, the\nregWRTI proof system's use of input lemmas corresponds directly to the clause learning\nstrategies of Silva and Sakallah [23], including first-UIP, relsat, and other clauses based\non cuts, and including learning multiple clauses at a time. Van Gelder [25] shows that\npool resolution can also simulate these kinds of clause learning (at least, for learning single\nclauses), but the correspondence is much more natural for the system regWRTI than for\neither pool resolution or DLL-Learn.\nIt is known that DLL algorithms with clause learning and restarts can simulate full\n(non-regular, dag-like) resolution by learning every derived clause, and doing a restart\neach time a clause is learned [2]. Our proof systems, regWRTI and DLL-Learn, do not\nhandle restarts; instead, they can be viewed as capturing what can happen between restarts.\nAnother approach to simulating full resolution is via the use of \"proof trace extensions\"\nintroduced by Beame et al. [2]. Proof trace extensions allow resolution to be simulated by\nclause learning DLL algorithms, and a related construction is used by Hertel et al. [16] to\nshow that pool resolution can \"effectively\" p-simulate full resolution. These constructions\nrequire introducing new variables and clauses in a way that does not affect satisfiability,\nbut allow a clause learning DLL algorithm or pool resolution to establish non-satisfiability.\nHowever, the constructions by Beame et al. [2] and the initially circulated preprint of Hertel\net al. [16] had the drawback that the number of extra introduced variables depends on the\nsize of the (unknown) resolution refutation.\nSection 7 introduces an improved form of proof trace extensions called \"variable extensions\". Theorem 7.3 shows that variable extensions can be used to give a p-simulation\nof full resolution by regWRTI (at the cost of changing the formula that is being refuted).\nVariable extensions are simpler and more powerful than proof trace extensions. Their main\nadvantage is that a variable extension depends only on the number of variables, not on\nthe size of the (unknown) resolution proof. The results of Section 7 were first published in\nthe second author's diploma thesis [17]; the subsequently published version of the article\nof Hertel et al. [16] gives a similarly improved construction (for pool resolution) that does\nnot depend on the size of the resolution proof and, in addition, does not use degenerate\nresolution inferences.\n\n\f4\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nOne consequence of Theorem 7.3 is that regWRTI can effectively p-simulate full resolution. This improves on the results of Hertel et al. [16] since regWRTI is not known to\nbe as strong as pool resolution. It remains open whether regWRTI or pool resolution can\np-simulate general resolution without variable extensions.\nSection 8 proves a lower bound that shows that for certain hard formulas, the pigeonhole\nprinciple P HPn , learning only small clauses does not help a DLL-algorithm. We show that\nresolution trees with lemmas require size exponential in n log n to refute P HPn when the\nsize of clauses used as lemmas is restricted to be less than n/2. This bound is asymptotically\nthe same as the lower bound shown for tree-like resolution refutations of P HPn [18]. On the\nother hand, there are regular resolution refutations of P HPn of size exponential in n [7], and\nour results show that these can be simulated by DLL-L-UP. Hence the ability of learning\nlarge clauses can give a DLL-algorithm a superpolynomial speedup over one that learns\nonly short clauses.\n2. Preliminaries\nPropositional logic. Propositional formulas are formed using Boolean connectives \u00ac, \u2227, and\n\u2228. However, this paper works only with formulas in conjunctive normal form, namely\nformulas that can be expressed as a set of clauses. We write x for the negation of x, and x\ndenotes x. A literal l is defined to be either a variable x or a negated variable x. A clause C\nis a finite set of literals, and is interpreted as being the disjunction of its members. The\nempty clause is denoted \u2737. A unit clause is a clause containing a single literal. A set F\nof clauses is interpreted as the conjunction of its clauses, i.e., a conjunctive normal form\nformula (CNF).\nAn assignment \u03b1 is a (partial) mapping from the set of variables to {0, 1}, where we\nidentify 1 with True and 0 with False. The assignment \u03b1 is implicitly extended to assign\nvalues to literals by letting \u03b1(x) = 1 \u2212 \u03b1(x), and the domain, dom(\u03b1), of \u03b1 is the set of\nliterals assigned values by \u03b1. The restriction of a clause C under \u03b1 is the clause\n\uf8f1\nif there is a l \u2208 C with \u03b1(l) = 1\n\uf8f2 1\n0\nif \u03b1(l) = 0 for every l \u2208 C\nC|\u03b1 =\n\uf8f3\n{ l \u2208 C | l 6\u2208 dom(\u03b1) } otherwise\nThe restriction of a set F of clauses under \u03b1 is\n\uf8f1\nif there is a C \u2208 F with C|\u03b1 = 0\n\uf8f2 0\n1\nif C|\u03b1 = 1 for every C \u2208 F\nF |\u03b1 =\n\uf8f3\n{ C|\u03b1 | C \u2208 F } \\ {1} otherwise\n\nIf F |\u03b1 = 1, then we say \u03b1 satisfies F .\nAn assignment is called total if it assigns values to all variables. We call two CNFs F\nand F \u2032 equivalent and write F \u2261 F \u2032 to indicate that F and F \u2032 are satisfied by exactly the\nsame total assignments. Note, however, that F \u2261 F \u2032 does not always imply that they are\nsatisfied by the same partial assignments.\nIf \u01eb \u2208 {0, 1} and x is a variable, we define x\u01eb by letting x0 be x and x1 be x.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n5\n\nResolution. Suppose that C0 and C1 are clauses and x is a variable with x \u2208 C0 and x \u2208 C1 .\nThen the resolution rule can be used to derive the clause C = (C0 \\ {x}) \u222a (C1 \\ {x}). In\nthis case we write C0 , C1 \u22a2x C or just C0 , C1 \u22a2 C.\nA resolution proof of a clause C from a CNF F consists of repeated applications of\nthe resolution rule to derive the clause C from the clauses of F . If C = \u2737, then F is\nunsatisfiable and the proof is called a resolution refutation.\nWe represent resolution proofs either as graphs or as trees. A resolution dag (RD) is\na dag G = (V, E) with labeled edges and vertices satisfying the following properties. Each\nnode is labeled with a clause and a variable, and, in addition, each edge is labeled with a\nliteral. There must be a single node of out-degree zero, labeled with the conclusion clause.\nFurther, all nodes with in-degree zero are labeled with clauses from the initial set F . All\nother nodes must have in-degree two and are labeled with a variable x and a clause C such\nthat C0 , C1 \u22a2x C where C0 and C1 are the labels on the the two immediate predecessor\nnodes and x \u2208 C0 and x \u2208 C1 . The edge from C0 to C is labeled x, and the edge from C1\nto C is labeled x. (The convention that that x \u2208 C0 and x is on the edge from C0 might\nseem strange, but it allows a more natural formulation of Theorem 2.4 below.)\nA resolution dag G is x-regular iff every path in G contains at most one node that is\nlabeled with the variable x. G is regular (or a regRD) if G is x-regular for every x.\nWe define the size of a resolution dag G = (V, E) to be the number |V | of vertices in\nthe dag. Var (G) is the set of variables used as resolution variables in G. Note that if G is\na resolution proof rather than a refutation, then Var (G) may not include all the variables\nthat appear in clause labels of G.\nA resolution tree (RT) is a resolution dag which is tree-like, i.e., a dag in which every\nvertex other then the conclusion clause has out-degree one. A regular resolution tree is\ncalled a regRT for short.\nThe notion of (p-)simulation is an important tool for comparing the strength of proof\nsystems. If Q and R are refutation systems, we say that Q simulates R provided there\nis a polynomial p(n) such that, for every R-refutation of a CNF F of size n there is a\nQ-refutation of F of size \u2264 p(n). If the Q-refutation can be found by a polynomial time\nprocedure, then this called a p-simulation. Two systems that simulate (resp, p-simulate)\neach other are called equivalent (resp, p-equivalent). Some basic prior results for simulations\nof resolution systems include:\nTheorem 2.1.\n(a) [24] Regular tree resolution (regRT) p-simulates tree resolution (RT).\n(b) [14, 1] Regular resolution (regRD) does not simulate resolution (RD).\n(c) [6] Tree resolution (RT) does not simulate regular resolution (regRD).\nWeakening and w-resolution. The weakening rule allows the derivation of any clause C \u2032 \u2287 C\nfrom a clause C. However, instead of using the weakening rule, we introduce a w-resolution\nrule that essentially incorporates weakening into the resolution rule. Given two clauses C0\nand C1 , and a variable x, the w-resolution rule allows one to infer C = (C0 \\{x})\u222a(C1 \\{x}).\nWe denote this condition C0 , C1 \u22a2w\nx C. Note that x \u2208 C0 and x \u2208 C1 are not required for\nthe w-resolution inference.\nWe use the notations WRD, regWRD, WRT, and regWRT for the proof systems\nthat correspond to RD, regRD, RT, and regRT (respectively) but with the resolution rule\n\n\f6\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nreplaced with the w-resolution rule. That is, given a node labeled with C, an edge from C0 to\nC labeled with x\u0304 and an edge from C1 to C labeled with x, we have C = (C0 \\{x})\u222a(C1 \\{x}).\nSimilarly, we use the notations RDW and RTW for the proof systems that correspond to\nRD and RT, but with the general weakening rule added. In an application of the weakening\nrule, the edge connecting a clause C \u2032 \u2287 C with its single predecessor C does not bear any\nlabel.\nThe resolution and weakening rules can certainly p-simulate the w-resolution rule, since\na use of the w-resolution rule can be replaced by weakening inferences that derive C0 \u222a {x}\nfrom C0 and C1 \u222a {x} from C1 , and then a resolution inference that derives C. The converse\nis not true, since w-resolution cannot completely simulate weakening; this is because wresolution cannot introduce completely new variables that do not occur in the input clauses.\nAccording to the well-known subsumption principle, weakening cannot increase the strength\nof resolution though, and the same reasoning implies the same about w-resolution; namely,\nwe have:\nProposition 2.2. Let R be a WRD proof of C from F of size n. Then there is an RD\nproof S of C \u2032 from F of size \u2264 n for some C \u2032 \u2286 C. Furthermore, if R is regular, so is S,\nand if R is a tree, so is S.\nProof. The proof of the theorem is straightforward.\nWriting R as a sequence\nC0 , C1 , . . . , Cn = C, define clauses Ci\u2032 \u2286 Ci by induction on i so that the new clauses\nform the desired proof S. For Ci \u2208 F , let Ci\u2032 = Ci . Otherwise Ci is inferred by w-resolution\nfrom Cj and Ck w.r.t. a variable x. If x \u2208 Cj and x \u2208 Ck , let Ci\u2032 be the resolvent of Cj\u2032\n/ Cj\u2032 , or Ck\u2032\nand Ck\u2032 as obtained by the usual resolution rule; if not, then let Ci\u2032 be Cj\u2032 if x \u2208\n/ Ck\u2032 . It is easy to check that each Ci\u2032 \u2286 Ci and that, after removing duplicate clauses,\nif x \u2208\nthe clauses Cj\u2032 form a valid resolution proof S. If R is regular, then so is S, and if R is a\ntree so is S.\nEssentially the same proof shows the same property for the system with the full\nweakening rule:\nProposition 2.3. Let R be a RDW proof of C from F of size s. Then there is an RD\nproof S of C \u2032 from F of size \u2264 s for some C \u2032 \u2286 C. Furthermore, if R is regular, so is S,\nand if R is a tree, so is S.\nThere are several reasons why we prefer to work with w-resolution, rather than with\nthe weakening rule. First, we find it to be an elegant way to combine weakening with\nresolution. Second, it works well for using resolution trees (with input lemmas, see the next\nsection) to simulate DLL search algorithms. Third, since weakening and resolution together\nare stronger than w-resolution, w-resolution is a more refined restriction on resolution.\nFourth, for regular resolution, using w-resolution instead of general weakening can be a\nquite restrictive condition, since any w-resolution inference C0 , C1 \u22a2w\nx C \"uses up\" the\nvariable x, making it unavailable for other resolution inferences on the same path, even if\nthe variable does not occur at all in C0 and C1 . The last two reasons mean that w-resolution\ncan be rather weak; this strengthens our results below (Theorems 5.1 and 5.3) about the\nexistence of regular proofs that use w-resolution.\nThe following simple theorem gives some useful properties for regular w-resolution.\nTheorem 2.4. Let G be a regular w-resolution refutation. Let C be a clause in G.\n(a) Suppose that C is derived from C0 and C1 with the edge from C0 (resp. C1 ) to C labeled\n/ C0 , and x \u2208\n/ C1 .\nwith x (resp. x). Then x \u2208\n\n\fRESOLUTION TREES WITH LEMMAS\n\n7\n\n(b) Let \u03b1 be an assignment such that for every literal l labeling an edge on the path from C\nto the final clause, \u03b1(l) = T rue. Then C|\u03b1 = 0.\nProof. The proof of part a. is based on the observation that if x \u2208 C0 , then also x \u2208 C.\nHowever, by the regularity of the resolution refutation, every clause on the path from C to\n/ \u2737.\nthe final clause \u2737 must contain x. But clearly x \u2208\nPart b. is a well-known fact for regular resolution proofs. It holds for similar reasons\nfor regular w-resolution proofs: the proof proceeds by induction on clauses in the proof,\nstarting at the final clause \u2737 and moving up towards the leaves. Part a. makes the induction\nstep trivial.\nDirected acyclic graphs. We define some basic concepts that will be useful for analyzing\nboth resolution proofs and conflict graphs (which are defined below in Section 4). Let\nG = (V, E) be a dag. The set of leaves (nodes in V of in-degree 0) of G is denoted VG0 . The\ndepth of a node u in V is defined to equal the maximum number of edges on any path from\na leaf of G to the node u. Hence leaves have depth 0. The subgraph rooted at u in G is\ndenoted Gu ; its nodes are the nodes v for which there is a path from v to u in G, and its\nedges are the induced edges of G.\n3. w-resolution trees with lemmas\nThis section first gives an alternate characterization of resolution dags by using resolution trees with lemmas. We then refine the notion of lemmas to allow only input lemmas.\nFor non-regular derivations, resolution trees with lemmas and resolution trees with input\nlemmas are both proved below to be p-equivalent to resolution. However, for regular proofs,\nthe notions are apparently different. (In fact we give an exponential separation between\nregular resolution and regular w-resolution trees with input lemmas.) Later in the paper\nwe will give a tight correspondence between resolution trees with input lemmas and DLL\nsearch algorithms.\nThe intuition for the definition of a resolution tree with lemmas is to allow any clause\nproved earlier in the resolution tree to be reused as a leaf clause. More formally, assume we\nare given a resolution proof tree T , and further assume T is ordered in that each internal\nnode has a left child and a right child. We define <T to be the post-ordering of T , namely,\nthe linear ordering of the nodes of T such that if u is a node in T and v is in the subtree\nrooted at u's left child, and w is in the subtree rooted at u's right child, then v <T w <T u.\nFor F a set of clauses, a resolution tree with lemmas (RTL) proof from F is an ordered\nbinary tree such that (1) each leaf node v is labeled with either a member of F or with\na clause that labels some node u <T v, and (2) each internal node v is labeled with a\nvariable x and a clause C, such that C is inferred by resolution w.r.t. x from the clauses\nlabeling the two children of v, and (3) the unique out-degree zero node is labeled with the\nconclusion clause D. If D = \u2737, then the RTL proof is a refutation.\nw-resolution trees with lemmas (WRTL) are defined just like RTL's, but allowing wresolution in place of resolution, and resolution trees with lemmas and weakening (RTLW)\nare defined in the same way, but allowing the weakening rule in addition to resolution.\nAn RTL or WRTL proof is regular provided that no path in the proof tree contains\nmore than one (w-)resolution using a given variable x. Note that paths follow the tree edges\nonly; any maximal path starts at a leaf node (possibly a lemma) and ends at the conclusion.\n\n\f8\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nIt is not hard to see that resolution trees with lemmas (RTL) and resolution dags (RD)\np-simulate each other. Namely, an RD can be converted into an RTL by doing a depth-first,\nleftmost traversal of the RD. In addition, it is clear that regular RTL's p-simulate regular\nRD's. The converse is open, and it is false for regular WRTL, as we prove in Section 5:\nintuitively, the problem is that when one converts an RTL proof into an RD, new path\nconnections are created when leaf clauses are replaced with edges back to the node where\nthe lemma was derived.\nWe next define resolution trees with input lemma (RTI) proofs. These are a restricted\nversion of resolution trees with lemmas, where the lemmas are required to have been derived\nearlier in the proof by input proofs. Input proofs have also been called trivial proofs by\nBeame et al. [2], and they are useful for characterizing the clause learning permissible for\nDLL algorithms.\nDefinition 3.1. An input resolution tree is a resolution tree such that every internal node\nhas at least one child that is a leaf. Let v be a node in a tree T and let Tv be the subtree\nof T with root v. The node v is called an input-derived node if Tv is an input resolution\ntree.\nOften the node v and its label C are identified. In this case, C is called an input-derived\nclause. In RTI proofs, input-derived clauses may be reused as lemmas. Thus, in an RTI\nproof, an input-derived clause is derived by an input proof whose leaves either are initial\nclauses or are clauses that were already input-derived.\nDefinition 3.2. A resolution tree with input lemmas (RTI) proof T is an RTL proof with\nthe extra condition that every lemma in T must appear earlier in T as an input-derived\nclause. That is to say, every leaf node u in T is labeled either with an initial clause from F\nor with a clause that labels some input-derived node v <T u.\nThe notions of w-resolution trees with input lemmas (WRTI), regular resolution trees\nwith input lemmas (regRTI), and regular w-resolution trees with input lemmas (regWRTI)\nare defined similarly.1\nIt is clear that the resolution dags (RD) and resolution trees with lemmas (RTL) psimulate resolution trees with input lemmas (RTI). Somewhat surprisingly, the next theorem\nshows that the converse p-simulation holds as well.\nTheorem 3.3. Let G be a resolution dag of size s for the clause C from the set F of clauses.\nLet d be the depth of C in G. Then there is an RTI proof T for C from F of size < 2sd. If\nG is regular then T is also regular.\nProof. The dag proof G can be unfolded into a proof tree T \u2032 , possibly exponentially bigger.\nThe proof idea is to prune clauses away from T \u2032 leaving a RTI proof T of the desired size.\nWithout loss of generality, no clause appears more than once in G; hence, for a given\nclause C in the tree T \u2032 , every occurrence of C in T \u2032 is derived by the same subproof TC\u2032 .\nLet dC be the depth of C in the proof, i.e., the height of the tree TC\u2032 . Clauses at leaves have\ndepth 0. We give the proof tree T \u2032 an arbitrary left-to-right order, so that it makes sense\nto talk about the i-th occurrence of a clause C in T \u2032 .\n1A small, but important point is that w-resolution inferences are not allowed in input proofs, even for\n\ninput proofs that are part of WRTI proofs. We have chosen the definition of input proofs so as to make\nthe results in Section 5 hold that show the equivalence between regWRTI proofs and DLL-L-UP search\nalgorithms. Although similar results could be obtained if the definition of input proof were changed to allow\nw-resolution inferences, it would require also using a modified, and less natural, version of clause learning.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n9\n\nWe define the j-th occurrence of a clause C in T \u2032 to be leafable, provided j > dC . The\nintuition is that the leafable clauses will have been proved as a input clause earlier in T ,\nand thus any leafable clause may be used as a lemma in T .\nTo form T from T \u2032 , remove from T \u2032 any clause D if it has a successor that is leafable,\nso that every leafable occurrence of a clause either does not appear in T or appears in T\nas a leaf. To prove that T is a valid RTI proof, it suffices to prove, by induction on i, that\nif C has depth dC = i > 0, then the i-th occurrence of C is input-derived in T . Note that\nthe two children C0 and C1 of C must have depth < dC . Since every occurrence of C is\nderived from the same two clauses, these occurrences of C0 and C1 must be at least their i-th\noccurrences. Therefore, by the induction hypothesis, the children C0 and C1 are leafable\nand appear in T as leaves. Thus, since it is derived by a single inference from two leaves,\nthe i-th occurrence of C is input-derived.\nIt follows that T is a valid RTI proof. If the proof G was regular, clearly T is regular\ntoo.\nTo prove the size bound for T , note that G has at most s \u2212 1 internal nodes. Each one\noccurs at most d times as an internal node in T , so T has at most d(s \u2212 1) internal nodes.\nThus, T has at most 2d * (s \u2212 1) + 1 < 2sd nodes in all.\nThe following two theorems summarize the relationships between our various proof\nsystems. We write R \u2261 Q to denote that R and Q are p-equivalent, and Q \u2264 R to denote\nthat R p-simulates Q. The notation Q < R means that R p-simulates Q but Q does not\nsimulate R.\nTheorem 3.4. RD \u2261 WRD \u2261 RTI \u2261 WRTI \u2261 RTL \u2261 WRTL\nProof. The p-equivalences RD \u2261 WRD and RTI \u2261 WRTI and RTL \u2261 WRTL are shown\nby (the proof of) Proposition 2.2. The simulations RTI \u2264 RTL \u2261 RD are straightforward.\nFinally, RD \u2264 RTI is shown by Theorem 3.3.\nFor regular resolution, we have the following theorem.\nTheorem 3.5. regRD \u2261 regWRD \u2264 regRTI \u2264 regRTL \u2264 regWRTL \u2264 RD and regRTI \u2264\nregWRTI \u2264 regWRTL.\nProof. regRD \u2261 regWRD and regWRTL \u2264 RD follow from the definitions and the\nproof of Proposition 2.2. The p-simulations regRTI \u2264 regRTL \u2264 regWRTL and\nregRTI \u2264 regWRTI \u2264 regWRTL follow from the definitions.\nThe p-simulation\nregRD \u2264 regRTI is shown by Theorem 3.3.\nBelow, we prove, as Theorem 5.4, that regRD < regWRTI. This is the only separation\nin the hierarchy that is known. In particular, it is open whether regRD < regRTI, regRTI <\nregRTL, regRTL < regWRTL, regWRTL < RD or regWRTI < regWRTL hold. It is also\nopen whether regWRTI and regRTL are comparable.\n4. DLL algorithms with clause learning\n4.1. The basic DLL algorithm. The DLL proof search algorithm is named after the\nauthors Davis, Logeman and Loveland of the paper where it was introduced [9]. Since they\nbuilt on the work of Davis and Putnam [10], the algorithm is sometimes called the DPLL\nalgorithm. There are several variations on the DLL algorithm, but the basic algorithm\n\n\f10\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nis shown in Figure 1. The input is a set F of clauses, and a partial assignment \u03b1. The\nassignment \u03b1 is a set of ordered pairs (x, \u01eb), where \u01eb \u2208 {0, 1}, indicating that \u03b1(x) = \u01eb.\nThe DLL algorithm is implemented as a recursive procedure and returns either UNSAT if F\nis unsatisfiable or otherwise a satisfying assignment for F .\nDLL(F, \u03b1)\n1\nif F |\u03b1 = 0 then\n2\nreturn UNSAT\n3\nif F |\u03b1 = 1 then\n4\nreturn \u03b1\n5\nchoose x \u2208 Var (F |\u03b1 ) and \u01eb \u2208 {0, 1}\n6\n\u03b2 \u2190DLL(F, \u03b1 \u222a {(x, \u01eb)})\n7\nif \u03b2 6= UNSAT then\n8\nreturn \u03b2\n9\nelse\n10\nreturn DLL(F, \u03b1 \u222a {(x, 1 \u2212 \u01eb)})\n\nFigure 1: The basic DLL algorithm.\nNote that the DLL algorithm is not fully specified, since line 5 does not specify how\nto choose the branching variable x and its value \u01eb. Rather one can think of the algorithm\neither as being nondeterministic or as being an algorithm schema. We prefer to think of the\nalgorithm as an algorithm schema, so that it incorporates a variety of possible algorithms.\nIndeed, there has been extensive research into how to choose the branching variable and its\nvalue [12, 22].\nThere is a well-known close connection between regular resolution and DLL algorithms.\nIn particular, a run of DLL can be viewed as a regular resolution tree, and vice-versa. This\ncan be formalized by the following two propositions.\nProposition 4.1. Let F be an unsatisfiable set of clauses and \u03b1 an assignment. If there\nis an execution of DLL(F, \u03b1) that returns UNSAT and performs s recursive calls, then there\nexists a clause C with C|\u03b1 = 0 such that C has a regular resolution tree T from F with\n|T | \u2264 s + 1 and Var (T ) \u2229 dom(\u03b1) = \u2205.\nThe converse simulation of Proposition 4.1 holds, too, that is, a regular resolution tree\ncan be transformed directly in a run of DLL.\nProposition 4.2. Let F be an unsatisfiable set of clauses. Suppose that C has a regular\nresolution proof tree T of size s from F . Let \u03b1 be an assignment with C|\u03b1 = 0 and Var (T ) \u2229\ndom(\u03b1) = \u2205. Then there is an execution of DLL(F, \u03b1), that returns UNSAT after at most\ns \u2212 1 recursive calls.\nThe two propositions are based on the following correspondence between resolution\ntrees and a DLL search tree: first, a leaf clause in a resolution tree corresponds to a\nclause falsified by \u03b1 (so that F |\u03b1 = 0), and second, a resolution inference with respect to\na variable x corresponds to the use of x as a branching variable in the DLL algorithm.\nTogether the two propositions give the following well-known exact correspondence between\nregular resolution trees and DLL search.\nTheorem 4.3. If F is unsatisfiable, then there is an execution of DLL(F, \u2205) that executes\nwith < s recursive calls if and only if there exists a regular refutation tree for F of size \u2264 s.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n11\n\n4.2. Learning by unit propagation. Two of the most successful enhancements of DLL\nthat are used by most modern SAT solvers are unit propagation and clause learning. Unit\nclause propagation (also called Boolean constraint propagation) was already part of the\noriginal DLL algorithm and is based on the following observation: If \u03b1 is a partial assignment\nfor a set of clauses F and if there is a clause C \u2208 F with C|\u03b1 = {l} a unit clause, then any\n\u03b2 \u2283 \u03b1 that satisfies F must assign l the value True.\nThere are a couple of methods that the DLL algorithm can use to implement unit\npropagation. One method is to just use unit propagation to guide the choice of a branching\nvariable by modifying line 5 so that, if there is a unit clause in F |\u03b1 , then x and \u01eb are\nchosen to make the literal true. More commonly though, DLL algorithms incorporate unit\npropagation as a separate phase during which the assignment \u03b1 is iteratively extended to\nmake any unit clause true until there are no unit clauses remaining. As the unit propagation\nis performed, the DLL algorithm keeps track of which variables were set by unit propagation\nand which clause was used as the basis for the unit propagation. This information is then\nuseful for clause learning.\nClause learning in DLL algorithms was first introduced by Silva and Sakallah [23] and\nmeans that new clauses are effectively added to F . A learned clause D must be implied\nby F , so that adding D to F does not change the space of satisfying assignments. In theory,\nthere are many potential methods for clause learning; however, in practice, the only useful\nmethod for learning clauses is based on unit propagation as in the original proposal [23].\nIn fact, all deterministic state of the art SAT solvers for structured (non-random) instances\nof SAT are based on clause learning via unit propagation. This includes solvers such as\nChaff [21], Zchaff [20] and MiniSAT [11].\nThese DLL algorithms apply clause learning when the set F is falsified by the current\nassignment \u03b1. Intuitively, they analyze the reason some clause C in F is falsified and use\nthis reason to infer a clause D from F to be learned. There are two ways in which a\nDLL algorithm assigns values to variables, namely, by unit propagation and by setting a\nbranching variable. However, if unit propagation is fully carried out, then the first time\na clause is falsified is during unit propagation. In particular, this happens when there are\ntwo unit clauses C1 |\u03b1 = {x} and C2 |\u03b1 = {x} requiring a variable x to be set both True and\nFalse. This is called a conflict.\nThe reason for a conflict is analyzed by building a conflict graph. Generally, this is\ndone by maintaining an unit propagation graph that tracks, for each variable which has\nbeen assigned a value, the reason that implies the setting of the variable. The two possible\nreasons are that either (a) the variable was set by unit propagation when a particular\nclause C became a unit clause, in which case C is the reason, or (b) the variable was set\narbitrarily as a branching variable. The unit propagation graph G has literals as its nodes.\nThe leaves of G are literals that were set true as branching variables, and the internal nodes\nare variables that were set true by unit propagation. If a literal l is an internal node in G,\nthen it was set true by unit propagation applied to some clause C. In this case, for each\nliteral l\u2032 6= l in C, l\u2032 is a node in G and there is an edge from l\u2032 to l. If the unit propagation\ngraph contains a conflict it is called a conflict graph. More formally, a conflict graph is\ndefined as follows.\nDefinition 4.4. A conflict graph G for a set F of clauses under the assignment \u03b1 is a dag\nG = (V \u222a {\u2737}, E) where V is a set of literals and where the following hold:\n\n\f12\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\n(a) For each l \u2208 V , either (i) l has in-degree 0 and \u03b1(l) = 1, or (ii) there is a clause C \u2208 F\nsuch that C = {l} \u222a {l\u2032 : (l\u2032 , l) \u2208 E}. For a fixed conflict graph G, we denote this clause\nas Cl .\n(b) There is a unique variable x such that V \u2287 {x, x}.\n(c) The node \u2737 has only the two incoming edges (x, \u2737) and (x, \u2737).\n(d) The node \u2737 is the only node with outdegree zero.\nLet VG0 denote the nodes in G of in-degree zero. Then, letting \u03b1G = {(x, \u01eb) : x\u01eb \u2208\nthe conflict graph G shows that every vertex l must be made true by any satisfying\nassignment for F that extends \u03b1. Since for some x, both x and x are nodes of G, this\nimplies \u03b1 cannot be extended to a satisfying assignment for F . Therefore, the clause\nD = {l : l \u2208 VG0 } is implied by F , and D can be taken as a learned clause. We call this\nclause D the conflict clause of G and denote it CC(G).\nThere is a second type of clause that can be learned from the conflict graph G in addition\nto the conflict clause CC(G). Namely, let l 6= \u2737 be any non-leaf node in G. Further, let\nVG0l be the set of leaves l\u2032 of G such that there is a path from l\u2032 to l. Then, the clauses\nin F imply that if all the leaves l\u2032 \u2208 VG0l are assigned true, then l is assigned true. Thus,\nthe clause D = {l} \u222a {l\u2032 : l\u2032 \u2208 VG0l } is implied by F and can be taken as a learned clause.\nThis clause D is called the induced clause of Gl and is denoted IC(l, G). In the degenerate\ncase where Gl consists of only the single literal l, this would make IC(l, G) equal to {l, l};\nrather than permit this as a clause, we instead say that the induced clause does not exist.\nIn practice, both conflict clauses CC(G) and induced clauses IC(l, G) are used by\nSAT solvers. It appears that most SAT solvers learn the first-UIP clauses [23], which\nequal CC(G) and IC(l, G\u2032 ) for appropriately formulated G and G\u2032 . Other conflict clauses\nthat can be learned include all-UIP clauses [26], rel-sat clauses [19], decision clauses [26],\nand first cut clauses [2]. All of these are conflict clauses CC(G) for appropriate G. Less\ncommonly, multiple clauses are learned, including clauses based on the cuts advocated by\nthe mentioned works [23, 26], which are a type of induced clauses.\nIn order to prove the correspondence in Section 5 between DLL with clause learning\nand regWRTI proofs, we must put some restrictions on the kinds of clauses that can be\n(simultaneously) learned. In essence, the point is that for DLL with clause learning to\nsimulate regWRTI proofs it is necessary to learn multiple clauses at once in order to learn\nall the clauses in a regular input subproof. But on the other hand, for regWRTI to simulate\nDLL with clause learning, regWRTI must be able to include regular input proofs that derive\nall the learned clauses so as to have them available for subsequent use as input lemmas.\nThus, we define a notion of \"compatible clauses\" which is a set of clauses that can be\nsimultaneously learned. For this, we define the notion of a series-parallel decomposition of\na conflict graph G.\nVG0 },\n\nDefinition 4.5. A graph H = (W, E \u2032 ) is a subconflict graph of the conflict graph G = (V, E)\nprovided that H is a conflict graph with W \u2286 V and E \u2032 \u2286 E, and that each non-leaf vertex\nof H (that is, each vertex in W \\ VH0 ) has the same in-degree in H as in G.\nH is a proper subconflict graph of G provided there is no path in G from any non-leaf\nvertex of H to a vertex in VH0 .\nNote that if l is a non-leaf vertex in the subconflict graph H of G, then the clause Cl\nis the same whether it is defined with respect to H or with respect to G.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n13\n\nDefinition 4.6. Let G be a conflict graph. A decomposition of G is a sequence H0 \u2282 H1 \u2282\n* * * \u2282 Hk , k \u2265 1, of distinct proper subconflict graphs of G such that Hk = G and H0 is the\ndag on the three nodes \u2737 and its two predecessors x and x.\nA decomposition of G will be used to describe sets of clauses that can be simultaneously\nlearned. For this, we put a structure on the decomposition that describes the exact types\nof clauses that can be learned:\nDefinition 4.7. A series-parallel decomposition H of G consists of a decomposition\nH0 , . . . , Hk plus, for each 0 \u2264 i < k, a sequence Hi = Hi,0 \u2282 Hi,1 \u2282 * * * \u2282 Hi,mi = Hi+1 of\nproper subconflict graphs of G. Note that the sequence\nH0 = H0,0 , H0,1 , H0,2 , . . . , H0,m0 = H1 = H1,0 , H1,1 , . . . , Hk\u22121,mk\u22121 = Hk\nis itself a decomposition of G. However, we prefer to view it as a two-level decomposition.\nA series decomposition is a series-parallel decomposition with trivial parallel part, i.e., with\nk = 1. A parallel decomposition is series-parallel decomposition in which mi = 1 for all i.\nNote that we always have Hi 6= Hi+1 and Hi,j 6= Hi,j+1 .\nFigure 2 illustrates a series-parallel decomposition.\nDefinition 4.8. For H a series-parallel decomposition, the set of learnable clauses, CC(H),\nfor H consists of the following induced clauses and conflict clauses:\n\u2022 For each 1 \u2264 j \u2264 m0 , the conflict clause CC(H0,j ), and\n\u2022 For each 0 < i < k and 0 < j \u2264 mi and each l \u2208 VH0 i \\VH0i,j , the induced clause IC(l, Hi,j ).\nIt should be noted that the definition of the parallel decomposition incorporates the\nnotion of \"cut\" used by Silva and Sakallah [23]. The DLL algorithm shown in Figure 3\nchooses a single series-parallel decomposition H and learns some subset of the learnable\nclauses in CC(H). It is clear that this generalizes all of the clause learning algorithms\nmentioned above.\nThe algorithm schema DLL-L-UP that is given in Figure 3 is a modification of the\nschema DLL. In addition to returning a satisfying assignment or UNSAT, it returns a modified\nformula that might include learned clauses. If F is a set of clauses and \u03b1 is an assignment\nthen DLL-L-UP(F, \u03b1) returns (F \u2032 , \u03b1\u2032 ) such that F \u2032 \u2287 F and F \u2032 is equivalent to F and\nsuch that \u03b1\u2032 either is UNSAT or is a satisfying assignment for F .2\nThe DLL-L-UP algorithm as shown in Figure 3 does not explicitly include unit\npropagation. Rather, the use of unit propagation is hidden in the test on line 2 of whether\nunit propagation can be used to find a conflict graph. In practice, of course, most algorithms\nset variables by unit propagation as soon as possible and update the implication graph each\ntime a new unit variable is set. The algorithm as formulated in Figure 3 is more general,\nand thus covers more possible implementations of DLL-L-UP, including algorithms that\nmay change the implication graph retroactively or may pick among several conflict graphs\ndepending on the details of how F can be falsified. There is at least one implemented clause\nlearning algorithm that does this [13].\n2 Our definition of DLL-L-UP is slightly different from the version of the algorithm as originally defined\nin Hoffmann's thesis [17]. The first main difference is that we use series-parallel decompositions rather the\ncompatible set of subconflict graphs of Hoffmann [17]. The second difference is that our algorithm does\nnot build the implication graph incrementally by the use of explicit unit propagation; instead, it builds the\nimplication graph once a conflict has been found.\n\n\f14\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nH3 = H2,1\nm\n\nl\nj\n\nLearnable clauses\n{l, h}\n{l, m, i}\n\nk\ni\n\nh\n\ng\n\nf\n\nH2 = H1,3 = H2,0\nH1,2\n\n{h, i, e}\n{f , i, e}\n\nH1,1\n\n{f , g, e}\n\nH1 = H0,3 = H1,0\ne\nd\nb\n\nc\n\n{e}\n\nH0,2\n\n{b, d}\n\nH0,1\n\n{b, c}\n\nH0 = H0,0\n\na\n\na\n\u2737\n\nFigure 2: A series-parallel decomposition. Solid lines define the sets Hi of the parallel part\nof the decomposition, and dotted lines define the sets Hi,j in the series part. Each\nline (solid or dotted) defines the set of nodes that lie below the line. The learnable\nclauses associated with each set are shown in the right column.\nDLL-L-UP(F, \u03b1)\n1\nif F |\u03b1 = 1 then return (F, \u03b1)\n2\nif there is a conflict graph for F under \u03b1 then\n3\nchoose a conflict graph G for F under \u03b1\n4\nand a series-parallel decomposition H of G\n5\nchoose a subset S of CC(H) -- the learned clauses\n6\nreturn (F \u222a S, UNSAT)\n7\nchoose x \u2208 Var (F |\u03b1 ) and \u01eb \u2208 {0, 1}\n8\n(G, \u03b2)\u2190DLL-L-UP(F, \u03b1 \u222a {(x, \u01eb)})\n9\nif \u03b2 6= UNSAT then\n10\nreturn (G, \u03b2)\n11\nreturn DLL-L-UP(G, \u03b1 \u222a {(x, 1 \u2212 \u01eb)})\n\nFigure 3: DLL with Clause Learning.\nAs shown in Figure 3, if F |\u03b1 is false, then the algorithm must return UNSAT (lines\n2-6). Sometimes, however, we use instead a \"non-greedy\" version of DLL-L-UP. For the\nnon-greedy version it is optional for the algorithm to immediately return UNSAT once F has\na conflict graph. Thus the non-greedy DLL-L-UP algorithm can set a branching variable\n(lines 7-11) even if F has already been falsified and even if there are unit clauses present.\nThis non-greedy version of DLL-L-UP will be used in the next section to simulate regWRTI\nproofs.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n15\n\nThe constructions of Section 5 also imply that DLL-L-UP is p-equivalent to the\nrestriction of DLL-L-UP in which only series decompositions are allowed. That is to\nsay, DLL-L-UP with only series decompositions can simulate any run of DLL-L-UP with\nat most polynomially many more recursive calls.\n5. Equivalence of regWRTI and DLL-L-UP\n5.1. regWRTI simulates DLL-L-UP. We shall prove that regular WRTI proofs are\nequivalent to non-greedy DLL-L-UP searches. We start by showing that every DLL-L-UP\nsearch can be converted into a regWRTI proof. As a first step, we prove that, for a given\nseries-parallel decomposition H of a conflict graph, there is a single regWRTI proof T such\nthat every learnable clause of H appears as an input-derived clause in T . Furthermore, T is\npolynomial size; in fact, T has size at most quadratic in the number of distinct variables\nthat appear in the conflict graph.\nThis theorem generalizes earlier, well-known results of Chang [8] and Beame et al. [2]\nthat any individual learned clause can be derived by input resolution (or, more specifically,\nthat unit resolution is equivalent to input resolution). The theorem states a similar fact\nabout proving an entire set of learnable clauses simultaneously.\nTheorem 5.1. Let G be a conflict graph of size n for F under the assignment \u03b1. Let H be\na series-parallel decomposition for G. Then there is a regWRTI proof T of size \u2264 n2 such\nthat every learnable clause of H is an input-derived clause in T . The final clause of T is\nequal to CC(G). Furthermore, T uses as resolution variables, only variables that are used\nas nodes (possibly negated) in G \\ VG0 .\nFirst we prove a lemma. Let the subconflict graphs H0 \u2282 H1 \u2282 * * * \u2282 Hk and H0,0 \u2282\nH0,1 \u2282 * * * \u2282 Hk\u22121,mk\u22121 be as in the definition of series-parallel decomposition.\nLemma 5.2.\n(a) There is an input proof T0 from F which contains every conflict clause CC(H0,j ), for\nj = 1, . . . , m0 . Every resolution variable in T0 is a non-leaf node (possibly negated)\nin H1 .\n(b) Suppose that 1 \u2264 i < k and u is a literal in VH0 i . Then there is an input proof Tiu which\ncontains every (existing) induced clause IC(u, Hi,j ) for j = 1, . . . , mi . Every resolution\nvariable in Tiu is a non-leaf node (possibly negated) in the subgraph (Hi+1 )u of Hi+1\nrooted at u.\nProof. We prove part a. of the lemma and then indicate the minor modifications needed to\nprove part b. The construction of T0 proceeds by induction on j to build proofs T0,j ; at the\nend, T0 is set equal to T0,m0 . Each proof T0,j ends with the clause CC(H0,j ) and contains\nthe earlier proof T0,j\u22121 as a subproof. In addition, the only variables used as resolution\nvariables in T0,j are variables that are non-leaf nodes (possibly negated) in H0,j .\nTo prove the base case j = 1, we must show that CC(H0,1 ) has an input proof T0,1 .\nLet the two immediate predecessors of \u2737 in G be the literals x and x. Define a clause C\nas follows. If x is not a leaf in H0,1 , then we let C = Cx ; recall that Cx is the clause\nthat contains the literal x and the negations of literals that are immediate predecessors\nof x in the conflict graph. Otherwise, since H0,1 6= H0 , x is not a leaf in H0,1 , and we let\nC = Cx . By inspection, C has the property that it contains only negations of literals that\n\n\f16\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nare in H0,1 . For l \u2208 C, define the {0, 1}-depth of l as the maximum length of a path to l\nfrom a leaf of H0,1 . If all literals in C have {0, 1}-depth equal to zero, then C = CC(H0,1 ),\nand C certainly has an input proof from F (in fact, since C = Cx or C = Cx , we must have\nC \u2208 F ).\nSuppose on the other hand, that C is a subset of the nodes of H0,1 with some literals\nof non-zero {0, 1}-depth. Choose a literal l in C of maximum {0, 1}-depth d and resolve\nC with the clause Cl \u2208 F to obtain a new clause C \u2032 . Since Cl \u2208 F , the resolution step\nintroducing C \u2032 preserves the property of having an input proof from F . Furthermore, the\nnew literals in C \u2032 \\ C have {0, 1}-depth strictly less than d. Redefine C to be the just\nconstructed clause C \u2032 . If this new C is a subset of CC(H0,1 ) we are done constructing C.\nOtherwise, some literal in C has non-zero {0, 1}-depth. In this latter case, we repeat\nthe above construction to obtain a new C, and continue iterating this process until we\nobtain C \u2282 CC(H0,1 ).\nWhen the above construction is finished, C is constructed as a clause with a regular\ninput proof T0,1 from F (the regularity follows by the fact that variables introduced in C \u2032\nhave {0, 1} depth less than that of the resolved-upon variable). Furthermore C \u2282 CC(H0,1 ).\nIn fact, C = CC(H0,1 ) must hold, because there is a path, in H0,1 , from each leaf of H0,1\nto \u2737. That completes the proof of the j = 1 base case.\nFor the induction step, with j > 1, the induction hypothesis is that we have constructed\nan input proof T0,j such that T0,j contains all the clauses CC(H0,p ) for 1 \u2264 p \u2264 j and such\nthat the final clause in T0,j is the clause CC(H0,j ). We are seeking to extend this input proof\nto an input proof T0,j+1 that ends with the clause CC(H0,j+1). The construction of T0,j+1\nproceeds exactly like the construction above of T0,1 , but now we start with the clause\nC = CC(H0,j ) (instead of C = Cx or Cx ), and we update C by choosing the literal l \u2208 C\nof maximum {0, j + 1}-depth and resolving with Cl to derive the next C. The rest of the\nconstruction of T0,j+1 is similar to the previous argument. For the regularity of the proof\nit is essential that H0,j is a proper subconflict graph of H0,j+1 . By inspection, any literal l\nused for resolution in the new part of T0,j+1 is a non-leaf node in H0,j+1 and has a path\nfrom l to some leaf node of H0,j . Since H0,j is proper, it follows that l is not an inner node\nof H0,j and thus is not used as a resolution literal in T0,j . Thus H0,j+1 is regular. This\ncompletes the proof of part a.\nThe proof for part b. is very similar to the proof for part a. Fixing i > 0, let u be any\nu from F such\nliteral in VH0i,0 . We need to prove, for 1 \u2264 j \u2264 mi , there is an input proof Ti,j\nu\nu\nthat (a) Ti,j contains every existing induced clause IC(u, Hi,k ) for 1 \u2264 k < j, and (b) Ti,j\nu are\nends with the induced clause IC(u, Hi,j ), and (c) the resolution variables used in Ti,j\nall non-leaf nodes (possibly negated) of V(Hi,j )u . The proof is by induction on j. One\nu\nu is to\nstarts with the clause C = Cu . The main step of the construction of Ti,j+1\nfrom Ti,j\nfind the literal v 6= u in C of maximum {i, j}-depth, and resolve C with Cv to obtain the\nnext C. This process proceeds iteratively exactly like the construction used for part a. This\ncompletes the proof of Lemma 5.2.\nWe now can prove Theorem 5.1. Lemma 5.2 constructed separate regular input\nu\nresolution proofs T0,m0 = T0 and Ti,m\n= Tiu that included all the learnable clauses of H.\ni\nTo complete the proof of Theorem 5.1, we combine all these proofs into one single regWRTI\n\u2217\nproof. For this, we construct proofs Ti\u2217 of the clause CC(Hi ). T1\u2217 is just T0 . The proof Ti+1\nis constructed from Ti\u2217 by successively resolving the final clause of Ti\u2217 with the final clauses\nof the proofs Tiu , using each u \u2208 VH0 i \\ VH0 i+1 as a resolution variable, taking the u's in\n\n\fRESOLUTION TREES WITH LEMMAS\n\n17\n\norder of increasing {i, mi }-depth to preserve regularity. Letting T = Tk\u2217 , it is clear that\nTk\u2217 contains all the clauses from CC(H), and, by construction, Tk\u2217 is regular.\nTo bound the size of T , note that any regular input proof S has size 2r + 1 where r is\nthe number of distinct variables used as resolution variables in S. Since T is regular, and is\nformed by combining the regular input proofs T0 , Tiu in a linear fashion, the total size of T\nPn\u22121\nis less than n + k=0\n(2k + 1) = n2 + 1. This completes the proof of Theorem 5.1.\n\u2737\n0\nNote that, since the final clause of T contains only literals from VG , T does not use any\nvariable that occurs in its final clause as a resolution variable.\nWe can now prove the first main result of this section, namely, that regWRTI proofs\npolynomially simulate DLL-L-UP search trees.\nTheorem 5.3. Suppose that F is an unsatisfiable set of clauses and that there is an\nexecution of a (possibly non-greedy) DLL-L-UP search algorithm on input F that outputs\nUNSAT with s recursive calls. Then there is a regWRTI refutation of F of size at most s * n2\nwhere n = |Var (F )|.\nProof. Let S be the search tree associated with the DLL-L-UP algorithm's execution. We\norder S so that the DLL-L-UP algorithm effectively traverses S in a depth-first, left-to-right\norder. We transform S into a regWRTI proof tree T as follows. The tree T contains a copy\nof S, but adds subproofs at the leaves of S (these subproofs will be derivations of learned\nclauses). For each internal node in S, if the corresponding branching variable was x and was\nfirst set to the value x\u01eb , then the corresponding node in T is labeled with x as the resolution\nvariable, and its left incoming edge is labeled with x\u01eb and its right incoming edge is labeled\nwith x1\u2212\u01eb . For each node u in S, let \u03b1u be the assignment at that node that is held by\nthe DLL-L-UP algorithm upon reaching that node. By construction, \u03b1u is equivalently\ndefined as the assignment that has \u03b1u (l) = 1 for literal l that labels an edge on the path\n(in T ) between u and the root of T .\nFor a node u that is a leaf of S, the DLL-L-UP algorithm chooses a conflict graph Gu\nwith a series-parallel decomposition Hu such that every leaf node l of Gu is a literal set to\ntrue by \u03b1u . Also, let Fu be the set F of original clauses augmented with all clauses learned\nby the DLL-L-UP algorithm before reaching node u. By Theorem 5.1, there is a proof Tu\nfrom the clauses Fu such that every learnable clause of Hu appears in Tu as in input-derived\nclause. Hence, of course, every clause learned at u by the DLL-L-UP algorithm appears\nin Tu as an input-derived clause. The leaf node u of S is then replaced by the proof Tu\nin T . Note that by Theorem 5.1 and the definition of conflict graphs, the final clause Cu\nof Tu is a clause that contains only literals falsified by \u03b1u .\nSo far, we have defined the clauses Cu that label nodes u in T only for leaf nodes u. For\ninternal nodes u, we define Cu inductively by letting v and w be the immediate predecessors\nof u in T and defining Cu to be the clause obtained by (w-)resolution from the clauses\nCv and Cw with respect to the branching variable x that was picked at node u by the\nDLL-L-UP algorithm. Clearly, using induction from the leaves of S, the clause Cu contains\nonly variables that are falsified by the assignment \u03b1u . This makes T a regWRTI proof.\nLet r be the root node of S. Since \u03b1r is the empty assignment, the clause Cr must equal\nthe empty clause \u2737. Thus T is a regWRTI refutation of F and Theorem 5.3 is proved.\nSince DLL clause learning based on first cuts has been shown to give exponentially\nshorter proofs than regular resolution [2], and since Theorem 5.3 states that regWRTI can\n\n\f18\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nsimulate DLL search algorithms (including ones that learn first cut clauses), we have proved\nthat regRD does not simulate regWRTI:\nTheorem 5.4. regRD < regWRTI.\nHoffmann [17] gave a direct proof of Theorem 5.4 based on the variable extensions\ndescribed below in Section 7.\n5.2. DLL-L-UP simulates regWRTI. We next show that the non-greedy DLL-L-UP\nsearch procedure can simulate any regWRTI proof T . The intuition is that we split T into\ntwo parts: the input parts are the subtrees of T that contain only input-derived clauses.\nThe interior part of T is the rest of T . The interior part will be simulated by a DLL-L-UP\nsearch procedure that traverses the tree T and at each node, chooses the resolution variable\nas the branching variable and sets the branching variable according to the label on the left\nincoming edge. In this way, the tree T is traversed in a depth-first, left-to-right order. The\ninput parts of T are not traversed however. Once an input-derived clause is reached, the\nDLL-L-UP search learns all the clauses in that input subproof and backtracks returning\nUNSAT.\nThe heart of the procedure is how a conflict graph and corresponding series-parallel\ndecomposition can be picked so as to make all the clauses in a given input subproof learnable.\nThis is the content of the next lemma.\nLemma 5.5. Let T be a regular input proof of C from a set of clauses F . Suppose that\n\u03b1 falsifies C, that is, C|\u03b1 = 0. Further suppose no variable in C is used as a resolution\nvariable in T . Then there is a conflict graph G for F under \u03b1 and a series decomposition H\nfor G such that the set of learnable clauses of H is equal to the set of input-derived clauses\nof T .\nRecall that a series decomposition just means a series-parallel decomposition with a\ntrivial parallel part, i.e, k = 1 in the definition of series-parallel decompositions.\nProof. Without loss of generality, F is just the set of initial clauses of T . Let the input\nproof T contain clauses Cm+1 = C, Cm , . . . , C1 , Dm , . . . , D1 as illustrated in Figure 4 with\nm = 4. Each Ci+1 is inferred from Ci and Di by resolution on li , where li \u2208 Ci and li \u2208 Di .\nFor each i, we have Di = {li } \u222a Di\u2032 , where Di\u2032 \u2286 Ci+1 . Likewise, Ci = {li } \u222a Ci\u2032 , where\nCi\u2032 \u2286 Ci+1 .\nAs illustrated in Figure 5, we construct conflict graphs H0,0 = {\u2737, l1 , l1 } \u2282 H0,1 \u2282 * * * \u2282\nH0,m = G which form a series decomposition of G. H0,i will be a conflict graph from the set\nof clauses {C1 , D1 , . . . , Di } under \u03b1i where \u03b1i is the assignment that falsifies all the literals\nin Ci+1 . Indeed, the leaves of H0,i are precisely the negations of literals in Ci+1 . For i > 0,\nthe non-leaf nodes of H0,i are l1 and l1 , . . . , li . The predecessors of l1 are defined to be the\nliterals u with u \u2208 C1\u2032 , that is Cl1 = C1 . Likewise, the predecessors of li are the literals u\nwith u \u2208 Di\u2032 so that Cli = Di .\nTo start with, we define H0,0 to equal {\u2737, l1 , l1 }. Let H0,i be already constructed. Then\nwe have li+1 \u2208 Ci+1 since Ci+2 is inferred by resolution on li+1 from Ci+1 . It follows that\n\u03b1i (li+1 ) = 1 and that li+1 is a leaf in H0,i . We obtain H0,i+1 from H0,i by adding the\n\u2032 ) to H . The leaves of H\npredecessors of li+1 (i.e., the literals u with u \u2208 Di+1\n0,i\n0,i+1 are now\n\u2032 . Finally the graph H\nexactly the negations of the literals in the clause Ci+2\n0,m = G and the\nseries decomposition H defined by the graphs H0,i is as wanted. This completes the proof\nof Lemma 5.5.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n19\n\nD1\n\nC1\nl1\n\nD2\n\nl1\n\nC2\nl2\n\nD3\n\nl2\n\nC3\nl3\n\nD4\n\nl3\nC4\nl4\n\nl4\nC5 = C\n\nFigure 4: A regular input proof of C. Edges are labeled li or li . The Ci 's and Di 's are\nclauses.\nH0,4\nD4\u2032\u2032\nH0,3\nD3\u2032\u2032\n\nl4\n\nH0,2\nD2\u2032\u2032\n\nl3\n\nH0,1\nC1\u2032\u2032\n\nD1\u2032\u2032\n\nl2\n\nH0,0\nl1\n\nl1\n\n\u2737\nFigure 5: A conflict graph and a series decomposition. The solid lines and arcs indicate\nedges that may or may not be present. The notations C1\u2032\u2032 and Di\u2032\u2032 indicate zero or\nmore literals, and the double lines indicate an edge from each literal in the set. The\ndashed lines indicate cuts, and thereby the sets H0,i in the series decomposition.\nNamely, the set H0,i contains the nodes below the corresponding dotted line.\nWe can now finish the proof that DLL-L-UP simulates regWRTI.\n\n\f20\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nTheorem 5.6. Suppose that F has a regWRTI proof of size s. Then there is an execution\nof the non-greedy DLL-L-UP algorithm with the input (F, \u2205) that makes < s recursive\ncalls.\nProof. Let T be a regWRTI refutation of F . The DLL-L-UP algorithm works by traversing\nthe proof tree T in a depth-first, left-to-right order. At each non-input-derived node u of T ,\nlabeled with a clause C, the resolution variable for that clause is chosen as the branching\nvariable x, and the variable x is assigned the value 1 or 0, corresponding to the label on the\nedges coming into u. By part b. of Theorem 2.4, the clause C is falsified by the assignment \u03b1.\nAt each input-derived node of T , the DLL-L-UP algorithm learns the clauses in the input\nsubproof above u by using the conflict graph and series decomposition given by Lemma 5.5.\nSince the DLL-L-UP search cannot find a satisfying assignment, it must terminate after\ntraversing the (non-input) nodes in the regWRTI refutation tree. The number of recursive\ncalls will equal twice the number of non-input-derived nodes of T , which is less than s.\n6. Generalized DLL with clause learning\n6.1. The algorithm DLL-Learn. This section presents a new formulation of DLL with\nlearning called DLL-Learn. This algorithm differs from DLL-L-UP in two important\nways. First, unit propagation is no longer used explicitly (although it can be simulated).\nSecond, the DLL-Learn algorithm uses more information that arises during the DLL\nsearch process, namely, it can infer clauses by resolution at each node in the search tree.\nThis makes it possible for DLL-Learn to simulate regular resolution trees with full lemmas;\nmore specifically, DLL-Learn is equivalent to regWRTL.\nThe DLL-Learn algorithm is very similar to the pool resolution system introduced\nby Van Gelder [25]. Furthermore, our Theorem 6.1 is similar to results obtained by Van\nGelder for pool resolution. Our constructions differ mostly in that we use w-resolution\nin place of the degenerate resolution inference of Van Gelder [25]. Loosely speaking, Van\nGelder's degenerate resolution inference is a method of allowing resolution to operate on any\ntwo clauses without any weakening. Conversely, our w-resolution is a method for allowing\nresolution to operate on any two clauses, but with the maximum reasonable amount of\nweakening.\nThe idea of DLL-Learn is to extend DLL so that it can learn a new clause C at\neach node in the search tree. As usual, the new clause will satisfy F \u2261 F \u222a {C}. At\nleaves, DLL-Learn does not learn a new clause, but marks a preexisting falsified clause as\n\"new\". At internal nodes, after branching on a variable x and making two recursive calls,\nthe DLL-Learn algorithm can use w-resolution to infer a new clause, CDLL(F,\u03b1) , from the\ntwo identified new clauses, C0 and C1 returned by the recursive calls. Since x does not have\nto occur in Var (C0 ) and Var (C1 ), C is obtained by a w-resolution instead of resolution.\nThe DLL-Learn algorithm shown in Figure 6 uses non-greedy detection of contradictions. Namely, the \"optionally do\" on line 2 of Figure 6 allows the algorithm to continue\nto branch on variables even if the formula is already unsatisfied. This feature is needed for\na direct proof of Theorem 6.1. In addition, it could be helpful in an implementation of the\nalgorithm: Think of a call of DLL(F, \u03b1) such that F |\u03b1 = 0 and suppose that all of the\nfalsified clauses C \u2208 F are very large and thus undesirable to learn. It might, for example,\nbe the case that F |\u03b1 contains two conflicting unit clauses C0 |\u03b1 = {x} and C1 |\u03b1 = {\u00acx},\n\n\fRESOLUTION TREES WITH LEMMAS\n\n21\n\nwhere C0 and C1 are small. In that case, it could be better to branch on the variable x and\nto learn the resolvent of C0 and C1 .\nThere is one situation where it is not optional to execute lines 3-4; namely, if \u03b1 is a\ntotal assignment and has assigned values to all variables, then the algorithm must do lines\n3-4.\nNote that it is possible to remove C0 and C1 from F in line 13 if they were previously\nlearned. Additionally, in an implementation of DLL-Learn it could be helpful to tag Ci\nas the new clause in H in line 13 if Ci \u2286 C for an i \u2208 {0, 1} instead of learning C -\nthis would be essentially equivalent to using Van Gelder's degenerate resolution instead of\nw-resolution.\nDLL-Learn(F, \u03b1)\n1\nif F |\u03b1 = 1 then return (F, \u03b1)\n2\nif F |\u03b1 = 0 then optionally do\n3\ntag a C \u2208 F with C|\u03b1 = 0 as the new clause\n4\nreturn (F, UNSAT)\n5\nchoose x \u2208 Var (F ) \\ dom(\u03b1) and a value \u01eb \u2208 {0, 1}\n6\n(G, \u03b2)\u2190DLL-Learn(F, \u03b1 \u222a {(x, \u01eb)})\n7\nif \u03b2 6= UNSAT then return (G, \u03b2)\n8\n(H, \u03b3)\u2190DLL-Learn(G, \u03b1 \u222a {(x, 1 \u2212 \u01eb)})\n9\nif \u03b3 6= UNSAT then return (H, \u03b3)\n10\nselect the new C0 \u2208 G and the new C1 \u2208 H\n11\nC \u2190 (C0 \u2212 {x1\u2212\u01eb }) \u222a (C1 \u2212 {x\u01eb })\n12\nH \u2190 H \u222a {C}\n-- learn a clause\n13\ntag C as the new clause in H.\n14\nreturn (H, UNSAT)\n\nFigure 6: DLL with a generalized learning.\nIt is easy to verify that, at any point in the DLL-Learn algorithm, when a clause C\nis tagged as new, then C|\u03b1 = 0.\nThere is a straightforward, and direct, translation between executions of the DLLLearn search algorithm on input (F, \u2205) and regWRTL proofs of F . An execution of\nDLL-Learn(F, \u2205) can be viewed as traversing a tree in depth-first, left-to-right order. If\nthere are s \u2212 1 recursive calls to DLL-Learn, the tree has s nodes. Each node of the search\ntree is labeled with the clause tagged in the corresponding call to DLL-Learn. Thus,\nleaves of the tree are labeled with clauses that either are from F or were learned earlier in\nthe tree. The clause on an internal node of the tree is inferred from the clauses on the two\nchildren using w-resolution with respect to the branching variable. Finally, the clause C\nlabeling the root node, where \u03b1 = \u2205, must be the empty clause, since \u03b1 must falsify C. In\nthis way the search algorithm describes precisely a regWRTL proof tree. Conversely, any\nregWRTL refutation of F corresponds exactly to an execution of the DLL-Learn(F, \u2205).\nThis translation between DLL-Learn and regWRTI proof trees gives the following\ntheorem.\nTheorem 6.1. Let F be a set of clauses. There exists a regWRTL refutation of F of\nsize s if and only if there is an execution of DLL-Learn(F, \u2205) that performs exactly s \u2212 1\nrecursive calls.\n\n\f22\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nIt follows as a corollary of Theorems 3.5 and 6.1 that DLL-Learn can polynomially\nsimulate DLL-L-UP.\n7. Variable Extensions\nThis section introduces the notion of a variable extension of a CNF formula. A variable\nextension augments a set F of clauses with additional clauses such that modified formula\nVEx (F ) is satisfiable if and only if F is satisfiable. Variable extensions will be used to\nprove that regWRTI proofs can simulate resolution dags, in the sense that if there is an\nRD refutation of F , then there is a polynomial size regWRTI refutation of VEx (F ). Hence,\nDLL-Learn and the non-greedy version of DLL-L-UP can simulate full (non-regular)\nresolution in the same sense.\nOur definition of variable extensions is inspired by the proof trace extensions of Beame\net al. [2] that were used to separate DLL with clause learning from regular resolution dags. A\nsimilar construction was used by Hertel et al. [16] to show that pool resolution can simulate\nfull resolution. Our results strengthen and extend the prior results by applying directly\nto regWRTI proofs. More importantly, in contrast to proof trace extensions, variable\nextensions do not depend on the size of a (possibly unknown) resolution proof but only\non the number of variables in the formula.\nDefinition 7.1. Let F be a set of clauses and |Var (F )| = n. The set of extension variables\nof F is EVar (F ) = {q, p1 , . . . , pn }, where q and pi are new variables. The variable extension\nof F is the set of clauses\n\b\n\b\nVEx (F ) = F \u222a {q,  \u0304l} : l \u2208 C \u2208 F \u222a {p1 , p2 , . . . , pn } .\nObviously VEx (F ) is satisfiable if and only if F is. Furthermore, |VEx (F )| = O(|F |).\nSuppose that G is a resolution dag (RD) proof from F . We can reexpress G as a\nsequence of (derived) clauses C1 , C2 , . . . , Ct which has the following properties: (a) Ct is\nthe final clause of G, and (b) each Ci is inferred by resolution from two clauses D and E,\nwhere each of D and E either are in F or appear earlier in the sequence as Cj with j < i.\nBasically, the sequence is an ordinary resolution refutation, but with the clauses from F\nomitted.\nLemma 7.2. Suppose that D, E \u22a2x C. Then, there is an input resolution proof tree TC of\nthe clause {q} from VEx (F ) \u222a {D, E} such that C appears in TC and such that |TC | = 2 *\n|C| + 3.\nProof. The proof TC starts by resolving D and E to yield C. It then resolves successively\nwith the clauses {q, l}, for l \u2208 C, to derive {q}.\nTheorem 7.3. Let F be a set of clauses, n = |Var (F )|, and let C be a clause. Suppose\nthat G is a resolution dag proof of C from F of size s. Then, there is a regWRTI proof T\nof C from VEx (F ) of size \u2264 2s * (d + 2) + 1 where d = max{|D| : D \u2208 G} \u2264 n.\nProof. Let C1 , . . . , Ct be a sequence of the derived clauses in G as above. Without loss of\ngenerality, t < 2n since F also has a regular resolution tree refutation, and this has depth\nat most n, and thus has < 2n internal nodes. Let T \u2032 be a binary tree with t leaves and of\nheight h = \u2308log2 t\u2309 \u2264 n. For each node u in T \u2032 , let l(u) be the level of u in T \u2032 , namely,\nthe number of edges between u and the root. Label u with the variable pl(u) . Also, label\nevery node u in T \u2032 with the clause {q}. T \u2032 will form the middle part of a regWRTI proof:\n\n\fRESOLUTION TREES WITH LEMMAS\n\n23\n\neach clause {q} at level i is inferred by w-resolution from its two children clauses (also equal\nto {q}) with respect to the variable pi .\nNow, we expand T \u2032 into a regWRTI proof tree T \u2032\u2032 . For this, for 1 \u2264 i \u2264 t, we replace\nthe i-th leaf of T \u2032 with a new subproof TCi defined as follows. Letting Ci be as above, let\nDi and Ei be the two clauses from which Ci is inferred in G. Then replace i-th leaf of T \u2032 by\nthe input proof TCi from Lemma 7.2 which contains Ci and ends with the clause {q}. Note\nthat each of Di and Ei either is in F or appeared as an input clause in a proof, TDi or TEi ,\ninserted at an earlier leaf of T \u2032 . Therefore T \u2032\u2032 is a valid regWRTI proof of {q} from VEx (F ).\nSince there are at most s \u2212 1 internal nodes in T \u2032 and each TCi has size \u2264 2d + 3, T \u2032\u2032 has\nsize at most (s \u2212 1) + s * (2d + 3).\nFinally, we form a regWRTI proof of C by modifying T \u2032\u2032 by adding a new root labeled\nwith the clause C and the resolution variable q. Let the left child of this new root be the\nroot of T \u2032\u2032 , and let the right child be a new node labeled also with C. (This is permissible\nsince C is input-derived in T \u2032\u2032 .) Label the left edge coming to the new root with the literal q,\nand the right edge with the literal q. This makes C inferred from {q} and C by w-resolution\nwith respect to q. T is a valid regWRTI of size at most s + 1 + s * (2d + 3) = 2s * (d + 2) + 1.\nSince DLL-L-UP and DLL-Learn simulate regWRTI, Theorem 7.3 implies that these\ntwo systems p-simulate full resolution by the use of variable extensions:\nCorollary 7.4. Suppose that F has a resolution dag refutation of size s. Then both DLLL-UP and DLL-Learn, when given VEx (F ) as input, have executions that return UNSAT\nafter at most p(s) recursive calls, for some polynomial p.\nWe now consider some issues about \"naturalness\" of proofs based on resolution with\nlemmas. Beame et al. [2] defined a refutation system to be natural provided that, whenever\nF has a refutation of size s, then F |\u03b1 has a refutation of size at most s. We need a somewhat\nrelaxed version of this notion:\nDefinition 7.5. Let R be a refutation system for sets of clauses. The system R is p-natural\nprovided, there is a polynomial p(s), such that, whenever a set F has an R-refutation of\nsize s, and \u03b1 is a restriction, then F |\u03b1 has an R-refutation of size \u2264 p(s).\nThe next proposition is well-known.\nProposition 7.6. Resolution dags (RD) and regular resolution dags (regRD) are natural\nproof systems.\nAs a corollary to Theorem 7.3 we obtain the following theorem.\nTheorem 7.7.\n(a) regWRTI is equivalent to RD if and only if regWRTI is p-natural.\n(b) regWRTL is equivalent to RD if and only if regWRTL is p-natural.\nProof. Suppose that regWRTI \u2261 RD. Then, since RD is natural, we have immediately that\nregWRTI is p-natural.\nConversely, suppose that regWRTI is p-natural. By Theorem 3.5, RD p-simulates\nregWRTI. So it suffices to prove that regWRTI p-simulates RD. Let F have an RD refutation\nof size s. By Theorem 7.3, VEx (F ) has a regWRTI proof of size 2s(s + 2) + 1. Let \u03b1 be\nthe assignment that assigns the value 1 to each of the extension variables q and p1 , . . . , pn .\nSince VEx (F )|\u03b1 is F and since regWRTI is p-natural, F has a regWRTI proof of size at\n\n\f24\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nmost p(2s(s + 2) + 1). This proves that regWRTI p-simulates RD, and completes the proof\nof a.\nThe proof of b. is similar.\nTheorem 7.7 is stated for the equivalence of systems with RD. It could also be stated for\np-equivalent but then one needs an \"effective\" version of p-natural, where the R-refutation\nof F |\u03b1 is computable in polynomial time from \u03b1 and a R-refutation of F .\n8. A Lower Bound for RTLW with short lemmas\nIn this section we prove a lower bound showing that learning only short clauses does\nnot help a DLL algorithm for certain hard formulas. The proof system corresponding to\nDLL algorithms with learning restricted to clauses of length k is, according to Section 5,\nregWRTI with the additional restriction that every used lemma is a clause of length at most\nk. We prove a lower bound for a stronger proof system that allows arbitrary lemmas instead\nof just input lemmas, drops the regularity restriction, and uses the general weakening rule\ninstead of just w-resolution, i.e., RTLW as defined in Section 3. We define RTLW(k) to\nbe the restriction of RTLW in which every lemma used, i.e., every leaf label that does not\noccur in the initial formula, is of size at most k.\nThe hard example formulas we prove the lower bound for are the well-known Pigeonhole\nPrinciple formulas. This principle states that there can be no 1-to-1 mapping from a set of\nsize n + 1 into a set of size n. In propositional logic, the negation of this principle gives rise\nto an unsatisfiable set of clauses P HPn in the variables xi,j for 1 \u2264 i \u2264 n + 1 and 1 \u2264 j \u2264 n.\nThe variable xi,j is intended to state that i is mapped to j. The set P HPn consists of the\nfollowing clauses:\n\b\n\u2022 the pigeon clause Pi = xi,j ; 1 \u2264 j \u2264 n for every 1 \u2264 i \u2264 n + 1.\n\u2022 the hole clause Hi,j,k = {x\u0304i,k , x\u0304j,k } for every 1 \u2264 i < j \u2264 n + 1 and k \u2264 n.\nIt is well-known that the pigeonhole principle requires exponential size dag-like resolution proofs: Haken [15] shows that every RD refutation of P HPn is of size 2\u03a9(n) . Note that\nthe number of variables is O(n2 ), so that this lower bound is far from maximal. In fact,\nIwama and Miyazaki [18] prove a larger lower bound for tree-like refutations.\nTheorem 8.1 (Iwama and Miyazaki [18]). Every resolution tree refutation of P HPn is of\nsize at least (n/4)n/4 .\nWe will show that for k \u2264 n/2, RTLW(k) refutations of P HPn are asymptotically\nof the same size 2\u03a9(n log n) as resolution trees. On the other hand, it is known [7] that\ndag-like resolution proofs need not be much larger than Haken's lower bound: there exist\nRD refutations of P HPn of size 2n * n2 . These refutations are even regular, and thus can\nbe simulated by regWRTI. Hence P HPn can be solved in time 2O(n) by some variant of\nDLL-L-UP when learning arbitrary long clauses, whereas our lower bound shows that any\nDLL algorithm that learns only clauses of size at most n/2 needs time 2\u03a9(n log n) .\nIn fact, we will prove our lower bound for the weaker functional pigeonhole principle\nF P HPn , which also includes the following clauses:\n\u2022 The functional clause Fi,j,k = {x\u0304i,j , x\u0304i,k } for every 1 \u2264 i \u2264 n + 1 and every 1 \u2264 j < k \u2264 n.\nWhile the lower bound of Iwama and Miyazaki is only stated for the clauses P HPn , it is\neasily verified that their proof works as well when the functional clauses are added to the\nformula.\n\n\fRESOLUTION TREES WITH LEMMAS\n\n25\n\nOur lower bound proof uses the fact that resolution trees with weakening (RTW) are\nnatural, i.e., preserved under restrictions in the following sense:\nProposition 8.2. Let R be a RTW proof of C from F of size s, and \u03c1 a restriction. There\nis an RTW proof R\u2032 for C|\u03c1 from F |\u03c1 of size at most s.\nWe denote the resolution tree R\u2032 by R|\u03c1 . Since this proposition is well-known a proof\nwill not be given.\nNext, we need to bring refutations in RTLW(k) to a certain normal form. First, we\nshow that it is unnecessary to use clauses as lemmas that are subsumed by axioms in the\nrefuted formula.\nLemma 8.3. If there is a RTLW(k) refutation of some formula F of size s, then there is\na RTLW(k) refutation of F of size at most 2s in which no clause C with C \u2287 D for some\nclause D in F is used as a lemma.\nProof. If a clause C with C \u2287 D for some D \u2208 F is used as a lemma, replace every leaf\nlabeled C by a weakening inference of C from D.\nSecondly, we need the fact that an RTLW(k) refutation does not need to use any\ntautological clauses, i.e., clauses of the form C \u222a {x, x\u0304} for a variable x.\nLemma 8.4. If there is a RTLW(k) refutation of some formula F of size s, then there is\na RTLW(k) refutation of F of size at most s that contains no tautological clause.\nProof. Let P be an RTLW(k)-refutation of F of size s that contains t occurrences of\ntautological clauses. We transform P into a refutation P \u2032 of size |P \u2032 | \u2264 s such that P \u2032\ncontains fewer than t occurrences of tautological clauses. Finitely many iterations of this\nprocess yields the claim.\nWe obtain P \u2032 as follows. Since the final clause of P is not tautological, if t > 0, there\nmust be a tautological clause C \u222a {x, x\u0304} which is resolved with a clause D \u222a {x} to yield\na non-tautological clause C \u222a D \u222a {x}. The idea is to cut out the subtree T0 that derives\nthe clause C \u222a {x, x\u0304}, and derive C \u222a D \u222a {x} by a weakening from D \u222a {x}. This gives a\n\"proof\" P0 with fewer tautological clauses than P . However, P0 may not be a valid proof,\nsince some of the clauses in T0 might be used as lemmas in P0 . To fix this, we shall extract\nparts of T0 and plant them onto P0 so that all lemmas used are derived. In order to make\nthis construction precise, we need the notion of trees in which some of the used lemmas are\nnot derived.\nA partial RTLW from F is defined to be a tree T which satisfies all the conditions of\nan RTLW, except that some leaves may be labeled by clauses that occur neither in F nor\nearlier in T ; these are called the open leaves of T .\nWe construct P \u2032 in stages by defining, for i \u2265 0, a partial RTLW refutation Pi of F\nand a partial RTLW derivation Ti of C \u222a {x, x\u0304} from F with the following properties:\n\u2022 All open leaves in Pi appear in Ti . The first open leaf in Pi is denoted Ci .\n\u2022 All open leaves in Ti appear in Pi before Ci .\n\u2022 |Pi | + |Ti | = |P | .\nP0 and T0 were defined above and certainly satisfy the two properties. Given Pi and Ti , we\nconstruct Pi+1 and Ti+1 as follows: We locate the first occurrence of Ci in Ti and let Ti\u2217 be\nthe subtree of Ti rooted at this occurrence. We form Ti+1 by replacing in Ti the subtree Ti\u2217\nby a leaf labeled Ci . And, we form Pi+1 by replacing the first open leaf, Ci , in Pi by the\ntree Ti\u2217 .\n\n\f26\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\nThe invariants are easily seen to be preserved. Obviously, |Pi+1 | + |Ti+1 | = |Pi | + |Ti | =\n|P |. The open leaves of Ti\u2217 appear in Pi before Ci , and therefore, any open leaf in Pi+1 , and\nin particular, Ci+1 if it exists, must occur after the (formerly open leaf) clause Ci . New\nopen leaves in Ti are Ci and possibly some lemmas derived in Ti\u2217 , and these all occur in Pi+1\nbefore Ci+1 .\nSince Pi+1 contains fewer open leaves than Pi for every i, there is an m such that\nPm contains no open leaves, and thus is an RTLW refutation. We then discard Tm and\nset P \u2032 := Pm . Each lemma used in P \u2032 was a lemma in P , thus P \u2032 is also an RTLW(k)\nrefutation.\nNote that the total number of occurrences of tautological clauses in Pi+1 and Ti+1\ncombined is the same as in Pi and Ti combined. This is also equal to the number of\ntautological clauses in P . Furthermore, Tm must contain at least one tautological clause,\nnamely its root C \u222a {x, x\u0304}. It follows that P \u2032 has fewer tautological clauses than P .\n\b\nA matching \u03c1 is a set of pairs (i1 , j1 ), . . . , (ik , jk ) \u2282 {1, . . . , n + 1} \u00d7 {1, . . . , n} such\nthat all the i\u03bd as well as all the j\u03bd are pairwise distinct. The size of \u03c1 is |\u03c1| = k. A matching\n\u03c1 induces a partial assignment to the variables of P HPn as follows:\n\uf8f1\n1\nif (i, j) \u2208 \u03c1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f20\nif there is (i, j \u2032 ) \u2208 \u03c1 with j 6= j \u2032\n\u03c1(xi,j ) =\n\uf8f4\nor (i\u2032 , j) \u2208 \u03c1 with i 6= i\u2032\n\uf8f4\n\uf8f4\n\uf8f3\nundefined otherwise.\n\nWe will identify a matching and the assignment it induces. The crucial property of such\na matching restriction \u03c1 is that F P HPn |\u03c1 is \u2013 up to renaming of variables \u2013 the same as\nF P HPn\u2212|\u03c1| .\nThe next lemma states that a short clause occurring as a lemma in an RTLW refutation\ncan always be falsified by a small matching restriction.\nLemma 8.5. Let C be a clause of size k \u2264 n/2 such that\n\u2022 C is not tautological,\n\u2022 C 6\u2287 Hi,i\u2032 ,j for any hole clause Hi,i\u2032 ,j ,\n\u2022 C 6\u2287 Fi,j,j \u2032 for any functional clause Fi,j,j \u2032 .\nThen there is a matching \u03c1 of size |\u03c1| \u2264 k such that C|\u03c1 = \u2737.\n\nProof. First, we let \u03c11 consist of all those pairs (i, j) such that the negative literal x\u0304i,j occurs\nin C. By the second and third assumption, these pairs form a matching. All the negative\nliterals in C are set to 0 by \u03c11 , and by the first assumption, no positive literal in C is set\nto 1 by \u03c11 .\nNow consider all pigeons i1 , . . . , ir mentioned in positive literals in C that are not\nalready set to 0 by \u03c11 , i.e., that are not mentioned in any of the \b\nnegative literals in C. Pick\nj1 , . . . , jr from the n/2 holes not mentioned in C, and set \u03c12 := (i1 , j1 ), . . . , (ir , jr ) . This\nmatching sets the remaining positive literals to 0, thus for \u03c1 := \u03c11 \u222a \u03c12 , we have C|\u03c1 = \u2737.\nClearly the size of \u03c1 is at most k since we have picked at most one pair for each literal\nin C.\nFinally, we are ready to put all ingredients together to prove our lower bound.\nTheorem 8.6. For every k \u2264 n/2, every RTLW(k)-refutation of F P HPn is of size\n2\u03a9(n log n) .\n\n\fRESOLUTION TREES WITH LEMMAS\n\n27\n\nProof. Let R be an RTLW(k)-refutation of F P HPn of size s. By Lemmas 8.3 and 8.4,\nR can be transformed into R\u2032 of size at most 2s in which no clause is tautological and no\nclause used as a lemma is subsumed by a clause in F P HPn . Let C be the first clause in R\u2032\nwhich is used as a lemma; C is of size at most k. The subtree RC of R\u2032 rooted at C is a\nresolution tree for C from F P HPn .\nBy Lemma 8.5, there is a matching restriction \u03c1 of size |\u03c1| \u2264 k such that C|\u03c1 = \u2737.\nThen RC |\u03c1 is a resolution tree with weakening refutation of F P HPn |\u03c1 , which is the same as\nF P HPn\u2212k . By Proposition 2.3, applications of the weakening rule can be eliminated from\nRC |\u03c1 without increasing the size. Therefore by Theorem 8.1, RC is of size\n\u0010 n \u2212 k \u0011 n\u2212k \u0010 n \u0011 n\n4\n8\n\u2265\n4\n8\nand hence the size of R is at least\n1\ns \u2265 |RC | \u2265 2\u03a9(n log n) .\n2\nReferences\n[1] Michael Alekhnovich, Jan Johannsen, Toniann Pitassi, and Alasdair Urquhart. An exponential separation between regular and general resolution. Theory of Computing, 3:81\u2013102, 2007.\n[2] Paul Beame, Henry A. Kautz, and Ashish Sabharwal. Towards understanding and harnessing the\npotential of clause learning. J. Artif. Intell. Res. (JAIR), 22:319\u2013351, 2004.\n[3] Daniel Le Berre and Laurent Simon. The essentials of the SAT 2003 competition. In Proc. 6th International Conference on Theory and Applications of Satisfiability (SAT 2003), LNCS 2919, pages 452\u2013467.\nSpringer, 2003.\n[4] Daniel Le Berre and Laurent Simon. Fifty-five solvers in Vancouver: The SAT 2004 competition. In\nTheory and Applications of Satisfiability Testing: 7th International Conference, SAT 2004, LNCS 3542,\npages 321\u2013344. Springer, 2004.\n[5] Daniel Le Berre and Laurent Simon. Preface to the special volume on the SAT 2005 competitions and\nevaluations. Journal on Satisfiability, Boolean Modeling and Computation, 2:i\u2013xiv, 2005.\n[6] Maria Luisa Bonet, Juan Luis Esteban, Nicola Galesi, and Jan Johannsen. On the relative complexity\nof resolution restrictions and cutting planes proof systems. SIAM Journal on Computing, 30:1462\u20131484,\n2000.\n[7] Samuel R. Buss and Toniann Pitassi. Resolution and the weak pigeonhole principle. In Mogens Nielsen\nand Wolfgang Thomas, editors, Computer Science Logic, 11th International Workshop CSL '97, pages\n149\u2013156. Springer LNCS 1414, 1998.\n[8] C. L. Chang. The unit proof and the input proof in theorem proving. J. ACM, 17(4):698\u2013707, 1970.\n[9] Martin Davis, George Logemann, and Donald W. Loveland. A machine program for theorem-proving.\nCommun. ACM, 5(7):394\u2013397, 1962.\n[10] Martin Davis and Hilary Putnam. A computing procedure for quantification theory. J. ACM, 7(3):201\u2013\n215, 1960.\n[11] Niklas E\u00e9n and Armin Biere. Effective preprocessing in SAT through variable and clause elimination.\nIn Proc. 8th International Conference on Theory and Applications of Satisfiability Testing (SAT'05),\nLNCS 3569, pages 61\u201375. Springer, 2005.\n[12] Jon W. Freeman. Improvements to Propositional Satisfiability Search Algorithms. PhD thesis, University\nof Pennsylvania, Philadelphia, PA, USA, 1995.\n[13] Zhaohui Fu, Yogesh Mahajan, and Sharad Malik. New features of the SAT'04 version of zChaff. SAT\nCompetition 2004 \u2013 Solver Description, http://www.princeton.edu/ chaff/zchaff/sat04.pdf, 2004.\n[14] Andreas Goerdt. Regular resolution versus unrestricted resolution. SIAM J. Comput., 22(4):661\u2013683,\n1993.\n[15] Armin Haken. The intractability of resolution. Theor. Comput. Sci., 39:297\u2013308, 1985.\n\n\f28\n\nS. R. BUSS, J. HOFFMANN, AND J. JOHANNSEN\n\n[16] Philipp Hertel, Fahiem Bacchus, Toniann Pitassi, and Allen Van Gelder. Clause learning can effectively\np-simulate general propositional resolution. In Dieter Fox and Carla P. Gomes, editors, Proceedings of\nthe Twenty-Third AAAI Conference on Artificial Intelligence, AAAI 2008, pages 283\u2013290. AAAI Press,\n2008.\n[17] Jan Hoffmann. Resolution proofs and DLL-algorithms with clause learning. Diploma Thesis, LMU\nM\u00fcnchen, 2007. http://www.tcs.ifi.lmu.de/ ~hoffmann .\n[18] Kazuo Iwama and Shuichi Miyazaki. Tree-like resolution is superpolynomially slower than dag-like resolution for the pigeonhole principle. In Proceedings of the 10th International Symposium on Algorithms\nand Computation (ISAAC), pages 133\u2013142, 1999.\n[19] Roberto J. Bayardo Jr. and Robert C. Schrag. Using CSP look-back techniques to solver real-world\nSAT instances. In Proc. 14th Natl. Conference on Artificial Intelligence, pages 203\u2013208, 1997.\n[20] Yogesh S. Mahajan, Zhaohui Fu, and Sharad Malik. Zchaff2004: An efficient SAT solver. In Theory\nand Applications of Satisfiability Testing: 7th International Conference, SAT 2004, LNCS 3542, pages\n360\u2013375. Springer, 2004.\n[21] Matthew W. Moskewicz, Conor F. Madigan, Ying Zhao, Lintao Zhang, and Sharad Malik. Chaff:\nEngineering an efficient SAT solver. In Proc. 38th Design Automation Conference (DAC'01), pages\n530\u2013535, 2001.\n[22] Alexander Nadel. Backtrack search algorithms for propositional logic satisfiability: Review and innovations. Master's thesis, Hebrew University of Jerusalem, Israel, 2002.\n[23] Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP - a new search algorithm for satisfiability. In\nProc. IEEE/ACM International Conference on Computer Aided Design (ICCAD), pages 220\u2013227, 1996.\n[24] G.S. Tseitin. On the complexity of derivation in propositional calculus. Studies in Constructive Mathematics and Mathematical Logic, Part 2, pages 115\u2013125, 1968.\n[25] Allen Van Gelder. Pool resolution and its relation to regular resolution and DPLL with clause learning.\nIn Logic for Programming, Artificial Intelligence, and Reasoning (LPAR), LNAI 3835, pages 580\u2013594,\nMontego Bay, Jamaica, 2005. Springer-Verlag.\n[26] Lintao Zhang, Conor F. Madigan, Matthew W. Moskewicz, and Sharad Malik. Efficient conflict driven\nlearning in a Boolean satisfiability solver. In Proc. IEEE/ACM International Conference on Computer\nAided Design (ICCAD), pages 279\u2013285, 2001.\n\nThis work is licensed under the Creative Commons Attribution-NoDerivs License. To view\na copy of this license, visit http:// reative ommons.org/li enses/by-nd/2.0/ or send a\nletter to Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305, USA.\n\n\f"}