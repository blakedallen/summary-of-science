{"id": "http://arxiv.org/abs/0812.3788v2", "guidislink": true, "updated": "2009-01-26T12:52:36Z", "updated_parsed": [2009, 1, 26, 12, 52, 36, 0, 26, 0], "published": "2008-12-19T13:51:57Z", "published_parsed": [2008, 12, 19, 13, 51, 57, 4, 354, 0], "title": "Foundations of SPARQL Query Optimization", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0812.3882%2C0812.0357%2C0812.1814%2C0812.4676%2C0812.2802%2C0812.2514%2C0812.3915%2C0812.3523%2C0812.0695%2C0812.0473%2C0812.2650%2C0812.4743%2C0812.2358%2C0812.5006%2C0812.0768%2C0812.1399%2C0812.0824%2C0812.0783%2C0812.4973%2C0812.4376%2C0812.1041%2C0812.1895%2C0812.2252%2C0812.3741%2C0812.4795%2C0812.4528%2C0812.4907%2C0812.1690%2C0812.4509%2C0812.0418%2C0812.1914%2C0812.2550%2C0812.5039%2C0812.4051%2C0812.2852%2C0812.3017%2C0812.3673%2C0812.1088%2C0812.4901%2C0812.4403%2C0812.0674%2C0812.1896%2C0812.1432%2C0812.0920%2C0812.2727%2C0812.3788%2C0812.1775%2C0812.0956%2C0812.0886%2C0812.0747%2C0812.0275%2C0812.0141%2C0812.1156%2C0812.3280%2C0812.2477%2C0812.0249%2C0812.2982%2C0812.3463%2C0812.3880%2C0812.0611%2C0812.1695%2C0812.3135%2C0812.3694%2C0812.3922%2C0812.4156%2C0812.3035%2C0812.3737%2C0812.2014%2C0812.2856%2C0812.3518%2C0812.1268%2C0812.2751%2C0812.3272%2C0812.2872%2C0812.3751%2C0812.2121%2C0812.2081%2C0812.2049%2C0812.0560%2C0812.3285%2C0812.1031%2C0812.1855%2C0812.2634%2C0812.4919%2C0812.0989%2C0812.4565%2C0812.4808%2C0812.1016%2C0812.3366%2C0812.4671%2C0812.4600%2C0812.0624%2C0812.4740%2C0812.3225%2C0812.3988%2C0812.1520%2C0812.3047%2C0812.2670%2C0812.2628%2C0812.2265%2C0812.3642&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Foundations of SPARQL Query Optimization"}, "summary": "The SPARQL query language is a recent W3C standard for processing RDF data, a\nformat that has been developed to encode information in a machine-readable way.\nWe investigate the foundations of SPARQL query optimization and (a) provide\nnovel complexity results for the SPARQL evaluation problem, showing that the\nmain source of complexity is operator OPTIONAL alone; (b) propose a\ncomprehensive set of algebraic query rewriting rules; (c) present a framework\nfor constraint-based SPARQL optimization based upon the well-known chase\nprocedure for Conjunctive Query minimization. In this line, we develop two\nnovel termination conditions for the chase. They subsume the strongest\nconditions known so far and do not increase the complexity of the recognition\nproblem, thus making a larger class of both Conjunctive and SPARQL queries\namenable to constraint-based optimization. Our results are of immediate\npractical interest and might empower any SPARQL query optimizer.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0812.3882%2C0812.0357%2C0812.1814%2C0812.4676%2C0812.2802%2C0812.2514%2C0812.3915%2C0812.3523%2C0812.0695%2C0812.0473%2C0812.2650%2C0812.4743%2C0812.2358%2C0812.5006%2C0812.0768%2C0812.1399%2C0812.0824%2C0812.0783%2C0812.4973%2C0812.4376%2C0812.1041%2C0812.1895%2C0812.2252%2C0812.3741%2C0812.4795%2C0812.4528%2C0812.4907%2C0812.1690%2C0812.4509%2C0812.0418%2C0812.1914%2C0812.2550%2C0812.5039%2C0812.4051%2C0812.2852%2C0812.3017%2C0812.3673%2C0812.1088%2C0812.4901%2C0812.4403%2C0812.0674%2C0812.1896%2C0812.1432%2C0812.0920%2C0812.2727%2C0812.3788%2C0812.1775%2C0812.0956%2C0812.0886%2C0812.0747%2C0812.0275%2C0812.0141%2C0812.1156%2C0812.3280%2C0812.2477%2C0812.0249%2C0812.2982%2C0812.3463%2C0812.3880%2C0812.0611%2C0812.1695%2C0812.3135%2C0812.3694%2C0812.3922%2C0812.4156%2C0812.3035%2C0812.3737%2C0812.2014%2C0812.2856%2C0812.3518%2C0812.1268%2C0812.2751%2C0812.3272%2C0812.2872%2C0812.3751%2C0812.2121%2C0812.2081%2C0812.2049%2C0812.0560%2C0812.3285%2C0812.1031%2C0812.1855%2C0812.2634%2C0812.4919%2C0812.0989%2C0812.4565%2C0812.4808%2C0812.1016%2C0812.3366%2C0812.4671%2C0812.4600%2C0812.0624%2C0812.4740%2C0812.3225%2C0812.3988%2C0812.1520%2C0812.3047%2C0812.2670%2C0812.2628%2C0812.2265%2C0812.3642&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The SPARQL query language is a recent W3C standard for processing RDF data, a\nformat that has been developed to encode information in a machine-readable way.\nWe investigate the foundations of SPARQL query optimization and (a) provide\nnovel complexity results for the SPARQL evaluation problem, showing that the\nmain source of complexity is operator OPTIONAL alone; (b) propose a\ncomprehensive set of algebraic query rewriting rules; (c) present a framework\nfor constraint-based SPARQL optimization based upon the well-known chase\nprocedure for Conjunctive Query minimization. In this line, we develop two\nnovel termination conditions for the chase. They subsume the strongest\nconditions known so far and do not increase the complexity of the recognition\nproblem, thus making a larger class of both Conjunctive and SPARQL queries\namenable to constraint-based optimization. Our results are of immediate\npractical interest and might empower any SPARQL query optimizer."}, "authors": ["Michael Schmidt", "Michael Meier", "Georg Lausen"], "author_detail": {"name": "Georg Lausen"}, "author": "Georg Lausen", "links": [{"href": "http://arxiv.org/abs/0812.3788v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0812.3788v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DB", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DB", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0812.3788v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0812.3788v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Foundations of SPARQL Query Optimization\nMichael Meier\u2217\nGeorg Lausen\nInstitut f\u00fcr Informatik\nGeorges-K\u00f6hler-Allee, Geb\u00e4ude 051\n79110 Freiburg i. Br., Germany\n{mschmidt, meierm, lausen}@informatik.uni-freiburg.de\n\narXiv:0812.3788v2 [cs.DB] 26 Jan 2009\n\nMichael Schmidt\u2217\n\nABSTRACT\nThe SPARQL query language is a recent W3C standard for\nprocessing RDF data, a format that has been developed to\nencode information in a machine-readable way. We investigate the foundations of SPARQL query optimization and\n(a) provide novel complexity results for the SPARQL evaluation problem, showing that the main source of complexity\nis operator Optional alone; (b) propose a comprehensive\nset of algebraic query rewriting rules; (c) present a framework for constraint-based SPARQL optimization based upon\nthe well-known chase procedure for Conjunctive Query minimization. In this line, we develop two novel termination\nconditions for the chase. They subsume the strongest conditions known so far and do not increase the complexity of the\nrecognition problem, thus making a larger class of both Conjunctive and SPARQL queries amenable to constraint-based\noptimization. Our results are of immediate practical interest\nand might empower any SPARQL query optimizer.\n\n1.\n\nIntroduction\n\nThe SPARQL Protocol and Query Language is a recent\nW3C recommendation that has been developed to extract\ninformation from data encoded using the Resource Description Framework (RDF) [14]. From a technical point of view,\nRDF databases are collections of (subject,predicate,object)\ntriples. Each triple encodes the binary relation predicate between subject and object, i.e. represents a single knowledge\nfact. Due to their homogeneous structure, RDF databases can\nbe seen as labeled directed graphs, where each triple defines\nan edge from the subject to the object node under label predicate. While originally designed to encode knowledge in the\nSemantic Web in a machine-readable format, RDF has found\nits way out of the Semantic Web community and entered the\nwider discourse of Computer Science. Coming along with\nits application in other areas, such as bio informatics, data\npublishing, or data integration, large RDF repositories have\nbeen created (cf. [29]). It has repeatedly been observed that\nthe database community is facing new challenges to cope\nwith the specifics of the RDF data format [7, 18, 21, 31].\n\u2217\nThe work of this author was funded by Deutsche\nForschungsgemeinschaft grant GRK 806/03.\n\nWith SPARQL, the W3C has recommended a declarative\nquery language that allows to extract data from RDF graphs.\nSPARQL comes with a powerful graph matching facility,\nwhose basic construct are so-called triple patterns. During\nquery evaluation, variables inside these patterns are matched\nagainst the RDF input graph. The solution of the evaluation\nprocess is then described by a set of mappings, where each\nmapping associates a set of variables with RDF graph components. SPARQL additionally provides a set of operators\n(namely And, Filter, Optional, Select, and Union),\nwhich can be used to compose more expressive queries.\nOne key contribution in this paper is a comprehensive complexity analysis for fragments of SPARQL. We follow previous approaches [26] and use the complexity of the Evaluation problem as a yardstick: given query Q, data set D,\nand candidate solution S as input, check if S is contained in\nthe result of evaluating Q on D. In [26] it has been shown\nthat full SPARQL is PSpace-complete, which is bad news\nfrom a complexity point of view. We show that yet operator Optional alone makes the Evaluation problem\nPSpace-hard. Motivated by this result, we further refine our\nanalysis and prove better complexity bounds for fragments\nwith restricted nesting depth of Optional expressions.\nHaving established this theoretical background, we turn\ntowards SPARQL query optimization. The semantics of\nSPARQL is formally defined on top of a compact algebra\nover mapping sets. In the evaluation process, the SPARQL\noperators are first translated into algebraic operations, which\nare then directly evaluated on the data set. The SPARQL\nAlgebra (SA) comprises operations such as join, union, left\nouter join, difference, projection, and selection, akin to the\noperators defined in Relational Algebra (RA). At first glance,\nthere are many parallels between SA and RA; in fact, the\nstudy in [1] reveals that SA and RA have exactly the same\nexpressive power. Though, the technically involved proof\nin [1] indicates that a semantics-preserving SA-to-RA translation is far from being trivial (cf. [6]). Hence, although both\nalgebras provide similar operators, there are still very fundamental differences between both. One of the most striking\ndiscrepancies, as also argued in [26], is that joins in RA are\nrejecting over null-values, but in SA, where the schema is\nloose in the sense that mappings may bind an arbitrary set\nof variables, joins over unbound variables (essentially the\nequivalent of RA null-values) are always accepting.\n\n\ftion problem for constraints. Further, they apply to the core\nchase introduced in [8] (there it was proven that the termination of the chase implies termination of the core chase).\n\nOne direct implication is that not all equivalences that hold\nin RA also hold in SA, and vice versa, which calls for a study\nof SA by its own. In response, we present an elaborate study\nof SA in the second part of the paper. We survey existing and develop new algebraic equivalences, covering various SA operators, their interaction, and their relation to the\nRA counterparts. When interpreted as rewriting rules, these\nequivalences form the theoretical foundations for transferring\nestablished RA optimization techniques, such as filter pushing, into the SPARQL context. Going beyond the adaption\nof existing techniques, we also address SPARQL-specific issues, e.g. provide rules for simplifying expressions involving\n(closed-world) negation, which can be expressed in SPARQL\nsyntax using a combination of Optional and Filter.\n\nIn order to optimize SPARQL queries, we translate Andblocks of the query into CQs, optimize them using the C&Balgorithm, and translate the outcome back into SPARQL. Additionally, we provide optimization rules that go beyond such\nsimple queries, showing that in some cases Optional- and\nFilter-queries can be simplified. With respect to chase termination, we introduce two alternate SPARQL-to-CQ translation schemes. They differ w.r.t. the termination conditions\nthat they exhibit for the subsequent chase, i.e. our sufficient\nchase termination conditions might guarantee termination for\nthe first but not for the second translation, and vice versa.\n\nWe note that in the past much research effort has been\nspent in processing RDF data with traditional systems, such\nas relational DBMSs or datalog engines [7, 18, 31, 25, 12, 21,\n27], thus falling back on established optimization strategies.\nSome of them (e.g. [31, 12]) work well in practice, but are\nlimited to small fragments, such as And-only queries. More\ncomplete approaches (e.g. [7]) suffer from performance bottlenecks for complex queries, often caused by poor optimization results (cf. [18, 21, 22]). For instance, [21] identifies\ndeficiencies of existing schemes for queries involving negation, a problem that we tackle in our analysis. This also\nshows that traditional approaches are not laid out for the specific challenges that come along with SPARQL processing\nand urges the need for a thorough investigation of SA.\n\nOur key contributions can be summarized as follows.\n\u2022 We present previously unknown complexity results for\nfragments of the SPARQL query language, showing that\nthe main source of complexity is operator Optional\nalone. Moreover, we prove there are better bounds when\nrestricting the nesting depth of Optional expressions.\n\u2022 We summarize existent and establish new equivalences\nover SPARQL Algebra. Our extensive study characterizes the algebraic operators and their interaction, and\nmight empower any SPARQL query optimizer. We also\nindicate an erratum in [26] and discuss its implications.\n\u2022 Our novel SQO scheme for SPARQL can be used to\noptimize And-only queries under a set of constraints.\nFurther, we provide rules for semantic optimization of\nqueries involving operators Optional and Filter.\n\u2022 We present two novel sufficient termination conditions\nfor the chase, which strictly generalize previous conditions. This improvement empowers the practicability of\nmany important research areas, like e.g. [28, 20, 15, 9].\n\nIn the final part of the paper we study constraint-based\nquery optimization in the context of SPARQL, also known\nas Semantic Query Optimization (SQO). SQO has been applied successfully in other contexts before, such as Conjunctive Query (CQ) optimization (e.g., [3]), relational databases\n(e.g., [17]), and deductive databases (e.g., [5]). We demonstrated the prospects of SQO for SPARQL in [19], and in\nthis work we lay the foundations for a schematic semantic\noptimization approach. Our SQO scheme builds upon the\nChase & Backchase (C&B) algorithm [9], an extension of\nthe well-known chase procedure for CQ optimization [24, 3,\n16]. One key problem with the chase is that it might not always terminate. Even worse, it has recently been shown that\nfor an arbitrary set of constraints it is undecidable if it terminates or not [8]. There exist, however, sufficient conditions\nfor the termination of the chase; the best condition known so\nfar is that of stratified constraints [8]. The definition of stratification uses a former termination condition for the chase,\nnamely weak acyclicity [28]. In this paper, we present two\nprovably stronger termination conditions, making a larger\nclass of CQs amenable to the semantic optimization process\nand generalizing the methods introduced in [28, 8].\n\nStructure. We start with some preliminaries in Section 2\nand present the complexity results for SPARQL fragments in\nSection 3. The subsequent discussion of query optimization\ndivides into algebraic optimization (Section 4) and semantic optimization (Section 5). The latter discussion is complemented by the chase termination conditions presented in\nSection 6. Finally, Section 7 contains some closing remarks.\n\n2. Preliminaries\nRDF. We follow the notation from [26]. We consider\nthree disjoint sets B (blank nodes), I (IRIs), and L (literals)\nand use the shortcut BIL to denote the union of the sets\nB, I, and L. By convention, we indicate literals by quoted\nstrings (e.g.\"Joe\", \"30\") and prefix blank nodes with \" :\". An\nRDF triple (v1 ,v2 ,v3 ) \u2208 BI \u00d7 I \u00d7 BIL connects subject\nv1 through predicate v2 to object v3 . An RDF database,\nalso called document, is a finite set of triples. We refer the\ninterested reader to [14] for an elaborate discussion of RDF.\n\nOur first condition, called safety, strictly subsumes weak\nacyclicity and the second, safe restriction, strictly subsumes\nstratification. They do not increase the complexity of the\nrecognition problem, i.e. safety is checkable in polynomial\ntime (like weak acyclicity) and safe restriction by a coNPalgorithm (like stratification). We emphasize that our results\nimmediately carry over to data exchange [28] and integration [20], query answering using views [15], and the implica-\n\nSPARQL Syntax. Let V be an infinite set of variables\ndisjoint from BIL. We start with an abstract syntax for\nSPARQL, where we abbreviate operator Optional as Opt.\n2\n\n\fDefinition 1. We define SPARQL expressions recursively\nas follows. (1) A triple pattern t \u2208 BIV \u00d7 IV \u00d7 BILV\nis an expression. (2) Let Q1 , Q2 be expressions and R\na filter condition. Then Q1 Filter R, Q1 Union Q2 ,\nQ1 Opt Q2 , and Q1 And Q2 are expressions.\n\u2737\n\nWe follow the compositional, set-based semantics proposed in [26] and define the result of evaluating SPARQL\nquery Q on document D using operator J.KD defined below.\nDefinition 4. Let t be a triple pattern, Q1 , Q2 SPARQL\nexpressions, R a filter condition, and S \u2282 V a finite set\nof variables. The semantics of SPARQL evaluation over\ndocument D is defined as follows.\n\nIn the remainder of the paper we restrict our discussion\nto safe filter expressions Q Filter R, where the variables\noccurring in R form a subset of the variables in Q. As shown\nin [1], this restriction does not compromise expressiveness.\n\nJtKD := {\u03bc | dom(\u03bc) = vars(t) and \u03bc(t) \u2208 D}\nJQ1 And Q2 KD\n:= JQ1 KD \u2736 JQ2 KD\nJQ1 Opt Q2 KD\n:= JQ1 KD\nJQ2 KD\nJQ1 Union Q2 KD := JQ1 KD \u222a JQ2 KD\nJQ1 Filter RKD := \u03c3R (JQ1 KD )\nJSelectS (Q1 )KD := \u03c0S (JQ1 KD )\n\n1\n\nNext, we define SPARQL queries on top of expressions.1\nDefinition 2. Let Q be a SPARQL expression and let\nS \u2282 V a finite set of variables. A SPARQL query is an\nexpression of the form SelectS (Q).\n\u2737\n\nFinally, we extend the definition of function vars. Let Q\nbe a SPARQL expression, A a SPARQL Algebra expression,\nand R a filter condition. By vars(A), vars(Q), and vars(R)\nwe denote the set of variables in A, Q, and R, respectively.\nFurther, we define function safeVars(A), which denotes the\nsubset of variables in vars(A) that are inevitably bound when\nevaluating A on any document D.\n\nSPARQL Semantics. A mapping is a partial function\nV \u2192 BIL from a subset of variables V to RDF terms BIL.\nThe domain of a mapping \u03bc, written dom(\u03bc), is defined as the\nsubset of V for which \u03bc is defined. As a naming convention,\nwe distinguish variables from elements in BIL through a\nleading question mark symbol. Given two mappings \u03bc1 , \u03bc2 ,\nwe say \u03bc1 is compatible with \u03bc2 if \u03bc1 (?x) = \u03bc2 (?x) for\nall ?x \u2208 dom(\u03bc1 ) \u2229 dom(\u03bc2 ). We write \u03bc1 \u223c \u03bc2 if \u03bc1\nand \u03bc2 are compatible, and \u03bc1 6\u223c \u03bc2 otherwise. Further, we\nwrite vars(t) to denote all variables in triple pattern t and by\n\u03bc(t) we denote the triple pattern obtained when replacing all\nvariables ?x \u2208 dom(\u03bc) \u2229 vars(t) in t by \u03bc(?x).\n\nDefinition 5. Let A be a SPARQL Algebra expression,\nS \u2282 V a finite set of variables, and R a filter condition. We define function safeVars(A) recursively on\nthe structure of expression A as follows.\nsafeVars(JtKD )\n:=\nsafeVars(A1 \u2736 A2 ) :=\nsafeVars(A1 \u222a A2 ) :=\nsafeVars(A1 \\ A2 ) :=\nsafeVars(A1\nA2 ) :=\nsafeVars(\u03c0S (A1 )) :=\nsafeVars(\u03c3R (A1 )) :=\n\nGiven variables ?x, ?y and constants c, d, a filter condition\nR is either an atomic filter condition of the form bound(?x)\n(abbreviated as bnd(?x)), ?x = c, ?x =?y, or a combination\nof atomic conditions using connectives \u00ac, \u2227, \u2228. Condition\nbnd(?x) applied to a mapping set \u03a9 returns all mappings in\n\u03a9 for which ?x is bound, i.e. {\u03bc \u2208 \u03a9 |?x \u2208 dom(\u03bc)}. The\nconditions ?x = c and ?x =?y are equality checks, comparing the values of ?x with c and ?y, respectively. These\nchecks fail whenever one of the variables is not bound. We\nwrite \u03bc |= R if mapping \u03bc satisfies filter condition R (see\nDefinition 16 in Appendix B.2 for a formal definition). The\nsemantics of SPARQL is then formally defined using a compact algebra over mapping sets (cf. [26]). The definition of\nthe algebraic operators join \u2736, union \u222a, set minus \\, left\nouter join\n, projection \u03c0, and selection \u03c3 is given below.\n\n1\n\nDefinition 3. Let \u03a9, \u03a9l , \u03a9r denote mapping sets, R a\nfilter condition, and S \u2282 V a finite set of variables. We\n, \u03c0, and \u03c3:\ndefine the algebraic operations \u2736, \u222a, \\,\n\n1\n\n{\u03bcl \u222a \u03bcr | \u03bcl \u2208 \u03a9l , \u03bcr \u2208 \u03a9r : \u03bcl \u223c \u03bcr }\n{\u03bc | \u03bc \u2208 \u03a9l or \u03bc \u2208 \u03a9r }\n{\u03bcl \u2208 \u03a9l | for all \u03bcr \u2208 \u03a9r : \u03bcl 6\u223c \u03bcr }\n(\u03a9l \u2736 \u03a9r ) \u222a (\u03a9l \\ \u03a9r )\n{\u03bc1 | \u2203\u03bc2 : \u03bc1 \u222a \u03bc2 \u2208 \u03a9 \u2227 dom(\u03bc1 ) \u2286 S\n\u2227 dom(\u03bc2 ) \u2229 S = \u2205}\n:= {\u03bc \u2208 \u03a9 | \u03bc |= R}\n\u2737\n\n\u03a9l \u2736 \u03a9r :=\n\u03a9l \u222a \u03a9r :=\n\u03a9l \\ \u03a9r :=\n\u03a9r:=\n\u03a9l\n\u03c0S (\u03a9) :=\n\u03c3R (\u03a9)\n\nvars(t)\nsafeVars(A1 ) \u222a safeVars(A2 )\nsafeVars(A1 ) \u2229 safeVars(A2 )\nsafeVars(A1 )\nsafeVars(A1 )\nsafeVars(A1 ) \u2229 S\nsafeVars(A1 )\n\u2737\n\nRelational Databases, Constraints and Chase.\nWe assume that the reader is familiar with first-order logic\nand relational databases. We denote by dom(I) the domain of the relational database instance I, i.e. the set of\nconstants and null values that occur in I. The constraints\nwe consider, are tuple-generating dependencies (TGD) and\nequality-generating dependencies (EGD). TGDs have the\nform \u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)) and EGDs have the form\n\u2200x(\u03c6(x) \u2192 xi = xj ). A more exact definition of these\ntypes of constraints can be found in Appendix D.1. In the\nrest of the paper \u03a3 stands for a fixed set of TGDs and EGDs.\nIf an instance I is not a model of some constraint \u03b1, then we\nwrite I 2 \u03b1.\n\n1\n\n1\n\n\u2737\n\nWe now introduce the chase as defined in [8]. A chase\n\u03b1,a\nstep I \u2192 J takes a relational database instance I such that\nI 2 \u03b1(a) and adds tuples (in case of TGDs) or collapses some\nelements (in case of EGDs) such that the resulting relational\ndatabase J is a model of \u03b1(a). If J was obtained from I in\nthat kind, we sometimes also write Ia \u2295 C\u03b1 instead of J. A\nchase sequence is a sequence of relational database instances\nI0 , I1 , ... such that Is+1 is obtained from Is by a chase step.\n\n1\nWe do not consider the remaining SPARQL query forms\nAsk, Construct, and Describe in this paper.\n\n3\n\n\f3. SPARQL Complexity\n\nA chase sequence I0 , ..., In is terminating if In |= \u03a3. In\nthis case, we set I \u03a3 := In as the result (I \u03a3 is defined only\nunique up to homomorphic equivalence, but this will suffice).\nOtherwise, I \u03a3 is undefined. I \u03a3 is also undefined in case the\nchase fails. More details can be found in Appendix D.1.\nThe chase does not always terminate and there has been\ndifferent work on sufficient termination conditions. In [28]\nthe following condition, based on the notion of dependency\ngraph, was introduced. The dependency graph dep(\u03a3) :=\n(V, E) of a set of constraints \u03a3 is the directed graph defined\nas follows. V is the set of positions that occur in \u03a3. There\nare two kind of edges in E. Add them as follows: for every\nTGD \u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)) \u2208 \u03a3 and for every x in x that\noccurs in \u03c8 and every occurrence of x in \u03c6 in position \u03c01\n\nWe introduce operator shortcuts A := And, F := Filter,\nO := Opt, U := Union, and denote the class of expressions that can be constructed using a set of operators by\nconcatenating their shortcuts. Further, by E we denote the\nwhole class of SPARQL expressions, i.e. E := AF OU. The\nterms class and fragment are used interchangeably.\nWe first present a complete complexity study for all possible expression classes, which complements the study in [26].\nWe assume the reader to be familiar with basics of complexity theory, yet summarize the background in Appendix A.1,\nto be self-contained. We follow [26] and take the combined\ncomplexity of the Evaluation problem as a yardstick:\n\n\u2022 for every occurrence of x in \u03c8 in position \u03c02 , add an edge\n\u03c01 \u2192 \u03c02 (if it does not already exist).\n\u2022 for every existentially quantified variable y and for every\noccurrence of y in a position \u03c02 , add a special edge\n\u2217\n\u03c01 \u2192 \u03c02 (if it does not already exist).\n\nEvaluation: given a mapping \u03bc, a document D, and an\nexpression/query Q as input: is \u03bc \u2208 JQKD ?\nThe theorem below summarizes previous results from [26].\nTheorem 1. [26] The Evaluation problem is\n\u2022 in PTime for class AF ; membership in PTime for\nclasses A and F follows immediately,\n\u2022 NP-complete for class AF U, and\n\u2737\n\u2022 PSpace-complete for classes AOU and E.\n\nA set \u03a3 of TGDs and EGDs is called weakly acyclic iff\ndep(\u03a3) has no cycles through a special edge. In [8] weak\nacyclicity was lifted to stratification. Given two TGDs or\nEGDs \u03b1 = \u2200x1 \u03c6, \u03b2 = \u2200x2 \u03c8, we define \u03b1 \u227a \u03b2 (meaning\nthat firing \u03b1 may cause \u03b2 to fire) iff there exist relational\ndatabase instances I, J and a \u2208 dom(I), b \u2208 dom(J) s.t.\n\nOur first goal is to establish a more precise characterization\nof the Union operator. As also noted in [26], its design was\nsubject to controversial discussions in the SPARQL working\ngroup2, and we pursue the goal to improve the understanding\nof the operator and its relation to others, beyond the known\nNP-completeness result for class AF U. The following theorem gives the results for all missing Opt-free fragments.\n\n\u2022 I 2 \u03c8(b) (possibly b is not in dom(I)),\n\u03b1,a\n\n\u2022 I \u2212\u2192 J, and\n\u2022 J 2 \u03c8(b).\nThe chase graph G(\u03a3) = (\u03a3, E) of a set of constraints \u03a3\ncontains a directed edge (\u03b1, \u03b2) between two constraints iff\n\u03b1 \u227a \u03b2. We call \u03a3 stratified iff the set of constraints in every\ncycle of G(\u03a3) are weakly acyclic. It is immediate that weak\nacyclicity implies stratification; further, it was proven in [8]\nthat the chase always terminates for stratified constraint sets.\n\nTheorem 2. The Evaluation problem is\n\u2022 in PTime for classes U and F U, and\n\u2022 NP-complete for class AU.\n\n\u2737\n\nThe hardness part of the NP-completeness proof for fragment AU is a reduction from SetCover. The interested\nreader will find details and other technical results of this\nsection in Appendix A. Theorems 1 and 2 clarify that the\nsource of complexity in Opt-free fragments is the combination of And and Union. In particular, adding or removing\nFilter-expressions in no case affects the complexity.\n\nA Conjunctive Query (CQ) is an expression of the form\nans(x) \u2190 \u03c6(x, z), where \u03c6 is a CQ of relational atoms and\nx, z are tuples of variables and constants. Every variable in\nx must also occur in \u03c6. The semantics of such a query on a\ndatabase instance I is q(I) := { a | I |= \u2203z\u03c6(a, z) }.\nLet q, q \u2032 be CQs and \u03a3 be a set of constraints. We write\nq \u2291\u03a3 q \u2032 if for all database instances I such that I |= \u03a3 it\nholds that q(I) \u2286 q \u2032 (I) and say that q and q \u2032 are \u03a3-equivalent\n(q \u2261\u03a3 q \u2032 ) if q \u2291\u03a3 q \u2032 and q \u2032 \u2291\u03a3 q. In [9] an algorithm was\npresented that, given q and \u03a3, lists all \u03a3-equivalent minimal\n(with respect to the number of atoms in the body) rewritings\n(up to isomorphism) of q. This algorithm, called Chase &\nBackchase, uses the chase and therefore does not necessarily\nterminate. We denote its output by cb\u03a3 (q) (if it terminates).\n\nWe now turn towards an investigation of the complexity of\noperator Opt and its interaction with other operators. The\nPSpace-completeness results for classes AOU and AF OU\nstated in Theorem 1 give only partial answers to the questions.\nOne of the main results in this section is the following.\nTheorem 3. Evaluation is PSpace-complete for O.\u2737\nThis result shows that already operator Opt alone makes\nthe Evaluation problem really hard. Even more, it upgrades the claim in [26] that \"the main source of complexity\nin SPARQL comes from the combination of Union and\n\nGeneral mathematical notation. The natural numbers N do not include 0; N0 is used as a shortcut for N \u222a {0}.\nFor n \u2208 N, we denote by [n] the set {1, ..., n}. Further, for\na set M , we denote by 2M its powerset.\n\n2\nSee the discussion of disjunction in Section 6.1 in\nhttp://www.w3.org/TR/2005/WD-rdf-sparql-query-20050217/.\n\n4\n\n\f4. SPARQL Algebra\n\nOpt operators\", by showing that Union (and And) are not\nnecessary to obtain PSpace-hardness. The intuition of this\n(which is the algebraic\nresult is that the algebra operator\ncounterpart of operator Opt) is defined using operators \u2736,\n\u222a, and \\; the mix of these algebraic operations compensates\nfor missing And and Union operators at syntax level. The\ncorollary below follows from Theorems 1 and 3 and makes\nthe complexity study of the expression fragments complete.\n\n1\n\nWe next present a rich set of algebraic equivalences for\nSPARQL Algebra. In the interest of a complete survey we\ninclude equivalences that have been stated before in [26].3\nOur main contributions in this section are (a) a systematic\nextension of previous rewriting rules, (b) a correction of an\nerratum in [26], and (c) the development and discussion of\nrewriting rules for SPARQL expressions involving negation.\n\nCorollary 1. The Evaluation problem for any expression fragment involving Opt is PSpace-complete. \u2737\n\nWe focus on two fragments of SPARQL algebra, namely\nthe full class of algebra expressions A (i.e., algebra expressions build using operators \u222a, \u2736, \\,\n, \u03c0, and \u03c3) and the\nunion- and projection-free expressions A\u2212 (build using only\noperator \u2736, \\,\n, and \u03c3). We start with a property that\nseparates A\u2212 from A, called incompatibility property.4\n\nDue to the high complexity of Opt, an interesting question\nis whether we can find natural syntactic conditions that lower\nthe complexity of fragments involving Opt. In fact, a restriction of the nesting depth of Opt expressions constitutes such\na condition. We define the Opt-rank r of an expression as its\ndeepest nesting of Opt expressions: for triple pattern t, expressions Q, and condition R, we define r (Q) recursively on\nthe structure of Q as r(t) := 0, r(Q1 Filter R) := r (Q1 ),\nr(Q1 And Q2 )=r (Q1 Union Q2 ) := max (r (Q1 ), r (Q2 )),\nand r(Q1 Opt Q2 ) := max (r (Q1 ), r (Q2 )) + 1.\n\n1\n\n1\n\nProposition 1. Let \u03a9 be the mapping set obtained from\nevaluating an A\u2212 -expression on any document D. All\npairs of distinct mappings in \u03a9 are incompatible. \u2737\nFigure 1(I-IV) surveys rewriting rules that hold with respect to common algebraic laws (we write A \u2261 B if A is\nequivalent to B on any document D). Group I contains\nresults obtained when combining an expression with itself\nusing the different operators. It is interesting to see that (JIdem) and (LIdem) hold only for fragment A\u2212 ; in fact, it\nis the incompatibility property that makes the equivalences\nvalid. The associativity and commutativity rules were introduced in [26] and we list them for completeness. Most\ninteresting is distributivity. We observe that \u2736, \\,\nare\nright-distributive over \u222a, and \u2736 is also left-distributive over\n\u222a. The listing in Figure 1 is complete in the following sense:\n\nBy E \u2264n we denote the class of expressions Q \u2208 E with\nr(Q) \u2264 n. The following theorem shows that, when restricting the Opt-rank of expressions, the Evaluation problem\nfalls into a class in the polynomial hierarchy.\nTheorem 4. For any n \u2208 N0 , the Evaluation problem\nis \u03a3P\n\u2737\nn+1 -complete for the SPARQL fragment E \u2264n .\n\n1\n\nObserve that Evaluation for class E \u22640 is complete for\n\u03a3P\n1 =NP, thus obtaining the result for Opt-free expressions\n(cf. Theorem 1). With increasing nesting-depth of Opt expressions we climb up the polynomial hierarchy (PH). This is\nreminiscent of the Validity-problem for quantified boolean\nformulae, where the number of quantifier alternations fixes\nthe complexity class in the PH. In fact, the hardness proof\n(see Appendix A.3) makes these similarities explicit.\n\n1\n\nLemma 1. Let O1 := { \u2736, \\,\n} and O2 := O1 \u222a {\u222a}.\n\u2022 The two equivalences (JIdem) and (LIdem) in general do not hold for fragments larger than A\u2212 .\n\u2022 Associativity and Commutativity do not hold for\noperators \\ and\n.\n\u2022 Neither \\ nor\nare left-distributive over \u222a.\n\u2022 Let o1 \u2208 O1 , o2 \u2208 O2 , and o1 6= o2 . Then o2 is\nneither left- nor right-commutative over o1 .\n\u2737\n\n1\n\nWe finally extend our study to SPARQL queries, i.e. fragments involving top-level projection in the form of a Select-operator (see Def. 2). We extend the notation for\nclasses as follows. Let F be an expression fragment. We\ndenote by F+ the class of queries of the form SelectS (Q),\nwhere S \u2282 V is a finite set of variables and Q \u2208 F is an expression. The next theorem shows that we obtain (top-level)\nprojection for free in fragments that are at least NP-complete.\n\n1\n\nCases (3) and (4) rule out distributivity for all operator\ncombinations different from those listed in Figure 1. This\nresult implies that Proposition 1(3) in [26] is wrong:\nExample 1. We show that the SPARQL equivalence\n\nTheorem 5. Let C be a complexity class and F a class\nof expressions. If Evaluation is C-complete for F and\nC \u2287 NP then Evaluation is also C-complete for F+ .\u2737\n\nA1 Opt (A2 Union A3 ) \u2261 (A1 Opt A2 ) Union (A1 Opt A3 )\n\nstated in Proposition 1(3) in [26] does not hold in\nthe general case. We choose database D={(0, c, 1)} and\nset A1 =(0, c, ?a), A2 =(?a, c, 1), and A3 =(0, c, ?b). Then\nJA1 Opt (A2 Union A3 )KD = {{?a 7\u2192 1, ?b 7\u2192 1}},\nbut J(A1 Opt A2 ) Union (A1 Opt A3 )KD evaluates to\n{{?a 7\u2192 1}, {?a 7\u2192 1, ?b 7\u2192 1}}. The results differ.\n\u2737\n\nIn combination with Corollary 1 we immediately obtain\nPSpace-completeness for query classes involving operator Opt. Similarly, all Opt-free query fragments involving both And and Union are NP-complete. We conclude\nour complexity analysis with the following theorem, which\nshows that top-level projection makes the Evaluation\nproblem for And-only expressions considerably harder.\n\n3\nMost equivalences in [26] were established at the syntactic\nlevel. In summary, rule (MJ) in Proposition 2 and about\nhalf of the equivalences in Figure 1 are borrowed from [26].\nWe indicate these rules in the proofs in Appendix B.\n4\nLemma 2 in [26] also builds on this observation.\n\nTheorem 6. Evaluation is NP-complete for A+ . \u2737\n5\n\n\fI. Idempotence and Inverse\nA\u222aA\n\u2261A\nA\u2212 \u2736 A\u2212 \u2261 A\u2212\nA\u2212 \u2261 A\u2212\nA\u2212\nA\\A\n\u2261\u2205\n\nV. Filter Decomposition and Elimination\n\u03c3R (A1 \u222a A2 ) \u2261 \u03c3R (A1 ) \u222a \u03c3R (A2 )\n\u03c3R1 \u2227R2 (A)\n\u2261 \u03c3R1 (\u03c3R2 (A))\n\u03c3R1 \u2228R2 (A)\n\u2261 \u03c3R1 (A) \u222a \u03c3R2 (A)\n\u03c3R1 (\u03c3R2 (A)) \u2261 \u03c3R2 (\u03c3R1 (A))\n\n(UIdem)\n(JIdem)\n(LIdem)\n(Inv)\n\n1\n\n\u03c3bnd(?x) (A1 )\n\u03c3bnd(?x) (A1 )\n\u03c3\u00acbnd(?x) (A1 )\n\u03c3\u00acbnd(?x) (A1 )\n\nII. Associativity\n(A1 \u222a A2 ) \u222a A3 \u2261 A1 \u222a (A2 \u222a A3 )\n(A1 \u2736 A2 ) \u2736 A3 \u2261 A1 \u2736 (A2 \u2736 A3 )\n\n(UAss)\n(JAss)\n\nIII. Commutativity\nA1 \u222a A2 \u2261 A2 \u222a A1\nA1 \u2736 A2 \u2261 A2 \u2736 A1\n\n(UComm)\n(JComm)\n\nIV. Distributivity\n(A1 \u222a A2 ) \u2736 A3 \u2261 (A1 \u2736 A3 ) \u222a (A2 \u2736 A3 )\nA1 \u2736 (A2 \u222a A3 ) \u2261 (A1 \u2736 A2 ) \u222a (A1 \u2736 A3 )\n(A1 \u222a A2 ) \\ A3 \u2261 (A1 \\ A3 ) \u222a (A2 \\ A3 )\n(A1 \u222a A2 )\nA3 \u2261 (A1\nA3 ) \u222a (A2\nA3 )\n\n(JUDistR)\n(JUDistL)\n(MUDistR)\n(LUDistR)\n\n1\n\n1\n\n1\n\n\u2261\n\u2261\n\u2261\n\u2261\n\n(SUPush)\n(SDecompI)\n(SDecompII)\n(SReord)\n\nA1 , if ?x \u2208 safeVars(A1 )\n\u2205, if ?x 6\u2208 vars(A1 )\n\u2205, if ?x \u2208 safeVars(A1 )\nA1 , if ?x 6\u2208 vars(A1 )\n\n(BndI)\n(BndII)\n(BndIII)\n(BndIV)\n\n1\n\nIf ?x \u2208 safeVars(A2 ) \\ vars(A1 ), then\n\u03c3bnd(?x) (A1\nA2 ) \u2261 A1 \u2736 A2\n\n(BndV)\n\nVI. Filter Pushing\nThe following rules hold if vars(R) \u2286 safeVars(A1 ).\n\u03c3R (A1 \u2736 A2 ) \u2261 \u03c3R (A1 ) \u2736 A2\n\u03c3R (A1 \\ A2 )\n\u2261 \u03c3R (A1 ) \\ A2\n\u03c3R (A1\nA2 ) \u2261 \u03c3R (A1 )\nA2\n\n1\n\n(SJPush)\n(SMPush)\n(SLPush)\n\n1\n\nFigure 1: SA equivalences for A-expr. A, A1 , A2 , A3 ; A\u2212 -expr. A\u2212 ; filter condition R; variable ?x.\nWe pass on a detailed discussion of operator \u03c0, also because \u2013 when translating SPARQL queries into algebra expression \u2013 this operator appears only at the top-level. Still,\nwe emphasize that also for this operator rewriting rules exist,\ne.g. allowing to project away unneeded variables at an early\nstage. Instead, in the remainder of this section we will present\na thorough discussion of operator \\. The latter, in contrast\nto the other algebraic operations, has no direct counterpart at\nthe syntactic level. This complicates the encoding of queries\ninvolving negation and, as we will see, poses specific challenges to the optimization scheme. We start with the remark\nthat, as shown in [1], operator \\ can always be encoded at\nthe syntactic level through a combination of operators Opt,\nFilter, and bnd. We illustrate the idea by example.\n\nRemark 1. This erratum calls the existence of the union\nnormal form stated in Proposition 1 in [26] into question, as it builds upon the invalid equivalence. We actually do not see how to fix or compensate for this rule,\nso it remains an open question if such a union normal\nform exists or not. The non-existence would put different results into perspective, since \u2013 based on the claim\nthat Union can always be pulled to the top \u2013 the authors restrict the subsequent discussion to Union-free\nexpressions. For instance, results on well-defined patterns, normalization, and equivalence between compositional and operational semantics are applicable only\nto queries that can be brought into union normal form.\nArguably, this class may comprise most of the SPARQL\nqueries that arise in practice (queries without union or\nwith union only at the top-level also constitute very frequent patterns in other query languages, such as SQL).\nStill, a careful reinvestigation would be necessary to extend the results to queries beyond that class.\n\u2737\n\nExample 2. The following SPARQL expression Q1 and\nthe corresponding algebra expression A1 select all persons for which no name is specified in the data set.\nQ1 = Filter\u00acbnd(?n) ((?p, type, P erson) Opt\n((?p, type, P erson) And (?p, name, ?n)))\nA1 = \u03c3\u00acbnd(?n) (J(?p, type, P erson)K\n(J(?p, type, P erson)K \u2736 J(?p, name, ?n)K))\n\n1\n\nFigure 1(V-VI) presents rules for decomposing, eliminating, and rearranging (parts of) filter conditions. In combination with rewriting rules I-IV they provide a powerful framework for manipulating filter expressions in the style of RA filter rewriting and pushing. Most interesting is the use of safeVars as a sufficient precondition for (SJPush), (SMPush),\nand (SLPush).5 The need for this precondition arises from\nthe fact that joins over mappings are accepting for unbound\nvariables. In RA, where joins over null values are rejecting,\nthe situation is less complicated. For instance, given two RA\nrelations A1 , A2 and a (relational) filter R, (SJPush) is applicable whenever the schema of A1 contains all attributes in R.\nWe conclude this discussion with the remark that, for smaller\nfragments of SPARQL conditions, weaker preconditions for\nthe rules in group VI exist. For instance, if R = e1 \u2227 * * * \u2227 en\nis a conjunction of atomic equalities e1 , . . . , en , then the\nequivalences in group VI follow from the (weaker) condition\nvars(R) \u2286 vars(A) \u2227 vars(B) \u2229 vars(R) \u2286 safeVars(A).\n\n\u2737\n\nFrom an optimization point of view it would be desirable to\nhave a clean translation of this constellation using operator \\,\nbut the semantics maps Q1 into A1 , which contains operators\n, \u2736, and predicate bnd, rather than \\. In fact, a better\n\u03c3,\ntranslation (based on \\) exists for a class of practical queries\nand we will provide rewriting rules for such a transformation.\n\n1\n\nProposition 2. Let A1 , A2 be A-expressions and A\u2212\n1 ,\n\u2212\nA\u2212\n1 be A -expressions. The following equivalences hold.\n(A1 \\ A2 ) \\ A3\n(A1 \\ A2 ) \\ A3\nA1 \\ A2\nA\u2212\nA\u2212\n2\n1\n\n1\n\n\u2261\n\u2261\n\u2261\n\u2261\n\n(A1 \\ A3 ) \\ A2\nA1 \\ (A2 \u222a A3 )\nA1 \\ (A1 \u2736 A2 )\n\u2212\nA\u2212\n(A\u2212\n1\n1 \u2736 A2 )\n\n1\n\n(MReord)\n(MMUCorr)\n(MJ)\n(LJ)\n\n\u2737\n\nRules (MReord) and (MMUCorr) are general-purpose\nrewriting rules, listed for completeness. Most important in\nour context is rule (LJ). It allows to eliminate redundant\nsubexpressions in the right side of\n-expressions (for A\u2212\n\n1\n\n5\nA variant of rule (SJPush), restricted to And-only queries,\nhas been stated (at syntax level) in Lemma 1(2) in [26].\n\n6\n\n\f1\n\nWe define the translation C1 (Q) := q, where\n\nexpressions), e.g. the application of (LJ) simplifies A1 to\nJ(?p, name, ?n)K).\nA\u20321 = \u03c3\u00acbnd(?n) (J(?p, type, P erson)K\nThe following lemma allows for further simplification.\n\nq : ans(s) \u2190 T (s1 , p1 , o1 ), . . . , T (sn , pn , on ),\nand s is a vector of variables containing exactly the\nvariables in S. We define C1\u22121 (q) as follows. It takes a\nCQ in the form of q as input and returns Q if it is a valid\nSPARQL query, i.e. if si \u2208 BIV , pi \u2208 IV , oi \u2208 BILV\nfor all i \u2208 [n]; otherwise, C1\u22121 (q) is undefined.\n\u2737\n\n\u2212\n\u2212\nLemma 2. Let A\u2212\n1 , A2 be A -expressions, R a filter\ncondition, and ?x \u2208 safeVars(A2 ) \\ vars(A1 ) a variable.\n\u2212\n\u2212\nThen \u03c3\u00acbnd (?x) (A\u2212\nA\u2212\n\u2737\n1\n2 ) \u2261 A1 \\ A2 holds.\n\n1\n\nThe application of the lemma to query A\u20321 yields the expression A\u2032\u20321 = J(?p, type, P erson)K \\ J(?p, name, ?n)K. Combined with rule (LJ), we have established a powerful mechanism that often allows to make simulated negation explicit.\n\n5.\n\nDefinition 7. Let \u03a3 be a set of RDF constraints, D an\nRDF database, and \u03b1 = \u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)) \u2208 \u03a3.\nWe use h(T (a1 , a2 , a3 )) := a2 (a1 , a3 ) if a2 is not a variable, otherwise\nVn we set it to the empty string.\nVn For a conT\n(a\njunction\n)\nof\natoms,\nwe\nset\nh(\ni\ni=1\ni=1 T (ai )) :=\nVn\nh(T\n(a\n)).\nThen,\nwe\ndefine\nthe\nconstraint\n\u03b1\u2032 as\ni\ni=1\n\u2032\n\u2032\n\u2200x(h(\u03c6(x)) \u2192 \u2203yh(\u03c8(x, y))). We set \u03a3 := {\u03b1 | \u03b1 \u2208 \u03a3}\nif all \u03b1\u2032 are constraints, otherwise \u03a3\u2032 := \u2205.\n\nSemantic SPARQL Query Optimization\n\nThis chapter complements the discussion of algebraic optimization with constraint-based, semantic query optimization\n(SQO). The key idea of SQO is to find semantically equivalent queries over a database that satisfies a set of integrity\nconstraints. These constraints might have been specified by\nthe user, extracted from the underlying database, or hold implicitly when SPARQL is evaluated on RDFS data coupled\nwith an RDFS inference system.6 More precisely, given a\nquery Q and a set of constraints \u03a3 over an RDF database\nD s.t. D |= \u03a3, we want to enumerate (all) queries Q\u2032 that\ncompute the same result on D. We write Q \u2261\u03a3 Q\u2032 if Q\nis equivalent to Q\u2032 on each database D s.t. D |= \u03a3. Following previous approaches [9], we focus on TGDs and\nEGDs, which cover a broad range of practical constraints\nover RDF, such as functional and inclusion dependencies.\nWhen talking about constraints in the following we always\nmean TGDs or EGDs. We refer the interested reader to [19]\nfor motivating examples and a study of constraints for RDF.\nWe represent each constraint \u03b1 \u2208 \u03a3 by a first-order logic\nformula over a ternary relation TD (s, p, o) that stores all\ntriples contained in RDF database D and use T as the corresponding relation symbol. For instance, the constraint\n\u2200x1 , x2 (T (x1 , p1 , x2 ) \u2192 \u2203y1 T (x1 , p2 , y1 )) states that each\nRDF resource with property p1 also has property p2 . Like in\nthe case of conjunctive queries we call a A+ query minimal\nif there is no equivalent A+ query with fewer triple patterns.\n\nLet S \u2282 V be a set of variables, Q \u2208 A+ defined as\nQ = SelectS ((s1 , p1 , o1 ) And ... And (sn , pn , on )),\nand assume that pi is never a variable. We define the\ntranslation C2 (Q) := ans(s) \u2190 p1 (s1 , o1 ), ..., pn (sn , on ),\nwhere vector s contains exactly the variables in S. For\na CQ q: ans(s) \u2190 R1 (x11 , x12 ), ..., Rn (xn1 , xn2 ), we denote by C2\u22121 (q) the expression\nSelectS ((x11 , R1 , x12 ) And ... And (xn1 , Rn , xn2 ))\nif it is a SPARQL query, else C2\u22121 (q) is undefined. \u2737\nC1 (Q) and C1\u22121 (Q) constitute straightforward translations\nfrom SPARQL And-only queries to CQs and back. The definition of C2 (Q) and C2\u22121 (Q) was inspired by the work in [13]\nand is motivated by the observation that in many real-world\nSPARQL queries variables do not occur in predicate position;\nit is applicable only in this context. Given that the second\ntranslation scheme is not always applicable, the reader may\nwonder why we introduced it. The reason is that the translation schemes are different w.r.t. the termination conditions\nfor the subsequent chase that they exhibit. We will come\nback to this issue when discussing termination conditions for\nthe chase in the next section (see Proposition 4).\n\nOur approach relies on the Chase & Backchase (C&B)\nalgorithm for semantic optimization of CQs proposed in [9].\nGiven a CQ q and a set \u03a3 of constraints as input, the algorithm\noutputs all semantically equivalent and minimal q \u2032 \u2261\u03a3 q\nwhenever the underlying chase algorithm terminates. We\ndefer the discussion of chase termination to the subsequent\nsection and use the C&B algorithm as a black box with\nthe above properties. Our basic idea is as follows. First, we\ntranslate And-only blocks (or queries), so-called basic graph\npatterns (BGPs), into CQs and then apply C&B to optimize\nthem. We introduce two alternate translation schemes below.\n\nThe translation schemes, although defined for A+ queries,\ndirectly carry over to A-expressions, i.e. each expression\nQ \u2208 A can be rewritten into the equivalent A+ -expression\nSelectvars(Q) (Q). Coupled with the C&B algorithm, they\nprovide a sound approach to semantic query optimization for\nAnd-only queries whenever the underlying chase algorithm\nterminates, as stated by the following lemma.\nLemma 3. Let Q an A+ -expression, D a database, and\n\u03a3 a set of EGDs and TGDs.\n\u2022 If cb\u03a3 (C1 (Q)) terminates then \u2200Q\u2032 \u2208 A+ :\nQ\u2032 \u2208 C1\u22121 (cb\u03a3 (C1 (Q))) \u21d2 Q\u2032 \u2261\u03a3 Q and Q\u2032 minimal.\n\u2022 If C2 (Q) is defined, |\u03a3\u2032 | = |\u03a3| and cb\u03a3\u2032 (C2 (Q)) terminates then so does cb\u03a3 (C1 (Q)).\n\u2022 If C2 (Q) is defined, |\u03a3\u2032 | = |\u03a3| and cb\u03a3\u2032 (C2 (Q)) terminates then \u2200Q\u2032 \u2208 A+ :\nQ\u2032 \u2208 C1\u22121 (cb\u03a3 (C1 (Q))) \u21d2 Q\u2032 \u2261\u03a3 Q.\n\u2737\n\nDefinition 6. Let S \u2282 V be a finite set of variables and\nQ \u2208 A+ be a SPARQL query defined as\nQ = SelectS ((s1 , p1 , o1 ) And . . . And (sn , pn , on )).\n6\nNote that the SPARQL semantics disregards RDFS inference, but assumes that it is realized in a separate layer.\n\n7\n\n\f\u2022 If Q1 \u2261\u03a3 Selectvars(Q1 ) (Q1 And Q2 ) then\nJFilter\u00acbnd(?x) (Q1 Opt Q2 )KD = \u2205.\n\nThe converse direction in bullets one and three does not\nhold in general, i.e. the scheme is not complete. Before we\naddress this issue, we illustrate the problem by example.\n\n\u2022 If SelectS (Q2 ) \u2261\u03a3 SelectS (Q2 ?x\n?y ) then\nSelectS (Filter?x=?y (Q2 )) \u2261\u03a3 SelectS (Q2 ?x\n?y ).\n\n\u2032 \u2032\n\nExample 3. Let the two expressions Q1 := (?x, b, l ),\nQ2 := (?x, b,\u2032 l\u2032 ) And (?x, a, c), and let the constraint\n\u2200x1 , x2 , x3 (T (x1 , x2 , x3 ) \u2192 T (x3 , x2 , x1 )) be given. By\ndefinition, there are no RDF databases that contain a\nliteral in a predicate position because, according to the\nconstraint, such a literal would also occur in the subject\nposition, which is not allowed. Therefore, the answer\nto both expressions Q1 and Q2 is always the empty set,\nwhich implies Q1 \u2261\u03a3 Q2 . But it is easy to verify that\nC1 (Q1 ) \u2261\u03a3 C1 (Q2 ) does not hold. The reason for this\ndiscrepancy is that the universal plan [9] of the queries\nis not a valid SPARQL query.\n\u2737\n\n\u2022 If SelectS (Q2 ) \u2261\u03a3 SelectS (Q2 ?x\n?y ) then\nJFilter\u00ac?x=?y (Q2 )KD = \u2205.\n\n\u2737\n\nWe conclude this section with some final remarks. First,\nwe note that semantic optimization strategies are basically\northogonal to algebraic optimizations,hence both approaches\ncan be coupled with each other. For instance, we might\nget better optimization results when combining the rules for\nfilter decomposition and pushing in Figure 1(V-VI) with the\nsemantic rewriting rules for filter expressions in the lemma\nabove. Second, as discussed in [9], the C&B algorithm can\nbe enhanced by a cost function, which makes it easy to factor\nin cost-based query optimization approaches for SPARQL,\ne.g. in the style of [23]. This flexibility strengthens the\nprospectives and practicability of our semantic optimization\nscheme. The study of rewriting heuristics and the integration\nof a cost function, though, is beyond the scope of this paper.\n\nWe formalize this observation in the next lemma, i.e. provide a precondition that guarantees completeness.7 For a\nCQ q, we denote by U (q) its universal plan [9], namely the\nconjunctive query q \u2032 obtained from q by chasing its body.\nLemma 4. Let D be a database and Q an A+ -expression\nsuch that C1\u22121 (U (C1 (Q))) \u2208 A+ .\n\u2022 If cb\u03a3 (C1 (Q)) terminates then \u2200Q\u2032 \u2208 A+ such that\nC1\u22121 (U (C1 (Q\u2032 ))) \u2208 A+ :\nQ\u2032 \u2208 C1\u22121 (cb\u03a3 (C1 (Q))) \u21d4 Q\u2032 \u2261\u03a3 Q and Q\u2032 minimal.\n\u2022 If C2 (Q) is defined, |\u03a3\u2032 | = |\u03a3| and cb\u03a3\u2032 (C2 (Q)) terminates then \u2200Q\u2032 \u2208A+ s.t. C1\u22121 (U (C1 (Q\u2032 ))) \u2208 A+ :\nQ\u2032 \u2208 C1\u22121 (cb\u03a3 (C1 (Q))) \u21d4 Q\u2032 \u2261\u03a3 Q and Q\u2032 minimal.\u2737\n\n6. Chase Termination\nThe applicability of the C&B algorithm, and hence of our\nSQO scheme presented in the previous section, depends on\nthe termination of the underlying chase algorithm. Given\nan arbitrary set of constraints it is in general undecidable if\nthe chase terminates for every database instance [8]; still, in\nthe past several sufficient termination conditions have been\npostulated [16, 10, 9, 28, 8]. The strongest sufficient conditions known so far are weak acyclicity [28], which was\nstrictly generalized to stratification in [8], raising the recognition problem from P to coNP. Our SQO approach on top\nof the C&B algorithm motivated a reinvestigation of these\ntermination conditions, and as a key result we present two\nnovel chase termination conditions for the classical framework of relational databases, which empower virtually all\napplications that rely on the chase. Whenever we mention a database or a database instance in this section, we\nmean a relational database. We will start our discussion\nwith a small example run of the chase algorithm. The basic idea is simple: given a database and a set of constraints\nas input, it fixes constraint violations in the database instance. Consider for example database {R(a, b)} and constraint \u2200x1 , x2 (R(x1 , x2 ) \u2192 \u2203yR(x2 , y)). The chase first\nadds R(b, y1 ) to the instance, where y1 is a fresh null value.\nThe constraint is still violated, because y1 does not occur\nin the first position of an R-tuple. So, the chase will add\nR(y1 , y2 ), R(y2 , y3 ), R(y3 , y4 ), . . . in subsequent steps,\nwhere y2 , y3 , y4 , . . . are fresh null values. Obviously, the\nchase algorithm will never terminate in this toy example.\n\nBy now we have established a mechanism that allows us to\nenumerate equivalent queries of SPARQL And-only queries,\nor BGPs inside queries. Next, we provide extensions that go\nbeyond And-only queries. The first rule in the following\nlemma shows that sometimes Opt can be replaced by And;\ninformally spoken, it applies when the expression in the Opt\nclause is implied by the constraints. The second rule can be\nused to eliminate redundant BGPs in Opt-subexpressions.\nLemma 5. Let Q1 , Q2 , Q3 \u2208 A and S \u2282 V a finite set\nof variables.\n\u2022 If Q1 \u2261\u03a3 Selectvars(Q1 ) (Q1 And Q2 ) then\nQ1 Opt Q2 \u2261\u03a3 Q1 And Q2 .\n\u2022 If Q1 \u2261\u03a3 Q1 And Q2 then\n(Q1 Opt (Q2 And Q3 )) \u2261\u03a3 Q1 Opt Q3 .\n\u2737\nNote that the preconditions are always expressed in terms\nof And-only queries and projection, thus can be checked\nusing our translation schemes and the C&B algorithm. We\nconclude our discussion of SQO with a lemma that gives\nrules for the elimination of redundant filter expressions.\nLemma 6. Let Q1 , Q2 \u2208 A, S \u2282 V \\{?y} a set of variables, ?x, ?y \u2208 vars(Q2 ), \u03a3 a set of constraints, and D\na documents s.t. D |= \u03a3. Further let Q2 ?x\n?y be obtained\nfrom Q2 by replacing each occurrence of ?y by ?x.\n\nFigure 2 summarizes the results of this section and puts\nthem into context. First, we will introduce the novel class\nof safe constraints, which guarantees the termination of the\nchase. It strictly subsumes weak acyclicity, but is different\nfrom stratification. Building upon the definition of safety, we\n\n7\n\nWe might expect that situations as the one sketched in Example 3 occur rarely in practice, so the condition in Lemma 4\nmay guarantee completeness in most practical scenarios.\n\n8\n\n\fFigure 3: Left: Dependency graph. Right: Corresponding propagation graph (it has no edges).\nFigure 2: Chase termination conditions.\nsubsumes [4] nor the other way around. Like in the case of\nweak acyclicity, we define the safety condition with the help\nof the absence of cycles containing special edges in some\ngraph. We call this graph propagation graph.\n\nthen present safely restricted constraints as a consequent advancement of our ideas. The latter class strictly subsumes all\nremaining termination conditions known so far. Finally, we\nwill show that, based on our framework, we can easily define\nanother class called safely stratified constraints, which is\nstrictly contained in the class of safely restricted constraints,\nbut also subsumes weak acyclicity and safeness.\n\nDefinition 9. Given a set of TGDs \u03a3, the propagation\ngraph prop(\u03a3) := (aff(\u03a3), E) is the directed graph defined as follows. There are two kinds of edges in E. Add\nthem as follows: for every TGD \u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)) \u2208\n\u03a3 and for every x in x that occurs in \u03c8 and every occurrence of x in \u03c6 in position \u03c01\n\u2022 if x occurs only in affected positions in \u03c6 then, for\nevery occurrence of x in \u03c8 in position \u03c02 , add an\nedge \u03c01 \u2192 \u03c02 (if it does not already exist).\n\u2022 if x occurs only in affected positions in \u03c6 then, for\nevery existentially quantified variable y and for every occurrence of y in a position \u03c02 , add a special\n\u2217\n\u2737\nedge \u03c01 \u2192 \u03c02 (if it does not already exist).\n\nSafe Constraints. The basic idea of the first termination condition is to keep track of positions a newly introduced\nlabeled null may be copied to. Consider for instance constraint R(x1 , x2 , x3 ), S(x2 ) \u2192 \u2203yR(x2 , y, x1 ), which is not\nweakly acyclic. Its dependency graph is depicted in Figure\n3 (left). As illustrated in the toy example in the beginning\nof this section, a cascading of labeled nulls (i.e. new labeled\nnull values that are created over and over again) may cause a\nnon-terminating chase sequence. However, we can observe\nthat for the constraint above such a cascading of fresh labeled\nnulls cannot occur, i.e. no fresh labeled null can repeatedly\ncreate new labeled nulls in position R2 while copying itself\nto position R1 . The reason is that the constraint cannot be\nviolated with a fresh labeled null in R2 , i.e. if R(a1 , a2 , a3 )\nand S(a2 ) hold, but \u2203yR(a2 , y, a1 ) does not, then a2 is never\na newly created labeled null. This is due to the fact that a2\nmust also occur in relation S, which is not modified when\nchasing only with this single constraint. Consequently, the\nchase sequence always terminates. We will later see that this\nis not a mere coincidence: the constraint is safe.\n\nDefinition 10. A set \u03a3 of constraints is called safe iff\nprop(\u03a3) has no cycles going through a special edge. \u2737\n\nDefinition 8. [4] Let \u03a3 be a set of TGDs. The set of\naffected positions aff(\u03a3) of \u03a3 is defined inductively as\nfollows. Let \u03c0 be a position in the head of an \u03b1 \u2208 \u03a3.\n\nThe intuition of these definitions is that we forbid an unrestricted cascading of null values, i.e. with the help of the\npropagation graph we impose a partial order on the affected\npositions such that any newly introduced null value can only\nbe created in a position that has a higher rank in that partial\norder in comparison to null values that may occur in the body\nof a TGD. To state this more precisely, assume a TGD of the\nform \u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)) is violated. Then, I |= \u03c6(a)\nand I 2 \u2203y\u03c8(a, y)) must hold. The safety condition ensures\nthat any position in the body that has a newly created labeled\nnull from a in itself and also occurs in the head of the TGD\nhas a strictly lower rank in our partial order than any position\nin which some element from y occurs. The main difference\nin comparison to weak acyclicity is that we look in a refined\nway (see affected positions) on where a labeled null can be\npropagated to. We note that given a set of constraints it can\nbe decided in polynomial time whether it is safe.\n\n\u2022 If an existentially quantified variable appears in \u03c0,\nthen \u03c0 \u2208 aff(\u03a3).\n\u2022 If the same universally quantified variable X appears both in position \u03c0, and only in affected positions in the body of \u03b1, then \u03c0 \u2208 aff(\u03a3).\n\u2737\n\nExample 4. Consider the TGD R(x1 , x2 , x3 ), S(x2 ) \u2192\n\u2203yR(x2 , y, x1 ) from before. The dependency graph is\ndepicted in Figure 3 on the left side and its propagation\ngraph on the right side. The only affected position is\nR2 . From the respective definitions it follows that this\nconstraint is safe, but not weakly acyclic.\n\u2737\n\nAlthough we borrow this definition from [4] our focus is\ndifferent. We extend known classes of constraints for which\nthe chase terminates. The focus in [4] is on query answering\nin cases the chase may not terminate. Our work neither\n\nNote that if \u03a3 is safe, then every subset of \u03a3 is safe, too.\nWe will now compare safety to other termination conditions.\nIn the example, the propagation graph is a subgraph of the\ndependency graph. This is not a mere coincidence.\n\nTo formally define safety, we first introduce the notion of\naffected positions. Intuitively, a position is affected if, during\nthe application of the chase, a newly introduced labeled null\ncan be copied or created in it. Thus, the set of affected\npositions is an overestimation of the positions in which a\nnull value that was introduced during the chase may occur.\n\n9\n\n\fDefinition 13. A restriction system is a pair (G\u2032 (\u03a3), f ),\nwhere G\u2032 (\u03a3) := (\u03a3, E) is a directed graph and f : \u03a3 \u2192\n2pos(\u03a3) is a function such that\n\u2022 forall TGDs \u03b1 and forall (\u03b1, \u03b2) \u2208 E:\naff-cl(\u03b1, f (\u03b1)) \u2229 pos({\u03b2}) \u2286 f (\u03b2),\n\u2022 forall EGDs \u03b1 and forall (\u03b1, \u03b2) \u2208 E:\nf (\u03b1) \u2229 pos({\u03b2}) \u2286 f (\u03b2), and\n\u2022 forall \u03b1, \u03b2 \u2208 \u03a3: \u03b1 \u227af (\u03b1) \u03b2 =\u21d2 (\u03b1, \u03b2) \u2208 E.\n\u2737\n\nTheorem 7. Let \u03a3 be a set of constraints.\n\u2022 Then, prop(\u03a3) is a subgraph of dep(\u03a3). It holds\nthat if \u03a3 is weakly acyclic, then it is also safe.\n\u2022 There is some \u03a3 that is safe, but not stratified.\n\u2022 There is some \u03a3 that is stratified, but not safe. \u2737\nThe next result shows that safety guarantees termination\nwhile retaining polynomial time data complexity.\nTheorem 8. Let \u03a3 be a fixed set of safe constraints.\nThen, there exists a polynomial Q \u2208 N[X] such that for\nany database instance I, the length of every chase sequence is bounded by Q(||I||), where ||I|| is the number\nof distinct values in I.\n\u2737\n\nWe illustrate this definition by an example. It also shows\nthat restriction systems always exist.\nExample 5. Let \u03a3 a set of constraints. Then, (G(\u03a3), f ),\nwhere f (\u03b1) := pos({\u03b1}) for all \u03b1 \u2208 \u03a3 is a restriction\nsystem for \u03a3.\n\u2737\n\nSafely Restricted Constraints. In this section we\ngeneralize the method of stratification from [8] to a condition\nwhich we call safe restriction. The chase graph from [8]\nwill be a special case of our new notion. We then define\nthe notion of safe restriction and show that the chase always\nterminates for constraints obeying it.\n\nBased on the novel technical notion of restriction systems\nwe can easily define a new class of constraints.\nDefinition 14. \u03a3 is called safely restricted if and only if\nthere is a restriction system (G\u2032 (\u03a3), f ) for \u03a3 such that\nevery strongly connected component in G\u2032 (\u03a3) is safe. \u2737\n\nLet \u03b1 := S(x2 , x3 ), R(x1 , x2 , x3 ) \u2192 \u2203yR(x2 , y, x1 ) and\n\u03b2 := R(x1 , x2 , x3 ) \u2192 S(x1 , x3 ). It can be seen that \u03b1 \u227a \u03b2\nand \u03b2 \u227a \u03b1. Further, {\u03b1, \u03b2} is not weakly acyclic, so it\nfollows that {\u03b1, \u03b2} is not stratified. Still, the chase will\nalways terminate: A firing of \u03b1 may cause a null value to\nappear in position R2 , but a firing of \u03b2 will never introduce\nnull values in the head of \u03b2 although \u03b2 \u227a \u03b1 holds. This is\nthe key observation for the upcoming definitions. First, we\nwill refine the relation \u227a from [8]. This refinement helps us\nto detect if during the chase null values might be copied to\nthe head of some constraint. Let pos(\u03a3) denote the set of\npositions that occur in the body of some constraint in \u03a3.\n\nThe next theorem shows that safe restriction strictly extends the notion of stratification and safety.\nTheorem 9. If \u03a3 is stratified or safe, then it is also safely\nrestricted. There is some \u03a3 that is safely restricted but\nneither safe nor stratified.\n\u2737\nDefinition 14 implies that safely restricted constraints can\nbe recognized by a \u03a3P\n2 -algorithm. However, with the help\nof a canonical restriction system, we can show that safe\nrestriction can be decided in coNP (like stratification).\nTheorem 10. Given constraint set \u03a3 it can be checked\nby a coNP-algorithm whether \u03a3 is safely restricted. \u2737\n\nDefinition 11. Let \u03a3 a set of constraints and P \u2286 pos(\u03a3).\nFor all \u03b1, \u03b2 \u2208 \u03a3, we define \u03b1 \u227aP \u03b2 iff there are tuples\na, b and a database instance I s.t.\n\u2022 I 2 \u03b1(a),\n\u2022 \u03b2 is not applicable on b and I,\n\u2022 Ia \u2295 C\u03b1 2 \u03b2(b),\n\u2022 null values in I occur only in positions from P , and\n\u2022 the firing of \u03b2 in the case of bullet three copies some\n\u2737\nnull value from Ia \u2295 C\u03b1 to the head of \u03b2.\n\nThe next theorem is the main contribution of this section.\nIt states that the chase will always terminate in polynomial\ntime data complexity for safely restricted constraints.\nTheorem 11. Let \u03a3 be a fixed set of safely restricted\nconstraints. Then, there exists a polynomial Q \u2208 N[X]\nsuch that for any database instance I, the length of\nevery chase sequence is bounded by Q(||I||), where ||I||\nis the number of distinct values in I.\n\u2737\n\nWe next introduce a notion for affected positions relative\nto a constraint and a set of positions.\n\nTo the best of our knowledge safe restriction is the most\ngeneral sufficient termination condition for TGDs and EGDs.\nWe finally compare the chase graph to restriction systems.\nThe reader might wonder what happens if we substitute weak\nacyclicity with safety in the definition of stratification (in the\npreliminaries).\n\nDefinition 12. For any set of positions P and tgd \u03b1 let\naff-cl(\u03b1, P ) be the set of positions \u03c0 from the head of \u03b1\nsuch that either\n\u2022 the variable in \u03c0 occurs in the body of \u03b1 only in\npositions from P or\n\u2022 \u03c0 contains an existentially quantified variable.\n\u2737\n\nDefinition 15. We call \u03a3 safely stratified iff the constraints in every cycle of G(\u03a3) are safe.\n\u2737\n\nThe latter definition and the refinement of \u227a will help us\nto define the notion of a restriction system, which is a strict\ngeneralization of the chase graph introduced in [8].\n\nWe obtain the following result, showing that with the help\nof restriction systems, we strictly extended the method of the\nchase graph from [8].\n10\n\n\f8. References\n\nTheorem 12. Let \u03a3 be a set of constraints.\n\u2022 If \u03a3 is weakly acyclic or safe, then it is safely stratified.\n\u2022 If \u03a3 is safely stratified, then it is safely restricted.\n\u2022 There is some set of constraints that is safely restricted, but not safely stratified.\n\u2737\n\n[1] R. Angles and C. Guti\u00e9rrez. The Expressive Power of\nSPARQL. In ISWC, pages 114\u2013129, 2008.\n[2] S. Arora and B. Barak. Computational Complexity: A\nModern Approach. Cambridge University Press, 2007.\n[3] C. Beeri and M. Y. Vardi. A Proof Procedure for Data\nDependencies. J. ACM, 31(4):718\u2013741, 1984.\n\nNote that we used safety instead of safe stratification in\nthe definition of safe restrictedness although safely stratified\nconstraints are the provably larger class. This is due to the\nfact that safety is easily checkable and would not change the\nclass of constraints. The next proposition clarifies this issue.\n\n[4] A. Cal\u0131\u0300, G. Gottlob, and M. Kifer. Taming the Infinite\nChase: Query Answering under Expressive Relational\nConstraints. In Descr. Logics, volume 353, 2008.\n[5] U. S. Chakravarthy, J. Grant, and J. Minker. Logic-based\nApproach to Semantic Query Optimization. TODS,\n15(2):162\u2013207, 1990.\n\nProposition 3. \u03a3 is safely restricted iff there is a restriction system (G\u2032 (\u03a3), f ) for \u03a3 such that every strongly\nconnected component in G\u2032 (\u03a3) is safely stratified. \u2737\n\n[6] R. Cyganiac. A relational algebra for SPARQL. Technical\nReport, HP Laboratories Bristol, 2005.\n[7] D. Abadi et al. Scalable Semantic Web Data Management\nUsing Vertical Partitioning. In VLDB, pages 411\u2013422, 2007.\n\nIn the previous section we proposed two SPARQL translation schemes and it is left to explain why we introduced two\nalternative schemes. The next proposition states that the two\nschemes behave differently with respect to safe restriction.\n\n[8] A. Deutsch, A. Nash, and J. Remmel. The Chase Revisited.\nIn PODS, pages 149\u2013158, 2008.\n[9] A. Deutsch, L. Popa, and V. Tannen. Query Reformulation\nwith Constraints. SIGMOD Record, 35(1):65\u201373, 2006.\n[10] A. Deutsch and V. Tannen. XML queries and constraints,\ncontainment and reformulation. Theor. Comput. Sci.,\n336(1):57\u201387, 2005.\n\nProposition 4. Let \u03a3 be a non-empty set of constraint\nset over a ternary relation symbol T .\n\u2022 There is some \u03a3 that is safely restricted, but \u03a3\u2032 = \u2205,\ni.e. the second translation scheme is not applicable.\n\u2022 There is some \u03a3 such that |\u03a3| = |\u03a3\u2032 | and \u03a3\u2032 is safely\nrestricted, but \u03a3 is not.\n\u2737\n\n[11] F. Bry et al. Foundations of Rule-based Query Answering.\nIn Reasoning Web, pages 1\u2013153, 2007.\n[12] G. H. L. Fletcher and P. W. Beck. A Role-free Approach to\nIndexing Large RDF Data Sets in Secondary Memory for\nEfficient SPARQL Evaluation. CoRR, abs/0811.1083, 2008.\n\nReferring back to Lemma 3, this means we might check\nboth \u03a3 or \u03a3\u2032 for safe restrictedness, and can guarantee termination of the chase if at least one of them is safely restricted.\n\n[13] G. Serfiotis et al. Containment and Minimization of RDF/S\nQuery Patterns. In ISWC, pages 607\u2013623, 2005.\n\n7.\n\n[15] A. Y. Halevy. Answering Queries Using Views: A Survey.\nVLDB Journal, pages 270\u2013294, 2001.\n\n[14] C. Guti\u00e9rrez, C. A. Hurtado, and A. O. Mendelzon.\nFoundations of Semantic Web Databases. In PODS, pages\n95\u2013106, 2004.\n\nConclusion\n\n[16] D. S. Johnson and A. Klug. Testing Containment of\nConjunctive Queries under Functional and Inclusion\nDependencies. In PODS, pages 164\u2013169, 1982.\n\nWe have discussed several facets of the SPARQL query\nlanguage. Our complexity analysis extends prior investigations [26] and (a) shows that the combination of And\nand Union is the main source of complexity in Opt-free\nSPARQL fragments and (b) clarifies that yet operator Opt\nalone makes SPARQL evaluation PSpace-complete. We\nalso show that, when restricting the nesting depth of Optexpressions, we obtain better complexity bounds.\n\n[17] J. J. King. QUIST: a system for semantic query\noptimization in relational databases. In VLDB, pages\n510\u2013517, 1981.\n[18] L. Sidirourgos et al. Column-store Support for RDF Data\nManagement: not all swans are white. In VLDB, pages\n1553\u20131563, 2008.\n[19] G. Lausen, M. Meier, and M. Schmidt. SPARQLing\nConstraints for RDF. In EDBT, pages 499\u2013509, 2008.\n\nThe subsequent study of SPARQL Algebra lays the foundations for transferring established Relational Algebra optimization techniques into the context of SPARQL. Additionally, we considered specifics of the SPARQL query language,\nsuch as rewriting of SPARQL queries involving negation.\nThe algebraic optimization approach is complemented by a\npowerful framework for semantic query optimization. We\nargue that a combination of both algebraic and semantic\noptimization will push the limits of existing SPARQL implementations and leave the study of a schematic rewriting\napproach and good rewriting heuristics as future work.\n\n[20] M. Lenzerini. Data Integration: A Theoretical Perspective.\nIn PODS, pages 233\u2013246, 2002.\n[21] M. Schmidt et al. An Experimental Comparison of RDF\nData Management Approaches in a SPARQL Benchmark\nScenario. In ISWC, pages 82\u201397, 2008.\n[22] M. Schmidt et al. SP2 Bench: A SPARQL Performance\nBenchmark. In ISWC, 2009.\n[23] M. Stocker et al. SPARQL Basic Graph Pattern\nOptimization Using Selectivity Estimation. In WWW, 2008.\n[24] D. Maier, A. Mendelzon, and Y. Sagiv. Testing Implications\nof Data Dependencies. In SIGMOD, pages 152\u2013152, 1979.\n\nFinally, our results on chase termination empower the practicability of SPARQL query optimization in the presence of\nconstraints and directly carry over to other applications that\nrely on the chase, such as [28, 20, 15, 9].\n\n[25] T. Neumann and G. Weikum. RDF-3X: a RISC-style\nengine for RDF. PVLDB, 1(1):647\u2013659, 2008.\n[26] J. P\u00e9rez, M. Arenas, and C. Guti\u00e9rrez. Semantics and\nComplexity of SPARQL. CoRR, cs/0605124, 2006.\n\n11\n\n\f[27] A. Polleres. From SPARQL to Rules (and back). In WWW,\npages 787\u2013796, 2007.\n\nAPPENDIX\n\n[28] R. Fagin et al. Data Exchange: Semantics and Query\nAnswering. Theor. Comput. Sci., 336(1):89\u2013124, 2005.\n\nA.\n\n[29] Semantic Web Challenge. Billion triples dataset.\nhttp://www.cs.vu.nl/~ pmika/swc/btc.html.\n[30] L. J. Stockmeyer. The polynomial-time hierarchy. Theor.\nComput. Sci., 3:1\u201322, 1976.\n\nProofs of the Complexity Results\n\nThis section contains the complexity proofs of the Evaluation problem for the fragments studied in Section 3. We\nrefer the interested reader to [26] for the proof of Theorem 1.\nWe start with some basics from complexity theory.\n\n[31] C. Weiss, P. Karras, and A. Bernstein. Hexastore: Sextuple\nIndexing for Semantic Web Data Management. In VLDB,\npages 1008\u20131019, 2008.\n\nA.1 Background from Complexity Theory\nComplexity Classes. As usual, we denote by PTime\n(or P, for short) the complexity class comprising all problems\nthat can be decided by a deterministic Turing Machine (TM)\nin polynomial time, by NP the set of problems that can be\ndecided by a non-deterministic TM in polynomial time, and\nby PSpace the class of problems that can be decided by a\ndeterministic TM within polynomial space bounds.\nThe Polynomial Hierarchy\nGiven a complexity class C we denote by coC the set of\ndecision problems whose complement can be decided by a\nTM in class C. Given complexity classes C1 and C2 , the\n2\nclass CC\n1 captures all problems that can be decided by a TM\nM1 in class C1 enhanced by an oracle TM M2 for solving\nproblems in class C2 . Informally, engine M1 can use M2\nto obtain a yes/no-answer for a problem in C2 in a single\nstep. We refer the interested reader to [2] for a more formal\ndiscussion of oracle machines. Finally, we define the classes\nP\n\u03a3P\ni and \u03a0i recursively as\nP\n\n\u03a3n\nP\nP\n, and put\n\u03a3P\n0 = \u03a00 :=P and \u03a3n+1 :=NP\n\u03a3P\nP\n\u03a0n+1 :=coNP n .\n\nThe polynomial hierarchy PH [30] is then defined as\nPH =\n\nS\n\ni\u2208N0\n\n\u03a3P\ni\n\nP\nP\nP\nIt is folklore that \u03a3P\ni = co\u03a0i , and that \u03a3i \u2286 \u03a0i+1\nP\nP\nand \u03a0i \u2286 \u03a3i+1 holds. Moreover, the following inclusion\nP\nhierarchies for \u03a3P\ni and \u03a0i are known.\nP\nP\nP = \u03a3P\n0 \u2286 NP = \u03a31 \u2286 \u03a32 \u2286 * * * \u2286 PSPACE, and\nP\nP\nP = \u03a00 \u2286 coNP = \u03a01 \u2286 \u03a0P\n2 \u2286 * * * \u2286 PSPACE.\n\nComplete Problems\nWe consider completeness only with respect to polynomialtime many-one reductions. QBF, the tautology test for quantified boolean formulas, is known to be PSpace-complete\n[2]. Forms of QBF with restricted quantifier alternation are\nP\ncomplete for classes \u03a0P\ni or \u03a3i depending on the question if\nthe first quantified of the formula is \u2200 or \u2203. A more thorough\nintroduction to complete problems in the polynomial hierarchy can be found in [2]. Finally, the NP-completeness of\nthe SetCover-problem and the 3Sat-problem is folklore.\n12\n\n\fA.2\n\nFinally we define the SPARQL expression\n\nOPT-free Fragments (Theorem 2)\n\nP := PS And . . . And PS ,\nwhere PS appears exactly k times.\n\nFragment U: UNION (Theorem 2(1))\nFor a Union-only expression P and data set D it suffices\nto check if \u03bc \u2208 JtKD for any triple pattern t in P . This can\neasily be achieved in polynomial time.\u2737\n\nIt is straightforward to show that SetCover is true if\nand only if \u03bc = {?U1 7\u2192 1, . . . , ?Uk 7\u2192 1} \u2208 JP KD . The\nintuition of the encoding is as follows. PS encodes all subsets\nSi . A set element, say x, is represented in SPARQL by a\nmapping from variable ?X to value 1. The encoding of P\nallows us to merge (at most) k arbitrary sets Si . We finally\ncheck if the universe U can be constructed this way.\u2737\n\nFragment F U: FILTER + UNION (Theorem 2(1))\nWe present a PTime-algorithm that solves the Evaluation\nproblem for this fragment. It is defined on the structure of\nthe input expression P and returns true if \u03bc \u2208 JP KD , false\notherwise. We distinguish three cases. (a) If P = t is\na triple pattern, we return true if and only if \u03bc \u2208 JtKD .\n(b) If P = P1 Union P2 we (recursively) check if \u03bc \u2208\nJP1 KD \u2228 \u03bc \u2208 JP2 KD holds. (c) If P = P1 Filter R for\nany filter condition R we return true if and only if \u03bc \u2208\nJP1 KD \u2227 R |= \u03bc. It is easy to see that the above algorithm\nruns in polynomial time. Its correctness follows from the\ndefinition of the algebraic operators \u222a and \u03c3.\u2737\n\nRemark 2. The proof above relies on the fact that mapping \u03bc is part of the input of the Evaluation problem.\nIn fact, when fixing \u03bc the resulting (modified) version\nof the Evaluation problem can be solved in PTime.\u2737\nA.3 Fragments Including Operator OPT\nWe now discuss several fragments including Opt. One\ngoal here is to show that fragment O is PSpace-complete\n(c.f. Theorem 3); PSpace-completeness for all fragments\ninvolving Opt then follows (cf. Corollary 1). Given the\nPSpace-completeness results for fragment E = AF OU , it\nsuffices to prove hardness for all smaller fragments; membership is implicit. Our road map is as follows.\n\nFragment AU: AND + UNION (Theorem 2(2))\nIn order to show that Evaluation for this fragment is NPcomplete we have to show membership and hardness.\nMembership in NP. Let P be a SPARQL expression\ncomposed of operators And and Union, D a document,\nand \u03bc a mapping. We provide an NP-algorithm that returns\ntrue if \u03bc \u2208 JP KD , and false otherwise. Our algorithm is\ndefined on the structure of P . (a) If P = t return true if\n\u03bc \u2208 JtKD , false otherwise. (b) If P = P1 Union P2 , we\nreturn the truth value of \u03bc \u2208 JP1 KD \u2228 \u03bc \u2208 JP2 KD . (c) If\nP = P1 And P2 , we guess a decomposition \u03bc = \u03bc1 \u222a \u03bc2\nand return the truth value of \u03bc1 \u2208 JP1 KD \u2227 \u03bc2 \u2208 JP2 KD .\nCorrectness of the algorithm follows from the definition of\nthe algebraic operators \u2736 and \u222a. It can easily be realized by\na non-deterministic TM that runs in polynomial time, which\nproves membership in NP.\n\n1. We first show PSpace-hardness for fragment AF O.\n2. We then show PSpace-hardness for fragment AO.\n3. Next, a rewriting of operator And by Opt is presented,\nwhich can be used to eliminate all And operators in\nthe proof of (2). PSpace-completeness for O then is\nshown using this rewriting rule.\n4. Finally, we prove Theorem 4, i.e. show that fragment\nE \u2264n is \u03a3P\nn+1 -complete, making use of part (1).\nFragment AF O: AND + FILTER + OPT\n\nNP-Hardness. We reduce the SetCover problem to the\nEvaluation problem for SPARQL (in polynomial time).\nSetCover is known to be NP-complete, so the reduction\ngives us the desired hardness result.\n\nWe present a (polynomial-time) reduction from QBF to\nEvaluation for fragment AF O. The QBF problem is\nknown to be PSpace-complete, so this reduction gives us the\ndesired PSpace-hardness result. Membership in PSpace,\nand hence PSpace-completeness, then follows from Theorem 1(3). QBF is defined as follows.\n\nThe decision version of SetCover is defined as follows.\nLet U = {u1 , . . . , uk } be a universe, S1 , . . . Sn \u2286 U be\nsets over U , and let k be positiveSinteger. Is there a set\nI \u2286 {1, . . . , n} of size | I |\u2264 k s.t. i\u2208I Si = U ?\n\nQBF: given a quantified boolean formula of the form\n\nWe use the fixed database D := {(a, b, 1)} for our encoding and represent each set Si = {x1 , x2 , . . . , xm } by a\nSPARQL expression of the form\n\n\u03c6 = \u2200x1 \u2203y1 \u2200x2 \u2203y2 . . . \u2200xm \u2203ym \u03c8,\nwhere \u03c8 is a quantifier-free boolean formula,\nas input: is \u03c6 valid?\n\nPSi := (a, b, ?X1 ) And . . . And (a, b, ?Xm ).\nThe following proof was inspired by the proof of Theorem 3 in [26]: we encode the inner formula \u03c8 using And\nand Filter, and then adopt the translation scheme for the\nquantifier sequence \u2200\u2203\u2200\u2203 . . . proposed in [26].\n\nThe set S = {S1 , . . . , Sn } of all Si is then encoded as\nPS := PS1 Union . . . Union PSn .\n13\n\n\fIt can be shown that \u03bc = {?B0 7\u2192 1} \u2208 JP\u03c6 KD iff \u03c6 is\nvalid, which completes the reduction. We refer the reader to\nthe proof of Theorem 3 in [26] for this part of the proof.\u2737\n\nFirst note that, according to the problem statement, \u03c8 is a\nquantifier-free boolean formula. We assume w.l.o.g. that \u03c8\nis composed of \u2227, \u2228 and \u00ac.8 We use the fixed database\n\nRemark 3. The proof for this fragment (AF O) is subsumed by the subsequent proof, which shows PSpacehardness for a smaller fragment. It was included to\nillustrate how to encode quantifier-free boolean formulas that are not in CNF. Some of the following proofs\nbuild upon this construction.\n\u2737\n\nD := {(a, tv, 0), (a, tv, 1), (a, false, 0), (a, true, 1)}\nand denote by V = {v1 , . . . vl } the set of variables appearing in \u03c8. Formula \u03c8 then is encoded as\nP\u03c8 :=((a, tv, ?V1 ) And (a, tv, ?V2 ) And . . .\nAnd (a, tv, ?Vl )) Filter f (\u03c8),\n\nFragment AO: AND + OPT\nWe reduce the QBF problem to Evaluation for class AO.\nWe encode a quantified boolean formula of the form\n\nwhere f (\u03c8) is a function that generates a SPARQL condition that mirrors the boolean formula \u03c8. More precisely, f is\ndefined recursively on the structure of \u03c8 as\nf(vi )\nf(\u03c81 \u2227 \u03c82 )\nf(\u03c81 \u2228 \u03c82 )\nf(\u00ac\u03c81 )\n\n:=\n:=\n:=\n:=\n\n\u03c6 = \u2200x1 \u2203y1 \u2200x2 \u2203y2 . . . \u2200xm \u2203ym \u03c8,\n\n?Vi = 1\nf(\u03c81 ) \u2227 f(\u03c82 )\nf(\u03c81 ) \u2228 f(\u03c82 )\n\u00ac f(\u03c81 )\n\nwhere \u03c8 is a quantifier-free formula in conjunctive normal\nform (CNF), i.e. \u03c8 is a conjunction of clauses\n\u03c8 = C1 \u2227 * * * \u2227 Cn ,\n\nIn our encoding P\u03c8 , the And-block generates all possible\nvaluations for the variables, while the Filter-expression\nretains exactly those valuations that satisfy formula \u03c8. It is\nstraightforward to show that \u03c8 is satisfiable if and only if\nthere exists a mapping \u03bc \u2208 JP\u03c8 KD and, moreover, for each\nmapping \u03bc \u2208 JP\u03c8 KD there is a truth assignment \u03c1\u03bc defined\nas \u03c1\u03bc (x) = \u03bc(?X) for all variables ?Xi , ?Yi \u2208 dom(\u03bc)\nsuch that \u03bc \u2208 JP\u03c8 KD if and only if \u03c1\u03bc satisfies \u03c8. Given\nP\u03c8 , we can encode the quantifier-sequence using a series of\nnested Opt statements as shown in [26]. To make the proof\nself-contained, we shortly summarize this construction.\n\nwhere the Ci , 1 \u2264 i \u2264 n, are disjunctions of literals.9\nBy V we denote the variables in \u03c8 and by VCi the variables\nappearing in clause Ci (either as positive of negative literals).\nWe use the following database, which is polynomial in the\nsize of the query.\nD :={(a, tv, 0), (a, tv, 1), (a, false, 0), (a, true, 1)} \u222a\n{(a, vari , v) | v \u2208 VCi } \u222a {(a, v, v) | v \u2208 V }\nFor each Ci = v1 \u2228 * * * \u2228 vj \u2228 \u00acvj+1 \u2228 * * * \u2228 \u00acvk , where the\nv1 . . . vj are positive and the vj+1 . . . vk are negated variables\n(contained in VCi ), we define a separate SPARQL expression\n\nSPARQL variables ?X1 , . . . , ?Xm and ?Y1 , . . . Ym are\nused to represent variables x1 , . . . xm and y1 , . . . , ym , respectively. In addition to these variables, we use fresh variables ?A0 , . . .?Am , ?B0 , . . .?Bm , and operators And and\nOpt to encode the quantifier sequence \u2200x1 \u2203y1 . . . \u2200xm \u2203ym .\nFor each i \u2208 [m] we define two expressions Pi and Qi\n\nPCi :=(. . . ((. . . (\n(a, vari , ?vari )\nOpt ((a, v1 , ?vari ) And (a, true, ?V1 )))\n...\nOpt ((a, vj , ?vari ) And (a, true, ?Vj )))\nOpt ((a, vj+1 , ?vari ) And (a, f alse, ?Vj+1 )))\n...\nOpt ((a, vk , ?vari ) And (a, f alse, ?Vk )))\n\nPi := ((a, tv, ?X1 ) And . . . And (a, tv, ?Xi ) And\n(a, tv, ?Y1 ) And . . . And (a, tv, ?Yi\u22121 ) And\n(a, false, ?Ai\u22121 ) And (a, true, ?Ai )),\nQi := ((a, tv, ?X1 ) And . . . And (a, tv, ?Xi ) And\n(a, tv, ?Y1 ) And . . . And (a, tv, ?Yi ) And\n(a, false, ?Bi\u22121 ) And (a, true, ?Bi )),\n\nand encode formula \u03c8 as\n\nand encode P\u03c6 as\n\nP\u03c8 := PC1 And . . . And PCn .\n\nP\u03c6 := ((a, true, ?B0 )\nOpt (P1 Opt (Q1\nOpt (P2 Opt (Q2\n...\nOpt (Pm Opt (Qm And P\u03c8 )) . . . )))))\n\nIt is straightforward to verify that \u03c8 is satisfiable if and\nonly if there is a mapping \u03bc \u2208 JP\u03c8 KD and, moreover, for\neach \u03bc \u2208 JP\u03c8 KD there is a truth assignment \u03c1\u03bc defined as\n\u03c1\u03bc (x) = \u03bc(?X) for all variables ?Xi , ?Yi \u2208 dom(\u03bc) such\nthat \u03bc \u2208 JP\u03c8 KD if and only if \u03c1\u03bc satisfies \u03c8. Now, given\n9\n\nIn the previous proof (for fragment AFO) there was no\nsuch restriction for formula \u03c8. Still, it is known that QBF is\nalso PSpace-complete when restricting to formulae in CNF.\n\n8\n\nIn [26] \u03c8 was additionally restricted to be in CNF. We relax\nthis restriction here.\n\n14\n\n\fFragment O: OPT-only (Theorem 3)\n\nP\u03c8 , we encode the quantifier-sequence using only operators\nOpt and And, as shown in the previous proof for fragment\nAF O. For the resulting encoding P\u03c6 , it analogously holds\nthat \u03bc = {?B0 7\u2192 1} \u2208 JP\u03c6 KD iff \u03c6 is valid.\u2737\n\nWe start with a transformation rule for operator And; it\nessentially expresses the key idea of the subsequent proof.\nLemma 7. Let\n\u2022 Q, Q1 , Q2 , . . . , Qn (n \u2265 2) be SPARQL expressions,\n\u2022 S = vars(Q )\u222avars(Q1 )\u222avars(Q2 )\u222a* * *\u222avars(Qn ),\ndenote the set of variables in Q, Q1 , Q2 , . . . , Qn\n\u2022 D = {(a, true, 1), (a, f alse, 0), (a, tv, 0), (a, tv, 1)}\nbe a fixed database,\n\u2022 ?V2 , ?V3 , . . . , ?Vn be a set of n \u2212 1 fresh variables,\ni.e. S \u2229 {?V2 , ?V3 , . . . , ?Vn } = \u2205 holds.\nFurther, we define\n\nWe provide a small example that illustrates the translation\nscheme for QBF presented in in the proof above.\nExample 6. We show how to encode the QBF\n\u03c6 = \u2200x1 \u2203y1 (x1 \u21d4 y1 )\n= \u2200x1 \u2203y1 ((x1 \u2228 \u00acy1 ) \u2227 (\u00acx1 \u2228 y1 )),\nwhere \u03c8 = ((x1 \u2228 \u00acy1 ) \u2227 (\u00acx1 \u2228 y1 )) is in CNF. It\nis easy to see that the QBF formula \u03c6 is a tautology.\nThe variables in \u03c8 are V = {x1 , y1 }; further, we have\nC1 = x1 \u2228 \u00acy1 , C2 = \u00acx1 \u2228 y1 , and VC1 = VC2 = V =\n{x1 , y1 }. Following the construction in the proof we set\nup the database\n\nQ\u2032 :=((. . . ((Q Opt V2 ) Opt V3 ) . . . ) Opt Vn ),\nQ\u2032\u2032 :=((. . . ((Q1 Opt (Q2 Opt V2 ))\nOpt (Q3 Opt V3 ))\n...\nOpt (Qn Opt Vn ))),\nVi :=(a, true, ?Vi ), and\nV i :=(a, f alse, ?Vi ).\n\nD := {(a, tv, 0), (a, tv, 1), (a, false, 0), (a, true, 1),\n(a, var1 , x1 ), (a, var1 , y1 ), (a, var2 , x1 ),\n(a, var2 , y1 ), (a, x1 , x1 ), (a, y1 , y1 )}\nand define expression P\u03c8 = PC1 And PC2 , where\n\nThe following claims hold.\n\nPC1 :=((a, var1 , ?var1 )\nOpt ((a, x1 , ?var1 ) And (a, true, ?X1 )))\nOpt ((a, y1 , ?var1 ) And (a, f alse, ?Y1 ))\nPC2 :=((a, var2 , ?var2 )\nOpt ((a, y1 , ?var2 ) And (a, true, ?Y1 )))\nOpt ((a, x1 , ?var2 ) And (a, f alse, ?X1 )).\n\n(1) JQ\u2032 KD = {\u03bc \u222a {?V2 7\u2192 1, . . . , ?Vn 7\u2192 1} | \u03bc \u2208 JQKD },\n(2) JQ\u2032 Opt (Q1 And Q2 And . . . And Qn )KD\n= JQ\u2032 Opt (. . . ((Q\u2032\u2032 Opt V 2 )\nOpt V 3 )\n...\nOpt V n )KD\n\u2737\n\nWhen evaluating these expressions we get:\n\n1\n\nThe second part of the lemma provides a way to rewrite an\nAnd-only expression that is encapsulated in the right side\nof an Opt-expression by means of an Opt-only expression.\nBefore proving the lemma, we illustrate the construction by\nmeans of a small example.\n\nJPC1 KD = ({{?var1 7\u2192 x1 }, {?var1 7\u2192 y1 }}\n{{?var1 7\u2192 x1 , ?X1 7\u2192 1}})\n{{?var1 7\u2192 y1 , ?Y1 7\u2192 0}}\n= {{?var1 7\u2192 x1 , ?X1 7\u2192 1}, {?var1 7\u2192 y1 , ?Y1 7\u2192 0}}\n\n1\n\n1\n\nJPC2 KD = {{?var2 7\u2192 x1 }, {?var2 7\u2192 y1 }}\n{{?var2 7\u2192 y1 , ?Y1 7\u2192 1}}\n{{?var2 7\u2192 x1 , ?X1 7\u2192 0}}\n= {{?var2 7\u2192 x1 , ?X1 7\u2192 0}, {?var2 7\u2192 y2 , ?Y2 7\u2192 1}}\n\nExample 7. Let D be the database given in the previous\nlemma and consider the expressions\n\n1\n\nQ := (a, tv, ?a)\n,i.e. JQKD = {{?a 7\u2192 0}, {?a 7\u2192 1}}\nQ1 := (a, true, ?a) ,i.e. JQ1 KD= {{?a 7\u2192 1}}\nQ2 := (a, f alse, ?b) ,i.e. JQ2 KD= {{?b 7\u2192 0}}\n\nJP\u03c8 KD = JPC1 And PC2 KD\n= {{?var1 7\u2192 x1 , ?var2 7\u2192 y1 , ?X1 7\u2192 1, ?Y1 7\u2192 1},\n{?var1 7\u2192 y1 , ?var2 7\u2192 x1 , ?X1 7\u2192 0, ?Y1 7\u2192 0}}\n\nAs for the part (1) of the lemma we observe that\nJQ\u2032 KD = JQ Opt V2 KD\n= JQ Opt (a, true, ?V2 )KD\n= {{?a 7\u2192 0, ?V2 7\u2192 1}, {?a 7\u2192 1, ?V2 7\u2192 1}}.\n\nFinally, we set up the expressions P1 and Q1 , as described in the proof for fragment AOF\nP1 := ((a, tv, ?X1 ) And (a, false, ?A0 )\nAnd (a, true, ?A1 ))\nQ1 := ((a, tv, ?X1 ) And (a, tv, ?Y1 )\nAnd (a, false, ?B0 ) And (a, true, ?B1 ))\n\nConcerning part (2) it holds that the left side\nJQ\u2032 Opt (Q1 And Q2 )KD\n= JQ\u2032 KD\n{{?a 7\u2192 1, ?b 7\u2192 0}}\n= {{?a 7\u2192 0, ?V2 7\u2192 1}, {?a 7\u2192 1, ?b 7\u2192 0, ?V2 7\u2192 1}}\n\n1\n\nand encode the quantified boolean formula \u03c6 as\n\nis equal to the right side\n\nP\u03c6 := (a, true, ?B0 ) Opt (P1 Opt (Q1 And P\u03c8 ))\n\nJQ\u2032 Opt ((Q1 Opt (Q2 Opt V2 )) Opt V2 )KD\n= JQ\u2032 KD\n({{?a 7\u2192 1, ?b 7\u2192 0, ?V2 7\u2192 1}}\nJV2 KD )\n= JQ\u2032 KD\n{{?a 7\u2192 1, ?b 7\u2192 0, ?V2 7\u2192 1}}\n= {{?a 7\u2192 0, ?V2 7\u2192 1}, {?a 7\u2192 1, ?b 7\u2192 0, ?V2 7\u2192 1}}.\u2737\n\n1\n1\n\nWe leave it as an exercise to verify that the mapping\n\u03bc = {?B0 7\u2192 1} is contained in JP\u03c6 KD . This result\nconfirms that the original formula \u03c8 is valid.\n\u2737\n15\n\n1\n\n\fJQ\u2032 Opt RKD\n= JQ\u2032 Opt (Q1 And QV2 And QV3 And . . . And QVn )KD\n= JQ\u2032 Opt (Q1 And Q2 And Q3 And . . . And Qn )KD\n\nProof of Lemma 7. We omit some technical details,\nbut instead give the intuition of the encoding. (1) The first\nclaim follows trivially from the definition of Q\u2032 , the observations that each Vi evaluates to {{?Vi 7\u2192 1}}, and the\nfact that all ?Vi are unbound in Q\u2032 (recall that, by assumption, the ?Vi are fresh variables). To prove (2), we consider the evaluation of the right side expression, in order to\nshow that it yields the same result as the left side. First\nconsider subexpression Q\u2032\u2032 and observe that the result of\nevaluating Qi Opt Vi is exactly the result of evaluating Qi\nextended by the binding ?Vi 7\u2192 1. In the sequel, we use\nQVi as an abbreviation for Qi Opt Vi , i.e. we denote Q\u2032\u2032 as\n((. . . ((Q1 Opt QV2 ) Opt QV3 ) Opt . . . ) Opt QVn ). Applying semantics, we can rewrite JQ\u2032\u2032 KD into the form\n\nThus, we have shown that the equivalence holds. This\ncompletes the proof. \u2737\nGiven Lemma 7 we are now in the position to prove\nPSpace-completeness for fragment O. As in previous\nproofs it suffices to show hardness; membership follows as\nbefore from the PSpace-completeness of fragment E.\n\nJQ\u2032\u2032 KD\n= J((. . . ((Q1 Opt QV2 ) Opt QV3 ) Opt . . . ) Opt QVn )KD\n= J(Q1 And QV2 And QV3 And . . . And QVn )KD \u222a PD ,\n\nThe proof idea is the following. We show that, in the\nprevious reduction from QBF to Evaluation for fragment\nAO, each And expression can be rewritten using only Opt\noperators. We start with a QBF of the form\n\u03c6 = \u2200x1 \u2203y1 \u2200x2 \u2203y2 . . . \u2200xm \u2203ym \u03c8,\nwhere \u03c8 is a quantifier-free formula in conjunctive normal\nform (CNF), i.e. \u03c8 is a conjunction of clauses\n\nwhere we call the left subexpression of the union join\npart, and PD at the right side is an algebra expression (over\ndatabase D) with the following property: for each mapping\n\u03bc \u2208 PD there is at least one ?Vi (2 \u2264 i \u2264 n) s.t. ?Vi 6\u2208\ndom(\u03bc). We observe that, in contrast, for each mapping\nin the join part dom(\u03bc) \u2287 {?V2 , . . . , ?Vn } holds and, even\nmore, \u03bc(?Vi ) = 1, for 2 \u2264 i \u2264 n. Hence, the mappings in\nthe result of the join part are identified by the property that\n?V2 , ?V3 , . . . , ?Vn are all bound to 1.\n\n\u03c8 = C1 \u2227 * * * \u2227 Cn ,\nwhere the Ci , 1 \u2264 i \u2264 n, are disjunctions of literals.\nBy V we denote the set of variables inside \u03c8 and by VCi\nthe variables appearing in clause Ci (either in positive of\nnegative form) and use the same database as in the proof for\nfragment AO, namely\n\nLet us next consider the evaluation of the larger expression\n(on the right side of the original equation)\n\nD :={(a, tv, 0), (a, tv, 1), (a, false, 0), (a, true, 1)} \u222a\n{(a, vari , v) | v \u2208 VCi } \u222a {(a, v, v) | v \u2208 V }\n\nR := ((. . . ((Q\u2032\u2032 Opt V 2 ) Opt V 3 ) Opt . . . ) Opt V n )).\n\nThe first modification of the proof for class AO concerns\nthe encoding of clauses Ci = v1 \u2228* * *\u2228vj \u2228\u00acvj+1 \u2228* * *\u2228\u00acvk ,\nwhere the v1 . . . vj are positive and vj+1 . . . vk are negated\nvariables. In the prior encoding we used both And and Opt\noperators to encode them. It is easy to see that we can simply replace each And operator there through Opt without\nchanging semantics. The reason is that, for all subexpressions A Opt B in the encoding, it holds that vars(A) \u2229\nvars(B) = \u2205 and JBKD 6= \u2205; hence, all mappings in A are\ncompatible with all mappings in B and there is at least one\nmapping in B. When applying this modification, we obtain\nthe following O-encoding for clauses Ci .\n\nWhen evaluating R, we obtain exactly the mappings from\nJQ\u2032\u2032 KD , but each mapping \u03bc \u2208 JQ\u2032\u2032 KD is extended by bindings ?Vi 7\u2192 0 for all ?Vi 6\u2208 dom(\u03bc) (cf. the argumentation\nin for claim (1)). As argued before, all mappings in the join\npart of Q\u2032\u2032 are complete in the sense that all ?Vi are bound,\nso these mappings will not be affected. The remaining mappings (i.e. those originating from PD ) will be extended by\nbindings ?Vi 7\u2192 0 for at least one ?Vi . The resulting situation\ncan be summarized as follows: all mappings resulting from\nthe join part of Q\u2032\u2032 bind all variables ?Vi to 1; all mappings\nin PD bind all ?Vi , but at least one of them is bound to 0.\n\nPCi :=(. . . ((. . . (\n(a, vari , ?vari )\nOpt ((a, v1 , ?vari ) Opt (a, true, ?V1 )))\n...\nOpt ((a, vj , ?vari ) Opt (a, true, ?Vj )))\nOpt ((a, vj+1 , ?vari ) Opt (a, f alse, ?Vj+1 )))\n...\nOpt ((a, vk , ?vari ) Opt (a, f alse, ?Vk ))),\n\nFrom part (1) we know that each mapping in JQ\u2032 KD maps\nall ?Vi to 1. Hence, when computing JQ\u2032 Opt RKD =\nJQ\u2032 KD\nJRKD , the bindings ?Vi 7\u2192 1 for all \u03bc \u2208 JQ\u2032 KD\nserves as a filter that removes the mappings in JRKD originating from PD . This means\n\n1\n\nJQ\u2032 Opt RKD\nJRKD\n= JQ\u2032 KD\n= JQ\u2032 KD\nJ(Q1 And QV2 And QV3 And . . . And QVn )KD\nLet us next consider the Pi and Qi used for simulating\n\u2032\n= JQ Opt (Q1 And QV2 And QV3 And . . . And QVn )KD . the quantifier alternations. The original definition of these\nexpression was given in the proof for fragment AF O. With\na similar argumentation as before we can replace each ocEven more, we observe that all ?Vi are already bound in\ncurrence of operator And through Opt without changing\nQ\u2032 (all of them to 1), so the following rewriting is valid.\n\n1\n1\n\n16\n\n\fbe an RDF database and F = \u2200x1 \u2203y1 . . . \u2200xm \u2203ym \u03c8\n(m \u2265 1) be a QBF, where \u03c8 is a quantifier-free boolean\nformula. There is an E \u22642m encoding enc(F ) of F s.t.\n1. F is valid exactly if {?B0 7\u2192 1} \u2208 Jenc(F )KD\n2. F is invalid exactly if all mappings \u03bc\u2032 \u2208 Jenc(F )KD\nare of the form \u03bc\u2032 = \u03bc\u20321 \u222a \u03bc\u20322 , where \u03bc\u20321 \u223c \u03bc\u20322 and\n\u2737\n\u03bc\u20321 = {?B0 7\u2192 1, ?A1 7\u2192 1}.\n\nthe semantics of the whole expression. This results in the\nfollowing O encodings for Pi and Qi , i \u2208 [m].\nPi := ((a, tv, ?X1 ) Opt . . . Opt (a, tv, ?Xi ) Opt\n(a, tv, ?Y1 ) Opt . . . Opt (a, tv, ?Yi\u22121 ) Opt\n(a, false, ?Ai\u22121 ) Opt (a, true, ?Ai ))\nQi := ((a, tv, ?X1 ) Opt . . . Opt (a, tv, ?Xi ) Opt\n(a, tv, ?Y1 ) Opt . . . Opt (a, tv, ?Yi ) Opt\n(a, false, ?Bi\u22121 ) Opt (a, true, ?Bi )),\n\nProof: The lemma follows from the PSpace-hardness\nproof for fragment AF O, where we have shown how to\nencode QBF for a (possibly non-CNF) inner formula \u03c8.\u2737\nLemma 9. Let A and B SPARQL expressions for which\nthe evaluation problem is in \u03a3P\ni , i \u2265 1, and let R a\nFilter condition. The following claims hold.\n1. The Evaluation problem for the SPARQL expression A Union B is in \u03a3P\ni .\n2. The Evaluation problem for the SPARQL expression A And B is in \u03a3P\ni .\n3. The Evaluation problem for the SPARQL expression A Filter R is in \u03a3P\n\u2737\ni .\n\nIn the underlying proof for AO, the conjunction \u03c8 is\nencoded as PC1 And . . . And PCn , thus we have not yet\neliminated all And-operators. We shortly summarize what\nwe have achieved so far:\nP\u03c6 := ((a, true, ?B0 )\nOpt (P1 Opt (Q1\n...\nOpt (Pm\u22121 Opt (Qm\u22121\nOpt (P \u2032 ))) . . . ))), where\nP \u2032 = Pm Opt (Qm And (P\u03c8 ))\n= Pm Opt (Qm And PC1 And . . . And PCn )\n\nProof: 1. According to the SPARQL semantics we have\nthat \u03bc \u2208 JA Union BK if and only if \u03bc \u2208 JAK or \u03bc \u2208 JBK.\nBy assumption, both conditions can be checked individually\nin \u03a3P\ni , and so can both checks in sequence.\n\nNote that P \u2032 is the only expression that still contains And\noperators (where Qm , PC1 , . . . , PCn are already And-free).\nWe now exploit the rewriting given in Lemma 7. In particular,\nwe replace P \u2032 in P\u03c6 by the expression P\u2217\u2032 defined as\nP\u2217\u2032 := Q\u2032 Opt\n((. . . ((Q\u2032\u2032 Opt V 2 ) Opt V 3 ) Opt . . . ) Opt V n+1 )),\nwhere\nQ\u2032 :=((. . . ((Pm Opt V2 ) Opt V3 ) . . . ) Opt Vn+1 ),\nQ\u2032\u2032 :=((. . . ((Qm Opt (PC1 Opt V2 ))\nOpt (PC2 Opt V3 ))\n...\nOpt (PCn Opt Vn+1 ))),\nVi :=(a, true, ?Vi ),\nV i :=(a, f alse, ?Vi ),\nand the ?Vi (i \u2208 {2, . . . , n + 1}) are fresh variables.\n\n2. It is easy to see that \u03bc \u2208 JA And BK iff \u03bc can\nbe decomposed into two compatible mappings \u03bc1 and \u03bc2\ns.t. \u03bc = \u03bc1 \u222a \u03bc2 and \u03bc1 \u2208 JAK and \u03bc2 \u2208 JBK. By assumption, testing \u03bc1 \u2208 JAK (\u03bc2 \u2208 JBK) is in \u03a3P\ni . Since i \u2265 1,\nthis complexity class is at least \u03a3P\n1 = NP. So we can guess\na decomposition \u03bc = \u03bc1 \u222a \u03bc2 and test for the two conditions\none after the other. Hence, the whole procedure is in \u03a3P\ni .\n3. \u03bc \u2208 JA Filter RK holds iff \u03bc \u2208 JAK, which can be\ntested in \u03a3P\n1 by assumption, and R satisfies \u03bc, which can be\ntested in polynomial time. Since \u03a3P\ni \u2287 NP \u2287 P for i \u2265 1,\nthe whole procedure is still in \u03a3P\n.\u2737\ni\nWe are now ready to prove Theorem 4. The proof divides\ninto two parts, i.e. hardness and membership. The hardness proof is a reduction from QBF with a fixed number of\nquantifier alternations. Second, we prove by induction on\nthe Opt-rank that there exists a \u03a3P\nn+1 -algorithm to solve the\nEvaluation problem for E \u2264n expressions.\n\nThe resulting P\u03c6 is now an O-expression. From Lemma 7\nit follows that the result of evaluating P\u2217\u2032 is obtained from\nthe result of P \u2032 by extending each mapping in P \u2032 by additional variables, more precisely by {?V2 7\u2192 1, ?V3 7\u2192\n1, . . . , ?Vn+1 7\u2192 1}, i.e. the results are identical modulo\nthis extension. It is straightforward to verify that these additional bindings do not harm the construction, i.e. it holds\nthat {?B0 7\u2192 1} \u2208 JP\u03c6 KD iff \u03c6 is valid.\u2737\n\nHardness. We consider a QBF of the form\n\u03c6 = \u2203x0 \u2200x1 \u2203x2 . . . Qxn \u03c8,\nwhere n \u2265 1, Q = \u2203 if n is even, Q = \u2200 if n is odd,\nand \u03c8 is a quantifier-free boolean formula. It is known that\nthe Validity problem for such formulae is \u03a3P\nn+1 -complete.\nWe now present a (polynomial-time) reduction from the Validity problem for these quantified boolean formulae to\nthe Evaluation problem for the E \u2264n fragment, to prove\n\u03a3P\nn+1 -hardness. We distinguish two cases.\n\n\u03a3P\nn+1 -completeness of Fragment E \u2264n (Theorem 4)\nWe start with two lemmas that will be used in the proof.\nLemma 8. Let\n\nCase 1: Let Q = \u2203, so the formula is of the form\n\nD = {(a, tv, 0), (a, tv, 1), (a, true, 1), (a, f alse, 0)}\n17\n\n\fvalid (since otherwise, there is a compatible mapping for \u03bc\u2032 ,\nnamely {?B0 7\u2192 1} in Jenc(F1 ) Union enc(F2 )KD ). In\nsummary, this means \u03bc\u2032 \u2208 JQKD if and only if \u00ac(F1\u2032 \u2228 F2\u2032 ) =\nF \u2032 holds. Since both enc(F1 ) and enc(F2 ) are E \u22642m expressions, Q is contained in E \u22642m+1 , so (*) holds.\n\nF = \u2203y0 \u2200x1 \u2203y1 . . . \u2200xm \u2203ym \u03c8.\nThe formula F has 2m + 1 quantifier alternations, so we\nneed to find an E \u22642m encoding for this expressions. We\nrewrite F into an equivalent formula F = F1 \u2228 F2 , where\n\nMembership. We next prove membership of E \u2264n expressions in \u03a3P\nn+1 by induction on the Opt-rank. Let us assume\nthat for each E \u2264n expression (n \u2208 N0 ) Evaluation is in\nP\n\u03a3P\nn+1 . As stated in Theorem 1(2), Evaluation is \u03a31 =\nNP-complete for Opt-free expressions, so the hypothesis\nholds for the basic case. In the induction step we increase\nthe Opt-rank from n to n + 1.\n\nF1 = \u2200x1 \u2203y1 . . . \u2200xm \u2203ym (\u03c8 \u2227 y0 ), and\nF2 = \u2200x1 \u2203y1 . . . \u2200xm \u2203ym (\u03c8 \u2227 \u00acy0 ).\nAccording to Lemma 8 there is a fixed document D and\nE \u22642m encodings enc(F1 ) and enc(F2 ) (for F1 and F2 , respectively) s.t. Jenc(F1 )KD (Jenc(F2 )KD ) contains the mapping \u03bc = {?B0 7\u2192 1} if and only if F1 (F2 ) is valid. Then the\nexpression enc(F ) = enc(F1 ) Union enc(F2 ) contains \u03bc\nif and only if F1 or F2 is valid, i.e. iff F is valid. Clearly,\nenc(F ) is an E \u22642m expression, so enc(F ) constitutes the\ndesired E \u22642m encoding of the Evaluation problem.\n\nWe distinguish several cases, depending on the structure\nof the expression, say A, with Opt-rank n + 1.\nCase 1: Checking if \u03bc \u2208 JA Opt BK. First note that\nA Opt B is in E \u2264n+1 , and from the definition of Opt-rank\nr it follows immediately that both A and B are in E \u2264n .\nHence, by induction hypothesis, both A and B can be evaluated in \u03a3P\nn+1 . By semantics, we have that JA Opt BK =\nJA And BK \u222a (JAK \\ JBK), so \u03bc is in JA Opt BK iff it is\ngenerated by the (a) left or (b) right side of the union. Following Lemma 9, part (a) can be checked in \u03a3P\nn+1 . (b) The\nmore interesting part is to check if \u03bc \u2208 JAK \\ JBK. According to the semantics of operator \\, this check can be\nformulated as C = C1 \u2227 C2 , where C1 = \u03bc \u2208 JAK and\nC2 = \u00ac\u2203\u03bc\u2032 \u2208 JBK : \u03bc and \u03bc\u2032 are compatible. By induction hypothesis, C1 can be checked in \u03a3P\nn+1 . We argue that\nalso \u00acC2 = \u2203\u03bc\u2032 \u2208 JBK : \u03bc and \u03bc\u2032 are compatible can be\n\u2032\nevaluated in \u03a3P\nn+1 : we can guess a mapping \u03bc (in NP), then\nP\ncheck if \u03bc \u2208 JBK (in \u03a3n+1 ), and finally check if \u03bc and \u03bc\u2032 are\ncompatible (in polynomial time). Since P \u2286 N P \u2286 \u03a3P\nn+1 ,\nall these checks in sequence can be done in \u03a3P\n.\nCheckn+1\ning if the inverse problem, i.e. C2 , holds is then possible in\nP\nco\u03a3P\nn+1 = \u03a0n+1 . Summarizing cases (a) and (b) we obP\nP\nserve that (a) \u03a3P\nn+1 and (b) \u03a0n+1 are contained in \u03a3n+2 ,\nP\nso both checks in sequence can be executed in \u03a3n+2 , which\ncompletes case 1.\n\nCase 2: Let Q = \u2200, so the formula is of the form\nF = \u2203x0 \u2200y0 \u2203x1 \u2200x1 . . . \u2203xm \u2200ym \u03c8.\nF has 2m+2 quantifier alternations, so we need to provide\na reduction into the E \u22642m+1 fragment. We eliminate the\nouter \u2203-quantifier by rewriting F as F = F1 \u2228 F2 , where\nF1 = \u2200y0 \u2203x1 \u2200y1 . . . \u2203xm \u2200ym (\u03c8 \u2227 y0 ), and\nF2 = \u2200y0 \u2203x1 \u2200y1 . . . \u2203xm \u2200ym (\u03c8 \u2227 \u00acy0 ).\nAbstracting from the details of the inner formula, both F1\nand F2 are of the form\nF \u2032 = \u2200y0 \u2203x1 \u2200y1 . . . \u2203xm \u2200ym \u03c8 \u2032 ,\nwhere \u03c8 \u2032 is a quantifier-free boolean formula. We now\nshow (*) that we can encode F \u2032 by E \u22642m+1 expressions\nenc(F \u2032 ) that, evaluated on a fixed document D, yields a fixed\nmapping \u03bc exactly if F \u2032 is valid. This is sufficient, because\nthen the expression enc(F1 ) Union enc(F2 ) is an E \u22642m+1\nthat contains \u03bc exactly if the original formula F = F1 \u2228 F2\nis valid. We again start by rewriting F \u2032 :\nF\u2032 =\n=\n=\nF1\u2032 =\nF2\u2032 =\n\nCase 2: Checking if \u03bc \u2208 JA And BK. Figure 4(a) shows\nthe structure of a sample And expression, where the \u2022 symbols represent non-Opt operators (i.e. And,Union, or Filter), and t stands for triple patterns. There is an arbitrary\nnumber of Opt-subexpression (which might, of course, contain Opt subexpression themselves). Each of these subexpressions has Opt-rank \u2264 n + 1. Using the same argumentation as in case (1), the evaluation problem for all of\nthem is in \u03a3P\nn+2 . Moreover, there might be triple leaf nodes;\nthe evaluation problem for such patterns is in PTime, and\nclearly P \u2287 \u03a3P\nn+2 . Figure 4(b) illustrates the situation when\nall Opt-expressions and triple patterns have been replaced\nby the complexity of their Evaluation problem.\n\n\u2200y0 \u2203x1 \u2200y1 . . . \u2203xm \u2200ym \u03c8 \u2032\n\u00ac\u2203y0 \u2200x1 \u2203y1 . . . \u2200xm \u2203ym \u00ac\u03c8 \u2032\n\u00ac(F1\u2032 \u2228 F2\u2032 ), where\n\u2200x1 \u2203y1 . . . \u2200xm \u2203ym (\u00ac\u03c8 \u2032 \u2227 y0 ), and\n\u2200x1 \u2203y1 . . . \u2200xm \u2203ym (\u00ac\u03c8 \u2032 \u2227 \u00acy0 ).\n\nAccording to Lemma 8, each Fi\u2032 can be encoded by an\nE \u22642m expressions enc(Fi\u2032 ) s.t., on the fixed database D\ngiven there, (1) \u03bc = {?B0 7\u2192 1} \u2208 JFi\u2032 KD iff Fi\u2032 is valid\nand (2) if Fi\u2032 is not valid, then all mappings Jenc(Fi\u2032 )KD\nbind both variables ?A1 and ?B0 to 1. Then the same conditions (1) and (2) hold for enc(F1\u2032 ) Union enc(F2\u2032 ) exactly\nif F1 \u2228 F2 is valid. Now consider the expression Q =\n((a, false, ?A1 ) Opt (enc(F1 ) Union enc(F2 )). This expression contains \u03bc\u2032 = {?A1 7\u2192 0} (when evaluated on the\ndatabase given in Lemma 8) if and only if F1\u2032 \u2228 F2\u2032 is not\n\nWe then proceed as follows. We apply Lemma 9 repeatedly, folding the remaining And, Union, and Filter\nsubexpressions bottom up. The lemma guarantees that these\nfolding operations do not increase the complexity class, and\nit is easy to prove that Evaluation remains in \u03a3P\nn+2 for\n18\n\n\fAnd\n\nAnd\n\n...\n\nEvaluation in \u03a3P\nn+2\n\n\u2022\n\nOpt\n...\n\n\u2022\nt\n\nOpt\n...\n\n\u2022\n\n...\n\n\u2022\nEvaluation in \u03a3P\nn+2\n\nOpt\n...\n\n\u2022\n\u2022\n\nEvaluation in PTime\n\nEvaluation in \u03a3P\nn+2\n\n...\n\nFigure 4: (a) AND-expression with increased OPT-rank; (b) The OPT-expressions and leaf nodes\nhave been replaced by the complexity class of their EVALUATION problem.\nthe approach taken in the previous proof (of Theorem 5) and\neliminate the Select-clause. More precisely, we guess a\nmapping \u03bc\u2032\u2032 \u223c \u03bc and check if \u03bc\u2032\u2032 \u222a \u03bc \u2208 JQ\u2032 KD (we refer the\nreader to the proof of Theorem 5 before for more details).\nAgain, the size of the mapping to be guessed is bounded, and\nit is easy to see that the resulting algorithm is in NP.\n\nthe whole expression.\nCase 3: Checking if \u03bc \u2208 JA Union BK and Case 4:\nChecking if \u03bc \u2208 JA Filter RK. Similar to case 2.\nIt is worth mentioning that the structural induction is polynomially bounded by the size of the expression when the\nnesting depth of Opt-operators is fixed (which holds by assumption), i.e. comprises only polynomially many steps. In\nall cases except case 1 the recursive calls concern subexpressions of the original expression. In case 1, \u03bc \u2208 JA Opt BK\ngenerates two checks, namely \u03bc \u2208 JA And BK and \u03bc \u2208\nJAK \\ JBK. These two checks might trigger recursive checks\nagain. But since the nesting depth of Opt-expressions is\nrestricted, it is easy to see that there is a polynomial that\nbounds the number of recursive call. \u2737\nA.4\n\nTo prove hardness we reduce 3Sat, a prototypical NPcomplete problem, to our problem. The proof was inspired\nby the reduction of 3Sat to the evaluation problem for conjunctive queries in [11]. The 3Sat problem is defined as\nfollows. Let \u03c8 a boolean formula\n\u03c8 = C1 \u2227 * * * \u2227 Cn\nin CNF, where each clause Ci is of the form\nCi = li1 \u2228 li2 \u2228 li3 ,\n\nQueries: Fragments Including SELECT\n\ni.e. contains exactly three, possibly negated, literals: is \u03c8\nsatisfiable? For our encoding we use the fixed database\n\nProof of Theorem 5\nLet F be a fragment for which the Evaluation problem is\nC-complete, where C is a complexity class s.t. NP \u2286 C. We\nshow that, for a query Q \u2208 F+ , document D, and mapping \u03bc,\ntesting if \u03bc \u2208 JQKD is contained in C (C-hardness follows\ntrivially from C-hardness of fragment F ). By definition,\neach query in F+ is of the form Q = SelectS (Q\u2032 ), where\nS \u2282 V is a finite set of variables and Q\u2032 is an F -expression.\nBy definition of operator Select, \u03bc \u2208 JQKD holds if and\nonly if there exists a mapping \u03bc\u2032 \u2208 JQ\u2032 KD s.t. \u03bc\u2032 = \u03bc \u222a \u03bc\u2032\u2032 ,\nfor any mapping \u03bc\u2032\u2032 \u223c \u03bc. We observe that the domain of\ncandidate mappings \u03bc\u2032\u2032 is bounded by the set of variables\nin Q\u2032 , i.e. dom(\u03bc\u2032\u2032 ) \u2286 vars(Q\u2032 ). Hence, we can guess a\nmapping \u03bc\u2032\u2032 (this is possible since we are at least in NP) and\nsubsequently check if \u03bc\u2032 = \u03bc \u222a \u03bc\u2032\u2032 \u2208 JQ\u2032 KD , which is also\npossible in C. The whole algorithm is in C.\u2737\n\nD := {(1, 1, 1), (1, 1, 0), (1, 0, 1), (1, 0, 0), (0, 1, 1),\n(0, 1, 0), (0, 0, 1), (0, 0, 0), (0, c, 1), (1, c, 0)},\nwhere we assume that 0, 1 \u2208 I are any IRIs. Further let\nV = {x1 , . . . xm } denote the set of variables occurring in\nformula \u03c8. We set up the SPARQL core expression\nP \u2032 := (L\u221711 , L\u221712 , L\u221713 ) And . . . And (L\u2217n1 , L\u2217n2 , L\u2217n3 )\nAnd (?X1 , c, ?X 1 ) And . . . And (?Xm , c, ?X m )\nAnd (0, c, ?A), where\nL\u2217ij :=?Xk if lij = xk , and L\u2217ij :=?X k if lij = \u00acxk .\nFinally, set P :=Select?A (P \u2032 ). It is straightforward to\nverify that \u03bc = {?A 7\u2192 1} \u2208 JP KD iff \u03c8 is satisfiable.\u2737\n\nProof of Theorem 6\nFirst, we show that Evaluation for A+ -queries is contained in NP. By definition, each query in A+ is of the form\nQ = SelectS (Q\u2032 ), where S \u2282 V is a finite set of variables\nand Q\u2032 is an And-only expression. Further let D a document and \u03bc a mapping. To prove membership, we follow\n19\n\nB.\n\nAlgebraic Results\n\nB.1\n\nProofs of the Equivalences in Figure 1(I-IV)\n\n\fmapping in A3 . If \u03bc \u2208 A1 then the right side subexpression\nA1 \\ A3 generates \u03bc, in the other case A2 \\ A3 generates\ndoes. \u21d0: Consider a mapping \u03bc in (A1 \\ A3 ) \u222a (A2 \\ A3 ).\nThen \u03bc \u2208 (A1 \\ A3 ) or \u03bc \u2208 (A2 \u222a A3 ). In the first case,\n\u03bc is contained in A1 and there is no compatible mapping\nin A3 . Clearly, \u03bc is then also contained in A1 \u222a A2 and\n(A1 \u222a A2 ) \\ A3 . The second case is symmetrical.\u2737\n\nI. Idempotence and Inverse\nThe two equivalences (UIdem) and (Inv) follow directly\nfrom the definition of operators \u222a and \\, respectively.\n(JIdem). Let A\u2212 be an A\u2212 -expression. We show that both\ndirections of the equivalence hold. \u21d2: Consider a mapping\n\u03bc \u2208 A\u2212 \u2736 A\u2212 . Then \u03bc = \u03bc1 \u222a \u03bc2 where \u03bc1 , \u03bc2 \u2208 A\u2212\nand \u03bc1 \u223c \u03bc2 . Each pair of distinct mappings in A\u2212 is\nincompatible, so \u03bc1 = \u03bc2 and, consequently, \u03bc1 \u222a \u03bc2 =\n\u03bc1 . By assumption, \u03bc1 \u2208 A\u2212 holds and we are done. \u21d0:\nConsider a mapping \u03bc \u2208 A\u2212 . Choose \u03bc for both the left and\nright expression in A\u2212 \u2736 A\u2212 . By assumption, \u03bc = \u03bc \u222a \u03bc is\ncontained in the left side expression of the equation.\u2737\n\n(LUDistR). The following rewriting proves the equivalence.\n\n1\n\n(A1 \u222a A2 )\nA3\n= ((A1 \u222a A2 ) \u2736 A3 ) \u222a ((A1 \u222a A2 ) \\ A3 )\n(1)\n\n= ((A1 \u2736 A3 ) \u222a (A2 \u2736 A3 )) \u222a ((A1 \\ A3 ) \u222a (A2 \\ A3 ))\n\n(2)\n\nA\u2212\n\n1 A = (A\n\u2212\n\n1\n\n1\n\n= ((A1 \u2736 A3 ) \u222a (A1 \\ A3 )) \u222a ((A2 \u2736 A3 ) \u222a (A2 \\ A3 ))\n= (A1\nA3 ) \u222a (A2\nA3 )\n\n(LIdem). Let A\u2212 be an A\u2212 expression. Then\n\u2212\n\n\u2736 A\u2212 ) \u222a (A\u2212 \\ A\u2212 ) [semantics]\n= (A \u2736 A\u2212 ) \u222a \u2205\n[(Inv)]\n= A\u2212 \u2736 A\u2212\n= A\u2212\n[(JIdem)],\n\nStep (1) is an application of (JUDistR) and (MUDistR);\nin step (2) we applied (UAss) and (UComm).\u2737\n\n\u2212\n\nB.2\n\nwhich proves the equivalence.\u2737\n\nProofs of the Equivalences in Figure 1(V-VI)\n\nIn the paper satisfaction was defined informally; to be\nself-contained, we repeat the formal definition from [26].\n\nII. Associativity\n\nDefinition 16. Given a mapping \u03bc, filter conditions R,\nR1 , R2 , variables ?x, ?y, and constant c, we say that \u03bc\nsatisfies R (denoted as \u03bc |= R), if\n1. R is bnd (?x ) and ?x \u2208 dom(\u03bc),\n2. R is ?x = c, ?x \u2208 dom(\u03bc), and \u03bc(?x) = c,\n3. R is ?x =?y, {?x, ?y} \u2286 dom(\u03bc), and \u03bc(?x)=\u03bc(?y),\n4. R is \u00acR1 and it is not the case that \u03bc |= R1 ,\n5. R is R1 \u2228 R2 and \u03bc |= R1 or \u03bc |= R2 ,\n6. R is R1 \u2227 R2 and \u03bc |= R1 and \u03bc |= R2 .\n\n(UAss) and (JAss) are trivial (cf. [26]).\nIII. Commutativity\n(UComm) and (JComm) are trivial (cf. [26]).\nIV. Distributivity\n(JUDistR). We show that both directions of the equivalence\nhold. \u21d2: First assume that \u03bc \u2208 (A1 \u222a A2 ) \u2736 A3 . Then\n(according to the definition of \u2736) \u03bc is of the form \u03bc12 \u222a \u03bc3\nwhere \u03bc12 \u2208 A1 \u222a A2 , \u03bc3 \u2208 A3 , and \u03bc12 \u223c \u03bc3 . More\nprecisely, \u03bc12 \u2208 A1 \u222a A2 means \u03bc12 in A1 or in A2 , so we\ndistinguish two cases. If (a) \u03bc12 \u2208 A1 then the subexpression\nA1 \u2736 A3 on the right side generates \u03bc = \u03bc12 \u222a \u03bc3 (choose\n\u03bc12 from A1 and \u03bc3 from A3 ); similarly, if (b) \u03bc12 \u2208 A2 ,\nthen the expression A2 \u2736 A3 on the right side generates \u03bc.\n\u21d0: Consider a mapping \u03bc \u2208 (A1 \u2736 A3 ) \u222a (A2 \u2736 A3 ).\nThen \u03bc is of the form (a) \u03bc = \u03bc1 \u222a \u03bc3 or of the form (b)\n\u03bc = \u03bc2 \u222a \u03bc3 with \u03bc1 \u2208 A1 \u03bc2 \u2208 A2 , \u03bc3 \u2208 A3 (where\n(a) \u03bc1 \u223c \u03bc3 or (b) \u03bc2 \u223c \u03bc3 holds, respectively). Case (a):\n\u03bc1 is contained in A1 , so it is also contained in A1 \u222a A2 .\nHence, on the left-hand side we choose \u03bc1 from A1 \u222a A2\nand \u03bc3 from A3 . By assumption they are compatible and\ngenerate \u03bc = \u03bc1 \u222a \u03bc3 . Case (b) is symmetrical. \u2737\n\nRecall that, given a set of mappings \u03a9 and filter condition\nR, \u03c3R (\u03a9) is defined as the subset of mappings in \u03a9 that\nsatisfy condition R, i.e. \u03c3R (\u03a9) = {\u03bc \u2208 \u03a9 | \u03bc |= R}.\nThe following proposition states that function safeVars(A)\nreturns only variables that are bound in each mapping when\nevaluating A on any document D. It will be required in some\nof the subsequent proofs.\nProposition 5. Let A be a SPARQL Algebra expression\nand let \u03a9A denote the mapping set obtained from evaluating A on any document. Then ?x \u2208 safeVars(A) =\u21d2\n\u2200\u03bc \u2208 \u03a9A :?x \u2208 dom(\u03bc).\n\u2737\nProof. The proof is by induction on the structure of A and\napplication of Definition 5. We omit the details.\u2737\n\n(JUDistL). The equivalence follows from (JComm) and\n(JUDistR) (cf. [26]).\u2737\n\nProofs of Equivalences in Figure 1(V-VI)\n(SUPush). Follows directly from Proposition 1(5) in [26].\u2737\n\n(MUDistR). We show that both directions of the equation\nhold. \u21d2: Consider a mapping \u03bc \u2208 (A1 \u222a A2 ) \\ A3 . Hence,\n\u03bc is contained in A1 or in A2 and there is no compatible\n\n(SDecompI). Follows directly from Lemma 1(1) in [26].\u2737\n20\n\n\fJtK. By semantics, all mappings in A\u2212 bind exactly the\nsame set of variables, and consequently the values of each\ntwo distinct mappings must differ in at least one variable,\nwhich makes them incompatible.10 (Case 1) We assume\nthat the hypothesis holds and consider an expression A\u2212 =\n\u2212\n\u2212\nA\u2212\nis of the form\n1 \u2736 A2 . Then each mapping \u03bc \u2208 A\n\u2212\n\u2212\n\u03bc = \u03bc1 \u222a \u03bc2 with \u03bc1 \u2208 A1 , \u03bc2 \u2208 A2 , and \u03bc1 \u223c \u03bc2 .\nWe fix \u03bc and show that each mapping \u03bc\u2032 \u2208 A\u2212 different\nfrom \u03bc is incompatible. Any mapping in \u03bc\u2032 \u2208 A\u2212 that is\ndifferent from \u03bc is of the form \u03bc\u20321 \u222a \u03bc\u20322 with \u03bc\u20321 \u2208 A\u2212\n1,\n\u2032\n\u2032\n\u03bc\u20322 \u2208 A\u2212\nand\n\u03bc\ndifferent\nfrom\n\u03bc\nor\n\u03bc\ndifferent\nfrom\n1\n1\n2\n2\n\u03bc2 . Let us w.l.o.g. assume that \u03bc\u20321 is different from \u03bc1 .\nBy induction hypothesis, \u03bc1 is incompatible with \u03bc\u20321 . It is\neasy to verify that then \u03bc = \u03bc1 \u222a \u03bc2 is incompatible with\n\u03bc\u2032 = \u03bc\u20321 \u222a \u03bc\u20322 , since \u03bc1 and \u03bc\u20321 disagree in the value of\n\u2212\nat least one variable. (Case 2) Let A\u2212 = A\u2212\n1 \\ A2 . By\n\u2212\ninduction hypothesis, each two mappings in A1 are pairwise\nincompatible. By semantics, A\u2212 is a subset of A\u2212\n1 , so the\nincompatibility property still holds for A\u2212 . (Case 3) Let\nA\u2212\nA\u2212 = A\u2212\n2 . We rewrite the left outer join according\n1\n\u2212\n\u2212\n\u2212\nA\u2212\nto its semantics: A\u2212 = A\u2212\n2 = (A1 \u2736 A2 ) \u222a (A1 \\\n1\n\u2212\nA2 ). As argued in cases (1) and (2), the incompatibility\n\u2212\nproperty holds for both subexpressions A\u2736 = A\u2212\n1 \u2736 A2\n\u2212\n\u2212\n\\\nand A = A1 \\ A2 , so it suffices to show that the mappings\nin A\u2736 are pairwise incompatible to those in A\\ . We observe\n\u2736\nthat A\\ is a subset of A\u2212\n1 . Further, each mapping \u03bc \u2208 A\n\u2212\n\u2212\nis of the form \u03bc = \u03bc1 \u222a \u03bc2 , where \u03bc1 \u2208 A1 , \u03bc2 \u2208 A2 , and\n\u03bc1 \u223c \u03bc2 . By assumption, each mapping in A\u2212\n1 , and hence\neach mapping \u03bc\u20321 \u2208 A\\ is either identical to or incompatible\nwith \u03bc1 . (a) If \u03bc1 6= \u03bc\u20321 , then \u03bc\u20321 is incompatible with \u03bc1 , and\nconsequently incompatible with \u03bc1 \u222a\u03bc2 = \u03bc, so we are done.\n(b) Let \u03bc1 = \u03bc\u20321 . We observe that, by assumption, there is\na compatible mapping (namely \u03bc2 in A\u2212\n2 ). This means that\n\u2212\n\u2032\ndoes\nnot\ngenerate\n\u03bc\n,\nso\nwe\nhave\na contradiction\n\\\nA\nA\u2212\n1\n2\n1\n(i.e., the assumption \u03bc1 = \u03bc\u20321 was invalid). (Case 4) Let\n\u2212\n\u2212\nA = \u03c3C (A\u2212\n1 ). Analogously to case 2, A is a subset of A1 ,\nfor which the property holds by induction hypothesis. \u2737\n\n(SDecompII). Follows directly from Lemma 1(2) in [26].\u2737\n(SReord). Follows from the application of (SDecompI) and\nthe commutativity of the boolean operator \u2227.\u2737\n(BndI), (BndII), (BndIII), and (BndIV) are trivial.\n(BndV). Recall that by assumption ?x 6\u2208 vars(A1 ). The\nfollowing rewriting proves the equivalence.\n\n1A )\n\n\u03c3bnd (?x) (A1\n= \u03c3bnd (?x) (A1\n= \u03c3bnd (?x) (A1\n= \u03c3bnd (?x) (A1\n= A1 \u2736 A2\n\n2\n\n\u2736 A2 ) \u222a (A1 \\ A2 ))\n[semantics]\n\u2736 A2 ) \u222a \u03c3bnd (?x) (A1 \\ A2 ) [(SUPush)]\n\u2736 A2 )\n[\u22171 ]\n[\u22172 ]\n\n\u22171 follows immediately from assumption ?x 6\u2208 vars(A1 );\n\u22172 follows from the observation that ?x \u2208 safeVars(A2 ).\u2737\n\n1\n\n(SJPush). \u21d2: Let \u03bc \u2208 \u03c3R (A1 \u2736 A2 ). By semantics,\n\u03bc |= R. Furthermore, \u03bc is of the form \u03bc1 \u222a \u03bc2 , where\n\u03bc1 \u2208 A1 , \u03bc2 \u2208 A2 , and \u03bc1 \u223c \u03bc2 . Recall that by assumption vars(R) \u2286 safeVars(A1 ), so we always have that\ndom(\u03bc1 ) \u2286 vars(R) (cf. Proposition 5), i.e. each variable\nthat occurs in R is bound in mapping \u03bc1 . It is easy to verify\nthat R |= \u03bc implies R |= \u03bc1 , since both mappings coincide\nin the variables that are relevant for evaluating R. Consequently \u03c3R (A1 ) on the right side generates \u03bc1 , and clearly\n\u03c3R (A1 ) \u2736 A2 generates \u03bc1 \u222a \u03bc2 = \u03bc. \u21d0: Consider a mapping \u03bc \u2208 \u03c3R (A1 ) \u2736 A2 . Then \u03bc is of the form \u03bc = \u03bc1 \u222a \u03bc2 ,\n\u03bc1 \u2208 A1 , \u03bc2 \u2208 A2 , \u03bc1 \u223c \u03bc2 , and \u03bc1 |= R. It is easy to see\nthat then also \u03bc1 \u222a\u03bc2 |= R, because dom(\u03bc1 ) \u2286 vars(R) (as\nargued in case \u21d2) and \u03bc1 \u222a \u03bc2 coincides with \u03bc1 on all variables that are relevant for evaluating R. Hence, \u03bc = \u03bc1 \u222a \u03bc2\nis generated by the left side of the equation.\u2737\n(SMPush). \u21d2: Let \u03bc \u2208 \u03c3R (A1 \\ A2 ). By semantics,\n\u03bc \u2208 A1 and there is no \u03bc2 \u2208 A2 compatible with \u03bc1 and\n\u03bc |= R. From these preconditions it follows immediately\nthat \u03bc \u2208 \u03c3R (A1 ) \\ A2 . \u21d0: Let \u03bc \u2208 \u03c3R (A1 ) \\ A2 . Then\n\u03bc \u2208 A1 , \u03bc |= R, and there is no compatible mapping in A2 .\nClearly, then also \u03bc \u2208 A1 \\ A2 and \u03bc \u2208 \u03c3R (A1 \\ A2 ).\u2737\n\nProof of Lemma 1\nWe provide an exhaustive set of counterexamples.\n\n(SLPush). The following rewriting proves the equivalence.\n\n1\n\n\u03c3R (A1\nA2 )\n= \u03c3R ((A1 \u2736 A2 ) \u222a (A1 \\ A2 ))\n= \u03c3R (A1 \u2736 A2 ) \u222a \u03c3R (A1 \\ A2 )\n= (\u03c3R (A1 ) \u2736 A2 ) \u222a (\u03c3R (A1 ) \\ A2 )\n= \u03c3R (A1 )\nA2\n\n1\n\nProof of Claim 1. In this part, we give counterexamples\nfor two fragments (a) A{\u2736,\\, 1 ,\u03c3,\u222a} and (b) A{\u2736,\\, 1 ,\u03c3,\u03c0} .\nThe result for the full algebra (i.e., A{\u2736,\\, 1 ,\u03c3,\u222a,\u03c0} ) follows.\n\n[semantics]\n[(SUPush)]\n[*]\n[semantics]\n\n(1a) Fragment A{\u2736,\\, 1 ,\u03c3,\u222a} . We use the fixed database\nD = {(0, c, 1)}. Consider the algebra expression A =\nJ(?x, c, 1)KD \u222a J(0, c, ?y)KD . It is easy to see that both\nA \u2736 A = {{?x 7\u2192 0}, {?y 7\u2192 1}, {?x 7\u2192 0, ?y 7\u2192 1}}\nand A A = {{?x 7\u2192 0}, {?y 7\u2192 1}, {?x 7\u2192 0, ?y 7\u2192 1}}\ndiffer from A = {{?x 7\u2192 0}, {?y 7\u2192 1}}, which shows that\nneither (JIdem) nor (LIdem) holds for this fragment.\n\n1\n\n* denotes application of (SJPush) and (SMPush).\u2737\nB.3\n\n1\n\nProofs of the Remaining Technical Results\n\n(1b) Fragment A{\u2736,\\, 1 ,\u03c3,\u03c0} . We use the fixed database\nD = {(0, f, 0), (1, t, 1), (a, tv, 0), (a, tv, 1)}. Consider the\nalgebra expression\n\nProof of Proposition 1\nProof. Let A\u2212 be an A\u2212 expression. The proof is by\ninduction on the structure of A\u2212 The basic case is A\u2212 =\n\n10\n\n21\n\nRecall that we assume set semantics.\n\n\fA = \u03c0{?x,?y} ((t1\n\n1 t ) 1 t ), where\n2\n\n1\n\ndef\n\nt1 := J(a, tv, ?z)KD ,\n\n1\n\ndef\n\nt2 := J(?z, f, ?x)KD , and\ndef\n\nt3 := J(?z, t, ?y)KD .\n\n1\n\nIt is easy to verify that A = {{?x 7\u2192 0}, {?y 7\u2192 1}}.\nA we then get exactly the same results\nFor A \u2736 A and A\nas in part (1a), and we conclude that neither (JIdem) nor\n(LIdem) holds for the fragment under consideration.\n\nDistributivity over\n\n1\n\n1\n\nProof of Claims 3 + 4. We provide counterexamples for\neach possible operator constellations. All counterexamples\nare designed for the database D = {(0, c, 1)}.\n\n1\n\nDistributivity over \u222a (Claim 3 in Lemma 1):\n\u2022 A1 \\ (A2 \u222a A3 ) \u2261 (A1 \\ A2 ) \u222a (A1 \\ A3 ) does not\nhold, e.g. A1 = J(0, c, ?a)KD , A2 = J(?a, c, 1)KD , and\nA3 = J(0, c, ?b)KD violates the equation.\n\u2022 A1\n(A2 \u222a A3 ) \u2261 (A1\nA2 ) \u222a (A1\nA3 ) does\nnot hold, e.g. A1 = J(0, c, ?a)KD , A2 = J(?a, c, 1)KD ,\nand A3 = J(0, c, ?b)KD . violates the equation.\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n(Claim 4 in Lemma 1):\n\n1\n\n1\n\n1\n\n1\n\n1\n1\n\n1\n\nThe list of counterexamples is exhaustive.\u2737\n\n\u2022 A1 \u222a (A2 \u2736 A3 ) \u2261 (A1 \u222a A2 ) \u2736 (A1 \u222a A3 ) does not\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(0, c, ?b)KD violates the equation.\n\u2022 (A1 \u2736 A2 ) \u222a A3 \u2261 (A1 \u222a A3 ) \u2736 (A2 \u222a A3 ) does not\nhold (symmetrical to the previous one).\n\u2022 A1 \\ (A2 \u2736 A3 ) \u2261 (A1 \\ A2 ) \u2736 (A1 \\ A3 ) does not\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(0, c, ?b)KD violates the equation.\n\u2022 (A1 \u2736 A2 ) \\ A3 \u2261 (A1 \\ A3 ) \u2736 (A2 \\ A3 ) does not\nhold, e.g. A1 = J(0, c, ?a)KD , A2 = J(0, c, ?b)KD , and\nA3 J(?a, c, 1)KD violates the equation.\n\u2022 A1\n(A2 \u2736 A3 ) \u2261 (A1\nA2 ) \u2736 (A1\nA3 ) does\nnot hold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD ,\nand A3 J(0, c, ?a)KD violates the equation.\n\u2022 (A1 \u2736 A2 )\nA3 \u2261 (A1\nA3 ) \u2736 (A2\nA3 ) does\nnot hold, e.g. A1 = J(0, c, ?a)KD , A2 = J(0, c, ?b)KD ,\nand A3 J(?a, c, 1)KD violates the equation.\n\n1\n\n1\n\n1\n\nDistributivity over \u2736 (Claim 4 in Lemma 1):\n\n1\n\n1\n\nA3 ) \u2261 (A1 \u222aA2 )\n(A1 \u222aA3 ) does not\n\u2022 A1 \u222a(A2\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(c, c, c)KD , and\nA3 J(?b, c, 1)KD violates the equation.\n\u2022 (A1\nA2 )\u222aA3 \u2261 (A1 \u222aA3 )\n(A2 \u222aA3 ) does not\nhold (symmetrical to the previous one).\n\u2022 A1 \u2736 (A2\nA3 ) \u2261 (A1 \u2736 A2 ) (A1 \u2736 A3 ) does\nnot hold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD ,\nand A3 J(0, c, ?a)KD violates the equation.\n\u2022 (A1\nA2 ) \u2736 A3 \u2261 (A1 \u2736 A3 ) (A2 \u2736 A3 ) does\nnot hold (symmetrical to the previous one).\nA3 ) \u2261 (A1 \\ A2 )\n(A1 \\ A3 ) does not\n\u2022 A1 \\ (A2\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(0, c, ?a)KD violates the equation.\nA2 ) \\ A3 \u2261 (A1 \\ A3 )\n(A2 \\ A3 ) does not\n\u2022 (A1\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(0, c, ?b)KD violates the equation.\n\nProof of Claim 2. Trivial.\n\n1\n\n1\n\n\u2022 A1\n(A2 \\A3 ) \u2261 (A1\nA2 )\\(A1\nA3 ) does not\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(?b, c, 1)KD violates the equation.\n\u2022 (A1 \\A2 )\nA3 \u2261 (A1\nA3 )\\(A2\nA3 ) does not\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(0, c, ?b)KD violates the equation.\n\n3\n\nProof of Proposition 2\n(MReord). We consider all possible mappings \u03bc. Clearly,\nif \u03bc is not contained in A1 , it will be neither contained in\nthe right side nor in the left side of the expressions (both are\nsubsets of A1 ). So we can restrict our discussion to mappings\n\u03bc \u2208 A1 . We distinguish three cases. Case (1): consider a\nmapping \u03bc \u2208 A1 and assume there is a compatible mapping\nin A2 . Then \u03bc is not contained in A1 \\ A2 , and also not in\n(A1 \\ A2 ) \\ A3 , which by definition is a subset of the former.\nNow consider the right-hand side of the equation and let us\nassume that \u03bc \u2208 A1 \\ A3 (otherwise we are done). Then,\nas there is a compatible mapping to \u03bc in A2 , the expression\n\u03bc \u2208 (A1 \\ A3 ) \\ A2 will not contain \u03bc. Case (2): The case\nof \u03bc \u2208 A1 being compatible with any mapping from A3 is\nsymmetrical to (2). Case (3): Let \u03bc \u2208 A1 be a mapping that\nis not compatible with any mapping in A2 and A3 . Then\nboth (A1 \\ A2 ) \\ A3 on the left side and (A1 \\ A3 ) \\ A2 on\nthe right side contain \u03bc. In all cases, \u03bc is contained in the\nright side exactly if it is contained in the left side.\u2737\n\nDistributivity over \\ (Claim 4 in Lemma 1):\n\u2022 A1 \u222a (A2 \\ A3 ) \u2261 (A1 \u222a A2 ) \\ (A1 \u222a A3 ) does not\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(0, c, ?a)KD , and\nA3 J(?a, c, 1)KD violates the equation.\n\u2022 (A1 \\ A2 ) \u222a A3 \u2261 (A1 \u222a A3 ) \\ (A2 \u222a A3 ) does not\nhold (symmetrical to the previous one).\n\u2022 A1 \u2736 (A2 \\ A3 ) \u2261 (A1 \u2736 A2 ) \\ (A1 \u2736 A3 ) does not\nhold, e.g. A1 = J(?a, c, 1)KD , A2 = J(?b, c, 1)KD , and\nA3 J(0, c, ?a)KD violates the equation.\n\u2022 (A1 \\ A2 ) \u2736 A3 \u2261 (A1 \u2736 A3 ) \\ (A2 \u2736 A3 ) does not\nhold (symmetrical to the previous one).\n\n(MMUCorr). We show both directions of the equivalence.\n\u21d2: Let \u03bc \u2208 (A1 \\A2 )\\A3 . Then \u03bc \u2208 A1 and there is neither\na compatible mapping \u03bc2 \u2208 A2 nor a compatible mapping\n\u03bc3 \u2208 A3 . Then both A2 and A3 contain only incompatible\nmappings, and clearly A2 \u222a A3 contains only incompatible\nmappings. Hence, the right side A1 \\ (A2 \u222a A3 ) produces\n\u03bc. \u21d0: Let \u03bc \u2208 A1 \\ (A2 \u222a A3 ). Then \u03bc \u2208 A1 and there is\nno compatible mapping in A2 \u222a A2 , which means that there\nis neither a compatible mapping in A2 nor in A3 . It follows\n22\n\n\fThen, it follows that C1 (Q\u2032 ) \u2208 cb\u03a3 (C1 (Q)) and Q\u2032 \u2208\nC1\u22121 (cb\u03a3 (C1 (Q))).\n\nthat A1 \\ A2 contains \u03bc (as there is no compatible mapping\nin A2 and \u03bc \u2208 A1 ). From the fact that there is no compatible\nmapping in A3 , we deduce \u03bc \u2208 (A1 \\ A2 ) \\ A3 . \u2737\n\n\u2022 Follows from the last point and bullet two in lemma 3.\u2737\n(MJ). See Lemma 3(2) in [26].\n\u2212\n\u2212\n(LJ). Let A\u2212\n1 , A2 be A -expressions. The following sequence of rewriting steps proves the equivalence.\n\nA\u2212\n1\n\n1\n\nProof of Lemma 5\n\u2022 We transform Q systematically.\ndatabase such that D |= \u03a3.\n\nA\u2212\n2\n\n\u2212\n\u2212\n\u2212\n= (A\u2212\n1 \u2736 A2 ) \u222a (A1 \\ A2 )\n\u2212\n\u2212\n\u2212\n\u2212\n\u2212\n= (A1 \u2736 (A1 \u2736 A2 )) \u222a (A\u2212\n1 \\ (A1 \u2736 A2 ))\n\u2212\n\u2212\n\u2212\n= (A1\n(A1 \u2736 A2 ))\n\n1\n\n[sem.]\n[*]\n[sem.]\n\nJQKD\n= J(Q1 Opt Q2 )KD\n= J(Q1 And Q2 )KD \u222a (JQ1 KD \\ JQ2 KD )\n= J(Q1 And Q2 )KD \u222a\n(\u03c0vars(Q1 ) J(Q1 And Q2 )KD \\ JQ2 KD )\n\n* denotes application of (JIdem), (JAss), and (MJ).\u2737\nProof of Lemma 2\nA\u2212\n1,\n\nA\u2212\n2\n\nIt is easy to verify that each mapping in JQ1 And Q2 KD\nis compatible with at least one mapping in Q2 , and the\nsame still holds for the projection \u03c0vars(Q1 ) J(Q1 And Q2 )KD .\nHence, the right side of the union can be dropped and the\nelimination simplifies to Q \u2261\u03a3 (Q1 And Q2 ).\n\u2022 Let D be an RDF database such that D |= \u03a3. Then we\nhave that\n\n\u2212\n\nbe A -expressions, R a filter condition, and\nLet\n?x \u2208 safeVars(A2 )\\vars(A1 ) a variable that is contained in\nthe set of safe variables of A2, but not in A1. We transform the\nleft side expression into the right side expression as follows.\n\n1\n\n\u03c3\u00acbnd(?x ) (A\u2212\nA\u2212\n1\n2)\n\u2212\n\u2212\n\u2212\n= \u03c3\u00acbnd(?x ) ((A1 \u2736 A\u2212\n2 ) \u222a (A1 \\ A2 ))\n\u2212\n\u2212\n= \u03c3\u00acbnd(?x ) (A1 \u2736 A2 ) \u222a\n\u2212\n\u03c3\u00acbnd(?x ) (A\u2212\n1 \\ A2 )\n\u2212\n\u2212\n= \u03c3\u00acbnd(?x ) (A1 \\ A2 )\n\u2212\n= A\u2212\n1 \\ A2\n\nJQKD = J(Q1 Opt (Q2 And Q3 ))KD\n= J(Q1 And Q2 And Q3 )KD \u222a\n(JQ1 KD \\ JQ2 And Q3 KD )\n= J(Q1 And Q3 )KD \u222a\n(JQ1 And Q2 KD \\ JQ2 And Q3 KD ).\n\n[semantics]\n[(SUPush)]\n[\u22171 ]\n[\u22172 ]\n\nWe now show that (JQ1 And Q2 KD \\JQ2 And Q3 KD ) =\n(JQ1 And Q2 KD \\ JQ3 KD ). Assume that there is some\n\u03bc \u2208 (JQ1 And Q2 KD \\ JQ2 And Q3 KD ). Then, for all\n\u03bc\u2032 \u2208 JQ2 And Q3 KD it holds that \u03bc\u2032 is incompatible\nto \u03bc. As \u03bc is, by choice, compatible to some element in\nJQ2 KD , it must be in compatible to all elements in JQ3KD .\nThis implies \u03bc \u2208 (JQ1 And Q2 KD \\ JQ3 KD ). Assume\nwe have \u03bd \u2208 (JQ1 And Q2 KD \\ JQ3 KD ). Choose \u03bd \u2032 \u2208\nJQ2 And Q3 KD . It follows that the projection of \u03bd \u2032 in\nthe variables in Q3 is not compatible to \u03bd, therefore \u03bd \u2032 is\nnot compatible to \u03bd. This implies \u03bd \u2208 (JQ1 And Q2 KD \\\nJQ2 And Q3 KD ). Consequently\n\nWe first show that rewriting step \u22171 holds. Observe that\n?x \u2208 safeVars(A\u2212\n2 ), which implies that (following Proposition 5) variable ?x is bound in each mapping generated by A2.\nConsequently, ?x is also bound in each mapping generated\nby A1 \u2736 A2 and the condition \u00acbnd (?x ) is never satisfied\nfor the join part, so it can be eliminated. Concerning step\n\u22172 we observe that ?x \u2208 safeVars(A2 ) \\ vars(A1 ) implies\n?x 6\u2208 vars(A1 ). It follows immediately that ?x is unbound\n\u2212\nin any mapping generated by A\u2212\n1 \\ A2 , so the surrounding\nfilter condition always holds and can be dropped. \u2737\n\nC.\n\nLet D be an RDF\n\nJQKD\n= \u03c0S (J(Q1 And Q3 )KD \u222a (JQ1 And Q2 KD \\ JQ3 KD ))\n= \u03c0S (J(Q1 And Q3 )KD \u222a (JQ1 KD \\ JQ3 KD ))\n= JQ1 Opt Q3 KD . \u2737\n\nProofs of the SQO Results\n\nProof of Lemma 3\n\u2022 Let Q\u2032 \u2208 C1\u22121 (cb\u03a3 (C1 (Q))) \u2229 A+ . Then C1 (Q\u2032 ) \u2208\ncb\u03a3 (C1 (Q)). This implies C1 (Q\u2032 ) \u2261\u03a3 C1 (Q). It follows that Q\u2032 \u2261\u03a3 Q.\n\u2022 Follows directly from the definition of the second translation scheme.\n\u2022 Follows from the last two points.\u2737\n\nProof of Lemma 6\n\u2022 Let \u03bc \u2208 JQ1 Opt Q2 KD . Then, \u03bc(?x) is defined because of Q1 \u2261\u03a3 Selectvars(Q1 ) (Q1 And Q2 ). So,\nJFilter\u00acbnd(?x) (Q1 Opt Q2 )KD = \u2205.\n\u2022 The proof of this claim is straightforward.\n\u2022 Assume that there is some \u03bc \u2208 JFilter\u00ac?x=?y (Q2 )KD .\nSo, \u03bc|S \u2208 JSelectS (Q2 )KD . It holds that SelectS (Q2 )\n\u2261\u03a3 SelectS (Q2 ?x\n?y ) \u2261\u03a3 SelectS (Filter?x=?y (Q2 )).\nIt follows that \u03bc \u2208 JSelectS (Filter?x=?y (Q2 ))KD ,\nwhich is a contradiction.\u2737\n\nProof of Lemma 4\n\u2022 Let Q\u2032 \u2261\u03a3 Q. We have that C1\u22121 (U (C1 (Q\u2032 ))),\nC1\u22121 (U (C1 (Q))) \u2208 A+ , therefore C1 (Q\u2032 ) \u2261\u03a3 C1 (Q).\n23\n\n\fD.\n\nProofs of the Chase Termination Results\n\nD.1\n\nAdditional Definitions\n\nIt is folklore that TGDs and EGDs together are expressive\nenough to express foreign key constraints, inclusion, functional, join, multivalued and embedded dependencies. Thus,\nwe can capture all important semantic constraints used in\ndatabases. Therefore, in the rest of the paper, all sets of\nconstraints are a union of TGDs and EGDs only.\n\nDatabases. We choose three pairwise disjoint infinite\nsets \u2206, \u2206null and V . We will refer to \u2206 as the set of constants, to \u2206null as the set of labelled nulls and to V as the\nset of variables. A database schema R is a finite set of relational symbols {R1 , ..., Rn }. To every Ri \u2208 R we assign\na natural number ar(Ri ) \u2208 N, which we call the arity of\nRi . The arity of R, denoted by ar(R), is defined as max{\nar(Ri ) | i \u2208 [n] }. Throughout the rest of the paper, we\nassume the database schema, the set of constants and the set\nof labelled nulls to be fixed. This is why we will suppress\nthese sets in our notation.\n\nHomomorphisms. A homomorphism from a set of\natoms A1 to a set of atoms A2 is a mapping\n\u03bc : \u2206 \u222a \u2206null \u222a V \u2192 \u2206 \u222a \u2206null \u222a V\nsuch that the following conditions hold: (a) if c \u2208 \u2206, then\n\u03bc(c) = c, (b) if c \u2208 \u2206null , then \u03bc(c) \u2208 \u2206 \u222a \u2206null and (c) if\nR(c1 , ..., cn ) \u2208 A1 , then R(\u03bc(c1 ), ..., \u03bc(cn )) \u2208 A2 .\n\nA database instance I is an n-tuple (I1 , ..., In ), where\nIi \u2286 (\u2206 \u222a \u2206null )ar(Ri ) for every i \u2208 [n]. We will denote (c1 , ..., car(Ri ) ) \u2208 Ii by the fact Ri (c1 , ..., car(Ri ) ) and\ntherefore represent the instance I as the set if its facts. Abusing notation, we write I = { Ri (t) | t \u2208 Ii , i \u2208 [n] }.\n\nChase. Let \u03a3 be a set of TGDs and EGDs and I an\ninstance, represented as a set of atoms. We say that a TGD\n\u2200x\u03c6 \u2208 \u03a3 is applicable to I if there is a homomorphism \u03bc\nfrom body(\u2200x\u03c6) to I and \u03bc cannot be extended to a homomorphism \u03bc\u2032 \u2287 \u03bc from head(\u2200x\u03c6) to I. In such a case the\n\nA position is a position in a predicate, e.g. a three-ary\npredicate R has three positions R1 , R2 , R3 . We say that a\nvariable, labelled null or constant c appears e.g. in a position\nR1 if there exists a fact R(c, ...).\n\nchase step I \u2212\u2192 J is defined as follows. We define a\nhomomorphism \u03bd as follows: (a) \u03bd agrees with \u03bc on all universally quantified variables in \u03c6, (b) for every existentially\nquantified variable y in \u2200x\u03c6 we choose a \"fresh\" labelled\nnull ny \u2208 \u2206null and define \u03bd(y) := ny . We set J to be\nI \u222a \u03bd(head(\u2200x\u03c6)). We say that an EGD \u2200x\u03c6 \u2208 \u03a3 is applicable to I if there is a homomorphism \u03bc from body(\u2200x\u03c6) to\n\n\u2200x\u03c6,\u03bc(x)\n\nConstraints. Let x, y be tuples of variables. We consider two types of database constraints, i.e. tuple-generating\nand equality generating dependencies. A tuple-generating\ndependency (TGD) is a first-order sentence\n\n\u2200x\u03c6,a\n\nI and \u03bc(xi ) 6= \u03bc(xj ). In such a case the chase step I \u2212\u2192 J\nis defined as follows. We set J to be\n\u2022 I except that all occurrences of \u03bc(xj ) are substituted by\n\u03bc(xi ) =: a, if \u03bc(xj ) is a labelled null,\n\u2022 I except that all occurrences of \u03bc(xi ) are substituted by\n\u03bc(xj ) =: a, if \u03bc(xi ) is a labelled null,\n\u2022 undefined, if both \u03bc(xj ) and \u03bc(xi ) are constants. In this\ncase we say that the chase fails.\n\n\u03c6 := \u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)),\nsuch that (a) both \u03c6 and \u03c8 are conjunctions of atomic formulas (possibly with parameters from \u2206), (b) \u03c8 is not empty, (c)\n\u03c6 is possibly empty, (d) both \u03c6 and \u03c8 do not contain equality\natoms and (e) all variables from x that occur in \u03c8 must also\noccur in \u03c6. We denote by body(\u03c6) the set of atoms in \u03c6 and\nby head(\u03c6) the set of atoms in \u03c8.\n\nA chase sequence is an exhaustive application of applicable\nconstraints\n\nAn equality generating dependency (EGD) is a first-order\nsentence\n\n\u03c60 ,a0\n\n\u03c61 ,a1\n\nI0 \u2212\u2192 I1 \u2212\u2192 . . .,\n\n\u03c6 := \u2200x(\u03c6(x) \u2192 xi = xj ),\n\nwhere we impose no strict order what constraint must be\napplied in case several constraints apply. If this sequence\nis finite, say Ir being its final element, the chase terminates\nand its result I0\u03a3 is defined as Ir . The length of this chase\nsequence is r. Note that different orders of application of\napplicable constraints may lead to a different chase result.\nHowever, as proven in [28], two different chase orders lead\nto homomorphically equivalent results, if these exist. Therefore, we write I \u03a3 for the result of the chase on an instance\nI under constraints \u03a3. It has been shown in [24, 3, 16] that\nI \u03a3 |= \u03a3. In case that a chase step cannot be performed\n(e.g., because a homomorphism would have to equate two\nconstants) the chase result is undefined. In case of an infinite\nchase sequence, we also say that the result is undefined.\n\nwhere xi , xj occur in \u03c6 and \u03c6 is a non-empty conjunction of\nequality-free R-atoms (possibly with parameters from \u2206).\nWe denote by body(\u03c6) the set of atoms in \u03c6 and by head(\u03c6)\nthe set {xi = xj }.\nFor brevity, we will often omit the \u2200-quantifier and the\nrespective list of universally quantified variables.\nConstraint satisfaction. Let |= be the standard firstorder model relationship and \u03a3 be a set of TGDs and EGDs.\nWe say that a database instance I = (I1 , ..., In ) satisfies \u03a3,\ndenoted by I |= \u03a3, if and only if (\u2206 \u222a \u2206null , I1 , ..., In ) |= \u03a3\nin the sense of an R-structure.\n24\n\n\fTheorem 14. (see [8]) Let \u03a3 be a fixed and stratified\nset of constraints. Then, there exists a polynomial Q \u2208\nN[X] such that for any database instance I, the length\nof every chase sequence is bounded by Q(||I||), where\n||I|| is the number of distinct values in I. Thus, the\nchase terminates in polynomial time data complexity.\n\u2737\n\nProvisio. We will make a simplifying assumption. Let I\nbe a database instance and \u03a3 some constraint set. Without\nloss of generality we can assume that whenever two labelled\nnulls, say y1 , y2 , are equated by the chase and y1 \u2208 dom(I),\nthen all occurrences of y2 are mapped to y1 in the chase step.\nThis does not affect chase termination as substituting y1 with\ny2 would lead to an isomorphic instance.\nD.2\n\nPrevious Results\nD.3\n\nIn the following we are only interested in constraints for\nwhich any chase sequence is finite. In [28] weak acyclicity\nwas introduced, which is the starting point for our work.\nDefinition 17. (see [28]) Given a set of constraints \u03a3,\nits dependency graph dep(\u03a3) := (V, E) is the directed\ngraph defined as follows. V is the set of positions that\noccur in the TGDs in \u03a3. There are two kind of edges\nin E. Add them as follows: for every TGD\n\u2200x(\u03c6(x) \u2192 \u2203y\u03c8(x, y)) \u2208 \u03a3\nand for every x in x that occurs in \u03c8 and every occurrence of x in \u03c6 in position \u03c01\n\u2022 for every occurrence of x in \u03c8 in position \u03c02 , add an\nedge \u03c01 \u2192 \u03c02 (if it does not already exist).\n\u2022 for every existentially quantified variable y and for\nevery occurrence of y in a position \u03c02 , add a special\n\u2217\nedge \u03c01 \u2192 \u03c02 (if it does not already exist).\nA set \u03a3 of TGDs and EGDs is called weakly acyclic iff\ndep(\u03a3) has no cycles through a special edge.\n\u2737\n\nProof of Theorem 7\n\u2022 Follows directly from the definition of the propagation\ngraph. In the propagation graph stronger conditions have\nto be satisfied than in the dependency graph in order to\nadd special or non-special edges.\n\u2022 Let \u03b1 := S(X2 , X3 ), R(X1 , X2 , X3 ) \u2192 \u2203Y R(X2 , Y, X1 )\nand \u03b2 := R(X1 , X2 , X3 ) \u2192 S(X1 , X3 ). It can be seen\nthat \u03b1 \u227a \u03b2 and \u03b2 \u227a \u03b1. Together with the fact that\n{\u03b1, \u03b2} is not weakly acyclic it follows that {\u03b1, \u03b2} is not\nstratified. However, {\u03b1, \u03b2} is safe.\n\u2022 (see [8]) Let \u03b3 := T (X1 , X2 ), T (X2 , X1 ) \u2192 \u2203 Y1 , Y2\nT (X1 , Y1 ), T (Y1 , Y2 ), T (Y2 , X1 ). It was argued in [8]\nthat {\u03b3} is stratified. However, it is not safe because\nboth T 1 and T 2 are affected and therefore dep({\u03b3}) =\nprop({\u03b3}) and it was argued in [8] that it is not weakly\nacyclic.\n\u2737\n\nThen, in [8] stratification was set on top of the definition\nof weak acyclicity. The main idea is that we can test if a\nconstraint can cause another constraint to fire, which is the\nintuition of the following definition.\nDefinition 18. (see [8]) Given two TGDs or EGDs \u03b1 =\n\u2200x1 \u03c6, \u03b2 = \u2200x2 \u03c8, we define \u03b1 \u227a \u03b2 iff there exist database\ninstances I, J and a \u2208 dom(I), b \u2208 dom(J) such that\n\nProof of Theorem 8\nFirst we introduce some additional notation. We denote constraints in the form \u03c6(x1 , x2 , u) \u2192 \u2203y\u03c8(x1 , x2 , y), where\nx1 , x2 , u are all the universally quantified variables and\n\u2022 u are those variables that do not occur in the head,\n\u2022 every element in x1 occurs in a non-affected position in\nthe body, and\n\u2022 every element in x2 occurs only in affected positions in\nthe body.\n\n\u2022 I 2 \u03c6(b), possibly b is not in dom(I),\n\u03b1,a\n\n\u2022 I \u2212\u2192 J and\n\u2022 J 2 \u03c8(b).\n\nProofs of the Technical Results\n\n\u2737\nThe proof is inspired by the proof of Theorem 3.8 in [28],\nespecially the notation and some introductory definitions are\ntaken from there. In a first step we will give the proof for\nTGDs only, i.e. we do not consider EGDs. Later, we will see\nwhat changes when we add EGDs again.\n\nThe actual definition of stratification then relies on weak\nacyclicity.\nDefinition 19. (see [8]) The chase graph G(\u03a3) = (\u03a3, E)\nof a set of TGDs \u03a3 contains a directed edge (\u03b1, \u03b2) between two constraints iff \u03b1 \u227a \u03b2. We call \u03a3 stratified iff\nthe set of constraints in every cycle of G(\u03a3) are weakly\nacyclic.\n\u2737\nTheorem 13. (see [8]) If a set of constraints of weakly\nacyclic, then it is also stratified. It can be decided by\na coNP-algorithm whether a set of constraints is stratified.\n\u2737\n\nNote that \u03a3 is fixed. Let (V, E) be the propagation graph\nprop(\u03a3). For every position \u03c0 \u2208 V an incoming path is a,\npossibly infinite, path ending in \u03c0. We denote by rank(\u03c0) the\nmaximum number of special edges over all incoming paths.\nIt holds that rank(\u03c0) < \u221e because prop(\u03a3) contains no\ncycles through a special edge. Define r := max{ rank(\u03c0) |\n\u03c0 \u2208 V } and p := |V |. It is easily verified that r \u2264 p, thus\nr is bounded by a constant. This allows us to partition the\npositions into sets N0 , ..., Np such that Ni contains exactly\nthose positions \u03c0 with rank(\u03c0) = i. Let n be the number of\nvalues in I. We define dom(\u03a3) as the set of constants in \u03a3.\n\nThe crucial property of stratification is that it guarantees\nthe termination of the chase in polynomially many chase\nsteps.\n25\n\n\fChoose some \u03b1 := \u03c6(x1 , x2 , u) \u2192 \u2203y\u03c8(x1 , x2 , y) \u2208 \u03a3.\n\nProof of Theorems 9 and 10\n\n\u03b1,a1 a2 b\n\nLet I \u2192 . . . \u2192 G \u2212\u2192 G\u2032 and let c be the newly created\nnull values in the step from G to G\u2032 . Then\n\nTheorem 9 Follows from Theorem 12. Before we prove\nTheorem 10, we introduce some additional tool.\n\n1. newly introduced labelled nulls occur only in affected\npositions,\n2. a1 \u2286 dom(I) \u222a dom(\u03a3) and\n3. for every labelled null Y \u2208 a2 that occurs in \u03c0 in \u03c6\nand every c \u2208 c that occurs in \u03c1 in \u03c8 it holds that\nrank(\u03c0) < rank(\u03c1).\n\nIn general, a set of constraints may have several restriction\nsystems. A restriction system is minimal if it is obtained\nfrom ((\u03a3, \u2205),{(\u03b1, \u2205) | \u03b1 \u2208 \u03a3}) by a repeated application\nof the constraints from bullets one to three in Definition 13\n(until all constraints hold) s.t., in case of the first and second\nbullet, the image of f (\u03b2) is extended only by those positions\nthat are required to satisfy the condition. Thus, a minimal\nrestriction system can be computed by a fixedpoint iteration.\n\nThis intermediate claim is easily proved by induction on\nthe length of the chase sequence. Now we show by induction\non i that the number of values that can occur in any position\nin Ni in G\u2032 is bounded by some polynomial Qi in n that\ndepends only on i (and, of course, \u03a3). As i \u2264 r \u2264 p, this\nimplies the theorem's statement because the maximal arity\nar(R) of a relation is fixed. We denote by body(\u03a3) the number of characters of the largest body of all constraints in \u03a3.\n\nLemma 10. Let \u03a3 be a set of constraints, (G\u2032 (\u03a3), f ) a\nrestriction system for \u03a3 and (G\u2032min (\u03a3), fmin ) its minimal one.\n\u2022 Let P be a set of positions and \u03b1, \u03b2 constraints.\nThen, the mapping (P, \u03b1, \u03b2) 7\u2192 \u03b1 \u227aP \u03b2? can be\ncomputed by an NP-algorithm.\n\u2022 The minimal restriction system for \u03a3 is unique. It\ncan be computed from \u03a3 in non-deterministic polynomial time.\n\u2022 It holds that \u03a3 is safely restricted if and only if every\nstrongly connected component in G\u2032min (\u03a3) is safe. \u2737\n\nCase 1: i = 0. We claim that Q0 (n):=n+|\u03a3|*nar(R)*body(\u03a3)\nis sufficient for our needs. We consider a position \u03c0 \u2208 N0\nand an arbitrary TGD from \u03a3 such that \u03c0 occurs in the head of\n\u03b1. For simplicity we assume that it has the syntactic form of\n\u03b1. In case that there is a universally quantified variable in \u03c0,\nthere can occur at most n distinct elements in \u03c0. Therefore,\nwe assume that some existentially quantified variable occurs\nin \u03c0 in \u03c8. Note that as i = 0 it must hold that |x2 | = 0. Every\nvalue in I can occur in \u03c0. But how many labelled nulls can\nbe newly created in \u03c0? For every choice of a1 \u2286 dom(G)\nsuch that G |= \u03c6(a1 , \u03bb, b) and G 2 \u2203y\u03c8(a1 , \u03bb, y) at most\none labelled null can be added to \u03c0 by \u03b1. Note that in this\ncase it holds that a1 \u2286 dom(I) due to (1). So, there are at\nmost nar(R)*body(\u03a3) such choices. Over all TGDs at most\n|\u03a3| * nar(R)*body(\u03a3) labelled nulls are created in \u03c0.\n\nProof. The proof of part one of the lemma proceeds like\nthe proof of Theorem 3 in [8]. It is enough to consider\ncandidate databases for A of size at most |\u03b1|+|\u03b2|, i.e. unions\nof homomorphic images of the premises of \u03b1 and \u03b2 s.t. null\nvalues occur only in positions from P . This concludes part\none.\n\nPi\nCase 2: i \u2192 i + 1. We claim that Qi+1 (n) := j=0 Qi (n)+\nPi\n|\u03a3| * ( j=0 Qi (n))ar(R)*body(\u03a3) is such a polynomial. Consider the fixed TGD \u03b1. Let \u03c0 \u2208 Ni+1 . Values in \u03c0 may\nbe either copied from a position in N0 \u222a ... \u222a Ni or may\nbe a new labelled null. Therefore w.l.o.g. we assume\nthat some existentially quantified variable occurs in \u03c0 in\n\u03c8. In case a TGD, say \u03b1, is violated in G\u2032 there must exist\na1 , a2 \u2286 domG\u2032 (N0 , ..., Ni ) and b \u2286 dom(G\u2032 ) such that\nG\u2032 |= \u03c6(a1 , a2 , b), but G\u2032 2 \u2203y\u03c8(a1 , a2 , y). If newly introduced labelled null occurs in a2 , say in some position \u03c1, then\nSi\nPi\n\u03c1 \u2208 j=0 Nj . As there are at most ( j=0 Qi (n))ar(R)*body(\u03a3)\nPi\nmany such choices for a1, a2 , at most ( j=0 Qi (n))ar(R)*body(\u03a3)\nmany labelled nulls can be newly created in \u03c0.\n\nUniqueness holds by definition. It can be computed via\nsuccessive application of the constraints (note that f and E\nare changed in each step) in definition 13 by a Turing machine\nthat guesses answers to the question \u03b1 \u227aP \u03b2?. As the\nmapping (P, \u03b1, \u03b2) 7\u2192 \u03b1 \u227aP \u03b2? can be computed by an NPalgorithm and the fixedpoint is reached after polynomially\nmany applications of the constraints from definition 13, this\nimplies the second claim.\nConcerning the second claim, observe that every strongly\nconnected component in G\u2032min (\u03a3) is contained in a single\nstrongly connected component of any other restriction system. This implies the third claim.\u2737\nNow we turn towards the proof of Theorem 10. By the\nprevious lemma it suffices to check the conditions from definition 14 only for the minimal restriction system. To decide\nwhether \u03a3 is not safely restricted, compute the minimal restriction system, guess a strongly connected component and\ncheck if it is not safe. Clearly, this can be done in nondeterministic polynomial time. \u2737\nProof of Theorem 11 (Sketch)\n\nWhen we allow EGDs among our constraints, we have that\nthe number of values that can occur in any position in Ni in G\u2032\ncan be bounded by the same polynomial Qi because equating\nlabelled nulls does not increase the number of labelled nulls\nand the fact that EGDs preserve valid existential conclusions\nof TGDs. \u2737\n\nBefore proving this theorem, we need a technical lemma. It\nstates the most important property of restriction systems.\nLemma 11. Let \u03b1 \u2208 \u03a3 and (G(\u03a3), f ) a restriction system for \u03a3 and I be a database instance. If during the\n26\n\n\f\u03b1,a\n\nis not safe. Therefore, it is also not safely stratified.\nThe minimal restriction system is ((\u03a3, E), f ), where\nE = \u2205 and f = { (\u03b3, \u2205) | \u03b3 \u2208 \u03a3 }. Obviously, every cycle in (\u03a3, E) is safe. Hence, \u03a3 is safely restricted.\n\u2737\n\nchase it occurs that J1 \u2192 J2 , then the set of positions\nin which null values from a that are not in dom(I) occur\nin the body of \u03b1 is contained in f (\u03b1).\n\u2737\nThe proof of this lemma is by induction on the length of\nthe chase sequence with which J1 was obtained from I and is\nstraightforward. Note that it uses the simplifying assumption\nthat we introduced at the end of appendix D.1.\n\nProof of Proposition 3\n\n\u2032\n\nLet us now turn to the proof of Theorem 11. Let (G (\u03a3), f ) =\n((G, E), f ) be the minimal restriction system of \u03a3. Let\nC1 , ..., Cm be all the pairwise different strongly connected\ncomponents of the reflexive closure of G\u2032 (\u03a3). The graph H\nis defined as the quotient graph with respect to { (\u03b1, \u03b2) \u2208 E\n| \u2203i \u2208 [m] : \u03b1, \u03b2 \u2208 Ci }, i.e. H := G\u2032 (\u03a3)/{ (\u03b1, \u03b2) \u2208 E |\n\u2203i \u2208 [m] : \u03b1, \u03b2 \u2208 Ci }. H is acyclic and depends only on\n\u03a3. We show the claim by induction on the number of nodes\nn in H.\n\nLet (G\u2032 (\u03a3), f ) be a restriction system for \u03a3 such that every\nstrongly connected component in G\u2032 (\u03a3) is safely stratified.\nChoose some strongly connected component C and two constraints \u03b1, \u03b2 \u2208 C such that \u03b1 \u227aP \u03b2 for some set of positions\nP . By Proposition 6, \u03b1 \u227a \u03b2 holds. As C is safely stratified,\nthis means that C must also be safe. So, every cycle in G\u2032 (\u03a3)\nis also safe.\n\u2737\nProof of Proposition 4\n\u2022 Let \u03a3 := {\u2200x1 , x2 (T (e, x1 , x2 ), T (x2 , d, d) \u2192 T (x1 , x2 , x1 ))},\nwhere d is a constant and xi are variables. Then, \u03a3\u2032 = \u2205.\n\u2022 An example for such a set of constraints C is constituted\nas follows.\nT (x1 , d, x2 ) \u2192 \u2203yT (g, e, y), T (f, d, y)\nT (x1 , e, x2 ) \u2192 \u2203yT (g, e, y), T (f, d, y)\nT (x1 , d, x2 ) \u2192 T (x2 , e, x1 )\nT (x1 , e, x2 ) \u2192 \u2203yT (x2 , d, y)\nNote that d, e, f, g are constants.\n\u2737\n\nCase: n = 1: G\u2032 (\u03a3) has a single strongly connected\ncomponent. This component is safe by prerequisite. It follows from Theorem 8 that the chase terminates in polynomial\ntime data complexity in this case.\nCase: n 7\u2192 n + 1: Let h be a node in H that has no\nsuccessors and H\u2212 the union of constraints from all other\nnodes in H. The chase with H\u2212 terminates by induction\nhypothesis, say that the number of distinct value in this result\nis bounded by some polynomial Q\u2212 . Chasing the constraints\nin h alone terminates, too, say that the number of distinct\nvalue in this result is bounded by the polynomial q. The\nfiring of constraints from H\u2212 can cause some constraints\nfrom h to copy null values in their heads. Yet, the firing\nof constraints in h cannot enforce constraints from H\u2212 to\ncopy null values to their head (by construction of the minimal\nrestriction system). If I is the database instance to be chased,\nthen the number of distinct value in this result is bounded\nby Q\u2212 (||I||) + q(||I|| + Q\u2212 (||I||)). As \u03a3 is fixed we can\nconclude that the chase terminates in polynomial time data\ncomplexity. \u2737\nProof of Theorem 12\n\u2022 Let \u03a3 be weakly acyclic. Every cycle in G(\u03a3) is safe,\nbecause \u03a3 is safe and weak acyclicity implies safety. Let\n\u03a3 be safe. Every cycle in G(\u03a3) is safe, because \u03a3 is.\n\u2022 Follows from Example 5 and the following proposition.\nProposition 6. Let P \u2286 P \u2032 \u2286 pos(\u03a3). If \u03b1 \u227aP \u03b2,\nthen \u03b1 \u227aP \u2032 \u03b2. It holds that if \u03b1 \u227aP \u03b2, then \u03b1 \u227a \u03b2.\n\u2737\nThe proof follows from the definition of \u227aP and \u227a.\n\u2022 Consider the following TGDs. \u03a3 := {\u03b1, \u03b2, \u03c7, \u03b4}.\n\u03b1 := R1 (x1 , x2 ) \u2192 \u2203yS(x1 , x2 , y),\n\u03b2 := R1 (x1 , x2 ) \u2192 \u2203yT (x1 , x2 , y),\n\u03c7 := S(x1 , x2 , x3 ), T (x4 , x5 , x6 ) \u2192 T (x5 , x1 , x4 ) and\n\u03b4 := S(x1 , x2 , x3 ), T (x4 , x5 , x3 ) \u2192 T (x1 , x3 , x3 ),\nR1 (x3 , x1 ), R2 (x3 , x1 ).\nIt can be seen that \u03b1 \u227a \u03c7, \u03b2 \u227a \u03c7, \u03c7 \u227a \u03b4, \u03b4 \u227a \u03b1 and\n\u03b4 \u227a \u03b2 holds. Thus , there is a cycle in the chase graph that\ninvolves all constraints. Unfortunately, the constraint set\n27\n\n\f"}