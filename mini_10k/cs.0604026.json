{"id": "http://arxiv.org/abs/cs/0604026v1", "guidislink": true, "updated": "2006-04-07T12:13:19Z", "updated_parsed": [2006, 4, 7, 12, 13, 19, 4, 97, 0], "published": "2006-04-07T12:13:19Z", "published_parsed": [2006, 4, 7, 12, 13, 19, 4, 97, 0], "title": "APHRODITE: an Anomaly-based Architecture for False Positive Reduction", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0604099%2Ccs%2F0604021%2Ccs%2F0604015%2Ccs%2F0604051%2Ccs%2F0604006%2Ccs%2F0604088%2Ccs%2F0604107%2Ccs%2F0604095%2Ccs%2F0604048%2Ccs%2F0604078%2Ccs%2F0604045%2Ccs%2F0604075%2Ccs%2F0604042%2Ccs%2F0604070%2Ccs%2F0604013%2Ccs%2F0604049%2Ccs%2F0604056%2Ccs%2F0604054%2Ccs%2F0604097%2Ccs%2F0604044%2Ccs%2F0604032%2Ccs%2F0604039%2Ccs%2F0604106%2Ccs%2F0604085%2Ccs%2F0604079%2Ccs%2F0604103%2Ccs%2F0604029%2Ccs%2F0604065%2Ccs%2F0604112%2Ccs%2F0604017%2Ccs%2F0604038%2Ccs%2F0604098%2Ccs%2F0604100%2Ccs%2F0604025%2Ccs%2F0604057%2Ccs%2F0604014%2Ccs%2F0604058%2Ccs%2F0604062%2Ccs%2F0604028%2Ccs%2F0604102%2Ccs%2F0604091%2Ccs%2F0604010%2Ccs%2F0604093%2Ccs%2F0604026%2Ccs%2F0604002%2Ccs%2F0604031%2Ccs%2F0604023%2Ccs%2F0604001%2Ccs%2F0604104%2Ccs%2F0604040%2Ccs%2F0604109%2Ccs%2F0604016%2Ccs%2F0604033%2Ccs%2F0604011%2Ccs%2F0604086%2Ccs%2F0604052%2Ccs%2F0604067%2Ccs%2F0512102%2Ccs%2F0512104%2Ccs%2F0512001%2Ccs%2F0512073%2Ccs%2F0512089%2Ccs%2F0512034%2Ccs%2F0512026%2Ccs%2F0512043%2Ccs%2F0512085%2Ccs%2F0512097%2Ccs%2F0512010%2Ccs%2F0512091%2Ccs%2F0512060%2Ccs%2F0512088%2Ccs%2F0512079%2Ccs%2F0512044%2Ccs%2F0512051%2Ccs%2F0512074%2Ccs%2F0512069%2Ccs%2F0512032%2Ccs%2F0512025%2Ccs%2F0512048%2Ccs%2F0512055%2Ccs%2F0512004%2Ccs%2F0512030%2Ccs%2F0512045%2Ccs%2F0512070%2Ccs%2F0512035%2Ccs%2F0512066%2Ccs%2F0512023%2Ccs%2F0512056%2Ccs%2F0512059%2Ccs%2F0512063%2Ccs%2F0512065%2Ccs%2F0512037%2Ccs%2F0512009%2Ccs%2F0512105%2Ccs%2F0512016%2Ccs%2F0512049%2Ccs%2F0512033%2Ccs%2F0512027%2Ccs%2F0512021%2Ccs%2F0512082%2Ccs%2F0512024&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "APHRODITE: an Anomaly-based Architecture for False Positive Reduction"}, "summary": "We present APHRODITE, an architecture designed to reduce false positives in\nnetwork intrusion detection systems. APHRODITE works by detecting anomalies in\nthe output traffic, and by correlating them with the alerts raised by the NIDS\nworking on the input traffic. Benchmarks show a substantial reduction of false\npositives and that APHRODITE is effective also after a \"quick setup\", i.e. in\nthe realistic case in which it has not been \"trained\" and set up optimally", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0604099%2Ccs%2F0604021%2Ccs%2F0604015%2Ccs%2F0604051%2Ccs%2F0604006%2Ccs%2F0604088%2Ccs%2F0604107%2Ccs%2F0604095%2Ccs%2F0604048%2Ccs%2F0604078%2Ccs%2F0604045%2Ccs%2F0604075%2Ccs%2F0604042%2Ccs%2F0604070%2Ccs%2F0604013%2Ccs%2F0604049%2Ccs%2F0604056%2Ccs%2F0604054%2Ccs%2F0604097%2Ccs%2F0604044%2Ccs%2F0604032%2Ccs%2F0604039%2Ccs%2F0604106%2Ccs%2F0604085%2Ccs%2F0604079%2Ccs%2F0604103%2Ccs%2F0604029%2Ccs%2F0604065%2Ccs%2F0604112%2Ccs%2F0604017%2Ccs%2F0604038%2Ccs%2F0604098%2Ccs%2F0604100%2Ccs%2F0604025%2Ccs%2F0604057%2Ccs%2F0604014%2Ccs%2F0604058%2Ccs%2F0604062%2Ccs%2F0604028%2Ccs%2F0604102%2Ccs%2F0604091%2Ccs%2F0604010%2Ccs%2F0604093%2Ccs%2F0604026%2Ccs%2F0604002%2Ccs%2F0604031%2Ccs%2F0604023%2Ccs%2F0604001%2Ccs%2F0604104%2Ccs%2F0604040%2Ccs%2F0604109%2Ccs%2F0604016%2Ccs%2F0604033%2Ccs%2F0604011%2Ccs%2F0604086%2Ccs%2F0604052%2Ccs%2F0604067%2Ccs%2F0512102%2Ccs%2F0512104%2Ccs%2F0512001%2Ccs%2F0512073%2Ccs%2F0512089%2Ccs%2F0512034%2Ccs%2F0512026%2Ccs%2F0512043%2Ccs%2F0512085%2Ccs%2F0512097%2Ccs%2F0512010%2Ccs%2F0512091%2Ccs%2F0512060%2Ccs%2F0512088%2Ccs%2F0512079%2Ccs%2F0512044%2Ccs%2F0512051%2Ccs%2F0512074%2Ccs%2F0512069%2Ccs%2F0512032%2Ccs%2F0512025%2Ccs%2F0512048%2Ccs%2F0512055%2Ccs%2F0512004%2Ccs%2F0512030%2Ccs%2F0512045%2Ccs%2F0512070%2Ccs%2F0512035%2Ccs%2F0512066%2Ccs%2F0512023%2Ccs%2F0512056%2Ccs%2F0512059%2Ccs%2F0512063%2Ccs%2F0512065%2Ccs%2F0512037%2Ccs%2F0512009%2Ccs%2F0512105%2Ccs%2F0512016%2Ccs%2F0512049%2Ccs%2F0512033%2Ccs%2F0512027%2Ccs%2F0512021%2Ccs%2F0512082%2Ccs%2F0512024&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We present APHRODITE, an architecture designed to reduce false positives in\nnetwork intrusion detection systems. APHRODITE works by detecting anomalies in\nthe output traffic, and by correlating them with the alerts raised by the NIDS\nworking on the input traffic. Benchmarks show a substantial reduction of false\npositives and that APHRODITE is effective also after a \"quick setup\", i.e. in\nthe realistic case in which it has not been \"trained\" and set up optimally"}, "authors": ["Damiano Bolzoni", "Sandro Etalle"], "author_detail": {"name": "Sandro Etalle"}, "author": "Sandro Etalle", "links": [{"href": "http://arxiv.org/abs/cs/0604026v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0604026v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0604026v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0604026v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "APHRODITE: an Anomaly-based Architecture\nfor False Positive Reduction\u22c6\n\narXiv:cs/0604026v1 [cs.CR] 7 Apr 2006\n\nDamiano Bolzoni, Sandro Etalle\nUniversity of Twente,\nP.O. Box 2100, 7500 AE Enschede, The Netherlands\n{damiano.bolzoni, sandro.etalle}@utwente.nl\n\nAbstract. We present APHRODITE, an architecture designed to reduce false positives in network intrusion detection systems. APHRODITE\nworks by detecting anomalies in the output traffic, and by correlating\nthem with the alerts raised by the NIDS working on the input traffic. Benchmarks show a substantial reduction of false positives and that\nAPHRODITE is effective also after a \"quick setup\", i.e. in the realistic\ncase in which it has not been \"trained\" and set up optimally.\nKeywords: Intrusion Detection, False Positives\n\n1\n\nIntroduction\n\nNetwork intrusion detection systems (NIDSs) are considered an effective second\nline of defense against network-based attacks directed at computer systems [1,2],\nand \u2013 due to the increasing severity and likelihood of such attacks \u2013 are employed\nin almost all large-scale IT infrastructures [3].\nThe Achille's heel of NIDSs lies in the large number of false positives (i.e.,\nfalse attacks) that occur: practitioners [4,5] as well as researchers [6,7,8] observe\nthat it is common for a NIDS to raise thousands of mostly false alerts per day.\nManganaris et al. [4] were able to collect more than 15,000 alerts per day per\nsensor during a monitoring period of just one month. Julisch [9] states that up\nto 99% of total alarms can be false alarms. Indeed, a high rate of false alarms\nis \u2013 also according to Axelsson [6] \u2013 the limiting factor for the performance of\nan intrusion detection system. False alarms often cause an overload for IT personnel [4], who must verify every single alert to prevent or block possible loss of\ndata confidentiality, integrity and availability (CIA). The manual identification\nof true positives amongst this flood of alarms it is not only labor intensive but\nalso error prone [10].\nFalse positives are a universal problem as they affect both signature-based\nintrusion detection systems and anomaly-based systems [11]. Finally, a high false\npositive rate can even be exploited by attackers to overload IT personnel, thereby\nlowering the defenses of the IT infrastructure.\n\u22c6\n\nThis\nresearch\nis\nsupported\nby\nthe\nresearch\nprogram\nSentinels\n(http://www.sentinels.nl). Sentinels is being financed by Technology Foundation STW, the Netherlands Organization for Scientific Research (NWO), and the\nDutch Ministry of Economic Affairs.\n\n\f2\n\nContribution of this paper Our thesis is that one of the main reasons why NIDSs\nshow a high false positive rate is that they do not correlate input with output\ntraffic: by observing the output determined by the alert-raising input traffic, one\nis capable to reduce the number of false positives in an effective manner.\nTo demonstrate this, we have developed APHRODITE (Architecture for false\nPositives Reduction): an innovative architecture for reducing the false positive\nrate of any NIDS (be it signature-based or anomaly-based). APHRODITE consists of an output anomaly detector (OAD) and a correlation engine; in addition,\nAPHRODITE assumes the presence of a NIDS on the input of the system (see\nFigure 1).\nWe have benchmarked APHRODITE in combination with the signaturebased NIDS Snort [12,13], as well as APHRODITE in combination with the\nanomaly-based NIDS POSEIDON. We have carried out the benchmarks both\non the common DARPA 1999 data set [14] as well as on a private data set. In\n6 out of 7 cases, our benchmarks show a reduction of false positives between\n50% and 100%, which is better than the only leading competitor [15] providing\nbenchmarks on a public data set.\n\nFig. 1. APHRODITE architecture\n\nArchitecture The main idea of our approach is simple: a successful attack often\ncauses an anomaly in the output of the system. For instance, a successful SQL\ninjection against a web-based system would typically cause the system to output\ne.g. SQL tables rather than the usual web pages. Taking advantage of this,\n\n\f3\n\nAPHRODITE works as follows: when the NIDS raises an alert, the correlation\nengine checks whether the communication that raised this alert also causes an\nanomaly in the output (detected by the OAD). If this is the case, the alert is\nconsidered a true positive and APHRODITE forwards it to the IT professionals,\notherwise, it is discarded as a false positive. (There are various exceptions to\nthis behaviour, taking into account e.g., the possible absence of output or the\nquality/quantity of alerts raised by the NIDS, we explain this in Section 3.)\nQuick setup Our benchmarks show that APHRODITE is effective also after\na \"quick setup\", without an optimal training and by using a simple heuristics\nfor setting the threshold. This is particularly relevant because anomaly detection systems (like our OAD) are often regarded as systems whose deployment\nis rather labor-intensive. This is because they need to be trained with a considerable amount (gigabytes) of data, which should be as clean as possible: the\ntraining data set should be representative of attack-free traffic. To carry out\nsuch a training, in principle the IT professional should clean up the data set by\ninspecting it and by manually removing the spurious traffic, a procedure which\nis time consuming. Moreover, the anomaly detector should be re-trained each\ntime that changes in the system denote a change in the traffic type. In addition, anomaly-detection systems require the IT professional to spend time to set\nthe threshold (see also Section 2). In our case we show that APHRODITE is\nreasonably accurate and complete also when it is trained with a data set that\nwas not cleaned up manually, and when the threshold is set using simple heuristics. This makes APHRODITE attractive for real-life situations, in which the IT\nprofessionals want to have a tool helping them to isolate true positives without\nrequiring a troublesome set up.\nStructure of the paper This paper is organized as follows: in Section 2 we introduce intrusion detection systems and the problems related to false positive.\nSection 3 reports the system architecture and its properties. In Section 4 we\nreport the results of our benchmarks. In Section 5 we discuss other related work.\nFinally, in Section 6 we draw our conclusions and set the course for further\ndevelopments. In the Appendix we report the pseudo-code of APHRODITE.\n\n2\n\nPreliminaries\n\nIn this Section, we introduce the concepts used in the rest of the paper and we\nexplain in more detail than in the introduction how false positives arise and the\nharm they can do to a system. Those who are familiar with signature-based and\nanomaly-based intrusion detection systems may skip this part.\nThere exist two different sorts of network intrusion detection systems: signaturebased and anomaly-based; both types are affected by a high false positive rate.\n2.1\n\nSignature-Based Systems\n\nSignature-based systems (e.g. Snort [12,13]) are based on pattern-recognition\ntechniques: the NIDS contains a database of signatures of known attacks and\n\n\f4\n\ntries to match these signatures against the analyzed data. When a match is\nfound, an alarm is raised. A signature must be developed off-line, and then loaded\nin the database before the system can begin to detect a particular intrusion. One\nof the disadvantages of signature-based NIDS is that they can detect only known\nattacks: all new attacks will go unnoticed until the system is updated, creating a\nwindow of opportunity for attackers (and affecting the NIDS completeness and\naccuracy [16,2]). Although this is considered acceptable for detecting attacks\nto e.g., the OS, it makes them less suitable for protecting web-based services,\nbecause of their ad-hoc and dynamic nature.\nFalse Positives in Signature-Based Systems Signature-based systems raise\nan alarm each time that traffic matches one of the signatures loaded into the\nsystem. For example: the path traversal attack allows access to files, directories,\nand commands that reside outside the (given) web document root directory.\nThe most elementary path traversal attack uses the ../ character sequence to\nalter the resource location requested in the URL. Variations include valid and\ninvalid Unicode-encoding (\"..%u2216\" or \"..%c0%af\"), URL encoded characters (\"%2e%2e%2f\"), and double URL encoding (\"..%255c\") of the backslash\ncharacter (excerpted from WASC Threat Classification [17]).\nTo detect these attacks, Snort, with the default configuration (like any signature-based intrusion detection system), raises an alarm each time that it identifies the pattern ../ in the incoming traffic. Unfortunately, this pattern is also\noften present in legal traffic, and this causes Snort to raise a high number of false\nalarms. These false alarms can be avoided by deactivating this rule, but this on\nthe other hand prevents the NIDS from finding this sort of attacks.\nTuning Signature-Based Systems A common way to reduce false positives in\nsignature-based systems is by deactivating the signatures relative to vulnerabilities that are not present in the given environment: many signatures can be\ndisabled because the monitored services are not exposed to a certain vulnerability\nor the vulnerability itself affects only certain OS platforms. This configuration\nphase of signature-based systems is also known as tuning and it is explicitly\nrequired when deploying NIDSs with several sensors in complex environments.\nTuning requires a thorough analysis of the environment by qualified IT personnel and the tuning must be kept up-to-date to keep up with the changes in the\nsystem: new vulnerabilities are discovered every day, new signatures are released\nregularly, and systems may be patched, thereby removing vulnerabilities.\n2.2\n\nAnomaly-Based Systems\n\nAnomaly-based systems (ABS), unlike signature-based systems, first build a statistical model describing the normal network traffic, then flag any behaviour that\nsignificantly deviates from the model as an attack. This is achieved by implementing a distance function and setting a threshold value: when the distance\nbetween the input sample and the model exceeds the threshold, an alert is raised.\n\n\f5\n\nThe main advantage of ABSs is that they can detect zero-day attacks: novel\nattacks can be detected as soon as they take place. The disadvantage is that an\nABS requires an extensive model building phase: a significant amount of (largely\nattack-free) data must be analyzed to build accurate models of legal behaviour.\nFalse Positives in Anomaly-Based Systems The value of the threshold\nhas a direct influence on both false negatives and false positives rates [18]: a low\nthreshold yields a high number of alarms, and therefore a low false negative rate,\nbut a high false positive rate. On the other hand a high threshold yields a low\nnumber of alarms in general (therefore a high number of false negatives, but a\nlow number of false positives). As a matter of fact, the high false positive rate\nis generally cited as one of the main disadvantages of anomaly-based systems.\nTuning Anomaly-Based Systems The most commonly used tuning procedure for\nABS is finding an optimal threshold value, i.e., the best compromise between a\nlow number of false negatives and a low (or acceptable) number of false positives. This is typically carried out manually by trained IT personnel: different\nimproving steps can be necessary to obtain a good balance between detection\nrate and false positive rate.\n2.3\n\nExploiting false positives\n\nTo conclude this section, we note that the presence of a NIDS with a relatively\nhigh number of false positives can also be exploited by an attacker.\nBoth signature-based and anomaly-based systems can be fooled to raise thousands of alerts: in the former case, the attacker can force an alert by inserting a\nknown attack sequence randomly in the input (e.g. inside a field of a web page\nform), even if it is not aimed to exploit any vulnerability; in the latter case, the\nattacker can send an input that is substantially different from the data analyzed\nduring the training phase (e.g. a long stream with the same character, which\nobviously was never observed before).\nThis can be exploited by an attacker, e.g., to perpetrate a Denial of Service\nattack against IT personnel [4] or to hide a real attack.\n\n3\n\nArchitecture\n\nThe main idea of our approach is the following: a successful attack (incident) [3]\nto a system (e.g., a web service) usually produces an anomaly in the output of\nthe system. On the other hand, if something in the input of the system causes\nthe NIDS to raise an alarm but does not cause the system to produce an unusual\noutput, then this alarm is likely to be a false positive.\nExample 1. SQL Injection is a technique that exploits vulnerabilities of (webbased) applications which are interfaced to an SQL database: if the application\n\n\f6\n\ndoes not sanitize potentially harmful characters first [17], an intruder can inject an SQL query in the database, and force the database to output sensitive\ndata (e.g. user passwords and personal details) from database tables, without\nbeing authorized. SQL Injections are considered a serious threat and are constantly listed in the \"Top Ten Most Critical Web Application Security Vulnerabilities\" [19] by \"The Open Web Application Security Project\".\nFor instance, the following HTTP request is actually a well-known attack [20]\nagainst the Content Management System (CMS) PostNuke [21] that can be used\nto get hold of the user passwords:\nhttp://[target]/[postnuke_dir]/modules.php?op=modload\n&name=Messages&file=readpmsg&start=\n0%20UNION%20SELECT%20pn_uname,null,pn_uname,pn_pass,pn_p\nWhen such an attack is carried out successfully, the output (a database table) is\nsignificantly different from the HTML page usually rendered. This is exploited\nby our system to distinguish false positive from true positives.\nAPHRODITE works by detecting anomalies in the output of the system and\nby correlating them to the alerts raised by the NIDS monitoring the input of the\nsystem. We want to stress that the NIDS monitoring the input is essential for the\nfunctioning of APHRODITE, but it is not part of APHRODITE's architecture:\nas a matter of fact\nAPHRODITE can work together with any kind of NIDS (be it anomalybased or signature-based).\nThe central component of APHRODITE is the Output Anomaly Detector\n(OAD), which is an anomaly-based NIDS placed on the output channel: the\nOAD refers to a statistical model describing the normal output of the system,\nand flags any behaviour that significantly deviates from the norm as the result\nof a possible attack. To connect the input to the output NIDS, the correlation\nengine is implemented with a stateful-inspection mechanism [22] to track and\ncorrelate input and output data belonging to the same communication.\nAPHRODITE works as follows (see Figure 1): the external NIDS monitors\nthe input data while, simultaneously, the OAD analyzes the response of network\nservices; when the input NIDS raises an alarm, it warns the correlation engine\n(CE), indicating the endpoint information (i.e. source and destination IP addresses, source and destination TCP ports) of the packet that raised the alert.\nAt this moment, the alert is not considered an incident yet (it is a pre-alarm)\nand is not forwarded immediately to the IT specialists yet. Next, the correlation\nengine marks the communication relative to the given endpoints as suspicious\nand waits for the output of the OAD: if the OAD detects an anomaly in the\noutgoing traffic related to the tracked communication, then the system considers the alert as an incident (i.e. a true positive) and the alert is forwarded to\nthe IT specialists for further handling and countermeasures reactions, otherwise\nit is considered a false positive.\nWhat we just described is the most common behaviour; nevertheless there\nexist important exceptions to it. Once an alarm has been raised by the input\nNIDS, the following exceptions can take place:\n\n\f7\n\n1. Missing output response. If the OAD does not detect any output related\nto the pre-alarm raised by the NIDS, then the pre-alarm is considered a true\nincident and is forwarded to the IT specialist.\nThis is because the pre-alarm could belong to a denial of service attack\nagainst a certain network service (preventing normal functioning or causing\na complete stop), leading to a situation of missing response.\nTherefore, the absence of an output should be considered an anomaly in\nthe normal data flow and must be handled accordingly by the correlation\nengine. To this end, we need to set appropriate application-dependent timeouts (commonly a data exchange between peers take place in a short time):\nafter their expiration the communication can be marked as anomalous.\n2. Alarm magnitude. When the NIDS monitoring the input is anomaly-based\n(as opposed to signature-based), then when it raises an alert it can also\nindicate the magnitude of the alert: anomaly-based NIDS compare the traffic\nto a statistical model of the traffic, and raise an alert when the input sample\nexceeds a give threshold. Here, by alarm magnitude we indicate the distance\nbetween the alarm-raising packet and the threshold. The higher the alarm\nmagnitude, the more anomalous is the packet, and therefore the more likely\nthat it indicates a true incident.\nIn APHRODITE when the magnitude is higher than a given value the alert\nraised by the NIDS is considered an incident, even if the OAD has not\ndetected any anomaly in the output.\n3. Number of alarm-raising packets. APHRODITE takes into account the\nnumber of anomalies regarding output traffic related to a single endpoint\n(e.g. in the past and in the current communications) in a given time frame:\nthis parameter becomes particularly interesting when the input NIDS is\nanomaly-based and packet-oriented, which can mark as anomalous a number\nof packets belonging to the same communication.\n3.1\n\nThe OAD\n\nAs we mentioned before, the OAD is basically a payload-based anomaly-based\nintrusion detection system, which monitors the output of a system rather than\nthe input of it. Specifically, the OAD has the same structure of POSEIDON [23],\ni.e. it is a payload-based two-tier NIDS, in which the first tier consists of a SelfOrganizing Map (SOM), and is used exclusively to classify payload data; the second tier (the actual analyzer) consists of a slight modification of the well-known\nPAYL system [24]. Actually, for the OAD we could have used any anomaly-based\npayload-based NIDS, we chose POSEIDON because we are familiar with it and\nbecause it gives better results than leading competitors[23].\nThe pseudo-code of APHRODITE (the OAD and the correlator) is reported\nin Appendix A. The fact that the OAD is anomaly-based (rather than signaturebased) allows it to adapt to the specific network environment/service, and to\nwork in an unsupervised manner (at least, after the tuning). The disadvantage\nis that the OAD needs an extensive (though unsupervised) training phase: a\nsignificant amount of data is needed to build an accurate statistical model of the\n\n\f8\n\nlegal behaviour. During the training phase, there are some parameters that can\naffect the completeness and accuracy of the OAD, namely:\n\u2013 Duration of the training phase. The duration of the training (thus, the\nnumber of samples used to train the system) directly affects the quality\nof the model that will be used in the detection phase: a too short training\nphase could lead to a (too) coarse data classification, which \u2013 in the detection\nphase \u2013 translates into flagging legitimate traffic too often as anomalous. The\nIT specialist can compensate for a too short training phase by increasing\nthe threshold (see below), but this has the disadvantage that the OAD will\nclassify (more) traffic resulting from attacks as legitimate.\n\u2013 Quality of the training phase. Also the quality of the samples used\nduring the training influences the quality of the models. The samples should\nbe representative of normal behaviour and be as attack-free as possible,\notherwise the OAD might classify data resulting from an attack as legitimate\noutput traffic. In general, the more attack-free the data is, the more accurate\nthe model will be. It is out of the scope of this work to detect and mitigate\nthis problem but it is worth mentioning that we have obtained good results\nalso using a private data set which was not made attack-free by hand (see\nSection 4 for further details).\n\u2013 Threshold. As we said before, setting the threshold is a delicate task that\ncould require different improving steps to reach a good balance between true\npositives rate and false positives rate.\n\n4\n\nExperiments and results\n\nTo validate our architecture, we have benchmarked APHRODITE in combination with the signature-based NIDS Snort [12,13] as well as APHRODITE in\ncombination with the anomaly-based NIDS POSEIDON [23]. To do this, we\nhave employed two different data sets: first, we have used the DARPA 1999 data\nset [14]: despite criticism [25,26] this is a standard data for benchmarking NIDS\n(e.g. [24,15]) and has the advantage that it allows one to duplicate experiments\nand to compare different NIDS directly. Secondly, we have benchmarked the\nsystem using a private data set.\nTests with the DARPA 1999 data set The testing environment of DARPA\n1999 data set contains several internal hosts that have been attacked by both\nexternal and internal attackers. Moreover, hosts inside the local area network are\nable to conduct attacks against external hosts. In our tests, we focus on FTP,\nTelnet, SMTP and HTTP protocols. There are two reasons for this: first only\nthese protocols gave us a sufficient number of samples we needed to train the\nOAD, and secondly only these protocols allowed to compare our architecture\nwith POSEIDON, that has been benchmarked following the same procedures\n(because of the large sample set available only for these protocols). Other restrictions have been applied to make the comparison: we consider only inbound\n\n\f9\nSnort\n+\nAPHRODITE\nDR\n59,9%\n59,9%\nHTTP\nFP 599 (0,069%) 5 (0,00057%)\nDR\n31,75%\n31,75%\nFTP\nFP 875 (3,17%) 317 (1,14%)\nDR\n26,83%\n26,83%\nTelnet\nFP 391 (0,041%) 6 (0,00063%)\nDR\n13,3%\nSMTP\nFP\n0 (0,0%)\nProtocol\n\nSnort\n\nPOSEIDON\n100%\n15 (0,0018%)\n100%\n3303 (11,31%)\n95,12%\n63776 (6,72%)\n100%\n6476 (3,69%)\n\nPOSEIDON\n+\nAPHRODITE\n100%\n0 (0,0%)\n100%\n373 (1,35%)\n95,12%\n56885 (5,99%)\n100%\n2797 (1,59%)\n\nTable 1. Comparison between Snort stand-alone, Snort in combination with\nAPHRODITE, POSEIDON stand-alone and POSEIDON in combination with\nAPHRODITE using the DARPA 1999 data set: DR stands for detection rate\n(attack instances), while FP is the false positive rate (packets); APHRODITE\nreduces FP by more than 50% most of the times, being close to zero in 3 tests,\nwithout affecting the detection rate.\n\nand outbound TCP packets that belong to attack connections against hosts of\nthe network 172.016.0.0/16.\nWe trained the OAD of APHRODITE with the data of weeks 1 and 3 (attack\nfree): for each different protocol we have used a different OAD instance. Afterward, we tested APHRODITE together with both POSEIDON and Snort to on\nthe traffic of weeks 4 and 5. The authors of DARPA provide a table containing\nall the attack instances, allowing one to distinguish between false positives and\ntrue positives attacks.\nTable 1 reports a comparison of the detection rate and false positives rate\nof Snort stand-alone (first column), Snort in combination with APHRODITE\n(second column), POSEIDON stand-alone (third column) and POSEIDON in\ncombination with APHRODITE (fourth column). In both cases, APHRODITE\nachieves a substantial improvement on the stand-alone system without affecting\nthe detection rate nor introducing false negatives. APHRODITE has not be\napplied to SMTP traffic in combination with Snort because in this case Snort\nraises no false positives.\nTests with a private data set To complete our validation, and to see how\nthe system behaves when trained with a data set that is not made attack-free,\nwe considered a second (private) data set we have collected at the University of\nTwente: this is data set B. Data was collected on a public network for 5 consecutive working days (24 hours per day), logging only TCP traffic directed to (and\noriginating from) a heavy-loaded web server (about 10 Gigabyte of total data\nper day). This web server hosts several official department web sites and personal web pages of students and research staff: thus, the traffic contains diverse\ndata such as static and dynamically generated HTML pages and, especially in\n\n\f10\n\nthe output traffic, common format documents (e.g. PDF) as well as raw binary\ndata (e.g. software executables). We did not inject any artificial attack.\nWe focus on HTTP traffic because nowadays Internet attacks are mainly\ndirected to web-based services: Symantec Corporation reports that in year the\n2005 web-based services have been the third most attacked service (ranked by\nTCP port), and in the second-half of the year 69% of total discovered vulnerabilities apply to web applications [27]. We classified alerts manually and detected\n33 attack instances in 59288 input packets: most of the attacks are XSS (Crosssite Scripting) [17] and SQL Injection attacks. Table 2 summarizes the results\nwe obtained.\nWe could not compare APHRODITE in combination with Snort on this\nsecond data set for the simple reason that Snort did not find any attack to the\nsystem (Snort raised only false alarms): by setting a high output threshold in\nAPHRODITE we could have easily removed all the false positives, but this would\nhave given no indication of the completeness and accuracy of APHRODITE.\nPOSEIDON\n+\nAPHRODITE\nDR\n100%\n100%\nHTTP\nFP 1683 (2,83%) 774 (1,30%)\nProtocol\n\nPOSEIDON\n\nTable 2. Comparison between POSEIDON stand-alone and POSEIDON in combination with APHRODITE using data set B; DR stands for detection rate\n(attack instances), while FP is the false positive rate (packets); APHRODITE\nreduces FP by more than 50% without affecting the detection rate.\n\nQuick setup To train the anomaly-detection engines of both POSEIDON and\nthe OAD on the data set B, we simply used a snapshot of the data collected\nduring working hours (approximately 3 hours, 1,8 Gigabyte of data): it is widely\nacknowledged that attackers prefer to conduct malicious activity during nonworking hours, when the system is usually less monitored by IT personnel. The\nchosen training data set has not been pre-processed and made attack-free: thus, it\nis possible that some malicious activities have been processed during the model\nbuilding phase. For the same reason, we randomly choose a nightly snapshot\n(approximately 8 hours, 1,8 Gigabyte of data) to benchmark POSEIDON standalone against POSEIDON in combination with APHRODITE. Moreover, we\nsetup the threshold following the simple heuristics discussed below.\nThis way of training the anomaly detection engines of POSEIDON and the\nOAD is not optimal (as we remarked before, the training set is supposed to be\nattack-free), but this allowed us to check the completeness and accuracy of our\nsystem in a fairly realistic situation, and to show that APHRODITE is useful\nfor reducing false positives also in those cases in which the IT professional wants\n\n\f11\n\nto carry out a quick setup and does not want to spend too much time cleaning\nup the training set and setting an optimal threshold, applying several enhancing\nsteps.\nSetting the threshold In Section 2.2 we introduce the fact that \u2013 in anomalybased systems \u2013 completeness and accuracy are intrinsically related and they are\nheavily influenced by the threshold value. Here, we call completeness the ratio\nT P/(T P +F N ) and accuracy the ratio T P/(T P +F P ), where T P is the number\nof true positives, F N is the number of false negatives and F P is the number of\nfalse positives raised during the benchmarks. Our experiments show that setting\nthe threshold at 3tmax\n4 , usually yields reasonably good results; here tmax is the\nmaximum distance between the analyzed data and the model observed during\nthe training phase.\nTables 1 and 2 report the best false positive rate we have measured during our benchmarks without affecting the detection rate achieved during the\nstand-alone session. Figure 2 shows more accurately what happens to the accuracy and completeness of POSEIDON and POSEIDON in combination with\nAPHRODITE when we modify the threshold of POSEIDON stand-alone (broken line) and when we modify the threshold of APHRODITE after having fixed\nthat of POSEIDON to the best value (unbroken line). Here, we concentrate on\nthe Telnet and SMTP protocol data of the DARPA 1999 data set and HTTP\nprotocol data from data set B (these protocols presented the highest F P rate,\nallowing more accurate measurements).\n\n5\n\nRelated work\n\nIn this section we present related work. The problem of reducing false positive\nhas been addressed using two different kind of approaches: on the one hand we\nhave techniques for identifying true positives, and on the other hand we have\ntechniques for identifying false positives.\nThe main difference between our work and the papers described below (with\nthe exception of Qiao and Weixin's [28] \u2013 see below) consists of the fact that we\ntake into account the output traffic of the system.\n5.1\n\nIdentifying true positives\n\nNing et al. develop a model [29] and an intrusion alert correlator [30] to help\nhuman analysts during the alert verification phase. Their work is based on the\nobservation that most incidents consist of several related stages, with the early\nstages preparing for the later ones. The authors introduce the concept of prerequisite of an attack : which is defined as the necessary condition for the attack to\nbe successful. Furthermore, logical formulas are used to describe relationships\nbetween different attack stages, and hyper-alert correlation graphs are employed\nto represent correlated alerts in an intuitive way. However, this correlation technique is ineffective when attackers use a different source at each attack step.\n\n\f12\n\nNing and Cui [30] demonstrate the effectiveness of this approach when applied\non a small data set: in [31,32] the same authors present other utilities they\ndeveloped to facilitate the analysis of large sets of correlated alerts, and report\nsome benchmarks employing network traffic used during the DEFCON 8 Capture\nthe Flag (CTF) event [33].\nMorin et al. [34] propose a data model for input alert correlation, which allows\nto aggregate alerts generated by multiple heterogeneous IDSs (e.g. network-based\nand host-based). The authors state that alert correlation techniques do not take\nfull advantage of the available information about an information system. They\nidentify four main information areas that must be exploited: properties and\ncharacteristics of the monitored environment and its vulnerabilities, monitoring\nsystems and events observed.\nThe model works by correlating input alerts using a similarity function: this\nfunction is defined over alerts from the same event (raised by different IDSs),\naddressing the same vulnerability, belonging to the same TCP/IP connection\nand based on temporal constraints. No benchmark result is provided to support\nthe system effectiveness.\nLee and Stolfo [35] develop a framework based on data mining techniques,\nsuch as sequential patterns mining and episodes rules (see Agrawal and Srikan [36]\nand Han et al. [37]), to address the problem of improving attack detection while\nmaintaining a low false positive rate. The system works by extracting information from audit traffic and building classification models (specifically designed\nfor certain types of intrusion) using data mining techniques: connection features\n(i.e. duration, type, protocol) are used to build the time-based traffic model, traffic features (i.e. number of connections directed to the same host or same service\nin a given time frame) constitutes the basis for the host-based traffic model while\nthe content model collects content features information (i.e. data payload, errors\nreported by the OS, root access attempts).\nThe system detects attacks combining the models and comparing them with\nactual traffic features. Benchmarks have been conducted using the DARPA 1998\ndata set [38]: detection score for different attack typologies has a minimum value\nof 65% with a false positive rate always below 0.05%.\n5.2\n\nIdentifying false positives\n\nPietraszek [15] tackles the problem of reducing false positives by introducing an\nalert classifier system (ALAC, Adaptive Learner for Alert Classification) based\non machine learning techniques. During the training phase, the system classifies\nalerts into true positives and false positives, by attaching a label from a fixed set\nof user-defined labels to the current alert. Then, the system computes an extra\nparameter (called classification confidence) and presents this classification to a\nhuman analyst. The analyst's feedback is used to generate training examples,\nused by the learning algorithm to build and update its classifiers. After the training phase, the classifiers are used to classify new alerts. To ensure the stability of\nthe system over time, a sub-sampling technique is applied: regularly, the system\nrandomly selects n alerts to be forwarded to the analyst instead of processing\n\n\f13\n\nthem autonomously. This approach relies on the analyst's ability to classify alerts\nproperly and on his availability to operate in real-time (otherwise the system will\nnot be updated in time); we believe that these (demanding) requirements can\nbe considered acceptable for a signature-based IDS (where the analyst can easily inspect both the signature and network that triggered the alert), but that\nit could be difficult to make the same analysis with an anomaly-based system\n(OAD). Benchmarks conducted over the 1999 DARPA data set [14], using the\nintrusion detection system Snort [12,13] to generate alerts, show an overall false\npositives reduction of over 30% (details on single attack classes are not given).\nIt is worth summarizing the main differences between ALAC and APHRODITE; namely: (a) ALAC does not consider the outgoing traffic, and (b) ALAC\nrelies heavily the expertise and the presence of an analyst (in APHRODITE, all\nthe IT specialist has to do is to set the thresholds). Pietraszek and Tanner [39]\nfurther expand the previous work using alert post-processing based on data\nmining and machine learning techniques.\nJulisch [8] presents a semiautomatic approach for identifying true positives\nbased on the idea of root cause: an alarm root cause is defined as \"the reason for\nwhich it occurs\". The author observes that in most environments, it is possible\nto identify a small number of highly predominant (and persistent) root causes.\nPersistent root causes trigger alarm floods that distract IT specialists from identifying real attacks. The process presented, based on techniques which discover\nfrequently occurring episodes in a given sequence (see Mannila et al. [40,41]),\nconsists of two different steps: the former (called root cause analysis) identifies\nroot causes related to a given (large) number of alarms. Then, the latter removes\nspotted root causes and thereby drastically reduces the future alarm rate.\nBenchmarks conducted on a log trace from a commercial NIDS deployed in a\nreal network show a reduction of 87% of root causes. No further details are given\nabout the testing condition, network topology or traffic typology. The work has\nbeen further expanded in [42,9] to improve the completeness and accuracy of\ndetecting algorithm.\nQiao and Weixin [28] introduce a NIDS that addresses the problem of reducing false positive combining anomaly-based and signature-based systems and\napplying a co-stimulation mechanism [43].\nThe system is composed by two main components: detectors and agent monitors. The first component is based on a biological immune mechanism (Forrest\net al. [44,45]) and it is responsible for detecting attacks: being anomaly-based,\nit is able to detect zero-day attacks (improving detection rate). Agent monitors\nare both signature-based and anomaly-based components, which analyze various\nsystem parameters and which are responsible for sending a feedback information\n(the co-stimulation) to the detectors to confirm a possible attack. The agents\nmonitor integrity of sensitive files (integrity monitor), information leakage (confidentiality monitor) and anomaly occupation of resources, e.g. CPU or system\nmemory, (availability monitor). When a detector d raises an alarm, a timer is\nstarted: the detector waits for a period of time \u03c4 , called co-stimulation delay, for\nthe (possible) feedback sent by at least one of the monitor agents. The feedback\n\n\f14\n\ncan also be sent by an IT specialist (e.g. the network administrator), that can\nlabel the alert as a real attack. If no feedback is received within the period \u03c4 , the\nalert is considered a false positive. The benchmarks do not allow a full comparison: the authors report only few details about the used data set (private, with\nartificial attacks introduced by authors themself), and state that all the attacks\nhave been detected without generating false positives.\n\n6\n\nConclusion\n\nIn this paper we present APHRODITE, an architecture for reducing false positives in standard NIDS. The core of APHRODITE consists of an Output Anomaly Detector (OAD): when the standard NIDS placed on the input raises an alert,\nAPHRODITE checks if the communication actually raises an anomaly in the output. When this is the case (and in another couple of exceptional situation), the\nalarm is forwarded to the IT specialist, otherwise it is discarded.\nThe fact that the OAD is anomaly-based (rather than signature-based) has\nvarious advantages: first, the OAD can adapt to the specific network environment/service; secondly it does not require the definition of new signatures to\ndetect anomalous output. Creating and maintaining a set of signatures for the\noutput traffic is labor intensive, as these signatures would heavily depend on the\nlocal application, and would have to be updated each time that the application\nchange its output format.\nBenchmarks on the DARPA 1999 data set show that APHRODITE determines a reduction of false positives between 50% and 100% in most of the cases,\nand that it does not introduce any extra false negative. Tests on our private data\nset show that APHRODITE is still effective also when it is not trained optimally:\nAPHRODITE can be thus used for reducing false positives also in those cases\nin which the IT professional wants to set it up quickly, without spending time\ntime at cleaning up the data set to carry out an optimal training.\n\nA\n\nAppendix: APHRODITE pseudo code\n\nIn this Section we give a semi-formal description of how APHRODITE works.\nDATA TYPE\nl = length of the longest packet payload\nPAYLOAD = array [1 ..l ] of [0 ..255 ]\nHOMENET = set of IP addresses\n/* hosts inside the monitored network */\nHOST = RECORD [\naddress : IP address \u2208 N\nport : TCP port \u2208 N\n]\n\n\f15\n\nPACKET = RECORD [\nsource : HOST\ndestination : HOST\npayload : PAYLOAD\n]\nALARM = RECORD [\nalarm :\n\u2212\u221e if input IDS is signature \u2212 based\nvalue \u2208 Real if input IDS is anomaly \u2212 based\nattacker : HOST (6\u2208 HOMENET )\nvictim : HOST (\u2208 HOMENET )\nprocessed : BOOLEAN /* track a processed alert by the OAD */\ntrueIncident : BOOLEAN /* alarm is marked as an incident */\ncounter : Integer\n/* packets marked as anomalous in a single communication */\n]\nDATA STRUCTURE\n\u03c4 \u2208 N\n/* Number of packets used for training phase */\noad \u2208 IDS\n/* Anomaly-based IDS analyzing outgoing network traffic */\noutThreshold \u2208 Real\n/* Numeric value used for anomaly detection by OAD */\nmagnitudeThreshold \u2208 Real\n/* Value used to evaluate input alarm magnitude */\nraisedThreshold \u2208 Integer\n/* Value used to evaluate alarm-raising packets */\nalarms = set of ALARM\n/* List of alarms, received from an IDS monitoring incoming traffic */\nINIT PHASE\n/* IT specialists set outThreshold, magnitudeThreshold and raisedThreshold values */\nTRAINING PHASE\nINPUT:\np : PACKET\n/* outgoing network packet */\n/* first, train the OAD with \u03c4 samples */\nfor t := 1 to \u03c4\n\n\f16\n\noad.train(p.source.address, p.source.port, p.payload)\nend for\nTESTING PHASE\nINPUT:\np : PACKET\n/* outgoing network packet */\nOUTPUT:\ntrueIncidents : set of ALARM\nfor each a \u2208 alarms do\nif (match alarm(a, p) = TRUE ) then\n/* the function tracks the packet and checks if it belongs to\na communication marked as anomalous by the input IDS */\nalarm level := oad.test(p.source.address, p.source.port, p.payload)\nif (alarm level > outThreshold ) then\na.trueIncident := TRUE\ntrueIncidents.add (a)\nend if\na.processed := TRUE\nend if\nend for\n/* Here we consider Exception1 */\nfor each a \u2208 alarms do\nif (a.processed = FALSE ) then\na.trueIncident := TRUE\ntrueIncidents.add (a)\na.processed := TRUE\nend if\nend for\n/* Here we consider Exception2 */\nfor each a \u2208 alarms do\nif (a.alarm > magnitudeThreshold ) then\na.trueIncident := TRUE\ntrueIncidents.add (a)\na.processed := TRUE\nend if\nend for\n/* Here we consider Exception3 */\nfor each a \u2208 alarms do\n\n\f17\n\nif (a.counter > raisedThreshold ) then\na.trueIncident := TRUE\ntrueIncidents.add (a)\na.processed := TRUE\nend if\nend for\nreturn trueIncidents\n\nReferences\n1. Bace, R.: Intrusion detection. Macmillan Publishing Co., Inc. (2000)\n2. Debar, H., Dacier, M., Wespi, A.: A revised taxonomy for intrusion detection\nsystems. Annales des T\u00e9l\u00e9communications 55(7\u20138) (2000) 361\u2013378\n3. Allen, J., Christie, A., Fithen, W., McHugh, J., Pickel, J., Stoner, E.: State of the\npractice of intrusion detection technologies. Technical Report CMU/SEI-99TR028, Carnegie-Mellon University - Software Engineering Institute (2000)\n4. Manganaris, S., Christensen, M., Zerkle, D., Hermiz, K.: A Data Mining Analysis\nof RTID alarms. Computer Networks: The International Journal of Computer and\nTelecommunications Networking 34(4) (2000) 571\u2013577\n5. Ning, P., Xu, D.: Learning attack strategies from intrusion alerts. In: CCS '03:\nProc. 10th ACM conference on Computer and Communications Security, ACM\nPress (2003) 200\u2013209\n6. Axelsson, S.: The base-rate fallacy and the difficulty of intrusion detection. ACM\nTrans. Inf. Syst. Secur. (TISSEC) 3(3) (2000) 186\u2013205\n7. Clifton, C., Gengo, G.: Developing custom intrusion detection filters using data\nmining. In: MILCOM '00: Proc. 21st Century Military Communications Conference. Volume 1., IEEE Computer Society Press (2000) 440\u2013443\n8. Julisch, K.: Mining Alarm Clusters to Improve Alarm Handling Efficiency. In:\nACSAC '01: Proc. 17th Annual Computer Security Applications Conference (ACSAC), ACM Press (2001) 12\u201321\n9. Julisch, K.: Clustering intrusion detection alarms to support root cause analysis.\nACM Transactions on Information and System Security (TISSEC) 6(4) (2003)\n443\u2013471\n10. Dain, O., Cunningham, R.: Fusing Heterogeneous Alert Streams into Scenarios. In:\nProc. Workshop on Data Mining for Security Applications, 8th ACM Conference\non Computer Security (CCS' 01), ACM Press (2002) 1\u201313\n11. Axelsson, S.: Intrusion Detection Systems: A Survey and Taxonomy. Technical\nReport 99-15, Chalmers University (2000)\n12. Roesch, M.: Snort - Lightweight Intrusion Detection for Networks. In: LISA '99:\nProc. 13th USENIX Conference on System Administration, USENIX Association\n(1999) 229\u2013238\n13. Sourcefire: Snort Network Intrusion Detection System web site (1999) URL\nhttp://www.snort.org.\n14. Lippmann, R., Haines, J.W., Fried, D.J., Korba, J., Das, K.: The 1999 DARPA offline intrusion detection evaluation. Computer Networks: The International Journal\nof Computer and Telecommunications Networking 34(4) (2000) 579\u2013595\n\n\f18\n15. Pietraszek, T.: Using Adaptive Alert Classification to Reduce False Positives in\nIntrusion Detection. In Jonsson, E., Valdes, A., Almgren, M., eds.: RAID '04:\nProc. 7th Symposium on Recent Advances in Intrusion Detection. Volume 3224 of\nLNCS., Springer-Verlag (2004) 102\u2013124\n16. Debar, H., Dacier, M., Wespi, A.: Towards a taxonomy of intrusion-detection\nsystems. Computer Networks 31(8) (1999) 805\u2013822\n17. Web Application Security Consortium: Web Security Threat Classification (2005)\nURL http://www.webappsec.org/projects/threat/.\n18. van Trees, H.L.: Detection, Estimation and Modulation Theory. Part I: Detection,\nEstimation, and Linear Modulation Theory. John Wiley and Sons, Inc. (1968)\n19. The Open Web Application Security Project:\nOWASP Top Ten\nMost Critical Web Application Security Vulnerabilities (2006) URL\nhttp://www.owasp.org/documentation/topten.html.\n20. Security Reason:\nPostNuke Input Validation Error (2005) URL\nhttp://securitytracker.com/alerts/2005/May/1014066.html.\n21. PostNuke:\nPostNuke Content Managament System (2006) URL\nhttp://www.postnuke.com/.\n22. Check Point Software Technologies: Stateful Inspection Technology (2005) URL\nhttp://www.checkpoint.com/products/downloads/Stateful Inspection.pdf.\n23. Bolzoni, D., Zambon, E., Etalle, S., Hartel, P.: POSEIDON: a 2-tier Anomalybased Network Intrusion Detection System. In: IWIA '06: Proc. 4th IEEE International Workshop on Information Assurance, IEEE Computer Society (2006) To\nappear.\n24. Wang, K., Stolfo, S.J.: Anomalous Payload-Based Network Intrusion Detection.\nIn Jonsson, E., Valdes, A., Almgren, M., eds.: RAID '04: Proc. 7th Symposium on\nRecent Advances in Intrusion Detection. Volume 3224 of LNCS., Springer-Verlag\n(2004) 203\u2013222\n25. McHugh, J.: Testing Intrusion Detection Systems: a critique of the 1998 and 1999\nDARPA intrusion detection system evaluations as performed by Lincoln Laboratory. ACM Transactions on Information and System Security (TISSEC) 3(4)\n(2000) 262\u2013294\n26. Mahoney, M.V., Chan, P.K.: An Analysis of the 1999 DARPA/Lincoln Laboratory\nEvaluation Data for Network Anomaly Detection. In Vigna, G., Kruegel, C., Jonsson, E., eds.: RAID '03: Proc. 6th Symposium on Recent Advances in Intrusion\nDetection. Volume 2820 of LNCS., Springer-Verlag (2003) 220\u2013237\n27. Symantec Corporation:\nInternet Security Threat Report (2006) URL\nhttps://enterprise.symantec.com/enterprise/whitepaper.cfm?id=2238.\n28. Qiao, Y., Weixin, X.: A Network IDS with Low False Positive Rate. In Fogel,\nD.B., El-Sharkawi, M.A., Yao, X., Greenwood, G., Iba, H., Marrow, P., Shackleton,\nM., eds.: CEC '02: Proc. IEEE Congress on Evolutionary Computation, IEEE\nComputer Society Press (2002) 1121\u20131126\n29. Ning, P., Reeves, D., Cui, Y.: Correlating Alerts Using Prerequisites of Intrusions.\nTechnical Report TR-2001-13, North Carolina State University (2001)\n30. Ning, P., Cui, Y.: An Intrusion Alert Correlator Based on Prerequisites of Intrusions. Technical Report TR-2002-01, North Carolina State University (2002)\n31. Ning, P., Cui, Y., Reeves, D.: Analyzing intensive intrusion alerts via correlation.\nIn Wespi, A., Vigna, G., Deri, L., eds.: RAID '02: Proc. 5th Symposium on Recent\nAdvances in Intrusion Detection. Volume 2516 of LNCS., Springer-Verlag (2002)\n74\u201394\n\n\f19\n32. Ning, P., Cui, Y., Reeves, D.S., Xu, D.: Techniques and tools for analyzing intrusion\nalerts. ACM Transactions on Information and System Security (TISSEC) 7(2)\n(2004) 274\u2013318\n33. DEFCON8:\nDefcon Capture the Flag (CTF) contest (2000) URL\nhttp://www.defcon.org/html/defcon-8/defcon-8-post.html,\ndata\nset\nhttp://wi2600.org/mediawhore/mirrors/shmoo/.\n34. Morin, B., M\u00e9, L., Debar, H., Ducass\u00e9, M.: M2d2: A formal data model for ids\nalert correlation. In Wespi, A., Vigna, G., Deri, L., eds.: RAID '02: Proc. 5th\nSymposium on Recent Advances in Intrusion Detection. Volume 2516 of LNCS.,\nSpringer-Verlag (2002) 115\u2013127\n35. Lee, W., Stolfo, S.J.: A Framework for Constructing Features and Models for Intrusion Detection Systems. ACM Transactions on Information and System Security\n3(4) (2000) 227\u2013261\n36. Agrawal, R., Srikant, R.: Mining sequential patterns. In: Proc. 7th International\nConference on Data Engineering, IEEE Computer Society Press (1995) 3\u201314\n37. Han, J., Pei, J., Yin, Y.: Mining frequent patterns without candidate. In: SIGMOD\n'00: Proc. 19th ACM SIGMOD International Conference on Management of Data,\nACM Press (2000) 1\u201312\n38. Lippmann, R., Fried, D., Graf, I., Haines, J., Kendall, K., McClung, D., Weber, D.,\nWebster, S., Wyschogrod, D., Cunningham, R., Zissman, M.: Evaluating Intrusion\nDetection Systems: The 1998 DARPA Off-line Intrusion Detection Evaluation. In:\nDISCEX '00: Proc. 1st DARPA Information Survivability Conference and Exposition. Volume 2., IEEE Computer Society Press (2000) 12\u201326\n39. Pietraszek, T., Tanner, A.: Data Mining and Machine Learning \u2013 Towards Reducing False Positives in Intrusion Detection. Information Security Technical Report\n10(3) (2005) 169\u2013183\n40. Mannila, H., Toivonen, H.: Discovering Generalized Episodes Using Minimal Occurrences. In: KDD '96: Proc. 2nd International Conference on Knowledge Discovery and Data Mining, AAAI Press (1996) 146\u2013151\n41. Mannila, H., Toivonen, H., Inkeri Verkamo, A.: Discovery of Frequent Episodes in\nEvent Sequences. Data Min. Knowl. Discov. 1(3) (1997) 259\u2013289\n42. Julisch, K., Dacier, M.: Mining intrusion detection alarms for actionable knowledge.\nIn: KDD '02: Proc. 8th ACM SIGKDD international conference on Knowledge\nDiscovery and Data Mining, ACM Press (2002) 366\u2013375\n43. Hofmeyr, S.A.: An Immunological Model of Distributed Detection and its Application to Computer Security. PhD thesis, University of New Mexico (1999) URL\nhttp://www.cs.unm.edu/\u223csteveah/steve diss.pdf.\n44. Forrest, S., Hofmeyr, S.A.: A Sense of Self for Unix Processes. In: S&P '96:\nProc. 17th IEEE Symposium on Security and Privacy, IEEE Computer Society\nPress (2002) 120\u2013128\n45. Forrest, S., Hofmeyr, S.A., Somayaji, A.: Computer immunology. Communications\nof the ACM 40(10) (1997) 88\u201396\n\n\f20\n\nFig. 2. Detection rates for POSEIDON in combination with APHRODITE using\nDARPA 1999 data set (Telnet and SMTP protocols) and data set B (HTTP\nprotocol): the x-axis and y-axis present false positive rate and detection rate\nrespectively. Is it possible to observe that APHRODITE presents a lower false\npositive rate than POSEIDON on every benchmarked protocol, considering the\nsame detection rate.\n\n\f"}