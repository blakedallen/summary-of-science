{"id": "http://arxiv.org/abs/1003.4431v2", "guidislink": true, "updated": "2012-02-28T06:04:45Z", "updated_parsed": [2012, 2, 28, 6, 4, 45, 1, 59, 0], "published": "2010-03-23T14:30:11Z", "published_parsed": [2010, 3, 23, 14, 30, 11, 1, 82, 0], "title": "Quasi-sure Stochastic Analysis through Aggregation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1003.0917%2C1003.3369%2C1003.4511%2C1003.0373%2C1003.4997%2C1003.4655%2C1003.4743%2C1003.2935%2C1003.5018%2C1003.2406%2C1003.1838%2C1003.2991%2C1003.5607%2C1003.4431%2C1003.5247%2C1003.1081%2C1003.3690%2C1003.5773%2C1003.3970%2C1003.3771%2C1003.0142%2C1003.2518%2C1003.3278%2C1003.5917%2C1003.4674%2C1003.0224%2C1003.3940%2C1003.1889%2C1003.2676%2C1003.4507%2C1003.0933%2C1003.2557%2C1003.4590%2C1003.4649%2C1003.1479%2C1003.2120%2C1003.3524%2C1003.4942%2C1003.5375%2C1003.1385%2C1003.5538%2C1003.1868%2C1003.4171%2C1003.3939%2C1003.4828%2C1003.2145%2C1003.0656%2C1003.5763%2C1003.0974%2C1003.3583%2C1003.5531%2C1003.4066%2C1003.3816%2C1003.3649%2C1003.1772%2C1003.1816%2C1003.1870%2C1003.2167%2C1003.1507%2C1003.1974%2C1003.1094%2C1003.2616%2C1003.4089%2C1003.4546%2C1003.5348%2C1003.5915%2C1003.2541%2C1003.5320%2C1003.3659%2C1003.4395%2C1003.4855%2C1003.2889%2C1003.4372%2C1003.5982%2C1003.3806%2C1003.3505%2C1003.4841%2C1003.3592%2C1003.5324%2C1003.5797%2C1003.5638%2C1003.4233%2C1003.1465%2C1003.1181%2C1003.4583%2C1003.4323%2C1003.2838%2C1003.4298%2C1003.1011%2C1003.0587%2C1003.3275%2C1003.1511%2C1003.3014%2C1003.0731%2C1003.0040%2C1003.3636%2C1003.2065%2C1003.4842%2C1003.0280%2C1003.4983%2C1003.0062&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Quasi-sure Stochastic Analysis through Aggregation"}, "summary": "This paper is on developing stochastic analysis simultaneously under a\ngeneral family of probability measures that are not dominated by a single\nprobability measure. The interest in this question originates from the\nprobabilistic representations of fully nonlinear partial differential equations\nand applications to mathematical finance. The existing literature relies either\non the capacity theory (by Denis and Martini), or on the underlying nonlinear\npartial differential equation (by Peng). In both approaches, the resulting\ntheory requires the smoothness of the corresponding processes and random\nvariables in terms of the underlying canonical process. In this paper, we\ninvestigate this question for a larger class of \"non-smooth\" processes, but\nwith a restricted family of non-dominated probability measures. For smooth\nprocesses, our approach leads to similar results as in previous literature,\nprovided the restricted family satisfies an additional density property.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1003.0917%2C1003.3369%2C1003.4511%2C1003.0373%2C1003.4997%2C1003.4655%2C1003.4743%2C1003.2935%2C1003.5018%2C1003.2406%2C1003.1838%2C1003.2991%2C1003.5607%2C1003.4431%2C1003.5247%2C1003.1081%2C1003.3690%2C1003.5773%2C1003.3970%2C1003.3771%2C1003.0142%2C1003.2518%2C1003.3278%2C1003.5917%2C1003.4674%2C1003.0224%2C1003.3940%2C1003.1889%2C1003.2676%2C1003.4507%2C1003.0933%2C1003.2557%2C1003.4590%2C1003.4649%2C1003.1479%2C1003.2120%2C1003.3524%2C1003.4942%2C1003.5375%2C1003.1385%2C1003.5538%2C1003.1868%2C1003.4171%2C1003.3939%2C1003.4828%2C1003.2145%2C1003.0656%2C1003.5763%2C1003.0974%2C1003.3583%2C1003.5531%2C1003.4066%2C1003.3816%2C1003.3649%2C1003.1772%2C1003.1816%2C1003.1870%2C1003.2167%2C1003.1507%2C1003.1974%2C1003.1094%2C1003.2616%2C1003.4089%2C1003.4546%2C1003.5348%2C1003.5915%2C1003.2541%2C1003.5320%2C1003.3659%2C1003.4395%2C1003.4855%2C1003.2889%2C1003.4372%2C1003.5982%2C1003.3806%2C1003.3505%2C1003.4841%2C1003.3592%2C1003.5324%2C1003.5797%2C1003.5638%2C1003.4233%2C1003.1465%2C1003.1181%2C1003.4583%2C1003.4323%2C1003.2838%2C1003.4298%2C1003.1011%2C1003.0587%2C1003.3275%2C1003.1511%2C1003.3014%2C1003.0731%2C1003.0040%2C1003.3636%2C1003.2065%2C1003.4842%2C1003.0280%2C1003.4983%2C1003.0062&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper is on developing stochastic analysis simultaneously under a\ngeneral family of probability measures that are not dominated by a single\nprobability measure. The interest in this question originates from the\nprobabilistic representations of fully nonlinear partial differential equations\nand applications to mathematical finance. The existing literature relies either\non the capacity theory (by Denis and Martini), or on the underlying nonlinear\npartial differential equation (by Peng). In both approaches, the resulting\ntheory requires the smoothness of the corresponding processes and random\nvariables in terms of the underlying canonical process. In this paper, we\ninvestigate this question for a larger class of \"non-smooth\" processes, but\nwith a restricted family of non-dominated probability measures. For smooth\nprocesses, our approach leads to similar results as in previous literature,\nprovided the restricted family satisfies an additional density property."}, "authors": ["H. Mete Soner", "Nizar Touzi", "Jianfeng Zhang"], "author_detail": {"name": "Jianfeng Zhang"}, "author": "Jianfeng Zhang", "arxiv_comment": "38 pages", "links": [{"href": "http://arxiv.org/abs/1003.4431v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1003.4431v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60H10, 60H30", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1003.4431v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1003.4431v2", "journal_reference": "Electronic Journal of Probability, Vol. 16, 1844-1879, Article\n  Number 67 (2011)", "doi": null, "fulltext": "Quasi-sure Stochastic Analysis through Aggregation\n\narXiv:1003.4431v2 [math.PR] 28 Feb 2012\n\nH. Mete Soner\u2217\n\nNizar Touzi\u2020\n\nJianfeng Zhang\u2021\n\nSubmitted: March 24, 2010. Accepted: August 19, 2011.\n\nAbstract\nThis paper is on developing stochastic analysis simultaneously under a general family of probability measures that are not dominated by a single probability measure.\nThe interest in this question originates from the probabilistic representations of fully\nnonlinear partial differential equations and applications to mathematical finance. The\nexisting literature relies either on the capacity theory (Denis and Martini [5]), or on\nthe underlying nonlinear partial differential equation (Peng [13]). In both approaches,\nthe resulting theory requires certain smoothness, the so called quasi-sure continuity, of\nthe corresponding processes and random variables in terms of the underlying canonical\nprocess. In this paper, we investigate this question for a larger class of \"non-smooth\"\nprocesses, but with a restricted family of non-dominated probability measures. For\nsmooth processes, our approach leads to similar results as in previous literature, provided the restricted family satisfies an additional density property.\nKey words: non-dominated probability measures, weak solutions of SDEs, uncertain\nvolatility model, quasi-sure stochastic analysis.\nAMS 2000 subject classifications: 60H10, 60H30.\n\n\u2217\n\nETH (Swiss Federal Institute of Technology), Z\u00fcrich and Swiss Finance Institute, hmsoner@ethz.ch.\nResearch partly supported by the European Research Council under the grant 228053-FiRM. Financial\nsupport from the Swiss Finance Institute and the ETH Foundation are also gratefully acknowledged.\n\u2020\nCMAP, Ecole Polytechnique Paris, nizar.touzi@polytechnique.edu. Research supported by the Chair\nFinancial Risks of the Risk Foundation sponsored by Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, the Chair Derivatives of the Future sponsored by the F\u00e9d\u00e9ration Bancaire Fran\u00e7aise, and the Chair Finance and Sustainable Development\nsponsored by EDF and Calyon.\n\u2021\nUniversity of Southern California, Department of Mathematics, jianfenz@usc.edu. Research supported\nin part by NSF grant DMS 06-31366 and DMS 10-08873.\n\n1\n\n\f1\n\nIntroduction\n\nIt is well known that all probabilistic constructions crucially depend on the underlying probability measure. In particular, all random variables and stochastic processes are defined up\nto null sets of this measure. If, however, one needs to develop stochastic analysis simultaneously under a family of probability measures, then careful constructions are needed as the\nnull sets of different measures do not necessarily coincide. Of course, when this family of\nmeasures is dominated by a single measure this question trivializes as we can simply work\nwith the null sets of the dominating measure. However, we are interested exactly in the\ncases where there is no such dominating measure. An interesting example of this situation\nis provided in the study of financial markets with uncertain volatility. Then, essentially all\nmeasures are orthogonal to each other.\nSince for each probability measure we have a well developed theory, for simultaneous\nstochastic analysis, we are naturally led to the following problem of aggregation. Given a\nfamily of random variables or stochastic processes, X P , indexed by probability measures P,\ncan one find an aggregator X that satisfies X = X P , P\u2212almost surely for every probability\nmeasure P? This paper studies exactly this abstract problem. Once aggregation is achieved,\nthen essentially all classical results of stochastic analysis generalize as shown in Section 6\nbelow.\nThis probabilistic question is also closely related to the theory of second order backward stochastic differential equations (2BSDE) introduced in [3]. These type of stochastic\nequations have several applications in stochastic optimal control, risk measures and in the\nMarkovian case, they provide probabilistic representations for fully nonlinear partial differential equations. A uniqueness result is also available in the Markovian context as proved\nin [3] using the theory of viscosity solutions. Although the definition given in [3] does\nnot require a special structure, the non-Markovian case, however, is better understood only\nrecently. Indeed, [17] further develops the theory and proves a general existence and uniqueness result by probabilistic techniques. The aggregation result is a central tool for this result\nand in our accompanying papers [15, 16, 17]. Our new approach to 2BSDE is related to\nthe quasi sure analysis introduced by Denis and Martini [5] and the G-stochastic analysis\nof Peng [13]. These papers are motivated by the volatility uncertainty in mathematical finance. In such financial models the volatility of the underlying stock process is only known\nto stay between two given bounds 0 \u2264 a < a. Hence, in this context one needs to define\nprobabilistic objects simultaneously for all probability measures under which the canonical\nprocess B is a square integrable martingale with absolutely continuous quadratic variation\nprocess satisfying\nadt \u2264 dhBit \u2264 adt.\nHere dhBit is the quadratic variation process of the canonical map B. We denote the set\n2\n\n\fof all such measures by P W , but without requiring the bounds a and a, see subsection 2.1.\nAs argued above, stochastic analysis under a family of measures naturally leads us to\nthe problem of aggregation. This question, which is also outlined above, is stated precisely\nin Section 3, Definition 3.1. The main difficulty in aggregation originates from the fact\nthat the above family of probability measures are not dominated by one single probability\nmeasure. Hence the classical stochastic analysis tools can not be applied simultaneously\nunder all probability measures in this family. As a specific example, let us consider the\ncase of the stochastic integrals. Given an appropriate integrand H, the stochastic integral\nRt\nItP = 0 Hs dBs can be defined classically under each probability measure P. However, these\nprocesses may depend on the underlying probability measure. On the other hand we are free\nto redefine this integral outside the support of P. So, if for example, we have two probability\nmeasures P1 , P2 that are orthogonal to each other, see e.g. Example 2.1, then the integrals\nare immediately aggregated since the supports are disjoint. However, for uncountably many\nprobability measures, conditions on H or probability measures are needed. Indeed, in order\nto aggregate these integrals, we need to construct a stochastic process It defined on all\nof the probability space so that It = ItP for all t, P\u2212almost surely. Under smoothness\nassumptions on the integrand H this aggregation is possible and a pointwise definition\nis provided by Karandikar [10] for c\u00e0dl\u00e0g integrands H. Denis and Martini [5] uses the\ntheory of capacities and construct the integral for quasi-continuous integrands, as defined\nin that paper. A different approach based on the underlying partial differential equation was\nintroduced by Peng [13] yielding essentially the same results as in [5]. In Section 6 below,\nwe also provide a construction without any restrictions on H but in a slightly smaller class\nthan P W .\nFor general stochastic processes or random variables, an obvious consistency condition\n(see Definition 3.2, below) is clearly needed for aggregation. But Example 3.3 also shows\nthat this condition is in general not sufficient. So to obtain aggregation under this minimal\ncondition, we have two alternatives. First is to restrict the family of processes by requiring\nsmoothness. Indeed the previous results of Karandikar [10], Denis-Martini [5], and Peng\n[13] all belong to this case. A precise statement is given in Section 3 below. The second\napproach is to slightly restrict the class of non-dominated measures. The main goal of this\npaper is to specify these restrictions on the probability measures that allows us to prove\naggregation under only the consistency condition (3.4).\nOur main result, Theorem 5.1, is proved in Section 5. For this main aggregation result,\nwe assume that the class of probability measures are constructed from a separable class\nof diffusion processes as defined in subsection 4.4, Definition 4.8. This class of diffusion\nprocesses is somehow natural and the conditions are motivated from stochastic optimal\ncontrol. Several simple examples of such sets are also provided. Indeed, the processes\n\n3\n\n\fobtained by a straightforward concatenation of deterministic piece-wise constant processes\nforms a separable class. For most applications, this set would be sufficient. However, we\nbelieve that working with general separable class helps our understanding of quasi-sure\nstochastic analysis.\nThe construction of a probability measure corresponding to a given diffusion process,\nhowever, contains interesting technical details. Indeed, given an F-progressively measurable\nprocess \u03b1, we would like to construct a unique measure P\u03b1 . For such a construction, we start\nwith the Wiener measure P0 and assume that \u03b1 takes values in S>0\nd (symmetric, positive\nRt\ndefinite matrices) and also satisfy 0 |\u03b1s |ds < \u221e for all t \u2265 0, P0 -almost surely. We then\nconsider the P0 stochastic integral\nZ t\n\u03b1\n\u03b11/2\n(1.1)\nXt :=\ns dBs .\n0\n\nClassically, the quadratic variation density of X \u03b1 under P0 is equal to \u03b1. We then set\nP\u03b1S := P0 \u25e6 (X \u03b1 )\u22121 (here the subscript S is for the strong formulation). It is clear that\nB under P\u03b1S has the same distribution as X \u03b1 under P0 . One can show that the quadratic\nvariation density of B under P\u03b1S is equal to a satisfying a(X \u03b1 (\u03c9)) = \u03b1(\u03c9) (see Lemma 8.1\nbelow for the existence of such a). Hence, P\u03b1S \u2208 P W . Let P S \u2282 P W be the collection\nof all such local martingale measures P\u03b1S . Barlow [1] has observed that this inclusion is\nstrict. Moreover, this procedure changes the density of the quadratic variation process to\nthe above defined process a. Therefore to be able to specify the quadratic variation a priori,\nin subsection 4.2, we consider the weak solutions of a stochastic differential equation ((4.4)\nbelow) which is closely related to (1.1). This class of measures obtained as weak solutions\nalmost provides the necessary structure for aggregation. The only additional structure we\nneed is the uniqueness of the map from the diffusion process to the corresponding probability\nmeasure. Clearly, in general, there is no uniqueness. So we further restrict ourselves into\nthe class with uniqueness which we denote by AW . This set and the probability measures\ngenerated by them, PW , are defined in subsection 4.2.\nThe implications of our aggregation result for quasi-sure stochastic analysis are given\nin Section 6. In particular, for a separable class of probability measures, we first construct\na quasi sure stochastic integral and then prove all classical results such as Kolmogrov continuity criterion, martingale representation, Ito's formula, Doob-Meyer decomposition and\nthe Girsanov theorem. All of them are proved as a straightforward application of our main\naggregation result.\nIf in addition the family of probability measures is dense in an appropriate sense, then\nour aggregation approach provides the same result as the quasi-sure analysis. These type\nof results, of course, require continuity of all the maps in an appropriate sense. The details\nof this approach are investigated in our paper [16], see also Remark 7.5 in the context of\n4\n\n\fthe application to the hedging problem under uncertain volatility. Notice that, in contrast\nwith [5], our approach provides existence of an optimal hedging strategy, but at the price\nof slightly restricting the family of probability measures.\nThe paper is organized as follows. The local martingale measures P W and a universal\nfiltration are studied in Section 2. The question of aggregation is defined in Section 3. In\nthe next section, we define AW , PW and then the separable class of diffusion processes. The\nmain aggregation result, Theorem 5.1, is proved in Section 5. The next section generalizes\nseveral classical results of stochastic analysis to the quasi-sure setting. Section 7 studies the\napplication to the hedging problem under uncertain volatility. In Section 8 we investigate\nthe class P S of mutually singular measures induced from strong formulation. Finally, several\nexamples concerning weak solutions and the proofs of several technical results are provided\nin the Appendix.\nNotations. We close this introduction with a list of notations introduced in the paper.\n\u2022 \u03a9 := {\u03c9 \u2208 C(R+ , Rd ) : \u03c9(0) = 0}, B is the canonical process, P0 is the Wiener\nmeasure on \u03a9.\n\u2022 For a given stochastic process X, FX is the filtration generated by X.\n\u2022 F := FB = {Ft }t\u22650 is the filtration generated by B.\n\u2022 F+ := {Ft+ , t \u2265 0}, where Ft+ := Ft+ :=\nP\n\nT\n\ns>t Fs ,\n\n\u2022 FtP := Ft+ \u2228 N P (Ft+ ) and F t := Ft+ \u2228 N P (F\u221e ), where\nn\no\nN P (G) := E \u2282 \u03a9 : there exists \u1ebc \u2208 G such that E \u2282 \u1ebc and P[\u1ebc] = 0 .\n\u2022 NP is the class of P\u2212polar sets defined in Definition 2.2.\n\u0001\nT\n\u2022 F\u0302tP := P\u2208P FtP \u2228 NP is the universal filtration defined in (2.3).\n\u2022 T is the set of all F\u2212stopping times \u03c4 taking values in R+ \u222a {\u221e}.\n\n\u2022 T\u0302 P is set of all F\u0302P \u2212stopping times.\n\u2022 hBi is the universally defined quadratic variation of B, defined in subsection 2.1.\n\u2022 \u00e2 is the density of the quadratic variation hBi, also defined in subsection 2.1.\n\u2022 Sd is the set of d \u00d7 d symmetric matrices.\n\u2022 S>0\nd is the set of positive definite symmetric matrices.\n5\n\n\f\u2022 P W is the set of measures defined in subsection 2.1.\n\u2022 P S \u2282 P W is defined in the Introduction, see also Lemma 8.1.\n\u2022 P MRP \u2282 P W are the measures with the martingale representation property, see (2.2).\n\u2022 Sets PW , PS , PMRP are defined in subsection 4.2 and section 8, as the subsets of P W ,\nP S , P MRP with the additional requirement of weak uniqueness.\n\u2022 A is the set of integrable, progressively measurable processes with values in S>0\nd .\n\u2022 AW :=\n\nS\n\nP\u2208P W\n\nAW (P) and AW (P) is the set of diffusion matrices satisfying (4.1).\n\n\u2022 AW , AS , AMRP are defined as above using PW , PS , PMRP , see section 8.\nab are defined in subsection 4.3.\n\u2022 Sets \u03a9a\u03c4\u0302 , \u03a9a,b\n\u03c4\u0302 and the stopping time \u03b8\n\n\u2022 Function spaces L0 , Lp (P), L\u0302p , and the integrand spaces H0 , Hp (Pa ), H2loc (Pa ), \u0124p ,\n\u01242loc are defined in Section 6.\n\n2\n\nNon-dominated mutually singular probability measures\n\nLet \u03a9 := C(R+ , Rd ) be as above and F = FB be the filtration generated by the canonical\nprocess B. Then it is well known that this natural filtration F is left-continuous, but is not\nright-continuous. This paper makes use of the right-limiting filtration F+ , the P\u2212completed\nP\nP\nfiltration FP := {FtP , t \u2265 0}, and the P\u2212augmented filtration F := {F t , t \u2265 0}, which are\nall right continuous.\n\n2.1\n\nLocal martingale measures\n\nWe say a probability measure P is a local martingale measure if the canonical process\nB is a local martingale under P. It follows from Karandikar [10] that there exists an\nRt\nF\u2212progressively measurable process, denoted as 0 Bs dBs , which coincides with the It\u00f4's\nintegral, P\u2212almost surely for all local martingale measure P. In particular, this provides a\npathwise definition of\nZ t\n1\nT\nBs dBs and \u00e2t := lim [hBit \u2212 hBit\u2212\u03b5 ].\nhBit := Bt Bt \u2212 2\n\u03b5\u21930\n\u03b5\n0\nClearly, hBi coincides with the P\u2212quadratic variation of B, P\u2212almost surely for all local\nmartingale measure P.\nLet P W denote the set of all local martingale measures P such that\nP-almost surely, hBit is absolutely continuous in t and \u00e2 takes values in S>0\nd ,\n6\n\n(2.1)\n\n\fwhere S>0\nd denotes the space of all d \u00d7 d real valued positive definite matrices. We note\nthat, for different P1 , P2 \u2208 P W , in general P1 and P2 are mutually singular, as we see in the\nnext simple example. Moreover, there is no dominating measure for P W .\n\u221a\nExample 2.1 Let d = 1, P1 := P0 \u25e6 ( 2B)\u22121 , and \u03a9i := {hBit = (1 + i)t, t \u2265 0}, i = 0, 1.\nThen, P0 , P1 \u2208 P W , P0 (\u03a90 ) = P1 (\u03a91 ) = 1, P0 (\u03a91 ) = P1 (\u03a90 ) = 0, and \u03a90 and \u03a91 are\ndisjoint. That is, P0 and P1 are mutually singular.\n\u2737\n\nIn many applications, it is important that P \u2208 P W has martingale representation propP\nerty (MRP, for short), i.e. for any (F , P)-local martingale M , there exists a unique (P-almost\nP\nsurely) F -progressively measurable Rd valued process H such that\nZ t\nZ t\n1/2\n2\nHs dBs , t \u2265 0, P-almost surely.\n|\u00e2s Hs | ds < \u221e and Mt = M0 +\n0\n\n0\n\nWe thus define\n\b\nP MRP := P \u2208 P W : B has MRP under P .\n\n(2.2)\n\nThe inclusion P MRP \u2282 P W is strict as shown in Example 9.3 below.\nAnother interesting subclass is the set P S defined in the Introduction. Since in this\npaper it is not directly used, we postpone its discussion to Section 8.\n\n2.2\n\nA universal filtration\n\nWe now fix an arbitrary subset P \u2282 P W . By a slight abuse of terminology, we define the\nfollowing notions introduced by Denis and Martini [5].\nDefinition 2.2 (i) We say that a property holds P-quasi-surely, abbreviated as P-q.s., if it\nholds P-almost surely for all P \u2208 P.\n(ii) Denote NP := \u2229P\u2208P N P (F\u221e ) and we call P-polar sets the elements of NP .\n(iii) A probability measure P is called absolutely continuous with respect to P if P(E) = 0\nfor all E \u2208 NP .\nIn the stochastic analysis theory, it is usually assumed that the filtered probability space\nsatisfies the usual hypotheses. However, the key issue in the present paper is to develop\nstochastic analysis tools simultaneously for non-dominated mutually singular measures. In\nthis case, we do not have a good filtration satisfying the usual hypotheses under all the\nmeasures. In this paper, we shall use the following universal filtration F\u0302P for the mutually\nsingular probability measures {P, P \u2208 P}:\n\\\n\u0001\nF\u0302P := {F\u0302tP }t\u22650 where F\u0302tP :=\n(2.3)\nFtP \u2228 NP for t \u2265 0.\nP\u2208P\n\n7\n\n\fMoreover, we denote by T (resp. T\u0302 P ) the set of all F-stopping times \u03c4 (resp., F\u0302P stopping times \u03c4\u0302 ) taking values in R+ \u222a {\u221e}.\nP\n\nRemark 2.3 Notice that F+ \u2282 FP \u2282 F . The reason for the choice of this completed\nfiltration FP is as follows. If we use the small filtration F+ , then the crucial aggregation\nresult of Theorem 5.1 below will not hold true. On the other hand, if we use the augmented\nP\nfiltrations F , then Lemma 5.2 below does not hold. Consequently, in applications one will\nnot be able to check the consistency condition (5.2) in Theorem 5.1, and thus will not be\nable to apply the aggregation result. See also Remarks 5.3 and 5.6 below. However, this\nchoice of the completed filtration does not cause any problems in the applications.\n\u2737\nWe note that F\u0302P is right continuous and all P-polar sets are contained in F\u03020P . But\nF\u0302P is not complete under each P \u2208 P. However, thanks to the Lemma 2.4 below, all the\nproperties we need still hold under this filtration.\nFor any sub-\u03c3\u2212algebra G of F\u221e and any probability measure P, it is well-known that\nP\nan F \u221e -measurable random variable X is [G \u2228 N P (F\u221e )]\u2212measurable if and only if there\nexists a G-measurable random variable X\u0303 such that X = X\u0303, P-almost surely. The following result extends this property to processes and states that one can always consider any\nprocess in its F+ -progressively measurable version. Since F+ \u2282 F\u0302P , the F+ -progressively\nmeasurable version is also F\u0302P -progressively measurable. This important result will be used\nthroughout our analysis so as to consider any process in its F\u0302P -progressively measurable\nversion. However, we emphasize that the F\u0302P -progressively measurable version depends on\nthe underlying probability measure P.\nLemma 2.4 Let P be an arbitrary probability measure on the canonical space (\u03a9, F\u221e ), and\nP\nlet X be an F -progressively measurable process. Then, there exists a unique (P-almost\nsurely) F+ -progressively measurable process X\u0303 such that X\u0303 = X, P\u2212almost surely. If, in\naddition, X is c\u00e0dl\u00e0g P-almost surely, then we can choose X\u0303 to be c\u00e0dl\u00e0g P-almost surely.\nThe proof is rather standard but it is provided in Appendix for completeness. We note that,\nthe identity X\u0303 = X, P-almost surely, is equivalent to that they are equal dt \u00d7 dP-almost\nsurely. However, if both of them are c\u00e0dl\u00e0g, then clearly X\u0303t = Xt , 0 \u2264 t \u2264 1, P-almost\nsurely.\n\n3\n\nAggregation\n\nWe are now in a position to define the problem.\n\n8\n\n\fDefinition 3.1 Let P \u2282 P W , and let {X P , P \u2208 P} be a family of F\u0302P -progressively measurable processes. An F\u0302P -progressively measurable process X is called a P-aggregator of the\nfamily {X P , P \u2208 P} if X = X P , P-almost surely for every P \u2208 P.\nClearly, for any family {X P , P \u2208 P} which can be aggregated, the following consistency\ncondition must hold.\nDefinition 3.2 We say that a family {X P , P \u2208 P} satisfies the consistency condition if, for\nany P1 , P2 \u2208 P, and \u03c4\u0302 \u2208 T\u0302 P satisfying P1 = P2 on F\u0302\u03c4\u0302P we have\nX P1 = X P2 on [0, \u03c4\u0302 ], P1 \u2212 almost surely.\n\n(3.4)\n\nExample 3.3 below shows that the above condition is in general not sufficient. Therefore,\nwe are left with following two alternatives.\n\u2022 Restrict the range of aggregating processes by requiring that there exists a sequence\nof F\u0302P -progressively measurable processes {X n }n\u22651 such that X n \u2192 X P , P-almost\nsurely as n \u2192 \u221e for all P \u2208 P. In this case, the P-aggregator is X := limn\u2192\u221e X n .\nMoreover, the class P can be taken to be the largest possible class P W . We observe\nthat the aggregation results of Karandikar [10], Denis-Martini [5], and Peng [13] all\nbelong to this case. Under some regularity on the processes, this condition holds.\n\u2022 Restrict the class P of mutually singular measures so that the consistency condition\n(3.4) is sufficient for the largest possible family of processes {X P , P \u2208 P}. This is the\nmain goal of the present paper.\nWe close this section by constructing an example in which the consistency condition is\nnot sufficient for aggregation.\n\u221a\n\u221a\nExample 3.3 Let d = 2. First, for each x, y \u2208 [1, 2], let Px,y := P0 \u25e6 ( xB 1 , yB 2 )\u22121\nand \u03a9x,y := {hB 1 it = xt, hB 2 it = yt, t \u2265 0}. Cleary for each (x, y), Px,y \u2208 P W and\nPx,y [\u03a9x,y ] = 1. Next, for each a \u2208 [1, 2], we define\nZ\n1 2 a,z\n(P [E] + Pz,a [E])dz for all E \u2208 F\u221e .\nPa [E] :=\n2 1\nWe claim that Pa \u2208 P W . Indeed, for any t1 < t2 and any bounded Ft1 -measurable random\nvariable \u03b7, we have\nZ 2\na,z\nz,a\n{EP [(Bt2 \u2212 Bt1 )\u03b7] + EP [(Bt2 \u2212 Bt1 )\u03b7]}dz = 0.\n2EPa [(Bt2 \u2212 Bt1 )\u03b7] =\n1\n\nHence Pa is a martingale measure. Similarly, one can easily show that I2 dt \u2264 dhBit \u2264 2I2 dt,\nPa -almost surely, where I2 is the 2 \u00d7 2 identity matrix.\n9\n\n\fFor a \u2208 [1, 2] set\n\u03a9a := {hB 1 it = at, t \u2265 0} \u222a {hB 2 it = at, t \u2265 0} \u2287 \u222az\u2208[1,2] [\u03a9a,z \u222a \u03a9z,a]\nso that Pa [\u03a9a ] = 1. Also for a 6= b, we have \u03a9a \u2229 \u03a9b = \u03a9a,b \u222a \u03a9b,a and thus Pa [\u03a9a \u2229 \u03a9b ] =\nPb [\u03a9a \u2229 \u03a9b ] = 0.\nNow let P := {Pa , a \u2208 [1, 2]} and set Xta (\u03c9) = a for all t, \u03c9. Notice that, for a 6= b,\nPa and Pb disagree on F0+ \u2282 F\u03020P . Then the consistency condition (3.4) holds trivially.\nHowever, we claim that there is no P-aggregator X of the family {X a , a \u2208 [1, 2]}. Indeed,\nif there is X such that X = X a , Pa -almost surely for all a \u2208 [1, 2], then for any a \u2208 [1, 2],\nZ\n\u0011\n1 2\u0010 a,z\n1 = Pa [X.a = a] = Pa [X. = a] =\nP [X. = a] + Pz,a [X. = a] dz.\n2 1\nLet \u03bbn the Lebesgue measure on [1, 2]n for integer n \u2265 1. Then, we have\n\u0010\n\u0011\n\u0010\n\u0011\n\u03bb1 {z : Pa,z [X. = a] = 1} = \u03bb1 {z : Pz,a [X. = a] = 1} = 1, for all a \u2208 [1, 2].\n\nSet A1 := {(a, z) : Pa,z [X. = a] = 1}, A2 := {(z, a) : Pz,a[X. = a] = 1} so that \u03bb2 (A1 ) =\n\u03bb2 (A2 ) = 1. Moreover, A1 \u2229 A2 \u2282 {(a, a) : a \u2208 (0, 1]} and \u03bb2 (A1 \u2229 A2 ) = 0. Now we directly\ncalculate that 1 \u2265 \u03bb2 (A1 \u222a A2 ) = \u03bb2 (A1 ) + \u03bb2 (A2 ) \u2212 \u03bb2 (A1 \u2229 A2 ) = 2. This contradiction\nimplies that there is no aggregator.\n\u2737\n\n4\n\nSeparable classes of mutually singular measures\n\nThe main goal of this section is to identify a condition on the probability measures that\nyields aggregation as defined in the previous section. It is more convenient to specify this\nrestriction through the diffusion processes. However, as we discussed in the Introduction\nthere are technical difficulties in the connection between the diffusion processes and the\nprobability measures. Therefore, in the first two subsections we will discuss the issue of\nuniqueness of the mapping from the diffusion process to a martingale measure. The separable class of mutually singular measures are defined in subsection 4.4 after a short discussion\nof the supports of these measures in subsection 4.3.\n\n4.1\n\nClasses of diffusion matrices\n\nLet\nn\n\nA := a : R+ \u2192\n\nS>0\nd\n\n| F-progressively measurable and\n\nZ\n\nt\n0\n\no\n|as |ds < \u221e, for all t \u2265 0 .\n\nFor a given P \u2208 P W , let\nn\no\nAW (P) := a \u2208 A : a = \u00e2, P-almost surely .\n10\n\n(4.1)\n\n\fRecall that \u00e2 is the density of the quadratic variation of hBi and is defined pointwise. We\nalso define\n[\nAW :=\nAW (P).\nP\u2208P W\n\nA subtle technical point is that AW is strictly included in A. In fact, the process\nat := 1{\u00e2t \u22652} + 31{\u00e2t <2} is clearly in A \\ AW .\nFor any P \u2208 P W and a \u2208 AW (P), by the L\u00e9vy characterization, the following It\u00f4's\nstochastic integral under P is a P-Brownian motion:\nZ t\nZ t\n\u22121/2\nP\na\u22121/2\ndBs , t \u2265 0. P \u2212 a.s.\n(4.2)\n\u00e2s dBs =\nWt :=\ns\n0\n\n0\n\nAlso since B is the canonical process, a = a(B* ) and thus\n1/2\n\ndBt = at (B* )dWtP , P-almost surely, and WtP is a P-Brownian motion.\n\n4.2\n\n(4.3)\n\nCharacterization by diffusion matrices\n\nIn view of (4.3), to construct a measure with a given quadratic variation a \u2208 AW , we\nconsider the stochastic differential equation,\n1/2\n\ndXt = at (X* )dBt , P0 -almost surely.\n\n(4.4)\n\nIn this generality, we consider only weak solutions P which we define next. Although the\nfollowing definition is standard (see for example Stroock & Varadhan [18]), we provide it\nfor specificity.\nDefinition 4.1 Let a be an element of AW .\n(i) For F\u2212stopping times \u03c41 \u2264 \u03c42 \u2208 T and a probability measure P1 on F\u03c41 , we say that P is\na weak solution of (4.4) on [\u03c41 , \u03c42 ] with initial condition P1 , denoted as P \u2208 P(\u03c41 , \u03c42 , P1 , a),\nif the followings hold:\n1. P = P1 on F\u03c41 ;\n2. The canonical process Bt is a P-local martingale on [\u03c41 , \u03c42 ];\nR t \u22121/2\n3. The process Wt := \u03c41 as (B* )dBs , defined P\u2212almost surely for all t \u2208 [\u03c41 , \u03c42 ], is a\nP-Brownian Motion.\n(ii) We say that the equation (4.4) has weak uniqueness on [\u03c41 , \u03c42 ] with initial condition P1\nif any two weak solutions P and P\u2032 in P(\u03c41 , \u03c42 , P1 , a) satisfy P = P\u2032 on F\u03c42 .\n(iii) We say that (4.4) has weak uniqueness if (ii) holds for any \u03c41 , \u03c42 \u2208 T and any initial\ncondition P1 on F\u03c41 .\n11\n\n\fWe emphasize that the stopping times in this definition are F-stopping times.\nNote that, for each P \u2208 P W and a \u2208 AW (P), P is a weak solution of (4.4) on R+ with\ninitial value P(B0 = 0) = 1. We also need uniqueness of this map to characterize the measure\nP in terms of the diffusion matrix a. Indeed, if (4.4) with a has weak uniqueness, we let\nPa \u2208 P W be the unique weak solution of (4.4) on R+ with initial condition Pa (B0 = 0) = 1,\nand define,\n\b\nAW := a \u2208 AW : (4.4) has weak uniqueness ,\nPW := {Pa : a \u2208 AW }.\n(4.5)\nWe also define\n\nPMRP := P MRP \u2229 PW ,\n\nAMRP := {a \u2208 AW : Pa \u2208 PMRP }.\n\n(4.6)\n\nFor notational simplicity, we denote\na\n\na\n\nPa\n\nFa := FP , F := F , for all a \u2208 AW .\n\n(4.7)\n\nIt is clear that, for each P \u2208 PW , the weak uniqueness of the equation (4.4) may depend\non the version of a \u2208 AW (P). This is indeed the case and the following example illustrates\nthis observation.\nExample 4.2 Let a0 (t) := 1, a2 (t) := 2 and\na1 (t) := 1 + 1E 1(0,\u221e) (t), where E :=\n\nn\n\nlim \u221a\nh\u21930\n\nBh \u2212 B0\n\n2h ln ln h\u22121\n\no\n6= 1 \u2208 F0+ .\n\nThen clearly both a0 and a2 belong to AW . Also a1 = a0 , P0 -almost surely and a1 = a2 ,\nPa2 -almost surely. Hence, a1 \u2208 AW (P0 ) \u2229 AW (Pa2 ). Therefore the equation (4.4) with\ncoefficient a1 has two weak solutions P0 and Pa2 . Thus a1 \u2208\n/ AW .\n\u2737\nRemark 4.3 In this paper, we shall consider only those P \u2208 PW \u2282 P W . However, we do\nnot know whether this inclusion is strict or not. In other words, given an arbitrary P \u2208 P W ,\ncan we always find one version a \u2208 AW (P) such that a \u2208 AW ?\n\u2737\nIt is easy to construct examples in AW in the Markovian context. Below, we provide\ntwo classes of path dependent diffusion processes in AW . These sets are in fact subsets of\nAS \u2282 AW , which is defined in (8.11) below. We also construct some counter-examples in\nthe Appendix. Denote\nn\no\nQ := (t, x) : t \u2265 0, x \u2208 C([0, t], Rd ) .\n(4.8)\n\nExample 4.4 (Lipschitz coefficients) Let\n\nat := \u03c3 2 (t, B* ) where \u03c3 : Q \u2192 S>0\nd\nis Lebesgue measurable, uniformly Lipschitz continuous in x under the uniform norm, and\n\u2737\n\u03c3 2 (*, 0) \u2208 A. Then (4.4) has a unique strong solution and consequently a \u2208 AW .\n12\n\n\fP\nExample 4.5 (Piecewise constant coefficients) Let a = \u221e\nn=0 an 1[\u03c4n ,\u03c4n+1 ) where {\u03c4n }n\u22650 \u2282\nT is a nondecreasing sequence of F\u2212stopping times with \u03c40 = 0, \u03c4n \u2191 \u221e as n \u2192 \u221e, and\nan \u2208 F\u03c4n with values in S>0\nd for all n. Again (4.4) has a unique strong solution and a \u2208 AW .\nThis example is in fact more involved than it looks like, mainly due to the presence of\nthe stopping times. We relegate its proof to the Appendix.\n\u2737\n\n4.3\n\nSupport of Pa\n\nIn this subsection, we collect some properties of measures that are constructed in the previous subsection. We fix a subset A \u2282 AW , and denote by P := {Pa : a \u2208 A} the\ncorresponding subset of PW . In the sequel, we may also say\na property holds A\u2212quasi surely if it holds P\u2212quasi surely.\nFor any a \u2208 A and any F\u0302P \u2212stopping time \u03c4\u0302 \u2208 T\u0302 P , let\nZ t\n[ nZ t\n1 o\na\nas ds, for all t \u2208 [0, \u03c4\u0302 + ] .\n\u03a9\u03c4\u0302 :=\n\u00e2s ds =\nn\n0\n0\n\n(4.9)\n\nn\u22651\n\nIt is clear that\n\u03a9a\u03c4\u0302 \u2208 F\u0302\u03c4\u0302P , \u03a9at is non-increasing in t, \u03a9a\u03c4\u0302+ = \u03a9a\u03c4\u0302 , and Pa (\u03a9a\u221e ) = 1.\n\n(4.10)\n\nWe next introduce the first disagreement time of any a, b \u2208 A, which plays a central role in\nSection 5:\nZ t\nZ t\no\nn\nbs ds ,\nas ds 6=\n\u03b8 a,b := inf t \u2265 0 :\n0\n\n0\n\nand, for any F\u0302P \u2212stopping time \u03c4\u0302 \u2208 T\u0302 P , the agreement set of a and b up to \u03c4\u0302 :\n\u03a9\u03c4\u0302a,b := {\u03c4\u0302 < \u03b8 a,b } \u222a {\u03c4\u0302 = \u03b8 a,b = \u221e}.\nHere we use the convention that inf \u2205 = \u221e. It is obvious that\n\u03b8 a,b \u2208 T\u02c6 P , \u03a9\u03c4\u0302a,b \u2208 F\u0302\u03c4\u0302P\n\nand \u03a9a\u03c4\u0302 \u2229 \u03a9b\u03c4\u0302 \u2282 \u03a9a,b\n\u03c4\u0302 .\n\n(4.11)\n\nRemark 4.6 The above notations can be extended to all diffusion processes a, b \u2208 A. This\nwill be important in Lemma 4.12 below.\n\u2737\n\n4.4\n\nSeparability\n\nWe are now in a position to state the restrictions needed for the main aggregation result\nTheorem 5.1.\n13\n\n\fDefinition 4.7 A subset A0 \u2282 AW is called a generating class of diffusion coefficients if\n(i) A0 satisfies the concatenation property: a1[0,t) + b1[t,\u221e) \u2208 A0 for a, b \u2208 A0 , t \u2265 0.\n(ii) A0 has constant disagreement times: for all a, b \u2208 A0 , \u03b8 a,b is a constant or, equivalently, \u03a9a,b\nt = \u2205 or \u03a9 for all t \u2265 0.\nWe note that the concatenation property is standard in the stochastic control theory in\norder to establish the dynamic programming principle, see, e.g. page 5 in [14]. The constant\ndisagreement times property is important for both Lemma 5.2 below and the aggregation\nresult of Theorem 5.1 below. We will provide two examples of sets with these properties,\nafter stating the main restriction for the aggregation result.\nDefinition 4.8 We say A is a separable class of diffusion coefficients generated by A0 if\nA0 \u2282 AW is a generating class of diffusion coefficients and A consists of all processes a of\nthe form,\na=\n\n\u221e X\n\u221e\nX\n\nani 1Ein 1[\u03c4n ,\u03c4n+1 ) ,\n\n(4.12)\n\nn=0 i=1\n\nwhere (ani )i,n \u2282 A0 , (\u03c4n )n \u2282 T is nondecreasing with \u03c40 = 0 and\n\u2022 inf{n : \u03c4n = \u221e} < \u221e, \u03c4n < \u03c4n+1 whenever \u03c4n < \u221e, and each \u03c4n takes at most\ncountably many values,\n\u2022 for each n, {Ein , i \u2265 1} \u2282 F\u03c4n form a partition of \u03a9.\nWe emphasize that in the previous definition the \u03c4n 's are F\u2212stopping times and Ein \u2208\nF\u03c4n . The following are two examples of generating classes of diffusion coefficients.\nExample 4.9 Let A0 \u2282 A be the class of all deterministic mappings. Then clearly A0 \u2282\nAW and satisfies both properties (the concatenation and the constant disagreement times\nproperties) of a generating class.\n\u2737\nExample 4.10 Recall the set Q defined in (4.8). Let D0 be a set of deterministic Lebesgue\nmeasurable functions \u03c3 : Q \u2192 S>0\nd satisfying,\n- \u03c3 is uniformly Lipschitz continuous in x under L\u221e -norm, and \u03c3 2 (*, 0) \u2208 A and\n- for each x \u2208 C(R+ , Rd ) and different \u03c31 , \u03c32 \u2208 D0 , the Lebesgue measure of the set\nA(\u03c31 , \u03c32 , x) is equal to 0, where\nn\no\nA(\u03c31 , \u03c32 , x) :=\nt : \u03c31 (t, x|[0,t] ) = \u03c32 (t, x|[0,t] ) .\nLet D be the class of all possible concatenations of D0 , i.e. \u03c3 \u2208 D takes the following form:\n\u03c3(t, x) :=\n\n\u221e\nX\ni=0\n\n\u03c3i (t, x)1[ti ,ti+1 ) (t), (t, x) \u2208 Q,\n14\n\n\ffor some sequence ti \u2191 \u221e and \u03c3i \u2208 D0 , i \u2265 0. Let A0 := {\u03c3 2 (t, B* ) : \u03c3 \u2208 D}. It is immediate\nto check that A0 \u2282 AW and satisfies the concatenation and the constant disagreement times\nproperties. Thus it is also a generating class.\n\u2737\nWe next prove several important properties of separable classes.\nProposition 4.11 Let A be a separable class of diffusion coefficients generated by A0 .\nThen A \u2282 AW , and A-quasi surely is equivalent to A0 -quasi surely. Moreover, if A0 \u2282 AMRP ,\nthen A \u2282 AMRP .\nWe need the following two lemmas to prove this result. The first one provides a convenient structure for the elements of A.\nLemma 4.12 Let A be a separable class of diffusion coefficients generated by A0 . For any\na \u2208 A and F-stopping time \u03c4 \u2208 T , there exist \u03c4 \u2264 \u03c4\u0303 \u2208 T , a sequence {an , n \u2265 1} \u2282 A0 , and\na partition {En , n \u2265 1} \u2282 F\u03c4 of \u03a9, such that \u03c4\u0303 > \u03c4 on {\u03c4 < \u221e} and\nat =\n\nX\n\nan (t)1En\n\nfor all t < \u03c4\u0303 .\n\nn\u22651\nn\nn\nIn particular, En \u2282 \u03a9a,a\nand consequently \u222an \u03a9a,a\n= \u03a9. Moreover, if a takes the form\n\u03c4\n\u03c4\n(4.12) and \u03c4 \u2265 \u03c4n , then one can choose \u03c4\u0303 \u2265 \u03c4n+1 .\n\nThe proof of this lemma is straightforward, but with technical notations. Thus we postpone\nit to the Appendix.\nWe remark that at this point we do not know whether a \u2208 AW . But the notations \u03b8 a,an\nn\nand \u03a9a,a\nare well defined as discussed in Remark 4.6. We recall from Definition 4.1 that\n\u03c4\nP \u2208 P(\u03c41 , \u03c42 , P1 , a) means P is a weak solution of (4.4) on [\u03c4\u03031 , \u03c4\u03032 ] with coefficient a and\ninitial condition P1 .\nLemma 4.13 Let \u03c41 , \u03c42 \u2208 T with \u03c41 \u2264 \u03c42 , {ai , i \u2265 1} \u2282 AW (not necessarily in AW )\nand {Ei , i \u2265 1} \u2282 F\u03c41 be a partition of \u03a9. Let P0 be a probability measure on F\u03c41 and\nPi \u2208 P(\u03c41 , \u03c42 , P0 , ai ) for i \u2265 1. Define\nP(E) :=\n\nX\ni\u22651\n\nPi (E \u2229 Ei ) for all E \u2208 F\u03c42\n\nand\n\nat :=\n\nX\ni\u22651\n\nait 1Ei ,\n\nt \u2208 [\u03c41 , \u03c42 ].\n\nThen P \u2208 P(\u03c41 , \u03c42 , P0 , a).\nProof. Clearly, P = P0 on F\u03c41 . It suffices to show that both Bt and Bt BtT \u2212\nP-local martingales on [\u03c41 , \u03c42 ].\n\n15\n\nRt\n\n\u03c41\n\nas ds are\n\n\fBy a standard localization argument, we may assume without loss of generality that all\nthe random variables below are integrable. Now for any \u03c41 \u2264 \u03c43 \u2264 \u03c44 \u2264 \u03c42 and any bounded\nrandom variable \u03b7 \u2208 F\u03c43 , we have\ni\nX ih\nEP [(B\u03c44 \u2212 B\u03c43 )\u03b7] =\nEP (B\u03c44 \u2212 B\u03c43 )\u03b71Ei\ni\u22651\n\n=\n\nX\ni\u22651\n\ni\n\u0011\nh i\u0010\ni\nEP EP B\u03c44 \u2212 B\u03c43 |F\u03c43 \u03b71Ei = 0.\n\nTherefore B is a P-local martingale on [\u03c41 , \u03c42 ]. Similarly one can show that Bt BtT \u2212\nis also a P-local martingale on [\u03c41 , \u03c42 ].\n\nRt\n\n\u03c41\n\nas ds\n\u2737\n\nProof of Proposition 4.11. Let a \u2208 A be given as in (4.12).\n(i) We first show that a \u2208 AW . Fix \u03b81 , \u03b82 \u2208 T with \u03b81 \u2264 \u03b82 and a probability measure P0\non F\u03b81 . Set\n\u03c4\u03030 := \u03b81 and \u03c4\u0303n := (\u03c4n \u2228 \u03b81 ) \u2227 \u03b82 , n \u2265 1.\nWe shall show that P(\u03b81 , \u03b82 , P0 , a) is a singleton, that is, the (4.4) on [\u03b81 , \u03b82 ] with coefficient\na and initial condition P0 has a unique weak solution. To do this we prove by induction on\nn that P(\u03c4\u03030 , \u03c4\u0303n , P0 , a) is a singleton.\nFirst, let n = 1. We apply Lemma 4.12 with \u03c4 = \u03c4\u03030 and choose \u03c4\u0303 = \u03c4\u03031 . Then,\nP\nat = i\u22651 ai (t)1Ei for all t < \u03c4\u03031 , where ai \u2208 A0 and {Ei , i \u2265 1} \u2282 F\u03c4\u03030 form a partition of\n\u03a9. For i \u2265 1, let P0,i be the unique weak solution in P(\u03c4\u03030 , \u03c4\u03031 , P0 , ai ) and set\nP0,a (E) :=\n\nX\ni\u22651\n\nP0,i (E \u2229 Ei ) for all E \u2208 F\u03c4\u03031 .\n\nWe use Lemma 4.13 to conclude that P0,a \u2208 P(\u03c4\u03030 , \u03c4\u03031 , P0 , a). On the other hand, suppose\nP \u2208 P(\u03c4\u03030 , \u03c4\u03031 , P0 , a) is an arbitrary weak solution. For each i \u2265 1, we define Pi by\nPi (E) := P(E \u2229 Ei ) + P0,i (E \u2229 (Ei )c ) for all E \u2208 F\u03c4\u03031 .\nWe again use Lemma 4.13 and notice that a1Ei + ai 1(Ei )c = ai . The result is that Pi \u2208\nP(\u03c4\u03030 , \u03c4\u03031 , P0 , ai ). Now by the uniqueness in P(\u03c4\u03030 , \u03c4\u03031 , P0 , ai ) we conclude that Pi = P0,i on\nF\u03c4\u03031 . This , in turn, implies that P(E \u2229 Ei ) = P0,i (E \u2229 Ei ) for all E \u2208 F\u03c4\u03031 and i \u2265 1.\nP\nTherefore, P(E) = i\u22651 P0,i (E \u2229 Ei ) = P0,a (E) for all E \u2208 F\u03c4\u03031 . Hence P(\u03c4\u03030 , \u03c4\u03031 , P0 , a) is a\nsingleton.\nWe continue with the induction step. Assume that P(\u03c4\u03030 , \u03c4\u0303n , P0 , a) is a singleton, and\ndenote its unique element by Pn . Without loss of generality, we assume \u03c4\u0303n < \u03c4\u0303n+1 . Following the same arguments as above we know that P(\u03c4\u0303n , \u03c4\u0303n+1 , Pn , a) contains a unique weak\n16\n\n\fRt\nsolution, denoted by Pn+1 . Then both Bt and Bt BtT \u2212 0 as ds are Pn+1 -local martingales on\n[\u03c4\u03030 , \u03c4\u0303n ] and on [\u03c4\u0303n , \u03c4\u0303n+1 ]. This implies that Pn+1 \u2208 P(\u03c4\u03030 , \u03c4\u0303n+1 , P0 , a). On the other hand, let\nP \u2208 P(\u03c4\u03030 , \u03c4\u0303n+1 , P0 , a) be an arbitrary weak solution. Since we also have P \u2208 P(\u03c4\u03030 , \u03c4\u0303n , P0 , a),\nby the uniqueness in the induction assumption we must have the equality P = Pn on F\u03c4\u0303n .\nTherefore, P \u2208 P(\u03c4\u0303n , \u03c4\u0303n+1 , Pn , a). Thus by uniqueness P = Pn+1 on F\u03c4\u0303n+1 . This proves the\ninduction claim for n + 1.\nFinally, note that Pm (E) = Pn (E) for all E \u2208 F\u03c4\u0303n and m \u2265 n. Hence, we may define\nP\u221e (E) := Pn (E) for E \u2208 F\u03c4\u0303n . Since inf{n : \u03c4n = \u221e} < \u221e, then inf{n : \u03c4\u0303n = \u03b82 } < \u221e and\nthus F\u03b82 = \u2228n\u22651 F\u03c4\u0303n . So we can uniquely extend P\u221e to F\u03b82 . Now we directly check that\nP\u221e \u2208 P(\u03b81 , \u03b82 , P0 , a) and is unique.\n(ii) We next show that Pa (E) = 0 for all A0 \u2212polar set E. Once again we apply Lemma\nP\n4.12 with \u03c4 = \u221e. Therefore at = i\u22651 ai (t)1Ei for all t \u2265 0, where {ai , i \u2265 1} \u2282 A0 and\n{Ei , i \u2265 1} \u2282 F\u221e form a partition of \u03a9. Now for any A0 -polar set E,\nPa (E) =\n\nX\ni\u22651\n\nPa (E \u2229 Ei ) =\n\nX\ni\u22651\n\nPai (E \u2229 Ei ) = 0.\n\nThis clearly implies the equivalence between A-quasi surely and A0 -quasi surely.\n(iii) We now assume A0 \u2282 AMRP and show that a \u2208 AMRP . Let M be a Pa -local martingale.\nWe prove by induction on n again that M has a martingale representation on [0, \u03c4n ] under\nPa for each n \u2265 1. This, together with the assumption that inf{n : \u03c4n = \u221e} < \u221e, implies\nthat M has martingale representation on R+ under Pa , and thus proves that Pa \u2208 AMRP .\nSince \u03c40 = 0, there is nothing to prove in the case of n = 0. Assume the result holds on\n[0, \u03c4n ]. Apply Lemma 4.12 with \u03c4 = \u03c4n and recall that in this case we can choose the \u03c4\u0303 to\nP\nbe \u03c4n+1 . Hence at = i\u22651 ai (t)1Ei , t < \u03c4n+1 , where {ai , i \u2265 1} \u2282 A0 and {Ei , i \u2265 1} \u2282 F\u03c4n\nform a partition of \u03a9. For each i \u2265 1, define\nMti := [Mt\u2227\u03c4n+1 \u2212 M\u03c4n ]1Ei 1[\u03c4n ,\u221e)(t) for all t \u2265 0.\nThen one can directly check that M i is a Pai -local martingale. Since ai \u2208 A0 \u2282 AMRP ,\nP\nthere exists H i such that dMti = Hti dBt , Pai -almost surely. Now define Ht := i\u22651 Hti 1Ei ,\n\u03c4n \u2264 t < \u03c4n+1 . Then we have dMt = Ht dBt , \u03c4n \u2264 t < \u03c4n+1 , Pa -almost surely.\n\u2737\nWe close this subsection by the following important example.\nExample 4.14 Assume A0 consists of all deterministic functions a : R+ \u2192 S>0\nd taking the\nPn\u22121\nform at = i=0 ati 1[ti ,ti+1 ) + atn 1[tn ,\u221e) where ti \u2208 Q and ati has rational entries. This\nis a special case of Example 4.9 and thus A0 \u2282 AW . In this case A0 is countable. Let\nP\n\u2212i ai\nA0 = {ai }i\u22651 and define P\u0302 := \u221e\ni=1 2 P . Then P\u0302 is a dominating probability measure\nof all Pa , a \u2208 A, where A is the separable class of diffusion coefficients generated by A0 .\n17\n\n\fTherefore, A-quasi surely is equivalent to P\u0302-almost surely. Notice however that A is not\ncountable.\n\u2737\n\n5\n\nQuasi-sure aggregation\n\nIn this section, we fix\na separable class A of diffusion coefficients generated by A0\n\n(5.1)\n\nand denote P := {Pa , a \u2208 A}. Then we prove the main aggregation result of this paper.\nFor this we recall that the notion of aggregation is defined in Definition 3.1 and the\nnotations \u03b8 a,b and \u03a9a,b\n\u03c4\u0302 are introduced in subsection 4.3.\nTheorem 5.1 (Quasi sure aggregation) For A satisfying (5.1), let {X a , a \u2208 A} be\na family of F\u0302P -progressively measurable processes. Then there exists a unique (P\u2212q.s.)\nP-aggregator X if and only if {X a , a \u2208 A} satisfies the consistency condition\nX a = X b , Pa \u2212 almost surely on [0, \u03b8 a,b ) for any a \u2208 A0 and b \u2208 A.\n\n(5.2)\n\nMoreover, if X a is c\u00e0dl\u00e0g Pa -almost surely for all a \u2208 A, then we can choose a P-q.s.\nc\u00e0dl\u00e0g version of the P-aggregator X.\nWe note that the consistency condition (5.2) is slightly different from the condition (3.4)\nbefore. The condition (5.2) is more natural in this framework and is more convenient to\ncheck in applications. Before the proof of the theorem, we first show that, for any a, b \u2208 A,\nthe corresponding probability measures Pa and Pb agree as long as a and b agree.\nLemma 5.2 For A satisfying (5.1) and a, b \u2208 A, \u03b8 a,b is an F-stopping time taking countably\nmany values and\na,b\nb\nP\nPa (E \u2229 \u03a9a,b\nand E \u2208 F\u0302\u03c4\u0302P .\n\u03c4\u0302 ) = P (E \u2229 \u03a9\u03c4\u0302 ) for all \u03c4\u0302 \u2208 T\u0302\n\n(5.3)\n\nProof. (i) We first show that \u03b8 a,b is an F-stopping time. Fix an arbitrary time t0 . In view\nof Lemma 4.12 with \u03c4 = t0 , we assume without loss of generality that\nat =\n\nX\n\nan (t)1En\n\nand bt =\n\nn\u22651\n\nX\n\nbn (t)1En for all t < \u03c4\u0303 ,\n\nn\u22651\n\nwhere \u03c4\u0303 > t0 , an , bn \u2208 A0 and {En , n \u2265 1} \u2282 Ft0 form a partition of \u03a9. Then\ni\n[h\n{\u03b8 a,b \u2264 t0 } =\n{\u03b8 an ,bn \u2264 t0 } \u2229 En .\nn\n\n18\n\n\fBy the constant disagreement times property of A0 , \u03b8 an ,bn is a constant. This implies that\n{\u03b8 an ,bn \u2264 t0 } is equal to either \u2205 or \u03a9. Since En \u2208 Ft0 , we conclude that {\u03b8 a,b \u2264 t0 } \u2208 Ft0\nfor all t0 \u2265 0. That is, \u03b8 a,b is an F-stopping time.\n(ii) We next show that \u03b8 a,b takes only countable many values. In fact, by (i) we may now\napply Lemma 4.12 with \u03c4 = \u03b8 a,b . So we may write\nat =\n\nX\n\n\u00e3n (t)1\u1ebcn\n\nand bt =\n\nX\n\nb\u0303n (t)1\u1ebcn for all t < \u03b8\u0303,\n\nn\u22651\n\nn\u22651\n\nwhere \u03b8\u0303 > \u03b8 a,b or \u03b8\u0303 = \u03b8 a,b = \u221e, \u00e3n , b\u0303n \u2208 A0 , and {\u1ebcn , n \u2265 1} \u2282 F\u03b8a,b form a partition of\n\u03a9. Then it is clear that \u03b8 a,b = \u03b8 \u00e3n ,b\u0303n on \u1ebcn , for all n \u2265 1. For each n, by the constant\ndisagreement times property of A0 , \u03b8 \u00e3n ,b\u0303n is constant. Hence \u03b8 a,b takes only countable many\nvalues.\n(iii) We now prove (5.3). We first claim that,\nh\ni\nPa\nE \u2229 \u03a9a,b\nfor any E \u2208 F\u0302\u03c4\u0302P .\n\u03c4\u0302 \u2208 F\u03b8 a,b \u2228 N (F\u221e )\n\n(5.4)\n\nIndeed, for any t \u2265 0,\n\na,b\nE \u2229 \u03a9a,b\n\u2264 t} = E \u2229 {\u03c4\u0302 < \u03b8 a,b } \u2229 {\u03b8 a,b \u2264 t}\n\u03c4\u0302 \u2229 {\u03b8\ni\n[ h\n1\nE \u2229 {\u03c4\u0302 < \u03b8 a,b } \u2229 {\u03c4\u0302 \u2264 t \u2212 } \u2229 {\u03b8 a,b \u2264 t} .\n=\nm\nm\u22651\n\nBy (i) above, {\u03b8 a,b \u2264 t} \u2208 Ft . For each m \u2265 1,\nE \u2229 {\u03c4\u0302 < \u03b8 a,b } \u2229 {\u03c4\u0302 \u2264 t \u2212\n\n1\na\nPa\nP\n+\n(F\u221e ) \u2282 Ft \u2228 N P (F\u221e ),\n} \u2208 F\u0302t\u2212\n1 \u2282 F\n1 \u2228 N\nt\u2212\nm\nm\nm\n\nand (5.4) follows.\nBy (5.4), there exist E a,i , E b,i \u2208 F\u03b8a,b , i = 1, 2, such that\na,2\nE a,1 \u2282 E \u2229 \u03a9a,b\n, E b,1 \u2282 E \u2229 \u03a9\u03c4\u0302a,b \u2282 E b,2 , and Pa (E a,2 \\E a,1 ) = Pb (E b,2 \\E b,1 ) = 0.\n\u03c4\u0302 \u2282 E\n\nDefine E 1 := E a,1 \u222a E b,1 and E 2 := E a,2 \u2229 E b,2 , then\nE 1 , E 2 \u2208 F\u03b8a,b ,\n\nE 1 \u2282 E \u2282 E 2 , and Pa (E 2 \\E 1 ) = Pb (E 2 \\E 1 ) = 0.\n\na,b\na\n2\nb\nb\n2\n2\nThus Pa (E \u2229 \u03a9a,b\n\u03c4\u0302 ) = P (E ) and P (E \u2229 \u03a9\u03c4\u0302 ) = P (E ). Finally, since E \u2208 F\u03b8 a,b , following\nthe definition of Pa and Pb , in particular the uniqueness of weak solution of (4.4) on the\ninterval [0, \u03b8 a,b ], we conclude that Pa (E 2 ) = Pb (E 2 ). This implies (5.3) immediately.\n\u2737\n\nRemark 5.3 The property (5.3) is crucial for checking the consistency conditions in our\naggregation result in Theorem 5.1. We note that (5.3) does not hold if we replace the\n19\n\n\fa\n\nb\n\ncompleted \u03c3\u2212algebra F\u03c4a \u2229 F\u03c4b with the augmented \u03c3\u2212algebra F \u03c4 \u2229 F \u03c4 . To see this, let\nd = 1, at := 1, bt := 1 + 1[1,\u221e) (t). In this case, \u03b8 a,b = 1. Let \u03c4 := 0, E := \u03a9a1 . One can\na\nb\na\nb\neasily check that \u03a9a,b\n0 = \u03a9, P (E) = 1, P (E) = 0. This implies that E \u2208 F 0 \u2229 F 0 and\na\nb\nE \u2282 \u03a9a,b\n\u2737\n0 . However, P (E) = 1 6= 0 = P (E). See also Remark 2.3.\nProof of Theorem 5.1. The uniqueness of P\u2212aggregator is immediate. By Lemma 5.2 and\nthe uniqueness of weak solutions of (4.4) on [0, \u03b8 a,b ], we know Pa = Pb on F\u03b8a,b . Then the\nexistence of the P-aggregator obviously implies (5.2). We now assume that the condition\n(5.2) holds and prove the existence of the P-aggregator.\nWe first claim that, without loss of generality, we may assume that X a is c\u00e0dl\u00e0g. Indeed,\nsuppose that the theorem holds for c\u00e0dl\u00e0g processes. Then we construct a P-aggregator for\na family {X a , a \u2208 A}, not necessarily c\u00e0dl\u00e0g, as follows:\nRt\n- If |X a | \u2264 R for some constant R > 0 and for all a \u2208 A, set Yta := 0 Xsa ds. Then,\nthe family {Y a , a \u2208 A} inherits the consistency condition (5.2). Since Y a is continuous for\nevery a \u2208 A, this family admits a P-aggregator Y . Define Xt := lim\u03b5\u21920 1\u03b5 [Yt+\u03b5 \u2212 Yt ]. Then\none can verify directly that X satisfies all the requirements.\n- In the general case, set X R,a := (\u2212R)\u2228X a \u2227R. By the previous arguments there exists\nP-aggregator X R of the family {X R,a , a \u2208 A} and it is immediate that X := limR\u2192\u221e X R\nsatisfies all the requirements.\nWe now assume that X a is c\u00e0dl\u00e0g, Pa -almost surely for all a \u2208 A. In this case, the\nconsistency condition (5.2) is equivalent to\nXta = Xtb , 0 \u2264 t < \u03b8 a,b , Pa -almost surely for any a \u2208 A0 and b \u2208 A.\n\n(5.5)\n\nStep 1. We first introduce the following quotient sets of A0 . For each t, and a, b \u2208 A0 ,\na,b \u2265 t). Then\nwe say a \u223ct b if \u03a9a,b\nt = \u03a9 (or, equivalently, the constant disagreement time \u03b8\n\u223ct is an equivalence relationship in A0 . Thus one can form a partition of A0 based on \u223ct .\nPick an element from each partition set to construct a quotient set A0 (t) \u2282 A0 . That is,\na\nfor any a \u2208 A0 , there exists a unique b \u2208 A0 (t) such that \u03a9a,b\nt = \u03a9. Recall the notation \u03a9t\ndefined in (4.9). By (4.11) and the constant disagreement times property of A0 , we know\nthat {\u03a9at , a \u2208 A0 (t)} are disjoint.\nStep 2. For fixed t \u2208 R+ , define\n\u03bet (\u03c9) :=\n\nX\n\nXta (\u03c9)1\u03a9at (\u03c9) for all\n\na\u2208A0 (t)\n\n\u03c9 \u2208 \u03a9.\n\n(5.6)\n\nThe above uncountable sum is well defined because the sets {\u03a9at , a \u2208 A0 (t)} are disjoint.\nIn this step, we show that\n\u03bet is F\u0302tP -measurable and \u03bet = Xta , Pa -almost surely for all a \u2208 A.\n20\n\n(5.7)\n\n\fWe prove this claim in the following three sub-cases.\n2.1. For each a \u2208 A0 (t), by definition \u03bet = Xta on \u03a9at . Equivalently {\u03bet 6= Xta } \u2282 (\u03a9at )c .\nMoreover, by (4.10), Pa ((\u03a9at )c ) = 0. Since \u03a9at \u2208 Ft+ and Fta is complete under Pa , \u03bet is\nFta -measurable and Pa (\u03bet = Xta ) = 1.\n2.2. Also, for each a \u2208 A0 , there exists a unique b \u2208 A0 (t) such that a \u223ct b. Then\n= \u03a9, it follows from Lemma 5.2 that Pa = Pb on Ft+ and\n\u03bet = Xtb on \u03a9bt . Since \u03a9a,b\nt\nPa (\u03a9bt ) = Pb (\u03a9bt ) = 1. Hence Pa (\u03bet = Xtb ) = 1. Now by the same argument as in the first\ncase, we can prove that \u03bet is Fta -measurable. Moreover, by the consistency condition (5.8),\nPa (Xta = Xtb ) = 1. This implies that Pa (\u03bet = Xta ) = 1.\n2.3. Now consider a \u2208 A. We apply Lemma 4.12 with \u03c4 = t. This implies that there exist\na,a\na sequence {aj , j \u2265 1} \u2282 A0 such that \u03a9 = \u222aj\u22651 \u03a9t j . Then\ni\n[h\na,a\n{\u03bet 6= Xta } =\n{\u03bet 6= Xta } \u2229 \u03a9t j .\nj\u22651\n\nNow for each j \u2265 1,\ni\ni[h\nh\na\na,a\na\na,a\n{Xt j 6= Xta } \u2229 \u03a9t j .\n\u2282 {\u03bet 6= Xt j } \u2229 \u03a9t j\n\na,aj\n\n{\u03bet 6= Xta } \u2229 \u03a9t\n\nApplying Lemma 5.2 and using the consistency condition (5.5), we obtain\n\u0011\n\u0010\n\u0011\n\u0010\na\na,a\na\na,a\n= Paj {Xt j 6= Xta } \u2229 \u03a9t j\nPa {Xt j 6= Xta } \u2229 \u03a9t j\n\u0010\n\u0011\na\n= Paj {Xt j 6= Xta } \u2229 {t < \u03b8 a,aj } = 0.\na\n\naj\n\nMoreover, for aj \u2208 A0 , by the previous sub-case, {\u03bet 6= Xt j } \u2208 N P (Ft+ ). Hence there\na\nexists D \u2208 Ft+ such that Paj (D) = 0 and {\u03bet 6= Xt j } \u2282 D. Therefore\na\n\na,aj\n\n{\u03bet 6= Xt j } \u2229 \u03a9t\n\na,aj\n\n\u2282 D \u2229 \u03a9t\na\n\na,a\n\na,aj\n\nand Pa (D \u2229 \u03a9t\n\na,aj\n\n) = Paj (D \u2229 \u03a9t\n\n) = 0.\n\na\n\nThis means that {\u03bet 6= Xt j } \u2229 \u03a9t j \u2208 N P (Ft+ ). All of these together imply that {\u03bet 6=\na\nXta } \u2208 N P (Ft+ ). Therefore, \u03bet \u2208 Fta and Pa (\u03bet = Xta ) = 1.\nFinally, since \u03bet \u2208 Fta for all a \u2208 A, we conclude that \u03bet \u2208 F\u0302tP . This completes the proof\nof (5.7).\nStep 3. For each n \u2265 1, set tni := ni , i \u2265 0 and define\nX a,n := X0a 1{0} +\n\n\u221e\nX\ni=1\n\nXtani 1(tni\u22121 ,tni ] for all a \u2208 A and X n := \u03be0 1{0} +\n\n\u221e\nX\n\n\u03betni 1(tni\u22121 ,tni ] ,\n\ni=1\n\nP , t \u2265 0}. By Step 2, X a,n , X n are F\u0302n where \u03betni is defined by (5.6). Let F\u0302n := {F\u0302t+\n1\nn\n\nprogressively measurable and Pa (Xtn = Xta,n , t \u2265 0) = 1 for all a \u2208 A. We now define\nX := lim X n .\nn\u2192\u221e\n\n21\n\n\fSince F\u0302n is decreasing to F\u0302P and F\u0302P is right continuous, X is F\u0302P -progressively measurable.\nMoreover, for each a \u2208 A,\nh\\\ni\\\n\\\n{Xt = Xta , t \u2265 0} {X is c\u00e0dl\u00e0g} \u2287\n{Xtn = Xta,n , t \u2265 0}\n{X a is c\u00e0dl\u00e0g}.\nn\u22651\n\nTherefore X = X a and X is c\u00e0dl\u00e0g, Pa -almost surely for all a \u2208 A. In particular, X is\nc\u00e0dl\u00e0g, P-quasi surely.\n\u2737\nLet \u03c4\u0302 \u2208 T\u02c6 P and {\u03be a , a \u2208 A} be a family of F\u0302\u03c4\u0302P -measurable random variables. We say an\nF\u0302\u03c4\u0302P -measurable random variable \u03be is a P-aggregator of the family {\u03be a , a \u2208 A} if \u03be = \u03be a , Pa almost surely for all a \u2208 A. Note that we may identify any F\u0302\u03c4\u0302P -measurable random variable\n\u03be with the F\u0302P -progressively measurable process Xt := \u03be1[\u03c4\u0302 ,\u221e) . Then a direct consequence\nof Theorem 5.1 is the following.\nCorollary 5.4 Let A be satisfying (5.1) and \u03c4\u0302 \u2208 T\u0302 P . Then the family of F\u0302\u03c4\u0302P -measurable\nrandom variables {\u03be a , a \u2208 A} has a unique (P-q.s.) P-aggregator \u03be if and only if the\nfollowing consistency condition holds:\na\n\u03be a = \u03be b on \u03a9a,b\n\u03c4\u0302 , P -almost surely for any a \u2208 A0 and b \u2208 A.\n\n(5.8)\n\nFor the next result, we recall that the P-Brownian motion W P is defined in (4.2). As a\ndirect consequence of Theorem 5.1, the following result defines the P-Brownian motion.\na\n\nCorollary 5.5 For A satisfying (5.1), the family {W P , a \u2208 A} admits a unique P-aggregator\na\nW . Since W P is a Pa -Brownian motion for every a \u2208 A, we call W a P-universal Brownian\nmotion.\nProof.\n\nLet a, b \u2208 A. For each n, denote\nn\n\n\u03c4n := inf t \u2265 0 :\n\nZ\n\nt\n0\n\no\n|\u00e2s |ds \u2265 n \u2227 \u03b8 a,b .\n\nThen B*\u2227\u03c4n is a Pb -square integrable martingale. By standard construction of stochastic\nintegral, see e.g. [11] Proposition 2.6, there exist F-adapted simple processes \u03b2 b,m such that\no\nn Z \u03c4n 1\n\u22121\nPb\n(5.9)\n|\u00e2s2 (\u03b2sb,m \u2212 \u00e2s 2 )|2 ds = 0.\nlim E\nm\u2192\u221e\n\n0\n\nDefine the universal process\nWtb,m\n\n:=\n\nZ\n\nt\n0\n\n\u03b2sb,m dBs .\n\n22\n\n\fThen\nlim EP\n\nb\n\nm\u2192\u221e\n\nn\n\nsup\n0\u2264t\u2264\u03c4n\n\nWtb,m \u2212 WtP\n\nb\n\n2o\n\n= 0.\n\n(5.10)\n\nBy Lemma 2.4, all the processes in (5.9) and (5.10) can be viewed as F-adapted. Since\n\u03c4n \u2264 \u03b8 a,b , applying Lemma 5.2 we obtain from (5.9) and (5.10) that\nn\no\no\nn Z \u03c4n 1\nb 2\na\n\u22121\nPa\nsup Wtb,m \u2212 WtP\n= 0.\nlim EP\n|\u00e2s2 (\u03b2sb,m \u2212 \u00e2s 2 )|2 ds = 0,\nlim E\nm\u2192\u221e\n\nm\u2192\u221e\n\n0\n\n0\u2264t\u2264\u03c4n\n\nThe first limit above implies that\nlim EP\n\nm\u2192\u221e\n\na\n\nn\n\nsup\n0\u2264t\u2264\u03c4n\n\nWtb,m \u2212 WtP\n\na\n\n2o\n\n= 0,\n\nwhich, together with the second limit above, in turn leads to\na\n\nb\n\nWtP = WtP , 0 \u2264 t \u2264 \u03c4n ,\n\nPa \u2212 a.s.\n\nClearly \u03c4n \u2191 \u03b8 a,b as n \u2192 \u221e. Then\na\n\nb\n\nWtP = WtP , 0 \u2264 t < \u03b8 a,b ,\n\nPa \u2212 a.s.\n\na\n\nThat is, the family {W P , a \u2208 A} satisfies the consistency condition (5.2). We then apply\nTheorem 5.1 directly to obtain the P\u2212aggregator W .\n\u2737\nThe P\u2212Brownian motion W is our first example of a stochastic integral defined simultaneously under all Pa , a \u2208 A:\nZ t\n\u00e2\u22121/2\ndBs , t \u2265 0, P \u2212 q.s.\n(5.11)\nWt =\ns\n0\n\nWe will investigate in detail the universal integration in Section 6.\na\n\nRemark 5.6 Although a and W P are F-progressively measurable, from Theorem 5.1 we\ncan only deduce that \u00e2 and W are F\u0302P -progressively measurable. On the other hand, if\na\na\nwe take a version of W P that is progressively measurable to the augmented filtration F ,\nthen in general the consistency condition (5.2) does not hold. For example, let d = 1,\na\nat := 1, and bt := 1 + 1[1,\u221e) (t), t \u2265 0, as in Remark 5.3. Set WtP (\u03c9) := Bt (\u03c9) + 1(\u03a9a1 )c (\u03c9)\nb\n\na\n\nb\n\na\n\nb\n\nand WtP (\u03c9) := Bt (\u03c9) + [Bt (\u03c9) \u2212 B1 (\u03c9)]1[1,\u221e) (t). Then both W P and W P are F \u2229 F b\na\nprogressively measurable. However, \u03b8 a,b = 1, but Pb (W0P = W0P ) = Pb (\u03a9a1 ) = 0, so we do\nb\na\n\u2737\nnot have W P = W P , Pb -almost surely on [0, 1].\n\n23\n\n\f6\n\nQuasi-sure stochastic analysis\n\nIn this section, we fix again a separable class A of diffusion coefficients generated by A0 ,\nand set P := {Pa : a \u2208 A}. We shall develop the P-quasi sure stochastic analysis. We\nemphasize again that, when a probability measure P \u2208 P is fixed, by Lemma 2.4 there is\nP\nno need to distinguish the filtrations F+ , FP , and F .\nP -measurable\nWe first introduce several spaces. Denote by L0 the collection of all F\u0302\u221e\nrandom variables with appropriate dimension. For each p \u2208 [1, \u221e] and P \u2208 P, we denote\nby Lp (P) the corresponding Lp space under the measure P and\nL\u0302p :=\n\n\\\n\nLp (P).\n\nP\u2208P\n\nSimilarly, H0 := H0 (Rd ) denotes the collection of all Rd valued F\u0302P -progressively measurable\nprocesses. Hp (Pa ) is the subset of all H \u2208 H0 satisfying\nkHkpT,Hp (Pa )\n\n:= E\n\nPa\n\nh\u0010 Z\n\n0\n\nT\n\n2\n|a1/2\ns Hs | ds\n\n\u0011p/2 i\n\n< \u221e for all T > 0,\n\nand H2loc (Pa ) is the subset of H0 whose elements satisfy\nsurely, for all T \u2265 0. Finally, we define\n\u0124p :=\n\n\\\n\nHp (P) and \u01242loc :=\n\nP\u2208P\n\nRT\n0\n\n\\\n\n1/2\n\n|as Hs |2 ds < \u221e, Pa -almost\n\nH2loc (P).\n\nP\u2208P\n\nThe following two results are direct applications of Theorem 5.1. Similar results were\nalso proved in [5, 6], see e.g. Theorem 2.1 in [5], Theorem 36 in [6] and the Kolmogorov\ncriterion of Theorem 31 in [6].\nProposition 6.1 (Completeness) Fix p \u2265 1, and let A be satisfying (5.1).\n(i) Let (Xn )n \u2282 L\u0302p be a Cauchy sequence under each Pa , a \u2208 A. Then there exists a unique\nP ) for every a \u2208 A.\nrandom variable X \u2208 L\u0302p such that Xn \u2192 X in Lp (Pa , F\u0302\u221e\n(ii) Let (Xn )n \u2282 \u0124p be a Cauchy sequence under the norm k * kT,Hp (Pa ) for all T \u2265 0 and\na \u2208 A. Then there exists a unique process X \u2208 \u0124p such that Xn \u2192 X under the norm\nk * kT,Hp (Pa ) for all T \u2265 0 and a \u2208 A.\nP ), we may find X a \u2208 Lp (Pa , F\u0302 P ) such that\nProof. (i) By the completeness of Lp (Pa , F\u0302\u221e\n\u221e\nP ). The consistency condition of Theorem 5.1 is obviously satisfied\nXn \u2192 X a in Lp (Pa , F\u0302\u221e\nby the family {X a , a \u2208 A}, and the result follows. (ii) can be proved by a similar argument.\n\u2737\n\n24\n\n\fProposition 6.2 (Kolmogorov continuity criteria) Let A be satisfying (5.1), and X\nbe an F\u0302P -progressively measurable process with values in Rn . We further assume that for\nsome p > 1, Xt \u2208 L\u0302p for all t \u2265 0 and satisfy\na\n\nEP [|Xt \u2212 Xs |p ] \u2264 ca |t \u2212 s|n+\u03b5a for some constants ca , \u03b5a > 0.\nThen X admits an F\u0302P -progressively measurable version X\u0303 which is H\u00f6lder continuous, Pq.s. (with H\u00f6lder exponent \u03b1a < \u03b5a /p, Pa -almost surely for every a \u2208 A).\nProof. We apply the Kolmogorov continuity criterion under each Pa , a \u2208 A. This yields a\nPa\nfamily of F -progressively measurable processes {X a , a \u2208 A} such that X a = X, Pa -almost\nsurely, and X a is H\u00f6lder continuous with H\u00f6lder exponent \u03b1a < \u03b5a /p, Pa -almost surely for\nevery a \u2208 A. Also in view of Lemma 2.4, we may assume without loss of generality that X a\nis F\u0302P -progressively measurable for every a \u2208 A. Since each X a is a Pa -modification of X\nfor every a \u2208 A, the consistency condition of Theorem 5.1 is immediately satisfied by the\nfamily {X a , a \u2208 A}. Then, the aggregated process X\u0303 constructed in that theorem has the\ndesired properties.\n\u2737\nRemark 6.3 The statements of Propositions 6.1 and 6.2 can be weakened further by allowing p to depend on a.\n\u2737\nWe next construct the stochastic integral with respect to the canonical process B which is\nsimultaneously defined under all the mutually singular measures Pa , a \u2208 A. Such constructions have been given in the literature but under regularity assumptions on the integrand.\nHere we only place standard conditions on the integrand but not regularity.\nTheorem 6.4 (Stochastic integration) For A satisfying (5.1), let H \u2208 \u01242loc be given.\nThen, there exists a unique (P-q.s.) F\u0302P -progressively measurable process M such that M is\na local martingale under each Pa and\nZ t\nHs dBs , t \u2265 0, Pa -almost surely for all a \u2208 A.\nMt =\n0\n\nIf in addition H \u2208 \u01242 , then for every a \u2208 A, M is a square integrable Pa -martingale.\na Rt\na\n1/2\nMoreover, EP [Mt2 ] = EP [ 0 |as Hs |2 ds] for all t \u2265 0.\n\nRt\nProof. For every a \u2208 A, the stochastic integral Mta := 0 Hs dBs is well-defined Pa -almost\nPa\nsurely as a F -progressively measurable process. By Lemma 2.4, we may assume without\nloss of generality that M a is F\u0302P -adapted. Following the arguments in Corollary 5.5, in\nparticular by applying Lemma 5.2, it is clear that the consistency condition (5.2) of Theorem\n5.1 is satisfied by the family {M a , a \u2208 A}. Hence, there exists an aggregating process\n25\n\n\fM . The remaining statements in the theorem follows from classical results for standard\nstochastic integration under each Pa .\n\u2737\nWe next study the martingale representation.\nTheorem 6.5 (Martingale representation) Let A be a separable class of diffusion coefficients generated by A0 \u2282 AMRP . Let M be an F\u0302P -progressively measurable process which\nis a P\u2212quasi sure local martingale, that is, M is a local martingale under P for all P \u2208 P.\nThen there exists a unique (P-q.s.) process H \u2208 \u01242loc such that\nZ t\nHs dBs , t \u2265 0, P \u2212 q.s..\nMt = M0 +\n0\n\nProof. By Proposition 4.11, A \u2282 AMRP . Then for each P \u2208 P, all P\u2212martingales can be\nrepresented as stochastic integrals with respect to the canonical process. Hence, there exists\nunique (P\u2212almost surely) process H P \u2208 H2loc (P) such that\nZ t\nHsP dBs , t \u2265 0, P-almost surely.\nMt = M0 +\n0\n\nThen the quadratic covariation under Pb satisfies\nZ t\nb\nHsP \u00e2s ds,\nt \u2265 0, P \u2212 almost surely.\nhM, BiPt =\n\n(6.1)\n\n0\n\nNow for any a, b \u2208 A, from the construction of quadratic covariation and that of Lebesgue\nintegrals, following similar arguments as in Corollary 5.5 one can easily check that\nZ t\nZ t\nb\na\na\nb\nHsP \u00e2s ds, 0 \u2264 t < \u03b8 a,b , Pa \u2212 almost surely.\nHsP \u00e2s ds = hM, BiPt = hM, BiPt =\n0\n\n0\n\nThis implies that\n\na\n\nb\n\nH P 1[0,\u03b8a,b ) = H P 1[0,\u03b8a,b ) , dt \u00d7 dPa \u2212 almost surely.\nThat is, the family {H P , P \u2208 P} satisfies the consistency condition (5.2). Therefore, we\nmay aggregate them into a process H. Then one may directly check that H satisfies all the\nrequirements.\n\u2737\nThere is also P-quasi sure decomposition of super-martingales.\nProposition 6.6 (Doob-Meyer decomposition) For A satisfying (5.1), assume an F\u0302P progressively measurable process X is a P-quasi sure supermartingale, i.e., X is a Pa supermartingale for all a \u2208 A. Then there exist a unique (P-q.s.) F\u0302P -progressively measurable processes M and K such that M is a P-quasi sure local martingale and K is predictable\nand increasing, P-q.s., with M0 = K0 = 0, and Xt = X0 + Mt \u2212 Kt , t \u2265 0, P-quasi surely.\nIf further X is in class (D), P-quasi surely, i.e. the family {X\u03c4\u0302 , \u03c4\u0302 \u2208 T\u02c6 } is P-uniformly\nintegrable, for all P \u2208 P, then M is a P-quasi surely uniformly integrable martingale.\n26\n\n\fProof. For every P \u2208 A, we apply Doob-Meyer decomposition theorem (see e.g. DellacherieMeyer [4] Theorem VII-12). Hence there exist a P-local martingale M P and a P-almost\nsurely increasing process K P such that M0P = K0P = 0, P-almost surely. The consistency\ncondition of Theorem 5.1 follows from the uniqueness of the Doob-Meyer decomposition.\nThen, the aggregated processes provide the universal decomposition.\n\u2737\nThe following results also follow from similar applications of our main result.\nProposition 6.7 (It\u00f4's formula) For A satisfying (5.1), let A, H be F\u0302P -progressively\nmeasurable processes with values in R and Rd , respectively. Assume that A has finite variaRt\ntion over each time interval [0, t] and H \u2208 \u01242loc . For t \u2265 0, set Xt := At + 0 Hs dBs . Then\nfor any C 2 function f : R \u2192 R, we have\nZ t\nZ\n1 t T\nf \u2032 (Xs )(dAs + Hs dBs ) +\nf (Xt ) = f (A0 ) +\nHs \u00e2s Hs f \u2032\u2032 (Xs )ds, t \u2265 0, P-q.s..\n2\n0\n0\nProof.\n\nApply It\u00f4's formula under each P \u2208 P, and proceed as in the proof of Theorem 6.4.\n\u2737\n\nProposition 6.8 (local time) For A satisfying (5.1), let A, H and X be as in Proposition\n6.7. Then for any x \u2208 R, the local time {Lxt , t \u2265 0} exists P-quasi surely and is given by,\n2Lxt\nProof.\n6.4.\n\n= |Xt \u2212 x| \u2212 |X0 \u2212 x| \u2212\n\nZ\n\nt\n0\n\nsgn(Xs \u2212 x)(dAs + Hs dBs ), t \u2265 0, P \u2212 q.s..\n\nApply Tanaka's formula under each P \u2208 P and proceed as in the proof of Theorem\n\u2737\n\nFollowing exactly as in the previous results, we obtain a Girsanov theorem in this context\nas well.\nProposition 6.9 (Girsanov) For A satisfying (5.1), let \u03c6 be F\u0302P -progressively measurable\nRt\nand 0 |\u03c6s |2 ds < \u221e for all t \u2265 0, P-quasi surely. Let\nZt := exp\n\n\u0012Z\n\nt\n\n0\n\n\u03c6s dWs \u2212\n\n1\n2\n\nZ\n\n0\n\nt\n\n|\u03c6s |2 ds\n\n\u0013\n\nand W\u0303t := Wt \u2212\n\nZ\n\n0\n\nt\n\n\u03c6s ds, t \u2265 0,\n\nwhere W is the P-Brownian motion of (5.11). Suppose that for each P \u2208 P, EP [ZT ] = 1 for\nsome T \u2265 0. On F\u0302T we define the probability measure QP by dQP = ZT dP. Then,\nQP \u25e6 W\u0303 \u22121 = P \u25e6 W \u22121 for every P \u2208 P,\ni.e. W\u0303 is a QP -Brownian motion on [0, T, ] for every P \u2208 P.\n27\n\n\fWe finally discuss stochastic differential equations in this framework. Set Qm := {(t, x) :\nt \u2265 0, x \u2208 C[0, t]m }. Let b, \u03c3 be two functions from \u03a9 \u00d7 Qm to Rm and Mm,d (R), respectively. Here, Mm,d (R) is the space of m \u00d7 d matrices with real entries. We are interested\nin the problem of solving the following stochastic differential equation simultaneously under\nall P \u2208 P,\nZ t\nZ t\nbs (X s )ds +\nXt = X0 +\n\u03c3s (X s )dBs , t \u2265 0, P \u2212 q.s.,\n(6.2)\n0\n\n0\n\nwhere X t := (Xs , s \u2264 t).\nProposition 6.10 Let A be satisfying (5.1), and assume that, for every P \u2208 P and \u03c4 \u2208 T ,\nthe equation (6.2) has a unique FP -progressively measurable strong solution on interval [0, \u03c4 ].\nThen there is a P-quasi surely aggregated solution to (6.2).\nProof. For each P \u2208 A, there is a P-solution X P on [0, \u221e), which we may consider in its\nF\u0302P -progressively measurable version by Lemma 2.4. The uniqueness on each [0, \u03c4 ],\u03c4 \u2208 T\nimplies that the family {X P , P \u2208 P} satisfies the consistency condition of Theorem 5.1. \u2737\n\n7\n\nAn application\n\nAs an application of our theory, we consider the problem of super-hedging contingent claims\nunder volatility uncertainty, which was studied by Denis and Martini [5]. In contrast with\ntheir approach, our framework allows to obtain the existence of the optimal hedging strategy.\nHowever, this is achieved at the price of restricting the non-dominated family of probability\nmeasures.\nWe also mention a related recent paper by Fernholz and Karatzas [8] whose existence\nresults are obtained in the Markov case with a continuity assumption on the corresponding\nvalue function.\nLet A be a separable class of diffusion coefficients generated by A0 , and P := {Pa :\na \u2208 A} be the corresponding family of measures. We consider a fixed time horizon, say\nT = 1. Clearly all the results in previous sections can be extended to this setting, after\nsome obvious modifications. Fix a nonnegative F\u03021 \u2212measurable real-valued random variable\n\u03be. The superhedging cost of \u03be is defined by\n\u001b\n\u001a\nZ 1\nHs dBs \u2265 \u03be, P-q.s. for some H \u2208 H ,\nv(\u03be) := inf x : x +\n0\n\nR*\n\nwhere the stochastic integral 0 Hs dBs is defined in the sense of Theorem 6.4 and H \u2208 H0\nbelongs to H if and only if\nZ .\nZ 1\nT\nHs dBs is a P-q.s. supermartingale.\nHt \u00e2t Ht dt < \u221e P-q.s. and\n0\n\n0\n\n28\n\n\fWe shall provide a dual formulation of the problem v(\u03be) in terms of the following dynamic\noptimization problem,\nV\u03c4\u0302P\n\na\n\na\n\nb\n\n:= ess supP EP [\u03be|F\u0302\u03c4\u0302 ], Pa -a.s., a \u2208 A, \u03c4\u0302 \u2208 T\u0302 ,\n\n(7.1)\n\nb\u2208A(\u03c4\u0302 ,a)\n\nwhere\nA(\u03c4\u0302 , a) := {b \u2208 A : \u03b8 a,b > \u03c4\u0302 or \u03b8 a,b = \u03c4\u0302 = 1}.\nTheorem 7.1 Let A be a separable class of diffusion coefficients generated by A0 \u2282 AMRP .\nAssume that the family of random variables {V\u03c4\u0302P , \u03c4\u0302 \u2208 T\u0302 } is uniformly integrable under all\nP \u2208 P. Then\na\nv(\u03be) = V (\u03be) := sup kV0P kL\u221e (Pa ) .\n(7.2)\na\u2208A\n\nMoreover, if v(\u03be) < \u221e, then there exists H \u2208 H such that v(\u03be) +\n\nR1\n0\n\nHs dBs \u2265 \u03be, P-q.s..\n\nTo prove the theorem, we need the following (partial) dynamic programming principle.\nLemma 7.2 Let A be satisfying (5.1), and assume V (\u03be) < \u221e. Then, for any \u03c4\u03021 , \u03c4\u03022 \u2208 T\u0302\nwith \u03c4\u03021 \u2264 \u03c4\u03022 ,\n\u0003\na\nb\nb\u0002\nV\u03c4\u0302P1 \u2265 EP V\u03c4\u0302P2 |F\u0302\u03c4\u03021 , Pa -almost surely for all a \u2208 A and b \u2208 A(a, \u03c4\u03021 ).\n\nProof. By the definition of essential supremum, see e.g. Neveu [12] (Proposition VI-1-1),\nbj\nb\nthere exist a sequence {bj , j \u2265 1} \u2282 A(b, \u03c4\u03022 ) such that V\u03c4\u0302P2 = supj\u22651 EP [\u03be|F\u0302\u03c4\u03022 ], Pb -almost\nbj\n\n\u2191 V\u03c4\u0302P2 , Pb -almost\nsurely. For n \u2265 1, denote V\u03c4\u0302b,n\n:= sup1\u2264j\u2264n EP [\u03be|F\u0302\u03c4\u03022 ]. Then V\u03c4\u0302b,n\n2\n2\nb\n|F\u0302\u03c4\u03021 ] \u2191\nsurely as n \u2192 \u221e. By the monotone convergence theorem, we also have EP [V\u03c4\u0302b,n\n2\nb\nb\nP\nb\nb\na\nP\nE [V\u03c4\u03022 |F\u0302\u03c4\u03021 ], P -almost surely, as n \u2192 \u221e. Since b \u2208 A(a, \u03c4\u03021 ), P = P on F\u0302\u03c4\u03021 . Then\nb\nb\nb\n|F\u0302\u03c4\u03021 ] \u2191 EP [V\u03c4\u0302P2 |F\u0302\u03c4\u03021 ], Pa -almost surely, as n \u2192 \u221e. Thus it suffices to show that\nEP [V\u03c4\u0302b,n\n2\na\n\nb\n\nV\u03c4\u0302P1 \u2265 EP [V\u03c4\u0302b,n\n|F\u0302\u03c4\u03021 ],\n2\n\nPa -almost surely for all n \u2265 1.\n\nb\n\n(7.3)\n\nFix n and define\n\u03b8nb := min \u03b8 b,bj .\n1\u2264j\u2264n\n\nBy Lemma 5.2, \u03b8 b,bj are F-stopping times taking only countably many values, then so is \u03b8nb .\nMoreover, since bj \u2208 A(b, \u03c4\u03022 ), we have either \u03b8nb > \u03c4\u03022 or \u03b8nb = \u03c4\u03022 = 1. Following exactly the\nsame arguments as in the proof of (5.4), we arrive at\n\u0011\n\u0010\nb\nF\u0302\u03c4\u03022 \u2282 F\u03b8nb \u2228 N P (F1 ) .\n29\n\n\fSince Pbj = Pb on F\u0302\u03c4\u03022 , without loss of generality we may assume the random variables\nbj\nbj\n} and \u00c31 := A1 ,\nare F\u03b8nb -measurable. Set Aj := {EP [\u03be|F\u0302\u03c4\u03022 ] = V\u03c4\u0302b,n\nEP [\u03be|F\u0302\u03c4\u03022 ] and V\u03c4\u0302b,n\n2\n2\n\u00c3j := Aj \\ \u222ai<j Ai , 2 \u2264 j \u2264 n. Then \u00c31 , * * * , \u00c3n are F\u03b8nb -measurable and form a partition\nof \u03a9. Now set\nn\nX\nbj (t)1\u00c3j 1[\u03c4\u03022 ,1] (t).\nb\u0303(t) := b(t)1[0,\u03c4\u03022 ) (t) +\nj=1\n\nWe claim that b\u0303 \u2208 A. Equivalently, we need to show that b\u0303 takes the form (4.12). We know\nthat b and bj have the form\nb(t) =\n\n\u221e X\n\u221e\nX\n\nb0,m\nand bj (t) =\n0 ,\u03c4 0\ni 1E 0,m 1[\u03c4m\nm+1 )\ni\n\nm=0 i=1\n\n\u221e X\n\u221e\nX\n\nbj,m\nj\ni 1E j,m 1[\u03c4m\n,\u03c4 j\n\nm+1 )\n\ni\n\nm=0 i=1\n\nwith the stopping times and sets as before. Since bj (t) = b(t) for t \u2264 \u03b8nb and j = 1, * * * , n,\nb\u0303(t) = b(t)1[0,\u03b8nb ) +\n\nn\nX\n\n1\u00c3j bj (t)1[\u03b8nb ,1] (t)\n\nj=1\n\n=\n\n\u221e X\n\u221e\nX\n\nb0,m\n0 \u2227\u03b8 b ,\u03c4 0\nb\ni 1E 0,m \u2229{\u03c4 0 <\u03b8 b } 1[\u03c4m\nn m+1 \u2227\u03b8n )\n\nm=0 i=1\n\u221e X\n\u221e\nn X\nX\n\n+\n\nj=1 m=0 i=1\n\ni\n\nm\n\nn\n\nbj,m\ni 1E j,m \u2229\u00c3j \u2229{\u03c4 j\n\nb\nm+1 >\u03b8n }\n\ni\n\n1[\u03c4m\nj\n\u2228\u03b8 b ,\u03c4 j\nn\n\nb\nm+1 \u2228\u03b8n )\n\n.\n\n0 \u2227 \u03b8 b and \u03c4 j \u2228 \u03b8 b are F-stopping times and take only\nBy Definition 4.8, it is clear that \u03c4m\nm\nn\nn\ncountably many values, for all m \u2265 0 and 1 \u2264 j \u2264 n. For m \u2265 0 and 1 \u2264 j \u2264 n, one can\nj,m\nj\n0 < \u03b8 b } is F\n\u2229 \u00c3j \u2229 {\u03c4m+1\n> \u03b8nb }\neasily see that Ei0,m \u2229 {\u03c4m\n0 \u2227\u03b8 b -measurable and that Ei\n\u03c4m\nn\nn\nj\n0 \u2227 \u03b8 b and \u03c4 \u2228 \u03b8 b we prove our\nis F\u03c4m\n-measurable. By ordering the stopping times \u03c4m\nj\nm\nn\nn\n\u2228\u03b8 b\nn\n\nclaim that b\u0303 \u2208 A.\nIt is now clear that b\u0303 \u2208 A(b, \u03c4\u03022 ) \u2282 A(a, \u03c4\u03021 ). Thus,\ni\nh b\u0303\na\nb\u0303\nb\u0303\nV\u03c4\u0302P1 \u2265 EP [\u03be|F\u0302\u03c4\u03021 ] = EP EP [\u03be|F\u0302\u03c4\u03022 ] F\u0302\u03c4\u03021\n= EP\n\n= EP\n\nb\u0303\n\nb\u0303\n\nn\nhX\n\nj=1\nn\nhX\nj=1\n\n= EP\n\nn\nhX\nb\u0303\nj=1\n\nb\u0303\n\nEP [\u03be1\u00c3j |F\u0302\u03c4\u03022 ] F\u0302\u03c4\u03021\nbj\n\ni\n\nEP [\u03be1\u00c3j |F\u0302\u03c4\u03022 ] F\u0302\u03c4\u03021\n\ni\n\ni\nb,n\na\nPb\u0303\nV\u03c4\u0302b,n\n1\nF\u0302\n\u03c4\u03021 = E [V\u03c4\u03022 F\u0302\u03c4\u03021 ], P -almost surely.\n\u00c3j\n2\n\nFinally, since Pb\u0303 = Pb on F\u0302\u03c4\u03022 and Pb = Pa on F\u0302\u03c4\u03021 , we prove (7.3) and hence the lemma. \u2737\n30\n\n\fProof of Theorem 7.1. We first prove that v(\u03be) \u2265 V (\u03be). If v(\u03be) = \u221e, then the inequality\nRt\nis obvious. If v(\u03be) < \u221e, there are x \u2208 R and H \u2208 H such that the process Xt := x+ 0 Hs dBs\nsatisfies X1 \u2265 \u03be, P\u2212quasi surely. Notice that the process X is a Pb -supermartingale for\nevery b \u2208 A. Hence\nb\n\nb\n\nx = X0 \u2265 EP [X1 |F\u03020 ] \u2265 EP [\u03be|F\u03020 ],\n\nPb \u2212 a.s.\n\n\u2200 b \u2208 A.\n\nBy Lemma 5.2, we know that Pa = Pb on F\u03020 whenever a \u2208 A and b \u2208 A(0, a). Therefore,\nb\n\nx \u2265 EP [\u03be|F\u03020 ], Pa -a.s..\na\n\na\n\nThe definition of V P and the above inequality imply that x \u2265 V0P , Pa -almost surely. This\na\nimplies that x \u2265 kV0P kL\u221e (Pa ) for all a \u2208 A. Therefore, x \u2265 V (\u03be). Since this holds for any\ninitial data x that is super-replicating \u03be, we conclude that v(\u03be) \u2265 V (\u03be).\nWe next prove the opposite inequality. Again, we may assume that V (\u03be) < \u221e. Then\n\u03be \u2208 L\u03021 . For each P \u2208 P, by Lemma 7.2 the family {V\u03c4\u0302P , \u03c4\u0302 \u2208 T\u0302 } satisfies the (partial) dynamic\nprogramming principle. Then following standard arguments (see e.g. [7] Appendix A2), we\nconstruct from this family a c\u00e0dl\u00e0g (F\u0302P , P)-supermartingale V\u0302 P defined by,\nV\u0302tP := lim VrP , t \u2208 [0, 1].\nQ\u220br\u2193t\n\n(7.4)\n\nAlso for each \u03c4\u0302 \u2208 T\u02c6 , it is clear that the family {V\u03c4\u0302P , P \u2208 P} satisfies the consistency\ncondition (5.8). Then it follows immediately from (7.4) that {V\u0302tP , P \u2208 P} satisfies the\nconsistency condition (5.8) for all t \u2208 [0, 1]. Since P-almost surely V\u0302 P is c\u00e0dl\u00e0g, the family\nof processes {V\u0302 P , P \u2208 P} also satisfy the consistency condition (5.2). We then conclude\nfrom Theorem 5.1 that there exists a unique aggregating process V\u0302 .\nNote that V\u0302 is a P-quasi sure supermartingale. Then it follows from the Doob-Meyer\ndecomposition of Proposition 6.6 that there exist a P-quasi sure local martingale M and\na P-quasi sure increasing process K such that M0 = K0 = 0 and V\u0302t = V\u03020 + Mt \u2212 Kt ,\nt \u2208 [0, 1), P-quasi surely. Using the uniform integrability hypothesis of this theorem, we\nconclude that the previous decomposition holds on [0, 1] and the process M is a P-quasi\nsure martingale on [0, 1].\nIn view of the martingale representation Theorem 6.5, there exists an F\u0302P -progressively\nR1\nRt\nmeasurable process H such that 0 HtT \u00e2t Ht dt < \u221e and V\u0302t = V\u03020 + 0 Hs dBs \u2212 Kt , t \u2265 0,\nR1\nP-quasi surely. Notice that V\u03021 = \u03be and K1 \u2265 K0 = 0. Hence V\u03020 + 0 Hs dBs \u2265 \u03be, P-quasi\nsurely. Moreover, by the definition of V (\u03be), it is clear that V (\u03be) \u2265 V\u03020 , P-quasi surely. Thus\nR1\nV (\u03be) + 0 Hs dBs \u2265 \u03be, P-quasi surely.\nFinally, since \u03be is nonnegative, V\u0302 \u2265 0. Therefore,\nZ t\nZ t\nHs dBs \u2265 V\u0302t \u2265 0,\nP \u2212 q.s..\nHs dBs \u2265 V\u03020 +\nV (\u03be) +\n0\n\n0\n\n31\n\n\fThis implies that H \u2208 H, and thus V (\u03be) \u2265 v(\u03be).\n\n\u2737\n\nRemark 7.3 Denis and Martini [5] require\na \u2264 a \u2264 a for all a \u2208 A,\n\n(7.5)\n\nfor some given constant matrices a \u2264 a in S>0\nd . We do not impose this constraint. In other\nwords, we may allow a = 0 and a = \u221e. Such a relaxation is important in problems of static\nhedging in finance, see e.g. [2] and the references therein. However, we still require that\neach a \u2208 A takes values in S>0\n\u2737\nd .\nWe shall introduce the set AS \u2282 AMRP induced from strong formulation in Section 8.\nWhen A0 \u2282 AS , we have the following additional interesting properties.\nRemark 7.4 If each P \u2208 P satisfies the Blumenthal zero-one law (e.g. if A0 \u2282 AS by\na\nLemma 8.2 below), then V0P is a constant for all a \u2208 A, and thus (7.2) becomes\na\n\nv(\u03be) = V (\u03be) := sup V0P .\na\u2208A\n\nRemark 7.5 In general, the value V (\u03be) depends on A, then so does v(\u03be). However, when\n\u03be is uniformly continuous in \u03c9 under the uniform norm, we show in [16] that\n\u001b\n\u001a\nZ 1\nP\nHs dBs \u2265 \u03be, P-a.s. for all P \u2208 P S , for some H \u2208 H ,(7.6)\nsup E [\u03be] = inf x : x +\nP\u2208P S\n\n0\n\nand the optimal superhedging strategy H exists, where H is the space of F-progressively\nR1\nR.\nmeasurable H such that, for all P \u2208 P S , 0 HtT \u00e2t Ht dt < \u221e, P-almost surely and 0 Hs dBs\nis a P-supermartingale. Moreover, if A \u2282 AS is dense in some sense, then\nV (\u03be) = v(\u03be) = the P S -superhedging cost in (7.6).\nIn particular, all functions are independent of the choice of A. This issue is discussed\nin details in our accompanying paper [16] (Theorem 5.3 and Proposition 5.4), where we\nestablish a duality result for a more general setting called the second order target problem.\nHowever, the set-up in [16] is more general and this independence can be proved by the\nabove arguments under suitable assumptions.\n\u2737\n\n8\n\nMutually singular measures induced by strong formulation\n\nWe recall the set P S introduced in the Introduction as\n\b\nP S := P\u03b1S : \u03b1 \u2208 A\n\nwhere P\u03b1S := P0 \u25e6 (X \u03b1 )\u22121 ,\n32\n\n(8.7)\n\n\fand X \u03b1 is given in (1.1). Clearly P S \u2282 P W . Although we do not use it in the present paper,\nthis class is important both in theory and in applications. We remark that Denis-Martini\n[5] and our paper [15] consider the class P W while Denis-Hu-Peng [6] and our paper [17]\nconsider the class P S , up to some technical restriction of the diffusion coefficients.\nWe start the analysis of this set by noting that\n\u03b1 is the quadratic variation density of X \u03b1 and dBs = \u03b1\u22121/2\ndXs\u03b1 , under P0 .\ns\n\n(8.8)\n\nSince B under P\u03b1S has the same distribution as X \u03b1 under P0 , it is clear that\n\u03b1\n\nthe P\u03b1S -distribution of (B, \u00e2, W PS ) is equal to the P0 -distribution of (X \u03b1 , \u03b1, B).\n\n(8.9)\n\nIn particular, this implies that\n\u03b1\n\n\u00e2(X \u03b1 ) = \u03b1(B), P0 -a.s., \u00e2(B) = \u03b1(W PS ), P\u03b1S -a.s.,\n(8.10)\nand for any a \u2208 AW (P\u03b1S ), X \u03b1 is a strong solution to SDE (4.4) with coefficient a.\nMoreover we have the following characterization of P S in terms of the filtrations.\n\u001a\n\u001b\nP\nP\nLemma 8.1 P S = P \u2208 P W : FW P = F .\nP0\n\nProof. By (8.8), \u03b1 and B are FX \u03b1 -progressively measurable. Since F is generated by B,\nP0\nP0\nP\nwe conclude that F \u2282 FX \u03b1 . By completing the filtration we next obtain that F 0 \u2282 FX \u03b1 .\nP0\n\u03b1\nP0\nP0\nMoreover, for any \u03b1 \u2208 A, it is clear that FX \u2282 F . Thus, FX \u03b1 = F . Now, we invoke\nP\nP\n(8.9) and conclude FW P = F for any P = P\u03b1S \u2208 P S .\nP\n\nP\n\nConversely, suppose P \u2208 P W be such that FW P = F . Then B = \u03b2(W*P ) for some\n\u03b1\nmeasurable mapping \u03b2 : Q \u2192 S>0\n\u2737\nd . Set \u03b1 := \u03b2(B* ), we conclude that P = PS .\nThe following result shows that the measures P \u2208 P S satisfy MRP and the Blumental\nzero-one law.\nLemma 8.2 P S \u2282 P MRP and every P \u2208 P S satisfies the Blumenthal zero-one law.\nProof.\n\nP\n\nFix P \u2208 P S . We first show that P \u2208 P MRP . Indeed, for any (F , P)-local martingale\nP\n\nM , Lemma 8.1 implies that M is a (FW P , P)-local martingale. Recall that W P is a P\nBrownian motion. Hence, we now can use the standard martingale representation theorem.\nP\nTherefore, there exists a unique FW P -progressively measurable process H\u0303 such that\nZ t\nZ t\n2\nH\u0303s dWsP , t \u2265 0, P-a.s..\n|H\u0303s | ds < \u221e and Mt = M0 +\n0\n\n0\n\nSince \u00e2 > 0, dW P = \u00e2\u22121/2 dB. So one can check directly that the process H := \u00e2\u22121/2 H\u0303\nsatisfies all the requirements.\n33\n\n\fWe next prove the Blumenthal zero-one law. For this purpose fix E \u2208 F0+ . By Lemma\nP\n\nP\n\n8.1, E \u2208 F0W . Again we recall that W P is a P Brownian motion and use the standard\nBlumenthal zero-one law for the Brownian motion. Hence P(E) \u2208 {0, 1}.\n\u2737\nWe now define analogously the following spaces of measures and diffusion processes.\nAS := {a \u2208 AW : Pa \u2208 PS } .\n\nPS := P S \u2229 PW ,\n\n(8.11)\n\nThen it is clear that\nPS \u2282 PMRP \u2282 PW\n\nand AS \u2282 AMRP \u2282 AW .\n\nThe conclusion PS \u2282 PW is strict, see Barlow [1]. We remark that one can easily check that\nthe diffusion process a in Examples 4.4 and 4.5 and the generating class A0 in Examples\n4.9, 4.10, and 4.14 are all in AS .\nOur final result extends Proposition 4.11.\nProposition 8.3 Let A be a separable class of diffusion coefficients generated by A0 . If\nA0 \u2282 AS , then A \u2282 AS .\nProof. Let a be given in the form (4.12) and, by Proposition 4.11, P be the unique weak\nsolution to SDE (4.4) on [0, \u221e) with coefficient a and initial condition P(B0 = 0) = 1. By\nP\n\nLemma 8.1 and its proof, it suffices to show that a is FW P -adapted. Recall (4.12). We\nprove by induction on n that\nP\n\nP\n\nW\n\u2212 measurable for all t \u2265 0.\nat 1{t<\u03c4n } is Ft\u2227\u03c4\nn\n\n(8.12)\n\nSince \u03c40 = 0, a0 is F0 -measurable, and P(B0 = 0) = 1, (8.12) holds when n = 0. Assume\n(8.12) holds true for n. Now we consider n + 1. Note that\nat 1{t<\u03c4n+1 } = at 1{t<\u03c4n } + at 1{\u03c4n \u2264t<\u03c4n+1 } .\nBy the induction assumption it suffices to show that\nP\n\nP\n\nat 1{t<\u03c4n+1 } is F\u03c4Wn \u2228t\u2227\u03c4n+1 \u2212 measurable for all t \u2265 0.\n\n(8.13)\n\nP\nApply Lemma 4.12, we have at =\nm\u22651 am (t)1Em for t < \u03c4n+1 , where am \u2208 A0 and\n{Em , m \u2265 1} \u2282 F\u03c4n form a partition of \u03a9. Let Pm denote the unique weak solution to SDE\n(4.4) on [0, \u221e) with coefficient am and initial condition Pm (B0 = 0) = 1. Then by Lemma\n5.2 we have, for each m \u2265 1,\nP(E \u2229 Em ) = Pm (E \u2229 Em ),\n34\n\n\u2200E \u2208 F\u03c4n+1 .\n\n(8.14)\n\n\fMorover, by (4.2) it is clear that\nm\n\nWtP = WtP , 0 \u2264 t \u2264 \u03c4n+1 , P \u2212 a.s. on Em (and Pm \u2212 a.s. on Em ).\nPm\n\nW\nNow since am \u2208 A0 \u2282 AS , we know am (t)1{t<\u03c4n+1 } is Ft\u2227\u03c4\nn+1\n\nPm\n\n(8.15)\n\n\u2212measurable. This, together\nPm\n\nPm\n\nwith the fact that Em \u2208 F\u03c4n , implies that am (t)1{t<\u03c4n+1 } 1Em is F\u03c4Wn \u2228t\u2227\u03c4n+1 \u2212measurable.\nBy (8.14), (8.15) and that at = am (t) for t < \u03c4n+1 on Em , we see that at 1{t<\u03c4n+1 } 1Em is\nP\n\nP\n\nF\u03c4Wn \u2228t\u2227\u03c4n+1 \u2212measurable. Since m is arbitrary, we get\nat 1{t<\u03c4n+1 } =\nP\n\nX\n\nm\u22651\n\nat 1{t<\u03c4n+1 } 1Em\n\nP\n\nis F\u03c4Wn \u2228t\u2227\u03c4n+1 \u2212measurable. This proves (8.13), and hence the proposition.\n\n9\n\n\u2737\n\nAppendix\n\nIn this Appendix we provide a few more examples concerning weak solutions of (4.4) and\ncomplete the remaining technical proofs.\n\n9.1\n\nExamples\n\nExample 9.1 (No weak solution) Let a0 = 1, and for t > 0,\nat := 1 + 1E , where E :=\n\nn\n\nlim \u221a\nh\u21930\n\nBh \u2212 B0\n\n2h ln ln h\u22121\n\no\n6= 2 .\n\nThen E \u2208 F0+ . Assume P is a weak solution to (4.4). On E, a = 2, then limh\u21930\nlimh\u21930 \u221a Bh \u2212B0 \u22121\n2h ln ln h\n\nEc,\n\n2, P-almost surely, thus P(E) = 0. On\na = 1, then\nsurely and thus P(E c ) = 0. Hence there can not be any weak solutions.\n\n\u221a Bh \u2212B0\n2h ln ln h\u22121\n\n=\n\n= 1, P-almost\n\u2737\n\nExample 9.2 (Martingale measure without Blumenthal 0-1 law) Let \u03a9\u2032 := {1, 2} and\nP\u20320 (1) = P\u20320 (2) = 12 . Let \u03a9\u0303 := \u03a9 \u00d7 \u03a9\u2032 and P\u03030 the product of P0 and P\u20320 . Define\nB\u0303t (\u03c9, 1) := \u03c9t ,\nThen P\u0303 := P\u03030 \u25e6 (B\u0303)\u22121 is in P W . Denote\n(\nE :=\n\nlim \u221a\nt\u21930\n\nB\u0303t (\u03c9, 2) := 2\u03c9t .\n\nB\u0303h \u2212 B\u03030\n\n2h ln ln h\u22121\n\nB\u0303 , and P\u0303 (E) = P\u2032 (1) = 1 .\nThen E \u2208 F0+\n0\n0\n2\n\n)\n\n=1 .\n\n\u2737\n\n35\n\n\fExample 9.3 (Martingale measure without MRP) Let \u03a9\u0303 := (C[0, 1])2 , (W\u0303 , W\u0303 \u2032 ) the canonical process, and P\u03030 the Wiener measure so that W\u0303 and W\u0303 \u2032 are independent Brownian\nmotions under P\u03030 . Let \u03c6 : R \u2192 [0, 1] be a measurable function, and\nZ t\n1\n\u03b1\u0303s dW\u0303s where \u03b1\u0303t := [1 + \u03c6(W\u0303t\u2032 )] 2 , t \u2265 0,\nB\u0303t :=\n0\n\nThis induces the following probability measure P on \u03a9 with d = 1,\nP := P\u03030 \u25e6 B\u0303 \u22121 .\nThen P is a square integrable martingale measure with dhBit /dt \u2208 [1, 2], P-almost surely.\nWe claim that B has no MRP under P. Indeed, if B has MRP under P, then so does B\u0303\nunder P\u03030 . Let \u03be\u0303 := EP\u03030 [W\u03031\u2032 |F1B\u0303 ]. Since \u03be\u0303 \u2208 F1B\u0303 and is obviously P\u03030 -square integrable, then\nthere exists H\u0303 a \u2208 H2 (P\u03030 , FB\u0303 ) such that\nZ 1\nZ 1\nP\u03030\nP\u03030\na\nP\u03030 \u2212 a.s..\nH\u0303ta \u03b1\u0303t dW\u0303t ,\nH\u0303t dB\u0303t = E [\u03be\u0303] +\n\u03be\u0303 = E [\u03be\u0303] +\n0\n\n0\n\nSince W\u0303 and W\u0303 \u2032 are independent under P\u03030 , we get 0 = EP\u03030 [\u03be\u0303 W\u03031\u2032 ] = EP\u03030 [|\u03be\u0303|2 ]. Then \u03be\u0303 = 0,\ndP\u03030 -almost surely, and thus\nEP\u03030 [W\u03031\u2032 |B\u03031 |2 ] = EP\u03030 [\u03be\u0303|B\u03031 |2 ] = 0.\n\n(9.1)\n\nHowever, it follows from It\u00f4's formula, together with the independence of W and W \u2032 , that\nZ 1\nZ 1\nh\nh\ni\ni\nP\u03030\nP\u03030\n\u2032\n2\nP\u03030\n\u2032\n\u2032\nE [W\u03031 |B\u03031 | ] = E W\u03031\n\u03b1\u03032t dt\n2B\u0303t \u03b1\u0303t dW\u0303t + E W\u03031\n0\n0\nhZ 1\nnZ 1\ni\no\n\u0001\n= EP\u03030\nW\u0303t\u2032 1 + \u03c6(W\u0303t\u2032 ) dt = EP\u03030\nW\u0303t\u2032 \u03c6(W\u0303t\u2032 )dt ,\n0\n\n0\n\nand we obtain a contradiction to (9.1) by observing that the latter expectation is non-zero\nfor \u03c6(x) := 1R+ (x).\n\u2737\nWe note that, however, we are not able to find a good example such that a \u2208 AW (so\nthat (4.4) has unique weak solution) but B has no MRP under Pa (and consequently (4.4)\nhas no strong solution).\n\n9.2\n\nSome technical proofs\n\nProof of Lemma 2.4. The uniqueness is obvious. We now prove the existence.\n(i) Assume X is c\u00e0dl\u00e0g, P-almost surely. Let E0 := {\u03c9 : X* (\u03c9) is not c\u00e0dl\u00e0g}. For each\nr \u2208 Q \u2229 (0, \u221e), there exists X\u0303r \u2208 Fr+ such that Er := {X\u0303r 6= Xr } \u2208 N P (F\u221e ). Let\nE := E0 \u222a (\u222ar Er ). Then P(E) = 0. For integers n \u2265 1 k \u2265 0, set tnk := k/n, and define\n\u0003\nXtn := X\u0303tnk+1 for t \u2208 tnk , tnk+1 , and X\u0303 := ( lim X n )1{limn\u2192\u221e X n \u2208R} .\nn\u2192\u221e\n\n36\n\n\fThen for any t \u2208 (tnk , tnk+1 ], Xtn \u2208 Ft+n\n\nk+1\n\nand X n |[0,t] \u2208 B([0, t]) \u00d7 Ft+n . Since F+ is right\nk+1\n\ncontinuous, we get X\u0303t \u2208 Ft+ and X\u0303|[0,t] \u2208 B([0, t]) \u00d7 Ft+ . That is, X\u0303 \u2208 F+ . Moreover, for\nany \u03c9 \u2208\n/ E and n \u2265 1, if t \u2208 (tnk , tnk+1 ], we get\nlim Xtn (\u03c9) = lim X\u0303tnk+1 (\u03c9) = lim Xtnk+1 (\u03c9) = Xt (\u03c9).\n\nn\u2192\u221e\n\nn\u2192\u221e\n\nn\u2192\u221e\n\nSo {\u03c9 : there exists t \u2265 0 such that X\u0303t (\u03c9) 6= Xt (\u03c9)} \u2282 E. Then, X\u0303 is P-indistinguishable\nfrom X and thus X\u0303 also has c\u00e0dl\u00e0g paths, P-almost surely.\nRt\nP\n(ii) Assume X is F -progressively measurable and is bounded. Let Yt := 0 Xs ds. Then Y\nis continuous. By (i), there exists F+ -progressively measurable continuous process \u1ef8 such\nthat \u1ef8 and Y are P-indistinguishable. Let E0 := {there exists t \u2265 0 such that \u1ef8t 6= Yt },\nthen P(E0 ) = 0 and \u1ef8* (\u03c9) is continuous for each \u03c9 \u2208\n/ E0 . Define,\nXtn := n[\u1ef8t \u2212 \u1ef8t\u2212 1 ];\nn\n\nX\u0303 := ( lim X n )1{limn\u2192\u221e X n \u2208R} for n \u2265 1.\nn\u2192\u221e\n\nAs in (i), we see X\u0303 \u2208 F+ . Moreover, for each \u03c9 \u2208\n/ E0 , Xtn (\u03c9) = n\nX\u0303* (\u03c9) = X* (\u03c9), dt-almost surely. Therefore, X\u0303 = X, P-almost surely.\n\nRt\n\n1\nt\u2212 n\n\nXs (\u03c9)ds. Then\n\nP\n\n(iii) For general F -progressively measurable X, let Xtm := (\u2212m) \u2228 (X \u2227 m), for any m \u2265 1.\nBy (ii), X m has an F+ -adapted modification X\u0303 m . Then obviously the following process X\u0303\n\u2737\nsatisfies all the requirements: X\u0303 := (limm\u2192\u221e X\u0303 m )1{limm\u2192\u221e X\u0303 m \u2208R} .\nTo prove Example 4.5, we need a simple lemma.\nLemma 9.4 Let \u03c4 be an F-stopping time and X is an F-progressively measurable process.\nThen \u03c4 (X* ) is also an F\u2212stopping time.\nMoreover, if Y is F-progressively measurable and Yt = Xt for all t \u2264 \u03c4 (X* ), then \u03c4 (Y* ) =\n\u03c4 (X* ).\nProof. Since \u03c4 is an F-stopping time, we have {\u03c4 (X* ) \u2264 t} \u2208 FtX for all t \u2265 0. Moreover,\nsince X is F-progressively measurable, we know FtX \u2282 FtB . Then {\u03c4 (X* ) \u2264 t} \u2208 FtB and\nthus \u03c4 (X* ) is an F\u2212stopping time.\nNow assume Yt = Xt for all t \u2264 \u03c4 (X* ). For any t \u2265 0, on {\u03c4 (X* ) = t}, we have Ys = Xs\nfor all s \u2264 t. Since {\u03c4 (X* ) = t} \u2208 FtX and by definition FtX = \u03c3(Xs , s \u2264 t}, then \u03c4 (Y* ) = t\non the event {\u03c4 (X* ) = t}. Therefore, \u03c4 (Y* ) = \u03c4 (X* ).\n\u2737\nProof of Example 4.5. Without loss of generality we prove only that (4.4) on R+ with X0 = 0\nhas a unique strong solution. In this case the stochastic differential equation becomes\ndXt =\n\n\u221e\nX\n\nn=0\n\nan (X* )1[\u03c4n (X* ),\u03c4n+1 (X* )) dBt , t \u2265 0, P0 \u2212 a.s..\n37\n\n\fWe prove the result by induction on n. Let X 0 be the solution to SDE:\nZ t\n1/2\n0\na0 (X*0 )dBs , t \u2265 0 , P0 \u2212 almost surely\nXt =\n0\n\n1\n\nNote that a0 is a constant, thus Xt0 = a02 Bt and is unique. Denote \u03c4\u03030 := 0 and \u03c4\u03031 := \u03c41 (X*0 ).\nBy Lemma 9.4, \u03c4\u03031 is an F\u2212stopping time. Now let Xt1 := Xt0 for t \u2264 \u03c4\u03031 , and\nZ t\n1/2\nXt1 = X\u03c4\u030301 +\na1 (X*1 )dBs , t \u2265 \u03c4\u03031 , P0 \u2212 a.s.\n\u03c4\u03031\n\nNote that a1 \u2208 F\u03c41 , that is, for any y \u2208 R and t \u2265 0, {a1 (B* ) \u2264 y, \u03c41 (B* ) \u2264 t} \u2208 Ft . Thus,\nfor any x, x\u0303 \u2208 C(R+ , Rd ), if xs = x\u0303s , 0 \u2264 s \u2264 t, then a1 (x)1{\u03c41 (x)\u2264t} = a1 (x\u0303)1{\u03c41 (x\u0303)\u2264t} . In\nparticular, noting that \u03c41 (X*1 ) = \u03c41 (X*0 ) = \u03c4\u03031 , for each \u03c9 by choosing t = \u03c4\u0303 we obtain that\na1 (X*1 ) = a1 (X*0 ). Thus Xt1 = X\u03c4\u030301 + a1 (X*0 )[Bt \u2212 B\u03c4\u03031 ], t \u2265 \u03c4\u03031 , and is unique. Now repeat\nthe procedure for n = 1, 2, * * * we obtain the unique strong solution X in [0, \u03c4\u0303\u221e ), where\n\u03c4\u0303\u221e := limn\u2192\u221e \u03c4n (X* ). Since a is bounded, it is obvious that X\u03c4\u0303\u221e := limt\u2191\u03c4\u0303\u221e Xt exists P0 almost surely. Then, by setting Xt := X\u03c4\u0303\u221e for t \u2208 (\u03c4\u0303\u221e , \u221e) we complete the construction.\n\u2737\nProof of Lemma 4.12. Let a be given as in (4.12) and \u03c4 \u2208 T be fixed. First, since {Ein , i \u2265 1}\nis a partition of \u03a9, then for any n \u2265 0,\no\nn\nalso form a partition of \u03a9.\n\u2229nj=0 Eijj , (ij )0\u2264j\u2264n \u2208 Nn+1\n\nNext, assume \u03c4n takes values tnk (possibly including the value \u221e), k \u2265 1. Then {{\u03c4n =\ntnk }, k \u2265 1} form a partition of \u03a9. Similarly we have, for any n \u2265 0,\no\nn\nj\nn+2\nform a partition of \u03a9.\n\u2229n+1\n{\u03c4\n=\nt\n},\n(k\n)\n\u2208\nN\nj\nj\n0\u2264j\u2264n+1\nj=0\nkj\n\nThese in turn form another partition of \u03a9 given by,\no\nnh\n\u0001i \\\n2(n+1)\n{\u03c4n+1 = tn+1\n},\n(i\n,\nk\n)\n\u2208\nN\n,\nk\n\u2208\nN\n. (9.2)\n\u2229nj=0 Eijj \u2229 {\u03c4j = tjkj }\nj j 0\u2264j\u2264n\nn+1\nkn+1\n\nDenote by I the family of all finite sequence of indexes I := (ij , kj )0\u2264j\u2264n for some n such\nthat 0 = t0k0 < * * * < tnkn < \u221e. Then I is countable. For each I \u2208 I, denote by |I| the\ncorresponding n, and define\nh\ni\u0011 \\\n\u0010\n\u0001\n|I|\n{\u03c4|I|+1 > \u03c4 } \u222a {\u03c4|I|+1 = \u03c4 = \u221e} ,\nEI :=\n\u2229j=0 Eijj \u2229 {\u03c4j = tjkj \u2264 \u03c4 }\n\u03c4\u0303\n\n:=\n\nX\nI\u2208I\n\n\u03c4|I|+1 1EI , and aI :=\n\n|I|\u22121\n\nX\nj=0\n\najij 1[tj\n\nj+1\nkj ,tkj+1 )\n\n|I|\n\n+ ai|I| 1[t|I|\n\nk|I| ,\u221e)\n\n.\n\nIt is clear that EI is F\u03c4 \u2212measurable. Then, in view of the concatenation property of A0 ,\naI \u2208 A0 . In light of (9.2), we see that {EI , I \u2208 I} are disjoint. Moreover, since \u03c4n = \u221e for\n38\n\n\fn large enough, we know {EI , I \u2208 I} form a partition of \u03a9. Then \u03c4\u0303 is an F\u2212stopping time\nand either \u03c4\u0303 > \u03c4 or \u03c4\u0303 = \u03c4 = \u221e. We now show that\nat =\n\nX\n\naI (t)1EI\n\nfor all t < \u03c4\u0303 .\n\n(9.3)\n\nI\u2208I\n\nIn fact, for each I = (ij , kj )0\u2264j\u2264n \u2208 I, \u03c9 \u2208 EI , and t < \u03c4\u0303 (\u03c9), we have \u03c4j (\u03c9) = tjkj \u2264 \u03c4 (\u03c9)\nfor j \u2264 n and \u03c4n+1 (\u03c9) = \u03c4\u0303 (\u03c9) > t. Let j0 = j0 (t, \u03c9) \u2264 n be such that \u03c4j0 (\u03c9) \u2264 t < \u03c4j0 +1 (\u03c9).\nThen 1[\u03c4j0 (\u03c9),\u03c4j0 +1 (\u03c9)) (t) = 1 and 1[\u03c4j (\u03c9),\u03c4j+1 (\u03c9)) (t) = 0 for j 6= j0 , and thus\nat (\u03c9) =\n\n\u221e\n\u221e X\nX\nj=0 i=1\n\naji (t, \u03c9)1E j (\u03c9)1[\u03c4j (\u03c9),\u03c4j+1 (\u03c9)) (t)\ni\n\n=\n\n\u221e\nX\ni=1\n\naji 0 (t, \u03c9)1E j0 (\u03c9) = ajij0 (t, \u03c9),\ni\n\n0\n\nwhere the last equality is due to the fact that \u03c9 \u2208 EI \u2282 Eijj0 and that {Eij0 , i \u2265 1} is a\n0\npartition of \u03a9. On the other hand, by the definition of aI , it is also straightforward to check\nthat aI (t, \u03c9) = ajij0 (t, \u03c9). This proves (9.3). Now since I is countable, by numerating the\n0\nelements of I we prove the lemma.\nFinally, we should point out that, if \u03c4 = \u03c4n , then we can choose \u03c4\u0303 = \u03c4n+1 .\n\u2737\n\nReferences\n[1] Barlow, M.T. (1982) One-dimensional stochastic differential equation with no strong\nsolution, Journal of the London Mathematical Society, 26 (2), 335-347.\n[2] Carr, P. and Lee, R. (2010), Hedging Variance Options on Continuous Semimartingales,\nFinance and Stochastics, 14 (2), 179207.\n[3] Cheridito, P., Soner, H.M. and Touzi, N., Victoir, N. (2007) Second order BSDE's\nand fully nonlinear PDE's, Communications in Pure and Applied Mathematics, 60 (7),\n1081-1110.\n[4] Dellacherie, C. and Meyer P-A. (1980), Probabilit\u00e9s et potentiel, Chapters V-VIII, Hermann.\n[5] Denis, L. and Martini, C. (2006) A Theorectical Framework for the Pricing of Contingent\nClaims in the Presence of Model Uncertainty, Annals of Applied Probability 16 (2), 827852.\n[6] Denis, L., Hu, M. and Peng, S. (2011) Function Spaces and Capacity Related to a\nSublinear Expectation: Application to G-Brownian Motion Paths, Potential Analysis,\n34 (2), 139-161.\n\n39\n\n\f[7] El Karoui, N. and Quenez, M.-C. (1995) Dynamic programming and pricing of contingent\nclaims in an incomplete markets. SIAM J. Control. Optim., 33 (1), 29\u201366.\n[8] Fernholz, D. and Karatzas, I. (2011) Optimal Arbitrage under Model Uncertainty, Annals\nof Applied Probability, to appear.\n[9] Fleming, W.H. and Soner, H.M., Controlled Markov processes and viscosity solutions.\nApplications of Mathematics (New York), 25. Springer-Verlag, New York, 1993.\n[10] Karandikar, R. (1995) On pathwise stochastic integration, Stochastic Processes and\nTheir Applications, 57, 11-18.\n[11] Karatzas, I. and Shreve, S. (1991) Brownian Motion and Stochastic Calculus, 2nd\nEdition, Springer.\n[12] Neveu, J. (1975) Discrete Parameter Martingales. North Holland Publishing Company.\n[13] Peng, S. (2007) G-Brownian motion and dynamic risk measure under volatility uncertainty, arXiv:0711.2834v1.\n[14] Soner, H. M. and Touzi, N. (2002) Dynamic programming for stochastic target problems\nand geometric flows, Journal of European Mathematical Society, 4/3, 201236.\n[15] Soner, H. M. Touzi, N. and Zhang, J. (2011) Martingale representation theorem for\nG\u2212expectation, Stochastic Processes and their Applications, 121, 265-287.\n[16] Soner, H. M. Touzi, N. and Zhang, J. (2009) Dual Formulation of Second Order Target\nProblems, arXiv:1003.6050.\n[17] Soner, H. M. Touzi, N. and Zhang, J. (2011) Wellposedness of second order backward\nSDEs, Probability Theory and Related Fields, to appear.\n[18] Stroock, D.W. and Varadhan, S.R.S. (1979), Multidimensional Diffusion Processes,\nSpringer-Verlag, Berlin, Heidelberg, New York.\n\n40\n\n\f"}