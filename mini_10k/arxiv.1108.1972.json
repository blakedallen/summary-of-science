{"id": "http://arxiv.org/abs/1108.1972v1", "guidislink": true, "updated": "2011-08-09T16:32:20Z", "updated_parsed": [2011, 8, 9, 16, 32, 20, 1, 221, 0], "published": "2011-08-09T16:32:20Z", "published_parsed": [2011, 8, 9, 16, 32, 20, 1, 221, 0], "title": "Extremal dependence: some contributions", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.3314%2C1108.5435%2C1108.3271%2C1108.2704%2C1108.6317%2C1108.0720%2C1108.2160%2C1108.4956%2C1108.0735%2C1108.6153%2C1108.5716%2C1108.2923%2C1108.1972%2C1108.3610%2C1108.3258%2C1108.6225%2C1108.2183%2C1108.5519%2C1108.1420%2C1108.1474%2C1108.1968%2C1108.3361%2C1108.1628%2C1108.0243%2C1108.2943%2C1108.1590%2C1108.2760%2C1108.3935%2C1108.6277%2C1108.2167%2C1108.1949%2C1108.1910%2C1108.5524%2C1108.4755%2C1108.4519%2C1108.2896%2C1108.1810%2C1108.3702%2C1108.3726%2C1108.0853%2C1108.3663%2C1108.1722%2C1108.6130%2C1108.2543%2C1108.5399%2C1108.3121%2C1108.2173%2C1108.6241%2C1108.3282%2C1108.1421%2C1108.5168%2C1108.0219%2C1108.3090%2C1108.5663%2C1108.4535%2C1108.2221%2C1108.3773%2C1108.6312%2C1108.5887%2C1108.4987%2C1108.0974%2C1108.0097%2C1108.1051%2C1108.3434%2C1108.5981%2C1108.3023%2C1108.3068%2C1108.0038%2C1108.4214%2C1108.2148%2C1108.1061%2C1108.4319%2C1108.4101%2C1108.2925%2C1108.2607%2C1108.0194%2C1108.0279%2C1108.3047%2C1108.2218%2C1108.5548%2C1108.4102%2C1108.3230%2C1108.2934%2C1108.6021%2C1108.4866%2C1108.4072%2C1108.0504%2C1108.0895%2C1108.3344%2C1108.2040%2C1108.6246%2C1108.5824%2C1108.1124%2C1108.5357%2C1108.2675%2C1108.0762%2C1108.1745%2C1108.1764%2C1108.1853%2C1108.1560%2C1108.2063&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Extremal dependence: some contributions"}, "summary": "Due to globalization and relaxed market regulation, we have assisted to an\nincreasing of extremal dependence in international markets. As a consequence,\nseveral measures of tail dependence have been stated in literature in recent\nyears, based on multivariate extreme-value theory. In this paper we present a\ntail dependence function and an extremal coefficient of dependence between two\nrandom vectors that extend existing ones. We shall see that in weakening the\nusual required dependence allows to assess the amount of dependence in\n$d$-variate random vectors based on bidimensional techniques. Very simple\nestimators will be stated and can be applied to the well-known \\emph{stable\ntail dependence function}. Asymptotic normality and strong consistency will be\nderived too. An application to financial markets will be presented at the end.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.3314%2C1108.5435%2C1108.3271%2C1108.2704%2C1108.6317%2C1108.0720%2C1108.2160%2C1108.4956%2C1108.0735%2C1108.6153%2C1108.5716%2C1108.2923%2C1108.1972%2C1108.3610%2C1108.3258%2C1108.6225%2C1108.2183%2C1108.5519%2C1108.1420%2C1108.1474%2C1108.1968%2C1108.3361%2C1108.1628%2C1108.0243%2C1108.2943%2C1108.1590%2C1108.2760%2C1108.3935%2C1108.6277%2C1108.2167%2C1108.1949%2C1108.1910%2C1108.5524%2C1108.4755%2C1108.4519%2C1108.2896%2C1108.1810%2C1108.3702%2C1108.3726%2C1108.0853%2C1108.3663%2C1108.1722%2C1108.6130%2C1108.2543%2C1108.5399%2C1108.3121%2C1108.2173%2C1108.6241%2C1108.3282%2C1108.1421%2C1108.5168%2C1108.0219%2C1108.3090%2C1108.5663%2C1108.4535%2C1108.2221%2C1108.3773%2C1108.6312%2C1108.5887%2C1108.4987%2C1108.0974%2C1108.0097%2C1108.1051%2C1108.3434%2C1108.5981%2C1108.3023%2C1108.3068%2C1108.0038%2C1108.4214%2C1108.2148%2C1108.1061%2C1108.4319%2C1108.4101%2C1108.2925%2C1108.2607%2C1108.0194%2C1108.0279%2C1108.3047%2C1108.2218%2C1108.5548%2C1108.4102%2C1108.3230%2C1108.2934%2C1108.6021%2C1108.4866%2C1108.4072%2C1108.0504%2C1108.0895%2C1108.3344%2C1108.2040%2C1108.6246%2C1108.5824%2C1108.1124%2C1108.5357%2C1108.2675%2C1108.0762%2C1108.1745%2C1108.1764%2C1108.1853%2C1108.1560%2C1108.2063&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Due to globalization and relaxed market regulation, we have assisted to an\nincreasing of extremal dependence in international markets. As a consequence,\nseveral measures of tail dependence have been stated in literature in recent\nyears, based on multivariate extreme-value theory. In this paper we present a\ntail dependence function and an extremal coefficient of dependence between two\nrandom vectors that extend existing ones. We shall see that in weakening the\nusual required dependence allows to assess the amount of dependence in\n$d$-variate random vectors based on bidimensional techniques. Very simple\nestimators will be stated and can be applied to the well-known \\emph{stable\ntail dependence function}. Asymptotic normality and strong consistency will be\nderived too. An application to financial markets will be presented at the end."}, "authors": ["Helena Ferreira", "Marta Ferreira"], "author_detail": {"name": "Marta Ferreira"}, "author": "Marta Ferreira", "links": [{"href": "http://arxiv.org/abs/1108.1972v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.1972v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.AP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60G70", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.1972v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.1972v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "1\n\nExtremal dependence: some contributions\nHelena Ferreira Department of Mathematics, University of Beira Interior, Covilh\u00e3, Portugal\n\narXiv:1108.1972v1 [math.ST] 9 Aug 2011\n\nMarta Ferreira Department of Mathematics, University of Minho, Braga, Portugal\nAbstract: Due to globalization and relaxed market regulation, we have assisted to an increasing of extremal dependence in international markets. As a consequence, several measures of tail dependence have\nbeen stated in literature in recent years, based on multivariate extreme-value theory. In this paper we\npresent a tail dependence function and an extremal coefficient of dependence between two random vectors\nthat extend existing ones. We shall see that in weakening the usual required dependence allows to assess\nthe amount of dependence in d-variate random vectors based on bidimensional techniques. Very simple\nestimators will be stated and can be applied to the well-known stable tail dependence function. Asymptotic\nnormality and strong consistency will be derived too. An application to financial markets will be presented\nat the end.\nKeywords: multivariate extreme value theory, tail dependence, extremal coefficients\n\n1\n\nIntroduction\n\nDependence between extremal events have increased in recent time periods in financial markets,\nespecially during bear markets and market crashes. The globalization and the lack of supervision\nare well-known contributions for this phenomena. Therefore, modern risk management is highly\ninterested in assessing the amount of extremal dependence. The concept of tail dependence is the\ncurrent tool used to this end, although it was first introduced far back in the sixties (Sibuya [25],\n1960; Tiago de Oliveira [26], 1962/63). Tail dependence coefficients measure the probability of\noccurring extreme values for one random variable (r.v.) given that another assumes an extreme\nvalue too. These coefficients can be defined via copulas of random vectors which refers to their\ndependence structure concerning extreme events independently of their marginal distributions.\nThe tail dependence coefficient,\n\u03bb = lim P (FX (X) > 1 \u2212 t|FY (Y ) > 1 \u2212 t),\nt\u21930\n\n(1)\n\nwhere FX and FY are the distribution functions (d.f.'s) of X and Y , respectively, is perhaps the\nmost referred in literature and characterizes the dependence in the tail of a random pair (X, Y ),\ni.e., \u03bb > 0 corresponds to tail dependence and \u03bb = 0 means tail independence. There are several\nreferences on this topic (besides the two above) and thus we point out only some of them: Ledford\nand Tawn ([12, 13], 1996, 1997), Joe ([10], 1997), Coles et al. ([2], 1999), Embrechts et al. ([5],\n2003).\nMultivariate formulations for tail dependence coefficients can be used to describe the amount\nof dependence in the orthant tail of a multivariate distribution (Marshall-Olkin [17] 1967; Wolff\n[27] 1980; Nelsen [18] 1996; Schmid and Schmidt [21] 2007; Li [14, 15, 16] 2006, 2008, 2009, among\nothers). These have been increasingly used in the most recent and higher demanding times. Most\nof the multivariate measures consider that extremal events must occur to all the components of the\nrandom vector, and obviously they are more complicated to deal with and to understand than in\nthe bivariate case. Not surprisingly, applications hardly go any further than the three-dimensional\ncase.\nBut maybe this is a too demanding condition and the occurrence of at least one extremal event\nin sub-vectors of a random vector can be enough to assess dependence. As already mentioned,\n\n\f2\nfinancial markets are increasingly connected and the occurrence of at least one market crash, for\ninstance, in Europe, will certainly influence a negative behavior in USA markets.\nBased on this, we define a new tail dependence function for a random vector as a measure of\nthe probability of occurring extreme values for the maximum of one sub-vector given that the maximum of another assumes an extreme value too. At the unit point, this function gives rise to the\nhere called extremal coefficient of dependence as it relates to the well-known extremal coefficient\n(Tiago de Oliveira 1962-63, Smith 1990). These extend, respectively, the concept of upper tail\ndependence function and upper tail dependence coefficient already stated in literature (see Schmidt\nand Stadtm\u00fcller (2006) and references therein). In deriving the moments of the random variables\ninvolved in this approach, we find very simple estimators that can be also applied to the well-known\nstable tail dependence function (for a survey on this function see e.g. Beirlant et al. [1], 2004).\nAsymptotic normality and strong consistency are proved.\nThis paper is organized as follows. In Section 2 we define our new upper-tail dependence function\nand the extremal coefficient of dependence. We present some properties and examples. We also\nanalyze the case of asymptotic independence. In Section 3 we present estimators and derive the\nrespective properties of asymptotic normality and strong consistency. Section 4 illustrates our\napproach through an application to financial data.\n\n2\n\nExtremal dependence between two random vectors\n\nLet X = (X1 , ..., Xd ) be a random\nvector with d.f. F and continuous marginal d.f.'s Fi . For\nW\nI \u2282 {1, ..., d}, define M (I) = i\u2208I Fi (Xi ) and XI the sub-vector of X having r.v.'s with indexes\nin I. Consider CF the copula function of F , i.e.,\nF (x1 , ..., xd ) = CF (F1 (x1 ), ..., Fd (xd )), (x1 , ..., xd ) \u2208 Rd .\n\n(2)\n\nWe are going to study the dependence between extremal events concerning two sub-vectors,\nXI1 and XI2 , where I1 and I2 are disjoint subsets of {1, ..., d}.\nWe start by extending in Definition 2.2 the concept of upper tail dependence function (see\nSchmidt and Stadtm\u00fcller (2006) and references therein) and from this we define a new tail dependence coefficient between two random vectors.\nDefinition 2.1. Let I1 and I2 be two non-empty subsets of {1, ..., d}.\nfunction of XI1 given XI2 is defined as, for (x, y) \u2208 (0, \u221e)2 ,\n\u0010\nx\n(I |I )\n\u039bU 1 2 (x, y) = lim P M (I1 ) > 1 \u2212 M (I2 ) > 1 \u2212\nt\u2192\u221e\nt\n\nThe upper-tail dependence\ny\u0011\n,\nt\n\n(3)\n\n\u0010\n1\n1\u0011\n(1, 1) = lim P M (I1 ) > 1 \u2212 M (I2 ) > 1 \u2212\n,\nt\u2192\u221e\nt\nt\n\n(4)\n\nprovided the limit exists.\n\nBy taking x = y = 1, we have\n(I |I2 )\n\n\u039bU 1\n\nwhich is a tail dependence coefficient greater than the one considered in Li and Sun (2008),\n\u03b3 = lim P\nt\u2192\u221e\n\n\u0010\\\n\ni\u2208I1\n\nFi (Xi ) > 1 \u2212\n\n1\u0011\n1 [\n,\nFi (Xi ) > 1 \u2212\nt\nt\n\n(5)\n\ni\u2208I2\n\nwhich in turn is greater than the coefficient of Li (2009) for I1 = {1, ..., d} \u2212 I2 ,\n\u03c4 = lim P\nt\u2192\u221e\n\n\u0010\\\n\ni\u2208I1\n\nFi (Xi ) > 1 \u2212\n\n1\u0011\n1 \\\n.\nFi (Xi ) > 1 \u2212\nt\nt\ni\u2208I2\n\n(6)\n\n\f3\n(I |I )\n\nThe tail dependence coefficient \u039bU 1 2 (1, 1) give us information about the probability of occurring some extreme value in {Fi (Xi ), i \u2208 I1 } given that some extreme value occurs in {Fi (Xi ), i \u2208\nI2 }.\n(I |I )\n\nBefore presenting the properties of function \u039bU 1 2 (x, y) that will be the basis for the definition\nof our coefficient, consider the following notation:\nfor (x, y) \u2208 (0, \u221e)2 , \u2205 \u2286 I1 , I2 \u2286 {1, ..., d} and i \u2208 {1, ..., d}, let\n(I1 ,I2 )\n\nai\n\n(x, y) = x1I1 (i) + y1I2 (i) + \u221e1I1 \u222aI2 (i),\n\n(7)\n\nwhere 1(*) is the indicator function, and\n(I ,I2 )\n\nl(I1 ,I2 ) (x, y) = \u2212 log F (a1 1\n\n(I ,I2 )\n\n(x, y), ..., ad 1\n\n(8)\n\n(x, y)),\n\nwith the convention that, when some of the arguments of F are \u221e we understand the limit of F\nas those arguments tend to \u221e.\nIf F is a multivariate extreme value distribution (MEV) with unit Fr\u00e9chet marginals, we have\nl(I1 ,I2 ) (x\u22121 , x\u22121 ) = \u2212 log(exp(\u2212x))\u01ebI1 \u222aI2 = x\u01ebI1 \u222aI2 ,\n\n(9)\n\nwhere \u01ebI1 \u222aI2 is the extremal coefficient of XI1 \u222aI2 (Tiago de Oliveira 1962-63, Smith 1990).\n(I |I2 )\n\nProposition 2.1. If F is a MEV distribution with unit Fr\u00e9chet marginals, then function \u039bU 1\nis defined and verifies\n(I |I2 )\n\n\u039bU 1\n\n(x, y) = 1 +\n\nx\u01ebI1\nl(I1 ,I2 ) (x\u22121 , y \u22121 )\n\u2212\n,\ny\u01ebI2\ny\u01ebI2\n\n(x, y)\n\n(10)\n\nDem. We have\n(I |I )\n\u039bU 1 2 (x, y)\n\n\u0001\n\u0001\n1 \u2212 P M (I1 ) \u2264 1 \u2212 xt , M (I2 ) \u2264 1 \u2212 yt\n1 \u2212 P M (I1 ) \u2264 1 \u2212 xt\n\u0001\u2212\n\u0001\n. (11)\n= lim 1 +\nt\u2192\u221e\n1 \u2212 P M (I2 ) \u2264 1 \u2212 yt\n1 \u2212 P M (I2 ) \u2264 1 \u2212 yt\n(I1 ,I2 )\n\nOn the other hand, for \u03b1i\n\n(u, v) = u1I1 (i) + v1I2 (i) + 1I1 \u222aI2 (i), it holds\n\nlim \u2212 t log P M (I1 ) \u2264 1 \u2212 xt , M (I2 ) \u2264 1 \u2212\n\nt\u2192\u221e\n\n=\n=\n=\n=\n=\n\ny\nt\n\n\u0001\n\n\u0010\n\u0001\n\u0001\u0011\n(I ,I )\n(I ,I )\nlim \u2212 t log CF \u03b11 1 2 1 \u2212 xt , 1 \u2212 yt , ..., \u03b1d 1 2 1 \u2212 xt , 1 \u2212 yt\n\nt\u2192\u221e\n\n\u0010\n\u0001t\n\u0001t \u0001\n\u0001t\n\u0001t \u0001\u0011\n(I ,I )\n(I ,I )\nlim \u2212 log CF \u03b11 1 2 1 \u2212 xt , 1 \u2212 yt , ..., \u03b1d 1 2 1 \u2212 xt , 1 \u2212 yt\n\nt\u2192\u221e\n\n\u0010\n\u0001\n\u0001\u0011\n(I ,I )\n(I ,I )\n\u2212 log CF \u03b11 1 2 exp(\u2212x), exp(\u2212y) , ..., \u03b1d 1 2 exp(\u2212x), exp(\u2212y)\n\n(12)\n\n\u0010\n\u0001\n\u0001\u0011\n(I ,I )\n(I ,I )\n\u2212 log F a1 1 2 x\u22121 , y \u22121 , ..., ad 1 2 x\u22121 , y \u22121\n\n\u0001\nl(I1 ,I2 ) x\u22121 , y \u22121 .\n\nTherefore, dividing the numerator and denominator of the fractions in (11) by t, we obtain\n(I |I2 )\n\n\u039bU 1\n\n(x, y) = 1 +\n\nl(I1 ,\u2205) (x\u22121 , x\u22121 ) l(I1 ,I2 ) (x\u22121 , y \u22121 )\n\u2212 (\u2205,I ) \u22121 \u22121\nl(\u2205,I2 ) (y \u22121 , y \u22121 )\nl 2 (y , y )\n\nl(I1 ,I2 ) (x\u22121 , y \u22121 )\n\u2212 log(exp(\u2212x))\u01ebI1\n\u2212\n.\u0003\n= 1+\n\u01eb\nI2\n\u2212 log(exp(\u2212y))\n\u2212 log(exp(\u2212y))\u01ebI2\n\n(13)\n\n\f4\nTherefore, under the conditions of Proposition 2.1, we have\n(I |I2 )\n\ny\u01ebI2 \u039bU 1\n\n(I |I1 )\n\n(x, y) = x\u01ebI1 \u039bU 2\n\n(y, x) = x\u01ebI1 + y\u01ebI2 \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )\n\n(I ,I2 )\n\nand we will denote this common value as \u039bU 1\n\n(x, y).\n\nDefinition 2.2. The upper-tail dependence function for random vector (XI1 , XI2 ) with d.f. MEV\nand unit Fr\u00e9chet marginals is defined as\n(I ,I2 )\n\n\u039bU 1\n\n(x, y) = x\u01ebI1 + y\u01ebI2 \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )\n\n(14)\n(I ,I2 )\n\nand the extremal coefficient of dependence between XI1 and XI2 is given by \u039bU 1\ndenote \u01eb(I1 ,I2 ) and hence\n\n(1, 1), which we\n\n\u01eb(I1 ,I2 ) = \u01ebI1 + \u01ebI2 \u2212 \u01ebI1 \u222aI2 .\n\n(15)\n\nThe upper-tail dependence function (14) generalizes the relation of Huang (1992) corresponding\nto I1 = {1} and I2 = {2},\nH\n\u039bU (x, y) = x + y \u2212 l(F\n(x, y),\n1 (X1 ),F2 (X2 ))\n\n(16)\n\nwhere the stable tail dependence function in the right-side is given by\n\u0010\ny\u0011\nx\nH\n\u2228\nF\n(X\n)\n>\n1\n\u2212\n.\nl(F\n(x,\ny)\n=\nlim\ntP\nF\n(X\n)\n>\n1\n\u2212\n2\n2\n1\n1\n(X\n),F\n(X\n))\n1\n1\n2\n2\nt\u2192\u221e\nt\nt\n\n(17)\n\nObserve that by (11) we also obtain\n\u0010\ny\u0011\nx\nH\n(x, y).\n= l(M(I\nl(I1 ,I2 ) (x\u22121 , y \u22121 ) = lim tP M (I1 ) > 1 \u2212 \u2228 M (I2 ) > 1 \u2212\n1 ),M(I2 ))\nt\u2192\u221e\nt\nt\n\n(18)\n\nMoreover, the upper-tail dependence function in (14) can be can be viewed as an extension of the\nbivariate upper-tail dependence function of Schmidt and Stadtm\u00fcller ([22], 2006), defined as\n\u0010\nx\ny\u0011\n\u039bS(F1 (X1 ),F2 (X2 )) (x, y) = lim tP F1 (X1 ) > 1 \u2212 , F2 (X2 ) > 1 \u2212\n,\n(19)\nt\u2192\u221e\nt\nt\n\nby taking in this limit the random pair (M (I1 ), M (I2 )) instead of (F (X1 ), F (X2 )). At the unit\nvector, the Schmidt and Stadtm\u00fcller upper-tail dependence function corresponds to the tail dependence coefficient \u03bb in (1), i.e., \u03bb = \u039bS(F1 (X1 ),F2 (X2 )) (1, 1).\n(I ,I )\n\nIn the following, we present the expression of the tail-dependence function \u039bU 1 2 (x, y) and\nthe value of the corresponding extremal coefficient \u01eb(I1 ,I2 ) for a d-variate random vector X with\nwell-known distribution functions for its margins.\nExample\n2.1. Consider vector X with unit Fr\u00e9chet margins and copula function CX (u1 , ..., ud ) =\nQ\n\u221e Q\u221e\n\u03b1lk1\nlkd\n\u2227 ... \u2227 u\u03b1\n, where uj \u2208 [0, 1], j = 1,P\n..., d, P\nand {\u03b1lkj , \u2212\u221e < k < \u221e, 1 \u2264 j \u2264\nl=1\nk=\u2212\u221e u1\nd\n\u221e\n\u221e\nd, l \u2265 1} is a family of non negative constants such that l=1 k=\u2212\u221e \u03b1lkj = 1, j = 1, ..., d. The\ndistribution of X is the MEV marginal distribution of multivariate maxima of moving maxima\nprocesses considered in Smith and Weissman ([24], 1996). We have\n\u221e X\n\u221e\nd\n\u0011 X\n\u0010\n_\n\u22121\n\u22121\na\u22121\nl(I1 ,I2 ) (x, y) = \u2212 log C e\u2212a1 (x,y) , ..., e\u2212ad (x,y) =\nj (x, y)\u03b1lkj .\nl=1 k=\u2212\u221e j=1\n\nTherefore,\n(I ,I2 )\n\n\u039bU 1\n=\n\nx\n\n(x, y) = l(I1 ,\u2205) (x\u22121 , x\u22121 ) + l(\u2205,I2 ) (y \u22121 , y \u22121 ) \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )\n\n\u221e X\n\u221e\nX\n_\n\nl=1 k=\u2212\u221e j\u2208I1\n\n\u03b1lkj + y\n\n\u221e X\n\u221e\nX\n_\n\nl=1 k=\u2212\u221e j\u2208I2\n\n\u03b1lkj \u2212\n\n\u221e X\n\u221e \u0012\u0010 _\n\u0011\u0013\n\u0011 \u0010 _\nX\n\u03b1lkj\nx\n\u03b1lkj \u2228 y\nl=1 k=\u2212\u221e\n\nj\u2208I1\n\nj\u2208I2\n\n\f5\nand\n\u01eb(I1 ,I2 ) (x, y) =\n\n\u221e X\n\u221e\nX\n_\n\n\u03b1lkj +\n\nl=1 k=\u2212\u221e j\u2208I1\n\nIllustrating with\n\n1/8\n\n1/8\n\n\u221e X\n\u221e\nX\n_\n\nl=1 k=\u2212\u221e j\u2208I2\n\n1/8\n\n1/8\n\n5/8\n\n4/8\n\n\u03b1lkj \u2212\n\n7/8\n\n\u221e X\n\u221e\nX\n\n_\n\n\u03b1lkj\n\nl=1 k=\u2212\u221e j\u2208I1 \u222aI2\n\n1/8\n\n1/8\n\n2/8\n\n1/8\n\n1/8\n\n6/8\n\nCX (u1 , u2 , u3 , u4 ) = (u1 \u2227u2 \u2227u3 \u2227u4 ).(u1 \u2227u2 \u2227u3 \u2227u4 ).(u1 \u2227u2 ).(u1 \u2227u2 \u2227u4 ),\nI1 = {1, 2} and I2 = {3, 4}, we obtain\n\u0011\n\u0010\n\u0010\n(I ,I )\n5\n2\n1\n1\n1\n\u039bU 1 2 (x, y) =\n8 + 8 + 8 + 8 x+ 8 +\n9\n8x\n\n=\n\n+\n\n14\n8 y\n\n\u2212\n\nand\n\n\u0010\n\n7\n8\n\n+\n\n6\n8\n\n\u0011\n\n\u0010\n\ny\u2212\n\n\u0001\n\u0001\n\u0001\n\u0001\u0011\nx 81 \u2228 y 18 + x 85 \u2228 y 87 + x 28 + x 81 \u2228 y 86\n\n\u0001\n\u0001\n\u0001\u0011\nx 81 \u2228 y 81 + x 58 \u2228 y 87 + x 28 + x 81 \u2228 y 86\n\n\u01eb(I1 ,I2 ) =\n\n9\n8\n\n14\n8\n\n+\n\n1\n8\n\n\u2212\n\n+\n\n7\n8\n\n2\n8\n\n+\n\n+\n\n6\n8\n\n\u0001\n\n7\n8\n\n=\n\nSimilarly, if I1 = {1, 2} and I2 = {4} we obtain\n\u0010\n\u0001\n\u0001\n\u0001\u0011\n(I ,I )\n\u039bU 1 2 (x, y) = 89 x + y \u2212 x 18 \u2228 y 81 + x 58 \u2228 y 81 + x 28 + x 18 \u2228 y 86\n\nand\n\n\u01eb(I1 ,I2 ) =\n\n9\n8\n\n+1\u2212\n\n1\n8\n\n+\n\n5\n8\n\n+\n\n2\n8\n\n+\n\n6\n8\n\nExample 2.2. For the symmetric logistic model we have\n(I ,I2 )\n\nl(I1 ,I2 ) (x, y) = \u2212 log F (a1 1\n\n(I ,I2 )\n\n(x, y), ..., ad 1\n\n\u0001\n\n(x, y)) =\n\n= 38 .\nd\n\u0010X\n\n(I1 ,I2 )\n\n(aj\n\n(x, y))\u22121/\u03b8\n\nj=1\n\n\u0011\u03b8\n\nwith \u03b8 \u2208 (0, 1], x, y > 0. Therefore,\n(I ,I2 )\n\n\u039bU 1\n\n(x, y) = l(I1 ,\u2205) (x\u22121 , x\u22121 ) + l(\u2205,I2 ) (y \u22121 , y \u22121 ) \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )\n=\n\n\u0010X\n\nx1/\u03b8\n\nj\u2208I1\n\n\u0011\u03b8\n\n+\n\n\u0010X\n\ny 1/\u03b8\n\nj\u2208I2\n\n\u0011\u03b8\n\n\u2212\n\n\u0010X\n\nj\u2208I1\n\n= |I1 |\u03b8 x + |I2 |\u03b8 y \u2212 |I1 |x1/\u03b8 + |I2 |y\nand\n\nx1/\u03b8 +\n\n\u0001\n1/\u03b8 \u03b8\n\nX\n\ny 1/\u03b8\n\nj\u2208I2\n\n\u0011\u03b8\n\n\u0001\u03b8\n\u01eb(I1 ,I2 ) = |I1 |\u03b8 + |I2 |\u03b8 \u2212 |I1 | + |I2 | .\n\nProposition 2.2. Under the conditions of Proposition 2.1 we have\n(I ,I2 )\n\n(i) 0 \u2264 \u039bU 1\n\n(x, y) \u2264 x\u01ebI1 \u2227 y\u01ebI2\n\n(ii) 0 \u2264 \u01eb(I1 ,I2 ) \u2264 \u01ebI1 \u2227 \u01ebI2 .\nDem.\n(I ,I )\n\n(i) The left inequality is straightforward by the definition of \u039bU 1 2 (x, y) in (14). Observe also\nthat, since X has MEV distribution, it is associated (in the sense of Joe [10], 1997; Theorem\n6.7) and hence, for all I1 , I2 \u2282 {1, ..., d},\n(I ,I2 )\n\nF (a1 1\n\u2265\n\n(I ,\u2205)\n\nF (a1 1\n\n(I ,I2 )\n\n(x\u22121 , y \u22121 ), ..., ad 1\n\n(I ,\u2205)\n\n(x\u22121 , x\u22121 ), ..., ad 1\n\n(x\u22121 , y \u22121 ))\n(\u2205,I2 )\n\n(x\u22121 , x\u22121 ))F (a1\n\n(\u2205,I2 )\n\n(y \u22121 , y \u22121 ), ..., ad\n\n(y \u22121 , y \u22121 )),\n\n\f6\nleading to the same conclusion, i.e.,\nl(I1 ,\u2205) (x\u22121 , x\u22121 ) + l(\u2205,I2 ) (y \u22121 , y \u22121 ) \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 ) \u2265 0.\nOn the other hand,\n(I ,I2 )\n\nF (a1 1\n\u2264\n\n(I ,\u2205)\n\nF (a1 1\n\n(I ,I2 )\n\n(x\u22121 , y \u22121 ), ..., ad 1\n\n(I ,\u2205)\n\n(x\u22121 , x\u22121 ), ..., ad 1\n\n(x\u22121 , y \u22121 ))\n(\u2205,I2 )\n\n(x\u22121 , x\u22121 )) \u2227 F (a1\n\n(\u2205,I2 )\n\n(y \u22121 , y \u22121 ), ..., ad\n\n(y \u22121 , y \u22121 ))\n\nand hence\nl(I1 ,\u2205) (x\u22121 , x\u22121 ) + l(\u2205,I2 ) (y \u22121 , y \u22121 ) \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )\n\u2264\n=\n\n\u0001\nl(I1 ,\u2205) (x\u22121 , x\u22121 ) + l(\u2205,I2 ) (y \u22121 , y \u22121 ) \u2212 l(I1 ,\u2205) (x\u22121 , x\u22121 ) \u2228 l(\u2205,I2 ) (y \u22121 , y \u22121 )\n\nx\u01ebI1 \u2227 y\u01ebI2 . \u0003\n\nThe result in (i) agrees with the one for the bivariate case. Observe that, from the proof above\nwe can also conclude that the boundary cases correspond to, respectively, independence and total\ndependence.\n(I ,I )\n\nRemark 2.1. With the conventions 1/0 := \u221e and 1/\u221e := 0, we can define \u039bU 1 2 (x, y) in\n(I ,I )\n(I ,I )\n(I ,I )\n(I ,I )\n[0, \u221e]2 \\{(\u221e, \u221e)} and found \u039bU 1 2 (0, y) = 0 = \u039bU 1 2 (x, 0), \u039bU 1 2 (\u221e, y) = y\u01ebI2 and \u039bU 1 2 (x, \u221e) =\nx\u01ebI1 .\nProposition 2.3. Under the conditions of Proposition 2.1 and Remark 2.1, for each y \u2265 0, the\n(I ,I )\npartial derivative \u2202\u039bU 1 2 /\u2202x exists for almost all x > 0, and\n0\u2264\n\n(I1 ,I2 )\n\u2202\n(x, y)\n\u2202x \u039bU\n\n\u2264 |I1 |.\n\n(I ,I2 )\n\nSimilarly, for each x \u2265 0, the partial derivative \u2202\u039bU 1\n0\u2264\n\n(I1 ,I2 )\n\u2202\n(x, y)\n\u2202y \u039bU\n\n(I ,I )\n\n/\u2202x exists for almost all y > 0, and\n\n\u2264 |I2 |.\n\n(I ,I2 )\n\nAlso, the functions x 7\u2192 \u2202\u039bU 1 2 (x, y)/\u2202y and y 7\u2192 \u2202\u039bU 1\ning almost everywhere on [0, \u221e).\n\n(x, y)/\u2202x are defined and non decreas-\n\n(I ,I )\n\nDem. The function \u039bU 1 2 (x, y) is 2-increasing since a bivariate d.f. is 2-increasing. By\n(I ,I )\nRemark 2.1 we conclude that \u039bU 1 2 (x, y) is grounded. Hence, applying Lemma 2.1.5. in Nelsen\n([19], 2006) we have, for (x, y), (x\u2217 , y \u2217 ) \u2208 [0, \u221e]2 \\{(\u221e, \u221e)},\n(I ,I2 )\n\n|\u039bU 1\n\u2264\n\n(I ,I2 )\n\n(x, y) \u2212 \u039bU 1\n\n(x\u2217 , y \u2217 )|\n\n\u0010\nlim t |P (M (I1 ) > 1 \u2212 xt ) \u2212 P (M (I1 ) > 1 \u2212\n\nt\u2192\u221e\n\nx\u2217\nt )|\n\n+ |P (M (I2 ) > 1 \u2212 yt ) \u2212 P (M (I2 ) > 1 \u2212\n\ny\u2217\nt )|\n\n\u2264 |I1 ||x \u2212 x\u2217 | + |I2 ||y \u2212 y \u2217 |.\n\nNow, the proof is straightforward from Theorem 3 in Schmidt and Stadtm\u00fcller ([22], 2006). \u0003\nRemark 2.1 and Propositions 2.2.(i) and 2.3 extend, respectively, Theorems 1.i), 2.i) and 3\nof Schmidt and Stadtm\u00fcller ([22], 2006). Moreover, given the above mentioned relation between\n(I ,I )\n\u039bU 1 2 (x, y) and the bivariate upper-tail dependence function \u039bS(F1 (X1 ),F2 (X2 )) (x, y) in (19), the\n\n\u0011\n\n\f7\nproperties ii)-v) of Theorems 1 and 2 of Schmidt and Stadtm\u00fcller ([22], 2006) are straightforward\n(I ,I )\nfor \u039bU 1 2 (x, y).\n\nWe now discuss the case of tail independence between M (I1 ) and M (I2 ) and hence extend our\ncontext beyond a MEV distribution.\nNotice that, in case of tail dependence between r.v.'s F1 (X1 ) and F2 (X2 ), the mapping\n\u0010\nx\ny\u0011\nt 7\u2192 P F1 (X1 ) > 1 \u2212 , F2 (X2 ) > 1 \u2212\nt\nt\n\n(20)\n\nis regularly varying of order \u22121 at \u221e, and so an homogeneity property holds for large t. However,\nif (F1 (X1 ), F2 (X2 )) is tail independent, this latter does not hold and an adjusted homogeneity\nproperty can be obtained by assuming that (20) is regularly varying of order \u22121/\u03b7 at \u221e, \u03b7 < 1\n(the case \u03b7 = 1 corresponds to tail dependence). Coefficient \u03b7 is the coefficient of tail dependence\nintroduced in Ledford and Tawn (1996, 1997).\nThus being, if we assume that (20) is regularly varying of order \u22121/\u03b7 at \u221e, i.e.,\n\u0001\nP F1 (X1 ) > 1 \u2212 x/t, F2 (X2 ) > 1 \u2212 y/t\n\u0001\nlim\n= c\u2217 (x, y)\n(21)\nt\u2192\u221e P F1 (X1 ) > 1 \u2212 1/t, F2 (X2 ) > 1 \u2212 1/t\nfor (x, y) \u2208 [0, \u221e)2 , where c\u2217 is homogeneous\u0001of order 1/\u03b7 for some \u03b7 \u2208 (0, 1] and c\u2217 (1, 1) = 1, then\nt 7\u2192 P F1 (X1 ) > 1 \u2212 1/t, F2 (X2 ) > 1 \u2212 1/t is regularly varying at \u221e with index \u22121/\u03b7 (choose\nx = y in (21)), and hence we can write\n\u0001\nP F1 (X1 ) > 1 \u2212 1/t, F2 (X2 ) > 1 \u2212 1/t = t\u22121/\u03b7 L(t)\n(22)\n\nwhere L is a slowly varying function at \u221e (i.e., L(tx)/L(t) \u2192 1, as t \u2192 \u221e, for any x >\u0001 0).\nObserve that \u03b7 dominates the speed of convergence of P F1 (X1 ) > 1 \u2212 1/t, F2 (X2 ) > 1 \u2212 1/t to\n0. If \u03b7 < 1 then F1 (X1 ) and F2 (X2 ) (and thus X1 and X2 ) are asymptotically independent (or tail\nindependent). In this case, the tail dependence coefficient \u03bb in (1) is null. Conversely, asymptotic\ndependence holds if \u03b7 = 1 and L(t) \u2192 a > 0, as t \u2192 \u221e, and we have \u03bb > 0. If \u03b7 = 1/2 we\nhave (almost) independence (perfect independence if L(t) = 1 and (21) holds with c\u2217 (x, y) = xy).\nThe cases \u03b7 \u2208 (0, 1/2) and \u03b7 \u2208 (1/2, 1) correspond to asymptotically negative independence and\nto asymptotically positive independence, respectively. Roughly speaking, coefficient \u03b7 governs a\nkind of a pre-asymptotic tail behavior that allows to better estimate the probability of extreme\nevents in case of tail independence. A bivariate extreme value distribution (BEV) allows only tail\ndependence (\u03b7 = 1) or independence (\u03b7 = 1/2), since\nP (F1 (X1 ) > 1 \u2212 1/t, F2 (X2 ) > 1 \u2212 1/t) \u223c (2 \u2212 l({1},{2}) (1, 1))/t + ((l({1},{2}) (1, 1))2 /2 \u2212 1)/t2\n\nas t \u2192 \u221e. For a discussion on this topic see, for instance, Ledford and Tawn ([12], 1996), Draisma\net al. ([3], 2004) and Drees and M\u00fcller ([4], 2008).\nNow assume that (21) holds for random pair (M (I1 ), M (I2 )), i.e.,\n\u0001\nP M (I1 ) > 1 \u2212 x/t, M (I2 ) > 1 \u2212 y/t\n\u0001 = c(I1 ,I2 ) (x, y)\nlim\nt\u2192\u221e P M (I1 ) > 1 \u2212 1/t, M (I2 ) > 1 \u2212 1/t\n\n(23)\n\nfor (x, y) \u2208 [0, \u221e)2 , where c(I1 ,I2 ) is homogeneous of order 1/\u03b7(I1 ,I2 ) for some \u03b7(I1 ,I2 ) \u2208 (0, 1] and\n\u0001\nc(I1 ,I2 ) (1, 1) = 1. Taking x = y in (23), one obtains that P M (I1 ) > 1 \u2212 1/t, M (I2 ) > 1 \u2212 1/t is\nregularly varying at \u221e, i.e.,\n\u0001\nP M (I1 ) > 1 \u2212 1/t, M (I2 ) > 1 \u2212 1/t = t\u22121/\u03b7(I1 ,I2 ) L(I1 ,I2 ) (t),\n(24)\n\n\f8\nwhere L(I1 ,I2 ) (t) is a slowly varying function at \u221e. Coefficient\n\u0001 \u03b7(I1 ,I2 ) is now a measure of the\nspeed of convergence of P M (I1 ) > 1 \u2212 1/t, M (I2 ) > 1 \u2212 1/t to 0 and is, therefore, a coefficient\nof tail dependence between M (I1 ) and M (I2 ), with analogous conclusions derived for \u03b7 above.\nSimilarly, in a MEV we obtain, as t \u2192 \u221e,\nP (M (I1 > 1 \u2212 1/t, M (I2 ) > 1 \u2212 1/t) \u223c (\u01ebI1 + \u01ebI2 \u2212 \u01ebI1 \u222aI2 )/t + (\u01eb2I1 \u222aI2 \u2212 \u01eb2I1 \u2212 \u01eb2I2 )/(2t2 ).\nHence it only occurs asymptotic dependence whenever \u01eb(I1 ,I2 ) = \u01ebI1 + \u01ebI2 \u2212 \u01ebI1 \u222aI2 > 0 (with\n\u03b7(I1 ,I2 ) = 1), and otherwise independence (\u03b7(I1 ,I2 ) = 1/2).\nIn the next result we compute \u03b7(I1 ,I2 ) and found that it is given by the maximum coefficient \u03b7{i},{j} ,\n\u2200i \u2208 I1 , j \u2208 I2 .\nProposition 2.4. Suppose that (24) holds and\n\u0010\n\u0011\nP\nmin (Fi (Xi ), Fj (Xj )) > 1 \u2212 1/t = t\u22121/\u03b7I,J L\u03b7I,J (t)\n\n(25)\n\ni\u2208I,j\u2208J\n\nholds for all \u2205 6= I \u2282 I1 and \u2205 6= J \u2282 I2 , where L\u03b7I,J is a slowly varying function at \u221e. Then\n\u03b7(I1 ,I2 ) = max{\u03b7{i},{j} : i \u2208 I1 , j \u2208 I2 }.\nDem. First observe that if I \u2032 \u2282 I and J \u2032 \u2282 J then\n1 \u2265 t\u22121/\u03b7I \u2032 ,J \u2032 L\u03b7I \u2032 ,J \u2032 (t) \u2265 t\u22121/\u03b7I,J L\u03b7I,J (t).\n\n(26)\n\nWe have that\nW\nW\nP ( i\u2208I1 Fi (Xi ) > 1 \u2212 1/t, j\u2208I2 Fj (Xj ) > 1 \u2212 1/t)\n\nS\nS\n= P ( i\u2208I1 {Fi (Xi ) > 1 \u2212 1/t, j\u2208I2 {Fj (Xj ) > 1 \u2212 1/t}})\n\n=\n=\n=\n\nP\n\nP\n\nP\n\nT\n\n|S|+1\nP(\n\u22056=S\u2286I1 (\u22121)\n\n\u22056=S\u2286I1\n\u22056=S\u2286I1\n\nP\n\nP\n\ni\u2208S {Fi (Xi )\n\nT\n\n|S|+|T |\nP(\n\u22056=T \u2286I2 (\u22121)\n\n> 1 \u2212 1/t},\n\ni\u2208S {Fi (Xi )\n\nS\n\nj\u2208I2 {Fj (Xj )\n\n> 1 \u2212 1/t},\n\n|S|+|T | \u22121/\u03b7S,T\nt\nL\u03b7S,T (t),\n\u22056=T \u2286I2 (\u22121)\n\nT\n\n> 1 \u2212 1/t})\n\nj\u2208T {Fj (Xj )\n\n(27)\n\n> 1 \u2212 1/t})\n\nwhere in the last equality we have applied (25). Let\n\u03b7=\n\nmax\n\n\u22056=S\u2286I1 \u22056=T \u2286I2\n\n\u03b7S,T\n\nFrom (27) and (28) we have that\nW\nW\nP ( i\u2208I1 Fi (Xi ) > 1 \u2212 1/t, j\u2208I2 Fj (Xj ) > 1 \u2212 1/t)\n= t\u22121/\u03b7 L\u03b7 (t)\n\nP\n\n\u22056=S\u2286I1\n\nP\n\n|S|+|T |\nAS,T (t)\n\u22056=T \u2286I2 (\u22121)\n\n(28)\n\n(29)\n\nwhere AS,T (t) = t\u2212(1/\u03b7S,T \u22121/\u03b7) L\u2217\u03b7S,T (t) and L\u2217\u03b7S,T (t) = L\u03b7S,T (t)/L\u03b7 (t) is a slowly varying function.\nObserve that, if S \u2032 \u2282 S and T \u2032 \u2282 T , then +\u221e > AS \u2032 ,T \u2032 (t) \u2265 AS,T (t) and, by the definition of \u03b7,\nwe have AS,T (t) = 1 or AS,T (t) \u2192 0 as t \u2192 \u221e, for all S \u2282 I1 and T \u2282 I2 . Therefore,\nP (M (I1 ) > 1 \u2212 1/t, M (I2 ) > 1 \u2212 1/t) \u223c t\u22121/\u03b7 L\u03b7 (t).\nMoreover, considering \u03b7 = \u03b7S0 ,T0 for some S0 \u2282 I1 , T0 \u2282 I2 , and so AS0 ,T0 (t) = 1 \u2264 A{i},{j} (t),\n\u2200 i \u2208 S0 , j \u2208 T0 , we must have A{i},{j} (t) = 1, \u2200 i \u2208 S0 , j \u2208 T0 . Then \u03b7 = \u03b7{i},{j} , \u2200 i \u2208 S0 , j \u2208 T0\nand \u03b7 \u2264 maxi\u2208I1 ,j\u2208I2 \u03b7{i},{j} . But, by (28), \u03b7 \u2265 maxi\u2208I1 ,j\u2208I2 \u03b7{i},{j} which leads to the result. \u0003\nIn the following we present some examples where tail independence takes place.\n\n\f9\nExample 2.3. Consider {Vn }n\u22651 an i.i.d. sequence of r.v.'s with distribution U(0, 1) and X =\n(X1 , X2 , X3 , X4 ) a random vector such that, X1 = min(V3 , V2 , V1 ), X2 = min(V4 , V2 , V1 ), X3 =\nmin(V4 , V3 , V1 ) and X4 = V5 . Observe that, for 0 \u2264 x \u2264 1, FX1 (x) = 1 \u2212 (1 \u2212 x)3 = FX2 (x) =\n\u22121\n\u22121\n\u22121\n\u22121\n(x) = 1 \u2212 (1 \u2212 x)1/3 = FX\nFX3 (x) and FX4 (x) = x and hence FX\n(x) = FX\n(x) and FX\n(x) = x.\n1\n2\n3\n4\nConsider I1 = {1, 2} and I2 = {3, 4}.\nWe have successively,\nP (F1 (X1 ) > 1 \u2212 t\u22121 , F3 (X3 ) > 1 \u2212 t\u22121 ) = P (F2 (X2 ) > 1 \u2212 t\u22121 , F3 (X3 ) > 1 \u2212 t\u22121 ) = t\u22124/3 ,\nand\nP (F1 (X1 ) > 1 \u2212 t\u22121 , F4 (X4 ) > 1 \u2212 t\u22121 ) = P (F2 (X2 ) > 1 \u2212 t\u22121 , F4 (X4 ) > 1 \u2212 t\u22121 ) = t\u22122 .\nHence, by Proposition 2.4, we must derive \u03b7({1,2},{3,4}) = 3/4.\nIn fact, applying (27), after some calculations we have\n\n=\n\nP (M (I1 ) > 1 \u2212 t\u22121 x, M (I2 ) > 1 \u2212 t\u22121 y)\n(\n2t\u22124/3 xy 1/3 + 2t\u22122 xy \u2212 t\u22124/3 x4/3 \u2212 2t\u22127/3 xy 4/3 \u2212 2t\u22127/3 x4/3 y\nt\n\n\u22124/3\n\n1/3\n\nyx\n\n+ 2t\n\n\u22122\n\nxy \u2212 3t\n\n\u22127/3 1/3 2\n\ny \u2212t\n\nx\n\n\u22127/3 4/3\n\nx\n\ny\n\n,x\u2264y\n\n, x > y.\n\nAccording to (24), coefficient \u03b7(I1 ,I2 ) can be obtained by taking x = y = 1 in the expression above,\nand by (23) we obtain\nc({1,2},{3,4}) (x, y) =\n\n(\n\n2xy 1/3 \u2212 x4/3\n1/3\n\nyx\n\n,x\u2264y\n\n, x > y.\n\nwhich is homogeneous of order 4/3.\nSimilarly, if we consider I1 = {1, 2, 3} and I2 = {4} we obtain \u03b7({1,2,3},{4}) = 1/2 and\nc({1,2,3},{4}) (x, y) = xy, and if I1 = {1} and I2 = {2, 3, 4} we have \u03b7({1},{2,3,4}) = 3/4 and\nc({1},{2,3,4}) (x, y) =\n\n(\n\nxy 1/3\n1/3\n\n2yx\n\n\u2212y\n\n4/3\n\n,x\u2264y\n\n,x>y\n\n= c({1,2},{3,4}) (y, x).\n\nExample 2.4. Consider X = (X1 , ...Xd ) a standard d-variate Gaussian random vector with positive definite correlation matrix.The bivariate tail-dependence structure is given by\nP (Fi (Xi ) > 1 \u2212 1/t, Fj (Xj ) > 1 \u2212 1/t) \u223c C\u03c1i,j t\u22122/(1+\u03c1i,j ) (log(t))\u2212\u03c1i,j /(1+\u03c1i,j ) , as t \u2192 \u221e,\n\n(30)\n\nfor i, j \u2208 {1, ..., d}, i < j, where \u03c1i,j = corr(Xi , Xj ) 6\u2208 {\u22121, 1} and\nC\u03c1i,j = (1 + \u03c1i,j )3/2 (1 \u2212 \u03c1i,j )\u22121/2 (4\u03c0)\u2212\u03c1i,j /(1+\u03c1i,j ) .\nHence (25) holds for I = {i} and J = {j} with \u03b7i,j = (1+\u03c1i,j )/2 (see Ledford and Tawn [12], 1996;\nDraisma et al. [3], 2004). According to Hua and Joe ([8], 2011), (25) also holds for non-empty\nsets I1 , I2 \u2282 {1, ..., d}. If we consider \u03c1(I1 ,I2 ) = max{\u03c1i,j : i \u2208 I1 , j \u2208 I2 } then, by Proposition 2.4,\nwe find \u03b7(I1 ,I2 ) = (1 + \u03c1(I1 ,I2 ) )/2, provided the left-hand side of (24) is non-null.\n\n\f10\n\n3\n\nEstimation\n\nSeveral estimators for the bivariate stable tail dependence function in (17) or even for the more\ngeneral d-variate stable tail dependence function\n\u0010\nxd \u0011\nx1\n\u2228 ... \u2228 Fd (Xd ) > 1 \u2212\nlim tP F1 (X1 ) > 1 \u2212\nt\u2192\u221e\nt\nt\n\n(31)\n\nhave been considered in literature. For a survey, see Krajina (2010) [11]. According to relation\n(18), they can be applied to our function l(I1 ,I2 ) (x\u22121 , y \u22121 ).\nWe remark that these are based on asymptotic results that depend on a sequence of positive\nintegers, {kn }, going to infinity at a lower rate than n. For instance, the estimator based on (17)\nby plugging-in the respective empirical counterparts given by\nn\n\u0010\nn\nkn\nkn \u0011\n1 X\n1 b\nPn Fb1 (X1 ) > 1 \u2212\nx \u2228 Fb2 (X2 ) > 1 \u2212\ny =\n,\nkn\nkn\nb\nkn\nn\nn\nkn i=1 {F1 (X1 )>1\u2212 n x\u2228F2 (X2 )>1\u2212 n y}\n\nPn\nwhere Fbl (u) = n\u22121 k=1 1{Xk \u2264u} is the empirical d.f. of Fl , l = 1, 2, is consistent and asymptotically normal if {kn } is an intermediate sequence, i.e., kn \u2192 \u221e and kn /n \u2192 0, as n \u2192 \u221e (Huang\n1992 [9]). The choose of the value k in the sequence {kn } that allows the better trade-off between\nbias and variance is of major difficulty, since small values of k come along with a large variance\nwhenever an increasing k results in a strong bias. Therefore, simulation studies have been carried\nout in order to find the best value of k that allows this compromise.\nAs mentioned before, the upper-tail dependence function in (14) can be viewed as an extension\nof the bivariate upper-tail dependence function of Schmidt and Stadtm\u00fcller (2006) given in (19),\nby taking in this limit the random pair (M (I1 ), M (I2 )) instead of (F (X1 ), F (X2 )). The estimators considered in Schmidt and Stadtm\u00fcller (2006), for which strong consistency and asymptotic\n(I ,I )\nnormality have been established, allow to estimate our function \u039bU 1 2 (x, y), as well as coefficient\n(I1 ,I2 )\n\u01eb(I1 ,I2 ) = \u039bU\n(1, 1). However they are also based on asymptotic results with the same drawback\nof including an intermediate sequence, already referred above.\nIn order to overcome this problem, we shall present a totally different and very simple approach.\nMore precisely, the following result suggests an estimation procedure for the d-variate stable tail\ndependence function in (31) that only evolves a sample mean.\nProposition 3.1. Under the conditions of Proposition 2.1, we have, for l(x1 , ..., xd ) = \u2212 log F (x1 , ..., xd ),\nl(x1 , ..., xd ) =\n\nE(F1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd )\n.\n1 \u2212 E(F1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd )\n\nDem. Consider for G(x) = exp(\u22121/x). Observe that\nE(G(x1 X1 ) \u2228 ... \u2228 G(xd Xd )) = E(G(x1 X1 \u2228 ... \u2228 xd Xd ))\nand the d.f. of x1 X1 \u2228 ... \u2228 xd Xd is given by\nP (x1 X1 \u2228 ... \u2228 xd Xd \u2264 u) =\n=\n=\n\nP (X1 \u2264 u/x1 , ..., Xd \u2264 u/xd )\n\u0001\n\u22121\nF ux\u22121\n1 , ..., uxd\n\u0001\u0001\n\u22121\nexp \u2212 l ux\u22121\n.\n1 , ..., uxd\n\n(32)\n\n\f11\nHence\nE(G(x1 X1 \u2228 ... \u2228 xd Xd ))\nZ \u221e\n\u0001\u0001 d\n\u0001\u0001\n\u22121\nexp(\u2212u\u22121 ) exp \u2212 l ux1\u22121 , ..., ux\u22121\n=\n\u2212 l ux\u22121\n1 , ..., uxd\nd\ndu\n0\nZ \u221e\n\u0001\u0001 d\n\u0001\u0001\n\u22121\n\u22121\n=\nexp(\u2212u\u22121 ) exp \u2212 u\u22121 l x\u22121\n\u2212 u\u22121 l x\u22121\n1 , ..., xd\n1 , ..., xd\ndu\n0\nZ\n\u0001 \u221e\n\u0001\u0001\u0001 \u22122\n\u22121\nu du\n= l x1\u22121 , ..., xd\u22121\nexp \u2212 u\u22121 1 + l x\u22121\n1 , ..., xd\n\n(33)\n\n0\n\n=\n\n\u0001\n\u22121\nl x\u22121\n1 , ..., xd\n\n\u22121\n1 + l x\u22121\n1 , ..., xd\n\n\u0001.\n\nd\n\nNow just observe that G(x1 X1 \u2228 ... \u2228 xd Xd ) = F1 (X1 )1/x1 \u2228 ... \u2228 Fd (Xd )1/xd . \u0003\nRemark 3.1. Observe that the d-variate stable tail dependence function in (31) corresponds to\n\u22121\n\u2212 log F (x\u22121\n1 , ..., xd ).\nBy applying Proposition 3.1 with xj replaced by xj\u22121 , j = 1, ..., d, we get the following corollary.\nCorollary 3.2. Under the conditions of Proposition 2.1, we have\nx\u01ebI1 \u2261 l(I1 ,\u2205) (x\u22121 , x\u22121 ) =\n\nE(M (I1 )1/x )\n,\n1 \u2212 E(M (I1 )1/x )\n\n(34)\n\ny\u01ebI2 \u2261 l(\u2205,I2 ) (y \u22121 , y \u22121 ) =\n\nE(M (I2 )1/y )\n1 \u2212 E(M (I2 )1/y )\n\n(35)\n\nand\nl(I1 ,I2 ) (x\u22121 , y \u22121 ) =\n\nE(M (I1 )1/x \u2228 M (I2 )1/y )\n.\n1 \u2212 E(M (I1 )1/x \u2228 M (I2 )1/y )\n\n(36)\n\nConsider the estimators derived from Proposition 2.1 and Corollary 3.2 by plugging-in the\nrespective sample means, respectively,\ne\nl(x1 , ..., xd ) =\n\nand\nxe\n\u01ebI1 =\n\nM (I1 )1/x\n1 \u2212 M (I1 )1/x\n\n, ye\n\u01ebI2 =\n\n1 \u2212 F1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd\n\nM (I2 )1/y\n1 \u2212 M (I2 )1/y\n\nwhere\nM (I1 )1/x =\n\nF1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd\n\n(37)\n\n,\n\nand e\nl(I1 ,I2 ) (x\u22121 , y \u22121 ) =\n\nM (I1 )1/x \u2228 M (I2 )1/y\n\n1 \u2212 M (I1 )1/x \u2228 M (I2 )1/y\n\nn\nn\n1X _\n1X _\n(i)\n(i)\nFj (Xj )1/x , M (I2 )1/y =\nFj (Xj )1/y\nn i=1\nn i=1\nj\u2208I1\n\nj\u2208I2\n\n. (38)\n\n(39)\n\n\f12\nand\nM (I1\n\n)1/x\n\n\u2228 M (I2\n\n)1/y\n\nn\n\u0011\n_\n1 X\u0010 _\n(i)\n(i)\nFj (Xj )1/x \u2228\nFj (Xj )1/y .\n=\nn i=1\nj\u2208I1\n\n(40)\n\nj\u2208I2\n\nWe will consider two situations: the first one for known margins and the second one for unknown\nmargins.\nIn case the margins are known, they become unit Fr\u00e9chet by transformation \u22121/ log Fj (Xj ) for\nj \u2208 I \u2282 {1, ..., d}.\nIt is quite straightforward to deduce the consistency and asymptotic normality of estimators\n(37) and (38) by the well-known Delta Method.\nProposition 3.3. Under the conditions of Proposition 2.1, we have\n\u221a\nn(e\nl(x1 , ..., xd ) \u2212 l(x1 , ..., xd )) \u2192 N (0, \u03c3 2 ),\n\n(41)\n\nwhere e\nl(x1 , ..., xd ) is the estimator derived from Proposition 3.1 by plugging-in the respective sample\nmean given in (37) and\n\u00012\nl(x1 ,...,xd ) 1+l(x1 ,...,xd )\n2\n\u0001\n.\n\u03c3 =\n2+l(x1 ,...,xd )\n\nDem.\nLet Yi , i = 1, ..., n, be independent copies of Y = F1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd . We have\n\u221a\nthat n(Y \u2212\u03bcY ) \u2192 N (0, \u03c3Y2 ), where \u03bcY = E(F1 (X1 )x1 \u2228...\u2228Fd (Xd )xd ) and \u03c3Y2 = V ar(F1 (X1 )x1 \u2228\n... \u2228 Fd (Xd )xd ). By a similar reasoning of (33) we derive\nE((F1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd )2 ) =\n\nl(x1 ,...,xd )\n2+l(x1 ,...,xd )\n\nand hence,\nV ar((F1 (X1 )x1 \u2228 ... \u2228 Fd (Xd )xd )2 ) =\n\nl(x1 ,...,xd )\n2+l(x1 ,...,xd )\n\n\u0001\n\n1+l(x1 ,...,xd )\n\n\u00012 .\n\nLet g(x) = (1 \u2212 x)\u22121 \u2212 1. We have [g \u2032 (\u03bcY )]2 = (1 \u2212 \u03bcY )\u22124 and, by the Delta Method,\nx\u01ebI1 ) \u2192 N (0, \u03c3Y2 (1 \u2212 \u03bcY )\u22124 ). \u0003\nCorollary 3.4. Under the conditions of Proposition 2.1, we have\n\u221a\nn(xe\n\u01ebI1 \u2212 x\u01ebI1 ) \u2192 N (0, \u03c312 ),\n\u221a\nn(ye\n\u01ebI2 \u2212 y\u01ebI2 ) \u2192 N (0, \u03c322 )\n\n\u221a\nn(g(Y ) \u2212\n\n(42)\n(43)\n\nand\n\u221a (I1 ,I2 ) \u22121 \u22121\nl\n(x , y ) \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )) \u2192 N (0, \u03c332 ),\nn(e\n\nl(I1 ,I2 ) (x\u22121 , y \u22121 ) are given in (38) and\n\u01ebI2 and e\nwhere xe\n\u01ebI1 , ye\n\u00012\nx\u01ebI1 1 + x\u01ebI1\n\u0001 ,\n\u03c312 =\n2 + x\u01ebI1\n\u03c322\nand\n\u03c332\n\ny\u01ebI2 1 + y\u01ebI2\n\u0001\n=\n2 + y\u01ebI2\n\n\u00012\n\n\u0001\n\u0001\u00012\nl(I1 ,I2 ) x\u22121 , y \u22121 1 + l(I1 ,I2 ) x\u22121 , y \u22121\n\u0001\u0001\n.\n=\n2 + l(I1 ,I2 ) x\u22121 , y \u22121\n\n(44)\n\n(45)\n\n(46)\n\n(47)\n\n\f13\nBased on the definition in (14), a natural estimator for the upper-tail dependence function is\ne(I1 ,I2 ) (x\u22121 , y \u22121 ),\ne (I1 ,I2 ) (x, y) = xf\n\u039b\n\u01ebI1 + y \u01ebf\nI2 \u2212 l\nU\n\n(48)\n\n\u01ebI1 \u222aI2 .\ne\n\u01eb(I1 ,I2 ) = \u01ebf\nI2 \u2212 e\nI1 + \u01ebf\n\n(49)\n\ne(I1 ,I2 ) (x\u22121 , y \u22121 ) stated in (38). Hence we have the following estimator for the\nwith xf\n\u01ebI1 , y \u01ebf\nI2 and l\nextremal coefficient of dependence between XI1 and XI2 :\nl(I1 ,I2 ) (1, 1).\nwhere e\n\u01ebI1 \u222aI2 = e\n\ne (I1 ,I2 ) (x, y) in (37) and (48), respectively, are\nProposition 3.5. Estimators e\nl(x1 , ..., xd ) and \u039b\nU\nstrong consistent. Consequently, the same holds for e\n\u01eb(I1 ,I2 ) in (49).\n\nDem. Just observe that, as the sample mean M (I1 )1/x converges almost surely to the\na.s.\na.s.\n\u01ebI1 = g(M (I1 )1/x ) \u2212\u2192 x\u01ebI1 =\nmean value E(M (I1 )1/x ), i.e., M (I1 )1/x \u2212\u2192 E(M (I1 )1/x ), then xf\ne(I1 ,I2 ) (x\u22121 , y \u22121 ) and e\nl(x1 , ..., xd ).\ng(E(M (I1 )1/x )), where g(x) = (1\u2212x)\u22121 \u22121. Analogously for y \u01ebf\nI2 , l\n(I\n,I\n)\n1 2\ne\n(x, y) is straightforward from\nNow, the strong consistency of \u039bU\n(I ,I2 )\n\ne 1\n|\u039b\nU\n\n(I ,I2 )\n\n(x, y) \u2212 \u039bU 1\n\ne(I1 ,I2 ) (x\u22121 , y \u22121 ) \u2212 l(I1 ,I2 ) (x\u22121 , y \u22121 )|. \u0003\n(x, y)| \u2264 |xf\n\u01ebI1 \u2212 x\u01ebI1 | + |y \u01ebf\nI2 \u2212 y\u01ebI2 | + |l\n\nNow consider Fbj the empirical d.f. of Fj , j = 1, ..., d,\nn\n\nFbj (u) =\n\n1 X\n1{X (k) \u2264u} .\nj\nn+1\nk=1\n\nThe denominator n + 1 instead of n in the empirical d.f. concerns estimation accuracy and other\nmodifications can be used. For a discussion see, for instance, Beirlant et al. [1] (2004).\nIn case of unknown margins, we can replace Fj by the respective empirical d.f. Fbj , j = 1, ..., d,\nin (37) and (38). More precisely, we have\nb\nl(x1 , ..., xd ) =\n\nas well as,\nxb\n\u01ebI1 =\nwhere\n\nc(I1 )1/x\nM\n\nc(I1 )1/x\n1\u2212M\n\n, yb\n\u01ebI2 =\n\nFb1 (X1 )x1 \u2228 ... \u2228 Fbd (Xd )xd\n,\n1 \u2212 Fb1 (X1 )x1 \u2228 ... \u2228 Fbd (Xd )xd\n\nc(I2 )1/y\nM\n\nc(I2 )1/y\n1\u2212M\n\nl(I1 ,I2 ) (x\u22121 , y \u22121 ) =\nand b\nn\n\n1X\nFb1 (X1 )x1 \u2228 ... \u2228 Fbd (Xd )xd =\nn i=1\n\nj\u2208{1,...,d}\n\nc(I1 )1/x \u2228 M\nc(I2 )1/y\nM\n\nc(I1 )1/x \u2228 M\nc(I2 )1/y\n1\u2212M\n\n(i)\nFbj (Xj )xj ,\n\nn _\nn _\nX\nX\n(i)\n(i)\nc(I1 )1/x = 1\nc(I2 )1/y = 1\nM\nFbj (Xj )1/x , M\nFbj (Xj )1/y\nn i=1\nn i=1\nj\u2208I1\n\nand\n\n_\n\n(50)\n\n(52)\n\n(53)\n\nj\u2208I2\n\nn \u0010 _\n\u0011\n_\nX\n(i)\n(i)\nc(I1 )1/x \u2228 M\nc(I2 )1/y = 1\nFbj (Xj )1/y .\nFbj (Xj )1/x \u2228\nM\nn i=1\nj\u2208I1\n\n(54)\n\nj\u2208I2\n\nWe still have asymptotic normality of estimators in (52)-(54) from the following result stated\nin Fermanian et al. (2002, [6], Theorem 6).\n\n(51)\n\n\f14\nTheorem 3.6. (Fermanian et al. (2002) [6], Theorem 6) Let F have continuous marginals and let\ncopula CF in (2) have continuous partial derivatives. Then\nn\n\n1 X\n(i)\n(i)\n(i)\n(i)\n\u221a\n{J(Fb1 (X1 ), ..., Fbd (Xd ))\u2212E(J(F1 (X1 ), ..., Fd (Xd )))} \u2192\nn i=1\n\nZ\n\nG(u1 , ..., ud )dJ(u1 , ..., ud )\n\n[0,1]d\n\nin distribution in l\u221e ([0, 1]d ), where the limiting process and G are centered Gaussian, and J :\n[0, 1]d \u2192 R is of bounded variation, continuous from above and with discontinuities of the first kind\n(Neuhaus, 1971 [20]).\nThe asymptotic normality of estimators (50) and (51) is now derived from a general version of\nthe Delta Method as considered in Schmidt and Stadtm\u00fcller [22] (2006; Theorem 13).\nWe also state strong consistency of estimators b\nl(x1 , ..., xd ) in (50) and\nb(I1 ,I2 ) (x\u22121 , y \u22121 ),\nb (I1 ,I2 ) (x, y) = xc\n\u039b\n\u01ebI1 + y \u01ebc\nI2 \u2212 l\nU\n\n(55)\n\nb(I1 ,I2 ) (x\u22121 , y \u22121 ) given in (51), and hence of estimator\nwith xc\n\u01ebI1 , y \u01ebc\nI2 and l\n\u01ebI1 \u222aI2 ,\nb\n\u01eb(I1 ,I2 ) = \u01ebc\nI2 \u2212 b\nI1 + \u01ebc\n\n(56)\n\nl(I1 ,I2 ) (1, 1).\nwhere b\n\u01ebI1 \u222aI2 = b\n\nb (I1 ,I2 ) (x, y) in (55) are strong consistent.\nProposition 3.7. Estimators b\nl(x1 , ..., xd ) in (50) and \u039b\nU\nTherefore, the same holds for estimator b\n\u01eb(I1 ,I2 ) in (56).\nDem. The proof runs along the same lines as the one of Proposition 3.5. We only prove the\na.s.\nmore general case b\nl(x1 , ..., xd ) \u2212\u2192 l(x1 , ..., xd ). Observe that\nn\n\n1X\nn i=1\n\n_\n\nj\u2208{1,...,d}\n\nn\n\n1X\nn i=1\n\n\u2264\n\n_\n\nj\u2208{1,...,d}\n\nn\n\n+\n\n1X\nn i=1\n\n_\n\ncj (X (i) )xj \u2212 E\nF\nj\n\n_\n\nj\u2208{1,...,d}\nn\n\nX\ncj (X (i) )xj \u2212 1\nF\nj\nn i=1\n\nj\u2208{1,...,d}\n\nFj (Xj )xj\n\n_\n\n(i)\n\nFj (Xj )xj\n\nj\u2208{1,...,d}\n\n_\n\n(i)\n\nFj (Xj )xj \u2212 E\n\n\u0001\n\nj\u2208{1,...,d}\n\n\u0001\nFj (Xj )xj ,\n\nwhere the second term converges almost surely to zero by the Strong Law of Large Numbers.\nFor the first term we have, successively,\n| n1\n\nPn\n\ni=1\n\n\u2264\n\n1\nn\n\n\u2264\n\n1\nn\n\nPn\n\nW\n\ni=1\n\nPn\n\ni=1\n\n(i) xj\nb\nj\u2208{1,...,d} Fj (Xj )\n\nW\n\n\u2212\n\n(i) xj\nb\nj\u2208{1,...,d} |Fj (Xj )\n\nP\n\n(i) xj\nb\nj\u2208{1,...,d} |Fj (Xj )\n\n1\nn\n\nPn\n\ni=1\n\nW\n\n(i) xj\nj\u2208{1,...,d} Fj (Xj ) |\n\n(i)\n\n\u2212 Fj (Xj )xj |\n(i)\n\n\u2212 Fj (Xj )xj |,\n\nwhich converges almost surely to zero according to Gilat and Hill ([7], 1992; proof of Theorem 1.1).\n\u0003\n\n\f15\n\n4\n\nApplication to financial data\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nEurope\n\n1.0\n0.8\n0.6\n\nFar East\n\n0.0\n\n0.2\n\n0.4\n\n0.6\n0.0\n\n0.2\n\n0.2\n\n0.4\n\nFar East\n\n0.6\n0.4\n\nUSA\n\n0.8\n\n0.8\n\n1.0\n\n1.0\n\nIn this section we show that tail dependence is present in financial data. Our analysis is based\non negative log-returns of daily closing values of the stock market indexes, CAC 40 (France),\nFTSE100 (UK), SMI (Swiss), XDAX (German), Dow Jones (USA), Nasdaq (USA), SP500 (USA),\nHSI (China), Nikkei (Japan). The period covered is January 1993 to March 2004. More precisely,\nwe consider the monthly maximums in each market and group the indexes in Europe (CAC 40,\nFTSE100, SMI, XDAX), USA (Dow Jones, Nasdaq) and Far East (HSI, Nikkei). The scatter plots\nin Figure 1 show the presence of dependence between the monthly maximums in Europe and USA,\nEurope and Far East, USA and Far East, respectively. We are interested in assessing the amount\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\n0.2\n\nEurope\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nUSA\n\nFigure 1: Scatter plots of the monthly maximums (84 data points) in Europe versus USA, Europe\nversus Far East and USA versus Far East.\nof tail dependence between the three big world markets referred: Europe, USA and Far East, and\nthis can be achieved through the extremal coefficient of dependence \u01eb(I1 ,I2 ) , defined in (15). As we\ndo not know the margins distribution, we use estimator b\n\u01eb(I1 ,I2 ) in (56) based on ranks. In Table\n1 are the obtained estimates for several groups, I1 and I2 . One can see that the Far East market\nhas less influence (lower values of the coefficient) but Europe and USA have a stronger effect on\neach other and on the respective group of foreign markets. Observe that the difference between\nthese two magnitudes of dependence is almost in the proportion 1:2.\nI1\nEurope\nEurope\nUSA\nEurope\nUSA\nFar East\n\nI2\nUSA\nFar East\nFar East\nUSA \u222a Far East\nEurope \u222a Far East\nUSA \u222a Europe\n\nb\n\u01eb(I1 ,I2 )\n1.008324625\n0.568780467\n0.364358832\n1.125919957\n0.921498322\n0.481954164\n\nTable 1: Estimates of the extremal coefficient of dependence b\n\u01eb(I1 ,I2 ) for the indicated groups, I1\nand I2 .\n\n5\n\nConclusion\n\nIn this work we introduce a new upper-tail dependence concept for a random vector which extends\nthe one in Schmidt and Stadtm\u00fcller ([22], 2006). Our approach weakens the usual imposed multivariate tail dependence and can be treated with bivariate techniques. The new function extends\nthe well-known relation of Huang ([9] 1992) for a MEV with unit Fr\u00e9chet marginals, and gives rise\n\n\f16\nto the so-called extremal coefficient of dependence as it is expressed through the extremal coefficient in Tiago de Oliveira ([26], 1962-63) and Smith ([23], 1990). We also enlarge our discussion\nto tail independence in the sense of Ledford and Tawn ([12, 13], 1996, 1997). At this point we are\nbeyond MEV distributions which only admit tail dependence or (exact) independence.\nIn calculating the moments of the r.v.'s involved in our function, we arrive at very simple\nestimators whose asymptotic normality is stated. These can also be applied to the well-known\nstable tail dependence function. We also prove strong consistency of the proposed estimators for\nour measures. We end with an application to financial data presenting tail dependence.\n\nReferences\n[1] Beirlant, J., Goegebeur, Y., Segers, J. e Teugels, J. (2004). Statistics of Extremes: Theory\nand Application. John Wiley.\n[2] Coles, S., Heffernan, J. and Tawn, J. (1999). Dependence measures for extreme value analysis,\nExtremes 2: 339-366.\n[3] Draisma, G., Drees, H., Ferreira, A. and de Haan, L. (2004). Bivariate tail estimation: dependence in asymptotic independence. Bernoulli, 10, 251-280.\n[4] Drees, H., and M\u00fcller, P. (2008). Fitting and validation of a bivariate model for large claims.\nInsurance: Mathematics and Economics 42, 638-650.\n[5] Embrechts, P., Lindskog, F. and McNeil, A. (2003). Modelling Dependence with Copulas and\nApplications to Risk Management, In: Handbook of Heavy Tailed Distibutions in Finance,\ned. S. Rachev, Elsevier, Chapter 8: 329-384.\n[6] Fermanian, J.-D., Radulovi\u0107, D., Wegkamp, M. (2004). Weak convergence of empirical copula\nprocesses. Bernoulli 10(5), 847-860.\n[7] Gilat, D. and Hill, T. (1992) One-sided refinements of the strong law of large numbers and\nthe Glivenko-Cantelli Theorem, Ann. Probab. 20 , 1213-1221.\n[8] Hua, L., Joe, H. (2004). Tail order and intermediate tail dependence of multivariate copulas.\n[9] Huang, X. (1992). Statistics of Bivariate Extreme Values. Ph. D. thesis, Tinbergen Institute\nResearch Series 22, Erasmus University Rotterdam.\n[10] Joe, H. (1997). Multivariate Models and Dependence Concepts. Chapman & Hall, London.\n[11] Krajina, A. (2010). An M-Estimator of Multivariate Tail Dependence. Tilburg: Tilburg University Press.\n[12] Ledford, A. and Tawn, J. A. (1996). Statistics for near independence in multivariate extreme\nvalues. Biometrika, 83, 169-187.\n[13] Ledford, A. and Tawn, J. A. (1997). Modelling Dependence within joint tail regions, J. R.\nStat. Soc. Ser. B Stat. Methodol. 59, 475-499.\n[14] Li, H. (2006). Tail dependence of multivariate Pareto distributions, WSU Mathematics Technical Report 2006-6. http://www.math.wsu.edu/TRS/.\n[15] Li, H. (2008). Tail Dependence Comparison of Survival Marshall-Olkin Copulas, Methodol.\nComput. Appl. Probab., 10(1), 39-54.\n[16] Li, H. (2009). Orthant tail dependence of multivariate extreme value distributions, J. Multivariate Anal., 100(1), 243-256.\n\n\f17\n[17] Marshall, A.W., Olkin, I. (1967). A multivariate exponential distribution, J. Amer. Statist.\nAssoc. 62 30-44.\n[18] Nelsen, R. B. (1996). Nonparametric measures of multivariate association, in Distribution with\nfixed marginals and related topics, IMS Lecture Notes - Monograph Series, vol. 28, 223-232.\n[19] Nelsen, R.B. (2006). An Introduction to Copulas. Second Edition. Springer, New York.\n[20] Neuhaus, G. (1971) On the weak convergence of stochastic processes with multidimensional\ntime parameter. Ann. Math. Statist., 42, 1285-1295.\n[21] Schmid, F., Schmidt, R. (2007). Multivariate conditional versions of Spearman's rho and\nrelated measures of tail dependence. J. Multivariate Anal., 98, 1123-1140.\n[22] Schmidt, R., Stadtm\u00fcller, U. (2006). Nonparametric estimation of tail dependence, The Scandinavian Journal of Statistics 33, 307-335.\n[23] Smith, R.L. (1990). Max-stable processes and spatial extremes. Preprint, Univ. North Carolina, USA.\n[24] Smith, R.L., Weissman, I. (1996). Characterization and estimation of the multivariate extremal index. Manuscript, UNC.\n[25] Sibuya, M. (1960). Bivariate extreme statistics. Ann. Inst. Statist. Math. 11, 195-210.\n[26] Tiago de Oliveira, J. (1962/63). Structure theory of bivariate extremes, extensions. Est. Mat.,\nEstat. e Econ. 7, 165-195.\n[27] Wolff, E. F. (1980). N-dimensional measures of dependence. Stochastica 4 (3), 175-188.\n\n\f"}