{"id": "http://arxiv.org/abs/cs/0011044v1", "guidislink": true, "updated": "2000-11-29T12:14:50Z", "updated_parsed": [2000, 11, 29, 12, 14, 50, 2, 334, 0], "published": "2000-11-29T12:14:50Z", "published_parsed": [2000, 11, 29, 12, 14, 50, 2, 334, 0], "title": "Scaling Up Inductive Logic Programming by Learning from Interpretations", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0003018%2Ccs%2F0003025%2Ccs%2F0003041%2Ccs%2F0003075%2Ccs%2F0003017%2Ccs%2F0003079%2Ccs%2F0003040%2Ccs%2F0003016%2Ccs%2F0003006%2Ccs%2F0003078%2Ccs%2F0003081%2Ccs%2F0003014%2Ccs%2F0003027%2Ccs%2F0003044%2Ccs%2F0003035%2Ccs%2F0003042%2Ccs%2F0003034%2Ccs%2F0003076%2Ccs%2F0003009%2Ccs%2F0003054%2Ccs%2F0003012%2Ccs%2F0003013%2Ccs%2F0003021%2Ccs%2F0003084%2Ccs%2F0003065%2Ccs%2F0003083%2Ccs%2F0003039%2Ccs%2F0003031%2Ccs%2F0003032%2Ccs%2F0003082%2Ccs%2F0003048%2Ccs%2F0003047%2Ccs%2F0003030%2Ccs%2F0003066%2Ccs%2F0003051%2Ccs%2F0003061%2Ccs%2F0003011%2Ccs%2F0003053%2Ccs%2F0003008%2Ccs%2F0003050%2Ccs%2F0003023%2Ccs%2F0003080%2Ccs%2F0003045%2Ccs%2F0003057%2Ccs%2F0003052%2Ccs%2F0003037%2Ccs%2F0003046%2Ccs%2F0003049%2Ccs%2F0003007%2Ccs%2F0003036%2Ccs%2F0003029%2Ccs%2F0003015%2Ccs%2F0003020%2Ccs%2F0003074%2Ccs%2F0003059%2Ccs%2F0003024%2Ccs%2F0003058%2Ccs%2F0003028%2Ccs%2F0003062%2Ccs%2F0003005%2Ccs%2F0003068%2Ccs%2F0011045%2Ccs%2F0011046%2Ccs%2F0011012%2Ccs%2F0011004%2Ccs%2F0011014%2Ccs%2F0011041%2Ccs%2F0011047%2Ccs%2F0011009%2Ccs%2F0011015%2Ccs%2F0011029%2Ccs%2F0011013%2Ccs%2F0011028%2Ccs%2F0011021%2Ccs%2F0011038%2Ccs%2F0011040%2Ccs%2F0011011%2Ccs%2F0011001%2Ccs%2F0011008%2Ccs%2F0011017%2Ccs%2F0011016%2Ccs%2F0011035%2Ccs%2F0011031%2Ccs%2F0011036%2Ccs%2F0011026%2Ccs%2F0011039%2Ccs%2F0011007%2Ccs%2F0011003%2Ccs%2F0011018%2Ccs%2F0011019%2Ccs%2F0011032%2Ccs%2F0011037%2Ccs%2F0011005%2Ccs%2F0011043%2Ccs%2F0011027%2Ccs%2F0011025%2Ccs%2F0011024%2Ccs%2F0011030%2Ccs%2F0011044%2Ccs%2F0011010%2Ccs%2F0011034&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Scaling Up Inductive Logic Programming by Learning from Interpretations"}, "summary": "When comparing inductive logic programming (ILP) and attribute-value learning\ntechniques, there is a trade-off between expressive power and efficiency.\nInductive logic programming techniques are typically more expressive but also\nless efficient. Therefore, the data sets handled by current inductive logic\nprogramming systems are small according to general standards within the data\nmining community. The main source of inefficiency lies in the assumption that\nseveral examples may be related to each other, so they cannot be handled\nindependently.\n  Within the learning from interpretations framework for inductive logic\nprogramming this assumption is unnecessary, which allows to scale up existing\nILP algorithms. In this paper we explain this learning setting in the context\nof relational databases. We relate the setting to propositional data mining and\nto the classical ILP setting, and show that learning from interpretations\ncorresponds to learning from multiple relations and thus extends the\nexpressiveness of propositional learning, while maintaining its efficiency to a\nlarge extent (which is not the case in the classical ILP setting).\n  As a case study, we present two alternative implementations of the ILP system\nTilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which\nloads all data in main memory, and Tilde-LDS, which loads the examples one by\none. We experimentally compare the implementations, showing Tilde-LDS can\nhandle large data sets (in the order of 100,000 examples or 100 MB) and indeed\nscales up linearly in the number of examples.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0003018%2Ccs%2F0003025%2Ccs%2F0003041%2Ccs%2F0003075%2Ccs%2F0003017%2Ccs%2F0003079%2Ccs%2F0003040%2Ccs%2F0003016%2Ccs%2F0003006%2Ccs%2F0003078%2Ccs%2F0003081%2Ccs%2F0003014%2Ccs%2F0003027%2Ccs%2F0003044%2Ccs%2F0003035%2Ccs%2F0003042%2Ccs%2F0003034%2Ccs%2F0003076%2Ccs%2F0003009%2Ccs%2F0003054%2Ccs%2F0003012%2Ccs%2F0003013%2Ccs%2F0003021%2Ccs%2F0003084%2Ccs%2F0003065%2Ccs%2F0003083%2Ccs%2F0003039%2Ccs%2F0003031%2Ccs%2F0003032%2Ccs%2F0003082%2Ccs%2F0003048%2Ccs%2F0003047%2Ccs%2F0003030%2Ccs%2F0003066%2Ccs%2F0003051%2Ccs%2F0003061%2Ccs%2F0003011%2Ccs%2F0003053%2Ccs%2F0003008%2Ccs%2F0003050%2Ccs%2F0003023%2Ccs%2F0003080%2Ccs%2F0003045%2Ccs%2F0003057%2Ccs%2F0003052%2Ccs%2F0003037%2Ccs%2F0003046%2Ccs%2F0003049%2Ccs%2F0003007%2Ccs%2F0003036%2Ccs%2F0003029%2Ccs%2F0003015%2Ccs%2F0003020%2Ccs%2F0003074%2Ccs%2F0003059%2Ccs%2F0003024%2Ccs%2F0003058%2Ccs%2F0003028%2Ccs%2F0003062%2Ccs%2F0003005%2Ccs%2F0003068%2Ccs%2F0011045%2Ccs%2F0011046%2Ccs%2F0011012%2Ccs%2F0011004%2Ccs%2F0011014%2Ccs%2F0011041%2Ccs%2F0011047%2Ccs%2F0011009%2Ccs%2F0011015%2Ccs%2F0011029%2Ccs%2F0011013%2Ccs%2F0011028%2Ccs%2F0011021%2Ccs%2F0011038%2Ccs%2F0011040%2Ccs%2F0011011%2Ccs%2F0011001%2Ccs%2F0011008%2Ccs%2F0011017%2Ccs%2F0011016%2Ccs%2F0011035%2Ccs%2F0011031%2Ccs%2F0011036%2Ccs%2F0011026%2Ccs%2F0011039%2Ccs%2F0011007%2Ccs%2F0011003%2Ccs%2F0011018%2Ccs%2F0011019%2Ccs%2F0011032%2Ccs%2F0011037%2Ccs%2F0011005%2Ccs%2F0011043%2Ccs%2F0011027%2Ccs%2F0011025%2Ccs%2F0011024%2Ccs%2F0011030%2Ccs%2F0011044%2Ccs%2F0011010%2Ccs%2F0011034&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "When comparing inductive logic programming (ILP) and attribute-value learning\ntechniques, there is a trade-off between expressive power and efficiency.\nInductive logic programming techniques are typically more expressive but also\nless efficient. Therefore, the data sets handled by current inductive logic\nprogramming systems are small according to general standards within the data\nmining community. The main source of inefficiency lies in the assumption that\nseveral examples may be related to each other, so they cannot be handled\nindependently.\n  Within the learning from interpretations framework for inductive logic\nprogramming this assumption is unnecessary, which allows to scale up existing\nILP algorithms. In this paper we explain this learning setting in the context\nof relational databases. We relate the setting to propositional data mining and\nto the classical ILP setting, and show that learning from interpretations\ncorresponds to learning from multiple relations and thus extends the\nexpressiveness of propositional learning, while maintaining its efficiency to a\nlarge extent (which is not the case in the classical ILP setting).\n  As a case study, we present two alternative implementations of the ILP system\nTilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which\nloads all data in main memory, and Tilde-LDS, which loads the examples one by\none. We experimentally compare the implementations, showing Tilde-LDS can\nhandle large data sets (in the order of 100,000 examples or 100 MB) and indeed\nscales up linearly in the number of examples."}, "authors": ["Hendrik Blockeel", "Luc De Raedt", "Nico Jacobs", "Bart Demoen"], "author_detail": {"name": "Bart Demoen"}, "author": "Bart Demoen", "arxiv_comment": "37 pages", "links": [{"href": "http://arxiv.org/abs/cs/0011044v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0011044v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.6 ; I.2.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0011044v1", "affiliation": "Katholieke Universiteit Leuven, Dept. of Computer Science", "arxiv_url": "http://arxiv.org/abs/cs/0011044v1", "journal_reference": "Data Mining and Knowledge Discovery 3(1), pp. 59-93, 1999", "doi": null, "fulltext": "arXiv:cs/0011044v1 [cs.LG] 29 Nov 2000\n\nScaling Up Inductive Logic\nProgramming by Learning From\nInterpretations\nHendrik Blockeel\nLuc De Raedt\nNico Jacobs\nBart Demoen\nReport CW 297, August 2000\n\nn\n\nKatholieke Universiteit Leuven\nDepartment of Computer Science\nCelestijnenlaan 200A \u2013 B-3001 Heverlee (Belgium)\n\n\fScaling Up Inductive Logic\nProgramming by Learning From\nInterpretations\u2217\nHendrik Blockeel\nLuc De Raedt\nNico Jacobs\nBart Demoen\nReport CW 297, August 2000\nDepartment of Computer Science, K.U.Leuven\nAbstract\nWhen comparing inductive logic programming (ILP) and attributevalue learning techniques, there is a trade-off between expressive power\nand efficiency. Inductive logic programming techniques are typically\nmore expressive but also less efficient. Therefore, the data sets handled\nby current inductive logic programming systems are small according\nto general standards within the data mining community. The main\nsource of inefficiency lies in the assumption that several examples may\nbe related to each other, so they cannot be handled independently.\nWithin the learning from interpretations framework for inductive\nlogic programming this assumption is unnecessary, which allows to scale\nup existing ILP algorithms. In this paper we explain this learning setting\nin the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that\nlearning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning,\nwhile maintaining its efficiency to a large extent (which is not the case\nin the classical ILP setting).\nAs a case study, we present two alternative implementations of the\nILP system Tilde (Top-down Induction of Logical DEcision trees): Tildeclassic,\nwhich loads all data in main memory, and TildeLDS, which loads the\nexamples one by one. We experimentally compare the implementations,\nshowing TildeLDS can handle large data sets (in the order of 100,000\nexamples or 100 MB) and indeed scales up linearly in the number of\nexamples.\nKeywords : Inductive logic programming, machine learning, data mining.\nAMS(MOS) Classification : Primary : I.2.6, Secondary : I.2.3.\n\n\u2217A\n\nversion of this report has appeared in Data Mining and Knowledge Discovery 3(1), 1999\n\n\f1\n\nIntroduction\n\nThere is a general trade-off in computer science between expressive power and efficiency. Theorem proving in first order logic is less efficient but more expressive than\ntheorem proving in propositional logic. It is therefore no surprise that first order\ninduction techniques (such as those studied within inductive logic programming)\nare less efficient than propositional or attribute-value learning techniques. On the\nother hand, inductive logic programming is able to solve induction problems beyond\nthe scope of attribute value learning, cf. (Bratko and Muggleton, 1995).\nThe computational requirements of inductive logic programming systems are\nhigher than those of propositional learners due to the following reasons: first, the\nspace of clauses considered by inductive logic programming systems typically is\nmuch larger than that of propositional learners and can even be infinite. Second,\ntesting whether a clause covers an example is more complex than in attribute value\nlearners. In attribute value learners an example corresponds to a single tuple in\na relational database, whereas in inductive logic programming one example may\ncorrespond to multiple tuples of multiple relations. Therefore, the coverage test in\ninductive logic programming needs a database system to solve complex queries or\neven a theorem prover. Third, and this is related to the second point, in attribute\nvalue learning testing whether an example is covered is done locally, i.e. independently of the other examples. Therefore, even if the data set is huge, a specific\ncoverage test can be performed efficiently. This contrasts with the large majority\nof inductive logic programming systems, such as FOIL (Quinlan, 1990) or Progol\n(Muggleton, 1995), in which coverage is tested globally, i.e. to test the coverage of\none example the whole ensemble of examples and background theory needs to be\nconsidered1 . Global coverage tests are much more expensive than local ones. Moreover, systems using global coverage tests are hard to scale up. Due to the fact that\none single coverage test (on one example) typically takes more than constant time\nin the size of the database, the complexity of induction systems exploiting global\ncoverage tests will grow more than linearly in the number of examples.\nIn a more recent setting for inductive logic programming, called learning from\ninterpretations (De Raedt and D\u017eeroski, 1994; De Raedt et al., 1998), it is assumed\nthat each example is a small database (or a part of a global database), and local\ncoverage tests are performed. Algorithms using local coverage tests are typically\nlinear in the number of examples. Furthermore, as each example can be loaded\nindependently of the other ones, there is no need to use a database system even\nwhen the whole data set cannot be loaded into main memory.\nWithin the setting of learning from interpretations, we investigate the issue\nof scaling up inductive logic programming. More specifically, we present two alternative implementations of the Tilde system (Blockeel and De Raedt, 1998):\nTildeclassic, which loads all data in main memory, and TildeLDS, which loads\nthe examples one by one. The latter is inspired by the work by Mehta et al. (1996),\nwho propose a level-wise algorithm that needs one pass through the data per level of\nthe tree it builds. Furthermore, we experimentally compare the algorithms on large\ndata sets involving 100,000 examples (in the order of 100 MBytes). The experiments\nclearly show that inductive logic programming systems can be scaled up to satisfy\nthe standards imposed by the data mining community. At the same time, this provides evidence in favor of local coverage tests (as in learning from interpretations)\nin inductive logic programming.\nThis article is organized as follows. In Section 2 we introduce the learning from\ninterpretations setting and relate it to the relational database context. In Section\n3 we introduce first order logical decision trees and discuss the ILP system Tilde,\n1 E.g.,\n\ntesting the coverage of member(a, [b, a]) may depend on member(a, [a]).\n\n2\n\n\fwhich induces such trees. Section 4 shows how many propositional techniques can\nbe upgraded to the learning from interpretations setting (using Tilde as an illustration), and discusses why this is much harder for the classical ILP setting. Section\n5 reports on experiments with Tilde through which we empirically validate our\nclaims, Section 6 discusses some related work and in Section 7 we conclude.\n\n2\n\nThe learning setting\n\nWe first introduce the problem specification in a logical context, then discuss it in\nthe context of relational databases, and finally relate it to the standard inductive\nlogic programming setting.\nWe assume familiarity with Prolog or Datalog (see e.g. (Bratko, 1990)), and\nrelational databases (see e.g. (Elmasri and Navathe, 1989)).\nA word on our notation: in logical formulae we will adopt the Prolog convention\nthat names starting with a capital denote variables, and names starting with a\nlowercase character denote constants.\n\n2.1\n\nProblem specification\n\nIn our framework, each example is a set of facts. These facts encode the specific\nproperties of the examples in a database. Furthermore, each example is classified into one of a finite set of possible classes. One may also specify background\nknowledge in the form of a Prolog program.\nMore formally, the problem specification is:\nGiven:\n\u2022 a set of classes C (each class label c is a nullary predicate),\n\u2022 a set of classified examples E (each element of E is of the form (e, c) with e\na set of facts and c a class label)\n\u2022 and a background theory B,\nFind: a hypothesis H (a Prolog program), such that for all (e, c) \u2208 E,\n\u2022 H \u2227 e \u2227 B |= c, and\n\u2022 \u2200c\u2032 \u2208 C \u2212 {c} : H \u2227 e \u2227 B 6|= c\u2032\nThis setting is known in inductive logic programming under the label learning\nfrom interpretations (De Raedt and D\u017eeroski, 1994; De Raedt, 1997; De Raedt et\nal., 1998) (an interpretation is just a set of facts). Notice that within this setting,\none always learns first order definitions of propositional predicates (the classes). An\nimplicit assumption is that the class of an example depends on that example only,\nnot on any other examples. This is a reasonable assumption for many classification\nproblems, though not for all; it precludes, e.g., recursive concept definitions.\nExample 1 Figure 1 shows a set of pictures each of which is labelled \u2296 or \u2295. The\ntask is to classify new pictures into one of these classes by looking at the objects\nin the pictures. We call this kind of problems Bongard-problems, after Mikhail\nBongard, who used similar problems for pattern recognition tests (Bongard, 1970).\nAssuming we only consider the shape, configuration (pointing upwards or downwards, for triangles only) and relative position (objects may be inside other objects)\nof objects, the pictures in Figure 1 can be represented as follows:\n\n3\n\n\fFigure 1: Bongard problems\nPicture 1: {circle(o1), triangle(o2), points(o2, up), inside(o2, o1)}\nPicture 2: {circle(o3), triangle(o4), points(o4, up), triangle(o5),\npoints(o5, down), inside(o4, o5)}\netc.\n(The oi are constants denoting geometric objects. The exact names of these constants are of no importance; they will not be referred to in the first order hypothesis.)\nBackground knowledge might be provided to the learner, e.g., the following definitions could be in the background:\ndoubletriangle(O1,O2) :- triangle(O1), triangle(O2), O1 6= O2.\npolygon(O) :- triangle(O).\npolygon(O) :- square(O).\nWhen considering a particular example (e.g. Picture 2) in conjunction with the\nbackground knowledge it is possible to deduce additional facts in the example. For\ninstance, in Picture 2, the facts doubletriangle(o4,o5) and polygon(o4) hold.\nThe format of a hypothesis in this setting will be illustrated later.\n\n2.2\n\nLearning from Multiple Relations\n\nThe learning from interpretations setting, as introduced before, can easily be related\nto learning from multiple relations in a relational database.\nTypically, each predicate will correspond to one relation in the relational database.\nEach fact in an interpretation is a tuple in the database, and an interpretation corresponds to a part of the database (a set of tuples). Background knowledge can be\nexpressed by means of views as well as extensional tables.\nExample 2 For the Bongard example, the following database contains a description\nof the first two pictures in Figure 1 (note that an extra relation CONTAINS is\nintroduced, linking objects to pictures; this relation was implicit in the previous\nrepresentation):\nCONTAINS\n\n4\n\n\fpicture\n1\n1\n2\n2\n2\nCIRCLE\nobject\no1\no3\n\nobject\no1\no2\no3\no4\no5\nTRIANGLE\nobject\no2\no4\no5\n\nPOINTS\nobject\no2\no4\no5\n\ndirection\nup\nup\ndown\n\nINSIDE\ninner outer\no2\no1\no4\no5\n\nThe background knowledge can be defined using views, as follows: (we are assuming here that a relation SQUARE is also defined)\nDEFINE VIEW doubletriangle AS\nSELECT c1.object, c2.object\nFROM contains c1, c2\nWHERE c1.object <> c2.object\nAND c1.picture = c2.picture\nAND c1.object IN triangle\nAND c2.object IN triangle;\nDEFINE VIEW polygon AS\nSELECT object FROM triangle\nUNION\nSELECT object FROM square;\nIn this example the background knowledge is in a sense redundant: it is computed from the other relations. This is not necessarily the case. The following\nexample illustrates this. It is also a more realistic example of an application where\nmining multiple relations is useful.\nExample 3 Assume that one has a relational database describing molecules. The\nmolecules themselves are described by listing the atoms and bonds that occur in them,\nas well as some properties of the molecule as a whole. Mendelev's periodic table of\nelements is a good example of background knowledge about this domain.\nThe following tables illustrate what such a chemical database could look like:\nMENDELEV\nnumber symbol\n1\nH\n2\nHe\n3\nLi\n4\nBe\n5\nB\n6\nC\n...\n...\n\natomic weight\n1.0079\n4.0026\n6.941\n9.0121\n10.811\n12.011\n...\n\nelectrons in outer layer\n1\n2\n1\n2\n3\n4\n...\n\nMOLECULES\n\nCONTAINS\n\n5\n\n...\n\n...\n\n\fformula\nH2 O\nCO2\nCO\nCH4\nCH3 OH\n...\nATOMS\natom id\nh2o-1\nh2o-2\nh2o-3\nco2-1\n...\n\nname\nwater\ncarbon dioxide\ncarbon monoxide\nmethane\nmethanol\n...\n\nelement\nH\nO\nH\nO\n...\n\nclass\ninorganic\ninorganic\ninorganic\norganic\norganic\n...\n\nBONDS\natom id1\nh2o-1\nh2o-2\nco2-1\nco2-2\n...\n\nmolecule\nH2 O\nH2 O\nH2 O\nCO2\nCO2\n...\n\natom id2\nh2o-2\nh2o-3\nco2-2\nco2-3\n...\n\natom id\nh2o-1\nh2o-2\nh2o-3\nco2-1\nco2-2\n...\n\ntype\nsingle\nsingle\ndouble\ndouble\n...\n\nA possible classification problem here is to classify unseen molecules into organic\nand inorganic molecules, based on their chemical structure.\nNotice that this representation of examples and background knowledge upgrades\nthe typical attribute value learning representation in two respects. First, in attribute\nvalue learning an example corresponds to a single tuple for a single relation. Our\nrepresentation allows for multiple tuples in multiple relations. Second, it also allows\nfor using background knowledge.\nBy joining all the relations in a database into one huge relation, one can of\ncourse eliminate the need for learning from multiple relations. The above example\nshould make clear that in many cases this is not an option. The information in\nMendelev's table, for instance, would be duplicated many times. Moreover, unless\na multiple-instance learner is used (see e.g. (Dietterich et al., 1997)) all the atoms a\nmolecule consists of, together with their properties, have to be stored in one tuple,\nso that an indefinite number of attributes is needed; see (De Raedt, 1998) for a\nmore detailed discussion.\nWhile mining such a database is not feasible using propositional techniques, it\nis feasible using learning from interpretations. We proceed to show how a relational\ndatabase can be converted into a suitable format.\nConversion from relational database to interpretations\nConverting a relational database to a set of interpretations can be done easily and\nin a semi-automated way, as follows:\nDecide which relations are background knowledge.\nLet DB be the original database without the background relations.\nChoose an attribute in a relation that uniquely identifies the examples.\nFor each value i of that attribute:\nS := set of all tuples in DB containing that value\nrepeat\nS := S \u222a set of all tuples in DB referred to by a foreign key in S\nuntil S does not change anymore\nSi := S\nThe tuples in S are here assumed to be labelled with the name of the relation\nthey are part of. A tuple (attr1 , . . . , attrn ) of a relation R can trivially be converted\nto a fact R(attr1 , . . . , attrn ). By doing this conversion for all Si , each Si becomes\na set of facts describing an individual example i. The extensional background\n6\n\n\frelations can be converted in the same manner into one set of facts that forms the\nbackground knowledge. Background relations defined by views can be converted to\nequivalent Prolog programs.\nThe only parts in this conversion process that are hard to automate are the\nselection of the background knowledge (typically, one selects those relations where\neach tuple can be relevant for many examples) and the conversion of view definitions\nto Prolog programs. Also, the user must indicate which attribute should be chosen\nas an example identifier, as this depends on the learning task.\nExample 4 In the chemical database, we choose as example identifier the molecular\nformula. The background knowledge consists of the table MENDELEV. In order\nto build a description of H2 O, one first collects the tuples containing H2 O; these\nare present in MOLECULES and CONTAINS. These tuples contain references to\natom id's h2o-i, i = 1, 2, 3, so the tuples containing those symbols are also collected\n(tuples from ATOMS and BONDS). These again refer to the elements H and O,\nwhich are foreign keys for the MENDELEV relation. Since this relation is in the\nbackground, no further tuples are collected. Converting the tuples to facts, we get\nthe following description of H2 O:\n{molecules('H2O', water, inorganic), contains('H2O', h2o-1), contains('H2O', h2o2), contains('H2O', h2o-3), atoms(h2o-1, 'H'), atoms(h2o-2, 'O'), atoms(h2o-3,\n'H'), bonds(h2o-1, h2o-2, single), bonds(h2o-2, h2o-3, single)}\nSome variations of this algorithm can be considered. For instance, when the\nexample identifier has no meaning except that it identifies the example (as the\npicture numbers 1 and 2 for the Bongard example), this attribute can be left out\nfrom the example description.\nThe key notion in this conversion process is localization of information. It is\nassumed that for each example only a relatively small part of the database is relevant, and that this part can be localized and extracted. From now on, we will refer\nto this assumption as the locality assumption.\n\n2.3\n\nThe standard ILP setting\n\nWe now briefly discuss the standard ILP setting and how it differs from our setting.\nFor a more thorough discussion of different ILP settings and the relationships among\nthem we refer to (De Raedt, 1997).\nThe standard ILP setting (also known as learning from entailment ) is usually\nformulated as follows:\nGiven:\n\u2022 a set of positive examples E + and a set of negative examples E \u2212\n\u2022 and a background theory B,\nFind: a hypothesis H (a Prolog program), such that\n\u2022 \u2200e \u2208 E + : H \u2227 B |= e, and\n\u2022 \u2200e \u2208 E \u2212 : H \u2227 B 6|= e\nNote that in this setting, an example e is a fact (or clause) that is to be explained by H \u2227 B, while in the learning from interpretations setting a property\nof the example (its class) is to be explained by H \u2227 B \u2227 e. Thus, the latter setting explicitates the separation between example-specific information and general\nbackground information.\nThe problem specification as given above is natural for the standard ILP setting,\nwhere one could, for instance, give the following examples for the predicate member:\n7\n\n\f+\n+\n+\n-\n\n:\n:\n:\n:\n:\n:\n\nmember(a,\nmember(d,\nmember(d,\nmember(b,\nmember(a,\nmember(d,\n\n[a,b,c]).\n[e,d,c,b]).\n[d,c,b]).\n[a,c,d]).\n[]).\n[c,b]).\n\nand expect the ILP system to come up with the following definition:\nmember(X, [X|Y]).\nmember(X, [Y|Z]) :- member(X,Z).\nNote that the class of an example (i.e., its truth value) now depends on the class\nof other examples; e.g., the class of member(d, [e,d,c,b]) depends on the class\nof member(d, [d,c,b]), which is a different example. Because of this property, it\nis in general not possible to find a small subset of the database that is relevant for\na single example, i.e., local coverage tests cannot be used. Results from computational learning theory confirm that learning hypotheses in this setting generally is\nintractable (see e.g. (D\u017eeroski et al., 1992; Cohen, 1995; Cohen and Page, 1995)).\nSince in learning from interpretations the class of an example is assumed to\nbe independent of other examples, this setting is less powerful than the standard\nILP setting (e.g., for what concerns recursion). With this loss of power comes a\ngain in efficiency, through local coverage tests. The interesting point is that the\nfull power of standard ILP is not used for most practical applications, and learning\nfrom interpretations usually turns out to be sufficient for practical applications, see\ne.g. the proceedings of the ILP workshops and conferences of the last few years (De\nRaedt, 1996; Muggleton, 1997; Lavra\u010d and D\u017eeroski, 1997; Page, 1998).\n\nTilde: Induction of First-Order Logical Decision Trees\n\n3\n\nIn this section, we discuss one specific ILP system that learns from interpretations,\ncalled Tilde (which stands for Top-down Induction of Logical DEcision trees). This\nsystem will be used to illustrate the topics discussed in the following sections.\nWe first introduce the hypothesis representation formalism used by Tilde, then\ndiscuss an algorithm for the induction of hypotheses in this formalism.\n\n3.1\n\nFirst order logical decision trees\n\nWe will use first order logical decision trees for representing hypotheses. These are\nan upgrade of the well-known propositional decision trees to first order learning.\nA first order logical decision tree (FOLDT) is a binary decision tree in which\n\u2022 the nodes of the tree contain a conjunction of literals\n\u2022 different nodes may share variables, under the following restriction: a variable\nthat is introduced in a node (which means that it does not occur in higher\nnodes) must not occur in the right branch of that node. The need for this\nrestriction follows from the semantics of the tree. A variable X that is introduced in a node, is quantified existentially within the conjunction of that\nnode. The right subtree is only relevant when the conjunction fails (\"there is\nno such X\"), in which case further reference to X is meaningless.\nAn example of such a tree is shown in Figure 2.\n\n8\n\n\ftriangle(X)\n\ninside(X,Y)\n\nFigure 2: A first order logical decision tree that allows to discriminate the two\nclasses for the Bongard problem shown in Figure 1.\nFirst order logical decision trees can be converted to normal logic programs (i.e.\nlogic programs that allow negated literals in the body of a clause) and to Prolog\nprograms. In the latter case the Prolog program represents a first order decision\nlist, i.e. an ordered set of rules where a rule is only relevant if none of the rules\nbefore it succeed. Each clause in such a Prolog program ends with a cut. We refer\nto (Blockeel and De Raedt, 1998) for more information on the relationship between\nfirst order decision trees, first order decision lists and logic programs.\nThe Prolog program equivalent to the tree in Figure 2 is2\nclass(pos) :- triangle(X), inside(X,Y), !.\nclass(neg) :- triangle(X), !.\nclass(neg).\nFigure 3 shows how to use FOLDTs for classification. We use the following\nnotation: a tree T is either a leaf with class c, in which case we write T = leaf(c),\nor it is an internal node with conjunction conj, left branch left and right branch\nright, in which case we write T = inode(conj, left, right ).\nBecause an example e is a Prolog program, a test in a node corresponds to\nchecking whether a query \u2190 C succeeds in e \u2227 B (with B the background knowledge). Note that it is not sufficient to use for C the conjunction conj in the node\nitself. Since conj may share variables with nodes higher in the tree, C consists\nof several conjunctions that occur in the path from the root to the current node.\nMore specifically, C is of the form Q \u2227 conj, where Q is the conjunction of all the\nconditions that occur in those nodes on the path from the root to this node where\nthe left branch was chosen. We call \u2190 Q the associated query of the node.\nWhen an example is sorted to the left, Q is updated by adding conj to it.\nWhen sorting an example to the right, Q need not be updated: a failed test never\nintroduces new variables. E.g., if in Figure 2 an example is sorted down the tree, in\nthe node containing inside(X,Y) the correct test is triangle(X), inside(X,Y);\nit is not correct to test inside(X,Y) on its own.\n\n3.2\n\nThe Tilde system\n\nFirst order logical decision trees can be induced in very much the same manner as\npropositional decision trees. The generic algorithm for this is usually referred to\n2 The Prolog program entails class(c) instead of c, in order to ensure that the cuts have the\nintended meaning; this is a merely syntactical difference with the original task formulation.\n\n9\n\n\fprocedure classify(e : example) returns class:\nQ := true\nN := root\nwhile N 6= leaf(c) do\nlet N = inode(conj, lef t, right)\nif Q \u2227 conj succeeds in e \u2227 B\nthen Q := Q \u2227 conj\nN := lef t\nelse N := right\nreturn c\nFigure 3: Classification of an example using an FOLDT (with background knowledge B)\n\nprocedure buildtree(T : tree, E: set of examples, Q: query):\n\u2190 Qb := element of \u03c1(\u2190 Q) with highest gain (or gain ratio)\nif \u2190 Qb is not good /* e.g. does not yield any gain at all */\nthen T := leaf(majority class(E))\nelse\nconj := Qb \u2212 Q\nE1 := {e \u2208 E| \u2190 Qb succeeds in e \u2227 B}\nE2 := {e \u2208 E| \u2190 Qb fails in e \u2227 B}\nbuildtree(left, E1 , Qb )\nbuildtree(right, E2 , Q)\nT := inode(conj, left, right)\nprocedure Tilde(T : tree, E: set of examples):\nbuildtree(T , E, true)\nFigure 4: Algorithm for first-order logical decision tree induction\n\n10\n\n\fas TDIDT: top-down induction of decision trees. Examples of systems using this\napproach are C4.5 (Quinlan, 1993a) and CART (Breiman et al., 1984).\nThe algorithm we use for inducing first order decision trees is shown in Figure 4.\nThe Tilde system (Blockeel and De Raedt, 1998) is an implementation of this\nalgorithm that is based on C4.5. It uses the same heuristics, the same post-pruning\nalgorithm, etc.\nThe main point where our algorithm differs from C4.5 is in the computation of\nthe set of tests to be considered at a node. C4.5 only considers tests comparing\nan attribute with a value. Tilde, on the other hand, generates possible tests by\nmeans of a user-defined refinement operator. Roughly, this operator specifies, given\nthe associated query of a node, which literals or conjunctions can be added to the\nquery.\nMore specifically, the refinement operator is a refinement operator under \u03b8-subsumption (Plotkin, 1970; Muggleton and De Raedt, 1994). Such an operator \u03c1 maps\nclauses onto sets of clauses, such that for any clause c and \u2200c\u2032 \u2208 \u03c1(c), c \u03b8-subsumes\nc\u2032 . A clause c1 \u03b8-subsumes another clause c2 if and only if there exists a variable\nsubstitution \u03b8 such that c1 \u03b8 \u2286 c2 . The operator could for instance add literals to\nthe clause, or unify several variables in it. The use of such refinement operators is\nstandard practice in ILP.\nIn order to refine a node with associated query \u2190 Q, Tilde computes \u03c1(\u2190 Q)\nand chooses the query \u2190 Qb \u2208 \u03c1(\u2190 Q) that results in the best split. The best split\nis the one that maximizes a certain quality criterion; in the case of Tilde this is by\ndefault the information gain ratio, as defined by Quinlan (1993a). The conjunction\nput in the node consists of Qb \u2212 Q, i.e., the literals that have been added to Q in\norder to produce Qb .\nExample 5 Consider the tree in Figure 2. Assuming that the root node has already\nbeen filled in with the test triangle(X), how does Tilde process the left child\nof it? This child has as associated query \u2190triangle(X). Tilde now generates\n\u03c1(\u2190 triangle(X)). According to the language bias specified by the user (see below),\na possible result could be (we use semicolons to separate the elements of \u03c1, as the\ncomma denotes a conjunction in Prolog)\n\u03c1(\u2190 triangle(X)) = { \u2190\n\u2190\n\u2190\n\u2190\n\ntriangle(X),\ntriangle(X),\ntriangle(X),\ntriangle(X),\n\ninside(X,Y);\ninside(Y,X);\nsquare(Y);\ncircle(Y) }\n\nAssuming the best of these refinements is Qb = triangle(X), inside(X,Y) the\nconjunction put in the node is Qb \u2212 Q = inside(X,Y).\nLanguage bias\nWhile propositional systems usually have a fixed language bias, most ILP systems\nmake use of a language bias that has been provided by the user. The language bias\nspecifies what kind of hypotheses are allowed; in the case of Tilde: what kind of\nliterals or conjunctions of literals can be put in the nodes of the tree. This bias\nfollows from the refinement operator, so it is sufficient to specify the latter. The\nspecific refinement operator that is to be used is defined by the user in a Progollike manner (Muggleton, 1995). A set of facts of the form rmode(n: conjunction)\nis provided, indicating which conjunctions can be added to a query, the maximal\nnumber of times the conjunction can be added (i.e. the maximal number of times it\ncan occur in any path from root to leaf, n), and the modes and types of its variables.\nTo illustrate this, we return to the example of the Bongard problems. A suitable\nrefinement operator definition in this case would be\n11\n\n\frmode(5:\nrmode(5:\nrmode(5:\nrmode(5:\nrmode(5:\nrmode(5:\nrmode(5:\n\ntriangle(+-V)).\nsquare(+-V)).\ncircle(+-V)).\ninside(+V,+-W)).\ninside(-V,+W)).\nconfig(+V,up)).\nconfig(+V,down)).\n\nThe mode of an argument is indicated by a +, \u2212 or +\u2212 sign before a variable.\n+ stands for input: the variable should already occur in the associated query of the\nnode where the test is put. \u2212 stands for output: the variable has to be one that\ndoes not occur yet. +\u2212 means that the argument can be both input and output;\ni.e. the variable can be a new one or an already existing one. Note that the names\nof the variables in the rmode facts are formal names; when the literal is added to\na clause actual variable names are substituted for them. Also note that a literal\ncan have multiple modes, e.g. the above facts specify that at least one of the two\narguments of inside has to be input.\nThis rmode definition tells Tilde that a test in a node may consist of checking whether an object that has already been referred to has a certain shape (e.g.\ntriangle(X) with X an already existing variable), checking whether there exists an\nobject with a certain shape in the picture (e.g. triangle(Y) with Y not occurring\nin the associated query), testing the configuration (up or down) of a certain object,\nand so on. At most 5 literals of a certain type can occur on any path from root to\nleaf (this is indicated by the 5 in the rmode facts).\nThe decision tree shown in Figure 2 conforms to this specification. When Tilde\nbuilds this tree, in the root node only the tests triangle(X), square(X) and\ncircle(X) are considered, because each other test requires some variable to occur in the associated query of the node (which for the root node is true). The left\nchild node of the root has as associated query \u2190 triangle(X), which contains one\nvariable X, hence the tests that are considered for this node are:\ntriangle(X)\nsquare(X)\ncircle(X)\n\ntriangle(Y)\nsquare(Y)\ncircle(Y)\n\ninside(X,Y)\ninside(Y,X)\n\npoints(X,up)\npoints(X,down)\n\nAssuming that inside(X,Y) yields the best split, this literal is put in the node.\nIn addition to rmodes, so-called lookahead specifications can be provided. These\nallow Tilde to perform several successive refinement steps at once. This alleviates\nthe well-known problem in ILP (see e.g. (Quinlan, 1993b)) that a refinement may\nnot yield any gain, but may introduce new variables that are crucial for classification. By performing successive refinement steps at once, Tilde can look ahead in\nthe refinement lattice and discover such situations.\nFor instance, lookahead(triangle(T), points(T,up)) specifies that whenever the literal triangle(T) is considered as possible addition to the current associated query, additional refinement by adding points(T,up) should be tried in the\nsame refinement step. Thus, both triangle(T) and triangle(T), points(T,up)\nwould be considered as possible addition. This is useful because normally Tilde can\nconstruct the test triangle(T), points(T,up) only by first putting triangle(T)\nin the node, then putting points(T,up) in its left child node. But if triangle(X)\nalready occurs in the associated query, then triangle(T) cannot yield any gain (if\nyou already know that there is a triangle, the question \"is there a triangle\" will\nnot give you new information) and hence would never be selected, and this would\nprevent points(T,up) from being added as well.\nThis lookahead method is very similar to lookahead methods that have been\nproposed for propositional decision tree learners. While for propositional systems\n12\n\n\fthe advantage of lookahead is generally considered to be marginal, it is much greater\nin ILP because of the occurrence of variables.\nWe finally mention that Tilde handles numerical data by means of a discretization algorithm that is based on Fayyad and Irani's (1993) and Dougherty et al.'s\n(1995) work, but extends it to first order logic (Van Laer et al., 1997). The algorithm accepts input of the form discretize(Query, Var), with Var a variable\noccurring in Query. It runs Query in all the examples, collecting all instantiations\nof Var that can be found, and finally generates discretization thresholds based on\nthis set of instantiations. Since this discretization procedure is not crucial to this\npaper, we refer to (Van Laer et al., 1997; Blockeel and De Raedt, 1997) for more\ndetails.\nInput Format\nA data set is presented to Tilde in the form of a set of interpretations. Each\ninterpretation consists of a number of Prolog facts, surrounded by a begin and end\nline. The background knowledge is simply a Prolog program. Examples of this will\nbe shown in Section 5.\nApplications of Tilde\nAlthough the above discussion of Tilde takes the viewpoint of induction of classifiers, the use of first order logical decision trees is not limited to classification.\nNumerical predictions can be made by storing numbers instead of classes in the\nleaves; such trees are usually called regression trees. Another task that is important for data mining, is clustering. Induction of cluster hierarchies can also be done\nusing a TDIDT approach, as is explained in (Blockeel et al., 1998).\nIt should be clear, therefore, that the techniques that will be described later in\nthis text should not be seen as specific for the classification context. They have a\nmuch broader application domain.\n\n4\n\nUpgrading Propositional KDD Techniques for\nTilde\n\nIn this section we discuss how existing propositional KDD techniques can be upgraded to first order learning in our setting. The Tilde system will serve as a case\nstudy here. Indeed, all of the techniques proposed below (except sampling) have\nbeen implemented in Tilde. We stress, however, that the methodology of upgrading KDD techniques is not specific for Tilde, nor for induction of decision trees. It\ncan also be used for rule induction, discovery of association rules, and other kinds\nof discovery. Systems such as Claudien (De Raedt and Dehaspe, 1997), ICL (De\nRaedt and Van Laer, 1995) and Warmr (Dehaspe and De Raedt, 1997) are illustrations of this. Both learn from interpretations and upgrade propositional techniques.\nICL learns first order rule sets, upgrading the techniques used in CN2, and Warmr\nlearns a first order equivalent of association rules (\"association rules over multiple\nrelations\"). Warmr has been designed specifically for large databases and employs\nan efficient algorithm that is an upgrade of Apriori (Agrawal et al., 1996).\n\n4.1\n\nDifferent Implementations of Tilde\n\nWe discuss two different implementations of Tilde: one is a straightforward implementation, following closely the TDIDT algorithm. The other is a more sophisticated implementation that aims specifically at handling large data sets; it is\n\n13\n\n\ffor each refinement \u2190 Qi :\n/* counter[true] and counter[false] are class distributions,\ni.e. arrays mapping classes onto their frequencies */\nfor each class c : counter[true][c] := 0, counter[false][c] := 0\nfor each example e:\nif \u2190 Qi succeeds in e\nthen increase counter[true][class(e)] by 1\nelse increase counter[false][class(e)] by 1\nsi := weighted average class entropy(counter[true], counter[false])\nQb := that Qi for which si is minimal /* highest gain */\nFigure 5: Computation of the best test Qb in Tildeclassic.\nbased on work by Mehta et al. (1996) , and as such is our first example of how\npropositional techniques can be upgraded.\n4.1.1\n\nA straightforward implementation: Tildeclassic\n\nThe original Tilde implementation, which we will refer to as Tildeclassic, is based\non the algorithm shown in Figure 4. This is the most straightforward way of implementing TDIDT.\nNoteworthy characteristics are that the tree is built depth-first, and that the\nbest test is chosen by enumerating the possible tests and for each test computing\nits quality (to this aim the test needs to be evaluated on every single example), as\nis shown in Figure 5. This algorithm should be seen as a detailed description of line\n6 in Figure 4.\nNote that with this implementation, it is crucial that fetching an example from\nthe database in order to query it is done as efficiently as possible, because this\noperation is inside the innermost loop. For this reason, Tildeclassic loads all data\ninto main memory when it starts up. Localization is then achieved by using the\nmodule system of the Prolog engine in which Tilde runs. Each example is loaded\ninto a different module, and accessing an example is done by changing the currently\nactive module, which is a very cheap operation. One could also load all the examples\ninto one module; no example selection is necessary then, and all data can always\nbe accessed directly. The disadvantage is that the relevant data needs to be looked\nup in a large set of data, so that a good indexing scheme is necessary in order to\nmake this approach efficient. We will return to this in the section on experiments.\nWe point out that, when examples are loaded into different modules, Tildeclassic\npartially exploits the locality assumption (in that it handles each individual example independently from the others, but still loads all the examples in main memory).\nIt does not exploit this assumption at all when all the examples are loaded into one\nmodule.\n4.1.2\n\nA more sophisticated implementation: TildeLDS\n\nMehta et al. (1996) proposed an alternative implementation of TDIDT that is\noriented towards mining large databases. With their approach, the database is\naccessed less intensively, which results in an important efficiency gain. We have\nadopted this approach for an alternative implementation of Tilde, which we call\nTildeLDS (LDS stands for Large Data Sets).\nThe alternative algorithm is shown in Figure 6. It differs from Tildeclassic in\nthat the tree is now built breadth-first, and examples are loaded into main memory\n\n14\n\n\fprocedure TildeLDS:\nS := {root}\nwhile S 6= \u03c6 do\n/* add one level to the tree */\nfor each example e that is not covered by a leaf node:\nload e\nN := the node in S that covers e\n\u2190 Q := associated query(N )\nfor each refinement \u2190 Qi of \u2190 Q:\nif \u2190 Qi succeeds in e\nthen increase counter[N ,i,true][class(e)] by 1\nelse increase counter[N ,i,false][class(e)] by 1\nfor each node N \u2208 S :\nremove N from S\n\u2190 Qb := best test(N )\nif \u2190 Qb is not good\nthen N := leaf(majority class(N ))\nelse\n\u2190 Q := associated query(N )\nconj := Qb \u2212 Q\nN := inode(conj, left, right )\nadd left and right to S\nfunction best test(N : node) returns query:\n\u2190 Q := associated query(N )\nfor each refinement \u2190 Qi of \u2190 Q:\nCDl := counter[N ,i,true]\nCDr := counter[N ,i,false]\nsi := weighted average class entropy(CDl , CDr )\nQb := that Qi for which si is minimal\nreturn \u2190 Qb\nFigure 6: The TildeLDS algorithm\none at a time.\nThe algorithm works level-wise. Each iteration through the while loop will\nexpand one level of the decision tree. S contains all nodes at the current level of\nthe decision tree. To expand this level, the algorithm considers all nodes N in S.\nFor each node and for each refinement in that node, a separate counter (to compute\nclass distributions) is kept. The algorithms makes one pass through the data, during\nwhich for each example that belongs to a non-leaf node N it tests all refinements\nfor N on the example and updates the corresponding counters.\nNote that while for Tildeclassic the example loop was inside the refinement\nloop, the opposite is true now. This minimizes the number of times a new example\nmust be loaded, which is an expensive operation (in contrast with the previous\napproach where all examples were in main memory and examples only had to be\n\"selected\" in order to access them, examples are now loaded from disk). In the\ncurrent implementation each example needs to be loaded at most once per level of\nthe tree (\"at most\" because once it is in a leaf it need not be loaded anymore), hence\nthe total number of passes through the data file is equal to the depth of the tree,\nwhich is the same as was obtained for propositional learning algorithms (Mehta et\n\n15\n\n\fal., 1996).\nThe disadvantage of this algorithm is that a four-dimensional array of counters\nneeds to be stored instead of a two-dimensional one (as in Tildeclassic), because\ndifferent counters are kept for each node and for each refinement.\nCare has been taken to implement TildeLDS in such a way that the size of the\ndata set that can be handled is not restricted by internal memory (in contrast to\nTildeclassic). Whenever information needs to be stored the size of which depends\non the size of the data set, this information is stored on disk.3 When processing\na certain level of the tree, the space complexity of TildeLDS therefore contains a\ncomponent O(r * n) with n the number of nodes on that level and r the (average)\nnumber of refinements of those nodes (because counters are kept for each refinement in each node), but is constant in the number of examples. This contrasts\nwith Tildeclassic where space complexity contains a component O(m) with m the\nnumber of examples (because all examples are loaded at once).\nWhile memory now restricts the number of refinements that can be considered\nin each node and the maximal size of the tree, this restriction is unimportant in\npractice, as the number of refinements and the tree size are usually much smaller\nthan the upper bounds imposed by the available memory. Therefore TildeLDS\ntypically consumes less memory than Tildeclassic, and may be preferable even\nwhen the whole data set can be loaded into main memory.\n\n4.2\n\nSampling\n\nWhile the above implementation is one step towards handling large data sets, there\nwill always be data sets that are too large to handle. An approach that is often taken\nby data mining systems when there are too many examples, is to select a sample\nfrom the data and learn from that sample. Such techniques are incorporated in e.g.\nC4.5 (Quinlan, 1993a) and CART (Breiman et al., 1984).\nIn the standard ILP context there are some difficulties with sampling, which\ncan be ascribed to the lack of a locality assumption. When one example contains\ninformation that is relevant for another example, either both examples have to be\nincluded together in the sample, or none of them should. Otherwise, one obtains\na sample in which some examples have an incomplete description (and hence are\nnoisy). It is even possible that no good sample can be drawn because all the examples are related to one another. To the best of our knowledge sampling has received\nlittle attention inside ILP, as is also noted by F\u00fcrnkranz (1997a) and Srinivasan\n(1998).\nIf the locality assumption can be made, such sampling problems do not occur.\nPicking individual examples from the population in a random fashion, independently\nfrom one another, is sufficient to create a good sample.\nAutomatic sampling has not been included in the current Tilde implementations. We do not give this high priority because Tilde learns from a flat file of data\nwhich is produced by extracting information from a database and putting related\ninformation together (as explained earlier in this text). Sampling should be done at\nthe level of the extraction of information, not by Tilde itself. It is rather inefficient\nto convert the whole database into a flat file and then use only a part of that file,\ninstead of only converting the part of the database that will be used.\nWe do not present experiments with sampling, as the effect of sampling in data\nmining is out of the scope of this paper; instead we refer to the already existing\nstudies on this subject (see e.g. (Muggleton, 1993; F\u00fcrnkranz, 1997b; Srinivasan,\n1999)).\n3 The\n\nresults of all queries for each example are stored in this manner, so that when the best\nquery is chosen after one pass through the data, these results can be retrieved from the auxiliary\nfile, avoiding a second pass through the data.\n\n16\n\n\f4.3\n\nInternal Validation\n\nInternal validation means that a part of the learning set (the validation set) is kept\napart for validation purposes, and the rest is used as the training set for building\nthe hypothesis. Such a methodology is often followed for tuning parameters of a\nsystem or for pruning. Similar to sampling, partitioning the learning set is easy\nif the locality assumption holds, otherwise it may be hard; hence learning from\ninterpretations makes it easier to incorporate validation based techniques in an ILP\nsystem.\n\n4.4\n\nScalability\n\nDe Raedt and D\u017eeroski (1994) have shown that in the learning from interpretations\nsetting, learning first-order clausal theories is tractable. More specifically, given\nfixed bounds on the maximal length of clauses and the maximal arity of literals,\nsuch theories are polynomial-sample polynomial-time PAC-learnable. This positive\nresult is related directly to the learning from interpretations setting.\nQuinlan (1986) has shown that induction of decision trees has time complexity\nO(a * N * n) where a is the number of attributes of each example, N is the number\nof examples and n is the number of nodes in the tree. Since Tilde uses basically\nthe same algorithm as Quinlan, it inherits the linearity in the number of examples\nand in the number of nodes. The main difference between Tilde and C4.5, as we\nalready noted, is the generation of tests in a node.\nThe number of tests to be considered in a node depends on the refinement\noperator. There is no theoretical bound on this, as it is possible to define refinement\noperators that cause an infinite branching factor. In practice, useful refinement\noperators always generate a finite number of refinements, but even then this number\nmay not be bounded: the number of refinements typically increases with the length\nof the associated query of the node. Also, the time for performing one single test\non a single example depends on the complexity of that test (it is in the worst case\nexponential in the length of the conjunction).\nThus, we can say that induction of first order decision trees has time complexity\nO(N * n * t * c) with t the average number of tests performed in each node and c the\naverage time complexity of performing one test for one example, if those averages\nexist. If one is willing to accept an upper bound on the complexity of the theory\nthat is to be learned (which was done for the PAC-learning results) and defines\na finite refinement operator, both the complexity of performing a single test on a\nsingle example and the number of tests are bounded and the averages do exist.\nOur main conclusion from this is that the time complexity of Tilde is linear\nin the number of examples. This is a stronger claim than can be made for the\nstandard ILP setting. The time complexity also depends on the global complexity\nof the theory and the branching factor of the refinement operator, which are domaindependent parameters.\n\n5\n\nExperiments\n\nIn this experimental section we try to validate our claims about time complexity\nempirically, and explore some influences on scalability. More specifically, we want\nto:\n\u2022 validate the claim that when the localization assumption is exploited, induction time is linear in the number of examples (all other things being equal,\ni.e. we control for other influences on induction time such as the size of the\ntree)\n17\n\n\f\u2022 study the influence of localization on induction time (by quantifying the\namount of localization and investigating its effect on the time complexity)\n\u2022 investigate how the induction time varies with the size of the data set in more\npractical situations (if we do not control other influences; i.e. a larger data\nset may cause the learner to induce a more complex theory, which in itself has\nan effect on the induction time)\nBefore discussing the experiments themselves, we describe the data sets that we\nhave used.\n\n5.1\n5.1.1\n\nDescription of the Data Sets\nRoboCup Data Set\n\nThis is a data set containing data about soccer games played by software agents\ntraining for the RoboCup competition (Kitano et al., 1997). It contains 88594\nexamples and is 100MB large. Each example consists of a description of the state\nof the soccer terrain as observed by one specific player on a single moment. This\ndescription includes the identity of the player, the positions of all players and of the\nball, the time at which the example was recorded, the action the player performed,\nand the time at which this action was executed. Figure 7 shows one example.\nWhile this data set would allow rather complicated theories to be constructed,\nfor our experiments the language bias was very simple and consisted of a propositional language (only high-level commands are learned). This use of the data set\nreflects the learning tasks considered up till now by the people who are using it, see\n(Jacobs et al., 1998). This does not influence the validity of our results for relational\nlanguages, because the propositions are defined by the background knowledge and\ntheir truth values are computed at runtime, so the query that is really executed is\nrelational. For instance, the proposition have ball, indicating whether some player\nof the team has the ball in its possession, is computed from the position of the player\nand of the ball.\n5.1.2\n\nPoker Data Sets\n\nThe Poker data sets are artificially created data sets where each example is a description of a hand of five cards, together with a name for the hand (pair, three of\na kind, . . . ). The aim is to learn definitions for several poker concepts from a set of\nexamples. The classes that are considered here are nothing, pair, two pairs,\nthree of a kind, full house and four of a kind. This is, of course, a simplification of the real poker domain, where more classes exist and it is necessary to\ndistinguish between e.g. a pair of queens and a pair of kings; but this simplified\nversion suffices to illustrate the relevant topics and keeps learning times sufficiently\nlow to allow for reasonably extensive experiments.\nFigure 8 illustrates how one example in the poker domain can be represented. We\nhave created the data sets for this domain using a program that randomly generates\nexamples for this domain. The advantage of this approach is its flexibility: it is easy\nto create multiple training sets of increasing size, as well as an independent test set.\nAn interesting property of this data set is that some classes, e.g. four of a kind,\nare very rare, hence a large data set is needed to learn these classes (assuming the\ndata are generated randomly).\n5.1.3\n\nMutagenesis Data Set\n\nThe Mutagenesis dataset (Srinivasan et al., 1996) is a classic benchmark in Inductive\nLogic Programming. The set that has been used most often in the literature consists\n18\n\n\fbegin(model(e71)).\nplayer(my,1,-48.804436,-0.16494742,339).\nplayer(my,2,-34.39789,1.0097091,362).\nplayer(my,3,-32.628735,-18.981379,304).\nplayer(my,4,-27.1478,1.3262547,362).\nplayer(my,5,-31.55078,18.985638,362).\nplayer(my,6,-41.653893,15.659259,357).\nplayer(my,7,-48.964966,25.731588,352).\nplayer(my,8,-18.363993,3.815975,362).\nplayer(my,9,-22.757153,32.208805,347).\nplayer(my,10,-12.914384,11.456045,362).\nplayer(my,11,-10.190831,14.468359,18).\nplayer(other,1,-4.242554,11.635328,314).\nplayer(other,2,0.0,0.0,0).\nplayer(other,3,-13.048958,23.604038,299).\nplayer(other,4,0.0,0.0,0).\nplayer(other,5,2.4806643,9.412553,341).\nplayer(other,6,-9.907758,2.6764495,362).\nplayer(other,7,0.0,0.0,0).\nplayer(other,8,0.0,0.0,0).\nplayer(other,9,-4.2189126,9.296844,339).\nplayer(other,10,0.4492856,11.43235,158).\nplayer(other,11,0.0,0.0,0).\nball(-32.503292,0.81057936,362).\nmynumber(5).\nrctime(362).\nturn(137.4931640625).\nactiontime(362).\nend(model(e71)).\nFigure 7: The Prolog representation of one example in the RoboCup data set. A\nfact such as player(other,3,-13.048958,23.604038,299) means that player 3 of\nthe other team was last seen at position (-13,23.6) at time 299. A position of (0,0)\nmeans that that player has never been observed by the player that has generated this\nmodel. The action performed currently by this player is turn(137.4931640625):\nit is turning towards the ball.\n\nbegin(model(4)).\ncard(7,spades).\ncard(queen,hearts).\ncard(9,clubs).\ncard(9,spades).\ncard(ace,diamonds).\npair.\nend(model(4)).\nFigure 8: An example from the Poker data set.\n\n19\n\n\fbegin(model(1)).\npos.\natom(d1_1,c,22,-0.117).\natom(d1_2,c,22,-0.117).\natom(d1_3,c,22,-0.117).\natom(d1_4,c,195,-0.087).\natom(d1_5,c,195,0.013).\natom(d1_6,c,22,-0.117).\n(...)\natom(d1_25,o,40,-0.388).\natom(d1_26,o,40,-0.388).\nbond(d1_1,d1_2,7).\nbond(d1_2,d1_3,7).\nbond(d1_3,d1_4,7).\nbond(d1_4,d1_5,7).\nbond(d1_5,d1_6,7).\nbond(d1_6,d1_1,7).\nbond(d1_1,d1_7,1).\nbond(d1_2,d1_8,1).\nbond(d1_3,d1_9,1).\n(...)\nbond(d1_24,d1_19,1).\nbond(d1_24,d1_25,2).\nbond(d1_24,d1_26,2).\nend(model(1)).\nFigure 9: The Prolog representation of one example in the Mutagenesis data set.\nThe atom facts enumerate the atoms in the molecule. For each atom its element\n(e.g. carbon), type (e.g. carbon can occur in several configurations; each type corresponds to one specific configuration) and partial charge. The bond facts enumerate\nall the bonds between the atoms (the last argument is the type of the bond: single,\ndouble, aromatic, etc.). pos denotes that the molecule belongs to the positive class\n(i.e. is mutagenic).\nof 188 examples. Each example describes a molecule. Some of these molecules are\nmutagenic (i.e., may cause DNA mutations), others are not. The task is to predict\nthe mutagenicity of a molecule from its description.\nThe data set is a typical ILP data set in that the example descriptions are highly\nstructured, and there is background knowledge about the domain. Several levels\nof background knowledge have been studied in the literature (see again Srinivasan\net al. (1996)); for our experiments we have always used the simplest background\nknowledge, i.e. only structural information about the molecules (the atoms and\nbonds occurring in them) are available.\nFigure 9 shows a part of the description of one molecule.\n\n5.2\n\nMaterials and Settings\n\nAll experiments were performed with the two implementations of Tilde we discussed: Tildeclassic and TildeLDS. These programs are implemented in Prolog\nand run under the MasterProlog engine (formerly named ProLog-by-BIM). The\nhardware we used is a Sun Ultra-2 at 167 MHz, running the Solaris system (except\n20\n\n\fwhen stated otherwise).\nBoth Tildeclassic and TildeLDS offer the possibility to precompile the data\nfile. We exploited this feature for all our experiments. For TildeLDS this raises\nthe problem that in order to load one example at a time, a different object file has\nto be created for each example (MasterProlog offers no predicates for loading only\na part of an object file). This can be rather impractical. For this reason several\nexamples are usually compiled into one object file; a parameter called granularity\n(G) controls how many examples can be included in one object file.\nObject files are then loaded one by one by TildeLDS, which means that G\nexamples at a time are loaded into main memory (instead of one). Because of this,\nthe granularity parameter can affect the efficiency of TildeLDS. This is investigated\nin our experiments.\nBy default, a value of 10 was used for G.\n\n5.3\n5.3.1\n\nExperiment 1: Time Complexity\nAim of the Experiment\n\nAs mentioned before, induction of trees with TildeLDS should in principle have a\ntime complexity that is linear in the number of examples. With our first experiment\nwe empirically test whether our implementation indeed exhibits this property. We\nalso compare it with other approaches where the locality assumption is exploited\nless or not at all.\nWe distinguish the following approaches:\n\u2022 loading all data at once in main memory without exploiting the locality assumption (the standard ILP approach)\n\u2022 loading all data at once in main memory, exploiting the locality assumption;\nthis is what Tildeclassic does\n\u2022 loading examples one at a time in main memory; this is what TildeLDS does\nTo the best of our knowledge all ILP systems that do not learn from interpretations follow the first approach (with the exception of a few systems that access\nan external database directly instead of loading the data into main memory, e.g.\nRdt/db (Morik and Brockhausen, 1997) ; but these systems still do not make a\nlocality assumption). We can easily simulate this approach with Tildeclassic by\nspecifying all information about the examples as background knowledge. For the\nbackground knowledge no locality assumption can be made, since all background\nknowledge is potentially relevant for each example.\nThe performance of a Prolog system that works with a large database is improved significantly if indexes are built for the predicates. On the other hand,\nadding indexes for predicates creates some overhead with respect to the internal\nspace that is needed, and a lot of overhead for the compiler. The MasterProlog\nsystem by default indexes all predicates, but this indexing can be switched off. We\nhave performed experiments for the standard ILP approach both with and without indexing (thus, the first approach in the above list is actually subdivided into\n\"indexed\" and \"not indexed\").\n5.3.2\n\nMethodology\n\nSince the aim of this experiment is to determine the influence of the number of\nexamples (and only that) on time complexity, we want to control as much as possible\nother factors that might also have an influence. We have seen in Section 4.4 that\nthese other factors include the number of nodes n, the average number of tests per\n21\n\n\fnode t and the average complexity of performing one test on one single example c.\nc depends on both the complexity of the queries themselves and on the example\nsizes.\nWhen varying the number of examples for our experiments, we want to keep\nthese factors constant. This means that first of all the refinement operator should\nbe the same for all the experiments. This is automatically the case if the user\ndoes not change the refinement operator specification (the rmode facts) between\nconsecutive experiments.\nThe other factors can be kept constant by ensuring that the same tree is built in\neach experiment, and that the average complexity of the examples does not change.\nIn order to achieve this, we adopt the following methodology. We create, from a\nsmall data set, larger data sets by including each single example several times. By\nensuring that all the examples occur an equal number of times in the resulting data\nset, the class distribution, average complexity of testing a query on an example etc.\nare all kept constant. In other words, all variation due to the influence of individual\nexamples is removed.\nBecause the class distribution stays the same, the test that is chosen in each\nnode also stays the same. This is necessary to ensure that the same tree is grown,\nbut not sufficient: the stopping criterion needs to be adapted as well so that a\nnode that cannot be split further for the small data set is not split when using the\nlarger data set either. In order to achieve this, the minimal number of examples\nthat have to be covered by each leaf (which is a parameter of Tilde) is increased\nproportionally to the size of the data set.\nBy following this methodology, the mentioned unwanted influences are filtered\nout of the results.\n5.3.3\n\nMaterials\n\nWe used the Mutagenesis data set for this experiment. Other materials are as\ndescribed in Section 5.2.\n5.3.4\n\nSetup of the Experiment\n\nFour different versions of Tilde are compared:\n\u2022 Tildeclassic without locality assumption, without indexing\n\u2022 Tildeclassic without locality assumption, with indexing\n\u2022 Tildeclassic with locality assumption\n\u2022 TildeLDS\nThe first three \"versions\" are actually the same version of Tilde as far as the\nimplementation of the learning algorithm is concerned, but differ in the way the\ndata are represented and in the way the underlying Prolog system handles them.\nEach Tilde version was first run on the original data set, then on data sets\nthat contain each original example 2n times, with n ranging from 1 to 9. Table 1\nsummarizes some properties of the data sets that were obtained in this fashion.\nFor each run on each data set we have recorded the following:\n\u2022 the time needed for the induction process itself (in CPU-seconds)\n\u2022 the time needed to compile the data (in CPU-seconds). The different systems\ncompile the data in different ways (e.g. according to whether indexes need\nto be built). As compilation of the data need only be done once, even if\nafterwards several runs of the induction system are done, compilation time\n22\n\n\fTable 1: Properties\nmultiplication factor #examples\n1\n188\n2\n376\n4\n752\n8\n1504\n16\n3008\n32\n6016\n64\n12032\n128\n24064\n256\n48128\n512\n96256\nTable 2: Scaling\nmultiplication\nfactor\n1\n2\n4\n8\n16\n32\n64\n128\n256\n512\n\nof the example sets\n#facts\nsize (MB)\n10512\n0.25\n21024\n0.5\n42048\n1\n84096\n2\n168192\n4\n336384\n8\n672768\n16\n1,345,536 32\n2,691,072 65\n5,382,144 130\n\nproperties of TildeLDS in terms of the number of examples\ntime (CPU seconds)\ninduction compilation\n123\n3\n245\n6.3\n496\n12.7\n992\n25\n2026\n50\n3980\n97\n7816\n194\n15794\n391\n32634\n799\n76138\n1619\n\nmay seem less relevant. Still, it is important to see how the compilation scales\nup, since it is not really useful to have an induction method that scales linearly\nif it needs a preprocessing step that scales super-linearly.\n5.3.5\n\nDiscussion of the Results\n\nTables 2, 3, 4 and 5 give an overview of the time each Tilde version needed to\ninduce a tree for each set, as well as the time it took to compile the data into the\ncorrect format. The results are shown graphically in Figure 10. Note that both\nthe number of examples and time are indicated on a logarithmic scale. Care must\nbe taken when interpreting these graphs: a straight line does not indicate a linear\nrelationship between the variables. Indeed, if log y = n \u2217 log x, then y = xn . This\nmeans the slope of the line should be 1 in order to have a linear relationship, while 2\nindicates a quadratic relationship, and so on. In order to make it easier to recognize\na linear relationship (slope 1), the function y = x has been drawn on the graphs as\na reference.\nNote that only TildeLDS scales up well to large data sets. The other versions\nof Tilde had problems loading or compiling the data from a multiplication factor\nof 16 or 32 on.\nThe graphs and tables show that induction time is linear in the number of examples for TildeLDS, for Tildeclassic with locality, and for Tildeclassic without\nlocality but with indexing. For Tildeclassic without locality or indexing the induction time increases quadratically with the number of examples. This is not\nunexpected, as in this setting the time needed to run a test on one single example\nincreases with the size of the dataset.\n23\n\n\fTable 3: Scaling properties of Tildeclassic in terms of the number of examples\nmultiplication\ntime (CPU seconds)\nfactor\ninduction compilation\n1\n26.3\n6.8\n2\n42.5\n13.7\n4\n75.4\n27.1\n8\n148.7\n54.2\n16\n296.1\n110.1\n32\n?*\n217.1\n* Prolog engine failed to load the data\n\nTable 4: Scaling properties of Tilde without locality assumption, with indexing,\nin terms of number of examples\nmultiplication\ntime (CPU seconds)\nfactor\ninduction compilation\n1\n26.1\n20.6\n2\n45.2\n293\n4\n83.9\n572\n8\n176.7\n1640\n16\n?*\n5381\n32\n?*\n18388\n* Prolog engine failed to load the data\n\nTable 5: Scaling properties of Tilde without locality assumption, without indexing,\nin terms of number of examples\nmultiplication\ntime (CPU seconds)\nfactor\ninduction compilation\n1\n2501\n2.85\n2\n12385\n5.91\n4\n51953\n12.21\n8\n207966\n25.47\n16\n?*\n52.25\n32\n?**\n* Prolog engine failed to load the data\n** Prolog compiler failed to compile the data\n\n24\n\n\f1e+06\nLDS\nclassic\nNo locality, indexing\nNo locality, no indexing\ny=x\n\nInduction time (CPU-seconds)\n\n100000\n\n10000\n\n1000\n\n100\n\n10\n\n1\n1\n\n10\n\n100\n\n1000\n\nMultiplication factor\n10000\n\nCompilation time (CPU-seconds)\n\nLDS\nclassic\nNo locality, indexing\nNo locality, no indexing\ny=x\n1000\n\n100\n\n10\n\n1\n1\n\n10\n\n100\n\n1000\n\nMultiplication factor\n\nFigure 10: Scaling properties of TildeLDS in terms of number of examples\n\n25\n\n\fWith respect to compilation times, we note that all are linear in the size of\nthe data set, except Tildeclassic without locality and with indexing. This is in\ncorrespondence with the fact that building an index for the predicates in a deductive\ndatabase is an expensive operation, super-linear in the size of the database.\nFurthermore, the experiments confirm that Tildeclassic with locality scales as\nwell as TildeLDS with respect to time complexity, but for large data sets runs into\nproblems because it cannot load all the data.\nObserving that without indexing induction time increases quadratically, and\nwith indexing compilation time increases quadratically, we conclude that the locality\nassumption is indeed crucial to our linearity results, and that loading only a few\nexamples at a time in main memory makes it possible to handle much larger data\nsets.\n\n5.4\n5.4.1\n\nExperiment 2: The Effect of Localization\nAim of the experiment\n\nIn the previous experiment we studied the effect of the number of examples on\ntime complexity, and observed that this effect is different according to whether the\nlocality assumption is made. In this experiment we do not just distinguish between\nlocalized and not localized, but consider gradual changes in localization, and thus\ntry to quantify the effect of localization on the induction time.\n5.4.2\n\nMethodology\n\nWe can test the influence of localization on the efficiency of TildeLDS by varying\nthe granularity parameter G in TildeLDS. G is the number of examples that are\nloaded into main memory at the same time. Localization of information is stronger\nwhen G is smaller.\nThe effect of G was tested by running TildeLDS successively on the same\ndata set, under the same circumstances, but with different values for G. In these\nexperiments G ranged from 1 to 200. For each value of G both compilation and\ninduction were performed ten times; the reported times are the means of these ten\nruns.\n5.4.3\n\nMaterials\n\nWe have used three data sets: a RoboCup data set with 10000 examples, a Poker\ndata set containing 3000 examples, and the Mutagenesis data set with a multiplication factor of 8 (i.e. 1504 examples). The data sets were chosen to contain a\nsufficient number of examples to make it possible to let G vary over a relatively\nbroad range, but not more (to limit the experimentation time).\nOther materials are as described in Section 5.2.\n5.4.4\n\nDiscussion of the Results\n\nInduction times and compilation times are plotted versus granularity in Figure 11.\nIt can be seen from these plots that induction time increases approximately linearly\nwith granularity. For very small granularities, too, the induction time can increase.\nWe suspect that this effect can be attributed to an overhead of disk access (loading\nmany small files, instead of fewer larger files). A similar effect is seen when we\nlook at the compilation times: these decrease when the granularity increases, but\nasymptotically approach a constant. This again suggests an overhead caused by\ncompiling many small files instead of one large file. The fact that the observed\n\n26\n\n\feffect is smallest for Mutagenesis, where individual examples are larger, increases\nthe plausibility of this explanation.\nThis experiment clearly shows that the performance of TildeLDS strongly depends on G, and that a reasonably small value for G is preferable. It thus confirms\nthe hypothesis that localization of information is advantageous with respect to time\ncomplexity.\n\n5.5\n5.5.1\n\nExperiment 3: Practical Scaling Properties\nAim of the experiment\n\nWith this experiment we want to measure how well TildeLDS scales up in practice,\nwithout controlling any influences. This means that the tree that is induced is not\nguaranteed to be the same one or have the same size, and that a natural variation\nis allowed with respect to the complexity of the examples as well as the complexity\nof the queries. This experiment is thus meant to mimic the situations that arise in\npractice.\nSince different trees may be grown on different data sets, the quality of these\ntrees may differ. We investigate this as well.\n5.5.2\n\nMethodology\n\nThe methodology we follow is to choose some domain and then create data sets with\ndifferent sizes for this domain. TildeLDS is then run on each data set, and for each\nrun the induction time is recorded, as well as the quality of the tree (according to\ndifferent criteria, see below).\n5.5.3\n\nMaterials\n\nData sets from two domains were used: RoboCup and Poker. These domains were\nchosen because large data sets were available for them. For each domain several\ndata sets of increasing size were created.\nWhereas induction times have been measured on both data sets, predictive accuracy has been measured only for the Poker data set. This was done using a separate\ntest set of 100,000 examples, which was the same for all the hypotheses.\nFor the RoboCup data set interpretability of the hypotheses by domain experts\nis the main evaluation criterion (because these theories are used for verification of\nthe behavior of agents, see (Jacobs et al., 1998)).\nThe RoboCup experiments have been run on a SUN SPARCstation-20 at 100\nMHz; for the Poker experiments a SUN Ultra-2 at 167 MHz was used.\n5.5.4\n\nDiscussion of the Results\n\nTable 6 shows the consumed CPU-times in function of the number of examples, as\nwell as the predictive accuracy. These figures are plotted in Figure 12. Note that\nthe CPU-time graph is again plotted on a double logarithmic scale.\nWith respect to accuracy, the Poker hypotheses show the expected behavior:\nwhen more data are available, the hypotheses can predict very rare classes (for\nwhich no examples occur in smaller data sets), which results in higher accuracy.\nThe graphs further show that in the Poker domain, TildeLDS scales up linearly,\neven though more accurate (and slightly more complex) theories are found for larger\ndata sets.\nIn the RoboCup domain, the induced hypotheses were the same for all runs\nexcept the 10000 examples run. In this single case the hypothesis was more simple\nand, according to the domain expert, less informative than for the other runs. This\n\n27\n\n\f9000\nPoker\nMutagenesis\nRobocup\n\n8000\n\nInduction time (CPU-seconds)\n\n7000\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n0\n\n50\n\n100\nGranularity\n\n150\n\n200\n\n3500\nPoker\nMutagenesis\nRobocup\n\nInduction time (CPU-seconds)\n\n3000\n\n2500\n\n2000\n\n1500\n\n1000\n\n500\n\n0\n0\n\n5\n\n10\n\n15\nGranularity\n\n20\n\n25\n\n30\n\n400\nPoker\nMutagenesis\nRobocup\n\nCompilation time (CPU-seconds)\n\n350\n\n300\n\n250\n\n200\n\n150\n\n100\n\n50\n\n0\n0\n\n50\n\n100\nGranularity\n\n150\n\n200\n\nFigure 11: The effect of granularity on induction time (full range, and zoomed in\non interval [0 \u2212 30]) and compilation time\n\n28\n\n\fTable 6: Consumed CPU-time and\nin the Poker domain\n#examples compilation\n(CPU-seconds)\n300\n1.36\n1000\n4.20\n3000\n12.36\n10000\n41.94\n30000\n125.47\n100000\n402.63\n\naccuracy of hypotheses produced by TildeLDS\ninduction\n(CPU-seconds)\n288\n1021\n3231\n12325\n33394\n121266\n\naccuracy\n0.98822\n0.99844\n0.99844\n0.99976\n0.99976\n1.0\n\n1e+06\nInduction\nCompilation\nx\n\nTime (CPU-seconds)\n\n100000\n\n10000\n\n1000\n\n100\n\n10\n\n1\n100\n\n1000\n\n10000\n\n100000\n\n# examples\n1\nAccuracy\n\n0.998\n\nPredictive accuracy\n\n0.996\n\n0.994\n\n0.992\n\n0.99\n\n0.988\n100\n\n1000\n\n10000\n\n100000\n\n# examples\n\nFigure 12: Consumed CPU-time and accuracy of hypotheses produced by\nTildeLDS in the Poker domain, plotted against the number of examples\n\n29\n\n\fTable 7: Consumed CPU-time of hypotheses produced by TildeLDS in the\nRoboCup domain\n#examples compilation induction\n10000\n274\n1448 \u00b1 44\n20000\n522\n4429 \u00b1 83\n30000\n862\n7678 \u00b1 154\n40000\n1120\n9285 \u00b1 552\n50000\n1302\n6607 \u00b1 704\n60000\n1793\n13665 \u00b1 441\n70000\n1964\n29113 \u00b1 304\n80000\n2373\n28504 \u00b1 657\n88594\n2615\n50353 \u00b1 3063\n\n60000\nInduction\nCompilation\n\nTime (CPU-seconds)\n\n50000\n\n40000\n\n30000\n\n20000\n\n10000\n\n0\n10000\n\n20000\n\n30000\n\n40000\n\n50000\n# examples\n\n60000\n\n70000\n\n80000\n\n90000\n\nFigure 13: Consumed CPU-time for TildeLDS in the RoboCup domain, plotted\nagainst the number of examples\n\n30\n\n\fsuggests that in this domain a relatively small set of examples (20000) suffices to\nlearn from.\nIt is harder to see how TildeLDS scales up for the RoboCup data. Since the\nsame tree is returned in all runs except the 10000 examples run, one would expect\nthe induction times to grow linearly. However, the observed curve does not seem\nlinear, although it does not show a clear tendency to be super-linear either. Because\nlarge variations in induction time were observed, we performed these runs 10 times;\nthe estimated mean induction times are reported together with their standard errors.\nThe standard errors alone cannot explain the observed deviations, nor can variations\nin example complexity (all examples are of equal complexity in this domain).\nA possible explanation is the fact that the Prolog engine performs a number\nof tasks that are not controlled by Tilde, such as garbage collection. In specific\ncases, the Prolog engine may perform many garbage collections before expanding\nits memory space (this happens when the amount of free memory after garbage collection is always just above some threshold), and the time needed for these garbage\ncollections is included in the measured CPU-times. The MasterProlog engine is\nknown to sometimes exhibit such behavior.\nIn order to sort this out, TildeLDS would have to be reimplemented in a lowerlevel language than Prolog, where one has full control over all computations that\noccur. Such a reimplementation is planned.\nDue to the domain-dependent character of these complexity results, one should\nbe careful when generalizing them; it seems safe to conclude, however, that the\nlinear scaling property has at least a reasonable chance of occurring in practice.\n\n6\n\nRelated Work\n\nOur work is closely related to efforts in the propositional learning field to increase\nthe capability of machine learning systems to handle large databases. It has been\ninfluenced more specifically by a tutorial on data mining by Usama Fayyad, in which\nthe work of Mehta and others was mentioned (Mehta et al., 1996; Shafer et al., 1996).\nThey were the first to propose the level-wise tree building algorithm we adopted,\nand to implement it in the SLIQ (Mehta et al., 1996) and SPRINT (Shafer et al.,\n1996) systems. The main difference with our approach is that SLIQ and SPRINT\nlearn from one single relation, while TildeLDS can learn from multiple relations.\nRelated work inside ILP includes the Rdt/db system (Morik and Brockhausen,\n1997), which presents the first approach to coupling an ILP system with a relational\ndatabase management system (RDBMS). Being an ILP system, Rdt/db also learns\nfrom multiple relations. The approach followed is that a logical test that is to\nbe performed is converted into an SQL query and sent to an external relational\ndatabase management system. This approach is essentially different from ours, in\nthat it exploits as much as possible the power of the RDBMS to efficiently evaluate\nqueries. Also, there is no need for preprocessing the data. Disadvantages are that\nfor each query an external database is accessed, which is relatively slow, and that it\nis less flexible with respect to background knowledge. Furthermore, to obtain good\nperformance complex modifications to the RDBMS system (tailoring it towards\ndata mining) are needed. Preliminary experiments with coupling Claudien and\nTilde to an Oracle RDBMS confirmed these claims and caused us to abandon such\nan approach.\nWe also mention the KEPLER system (Wrobel et al., 1996) , a data mining tool\nthat provides a framework for applying a broad range of data mining systems to\ndata sets; this includes ILP systems. KEPLER was deliberately designed to be very\nopen, and systems using the learning from interpretations setting can be plugged\ninto it as easily as other systems.\n31\n\n\fAt this moment few systems use the learning from interpretations setting (De\nRaedt and Van Laer, 1995; De Raedt and Dehaspe, 1997; Dehaspe and De Raedt,\n1997). Of these the research described in (Dehaspe and De Raedt, 1997) (the\nWarmr system: finding association rules over multiple relations; see also Dehaspe\nand Toivonen's contribution in this issue) is most closely related to the work described in this paper, in the sense that there, too, an effort was made to adapt\nthe system for large databases. The focus of that text is not on the advantages of\nlearning from interpretations in general, however, but on the power of first order\nassociation rules.\nMore loosely related work inside ILP would include all efforts to make ILP systems more efficient. Since most of this work concerns ILP systems that work in the\nclassical ILP setting, the ways in which this is done usually differ substantially from\nwhat we describe in this paper. For instance, the well-known ILP system Progol\n(Muggleton, 1995) has recently been extended with caching and other efficiency\nimprovements (Cussens, 1997). Other directions are the use of sampling techniques\nand stochastic methods, such as proposed by, e.g., Srinivasan (1999) and Sebag\n(1998).\nFinally, the Tilde system is related to other systems that induce first order\ndecision trees, such as the Struct system (Watanabe and Rendell, 1991) (which\nuses a less explicitly logic-based approach) and the regression tree learner SRT\n(Kramer, 1996).\n\n7\n\nConclusions\n\nWe have argued and demonstrated empirically that the use of ILP is not limited\nto small databases, as is often assumed. Mining databases of a hundred megabytes\nwas shown to be feasible, and this does not seem to be a limit.\nThe positive results that have been obtained are due mainly to the use of the\nlearning from interpretations setting, which is more scalable than the classical ILP\nsetting and makes the link with propositional learning more clear. This means that\na lot of results obtained for propositional learning can be extrapolated to learning\nfrom interpretations. We have discussed a number of such upgrades, using the\nTildeLDS system as an illustration. The possibility to upgrade the work by Mehta\net al. (1996) has turned out to be crucial for handling large data sets. It is not\nclear how the same technique could be incorporated in a system using the classical\nILP setting.\nAlthough we obtained specific results only for a specific kind of data mining (induction of decision trees), the results are generalizable not only to other approaches\nwithin the classification context (e.g. rule based approaches) but also to other inductive tasks within the learning from interpretations setting, such as clustering,\nregression and induction of association rules.\nAcknowledgements\nNico Jacobs and Hendrik Blockeel are supported by the Flemish Institute for the\nPromotion of Scientific and Technological Research in the Industry (IWT). Luc De\nRaedt is supported by the Fund for Scientific Research, Flanders. This work is\nalso part of the European Community Esprit project no. 20237, Inductive Logic\nProgramming 2.\nThe authors thank Luc Dehaspe, Kurt Driessens, H\u00e9l\u00e8ne Legras and Jan Ramon\nfor proofreading this text, as well as the anonymous reviewers and Sa\u0161o D\u017eeroski\nfor their very valuable comments on an earlier draft.\n\n32\n\n\fReferences\n[1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A.I. Verkamo. Fast discovery of association rules. In U. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and\nR. Uthurusamy, editors, Advances in Knowledge Discovery and Data Mining,\npages 307\u2013328. The MIT Press, 1996.\n[2] H. Blockeel and L. De Raedt. Lookahead and discretization in ILP. In Proceedings of the Seventh International Workshop on Inductive Logic Programming,\nvolume 1297 of Lecture Notes in Artificial Intelligence, pages 77\u201385. SpringerVerlag, 1997.\n[3] H. Blockeel and L. De Raedt. Top-down induction of first order logical decision\ntrees. Artificial Intelligence, 101(1-2):285\u2013297, June 1998.\n[4] H. Blockeel, L. De Raedt, and J. Ramon. Top-down induction of clustering trees. In Proceedings of the 15th International Conference on Machine Learning, pages 55\u201363, 1998. http://www.cs.kuleuven.ac.be/~ml/PS/ML98-56.ps.\n[5] M. Bongard. Pattern Recognition. Spartan Books, 1970.\n[6] I. Bratko. Prolog Programming for Artificial Intelligence. Addison-Wesley,\nWokingham, England, 1990. 2nd Edition.\n[7] I. Bratko and S. Muggleton. Applications of inductive logic programming.\nCommunications of the ACM, 38(11):65\u201370, 1995.\n[8] L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classification and\nRegression Trees. Wadsworth, Belmont, 1984.\n[9] W.W. Cohen. Pac-learning recursive logic programs: Negative results. Journal\nof Artificial Intelligence Research, 2:541\u2013573, 1995.\n[10] W.W. Cohen and D. Page. Polynomial learnability and inductive logic programming: Methods and results. New Generation Computing, 13, 1995.\n[11] J. Cussens. Part-of-speech tagging using progol. In Proceedings of the Seventh\nInternational Workshop on Inductive Logic Programming, Lecture Notes in\nArtificial Intelligence, pages 93\u2013108. Springer-Verlag, 1997.\n[12] L. De Raedt, editor. Advances in Inductive Logic Programming, volume 32 of\nFrontiers in Artificial Intelligence and Applications. IOS Press, 1996.\n[13] L. De Raedt. Logical settings for concept learning. Artificial Intelligence,\n95:187\u2013201, 1997.\n[14] L. De Raedt. Attribute-value learning versus inductive logic programming:\nthe missing links (extended abstract). In D. Page, editor, Proceedings of the\nEighth International Conference on Inductive Logic Programming, volume 1446\nof Lecture Notes in Artificial Intelligence, pages 1\u20138. Springer-Verlag, 1998.\n[15] L. De Raedt, H. Blockeel, L. Dehaspe, and W. Van Laer. Three companions\nfor first order data mining. In S. D\u017eeroski and N. Lavra\u010d, editors, Inductive\nLogic Programming for Knowledge Discovery in Databases, Lecture Notes in\nArtificial Intelligence. Springer-Verlag, 1998. To appear.\n[16] L. De Raedt and L. Dehaspe. Clausal discovery. Machine Learning, 26:99\u2013146,\n1997.\n33\n\n\f[17] L. De Raedt and S. D\u017eeroski. First order jk-clausal theories are PAC-learnable.\nArtificial Intelligence, 70:375\u2013392, 1994.\n[18] L. De Raedt and W. Van Laer. Inductive constraint logic. In Klaus P. Jantke, Takeshi Shinohara, and Thomas Zeugmann, editors, Proceedings of the\nSixth International Workshop on Algorithmic Learning Theory, volume 997 of\nLecture Notes in Artificial Intelligence, pages 80\u201394. Springer-Verlag, 1995.\n[19] L. Dehaspe and L. De Raedt. Mining association rules in multiple relations.\nIn Proceedings of the Seventh International Workshop on Inductive Logic Programming, volume 1297 of Lecture Notes in Artificial Intelligence, pages 125\u2013\n132, Berlin, 1997. Springer-Verlag.\n[20] T. G. Dietterich, R. H. Lathrop, and T. Lozano-P\u00e9rez. Solving the multipleinstance problem with axis-parallel rectangles. Artificial Intelligence, 89(12):31\u201371, 1997.\n[21] J. Dougherty, R. Kohavi, and M. Sahami. Supervised and unsupervised discretization of continuous features. In A. Prieditis and S. Russell, editors, Proceedings of the Twelfth International Conference on Machine Learning. Morgan\nKaufmann, 1995.\n[22] S. D\u017eeroski, S. Muggleton, and S. Russell. PAC-learnability of determinate\nlogic programs. In Proceedings of the 5th ACM workshop on Computational\nLearning Theory, pages 128\u2013135, 1992.\n[23] R. Elmasri and S. B. Navathe. Fundamentals of Database Systems. Benjamin/Cummings, 2nd edition, 1989.\n[24] U.M. Fayyad and K.B. Irani. Multi-interval discretization of continuous-valued\nattributes for classification learning. In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, pages 1022\u20131027, San Mateo,\nCA, 1993. Morgan Kaufmann.\n[25] J. F\u00fcrnkranz. Dimensionality reduction in ILP: a call to arms. In L. De Raedt\nand S. Muggleton, editors, Proceedings of the IJCAI-97 Workshop on Frontiers\nof ILP, 1997. http://www.cs.kuleuven.ac.be/ lucdr/filp.html.\n[26] J. F\u00fcrnkranz. Noise-tolerant windowing. In M. E. Pollack, editor, Proceedings\nof the 15th International Joint Conference on Artificial Intelligence, pages 852\u2013\n857. Morgan Kaufmann, 1997.\n[27] N. Jacobs, K. Driessens, and L. De Raedt. Using ILP systems for verification and validation of multi agent systems. In Proceedings of the Eighth International Conference on Inductive Logic Programming, volume 1446, pages\n145\u2013154. Springer-Verlag, 1998.\n[28] H. Kitano, M. Veloso, H. Matsubara, M. Tambe, S. Coradeschi, I. Noda,\nP. Stone, E. Osawa, and M. Asada. The robocup synthetic agent challenge\n97. In Proceedings of the 15th International Joint Conference on Artificial\nIntelligence, pages 24\u201329. Morgan Kaufmann, 1997.\n[29] Stefan Kramer. Structural regression trees. In Proceedings of the Thirteenth National Conference on Artificial Intelligence, pages 812\u2013819, Cambridge/Menlo Park, 1996. AAAI Press/MIT Press.\n[30] N. Lavra\u010d and S. D\u017eeroski, editors. Proceedings of the Seventh International\nWorkshop on Inductive Logic Programming, volume 1297 of Lecture Notes in\nArtificial Intelligence. Springer-Verlag, 1997.\n34\n\n\f[31] M. Mehta, R. Agrawal, and J. Rissanen. SLIQ: A fast scalable classifier for\ndata mining. In Proceedings of the Fifth International Conference on Extending\nDatabase Technology, 1996.\n[32] K. Morik and P. Brockhausen. A multistrategy approach to relational discovery\ni n databases. Machine Learning, 27(3):287\u2013312, 1997.\n[33] S. Muggleton. Optimal layered learning: a PAC approach to incremental sampling. In Proceedings of the 4th conference on algorithmic learning theory.\nOhmsma, Tokyo, Japan, 1993. Invited paper.\n[34] S. Muggleton. Inverse entailment and Progol. New Generation Computing,\nSpecial issue on Inductive Logic Programming, 13(3-4):245\u2013286, 1995.\n[35] S. Muggleton, editor. Proceedings of the Sixth International Workshop on Inductive Logic Programming, volume 1314 of Lecture Notes in Artificial Intelligence. Springer-Verlag, 1997.\n[36] S. Muggleton and L. De Raedt. Inductive logic programming : Theory and\nmethods. Journal of Logic Programming, 19,20:629\u2013679, 1994.\n[37] D. Page, editor. Proceedings of the Eighth International Conference on Inductive Logic Programming, volume 1446 of Lecture Notes in Artificial Intelligence.\nSpringer-Verlag, 1998.\n[38] G. Plotkin. A note on inductive generalization. In B. Meltzer and D. Michie,\neditors, Machine Intelligence, volume 5, pages 153\u2013163. Edinburgh University\nPress, 1970.\n[39] J. Ross Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann\nseries in machine learning. Morgan Kaufmann, 1993.\n[40] J.R. Quinlan. Induction of decision trees. Machine Learning, 1:81\u2013106, 1986.\n[41] J.R. Quinlan. Learning logical definitions from relations. Machine Learning,\n5:239\u2013266, 1990.\n[42] J.R. Quinlan. FOIL: A midterm report. In P. Brazdil, editor, Proceedings of\nthe 6th European Conference on Machine Learning, Lecture Notes in Artificial\nIntelligence. Springer-Verlag, 1993.\n[43] J.C. Shafer, R. Agrawal, and M. Mehta. SPRINT: A scalable parallel classifier\nfor data mining. In Proceedings of the 22th International Conference on Very\nLarge Databases, 1996.\n[44] A. Srinivasan. A study of two sampling methods for analysing large datasets\nwith ILP. Data Mining and Knowledge Discovery, 3(1):95\u2013123, 1999.\n[45] A. Srinivasan, S.H. Muggleton, M.J.E. Sternberg, and R.D. King. Theories\nfor mutagenicity: A study in first-order and feature-based induction. Artificial\nIntelligence, 85(1,2), 1996.\n[46] W. Van Laer, L. De Raedt, and S. D\u017eeroski. On multi-class problems and\ndiscretization in inductive logic programming. In Zbigniew W. Ras and Andrzej Skowron, editors, Proceedings of the Tenth International Symposium on\nMethodologies for Intelligent Systems, volume 1325 of Lecture Notes in Artificial Intelligence, pages 277\u2013286. Springer-Verlag, 1997.\n\n35\n\n\f[47] L. Watanabe and L. Rendell. Learning structural decision trees from examples. In Proceedings of the 12th International Joint Conference on Artificial\nIntelligence, pages 770\u2013776, 1991.\n[48] S. Wrobel, D. Wettschereck, E. Sommer, and W. Emde. Extensibility in data\nmining systems. In Proceedings of the Second International Conference on\nKnowledge Discovery and Data Mining (KDD-96). AAAI Press, 1996.\n\n36\n\n\f"}