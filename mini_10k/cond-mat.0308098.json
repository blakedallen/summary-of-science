{"id": "http://arxiv.org/abs/cond-mat/0308098v2", "guidislink": true, "updated": "2006-02-06T07:20:36Z", "updated_parsed": [2006, 2, 6, 7, 20, 36, 0, 37, 0], "published": "2003-08-06T01:48:50Z", "published_parsed": [2003, 8, 6, 1, 48, 50, 2, 218, 0], "title": "Population coding by globally coupled phase oscillators", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0308053%2Ccond-mat%2F0308471%2Ccond-mat%2F0308161%2Ccond-mat%2F0308139%2Ccond-mat%2F0308233%2Ccond-mat%2F0308605%2Ccond-mat%2F0308395%2Ccond-mat%2F0308402%2Ccond-mat%2F0308551%2Ccond-mat%2F0308350%2Ccond-mat%2F0308045%2Ccond-mat%2F0308381%2Ccond-mat%2F0308296%2Ccond-mat%2F0308358%2Ccond-mat%2F0308580%2Ccond-mat%2F0308416%2Ccond-mat%2F0308258%2Ccond-mat%2F0308086%2Ccond-mat%2F0308138%2Ccond-mat%2F0308224%2Ccond-mat%2F0308514%2Ccond-mat%2F0308008%2Ccond-mat%2F0308599%2Ccond-mat%2F0308388%2Ccond-mat%2F0308533%2Ccond-mat%2F0308034%2Ccond-mat%2F0308009%2Ccond-mat%2F0308300%2Ccond-mat%2F0308345%2Ccond-mat%2F0308478%2Ccond-mat%2F0308194%2Ccond-mat%2F0308436%2Ccond-mat%2F0308098%2Ccond-mat%2F0308267%2Ccond-mat%2F0308341%2Ccond-mat%2F0308430%2Ccond-mat%2F0308114%2Ccond-mat%2F0308455%2Ccond-mat%2F0308558%2Ccond-mat%2F0308415%2Ccond-mat%2F0308125%2Ccond-mat%2F0308387%2Ccond-mat%2F0308078%2Ccond-mat%2F0308535%2Ccond-mat%2F0308363%2Ccond-mat%2F0308132%2Ccond-mat%2F0308594%2Ccond-mat%2F0308538%2Ccond-mat%2F0308600%2Ccond-mat%2F0308245%2Ccond-mat%2F0308147%2Ccond-mat%2F0308604%2Ccond-mat%2F0308280%2Ccond-mat%2F0308273%2Ccond-mat%2F0308433%2Ccond-mat%2F0308118%2Ccond-mat%2F0308380%2Ccond-mat%2F0308421%2Ccond-mat%2F0308373%2Ccond-mat%2F0308177%2Ccond-mat%2F0308547%2Ccond-mat%2F0308093%2Ccond-mat%2F0308297%2Ccond-mat%2F0308225%2Ccond-mat%2F0308494%2Ccond-mat%2F0308352%2Ccond-mat%2F0308270%2Ccond-mat%2F0308143%2Ccond-mat%2F0308222%2Ccond-mat%2F0308372%2Ccond-mat%2F0308018%2Ccond-mat%2F0308570%2Ccond-mat%2F0308414%2Ccond-mat%2F0308083%2Ccond-mat%2F0308337%2Ccond-mat%2F0308140%2Ccond-mat%2F0308179%2Ccond-mat%2F0308106%2Ccond-mat%2F0308627%2Ccond-mat%2F0308499%2Ccond-mat%2F0308458%2Ccond-mat%2F0308087%2Ccond-mat%2F0308079%2Ccond-mat%2F0308268%2Ccond-mat%2F0308249%2Ccond-mat%2F0308408%2Ccond-mat%2F0308052%2Ccond-mat%2F0308346%2Ccond-mat%2F0308572%2Ccond-mat%2F0308030%2Ccond-mat%2F0308343%2Ccond-mat%2F0308423%2Ccond-mat%2F0308545%2Ccond-mat%2F0308431%2Ccond-mat%2F0308322%2Ccond-mat%2F0308149%2Ccond-mat%2F0308214%2Ccond-mat%2F0308227%2Ccond-mat%2F0308493%2Ccond-mat%2F0308606%2Ccond-mat%2F0308399&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Population coding by globally coupled phase oscillators"}, "summary": "A system of globally coupled phase oscillators subject to an external input\nis considered as a simple model of neural circuits coding external stimulus.\nThe information coding efficiency of the system in its asynchronous state is\nquantified using Fisher information. The effect of coupling and noise on the\ninformation coding efficiency in the stationary state is analyzed. The\nrelaxation process of the system after the presentation of an external input is\nalso studied. It is found that the information coding efficiency exhibits a\nlarge transient increase before the system relaxes to the final stationary\nstate.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0308053%2Ccond-mat%2F0308471%2Ccond-mat%2F0308161%2Ccond-mat%2F0308139%2Ccond-mat%2F0308233%2Ccond-mat%2F0308605%2Ccond-mat%2F0308395%2Ccond-mat%2F0308402%2Ccond-mat%2F0308551%2Ccond-mat%2F0308350%2Ccond-mat%2F0308045%2Ccond-mat%2F0308381%2Ccond-mat%2F0308296%2Ccond-mat%2F0308358%2Ccond-mat%2F0308580%2Ccond-mat%2F0308416%2Ccond-mat%2F0308258%2Ccond-mat%2F0308086%2Ccond-mat%2F0308138%2Ccond-mat%2F0308224%2Ccond-mat%2F0308514%2Ccond-mat%2F0308008%2Ccond-mat%2F0308599%2Ccond-mat%2F0308388%2Ccond-mat%2F0308533%2Ccond-mat%2F0308034%2Ccond-mat%2F0308009%2Ccond-mat%2F0308300%2Ccond-mat%2F0308345%2Ccond-mat%2F0308478%2Ccond-mat%2F0308194%2Ccond-mat%2F0308436%2Ccond-mat%2F0308098%2Ccond-mat%2F0308267%2Ccond-mat%2F0308341%2Ccond-mat%2F0308430%2Ccond-mat%2F0308114%2Ccond-mat%2F0308455%2Ccond-mat%2F0308558%2Ccond-mat%2F0308415%2Ccond-mat%2F0308125%2Ccond-mat%2F0308387%2Ccond-mat%2F0308078%2Ccond-mat%2F0308535%2Ccond-mat%2F0308363%2Ccond-mat%2F0308132%2Ccond-mat%2F0308594%2Ccond-mat%2F0308538%2Ccond-mat%2F0308600%2Ccond-mat%2F0308245%2Ccond-mat%2F0308147%2Ccond-mat%2F0308604%2Ccond-mat%2F0308280%2Ccond-mat%2F0308273%2Ccond-mat%2F0308433%2Ccond-mat%2F0308118%2Ccond-mat%2F0308380%2Ccond-mat%2F0308421%2Ccond-mat%2F0308373%2Ccond-mat%2F0308177%2Ccond-mat%2F0308547%2Ccond-mat%2F0308093%2Ccond-mat%2F0308297%2Ccond-mat%2F0308225%2Ccond-mat%2F0308494%2Ccond-mat%2F0308352%2Ccond-mat%2F0308270%2Ccond-mat%2F0308143%2Ccond-mat%2F0308222%2Ccond-mat%2F0308372%2Ccond-mat%2F0308018%2Ccond-mat%2F0308570%2Ccond-mat%2F0308414%2Ccond-mat%2F0308083%2Ccond-mat%2F0308337%2Ccond-mat%2F0308140%2Ccond-mat%2F0308179%2Ccond-mat%2F0308106%2Ccond-mat%2F0308627%2Ccond-mat%2F0308499%2Ccond-mat%2F0308458%2Ccond-mat%2F0308087%2Ccond-mat%2F0308079%2Ccond-mat%2F0308268%2Ccond-mat%2F0308249%2Ccond-mat%2F0308408%2Ccond-mat%2F0308052%2Ccond-mat%2F0308346%2Ccond-mat%2F0308572%2Ccond-mat%2F0308030%2Ccond-mat%2F0308343%2Ccond-mat%2F0308423%2Ccond-mat%2F0308545%2Ccond-mat%2F0308431%2Ccond-mat%2F0308322%2Ccond-mat%2F0308149%2Ccond-mat%2F0308214%2Ccond-mat%2F0308227%2Ccond-mat%2F0308493%2Ccond-mat%2F0308606%2Ccond-mat%2F0308399&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A system of globally coupled phase oscillators subject to an external input\nis considered as a simple model of neural circuits coding external stimulus.\nThe information coding efficiency of the system in its asynchronous state is\nquantified using Fisher information. The effect of coupling and noise on the\ninformation coding efficiency in the stationary state is analyzed. The\nrelaxation process of the system after the presentation of an external input is\nalso studied. It is found that the information coding efficiency exhibits a\nlarge transient increase before the system relaxes to the final stationary\nstate."}, "authors": ["Hiroya Nakao"], "author_detail": {"name": "Hiroya Nakao"}, "author": "Hiroya Nakao", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1143/JPSJ.75.034001", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0308098v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0308098v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "7 pages, 9 figures, revised version, new figures added, to appear in\n  JPSJ Vol 75, No. 3", "arxiv_primary_category": {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "nlin.AO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0308098v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0308098v2", "journal_reference": "J. Phys. Soc. Jpn. 75 (2006) 034001", "doi": "10.1143/JPSJ.75.034001", "fulltext": "Typeset with jpsj2.cls <ver.1.2>\n\nFull Paper\n\nPopulation Coding by Globally Coupled Phase Oscillators\nHiroya Nakao \u2217\n\narXiv:cond-mat/0308098v2 [cond-mat.dis-nn] 6 Feb 2006\n\nDepartment of Physics, Kyoto University, Kyoto 606-8502\n(Received November 4, 2018)\n\nA system of globally coupled phase oscillators subject to an external input is considered as\na simple model of neural circuits coding external stimulus. The information coding efficiency\nof the system in its asynchronous state is quantified using Fisher information. The effect of\ncoupling and noise on the information coding efficiency in the stationary state is analyzed. The\nrelaxation process of the system after the presentation of an external input is also studied. It\nis found that the information coding efficiency exhibits a large transient increase before the\nsystem relaxes to the final stationary state.\nKEYWORDS: coupled oscillators, neural networks, information coding, statistical inference\n\n1. Introduction\nOscillatory activity of neurons is ubiquitous in various areas of the brain at various scales, whose physiological relevance to the information processing has been\ndiscussed in a number of studies.1\u20134 In modeling cortical\nneural circuits, coupled oscillators have played important\nroles.5, 6 In this framework, the neurons are modeled as\nmutually interacting limit-cycle oscillators, where simplified interaction rules between the oscillators are often\nassumed for the sake of mathematical tractability. The\ncase of global (all-to-all) coupling is typical of such simplified interactions, where the oscillators interact through\nthe mean field of all oscillators. The prominent feature\nof globally coupled oscillators is complete synchronization.5, 7\u20139 However, it is experimentally known that the\ncortical neurons in vivo rarely exhibit large-scale complete synchronization, but usually exhibit irregular firing\npatterns.10 Therefore, it has been discussed how globally\ncoupled models of neural populations can sustain asynchronous firing activity.11\u201316\nIt is generally considered that the cortical information processing is achieved through population coding,\nnamely, collective representation of information by large\nnumbers of neurons.17\u201319 Regarding quantification of information coding efficiency by a population of neurons,\na framework based on statistical estimation theory has\nbeen utilized. In this framework, the information coding efficiency is quantified by how precisely the given\nstimulus can be estimated from the observed firing rates\nof those neurons. It can be measured by the Fisher information, which gives the accuracy of parameter estimation in statistical estimation theory.20, 21 Using this\nframework, the information coding efficiency of various\nstochastic neuron models has been calculated.17\u201319\nIn this paper, instead of stochastic neuron models, we\nintroduce a system of globally coupled phase oscillators\nas a simple model of cortical neural circuits. Our system\nexhibits asynchronous state where each oscillator rotates\n(\"fires\") independently, by which we model the \"irregular firing\" of the cortical neurons. It codes the parameter\nvalue of an external input in the asynchronous phase dis\u2217 nakao@ton.scphys.kyoto-u.ac.jp\n\ntribution of the oscillators. We quantify the information\ncoding efficiency of our system using the statistical estimation framework. We discuss the effect of coupling and\nnoise on the information coding efficiency in the asynchronous stationary state. We also study the dynamical\naspect of our system. Even if the oscillators are not in\nstrict synchrony with each other, their population density can still exhibit coherent damped oscillation. We\nshow that such oscillation can lead to a large transient\nincrease in the information coding efficiency.\n\n^\n\n\u03b8 m (\u03c6 1 , \u03c6 2 ,\n( \u03c61 ,\u03c6 2 ,\n\n\u03c61 \u03c6 2\n\n...,\u03c6m )\n\n. . . ,\u03c6 m )\n\n.....\n\n\u03c6N\n\n\u03b8\nFig. 1. Population coding by globally coupled phase oscillators.\nInformation coding efficiency of the system is quantified using\nFisher information, which gives the accuracy of an estimator\n\u03b8\u0302m (\u03c61 , ..., \u03c6m ) of the external input parameter \u03b8 from observed\nphase variables \u03c6 of the oscillators.\n\n2. Globally coupled phase oscillators\nWe use a system of globally coupled phase oscillators,\nwhich was previously studied in detail by Golomb et al.5\nIt exhibits asynchronous states as well as various synchronized states. We set the system at its asynchronous\nstate, and add a constant external input to the system\n\n\f2\n\nJ. Phys. Soc. Jpn.\n\nAuthor Name\n\nFull Paper\n\nthat depends on a given external parameter \u03b8. This parameter \u03b8 is then coded by the non-uniform phase distribution of the oscillators (Fig. 1). Our interest is how\nefficiently the population of the oscillators codes this external parameter. We quantify it by how precisely we can\nestimate the given input by observing the phase variables\nof the oscillators. This system may be considered, for example, as a simple qualitative model of the orientation\ncolumn in the visual cortex.15\u201318 In that case, the external parameter \u03b8 corresponds to the angle of a visual\ndirectional stimulus.\n\nFig. 2. Snapshots of the phase \u03c6 of the oscillators at two values\nof the external input, \u03b8 = \u03b80 and \u03b8 = \u03b80 \u00b1 \u03c0.\n\nOur system consists of N identical phase oscillators\nmutually interacting through their mean field, which\nobey the following Langevin equations:\nN\n1 X\nd\ng(\u03c6j (t)) + \u03bei (t) + H(\u03b8) (1)\n\u03c6i (t) = f (\u03c6i (t)) +\ndt\nN j=1\n\nfor i = 1, ..., N , where \u03c6i represents the phase of the i-th\noscillator, f (\u03c6) = A + sin \u03c6 the individual dynamics of\nan isolated oscillator, g(\u03c6) = C sin(\u03c6+\u03b1) the interaction\nbetween the oscillators, and \u03bei a Gaussian-white noise\nwith zero mean, whose correlation function is given by\nh\u03bei (t)\u03bej (t\u2032 )i = 2D\u03b4(t \u2212 t\u2032 )\u03b4i,j . We identify \u03c6 + 2\u03c0k (k is\nan integer number) with \u03c6 and restrict the value of \u03c6 in\n[\u2212\u03c0, \u03c0]. H(\u03b8) is a \u03b8-dependent constant external input\ncommon to all oscillators, which we explain below. The\nparameter A determines the dynamics of each oscillator,\nC the coupling strength, \u03b1 the phase shift of coupling,\nand D the intensity of noise. We assume that C can take\nboth positive and negative values, and the range of \u03b1\nto be (0, \u03c0). We exclude two extreme values \u03b1 = 0 and\n\u03b1 = \u03c0, since the system becomes singular with these\nvalues.5\nWhen isolated, each oscillator exhibits both excitatory\nand self-oscillatory dynamics depending on the value of\nA (without the noise and the external input, each oscillator is self-oscillatory when A > 1). To realize the asynchronous state, we set A at a sufficiently large value, so\nthat each oscillator is self-oscillatory even if the effects\nof the coupling, the noise, and the external input are\n\nincorporated. In this self-oscillatory situation, the mean\nrotation rate (or the \"firing rate\") of the oscillator increases with A.\nThrough the external input H(\u03b8), the dynamics of the\nphase \u03c6 is affected by the external parameter \u03b8. We assume the range of \u03b8 to be [\u2212\u03c0, \u03c0] (\"angle stimulus\") and\nuse a functional form H(\u03b8) = H0 cos(\u03b8 \u2212 \u03b80 ) as the external input, where H0 determines its strength and \u03b80\nthe location of its maximum (\"preferred stimulus\"). This\nH(\u03b8) roughly models the one-humped \"tuning curve\",\nwhich represents the response of a neuron to the stimulus.17\u201319 When \u03b8 approaches \u03b80 , the mean rotation rate\nof the oscillators increases, and reaches the maximum\nvalue at \u03b8 = \u03b80 (in the following discussion, the results\ndepends only on the difference \u03b8\u2212\u03b80 , so that the absolute\nvalue of \u03b80 is not important). Since this external input\nH(\u03b8) merely shifts the parameter A in the individual dynamics of the oscillator f (\u03c6) = A + sin \u03c6, we hereafter\ninclude H(\u03b8) in A and denote the effective value of A as\nA(\u03b8) = A + H(\u03b8).\nFigure 2 displays two snapshots of the phase \u03c6i of all\noscillators in the asynchronous stationary state obtained\nby direct numerical simulations of the Langevin equations (1) at two different values of the external input,\n\u03b8 = \u03b80 and \u03b8 = \u03b80 \u00b1 \u03c0 (\u03b8 = \u03b80 + \u03c0 and \u03b80 \u2212 \u03c0 give the\nsame external input because H(\u03b8) is periodic in \u03b8). The\nother parameters are fixed at A = 1.5, C = 0.5, \u03b1 = \u03c0/4,\nH0 = 0.1, and D = 0.1. It can be seen that the distribution of the phase is relatively uniform at the preferred\ninput \u03b8 = \u03b80 , whereas its non-uniformity is enhanced at\n\u03b8 = \u03b80 \u00b1 \u03c0.\nHereafter, rather than tracking the individual stochastic trajectories of the oscillators directly, we take the\nN \u2192 \u221e limit and consider the one-body probability\ndensity function (PDF) P (\u03c6, t; \u03b8) of the phase \u03c6. The\nevolution of the PDF P (\u03c6, t; \u03b8) is described by5, 7, 8\n\u2202\nP (\u03c6, t; \u03b8)\n\u2202t\n\n=\n\n\u2212\n\nI(\u03c6, t; \u03b8)\n\n=\n\n{A(\u03b8) + G(t; \u03b8) + sin \u03c6} P (\u03c6, t; \u03b8)\n\n\u2202\nI(\u03c6, t; \u03b8),\n\u2202\u03c6\n\n\u2212D\n\n\u2202\nP (\u03c6, t; \u03b8),\n\u2202\u03c6\n\n(2)\n\nwhere I(\u03c6, t; \u03b8) represents the probability flux, and\nG(t; \u03b8) the \"internal field\" defined as the interaction\nfunction averaged by the PDF P (\u03c6, t; \u03b8), i.e.,\nZ \u03c0\nG(t; \u03b8) =\nP (\u03c6, t; \u03b8)C sin(\u03c6 + \u03b1)d\u03c6.\n(3)\n\u2212\u03c0\n\nPeriodic boundary conditions are assumed for P (\u03c6, t; \u03b8)\nand I(\u03c6, t; \u03b8) at \u03c6 = \u00b1\u03c0.\nFigure 3 displays stationary PDFs of the phase\nP0 (\u03c6; \u03b8) at several values of the external parameter \u03b8\nin the asynchronous stationary state, which corresponds\nto Fig. 2. The details of this state will be given in the\nnext section. The PDF is relatively uniform at the preferred input \u03b8 = \u03b80 , and becomes steeper at \u03b8 = \u03b80 \u00b1 \u03c0.\nAt this weak noise level, D = 0.1, functional shape of the\nPDF is close to that in the noiseless case. As the value of\n\u03b8 is varied, the shape of P0 (\u03c6; \u03b8) varies correspondingly.\nIn other words, the external parameter \u03b8 is coded by the\n\n\fJ. Phys. Soc. Jpn.\n\n\u03b8 = \u03b80 \u00b1 \u03c0\n\u03b8 = \u03b80 \u00b1 \u03c0 / 2\n\u03b8 = \u03b80\n\nP 0 (\u03c6 ; \u03b8 )\n\n0.4\n0.3\n0.2\n0.1\n\u2212\u03c0 / 2\n\n0\n\n\u03c6\n\n\u03c0/2\n\n\u03c0\n\nFig. 3. Stationary PDF P0 (\u03c6; \u03b8) at several values of the external\nparameter \u03b8 (\u03b8 = \u03b80 \u00b1 \u03c0, \u03b8 = \u03b80 \u00b1 \u03c0/2, and \u03b8 = \u03b80 ).\n\nstationary PDF in the asynchronous state of our globally\ncoupled phase oscillators.\n3. Asynchronous stationary state\nIn this section, we summarize the dynamics of Eqs. (2)\nand (3) following Golomb et al.5 with emphasis on the\nasynchronous stationary state. The PDF P (\u03c6, t; \u03b8) exhibits mainly three behavior, namely, fixed state, limitcycle state, and asynchronous stationary state. The probability flux I(\u03c6, t; \u03b8) takes a small value in the fixed state\n(zero in the noiseless case), a non-zero constant value in\nthe asynchronous stationary state, and oscillates periodically in the limit-cycle state.\nLet us consider the noiseless case (D = 0) first. In this\ncase, existence and linear stability of each state can be\nstudied analytically.5 Here, it should be noted that even\nif we set D = 0, we always assume that the system is\nsubject to infinitesimally weak noise, to avoid singular\nbehavior specific to the noiseless equation and to ensure\nthe existence of final steady states.8 With this understanding, we formally set D = 0 to facilitate analytical\ntreatment, and compare the analytical results with the\nnumerical simulations at finite values of D.\nThe fixed-state solutions exist when C 2 +2C cos \u03b1+1 >\nA(\u03b8)2 , and the stability conditions are given by C cos \u03b1 >\n\u22121 + A(\u03b8) or by C cos \u03b1 > \u22121 \u2212 A(\u03b8) and C > 0. In this\nstate, all oscillators take the same fixed phase homogeneously, and the PDF is simply a \u03b4-function with fixed location. The probability flux is constantly zero. The limitcycle solution exists when C 2 +2C cos \u03b1+1 < A(\u03b8)2 , and\nis stable when C > 0. In this state, the oscillators exhibit\ncompletely synchronized rotation. The PDF is again a \u03b4function, whose location rotates steadily. The temporal\nsequence of the probability flux is given by periodically\naligned \u03b4-functions.\nIn our context, these two states are inappropriate for\nmodeling the dynamics of cortical neurons. In the fixed\nstate, all oscillators are trapped to the same fixed phase\nand never rotate, namely, the neurons do not fire at all.\nOn the other hand, the limit-cycle state corresponds to\nthe completely synchronized firing of all neurons, which\nis experimentally unrealistic. These situations are not\nchanged even if weak noise is introduced. Only with suffi-\n\n3\n\nciently strong noise, these states may be utilized in modeling the dynamics of cortical neurons, but we do not\nconsider such cases in this paper for simplicity.\nThe asynchronous stationary solution exists when\n\u2212\u221e < C cos \u03b1 < [A(\u03b8)2 \u22121]/2. It coexists with the limitcycle or fixed solution. Unlike the above two cases, the\nPDF takes a broad functional form in this state. The\noscillators are not in synchrony with each other, and rotate with a finite constant rate steadily. The probability\nflux I(\u03c6, t; \u03b8) takes a constant value, which is typically\nbetween 0.05 and 0.20 at the parameter values we use\nin this paper. The stationary PDF P0 (\u03c6; \u03b8) in the asynchronous stationary state at D = 0 can be obtained from\nEqs. (2) and (3) as\n\u0002\n\u00031\nF (\u03b8)2 \u2212 1 2\n1\n.\n(4)\nP0 (\u03c6; \u03b8) =\n2\u03c0\nF (\u03b8) + sin \u03c6\nHere, F (\u03b8) is defined as F (\u03b8) = A(\u03b8) + G0 (\u03b8), where\nG0 (\u03b8) denotes the internal field in this stationary state.\nThe value of G0 (\u03b8), or equivalently the value of F (\u03b8), is\ndetermined self-consistently so that G0 (\u03b8) and P0 (\u03c6; \u03b8)\nsatisfy Eq. (3). It is explicitly calculated as\nF (\u03b8)\n\n=\n\u00b1\n\n1\n{(1 + C cos \u03b1)A(\u03b8)\n1 + 2C cos \u03b1\np\n(C cos \u03b1)2 [A(\u03b8)2 \u2212 (1 + 2C cos \u03b1)]}. (5)\n\nWhen C = 0 or \u03b1 = \u03c0/2 (C cos \u03b1 = 0), we obtain\na trivial solution F (\u03b8) = A(\u03b8), i.e., G0 (\u03b8) = 0. The\nrelevant solution for C cos \u03b1 6= 0 is given by the negative branch when \u2212\u221e < C cos \u03b1 < 0, and by the positive branch when 0 < C cos \u03b1 < [A(\u03b8)2 \u2212 1]/2. When\nC cos \u03b1 > [A(\u03b8)2 \u2212 1]/2, no stationary PDF exists that\ncorresponds to the asynchronous stationary state.\n\n0.20\n\n0.15\n\nD\n\n0.5\n\n0\n\u2212\u03c0\n\nAuthor Name\n\nFull Paper\n\nA\n\n0.10\n\nA+S\n\n0.05\n\nS\n\nL+S\n\n0.00\n-1.0\n\nL\n-0.5\n\n0.0\n\n0.5\n\n1.0\n\nC\nFig. 4. Phase diagram of the system at A = 1.4. Region \"A\" represents the asynchronous stationary state, \"L\" the limit-cycle\nstate, and \"S\" the fixed state. In the small region \"A+S\", the\nasynchronous state and the fixed state are bistable, and in the region \"L+S\", the limit-cycle state and the fixed state are bistable.\nThe dotted curve distinguishes the regions \"A\" and \"S\" as defined in the text.\n\nFor example, when 0 < \u03b1 < \u03c0/2, the non-uniformity of\n\n\fJ. Phys. Soc. Jpn.\n\nAuthor Name\n\nFull Paper\n\nP0 (\u03c6; \u03b8) is enhanced as we increase C, because F (\u03b8) decreases. However, as we increase C further, C cos \u03b1 eventually reaches [A(\u03b8)2 \u22121]/2, and the stationary PDF corresponding to the asynchronous stationary state ceases\nto exist. We are then left with a \u03b4-peaked stationary PDF\nthat corresponds to the fixed state of the oscillators.\nAccording to the linear stability analysis of the stationary PDF,5 P0 (\u03c6; \u03b8) is marginally stable when C < 0,\nand is unstable when C > 0 in the absence of noise.\nTherefore, when C > 0, the asynchronous stationary\nstate cannot be realized without noise, and only the fixed\nor limit-cycle state is observed in numerical simulations.\nWhen the noise exists (D > 0), the functional form\nof the stationary PDF becomes complex. However, we\ncan still obtain it numerically by finding the stationary solution of Eqs. (2) and (3). The \u03b4-peaked PDF in\nthe fixed or limit-cycle state at D = 0 is smeared by\nthe noise, and takes broader functional form. The asynchronous stationary state is also broadened by the noise.\nFurthermore, the noise also stabilizes the asynchronous\nstationary state,5 so that originally only marginally stable PDF at C < 0 becomes linearly stable whenever\nD > 0, and even the originally unstable asynchronous\nstationary state at C > 0 can be stabilized when D > Dc ,\nwhere Dc is a certain critical noise intensity that depends\non C.\nFigure 4 displays a numerically obtained phase diagram of our system, where the final steady state of the\nsystem sufficiently after the initial transient is indicated\nas a function of the coupling strength C and the noise\nintensity D. The parameter A(\u03b8) is fixed to its minimum\nvalue, A(\u03b8 = \u03b80 \u00b1 \u03c0) = A \u2212 H0 = 1.4, because the stability region of the asynchronous stationary state, which is\nof our primary interest, becomes smallest at this value.\nAs can be seen, originally unstable asynchronous stationary state for C > 0 can easily be stabilized as D becomes\nlarger than a certain small critical value Dc .\nIn region \"A\" of the phase diagram, the PDF exhibits stable asynchronous stationary state, which continues from the marginally stable (C < 0) or unstable\n(C > 0) asynchronous solution at D = 0. In region \"L\",\nthe PDF exhibits limit-cycle oscillation, which is the continuation of the completely synchronous limit-cycle solution at D = 0. In region \"S\", the PDF exhibits fixed\nstationary state with small probability flux, which continues from the homogeneous fixed solution at D = 0.\nThere also exist small bistable regions where the fixed\nstate coexists with the asynchronous stationary state or\nwith the limit-cycle state at small noise intensity, roughly\nD < 0.07, as indicated in the figure as \"A+S\" or \"L+S\".\nAs D becomes larger than 0.07, the bistable region vanishes, and the distinction between the asynchronous stationary state and the fixed state becomes unclear. We\ntherefore distinguish the asynchronous stationary state\n\"A\" from the fixed state \"S\" by whether the probability\nflux I(\u03c6, t; \u03b8) exceeds 0.05 or not when D > 0.07. Here,\nthe value 0.05 is determined using the probability flux at\nthe upper endpoint of the bistable region \"A+S\". The\nboundary between \"A\" and \"S\" determined in this way\nis displayed in the figure by the dotted curve. As we cross\nthis boundary from region \"A\" to \"S\", the PDF changes\n\nits shape and the probability flux drops quickly. Hereafter, we restrict our analysis to the asynchronous stationary state \"A\" with sufficiently large probability flux.\nThe fixed state, the limit-cycle state, and the bistable\nregions are excluded from our consideration.\n4. Fisher information\nLet us quantify the information coding efficiency of our\nsystem using Fisher information. We consider the accuracy of the parameter estimation of \u03b8 from m samples\nof the phase \u03c61 , ..., \u03c6m observed independently from the\n\u03b8-dependent PDF P (\u03c6; \u03b8). According to the statistical\nestimation theory,20, 21 the maximum likelihood estimator \u03b8\u0302m (\u03c61 , ..., \u03c6m ), which is determined so Q\nas to maximize\nthe likelihood function L(\u03b8; \u03c61 , ..., \u03c6m ) = m\nk=1 P (\u03c6k ; \u03b8),\nweakly converges to a normal distribution with mean \u03b8\nand variance 1/mJ(\u03b8) in the limit of large m. The quantity J(\u03b8) in the denominator of the variance is the Fisher\ninformation, which is defined as\n\u0014\n\u00152\nZ \u03c0\n\u2202\nJ(\u03b8) =\nP (\u03c6; \u03b8)\nlog P (\u03c6; \u03b8) d\u03c6.\n(6)\n\u2202\u03b8\n\u2212\u03c0\nUnder some regularity conditions, the maximum likelihood estimator is proven to be asymptotically optimal in\nthe large m limit, in the sense that asymptotic variance\nof all other asymptotically normal estimators cannot be\nsmaller than 1/mJ(\u03b8).20, 21 Thus, the Fisher information\nJ(\u03b8) gives a lower bound to the error of parameter estimation, and it can be considered as quantifying the information (actually parameter) coding efficiency of the system by its PDF. As can be seen from Eq. (6), J(\u03b8) measures the mean \"response\" of the PDF P (\u03c6; \u03b8) to a slight\nchange in the parameter \u03b8. When this response is large,\nthe estimation error becomes small, and the information\ncoding efficiency becomes large. The Fisher information\ncan also be related to the discriminability measure between two similar stimuli used in psychophysics.17, 18\n\nC = 0.5\nC=0\nC = -0.5\nH(\u03b8)\n\n0.015\n\nJ(\u03b8)\n\n4\n\n0.010\n\n0.005\n\n0.000\n\u2212\u03c0\n\n\u2212\u03c0 / 2\n\n0\n\n\u03b8 \u2212 \u03b80\n\n\u03c0/2\n\n\u03c0\n\nFig. 5. Fisher information J(\u03b8) obtained for the uncoupled case\n(C = 0) and for the coupled cases (C = \u00b10.5). Cosine curve in\nthe lower part is the external input (\"tuning curve\") H(\u03b8) given\nto the system (rescaled and shifted).\n\n5. Stationary information coding efficiency\nWe first consider the information coding efficiency in\nthe stationary state of our system. In the absence of noise\n\n\fJ. Phys. Soc. Jpn.\n\n0.05\n\nC = 0.5\nC=0\nC = \u22120.5\n\n0.04\n0.050\n\n0.03\nJA\n\nSince F (\u03b8) contains the self-consistent internal field\nG0 (\u03b8), J(\u03b8) depends on the mutual coupling through\nthis quantity. By substituting the explicit form of F (\u03b8),\nEq. (5), we can express J(\u03b8) in terms of A(\u03b8) = A+H(\u03b8)\nand C cos \u03b1. When D > 0, we can calculate J(\u03b8) using\nnumerically obtained stationary PDFs. With the weak\nnoise we use in this paper, the numerically obtained\nFisher information for D > 0 is close to the noiseless\ntheoretical values at D = 0.\nFigure 5 displays the Fisher information J(\u03b8) obtained\nfor the uncoupled case (C = 0) and for the coupled cases\n(C = \u00b10.5) as a function of the external parameter \u03b8.\nThe other parameters are fixed at A = 1.5, \u03b1 = \u03c0/4,\nH0 = 0.1, and D = 0.1. The Fisher information clearly\ndepends on the coupling strength C; we attain much\nlarger value at C = 0.5 than at C = 0 or C = \u22120.5.\nAt this noise level, the numerically obtained Fisher information is close to the noiseless theoretical values. Note\nhere that the asynchronous stationary state is unstable\nwithout the noise when C > 0, so that the corresponding theoretical values of the Fisher information cannot\nbe attained in practice. However, as can be seen from\nFig. 4, the weak noise (D = 0.1) can readily stabilize the\noriginally unstable PDF at C > 0 and helps realize much\nlarger information coding efficiency.\n\n5\n\nthe stationary PDF most strongly depends on the external parameter \u03b8. This fact is consistent with the results\nin the previous studies,17\u201319 which is interesting since it\nis against our rate-coding intuition.\nIn Fig. 6, the dependence\nof the mean Fisher informaR\u03c0\ntion JA = (2\u03c0)\u22121 \u2212\u03c0 J(\u03b8)d\u03b8 on the coupling strength C\nis displayed at three values of the noise intensity, D = 0,\nD = 0.1, and D = 0.2. When D = 0, only the region\nC < 0 as indicated in the figure is realizable. However, when D = 0.1 or 0.2, originally unstable PDF for\nC > 0 is stabilized as shown in Fig. 4, so that the whole\ncurve can be realized. JA increases remarkably as C is\nincreased, because the non-uniformity of the stationary\nPDF is enhanced, and its dependence on the parameter\n\u03b8 becomes stronger.\n\nJA\n\n(D = 0), we can analytically calculate the Fisher information J(\u03b8) from the self-consistent stationary PDF\nP0 (\u03c6; \u03b8), Eq. (4), as\n\u0014\n\u00152\n1 \u2202F (\u03b8)\n1\nJ(\u03b8) =\n.\n(7)\n2\n2\n\u2202\u03b8\n[F (\u03b8) \u2212 1]2\n\n0.045\n\n0.02\n0.040\n0\n\n0.01\n0\n\n0.05\n\n0.1\n\nD\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nD\n\nFig. 7. Dependence of the mean Fisher information JA on the\nnoise intensity D. At D = 0, only the region indicated by the\narrow can be realized.\n\n0.25\n0.20\n\nD=0\nD = 0.1\nD = 0.2\n\nJA\n\n0.15\n0.10\n0.05\n0.00\n\nAuthor Name\n\nFull Paper\n\n\u22120.8\n\n\u22120.4\n\n0\n\n0.4\n\n0.8\n\nC\nFig. 6. Dependence of the mean Fisher information JA on the\ncoupling strength C. At D = 0, only the region indicated by the\narrow can be realized. Crosses represent the values of C where\nthe asynchronous stationary state disappears (D = 0) or gives\nway to the stationary fixed state (D = 0.1, D = 0.2).\n\nSince our external input H(\u03b8) takes its maximum value\nat \u03b8 = \u03b80 , the mean rotation rate of each oscillator is also\nmaximized at this value. However, J(\u03b8) vanishes at this\npoint, because \u03b8 = \u03b80 is the extremum of A(\u03b8), hence\n\u2202F/\u2202\u03b8 \u221d \u2202A/\u2202\u03b8 = 0 holds. Thus, accurate parameter\nestimation is difficult around \u03b8 = \u03b80 . Rather, J(\u03b8) takes\nits maximum at \u03b8 \u2243 \u00b1\u03c0/2, where the functional shape of\n\nIf C is further increased to a certain critical value, the\nstationary PDF corresponding to the asynchronous stationary state disappears (D = 0) or gives way to the fixed\nstate with low probability flux (D = 0.1, D = 0.2). These\nvalues are indicated by crosses in the figure. The Fisher\ninformation diverges at this point when D = 0, because\nthe stationary PDF changes its functional form discontinuously. When D = 0.1 and D = 0.2, divergence of\nthe Fisher information is suppressed, but it still exhibits\nabrupt increase due to the sudden change in the stationary PDF. Although this result is formally valid, such\ndivergent behavior indicates the failure of our present\nframework based on the Fisher information in quantifying the information coding efficiency around bifurcation points; it implies that we can estimate the external parameter with infinite precision even from a single observation. This is due to the basic assumption of\nour framework, namely, continuous dependence of the\nfunctional shape of the PDF on the external parameter, which is generally violated at the bifurcation points.\nThus, at present, we consider the divergent behavior of\nthe Fisher information around the bifurcation point as\nrather a mathematical artifact. In conventional studies of\nthe information coding efficiency using stochastic neuron\nmodels,17\u201319 the firing statistics of the neurons is usually\n\n\fJ. Phys. Soc. Jpn.\n\nassumed to be given by some specific family of the PDF,\ne.g. Gaussian or Poissonian, so that such a situation does\nnot arise generally.\nFigure 7 displays the dependence of the mean Fisher\ninformation JA on the noise intensity D at three values\nof the coupling strength, C = \u22120.5, C = 0, and C = 0.5.\nThe other parameters are fixed at A = 1.5, \u03b1 = \u03c0/4,\nand H0 = 0.1. As previous, the asynchronous stationary\nstate is unstable at small D when C = 0.5, and only\nthe region indicated by the arrow in the figure can be\nrealized. As we increase D, JA decreases. The noise generally decreases the information coding efficiency of the\nsystem, because the noise tends to flatten the stationary\nPDF and weakens its dependence on \u03b8. However, interestingly, the mean Fisher information JA corresponding\nto C = 0.5 takes its maximum value not at D = 0 but\nat a small but finite value of D, as shown in the inset of\nFig. 7 (the asynchronous stationary state is already stabilized at this value of D). Thus, the noise is generally\ndisturbing, but it can also help the realization of larger\ninformation coding efficiency.\n0.030\n\nt = 0.0\nt = 5.0\nt = 10.0\nt = 20.0\nstationary\n\n0.025\n\nJ(\u03b8, t)\n\n0.020\n0.015\n0.010\n0.005\n0.000\n\u2212\u03c0\n\n\u2212\u03c0 / 2\n\nAuthor Name\n\nFull Paper\n\n0\n\n\u03b8 \u2212 \u03b80\n\n\u03c0/2\n\n\u03c0\n\nFig. 8. Snapshots of Fisher information J(\u03b8, t) at several moments in the relaxation process after the onset of the external\ninput.\n\n0.08\n\nTransient increase\n\n0.06\n\nJA(t)\n\n6\n\nAsymptotic\nstationary value\n\n0.04\n0.02\nOnset of external input\n\n0\n\n0\n\n10\n\n20\n\n30\n\n40\n\nt\nFig. 9. Temporal variation of mean Fisher information JA (t) after the onset of the external input.\n\nJ(\u03b8, t) exhibits wavy functional shape that is considerably different from the previously obtained stationary\nfunctional shape, and then it gradually converges to the\nstationary shape. Correspondingly, after the onset of the\nexternal input, JA (t) rapidly increases from zero to a\ncertain maximum value and then exhibits an oscillatory\nrelaxation to the new stationary value.\nThis reflects the fact that the dependence of the transient PDF P (\u03c6, t; \u03b8) on \u03b8 is much stronger than that\nof the stationary PDF P0 (\u03c6; \u03b8), which can be qualitatively understood as follows. When we apply a constant\nexternal input H(\u03b8), the PDF undergoes oscillatory relaxation to the new stationary state, with the period of\nthe oscillation determined by the parameter \u03b8. In this\nprocess, the discrepancy of two PDFs corresponding to\ntwo slightly different values of \u03b8 becomes much larger\nthan that in the stationary state, through a mechanism\nessentially similar to the \"beat\" of sound waves. As a\nresult, the Fisher information, which measures the mean\nresponse of the PDF to a slight change in the parameter, also increases remarkably and exhibits a transient\nincrease in information coding efficiency.\n7. Summary\n\n6. Dynamic information coding efficiency\nSince our system is a stochastic dynamical system, we\ncan consider not only its stationary state, but also its\nnon-stationary state. We here briefly study the relaxation\nprocess after the presentation of an external input. Let\nus assume that the system is in its initial asynchronous\nstationary state without any external input when t < 0.\nAfter t = 0, we apply a constant external input H(\u03b8)\nto the system and observe its relaxation to a new asynchronous stationary state determined by the given parameter \u03b8. By solving the evolution equation (2) of the\nPDF P (\u03c6, t; \u03b8) numerically, we can calculate the Fisher\ninformation J(\u03b8, t) at any moment.\nFigure 8 shows several snapshots of J(\u03b8, t) during\nthe relaxation process, and Figure 9 shows temporal variation of the mean Fisher information JA (t) =\nR +\u03c0\n(2\u03c0)\u22121 \u2212\u03c0 J(\u03b8, t)d\u03b8. The system parameters are A =\n1.5, \u03b1 = \u03c0/4, C = 0.5, H0 = 0.1, and D = 0.1. Interestingly, slightly after the onset of the external input,\n\nWe considered population coding of an external parameter in the asynchronous state of globally coupled\nphase oscillators and quantified its information coding\nefficiency using Fisher information. The Fisher information depends on the mutual coupling through the selfconsistent internal field of the oscillators. The noise generally reduces the Fisher information of the system, but it\nalso stabilizes the originally unstable PDF and helps realize larger information coding efficiency. We found a substantial transient increase in Fisher information slightly\nafter the onset of an external input, before the system\nrelaxes to a new stationary state.\nAlthough we treated the information coding only in\nthe asynchronous state in this paper, the fixed or limitcycle state with sufficiently strong noise may also be considered as the basis for the information coding. It would\nthen be interesting to compare the information coding\nefficiency among those dynamically distinct situations.\nHowever, as we saw in Fig. 6, our framework based on\nFisher information does not yield practically meaning-\n\n\fJ. Phys. Soc. Jpn.\n\nFull Paper\n\nAuthor Name\n\n7\n\nful result around the bifurcation point between different\ndynamical states. To remedy this situation, further modifications to our present framework will be necessary.\nThe transient increase in Fisher information indicates\nthat the extraction of the information stored in our system can be better achieved in the transient state than\nin the final stationary state. Though our present system\nis only a rough caricature of real cortical networks, the\nmechanism leading such behavior can be generic. Thus, it\ncould provide an interesting viewpoint on the role played\nby the transient dynamical behavior of the population of\nreal cortical neurons, e.g. in interpreting the results of\npsychophysical experiments.\nIn any case, to assert the relevance of our physical findings in the actual information processing by the cortical\nneurons, we need careful discussions on the physiological plausibility of the model. A more detailed analysis of\nthe present system and generalization to more realistic\nneural models will be reported in the future.\nFinally, from a general viewpoint, our analysis reported in this paper can be considered as a prototypical\nstudy of physical systems coding external information.\nSuch a framework would be important in analyzing physical systems that process external information, not only\nin the context of neuroscience but also in various other\nareas.\n\n1) C. M. Gray and W. Singer, Proc. Natl. Acad. Sci. USA 86,\n1698 (1989).\n2) A. K. Engel, A. K. Kreiter, P. K\u00f6nig, and W. Singer, Proc.\nNatl. Acad. Sci. USA 88, 6048 (1991).\n3) F. Varela, J.-P. Lachaux, E. Rodriguez, and J. Martinerie, Nature Rev. Neurosci. 2, 229 (2001).\n4) E. Salinas and T. J. Sejnowski, Nature Rev. Neurosci. 2, 539\n(2001).\n5) D. Golomb, D. Hansel, B. Shraiman, and H. Sompolinsky,\nPhys. Rev. A 45, 3516 (1992).\n6) G. B. Ermentrout and D. Kleinfeld, Neuron 29, 33 (2001).\n7) Y. Kuramoto, Chemical Oscillations, Waves, and Turbulence\n(Springer-Verlag, Berlin, 1984).\n8) Y. Kuramoto, Physica D 50 (1991) 15.\n9) A. Pikovsky, M. Rosenblum, and J. Kurths, Synchronization\n(Cambridge University Press, Cambridge, 2001).\n10) W. R. Softky and C. Koch, Neural Comput. 4, 643 (1992).\n11) L. F. Abbott and C. van Vreeswijk, Phys. Rev. E 48, 1483\n(1993).\n12) W. Gerstner, Neural Comput. 12, 43 (2000).\n13) D. Hansel and G. Mato, Phys. Rev. Lett. 86, 4175 (2001).\n14) D. J. Mar, C. C. Chow, W. Gerstner, R. W. Adams, and J. J.\nCollins, Proc. Natl. Acad. Sci. USA 96, 10450 (1999).\n15) D. Q. Nykamp and D. Tranchina, Journal of Computational\nNeuroscience 8, 19 (2000).\n16) A. Omurtag, E. Kaplan, B. Knight, and L. Sirovich, Network:\nComput. Neural Syst. 11, 247 (2000).\n17) M. A. Paradiso, Biol. Cybern. 58, 35 (1988).\n18) H. S. Seung and H. Sompolinsky, Proc. Natl. Acad. Sci. USA\n90, 10749 (1993).\n19) L. Abbott and T. J. Sejnowski, eds., Neural Codes and Dis-\n\nAcknowledgments\n\ntributed Representations: Foundations of Neural Computation (MIT Press, Cambridge, 1999).\n20) E. L. Lehman, Theory of Point Estimation (Wiley, New York,\n1983).\n21) T. M. Cover and J. A. Thomas, Elements of Information Theory (Wiley, New York, 1991).\n\nThe author thanks Y. Sakai, M. Hayashi, Y. Tsubo,\nand H. Shimazaki for useful comments and suggestions.\nHe is also grateful to S. Amari, M. Okada, and the members of the RIKEN Brain Science Institute for their advice and support.\n\n\f"}