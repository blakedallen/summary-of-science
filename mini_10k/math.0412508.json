{"id": "http://arxiv.org/abs/math/0412508v1", "guidislink": true, "updated": "2004-12-28T02:15:23Z", "updated_parsed": [2004, 12, 28, 2, 15, 23, 1, 363, 0], "published": "2004-12-28T02:15:23Z", "published_parsed": [2004, 12, 28, 2, 15, 23, 1, 363, 0], "title": "The Operator Valued Autoregressive Filter Problem and the Suboptimal\n  Nehari Problem in Two Variables", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0412230%2Cmath%2F0412404%2Cmath%2F0412234%2Cmath%2F0412146%2Cmath%2F0412191%2Cmath%2F0412257%2Cmath%2F0412475%2Cmath%2F0412193%2Cmath%2F0412541%2Cmath%2F0412154%2Cmath%2F0412244%2Cmath%2F0412108%2Cmath%2F0412486%2Cmath%2F0412260%2Cmath%2F0412526%2Cmath%2F0412508%2Cmath%2F0412297%2Cmath%2F0412162%2Cmath%2F0412414%2Cmath%2F0412328%2Cmath%2F0412429%2Cmath%2F0412421%2Cmath%2F0412337%2Cmath%2F0412194%2Cmath%2F0412393%2Cmath%2F0412251%2Cmath%2F0412077%2Cmath%2F0412343%2Cmath%2F0412497%2Cmath%2F0412035%2Cmath%2F0412002%2Cmath%2F0412158%2Cmath%2F0412048%2Cmath%2F0412491%2Cmath%2F0412106%2Cmath%2F0412457%2Cmath%2F0412017%2Cmath%2F0412138%2Cmath%2F0412334%2Cmath%2F0412527%2Cmath%2F0412183%2Cmath%2F0412536%2Cmath%2F0412395%2Cmath%2F0412085%2Cmath%2F0412291%2Cmath%2F0412031%2Cmath%2F0412299%2Cmath%2F0412348%2Cmath%2F0412025%2Cmath%2F0412049%2Cmath%2F0412239%2Cmath%2F0412558%2Cmath%2F0412420%2Cmath%2F0412521%2Cmath%2F0412066%2Cmath%2F0412538%2Cmath%2F0412028%2Cmath%2F0412402%2Cmath%2F0412228%2Cmath%2F0412165%2Cmath%2F0412530%2Cmath%2F0412460%2Cmath%2F0412036%2Cmath%2F0412444%2Cmath%2F0412286%2Cmath%2F0412370%2Cmath%2F0412044%2Cmath%2F0412125%2Cmath%2F0412038%2Cmath%2F0412468%2Cmath%2F0412326%2Cmath%2F0412296%2Cmath%2F0412492%2Cmath%2F0412447%2Cmath%2F0412034%2Cmath%2F0412418%2Cmath%2F0412020%2Cmath%2F0412033%2Cmath%2F0412295%2Cmath%2F0412394%2Cmath%2F0412517%2Cmath%2F0412376%2Cmath%2F0412407%2Cmath%2F0412356%2Cmath%2F0412132%2Cmath%2F0412011%2Cmath%2F0412082%2Cmath%2F0412264%2Cmath%2F0412546%2Cmath%2F0412265%2Cmath%2F0412171%2Cmath%2F0412127%2Cmath%2F0412432%2Cmath%2F0412392%2Cmath%2F0412094%2Cmath%2F0412173%2Cmath%2F0412545%2Cmath%2F0412205%2Cmath%2F0412327%2Cmath%2F0412113%2Cmath%2F0412026&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The Operator Valued Autoregressive Filter Problem and the Suboptimal\n  Nehari Problem in Two Variables"}, "summary": "Necessary and sufficient conditions are given for the solvability of the\noperator valued two-variable autoregressive filter problem. In addition, in the\ntwo variable suboptimal Nehari problem sufficient conditions are given for when\na strictly contractive little Hankel has a strictly contractive symbol.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0412230%2Cmath%2F0412404%2Cmath%2F0412234%2Cmath%2F0412146%2Cmath%2F0412191%2Cmath%2F0412257%2Cmath%2F0412475%2Cmath%2F0412193%2Cmath%2F0412541%2Cmath%2F0412154%2Cmath%2F0412244%2Cmath%2F0412108%2Cmath%2F0412486%2Cmath%2F0412260%2Cmath%2F0412526%2Cmath%2F0412508%2Cmath%2F0412297%2Cmath%2F0412162%2Cmath%2F0412414%2Cmath%2F0412328%2Cmath%2F0412429%2Cmath%2F0412421%2Cmath%2F0412337%2Cmath%2F0412194%2Cmath%2F0412393%2Cmath%2F0412251%2Cmath%2F0412077%2Cmath%2F0412343%2Cmath%2F0412497%2Cmath%2F0412035%2Cmath%2F0412002%2Cmath%2F0412158%2Cmath%2F0412048%2Cmath%2F0412491%2Cmath%2F0412106%2Cmath%2F0412457%2Cmath%2F0412017%2Cmath%2F0412138%2Cmath%2F0412334%2Cmath%2F0412527%2Cmath%2F0412183%2Cmath%2F0412536%2Cmath%2F0412395%2Cmath%2F0412085%2Cmath%2F0412291%2Cmath%2F0412031%2Cmath%2F0412299%2Cmath%2F0412348%2Cmath%2F0412025%2Cmath%2F0412049%2Cmath%2F0412239%2Cmath%2F0412558%2Cmath%2F0412420%2Cmath%2F0412521%2Cmath%2F0412066%2Cmath%2F0412538%2Cmath%2F0412028%2Cmath%2F0412402%2Cmath%2F0412228%2Cmath%2F0412165%2Cmath%2F0412530%2Cmath%2F0412460%2Cmath%2F0412036%2Cmath%2F0412444%2Cmath%2F0412286%2Cmath%2F0412370%2Cmath%2F0412044%2Cmath%2F0412125%2Cmath%2F0412038%2Cmath%2F0412468%2Cmath%2F0412326%2Cmath%2F0412296%2Cmath%2F0412492%2Cmath%2F0412447%2Cmath%2F0412034%2Cmath%2F0412418%2Cmath%2F0412020%2Cmath%2F0412033%2Cmath%2F0412295%2Cmath%2F0412394%2Cmath%2F0412517%2Cmath%2F0412376%2Cmath%2F0412407%2Cmath%2F0412356%2Cmath%2F0412132%2Cmath%2F0412011%2Cmath%2F0412082%2Cmath%2F0412264%2Cmath%2F0412546%2Cmath%2F0412265%2Cmath%2F0412171%2Cmath%2F0412127%2Cmath%2F0412432%2Cmath%2F0412392%2Cmath%2F0412094%2Cmath%2F0412173%2Cmath%2F0412545%2Cmath%2F0412205%2Cmath%2F0412327%2Cmath%2F0412113%2Cmath%2F0412026&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Necessary and sufficient conditions are given for the solvability of the\noperator valued two-variable autoregressive filter problem. In addition, in the\ntwo variable suboptimal Nehari problem sufficient conditions are given for when\na strictly contractive little Hankel has a strictly contractive symbol."}, "authors": ["J. S. Geronimo H. J. Woerdeman"], "author_detail": {"name": "J. S. Geronimo H. J. Woerdeman"}, "author": "J. S. Geronimo H. J. Woerdeman", "arxiv_comment": "18 pages", "links": [{"href": "http://arxiv.org/abs/math/0412508v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0412508v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.FA", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.FA", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "42B05, 47A57, 47B35", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0412508v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0412508v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0412508v1 [math.FA] 28 Dec 2004\n\nThe Operator Valued Autoregressive Filter Problem and\nthe Suboptimal Nehari Problem in Two Variables\nJeffrey S. Geronimo\u2217and Hugo J. Woerdeman\nSeptember 27, 2018\n\nSchool of Mathematics\nGeorgia Institute of Technology\nAtlanta, GA 30332-0160\ngeronimo@math.gatech.edu\nand\nDepartment of Mathematics\nDrexel University\nPhiladelphia, PA 19104\nHugo.Woerdeman@drexel.edu\nKeywords: Autoregressive filter, two-variable polynomials, stability, two-variable Nehari\nproblem\nMSC: Primary: 42B05, 47A57, 47B35; Secondary: 15A48, 42C05, 47A68, 47A20, 60G25,\n60G10.\nAbstract\nNecessary and sufficient conditions are given for the solvability of the operator\nvalued two-variable autoregressive filter problem. In addition, in the two variable suboptimal Nehari problem sufficient conditions are given for when a strictly contractive\nlittle Hankel has a strictly contractive symbol.\n\n1\n\nIntroduction\n\nThe classical autoregressive filter problem asks for the construction of an autoregressive\nfilter based on a finite set of prescribed correlation coefficients c0 , . . . , cn . There is a\nsolution to this problem if and only if the Hermitian Toeplitz matrix C = (ci\u2212j )ni,j=0\nBoth authors are supported in part by grants from the National Science Foundation and by a NATO\nCLG grant\n\u2217\n\n1\n\n\fis positive definite, and in that case the filter coefficients can be read off from the\nfirst column of C \u22121 . While the above problem dates back to the 1950's other aspects\nof the theory of positive semidefinite Toeplitz matrices had already been studied in\ndetail in the early 1900's with the works of Carath\u00e9odory, Fej\u00e9r, Kolomogorov, Riesz,\nSchur, Szeg\u00f6, and Toeplitz (see e.g. [15] for a full account). Multivariable versions were\nconsidered about halfway through the 20th century. Several questions lead to extensive\nmultivariable results (e.g, [24, 25], [5, 6, 8]), while others lead to counterexamples ([3],\n[31], [17], [9], [27], [26]). The specific two variable autoregressive filter problem was\nnot completely solved until recently in [18]. The authors found that in addition to\nan expected positive definiteness requirement of a doubly Toeplitz matrix i.e. a block\nToeplitz matrix whose blocks are themselves Toeplitz matrices, a low rank condition\non a submatrix is necessary for the existence of a two-variable autoregressive filter\nwith a finite set of prescribed correlation coefficients. As it turns out, this low rank\ncondition may be reformulated as a commutativity condition on matrices built form\nthe correlation coefficients. While this was indirectly present in the results in [18] (see\nTheorem 2.2.1), it was not fully recognized as essential until now. This commutativity\ncondition allows for a generalization to the operator case which we will present in this\npaper.\nThe autoregressive filter result yields sufficient conditions on a partially defined\ndoubly Toeplitz matrix to have a positive definite completion, as follows. The notations\nrow(ck )k\u2208K and col(ck )k\u2208K stand for a row and column vector containing the entries\nck , k \u2208 K, respectively. Note that in the statement below matrices appear that have\nrows and columns indexed by pairs of integers.\nTheorem 1.1 Let ck , k \u2208 \u039b := {\u2212n, . . . , n} \u00d7 {\u2212m, . . . , m} \u2282 Z \u00d7 Z be given so that\n(ck\u2212l )k,l\u2208{0,...,n}\u00d7{0,...,m}\nis positive definite. Put\n\u03a6 = (ck\u2212l )k,l\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121} ,\n\u03a61 = (ck\u2212l )k\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121},l\u2208{1,...,n}\u00d7{0,...,m\u22121} ,\n\u03a62 = (ck\u2212l )k\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121},l\u2208{0,...,n\u22121}\u00d7{1,...,m} .\nSuppose that \u03a61 \u03a6\u22121 \u03a6\u22172 = \u03a6\u22172 \u03a6\u22121 \u03a61 and\nc\u2212n,m = Kn,m \u03a6\u22121 K\u0303n,m ,\nwhere\nKn,m = row(ck\u2212l )k=(0,m\u22121),l\u2208{1,...,n}\u00d7{0,...,m\u22121} ,\n\n(1.1)\n\nK\u0303n,m = col(c\u2217k\u2212l )k\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121},l=(n\u22121,1) .\n\n(1.2)\n\nand\nThen there exist ck , k 6\u2208 \u039b, so that (ck\u2212l )k,l\u2208Z\u00d7Z is positive definite (as an operator on\nl2 (Z \u00d7 Z))).\n\n2\n\n\fUsing the connection between positive definite and contractive completion problems\nas it was used in the band method (see, e.g., [12], [20], [32]) one may take the ideas\nthat go in to the proof of Theorem 1.1 and apply them to the two-variable Nehari\nproblem. The classical Nehari problem states that a bounded Hankel operator H has\nan essentially bounded symbol \u03c8, and in fact one can choose \u03c8 so that k\u03c8k\u221e = kHk\n(see, e.g., [29]). In two or more variables the situation is quite different. First of all,\nthere are several types of Hankels to consider. In two variables the most prominent\ntypes are the so-called big Hankel and the little Hankel. In [4] it was shown that\nthere exist bounded big Hankel operators that do not have an essentially bounded\nsymbol. Recently, in [13] it was shown that every bounded small Hankel operator has\nan essentially bounded symbol. The proof in [13] relies on the dual formulation of the\nproblem, due to [14]. In general, though, one cannot find a symbol \u03c8 of a small Hankel\nh, so that khk = k\u03c8k\u221e . We will give sufficient conditions under which this equality can\nbe established in a suboptimal sense. To be more precise, we give sufficient conditions\nunder which khk < 1 implies the existence of a symbol \u03c8 so that k\u03c8k\u221e < 1.\nThe paper is organized as follows. In Section 2 we treat the autoregressive filter\nproblem and as a corollary obtain Theorem 1.1. In Section 3 we treat the two-variable\nNehari problem.\n\n2\n\nOperator valued autoregressive filters\n2\n\nA two-variable polynomial p(z, w) is called stable if p(z, w) is invertible for (z, w) \u2208 D ,\nwhere D stands for the closure of D = {z \u2208 C : |z| < 1}. Also, we denote T = {z \u2208 C :\n|z| = 1}. The notation B(H, K) stands for the Banach space of bounded linear Hilbert\nspace operators acting H \u2192 K. We abbreviate B(H, H) as B(H).\nTheorem 2.1 Given are bounded linear operators cij \u2208 B(H), (i, j) \u2208 \u039b := {\u2212n, . . . , n}\u00d7\n{\u2212m, . . . , m} \\ {(n, m), (\u2212n, m), (n, \u2212m), (\u2212n, \u2212m)}. There exists stable polynomials\nX\nX\np(z, w) =\npij z i wj \u2208 B(H), r(z, w) =\nrij z i wj \u2208 B(H)\n(2.1)\ni\u2208{0,...,n}\nj\u2208{0,...,m}\n\ni\u2208{0,...,n}\nj\u2208{0,...,m}\n\nwith p00 > 0 and r00 > 0 so that\nX\np(z, w)\u2217\u22121 p(z, w)\u22121 =\ncij z i wj = r(z, w)\u22121 r(z, w)\u2217\u22121 , (z, w) \u2208 T2 ,\n\n(2.2)\n\n(i,j)\u2208Z2\n\nfor some cij \u2208 B(H), (i, j) 6\u2208 \u039b, if and only if\n(i) \u03a61 \u03a6\u22121 \u03a6\u22172 = \u03a6\u22172 \u03a6\u22121 \u03a61 ,\n(ii) when we put\nc\u2212n,m = row(ck\u2212l )k=(0,m\u22121),l\u2208{1,...,n}\u00d7{0,...,m\u22121} \u03a6\u22121 col(c\u2217k\u2212l )k\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121},l=(n\u22121,1) ,\nthen the matrices\n(ck\u2212l )k,l\u2208{0,...,n}\u00d7{0,...,m}\\{(n,m)} and (ck\u2212l )k,l\u2208{0,...,n}\u00d7{0,...,m}\\{(0,0)}\nare positive definite.\n\n3\n\n\fHere\n\u03a6 = (ck\u2212l )k,l\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121} ,\n\u03a61 = (ck\u2212l )k\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121},l\u2208{1,...,n}\u00d7{0,...,m\u22121} ,\n\u03a62 = (ck\u2212l )k\u2208{0,...,n\u22121}\u00d7{0,...,m\u22121},l\u2208{0,...,n\u22121}\u00d7{1,...,m} .\nThere is a unique choice for cn,m that results in pn,m = 0, namely\ncn,m = (ck\u2212l )k=(n,m),l\u2208{0,...,n}\u00d7{0,...,m}\\{(0,0),(n,m)} [(ck\u2212l )k,l\u2208{0,...,n}\u00d7{0,...,m}\\{(0,0),(n,m)} ]\u22121 \u00d7\n\u00d7(ck\u2212l )k\u2208{0,...,n}\u00d7{0,...,m}\\{(0,0),(n,m)},l=(0,0) .\nNotice that (i) is equivalent to the statement that \u03a6\u22121 \u03a61 and \u03a6\u22121 \u03a6\u22172 commute.\nThese operators correspond exactly to the operators appearing in Theorem 2.2.1 in\n[18]. When conditions (i) and (ii) are met, the polynomial p may be constructed\nby a Yule-Walker type of equation. Alternatively, the Fourier coefficients cij may be\nconstructed by an iterative process.\nIn the proof of Theorem 2.1 we shall make use of some well-known results, including\nthe 3 \u00d7 3 positive definite operator matrix completion problem and the one-variable\noperator valued autoregressive filter problem. We now recall these results.\nProposition 2.2 Let\n\n\u0012\n\nA B\nB\u2217 C\n\n\u0013\n\nand\n\n\u0012\n\nC D\nD\u2217 E\n\n\u0013\n\nbe positive definite Hilbert space operator matrices. Then there exist operators X so\nthat\n\uf8eb\n\uf8f6\nA B X\nM (X) = \uf8ed B \u2217 C D \uf8f8\nX \u2217 D\u2217 E\n\nis positive definite. E.g., one may choose X = BD \u22121 C =: X0 . In fact, X0 is the\nunique choice for X so that [M (X)\u22121 ]13 = 0.\n\nIt is not hard to prove this result directly. The result also appears in the literature\nin several places, e.g., in [11], [2], [16, Section XVI.3].\nWe will need operator valued generalizations of Theorem 2.1.5 in [18] (see also\nDelsarte et al. [7]) and Lemma 2.3.4 in [18].\nTheorem 2.3 . Let\np(z, w) =\n\nX\n\npij z i wj \u2208 B(H).\n\ni\u2208{0,...,n}\nj\u2208{0,...,m}\n\nThen p(z, w) is stable if and only if p(z, w) is invertible for all z \u2208 D and w \u2208 T and\nfor all z \u2208 T and w \u2208 D.\n\n4\n\n\fProof.\n\nSince p(z, w) is invertible for all z \u2208 D and w \u2208 T we can write\np(z, w)\u22121 =\n\n\u221e\nX\n\ngk (z)wk ,\n\nz \u2208 T, w \u2208 T,\n\nk=\u2212\u221e\n\nwhere gk (z) is analytic for z \u2208 D. The second condition implies that gk (z) = 0 for\n2\nk < 0. Thus p(z, w)\u22121 is analytic for all (z, w) \u2208 D . Thus p(z, w) is invertible for all\n2\n(z, w) \u2208 D , and hence p(z, w) is stable.\n\u0003\nLemma 2.4 Let A be a positive definite r\u00d7r operator matrix with entries Ai,j \u2208 B(H).\nSuppose that for some 1 \u2264 j < k \u2264 r we have that (A\u22121 )kl = 0, l = 1, . . . , j. Write\nA\u22121 = L\u2217 L where L is a lower triangular operator matrix with positive definite diagonal\nentries. Then L satisfies Lkl = 0, l = 1, . . . , j. Moreover, if \u00c3 is the (r \u2212 1) \u00d7 (r \u2212 1)\nmatrix obtained from A by removing the kth row and column, and L\u0303 is the lower\ntriangular factor of \u00c3\u22121 with positive diagonal entries, then\nLil = L\u0303il , i = 1, . . . , k \u2212 1; l = 1, . . . , j,\n\n(2.3)\n\nLi+1,l = L\u0303il , i = k, . . . , r \u2212 1; l = 1, . . . , j.\n\n(2.4)\n\nand\nIn other words, the first j columns of L and L\u0303 coincide after the kth row (which contains\nzeroes in columns 1, . . . , j) in L has been removed.\nProof.\n\nAnalog to the proof of Lemma 2.3.4 in [18].\n\n\u0003\n\nzn\n\nA polynomial A(z) = A0 + . . . + An is called stable if A(z) is invertible for z \u2208 D.\nWe say that B(z) = B0 + . . . + B\u2212n z \u2212n is antistable if B(1/z)\u2217 is stable.\nTheorem 2.5 (The one variable autoregressive filter problem) Let Aj , j = \u2212n, . . . , n,\nbe given Hilbert space operators, so that the Toeplitz matrix (Ai\u2212j )ni,j=0 is positive\ndefinite. Let P0 , . . . , Pn and Q\u2212n , . . . , Q0 be defined via\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n\uf8f6\n\uf8f6\uf8eb\n\uf8eb\n\uf8f6\uf8eb \uf8f6\n\uf8eb\n0\nI\nQ\u2212n\nA0 * * * A\u2212n\nP0\nA0 * * * A\u2212n\n\uf8ec .. \uf8f7\n\uf8ec 0\uf8f7\n\uf8ec ..\n.. \uf8f7 \uf8ec .. \uf8f7 = \uf8ec . \uf8f7 .\n.. \uf8f7 \uf8ec .. \uf8f7 = \uf8ec \uf8f7 , \uf8ec ..\n\uf8f7\n\uf8ed .\n.\uf8f7 \uf8ed .\n. \uf8f8\uf8ed . \uf8f8 \uf8ec\n. \uf8f8\uf8ed . \uf8f8 \uf8ec\n\uf8ed0 \uf8f8\n\uf8ed .. \uf8f8\nQ0\nAn * * * A0\nPn\nAn * * * A0\nI\n0\n\nWrite P0 = BB \u2217 and P\nQ0 = CC \u2217 with B and P\nC invertible, and put Ri = Pi B \u2217\u22121 ,\nSi = Qi C \u2217\u22121 , R(z) = ni=0 Ri z i , and S(z) = 0i=\u2212n Si z i . Then R(z) is stable and\nS(z) is anti-stable. Moreover,\nR(z)\u2217\u22121 R(z)\u22121 = S(z)\u2217\u22121 S(z)\u22121 =\n\n\u221e\nX\n\nAj z j , z \u2208 T,\n\nj=\u2212\u221e\n\nfor some Aj =\n\nA\u2217\u2212j , j\n\nA\u2217r = A\u2212r\n\n> n. In fact, Aj , |j| > n, is given inductively via\n\uf8f6\n\uf8eb\nA\u2212r+1\n\u0001\n\uf8f7\nn\u22121 \u22121 \uf8ec\n= A\u22121 * * * A\u2212n [(Ai\u2212j )i,j=0\n] \uf8ed ... \uf8f8 , r \u2265 n + 1.\nA\u2212r+n\n\n5\n\n\fThe matrix version of this result goes back to [10]. The operator valued case\nappeared first in [21]. One may also consult [32, Section III.3] or [22, Chapter XXXIV].\nWe will need the notions of left and P\nright stable factorizations of operator valued\ntrigonometric polynomials. Let A(z) = ni=\u2212n Ai z i be a matrix-valued trigonometric\npolynomial that is positive definite on T, i.e., A(z) > 0 for |z| = 1. In particular, since\nthe values of A(z) on the unit circle are Hermitian, we have Ai = A\u2217\u2212i , i = 0, . . . , n.\nThe positive matrix function A(z) allows a left stable factorization, that is, we may\nwrite\nA(z) = M (z)M (1/z)\u2217 , z \u2208 C \\ {0},\nwith M (z) a stable matrix polynomial of degree n. In the scalar case, this is the\nwell-known Fej\u00e9r-Riesz factorization and goes back to the early 1900's. For the matrix case the result goes back to [30] and [23]. When we require that M (0) is lower\ntriangular with positive definite diagonal entries, the stable factorization is unique.\nWe shall refer to this unique factor M (z) as the left stable factor of A(z). Similarly, we define right variations of the above notions. In particular, if N (z) is so that\nA(z) = N (1/z)\u2217 N (z), z \u2208 C \\ {0}, N (z) is stable and N (0) is lower triangular with\npositive definite diagonal elements, then N (z) is called the right stable factor of A(z).\nProof of Theorem 2.1. Observe that \u03a6i \u03a6\u22121 and \u03a6\u22121 \u03a6i , i = 1, 2, have the\nfollowing companion type forms:\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n0\n\u2217\n\u2217 *** \u2217 \u2217\n\uf8ec ..\n\uf8f7\n\uf8ecI 0\n\uf8f7\n\uf8ecI\n.\n\u2217\uf8f7\n\uf8ec\n\uf8f7 \u22121\n\u22121\n\uf8ec\n\uf8f7\n\u03a61 \u03a6 = \uf8ec\n(2.5)\n\uf8f7 , \u03a6 \u03a61 = \uf8ec .\n.. ..\n.. \uf8f7 ,\n\uf8ed\n.\n.\n. \uf8f8\n\uf8ed\n. 0 .\uf8f8\nI 0\nI \u2217\n\uf8f6\n\uf8eb\n\u2217 ***\n\u2217 \u2217\n\uf8f7\n\uf8ec\u03b4ij I 0\n\uf8f7\n\uf8ec\nn\u22121\n(2.6)\n, Qij = \uf8ec\n\u03a6\u22172 \u03a6\u22121 = (Qij )i,j=0\n\uf8f7,\n..\n..\n\uf8f8\n\uf8ed\n.\n.\n\uf8eb\n\n0\n\uf8ec\n\uf8ec\u03b4ij I\nn\u22121\n\u03a6\u22121 \u03a6\u22172 = (Rij )i,j=0\n, Rij = \uf8ec\n\uf8ec\n\uf8ed\n\n\u03b4ij I 0\n\uf8f6\n\u2217\n\uf8f7\n..\n.\n\u2217\uf8f7\n\uf8f7\n.. \uf8f7 ,\n..\n.\n0\n.\uf8f8\n\u03b4ij I \u2217\n\n(2.7)\n\nn\u22121\nsatisfies\nwhere \u03b4ij = 1 when i = j and \u03b4ij = 0 otherwise. Consequently, if S = (Sij )i,j=0\n\n\u03a61 \u03a6\u22121 S = S\u03a6\u22121 \u03a61 ,\n\n(2.8)\n\nthen S is block Toeplitz (i.e., Sij = Si+1,j+1 for all 0 \u2264 i, j \u2264 n \u2212 2). Next, if\nn\u22121\nS = (Sij )i,j=0\nsatisfies\n\u03a6\u22172 \u03a6\u22121 S = S\u03a6\u22121 \u03a6\u22172 ,\n(2.9)\nthen each Sij is Toeplitz. It follows from (i) that all expressions of the form\nS = \u03a8i1 \u03a6\u22121 \u03a8i2 \u03a6\u22121 * * * \u03a6\u22121 \u03a8ik ,\n\n6\n\n(2.10)\n\n\fwhere ij \u2208 {1, 2}, \u03a81 = \u03a61 and \u03a82 = \u03a6\u22172 , satisfy (2.8) and (2.9). Thus all expressions S\nin (2.10) are doubly Toeplitz. In particular, \u03a61 \u03a6\u22121 \u03a6\u22172 = \u03a6\u22172 \u03a6\u22121 \u03a61 is doubly Toeplitz.\nUpon closer inspection we have that\nn\u22121\nm m\u22121\n\u03a61 \u03a6\u22121 \u03a6\u22172 = (\u0393i\u2212j )n\u22122\ni=\u22121,j=0 , \u0393k = (ck,r\u2212s )r=1,s=0 ,\n\n(2.11)\n\nwhere c\u2212n,m is defined by this equation to be as under (ii). Notice that due to (2.11)\nwe have that\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\ne0\n0\nc\u22121,1 * * * c\u2212n,1\n\u0001\n\uf8f7\n\uf8ec\n\uf8ec ..\n..\n... \uf8f7\n(2.12)\n\uf8f8,\n\uf8f8 = I 0 * * * 0 \u03a61 \u03a6\u22121 \u03a6\u22172 \uf8ed\n\uf8ed .\n.\n0\ne0\nc\u22121,m * * * c\u2212nm\n\n\u0001\u2217\nwith e0 = 1 0 * * * 0 . Due to (ii) and the 3\u00d73 positive definite matrix completion\nproblem, we can choose cn,m = c\u2217\u2212n,\u2212m so that \u0393 := (ck\u2212l )k,l\u2208{0,...,n}\u00d7{0,...,m} > 0. View\n\u0393 = (Ci\u2212j )ni,j=0 where Ck = (ck,r\u2212s )m\nr,s=0 , and extend \u0393 following the one variable\n\u221e\ntheory to (Ci\u2212j )i,j=0 , where\nCr\u2217 = C\u2212r = C\u22121 * * *\n\nEquivalently, if we let\n\n\uf8eb\n\n\uf8f6\nC\u2212r+1\n\u0001\n\uf8f7\nn\u22121 \u22121 \uf8ec\n] \uf8ed ... \uf8f8 , r \u2265 n + 1.\nC\u2212n [(Ci\u2212j )i,j=0\nC\u2212r+n\n\uf8eb \uf8f6\nI\nQ0\n\uf8ec 0\uf8f7\n\uf8ec .. \uf8f7\n\u22121 \uf8ec \uf8f7\n\uf8ed . \uf8f8 = \u0393 \uf8ec .. \uf8f7 ,\n\uf8ed.\uf8f8\nQn\n0\n\uf8eb\n\n\uf8f6\n\nand we factor Q0 = LL\u2217 with L lower triangular, and put Pj = Qj L\u2217\u22121 , j = 0, . . . , n,\nthen P (z) := P0 + . . . + z n Pn is stable and\n\u221e\nX\n\nCj z j = P (z)\u2217\u22121 P (z)\u22121 , z \u2208 T.\n\nj=\u2212\u221e\n\nDue to (2.12) it follows from Lemma 2.4 that Pj is of the form\n\uf8eb\n\uf8f6\n\uf8eb pj0 \uf8f6 0\n\uf8ec pj1\n\uf8f7\n\uf8ec\n\uf8f7\nPj = \uf8ec\uf8ec . \uf8f7\n\uf8f7 , j = 0, . . . , n.\n\uf8ed\uf8ed .. \uf8f8 P\u0303j \uf8f8\npjm\n\nBut then it follows that P\u0303 (z) := P\u03030 + . . . + z n P\u0303n is stable, and that\n\u221e\nX\n\nC\u0303j z j = P\u0303 (z)\u2217\u22121 P\u0303 (z)\u22121 , z \u2208 T,\n\nj=\u2212\u221e\n\n7\n\n(2.13)\n\n\fwhere C\u0303j is obtained from Cj by leaving out the first row and column.\nSimilarly, if we let\n\uf8eb \uf8f6\n\uf8eb\n\uf8f6\n0\nR\u2212n\n\uf8ec .. \uf8f7\n\uf8ec .. \uf8f7\n\u22121 \uf8ec \uf8f7\n\uf8ed . \uf8f8 = \u0393 \uf8ec.\uf8f7 ,\n\uf8ed 0\uf8f8\nR0\nI\n\nand we factor R0 = U U \u2217 with U upper triangular, and put Sj = Rj U \u2217\u22121 , j = \u2212n, . . . , 0,\nthen S(z) := S0 + . . . + z \u2212n S\u2212n is anti-stable and\n\u221e\nX\n\nCj z j = S(z)\u2217\u22121 S(z)\u22121 , z \u2208 T.\n\nj=\u2212\u221e\n\nDue to (2.12) it follows from Lemma 2.4 that Sj is of the form\n\uf8eb\n\uf8f6\uf8f6\n\uf8eb\np\u0303j,\u2212m\n\uf8ec . \uf8f7\uf8f7\n\uf8ec\n\uf8ecS\u0303 \uf8ed .. \uf8f8\uf8f7\nSj = \uf8ec j\n\uf8f7 , j = \u2212n, . . . , 0.\n\uf8ed\np\u0303j,\u22121 \uf8f8\n0\np\u03030j\n\n(2.14)\n\nBut then it follows that S\u0303(z) := S\u03030 + . . . + z \u2212n S\u0303\u2212n is anti-stable, and that\n\u221e\nX\n\n\u0108j z j = S\u0303(z)\u2217\u22121 S\u0303(z)\u22121 , z \u2208 T,\n\nj=\u2212\u221e\n\nwhere \u0108j is obtained from Cj by leaving out the last row and column.\nDue to the block Toeplitzness of Cj , j = \u2212n, . . . , n, we have that C\u0303j = \u0108j , j =\n\u2212n, . . . , n. As S\u0303(z) and P\u0303 (z) follow the one variable construction with (C\u0303i\u2212j )ni,j=0 =\n(\u0108i\u2212j )ni,j=0 , we have by the one variable theory that\nP\u0303 (z)\u2217\u22121 P\u0303 (z)\u22121 = S\u0303(z)\u2217\u22121 S\u0303(z)\u22121 , z \u2208 T,\nand thus C\u0303j = \u0108j , j \u2208 Z. Thus Cj is Toeplitz for all j. Denote Cj = (cj,r\u2212s )m\nr,s=0 .\nP\u221e\nj\n\u221e\nAs j=\u2212\u221e Cj z > 0, j \u2208 T, we have that the infinite block Toeplitz (Ci\u2212j )i,j=\u2212\u221e\nis positive definite. We may regroup this infinite block Toeplitz matrix with Toeplitz\nentries as (Ti\u2212j )m\ni,j=0 where\nTj = (cr\u2212s,j )\u221e\nr,s=\u2212\u221e .\nTaking equality (2.13), and performing a regouping and extracting the first column\nfrom Pi , one arrives at\n\uf8eb \uf8f6\n\uf8f6\uf8eb \uf8f6\n\uf8eb\nQ0\n\u03a00\nT0 * * * T\u2212m\n\uf8ec0\uf8f7\n\uf8ec ..\n.. \uf8f7 \uf8ec .. \uf8f7 = \uf8ec \uf8f7 ,\n\uf8ed .\n. \uf8f7\n. \uf8f8\uf8ed . \uf8f8 \uf8ec\n\uf8ed .. \uf8f8\n\u03a0m\nTm * * *\nT0\no\n\n8\n\n\f\u22121\n\u221e\nwhere \u03a0j = (pr\u2212s,j )\u221e\nr,s=\u2212\u221e , Q0 = \u03a00 = (qr\u2212s,0 )r,s=\u2212\u221e , pij = 0 for i < 0 or i > n,\nj < 0 or j > m and\nn\n0\nX\nX\npi0 z i )\u2217\u22121 .\nqi0 z i := (\nq(z) =\ni=0\n\ni=\u2212\u221e\n\nPn\n\nNote that q(z) is indeed anti-analytic as i=0 pi0 z i is stable. The one variable theory\nnow yields that\n\u03a0(w) := \u03a00 + . . . + \u03a0m wm\nis invertible\nall w \u2208 D. As \u03a0(w) is Toeplitz, its symbol is invertible on T, and thus\nPfor P\ni j\np(z, w) = ni=0 m\nj=0 pij z w is invertible for all |w| \u2264 1 and |z| = 1. By reversing the\nroles of z and w one can prove in a similar way that p(z, w) is invertible for all |z| \u2264 1\nand |w| = 1. Combining these two statements yields by Theorem 2.3 that p(z, w) is\nstable. In addition, we obtain that\n\u03a0(w)\u2217\u22121 \u03a0(w)\u22121\nhas Fourier coefficients T\u2212m , . . . , Tm . But then it follows that\np(z, w)\u2217\u22121 p(z, w)\u22121\nhas Fourier coefficients cij . Similarly, one proves that r(z, w) :=\n\nP\n\ni\u2208{0,...,n}\nj\u2208{0,...,m}\n\np\u0303\u2217\u2212i,\u2212j z i wj\n\nis stable and r(z, w)\u22121 r(z, w)\u2217\u22121 has Fourier coefficients cij . This proves one direction\nof the theorem.\nFor the converse,\nP let p and r as in (2.1) be stablePand suppose ithat (2.2) holds.\nDenote f (z, w) = (i,j)\u2208Z2 cij z i wj . Write f (z, w) = \u221e\ni=\u2212\u221e fi (z)w . Then Tk (z) :=\nk\n(fi\u2212j (z))i,j=0 > 0 for all k \u2208 N0 and all z \u2208 T. Next, write\np(z, w) =\n\nm\nX\n\npi (z)wi , r(z, w) =\n\nm\nX\n\nri (z)wi ,\n\ni=0\n\ni=0\n\nand put pi (z) = ri (z) \u2261 0 for i > m. By the inverse formula for block Toeplitz matrices\n[19] we have that for k \u2265 m \u2212 1 and z \u2208 T\n\uf8f6\n\uf8eb\n\uf8f6\uf8eb\np0 (z)\np\u03040 (1/z)\u2217 * * * pk (1/z)\u2217\n\uf8f7\n\uf8ec\n\uf8f7\uf8ec\n..\n..\n..\nTk (z)\u22121 = \uf8ed ...\n\uf8f8\u2212\n\uf8f8\uf8ed\n.\n.\n.\npk (z) * * *\nrk+1 (1/z)\u2217\n\uf8ec\n..\n..\n\u2212\uf8ed\n.\n.\n\uf8eb\n\nr1 (1/z)\u2217\n\n***\n\np0 (z)\n\nrk+1 (1/z)\u2217\n\np0 (1/z)\u2217 \uf8f6\n\uf8f6\uf8eb\nrk+1 (z) * * *\nr1 (z)\n\uf8f7\uf8ec\n.. \uf8f7 =: E (z)\n.\n..\n\uf8f8\uf8ed\nk\n. \uf8f8\nrk+1 (z)\n\n(2.15)\n\nAs was proven in [18, Proposition 2.1.2] for the scalar case, we have that for k \u2265 m \u2212 1,\nthe left stable factors Mk (z) and Mk+1 (z) of Ek (z) and Ek+1 (z), respectively, satisfy\n\u0012\n\u0013\np0 (z)\n0\nMk+1 (z) =\n.\n(2.16)\ncol(pl (z))k+1\nMk (z)\nl=1\n\n9\n\n\fIndeed, if we define Mk+1 (z) by this equality, then writing out the product Mk+1 (z)Mk+1 (1/z\u0304)\u2217\nand comparing it to Ek+1 (z), it is straightforward to see that Mk+1 (z)Mk+1 (1/z\u0304)\u2217 =\nEk+1 (z). Since both p0 (z) and Mk (z) are stable, Mk+1 (z) is stable as well. Moreover, since p0 (0) > 0 and Mk (0) is lower triangular with positive diagonal entries,\nthe same holds for Mk+1 (0). Thus Mk+1 (z) must be the stable factor\nP\u221e of Ek+1k(z).\nm\nLet Ck = (ck,r\u2212s )r,s=0 as before. Then we have that Tm (z) =\n=\nk=\u2212\u221e Ck z\n\u2217\u22121\nn\nMm (1/z\u0304) Mm (z). Writing Mm (z) = P0 + . . . + z Pn it follows from the one-variable\nresult that\n\uf8eb \u2217\u22121 \uf8f6\n\uf8f6\uf8eb \uf8f6\n\uf8eb\nP0\nP0\nC0 * * * C\u2212n\n\uf8ec 0 \uf8f7\n\uf8f7\n\uf8ec ..\n.. \uf8f7 \uf8ec .. \uf8f7 = \uf8ec\n\uf8ed .\n. \uf8f7.\n. \uf8f8\uf8ed . \uf8f8 \uf8ec\n\uf8ed .. \uf8f8\nPn\nCn * * * C0\n0\n\nDue to the zeros in P1 , . . . , Pn (see (2.16)) it follows from Proposition 2.2 that (2.12)\nholds. By a similar argument, reversing the roles of z and w, we obtain that\n\uf8f6\n\uf8eb\n\uf8eb\n\uf8f6\uf8eb\n\uf8f6\n0\ne0 * * * C\ne\u2212n\nC\nS\u2212n\n\uf8ec . \uf8f7\n\uf8ec ..\n.. \uf8f7 \uf8ec .. \uf8f7 = \uf8ec .. \uf8f7 ,\n\uf8f7\n\uf8ed .\n. \uf8f8\uf8ed . \uf8f8 \uf8ec\n\uf8ed 0 \uf8f8\nen * * * C\ne0\nS0\nC\nS0\u2217\u22121\n\nek = (cr\u2212s,k )n\nwhere C\nr,s=0 and Sj has the form as in (2.14). Using the zero structure\nof S\u22121 , . . . , S\u2212n one obtains equality (2.12) with \u03a61 \u03a6\u22121 \u03a6\u22172 replaced by \u03a6\u22172 \u03a6\u22121 \u03a61 . But\nthen it follows that\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\ne0\n0\ne0\n0\n\u0001 \u2217 \u22121 \uf8ec\n\u0001\n\uf8f7\n\uf8f7\n\uf8ec\n..\n..\nI 0 * * * 0 \u03a61 \u03a6\u22121 \u03a6\u22172 \uf8ed\n\uf8f8.\n\uf8f8 = I 0 * * * 0 \u03a62 \u03a6 \u03a61 \uf8ed\n.\n.\n\ne0\n(2.17)\nDue to (2.5)-(2.7) it is easily seen that \u03a6\u22172 \u03a6\u22121 \u03a61 and \u03a61 \u03a6\u22121 \u03a6\u22172 have the same block\nentries anywhere else, so combining this with (2.17) gives that \u03a6\u22172 \u03a6\u22121 \u03a61 = \u03a61 \u03a6\u22121 \u03a6\u22172 .\nThis yields (i) and the equality for c\u2212n,m in (ii). The positive definiteness of the\nmatrices in (ii) follows as they are restriction of the multiplication operator with symbol\nf , which takes on positive definite values on T2 .\n\u0003\nProof of Theorem 1.1. Follows directly from Theorem 2.1.\n\u0003\n0\n\n3\n\n0\n\ne0\n\nNehari's problem in two variables\n\nWe start by stating a version of the operator valued one-variable Nehari result that\nwill be useful in our two-variable result. The operator valued Nehari result is due to\nPage [28] who proved it using its connection to the commutant lifting theorem, and\nindependently to Adamjan, Arov and Krein [1] who had a matricial approach. The\nlatter approach is close to the one we employ here.\n2 (K) denote the Hilbert space of sequences \u03b7 = (\u03b7 )\nWe let lH\nj j\u2208K satisfying k\u03b7k :=\nqP\n2\nj\u2208K k\u03b7j kH < \u221e. We shall typically write Hankels in a Toeplitz like format by\n\n10\n\n\freversing the order of the columns of our Hankel matrices. E.g., in the one-variable case\nour Hankels shall typically act l2 (\u2212N0 ) \u2192 l2 (N0 ) as opposed to the usual convention\nof acting l2 (N0 ) \u2192 l2 (N0 ).\nTheorem 3.1 Let \u0393i \u2208 L(H, K), i \u2265 0, be bounded linear Hilbert space operators so\nthat the Hankel\n\uf8f6\n\uf8eb\n\u03931 \u03930\n\uf8f7\n\uf8ec\n..\n\uf8ec\n. \u03931 \uf8f7 : l2 (\u2212N ) \u2192 l2 (N ),\n(3.1)\nH := \uf8ec\n\uf8f7 K\n0\n0\nH\n\uf8f8\n\uf8ed\nis a strict contraction. Solve for operators \u22060 , D\u22121 , D\u22122 , . . . , B0 , B1 , . . ., satisfying the\nYule-Walker type equation\n\u0012\n\u0013\u0012 \u0013 \u0012 \u0013\nI H\nB\n0\n=\n,\n(3.2)\nH\u2217 I\nD\n\u2206\nwhere\n\uf8eb \uf8f6\n\uf8eb\n\uf8f6\n\uf8eb \uf8f6\n..\n..\nB0\n.\n\uf8ecB1 \uf8f7\n\uf8ec\n\uf8f7\n\uf8ec . \uf8f7\n\uf8ec \uf8f7\n\uf8ec\n\uf8f7\n\uf8ec \uf8f7\n2\n2\n2\nB = \uf8ecB \uf8f7 : K \u2192 lH\n(N0 ), D = \uf8ecD\u22122 \uf8f7 : K \u2192 lK\n(\u2212N0 ), \u2206 = \uf8ec 0 \uf8f7 : K \u2192 lK\n(\u2212N0 ).\n2\n\uf8ed \uf8f8\n\uf8edD\u22121 \uf8f8\n\uf8ed0\uf8f8\n..\n.\nIK\n\u22060\n\nFor j = \u22121, \u22122, . . . , put\n\n\u0393j = \u2212\u0393j+1 D\u22121 \u2212 \u0393j+2 D\u22122 \u2212 . . . = \u2212\n\n\u221e\nX\n\n\u0393j+k D\u2212k .\n\n(3.3)\n\nk=1\n\nP\u221e\n\nThen f \u223c j=\u2212\u221e \u0393j z j belongs to L\u221e\nH (T) and kf k\u221e < 1.\nAlternatively, the Fourier coefficients \u0393j of f may be constructed as follows. Solve\nfor operators \u03b10 , A1 , A2 , . . . , C0 , C\u22121 , . . ., satisfying the Yule-Walker type equation\n\u0012\n\u0013\u0012 \u0013 \u0012 \u0013\nI H\nA\n\u03b1\n=\n,\n(3.4)\nH\u2217 I\nC\n0\nwhere\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb \uf8f6\n..\n\u03b10\nIH\n\uf8ec . \uf8f7\n\uf8ec0\uf8f7\n\uf8ecA1 \uf8f7\n\uf8ec\n\uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n2\n2\n2\n(N0 ).\n(N0 ), C = \uf8ecC\u22122 \uf8f7 : H \u2192 lK\n(\u2212N0 ), \u03b1 = \uf8ec 0 \uf8f7 : H \u2192 lH\nA = \uf8ecA \uf8f7 : H \u2192 lH\n\uf8edC\u22121 \uf8f8\n\uf8ed \uf8f8\n\uf8ed 2\uf8f8\n..\n..\n.\n.\nC0\n\uf8eb\n\nFor j = \u22121, \u22122, . . . ,, \u0393\u2217j may be calculated from,\n\n\u0393\u2217j = \u2212\u0393\u2217j+1 A1 \u2212 \u0393\u2217j+2 A2 \u2212 . . . = \u2212\n\n\u221e\nX\nk=1\n\n11\n\n\u0393\u2217j+k Ak .\n\n(3.5)\n\n\fProof. Let\n\n\uf8eb\n\nThen it follows from (3.2) that\n\u0012\nwhere\n\n\uf8f6\n\u03932 \u03931\n\uf8f7\n..\n. \u03932 \uf8f7 .\n\uf8f7\n\uf8f8\n\n\uf8ec\n\uf8ec\nH\u0303 = \uf8ec\n\uf8ed\nI H\u0303\nH\u0303 \u2217 I\n\n\u0013\u0012 \u0013\n\u0012 \u0013\nB\n\u0393\n=\u2212\n,\n0\nD\u0303\n\n\uf8f6\n\uf8f6\n\uf8eb\n..\n\u03930\n\uf8ec . \uf8f7\n\uf8ec \uf8f7\n\u0393 = \uf8ed\u03931 \uf8f8 , D\u0303 = \uf8edD\u22122 \uf8f8 .\n..\nD\u22121\n.\n\uf8eb\n\nBut then it follows that (3.3) is equivalent to the equation\n\u0393j = 0 Zj+1\nwhere\n\n\u0001\n\n\u0012\n\nI H\u0303\nH\u0303 \u2217 I\n\n\u0013\u22121 \u0012 \u0013\n\u0393\n, j \u2264 \u22121,\n0\n\n\u0001\n\u0393k+1 \u0393k .\n\nZk = * * *\n\n(3.6)\n\nBut this coincides exactly with the iterative process described in [1] (see also [29,\nSection 2.2]), and thus the conclusion follows from there.\nFor the alternative construction of \u0393j , use that (3.4) implies that\n\u0012\nwhere\n\nI H\u0303\nH\u0303 \u2217 I\n\n\u0013\u0012 \u0013\n\u0012 \u0013\n0\n\u00c3\n,\n=\u2212\nC\n\u0393\u0302\n\n\uf8f6\n\uf8eb \uf8f6\n..\nA1\n.\n\uf8ecA2 \uf8f7\n\uf8ec \u2217\uf8f7\n\u0393\u0302 = \uf8ed\u0393 \uf8f8 , \u00c3 = \uf8ed \uf8f8 .\n1\n..\n.\n\u0393\u22170\n\uf8eb\n\nBut then (3.5) is equivalent to the equality\n\nwith\n\n\u0001\n\u0393\u2217j = \u1e90j+1 0\n\n\u0012\n\nI H\u0303\nH\u0303 \u2217 I\n\n\u0013\u22121 \u0012 \u0013\n0\n,\n\u0393\u0302\n\n\u0001\n\u1e90k = \u0393k \u0393k+1 * * * ,\n\nwhich yields the same sequence of operators \u0393k , k \u2264 \u22121, as in (3.6). \u0003\nWe now come to the main result in this section.\n\n12\n\n\fTheorem 3.2 Let \u03b3ij \u2208 L(H, K), i, j \u2265 0, be given so that the little Hankel operator\n2 (\u2212N \u00d7 \u2212N ) \u2192 l2 (N \u00d7 N ) defined via\nh\u03b3 : lK\n0\n0\n0\n0\nH\n\uf8f6\n\uf8f6\n\uf8eb\n\uf8eb\n\u03b3j1 \u03b3j0\n\u03931 \u03930\n\uf8f7\n\uf8f7\n\uf8ec\n\uf8ec\n..\n..\n\uf8ec\n. \u03b3j1 \uf8f7 ,\n. \u03931 \uf8f7 , \u0393 = \uf8ec\nh\u03b3 = \uf8ec\n\uf8f7\n\uf8f7\n\uf8ec\nj\n\uf8f8\n\uf8f8\n\uf8ed\n\uf8ed\n\nis a strict contraction. Put\n\u0012\n\u0013\n\u0012\n\u0013\nI h\u03b3\nI h\u03b3\n\u2217\n\u2217\n\u2217\n\u2217\n\u03a6 = PN0 \u00d7N \u2295P\u2212N\u00d7\u2212N0\nP\n\u2295P\n=\nP\n\u2295P\nPN\u00d7N\n\u2295P\u2212N\n,\nN\u00d7N0\n\u2212N0 \u00d7\u2212N\nN0 \u00d7N\n\u2212N\u00d7\u2212N0\n0\n0 \u00d7\u2212N\nh\u2217\u03b3 I\nh\u2217\u03b3 I\n\u0012\n\u0013\n\u0012\n\u0013\nI h\u03b3\nI h\u03b3\n\u2217\n\u2217\n\u2217\n\u2217\n\u03a61 = PN0 \u00d7N0 \u2295P\u2212N\u00d7\u2212N\nP\n\u2295P\n=\nP\n\u2295P\n\u2295P\u2212N\nPN\u00d7N\n,\nN0 \u00d7N\n\u2212N\u00d7\u2212N0\nN\u00d7N0\n\u2212N0 \u00d7\u2212N\n0 \u00d7\u2212N0\nh\u2217\u03b3 I\nh\u2217\u03b3 I\n\u0012\n\u0013\n\u0012\n\u0013\nI h\u03b3\nI h\u03b3\n\u2217\n\u2217\n\u2217\n\u2217\n\u03a62 = PN0 \u00d7N0 \u2295P\u2212N\u00d7\u2212N\nPN0 \u00d7N \u2295P\u2212N\u00d7\u2212N0 = PN\u00d7N0 \u2295P\u2212N0 \u00d7\u2212N\n\u2295P\u2212N\nPN\u00d7N\n,\n0 \u00d7\u2212N0\nh\u2217\u03b3 I\nh\u2217\u03b3 I\n\nwhere the projection PK : l2 (M ) \u2192 l2 (K), K \u2286 M, is defined by Pk ((\u03b7j )j\u2208M ) =\n(\u03b7j )j\u2208K . Suppose that\n\u03a61 \u03a6\u22121 \u03a6\u22172 = \u03a6\u22172 \u03a6\u22121 \u03a61 .\n(3.7)\nThen there exist \u03b3ij \u2208 L(H), (i, j) \u2208 (Z \u00d7 \u2212N) \u222a (\u2212N \u00d7 Z), so that the operator matrix\n2\n2\n(\u03b3i\u2212j,k\u2212l )i,j,k,l\u2208Z : lK\n(Z \u00d7 Z) \u2192 lH\n(Z \u00d7 Z)\n\nis a strict contraction. Equivalently, the essentially bounded function f \u223c\nsatisfies kf k\u221e < 1.\n\nP\n\ni,j\u2208Z \u03b3ij z\n\ni wj\n\nProof. We start by applying Theorem 3.1 to construct \u0393j , j \u2264 \u22121, via (3.3) or,\nequivalently, (3.5), yielding the strict contraction\n(\u0393i\u2212j )i,j\u2208Z : ll22 (\u2212N0 ) (Z) \u2192 ll22 (N0 ) (Z).\nK\n\nH\n\nThe main step in the proof is to show that (3.7) implies that \u0393j , j \u2264 \u22121, are also\nHankel; that is, they are of the form\n\uf8f6\n\uf8eb\n\u03b3j1 \u03b3j0\n\uf8f7\n\uf8ec\n..\n\uf8ec\n. \u03b3j1 \uf8f7 , j \u2264 \u22121,\n\u0393j = \uf8ec\n\uf8f7\n\uf8f8\n\uf8ed\n\nfor some operators \u03b3ij , j \u2265 0, i \u2264\nclaim.\nClaim. Equation (3.7) implies\nform\n\uf8eb\n..\n.\n\uf8ec\n\uf8ec* * * \u2217\nDj = \uf8ec\n\uf8ed* * * \u2217\n*** 0\n\n\u22121. To show this we need to prove the following\n\nthat the operators Dj , j \u2264 \u22121, in (3.2) are of the\n\uf8f6\n.. ..\n. .\uf8f7\n2\n2\n\u2217 \u2217\uf8f7\n(\u2212N0 ) \u2192 lK\n(\u2212N0 ).\n\uf8f7 : lK\n\u2217 \u2217\uf8f8\n0 \u2217\n\n13\n\n\fSimilarly, (3.7) implies that Aj\n\uf8eb\n\u2217\n\uf8ec\u2217\n\uf8ec\nAj = \uf8ec\u2217\n\uf8ed\n..\n.\n\nin (3.4) is of the form\n\uf8f6\n0 0 ***\n\u2217 \u2217 ***\uf8f7\n\uf8f7 2\n2\n: l (N0 ) \u2192 lH\n(N0 ).\n\u2217 \u2217 ***\uf8f7\n\uf8f8 H\n.. ..\n. .\n\nProof of Claim. It is not hard to see that \u03a6i \u03a6\u22121 and \u03a6\u22121 \u03a6i , i = 1, 2, have a\ncertain companion type form (variations of the ones in the proof of Theorem 2.1). For\ninstance,\n\u0012\n\u0013\n\u0012\n\u0013\nZ Q\u0302\n\u015c Q\n\u03a61 \u03a6\u22121 =\n, \u03a6\u22121 \u03a61 =\n,\n0 S\n0 \u1e90\nwhere \u015c and \u1e90 have an infinite companion form\n\uf8eb\n\uf8f6\n\uf8eb\n\u2217 \u2217 ***\n..\n\uf8ecI\n\uf8f7\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\u015c = \uf8ec I\n\uf8f7 , \u1e90 = \uf8ed\nI\n\uf8ed\n\uf8f8\n..\nI\n.\n\n\uf8f6\n..\n.\uf8f7\n\u2217\uf8f8 ,\n\u2217\n\nthe operators S and Z are shifts\n\uf8eb\n\n\uf8ec\nS=\uf8ed\n\n..\n\n.\nI\n\n\uf8eb\n\uf8f6\n\uf8f6\n0 0 ***\n..\n\uf8ecI\n\uf8f7\n.\uf8f7\n\uf8ec\n\uf8f7\n,\nZ\n=\n\uf8ec\n\uf8f7,\n\uf8f8\n0\nI\n\uf8ed\n\uf8f8\n..\nI 0\n.\n\nand Q and Q\u0302 are zero except for the first block row and last block column, respectively:\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n.. ..\n\u2217 \u2217 ***\n.\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\nQ = \uf8ed0 0 * * * \uf8f8 , Q\u0302 = \uf8ed* * * 0 \u2217\uf8f8 .\n.. ..\n. .\n*** 0 \u2217\n\nBut then, viewing R := \u03a6\u22172 \u03a6\u22121 \u03a61 = \u03a61 \u03a6\u22121 \u03a6\u22172 in the four possible ways (\u03a6\u22172 \u03a6\u22121 )\u03a61 ,\n\u03a6\u22172 (\u03a6\u22121 \u03a61 ), (\u03a61 \u03a6\u22121 )\u03a6\u22172 , \u03a61 (\u03a6\u22121 \u03a6\u22172 ) one easily deduces that\n\u0012\n\u0013\nI h\u03b3\n\u22121 \u2217\n\u2217 \u22121\n\u2217\n\u2217\n\u03a61 \u03a6 \u03a62 = \u03a62 \u03a6 \u03a61 = PN0 \u00d7N \u2295 P\u2212N\u00d7\u2212N0\nPN\u00d7N\n\u2295 P\u2212N\n.\n0\n0 \u00d7\u2212N\nh\u2217\u03b3 I\nMultiplying the above equation on the left with 0 \u2295 P\u2212N\u00d7{0} and on the right with\n\u2217\n0 \u2295 P{0}\u00d7\u2212N\ngives that Y W \u22121 U = X, where U, W, X and Y are defined via\n\u0013\nI h\u03b3\n\u2217\nY = 0 \u2295 P\u2212N\u00d7{0}\nPN\u22170 \u00d7N0 \u2295 P\u2212N\u00d7\u2212N\n,\nh\u2217\u03b3 I\n\u0013\n\u0012\nI h\u03b3\n\u2217\nW = PN0 \u00d7N0 \u2295 P\u2212N\u00d7\u2212N\nPN\u22170 \u00d7N0 \u2295 P\u2212N\u00d7\u2212N\n,\nh\u2217\u03b3 I\n\u0012\n\n14\n\n\fU = PN0 \u00d7N0 \u2295 P\u2212N\u00d7\u2212N\nand\nX = 0 \u2295 P\u2212N\u00d7{0}\n\n\u0012\n\n\u0012\n\nI\nh\u2217\u03b3\n\nI\nh\u2217\u03b3\n\n\u0013\nh\u03b3\n\u2217\n0 \u2295 P{0}\u00d7\u2212N\n,\nI\n\n\u0013\nh\u03b3\n\u2217\n0 \u2295 P{0}\u00d7\u2212N\n.\nI\n\nView the operator\n\u0012\n\nM=\n\nI\nP(\u2212N0 \u00d7\u2212N0 )\\{(0,0)} h\u2217\u03b3\n\nafter permutation as the operator matrix\n\uf8eb\n\u2217 Y\n\uf8ed\u2217 W\n\u2217 \u2217\n\nacting on\n\n\u2217\nh\u03b3 P(\u2212N\n0 \u00d7\u2212N0 )\\{(0,0)}\nI\n\n\u0013\n\n\uf8f6\nX\nU\uf8f8\n\u2217\n\n[0 \u2295 l2 (\u2212N \u00d7 {0})] \u2295 [l2 (N0 \u00d7 N0 ) \u2295 l2 (\u2212N \u00d7 \u2212N)] \u2295 [0 \u2295 l2 ({0} \u00d7 \u2212N)].\nThen the equality Y W \u22121 U = X together with Proposition 2.2 gives that\n\u2217\n(0 \u2295 P\u2212N\u00d7{0} )M \u22121 (0 \u2295 P{0}\u00d7\u2212N\n) = 0.\n\nThis exactly yields the required zeros in Dj , j \u2264 \u22121.\nThe proof of the zeros in Aj , j \u2265 1, is similar. This proves the claim. \u0003\nFollowing the claim, we may now write Dj and Aj as\nDj =\nWrite\n\n\u0012\n\nej\nD\n0\n\n\u0013\n\u0012\n\u03b1j\nqj\n, j \u2264 \u22121; Aj =\nrj\n\u03b4j\n\uf8f6\n\u03b3j0\n\u0012\n***\n\u03b3j1 \uf8f7\n\uf8f8 , \u0393j =\n..\n.\n\n\uf8eb\n\n\uf8ece\n\u0393j = \uf8ed \u0393\nj\n\n\u0013\n0\nbj , j \u2265 1.\nA\n\n\u0013\n\u03b3j1 \u03b3j0\n.\nbj\n\u0393\n\nej = \u0393\nb j , j \u2265 0. Observe that due to (3.8), equation (3.2) implies\nNote that \u0393\n!\u0012 \u0013 \u0012 \u0013\nB\n0\nI e\nh\u03b3\ne = \u2206\ne ,\ne\nD\nh\u2217 I\n\u03b3\n\nwith\n\n\uf8eb . \uf8f6\n\uf8eb \uf8f6\n..\n..\n.\n\uf8ec\n\uf8ec \uf8f7\n\uf8f7\ne\n\uf8ec\n\uf8ec\n\uf8f7\n0\nD\ne\ne = \uf8ec \u22122 \uf8f7 , \u2206\ne i\u2212j )i\u2208N ,j\u2208\u2212N , D\ne =\uf8ec \uf8f7\nh\u03b3 = (\u0393\n\uf8f7,\n0\n0\n\uf8edD\n\uf8ed0\uf8f8\ne \u22121 \uf8f8\ne0\n\u2206\nI\n\n15\n\n(3.8)\n\n\fwhere\n\u0012\ne0\n\u2206\n\u2217\n\ne 0 is obtained from \u22060 by removing the last row and column; that is \u22060 =\n\u2206\n\u0013\n\u2217\n. Moreover, if we define\n\u2217\nej = \u2212\n\u0393\n\n\u221e\nX\nk=1\n\ne j+k D\ne \u2212k , j \u2264 \u22121,\n\u0393\n\ne j corresponds to \u0393j without the last column for j \u2264 \u22121 as well. In\nthen we have that \u0393\nother words,\n\u0010\n\u0011\ne j \u2217 , j \u2264 \u22121.\n\u0393j = \u0393\n\nbj may be constructed from (3.4) with\nLikewise, due to the form of Aj , we have that A\nbj . Moreover, if we define\n\u0393j replaced by \u0393\n\nthen we have that \u0393j =\nTheorem 3.1 that\n\nSince\n\nej = \u2212\n\u0393\n\n\u221e\nX\nk=1\n\n\u0012\n\nb\u2217 = \u2212\n\u0393\nj\n\u0013\n\n\u221e\nX\nk=1\n\nb\u2217 A\nb\n\u0393\nj+k j , j \u2264 \u22121,\n\n\u2217\nbj = \u0393\ne j , j \u2265 0, we obtain from\n, j \u2264 \u22121. But since \u0393\nb\n\u0393j\n\ne j+k D\ne \u2212k = \u2212\n\u0393\n\u0393j =\n\n\u221e\nX\nk=1\n\n\u0012\n\n\u2217\nbj\n\u0393\n\nb j+k D\ne \u2212k = \u2212\n\u0393\n\n\u0013\n\n\u221e\nX\nk=1\n\nb\u2217 \u0393\nb\nb\nA\nj j+k = \u0393j , j \u2264 \u22121.\n\n\u0010\n\u0011\ne j \u2217 , j \u2264 \u22121,\n= \u0393\n\nit now follows that \u0393j , j \u2264 \u22121, is Hankel.\nThe last step in the proof is to recognize that\n\nk(\u0393i\u2212j )i,j\u2208Z k < 1\nimplies that the Hankel (Hi\u2212j )i\u2208N0 ,j\u2208\u2212N0 is a strict contraction, where\nHi = (\u03b3p\u2212q,i )p,q\u2208Z , i \u2265 0.\nBut now it follows that Hi = (\u03b3p\u2212q,i )p,q\u2208Z , i \u2264 \u22121, exist so that (Hi\u2212j )\u221e\ni,j=\u2212\u221e is a\nstrict contraction. \u0003\n\nReferences\n[1] V. M. Adamjan, D. Z. Arov, and M. G. Kre\u0131\u0306n. Infinite Hankel block matrices\nand related problems of extension. Izv. Akad. Nauk Armjan. SSR Ser. Mat.,\n6(2-3):87\u2013112, 1971.\n\n16\n\n\f[2] Gr. Arsene, Zoia Ceau\u015fescu, and T. Constantinescu. Schur analysis of some completion problems. Linear Algebra Appl., 109:1\u201335, 1988.\n[3] A. Calderon and R. Pepinsky. On the phases of fourier coefficients for positive real\nperiodic functions. Computing Methods and the Phase Problem in X-Ray Crystal\nAnalysis (R. Pepinsky, ed.), pages 339\u2013346, 1950.\n[4] Mischa Cotlar and Cora Sadosky. Two distinguished subspaces of product BMO\nand Nehari-AAK theory for Hankel operators on the torus. Integral Equations\nOperator Theory, 26(3):273\u2013304, 1996.\n[5] Philippe Delsarte, Yves V. Genin, and Yves G. Kamp. Planar least squares inverse\npolynomials. I. Algebraic properties. IEEE Trans. Circuits and Systems, 26(1):59\u2013\n66, 1979.\n[6] Philippe Delsarte, Yves V. Genin, and Yves G. Kamp. Half-plane Toeplitz systems. IEEE Trans. Inform. Theory, 26(4):465\u2013474, 1980.\n[7] Philippe Delsarte, Yves V. Genin, and Yves G. Kamp. A simple proof of Rudin's\nmultivariable stability theorem, IEEE Trans. Acoust. Speech Signal Process,\n28(6):701\u2013705, (1980),\n[8] Philippe Delsarte, Yves V. Genin, and Yves G. Kamp. Half-plane minimization of matrix-valued quadratic functionals. SIAM J. Algebraic Discrete Methods,\n2(2):192\u2013211, 1981.\n[9] Bradley W. Dickinson. Two-dimensional markov spectrum estimates need not\nexist. IEEE Trans. Inform. Theory, 26:120\u2013121, 1980.\n[10] Harry Dym and Israel Gohberg. Extensions of matrix valued functions with rational polynomial inverses. Integral Equations Operator Theory, 2(4):503\u2013528, 1979.\n[11] Harry Dym and Israel Gohberg. Extensions of band matrices with band inverses.\nLinear Algebra Appl., 36:1\u201324, 1981.\n[12] Harry Dym and Israel Gohberg. Extensions of kernels of Fredholm operators. J.\nAnalyse Math., 42:51\u201397, 1982/83.\n[13] Sarah H. Ferguson and Michael T. Lacey. A characterization of product BMO by\ncommutators. Acta Math., 189(2):143\u2013160, 2002.\n[14] Sarah H. Ferguson and Cora Sadosky. Characterizations of bounded mean oscillation on the polydisk in terms of Hankel operators and Carleson measures. J.\nAnal. Math., 81:239\u2013267, 2000.\n[15] Ciprian Foias and Arthur E. Frazho. The commutant lifting approach to interpolation problems. Birkh\u00e4user Verlag, Basel, 1990.\n[16] Ciprian Foias and Arthur E. Frazho. The commutant lifting approach to interpolation problems, volume 44 of Operator Theory: Advances and Applications.\nBirkh\u00e4user Verlag, Basel, 1990.\n\n17\n\n\f[17] Y. Genin and Y. Kamp. Counterexample in the least-squres inverse stabilizatin\nof 2d recursive filters. Electron Lett., 11:330\u2013331, 1975.\n[18] Jeffrey S. Geronimo and Hugo J. Woerdeman. Positive extensions, Fej\u00e9r-Riesz\nfactorization and autoregressive filters in two variables. Ann. of Math. (2). to\nappear.\n[19] I. Gohberg and G. Heinig. Inversion of finite Toeplitz matrices consisting of\nelements of a noncommutative algebra. Rev. Roumaine Math. Pures Appl., 19:623\u2013\n663, 1974.\n[20] I. Gohberg, M. A. Kaashoek, and H. J. Woerdeman. The band method for positive\nand contractive extension problems. J. Operator Theory, 22:109\u2013155, 1989.\n[21] I. Gohberg, M. A. Kaashoek, and H. J. Woerdeman. The band method for positive\nand contractive extension problems: An alternative version and new applications.\nIntegral Equations and Operator Theory, 12:343\u2013382, 1989.\n[22] Israel Gohberg, Seymour Goldberg, and Marinus A. Kaashoek. Classes of linear\noperators. Vol. II, volume 63 of Operator Theory: Advances and Applications.\nBirkh\u00e4user Verlag, Basel, 1993.\n[23] Henry Helson. Lectures on invariant subspaces. Academic Press, New York, 1964.\n[24] Henry Helson and David Lowdenslager. Prediction theory and Fourier series in\nseveral variables. Acta Math., 99:165\u2013202, 1958.\n[25] Henry Helson and David Lowdenslager. Prediction theory and Fourier series in\nseveral variables. II. Acta Math., 106:175\u2013213, 1961.\n[26] Hanoch Lev-Ari, Sydney R. Parker, and Thomas Kailath. Multidimensional\nmaximum-entropy covariance extension. IEEE Trans. Inform. Theory, 35(3):497\u2013\n508, 1989.\n[27] J. S. Lim and N. A. Malik. A new algorithm for two-dimensional maximum entropy power spectrum estimation. IEEE Trans. Acoust., Speech, Signal Processing,\n29:401\u2013412, 1981.\n[28] Lavon B. Page. Applications of the Sz.-Nagy and Foia\u015f lifting theorem. Indiana\nUniv. Math. J., 20:135\u2013145, 1970/1971.\n[29] Vladimir V. Peller. Hankel operators and their applications. Springer Monographs\nin Mathematics. Springer-Verlag, New York, 2003.\n[30] R. Rochberg. Toeplitz operators on weighted H p spaces. Indiana Univ. Math. J.,\n26:291\u2013298, 1977.\n[31] Walter Rudin. The extension problem for positive-definite functions. Illinois J.\nMath., 7:532\u2013539, 1963.\n[32] H. J. Woerdeman. Matrix and operator extensions. Stichting Mathematisch Centrum Centrum voor Wiskunde en Informatica, Amsterdam, 1989.\n\n18\n\n\f"}