{"id": "http://arxiv.org/abs/1104.0504v3", "guidislink": true, "updated": "2011-05-14T13:59:42Z", "updated_parsed": [2011, 5, 14, 13, 59, 42, 5, 134, 0], "published": "2011-04-04T09:14:30Z", "published_parsed": [2011, 4, 4, 9, 14, 30, 0, 94, 0], "title": "Ludics with repetitions (Exponentials, Interactive types and\n  Completeness)", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1104.5621%2C1104.0504%2C1104.2793%2C1104.3163%2C1104.3927%2C1104.0214%2C1104.0564%2C1104.0056%2C1104.4919%2C1104.5139%2C1104.1509%2C1104.3905%2C1104.3501%2C1104.0218%2C1104.3261%2C1104.4419%2C1104.3832%2C1104.1642%2C1104.1799%2C1104.4248%2C1104.4885%2C1104.2909%2C1104.4572%2C1104.2126%2C1104.4264%2C1104.1315%2C1104.0690%2C1104.1538%2C1104.3466%2C1104.3495%2C1104.4398%2C1104.4705%2C1104.2241%2C1104.1763%2C1104.4430%2C1104.4517%2C1104.4529%2C1104.3894%2C1104.2776%2C1104.2716%2C1104.2361%2C1104.0621%2C1104.3480%2C1104.4639%2C1104.0433%2C1104.3133%2C1104.2537%2C1104.2455%2C1104.0335%2C1104.3773%2C1104.4191%2C1104.3310%2C1104.2836%2C1104.4759%2C1104.3516%2C1104.2402%2C1104.0716%2C1104.1155%2C1104.0829%2C1104.4227%2C1104.5196%2C1104.3154%2C1104.1222%2C1104.0678%2C1104.2007%2C1104.4939%2C1104.3053%2C1104.0023%2C1104.1365%2C1104.3851%2C1104.3867%2C1104.2494%2C1104.3539%2C1104.1713%2C1104.3312%2C1104.2229%2C1104.5243%2C1104.0620%2C1104.2737%2C1104.4436%2C1104.4409%2C1104.3953%2C1104.2027%2C1104.3410%2C1104.2486%2C1104.2023%2C1104.3394%2C1104.0448%2C1104.4563%2C1104.4898%2C1104.4583%2C1104.2022%2C1104.1759%2C1104.3301%2C1104.4211%2C1104.1307%2C1104.1360%2C1104.0797%2C1104.1246%2C1104.4658%2C1104.4045&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Ludics with repetitions (Exponentials, Interactive types and\n  Completeness)"}, "summary": "Ludics is peculiar in the panorama of game semantics: we first have the\ndefinition of interaction-composition and then we have semantical types, as a\nset of strategies which \"behave well\" and react in the same way to a set of\ntests. The semantical types which are interpretations of logical formulas enjoy\na fundamental property, called internal completeness, which characterizes\nludics and sets it apart also from realizability. Internal completeness entails\nstandard full completeness as a consequence. A growing body of work start to\nexplore the potential of this specific interactive approach. However, ludics\nhas some limitations, which are consequence of the fact that in the original\nformulation, strategies are abstractions of MALL proofs. On one side, no\nrepetitions are allowed. On the other side, the proofs tend to rely on the very\nspecific properties of the MALL proof-like strategies, making it difficult to\ntransfer the approach to semantical types into different settings. In this\npaper, we provide an extension of ludics which allows repetitions and show that\none can still have interactive types and internal completeness. From this, we\nobtain full completeness w.r.t. a polarized version of MELL. In our extension,\nwe use less properties than in the original formulation, which we believe is of\nindependent interest. We hope this may open the way to applications of ludics\napproach to larger domains and different settings.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1104.5621%2C1104.0504%2C1104.2793%2C1104.3163%2C1104.3927%2C1104.0214%2C1104.0564%2C1104.0056%2C1104.4919%2C1104.5139%2C1104.1509%2C1104.3905%2C1104.3501%2C1104.0218%2C1104.3261%2C1104.4419%2C1104.3832%2C1104.1642%2C1104.1799%2C1104.4248%2C1104.4885%2C1104.2909%2C1104.4572%2C1104.2126%2C1104.4264%2C1104.1315%2C1104.0690%2C1104.1538%2C1104.3466%2C1104.3495%2C1104.4398%2C1104.4705%2C1104.2241%2C1104.1763%2C1104.4430%2C1104.4517%2C1104.4529%2C1104.3894%2C1104.2776%2C1104.2716%2C1104.2361%2C1104.0621%2C1104.3480%2C1104.4639%2C1104.0433%2C1104.3133%2C1104.2537%2C1104.2455%2C1104.0335%2C1104.3773%2C1104.4191%2C1104.3310%2C1104.2836%2C1104.4759%2C1104.3516%2C1104.2402%2C1104.0716%2C1104.1155%2C1104.0829%2C1104.4227%2C1104.5196%2C1104.3154%2C1104.1222%2C1104.0678%2C1104.2007%2C1104.4939%2C1104.3053%2C1104.0023%2C1104.1365%2C1104.3851%2C1104.3867%2C1104.2494%2C1104.3539%2C1104.1713%2C1104.3312%2C1104.2229%2C1104.5243%2C1104.0620%2C1104.2737%2C1104.4436%2C1104.4409%2C1104.3953%2C1104.2027%2C1104.3410%2C1104.2486%2C1104.2023%2C1104.3394%2C1104.0448%2C1104.4563%2C1104.4898%2C1104.4583%2C1104.2022%2C1104.1759%2C1104.3301%2C1104.4211%2C1104.1307%2C1104.1360%2C1104.0797%2C1104.1246%2C1104.4658%2C1104.4045&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Ludics is peculiar in the panorama of game semantics: we first have the\ndefinition of interaction-composition and then we have semantical types, as a\nset of strategies which \"behave well\" and react in the same way to a set of\ntests. The semantical types which are interpretations of logical formulas enjoy\na fundamental property, called internal completeness, which characterizes\nludics and sets it apart also from realizability. Internal completeness entails\nstandard full completeness as a consequence. A growing body of work start to\nexplore the potential of this specific interactive approach. However, ludics\nhas some limitations, which are consequence of the fact that in the original\nformulation, strategies are abstractions of MALL proofs. On one side, no\nrepetitions are allowed. On the other side, the proofs tend to rely on the very\nspecific properties of the MALL proof-like strategies, making it difficult to\ntransfer the approach to semantical types into different settings. In this\npaper, we provide an extension of ludics which allows repetitions and show that\none can still have interactive types and internal completeness. From this, we\nobtain full completeness w.r.t. a polarized version of MELL. In our extension,\nwe use less properties than in the original formulation, which we believe is of\nindependent interest. We hope this may open the way to applications of ludics\napproach to larger domains and different settings."}, "authors": ["Claudia Faggian", "Michele Basaldella"], "author_detail": {"name": "Michele Basaldella"}, "author": "Michele Basaldella", "links": [{"title": "doi", "href": "http://dx.doi.org/10.2168/LMCS-7(2:13)2011", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1104.0504v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1104.0504v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "F.4.1, F.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1104.0504v3", "affiliation": "RIMS - Kyoto Univ.", "arxiv_url": "http://arxiv.org/abs/1104.0504v3", "arxiv_comment": null, "journal_reference": "Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,\n  2011) lmcs:1095", "doi": "10.2168/LMCS-7(2:13)2011", "fulltext": "Logical Methods in Computer Science\nVol. 7 (2:13) 2011, pp. 1\u201385\nwww.lmcs-online.org\n\nSubmitted\nPublished\n\nJan. 5, 2010\nMay. 17, 2011\n\nLUDICS WITH REPETITIONS\n(EXPONENTIALS, INTERACTIVE TYPES AND COMPLETENESS) \u2217\nMICHELE BASALDELLA a AND CLAUDIA FAGGIAN b\na\n\nResearch Institute for Mathematical Sciences, Kyoto University, Kitashirakawa Oiwakecho, Sakyoku, Kyoto 606-8502, Japan.\ne-mail address: mbasalde@kurims.kyoto-u.ac.jp\n\nb\n\n\u00c9quipe PPS, CNRS and Universit\u00e9 Paris 7, 2 place Jussieu, case 7017, 75251 Paris cedex 05,\nFrance.\ne-mail address: faggian@pps.jussieu.fr\nAbstract. Ludics is peculiar in the panorama of game semantics: we first have the definition of interaction-composition and then we have semantical types, as a set of strategies\nwhich \"behave well\" and react in the same way to a set of tests. The semantical types\nwhich are interpretations of logical formulas enjoy a fundamental property, called internal\ncompleteness, which characterizes ludics and sets it apart also from realizability. Internal\ncompleteness entails standard full completeness as a consequence.\nA growing body of work start to explore the potential of this specific interactive approach. However, ludics has some limitations, which are consequence of the fact that in\nthe original formulation, strategies are abstractions of MALL proofs. On one side, no\nrepetitions are allowed. On the other side, the proofs tend to rely on the very specific\nproperties of the MALL proof-like strategies, making it difficult to transfer the approach\nto semantical types into different settings.\nIn this paper, we provide an extension of ludics which allows repetitions and show that\none can still have interactive types and internal completeness. From this, we obtain full\ncompleteness w.r.t. a polarized version of MELL. In our extension, we use less properties\nthan in the original formulation, which we believe is of independent interest. We hope\nthis may open the way to applications of ludics approach to larger domains and different\nsettings.\n\n1. Introduction\nLudics is a research program started by Girard [22] with the aim of providing a foundation\nfor logic based on interaction. It can be seen as a form of game semantics where first we have\nthe definition of interaction (equivalently called composition, normalization), and then we\nhave semantical types, as sets of strategies which \"behave well\" with respect to composition.\n1998 ACM Subject Classification: F.4.1 Mathematical Logic (Proof theory), F.3 Logics and Meanings\nof Programs.\nKey words and phrases: linear logic, ludics, game semantics, internal completeness.\n\u2217\nThis paper is a completely revised and extended version of [5].\n\nl\n\nLOGICAL METHODS\nIN COMPUTER SCIENCE\n\nc\nDOI:10.2168/LMCS-7 (2:13) 2011\n\nCC\n\nM. Basaldella and C. Faggian\nCreative Commons\n\n\f2\n\nM. BASALDELLA AND C. FAGGIAN\n\nThis role of interaction in the definition of types is where lies the specificity of ludics in the\npanorama of game semantics.\nRecently, a growing body of work is starting to explore and to develop the potential of\nthis specific approach, and to put at work the more general notion of type offered by ludics:\nthe notion of type defined through interaction. We mention in particular work by Saurin\non interactive proof-search as a logic programming paradigm [38], and work by Terui on\ncomputability [39]. Terui gives an especially interesting use of the notion of orthogonality\n(\"to interact well\"): if the strategy D describes an automaton, {D}\u22a5 (the set of all strategies\nwhich \"interact well\" with it) is the language accepted by that automaton. In [6] Basaldella\nand Terui have studied the traditional logical duality between proofs and models in the\nsetting of computational ludics [39] enriched with exponentials (following our approach to\nexponentials [5], this paper). Both proofs and models live in an homogeneous setting, both\nare strategies, which are related by orthogonality. Finally, we observe that interactive types\nseem to be very natural also in process calculi; a bridge between process calculi and ludics\nhas already been established in Faggian and Piccolo [15], which shows a close correspondence\nbetween the strategies of ludics and the terms of the linear \u03c0-calculus [40] - from this one\ncan hope to transfer the whole approach of ludics to that setting.\nThere are also other lines of work in the literature which use orthogonality to define\nsemantical types. We mention work by Pitts on parametricity [37], work by Krivine on\nrealizability [28], work by Hyland and Schalk on categorical models of linear logic [27],\nwork by Melli\u00e8s and Vouillon on recursive types [34] and work by Paolini on parametric\n\u03bb-calculus [36].\nInteractive types. The computational objects of ludics - designs - can be seen as a linear\nform of Hyland-Ong (HO) innocent strategies (as shown in [14]) or as Curien's abstract\nB\u00f6hm trees [8, 11].\nHowever, in game semantics, we first define the types (arenas, games), and then strategies on a given type. The type information guarantees that strategies compose well. In\nludics, strategies are untyped, in the sense that all strategies are given on a universal arena\n(the arena of all possible moves); strategies can always interact with each other, and the\ninteraction may terminate well (the two strategies \"accept each other\", and are said to be\northogonal) or not (they deadlock). An interactive type is a set of strategies which \"compose well\", and reacts in the same way to a set of tests (see Section 4). More concretely,\na semantical type G is any set of strategies which reacts well to the same set of tests E,\nwhich are themselves strategies (counter-strategies), that is G = E\u22a5 .\nInternal completeness. With ludics, Girard also introduces a new notion of completeness,\nwhich is called internal completeness (see Section 5). This is a key - really defining -\nelement of ludics. We have already said that a semantical type is a set of strategies closed by\nbiorthogonal (G = G\u22a5\u22a5 ). Internal completeness (in [22]) is the property which essentially\nsays that the constructions on semantical types do not require any closure operation, i.e.,\nthey are already complete.\nFor instance, in [22] the interpretation of A \u2295 B (where \u2295 denotes the additive disjunction of linear logic) is defined as (A \u222a B)\u22a5\u22a5 . This set of terms could be in general strictly\ngreater than A \u222a B. But under certain conditions, it is possible to prove that A \u222a B is equal\nto (A \u222a B)\u22a5\u22a5 , and since the closure by biorthogonal does not introduce new terms, A \u222a B\n\n\fLUDICS WITH REPETITIONS\n\n3\n\nalready gives a simple and complete description of what inhabits the semantical type, i.e.,\nwe have internal completeness.\nWhile it is standard in realizability that a semantical type is a set S of terms closed\nby biorthogonal (S = S\u22a5\u22a5 ), when interpreting types one has to perform some kind of\nclosure, and this operation might introduce new terms. Such new terms do not pose any\nessential problem when we are only interested in proving the soundness of a calculus w.r.t.\na realizability model, that is, roughly, the property which states that if \u03c0 is a proof of\na formula A, then we can construct from \u03c0 a strategy D which realizes the semantical\ninterpretation A of A, i.e., D \u2208 A. However, introducing new terms does make a difference\nwhen we are also interested in the other direction, namely (full) completeness: given a\n\"good\" strategy D \u2208 A, we want to effectively associate to D a proof \u03c0 of A. Now the\nnew terms which might have been introduced by the closure operation have to be taken\ninto account. What internal completeness guarantees, is that we actually have a complete\ndescription of all the terms of a semantical types which correspond to logical proofs (or at\nleast a subset which includes the \"good\" strategies).\nIn Girard's paper on ludics, the semantical types which are interpretations of propositional formulas enjoy internal completeness. This is really the key property (and the one\nused in [38, 39]). Full completeness (for multiplicative-additive-linear logic MALL, in the\ncase of [22]) directly follows from it.\n1.1. Contributions of the paper. The purpose of this paper is two-fold.\nOn the one hand, we show that it is possible to overcome the main limitation of ludics,\nnamely the constraint of linearity, hence the lack of exponentials: we show that internal\ncompleteness (and from that full completeness) can be obtained also when having repetitions, if one extends in a rather natural way the setting of ludics.\nOn the other hand, we provide proofs which make use of less properties than the original\nones given by Girard. Not only we do believe this improves the understanding of the results,\nbut - more fundamentally - we hope this opens the way to the application of the approach\nof ludics to a larger domain.\nWe now give more details on the content of the paper.\n1.1.1. Ludics architecture. A difficulty in [22] is that there is a huge amount of structure\n(see the \"analytical theorems\"), without a clear distinction between what are properties\nobserved in the specific objects, and what is necessary to the construction. Strategies are\nan abstraction of MALL proofs, and enjoy many good properties. In [22], all proofs of the\nhigh level structure of ludics make essential use of these properties. Since some of those\nproperties are very specific to the particular nature of the objects, this makes it difficult in\nprinciple to extend the - very interesting - approach of ludics to a different setting, or\nbuild the interactive types on different computational objects.\nLudics, as introduced in [22], is composed of several layers.\n\u2022 At the low level, there is the definition of the untyped computational structures (strategies,\nthere called designs) and their dynamics (interaction). Interaction allows the definition\nof orthogonality.\n\u2212 The computational objects satisfy certain remarkable properties, called analytical theorems, in particular separation property, the ludics analogue of B\u00f6hm theorem for\n\n\f4\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u03bb-calculus: two strategies A, B are syntactically equal if and only if they are observationally equal (i.e., for any counter-strategy C, the strategies A, B react in the same\nway to C).\n\u2022 At the high level, there is the definition of interactive types, which satisfy internal completeness.\nBy relying on less structure, we show that the high level architecture of ludics is somehow independent from the low level entities (strategies), and in fact could be built on other\n- more general - computational objects.\nIn particular, separation is a strong property. It is a great property, but it is not a\ncommon one to have. However, the fact that computational objects do not enjoy separation\ndoes not mean that it is not possible to build the \"high level architecture\" of ludics. In\nfact, we show (Section 5) that the proofs of internal and full completeness rely on much less\nstructure, namely operational properties of the interaction.\nWe believe that discriminating between internal completeness and the properties which\nare specific to the objects is important both to improve understanding of the results, and\nto make it possible to build the same construction on different entities.\nIn particular, strategies with repetitions have weaker properties with respect to the original - linear - ones. We show that it is still possible to have interactive types, internal\ncompleteness, and from this full completeness for a polarized version of the constant-only\nfragment of MELL (multiplicative-exponential-linear logic) that we call MELLS (Section 2).\nThe reason we restrict our attention to the constant-only fragment is that the treatment\nof propositional variables is rather complicated in ludics (see [22] and also [13]) and not\nstrictly related to our purposes: the analysis of ludics with repetitions of actions. On the\nother hand, the extension of our framework to additives is straightforward.\n1.1.2. Exponentials in ludics. The treatment of exponentials has been the main open problem in ludics since [22]. Maurel [32] has been the first one to propose a solution (a summary\nof this solution can also be found in [11, 23]). The focus of Maurel's work is to recover a\nform of separation when having repetitions; for this purpose, he develops a sophisticated\nsetting, which is based on the use of probabilistic strategies: two probabilistic strategies\n\"compose well\" with a certain probability. This approach is however limited by its technical complexity; this is the main obstacle which stops Maurel from going further, and\nstudying interpretation and full completeness issues.\nIn this work, we do not analyze the issue of separation, while we focus exactly into\ninteractive types and internal completeness, and develop a fully complete interpretation\nfrom it.\nMaurel also explores a simpler solution in order to introduce exponentials, but he does\nnot pursue it further because of the failure of the separation property. Our work starts from\nan analysis of this simpler solution, and builds on it.\n1.1.3. Our approach. In the literature, there are two standard branches of game semantics\nwhich have been extensively used to build denotational models of various fragments of linear\nlogic. On the one hand, we have Abramsky-Jagadeesan-Malacaria style game semantics\n(AJM) [2] which is essentially inspired by Girard's geometry of interaction [18]. On the\nother hand, we have Hyland-Ong style game semantics (HO) [26], introducing innocent\n\n\fLUDICS WITH REPETITIONS\n\n5\n\nstrategies. The main difference between those two game models is how the semantical\nstructures corresponding to exponential modalities are built. In AJM, given a game A,\n!A is treated as an infinite tensor product of A, where each copy of A receives a different\nlabeling index. Two strategies in !A which only differ by a different labeling of moves\nare identified. By contrast, in HO the notion of justification pointer substitutes that of\nindex. The games A and !A share the same arena. Informally, a strategy in !A is a kind\nof \"juxtaposition\" of strategies of A such that by following the pointer structure, we can\nunambiguously decompose it as a set of strategies of A.\nGirard's designs [22] are a linear form of HO innocent strategies [14]. Hence, the most\nnatural solution to extend ludics to the exponentials is to consider as strategies, standard\nHO innocent strategies (on an universal arena). But in order to do so, there is a new kind\nof difficulty, which we deal with in this paper: we need to have enough tests.\nMore precisely, as we illustrate in Section 6, we need non-uniform counter-strategies.\nWe implement and concretely realize this idea of non-uniform (non-deterministic) tests by\nintroducing a non-deterministic sum of strategies, which builds on and refines work by\nFaggian and Piccolo [16]. More precise motivations and a sketch of the solution are detailed\nin Section 6.4.\n1.2. Plan of the paper. In Section 2, we introduce the polarized fragment of linear logic\nMELLS for which we will show a fully complete model in Section 11.\nIn Section 3, we recall the basic notions of HO innocent game semantics, which we then\nuse in Section 4 to present Girard's ludics.\nIn Section 5 we review the results of internal completeness for linear strategies and\noutline a direct proof of full completeness.\nIn Section 6, we provide the motivations and an informal description of non-uniform\nstrategies, and in Section 7 we give the formal constructions.\nIn Section 8 we describe in detail the composition of non-uniform strategies and in\nSection 9 we revise the notion of orthogonality in the non-uniform setting.\nIn Section 10 we introduce semantical types for MELLS, and we extend internal completeness to non-linear strategies. Full completeness is developed in Section 11.\nIn Section 12 we discuss related work and conclude the paper.\n2. Calculus\nWe start by introducing a calculus that we call MELLS, which will be our \"underlying\"\nsyntax; in Section 11, we prove that our model is fully complete for this calculus.\nMELLS is a polarized variant of the constant-only propositional fragment of multiplicative-exponential linear logic MELL [17] based on synthetic connectives [21]. Polarization,\nwhich we discuss in Section 2.2, is fundamental to Girard's computational analysis of classical logic [19] in which the system LC was introduced, and more recently to the design of\nLaurent's polarized linear logic LLP [29, 30].\n\n\f6\n\nM. BASALDELLA AND C. FAGGIAN\n\n2.1. MELL. Formulas of the constant-only, propositional, multiplicative-exponential linear\nlogic MELL [17] are finitely generated by the following grammar:\nT\n\nF ::= I |\nThe involutive linear negation\n:=\n\nT\n\nI\n\n\u22a5\n\n;\n\n\u22a5\n\n| F \u2297 F | F ` F | !F | ?F.\nis defined as follows:\n\nF \u2297G\n\n\u22a5\n\n:= F \u22a5 ` G\u22a5 ;\n\n!F\n\n\u22a5\n\n:= ?(F \u22a5 ).\n\nA sequent, written \u22a2 \u0393, consists of a (possibly empty) multi-set of formulas \u0393 =\nF1 , . . . , Fn . Given two multi-sets \u0393 and \u2206 the expression \u0393, \u2206 denotes their multi-set union.\nGiven a multi-set \u0393 = F1 , . . . , Fn we write ?\u0393 for ?F1 , . . . , ?Fn .\nSequent calculus rules are given in Table 1.\n\nExponential rules\n\n\u22a2 ?\u0393, F\n\u22a2 ?\u0393, !F\n\nCut-rule\n\n\u22a2 \u0393, F\n\n!\n\n\u2297\n\n\u22a2I\n\n\u22a2 \u0393, F\n\u22a2 \u0393, ?F\n\n\u22a2 \u2206, F \u22a5\n\u22a2 \u0393, \u2206\n\n?\n\nI\n\n\u22a2 \u0393, F, G\n\u22a2 \u0393, F ` G\n\u22a2\u0393\n\u22a2 \u0393, ?F\n\nW\n\n`\n\n\u22a2\u0393\n\u22a2 \u0393,\n\nT\n\n\u22a2 \u0393, F\n\u22a2 \u2206, G\n\u22a2 \u0393, \u2206, F \u2297 G\n\nT\n\nMultiplicative rules\n\n\u22a2 \u0393, ?F, ?F\n\u22a2 \u0393, ?F\n\nC\n\nCut\n\nTable 1: MELL\nA key feature of linear logic is the distinction between:\n\u2022 linear formulas: I , , F \u2297 F, F ` F ;\n\u2022 exponential formulas: ?F, !F .\nLinear formulas can only be used once, while the modalities !, ? allow formulas and sequent\ncalculus derivations to be erased or duplicated in the sense we now make precise.\nThe possibility of discarding formulas is expressed in the sequent calculus by the weakening rule (or erase, in the bottom-up reading of a derivation) on ?F formulas:\nT\n\n\u22a2\u0393 W\n\u22a2 \u0393, ?F\nThe possibility of repeating formulas is taken into account by the contraction rule (or\nduplication, in the bottom-up reading) on ?F formulas:\n\u22a2 \u0393, ?F, ?F\nC\n\u22a2 \u0393, ?F\nIn a dual sense, the modality ! allows derivations to be erased or duplicated during cutelimination procedure. Namely, (recall that ?F \u22a5 is defined as !(F \u22a5 )) we have:\n..\n..\n.\u03c0\n..\n.\u03c0\n.\n\u03c1\n\u22a2\n\u0393\n\u22a2\u0393 W\nreduces to\n:\nWeakening: a cut\n\u22a5\n.\n\u22a2 \u0393, ?F\n\u22a2 ?\u2206, !(F )\n.. weakenings ...\nCut\n\u22a2 \u0393, ?\u2206\n\u22a2 \u0393, ?\u2206\n\u22a5\nthe derivation of \u22a2 ?\u2206, !(F ) is erased.\nMore important (for the purposes of this paper) is the case of contraction rule:\n\n\fLUDICS WITH REPETITIONS\n\nContraction: a cut\n\n..\n.\u03c0\n\u22a2 \u0393, ?F, ?F\n\u22a2 \u0393, ?F\n\n..\n.\u03c1\n\nreduces to\n\nC\n\n\u22a2 ?\u2206, !(F \u22a5 )\n\u22a2 \u0393, ?\u2206\n..\n.\u03c1\n\n7\n\nCut\n\n..\n.\u03c0\n..\n.\u03c1\n\u22a2 ?\u2206, !(F \u22a5 )\n\u22a2 \u0393, ?F, ?F\nCut\n\u22a2 \u0393, ?\u2206, ?F\n\u22a2 ?\u2206, !(F \u22a5 )\nCut :\n\u22a2 \u0393, ?\u2206, ?\u2206\n.\n..\n. contractions ..\n\u22a2 \u0393, ?\u2206\n\u22a5\nthe derivation \u03c1 of \u22a2 ?\u2206, !(F ) can be used several times, once for each duplication of ?F .\n2.2. Polarities, focalization and synthetic connectives. The connectives and constants of linear logic are split into two families according to their polarity (positive or\nnegative). Let us discuss first the multiplicative-additive fragment MALL, where the distinction is clearly highlighted also typographically.\n\nNegative multiplicative :\n\nI , \u2297,\nT\n\nPositive multiplicative :\n\n, `,\n\nPositive additive :\n\n0 , \u2295,\n\nNegative additive : T , &.\n\nThe significance of polarities in linear logic was made explicit by Andreoli's seminal work on\nfocalization [3]. The distinction into positive and negative corresponds in fact to properties\nof the connectives in proof construction [21, 9]. If a sequent is provable in linear logic, then\nit is provable with a proof which satisfies the proof-search strategy which we recall next (we\nrecall that the polarity of a formula is the polarity of the outermost connective).\nIn the bottom-up construction of a proof:\n(1) If there is a negative formula, keep on decomposing it until we get to atoms or positive\nsubformulas.\n(2) If there are not negative formulas, choose a positive formula, and keep on decomposing\nit until we get to atoms or negative subformulas.\nFor the exponential modalities ?, !, the situation is however a bit more complex (see e.g., [3]\nand [29]). This has lead Girard to analyze the exponentials via the following decomposition [20, 30]:\n!F =  \u0301\u266fF,\n?F = \u02c6\u266dF,\nwhere \u266f is the negative modality, \u266d is the positive modality, and  \u0301, \u02c6 are operators which\nchange the polarity. The connectives \u266f and \u266d are the \"true\" modalities, responsible of\nduplicative features. Hence, after the previous decomposition, the contraction rule would\nbecome:\n\u22a2 \u0393, \u266dP, \u266dP\nC\n\u22a2 \u0393, \u266dP\nIn this paper, we decided to use symbols which are more familiar, and we simply write !N\n(instead of \u266f) for the negative modality, and ?P (instead of \u266d) for the positive modality.\n\n\f8\n\nM. BASALDELLA AND C. FAGGIAN\n\nPolarities allow us to have synthetic connectives [21, 23] i.e., maximal clusters of connectives of the same polarity. The key ingredient that allows for the definition of synthetic\nconnectives is precisely the focalization property. In fact, from the point of view of logic,\nfocalization (see the proof-search strategy above) means that each cluster of formulas with\nthe same polarity can be introduced by a single logical rule (with several premises). By\nusing synthetic connectives, formulas are in a canonical form, where immediate subformulas\nhave opposite polarity. This means that in a (cut-free) proof, there is a positive/negative\nalternation of rules, which matches the standard Player (positive)/Opponent (negative)\nalternation of moves in a strategy (see Section 3).\n2.3. MELLS. We now introduce in detail our calculus.\nFormulas of MELLS split into positive P and negative N formulas, and they are\ninductively generated by the following grammar:\nPositive formulas :\nNegative formulas :\n\nP\nN\n\n::= ?P (N1 \u2297 * * * \u2297 Nn ) (n \u2265 0)\n::= !N (P1 ` * * * ` Pn ) (n \u2265 0)\n\nT\n\nWhen n = 0, we write ?P I and !N for the positive and negative formula respectively. They\nare the only ground formulas of our calculus.\nWe will use F as a variable for formulas and indicate the polarity also by writing F +\nor F \u2212 . We use P, Q, R, . . . (resp. N, M, L, . . .) for positive (resp. negative) formulas. To\nstress the immediate subformulas of some formula F , we often write F + (N1 , . . . , Nn ) and\nF \u2212 (P1 , . . . , Pn ).\nThe involutive linear negation \u22a5 is defined in the natural way:\n?P (N1 \u2297 * * * \u2297 Nn )\n\n\u22a5\n\n:= !N (N1\u22a5 ` * * * ` Nn\u22a5 ).\n\nT\n\nIn particular, ?P I \u22a5 = !N .\nA sequent of MELLS is a (possibly empty) multi-set of formulas \u0393, written \u22a2 \u0393, such\nthat \u0393 contains at most one (occurrence of) negative formula. In the sequel, \u03a0 always\nstands for a (possibly empty) multi-set consisting of positive formulas only.\nRules of MELLS are given in Table 2.\n\u22a2 \u03a0, P, N1\n\nPositive rules :\n\n...\n\u22a2 \u03a0, P\n\n\u22a2 \u03a0, P, Nn\n\nP = ?P (N1 \u2297 * * * \u2297 Nn ) and n \u2265 0\n\u22a2 \u03a0, P1 , . . . , Pn\n\u22a2 \u03a0, N\n\nNegative rules :\n\nNegn\n\nN = !N (P1 ` * * * ` Pn ) and n \u2265 0\nTable 2: MELLS\n\nPos0\n\n\u22a2\u03a0\n\u22a2 \u03a0, !N\n\nT\n\n\u22a2 \u03a0, ?P I\n\nT\n\nIn particular, when n = 0 (and hence P = ?P I and N = !N\n\nNeg0\n\n) we have:\n\nPosn\n\n\fLUDICS WITH REPETITIONS\n\n9\n\nIn the sequel we use variables \u03c0, \u03c1, \u03c8, \u03b8 . . . for derivations of sequents in MELLS.\nStructural rules (weakening and contraction) are on positive formulas only, and given\nimplicitly in the positive rules.\n2.4. Expressivity of MELLS. In Appendix A we discuss the expressivity of MELLS by\nrelating it to more standard systems. In Appendix A.2 we give a correspondence between\nMELLS and a \"focalized and synthesized\" version of the \u00ac, \u2227 fragment of the sequent\ncalculus for propositional intuitionistic logic LJ. In Appendix A.3 we relate MELLS to a\nmore standard polarized version of MELL called MELLpol [29].\n2.5. Cut-rule. The cut-rule for MELLS is the following one:\n\u22a2 \u039e, \u03a0, P\n\u22a2 \u2206, P \u22a5\nCut\n\u22a2 \u039e, \u03a0, \u2206\nwhere the multi-set \u039e is either empty or it consists of exactly one (occurrence of) negative\nformula and \u2206 is a multi-set of positive formulas.\nThis cut is admissible in MELLS (Theorem A.3), i.e., it does not improve the derivability of sequents w.r.t. the cut-free formulation of MELLS. A proof of this fact is given\nin Appendix A.1.\n3. HO innocent game semantics\nAn innocent strategy [26] can be described either in terms of all possible interactions for\nthe player - strategy as set of plays - or in a more compact way, which provides only the\nminimal information for Player to move - strategy as set of views (see e.g., [35, 24, 10]).\nIt is standard that the two presentations are equivalent: from a play one can extract the\nviews, and from the views one can calculate the play.\nIn this paper we use the \"strategy as set of views\" description. Our presentation of\ninnocent strategies adapts to our needs the presentations by Harmer [25] and Laurent [30].\nBefore introducing the formal notions, let us use an image. A strategy tells the player\nhow to respond to a counter-player move. The dialogue between two players - let us call\nthem P (Player) and O (Opponent) - will produce an interaction (a play). The \"universe\nof moves\" which can be played is set by the arena. Each move belongs to only one of the\nplayers, hence there are P -moves and O -moves. For P, the moves which P plays are positive\n(active, output), while the moves played by O are negative (passive, input), to which P has\nto respond.\nPolarities. Let P ol := {+, \u2212} be the set of polarities: positive (for Player) and negative\n(for Opponent). We use the symbol \u01eb as a variable to range over polarities.\n\n\f10\n\nM. BASALDELLA AND C. FAGGIAN\n\nArenas. An arena is given by a directed acyclic graph, d.a.g. for short, which describes a\ndependency relation between moves and a polarity function, which assigns a polarity to the\nmoves.\nDefinition 3.1 (Arena). An arena A = (MA , \u22a2A , \u03bbA ) is given by:\n\u2022 a directed acyclic graph (MA , \u22a2A ) where:\n\u2212 MA (nodes of the d.a.g.) is the set of moves;\n\u2212 \u22a2A (edges of the d.a.g.) is a well founded, binary enabling relation on A. If there\nis an edge from m to n, we write m \u22a2A n. We call initial each move m such that no\nother move enables it, and we write this as \u22a2A n.\n\u2022 a function \u03bbA : MA \u2192 P ol which labels each element with a polarity \u01eb.\nEnabling relation and polarity have to satisfy the following property of alternation:\nif n \u22a2A m, they have opposite polarity.\nA non-empty arena whose initial moves have all the same polarity \u01eb, is said to be polarized [30]. In such a case, if \u01eb is positive (resp. negative), we say that the arena is positive\n(resp. negative).\nWith a slight abuse of notation, we will write m \u2208 A for m \u2208 MA .\nStrategies. A pointing string over a set X is a string s \u2208 X \u2217 with pointers between the\noccurrences of s = s1 . . . . sn such that, if si points to sj then j < i, i.e., pointers always point\nback to earlier occurrences, and we have at most one pointer from any given occurrence of\nsi .\nDefinition 3.2 (Justified sequence). Let A be an arena. A justified sequence s on A is\na pointing string s = s1 . . . . sn \u2208 A\u2217 which satisfies the following properties.\n\u2022 Justification. For each non-initial move si of s, there is a unique pointer to an earlier\noccurrence of move sj , called the justifier of si , such that sj \u22a2A si .\nThe polarity of a move in a justified sequence is given by the arena. We sometimes put in\nevidence the polarity of a move x by writing x+ or x\u2212 .\nDefinition 3.3 (View). A view on A is a justified sequence on A which satisfies:\n\u2022 Alternation. No two following moves have the same polarity.\n\u2022 View. If s = s1 . . . . sn , for each negative (Opponent) move si such that i > 1, si is justified\nby its immediate predecessor si\u22121 .\nDefinition 3.4 (Strategy). A strategy D on A, denoted by D : A is a prefix-closed set of\nnon-empty views, such that:\n(1) Coherence. If s.m, s.n \u2208 D and m 6= n then m, n are negative.\n(2) Positivity. If s.m is maximal in D (i.e., no other view extends it), then m is positive.\nIn case that the arena is polarized -which is the case for all arenas we deal with in\nthis paper- we call positive (resp. negative) a strategy on a positive (resp. negative) arena.\nRemark 3.5. The choice of defining a strategy as a set of non-empty views is not standard,\nbut is coherent with the setting of ludics. Following [22], a strategy can be an empty set\n(of views), whereas it never contains the empty view.\n\n\fLUDICS WITH REPETITIONS\n\n11\n\nAs a consequence, condition (1) (Coherence) in Definition 3.4 implies that in a positive\nstrategy, all views have the same first move. On the other hand, a negative strategy may\nalso be a forest, rather than a tree (see Section 3.3).\n3.1. Constructions on arenas. We give some constructions on arenas, which we will need\nin Section 4.\nLet A1 , A2 be positive arenas such that the sets of moves are disjoint (i.e., MA1 \u2229MA2 =\n\u2205).\nThe arena A1 k A2 is defined as follows:\n\u2022 MA1 kA2 := MA1 \u222a MA2 ;\n\u2022 \u03bbA1 kA2 (m) := \u03bbA1 (m) if m \u2208 MA1 , \u03bbA1 kA2 (m) := \u03bbA2 (m) if m \u2208 MA2 ;\n\u2022 \u22a2A1 kA2 := \u22a2A1 \u222a \u22a2A2 .\nObserve that the structure of A1 k A2 is inherited from its constituent arenas; we place\nthe arenas side-by-side. The construction immediately generalizes to the n-ary case: if\nA1 . . . , An (n \u2265 1) are positive arenas such that for any 1 \u2264 i, j \u2264 n the sets of moves of Ai\nand Aj are pairwise disjoint, we obtain A1 k * * * k An . It is immediate that A1 k * * * k An is\na positive arena.\nLet C be a negative and A be a positive arena, with disjoint sets of moves.\nThe arena C \u25ed A is defined as follows.\n\u2022 MC\u25edA := MC \u222a MA ;\n\u2022 \u03bbC\u25edA (m) := \u03bbC (m) if m \u2208 MC , \u03bbC\u25edA (m) := \u03bbA (m) if m \u2208 MA ;\n\u2022 m \u22a2C\u25edA n holds if\nm \u22a2C n , or\nm \u22a2A n , or\nm is initial in C and n is initial in A.\nIn words, the arenas C is lifted on top of the roots of A, by adding each root of A as child\nto each root of C.\n3.2. Composition of strategies. Composition of strategies as sets of views has been\nstudied in particular by Curien and Herbelin. They have introduced the View-AbstractMachine (VAM) [8, 11] by elaborating Coquand's Debates machine [7]. We will give more\ndetails in section 8.\n3.3. Conventions and notation. It is now convenient to fix some conventions and notation we will employ in all the rest of this paper.\nWe will often deal with sets of n \u2265 0 elements, which we write {Li : 1 \u2264 i \u2264 n} or\n{L1 , . . . , Ln }. The case n = 0 always corresponds to the empty set.\nGiven n \u2265 0, In always stands for the set given as follows:\nIn :=\n\n\u001a\n\n{1, . . . , n}, if n > 0;\n\u2205,\nif n = 0.\n\n\f12\n\nM. BASALDELLA AND C. FAGGIAN\n\nGiven an index set S, we will often use (as in [22]) the notation (Ls ), s \u2208 S, to indicate a\nfamily of elements, indexed by S. When S is clear from the context, we just write (Ls ).\nLet X be a set of views. We call root each occurrence of move a such that a.s \u2208 X .\nEmphasizing the arborescent structure of a strategy, it is convenient to write a strategy\nwith a single root a as D = a.X , where X is the set of pointing strings {s : a.s \u2208 X }. Notice\nthat X does not need to be a strategy. In case X is empty we just write D = a.\nWe will come back on this in Section 4.1.2 and in Section 10.1, Lemma 10.1.\nTo better grasp the intuitions, we will draw strategies as trees whose nodes are labeled\nby moves. Nodes which are labeled by positive moves are circled.\nExample 3.6. Let D be the strategy given by the closure under non-empty prefix of the set\nof views {a+ .b\u2212 .d+ , a+ .c\u2212 .e+ } (less formally, we could also write D = a+ .{b\u2212 .d+ , c\u2212 .e+ }).\nWe represent D by the following tree:\n\nD\n\nd+\n\ne+\n\nb\u2212\n\nc\u2212\na+\n\n4. Ludics, the linear case\nIn this and next section we give a compact but complete presentation of ludics [22], introducing all definitions and technical results which are relevant to our approach, including\ninternal completeness and full completeness. Our choice here is to give a presentation which\nfits into the language of game semantics.\nLet us first stress again the peculiarity of ludics in the panorama of game semantics. In\ngame semantics, one defines constructions on arenas which correspond to the interpretation\nof types. A strategy is always \"typed\", in the sense that it is a strategy on a specific arena:\nfirst we have the \"semantical type\" (the arena), and then the strategy on that arena. When\nstrategies are opportunely typed, they interact (compose) well.\nIn the approach of ludics, there is only one arena (up to renaming): the universal arena\nof all possible moves. Strategies are \"untyped\", in the sense that all strategies are defined\non the universal arena. Strategies then interact with each other, and the interaction can\nterminate well (the two strategies \"accept\" each other) or not (deadlock).\nTwo opposite strategies D, E whose interaction terminates well, are said to be orthogonal, written D\u22a5E. Orthogonality allows us to define interactive types. A semantical type\nG is any set of strategies which react well to the same set of tests E, which are themselves\nstrategies (counter-strategies), that is G = E\u22a5 .\n\n\fLUDICS WITH REPETITIONS\n\n13\n\nDaimon. One of the goals in the program of ludics is to overcome the distinction between\nsyntax (the formal system) on one side and semantics (its interpretation) on the other side.\nRather then having two separate worlds, proofs are interpreted via proofs. To determine\nand test properties, a proof of A should be tested with proofs of A\u22a5 . Ludics provides a\nsetting in which proofs of A interact with proofs of A\u22a5 ; to this aim, it generalizes the\nnotion of proof.\nA proof should be thought in the sense of \"proof-search\" or \"proof-construction\": we\nstart from the conclusion, and guess a last rule, then the rule above. What if we cannot\napply any rule? A new rule is introduced, called daimon:\n\u2020\n\u22a2\u03a0\nSuch a rule allows us to assume any conclusion, or said in other words, it allows to close\nany open branch in the proof-search tree of a sequent.\nIn the semantics, the daimon is a special action which acts as a termination signal.\n4.1. Strategies on a universal arena. We now introduce the notion of strategy as defined in ludics. The role of the arena becomes somehow secondary, while the central notion,\nis that of name. Strategies communicate on names. We can think of names as process\nalgebras channels, which can be used to send outputs (if positive) or to receive inputs (if\nnegative). Each strategy D will have an interface, which provides the names on which D\ncan communicate with the rest of the world, and the use (input/output) of each name.\nA name (called locus in [22]) is a string of natural numbers. We use the variables\n\u03be, \u03c3, \u03b1, . . . to range over names. Two names are disjoint if neither is a prefix of the other\none.\nAn action x is either the symbol \u2020 (called daimon) or a pair (\u03be, I), where \u03be is a\nname, and I is a finite subset of N. In this paper, we will always assume I of the form\nIn = {1, . . . , n}, for some n \u2265 0 (see Section 3.3)1. Given an action (\u03be, I) on the name \u03be,\nthe set I is actually a shortcut for the set of the names {\u03bei : i \u2208 I} which are generated\nfrom \u03be by this action. We call proper an action of the form (\u03be, I) (to contrast with a \u2020\naction, which has a different function). The role of proper actions and of the \u2020 actions will\nbe very different when defining interaction between strategies.\nThe prefix relation (written \u03be \u2291 \u03c3) induces a natural relation of dependency on names,\nand hence on the proper actions, which generates an arena.\nDefinition 4.1 (Universal arena (on a name)). Given a name \u03be and a polarity \u01eb \u2208 {+, \u2212},\nthe universal arena A(\u03be, \u01eb) is the tuple (M, \u22a2, \u03bb) defined as follows:\n(1) The set of moves M is the set of all actions of the form (\u03be \u2032 , I), where \u03be \u2291 \u03be \u2032 and\nI is a finite subset of N.\n(2) The polarity of the initial actions is \u03bb((\u03be, I)) = \u01eb for each I; the polarity of any\nother action is the one induced by alternation.\nThe enabling relation x \u22a2 y is defined as follows:\n1 We can think of the set I only just as an \"arity provider.\" We use the notation I first of all for\nn\nn\n\ncompatibility (and comparability) with [22], in which the general case is needed to deal with the additives.\nSecondly, this choice leaves open the possibility to extend our work with the additive structure of ludics,\nwithout essential modifications.\n\n\f14\n\nM. BASALDELLA AND C. FAGGIAN\n\nx \u22a2 y if x = (\u03be \u2032 , I) and y = (\u03be \u2032 i, J), with i \u2208 I.\nThe choice of a name \"delocalizes\" the universal arena on a specific name. Of course, all\nuniversal arenas are isomorphic up to the choice of some name \u03be.\nDefinition 4.2 (Interface). An interface \u0393 (called base in [22]) is a (possibly empty) finite\nset of pairwise disjoint names, together with a polarity for each name, such that at most\none name is negative. If a name \u03be has polarity \u01eb, we write \u03be \u01eb \u2208 \u0393.\nWith an abuse of notation, in the sequel we often write \u0393 = \u03be1\u01eb1 , . . . , \u03ben\u01ebn instead of\n\u0393 = {\u03be1\u01eb1 , . . . , \u03ben\u01ebn }. When no confusion arises, we also omit the polarities and simply write\n\u0393 = \u03be1 , . . . , \u03ben .\nAn interface \u0393 is negative if it contains a negative name, positive otherwise. In particular, the empty interface is positive.\nDefinition 4.3 (Universal arena on an interface). We denote by A\u2020 the arena whose set of\nmoves is {\u2020}, with the polarity of \u2020 being positive.\nLet \u03a0 = \u03be1 , . . . , \u03ben be a (possibly empty) positive interface.\nThe universal arena on the interface \u03a0 is the arena\nU (\u03a0) := A(\u03be1 , +) k * * * k A(\u03ben , +) k A\u2020 .\nThe universal arena on a (negative) interface {\u03c3 \u2212 } \u222a \u03a0 is the arena\nU (\u0393) := A(\u03c3, \u2212) \u25ed U (\u03a0).\nRemark 4.4. We observe that, according to Definition 3.1, a universal arena U (\u0393) is a\npolarized arena; the polarity of the arena is that of its initial actions, which results the same\nas the polarity of the interface \u0393.\nExample 4.5. The universal arena U (\u03be + ) can be pictured as in Figure 1. An arrows from\nb to a stands for an enabling a \u22a2 b; the polarity of the actions is given as follows: actions\nlying on even (resp. odd) layers have positive (resp. negative) polarity.\n..\n.\n\nLayer 1\n\nLayer 0 (Roots)\n\n(\u03be1, {1})\n\n...\n\n\u2020\n\n(\u03be, {1})\n\n(\u03be1, {1, . . . , n}) . . . (\u03be2, {1}) . . .\n\n(\u03be2, {1, . . . , k}) . . .\n(\u03be, {1, 2})\n\n...\n\nFigure 1: The universal arena U (\u03be + )\nDefinition 4.6 (Untyped strategies). Let \u0393 be an interface. A strategy D on \u0393, also\nwritten D : \u0393, is a strategy (in the sense of Definition 3.4) on the universal arena U (\u0393).\nWe point out that here we call strategies and views (following the language of game\nsemantics) what in [22] is indicated as designs and chronicles respectively.\n\n\fLUDICS WITH REPETITIONS\n\n15\n\nExamples 4.7 (Basic strategies: Dai, Fid, \u2205). Let us point out a few relevant strategies.\n\u2022 There are two positive strategies which play a key role in ludics: Dai and Fid. Both are\ndefined on any positive interface, and in particular also on the empty interface. In fact,\nthey are the only possible strategies on the empty interface.\n\u2212 Dai is the strategy which consists of only one action {\u2020}; it is called daimon.\n\u2212 Fid is the empty strategy; it is called faith.\n\u2022 We highlight also a simple example of negative strategy: the empty strategy on a negative\ninterface. We will denote this strategy simply by \u2205.\n4.1.1. Totality.\nDefinition 4.8 (Totality). We say that an untyped strategy is total when it is not Fid.\nThe definition of totality deserves some explanations. First, it is not the usual totality\ncondition of game semantics. Totality, in ludics, is closely connected with the definition of\northogonality, hence it will become clear only after Section 4.3. Let us however anticipate\nsome remarks, to justify why Fid is not a total strategy (while the empty negative strategy \u2205\nis total). The definition of orthogonality is based on the fact that there are only two possible\noutcomes when we make interact two strategies on dual interfaces: either Fid or Dai. The\nformer is interpreted as failure of the interaction process (no output/deadlock), while Dai\nis interpreted as success of the interaction process. In such a case, the strategies are said\nto be orthogonal. We will see (Example 4.27) that, for the way in which the interaction\nis defined, when we have a negative strategy E, its interaction with Dai always succeeds,\nwhile its interaction with Fid always fails (i.e., there is no output).\nMoreover, the fact that the interaction with Dai succeeds for any negative strategy,\nincluding the case of the empty negative strategy allows us also to understand why the\nnegative empty strategy is total. Such a strategy is in fact the smallest strategy to be\northogonal to Dai.\nIn terms of linear logic, the empty negative strategy \u2205 interprets the rule for T , while\nDai would correspond to a \"proof\" of 0 (here T and 0 denote the additive constants top\nand zero respectively). But there is no corresponding \"proof-object\" for Fid. We want a\nstrategy which corresponds to a proof to be total.\n4.1.2. Linearity.\nDefinition 4.9 (Linearity). Given a strategy D : \u0393, we say that an occurrence of action\n(\u03be, I) in D is linear if the name \u03be is only used by that occurrence of action. We say that\nD : \u0393 is linear if each occurrence of (proper) action in D is linear.\nLinearity has as consequence that all pointers are trivial (each move has only one\npossible justifier and the prefix relation between names univocally tells us which is), and\nthen can be forgotten.\nRemark 4.10. Linear strategies are essentially the strategies introduced in [22]. Our\ncondition is actually more strict than the condition in [22], and allows us a simplification\nof some details, by restricting the setting only to multiplicatives. The linearity condition\nin [22] is slightly more complex, in order to take into account also the additive structures\n(additive duplication is allowed), but for our discussion it is enough to ask that in a strategy\neach name is only used once.\n\n\f16\n\nM. BASALDELLA AND C. FAGGIAN\n\nObserve that a relevant consequence of our strict condition of linearity is that both positive and negative strategies have a single root (i.e., they are trees, and not forests). Hence,\nwe can always write a negative strategy of root x as x\u2212 .C. It is immediate to check that C is\na positive strategy. As for positive strategies, let D have root (\u03c3, In )+ , i.e., D = (\u03c3, In )+ .E.\nAll views in E have a first action of the form (\u03c3i, K), with i \u2208 In . We partition E into\nmaximal subsets Ei , 1 \u2264 i \u2264 n of views which start with the same action. The linearity condition implies that each Ei is a negative strategy which either has a unique root\nof the form (\u03c3i, K)\u2212 or is the empty negative strategy (i.e., Ei = \u2205). We will also write\nD = (\u03c3, In )+ .{E1 , . . . , En }, to emphasize the tree structure.\nFrom now on, and till the end of Section 5, strategies are always linear strategies.\n4.2. Dynamics in the linear case. The composition of untyped strategies can be described via the VAM machine (see Section 8). For the moment, we only describe normalization in the linear case (see [22, 12]). This case is simpler, but has all the key ingredients\nto follow most of the examples of this paper.\nThe central idea beyond names, is that we can compose two strategies when their\ninterfaces have a common name, which appears in the two interfaces with opposite polarity.\nThe key case is the following: D1 : \u03c3 + , \u0393 and D2 : \u03c3 \u2212 , \u2206, with \u0393 \u2229 \u2206 = \u2205.\nD1 can communicate with D2 through the name \u03c3. The shared name \u03c3 is called a cut.\nRather than define the dynamics for pairs of strategies, it is more convenient to define\nit for an arbitrary finite number of strategies at the same time.\nDefinition 4.11 (Cuts and cut-nets). Two interfaces \u03931 , \u03932 are said to be compatible if\nall names are pairwise disjoint or equal, and in the latter case any name which appears in\nboth the interfaces, appears with opposite polarity. If \u03be + \u2208 \u0393i and \u03be \u2212 \u2208 \u0393j , the name \u03be is\nsaid to be a cut.\nA non-empty finite set of interfaces {\u03931 , . . . , \u0393n } is said to be valid if:\n\u2022 \u03931 , . . . , \u0393n are pairwise compatible interfaces;\n\u2022 the graph defined here below is connected and acyclic:\n\u2212 nodes: \u03931 , . . . , \u0393n ;\n\u2212 edges: there is an edge between \u0393i and \u0393j for each cut \u03be such that \u03be + \u2208 \u0393i and \u03be \u2212 \u2208 \u0393j .\nA non-empty finite set of strategies R = {D1 : \u03931 , . . . , Dn : \u0393n } is said to be a cut-net if\n{\u03931 , . . . , \u0393n } is a valid set of interfaces.\nWe also write R = {D1 , . . . , Dn } when the interfaces of the strategies are clear from\nthe contexts or irrelevant for our purposes.\nRemark 4.12. The acyclicity condition implies that any two interfaces in a valid set have\nat most one name in common. Observe that if {\u03931 , \u03932 } is a valid set of interfaces, then\nthere is exactly one cut (at most one by acyclicity, at least one by connectedness).\nExample 4.13. The following three sets of interfaces are all pairwise compatible, but only\nthe third one (3) is valid: (1) is not acyclic, an (2) is not connected. 2\n2In the picture, we orient the edges for future uses of this example (Proposition 4.18). But recall that\n\nthe edges of the graph as given in Definition 4.11 are not oriented.\n\n\fLUDICS WITH REPETITIONS\n\n\u03b2\n\n\u03c3\n\n(1)\n\n\u03be \u2212 , \u03c3+\n\n17\n\n\u03c3 \u2212 , \u03b1+ , \u03b2 +\n\n\u03b2\u2212, \u03be+\n\n\u03be\n\n(2)\n\n\u03b2\u2212, \u03be+\n\n\u03b1\u2212 , \u03b3 +\n\n\u03b2\n\n(3)\n\n\u03c3 \u2212 , \u03b1+ , \u03b2 +\n\n\u03b2\u2212, \u03be+\n\n\u03b1\u2212 \u03b3 +\n\n\u03b1\n\nDefinition 4.14 (Closed cut-net). A cut-net R is closed if all names in the interfaces are\ncuts.\nExample 4.15. We have a typical example of closed cut-net when we have strategies on\nopposite interface, such as D : \u03be + and E : \u03be \u2212 .\nRemark 4.16. Closed cut-nets contain exactly one positive strategy (see also Remark 4.19).\nGiven a cut-net R = {D1 : \u03931 , . . . , Dn : \u0393n }, the result of the composition is called\nnormal form, and denoted by [[R]]. Composition (normalization) follows the standard\nparadigm of parallel composition (the interaction) plus hiding of internal communication:\n[[R]] is obtained from the result of the interaction by hiding all the actions\non internal\nS\nnames. The result is a strategy on the interface which is obtained from \u0393i by hiding all\ncut names.\nS\nGiven the cut-net R, if \u0398 is the set of the cuts, then ( 1\u2264i\u2264n \u0393i ) \\ \u0398 is an interface,\nwhich is called the interface of R.\nComposition of the strategies in a cut-net can be described in several equivalent ways.\nThe merging of orders [22, 16] is the most compact and mathematically pleasant - but it\nis specific to the linear case. In this paper, we prefer to describe composition via an abstract\nmachine (the LAM [23, 12]), because this will serve as an introduction to the machine which\nperforms the composition of strategies with repetitions.\nLet us first introduce with a small example the basic ideas on the way in which strategies\nin a cut-net interact with each other to produce the normal form. Since each action appears\nonly once, the dynamics is extremely simple: we match actions of opposite polarity.\nExample 4.17. Let us consider the following strategies:\n\u2022 D = a+ .b\u2212 .\u2020;\n\u2022 E = a+ ;\n\u2022 F = a\u2212 .b+ ;\nwhere a = (\u03be, I) and b = (\u03be1, K), so that D, E : \u03be + and F : \u03be \u2212 . Notice that b is enabled by\na in both the underlying universal arenas. We can draw these strategies as follows:\n\n\f18\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u2020\nb\u2212\nD\n\na+\n\nb+\nE\n\na+\n\nF\n\na\u2212\n\nLet us have D interact with F. Remember the intuition that \"+\" corresponds to an output,\nand \"\u2212\" to an input. D starts by playing the move a+ , F receives a and checks its answer\nto that move, which is b+ . If D receives input b, its answer is \u2020, which terminates the\ninteraction. Summing up, the interaction produces a+ .a\u2212 .b+ .b\u2212 .\u2020. If we hide the internal\ncommunication, we get \u2020, i.e., [[D, F]] = Dai.\nIf we have E interacting with F, we again match a+ with a\u2212 . Then F plays b, but E\nhas not considered the action b. Here we have a deadlock i.e., [[E, F]] = Fid.\n4.2.1. Linear composition: LAM (Loci-Abstract-Machine). To formally define normalization, we need to introduce a notion of order on the strategies of a cut-net; such a definition\nmakes explicit the order in which normalization accesses the strategies.\nUp to the end of this section, let us fix a cut-net R = {D1 : \u03931 , . . . , Dn : \u0393n }.\nProposition 4.18 (Main strategy). Given a cut-net R, we define the following precedence\nrelation < on the strategies:\nDi : \u0393i < Dj : \u0393j if there is a cut \u03be such that \u03be + \u2208 \u0393i and \u03be \u2212 \u2208 \u0393j .\nThe order induced by this precedence relation has a minimal element, which is called the\nmain strategy of R.\nProof. Since the graph induced by the valid set of interfaces is acyclic (Definition 4.11), the\norder is arborescent, because each interface contains at most one negative name, hence each\nstrategy has at most one immediate predecessor.\nTo verify that there is a unique minimal element, we observe that the precedence relation\ninduces also an orientation on the edges of the graph: for each cut \u03be such that \u03be + \u2208 \u0393i\nand \u03be \u2212 \u2208 \u0393j , the edge is oriented from \u0393i to \u0393j (see Example 4.13). Since the graph is\nconnected, the oriented graph is a tree, and not a forest. Hence there is a unique minimal\nstrategy.\nRemark 4.19. In a cut-net, there is at most one positive strategy, which necessarily is the\nmain one. The argument is the same as in the previous proof.\nA cut name \u03be and all the names hereditarily generated from \u03be, are said to be internal.\nWe call internal an action on an internal name, otherwise the action is said to be visible.\nObserve that if R is a closed cut-net, then all the names are internal (and its interface\nis empty). The only possible visible actions are \u2020 actions.\nThe following lemma is also an easy preliminary observation.\nLemma 4.20. Let R be a cut-net. Given a proper action x\u01eb , it occurs in at most one\nD \u2208 R.\n\n\fLUDICS WITH REPETITIONS\n\n19\n\nDefinition 4.21 (LAM [12, 23]). Given a cut-net R, the set LAM (R) is the set of sequences\nof actions defined as follows.\n(1) (Initialization) If the main strategy of R is empty, we set LAM (R) := \u2205. Otherwise,\nif a is the root of the main strategy, we set a \u2208 LAM (R).\n(2) Let p = x1 . . . xn \u2208 LAM (R). We have the following two cases:\na. (Continuation)\nThe action xn is either a negative action or a positive visible action. If xn is\nproper, by the previous lemma there exists a unique strategy D \u2208 R such that a\nview s.xn \u2208 D. In such a case, for each action a which extends s.xn in D we set\np.a \u2208 LAM (R).\nb. (Jump) The action xn = a+ is an internal positive action. If there is E \u2208 R such\nthat a view s.a\u2212 \u2208 E, we set p.a\u2212 \u2208 LAM (R). We say that a\u2212 matches a+ .\nLet us informally explain how the machine calculates the interaction of a cut-net R. The\nmachine visits actions of the strategies in R and collects the sequences of visited actions,\nproceeding as follows:\n\u2022 We start on the root of the main strategy of a cut-net R.\n\u2022 If we visit a visible action a occurring in some D \u2208 R, we continue to explore the current\nstrategy D. The process branches when a is a branching node of D.\n\u2022 If we visit an internal action a+ occurring in D we match it with its opposite a\u2212 occurring\nin E \u2208 R, then we continue to collect actions in E (this is a jump of the machine).\n\u2022 We may eventually stop when either we reach a maximal action or an internal action\nwhich has no match.\nDefinition 4.22 (Hiding). Given a cut-net R, and p = x1 , . . . , xn \u2208 LAM (R), we define\nhide(p) as the sequence obtained from p by deleting all the internal actions.\nDefinition 4.23 (Normal form). Let R be a cut-net. We define the set I(R) of the\ninteractions of R as the closure by non-empty prefix of\n{q.c \u2208 LAM (R) : c visible and positive}.\nThe normal form of R, denoted by [[R]] is defined as\n[[R]] = {hide(p) : p \u2208 I(R) and hide(p) non-empty}.\nThe normal form of a cut-net is a strategy [22, 9, 23].\nTheorem 4.24. If R is a cut-net of interface \u0393, then [[R]] is a strategy on \u0393.\nComposition satisfies associativity, in the following sense [22, 9, 23].\nTheorem 4.25 (Associativity). Let R be a cut-net which can be partitioned into cut-nets\nR = R1 \u222a . . . \u222a Rn . We have:\n[[R]] = [[[[R1 ]], . . . , [[Rn ]]]].\n\n\f20\n\nM. BASALDELLA AND C. FAGGIAN\n\nRemark 4.26. The standard associativity of game semantics (in terms of \"morphisms\")\ncan be expressed in this setting, considering the universal arena on an interface of the form\n\u03b1\u2212 , \u03b2 + as an arena \"of the form A \u2192 B.\" Let us write for now \u03b1 \u2192 \u03b2 instead of \u03b1\u2212 , \u03b2 + .\nLet \u03b1, \u03b2, \u03b3, \u03b4 be disjoint names and consider D : \u03b1 \u2192 \u03b2, E : \u03b2 \u2192 \u03b3 and F : \u03b3 \u2192 \u03b4. By\nTheorems 4.24 and 4.25, we have that\n[[[[D, E]], F]] = [[D, E, F]] = [[D, [[E, F]]]]\nis a strategy on interface \u03b1 \u2192 \u03b4.\nExample 4.27 (Interaction with Dai or Fid). We can now examine how Fid and Dai\nbehave in the normalization, and so make precise the discussion in Section 4.1.1. Let\nR = {D, E1 , . . . , En } be a positive cut-net, where D is the unique positive strategy (see\nRemark 4.19). Let us see what happens when D = Dai or D = Fid.\n\u2022 The interaction starts from D (because it is the main strategy).\n\u2022 If D is Dai, the interaction reaches \u2020 at the first step, and terminates immediately,\nwhatever the other (negative) strategies in E1 , . . . , En are.\n\u2022 If D is Fid, nothing can happen. Since D is empty, the output of the interaction is also\nempty.\nSumming up, we always have that:\n[[Dai, E1 , . . . , En ]] = Dai\n\nand\n\n[[Fid, E1 , . . . , En ]] = Fid.\n\n4.2.2. A notation to describe the interaction. In the sequel, given two strategies D and F\nwe often describe their interaction in the following graphical way:\n\n\u2020\n\n3\n\n4\n\nb\u2212\n\nb+\n2\n\nD\n\na+\n\na\u2212\n\nF\n\n1\n\nHere, we have taken D and F as in Example 4.17. We draw tagged arrows to denote the\nmatching of actions (e.g., a+ matches a\u2212 at step 1) and the (unique) positive action (the\n\"answer\") above a reached negative action (e.g., , b+ after a\u2212 ). The tags 1, 2, . . . are only\nneeded to record the chronological order in which actions are visited. Following the arrows\nwith this order, we retrieve the sequence of actions a+ .a\u2212 .b+ .b\u2212 .\u2020 which corresponds to the\ninteraction of D and F of Example 4.17.\n\n\fLUDICS WITH REPETITIONS\n\n21\n\n4.3. Orthogonality. The most important case of composition in ludics is the closed case,\nthe typical example being a cut-net given by two strategies on opposite interfaces D : \u03be +\nand E : \u03be \u2212 .\nWe already observed that in this case, all names are internal, and the interface of the\ncut-net is empty. Since we know that there are only two possible strategies which have\nempty interface: Fid and Dai, we only have two possible values as normal form. Fid and\nDai are respectively interpreted as failure (deadlock) or success of the interaction process.\nMore precisely, either normalization gives no output at all - and in this case the result\nis the empty strategy, i.e., Fid - or it succeeds by reaching the action \u2020, which signals\ntermination - and in this case the result is the strategy Dai. In the case of success, we say\nthat the strategies are orthogonal.\nThe orthogonality relation is defined only on total strategies. In fact, we already know\n(Example 4.27) that if Fid \u2208 R then [[R]] = Fid, whatever are the other strategies.\nLet us first anticipate the definition in the key case of strategies on a unary interface,\nand then give the general definition of being orthogonal.\nGiven two total strategies D : \u03be + and E : \u03be \u2212 , they are said to be orthogonal, written\nD\u22a5E (or equivalently E\u22a5D), if [[D, E]] = Dai.\nOrthogonality means that at each step of the interaction, the positive action x+ is\nmatched with its negative dual action x\u2212 , and the computation terminates by reaching a \u2020\naction.\nWe can then define the orthogonal set of a set of total strategies S on the same interface\n\u03be \u01eb in a standard way as\nS\u22a5 = {E : E is a total strategy on the interface \u03be \u01eb and E\u22a5D for any D \u2208 S}\nNotice that (as in [22]) the partial strategy Fid is ruled out in the definition of the orthogonal\nsets. For instance, if S is the empty set of negative strategies on \u03be \u2212 , then S\u22a5 is the set of\nall total strategies on \u03be + (in particular, Fid \u2208\n/ S\u22a5 ).\nExample 4.28. In example 4.17, D\u22a5F, while E and F are not orthogonal.\nWe now make this notion general.\nDefinition 4.29 (Counter-strategies). Given an interface \u0393, we call family of counterstrategies (w.r.t. \u0393) any family of total strategies (E\u03be : \u03be \u01eb )\u03be \u01eb \u2208\u0393 .\nWith a slight abuse of notation, we will write simply (E\u03be )\u03be\u2208\u0393 , by omitting the indication\nof the polarity (when clear from the context, we will also omit the indication of the indexing\nset \u0393).\nIf D : \u0393 is a strategy, we will use the notation {D, (E\u03be )} for the cut-net {D}\u222a{E\u03be : \u03be \u2208 \u0393}\nthey induce. Observe that {D, (E\u03be )} is a closed cut-net.\nExample 4.30. If \u0393 = \u03be + , a counter-strategy has the form E : \u03be \u2212 .\nIf \u0393 = \u03be \u2212 , \u03b1+ , \u03b2 + , then {E1 : \u03be + , E2 : \u03b1\u2212 , E3 : \u03b2 \u2212 } is a family of counter-strategies.\nWe can now define the orthogonality relation and orthogonal sets. We use the same\nnotation of Definition 4.29.\nDefinition 4.31 (Orthogonality, orthogonal set). Let D : \u0393 be a total strategy and (E\u03be )\nbe a family of counter-strategies w.r.t. \u0393. D and (E\u03be ) are said to be orthogonal, written\nD\u22a5(E\u03be ) (or equivalently (E\u03be )\u22a5D), if [[D, (E\u03be )]] is total. In other words, we have orthogonality\nif [[D, (E\u03be )]] = Dai.\n\n\f22\n\nM. BASALDELLA AND C. FAGGIAN\n\nGiven a set S of total strategies on the same interface \u0393, its orthogonal set is defined\nas\nS\u22a5 := {(E\u03be ) : (E\u03be ) is a family of counter-strategies w.r.t. \u0393 and (E\u03be )\u22a5D for any D \u2208 S}.\nSimilarly, given a set C of families of counter-strategies w.r.t. \u0393, its orthogonal set is\ndefined as\nC\u22a5 := {D : D is total on interface \u0393 and D\u22a5(E\u03be ) for any (E\u03be ) \u2208 C}.\nOrthogonality satisfies the usual closure properties: if E, F are sets of total strategies on\nthe same interface (resp. sets of families of counter-strategies w.r.t. the same interface),\nthen\n\u2022 E \u2286 F implies F\u22a5 \u2286 E\u22a5 (and thus E\u22a5\u22a5 \u2286 F\u22a5\u22a5 );\n\u2022 E \u2286 E\u22a5\u22a5 ;\n\u2022 E\u22a5 = E\u22a5\u22a5\u22a5 .\nIn terms of games, orthogonality allows the players to agree (or not), without this being\nguaranteed in advance by the type: {D}\u22a5 is the set of the families of counter-strategies which\nare consensual (i.e., well interact) with D.\n4.4. Interactive types (behaviours).\nDefinition 4.32 (Behaviour). A behaviour (or interactive type) on the interface \u0393 is\na set G of strategies D : \u0393 such that G\u22a5\u22a5 = G (i.e., it is closed by bi-orthogonal). We say\nthat a behaviour G is positive or negative according to its interface.\nWe observe that (by the definition of orthogonal set) an interactive type only contains\ntotal strategies.\nWhen is useful to emphasize that G is a set of strategies on the name \u03be, we may\nannotate the name \u03be as a subscript: G\u03be .\nExample 4.33 (00, \u22a4 ). Given a name \u03be, the minimal positive behaviour on \u03be + is the one\ngenerated by the empty set of total strategies on \u03be + . Its orthogonal set consists of all the\nnegative strategies on interface \u03be \u2212 . Let us call \u22a4 this set, which is the maximal negative\nbehaviour on \u03be. By the definition of orthogonality, a strategy in \u22a4 \u22a5 must be consensual\nto all negative strategies on interface \u03be \u2212 . But the only strategy which can do this is Dai.\nHence the closure by bi-orthogonal of the empty set of positive total strategies on \u03be + is\n{Dai}. Let us call 0 this behaviour.\nIn [22] \u22a4 and 0 are the interpretations of the additive constants T and 0 of linear logic\nrespectively, whence their name.\nRemark 4.34. In our setting - but not in [22]- behaviours can be empty. While a\npositive behaviour is never empty (because it contains at least Dai), a negative behaviour\ncan be empty: if S is the empty set of strategies on a negative interface, S = S\u22a5\u22a5 . This\ndifference with [22] is a limit of our choice of \"strict linearity\" (Section 4.1.2), and will\ndisappear in the non-linear setting.\nThis mismatch deserves some discussion. The purpose of this and next section is to\ngive a compact but complete presentation of the construction of ludics and of internal\ncompleteness in the linear case. In particular, we want to show (in this setting which\nis easier to grasp) how full completeness follows from internal completeness, and provide\na proof which will then be possible to generalize to a full setting in the second part of\n\n\fLUDICS WITH REPETITIONS\n\n23\n\nthe paper. For this reason, we will restrict our attention to the multiplicatives. To have\nadditive structure would make the behaviours never empty, but require some more technical\ndefinitions, without adding anything substantial to our purposes. The small price is the\nexplicit request for the behaviours to be \"non-empty\" in the various constructions below.\n4.5. Linear types constructors. In this section we consider the behaviours which will\ninterpret logical formulas, more precisely multiplicative formulas.\n4.5.1. Constructions on strategies. Let D1 : \u03be1\u2212 , . . . , Dn : \u03ben\u2212 with n \u2265 0 be negative\nstrategies. We obtain a new positive strategy on the interface \u03be + , denoted by D1 \u2022 * * * \u2022 Dn ,\nby adding to the union of the strategies the positive root (\u03be, In )+ , i.e.,\nD1 \u2022 * * * \u2022 Dn := (\u03be, In )+ .{D1 , . . . , Dn }.\nRecall that as we stipulated in Section 3.3, In denotes either {1, . . . , n} if n > 0, or \u2205 if\nn = 0.\n4.5.2. Constructions on behaviours.\nDefinition 4.35 (Tensor/Par of behaviours). Let N1 . . . , Nn be non-empty negative behaviours on interface \u03be1\u2212 , . . . , \u03ben\u2212 respectively.\nWe define the set of strategies:\nN1 \u2022 * * * \u2022 Nn := {D1 \u2022 * * * \u2022 Dn : Di \u2208 Ni for any 1 \u2264 i \u2264 n}\nand the behaviours\nN1 \u2297 * * * \u2297 Nn := (N1 \u2022 * * * \u2022 Nn )\u22a5\u22a5\n\u22a5\n\u22a5\nN\u22a5\n1 ` * * * ` Nn := (N1 \u2022 * * * \u2022 Nn )\n\npositive behaviour on \u03be + ;\nnegative behaviour on \u03be \u2212\n\nWe call multiplicative a behaviour which is inductively generated by these constructions.\nRemark 4.36 (0-ary case). In the case that n = 0, the set N1 \u2022* * * \u2022Nn consists of a unique\n\u22a5\n\u2212\nstrategy D = (\u03be, \u2205)+ . We have that N\u22a5\n1 `* * *`Nn only contains the strategy E = (\u03be, \u2205) .Dai\n, since there is no other possibility to be orthogonal to D. Finally, N1 \u2297* * *\u2297Nn = {D, Dai},\nagain because there are no other possibilities.\n\u22a5\nWe denote by 1 the behaviour N1 \u2297 * * * \u2297 Nn and by \u22a5 the behaviour N\u22a5\n1 ` * * * ` Nn\nin the case n = 0. Of course, both behaviours are multiplicative.\n\u22a5\nProposition 4.37. Let P = N1 \u2297 * * * \u2297 Nn and N = N\u22a5\n1 ` * * * ` Nn .\n\u2022 P, N are non-empty;\n\u2022 P, N contain only non-empty strategies.\nIn particular, multiplicative behaviours are never empty.\n\nProof. A positive behaviour is never empty, because it contains at least Dai. Moreover,\nFid \u2208\n/ P, by definition of orthogonality. For negatives behaviours generated by our construction, observe that since N1 , . . . , Nn are non-empty, N1 \u2022 * * * \u2022 Nn is non-empty too and\nby construction all the strategies have the same root (\u03be, In ). A negative behaviour N of the\nform (N1 \u2022 * * * \u2022 Nn )\u22a5 is also never empty, because it contains E := (\u03be, In )\u2212 .\u2020. The empty\nstrategy cannot belong to N, because it is not orthogonal to any strategy in N1 \u2022 * * * \u2022 Nn .\n\n\f24\n\nM. BASALDELLA AND C. FAGGIAN\n\n4.6. Sequent of behaviours. As a behaviour on a unary interface corresponds in ludics to\na logical formula, the notion of sequent of behaviours corresponds to the notion of sequent.\nDefinition 4.38 (Sequent of behaviours). Let \u0393 = \u03be1\u01eb1 , . . . , \u03ben\u01ebn (n \u2265 0) be an interface, and\nlet \u0393 = G\u03be1 , . . . , G\u03ben (n \u2265 0) behaviours of respective polarities \u01eb1 , . . . , \u01ebn .\nWe define a new behaviour on the same interface \u0393, which we call sequent of behaviours and denote by \u22a2 \u0393, as follows:\n\u22a5\n\u22a2 \u0393 := {D : D is total on interface \u0393 and D\u22a5{E1 , . . . , En } for all E1 \u2208 G\u22a5\n\u03be1 , . . . , En \u2208 G\u03ben }.\n\nIt is clear that a sequent of behaviours is itself a behaviour, since it is the orthogonal set of\n\u22a5\nthe set of families of counter-strategies (E1 , . . . , En ) such that E1 \u2208 G\u22a5\n\u03be1 , . . . , En \u2208 G\u03ben .\nObserve that:\n\u2022 \u22a2 P = P and \u22a2 N = N.\n\u2022 if \u03a0 is empty, \u22a2 \u03a0 = {Dai}.\nWhen moving to full completeness (and thus consider sequents of multiplicative behaviours), we will use also the following property, which is immediate by associativity\n(Theorem 4.25).\nProposition 4.39. Let A, G1 , . . . Gn (n \u2265 0) be a sequence of multiplicative behaviours,\nand \u0393 = G1 , . . . Gn . We have that:\n\u2022 D \u2208 \u22a2 \u0393, A if and only if for each F \u2208 A\u22a5 , [[D, F]] \u2208 \u22a2 \u0393.\n\u2022 D \u2208 \u22a2 \u0393, A if and only if [[D, (Ei )]] \u2208 \u22a2 A, for each family (Ei ) such that E1 \u2208 G\u22a5\n1 ,...,\n.\nEn \u2208 G\u22a5\nn\n\u22a5\nProof. Let us abbreviate the set {(Ei ) : E1 \u2208 G\u22a5\n1 , . . . , En \u2208 Gn } by C. We then have:\n\nD \u2208 \u22a2 \u0393, A \u21d4\n\u21d4\n\u21d4\n\u21d4\n\u21d4\n\n\u2200F\n\u2200F\n\u2200F\n\u2200F\n\u2200F\n\n\u2208 A\u22a5 \u2200(Ei ) \u2208 C, D\u22a5{F, (Ei )}\n\u2208 A\u22a5 \u2200(Ei ) \u2208 C, [[D, F, (Ei )]] is total\n\u2208 A\u22a5 \u2200(Ei ) \u2208 C, [[[[D, F]], (Ei )]] is total\n\u2208 A\u22a5 \u2200(Ei ) \u2208 C, [[D, F]]\u22a5(Ei )\n\u2208 A\u22a5 , [[D, F]] \u2208 \u22a2 \u0393.\n\n(associativity)\n\nThe second claim is obtained by iterating the first one.\n5. Ludics in the linear case: internal and full completeness\nWe introduce the notion of internal completeness and give a direct proof of internal completeness, as well as full completeness, without relying on separation.\nIn [22], the set of strategies which interprets MALL formulas satisfies a remarkable\nclosure property, called internal completeness: the set S of strategies produced by the\nconstruction is essentially equal to its biorthogonal (S = S\u22a5\u22a5 ). Since the biorthogonal does\nnot introduce new objects, we have a complete description of all strategies in the behaviour.\nThe best example is the interpretation N1 \u2297 N2 := (N1 \u2022 N2 )\u22a5\u22a5 of a tensor formula.\nOne proves that (N1 \u2022 N2 ) \u222a {Dai} = (N1 \u2022 N2 )\u22a5\u22a5 , i.e., we do not add new objects when\nclosing by biorthogonal: our description - the one which generates the set - is already\ncomplete.\n\n\fLUDICS WITH REPETITIONS\n\n25\n\nFrom this, full completeness follows. In fact, because of internal completeness, if D \u2208\nN1 \u2297 N2 and D 6= Dai we know we can decompose it as D1 \u2022 D2 , with D1 \u2208 N1 and\nD2 \u2208 N2 . This corresponds to writing the rule:\n..\n..\n.\n.\n\u22a2 N1\n\u22a2 N2\n\u2297\n\u22a2 N1 \u2297 N2\ni.e., if each Di corresponds to a proof of Ni , and D corresponds to a proof of N1 \u2297 N2 .\n5.1. Internal completeness. Until the end of Section 5 , we assume the following:\n\u2022 we fix a name \u03be\n\u2022 N1 , . . . Nn (n \u2265 0) are non-empty negative behaviours, respectively on \u03be1\u2212 , . . . , \u03ben\u2212 .\nLet us examine the form of the strategies which inhabit a behaviour of the type we\nhave introduced in the last section. Let us first consider N1 \u2022 N2 . By construction, each\nstrategy in N1 \u2022 N2 is on \u03be + and has x+ = (\u03be, {1, 2})+ as root.\nWhat is (N1 \u2022N2 )\u22a5 ? By definition of linear normalization, each strategy has as root the\naction x\u2212 = (\u03be, {1, 2})\u2212 (otherwise, normalization would fail immediately). In particular\nwe have the strategy x\u2212 .\u2020.\nWhat is (N1 \u2022 N2 )\u22a5\u22a5 ? All strategies have a positive root, which, to normalize against\n(N1 \u2022 N2 )\u22a5 , must be either \u2020, or x+ . Hence, we know that a strategy D \u2208 N1 \u2297 N2 is\neither Dai or has the form x+ .{D1 , D2 }, where D1 : \u03be1 and D2 : \u03be2. The following picture\nrepresents this.\n\nD1\n\n(\u03be1, J)\u2212\n\n(\u03be2, K)\u2212 D2\nx+\n\nx\u2212\n\nD \u2208 (N1 \u2022 N2 )\u22a5\u22a5\n\nE \u2208 (N1 \u2022 N2 )\u22a5\n\nWe now want to prove that if D \u2208 (N1 \u2297 N2 ) (and D 6= Dai) then D1 \u2208 N1 and D2 \u2208 N2 ,\nwhich means that (N1 \u2022 N2 ) was already complete, i.e., closed by biorthogonal.\nProposition 5.1 (Internal completeness of tensor). Let N1 , . . . , Nn be n \u2265 0 non-empty\nnegative behaviours, respectively on \u03be1\u2212 , . . . , \u03ben\u2212 . We have that\nN1 \u2297 * * * \u2297 Nn = N1 \u2022 * * * \u2022 Nn \u222a {Dai}.\nProof. We have already shown that this is true in the case n = 0 (Remark 4.36). W.l.o.g.,\nwe prove the claim in the case n = 2.\nLet D \u2208 N1 \u2297 N2 , D =\n6 Dai. We know (by the discussion above) that D has the form\nx+ .{D1 , D2 }, with x = (\u03be, {1, 2}). We now prove that D1 \u2208 N1 and D2 \u2208 N2 .\n\n\f26\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u2032\n\u2212\n\u2212\n(i) Given any E : \u03be1+ \u2208 N\u22a5\n1 , we obtain the strategy E : \u03be = x .E by adding the root\n\u2212\nx . We have that\n[[x\u2212 .E, x+ .{D1 , D2 }]] = [[E, D1 ]]\n(\u22c6)\nby definition of normalization, and by the fact that since in E there are only names\ngenerated by \u03be1. Hence, E : \u03be1+ only interact with the subtree D1 : \u03be1\u2212 . No action in\nD2 is ever used.\n(ii) E \u2032 \u2208 (N1 \u2022 N2 )\u22a5 , because by using (\u22c6) we deduce that E \u2032 \u22a5D, for any D \u2208 (N1 \u2022 N2 ).\n(iii) Given any D \u2208 N1 \u2297 N2 , by definition we have that D\u22a5E for each E \u2208 (N1 \u2022 N2 )\u22a5 .\n\u2032\n\u2032\nHence in particular, for each E \u2208 N\u22a5\n1 , we have D\u22a5E (E defined as above). Again\n\u22a5\n\u22a5\nbecause of (\u22c6), D1 \u22a5E. This says that D1 \u2208 (N1 ) = N1 .\n\nRemark 5.2 (Important). The key to extend this argument to the case of ludics with\nrepetition, is that here we only use two properties of the strategies: the dynamics (normalization), and the fact that the root is the only action on the name \u03be (to say at point (i) in\nthe proof above that occurrences of \u03be1 only appear inside D1 ).\nProposition 5.3 (Internal completeness of par). Let N1 , . . . , Nn be as in 5.1 (hence\n+\n+\n\u22a5\nN\u22a5\n1 , . . . , Nn are positive behaviours respectively on \u03be1 , . . . , \u03ben ), and let x = (\u03be, In ). We\nhave:\n\u22a5\n\u22a5\n\u22a5\nx\u2212 .E \u2208 N\u22a5\n1 ` * * * ` Nn \u21d4 E \u2208 \u22a2 N1 , . . . , Nn .\nProof. The case n = 0 is actually given by Remark 4.36, observing that the empty sequent\nof behaviours contains only Dai.\n\u22a5\nLet us give the proof in the case n = 2. A strategy x\u2212 .E belongs to N\u22a5\n1 ` N2 if and\n+\n\u2212\n+\nonly if for any x .{D1 , D2 } \u2208 N1 \u2022 N2 , we have that x .E \u22a5 x .{D1 , D2 }. By definition\nof normalization, [[x\u2212 .E, x+ .{D1 , D2 }]] = [[E, D1 , D2 ]], and from this and the definition of\nsequent of behaviours (Definition 4.38) the claim follows immediately.\n5.2. Full completeness. We are now ready to show how full completeness is obtained\nfrom internal completeness, in the linear case. More precisely, we are going to introduce\nthe calculus MLLS, which is the multiplicative fragment of the calculus HS introduced\nby Girard in [22, 23]. We then show that full completeness can be derived from internal\ncompleteness of tensor and par and Proposition 4.39.\nWhile the proof in [22] relies on separation, we give a direct proof which uses only the\nproperties of the dynamics. The choice of omitting the additive here only simplifies (and\nshortens) the presentation; the proof can be extended to the additive structure without\nproblems (but in that case, we would need to add one more \"winning conditions\", as we\nwill discuss below).\n5.2.1. MLLS. As it is the case for HS [22, 23], the calculus MLLS is affine, i.e., we have\nweakening (but restricted to positive formulas).\nThe calculus MLLS can be seen as the affine (with implicit weakening but without\nimplicit contraction for positive formulas) restriction of the calculus MELLS given in Section 2 3.\nFormulas of MLLS are inductively given by:\nP ::= N1 \u2297 * * * \u2297 Nn\n\nN ::= P1 ` * * * ` Pn\n\n3We do not consider the cut-rule here, but we do it in Section 11.3.\n\n(n \u2265 0).\n\n\fLUDICS WITH REPETITIONS\n\n27\n\nT\n\nWhen n = 0, we write I and for the positive and negative formula respectively.\nRules of MLLS are given in Table 3.\n\nPositive rules :\nP = N1 \u2297 * * * \u2297 Nn and n \u2265 0\n\n\u22a2 \u03a01 , N1\n...\n\u22a2 \u03a0n , Nn\n\u22a2 \u03a00 , \u03a01 , . . . , \u03a0n , P\n\u22a2 \u03a0, P1 , . . . , Pn\n\u22a2 \u03a0, N\n\nNegative rules :\n\nPosn\n\nNegn\n\nN = P1 ` * * * ` Pn and n \u2265 0\nTable 3: MLLS\nNotice the (implicit) weakening on occurrences of positive formulas \u03a00 in the positive rule.\n5.2.2. Interpretation. We only give an outline of the interpretation of formulas and sequents.\nWe will discuss it in full detail the interpretation of derivations in the setting which also\nincludes exponentials in Section 11.3.\nGiven a formula F of MLLS and an arbitrary name \u03be we associate a multiplicative\nbehaviour of the same polarity F on interface \u03be inductively as follows.\nN1 \u2297 * * * \u2297 Nn\nP1 ` * * * ` Pn\n\n\u03be\n\u03be\n\n:= N1 \u03be1 \u2297 * * * \u2297 Nn \u03ben ;\n:= P1 \u03be1 ` * * * ` Pn \u03ben .\n\nGiven a positive sequent \u22a2 P1 , . . . , Pn , and a positive interface \u03be1+ . . . , \u03ben+ we associate the sequent of behaviours \u22a2 P1 \u03be1 , . . . , Pn \u03ben . Given a negative sequent \u22a2 N, P1 , . . . , Pn and a negative interface \u03c3 \u2212 , \u03be1+ . . . , \u03ben+ we associate the sequent of behaviours \u22a2 N \u03c3 , P1 \u03be1 , . . . , Pn \u03ben .\nThe interpretation of a proof \u03c0 of \u22a2 \u0393 will be a daimon-free strategy in the sequent of\nbehaviours \u22a2 \u0393. Once given the interpretation of proofs (which we only do in Section 11.5)\none can establish the following theorem.\nTheorem 5.4. Let \u03c0 be a proof of a sequent \u22a2 \u0393 in MLLS. There exists a daimon-free\nstrategy D \u2208 \u22a2 \u0393 such that D is interpretation of \u03c0.\n5.2.3. Full completeness. We now show the following in detail:\nTheorem 5.5 (Full completeness). Let \u22a2 \u0393 be a sequent of behaviours which is interpretation of the sequent \u22a2 \u0393 in MLLS. If D is a daimon-free strategy in \u22a2 \u0393 then D is the\ninterpretation of a proof \u03c0 of the sequent \u22a2 \u0393 in MLLS.\n\n\f28\n\nM. BASALDELLA AND C. FAGGIAN\n\nWe notice that we associate proofs only to daimon-free strategies. Being daimon-free is\nwhat is called a \"winning condition.\" Since we are only concerned with the multiplicative\nstructure, this is the only condition necessary for linear strategies.\nWhen working with additive structure, or with exponentials, one also needs the notion\nof materiality, which is introduced in [22] and that we will discuss in Section 11. However,\nsince we restrict out attention to the multiplicative fragment, we can overlook materiality\nfor the moment.\nLet \u22a2 \u0393 be the interpretation of the sequent \u22a2 \u0393, and D \u2208 \u22a2 \u0393 a daimon-free strategy.\nOur purpose is to associate to D a derivation D \u22c6 of \u22a2 \u0393 in MLLS by progressively decomposing D, i.e., inductively writing \"the last rule.\" To be able to use internal completeness,\nwhich is defined on behaviours on unary interfaces (and not on sequents of behaviours),\nwe will use - back and forth - the definition of sequent of behaviours and in particular\nProposition 4.39.\nThe formula on which the last rule is applied is indicated by the name of the root\naction. For example, let us assume that the root of D is (\u03be, I); then if D \u2208 \u22a2 G\u03b1 , F\u03be , the\nbehaviour which corresponds to the last rule is the one on \u03be, that is F\u03be .\nThe proof is by induction on the number of logical symbols occurring in the sequent\n\u22a2 \u0393 we have interpreted in \u22a2 \u0393.\nIn the sequel, we consider sequents of behaviours of the form \u22a2 \u03a0, F\u03be , which are interpretations of sequents \u22a2 \u03a0, F of MLLS. F is the interpretation of a formula F and \u03a0 is a\nsequence of m behaviours Q\u03b11 , . . . , Q\u03b1m which respectively interpret formulas Q1 , . . . , Qm .\nObserve that by the shape of the rules of MLLS and the fact that the interpretation of\nformulas preserves the polarity, \u03a0 always consists of positive behaviours only.\nWe also remark the following facts:\n\u2022 Since we consider daimon-free strategies, all the actions in D are proper actions.\n\u2022 By linearity, both positive and negative strategies have a single root (i.e., they are trees,\nand not forests), and hence are of the form D = x+ .{D1 , . . . , Dn } or D = x\u2212 .D \u2032 .\n\u2022 Suppose that D belongs to some negative behaviour F which is interpretation of a formula\nof MLLS. Since F has to be of the form (N1 \u2022 * * * \u2022 Nn )\u22a5 , then D is not empty (see\nProposition 4.37).\nBelow we use the following convention: we write (E) and (E) \u2208 C for E1 , . . . , Em and\n\u22a5\nE1 \u2208 Q \u22a5\n\u03b11 , . . . , Em \u2208 Q\u03b1m respectively.\nWe have two cases.\nPositive case. Let D = (\u03be, In )+ .{D1 , . . . , Dn } be a positive daimon-free strategy which belongs to \u22a2 \u03a0, F\u03be . Let F\u03be = N1 \u2297 * * * \u2297 Nk . By Proposition 4.39, for any (E) \u2208 C, we\nhave that [[D, (E)]] \u2208 F\u03be , hence its root is (\u03be, Ik ). By definition of normalization, the root\nof [[D, (E)]] is still (\u03be, In ) (because it is a visible action), hence k = n.\nWe proceed as follows, using internal completeness.\n(1) Let C = [[D, (E)]]. By internal completeness of the tensor (Proposition 5.1), we have\nthat C can be written as C1 \u2022 * * * \u2022 Cn , for some Ci \u2208 \u22a2 Ni .\n(2) By linearity, observe that a name \u03b1 \u2208 {\u03b11 , . . . , \u03b1m } of the context \u03a0 = Q\u03b11 , . . . , Q\u03b1m\neither appears in one of the Di - and there is only one such a Di - or it does not\nappear at all. This allows us to univocally split the context \u03a0 into disjoint subsets as\nfollows. We define:\na. \u03a0i := {Q\u03b1 \u2208 \u03a0 : the name \u03b1 occurs in Di }, for 1 \u2264 i \u2264 n;\n\n\fLUDICS WITH REPETITIONS\n\n29\n\nS\nb. \u03a00 := \u03a0 \\ 1\u2264i\u2264n \u03a0i .\nLet us split (E) \u2208 C into (E)0 \u2208 C0 , (E)1 \u2208 C1 . . . , (E)n \u2208 Cn . By definition of\nnormalization we have:\nC = [[x+ .{D1 , . . . , Dn }, (E)]] = x+ .{[[D1 , (E)1 ]], . . . , [[Dn , (E)n ]]}\n= [[D1 , (E)1 ]] \u2022 * * * \u2022 [[Dn , (E)n ]]\n= C1 \u2022 * * * \u2022 Cn .\nFrom this, we conclude that [[D1 , (E)1 ]] \u2208 \u22a2 N1 , . . . , [[Dn , (E)n ]] \u2208 \u22a2 Nn . By applying\nProposition 4.39 again, we have that D1 \u2208 \u22a2 \u03a01 , N1 , . . . , Dn \u2208 \u22a2 \u03a0n , Nn . The size has\ndecreased for all sequents, and D1 , . . . , Dn are obviously all daimon-free. We can then apply\nthe inductive hypothesis and write the derivation:\n.. \u22c6\n.. \u22c6\n. D1\n. Dn\n\u22a2 \u03a0n , Nn\n\u22a2 \u03a01 , N1\n...\nPosn\n\u22a2 \u03a00 , \u03a01 . . . , \u03a0n , N1 \u2297 * * * \u2297 Nn\nNotice that in case F\u03be = 1 then D = (\u03be, \u2205)+ and the procedure above gives the rule\n\u22a2 \u03a00 , I\n\nPos0\n\nNegative case. The negative case is an immediate application of the internal completeness\nfor par (Proposition 5.3) and Proposition 4.39.\nLet D = x\u2212 .D \u2032 , and x = (\u03be, In ). Assume D \u2208 \u22a2 \u03a0, F\u03be and D daimon-free, where\nF\u03be = P1 `* * *`Pn is the interpretation of the formula P1 `* * *`Pn and \u03a0 is the interpretation\nof the context \u03a0 of a negative sequent \u22a2 \u03a0, P1 ` * * * ` Pn of MLLS.\nFor any family (E) \u2208 C, we have\n(1) [[D, (E)]] \u2208 P1 ` * * * ` Pn , and the root is still x\u2212 . This allows us to use internal\ncompleteness.\n(2) By internal completeness (Proposition 5.3), we conclude that [[D, (E)]] is of the form\nx\u2212 .D \u2032\u2032 with D \u2032\u2032 \u2208 \u22a2 P1 , . . . , Pn .\n(3) By the definition of normalization,\n[[D, (E)]] = [[x\u2212 .D \u2032 , (E)]] = x\u2212 .[[D \u2032 , (E)]].\nFrom this, we have that D \u2032\u2032 = [[D \u2032 , (E)]] and hence [[D \u2032 , (E)]] \u2208 \u22a2 P1 , . . . , Pn .\nBy applying Proposition 4.39 again, we have that D \u2032 \u2208 \u22a2 \u03a0, P\u03be1 , . . . , P\u03ben . By applying the\ninductive hypothesis, we can write the derivation:\n.. \u2032 \u22c6\n.D\n\u22a2 \u03a0, P1 , . . . , Pn ,\nNegn\n\u22a2 \u03a0, P1 ` * * * ` Pn\n\n\f30\n\nM. BASALDELLA AND C. FAGGIAN\n\n6. Ludics with repetitions: what, how, why\nIn the previous section, we assumed linearity of the strategies to prove internal completeness.\nFrom now on, we go back to the general definition of strategy (on an universal arena) as in\nthe beginning of Section 4, without any hypothesis of linearity. This means that strategies\nnow allow repeated actions.\nIn this section, we mainly discuss the difficulties in extending the approach of ludics to\nthis setting, and introduce our solution, which will be technically developed in Section 7.\nFirst, let us introduce some operations which we will use in this section to deal with\nrepeated actions and describe the composition.\n6.1. Copies and renaming.\nRenaming. Given a strategy D : \u03be of arbitrary polarity, let us indicate by D[\u03c3/\u03be] the\nstrategy obtained from D by renaming, in all occurrences of action, the prefix \u03be into \u03c3, i.e.,\neach name \u03be.\u03b1 becomes \u03c3.\u03b1. Obviously, if D : \u03be, then D[\u03c3/\u03be] : \u03c3.\nRenaming of the root. Given a positive strategy D : \u03be + , let us indicate by \u03c3(D) the strategy\nobtained by renaming the prefix \u03be into \u03c3 in the root, and in all actions which are hereditarily\njustified by the root. If D : \u03be + , we obtain a new strategy \u03c3(D) : \u03c3 + , \u03be + .\nWe picture both the operations in Figures 2(a) and (b). For readability, we indicate an\naction on \u03be simply with the name \u03be.\nCopies of a behaviour. We remind that to emphasize that A is a set of strategies on interface\n\u03be, we annotate the name \u03be as a subscript: A\u03be . If A\u03be is a set of strategies on the name \u03be,\nwe write A\u03c3 for {D[\u03c3/\u03be] : D \u2208 A\u03be }. A\u03c3 is a copy of A\u03be : they are equal up to renaming.\n6.2. Composition (normalization). In a strategy, actions can now be repeated. Composition of strategies as sets of views can be described via the VAM abstract machines\nintroduced in [11]. We describe composition in details in Section 8.\nWe now give an example of composition of strategies using the graphical notation\nintroduce before.\nHowever, what we will really need is only that composition has a fundamental property,\nexpressed by the following equation:\n(6.1)\n[[D, E]] = [[\u03c3(D), E, E[\u03c3/\u03be]]]\nfor any D :\nand E :\nsuch that the operations \"\u03c3( )\" and \"[\u03c3/\u03be]\" make sense. This\nproperty will also hold for strategies with silent actions we introduce later. The proof for a\nmore general equation is given in Section 8 (Proposition 8.15).\n\u03be+\n\n\u03be\u2212\n\nRemark 6.1. Equation 6.1 is reminiscent of the separation of head occurrence property\nof [2] and the linearization of the head occurrence property of [1] (see also the discussion\ntherein).\nFrom Equation (6.1), we have in particular:\nCorollary 6.2. D\u22a5E if and only if \u03c3(D)\u22a5{E, E[\u03c3/\u03be]}.\n\n\fLUDICS WITH REPETITIONS\n\n31\n\n(a)\n\n\u03bel\u2212\n\n\u03bek \u2212\n\n\u03c3l\u2212\n\n\u03c3k\u2212\n\n\u03be+\n\n\u03be+\n\n\u03c3+\n\n\u03c3+\n\n\u03bei\u2212\n\n\u03c3i\u2212\n\n\u03be+\n\n\u03c3+\n\nD : \u03be+\n\nD[\u03c3/\u03be] : \u03c3 +\n\n(b)\n\n\u03bel\u2212\n\n\u03bek \u2212\n\n\u03bel\u2212\n\n\u03bek\u2212\n\n\u03be+\n\n\u03be+\n\n\u03be+\n\n\u03be+\n\n\u03bei\u2212\n\n\u03c3i\u2212\n\n\u03be+\n\n\u03c3+\n\nD : \u03be+\n\n\u03c3(D) : \u03c3 + , \u03be +\n\nFigure 2: Renaming (a) and renaming of the root (b)\nLet us see how Equation (6.1) works by giving a description of the composition.\nLet D : \u03be + and E : \u03be \u2212 be two strategies, which we represent in Figure 3 (a) (again, we\nindicate an action x on \u03be simply with the name \u03be). The idea behind the abstract machine\nin [11] is that, when the two strategies D and E interact, every time D plays an action x on\n\u03be, a copy of E is created; i.e., composition works as if we had a copy of E for each occurrence\nof x in D. It is rather intuitive that the result of normalization is the same if we make this\nexplicit, by renaming one occurrence of x (namely the root), and making an explicit copy\nof E, as illustrated in Figure 3 (b).\nExample 6.3. Let us consider the strategies D and E in Figure 4, where we indicate an\naction x on \u03be simply with the name \u03be. Observe that we explicitly need to draw a pointer\nfrom \u03be11+ to the right occurrence of \u03be1\u2212 (the lowermost one in our case) which justifies it.\nThe other pointers can be univocally determined. The interaction is the sequence given by\nfollowing the arrows and the normal form is Dai.\n\n\f32\n\nM. BASALDELLA AND C. FAGGIAN\n\n(a)\n\u03bel\u2212\n\n\u03bek \u2212\n\n\u03be+\n\n\u03be+\n\u03bei\u2212\n\u03be+\n\n\u03be\u2212\n\nD : \u03be+\n\nE : \u03be\u2212\n\n(b)\n\u03bel\u2212\n\n\u03bek\u2212\n\n\u03be+\n\n\u03be+\n\u03c3i\u2212\n\u03c3+\n\n\u03be\u2212\n\n\u03c3\u2212\n\n\u03c3(D) : \u03c3 + , \u03be +\n\nE : \u03be\u2212\n\nE[\u03c3/\u03be] : \u03c3 \u2212\n\nFigure 3: Composition (with repeated actions)\nExample 6.4. We now check for D, E in Example 6.3 that [[D, E]] = [[\u03c3(D), E, E[\u03c3/\u03be]]] as\npictured in Figure 5. Since \u03c3(D) is linear in this example, we no longer need to show the\npointers explicitly.\n6.3. What are the difficulties. We are ready to discuss which are the difficulties in\nextending the approach of ludics to a setting where strategies are non-linear.\nProblem 1: Separation. The first problem when strategies have repetitions is with separation. Let us give a simple example of why separation fails if we allow repetitions.\nExample 6.5 ([32]). Let D1 , D2 : \u03be + and E : \u03be \u2212 be strategies as in Figure 6, where\nx = (\u03be, I), y = (\u03bei, J). We cannot find a strategy orthogonal to D1 but not orthogonal\nto D2 . For example, the interactions between D1 and E and D2 and E produce the same\nnormal form Dai.\n\n\fLUDICS WITH REPETITIONS\n\n\u03be11+\n\n33\n\n9\n\n8\n\n\u03be1\u2212\n\n\u2020\n7\n\n\u03be+\n\n10\n\n\u03be11\u2212\n\n3\n\n4\n5\n\n\u03be1\u2212\n\n\u03be1+\n2,6\n\n\u03be+\n\nD\n\n\u03be\u2212\n\nE\n\n1\n\nFigure 4: Example of interaction with repetitions\n\n\u03c311+\n8\n\n\u2020\n\n9\n\n\u03be1\u2212\n\n10\n\n\u2020\n7\n\n\u03be+\n\n\u03c311\u2212\n3\n\n\u03c31+\n\n\u03be11\u2212\n\n4\n\n\u03c31\u2212\n\n5\n\n\u03be1+\n\n2\n\n6\n\nE[\u03c3/\u03be] \u03c3 \u2212\n\n\u03c3+\n1\n\n\u03be\u2212\n\nE\n\n\u03c3(D)\n\nFigure 5: Example of interaction with copies\nIn this work, we ignore separation all together. As we discussed in Section 5, even if\nseparation is an important property, we don't need it in order to have interactive types\nand internal completeness. In future work, it may be possible to refine our setting using\nMaurel's techniques [32].\n\n\f34\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u2020\n8\n\ny\u2212\n\n3\n\n4\n\n7\n\nx+\n\n\u2020\ny\u2212\n\n3\n\n4\n\ny+\n\ny\u2212\n\n5\n\ny+\n2,6\n\n2\n\nx+\n\nx\u2212\n\nx+\n\nE\n\nD2\n\n1\n\nx\u2212\n1\n\nD1\n\nE\n\nFigure 6: Non-separation\nProblem 2: Enough tests (counter-strategies). The second problem - which we believe being the deeper one- has to do with having enough tests, i.e., enough counter-strategies.\nAs in [22], we have defined an interactive type to be any set of strategies closed by\nbiorthogonal. Assume we have defined how to interpret formulas of MELLS, like P =\n?P (N1 \u2297 * * * \u2297 Nn ) and P \u22a5 = !N (N1\u22a5 ` * * * ` Nn\u22a5 ).\nWe would like to associate to each \"good\" strategy in the interpretation of a formula,\nsay the positive formula P above, in a behaviour that we indicate with P, a syntactical\nproof of \u22a2 P (full completeness). If D : \u03be + \u2208 P, we would like to transform it into a\nstrategy D \u2032 \u2208 \u22a2 P\u03be , P\u03c3 (where distinct names indicate distinct copies). This corresponds\nto the contraction rule (in its upwards reading).\nThe natural idea is to use the same technique as in [2], and to rename the root, and all\nthe actions which are hereditarily justified by it. We have already illustrated this operation\nin Section 6.1 (Figure 2). From D : \u03be + , we obtain a new strategy D \u2032 : \u03be + , \u03c3 + , where\nD \u2032 = \u03c3(D).\nWe would like to prove that:\n(\u2217) D \u2208 \u22a2 P\u03be\n\n\u21d2 (\u2217\u2217) \u03c3(D) \u2208 \u22a2 P\u03be , P\u03c3 .\n\nTo have (\u2217\u2217), we need (see Definition 10.5) to know that \u03c3(D)\u22a5{E, F} for each E \u2208 P\u22a5\n\u03be and\n\u22a5 is a copy (renamed in \u03c3) of P\u22a5 , we can also write this condition as\neach F \u2208 P\u22a5\n.\nSince\nP\n\u03c3\n\u03c3\n\u03be\n\u03c3(D)\u22a5{E, F[\u03c3/\u03be]},\nP\u22a5\n\u03be .\n\n(6.2)\n\nwhere both F and E vary in\nHowever, from Equation (6.1) we only have that \u03c3(D)\u22a5{E, E[\u03c3/\u03be]}: two copies of the\nsame (up to renaming) strategy E. This fact can be rephrased by saying that in our \"HO\nsetting\", strategies in the type P\u22a5 , which is, roughly speaking, \"of the form !N C\" are\nuniform: every time we find a repeated action in P, Opponent P\u22a5 reacts in the same way.\n\n\fLUDICS WITH REPETITIONS\n\n35\n\n6.4. A solution: non-uniform tests. The need for having enough tests appears similar\nto the one which has led Girard to the introduction of the daimon rule: in ludics, one\ntypically opposes to an abstract \"proof of A\" an abstract \"counter-proof of A.\" To have\nenough tests (that is, to have both proofs of A and proofs of A\u22a5 ) there is a new rule which\nallow us to justify any premise.\nSimilarly here, when we oppose to a proof of P a proof of P\u22a5 , we need enough counterstrategies. We are led to enlarge the universe of tests by introducing non-uniform counterstrategies. This is extremely natural to realize in an AJM setting [2, 4], where a strategy\nof type \"!N C\" is a sort of infinite tensor of strategies on \"C\", each one with its index of\ncopy. To have HO non-uniform counter-strategies, we introduce a non-deterministic sum of\nstrategies. Let us illustrate the idea, which we will formalize in the next section.\nNon-uniform counter-strategies. The idea is to allow a kind of \"non-deterministic sum\" of\nnegative strategies E, F. Let us, for now, informally write such a sum of E and F in the\nfollowing way, which is reminiscent of non-deterministic sum in \u03c0-calculus, where the two\npossible (non-deterministic) choices are prefixed by \u03c4 actions:\n\u03c4.E + \u03c4.F\n\u2022 During the composition with other strategies, we might have to use several times this\nstrategy, hence \"entering\" it several times. Every time is presented with this choice,\nnormalization will non-deterministically choose one of the two possible continuations.\nThe choice could be different at each repetition.\n\u2022 To define orthogonality, we essentially set:\nD\u22a5(\u03c4.E + \u03c4.F) if and only if [[D, \u03c4.E + \u03c4.F]] is total for each possible choice\namong the \u03c4 's.\nIt is immediate that:\nD\u22a5(\u03c4.E + \u03c4.F) \u21d2 D\u22a5E and D\u22a5F.\n\n(6.3)\n\nAs we will see, if E \u2208 G and F \u2208 G for G interpreting a formula of MELLS, we have that\n(\u03c4.E + \u03c4.F) \u2208 G, and vice-versa. Hence:\n\u2022 if D \u2208 P, for each E, F \u2208 P\u22a5 we have D\u22a5(\u03c4.E + \u03c4.F).\n\u2022 By using Equation (6.1) we have that \u03c3(D)\u22a5{(\u03c4.E + \u03c4.F), (\u03c4.E + \u03c4.F)[\u03c3/\u03be]}.\n\u2022 By using Equation (6.3), we deduce that \u03c3(D)\u22a5{E, F[\u03c3/\u03be]}, as we wanted.\nLinearity of the root. Observe that by construction, in \u03c3(D) the action at the root is positive\nand it is the only action on the name \u03c3. We can hence apply the same argument we have\nalready given in Section 5.1 for the internal completeness of tensor.\nAs a consequence, if P = ?P (N1 \u2297 N2 ), given a \"good\" strategy D \u2208 P\u03be , we have that\n\u03c3(D) actually belongs to \u22a2P\u03c3 , P\u03be and (\u03c3, {1, 2})+ occurs linearly in \u03c3(D) (only at the root).\nHence, \u03c3(D) can be decomposed in strategies \u03c3(D)1 \u2208 \u22a2 P\u03be , N\u03c31 and \u03c3(D)2 \u2208 \u22a2 P\u03be , N\u03c32 .\nThis allows us to associate to D \u2208 \u22a2\u03a0, P a proof which essentially has this form:\n..\n.\n\n..\n.\n\n\u22a2 \u03a0, ?P (N1 \u2297 N2 ), N2\n\u22a2 \u03a0, ?P (N1 \u2297 N2 ), N1\n\u2297 + contractions\n\u22a2 \u03a0, ?P (N1 \u2297 N2 ), N1 \u2297 N2\ndereliction + contraction\n\u22a2 \u03a0, ?P (N1 \u2297 N2 )\n\n\f36\n\nM. BASALDELLA AND C. FAGGIAN\n\n7. Ludics with repetitions: non-uniform strategies\nIn this section we technically implement the ideas which we have presented in Section 6.4.\nIn particular, we revise the definition of universal arena and strategy so to accommodate\nactions which corresponds to the \u03c4 actions we have informally introduced, and a notion\nof strategy which correspond to the \u03c4 -sum. In this section we use ideas which have been\ndeveloped to bridge between ludics and concurrency in [16], but here we choose a more\nstandard presentation.\nThe silent arena. We extend the set of actions with a set M\u03c4 = {t} \u222a {ti : i \u2208 N} of actions\nwhich we call silent. We define the arena A\u03c4 = (M\u03c4 , \u22a2, \u03bb) as follows.\n\u2022 the set of moves is M\u03c4 ;\n\u2022 the polarity is \u03bb(t) = +, \u03bb(ti ) = \u2212;\n\u2022 t \u22a2 ti , for each i.\nWe can represent A\u03c4 as follows:\nt\u2212\n0\n\n...\n\nt\u2212\nn\n\n...\n\nt+\nDefinition 7.1 (Universal arena on an interface). Let A(\u03be, \u01eb) and A\u2020 be as in Definition 4.1.\nWe extend the construction of universal arena on an interface (Definition 4.3) as follows.\nLet \u03a0 = \u03be1 , . . . , \u03ben be a (possibly empty) positive interface.\nThe extended universal arena on the interface \u03a0 is the arena\nU \u2217 (\u03a0) := A(\u03be1 , +) k * * * k A(\u03ben , +) k A\u2020 k A\u03c4 .\nThe universal arena on a (negative) interface {\u03c3 \u2212 } \u222a \u03a0 is the arena\nU \u2217 (\u0393) := A(\u03c3, \u2212) \u25ed U \u2217 (\u03a0).\nThe silent actions play a role similar to that of \u2020 in Definition 4.6. The actions in both\nA\u2020 and A\u03c4 are \"special actions\" which are not localized on a name. Observe that even when\nthe interface is empty, the universal arena still contains A\u2020 k A\u03c4 .\nNon uniform strategies. As one may expected, we are now going to take strategies on U \u2217 (\u0393).\nWe reformulate the definition of strategy,\nDefinition 7.2 (Non-uniform strategies). Let \u0393 be an interface. A non-uniform strategy\n(n.u. strategy for short) D on \u0393, written D : \u0393, is a prefix-closed set of non-empty views\n(as in Definition 3.3) on the arena U \u2217 (\u0393) , such that:\n(1) Coherence. If s.m, s.n \u2208 D and m 6= n then m, n are negative.\n(2) \u03c4 -Positivity. If s.m is maximal in D (i.e., no other view extends it), and m is a proper\naction (i.e., and action on a name), then m is positive.\nWe will call deterministic a n.u. strategy which has no silent actions. (Observe that in\nsuch a case the only special action is \u2020, and the definition coincides with the usual one, as\nin Definition 4.6.)\n\n\fLUDICS WITH REPETITIONS\n\n37\n\nThe new Positivity condition says that if a maximal view terminates with a proper\naction, that action must be positive. However, a maximal view may terminate with a\nsilent action ti (negative). This is necessary to our construction, and more precisely to the\ndefinition of orthogonality (see Section 9 and Example 9.3).\nRemark 7.3. Definition 7.2 makes explicit the difference in role between proper actions\nand \"special\" actions, those in A\u2020 \u222a A\u03c4 . This will be apparent in normalization. Since\ncommunication propagates along the names, the interaction between strategies only takes\nplace on the proper actions. The \u2020 and the silent actions are never internal - as they have\nno names. But they have a fundamental role in the definition of orthogonality.\nAs a notational convention, from now on, by strategy we always mean n.u. strategy,\notherwise we specify \"deterministic\" strategy.\nNotation \u03c4i . In the pictures, we will write \u03c4i for the segment of sequence t.ti ; this to convey\nthe intuition that a pair t.ti represent a \"\u03c4 -action.\"\nExample 7.4. The following is an example of non-uniform strategy:\n\u2020\n\u03c41\n\n\u03c42\n\n\u2020\n\nc+\n\nz1\u2212\n\nz2\u2212\n\ny1\u2212\n\n\u2020\n\nz+\n\ny+\n\n\u03c41\n\n\u03c42\n\n\u03c41\n\n\u03c42\nx\u2212\n\nSum of strategies. We use non-uniform strategies to capture the idea of \"non-uniform\" tests.\nAs anticipated in Section 6.4, a non-uniform strategies can be seen as a non-deterministic\nsum of \"standard\" strategies.\nDefinition 7.5 (\u03c4 -sum). Given a family of strategies on the same interface (and hence all\nwith the same polarity), we define their sum. Let S be a non-empty subset of N.\n\u2022 If {Di : \u03a0}i\u2208S is a family of positive strategies, we define their positive sum:\n[\nM\u03c4\nDi :=\n{t+ .t\u2212\ni .Di }.\ni\u2208S\n\ni\u2208S\n\nWhen S is a finite set, say {1, . . . , k}, we write D1 \u2295\u03c4 * * * \u2295\u03c4 Dk .\n\u2022 If {x\u2212 .Di : \u0393}i\u2208S is a family of negative strategies which have the same root x\u2212 , we define\ntheir negative sum:\nM\u03c4\nX\u03c4\nDi .\nx\u2212 .Di := x\u2212 .\ni\u2208S\n\ni\u2208S\n\nIn the finite case, we also write x\u2212 .D1 +\u03c4 * * * +\u03c4 x\u2212 .Dk .\n\n\f38\n\nM. BASALDELLA AND C. FAGGIAN\n\nThe following is easy to check.\nProposition 7.6. Let DL\nand Fi a family of negative\ni be a family of positive strategies,P\nstrategies. We have that \u03c4i\u2208S Di is a positive strategy, and \u03c4i\u2208S Fi is a negative strategy\n(in the sense of Definition 7.2).\nA \u03c4 -sum of strategies can be seen as a superposition of strategies in a way that they do\nnot overlap.\nTotality. Roughly speaking, a non-uniform strategy is total if it is not Fid, but also not\nobtained via \u03c4 -sum with Fid. Precisely:\nDefinition 7.7 (Totality, non-uniform strategies). A strategy D is total if D 6= Fid and for\neach s \u2208 D, there are pointing sequences p and q such that:\np.a.q \u2208 D, s \u2291 p.a.q and a 6\u2208 A\u03c4 .\nIn words, each path from the root\nL of D has to take to at least an action which is not silent.\nSo for example, Fid \u2295\u03c4 Fid or \u03c41 Fid are partial strategies, as well as D \u2295\u03c4 Fid, whatever\npositive strategy is D. Notice also that any negative strategy is total, since it is either\nempty - and we have already discussed the reason of its totality in Section 4.1.1 - or it\nis not empty and each root is by definition a negative proper action (non-silent, because\nnegative silent actions are never initial).\nAs in the linear case, in an untyped setting, partial strategies emerge naturally in case\nof unsuccessful interaction. In fact, they have a key role in the definition of orthogonality.\nBefore discussing orthogonality and behaviours in the case of non-uniform strategies, we\nfirst make precise the definition of normalization.\nStrategies on the empty interface. In the linear case, a strategy on the empty interface is\na strategy on A\u2020 , hence, as we have already seen, there are only two possibilities: Dai or\nFid. The introduction of silent actions give more possibilities; a non-uniform strategy on\nthe empty interface is a non-uniform strategy on the arena A\u2020 \u222a A\u03c4 . Beside Dai or Fid,\nthere are other strategies, those which have as root t+ \u2208 A\u03c4 . Each view can then contain\nseveral repetitions of silent actions, and terminate or not with a \u2020 action.\n8. Strategies with repetitions: normalization via the VAM abstract\nmachine\nThe basic notions we use in this section (cut-net, visible action, . . . ) are exactly the same\nas defined in Section 4.2.\nComposition of strategies in our setting works accordingly to the standard paradigm of\n\"parallel composition plus hiding.\"\n(1) Given a cut-net R, we calculate the set of its interaction I(R) (this is the parallel\ncomposition), which is a set of pointing strings, calculated via an abstract machine, the\nVAM [11].\n(2) From the interactions I(R), we obtain the strategy which corresponds to the normal\nform [[R]] (Definition 8.9) by hiding the internal communication.\n\n\fLUDICS WITH REPETITIONS\n\n39\n\nSince we allow for the repetition of actions, there might be several occurrence of the same\naction a in a strategy. To define the VAM, we need the following notion.\nDefinition 8.1 (View extraction). Let s = x1 . . . xn be a pointing string of actions. We\ndefine the view of s denoted by psq as follows:\n\u2022 psq := s if s is empty;\n\u2022 ps.x+ q := psq.x+ (x is positive);\n\u2022 ps.x\u2212 q = x\u2212 , if x is initial (i.e., it does not point to any previous action).\n\u2022 ps.x\u2212 q := pqq.x\u2212 if s = q.r.x and x points to the last action of q.\nGiven a pointing string of actions s = x1 . . . xn we obtain a subsequence psq = xk1 . . . xkm ,\nwhere 1 \u2264 k1 < * * * < km \u2264 n. We say that the element at position j in psq (1 \u2264 j \u2264 m)\ncorresponds to the element at position kj in s (1 \u2264 kj \u2264 n). We will use this in the\nfollowing.\nAs for the pointers, the operation p q is pointer preserving in the sense that if xky , xkz\nin psq respectively correspond to xi , xj in s, and xj points to xi in s, then xkz points to xky\nin psq.\nIn words, we trace back from the end of s: (i) following the pointers of negative actions\nof s and erasing all actions under such pointers, (ii) bypassing positive actions, (iii) stopping\nthe process when we reach an initial negative action. 4\nExample 8.2. Given s = x1 .x2 . . . x6 and t = y1 .y2 . . . y5 as follows:\n+\ns = a + a \u2212 b+ b\u2212\n0 a0\n\na\u2212\n0\n\n+\nt = a + a \u2212 b+ b\u2212\n0 a0\n\nwe get psq = x1 .x6 and ptq = y2 .y3 .y4 .y5 :\npsq = a+ a\u2212\n0\n\n+\nptq = a\u2212 b+ b\u2212\n0 a0\n\nWe will also rely on the following Lemma.\nLemma 8.3. Let R = {D1 , . . . , Dn } be a cut-net. The following properties hold:\n\u01eb\n(1) Given an address\nS \u03be, and a polarity \u01eb, \u03be occurs in at most one of the interfaces.\n(2) Each view s \u2208 {Di : 1 \u2264 i \u2264 n} belongs exactly to one Di .\n\nProof.\n(1) By definition of cut-net (Definition 4.11).\n(2) The first action x in the view s is enough to determine to which Di it belongs. If x is\na proper action (\u03be, I)\u01eb , the conclusion is immediate from the previous point (x belongs\nto the same strategy to which \u03be \u01eb belongs). If x is in A\u2020 \u222a A\u03c4 , the interface must be\npositive; we already observed that a cut-net contains at most one positive interface.\n\n4In general, the procedure of view extraction may delete some pointers. This will never happen for the\npointing strings we consider in this paper.\n\n\f40\n\nM. BASALDELLA AND C. FAGGIAN\n\n8.1. VAM (View-Abstract-Machine). Let us first informally explain how the abstract\nmachine calculates the interaction of a cut-net R. The machine visits actions of the strategies in R and collects the sequences of visited actions, proceeding as follows:\n\u2022 We start on the roots of the main strategy of a cut-net R.\n\u2022 If we visit a visible action a occurring in some D \u2208 R, we continue to explore the current\nstrategy D. The process branches when a is a branching node of D.\n\u2022 If we visit an internal action a+ occurring in D we match it with its opposite a\u2212 occurring\nin E \u2208 R, then we continue to collect actions in E (this is a jump of the machine).\nSince there could be several occurrences of a\u2212 in E, we use p q to determine the correct\noccurrence of action to which we have to move.\n\u2022 We may eventually stop when either we reach a maximal action or an internal action\nwhich has no match.\nWe now give the formal definition of the VAM. The definition below is a reformulation of\nthe machine defined in [11].\nDefinition 8.4 (VAM). Let R = {D1 , . . . , Dn } be a cut-net. V AM (R) is the set of pointing\nstrings defined as follows. The construction preserves the following invariant:\n(*)\n\nif p \u2208 V AM (R) then ppq is a view which belongs to one of the D \u2208 R.\n\n(1) (Initialization) If the main strategy of R is empty, we set V AM (R) := \u2205. Otherwise,\nfor each a root of the main strategy, a \u2208 V AM (R).\n(2) Let p = x1 . . . xn \u2208 V AM (R). We have the following two cases.\n(a) (Continuation)\nThe action xn is either a negative action or a positive visible action. We\nconsider ppq. There exists a unique strategy D \u2208 R such that ppq \u2208 D (because of\nthe invariant (*) and Lemma 8.3). For each action a which extends ppq in D (i.e.,\nsuch that ppq.a \u2208 D) we set p.a \u2208 V AM (R) where the pointer for a is given by the\nequation pp.aq = ppq.a.\n(b) (Jump) The action xn = a+ is an internal positive action. We consider the\nsequence p.a\u2212 obtained by adding the action a\u2212 to p and possibly a pointer as\nfollows. If xn = (\u03bei, J)+ points to xi = (\u03be, I)\u2212 we add a pointer from a\u2212 to xi\u22121 in p.\nIf there is D \u2208 R such that pp.a\u2212 q \u2208 D, we set p.a\u2212 \u2208 V AM (R). That occurrence\nof a\u2212 is the match of a+ .\nRemark 8.5 (The pointers in case (2)). In the case (2)(a), the equation pp.aq = ppq.a\nsummarizes the following conditions.\n\u2022 Assume a is negative. a must point to xn .\n\u2022 Assume a is positive. Let ppq = xk1 . . . xkm , where each xkj corresponds to en element xi\nin p. If in the view ppq.a \u2208 D we have that a points to xkj , in p.a, we have that a points\nto the corresponding element.\nIn the case (2)(b), we have the following distinct situations.\n\u2022 If xn = (\u03bei, J)+ points to xi = (\u03be, I)\u2212 , then i > 1, because if xi is a negative hidden action\nand by definition of cut-net it cannot be a root of the main strategy of R. (Moreover, it\nis easily seen that xi\u22121 = (\u03be, I)+ so that xi has been introduced by a Jump case.)\n\u2022 If xn = (\u03be, J)+ points to a negative action xi = (\u03c3, K)\u2212 with \u03c3 and \u03be disjoint, it means\nthat both occurrences of actions belongs to the same strategy D \u2208 R of interface \u03c3 \u2212 , \u03be + , \u03a0.\n\n\fLUDICS WITH REPETITIONS\n\n41\n\nWe do not need to add any pointer, because the match for xn (if any) must be a root of\na strategy E : \u03be \u2212 , \u03a0\u2032 of R.\n\u2022 Last, if xn = (\u03be, J)+ does not point to any action, then xn occurs in a strategy D \u2208 R of\ninterface \u03be + , \u03a0. Again, we do not need to add any pointer, because the match for xn (if\nany) must be a root of a strategy E : \u03be \u2212 , \u03a0\u2032 of R.\nRemark 8.6. Observe that the interface \u0393 of the cut-net R is negative if and only if the\nmain strategy is negative. In such a case, the first action in each p \u2208 V AM (R) is a root a\u2212\nof the main strategy. Such an action is visible, and never occurs again in p.\n8.2. Normal form.\nDefinition 8.7 (Hiding). Given a cut-net R, and p = x1 . . . xn \u2208 V AM (R), we define\nhide(p) as the pointing string obtained as follows:\n(1) If x1 = a\u2212 is negative (see the remark above), the pointers are updated as follows: for\neach c+ visible action pointing to an internal action b\u2212 , we make c+ point to x1 .\n(2) We hide all the internal actions.\nAll pointers between actions which are visible are preserved, i.e., if p = x1 . . . . .xn and\nxi points to xj (1 \u2264 j < i \u2264 n) in p, and both xi , xj are visible, then in hide(p) the\naction (which corresponds to) xi still points to the action (which corresponds to) xj .\nWhat remains after hiding is the subsequence of visible actions of p, written hide(p), with\nthe inherited pointer structure. If X \u2286 V AM (R), we will also write hide(X) for the set\n{hide(p) : p \u2208 X}.\nRemark 8.8. Observe that after step (1) of hiding, each visible action in p either does\nnot point to any previous action (but only because it is initial in the arena induced by\nthe interface of the cut-net) or it points to a visible action. The latter point deserves\nsome explanations. If an action c+ is visible and points to an internal action (say b\u2212 ), it\nmeans that both b\u2212 and c+ belong to the same strategy D : \u03be \u2212 , \u03a0. Moreover, by definition of\ninternal action and of the universal arena U \u2217 (\u03be \u2212 , \u03a0), the action b\u2212 must be an action (\u03be, I)\u2212 ,\ninitial in A(\u03be \u2212 ), the action c+ must be initial in U \u2217 (\u03a0), and the pointer form c+ to b\u2212 must\ncorrespond to the enabling b\u2212 \u22a2 c+ introduced by the construction A(\u03be, \u2212) \u25ed U \u2217 (\u03a0).\nBy using the V AM machine, we are now going to define the set I(R) of the interactions\nof a cut-net R, and from this its normal form [[R]].\nDefinition 8.9 (Normal form). Let R be a cut-net. We define the set I(R) of the interactions of R as the closure under non-empty prefix of\n{q.c \u2208 V AM (R) : c is visible and not a proper negative action }.\nThe normal form of R, denoted by [[R]] is defined as\n[[R]] = {hide(p) : p \u2208 I(R) and hide(p) non-empty}.\nObserve that since V AM (R) is closed by non-empty prefix, we have that I(R) \u2286 V AM (R).\nThe normal form of a cut-net is a strategy. We show this fact in Proposition 8.12.\nLemma 8.10. If p.m, p.n \u2208 V AM (R) and m 6= n, then m, n are negative and visible.\n\n\f42\n\nM. BASALDELLA AND C. FAGGIAN\n\nProof. First of all, we observe that the polarity of m and n is the same. Assume m, n are\npositive. If p is empty, then m, n are both roots of the main strategy (Case (1) in the VAM).\nBy Coherence condition (Definition 7.2), we have that m = n. The case of p non-empty is\nsimilar, with m, n which extend ppq (Case (2)(a) in the VAM).\nWe have established that if m 6= n, then m, n are negative. They must also be visible,\nbecause the only way to extend p with a negative, internal action is Case (2)(b). However,\nin such a case since the extension of ppq is uniquely given by the construction, we would\nhave that m = n.\nCorollary 8.11. Let p, q \u2208 V AM (R). If hide(p) = hide(q) then p \u2291 q or q \u2291 p.\nProof. Assume that neither p \u2291 q nor q \u2291 p hold, and let s be the longest common prefix of\np and q, i.e., s.a \u2291 p, s.b \u2291 q, and a 6= b. By Proposition 8.10, a, b are negative and visible,\nhence hide(s.a) 6= nide(s.b) which contradicts the fact that hide(p) = hide(q).\nProposition 8.12. If R is a cut-net of interface \u0393, then [[R]] is a strategy on \u0393.\nProof. We show the following:\n(1) if p \u2208 V AM (p), then hide(p) is a view (on the arena U \u2217 (\u0393));\n(2) the set hide(V AM (R)) satisfies the Coherence condition (as given in Definition 7.2);\n(3) I(R) and [[R]] satisfy \u03c4 -Positivity (as given in Definition 7.2).\n(1) a. hide(p) is a justified sequence (on the appropriate arena). It is immediate to\ncheck that the pointers in hide(p) satisfy the justification condition, as this fact is\ninherited from the same property of the strategies which take part in the construction\nof p. The only delicate aspect are the pointers in the case where the interface of\nR is negative, i.e., \u0393 = \u03c3 \u2212 , \u03a0. More precisely, the pointers which in the arena\nU \u2217 (\u03c3 \u2212 , \u03a0) = A(\u03c3, \u2212) \u25ed U \u2217 (\u03a0) correspond to the enabling a \u22a2 c, with a initial in\nA(\u03c3, \u2212) and c initial in U \u2217 (\u03a0). However, this situation is taken care by step (1) in\nthe hiding (the updating of the pointers, see Remark 8.8).\nb. hide(p) is alternating. First of all, we observe that if p \u2208 V AM (R), then p is\nalternating (by construction). As a consequence, hide(p) is also alternating, because\nall occurrences of internal actions appear (and are deleted) as pairs p = p\u2032 .a+ .a\u2212 .p\u2032\u2032 ,\nor they occur in the very last position.\nc. hide(p) is a view. Each visible negative action in p is either initial (Case (1)), or\npoints to its immediate predecessor (Case (2)(a)).\n(2) Assume s.m 6= s.n. We have that s.m = hide(p.m), s.n = hide(q.n) and hide(p) =\nhide(q) = s. Using Corollary 8.11, let assume p \u2291 q. Let us consider p.x \u2291 q.n. By\nLemma 8.10, we have that if m 6= x, then m, x are negative. The execution of the VAM\nintroduces both p.m and p.x by checking how ppq is extended in R. Since m is visible,\nx must be as well. From this we deduce that x = n and then that p = q. Hence, m, n\nare negative, by Lemma 8.10.\n(3) We first observe that the \u03c4 -Positivity condition holds in I(R). Assume that p = q.c \u2208\nI(R) and has no extensions in I(R); then c is not a proper negative action. Moreover,\nfrom the fact that c is visible, it follows that [[R]] satisfies \u03c4 -Positivity.\nLike for the strategies in [22], our strategies are a variant of abstract B\u00f6hm trees (see [9,\n32] for a description of ludics strategies in terms of B\u00f6hm trees). Abstract B\u00f6hm trees\nnormalize via the VAM abstract machine [8, 11], which we have described in this section; a\nfundamental property that normalization satisfies is associativity.\n\n\fLUDICS WITH REPETITIONS\n\n43\n\nTheorem 8.13 (Associativity). Let R be a cut-net which can be partitioned into cut-nets\nR = R1 , . . . , Rn . We have:\n[[R]] = [[[[R1 ]], . . . , [[Rn ]]]]\nWe omit the formal proof of this fact, which is established in [8, 11]. We must observe that\nin our setting, the only essential difference (w.r.t. abstract B\u00f6hm trees) are the conditions\non the polarity of the maximal actions, but this is irrelevant to establish associativity.\n8.3. Renamings and normalization. We now state a property which relates renamings\n(in the sense of Section 6.1) and normalization. We first generalize the renaming operator\ndefined in Section 6.1. We now allow simultaneous renamings in arbitrary interfaces.\n\u01ebk+1\n, . . . , \u03b1\u01ebnn } be an interface, \u2206 = {\u03b1\u01eb11 , . . . , \u03b1\u01ebkk } and \u2206\u2032 =\nLet \u0393 = {\u03b1\u01eb11 , . . . , \u03b1\u01ebkk , \u03b1k+1\n\u01ebk+1\n, . . . , \u03b1\u01ebnn } forms an interface.\n\u03b21 , . . . , \u03b2k names such that \u0393\u2032 := {\u03b21\u01eb1 , . . . , \u03b2k\u01ebk } \u222a {\u03b1k+1\n\u2032\nLet D be a strategy on \u0393. By D[\u2206 /\u2206] we denote the strategy on interface \u0393\u2032 obtained\nfrom D by renaming, in all occurrences of action, the prefix \u03b1l into \u03b2l for any 1 \u2264 l \u2264 k.\nWe observe that D[\u2206\u2032 /\u2206] is indeed a strategy (in the sense of Definition 7.2) because:\n(1) we explicitly request that \u0393\u2032 forms an interface;\n(2) the conditions of being a strategy are inherited from D, since the operation of renaming\npreserves the polarity of the actions, their nature (proper, silent, . . . ), and the pointer\nstructure of the strategy (our operation acts only on names of proper actions, all the\nexisting pointers are preserved).\nThe main property we need in the sequel is following one. Let us consider the following\ndata:\n\u2022 D : \u0393, \u03be + , \u03c3 + ;\n+\n\u2022 E : \u03be \u2212 , \u2206, where \u2206 = \u03b1+\n1 , . . . , \u03b1k ;\n\u2032\n\u2212\n\u2032\n\u2032\n\u2022 E[\u03c3/\u03be, \u2206 /\u2206] : \u03c3 , \u2206 , where \u2206 = \u03b21+ , . . . , \u03b2k+ (an \"isomorphic\" copy of E);\n\u2022 D[\u03be/\u03c3] : \u0393, \u03be + ;\n\u2022 (Fj ) = F1 , . . . , Fn a list of strategies.\nLet us assume that R := {D, E, E[\u03c3/\u03be, \u2206\u2032 /\u2206], (Fj )} forms a cut-net of interface \u039b, \u2206, \u2206\u2032 ,\nwhere names in \u039b comes from \u0393 and the names of the interfaces of (Fj ), so that R\u2032 :=\n{D[\u03be/\u03c3], E, (Fj )} is a cut-net on interface \u039b, \u2206. We have:\nProposition 8.14.\n[[D, E, E[\u03c3/\u03be, \u2206\u2032 /\u2206], (Fj )]] [\u2206/\u2206\u2032 ] = [[D[\u03be/\u03c3], E, (Fj )]].\nProof. (Sketch.) By reasoning on the names of the interfaces, we can easily deduce:\n\u2022 The names in \u2206 and \u2206\u2032 (resp. \u2206) are not cuts in R (resp. R\u2032 ).\n\u2022 D (resp. Fj ) is the main strategy of R if and only if D[\u03be/\u03c3] (resp. Fj ) is the main strategy\nof R\u2032 .\n\u2022 Neither E nor E[\u03c3/\u03be, \u2206\u2032 /\u2206] (resp. E) is the main strategy of R (resp. R\u2032 ).\nIf we normalize R and R\u2032 , they share a very similar dynamics: the only difference is that\nthe part of interaction between D, E and the \"isomorphic\" copy of E in R is reproduced\nin R\u2032 by D[\u03c3/\u03be] and E. But this creates no relevant differences on the pointing string in\nV AM (R) and V AM (R\u2032 ), since we have a pointing string e.g.,\np = . . . (\u03c3, I) . . . (\u03be.\u03b3, K) . . . (\u03b1i .L) . . . (\u03b2j .M ) . . . \u2208 V AM (R)\n\n\f44\n\nM. BASALDELLA AND C. FAGGIAN\n\nif and only if we have a \"corresponding\" pointing string of the same length\np\u2032 = . . . (\u03be, I) . . . (\u03be.\u03b3, K) . . . (\u03b1i .L) . . . (\u03b1j .M ) . . . \u2208 V AM (R\u2032 )\nwhere, for p = x1 . . . xn and p\u2032 = y1 . . . yn :\n\u2022 the polarity of xi and yi is the same, for 1 \u2264 i \u2264 n;\n\u2022 the pointer structures of p and p\u2032 are exactly the same in the sense that xi points to xj\nif and only if yi points to yj ;\n\u2022 for any 1 \u2264 i \u2264 n, either xi = yi or xi = (\u03c3.\u03b3, I) and yi = (\u03be.\u03b3, I) or xi = (\u03b1l .\u03b3, I) and\nyi = (\u03b2l .\u03b3, I), for 1 \u2264 l \u2264 k.\nThis follows from the fact that using the views extraction operation on pointing strings\ngiven by the VAM, we can univocally determine a specific view of strategy. In particular,\ngiven p (resp. p\u2032 ) we can univocally reconstruct p\u2032 (resp. p).\nSince the nature (visible, hidden, proper, silent,. . . ) of the action in p and p\u2032 corresponds\nelementwise too, it follows that p \u2208 I(R) if and only if there is a \"corresponding\" p\u2032 \u2208 I(R\u2032 ).\nThe difference between p and p\u2032 then is only on names occurring in proper actions, but names\ngenerated by cuts \u03be and \u03c3 will be erased by hiding, thus obtaining a view s \u2208 [[R]] and a\n\"corresponding\" view s\u2032 \u2208 [[R\u2032 ]], and names generated by \u2206\u2032 which are not in s\u2032 are renamed\nby using the renaming [\u2206/\u2206\u2032 ] which is only needed to this aim.\nA formal proof can be carried out by induction on the length of the pointing strings.\nAs a special instance of the previous proposition we have:\nProposition 8.15 (Copies). Let D : \u03be + and E : \u03be \u2212 be strategies. We have:\n[[D, E]] = [[\u03c3(D), E, E[\u03c3/\u03be]]].\n\n(8.1)\n\n9. Orthogonality and interactive types\n9.1. Orthogonality. The definition of orthogonality is the same as for linear strategies\n(Definition 4.31); we repeat it for convenience.\nLike in the linear case (and with a similar meaning) orthogonality is a relation which\nis defined on total strategies (with the notion of totality being now that in Definition 7.7).\nDefinition 9.1 (Orthogonality, orthogonal set). Let D : \u0393 be a total strategy and (E\u03be )\u03be\u2208\u0393\nbe a family of counter-strategies (Definition 4.29). D and (E\u03be ) are said to be orthogonal,\nwritten D\u22a5(E\u03be ) if [[D, (E\u03be )]] is total.\nGiven a set S of total strategies on the same interface \u0393, its orthogonal set is defined\nas\nS\u22a5 := {(E\u03be ) : (E\u03be ) is a family of counter-strategies w.r.t. \u0393 and (E\u03be )\u22a5D for any D \u2208 S}.\nSimilarly, given a set C of families of counter-strategies w.r.t. \u0393, its orthogonal set is\ndefined as\nC\u22a5 := {D : D is total on interface \u0393 and D\u22a5(E\u03be ) for any (E\u03be ) \u2208 C}.\n\n\fLUDICS WITH REPETITIONS\n\n45\n\nObserve that [[D, (E\u03be )]] is a strategy on the empty interface. By Definition 7.7, we have\northogonality if [[D, (E\u03be )]] 6= Fid and for each s \u2208 [[D, (E\u03be )]] there is p.\u2020 \u2208 [[D, (E\u03be )]] such\nthat s \u2291 p.\u2020. The intuition is that each interaction should lead to \u2020. Coherently with this\nintuition, we will also see that two distinct views in the normal form of a closed net always\nbranch on silent actions.\nThe following lemma is a direct consequence of the definition of orthogonality:\nP\nLemma 9.2. Let E : \u03be \u2212 be a negative strategy such that E = i\u2208S \u03c4 Ei . Let {D1 , . . . , Dn , E}\nbe a closed cut-net. We have that:\n[[D1 , . . . , Dn , E]] is total\n\n\u21d2 [[D1 , . . . , Dn , Ei ]] is total, for each i \u2208 S.\n\nHence in particular, for any strategy D\u22a5E, we have\nD\u22a5E \u21d2 D\u22a5Ei , for each i \u2208 S.\nThe converse of Lemma 9.2 does not hold in general. We now give a concrete example,\nwhich is also useful to better understand composition and orthogonality.\nExample 9.3. Let us consider the following strategies.\n\u2020\n\n\u2020\n\ny\u2212\n\nz\u2212\n\nx+\n\nx+\n\ny+\n\nz+\n\ny+\n\nz+\n\ny\u2212\n\nz\u2212\n\nx\u2212\n\nx\u2212\n\n\u03c41\n\n\u03c42\n\nE1\n\nE2\n\nx+\n\nD\n\nx\u2212\n\nE1 + \u03c4 E2\n\nIf we compose D with Ei , it is rather clear that we always reach \u2020, hence D\u22a5E1 and D\u22a5E2 .\nOn the other hand, if we compose D with E1 +\u03c4 E2 , we have the interaction as (partially)\ndescribed below.\n\u2020\n\n\u2020\n\ny\u2212\n\nz\u2212\n4'\n\nx+\n\nx+\n\ny+\n\nz\u2212\n\n\u03c41\n\n5'\n\n5\n\ny\u2212\n\nz+\n3'\n\n3\n2\n\n2'\n\n\u03c42\n\n4\n\nD\n\nx+\n\n1\n\nx\u2212\n\nE1 + \u03c4 E2\n\n\f46\n\nM. BASALDELLA AND C. FAGGIAN\n\nAfter the steps tagged by 5 and 5\u2032 the interaction \"re-enters\" in E1 +\u03c4 E2 . The steps which\nfollow 5 are described below (for the steps which follow 5\u2032 the situation is symmetric).\n\n\u2020\n\n\u2020\n\ny\u2212\n\nz\u2212\n\nx+\n\nx+\n\ny\u2212\n\nz\u2212\n\n10\n\ny+\n\nx+\n\n8a\n\n8\n\n9\n\nD\n\nz+\n\n\u03c41\n\n7\n\n\u03c42\n\n7a\n\nx\u2212\n\n6\n\nE1 + \u03c4 E2\n\nNotice that after the step tagged by 8a we have a deadlock : the action z + should match an\naction z \u2212 above (i.e., justified) by the last visited occurrence of x+ (the leftmost one), but\nthere is no such an action since we only have y \u2212 .\nThe result of composition is:\n\u2020\n\n\u2020\n\n\u03c41\n\n\u03c42\n\n\u03c41\n\n\u03c41\n\n\u03c42\n\u03c42\n\n[[D, E1 +\u03c4 E2 ]]\n\nwhich has four maximal views:\n\u2020\n\n\u2020\n\n\u03c41\n\n\u03c42\n\n\u03c41\n\n\u03c42\n\n\u03c41\n\n\u03c41\n\n\u03c42\n\n\u03c42\n\ns1\n\ns2\n\ns3\n\ns4\n\n\fLUDICS WITH REPETITIONS\n\n47\n\nFrom this we conclude that D 6 \u22a5 E1 +\u03c4 E2 because s2 and s3 do not satisfy the totality\ncondition of Definition 7.7.\nWe will use also the following properties of normalization.\nLemma 9.4. Let D, D1 , D2 be strategies on the same positive interface \u03a0 = \u03be1+ , . . . , \u03ben+ .\nLet (Ei )\u03bei\u2208\u03a0 = (Ei ) = {E1 , . . . , En } be a family of (negative) counter-strategies w.r.t. \u03a0.\nWe have the following:\n(a) {E1 , . . . , En } \u22a5 D if and only if x+ .{E1 , . . . , En } \u22a5 x\u2212 .D, where x = (\u03be, In );\n(b) (Ei ) \u22a5 D1 \u2295\u03c4 D2 if and only if (Ei ) \u22a5 D1 and (Ei ) \u22a5 D2 .\nProof.\n(a) By construction, the root action x is never repeated in x+ .{E1 , . . . , En }. By definition\nof VAM, the interaction in the cut-net {x+ .{E1 , . . . , En }, x\u2212 .D} starts by matching x+\nwith x\u2212 , and then continue as in {E1 , . . . , En , D}. More precisely,\nV AM (x+ .{E1 , . . . , En }, x\u2212 .D) = {x+ , x+ .x\u2212 } \u222a {x+ .x\u2212 .q : q \u2208 V AM (E1 , . . . , En , D)}.\nIf I(E1 , . . . , En , D) 6= \u2205, then\nI(x+ .{E1 , . . . , En }, x\u2212 .D) = {x+ , x+ .x\u2212 } \u222a {x+ .x\u2212 .q : q \u2208 I(E1 , . . . , En , D)}.\nIf I(E1 , . . . , En , D) = \u2205, then I(x+ .{E1 , . . . , En }, x\u2212 .D) is also empty. By hiding, we have\nthe conclusion.\n(b) By definition of VAM,\nV AM (E1 , . . . , En , D1 \u2295\u03c4 D2 ) = {t.t1 .q : q \u2208 V AM (E1 , . . . , En , D1 )}\n\u222a {t.t2 .q : q \u2208 V AM (E1 , . . . , En , D2 )}.\nSince\n(precisely)\n\nD1 \u2295\u03c4 D2\n\nwe have\n\nD1\n\nD2\n\n\u03c41\n\n\u03c42\n\nD1\n\nD2\n\nt\u2212\n1\n\nt\u2212\n2\nt+\nD1 \u2295\u03c4 D2\n\n\f48\n\nM. BASALDELLA AND C. FAGGIAN\n\n(precisely)\n\n[[(Ei ), D1 ]][[(Ei ), D2 ]]\n\u03c41\n\n[[(Ei ), D1 ]]\n\n[[(Ei ), D2 ]]\n\nt\u2212\n1\n\nt\u2212\n2\nt+\n\n\u03c42\n\n[[(Ei ), D1 \u2295\u03c4 D2 ]]\n\n[[(Ei ), D1 \u2295\u03c4 D2 ]]\n\n9.2. Interactive types. As already defined in Section 4.3, a behaviour G is a set of strategies closed by biorthogonal. Since we have abandoned the limitation of \"strict linearity\"\nwhich we had in Section 4.1.2 , now behaviours are never empty.\nDefinition 9.5. A behaviour on the interface \u0393 is a set G of strategies D : \u0393 such that\nG\u22a5\u22a5 = G. A behaviour is positive or negative according to the polarity of the interface.\nProposition 9.6. A behaviour is always non-empty.\nProof. A positive behaviour always contains at least Dai. A negative behaviour on the\ninterface \u03c3 \u2212 , \u03be1+ , . . . , \u03ben+ , always contains at least the following strategy Dai\u2212 (called negative\ndaimon in [22]):\n\u2020\nDai\u2212\n\n\u2020\n\n\u2020\n\n(\u03c3, I0 )\u2212 (\u03c3, I1 )\u2212 . . . (\u03c3, In )\u2212 . . .\n\nIndeed, let D : \u03c3 + and E1 : \u03be1\u2212 , . . . , En : \u03ben\u2212 be total counter-strategies. Let us consider then\nthe closed cut-net {Dai\u2212 , D, E1 , . . . , En } and calculate its normal form. By definition of the\nabstract machine, we start by collecting actions in D (because it is the main strategy). Since\nD is total, after a sequence of silent actions we reach \u2020 or we reach a positive action (\u03c3, In )+\n(both cases are possible \"in parallel\", since D is non-uniform). In the latter case this proper\naction matches its opposite (\u03c3, In )\u2212 and we eventually reach \u2020. The normal form is then a\ntotal strategy on the empty interface, since each path from the root of [[Dai\u2212 , D, E1 , . . . , En ]]\nleads to \u2020.\n\n\fLUDICS WITH REPETITIONS\n\n49\n\nExample 9.7 (?P 0 , !N \u22a4 ). Let us see what happens to the behaviour generated from\nDai : \u03be + (cf. Example 4.33) in the non-linear setting.\n?P 0 := {Dai}\u22a5\u22a5 on interface \u03be + ;\n\n!N \u22a4 := {Dai}\u22a5 on interface \u03be \u2212 .\n\nWe have that ?P 0 contains a unique deterministic strategy, which is Dai. ?P 0 also contains\nstrategies which are set of views of the form s = t.ti . . . . .t.tj .\u2020. On the other side, !N \u22a4\ncontains all negative strategies which have interface \u03be, including the empty one.\nWhen we take ?P 0 on the empty interface, it consists exactly of all the total strategies\non the empty interface.\n10. Ludics with repetitions: types and internal completeness\nIn this section, we give constructions for the behaviours which correspond to the construction of MELLS formulas, and prove that they enjoy internal completeness.\n10.1. MELLS types. In this section, we use the same constructions on strategies as in\nSection 4.5. The resulting behaviours are different, because normalization is different (i.e.,\nnon-linear).\n10.1.1. Constructions on strategies. Let Di : \u03bei\u2212 , \u03a0 (1 \u2264 i \u2264 n) be n \u2265 0 negative strategies\n(which can possibly also be empty). We obtain a new positive strategy on the interface\n\u03be + , \u03a0, denoted by D1 \u2022 * * * \u2022 Dn , by adding to the union of the strategies the positive root\n(\u03be, In )+ , i.e.,\nD1 \u2022 * * * \u2022 Dn := (\u03be, In )+ .{D1 , . . . , Dn }.\nWe observe that the root of the resulting strategy is linear. A converse construction also\nexists.\nLemma 10.1. Let D : \u03be + , \u03a0 be a positive strategy having as root a linear occurrence of the\nproper action (\u03be, In )+ . We can write D as D1 \u2022 * * * \u2022 Dn , with Di : \u03bei\u2212 , \u03a0 for each 1 \u2264 i \u2264 n.\nProof. Let us write D as (\u03be, In )+ .E. All views in E have a first action of the form (\u03bei, K)\u2212 ,\nwith 1 \u2264 i \u2264 n. We partition E into maximal subsets of views which start with an action\non the same name, that is, we set Di := {s \u2208 E : s = (\u03bei, K)\u2212 .s\u2032 for some K}. Then it is\nimmediate to verify that each Di is in fact a negative strategy on interface \u03bei\u2212 , \u03a0 and that\nE = D1 \u222a . . . \u222a Dn . We finally conclude D = D1 \u2022 * * * \u2022 Dn .\nLemma 10.2. Let D1 : \u03be1\u2212 , \u03a0, . . . , Dn : \u03ben\u2212 , \u03a0 be negative strategies. Let (F\u03b1 )\u03b1\u2208\u03a0 be a\nfamily of counter-strategies ( w.r.t. \u03a0). We have that\n[[D1 \u2022 * * * \u2022 Dn , (F\u03b1 )]] = [[D1 , (F\u03b1 )]] \u2022 * * * \u2022 [[Dn , (F\u03b1 )]].\nThat is,\n[[(\u03be, In )+ .{D1 , . . . , Dn }, (F\u03b1 )]] = (\u03be, In )+ .{[[D1 , (F\u03b1 )]], . . . , [[Dn , (F\u03b1 )]]}.\nProof. It easily follows from the definition of VAM. We first observe that by construction,\nthe root of D1 \u2022 * * * \u2022 Dn is (\u03be, In )+ and that it is a visible action. This implies that it is also\nthe root of [[D1 \u2022 * * * \u2022 Dn , (F\u03b1 )]]. Since (\u03be, In )+ occurs linearly, the interaction never uses\n(occurrences of) (\u03be, In )+ again, and we can write the equations above.\n\n\f50\n\nM. BASALDELLA AND C. FAGGIAN\n\nFrom now until the end of Section 10, let us fix a family of n (n \u2265 0) negative behaviours\nN\u03bei : \u03bei\u2212 , with 1 \u2264 i \u2264 n. We define\nN\u03be1 \u2022 * * * \u2022 N\u03ben := {D1 \u2022 * * * \u2022 Dn : Di \u2208 N\u03bei }.\nWe define a new positive (resp. negative) behaviour on the interface \u03be + (resp. \u03be \u2212 ) as follows:\n\u22a5\u22a5\n;\nF+\n\u03be (N\u03be1 , . . . , N\u03ben ) := (N\u03be1 \u2022 * * * \u2022 N\u03ben )\n\n\u22a5\n\u22a5\n\u22a5\nF\u2212\n\u03be (N\u03be1 , . . . , N\u03ben ) := (N\u03be1 \u2022 * * * \u2022 N\u03ben ) .\n\nRemark 10.3. We stress once more that, by construction, all strategies in N\u03be1 \u2022 * * * \u2022 N\u03ben\nhave as root x = (\u03be, In )+ , which is linear. The repetitions of occurrences of x are obtained\nvia the closure by biorthogonality, and hence only belong to (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5\u22a5 .\nWhen n = 0 we write ?P 1 and !N \u22a5 for the positive behaviour and the negative one\ngiven by the previous constructions respectively. Precisely, ?P 1 = {D}\u22a5\u22a5 and !N \u22a5 = {D}\u22a5 ,\nwhere D = (\u03be, \u2205)+ .\nLemma 10.4. If the root x of D \u2208 P\u03be = (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5\u22a5 is a proper action, then\nx = (\u03be, In )+ .\nProof. By construction, all the strategies in N\u03be1 \u2022 * * * \u2022 N\u03ben have root x = (\u03be, In )+ . Hence,\n(N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5 contains the strategy E := (\u03be, In )\u2212 .\u2020. Since any D \u2208 (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5\u22a5\nhas to be orthogonal to E, when its root is a proper action it must be (\u03be, In )+ .\n10.2. Sequent of behaviours. The definition of sequent of behaviours remains the same\nas in the linear case, and Proposition 4.39 still holds. For the reader's convenience we repeat\nthem below.\nDefinition 10.5 (Sequent of behaviours). Let \u0393 = \u03be1\u01eb1 , . . . , \u03ben\u01ebn (n \u2265 0) be an interface, and\nlet \u0393 = G\u03be1 , . . . , G\u03ben (n \u2265 0) behaviours of respective polarities \u01eb1 , . . . , \u01ebn .\nWe define a new behaviour on the same interface \u0393, which we call sequent of behaviours and denote by \u22a2 \u0393, as follows:\n\u22a5\n\u22a2 \u0393 := {D : D is total on interface \u0393 and D\u22a5{E1 , . . . , En } for all E1 \u2208 G\u22a5\n\u03be1 , . . . , En \u2208 G\u03ben }.\n\nObserve that if \u0393 is empty, then \u22a2 \u0393 consists of those strategies on the empty interface\nwhich are total (cf. Section 7). Hence, \u22a2 \u0393 is {Dai}\u22a5\u22a5 .\nWe will use the following two results.\nProposition 10.6. Let A, G1 , . . . Gn (n \u2265 0) be a sequence of behaviours, and \u0393 =\nG1 , . . . Gn . We have that:\n\u2022 D \u2208 \u22a2 \u0393, A if and only if for each F \u2208 A\u22a5 , [[D, F]] \u2208 \u22a2 \u0393.\n\u2022 D \u2208 \u22a2 \u0393, A if and only if [[D, (Ei )]] \u2208 \u22a2 A, for each family (Ei ) such that E1 \u2208 G\u22a5\n1 ,...,\nEn \u2208 G\u22a5\n.\nn\nThe proof is the same as for Proposition 4.39 (but now using Theorem 8.13). Observe again\nthat if \u0393 = \u2205, the condition in the first claim is simply a reformulation of the definition of\northogonality: D\u22a5F if [[D, F]] is a total strategy on the empty interface.\n\n\fLUDICS WITH REPETITIONS\n\n51\n\nLemma 10.7. Let N = (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5 . We have that\n(1) If F \u2208 N, then F =\n6 \u2205.\n(2) If F \u2208 \u22a2 N, \u03a0, then F =\n6 \u2205.\nProof.\n(1) F =\n6 \u2205 because each D \u2208 N\u03be1 \u2022 * * * \u2022 N\u03ben has root (\u03be, In )+ , and F has to be orthogonal\nto D.\n(2) The second point is proven with a similar argument.\n10.3. Internal completeness. The following two propositions are the core of internal\ncompleteness. Internal completeness for a negative behaviour is the same as in the linear\ncase. For the positive case, we also first state internal completeness for those strategies\nwhose root is linear. The key element which allows us to reduce the general case to this\none is Lemma 10.10.\nProposition 10.8 (Internal completeness of F\u2212 ). Let P\u03bei = N\u22a5\n\u03bei and x = (\u03be, In ).\n(1) x\u2212 .D \u2208 F\u2212 (P\u03be1 , . . . , P\u03ben ) \u21d4 (2) D \u2208 \u22a2 P\u03be1 , . . . , P\u03ben .\nProof. The proof follows immediately from the definitions. Expanding the definition, we\nobtain the two following properties, which are equivalent by using Lemma 9.4 (a):\n\u22a5\n(1) x\u2212 .D \u22a5 x+ .{E1 , . . . , En }, for any E1 \u2208 P\u22a5\n\u03be1 , . . . , En \u2208 P\u03ben ;\n\u22a5\n(2) D \u22a5 {E1 , . . . , En }, for any E1 \u2208 P\u22a5\n\u03be1 , . . . , En \u2208 P\u03ben .\nProposition 10.9 (Linear internal completeness of F+ ). Let D \u2208 F+ (N\u03c31 , . . . , N\u03c3n ) have\na root that is a linear occurrence of a proper action. Then D = D1 \u2022 * * * \u2022 Dn , with Di \u2208 N\u03c3i ,\nfor any 1 \u2264 i \u2264 n.\nProof. By Lemma 10.4 we know that the root of D must be (\u03c3, In )+ . Since it occurs\nlinearly, we can apply Lemma 10.1 and then write D as D1 \u2022 * * * \u2022 Dn . We already observed\n(Remark 5.2), that the argument in Proposition 5.1 only relies on the fact that the root is\na linear occurrence of action. We can hence repeat the same proof as in 5.1.\nThe essential property which allows us to use the argument we sketched in Section 6.4\nis the following Lemma 10.10 (1). Point (2) guarantees that all tests we are interested in\nhave the form requested by point (1).\nLemma 10.10. Let N\u03be = (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5 , P\u03be = (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5\u22a5 , and x = (\u03be, In ).\n(1) Let F1 , F2 \u2208 N\u03be . Assume F1 = x\u2212 .D1 , F2 = x\u2212 .D2 . We have that F1 +\u03c4 F2 \u2208 N\u03be (cf.\nDefinition 7.5).\n(2) Let us denote by N\u03be hxi the set of all F \u2208 N\u03be such that F has x as unique root. We\nhave that (N\u03be hxi)\u22a5 = N\u22a5\n\u03be i.e.,\nP\u03be = (N\u03be hxi)\u22a5 .\nProof.\n\u22a5\n(1) By internal completeness (Proposition 10.8), D1 , D2 \u2208 \u22a2 N\u22a5\n\u03be1 , . . . , N\u03ben . By Lemma 9.4,\n\u22a5\n\u03c4\n\u22a5\nD1 \u2295 D2 \u2208 \u22a2 N\u03be1 , . . . , N\u03ben . By Proposition 10.8 again, we conclude F1 +\u03c4 F2 =\nx\u2212 .(D1 \u2295\u03c4 D2 ) \u2208 N.\n\n\f52\n\nM. BASALDELLA AND C. FAGGIAN\n\n(2) Let F \u2208 (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5 . Being on interface \u03be, a negative strategy F may have\nseveral roots, all of the form (\u03be, K)\u2212 (all views in F start with such an action). We\ndefine Fx \u2286 F as the subset of views whose first action is x = (\u03be, In ). Fx is clearly a\nstrategy. We proceed in two steps.\n(i) We prove that for each F \u2208 N\u03be , then Fx \u2208 N\u03be .\nLet D : \u03be + \u2208 N\u03be1 \u2022 * * * \u2022 N\u03ben . A positive strategy has a unique root. By construction,\nthe root of D is the action x+ = (\u03be, In )+ . For each F \u2208 N\u03be , it must be D\u22a5F. Since\nD is the main strategy in the cut-net {D, F}, F need to have x\u2212 = (\u03be, In )\u2212 as a root,\nin order to match x+ , otherwise those strategies would not be orthogonal. We observe\nthat the normalization with any D \u2208 N\u03be1 \u2022 * * * \u2022 N\u03ben only uses views in Fx , because D\nby construction does not contain any other occurrence of action on the name \u03be but the\nroot. As a consequence, [[D, F]] = [[D, Fx ]].\n(ii) We can now prove that (N\u03be hxi)\u22a5 \u2286 N\u22a5\n\u03be (the other inclusion is obvious, since\n\u22a5\nN\u03be hxi \u2286 N\u03be ). Let D \u2208 (N\u03be hxi) . We prove that for each F \u2208 N\u03be , D\u22a5F, i.e.,\nD \u2208 N\u22a5\n\u03be . More precisely, we prove that [[D, F]] = [[D, Fx ]], by showing that the part of\nF used in the interaction against D is all contained in Fx .\nAssume there exists p \u2208 I(D, F) such that ppq 6\u2208 Fx , and let us take it minimal,\ni.e., ppq = y \u2212 , where y = (\u03be, J), J 6= In (i.e., the interaction enters the root of another\nsubtree of Fy of F). In this case p = p\u2032 .y + .y \u2212 , with ptq \u2208 {D, Fx }, for each t \u2291 p\u2032 .y + .\nWe observe that p\u2032 .y + has no extensions in V AM (D, Fx ) (because there is no match\nfor y + ), and that it contains no \u2020. Let s be the maximal prefix of p\u2032 .y + which has an\nextension q.\u2020 in V AM (D, Fx ) (i.e., an extension which terminates with a \u2020 action). We\nhave s.a \u2291 p\u2032 .y + , s.b \u2291 q.\u2020, and by Lemma 8.10, we have that a, b are negative silent\nactions. Hence s.a \u2208 I(D, Fx ), and hide(s.a) \u2208 [[D, Fx ]], but hide(s.a) has no extension\nterminating with a \u2020 action, against the hypothesis that D\u22a5Fx .\nObserve that, putting all elements together, we have also established that\n[[D, F]] = [[D, Fx ]] for each D \u2208 N\u22a5\n\u03be , F \u2208 N\u03be .\nWe will use this in the sequel.\nObserve that the property at the point (1) above does not hold in general, for arbitrary\nbehaviours (see Example 9.3 and take G = {D}\u22a5 ).\nLemma 10.11. Let D \u2208 P\u03be = (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5\u22a5 , such that the root is a proper action.\nWe have that \u03c3(D) \u2208 \u22a2 P\u03be , P\u03c3 . Moreover, the new root on \u03c3 is linear.\nProof. By Lemma 10.10 (2), P\u03be = (N\u03be hxi)\u22a5 . For all pairs E, F \u2208 N\u03be hxi, we have D\u22a5E\nand D\u22a5F. By Lemma 10.10 (1), we have that D\u22a5 (E +\u03c4 F). Using Proposition 8.15,\nwe have that \u03c3(D)\u22a5{E +\u03c4 F, (E +\u03c4 F)[\u03c3/\u03be]} and by using twice Lemma 9.2 we have that\n\u03c3(D)\u22a5{E, F[\u03c3/\u03be]}, that is \u03c3(D) \u2208 \u22a2 P\u03be , P\u03c3 . The linearity of \u03c3(D) is given by the construction \"\u03c3( ).\"\nCorollary 10.12 (Internal completeness of F+ ). Let D \u2208 P\u03be = F+ (N\u03be1 , . . . , N\u03ben ) be as in\nLemma 10.11. Then \u03c3(D) = D1\u2032 \u2022 * * * \u2022 Dn\u2032 where each Di\u2032 \u2208 \u22a2 N\u03c3i , P\u03be .\nProof. By Lemma 10.4, the root x of D \u2208 P\u03be is x = (\u03be, In ). By Lemma 10.11, we have that\n\u03c3(D) \u2208 \u22a2 P\u03be , P\u03c3 . The root (\u03c3, In ) is the only occurrence of action on \u03c3. By Lemma 10.1, we\ncan write \u03c3(D) as \u03c3(D) = E1 \u2022 * * * \u2022 En . Now we use Proposition 10.6. For each A\u03be \u2208 P\u22a5\n\u03be , we\nhave [[\u03c3(D), A]] \u2208 P\u03c3 . By Lemma 10.2 we have that: [[E1 \u2022* * *\u2022En , A]] = [[E1 , A]]\u2022* * *\u2022[[E1 , A]].\n\n\fLUDICS WITH REPETITIONS\n\n53\n\nBy Proposition 10.9, [[Ei , A]] \u2208 N\u03c3i . By using again Proposition 10.6, we have that Ei \u2208 \u22a2\nN\u03c3i , P\u03be .\n11. Ludics with repetitions: full completeness\nIn this section, we show that our model is fully complete with respect to MELLS (Section 2).\nAs usual in game semantics (e.g., [31, 33]), not all strategies are suitable to be interpretation of a proof. In general, strategies which are interpretations of a proof have to satisfy\nsome winning conditions which describe a strategy with \"good properties.\" Our winning\nstrategies are those that are finite, deterministic, daimon-free and material (see below).\nWe now introduce the notion of materiality.\n11.1. Materiality. It is important to have in mind that normalization does not necessarily\nvisit all the actions of a strategy. This is exactly what underlies the notion of materiality.\nLet us first examine an example, to understand materiality.\nBy definition of normalization (Section 8), at each step, the machine examines (i.e.,\nvisits) an occurrence of action a in a view s.a belonging to a strategy of the cut-net. We\nsay that the view s.a is used or visited.\nExample 11.1. Let D, E, F be the strategies in Figure 7.\n\na+\nb\u2212\n\n\u2020\n\na+\n\na+\n\na\u2212\n\nE \u2208E\n\nD\u2208E\n\nF \u2208 E\u22a5\n\nFigure 7: Materiality\nConsider the behaviour E = {D}\u22a5\u22a5 and notice that F \u2208 E\u22a5 . Observe also that E \u2208 E,\nbut the normalization between E and F uses only the first action a+ ; the action b\u2212 is never\nvisited through the interaction between E and F.\nThe notion of materiality exactly captures the significant part of a strategy D in a\nbehaviour, i.e., the part that is really used to react to the tests in E\u22a5 .\nTo make these ideas formal, we proceed in two steps.\nFirst, in Section 11.1.1, we consider a strategy D, and a family of counter-strategies (Ei ).\nWe define the restriction of D to the part D \u2032 \u2286 D which is really used (visited) to produce the\nnormal form [[D, (Ei )]]. We have that D \u2032 is a strategy, and that [[D \u2032 , (Ei )]] = [[D, (Ei )]]. Any\n\n\f54\n\nM. BASALDELLA AND C. FAGGIAN\n\noccurrence of action in D which is outside D \u2032 will never be accessed during this normalization\nand in fact those - not visited - actions are not significant in the calculation.\nThen, in Section 11.1.2, we consider D inside a behaviour G. From the point of view\nof the behaviour G, the part of D which is significant is the part that is really used to react\nto the tests (strategies of G\u22a5 ). This leads to the definition of material part of a strategy in\na behaviour.\n11.1.1. Part of a cut-net used by the normalization. When normalizing two strategies D, E,\nonly a part D \u2032 \u2286 D, E \u2032 \u2286 E is used to produce the normal form; this is the set of views\nwhich are examined by the machine in Definition 8.4. If we run the machine on {D, E} or\non {D \u2032 , E \u2032 }, the result will be the same.\nDefinition 11.2. Let R be a cut-net. For each D \u2208 R, we define the restriction of D to\nthose of its views which are used (or visited) in the process of interaction to produce [[R]]\nas follows:\nD R = D \u2229 {ppq : p \u2208 I(R)}.\nIf R = {D, E1 , . . . , En }, we will also write D[E1 , . . . , En ] for D R .\nLemma 11.3. Let R be a cut-net. For each D \u2208 R, D R is a strategy.\nProof. Let D \u2208 R. Since D R \u2286 D, to show that it is a strategy, we only need to show\nthat it satisfies \u03c4 -Positivity, in the sense of Definition 7.2. Let s.a be maximal in D R . By\nconstruction, s.a = ppq, for some p = x1 . . . xn \u2208 I(R). Moreover, by definition of view\nextraction pq (Definition 8.1) xn = a. If a is a proper negative action, by definition of\nI(R), p must have an extension. Let us consider a minimal one, p.c+ . It has to be that\nppq.c+ \u2208 D (by Definition 8.4 of VAM). We have that pp.c+ q = ppq.c+ = sa.c+ \u2208 D R ,\nagainst the hypothesis that s.a is maximal.\nThe part of a strategy which we have defined in Definition 11.2 is the part of the cut-net\nin which normalization takes place.\nLemma 11.4. Let R = {D1 , . . . , Dn } be a cut-net. We have that\n[[D1 , . . . , Dn ]] = [[D1R , . . . , DnR ]].\nProof. It is a straightforward consequence of Definition 8.4, since all the views of D1 , . . . , Dn\nwhich are used for the construction of I(R) are contained in D1R , . . . , DnR .\n11.1.2. Material part of a strategy in a behaviour. If D is a strategy in a behaviour G, the\npart of D which is used to interact with all the tests (i.e., the strategies in G\u22a5 ) is the only\nsignificant part of D from the point of view of the behaviour.\nTo make the notion of materiality easier to grasp, we first give he definition in the case\nof behaviours on unary interfaces, and then generalize it to sequents of behaviours.\nDefinition 11.5 (Materiality). Let G be a behaviour and D a strategy in G. We define\nthe material part of D in G as\n[\b\n|D|G :=\nD[E] : E \u2208 G\u22a5 .\nA strategy D \u2208 G is said to be material in G if D = |D|G .\n\n\fLUDICS WITH REPETITIONS\n\n55\n\nFor \u0393 = G1 , . . . , Gn , let \u22a2 \u0393 be a sequent of behaviours, D \u2208 \u22a2 \u0393, and (Ei ) a family of\n\u22a5\ncounter-strategies E1 \u2208 G\u22a5\n1 , . . . , En \u2208 Gn . The material part of D in \u22a2 \u0393 is defined as\n[\b\n\u22a5\n|D|\u22a2\u0393 :=\nD[(Ei )] : E1 \u2208 G\u22a5\n1 , . . . , En \u2208 Gn .\n\nA strategy D \u2208 \u22a2 \u0393 is said material in \u22a2 \u0393 if D = |D|\u22a2\u0393 .\n\nAs an immediate consequence of Lemma 11.3, we have that:\nLemma 11.6. |D|G and |D|\u22a2\u0393 are strategies.\nExample 11.7. Let us consider D and E as in Example 11.1. We see that D is material in\nE whereas E is not.\nThe content of the definition of materiality is made explicit by the properties below.\nProposition 11.8. Let G be a behaviour on a unary interface and D \u2208 G. We have:\n(1) [[|D|G , E]] = [[D, E]], for each E \u2208 G\u22a5 .\n(2) |D|G \u22a5E, for each E \u2208 G\u22a5 . In particular, |D|G \u2208 G.\nProof. By Lemma 11.4, we have that [[D[E], E]] = [[D, E]]. From this we have (1) which\nimplies (2).\nThe previous proposition obviously extends to sequents of behaviours.\nLemma 11.9. Let N = (N\u03be1 \u2022 * * * \u2022 N\u03ben )\u22a5 be a behaviour on interface \u03be \u2212 . We have that if\nF is material in N, then it has a single root which is x = (\u03be, In )\u2212 .\nIn other words, with the notations introduced in Lemma 10.10, we have |F|N \u2208 Nhxi, for\neach F \u2208 N.\nProof. The proof is actually part of the proof of Lemma 10.10 (2), because we have proven\nthat given F \u2208 N, for each D \u2208 N\u22a5 , we have [[D, F]] = [[D, Fx ]], which in turn implies\nF[D] \u2286 Fx .\nExample 11.10 (Materiality with constant types). Let us fix a name \u03be. The material and\ndeterministic strategies in the constant type ?P 1 are D = (\u03be, \u2205)+ and Dai. Moreover, D is\nwinning in ?P 1 (see Definition 11.11).\nThe only material and deterministic strategy which inhabits !N \u22a5 is E = (\u03be, \u2205)\u2212 .Dai.\nIn particular, there are no winning strategies in !N \u22a5 , i.e., \" no syntactical derivations of\n\u22a2 !N .\"\nT\n\n11.2. Completeness theorems. In Section 11.3, we describe the interpretation of a formula F of MELLS into a behaviour F and similarly the interpretation of a syntactical\nsequent of MELLS into a sequent of behaviours. A derivation of a sequent in MELLS will\nbe interpreted by a winning strategy which belongs to the interpretation of the sequent.\nDefinition 11.11 (Winning strategy). A strategy D \u2208 \u22a2 \u0393 is said winning if it is finite,\ndeterministic, daimon-free and material in \u22a2 \u0393.\nIn the sequel, finiteness, determinism, daimon-freeness and materiality are also called\nwinning conditions.\n\n\f56\n\nM. BASALDELLA AND C. FAGGIAN\n\nRemark 11.12 (Finiteness condition). We here assume finiteness among the winning conditions. However, recent work by Basaldella and Terui [6] shows an exciting property of\ninteractive types: any material, deterministic and daimon free strategy in a behaviour which\nis interpretation of a logical formula is finite. We are confident that this result is also valid\nour setting; we need to check this in detail and we postpone it to a subsequent work.\nThe rest of this article is then devoted to proving the following theorems.\nSoundness: (Theorem 11.16) Let \u03c0 be a derivation of a sequent \u22a2 \u0393 in MELLS interpreted\nby a sequent of behaviours \u22a2 \u0393. There exists a winning strategy D(\u03c0) \u2208 \u22a2 \u0393.\nFull Completeness: (Theorem 11.17) Let \u22a2 \u0393 be the interpretation of a sequent \u22a2 \u0393 of\nMELLS and let D \u2208 \u22a2 \u0393. If D is winning, then D is the interpretation of a cut-free\nderivation \u03c0 of the sequent \u22a2 \u0393 in MELLS.\n11.3. Interpretation of formulas, sequents, derivations. In the rest of this work,\nwe only consider behaviours inductively defined as follows, using the types constructors\nintroduced in Section 10:\nP\u03be ::= F+ (N\u03be1 , . . . , N\u03ben )\n\nN\u03be ::= F\u2212 (P\u03be1 , . . . , P\u03ben )\n\nwhere n \u2265 0 and \u03be is an arbitrary name.\nWe now interpret formulas and sequents of MELLS. Intuitively, given a MELLS\nformula F we associate to it a behaviour F of the same polarity. Given a sequent \u22a2\nF1 , . . . , Fn , we associate to the occurrences of formula F1 , . . . , Fn behaviours F1 , . . . , Fn\nto form a sequent of behaviours \u22a2 F1 , . . . , Fn .\nDefinition 11.13 (Interpretation of formulas and sequents of MELLS).\n(1) Given a formula F and an arbitrary name \u03be we associate a behaviour of the same\npolarity F on interface \u03be inductively as follows.\n?P (N1 \u2297 * * * \u2297 Nn )\n!N (P1 ` * * * ` Pn )\n\n\u03be\n\u03be\n\n:= F+ (N1 \u03be1 , . . . , Nn \u03ben );\n:= F\u2212 (P1 \u03be1 , . . . , Pn \u03ben ).\n\n(2a) Given a positive sequent \u22a2 P1 , . . . , Pn , and a positive interface \u03be1+ . . . , \u03ben+ we associate\nthe sequent of behaviours \u22a2 P1 \u03be1 , . . . , Pn \u03ben .\n(2b) Given a negative sequent \u22a2 N, P1 , . . . , Pn and a negative interface \u03c3 \u2212 , \u03be1+ . . . , \u03ben+ we\nassociate the sequent of behaviours \u22a2 N \u03c3 , P1 \u03be1 , . . . , Pn \u03ben .\nT\n\nFor instance, we have ?P I \u03be = ?P 1 and !N \u03be = !N \u22a5 on interface \u03be + and \u03be \u2212 respectively.\nIn the sequel, we indicate the behaviour F \u03be by F\u03be or just by F when the name \u03be is\nclear from the context or irrelevant for our purposes. Similarly, we write \u22a2 P\u03be1 , . . . , P\u03ben\nand \u22a2 N\u03c3 , P\u03be1 , . . . , P\u03ben or just \u22a2 \u03a0 and \u22a2 N, \u03a0.\nWe are now ready to define the interpretation of a derivation \u03c0 of a sequent \u22a2 \u0393 in\nMELLS.\nDefinition 11.14 (Interpretation of derivations of MELLS). Let \u03c0 be a derivation of\na sequent \u22a2 F1 , . . . , Fn in MELLS and \u22a2 F\u03be1 , . . . , F\u03ben its interpretation on an arbitrary\ninterface \u03be1 , . . . , \u03ben . The interpretation of \u03c0 in \u22a2 F\u03be1 , . . . , F\u03ben is a strategy D(\u03c0) on\ninterface \u03be1 , . . . , \u03ben inductively defined as follows.\nPositive rule: \u03c0 ends with a positive rule Posn and the principal formula is P = ?P (N1 \u2297\n* * * \u2297 Nn ).\n\n\fLUDICS WITH REPETITIONS\n\n..\n. \u03c01\n\u22a2 \u03a0, P, N1\n\n57\n\n..\n. \u03c0n\n\u22a2 \u03a0, P, Nn\n\n...\nPosn\n\u22a2 \u03a0, P\nLet D(\u03c0i ) be the interpretation of \u03c0i in \u22a2 \u03a0, P\u03be , N\u03c3i , for 1 \u2264 i \u2264 n. The strategy\nD(\u03c0) := (\u03c3, In )+ .{D1 , . . . , Dn }[\u03be/\u03c3]\nis the interpretation of \u03c0 in \u22a2 \u03a0, P\u03be .\nNegative rule: \u03c0 ends with a negative rule Negn , where N = !N (P1 ` * * * ` Pn ).\n..\n. \u03c00\n\u22a2 \u03a0, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, N\nLet D(\u03c00 ) be the interpretation of \u03c00 in \u22a2 \u03a0, P\u03be1 , . . . , P\u03ben . The strategy\nD(\u03c0) := (\u03be, In )\u2212 .D(\u03c00 )\nis the interpretation of \u03c0 in \u22a2 \u03a0, N\u03be .\nCut: \u03c0 ends with a Cut rule:\n..\n.\u03c0\n\n..\n. \u03c02\n\u22a2 \u2206, P \u22a5\n\u22a2 \u039e, \u03a0, P\nCut\n\u22a2 \u039e, \u03a0, \u2206\nLet D(\u03c01 ) and D(\u03c02 ) be the interpretation of \u03c01 and \u03c02 in \u22a2 \u039e, \u03a0, P\u03be and \u22a2 \u2206, P\u22a5\n\u03be\nrespectively. The strategy\nD(\u03c0) := [[D(\u03c01 ), D(\u03c02 )]]\nis the interpretation of \u03c0 in \u22a2 \u039e, \u03a0, \u2206. (Here we are assuming that the names in \u03a0 and\n\u2206 are disjoint.)\n1\n\nExample 11.15. Let us consider the case n = 0 in the interpretation of the positive and\nnegative rule respectively. Following the previous definition (with the same notation) we\nhave:\n\u2022 The strategy (\u03be, \u2205)+ is the interpretation in \u22a2 \u03a0, ?P 1 \u03be of the derivation \u22a2 \u03a0, ?P I Pos0\n(where the behaviour ?P 1 \u03be interprets the occurrence of the principal formula ?P I ).\n\u2022 The strategy (\u03be, \u2205)\u2212 .D(\u03c1) is the interpretation in \u22a2 \u03a0, !N \u22a5 \u03be of the derivation\n..\n.\u03c1\n\u22a2\u03a0\nNeg0\n\u22a2 \u03a0, !N\nT\n\n11.4. Soundness. Having fixed the interpretations of formulas, sequents and derivations\nwe are ready to show:\nTheorem 11.16 (Soundness). Let \u03c0 be a derivation of a sequent \u22a2 \u0393 in MELLS and D(\u03c0)\nbe the interpretation of \u03c0 in a sequent of behaviours \u22a2 \u0393. We have that:\nD(\u03c0) is a winning strategy in \u22a2 \u0393.\nMoreover, the interpretation is invariant under cut-elimination.\n\n\f58\n\nM. BASALDELLA AND C. FAGGIAN\n\nThe proof consists of several lemmas and it is given in Appendix B.\n11.5. Full completeness. We can finally prove the following:\nTheorem 11.17 (Full Completeness). Let \u22a2 \u0393 be a sequent of behaviours which is interpretation of the sequent \u22a2 \u0393 in MELLS. If D is a winning strategy in \u22a2 \u0393 then it is the\ninterpretation of a cut-free derivation \u03c0 of the sequent \u22a2 \u0393 in MELLS.\nProof. Since D is finite, we can reason by induction on the number \u03bd of its actions. Let us\nexamine the other implications of the winning conditions on D. Since D is a daimon-free\nand deterministic strategy, all occurrences of actions in D are proper actions. Moreover, we\nhave that D is non-empty, and has a single root (both properties always hold for positive\nstrategies, and here also in case D is negative by Lemma 10.7 and 11.9, because D is\nmaterial).\nLike in the linear case, we will use - back and forth - the definition of sequent of\nbehaviours and more precisely Proposition 10.6. Let \u22a2 \u0393 be the interpretation of the sequent\n\u22a2 \u0393, and D \u2208 \u22a2 \u0393 a winning strategy. Our purpose is to associate to D a derivation D \u22c6 of\n\u22a2 \u0393 in MELLS, by progressively decomposing D, i.e., inductively writing \"the last rule.\"\nThe formula on which the last rule is applied is indicated by the name of the root\naction. The argument is the same as in the linear case. For example, assume that the root\nof D is (\u03be, I); then if D \u2208 \u22a2 F\u03be , Q\u03c3 , the behaviour which corresponds to the last rule is the\none on \u03be, i.e., F\u03be .\nIn the sequel, we consider sequents of behaviours of the form \u22a2 \u03a0, F\u03be , which are interpretations of a sequent \u22a2 \u03a0, F in MELLS. F is the interpretation of a formula F and \u03a0 is a\nsequence of m behaviours Q\u03b11 , . . . , Q\u03b1m which respectively interpret formulas Q1 , . . . , Qm .\nObserve that \u03a0 always consists of positive behaviours only.\nWe use the following convention: we write (E) and (E) \u2208 C for E1 , . . . , Em and E1 \u2208\n\u22a5\nQ\u22a5\n,\n\u03b11 . . . , Em \u2208 Q\u03b1m respectively.\nWe have two cases.\nPositive case. Let D = (\u03be, In )+ .{D1 , . . . , Dn } (n \u2265 0) be a positive winning strategy which\nbelongs to \u22a2 \u03a0, P\u03be , where P\u03be = F+ (N\u03be1 , . . . , N\u03bek ) is the interpretation of the formula of\nMELLS P = ?P (N1 \u2297 * * * \u2297 Nk ).\nBy Proposition 10.6, for any (E) \u2208 C, we have that C = [[D, (E)]] \u2208 P\u03be . The root of\n[[D, (E)]] is still (\u03be, In )+ (by the definition of the abstract machine, since it is a visible action\nwhich is root of the main). Hence k = n.\nWe now use internal completeness.\n(1) By internal completeness of positive connectives (Proposition 10.12), we have that the\nstrategy \u03c3([[D, (E)]]) can be written as C1 \u2022 * * * \u2022 Cn , where Ci \u2208 \u22a2 P\u03be , N\u03c3i .\n(2) It is immediate that \u03c3([[D, (E)]]) = [[\u03c3(D), (E)]]. By Lemma 10.1 , we can write \u03c3(D) =\n(\u03c3, In )+ .{D1\u2032 , . . . , Dn\u2032 } as D1\u2032 \u2022* * *\u2022Dn\u2032 . By Lemma 10.2, we have that [[D1\u2032 \u2022* * *\u2022Dn\u2032 , (E)]] =\n[[D1\u2032 , (E)]] \u2022 * * * \u2022 [[Dn\u2032 , (E)]].\nFrom (1), we conclude that [[Di\u2032 , (E)]] \u2208 \u22a2 P\u03be , N\u03c3i .\nBy applying Proposition 10.6 again, we have that Di\u2032 \u2208 \u22a2 \u03a0, P\u03be , N\u03c3i .\n\n\fLUDICS WITH REPETITIONS\n\n59\n\nIf \u03bd = 1, D consists of a single action (\u03be, In )+ , and we must have n = 0. Otherwise,\nwe would have empty Di\u2032 's, and we already observed that this cannot be the case. Hence,\n\u03bd = 1 gives P\u03be = ?P 1 , and we have that D = (\u03be, \u2205)+ is the interpretation of the rule Pos0 .\nIf \u03bd > 1, we note that the winning conditions are preserved for each Di\u2032 (by Lemma 11.18\nand Lemma 11.19 below) and the number of actions decreases. Hence, the inductive hypothesis applies, and we can write the derivation:\n.. \u2032 \u22c6\n.. \u2032 \u22c6\n. D1\n. Dn\n\u22a2 \u03a0, P, N1\n...\n\u22a2 \u03a0, P, Nn\nPosn\n\u22a2 \u03a0, P\nNegative case. Let us consider a negative winning strategy D \u2208 \u22a2 \u03a0, N\u03be , where the behaviour N\u03be = F\u2212 (P1 , . . . , Pn ) is the interpretation of a formula N = !N (P1 ` * * * ` Pn ) of\nMELLS. Let D = x\u2212 .D \u2032 , with x = (\u03be, In ).\nFor any family (E) \u2208 C, we have\n(1) [[D, (E)]] \u2208 N\u03be , and the root is still x\u2212 . This allows us to use internal completeness.\n(2) By internal completeness of negative connectives (Proposition 10.8), we conclude that\n[[D, (E)]] is of the form x\u2212 .D \u2032\u2032 with D \u2032\u2032 \u2208 \u22a2 P\u03be1 , . . . , P\u03ben .\n(3) By the definition of normalization,\n[[D, (E)]] = [[x\u2212 .D \u2032 , (E)]] = x\u2212 .[[D \u2032 , (E)]].\nFrom this, we have that D \u2032\u2032 = [[D \u2032 , (E)]] and hence [[D \u2032 , (E)]] \u2208 \u22a2 P\u03be1 , . . . , P\u03ben .\nBy applying Proposition 10.6 again, we have that D \u2032 \u2208 \u22a2 \u03a0, P\u03be1 , . . . , P\u03ben . The winning\nconditions are preserved for D \u2032 (Lemma 11.20 below) and the number of actions decreases.\nHence, the inductive hypothesis applies. Then, we can write the derivation:\n.. \u2032 \u22c6\n.D\n\u22a2 \u03a0, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, N\nWe still have to prove that the winning conditions are preserved by the deconstructions we\nhave used in the last proof. The only condition which is not obvious is materiality.\nTo show that a strategy D is material in \u22a2 \u0393, we check that for each s \u2208 D there is a\ncertain family of counter-strategies (E) \u2208 C such that s = ppq and p \u2208 I(D, (E)). In other\nwords, s is used to produce the normal form [[D, (E)]] (see Definitions 11.5 and 11.2).\nLemma 11.18. Let P\u03be = F+ (N\u03be1 , . . . , N\u03ben ), D \u2208 \u22a2 \u03a0, P\u03be and \u03c3(D) \u2208 \u22a2 \u03a0, P\u03be , P\u03c3 . If D\nis material in \u22a2 \u03a0, P\u03be then \u03c3(D) is material in \u22a2 \u03a0, P\u03be , P\u03c3 .\nProof. W.l.o.g., we assume \u03a0 = Q\u03b1 . If D : \u03b1+ , \u03be + is material, it means that for each t \u2208 D,\n\u22a5\nwe have t = pqq, with q \u2208 I(D, E, A) for a certain E \u2208 P\u22a5\n\u03be and a certain A \u2208 Q\u03b1 .\nLet us consider R = {\u03c3(D), E, E[\u03c3/\u03be], A} and R\u2032 = {D, E, A}. As discussed in the proof\nof Proposition 8.14, p \u2208 I(R) if and only if there is a \"corresponding\" p\u2032 \u2208 I(R\u2032 ), where p\u2032\nis obtained from p by the operation of renaming of pointing strings described in the proof\nof Proposition 8.14.\nNow, let us consider a view s \u2208 \u03c3(D) : \u03b1+ , \u03be + , \u03c3 + . We have that s\u2032 \u2208 D (where s\u2032 is\nobtained from s by the same operation of renaming), and since D is material, s\u2032 = pqq for\n\n\f60\n\nM. BASALDELLA AND C. FAGGIAN\n\nq \u2208 I(D, E, A), where E and A are those provided by the materiality of D. Let p be the\npointing string such that q = p\u2032 . We conclude that s = ppq, for p \u2208 I(\u03c3(D), E, E[\u03c3/\u03be], A).\nLemma 11.19. Let P\u03c3 = F+ (N\u03c31 , . . . , N\u03c3n ), D = D1 \u2022 * * * \u2022 Dn \u2208 \u22a2 \u03a0, P\u03c3 , and Di \u2208 \u22a2\n\u03a0, N\u03c3i . If D1 \u2022 * * * \u2022 Dn is material in \u22a2 \u03a0, P\u03c3 , then each Di is material in \u22a2 \u03a0, N\u03c3i .\nProof. For concreteness, we only discuss the case \u03a0 = Q, and n = 2 (the general case being\na simple generalization). Let D = x+ .{D1 , D2 } (we recall that x occurs linearly in D). For\n\u22a5\n\u22a5\neach x\u2212 .E \u2208 P\u22a5\n\u03c3 , we have by internal completeness (Proposition 10.8) that E \u2208 \u22a2 N\u03c31 , N\u03c32 ;\n\u22a5\nmoreover for each A \u2208 Q , [[Di , A]] \u2208 N\u03c3i .\nLet s \u2208 D1 . By construction, x+ .s is a view in D, and since D is material, x+ .s belongs\n\u22a5\nto D[x\u2212 .E, A], for a certain x\u2212 .E \u2208 P\u22a5\n\u03c3 and a certain A \u2208 Q (we restrict our attention\n\u22a5\nto single-rooted strategies in P\u03c3 , thanks to Lemma 10.10). It is then straightforward to\ncheck that if x+ .s is used in the interaction which produces [[x+ .{D1 , D2 }, x\u2212 .E, A]], then s\nis used in the interaction which produces [[D1 , F, A]], where F := [[E, D2 , A]] \u2208 N\u22a5\n\u03c31 .\nLemma 11.20. Let N\u03be = F\u2212 (P\u03be1 , . . . , P\u03ben ). If x\u2212 .D \u2208 \u22a2 \u03a0, N\u03be is material, then D \u2208 \u22a2\n\u03a0, P\u03be1 , . . . , P\u03ben is material.\nProof. The argument is similar to the one for Lemma B.1(2), or rather it is its inverse. The\nonly subtlety is that to ensure that the root of the counter-strategy we fix in N\u22a5\n\u03be is linear,\nwe need to go through some lengthy but straightforward steps of renaming (which we omit\nhere) by repeated use of Proposition 8.14.\n12. Conclusion\nIn this work, we started by recalling the standard notion of HO strategy and we have\nshown how ludics strategies can be expressed in term HO strategies by giving an universal\narena. We have revised the main results of the higher-level part of ludics (namely, internal\ncompleteness) giving direct proofs of them using basic properties of the dynamics only.\nWe have motivated and introduced the notion of non-uniform strategy and shown that\nwe still have a suitable form of internal completeness when strategies are non-linear and\nnon-uniform. From this, we finally have shown a full completeness result with respect to\nMELLS.\nRelated and future work.\nMaurel's exponentials. Maurel [32] has built a sophisticated setting to recover a form of separation when having repetitions in ludics; however, the complexity of the setting prevented\nhim from going further and studying interpretation and full completeness issues. In this\npaper, we ignore separation all together, and in fact we show that we don't need it in order\nto have interactive types and internal completeness. In future work, we hope it may be possible to refine our setting by using Maurel's techniques. In Maurel's setting, strategies have\na quantitative information carried by probabilistic values (called coefficients). The values\nin the coefficients have a central role, and must satisfy a set of \"quantitative conditions\" inspired by measure theory. This is fundamentally different from our \"indexed silent actions\",\nas the specific natural number which is chosen as index for a silent action is irrelevant (in\nparticular, all the indexes can be interchanged, and this does not affect orthogonality), and\n\n\fLUDICS WITH REPETITIONS\n\n61\n\nthere are no condition attached. Our indexed silent actions have the same role as in [41].\nHowever, in a way, we think that our approach could be seen as a simplification - or rather\na kind of quotient - on Maurel's coefficients; on this grounds, we hope it may be possible\nto refine our silent actions by attaching probabilities to them, without losing our high-level\nresults.\nAJM style exponentials for ludics. A different solution that uses AJM style exponentials has\nbeen studied by the first of the two authors in [4]. Essentially, the strategies which inhabit\na semantical type !N A are those of the form (D, 1) \u222a (E, 2) \u222a . . . : an indexed (and disjoint)\nsuperimposition of strategies D, E, . . . of A. However, the approach we use in this paper,\nwhich exploits similar ideas - namely the disjoint superimposition which is technically\nimplemented by using silent actions here - is considerably simpler, as we do not need to\nconsider further (rather complex) \"uniformity\" conditions to discriminate those strategies\nwhich are interpretations of syntactical derivations; here the \"uniform strategies\" are simply\nthe deterministic strategies. We think that the approach to repetitions we implement in\nthis paper is more suitable for more applicative uses of ludics [15, 38, 39].\nComputational ludics. By using the approach we present in this paper, Basaldella and\nTerui [6] have recently extended Terui's computational ludics [39] in order to accommodate\nexponentials.\nTheir paper is aimed at analyzing the traditional logical duality between proofs and\nmodels from the point of view of ludics and they get an alternative proof of full completeness\nbased on a direct construction of a counter-model. Very interestingly, that work also reveals\nan exciting property of the \"interactive types.\" Unlike in standard HO game semantics,\nfiniteness does not need to be requested as a condition for strategies to be winning; it\nis rather an outcome of the closure by orthogonality. In fact, Basaldella and Terui show\nthat any material, deterministic strategy in a behaviour which is interpretation of logical\nformula is finite. We are confident that this result is also valid our setting. However, a\ncareful verification of all the details is needed.\nNon-deterministic innocent strategies. They have been introduced by Harmer in [24], with\nthe purpose of modeling non-determinism (in PCF with erratic choice).\nIn this paper we introduce non-uniform strategies, which are realized by means of nondeterministic sums. However, the purpose of our non-deterministic sums is to implement\nnon-uniformity via \"formal sums\" of strategies, in order to provide enough tests to make\npossible the interactive approach of ludics. The different purpose is reflected in the composition, which is simpler in our setting, where is in fact reduced to deterministic composition.\nOur strategies could be seen as a \"concrete\" implementation of Harmer's solution, in a\nsimplified setting. Harmer overcomes the problems with composition moving from naive\nnon-deterministic strategies S : A \u2192 B to an \"indirect\" definition of strategies of the kind\nS : A \u00d7 N \u2192 B. We have instead silent actions, which can be seen as \u03c4 actions carrying\nan index i \u2208 N. These actions have a two-fold role: they guard the sum (as in [41]), and\nprovide an \"index of copy\" (as in AJM game semantics, but here the index is unfold only\nwhen needed), but do not go so far as to model non-determinism. In particular, we do not\nintroduce any quotient on the strategies.\n\n\f62\n\nM. BASALDELLA AND C. FAGGIAN\n\nGame semantics for linear logic. When we work with innocent strategies, in this paper we\nconsider the variant of HO strategies introduced in [31]. Having now enriched the setting\nof ludics with duplicative features, we want to make comparisons with other kinds of game\nsemantics for linear logic. In particular, we are interested in finding connections between\nour treatment of duplication and the resource modalities of games semantics introduced by\nMelli\u00e8s and Tabareau in [33].\nAbstract machines. Curien and Herbelin in [11] have studied composition of strategies as\nsets of views. In particular they have developed the View-Abstract-Machine (VAM) (see\nalso [8]) which is the device we use in this paper.\nAcknowledgement\nWe are in debt with Olivier Laurent for his sharp remarks and detailed suggestions which\nsignificantly contributed to improve an earlier version of our work. Many thanks to PierreLouis Curien, Kazushige Terui, Mauro Piccolo, for fruitful discussions and helpful suggestions. Finally, we gratefully acknowledge the anonymous referees whose in depth revision\nand many detailed comments have given an invaluable aid in improving the quality of this\npaper.\nReferences\n[1] Abramsky, S.: Axioms for definability and full completeness. In: Proof, Language, and Interaction\n(Essay in honor of Robin Milner) The MIT Press (2000) 55\u201376.\n[2] Abramsky, S., Jagadeesan, R., Malacaria, P.: Full Abstraction for PCF. Inf. Comput. 163(2) (2000)\n409\u2013470.\n[3] Andreoli, J.-M.: Logic Programming with Focusing Proof in Linear Logic. J. Log. Comput. 2(3) (1992)\n297\u2013347.\n[4] Basaldella, M.: On Exponentials in Ludics. PhD Thesis (2008) University of Siena.\n[5] Basaldella, M., Faggian, C.: Ludics with Repetitions (Exponentials, Interactive Types and Completeness). In: LICS. (2009) 375\u2013384.\n[6] Basaldella, M., Terui, K.: On the meaning of logical completeness. Logical Methods in Computer\nScience 6(4:11) (2010) 1\u201335.\n[7] Coquand, T.: A semantics of evidence for classical arithmetic. J. Symb. Log. 60(1) (1995) 325-337.\n[8] Curien, P.-L.: Abstract B\u00f6hm trees. Math. Struct. in Comp. Sci. 8(6) (1998) 559\u2013591.\n[9] Curien, P.-L.: Introduction to Linear Logic and Ludics, part II. Advances of Mathematics (China)\n35(1) (2006) 1\u201344.\n[10] Curien, P.-L.: Notes on game semantics. Manuscript (2006).\n[11] Curien, P.-L., Herbelin, H.: Abstract machines for dialogue games. Panoramas et Synth\u00e8ses 27 (2009)\n231\u2013275.\n[12] Faggian, C.: Travelling on designs. In: CSL. (2002) 427\u2013441.\n[13] Faggian, C., Fleury, M.-R., Quatrini, M.: An introduction to uniformity in Ludics. In: Linear logic\nin computer science, London Math. Soc. Lecture Note Ser., 316, Cambridge Univ. Press, Cambridge,\n(2004) 236\u2013246.\n[14] Faggian, C., Hyland, J.M.E.: Designs, disputes and strategies. In : CSL. (2002) 442\u2013457.\n[15] Faggian, C., Piccolo, M.: Ludics is a model for the finitary linear pi-calculus. In: TLCA. (2007) 148\u2013162.\n[16] Faggian, C., Piccolo, M.: Partial Orders, Event Structures, and Linear Strategies. In: TLCA. (2009)\n95\u2013111.\n[17] Girard, J.-Y.: Linear Logic. Theor. Comput. Sci. 50(1) (1987) 1\u2013102.\n[18] Girard, J.-Y.: Geometry of interaction I: Interpretation of System F. Logic Colloquium 88, In R. Ferro\net al., (1989) 221\u2013260.\n\n\fLUDICS WITH REPETITIONS\n\n63\n\n[19] Girard, J.-Y.: A New Constructive Logic: Classical Logic. Math. Struct. in Comp. Sci. 1(3) (1991)\n255\u2013296.\n[20] Girard, J.-Y.: On the meaning of logical rules I: syntax vs. semantics. Computational Logic (U. Berger\nand H. Schwichtenberg eds) Heidelberg Springer-Verlag (1999) 215 \u2013 272.\n[21] Girard, J.-Y.: On the meaning of logical rules II : multiplicatives and additives. Foundation of Secure\nComputation (2000) 183\u2013212.\n[22] Girard, J.-Y.: Locus solum: From the rules of logic to the logic of rules. Math. Struct. in Comp. Sci.\n11(3) (2001) 301\u2013506.\n[23] Girard, J.-Y.: Le Point Aveugle, Cours de logique, Tome II: Vers l'imperfection. Visions des Sciences.\nHermann (2007).\n[24] Harmer, R. S.: Games and Full Abstraction for Nondeterministic Languages. PhD Thesis (1999) University of London.\n[25] Harmer, R. S.: Innocent game semantics. Manuscript (2006).\n[26] Hyland, J.M.E., Ong, C.H.L.: On full abstraction for PCF: I, II, and III. Inf. Comput. 163(2) (2000)\n285\u2013408.\n[27] Hyland, J.M.E., Schalk, A.: Glueing and orthogonality for models of linear logic. Theor. Comput. Sci.\n294(1-2) (2003) 183\u2013231.\n[28] Krivine, J.-L.: Realizability in classical logic. Panoramas et Synth\u00e8ses 27 (2009) 197\u2013229.\n[29] Laurent, O.: \u00c9tude de la polarization en logique. PhD thesis, Universit\u00e9 Aix-Marseille II (2002).\n[30] Laurent, O.: Polarized games. Ann. Pure Appl. Logic 130(1-3) (2004) 79\u2013123.\n[31] Laurent, O.: Syntax vs. semantics: A polarized approach. Theor. Comput. Sci. 343(1-2) (2005) 177\u2013206.\n[32] Maurel, F.: Un cadre quantitatif pour la Ludique. PhD Thesis (2004) Universit\u00e9 Paris VII.\n[33] Melli\u00e8s, P.-A., Tabareau, N.: Resource modalities in game semantics. In: LICS. (2007) 389\u2013398.\n[34] Melli\u00e8s, P.-A., Vouillon, J.: Recursive Polymorphic Types and Parametricity in an Operational Framework. In: LICS. (2005) 82\u201391.\n[35] Nickau, H.: Hereditarily Sequential Functionals: A Game-Theoretic Approach to Sequentiality. PhD\nthesis, Universit\u00e4t GH Siegen (1996).\n[36] Paolini, L.: Parametric \u03bb-Theories. Theor. Comput. Sci. 398(1-3) (2008) 51\u201362.\n[37] Pitts, A.M.: Parametric polymorphism and operational equivalence. Math. Struct. in Comp. Sci. 10(3)\n(2000) 321\u2013359.\n[38] Saurin, A.: Towards Ludics Programming: Interactive Proof Search. In: ICLP. (2008) 253\u2013268.\n[39] Terui, K.: Computational ludics. To appear in Theor. Comput. Sci. (2008).\n[40] Yoshida, N., Berger, M., Honda, K.: Strong Normalisation in the pi-Calculus. In: LICS. (2001) 311\u2013322.\n[41] Varacca, D., Yoshida, N.: Typed Event Structures and the pi-Calculus: Extended Abstract. In: MFPS.\n(2006) 373\u2013397.\n\nAppendix A. Admissibility of the Cut-rule and expressivity of MELLS\nIn Section A.1 we prove that the cut-rule is admissible in MELLS.\nWe then discuss the expressivity of MELLS by relating it to more standard systems\n(in Sections A.2 and A.3). Since we are interested in clarifying the nature of the logical\nrules and sequents of MELLS, we omit the cut-rule in all system.\nIn the sequel we use extensively the following notions.\nDefinition A.1 (Depth, height). We define the depth of a formula F , noted by d(F ) as\nthe length of the longest branch of F in the obvious tree representation of F . More precisely,\nlet F be a formula in some language and G1 , . . . , Gn its immediate subformulas. We define\nd(F ) as the natural number inductively given by:\nd(F ) := sup{d(G1 ), . . . , d(Gn )} + 1.\nLet \u03c0 be a syntactical derivation of a sequent in some system. The height of \u03c0 , noted\nby h(\u03c0), is inductively given as follows: if \u03c0 ends with a rule whose premises are derived by\n\n\f64\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u03c01 , . . . , \u03c0n , then\nh(\u03c0) := sup{h(\u03c01 ), . . . , h(\u03c0n )} + 1.\nFor instance, if F (resp. \u03c0) is a formula (resp. derivation) in MELLS, we have that:\n\u2022 d(F ) = 1 if and only if either F = ?P I or F = !N ;\n\u2022 h(\u03c0) = 1 if and only if \u03c0 is of the form \u22a2 \u03a0, ?P I Pos0 for some \u03a0.\nThe following lemma is also useful in the sequel.\nT\n\nProposition A.2 (Structural rules).\n(1) Weakening: if \u22a2 \u0393 is cut-free derivable then \u22a2 \u0393, Q is cut-free derivable.\n(2) Contraction: if \u22a2 \u0393, Q, Q is cut-free derivable then \u22a2 \u0393, Q is cut-free derivable.\nProof.\n(1) Let \u03c0 a be derivation of \u22a2 \u0393. By induction on the height of \u03c0 we now construct a\nderivation \u03c0 \u2032 of \u22a2 \u0393, Q.\na. \u03c0 ends with a positive rule, where P = ?P (N1 \u2297 * * * \u2297 Nn ):\n..\n..\n. \u03c01\n. \u03c0n\n\u22a2 \u03a0, P, N1\n...\n\u22a2 \u03a0, P, Nn\nPosn\n\u22a2 \u03a0, P\nBy inductive hypothesis, \u03c0i\u2032 is a derivation of \u22a2 \u03a0, Q, P, Ni for any 1 \u2264 i \u2264 n. We\ncan then apply a rule Posn and obtain\n.. \u2032\n.. \u2032\n. \u03c01\n. \u03c0n\n\u22a2 \u03a0, Q, P, Nn\n\u22a2 \u03a0, Q, P, N1\n...\nPosn\n\u22a2 \u03a0, Q, P\nb. \u03c0 ends with a negative rule, where N = !N (P1 ` * * * ` Pn ):\n..\n.\u03c1\n\u22a2 \u03a0, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, N\nBy inductive hypothesis, \u03c1\u2032 is a derivation of \u22a2 \u03a0, Q, P1 , . . . , Pn . We can then apply\na rule Negn and obtain\n.. \u2032\n.\u03c1\n\u22a2 \u03a0, Q, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, Q, N\n(2) Let \u03c0 a be derivation of \u22a2 \u0393, Q, Q. By induction on the height of \u03c0 we now construct a\nderivation \u03c0 \u2032 of \u22a2 \u0393, Q.\na. \u03c0 ends with a positive rule,where the principal formula of Posn is (an occurrence of)\nsome formula P = ?P (N1 \u2297\n.. * * * \u2297 Nn ) in \u03a0, Q, Q: ..\n. \u03c0n\n. \u03c01\n\u22a2 \u03a0, Q, Q, Nn\n\u22a2 \u03a0, Q, Q, N1\n...\nPosn\n\u22a2 \u03a0, Q, Q\nBy inductive hypothesis, \u03c0i\u2032 is a derivation of \u22a2 \u03a0, Q, Ni for any 1 \u2264 i \u2264 n. Since P\nalso occurs in \u03a0, Q, we can then apply Posn and obtain\n\n\fLUDICS WITH REPETITIONS\n\n.. \u2032\n. \u03c01\n\u22a2 \u03a0, Q, N1\n\n65\n\n.. \u2032\n. \u03c0n\n\u22a2 \u03a0, Q, Nn\n\n...\nPosn\n\u22a2 \u03a0, Q\nb. \u03c0 ends with a negative rule, where N = !N (P1 ` * * * ` Pn ):\n..\n.\u03c1\n\u22a2 \u03a0, Q, Q, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, Q, Q, N\nBy inductive hypothesis, \u03c1\u2032 is a derivation of \u22a2 \u03a0, Q, P1 , . . . , Pn . We can then apply\nNegn rule and obtain\n.. \u2032\n.\u03c1\n\u22a2 \u03a0, Q, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, Q, N\n\nA.1. Admissibility of the Cut-rule. In this section we show that the cut-rule\n\u22a2 \u039e, \u03a0, P\n\u22a2 \u2206, P \u22a5\n\u22a2 \u039e, \u03a0, \u2206\n\nCut\n\nis admissible in MELLS (more precisely, the cut-rule is admissible in MELLS without\nCut).\nTheorem A.3 (Cut-elimination). Let \u03c0 and \u03c1 be cut-free derivations of \u22a2 \u039e, \u03a0, P and\n\u22a2 \u2206, P \u22a5 respectively. The sequent \u22a2 \u039e, \u03a0, \u2206 is derivable with a cut-free derivation \u03b8.\nProof. The proof by induction on the pair (d(P ), h(\u03c0)+h(\u03c1)) - where d(P ) and h(\u03c0) denote\nthe depth of the formula P and height of the derivation \u03c0 respectively (Definition A.1) -\nordered lexicographically: (d(P ), h(\u03c0) + h(\u03c1)) < (d(P \u2032 ), h(\u03c0 \u2032 ) + h(\u03c1\u2032 )) if and only if either\nd(P ) < d(P \u2032 ) or d(P ) = d(P \u2032 ) and h(\u03c0) + h(\u03c1) < h(\u03c0 \u2032 ) + h(\u03c1\u2032 ).\nObserve that we are assuming that \u03c0 and \u03c1 are cut-free derivations, this implies that\nthe last rule of \u03c1 is always a negative rule having P \u22a5 as principal formula.\nWe now give a procedure to obtain a cut-free derivation \u03b8 of \u22a2 \u039e, \u03a0, \u2206. We have three\ndistinct cases, depending on the last rule of \u03c0.\n(a) The last rule of \u03c0 is a positive rule Posn and P is principal in Posn .\nFor readability, we only consider the cases n = 0 and n = 2. The general n-ary case\nstraightforwardly follows.\nIf n = 0, then P = ?P I , P \u22a5 = !N and d(P ) = 1. We have derivations:\nT\n\nPos0\n\nT\n\n\u22a2 \u03a0, ?P I\n\n..\n. \u03c10\n\u22a2\u2206\n\u22a2 \u2206, !N\n\nNeg0\n\nThe cut-free derivation \u03b8 of \u22a2 \u03a0, \u2206, is obtained from \u03c10 by weakening, in the sense of\nProposition A.2 (1) (weakening on positive formulas).\nIf n = 2, then P = ?P (N1 \u2297 N2 ) and P \u22a5 = !N (N1\u22a5 ` N2\u22a5 ). We have derivations:\n\n\f66\n\nM. BASALDELLA AND C. FAGGIAN\n\n..\n..\n. \u03c02\n. \u03c01\n\u22a2 \u03a0, P, N2\n\u22a2 \u03a0, P, N1\n\u22a2 \u03a0, P\n\n..\n. \u03c10\nPos2\n\n\u22a2 \u2206, N1\u22a5 , N2\u22a5\n\u22a2 \u2206, P \u22a5\n\nNeg2\n\nWe now construct a cut-free derivation \u03b8 of \u22a2 \u03a0, \u2206 as follows.\nConsider for i \u2208 {1, 2} the following derivations:\n..\n. \u03c0i\n\u22a2 \u03a0, P, Ni\n\n..\n.\u03c1\n\u22a2 \u2206, P \u22a5\n\nSince h(\u03c0i ) < h(\u03c0), we have (d(P ), h(\u03c0i ) + h(\u03c1)) < (d(P ), h(\u03c0) + h(\u03c1)) and the induction\nhypothesis yields a cut-free derivation \u03c8i of \u22a2 \u03a0, \u2206, Ni . Consider now\n..\n. \u03c10\n\u22a2 \u2206, N1\u22a5 , N2\u22a5\n\n..\n. \u03c81\n\u22a2 \u03a0, \u2206, N1\n\nSince N1\u22a5 is an immediate subformula of P , we have d(N1\u22a5 ) < d(P ) and by induction we\nhave a cut-free derivation \u03b81 of \u22a2 \u03a0, \u2206, \u2206, N2\u22a5 . Similarly, from \u03b81 and \u03c82 we get a cut-free\nderivation \u03b82 of \u22a2 \u03a0, \u03a0, \u2206, \u2206, \u2206. From \u03b82 we finally obtain a cut-free derivation \u03b8 of \u22a2 \u03a0, \u2206\nby repeatedly applying Proposition A.2 (2) (contraction on positive formulas).\n(b) The last rule of \u03c0 is a positive rule Posn and P is not principal in Posn :\n..\n. \u03c01\n\u22a2 \u03a0, P, Q, N1\n\n...\n\u22a2 \u03a0, P, Q\n\n..\n. \u03c0n\n\u22a2 \u03a0, P, Q, Nn\n\n..\n.\u03c1\nPosn\n\n\u22a2 \u2206, P \u22a5\n\nand the principal formula of Posn is the occurrence of formula Q = ?P (N1 \u2297 * * * \u2297 Nn ). We\nnow define a cut-free derivation \u03b8 of \u22a2 \u03a0, Q, \u2206 as follows. For 1 \u2264 i \u2264 n consider pairs of\nderivations\n..\n. \u03c0i\n\u22a2 \u03a0, P, Q, Ni\n\n..\n.\u03c1\n\u22a2 \u2206, P \u22a5\n\nSince h(\u03c0i ) < h(\u03c0), we have (d(P ), h(\u03c0i ) + h(\u03c1)) < (d(P ), h(\u03c0) + h(\u03c1)) and by induction we\nget a cut-free derivation \u03c8i of \u22a2 \u03a0, Q, \u2206, Ni . We now apply Posn to the sequents derived\nby \u03c81 , . . . , \u03c8n , to obtain the cut-free derivation \u03b8 of \u22a2 \u03a0, Q, \u2206:\n..\n..\n. \u03c8n\n. \u03c81\n\u22a2 \u03a0, Q, \u2206, Nn\n\u22a2 \u03a0, Q, \u2206, N1\n...\nPosn\n\u22a2 \u03a0, Q, \u2206\nNotice that when n = 0 and hence Q = ?P I and h(\u03c0) = 1, we have that\n\n\fLUDICS WITH REPETITIONS\n\n67\n\n..\n.\u03c1\n\u22a2 \u03a0, P, ?P I\n\nPos0\n\n\u22a2 \u2206, P \u22a5\n\nPos0\n.\n\u22a2 \u03a0, \u2206, ?P I\n(c) The last rule of \u03c0 is a negative rule Negn , having N = !N (P1 ` * * * ` Pn ) as principal\nformula.\n..\n. \u03c00\n..\n.\u03c1\n\u22a2 \u03a0, P, P1 , . . . , Pn\n\nThe procedure described above gives the cut-free derivation\n\n\u22a2 \u03a0, P, N\n\nNegn\n\n\u22a2 \u2206, P \u22a5\n\nTo build a cut-free derivation of \u22a2 N, \u03a0, \u2206, we first consider\n..\n..\n.\u03c1\n. \u03c00\n\u22a2 \u03a0, P, P1 , . . . , Pn\n\u22a2 \u2206, P \u22a5\nSince h(\u03c00 ) < h(\u03c0), we have (d(P ), h(\u03c00 ) + h(\u03c1)) < (d(P ), h(\u03c0) + h(\u03c1)) and by induction we\nget a cut-free derivation \u03c8 of \u22a2 \u03a0, P1 , . . . , Pn , \u2206. Applying Negn , we finally get a cut-free\nderivation \u03b8 of \u22a2 N, \u03a0, \u2206\n..\n.\u03c8\n\u22a2 \u03a0, P1 , . . . , Pn , \u2206\nNegn\n\u22a2 N, \u03a0, \u2206\nBy using the previous theorem, we have:\nCorollary A.4. If \u22a2 \u0393 is derivable in MELLS then \u22a2 \u0393 is derivable in MELLS without\nCut.\nProof. By induction on the height of a derivation \u03c0 of \u22a2 \u0393. Suppose that \u03c0 ends with:\n..\n. \u03c01\n\u22a2 \u039e1 , \u03a01\n\n...\n\u22a2 \u039e, \u03a0\n\n..\n. \u03c0k\n\u22a2 \u039ek , \u03a0k\n\nRule\n\nBy inductive hypothesis, we have cut-free derivations \u03c8i of \u22a2 \u039ei , \u03a0i , for any 1 \u2264 i \u2264 k.\nIf Rule is not Cut, we apply it to the sequents \u22a2 \u039ei , \u03a0i derived from \u03c8i and get a cut-free\nderivation of the conclusion. If Rule is Cut (and hence k = 2), from the cut-free derivations\n\u03c81 and \u03c82 we get a cut-free derivation of the conclusion, by means of Theorem A.3.\nA.2. MELLS related to the intuitionistic sequent calculus LJ. We show a correspondence between the calculus MELLS and a fragment of intuitionistic logic sequent calculus\nLJ, that we call LJ0 , in which any formula is (hereditarily) a negation of a (possibly empty)\nconjunction of formulas.\n\n\f68\n\nM. BASALDELLA AND C. FAGGIAN\n\nThe main motivation for doing this is that in LJ0 we can employ the bilateral presentation of intuitionistic sequents - with at most one formula on the right side of the\nentailment symbol - to represent, in a more traditional way, the asymmetry between the\npolarized formulas of MELLS.\nFormulas of LJ0 are given by the following grammar:\nA ::= \u00ac(A1 \u2227 * * * \u2227 An )\n\n(n \u2265 0).\n\n5\n\nWe write \u00ac\u22a4 when n = 0.\nAnalogously to the standard calculus LJ, a sequent of LJ0 is a pair of (possibly empty)\nmulti-sets of formulas \u03a0, \u039e, written \u03a0 \u22a2int \u039e, such that \u039e contains at most one (occurrence\nof) formula.\nThe calculus LJ0 consists of two kinds of rules. They are given in Table 4.\n\u03a0, A \u22a2int A1\n\nLeft rules :\nA = \u00ac(A1 \u2227 * * * \u2227 An ) and n \u2265 0\n\n...\n\u03a0, A \u22a2int An\n\u03a0, A \u22a2int\n\n\u03a0, A1 , . . . , An \u22a2int\n\u03a0 \u22a2int A\n\nRight rules :\nA = \u00ac(A1 \u2227 * * * \u2227 An ) and n \u2265 0\n\nLn\n\nRn\n\nTable 4: LJ0\nIn particular, when n = 0 we have:\n\u03a0, \u00ac\u22a4 \u22a2int\n\nA.2.1. From MELLS to LJ0 . The translation\nLJ0 is given as follows.\n?P (N1 \u2297 * * * \u2297 Nn )\n\n\u2217\n\n\u03a0 \u22a2int\n\u03a0 \u22a2int \u00ac\u22a4\n\nL0\n\n\u2217\n\nR0\n\nof formulas of MELLS into formulas of\n\n:= \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 ); !N (P1 ` * * * ` Pn )\n\n\u2217\n\n:= \u00ac(P1\u2217 \u2227 * * * \u2227 Pn\u2217 ).\n\nGiven a multi-set \u0393 = F1 , . . . , Fn of formulas of of MELLS we denote by \u0393\u2217 the multi-set\nF1\u2217 , . . . , Fn\u2217 of formulas of LJ0 .\nGiven a sequent \u22a2 \u03a0, \u039e of MELLS, where \u03a0 is a multi-set of positive formulas and \u039e\nis either empty of it consists of exactly of one (occurrence of) negative formula, we define\n\u22a2 \u03a0, \u039e \u2217 := \u03a0\u2217 \u22a2int \u039e\u2217 .\nWe have the following:\nProposition A.5. If \u22a2 \u03a0, \u039e is derivable in MELLS then \u22a2 \u03a0, \u039e\n\n\u2217\n\nis derivable in LJ0 .\n\nProof. By induction on the height of the derivation \u03c0 of \u22a2 \u03a0, \u039e in MELLS.\n\u2022 \u03c0 ends with a positive rule, where P = ?P (N1 \u2297 * * * \u2297 Nn ).\n5We chose the symbol \u22a4 because \u22a4 usually denotes the nullary version of \u2227. Consistently, we write \u00ac\u22a4\nfor the nullary version of \u00ac(A1 \u2227 * * * \u2227 An ).\n\n\fLUDICS WITH REPETITIONS\n\n\u22a2 \u03a0, P, N1\n\n...\n\u22a2 \u03a0, P, Nn\n\u22a2 \u03a0, P\nBy inductive hypothesis, we have derivable sequents\n\u22a2 \u03a0, P, Ni\n\n\u2217\n\n69\n\nPosn\n\n= \u03a0\u2217 , \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 ) \u22a2int Ni\u2217 ,\n\nfor any 1 \u2264 i \u2264 n. We can then apply Ln -rule and obtain\n...\n\u03a0\u2217 , \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 ) \u22a2int Nn\u2217\n\u03a0\u2217 , \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 ) \u22a2int N1\u2217\n\u03a0\u2217 , \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 ) \u22a2int\nSince \u22a2 \u03a0, P \u2217 = \u03a0\u2217 , \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 ) \u22a2int , we are done.\n\u2022 \u03c0 ends with a negative rule, where N = !N (P1 ` * * * ` Pn ).\n\u22a2 \u03a0, P1 , . . . , Pn\n\u22a2 \u03a0, N\nBy inductive hypothesis, the sequent\n\u22a2 \u03a0, P1 , . . . , Pn\n\n\u2217\n\nLn\n\nNegn\n\n= \u03a0\u2217 , P1\u2217 , . . . , Pn\u2217 \u22a2int\n\nis derivable. We can then apply Rn -rule and obtain\n\u03a0\u2217 , P1\u2217 , . . . , Pn\u2217 \u22a2int\nRn\n\u22a2int \u00ac(P1\u2217 \u2227 * * * \u2227 Pn\u2217 )\n\u00ac(P1\u2217 \u2227 * * * \u2227 Pn\u2217 ), we are done.\n\u03a0\u2217\n\nSince \u22a2 \u03a0, N\n\n\u2217\n\n= \u03a0\u2217 \u22a2int\n\nA.2.2. From LJ0 to MELLS. We also define an inverse translation \u2666 as follows.\nWe first define two translations, noted by p and n , from formulas of LJ0 to positive and\nnegative formulas of MELLS respectively:\n\u00ac(A1 \u2227 * * * \u2227 An )\n\np\n\n:= ?P (An1 \u2297 * * * \u2297 Ann ); \u00ac(A1 \u2227 * * * \u2227 An )\n\n:= !N (Ap1 ` * * * ` Apn ).\n\nn\n\nIn particular, \u00ac\u22a4 p = ?P I . Notice also that Ap = (An )\u22a5 .\nGiven a multi-set \u0393 = A1 , . . . , An of formulas of LJ0 we write \u0393p (resp. \u0393n ) for Ap1 , . . . , Apn\n(resp. An1 , . . . , Ann ). Given a sequent \u03a0 \u22a2int \u039e of LJ0 we define \u03a0 \u22a2int \u039e \u2666 := \u22a2 \u03a0p , \u039en .\nNotice that \u03a0 \u22a2int \u039e \u2666 is always a sequent of MELLS, since it contains at most one\n(occurrence of) negative formula \u039en .\nWe have:\nProposition A.6. If \u03a0 \u22a2int \u039e is derivable in LJ0 then \u03a0 \u22a2int \u039e\n\n\u2666\n\nis derivable in MELLS.\n\nProof. By induction on the height of a derivation \u03c0 of \u03a0 \u22a2int \u039e in LJ0 .\n\u2022 \u03c0 ends with a left rule, where A = \u00ac(A1 \u2227 * * * \u2227 An ).\n\u03a0, A \u22a2int A1\n\n...\n\u03a0, A \u22a2int An\n\u03a0, A \u22a2int\nBy inductive hypothesis, we have derivable sequents\n\u03a0, A \u22a2int Ai\n\n\u2666\n\nLn\n\n= \u22a2 \u03a0p , ?P (An1 \u2297 * * * \u2297 Ann ), Ani ,\n\nfor any 1 \u2264 i \u2264 n. We can then apply Posn -rule and obtain\n...\n\u22a2 \u03a0p , ?P (An1 \u2297 * * * \u2297 Ann ), Ann\n\u22a2 \u03a0p , ?P (An1 \u2297 * * * \u2297 Ann ), An1\n\u22a2 \u03a0p , ?P (An1 \u2297 * * * \u2297 Ann )\nSince \u03a0, A \u22a2int\n\n\u2666\n\n= \u22a2 \u03a0p , ?P (An1 \u2297 * * * \u2297 Ann ), we conclude the argument.\n\nPosn\n\n\f70\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u2022 \u03c0 ends with a right rule, where A = \u00ac(A1 \u2227 * * * \u2227 An ).\n\u03a0, A1 , . . . , An \u22a2int\n\u03a0 \u22a2int A\nBy inductive hypothesis, the sequent\n\u03a0, A1 , . . . , An \u22a2int\n\n\u2666\n\nRn\n\n= \u22a2 \u03a0p , Ap1 , . . . , Apn\n\nis derivable. Applying Negn -rule we obtain\n\u22a2 \u03a0p , Ap1 , . . . , Apn\n\u22a2 \u03a0p , !N (Ap1 ` * * * ` Apn )\nSince \u03a0 \u22a2int A\n\n\u2666\n\nNegn\n\n= \u22a2 \u03a0p , !N (Ap1 ` * * * ` Apn ), we conclude the argument.\n\nA.2.3. Composing \u2217 and \u2666 . We can finally show that the translations \u2217 and \u2666 are the inverse\nof each other, in the sense we are now going to make precise.\nWe first show the following lemma.\nLemma A.7.\n(1) For any positive formula P of MELLS, we have (P \u2217 )p = P . Similarly, for any negative\nformula N , we have (N \u2217 )n = N .\n(2) For any formula A of LJ0 , we have (Ap )\u2217 = (An )\u2217 = A.\n(3) For any sequent \u22a2 \u0393 of MELLS, we have (\u22a2 \u0393 \u2217 )\u2666 = \u22a2 \u0393.\n(4) For any sequent \u03a0 \u22a2int \u039e of LJ0 , we have (\u03a0 \u22a2int \u039e \u2666 )\u2217 = \u03a0 \u22a2int \u039e.\nProof.\n(1) By induction on the depth of F .\nLet P = ?P (N1 \u2297 * * * \u2297 Nn ). We have (P \u2217 )p = \u00ac(N1\u2217 \u2227 * * * \u2227 Nn\u2217 )p = ?P ((N1\u2217 )n \u2297\n* * * \u2297 (Nn\u2217 )n ), and by inductive hypothesis we conclude the argument. Similarly, let\nN = !N (P1 ` * * * ` Pn ). We have (N \u2217 )n = \u00ac(P1\u2217 \u2227 * * * \u2227 Pn\u2217 )n = !N ((P1\u2217 )p ` * * * ` (Pn\u2217 )p ),\nand again by inductive hypothesis we conclude the argument.\n(2) By induction on the depth of A = \u00ac(A1 \u2227 * * * \u2227 An ).\nWe have (Ap )\u2217 = ?P (An1 \u2297 * * * \u2297 Ann )\u2217 = \u00ac((An1 )\u2217 \u2227 * * * \u2227 (Ann )\u2217 ), and by inductive\nhypothesis we conclude the argument. Similarly, (An )\u2217 = !N (Ap1 `* * *`Apn)\u2217 = \u00ac((Ap1 )\u2217 \u2227\n* * * \u2227 (Apn )\u2217 ) and again by inductive hypothesis we conclude the argument.\n(3) Let \u22a2 \u0393 =\u22a2 P1 , . . . , Pn , \u039e. We have (\u22a2 P1 , . . . , Pn , \u039e \u2217 )\u2666 = (P1\u2217 , . . . , Pn\u2217 \u22a2int \u039e\u2217 )\u2666 =\n\u22a2 (P1\u2217 )p , . . . , (Pn\u2217 )p , (\u039e\u2217 )n , and by point (1) above we conclude the argument.\n(4) If \u03a0 \u22a2int \u039e = A1 , . . . , An \u22a2int \u039e, we get (A1 , . . . , An \u22a2int \u039e \u2666 )\u2217 = (\u22a2 Ap1 , . . . , Apn , \u039en )\u2217 =\n(Ap1 )\u2217 , . . . , (Apn )\u2217 \u22a2int (\u039en )\u2217 , and by point (2) above we conclude the argument.\nGiven a derivation \u03c0 of a sequent \u22a2 \u03a0, \u039e of MELLS we denote by \u03c0 \u2217 the derivation of\nthe sequent \u22a2 \u03a0, \u039e \u2217 of LJ0 given by Proposition A.5. Similarly, given a derivation \u03c0 of\na sequent \u03a0 \u22a2int \u039e of LJ0 we denote by \u03c0 \u2666 the derivation of the sequent \u03a0 \u22a2int \u039e \u2666 of\nMELLS given by Proposition A.6.\nWe can finally show the following:\nTheorem A.8.\n(1) (\u03c0 \u2217 )\u2666 = \u03c0;\n(2) (\u03c0 \u2666 )\u2217 = \u03c0.\n\n\fLUDICS WITH REPETITIONS\n\n71\n\nProof.\n(1) By induction on the height of the derivation \u03c0 of a sequent \u22a2 \u03a0, \u039e of MELLS.\nSuppose that \u03c0 ends with\n..\n..\n. \u03c0n\n. \u03c01\n\u22a2 \u03a0n , \u039en\n\u22a2 \u03a01 , \u039e1\n...\nRule\n\u22a2 \u03a0, \u039e\nBy Proposition A.5, we get the derivation \u03c0 \u2217 ending with\n.. \u2217\n.. \u2217\n. \u03c01\n. \u03c0n\n\u2217\n\u2217\n\u2217\n\u03a0n \u22a2int \u039e\u2217n\n...\n\u03a01 \u22a2int \u039e1\nRule\u2217\n\u2217\n\u2217\n\u03a0 \u22a2int \u039e\nand by Proposition A.6 we finally get the derivation (\u03c0 \u2217 )\u2666 ending with\n.. \u2217 \u2666\n.. \u2217 \u2666\n. (\u03c01 )\n. (\u03c0n )\nn\np\n\u2217\n\u2217\n\u22a2 (\u03a0\u2217n )p , (\u039e\u2217n )n\n...\n\u22a2 (\u03a01 ) , (\u039e1 )\n(Rule\u2217 )\u2666\n\u22a2 (\u03a0\u2217 )p , (\u039e\u2217 )n\nBy Lemma A.7 (3), \u22a2 (\u03a0\u22171 )p , (\u039e\u22171 )n = \u22a2 \u03a01 , \u039e1 , . . . , \u22a2 (\u03a0\u2217n )p , (\u039e\u2217n )n = \u22a2 \u03a0n , \u039en and\n\u22a2 (\u03a0\u2217 )p , (\u039e\u2217 )n = \u22a2 \u03a0, \u039e. It is immediate to verify that the principal and the auxiliary\n(occurrences of) formulas of Rule are exactly the same of (Rule\u2217 )\u2666 , and hence the two\nexpressions denote the same rule. By inductive hypothesis (\u03c01\u2217 )\u2666 = \u03c01 ,. . . ,(\u03c0n\u2217 )\u2666 = \u03c0n .\nWe can finally conclude (\u03c0 \u2217 )\u2666 = \u03c0.\n(2) By induction on the height of the derivation \u03c0 of a sequent \u03a0 \u22a2int \u039e of LJ0 .\nSuppose that \u03c0 ends with\n..\n..\n. \u03c01\n. \u03c0n\n\u03a01 \u22a2int \u039e1\n...\n\u03a01 \u22a2int \u039en\nRule\n\u03a0 \u22a2int \u039e\nBy Proposition A.6, we get the derivation \u03c0 \u2666 ending with\n.. \u2666\n.. \u2666\n. \u03c01\n. \u03c0n\n\u22a2 \u03a0p1 , \u039en1\n\n...\n\u22a2 \u03a0pn , \u039enn\n\u22a2 \u03a0p , \u039en\n\nRule\u2666\n\nand by Proposition A.5 we finally get the derivation (\u03c0 \u2666 )\u2217 ending with\n.. \u2666 \u2217\n. (\u03c01 )\n\n.. \u2666 \u2217\n. (\u03c0n )\n\n(\u03a0p1 )\u2217 \u22a2int (\u039en1 )\u2217\n...\n(\u03a0pn )\u2217 \u22a2int (\u039enn )\u2217\n(Rule\u2666 )\u2217\n(\u03a0p )\u2217 \u22a2int (\u039en )\u2217\nBy Lemma A.7 (4), (\u03a0p1 )\u2217 \u22a2int (\u039en1 )\u2217 = \u03a01 \u22a2int \u039e1 , . . . , (\u03a0pn )\u2217 \u22a2int (\u039enn )\u2217 = \u03a0n \u22a2int \u039en\nand (\u03a0p )\u2217 \u22a2int (\u039en )\u2217 = \u03a0 \u22a2int \u039e. As before, it is immediate to verify that the principal\nand the auxiliary (occurrences of) formulas of Rule are exactly the same of (Rule\u2666 )\u2217 , and\nhence they denote the same rule. By inductive hypothesis (\u03c01\u2666 )\u2217 = \u03c01 ,. . . ,(\u03c0n\u2666 )\u2217 = \u03c0n .\nWe finally conclude (\u03c0 \u2666 )\u2217 = \u03c0.\n\n\f72\n\nM. BASALDELLA AND C. FAGGIAN\n\nA.3. On the expressivity of MELLS. In this part, we discuss the relation between\nMELLS and some other (more standard) polarized variants of MELL (see also [6]).\nA.3.1. MELLpol . We first recall the syntax of MELLpol [29], the fragment of MELL given\nby the following data.\nFormulas of MELLpol are the polarized formulas given by the following grammar:\nPositive formulas : P ::= 1 | P \u2297 P | !N\nNegative formulas : N ::= \u22a5 | N ` N | ?P\nRules of MELLpol are the standard rules of MELL (Table 1) applied to sequents containing polarized formulas.\nFor our purposes, it is convenient to redefine the syntax of MELLpol by considering\nformulas in a certain canonical form, using the syntactical isomorphisms of linear logic\n(A \u2297 B) \u2297 C \u223c\nA\u22971\u223c\n= A \u2297 (B \u2297 C),\n= A,\n(A ` B) ` C \u223c\n= A ` (B ` C),\nWe redefine the formulas of MELLpol as follows:\nPositive formulas :\nNegative formulas :\n\nP ::= !M\nN ::= ?Q\n\nA`\u22a5\u223c\n= A.\nQ ::= P1 \u2297 * * * \u2297 Pn (n \u2265 0)\nM ::= N1 ` * * * ` Nn (n \u2265 0)\n\nThe constant 1 (resp. \u22a5) is given by P1 \u2297 * * * \u2297 Pn (resp. N1 ` * * * ` Nn ) with n = 0.\nNotice that in this reformulation we now allow the unary tensor \"\u2297!M\" and par \"`?Q.\"\nWe also point out that \u2297!M is different from !M as they have different outermost connectives.\nSimilarly, `?Q is different from ?Q. On the other hand, we do not have formulas like\n?(!(?(. . .))). This is not a big loss, since we can consider formulas of the form ?(\u2297!(`?(. . .)))\nin place of them.\nThe rules are almost the same we gave for MELL. The only difference is that we here\nconsider tensor and par rules of any arity n \u2265 0. They are given in Table 5.\n\nMultiplicative rules\n\n\u22a2 \u03931 , P1\n...\n\u22a2 \u0393n , Pn\n\u22a2 \u03931 , . . . , \u0393n , P1 \u2297 * * * \u2297 Pn\n\u22a2 \u0393, N1 , . . . , Nn\n\u22a2 \u0393, N1 ` * * * ` Nn\n\nExponential and structural rules\n\n\u22a2 N1 , . . . , Nn , M\n\u22a2 N1 , . . . , Nn , !M\n\u22a2\u0393\n\u22a2 \u0393, N\n\nTable 5: MELLpol\n\nW\n\n!\n\n\u2297n\n\n`n\n\n\u22a2 \u0393, Q\n\u22a2 \u0393, ?Q\n\n\u22a2 \u0393, N, N\n\u22a2 \u0393, N\n\nC\n\n?\n\n\fLUDICS WITH REPETITIONS\n\n73\n\nThe following lemmas are useful in the sequel.\nLemma A.9. If the sequent \u22a2 \u0393 is derivable in MELLpol then \u0393 contains at most one\noccurrence of positive formulas.\nProof. By induction on the height of a derivation \u03c0 of \u22a2 \u0393.\n\u2022 Suppose that \u03c0 ends with a \u2297n -rule. By inductive hypothesis, since Pi is positive, any\n\u0393i consists of negative formulas only. Hence, in final sequent, P1 \u2297 * * * \u2297 Pn is the only\noccurrence of positive formula.\n\u2022 Suppose that \u03c0 ends with a `n -rule. In this case, the number of occurrence of positive\nformulas in the premise is the same as in the conclusion.\n\u2022 Suppose that \u03c0 ends with the !-rule. In this case, there is no occurrence of positive\nformula in the premise and exactly one in the conclusion.\n\u2022 Suppose that \u03c0 ends with the ?-rule. In this case, there exactly one occurrence of positive\nformula in the premise and none in the conclusion.\n\u2022 Suppose that \u03c0 ends with a structural rule W or C. In this case the number of occurrence\nof positive formulas in the premise is the same as in the conclusion.\nLemma A.10. If \u22a2 \u0393, N1 ` * * * ` Nm is derivable then \u22a2 \u0393, N1 , . . . , Nm is derivable.\nProof. By induction on the height of the derivation \u03c0 of \u22a2 \u0393, N1 ` * * * ` Nm , we construct a\nderivation \u03c0 \u2032 of \u22a2 \u0393, N1 , . . . , Nm as follows.\n\u2022 Suppose that \u03c0 ends with\n..\n..\n..\n. \u03c01\n. \u03c0i\n. \u03c0n\n\u22a2 \u03931 , P1\n...\n\u22a2 \u0393i , N1 ` * * * ` Nm , Pi\n...\n\u22a2 \u0393n , Pn\n\u2297n\n\u22a2 \u03931 , . . . , \u0393i , N1 ` * * * ` Nm , . . . , \u0393n , P1 \u2297 * * * \u2297 Pn\nBy inductive hypothesis, \u03c0i\u2032 derives \u22a2 \u0393i , N1 , . . . , Nm , Pi . We take\n.. \u2032\n..\n..\n. \u03c01\n. \u03c0n\n. \u03c01\n\u22a2 \u0393n , Pn\n...\n\u22a2 \u0393i , N1 , . . . , Nm , Pi\n...\n\u22a2 \u03931 , P1\n\u22a2 \u03931 , . . . , \u0393i , N1 , . . . , Nm , . . . , \u0393n , P1 \u2297 * * * \u2297 Pn\n\u2022 Suppose that \u03c0 ends with a `k -rule. We distinguish two subcases.\nIf N1 ` * * * ` Nm is the principal formula in the last rule\n..\n. \u03c00\n\u22a2 \u0393, N1 , . . . , Nm\n`m\n\u22a2 \u0393, N1 ` * * * ` Nm\nwe take the derivation \u03c0 \u2032 = \u03c00 .\nOtherwise, N1 ` * * * ` Nm is not the principal formula in the last rule\n..\n. \u03c00\n\u22a2 \u0393, N1 ` * * * ` Nm , N\u20321 , . . . , N\u2032n\n`n\n\u22a2 \u0393, N1 ` * * * ` Nm , N\u20321 ` * * * ` N\u2032n\nBy inductive hypothesis, \u03c00\u2032 derives \u22a2 \u0393, N1 , . . . , Nm , N\u20321 , . . . , N\u2032n . We take\n\n\u2297n\n\n\f74\n\nM. BASALDELLA AND C. FAGGIAN\n\n.. \u2032\n. \u03c00\n\u22a2 \u0393, N1 , . . . , Nm , N\u20321 , . . . , N\u2032n\n\u22a2 \u0393, N1 , . . . , Nm , N\u20321 ` * * * ` N\u2032n\n\u2022 Suppose that \u03c0 ends with Rule \u2208 {?,W,C}\n\n`n\n\n..\n. \u03c00\n\u22a2 \u0393\u2032 , N1 ` * * * ` Nm\nRule\n\u22a2 \u0393, N1 ` * * * ` Nm\nBy inductive hypothesis, \u03c00\u2032 derives \u22a2 \u0393\u2032 , N1 , . . . , Nm . We take\n.. \u2032\n. \u03c00\n\u2032\n\u22a2 \u0393 , N1 , . . . , Nm\nRule\n\u22a2 \u0393, N1 , . . . , Nm\nWe finally observe that there are no other cases: due to the presence of N1 ` * * * ` Nm in\nthe final sequent, \u03c0 cannot end with the !-rule.\nA.3.2. MELL\u2217pol . The next step is to consider the following subsystem of MELLpol that\nwe call MELL\u2217pol .\nFormulas of MELL\u2217pol are the same of MELLpol but sequents are now multi-set of\nformulas of the form \u22a2 \u2206 = \u22a2 N1 , . . . , Nk\u22121 , Fk , for some k \u2265 0. In other words, a sequent\nof MELL\u2217pol contains at most one occurrence of formulas which is not a ?-formula. In some\ncases we also denote a sequent of MELL\u2217pol by \u22a2 ?\u0393, F.\nThe rules of MELL\u2217pol are the same of MELLpol , with the obvious modifications due\nto the constraint on sequents. They are given in Table 6.\n\nMultiplicative rules\n\n\u22a2 ?\u03931 , P1\n...\n\u22a2 ?\u0393n , Pn\n\u22a2 ?\u03931 , . . . , ?\u0393n , P1 \u2297 * * * \u2297 Pn\n\u22a2 ?\u0393, N1 , . . . , Nn\n\u22a2 ?\u0393, N1 ` * * * ` Nn\n\nExponential and structural rules\n\n\u22a2 ?\u0393, M\n\u22a2 ?\u0393, !M\n\u22a2\u2206\n\u22a2 \u2206, N\n\nW\n\n!\n\n\u2297n\n\n`n\n\n\u22a2 ?\u0393, Q\n\u22a2 ?\u0393, ?Q\n\n?\n\n\u22a2 \u2206, N, N\n\u22a2 \u2206, N\n\nC\n\nTable 6: MELL\u2217pol\nThe main consequence of restriction on the shape of sequents is that a sequent of the form\n\n\fLUDICS WITH REPETITIONS\n\n75\n\n\u22a2 ?\u0393, ?Q, N1 ` * * * ` Nn\ncannot be inferred using the ?-rule on Q, as the resulting premise\n\u22a2 ?\u0393, Q, N1 ` * * * ` Nn\nwhich is a sequent in MELLpol , would not be a sequent of MELL\u2217pol .\nClearly, if \u22a2 \u2206 is derivable in MELL\u2217pol , then \u22a2 \u2206 is derivable in MELLpol . But we\nalso have the converse.\nProposition A.11. If \u22a2 \u2206 is derivable in MELLpol then \u22a2 \u2206 is derivable in MELL\u2217pol .\nBy induction on the height of a derivation \u03c0 of \u22a2 \u2206 in MELLpol we construct a\nderivation \u03c0 \u2217 of \u22a2 \u2206 in MELL\u2217pol . There are several cases to analyze.\nStructural rules: \u03c0 ends with a structural rule Rule \u2208 {W,C}:\n..\n. \u03c00\n\u22a2 \u2206\u2032 Rule\n\u22a2\u2206\nSince structural rules only affect ?-formulas, it is clear that \u22a2 \u2206\u2032 is a sequent of MELL\u2217pol .\nThe inductive hypothesis yields a derivation \u03c00\u2217 of the premise. We can then apply Rule\nand conclude.\nPositive case: Suppose that \u22a2 \u2206 contains an (occurrence of) positive formula F. We have\nthe following subcases.\n\u2022 F = P1 \u2297 * * * \u2297 Pn and \u03c0 ends with a \u2297n -rule:\n..\n..\n. \u03c01\n. \u03c0n\n\u22a2 ?\u03931 , P1\n...\n\u22a2 ?\u0393n , Pn\n\u2297n\n\u22a2 ?\u03931 , . . . , ?\u0393n , P1 \u2297 * * * \u2297 Pn\nSince the premises are sequent of MELL\u2217pol , the inductive hypothesis yields the derivations \u03c01\u2217 , . . . , \u03c0n\u2217 of the premises in MELL\u2217pol . We can then apply \u2297n and conclude.\n\u2022 F = !M and \u03c0 ends with the !-rule:\n..\n.\u03c0\n0\n\n\u22a2 ?\u0393, M\n!\n\u22a2 ?\u0393, !M\nSince \u22a2 ?\u0393, M is a sequent of MELL\u2217pol , the inductive hypothesis yields a derivation\n\u03c00\u2217 of the premise. We can then apply ! and conclude.\nThere are no other cases, since the only possibility left out would be an inference of the\nform\n\u22a2 ?\u0393\u2032 , Q, F\n?\n\u22a2 ?\u0393\u2032 , ?Q, F\nbut by Lemma A.9, \u22a2 ?\u0393\u2032 , Q, F is not derivable in MELLpol , as it contains two occurrences\nof positive formula.\nNegative case: Suppose that \u22a2 \u2206 contains no positive formula, so that \u22a2 \u2206 = \u22a2 ?\u0393, F,\nwhere F is an (occurrence of) negative formula. We have the following subcases.\n\n\f76\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u2022 F = N1 ` * * * ` Nn . In such a case \u03c0 does not necessarily end with a `n -rule. For\ninstance, the last rules of \u03c0 could be\n\u22a2 ?\u0393\u2032 , Q, N1 ` * * * ` Nn\n`n\n\u22a2 ?\u0393\u2032 , ?Q, N1 ` * * * ` Nn\nand \u22a2 ?\u0393\u2032 , Q, N1 ` * * * ` Nn is not a sequent of MELL\u2217pol , as we have already discussed.\nWe then proceed as follows.\nObserve that the formula N1 ` * * * ` Nn cannot be affected by means of structural rules,\nand the contexts of the \u2297n -rules are splitting. Hence, there is a unique branch in \u03c0\nwhere at some stage the formula N1 ` * * * ` Nn is decomposed by means of a `n -rule:\n..\n. \u03c00\n\u2032\n\u22a2 \u0393 , N1 , . . . , Nn\n`n\n\u22a2 \u0393\u2032 , N1 ` * * * ` Nn\n..\n.\n..[N1 `***`Nn ]\n.\n\u22a2 ?\u0393, N1 ` * * * ` Nn\nWe also observe that \u22a2 \u0393\u2032 , N1 , . . . , Nn might not be a sequent of MELL\u2217pol and that\nthere is no application of the !-rule in the branch.\nLet \u03c1 be the proof-tree obtained from \u03c0 by replacing the previous branch with\n..\n. \u03c00\n\u2032\n\u22a2 \u0393 , N1 , . . . , Nn\n..\n.\n..[N1 ,...,Nn ]\n.\n\u22a2 ?\u0393, N1 , . . . , Nn\n`n\n\u22a2 ?\u0393, N1 ` * * * ` Nn\nBy Lemma A.10, \u03c1 is a correct derivation of \u22a2 ?\u0393, N1 ` * * * ` Nn in MELLpol ending\nwith a `n -rule. Moreover, the height of \u03c1 is the same of \u03c0 because the new branch\nhas the same height of the previous one. We can then apply the inductive hypothesis\nto the derivation, say \u03c10 , of the premise \u22a2 ?\u0393, N1 , . . . , Nn of the last inference rule of \u03c1.\nWe obtain a derivation \u03c1\u22170 of \u22a2 ?\u0393, N1 , . . . , Nn in MELL\u2217pol . To conclude, we apply `n .\n\u2022 F = ?Q and \u03c0 ends with the ?-rule:\n..\n. \u03c00\n\u22a2 ?\u0393, Q\n?\n\u22a2 ?\u0393, ?Q\nSince \u22a2 ?\u0393, Q is a sequent of MELL\u2217pol , the inductive hypothesis yields a derivation\n\u03c00\u2217 . We can then apply ? and conclude the argument\n\n\fLUDICS WITH REPETITIONS\n\n77\n\nIt is now possible to give a correspondence between MELLS and MELL\u2217pol . We do this in\nthe next section.\nA.3.3. Correspondence with MELL\u2217pol . We first observe that any exponential formula (that\nis, a ?-formula or a !-formula) of MELL\u2217pol can be generated by the following grammar:\nPositive exponential formulas : P ::= !(N1 ` * * * ` Nn ) (n \u2265 0)\nNegative exponential formulas : N ::= ?(P1 \u2297 * * * \u2297 Pn ) (n \u2265 0)\nWe can then define a translation\nMELL\u2217pol recursively as follows:\nP\nN\n\n\u25e6\n\u25e6\n\n\u25e6\n\nfrom formulas of MELLS to exponential formulas of\n\n= ?P (N1 \u2297 * * * \u2297 Nn ) \u25e6 := ?(N1\u25e6 \u2297 * * * \u2297 Nn\u25e6 );\n= !N (P1 ` * * * ` Pn ) \u25e6 := !(P1\u25e6 ` * * * ` Pn\u25e6 ).\n\nNotice that the translation \u25e6 inverts the polarity. Given a multi-set of formulas \u0393 =\nF1 , . . . , Fn of MELLS we write \u0393\u25e6 for the multi-set F1\u25e6 , . . . , Fn\u25e6 of formulas of MELL\u2217pol .\nNotice that, as a consequence of the restriction on the polarities for sequents of MELLS,\n\u22a2 \u0393\u25e6 is always a sequent of MELL\u2217pol , as it contains at most one occurrence of !-formula\n(all the remaining ones are ?-formulas).\nProposition A.12. If \u22a2 \u0393 is derivable in MELLS then \u22a2 \u0393\u25e6 is derivable in MELL\u2217pol .\nProof. By induction on the height of a derivation \u03c0 of \u22a2 \u0393 in MELLS.\n\u2022 \u03c0 is \u22a2 \u03a0, ?P I Pos0 . We set:\n\u22a21\n\u22a2 ?1\n\n1\n?\n\n..\n.\n. weakenings ..\n\u22a2 \u03a0\u25e6 , ?1\n\u2022 \u03c0 ends with a positive rule on P = ?P (N1 \u2297 * * * \u2297 Nn ) (with n \u2265 1):\n\u22a2 \u03a0, P, N1\n\n...\n\u22a2 \u03a0, P, Nn\nPosn\n\u22a2 \u03a0, P\nBy inductive hypothesis, \u22a2 \u03a0\u25e6 , P \u25e6 , Ni\u25e6 is derivable for any 1 \u2264 i \u2264 n. We set:\n...\n\u22a2 \u03a0\u25e6 , P \u25e6 , Nn\u25e6\n\u22a2 \u03a0\u25e6 , P \u25e6 , N1\u25e6\n\u2297n\n\u25e6\n\u25e6\n\u25e6\n\u25e6\n\u22a2 \u03a0 , . . . , \u03a0 , P , . . . , P , N1\u25e6 \u2297 * * * \u2297 Nn\u25e6\n?\n\u22a2 \u03a0\u25e6 , . . . , \u03a0\u25e6 , P \u25e6 , . . . , P \u25e6 , ?(N1\u25e6 \u2297 * * * \u2297 Nn\u25e6 )\n..\n.\n. contractions ..\n\u22a2 \u03a0\u25e6 , P \u25e6\n\u2022 \u03c0 ends with a negative rule on N = !N (P1 ` * * * ` Pn ) (with n \u2265 0):\n\u22a2 \u03a0, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, !N (P1 ` * * * ` Pn )\nBy inductive hypothesis, \u22a2 \u03a0\u25e6 , P1\u25e6 , . . . , Pn\u25e6 is derivable and we set:\n\n\f78\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u22a2 \u03a0\u25e6 , P1\u25e6 , . . . , Pn\u25e6\n`n\n\u22a2 \u03a0\u25e6 , P1\u25e6 ` * * * ` Pn\u25e6\n!\n\u22a2 \u03a0\u25e6 , !(P1\u25e6 ` * * * ` Pn\u25e6 )\nTo show the converse, we define a translation\nMELLS recursively as follows:\nP\nN\n\n\u2022\n\u2022\n\n= !M \u2022 := M\u2022 ;\n= ?Q \u2022 := Q\u2022 ;\n\nQ\nM\n\n\u2022\n\n\u2022\n\nfrom formulas of MELL\u2217pol to formulas of\n\n= P1 \u2297 * * * \u2297 Pn \u2022 := ?P (P\u20221 \u2297 * * * \u2297 P\u2022n );\n= N1 ` * * * ` Nn \u2022 := !N (N\u20221 ` * * * ` N\u2022n ).\n\n\u2022\n\nWe observe that the translation \u2022 inverts the polarity of the exponential formulas whereas\nit preserves the polarity of the other formulas. Given a multi-set of formulas \u0393 = F1 , . . . , Fk\nof MELL\u2217pol we write \u0393\u2022 for the multi-set F\u20221 , . . . , F\u2022k of formulas of MELLS.\nConsider now a sequent \u22a2 \u2206 = \u22a2 N1 , . . . , Nk\u22121 , Fk of MELL\u2217pol . Since N1 , . . . , Nk\u22121\nare ?-formula, the multi-set N\u20221 , . . . , N\u2022k\u22121 , F\u2022k contains at most one occurrence of negative\nformula. Hence, every sequent \u22a2 \u2206 of MELL\u2217pol is sent to a sequent \u22a2 \u2206\u2022 of MELLS.\nWe are now ready to show the converse correspondence.\nProposition A.13. If \u22a2 \u2206 is derivable in MELL\u2217pol then \u22a2 \u2206\u2022 is derivable in MELLS.\nProof. By induction on the height of a derivation \u03c0 of a sequent \u22a2 \u2206 in MELL\u2217pol .\n\u2297n : Suppose that \u03c0 ends with\n\u22a2 ?\u03931 , P1\n...\n\u22a2 ?\u0393n , Pn\n\u22a2 ?\u03931 , . . . , ?\u0393n , P1 \u2297 * * * \u2297 Pn\nWe have to show a derivation of\n\u22a2 ?\u03931 , . . . , ?\u0393n , P1 \u2297 * * * \u2297 Pn\n\n\u2022\n\n\u2297n\n\n= \u22a2 ?\u0393\u20221 , . . . , ?\u0393\u2022n , ?P (P\u20221 \u2297 * * * \u2297 P\u2022n ).\n\nBy inductive hypothesis, the sequent \u22a2 ?\u0393\u2022i , P\u2022i is derivable for any 1 \u2264 i \u2264 n. By\nProposition A.2 (1) \u22a2 ?\u0393\u20221 , . . . , ?\u0393\u2022n , Q\u2022 , P\u2022i is also derivable for any 1 \u2264 i \u2264 n, where\nQ\u2022 = ?P (P\u20221 \u2297 * * * \u2297 P\u2022n ). We take:\n...\n\u22a2 ?\u0393\u20221 , . . . , ?\u0393\u2022n , Q\u2022 , P\u2022n\n\u22a2 ?\u0393\u20221 , . . . , ?\u0393\u2022n , Q\u2022 , P\u20221\n\u22a2 ?\u0393\u20221 , . . . , ?\u0393\u2022n , Q\u2022\n`n : Suppose that \u03c0 ends with\n\u22a2 ?\u0393, N1 , . . . , Nn\n\u22a2 ?\u0393, N1 ` * * * ` Nn\nWe have to show a derivation of\n\u22a2 ?\u0393, N1 ` * * * ` Nn\n\n\u2022\n\nPosn\n\n`n\n\n= \u22a2 ?\u0393\u2022 , !N (N\u20221 ` * * * ` N\u2022n ).\n\nBy inductive hypothesis, the sequent \u22a2 ?\u0393\u2022 , N\u20221 , . . . , N\u2022n is derivable. We take:\n\u22a2 ?\u0393\u2022 , N\u20221 , . . . , N\u2022n\n\u22a2 ?\u0393\u2022 , !N (N\u20221 ` * * * ` N\u2022n )\n\nNegn\n\n! : Suppose that \u03c0 ends with\n\u22a2 ?\u0393, M\n!\n\u22a2 ?\u0393, !M\nBy inductive hypothesis, the sequent \u22a2 ?\u0393\u2022 , M\u2022 is derivable. Since !M\nconclude the argument.\n? : Suppose that \u03c0 ends with\n\n\u2022\n\n= M\u2022 , we\n\n\fLUDICS WITH REPETITIONS\n\n\u22a2 ?\u0393, Q\n?\n\u22a2 ?\u0393, ?Q\nBy inductive hypothesis, the sequent \u22a2 ?\u0393\u2022 , Q\u2022 is derivable. Since ?Q\nconclude the argument.\nW : Suppose that \u03c0 ends with\n\n79\n\n\u2022\n\n= Q\u2022 , we\n\n\u22a2\u2206 W\n\u22a2 \u2206, N\nBy inductive hypothesis, the sequent \u22a2 \u2206\u2022 is derivable. By Proposition A.2 (1), the\nsequent \u22a2 \u2206\u2022 , N\u2022 is also derivable.\nC : Suppose that \u03c0 ends with\n\u22a2 \u2206, N, N\nC\n\u22a2 \u2206, N\nBy inductive hypothesis, the sequent \u22a2 \u2206\u2022 , N\u2022 , N\u2022 is derivable. By Proposition A.2\n(2), the sequent \u22a2 \u2206\u2022 , N\u2022 is also derivable.\nRegarding the composition of the translations\n\n\u25e6\n\nand \u2022 , we observe the following properties.\n\nLemma A.14.\n(1) For any formula F of MELLS, we have (F \u25e6 )\u2022 = F .\n(2) For any exponential formula F of MELL\u2217pol , we have (F\u2022 )\u25e6 = F.\n(3) For any sequent \u22a2 \u0393 of MELLS, we have (\u22a2 \u0393 \u25e6 )\u2022 = \u22a2 \u0393.\n(4) Let \u2206 = F1 , . . . , Fn . We get (\u22a2 F1 , . . . , Fn \u2022 )\u25e6 = (\u22a2 F\u20221 , . . . , F\u2022n )\u25e6 = \u22a2 (F\u20221 )\u25e6 , . . . , (F\u2022n )\u25e6 ,\nand by point (2) above we conclude the argument.\n(5) For any sequent \u22a2 \u2206 of MELL\u2217pol consisting of exponential formulas only, we have\n(\u22a2 \u2206 \u2022 )\u25e6 = \u22a2 \u2206.\nProof.\n(1) By induction on the depth of F . Let P = ?P (N1 \u2297 * * * \u2297 Nn ). We have:\n(P \u25e6 )\u2022 =\n=\n=\n=\n\n?P (N1 \u2297 * * * \u2297 Nn ) \u25e6 \u2022\n?(N1\u25e6 \u2297 * * * \u2297 Nn\u25e6 ) \u2022\nN1\u25e6 \u2297 * * * \u2297 Nn\u25e6 \u2022\n?P ((N1\u25e6 )\u2022 \u2297 * * * \u2297 (Nn\u25e6 )\u2022 ),\n\nand by inductive hypothesis we conclude the argument. The negative case is similar.\n(2) By induction on the depth of F. Let P = !(N1 ` * * * ` Nn ). We have:\n(P\u2022 )\u25e6 =\n=\n=\n=\n\n!(N1 ` * * * ` Nn ) \u2022 \u25e6\nN1 ` * * * ` Nn \u2022 \u25e6\n!N (N\u20221 ` * * * ` N\u2022n ) \u25e6\n!((N\u20221 )\u25e6 ` * * * ` (N\u2022n )\u25e6 ),\n\nand by inductive hypothesis we conclude the argument. The negative case is similar.\n(3) Let \u0393 = F1 , . . . , Fn . We get (\u22a2 F1 , . . . , Fn \u25e6 )\u2022 = (\u22a2 F1\u25e6 , . . . , Fn\u25e6 )\u2022 = \u22a2 (F1\u25e6 )\u2022 , . . . , (Fn\u25e6 )\u2022 ,\nand by point (1) above we conclude the argument.\n(4) Let \u2206 = F1 , . . . , Fn . We get (\u22a2 F1 , . . . , Fn \u2022 )\u25e6 = (\u22a2 F\u20221 , . . . , F\u2022n )\u25e6 = \u22a2 (F\u20221 )\u25e6 , . . . , (F\u2022n )\u25e6 ,\nand by point (2) above we conclude the argument.\nWe can finally collect the previous results in the next theorem.\n\n\f80\n\nM. BASALDELLA AND C. FAGGIAN\n\nTheorem A.15.\n(1) Let \u22a2 \u2206 be a sequent of MELLpol consisting of exponential formulas only.\n\u22a2 \u2206 is derivable in MELLpol if and only if \u22a2 \u2206\u2022 is derivable in MELLS.\n(2) \u22a2 \u0393 is derivable in MELLS if and only if \u22a2 \u0393\u25e6 is derivable in MELLpol .\nProof.\n(1) If \u22a2 \u2206 is a derivable sequent of MELLpol , then by Lemma A.9 it contains at most one\noccurrence of positive formula. Since \u22a2 \u2206 is made of exponential formulas only, it is\nof the form \u22a2 ?\u0393, F, where F is either a ?-formula or a !-formula. In particular, \u22a2 \u2206 is\na sequent of MELL\u2217pol . By Proposition A.11, \u22a2 \u2206 is a derivable sequent of MELL\u2217pol .\nBy Proposition A.13, \u22a2 \u2206\u2022 is derivable in MELLS.\nConversely, if \u22a2 \u2206\u2022 is derivable in MELLS then, by Proposition A.12, (\u22a2 \u2206\u2022 )\u25e6 is\nderivable in MELL\u2217pol and hence in of MELLpol . By Lemma A.14 (4), (\u22a2 \u2206\u2022 )\u25e6 = \u22a2 \u2206\nand we conclude the argument.\n(2) If \u22a2 \u0393 is derivable in MELLS then, by Proposition A.12, \u22a2 \u0393\u25e6 is derivable in MELL\u2217pol\nand hence also in MELLpol .\nFor the converse, we observe that by the definition of \u25e6 , \u22a2 \u0393\u25e6 is a sequent of MELL\u2217pol .\nSince we are assuming that it is derivable in MELLpol , by Proposition A.11, it is also\nderivable in MELL\u2217pol . By Proposition A.13, (\u22a2 \u0393\u25e6 )\u2022 is derivable in MELLS. By\nLemma A.14 (3), (\u22a2 \u0393\u25e6 )\u2022 = \u22a2 \u0393 and we conclude the argument.\nAppendix B. Soundness\nWe first show some technical lemmas.\nLemma B.1 (Logical rules).\n(1) Let P = F+ (N1 , . . . , Nn ) be a positive behaviour.\nIf E1 \u2208 \u22a2 \u03a0, N\u03c31 , . . . , En \u2208 \u22a2 \u03a0, N\u03c3n then D := (\u03c3, In )+ .{E1 , . . . , En } \u2208 \u22a2 \u03a0, P\u03c3 .\nMoreover, if E1 , . . . , En are winning, then D is winning.\n(2) Let N = F\u2212 (P1 , . . . , Pn ) be a negative behaviour.\nIf E \u2208 \u22a2 \u03a0, P\u03be1 , . . . , P\u03ben then D := (\u03be, In )\u2212 .E \u2208 \u22a2 \u03a0, N\u03be .\nMoreover, if E is winning, then D is winning.\n\u22a5\nProof. Let us fix \u03a0 = Q\u03b11 , . . . , Q\u03b1k and arbitrary strategies F1 \u2208 Q\u22a5\n\u03b11 , . . . , Fk \u2208 Q\u03b1k . We\n\u22a5\n\u22a5\nwill write (Fj ) and (Fj ) \u2208 C for F1 , . . . , Fk and F1 \u2208 Q\u03b11 , . . . , Fk \u2208 Q\u03b1k respectively.\n(1) For sake of clarity, we distinguish two subcases.\nIf n = 0, then P = ?P 1 and D is just (\u03c3, \u2205)+ . It is then immediate to show (1), since\nfor any A \u2208 P\u22a5\n\u03c3 = !N \u22a5 \u03c3 , we have [[D, A, (Fj )]] = [[D, A]] and D and A are obviously\northogonal. It is also immediate to check that D is winning.\nIf n > 0, by Proposition 10.6, Ei \u2208 \u22a2 \u03a0, N\u03c3i if and only if Ei\u2032 := [[Ei , (Fj )]] \u2208 N\u03c3i , for\nany 1 \u2264 i \u2264 n. By construction of F+ (N1 , . . . , Nn ), the strategy (\u03c3, In )+ .{E1\u2032 , . . . , En\u2032 } \u2208\nP\u03c3 . By using Lemma 10.2 and Proposition 10.6 again, we conclude D \u2208 \u22a2 \u03a0, P\u03c3 .\nAs for winning conditions, the only one which is not immediate is materiality. Let A\n+\n\u2217\n\u2212\n\u22a5\nbe a strategy in N\u22a5\n\u03c3i and A := (\u03c3, In ) .A \u2208 P\u03c3 . Observe that by construction (\u03c3, In )\n\u2217\noccurs linearly in D at the root. This makes the interaction of the cut-net {D, A , (Fj )}\nparticularly simple to describe: (i) (\u03c3, In )+ and (\u03c3, In )\u2212 match, (ii) after matching, the\n\n\fLUDICS WITH REPETITIONS\n\n81\n\ninteraction is exactly as in the cut-net {Ei , A, (Fj )}. So we have (in the notation of\nDefinition 11.2)\nD[A\u2217 , (Fj )] = (\u03c3, In )+ .Ei [A, (Fj )].\nSince Ei is material, if we let vary A \u2208 N\u22a5\n\u03c3i and (Fj ) \u2208 C and use the counter-strategies\n\u2217\nA , (Fj ), we can visit the whole subtree (\u03c3, In )+ .Ei \u2286 D. Applying the same reasoning\nto each 1 \u2264 i \u2264 n we have our claim.\n(2) By Proposition 10.6, E \u2208 \u22a2 \u03a0, P\u03be1 , . . . , P\u03ben if and only if E \u2032 := [[E, (Fj )]] \u2208 \u22a2 P\u03be1 , . . . ,\nP\u03ben . By Proposition 10.8, (\u03be, In )\u2212 .E \u2032 \u2208 \u22a2 N\u03be . Since we have that (\u03be, In )\u2212 .[[E, (Fj )]] =\n[[(\u03be, In )\u2212 .E, (Fj )]], by using Proposition 10.6 again, we conclude D \u2208 \u22a2 \u03a0, N\u03be .\nAs for winning conditions, the only one which is not immediate is materiality.\n\u2217\n+\n\u22a5\n\u22a5\nFor A1 , \u2208 P\u22a5\n\u03be1 , . . . , An \u2208 P\u03ben , let us set A := (\u03be, In ) .{A1 , . . . , An } \u2208 N\u03be . Since by\nconstruction (\u03be, In )+ occurs linearly in A\u2217 , the interaction of the cut-net {D, A\u2217 , (Fj )}\ncan be simply described as follows: (i) the actions (\u03be, In )+ and (\u03be, In )\u2212 match, (ii) after\nmatching the interaction is the exactly as in the cut-net {E, A1 , . . . , An , (Fj )}. So we\nhave\nD[A\u2217 , (Fj )] = (\u03be, In )\u2212 .E[A1 , . . . , An , (Fj )].\n\u22a5\nSince E is material, if we let vary A1 , \u2208 P\u22a5\n\u03be1 , . . . , An \u2208 P\u03ben and (Fj ) \u2208 C, we can use\n\u2217\nthe counter-strategies A , (Fj ) in order to completely visit D.\nLemma B.2 (Structural rules).\n(1) Weakening: if D \u2208 \u22a2 \u0393 then D \u2208 \u22a2 \u0393, Q\u03be .\nMoreover, if D is winning (in \u22a2 \u0393) then D is winning (in \u22a2 \u0393, Q\u03be ).\n(2) Contraction: if D \u2208 \u22a2 \u0393, Q\u03be , Q\u03c3 then D[\u03be/\u03c3] \u2208 \u22a2 \u0393, Q\u03be .\nMoreover, if D is winning then D[\u03be/\u03c3] is winning.\n\u22a5\nProof. Let us fix \u0393 = F\u03b11 , . . . , F\u03b1k and arbitrary strategies F1 \u2208 F\u22a5\n\u03b11 , . . . , Fk \u2208 F\u03b1k . We\n\u22a5\n\u22a5\nwill write (Fj ) and (Fj ) \u2208 C for F1 , . . . , Fk and F1 \u2208 F\u03b11 , . . . , Fk \u2208 F\u03b1k respectively.\n\n(1) Since no action with name \u03be occurs in D, we have for any E \u2208 Q\u22a5\n\u03be :\n[[D, (Fj )]] = [[D, E, (Fj )]],\nwhere D is taken on the interface \u03b11 , . . . , \u03b1k of \u22a2 \u0393 (resp. \u03b11 , . . . , \u03b1k , \u03be + of \u22a2 \u0393, Q\u03be )\non the LHS (resp. RHS) of the equality above. Moreover it is easily seen that the\ninteractions of the two cut-nets are exactly the same. The result then immediately\nfollows.\n(2) We first prove that D \u2208 \u22a2 \u0393, Q\u03be , Q\u03c3 implies D[\u03be/\u03c3] \u2208 \u22a2 \u0393, Q\u03be . By hypothesis, for\nany A, B \u2208 Q\u22a5\n\u03be , we have that D\u22a5{A, B[\u03c3/\u03be], (Fj )}. When A = B, we have that\nD\u22a5{A, A[\u03c3/\u03be], (Fj )} which implies D[\u03be/\u03c3]\u22a5{A, (Fj )} by Proposition 8.14. Hence, we\nhave D[\u03be/\u03c3] \u2208 \u22a2 \u0393, Q\u03be .\nAs for winning conditions, the only one which is not immediate to prove is materiality.\n\u22a5\n\u22a5\nBy Lemma 10.10 (2), we have that Q\u03be = (Q\u22a5\n\u03be hxi) , where recall that Q\u03be hxi consists\nof the negative strategies of Q\u22a5 which have a unique negative root x = (\u03be, In ). Since\nD is material in \u22a2 \u0393, Q\u03be , Q\u03c3 , we have by Definition 11.5:\n[\b\nD=\nD[A, B[\u03c3/\u03be], (Fj )] : A, B \u2208 Q\u22a5\n\u03be hxi and (Fj ) \u2208 C .\nSince A, B have the same root x, by Lemma 10.10 (1) the strategy A +\u03c4 B \u2208 Q\u22a5\n\u03be .\n\u03c4\n\u03c4\n\u22a5\nThe strategy A + B has the same unique root x too, hence A + B \u2208 Q\u03be hxi.\n\n\f82\n\nM. BASALDELLA AND C. FAGGIAN\n\nObserve that using the counter-strategy A +\u03c4 B we are able to visit the part of D\nwhich can be visited interchanging A and B (and possibly visit new actions), i.e.,\nD[A, B[\u03c3/\u03be], (Fj )] \u2286 D[A +\u03c4 B, (A +\u03c4 B)[\u03c3/\u03be], (Fj )]\nD[B, A[\u03c3/\u03be], (Fj )] \u2286 D[A +\u03c4 B, (A +\u03c4 B)[\u03c3/\u03be], (Fj )]\nBut then, we have that\n[\b\nD =\nD[A +\u03c4 B, (A +\u03c4 B)[\u03c3/\u03be], (Fj )] : A +\u03c4 B \u2208 Q\u22a5\n\u03be hxi and (Fj ) \u2208 C\n[\b\n\u22a5\n=\nD[C, C[\u03c3/\u03be], (Fj )] : C \u2208 Q\u03be hxi and (Fj ) \u2208 C .\n\nSimilarly as in Proposition 8.14, we can derive that\n\nD[C, C[\u03c3/\u03be], (Fj )][\u03be/\u03c3] = D[\u03be/\u03c3][C, (Fj )],\nbecause the interactions of the cut-nets {D, C, C[\u03c3/\u03be], (Fj )} and {D[\u03be/\u03c3], C, (Fj )} differ\nonly in the names of some hidden actions but have the same pointer structure. Hence:\n[\b\nD[\u03be/\u03c3] =\nD[C, C[\u03c3/\u03be], (Fj )] : C \u2208 Q\u22a5\n\u03be hxi and (Fj ) \u2208 C [\u03be/\u03c3]\n[\b\n=\nD[C, C[\u03c3/\u03be], (Fj )][\u03be/\u03c3] : C \u2208 Q\u22a5\n\u03be hxi and (Fj ) \u2208 C\n[\b\n\u22a5\n=\nD[\u03be/\u03c3][C, (Fj )] : C \u2208 Q\u03be hxi and (Fj ) \u2208 C ,\nwhich shows the materiality of D[\u03be/\u03c3] in \u22a2 \u0393, Q\u03be .\n\nWe can now prove the following:\nProposition B.3. Let \u03c0 be a cut-free derivation of a sequent \u22a2 \u0393 in MELLS and D(\u03c0) be\nthe interpretation of \u03c0 in a sequent of behaviours \u22a2 \u0393. D(\u03c0) is a winning strategy in \u22a2 \u0393.\nProof. By induction on the height of \u03c0. As for positive rules, we use Lemmas B.1 (1)\nand B.2. As for negatives rules, we use Lemma B.1 (2).\nIn order to expand the previous proposition to derivation with cuts, we need to study\nthe relation between composition of strategies and the procedure of cut-elimination defined\nin the proof of admissibility of the cut-rule of MELLS (Theorem A.3).\nWe first show the following:\nLemma B.4 (Cut-rule). If D \u2208 \u22a2 \u039e, \u03a0, P\u03be and E \u2208 \u22a2 \u2206, P\u22a5\n\u03be then [[D, E]] \u2208 \u22a2 \u039e, \u03a0, \u2206\nProof. We only consider the case in which \u039e is empty, the case \u039e = N is similar.\n+\nLet \u03a0 = A\u03b11 , . . . , A\u03b1n and \u2206 = B\u03b21 , . . . , B\u03b2k on disjoint interfaces \u03b1+\n1 , . . . , \u03b1n and\n\u22a5\n\u22a5\n\u22a5\n\u03b21+ , . . . , \u03b2k+ respectively. Let A1 \u2208 A\u22a5\n\u03b11 , . . . , An \u2208 A\u03b1n and B1 \u2208 B\u03b21 , . . . , Bk \u2208 B\u03b2k be\narbitrary strategies and write (Aj ) and (Bl ) for A1 , . . . , An and B1 , . . . , Bk respectively.\nBy Proposition 10.6 we have that [[D, (Aj )]] \u2208 P\u03be and [[E, (Bl )]] \u2208 P\u22a5\n\u03be which implies\nthat [[[[D, (Aj )]], [[E, (Bl )]]]] is total. By associativity, we have that [[[[D, E]], (Aj ), (Bl )]] is\ntotal, which shows that [[D, E]] \u2208 \u22a2 \u03a0, \u2206.\nWe now relate our interpretation and Proposition A.2, which deals with the structural\nrules of MELLS.\n\n\fLUDICS WITH REPETITIONS\n\n83\n\nLemma B.5.\n(1) Let D(\u03c0) be the interpretation of a cut-free derivation \u03c0 of \u22a2 \u0393 in a sequent of behaviours\n\u22a2 \u0393 and D(\u03c0 \u2032 ) be the interpretation of the cut-free derivation \u03c0 \u2032 of \u22a2 \u0393, Q in the sequent\nof behaviours \u22a2 \u0393, Q\u03be as given by Proposition A.2 (1). We have D(\u03c0) = D(\u03c0 \u2032 ).\n(2) Let D(\u03c0) be interpretation of a cut-free derivation \u03c0 of \u22a2 \u0393, Q, Q in a sequent of behaviours \u22a2 \u0393, Q\u03be , Q\u03c3 and D(\u03c0 \u2032 ) be the interpretation of the cut-free derivation \u03c0 \u2032 of\n\u22a2 \u0393, Q in a sequent of behaviours \u22a2 \u0393, Q\u03be as given by Proposition A.2 (2). We have\nD(\u03c0 \u2032 ) = D(\u03c0)[\u03be/\u03c3].\nProof. By induction on the height of \u03c0.\nWe can finally show the correspondence between composition and cut-elimination.\nLemma B.6 (Composition and cut-elimination). Let \u03c0 and \u03c1 be cut-free derivations in\nMELLS of \u22a2 \u039e, \u03a0, P and \u22a2 \u2206, P \u22a5 respectively and D(\u03c0) and D(\u03c1) be the interpretation\nof \u03c0 and \u03c1 in \u22a2 \u039e, \u03a0, P\u03be and \u22a2 \u2206, P\u22a5\n\u03be respectively. Let \u03b8 be the cut-free derivation of\n\u22a2 \u039e, \u03a0, \u2206 as given by Theorem A.3 and D(\u03b8) its interpretation in \u22a2 \u039e, \u03a0, \u2206.\nWe have [[D(\u03c0), D(\u03c1)]] = D(\u03b8).\nProof. As in Theorem A.3, the proof is given by induction on the pair (d(P ), h(\u03c0) + h(\u03c1)),\nwhere d (resp. h) denotes the depth of a formula (resp. the height of a proof), as given in\nDefinition A.1. We distinguish three subcases.\n(a) The last rule of \u03c0 is a positive rule Posn and P is principal in Posn . As in Theorem A.3,\nwe only consider the cases n = 0 and n = 2.\nIf n = 0 and we have\n..\n. \u03c10\n\u22a2\u2206\nNeg0\nPos0\n\u22a2 \u03a0, ?P I\n\u22a2 \u2206, !N\nT\n\nthe procedure described in the proof of Theorem A.3 gives the cut free derivation \u03b8 of\n\u22a2 \u03a0, \u2206, where \u03b8 is obtained from \u03c10 by means of Proposition A.2 (1) (weakening on positive\nformulas).\nBy our interpretation, we have that D(\u03c0) = (\u03be, \u2205)+ and D(\u03c1) = (\u03be, \u2205)\u2212 .D(\u03c10 ). By\nnormalization and Lemma B.5 (1), we have [[D(\u03c0), D(\u03c1)]] = D(\u03c10 ) = D(\u03b8).\nIf n = 2, for P = ?P (N1 \u2297 N2 ) and P \u22a5 = !N (N1\u22a5 ` N2\u22a5 ), we have\n..\n..\n. \u03c01\n. \u03c02\n\u22a2 \u03a0, P, N1\n\u22a2 \u03a0, P, N2\n\u22a2 \u03a0, P\n\n..\n. \u03c10\nPos2\n\n\u22a2 \u2206, N1\u22a5 , N2\u22a5\n\nNeg2\n\n\u22a2 \u2206, P \u22a5\n\b\nSuppose that \u03c0 is interpreted by D(\u03c0) = (\u03c3, {1, 2})+ . D(\u03c01 ), D(\u03c02 ) [\u03be/\u03c3] in the sequent\nof behaviours \u22a2 \u03a0, P on interface \u03a0, \u03be + and \u03c1 is interpreted by D(\u03c1) = (\u03be, {1, 2})\u2212 .D(\u03c10 )\nin the sequent of behaviours \u22a2 \u2206, P\u22a5 on interface \u2206, \u03be \u2212 . Since the construction of the\ncut-free derivation \u03b8 of \u22a2 \u03a0, \u2206 (as given in Theorem A.3) involves \"copies\" of derivations\nand contractions, we also consider:\n\u2022 A1 := D(\u03c01 )[\u03a0\u2032 /\u03a0], the interpretation of \u03c01 in the sequent of behaviours \u22a2 \u03a0, P, N1 on\ninterface \u03a0\u2032 , \u03be + , \u03c31\u2212 ,\n\n\f84\n\nM. BASALDELLA AND C. FAGGIAN\n\n\u2022 A2 := D(\u03c02 )[\u03a0\u2032\u2032 /\u03a0], the interpretation of \u03c02 in the sequent of behaviours \u22a2 \u03a0, P, N2 on\ninterface \u03a0\u2032\u2032 , \u03be + , \u03c32\u2212 ,\n\u2022 B := D(\u03c1)[\u03c3/\u03be, \u2206\u2032 /\u2206], the interpretation of \u03c1 in the sequent of behaviours \u22a2 \u2206, P\u22a5 on\ninterface \u2206\u2032 , \u03c3 \u2212 ,\n\u2022 B0 := D(\u03c10 )[\u03c31/\u03be1, \u03c32/\u03be2, \u2206\u2032 /\u2206], the interpretation of \u03c10 in the sequent of behaviours\n\u22a5\n\u2032\n\u2212\n\u2212\n\u22a2 \u2206, N\u22a5\n1 , N2 on interface \u2206 , \u03c31 , \u03c32 . Equivalently, B0 is obtained from B by removing\nits root (\u03c3, {1, 2})\u2212 ,i.e., B = (\u03c3, {1, 2})\u2212 .B0 ,\n\u2022 C1 := D(\u03c1)[\u2206\u2032\u2032 /\u2206], the interpretation of \u03c1 in the sequent of behaviours \u22a2 \u2206, P\u22a5 on\ninterface \u2206\u2032\u2032 , \u03be \u2212 ,\n\u2022 C2 := D(\u03c1)[\u2206\u2032\u2032\u2032 /\u2206], the interpretation of \u03c1 in the sequent of behaviours \u22a2 \u2206, P\u22a5 on\ninterface \u2206\u2032\u2032\u2032 , \u03be \u2212 ,\nwhere the names \u03a0\u2032 , \u03a0\u2032\u2032 , \u2206\u2032 , \u2206\u2032\u2032 , \u2206\u2032\u2032\u2032 are all fresh and disjoint.\nRecall that the procedure described in Theorem A.3 introduces cut-free derivations \u03c81\nof \u22a2 \u03a0, \u2206, N1 (from \u03c01 and \u03c1), \u03c82 of \u22a2 \u03a0, \u2206, N2 (from \u03c02 and \u03c1), \u03b81 of \u22a2 \u03a0, \u2206, \u2206, N2\u22a5 (from\n\u03c10 and \u03c81 ), \u03b82 of \u22a2 \u03a0, \u03a0, \u2206, \u2206, \u2206 (from \u03b81 and \u03c82 ). Finally, the cut-free derivation \u03b8 of\n\u22a2 \u03a0, \u2206 is obtained from \u03b82 by means of contractions, in the sense of Proposition A.2 (2)\n(contraction on positive formulas).\nIn terms of our interpretation, we have:\nD(\u03b8) = [[[[B0 , [[A1 , C1 ]]]], [[A2 , C2 ]]]][\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ]\nwhere [[A1 , C1 ]] (resp. [[A2 , C2 ]]) interprets the derivation \u03c81 (resp. \u03c82 ), [[B0 , [[A1 , C1 ]]]] interprets the derivation \u03b81 , [[[[B0 , [[A1 , C1 ]]]], [[A2 , C2 ]]]] interprets the derivation \u03b82 and finally, by\nLemma B.5 (2), the renamings [\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ] take care of the contractions.\nWe have to show that [[D(\u03c0), D(\u03c1)]] = D(\u03b8).\nWriting a (resp. b) for (\u03c3, {1, 2}) (resp. (\u03be, {1, 2}) and using Proposition 8.14 and the\nassociativity of the normalization, we get:\n\b\n[[D(\u03c0), D(\u03c1)]] = [[a+ .\bD(\u03c01 ), D(\u03c02 ) [\u03be/\u03c3] , b\u2212 .D(\u03c10 )]]\n= [[a+ . \bD(\u03c01 ), D(\u03c02 ) , b\u2212 .D(\u03c10 ) , B]][\u2206/\u2206\u2032 ]\n= [[[[a+ . D(\u03c01 ) , D(\u03c02 ) , b\u2212 .D(\u03c10 )]] , B]][\u2206/\u2206\u2032 ]\n\b\nIn [[a+ . D(\u03c01 ) , D(\u03c02 ) , b\u2212 .D(\u03c10 )]] , the action a+ is visible and then we can \"push\" D(\u03c1)\nin both premises D(\u03c01 ) and D(\u03c02 ) using the strategies A1 , A2 , C1 , C2 introduced above as\nfollows:\n\b\n\b\n[[a+ . D(\u03c01 ) , D(\u03c02 ) , b\u2212 .D(\u03c10 )]] = a+ . [[A1 , C1 ]] , [[A2 , C2 ]] [\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ]\nwhere the renamings [\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ] ensure that the strategy on LHS and the\nstrategy on RHS of the equality are on the same interface \u03a0, \u2206, \u03c3 + . We have that\n\b\n[[D(\u03c0), D(\u03c1)]] = [[a+ .\b[[A1 , C1 ]] , [[A2 , C2 ]] [\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ] , B]][\u2206/\u2206\u2032 ]\n= [[a+ . [[A1 , C1 ]] , [[A2 , C2 ]] , B]][\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ]\n= [[B0 , [[A1 , C1 ]] , [[A2 , C2 ]]]][\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ]\n= [[[[B0 , [[A1 , C1 ]]]] , [[A2 , C2 ]]]][\u03a0/\u03a0\u2032 , \u03a0/\u03a0\u2032\u2032 , \u2206/\u2206\u2032 , \u2206/\u2206\u2032\u2032 , \u2206/\u2206\u2032\u2032\u2032 ]\n= D(\u03b8),\nwhere the second equality above is justified by the fact that those renamings on \"contexts\"\nof visible actions do not modify the calculation of the normal form (and we have correct\n\n\fLUDICS WITH REPETITIONS\n\n85\n\ncut-nets on both sides of the equality), the third one by the fact that by construction a+\noccurs linearly (recall that B = a\u2212 .B0 ) and the fourth one by associativity.\n(b) The last rule of \u03c0 is a positive rule Posn and P is not principal in Posn :\n..\n. \u03c01\n\u22a2 \u03a0, P, Q, N1\n\n...\n\u22a2 \u03a0, P, Q\n\n..\n. \u03c0n\n\u22a2 \u03a0, P, Q, Nn\n\n..\n.\u03c1\nPosn\n\n\u22a2 \u2206, P \u22a5\n\nand the principal formula\b of Posn is the occurrence of formula Q = ?P (N1 \u2297 * * * \u2297 Nn ).\nLet D(\u03c0) = (\u03c3, In )+ . D(\u03c01 ), . . . , D(\u03c0n ) [\u03b1/\u03c3] be the interpretation of \u03c0 in the sequent\nof behaviours \u22a2 \u03a0, P\u03be , Q\u03b1 on interface \u03a0, \u03be + , \u03b1+ and D(\u03c1) the interpretation of \u03c1 in the\n\u2212\nsequent of behaviours \u22a2 \u2206, P\u22a5\n\u03be on interface \u2206, \u03be .\nThe procedure described\nin Theorem A.3 gives a cut-free derivation \u03b8 which is interpre\b\n+\nted by D(\u03b8) = (\u03c3, In ) . [[D(\u03c01 ), D(\u03c1)]], . . . , [[D(\u03c0n ), D(\u03c1)]] [\u03b1/\u03c3], where each [[D(\u03c0i ), D(\u03c1)]]\nis the strategy which is interpretation of \u22a2 \u03a0, Q, \u2206, Ni on interface \u03a0, \u03b1+ , \u2206, \u03c3i\u2212 .\nWe have to show that [[D(\u03c0), D(\u03c1)]] = D(\u03b8), but this easily follows from the definition of\nnormalization, observing that the main strategy D(\u03c0) starts with a visible positive action.\n(c) The last rule of \u03c0 is a negative rule Negn , having N = !N (P1 ` * * * ` Pn ) as principal\nformula.\n..\n. \u03c00\n..\n.\u03c1\n\u22a2 \u03a0, P, P1 , . . . , Pn\nNegn\n\u22a2 \u03a0, P, N\n\u22a2 \u2206, P \u22a5\nSuppose that D(\u03c0) = (\u03b1, In )\u2212 .D(\u03c1) interprets \u03c0 in the sequent of behaviours \u22a2 \u03a0, P\u03be , N\u03b1 on\ninterface \u03a0, \u03be + , \u03b1\u2212 and D(\u03c1) interprets \u03c1 in the sequent of behaviours \u22a2 \u2206, P\u22a5\n\u03be on interface\n\u2212\n\u2206, \u03be .\nThe procedure described in Theorem A.3 gives a cut-free derivation \u03b8 which is interpreted by D(\u03b8) = (\u03b1, In )\u2212 .[[D(\u03c00 ), D(\u03c1)]], where [[D(\u03c00 ), D(\u03c1)]] is the strategy which is\ninterpretation of \u22a2 \u03a0, P1 , . . . , Pn , \u2206 on interface \u03a0, \u03b11+ , . . . , \u03b1n+ , \u2206.\nWe have to show that [[D(\u03c0), D(\u03c1)]] = D(\u03b8), but this easily follows from the definition of\nnormalization, observing that the main strategy D(\u03c0) starts with a visible negative action.\nWe can finally prove:\nTheorem B.7 (Soundness). Let \u03c0 be a derivation of a sequent \u22a2 \u0393 in MELLS and D(\u03c0)\nbe the interpretation of \u03c0 in a sequent of behaviours \u22a2 \u0393.\nD(\u03c0) is a winning strategy in \u22a2 \u0393.\nMoreover, the interpretation is invariant under cut-elimination.\nProof. If \u03c0 is cut-free, the result is given in Proposition B.3. If \u03c0 contains cuts, then using\nLemmas B.1, B.2 and B.4 we can inductively show that D(\u03c0) \u2208 \u22a2 \u0393.\nBy repeatedly applying Lemma B.6, we eventually prove that D(\u03c0) is also the interpretation of a cut-free derivation interpreted in \u22a2 \u0393. Finally, we use Proposition B.3 again.\n\nThis work is licensed under the Creative Commons Attribution-NoDerivs License. To view\na copy of this license, visit http://creativecommons.org/licenses/by-nd/2.0/ or send a\nletter to Creative Commons, 171 Second St, Suite 300, San Francisco, CA 94105, USA, or\nEisenacher Strasse 2, 10777 Berlin, Germany\n\n\f"}