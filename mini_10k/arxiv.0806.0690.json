{"id": "http://arxiv.org/abs/0806.0690v1", "guidislink": true, "updated": "2008-06-04T05:06:16Z", "updated_parsed": [2008, 6, 4, 5, 6, 16, 2, 156, 0], "published": "2008-06-04T05:06:16Z", "published_parsed": [2008, 6, 4, 5, 6, 16, 2, 156, 0], "title": "Phase Transitions, Chaos and Joint Action in the Life Space Foam", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0806.0843%2C0806.0819%2C0806.4487%2C0806.0122%2C0806.3391%2C0806.4624%2C0806.2371%2C0806.1525%2C0806.4622%2C0806.4964%2C0806.4431%2C0806.4320%2C0806.3489%2C0806.3909%2C0806.0355%2C0806.1744%2C0806.1667%2C0806.1463%2C0806.0607%2C0806.0780%2C0806.1429%2C0806.4284%2C0806.3048%2C0806.4599%2C0806.1746%2C0806.0627%2C0806.3746%2C0806.4058%2C0806.2442%2C0806.0947%2C0806.3602%2C0806.2511%2C0806.0386%2C0806.4169%2C0806.0120%2C0806.3716%2C0806.4744%2C0806.2056%2C0806.0791%2C0806.3966%2C0806.3756%2C0806.0788%2C0806.3949%2C0806.4828%2C0806.4302%2C0806.4225%2C0806.4738%2C0806.3493%2C0806.4955%2C0806.1104%2C0806.3691%2C0806.0730%2C0806.1892%2C0806.1863%2C0806.1074%2C0806.4741%2C0806.0690%2C0806.3298%2C0806.3530%2C0806.2740%2C0806.4443%2C0806.0592%2C0806.4297%2C0806.2106%2C0806.0767%2C0806.0291%2C0806.0724%2C0806.0019%2C0806.1648%2C0806.3401%2C0806.0461%2C0806.4174%2C0806.3265%2C0806.4305%2C0806.3205%2C0806.3310%2C0806.3752%2C0806.0531%2C0806.1582%2C0806.1884%2C0806.0748%2C0806.0544%2C0806.4881%2C0806.3405%2C0806.3260%2C0806.2641%2C0806.3727%2C0806.2340%2C0806.2645%2C0806.3736%2C0806.0914%2C0806.0943%2C0806.0093%2C0806.0412%2C0806.1737%2C0806.2046%2C0806.1210%2C0806.1291%2C0806.1490%2C0806.3841%2C0806.3665&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Phase Transitions, Chaos and Joint Action in the Life Space Foam"}, "summary": "This paper extends our recently developed Life Space Foam (LSF) model of\nmotivated cognitive dynamics \\cite{IA}. LSF uses adaptive path integrals to\ngenerate Lewinian force--fields on smooth manifolds, in order to characterize\nthe dynamics of individual goal--directed action. According to explanatory\ntheories growing in acceptance in cognitive neuroscience, one of the key\nproperties of this dynamics, capable of linking it to microscopic-level\ncortical neurodynamics, is its meta-stability and the resulting phase\ntransitions. Our extended LSF model incorporates the notion of phase\ntransitions and complements it with embedded geometrical chaos. To describe\nthis LSF phase transition, a general path--integral is used, along the\ncorresponding LSF topology change. As a result, our extended LSF model is able\nto rigorously represent co-action by two or more actors in the common\nLSF--manifold. The model yields substantial qualitative differences in\ngeometrical properties between bilateral and multi-lateral co-action due to\nintrinsic chaotic coupling between $n$ actors when $n\\geq 3$.\n  Keywords: cognitive dynamics, adaptive path integrals, phase transitions,\nchaos, topology change, human joint action, function approximation", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0806.0843%2C0806.0819%2C0806.4487%2C0806.0122%2C0806.3391%2C0806.4624%2C0806.2371%2C0806.1525%2C0806.4622%2C0806.4964%2C0806.4431%2C0806.4320%2C0806.3489%2C0806.3909%2C0806.0355%2C0806.1744%2C0806.1667%2C0806.1463%2C0806.0607%2C0806.0780%2C0806.1429%2C0806.4284%2C0806.3048%2C0806.4599%2C0806.1746%2C0806.0627%2C0806.3746%2C0806.4058%2C0806.2442%2C0806.0947%2C0806.3602%2C0806.2511%2C0806.0386%2C0806.4169%2C0806.0120%2C0806.3716%2C0806.4744%2C0806.2056%2C0806.0791%2C0806.3966%2C0806.3756%2C0806.0788%2C0806.3949%2C0806.4828%2C0806.4302%2C0806.4225%2C0806.4738%2C0806.3493%2C0806.4955%2C0806.1104%2C0806.3691%2C0806.0730%2C0806.1892%2C0806.1863%2C0806.1074%2C0806.4741%2C0806.0690%2C0806.3298%2C0806.3530%2C0806.2740%2C0806.4443%2C0806.0592%2C0806.4297%2C0806.2106%2C0806.0767%2C0806.0291%2C0806.0724%2C0806.0019%2C0806.1648%2C0806.3401%2C0806.0461%2C0806.4174%2C0806.3265%2C0806.4305%2C0806.3205%2C0806.3310%2C0806.3752%2C0806.0531%2C0806.1582%2C0806.1884%2C0806.0748%2C0806.0544%2C0806.4881%2C0806.3405%2C0806.3260%2C0806.2641%2C0806.3727%2C0806.2340%2C0806.2645%2C0806.3736%2C0806.0914%2C0806.0943%2C0806.0093%2C0806.0412%2C0806.1737%2C0806.2046%2C0806.1210%2C0806.1291%2C0806.1490%2C0806.3841%2C0806.3665&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper extends our recently developed Life Space Foam (LSF) model of\nmotivated cognitive dynamics \\cite{IA}. LSF uses adaptive path integrals to\ngenerate Lewinian force--fields on smooth manifolds, in order to characterize\nthe dynamics of individual goal--directed action. According to explanatory\ntheories growing in acceptance in cognitive neuroscience, one of the key\nproperties of this dynamics, capable of linking it to microscopic-level\ncortical neurodynamics, is its meta-stability and the resulting phase\ntransitions. Our extended LSF model incorporates the notion of phase\ntransitions and complements it with embedded geometrical chaos. To describe\nthis LSF phase transition, a general path--integral is used, along the\ncorresponding LSF topology change. As a result, our extended LSF model is able\nto rigorously represent co-action by two or more actors in the common\nLSF--manifold. The model yields substantial qualitative differences in\ngeometrical properties between bilateral and multi-lateral co-action due to\nintrinsic chaotic coupling between $n$ actors when $n\\geq 3$.\n  Keywords: cognitive dynamics, adaptive path integrals, phase transitions,\nchaos, topology change, human joint action, function approximation"}, "authors": ["Vladimir Ivancevic", "Eugene Aidman", "Leong Yen", "Darryn Reid"], "author_detail": {"name": "Darryn Reid"}, "author": "Darryn Reid", "arxiv_comment": "20 pages, no figures, elsart", "links": [{"href": "http://arxiv.org/abs/0806.0690v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0806.0690v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "q-bio.OT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0806.0690v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0806.0690v1", "journal_reference": null, "doi": null, "fulltext": "Phase Transitions, Chaos and Joint Action in\nthe Life Space Foam\n\narXiv:0806.0690v1 [q-bio.NC] 4 Jun 2008\n\nVladimir Ivancevic, Eugene Aidman, Leong Yen and Darryn Reid\nLand Operations Division, Defence Science & Technology Organisation,\nAUSTRALIA\n\nAbstract\nThis paper extends our recently developed Life Space Foam (LSF) model of motivated cognitive dynamics [1]. LSF uses adaptive path integrals to generate Lewinian\nforce\u2013fields on smooth manifolds, in order to characterize the dynamics of individual goal\u2013directed action. According to explanatory theories growing in acceptance in\ncognitive neuroscience, one of the key properties of this dynamics, capable of linking\nit to microscopic-level cortical neurodynamics, is its meta-stability and the resulting phase transitions. Our extended LSF model incorporates the notion of phase\ntransitions and complements it with embedded geometrical chaos. To describe this\nLSF phase transition, a general path\u2013integral is used, along the corresponding LSF\ntopology change. As a result, our extended LSF model is able to rigorously represent co-action by two or more actors in the common LSF\u2013manifold. The model\nyields substantial qualitative differences in geometrical properties between bilateral\nand multi-lateral co-action due to intrinsic chaotic coupling between n actors when\nn \u2265 3.\nKeywords: cognitive dynamics, adaptive path integrals, phase transitions, chaos,\ntopology change, human joint action, function approximation\n\n1\n\nIntroduction\n\nGeneral stochastic dynamics, developed in a framework of Feynman path integrals, have recently [1] been applied to Lewinian field\u2013theoretic psychodynamics [2,3,4], resulting in the development of a new concept of life\u2013space foam\n(LSF) as a natural medium for motivational (MD) and cognitive (CD) psychodynamics. According to the LSF\u2013formalism, the classic Lewinian life space can\nbe macroscopically represented as a smooth manifold with steady force\u2013fields\nand behavioral paths, while at the microscopic level it is more realistically represented as a collection of wildly fluctuating force\u2013fields, (loco)motion paths\nand local geometries (and topologies with holes).\nPreprint submitted to Elsevier Science\n\n2 September 2018\n\n\fA set of least\u2013action principles is used to model the smoothness of global,\nmacro\u2013level LSF paths, fields and geometry, according to the following prescription. The action S[\u03a6], psycho\u2013physical dimensions of Energy \u00d7 T ime =\nEf f ort and depending on macroscopic paths, fields and geometries (commonly denoted by an abstract field symbol \u03a6i ) is defined as a temporal integral\nfrom the initial time instant tini to the final time instant tf in ,\nS[\u03a6] =\n\nZ\n\ntf in\n\ntini\n\nL[\u03a6] dt,\n\n(1)\n\nwith Lagrangian density given by\nL[\u03a6] =\n\nZ\n\ndn x L(\u03a6i , \u2202xj \u03a6i ),\n\nwhere the integral is taken over all n coordinates xj = xj (t) of the LSF,\nand \u2202xj \u03a6i are time and space partial derivatives of the \u03a6i \u2212variables over\ncoordinates. The standard least action principle\n\u03b4S[\u03a6] = 0,\n\n(2)\n\ngives, in the form of the so\u2013called Euler\u2013Lagrangian equations, a shortest\n(loco)motion path, an extreme force\u2013field, and a life\u2013space geometry of minimal curvature (and without holes). In this way, we effectively derive a unique\nglobally smooth transition map\nF : INT ENT IONtini\n\n\u2732\n\nACT IONtf in ,\n\n(3)\n\nperformed at a macroscopic (global) time\u2013level from some initial time tini to\nthe final time tf in . In this way, we have obtained macro\u2013objects in the global\nLSF: a single path described by Newtonian\u2013like equation of motion, a single\nforce\u2013field described by Maxwellian\u2013like field equations, and a single obstacle\u2013\nfree Riemannian geometry (with global topology without holes).\nTo model the corresponding local, micro\u2013level LSF structures of rapidly fluctuating MD & CD, an adaptive path integral is formulated, defining a multi\u2013\nphase and multi\u2013path (multi\u2013field and multi\u2013geometry) transition amplitude\nfrom the state of Intention to the state of Action,\n\nR\n\nhAction|Intentionitotal := \u03a3 D[w\u03a6] eiS[\u03a6],\nLSF\n\n(4)\n\nwhere the Lebesgue integration is performed over all continuous \u03a6icon = paths+\nf ields + geometries, while summation is performed over all discrete processes\nand regional topologies \u03a6jdis . The symbolic differential D[w\u03a6] in the general\npath integral (22), represents an adaptive path measure, defined as a weighted\n2\n\n\fproduct\nN\nY\n\nw d\u03a6i ,\nD[w\u03a6] = lim\nN\u2212\n\u2192\u221e s=1 s s\n\n(i = 1, ..., n = con + dis).\n\n(5)\n\nThe adaptive path integral (4)\u2013(5) represents an \u221e\u2212dimensional neural network, with weights w updating by the general rule [1]\nnew value(t + 1) = old value(t) + innovation(t).\nOn the other hand, it is well\u2013known that phase transitions (PTs) are phenomena which bring about qualitative physical changes at the macroscopic level\nin presence of the same microscopic forces acting among the constituents of a\nsystem. Their mathematical description requires to translate into quantitative\nterms the mentioned qualitative changes. The standard way of doing this is\nto consider how the values of thermodynamic observables, obtained in laboratory experiments, vary with temperature, or volume, or an external field, and\nthen to associate the experimentally observed discontinuities at a PT to the\nappearance of some kind of singularity entailing a loss of analyticity [22]. Despite the smoothness of the statistical measures, after the Yang\u2013Lee theorem\n[23] we know that in the N \u2192 \u221e limit non\u2013analytic behaviors of thermodynamic functions are possible whenever the analyticity radius in the complex\nfugacity plane shrinks to zero, because this entails the loss of uniform convergence in N (number of degrees of freedom) of any sequence of real-valued\nthermodynamic functions, and all this depends on the distribution of the zeros of the grand canonical partition function. Also the other developments of\nthe rigorous theory of PTs (see, e.g., [24,25]), identify PTs with the loss of\nanalyticity.\nSimilarly, experimental findings and theoretical insights of modern neuroscience converge on interpreting brain physiology within the conceptual framework of nonlinear dynamics, operating at the brink of criticality, which is\nachieved and maintained by self-organization [5]. In this approach, dynamical\npatterning of both brain activity and corresponding behaviors is examined in\norder to develop models of how brain and behavioral events are coordinated.\nGrowing evidence supports the assumption that the linkages between events at\nmicroscopic level of neuronal assemblies and those at macroscopic behavioral\nlevels are better explained as based on shared dynamics \u2013 not on any ontological priority [6,7]. This dynamics is characterized by meta-stability and phase\ntransitions in self-organized criticality [8], both at the level of neuronal assemblies [9,5], functional connectivity of the human brain [10] and corresponding\nbehavior patterns [6,11]. A key feature of this approach is that phenomenological laws at the behavioral level can be connected to a field-theoretical description of cortical dynamics [6]. Dynamic Field Theory (DFT) [12] extends this\napproach by developing field-theoretic representations of both behavior and\n3\n\n\fits environment [13], thus building on a long established, albeit metaphorical,\ntradition of behavioral force-field analysis [2,3,4]. Our LSF\u2013formalism can be\nseen as a further extension of DFT.\nRegarding brain modelling: classical physics has provided a strong foundation\nfor understanding brain function through measuring brain activity, modelling\nthe functional connectivity of networks of neurons with algebraic matrices,\nand modelling the dynamics of neurons and neural populations with sets of\ncoupled differential equations [14,15]. Various tools from classical physics enabled recognition and documentation of aspects of the physical states of the\nbrain; the structures and dynamics of neurons, the operations of membranes\nand organelles that generate and channel electric currents; and the molecular and ionic carriers that implement the neural machineries of electrogenesis\nand learning. They support description of brain functions at several levels of\ncomplexity through measuring neural activity in the brains of animal and human subjects engaged in behavioral exchanges with their environments. One\nof the key properties of brain dynamics are the coordinated oscillations of\npopulations of neurons that change rapidly in concert with changes in the\nenvironment [16].\nAlso, most experimental neurobiologists and neural theorists have focused on\nsensorimotor functions and their adaptations through various forms of learning and memory. Reliance has been placed on measurements of the rates and\nintervals of trains of action potentials of small numbers of neurons that are\ntuned to perceptual invariances and modelling neural interactions with discrete networks of simulated neurons. These and related studies have given a\nvivid picture of the cortex as a mosaic of modules, each of which performs a\nsensory or motor function; they have not given a picture of comparable clarity\nof the integration of modules (see [16] and references therein).\nThe EEG analysis performed on rabbits and cats trained to discriminate conditioned stimuli in the various modalities (with EEG-recordings collected from\nhigh-density electrode arrays fixed on the epidural surfaces of primary sensory\nand limbic areas) has shown that cortical activity does not change continuously with time but by multiple spatial patterns in sequences during each\nperceptual action that resemble cinematographic frames on multiple screens\n[16]. The carrier waves of the patterned activity in frames have come in at\nleast two ranges identified with beta (12-30 Hz) and gamma (30-80 Hz) oscillations. The abrupt change in dynamical state with each new frame, proposed\nto be formed by a phase transition [17], has not been describable either with\nclassic integro-differential equations, or the algebras of neural networks. The\ninitiation and maintenance of shared oscillations by this phase transition requires rapid communication among neurons. Several alternative mechanisms\nhave been proposed as the agency for widespread synchrony. These are based\nin the dendritic loop current as the chief agent for intracellular communication\n4\n\n\fand the axonal action potential as the chief agent for intercellular communication [16].\nAccording to [16], many-body quantum field theory appears to be the only\nexisting theoretical tool capable to explain the dynamic origin of long-range\ncorrelations, their rapid and efficient formation and dissolution, their interim\nstability in ground states, the multiplicity of coexisting and possibly noninterfering ground states, their degree of ordering, and their rich textures\nrelating to sensory and motor facets of behaviors. It is historical fact that\nmany-body quantum field theory has been devised and constructed in past\ndecades exactly to understand features like ordered pattern formation and\nphase transitions in condensed matter physics that could not be understood\nin classical physics, similar to those in the brain.\nCommunication by propagating action potentials imposes distance-dependent\ndelays in the onset of re-synchronization during a phase transition over an\narea of cortex. The delays are measurable as brief but distance-dependent\nphase lags at the various frequencies of oscillation [17]. However, the length\nof most axons in cortex is a small fraction of observed distances of long-range\ncorrelation, with the requirement for synaptic renewal at each successive relay.\nThese long-range correlations are maintained despite continuous variations in\ntransmission frequencies that are apparent in aperiodic 'chaotic' oscillations.\nSome researchers have sought to explain zero-lag correlations with processes\nother than axo-dendritic synaptic transmission, stating that both electric fields\nand magnetic fields accompany neural loop currents. However, the electric\npotential gradients of the EEG have been shown by [18] to be inadequate in\nvivo to account for the long-range of the observed coherent activity, largely\nowing to the shunting action of glia that reduce the fraction of extracellular\ndendritic current penetrating adjacent neurons and minimize ephaptic crosstalk among cortical neurons.\nIn this paper, to describe the LSF\u2013phase\u2013transitions, with embedded chaos, we\nuse our adaptive path\u2013integral (22) along the corresponding LSF\u2013topology\u2013\nchange:\n\nR\n\nhphase out | phase ini := \u03a3\n\ntopology\u2212change\n\nD[w\u03a6] eiS[\u03a6].\n\nThis paper extends the earlier establishment of the LSF model by introducing\nthe study of chaos and phase transitions within this framework. This development is motivated \u2013 as was the original LSF model \u2013 by the potential for an\nimproved theoretical basis for studying brain physiology, and thereby also for\novercoming shortfalls in current artificial neural network function representation and approximation technologies.\n5\n\n\f2\n\nGeometrical Chaos and Topological Phase Transitions\n\nIn this section we extend the LSF\u2013formalism to incorporate geometrical chaos\nand associated topological phase transitions.\nIt is well\u2013known that on the basis of the ergodic hypothesis, statistical mechanics describes the physics of many-degrees of freedom systems by replacing\ntime averages of the relevant observables with ensemble averages. Therefore,\ninstead of using statistical ensembles, we can investigate the Hamiltonian (microscopic) dynamics of a system undergoing a phase transition. The reason for\ntackling dynamics is twofold. First, there are observables, like Lyapunov exponents, that are intrinsically dynamical. Second, the geometrization of Hamiltonian dynamics in terms of Riemannian geometry provides new observables\nand, in general, an interesting framework to investigate the phenomenon of\nphase transitions [21,35]. The geometrical formulation of the dynamics of conservative systems [26] was first used by [27] in his studies on the dynamical\nfoundations of statistical mechanics and subsequently became a standard tool\nto study abstract systems in ergodic theory.\nThe simplest, mechanical\u2013like LSF\u2013action in the individual's LSF\u2013manifold \u03a3\nhas a Riemannian locomotion form [1]\n1 Z tf in\nS[q] =\n[aij q\u0307 i q\u0307 j \u2212 V (q)] dt,\n2 tini\n\n(summation convention is assumed)\n\n(6)\nwhere aij is the 'material' metric tensor that generates the total 'kinetic energy' of cognitive (loco)motions defined by their configuration coordinates q i\nand velocities q\u0307 i , with the motivational potential energy V (q) and the standard\nHamiltonian\nN\nX\n1 2\nH(p, q) =\npi + V (q),\n(7)\ni=1 2\nwhere pi are the canonical (loco)motion momenta.\n\nDynamics of N DOF mechanical\u2013like systems with action (6) and Hamiltonian\n(7) are commonly given by the set of geodesic equations [32,33]\nk\nj\nd2 q i\ni dq dq\n+\n\u0393\n= 0,\njk\nds2\nds ds\n\n(8)\n\nwhere \u0393ijk are the Christoffel symbols of the affine Levi\u2013Civita connection of\nthe Riemannian LSF\u2013manifold \u03a3.\nAlternatively, a description of the extrema of the Hamilton's action (6) can\nbe obtained using the Eisenhart metric [28] on an enlarged LSF space-time\nmanifold (given by {q 0 \u2261 t, q 1 , . . . , q N } plus one real coordinate q N +1 ), whose\n6\n\n\farc\u2013length is\nds2 = \u22122V (q)(dq 0)2 + aij dq i dq j + 2dq 0 dq N +1 .\n\n(9)\n\nThe manifold has a Lorentzian structure [35] and the dynamical trajectories\nare those geodesics satisfying the condition ds2 = Cdt2 , where C is a positive\nconstant. In this geometrical framework, the instability of the trajectories\nis the instability of the geodesics, and it is completely determined by the\ncurvature properties of the LSF\u2013manifold \u03a3 according to the Jacobi equation\nof geodesic deviation [32,33]\nD2J i\ndq j k dq m\ni\n+\nR\nJ\n= 0,\njkm\nds2\nds\nds\n\n(10)\n\nwhose solution J, usually called Jacobi variation field, locally measures the\ndistance between nearby geodesics; D/ds stands for the covariant derivative\nalong a geodesic and Ri jkm are the components of the Riemann curvature\ntensor of the LSF\u2013manifold \u03a3.\nUsing the Eisenhart metric (9), the relevant part of the Jacobi equation (10)\nis given by the tangent dynamics equation [29,21]\nd2 J i\n+ Ri 0k0 J k = 0,\n2\ndt\n\n(i = 1, . . . , N),\n\n(11)\n\nwhere the only non-vanishing components of the curvature tensor of the LSF\u2013\nmanifold \u03a3 are\nRi 0k0 = \u2202 2 V /\u2202q i \u2202q j .\nThe tangent dynamics equation (11) is commonly used to define Lyapunov exponents in dynamical systems given by the Riemannian action (6) and Hamiltonian (7), using the formula [30]\n2\n2\nN\n2\n2\n\u03bb1 = lim 1/2t log(\u03a3N\ni=1 [Ji (t) + Ji (t)]/\u03a3i=1 [Ji (0) + Ji (0)]).\nt\u2192\u221e\n\n(12)\n\nLyapunov exponents measure the strength of dynamical chaos.\nNow, to relate these results to topological phase transitions within the LSF\u2013\nmanifold \u03a3, recall that any two high\u2013dimensional manifolds \u03a3v and \u03a3v\u2032 have\nthe same topology if they can be continuously and differentiably deformed into\none another, that is if they are diffeomorphic. Thus by topology change the\n'loss of diffeomorphicity is meant [35]. In this respect, the so\u2013called topological\ntheorem [22] says that non\u2013analyticity is the 'shadow' of a more fundamental\nphenomenon occurring in the system's configuration manifold (in our case the\nLSF\u2013manifold): a topology change within the family of equipotential hypersurfaces\n\u03a3v = {(q 1 , . . . , q N ) \u2208 RN | V (q 1 , . . . , q N ) = v},\n7\n\n\fwhere V and q i are the microscopic interaction potential and coordinates respectively. This topological approach to PTs stems from the numerical study\nof the dynamical counterpart of phase transitions, and precisely from the observation of discontinuous or cuspy patterns displayed by the largest Lyapunov exponent \u03bb1 at the transition energy [30]. Lyapunov exponents cannot be measured in laboratory experiments, at variance with thermodynamic\nobservables, thus, being genuine dynamical observables they are only be estimated in numerical simulations of the microscopic dynamics. If there are\ncritical points of V in configuration space, that is points qc = [q 1 , . . . , q N ] such\nthat \u2207V (q)|q=qc = 0, according to the Morse Lemma [31], in the neighborhood of any critical point qc there always exists a coordinate system q\u0303(t) =\n[q\u0303 1 (t), .., q\u0303 N (t)] for which\n2\n2\nV (q\u0303) = V (qc ) \u2212 q\u030312 \u2212 * * * \u2212 q\u0303k2 + q\u0303k+1\n+ * * * + q\u0303N\n,\n\n(13)\n\nwhere k is the index of the critical point, i.e., the number of negative eigenvalues of the Hessian of the potential energy V . In the neighborhood of a critical\npoint of the LSF\u2013manifold \u03a3, (13) yields\n\u2202 2 V /\u2202q i \u2202q j = \u00b1\u03b4 ij ,\nwhich gives k unstable directions which contribute to the exponential growth\nof the norm of the tangent vector J [30].\nThis means that the strength of dynamical chaos within the individual's LSF\u2013\nmanifold \u03a3, measured by the largest Lyapunov exponent \u03bb1 given by (12), is\naffected by the existence of critical points qc of the potential energy V (q).\nHowever, as V (q) is bounded below, it is a good Morse function, with no\nvanishing eigenvalues of its Hessian matrix. According to Morse theory [31],\nthe existence of critical points of V is associated with topology changes of the\nhypersurfaces {\u03a3v }v\u2208R .\nMore precisely, let VN (q1 , . . . , qN ) : RN \u2192 R, be a smooth, bounded from\nbelow, finite-range and confining potential 1 . Denote by \u03a3v = V \u22121 (v), v \u2208 R,\nits level sets, or equipotential hypersurfaces, in the LSF\u2013manifold \u03a3. Then let\nv\u0304 = v/N be the potential energy per degree of freedom. If there exists N0 , and\nif for any pair of values v\u0304 and v\u0304 \u2032 belonging to a given interval Iv\u0304 = [v\u03040 , v\u03041 ] and\nfor any N > N0 then the sequence of the Helmoltz free energies {FN (\u03b2)}N \u2208N\n\u2013 where \u03b2 = 1/T (T is the temperature) and \u03b2 \u2208 I\u03b2 = (\u03b2(v\u03040 ), \u03b2(v\u03041 )) \u2013\nis uniformly convergent at least in C 2 (I\u03b2 ) [the space of twice differentiable\nfunctions in the interval I\u03b2 ], so that limN \u2192\u221e FN \u2208 C 2 (I\u03b2 ) and neither first\nnor second order phase transitions can occur in the (inverse) temperature\n1\n\nThese requirements for V are fulfilled by standard interatomic and intermolecular\ninteraction potentials, as well as by classical spin potentials.\n\n8\n\n\finterval (\u03b2(v\u03040 ), \u03b2(v\u03041 )), where the inverse temperature is defined as [22,35]\n(\u2212)\n\n\u03b2(v\u0304) = \u2202SN (v\u0304)/\u2202v\u0304,\n\n(\u2212)\n\nSN (v\u0304) = N \u22121 log\n\nwhile\n\nZ\n\nV (q)\u2264v\u0304N\n\ndN q\n\nis one of the possible definitions of the microcanonical configurational entropy.\nThe intensive variable v\u0304 has been introduced to ease the comparison between\nquantities computed at different N-values.\nThis theorem means that a topology change of the {\u03a3v }v\u2208R at some vc is a\nnecessary condition for a phase transition to take place at the corresponding\nenergy value. The topology changes implied here are those described within\nthe framework of Morse theory through 'attachment of handles' [31] to the\nLSF\u2013manifold \u03a3.\nIn the LSF path\u2013integral language [1], we can say that suitable topology\nchanges of equipotential submanifolds of the individual's LSF\u2013manifold \u03a3 can\nentail thermodynamic\u2013like phase transitions [37,38,39], according to the general formula:\n\nR\n\nhphase out | phase ini := \u03a3\n\ntopology\u2212change\n\nD[w\u03a6] eiS[\u03a6].\n\nThe statistical behavior of the LSF\u2013(loco)motion system (6) with the standard\nHamiltonian (7) is encompassed, in the canonical ensemble, by its partition\nfunction, given by the phase\u2013space path integral [33]\n( Z\n\nR\n\nD[p]D[q] exp i\nZN = \u03a3\ntop\u2212ch\n\n)\n\nt\u2032\n\nt\n\n[pq\u0307 \u2212 H(p, q)] d\u03c4 ,\n\n(14)\n\nwhere we have used the shorthand notation\n\nR\n\n\u03a3\ntop\u2212ch\n\nD[p]D[q] \u2261\n\nZ Y\n\u03c4\n\ndq(\u03c4 )dp(\u03c4 )\n.\n2\u03c0\n\nThe phase\u2013space path integral (14) can be calculated as the partition function\n[36],\n\nZN (\u03b2) =\n\nZ Y\nN\n\ndpi dq i e\u2212\u03b2H(p,q) =\n\ni=1\n\n=\n\n\u03c0\n\u03b2\n\n!N Z\n2\n\n0\n\n\u221e\n\ndv e\u2212\u03b2v\n\nZ\n\n\u03a3v\n\n\u03c0\n\u03b2\n\n! NZ\n2\n\nN\nY\n\ndq i e\u2212\u03b2V (q)\n\ni=1\n\nd\u03c3\n,,\nk\u2207V k\n\n(15)\n\nwhere the last term is written using the so\u2013called co\u2013area formula [20], and v\nlabels the equipotential hypersurfaces \u03a3v of the LSF\u2013manifold \u03a3,\n\u03a3v = {(q 1 , . . . , q N ) \u2208 RN |V (q 1 , . . . , q N ) = v}.\n9\n\n\fEquation (15) shows that the relevant statistical information is contained in\nthe canonical configurational partition function\nZNC\n\n=\n\nZ Y\n\ndq i V (q)e\u2212\u03b2V (q) .\n\nNote that ZNC is decomposed, in the last term of (15), into an infinite summation of geometric integrals,\nZ\n\n\u03a3v\n\nd\u03c3 /k\u2207V k,\n\ndefined on the {\u03a3v }v\u2208R . Once the microscopic interaction potential V (q) is\ngiven, the configuration space of the system is automatically foliated into\nthe family {\u03a3v }v\u2208R of these equipotential hypersurfaces. Now, from standard\nstatistical mechanical arguments we know that, at any given value of the\ninverse temperature \u03b2, the larger the number N, the closer to \u03a3v \u2261 \u03a3u\u03b2\nare the microstates that significantly contribute to the averages, computed\nthrough ZN (\u03b2), of thermodynamic observables. The hypersurface \u03a3u\u03b2 is the\none associated with\nu\u03b2 =\n\n(ZNC )\u22121\n\nZ Y\n\ndq i V (q)e\u2212\u03b2V (q) ,\n\nthe average potential energy computed at a given \u03b2. Thus, at any \u03b2, if N is\nvery large the effective support of the canonical measure shrinks very close\nto a single \u03a3v = \u03a3u\u03b2 . Hence, the basic origin of a phase transition lies in a\nsuitable topology change of the {\u03a3v }, occurring at some vc [36]. This topology\nchange induces the singular behavior of the thermodynamic observables at a\nphase transition. It is conjectured that the counterpart of a phase transition\nis a breaking of diffeomorphicity among the surfaces \u03a3v , it is appropriate to\nchoose a diffeomorphism invariant to probe if and how the topology of the \u03a3v\nchanges as a function of v. Fortunately, such a topological invariant exists, the\nEuler characteristic of the LSF\u2013manifold \u03a3, defined by [32,33]\n\u03c7(\u03a3) =\n\nN\nX\n\n(\u22121)k bk (\u03a3),\n\n(16)\n\nk=0\n\nwhere the Betti numbers bk (\u03a3) are diffeomorphism invariants. 2 This homological formula can be simplified by the use of the Gauss\u2013Bonnet\u2013Hopf theorem,\nthat relates \u03c7(\u03a3) with the total Gauss\u2013Kronecker curvature KG of the LSF\u2013\nmanifold \u03a3\nZ\n\u03c7(\u03a3) = KG d\u03c3,\n(17)\n\u03a3\n\nwhere\n\nd\u03c3 =\n2\n\nq\n\ndet(a)dx1 dx2 * * * dxn\n\nThe Betti numbers bk are the dimensions of the de Rham's cohomology vector\nspaces H k (\u03a3; R) (therefore the bk are integers).\n\n10\n\n\fis the invariant volume measure of the LSF\u2013manifold \u03a3 and a is the determinant of the LSF metric tensor aij . For technical details of this topological\napproach, see [34].\nThe domain of validity of the 'quantum' is not restricted to the microscopic\nworld [19]. There are macroscopic features of classically behaving systems,\nwhich cannot be explained without recourse to the quantum dynamics. This\nfield theoretic model leads to the view of the phase transition as a condensation that is comparable to the formation of fog and rain drops from water\nvapor, and that might serve to model both the gamma and beta phase transitions. According to such a model, the production of activity with long-range\ncorrelation in the brain takes place through the mechanism of spontaneous\nbreakdown of symmetry (SBS), which has for decades been shown to describe\nlong-range correlation in condensed matter physics. The adoption of such a\nfield theoretic approach enables modelling of the whole cerebral hemisphere\nand its hierarchy of components down to the atomic level as a fully integrated\nmacroscopic quantum system, namely as a macroscopic system which is a\nquantum system not in the trivial sense that it is made, like all existing matter, by quantum components such as atoms and molecules, but in the sense\nthat some of its macroscopic properties can best be described with recourse\nto quantum dynamics (see [16] and references therein).\nPhase transitions can also be associated with autonomous robot competence\nlevels, as informal specifications of desired classes of behaviors for robots over\nall environments they will encounter, as described by Brooks' subsumption\narchitecture approach [45,46,47]. The distributed network of augmented finite\u2013\nstate machines can exist in different phases or modalities of their state\u2013space\nvariables, which determine the systems intrinsic behavior. The phase transition\nrepresented by this approach is triggered by either internal (a set\u2013point) or\nexternal (a command) control stimuli, such as a command to transition from\na sleep mode to awake mode, or walking to running.\n\n3\n\nModelling Human Joint Action\n\nCognitive neuroscience investigations, including fMRI studies of human coaction, suggest that cognitive and neural processes supporting co-action include joint attention, action observation, task sharing, and action coordination\n[40,41,42,43]. For example, when two actors are given a joint control task (e.g.,\ntracking a moving target on screen) and potentially conflicting controls (e.g.,\none person in charge of acceleration, the other \u2013 deceleration), their joint performance depends on how well they can anticipate each other's actions. In\nparticular, better coordination is achieved when individuals receive real-time\nfeedback about the timing of each other's actions [43].\n11\n\n\fTo model the dynamics of the two\u2013actor joint action, we propose to associate each of the actors with an n\u2212dimensional Riemannian LSF\u2013manifold\n\u03a3, that is a set of their own time dependent trajectories, \u03a3\u03b1 = {xi (ti )} and\n\u03a3\u03b2 = {y j (tj )}, respectively. Their associated tangent bundles contain their\nindividual nD (loco)motion velocities, T \u03a3\u03b1 = {\u1e8bi (ti ) = dxi /dti } and T \u03a3\u03b2 =\n{\u1e8f j (tj ) = dy j /dtj }. Further, following the general formalism of [1], outlined\nin the introduction, we use the modelling machinery consisting of: (i) Adaptive joint action at the top\u2013master level, describing the externally\u2013appearing\ndeterministic, continuous and smooth dynamics, and (ii) Corresponding adaptive path integral (22) at the bottom\u2013slave level, describing a wildly fluctuating dynamics including both continuous trajectories and Markov chains. This\nlower\u2013level joint dynamics can be further discretized into a partition function\nof the corresponding statistical dynamics.\nIn particular, by extending and adapting classical Wheeler\u2013Feynman action\u2013\nat\u2013a\u2013distance electrodynamics [44] and applying it to human co\u2013action, we\npropose a two\u2013term joint action:\n\nA[x, y; ti , tj ] =\nwith\n\n1\n2\nh\n\nZ Z\nti\n\ntj\n\n\u03b1i \u03b2 j \u03b4(Iij2 ) \u1e8bi (ti ) \u1e8f j (tj ) dti dtj +\ni2\n\nIij2 = xi (ti ) \u2212 y j (tj ) ,\n\n1\n2\n\nZ\n\nt\n\ngij \u1e8bi (t)\u1e8bj (t) dt\n\nwhere IN \u2264 ti , tj , t \u2264 OUT.\n\nThe first term in (18) represents potential energy of the cognitive/motivational\ninteraction between the two agents \u03b1i and \u03b2 j . 3 It is a double integral over a\ndelta function of the square of interval I 2 between two points on the paths in\ntheir Life\u2013Spaces; thus, interaction occurs only when this interval, representing\nthe motivational cognitive distance between the two agents, vanishes. Note\nthat the cognitive (loco)motions of the two agents \u03b1i [xi (ti )] and \u03b2 j [y j (tj )],\ngenerally occur at different times ti and tj unless ti = tj , when cognitive\nsynchronization occurs.\nThe second term in (18) represents kinetic energy of the physical interaction.\nNamely, when the cognitive synchronization in the first term takes place, the\nsecond term of physical kinetic energy is activated in the common manifold,\nwhich is one of the agents' Life Spaces, say \u03a3\u03b1 = {xi (ti )}.\nConversely, if we have a need to represent coaction of three actors, say \u03b1i , \u03b2 j\nand \u03b3 k (e.g., \u03b1i in charge of acceleration, \u03b2 j \u2013 deceleration and \u03b3 k \u2212 steering),\nwe can associate each of them with an nD Riemannian Life\u2013Space manifold,\n\u03a3\u03b1 = {xi (ti )}, \u03a3\u03b2 = {y j (tj )}, and \u03a3\u03b3 = {z k (tk )}, respectively, with the corresponding tangent bundles containing their individual (loco)motion velocities,\n3\n\nAlthough, formally, this term contains cognitive velocities, it still represents 'potential energy' from the physical point of view.\n\n12\n\n(18)\n\n\fT \u03a3\u03b1 = {\u1e8bi (ti ) = dxi /dti }, T \u03a3\u03b2 = {\u1e8f j (tj ) = dy j /dtj } and T \u03a3\u03b3 = {\u017c k (tk ) =\ndz k /dtk }. Then, instead of (18) we have\n\nA[ti , tj , tk ; t] =\n\n1\n2\n\nZ Z Z\nti\n\ntj\n\ntk\n\n2\n\u03b1i (ti )\u03b2 j (tj ) \u03b3 k (tk )\u03b4(Iijk\n) \u1e8bi (ti ) \u1e8f j (tj ) \u017c k (tk ) dti dtj dtk\n\n1\nW M (t, q, q\u0307) q\u0307 r q\u0307 s dt,\nwhere IN \u2264 ti , tj , tk , t \u2264 OUT\n2 t rs\n2\nwith\nIijk\n= [xi (ti ) \u2212 y j (tj )]2 + [y j (tj ) \u2212 z k (tk )]2 + [z k (tk ) \u2212 xi (ti )]2 ,\n+\n\nZ\n\n(19)\n\nDue to an intrinsic chaotic coupling, the three\u2013actor (or, n\u2212actor, n > 3)\njoint action (19) has a considerably more complicated geometrical structure\nthen the bilateral co\u2013action (18). 4 It actually happens in the common 3nD\nFinsler manifold \u03a3J = \u03a3\u03b1 \u222a \u03a3\u03b2 \u222a \u03a3\u03b3 , parameterized by the local joint coordinates dependent on the common time t. That is, \u03a3J = {q r (t), r = 1, ..., 3n}.\nGeometry of the joint manifold \u03a3J is defined by the Finsler metric function\nds = F (q r , dq r ), defined by\nF 2 (q, q\u0307) = grs (q, q\u0307)q\u0307 r q\u0307 s ,\n\n(where grs is the Riemann metric tensor) (20)\n\nand the Finsler tensor Crst (q, q\u0307), defined by (see [32,33])\nCrst (q, q\u0307) =\n\n1 \u2202 3 F 2 (q, q\u0307)\n1 \u2202grs\n=\n.\nr\ns\nt\n4 \u2202 q\u0307 \u2202 q\u0307 \u2202 q\u0307\n2 \u2202 q\u0307 r \u2202 q\u0307 s\n\n(21)\n\nFrom the Finsler definitions (20)\u2013(21), it follows that the partial interaction\nmanifolds, \u03a3\u03b1 \u222a \u03a3\u03b2 , \u03a3\u03b2 \u222a \u03a3y and \u03a3\u03b1 \u222a \u03a3y , have Riemannian structures with\nthe corresponding interaction kinetic energies,\n1\nT\u03b1\u03b2 = gij \u1e8bi \u1e8f j ,\n2\n\n1\nT\u03b1\u03b3 = gik \u1e8bi \u017c k ,\n2\n\n1\nT\u03b2\u03b3 = gjk \u1e8f j \u017c k .\n2\n\nAt the slave level, the adaptive path integral (see [1]), representing an \u221e\u2212dimensional neural network, corresponding to the adaptive bilateral joint action (18),\nreads\nhOUT |INi := \u03a3 D[w, x, y] eiA[x,y;ti,tj ] ,\n(22)\n\nR\n\nwhere the Lebesgue integration is performed over all continuous paths xi =\nxi (ti ) and y j = y j (tj ), while summation is performed over all associated discrete Markov fluctuations and jumps. The symbolic differential in the path\nintegral (22) represents an adaptive path measure, defined as a weighted product\nD[w, x, y] = lim\n\nN \u2192\u221e\n\nN\nY\n\nwijs dxi dy j ,\n\n(i, j = 1, ..., n).\n\n(23)\n\ns=1\n\n4\n\nRecall that the necessary condition for chaos in continuous temporal or spatiotemporal systems is to have three variables with nonlinear couplings between them.\n\n13\n\n\fSimilarly, in case of the triple joint action, the adaptive path integral reads,\n\nR\n\nhOUT |INi := \u03a3 D[w; x, y, z; q] eiA[ti,tj ,tk ;t] ,\n\n(24)\n\nwith the adaptive path measure defined by\nD[w; x, y, z; q] = lim\n\nN \u2192\u221e\n\nN\nY\n\nS\nwijkr\ndxi dy j dz k dq r ,\n\n(i, j, k = 1, ..., n; r = 1, ..., 3n).\n\nS=1\n\n(25)\n\nThe adaptive path integrals (22) and (24) incorporate the local Bernstein\nadaptation process [48,49] according to Bernstein's discriminator concept\ndesired state SW (t + 1) = current state IW (t) + adjustment step \u2206W (t).\n\n4\n\nDiscussion\n\nThis paper has developed an adaptive path integral approach to modelling\ntopological phase transition, chaos and joint action in the LSF\u2013manifold. The\ntraditional neural networks approaches are known for their classes of functions they can represent. 5 This limitation has been attributed to their lowdimensionality (the largest neural networks are limited to the order of 105\ndimensions [53]). The proposed path integral approach represents a new family of function-representation methods, which potentially offers a basis for a\nfundamentally more expansive solution.\nThis new family of function-representation methods is now capable of representing input/output behavior of more than one actor. However, as we add the\nsecond and subsequent actors to the model, the requirements for the rigorous\ngeometrical representations of their respective LSFs become nontrivial. For a\nsingle actor or a two\u2013actor co\u2013action the Riemannian geometry was sufficient,\nbut it becomes insufficient for modelling the n\u2013actor (with n \u2265 3) joint action,\ndue to an intrinsic chaotic coupling between the individual actors' LSFs. To\nmodel an n\u2013actor joint LSF, we have to use the Finsler geometry, which is a\ngeneralization of the Riemannian one. This progression may seem trivial, both\nfrom standard psychological point of view, and from computational point of\nview, but it is not trivial from the geometrical perspective.\nThe robustness of biological motor control systems in handling excess degrees of freedom has been attributed to a combination of tight hierarchical\ncentral planning and multiple levels of sensory feedback self\u2013regulation that\n5\n\nHere we are talking about functions in an extensional rather than merely intensional sense; that is, function can be read as input/output behavior [54,55,56,57].\n\n14\n\n\fare relatively autonomous in their operation [50]. These two processes are connected through a top\u2013down process of action script delegation and bottom\u2013up\nemergency escalation mechanisms. There is a complex interplay between the\ncontinuous sensory feedback and motion/action planning to achieve effective\noperation in uncertain environments, such as movement on uneven terrain\ncluttered with obstacles.\nComplementing Bernstein's motor control principles is Brooks' concept of\ncomputational subsumption architectures [45,47], which provides a method\nfor structuring reactive systems from the bottom up using layered sets of behaviors. Each layer implements a particular goal of the agent, which subsumes\nthat of the underlying layers. Similar architectures have been proposed to account for the mechanism of cognitive and motor working memory, sequence\nlearning and performance (see, e.g.,[11]). According to [45,47], a robot's lowest layer could be \"avoid an object\", on top of it would be the layer \"wander\naround\", which in turn lies under \"explore the world\". The top layer in such\na case could represent the ultimate goal of \"creating a map\". In this configuration, the lowest layers can work as reflexive mechanisms, while the higher\nlayers contain control logic implementing more abstract goals.\nThe substrate for this architecture comprises a network of finite state machines augmented with timing elements. A subsumption compiler compiles\naugmented finite state machine descriptions into a special-purpose scheduler\nto simulate parallelism and a set of finite state machine simulation routines.\nThe resulting networked behavior function can be described as:\nf inal state w(t+1) = current state w(t) + adjustment behavior f (\u2206w(t)).\nThe Bernstein weights, or Brooks nodes, wijs = wijs (t) in (23) are updated\nby the Bernstein loop during the joint transition process, according to one of\nthe two standard neural learning schemes, in which the micro\u2013time level is\ntraversed in discrete steps:\n(1) A self\u2013organized, unsupervised (e.g., Hebbian\u2013like [51]) learning rule:\nwijs (t + 1) = wijs (t) +\n\n\u03c3 s,d\n(wij (t) \u2212 wijs,a(t)),\n\u03b7\n\n(26)\n\nwhere \u03c3 = \u03c3(t), \u03b7 = \u03b7(t) denote signal and noise, respectively, while new\nsuperscripts d and a denote desired and achieved micro\u2013states, respectively; or\n(2) A certain form of a supervised gradient descent learning:\nwijs (t + 1) = wijs (t) \u2212 \u03b7\u2207J(t),\n\n(27)\n\nwhere \u03b7 is a small constant, called the step size, or the learning rate, and\n15\n\n\f\u2207J(n) denotes the gradient of the 'performance hyper\u2013surface' at the\nt\u2212th iteration,\nwhere t = t0 , t1 , ..., ts then t + 1 = t1 , t2 , ..., ts+1 .\nBoth Hebbian and supervised learning 6 are used in local decision making\nprocesses, e.g., at the intention formation phase (see [1]). Overall, the model\npresents a set of formalisms to represent time-critical aspects of collective\nperformance in tactical teams. Its applications include hypotheses generation for real and virtual experiments on team performance, both in human\nteams (e.g., emergency crews) and hybrid human-machine teams (e.g., humanrobotic crews). It is of particular value to the latter, as the increasing autonomy of robotic platforms poses non-trivial challenges, not only for the design\nof their operator interfaces, but also for the design of the teams themselves\nand their concept of operations.\nSome specific problems that Brooks poses in [47] include: (i) how to combine\nmany (e.g., more than a dozen) behavior generating modules in a way which\nlets them be productive and cooperative; (ii) how to automate the building\nof interaction interfaces between behavior generating modules, so that larger\n(and hence more competent) systems can be built; and (iii) how to automate\nthe construction of individual behavior generating modules, or even to automate their modification. An aggregation of phase\u2013transition\u2013related order\nparameters within individual actors need to be triggered (either by an internal\nor external control mechanism) into collective alignment to be able to perform the joint action. The 'guiding' forces help to guide the better alignment\nor fine\u2013tunning of individual LSFs for useful co\u2013action outcomes to emerge.\nUsing the combined LSF\u2013geometry approach proposed in this paper should\nprovide some useful answers to the above questions.\nHere we remark that collective phase transitions, which have more coupled degrees of freedom than individual ones, necessitate more stringent constraints,\nto avoid/control a higher-dimensional chaos. The sophisticated chaos\u2013control\ntechniques, including constraining contextual boundaries \u2013 choosing a target\nsubspace of the joint LSF-manifold \u2013 and guiding force\u2013fields, need to be defined to alow desired collective behaviors to emerge from both chaotic and\nnon-chaotic sets of possible initial evolution alternatives.\n6\n\nNote that we could also use a reward\u2013based, reinforcement learning rule [52], in\nwhich system learns its optimal policy:\ninnovation(t) = |reward(t) \u2212 penalty(t)|.\n\n16\n\n\f5\n\nConclusion\n\nExtending the LSF model to incorporate the notions of meta-stability, phase\ntransitions and embedded geometrical chaos has enabled representation of increased complexity in goal-directed action, including the capability to represent joint action by two or more co-actors. This capability remains consistent\nwith modern neuroscience theorizing linking macro-behavioral meta-stability\nand phase transitions to microscopic-level cortical neurodynamics.\nThere is a degree of correspondence between phase transition mechanisms\nfor cognitive performance in humans and transitions between stable behavior\nstates and competency levels in autonomous robots. The approach developed\nin this paper offers a theoretical framework to integrate observations and models of both individual and collective robot behaviors and competencies, capable\nof coping with the increased complexity of the real world. This framework can\nboth guide future substantive empirical work into collective robot behaviors\nand be validated by it.\nThe new model developed in this paper offers substantial improvements over\nthe geometrical properties regarding multiple-actor systems, due to the chaotic\ncoupling between the actors. We have also discussed how the proposed path\nintegral represents a new family of function representation techniques that\nmay expand on the range of function types that are currently afforded by\nstandard neural-network models. Specifically, we are interested here in biologically plausible function representation as a means for characterizing the\ninput/output behavior of multi-actor systems, and thus regard function representation in an extensional sense. The full realisation of these possibilities\nin practical applications is a subject of ongoing research.\n\nReferences\n[1] V. Ivancevic, E. Aidman, Life-space foam: A medium for motivational and\ncognitive dynamics. Physica A 382, 616\u2013630, (2007)\n[2] K. Lewin, Field Theory in Social Science. Univ. Chicago Press, Chicago, (1951)\n[3] K. Lewin, Resolving Social Conflicts, and, Field Theory in Social Science. Am.\nPsych. Assoc., Washington, (1997)\n[4] M. Gold, A Kurt Lewin Reader, the Complete Social Scientist, Am. Psych.\nAssoc., Washington, (1999)\n[5] Werner, G., Metastability, criticality and phase transitions in brain and its\nmodels. Biosyst. 90(2), 496-508, (2007)\n\n17\n\n\f[6] Kelso, J.A.S., Bressler, S.L., Buchanan, S., DeGuzman, G.C., Ding, M., Fuchs,\nA., Holroyd, T., Phase transition in brain and human behavior. Phys. Lett. A\n169, 134144, (1992)\n[7] W. Erlhagen, E. Bicho, The dynamic neural field approach to cognitive robotics.\nJ. Neu. Eng. 3, R36-R54, (2006)\n[8] Bak, P. How Nature Works: The Science of Self-Organized Criticality.\nCopernicus, New York, (1996)\n[9] Freeman, W.J., A field-theoretic approach to understanding scale-free\nneocortical dynamics. Biol. Cybern. 92, 350359, (2005)\n[10] Chialvo, D.R., Critical brain networks. Physica A 340, 756765, (2004)\n[11] Grossberg, S., Pearson, L.R., Laminar Cortical Dynamics of Cognitive and\nMotor Working Memory, Sequence Learning and Performance: Toward a Unified\nTheory of How the Cerebral Cortex Works. Tec. Rep. CAS/CNS-TR-08-002,\nBoston Univ. Psych. Review, in press. (2008)\n[12] Amari, S., Dynamics of pattern formation in lateral-inhibition type neural fields.\nBiol. Cybern. 27, 77\u201387, (1977)\n[13] Sch\u00f6ner, G., Dynamical Systems Approaches to Cognition. In: Cambridge\nHandbook of Computational Cognitive Modeling. Cambridge University Press.\nR. Sun (ed), (2007)\n[14] Freeman, W.J., Mass Action in the Nervous System. Academic Press, New York,\n(1975/2004)\n[15] Freeman, W.J., Neurodynamics. An Exploration of Mesoscopic Brain\nDynamics. Springer-Verlag, London UK, (2000)\n[16] Freeman, W.J., Vitiello, G., Nonlinear brain dynamics as macroscopic\nmanifestation of underlying many-body field dynamics. Phys. Life Rev. 3(2),\n93\u2013118, (2006)\n[17] Freeman, W.J., Origin, structure, and role of background EEG activity. Part 2.\nAmplitude. Clin. Neurophysiol. 115, 2089-2107, (2004)\n[18] Freeman, W.J., Baird, B., Effects of applied electric current fields on cortical\nneural activity. Chapter in: Schwartz E (ed.) Computational Neuroscience.\nPlenum, New York, 274-287, (1989)\n[19] Umezawa, H., Advanced field theory: micro, macro and thermal concepts. Am.\nInst. Phys. New York, (1993)\n[20] H. Federer, Geometric Measure Theory. Springer, New York, (1969)\n[21] L. Caiani, L. Casetti, C. Clementi, M. Pettini, Geometry of Dynamics,\nLyapunov Exponents, and Phase Transitions. Phys. Rev. Lett. 79, 4361-4364,\n(1997)\n\n18\n\n\f[22] R. Franzosi, M. Pettini, Theorem on the origin of Phase Transitions. Phys. Rev.\nLett. 92(6), 060601, (2004)\n[23] C.N. Yang, T.D. Lee, Statistical Theory of Equations of State and Phase\nTransitions. I. Theory of Condensation. Phys. Rev. 87, 404, (1952)\n[24] H.O. Georgii, Gibbs Measures and Phase Transitions. Walter de Gruyter,\nBerlin, (1988)\n[25] D. Ruelle, Thermodynamic formalism. Encyclopaedia of Mathematics and its\nApplications, Addison-Wesley, New York, (1978)\n[26] R. Abraham, J.E. Marsden, Foundations of mechanics. Addison-Wesley,\nRedwood City, (1987)\n[27] N.S. Krylov, Works on the foundations of statistical mechanics. Princeton Univ.\nPress, Princeton, (1979)\n[28] L.P. Eisenhart, Dynamical trajectories and geodesics. Math. Ann. 30, 591-606,\n(1929)\n[29] L. Casetti, C. Clementi, M. Pettini, Riemannian theory of Hamiltonian chaos\nand Lyapunov exponents. Phys. Rev. E 54, 5969 (1996)\n[30] L. Casetti, M. Pettini, and E.G.D. Cohen, Geometric Approach to Hamiltonian\nDynamics and Statistical Mechanics. Phys. Rep. 337, 237-341, (2000)\n[31] M.W. Hirsch, Differential Topology. Springer, New York, (1976)\n[32] Ivancevic, V., Ivancevic, T.: Geometrical Dynamics of Complex Systems.\nSpringer, Series: Microprocessor-Based and Intelligent Systems Engineering,\nVol. 31, (2006)\n[33] V. Ivancevic, T. Ivancevic, Applied Differfential Geometry: A Modern\nIntroduction. World Scientific, Series: Mathematics, (2007)\n[34] J.A. Thorpe, Elementary Topics in Differential Geometry. (Springer-Verlag,\nNew York, 1979).\n[35] M. Pettini, Geometry and Topology in Hamiltonian Dynamics and Statistical\nMechanics. Springer, New York, (2007)\n[36] R. Franzosi, M. Pettini, L. Spinelli, Topology and phase transitions: a\nparadigmatic evidence. Phys. Rev. Lett. 84, 2774-2777, (2000)\n[37] Haken, H., Synergetics: An Introduction (3rd ed) Springer, Berlin, (1983)\n[38] Haken, H., Advanced Synergetics: Instability Hierarchies of Self-Organizing\nSystems and Devices (3nd ed.) Springer, Berlin. (1993)\n[39] Haken, H., Principles of Brain Functioning: A Synergetic Approach to Brain\nActivity, Behavior and Cognition, Springer, Berlin, (1996)\n\n19\n\n\f[40] L. Fogassi, P.F. Ferrari, B. Gesierich, S. Rozzi, F. Chersi, G. Rizzolatti, Parietal\nlobe: From action organization to intention understanding. Science, 29, 662-667,\n(2005)\n[41] G. Knoblich, S. Jordan, Action coordination in individuals and groups: Learning\nanticipatory control. J. Exp. Psych.: Learning, Memory & Cognition, 29, 10061016, (2003)\n[42] R.D. Newman-Norlund, M.L. Noordzij, R.G.J. Meulenbroek, H. Bekkering,\nExploring the brain basis of joint action: Co-ordination of actions, goals and\nintentions. Soc. Neurosci. 2(1), 48\u201365, (2007)\n[43] N. Sebanz, H. Bekkering, G. Knoblich. Joint action: bodies and minds moving\ntogether. Tr. Cog. Sci. 10(2), 70-76, (2006)\n[44] J.A. Wheeler, R.P. Feynman, Classical Electrodynamics in Terms of Direct\nInterparticle Action. Rev. Mod. Phys., 21, 425-433, (1949)\n[45] R.A. Brooks, A Robust Layered Control System for a Mobile Robot. IEEE\nTrans. Rob. Aut., 2(1), 14-23, (1986)\n[46] R.A. Brooks, A robot that walks: Emergent behavior form a carefully evolved\nnetwork, Neural Computation, 1(2) (Summer 1989) 253-262.\n[47] R.A. Brooks, Elephants Don't Play Chess. Rob. Aut. Sys. 6, 3-15, (1990)\n[48] N.A. Bernstein, The Coordination and Regulation of Movements. Pergamon,\nLondon, (1967)\n[49] N.A. Bernstein, Some emergent problems of the regulation of motor acts. In:\nH.T.A.Whiting (Ed.) Human Motor Actions: Bernstein Reassessed, 343\u2013358.\nNorth Holland, Amsterdam, (1982)\n[50] N.A. Bernstein, M.L. Latash, M.T. Turvey (Eds), Dexterity and its\ndevelopment. Hillsdale, NJ, England: Lawrence Erlbaum Associates, (1996)\n[51] D.O. Hebb, The Organization of Behavior, Wiley, New York, (1949)\n[52] R.S. Sutton, A.G. Barto, Reinforcement Learning: An Introduction. MIT Press,\nCambridge, MA, (1998)\n[53] Izhikevich, E.M., Edelman, G.M., Large-Scale Model of Mammalian\nThalamocortical Systems. PNAS, 105, 3593-3598, (2008)\n[54] Barendregt, H., The Lambda Calculus: Its syntax and semantics. Studies in\nLogic and the Foundations of Mathematics, North Holland, Amsterdam, (1984)\n[55] van Benthem, J., Reflections on epistemic logic. Logique & Analyse, 133-134,\n514, (1991)\n[56] Forster, T., Logic, Induction and the Theory of Sets. London Mathematical\nSociety Student Texts 56, Cambridge Univ. Press, (2003)\n[57] Hankin, C., An introduction to Lambda Calculi for Computer Scientists, College\nPub. (2004)\n\n20\n\n\f"}