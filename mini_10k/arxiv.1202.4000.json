{"id": "http://arxiv.org/abs/1202.4000v2", "guidislink": true, "updated": "2012-02-20T14:55:55Z", "updated_parsed": [2012, 2, 20, 14, 55, 55, 0, 51, 0], "published": "2012-02-17T20:06:50Z", "published_parsed": [2012, 2, 17, 20, 6, 50, 4, 48, 0], "title": "High order three-term recursions, Riemann-Hilbert minors and Nikishin\n  systems on star-like sets", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.2813%2C1202.5937%2C1202.1609%2C1202.6665%2C1202.1538%2C1202.3322%2C1202.3952%2C1202.5785%2C1202.0419%2C1202.4000%2C1202.0320%2C1202.5185%2C1202.1527%2C1202.1738%2C1202.4879%2C1202.3599%2C1202.2445%2C1202.6046%2C1202.1359%2C1202.6656%2C1202.4301%2C1202.3985%2C1202.3586%2C1202.5264%2C1202.1938%2C1202.2393%2C1202.3265%2C1202.2334%2C1202.1094%2C1202.4237%2C1202.0498%2C1202.0624%2C1202.4297%2C1202.3020%2C1202.5781%2C1202.6094%2C1202.1758%2C1202.1574%2C1202.5309%2C1202.2444%2C1202.4912%2C1202.5903%2C1202.3803%2C1202.3902%2C1202.2057%2C1202.4569%2C1202.0880%2C1202.1215%2C1202.4636%2C1202.1727%2C1202.0700%2C1202.5938%2C1202.3935%2C1202.0120%2C1202.2607%2C1202.2121%2C1202.0859%2C1202.6446%2C1202.5422%2C1202.3674%2C1202.1452%2C1202.2949%2C1202.6352%2C1202.2546%2C1202.4926%2C1202.1812%2C1202.1064%2C1202.2673%2C1202.3657%2C1202.5130%2C1202.2633%2C1202.1601%2C1202.1848%2C1202.0861%2C1202.0891%2C1202.2606%2C1202.2484%2C1202.5723%2C1202.5612%2C1202.5447%2C1202.3490%2C1202.0926%2C1202.1203%2C1202.3941%2C1202.2016%2C1202.6246%2C1202.6345%2C1202.5453%2C1202.3349%2C1202.0588%2C1202.2537%2C1202.3256%2C1202.3051%2C1202.3567%2C1202.6129%2C1202.2202%2C1202.1654%2C1202.5132%2C1202.4645%2C1202.6393%2C1202.5405&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "High order three-term recursions, Riemann-Hilbert minors and Nikishin\n  systems on star-like sets"}, "summary": "We study monic polynomials $Q_n(x)$ generated by a high order three-term\nrecursion $xQ_n(x)=Q_{n+1}(x)+a_{n-p} Q_{n-p}(x)$ with arbitrary $p\\geq 1$ and\n$a_n>0$ for all $n$. The recursion is encoded by a two-diagonal Hessenberg\noperator $H$. One of our main results is that, for periodic coefficients $a_n$\nand under certain conditions, the $Q_n$ are multiple orthogonal polynomials\nwith respect to a Nikishin system of orthogonality measures supported on\nstar-like sets in the complex plane. This improves a recent result of\nAptekarev-Kalyagin-Saff where a formal connection with Nikishin systems was\nobtained in the case when $\\sum_{n=0}^{\\infty}|a_n-a|<\\infty$ for some $a>0$.\n  An important tool in this paper is the study of \"Riemann-Hilbert minors\", or\nequivalently, the \"generalized eigenvalues\" of the Hessenberg matrix $H$. We\nprove interlacing relations for the generalized eigenvalues by using totally\npositive matrices. In the case of asymptotically periodic coefficients $a_n$,\nwe find weak and ratio asymptotics for the Riemann-Hilbert minors and we obtain\na connection with a vector equilibrium problem. We anticipate that in the\nfuture, the study of Riemann-Hilbert minors may prove useful for more general\nclasses of multiple orthogonal polynomials.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.2813%2C1202.5937%2C1202.1609%2C1202.6665%2C1202.1538%2C1202.3322%2C1202.3952%2C1202.5785%2C1202.0419%2C1202.4000%2C1202.0320%2C1202.5185%2C1202.1527%2C1202.1738%2C1202.4879%2C1202.3599%2C1202.2445%2C1202.6046%2C1202.1359%2C1202.6656%2C1202.4301%2C1202.3985%2C1202.3586%2C1202.5264%2C1202.1938%2C1202.2393%2C1202.3265%2C1202.2334%2C1202.1094%2C1202.4237%2C1202.0498%2C1202.0624%2C1202.4297%2C1202.3020%2C1202.5781%2C1202.6094%2C1202.1758%2C1202.1574%2C1202.5309%2C1202.2444%2C1202.4912%2C1202.5903%2C1202.3803%2C1202.3902%2C1202.2057%2C1202.4569%2C1202.0880%2C1202.1215%2C1202.4636%2C1202.1727%2C1202.0700%2C1202.5938%2C1202.3935%2C1202.0120%2C1202.2607%2C1202.2121%2C1202.0859%2C1202.6446%2C1202.5422%2C1202.3674%2C1202.1452%2C1202.2949%2C1202.6352%2C1202.2546%2C1202.4926%2C1202.1812%2C1202.1064%2C1202.2673%2C1202.3657%2C1202.5130%2C1202.2633%2C1202.1601%2C1202.1848%2C1202.0861%2C1202.0891%2C1202.2606%2C1202.2484%2C1202.5723%2C1202.5612%2C1202.5447%2C1202.3490%2C1202.0926%2C1202.1203%2C1202.3941%2C1202.2016%2C1202.6246%2C1202.6345%2C1202.5453%2C1202.3349%2C1202.0588%2C1202.2537%2C1202.3256%2C1202.3051%2C1202.3567%2C1202.6129%2C1202.2202%2C1202.1654%2C1202.5132%2C1202.4645%2C1202.6393%2C1202.5405&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We study monic polynomials $Q_n(x)$ generated by a high order three-term\nrecursion $xQ_n(x)=Q_{n+1}(x)+a_{n-p} Q_{n-p}(x)$ with arbitrary $p\\geq 1$ and\n$a_n>0$ for all $n$. The recursion is encoded by a two-diagonal Hessenberg\noperator $H$. One of our main results is that, for periodic coefficients $a_n$\nand under certain conditions, the $Q_n$ are multiple orthogonal polynomials\nwith respect to a Nikishin system of orthogonality measures supported on\nstar-like sets in the complex plane. This improves a recent result of\nAptekarev-Kalyagin-Saff where a formal connection with Nikishin systems was\nobtained in the case when $\\sum_{n=0}^{\\infty}|a_n-a|<\\infty$ for some $a>0$.\n  An important tool in this paper is the study of \"Riemann-Hilbert minors\", or\nequivalently, the \"generalized eigenvalues\" of the Hessenberg matrix $H$. We\nprove interlacing relations for the generalized eigenvalues by using totally\npositive matrices. In the case of asymptotically periodic coefficients $a_n$,\nwe find weak and ratio asymptotics for the Riemann-Hilbert minors and we obtain\na connection with a vector equilibrium problem. We anticipate that in the\nfuture, the study of Riemann-Hilbert minors may prove useful for more general\nclasses of multiple orthogonal polynomials."}, "authors": ["Steven Delvaux", "Abey L\u00f3pez Garc\u00eda"], "author_detail": {"name": "Abey L\u00f3pez Garc\u00eda"}, "author": "Abey L\u00f3pez Garc\u00eda", "arxiv_comment": "59 pages, 3 figures", "links": [{"href": "http://arxiv.org/abs/1202.4000v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1202.4000v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.CA", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.CA", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.CO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1202.4000v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1202.4000v2", "journal_reference": null, "doi": null, "fulltext": "High order three-term recursions, Riemann-Hilbert minors\nand Nikishin systems on star-like sets\nSteven Delvaux\u2217 and Abey L\u00f3pez\u2217\n\narXiv:1202.4000v2 [math.CA] 20 Feb 2012\n\nNovember 19, 2018\n\nAbstract\nWe study monic polynomials Qn (x) generated by a high order three-term recursion\nxQn (x) = Qn+1 (x) + an\u2212p Qn\u2212p (x) with arbitrary p \u2265 1 and an > 0 for all n. The recursion\nis encoded by a two-diagonal Hessenberg operator H. One of our main results is that,\nfor periodic coefficients an and under certain conditions, the Qn are multiple orthogonal\npolynomials with respect to a Nikishin system of orthogonality measures supported on starlike sets in the complex plane. This improves a recent result of Aptekarev-Kalyagin-Saff\nP\nwhere a formal connection with Nikishin systems was obtained in the case when \u221e\nn=0 |an \u2212\na| < \u221e for some a > 0.\nAn important tool in this paper is the study of 'Riemann-Hilbert minors', or equivalently,\nthe 'generalized eigenvalues' of the Hessenberg matrix H. We prove interlacing relations for\nthe generalized eigenvalues by using totally positive matrices. In the case of asymptotically\nperiodic coefficients an , we find weak and ratio asymptotics for the Riemann-Hilbert minors\nand we obtain a connection with a vector equilibrium problem. We anticipate that in the\nfuture, the study of Riemann-Hilbert minors may prove useful for more general classes of\nmultiple orthogonal polynomials.\nKeywords: Multiple orthogonal polynomial, Nikishin system, banded Hessenberg matrix, block Toeplitz matrix, Riemann-Hilbert matrix, generalized Poincar\u00e9 theorem, ratio\nasymptotics, vector equilibrium problem, interlacing, totally positive matrix.\nMSC 2010: Primary 42C05; Secondary 15B05, 15B48.\n\nContents\n1 Introduction\n\n2\n\n2 Statement of results\n2.1 Limiting zero distribution of Riemann-Hilbert\n2.2 Star-like structure of \u0393k . . . . . . . . . . . .\n2.3 Generalized eigenvalues and interlacing . . . .\n2.4 Connection with Nikishin systems . . . . . .\n2.5 Widom-type formula . . . . . . . . . . . . . .\n2.6 Outline of the paper . . . . . . . . . . . . . .\n\nminors .\n. . . . .\n. . . . .\n. . . . .\n. . . . .\n. . . . .\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n\n6\n6\n7\n8\n11\n13\n14\n\n\u2217 Department of Mathematics, University of Leuven (KU Leuven), Celestijnenlaan 200B, B-3001 Leuven, Belgium. email: {steven.delvaux, abey.lopezgarcia}@wis.kuleuven.be. The authors are Postdoctoral Fellows of the\nFund for Scientific Research-Flanders (FWO), Belgium.\n\n1\n\n\f3 Riemann-Hilbert minors and generalized eigenvalues\n4 Interlacing of generalized eigenvalues\n4.1 Generalized eigenvalues of totally positive matrices\n4.2 The approach of Eiermann-Varga revisited . . . . .\n4.3 Proofs of Theorems 2.7 and 2.12 . . . . . . . . . .\n4.4 Interlacing for arbitrary Riemann-Hilbert minors .\n\n14\n.\n.\n.\n.\n\n17\n17\n20\n21\n27\n\n5 Normal family estimates\n5.1 Combinatorial expansion of generalized eigenvalue determinants . . . . . . . . . .\n5.2 Proof of Lemma 5.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n28\n28\n32\n\n6 Proof of the Widom-type formula\n\n33\n\n7 Ratio and weak asymptotics of Riemann-Hilbert minors\n7.1 Generalized Poincar\u00e9 theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7.2 Ratio and weak asymptotics of Riemann-Hilbert minors . . . . . . . . . . . . . .\n7.3 Proofs of Proposition 7.6 and Theorem 2.2 . . . . . . . . . . . . . . . . . . . . . .\n\n38\n38\n39\n44\n\n8 Nikishin system\n8.1 Multiple orthogonality relations\n8.2 Formal Nikishin system . . . .\n8.3 Proof of Theorem 2.10 . . . . .\n8.4 Proof of Lemma 8.4 . . . . . .\n\n49\n49\n50\n52\n54\n\n1\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\nIntroduction\n\nLet (Qn )\u221e\nn=0 be the sequence of monic polynomials generated by the recurrence relation\nxQn (x) = Qn+1 (x) + an\u2212p Qn\u2212p (x),\n\nn \u2265 0,\n\n(1.1)\n\nfor a fixed integer p \u2208 N := {1, 2, 3, . . .}, with initial conditions\nQ0 (x) \u2261 1,\n\nQ\u22121 (x) \u2261 * * * \u2261 Q\u2212p (x) \u2261 0.\n\n(1.2)\n\nThe recurrence coefficients an are assumed to be positive real numbers:\nn \u2265 0.\n\nan > 0,\n\n(1.3)\n\nNote that for p = 1, (1.1) reduces to the standard three-term recurrence relation for orthogonal\npolynomials on the real line, in the special case of an even orthogonality measure. We will be\ninterested in the case where p \u2265 2, which we refer to as a high order three-term recurrence [1].\nThe assumption (1.3) implies that the zeros of Qn are located on the star S+ := {x \u2208 C |\nxp+1 \u2208 R+ }, and that they satisfy certain interlacing relations. This was demonstrated by\nEiermann-Varga [12] and Romdhane [24]; see also Fig. 1 and 2 below for the case p = 2. In\nthe present paper we will obtain more general interlacing relations, in the context of so-called\nRiemann-Hilbert minors.\nThe polynomials Qn are studied in the literature under various assumptions on the recurrence coefficients an . He and Saff [16] show that the Faber polynomials associated with the\nclosed domain bounded by a (p + 1)-cusped hypocycloid satisfy the recursion (1.1) with constant\ncoefficients an = a = 1/p. Many properties of these Faber polynomials are obtained in [12, 16].\n2\n\n\fMore properties and applications for the polynomials Qn are obtained by Ben Cheikh-Douak\n[3], Douak-Maroni [9], Maroni [20] and others [22, 24]. The polynomials Qn are often called\nd-symmetric d-orthogonal polynomials in these references (with d := p). An application from the\nnormal matrix model is given in [5].\nGeneral considerations [10, 17] show that the polynomials Qn satisfy formal multiple orthogonality relations with respect to certain linear functionals. Aptekarev, Kalyagin and Van Iseghem\n[2] obtain a stronger version of this result:\nTheorem 1.1. (See [1, Th. 1.1], [2, Cor. 2]:) Suppose that an > 0 for all n and the numbers\nan are uniformly bounded. Then the polynomials Qn (x) are multiple orthogonal with respect to\nthe measures \u03bd1 , . . . , \u03bdp defined in (8.3) (see Section 8), in the sense that\nZ\nQn (x)xm d\u03bdj (x) = 0,\n(1.4)\nfor any m \u2208 [0 : \u230a n\u2212j\np \u230b] and j \u2208 [1 : p].\nHere x 7\u2192 \u230ax\u230b denotes the 'floor' function and we abbreviate [i : j] := {i, i + 1, . . . , j}. This\nnotation will be used throughout the paper.\nThe measures \u03bd1 , . . . , \u03bdp are supported on a compact subset of the star S+ . We will call them\nthe orthogonality\nmeasures. Aptekarev, Kalyagin and Saff [1] study these measures in the case\nP\u221e\nwhere n=0 |an \u2212 a| < \u221e for some a > 0. They obtain a formal link with Nikishin systems. In\nthe present paper we will extend this link to the case of periodic an . In particular, we will obtain\nconditions guaranteeing that \u03bd1 , . . . , \u03bdp form a true, rather than a formal, Nikishin system.\n(j)\nFor any j \u2208 [1 : p], define the second kind function \u03a8n by\nZ\nQn (t)\n(j)\n\u03a8n (z) :=\nd\u03bdj (t),\nn \u2265 0.\n(1.5)\nz\u2212t\nDefine the Riemann-Hilbert matrix (briefly RH matrix ) Yn (z) by\n\uf8eb\n\uf8f6\n(1)\n(p)\nQn (z)\n\u03a8n (z) . . . \u03a8n (z)\n\uf8ec\n\uf8f7\n(1)\n(p)\n\uf8ecQn\u22121 (z) \u03a8n\u22121 (z) . . . \u03a8n\u22121 (z)\uf8f7\n\uf8ec\n\uf8f7.\nYn (z) = \uf8ec\n..\n..\n..\n\uf8f7\n\uf8ed\n\uf8f8\n.\n.\n.\n(1)\n(p)\nQn\u2212p (z) \u03a8n\u2212p (z) . . . \u03a8n\u2212p (z)\n\n(1.6)\n\nThis definition is a variant of the one in Van Assche, Geronimo and Kuijlaars [28], see also [13].\nThe matrix Yn (z) satisfies a certain Riemann-Hilbert problem; but we will not need this here.\nDenote the principal (k + 1) \u00d7 (k + 1) minor of Yn (z) by\n\uf8eb\n\uf8f6\n(k)\n(1)\nQn (z)\n\u03a8n (z) . . . \u03a8n (z)\n\uf8ec\n\uf8f7\n..\n..\n..\n\uf8f7,\nBk,n (z) = det \uf8ec\n(1.7)\n.\n.\n.\n\uf8ed\n\uf8f8\n(1)\n\n(k)\n\nQn\u2212k (z) \u03a8n\u2212k (z) . . . \u03a8n\u2212k (z)\n\nfor k \u2208 [0 : p]. We call this the kth principal Riemann-Hilbert minor of Yn . For n < k we set\nBk,n (z) \u2261 1. In this paper we will also work with the determinants of more general submatrices\nof (1.6), whose rows are not necessarily consecutive; see Section 3 and following.\nLemma 1.2. For any k \u2208 [0 : p], Bk,n (x) is a polynomial of degree\ndeg Bk,n \u2264\n\np\u2212k\n(n \u2212 k).\np\n3\n\n\fProof. First we prove that Bk,n (x) is a polynomial. By the multi-linearity of the determinant,\n\uf8eb\n\uf8f6\nQn (z)\nQn (y1 )\n...\nQn (yk )\nZ\nZ\n\uf8ec\n\uf8f7 d\u03bd1 (y1 ) . . . d\u03bdk (yk )\n..\n..\n..\n.\nBk,n (z) = * * * det \uf8ed\n\uf8f8\n.\n.\n.\n(z \u2212 y1 ) * * * (z \u2212 yk )\nQn\u2212k (z) Qn\u2212k (y1 ) . . . Qn\u2212k (yk )\n\nThe integrand is clearly a polynomial in z, hence Bk,n is a polynomial. Finally, the claim about\nthe degree of Bk,n (z) will be a consequence of Prop. 2.6 and Lemma 2.5 in what follows. (This\nclaim may be shown in a direct way as well.)\nNote in particular that deg Bp,n = 0, i.e., the determinant of the full RH matrix Yn (z) is a\nconstant. Prop. 2.6 will imply that this constant is nonzero.\nDefine the two complementary 'stars'\nS\u00b1 := {x \u2208 C | xp+1 \u2208 R\u00b1 }.\n\n(1.8)\n\nIn this paper we will prove that the zeros of Bk,n (and of more general RH minors) are all located\non the star S+ if k is even and on the star S\u2212 if k is odd. We will also obtain several kinds of\ninterlacing relations between the zeros of the different RH minors.\nThe main focus of this paper is on the case where the recurrence coefficients an are asymptotically periodic of period r \u2208 N. This means that\nlim arn+j =: bj > 0,\n\nn\u2192\u221e\n\nj \u2208 [0 : r \u2212 1],\n\n(1.9)\n\nfor certain limiting values b0 , . . . , br\u22121 > 0.\nIt turns out that in the asymptotically periodic case, the zeros of Qn for n \u2192 \u221e are attracted\n(in the sense of weak convergence) by a certain rotationally invariant subset \u03930 of the star S+ .\nMoreover, the zeros asymptotically distribute themselves according to a measure \u03bc0 on \u03930 , which\nappears in the solution to a certain vector equilibrium problem. An example of the set \u03930 is\nshown in the left picture of Fig. 1. Below we will also introduce a family of sets \u0393k and measures\n\u03bck , k \u2208 [0 : p \u2212 1], which will be the limiting zero distributions of the RH minors Bk,n .\nDefine the matrix\nF (z, x) := Z \u22121 + Z p diag(b0 , . . . , br\u22121 ) \u2212 xIr ,\n\n(1.10)\n\n0 = f (z, x) := det F (z, x),\n\n(1.11)\n\nand the algebraic curve\nwhere Z denotes the cyclic shift matrix\nZ=\n\n\u0012\n\n0\n\nIr\u22121\n\n\u0013\nz\n,\n0\n\n(1.12)\n\nand where Ik denotes the identity matrix of size k. If r = 1 then we put Z = z and b0 =: b. In\nthat case, (1.11) reduces to the algebraic curve z \u22121 + bz p \u2212 x = 0 in [1, 16]. The matrix F (z, x)\ncan be interpreted as the symbol of a block Toeplitz matrix. This is explained in Section 6.\nThe expression f (z, x) can be expanded as a Laurent polynomial in z:\nf (z, x) = (\u22121)r\u22121 z \u22121 + f0 (x) + f1 (x)z + * * * + fp (x)z p ,\n\n4\n\n(1.13)\n\n\fFigure 1: Zeros of Q80 (left) and P1,80 (right) in the periodic case with p = 2 and period r = 8\nand (a0 , . . . , a7 ) = (3, 1, 5, 2, 2, 9, 6, 1). The zeros of Qn accumulate on a set \u03930 \u2282 S+ whose\nintersection with R is [0, 0.85] \u222a [1.52, 2.19] \u222a [2.67, 2.89] (using two digits of precision). The zeros\nof P1,n accumulate on a set \u03931 \u2282 S\u2212 whose intersection with R is [\u22123.72, \u22121.59] \u222a [\u22120.17, 0].\nNote that Q80 has an isolated zero between some of the intervals.\nwhere each fk (x), k \u2208 [0 : p], is a polynomial in x, and\nfp (x) \u2261 fp = (\u22121)p(r\u2212p)\n\nr\u22121\nY\n\nbk .\n\n(1.14)\n\nk=0\n\nThe algebraic equation f (z, x) = 0 has precisely p + 1 roots zk = zk (x), k \u2208 [0 : p] (counting\nmultiplicities), and we order them by increasing modulus as\n|z0 (x)| \u2264 |z1 (x)| \u2264 * * * \u2264 |zp (x)|\n\n(1.15)\n\nfor all x \u2208 C. If x \u2208 C is such that two or more subsequent roots zk (x) in (1.15) have the same\nmodulus then we may arbitrarily label them so that (1.15) is satisfied. It is easy to see (see e.g.\n[7, Sec. 4] or [29, p. 102]) that for x \u2192 \u221e,\nz0 (x) = x\u2212r + O(x\u2212r\u22121 ),\n\nzk (x) = O(xr/p ),\n\nk \u2208 [1 : p].\n\n(1.16)\n\nMore precisely, for any x \u2208 C there is a permutation (z\u0303k (x))pk=1 of the set (zk (x))pk=1 so that\n\uf8eb\n\nzek (x)p/d = \uf8ed\n\nr/d\u22121\n\nY\n\nn=0\n\n\uf8f6\u22121\n\nbdn+(k\u22121 mod d) \uf8f8\n\nxr/d (1 + o(1)),\n\nk \u2208 [1 : p],\n\n(1.17)\n\nas x \u2192 \u221e, where d := gcd{p, r}. See [29, p. 102].\nDefine the sets \u0393k by\n\n\u0393k = {x \u2208 C | |zk (x)| = |zk+1 (x)|},\n\nk \u2208 [0 : p \u2212 1].\n\n(1.18)\n\nIt turns out that \u0393k is a finite union of line segments on the star S+ if k is even and S\u2212 if k is\nodd: see Fig. 1 and Theorem 2.2. The next lemma shows that \u0393k is rotationally invariant.\n5\n\n\fLemma 1.3. (Rotational symmetry:) With \u03c9 := exp(2\u03c0i/(p+1)), we have f (z, \u03c9x) = \u03c9 r f (\u03c9 r z, x).\nHence, for any x \u2208 C the sets (zk (\u03c9x))pk=0 and (\u03c9 \u2212r zk (x))pk=0 are equal up to permutation, and\neach set \u0393k is invariant under rotations over 2\u03c0/(p + 1).\nProof. Recalling (1.10)\u2013(1.12), it is easy to see that D\u22121 F (z, \u03c9x)D = \u03c9F (\u03c9 r z, x) where D :=\ndiag(1, \u03c9, \u03c9 2 , . . . , \u03c9 r\u22121 ). This implies the lemma.\nFor any k \u2208 [0 : p \u2212 1], define the measure\nk\n\n1 1X\nd\u03bck (\u03bb) =\n2\u03c0i r j=0\n\n\u0012\n\n\u2032\n\u2032\nzj+\n(\u03bb) zj\u2212\n(\u03bb)\n\u2212\nzj+ (\u03bb) zj\u2212 (\u03bb)\n\n\u0013\n\nd\u03bb\n\n(1.19)\n\nsupported on \u0393k . Here the prime denotes the derivative with respect to \u03bb, and d\u03bb denotes\nthe complex line element on each line segment of \u0393k , according to some fixed orientation of\n\u0393k . Moreover, zj+ (\u03bb) and zj\u2212 (\u03bb) are the boundary values of zj (\u03bb) obtained from the +-side\nand \u2212-side respectively of \u0393k , where the +-side (\u2212-side) is the side that lies on the left (right)\nwhen moving through \u0393k according to its orientation. It turns out that \u03bck is a positive measure\n(obviously independent of the orientation given to \u0393k ) with total mass [7, Sec. 4]\n\u03bck (\u0393k ) =\n\np\u2212k\n,\np\n\nk \u2208 [0 : p \u2212 1].\n\n(1.20)\n\nThe measures (\u03bck )k are the minimizers to an equilibrium problem that we now describe. For\nany measures \u03bc, \u03bd on C define their mutual logarithmic energy as\nZZ\n1\nd\u03bc(x) d\u03bd(y).\nI(\u03bc, \u03bd) =\nlog\n|x \u2212 y|\nThe logarithmic energy of the measure \u03bc is defined as I(\u03bc) = I(\u03bc, \u03bc).\nWe call a vector of positive measures ~\u03bd = (\u03bd0 , . . . , \u03bdp\u22121 ) admissible if \u03bdk has finite logarithmic\nenergy, \u03bdk is supported on \u0393k , and \u03bdk has total mass \u03bdk (\u0393k ) = p\u2212k\np , k \u2208 [0 : p \u2212 1]. The energy\nfunctional J is defined by\np\u22121\np\u22122\nX\nX\nJ(~\u03bd ) =\nI(\u03bdk ) \u2212\nI(\u03bdk , \u03bdk+1 ).\n(1.21)\nk=0\n\nk=0\n\nThe (vector) equilibrium problem is to minimize the energy functional (1.21) over all admissible\nvectors of positive measures ~\u03bd . The equilibrium problem has a unique solution which is given by\nthe measures \u03bck in (1.19), see [7].\n\n2\n2.1\n\nStatement of results\nLimiting zero distribution of Riemann-Hilbert minors\n\nDenote the normalized zero counting measure of Bk,n , k \u2208 [0 : p \u2212 1], by\n\u03bck,n :=\n\n1\nn\n\nX\n\n\u03b4x ,\n\n(2.1)\n\nx|Bk,n (x)=0\n\nwhere \u03b4x is the Dirac measure at x and each zero is counted according to its multiplicity.\nLemma 1.2 shows that \u03bck,n has total mass at most (p \u2212 k)/p. Now we state our first main\ntheorem.\n6\n\n\fTheorem 2.1. Assume we have asymptotically periodic recurrence coefficients (1.9), and define\n\u03bck,n , \u03bck as in (2.1) and (1.19). Then for any k \u2208 [0 : p \u2212 1], the measures \u03bck,n weakly converge\nto the measure \u03bck on \u0393k as n \u2192 \u221e. This means that\nZ\nZ\nlim\n\u03c6(x) d\u03bck,n (x) = \u03c6(x) d\u03bck (x)\n(2.2)\nn\u2192\u221e\n\nfor any bounded continuous function \u03c6.\nTheorem 2.1 will be proved in Section 7 with the help of a 'normal family' estimate for the\nratio of two RH minors (Section 5), and using the generalized Poincar\u00e9 theorem. In fact, we will\nuse a multi-column version of the generalized Poincar\u00e9 theorem (Lemma 7.2). This approach\nyields not only weak asymptotics but also ratio asymptotics for the RH minors, as we explain in\nSection 7, see e.g. (7.23) or (7.28). Moreover, we will see that Theorem 2.1 remains valid with\nBk,n replaced by more general RH minors (Remark 7.7).\nWe point out that Theorem 2.1 for k = 0 could also be obtained from the normal family\narguments in [4], taking into account the interlacing relations for the zeros of Qn .\nTheorem 2.1 shows that the limiting zero distribution of each Riemann-Hilbert minor Bk,n\nexists and that the limiting measures are the minimizers to a vector equilibrium problem. We\nhave reason to believe that a similar conclusion may hold for more general classes of multiple\northogonal polynomials. This may be an interesting topic for further research.\n\nStar-like structure of \u0393k\n\n2.2\n\nTheorem 2.2. Assume that (1.9) holds. Fix k \u2208 [0 : p \u2212 1] and define \u0393k (1.18) and also\ne k = \u0393p+1 := {xp+1 | x \u2208 \u0393k }.\n\u0393\nk\n\nThen:\n\n(2.3)\n\ne k is part of R+ (or R\u2212 ) if k is even (or odd respectively).\n(a) \u0393\ne k is the union of nk intervals Ij,k :\n(b) \u0393\nek =\n\u0393\n\nnk\n[\n\nIj,k ,\n\nwith nk =\n\nj=1\n\n\u0018\n\n\u0019 \u0016 \u0017\nk+1\nkr\n,\nr \u2212\np+1\np\n\n(2.4)\n\nwith x 7\u2192 \u2308x\u2309 and x 7\u2192 \u230ax\u230b denoting the 'ceiling' and 'floor' functions. The intervals Ij,k ,\nj \u2208 [1 : nk ] are pairwise disjoint except maybe for common endpoints.\ne k contains 0 or \u221e:\n(c) The following conditions imply that \u0393\n\nkr\nek .\n6\u2208 N \u222a {0} \u21d2 (\u22121)k \u221e \u2208 \u0393\np\n\nk+1\nek ,\nr 6\u2208 N \u21d2 0 \u2208 \u0393\np+1\n\n(2.5)\n\ne k in (2.3). In terms of the original sets \u0393k , it\nTheorem 2.2 was formulated for the sets \u0393\nimplies that \u0393k lies on one of the two stars S+ and S\u2212 in (1.8), depending on whether k is even\nor odd respectively. Recall that \u0393k is rotationally invariant (Lemma 1.3).\nTheorem 2.2 will be proved in Section 7.3. In the case r = 1 it was already obtained by\ne 0 = [0, c] for\nAptekarev-Kalyagin-Saff [1]; note that in that case we have n0 = * * * = np\u22121 = 1, \u0393\nk\ne\na certain c > 0, and \u0393k = (\u22121) R+ for k \u2208 [1 : p \u2212 1].\n7\n\n\fRemark 2.3. As mentioned in the statement of the theorem, the intervals Ij,k , j \u2208 [1 : nk ] in\n(2.4) are pairwise disjoint except possibly for common endpoints. We believe that such common\nendpoints are rare, in the sense that for a sufficiently 'generic' choice of the parameters bk > 0,\nk \u2208 [0 : r \u2212 1], all the endpoints of the intervals are distinct.\nRemark 2.4. Suppose p = 2. Then we have two values k = 0 and k = 1, and (2.4) reduces to\n\u0018 \u0019 j k\nlr m\n2r\nr\nn0 =\n,\nn1 =\n\u2212\n.\n3\n3\n2\n\nFor example, if the period r = 6 then we have n0 = 2 and n1 = 1. Note that this is the same\nsetting as in [19], but in the latter paper there is an additional structure on the bk > 0 which\ne 0 are tangent (and contain the origin), so that \u0393\ne 0 consists of a\nimplies that the two intervals of \u0393\nsingle contiguous interval in that case. If the period r = 8 then we have n0 = 3 and n1 = 2: see\nFig. 1.\n\n2.3\n\nGeneralized eigenvalues and interlacing\n\nTo obtain interlacing relations for the zeros of RH minors, we will use an alternative representation via generalized eigenvalue determinants that we now describe. To the recurrence (1.1) we\nassociate the Hessenberg operator H = (Hi,j )\u221e\ni,j=0 with entries\n\uf8f1\n\uf8f2 Hj\u22121,j = 1, j \u2265 1,\nHj+p,j = aj , j \u2265 0,\n(2.6)\n\uf8f3\nHi,j\n= 0, otherwise.\n\nWe refer to H as a two-diagonal Hessenberg matrix. We denote with Hn its n\u00d7n leading principal\nsubmatrix:\n\uf8eb\n\uf8f6\n0\n1\n0\n\uf8ec .. . .\n\uf8f7\n..\n\uf8ec.\n\uf8f7\n.\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\nn\u22121\n..\n..\nHn = (Hi,j )i,j=0 = \uf8eca0\n.\n(2.7)\n\uf8f7\n.\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\n.\n.\n..\n. . 1\uf8f8\n\uf8ed\n0\nan\u2212p\u22121 . . . 0 n\u00d7n\n\nThe recurrence relation (1.1) can be written in matrix-vector form as\n\nx(Q0 (x), Q1 (x), . . .)T = H(Q0 (x), Q1 (x), . . .)T ,\nT\n\n(2.8)\n\nwhere the superscript denotes the transpose. This implies easily that Qn (x) = det(xIn \u2212 Hn ).\nSo the eigenvalues of Hn are the zeros of Qn .\nFor k \u2208 [0 : p] we define the polynomial Pk,n (x) as the determinant of the submatrix of\nHn \u2212 xIn obtained by skipping the first k rows and the last k columns. Thus\n\uf8f6\n\uf8eb\n0 . . . \u2212x 1\n\uf8f7\n\uf8ec .. . .\n..\n..\n\uf8f7\n\uf8ec.\n.\n.\n.\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n.\n.\n.\n..\n..\n..\n\uf8f7\n\uf8ec a0\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n..\n..\n..\n.\n(2.9)\nPk,n (x) = det \uf8ec\n.\n.\n.\n1 \uf8f7\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n..\n..\n\uf8ec\n.\n.\n\u2212x\uf8f7\n\uf8f7\n\uf8ec\n\uf8ec\n.. \uf8f7\n..\n..\n\uf8ed\n.\n.\n. \uf8f8\nan\u2212p\u22121 . . . 0 (n\u2212k)\u00d7(n\u2212k)\n8\n\n\fThe kth generalized eigenvalues of Hn are the numbers x \u2208 C such that Pk,n (x) = 0. For n \u2264 k\nwe set Pk,n (x) \u2261 1. Note that for k = p we have Pp,n (x) \u2261 a0 * * * an\u2212p\u22121 > 0.\nLemma 2.5. For any k \u2208 [0 : p], the polynomial Pk,n (x) has degree\ndeg Pk,n \u2264\n\np\u2212k\n(n \u2212 k).\np\n\nProof. This follows by a simple combinatorial argument; see e.g. [11, Proof of Prop. 2.5].\nLemma 2.5 could be refined using the combinatorial formulas in Section 5. This leads to an\nexact formula for deg Pk,n , depending on n mod p. We will not go into this issue here.\nThe fact of the matter is the following.\nProposition 2.6. (Generalized eigenvalues versus RH minors:) For any k \u2208 [0 : p],\n) c P (x),\nk k,n\n\nBk,n (x) = (\u22121)n(k+1)\u2212(\n\nk+1\n2\n\n(2.10)\n\ncf. (1.7), where the constant ck depends only on the first k moments of the measures \u03bd1 , . . . , \u03bdk :\n\u0012Z\n\u0013 \u0012Z\n\u0013\n\u0012Z\n\u0013\nk\nck = (\u22121)\nd\u03bd1 (t)\nQ1 (t) d\u03bd2 (t) * * *\nQk\u22121 (t) d\u03bdk (t) .\n(2.11)\n\n\u0001\nNote that in (2.10) and (2.11), we should understand 12 = 0 and c0 = 1.\nWe point out that Prop. 2.6 remains valid for arbitrary banded Hessenberg operators, that\nis, for matrices H = (Hi,j )\u221e\ni,j=0 defined by\n\uf8f1\nj \u2265 1,\n\uf8f2 Hj\u22121,j = 1,\n(k)\n(k)\n(2.12)\nH\n= aj , j \u2265 0, k \u2208 [0 : p], aj \u2208 C,\n\uf8f3 j+k,j\nHi,j = 0,\notherwise,\nso that\n\n\uf8eb\n\nn\u22121\nHn = (Hi,j )i,j=0\n\n(p)\naj\n\n(0)\n\na0\n\uf8ec .\n\uf8ec ..\n\uf8ec\n\uf8ec\n(p)\n=\uf8ec\n\uf8ec a0\n\uf8ec\n\uf8ec\n\uf8ed\n0\n\n1\n..\n.\n..\n\n0\n\n..\n\n.\n\n..\n\n.\n\n..\n\n.\n\n..\n\n.\n(p)\nan\u2212p\u22121\n\n\uf8f6\n\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n1 \uf8f8\n\n.\n(0)\n. . . an\u22121\n\n.\n\n(2.13)\n\nn\u00d7n\n\n6= 0, for all j, so the entries on the pth subdiagonal of (2.13) are nonWe will assume that\nzero. We associate to H the sequence of monic polynomials (Qn )\u221e\nn=0 satisfying the (p + 2)-term\nrecurrence relation (2.8), i.e.,\n(1)\n\n(p)\n\nxQn (x) = Qn+1 (x) + a(0)\nn Qn (x) + an\u22121 Qn\u22121 (x) + * * * + an\u2212p Qn\u2212p (x),\n\nn \u2265 0,\n\n(2.14)\n\nwith initial conditions\nQ\u22121 \u2261 * * * \u2261 Q\u2212p = 0,\n\nQ0 \u2261 1.\n\n(2.15)\n\nProp. 2.6 will be a consequence of a result proved in Prop. 3.1 for the polynomials Qn satisfying\n(2.14)\u2013(2.15), assuming that these polynomials are multiple orthogonal with respect to a system\nof p measures, see Section 3 for more details.\nProp. 2.6 shows that RH minors can be alternatively represented as generalized eigenvalue\ndeterminants. We now state interlacing relations for the latter.\n9\n\n\fFigure 2: Left picture: zeros of Q23 (circles) and Q24 (squares). Right picture: zeros of Q24\n(squares) and Q27 (circles). In these pictures we have a two-diagonal Hessenberg matrix H\nas in (2.6)\u2013(2.7) with p = 2 and recurrence coefficients (a0 , . . . , a5 ) = (3, 2, 3, 5, 4, 1) extended\nperiodically with periodicity r = 6.\nTheorem 2.7. (Interlacing for generalized eigenvalues:) Let H be a two-diagonal Hessenberg\nmatrix (2.6) with aj > 0 for all j. Fix n \u2208 N and k \u2208 [0 : p \u2212 1]. Then\n(a) We have Pk,n (x) = xmk,n Pek,n (xp+1 ), for a polynomial Pek,n with Pek,n (0) 6= 0 and with\n(\n(j \u2212 k)(k + 1), if n \u2261 j mod (p + 1), j \u2208 [k : p],\nmk,n =\n(2.16)\n(k \u2212 j)(p \u2212 k), if n \u2261 j mod (p + 1), j \u2208 [\u22121 : k].\nThe zeros of Pek,n all lie in R+ (R\u2212 ) if k is even (odd).\n\n(b) Denote the zeros of Pek,n and Pek,n+1 as (xi )i=1,2,... and (yi )i=1,2,... respectively, counting\nmultiplicities and ordered by increasing modulus. We have the weak interlacing relation\n0 < |x1 | \u2264 |y1 | \u2264 |x2 | \u2264 |y2 | \u2264 . . .\n\nif n \u2261 j mod (p + 1), j \u2208 [k : p \u2212 1], and\n0 < |y1 | \u2264 |x1 | \u2264 |y2 | \u2264 |x2 | \u2264 . . .\nif n \u2261 j mod (p + 1), j \u2208 [\u22121 : k \u2212 1].\n(c) Let (xi )i=1,2,... be the zeros of Pek,n , as in (b), and let (wi )i=1,2,... be the zeros of Pek,n+p+1 ,\ncounting multiplicities and ordered by increasing modulus. We have\n0 < |w1 | \u2264 |x1 | \u2264 |w2 | \u2264 |x2 | \u2264 . . . .\n\nNote that the moduli can be removed if k is even and replaced by minus signs if k is odd.\nTheorem 2.7 generalizes known results for the standard eigenvalues k = 0 [12, 24]. The\ntheorem will be proved in Section 4, by using the theory of totally positive matrices and extending\nthe approach of Eiermann-Varga [12]. See also Theorems 2.12 and 4.6 below for related results.\nTheorem 2.7 is illustrated in Figures 2 and 3.\nGeneralized eigenvalues turn out to be deeply connected to the hierarchy of functions of the\n(formal) Nikishin system generated by H. This will be the topic of Section 2.4.\n10\n\n\fFigure 3: Left picture: zeros of P1,23 (circles) and P1,24 (squares). Right picture: zeros of P1,24\n(squares) and P1,27 (circles). The matrix H is as in Figure 2.\n\n2.4\n\nConnection with Nikishin systems\n\nP\u221e\nAptekarev-Kalyagin-Saff [1] show that, in the trace class k=0 |ak \u2212 a| < \u221e and with period\nr = 1, the two-diagonal operator H generates a (formal) Nikishin system. These objects are only\nformally defined however.\nIn this paper we will obtain a related result. It will apply to the exactly periodic case\nn \u2208 N,\n\narn+k = ak = bk ,\n\nk \u2208 [0 : r \u2212 1].\n\n(2.17)\n\nWe assume without loss of generality that the period r is a multiple of p. We also assume that\nr/p\u22121\n\nY\n\nr/p\u22121\n\napn >\n\nn=0\n\nY\n\nr/p\u22121\n\napn+1 > * * * >\n\nn=0\n\nY\n\napn+(p\u22121) .\n\n(2.18)\n\nn=0\n\nUnder these conditions, we will show that the polynomials Qn are multiple orthogonal with\nrespect to a true Nikishin system generated by rotationally invariant measures on the stars S+\nand S\u2212 , coming from measures on R+ or R\u2212 with constant sign. There can also be possible\npoint masses at each level of the Nikishin hierarchy.\nNikishin systems formed by measures supported on the real line were introduced by E.M.\nNikishin in [23]. The same definition can be easily adapted to our context of star-like sets, as we\nnow explain. Compare this definition with the one given in [1, Section 8.1].\nDefinition 2.8. Let \u03bd1 , . . . , \u03bdp be a collection of p complex measures supported on the set\n\u03930 \u222a A0 , where A0 \u2282 S+ \\ \u03930 is a discrete set. We say that (\u03bd1 , . . . , \u03bdp ) forms a Nikishin\nsystem on (\u03930 , . . . , \u0393p\u22121 ) if for each k \u2208 [0 : p \u2212 1], there exists a collection of complex measures\n(\u03bdl,k )pl=k+1 supported on \u0393k \u222a Ak , where Ak is a discrete subset of S+ \\ \u0393k (if k is even) or S\u2212 \\ \u0393k\n(if k is odd), with the following properties:\n(a) (\u03bd1 , . . . , \u03bdp ) = (\u03bd1,0 , . . . , \u03bdp,0 ).\n(s)\n\n(s)\n\n(b) If d\u03bdl,k (x) = gl,k (x) dx + d\u03bdl,k (x), d\u03bdl,k (x) \u22a5 gl,k (x) dx, denotes the Lebesgue decomposition of \u03bdl,k , l \u2208 [k + 1 : p], then\nZ\nd\u03bdl,k+1 (t)\ngl,k (x)\n=\n,\nx \u2208 \u0393k , l \u2208 [k + 2 : p].\n(2.19)\ngk+1,k (x)\nx\u2212t\n11\n\n\f(c) For every l \u2208 [k + 1 : p], there exists a real measure \u03bd\u0303l,k with constant sign (either positive\nor negative), supported on R+ (R\u2212 ) if k is even (odd), such that\nd\u03bdl,k (t) = tk+1\u2212l d\u03bd\u0303l,k (tp+1 ).\n\n(2.20)\n\nRemark 2.9. We observe that Nikishin systems possess a hierarchical structure, with the measures\n(\u03bd1 , . . . , \u03bdp ) forming level 0 of the hierarchy. The measure \u03bdl,k is said to be at the kth level of the\nNikishin hierarchy. Note that (2.20) implies that for any k \u2208 [0 : p \u2212 1], the measure \u03bdk+1,k is\nrotationally invariant, and the induced measure \u03bd\u0303k+1,k is real with constant sign. The measures\n\u03bdk+1,k are usually referred to as the generating measures of the Nikishin system. We are implicitly\nrequiring in (2.19) that gk+1,k (x) 6= 0 for all but finitely many x \u2208 \u0393k .\nOur main result is the following.\nTheorem 2.10. Let H be a two-diagonal Hessenberg matrix (2.6) with exactly periodic coefficients aj > 0 satisfying (2.17)\u2013(2.18), where the period r is a multiple of p. Then the orthogonality measures (\u03bd1 , . . . , \u03bdp ) in Theorem 1.1 form a Nikishin system on (\u03930 , . . . , \u0393p\u22121 ) (Def. 2.8).\np\u22121\nMoreover, the star-like sets (\u0393k )p\u22121\nk=0 are compact and the discrete sets (Ak )k=0 are finite.\nTheorem 2.10 will be proved in Section 8.\nRemark 2.11. Theorem 2.10 was stated under the condition (2.18). In general, consider the set\n\uf8f1\n\uf8fc\nr/p\u22121\nr/p\u22121\n\uf8f2r/p\u22121\n\uf8fd\nY\nY\nY\napn ,\napn+1 , * * * ,\napn+(p\u22121) .\n(2.21)\n\uf8f3\n\uf8fe\nn=0\n\nn=0\n\nn=0\n\nEq. (1.17) (with d = p) shows that there exists a permutation \u03a0 of [1 : p] so that\n\uf8eb\n\nr/p\u22121\n\nz\u03a0(k) (x) = \uf8ed\n\nY\n\nn=0\n\n\uf8f6\u22121\n\napn+k\u22121 \uf8f8\n\nxr/p (1 + o(1)),\n\nk \u2208 [1 : p],\n\n(2.22)\n\nfor x \u2192 \u221e. This can also be seen from the derivation of (8.26) in Section 8. As a consequence,\nif the p numbers in (2.21) are pairwise distinct then all the \u0393k are bounded. The converse of\nthe last statement is also true, due to [26, Lemma 3.3]. Now if the numbers (2.21) are pairwise\ndistinct but ordered in a different way than (2.18), then a variant to Theorem 2.10 holds. We\nthen have an additional constant or monomial term in the right hand side of (2.19). This is due\nto the fact that the constant \u03b1 in Eq. (8.19) in Section 8 can be nonzero in this case.\nWe see that the key to obtaining a true (rather than a formal) Nikishin system is to show\nthat the ratio between the densities (2.19) of the measures at the different levels of the Nikishin\nhierarchy are Cauchy transforms of measures on S+ or S\u2212 , associated to real measures with\nconstant sign on R+ or R\u2212 . We will establish this requirement via a surprising connection with\nRH minors. In particular we will use the interlacing relations between the zeros of RH minors.\nRecall the generalized eigenvalue determinant Pk,n (x) from (2.9). We need a more general\ndefinition. For any 1 \u2264 k \u2264 l \u2264 p we define Pk,l,n (x) as the determinant of the submatrix\nobtained by skipping rows 0, 1, . . . , k \u2212 1 and columns n \u2212 l, n \u2212 k + 1, n \u2212 k + 2, . . . , n \u2212 1 of\nHn \u2212 xIn . If l = k then we retrieve our previous definition: Pk,k,n (x) \u2261 Pk,n (x).\nIn the proof of Theorem 2.10 we need the following result on the polynomials Pk,l,n (x).\nTheorem 2.12. (Interlacing for Pk,l,n and Pk,n :) Let H be a two-diagonal Hessenberg matrix (2.6) with aj > 0 for all j. Fix n \u2208 N and 0 \u2264 k < l \u2264 p. Then\n12\n\n\f(a) We have Pk,l,n (x) = xk\u2212l+mk,n Pek,l,n (xp+1 ), with mk,n defined in (2.16) and with Pek,l,n a\npolynomial whose zeros all lie in R+ (R\u2212 ) if k is even (odd).\n\n(b) Denote the zeros of Pek,n (x) and Pek,l,n (x) as (xi )i=1,2,... and (yi )i=1,2,... respectively, ordered\nby increasing modulus and counting multiplicities. We have the weak interlacing relation\n0 \u2264 |y1 | \u2264 |x1 | \u2264 |y2 | \u2264 |x2 | \u2264 . . . .\n\nTheorem 2.12 is proved in Section 4. The precise way how Theorem 2.12 is used in the proof\nof Theorem 2.10 will be explained in Section 8.\nRemark 2.13. The polynomial Pek,l,n could have one, and at most one, zero at the origin. This\nhappens precisely when n \u2261 j mod (p + 1) for some j \u2208 [k : l \u2212 1].\n\n2.5\n\nWidom-type formula\n\nIn this section we state an exact formula for the polynomials Qn in the exactly periodic case (2.17).\nIn fact, we prove the formula for general banded Hessenberg matrices H of the form (2.12). We\nsay that H is exactly periodic with period r if\n(j)\n\n(j)\n\n(j)\n\nn \u2208 N,\n\narn+k = ak = bk ,\n\nk \u2208 [0 : r \u2212 1],\n\nj \u2208 [0 : p].\n\n(2.23)\n\n(p)\n\nRecall that we are assuming bk 6= 0 for all k. Define the 'block Toeplitz symbol'\nF (z, x) = Z \u22121 +\n\np\nX\n\n(k)\n\n(k)\n\nZ k diag(b0 , . . . , br\u22121 ) \u2212 xIr ,\n\n(2.24)\n\nk=0\n\nwith Z as in (1.12). In the case of a two-diagonal Hessenberg matrix (2.6) this reduces to (1.10).\nAlso define f (z, x) = det F (z, x), the roots zk (x) of the algebraic equation f (z, x) = 0 as in\n(1.15), and the sets \u0393k as in (1.18). Prop. 1.1 in [7] shows that \u0393k is a finite union of analytic\n(p)\narcs. Clearly, (1.13)\u2013(1.14) remain valid in this setting (with bk replaced by bk ).\nTheorem 2.14. (Widom-type formula:) With the above notations, let x \u2208 C be such that the\nsolutions zk (x) of the algebraic equation 0 = f (z, x) = det F (z, x) are pairwise distinct. Then\nfor each n \u2208 N \u222a {0} and for each j \u2208 [0 : r \u2212 1],\nQrn+j (x) := det(xIrn+j \u2212 Hrn+j ) =\n\np\n(\u22121)r+j X det F r\u22121,j (zk (x), x)\nQp\nzk (x)\u2212n\u22121 .\nfp\ni=0,i6=k (zk (x) \u2212 zi (x))\n\n(2.25)\n\nk=0\n(p)\n\nHere fp is defined in (1.14) (with bk replaced by bk ), and we use the notation F i,j to denote the\nsubmatrix of F in (2.24) that is obtained by skipping the ith row and the jth column, i, j \u2208 [0 :\nr \u2212 1]. Moreover, for all i, j, k, det F i,j (zk (x), x) is zero for only finitely many x.\nTheorem 2.14 will be proved in Section 6, as a consequence of Widom's determinant identity\nfor block Toeplitz matrices [30, Section 6]. From (2.25) and (1.15)\u2013(1.18) we also find:\nCorollary 2.15. The strong asymptotic formula\nlim Qrn+j (x)z0 (x)n+1 =\n\nn\u2192\u221e\n\n(\u22121)r+j det F r\u22121,j (z0 (x), x)\nQp\n,\nfp\ni=1 (z0 (x) \u2212 zi (x))\n\nholds uniformly on compact subsets of C \\ (\u03930 \u222a A) with A a finite set.\n\nj \u2208 [0 : r \u2212 1],\n\nP\u221e\nIncidentally, Aptekarev et al. [1] obtain strong asymptotics for Qn in the trace class k=0 |ak \u2212\na| < \u221e (a > 0) with period r = 1. By using Theorem 2.14, it is possible to extend these results\nto higher periods r. We will not go into this issue here.\n13\n\n\f2.6\n\nOutline of the paper\n\nThe rest of this paper is organized as follows. In Section 3 we prove the connection between RH\nminors and generalized eigenvalue determinants and we introduce the concept of a general RH\nminor B (n0 ,n1 ,...,nk ) (z). In Section 4 we prove interlacing relations for generalized eigenvalues.\nSection 5 contains normal family estimates for the ratio between two RH minors. The remaining\nsections deal with asymptotically periodic coefficients an . The proof of the Widom-type formula\nfor Qn in the exactly periodic case is given in Section 6. In Section 7 we obtain weak and\nratio asymptotics for RH minors and we prove Theorem 2.2 on the star-like structure of \u0393k . In\nSection 8 we prove Theorem 2.10 on the connection with Nikishin systems.\n\n3\n\nRiemann-Hilbert minors and generalized eigenvalues\n\nIn this section we prove Prop. 2.6 in the general context of banded Hessenberg operators H =\n(Hi,j )\u221e\ni,j=0 defined in (2.12).\nLet (Qn )\u221e\nn=0 be the sequence of monic polynomials associated to the operator H, i.e., the\nsequence satisfying (2.14)\u2013(2.15). We will assume in this section that the polynomials Qn are\nmultiple orthogonal with respect to a system of p complex measures \u03bd1 , . . . , \u03bdp supported on a\ncompact contour \u03a3 \u2282 C. This means that for every j \u2208 [1 : p],\n\u0017\n\u0016\nZ\nn\u2212j\n].\n(3.1)\nQn (t) tm d\u03bdj (t) = 0,\nm \u2208 [0 :\np\n\u03a3\n(j)\n\nDefine the second kind functions \u03a8n as in (1.5).\nFor later use, we need a more general definition of generalized eigenvalues. Let Hn =\nn\u22121\n(Hi,j )i,j=0\n. As in (2.9), we denote by Pk,n (x) the determinant of the matrix obtained by skipping\nthe first k rows and the last k columns of the matrix Hn \u2212 xIn . Similarly we could skip any set\nof k different columns, not necessarily consecutive.\nLet k \u2208 [0 : p] and let (n0 , n1 , . . . , nk ) be a (k + 1)-tuple of positive integers such that\n0 \u2264 n0 < n1 < . . . < nk \u2264 n0 + p.\n\n(3.2)\n\nWe define the generalized eigenvalue determinant associated to (n0 , n1 , . . . , nk ) as\nP (n0 ,n1 ,...,nk ) (x) := det(Hnk \u2212 xInk )(0,1,...,k\u22121;n0 ,n1 ,...,nk\u22121 ) .\n\n(3.3)\n\nThat is, the polynomial P (n0 ,n1 ,...,nk ) (x) is the determinant of the submatrix obtained by skipping\nrows 0, 1, . . . , k \u2212 1 and columns n0 , n1 , . . . , nk\u22121 of Hnk \u2212 xInk . The generalized eigenvalues\nassociated to (n0 , n1 , . . . , nk ) are the numbers x \u2208 C such that P (n0 ,n1 ,...,nk ) (x) = 0. In the case\nk = 0 we put n := n0 and we understand P (n) (x) = det(Hn \u2212 xIn ) = (\u22121)n Qn (x).\nBy choosing (n0 , n1 , . . . , nk ) to be a sequence of consecutive numbers:\n(n0 , n1 , . . . , nk ) = (n \u2212 k, . . . , n \u2212 1, n),\nwe retrieve our earlier definition P (n\u2212k,...,n\u22121,n) (x) \u2261 Pk,n (x). Similarly we can retrieve Pk,l,n (x).\nIn this section we prove the following connection with Riemann-Hilbert minors.\n(p)\n\nProposition 3.1. Let H = (Hi,j )\u221e\ni,j=0 be the banded Hessenberg matrix (2.12) with aj 6= 0 for\nall j \u2265 0. Assume that the monic polynomials (Qn )\u221e\nn=0 (2.14)\u2013(2.15) associated with H satisfy\n\n14\n\n\fthe multiple orthogonality relations (3.1), for some complex measures \u03bd1 , . . . , \u03bdp supported on\n(j)\n\u03a3 \u2282 C. Let \u03a8n be the second kind functions (1.5). For any k \u2208 [0 : p], we have\nck (\u22121)n0 +...+nk P (n0 ,n1 ,...,nk ) (z) = B (n0 ,n1 ,...,nk ) (z),\nwhere\n\n(3.4)\n\n\uf8eb\n\n\uf8f6\n(1)\n(k)\nQnk (z) \u03a8nk (z) . . . \u03a8nk (z)\n\uf8ec .\n..\n.. \uf8f7\n\uf8ec ..\n.\n. \uf8f7\n\uf8f7\nB (n0 ,n1 ,...,nk ) (z) := det \uf8ec\n,\n\uf8ec\n\uf8f7\n(k)\n(1)\n\uf8edQn1 (z) \u03a8n1 (z) . . . \u03a8n1 (z)\uf8f8\n(1)\n(k)\nQn0 (z) \u03a8n0 (z) . . . \u03a8n0 (z) (k+1)\u00d7(k+1)\n\n(3.5)\n\nand where the constant ck is given in (2.11).\n\nThe matrix in the right hand side of (3.5) is again a submatrix of the RH matrix in (1.6)\n(with n = nk ), although not necessarily a principal submatrix. This follows from (3.2).\nProof of Prop. 3.1. We prove (3.4) by verifying that both sides of the equation satisfy the same\nrecurrence relation. Assume that nk \u2265 k + 1. If we apply the cofactor expansion formula to\nP (n0 ,n1 ,...,nk ) (z) along the last row, we obtain\nP (n0 ,n1 ,...,nk ) (z) =\n\np+1\nX\nj=1\n\n(\u22121)\u03c3j (Hnk \u2212 zInk )nk \u22121,nk \u2212j Pe (n0 ,...,nk\u22121 ,nk \u2212j) (z),\n\n(3.6)\n\nwhere in the right hand side of (3.6), Ai,j denotes the (i, j) entry of a matrix A, the function Pe\nis defined in the following way:\n\u001a (\u00f1 ,\u00f1 ,...,\u00f1 )\nk\nP 0 1\n(z)\nif nk \u2212 j 6\u2208 {n0 , . . . , nk\u22121 },\n(n0 ,...,nk\u22121 ,nk \u2212j)\ne\nP\n(z) :=\n0\notherwise,\n\nwhere (\u00f10 , \u00f11 , . . . , \u00f1k ) is obtained by ordering the entries of (n0 , . . . , nk\u22121 , nk \u2212 j) increasingly,\nand where \u03c3j is the sum of the row and column coordinates of the entry (Hnk \u2212 zInk )nk \u22121,nk \u2212j\nin the matrix (Hnk \u2212 zInk )(0,1,...,k\u22121;n0 ,n1 ,...,nk\u22121 ) (the definition of \u03c3j is used only when nk \u2212 j 6\u2208\n{n0 , . . . , nk\u22121 }). We also put (Hnk \u2212 zInk )i,j := 0 whenever j < 0.\nTo prove (3.6) we observe that the submatrix of (Hnk \u2212 zInk )(0,1,...,k\u22121;n0 ,n1 ,...,nk\u22121 ) obtained\nby skipping the row and column occupied by the entry (Hnk \u2212 zInk )nk \u22121,nk \u2212j , takes the form\n\u0013\n\u0012\n(Hnek \u2212 zInek )(0,1,...,k\u22121;en0 ,en1 ,...,enk\u22121 ) 0\n,\n\u2217\nL\nwhere L is a lower triangular square matrix of size nk \u2212 1 \u2212 n\nek with 1's on the main diagonal.\nHence the determinant of this submatrix equals P (en0 ,en1 ,...,enk ) (z), which yields (3.6).\nNote that the recursion (3.6) is completely determined from its initial condition (determinant\nof an empty matrix)\nP (0,1,...,k) (z) \u2261 1.\n(3.7)\n(k)\n\nIt is well-known (and easily checked) that the second kind functions \u03a8n satisfy exactly the\nsame recursion as the polynomials Qn , in the sense that\n(k)\n\n(1)\n\n(k)\n\n(p)\n\n(k)\n\n(0) (k)\nx\u03a8(k)\nn (z) = \u03a8n+1 (z) + an \u03a8n (z) + an\u22121 \u03a8n\u22121 (z) + * * * + an\u2212p \u03a8n\u2212p (z),\n\n15\n\nn \u2265 k,\n\n(3.8)\n\n\f(k)\n\nfor any k \u2208 [1 : p]. The recursion for the functions \u03a8n (z) starts only from the index n = k.\nAssume that nk \u2265 k + 1. Applying (2.14) and (3.8) (with n := nk \u2212 1) to the first row of (3.5)\nand using the linearity of the determinant, we deduce that\nB (n0 ,n1 ,...,nk ) (z) =\n\np+1\nX\nj=1\n\nwhere\ne (n0 ,...,nk\u22121 ,nk \u2212j) (z) :=\nB\n\ne (n0 ,...,nk\u22121 ,nk \u2212j) (z)\n(\u22121)1+\u03c4j (Hnk \u2212 zInk )nk \u22121,nk \u2212j B\n\u001a\n\nB (\u00f10 ,\u00f11 ,...,\u00f1k ) (z)\n0\n\n(3.9)\n\nif nk \u2212 j 6\u2208 {n0 , . . . , nk\u22121 },\notherwise,\n\nand \u03c4j is the number of adjacent transpositions that are necessary to order (n0 , . . . , nk\u22121 , nk \u2212 j)\nincreasingly, e.g. for (n0 , n1 , n2 , n3 \u2212 j) = (1, 4, 5, 3) we have \u03c4j = 2.\nIf (e\nn0 , n\ne1 , . . . , n\ne k ) is obtained by ordering (n0 , . . . , nk\u22121 , nk \u2212 j) increasingly, then obviously\nn0 + n1 + * * * + nk \u2212 (e\nn0 + n\ne1 + * * * + n\nek ) = j.\n\n(3.10)\n\nFrom (3.6) and (3.10) we have\n\nck (\u22121)n0 +n1 +***+nk P (n0 ,n1 ,...,nk ) (z)\n=\n\np+1\nX\nj=1\n\n(Hnk \u2212 zInk )nk \u22121,nk \u2212j (\u22121)\u03c3j (\u22121)j (\u22121)ne0 +en1 +***+enk ck Pe(n0 ,n1 ,...,nk \u2212j) (z). (3.11)\n\nWe claim that\n\n(\u22121)1+\u03c4j = (\u22121)\u03c3j +j .\n\n(3.12)\n\nLet j \u2265 1 and assume that nk\u22121 < nk \u2212 j. Then \u03c4j = 0 so the left-hand side of (3.12) is \u22121.\nNow, if j is even then \u03c3j is odd and vice-versa. So (3.12) holds in this case. Now let j1 be such\nthat (\u22121)1+\u03c4j1 = (\u22121)\u03c3j1 +j1 and nk \u2212 j1 = nl + 1 for some l \u2208 [0 : k \u2212 1]. Assume further that\nthe next value of j greater than j1 for which nk \u2212 j 6= ni for all i is j = j1 + q + 2, q \u2265 0. These\nassumptions imply that \u03c4j = \u03c4j1 + q + 1, \u03c3j = \u03c3j1 + 1, and therefore (\u22121)1+\u03c4j1 = (\u22121)\u03c3j1 +j1\nimplies that (3.12) is valid for j. This completes the justification of (3.12).\nIt follows from (3.9), (3.11) and (3.12) that for each k, the functions B (n0 ,n1 ,...,nk ) and\nck (\u22121)n0 +n1 +***+nk P (n0 ,n1 ,...,nk ) satisfy the same recurrence relations. The recursion (3.9) is\nalso completely determined from its initial condition B (0,1,...,k) , which is\n\uf8f6\n(1)\n(k)\nQk (z) \u03a8k (z) . . . \u03a8k (z)\n\uf8ec .\n..\n.. \uf8f7\n\uf8f7\nB (0,1,...,k) (z) = det \uf8ec\n.\n. \uf8f8\n\uf8ed ..\n(1)\n(k)\nQ0 (z) \u03a80 (z) . . . \u03a80 (z)\n\uf8eb k\nz + O(z k\u22121 )\nO(z \u22122 )\nO(z \u22122 )\n\u22122\n\uf8ec O(z k\u22121 )\nO(z )\nO(z \u22122 )\n\uf8ec\n\uf8ec\n..\n..\n..\n\uf8ec\n.\n.\n.\n= det \uf8ec\n2\n\u22122\n\u22122\n\uf8ec\nO(z\n)\nO(z\n)\nO(z\n)\n\uf8ec\n\u22122\n\u22121\n\uf8ed\nO(z)\nO(z )\nC2 z + O(z \u22122 )\nO(1)\nC1 z \u22121 + O(z \u22122 )\nO(z \u22121 )\n\uf8eb\n\n16\n\n\uf8f6\n...\nO(z \u22122 )\n. . . Ck z \u22121 + O(z \u22122 )\uf8f7\n\uf8f7\n\uf8f7\n..\n\uf8f7\n.\n\uf8f7\n\uf8f7\n...\nO(z \u22121 )\n\uf8f7\n\uf8f8\n...\nO(z \u22121 )\n...\nO(z \u22121 )\n\n\fR\nwith Cj := Qj\u22121 (t) d\u03bdj (t). Expanding this determinant as a signed sum over all permutations of\n(0, 1, . . . , k), we see that all the terms in this sum are O(z \u22121 ) except for the one that corresponds\nto the permutation (0, k, . . . , 2, 1):\nk\nB (0,1,...,k) (z) = (\u22121)(2 ) C1 C2 . . . Ck + O(z \u22121 ).\n\nSince we already know by Lemma 1.2 that the determinant in the left hand side is a polynomial\nin z, the O(z \u22121 ) term in the right hand side vanishes. The value of ck was chosen so that\nck (\u22121)0+1+***+k P (0,1,...,k) (z) = B (0,1,...,k) (z),\nso the two initial conditions are the same and this concludes the proof of (3.4).\n\n4\n\nInterlacing of generalized eigenvalues\n\nIn this section we prove Theorems 2.7 and 2.12 on the interlacing of generalized eigenvalues. To\nthis end we use some results on totally positive matrices.\n\n4.1\n\nGeneralized eigenvalues of totally positive matrices\n\nA matrix A \u2208 Cn\u00d7m is called totally positive (TP) if the determinant of any square submatrix\nof A is positive, i.e.,\ndet A(K, L) > 0,\n(4.1)\nfor any index sets K \u2282 [0 : n \u2212 1], L \u2282 [0 : m \u2212 1] of the same cardinality |K| = |L|, where we\nwrite A(K, L) for the submatrix of A with rows and columns indexed by K and L, respectively.\nWe emphasize that in the submatrix A(K, L) the rows and columns are positioned in the same\norder given in A. Fekete's criterion asserts that a sufficient condition for A to be TP is that (4.1)\nholds for all index sets K and L formed by consecutive indices, i.e., K = {r, r \u2212 1, . . . , r \u2212 q + 1}\nand L = {c, c \u2212 1, . . . , c \u2212 q + 1} with q := |K| = |L| and for suitable integers r, c.\nThe matrix A is called totally nonnegative (TNN) if we have the inequality \u2265 in (4.1):\ndet A(K, L) \u2265 0,\n\n(4.2)\n\nfor all index sets K \u2282 [0 : n \u2212 1], L \u2282 [0 : m \u2212 1] with |K| = |L|. It is well known that TP\nmatrices are dense in the class of TNN matrices. Moreover, the class of TP (or TNN) matrices\nis closed under matrix multiplication.\nThe theory of eigenvalues for TP matrices was developed by Gantmacher-Krein [15]. They\nshowed that the eigenvalues of an n \u00d7 n TP matrix are all positive and distinct and that they\nstrictly interlace with those of its principal (n \u2212 1) \u00d7 (n \u2212 1) submatrix. We need the following\nanalogue for generalized eigenvalues of TP matrices, which are again defined as in Section 2.3.\nProposition 4.1. (Generalized eigenvalues of TP matrices:) Fix 0 \u2264 k < n and let M \u2208\nC(n+k)\u00d7(n+k) be a TP matrix. Then the kth generalized eigenvalues of M are simple, lie in\n(0, \u221e) if k is even and lie in (\u2212\u221e, 0) if k is odd. The number of kth generalized eigenvalues of\nM is n \u2212 k. Moreover, the kth generalized eigenvalues of M and its principal leading submatrix\nQ \u2208 C(n+k\u22121)\u00d7(n+k\u22121) are strictly interlacing.\nProof. Let N be the submatrix of M obtained after skipping the first k rows and the last k\ncolumns of M . Thus N is of size n \u00d7 n. Partition\n\u0012\n\u0013\nA B\nN=\n(4.3)\nC D\n17\n\n\fwith C of size k \u00d7 k. By definition, the kth generalized eigenvalues of M are the numbers x \u2208 C\nsuch that\n\u0013\n\u0012\nA B \u2212 xIn\u2212k\n= 0.\n(4.4)\ndet\nC\nD\nThe assumption that M is totally positive implies in particular that all the entries of N are\npositive. We bring N to a simpler form by means of elementary row operations. Denote\nGj := In \u2212\n\nNj,0\nEj,j+1 ,\nNj+1,0\n\nwhere for j, l \u2208 [0 : n \u2212 1], Nj,l denotes the (j, l) entry of N , and where Ej,l is the elementary\nmatrix of size n \u00d7 n whose (j, l) entry is 1 and which has all its other entries equal to zero.\nMultiplying N on the left with the matrix Gj amounts to subtracting from row j, Nj,0 /Nj+1,0\ntimes row j + 1. This operation eliminates the (j, 0) entry of N .\nWe also define\n(\nNj,0\nIn + Nj+1,0\nEj+k,j+k+1 , if j + k + 1 < n,\nej :=\nG\nIn ,\notherwise.\ne j satisfy\nThe matrices Gj and G\n\u0012\n\u0013\n\u0012\n\u0013\n0 In\u2212k e\n0 In\u2212k\nGj\nGj =\n,\n0\n0\n0\n0\n\nj \u2208 [0 : n \u2212 2],\n\n(4.5)\n\nwhere we use the same decomposition in blocks as in (4.3).\nConsider the transformed matrix\ne1 . . . G\ne n\u22122 .\ne (1) := Gn\u22122 . . . G1 G0 N G\ne0 G\nN\n\n(4.6)\n\ne (1) has all its entries in the first column equal to zero except for the last one, which\nThe matrix N\nequals Nn\u22121,0 . Let N (1) be the matrix obtained by removing the first column and the last row\ne (1) . Using (4.5), we deduce that the kth generalized eigenvalues of M are the points x \u2208 C\nof N\nsuch that\n!\ne B\ne \u2212 xIn\u2212k\nA\ndet e\n= 0,\n(4.7)\ne\nC\nD\nwhere\n\nN\n\n(1)\n\n=\n\ne B\ne\nA\ne\ne\nC D\n\n!\n\ne of size (k \u2212 1) \u00d7 (k \u2212 1). Observe that compared to (4.4), the diagonal of x's in (4.7) is\nwith C\ncloser to the main diagonal.\nWe claim that the matrix \u2212N (1) is a TP matrix (note the minus sign). For convenience\nwe label the rows and columns of N (1) from 0 to n \u2212 2 and from 1 to n \u2212 1, respectively. Let\nK = {r, r \u2212 1, . . . , r \u2212 q + 1} \u2282 [0 : n \u2212 2] and L = {c, c \u2212 1, . . . , c \u2212 q + 1} \u2282 [1 : n \u2212 1] be two\nindex sets. From the fact that N is TP we have that\ndet N (K \u222a {r + 1}, L \u222a {0}) > 0,\ni.e., the determinant of the enlarged submatrix obtained by adjoining row r + 1 and column 0 to\nN (K, L) is positive.\n18\n\n\fDefine\n\nb := Gr . . . G1 G0 N.\nN\n\nIt is clear that\n\nb (K \u222a {r + 1}, L \u222a {0}),\n0 < det N (K \u222a {r + 1}, L \u222a {0}) = det N\n\n(4.8)\n\nwhere the last equality follows since the row operations G0 , . . . , Gr applied to N leave the determinant invariant.\nFrom the definition of the row operations G0 , . . . , Gr , the submatrix in the right hand side\nof (4.8) is zero in its first column except for its last entry. Expanding the determinant along its\nfirst column we therefore see that\nb (K \u222a {r + 1}, L \u222a {0}) = (\u22121)q Nr+1,0 det N\nb (K, L),\ndet N\n\nwhich combined with (4.8) and the TP property of N yields\nb (K, L) > 0.\n(\u22121)q det N\n\n(4.9)\n\nb replaced by the matrix\nThe property (4.9) remains valid with N\n\nb = Gn\u22122 . . . G1 G0 N,\nGn\u22122 . . . Gr+1 N\n\nb leave the submatrix indexed by rows\nsince the row operations Gr+1 , . . . , Gn\u22122 applied to N\nK and columns L invariant. Since K and L are arbitrary index sets, this implies by Fekete's\ncriterion that the matrix of size (n \u2212 1) \u00d7 (n \u2212 1),\n\u2212(Gn\u22122 . . . G1 G0 N )([0 : n \u2212 2], [1 : n \u2212 1]),\nis TP. This implies in turn that\ne (1) ([0 : n \u2212 2], [1 : n \u2212 1]) = \u2212N (1)\n\u2212N\n\ne0 , G\ne1 , . . . , G\ne n\u22122 adds to a column\nis also TP, since (cf. (4.6)) each of the column operations G\na positive multiple of the previous column; it is straightforward to verify that such operations\nleave the total positivity of a matrix invariant.\nBy repeating the transformation N (0) := N 7\u2192 N (1) k times, we get a series of matrices\n(0)\nN , N (1) , N (2) , . . . , N (k) so that the kth generalized eigenvalues of M are the (usual) eigenvalues\nof N (k) . Moreover, the matrix (\u22121)k N (k) is TP. One of the assertions of the Gantmacher-Krein\ntheorem implies then the validity of the first statement of the Proposition.\nFinally, if we apply to the leading principal submatrix Q of M the operations described\nabove, and denote the resulting series of matrices by Q(0) , Q(1) , Q(2) , . . . , Q(k) , then Q(j) will be\nthe leading principal submatrix of N (j) for each j \u2208 [0 : k]. In particular, Q(k) is the leading\nprincipal submatrix of N (k) and the Gantmacher-Krein theorem implies the interlacing property\nwe want.\nSince TP matrices are dense in the class of TNN matrices, we obtain\nCorollary 4.2. (Generalized eigenvalues of TNN matrices:) Fix 0 \u2264 k < n and let M \u2208\nC(n+k)\u00d7(n+k) be a TNN matrix. Then the kth generalized eigenvalues of M lie in [0, \u221e) if k is\neven and lie in (\u2212\u221e, 0] if k is odd. Denoting the kth generalized eigenvalues of M by (yi )i=1,2,...\nand those of its principal leading submatrix by (xi )i=1,2,... , both of them ordered by increasing\nmodulus and counting multiplicities, then we have the (weak) interlacing\n0 \u2264 |y1 | \u2264 |x1 | \u2264 |y2 | \u2264 |x2 | \u2264 . . . .\nNote that the moduli can be removed if k is even and replaced by minus signs if k is odd.\n19\n\n\fRemark 4.3. In the process of approximating a TNN matrix by a sequence of TP matrices, some\nof the generalized eigenvalues may escape to infinity. This will always happen for the kind of\nbanded matrices we are interested in.\n\n4.2\n\nThe approach of Eiermann-Varga revisited\n\nIn the proofs of Theorems 2.7 and 2.12, we will use some ideas from Eiermann-Varga [12], which\nwe now review.\nConsider Qn (x) = (\u22121)n det(Hn \u2212 xIn ) with Hn the n \u00d7 n two-diagonal Hessenberg matrix\nin (2.7). Let P : [0 : n \u2212 1] 7\u2192 [0 : n \u2212 1] be the permutation that sorts the indices according to\ntheir residue modulo p + 1, in the natural way, that is,\n(P (0), P (1), . . . , P (n \u2212 1)) = (0, p + 1, 2p + 2, . . . ; 1, p + 2, 2p + 3, . . . ; . . . ; p, 2p + 1, 3p + 2, . . .).\nAlso denote with P the corresponding permutation matrix such that P ej = eP (j) for j \u2208 [0 :\nn \u2212 1]. Thus P has in its jth column the value 1 at position P (j) and zero at all other positions.\nWe consider the permuted matrix P \u22121 Hn P \u2212 xIn . It has a block bidiagonal structure:\n\uf8eb\n\uf8f6\nX0 Y0\n\uf8ec 0 X1 Y1\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\n\u22121\n.\n.\n..\n..\nP Hn P \u2212 xIn = \uf8ec\n(4.10)\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ed\n\uf8f8\nXp\u22121 Yp\u22121\nYp\nXp\nk\nj\n, where Yj is the principal truncation of size nj \u00d7 nj+1\nwhere Xj = \u2212xInj with nj := n+p\u2212j\np+1\nof the semi-infinite bidiagonal matrix\n\uf8eb\n\uf8f6\n1\n\uf8ecaj+1\n\uf8f7\n1\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\na\n1\np+j+2\nYj,\u221e = \uf8ec\n(4.11)\n\uf8f7\n\uf8ec\n\uf8f7\na\n1\n2p+j+3\n\uf8ed\n\uf8f8\n.. ..\n.\n.\nfor j \u2208 [0 : p \u2212 1], and where Yp is the principal truncation of size np \u00d7 n0 of the matrix\n\uf8f6\n\uf8eb\na0\n1\n\uf8f7\n\uf8ec\nap+1\n1\n\uf8f7\n\uf8ec\n(4.12)\nYp,\u221e = \uf8ec\n\uf8f7.\na2p+2 1\n\uf8f8\n\uf8ed\n..\n..\n.\n.\nLemma 4.4. (a) Let A be a matrix of size n \u00d7 n as in the right hand side of (4.10), with\ndiagonal blocks Xj = \u2212xInj , j \u2208 [0 : p]. Then we have\ndet A = (\u22121)n\u2212n0 xn\u2212(p+1)n0 det(Y0 Y1 . . . Yp \u2212 xp+1 In0 ).\n(b) Under the same hypotheses, if we replace X0 by an arbitrary square matrix of size n0 \u00d7 n0 ,\nthen we have\ndet A = (\u22121)n\u2212n0 xn\u2212(p+1)n0 det(Y0 Y1 . . . Yp + xp X0 ).\n\n20\n\n\fProof. Use Gaussian elimination with the blocks X1 , . . . , Xp as pivots to eliminate the blocks\nabove the main diagonal. After these operations, the block we obtain in the upper left corner is\nthe matrix X0 + x\u2212p Y0 Y1 . . . Yp . The exponent of x is easily determined.\nNote that the zeros of Qn are the points x where det(P \u22121 Hn P \u2212 xIn ) vanishes. Now we\napply Lemma 4.4(a) to this determinant. Each of the matrices Y0 , Y1 , . . . , Yp in (4.11)\u2013(4.12)\nis bidiagonal with positive entries and hence TNN. Thus also the matrix product Y0 Y1 . . . Yp is\nTNN (actually it is oscillatory [12]). This already shows that all the eigenvalues of Y0 Y1 . . . Yp\nare in [0, \u221e). Taking into account the factor xp+1 in Lemma 4.4(a), we then see that the zeros\nof Qn are all located on the star S+ .\nCarrying on this approach a little further and using the Gantmacher-Krein theory, one obtains\nthe (strict) interlacing relations for the zeros of the polynomials Qn and Qn+1 , and for Qn and\nQn+p+1 . See Eiermann-Varga [12]. Alternative proofs of the interlacing are in [16] and [24].\n\n4.3\n\nProofs of Theorems 2.7 and 2.12\n\nIn this section we prove Theorems 2.7 and 2.12. To this end we will rely on Cor. 4.2 and the\nideas in Section 4.2.\nWe always label rows and columns starting from 0. We will assume throughout the proof\nthat n is a fixed multiple of p + 1 and we fix k \u2208 [0 : p \u2212 1]. The modifications if n is not a\nmultiple of p + 1 are discussed at the end of this section.\n4.3.1\n\nProof of Theorem 2.7(a) (n a multiple of p + 1)\n\nRecall that Pk,n (x) is the determinant of the matrix obtained by skipping rows [0 : k \u2212 1] and\ncolumns [n \u2212 k : n \u2212 1] of Hn \u2212 xIn . Applying the permutation P above, this is equivalent to\nskipping certain rows and columns of the permuted matrix (4.10). More precisely, Pk,n (x) is, up\nto its sign, equal to the determinant of the submatrix obtained by skipping the first row of each\nof the blocks X0 , Y0 , X1 , Y1 , . . . , Xk\u22121 , Yk\u22121 in (4.10), and skipping the last column of each of the\nblocks Xp , Yp\u22121 , Xp\u22121 , Yp\u22122 , . . . , Xp\u2212k+1 , Yp\u2212k (here we are using the fact that n is a multiple\nof p + 1). This can be seen as follows: if we write the submatrix of Hn \u2212 xIn as L(Hn \u2212 xIn )R,\nwith L and R suitable submatrices of the identity matrix In (of size (n \u2212 k) \u00d7 n and n \u00d7 (n \u2212 k),\ne \u22121 (Hn \u2212 xIn )P R,\ne then\nrespectively), and similarly the submatrix of P \u22121 (Hn \u2212 xIn )P as LP\n\u22121\ne = P1 LP and R\ne = P RP2 , for some permutation matrices P1 and P2 of size n \u2212 k.\nL\nDue to the above skipping of rows and columns, some of the diagonal blocks Xj in (4.10) will\nbecome rectangular instead of square. Thus we cannot apply Lemma 4.4 anymore. Our goal is\ntherefore to make all the diagonal blocks square again. More precisely, our goal is to get a matrix\nas in the right hand side of (4.10) with diagonal blocks Xj\u2032 = \u2212xI, for the identity matrix of\n\u0012\n\u0013\n0\n\u2212xI\n\u2032\ncertain size, j \u2208 [1 : p], and with X0 =\n. (We write Xj\u2032 , Yj\u2032 to distinguish from the\n0k\u00d7k\n0\nblocks Xj , Yj in (4.10).) We will then be able to apply Lemma 4.4(b).\nRecall that in the determinantal formula for Pk,n (x) we are skipping rows [0 : k\u22121] of Hn \u2212xIn .\nThen in the first k columns of this matrix there is only one non-zero entry left, being a0 , . . . , ak\u22121\nrespectively. Expanding the determinant along the columns [1 : k \u2212 1] (we do not touch column\n0) we necessarily have to pick these entries. Then the determinant equals \u00b1a1 * * * ak\u22121 times\nthe determinant of the matrix obtained by skipping the rows and columns in which the entries\na1 , . . . , ak\u22121 are standing. These are columns [1 : k \u2212 1] and rows [p + 1 : p + k \u2212 1].\n\n21\n\n\fFrom the skipping of rows [p + 1 : p + k \u2212 1], we see that in columns [p + 2 : p + k \u2212 1] there is\nonly one non-zero entry left, being ap+2 , . . . , ap+k\u22121 respectively. So again the determinant picks\nup a factor \u00b1ap+2 . . . ap+k\u22121 , and we can proceed with the determinant of the matrix obtained\nby skipping the rows and columns in which the entries ap+2 , . . . , ap+k\u22121 are standing. These are\ncolumns [p + 2 : p + k \u2212 1] and rows [2p + 2 : 2p + k \u2212 1].\nFrom the skipping of rows [2p + 2 : 2p + k \u2212 1], we now have only one non-zero entry left in\neach of the columns [2p + 3 : 2p + k \u2212 1], being a2p+3 , . . . , a2p+k\u22121 respectively. We can then\nmake a reduction as in the previous paragraphs. Carrying on this scheme a few more steps, we\nare left with the following submatrix of Hn \u2212 xIn : It is obtained by skipping the rows\n[0 : k \u2212 1] \u222a [p + 1 : p + k \u2212 1] \u222a [2p + 2 : 2p + k \u2212 1] \u222a . . . \u222a {(k \u2212 1)p + k \u2212 1}\n\n(4.13)\n\nand the columns\n[1 : k \u2212 1] \u222a [p + 2 : p + k \u2212 1] \u222a [2p + 3 : 2p + k \u2212 1] \u222a . . . \u222a {(k \u2212 2)p + k \u2212 1}\n\n(4.14)\n\nin the starting matrix Hn \u2212 xIn .\nWe can do similar operations with the last rows and columns of Hn \u2212 xIn . Indeed, recall that\nin the definition of Pk,n (x) we are skipping columns [n \u2212 k : n \u2212 1] of Hn \u2212 xIn . The determinant\ncan then be further reduced to the one obtained by skipping the rows\n{n \u2212 (k \u2212 1)p \u2212 k} \u222a . . . \u222a [n \u2212 2p \u2212 k : n \u2212 2p \u2212 3] \u222a [n \u2212 p \u2212 k : n \u2212 p \u2212 2] \u222a [n \u2212 k : n \u2212 1] (4.15)\nand the columns\n{n \u2212 kp \u2212 k} \u222a . . . \u222a [n \u2212 2p \u2212 k : n \u2212 2p \u2212 2] \u222a [n \u2212 p \u2212 k : n \u2212 p \u2212 1] \u222a [n \u2212 k : n \u2212 1] (4.16)\nin the matrix Hn \u2212 xIn .\nSummarizing, we see that Pk,n (x) is, up to a constant, equal to the determinant of the\nsubmatrix of Hn \u2212 xIn obtained by skipping the rows (4.13) and (4.15) and the columns (4.14)\nand (4.16).\nThe skipping of the indicated rows and columns of Hn \u2212 xIn is again equivalent (up to a sign)\nto removing certain rows and columns of the permuted matrix P \u22121 Hn P \u2212 xIn in (4.10). This\nleads to the formula\n\uf8f6\n\uf8eb \u2032\nX0 Y0\u2032\n\uf8f7\n\uf8ec 0 X1\u2032 Y1\u2032\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n.\n.\n..\n..\nPk,n (x) = c det \uf8ec\n(4.17)\n\uf8f7,\n\uf8f7\n\uf8ec\n\u2032\n\u2032\n\uf8ed\nXp\u22121 Yp\u22121 \uf8f8\nYp\u2032\nXp\u2032\n\nc 6= 0, where X0\u2032 is obtained by skipping the first k rows and last k columns of X0 ; where\nXj\u2032 , j \u2208 [1 : p], is obtained by skipping the first max{k \u2212 j, 0} rows and columns and the last\nmax{j \u2212 p + k, 0} rows and columns of Xj ; where Yj\u2032 , j \u2208 [0 : p \u2212 1], is obtained by skipping the\nfirst max{k \u2212 j, 0} rows and max{k \u2212 j \u2212 1, 0} columns and the last max{j \u2212 p + k, 0} rows and\nmax{j \u2212 p + k + 1, 0} columns of Yj ; and finally Yp\u2032 is obtained by skipping the last k rows and\ncolumns of Yp .\nNote that each of the diagonal blocks Xj\u2032 , j \u2208 [1 : p] in (4.17) is of the form \u2212xI and moreover\nX0\u2032\n\n=\n\n\u0012\n\n0\n\n0k\u00d7k\n22\n\n\u2212xI\n0\n\n\u0013\n\n(4.18)\n\n\fwith k zero columns added at the left and k zero rows at the bottom. Hence we are in a position\nto apply Lemma 4.4(b): this yields\n\u0012\n\u0013\u0013\n\u0012\n0\nI\nk(p\u2212k)\n\u2032 \u2032\n\u2032\np+1\n,\n(4.19)\nPk,n (x) = cx\ndet Y0 Y1 . . . Yp \u2212 x\n0k\u00d7k 0\nc 6= 0. Note that each of the matrices Y0\u2032 , Y1\u2032 , . . . , Yp\u2032 in (4.17) is bidiagonal with nonnegative\nentries and hence TNN. Thus also the matrix product Y0\u2032 Y1\u2032 . . . Yp\u2032 is TNN. Cor. 4.2 and (4.19)\nthen imply that all the zeros of Pk,n lie on the star S+ (S\u2212 ) if k is even (odd). Finally, if we\napply the Cauchy-Binet formula to det(Y0\u2032 Y1\u2032 . . . Yp\u2032 ) then we see that this determinant is the sum\nof a finite number of nonnegative terms with at least one term strictly positive (for instance,\nthe term obtained by multiplying the determinants of the principal leading submatrices of Yi\u2032 ,\ni \u2208 [0 : p], is strictly positive). Noting that mk,n = k(p \u2212 k) if n is a multiple of p + 1, we now\nobtain Theorem 2.7(a).\n4.3.2\n\nProof of Theorem 2.7(b) (n a multiple of p + 1)\n\nNow we will prove the interlacing between the zeros of Pk,n and Pk,n+1 in Theorem 2.7(b), still\nassuming that n is a multiple of p + 1.\nRecall that in the determinantal formula for Pk,n+1 (x) we are skipping the rows [0 : k \u2212 1]\nof Hn+1 \u2212 xIn+1 . In exactly the same way as in Section 4.3.1, this leads to an iterated skipping\nprocess, allowing us to skip the rows (4.13) and the columns (4.14) of Hn+1 \u2212 xIn+1 .\nIn the definition of Pk,n+1 (x) we are skipping the columns [n \u2212 k + 1 : n] of Hn+1 \u2212 xIn+1 .\nThis leads again to an iterated skipping process, allowing us to skip the rows\n{n\u2212(k\u22122)p\u2212k+1}\u222a. . .\u222a[n\u22122p\u2212k+1 : n\u22122p\u22123]\u222a[n\u2212p\u2212k+1 : n\u2212p\u22122]\u222a[n\u2212k+1 : n\u22121] (4.20)\nand the columns\n{n\u2212(k\u22121)p\u2212k+1}\u222a. . .\u222a[n\u22122p\u2212k+1 : n\u22122p\u22122]\u222a[n\u2212p\u2212k+1 : n\u2212p\u22121]\u222a[n\u2212k+1 : n] (4.21)\nof Hn+1 \u2212 xIn+1 . Note that we are not skipping the rows n, n \u2212 p \u2212 1, n \u2212 2p \u2212 2, . . . and the\ncolumns n \u2212 p, n \u2212 2p \u2212 1, n \u2212 3p \u2212 2, . . ., although we are allowed to do that. The reason for\nnot skipping these rows and columns, is because that would complicate the comparison to the\nformulas (4.15)\u2013(4.16) for Pk,n .\nIn terms of the permuted matrix (4.17) we obtain\n\uf8eb\n\uf8f6\ne0 Ye0\nX\n\uf8ec\n\uf8f7\ne1 Ye1\n\uf8ec0 X\n\uf8f7\n\uf8ec\n\uf8f7\n.\n.\n\uf8ec\n\uf8f7,\n.\n.\nPk,n+1 (x) = c det \uf8ec\n(4.22)\n.\n.\n\uf8f7\n\uf8ec\n\uf8f7\ne\ne\n\uf8ed\nXp\u22121 Yp\u22121 \uf8f8\nep\nX\nYep\nej , Yej are obtained from the blocks X \u2032 , Y \u2032 for Pk,n in (4.17) by the\nc 6= 0, where the blocks X\nj\nj\nformulas\n\u0012 \u2032\n\u0013\nX0 \u2212x\u1ebd\ne\nX0 =\n,\n0\n0\nej = X \u2032 ,\nj \u2208 [1 : p \u2212 k],\nX\nj\n\u0013\n\u0012 \u2032\n0\ne j = Xj\n,\nj \u2208 [p \u2212 k + 1 : p],\nX\n0 \u2212x\n23\n\n\fwith \u1ebd denoting the kth last column of the identity matrix, and\n\u0012\n\u0013\nY0\u2032\ne\nY0 =\n,\nYej = Yj\u2032 ,\nj \u2208 [1 : p \u2212 k \u2212 1],\na\u2217 e T\n\u0013\n\u0012 \u2032\n\u0001\nYj e\n\u2032\ne ,\n,\nj \u2208 [p \u2212 k + 1 : p],\nYep\u2212k = Yp\u2212k\nYej =\n0 a\u2217\nwith e denoting the last column of the identity matrix, and with the\ncoefficients. Lemma 4.4(b) yields\n\u0012\n\u0012\n0\nPk,n+1 (x) = cx(k\u22121)(p\u2212k) det Ye0 Ye1 . . . Yep \u2212 xp+1\n0k\u00d7k\n\na\u2217 certain recurrence\n\nI\n0\n\n\u0013\u0013\n\n,\n\n(4.23)\n\nc 6= 0. But the cyclic product Ye0 Ye1 . . . Yep has Y0\u2032 Y1\u2032 . . . Yp\u2032 as its leading principal submatrix.\nHence Cor. 4.2 yields the required interlacing relation in Theorem 2.7(b). It is also easy to see,\nas at the end of Section 4.3.1, that det(Ye0 Ye1 . . . Yep ) > 0.\n\n4.3.3\n\nProof of Theorem 2.7(c) (n a multiple of p + 1)\n\nNext we prove the interlacing between the zeros of Pk,n and Pk,n+p+1 in Theorem 2.7(c), still\nassuming that n is a multiple of p + 1. Observe that n + p + 1 is also a multiple of p + 1. Applying\nexactly the same approach as in Section 4.3.1, we find that Pk,n+p+1 can be written as in the\nej , Yej are now obtained from the blocks X \u2032 , Y \u2032 for\nright hand side of (4.22), where the blocks X\nj\nj\nPk,n in (4.17) by the formulas\n\u0012 \u2032\n\u0013\n\u0012 \u2032\n\u0013\n0\nX0 \u2212x\u1ebd\ne0 =\ne j = Xj\nX\n,\nX\n,\nj \u2208 [1 : p],\n0\n0\n0 \u2212x\nwith again \u1ebd denoting the kth last column of the identity matrix, and\n\u0012\n\u0013\n0\nYj\u2032\ne\nYj =\n,\nj \u2208 [0 : p \u2212 k \u2212 1],\na\u2217 e T 1\n\u0012 \u2032\n\u0013\nYj e\nYej =\n,\nj \u2208 [p \u2212 k : p],\n0 a\u2217\n\nwith e denoting the last column of the identity matrix and with a\u2217 certain recurrence coefficients.\nWe can again apply Lemma 4.4(b). But the cyclic product Ye0 Ye1 . . . Yep has Y0\u2032 Y1\u2032 . . . Yp\u2032 as its leading principal submatrix. Cor. 4.2 then yields the required interlacing relation in Theorem 2.7(c).\n4.3.4\n\nProof of Theorem 2.12 (n a multiple of p + 1)\n\nNext we prove the interlacing relations between the zeros of Pk,n and Pk,l,n in Theorem 2.12,\nassuming that 1 \u2264 k < l \u2264 p and n is a multiple of p + 1. Recall that Pk,l,n is the determinant of\nthe submatrix obtained by skipping the rows [0 : k \u2212 1] and the columns {n\u2212 l} \u222a[n\u2212 k + 1 : n\u2212 1]\nof Hn \u2212 xIn . This leads to an iterated skipping process, allowing us to skip the rows (4.13) and\n{n\u2212(k \u22122)p\u2212(k \u22121)}\u222a. . .\u222a[n\u22122p\u2212k +1 : n\u22122p\u22123]\u222a[n\u2212p\u2212k +1 : n\u2212p\u22122]\u222a[n\u2212k +1 : n\u22121],\nand the columns (4.14) and\n{n\u2212(k\u22121)p\u2212k+1}\u222a. . .\u222a[n\u22122p\u2212k+1 : n\u22122p\u22122]\u222a[n\u2212p\u2212k+1 : n\u2212p\u22121]\u222a{n\u2212l}\u222a[n\u2212k+1 : n\u22121]\n24\n\n\fin the matrix Hn \u2212 xIn . Then Pk,l,n can be written as in the right hand side of (4.22), where\nej , Yej are now obtained from the blocks X \u2032 , Y \u2032 for Pk,n in (4.17) by the formulas\nthe blocks X\nj\nj\n\u0001\nej = X \u2032 ,\nX0\u2032 \u2212x\u1ebd ,\nX\nj \u2208 [1 : p \u2212 k], j 6= p \u2212 l + 1,\nj\n\u0012 \u2032\n\u0013\n\u0010\n\u0011\n0\ne j = Xj\nep\u2212l+1 \u2212xe ,\n= X\nX\n,\nj \u2208 [p \u2212 k + 1 : p],\n0 \u2212x\n\ne0 =\nX\n\n\u2032\nXp\u2212l+1\n\nand\n\nYej = Yj\u2032 ,\n\u0010\n\u0011\n\u2032\nYp\u2212l\n= Yep\u2212l e ,\n\u0001\n\u2032\ne ,\nYep\u2212k = Yp\u2212k\n\u0012 \u2032\n\u0013\nYj e\nYej =\n,\n0 a\u2217\n\nj \u2208 [0 : p \u2212 k \u2212 1], j 6= p \u2212 l,\n\nj \u2208 [p \u2212 k + 1 : p],\n\nwith the notations e, \u1ebd, a\u2217 as defined before.\nep\u2212l+1 : this is a scalar multiple of the identity\nThere is now a complication for the block X\n\u2032\nmatrix but with the last column skipped. Moreover, Yep\u2212l is a submatrix of Yp\u2212l\nrather than the\nother way around. We will resolve both issues by appending an extra row and column at the\nend of some of the blocks in the matrix in the right hand side of (4.22). These extra rows and\ncolumns will have a triangular structure and therefore will not influence the determinant (except\nfor a scalar factor), as we will see below. Here is the definition: we put\n\u0011\n\u0010\nbp\u2212l+1 := X\nep\u2212l+1 \u2212xe ,\nX\n\nthereby making this block square again. We also put\n\u0012\n\u0012 \u0013\n\u0013\nej\ne0\nX\n0\nX\nb\nb\n,\nXj :=\nX0 :=\n,\n0\n0 \u2212x\n\nwith the zeros denoting a row or column vector,\n\u0012\n\u0013\nYej 0\nb\nYj :=\n,\nj \u2208 [0 : p \u2212 l \u2212 1],\n0 1\n\nfor an arbitrary constant a 6= 0, and\n\nbj := X\nej ,\nX\nYbj := Yej ,\n\nj \u2208 [1 : p \u2212 l],\n\nYbp\u2212l :=\n\n\u0012\n\nYep\u2212l\n0\n\ne\na\n\n\u0013\n\n,\n\nj \u2208 [p \u2212 l + 2 : p],\nj \u2208 [p \u2212 l + 1 : p].\n\nAs mentioned, the triangular structure of the added rows\n\uf8f6\n\uf8eb\n\uf8eb\nb0 Yb0\ne0\nX\nX\n\uf8f7\n\uf8ec\n\uf8ec\nb\nb\n\uf8f7\n\uf8ec 0 X1 Y1\n\uf8ec0\n\uf8f7\n\uf8ec\n\uf8ec\n.\n.\n\uf8f7\n\uf8ec\n\uf8ec\n..\n..\ndet \uf8ec\n\uf8f7 = \u00b1a det \uf8ec\n\uf8f7\n\uf8ec\n\uf8ec\nbp\u22121 Ybp\u22121 \uf8f8\n\uf8ed\n\uf8ed\nX\nbp\nX\nYbp\nYep\n25\n\nand columns implies that\n\uf8f6\nYe0\n\uf8f7\ne1 Ye1\nX\n\uf8f7\n\uf8f7\n..\n..\n\uf8f7.\n.\n.\n\uf8f7\nep\u22121 Yep\u22121 \uf8f7\n\uf8f8\nX\nep\nX\n\n(4.24)\n\n\fb0\n(To see this, expand the determinant on the left-hand side of (4.24) along the last row of X\nb\nand Y0 . This row has only one nonzero entry. This allows to delete this row and also the last\nb1 . Next we expand the new determinant along the last row of X\nb1 and Yb1 ,\ncolumn of Yb0 and X\nb\nb\ne\ne\nand so on.) So we can work with Xj , Yj instead of Xj , Yj .\nSummarizing, Pk,l,n can be written as a constant times the left hand side of (4.24). Combining\nbj , Ybj are obtained from the blocks X \u2032 , Y \u2032 for\nthe above descriptions, we see that the blocks X\nj\nj\nPk,n in (4.17) by the formulas\n\u0012 \u2032\n\u0013\n\u0012 \u2032\n\u0013\n0\nX0 \u2212x\u1ebd\nb0 =\nb j = Xj\nX\n,\nX\n,\nj \u2208 [1 : p \u2212 l] \u222a [p \u2212 k + 1 : p],\n0\n0\n0 \u2212x\nbj = X \u2032 ,\nX\nj \u2208 [p \u2212 l + 1 : p \u2212 k],\nj\n\nand\n\n\u0012 \u2032\n\u0013\nYj 0\n,\n0 1\n\u0012 \u2032 \u0013\nYp\u2212l\n,\nYbp\u2212l =\naeT\nYbj = Yj\u2032 ,\n\u0001\n\u2032\ne ,\nYbp\u2212k = Yp\u2212k\n\u0012 \u2032\n\u0013\nYj e\nYbj =\n,\n0 a\u2217\nYbj =\n\nj \u2208 [0 : p \u2212 l \u2212 1],\n\nj \u2208 [p \u2212 l + 1 : p \u2212 k \u2212 1],\n\nj \u2208 [p \u2212 k + 1 : p].\n\nLemma 4.4(b) can be applied and yields\n\nk(p\u2212k)+k\u2212l\n\nPk,l,n (x) = cx\n\n\u0012\n\u0012\n0\np+1\nb\nb\nb\ndet Y0 Y1 . . . Yp \u2212 x\n0k\u00d7k\n\nI\n0\n\n\u0013\u0013\n\n,\n\n(4.25)\n\nc 6= 0. But the principal leading submatrix of Yb0 Yb1 . . . Ybp is precisely the matrix Y0\u2032 Y1\u2032 . . . Yp\u2032 .\nTaking into account that mk,n = k(p\u2212 k) if n is a multiple of p+ 1, we then obtain Theorem 2.12.\n4.3.5\n\nModifications if n is not a multiple of p + 1\n\nIf n is not a multiple of p + 1, we can use the same ideas but with a few modifications. We focus\non the construction for Pk,n in Section 4.3.1. We can again write Pk,n as in (4.17). But now the\ndescription of the blocks Xj\u2032 , Yj\u2032 depends on the residue q of n modulo p + 1, q \u2208 [1 : p]. More\nprecisely, the number of rows and columns to be skipped at the top and at the left of each block\nXj\u2032 , Yj\u2032 , is exactly the same as in Section 4.3.1. But for the rows and columns at the bottom and\nat the right of each block, the description that was given for Xj\u2032 , Yj\u2032 in Section 4.3.1 should now\n\u2032\n\u2032\nbe applied to Xj+q\n, Yj+q\n(where we view the subscripts modulo p + 1).\n\u0001\nThe above description\nimplies\nin particular that X0\u2032 = 0 \u2212xI , with k zero columns added\n\u0012\n\u0013\n\u2212xI\nat its left, and Xq\u2032 =\n, with k zero rows added at its bottom. All the other Xj are of the\n0\nform \u2212xI. Thus we are not able to apply Lemma 4.4.\nTo get around this issue, we append k extra rows and columns in the top and/or left part of\nsome of the blocks. We set\n\u0013\n\u0012\n\u0012\n\u0013\n\u2212xIk 0\nk\ne\ne0 = \u2212xE\n,\nX\n=\nX\n,\nj \u2208 [1 : q \u2212 1],\nj\n0\nXj\u2032\nX0\u2032\n\u0001\neq = 0 Xq\u2032 ,\nej = Xj\u2032 ,\nX\nX\nj \u2208 [q + 1 : p],\n26\n\n\fwhere Ek is the submatrix formed by the first k rows of the identity matrix, and\n\u0012\n\u0013\nI\n0\nYej = k\n,\nj \u2208 [0 : q \u2212 1]\n0 Yj\u2032\nYej = Yj\u2032 ,\n\nj \u2208 [q : p].\n\nDue to the triangular structure of the added rows and columns, they leave the determinant\nej , Yej .\ninvariant up to its sign. So we can replace the Xj\u2032 , Yj\u2032 by the X\ne\ne\ne\n\u0012 The blocks\n\u0013 Xj are now all of the form \u2212xI, except for Xq which is of the form Xq =\n0\n\u2212xI\n. To bring the matrix to the form required by Lemma 4.4, it suffices to apply\n0k\u00d7k\n0\nej , Yej , q positions to\na cyclic block permutation. More precisely, we move each of the blocks X\nthe top and to the left (in a cyclic way, thus reappearing at the bottom or right of the matrix\nwhen crossing the top or left matrix border respectively). We relabel the blocks in the permuted\nej+q and Y \u2032 := Yej+q where we view the subscripts\nmatrix as Xj\u2032 , Yj\u2032 in the usual way. Thus Xj\u2032 := X\nj\nmodulo p + 1.\nSummarizing, we can write Pk,n as in (4.17), where the blocks Xj\u2032 , Yj\u2032 have the form described\nin Lemma 4.4. The blocks Xj\u2032 , Yj\u2032 will play exactly the same role as in Sections 4.3.1\u20134.3.4.\nThe above construction for Pk,n , can also be used for the matrices associated to Pk,n+1 ,\nPk,n+p+1 and Pk,l,n . The blocks in these matrices differ from those for Pk,n only in their bottom\nright matrix corner. So the above modifications, which only affect a fixed number of top and\nleft rows and columns in each block, are exactly the same for each of these matrices. Since\nthe interlacing relations are obtained by comparing the bottom and right rows and columns, the\nproofs in Sections 4.3.2\u20134.3.4 then carry on in exactly the same way as before.\nThe only effect of adding rows and columns at the top or at the left, is that it changes the sizes\nof some of the blocks Xj\u2032 , Yj\u2032 . The sizes depend explicitly on the residue q of n modulo p + 1. The\nsame then holds for the exponents of x yielded by Lemma 4.4. The details are straightforward.\nRemark 4.5. To obtain the values for mk,n in (2.16) and the fact that Pek,n (0) 6= 0 in Theorem 2.7\nwith the above approach, one has to do a careful bookkeeping. Another approach for checking\nthese statements is to use (5.6) below. It suffices there to find the patterns s that yield the lowest\nexponent of x in (5.6), which is a combinatorial exercise.\n\n4.4\n\nInterlacing for arbitrary Riemann-Hilbert minors\n\nThe techniques in Sections 4.3.4 and 4.3.5 can be used to prove the following result for arbitrary\nRiemann-Hilbert minors. It generalizes Theorem 2.12.\nTheorem 4.6. Consider the two-diagonal Hessenberg matrix Hn in (2.7), where n is sufficiently\nlarge. Let k \u2208 [0 : p \u2212 1] and \u03ba \u2208 [0 : k \u2212 1] and consider the polynomials P n1 (x) and P n2 (x) (cf.\n(3.3)), with\nn1 = (n0 , . . . , n\u03ba , n \u2212 k + \u03ba + 1, . . . , n \u2212 1, n),\n\n(4.26)\n\nn2 = (n0 , . . . , n\u03ba\u22121 , n \u2212 k + \u03ba, . . . , n \u2212 1, n),\nwhere\nn \u2212 p \u2264 n0 < n1 < * * * < n\u03ba < n \u2212 k + \u03ba,\nand the last k \u2212 \u03ba (k \u2212 \u03ba + 1) components of n1 (n2 ) are taken consecutively.\n\n27\n\n(4.27)\n\n\f(a) We have\nP n1 (x) = xm Pe n1 (xp+1 ),\n\nP n2 (x) = xm+n\u03ba \u2212(n\u2212k+\u03ba) Pe n2 (xp+1 ),\n\nfor some explicit m depending only on the residues of the indices n0 , . . . , n\u03ba , n modulo p+1.\nThe zeros of the above polynomials Pe lie in R+ (R\u2212 ) if k is even (odd).\n\n(b) Denote by (yi )i=1,2,... and (xi )i=1,2,... the roots of Pen1 (x) and Pen2 (x) respectively, counting\nmultiplicities and ordered by increasing modulus. We have the weak interlacing relation\n0 \u2264 |y1 | \u2264 |x1 | \u2264 |y2 | \u2264 |x2 | \u2264 . . . .\n\n5\n\nNormal family estimates\n\nThe goal of this section is to prove the following result.\nLemma 5.1. (Normal family:) Let k \u2208 [0 : p] be fixed, and assume there exists an absolute\nconstant R > 0 so that\nR\u22121 < an < R,\nn \u2265 0.\n(5.1)\nThen for any compact set K \u2282 C \\ S+ (if k is even) or K \u2282 C \\ S\u2212 (if k is odd) and for any fixed\nset of indices ij \u2208 Z, j \u2208 [0 : k], with\ni0 < i1 < . . . < ik \u2264 i0 + p,\n\n(5.2)\n\nthere exists a constant M > 0 so that for all x \u2208 K and for all n we have\nM \u22121 < P (n+i0 ,n+i1 ,...,n+ik ) (x)/Pk,n (x) < M.\n\n(5.3)\n\nLemma 5.1 is proved in Section 5.2. In the proof we will need a combinatorial expansion of\nthe generalized eigenvalue determinant P (n0 ,n1 ,...,nk ) , to which we turn now.\n\n5.1\n\nCombinatorial expansion of generalized eigenvalue determinants\n\nWe start with a definition.\nDefinition 5.2. Let p \u2208 N, k \u2208 [0 : p] and n \u2212 p \u2264 n0 < n1 < . . . < nk = n be fixed numbers.\nn\u22121\nA pattern is a sequence s = (sj )j=0\nsuch that sj \u2208 {0, 1} for all j, with boundary conditions\ns0 = . . . = sk\u22121 = 1,\nsj =\n\n\u001a\n\n1,\n0,\n\nj = n0 , n1 , . . . , nk\u22121 ,\nj \u2208 [n \u2212 p : n \u2212 1] \\ {n0 , n1 , . . . , nk\u22121 },\n\n(5.4)\n(5.5)\n\nand such that the following rule holds:\nPattern rule: For each j \u2208 [0 : n \u2212 p \u2212 1] with sj = 1, exactly k out of the p numbers\nsj+1 , . . . , sj+p are equal to 1.\nWe denote with S the set of all such patterns s.\nFor example, if p = 4, k = 2 and (n0 , n1 , n2 = n) = (14, 15, 16) then the following sequence\nis a pattern: (sj )15\nj=0 = (1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1). For instance, note that s3 = 1 and\nexactly 2 out of the 4 numbers {s4 , s5 , s6 , s7 } are equal to 1, namely the numbers s5 and s6 .\nPn\u2212p\u22121\nFor a pattern s \u2208 S, write |s| = j=0\nsj . Thus |s| is the number of indices j \u2208 [0 : n\u2212p\u22121]\nfor which sj = 1. In the example above we have |s| = 8.\n28\n\n\fRemark 5.3. Let s be a pattern and consider a group of p consecutive numbers (sj )m\u22121\nj=m\u2212p ,\np \u2264 m \u2264 n. Def. 5.2 easily implies that #{j \u2208 [m \u2212 p : m \u2212 1] | sj = 1} \u2208 {k, k + 1}.\nRemark 5.4. In the case k = 0, we understand that there is no initial condition (5.4), and (5.5)\nreduces to ask sj = 0 for all j \u2208 [n \u2212 p : n \u2212 1].\nProposition 5.5. The generalized eigenvalue determinant P (n0 ,n1 ,...,nk ) can be written as a sum\nover patterns:\n\uf8f6\n\uf8eb\nn\u2212p\u22121\nY s\nX\n(5.6)\naj j \uf8f8 (\u2212x)(k+1)(n\u2212k)\u2212(p+1)|s|\u2212q ,\nP (n0 ,n1 ,...,nk ) (x) =\n(\u22121)(p\u2212k)|s| \uf8ed\nj=0\n\ns\u2208S\n\nwhere q :=\n\nPk\u22121\n\nj=0 (n\n\n+ j \u2212 k \u2212 nj ) \u2265 0.\n\nProof. In the proof we assume that k \u2265 1. Simpler arguments can be applied to prove (5.6)\nin the case k = 0. By definition, P (n0 ,n1 ,...,nk ) (x) is the determinant of the matrix obtained by\nskipping rows 0, . . . , k \u2212 1 and columns n0 , . . . , nk\u22121 of the matrix Hn \u2212 xI, with n = nk . We\nwrite this determinant as a signed sum over all permutations \u03c3 of length n \u2212 k:\n!\nn\u22121\nX\nY\nP (n0 ,n1 ,...,nk ) (x) =\n(\u22121)sign(\u03c3)\n(Hn \u2212 xI)i,\u03c3(i)\n(5.7)\n\u03c3\u2208Sn\u2212k\n\ni=k\n\nwhere (Hn \u2212 xI)i,j denotes the (i, j) entry of Hn \u2212 xI and we view \u03c3 as a map \u03c3 : [k : n \u2212 1] \u2192\n[0 : n \u2212 1] \\ {n0 , n1 , . . . , nk\u22121 }, in the natural way. We will often find it convenient to use the\ninverse map \u03c3 \u22121 .\nSince Hn \u2212 xI has only three nonvanishing diagonals, most of the terms in the sum (5.7) will\nbe zero. To have a nonzero term we must have \u03c3 \u22121 (i) \u2208 {i \u2212 1, i, i + p} for all i. For such a\nn\u2212p\u22121\n\u03c3, we define a sequence (sj )j=0\nby sj = 1 if \u03c3 \u22121 (j) = j + p (meaning that the permutation\n\u03c3 selects the entry (Hn \u2212 xI)j+p,j = aj ) and sj = 0 otherwise. We define the boundary values\nn\u22121\n(sj )j=n\u2212p\nas in (5.5). We claim that this sets up a bijection between the permutations \u03c3 leading\nto a nonzero term in (5.7), and the patterns s \u2208 S.\nTo prove this assertion, consider the matrix obtained by skipping rows 0, . . . , k \u2212 1 of Hn \u2212 xI.\nIts leading principal submatrix of size 2p \u2212 k + 1 by p + 1 can be partitioned in blocks as follows:\np \u2212 k +\uf8f6\n1\nX\n\uf8f8 ,\nY\nB\n\uf8eb\n\u2212x\n\uf8ec\nwhere A = diag(a0 , . . . , ak\u22121 ), B = diag(ak , . . . , ap ), X = \uf8ed\np\u2212k\nk\np\u2212k+1\n\n\uf8eb k\n0\n\uf8ed A\n0\n\n(5.8)\n\n1\n..\n.\n\n\uf8f6\n\n\uf8f7\n\uf8f8, and Y has its\n.\n\u2212x 1\n..\n\ntop right entry equal to \u2212x and all its other entries equal to zero.\nObserve that in each of the first k columns of (5.8) there is only one nonzero entry, being of\nthe form aj , j \u2208 [0 : k \u2212 1] in the block A. The permutation \u03c3 has to pick these entries. Hence\ns0 = . . . = sk\u22121 = 1, consistent with (5.4). In particular, since we have to pick a0 , we are not\nallowed to choose the entry \u2212x in the top right corner of the block Y .\nNow in each of the first p \u2212 k rows of (5.8), \u03c3 has to pick either the entry \u2212x or the entry 1\nfrom the corresponding row of the block X. Since X is rectangular with one more column than\nrow, there will be one of the chosen entries in each of the columns of X except one. This means\n29\n\n\fin turn that \u03c3 has to pick exactly one of the entries ak , . . . , ap of the block B in (5.8). So exactly\none of the numbers sk , . . . , sp equals 1 and the others equal zero.\nNow let 0 \u2264 j < i < n \u2212 p be two integers with sj = si = 1 and sj+1 = . . . = si\u22121 = 0.\nAssume (by induction) that exactly k out of the p numbers sj+1 , . . . , sj+p equal 1. By the above\nparagraphs, this holds if j = 0. We will prove that exactly k out of the p numbers si+1 , . . . , si+p\nn\u22121\nequal 1. Applying this argument iteratively, we will then obtain that (sj )j=0\nsatisfies the pattern\nrule (Def. 5.2).\nBy assumption we have that exactly k of the numbers sj+1 , . . . , sj+p equal 1. By the definition\nof i, this implies that exactly k \u2212 1 of the numbers si+1 , . . . , sj+p equal 1. So it will be enough\nto show that exactly one of the numbers sj+p+1 , . . . , si+p equals 1.\nConsider the submatrix of Hn \u2212 xI obtained by extracting rows j + p, . . . , i + p:\n\uf8eb\n\uf8f6\naj\n\u2212x 1\n\uf8ec\n\uf8f7\naj+1\n\u2212x 1\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\n.\n.\n.\n..\n..\n..\n(5.9)\n\uf8ec\n\uf8f7.\n\uf8ec\n\uf8f7\n\uf8ed\n\uf8f8\nai\u22121\n\u2212x 1\nai\n\u2212x 1\n\nNote that the entry \u2212x in the topmost row lies either in the same column or in a column to the\nright of ai . This follows from our assumptions that exactly k \u2265 1 of the numbers sj+1 , . . . , sj+p\nequal 1, and sj+1 = * * * = si\u22121 = 0. Now since \u03c3 picks the entries aj and ai , the entries \u2212x and\n1 in the first and last row of (5.9) cannot be chosen. On the other hand, \u03c3 has to choose one\nof the entries \u2212x or 1 from each of the rows containing aj+1 , . . . , ai\u22121 in (5.9). Since the block\nformed by the entries \u2212x and 1 lying between the two horizontal lines in (5.9) is rectangular\nwith one more column than row, there will be one of the chosen entries in each of its columns\n(i.e., the columns [j + p + 1 : i + p]), except one. This implies in turn that \u03c3 has to pick exactly\none of the entries aj+p+1 , . . . , ai+p . Thus exactly one of the numbers sj+p+1 , . . . , si+p equals 1,\nproving the claim of the above paragraph.\nIn the above argument we were tacitly assuming that [j + p + 1 : i + p] is disjoint from the set\nof skipped columns {n0 , n1 , . . . , nk\u22121 } in the definition of P (n0 ,n1 ,...,nk ) . If this disjointness fails,\nthen similar arguments as above show that [j + p + 1 : i + p] must contain exactly one of the\nindices n0 , n1 , . . . , nk\u22121 , and again, exactly one of the numbers sj+p+1 , . . . , si+p equals 1 (recall\n(5.5)).\nSummarizing, we have proved that each permutation \u03c3 leading to a nonzero term in (5.7)\ndefines a pattern s \u2208 S with\nsj = 1 if and only if \u03c3 \u22121 (j) = j + p, j \u2208 [0 : n \u2212 p \u2212 1].\n\n(5.10)\n\nConversely, we claim that each pattern s \u2208 S leads to a unique permutation \u03c3 satisfying (5.10)\nand associated to a nonzero term in (5.7). We call \u03c3 the permutation induced by s \u2208 S. To prove\nits existence and uniqueness, let again j < i be two numbers with sj = si = 1, sj+1 = . . . =\nsi\u22121 = 0. As observed before, exactly one of the numbers sj+p+1 , . . . , si+p equals 1; denote this\nnumber by sl+p , for suitable l. Skipping the corresponding column in (5.9), the block formed\nby the entries \u2212x and 1 lying between the two horizontal lines in (5.9) then takes the form\ndiag(C, D) with\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\n1\n\u2212x 1\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n..\n..\n\uf8f7\n\uf8ec\u2212x . . .\n\uf8f7\n\uf8ec\n.\n.\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n.\n,\nD=\uf8ec\nC=\uf8ec\n\uf8f7\n\uf8f7\n.\n.\n.\n..\n..\n.. 1 \uf8f8\n\uf8f8\n\uf8ed\n\uf8ed\n\u2212x 1 (i\u2212l)\u00d7(i\u2212l)\n\u2212x (l\u2212j\u22121)\u00d7(l\u2212j\u22121)\n30\n\n\fNote that both matrices C and D are square and triangular with nonzero diagonal entries. Hence\nif \u03c3 is a permutation induced by s, then we should have \u03c3 \u22121 (m) = m, for m \u2208 [j + p+ 1 : l + p\u2212 1]\n(so that \u03c3 picks the diagonal entries of C), and \u03c3 \u22121 (m) = m \u2212 1, for m \u2208 [l + p + 1 : i + p] (so\nthat \u03c3 picks the diagonal entries of D). If we follow this rule consequently for all j < i with\nsj = si = 1 and sj+1 = . . . = si\u22121 = 0, and use a similar reasoning near the top left matrix\ncorner (5.8), and near the bottom right matrix corner, then we will end up with the unique\npermutation \u03c3 induced by s \u2208 S. This proves the existence and uniqueness of \u03c3.\nNow let s \u2208 S be a pattern with induced permutation \u03c3. We claim that sign(\u03c3) = (\u22121)(p\u2212k)|s| .\nTo see this, recall that sign(\u03c3) = (\u22121)K where K is the number of pairs of column indices (j, i) in\n[0 : n \u2212 1] \\ {n0, . . . , nk\u22121 } with j < i and \u03c3 \u22121 (j) > \u03c3 \u22121 (i). Since \u03c3 \u22121 (i) \u2208 {i \u2212 1, i, i + p} for all i,\nin our case K is the number of pairs of column indices (j, i) with j \u2208 [0 : n \u2212 p \u2212 1], i \u2208 [j : j + p],\n\u03c3 \u22121 (j) = j + p (i.e., sj = 1) and \u03c3 \u22121 (i) \u2208 {i \u2212 1, i} (i.e., si = 0). But if j \u2208 [0 : n \u2212 p \u2212 1]\nis such that sj = 1 then exactly p \u2212 k of the numbers sj+1 , . . . , sj+p are 0, by Def. 5.2. Thus\nK = (p \u2212 k)|s| and sign(\u03c3) = (\u22121)(p\u2212k)|s| , proving our claim.\nLet again s \u2208 S be a pattern with induced permutation \u03c3. Let a, b, c be the number of indices\ni \u2208 [k : n \u2212 1] with \u03c3(i) = i \u2212 p, \u03c3(i) = i and \u03c3(i) = i + 1, respectively. Thus a, b, c denote the\nnumber of entries of Hn \u2212 xI of the form aj , \u2212x and 1, respectively, that are picked by \u03c3. We\nhave the two relations\na + b + c = n \u2212 k,\n\npa \u2212 c +\n\nk\u22121\nX\n\n(i \u2212 ni ) = 0.\n\n(5.11)\n\ni=0\n\nPn\u22121\nPk\u22121\nThe first relation is obvious. The second one follows from i=k (i \u2212 \u03c3(i)) + i=0 (i \u2212 ni ) =\n0, due to the facts that \u03c3 is a permutation and we are skipping the rows 0, 1, . . . , k \u2212 1 and\ncolumns n0 , n1 , . . . , nk\u22121 of Hn \u2212 xI. Now by adding the two relations in (5.11), we obtain\nb = (k + 1)(n \u2212 k) \u2212 (p + 1)a \u2212 q with q as in the statement of the proposition. This yields the\nexponent of \u2212x in (5.6). Putting together all the above observations, we obtain (5.6).\nNext we state a technical lemma on the existence of patterns with prescribed initial part.\nn\u2212K\nLemma 5.6. Let p, k, n and K \u2265 (p + 1)(k + 1) + pk be positive integers and let (sj )j=0\nsatisfy\n(5.4), with sj \u2208 {0, 1} for all j, and such that the pattern rule holds for all j \u2208 [0 : n \u2212 K \u2212 p].\nThen for any indices (nj )kj=0 with n \u2212 p \u2264 n0 < n1 < . . . < nk = n one can assign the numbers\nn\u22121\nn\u22121\n(sj )j=n\u2212K+1\nsuch that (sj )j=0\nis a pattern with respect to these indices (Def. 5.2).\n\ne := (p + 1)(k + 1) + pk; the case where K > K\ne is discussed\nProof. We will assume that K = K\nat the end of the proof.\nConsider the group of p consecutive numbers (sj )m\nm\u2212p+1 with m = n \u2212 K. Remark 5.3\nimplies that it has exactly k or k + 1 entries equal to 1. Assume these entries are at the positions\nm \u2212 p + ij , j \u2208 [l : k], with l \u2208 {0, 1} and 1 \u2264 il < . . . < ik \u2264 p. We define the next group of\np consecutive numbers (sj )m+p\nm+1 such that it has precisely k entries equal to 1, standing at the\npositions m + ij , j \u2208 [1 : k]. This definition is valid since it satisfies the pattern rule.\nm+2p\nNext, we define (sj )m+p+1\nsuch that it has 1's precisely at the positions m + p + eij with\nm+3p\nei1 = 1 and eij = ij for j \u2208 [2 : k]. In the next group (sj )m+2p+1\nwe put 1's at the indices\nb\nb\nb\nb\nm + 2p + ij with i1 = 1, i2 = 2 and ij = ij , j \u2208 [3 : k]. We repeat this procedure until we arrive\nm+(k+1)p\nat (sj )m+kp+1 with 1's at its first k positions and zeros elsewhere. We also define each of the\nm+(k+1)p+k\n\nnumbers (sj )m+(k+1)p+1 as 1. These definitions are compatible with the pattern rule.\n31\n\n\fNext, we use a similar strategy to arrive at the prescribed boundary conditions (5.5). Setting\ne\nm\ne := m + (k + 1)(p + 1), we know from the last paragraph that the group (sj )m\u22121\nhas 1's\nm\u2212p\ne\n\ne\nat its last k positions and zeros elsewhere. Then we define (sj )m+p\u22121\nwith 1's at the position\nm\ne\nm+2p\u22121\ne\nm\ne + p + n0 \u2212 n and at its last k \u2212 1 positions. Next, we define (sj )m+p\nwith 1's at the positions\ne\nm\ne + 2p + n0 \u2212 n, m\ne + 2p + n1 \u2212 n and at its last k \u2212 2 positions. Repeating this process, we\ne\nend up with (sj )m+kp\u22121\nhaving 1's at the positions m\ne + kp + nj \u2212 n, j \u2208 [0 : k \u2212 1], and zeros\nm+(k\u22121)p\ne\nelsewhere. These definitions are compatible with the pattern rule. Moreover, one checks that\n\nm\ne + kp + nj \u2212 n = nj ,\n\nm\ne + kp \u2212 1 = n \u2212 1.\n\nSo we obtain the desired boundary condition (5.5).\ne := (p + 1)(k + 1) + pk then we arbitrarily assign the numbers (sj )n\u2212Ke\nFinally, if K > K\nj=n\u2212K+1\ne\n\nn\u2212K\nso that the pattern rule is satisfied. We then use the extended sequence (sj )j=0\nand proceed in\nexactly the same way as before.\n\n5.2\n\nProof of Lemma 5.1\n\nWe write (5.6) in the form\nP (n0 ,n1 ,...,nk ) (x) = (\u2212x)(k+1)(n\u2212k)\u2212q\n\nX\ns\u2208S\n\n\uf8eb\n\n(\u22121)(k+1)|s| \uf8ed\n\nn\u2212p\u22121\nY\nj=0\n\ns\n\n\uf8f6\n\naj j \uf8f8 y \u2212|s| ,\n\n(5.12)\n\nwith y := xp+1 . Suppose that k is odd and y = xp+1 \u2208 R+ . Then in the above sum, each term\nis real and positive and hence no cancelation can occur. The same happens if k is even and\ny = xp+1 \u2208 R\u2212 .\nConsider the ratio of polynomials in (5.3). Both the numerator and denominator can be\nk \u22121\nbe a pattern corresponding to the indices n+i0 , . . . , n+ik .\nwritten as in (5.12). Let s = (sj )n+i\nj=0\nn\u22121\nLemma 5.6 implies that there exists a pattern se = (e\nsj )j=0\ncorresponding to the indices [n\u2212k +1 :\nn] such that sej = sj for all j \u2208 [0 : n \u2212 K], with K = max{(k + 1)(p + 1) + kp, \u2212ik + 1}. Clearly\nn\u2212K\nthere are only finitely many such patterns se (or s) with prescribed initial part (e\nsj )j=0\n(or\nn\u2212K\n(sj )j=0 ). Now for each fixed y \u2208 C \\ {0} there exists a constant M > 0 so that\n\uf8eb\n\nM \u22121 < \uf8edy \u2212|s|\n\nn+iY\nk \u2212p\u22121\nj=0\n\n\uf8f6 \uf8eb\n\ns\naj j \uf8f8 / \uf8edy \u2212|s\u0303|\n\nn\u2212p\u22121\nY\nj=0\n\n\uf8f6\n\ns\u0303\naj j \uf8f8\n\n< M,\n\n(5.13)\n\nuniformly in n. This is because the products in the numerator and denominator are equal except\nfor at most a finite number (independent of n) of factors aj and y, and in view of (5.1). We\nconclude that for each fixed x \u2208 S+ \\ {0} (if k is odd) or x \u2208 S\u2212 \\ {0} (if k is even) there is a\n(new) constant M > 0 so that\nM \u22121 < P (n+i0 ,n+i1 ,...,n+ik ) (x)/Pk,n (x) < M,\n\n(5.14)\n\nuniformly in n. This is due to the termwise estimate (5.13) and our earlier observation that the\nterms in (5.12) are all real with fixed sign. This already gives us a normal family estimate on\ncompact sets of S+ \\ {0} (if k is odd) or S\u2212 \\ {0} (if k is even).\nTo obtain the full statement of Lemma 5.1, we recall the interlacing relation for the generalized\neigenvalues in Theorem 4.6. With the notations n1 , n2 as in (4.26), Theorem 4.6 yields the partial\n32\n\n\ffraction decomposition\nPe n2 (x)/Pen1 (x) = \u03b10 +\n\nX\n\n\u03b1i /(x \u2212 yi ),\n\n(5.15)\n\ni=1,2,3,...\n\nwhere the numbers \u03b11 , \u03b12 , . . . all have the same sign, which is also the sign of \u03b10 if k is odd, or\nminus the sign of \u03b10 if k is even. For convenience we will assume that k is odd. In view of (5.14)\nwe already know that the left hand side of (5.15) is uniformly bounded in n for each fixed point\nx \u2208 R+ \\ {0}. Fix such an x. In view of the above observations we have\nX\n|\u03b1i |/dist(x, yi ) < M,\n|\u03b10 | < M,\ni=1,2,3,...\n\nuniformly in n, where dist is the Euclidean distance and we used that x > 0, yi \u2264 0 and all terms\nin (5.15) have positive sign. But now for any compact set K\u2032 \u2282 C \\ R\u2212 there exists R > 0 so that\nR\u22121 < |dist(x, yi )/dist(t, yi )| < R,\n\nfor all t \u2208 K\u2032 and yi \u2208 R\u2212 .\n\nThis now easily implies that\nPe n2 (t)/Pe n1 (t) < M,\n\nfor a new M > 0 and for all t \u2208 K\u2032 , uniformly in n. This already shows that the family of ratios\n(5.15) is normal on C \\ R\u2212 . Applying (5.14) two times for appropriate indices, we know that for\neach t > 0 there exists a constant M \u2032 > 0 such that\nPe n2 (t)/Pe n1 (t) > M \u2032 ,\n\nfor all n. This observation and Hurwitz' theorem imply that for any compact set K\u2032 \u2282 C \\ R\u2212 ,\nthe functions (5.15) are also uniformly bounded from below on K\u2032 by a positive constant. This\nproves (5.3) for the ratios P n2 (t)/P n1 (t). Similarly, using Theorem 2.7(b) we obtain\nM \u22121 < |Pk,n (t)/Pk,n+1 (t)| < M,\n\n(5.16)\n\nfor all t in a compact K \u2282 C \\ S\u2212 , uniformly in n. But now the ratio of polynomials in (5.3)\ncan be written as a product of finitely many ratios of the form (5.16) or P n2 (t)/P n1 (t), or their\ninverses, recall (4.26). This yields Lemma 5.1.\n\u0003\nRemark 5.7. The proof of Lemma 5.1 simplifies considerably when k = 0 or k = p. This is because\nin the former case we deal with the polynomials Qn (x), whose zeros are uniformly bounded on\nS+ , while in the latter case the numerator and denominator in (5.3) are simply constants.\n\n6\n\nProof of the Widom-type formula\n\nIn this section we prove Theorem 2.14. For ease of exposition let us assume for the moment that\nthe period r is sufficiently large: r \u2265 p. The condition (2.23) implies that H is a tridiagonal\nblock Toeplitz operator\n\uf8eb\n\uf8f6\nB0 B\u22121\n\uf8ecB1 B0 B\u22121\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8f7,\n.\nH =\uf8ec\n(6.1)\n.\n\uf8ec\n.\uf8f7\nB1\nB0\n\uf8ed\n\uf8f8\n..\n..\n.\n.\n33\n\n\fwhere the blocks Bk are of size r \u00d7 r and given by\n\uf8eb (0)\n\uf8f6\n\uf8eb\n(p)\nb0\n1\n0\n0 . . . br\u2212p\n\uf8ec .\n\uf8f7\n\uf8ec. .\n..\n..\n\uf8ec ..\n\uf8f7\n..\n\uf8ec ..\n.\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8ec\n\uf8f7\n\uf8ec\n..\n..\n..\n\uf8f7 , B1 = \uf8ec ..\n(p)\nB0 = \uf8ec\n.\n.\n.\n\uf8ecb0\n\uf8f7\n\uf8ec.\n\uf8ec\n\uf8f7\n\uf8ec.\n..\n..\n\uf8ec\n\uf8f7\n\uf8ed ..\n.\n.\n1 \uf8f8\n\uf8ed\n(p)\n(0)\n0 ... ...\n0\nbr\u2212p\u22121 . . . br\u22121\nB\u22121\n\n\u0012\n0\n=\n1\n\n0\n0\n\n\u0013\n\n(1) \uf8f6\n. . . br\u22121\n.. \uf8f7\n..\n.\n. \uf8f7\n\uf8f7\n\uf8f7\n(p) \uf8f7 ,\nbr\u22121 \uf8f7\n.. \uf8f7\n..\n.\n. \uf8f8\n\n...\n\n(6.2)\n\n0\n\n,\n\n(6.3)\n\nr\u00d7r\n\nwhere 0 denotes either a row or a column vector and the 0 in the top right corner is a square\nmatrix of size r \u2212 1. The symbol F (z, x) of the block Toeplitz matrix (6.1) is defined as [6, 30]\nF (z, x) = B\u22121 z \u22121 + B0 + B1 z \u2212 xIr ,\nwhere Ir is the identity matrix of size r. One checks that this definition coincides with (2.24).\nIn fact, a similar reasoning can be used also if r < p [7, Sec. 4].\nThe determinant of a banded block Toeplitz matrix is given by the next result.\nLemma 6.1. (Widom's determinant identity:) Under the assumptions of Theorem 2.14, we\nhave for all n sufficiently large that\nQrn (x) := det(xIrn \u2212 Hrn ) =\n\np\nX\n\nCk (x)(zk (x))\u2212n\u22121 ,\n\n(6.4)\n\n\u0013\n\n(6.5)\n\nk=0\n\nwith\nCk (x) = det\n\n\u0012\n\n1\n2\u03c0i\n\nZ\n\nF (z, x)\u22121\n\n\u03c3\n\ndz\nz\n\n,\n\nwhere F (z, x) is the symbol (2.24) and \u03c3 is an arbitrary, clockwise oriented, closed Jordan curve\nenclosing z = 0 and the point zk (x), but none of the other points zj (x), j \u2208 [0 : p], j 6= k.\nLemma. 6.1 follows by specializing Widom's result [30, Theorem 6.2] to the present setting.\nWe now find a more explicit form for the coefficients Ck (x).\nLemma 6.2. Under the assumptions of Lemma. 6.1, we have\nCk (x) =\n\n(\u22121)r det F r\u22121,0 (zk (x), x)\nQ\n,\nfp\nj6=k (zk (x) \u2212 zj (x))\n\nk \u2208 [0 : p].\n\n(6.6)\n\nProof. We start from formula (6.5). Note that this formula involves the matrix\nFe(z, x) := F (z, x)\u22121 ,\n\nwhich can be written in entrywise form as Fe(z, x) = (Fei,j (z, x))r\u22121\ni,j=0 with\ndet F j,i (z, x)\nFei,j (z, x) = (\u22121)i+j\n,\ndet F (z, x)\n\ni, j \u2208 [0 : r \u2212 1],\n\nthanks to the well-known cofactor formula for the inverse of a matrix.\n34\n\n(6.7)\n\n\fNow we consider in more detail the numerator and denominator of (6.7). For the denominator\nwe have\ndet F (z, x) \u2261 f (z, x) = (\u22121)r\u22121 z \u22121 + O(1),\nz \u2192 0,\nby virtue of (1.11)\u2013(1.13) and (2.24). For the numerator we have\n\u0012\n\u0013\n(\u22121)r 0 R\nr\u22121\ni,j\n+ O(1),\n(det F (z, x))i,j=0 =\n0 0\nz\n\nz \u2192 0,\n\nwhere each 0 is a row or column vector and where R is an upper triangular matrix with 1's on\nthe diagonal. Indeed, this follows due to the particular form of (2.24), (1.12). Observe that in\nthe matrix F (z, x), the entries with index (i, j) with j \u2265 i + 2 are of order O(z) as z \u2192 0. This\nexplains the upper triangularity of R. Secondly, the presence of 1's in the first super-diagonal\nof F (z, x) and of 1/z in the bottom left corner of the same matrix implies that for j = i + 1,\ndet F i,j (z, x) = (\u22121)r /z + O(1) as z \u2192 0.\nInserting the above expressions in (6.7), we obtain\n\u0012\n\u0013\ne T\n0 R\ne\nF (z, x) =\n+ O(z),\nz \u2192 0,\n(6.8)\n0 0\n\ne with 1's on the diagonal, where\nfor a new upper triangular matrix R\ne\nWe also need the behavior of F (z, x) for z \u2192 zk (x). Note that\n\nT\n\ndenotes the transpose.\n\np\nfp Y\nf (z, x) =\n(z \u2212 zt (x)),\nz t=0\n\nsee (1.13)\u2013(1.14). Hence from (6.7) we have\ndet F j,i (z, x)\nz\n(\u22121)i+j\nQ\n,\nFei,j (z, x) =\nfp\nz \u2212 zk (x) t6=k (z \u2212 zt (x))\n\n(6.9)\n\nfor i, j \u2208 [0 : r \u2212 1]. The factor z \u2212 zk (x) in the denominator of (6.9) shows that Fei,j (z, x) can\nhave a simple pole at z = zk (x). Widom [30, Sec. 6] observed that the matrix with the residues,\n\u0010\n\u0011r\u22121\nResz=zk (x) Fei,j (z, x)\n,\n(6.10)\ni,j=0\n\nis a rank-one matrix.\nNow we can finish the proof of the lemma. With the contour \u03c3 as in the statement of\nLemma 6.1, we find from (6.8) and the residue theorem that\n\u0012\n\u0013\nZ\n\u0011r\u22121\ne T\n1\ndz\n1 \u0010\n0 R\nResz=zk (x) Fei,j (z, x)\n=\u2212\n.\nFe (z, x)\n\u2212\n0 0\n2\u03c0i \u03c3\nz\nzk (x)\ni,j=0\nSince (6.10) is a rank-one matrix, simple linear algebra then shows that\n\u0013\n\u0012\nZ\n1\n1\ndz\ne\nResz=zk (x) Fe0,r\u22121 (z, x).\n=\u2212\nF (z, x)\ndet\n2\u03c0i \u03c3\nz\nzk (x)\nUsing (6.9), we conclude that\n\u0013\n\u0012\nZ\n(\u22121)r det F r\u22121,0 (zk (x), x)\n1\ndz\nQ\n,\n=\ndet\nFe (z, x)\n2\u03c0i \u03c3\nz\nfp\nj6=k (zk (x) \u2212 zj (x))\n\nComparing this with (6.5), we obtain the desired formula (6.6).\n35\n\n\fProof of Theorem 2.14. For ease of reference in the next section, we\ncase of a two-diagonal Hessenberg matrix (2.6). It will be clear that\nfor a general Hessenberg matrix (2.12). From (2.8) we have\n\uf8eb\n0 . . . 0 arn\u22121\u2212p . . .\n\u2212x\n1\n\uf8ec ..\n..\n.\n.\n..\n..\n..\n\uf8ec .\n.\n.\n\uf8ec\n\uf8ec 0\n0\na\n.\n.\n.\n\u2212x\n1\nrn\u22121\n\uf8ec\n\uf8ec .\n.\n.\n.\n..\n..\n.. ...\n\uf8ed ..\n0 ... 0\narn+r\u22122\u2212p . . . \u2212x 1\n\nwill give the proof for the\nthe same proof also works\n\uf8f6\uf8eb\n\uf8f7\uf8ec\n\uf8f7\uf8ec\n\uf8f7\uf8ec\n\uf8f7\uf8ec\n\uf8f7\uf8ec\n\uf8f7\uf8ec\n\uf8f8\uf8ed\n\nQrn\u2212r (x)\n..\n.\nQrn\u22121 (x)\n..\n.\nQrn+r\u22121 (x)\n\n\uf8f6\n\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7 = 0,\n\uf8f7\n\uf8f7\n\uf8f8\n\n(6.11)\nwhere the matrix multiplying the column vector, which we call M (x), is of size r \u00d7 2r. Let us\ndenote by Bn (x) and Cn (x) the matrices formed by the first r columns and last r columns of\nM (x), respectively, i.e.\n\uf8eb\n\uf8f6\n1\n\uf8ec\n\uf8f7\n..\n\uf8eb\n\uf8f6\n\uf8ec \u2212x\n\uf8f7\n.\narn\u2212p\u22121\n\u2212x\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\n.\n.\n\uf8ec\n\uf8f7\n.\n.\n.\n\uf8ec\n\uf8f7\n.\n.\n..\n\uf8ec\n\uf8f7\n\uf8f7,\nBn (x) = \uf8ec 0\n\uf8f7 , Cn (x) = \uf8ec\n\uf8ec\n\uf8f7\n..\n..\n\uf8ed\narn\u22121 \uf8f8\n\uf8ec arn\n\uf8f7\n.\n.\n\uf8ec\n\uf8f7\n0\n0\n\uf8ec\n\uf8f7\n.\n.\n.\n..\n..\n..\n\uf8ed\n\uf8f8\narn+r\u2212p\u22122\n\u2212x 1\n(6.12)\nwhere 0 denotes zero blocks of appropriate sizes, such that the last r \u2212 p \u2212 1 rows and the first\nr \u2212 p \u2212 1 columns of Bn (x) are zero. Here we are assuming that r \u2265 p + 1; the case r \u2264 p will\nbe discussed in Remark 6.4. Using the vectorial notation\nT\n\nQn (x) := (Qrn (x), . . . , Qrn+r\u22121 (x)) ,\n\n(6.13)\n\nwe then write the recurrence (6.11) as\nQn (x) = An (x)Qn\u22121 (x),\n\nwith An (x) := \u2212Cn\u22121 (x)Bn (x),\n\n(6.14)\n\nfor n \u2265 1. Now the periodicity assumption arn+j \u2261 bj implies that Bn (x) =: B(x), Cn (x) =:\nC(x) and An (x) =: A(x) are all independent of n. By repeatedly using (6.14), this yields\nQn (x) = A(x)n Q0 (x).\n\n(6.15)\n\nAssume that \u03bb is a non-zero eigenvalue of A(x). Then det(B(x) + \u03bbC(x)) = 0. But now\n\uf8eb\n\uf8f6\n\u03bb\nbr\u2212p\u22121\n\u2212x\n\uf8ec\n\uf8f7\n.\n..\n\uf8ec\u2212\u03bbx . .\n\uf8f7\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\n.\n.\n..\n..\n\uf8ec\nbr\u22121 \uf8f7\n\uf8f7.\nB + \u03bbC = \uf8ec\n\uf8ec\n\uf8f7\n..\n..\n\uf8ec \u03bbb0\n\uf8f7\n.\n.\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7\n.\n.\n.\n..\n..\n..\n\uf8ed\n\uf8f8\n\u03bbbr\u2212p\u22122\n\u2212\u03bbx\n\u03bb\n\nIf we perform the following operations to B(x) + \u03bbC(x): divide rows 2 to r by \u03bb, move row\n1 to the bottom and move rows 2 to r one level up, the resulting matrix is exactly F (1/\u03bb, x).\n36\n\n\fTherefore det F (1/\u03bb, x) = 0 and \u03bb = 1/zk (x) for some k \u2208 [0 : p]. In conclusion, the non-zero\neigenvalues of A(x) are given by 1/zk (x), k \u2208 [0 : p]. Since the first r \u2212 p \u2212 1 columns of A(x)\nare zero, 0 is also an eigenvalue of A(x), with multiplicity r \u2212 p \u2212 1.\nThe eigenspace of A(x) associated with the eigenvalue 1/zk (x) is one-dimensional and coincides with the nullspace of F (zk (x), x). By Cramer's rule it is easy to see that this subspace is\nspanned by the vector\n\u0001T\nvk (x) = det F r\u22121,0 (zk (x), x), \u2212 det F r\u22121,1 (zk (x), x), . . . , (\u22121)r\u22121 det F r\u22121,r\u22121 (zk (x), x) ,\n(6.16)\nfor any k \u2208 [0 : p], whenever the vector (6.16) is nonzero.\nLet us show that the first component of vk (x) is zero for only finitely many x. Let R be\nthe compact Riemann surface associated to the algebraic equation f (z, x) = 0 whose roots are\nthe functions zk (x). The collection of functions det F r\u22121,0 (zk (x), x), k \u2208 [0 : p], can be seen as\na single meromorphic function defined on R. (It has poles at infinity, see also [29]). Now [7,\nLemma 5.5] (see also [7, Lemma 5.6]) shows that R is connected. Hence the above meromorphic\nfunction cannot be identically zero since this would imply by (6.4) and (6.6) that Qrn \u2261 0, clearly\ncontradictory. Hence, each function det F r\u22121,0 (zk (x), x) has only finitely many zeros in C.\nNow define the matrices\nD(x) := diag(z0 (x)\u22121 , z1 (x)\u22121 , . . . , zp (x)\u22121 , 0, . . . , 0)r\u00d7r ,\nV (x) := (v0 (x), v1 (x), . . . , vp (x), e1 , . . . , er\u2212p\u22121 )r\u00d7r ,\nwhere ei denotes the standard column unit vector of index i. Then A(x) = V (x)D(x)V \u22121 (x),\nand so (6.15) gives\nQn (x) = V (x)D(x)n V \u22121 (x)Q0 (x).\n(6.17)\nWe already know the expression of Qrn , see (6.4) and (6.6). This allows us to find that the\nfirst p + 1 components of the vector V \u22121 (x)Q0 (x) are\n1\n1\n(\u22121)r\n(\u22121)r\nQ\nQ\nz0 (x)\u22121 , . . . ,\nzp (x)\u22121 .\nfp\nf\n(z\n(x)\n\u2212\nz\n(x))\n(z\n(x)\n\u2212\nz\n(x))\np\ni\ni\ni6=0 0\ni6=p p\n\nFrom this observation and (6.17), the desired formula (2.25) follows immediately.\nWe have actually shown that (2.25) is valid for all points x \u2208 C satisfying two conditions,\nnamely that the roots zk (x), k \u2208 [0 : p] are pairwise distinct, and the vectors vk (x), k \u2208 [0 : p],\nare all nonzero. The collection of points in C for which the first condition holds but the second\nfails is finite, as we have already seen. By continuity it is clear that formula (2.25) is also valid\nfor the exceptional points in this finite set.\nWith (2.25) at our disposal, we can prove as before that the functions det F r\u22121,j (zk (x), x)\nare zero for only a finite set of x \u2208 C. Finally, to see that the same holds for each function\ndet F i,j (zk (x), x), apply formula (2.25) for the monic polynomials associated to the cyclically\npermuted symbol Z \u2212i\u22121 F (z, x)Z i+1 .\nRemark 6.3. Let x \u2208 C be such that the values zk (x), k \u2208 [0 : p], are pairwise distinct. We\nalready observed that there are at most finitely many such x with the property that the vector\n(6.16) is zero. For such x, vk (x) will always denote in the next section an eigenvector of A(x)\nassociated with the eigenvalue 1/zk (x).\nRemark 6.4. To obtain (6.14) we assumed that r \u2265 p + 1. If r \u2264 p we proceed as follows. Let\nm \u2208 N be large enough so that r\u0303 := mr \u2265 p + 1. The matrix H, which is periodic of period r, can\nalso be viewed as a periodic matrix of period r\u0303. Let Fe(z, x) be the associated symbol. Linear\n37\n\n\falgebra shows that the roots zek (x) of det Fe(z, x) = 0 are given by zek (x) := zk (x)m , k \u2208 [0 : p].\nek (x) such that Fe (e\nMoreover, the null space vector v\nzk (x), x)e\nvk (x) = 0 can be constructed as\nek of length r\u0303 by\nfollows. With vk denoting the vector of length r in (6.16), we define the vector v\nek (x) = vk (x)T , zk (x)\u22121 vk (x)T , . . . , zk (x)\u2212m+1 vk (x)T\nv\n\n\u0001T\n\n.\n\n(6.18)\n\nWith this vector (6.18) playing the role that was played before by vk (x), the above proof goes\nthrough in exactly the same way as before. This leads again to the same formula (2.25).\n\n7\n\nRatio and weak asymptotics of Riemann-Hilbert minors\n\n7.1\n\nGeneralized Poincar\u00e9 theorem\n\nThe following result is contained in [21], see also [27]. It is closely related to the theory of Krylov\nsubspaces and subspace iteration in numerical linear algebra.\nLemma 7.1. (Generalized Poincar\u00e9 theorem:) Assume that (An )\u221e\nn=1 , A are nonsingular matrices\nof size m \u00d7 m, m \u2208 N, and A = limn\u2192\u221e An . Suppose that A is diagonalizable with eigenvalues\n{\u03bbi }m\ni=1 satisfying\n|\u03bb1 | > |\u03bb2 | > * * * > |\u03bbm | > 0.\nLet v1 , . . . , vm be eigenvectors associated to the eigenvalues \u03bb1 , . . . , \u03bbm , respectively. Let (un )\u221e\nn=0\nbe a sequence of column vectors with u0 6= 0, generated by the recurrence\nun = An un\u22121 ,\n\nn \u2265 1.\n\nThen there exists a sequence of complex numbers (cn )n such that cn un \u2192 vj , for some j \u2208 [1 : m].\nWe need a multi-column version of Lemma 7.1.\nLemma 7.2. Under the same assumptions of Lemma 7.1, let (Un )\u221e\nn=0 be a sequence of matrices\nof size m \u00d7 l, l \u2208 [1 : m], with U0 having linearly independent columns, such that\nUn = An Un\u22121 ,\n\nn \u2265 1.\n\nThen there exists a sequence (Cn )\u221e\nn=0 of invertible, upper triangular matrices of size l \u00d7 l such\nthat\nlim Un Cn = (vj1 , vj2 , . . . , vjl ),\nn\u2192\u221e\n\nthe matrix with columns vj1 , . . . , vjl , where j1 , . . . , jl are l distinct indices in [1 : m]. Here the\nlimit is defined entrywise.\nProof. We prove this lemma by induction on l. For l = 1 it reduces to Lemma 7.1. Let us assume\nas induction hypothesis that the result holds for the index l \u2212 1. Thus there exists a sequence of\nupper triangular, invertible matrices Cn of size l \u2212 1 such that, if we write\n(l\u22121)\nMn := (u(1)\n) Cn ,\nn , . . . , un\n\n(7.1)\n\n(i)\n\nwith un denoting the ith column of Un , then\nlim Mn = (vj1 , vj2 , . . . , vjl\u22121 ),\n\nn\u2192\u221e\n\nwhere j1 , . . . , jl\u22121 are distinct indices in [1 : m].\n38\n\n(7.2)\n\n\fFor n large enough, there exists a unique column vector dn such that the vector\nm\nwn := u(l)\nn + M n dn \u2208 C\n\n(7.3)\n\ndoes not have a contribution from the vectors vj1 , vj2 , . . . , vjl\u22121 , i.e., if we write wn in terms of\nm\nthe basis {vi }m\ni=1 of C , then the coefficients multiplying vj1 , . . . , vjl\u22121 are zero. To see this,\nobserve that finding the coefficients of dn amounts to solve a non-homogeneous linear system\nwhose coefficient matrix tends to the identity matrix, thanks to (7.2). Observe that wn 6= 0\nfor all n, because otherwise we would have a linear dependency between the columns of Un and\ntherefore (by the recursion Un = An Un\u22121 with An nonsingular) between the columns of U0 ,\ncontrary to the assumptions of the lemma.\nFrom (7.1), (7.3) and the recursion Un = An Un\u22121 we have\nAn wn\u22121\n\n=\n\n(l\u22121)\n(1)\n) Cn\u22121 dn\u22121\nu(l)\nn + (un , . . . , un\n\n=\n=\n\n\u22121\nu(l)\nn + Mn Cn Cn\u22121 dn\u22121\n\u0001\nwn + Mn Cn\u22121 Cn\u22121 dn\u22121 \u2212 dn\n\n=: wn + Mn fn .\n\n(7.4)\n\nNote that for n sufficiently large, fn is the unique column vector for which An wn\u22121 \u2212Mn fn has no\ncontribution from the vectors vj1 , vj2 , . . . , vjl\u22121 . Equivalently, since the {vi }m\ni=1 are eigenvectors\nfor A, fn is the unique column vector for which (An \u2212 A)wn\u22121 \u2212 Mn fn has no contribution from\nthe vectors vj1 , vj2 , . . . , vjl\u22121 . This yields the estimate\n|fn | \u2264 c||An \u2212 A|| |wn\u22121 |\n\n(7.5)\n\nfor a suitable constant c and for all n sufficiently large, on account of (7.2). Here we write | * |\nfor the Euclidean norm of a vector and || * || for the induced matrix norm.\nDefine\nfn wH\nBn := An \u2212 Mn H n\u22121 ,\nwn\u22121 wn\u22121\nH\nwith wn\u22121\ndenoting the conjugate transpose of wn\u22121 . From (7.4) we get\n\nBn wn\u22121 = wn\nwhile (7.2), (7.5) and the fact that An \u2192 A imply that\n||Bn \u2212 An || \u2192 0,\n\nn \u2192 \u221e.\n\nWe can now apply Lemma 7.1 to the matrices (Bn )n and the vectors (wn )n . This yields a\nsequence of nonzero constants (cn )n such that cn wn \u2192 vjl for a certain index jl \u2208 [1 : m]. By\nthe very construction of wn we have that jl 6\u2208 {j1 , . . . , jl\u22121 }. The definition of the new sequence\nof upper triangular matrices of size l \u00d7 l is obvious.\n\n7.2\n\nRatio and weak asymptotics of Riemann-Hilbert minors\n\nWe will apply Lemma 7.2 to the polynomials Qn generated by the three-term recurrence (1.1),\nxQn (x) = Qn+1 (x) + an\u2212p Qn\u2212p (x),\n\nn \u2265 p.\n\n(7.6)\n\nWe will assume that the recurrence coefficients an are asymptotically periodic with period r \u2208 N,\nwhere we may assume without loss of generality that r \u2265 p + 1. The case r \u2264 p can be handled\nby enlarging the period and/or by using Remark 6.4.\n39\n\n\fWe write the recurrence relation in matrix-vector form as (6.14), recalling (6.12)\u2013(6.13). Since\nthe recurrence coefficients an are asymptotically periodic with period r, we have\nlim (An (x), Bn (x), Cn (x)) = (A(x), B(x), C(x)),\n\nn\u2192\u221e\n\n(7.7)\n\nwith A(x) := \u2212C(x)\u22121 B(x) and B(x), C(x) as in (6.12) but with arn+j replaced by bj , j \u2208 [0 :\nr \u2212 1], and where the limits of the matrices are taken entrywise.\nIn the proof of Theorem 2.14 we observed that the matrix A(x) is closely related to the block\nToeplitz symbol F (z, x). More precisely, we showed that the non-zero eigenvalues of A(x) are the\ninverted roots 1/zk (x), k \u2208 [0 : p] and the corresponding eigenvectors vk (x) are given by (6.16)\n(see also Remark 6.3). In addition the matrix A(x) has zero as an eigenvalue of multiplicity\nr \u2212 p \u2212 1.\n(k)\nThe second kind functions \u03a8n are defined in (1.5). They satisfy the same recurrence relation\n(7.6) for all n \u2265 p. In analogy with (6.13) we set\n\u0010\n\u0011T\n(k)\n(k)\n\u03a8(k)\n(x)\n:=\n\u03a8\n(x),\n.\n.\n.\n,\n\u03a8\n(x)\nn\nrn\nrn+r\u22121\n\n(7.8)\n\nand we define the RH-type matrix\n\n\u0010\nUn (x) := Qn (x)\n\n(1)\n\n\u03a8n (x)\n\nThen the recurrence (6.14) extends to\n\nUn (x) = An (x)Un\u22121 (x),\n\n\u0011\n(p)\n. . . \u03a8n (x) .\n\n(7.9)\n\nn \u2265 1.\n\n(7.10)\n\nNote the similarity with Lemma 7.2. Hence the next result should not come as a surprise.\nS\nProposition 7.3. Let Un (x) be the RH type matrix in (7.9). For any fixed x \u2208 C \\ j \u0393j , there\nexists a sequence of invertible upper triangular matrices Cn (x) of size p + 1 such that\n\u0012\n\u0013\n\u0013\n\u0012\n...\nvjp (x)\nvj0 (x)\nUn\u22121 (x)\nlim\n(7.11)\nCn (x) =\nzj\u22121\n(x)vj0 (x) . . . zj\u22121\n(x)vjp (x)\nUn (x)\nn\u2192\u221e\n0\np\nwhere (j0 , . . . , jp ) is a permutation of [0 : p] (depending on x), and with vk (x) defined in (6.16),\nsee also Remark 6.3.\nProof. Throughout the proof we will drop the x-dependence for convenience. We want to apply\nthe generalized Poincar\u00e9 theorem (Lemma 7.2) to the recurrence (7.10). Recall that only the\nlast p + 1 columns of An are nonzero. So the matrix An could have zero as an eigenvalue (of\nmultiplicity r \u2212 p \u2212 1), contrary to the assumptions of Lemma 7.2. To resolve this issue, we\npartition\n!\n\u0012 \u0013\nen\nej\nv\nU\n,\nvj =:\nUn =: b ,\nbj\nv\nUn\nen and U\nbn having r \u2212 p \u2212 1 and p + 1 rows respectively, and similarly for v\nej and v\nbj . We\nwith U\nalso partition\n!\n!\ne\nen\n0 A\n0 A\nA =:\nAn =:\nb ,\nbn ,\n0 A\n0 A\nbn and A\nb square matrices of size p + 1.\nwith A\n\n40\n\n\fRecall that the nonzero eigenvalues of A are zj\u22121 , j \u2208 [0 : p], and the corresponding eigenvectors are vj . With the above partitions, this yields\n!\u0012 \u0013\ne\n\u2212zj\u22121 I\nA\nej\nv\n\u22121\n,\n(7.12)\n0 = (A \u2212 zj I)vj =\nb \u2212 z \u22121 I\nb\nv\n0\nA\nj\nj\n\nb is diagonalizable with z \u22121 as eigenvalues, j \u2208 [0 : p],\nfor all j \u2208 [0 : p]. In particular, the matrix A\nj\nbj (note also that (7.12) implies v\nbj 6= 0).\nand the corresponding eigenvectors are v\nThe recursion (7.10) becomes\n!\n!\n!\nen\nen\u22121\nen\n0 A\nU\nU\n(7.13)\nbn\u22121 .\nbn\nbn = 0 A\nU\nU\nIn particular,\n\nbn\u22121 ,\nbn = A\nbn U\nn \u2265 1.\n(7.14)\nU\nb\nb\nb\nWe can now apply Lemma 7.2 to the matrices (An )n and (Un )n . Observe that the matrices Un are\nbn ); in fact, det U\nbn (x) is a nonzero constant (independent\nall nonsingular (and so the matrices A\nof x), as it follows from Prop. 2.6. Lemma 7.2 yields a sequence of invertible upper triangular\nmatrices Cn such that\n\u0001\nbn\u22121 Cn \u2192 v\nbjp\nbj0 . . . v\nU\n(7.15)\nas n \u2192 \u221e, for a certain permutation (j0 , . . . , jp ) of [0 : p]. (Note that we write Cn instead of\nCn\u22121 .) Applying (7.14) and (7.15) we then get\n\u0011\n\u0010\n\u22121\nbn\u22121 Cn \u2192 zj\u22121 v\nbn Cn = A\nbn U\nb\nb\nv\n.\n.\n.\nz\n,\nU\nj\nj\np\n0\njp\n0\nbn \u2192 A\nb and v\nb for the eigenvalue z \u22121 .\nbj is an eigenvector of A\nas n \u2192 \u221e, where we used that A\nj\nOn the other hand, from the first block row of (7.13) we have\n\u0011\n\u0001 \u0010\nbn\u22121 Cn \u2192 A\ne v\nen Cn = A\nen U\nej0 . . . zj\u22121\nejp ,\nv\nv\nbjp = zj\u22121\nbj0 . . . v\nU\n0\np\nas n \u2192 \u221e, where the equality follows from the first block row of (7.12). Finally,\nbn\u22122 Cn = A\nen\u22121 (A\nbn\u22121 )\u22121 U\nbn\u22121 Cn \u2192 v\nen\u22121 Cn = A\nen\u22121 U\nej0\nU\n\nCombining the above limits, the proposition is proved.\n\n\u0001\nejp .\n... v\n\nIn principle, the indices j0 , . . . , jp in Prop. 7.3 could depend on x. We will see further that\nthis is not the case; in fact we have j0 = 0, j1 = 1, and so on.\nFix k \u2208 [0 : p]. Taking determinants of suitable (k + 1) \u00d7 (k + 1) minors of (7.11) and using\nthe fact that Cn is upper triangular, we find that\n\u0001\n(7.16)\nlim Bk,rn\u22121 (x) cn (x) = (\u22121)k(k+1)/2 det vj\u2032 0 (x), . . . , vj\u2032 k (x) ,\nn\u2192\u221e\n\u0001\n\u0001\n(7.17)\ndet vj\u2032 0 (x), . . . , vj\u2032 k (x) ,\n. . . zj\u22121\nlim Bk,rn+r\u22121 (x) cn (x) = (\u22121)k(k+1)/2 zj\u22121\n0\nk\nn\u2192\u221e\n\nS\nfor any fixed x \u2208 C \\ j \u0393j , where cn denotes the determinant of the principal (k + 1) \u00d7 (k + 1)\nsubmatrix of Cn , and where the vector vj\u2032 consists of the last k + 1 entries of vj . For convenience\nwe introduce the following notation:\n(\nS+ , for k even, k \u2208 [0 : p],\nSk :=\n(7.18)\nS\u2212 , for k odd, k \u2208 [0 : p].\n41\n\n\fS\nLemma 7.4. Let k \u2208 [0 : p], and let x be a fixed point in C \\ ( j \u0393j \u222a Sk ). Then in (7.16)\u2013(7.17)\nwe have\n\u0001\n(7.19)\ndet vj\u2032 0 (x), . . . , vj\u2032 k (x) 6= 0.\n\nbj consist of the last p + 1 rows of vj , as in the proof of Prop. 7.3. Recall that the\nProof. Let v\ncolumns of the matrix\nbjk (x))\n(7.20)\n(b\nvj0 (x), . . . , v\n\nare linearly independent, since they are eigenvectors corresponding to distinct eigenvalues of the\nb (see the proof of Prop. 7.3). In particular, there exist k + 1 row indices such that the\nmatrix A\nminor obtained by selecting these rows in (7.20) is nonzero. Denoting the value of this minor\nwith \u03ba(x) 6= 0 and taking the determinant of the corresponding (k + 1) \u00d7 (k + 1) minor in (7.11),\nwe get\nlim B (n0 ,n1 ,...,nk ) (x) cn (x) = \u00b1\u03ba(x) 6= 0,\nn\u2192\u221e\n\nfor suitable indices ni with rn \u2212 p \u2212 1 \u2264 n0 < n1 < . . . < nk \u2264 rn \u2212 1, with again cn the\ndeterminant of the principal (k + 1) \u00d7 (k + 1) submatrix of Cn . Comparing this to (7.16), we get\n\u0001\nlim Bk,rn\u22121 (x)/B (n0 ,n1 ,...,nk ) (x) = \u00b1 det vj\u2032 0 (x), . . . , vj\u2032 k (x) /\u03ba(x).\nn\u2192\u221e\n\nNow if (7.19) fails, then this limit would be zero, thereby contradicting Lemma 5.1 (see also\n(3.4)).\nRemark 7.5. The above proof shows that any (k + 1) \u00d7 (k + 1) minor of\n\u0012\n\u0013\n...\nvjk (x)\nvj0 (x)\n,\nzj\u22121\n(x)vj0 (x) . . . zj\u22121\n(x)vjk (x)\n0\nk\n\nobtained by selecting k + 1 rows with the\nS difference between the smallest and largest row index\nnot exceeding p, is nonzero if x \u2208 C \\ ( j \u0393j \u222a Sk ). Also recall Remark 6.3.\nBy Lemma 7.4, we can take the ratio of (7.16) and (7.17) and get the pointwise limit\n[\n\u0001\n\u0393j \u222a Sk .\nx\u2208 C\\\nlim Bk,rn\u22121 (x)/Bk,rn+r\u22121 (x) = zj0 (x) . . . zjk (x),\nn\u2192\u221e\n\nj\n\nSimilar arguments can be applied for the other residue classes modulo r, showing that\n[\n\u0001\n\u0393j \u222a Sk .\nx \u2208C\\\nlim Bk,n (x)/Bk,n+r (x) = zj0 (x) . . . zjk (x),\nn\u2192\u221e\n\n(7.21)\n\nj\n\nProposition 7.6. In Prop. 7.3 we have for any fixed x \u2208 C \\ (S+ \u222a S\u2212 ),\n(j0 , . . . , jp ) = (0, . . . , p).\n\n(7.22)\n\nProp. 7.6 will be proved in Section 7.3. In the latter section we also prove Theorem 2.2, in\nparticular we show that \u0393k \u2282 Sk for all k \u2208 [0 : p]. Note that we did not use Theorem 2.2 so far.\nLemma 5.1 and (7.21)\u2013(7.22) imply that, uniformly on compact subsets of C \\ Sk ,\nlim Bk,n (x)/Bk,n+r (x) = z0 (x) . . . zk (x).\n\nn\u2192\u221e\n\nWe are now ready for the\n\n42\n\n(7.23)\n\n\fProof of Theorem 2.1. For any measure \u03bc in C denote its logarithmic potential U \u03bc (x) as\nZ\nU \u03bc (x) = \u2212 log |x \u2212 s| d\u03bc(s).\n(7.24)\nWe will prove formula (2.2) for each sequence \u03bck,n with n of the form rm + l, l \u2208 [0 : r \u2212 1] fixed.\nDenote with \u03ban the leading coefficient of the polynomial Bk,n (x). We have uniformly for x in\ncompact subsets of C \\ Sk that\n\u0013\n\u0012\n1\n1\n\u03bck,n\nlog |Bk,n (x)|\nlim U\n(x) \u2212 log |\u03ban | = \u2212 lim\nn\u2192\u221e n\nn\u2192\u221e\nn\n\nk\nm\nY\n1 X\n1\n|zj (x)| = U \u03bck (x) + c, (7.25)\nlog |Bk,rj+l (x)/Bk,r(j\u22121)+l (x)| = log\nm\u2192\u221e rm + l\nr\nj=0\nj=1\n\n= \u2212 lim\n\nwith c a constant independent of x, and \u03bck the measure in (1.19). Here the first equality is\nobvious from the definitions (7.24) and (2.1), the second one follows by telescopic cancelation,\nthe third one follows by (7.23) and the fourth one by [7, Prop. 5.10]. It is easy to see that\nlog |\u03ban |/n is bounded from below as a function of n, due to (5.1) and Prop. 5.5.\nLet C0 (Sk ) denote the space of continuous functions on the star Sk that vanish at infinity.\nSince k\u03bck,n k \u2264 (p \u2212 k)/p for all n (cf. Lemma 1.2), it follows from the Banach-Alaoglu theorem\nthat we can extract a subsequence from \u03bck,n that converges in the weak-star topology to a finite\nmeasure \u03bd supported on Sk . Let x0 \u2208 C \\ Sk be a fixed point. From the weak-star convergence\nand (7.25) we deduce that for every x \u2208 C \\ Sk ,\nZ\nwhere log\n\nQk\n\nlog\n\nx0 \u2212 s\nx\u2212s\n\nj=0 zj (x)\n\nd\u03bd(s) = U \u03bck (x) \u2212 U \u03bck (x0 ) =\n\nk\n\u0011\n\u0010\nY\n1\nzj (x) + e\nc,\nRe log\nr\nj=0\n\nis a holomorphic branch of the logarithm of\n\nconstant. Note that \u03c6(s) := log\nWe claim that\n\nx0 \u2212s\nx\u2212s\n\nZ\n\nQk\n\nj=0 zj (x)\n\n(7.26)\n\nand e\nc is some\n\n\u2208 C0 (Sk ), so the weak-star convergence indeed applies.\nlog(1 + |s|) d\u03bd(s) < \u221e.\n\n(7.27)\n\nSk\n\nThis will be justified at the end of the proof and now we complete the argument as follows.\nFrom (7.27) we obtain that U \u03bd is well-defined and superharmonic in C, and in particular we can\nreplace the first integral in (7.26) by U \u03bd (x) \u2212 U \u03bd (x0 ). Note also that the last relation in (7.25),\nwhich is in fact valid for all x \u2208 C, implies that U \u03bck is continuous everywhere in the complex\nplane. This in turn implies, using (7.26) and the superharmonicity of U \u03bd , that U \u03bd is bounded\non every compact segment of Sk . Now we are in a position to apply Theorem II.1.4 from [25],\nwhich gives \u03bck = \u03bd.\nNow we justify (7.27). This is equivalent to say that U \u03bd (x) > \u2212\u221e for any fixed x \u2208 C \\ Sk .\nIt is clear that we can construct a non-increasing sequence of functions (km (y))m\u2208N in C0 (Sk )\nsatisfying km (y) = log (1/|x \u2212 y|) whenever log(1/|x \u2212 y|) \u2265 \u2212m and km (y) \u2265 \u2212m for all y \u2208 Sk .\nApplying a standard monotone convergence theorem argument to this sequence km together with\n(7.25) and the weak-star convergence to \u03bd, it is easy to deduce that U \u03bd (x) \u2265 U \u03bck (x) + c, for\nsome other constant c.\nSummarizing, we obtain that (2.2) is valid for every \u03c6 \u2208 C0 (Sk ). Since k\u03bck,n k \u2264 (p \u2212 k)/p\nand k\u03bck k = (p \u2212 k)/p, the convergence in the weak-star topology of \u03bck,n to \u03bck implies that the\nsequence \u03bck,n is tight. This implies again by a standard argument that (2.2) is also valid for\nbounded continuous functions on Sk .\n43\n\n\fRemark 7.7. Due to the interlacing properties described in Theorem 4.6, it is easy to see that\nthe conclusion of Theorem 2.1 remains valid for the zeros of general Riemann-Hilbert minors\nP (n+i0 ,n+i1 ,...,n+ik ) , with ij \u2208 Z, j \u2208 [0 : k], a fixed set of indices satisfying (5.2).\nFor later use, we state the next lemma.\nLemma 7.8. Fix 0 \u2264 k < l \u2264 p. Uniformly for x in compact subsets of C \\ Sk , we have\nf \u03030 (z0 (x), x)\n..\nBk,l,rn (x)\n.\nlim\n=\nn\u2192\u221e Bk,rn (x)\nf \u0303k\u22121 (z0 (x), x)\nf \u0303l (z0 (x), x)\n\nf \u03030 (zk (x), x)\nf \u03030 (z0 (x), x)\n..\n..\n.\n.\n/\n. . . f \u0303k\u22121 (zk (x), x)\nf \u0303k\u22121 (z0 (x), x)\n...\nf \u0303l (zk (x), x)\nf \u0303k (z0 (x), x)\n\nf \u03030 (zk (x), x)\n..\n.\n,\n. . . f \u0303k\u22121 (zk (x), x)\n...\nf \u0303k (zk (x), x)\n(7.28)\nwhere the functions f \u0303j (z, x) are defined in (8.16), and Bk,l,n (x) := B (n\u2212l,n\u2212k+1,...,n\u22121,n) (x).\nDenoting with Aek the set of x \u2208 C for which the denominator in (7.28) is zero, then the set Aek\nis finite. For any x \u2208 Aek \\ Sk the right hand side of (7.28) has a removable pole at x.\n...\n\n...\n\nProof. Remark 7.5 shows that the determinants in the numerator and denominator in (7.28) are\nboth nonzero if x \u2208 C \\ (S+ \u222a S\u2212 ). For any fixed such x, we obtain (7.28) by taking determinants\nof suitable submatrices in Prop. 7.3 (with ji = i for all i). Lemma 5.1 shows the convergence\nholds uniformly on compact subsets of C \\ Sk .\n\u0001\np+1\nFinally, let us prove that Aek is finite. Let R be the compact Riemann surface with (k+1)! k+1\nsheets which are labeled by the ordered (k + 1)-tuples (i0 , i1 , . . . , ik ) in [0 : p]. On the sheet\n(i0 , i1 , . . . , ik ) we cut away all the sets \u0393ij and \u0393ij \u22121 , j \u2208 [0 : k]. If we cross such a cut, then we\nmove to the sheet labeled by (\u01290 , \u01291 , . . . , \u0129k ) where zeij is the analytic continuation of zij through\nthe cut. Now in the denominator of (7.28) we can replace the role of z0 , . . . , zk by zi0 , . . . , zik .\nThe collection of all these functions yields a meromorphic function on R. Since we already know\nthat this function is not identically zero on the sheet (0, 1, . . . , k), it can indeed have only finitely\nmany zeros on that sheet. (Note that R can be disconnected; in that case we restrict ourselves\nto the connected component(s) involving the sheet (0, 1, . . . , k)).\n\n7.3\n\nProofs of Proposition 7.6 and Theorem 2.2\n\nIn this section we prove Prop. 7.6 and Theorem 2.2. Note that we did not use Theorem 2.2\nprior to the statement of Prop. 7.6. Moreover, it is a general fact [7, Prop. 1.1] that each set \u0393k\nassociated to a Hessenberg matrix H consists of a finite union of analytic arcs.\nFor each k \u2208 [0 : p],\nS the sequence (Bk,n (x)/Bk,n+r (x))n for n tending to infinity converges\npointwise for x \u2208 C \\ ( j \u0393j \u222a Sk ), by (7.21), and it is a normal family in C \\ Sk by Lemma 5.1,\nrecall the definition of Sk in (7.18). Therefore, the convergence in (7.21) is in fact uniform on\ncompact subsets of C \\ Sk and the limit function zj0 (x) . . . zjk (x) is analytic there. Applying this\nobservation subsequently for k \u2208 [0 : p], we see that for each x \u2208 C, there exists a permutation\n(z\u0303j (x))pj=0 of the set (zj (x))pj=0 so that z\u03030 is analytic in C \\ S+ , z\u03030 z\u03031 is analytic in C \\ S\u2212 , z\u03030 z\u03031 z\u03032\nis analytic in C \\ S+ , z\u03030 z\u03031 z\u03032 z\u03033 is analytic in C \\ S\u2212 , and so on (alternatingly with S+ and S\u2212 ).\nIn fact z\u0303i := zji , i \u2208 [0 : p]. We also deduce from (1.16) that as x \u2192 \u221e, z\u03030 (x) = x\u2212r + O(x\u2212r\u22121 )\nand z\u0303j (x) = O(xr/p ), j \u2208 [1 : p], since it is clear that for x sufficiently large, z\u03030 (x) = z0 (x).\n7.3.1\n\nProofs of Prop. 7.6 and Theorem 2.2(a)\n\nThe proof will proceed in a very similar way to the one in [8, Section 4]. For convenience, we\nwill list the main highlights of the proof but we will sometimes refer to [8] for the details. We\nwill assume without loss of generality that r is a multiple of p + 1, see also Remark 7.10 below.\n44\n\n\fWe already observed that for each k \u2208 [0 : p],\nlim Bk,n (x)/Bk,n+r (x) = \u00b1 lim Pk,n (x)/Pk,n+r (x) = z\u03030 (x) . . . z\u0303k (x),\n\nn\u2192\u221e\n\nn\u2192\u221e\n\nx \u2208 C \\ Sk . (7.29)\n\nIt follows from (7.29) and Theorem 2.7(a) that the functions z\u0303i satisfy the symmetry property\nz\u0303i (\u03c9x) = z\u0303i (x), where \u03c9 = exp(2\u03c0i/(p + 1)); recall that r is a multiple of p + 1. In accordance to\nthis symmetry property, we define the functions\n\u1ef9k (x) = z\u0303k (x1/(p+1) ),\n\nk \u2208 [0 : p],\n\nwhere we take the principal branch of x1/(p+1) . (By the symmetry property, the choice of the\nbranch is irrelevant.) Note that \u1ef9k (x) is analytic in C \\ R.\nLet us introduce the notation\nRk := (\u22121)k R+ ,\n\nk \u2208 [0 : p].\n\nWe now define a measure sk on Rk with density\n\u0012 \u2032\n\u0013\n\u2032\n(x) \u1ef9k,\u2212\n(x)\n1 p + 1 \u1ef9k,+\ndsk (x) =\n\u2212\ndx,\n2\u03c0i r\n\u1ef9k,+ (x) \u1ef9k,\u2212 (x)\n\nx \u2208 Rk ,\n\n(7.30)\n\nk \u2208 [0 : p \u2212 1], where the prime denotes the derivative with respect to x, and where the + and \u2212\nsubscripts stand for the boundary values obtained from the upper or lower half of the complex\nplane, respectively. Note that the measure (7.30) is well-defined except for finitely many x, and\nits density is integrable near each endpoint of its support [11]. We claim that sk is a real-valued\n(possibly signed) measure on Rk with total mass\nZ\np\u2212k\n,\nk \u2208 [0 : p \u2212 1].\n(7.31)\ndsk (x) =\nsk (Rk ) :=\np\nRk\nIndeed, since the polynomials Pk,n (2.9) have real coefficients, it follows from (7.29) that z\u0303i (x\u0304) =\nz\u0303i (x), where the bar denotes complex conjugation. This shows that sk is a real-valued measure.\nFor x \u2208 C \\ Rk , we have\nZ\n\nRk\n\nk\n\ndsk (t)\n1 p+1 X\n=\nx\u2212t\n2\u03c0i r j=0\n\nZ\n\nRk\n\n1\nx\u2212t\n\n\u0012\n\n\u2032\n\u2032\n\u1ef9j,+\n(t) \u1ef9j,\u2212\n(t)\n\u2212\n\u1ef9j,+ (t) \u1ef9j,\u2212 (t)\n\n\u0013\n\ndt = \u2212\n\nk\np + 1 X \u1ef9j\u2032 (x)\n,\nr j=0 \u1ef9j (x)\n\n(7.32)\n\nPk\u22121 \u2032\nQk\u22121\nwhere in the first equality we used the fact that j=0\n\u1ef9j (x)/\u1ef9j (x) = (log j=0\n\u1ef9j (x))\u2032 is analytic\nacross Rk , and the second equality follows by contour deformation and the residue theorem. From\nthe behavior of the functions \u1ef9j (x) near infinity we see that the right hand side of (7.32) behaves\n\u22121\n+ o(x\u22121 ) as x \u2192 \u221e. This implies (7.31).\nas p\u2212k\np x\nWe then obtain from (7.30)\u2013(7.31) that\n\u0013\n\u0012 \u2032\nZ\n\u1ef9k,+ (x)\np\u2212k\n1p+1\ndx =\n,\nk \u2208 [0 : p \u2212 1],\n(7.33)\nIm\n\u03c0 r\n\u1ef9k,+ (x)\np\nRk\nwith Im denoting the imaginary part of a complex number.\nAs in [8], we now turn to the construction of a second collection of auxiliary measures. The\nSp\u22121\nfunctions zk (x) are unambiguously defined in the complement of k=0 \u0393k , which is a finite union\nof analytic arcs. Consider the functions\nyk (x) := zk (x1/(p+1) ),\n45\n\nk \u2208 [0 : p],\n\n\fwhere we take the principal branch of x1/(p+1) . The \u00b1-boundary values of yk and yk\u2032 are welle k := \u0393p+1 . This allows us to introduce the measures\ndefined at almost every point x \u2208 \u0393\nk\nk\n\n1 p+1 X\nd\u03c3k (x) :=\n2\u03c0i r j=0\n\n\u0012\n\n\u2032\n\u2032\nyj,+\n(x) yj,\u2212\n(x)\n\u2212\nyj,+ (x) yj,\u2212 (x)\n\n\u0013\n\ndx,\n\nek.\nx\u2208\u0393\n\n(7.34)\n\nThe measure \u03c3k is closely related to the measure \u03bck in (1.19). In fact, for any Borel set B,\n\u03c3k (B) = \u03bck (h\u22121 (B))\n\n(7.35)\n\nwhere h is the map x 7\u2192 xp+1 . In particular, \u03c3k is a positive measure and\nek ) = p \u2212 k ,\n\u03c3k (\u0393\np\n\nk \u2208 [0 : p \u2212 1].\n\n(7.36)\n\nAlternatively, (7.36) could be proved directly by using the same argument as in (7.31).\nNow let us take a fixed open interval J \u2282 R that does not contain any intersection points\ne k , for every k. We also ask J not to contain\nor endpoints of the analytic arcs constituting \u0393\ne\nisolated intersection points of the sets \u0393k with the real axis. Thus there exists an open connected\ne k is either empty or equal to J, for any\nset U \u2282 C such that U \u2229 R = J and moreover U \u2229 \u0393\nk \u2208 [0 : p \u2212 1]. The boundary values yk,+ (x) for x \u2208 J are then uniquely defined and they vary\nanalytically with x.\nOn the interval J, there exist indices 0 \u2264 m1 < m2 < . . . < mL < p such that\n|y0,+ (x)| = . . . = |ym1 ,+ (x)| < |ym1 +1,+ (x)| = . . . = |ym2 ,+ (x)| < . . .\n< |ymL +1,+ (x)| = . . . = |yp,+ (x)|,\n\n(7.37)\n\nfor all x \u2208 J. We define m0 := \u22121 and mL+1 := p.\nWe will see later that mk+1 \u2212 mk \u2208 {1, 2} for all k, i.e., each \"cluster\" |ymk +1,+ (x)| = . . . =\n|ymk+1 ,+ (x)| in (7.37) can only have length 1 or 2. The Cauchy-Riemann equations imply [8]\n\u0013\n\u0012 \u2032\n\u0013\n\u0012 \u2032\nymk+1 ,+ (x)\nymk +1,+ (x)\n\u2265 . . . \u2265 Im\n,\nx \u2208 J, k \u2208 [0 : L],\n(7.38)\nIm\nymk +1,+ (x)\nymk+1 ,+ (x)\nand the numbers in (7.38) satisfy the pairing\n!\n\u0012 \u2032\n\u0013\n\u2032\nym\n(x)\nymk +j,+ (x)\nk+1 +1\u2212j,+\nIm\n= \u2212Im\n,\nymk +j,+ (x)\nymk+1 +1\u2212j,+ (x)\n\nj = 1, . . . , mk+1 \u2212 mk .\n\n(7.39)\n\nThe underlying reason for (7.39) is that for any x \u2208 R, the numbers yk,+ (x), k \u2208 [0 : p], are\neither real or they come in complex conjugate pairs. This is trivial if x > 0. If x < 0 it can be\nseen e.g. with the help of Lemma 1.3, taking into account that r is a multiple of p + 1.\nNow we get\np\u22121\nX\np\u2212k\np\nk=0\n\n\u0012 \u2032\n\u0013\nZ X\np\nyk,+ (x)\n1 p+1\ndx\n\u03c3k (R) \u2265\n\u2265\nIm\n2\u03c0 r\nyk,+ (x)\nR k=0\nk=0\n\u0013\n\u0012 \u2032\nZ X\np\n\u1ef9k,+ (x)\n1 p+1\n=\ndx\nIm\n2\u03c0 r\n\u1ef9k,+ (x)\nR k=0\n\u0013\n\u0012 \u2032\np\u22121\np\u22121 Z\nX\n\u1ef9k,+ (x)\np\u2212k\n1 p+1 X\ndx \u2265\n=\n,\nIm\n\u03c0 r\n\u1ef9k,+ (x)\np\nRk\np\u22121\nX\n\nk=0\n\n46\n\nk=0\n\n\fwhere the first relation uses (7.36) and the positivity of \u03c3k , the second relation follows exactly\nlike in [8, Sec. 4], the third one follows since the numbers \u1ef9k form a permutation of the yk , and\nthe \u0010fifth relation\n\u0011 is a consequence\n\u0010\n\u0011of (7.33). Finally, the fourth\n\u0010 relation\n\u0011 uses that\u0010 on R+ we\u0011have\n\u1ef9 \u2032\n\n\u2032\n\u1ef92k+1,+\n(x)\n\u1ef92k+1,+ (x)\n\n(x)\n\n= \u2212Im\nIm \u1ef92k,+\n2k,+ (x)\nR+ this follows since\n2k+1\nX\n\nIm\n\nj=2k\n\n\u0012\n\n\u2032\n\u1ef9j,+\n(x)\n\u1ef9j,+ (x)\n\n\u0013\n\nand on R\u2212 we have Im\n\n\u2032\n\u1ef92k,+\n(x)\n\u1ef92k,+ (x)\n\n\u0013\n2k+1 \u0012 \u2032\n\u2032\n(x)\n(x) \u1ef9j,\u2212\n1 X \u1ef9j,+\n=\n= 0,\n\u2212\n2i\n\u1ef9j,+ (x) \u1ef9j,\u2212 (x)\n\n= \u2212Im\n\n\u2032\n\u1ef92k\u22121,+\n(x)\n\u1ef92k\u22121,+ (x)\n\n; for\n\nx \u2208 R+ ,\n\nj=2k\n\ndue to the fact that (log ye2k ye2k+1 )\u2032 is analytic on R+ .\nFrom the above chain of inequalities we obtain:\nLemma 7.9.\n\n(a) We have\n\ne k \u2282 R,\n\u0393\n\nk \u2208 [0 : p \u2212 1].\n\n(7.40)\n\n(b) Clusters of length \u2265 3 in (7.37) cannot occur.\nThe proof is exactly as in [8].\nek \u2229 \u0393\ne k\u22121 contains at most finitely many points. We\nFrom Lemma 7.9(a)\u2013(b) we see that \u0393\n\u2032\ne k\u22121 , so in particular this holds on the interior\nalso have that (log y0 . . . yk\u22121 ) is analytic in C \\ \u0393\ne k . Then (7.34)\u2013(7.36) imply that\nof each interval of \u0393\n1 p+1\n\u03c0 r\n\nZ\n\nek\n\u0393\n\nIm\n\n\u0012\n\n\u2032\nyk,+\n(x)\nyk,+ (x)\n\n\u0013\n\nek ) = p \u2212 k ,\ndx = \u03c3k (\u0393\np\n\nk \u2208 [0 : p \u2212 1].\n\n(7.41)\n\ne k (see the proof of Lemma 7.9(a)). From the\nThe measure \u03c3k is non-trivial on each subarc of \u0393\npositivity of \u03c3k we also have\n\uf8f1\ne k ),\nx \u2208 int(\u0393\n\uf8f4 > 0,\n\u0012 \u2032\n\u0013\uf8f4\n\u0011\n\u0010 \u2032\nyk\u22121,+ (x)\nyk,+ (x) \uf8f2\ne k\u22121 ,\nx\u2208\u0393\n= \u2212Im yk\u22121,+ (x) \u2264 0,\nIm\n(7.42)\n\u0011\n\u0010\nyk,+ (x) \uf8f4\n\uf8f4\n\uf8f3 = 0,\nek \u222a \u0393\ne k\u22121 ,\nx \u2208R\\ \u0393\n\ne k ) denotes the interior of \u0393\ne k in the topology of R, where the first equality uses (7.39)\nwhere int(\u0393\nand Lemma 7.9(b).\nRecall that yek (x) is analytic for x \u2208 C \\ R. By Lemma 7.9(a) the same holds for the function\nyk (x). Thus for each fixed k \u2208 [0 : p] we have that yek (x) = yjk (x) for all x \u2208 C \\ R and for\na certain jk which is independent of x. From (7.41)\u2013(7.42) and (7.33) we now easily find by\ne k \u2282 Rk . This proves Proposition 7.6 and\ninduction on k = 0, 1, . . . that jk = k and moreover \u0393\nTheorem 2.2(a).\n\u0003\n\nRemark 7.10. In the above proof we assumed that r is a multiple of p + 1. For general r,\nthe symmetry properties take the form zek (\u03c9x) = \u03c9 \u2212r zek (x) and zk (\u03c9x) = \u03c9 \u2212r zk (x) (Recall\nLemma 1.3). Then the functions yek and yk have a jump on the whole of R\u2212 . But the logarithmic\nderivatives do not have such a jump, therefore the proof goes through in exactly the same way\nas above.\n\n47\n\n\f7.3.2\n\nProof of Theorem 2.2(b)\u2013(c)\n\ne k \u2282 Rk . We will assume that\nFix k \u2208 [0 : p \u2212 1] and let r be arbitrary. Let I be an interval of \u0393\ne k is not the whole set R+ or R\u2212 since otherwise there is nothing to prove. We claim that\n\u0393\n\uf8f1\nif I \u2229 {0, \u221e} = \u2205,\n\uf8f2 \u2208 N,\nr\n\u2208 N/(p + 1), if 0 \u2208 I,\n\u03c3k (I) =\n(7.43)\n\uf8f3\np+1\n\u2208 N/p,\nif \u221e \u2208 I.\n\ne k in smaller subintervals\nLet us assume this for the moment. By breaking each interval I of \u0393\nif necessary, in such a way that (7.43) remains valid, we may assume that the left hand side of\n(7.43) always lies in the range (0, 1]. Then we have from the total mass of \u03c3k in (7.36) that\na+\n\nb\nc\nr p\u2212k\nk+1\nkr\n+\n=\n=\nr\u2212 ,\np+1 p\np+1 p\np+1\np\n\n(7.44)\n\ne k for which the left hand side of (7.43) equals 1,\nwhere a denotes the number of intervals I of \u0393\ne k containing\nand where b \u2208 [0 : p] and c \u2208 [0 : p \u2212 1] are nonzero only if there is an interval I \u2282 \u0393\n0 or \u221e respectively and with the left hand side of (7.43) being < 1. Since p and p + 1 are\ncoprime, from (7.44) we deduce that\n\u0016\n\u0017\n\u0018 \u0019\nkr\nk+1\nc\nb\nk+1\nkr\n\u2212 .\n=\nr\u2212\nr ,\nand =\np+1\np+1\np+1\np\np\np\nInserting this in (7.44) we get\n\n\u0017 \u0018 \u0019\nkr\nk+1\n.\na=\nr \u2212\np+1\np\n\u0016\n\ne k that\nWe then find for the total number nk of intervals of \u0393\n\u0018\n\u0017 \u0018 \u0019\n\u0019 \u0016 \u0017\n\u0016\nk+1\nkr\nkr\nk+1\n+ 1b6=0 + 1c6=0 =\n,\nr \u2212\nr \u2212\nnk =\np+1\np\np+1\np\nwhere the indicator function 1x6=0 equals 1 if x 6= 0 and zero otherwise, and where the second\nequality uses that b 6= 0 if and only if (k + 1)r/(p + 1) 6\u2208 N and similarly c 6= 0 if and only if\nkr/p 6\u2208 N \u222a {0}. This proves Theorem 2.2(b)\u2013(c).\nFinally we prove (7.43). Due to (7.35) it will be enough to prove that\n\u001a\n\u2208 N,\nif J \u2229 {\u221e} = \u2205,\n(7.45)\nr\u03bck (J) =\n\u2208 N/p, if \u221e \u2208 J,\nfor any connected component J of \u0393k \u2282 Sk . Thus J is either a line segment on Sk \\ {0} (there\nare p + 1 rotations of such a segment), or it is a set of the form J = {x \u2208 Sk | |x| \u2264 a} for some\na > 0.\nThe first statement of (7.45) follows from [7, Prop 2.10]. Let us check it directly if J \u2282 Sk is\na line segment of the form [a, b] with a, b 6\u2208 {0, \u221e}. From the definition (1.19) of \u03bck it is easy to\nsee that\n\uf8f6\n\uf8eb\nk\nk\nY\nY\n1\nzj,\u2212 (x)\uf8f8\n(7.46)\nzj,+ (x) \u2212 arg\nlim \uf8edarg\nr\u03bck (J) =\n2\u03c0 x\u2192b,x\u2208J\nj=0\nj=0\nQk\n\nis continuous in U \\ J with U a\nQk\ncomplex neighborhood of [a, b) (U excludes b). This is possible since j=0 zj (x) is analytic and\n\nwhere we take the argument function arg so that arg\n\n48\n\nj=0 zj (x)\n\n\fnonzero in C \\ \u0393k . But then the expression between brackets in (7.46) is an integral multiple of\n2\u03c0, yielding the first statement in (7.45).\nTo prove the second statement of (7.45), note that (7.46) remains valid if b lies at \u221e. In\nthat case, the behavior of the functions zk (x) near infinity in (1.17) implies that the expression\nbetween brackets in (7.46) is an integral multiple of 2\u03c0/p. This proves (7.45).\n\u0003\n\n8\n\nNikishin system\n\nIn this section we prove Theorem 2.10 on the connection with Nikishin systems. We start by\nrecalling some ideas in [2].\n\n8.1\n\nMultiple orthogonality relations\n\nFor any l \u2208 [0 : p], we define the sequence of monic polynomials (Qn,l (x))\u221e\nn=l by the recurrence\nrelation\nxQn,l (x) = Qn+1,l (x) + an\u2212p Qn\u2212p,l (x),\nn \u2265 l,\n(8.1)\nwith initial conditions\nQl,l (x) \u2261 1,\n\nQl\u22121,l (x) \u2261 * * * \u2261 Ql\u2212p,l (x) \u2261 0.\n\n(8.2)\n\nNote that deg Qn,l = n\u2212l and that Qn,0 (x) \u2261 Qn (x). Moreover, the p+1 sequences (Qn,l (x))\u221e\nn=0\nform a basis for the space of all solutions (qn )\u221e\nn=0 to the difference equation\nn \u2265 p.\n\nxqn = qn+1 + an\u2212p qn\u2212p ,\n\nLemma 8.1. (The measures \u03bd1 , . . . , \u03bdp ; see [2]:) Suppose that an > 0 for all n and the numbers\nan are uniformly bounded. There exists an increasing sequence of positive integers (nj )\u221e\nj=0 such\nthat for any fixed l \u2208 [1 : p], we have\n(a)\nQ(p+1)nj ,l (x)\n=\nj\u2192\u221e Q(p+1)nj (x)\nlim\n\nZ\n\nd\u03bdl (t)\n,\nx\u2212t\n\n(8.3)\n\nuniformly for x in compact subsets of C \\ S+ , where \u03bdl is a compactly supported measure\non S+ .\n(b) The moments of \u03bdl are uniquely determined from the condition (8.3), independently of the\nchoice of the sequence (nj )\u221e\nj=0 .\n(c) The measure \u03bdl can be written as\nd\u03bdl (t) = t1\u2212l d\u03bd\u0303l (tp+1 ),\n\n(8.4)\n\np+1\nfor a compactly supported, positive measure \u03bd\u0303l supported on S+\n= R+ . Thus for l = 1\nthe measure \u03bdl is rotationally invariant under rotations over 2\u03c0/(p + 1) while for l > 1 it\nis rotationally invariant up to a monomial factor.\n\nLemma 8.1 was shown by Aptekarev-Kalyagin-Van Iseghem [2]. The key fact for (8.3) is that\nfor any n \u2208 N and l \u2208 [1 : p] the zeros of Q(p+1)n,l (x) and Q(p+1)n (x) interlace (in a suitable\nsense) on the star-like set S+ . The existence of a sequence (nj )\u221e\nj=0 such that (8.3) holds then\nfollows from the Helly selection theorem, see [2].\n49\n\n\fRecall from Theorem 1.1 that the polynomials Qn (x) are multiple orthogonal with respect\nto the measures \u03bd1 , . . . , \u03bdp defined in (8.3), in the sense of (1.4).\nWe will assume throughout this section that we are in the exactly periodic case (2.17) and\nthat (2.18) holds. We can assume that the sequence nj in (8.3) is such that each (p + 1)nj is a\nmultiple of r; this follows directly from the freedom in choosing a convergent subsequence in the\nproof of Lemma 8.1 in [2]. For a fixed l \u2208 [0 : p], let\nTn (x) := Qn+l,l (x),\n\nn \u2265 0.\n\nBy (8.1) and (8.2), this sequence satisfies\nxTn (x) = Tn+1 (x) + an+l\u2212p Tn\u2212p (x),\n\nn \u2265 0,\n\n(8.5)\n\nwith initial conditions\nT0 (x) \u2261 1,\n\nT\u22121 (x) \u2261 * * * \u2261 T\u2212p (x) \u2261 0.\n\n(8.6)\n\n\u2212l\nl\nIt follows that the block Toeplitz symbol associated with (Tn )\u221e\nn=0 is Z F (z, x)Z , with Z and\nF given by (1.12) and (1.10), respectively.\nUsing Theorem 2.14 and simple considerations, we deduce that for any index sequence (nj )\u221e\nj=0\nas described above, we have\n\nQ(p+1)nj ,l (x)\nT(p+1)nj \u2212l (x)\nfl (z0 (x), x)\n= lim\n=\n,\nj\u2192\u221e Q(p+1)nj (x)\nj\u2192\u221e Q(p+1)nj (x)\nf0 (z0 (x), x)\nlim\n\nl \u2208 [0 : p],\n\n(8.7)\n\nuniformly on compact subsets of C \\ S+ , where the functions fl are the following minors of the\nblock Toeplitz symbol:\nf0 (z, x) = (\u22121)r z \u22121 det F r\u22121,0 (z, x),\nfl (z, x) = (\u22121)l det F l\u22121,0 (z, x),\nl \u2208 [1 : r].\n\n(8.8)\n\nNote that the functions fl (z0 (x), x), l \u2208 [0 : p], are analytic in C \\ \u03930 , and that f0 (z, x) has an\nextra factor z \u22121 in comparison to the other functions fl (z, x). Let\nA0 := {x \u2208 C \\ \u03930 :\n\nfl (z0 (x), x)\nhas a non-removable pole at x for some l \u2208 [1 : p]}.\nf0 (z0 (x), x)\n\nFrom the statement of Theorem 2.14 we know that the set A0 is finite. Moreover, since the\nfunctions Qn,l (x)/Qn (x) are analytic on C \\ S+ , we deduce from (8.7) that A0 \u2282 S+ .\n\n8.2\n\nFormal Nikishin system\n\nIn this section we will introduce a hierarchy of functions fl,k , 0 \u2264 k < l \u2264 p, which will be\nidentified later as the Cauchy transforms of certain measures that form the different layers of a\nNikishin system on (\u03930 , . . . , \u0393p\u22121 ).\nFrom (8.3) and (8.7) we obtain\nZ\nd\u03bdl (t)\nfl (z0 (x), x)\n=\n=: fl,0 (z0 (x), x),\nl \u2208 [1 : p],\n(8.9)\nx\u2212t\nf0 (z0 (x), x)\nfor x \u2208 C \\ (\u03930 \u222a A0 ). The measures \u03bdl and the functions fl,0 will form layer 0 of the Nikishin\nhierarchy, as we will show later in this section. We also deduce that the measures \u03bdl are supported\non \u03930 \u222a A0 .\n50\n\n\fWe consider the functions\nfl,0 (z0,+ (x), x) \u2212 fl,0 (z0,\u2212 (x), x)\n,\nf1,0 (z0,+ (x), x) \u2212 f1,0 (z0,\u2212 (x), x)\n\nx \u2208 \u03930 ,\n\nl \u2208 [2 : p]. (These expressions will be well-defined as we will show in the next section.) The\nrelations z0,\u00b1 = z1,\u2213 on \u03930 imply that these functions can be meromorphically extended to\nC \\ \u03931 ; we denote the resulting functions by\nfl,1 (z0 (x), z1 (x), x) :=\n\nfl,0 (z1 (x), x) \u2212 fl,0 (z0 (x), x)\n,\nf1,0 (z1 (x), x) \u2212 f1,0 (z0 (x), x)\n\n(8.10)\n\nand we observe that fl,1 is a symmetric function of its two arguments z0 and z1 . This will form\nlayer 1 of the Nikishin hierarchy.\nNext we consider the functions\nfl,1 (z0 (x), z1,+ (x), x) \u2212 fl,1 (z0 (x), z1,\u2212 (x), x)\n,\nf2,1 (z0 (x), z1,+ (x), x) \u2212 f2,1 (z0 (x), z1,\u2212 (x), x)\n\nx \u2208 \u03931 ,\n\nl \u2208 [3 : p]. They can be extended to C \\ \u03932 by the functions\nfl,2 (z0 (x), z1 (x), z2 (x), x) :=\n\nfl,1 (z0 (x), z2 (x), x) \u2212 fl,1 (z0 (x), z1 (x), x)\n,\nf2,1 (z0 (x), z2 (x), x) \u2212 f2,1 (z0 (x), z1 (x), x)\n\n(8.11)\n\nand we observe that fl,2 is a symmetric function of its three arguments z0 , z1 , z2 (this is a bit\nharder to see now). This will form layer 2 of the Nikishin hierarchy.\nWe can continue this procedure and set\nfl,k (z0 (x), . . . , zk (x), x)\n=\n\nfl,k\u22121 (z0 (x), . . . , zk\u22122 (x), zk (x), x) \u2212 fl,k\u22121 (z0 (x), . . . , zk\u22122 (x), zk\u22121 (x), x)\n,\nfk,k\u22121 (z0 (x), . . . , zk\u22122 (x), zk (x), x) \u2212 fk,k\u22121 (z0 (x), . . . , zk\u22122 (x), zk\u22121 (x), x)\n\nfor l \u2208 [k + 1 : p] and k \u2208 [1 : p \u2212 1], using induction on k. It allows a determinantal formula:\nLemma 8.2. Consider the functions fl , l \u2208 [0 : p] in (8.8). Define the hierarchy of functions\nfl,k , 0 \u2264 k < l \u2264 p, as explained above. Abbreviating fl (zk (x)) := fl (zk (x), x) for each l, we have\n\nfl,k (z0 (x), . . . , zk (x), x) =\n\nf0 (z0 (x))\n..\n.\n\n...\n\nf0 (zk (x))\n..\n.\n\nfk\u22121 (z0 (x)) . . . fk\u22121 (zk (x))\nfl (z0 (x)) . . . fl (zk (x))\n\n/\n\nf0 (z0 (x))\n..\n.\n\n...\n\nf0 (zk (x))\n..\n.\n\n.\nfk\u22121 (z0 (x)) . . . fk\u22121 (zk (x))\nfk (z0 (x)) . . . fk (zk (x))\n(8.12)\n\nWe also have\nfl,k,+ (z0 (x), . . . , zk (x), x) \u2212 fl,k,\u2212 (z0 (x), . . . , zk (x), x) =\nf0 (z0 (x)) . . . f0 (zk\u22121 (x))\n..\n..\n.\n.\n\nf0 (z0 (x)) . . . f0 (zk+1 (x))\n..\n..\n.\n.\n\nfk (z0 (x)) . . . fk (zk+1 (x))\nfl (z0 (x)) . . . fl (zk+1 (x))\n\u2212\n, (8.13)\nf0 (z0 (x)) . . . f0 (zk (x)) f0 (z0 (x)) . . . f0 (zk\u22121 (x)) f0 (zk+1 (x))\n..\n..\n..\n..\n..\n.\n.\n.\n.\n.\nfk (z0 (x)) . . . fk (zk (x)) fk (z0 (x)) . . . fk (zk\u22121 (x)) fk (zk+1 (x))\nfk\u22121 (z0 (x)) . . . fk\u22121 (zk\u22121 (x))\n\n51\n\n\ffor x \u2208 \u0393k , where in the right hand side of (8.13) we define the values zj (x) as the limiting\nvalues obtained from the +-side of \u0393k (picking another labeling of the zj (x) so that (1.15) holds\ncan only change the sign in (8.13)), and where we set the determinant of an empty matrix as 1.\nProof. The determinantal formulas follow by induction on k = 0, 1, 2, . . . by means of a basic\nlinear algebra calculation using Sylvester's determinant identity [14]. See also [1, Sec. 8].\nRemark 8.3. As in the proof of Lemma 7.8, we see that the denominator in the right-hand side\nof (8.12) vanishes only for finitely many x \u2208 C. Taking into account the relations zi,\u00b1 = zi+1,\u2213\non \u0393i , i \u2208 [0 : k \u2212 1], we see that the ratio in (8.12) is in fact analytic in C \\ (\u0393k \u222a Ak ), where Ak\nis a finite set in C \\ \u0393k .\nLemma 8.4. Let r be a multiple of p and assume the ordering (2.18). For any 0 \u2264 k < l \u2264 p\nthere exists C 6= 0 such that the following asymptotics hold for x \u2192 \u221e:\nf0 (z0 (x))\n..\n.\nfk\u22121 (z0 (x))\nfl (z0 (x))\n\n...\n\nf0 (zk (x))\n..\n.\n\n. . . fk\u22121 (zk (x))\n...\nfl (zk (x))\n\n/\n\nf0 (z0 (x))\n..\n.\nfk\u22121 (z0 (x))\nfk (z0 (x))\n\n...\n\nf0 (zk (x))\n..\n.\n\n. . . fk\u22121 (zk (x))\n...\nfk (zk (x))\n\n= Cxk\u2212l (1 + O(x\u2212p\u22121 )).\n\nThe proof of Lemma 8.4 is postponed to Section 8.4.\nFor convenience, we define a new symbol:\nFb (z, x) := Pr F (z, x)T Pr ,\n\n(8.14)\n\nwhere Pr is the r \u00d7 r permutation matrix that consists of 1's in the main antidiagonal and 0's\nelsewhere, i.e., the (i, j) entry of Pr equals \u03b4i+j\u2212r+1 , for i, j \u2208 [0 : r \u2212 1]. Note that Fb(z, x) is\nthe reflection of F (z, x) with respect to its main antidiagonal. We can rewrite (8.8) as\nf0 (z, x) = (\u22121)r z \u22121 det Fbr\u22121,0 (z, x),\nfl (z, x) = (\u22121)l det Fb r\u22121,r\u2212l (z, x),\n\nl \u2208 [1 : r].\n\n(8.15)\n\nWe also define the functions\n\nf \u03030 (z, x) = (\u22121)r z \u22121 det F r\u22121,0 (z, x),\nf \u0303l (z, x) = (\u22121)l det F r\u22121,r\u2212l (z, x),\n\n8.3\n\nl \u2208 [1 : r].\n\n(8.16)\n\nProof of Theorem 2.10\n\nLemma 8.2 asserts that the measures \u03bdj form a formal Nikishin system in the sense of [1]. To\nprove Theorem 2.10, we will now show that they are a true Nikishin system.\nTheorem 8.5. (Nikishin property.) Let H be the two-diagonal Hessenberg matrix (2.6), with\nentries an > 0 that satisfy (2.17)\u2013(2.18). For each pair of indices k, l with 0 \u2264 k < l \u2264 p,\nZ\nd\u03bdl,k (t)\n,\n(8.17)\nfl,k (z0 (x), . . . , zk (x), x) =\nx\u2212t\nfor a measure \u03bdl,k supported on \u0393k \u222a Ak , where Ak is a finite subset of Sk \\ \u0393k (S\u2212 \\ \u0393k ) if\nk is even (odd). The measure \u03bdl,k takes the form (2.20), for a measure \u03bd\u0303l,k with constant sign\nsupported on R+ (R\u2212 ) if k is even (odd).\n\n52\n\n\fProof. By (8.9) we know that (8.17) is valid for k = 0 and l \u2208 [1 : p]. We also know already that\nthe measures \u03bdl,0 are supported on \u03930 \u222a A0 , with A0 a finite subset of S+ \\ \u03930 , and that (2.20)\nholds for k = 0.\nIn what follows we are going to work with the polynomials associated with the symbol Fb\nb with\nintroduced in (8.14). That is, we consider now the two-diagonal Hessenberg operator H\nperiodic structure whose first r coefficients are given in the following order:\nar\u2212p\u22121 , ar\u2212p\u22122 , . . . , a1 , a0 , ar\u22121 , . . . , ar\u2212p .\n\nb the polynomials Pk,l,n as defined in Section 2.4. These\nWe associate with the new operator H\nare the polynomials we will employ below.\nLet 1 \u2264 k < l \u2264 p. Applying Theorem 2.12,\nPk,l,n (x)\nPek,l,n (xp+1 )\n,\n= xk\u2212l\nPk,n (x)\nPek,n (xp+1 )\n\nwhere the zeros of Pek,n and Pek,l,n lie in R+ (R\u2212 ) if k is even (odd), and are weakly interlacing.\nLet us denote by dn the degree of Pek,n . Thanks to the weak interlacing property, we know\nthat either deg Pek,l,n = dn or deg Pek,l,n = dn + 1. In any case, we can write\ndn\nX\n\u03b1i,n\nPek,l,n (z)\n,\n= \u03b1\u22121,n +\ne\nz\n\u2212\nxi,n\nz Pk,n (z)\ni=0\n\nn\nwhere x0,n := 0, {xi,n }di=1\ndenotes the zeros of Pek,n , and for i \u2265 0, we set \u03b1i,n = 0 if z \u2212 xi,n is a\ncommon factor of the numerator and denominator. It also follows from the interlacing property\nn\nhave the same sign.\nthat all the coefficients {\u03b1i,n }di=0\nAssume for the moment that k is even, so the zeros of Pek,n lie in R+ . Let \u03bdl,k,n be the discrete\nn\nwith mass \u03b1i,n at xi,n . Hence\nmeasure supported on {xi,n }di=0\n\nZ\nPek,l,n (z)\nd\u03bdl,k,n (t)\n= \u03b1\u22121,n +\n.\nz\u2212t\nz Pek,n (z)\n\n(8.18)\n\nIt is easy to check that \u03b1\u22121,n \u2264 0 if \u03bdl,k,n \u2265 0, and \u03b1\u22121,n \u2265 0 if \u03bdl,k,n \u2264 0. Therefore the function\n(8.18) maps (\u2212\u221e, 0) into (\u2212\u221e, 0) if \u03bdl,k,n is positive, and maps (\u2212\u221e, 0) into (0, \u221e) if \u03bdl,k,n is\nnegative. Moreover, it maps the upper half plane into the lower half plane (upper half plane) if\n\u03bdl,k,n is positive (negative).\nAn important ingredient in our proof is formula (7.28), which certainly applies in our situb (or\nation. We should apply this formula for the B-polynomials associated with the operator H\nthe symbol Fb ). Therefore, taking into account (8.15)\u2013(8.16), the determinants in the right-hand\nside of (7.28) are in this situation constructed with the functions fk (z, x).\nWe know by Lemma 7.8 that\nPek,l,n (z)\n=: G(z),\nn\u2192\u221e z P\nek,n (z)\nlim\n\nuniformly on compact subsets of C \\ [0, \u221e). Since G 6\u2261 0, the measures \u03bdl,k,n are all positive for\nn sufficiently large, or they are all negative for n sufficiently large. Therefore G is an analytic\nfunction in C \\ [0, \u221e) that satisfies one of the following properties:\n53\n\n\f(a) G(x) < 0 for all x \u2208 (\u2212\u221e, 0) and G maps the upper half plane into the lower half plane,\n(b) G(x) > 0 for all x \u2208 (\u2212\u221e, 0) and G maps the upper half plane into the upper half plane.\nApplying Theorem A.4 from [18], we deduce that\nZ\nd\u03bd\u0302l,k (t)\nG(z) = \u03b1 +\n,\nz\u2212t\n\nz \u2208 C \\ [0, \u221e),\n\nwhere \u03b1 \u2208 R and \u03bd\u0302l,k is a measure with constant sign supported on R+ .\nIn particular, applying the above equations together with (7.28), (3.4), and (8.12), we obtain\nZ\n\u0010\nPk,l,n (x)\nd\u03bd\u0302l,k (t) \u0011\nk\u2212l+p+1\nlim\n= (\u22121)l\u2212k fl,k (z0 (x), . . . , zk (x), x),\n(8.19)\n\u03b1+\n=x\nn\u2192\u221e Pk,n (x)\nxp+1 \u2212 t\nuniformly on compact subsets of C \\ S+ . Now, Lemma 8.4 implies that \u03b1 = 0. Finally, using\n2\u03c0im\np\n1 X (e p+1 s)k\u2212l+1\nxk\u2212l+p+1\n,\n=\nxp+1 \u2212 t\np + 1 m=0 x \u2212 e 2\u03c0im\np+1 s\n\nwe deduce\nxk\u2212l+p+1\n\nZ\n\nR+\n\nd\u03bd\u0302l,k (t)\n1\n=\np+1\nx\n\u2212t\np+1\n\nZ\n\nS+\n\nt = sp+1 ,\n\nsk\u2212l+1\nd\u03bd\u0302l,k (sp+1 ).\nx\u2212s\n\nl\u2212k\n\nThis justifies (8.17) and (2.20) with \u03bd\u0303l,k := (\u22121)\np+1 \u03bd\u0302l,k . and we see from (8.19) that the function\nfl,k (z0 (x), . . . , zk (x), x) has no singularities outside S+ . The proof is analogous for odd values of\nk. It is clear from the analyticity of fl,k (z0 (x), . . . , zk (x), x) on C \\ (\u0393k \u222a Ak ), see Remark 8.3,\nthat the measure \u03bdl,k is supported on \u0393k \u222a Ak .\nProof of Theorem 2.10: We have precisely shown in Theorem 8.5 that if d\u03bdl,k (x) = gl,k (x) dx +\n(s)\nd\u03bdl,k (x) denotes the Lebesgue decomposition of \u03bdl,k , then for l \u2208 [k + 2 : p],\nfl,k,+ (z0 (x), . . . , zk (x), x) \u2212 fl,k,\u2212 (z0 (x), . . . , zk (x), x)\ngl,k (x)\n=\n,\ngk+1,k (x)\nfk+1,k,+ (z0 (x), . . . , zk (x), x) \u2212 fk+1,k,\u2212 (z0 (x), . . . , zk (x), x)\n\nx \u2208 \u0393k ,\n\nis expressible as the Cauchy transform of a measure \u03bdl,k+1 supported on the star complementary\nto \u0393k .\n\u0003\n\n8.4\n\nProof of Lemma 8.4\n\nIn this section we will prove Lemma 8.4. First we establish the following result.\nLemma 8.6. (Asymptotics of fj (zk , x):) Let r be a multiple of p and assume the ordering (2.18).\nThe functions fj (zk (x), x) in (8.8) behave for x \u2192 \u221e as\n\nand\n\nf0 (z0 (x), x) = (\u22121)r xr + O(xr\u2212p\u22121 ),\nf0 (zk (x), x) = O(xr\u2212p\u22121 ),\nk \u2208 [1 : p],\n\n(8.20)\n\nfj (z0 (x), x) = (\u22121)r xr\u2212j + O(xr\u2212j\u2212p\u22121 ),\nfj (zk (x), x) = Cj,k xr\u2212j + O(xr\u2212j\u2212p\u22121 ),\nk \u2208 [1 : j],\nfj (zk (x), x) = O(xr\u2212j\u2212p\u22121 ),\nk \u2208 [j + 1 : p],\n\n(8.21)\n\nfor j \u2208 [1 : p], for certain constants Cj,k 6= 0, k \u2264 j.\n54\n\n\fNote that the O-terms jump with powers of x\u2212p\u22121 rather than x\u22121 . This is due to the\nrotational symmetry under rotations with exp(2\u03c0i/(p + 1)).\nLemma 8.6 implies that for l \u2265 k,\n\uf8eb\n\nf0 (z0 (x))\n\uf8ec\n..\n\uf8ec\n.\n\uf8ec\n\uf8edfk\u22121 (z0 (x))\nfl (z0 (x))\n\n\uf8f6\nf0 (zk (x))\n\uf8f7\n..\n\uf8f7\n.\n\uf8f7 = diag(xr , xr\u22121 , . . . , xr\u2212k+1 , xr\u2212l )\n. . . fk\u22121 (zk (x))\uf8f8\n...\nfl (zk (x))\n\uf8eb\n1 O(x\u2212p\u22121 ) O(x\u2212p\u22121 ) . . . O(x\u2212p\u22121 )\n\uf8ec1\nC1,1\nO(x\u2212p\u22121 ) . . . O(x\u2212p\u22121 )\n\uf8ec\n\uf8ec1\nC2,1\nC2,2\n. . . O(x\u2212p\u22121 )\n\uf8ec\n\u00d7 \uf8ec.\n..\n..\n..\n\uf8ec ..\n.\n.\n.\n\uf8ec\n\uf8ed1\nCk\u22121,1\nCk\u22121,2\n. . . Ck\u22121,k\u22121\n1\nCl,1\nCl,2\n...\nCl,k\u22121\n...\n\nwhere each Cj,k is a non-zero constant. Therefore,\nf0 (z0 (x))\n..\n.\nfk\u22121 (z0 (x))\nfl (z0 (x))\n\n...\n\nf0 (zk (x))\n..\n.\n\n. . . fk\u22121 (zk (x))\n...\nfl (zk (x))\n\n\uf8f6\nO(x\u2212p\u22121 )\nO(x\u2212p\u22121 )\uf8f7\n\uf8f7\nO(x\u2212p\u22121 )\uf8f7\n\uf8f7\n\uf8f7\n..\n\uf8f7\n.\n\uf8f7\n\u2212p\u22121 \uf8f8\nO(x\n)\nCl,k\n\n= Cxr+(r\u22121)+...+(r\u2212k+1)+(r\u2212l) (1 + O(x\u2212p\u22121 )),\n\n(8.22)\n\nfor some constant C 6= 0. Taking ratios of such determinants, we then get the desired Lemma 8.4.\nIn the rest of this section we prove (8.20)\u2013(8.21). First of all, the statements involving z0 (x)\nfollow easily from the Widom-type formula (2.25) (applied to the antidiagonal reflected symbol\n(8.14)) taking into account that z0 (x) \u223c x\u2212r and z1 (x), . . . , zp (x) = O(xr/p ) for x \u2192 \u221e, and\nthat z0 (x) . . . zp (x) = (\u22121)r+p /fp .\nNext, we prove (8.20)\u2013(8.21) for the functions zk (x) with k \u2265 1. Let ej \u2208 Cr be the standard\nbasis vector which has all its entries equal to zero except for the entry in position j, which is\nequal to 1. Let P be the permutation matrix of size r \u00d7 r which acts on the vectors ej by the\nrule\nP eap+b = ebr/p+a ,\nfor any a \u2208 [0 : r/p \u2212 1] and b \u2208 [0 : p \u2212 1]. Let D be the r \u00d7 r diagonal matrix\n\u0011\n\u0010\n2p\nr\u2212p\np\nD := diag Ip , z r Ip , z r Ip , . . . , z r Ip .\n\n(8.23)\n\nWe conjugate the block Toeplitz symbol F (z, x) by the matrices D and P . This results in the\nfollowing matrix:\n\uf8f6\n\uf8eb\nA0 I\n0\n...\n0\n0\n\uf8f7\n\uf8ec\n..\n\uf8ec 0 A1 I\n.\n0\n0 \uf8f7\n\uf8f7\n\uf8ec\n\uf8ec .\n.. \uf8f7\n..\n..\n..\n..\n\u22121 \u22121\n.\n\uf8ec\n.\n.\n.\n.\n(8.24)\nP DF (z, x)D P = \uf8ec .\n. \uf8f7\n\uf8f7,\n\uf8f7\n\uf8ec0\n0\n0\nA\nI\n0\np\u22123\n\uf8f7\n\uf8ec\n\uf8ed0\n0\n0\n0\nAp\u22122\nI \uf8f8\nZ\n0\n0\n0\n0\nAp\u22121\n55\n\n\fp\n\nwith Z := z \u2212 r\n\n\u0012\n0\n1\n\n\uf8eb\n\n\u0013\nIr/p\u22121\n, and\n0\n\n\u2212x\n\n\uf8ec p/r\n\uf8ec aj z\n\uf8ec\n\uf8ec\n\uf8ec\nAj = \uf8ec 0\n\uf8ec .\n\uf8ec ..\n\uf8ec\n\uf8ed 0\n0\n\n0\n\n0\n\n\u2212x\n\n0\n\nap+j z p/r\n..\n.\n\n\u2212x\n..\n.\n\n...\n..\n.\n..\n.\n..\n.\n\n0\n0\n\n0\n0\n\nar\u22123p+j z p/r\n0\n\n0\n\nar\u2212p+j z p/r\n\n0\n..\n.\n\n0\n\n..\n\n0\n..\n.\n\nar\u22122p+j z p/r\n\n0\n\u2212x\n\n.\n\u2212x\n\n\uf8f6\n\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7,\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f8\n\n(8.25)\n\nfor j \u2208 [0 : p \u2212 1]. Note that each of the blocks in (8.24) is a square matrix of size r/p by r/p.\np/r\np/r\nFix k \u2208 [1 : p]. We already know that zk (x) \u223c Ck xr/p as x \u2192 \u221e. Hence zk (x) \u223c Ck x.\nFrom (8.24)\u2013(8.25) and the fact that det F (zk (x), x) = 0 we see that (see also (2.22))\n\uf8f1\n\uf8fc\nr/p\u22121\nr/p\u22121\n\uf8f2r/p\u22121\n\uf8fd\nY\nY\nY\n\u22121\n\u22121\nCk \u2208\na\u22121\n,\na\n,\n.\n.\n.\n,\na\npn\npn+1\npn+(p\u22121) \uf8fe .\n\uf8f3\nn=0\n\nn=0\n\nn=0\n\nCombining this with (2.18) and (1.15), we obtain that for x \u2192 \u221e,\nz1 (x) =\n..\n.\nzp (x) =\n\n\u0010Q\n\nr/p\u22121\nn=0\n\n\u0010Q\n\nr/p\u22121\nn=0\n\napn\n\n\u0011\u22121\n\nxr/p (1 + O(x\u2212p\u22121 )),\n\napn+p\u22121\n\n\u0011\u22121\n\n(8.26)\nxr/p (1 + O(x\u2212p\u22121 )).\n\nNow we consider det F j\u22121,0 (z, x), i.e., the determinant obtained by skipping the jth row\nand the first column of F (z, x), j \u2208 [1 : p]. Clearly, this determinant is not influenced by\nthe conjugation with the diagonal matrix D in (8.23), in the sense that det F j\u22121,0 (z, x) =\ne the matrix obtained by skipping the\ndet(DF D\u22121 )j\u22121,0 (z, x). For a matrix A denote with A\nb\nfirst row of A and with A the matrix obtained by skipping the first column of A. Then from\n(8.24) we obtain\n\uf8f6\n\uf8eb\nb0 I\nA\n\uf8f7\n\uf8ec\nA1 I\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n..\n..\n\uf8f7\n\uf8ec\n.\n.\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\nej\u22121 Ie\n\uf8f7\n\uf8ec\nA\nj\u22121,0\ndet F\n(z, x) = \u00b1 det \uf8ec\n\uf8f7.\n\uf8f7\n\uf8ec\nAj I\n\uf8f7\n\uf8ec\n..\n..\n\uf8f7\n\uf8ec\n.\n.\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8ed\nAp\u22122\nI \uf8f8\nb\nZ\nAp\u22121\nNow by repeated Gaussian elimination with the identity matrices I as pivots, the above determinant can be brought to the form\n!\nb0\nej\u22121 . . . A1 A\nIe\n\u00b1A\nj\u22121,0\n.\n(8.27)\ndet F\n(z, x) = \u00b1 det\nb\nZ\n\u00b1Ap\u22121 Ap\u22122 . . . Aj\n56\n\n\fFix k \u2208 [1 : p]. To obtain the dominant behavior of (8.27) for z = zk (x) as x \u2192 \u221e, we\nshould only use the (1, 1) and the (2, 2) blocks in (8.27). Note that both blocks are square. The\ndeterminant of the (2, 2) block can be simply factored as (det Aj )(det Aj+1 ) . . . (det Ap\u22121 ) with\n\u001a\nCi,k xr/p + O(xr/p\u2212p\u22121 ), if k 6= i + 1,\ndet Ai (z = zk (x)) =\n(8.28)\nO(xr/p\u2212p\u22121 ),\notherwise,\nfor some Ci,k 6= 0, thanks to (8.26). The determinant of the (1, 1) block can be expanded by\nmeans of the Cauchy-Binet formula:\n\u0011\n\u0010\nb0 =\nej\u22121 . . . A1 A\ndet A\n\nr/p\u22121\n\nX\n\nm ,mj\u22121\n\nj\n(det Aj\u22121\n\n2 ,m1\n1 ,m0\n) . . . (det Am\n)(det Am\n),\n1\n0\n\n(8.29)\n\nm1 ,...,mj\u22121 =0\n\nwhere the sum runs over all (j \u2212 1)-tuples of integers (m1 , . . . , mj\u22121 ), each of them ranging\nbetween 0 and r/p \u2212 1, with boundary conditions m0 = mj := 0. We remind the reader that\nAi,j denotes the submatrix of A obtained by deleting row i and column j. Clearly,\nmi+1 ,mi\n\ndet Ai\n\nei,k xr/p\u22121 + O(xr/p\u2212p\u22122 ),\n(z = zk (x)) = C\n\nei,k 6= 0,\nC\n\nfor all i \u2208 [0 : j \u2212 1]. Using this in (8.29) we get\n\u0011\n\u0010\njr\nb0 (z = zk (x)) = Cj,k x p \u2212j (1 + O(x\u2212p\u22121 )),\nej\u22121 . . . A1 A\ndet A\n\n(8.30)\n\nas x \u2192 \u221e, for a new constant Cj,k . This constant Cj,k is nonzero, since cancelation of the\nleading order terms in the sum in (8.29) cannot occur. This is due to Lemma 8.7 below.\nBy combining (8.27), (8.28) and (8.30), we obtain the desired asymptotics in (8.21) for z =\nzk (x) with k \u2208 [1 : p].\nThe asymptotics in (8.20) can be proved by a similar argument. We now have the relation\ne the\nz \u22121 det F r\u22121,0 (z, x) = z \u2212p/r det(DF D\u22121 )r\u22121,0 (z, x). For a matrix A denote now with A\nb\nmatrix obtained by skipping the last (rather than the first) row of A and denote again with A\nthe matrix obtained by skipping the first column of A. Then by Gaussian elimination we get the\nfollowing analogue of (8.27):\nb0 ),\nep\u22121 . . . A1 A\nz \u22121 det F r\u22121,0 (z, x) = \u00b1z \u2212p/r det(z \u2212p/r I \u00b1 A\n\nwhere z \u2212p/r I arises as the submatrix obtained by skipping the last row and the first column of Z.\nb0 ).\nep\u22121 . . . A1 A\nClearly, the dominant behavior for z = zk (x) as x \u2192 \u221e comes from \u00b1z \u2212p/r det(A\nThis determinant can be evaluated using Cauchy-Binet in the same way as before. Then we easily\nget the asymptotics in (8.20) for z = zk (x) with k \u2208 [1 : p]. This ends the proof of Lemma 8.6.\n\u0003\nTo conclude this section, we state the following lemma which was used above.\nLemma 8.7. Let A be an n \u00d7 n matrix of the form\n\uf8eb\n\u2212b0\n\uf8ec a0 \u2212b1\n\uf8ec\n\uf8ec\n..\n.\na1\nA=\uf8ec\n\uf8ec\n\uf8ec\n.\n.\n\uf8ed\n. \u2212bn\u22122\nan\u22122\n57\n\nan\u22121\n\n\u2212bn\u22121\n\n\uf8f6\n\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7,\n\uf8f7\n\uf8f7\n\uf8f8\n\n\fwith ak , bk > 0 for all k \u2208 [0 : n \u2212 1]. Denote with Ak,l the submatrix obtained by skipping the\nkth row and the lth column of A. Then\n(\u22121)n+k+l+1 det Ak,l > 0.\nProof. Straightforward verification.\n\nReferences\n[1] A.I. Aptekarev, V.A. Kalyagin and E.B. Saff, Higher order three-term recurrences and\nasymptotics of multiple orthogonal polynomials, Constr. Approx. 30 (2009), 175-223.\n[2] A.I. Aptekarev, V.A. Kalyagin and J. Van Iseghem, The genetic sum's representation for the\nmoments of a system of Stieltjes functions and its applications, Constr. Approx. 16 (2000),\n487-524.\n[3] Y. Ben Cheikh and K. Douak, On the classical d-orthogonal polynomials defined by certain\ngenerating functions I, Bull. Belg. Math. Soc. Simon Stevin 7 (2000), 107-124.\n[4] M. Bender, S. Delvaux and A.B.J. Kuijlaars, Multiple Meixner-Pollaczek polynomials and\nthe six-vertex model, J. Approx. Theory 163 (2011), 1606\u20131637.\n[5] P. Bleher and A.B.J. Kuijlaars, Orthogonal polynomials in the normal matrix model with\na cubic potential, arXiv:1106.6168.\n[6] A. B\u00f6ttcher and B. Silbermann, Introduction to Large Truncated Toeplitz Matrices, Universitext, Springer-Verlag, New York 1998.\n[7] S. Delvaux, Equilibrium problem for the eigenvalues of banded block Toeplitz matrices,\nMath. Nachr. (2012), to appear. arXiv:1101.2644.\n[8] S. Delvaux, A. L\u00f3pez and G. L\u00f3pez Lagomasino, A family of Nikishin systems with periodic\nrecurrence coefficients, arXiv:1110.2644.\n[9] K. Douak and P. Maroni, Les polyn\u00f4mes orthogonaux \"classiques\" de dimension deux,\nAnalysis 12 (1992), 71\u2013107.\n[10] K. Douak and P. Maroni, On d-orthogonal Tchebyshev polynomials I, Appl. Numer. Math.\n24 (1997) 23-53.\n[11] M. Duits and A.B.J. Kuijlaars, An equilibrium problem for the limiting eigenvalue distribution of banded Toeplitz matrices, SIAM J. Matrix Anal. Appl. 30 (2008), 173\u2013196.\n[12] M. Eiermann and R.S. Varga, Zeros and local extreme points of Faber polynomials associated\nwith hypocycloidal domains, ETNA 1 (1993), 49\u201371.\n[13] A.S. Fokas, A.R. Its and A.V. Kitaev, The isomonodromy approach to matrix models in 2D\nquantum gravity, Commun. Math. Phys. 147 (1992), 395\u2013430.\n[14] F. Gantmacher, The Theory of Matrices, Vol. 1, Chelsea Publishing Company, New York,\n1959.\n[15] F. Gantmacher and M. Krein, Oscillation Matrices and Kernels and Small Vibrations of\nMechanical Systems: Revised Edition, AMS Chelsea Publishing, 2002.\n58\n\n\f[16] M.X. He and E.B. Saff, The zeros of Faber polynomials for an m-cusped hypocycloid, J.\nApprox. Theory 78 (1994), 410\u2013432.\n[17] V.A. Kaliaguine, The operator moment problem, vector continued fractions and an explicit\nform of the Favard theorem for vector orthogonal polynomials, J. Comput. Appl. Math. 65\n(1995), 181\u2013193.\n[18] M.G. Krein and A.A. Nudel'man, The Markov Moment Problem and Extremal Problems,\nTranslations of Mathematical Monographs, Vol. 50, Amer. Math. Soc., RI 1977.\n[19] A. L\u00f3pez Garc\u0131\u0301a, Asymptotics of multiple orthogonal polynomials for a system of two measures supported on a starlike set, J. Approx. Theory 163 (2011), 1146\u20131184.\n[20] P. Maroni, Two-dimensional orthogonal polynomials, their associated sets and the corecursive sets, Numer. Algorithms 3 (1992) 299-312.\n[21] A. Mat\u00e9 and P. Nevai, A generalization of Poincar\u00e9's theorem for recurrence equations, J.\nApprox. Theory 63 (1990), 92\u201397.\n[22] G.V. Milovanovic and G.B. Djordjevic, On some properties of Humbert's polynomials II,\nSer. Math. Inform. 6 (1991), 23-30.\n[23] E.M. Nikishin, On simultaneous Pad\u00e9 approximations, Mat. Sb. 113 (1980), 499\u2013519; English transl. in Math. USSR Sb. 41 (1982), 409\u2013426.\n[24] N.B. Romdhane, On the zeros of d-orthogonal d-symmetric polynomials, J. Math. Anal.\nAppl. 344 (2008), 888\u2013897.\n[25] E.B. Saff and V. Totik, Logarithmic Potentials with External Field, Springer-Verlag, Berlin,\n1997.\n[26] P. Schmidt and F. Spitzer, The Toeplitz matrices of an arbitrary Laurent polynomial, Math.\nScand. 8 (1960), 15\u201338.\n[27] B. Simon, Orthogonal Polynomials on the Unit Circle. Part 2: Spectral Theory, Amer.\nMath. Soc. Coll. Publ. Vol. 54, Amer. Math. Soc. Providence, R.I. 2005.\n[28] W. Van Assche, J.S. Geronimo and A.B.J. Kuijlaars, Riemann-Hilbert problems for multiple\northogonal polynomials, Special Functions 2000: Current Perspectives and Future Directions\n(J. Bustoz et al., eds.), Kluwer, Dordrecht, 2001, pp. 23\u201359.\n[29] P. Van Moerbeke and D. Mumford, The spectrum of difference operators and algebraic\ncurves, Acta Math. 143 (1979), 93\u2013154.\n[30] H. Widom, Asymptotic behavior of block Toeplitz matrices and determinants, Adv. Math.\n13 (1974), 284\u2013322.\n\n59\n\n\f"}