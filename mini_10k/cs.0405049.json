{"id": "http://arxiv.org/abs/cs/0405049v1", "guidislink": true, "updated": "2004-05-16T03:24:55Z", "updated_parsed": [2004, 5, 16, 3, 24, 55, 6, 137, 0], "published": "2004-05-16T03:24:55Z", "published_parsed": [2004, 5, 16, 3, 24, 55, 6, 137, 0], "title": "Export Behaviour Modeling Using EvoNF Approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0405012%2Ccs%2F0405025%2Ccs%2F0405109%2Ccs%2F0405049%2Ccs%2F0405024%2Ccs%2F0405089%2Ccs%2F0405082%2Ccs%2F0405110%2Ccs%2F0405019%2Ccs%2F0405006%2Ccs%2F0405016%2Ccs%2F0405073%2Ccs%2F0405005%2Ccs%2F0405052%2Ccs%2F0405031%2Ccs%2F0405030%2Ccs%2F0405077%2Ccs%2F0405068%2Ccs%2F0405090%2Ccs%2F0405053%2Ccs%2F0405083%2Ccs%2F0405057%2Ccs%2F0405003%2Ccs%2F0405086%2Ccs%2F0405020%2Ccs%2F0405035%2Ccs%2F0405038%2Ccs%2F0405039%2Ccs%2F0405071%2Ccs%2F0405096%2Ccs%2F0405092%2Ccs%2F0405098%2Ccs%2F0405013%2Ccs%2F0405087%2Ccs%2F0405066%2Ccs%2F0405051%2Ccs%2F0405014%2Ccs%2F0405094%2Ccs%2F0405075%2Ccs%2F0405065%2Ccs%2F0405085%2Ccs%2F0405032%2Ccs%2F0405034%2Ccs%2F0405070%2Ccs%2F0405002%2Ccs%2F0405050%2Ccs%2F0405105%2Ccs%2F0405026%2Ccs%2F0405022%2Ccs%2F0405058%2Ccs%2F0405007%2Ccs%2F0405048%2Ccs%2F0405043%2Ccs%2F0405008%2Ccs%2F0405010%2Ccs%2F0405055%2Ccs%2F0405045%2Ccs%2F0505054%2Ccs%2F0505021%2Ccs%2F0505088%2Ccs%2F0505016%2Ccs%2F0505057%2Ccs%2F0505042%2Ccs%2F0505063%2Ccs%2F0505037%2Ccs%2F0505052%2Ccs%2F0505036%2Ccs%2F0505001%2Ccs%2F0505039%2Ccs%2F0505007%2Ccs%2F0505022%2Ccs%2F0505006%2Ccs%2F0505004%2Ccs%2F0505012%2Ccs%2F0505081%2Ccs%2F0505051%2Ccs%2F0505079%2Ccs%2F0505076%2Ccs%2F0505031%2Ccs%2F0505038%2Ccs%2F0505048%2Ccs%2F0505030%2Ccs%2F0505055%2Ccs%2F0505062%2Ccs%2F0505015%2Ccs%2F0505083%2Ccs%2F0505047%2Ccs%2F0505087%2Ccs%2F0505085%2Ccs%2F0505049%2Ccs%2F0505058%2Ccs%2F0505023%2Ccs%2F0505034%2Ccs%2F0505073%2Ccs%2F0505017%2Ccs%2F0505009%2Ccs%2F0505026%2Ccs%2F0505044%2Ccs%2F0505003%2Ccs%2F0505061%2Ccs%2F0505045&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Export Behaviour Modeling Using EvoNF Approach"}, "summary": "The academic literature suggests that the extent of exporting by\nmultinational corporation subsidiaries (MCS) depends on their product\nmanufactured, resources, tax protection, customers and markets, involvement\nstrategy, financial independence and suppliers' relationship with a\nmultinational corporation (MNC). The aim of this paper is to model the complex\nexport pattern behaviour using a Takagi-Sugeno fuzzy inference system in order\nto determine the actual volume of MCS export output (sales exported). The\nproposed fuzzy inference system is optimised by using neural network learning\nand evolutionary computation. Empirical results clearly show that the proposed\napproach could model the export behaviour reasonable well compared to a direct\nneural network approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0405012%2Ccs%2F0405025%2Ccs%2F0405109%2Ccs%2F0405049%2Ccs%2F0405024%2Ccs%2F0405089%2Ccs%2F0405082%2Ccs%2F0405110%2Ccs%2F0405019%2Ccs%2F0405006%2Ccs%2F0405016%2Ccs%2F0405073%2Ccs%2F0405005%2Ccs%2F0405052%2Ccs%2F0405031%2Ccs%2F0405030%2Ccs%2F0405077%2Ccs%2F0405068%2Ccs%2F0405090%2Ccs%2F0405053%2Ccs%2F0405083%2Ccs%2F0405057%2Ccs%2F0405003%2Ccs%2F0405086%2Ccs%2F0405020%2Ccs%2F0405035%2Ccs%2F0405038%2Ccs%2F0405039%2Ccs%2F0405071%2Ccs%2F0405096%2Ccs%2F0405092%2Ccs%2F0405098%2Ccs%2F0405013%2Ccs%2F0405087%2Ccs%2F0405066%2Ccs%2F0405051%2Ccs%2F0405014%2Ccs%2F0405094%2Ccs%2F0405075%2Ccs%2F0405065%2Ccs%2F0405085%2Ccs%2F0405032%2Ccs%2F0405034%2Ccs%2F0405070%2Ccs%2F0405002%2Ccs%2F0405050%2Ccs%2F0405105%2Ccs%2F0405026%2Ccs%2F0405022%2Ccs%2F0405058%2Ccs%2F0405007%2Ccs%2F0405048%2Ccs%2F0405043%2Ccs%2F0405008%2Ccs%2F0405010%2Ccs%2F0405055%2Ccs%2F0405045%2Ccs%2F0505054%2Ccs%2F0505021%2Ccs%2F0505088%2Ccs%2F0505016%2Ccs%2F0505057%2Ccs%2F0505042%2Ccs%2F0505063%2Ccs%2F0505037%2Ccs%2F0505052%2Ccs%2F0505036%2Ccs%2F0505001%2Ccs%2F0505039%2Ccs%2F0505007%2Ccs%2F0505022%2Ccs%2F0505006%2Ccs%2F0505004%2Ccs%2F0505012%2Ccs%2F0505081%2Ccs%2F0505051%2Ccs%2F0505079%2Ccs%2F0505076%2Ccs%2F0505031%2Ccs%2F0505038%2Ccs%2F0505048%2Ccs%2F0505030%2Ccs%2F0505055%2Ccs%2F0505062%2Ccs%2F0505015%2Ccs%2F0505083%2Ccs%2F0505047%2Ccs%2F0505087%2Ccs%2F0505085%2Ccs%2F0505049%2Ccs%2F0505058%2Ccs%2F0505023%2Ccs%2F0505034%2Ccs%2F0505073%2Ccs%2F0505017%2Ccs%2F0505009%2Ccs%2F0505026%2Ccs%2F0505044%2Ccs%2F0505003%2Ccs%2F0505061%2Ccs%2F0505045&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The academic literature suggests that the extent of exporting by\nmultinational corporation subsidiaries (MCS) depends on their product\nmanufactured, resources, tax protection, customers and markets, involvement\nstrategy, financial independence and suppliers' relationship with a\nmultinational corporation (MNC). The aim of this paper is to model the complex\nexport pattern behaviour using a Takagi-Sugeno fuzzy inference system in order\nto determine the actual volume of MCS export output (sales exported). The\nproposed fuzzy inference system is optimised by using neural network learning\nand evolutionary computation. Empirical results clearly show that the proposed\napproach could model the export behaviour reasonable well compared to a direct\nneural network approach."}, "authors": ["Ron Edwards", "Ajith Abraham", "Sonja Petrovic-Lazarevic"], "author_detail": {"name": "Sonja Petrovic-Lazarevic"}, "author": "Sonja Petrovic-Lazarevic", "links": [{"href": "http://arxiv.org/abs/cs/0405049v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0405049v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.0", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0405049v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0405049v1", "arxiv_comment": null, "journal_reference": "The International Conference on Computational Science 2003 (ICCS\n  2003), Springer Verlag, Lecture Notes in Computer Science Volume 2660, Sloot\n  P.M.A. et al (Eds.), pp. 169-178, 2003", "doi": null, "fulltext": "Export Behaviour Modeling Using EvoNF Approach\nRon Edwards1, Ajith Abraham2 and Sonja Petrovic-Lazarevic3\n1\n\nMonash University, School of Business and Economics,\nMcMahons Road, Frankston 3199, Australia\nron.edwards@buseco.monash.edu.au\n2\nDepartment of Computer Science, Oklahoma State University,\n700 N Greenwood Avenue, Tulsa, OK 74106-0700, USA\najith.abraham@ieee.org\n3\nMonash University, Department of Management,\nMcMahons Road, Frankston 3199, Australia\nsonja.petrovic-lazarevic@buseco.monash.edu.au\n\nAbstract. The academic literature suggests that the extent of exporting by\nmultinational corporation subsidiaries (MCS) depends on their product\nmanufactured, resources, tax protection, customers and markets, involvement\nstrategy, financial independence and suppliers' relationship with a multinational\ncorporation (MNC). The aim of this paper is to model the complex export\npattern behaviour using a Takagi-Sugeno fuzzy inference system in order to\ndetermine the actual volume of MCS export output (sales exported). The\nproposed fuzzy inference system (FIS) is optimised by using neural network\nlearning and evolutionary computation. Empirical results clearly show that the\nproposed approach could model the export behaviour reasonable well compared\nto a direct neural network approach.\n\n1. Introduction\nMalaysia has been pursuing an economic strategy of export-led industrialisation\n[3][6][7]. To facilitate this strategy, foreign investment is courted through the creation\nof attractive incentive packages. These primarily entail taxation allowances and more\nliberal ownership rights for investments [8][10][11]. The quest to attract foreign direct\ninvestment (FDI) has proved to be highly successful [9]. The bulk of investment has\ngone into export-oriented manufacturing industries.\nSeveral specific subsidiary features identified in international business literature are\nparticularly relevant when seeking to explain MNC subsidiary export behaviour. The\nlocation factors in attracting FDI to the country, the subsidiary's functional roles, size\nand age, and whether subsidiary products are targeted at niche or broader markets,\nhave all been perceived to be determinants of export behaviour. This paper is\nconcerned with the manner in which the structure and strategy of MNC that have\ninvested in Malaysia affect the export intensity of their subsidiaries. Prior to going\ninto the details of the study, it is important to explain that there are two related aspects\nof export behaviour. One aspect is the probability of a firm exporting at all. The other\naspect is the relationship between the percentage of total sales exported and the size of\nthe firm. According to the literature, larger firms are more likely to export. However,\n\n\fthere is no clear relationship between size of the firm and export intensity. For\nexample Bonnaccorsi [4] found that although larger firms were more likely to export,\nthere was no significant difference between the export intensity of small, medium, or\nlarge firms. Wolff et al [12] also found no significant difference in export intensity\nbetween small, medium and large firms. They argued that the type of resources\navailable is a key factor, specifically, that with the appropriate type of resource, a\nsmall firm can use the same competitive patterns utilised by larger firms with the\nsame effectiveness. Wagner (2001) notes that greater firm size is neither necessary\nnor sufficient for any industry or country.\nIn this paper we are concentrated on the MCS product manufactured, resources, tax\nprotection, customers and markets, involvement strategy, financial independence and suppliers'\nrelationship with a MNC. We use the EvoNF, an integrated computational framework to\n\noptimise FIS through neural network learning and evolutionary computation [1].\nThe paper is divided as follows: Section 2 explains the role of fuzzy inference\nsystems in determining the export behaviour of MCS. Section 3 illustrates the\nexperimentation results based on data provided by Malaysian MCS. The paper ends\nwith concluding remarks.\n\n2. The Role of FIS for Explaining the Export Behaviour of MCS\nA FIS can utilize human expertise by storing its essential components in rule base and\ndatabase, and perform fuzzy reasoning to infer the overall output value. The\nderivation of if-then rules and corresponding membership functions (MF) depends\nheavily on the researcher's a priori knowledge about the system under consideration.\nHowever, there is no systematic way of transforming experiences of knowledge of\nhuman experts to the knowledge base of a FIS. There is also a need for adaptability or\nsome learning algorithms to produce outputs within the required error rate [2].\nIn this section, we define the architecture of EvoNF, as an integrated computational\nframework to optimise FIS by using neural network learning technique and\nevolutionary computation. The proposed framework could adapt to Mamdani, TakagiSugeno or other FIS. The architecture and the evolving mechanism can be considered\nas general framework for adaptive fuzzy systems. That is a FIS can change their MF\n(quantity and shape), rule base (architecture), fuzzy operators and learning parameters\naccording to different environments without human intervention.\nSolving multi-objective problems is, generally, a very difficult goal. In optimisation\nproblems, the objectives often conflict across a high-dimension problem space and\nmay also require extensive computational resources. The hierarchical evolutionary\nsearch framework could adapt MF (shape and quantity), rule base (architecture),\nfuzzy inference mechanism (T-norm and T-conorm operators) and the learning\nparameters of neural network learning algorithm. In addition to the evolutionary\nlearning (global search) neural network learning could be considered as a local search\ntechnique to optimise the parameters of the rule antecedent/consequent parameters\nand the parameterised fuzzy operators.\nFigure 1 illustrates the interaction of various evolutionary search procedures. For\nevery type of FIS (for example Mamdani type), there exist a global search of learning\n\n\falgorithm parameter, inference mechanism, rule base and MF in an environment\ndecided by the problem. Thus the evolution of FIS will evolve at the slowest time\nscale while the evolution of the quantity and type of MF will evolve at the fastest rate.\nThe function of the other layers could be derived similarly.\n\nFigure 1. General computational framework for EvoNF\nHierarchy of the different adaptation layers (procedures) will rely on the prior\nknowledge. For example, if there is more prior knowledge about the architecture than\nthe inference mechanism then it is better to implement the architecture at a higher\nlevel. If we know that a particular FIS will suit best for the problem, we could also\nminimize the search space. For fine-tuning the FIS all the node functions are to be\nparameterised.\n2.1 Parameterization of Membership Functions\nFIS is completely characterized by its MF For example, a generalized bell MF is\nspecified by three parameters (p, q, r) and is given by:\n1\nBell (x, p, q, r) =\n2q\nx-r\n1+\np\nFigure 2 shows the effects of changing p, q and r in a bell MF. Similar\nparameterisation can be done with most of the other MF.\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 2. (a) Changing parameter p (b) changing parameter q (c) changing parameter\nr (d) changing p and q\n\n\f2.2 Parameterization of T-norm operators\nT-norm is a fuzzy intersection operator, which aggregates the intersection of two\nfuzzy sets A and B. The Schweizer and Sklar'\ns T-norm operator can be expressed as:\n\n[ {\n\n}]\n\nT (a, b, p) = max 0, (a \u2212 p + b \u2212 p \u2212 1)\n\n\u2212\n\n1\np\n\nIt is observed that\n\nlim p \u2192 0 T (a, b, p) = ab\nlim p \u2192 \u221e T ( a.b, p ) = min{a, b}\nwhich correspond to two of the most frequently used T-norms in combining the\nmembership values on the premise part of a fuzzy if-then rule.\n\nFigure 3. Effects of changing p of T-norm operator for two Bell MF\nTo give a general idea of how the parameter p affects the T-norm operator, Figure 3\nillustrates T-norm operator T(a,b,p) for different values of p.\n2.3 Chromosome Modeling and Representation\nThe antecedent of a fuzzy rule defines a local region, while the consequent the\nbehaviour within the region via various constituents. Basically the antecedent part\nremains the same regardless of the inference system used. Different consequent\ndescribes constituents result in different FIS. For applying evolutionary algorithms,\nproblem representation (chromosome) is very important as it directly affects the\nproposed algorithm. Referring to Figure 1 each layer (from fastest to slowest) of the\nhierarchical evolutionary search process has to be represented in a chromosome for\nsuccessful modeling of EvoNF. A typical chromosome of the EvoNF would appear as\nshown in Figure 5 and the detailed modeling process is as follows.\nLayer 1: The simplest way is to encode the number of MF per input variable and\nthe parameters of the MF. Figure 5 depicts the chromosome representation of n bell\nMF specified by its parameters p, q and r. The optimal parameters of the MF located\nby the evolutionary algorithm will be later fine tuned by the neural network-learning\nalgorithm. Similar strategy could be used for the output MF in the case of a Mamdani\nFIS. Experts may be consulted to estimate the MF shape forming parameters to\nestimate the search space of the MF parameters.\n\n\fFuzzy inference system\n\nParameters of learning algorithm\n\nFuzzy operators\n\nFuzzy rules\n\nFuzzy membership functions\n\nFigure 4. Chromosome structure of the EvoNF model\nMFn\n\nMF1\np1\n\nq1\n\nr1\n\npn\n\n........\n\nqn\n\nrn\n\nFigure 5. Chromosome representing n MF for every input/output variable coding the\nparameters of a bell shape MF\np1 = 4\n\n1\n\n2\n\n3\n\n0\n\n1\n\n1\n\ninput variables\n\np 1=-71.560\n\n1\n\n(a)\n\n0\n\nm-1\n\nm\n\n1\n\n0\n\n(b)\n\np 1 = 760\n\np1 = - 3\n\nm-2\n........\n\n0\n\n1\n\n1\n\n1\n\noutput variable\n0\n\n1\n\n1\n\n0\n\n1\n\n( c)\n\nFigure 6. (a) Angular coding technique (b) representation of m fuzzy rules (c)\nrepresentation of I/O variables\nWe used the angular coding method proposed by [5] for representing the rule\nconsequent parameters of the Takagi-Sugeno inference system. Rather than directly\ncoding the consequent parameters, the \"transformed\" parameters represent the\ndirection of the tangent i = arctan pi. The range for the parameters i is the interval (900, +900), such that the parameters pi can assume any real value. A single input\nTakagi-Sugeno system Y = p1 X + p0 defines a straight line. The real value p1 is\nsimply the gradient between this line and the X-axis. Parameter p0 determines the\noffset of the straight line (intercept) along the Y-axis. The procedure is illustrated in\nFigure 6.\n\n\fLayer 2. This layer is responsible for the optimisation of the rule base. This\nincludes deciding the total number of rules, representation of the antecedent and\nconsequent parts. The simplest way is that each gene represents one rule, and \"1\"\nstands for a selected and \"0\" for a non-selected rule. Figure 6 (b) displays such a\nchromosome structure representation. To represent a single rule a position dependent\ncode with as many elements as the number of variables of the system is used. Each\nelement is a binary string with a bit per fuzzy set in the fuzzy partition of the variable,\nmeaning the absence or presence of the corresponding linguistic label in the rule. For\na three input and one output variable, with fuzzy partitions composed of 3,2,2 fuzzy\nsets for input variables and 3 fuzzy sets for output variable, the fuzzy rule will have a\nrepresentation as shown in Figure 6(c).\nLayer 3. In this layer, a chromosome represents the different parameters of the Tnorm and T-conorm operators. Real number representation is adequate to represent\nthe fuzzy operator parameters. The parameters of the operators could be fine- tuned\nusing gradient descent techniques.\nLayer 4. This layer is responsible for the selection of optimal learning parameters.\nPerformance of the gradient descent algorithm directly depends on the learning rate\naccording to the error surface. The optimal learning parameters decided by the\nevolutionary algorithm will be used to tune MF and the inference mechanism.\nLayer 5. This layer basically interacts with the environment and decides which FIS\n(Mamdani type and its variants, Takagi-Sugeno type, Tsukamoto type etc.) will be the\noptimal according to the environment. Once the chromosome representation, C, of the\nentire EvoNF model is done, the evolutionary search procedure could be initiated as\nfollows:\n1.\n2.\n3.\n4.\n5.\n\nGenerate an initial population of N numbers of C chromosomes. Evaluate the\nfitness of each chromosome depending on the problem.\nDepending on the fitness and using suitable selection methods reproduce a\nnumber of children for each individual in the current generation.\nApply genetic operators to each child individual generated above and obtain\nthe next generation.\nCheck whether the current model has achieved the required error rate or the\nspecified number of generations has been reached. Go to Step 2.\nEnd\n\n3. Model Evaluation and Experimentation Results\nFor simulations we have used data provided from a survey of 69 Malaysian MCS.\nEach corporation subsidiary data set were represented by the following input\nvariables:\n\u2022 Product manufactured (1 -5 scale representing fully independent from the\nparent and fully dependent)\n\u2022 Resources (1 - 5 scale representing fully independent from the parent and fully\ndependent)\n\n\f\u2022\n\u2022\n\u2022\n\u2022\n\nTax protection (1 - 5 scale representing tax protection and no tax protection)\nCustomers and market (1 - 4 scale representing the geographical distribution of\nthe customers)\nInvolvement strategy (1 - 4 scale representing subsidiary, subsidiary and parent,\nparent alone and equal share)\nFinancial independence (1-5 scale representing fully independent from the\nparent and fully dependent)\nSuppliers relationship (1 - 5 scale representing fully independent from the\nparent and fully dependent)\n\n3.1 EvoNF training\nWe used the popular grid partitioning method (clustering) to generate the initial rule\nbase. This partition strategy requires only a small number of MF for each input. We\nused the 90% of the data for training and remaining 10% for testing and validation\npurposes. The initial populations were randomly created based on the parameters\nshown in Table 1. We used a special mutation operator, which decreases the mutation\nrate as the algorithm greedily proceeds in the search space 0. If the allelic value xi of\nthe i-th gene ranges over the domain ai and bi the mutated gene x'i is drawn randomly\nuniformly from the interval [ai , bi].\nxi + \u2206(t , bi \u2212 xi ), if \u03c9 = 0\nxi'=\nxi + \u2206(t , xi \u2212 ai ), if \u03c9 = 1\n\nwhere \u03c9 represents an unbiased coin flip p( \u03c9 =0) = p( \u03c9 =1) = 0.5, and\n\u2206 (t , x ) = x 1 \u2212 \u03b3\n\n1\u2212\n\nt\n\nb\n\nt max\n\ndefines the mutation step, where \u03b3 is the random number from the interval [0,1] and t\nis the current generation and tmax is the maximum number of generations. The function\n\u2206 computes a value in the range [0,x] such that the probability of returning a number\nclose to zero increases as the algorithm proceeds with the search. The parameter b\ndetermines the impact of time on the probability distribution \u2206 over [0,x]. Large\nvalues of b decrease the likelihood of large mutations in a small number of\ngenerations. The parameters mentioned in Table 1 were decided after a few trial and\nerror approaches. Experiments were repeated 3 times and the average performance\nmeasures are reported. Figures 10 illustrates the meta-learning approach for training\nand test data combining evolutionary learning and gradient descent technique during\nthe 35 generations.\n\n\fFigure 7. Meta-learning performance (training and test) of EvoNF framework\nThe 35 generations of meta-learning approach created 76 if-then Takagi-Sugeno type\nfuzzy if-then rules compared to 128 rules using the grid-partitioning method. We also\nused a feed forward neural network with 12 hidden neurons (single hidden layer) to\nmodel the export output for the given input variables. The learning rate and\nmomentum were set at 0.05 and 0.2 respectively and the network was trained for\n10,000 epochs using BP [2]. The network parameters were decided after a trial and\nerror approach. The obtained training and test results are depicted in Table 2\n(CC=correlation coefficient).\nTable 1. Parameter settings of EvoNF framework\nPopulation size\nMaximum no of generations\nFIS\nRule antecedent MF\nRule consequent parameters\nGradient descent learning\nRanked based selection\nElitism\nStarting mutation rate\n\n40\n35\nTakagi Sugeno\n2 MF (parameterised Gaussian)/ Input\nLinear parameters\n10 epochs\n0.50\n5%\n0.50\n\nTable 2. Training and test performance of the different intelligent paradigms\nIntelligent paradigms\nExport\noutput\n\nEvoNF\nRMSE\nTrain\nTest\n0.0013\n\n0.012\n\n*CC\n0.989\n\nNeural network\nRMSE\nTrain\nTest\n0.0107\n\n0.1261\n\n*CC\n0.946\n\n\fFigure 8. Test results showing the export output (scaled values) for 13 MNC's with\nrespect to the desired values (*).\n\n4. Conclusions\nOur analysis on the export behavior of Malaysia's MCS reveals that the developed\nEvoNF model could learn the chaotic patterns and model the behavior using an\noptimized Takagi Sugeno FIS. As illustrated in Figure 8 and Table 2, EvoNF could\neasily approximate the export behavior within the tolerance limits. When compared to\na neural network approach, EvoNF performed better (in terms of lowest RMSE) and\nbetter correlation coefficient. Our experiment results also reveal the importance of all\nthe key input variables to model the behavior within the required accuracy limits.\nThese techniques might be useful not only to MNC's but also to administrators and\nGovernment for long-term strategic management of the economy.\nAs a future research, we also plan to incorporate more intelligent paradigms to\nimprove the modeling aspects of the export behavior.\n\nReferences\n1.\n\nAbraham, A. (2002), EvoNF: A Framework for Optimization of Fuzzy Inference\nSystems Using Neural Network Learning and Evolutionary Computation, In\nProceedings of 17th IEEE International Symposium on Intelligent Control,\nISIC'\n02, IEEE Press, pp 327-332, 2002\n\n2.\n\nAbraham, A. (2001), Neuro-Fuzzy Systems: State-of-the-art Modelling\nTechniques, Lecture Notes in Computer Science. Volume. 2084, Springer-Verlag\nGermany, Jose Mira and Alberto Prieto (Eds.), ISBN 3540422358, Granada,\nSpain, pp. 269-276.\n\n\f3.\n\nAriff, M. and Hill, H (1985) Export-Oriented Industrialisation: The ASEAN\nExperience, Allen and Unwin, Sydney.\n\n4.\n\nBonnaccorsi, A. (1992) On the Relationship between Firm Size and Export\nIntensity, Journal of International Business Studies, XXIII( 4)\" 605-635.\n\n5.\n\nCord\u00f3n O., Herrera F., Hoffmann F. and Magdalena L. (2001), Genetic Fuzzy\nSystems: Evolutionary Tuning and Learning of Fuzzy Knowledge Bases, World\nScientific Publishing Company, Singapore.\n\n6.\n\nDoraisami, A. (1996) Malaysia, in R. Edwards and M. Skully (eds.) ASEAN\nBusiness Trade and Development: An Australian Perspective, Butterworth\nHeinemann, Sydney.\n\n7.\n\nGomez, E.T. and Jomo, K.S. (1997) Malaysia's Political Economy: Politics,\nPatronage and Profits, Cambridge University Press, Cambridge.\n\n8.\n\nGovernment of Malaysia (1999) Malaysian Investment in the Manufacturing\nSector Policies, Incentives and Facilities.\n\n9.\n\nLyles, M. Sulaiman, M., Barden, J. and Kechik, A. (1999) Factors Affecting\nInternational Joint Ventures Performance: A Study of Malaysian Joint Ventures,\nInternational Business Review, XV (2): 1-20.\n\n10. Tan Ser Kiat (1999) Malaysia: Foreign Investment Policy\n11. http://www.malaysianlaw.com <accessed on 03 March 2003>\n12. Wolff, J. A. & Pett, T.L (2000), Internationalization of small firms: An\nexamination of export competitive patterns, firm size, and export performance.\nJournal of Small Business Management, 38 (2), pp. 34-47.\n\n\f"}