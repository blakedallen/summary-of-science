{"id": "http://arxiv.org/abs/physics/0409127v1", "guidislink": true, "updated": "2004-09-24T14:34:18Z", "updated_parsed": [2004, 9, 24, 14, 34, 18, 4, 268, 0], "published": "2004-09-24T14:34:18Z", "published_parsed": [2004, 9, 24, 14, 34, 18, 4, 268, 0], "title": "Probabilistic forecasting of temperature: comments on the Bayesian Model\n  Averaging approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=physics%2F0409117%2Cphysics%2F0409150%2Cphysics%2F0409142%2Cphysics%2F0409054%2Cphysics%2F0409003%2Cphysics%2F0409026%2Cphysics%2F0409008%2Cphysics%2F0409114%2Cphysics%2F0409121%2Cphysics%2F0409101%2Cphysics%2F0409032%2Cphysics%2F0409001%2Cphysics%2F0409074%2Cphysics%2F0409143%2Cphysics%2F0409131%2Cphysics%2F0409064%2Cphysics%2F0409103%2Cphysics%2F0409042%2Cphysics%2F0409049%2Cphysics%2F0409045%2Cphysics%2F0409020%2Cphysics%2F0409082%2Cphysics%2F0409104%2Cphysics%2F0409140%2Cphysics%2F0409021%2Cphysics%2F0409146%2Cphysics%2F0409128%2Cphysics%2F0409135%2Cphysics%2F0409111%2Cphysics%2F0409119%2Cphysics%2F0409094%2Cphysics%2F0409063%2Cphysics%2F0409127%2Cphysics%2F0409007%2Cphysics%2F0409092%2Cphysics%2F0409025%2Cphysics%2F0409088%2Cphysics%2F0409115%2Cphysics%2F0409005%2Cphysics%2F0409098%2Cphysics%2F0409016%2Cphysics%2F0409077%2Cphysics%2F0409031%2Cphysics%2F0409087%2Cphysics%2F0409091%2Cphysics%2F0409079%2Cphysics%2F0409112%2Cphysics%2F0409047%2Cphysics%2F0409041%2Cphysics%2F0409154%2Cphysics%2F0409096%2Cphysics%2F0409136%2Cphysics%2F0409081%2Cphysics%2F0409023%2Cphysics%2F0409059%2Cphysics%2F0409043%2Cphysics%2F0409039%2Cphysics%2F0409080%2Cphysics%2F0409093%2Cphysics%2F0409158%2Cphysics%2F0409071%2Cphysics%2F0409056%2Cphysics%2F0409053%2Cphysics%2F0409102%2Cphysics%2F0409002%2Cphysics%2F0409044%2Cphysics%2F0409159%2Cphysics%2F0409024%2Cphysics%2F0409109%2Cphysics%2F0409152%2Cphysics%2F0409106%2Cphysics%2F0409095%2Cphysics%2F0409137%2Cphysics%2F0409153%2Cphysics%2F0409120%2Cphysics%2F0409015%2Cphysics%2F0409099%2Cphysics%2F0409133%2Cphysics%2F0409010%2Cphysics%2F0409123%2Cphysics%2F0409029%2Cphysics%2F0409075%2Cphysics%2F0409011%2Cphysics%2F0409138%2Cphysics%2F0409046%2Cphysics%2F0409051%2Cphysics%2F0409089%2Cphysics%2F0409017%2Cphysics%2F0409090%2Cphysics%2F0409151%2Cphysics%2F0409122%2Cphysics%2F0409116%2Cphysics%2F0409149%2Cphysics%2F0409062%2Cphysics%2F0409134%2Cphysics%2F0409058%2Cphysics%2F0409084%2Cphysics%2F0409100%2Cphysics%2F0409066%2Cphysics%2F0409126%2Cphysics%2F0409072&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Probabilistic forecasting of temperature: comments on the Bayesian Model\n  Averaging approach"}, "summary": "A specific implementation of Bayesian model averaging has recently been\nsuggested as a method for the calibration of ensemble temperature forecasts. We\npoint out the similarities between this new approach and an earlier method\nknown as kernel regression. We also argue that the Bayesian model averaging\nmethod (as applied) has a number of flaws that would result in forecasts with\nsuboptimally calibrated mean and uncertainty.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=physics%2F0409117%2Cphysics%2F0409150%2Cphysics%2F0409142%2Cphysics%2F0409054%2Cphysics%2F0409003%2Cphysics%2F0409026%2Cphysics%2F0409008%2Cphysics%2F0409114%2Cphysics%2F0409121%2Cphysics%2F0409101%2Cphysics%2F0409032%2Cphysics%2F0409001%2Cphysics%2F0409074%2Cphysics%2F0409143%2Cphysics%2F0409131%2Cphysics%2F0409064%2Cphysics%2F0409103%2Cphysics%2F0409042%2Cphysics%2F0409049%2Cphysics%2F0409045%2Cphysics%2F0409020%2Cphysics%2F0409082%2Cphysics%2F0409104%2Cphysics%2F0409140%2Cphysics%2F0409021%2Cphysics%2F0409146%2Cphysics%2F0409128%2Cphysics%2F0409135%2Cphysics%2F0409111%2Cphysics%2F0409119%2Cphysics%2F0409094%2Cphysics%2F0409063%2Cphysics%2F0409127%2Cphysics%2F0409007%2Cphysics%2F0409092%2Cphysics%2F0409025%2Cphysics%2F0409088%2Cphysics%2F0409115%2Cphysics%2F0409005%2Cphysics%2F0409098%2Cphysics%2F0409016%2Cphysics%2F0409077%2Cphysics%2F0409031%2Cphysics%2F0409087%2Cphysics%2F0409091%2Cphysics%2F0409079%2Cphysics%2F0409112%2Cphysics%2F0409047%2Cphysics%2F0409041%2Cphysics%2F0409154%2Cphysics%2F0409096%2Cphysics%2F0409136%2Cphysics%2F0409081%2Cphysics%2F0409023%2Cphysics%2F0409059%2Cphysics%2F0409043%2Cphysics%2F0409039%2Cphysics%2F0409080%2Cphysics%2F0409093%2Cphysics%2F0409158%2Cphysics%2F0409071%2Cphysics%2F0409056%2Cphysics%2F0409053%2Cphysics%2F0409102%2Cphysics%2F0409002%2Cphysics%2F0409044%2Cphysics%2F0409159%2Cphysics%2F0409024%2Cphysics%2F0409109%2Cphysics%2F0409152%2Cphysics%2F0409106%2Cphysics%2F0409095%2Cphysics%2F0409137%2Cphysics%2F0409153%2Cphysics%2F0409120%2Cphysics%2F0409015%2Cphysics%2F0409099%2Cphysics%2F0409133%2Cphysics%2F0409010%2Cphysics%2F0409123%2Cphysics%2F0409029%2Cphysics%2F0409075%2Cphysics%2F0409011%2Cphysics%2F0409138%2Cphysics%2F0409046%2Cphysics%2F0409051%2Cphysics%2F0409089%2Cphysics%2F0409017%2Cphysics%2F0409090%2Cphysics%2F0409151%2Cphysics%2F0409122%2Cphysics%2F0409116%2Cphysics%2F0409149%2Cphysics%2F0409062%2Cphysics%2F0409134%2Cphysics%2F0409058%2Cphysics%2F0409084%2Cphysics%2F0409100%2Cphysics%2F0409066%2Cphysics%2F0409126%2Cphysics%2F0409072&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A specific implementation of Bayesian model averaging has recently been\nsuggested as a method for the calibration of ensemble temperature forecasts. We\npoint out the similarities between this new approach and an earlier method\nknown as kernel regression. We also argue that the Bayesian model averaging\nmethod (as applied) has a number of flaws that would result in forecasts with\nsuboptimally calibrated mean and uncertainty."}, "authors": ["Stephen Jewson"], "author_detail": {"name": "Stephen Jewson"}, "author": "Stephen Jewson", "links": [{"href": "http://arxiv.org/abs/physics/0409127v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/physics/0409127v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "physics.ao-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "physics.ao-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/physics/0409127v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/physics/0409127v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:physics/0409127v1 [physics.ao-ph] 24 Sep 2004\n\nProbabilistic forecasting of temperature: comments on the\nBayesian Model Averaging approach\nStephen Jewson\u2217\nNovember 13, 2018\n\nAbstract\nA specific implementation of Bayesian model averaging has recently been suggested as a method\nfor the calibration of ensemble temperature forecasts. We point out the similarities between this new\napproach and an earlier method known as kernel regression. We also argue that the Bayesian model\naveraging method (as applied) has a number of flaws that would result in forecasts with suboptimally\ncalibrated mean and uncertainty.\n\n1\n\nIntroduction\n\nThere is significant demand within industry for adequate probabilistic forecasts of temperature. However,\nthis demand has not been met by the meteorological community and such forecasts are not commercially\navailable. A small number of forecast vendors do produce probabilistic forecasts but the calibration methods they use are flawed. A number of academic papers have suggested methods by which such forecasts\ncould be improved but again the methods described are flawed. To attempt to remedy this situation we\nrun a program of research aimed at clarifying the issues involved in the creation of probabilistic temperature forecasts and at developing methods that can be used to produce such forecasts. We are not\nforecasters ourselves: our hope is that the forecasting community will use the methods we describe to\nproduce forecasts that we can then use in our industrial applications.\nThis article discusses a new method with the name Bayesian model averaging (BMA) that has recently\nbeen proposed for the calibration of temperature forecast ensembles (see Raftery et al. (2003)). Our\npurpose is twofold:\n1. To point out the close connections between BMA and earlier methods known as kernel regression\n(KR) and kernel spread regression (KSR)\n2. To describe a number of flaws that we believe that the BMA approach suffers from that render it\ninappropriate as a method to be used for the calibration of real forecast data\nWe start by describing the KR and BMA approaches. We then compare the two and point out the\nproblems we see in BMA. Finally we suggest some further methods that take features from both BMA\nand KR that could be used to solve the calibration problem that is discussed in Raftery et al. (2003).\n\n2\n\nKernel Regression\n\nKernel regression (KR) was described by us in Jewson (2003). It is a method that takes an ensemble\nforecast and turns it into a probabilistic forecast. The simplest reasonable way to do this is to use\nlinear regression on the ensemble mean. KR is a simple extension of linear regression that allows for the\nrepresentation of non-normality in the temperature distribution by putting a small kernel of optimum\nwidth around each ensemble member. The probability density forecast from KR can be written as:\np(x) =\n\nM\nX\n\npi (x)\n\n(1)\n\ni=1\n\nwhere the pi are the individual kernels given by\npi (x) \u223c N (xi , \u03bb2 )\n\u2217 Correspondence\n\naddress: RMS, 10 Eastcheap, London, EC3M 1AJ, UK. Email: x@stephenjewson.com\n\n(2)\n\n\fwhere xi is the i'th ensemble member and \u03bb is the bandwidth (these equations come from equation 1\nin Jewson (2003)).\nIn addition to applying kernels in this way the mean and the variance of the ensemble members are\ncalibrated using linear regression. We write the complete model as:\nTi \u223c K(\u03b1 + \u03b2mi , \u03b3, \u03bb)\n\n(3)\n\nKR calibrates the ensemble mean using linear regression (which gives an optimal combination between\nthe ensemble mean and climatology) and fixes the spread and the non-normality using the parameters \u03b3\nand \u03bb. The parameter \u03bb is the bandwidth of the kernels used and controls the smoothness of the final\npredicted distribution. Small values of \u03bb lead to a multimodal distribution while large values of \u03bb lead\nto a unimodal smooth distribution.\nThe mean of the prediction from KR is given by:\nE(x) = \u03b1 + \u03b2mi\n\n(4)\n\nwhile the variance of the prediction, which is constant in time for the anomalies, is given by:\n\nvar(x)\n\n=\n\nM\n1 X\n(xi \u2212 \u03bc)2\n\u03bb +\nM i=1\n\n=\n\n\u03bb2 + \u03b3 2\n\n2\n\n(5)\n\nor\nvariance of modelled temperatures = \u03bb2 + sample variance of calibrated ensemble members\n\n(6)\n\n(this equation is equation 9 in Jewson (2003)).\nAn extension of KR that allows for the uncertainty to vary in time according to variations in the ensemble\nspread is also described Jewson (2003), and can be written as\nTi \u223c K(\u03b1 + \u03b2mi , \u03b3 + \u03b4si , \u03bb)\n\n(7)\n\nThis model, known as kernel spread regression (KSR), calibrates the ensemble spread by having separate\nparameters for the mean and the variance of the spread. This was shown to be necessary in Jewson et al.\n(2003).\nThe predicted variance from KSR is:\nvar(x)\n\n3\n\nM\n1 X\n(xi \u2212 \u03bc)2\nM i=1\n\n=\n\n\u03bb2 +\n\n=\n\n\u03bb2 + (\u03b3 + \u03b4si )2\n\n(8)\n\nBayesian model averaging\n\nBMA is a general approach for combining the results from several statistical models using weights (Hoeting et al.,\n1999). There are a number of ways that BMA could be used in the creation of probabilistic forecasts.\nWe will discuss the particular application of BMA given in Raftery et al. (2003). The conclusions we will\ndraw do not apply to BMA in general, but only to this particular way of using BMA.\nThe suggestion in Raftery et al. (2003) is that the probability density of future temperatures can be\nmodelled as a weighted sum of a number of probability densities from different sources:\np(x) =\n\ni=M\nX\n\nwi gi (x)\n\n(9)\n\ni=1\n\nwhere\ngi (x) \u223c N (xi , \u03c3i2 )\n\n(10)\n\nwhere xi are the ensemble members (these equations are equations 2 and 3 from Raftery et al. (2003),\nwritten in our notation).\nThe variance of the probabilistic forecast is then given by\nvar(x) =\n\nM\nX\ni=1\n\n(this is equation 7 from Raftery et al. (2003)).\n\nwi (xi \u2212 \u03bc)2 +\n\nM\nX\ni=1\n\nwi \u03c3i2\n\n(11)\n\n\f4\n\nThe connection between BMA and KR\n\nWe now consider how BMA and KR are related. To see the connection we consider a case where the\nindividual forecasts are statistically identical. BMA also considers the more general case where the\nforecasts are statistically different although we will argue that since it doesn't work in the simplest case\nof identical members it certainly can't be expected to work in the more complex cases.\nIf the forecasts are statistically identical then we can assume that the BMA weights and \u03c3i 's are equal:\n\nwi\n\u03c3i\n\n1\nM\n= \u03c3\n\n=\n\n(12)\n(13)\n\nEquation 9 now gives:\np(x) =\n\ni=M\nX\ni=1\n\n1\ngi (x)\nM\n\n(14)\n\nand we can see that this agrees with equation 1 if we define gi (x) = M pi (x) i.e. if we normalise the kernels\ndifferently. So this part of the two models is the same up to a simple definition of the normalisation.\nThe BMA predicted mean is just\nM\nX\nxi\n(15)\nE(x) =\ni=1\n\ni.e. the ensemble mean, and the BMA predicted variance is\nvar(x) =\n\nM\nX\n1\n(xi \u2212 \u03bc)2 + \u03c3 2\nM\ni=1\n\n(16)\n\nWe can now see the similarities and differences between BMA and kernel regression very clearly.\n1. By comparing equation 4 with equation 15 we see that BMA predicts the expected temperature using the ensemble mean while KR predicts the expected temperature using an optimum combination\nof the ensemble mean with climatology\n2. By comparing equations 5 and 8 with equation 16 we see that BMA calibrates the mean level of\nuncertainty, the variability of the uncertainty and the smoothness of the distribution using a single\nparameter \u03c3. KR uses two parameters to calibrate the mean level of uncertainty and the smoothness\nwhile KSR uses three parameters to calibrate the mean level of uncertainty, the variability of the\nuncertainty and the smoothness.\nBMA (when applied to the identical members case) is a special case of KSR in which \u03b2 = 1, \u03b3 = 0 and\n\u03b4 = 1.\n\n5\n\nThe problems with BMA\n\nUnfortunately Bayesian model averaging seems to suffer from a number of flaws as a method for calibrating\ntemperature ensembles. These issues discussed below: the research on which these conclusions are based\nis summarised in Jewson (2004).\nThe first problem concerns the calibration of the ensemble mean. In the special case that we are considering BMA predicts the expected temperature using the ensemble mean. However it is well documented\n(Leith (1974), von Storch and Zwiers (1999), Jewson and Ziehmann (2003)) that the ensemble mean is\nnot the optimal forecast for the expected temperature: a 'damped' version of the ensemble mean calculated using linear regression is better. This damping performs an optimal calibration of the ensemble\nmean with climatology. An undamped ensemble mean such as that produced by BMA does not have the\ncorrect variance and will not minimise RMSE.\nThe second problem concerns the calibration of the uncertainty. To correctly calibrate the uncertainty of\na probabilistic forecast one needs to consider (at least) two operations. First, the temporal mean of the\nuncertainty must be fixed at an appropriate level. There is no information about the temporal mean of\nthe uncertainty in the ensemble itself: this information can only come from past forecast error statistics.\nSecondly, the amplitude of the variability of the uncertainty must be fixed at an appropriate level. Again,\n\n\fthere is no information about the amplitude of the variability of the uncertainty in the ensemble itself:\nthis must be fitted from past forecast error statistics too. What the ensemble provides is then the relative\namplitude and phase of the fluctuations of the uncertainty.\nThe important point is that these two calibration steps (calibrating the mean and the amplitude of the\nvariability of the spread) are independent. To set the mean level of the uncertainty correctly one typically\nneeds to inflate the ensemble spread. However, to set the amplitude of the variations in the uncertainty\ncorrectly one may need to reduce the amplitude of the variations in the ensemble spread. A statistical\nmodel thus needs at least two parameters in order to calibrate spread correctly. If only one parameter is\navailable, the calibration of the mean and the variability of the uncertainty will be mixed together, and\nthe results will be somewhat arbitrary and very possibly less good than a calibration method that ignores\nthe variability in the ensemble spread altogether. This mixing of different aspects of the calibration is\nwhat happens in BMA1 .\nKR, KSR and BMA add another operation in the calibration of the ensemble, which is the smoothing of\nthe ensemble towards or away from a normal distribution. If the bandwidth of the kernel (\u03bb in kernel\nregression and \u03c3 in BMA) is large then the ensemble is smoothed towards a normal while if the bandwidth\nis small the probability forecast will likely be rather multimodal and will have a shape that depends more\nstrongly on the distribution of the individual ensemble members. This smoothing operation needs a\nseparate parameter to be performed correctly as it is an independent issue from the calibration of the\nuncertainty. KR and KSR use a separate parameter for this step while BMA uses the same parameter\nas is used to calibrate the uncertainty.\nIn summary BMA only has a single free parameter (\u03c3) rather than the three that are required to perform\nthe calibration that is being attempted. Thus the three operations that are being performed (calibration\nof the mean level of the uncertainty, calibration of the variability of the uncertainty and calibration of the\nsmoothness of the forecast distribution) are mixed together. It is easy to imagine situations in which this\nwould cause problems. For instance it would not be possible for BMA to correctly calibrate an ensemble\nfor which the variability in the ensemble spread contains very little information (requiring a large value\nof \u03c3) but in which the temporal mean of the ensemble spread is close to the correct level (requiring a\nsmall value of \u03c3). Nor would it be possible for BMA to correctly calibrate an ensemble for which the\nensemble spread was larger than the actual uncertainty.\n\n6\n\nThe solution\n\nThe solution to this problem is to use the correct number of free parameters for the calibration that is\nbeing attempted. Given only a single parameter the most sensible course of action seems to be to assume\na normal distribution, ignore the variations in spread and use the parameter to represent the mean level\nof uncertainty. Given two parameters one should calibrate the mean and variability of the uncertainty,\nwhile still assuming a normal distribution. Finally given three parameters one can calibrate all three of\nthe mean level of uncertainty, the variability of the uncertainty and the smoothness.\n\n7\n\nWeighted kernel regression\n\nIn Raftery et al. (2003) BMA was used to combine a number of forecasts that were not statistically\nidentical. We have argued that BMA does not calibrate correctly in the statistically identical case, and\nso cannot be expected to work in more general cases either. How, then, should the original calibration\nproblem described in Raftery et al. (2003) be solved? The kernel regression models should not be used\nas is since they assume that the forecasts are statistically identical.\nOne can imagine methods that take the best of the KSR and BMA approaches that might include one\nor more of the following features:\n\u2022 the mean is predicted using multiple linear regression on the anomalies\n\u2022 kernels with different widths are used on each ensemble member\n\u2022 the kernels could be combined with different weights\n\u2022 the uncertainty is predicted using some linear function on the weight ensemble spread\n1 and\n\nto be fair we should note that this problem also arises in other forecast calibration methods that have been suggested\nin the academic literature such as the methods of Roulston and Smith (2003) and Mylne et al. (2002)\n\n\fHowever, our previous experience of calibration suggests to us that much simpler models might perform\njust as well since the effects of non-normality and the benefit of using the spread may well both be small.\nIn that case multiple linear regression on the anomalies is probably ideal, and whatever method is being\nused it should be compared with linear regression on the anomalies as an appropriate minimal model.\n\n8\n\nSummary\n\nWe have discussed the question of how to produce probabilistic forecasts of temperature. In particular\nwe have dissected the Bayesian model averaging approach of Raftery et al. (2003). This approach is very\nsimilar to an earlier approach known as kernel regression (Jewson, 2003). We have argued that BMA does\nnot calibrate temperatures in an appropriate way. Neither the predicted mean nor the predicted variance\nare constructed accurately. With respect to the predicted mean, the issue of 'damping' towards climatology has been omitted. With respect to the variance, BMA mixes the separate functions of calibrating the\nmean level of uncertainty, the amplitude of the variability of the uncertainty and the smoothness of the\nforecast distribution into a single factor. We conclude that BMA (as applied in Raftery et al. (2003)) is\nnot a calibration method at all, but simply a method to fit a distribution to a set of ensemble members.\nAs such it is more or less the same as the well known kernel density of classical statistics.\n\n9\n\nAcknowledgements\n\nThanks to Christine Ziehmann for interesting discussions on this topic.\n\n10\n\nLegal statement\n\nSJ was employed by RMS at the time that this article was written.\nHowever, neither the research behind this article nor the writing of this article were in the course of his\nemployment, (where 'in the course of their employment' is within the meaning of the Copyright, Designs\nand Patents Act 1988, Section 11), nor were they in the course of his normal duties, or in the course\nof duties falling outside his normal duties but specifically assigned to him (where 'in the course of his\nnormal duties' and 'in the course of duties falling outside his normal duties' are within the meanings of the\nPatents Act 1977, Section 39). Furthermore the article does not contain any proprietary information or\ntrade secrets of RMS. As a result, the author is the owner of all the intellectual property rights (including,\nbut not limited to, copyright, moral rights, design rights and rights to inventions) associated with and\narising from this article. The author reserves all these rights. No-one may reproduce, store or transmit,\nin any form or by any means, any part of this article without the author's prior written permission. The\nmoral rights of the author have been asserted.\nThe contents of this article reflect the author's personal opinions at the point in time at which this article\nwas submitted for publication. However, by the very nature of ongoing research, they do not necessarily\nreflect the author's current opinions. In addition, they do not necessarily reflect the opinions of the\nauthor's employer.\n\nReferences\nJ Hoeting, D Madigan, A Raftery, and C Volinsky. Bayesian model averaging: a tutorial. Statistical\nScience, 14:382\u2013417, 1999.\nS Jewson. Do probabilistic medium-range temperature forecasts need to allow for non-normality?\narXiv:physics/0310060, 2003.\nS Jewson. A summary of our recent research into practical methods for probabilistic temperature forecasting. arxiv:physics/0409096, 2004.\nS Jewson, A Brix, and C Ziehmann. A new framework for the assessment and calibration of ensemble\ntemperature forecasts. Atmospheric Science Letters, 2003.\nS Jewson and C Ziehmann. Weather swap pricing and the optimum size of medium range forecast\nensembles. Weather and Forecasting, 18(4):675\u2013681, 2003.\nC Leith. Theoretical skill of Monte Carlo forecasts. Monthly Weather Review, 102:409\u2013418, 1974.\n\n\fK Mylne, C Woolcock, J Denholm-Price, and R Darvell. Operational calibrated probability forecasts\nfrom the ECMWF ensemble prediction system: implementation and verification. In Preprints of the\nSymposium on Observations, Data Asimmilation and Probabilistic Prediction, pages 113\u2013118. AMS, 1\n2002.\nA Raftery, F Balabdaoui, T Gneiting, and M Polakowski. Using bayesian model averaging to calibrate\nforecast ensembles. University of Washington Department of Statistics Technical Report, 440, 2003.\nM Roulston and L Smith. Combining dynamical and statistical ensembles. Tellus A, 55:16\u201330, 2003.\nH von Storch and F W Zwiers. Statistical Analysis in Climate Research. CUP, 1999.\n\n\f"}