{"id": "http://arxiv.org/abs/1101.2883v1", "guidislink": true, "updated": "2011-01-14T20:09:03Z", "updated_parsed": [2011, 1, 14, 20, 9, 3, 4, 14, 0], "published": "2011-01-14T20:09:03Z", "published_parsed": [2011, 1, 14, 20, 9, 3, 4, 14, 0], "title": "Dueling Algorithms", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1101.5086%2C1101.5681%2C1101.3720%2C1101.0926%2C1101.3718%2C1101.1789%2C1101.5411%2C1101.3145%2C1101.1712%2C1101.4120%2C1101.1405%2C1101.4159%2C1101.5444%2C1101.4759%2C1101.2557%2C1101.1259%2C1101.0919%2C1101.5474%2C1101.4755%2C1101.3886%2C1101.1192%2C1101.3256%2C1101.3092%2C1101.2335%2C1101.2568%2C1101.4577%2C1101.5510%2C1101.0479%2C1101.5965%2C1101.1183%2C1101.0198%2C1101.0364%2C1101.2771%2C1101.0216%2C1101.5076%2C1101.0876%2C1101.4077%2C1101.0417%2C1101.5687%2C1101.1844%2C1101.1671%2C1101.3122%2C1101.4375%2C1101.1918%2C1101.2883%2C1101.4462%2C1101.3677%2C1101.4694%2C1101.5434%2C1101.0222%2C1101.3917%2C1101.3551%2C1101.3127%2C1101.4455%2C1101.5897%2C1101.4690%2C1101.1338%2C1101.0752%2C1101.2580%2C1101.0226%2C1101.2935%2C1101.3440%2C1101.5069%2C1101.4074%2C1101.4493%2C1101.2375%2C1101.1214%2C1101.4520%2C1101.2307%2C1101.3069%2C1101.2713%2C1101.2795%2C1101.0837%2C1101.5311%2C1101.5108%2C1101.4874%2C1101.0539%2C1101.1330%2C1101.1983%2C1101.1978%2C1101.1263%2C1101.1526%2C1101.4735%2C1101.4156%2C1101.3549%2C1101.1417%2C1101.5864%2C1101.2165%2C1101.5168%2C1101.1818%2C1101.4485%2C1101.4241%2C1101.5776%2C1101.5330%2C1101.4689%2C1101.5017%2C1101.3938%2C1101.2330%2C1101.5702%2C1101.0033%2C1101.3607&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Dueling Algorithms"}, "summary": "We revisit classic algorithmic search and optimization problems from the\nperspective of competition. Rather than a single optimizer minimizing expected\ncost, we consider a zero-sum game in which an optimization problem is presented\nto two players, whose only goal is to outperform the opponent. Such games are\ntypically exponentially large zero-sum games, but they often have a rich\ncombinatorial structure. We provide general techniques by which such structure\ncan be leveraged to find minmax-optimal and approximate minmax-optimal\nstrategies. We give examples of ranking, hiring, compression, and binary search\nduels, among others. We give bounds on how often one can beat the classic\noptimization algorithms in such duels.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1101.5086%2C1101.5681%2C1101.3720%2C1101.0926%2C1101.3718%2C1101.1789%2C1101.5411%2C1101.3145%2C1101.1712%2C1101.4120%2C1101.1405%2C1101.4159%2C1101.5444%2C1101.4759%2C1101.2557%2C1101.1259%2C1101.0919%2C1101.5474%2C1101.4755%2C1101.3886%2C1101.1192%2C1101.3256%2C1101.3092%2C1101.2335%2C1101.2568%2C1101.4577%2C1101.5510%2C1101.0479%2C1101.5965%2C1101.1183%2C1101.0198%2C1101.0364%2C1101.2771%2C1101.0216%2C1101.5076%2C1101.0876%2C1101.4077%2C1101.0417%2C1101.5687%2C1101.1844%2C1101.1671%2C1101.3122%2C1101.4375%2C1101.1918%2C1101.2883%2C1101.4462%2C1101.3677%2C1101.4694%2C1101.5434%2C1101.0222%2C1101.3917%2C1101.3551%2C1101.3127%2C1101.4455%2C1101.5897%2C1101.4690%2C1101.1338%2C1101.0752%2C1101.2580%2C1101.0226%2C1101.2935%2C1101.3440%2C1101.5069%2C1101.4074%2C1101.4493%2C1101.2375%2C1101.1214%2C1101.4520%2C1101.2307%2C1101.3069%2C1101.2713%2C1101.2795%2C1101.0837%2C1101.5311%2C1101.5108%2C1101.4874%2C1101.0539%2C1101.1330%2C1101.1983%2C1101.1978%2C1101.1263%2C1101.1526%2C1101.4735%2C1101.4156%2C1101.3549%2C1101.1417%2C1101.5864%2C1101.2165%2C1101.5168%2C1101.1818%2C1101.4485%2C1101.4241%2C1101.5776%2C1101.5330%2C1101.4689%2C1101.5017%2C1101.3938%2C1101.2330%2C1101.5702%2C1101.0033%2C1101.3607&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We revisit classic algorithmic search and optimization problems from the\nperspective of competition. Rather than a single optimizer minimizing expected\ncost, we consider a zero-sum game in which an optimization problem is presented\nto two players, whose only goal is to outperform the opponent. Such games are\ntypically exponentially large zero-sum games, but they often have a rich\ncombinatorial structure. We provide general techniques by which such structure\ncan be leveraged to find minmax-optimal and approximate minmax-optimal\nstrategies. We give examples of ranking, hiring, compression, and binary search\nduels, among others. We give bounds on how often one can beat the classic\noptimization algorithms in such duels."}, "authors": ["Nicole Immorlica", "Adam Tauman Kalai", "Brendan Lucier", "Ankur Moitra", "Andrew Postlewaite", "Moshe Tennenholtz"], "author_detail": {"name": "Moshe Tennenholtz"}, "author": "Moshe Tennenholtz", "arxiv_comment": "26 pages", "links": [{"href": "http://arxiv.org/abs/1101.2883v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1101.2883v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1101.2883v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1101.2883v1", "journal_reference": null, "doi": null, "fulltext": "Dueling algorithms\nNicole Immorlica\u2217\u2020\n\nAdam Tauman Kalai\u2021\nAndrew Postlewaitek\u2020\n\nBrendan Lucier\u00a7\u2020\n\nAnkur Moitra\u00b6 \u2020\n\nMoshe Tennenholtz\u2217\u2217\n\narXiv:1101.2883v1 [cs.GT] 14 Jan 2011\n\nOctober 29, 2018\n\nAbstract\nWe revisit classic algorithmic search and optimization problems from the perspective of\ncompetition. Rather than a single optimizer minimizing expected cost, we consider a zerosum game in which an optimization problem is presented to two players, whose only goal is\nto outperform the opponent. Such games are typically exponentially large zero-sum games, but\nthey often have a rich combinatorial structure. We provide general techniques by which such\nstructure can be leveraged to find minmax-optimal and approximate minmax-optimal strategies.\nWe give examples of ranking, hiring, compression, and binary search duels, among others. We\ngive bounds on how often one can beat the classic optimization algorithms in such duels.\n\n\u2217\n\nDepartment of Electrical Engineering and Computer Science, Northwestern University\nPart of this work was performed while the author was at Microsoft Research\n\u2021\nMicrosoft Research New England\n\u00a7\nDepartment of Computer Science, University of Toronto\n\u00b6\nDepartment of Electrical Engineering and Computer Science, Massachusetts Institute of Technology. Supported\nin part by a Fannie Hurts Fellowship.\nk\nDepartment of Economics, University of Pennsylvania\n\u2217\u2217\nMicrosoft R&D Israel and the Technion, Israel\n\u2020\n\n0\n\n\f1\n\nIntroduction\n\nMany natural optimization problems have two-player competitive analogs. For example, consider the ranking problem of selecting an order on n items, where the cost of searching for a\nsingle item is its rank in the list. Given a fixed probability distribution over desired items, the\ntrivial greedy algorithm, which orders items in decreasing probability, is optimal.\nNext consider the following natural two-player version of the problem, which models a user\nchoosing between two search engines. The user thinks of a desired web page and a query and\nexecutes the query on both search engines. The engine that ranks the desired page higher is chosen by the user as the \"winner.\" If the greedy algorithm has the ranking of pages \u03c91 , \u03c92 , . . . , \u03c9n ,\nthen the ranking \u03c92 , \u03c93 , . . . , \u03c9n , \u03c91 beats the greedy ranking on every item except \u03c91 . We say\nthe greedy algorithm is 1 \u2212 1/n beatable because there is a probability distribution over pages\nfor which the greedy algorithm loses 1 \u2212 1/n of the time. Thus, in a competitive setting, an\n\"optimal\" search engine can perform poorly against a clever opponent.\nThis ranking duel can be modeled as a symmetric constant-sum game, with n! strategies,\nin which the player with the higher ranking of the target page receives a payoff of 1 and the\nother receives a payoff of 0 (in the case of a tie, say they both receive a payoff of 1/2). As in all\nsymmetric one-sum games, there must be (mixed) strategies that guarantee expected payoff of\nat least 1/2 against any opponent. Put another way, there must be a (randomized) algorithm\nthat takes as input the probability distribution and outputs a ranking, which is guaranteed to\nachieve expected payoff of at least 1/2 against any opposing algorithm.\nThis conversion can be applied to any optimization problem with an element of uncertainty.\nSuch problems are of the form minx\u2208X E\u03c9\u223cp [c(x, \u03c9)], where p is a probability distribution over\nthe state of nature \u03c9 \u2208 \u03a9, X is a feasible set, and c : X \u00d7 \u03a9 \u2192 R is an objective function.\nThe dueling analog has two players simultaneously choose x, x\u2032 ; player 1 receives payoff 1 if\nc(x, \u03c9) < c(x\u2032 , \u03c9), payoff 0 if c(x, \u03c9) > c(x\u2032 , \u03c9), payoff 1/2 otherwise, and similarly for player 2.1\nThere are many natural examples of this setting beyond the ranking duel mentioned above.\nFor example, for the shortest-path routing under a distribution over edge times, the corresponding racing duel is simply a race, and the state of nature encodes uncertain edge delays.2 For\nthe classic secretary problem, in the corresponding hiring duel two employers must each select a\ncandidate from a pool of n candidates (though, as standard, they must decide whether or not to\nchoose a candidate before interviewing the next one), and the winner is the one that hires the\nbetter candidate. This could model, for example, two competing companies attempting to hire\nCEOs or two opposing political parties selecting politicians to run in an election; the absolute\nquality of the candidate may be less important than being better than the other's selection.\nIn a compression duel, a user with a (randomly chosen) sample string \u03c9 chooses between two\ncompression schemes based on which one compresses that string better. This setting can also\nmodel a user searching for a file in two competing, hierarchical storage systems and choosing\nthe system that finds the file first. In a binary search duel, a user searches for a random element\nin a list using two different search trees, and chooses whichever tree finds the element faster.\n\nOur contribution. For each of these problems, we consider a number of questions related\nto how vulnerable a classic algorithm is to competition, what algorithms will be selected at\nequilibrium, and how well these strategies at equilibrium solve the original optimization problem.\nQuestion 1. Will players use the classic optimization solution in the dueling setting?\nIntuitively, the answer to this question should depend on how much an opponent can game\nthe classic optimization solution. For example, in the ranking duel an opponent can beat the\ngreedy algorithm on almost all pages \u2013 and even the most oblivious player would quickly realize\nthe need to change strategies. In contrast, we demonstrate that many classic optimization\n1\n\nOur techniques will also apply to asymmetric payoff functions; see Appendix D.\nWe also refer to this as the primal duel because any other duel can be represented as a race with an appropriate\ngraph and probability distribution p, though there may be an exponential blowup in representation size.\n2\n\n1\n\n\fsolutions \u2013 such as the secretary algorithm for hiring, Huffman coding for compression, and\nstandard binary search \u2013 are substantially less vulnerable. We say an algorithm is \u03b2-beatable\n(over distribution p) if there exists a response which achieves payoff \u03b2 against that algorithm\n(over distribution p). We summarize our results on the beatability of the standard optimization\nalgorithm in each of our example optimization problems in the table below:\nOptimization Problem\nRanking\nRacing\nHiring\nCompression\nSearch\n\nUpper Bound\n1 \u2212 1/n\n1\n0.82\n3/4\n5/8\n\nLower Bound\n1 \u2212 1/n\n1\n0.51\n2/3\n5/8\n\nQuestion 2. What strategies do players play at equilibrium?\nWe say an algorithm efficiently solves the duel if it takes as input a representation of the\ngame and probability distribution p, and outputs an action x \u2208 X distributed according to\nsome minmax optimal (i.e., Nash equilibrium) strategy. As our main result, we give a general\nmethod for solving duels that can be represented in a certain bilinear form. We also show how\nto convert an approximate best-response oracle for a dueling game into an approximate minmax\noptimal algorithm, using techniques from low-regret learning. We demonstrate the generality of\nthese methods by showing how to apply them to the numerous examples described above. For\nmany problems we consider, the problem of computing minmax optimal strategies reduces to\nfinding a simple description of the space of feasible mixed strategies (i.e. expressing this set as\nthe projection of a polytope with polynomially many variables and constraints). See [18] for a\nthorough treatment of such problems.\nQuestion 3. Are these equilibrium strategies still good at solving the optimization problem?\nAs an example, consider the ranking duel. How much more time does a web surfer need\nto spend browsing to find the page he is interested in, because more than one search engine is\ncompeting for his attention? In fact, the surfer may be better off due to competition, depending\non the model of comparison. For example, the cost to the web surfer may be the minimum of\nthe ranks assigned by each search engine. And we leave open the tantalizing possibility that\nthis quantity could in general be smaller at equilibrium for two competing search engines than\nfor just one search engine playing the greedy algorithm.\n\nRelated work. The work most relevant to ours is the study of ranking games [4], and\nmore generally the study of social context games [1]. In these settings, players' payoffs are\ntranslated into utilities based on social contexts, defined by a graph and an aggregation function.\nFor example, a player's utility can be the sum/max/min of his neighbors' payoffs. This work\nstudies the effect of social contexts on the existence and computation of game-theoretic solution\nconcepts, but does not re-visit optimization algorithms in competitive settings.\nFor the hiring problem, several competitive variants and their algorithmic implications have\nbeen considered (see, e.g., [10] and the references therein). A typical competitive setting is a\n(general sum) game where a player achieves payoff of 1 if she hires the very best applicant and\nzero otherwise. But, to the best of our knowledge, no one has considered the natural model of\na duel where the objective is simply to hire a better candidate than the opponent. Also related\nto our algorithmic results are succinct zero-sum games, where a game has exponentially many\nstrategies but the payoff function can be computed by a succinct circuit. This general class has\nbeen showed to be EXP-hard to solve [6], and also difficult to approximate [7].\nFinally, we note the line of research on competition among mechanisms, such as the study\nof competing auctions (see e.g. [5, 15, 16, 17]) or schedulers [2]. In such settings, each player\nselects a mechanism and then bidders select the auction to participate in and how much to bid\nthere, where both designers and bidders are strategic. This work is largely concerned with the\nexistence of sub-game perfect equilibrium.\n\n2\n\n\fOutline. In Section 2 we define our model formally and provide a general framework for\nsolving dueling problems as well as the warmup example of the ranking duel. We then use these\ntools to analyze the more intricate settings of the hiring duel (Section 3), the compression duel\n(Section 4), and the search duel (Section 5). We describe avenues of future research in Section 6.\n\n2\n\nPreliminaries\n\nA problem of optimization under uncertainty, (X, \u03a9, c, p), is specified by a feasible set X, a\ncommonly-known distribution p over the state of nature, \u03c9, chosen from set \u03a9, and an objective\nfunction c : X \u00d7 \u03a9 \u2192 R. For simplicity we assume all these sets are finite. When p is clear from\ncontext, we write the expected cost of x \u2208 X as c(x) = E\u03c9\u223cp [c(x, \u03c9)]. The one-player optimum\nis opt = minx\u2208X c(x). Algorithm A takes as input p and randomness r \u2208 [0, 1], and outputs\nx \u2208 X. We define c(A) = Er [c(A(p, r))] and an algorithm A is one-player optimal if c(A) = opt.\nIn the two-person constant-sum duel game D(X, \u03a9, c, p), players simultaneously choose\nx, x\u2032 \u2208 X, and player 1's payoff is:\n1\nv(x, x\u2032 , p) = Pr [c(x, \u03c9) < c(x\u2032 , \u03c9)] + Pr [c(x, \u03c9) = c(x\u2032 , \u03c9)].\n\u03c9\u223cp\n2 \u03c9\u223cp\nWhen p is understood from context we write v(x, x\u2032 ). Player 2's payoff is v(x\u2032 , x) = 1 \u2212 v(x, x\u2032 ).\nThis models a tie, c(x, \u03c9) = c(x\u2032 , \u03c9), as a half point for each. We define the value of a strategy,\nv(x, p), to be how much that strategy guarantees, v(x, p) = minx\u2032 \u2208X v(x, x\u2032 , p). Again, when p\nis understood from context we write simply v(x).\nThe set of probability distributions over set S is denoted \u2206(S). A mixed strategy is \u03c3 \u2208 \u2206(X).\nAs is standard, we extend the domain of v to mixed strategies bilinearly by expectation. A\nbest response to mixed strategy \u03c3 is a strategy which yields maximal payoff against \u03c3, i.e.,\n\u03c3 \u2032 is a best response to \u03c3 if it maximizes v(\u03c3 \u2032 , \u03c3). A minmax strategy is a (possibly mixed)\nstrategy that guarantees the safety value, in this case 1/2, against any opponent play. The\nbest response to such a strategy yields payoffs of 1/2. The set of minmax strategies is denoted\nM M (D(X, \u03a9, c, p)) = {\u03c3 \u2208 \u2206(X) | v(\u03c3) = 1/2}. A basic fact about constant-sum games is that\nthe set of Nash equilibria is the cross product of the minmax strategies for player 1 and those\nof player 2.\n\n2.1\n\nBilinear duels\n\nIn a bilinear duel, the feasible set of strategies are points in n-dimensional Euclidean space, i.e.,\n\u2032\n\u2032\nX \u2286 Rn , X \u2032 \u2286 Rn and the payoff to player 1 is v(x, x\u2032 ) = xt M x\u2032 forP\nsome matrix M \u2208 Rn\u00d7n .\nIn n \u00d7 n bimatrix games, X and X \u2032 are just simplices {x \u2208 Rn\u22650 |\nxi = 1}. Let K be the\nconvex hull of X. Any point in K is achievable (in expectation) as a mixed strategy. Similarly\ndefine K \u2032 . As we will point out in this section, solving these reduces to linear programming\nwith a number of constraints proportional to the number of constraints necessary to define the\nfeasible sets, K and K \u2032 . (In typical applications, K and K \u2032 have a polynomial number of facets\nbut an exponential number of vertices.)\nLet K be a polytope defined by the intersection of m halfspaces, K = {x \u2208 Rn | wi * x \u2265\nbi for i = 1, 2, . . . , m}. Similarly, let K \u2032 be the intersection of m\u2032 halfspaces wi\u2032 * x \u2265 b\u2032i . The\ntypical way to reduce to an LP for constant-sum games is:\nmax\n\nv\u2208R,x\u2208Rn\n\nv such that x \u2208 K and xT M x\u2032 \u2265 v for all x\u2032 \u2208 X \u2032 .\n\nThe above program has a number of constraints which is m + |X \u2032|, (m constraints guaranteeing\nthat x \u2208 K), and |X \u2032 | is typically exponential. Instead, the following linear program has\nO(n\u2032 + m + m\u2032 ) constraints, and hence can be found in time polynomial in n\u2032 , m, m\u2032 and the\nbit-size representation of M and the constraints in K and K \u2032 .\n\u2032\n\nmax\n\nx\u2208Rn ,\u03bb\u2208Rm\u2032\n\nm\nX\n\n\u2032\n\n\u03bbi b\u2032i\n\nt\n\nsuch that x \u2208 K and x M =\n\n1\n\nm\nX\n1\n\n3\n\n\u03bbi wi\u2032 .\n\n(1)\n\n\fLemma 1. For any constant-sum game with strategies x \u2208 K, x\u2032 \u2208 K and payoffs xt M x\u2032 , the\nmaximum of the above linear program is the value of the game to player 1, and any maximizing\nx is a minmax optimal strategy.\nProof. First we argue that the value of the above LP is at least as large as the value of the game\nto player 1. Let x, \u03bb maximize the above LP and let the maximum be \u03b1. For any x\u2032 \u2208 K \u2032 ,\n\u2032\n\nt\n\n\u2032\n\nx Mx =\n\nm\nX\n\n\u2032\n\n\u03bbi wi\u2032\n\n\u2032\n\n*x \u2265\n\n1\n\nm\nX\n\n\u03bbi b\u2032i = \u03b1.\n\n1\n\nHence, this means that strategy x guarantees player x at least \u03b1 against any opponent response,\nx\u2032 \u2208 K. Hence \u03b1 \u2264 v with equality iff x is minmax optimal. Next, let x be any minmax optimal\nstrategy, and let v be the value of the constant-sum game. This means that xt M x\u2032 \u2265 v for all\nx\u2032 \u2208 K \u2032 with equality for some point. In particular, the minmax theorem (equivalently, duality)\nmeans that the LP minx\u2032 \u2208K \u2032 xt M x\u2032 has a minimum value of v and that there is a vector of\nP m\u2032\nPm\u2032\n\u03bb \u2265 0 such that 1 \u03bbi wi\u2032 = xt M and 1 \u03bbi b\u2032i = v. Hence \u03b1 \u2265 v.\n\n2.2\n\nReduction to bilinear duels\n\nThe sets X in a duel are typically objects such as paths, trees, rankings, etc., which are not\nthemselves points in Euclidean space. In order to use the above approach to reduce a given duel\nD(X, \u03a9, c, p) to a bilinear duel in a computationally efficient manner, one needs the following:\n1. An efficiently computable function \u03c6 : X \u2192 K which maps any x \u2208 X to a feasible point\nin K \u2286 Rn .\n2. A payoff matrix M demonstrating such that v(x, x\u2032 ) = \u03c6(x)t M \u03c6(x\u2032 ), demonstrating that\nthe problem is indeed bilinear.\n3. A set of polynomially many feasible constraints which defines K.\n4. A \"randomized rounding algorithm\" which takes as input a point in K outputs an object\nin X.\nIn many cases, parts (1) and (2) are straightforward. Parts (3) and (4) may be more challenging.\nFor example, for the binary trees used in the compression duel, it is easy to map a tree to a\nvector of node depths. However, we do not know how to efficiently determine whether a given\nvector of node depths is indeed a mixture over trees (except for certain types of trees which are\nin sorted order, like the binary search trees in the binary search duel). In the next subsection,\nwe show how computing approximate best responses suffices.\n\n2.3\n\nApproximating best responses and approximating minmax\n\nIn some cases, the polytope K may have exponentially or infinitely many facets, in which case\nthe above linear program is not very useful. In this section, we show that if one can compute\napproximate best responses for a bilinear duel, then one can approximate minmax strategies.\nFor any \u01eb > 0, an \u01eb-best response to a player 2 strategy x\u2032 \u2208 K \u2032 is any x \u2208 K such that\nt\nx M x\u2032 \u2265 miny\u2208K y T M x\u2032 \u2212 \u01eb. Similarly for player 1. An \u01eb-minmax strategy x \u2208 K for player 1\nis one that guarantees player 1 an expected payoff not worse than \u01eb minus the value, i.e.,\nmin v(x, x\u2032 ) \u2265 max min\nv(y, x\u2032 ) \u2212 \u01eb.\n\u2032\n\nx\u2032 \u2208K\n\ny\u2208K x \u2208K\n\nBest response oracles are functions from K to K \u2032 and vice versa. However, for many applications (and in particular the ones in this paper) where all feasible points are nonnegative, one\ncan define a best response oracle for all nonnegative points in the positive orthant. (With additional effort, one can remove this assumption using Kleinberg and Awerbuch's elegant notion\nof a Barycentric spanner [3].) For scaling purposes, we assume that for some B > 0, the convex\n\u2032\n\u2032\nsets are K \u2286 [0, B]n and K \u2032 \u2286 [0, B]n and the matrix M \u2208 [\u2212B, B]n\u00d7n is bounded as well.\n\n4\n\n\fFix any \u01eb > 0. We suppose that we are given an \u01eb-approximate best response oracle in the\n\u2032\nfollowing sense. For player 1, this is an oracle O : [0, B]n \u2192 K which has the property that\n\u2032 t\n\u2032\nt\n\u2032\n\u2032\nn\u2032\nO(x ) M x \u2265 maxx\u2208K x M x \u2212 \u01eb for any x \u2208 [0, B] . Similarly for O\u2032 for player 2. Hence, one\nis able to potentially respond to things which are not feasible strategies of the opponent. As\ncan be seen in a number of applications, this does not impose a significant additional burden.\nLemma 2. For any \u01eb > 0, n, n\u2032 \u2265 1, B > 0, and any bilinear dual with convex K \u2286 [0, B]n\n\u2032\n\u2032\nand K \u2032 \u2286 [0, B]n and M \u2208 [\u2212B, B]n\u00d7n , and\n\u0001 any \u01eb-best response oracles, there is an algorithm\nfor finding 24(\u01eb max(m, m\u2032 ))1/3 B 2 (nn\u2032 )2/3 -minmax strategies x \u2208 K, x\u2032 \u2208 K \u2032 . The algorithm\nuses poly(\u03b2, m, m\u2032 , 1/\u01eb) runtime and make poly(\u03b2, m, m\u2032 , 1/\u01eb) oracle calls.\nThe reduction and proof is deferred to Appendix A. It uses Hannan-type of algorithms,\nnamely \"Follow the expected leader\" [11].\nWe reduce the compression duel, where the base objects are trees, to a bilinear duel and use\nthe approximate best response oracle. To perform such a reduction, one needs the following.\n1. An efficiently computable function \u03c6 : X \u2192 K which maps any x \u2208 X to a feasible point\nin K \u2286 Rn .\n2. A bounded payoff matrix M demonstrating such that v(x, x\u2032 ) = \u03c6(x)t M \u03c6(x\u2032 ), demonstrating that the problem is indeed bilinear.\n3. \u01eb-best response oracles for players 1 and 2. Here, the input to an \u01eb best response oracle\n\u2032\nfor player 1 is x\u2032 \u2208 [0, B]n .\n\n2.4\n\nBeatability\n\nOne interesting quantity to examine is how well a one-player optimization algorithm performs in\nthe two-player game. In other words, if a single player was a monopolist solving the one-player\noptimization problem, how badly could they be beaten if a second player suddenly entered. For\na particular one-player-optimal algorithm A, we define its beatability over distribution p to be\nEr [v(A(p, r), p)], and we define its beatability to be inf p Er [v(A(p, r), p)].\n\n2.5\n\nA warmup: the ranking duel\n\nIn the ranking duel, \u03a9 = [n] = {1, 2, . . . , n}, X is the set of permutations over n items, and\nc(\u03c0, \u03c9) \u2208 [n] is the position of \u03c9 in \u03c0 (rank 1 is the \"best\" rank). The greedy algorithm, which\noutputs permutation (\u03c91 , \u03c92 , . . . , \u03c9n ) such that p(\u03c91 ) \u2265 p(\u03c92 ) \u2265 * * * \u2265 p(\u03c9n ), is optimal in the\none-player version of the problem.3\n\u2032\nThis game can be represented as a bilinear duel\nP as follows.PLet K and K be the set of doubly\n\u2032\nn2\nstochastic matrices, K = K = {x \u2208 R\u22650 | \u2200j i xij = 1, \u2200i j xij = 1}. Here xij indicates the\nprobability that item i is placed in position j, in some distribution over rankings. The Birkhoffvon Neumann Theorem states that the set K is precisely the set of probability distributions\n2\nover rankings (where each ranking is represented as a permutation matrix x \u2208 {0, 1}n ), and\nmoreover any such x \u2208 K can be implemented efficiently via a form of randomized rounding.\nSee, for example, Corollary 1.4.15 of [14]. Note K is a polytope in n2 dimensions with O(n)\nfacets. In this representation, the expected payoff of x versus x\u2032 is\n\uf8eb\n\uf8f6\n\u0012\n\u0013 X\nX\nX\nX\n1\n1\nxij \uf8ed x\u2032ij +\np(i)\np(i)\nPr[Equally rank i] + Pr[P1 ranks i higher] =\nx\u2032ik \uf8f8 .\n2\n2\nj\ni\ni\nk>j\n\nThe above is clearly bilinear in x and x\u2032 and can be written as xt M x\u2032 for some matrix M with\nbounded coefficients. Hence, we can solve the bilinear duel by the linear program (1) and round\nit to a (randomized) minmax optimal algorithm for ranking.\n3\n\nIn some cases, such as a model of competing search engines, one could have the agents rank only k items, but\nthe algorithmic results would be similar.\n\n5\n\n\fWe next examine the beatability of the greedy algorithm. Note that for the uniform probability distribution p(1) = p(2) = . . . = p(n) = 1/n, the greedy algorithm outputting, say,\n(1, 2, . . . , n) can be beaten with probability 1 \u2212 1/n by the strategy (2, 3, . . . , n, 1). One can\nmake greedy's selection unique by setting p(i) = 1/n + (i \u2212 n/2)\u01eb, and for sufficient small \u01eb\ngreedy can be beaten a fraction of time arbitrarily close to 1 \u2212 1/n.\n\n3\n\nHiring Duel\n\nIn a hiring duel, there are two employers A and B and two corresponding sets of workers\nUA = {a1 , . . . , an } and UB = {b1 , . . . , bn } with n workers each. The i'th worker of each set has\na common value v(i) where v(i) > v(j) for all i and j > i. Thus there is a total ranking of\nworkers ai \u2208 UA (similarly bi \u2208 UB ) where a rank of 1 indicates the best worker, and workers are\nlabeled according to rank. The goal of the employers is to hire a worker whose value (equivalently\nrank) beats that of his competitor's worker. Workers are interviewed by employers one-by-one\nin a random order. The relative ranks of workers are revealed to employers only at the time\nof the interview. That is, at time i, each employer has seen a prefix of the interview order\nconsisting of i of workers and knows only the projection of the total ranking on this prefix.4\nHiring decisions must be made at the time of the interview, and only one worker may be hired.\nThus the employers' pure strategies are mappings from any prefix and permutation of workers'\nranks in that prefix to a binary hiring decision. We note that the permutation of ranks in a\nprefix does not effect the distribution of the rank of the just-interviewed worker, and hence\nwithout loss of generality we may assume the strategies are mapings from the round number\nand current rank to a hiring decision.\nIn dueling notation, our game is (X, \u03a9, c, p) where the elements of X are functions h :\n{1, . . . , n}2 \u2192 {0, 1} indicating for any round i and projected rank of current interviewee j \u2264 i\nthe hiring decision h(i, j); \u03a9 is the set (\u03c3A , \u03c3B ) of all pairs of permutations of UA and UB ; c(h, \u03c3)\nis the value v(\u03c3 \u22121 (i\u2217 )) of the first candidate i\u2217 = argmini {i : h(i, [\u03c3 \u22121 (i)]i ) = 1} (where [\u03c3 \u22121 (i)]j\nindicates the projected rank of the i'th candidate among the first j candidates according to \u03c3)\nthat received an offer; and p (as is typical in the secretary problem) is the uniform distribution\nover \u03a9. The mixed strategies \u03c0 \u2208 \u2206(X) are simply mappings \u03c0 : {0, . . . , n}2 \u2192 [0, 1] from\nrounds and projected ranks to a probability \u03c0(i, j) of a hiring decision.\nThe values v(*) may be chosen adversarially, and hence in the one-player setting the optimal\nalgorithm against a worst-case v(*) is the one that maximizes the probability of hiring the\nbest worker (the worst-case values set v(1) = 1 and v(i) << 1 for i > 1). In the literature\non secretary problems, the following classical algorithm is known to hire the best worker with\nprobability approaching 1e : Interview n/e workers and hire next one that beats all the previous.\nFurthermore, there is no other algorithm that hires the best worker with higher probability.\n\n3.1\n\nCommon pools of workers\n\nIn this section, we study the common hiring duel in which employers see the same candidates\nin the same order so that \u03c3A = \u03c3B and each employer observes when the other hires. In this\ncase, the following strategy \u03c0 is a symmetric equilibrium: If the opponent has already hired,\nthen hire anyone who beats his employee; otherwise hire as soon as the current candidate has\nat least a 50% chance of being the best of the remaining candidates.\nLemma 3. Strategy \u03c0 is efficiently computable and constitutes a symmetric equilibrium of the\ncommon hiring duel.\nThe computability follows from a derivation of probabilities in terms of binomials, and the\nequilibrium claim follows by observing that there can be no profitable deviation. This strategy\n4\n\nIn some cases, an employer also knows when and whom his opponent hired, and may condition his strategy on\nthis information as well. Only one of the settings described below needs this knowledge set; hence we defer our\ndiscussion of this point for now and explicitly mention the necessary assumptions where appropriate.\n\n6\n\n\falso beats the classical algorithm, enabling us to provide non-trivial lower and upper bounds for\nits beatability.\nProof. For a round i, we compute a threshold ti such that \u03c0 hires if and only if the projected\nrank of the current candidate j is at most ti . Note that if i candidates are observed, the\nprobability\nthat the ti 'th best among them is better than all remaining candidates is precisely\n\u0001 n\u0001\ni\n.\nThe\nnumerator is the number of ways to place the 1 through ti 'th best candidates\n/\nti\nti\noverall among the first i and the denominator is the number of ways to place the 1 through\nti 'th best among the whole order. Hence to efficiently compute \u03c0 we just need to compute ti\nor, equivalently, estimate\nratios of binomials and hire whenever on round i and observing\n\u0001 these\n\u0001\nthe j'th best so far, ji / nj \u2265 1/2.\nWe further note \u03c0 is a symmetric equilibrium since if an employer deviates and hires early\nthen by definition the opponent has a better than 50% chance of getting a better candidate.\nSimilarly, if an employer deviates and hires late then by definition his candidate has at most a\n50% chance of being a better candidate than that of his opponent.\nLemma 4. The beatability of the classical algorithm is at least 0.51 and at most 0.82.\nThe lower bound follows from the fact that \u03c0 beats the classical algorithm with probability\nbounded above 1/2 when the classical algorithm hires early (i.e., before round n/2), and the\nupper bound follows from the fact that the classical algorithm guarantees a probability of 1/e\nof hiring the best candidate, in which case no algorithm can beat it.\nProof. For the lower bound, note that in any event, \u03c0 guarantees a payoff of at least 1/2\nagainst the classical algorithm. We next argue that for a constant fraction of the probability\nspace, \u03c0 guarantees a payoff of strictly better than 1/2. In particular, for some q, 1/e < q < 1/2,\nconsider the event that the classical algorithm hires in the interval {n/e, qn}. This event happens\nwhenever the best among the first qn candidates is not among the first n/e candidates, and\nhence has a probability of (1 \u2212 1/qe). Conditioned on this event, \u03c0 beats the classical algorithm\nwhenever the best candidate overall is in the last n(1 \u2212 q) candidates,5 which happens with\nprobability (1 \u2212 q) (the conditioning does not change this probability since it is only a property\nof the permutation projected onto the first qn elements). Hence the overall payoff of \u03c0 against\nthe classical algorithm is (1 \u2212 q)(1 \u2212 1/qe) + (1/2)(1/qe). Optimizing for q yields the result.\nFor the upper bound, note as mentioned above that the classical algorithm has a probability\napproaching 1/e of hiring the best candidate. From here, we see ((1/2e)+(1\u22121/e)) = 1\u22121/2e <\n0.82 is an upper bound on the beatability of the classical algorithm since the best an opponent\ncan do is always hire the best worker when the classical algorithm hires the best worker and\nalways hire a better worker when the classical algorithm does not hire the best worker.\n\n3.2\n\nIndependent pools of workers\n\nIn this section, we study the independent hiring duel in which the employers see different candidates. Thus \u03c3A 6= \u03c3B and the employers do not see when the opponent hires. We use the\nbilinear duel framework introduced in Section 2.1 to compute an equilibrium for this setting,\nyielding the following theorem.\nTheorem 1. The equilibrium strategies of the independent hiring duel are efficiently computable.\nThe main idea is to represent strategies \u03c0 by vectors {pij } where pij is the (total) probability\nof hiring the j'th best candidate seen so far on round i. Let qi be the probability of reaching\nround i, and note it can be computed from the {pij }. Recall \u03c0(i, j) is the probability of hiring\nthe j'th best so far at round i conditional on seeing the j'th best so far at round i. Thus\nusing Bayes' Rule we can derive an efficiently-computable bijective mapping (with an efficiently\ncomputable inverse) \u03c6(\u03c0) between \u03c0 and {pij } which simply sets \u03c0(i, j) = pij /(qi /i). It only\n5\nThis is a loose lower bound; there are many other instances where \u03c0 also wins, e.g., if the second-best candidate\nis in the last n(1 \u2212 q) candidates and the best occurs after the third best in the first qn candidates.\n\n7\n\n\fremains to show that one can find a matrix M such that the payoff of a strategy \u03c0 versus a\nstrategy \u03c0 \u2032 is \u03c6(\u03c0)t M \u03c6(\u03c0 \u2032 ). This is done by calculating the appropriate binomials.\nWe show how to apply the bilinear duel framework to compute the equilibrium of the independent hiring duel. This requires the following steps: define a subset K of Euclidean space\nto represent strategies, define a bijective mapping between K and feasible (mixed) strategies\n\u2206(X), and show how to represent the payoff matrix of strategies in the bilinear duel space. We\ndiscuss each step in order.\nDefining K. For each 1 \u2264 i \u2264 n and j \u2264 i we define pij to be the (total) probability of\nseeing and hiring the j'th best candidate seen so far at round i. Our subspace K = [0, 1]n(n+1)/2\nconsists of the collection of probabilities {pij }. To derive constraints on this space, we introduce\na new variable qi representing the probability of reaching round i. We note that the probability\nof reaching P\nround (i + 1) must equal the probability of reaching round i and not hiring, so that\nqi+1 = qi \u2212 nj=1 pij . Furthermore, the probability pij can not exceed the probability of reaching\nround i and interviewing the j'th best candidate seen so far. The probability of reaching round\ni is qi by definition, and the probability that the projected rank of the i'th candidate is j is 1/i\nby our choice of a uniformly random permutation. Thus pij \u2264 qi /i. Together with the initial\ncondition that qi = 1, these constraints completely characterize K.\nMapping. Recall a strategy \u03c0 indicates for each i and j \u2264 i the conditional probability\nof making an offer given that the employer is interviewing the i'th candidate and his projected\nrank is j whereas pij is the total probability of interviewing the i'th candidate with a projected\nrank of j and making an offer. Thus \u03c0(i, j) = pij /(qi /i) and soPpij = qi \u03c0(i, j)/i. Together\nn\nwith the equailities derived above that q1 = 1 and qi+1 = qi \u2212 j=1 pij , we can recursively\nmap any strategy \u03c0 to K efficiently. To map back we just take the inverse of this bijection:\ngiven a point\nPn{pij } in K, we compute the (unique) qi satisfying the constraints q1 = 1 and\nqi+1 = qi \u2212 j=1 pij , and define \u03c0(i, j) = pij /(qi /i).\nPayoff Matrix. By the above definitions, for any strategy \u03c0 and corresponding mapping\n{pij }, the probability that the strategy hires the j'th best so far on round i is pij . Given that\nemployer A hires the j'th best so far on round i and employer B hires the j \u2032 'th best so far\non round i\u2032 , we define Miji\u2032 j \u2032 to be the probability that the overall rank of employer A's hire\nbeats that of employer B's hire plus one-half times the probability that their ranks are equal.\nWe can derive the entries of the this matrix as follows: Let ErX be the event that with respect\nto permutation \u03c3X the overall rank of a fixed candidate is r, and FijX be the event that the\nprojected rank of the last candidate in a random prefix of size i is j. Then\nMiji\u2032 j \u2032 =\n\nX\n\nPr[ErA |FijA ] Pr[ErB\u2032 |FiB\u2032 j \u2032 ] +\n\nr,r \u2032 :1\u2264r<r \u2032 \u2264n\n\n1 X\nPr[ErA |FijA ] Pr[ErB |FiB\u2032 j \u2032 ].\n2\n1\u2264r\u2264n\n\nFurthermore, by Bayes rule, Pr[ErX |FijX ] = Pr[FijX |ErX ] Pr[ErX ]/ Pr[FijX ] where Pr[ErX ] = 1/n\nand Pr[FijX ] = 1/i. To compute Pr[FijX |ErX ], we select the ranks of the other candidates in the\n\u0001\n\u0001\nprefix of size i. There are r\u22121\ncandidates and n\u2212r+1\nj\u22121 ways to pick the ranks of the better\ni\u2212j\n\u0001\nways to pick the ranks of the worse candidates. As there are n\u22121\ni\u22121 ways overall to pick the\nranks of the other candidates, we see:\n\u0001\n\u0001\nr\u22121 n\u2212r+1\nPr[FijX |ErX ] =\n\nj\u22121\n\ni\u2212j\n\u0001\nn\u22121\ni\u22121\n\n.\n\nLetting {pij } be the mapping \u03c6(\u03c0) of employer A's strategy \u03c0 and {p\u2032ij } be the mapping \u03c6(\u03c0)\nof employer B's strategy \u03c0 \u2032 , we see that c(\u03c0, \u03c0 \u2032 ) = \u03c6(\u03c0)t M \u03c6(\u03c0 \u2032 ), as required.\nBy the above arguments, and the machinery from Section 2.1, we have proven Theorem 1\nwhich claims that the equilibrium of the independent hiring duel is computable.\n\n8\n\n\f4\n\nCompression Duel\n\nIn a compression duel, two competitors each choose a binary tree with leaf set \u03a9. An element\n\u03c9 \u2208 \u03a9 is then chosen according to distribution p, and whichever player's tree has \u03c9 closest\nto the root is the winner. This game can be thought of as a competition between prefix-free\ncompression schemes for a base set of words. The Huffman algorithm, which repeatedly pairs\nnodes with lowest probability, is known to be optimal for single-player compression.\nThe compression duel is D(X, \u03a9, c, p), where \u03a9 = [n] and X is the set of binary trees with\nleaf set \u03a9. For T \u2208 X and \u03c9 \u2208 \u03a9, c(T, \u03c9) is the depth of \u03c9 in T . In Section 4.3 we consider a\nvariant in which not every element of \u03a9 must appear in the tree.\n\n4.1\n\nComputing an equilibrium\n\nThe compression duel can be represented as a bilinear game. In this case, K and K \u2032 will be sets\nof stochastic matrices, where a matrix entry {xij } indicates the probability that item \u03c9i is placed\nat depth j. The set K is precisely the set of probability distributions over node depths that are\nconsistent with probability distributions over binary trees. We would like to compute minmax\noptimal algorithms as in Section 2.2, but we do not have a randomized rounding scheme that\nmaps elements of K to binary trees. Instead, following Section 2.3, we will find approximate\nminmax strategies by constructing an \u01eb-best response oracle.\nThe mapping \u03c6 : X \u2192 K is straightforward: it maps a binary \u0010tree to its depth profile.\nAlso,\n\u0011\nP\nP\nP\n1 \u2032\n\u2032\n\u2032\n\u2032\nthe expected payoff of x \u2208 K versus x \u2208 K is i p(i) j xij 2 xij + k>j xij which can\n\nbe written as xt M x\u2032 where matrix M has bounded entries. To apply Lemma 2, we must now\nprovide an \u01eb best response oracle, which we implement by reducing to a knapsack problem.\nFix p and x\u2032 \u2208 K \u2032 . We will reduce the problem of finding a best response for x\u2032 to the\nmultiple-choice knapsack problem (MCKP), for which there is an FPTAS [13]. In the MCKP,\nthere are n lists of items, say {(\u03b1i1 , . . . , \u03b1iki ) | 1 \u2264 i \u2264 n}, with each item \u03b1ij having a value\nvij \u2265 0 and weight wij \u2265 0. The problem is to choose exactly one item from each list with total\nweight at most 1, with the goal of maximizing total value. Our\nis as\u0011follows. For each\n\u0010 reduction\nP\n1 \u2032\n\u2212j\n\u03c9i \u2208 \u03a9 and 0 \u2264 j \u2264 n, define wij = 2 and vij = p(\u03c9i ) 2 xij + d>j x\u2032id . This defines a\nP\nP\nMCKP input instance. For any given t \u2208 X, v(\u03c6(t), x\u2032 ) = \u03c9i \u2208\u03a9 vidt (i) and \u03c9i \u2208\u03a9 wi,dt (i) \u2264 1\nby the Kraft inequality. Thus, any strategy for the compression duel can be mapped to a solution\nto the MCKP. Likewise, a solution to the MCKP can be mapped in a value-preserving way to\na binary tree t with leaf set \u03a9, again by the Kraft inequality. This completes the reduction.\n\n4.2\n\nBeatability\n\nWe will obtain a bound of 3/4 on the beatability of the Huffman algorithm. The high-level idea\nis to choose an arbitrary tree T and consider the leaves for which T beats H and vice-versa. We\nthen apply structural properties of trees to limit the relative sizes of these sets of leaves, then\nuse properties of Huffman trees to bound the relative probability that a sampled leaf falls in\none set or the other.\nBefore bounding the beatability of the Huffman algorithm in the No Fail compression model,\nwe review some facts about Huffman trees. Namely, that nodes with lower probability occur\ndeeper in the tree, and that siblings are always paired in order of probability (see, for example,\npage 402 of Gersting [9]. In what follows, we will suppose that H is a Huffman tree.\nFact 1. If dH (v1 ) > dH (v2 ) then pH (v1 ) \u2264 pH (v2 ).\nFact 2. If v1 and v2 are siblings with pH (v1 ) \u2264 pH (v2 ), then for every node v3 \u2208 H either\npH (v3 ) \u2264 pH (v1 ) or pH (v3 ) \u2265 pH (v2 ).\nWe next give a bound on the relative probabilities of nodes on any given level of a Huffman\ntree, subject to the tree not being too \"sparse\" at the subsequent (deeper) level. Let pmin\nH (d) =\nminv:dH (v)=d pH (v) and pmax\nH (d) = maxv:dH (v)=d pH (v).\n\n9\n\n\fLemma 5. Choose any d < maxv dH (v) and nodes v, w such that dH (w) = dH (v) = d. If v is\nnot the common ancestor of all nodes of depth greater than d, then pH (w) \u2264 3pH (v).\nProof. Let a = pH (v). By assumption there exists a non-leaf node z 6= v with dH (z) = d, say\nwith children z1 and z2 . Then pH (z1 ) \u2264 a and pH (z2 ) \u2264 a by Fact 1, so pH (z) \u2264 2a. This\nimplies that v's sibling has probability at most 2a by Fact 2, so the parent of v has probability\nat most 3a. Fact 1 then implies that pH (w) \u2264 3a as required.\nany T \u2208 X and set of nodes R \u2286 T we define the weight of R to be wT (R) =\nP For \u2212d\nT (v)\n. The Kraft inequality for binary trees is wT (T ) \u2264 1. In fact, we have wT (T ) = 1\nv\u2208R 2\nsince we can assume each interior node of T has two children.\nLemma 6. Choose R \u2286 H such that no node of R is a descendent of any other, and suppose\nmax\nw(R) = 2\u2212d for some d \u2208 [n]. Then pmin\nH (d) \u2264 p(R) \u2264 pH (d).\nProof. We will show p(R) \u2264 pmax\nH (d); the argument for the other inequality is similar. We\nproceed by induction on |R|. If |R| = 1 the result is trivial (since R = {v} where dH (v) = d).\nOtherwise, since w(R) = 2\u2212d , there must be at least two nodes of the maximum depth present\nin R. Let v and w be the two such nodes with smallest probability, say with pH (v) \u2264 pH (w).\nLet w\u2032 be the parent of w. Then pH (w\u2032 ) \u2265 pH (w) + pH (v), since the sibling of w has weight\nat least pH (v) by Fact 2. Also, w\u2032 6\u2208 R since w \u2208 R and no node of R is a descendent of any\nother. Let R\u2032 = R \u222a {w\u2032 } \u2212 {w, v}. Then w(R\u2032 ) = w(R), p(R\u2032 ) \u2265 p(R), and no node of R\u2032 is a\ndescendent of any other. Thus, by induction, p(R) \u2264 p(R\u2032 ) \u2264 pmax\nH (d) as required.\nWe are now ready to show that the beatability of the Huffman algorithm is at most 34 .\nProposition 2. The beatability of the Huffman algorithm is at most 34 .\nFix \u03a9 and p. Let H denote the Huffman tree and choose any other tree T . Define P = {v \u2208\n\u03a9 : dT (v) < dH (v)}, Q = {v \u2208 \u03a9 : dT (v) > dH (v)}. That is, P is the set of elements of \u03a9 for\nwhich T beats H, and Q is the set of elements for which H beats T . Our goal is to show that\np(P ) < 3p(Q), which would imply that v(T, H) \u2264 3/4.\nWe first claim that w(P ) < w(Q). To see this, write U = \u03a9 \u2212 (P \u222a Q) and note that, by the\nKraft inequality,\nw(P ) + w(Q) + w(U ) = 1 = wT (P ) + wT (Q) + wT (U ).\n\n(2)\n\nMoreover, wT (Q) > 0, wT (U ) = wH (U ), and wT (P ) \u2265 2w(P ) (since dT (v) \u2264 dH (v) \u2212 1 for all\nv \u2208 P ). Applying these inequalities to (2) implies w(P ) \u2212 w(Q) < 0, completing the claim.\nOur approach will be to express P and Q as disjoint unions P = P1 \u222a . . . \u222a Pr and Q =\nQ1 \u222a . . . \u222a Qr such that p(Pi ) \u2264 3p(Qi ) for all i. To this end, we express the quantities\nP w(P ) and\nw(Q) in P\nbinary: choose x1 , . . . , xn and y1 , . . . , yn from {0, 1} such that w(P ) = i xi 2\u2212i and\nw(Q) = i yi 2\u2212i . Since w(P ) is a sum of element weights that are inverse powers of two, we\ncan partition the elements of P into disjoint subsets P1 , . . . , Pn such that w(Pi ) = xi 2\u2212i for all\ni \u2208 [n]. Similarly, we can partition Q into disjoint subsets Q1 , . . . , Qn such that w(Qi ) = yi 2\u2212i\nfor all i \u2208 [n].\nLet r = min{i : xi 6= yi }. Note that, since w(P ) < w(Q), we must have xr = 0 and yr = 1.\nWe first show that p(Pi ) \u2264 3p(Qi ) for each i < r. Since xi = yi , we either have Pi = Qi = \u2205 or\nelse w(Pi ) = w(Qi ) = 2\u2212i . In the latter case, suppose first that |Qi | = 1. Then, since Qi consists\nof a single leaf and i is not the maximum depth of tree H, we can apply Lemma 6 and Lemma 5 to\nconclude p(Pi ) \u2264 pmax\nH (i) \u2264 3p(Qi ). Next suppose that |Qi | > 1. We would again like to apply\nLemma 5, but we must first verify that its conditions are met. Suppose for contradiction that\nall nodes of depth greater than i share a common ancestor of depth i. Then, since w(Qi ) = 2\u2212i\nand |Qi | > 1, it must be that Qi contains all such nodes, which contradicts the fact that Qr\ncontains at least one node of depth greater than i. We conclude that the conditions of Lemma\nmin\n5 are satisfied for all v and w at depth i, and therefore p(Pi ) \u2264 pmax\nH (i) \u2264 3pH (i) \u2264 3p(Qi ) as\nrequired.\n\n10\n\n\fS\nS\nWe next consider i \u2265 r. Let Pr\u2032 = j\u2265r Pj and Q\u2032r = j\u2265r Qj . We claim that p(Pr\u2032 ) \u2264\n3p(Q\u2032r ). If Pr\u2032 = \u2205 then this is certainly true, so suppose otherwise. Then w(Pr\u2032 ) < 2\u2212r , so Pr\u2032\ncontains elements of depth greater than r. As in the case i < r, this implies that either Qr\ncontains only a single node (and cannot be the common ancestor of all nodes of depth greater\nthan r), or else not all nodes of depth greater than r have a common ancestor of depth r. We\n\u2032\ncan therefore apply Lemma 6 and Lemma 5 to conclude p(Pr\u2032 ) \u2264 pmax\nH (r) \u2264 3p(Qr ) \u2264 3p(Qr ).\nSince P = P1 \u222a . . . \u222a Pr\u22121 \u222a Pr\u2032 and Q = Q1 \u222a . . . \u222a Qr\u22121 \u222a Q\u2032r are disjoint partitions, we\nconclude that p(P ) \u2264 3p(Q) as required.\nWe now give an example to demonstrate that the Huffman algorithm is at least (2/3 \u2212 \u01eb)beatable for every \u01eb > 0. For any n \u2265 3, consider the probability distribution given by p(\u03c91 ) = 31 ,\np(\u03c9i ) = 3*21i\u22122 for all 1 < i < n, and p(\u03c9n ) = 3*21n\u22123 . For this distribution, the Huffman tree t\nsatisfies dt (\u03c9i ) = i for each i < n and dt (\u03c9n ) = n \u2212 1. Consider the alternative tree t\u2032 in which\n\u2032\nd(\u03c91 ) = n \u2212 1 and d(\u03c9i ) = i \u2212 1 for all i >\nP 1. Then t will win if any of \u03c92 , \u03c93 , . . . , \u03c9n\u22121 are\nchosen, and will tie on \u03c9n . Thus v(t\u2032 , t) = i>1 3*21i\u22122 + 12 * 3*21n\u22123 = 23 \u2212 3*21n\u22122 , and hence the\nHuffman algorithm is ( 23 \u2212 3*21n\u22122 )-beatable for every n \u2265 3.\nWe conclude the section by noting that if all probabilities are inverse powers of 2, the Huffman\nalgorithm is minmax optimal.\nProposition 3. Suppose there exist integers a1 , . . . , an such that p(\u03c9i ) = 2\u2212ai for each i \u2264 n.\nThen the value of the Huffman tree H is v(H) = 1/2.\nProof. We suppose that there exist integers a1 , . . . , an such that p(\u03c9i ) = 2\u2212ai for each i \u2264 n.\nOur goal is to show that the value of the Huffman tree H is v(H) = 1/2.\nFor this set of probabilities, the Huffman tree will set dH (\u03c9i ) = ai for all \u03c9i \u2208 \u03a9. In this case,\np(R) = w(R) for all R \u2286 H. Choose any other tree T , and define sets P and Q as in the proof\nof Proposition 2. That is, P is the set of elements of \u03a9 for which T beats H, and Q is the set\nof elements for which H beats T . Then, as in Proposition 2, we must have w(P ) < w(Q), and\nhence p(P ) < p(Q). Thus v(H, T ) < 1/2. We conclude that the best response to the Huffman\ntree H must be H itself, and thus strategy H has a value of 1/2.\n\n4.3\n\nVariant: allowed failures\n\nWe consider a variant of the compression duel in which an algorithm can fail to encode certain\nelements. If we write L(T ) to be the set of leaves of binary tree T , then in the (original) model\nof compression we require that L(T ) = \u03a9 for all T \u2208 X, whereas in the \"Fail\" model we require\nonly that L(T ) \u2286 \u03a9. If \u03c9 6\u2208 L(T ), we will take c(T, \u03c9) = \u221e. The Huffman algorithm is optimal\nfor single-player compression in the Fail model.\nWe note that our method of computing approximate minmax algorithms carries over to this\nvariant; we need only change our best-response reduction to use a Multiple-Choice Knapsack\nProblem in which at most one element is chosen from each list. What is different, however, is\nthat the Huffman algorithm is completely beatable in the Fail model. If we take \u03a9 = {\u03c91 , \u03c92 }\nwith p(\u03c91 ) = 1 and p(\u03c92 ) = 0, the Huffman tree H places each of the elements of \u03a9 at depth 2.\nIf T is the singleton tree that consists of \u03c91 as the root, then v(T, H) = 1.\n\n5\n\nBinary Search Duel\n\nIn a binary search duel, \u03a9 = [n] and X is the set of binary search trees on \u03a9 (i.e. binary trees\nin which nodes are labeled with elements of \u03a9 in such a way that an in-order traversal visits\nthe elements of \u03a9 in sorted order). Let p be a distribution on \u03a9. Then for T \u2208 X and \u03c9 \u2208 \u03a9,\nc(T, \u03c9) is the depth of the node labeled by \"\u03c9\" in the tree T . In single-player binary search\nand uniform p, selecting the median m element in \u03a9 as the root node and recursing on the left\n{\u03c9|\u03c9 < m} and right {\u03c9|\u03c9 > m} subsets to construct sub-trees is known to be optimal.\nThe binary search game can be represented as a bilinear duel. In this case, K and K \u2032 will\nbe sets of stochastic matrices (as in the case of the compression game) and the entry {xi,j }\n\n11\n\n\fwill represent the probability that item \u03c9j is placed at depth i. Of course, not every stochastic\nmatrix is realizable as a distribution on binary search trees (i.e. such that the probability \u03c9j is\nplaced at depth i is {xi,j }). In order to define linear constraints on K so that any matrix in K is\nrealizable, we will introduce an auxiliary data structure in Section 5.1 called the State-Action\nStructure that captures the decisions made by a binary search tree. Using these ideas, we will\nbe able to fit the binary search game into the bilinear duel framework introduced in Section 2.2\nand hence be able to efficiently compute a Nash equilibrium strategy for each player.\nGiven a binary search tree T \u2208 X, we will write cT (\u03c9) for the depth of \u03c9 in T . We will also\nrefer to cT (\u03c9) as the time that T finds \u03c9.\n\n5.1\n\nComputing an equilibrium\n\nIn this subsection, we give an algorithm for computing a Nash equilibrium for the binary search\ngame, based on the bilinear duel framework introduced in Section 2.2. We will do this by\ndefining a structure called the State-Action Structure that we can use to represent the\ndecisions made by a binary search tree using only polynomially many variables. The set of valid\nvariable assignments in a State-Action Structure will also be defined by only polynomially\nmany linear constraints and so these structures will naturally be closed under taking convex\ncombinations. We will demonstrate that the value of playing \u03c3 \u2208 \u2206(X) against any value matrix\nV \u2013 see Definition 1 is a linear function of the variables in the State-Action Structure\ncorresponding to \u03c3. Furthermore, all valid State-Action Structures can be efficiently\nrealized as a distribution on binary search trees which achieves the same expected value.\nTo apply the bilinear duel framework, we must give a mapping \u03c6 from the space of binary\nsearch trees to a convex set K defined explicitly by a polynomial number of linear constraints\n(on a polynomial number of variables). We now give an informal description of K: The idea\nis to represent a binary search tree T \u2208 X as a layered graph. The nodes (at each depth)\nalternate in type. One layer represents the current knowledge state of the binary search tree.\nAfter making some number of queries (and not yet finding the token), all the information that\nthe binary search tree knows is an interval of values to which the token is confined - we refer to\nthis as the live interval. The next layer of nodes represents an action - i.e. a query to some item\nin the live interval. Correspondingly, there will be three outgoing edges from an action node\nrepresenting the possible replies that either the item is to the left, to the right, or at the query\nlocation (in which case the outgoing edge will exit to a terminal state).\nWe will define a flow on this layered graph based on T and the distribution p on \u03a9. Flow will\nrepresent total probability - i.e. the total flow into a state node will represent the probability\n(under a random choice of \u03c9 \u2208 \u03a9 according to p) that T reaches this state of knowledge (in\nexactly the corresponding number of queries). Then the flow out of a state node represents a\ndecision of which item to query next. And lastly, the flow out of an action node splits according\nto Bayes' Rule - if all the information revealed so far is that the token is confined to some\ninterval, we can express the probability that (say) our next query to a particular item finds the\ntoken as a conditional probability. We can then take convex combinations of these \"basic\" flows\nin order to form flows corresponding to distributions on binary search trees.\nWe give a randomized rounding algorithm to select a random binary search tree based on a\nflow - in such a way that the marginal probabilities of finding a token \u03c9i at time r are exactly\nwhat the flow specifies they should be. The idea is that if we choose an outgoing edge for each\nstate node (with probability proportional to the flow), then we have fixed a binary search tree\nbecause we have specified a decision rule for each possible internal state of knowledge. Suppose\nwe were to now select an edge out of each action node (again with probability proportional to\nthe flow) and we were to follow the unique path from the start node to a terminal node. This\nprocedure would be equivalent to searching for a randomly chosen token \u03c9i chosen according to\np and using this token to choose outgoing edges from action nodes. This procedure generates\na random path from the start node to a terminal node, and is in fact equivalent to sampling a\nrandom path in the path decomposition of the flow proportionally to the flow along the path.\nBecause these two rounding procedures are equivalent, the marginal distribution that results\n\n12\n\n\ffrom generating a binary search tree (and choosing a random element to look for) will exactly\nmatch the corresponding values of the flow.\n\n5.2\n\nNotation\n\nThe natural description of the strategy space of the binary search game is exponential (in |\u03a9|)\n\u2013 so we will assume that the value of playing any binary search tree T against an opponent's\nmixed strategy is given to us in a compact form which we will refer to as a value matrix:\nDefinition 1. A value matrix V is an |\u03a9| \u00d7 |\u03a9| matrix in which the entry Vi,j is interpreted\nto be the value of finding item \u03c9j at time i.\nGiven any binary search tree T \u2032 \u2208 X, we can define a value matrix V (T \u2032 ) so that the\nexpected value of P\nplaying any binary search tree T \u2208 X against T in the binary search game\ncan be written as i,j 1cT (\u03c9j )=i V (T \u2032 )i,j :\nDefinition 2. Given a binary search tree T \u2032 \u2208 X,\n\uf8f1\n\uf8f2 0 if\n1\nif\nV (T \u2032 )i,j =\n\uf8f3 2\n1 if\n\nlet V (T \u2032 ) be a value matrix such that\ncT \u2032 (\u03c9j ) < i\ncT \u2032 (\u03c9j ) = i\ncT \u2032 (\u03c9j ) > i\n\nSimilarly, given a mixed strategy \u03c3 \u2032 \u2208 \u2206(X), let V (\u03c3 \u2032 ) = ET \u2032 \u223c\u03c3\u2032 [V (T \u2032 )]\nNote that not every value matrix V can be realized as the value matrix V (T \u2032 ) for some\nT \u2208 X. In fact, V need not be realizable as V (\u03c3) for some \u03c3 \u2208 \u2206(X). However, we will be\nable to compute the best response against any value matrix V , regardless of whether or not\nthe matrix corresponds to playing the binary search game against an adversary playing some\nmixed strategy. Lastly, we define a stochastic matrix I(T ), given T \u2208 X. From I(T ), and\n\u2032\nV (T \u2032 ) we can\nPwrite the expected value of playing T against T as a inner-product. We let\n< A, B >p = i,j Ai,j Bi,j p(\u03c9j ) when A and B are |\u03a9| \u00d7 |\u03a9| matrices.\n\u2032\n\nDefinition 3. Given a binary search tree T \u2208 X, let I(T ) be an |\u03a9| \u00d7 |\u03a9| matrix in which\nI(T )i,j = 1cT (\u03c9j )=i . Similarly, given \u03c3 \u2208 \u2206(X), let I(\u03c3) = ET \u223c\u03c3 [I(T )].\n\nLemma 7. Given \u03c3, \u03c3 \u2032 \u2208 \u2206(X), the expected value of playing \u03c3 against \u03c3 \u2032 in the binary search\ngame is exactly < I(\u03c3), V (\u03c3 \u2032 ) >p .\nProof. Consider any T, T \u2032 \u2208 X. hThen the expected value of playing\ni T against T in the binary\nP\nsearch game is exactly i p(\u03c9i ) 1cT (\u03c9i )<cT \u2032 (\u03c9i ) + 21 1cT (\u03c9i )=cT \u2032 (\u03c9i ) =< I(T ), V (T \u2032 ) >p . And\nsince < I(T ), V (T \u2032 ) >p is bilinear in the matrices I(T ) and V (T \u2032 ), indeed the expected value of\nplaying \u03c3 against \u03c3 \u2032 is < I(\u03c3), V (\u03c3 \u2032 ) >p .\n\n5.3\n\nState-Action Structure\n\nDefinition 4. Given a distribution p on \u03a9 and \u03c9i , \u03c9j , \u03c9k \u2208 \u03a9 (and ai < j < k), let\npL\ni,j,k =\n\nP r\u03c9k\u2032 \u223cp [k \u2032 = k]\nP r\u03c9k\u2032 \u223cp [k < k \u2032 \u2264 j]\nP r\u03c9k\u2032 \u223cp [i \u2264 k \u2032 < k] E\n, pi,j,k =\n, and pR\ni,j,k =\n\u2032\n\u2032\nP r\u03c9k\u2032 \u223cp [i \u2264 k \u2264 j]\nP r\u03c9k\u2032 \u223cp [i \u2264 k \u2264 j]\nP r\u03c9k\u2032 \u223cp [i \u2264 k \u2032 \u2264 j]\n\nIntuitively, we can regard the interval [\u03c9i , \u03c9j ] as being divided into the sub-intervals [\u03c9i , \u03c9k\u22121 ],\n{\u03c9k } and [\u03c9k+1 , \u03c9j ]. Then the quantity pL\ni,j,k represents the probability that randomly generated element is contained in the first interval, conditioned on the element being contained in\nR\nthe original interval [\u03c9i , \u03c9j ]. Similarly, one can interpret pE\ni,j,k and pi,j,k as being conditional\nprobabilities as well.\nWe also define a set of knowledge states, which represent the current information that the\nbinary search tree knows about the element and also how many queries have been made:\nDefinition 5. We define:\n\n13\n\n\f1. S = {(i, j, r)|\u03c9i , \u03c9j \u2208 \u03a9, i < j, and r \u2208 {1, 2, ...., |\u03a9|}}\n2. A = {(S, k)|S = (i, j, r) \u2208 S, \u03c9k \u2208 \u03a9 and k \u2208 (i, j)}\n3. F = {(k, r)|\u03c9k \u2208 \u03a9 and r \u2208 {1, 2, ...., |\u03a9|}}\nWe will refer to S as the set of knowledge state. Additionally we will refer to Sstart = (\u03c91 , \u03c9n , 0)\nas the start state. We will refer to A as the set of action state and F as the set of termination\nstates.\nWe can now define a State-Action Structure:\nDefinition 6. A State-Action Structure is a fixed directed graph generated as:\n1. Create a node nS for each S \u2208 S, a node nA for each A \u2208 A and a node nF for each\nF \u2208 F.\n2. For each S = (i, j, r) \u2208 S, and for each k such that i < k < j, create a directed edge eS,k\nfrom S to A = (S, k) \u2208 A.\n3. For each A = (S, k) \u2208 A and S = (i, j, r), create a directed edge eA,F from A to F =\n(k, r + 1) and directed edges eA,SL and eA,SR from A to SL and SR respectively for SL =\n(i, k \u2212 1, r + 1) and SR = (k + 1, j, r + 1).\nWe will define a flow on this directed graph. The source of this flow will be the start node\nSstart and the node corresponding to each termination state will be a sink. The total flow in this\ngraph will be one unit, and this flow should be interpreted as representing the total probability\nof reaching a particular knowledge state, or performing a certain action.\nDefinition 7. We will call an set of values xe for each directed edge in a State-Action\nStructure a stateful flow if (let us adopt the notation that xS,A is the flow on an edge eS,A ):\n1. For all e, 0 \u2264 xe \u2264 1\n2. All nodes except nSstart and nF (for F \u2208 F ) satisfy conservation of flow\n3. For each action state A = (S, i) \u2208 A for S = (i, j, r), the the flow on the three outL\ngoing edges eA,F , eA,SL and eA,SR from nA , satisfy xA,F = pE\ni,j,k C, xA,SL = pi,j,k C and\nP\n\u2032\nxA,SR = pR\ni,j,k where C =\ne=(S \u2032 ,A) for S \u2032 \u2208S xS ,A\n\nGiven T \u2208 X, we can define a flow xT in the State-Action Structure that captures the\ndecisions made by T :\nDefinition 8. Given T \u2208 X, define xT as follows:\n\n1. For each S = (i, j, r) \u2208 S let Ti,j be the sub-tree of T (if a unique such sub-tree exists)\nsuch that the labels contained in Ti,j are exactly {\u03c9i , \u03c9i+1 , ..., \u03c9j }. Suppose that the root\nof this sub-tree Ti,j is \u03c9k . Then send all flow entering the node nS on the outgoing edge\neS,A for A = (S, k).\n2. For each A \u2208 A, divide flow into a action node nA according to Condition 3 in Definition 7\namong outgoing edges.\nNote that the flow out of nSstart is one. Of course, the choice of how to split flow on outgoing\nedges from an action node nA is already well-defined. But we need to demonstrate that xT does\nindeed satisfy conservation of flow requirements, and hence is a stateful flow:\nLemma 8. For any T \u2208 X, xT is a stateful flow\nProof. For some intervals {\u03c9i , \u03c9i+1 , ..., \u03c9j }, there is no sub-tree in T for which the labels contained in the sub-tree is exactly {\u03c9i , \u03c9i+1 , ..., \u03c9j }. If there is such an interval, however, it is\nclearly unique. We will prove by induction that the only state nodes in the State-Action\nStructure which are reached by flow xT are state nodes for which there is such a sub-tree.\nWe will prove this condition by induction on r for state nodes nS of the form S = (i, j, r).\nThis condition is true in the base case because all flow starts at the node nSstart and Sstart =\n\n14\n\n\f(\u03c91 , \u03c9n , 0) and indeed the entire binary search tree T has the property that the set of labels\nused is exactly {\u03c91 , \u03c92 , ...\u03c9n }.\nSuppose by induction that there is some sub-tree Ti,j of T for which the labels of contained\nin the sub-tree are exactly {\u03c9i , \u03c9i+1 , ..., \u03c9j }. Let \u03c9k be the label of the root node of Ti,j . Then\nall flow entering nS would be sent to the action node A = (S, k) and all flow out of this action\nnode would be set to either a termination node or to state nodes SL = (i, k \u2212 1, r + 1) or\nSR = (k + 1, r + 1) and both of the intervals {\u03c9i , \u03c92 , ...\u03c9r\u22121 } or {\u03c9r+1 , \u03c9r+2 , ..., \u03c9j } do indeed\nhave the property that there is a sub-tree that contains exactly each respective set of labels these are just the left and right sub-trees of Ti,j .\nThe variables in a stateful flow capture marginal probabilities that we need to compute the\nexpected value of playing a binary search tree T against some value matrix V :\nLemma 9. Consider any state S = (i, j, r) \u2208 S. The total flow in xT into nS is exactly the\nprobability that (under a random choice of \u03c9k \u223c p), \u03c9k is contained in some sub-tree of T at\ndepth r + 1. Similarly the total flow in xT into any terminal node nF for F = (\u03c9f , r) is exactly\nthe probability (under a random choice of \u03c9k \u223c p) that cT (\u03c9k ) = r.\nProof. We can again prove this lemma by induction on r for state nodes nS of the form S =\n(i, j, r). In the base case, the flow into nSstart is 1, which is exactly the probability that (under\na random choice of \u03c9t \u223c p), \u03c9t is contained in some sub-tree of T at depth 1.\nSo we can prove the inductive hypothesis by sub-conditioning on the event that the element\n\u03c9k is contained in some sub-tree of T at depth r. Let this subtree be T \u2032 . By the inductive\nhypothesis, this is exactly the flow into the node nS \u2032 where S \u2032 = (i, j, r \u2212 1) for some \u03c9i , \u03c9j \u2208 \u03a9\nand i \u2264 k \u2264 j. We can then condition on the event that \u03c9k is such that i \u2264 k \u2264 j. Let \u03c9r be the\nlabel of the root node of T \u2032 . Then using conditioning, the probability that \u03c9k is contained in\nthe left-subtree of T \u2032 is exactly pL\ni,j,r , and similarly for the right sub-tree. Also the probability\nthat \u03c9k = \u03c9r is pE\n.\nAnd\nso\nCondition\n3 in Definition 7 enforces the condition that the flow\ni,j,r\nsplits exactly as this total probability splits - i.e. the probability that \u03c9k is contained in the left\nand right sub-interval of {\u03c9i , \u03c9i+1 , ...\u03c9j } or contained in the root \"\u03c9r \" respectively. Note that\nthe set of sub-trees at any particular depth in T correspond to disjoint intervals of \u03a9, and hence\nthere is no other flow entering the state nS , and this proves the inductive hypothesis.\nAs an immediate corollary:\nCorollary 1. The expected value of playing T against value matrix V ,\nX\nxin\n< I(T ), V >p =\nT (F )Vr,k\nF =(\u03c9k ,r)\u2208F\n\nwhere xin\nT denotes the total flow into a node according to xT .\nAnd as a second corollary:\nCorollary 2. Given T \u2208 X,\nV (T )i,j =\n\n1 in\n2 xT (\u03c9j , i)\n\nP\n\u2032\n+ i\u2032 >i xin\nT (\u03c9j , i )\np(\u03c9j )\n\nwhere xin\nT (\u03c9j , i) denotes the total flow into nF for F = (\u03c9j , i) \u2208 F .\n\n5.4\n\nA rounding algorithm\n\nProposition 4. Given a stateful flow x, there is an efficient randomized rounding procedure that\ngenerates a random T \u2208 X with the property that for any \u03c9j \u2208 \u03a9 and for any i \u2208 {1, 2, ..., |\u03a9|},\nP r[cT (\u03c9j ) = i] =\n\nxin (\u03c9j ,i)\n.\np\u03c9j\n\n15\n\n\fProof. Since x is a unit flow from nSstart to the set of sink nodes nF for F \u2208 F . So if we could\nsample a random path proportional to the total flow along the path, the probability that the\npath ends at any sink nF for F = (\u03c9j , r) is exactly xin (\u03c9j , r).\nFirst Rounding Procedure: Consider the following procedure for generating a path according to this distribution - i.e. the probability of generating any path is exactly the flow\nalong the path: Starting at the source node, and at every step choose a new edge to traverse\nproportionally to the flow along it. So if the process is currently at some node nS and the total\nflow into the node is U , and the total flow on some outgoing edge e is u, edge e is chosen with\nprobability exactly Uu and the process continues until a sink node is reached. Notice that this\nprocedure always terminates in O(|\u03a9|) steps because each time we traverse an action node nA ,\nthe counter r is incremented and every edge in a State-Action Structure either points into\nor points out of a action node.\nThe key to our randomized rounding procedure is an alternative way to generate a path\nfrom the source node to a sink such that the probability that the path ends at any sink nF for\nF = (\u03c9j , r) is still exactly xin (\u03c9j , r). Instead, for each state node nS , we choose an outgoing\nedge in advance (to some action node) proportional to the flow on x on that edge.\nSecond Rounding Procedure: If we fix these choices in advance, we can define an alternate path selection procedure which starts at the source node, and traverse any edges that have\nalready been decided upon. Whenever the process reaches an action node (in which case the\noutgoing edge has not been decided upon), we can select an edge proportional to the total flow\non the edge. This procedure still satisfies the property that the probability that the path ends\nat any sink nF for F = (\u03c9j , r) is exactly xin (\u03c9j , r).\nThird Rounding Procedure: Next, consider another modification to this procedure.\nImagine still that the outgoing edges from every state node are chosen (randomly, as above in\nthe Second Rounding Procedure: ). Instead of choosing which outgoing edge to pick from\nan action node when we reach it, we could instead pick an item \u03c9k\u2032 \u223c p in advance and using this\nhidden value to determine which outgoing edge from a action node to traverse. We will maintain\nthe invariant that if we are at nA and A = (S, k) for S = (i, j, r), we must have i \u2264 k \u2032 \u2264 j.\nThis is clearly true at the base case. Then we will traverse the edge eA,F for F = (k, r) if\n\u03c9k\u2032 = \u03c9k . Otherwise if i \u2264 k \u2032 \u2264 k \u2212 1 we will traverse the edge eA,SL for SL = (i, k \u2212 1, r + 1).\nOtherwise i \u2264 k \u2032 \u2264 k \u2212 1 and we will traverse the edge eA,SR for SR = (k + 1, j, r + 1). This\nclearly maintains the invariant that k \u2032 is contained in the interval corresponding to the current\nknowledge state.\nThis third procedure is equivalent to the second procedure. This follows from interpreting\nCondition 3 in Definition 7 as a rule for splitting flow that is consistent with the conditional\nprobability that \u03c9k\u2032 is contained in the left or right sub-interval of {\u03c9i , \u03c9i+1 , ...\u03c9j } or is equal\nto \u03c9k conditioned on \u03c9k\u2032 \u2208 {\u03c9i , \u03c9i+1 , ...\u03c9j }. An identical argument is used in the proof of\nLemma 9. In this case, we will say that \u03c9k\u2032 is the rule for choosing edges out of action nodes.\nNow we can prove the Lemma: The key insight is that once we have chosen the outgoing\nedges from each state node (but not which outgoing edges from each action node), we have\ndetermined a binary search tree: Given any element \u03c9k\u2032 , if we follow outgoing edges from action\nnodes using \u03c9k\u2032 as the rule, we must reach a terminal node F = (\u03c9k\u2032 , r) for some r. In fact, the\nvalue of r is determined by \u03c9k\u2032 because once \u03c9k\u2032 is chosen, there are no more random choices. So\nwe can compute a vector of dimension |\u03a9|, ~u such that ~uj = r such that F = (\u03c9j , r) is reached\nwhen the \u03c9j is the rule for choosing edges out of action nodes.\nUsing the characterization in Proposition 6, it is easy to verify that the transition rules in\nthe State Action Structure enforce that ~u is a depth vector and hence we can compute a\nbinary search tree T which has the property that using selection rule \u03c9j results in reaching the\nsink node F = (\u03c9j , cT (\u03c9j )).\nSuppose we select each outgoing edge from a state node (as in the Third Rounding Procedure) and select an \u03c9k\u2032 \u223c p (again as in the Third Rounding Procedure) independently.\nThen from the choices of the outgoing edges from each state node, we can recover a binary\nsearch tree T . Then P rT,\u03c9k\u2032 [cT (\u03c9k\u2032 ) = r] = xin (\u03c9k\u2032 , r) precisely because the First Rounding\nProcedure and the Third Rounding Procedure are equivalent. And then we can apply\n\n16\n\n\fBayes' Rule to compute that\nP rT [cT (\u03c9k\u2032 ) = r|\u03c9k\u2032 = \u03c9k ] =\n\nxin (\u03c9k , r)\np(\u03c9k )\n\nTheorem 5. There is an algorithm that runs in time polynomial in |\u03a9| that computes an exact\nNash equilibrium for the binary search game.\nProof. We can now apply the biliear duel framework introduced in Section 2.2 to the binary\nsearch game: The space K is the set of all stateful flows. The set of variables is polynomially\nsized \u2013 see Definition 6, and the set of linear constraints is also polynomially sized and is given\nexplicitly in Definition 7. The function \u03c6 maps binary search trees T \u2208 X to a stateful flow xT\nand is the procedure given in Defintion 8 for computing this mapping is efficient. Also the payoff\nmatrix M is given explicitly in Corollary 1 and Corollary 2. And lastly we give a randomized\nrounding algorithm in Proposition 4.\n\n5.5\n\nBeatability\n\nWe next consider the beatability of the classical algorithm when p is the uniform distribution\non \u03a9. For lack of a better term, let us call this single-player optima the median binary search or median search.\nHere we give matching upper and lower bounds on the beatability of median search. The\nidea is that an adversary attempting to do well against median search can only place one item\nat depth 1, two items at depth 2, four items at depth 3 and so on. We can regard these as\nbudget restrictions - the adversary cannot choose too many items to map to a particular depth.\nThere are additional combinatorial restrictions, as well For example, an adversary cannot place\ntwo labels of depth 2 both to the right of the label of depth 1 - because even though the root\nnode in a binary search tree can have two children, it cannot have more than one right child.\nBut suppose we relax this restriction, and only consider budget restrictions on the adversary. Then the resulting best response question becomes a bipartite maximum weight matching\nproblem. Nodes on the left (in this bipartite graph) represent items, and nodes on the right\nrepresent depths (there is one node of depth 1, two nodes of depth 2, ...). And for any choice\nof a depth to assign to a node, we can evaluate the value of this decision - if this decision beats\nmedian search when searching for that element, we give the corresponding edge weight 1. If it\nties median search, we give the edge weight 12 and otherwise we give the edge zero weight.\nWe give an upper bound on the value of a maximum weight matching in this graph, hence\ngiving an upper bound on how well an adversary can do if he is subject to only budget restrictions. If we now add the combinatorial restrictions too, this only makes the best response\nproblem harder. So in this way, we are able to bound how much an adversary can beat median\nsearch. In fact, we give a lower bound that matches this upper bound - so our relaxation did\nnot make the problem strictly easier (to beat median search).\nWe focus on the scenario in which |\u03a9| = 2r \u22121 and p is the uniform distribution. Throughout\nthis section we denote n = |\u03a9|. The reason we fix n to be of the form 2r \u2212 1 is because the\noptimal single-player strategy is well-defined in the sense that the first query will be at precisely\nthe median element, and if the element \u03c9 is not found on this query, then the problem will break\ndown into one of two possible 2r\u22121 \u2212 1 sized sub-problems. For this case, we give asymptotically\nmatching upper and lower bounds on the beatability of median search.\nDefinition 9. We will call a |\u03a9|-dimensional vector ~u over {1, 2, ...|\u03a9|} a depth vector (over\nthe universe \u03a9) if there is some T \u2208 X such that ~uj = cT (\u03c9j ).\nProposition 6. A |\u03a9|-dimensional vector ~u over {1, 2, ...|\u03a9|} is a depth vector (over the universe\n\u03a9) if and only if\n1. exactly one entry of ~u is set to 1 (let the corresponding index be j), and\n\n17\n\n\f2. the vectors [~u1 \u2212 1, ~u2 \u2212 1, ....~uj\u22121 \u2212 1] and [~uj+1 \u2212 1, ~uj+2 \u2212 1, ....~un \u2212 1] are depth vectors\nover the universe {\u03c91 , \u03c92 , ...\u03c9j\u22121 } and {\u03c9j+1 , \u03c9j+2 , ...\u03c9n } respectively.\nProof. Given any vector ~u that (recursively) satisfies the above Conditions 1 and 2, one can\nbuild up a binary search tree on \u03a9 inductively. Let \u03c9j \u2208 \u03a9 be the unique item such that\n~uj = 1 which exists because ~u satisfies Condition 1. Since ~u satisfies Condition 2, the vectors\n~uL = [~u1 \u2212 1, ~u2 \u2212 1, ....~uj\u22121 \u2212 1] and ~uR = [~uj+1 \u2212 1, ~uj+2 \u2212 1, ....~un \u2212 1] and hence by induction\nwe know that there are binary search trees TL and TR on the universe {\u03c91 , \u03c92 , ...\u03c9j\u22121 } and\n{\u03c9j+1 , \u03c9j+2 , ...\u03c9n } respectively for which ~uL (i) = cTL (\u03c9i ) and ~uR (i\u2032 ) = cTR (\u03c9i\u2032 ) for each 1 \u2264\ni \u2264 j \u2212 1 and j + 1 \u2264 i\u2032 \u2264 n respectively.\nSo we can build a binary search tree T on \u03a9 by labeling the root node \u03c9j and letting the\nleft sub-tree to TL and the right sub-tree to TR . Since the in-order traversal of TL and of TR\nresult in visiting {\u03c91 , \u03c92 , ...\u03c9j\u22121 } and {\u03c9j+1 , \u03c9j+2 , ...\u03c9n } in sorted order, the in-order traversal\nof T will visit \u03a9 in sorted order and hence T \u2208 X.\nNot also that cT (\u03c9i ) = 1 + cTL (\u03c9i ) for 1 \u2264 i \u2264 j \u2212 1 and similarly cT (\u03c9i\u2032 ) = 1 + cTR (\u03c9i\u2032 ) for\nj + 1 \u2264 i\u2032 \u2264 n. So this implies that ~u satisfies ~ui = cT (\u03c9i ) for all 1 \u2264 i \u2264 n, as desired. This\ncompletes the inductive proof that if a vector ~u satisfies Conditions 1 and 2, then it is a depth\nvector.\nConversely, given T \u2208 X, there is only one element \u03c9j such that cT (\u03c9j ) = 1 and so Condition\n1 is met. Let TL and TR be the binary search trees that are the left and right sub-tree of T rooted\nat \u03c9j respectively, where \"\u03c9j \" is the label of the root node in T . Again, cT (\u03c9i ) = 1 + cTL (\u03c9i ) for\n1 \u2264 i \u2264 j \u2212 1 and similarly cT (\u03c9i\u2032 ) = 1 + cTR (\u03c9i\u2032 ) for j + 1 \u2264 i\u2032 \u2264 n so the vector corresponding\nto cT does indeed satisfy Condition 2 by induction.\nClaim 1. For any depth vector ~u, and any s \u2208 {1, 2, ...|\u03a9|},\n|{j \u2208 [n]| such that ~uj = s}| \u2264 2s\u22121\nLemma 10. The beatability of median search is at least\n\n2r\u22121 \u22121+2r\u22123\n2r \u22121\n\n\u2248 85 .\n\nProof. Consider the depth vector for median search for 23 \u2212 1 (r = 3): [3, 2, 3, 1, 3, 2, 3] and\nconsider a partially filled vector [2, 1, \u2217, \u2217, 2, \u2217, \u2217]. We can generate the depth vector for median\nsearch for r + 1 from the depth vector for median search for r as follows: alternately interleave\nvalues of r + 1 into the depth vector for r. For example the depth vector for median search\nfor r = 4 is [4, 3, 4, 2, 4, 3, 4, 1, 4, 3, 4, 2, 4, 3, 4]. We assume by induction that all blocks in the\npartially filled vector are either \u2217s or are one less than the corresponding entry in the depth\nvector for median search. This is true by induction for the base case r = 3. We also assume that\nthe \u2217s are given in blocks of length exactly two. This is also true in the base case. Then if we\nconsider the depth vector for median search for r + 1, if an entry of r + 1 is interleaved, we can\nplace a value of r if the corresponding entry in the partially filled vector is interleaved between\ntwo entries that are already assigned numbers. Otherwise three entries are interleaved into a\nstring of exactly two \u2217s. The median entry in this string of 5 symbols corresponds to a newly\nadded r + 1 entry in the depth vector for median search. At the median of this 5 symbol string,\nwe can place a value of r. This again creates sequences of \u2217s of length exactly two, because we\nhave replaced only the median entry in the string of 5 symbols.\nIf we are given a partially filled depth vector with the property that one value 1 is placed,\ntwo values of 2 are placed, four values of 3 are placed,... and 2r\u22121 values of r are placed.\nAdditionally, we require that all unfilled entries (which are given the value \u2217 for now) occur in\nblocks of length exactly 2. Then we can fill these symbols with the values r + 1 and r + 2, such\nthat the value of r + 1 aligns with a corresponding value of r + 1 in the depth vector for median\nsearch (precisely because any two consecutive symbols contain exactly one value of r + 1 in the\ndepth vector corresponding to median search for r + 1).\nWe can use Proposition 6 to prove that this resulting completely filled vector is indeed a\ndepth vector. How much does this strategy beat median search? There are 2r \u2212 1 locations\n(i.e. every index in which a value of 1, 2, ... or r is placed) in which this strategy beats median\n\n18\n\n\fsearch. And there are 2r\u22121 locations in which this strategy ties median search. Note that this\nis for 2r+1 \u2212 1 items, and so the beatability of median search on 2r \u2212 1 items is exactly\n2r\u22121 \u2212 1 + 2r\u22123\n5\n=\nr\nr\u2192\u221e\n2 \u22121\n8\nlim\n\nLemma 11. The beatability of median search is at most\n\n2r\u22121 \u22121+2r\u22123\n2r \u22121\n\n\u2248 85 .\n\nProof. One can give an upper bound on the beatability of median search by relaxing the question\nto a matching problem. Given a universe \u03a9 of size 2r \u2212 1, consider the following weighted\nmatching problem: For every value of s \u2208 {1, 2, ...r \u2212 1}, add 2s\u22121 nodes on both the left and\nright side with label \"s\". For any pair of nodes a, b where a is contained on the left side, and b\nis contained on the right side, set the value of the edge connecting a and b to be equal to 0 if\nthe label of a is strictly smaller than the label of b, 21 if the two labels have the same value, and\n1 if the label of a is strictly larger than the label of b.\nLet M be the maximum value of a perfect matching. Let M\u0304 be the average value - i.e. 2rM\u22121 .\nClaim 2. M\u0304 is an upper bound on the beatability of binary search.\nProof. For any s \u2208 {1, 2, ...r \u2212 1}, the depth vector ~u(M ) corresponding to median search has\nexactly 2s\u22121 indices j for which ~u(M )j = s.\nWe can make an adversary more powerful by allowing the adversary to choose any vector\n~u which satisfies the condition that for any s \u2208 {1, 2, ...|\u03a9|}, the number of indices j for which\n~uj = s is at most 2s\u22121 because using Claim 1 this is a weaker restriction than requiring the\nadversary to choose a vector ~u that is a depth vector. So in this case, the adversary may as well\nchoose a vector ~u that satisfies the constraint in Claim 1 with equality.\nAnd in this case where we allow the adversary to choose any vector ~u that satisfies Claim 1,\nthe best response question is exactly the matching problem described above - because for each\nentry in ~uM because the adversary only needs to choose what label s \u2208 {1, 2, ...r \u2212 1} to place\nat this location subject to the above budget constraint that at most 2s\u22121 labels of type \"s\" are\nused in total.\nClaim 3. M\u0304 \u2264\n\n2r\u22121 \u22121+2r\u22123\n.\n2r \u22121\n\nProof. Given a maximum value, bipartite matching problem, the dual covering\nproblem has\nP\nvariables yv corresponding to each node v, and the goal is to minimize v yv subject to the\nconstraint that for every edge (u, v) in the graph (which has value w(u, v)), the dual variables\nsatisfy yu + yv \u2265 w(u, v) and each variable yv is non-negative.\nSo we can upper bound M by giving a valid dual solution. This will then yield an upper\nbound on M and consequently will also give an upper bound on M\u0304 .\nConsider the following dual solution: For each node on the right, with label \"s\" for s < r \u2212 2,\nset yv equal to 1. For a node on the right with label \"s\" for s = r \u2212 2, set yv equal to 12 and\nfor each label \"s\" for s = r \u2212 1, set yv = 0. Additionally, for every node on the left, only nodes\nwith label \"s\" for s = r \u2212P\n1 are given non-zero dual variable, and set this variable equal to 21 .\nThe value of the dual v yv is 1 + 2 + ...2r\u22123 + 12 2r\u22122 + 21 2r\u22121 . And so this yields an upper\nr\u22121\nr\u22123\nand\nbound on M\u0304 of 2 2\u22121+2\nr \u22121\n5\n2r\u22121 \u2212 1 + 2r\u22123\n=\nr\u2192\u221e\n2r \u2212 1\n8\nlim\n\n19\n\n\f6\n\nConclusions and Future Directions\n\nThe dueling framework presents a fresh way of looking at classic optimization problems through\nthe lens of competition. As we have demonstrated, standard algorithms for many optimization\nproblems do not, in general, perform well in these competitive settings. This leads us to suspect\nthat alternative algorithms, tailored to competition, may find use in practice. We have adapted\nlinear programming and learning techniques into methods for constructing such algorithms.\nWe have only just begun an exploration of the dueling framework for algorithm analysis;\nthere are many open questions yet to consider. For instance, one avenue of future work is to\ncompare the computational difficulty of solving an optimization problem with that of solving the\nassociated duel. We know that one is not consistently more difficult than the other: in Appendix\nB we provide an example in which the optimization problem is computationally easy but the\ncompetitive variant appears difficult; an example of the opposite situation is given in Appendix\nC, where a computationally hard optimization problem has a duel which can be solved easily.\nIs there some structure underlying the relationship between the computational hardness of an\noptimization problem and its competitive analog?\nPerhaps more importantly, one could ask about performance loss inherent when players\nchoose their algorithms competitively instead of using the (single-player) optimal algorithm.\nIn other words, what is the price of anarchy [12] of a given duel? Such a question requires\na suitable definition of the social welfare for multiple algorithms, and in particular it may be\nthat two competing algorithms perform better than a single optimal algorithm. Our main open\nquestion is: does competition between algorithms improve or degrade expected performance?\n\n20\n\n\fReferences\n[1] Itai Ashlagi, Piotr Krysta, and Moshe Tennenholtz. Social context games. In WINE, pages\n675\u2013683, 2008.\n[2] Itai Ashlagi, Moshe Tennenholtz, and Aviv Zohar. Competing schedulers. In AAAI, 2010.\n[3] Baruch Awerbuch and Robert D. Kleinberg. Adaptive routing with end-to-end feedback:\ndistributed learning and geometric approaches. In STOC '04: Proceedings of the thirtysixth annual ACM symposium on Theory of computing, pages 45\u201353, New York, NY, USA,\n2004. ACM.\n[4] Felix Brandt, Felix A. Fischer, Paul Harrenstein, and Yoav Shoham. Ranking games. Artif.\nIntell., 173(2):221\u2013239, 2009.\n[5] R. Burguet and J. Sakovics. Imperfect Competition in Auction Designs. International\nEconomic Review, 40(1):231\u2013247, 1999.\n[6] J. Feigenbaum, D. Koller, and P. Shor. A game-theoretic classification of interactive complexity classes. In SCT '95: Proceedings of the 10th Annual Structure in Complexity Theory\nConference (SCT'95), page 227, Washington, DC, USA, 1995. IEEE Computer Society.\n[7] Lance Fortnow, Russell Impagliazzo, Valentine Kabanets, and Christopher Umans. On the\ncomplexity of succinct zero-sum games. In CCC '05: Proceedings of the 20th Annual IEEE\nConference on Computational Complexity, pages 323\u2013332, Washington, DC, USA, 2005.\nIEEE Computer Society.\n[8] Yoav Freund and Robert E. Schapire. Game theory, on-line prediction and boosting. In\nCOLT '96: Proceedings of the ninth annual conference on Computational learning theory,\npages 325\u2013332, New York, NY, USA, 1996. ACM.\n[9] Judith L. Gersting. Mathematical Structures for Computer Science. W. H. Freeman & Co.,\nNew York, NY, USA, 1993.\n[10] Nicole Immorlica, Robert Kleinberg, and Mohammad Mahdian. Secretary problems with\ncompeting employers. In Paul Spirakis, Marios Mavronicolas, and Spyros Kontogiannis, editors, Internet and Network Economics, volume 4286 of Lecture Notes in Computer Science,\npages 389\u2013400. Springer Berlin / Heidelberg, 2006.\n[11] Adam Kalai and Santosh Vempala. Efficient algorithms for online decision problems. Journal of Computer and System Sciences, 71(3):291 \u2013 307, 2005. Learning Theory 2003.\n[12] Elias Koutsoupias and Christos Papadimitriou. Worst-case equilibria. In Proceedings of\nthe 16th annual conference on Theoretical aspects of computer science, STACS'99, pages\n404\u2013413, Berlin, Heidelberg, 1999. Springer-Verlag.\n[13] E. L. Lawler. Fast approximation algorithms for knapsack problems. Mathematics of\nOperations Research, 4(4):339\u2013356, 1979.\n[14] L. Lov\u00e1sz and M. D. Plummer. Matching theory. Ann. Discrete Math., 29, 1986.\n[15] P. McAfee. Mechanism Design by Competing Sellers. Econometrica, 61:1281\u20131312, 1993.\n[16] D. Monderer and M. Tennenholtz. K-price auctions: Revenue Inequalities, Utility Equivalence, and Competition in Auction Design. Economic Theory, 24(2):255\u2013270, 2004.\n[17] M. Peters and S. Severinov. Competition Among Sellers Who Offer Auctions Instead of\nPrices. Journal of Economic Theory, 75:141\u2013179, 1997.\n[18] Mihalis Yannakakis. Expressing combinatorial optimization problems by linear programs.\nJ. Comput. Syst. Sci., 43(3):441\u2013466, 1991.\n\n21\n\n\fA\n\nProofs from Section 2\n\nHere we present the proof of Lemma 2. The proof follows a reduction from low-regret learning to\ncomputing approximate minmax strategies [8]. It was shown there that if two players use \"low\nregret\" algorithms, then the empirical distribution over play will converge to the set of minmax\nstrategies. However, instead of using the weighted majority algorithm, we use the \"Follow the\nexpected leader\" (FEL) algorithm [11]. That algorithm gives a reduction between the ability to\ncompute best responses and \"low regret.\"\nNote, for this section, we will use the fact that xt M x\u2032 \u2208 [\u2212C, C] for C = B 3 nn\u2032 under our\n\u2032\nassumptions on K, K \u2032 , and M . We will extend the domain of v : Rn\u22650 \u00d7 Rn\u22650 \u2192 R naturally\n\u2032\nby v(x, x\u2032 ) = xt M x\u2032 . For x \u2208 [0, B]n and x\u2032 \u2208 [0, B]n , v(x, x\u2032 ) \u2208 [\u2212C, C]. Additionally, for\n\u2032\n\u2032\nsimplicity we will change the domains of O and O to Rn\u22650 and Rn\u22650 , as follows. For any\n\u2032\nn\nx\u2032 \u2208 R\u22650\n, we simply take O(Bx\u2032 /kx\u2032 k\u221e ) as the best response to x\u2032 (for x\u2032 = 0 an arbitrary\nelement of K, such as O(0) may be chosen). This scaling is logical since arg maxx\u2208K xt M x\u2032 =\narg maxx\u2208K xt M \u03b1x\u2032 for \u03b1 > 0. By linearity in v, it implies that, for the new oracle O and any\n\u2032\nx\u2032 \u2208 Rn\u22650 ,\nkx\u2032 k\u221e\nv(O(x\u2032 ), x\u2032 ) \u2265 max v(x, x\u2032 ) \u2212 \u01eb\n.\n(3)\nx\u2208K\nB\nSimilarly for O\u2032 .\nFix any sequence length T \u2265 1. Consider T periods of repeated play of the duel. Let the\nstrategies chosen by players 1 and 2, in period t, be xt and x\u2032t , respectively. Define the regret of\na player 1 on the sequence to be,\nmax\nx\u2208K\n\nT\nX\n\nv(x, x\u2032t ) \u2212\n\nt=1\n\nT\nX\n\nv(xt , x\u2032t ).\n\nt=1\n\nSimilarly define regret for player 2. The (possibly negative) regret of a player is how much\nbetter that player could have done using the best single strategy, where the best is chosen with\nthe benefit of hindsight.\nObservation 1. Suppose in sequence x1 , x2 , . . . , xT and x\u20321 , x\u20322 , . . . , x\u2032T , both players have at\nmost r regret. Let \u03c3 = (x1 + . . . + xT )/T , \u03c3 \u2032 = (x\u20321 + . . . + x\u2032T )/T be the uniform mixed\nstrategies over x1 , . . . , xT , and x\u20321 , . . . , x\u2032T , respectively. Then \u03c3 and \u03c3 \u2032 are \u01eb-minmax strategies,\nfor \u01eb = 2r/T .\nP\nProof. Say the minmax value of the game is \u03b1. Let a = T1 t v(xi , x\u2032i ). Then, by the definition\nof regret, a \u2265 \u03b1 \u2212 r/T , because otherwise player 1 would have more than r regret as seen by any\nminmax strategy for player 1, which guarantees at least an \u03b1T payoff on the sequence. Also, we\nhave that, against the uniform mixed strategy over x1 , . . . , xT , no strategy can achieve payoff\nof at least a \u2212 r, by the definition of regret (for player 2). Hence, \u03c3 guarantees player 1 a payoff\nof at least \u03b1 \u2212 2r/T . A similar argument shows that \u03c3 \u2032 is 2r/T -minmax for player 2.\nThe FEL algorithm for a player is simple. It has parameters B, R > 0, N \u2265 1 and also\ntakes as input an \u01eb best response oracle for the player. For player 1 with best response orace\nO, the algorithm operates as follows. On each period t = 1, 2, . . ., it chooses N independent\n\u2032\nuniformly-random vectors rt1 , rt2 , . . . , rtN \u2208 [0, R]m . It plays,\n\uf8eb\n!\uf8f6\nt\u22121\nN\nX\nX\n1 \uf8ed\nO rtj +\nx\u03c4 \uf8f8 \u2208 K.\nN j=1\n\u03c4 =1\nThe above is seen to be in K by convexity. Also recall that for ease of analysis, we have assumed\nthat O takes as input any positive combination of points in K \u2032 .\n\n22\n\n\f\u2032\n\nLemma 12. For any B, C, R, T, \u03b2, \u01eb > 0, and any r \u2208 [0, R]m ,\nT\nX\n\nv(O(r + x\u20321 + x\u20322 + . . . + x\u2032t ), x\u2032t ) \u2265 max\nx\u2208K\n\nt=1\n\nT\nX\n\nv(x, x\u2032t ) \u2212 2CR/B \u2212 T (T + R/B)\u01eb.\n\nt=1\n\nThe proof is a straightforward modification of Kalai and Vempala's proof [11]. What this is\nsaying is that the \"be the leader\" algorithm, which is \"one step ahead\" and uses the information\nfor the current period in choosing the current period's play, has low regret. Moreover, one\ncan perturb the payoffs by any amount in a bounded cube, and this won't affect the bounds\nsignificantly. The point of the perturbations, which we will choose randomly, will be to make\nit harder to predict what the algorithm will do. For the analysis, they will make it so that \"be\nthe leader\" and \"follow the leader\" perform similarly.\nProof. Define yt = r + x\u20321 + . . . + x\u2032t\u22121 . We first show,\nv(O(y1 ), r) +\n\nT\nX\n\nv(O(yt+1 ), x\u2032t ) \u2265 v(O(yT +1 ), r) +\n\nt=1\n\nT\nX\n\nv(O(yT +1 ), x\u2032t ) \u2212 T (T + R/B)\u01eb.\n\n(4)\n\nt=1\n\nThe facts that krk\u221e \u2264 R implies that v(x, r) \u2208 [\u2212CR/B, CR/B], and hence,\n!\nT\nT\nX\nX\n\u2032\n\u2032\nv(x, xt ) \u2212 T (T + R/B)\u01eb\nCR/B +\nv(O(yt+1 ), xt ) \u2265 max v(x, r) +\nx\u2208K\n\nt=1\n\n\u2265 max\nx\u2208K\n\nt=1\n\nT\nX\n\n!\n\nv(x, x\u2032t )\n\nt=1\n\n\u2212 T (T + R/B)\u01eb \u2212 2CR/B,\n\nwhich is equivalent to the lemma. We now prove (4) by induction on T . For T = 0, we have\nequality. For the induction step, it suffices to show that,\nv(O(yT ), r) +\n\nT\n\u22121\nX\n\nv(O(yT ), x\u2032t ) \u2265 v(O(yT +1 ), r) +\n\nt=1\n\nT\n\u22121\nX\n\nv(O(yT +1 ), x\u2032t ) \u2212 (R/B + T )\u01eb.\n\nt=1\n\nHowever, this is just an inequality between v(O(yT ), yT ) and v(O(yT +1 ), yT ), and hence follows\nfrom (3) and the fact that kyT k\u221e /B \u2264 R/B + T . Hence we have established (4) and also the\nlemma.\nLemma 13. For any \u03b4 \u2265 0, with probability \u2265 1 \u2212 2T e\u22122\u03b4\nT\nX\nt=1\n\nv(xt , x\u2032t ) \u2265 max\nx\u2208K\n\nT\nX\n\n2\n\nN\n\n,\n\nv(x, x\u2032t ) \u2212 \u03b4CT \u2212 2BCm\u2032 T /R \u2212 2CR/B \u2212 T (T + R/B)\u01eb.\n\nt=1\n\nProof. It is clear that yt and yt+1 are similarly distributed. For any fixed x\u20321 , x\u20322 , . . . , x\u2032T , define\nx\u0304t by,\nZ\n\u0001\n1\nO r + x\u20321 + . . . + x\u2032t\u22121 dr.\nx\u0304t = m\u2032\n\u2032\nR\nr\u2208[0,R]m\nBy linearity of expectation and v, it is easy to see that E[xt |x\u20321 , . . . , x\u2032t\u22121 ] = x\u0304t and,\nE[v(xt , x\u2032t ) | x\u20321 , . . . , x\u2032t ] = v(x\u0304t , x\u2032t ).\nBy Chernoff-Hoeffding bounds, since v(xt , x\u2032t ) \u2208 [\u2212C, C], for any \u03b4 \u2265 0, we have that with\n2\nprobability at least 1 \u2212 e\u22122\u03b4 N ,\n\u0002\nPr |v(xt , x\u2032t ) \u2212 v(x\u0304t , x\u2032t )| \u2265 \u03b4C\n\n23\n\n\u0003\n2\nx\u20321 , . . . , x\u2032t \u2264 2e\u22122\u03b4 N .\n\n\fP\nP\n2\nHence, by the union bound, Pr [ | t v(xt , x\u2032t ) \u2212 t v(x\u0304t , x\u2032t )| \u2265 \u03b4CT ] \u2264 2T e\u22122\u03b4 N .\nThe key observation of Kalai and Vempala is that x\u0304t and x\u0304t+1 are close because the m\u2032 \u2032\n\u2032\ndimensional translated cubes x\u20321 + . . . + x\u2032t\u22121 + [0, R]m and x\u20321 + . . . + x\u2032t + [0, R]m overlap\n\u2032\nsignificantly. In particular, they overlap in on all but at most a Bm /R fraction [11] of their\nvolume. Since v is in [\u22121, 1], this means that v(x\u0304t , x\u2032t ) \u2212 v(x\u0304t+1 , x\u2032t ) \u2264 2BCm\u2032 /R. This follows\nfrom the fact that v is bilinear, and hence when moved into the integral has exactly the same\nbehavior on all but a Bm\u2032 /R fraction of the points in each cube. This implies, that with\n2\nprobability \u2265 1 \u2212 2T e\u22122\u03b4 N ,\nT\nX\n\nv(xt , x\u2032t )\n\n\u2265\n\nt=1\n\nT\nX\n\nv(x\u0304t+1 , x\u2032t ) \u2212 \u03b4CT \u2212 2BCm\u2032 T /R.\n\nt=1\n\nCombining this with Lemma 12 completes the proof.\nWe are now ready to prove Lemma 2.\n\u0010 p\n\u00112/3\np\nProof of Lemma 2. We take T = 4C max(m, m\u2032 )/(3\u01eb)\n, R = B max(m, m\u2032 )T and N =\n\nln(4T C/\u03b4)/(2\u01eb2). As long as T \u2265 max(m, m\u2032 ), R/B \u2264 T and hence Lemma 13 implies that\nwith probability at least 1 \u2212 \u03b4, if both players play FEL then both will have regret at most\np\np\n\u01ebT + 4C max(m, m\u2032 )T + 2T 2 \u01eb \u2264 4C max(m, m\u2032 )T + 3T 2 \u01eb \u2264 12(max(m, m\u2032 )C 2 )2/3 \u01eb\u22121/3 .\nObservation 1 completes the proof.\n\nB\n\nA Racing Duel\n\nThe racing duel illustrates a simple example in which the beatability is unbounded, the optimization problem is \"easy,\" but finding polynomial-time minmax algorithms remains a challenging\nopen problem. The optimization problem behind the racing duel is routing under uncertainty.\nThere is an underlying directed multigraph (V, E) containing designated start and terminal\nnodes s, t \u2208 V , along with a distribution over bounded weight vectors \u03a9 \u2282 RE\n\u22650 , where \u03c9e\nrepresents the delay in traversing edge e. The feasible set X is the set of paths from sPto t. The\nprobability distribution p \u2208 \u2206(\u03a9) is an arbitrary measure over \u03a9. Finally, c(x, \u03c9) = e\u2208x \u03c9e .\nFor general graphs, solving the racing duel seems quite challenging. This is true even when\nrouting between two nodes with parallel edges, i.e., V = {s, t} and all edges E = {e1 , e2 , . . . , en }\nare from s to t. As mentioned in the introduction, this problem is in some sense a \"primal\"\nduel in the sense that it can encode any duel and finite strategy set. In particular, given any\noptimization problem with |X| = n, we can create a race where each edge ei \u2208 E corresponds\nto a strategy xi \u2208 X, and the delays on the edges match the costs of the associated strategies.\n\nB.1\n\nShortest path routing is 1-beatable\n\nThe single-player racing problem is easy: take the shortest path on the graph with weights\nwe = E\u03c9\u223cp [\u03c9e ]. However, this algorithm can be beaten almost always. Consider a graph with\ntwo parallel edges, a and b, both from s to t. Say the cost of a is \u01eb/2 > 0 with probability 1, and\nthe cost of b is 0 with probability 1 \u2212 \u01eb and 1 with probability \u01eb. The optimization algorithm\nwill choose a, but b beats a with probability 1 \u2212 \u01eb, which is arbitrarily close to 1.\n\nB.2\n\nPrice of anarchy\n\nTake social welfare to be the average performance, W (x, x\u2032 ) = (c(x) + c(x\u2032 ))/2. Then the price\nof anarchy for racing is unbounded. Consider a graph with two parallel edges, a and b, both\nfrom s to t. The cost of a is \u01eb > 0 with probability 1, and the cost of b is 0 with probability 3/4\nand 1 with probability 1/4. Then b a dominant strategy for both players, but its expected cost\nis 1/4, so the price of anarchy is 1/(4\u01eb), which can be arbitrarily large.\n\n24\n\n\fC\n\nWhen Competing is Easier than Playing Alone\n\nRecall that the racing problem from Appendix B was \"easy\" for single-player optimization, yet\nseemingly difficult to solve in the competitive setting. We now give a contrasting example: a\nproblem for which competing is easier than solving the single-player optimization.\nThe intuition behind our construction is as follows. The optimization problem will be based\nupon a computationally difficult decision problem, which an algorithm must attempt to answer.\nAfter the algorithm submits an answer, nature provides its own \"answer\" chosen uniformly at\nrandom. If the algorithm disagrees with nature, it incurs a large cost that is independent of\nwhether or not it was correct. If the algorithm and nature agree, then the cost of answering the\nproblem correctly is less than the cost of answering incorrectly.\nMore formally, let L \u2286 {0, 1}\u2217 be an arbitrary language, and let z \u2208 {0, 1}\u2217 be a string. Our\nduel will be D(X, \u03a9, p, c) where X = \u03a9 = {0, 1}, p is uniform, and the cost function is\n\uf8f1\n\uf8f4\n\uf8f20 if (x = \u03c9 = 1 and z \u2208 L) or (x = \u03c9 = 0 and z 6\u2208 L)\nc(x, \u03c9) = 1 if (x = \u03c9 = 1 and z 6\u2208 L) or (x = \u03c9 = 0 and z \u2208 L)\n\uf8f4\n\uf8f3\n2 if x 6= \u03c9\n\nThe unique optimal solution to this (single-player) problem is to output 1 if and only if z \u2208 L.\nDoing so is as computationally difficult as the decision problem itself. On the other hand, finding\na minmax optimal algorithm is trivial for every z and L, since every algorithm has value 1/2:\nfor any x\u2032 , v(1 \u2212 x\u2032 , x\u2032 ) = Pr[\u03c9 6= x\u2032 ] = 1/2 = v(x\u2032 , x\u2032 ).\n\nD\n\nAsymmetric Games\n\nWe note that all of the examples we considered have been symmetric with respect to the players,\nbut our results can be extended to asymmetric games. Our analysis of bilinear duels in Section\n2.1 does not assume symmetry when discussing bilinear games. For instance, we could consider\na game where player 1 wins in the case of ties, so player 1's payoff is Pr[c(x, \u03c9) \u2264 c(x\u2032 , \u03c9)]. One\nnatural example would be a ranking duel in which there is an \"incumbent\" search engine that\nappeared first, so a user prefers to continue using it rather than switching to a new one. This\ngame can be represented in the same bilinear form as in Section 2.5, the only change being a\nsmall modification of the payoff matrix M . Other types of asymmetry, such as players having\ndifferent objective functions, can be handled in the same way. For example, in a hiring duel,\nour analysis techniques apply even if the two players may have different pools of candidates, of\npossibly different sizes and qualities.\n\n25\n\n\f"}