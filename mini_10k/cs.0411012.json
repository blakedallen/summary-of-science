{"id": "http://arxiv.org/abs/cs/0411012v1", "guidislink": true, "updated": "2004-11-06T20:40:39Z", "updated_parsed": [2004, 11, 6, 20, 40, 39, 5, 311, 0], "published": "2004-11-06T20:40:39Z", "published_parsed": [2004, 11, 6, 20, 40, 39, 5, 311, 0], "title": "Capacity Analysis for Continuous Alphabet Channels with Side\n  Information, Part II: MIMO Channels", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0411065%2Ccs%2F0411079%2Ccs%2F0411086%2Ccs%2F0411087%2Ccs%2F0411061%2Ccs%2F0411014%2Ccs%2F0411094%2Ccs%2F0411098%2Ccs%2F0411092%2Ccs%2F0411099%2Ccs%2F0411002%2Ccs%2F0411001%2Ccs%2F0411038%2Ccs%2F0411025%2Ccs%2F0411088%2Ccs%2F0411081%2Ccs%2F0411052%2Ccs%2F0411074%2Ccs%2F0411011%2Ccs%2F0411030%2Ccs%2F0411072%2Ccs%2F0411051%2Ccs%2F0411005%2Ccs%2F0411076%2Ccs%2F0411003%2Ccs%2F0411016%2Ccs%2F0411059%2Ccs%2F0411036%2Ccs%2F0411022%2Ccs%2F0411070%2Ccs%2F0411100%2Ccs%2F0411056%2Ccs%2F0411040%2Ccs%2F0411077%2Ccs%2F0411060%2Ccs%2F0411090%2Ccs%2F0411017%2Ccs%2F0411032%2Ccs%2F0411027%2Ccs%2F0411050%2Ccs%2F0411043%2Ccs%2F0411073%2Ccs%2F0411097%2Ccs%2F0411053%2Ccs%2F0411067%2Ccs%2F0411066%2Ccs%2F0411096%2Ccs%2F0411082%2Ccs%2F0411015%2Ccs%2F0411007%2Ccs%2F0411035%2Ccs%2F0411078%2Ccs%2F0411057%2Ccs%2F0411091%2Ccs%2F0411021%2Ccs%2F0411010%2Ccs%2F0411018%2Ccs%2F0411093%2Ccs%2F0411095%2Ccs%2F0411039%2Ccs%2F0411033%2Ccs%2F0411023%2Ccs%2F0411062%2Ccs%2F0411048%2Ccs%2F0411019%2Ccs%2F0411029%2Ccs%2F0411047%2Ccs%2F0411042%2Ccs%2F0411041%2Ccs%2F0411034%2Ccs%2F0411075%2Ccs%2F0411069%2Ccs%2F0411031%2Ccs%2F0411084%2Ccs%2F0411055%2Ccs%2F0411085%2Ccs%2F0411058%2Ccs%2F0411012%2Ccs%2F0411009%2Ccs%2F0411006%2Ccs%2F0411028%2Ccs%2F0411083%2Ccs%2F0001023%2Ccs%2F0001002%2Ccs%2F0001015%2Ccs%2F0001020%2Ccs%2F0001019%2Ccs%2F0001011%2Ccs%2F0001005%2Ccs%2F0001021%2Ccs%2F0001009%2Ccs%2F0001010%2Ccs%2F0001014%2Ccs%2F0001022%2Ccs%2F0001017%2Ccs%2F0001008%2Ccs%2F0001016%2Ccs%2F0001018%2Ccs%2F0001025%2Ccs%2F0001007%2Ccs%2F0001027&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Capacity Analysis for Continuous Alphabet Channels with Side\n  Information, Part II: MIMO Channels"}, "summary": "In this part, we consider the capacity analysis for wireless mobile systems\nwith multiple antenna architectures. We apply the results of the first part to\na commonly known baseband, discrete-time multiple antenna system where both the\ntransmitter and receiver know the channel's statistical law. We analyze the\ncapacity for additive white Gaussian noise (AWGN) channels, fading channels\nwith full channel state information (CSI) at the receiver, fading channels with\nno CSI, and fading channels with partial CSI at the receiver. For each type of\nchannels, we study the capacity value as well as issues such as the existence,\nuniqueness, and characterization of the capacity-achieving measures for\ndifferent types of moment constraints. The results are applicable to both\nRayleigh and Rician fading channels in the presence of arbitrary line-of-sight\nand correlation profiles.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0411065%2Ccs%2F0411079%2Ccs%2F0411086%2Ccs%2F0411087%2Ccs%2F0411061%2Ccs%2F0411014%2Ccs%2F0411094%2Ccs%2F0411098%2Ccs%2F0411092%2Ccs%2F0411099%2Ccs%2F0411002%2Ccs%2F0411001%2Ccs%2F0411038%2Ccs%2F0411025%2Ccs%2F0411088%2Ccs%2F0411081%2Ccs%2F0411052%2Ccs%2F0411074%2Ccs%2F0411011%2Ccs%2F0411030%2Ccs%2F0411072%2Ccs%2F0411051%2Ccs%2F0411005%2Ccs%2F0411076%2Ccs%2F0411003%2Ccs%2F0411016%2Ccs%2F0411059%2Ccs%2F0411036%2Ccs%2F0411022%2Ccs%2F0411070%2Ccs%2F0411100%2Ccs%2F0411056%2Ccs%2F0411040%2Ccs%2F0411077%2Ccs%2F0411060%2Ccs%2F0411090%2Ccs%2F0411017%2Ccs%2F0411032%2Ccs%2F0411027%2Ccs%2F0411050%2Ccs%2F0411043%2Ccs%2F0411073%2Ccs%2F0411097%2Ccs%2F0411053%2Ccs%2F0411067%2Ccs%2F0411066%2Ccs%2F0411096%2Ccs%2F0411082%2Ccs%2F0411015%2Ccs%2F0411007%2Ccs%2F0411035%2Ccs%2F0411078%2Ccs%2F0411057%2Ccs%2F0411091%2Ccs%2F0411021%2Ccs%2F0411010%2Ccs%2F0411018%2Ccs%2F0411093%2Ccs%2F0411095%2Ccs%2F0411039%2Ccs%2F0411033%2Ccs%2F0411023%2Ccs%2F0411062%2Ccs%2F0411048%2Ccs%2F0411019%2Ccs%2F0411029%2Ccs%2F0411047%2Ccs%2F0411042%2Ccs%2F0411041%2Ccs%2F0411034%2Ccs%2F0411075%2Ccs%2F0411069%2Ccs%2F0411031%2Ccs%2F0411084%2Ccs%2F0411055%2Ccs%2F0411085%2Ccs%2F0411058%2Ccs%2F0411012%2Ccs%2F0411009%2Ccs%2F0411006%2Ccs%2F0411028%2Ccs%2F0411083%2Ccs%2F0001023%2Ccs%2F0001002%2Ccs%2F0001015%2Ccs%2F0001020%2Ccs%2F0001019%2Ccs%2F0001011%2Ccs%2F0001005%2Ccs%2F0001021%2Ccs%2F0001009%2Ccs%2F0001010%2Ccs%2F0001014%2Ccs%2F0001022%2Ccs%2F0001017%2Ccs%2F0001008%2Ccs%2F0001016%2Ccs%2F0001018%2Ccs%2F0001025%2Ccs%2F0001007%2Ccs%2F0001027&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this part, we consider the capacity analysis for wireless mobile systems\nwith multiple antenna architectures. We apply the results of the first part to\na commonly known baseband, discrete-time multiple antenna system where both the\ntransmitter and receiver know the channel's statistical law. We analyze the\ncapacity for additive white Gaussian noise (AWGN) channels, fading channels\nwith full channel state information (CSI) at the receiver, fading channels with\nno CSI, and fading channels with partial CSI at the receiver. For each type of\nchannels, we study the capacity value as well as issues such as the existence,\nuniqueness, and characterization of the capacity-achieving measures for\ndifferent types of moment constraints. The results are applicable to both\nRayleigh and Rician fading channels in the presence of arbitrary line-of-sight\nand correlation profiles."}, "authors": ["Majid Fozunbal", "Steven W. McLaughlin", "Ronald W. Schafer"], "author_detail": {"name": "Ronald W. Schafer"}, "author": "Ronald W. Schafer", "arxiv_comment": "Submitted to Trans. Inform. Theory", "links": [{"href": "http://arxiv.org/abs/cs/0411012v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0411012v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0411012v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0411012v1", "journal_reference": null, "doi": null, "fulltext": "Capacity Analysis for Continuous Alphabet Channels\n\narXiv:cs/0411012v1 [cs.IT] 6 Nov 2004\n\nwith Side Information, Part II: MIMO Channels\nMajid Fozunbal, Steven W. McLaughlin, and Ronald W. Schafer\u2217\nSchool of Electrical and Computer Engineering\nGeorgia Institute of Technology\nAtlanta, GA 30332-0250\n{majid, swm, rws}@ece.gatech.edu\nAugust 4, 2004\n\nAbstract\nIn this part, we consider the capacity analysis for wireless mobile systems with\nmultiple antenna architectures. We apply the results of the first part to a commonly\nknown baseband, discrete-time multiple antenna system where both the transmitter\nand receiver know the channel's statistical law. We analyze the capacity for additive white Gaussian noise (AWGN) channels, fading channels with full channel state\ninformation (CSI) at the receiver, fading channels with no CSI, and fading channels\nwith partial CSI at the receiver. For each type of channels, we study the capacity\nvalue as well as issues such as the existence, uniqueness, and characterization of the\ncapacity-achieving measures for different types of moment constraints. The results are\napplicable to both Rayleigh and Rician fading channels in the presence of arbitrary\nline-of-sight and correlation profiles.\n\nIndex Terms\nCapacity, capacity-achieving measure, channel state information, fading, multiple\nantenna, Rayleigh, and Rician.\n\u2217\n\nThis work was supported in part by Texas Instruments Leadership University Program.\n\n1\n\n\f1\n\nIntroduction\n\nMultiple antenna architectures have an increasingly important role to play in emerging wireless communication networks, particularly at base stations in cellular systems. Indeed, when\nused in conjunction with appropriately designed signal processing and coding algorithms,\nsuch architectures can dramatically enhance the performance of wireless mobile systems.\nHowever, in order to make efficient use of the resources, it is necessary to understand the\nfundamental limits of these systems.\nBecause of the time-varying nature of the channel in wireless mobile systems, the channel state (realization) is changing over time, called as fading, that imposes new challenges\nin determining the capacity of the channel. For this purpose, it is essential to know how\nmuch knowledge we have about the channel states either at the transmitter or at the receiver. In practice, depending on the application, we might have a range of scenarios from\nno channel state information (CSI) to full CSI. Hence, the capacity analysis and optimal\ncoding strategies for different CSI scenarios could be quite different. For example, if full\nCSI is available at both the transmitter and the receiver, then the capacity-achieving input\ndistribution is Gaussian, and the optimal encoder employs a power adaptation algorithm\n(water pouring) [1], [2], [3], [4]. In contrast, in the presence of full CSI at just the receiver,\nthe capacity-achieving input distribution is Gaussian [5], [6], but the encoder uses the same\naverage power over all time instances. This scenario is well investigated for multiple antenna\nchannels in the presence of i.i.d. Rayleigh fading [7], [8], and recent interests in this area\ninclude determining the capacity and the capacity-achieving measures in the presence of\narbitrary correlation and line-of-site fading components [9], [10], [11], [12], [13], [14].\nUnlike these scenarios, the capacity and capacity-achieving distributions for fading channels in the absence of CSI, such as applications where the fading changes rapidly, are generally\nunknown even for the case of single-input single-output (SISO) channels. For multiple-input\nmultiple-output (MIMO) channels with no CSI, Hochwald and Marzetta [15] have addressed\nthe capacity problem for Rayleigh channels under certain assumptions on the SNR regime\nand on the ratio of the number of transmitters to the coherence time of the channels. For\nSISO channels, [16] was the first rigorous result in this area that addressed the characteri-\n\n2\n\n\fzation of the capacity-achieving input distribution (subject to an average power constraint)\nfor Rayleigh channels. Unlike Rayleigh channels, the capacity and capacity-achieving input\ndistributions for Rician channels in the absence of CSI are barely touched. For low signalto-noise ratio, [17] showed that the capacity-achieving input distribution (subject to second\nand fourth moment constraints) is discrete. Asymptotic upper bound and lower bound for\nthe capacity of fading channels are derived in [18], subject to a maximum-power constraint.\nMore results can be found in [19], and [20].\nIn this part, we use the results of Part I and study the capacity problem of MIMO\nchannels in a unified manner, irrespective of the type of fading, the correlation profile, and\nthe amount of available knowledge about the CSI at the receiver. More precisely, we study the\ncapacity problem for AWGN channels, fading channels with full CSI at the receiver, fading\nchannels with no CSI, and fading channels with partial CSI at the receiver. For each type of\nchannels, we investigate its capacity as well as issues such as the existence, uniqueness, and\ncharacterization of the capacity-achieving measures of multiple antenna channels subject to\ndifferent types of input moment constraints. The organization of this paper and a summary\nof our contributions are as follows.\nIn Section 2, we introduce the multiple antenna system setup. In Section 3, we address the\ncapacity analysis for additive white Gaussian noise (AWGN) channels. Let n and m denote\nthe number of transmit and receive antennas, respectively, and let X = Cn and Y = Cm\ndenote the input and output alphabets of the channel. Suppose the channel realization\n\u0001\nis described by H\u0304 \u2208 Cm\u00d7n . For moment constraints of type E kxk\u03b7\u03b7 (1 \u2264 \u03b7),1 we show\nthat capacity-achieving measure, Po , exists uniquely. If \u03b7 > 2, we show that the capacity-\n\nachieving measure has a bounded support with no interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2,\nthen a necessary condition for Po is that for sufficiently large y in the column space of H\u0304,\n2\n\n\u03b7\n\nsupr\u22650 e\u2212r Po (ky \u2212 H\u0304xk2 \u2264 r\u03c3) = O(e\u2212\u03b1kyk\u03b7 ) for some \u03b1 > 0. For the case of \u03b7 = 2, we\nalso derive the capacity-achieving measure for these channels using Kuhn-Tucker conditions,\nwhere the result is the same as previously known results in [8].\nIn Section 4, we address the capacity analysis of MIMO fading channels with full CSI at\nthe receiver for Rayleigh or Rician channels with arbitrary correlation profile. For moment\n1\n\nRefer to [21] for definition of \u03b7-norm.\n\n3\n\n\f\u0001\nconstraints of type E kxk\u03b7\u03b7 (1 \u2264 \u03b7), we show that capacity-achieving measure, Po , exists\n\nuniquely. If \u03b7 > 2, we show that the capacity-achieving measure has a bounded support with\nno interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2, then a necessary condition for Po is that for almost\n\u03b7\n\n2\n\nevery channel side information v \u2208 V = Cm\u00d7n , supr\u22650 e\u2212r Po (ky\u2212vxk2 \u2264 r\u03c3) = O(e\u2212\u03b1(v)kyk\u03b7 )\nfor sufficiently large y in the column space of v and for some positive function \u03b1 : V \u2192 R+ .\nFor \u03b7 = 2, we fully characterize the capacity-achieving measure for these channels, where\nour results reduces to the results of [8] for the case of isotropic Rayleigh channels.\nIn Section 5, we address the capacity analysis of MIMO fading channels with no CSI at\nthe receiver for Rayleigh or Rician channels with arbitrary correlation profile. For moment\n\u0001\nconstraints of type E kxk\u03b7\u03b7 (1 \u2264 \u03b7), we show that capacity-achieving measure, Po , exists\n\nuniquely. If \u03b7 > 2, we show that the capacity-achieving measure has a bounded support with\nno interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2, a necessary condition for the capacity-achieving\nmeasure is\n\u03b7\n\nPo (kyk2 \u2264 kxk2 , R(y) \u2286 R(x)) = O(e\u2212\u03b1kyk\u03b7 ),\nwhere R(*) denote the row space of a matrix, and \u03b1 > 0 is a constant.\nIn Section 6, we address the capacity analysis of MIMO fading channels with partial CSI\nat the receiver. We consider a certain class of estimators where the channel side information\n\u0001\nis jointly Gaussian with the channel realization. For moment constraints of type E kxk\u03b7\u03b7\n(1 \u2264 \u03b7), we show that capacity-achieving measure, Po , exists uniquely. If \u03b7 > 2, we show that\nthe capacity-achieving measure has a bounded support with no interior point. In contrast,\nif 1 \u2264 \u03b7 \u2264 2, a necessary condition for the capacity-achieving measure is\n\u03b7\n\n\u2200v \u2208 V, Po (kyk2 \u2264 \u03bbmin(v)kxk2 , R(y) \u2286 R(x)) = O(e\u2212\u03b1(v)kyk\u03b7 ),\nwhere R(*) denotes the row space of a matrix, V denotes the state information space, \u03bbmin(v)\ndenotes the minimum eigenvalue of the covariance of channel realization conditioned on v,\nand \u03b1 : V \u2192 R+ is a positive function.\nFinally, Section 7 states some concluding remarks along with some directions for future\nresearch.\n\n4\n\n\f2\n\nGeneral System Model\n\nWe assume a wireless communication system employing n transmit and m receive antennas,\nwhere the baseband model of the channel is described by a discrete-time model as follows.\nFor each pair of transmit and receive antennas, (s, r), the path from transmit antenna s to\nreceive antenna r is represented by a complex symbol hrs called the path gain. Let H \u2208 Cm\u00d7n\ndenote an m\u00d7n matrix with hrs 's as its entries which is known as the channel state or channel\nrealization.2 Correspondingly, we denote the space of all possible states as H = Cm\u00d7n .\nWe assume a block channel model where in each block the channel is used L \u2265 1 times\nwhich is called the block-length. In each channel use, all antennas are used simultaneously,\nand n complex symbols are transmitted through n transmit antennas. We assume the channel\nis governed by a linear statistical model as follows.\nLet X = Cn\u00d7L and Y = Cm\u00d7L denote the input and output alphabets, respectively. At\neach block k, a matrix xk \u2208 X is transmitted through the transmit antennas and a matrix\nyk \u2208 Y is received in receiver which is described by\nyk = Hk xk + zk ,\n\n(1)\n\nwhere zk \u2208 Cm\u00d7L denotes the additive noise and at block k. We assume that the noise\nmatrices are temporally independent, with identically distributed (i.i.d.) complex normal\nentries which have zero mean and variance \u03c3 2 , i.e., CN (0, \u03c3 2 ). We assume that the channel\nstate remains unchanged during each block, but it might change after each block. We\nassume that at each block, there exists an element vk available at the receiver that gives\nsome information about the channel state Hk . This enables us to consider a broad range\nof channel state information (CSI) scenarios from no CSI where vk and Hk are statistically\nindependent, to full CSI where conditioned on vk there is no uncertainty about Hk . We\nassume that vk belongs to a Borel-measurable space V and there exists a joint measure\nQ \u25e6 R on H \u00d7 V and the input alphabet X is statistically independent from H \u00d7 V . Note\nthat to fully characterize the statistical properties of the channel, we need to specify the joint\n2\n\nTo clarify any confusion which might be raised by this notion in comparison to our notion in Part I, one\n\nshould note that channel realization matrix, H, denotes the state of the channel which was previously shown\nas s. The reason of this change is to comply with the common notion in the literature of MIMO channels.\n\n5\n\n\fprobability measure Q \u25e6 R, however, we postpone this to later sections where we address it\nin different scenarios.\nWe assume that there exists a nonnegative continuous function g : X \u2192 R+ and a\npositive value \u0393 > 0, such that for a K-length block code, the codewords are chosen to satisfy\nPK\n1\n\u03b7\nk=1 g(xk ) \u2264 \u0393. Motivated by practical scenarios, we consider g(x) = kxk\u03b7 (1 \u2264 \u03b7 < \u221e),\nK\nwhere the most common choice is g(x) = kxk22 (the Frobenius norm) and \u0393 is the average\n\nenergy per block. By the Law of Large Numbers [22, p. 325], as K grows to infinity, this\nis equivalent to assuming that the empirical measures of codes are obtained from a set of\ninput probability measures which are characterized by a continuous positive function g(x)\ntogether with a real value \u0393 > 0 as follows,\nZ\nn\no\nPg,\u0393 (X) = P \u2208 P(X) |\ng(x)dP \u2264 \u0393 .\nNote that for the choice g(*) = kxk\u03b7\u03b7 (1 \u2264 \u03b7 < \u221e),3 one can easily verify that g satisfy the\nhypothesis of Lemma 3.1 of Part I, hence, Pg,\u0393 (X) is weak* compact.\nIt just remains to specify the generic statistical law that governs the channel, that is to\ndescribe W (*|x, H). For this purpose, recall that the additive white noise is a complex normal\nrandom matrix with i.i.d. components. Hence, the channel is described by the conditional\nmeasure, W (*|x, H), which is absolutely continuous with respect to the Lebesgue measure,\ni.e., W (*|x, H) \u226a \u03bcY , with the density function\nf(y|x, H) =\n\nky\u2212Hxk2\n1\n2\n\u2212\n\u03c32\n.\ne\nmL\n2mL\n\u03c0 \u03c3\n\n(2)\n\nLet define an auxiliary measure T as follows,\n\u2200 E \u2208 BY ,\n\n1\nT (E) =\nmL\n\u03b2\u03c0 \u03c3 2mL\n\nZ\n\ne\u2212\n\np\n\u03b12 kyk\n2\n\u03c32\n\nd\u03bcY ,\n\n(3)\n\nE\n\nwhere 1 < p \u2264 2 and 0 < \u03b1 < 1 are free variables and \u03b2 > 0 is chosen such that T has a\nunit norm. Since (2) is nonzero, one can verify that W (*|x, H) \u226a T for all x and H and the\ndensity function of W (*|x, H) with respect to T is described by\np\n\nfT (y|x, H) ,\n3\n\n\u03b12 kyk \u2212ky\u2212Hxk2\n2\ndW (*|x, H)\n2\n\u03c32\n= \u03b2e\n.\ndT\n\nRefer to [21] for the definition of \u03b7-norm.\n\n6\n\n(4)\n\n\f3\n\nAdditive White Gaussian Noise Channels\n\nIn this section, we consider a class of wireless channels where the physical medium between\nthe transmitter and receiver remains unchanged throughout the communication. We assume\nthat the channel is governed by a linear model as (1) and the channel state (realization) is\nHk = H\u0304 for all blocks, where H\u0304 is known both at the transmitter and the receiver. Thus,\nwe characterize the channel just by the matrix H\u0304. To emphasize that a channel is Gaussian,\nwe use a subscript \"G\" and denote the channel by WG (H\u0304). Since H\u0304 is known, there is no\nadvantage of taking L > 1. Hence, throughout this section, we assume that L = 1.\nIn the framework of the general system model, we consider that V = H where the\nprobability measure Q \u25e6 R on H \u00d7 V is a point mass measure (Dirac measure) [21] at (H\u0304, H\u0304)\nthat can be explained as follows. Since there is no uncertainty on the channel realization\nwith the knowledge of v at the receiver, the conditional probability measure Qv on H is a\npoint mass measure at H = v. Moreover, because the channel state remains unchanged, the\nmeasure R on V is a point mass measure at v = H\u0304. As a result, we observe that the channel\ncan be simply described by measure WQH\u0304 (*|x) \u226a T with the density function\nZ\np\n\u03b12 kyk2 \u2212ky\u2212H\u0304xk2\n2\n\u03c32\n.\nfT,QH\u0304 (y|x) = fT (y|x, H)dQH\u0304 = \u03b2e\nFor every P \u2208 Pg,\u0393 (X), it can be verified that PWQH\u0304 \u226a T with the density function\nZ \u03b12 kykp \u2212ky\u2212H\u0304xk2\n2\n2\n\u03c32\nfT,P,QH\u0304 (y) = \u03b2 e\ndP.\n\n(5)\n\n(6)\n\nAs a result, we simplify the expression of the mutual information (6 of Part I) for the additive\nwhite Gaussian channels as\nZZ\nZ\nI(P, WG (H\u0304)) =\nfT,QH\u0304 (y|x) log2 fT,QH\u0304 (y|x)dT dP \u2212 fT,P,QH\u0304 (y) log2 fT,P,QH\u0304 (y)dT . (7)\nNote that both of the terms on the right-hand side (RHS) in (7) are finite.\n\n3.1\n\nProperties of mutual information\n\nIn this subsection, we address some analytical properties of the mutual information function\nof the Gaussian channels. This includes properties such as strict concavity and continuity of\nthe mutual information, which are used in the capacity analysis of channels.\nRecall that Proposition 3.3 of Part I addresses the strict concavity of the mutual infor7\n\n\fmation in general. Since the strictness property is essential to addressing the uniqueness\nof the capacity-achieving probability measure, simpler arguments are of interest. Using the\nfollowing observation, we address this issue.\nObservation 3.1. For every P \u2208 Pg,\u0393(X), fT,P,QH\u0304 (y) is continuous and nonzero over Y .\nProof. By (5), the continuity and positiveness of fT,QH\u0304 (y|x) are obvious. The positiveness\nof fT,QH\u0304 (y|x) implies the positiveness of fT,P,QH\u0304 (y). To prove the continuity, suppose that\nyn \u2192 y in the Euclidean norm. Then,\nlim fT,P,QH\u0304 (yn ) = \u03b2 lim\nn\n\nn\n\nZ\n\n= \u03b2 lim e\n\ne\n\np\n\u03b12 kyn k \u2212kyn \u2212H\u0304xk2\n2\n2\n\u03c32\n\np\n\u03b12 kyn k2\n\u03c32\n\nBy DCT = \u03b2e\n\nlim\nn\n\nn\n\np\n\u03b12 kyk\n2\n\u03c32\n\nZ\n\ne\u2212\n\nZ\n\n\u2212\n\ne\n\nky\u2212H\u0304xk2\n2\n\u03c32\n\ndP\n\nkyn \u2212H\u0304xk2\n2\n\u03c32\n\ndP\n\ndP\n\n= fT,P,QH\u0304 (y).\nThis proves the continuity of fT,P,QH\u0304 (y) over Y .\nWe define that two probability measures P1 , P2 \u2208 Pg,\u0393 (X) are equivalent over WG (H\u0304),\nif they induce the same output probability measure. Equivalently, two input measures are\nequivalent over WG (H\u0304) if fT,P1 ,QH\u0304 (y) = fT,P2 ,QH\u0304 (y) for all y \u2208 Y .\nProposition 3.1 (Strict concavity). The mutual information of a Gaussian channel\nWG (H\u0304) is strictly concave with respect to the convex combination of two input measures\nP1 and P2 , unless they are equivalent over WG (H\u0304).\nProof. By Observation 3.1, if there exists y \u2208 Y such that fT,P1 ,QH\u0304 (y) 6= fT,P2 ,QH\u0304 (y), then\nthere exists a neighborhood Uy \u2282 Y of y with that property. Then, by definition of T (3),\nT (Uy ) > 0. This means that the set Uy \u00d7 {H\u0304} complies the requirements of Proposition\n3.3 of Part I. As a result, the mutual information function of a Gaussian channel is strictly\nconcave with respect to the convex combination of P1 and P2 if and only if there exists\ny \u2208 Y such that fT,P1 ,QH\u0304 (y) 6= fT,P2 ,QH\u0304 (y). By definition of equivalency for input probability\nmeasures, we deduce the assertion.\nAnother important property of the mutual information in capacity analysis is its weak*\ncontinuity, which is stated as follows.\n8\n\n\fProposition 3.2 (Continuity). The mutual information of any Gaussian channel WG (H\u0304)\nis weak* continuous over Pg,\u0393(X).\nProof. It suffices to check if the hypothesis of Theorem 3.3 of Part I is satisfied. We prove\nthe theorem for g(x) = kxk22 , and the proof for other choices of g is also similar. To prove\nhypothesis (a) of Theorem 3.3 of Part I, we proceed as follows. Assume that \u03b1 < 1 and\np < 2, which are fixed, and let\nAc = {(x, y) \u2208 X \u00d7 Y |fT,QH\u0304 (y|x) log2 fT,QH\u0304 (y|x) > c2 }.\nLet define\nBc = {(x, y) \u2208 X \u00d7 Y |fT,QH\u0304 (y|x) > c}.\nFor sufficiently large c > 0, e.g. c > 10, it can be observed that Ac \u2282 Bc . But the condition\nfT,QH\u0304 (y|x) > c is equivalent to the condition\nc\n\u03b12 kykp2 \u2212 ky \u2212 H\u0304xk22 > \u03c3 2 ln .\n\u03b2\nHence, if we define\nc\nEc = {(x, y) \u2208 X \u00d7 Y |\u03b12 kykp2 > \u03c3 2 ln },\n\u03b2\nwe can deduce that for sufficiently large c > 0, we would have Ac \u2286 Bc \u2286 Ec . Let \u03c9(c) =\n\u00111/p\n\u0010 2\nc\n\u03c3\nln\n. As a result, for every P \u2208 Pg,\u0393 (X)\n\u03b12\n\u03b2\nZZ\nZZ\nfT,QH\u0304 (y|x) log2 fT,QH\u0304 (y|x) dT dP \u2264\nfT,QH\u0304 (y|x) log2 fT,QH\u0304 (y|x) dT dP\nAc\nEc\nZZ\nky\u2212H\u0304xk2\n1\n2\n\u2212\n\u03c32\nd\u03bcY dP\ne\n\u2264 |log2 \u03b2|\nm\n2m\nEc \u03c0 \u03c3\nZZ\n2\nlog2 e\n\u03b12 kykp2 \u2212 ky\u2212H\u0304xk\n2\n\u03c32\n+ 2\ne\nd\u03bcY dP\nm\n2m\n\u03c3\nEc \u03c0 \u03c3\n\u0013 ZZ\n\u0012\n2\nkyk22 \u2212 ky\u2212H\u0304xk\nlog2 e\n|log2 \u03b2|\n2\n2\n\u03c3\n+ 2 2\u2212p\ne\nd\u03bcY dP\n\u2264\n2\nm\n2m\n\u03c9 (c)\n\u03c3 \u03c9 (c)\n\u03c0 \u03c3\n\u0012\n\u0013\nZ\n|log2 \u03b2|\nlog2 e\n2\n=\n(m\u03c3 + kH\u0304xk22 dP )\n+ 2 2\u2212p\n2\n\u03c9 (c)\n\u03c3 \u03c9 (c)\n\u0013\n\u0012\nlog2 e\n|log2 \u03b2|\n(m\u03c3 2 + kH\u0304k2 \u0393)\n+ 2 2\u2212p\n\u2264\n\u03c9 2 (c)\n\u03c3 \u03c9 (c)\nSince \u03c9(c) \u2192 \u221e as c \u2192 \u221e, we can deduce that\nZ\nfT,QH\u0304 (y|x) log2 fT,QH\u0304 (y|x) dT dP = 0.\nlim sup\nc\u2192\u221e P\u2208P\n\ng,\u0393 (X)\n\nAc\n\n9\n\n\fThis implies that the hypothesis (a) of Theorem 3.3 of Part I holds. To verify the hypothesis\n(b), for a fixed y, let Dc = {x \u2208 X : fT,QH\u0304 (y|x) > c}. Then,\nZ\nZ\n1\nfT,QH\u0304 (y|x)dP \u2264\nsup\nsup\n(fT,QH\u0304 (y|x))2dP\nc P\u2208Pg,\u0393 (X)\nP\u2208Pg,\u0393 (X) Dc\nZ\np\n\u03b12 kyk2 \u2212ky\u2212H\u0304xk2\n2\n\u03b22\n\u03c32\ndP\n=\nsup\ne2\nc P\u2208Pg,\u0393 (X)\n\u03b2 2 2 \u03b12 kyk\n2\ne \u03c32 \u2192 0, as c \u2192 \u221e.\nc\np\n\n\u2264\n\nThus, since both hypotheses of Theorem 3.3 of Part I hold, the mutual information is weak*\ncontinuous.\n\n3.2\n\nCapacity analysis\n\nIn this subsection, we address issues on the existence, the uniqueness, and the characterization of the capacity-achieving measures for Gaussian channels.\nLemma 3.1 (Existence). For any Gaussian channel WG (H\u0304) and the set Pg,\u0393 (X), there\nexists a measure Po \u2208 Pg,\u0393 (X) that achieves the capacity of the channel WG (H\u0304).\nProof. Proposition 3.2 states the weak* continuity of the mutual information over Pg,\u0393(X).\nSince Pg,\u0393(X) is weak* compact, by Proposition 4.1 of Part I, we conclude the assertion.\nLemma 3.1 states the existence of the capacity-achieving measure over Gaussian channels.\nTo address its uniqueness, we use an earlier result on strict concavity of mutual information,\ni.e., Proposition 3.1.\nLemma 3.2 (Uniqueness). For any Gaussian channel WG (H\u0304) and the set Pg,\u0393 (X), the\ncapacity-achieving measure is unique up to the equivalency of input measures.\nProof. Suppose there exist distinct probability measures Po and P\u2217 that achieve the capacity.\nBy Proposition 3.1, the mutual information is strictly concave with respect to their convex\ncombination. This means that any measure in the form \u03b1Po + (1 \u2212 \u03b1)P\u2217 achieves a higher\nmutual information that is a contradiction to optimality of Po and P\u2217 . Thus, Po and P\u2217 must\nbe equivalent.\n\n10\n\n\fSo far, in this subsection, we have shown the existence and the uniqueness of the capacityachieving measure over AWGN channels. It remains to provide some insight to the characterization of such input measure.\nProposition 3.3. Let g(*) = k * k\u03b7\u03b7 for 1 \u2264 \u03b7. If \u03b7 > 2, the capacity-achieving measure has a\nbounded support with no interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2, then a necessary condition\n2\n\nfor Po is that for sufficiently large y in the column space of H\u0304, supr\u22650 e\u2212r Po (ky \u2212 H\u0304xk2 \u2264\n\u03b7\n\nr\u03c3) = O(e\u2212\u03b1kyk\u03b7 ) for some \u03b1 > 0.\nProof. Suppose Po WQH\u0304 is the optimal capacity-achieving output measure. Applying KuhnTucker condition, Theorem 4.3 of Part I, to our problem, we need to find a positive value\n\u03b3 > 0 such that\nD(WQH\u0304 (*|x)kPoWQH\u0304 ) \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\nUsing some straightforward mathematical manipulation, this results to\nZ\nky\u2212H\u0304xk2\n1\n2\n\u2212\n2\n\u03c32\n\u2212m log2 (\u03c0\u03c3 e) \u2212\ne\nlog2 fPo ,QH\u0304 (y)d\u03bcY \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\n2\nm\n(\u03c0\u03c3 )\n\n(8)\n\nThe problem is now finding an output density function together with the value \u03b3 > 0\nsuch that the above inequality is satisfied with equality on all x \u2208 X in the support of the\ncapacity-achieving measure.\nCase \u03b7 > 2: We note that (8) has a constant part and a part that depends on x. It can\nbe inspected that for large values of x the term \u03b3kxk\u03b7\u03b7 is a dominant term. Hence, for large\nvalues of x to be in the support of Po , the integral term must have a growth rate of kxk\u03b7\u03b7 ;\notherwise, the support is bounded. As a result, it suffices to study the asymptotic behavior\n(tail) of the density function fPo ,QH\u0304 (y) =\n\nd(Po WQ )\nH\u0304\n\nd\u03bcY\n\n. We have\n\nky\u2212H\u0304xk2\n1\n2\n\u2212\n\u03c32\ne\ndPo\nm\n2m\n\u03c0 \u03c3\nZ\n2\nky\u2212H\u0304xk2\n1\n2 \u2212 ky+H\u0304xk2\n\u2212\n2\n2\n\u03c3\n\u03c3\n\u2265 m 2m e\ne\ndPo\n\u03c0 \u03c3\nZ\n2kH\u0304xk2\n2kyk2\n1\n2\n2\n= e\u2212 \u03c32 m 2m e\u2212 \u03c32 dPo .\n\u03c0 \u03c3\n\nfPo ,QH\u0304 (y) =\n\nZ\n\nThis means that \u2212 log2 fPo ,QH\u0304 (y) = O(kyk22). As a result, it can be verified that for \u03b7 > 2,\nthere exists no choice for the input measure so that the integral part of (8) catch up with\nthe growth rate of kxk\u03b7\u03b7 for large values of x. Thus, the support of the capacity-achieving\n11\n\n\finput measure is bounded for \u03b7 > 2. One can verify that the hypothesis of Proposition 4.3\nof Part I holds for Gaussian channels. More specifically, the function \u03c1(z) is analytic on Z\nexcept possibly at z = 0. As a result, we deduce that Sx (Po ) can not have any interior point.\nCase \u03b7 \u2264 2: Note that every y \u2208 Y can be uniquely decomposed as y = yH\u0304 + yH\u0304 \u22a5 where\nyH\u0304 is in the column space of H\u0304 and yH\u0304 \u22a5 is orthogonal to the column space of H\u0304. One can\nobserve that the contribution of yH\u0304 \u22a5 is on the constant terms of (8) and it does not affect\nour analysis on the terms that depend on x. As a result, for every y \u2208 Y in the column\nspace of H\u0304, we have\n1\nfPo ,QH\u0304 (y) = m 2m\n\u03c0 \u03c3\n\nZ\n\ne\u2212\nZ\n\nky\u2212H\u0304xk2\n2\n\u03c32\n\ndPo\n\nky\u2212H\u0304xk2\n1\n2\n\u2212\n\u03c32\ndPo\ne\nm\n2m\nr \u03c0 \u03c3\nky\u2212H\u0304xk2 \u2264r\u03c3\n1\n2\n\u2265 m 2m sup e\u2212r Po (ky \u2212 H\u0304xk2 \u2264 r\u03c3)\n\u03c0 \u03c3\nr\n\n\u2265 sup\n\n2\n\nLet k(y) , supr e\u2212r Po (ky \u2212 H\u0304xk2 \u2264 r\u03c3). Then, for every y in the column space of H\u0304, we\ndeduce that\n\u2212 log2 fPo ,QH\u0304 (y) = O(min (\u2212 log2 k(y), kyk22)).\nTwo scenarios can be considered. Either the support is bounded or it is not. For the latter\ncase to be true, we need to have the integral term of growth rate of kxk\u03b7\u03b7 . Hence, it is\n\u03b7\n\nnecessary to have k(y) = O(e\u2212\u03b1kyk\u03b7 ) for sufficiently large y in the column space of H\u0304 where\n\u03b1 is a positive real number. We remark that this necessary condition remains valid for the\nother case also.\nProposition 3.3 provide us intuition about the support and the possible behavior of capacity achieving measures subject to different choices for \u03b7. However, it is still not possible\nto obtain closed form expressions for the the capacity-achieving measure for the general\nchoice of g(*) = k * k\u03b7\u03b7 (\u03b7 6= 2). However, for the case of \u03b7 = 2, it is possible to characterize the capacity achieving measure as shown in [8]. Using the observation that among\ndistributions with the same covariance matrix, the Gaussian distribution achieves the largest\nrelative entropy [23], Telatar [8] proves that the capacity-achieving input measure must have\na Gaussian density function. Here, we use Kuhn-Tucker conditions, i.e., Theorem 4.3 of\nPart I, and provide a different approach toward characterizing the capacity-achieving input\n12\n\n\fmeasure.\nTheorem 3.1. Let g(*) = k * k22 . The probability measure in Pg,\u0393 (X) which achieves the\ncapacity of the channel WG (H\u0304) is absolutely continuous with respect to the Lebsegue measure\nwith a unique (a.e.) Gaussian density function of zero mean and covariance matrix to\nh1\ni+\nSx =\nI \u2212 \u03c3 2 (H\u0304 \u2032 H\u0304)\u22121 ,\n\u03bc\nand \u03bc is selected such that tr (Sx ) = \u0393. Moreover, the capacity of this channel is\nC = log2 det(I +\n\n1\nH\u0304Sx H\u0304 \u2032 ).\n\u03c32\n\nProof. Suppose Po WQv is the optimal capacity-achieving output measure. Applying KuhnTucker condition, Theorem 4.3 of Part I, to our problem, we need to find a positive value\n\u03b3 > 0 such that\nD(WQH\u0304 (*|x)kPoWQH\u0304 ) \u2212 \u03b3kxk22 \u2264 C \u2212 \u03b3\u0393,\nfor every x \u2208 X. Using some straightforward mathematical manipulation, this results to\nZ\nky\u2212H\u0304xk2\nd(Po WQH\u0304 ) 1\n2\n\u2212\n2\n\u03c32\nd\u03bcY \u2212 \u03b3kxk22 \u2264 C \u2212 \u03b3\u0393.\n(9)\n\u2212m log2 (\u03c0\u03c3 e) \u2212 log2\ne\n2\nm\nd\u03bcY\n(\u03c0\u03c3 )\nNow, the problem is to find an output density function together with the value \u03b3 > 0\nsuch that the above inequality is satisfied with equality on all x \u2208 X in the support of the\ncapacity-achieving measure.\nSuppose x \u2208 X be in the support of the optimizing input measure. Then, we need to have\nthe integration in the above inequality result into a quadratic form. To obtain a quadratic\nform out of integral, an straightforward option is to assume log2\n\nd(Po WQv )\nd\u03bcY\n\n= a \u2212 kbyk22 , where\n\na is a constant value and b is an m \u00d7 m matrix. As a result, we will obtain\n\u0001\n\u2212m log2 (\u03c0\u03c3 2 e) \u2212 a + \u03c3 2 tr (b\u2032 b) + tr x\u2032 H\u0304 \u2032 b\u2032 bH\u0304x \u2212 \u03b3kxk22 \u2212 C + \u03b3\u0393 = 0\n\nBut to solve such equation, we can separate the constant part and the variable part to obtain\n\uf8f1\n\uf8f2 x\u2032 (H\u0304 \u2032 b\u2032 bH\u0304 \u2212 \u03b3I)x = 0\n(10)\n\uf8f3 \u2212m log (\u03c0\u03c3 2 e) \u2212 a + \u03c3 2 tr (b\u2032 b) \u2212 C + \u03b3\u0393 = 0\n2\n\nTo satisfy the first equation of (10), we need to consider two cases. For any x in the support\n\nof P, it suffices to have x as an eigenvector of H\u0304 \u2032 b\u2032 bH\u0304 with its corresponding eigenvalue\n13\n\n\fequal to \u03b3. This implies that we can take b such that H\u0304 \u2032 b\u2032 bH\u0304 represents a projection matrix\nsuch that its column space denotes the set of all x in the support of Po . For any x not in\nthe support, it suffices to have x\u2032 (H\u0304 \u2032 b\u2032 bH\u0304 \u2212 \u03b3I)x \u2264 0. Let t denote the dimension of the\nspace that is spanned by the vectors in support. Let Mt denote a diagonal m \u00d7 m matrix\nwith the first t elements equal to 1, and the rest of them 0. Thus, it suffices to take b\nsuch that b\u2032 b = \u03b3(H\u0304 H\u0304 \u2032 )\u2020 Mt + \u03b2(I \u2212 Mt ), where (*)\u2020 denotes the pseudo-inverse operator and\n\u03b2 > 0 is selected later to satisfy the above requirements. Note that t is smaller or equal\nto the rank of H, since if some x is in the null space of H\u0304, it can not be in the support.\nThus, b\u2032 b is a full-rank positive definite matrix. This implies that the density function of\nPo WQv with respect to the Lebesgue measure is Gaussian with zero mean and covariance\n\u0010\n\u0011\nlog2 e\n\u22121\n\u2032\n\u22121\n\u03b3 H\u0304 H\u0304 Mt + \u03b2 (I \u2212 Mt ) . But, to have such Gaussian density at the output, it\n2\nsuffices to have a Gaussian input with zero mean and covariance Sx such that\n\u0010\n\u0011\n\u22121\n\u2032\n\u22121\nlog2 e \u03b3 H\u0304 H\u0304 Mt + \u03b2 (I \u2212 Mt ) = H\u0304Sx H\u0304 \u2032 + \u03c3 2 I.\n\nThus, we need to pick Sx , \u03b3, \u03b2, and t to satisfy the above requirement. By Kuhn-Tucker\nR\ncondition we need to have \u03b3( kxk22 dPo \u2212 \u0393) = 0. Since, \u03b3 can not be zero, we need to\n\nfind \u03b3 in the late equation with the constraint tr (Sx ) = \u0393. As the result, it suffices to take\n\u03b2=\n\nlog2 e\n,\n\u03c32\n\nand to take\nS=\n\nh log e\ni+\n2\nI \u2212 \u03c3 2 (H\u0304 \u2032 H\u0304)\u2020 Mt ,\n\u03b3\n\nwhere [*]+ ceils negative eigenvalues to 0. It just remains to select t, \u03b3 such that tr (S) = \u0393.\nWe emphasize that t \u2264 rank(H\u0304). Thus, to find the solution we first pick t = rank(H\u0304) and\nsearch for the value of \u03b3. If we find the solution, we stop. Otherwise we reduce t by 1 and\nrepeat the procedure till we find the solution.\nPicking \u03b3 and S as explained would result to obtain\na = \u2212m log2 (\u03c0) \u2212 log det (\n\nlog2 e\nH\u0304 H\u0304 \u2032 Mt + \u03c3 2 (I \u2212 Mt )).\n\u03b3\n\nFurthermore, we would have \u03c3 2 tr (b\u2032 b) = m log2 e \u2212 \u03b3\u0393. Thus, substituting and satisfying\nthe equality in the second equation of (10) would result to\nC = log2 det(I +\n\n1\nH\u0304S H\u0304 \u2032 ),\n\u03c32\n\nwhere S is chosen as explained. For the sake of convenience in presentation, let \u03bc =\n14\n\n\u03b3\n,\nlog2 e\n\n\fthen we can simplify determination of S to\nh1\ni+\nS=\nI \u2212 \u03c3 2 (H\u0304 \u2032 H\u0304)\u22121 ,\n\u03bc\nwhere \u03bc is selected such that tr (S) = \u0393.\nThe uniqueness property follows by Lemma 3.2 and the fact that that there exists no\nother choice for Po to yield to the same Gaussian density function on the output.\n\n4\n\nFull Channel State Information at the Receiver\n\nIn mobile communications, sometimes it is possible to obtain an estimation of the channel\nrealization at the receiver. This is specifically true in block-fading channels with a large\ncoherence time, i.e., where there is sufficient delay between changes in channel realizations.\nIn these systems, the transmitter assigns a portion of each block for training, where it sends\nsome known signals to the receiver, so that the receiver obtains an estimate of the current\nchannel realization. This process, called as channel estimation, allows the receiver to obtain\nsome information about the channel state from none to (asymptotically) full channel state\ninformation (CSI).\nIn this section, we assume that full CSI is available at the receiver. Considering the\ngeneral linear statistical model (1), this means that the channel realization, Hk , changes\nthrough the time but it is perfectly known at the receiver. We assume that the channel\nis Rayleigh or Rician faded [24], [5]. This means that the channel realization changes in\naccordance of a probability measure with a Gaussian density function with respect to the\nLebesgue measure. If the density function is centralized (zero mean), the fading is Rayleigh;\notherwise, it is Rician. In either case, the channel statistical law is fully characterized by the\nline-of-sight (mean) and scattering component (covariance matrix) of the channel realization\n[24], [5].\nLet vec (*) denotes the vector operator that concatenates the columns of an m\u00d7n matrix,\nrespectively, into an mn \u00d7 1 vector. Thus, for every channel realization H, we denote its\nvector form as vec H, which is a multivariate random vector in Cmn that is characterized by\n\n15\n\n\fthe mean value vec H\u0304 and the spatial covariance matrix\n\u03a3 = cov (vec H, vec H) .\nTo emphasize that the channel state information is fully known, we use a subscript \"F \". As\na result, we denote the channel as WF (H\u0304, \u03a3). Since the channel realization is known at the\nreceiver, there exists no advantage in taking L > 1 in the capacity analysis. Hence, likewise\nthe previous section, we assume L = 1.\nSince the channel realization is fully known at the receiver, we assume that V = Cm\u00d7n is\nthe space of state information and the conditional probability measure Qv on H is a point\nmass measure at H = v. Since the channel is Rayleigh or Rician fading, the probability\nmeasure on V , i.e., R, is absolutely continuous with respect to the Lebesgue measure with\nthe Gaussian density function\ndR\n1\n\u2032\n\u22121\n= mn\ne\u2212vec (v\u2212H\u0304 )\u03a3 vec (v\u2212H\u0304 ) .\nd\u03bcV\n\u03c0 det \u03a3\n\n(11)\n\nBy definition of the auxiliary measure T (3), one can inspect that WQv (*|x) \u226a T for\nevery v and x, where its density function is obtained from (4) as\nZ\np\n\u03b12 kyk \u2212ky\u2212vxk2\n2\n2\n\u03c32\nfT,Qv (y|x) = fT (y|x, H)dQv = \u03b2e\n.\nFor every P \u2208 Pg,\u0393 (X), it can be verified that PWQv \u226a T with the density function\nZ \u03b12 kykp \u2212ky\u2212vxk2\n2\n2\n\u03c32\nfT,P,Qv (y) = \u03b2 e\ndP.\nAs a result, the mutual information of this channel can be expressed as\nZZZ\nI(P, WF (H\u0304, \u03a3)) =\nfT,Qv (y|x) log2 fT,Qv (y|x)dT dPdR\nZZ\n\u2212\nfT,P,Qv (y) log2 fT,P,Qv (y)dT dR.\n\n4.1\n\n(12)\n\n(13)\n\n(14)\n\nProperties of mutual information\n\nIn this subsection, we address properties such as strict concavity and continuity of the\nmutual information, which are used in capacity analysis of fading channels with full CSI at\nthe receiver.\nIn Proposition 3.3 of Part I, we have addressed the strict concavity of the mutual information. Since this property is essential to addressing the uniqueness of the capacity-achieving\n16\n\n\fprobability measure, we address a simpler condition to verify the strict concavity of the\nmutual information for fading channels with full CSI at the receiver. Using the following\nobservation, we address this issue.\nObservation 4.1. For every P \u2208 Pg,\u0393 (X), fT,P,Qv (y) is continuous and nonzero over Y \u00d7V .\n\nProof. By (12), the continuity and positiveness of fT,Qv (y|x) are obvious. The positiveness\nof fT,Qv (y|x) implies the positiveness of fT,P,Qv (y). To prove the continuity, suppose that\n(yn , vn ) \u2192 (y, v) in the Euclidean norm. Then,\nZ \u03b12 ky kp \u2212ky \u2212v xk2\nn 2\nn\nn 2\n\u03c32\nlim fT,P,Qvn (yn ) = \u03b2 lim e\ndP\nn\nn\nZ\np\n\u03b12 kyn k2\nkyn \u2212vn xk2\n2\n2\nlim e\u2212 \u03c32 dP\n= \u03b2 lim e \u03c3\nn\nn\np Z\n\u03b12 kyk2\nky\u2212H\u0304xk2\n2\nBy DCT = \u03b2e \u03c32\ne\u2212 \u03c32 dP\n= fT,P,Qv (y).\nThis proves the continuity of fT,P,Qv (y) over Y \u00d7 V .\nWe define that two probability measures P1 , P2 \u2208 Pg,\u0393(X) are equivalent over WF (H\u0304, \u03a3),\nif they induce the same conditional output probability measure (conditional on v). Equivalently, two input measures are equivalent over WF (H\u0304, \u03a3) if fT,P1 ,Qv (y) = fT,P2 ,Qv (y) for all\n(y, v) \u2208 Y \u00d7 V such that v is in the support of R. Note that for full-rank \u03a3, all v \u2208 V are\nin the support of R.\nProposition 4.1 (Strict concavity). The mutual information of channel WF (H\u0304, \u03a3) is\nstrictly concave with respect to the convex combination of two input measures P1 and P2 ,\nunless they are equivalent on WF (H\u0304, \u03a3).\nProof. By Observation 4.1, if there exists (y, v) \u2208 Y \u00d7V such that fT,P1 ,Qv (y) 6= fT,P2 ,Qv (y) 6=\n0 then there exists a neighborhood U(y,v) \u2282 Y \u00d7 V of (y, v) with that property. By definition\nof T (3) and R (11), (T \u00d7 R)(U(y,v) ) > 0. This implies that the set U(y,v) complies the\nrequirements of Proposition 3.3 of Part I. Thus, the mutual information function of an FCSI\nchannel is strictly concave with respect to the convex combination of P1 and P2 if and only\nif there exists (y, v) \u2208 Y \u00d7 V such that fT,P1 ,Qv (y) 6= fT,P2 ,Qv (y).\n17\n\n\fAnother important property of the mutual information in capacity analysis is its weak*\ncontinuity, which is stated as follows.\nProposition 4.2 (Continuity). The mutual information of any fading channel WF (H\u0304, \u03a3)\nis weak* continuous over Pg,\u0393(X).\nProof. It suffices to check if the hypothesis of Theorem 3.3 of Part I is satisfied. We prove\nthe theorem for g(x) = kxk22 , and the proof for other choices of g is also similar. To prove\nhypothesis (a) of Theorem 3.3 of Part I, we proceed as the proof of Proposition 3.2.\nLet assume that \u03b1 < 1 and p < 2 are fixed. Let define\nAc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |fT,Qv (y|x) |log2 fT,Qv (y|x)| > c2 }.\nLet also define\nBc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |fT,Qv (y|x) > c}.\nFor sufficiently large c > 0, e.g. c > 10, it can be observed that Ac \u2282 Bc . But fT,Qv (y|x) > c\nis equivalent to \u03b12 kykp2 \u2212 ky \u2212 vxk22 > \u03c3 2 ln \u03b2c . Hence, if we define\nc\nEc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |\u03b12kykp2 > \u03c3 2 ln },\n\u03b2\nwe can deduce that for sufficiently large c > 0, we would have Ac \u2286 Bc \u2286 Ec . Let \u03c9(c) =\n\u00111/p\n\u0010 2\nc\n\u03c3\nln\n. We have,\n\u03b12\n\u03b2\nZZZ\nZZZ\nfT,Qv (y|x) |log2 fT,Qv (y|x)| dT dP dR \u2264\nfT,Qv (y|x) |log2 fT,Qv (y|x)| dT dP dR\nAc\nEc\nZZZ\nky\u2212vxk2\n1\n2\n\u2212\n\u03c32\nd\u03bcY dP dR\ne\n\u2264 |log2 \u03b2|\nm\n2m\nEc \u03c0 \u03c3\nZZZ\n2\nlog2 e\n\u03b12 kykp2 \u2212 ky\u2212vxk\n2\n\u03c32\n+ 2\ne\nd\u03bcY dP dR\nm\n2m\n\u03c3\nEc \u03c0 \u03c3\n\u0013\n\u0012\nlog2 e\n|log2 \u03b2|\n\u2264\n+ 2 2\u2212p\n\u03c9 2 (c)\n\u03c3 \u03c9 (c)\nZZZ\n2\n2\nkyk2 \u2212 ky\u2212vxk\n2\n2\n\u03c3\ne\nd\u03bcY dP dR\nm\n2m\n\u03c0 \u03c3\n\u0013\n\u0012\nZZ\nlog2 e\n|log2 \u03b2|\n2\n(m\u03c3 +\nkvxk22 dP dR)\n+ 2 2\u2212p\n=\n2\n\u03c9 (c)\n\u03c3 \u03c9 (c)\n\u0013\n\u0012\nZ\nlog2 e\n|log2 \u03b2|\n2\n(m\u03c3 + \u0393 kvk2 dR).\n+ 2 2\u2212p\n\u2264\n\u03c9 2 (c)\n\u03c3 \u03c9 (c)\n\n18\n\n\fR\nSince (m\u03c3 2 + \u0393 kvk2 dR) < \u221e and \u03c9(c) \u2192 \u221e as c \u2192 \u221e, we can deduce that\nZZZ\nfT,Qv (y|x) |log2 fT,Qv (y|x)| dT dP dR = 0.\nlim sup\nc\u2192\u221e P\u2208P\n\ng,\u0393 (X)\n\nAc\n\nThis implies that hypothesis (a) of Theorem 3.3 of Part I holds.\nTo verify if hypothesis (b) holds, for fixed y and v, let Bc = {x \u2208 X|fT,Qv (y|x) > c}.\nThen,\nsup\nP\u2208Pg,\u0393 (X)\n\n1\nfT,Qv (y|x)dP \u2264\nsup\nc P\u2208Pg,\u0393 (X)\nBc\n\nZ\n\n\u03b22\n=\nc\n\nZ\n\nsup\nP\u2208Pg,\u0393 (X)\n\n(fT,Qv (y|x))2 dP\n\nZ\n\n2\n\ne\n\np\n\u03b12 kyk2 \u2212ky\u2212vxk2\n2\n\u03c32\n\ndP\n\n\u03b2 2 2 \u03b12 kyk\n2\n\u2264\ne \u03c32 \u2192 0, as c \u2192 \u221e.\nc\np\n\nThus, both hypotheses of Theorem 3.3 of Part I hold. Hence, the mutual information is\nweak* continuous.\n\n4.2\n\nCapacity analysis\n\nIn this subsection, we address issues on the existence, the uniqueness, and the characterization of the capacity-achieving measure for fading channels with full CSI at the receiver.\nLemma 4.1 (Existence). For any channel WF (H\u0304, \u03a3) and the set of input measures Pg,\u0393(X),\nthere exists a measure Po \u2208 Pg,\u0393 (X) that achieves the capacity of WF (H\u0304, \u03a3).\nProof. By Proposition 4.2, the mutual information is continuous over Pg,\u0393 (X).\n\nSince\n\nPg,\u0393 (X) is weak* compact, the existence is guaranteed by Proposition 4.1 of Part I.\nOne immediate result of our arguments on strict concavity of mutual information, Proposition 4.1, is on the uniqueness of the capacity-achieving measure, as shown below.\nLemma 4.2 (Uniqueness). For any fading channel WF (H\u0304, \u03a3) and the set of input measures\nPg,\u0393 (X), the capacity-achieving measure is unique up to the equivalency of input measures.\n\nProof. The proof is similar to the proof of Lemma 3.2.\n\n19\n\n\fWe remark that using Lemma 4.2 with some simple intuitive arguments, one can justify\nthat the capacity-achieving input measure is symmetric.\nSo far, in this section, we have addressed issues on the existence and the uniqueness of\nthe capacity-achieving measure over fading channels with full CSI at the receiver. It remains\nto provide some insight to the characterization of the capacity-achieving measure.\nProposition 4.3. Let g(*) = k * k\u03b7\u03b7 for 1 \u2264 \u03b7. If \u03b7 > 2, the capacity-achieving measure has a\nbounded support with no interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2, then a necessary condition\n\u03b7\n\n2\n\nfor Po is that for almost every v \u2208 V , supr\u22650 e\u2212r Po (ky \u2212 vxk2 \u2264 r\u03c3) = O(e\u2212\u03b1(v)kyk\u03b7 ) for\nsufficiently large y in the column space of v and for some positive function \u03b1 : V \u2192 R+ .\nProof. Let Po WQv denote the optimal conditional capacity-achieving output measure. Applying Kuhn-Tucker condition, Theorem 4.3 of Part I, to our problem, we need to find a\npositive value \u03b3 > 0 such that\nZ\nD(WQv (*|x)kPoWQv )dR \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\nUsing some straightforward mathematical manipulation, this results to\n\n2\n\n\u2212m log2 (\u03c0\u03c3 e) \u2212\n\nZZ\n\nky\u2212vxk2\n1\n2\n\u2212\n\u03c32\nlog2 fPo ,Qv (y)d\u03bcY dR \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\ne\n2\nm\n(\u03c0\u03c3 )\n\n(15)\n\nThe problem is now finding an output density function together with the value \u03b3 > 0\nsuch that the above inequality is satisfied with equality on all x \u2208 X in the support of the\ncapacity-achieving measure.\nIt can be inspected that for large values of x the term \u03b3kxk\u03b7\u03b7 is a dominant term. Hence,\nthe integral term must have a growth rate equal or smaller than \u03b3kxk\u03b7\u03b7 . As a result, it suffices\nto study the asymptotic behavior (tail) of the density function fPo ,Qv (y) =\n\nd(Po WQv )\n.\nd\u03bcY\n\nSuppose y \u2208 Y and v \u2208 V are fixed and y is in the column space of v. Let kv (y) =\n2\n\nsupr e\u2212r Po (ky \u2212 vxk2 \u2264 r\u03c3). Similar to the proof of Proposition (3.3), we can deduce that\nfor y in the column space of v,\n\u2212 log2 fPo ,Qv (y) = O(min (\u2212 log2 kv (y), kyk22)).\nNow, let consider this together with (15). It can be verified that for \u03b7 > 2, there exists\nno choice for the input measure to catch up with the growth rate of kxk\u03b7\u03b7 for large values\n20\n\n\fof x. This implies that the support of the input measure is bounded for \u03b7 > 2. One can\nverify that the hypothesis of Proposition 4.3 of Part I holds for fading channels with full\nCSI. More specifically, the function \u03c1(z) is analytic on Z except possibly at z = 0. As a\nresult, we deduce that Sx (Po ) can not have any interior point. On the other hand, for \u03b7 \u2264 2,\n\u03b7\n\na necessary condition for the input measure is k(y) = O(e\u2212\u03b1(v)kyk\u03b7 ) for sufficiently large y in\nthe column space of v where \u03b1 : V \u2192 R+ .\nThe capacity-achieving measures for the general choice of g(*) = k * k\u03b7\u03b7 are not known.\nHowever, for the case that \u03b7 = 2, this problem was first addressed in [8] and solved for i.i.d\nRayleigh distribution. Telatar [8] showed that the capacity-achieving input distribution is\nan isotropic Gaussian distribution. Foschini [7] has shown similar results also.\nHere, we want to address the capacity of the channel in the presence of arbitrary correlation and line-of-sight components. For this purpose, we use Kuhn-Tucker condition,\nTheorem 4.3 of Part I.\nTheorem 4.1. Let g(*) = k * k22 . The probability measure in Pg,\u0393 (X) that achieves the capacity of the channel WF (H\u0304, \u03a3) is absolutely continuous with respect to the Lebsegue measure\nwith a unique (a.e.) Gaussian density function of zero mean and covariance matrix S that\nsatisfies\nZ\n\nx\u2032 v \u2032 (vSv \u2032 + \u03c3 2 Im )\u22121 vxdR \u2264 \u03bckxk22 , \u2200x \u2208 X\n\nwhere the equality occurs if and only if x is in the support of capacity-achieving measure and\n\u03bc > 0 is selected to satisfy tr (S) = \u0393. Moreover, the capacity of this channel is\nZ\nC = log det (Im + 1/\u03c3 2 vSv \u2032)dR.\n\nProof. Suppose Po WQv is the optimal capacity-achieving output measure. Applying KuhnTucker condition, Theorem 4.3 of Part I, to our problem, we need to find a positive value\n\u03b3 > 0 such that\nZ\n\nD(WQv (*|x)kPo WQv )dR \u2212 \u03b3kxk22 \u2264 C \u2212 \u03b3\u0393.\n\n21\n\n\fUsing some straightforward mathematical manipulation, this results to\nZZ\nky\u2212vxk2\nd(Po WQv ) 1\n2\n\u2212\n2\n\u03c32\n\u2212m log2 (\u03c0\u03c3 e) \u2212\nlog2\ne\nd\u03bcY dR \u2212 \u03b3kxk22 \u2264 C \u2212 \u03b3\u0393.\n2\nm\nd\u03bcY\n(\u03c0\u03c3 )\nThe problem is now finding an output density function together with the value \u03b3 > 0\nsuch that the above inequality is satisfied with equality on all x \u2208 X in the support of the\ncapacity-achieving measure.\nSuppose x \u2208 X be in the support of the optimizing input measure. Then, we need to have\nthe integration in the above inequality result into a quadratic form. To obtain a quadratic\nform out of integral, an straightforward option is to assume log2\n\nd(Po WQv )\nd\u03bcY\n\n= a(v) \u2212 kb(v)yk22,\n\nwhere a(v) is a function and b(v) is a mapping from V to the Mm (R). As the result, we will\nobtain\n2\n\n\u2212m log2 (\u03c0\u03c3 e) +\n\nZ\n\n[\u2212a(v) + \u03c3 2 tr (b(v)\u2032 b(v)) + x\u2032 v \u2032 b(v)\u2032 b(v)vx]dR \u2212 \u03b3kxk22 \u2212 C + \u03b3\u0393 = 0\n\nBut to solve such equation, we can separate the constant part and the variable part to obtain\n\uf8f1R\n\uf8f2 x\u2032 v \u2032 b(v)\u2032 b(v)vxdR \u2212 \u03b3kxk2 = 0\n2\n(16)\n\uf8f3 \u2212m log (\u03c0\u03c3 2 e) + R [\u2212a(v) + \u03c3 2 tr (b(v)\u2032 b(v))]dR \u2212 C + \u03b3\u0393 = 0\n2\n\nTo satisfy the first equation of (16), we proceed as follows. For any x in the support of Po ,\nit suffices to have x as an eigenvector of E (v \u2032 b(v)\u2032 b(v)v) with its corresponding eigenvalue\n\nequal to \u03b3. For any x not in the support of Po , we must have x\u2032 E (v \u2032 b(v)\u2032 b(v)v) x\u2212\u03b3kxk22 < 0.\nThis implies that we should select b(v) such that the maximal eigenvalues of E (v \u2032 b(v)\u2032 b(v)v)\n(that correspond to the support of Po be \u03b3) and the rest of its eigenvalues be less than \u03b3.\nOne immediate approach to select b(v) is to assume that the input measure is a centralized\nmultivariate normal with covariance S. As a result, this implies that b(v)\u2032 b(v) = log2 e (vSv \u2032 +\n\u03c3 2 Im )\u22121 . Therefore, it remains just to pick a semi-positive definite matrix S such that\nlog2 e E (v \u2032 (vSv \u2032 + \u03c3 2 Im )\u22121 v) have our desired structure. That is we need to find S such that\n\u0001\nlog2 e E v \u2032 (vSv \u2032 + \u03c3 2 Im )\u22121 v \u2212 \u03b3I \u2264 0\nin consideration of other constraints raising from (16). It can be inspected that such choice\n\nfor S exists and depends on the value of \u03b3. By Kuhn-Tucker condition we need to have\nR\n\u03b3( kxk22 dPo \u2212 \u0393) = 0. Since \u03b3 can not be zero, we need to find \u03b3 such that tr (S) = \u0393. For\nconvenience in presentation, let define \u03bc =\n\ng\n.\nlog2 e\n\n22\n\nNow, multiplying the above equation from\n\n\fleft by x\u2032 and right by x, and taking the expectation with respect to x, one can verify that\nwe obtain the equality\nZ\nSince we have\n\n\u0001\n\u03c3 2 tr (vSv \u2032 + \u03c3 2 Im )\u22121 dR \u2212 mlog2 e + \u03bc\u0393 = 0\na(v) = \u2212m log2 \u03c0 \u2212\n\n(17)\n\n1\nlog det (vSv \u2032 + \u03c3 2 Im ).\n2\n\nSubstituting in (16), we obtain\nZ\nZ\n2\n\u2032\nlog2 det (Im + 1/\u03c3 vSv )dR \u2212 C + \u03c3 2 tr (b(v)\u2032 b(v)) dR \u2212 m log2 e + \u03bc\u0393 = 0\nIn consideration of (17), we would obtain\nZ\nC = log2 det (Im + 1/\u03c3 2 vSv \u2032 )dR.\nThe uniqueness property follows by from Lemma 4.2 and the fact that there exists no other\ninput measure than can induce the same conditional output measure with Gaussian density\nfunction.\nNote that Theorem 4.1 characterizes the capacity-achieving measure for any Rician\nMIMO channel with full CSI at the receiver. In general, a closed form solution for S is\nnot obtainable from Theorem 4.1, and S should be found through exhaustive computer\nsearch. However, for special cases of channels, one may use some novel approaches to solve\nthe conditions in Theorem 4.1. As an example, consider the following corollary.\nCorollary 4.1. If WF (H\u0304, \u03a3) is an i.i.d. Rayleigh channel, i.e., H\u0304 = 0 and \u03a3 = I, then the\ncapacity-achieving measure has an isotropic Gaussian density function with zero mean and\ncovariance matrix S = \u0393n I.\nProof. Suppose S is the covariance matrix that satisfies the condition in Theorem 4.1. Let U\nbe an n\u00d7n unitary matrix. Since R is invariant under the operation of U, it can be inspected\nthat USU \u2032 is also a right candidate. By uniqueness of the capacity-achieving measure, we\ndeduce that S = USU \u2032 for every unitary matrix U. This implies that S = \u03bbI for some \u03bb > 0.\nSince tr (S) = \u0393, we deduce that S = \u0393n I.\nRecall that this is the same result as given in [8] for Rayleigh channels. One can verify\nthat if \u03a3 is not singular, then for large signal-to-noise ratio (SNR), i.e.\n23\n\n\u0393\n,\n\u03c32\n\nthe covariance\n\n\fmatrix S would be very close to \u0393n I. Hence, for large SNR, an input measure with isotropic\nGaussian distribution is near optimal. Relevant work can be found in [9], [25], and [26].\n\n5\n\nNo Channel State Information at the Receiver\n\nIn some applications, the system setup does not allow any estimation of the channel realization at the receiver. This is specifically true in fast fading channels, where there is not\nsufficient delay available between changes in the channel realization.\nIn this section, we consider Rayleigh or Rician fading channels where no CSI is available\nat the receiver. Regarding the general linear statistical model as (1), this means that the\nchannel realization, Hk , changes through time in accordance of a Gaussian probability density\nfunction, but the realization is not known at the receiver. As in the previous section, we\ncharacterize these channels with the mean value H\u0304 and the covariance matrix \u03a3 of the fading.\nTo emphasize that CSI is not known, we use a subscript \"N\", and denote the channel as\nWN (H\u0304, \u03a3).\nSince we assumed that no CSI is available at the receiver, the space of side information,\nV , is statistically independent from H. In the framework of the generic system model\n(Section 3), this is equivalent to assume that an arbitrary Borel measurable space V with\nan arbitrary measure R on it such for every given v, the conditional probability measure on\nH, Qv , has a Gaussian density function characterized by H\u0304 and \u03a3. Since the measure Qv is\nnot dependent on v, we drop indexing by v and simply use Q, instead.\nSince the channel realization is not known at the receiver, the size of block length L is\nimportant in capacity analysis of these channels. Hence, we assume X = Cn\u00d7L for a general\nL \u2265 1. By definition of the auxiliary measure T (3), one can inspect that WQ (*|x) \u226a T for\nevery x with the density function (obtained from (4))\n\u0013\n\u0012 2\n\u03b2\n\u03b1 kykp2 \u2212 vec (y \u2212 H\u0304x)\u2032 \u03a6\u22121\nx vec (y \u2212 H\u0304x)\nfT,Q (y|x) =\nexp\ndet \u03a6x\n\u03c32\nwhere \u03a6x ,\n\n1\n(x\u2032\n\u03c32\n\n\u2297 Im )\u03a3(x \u2297 Im ) + ImL . For every P \u2208 Pg,\u0393 (X), let\nZ\nfT,P,Q (y) = fT,Q (y|x)dP\n\n24\n\n(18)\n\n(19)\n\n\fdenote the output density function. The mutual information of this channel is expressed as\nZZ\nZ\nI(P, WN (H\u0304, \u03a3)) =\nfT,Q (y|x) log2 fT,Q (y|x)dT dP \u2212 fT,P,Q(y) log2 fT,P,Q (y)dT . (20)\nOne should note that the maximum of (20) should be divided by L to determine the capacity\nper channel use.\n\n5.1\n\nProperties of mutual information\n\nIn this subsection, we address properties such as strict concavity and continuity of the mutual\ninformation for fading channels with no CSI at the receiver.\nPropositions 3.3 of Part I addressed the strict concavity of the mutual information in\ngeneral. Since the strictness property is essential to addressing the uniqueness of the capacityachieving probability measure, we address a simpler condition for the case of fading channels\nwith no CSI at the receiver.\nObservation 5.1. For every P \u2208 Pg,\u0393(X), fT,P,Q (y) is continuous and nonzero over Y .\nProof. By (18), the continuity and positiveness of fT,Q (y|x) is obvious. The positiveness of\nfT,Q (y|x) implies the positiveness of fT,P,Q(y). To prove the continuity, suppose that yn \u2192 y\nin the Euclidean norm. Then,\nZ\nlim fT,P,Q (yn ) = lim fQ (y|x)dP\nn\n\nn\n\n\u0012\n\u0013\nZ\np\n\u03b12 kyn k\n\u2212vec (yn \u2212 H\u0304x)\u2032 \u03a6\u22121\nvec (yn \u2212 H\u0304x)\n\u03b2\n2\nx\n2\n= lim\ne \u03c3\nlim exp\ndP\nn det \u03a6x\nn\n\u03c32\n\u0013\n\u0012\np Z\n\u2032 \u22121\n\u03b12 kyk\n\u03b2\n\u2212vec\n(y\n\u2212\nH\u0304x)\n\u03a6\nvec\n(y\n\u2212\nH\u0304x)\n2\nx\nBy DCT =\ndP\ne \u03c32\nexp\ndet \u03a6x\n\u03c32\n= fT,P,Q (y).\nThis proves the continuity of fT,P,Q (y) over Y .\nWe define that two probability measures P1 , P2 \u2208 Pg,\u0393 (X) are equivalent over WN (H\u0304, \u03a3)\nif they induce the same output probability measure. Equivalently, two input measures are\nequivalent over WN (H\u0304, \u03a3) if fT,P1 ,Q (y) = fT,P2 ,Q (y) for all y \u2208 Y .\nProposition 5.1 (Strict concavity). The mutual information of channel WN (H\u0304, \u03a3) is\nstrictly concave with respect to the convex combination of two input measures P1 and P2 ,\nunless they are equivalent.\n25\n\n\fProof. By Observation 5.1, if there exists y \u2208 Y such that fT,P1 ,Q (y) 6= fT,P2 ,Q (y) then\nthere exists a neighborhood Uy \u2282 Y of y with that property. Then by definition of T\n(3), T (Uy ) > 0. This implies that the set Uy complies the requirements of Proposition\n3.3 of Part I. Thus, the mutual information of an NCSI channel is strictly concave with\nrespect to the convex combination of P1 and P2 if and only if there exists y \u2208 Y such that\nfT,P1 ,Q (y) 6= fT,P2 ,Q (y). By definition of equivalency of measures over WN (H\u0304, \u03a3), we deduce\nthe assertion.\nIn the following, we state and prove another important property of mutual information,\nweak* continuity, which will be used later in the capacity analysis of fading channels with\nno CSI.\nProposition 5.2 (Continuity). The mutual information of any fading channel WN (H\u0304, \u03a3)\nis weak* continuous over Pg,\u0393(X).\nProof. It suffices to check if the hypothesis of Theorem 3.3 of Part I is satisfied. We prove\nthe theorem for g(x) = kxk22 , and the proof for other choices of g is also similar. To prove\nhypothesis (a) of Theorem 3.3 of Part I, we proceed as the proof of Proposition 3.2. For\nevery P \u2208 Pg,\u0393 (X), let\nAc = {(x, y) \u2208 X \u00d7 Y |fT,Q (y|x) |log2 fT,Q (y|x)| > c2 }.\nLet\nBc = {(x, y) \u2208 X \u00d7 Y |fT,Q (y|x) > c},\nfor sufficiently large c > 0, it can be observed that Ac \u2282 Bc . Let\n2\nDc = {(x, y) \u2208 X \u00d7 Y |\u03b12kykp2 \u2212 vec (y \u2212 H\u0304x)\u2032 \u03a6\u22121\nx vec (y \u2212 H\u0304x) > \u03c3 ln\n\nc det \u03a6x\n}.\n\u03b2\n\nIt can be inspected that Bc \u2282 Dc . We also note that or sufficiently large c > 0, \u03b12 kykp2 \u2265\nvec (y \u2212 H\u0304x)\u2032 \u03a6\u22121\nx vec (y \u2212 H\u0304x). Let also define\nEc = {(x, y) \u2208 X \u00d7 Y |kykp2 >\n\n\u03c3 2 c det \u03a6x\nln\n}.\n\u03b12\n\u03b2\n\nThus, for sufficiently large c > 0, Dc \u2286 Ec . Noting that det \u03a6x \u2265 1, let define \u03c9(c) =\n\n26\n\n\f\u0010\n\n\u03c32\n\u03b12\n\nZZ\n\nln\n\nAc\n\nc\n\u03b2\n\n\u00111/p\n\n. In a similar discussion as in of Proposition 3.2, we can deduce that\n\nfT,Q (y|x) |log2 fT,Q (y|x)| dT dP\nZZ\nfT,Q (y|x) |log2 fT,Q (y|x)| dT dP\n\u2264\nEc\nZZ\n1\n\u2032 \u22121\n1\n\u2264 |log2 \u03b2|\ne\u2212 \u03c32 vec (y\u2212H\u0304x) \u03a6x vec (y\u2212H\u0304x) d\u03bcY dP\nmL\n2mL\n\u03c3\ndet \u03a6x\nE \u03c0\nZZ c\n2\n2\u03b1 kykp2\nlog2 e\n\u2212 12 vec (y\u2212H\u0304x)\u2032 \u03a6\u22121\nx vec (y\u2212H\u0304x)\n\u03c3\ne\nd\u03bcY dP\n+ 2\nmL\n2mL\n\u03c3\n\u03c3\ndet \u03a6x\nEc \u03c0\n\u0014\n\u0015\n|log2 \u03b2| 2\u03b12 log2 e\n\u2264\n+ 2 2\u2212p\n\u03c9 2 (c)\n\u03c3 \u03c9 (c)\nZZ\n1\n\u2032 \u22121\nkyk22\ne\u2212 \u03c32 vec (y\u2212H\u0304x) \u03a6x vec (y\u2212H\u0304x) d\u03bcY dP\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x\n\nIf we take the supP\u2208Pg,\u0393 (X) of both sides, the second term of the RHS is a finite value. Now,\napplying limc\u2192\u221e to both sides, we observe that \u03c9(c) \u2192 \u221e as c \u2192 \u221e. Hence,\nZZ\nfT,Q (y|x) |log2 fT,Q (y|x)| dT dP = 0.\nlim sup\nc\u2192\u221e P\u2208P\n\ng,\u0393 (X)\n\nAc\n\nThis implies that the hypothesis (a) of Theorem 3.3 of Part I holds. To verify if the hypothesis\n(b) holds, the proof is by Chebychev's inequality which is essentially similar to the proof\nof Proposition 4.2. Thus, both hypotheses of Theorem 3.3 of Part I hold, so the mutual\ninformation is weak* continuous.\n\n5.2\n\nCapacity analysis\n\nIn this subsection, we address issues on the existence, the uniqueness, and the characterization of the capacity-achieving measures for fading channels with no CSI at the receiver.\nLemma 5.1 (Existence). For any channel WN (H\u0304, \u03a3), there exists a measure Po \u2208 Pg,\u0393(X)\nthat achieves the capacity of WN (H\u0304, \u03a3) over Pg,\u0393(X).\nProof. Proposition 5.2 states the weak* continuity of the mutual information over Pg,\u0393(X).\nSince Pg,\u0393(X) is weak* compact, by Proposition 4.1 of Part I, we conclude the assertion.\nLemma 5.1 states the existence of the capacity-achieving measure over fading channels\nwith no CSI. One immediate result of our arguments on strict concavity of mutual infor-\n\n27\n\n\fmation, Proposition 5.1, is on the uniqueness of the capacity-achieving measure, as shown\nbelow.\nLemma 5.2 (Uniqueness). For any channel WN (H\u0304, \u03a3), the capacity-achieving measure\nover Pg,\u0393 (X) is unique up to the equivalency of input measures.\nProof. The proof is essentially the same as the proof of Lemma 3.2.\nSo far, in this section, we have shown the existence and uniqueness of the capacityachieving measure over fading channels with no CSI at the receiver. It remains to provide\nsome insight to the characterization of such input measure.\nProposition 5.3. Suppose g(*) = k * k\u03b7\u03b7 for 1 \u2264 \u03b7. If \u03b7 > 2, the capacity-achieving measure\nhas a bounded support with no interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2, a necessary condition\nfor the capacity-achieving measure is\n\u03b7\n\nPo (kyk2 \u2264 kxk2 , R(y) \u2286 R(x)) = O(e\u2212\u03b1kyk\u03b7 ),\nwhere R(*) denote the row space of a matrix, and \u03b1 > 0 is a constant.\nProof. Suppose Po WQ is the optimal capacity-achieving output measure. Applying KuhnTucker condition, Theorem 4.3 of Part I, to our problem, we need to find a positive value\n\u03b3 > 0 such that\nD(WQ (*|x)kPoWQ ) \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\nWe note that WQ (*|x) \u226a \u03bcY with density function\nfQ (y|x) =\n\n1\n\n1\n\n\u03c0 mL \u03c3 2mL det \u03a6x\n\n\u2032\n\n\u22121\n\ne\u2212 \u03c32 vec (y\u2212H\u0304x) \u03a6x\n\nvec (y\u2212H\u0304x)\n\n,\n\nwhere \u03a6x is defined as in (18). Using some straightforward mathematical manipulation, we\nobtain\n2\n\n\u2212mL log2 (\u03c0e\u03c3 ) \u2212\n\nZ\n\nlog2\n\nd(Po WQ )\nfQ (y|x)d\u03bcY \u2212 log2 (det \u03a6x ) \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393. (21)\nd\u03bcY\n\nNow, the problem is to find an output density function together with the value \u03b3 > 0 such\nthat the above inequality is satisfied with equality on all x \u2208 X in the support of the capacityachieving measure. Unfortunately, because of the inherent difficulties in this expression, it is\nnot possible to find an analytic solution for the output density function. However, through\n28\n\n\fsome asymptotic analysis discussion we can obtain some intuition on characterization of the\nsupport of the capacity-achieving measure, as follows.\nCase \u03b7 > 2: It can be inspected that for large values of x, the term \u03b3kxk\u03b7\u03b7 is a dominant\nterm. Hence, the integral term must have a growth rate of kxk\u03b7\u03b7 ; otherwise, the support of\nthe capacity-achieving measure is bounded. Thus, it suffices to study the asymptotic (tail)\nd(P W )\n\nbehavior of the density function fPo ,Q (y) = d\u03bco Y Q . For every fixed y \u2208 Y , we have\nZ\n1\n\u2212 12 vec (y\u2212H\u0304x)\u2032 \u03a6\u22121\nx vec (y\u2212H\u0304x)\n\u03c3\ne\ndPo\nfPo ,Q (y) =\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x\nZ\n2\n2\n\u2032 \u22121\n\u2032 \u22121\n1\n\u2265\ne\u2212 \u03c32 vec y \u03a6x vec y e\u2212 \u03c32 vec (H\u0304x) \u03a6x vec (H\u0304x) dPo\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x\nZ\n2\n2\n2\n\u2032 \u22121\n1\n\u2265 e\u2212 \u03c32 kyk2\ne\u2212 \u03c32 vec (H\u0304x) \u03a6x vec (H\u0304x) dPo\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x\nThis means that \u2212 log2 fPo ,QH\u0304 (y) = O(kyk22). As a result, it can be verified that for \u03b7 > 2,\nthere exists no choice for the input measure so that the integral part of (21) catch up with\nthe growth rate of kxk\u03b7\u03b7 for large values of x. Thus, the support of the capacity-achieving\ninput measure is bounded for \u03b7 > 2. Trying to use Proposition 4.3 of Part I, one can verify\nthat \u03c1(z) is analytic over Z except the zero set of some polynomials, say A \u2208 Z. Since the\nzero set of polynomials are closed sets including boundary points [27], the set U = Z\\A is a\nconnected set. Because of the existence of log2 (det \u03a6x ) in (21), we know that the zero set of\n\u03c1(z) is not the solution of a polynomial. Thus, \u03be(Sx (Po )) \u2229 U is not empty. Now, applying\nProposition 4.3 of Part I, we deduce that Sx (Po ) can not have any interior point.\nCase \u03b7 \u2264 2: Recalling that \u03a6x =\n\n1\n(x\u2032\n\u03c32\n\n\u2297 Im )\u03a3(x \u2297 Im ) + ImL , one can verify that for\n\nevery x \u2208 X,\n(\n\n\u03bbmin \u2032\n\u03bbmax\nx\nx\n+\nI\n)\n\u2297\nI\n\u2264\n\u03a6\n\u2264\n(\nkxk22 + 1)ImL ,\nL\nm\nx\n\u03c32\n\u03c32\n\nwhere \u03bbmax and \u03bbmin > 0 are the maximum and minimum eigenvalues of \u03a3. Let the operator\nR(*) denote the row space of a matrix. Then,\nZ\n2\n2\n\u2032 \u22121\n\u2032 \u22121\n1\nfPo ,Q (y) \u2265\ne\u2212 \u03c32 vec y \u03a6x vec y e\u2212 \u03c32 vec (H\u0304x) \u03a6x vec (H\u0304x) dPo\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x\nZ\n\u2032\n2\n\u22121 \u2032 \u2032\n\u2032\n2\n\u22121 \u2032\n1\ne\u2212tr(y(\u03bbmin x x+\u03c3 IL ) y ) e\u2212tr(H\u0304x(\u03bbmin x x+\u03c3 IL) x H\u0304 ) dPo\n\u2265\n2\nmL\n2\nmL\n\u03c0 (\u03bbmax kxk2 + \u03c3 )\nZ\nk\ndPo,\n\u2265\n2\n2 mL\nkyk2 \u2264kxk2 ,R(y)\u2286R(x) (\u03bbmax kxk2 + \u03c3 )\n\n29\n\n\fwhere k = k(H\u0304, \u03a3) is a nonzero constant dependent on H\u0304 and \u03a3. Assuming that\nPo (kyk2 \u2264 kxk2 , R(y) \u2286 R(x)) = \u0398(e\u2212l(y) ),\nfor some positive function l : Y \u2192 R+ , where l(y) = \u03c9(ln kyk2), for sufficiently large kyk22,\nwe would obtain.\nfPo ,Q (y) \u2265 \u0398(e\u22122l(y) ).\nBut this means that\n\u2212 log2 fPo ,Q (y) = O(min (kyk22, l(y))).\nNow, consider this together with (21), we can observe that for large values of kxk\u03b7\u03b7 , the\nintegral part of (21) is behaving as O(min (kxk22 , l(x))). Thus, a necessary condition for the\ncapacity achieving-measure is l(x) = \u03a9(kxk\u03b7\u03b7 ).\nWe remark that(21) in Proposition 5.3 provides necessary and sufficient condition for\nthe capacity-achieving measure for Rician and Rayleigh channels (with full-rank covariance\nmatrix) subject to any moment constraint of order \u03b7 > 1. However, it is still not possible\nto solve (21) to find the capacity-achieving measure for the general choice of \u03b7, and this\nproblem remains open for future investigations. For the case that \u03b7 = 2, this problem has\nbeen addressed to some extent for Rayleigh channels in [15], [16], and [20]. For the case\nof SISO Rayleigh channels, it has been shown [16] that the capacity-achieving distribution\nhas a finite number of mass points. Also, for the MIMO channel with isotropic Rayleigh\ndistribution, the authors [15] have conjectured that the support of the capacity-achieving\nmeasure is in the form of concentric spheres around the origin with no interior point. More\nresults can be found in [28].\n\n6\n\nPartial Channel State Information at the Receiver\n\nIn some fading channels, the system setup allows estimation of the channel at the receiver\nto some extent. In such cases, we assume that the channel state information is partially\navailable at the receiver. Thus, in consideration of the general system model (1), we assume\nthat the channel realization, H, is partially known at the receiver. We assume that the\n\n30\n\n\fchannel realization is governed by a Gaussian distribution characterized by H\u0304 and \u03a3 (fullrank), as before. The channel state information is assumed to be available at the receiver\nin the form of elements from an LCH Borel-measurable space V , where each value v \u2208 V is\nan estimation for the channel realization H. We assume that H \u00d7 V is associated with a\nmeasure Q \u25e6 R which has a joint Gaussian density function. That is for every v \u2208 V , the\nmeasure Qv has a Gaussian density function characterized by\n\u03bcH|v = H\u0304 + \u03a3Hv \u03a3\u22121\nvv (v \u2212 \u03bcv )\n\u03a3H|v = \u03a3 \u2212 \u03a3Hv \u03a3\u22121\nvv \u03a3vH ,\nwhere \u03a3Hv (and \u03a3vH ) denotes cross-covariance of H and v, and \u03bcv and \u03a3vv are mean and\ncovariance of the a Gaussian density function of the probability measure R on V . To emphasize that the channel state information is partially known, we use a subscript \"P\", we\ndenote the channel as WP (\u03bcH|v , \u03a3H|v ). To avoid extra difficulties, we assume that \u03a3H|v is\nfull-rank for all v \u2208 V .\nSince the CSI is not fully known at the receiver, the size of block-length, L, is important\nin capacity analysis. Hence, we assume X = Cn\u00d7L . Note that WQv (*|x) \u226a T with a density\nfunction (obtained from (4))\n\u03b2\nfT,Qv (y|x) =\nexp\ndet \u03a6x,v\nwhere \u03a6x,v =\n\n1\n(x\u2032\n\u03c32\n\n\u0012\n\n\u03b12 kykp2 \u2212 (y \u2212 \u03bcH|v x)\u2032 \u03a6\u22121\nx,v (y \u2212 \u03bcH|v x)\n\u03c32\n\n\u0013\n\n(22)\n\n\u2297 Im )\u03a3H|v (x \u2297 Im ) + ImL . For every input measure P \u2208 Pg,\u0393 (X), we\n\nhave P WQv \u226a T with a density function\nfT,P,Qv (y) =\n\nZ\n\nfT,Qv (y|x)dP.\n\nAs a result, the mutual information of this channel is expressed as\nZZZ\nI(P, WP (\u03bcH|v , \u03a3H|v )|R) =\nfT,Qv (y|x) log2 fT,Qv (y|x)dT dPdR\nZZ\n\u2212\nfT,P,Qv (y) log2 fT,P,Qv (y)dT dR.\n\n(23)\n\n(24)\n\nNote that the capacity per channel use is obtained by dividing the maximum of (24) by L.\n\n31\n\n\f6.1\n\nProperties of mutual information\n\nIn Proposition 3.3 of Part I, we addressed the strict concavity of the mutual information\nin general. Since the strictness property is essential to addressing the uniqueness of the\ncapacity-achieving probability measure, here, we address a simpler condition to verify this\nproperty of the mutual information function for fading channels with partial CSI at the\nreceiver.\nObservation 6.1. For every P \u2208 Pg,\u0393 (X), fT,P,Qv (y) is continuous and nonzero for all\n(y, v) \u2208 Y \u00d7 V .\nProof. By (22), the continuity and positiveness of fT,Qv (y|x) is obvious. The positiveness\nof fT,Qv (y|x) implies the positiveness of fT,P,QH\u0304 (y). To prove the continuity, suppose that\n(yn , vn ) \u2192 (y, v) in the Euclidean norm. Then,\nZ\nlim fT,P,Qvn (yn ) = lim fT,Qvn (yn )dP\nn\nn\nZ\np\n(yn \u2212\u03bcH|v x)\u2032 \u03a6x,v \u22121\n\u03b12 kyn k2\nn (yn \u2212\u03bcH|vn x)\nn\n\u03b2\n\u03c32\ndP\n= lim e \u03c32 lim\ne\u2212\nn\nn\ndet \u03a6x,v n\np Z\n(y\u2212\u03bcH|v x)\u2032 \u03a6x,v \u22121 (y\u2212\u03bcH|v x)\n\u03b12 kyk\n\u03b2\n2\n\u2212\n2\n\u03c32\nBy DCT = e \u03c3\ndP\ne\ndet \u03a6x,v\n= fT,P,Qv (y).\nThis proves the continuity of fT,P,Qv (y) over Y \u00d7 V .\nWe say two probability measures P1 , P2 \u2208 Pg,\u0393(X) are equivalent over WP (\u03bcH|v , \u03a3H|v )\nif they induce the same conditional output probability measure (conditional on v). Equivalently, two input measures are equivalent over WP (\u03bcH|v , \u03a3H|v ) if fT,P1 ,Qv (y) = fT,P2 ,Qv (y) for\nall (y, v) \u2208 Y \u00d7 V such that v is in the support of R.\nProposition 6.1 (Strict concavity). The mutual information of channel WP (\u03bcH|v , \u03a3H|v )\nis strictly concave with respect to the convex combination of two input measures P1 and P2 ,\nunless they are equivalent over WP (\u03bcH|v , \u03a3H|v ).\nProof. By Observation 6.1, if there exists y \u2208 Y such that fT,P1 ,Qv (y) 6= fT,P2 ,Qv (y) then\nthere exists a neighborhood U(y,v) \u2282 Y \u00d7 V of (y, v) with that property. Then by definition\nof T \u00d7 R (3), (T \u00d7 R)(U(y,v) ) > 0. This implies that the set U(y,v) complies the requirements\n32\n\n\fof Proposition 3.3 of Part I. Thus, the mutual information function of an PCSI channel is\nstrictly concave with respect to the convex combination of P1 and P2 if and only if there\nexists (y, v) \u2208 Y \u00d7 V such that fT,P1 ,Qv (y) 6= fT,P2 ,Qv (y).\nAnother important property of mutual information which is useful in capacity analysis\nis its continuity, as shown below.\nProposition 6.2 (Continuity). The mutual information of any channel WP (\u03bcH|v , \u03a3H|v )\nis weak* continuous over Pg,\u0393(X).\nProof. It suffices to check if the hypothesis of Theorem 3.3 of Part I is satisfied. We prove\nthe theorem for g(x) = kxk22 , and the proof for other choices of g is also similar. To prove\nhypothesis (a) of Theorem 3.3 of Part I, we proceed as the proof of Proposition 3.2. For\nevery P \u2208 Pg,\u0393 (X), let\nAc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |fT,Qv (y|x) |log2 fT,Qv (y|x)| > c2 }.\nLet\nBc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |fT,Qv (y|x) > c},\nfor sufficiently large c > 0, it can be observed that Ac \u2282 Bc . Let\n2\nDc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |\u03b12 kykp2 \u2212 vec (y \u2212 \u03bcH|v x)\u2032 \u03a6\u22121\nx,v vec (y \u2212 \u03bcH|v x) > \u03c3 ln\n\nc det \u03a6x,v\n}.\n\u03b2\n\nIt can be inspected that Bc \u2282 Dc . For sufficiently large c > 0, it can be inspected that\n\u03b12 kykp2 \u2265 vec (y \u2212 \u03bcH|v x)\u2032 \u03a6\u22121\nx vec (y \u2212 \u03bcH|v x). Let also define\nEc = {(x, y, v) \u2208 X \u00d7 Y \u00d7 V |kykp2 >\n\n\u03c3 2 c det \u03a6x,v\nln\n}.\n\u03b12\n\u03b2\n\nThus, for sufficiently large c > 0, Dc \u2286 Ec . Noting that det \u03a6x,v \u2265 1, let define \u03c9(c) =\n\n33\n\n\f\u0010\n\n\u03c32\n\u03b12\n\nln\nZZZ\n\nc\n\u03b2\n\nAc\n\n\u00111/p\n\n. In a similar discussion as in Proposition 3.2, we can deduce that\n\nfT,Qv (y|x) |log2 fT,Qv (y|x)| dT dP dR\nZZZ\nfT,Qv (y|x) |log2 fT,Qv (y|x)| dT dP dR\n\u2264\nEc\nZZZ\n1\n\u2032 \u22121\n1\n\u2264 |log2 \u03b2|\ne\u2212 \u03c32 vec (y\u2212\u03bcH|v x) \u03a6x,v vec (y\u2212\u03bcH|v x) d\u03bcY dPdR\nmL\n2mL\n\u03c3\ndet \u03a6x,v\nE \u03c0\nZZZ c\n2\n2\u03b1 kykp2\nlog2 e\n\u2212 12 vec (y\u2212\u03bcH|v x)\u2032 \u03a6\u22121\nx vec (y\u2212\u03bcH|v x)\n\u03c3\ne\nd\u03bcY dPdR\n+ 2\nmL\n2mL\n\u03c3\n\u03c3\ndet \u03a6x,v\nEc \u03c0\n\u0014\n\u0015\n|log2 \u03b2| 2\u03b12 log2 e\n\u2264\n+ 2 2\u2212p\n\u03c9 2 (c)\n\u03c3 \u03c9 (c)\nZZZ\n1\n\u2032 \u22121\nkyk22\ne\u2212 \u03c32 vec (y\u2212\u03bcH|v x) \u03a6x,v vec (y\u2212\u03bcH|v x) d\u03bcY dPdR\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x,v\n\nIf we take supP\u2208Pg,\u0393 (X) of both sides, the second term of the RHS is a finite value. Now,\napplying limc\u2192\u221e to both sides, we observe that \u03c9(c) \u2192 \u221e as c \u2192 \u221e. Hence,\nZZZ\nfT,Qv (y|x) |log2 fT,Qv (y|x)| dT dP dR = 0.\nlim sup\nc\u2192\u221e P\u2208P\n\ng,\u0393 (X)\n\nAc\n\nThis implies that the hypothesis (a) of Theorem 3.3 of Part I holds. Similar to the proof\nof Proposition 4.2, one can verify that the hypothesis (b) holds. Thus, both hypotheses of\nTheorem 3.3 of Part I hold, so the mutual information is weak* continuous.\n\n6.2\n\nCapacity analysis\n\nIn this subsection, we address issues on the existence, the uniqueness, and the characterization of the capacity-achieving measures for fading channels with partial CSI at the receiver.\nLemma 6.1 (Existence). For every channel WP (\u03bcH|v , \u03a3H|v ), there exists a measure Po \u2208\nPg,\u0393 (X) that achieves the capacity of WP (\u03bcH|v , \u03a3H|v ) over Pg,\u0393 (X).\nProof. Proposition 5.2 states the weak* continuity of the mutual information over Pg,\u0393(X).\nSince Pg,\u0393(X) is weak* compact, by Proposition 4.1 of Part I, we conclude the assertion.\nLemma 6.1 states the existence of the capacity-achieving measure over fading channels\nwith partial CSI. One immediate result of strict concavity of mutual information, Proposition\n6.1, is on the uniqueness of the capacity-achieving measure, as shown below.\n\n34\n\n\fLemma 6.2 (Uniqueness). For every channel WP (\u03bcH|v , \u03a3H|v ), the capacity-achieving measure over Pg,\u0393 (X) is unique up to the equivalency of input measures.\nProof. The proof is essentially the same as the proof of Lemma 3.2.\nSo far, in this section, we have shown the existence and the uniqueness of the capacityachieving measure over fading channels with PCSI at the receiver. It remains to provide\nsome insight to the characterization of such input measure.\nProposition 6.3. Suppose g(*) = k * k\u03b7\u03b7 for 1 \u2264 \u03b7. If \u03b7 > 2, the capacity-achieving measure\nhas a bounded support with no interior point. In contrast, if 1 \u2264 \u03b7 \u2264 2, a necessary condition\nfor the capacity-achieving measure is\n\u03b7\n\nPo (kyk2 \u2264 \u03bbmin (v)kxk2 , R(y) \u2286 R(x)) = O(e\u2212\u03b1(v)kyk\u03b7 ),\nwhere R(*) denotes the row space of a matrix, \u03bbmin (v) denotes the minimum eigenvalue of\n\u03a3H|v , and \u03b1 : V \u2192 R+ is a positive function.\nProof. Suppose Po WQv is the optimal capacity-achieving output measure. Applying KuhnTucker condition, Theorem 4.3 of Part I, to our problem, we need to find a positive value\n\u03b3 > 0 such that\nZ\n\nD(WQv (*|x)kPoWQv )dR \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\n\nWe note that WQv (*|x) \u226a \u03bcY with density function\nfQv (y|x) =\n\n1\n\n1\n\n\u03c0 mL \u03c3 2mL det \u03a6x,v\n\n\u2032\n\n\u22121\n\ne\u2212 \u03c32 vec (y\u2212\u03bcH|v x) \u03a6x,v vec (y\u2212\u03bcH|v x) ,\n\nwhere \u03a6x,v is defined as in (22). Using some straightforward mathematical manipulation, we\nobtain\nd(Po WQv )\nfQv (y|x)d\u03bcY dR\n\u2212mL log2 (\u03c0e\u03c3 ) \u2212\nlog2\nd\u03bcY\nZ\n\u2212 log2 (det \u03a6x,v )dR \u2212 \u03b3kxk\u03b7\u03b7 \u2264 C \u2212 \u03b3\u0393.\n2\n\nZZ\n\n(25)\n\nNow, the problem is to find an output density function together with the value \u03b3 > 0 such\nthat the above inequality is satisfied with equality on all x \u2208 X in the support of the capacityachieving measure. Unfortunately, because of the inherent difficulties in this expression, it is\nnot possible to find an analytic solution for the output density function. However, through\n35\n\n\fsome asymptotic analysis discussion we can obtain some intuition on characterization of the\nsupport of the capacity-achieving measure, as follows.\nCase \u03b7 > 2: It can be inspected that for large values of x, the term \u03b3kxk\u03b7\u03b7 is a dominant\nterm. Hence, the first integral term in (25) must have a growth rate of kxk\u03b7\u03b7 ; otherwise,\nthe support of the capacity-achieving measure is bounded. Thus, it suffices to study the\nasymptotic (tail) behavior of the density function fPo ,Qv (y) =\n\nd(Po WQv )\n.\nd\u03bcY\n\nFor every fixed\n\ny \u2208 Y , we have\nfPo ,Qv (y) =\n\nZ\n\n1\n\n1\n\n\u2032\n\n\u22121\n\ne\u2212 \u03c32 vec (y\u2212\u03bcH|v x) \u03a6x,v vec (y\u2212\u03bcH|v x) dPo\n\n\u03c0 mL \u03c3 2mL det \u03a6x,v\n2\n\u2032 \u22121\n1\n\u2212 22 vec y \u2032 \u03a6\u22121\nx,v vec y \u2212 \u03c3 2 vec (\u03bcH|v x) \u03a6x vec (\u03bcH|v x)\n\u03c3\n\u2265\ne\ndPo\ne\n\u03c0 mL \u03c3 2mL det \u03a6x,v\nZ\n2\n2\n1\n\u2212 22 vec (\u03bcH|v x)\u2032 \u03a6\u22121\nx,v vec (\u03bcH|v x)\n\u03c3\ne\n\u2265 e\u2212 \u03c32 kyk2\ndPo\nmL\n2mL\n\u03c0 \u03c3\ndet \u03a6x,v\nZ\n\nThis means that \u2212 log2 fPo ,Qv (y) = O(kyk22). As a result, it can be verified that for \u03b7 > 2,\nthere exists no choice for the input measure so that the growth rate of the first integral of\n(25) catch up with the growth rate of kxk\u03b7\u03b7 for large values of x. Thus, the support of the\ncapacity-achieving input measure is bounded for \u03b7 > 2. Using an argument similar to the\none in the proof of Proposition 5.3, one can deduce that the support of Po has no interior\npoint.\nCase \u03b7 \u2264 2: Recalling that \u03a6x,v =\n\n1\n(x\u2032\n\u03c32\n\n\u2297 Im )\u03a3H|v (x \u2297 Im ) + ImL , one can verify that for\n\nevery x \u2208 X,\n(\n\n\u03bbmin(v) \u2032\n\u03bbmax (v)\nx x + IL ) \u2297 Im \u2264 \u03a6x,v \u2264 (\nkxk22 + 1)ImL ,\n2\n\u03c3\n\u03c32\n\nwhere \u03bbmax (v) and \u03bbmin(v) > 0 are the maximum and minimum eigenvalues of \u03a3H|v . Let the\noperator R(*) denote the row space of a matrix. Then,\nZ\n2\n\u2032 \u22121\n1\n\u2212 22 vec y \u2032 \u03a6\u22121\nx,v vec y \u2212 \u03c3 2 vec (\u03bcH|v x) \u03a6x,v vec (\u03bcH|v x)\n\u03c3\nfPo ,Qv (y) \u2265\ne\ne\ndPo\n\u03c0 mL \u03c3 2mL det \u03a6x,v\nZ\n\u2032\n2\n\u22121 \u2032\ne\u2212tr(y(\u03bbmin (v)x x+\u03c3 IL ) y ) \u2212tr(\u03bcH|v x(\u03bbmin (v)x\u2032 x+\u03c32 IL )\u22121 x\u2032 \u03bc\u2032H|v )\ndPo\ne\n\u2265\n\u03c0 mL (\u03bbmax (v)kxk22 + \u03c3 2 )mL\nZ\nk(v)\n\u2265\ndPo,\n2\n2 mL\nkyk2 \u2264\u03bbmin (v)kxk2 ,R(y)\u2286R(x) (\u03bbmax (v)kxk2 + \u03c3 )\nwhere k(v) = k(\u03bcH|v , \u03a3H|v ) is a nonzero function from V to R+ . Assuming that\nPo (kyk2 \u2264 \u03bbmin (v)kxk2 , R(y) \u2286 R(x)) = \u0398(e\u2212l(y)\u03b1(v) ),\n36\n\n\ffor some positive function l : Y \u2192 R+ , \u03b1 : V \u2192 R+ , where l(y) = \u03c9(ln kyk2), we would\nobtain\nfPo ,Qv (y) \u2265 \u0398(e\u22122l(y)r(v) ).\nBut this means that\n\u2212 log2 fPo ,Qv (y) = O(min (kyk22, l(y)\u03b1(v))).\nNow, consider this together with (25), we can observe that for large values of kxk\u03b7\u03b7 , the\nintegral part of (25) is behaving as O(min (kxk22 , l(x))). Thus, a necessary condition for the\ncapacity achieving-measure is l(x) = \u03a9(kxk\u03b7\u03b7 ). This concludes the assertion.\nWe remark that (25) in Proposition 6.3 provides necessary and sufficient conditions for\nthe capacity-achieving measure of Rician or Rayleigh channels (with full-rank covariance\nmatrix) subject to any moment constraint \u03b7 > 1. However, it is still not possible to solve\n(25) and determine the capacity-achieving measures. Hence, this problem remains open for\nfuture investigations.\n\n7\n\nConclusion\n\nIn this part, we addressed a unified approach toward capacity analysis of multiple antenna\nchannels. We used the results of the Part I to analyze the capacity of multiple antenna\nchannels in a unified manner, irrespective of the type of fading, amount of correlation, and the\namount of available knowledge about the channel state information (CSI) at the receiver. We\nstudied the mutual information function and some of its analytical properties such as strict\nconcavity and continuity for additive white Gaussian (AWGN) channels, fading channels\nwith full CSI at the receiver, fading channels with no CSI, and fading channels with partial\nCSI at the receiver. Then, for each type of channels we studied the capacity value as well\nas issues such as the existence, uniqueness, and characterization of the capacity-achieving\nmeasures.\nFor channels with no CSI or partial CSI at the receiver, we provided necessary and sufficient conditions for characterization of the capacity-achieving measures and used asymptotic\nanalysis to characterize the tail behavior of these measures. However, a closed form expres37\n\n\fsion or full characterization of these measures remain open for future investigations. As\na direction for future research, one might consider the problem of characterization of the\ncapacity-achieving measure for channels with no CSI or partial CSI at the receiver.\n\nReferences\n[1] A. Goldsmith and P. Varaiya, \"Capacity of fading channels with channel side information,\" IEEE Trans. Inform. Theory, pp. 1218\u20131230, Oct. 1997.\n[2] A. Goldsmith and S. Chua, \"Variable-rate variable-power MQAM for fading channels,\"\n[3] A. J. Goldsmith and S. Chua, \"Adaptive coded modulation for fading channels,\" IEEE\nTrans. Commun., vol. 46, pp. 595\u2013602, May 1998.\n[4] A. Goldsmith, S. A. Jafar, N. Jindal, and S. Vishwanath, \"Capacity limits of MIMO\nchannels,\" IEEE J. Select. Areas Commun., vol. 21, p. 684:702, Jun. 2003.\n[5] E. Biglieri, J. Proakis, and S. Shamai, \"Fading channels: Information-theoretic and\ncommunications aspects,\" IEEE Trans. on Inform. Theory, vol. 44, pp. 2619\u20132692,\nOct. 1998.\n[6] G. Caire and S. Shamai, \"On the capacity of some channels with channel side information,\" IEEE Trans. Inform. Theory, vol. 45, pp. 2007\u20132019, Sept. 1999.\n[7] G. J. Foschini and M. J. Gans, \"On limits of wireless communications in a fading\nenvironment when using multiple antennas,\" Wireless Personal Communications, vol. 6,\npp. 311\u2013335, 1998.\n[8] E. Teletar, \"Capacity of multi-antenna Gaussian channels,\" tech. rep., Lucent Technology, Bell Laboratories, June 1995.\n[9] Y. H. Kim and A. Lapidoth, \"On the log determinant of non-centeral Wishart matrices,\"\nProc. of ISIT, pp. 54\u201354, Jun. 2003.\n\n38\n\n\f[10] D.-S. Shiu, G. J. Foschini, M. J. Gans, and J. Kahn, \"Fading correlation and its effect\non the capacity of multielement antenna systems,\" IEEE Trans. Commun., vol. 48,\npp. 502\u2013513, Mar. 2000.\n[11] M. Chiani, M. Z. Win, and A. Zanella, \"On the capacity of spatially correlated MIMO\nchannels,\" IEEE Trans. Inform. Theory, vol. 49, pp. 2363\u20132371, Oct. 2003.\n[12] K. Liu, V. Raghavan, and A. Sayeed, \"Capacity scaling and spectral efficiency in wideband correlated mimo channels,\" IEEE Trans. Inform. Theory, vol. 49, pp. 2504\u20132526,\nOct. 2003.\n[13] H. Shin and J. H. Lee, \"Capacity of multiple antenna fading channels: spatial fading correlation, double scattering and keyhole,\" IEEE Trans. Inform. Theory, vol. 49,\npp. 2636\u20132647, Oct. 2003.\n[14] P. Smith, S. Roy, and M. Shafi, \"Capacity of MIMO systems with semicorrelated flat\nfadingh,\" IEEE Trans. Inform. Theory, vol. 49, pp. 2781\u20132788, Oct. 2003.\n[15] T. L. Marzetta and B. M. Hochwald, \"Capacity of a mobile multiple-antenna communication link in Rayleigh flat fading,\" IEEE Trans. Inform. Theory, vol. 45, pp. 139\u2013157,\nJan. 1999.\n[16] I. C. Abou-Faycal, M. D. Trott, and S. Shamai, \"The capacity of discrete-time memoryless Rayleigh-fading channels,\" IEEE Trans. Inform. Theory, vol. 47, pp. 1290\u20131301,\nMay 2001.\n[17] M. C. Gursoy, H. V. Poor, and S. Verd\u00fa, \"Efficient signaling for low-power rician fading\nchannels,\" Proceedings of 40th Alerton Conf., pp. 327\u2013336, 2002.\n[18] A. Lapidoth, \"On the asymptotic capacity of fading channels,\" IEEE Trans. Inform.\nTheory, 2003. Preprint, submitted to.\n[19] A. Lapidoth and S. Moser, \"Capacity bounds via duality with applications to multiantenna systems on flat fading channels,\" IEEE Trans. Inform. Theory, vol. 49,\npp. 2426\u20132467, Oct. 2003.\n39\n\n\f[20] L. Zheng and D. Tse, \"Communicating on the Grassmann manifold: A geometric approach to the non-coherent multiple antenna channel,\" IEEE Trans. Inform. Theory,\nvol. 48, pp. 359\u2013383, Feb. 2002.\n[21] G. B. Folland, Real Analysis: Modern Techniques and Their Applications. John Wiley,\nsecond ed., 1999.\n[22] A. N. Shiryaev, Probability. No. 95 in Graduate Texts in Mathematics, New York:\nSpringer-Verlag, second ed., 1996.\n[23] T. M. Cover and J. A. Thomas, Elements of Information Theory. Wiley series in\ntelecommunications, New York: John Wiley & Sons, 1991.\n[24] J. G. Proakis, Digital Communications. McGraw-Hill, 3 ed., 1995.\n[25] S. Venkatesan, S. H. Simon, and R. A. Valenzuela, \"Capacity of a Gaussian MIMO\nchannel with nonzero mean,\" Proc. IEEE Veh. Technol., Oct. 2003.\n[26] A. M. Tulino, A. Lozano, and S. Verdu, \"Capacity-achieving input covariance for correlated multi-antenna channels,\" Proc. 41st Allerton Conf., pp. 242\u2013251, Oct. 2003.\n[27] R. G. Bartle, The Elements of Real Analysis. New York: John Wiley & Suns, Inc.,\nsecond ed., 1976.\n[28] R. Palanki, \"On the capacity achieving distributions of some fading channels,\" Proceedings of 40th Alerton Conf., pp. 337\u2013346, 2002.\n\n40\n\n\f"}