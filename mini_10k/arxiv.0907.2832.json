{"id": "http://arxiv.org/abs/0907.2832v1", "guidislink": true, "updated": "2009-07-16T13:16:31Z", "updated_parsed": [2009, 7, 16, 13, 16, 31, 3, 197, 0], "published": "2009-07-16T13:16:31Z", "published_parsed": [2009, 7, 16, 13, 16, 31, 3, 197, 0], "title": "Distribution Fitting 2. Pearson-Fisher, Kolmogorov-Smirnov,\n  Anderson-Darling, Wilks-Shapiro, Cramer-von-Misses and Jarque-Bera statistics", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0907.3159%2C0907.3595%2C0907.1548%2C0907.0258%2C0907.0957%2C0907.1418%2C0907.1224%2C0907.3849%2C0907.5290%2C0907.1028%2C0907.2120%2C0907.5605%2C0907.2612%2C0907.2494%2C0907.0071%2C0907.5150%2C0907.5227%2C0907.2205%2C0907.1172%2C0907.5413%2C0907.1186%2C0907.4714%2C0907.4043%2C0907.3778%2C0907.4978%2C0907.0890%2C0907.4750%2C0907.0799%2C0907.5040%2C0907.2920%2C0907.0807%2C0907.0638%2C0907.4155%2C0907.0679%2C0907.3270%2C0907.4197%2C0907.1935%2C0907.1976%2C0907.4060%2C0907.2255%2C0907.0952%2C0907.2385%2C0907.2595%2C0907.2419%2C0907.3587%2C0907.2091%2C0907.3098%2C0907.0039%2C0907.4744%2C0907.0631%2C0907.1008%2C0907.1082%2C0907.3885%2C0907.1941%2C0907.4789%2C0907.3850%2C0907.2038%2C0907.5508%2C0907.4398%2C0907.4638%2C0907.1138%2C0907.0891%2C0907.3548%2C0907.0846%2C0907.0815%2C0907.0528%2C0907.5499%2C0907.0818%2C0907.3079%2C0907.3368%2C0907.2931%2C0907.3214%2C0907.0875%2C0907.1756%2C0907.2508%2C0907.2974%2C0907.0879%2C0907.4759%2C0907.3266%2C0907.5351%2C0907.1056%2C0907.2944%2C0907.2832%2C0907.1168%2C0907.0804%2C0907.2116%2C0907.4839%2C0907.1409%2C0907.0899%2C0907.2943%2C0907.4854%2C0907.0279%2C0907.3831%2C0907.1391%2C0907.4504%2C0907.2516%2C0907.5183%2C0907.2708%2C0907.3739%2C0907.2245%2C0907.4173&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Distribution Fitting 2. Pearson-Fisher, Kolmogorov-Smirnov,\n  Anderson-Darling, Wilks-Shapiro, Cramer-von-Misses and Jarque-Bera statistics"}, "summary": "The methods measuring the departure between observation and the model were\nreviewed. The following statistics were applied on two experimental data sets:\nChi-Squared, Kolmogorov-Smirnov, Anderson-Darling, Wilks-Shapiro, and\nJarque-Bera. Both investigated sets proved not to be normal distributed. The\nGrubbs test identified one outlier and after its removal the normality of the\nset of 205 chemical active compounds was accepted. The second data set proved\nnot to have any outliers. Kolmogorov-Smirnov statistic is less affected by the\nexistence of outliers (positive variation expressed as percentage smaller than\n2). The outliers bring to Kolmogorov-Smirnov statistic errors of type II and to\nthe Anderson-Darling statistic errors of type I.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0907.3159%2C0907.3595%2C0907.1548%2C0907.0258%2C0907.0957%2C0907.1418%2C0907.1224%2C0907.3849%2C0907.5290%2C0907.1028%2C0907.2120%2C0907.5605%2C0907.2612%2C0907.2494%2C0907.0071%2C0907.5150%2C0907.5227%2C0907.2205%2C0907.1172%2C0907.5413%2C0907.1186%2C0907.4714%2C0907.4043%2C0907.3778%2C0907.4978%2C0907.0890%2C0907.4750%2C0907.0799%2C0907.5040%2C0907.2920%2C0907.0807%2C0907.0638%2C0907.4155%2C0907.0679%2C0907.3270%2C0907.4197%2C0907.1935%2C0907.1976%2C0907.4060%2C0907.2255%2C0907.0952%2C0907.2385%2C0907.2595%2C0907.2419%2C0907.3587%2C0907.2091%2C0907.3098%2C0907.0039%2C0907.4744%2C0907.0631%2C0907.1008%2C0907.1082%2C0907.3885%2C0907.1941%2C0907.4789%2C0907.3850%2C0907.2038%2C0907.5508%2C0907.4398%2C0907.4638%2C0907.1138%2C0907.0891%2C0907.3548%2C0907.0846%2C0907.0815%2C0907.0528%2C0907.5499%2C0907.0818%2C0907.3079%2C0907.3368%2C0907.2931%2C0907.3214%2C0907.0875%2C0907.1756%2C0907.2508%2C0907.2974%2C0907.0879%2C0907.4759%2C0907.3266%2C0907.5351%2C0907.1056%2C0907.2944%2C0907.2832%2C0907.1168%2C0907.0804%2C0907.2116%2C0907.4839%2C0907.1409%2C0907.0899%2C0907.2943%2C0907.4854%2C0907.0279%2C0907.3831%2C0907.1391%2C0907.4504%2C0907.2516%2C0907.5183%2C0907.2708%2C0907.3739%2C0907.2245%2C0907.4173&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The methods measuring the departure between observation and the model were\nreviewed. The following statistics were applied on two experimental data sets:\nChi-Squared, Kolmogorov-Smirnov, Anderson-Darling, Wilks-Shapiro, and\nJarque-Bera. Both investigated sets proved not to be normal distributed. The\nGrubbs test identified one outlier and after its removal the normality of the\nset of 205 chemical active compounds was accepted. The second data set proved\nnot to have any outliers. Kolmogorov-Smirnov statistic is less affected by the\nexistence of outliers (positive variation expressed as percentage smaller than\n2). The outliers bring to Kolmogorov-Smirnov statistic errors of type II and to\nthe Anderson-Darling statistic errors of type I."}, "authors": ["Lorentz Jantschi", "Sorana D. Bolboaca"], "author_detail": {"name": "Sorana D. Bolboaca"}, "author": "Sorana D. Bolboaca", "arxiv_comment": "8 pages, 1 figure, 4 tables, 14 equations", "links": [{"href": "http://arxiv.org/abs/0907.2832v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0907.2832v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0907.2832v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0907.2832v1", "journal_reference": null, "doi": null, "fulltext": "Distribution Fitting 2. Pearson-Fisher, Kolmogorov-Smirnov, Anderson-Darling, WilksShapiro, Cramer-von-Misses and Jarque-Bera statistics\nLorentz J\u00c4NTSCHI1 and Sorana D. BOLBOAC\u01022\n1\n\nTechnical University of Cluj-Napoca, 400641 Cluj-Napoca; http://lori.academicdirect.org\n\"Iuliu Ha\u0163ieganu\" University of Medicine and Pharmacy, 400349 Cluj-Napoca, Romania;\nsbolboaca@umfcluj.ro\n\n2\n\nAbstract. The methods measuring the departure between observation and the model\nwere reviewed. The following statistics were applied on two experimental data sets: ChiSquared, Kolmogorov-Smirnov, Anderson-Darling, Wilks-Shapiro, and Jarque-Bera. Both\ninvestigated sets proved not to be normal distributed. The Grubbs' test identified one outlier\nand after its removal the normality of the set of 205 chemical active compounds was accepted.\nThe second data set proved not to have any outliers. Kolmogorov-Smirnov statistic is less\naffected by the existence of outliers (positive variation expressed as percentage smaller than\n2). The outliers bring to Kolmogorov-Smirnov statistic errors of type II and to the AndersonDarling statistic errors of type I.\nKeywords: Pearson-Fisher statistic, Kolmogorov-Smirnov statistic, Anderson-Darling\nstatistic, Wilks-Shapiro statistic, Kramer-von-Misses statistic, Jarque-Bera statistic, Grubbs\nstatistic.\nINTRODUCTION\nA series of alternatives are available in the literature to measure the agreement\nbetween observation and the model. When the model is a distribution law, these alternatives\nare called statistics. The problem of agreement can be divided in two classes: estimation of\n(theoretical) distribution parameters and measure of the departure between the model and the\nobserved data. The estimating of the (theoretical) distribution parameters is in details\npresented in (J\u00e4ntschi, 2009).\nThe present paper presented the common statistics measurement of the departure\nbetween observation and the model beside their application on one set of biological active\ncompounds.\nMATERIALS AND METHODS\nPearson-Fisher Statistic\nChi Square or Pearson-Fisher (\u03c72) test was proposed as a measure of random departure\nbetween observation and the theoretical model by Karl PEARSON (Pearson, 1900). The test\nwas later corrected by Ronald FISHER through decrease of the degrees of freedom by a unit\n(decrease due to the existence of the equality relationship between the sum of observed\nfrequencies and the sum of theoretical frequencies, (Fisher, 1922)), and by the number of\nunknown parameters of the theoretical distribution when they come as estimated from\nmeasures of central tendency (Fisher, 1924).\nThe agreement between observation and the model are testes though the division of\nthe interval of observation in a given number of intervals (let be n this number) by X2\nexpression given in Eq(1).\n\n\fn\n\nX 2 = \u2211 (O i \u2212 E i ) 2 E i ; p = p \u03c7 2 (X 2 , n \u2212 t \u2212 1)\n\n(1)\n\ni =1\n\nwhere X2 = chi square statistic; Oi and Ei are the observed and expected frequencies in the i-th\nfrequency class; p\u03c72 = probability of observing the X2 departure (from 0) by using chi square\ndistribution; n = number of classes; t is the number of central tendency measures estimated\nparameters).\nUsually the agreement is accepted when p is no less than 5%. Despite the fact that \u03c72\ntest is the best known statistic for testing the agreement between observation and the model,\nthe frame of the application of it is one of the complex ones (Snedecor and Cochran, 1989).\nA first issue is about the number of the frequency classes; a series of options are available,\nfrom which two of them are as follows:\n\u00f7 Rounding the Hartley entropy (Hartley, 1928) of observation: log2(2N), where N is the\nnumber of observations (EasyFit software1 uses this approach);\n\u00f7 Obtaining simultaneously of classes number and classes width from the histogram seen as\nan estimator of the density (Scott, 1992) when an optimal criteria is chosen from a list\n(Dataplot2 automatically generate the frequency classes using a rule of this type: width of\na frequency class is 0.3*s, where s is the sample standard deviation; highest class and\nlowest class are given by a departure of \u00b16*s relative to the sample mean and the marginal\nclasses with zero observed frequency are omitted).\nA second issue is about the width of the frequency classes. At least two approaches are\navailable: the data can be grouped in equal (theoretical or observed) probability or the data\ncan be grouped in equal (theoretical or observed) width. First approach (equal probability) is\nmore often used due to its better efficiency for grouped data.\nOther issue take into consideration the number of observations in a frequency class. In\norder to keep only the random effect, at least 5 observations are required in every class. Thus,\nin practice, when a procedure give the frequency classes with less than 5 observations per\nclass, adjacent classes are joined together to fulfil this requirement.\nKolmogorov-Smirnov Statistic\nKolmogorov-Smirnov statistic uses comparison of the cumulative frequencies. The\nKolmogorov-Smirnov statistic may act as measure of the agreement between observation and\nthe model (Kolmogorov, 1941) as well as a measure between two series of observations\n(Smirnov, 1948). If Ft(Xi) and Fo(Xi) are the theoretical and the observed cumulative\nfrequencies for distinct and ascending ordered observations Xi, then a series of statistics are\nbased on Ft(Xi)-Fo(Xi) difference:\nD \u2212 = max(Ft (X i ) \u2212 Fo (X i ) ) , D + = max(Fo (X i ) \u2212 Ft (X i ) )\n1\u2264i \u2264 n\n\n1\u2264i \u2264 n\n\nD = max(D \u2212 , D + ) , V = D \u2212 + D +\n(2)\nwhere D- measures the largest leak in observation compared with theoretical value, D+\nmeasures the largest excess in observation compared with theoretical value, D measures the\nlargest difference in between (it is the most frequent used), and V represent the modification\nof D given by Kuiper (Kuiper, 1960).\nFor the K = D N statistic the distribution law comes from:\nK = max B( t ) , where B is the Brownian bridge conditioned by:\n0\u2264 t \u22641\n\n1\n2\n\nhttp://www.mathwave.com\nhttp://www.itl.nist.gov/div898/software/dataplot.html\n\n\fB(0) = B(1) = 0 (boundaries), M(B(t)) = 0 (mean), Var(B(t)) = t(t-1) (variance)\nand the probability of observing a larger departure (K < x) is given by:\n\u221e\n2 2\n2\u03c0 \u221e \u2212( 2i \u22121) 2 \u03c0 2 / 8 K 2\nP(K < x ) = 1 \u2212 2\u2211 (\u22121) i \u22121 e \u2212 2i K =\n(3)\n\u2211e\nK i =1\ni =1\nSimilarly, for V statistic:\n\nP(V < x ) = Q KP ( n + 0.155 + 0.24\n\n\u221e\n\nn ) ; Q KP (\u03bb) = 2\u2211 (4i 2 \u03bb2 \u2212 1)e \u2212 2i \u03bb\n\n2 2\n\n(4)\n\ni =1\n\nAnderson-Darling Statistic\nThe Anderson-Darling statistic (Anderson and Darling, 1952) uses the distinct values\nfrom the observed data ordered ascending. The A2 statistic is computed as follows:\nN\n2k \u2212 1\n(ln(F(X k ) + ln(1 \u2212 F(X n +1\u2212k )))\nA2 = \u2212N \u2212 \u2211\n(5)\nN\nk =1\nand has the variance given by:\n2(\u03c0 2 \u2212 9) 10 \u2212 \u03c0 2\n+\n(6)\nVar (A 2 ) =\n3\nN\nThe probability of the worst observation depends on the theoretical distribution. For\nthe normal distribution this probability is given by (Trujillo-Ortiz et al., 2007):\nA 2 c = A 2 (1 + 0.75 n + 2.25 n 2 )\n1 exp( 13.436 + 101.14 A c\n\np=\n\n1 exp( 8.318 + 42.796 A c\n\n223.73 A c2 ), A c < 0.2\n\n59.938 A c2 ),\n\nexp(0.9177 4.279 A c 1.38 A ),\n2\nc\n\nexp(1.2937 5.709 A c + 0.0186 A c2 ),\n\n0.2 \u2264A c < 0.34\n0.34 \u2264A c < 0.6\n\n(7)\n\nA c \u22640.6\n\nWilks-Shapiro Statistic\nWilks-Shapiro statistic (Shapiro and Wilk, 1965) measure a departure from normality.\nThe W2 statistic is computed on ordered values of observed data as follows:\n2\n\nN\n\u239b N\n\u239e\nW = \u239c \u2211 A i X i \u239f \u2211 ( X i \u2212 X ) 2 , A = m T V \u22121 ( m T V \u22121 V \u22121 m T ) \u22121 / 2\n(8)\ni =1\n\u239d i =1\n\u23a0\nwhere m and V = expected values of the order statistics of independent and identicallydistributed random variables sampled from the standard normal distribution and their\ncovariances respectively. The agreement is rejected if W2 value is too high. The expression of\ncritical values as well as exact probabilities associated with the observed values can be\nobtained via software (Royston, 1995).\n2\n\nCramer-von-Misses Statistic\nThen the Cram\u00e9r-von-Mises statistic (CMS) is:\n2\nn\n1 \u239b\u239c 1\n\u239b 2i \u2212 1\n\u239e \u239e\u239f\n2\n+ \u2211\u239c\n\u2212 F(X i ) \u239f\nW =\n(9)\nn \u239c\u239d 12n i =1 \u239d n\n\u23a0 \u239f\u23a0\nThe probability to observe a value greater than CMS is given by the following\napproximate function (Levin, 2003):\n(10)\np( W 2 < x ) = 0.67 \u22c5 exp(\u22125.6 \u22c5 W 2 )\n\n\fJarque-Bera Statistic\nThe Jaque-Bera statistic (Jarque and Bera, 1981) uses third and fourth central\nmoments as measures of the departure between observed distribution and a normal\ndistribution. The statistic comes from:\nN\n\n2\n\n\u2211 (X\n\n2\n\n\u2212 X)k\n\nm\ng1 + g 2 / 4\nm\n; g1 = 33/ 2 ; g 2 = 42 \u2212 3 ; m k = i =1\n(11)\nN\n6\nm2\nm2\nand the probability of observation comes from Chi Square distribution with 2 degrees of\nfreedom ( p = p \u03c7 2 (JB,2) ).\n\nJB = N\n\ni\n\nZ-Based Statistics\nFor central tendency measures, the normal distribution assumption operates as well on\nit. The following statistics are available:\n( N \u2212 1)s 2 \u2212 \u03c3 2 N\nX \u2212\u03bc\nz mean =\nN ; z var iance =\nN\n2\ns\n( N \u2212 1) 3 m \u2212 ( N \u2212 3)m\n4\n\nz st .dev\n\n2\ns\n\u0393(n 2 )\n\u22121\nn \u22121\n\u03c3\n; c4 =\n=\n2\n\u0393((n \u2212 1) 2 )\n1 \u2212 c4\n\nc4\n\nz skewness = g1\n\n2\n\n(12)\n\n2\n( N + 1)( N + 3)\n\u239b N +1\n\u239e ( N + 3)( N + 5)( N \u2212 1)\ng 2 \u2212 3\u239f\n; z kurtosis = \u239c\n6( N \u2212 2)\n\u239d N \u22121\n\u23a0 24 N( N \u2212 2)( N \u2212 3)\n\nGrubbs' Statistic\nMany statistical techniques are sensitive to the presence of outliers, Grubbs being one\nof them. All calculations, including the mean and standard deviation may be distorted by a\nsingle grossly inaccurate data point. Checking for outliers should be a routine part of any data\nanalysis. Grubbs' test is used to detect outliers in a univariate data set (Grubbs, 1969). It is\nbased on the assumption of normality. The Grubbs' test statistic is the largest absolute\ndeviation from the sample mean ( X ) in units of the sample standard deviation (s). The\nGrubbs test statistics may be applied to the minimum and to the maximum (Eq(13)) and to the\nboth (Eq(14) when associated probabilities of observed are obtained from Student t\ndistribution:\nX \u2212 min(X)\nmax(X) \u2212 X\nG min =\n, G max =\ns\ns\n\u239b\n\u239e\nn (n \u2212 2)\n(13)\np G = 2n \u22c5 p t \u239c G\n, n \u2212 2,1\u239f\n\u239c\n\u239f\nn\n\u2212\n1\n\u239d\n\u23a0\nmax(X \u2212 min(X ), max(X ) \u2212 X )\n,\nG all =\ns\n\u239e\n\u239b\nn (n \u2212 2)\npG = n \u22c5 p t \u239c G\n, n \u2212 2,2 \u239f\n(14)\n\u239f\n\u239c\nn\n1\n\u2212\n\u23a0\n\u239d\n\n\fUnder assumption of normal distributed errors the Wilk-Shapiro, Jarque-Bera, and\nGrubbs' statistics can be applied for detecting outliers, obtaining thus powerful tests for\ndetecting outliers for any model of observed data.\n\nApplications\nTwo sets of investigated data were taken from literature in order to illustrate the\nprocedures described above. First set (Duchowicz et al., 2008) records the measurements of\naqueous solubility (Sol) for a series of 166 drug-like compounds. The second set (J\u00e4ntschi et\nal., 2009) the measurements of octanol-water partition coefficient (Kow) for a series of 206\npolychlorinated biphenils expressed both in logarithmic scale (log10(Sol), [Sol]=mg*ml-1;\nlog10(Kow), [Kow]=1). Table 1 contain the experimental values for each set in ascending order.\nThe following tests were applied on the investigated experimental data: KolmogorovSmirnov (abbreviated as KS), Anderson-Darling (AD), Chi Square (CS), Wilks-Shapiro\n(WS), Z-based Skewnes (ZSkewness), Z-based Kurtosis (ZKurtosis), Jarque-Bera (JB).\nTab. 1.\nTwo data sets of measurements under assumption of normal distribution\nlog(Sol) for 166 drug-like compounds\nlog(Kow) for 206 polychlorinated biphenils\n-6; -5.53; -5.376; -4.247; -4.173; -4; -3.699; -3.61; - 4.151; 4.401; 4.421; 4.601; 4.941; 5.021; 5.023; 5.15;\n3.522; -3.397; -3.239; -3.125; -3.096; -3.07; -3.046; 5.18; 5.295; 5.301; 5.311; 5.311; 5.335; 5.343; 5.404;\n-3; -2.85; -2.795; -2.747; -2.656; -2.397; -2.318; - 5.421; 5.447; 5.452; 5.452; 5.481; 5.504; 5.517; 5.537;\n5.537; 5.551; 5.561; 5.572; 5.577; 5.577; 5.627; 5.637;\n2.221; -2.136; -2.113; -2.041; -2; -2; -2; -1.958; 5.637; 5.667; 5.667; 5.671; 5.677; 5.677; 5.691; 5.717;\n1.886; -1.853; -1.853; -1.826; -1.823; -1.823; 1.728; -1.673; -1.657; -1.61; -1.588; -1.397; -1.397; 5.743; 5.751; 5.757; 5.761; 5.767; 5.767; 5.787; 5.811;\n5.817; 5.827; 5.867; 5.897; 5.897; 5.904; 5.943; 5.957;\n-1.392; -1.337; -1.301; -1.301; -1.252; -1.23; 5.957; 5.987; 6.041; 6.047; 6.047; 6.047; 6.057; 6.077;\n1.216; -1.209; -1.124; -1.051; -1.045; -1.003; 6.091; 6.111; 6.117; 6.117; 6.137; 6.137; 6.137; 6.137;\n0.951; -0.854; -0.854; -0.841; -0.821; -0.767; 0.701; -0.699; -0.658; -0.652; -0.648; -0.62; -0.602; 6.137; 6.142; 6.167; 6.177; 6.177; 6.177; 6.204; 6.207;\n6.221; 6.227; 6.227; 6.231; 6.237; 6.257; 6.267; 6.267;\n-0.585; -0.523; -0.523; -0.495; -0.495; -0.495; 6.267; 6.291; 6.304; 6.327; 6.357; 6.357; 6.367; 6.367;\n0.444; -0.426; -0.397; -0.367; -0.301; -0.225; 0.222; -0.22; -0.187; -0.161; -0.125; -0.102; -0.08; 6.371; 6.427; 6.457; 6.467; 6.487; 6.497; 6.511; 6.517;\n6.517; 6.523; 6.532; 6.547; 6.583; 6.587; 6.587; 6.587;\n-0.056; -0.051; -0.009; 0; 0; 0.013; 0.017; 0.026;\n6.607; 6.611; 6.647; 6.647; 6.647; 6.647; 6.647; 6.657;\n0.057; 0.077; 0.079; 0.079; 0.079; 0.079; 0.146;\n6.657; 6.671; 6.671; 6.677; 6.677; 6.677; 6.697; 6.704;\n0.204; 0.258; 0.301; 0.301; 0.301; 0.398; 0.431;\n6.717; 6.717; 6.737; 6.737; 6.737; 6.747; 6.767; 6.767;\n0.477; 0.602; 0.623; 0.633; 0.663; 0.699; 0.699;\n0.699; 0.7; 0.769; 0.78; 0.806; 0.826; 0.845; 0.846; 6.767; 6.797; 6.827; 6.857; 6.867; 6.897; 6.897; 6.937;\n6.937; 6.957; 6.961; 6.997; 7.027; 7.027; 7.027; 7.057;\n0.873; 0.886; 0.912; 0.933; 1.012; 1.053; 1.079;\n7.071; 7.087; 7.087; 7.117; 7.117; 7.117; 7.121; 7.123;\n1.079; 1.103; 1.187; 1.294; 1.301; 1.397; 1.414;\n7.147; 7.151; 7.177; 7.177; 7.187; 7.187; 7.207; 7.207;\n1.519; 1.536; 1.556; 1.623; 1.658; 1.698; 1.698;\n7.207; 7.211; 7.247; 7.247; 7.277; 7.277; 7.277; 7.281;\n1.698; 1.763; 1.857; 1.872; 1.914; 1.929; 1.934;\n7.304; 7.307; 7.307; 7.321; 7.337; 7.367; 7.391; 7.427;\n2.146; 2.214; 2.221; 2.301; 2.396; 2.522; 2.557;\n7.441; 7.467; 7.516; 7.527; 7.527; 7.557; 7.567; 7.592;\n2.665; 2.698; 2.698; 2.698; 2.77; 2.806; 3.352\n7.627; 7.627; 7.657; 7.657; 7.717; 7.747; 7.751; 7.933;\n8.007; 8.164; 8.423; 8.683; 9.143; 9.603\n\nRESULTS AND DISCUSSION\nThe distributions of the investigated experimental data expressed graphically by using\nhistogram plot are presented in Figure 1. The analysis of the Duchowicz et al. data set\n\n\f(Duchowicz et al., 2008) seems to be more skewed compared to the J\u00e4ntschi et al. data set\n(J\u00e4ntschi et al, 2009).\nSeven tests were applied in order to measurement of the departure between\nobservation and the model. The results are presented in Tables 2 and 3.\nProbability Density Function\n\nProbability Density Function\n0.32\n\n0.28\n0.26\n\n0.28\n\n0.24\n0.22\n\n0.24\n\n0.2\n0.18\n\n0.2\nf(x)\n\nf(x)\n\n0.16\n\n0.16\n\n0.14\n0.12\n\n0.12\n\n0.1\n0.08\n\n0.08\n\n0.06\n0.04\n\n0.04\n\n0.02\n0\n\n-6\n\n-5\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n0\n\n4.5\n\n5\n\n5.5\n\n6\n\n6.5\n\nx\nHistogram\n\n7\n\n7.5\n\n8\n\n8.5\n\n9\n\n9.5\n\nx\n\nNormal\n\n(Duchowicz et al., 2008) - N = 166\n\nHistogram Normal\n\n(J\u00e4ntschi et al, 2009) - N = 206\n\nFig. 1. Histograms of observed biological activities\nTab. 2.\nHypothesis of normality: experimental biologic activity for Duchowicz et al. set (Duchowicz et al.,\n2008)\nStatistic\nKolmogorov-Smirnov\nAnderson-Darling\nChi Squared\nWilks-Shapiro\nZSkewness\nZKurtosis\nJarque-Bera\n\nValue Probability of observation Reject the hypothesis of normality\n0.05508\n67.43%\nNo\n0.56539 14.1%; 12.5%; 14.3%\nNo\n3(df=7)\n88.6%\nNo\n0.98173\n2.8%\nYes\n-2.58\n1\u2030\nYes\n0.53\n59.5%\nNo\n6.61\n3.7%\nYes\n\nTab. 3.\nHypothesis of normality: experimental biologic activity for J\u00e4ntschi et al. set (J\u00e4ntschi et al., 2009)\nStatistic\nKolmogorov-Smirnov\nAnderson-Darling\nChi Squared\nWilks-Shapiro\nZSkewness\nZKurtosis\nJarque-Bera\n\nValue Probability of observation Reject the hypothesis of normality\n0.03348\n96.91%\nNo\n0.44432 27.2%; 25.2%; 19.2%\nNo\n11(df=7)\n13.8%\nNo\n0.98709\n5.8%\nNo\n1.48\n14%\nNo\n2.51\n1.2%\nYes\n7.577\n2.3%\nYes\n\nThe Jarque-Bera test is not affected by the tied values while the Kolmogorov-Smirnov and\nAnderson-Darling test are affected as results from Table 2.\n\nThe analysis of the results presented in table 2 and 3 revealed that the hypothesis of\nnormality do not be accepted for the investigated data sets. This hypothesis is rejected by 3\ntests when Duchowicz et al. set (Duchowicz et al., 2008) is analyzed and by 2 tests when\n\n\fJ\u00e4nstchi et al. (J\u00e4ntschi et al., 2009) set is investigated. These results lead to the conclusion\nthat both sets contain outliers.\nThe Grubbs' test was applied in order to identify the outliers. The Grubbs' test did not\nidentify any outlier for the Duchowicz et al. set. The following results were identified for the\nJ\u00e4ntschi et al. set for a significance level of 5% (\u03b1=5%):\n\u0083 One outlier: experimental data of 9.603 (5%).\n\u0083 No outlier (5%): Y\\{9.603}.\nThe outlier identified by Grubb's test was removed from the J\u00e4ntschi et al. set and the\nsame seven tests were again applied in order to measurement of the departure between\nobservation and the model. The results are presented in Table 4.\nTab. 4.\nHypothesis of normality: experimental biologic activity for J\u00e4ntschi et al. set after remodel of the\nidentified outlier (\u03bc = 6.4653; \u03c3 = 0.80344)\nReject the hypothesis of\nStatistic\nValue Probability of observation\nnormality\nKolmogorov-Smirnov 0.03579\n94.68%\nNo\nAnderson-Darling\n0.37878\n40.3%; 39.5%; 21.0%\nNo\nChi Squared\n8.64(df=7)\n27.9%\nNo\nWilks-Shapiro\n0.98709\n47.8%\nNo\nZSkewness\n1.48\n79.2%\nNo\nZKurtosis\n2.51\n41.5%\nNo\nJarque-Bera\n0.56146\n75.5%\nNo\n\nCONCLUSIONS\nKolmogorov-Smirnov statistic is less affected by the existence of outliers (positive\nvariation expressed as percentage smaller than 2). The outliers bring to Kolmogorov-Smirnov\nstatistic errors of type II (the null hypothesis is accepted even if it is not true). The\nKolmogorov-Smirnov statistic is followed by Anderson-Darling (variation of 10%). The\noutliers bring to Anderson-Darling statistic errors of type I (the null hypothesis is rejected\neven if it is true). The other statistics are more affected by the existence of outliers in the\nfollowing order: Chi-Square (100%), ZSkewness (470%), Jarque-Bera (3200%), ZKurtosis\n(3400%).\n\nAcknowledgments. The research was partly supported by UEFISCSU Romania\nthrough ID1051/202/2007 grant.\nREFERENCES\nAnderson, T. W. and D. A. Darling. (1952). Asymptotic theory of certain \"goodnessof-fit\" criteria based on stochastic processes. Annals of Mathematical Statistics 23(2):193212.\nDuchowicz, P. R., A. Talevi, L. E. Bruno-Blanch, E. A. Castro. (2008). New QSPR\nstudy for the prediction of aqueous solubility of drug-like compounds. Bioorganic &\nMedicinal Chemistry 16:7944-7955.\nFisher, R. A. (1922). On the Interpretation of \u03c72 from Contingency Tables, and the\nCalculation of P. Journal of the Royal Statistical Society 85:87-94.\nFisher, R. A. (1924). The Conditions Under Which \u03c72 Measures the Discrepancy\nBetween Observation and Hypothesis. Journal of the Royal Statistical Society 87:442-450.\n\n\fGrubbs F. 1969. Procedures for Detecting Outlying Observations in Samples.\nTechnometrics 11(1):1-21.\nHartley, R. V. L. (1928). Transmission of Information. Bell System Technical Journal\n535-563.\nJ\u00e4ntschi L. (2009). Distribution Fitting 1. Parameters Estimation under Assumption of\nAgreement between Observation and Model. Bulletin of Agricultural Sciences and Veterinary\nMedicine University of Cluj-Napoca ZZ:XX-YY.\nJ\u00e4ntschi, L., S. D. Bolboac\u0103 and R. E. Sestra\u015f. 2009. Meta-Heuristics on Quantitative\nStructure-Activity Relationships: A Case Study on Polychlorinated Biphenyls. DOI:\n10.1007/s00894-009-XXXX.\nJarque, C. M. and A. K. Bera. (1981). Efficient tests for normality, homoscedasticity and\nserial independence of regression residuals: Monte Carlo evidence. Economics Letters 7(4):313318.\nKolmogorov, A. (1941). Confidence Limits for an Unknown Distribution Function.\nThe Annals of Mathematical Statistics 12(4):461-463.\nKuiper, N., H. (1960). Tests concerning random points on a circle. Indagationes\nMathematicae 32:38-47.\nLevin, G. (2003). Smirnov Cramer Von Mises Test. BSD License.\nhttp://www.mathworks.com/matlabcentral/fileexchange/3579\nPearson, K. (1900). On the criterion that a given system of deviations from the\nprobable in the case of a correlated system of variables is such that it can be reasonably\nsupposed to have arisen from random sampling. Philosophical Magazine 5th Ser 50:157-175.\nRoyston, P. (1995). Wilks-Shapiro Algorithm AS. Applied Statistics 44(4):R94\nScott D. (1992). Multivariate Density Estimation. John Wiley, Chapter 3.\nShapiro, S. S. and M. B. Wilk. (1965). An analysis of variance test for normality\n(complete samples). Biometrika 52(3-4):591-611.\nSmirnov, N. V. (1948). Table for estimating the goodness of fit of empirical\ndistributions. The Annals of Mathematical Statistics 19(2):279-281.\nSnedecor, G. W. and W. G. Cochran. (1989). Statistical Methods, Eighth Edition,\nIowa State University Press.\nTrujillo-Ortiz, A., R. Hernandez-Walls, K. Barba-Rojo and A. Castro-Perez. (2007).\nAnDartest:Anderson-Darling test for assessing normality of a sample data.\nhttp://mathworks.com/matlabcentral/fileexchange/14807.\n\n\f"}