{"id": "http://arxiv.org/abs/cond-mat/0303080v2", "guidislink": true, "updated": "2003-05-26T07:22:48Z", "updated_parsed": [2003, 5, 26, 7, 22, 48, 0, 146, 0], "published": "2003-03-05T10:46:50Z", "published_parsed": [2003, 3, 5, 10, 46, 50, 2, 64, 0], "title": "Directed geometrical worm algorithm applied to the quantum rotor model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0303086%2Ccond-mat%2F0303157%2Ccond-mat%2F0303131%2Ccond-mat%2F0303514%2Ccond-mat%2F0303374%2Ccond-mat%2F0303072%2Ccond-mat%2F0303645%2Ccond-mat%2F0303320%2Ccond-mat%2F0303380%2Ccond-mat%2F0303005%2Ccond-mat%2F0303193%2Ccond-mat%2F0303487%2Ccond-mat%2F0303602%2Ccond-mat%2F0303388%2Ccond-mat%2F0303261%2Ccond-mat%2F0303385%2Ccond-mat%2F0303576%2Ccond-mat%2F0303075%2Ccond-mat%2F0303573%2Ccond-mat%2F0303562%2Ccond-mat%2F0303286%2Ccond-mat%2F0303257%2Ccond-mat%2F0303058%2Ccond-mat%2F0303302%2Ccond-mat%2F0303293%2Ccond-mat%2F0303103%2Ccond-mat%2F0303359%2Ccond-mat%2F0303406%2Ccond-mat%2F0303080%2Ccond-mat%2F0303200%2Ccond-mat%2F0303549%2Ccond-mat%2F0303396%2Ccond-mat%2F0303339%2Ccond-mat%2F0303502%2Ccond-mat%2F0303610%2Ccond-mat%2F0303639%2Ccond-mat%2F0303218%2Ccond-mat%2F0303586%2Ccond-mat%2F0303201%2Ccond-mat%2F0303486%2Ccond-mat%2F0303360%2Ccond-mat%2F0303529%2Ccond-mat%2F0303071%2Ccond-mat%2F0303171%2Ccond-mat%2F0303250%2Ccond-mat%2F0303635%2Ccond-mat%2F0303449%2Ccond-mat%2F0303416%2Ccond-mat%2F0303039%2Ccond-mat%2F0303059%2Ccond-mat%2F0303064%2Ccond-mat%2F0303333%2Ccond-mat%2F0303516%2Ccond-mat%2F0303207%2Ccond-mat%2F0303550%2Ccond-mat%2F0303122%2Ccond-mat%2F0303296%2Ccond-mat%2F0303009%2Ccond-mat%2F0303452%2Ccond-mat%2F0303007%2Ccond-mat%2F0303299%2Ccond-mat%2F0303643%2Ccond-mat%2F0303418%2Ccond-mat%2F0303232%2Ccond-mat%2F0303545%2Ccond-mat%2F0303578%2Ccond-mat%2F0303569%2Ccond-mat%2F0303056%2Ccond-mat%2F0303422%2Ccond-mat%2F0303150%2Ccond-mat%2F0303395%2Ccond-mat%2F0303432%2Ccond-mat%2F0303146%2Ccond-mat%2F0303636%2Ccond-mat%2F0303650%2Ccond-mat%2F0303078%2Ccond-mat%2F0303614%2Ccond-mat%2F0303377%2Ccond-mat%2F0303394%2Ccond-mat%2F0303435%2Ccond-mat%2F0303113%2Ccond-mat%2F0303327%2Ccond-mat%2F0303622%2Ccond-mat%2F0303199%2Ccond-mat%2F0303356%2Ccond-mat%2F0303025%2Ccond-mat%2F0303544%2Ccond-mat%2F0303081%2Ccond-mat%2F0303518%2Ccond-mat%2F0303608%2Ccond-mat%2F0303590%2Ccond-mat%2F0303481%2Ccond-mat%2F0303237%2Ccond-mat%2F0303454%2Ccond-mat%2F0303263%2Ccond-mat%2F0303204%2Ccond-mat%2F0303079%2Ccond-mat%2F0303259%2Ccond-mat%2F0303513%2Ccond-mat%2F0303340%2Ccond-mat%2F0303490&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Directed geometrical worm algorithm applied to the quantum rotor model"}, "summary": "We discuss the implementation of a directed geometrical worm algorithm for\nthe study of quantum link-current models. In this algorithm Monte Carlo updates\nare made through the biased reptation of a worm through the lattice. A directed\nalgorithm is an algorithm where, during the construction of the worm, the\nprobability for erasing the immediately preceding part of the worm, when adding\na new part,is minimal. We introduce a simple numerical procedure for minimizing\nthis probability. The procedure only depends on appropriately defined local\nprobabilities and should be generally applicable. Furthermore we show how\ncorrelation functions, C(r,tau) can be straightforwardly obtained from the\nprobability of a worm to reach a site (r,tau) away from its starting point\nindependent of whether or not a directed version of the algorithm is used.\nDetailed analytical proofs of the validity of the Monte Carlo algorithms are\npresented for both the directed and un-directed geometrical worm algorithms.\nResults for auto-correlation times and Green functions are presented for the\nquantum rotor model.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0303086%2Ccond-mat%2F0303157%2Ccond-mat%2F0303131%2Ccond-mat%2F0303514%2Ccond-mat%2F0303374%2Ccond-mat%2F0303072%2Ccond-mat%2F0303645%2Ccond-mat%2F0303320%2Ccond-mat%2F0303380%2Ccond-mat%2F0303005%2Ccond-mat%2F0303193%2Ccond-mat%2F0303487%2Ccond-mat%2F0303602%2Ccond-mat%2F0303388%2Ccond-mat%2F0303261%2Ccond-mat%2F0303385%2Ccond-mat%2F0303576%2Ccond-mat%2F0303075%2Ccond-mat%2F0303573%2Ccond-mat%2F0303562%2Ccond-mat%2F0303286%2Ccond-mat%2F0303257%2Ccond-mat%2F0303058%2Ccond-mat%2F0303302%2Ccond-mat%2F0303293%2Ccond-mat%2F0303103%2Ccond-mat%2F0303359%2Ccond-mat%2F0303406%2Ccond-mat%2F0303080%2Ccond-mat%2F0303200%2Ccond-mat%2F0303549%2Ccond-mat%2F0303396%2Ccond-mat%2F0303339%2Ccond-mat%2F0303502%2Ccond-mat%2F0303610%2Ccond-mat%2F0303639%2Ccond-mat%2F0303218%2Ccond-mat%2F0303586%2Ccond-mat%2F0303201%2Ccond-mat%2F0303486%2Ccond-mat%2F0303360%2Ccond-mat%2F0303529%2Ccond-mat%2F0303071%2Ccond-mat%2F0303171%2Ccond-mat%2F0303250%2Ccond-mat%2F0303635%2Ccond-mat%2F0303449%2Ccond-mat%2F0303416%2Ccond-mat%2F0303039%2Ccond-mat%2F0303059%2Ccond-mat%2F0303064%2Ccond-mat%2F0303333%2Ccond-mat%2F0303516%2Ccond-mat%2F0303207%2Ccond-mat%2F0303550%2Ccond-mat%2F0303122%2Ccond-mat%2F0303296%2Ccond-mat%2F0303009%2Ccond-mat%2F0303452%2Ccond-mat%2F0303007%2Ccond-mat%2F0303299%2Ccond-mat%2F0303643%2Ccond-mat%2F0303418%2Ccond-mat%2F0303232%2Ccond-mat%2F0303545%2Ccond-mat%2F0303578%2Ccond-mat%2F0303569%2Ccond-mat%2F0303056%2Ccond-mat%2F0303422%2Ccond-mat%2F0303150%2Ccond-mat%2F0303395%2Ccond-mat%2F0303432%2Ccond-mat%2F0303146%2Ccond-mat%2F0303636%2Ccond-mat%2F0303650%2Ccond-mat%2F0303078%2Ccond-mat%2F0303614%2Ccond-mat%2F0303377%2Ccond-mat%2F0303394%2Ccond-mat%2F0303435%2Ccond-mat%2F0303113%2Ccond-mat%2F0303327%2Ccond-mat%2F0303622%2Ccond-mat%2F0303199%2Ccond-mat%2F0303356%2Ccond-mat%2F0303025%2Ccond-mat%2F0303544%2Ccond-mat%2F0303081%2Ccond-mat%2F0303518%2Ccond-mat%2F0303608%2Ccond-mat%2F0303590%2Ccond-mat%2F0303481%2Ccond-mat%2F0303237%2Ccond-mat%2F0303454%2Ccond-mat%2F0303263%2Ccond-mat%2F0303204%2Ccond-mat%2F0303079%2Ccond-mat%2F0303259%2Ccond-mat%2F0303513%2Ccond-mat%2F0303340%2Ccond-mat%2F0303490&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We discuss the implementation of a directed geometrical worm algorithm for\nthe study of quantum link-current models. In this algorithm Monte Carlo updates\nare made through the biased reptation of a worm through the lattice. A directed\nalgorithm is an algorithm where, during the construction of the worm, the\nprobability for erasing the immediately preceding part of the worm, when adding\na new part,is minimal. We introduce a simple numerical procedure for minimizing\nthis probability. The procedure only depends on appropriately defined local\nprobabilities and should be generally applicable. Furthermore we show how\ncorrelation functions, C(r,tau) can be straightforwardly obtained from the\nprobability of a worm to reach a site (r,tau) away from its starting point\nindependent of whether or not a directed version of the algorithm is used.\nDetailed analytical proofs of the validity of the Monte Carlo algorithms are\npresented for both the directed and un-directed geometrical worm algorithms.\nResults for auto-correlation times and Green functions are presented for the\nquantum rotor model."}, "authors": ["Fabien Alet", "Erik S. Sorensen"], "author_detail": {"name": "Erik S. Sorensen"}, "author": "Erik S. Sorensen", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1103/PhysRevE.68.026702", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0303080v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0303080v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "11 pages, 9 figures, v2 : Additional results and data calculated at\n  an incorrect chemical potential replaced. Conclusions unchanged", "arxiv_primary_category": {"term": "cond-mat.str-el", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.str-el", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.supr-con", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0303080v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0303080v2", "journal_reference": "Phys. Rev. E 68, 026702 (2003)", "doi": "10.1103/PhysRevE.68.026702", "fulltext": "Directed geometrical worm algorithm applied to the quantum rotor model\n(1)\n\nFabien Alet(1,2)\u2217 and Erik S. S\u00f8rensen(3)\n\nComputational Laboratory, ETH Z\u00fcrich, CH-8092 Z\u00fcrich, Switzerland\nTheoretische Physik, ETH Z\u00fcrich, CH-8093 Z\u00fcrich, Switzerland and\n(3)\nDepartment of Physics and Astronomy, McMaster University, Hamilton, ON, L8S 4M1 Canada\n(Dated: October 25, 2018)\n\narXiv:cond-mat/0303080v2 [cond-mat.str-el] 26 May 2003\n\n(2)\n\nWe discuss the implementation of a directed geometrical worm algorithm for the study of quantum\nlink-current models. In this algorithm Monte Carlo updates are made through the biased reptation\nof a worm through the lattice. A directed algorithm is an algorithm where, during the construction\nof the worm, the probability for erasing the immediately preceding part of the worm, when adding\na new part, is minimal. We introduce a simple numerical procedure for minimizing this probability.\nThe procedure only depends on appropriately defined local probabilities and should be generally applicable. Furthermore we show how correlation functions, C(r, \u03c4 ) can be straightforwardly obtained\nfrom the probability of a worm to reach a site (r, \u03c4 ) away from its starting point independent of\nwhether or not a directed version of the algorithm is used. Detailed analytical proofs of the validity\nof the Monte Carlo algorithms are presented for both the directed and un-directed geometrical worm\nalgorithms. Results for auto-correlation times and Green functions are presented for the quantum\nrotor model.\nPACS numbers: 02.70.Ss, O2.70.Tt, 74.20.Mn\n\nI.\n\nINTRODUCTION\n\nImproving and developing new numerical algorithms\nlies at the heart of computational physics. Amongst\nothers, Monte Carlo (MC) methods are often seen as\nthe best choice for the study of phase transitions taking place in classical or quantum models. For the study\nof spin models for example, cluster algorithms, either in\nthe classical [1, 2] or quantum [3, 4, 5] case, perform nonlocal moves in phase space, allowing for the treatment of\nsystems much larger than with traditional local update\nmethods (single spin-flip algorithms). These types of algorithms have almost completely solved the problem of\ncritical slowing down arising near phase transitions.\nThe class of systems for which cluster methods are\nknown to exist is limited, and it is therefore of great interest to search for new algorithms possessing the same efficient features for other models. In this context, we have\nproposed recently a non-local \"worm\" algorithm for the\nstudy of quantum link-current models [6]. These models\narise from a phase approximation of bosonic Hubbard\nmodels, but are also relevant in the context of quantum electrodynamics [7]. Previous MC simulations of\nthe quantum link-current (quantum rotor) model used a\nlocal algorithm suffering from critical slowing down. In\nthe new algorithm [6] updates are made by reptating a\n\"worm\" through the lattice [5, 8]. Since the movement\nof the worm only depends on a few probabilities determined locally with respect to the current position of the\n\"head\" of the worm, we call this type of algorithm a geometrical worm algorithm as opposed to other recently\ndeveloped worm algorithms based on high-temperature\n\n\u2217 Electronic\n\naddress: alet@phys.ethz.ch\n\nseries expansions [8]. The geometrical worm algorithm\ngives rise to very small autocorrelation times and by directing the algorithm these autocorrelation times can be\neven further reduced.\nIn this paper, we briefly recall the principles of the\ngeometrical worm algorithm [6]. During the construction of a worm a new part is added to the worm by\nmoving the worm through one of the \u03c3 nearest neighbor links. Usually the associated \u03c3 probabilities, p\u03c3 ,\nare chosen in an un-biased geometrical way and there\nis therefore a significant probability that the new part of\nthe worm will back-track in its own path, thereby erasing the immediately preceding part. In many cases this\nback-tracking (or bounce) probability is the dominant\nprobability among the \u03c3 probabilities and using these\nun-biased probabilities is therefore clearly rather wasteful. Here we describe an improvement of this geometric\nworm algorithm, which we call the directed worm algorithm, as a reference to recently developed directed loop\nmethods for Quantum Monte Carlo simulations of spin\nsystems [9]. This directed geometrical worm algorithm\nis identical to its un-directed counterpart except for the\nfact that the probabilities p\u03c3 are now chosen in a biased\nway, using knowledge of the immediately preceding step\nin the construction of the worm. These biased probabilities can all be tabulated at the start of the simulation and the additional computational effort stems solely\nfrom the significantly wider distribution of the directed\nworms. The directed algorithm gives rise to even better\nresults, as will be shown in the following part of this paper, where we present results on autocorrelation times for\nboth directed and \"undirected\" worm algorithms. The\nprocedure for choosing the \"biased\" probabilities leading to the directed algorithm is quite general and should\nbe applicable to other algorithms that depend on local\nprobabilities. Furthermore, we show how Green functions C(r, \u03c4 ) of the original quantum model can be mea-\n\n\f2\nsured efficiently during the construction of the worm by\ncalculating the probability that the worm reaches a given\nsite (r, \u03c4 ) away from its starting point, independently of\nwhether a directed or un-directed algorithm is used. For\nboth the derivation of the directed algorithm and the\nmeasurements of correlation functions, analytical proofs\nof the validity of the algorithms are presented.\nThe outline of the paper is as follows: in the next section, we present the quantum rotor model and introduce\nsome useful notation. Then, a brief description of the\n\"undirected\" worm algorithm is given in section III A,\nbefore proceeding to the main contents of this paper, a\ndescription of the directed geometrical worm algorithm\n(section III B). A simple procedure for numerically determining the biased probabilities for the worm moves\nis presented. In addition, we derive a proof of detailed\nbalance for the directed worm algorithm. In order to\ncompare our algorithms to related ones, we present in\nsection III C another recent approach due to Prokof'ev\nand Svistunov [8], originally based on high temperature\nseries expansion for classical statistical models, which we\ntherefore will refer to as \"classical worms\" throughout\nthis paper. In section IV, we estimate the efficiency of\nthe algorithms by calculating auto-correlation times in\nthe MC simulation, and compare to both undirected and\nclassical algorithms. We then discuss the measurements\nof correlation functions within the worm algorithm in section V and show some results at a specific point of the\nphase diagram. We conclude with a discussion of the\nfeatures of the directed algorithm.\n\nII.\n\nTHE MODEL\n\nMany magnetic systems, Josephson Junction arrays\nand several other systems can be described by a quantum\nrotor model [10]:\n\nThe sum is taken over all divergenceless current configurations \u2207 * J = 0. The degrees of freedom are \"currents\"\nJ = (J x , J y , J \u03c4 ) living on the links of the lattice. These\nlink variables J x , J y , J \u03c4 = 0, \u00b11, \u00b12, \u00b13 . . . are integers.\nK is the effective temperature, varying like t/U in the\nquantum rotor model. We refer to Ref. [11] for a precise derivation of this model and for a description of its\nphysical implications.\nAnother incentive for studying the critical behavior\nof the quantum rotor model comes from the close relation between this model and bosonic systems. Bosonic\nsystems with strong correlations are often described in\nterms of the (disordered)\nboson Hubbard model: HbH =\n\u0001\nP U 2\nP\n\u2020\n\u2212\nt\nn\u0302\n\u2212\n\u03bc\nn\u0302\n0\nr\nr\nr\nr 2\nhr,r\u2032 i (\u03a6\u0302r \u03a6\u0302r\u2032 + c.c) . The correlations are here described by U the on-site repulsion.\nThe hopping strength is given by t0 and \u03bcr the chemical potential varying uniformly in space between \u03bc \u00b1 \u2206.\nn\u0302r = \u03a6\u0302\u2020r \u03a6\u0302r is the number operator. If we set \u03a6\u0302r \u2261\n|\u03a6\u0302r |ei\u03b8\u0302r and integrate out amplitude fluctuations, it can\nbe shown that HbH is equivalent to the quantum rotor\nmodel [11]. For systems where amplitude fluctuations\ncan be neglected at the critical point, such as granular superconductors and Josephson junctions arrays, the\nquantum rotor model should therefore correctly describe\nthe underlying quantum critical phenomena.\nIn the following we only discuss the quantum rotor\nmodel in d = 2 dimensions corresponding to the d + 1\ndimensional link-current model. In general a non-zero \u03bc\nwill introduce separate dynamics for the time and space\ndirections from which a dynamical critical exponent, z\ncan be defined. If the divergence of the spatial correlation\nlength close to criticality is characterized by the exponent\n\u03bd, z is defined by requiring that the correlation length in\nthe time direction diverges with the exponent z\u03bd. For\nwhat we will be discussing here \u03bc = 0 and z = 1.\n\nIII.\n\nHqr\n\n\u00132 X\n\u0012\nX\nUX 1 \u2202\n\u2202\n=\ncos(\u03b8r \u2212\u03b8r\u2032 ).\n\u2212t\n+i\n\u03bcr\n2 r\ni \u2202\u03b8r\n\u2202\u03b8r\n\u2032\nr\n\nA.\n\nALGORITHMS\n\nThe Geometrical (Undirected) Worm algorithm\n\nhr,r i\n\n(1)\nHere, \u03b8r is the phase of the quantum rotor, t the renormalized coupling strength and \u03bcr an effective chemical\npotential. If \u03bc \u2261 0 it can be shown that this model\ndisplays the same critical behavior as the D + 1 dimensional XY -model. However, when \u03bcr 6= 0 this model is\nnot amenable to direct numerical treatment in this representation due to the resulting imaginary term. It is\ntherefore very noteworthy that an equivalent completely\nreal representation in terms of link-currents exists even\nfor non-zero \u03bcr . This link-current (Villain) representation is a classical (2+1)D equivalent Hamiltonian that is\nusually written in the following manner [11]:\nH=\n\n\u0014\n\u0015\n1 X 1 2\n\u03c4\nJ(r,\u03c4 ) \u2212 \u03bcr J(r,\u03c4\n) .\nK\n2\n(r,\u03c4 )\n\n(2)\n\nThe quantum rotor model has been extensively studied in the link-current representation using conventional\nMonte Carlo technique using local updates [11, 12, 13,\n14, 15].\nConventional Monte Carlo updates on the model (2)\nconsists of updating simultaneously four link variables\nas shown in the left part of Fig. 1 (A). To ensure ergodicity, one also has to use global moves, updating a\nwhole line of link variables (B in Fig. 1). The acceptance ratio for these global moves becomes exponentially\nsmall with the system size for large systems. Many interesting quantities such as the stiffness, necessary for the\ndetermination of the critical point, and current-current\ncorrelations, necessary for the calculation of transport\nproperties such as the resistivity and the compressibility,\nare only non-zero when these global moves are successful.\n\n\f3\n\nB\n\nC\nA\n\ny\n\n+1\n\n+1\n\n-1\n\n\u03c4\n-1\n\n-x\n\nx\n\u2212\u03c4\n\n-y\n\nFIG. 1: Monte Carlo moves in the model. To ensure the\ndivergenceless condition, only closed moves can be performed.\nOn the left part of the figures, previous Monte Carlo updates\nwith the local algorithm are depicted. On the right part is\ngiven an example of a move with the worm algorithm starting\nfrom an initial random site (black dot).\n\nAn effective Monte Carlo sampling of these global moves\nis therefore imperative and it is easy to understand that\nthe performance of the local algorithm is rather poor, especially near a phase transition: critical slowing down in\nthe Monte Carlo simulations prohibits the study of large\nsystem sizes.\nIn order to be able to correctly describe the directed geometrical worm algorithm we have to review the geometrical worm-cluster algorithm introduced in reference [6]\nin some detail. This algorithm allows for non-local moves\nas the ones depicted on the right part of Fig. 1 (C). The\nperformances of this algorithm have been reported in the\nprevious work [6]. This algorithm is closely related to\nother cluster algorithms [1, 2, 3] and especially to \"worm\"\nalgorithms [4, 5, 8], from which we have borrowed the\nname. We stress that this algorithm is different from\nthe \"classical\" worm algorithm presented in Ref. [8] in\nthe sense that it is geometrical: link variables are not\n\"flipped\" with a thermodynamic probability, instead, a\nnew part of the worm is added by selecting a direction\naccording to \u03c3 locally determined probabilities p\u03c3 . Since\nthese probabilities only depend on the local environment\nwe call them \"geometrical\" probabilities. Secondly, even\nthough the local probabilities p\u03c3 do depend\nP on the effective temperature, K, we always have \u03c3 p\u03c3 = 1 (per\ndefinition) and the only effect of the temperature is therefore to preferentially move the worm in one direction as\nopposed to another one. In some sense this is very similar to the N-fold way [16] of performing Monte Carlo\nsimulations.\nWe now describe the contents of the geometrical algorithm: we update the configurations by moving a \"worm\"\nthrough the lattice of links. The links through which\nthe worm pass are updated during its construction. The\nconfigurations generated during the construction (\"reptation\") of the worm are not valid (the divergenceless of\nJ is not fulfilled) but at the end of its path, when the\nworm forms a closed loop, this condition is verified and\n\nthe final configuration is valid.\nWe first define a convention for the orientation of the\nlattice. Around each site with coordinates (r = (x, y), \u03c4 ),\n\u03c3\nthere are six links on which the integer currents J(r,\u03c4\n) are\n\u03c3\ndefined with \u03c3 = x, y, \u03c4, \u2212x, \u2212y, \u2212\u03c4 . The change in J(r,\u03c4\n)\nthat the worm will perform during its course depends on\nwhether \u03c3 is an incoming or outgoing link: here our convention is to consider positive x, y, \u03c4 as outgoing directions and \u2212x, \u2212y, \u2212\u03c4 as incoming (see left lower part of\nFig. 1).\nIf the worm is leaving the site (r, \u03c4 ) passing through\nan outgoing link \u03c3 = x, y, \u03c4 , then\n\u03c3\n\u03c3\nJ(r,\u03c4\n) \u2192 J(r,\u03c4 ) + 1.\n\n(3)\n\nIf it is leaving through an incoming link \u03c3 = \u2212x, \u2212y, \u2212\u03c4\n, we have\n\u03c3\n\u03c3\nJ(r,\u03c4\n) \u2192 J(r,\u03c4 ) \u2212 1.\n\n(4)\n\nGraphically, the convention means that the update in\n\u03c3\nJ(r,\u03c4\n) is +1 (\u22121) if the worm goes in the same (opposite)\ndirection as the arrows denoted in the left lower part of\nfigure 1.\nThe construction (\"reptation\") of the worm can be described the following way: first, we start the worm at\na random site N1 = (r1 , \u03c41 ) of the lattice (black dot in\nfigure 1). From this site, the worm has the possibility to\ngo to one of its six neighboring sites. To choose which\ndirection to take, a weight A\u03c3 is calculated for the six\ndirections \u03c3 = \u00b1x, \u00b1y, \u00b1\u03c4 . For A\u03c3 , we use a Metropolislike weight:\nA\u03c3 = min(1, exp(\u2212(E\u03c3\u2032 \u2212 E\u03c3 )/K))\n\n(5)\n\nwhere E\u03c3 = 21 (J \u03c3 )2 \u2212 \u03bcJ \u03c3 \u03b4\u03c3,\u03c4 is the local energy carried\nby the link \u03c3 and E\u03c3\u2032 = 21 (J \u03c3 \u00b1 1)2 \u2212 \u03bc(J \u03c3 \u00b1 1)\u03b4\u03c3,\u03c4 is the\nlocal energy on the link \u03c3 if the worm passes through this\nlink. The plus or minus sign depends on the incoming\nor outcoming nature of the link (see above). Please note\nthat there are other possible choices for A\u03c3 [17].\nOnce the A\u03c3 's are calculated, one computes the probabilities p\u03c3 by normalizing the weights A\u03c3 :\np\u03c3 =\n\nA\u03c3\nN\n\n(6)\n\nP\nwhere N = \u03c3 A\u03c3 is the normalization. A random number uniformly distributed in [0, 1] is generated and a direction \u03c3 chosen according to equation (6). Once a direction is chosen, the corresponding link variable J \u03c3 is\nupdated by \u00b11 and the worm moved to the next lattice\nsite in this direction.\nFrom there, we apply the same procedure to choose\nanother site, modify the link variable, move the worm\nuntil the worm eventually reaches its starting point and\nforms a closed loop. This is then the end of this non-local\nmove.\nTo satisfy the detailed balance condition, this worm\nmove must either be accepted or rejected. To check this,\n\n\f4\none has to store the initial and final normalizations Nsi1\nand Nsf1 (calculated as in Eq. 6) of the weights at the site\ns1 = (r1 , \u03c41 ). Nsi1 is the initial normalization before the\nworm is inserted and Nsf1 the final normalization after\nthe worm reaches the initial point. The worm move is\nthen accepted with probability Nsi1 /Nsf1 . If the move is\nrejected, we have to cancel all changes of the link-currents\nmade during the construction of the worm. During a\ntypical simulation the rejection probability is usually very\nsmall.\nAs already mentioned, the link configurations generated during the worm move do not satisfy the divergenceless constraint, but it is easy to see that the final configuration does. It is important to note that the worm may\npass many times though the same link and that at each\nstep, it can bounce back (back-track) to the previous lattice site in its path.\nA proof of detailed balance for this algorithm is obtained by considering the moves of the worm and of an\nanti-worm, going exactly in the opposite direction [6].\nThis worm algorithm satisfies ergodicity since the worm\ncan make local loops and line moves as in the local algorithm, which is ergodic.\nAll in all, the geometrical un-directed worm algorithm\ncan be summarized using the following pseudo-algorithm:\n1. Choose a random initial site s1 = (r1 , \u03c41 ) in the\nspace-time lattice.\n2. For each of the directions \u03c3 = \u00b1x, \u00b1y, \u00b1\u03c4 ,\n=\ncalculate the weights A\u03c3si with A\u03c3si\nmin(1, exp(\u2212\u2206Es\u03c3i /K)), \u2206Es\u03c3i = Es\u2032\u03c3i \u2212 Es\u03c3i .\nP\n3. Calculate the normalization Nsi = \u03c3 A\u03c3si and the\nassociated probabilities p\u03c3si = A\u03c3si /Nsi .\n4. According to the probabilities, p\u03c3si , choose a direction \u03c3.\n5. Update the Js\u03c3i for the direction chosen and move\nthe worm to the new lattice site si+1 .\n6. If si 6= s1 goto 2.\n7. Calculate the normalizations N\u0304s1 and Ns1 of the\ninitial site, s1 , with and without the worm present.\nErase the worm with probability P e = 1 \u2212\nmin(1, Ns1 /N\u0304s1 ).\nB.\n\nThe Directed Geometrical Worm algorithm\n\nThe above algorithm for geometrical worms is not optimal since the worm quite often will choose to erase\nitself by returning to the previous site. While it is in\ngeneral not possible to always set this back-tracking (or\nbounce) probability to zero it is quite straightforward to\nchoose the probabilities p\u03c3si such that the bounce or backtracking probability will be eliminated in almost all cases\n\nand in general will be as small as possible. The procedure for doing this amounts to solving a simple linear\nprogramming optimizing problem. If we consider models\nwith disorder this has to be done at each site, but the\ncorrectly optimized (biased) probabilities p\u03c3si can still be\ntabulated at the start of the calculation.\nIn order to see how we can minimize the back-tracking\nprobability let us define the 6 \u00d7 6 matrix Psi of probabilities where the element Pskli of the matrix Psi is given\nby the conditional probability psi (\u03c3k |\u03c3l ) for going in the\ndirection \u03c3k at the site si if the worm is coming from the\ndirection \u03c3l . The back-tracking probabilities at the site\nsi now correspond to the diagonal elements of the matrix\nPsi . For the algorithm described in the previous section\npsi (\u03c3k |\u03c3l ) was simply chosen as A\u03c3sik /Nsi independent of\n\u03c3l . Thus all the columns of Psi were the same and Psi\nhad in general rather large diagonal elements. However,\nas we shall see below, the matrix Psi only needs to satisfy\nthe following two conditions in order to define a working\ngeometrical worm algorithm. These conditions are:\nX\n\npsi (\u03c3k |\u03c3l ) = 1 (probability)\n\n(7)\n\nk\n\nPskli\nA\u03c3sik\npsi (\u03c3k |\u03c3l )\n\u2261\n=\n(detailed balance). (8)\nPslki\npsi (\u03c3l |\u03c3k )\nA\u03c3sil\nThese conditions are not very restrictive and will in most\ncases allow us to define a matrix Psi with all the diagonal\nelements (back-tracking probabilities) equal to zero. The\nconventional geometrical worm algorithm, discussed in\nthe previous section, corresponds to Pskli = A\u03c3sik /Nsi .\nIf we define a function P\nf as the sum of the diagokk\nnal elements of Psi , f =\nk Psi , we can reformulate\nthe search for a matrix Psi with minimal diagonal elements as a standard\nP linear programming problem. Writ= 1 \u2212 l6=k Pskli we should minimize f subject\ning Pskk\ni\nP\nto the constraints l6=k Pskli \u2264 1 \u2200k. The minimum can\nbe found using standard techniques of linear programming [18] and corresponds in almost all cases to f = 0.\nThe matrix Psi depends on the value of all the 6 linkcurrents Js\u03c3i . During the construction of the worm only\n\u2212 Jsxi \u2212 Jsyi \u2212 Js\u03c4i = 1, si 6= s1\n+ Js\u2212\u03c4\n+ Js\u2212y\nsites where Js\u2212x\ni\ni\ni\n\u03c3\noccur. Since in general |Jsi | will almost never exceed a\ncertain value Jmax it is easy to construct a lookup table\nfor the matrices Psi at the beginning of the simulation\nand only calculate Psi ({Js\u03c3i }) during the simulation if for\nsome \u03c3 |Js\u03c3i | > Jmax .\nThis idea of minimizing the bounce processes is also at\nthe heart of Quantum Monte Carlo directed loop methods [9]. The previous restrictions on the matrix P and\nthe way to solve them numerically are indeed very general, and constitute a simple framework for how one can\nconstruct a directed algorithm out of a \"standard\" nonlocal loop, worm or cluster algorithm.\nWe can now define a directed geometrical worm algorithm with minimal back-tracking probability. Using a\npseudo-code notation we have:\n\n\f5\n1. Choose a random initial site s1 = (r1 , \u03c41 ) in the\nspace-time lattice.\n2. If i = 1 then: For each of the directions \u03c3 =\n\u00b1x, \u00b1y, \u00b1\u03c4 , calculate the weights A\u03c3si with A\u03c3si =\nEs\u2032\u03c3i \u2212 Es\u03c3i . Calmin(1, exp(\u2212\u2206Es\u03c3i /K)), \u2206Es\u03c3i = P\n\u03c3\nculate the normalization Nsi =\n\u03c3 Asi and the\n\u03c3\n\u03c3\nassociated probabilities psi = Asi /Nsi . Else: According to the incoming direction, \u03c3l , set p\u03c3si equal\nto the l'th column of Psi .\n3. According to the probabilities, p\u03c3si , choose a direction \u03c3.\n4. Update Js\u03c3i for the direction chosen and move the\nworm to the new lattice site si+1 .\n5. If si 6= s1 goto 2.\n6. Calculate the normalizations N\u0304s1 , of the site s1\nwith the worm present, and Ns1 , without the\nworm. Erase the worm with probability P e =\n1 \u2212 min(1, Ns1 /N\u0304s1 ).\nNow we turn to the proof of detailed balance for the\ndirected algorithm. Let us consider the case where the\nworm, w, visits the sites {s1 . . . sN } where s1 is the initial\nsite. The worm then goes through the corresponding link\nvariables {l1 . . . lN }, with li connecting si and si+1 . Note\nthat sN is the last site visited before the worm reaches s1 .\nHence, sN and s1 are connected by the link lN . The total\nprobability for constructing the worm w is then given by:\nPw = Ps1 (1 \u2212\n\nN\nA\u03c3 Y\nPwe ) s1\nps (si+1 |si\u22121 ).\nNs1 i=2 i\n\n2\n\u0100\u03c3\u0304s1 Y\nps (si\u22121 |si+1 ).\nN\u0304s\u03041 i=N i\n\n(10)\n\n(11)\n\nand since Ps1 = Ps\u03041 , we find:\nPw\n1 \u2212 Pwe N\u0304s\u03041\n=\nexp(\u2212\u2206ETot /K).\nPw\u0304\n1 \u2212 Pw\u0304e Ns1\n\n(13)\n\nFor a worm of length N there are N starting sites that\nwill yield the same final configuration. The above proof\nshows that for each of the starting sites there exists\nan anti-worm, w\u0304, such that Pw = exp(\u2212\u2206ETot /K)Pw\u0304 .\nHence, if we by \u03bc denote the configuration without the\nworm and \u03bd the configuration with the worm and furthermore let Pw (si ) denote the probability of building\nthe worm w starting from site si , we see that:\nP (\u03bc \u2192 \u03bd)\nP (\u03bd \u2192 \u03bc)\n\nPN\n\nPw (si )\n\nPN\n\nPw\u0304 (si )\n\n= PiN\ni\n\ni\n= PN\n\nPw\u0304 (si )\n\nexp(\u2212\u2206ETot /K)\nPw\u0304 (si )\n= exp(\u2212\u2206ETot /K).\n(14)\ni\n\nErgodicity is proved the same way as for the undirected\nalgorithm as the worm can perform local loops and wind\naround the lattice in any direction, as in the conventional\nalgorithm.\n\nThe Classical Worm algorithm\n\n(9)\n\nHere, the index \u03c3 denotes the direction needed to go from\ns1 to sN , Note that, in this case the sites are visited in\nthe opposite order, s1 , sN , . . . , s2 . From Eq. (8) we have\nthat psi (si+1 |si\u22121 )/psi (si\u22121 |si+1 ) = A\u03c3sik /\u0100\u03c3sil . Since,\nA\u03c3si /\u0100\u03c3si = exp(\u2212\u2206Es\u03c3i /K), i = 1 . . . N,\n\nPw\n= exp(\u2212\u2206ETot /K).\nPw\u0304\n\nC.\n\nThe index \u03c3 denotes the direction needed to go from s1\nto s2 , Ps1 is the probability for choosing site s1 as the\nstarting point and Pwe is the probability for erasing the\nworm w after construction. psi (si+1 |si\u22121 ) is the conditional probability for continuing to site si+1 , at site si ,\ngiven that the worm is coming from si\u22121 . If the worm w\nhas been accepted we have to consider the probability for\nreversing the move. That is, we consider the probability\nfor constructing an anti-worm w\u0304 annihilating the worm\nw. We have:\nPw\u0304 = Ps\u03041 (1 \u2212 Pw\u0304e )\n\nwhere \u2206ETot is the total energy difference between a configuration with and without the worm w present. With\nour definition of P e we see that (1\u2212P e (w))/(1\u2212P e (w\u0304)) =\nNs1 /N\u0304s1 and it follows that:\n\nProkof'ev and Svistunov [8] have proposed a very elegant way of performing Monte Carlo simulations on the\nhigh temperature expansion of classical statistical mechanical models using worm algorithms. In order to distinguish between the algorithms we call this algorithm\nthe classical worm algorithm. In a recent study [19] these\nauthors have performed simulations on the quantum rotor model in the link-current representation, Eq. (2). Due\nto the divergenceless constraint, the classical worm algorithm is in this case quite close to the geometrical worm\nalgorithm proposed previously in Ref. 6 and not directly\nrelated to the high temperature expansion of this model.\nRecasting their algorithm in the same framework used\nabove we outline our understanding of their algorithm\nbelow for comparison:\n1. Choose a random initial site s1 = (r1 , \u03c41 ) in the\nspace-time lattice.\n2. For each of the directions \u03c3 = \u00b1x, \u00b1y, \u00b1\u03c4 ,\ncalculate the probabilities A\u03c3si with A\u03c3si =\nmin(1, exp(\u2212\u2206Es\u03c3i /K)), \u2206Es\u03c3i = Es\u2032\u03c3i \u2212 Es\u03c3i .\n3. With uniform probability choose a direction \u03c3.\n\n(12)\n\n4. With probability A\u03c3si accept to go in the direction\n\u03c3, and with probability 1 \u2212 A\u03c3si go to 3.\n\n\f6\n1\n\n5. Update Js\u03c3i for the direction chosen and move the\nworm to the new lattice site si+1 .\n\n0.8\n\n6. If si 6= s1 go to 2.\n\nOne advantage of this algorithm is its simplicity and the\nfact that a constructed worm is always accepted, on the\nother hand this algorithm is not directed and steps 3-4\nabove are quite wasteful since in many cases the worm\nis not moved. This is avoided in the geometrical worm\nalgorithm at the price of occasionally having to reject\na complete worm. The geometrical worm algorithm, as\ndescribed in the preceding sections, should be straightforwardly applicable to the high temperature expansion\nas it was done in Ref. [8] using the classical worm algorithm. We expect that this would enhance the efficiency\nof the Monte Carlo sampling.\nIV.\n\n0.6\nC\u03c1(t)\n\n7. If si = s1 go to 1 with probability p0 and to 3 with\nprobability 1\u2212p0 (p0 \u2208 (0, 1) and usually p0 = 1/2).\nWe use p0 = 1/2 in the following.\n\nDirected worms\nUndirected worms\nClassical worms\n\n0.4\n\n0.2\n\n0\n0\n\n250\n\n500\nt\n\n750\n\n1000\n\nFIG. 2: Auto-correlation function of stiffness versus Monte\nCarlo time (defined by one worm construction - see text -) for\nL = 56 at K = 0.333 for directed (circle), undirected (dotted\nline) and classical (solid line) algorithms.\n\nPERFORMANCE OF THE ALGORITHMS\n\nHere we present results on autocorrelation times obtained with both directed and undirected algorithms. For\nthe sake of brevity, we restrict ourselves to the case \u03bc = 0,\nwhere the critical point is known with high precision,\nand where results on autocorrelations for the undirected\nworm algorithm have already been published [6]. All the\nresults presented in this section correspond to runs on\ncubic lattices of 107 -108 Monte Carlo worms for a value\nof K = 0.333, extremely close to the critical point (estimated as Kc = 0.33305(5) in Ref. [6]). In principle, simulations should be performed on lattices of size L\u00d7L\u00d7L\u03c4 ,\nbut here since the dynamical exponent z = 1 at \u03bc = 0,\nwe can set L\u03c4 = L. We focus here on calculations of the\nenergy E = hHi and the stiffness \u03c1 defined as\n1 X x 2\n\u03c1 = 3 h(\nJr,\u03c4 ) i\n(15)\nL\nr,\u03c4\nwhere L is the linear size of the lattice.\nFor the simulations with directed worms, we restrict\nourselves to |J| \u2264 3 for the tabulation of probabilities.\nProbabilities involving higher values of |J| were calculated during the construction of the worm. Such configurations were found to be exceedingly rare.\nFor the case at hand, only 1% of the \"scattering\" matrices Psi contained diagonal elements corresponding to\na non-zero back-tracking probability. Moreover, these\nback-tracking (bounce) processes were found to occur for\nvery unlikely configurations. The acceptance rate, 1\u2212P e ,\nis very high for both algorithms at Kc (around 98% for\nundirected worms and 97% for directed worms for all\nlattice sizes). For the classical worms, all worms are accepted due to the nature of the algorithm. However, we\nfound that many proposed attempts at changing one link\nwere refused (more than 60% in our simulations).\n\nIn figure 2, we present the autocorrelation function of\nstiffness for a lattice size L = 56, for directed, undirected\nand classical worms. The autocorrelation function CO (t)\nof an observable O is defined in the standard way:\nCO (t) =\n\nhO(t)O(0)i \u2212 hOi2\nhO2 i \u2212 hOi2\n\n(16)\n\nwhere h. . .i denotes statistical average and t is the MC\ntime, measured in the number of constructed worms (accepted or not). We clearly see in figure 2 that the directed worm algorithm is more efficient at decorrelating\nthe data than undirected and classical worms, the latter\nhaving the longest autocorrelation times.\nNow we define the autocorrelation time \u03c4O of an observable O. In Ref. [6], \u03c4O was defined as the greater\ntime of a double-exponential fit of the autocorrelation\nfunction. Here we use a much simpler definition, independent of any fitting procedure: \u03c4O is defined as the\ntime where the normalized autocorrelation function decrease below a threshold tO . We can use different thresholds for different observables O. Since for small lattices\nand especially for directed worms, autocorrelation times\nare small, and since CO (t) is known only for discrete values of t, \u03c4O is determined by a simple linear interpolation\nbetween the two times surrounding the threshold. It is\nimportant to note that the values of the autocorrelation\ntime depends on the threshold tO , but the dependence\non lattice size of these autocorrelation times should not\nchange as long as tO is small enough. Error bars on tO\nhave been estimated by slightly changing the threshold,\nby an amount in between 2% and 5% in this work.\nUsing the above mentioned determination of autocorrelation times, we extract autocorrelation times of the\nstiffness \u03c1 and the energy E for directed, undirected and\nclassical worms. The threshold was set the same for\n\n\f7\n1000\n\n0.1\n\nDirected worms\nUndirected worms\nClassical worms\n\n800\n\n0.08\n\n0.06\n\n\u03c4\u03c1\n\n<w>/3L\n\n3\n\n600\n\nDirected worms\nUndirected worms\nClassical worms\n\n400\n\n0.04\n\n200\n\n0.02\n\n0\n\n0\n0\n\n20\n\n40\nL\n\n60\n\n80\n\nFIG. 3: Auto-correlation times of the stiffness, \u03c1, for directed, undirected and classical algorithms versus lattice size\nL. Shown are the raw auto-correlations times, before rescaling\nto take into account the computational effort expended.\n3000\n\nDirected worms\nUndirected worms\nClassical worms\n\n\u03c4E\n\n2000\n\n1000\n\n0\n\n0\n\n20\n\n40\nL\n\n60\n\n80\n\nFIG. 4: Auto-correlation times of energy E for the three\nalgorithms versus lattice size L. Shown are the raw autocorrelations times, before rescaling to take into account the\ncorresponding computational effort expended.\n\nall algorithms when comparing the same quantity: we\nused through this work t\u03c1 = 0.02 for the stiffness and\ntE = 0.05 for the energy. Scaling of these times with the\nlattice size is shown in figure 3 for stiffness and in figure 4\nfor energy. It can be seen that whereas autocorrelation\ntimes grow approximatively linearly with lattice size for\nall algorithms, the slope is significantly smaller for the\ndirected worm algorithm.\nIt is clear from these results that the directed algorithm\nsignificantly reduces the autocorrelation times. However,\nthe average size of the directed worms could be larger,\nand hence on average consume more computational time.\nFor all algorithms the computational effort is linearly pro-\n\n0\n\n20\n\n40\nL\n\n60\n\n80\n\nFIG. 5: Mean size hwi divided by 3L3 versus lattice size L for\ndirected, undirected and classical worms.\n\nportional to the length of the worm. To make an honest\ncomparison, we therefore have to multiply the autocorrelation times by the number of attempted changes per\nlink, which we define as hwi/(3L3 ), where hwi is the mean\nworm size (the mean number of links the worm has attempted to visit), L the lattice size preceded by an irrelevant factor indicating that there are 3 links per site. For\nthe classical worms, the mean worm size hwi is defined\nas the total number of proposed attempts (step 4 in the\npseudo-code presentation in section III C). In order to\nmake an un-biased comparison of the three algorithms it\nis here necessary to include the updates refused during\nthe construction of the classical worms in the definition\nof hwi.\nAs mentioned, the computational effort (the CPU\ntime) is linear in hwi for all algorithms. An equivalent\nrescaling was used in Ref. [6] in order to make a fair\ncomparison with the local algorithm. In Fig. 5 is shown\nthe mean worm size hwi (divided by 3L3 ) for the three\nalgorithms versus lattice size, corresponding to the average fraction of the total number of links occupied by the\nworm. In both cases, we see that this fraction decreases\nwith L. We also note that the classical worms are longer\nthan in the other proposed algorithms, which will result\nin larger autocorrelation times. Directed and undirected\nworms are almost of the same size, with very slightly\nlarger directed worms. The corresponding effect on the\nvalue of rescaled effort (presented in the next paragraph)\nwill be small when comparing autocorrelation times for\nthose algorithms, however we wish to keep it present for\na more fair analysis.\nHaving discussed the behavior of hwi we now take\ninto account the computational effort used to construct\nthe worm by rescaling the auto-correlation times by\nhwi/(3L3 ). We show in figure 6 the rescaled autocorrelation times for the three algorithms. We find that\nthe auto-correlation times per link stay reasonably small\n\n\f8\n10000\n\nDirected Algorithm\nUndirected Algorithm\n\n3\n\nP(w)\n\n\u03c4.<w>/(3L )\n\n10\n\n\u03c4\u03c1\n\u03c4\u03c1\n\u03c4\u03c1\n\u03c4E\n\u03c4E\n\u03c4E\n\n1\n\nDirected worms\nUndirected worms\nClassical worms\nDirected worms\nUndirected worms\nClassical worms\n\n100\n\n1\n\n0.001\n\n0.01\n3\n\n0.1\n\nw/(3L )\n10\n\n100\nL\n\nFIG. 6: Auto-correlation times of stiffness \u03c1 and energy E for\nthe three presented algorithms versus lattice size L. These\nauto-correlations times are rescaled auto-correlation times\nwhere the computational effort is taken into account.\n\nfor all algorithms, but the directed algorithm clearly gives\nbetter results, with auto-correlation times smaller by a\nfactor around 4 (1.5 \u2212 1.7) for the stiffness (energy) with\nrespect to the undirected algorithm, and a factor around\n10 (4) with respect to the classical worm for the largest\nsizes. The fact that both algorithms are more efficient at\ndecorrelating the stiffness than the energy seems to indicate that the worms couple more effectively to \"winding\nmodes\", from which the stiffness is uniquely determined,\nthan to simple local modes which determine the energy.\nWith the same argument, we can see that directed worms\nare more efficient at updating winding modes than undirected or classical worms.\nThe actual distribution of the size of the worms generated, P (w) is also of interest. In Fig. 7 we show results for the probability density, P (w) for generating a\nworm occupying a fraction of w/3L3 of the lattice, as a\nfunction of w/3L3 for the directed and un-directed algorithms. The classical worm algorithm has a distribution\nidentical to the one shown for the un-directed algorithm.\nClearly, the directed worms have a somewhat broader\ndistribution but for both algorithms the distribution follows a power-law form P (w) \u223c w\u2212\u03b1 with \u03b1 \u223c 1.37. The\npower-law behavior is to be expected since the simulations were performed at the critical point. Away from\nthe critical point we have verified that the initial powerlaw form crosses over to an exponential behavior at large\narguments.\nTo summarize, we find that in all cases, rescaled autocorrelation times stay almost constant with the lattice\nsize, but could also be fitted with a very small powerlaw or logarithm, showing an almost complete elimination of critical slowing down. All in all, the main result\nof this section is that directed worms produce less correlated data (smaller autocorrelation times), even if the\n\nFIG. 7: The probability density, P (w) for generating a worm\noccupying a fraction of w/3L3 of the lattice, as a function of\nw/3L3 for the directed and un-directed algorithms. Shown\nare results for a lattice of linear size L = 56 at K = Kc . The\nsolid lines indicate power-law fits to the data.\n\nscaling is good for all the three (directed, undirected and\nclassical) algorithms. We also note that the geometrical\nworm algorithms perform better than the classical worm\nalgorithm.\nThe fact that both directed and undirected algorithms\nhave almost the same scaling of the rescaled autocorrelation time with L, seems also to be observed for the directed loop Quantum Monte Carlo cluster algorithms [9].\n\nV.\nA.\n\nTHE CORRELATION FUNCTIONS\n\nMeasurements of correlation functions with\nworm algorithms\n\nFor the quantum rotor model, the correlation functions\nof interest have the following form [11]:\nC(r, r\u2032 , \u03c4, \u03c4 \u2032 ) = hei(\u03b8\u0302r (\u03c4 )\u2212\u03b8\u0302r\u2032 (\u03c4\n\n\u2032\n\n))\n\ni,\n\n(17)\n\nwhere the \u03b8\u0302's are operators for the phase of the bosons,\nand ei\u03b8\u0302r (\u03c4 ) = e\u03c4 H ei\u03b8\u0302r e\u2212\u03c4 H . Due to translational invariance, C(r, r\u2032 , \u03c4, \u03c4 \u2032 ) = C(r \u2212 r\u2032 , \u03c4 \u2212 \u03c4 \u2032 ). Physically this\ncorresponds to creating a particle at (r, \u03c4 ) and destroying\nit at (r\u2032 , \u03c4 \u2032 ). When this correlation function is mapped\nonto the link-current representation the creation and destruction of the particle is interpreted as a particle current going from (r, \u03c4 ) to (r\u2032 , \u03c4 \u2032 ). As is evident from the\ndefinition of the correlation function in Eq. (17) the value\nof the correlation function can not depend on the specific\npath taken from (r, \u03c4 ) to (r\u2032 , \u03c4 \u2032 ) as long as we take into\naccount the fact that going in the x, y, \u03c4 increases the\nlocal current, whereas going in the \u2212x, \u2212y, \u2212\u03c4 direction\ndecreases the local current. In the link current representation this correlation function can be written [11] in the\n\n\f9\n\n\u03c4\n\nfollowing way:\nC(r, \u03c4 ) = h\n\n1\n\nY\n\n1\n\n1\n\n(ri ,\u03c4i ) \u2208path\n\n\u0012\n\u001a\n\u0011 1 \u0013\u001b\n\u0010\n1\n\u03bd\n\u2212\n\u03b4\n\u03bc\u0303\nsign(\u03c3i ) J(r\ni,\nexp \u2212\n\u03c3i ,\u00b1\u03c4 ri +\ni ,\u03c4i )\nK\n2\n(18)\nwhere \"path\" is any path on the space-lattice connecting two points a distance (r, \u03c4 ) apart and \u03c3i is the direction needed to go from (ri , \u03c4i ) to (ri+1 , \u03c4i+1 ), \u03c3i =\n\u00b1x, \u00b1y, \u00b1\u03c4 . When going in the direction \u03c3i = x, y, \u03c4 we\npropagate a particle and the correlation function corresponds to incrementing the corresponding link-variable\nby one. When going in the direction \u03c3i = \u2212x, \u2212y, \u2212\u03c4\nwe propagate a hole in the x, y, z direction and the correlation function corresponds to decrementing the corresponding link-variable by one. This is indicated in\nthe expression Eq. (18) by sign(\u03c3i ). Furthermore, we\nonly get a contribution from \u03bcri whenever we go in the\n\u03c4 \u2212direction and we take this into account by \u03b4\u03c3i ,\u00b1\u03c4 . If\n\u2212x\nx\nwe define J(x,y,\u03c4\n) = \u2212J(x\u22121,y,\u03c4 ) with analogous definitions for the other directions we see that by incrementing\nand decrementing\nthe link-current variables in the above\nP \u03c3\n= 0 at all the sites between (ri , \u03c4i ) and\nmanor \u03c3 J(r,\u03c4\n(ri+1 , \u03c4i+1 ). The current is divergenceless at all the intermediary sites. The sites (rP\ni , \u03c4i ) and (ri+1 , \u03c4i+1 ) will have\n\u03c3\n= 1 corresponding to\nnon-zero divergence with \u03c3 J(r,\u03c4\na site where\na\nparticle\nis\ncreated\n(or\na hole destroyed). A\nP \u03c3\n= \u22121 is a site where a hole is created\nsite with \u03c3 J(r,\u03c4\n(or a particle destroyed). In Fig. 8 we show two possible paths Pa and Pb for the evaluation of the correlation\nfunction C(r, \u03c4 ). As usual, C(r, \u03c4 ) = C(r + L, \u03c4 + L\u03c4 )\nbut C(r, \u03c4 ) is in general not equal to C(r, \u2212\u03c4 ).\nPrevious work [11, 14] have attempted to calculate the\ncorrelation function by evaluating the thermal expectation value in Eq. (18) along a straight path from (r, \u03c4 ) to\n(r\u2032 , \u03c4 \u2032 ). Although formally correct, this method fails for\nlarge arguments of the correlation function due to the\nfact that for a given configuration of the link-variables\nroughly only one specific path between (r, \u03c4 ) and (r\u2032 , \u03c4 \u2032 )\nwill yield a contribution of order 1.\nThe geometrical worm algorithm allows for a much\nmore efficient way of evaluating the correlation functions.\nIn essence, before the worm returns to the starting site,\nthe path of the worm corresponds precisely to the creation of a particle at site s1 and the destruction at the\ncurrent site si with a current going between the two sites.\nThis is precisely the Greens function that we want to calculate. More precisely we extend Eq. (18) to include a\nsummation over all possible paths:\nY\n1 X\nC(r, \u03c4 ) =\nh\nNP\nP (ri ,\u03c4i ) \u2208P\n\u0012\n\u001a\n\u0011 1 \u0013\u001b\n\u0010\n1\n\u03bd\nsign(\u03c3i ) J(ri ,\u03c4i ) \u2212 \u03b4\u03c3i ,\u00b1\u03c4 \u03bc\u0303ri +\ni.\nexp \u2212\nK\n2\n(19)\n\n1\n\n1\n1\n\n\u22121\n\n1\n\n( r,\u03c4 )\n\nPa 1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n\u22121\n1\n\n1\n\n1\n\n1\n\n(0,0)\n\n1\n\n1\n\n1\n\nPb\nx\n\nFIG. 8: Two possible paths, Pa and Pb , for the evaluation\nof C(r, \u03c4 ). When the path is going in the x, y, \u03c4 direction a\nparticle is propagated in the forward direction corresponding\nto an increment in the current. When the path is going in\n\u2212x, \u2212y, \u2212\u03c4 direction we propagate a hole in the forward direction corresponding to a decrement in the current. The solid\ncircles correspond to sites where a single particle is created or\ndestroyed.\n\nHere P is a path for the correlation function and NP is\nthe number of paths included in the sum. Since the geometrical worm algorithm generates paths between (r, \u03c4 )\nand (rn , \u03c4n ) with the correct exponential factor (except\nfor a multiplicative constant) it is now easy to calculate\nthe correlation functions.\nSuppose that we, by using either the directed or undirected worm algorithm, have reached the equilibrium\nconfiguration \u03bc. The probability for, during the construction of a worm starting at site s1 = (r1 , \u03c41 ), creating a\ncurrent j that reaches sn = (rn , \u03c4n ) 6= s1 is given by:\nP (j; \u03bc \u2192 \u03bc\u2032 ) = P (s1 )\n\nn\u22121\nY\ni=1\n\nA\u03c3si\nNsi\n\n(20)\n\nfor the undirected algorithm. For the directed algorithm\nwe have:\nP (j; \u03bc \u2192 \u03bc\u2032 ) = P (s1 )\n\nn\u22121\nA\u03c3s1 Y\nps (si+1 |si\u22121 ).\nNs1 i=2 i\n\n(21)\n\nIf we call the resulting state \u03bc\u2032 we can calculate the probability for, starting from \u03bc\u2032 , creating an anti-current, j\u0304,\ngoing from sn to s1 . We find for the undirected algorithm:\nP (j\u0304; \u03bc\u2032 \u2192 \u03bc) = P (sn )\n\n2\nY\n\u0100\u03c3si\n,\nNsi\ni=n\n\n(22)\n\n\f10\n1\n\nand for the directed algorithm:\n\nSimulation\n\u22121.035\n\u22121.035\n0.296(x\n+(64\u2212x)\n)\n\n(23)\n\nIn both cases we see that\nY\nN\u0304sn\nP (j; \u03bc \u2192 \u03bc\u2032 )\n=\n\u2032\nP (j\u0304; \u03bc \u2192 \u03bc)\nNs1\n(ri ,\u03c4i ) \u2208P\n\u001a\n\u0012\n\u0010\n\u0011 1 \u0013\u001b\n1\n\u03bd\nexp \u2212\nsign(\u03c3i ) J(ri ,\u03c4i ) \u2212 \u03b4\u03c3i ,\u00b1\u03c4 \u03bc\u0303ri +\n.\nK\n2\n(24)\nHence, we see that for both algorithms the intermediate states generated during the construction of the worm\nfollows precisely the distribution needed apart from the\nfactor N\u0304sn /Ns1 . It follows that whenever a worm reaches\na point a distance (r, \u03c4 ) away from the initial point it contributes a factor of Ns1 /N\u0304sn to the correlation function of\nargument (r, \u03c4 ). Note that it follows from the above proof\nthat all worms, even the ones that are finally rejected,\nhave to be included in the calculation of the Greens functions. Per definition C(0, 0, 0) \u2261 C(L, L, L\u03c4 ) \u2261 1.\nB.\n\nResults\n\nThe above procedure is straight forward to implement.\nSuppose we want to calculate the Greens functions for a\nd+ 1 dimensional system with d = 2. Since the two space\ndirections are equivalent by symmetry it is only necessary\nto calculate C(x, \u03c4 ). This is easily done by keeping track\nof the position of the worm during construction. If the\nrelative position of the worm with respect to its starting\npoint s1 , is denoted by (xr , yr , \u03c4r ), when the worm has\nreached site sn , we add Ns1 /N\u0304sn to C(xr , yr , \u03c4r ). This\ncan be done with very little computational effort and\nsince an enormous amount of worms are generated during\nthe simulation extremely good statistics can be obtained\nfor C(xr , yr , \u03c4r ) by averaging over the worms (which cannot be achieved with the local algorithm). As mentioned,\nin order not to bias the calculation, even worms that are\neventually rejected should be included for a correct calculation of the Greens functions. In Figure 9 we show\nresults for the Greens function as a function of x for a\nsystem of size L3 , L = 64. For this simulation the directed algorithm was used with a total number of worms\nequal to 1.5 \u00d7 108 . It is easy to obtain extremely small\nerror bars on the Greens functions even for very large\nsystem sizes. For the results shown in Fig 9 \u03bc = 0 and\nby symmetry C(\u03c4 ) is identical to C(x). From scaling\nrelations [21] C(r) is expected to decay as r\u2212(d\u22122+z+\u03b7)\nwhere z is the dynamical critical exponent. With \u03bc = 0,\nz = 1 we find C(r) \u223c r\u2212(1+\u03b7) . Fitting to this form we\nfind \u03b7 = 0.035(5). The obtained critical exponents are\nin excellent agreement with previous work [11] and more\nrecent high-precision estimates for the critical exponents\nof the 3d XY model [20].\n\nC(x)\n\n2\n\u0100\u03c3 Y\nP (j\u0304; \u03bc\u2032 \u2192 \u03bc) = P (sN ) sn\nps (si\u22121 |si+1 ).\nN\u0304sn i=n\u22121 i\n\n0.1\n\n0.01\n\n1\n\n10\n\n100\n\nx\n\nFIG. 9: The Greens function C(x) for a system of size L3 , L =\n64 at K = Kc = 0.33305, \u03bc = 0, as a function of x. The solid\nline indicates a power-law fit of the form 0.296(x\u22121.035 +(64\u2212\nx)\u22121.035 ).\n\nIt would be of much interest to calculate C(r, \u03c4 ) for\n\u03bc 6= 0 using this method. Such calculations are currently\nin progress [22].\n\nVI.\n\nSUMMARY AND DISCUSSION\n\nWe have proposed a directed worm algorithm for the\nquantum rotor model. This algorithm is an improvement of the \"undirected\" algorithm presented in [6]. It\nhas been shown that by adjusting the degrees of freedom\nleft in the detailed balance condition, one can construct a\nmore efficient algorithm by minimizing the back-tracking\n(bounce) probability for the worm to erase itself. The\nminimal probabilities can be found by solving a linear\nprogramming problem subject to a few well-defined constraints. A proof of detailed balance for the directed case\nhas also been presented. The directed and un-directed algorithms are identical except for the fact that appropriately defined local probabilities p\u03c3 for moving the worm\nthrough the lattice are chosen in an optimal manner\nfor the directed algorithm. Hence, only a very limited\namount of additional programming has to be done to implement the directed algorithm.\nThese central ideas for this directed algorithm can be\nstraightforwardly applied to directed QMC loop algorithms [9] and one can avoid an analytical calculation\nfor each new model where one wants to implement a directed algorithm. More generally speaking, we believe\nthat the framework presented here could be useful for\nconstructing new algorithms for other models, for example classical spin models [23].\nWe have shown the superiority of the directed algorithm as compared to the undirected one and to the approach (\"classical worms\") proposed in [8] by calculating\nautocorrelation times of different observables near a critical point. Whereas the computational gain is not as\n\n\f11\ndrastic as when passing from a local update algorithm\nto a worm algorithm [6, 17], we showed that one gains a\nfactor ranging from 1.5 to 10 (depending on the quantity\nand on the comparison) for the simulations considered\nhere. We did not try to estimate autocorrelation exponent z for the algorithms, because in all cases, it is small\n(as can be seen in figure 6) and it would be hard to determine with high precision. Looking at the data, it is likely\nthat values of z for all algorithms are the same or quite\nclose. A logarithmic dependence of \u03c4 on L, indicating\nz = 0, cannot also be excluded.\nIn this paper, we have also derived an efficient way\nof measuring correlation functions during the worm constructions. This feature is similar to other worm algorithms [4, 5], but here we show, including analytical arguments, that it also works for directed worms. The situation for directed QMC loop algorithms [9] is less certain,\n\neven if some results were recently presented in Ref.[24].\nThe directed worm algorithm could be specially useful\nto study the transition for a non-commensurate value of\nthe chemical potential in the pure quantum rotor model\nor for the disordered case, where very strong finite size\neffects have been identified [17, 19, 22].\n\n[1] R. H. Swendsen and J. S. Wang, Phys. Rev. Lett. 58, 86\n(1987).\n[2] U. Wolff, Phys. Rev. Lett. 62, 361 (1989).\n[3] H. G. Evertz, G. Lana and M. Marcu, Phys. Rev. Lett.\n70, 875 (1993). H. G. Evertz, Adv. Phys. 52, 1 (2003).\n[4] A. W. Sandvik, Phys. Rev. B 59, R14157 (1999); A.\nDorneich and M. Troyer, Phys. Rev. E 64, 066701 (2001).\n[5] N. V. Prokof'ev, B. V. Svistunov and I. S. Tupitsyn,\nPhys. Lett. A 238, 253 (1998).\n[6] F. Alet and E. S. S\u00f8rensen, Phys. Rev. E 67, 015701(R)\n(2003).\n[7] T. Banks, R. Myerson, J. Kogut, Nucl. Phys. B129, 493,\n(1977); P. R. Thomas, M. Stone, Nucl. Phys. B114,\n513 (1978); M. E. Peskin, Ann. Phys. 113, 122 (1978);\nR. Savit, Rev. Mod. Phys. 52, 453 (1980).\n[8] N. Prokof'ev and B. Svistunov, Phys. Rev. Lett. 87,\n160601 (2001).\n[9] O. F. Sylju\u00e5sen and A. W. Sandvik, Phys. Rev. E 66,\n046701 (2002); K. Harada and N. Kawashima, ibid 66\n056705 (2002); O. F. Sylju\u00e5sen, Phys. Rev. E 67, 046701\n(2003); J. Smakov, K. Harada and N. Kawashima, e-print\ncond-mat/0301416; F. Alet, S. Wessel and M. Troyer,\n(unpublished).\n[10] S. Sachdev Quantum Phase Transitions, Cambridge University Press, Cambridge 1999.\n[11] E. S. S\u00f8rensen et al., Phys. Rev. Lett. 69, 828 (1992); M.\nWallin et al., Phys. Rev. B 49, 12115 (1994).\n\n[12] M.-C. Cha et al., Phys. Rev. B 44, 6883 (1991).\n[13] A. vanOtterlo and K.-H. Wagenblast, Phys. Rev. Lett.\n72, 3598 (1994); A. vanOtterlo et al., Phys. Rev. B 52,\n16176 (1995).\n[14] J. Kisker and H. Rieger, Phys. Rev. B 55, R11981 (1997),\nPhysica A 246, 348 (1997);\n[15] S. Y. Park et al., Phys. Rev. B 59, 8420 (1999); J.W. Lee, M.-C. Cha and D. Kim, Phys. Rev. Lett. 87,\n247006 (2001).\n[16] A. B. Bortz, M. H. Kalos and J. L. Lebowitz,\nJ. Comp. Physics, 17, 10 (1975).\n[17] F. Alet, PhD thesis, Universit\u00e9 Paul Sabatier, Toulouse\n(2002).\n[18] Numerical Recipes in C++, W. Press et al., Cambridge\nUniversity Press (2002).\n[19] N. V. Prokof'ev and B. V. Svistunov, e-print\ncond-mat/0301205.\n[20] See I. Dukovski, J. Machta and L. V. Chayes,\nPhys. Rev. E, 65, 026702 (2002) and references there\nin.\n[21] M. P. A. Fisher, P. B. Weichman, G. Grinstein, and\nD. S. Fisher, Phys. Rev. B 40, 546 (1989).\n[22] F. Alet and E. S. S\u00f8rensen, (unpublished).\n[23] P. Hitchcock, F. Alet and E. S\u00f8rensen, (unpublished).\n[24] A. Cuccoli et al., Phys. Rev. B 67, 104414 (2003).\n\nAcknowledgments\n\nWe thank M. Troyer for useful discussions and\nJ. Asikainen for a careful reading of the manuscript.\nThis work is supported by the NSERC of Canada, the\nSHARCNET computational initiative and by the Swiss\nNational Science Foundation.\n\n\f"}