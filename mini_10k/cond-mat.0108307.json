{"id": "http://arxiv.org/abs/cond-mat/0108307v3", "guidislink": true, "updated": "2002-10-01T10:28:11Z", "updated_parsed": [2002, 10, 1, 10, 28, 11, 1, 274, 0], "published": "2001-08-20T15:41:39Z", "published_parsed": [2001, 8, 20, 15, 41, 39, 0, 232, 0], "title": "Direct sampling of complex landscapes at low temperatures: the\n  three-dimensional +/-J Ising spin glass", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0108100%2Ccond-mat%2F0108259%2Ccond-mat%2F0108052%2Ccond-mat%2F0108484%2Ccond-mat%2F0108360%2Ccond-mat%2F0108262%2Ccond-mat%2F0108459%2Ccond-mat%2F0108308%2Ccond-mat%2F0108391%2Ccond-mat%2F0108533%2Ccond-mat%2F0108408%2Ccond-mat%2F0108231%2Ccond-mat%2F0108444%2Ccond-mat%2F0108010%2Ccond-mat%2F0108466%2Ccond-mat%2F0108506%2Ccond-mat%2F0108230%2Ccond-mat%2F0108377%2Ccond-mat%2F0108475%2Ccond-mat%2F0108488%2Ccond-mat%2F0108268%2Ccond-mat%2F0108454%2Ccond-mat%2F0108153%2Ccond-mat%2F0108242%2Ccond-mat%2F0108386%2Ccond-mat%2F0108239%2Ccond-mat%2F0108124%2Ccond-mat%2F0108055%2Ccond-mat%2F0108123%2Ccond-mat%2F0108494%2Ccond-mat%2F0108312%2Ccond-mat%2F0108192%2Ccond-mat%2F0108263%2Ccond-mat%2F0108473%2Ccond-mat%2F0108036%2Ccond-mat%2F0108311%2Ccond-mat%2F0108375%2Ccond-mat%2F0108293%2Ccond-mat%2F0108463%2Ccond-mat%2F0108477%2Ccond-mat%2F0108514%2Ccond-mat%2F0108358%2Ccond-mat%2F0108354%2Ccond-mat%2F0108363%2Ccond-mat%2F0108125%2Ccond-mat%2F0108025%2Ccond-mat%2F0108166%2Ccond-mat%2F0108491%2Ccond-mat%2F0108216%2Ccond-mat%2F0108057%2Ccond-mat%2F0108389%2Ccond-mat%2F0108442%2Ccond-mat%2F0108108%2Ccond-mat%2F0108151%2Ccond-mat%2F0108113%2Ccond-mat%2F0108322%2Ccond-mat%2F0108339%2Ccond-mat%2F0108157%2Ccond-mat%2F0108544%2Ccond-mat%2F0108022%2Ccond-mat%2F0108307%2Ccond-mat%2F0108127%2Ccond-mat%2F0108007%2Ccond-mat%2F0108074%2Ccond-mat%2F0108453%2Ccond-mat%2F0108049%2Ccond-mat%2F0108117%2Ccond-mat%2F0108051%2Ccond-mat%2F0108191%2Ccond-mat%2F0108103%2Ccond-mat%2F0108364%2Ccond-mat%2F0108380%2Ccond-mat%2F0108385%2Ccond-mat%2F0108302%2Ccond-mat%2F0108403%2Ccond-mat%2F0211270%2Ccond-mat%2F0211118%2Ccond-mat%2F0211357%2Ccond-mat%2F0211531%2Ccond-mat%2F0211154%2Ccond-mat%2F0211294%2Ccond-mat%2F0211300%2Ccond-mat%2F0211529%2Ccond-mat%2F0211553%2Ccond-mat%2F0211366%2Ccond-mat%2F0211551%2Ccond-mat%2F0211661%2Ccond-mat%2F0211088%2Ccond-mat%2F0211096%2Ccond-mat%2F0211568%2Ccond-mat%2F0211232%2Ccond-mat%2F0211245%2Ccond-mat%2F0211305%2Ccond-mat%2F0211124%2Ccond-mat%2F0211328%2Ccond-mat%2F0211284%2Ccond-mat%2F0211402%2Ccond-mat%2F0211608%2Ccond-mat%2F0211693%2Ccond-mat%2F0211057%2Ccond-mat%2F0211326&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Direct sampling of complex landscapes at low temperatures: the\n  three-dimensional +/-J Ising spin glass"}, "summary": "A method is presented, which allows to sample directly low-temperature\nconfigurations of glassy systems, like spin glasses. The basic idea is to\ngenerate ground states and low lying excited configurations using a heuristic\nalgorithm. Then, with the help of microcanonical Monte Carlo simulations, more\nconfigurations are found, clusters of configurations are determined and\nentropies evaluated. Finally equilibrium configuration are randomly sampled\nwith proper Gibbs-Boltzmann weights.\n  The method is applied to three-dimensional Ising spin glasses with +- J\ninteractions and temperatures T<=0.5. The low-temperature behavior of this\nmodel is characterized by evaluating different overlap quantities, exhibiting a\ncomplex low-energy landscape for T>0, while the T=0 behavior appears to be less\ncomplex.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0108100%2Ccond-mat%2F0108259%2Ccond-mat%2F0108052%2Ccond-mat%2F0108484%2Ccond-mat%2F0108360%2Ccond-mat%2F0108262%2Ccond-mat%2F0108459%2Ccond-mat%2F0108308%2Ccond-mat%2F0108391%2Ccond-mat%2F0108533%2Ccond-mat%2F0108408%2Ccond-mat%2F0108231%2Ccond-mat%2F0108444%2Ccond-mat%2F0108010%2Ccond-mat%2F0108466%2Ccond-mat%2F0108506%2Ccond-mat%2F0108230%2Ccond-mat%2F0108377%2Ccond-mat%2F0108475%2Ccond-mat%2F0108488%2Ccond-mat%2F0108268%2Ccond-mat%2F0108454%2Ccond-mat%2F0108153%2Ccond-mat%2F0108242%2Ccond-mat%2F0108386%2Ccond-mat%2F0108239%2Ccond-mat%2F0108124%2Ccond-mat%2F0108055%2Ccond-mat%2F0108123%2Ccond-mat%2F0108494%2Ccond-mat%2F0108312%2Ccond-mat%2F0108192%2Ccond-mat%2F0108263%2Ccond-mat%2F0108473%2Ccond-mat%2F0108036%2Ccond-mat%2F0108311%2Ccond-mat%2F0108375%2Ccond-mat%2F0108293%2Ccond-mat%2F0108463%2Ccond-mat%2F0108477%2Ccond-mat%2F0108514%2Ccond-mat%2F0108358%2Ccond-mat%2F0108354%2Ccond-mat%2F0108363%2Ccond-mat%2F0108125%2Ccond-mat%2F0108025%2Ccond-mat%2F0108166%2Ccond-mat%2F0108491%2Ccond-mat%2F0108216%2Ccond-mat%2F0108057%2Ccond-mat%2F0108389%2Ccond-mat%2F0108442%2Ccond-mat%2F0108108%2Ccond-mat%2F0108151%2Ccond-mat%2F0108113%2Ccond-mat%2F0108322%2Ccond-mat%2F0108339%2Ccond-mat%2F0108157%2Ccond-mat%2F0108544%2Ccond-mat%2F0108022%2Ccond-mat%2F0108307%2Ccond-mat%2F0108127%2Ccond-mat%2F0108007%2Ccond-mat%2F0108074%2Ccond-mat%2F0108453%2Ccond-mat%2F0108049%2Ccond-mat%2F0108117%2Ccond-mat%2F0108051%2Ccond-mat%2F0108191%2Ccond-mat%2F0108103%2Ccond-mat%2F0108364%2Ccond-mat%2F0108380%2Ccond-mat%2F0108385%2Ccond-mat%2F0108302%2Ccond-mat%2F0108403%2Ccond-mat%2F0211270%2Ccond-mat%2F0211118%2Ccond-mat%2F0211357%2Ccond-mat%2F0211531%2Ccond-mat%2F0211154%2Ccond-mat%2F0211294%2Ccond-mat%2F0211300%2Ccond-mat%2F0211529%2Ccond-mat%2F0211553%2Ccond-mat%2F0211366%2Ccond-mat%2F0211551%2Ccond-mat%2F0211661%2Ccond-mat%2F0211088%2Ccond-mat%2F0211096%2Ccond-mat%2F0211568%2Ccond-mat%2F0211232%2Ccond-mat%2F0211245%2Ccond-mat%2F0211305%2Ccond-mat%2F0211124%2Ccond-mat%2F0211328%2Ccond-mat%2F0211284%2Ccond-mat%2F0211402%2Ccond-mat%2F0211608%2Ccond-mat%2F0211693%2Ccond-mat%2F0211057%2Ccond-mat%2F0211326&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A method is presented, which allows to sample directly low-temperature\nconfigurations of glassy systems, like spin glasses. The basic idea is to\ngenerate ground states and low lying excited configurations using a heuristic\nalgorithm. Then, with the help of microcanonical Monte Carlo simulations, more\nconfigurations are found, clusters of configurations are determined and\nentropies evaluated. Finally equilibrium configuration are randomly sampled\nwith proper Gibbs-Boltzmann weights.\n  The method is applied to three-dimensional Ising spin glasses with +- J\ninteractions and temperatures T<=0.5. The low-temperature behavior of this\nmodel is characterized by evaluating different overlap quantities, exhibiting a\ncomplex low-energy landscape for T>0, while the T=0 behavior appears to be less\ncomplex."}, "authors": ["Alexander K. Hartmann", "Federico Ricci-Tersenghi"], "author_detail": {"name": "Federico Ricci-Tersenghi"}, "author": "Federico Ricci-Tersenghi", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1103/PhysRevB.66.224419", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0108307v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0108307v3", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "9 pages, 7 figures, revtex (one sentence changed compared to v2)", "arxiv_primary_category": {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0108307v3", "affiliation": "University \"La Sapienza\", Rome, Italy", "arxiv_url": "http://arxiv.org/abs/cond-mat/0108307v3", "journal_reference": "Phys. Rev. B 66, 224419 (2002)", "doi": "10.1103/PhysRevB.66.224419", "fulltext": "Direct sampling of complex landscapes at low temperatures:\nthe three-dimensional \u00b1J Ising spin glass\nAlexander K. Hartmann\u2217\n\narXiv:cond-mat/0108307v3 [cond-mat.dis-nn] 1 Oct 2002\n\nInstitut f\u00fcr Theoretische Physik,University of G\u00f6ttingen, Bunsenstr. 9, 37073 G\u00f6ttingen, Germany\n\nFederico Ricci-Tersenghi\u2020\nDipartimento di Fisica and INFM, Universit\u00e0 di Roma \"La Sapienza\", Piazzale Aldo Moro 2, I-00185 Roma (Italy)\n(Dated: November 8, 2018)\nA method is presented, which allows to sample directly low-temperature configurations of glassy\nsystems, like spin glasses. The basic idea is to generate ground states and low lying excited configurations using a heuristic algorithm. Then, with the help of microcanonical Monte Carlo simulations,\nmore configurations are found, clusters of configurations are determined and entropies evaluated.\nFinally equilibrium configuration are randomly sampled with proper Gibbs-Boltzmann weights.\nThe method is applied to three-dimensional Ising spin glasses with \u00b1J interactions and temperatures T \u2264 0.5. The low-temperature behavior of this model is characterized by evaluating different\noverlap quantities, exhibiting a complex low-energy landscape for T > 0, while the T = 0 behavior\nappears to be less complex.\nPACS numbers: PACS Numbers: 75.10.Nr, 75.50.Lk, 75.40.Mg, 05.50.+q\n\nI.\n\nINTRODUCTION\n\nDespite large efforts made by the scientists in the last\ntwo decades, complex energy landscapes with many local minima and nested valleys, like that of spin glasses1,\nstill offer many relevant questions to be answered. These\nquestions usually regard the lowest energy levels of the\nlandscape. The traditional numerical approach is to apply a Monte Carlo (MC) simulation2 . Equilibration is\ntested by monitoring different average quantities as a\nfunction of the number of MC steps. Equilibration can\nbe assumed, when the measured values of different runs,\ninitially being far apart, agree within error bars. Another approach3 is to calculate one quantity, like the link\noverlap, in two different ways, one time directly and one\ntime depending on some other measured quantity like the\nenergy, and wait till both results agree.\nSuch a test is available only in special cases, e.g. for\nspin glasses with a Gaussian distribution of the bonds.\nOtherwise, one usually waits till the quantity of interest does not show any more a time dependence. Nevertheless, at low temperatures and with increasing system\nsize, equilibration becomes much harder and eventually,\nat very low temperatures, is impossible.\nIn the very last years, a different approach has been\nproposed, namely the calculation of ground-state (GS)\nand low-energy configurations. Some characteristics of\nthe low-energy landscape can be probed by the application of suitable perturbations which slightly modify the\nGS4 . But the full information on the low-temperature behavior can be obtained only by an equilibrium sampling\nof the system at a given temperature. Here we show,\nthat by calculating GS and excited states, one can directly sample very low temperatures. Several algorithms\nand heuristics5 are available to obtain ground states and\nexcited states. Some are based again on Monte Carlo\ntechniques like simulated annealing (SimA) and parallel\n\ntempering (PT). All these techniques have the drawback,\nthat it is impossible to obtained an unbiased, i.e. equilibrium sample of configurations for T \u2192 0. For the MC\nmethods, the reason is that for larger systems and very\nlow temperatures, equilibration times are too long. We\nshall give below an example which shows for a \u00b1J Ising\nspin glass, which exhibits an exponential ground state\ndegeneracy, that just obtaining ground states is much\neasier than obtaining ground states with their proper\nstatistics, i.e. each ground state with the same probability. For other existing heuristics the statistics of the\nconfigurations is influenced in an uncontrollable way by\nthe low-energy landscape.\nIn this work, a post-processing method is presented,\nwhich removes the bias induced by the non-equilibrium\nlow-temperature sampling and allows to obtain a properly equilibrated state for systems having a high degeneracy. The basic idea of the technique is to calculate clusters of configurations, which are connected in configuration space by zero-energy moves, e.g. zero-energy flips of\nspins in the Ising spin-glass case. Next, the sizes of these\nclusters are estimated and used to obtain an unbiased\nsample, where each cluster contributes with a factor to\nthe size of the cluster and to the Gibbs-Boltzmann (G-B)\nweight. This method has already been successfully applied to the ground-state sampling of three-dimensional\nIsing \u00b1J spin glasses6. Here, the method is extended to\nthe T > 0 case and again applied to the d = 3 \u00b1J SG\nmodel. Please note that this approach works better and\nbetter with decreasing temperature, hence is complementary to the MC technique, which suffers from equilibration problems at low temperatures. But similar to MC,\none has to monitor some measured quantities as a function of some parameters to establish equilibration, e.g.\nthe number of clusters found in the analysis as a function of the number of states included. Also similar to\nMC, obtaining equilibrium becomes harder with increas-\n\n\f2\n300\n\nTn+1=0.5Tn, T=2,...,0.1 (6 steps)\n\n250\n\nfrequency\n\n200\n150\n100\n50\n0\n\n0\n\n20\n\n40\n\n60\n\nground state\n300\n\nTn+1=0.99Tn, T=2,...,0.1 (300 steps)\n\n250\n200\n\nfrequency\n\ning system size. In this sense, the method is also not exact. But in contrast to MC, ensuring equilibrium in this\nway is possible at very low temperatures for larger systems (and becomes impossible for higher temperatures),\nwhile for MC it is the other way round.\nWe apply the algorithm to three-dimensional Ising\nspin glasses. The EA model consists of N = L3 Ising\nspins si P\n= \u00b11 on a cubic lattice with the Hamiltonian\nH = \u2212 hi,ji Jij si sj . The sum runs over all pairs of\nnearest neighbors hi, ji. The Jij are quenched random\nvariables taking values JijP\n= \u00b11 with equal probability\nand satisfy the constraint hi,ji Jij = 0. We apply periodic boundary conditions in all directions.\nIn this work we show that the overlap distribution\nP (q) at zero temperature is qualitatively different from\nP (q) at low but non-zero temperature. This means, even\nif there is an exponential number of GS configurations,\nzero-temperature quantities may be very different from\nthose at any finite and small temperature. In particular we will show here that for the three-dimensional EA\nmodel, which has a finite zero-temperature entropy, P (q)\nis very narrow at exactly T = 0, while it is broad at any\nfinite temperature. We obtained the same result for the\nbox-overlap Pbox (q). The picture resulting from our findings is that of a large number of GS which are however\nvery close. Nevertheless, quite different states can be\neasily found once the first excited energy levels are considered. This picture agrees with the very recent MC\nresults by Palassini and Young7 .\nBefore proceeding with our results and methods, we\nshow, as a motivation, results from applying the SimA\nmethod to one sample realization of site L = 5 of our\nmodel. We have performed 104 independent runs of the\nSimA algorithm, starting with a temperature T0 = 2 and\nreducing the temperature according Tn+1 = bTn until\nT = 0.1 is reached. Per temperature 10 MC sweeps\nwere performed. At the end of the simulation, one randomly chosen configuration exhibiting the lowest energy\nencountered during the run was stored. After having performed 104 runs, only the true ground states were kept.\nA GS configuration and its mirror image, obtained by reversing all states, are treated as being equivalent. As it\nturns out, the system has 59 distinct GS configurations.\nIn Fig. 1 histograms of the number of times each GS has\nbeen found are displayed for b = 0.5 and b = 0.99. One\nsees clearly that for b = 0.5 different GS configurations\noccur with different frequencies8 , i.e. not all appear with\nthe same frequency as requested by the G-B distribution.\nWhen cooling much slower, i.e. with b = 0.99, all GS are\nalmost equiprobable. This means that just finding GS\nconfigurations is much easier than finding each GS configuration with the correct probability.\nFor system sizes just slightly larger than L = 5, the\nnumber of GS and excited states is already huge (e.g.\n\u223c 1016 for L = 8). For this system sizes it is impossible to obtain a histogram similar to the one presented above. Consequently, it is impossible to determine\nwhether all GS are sampled with the correct statistics.\n\n150\n100\n50\n0\n\n0\n\n20\n\n40\n\n60\n\nground state\n\nFIG. 1: Histogram of the number of times each GS is found\nwith a SimA simulation of 104 independent runs for one L = 5\nrealization of a \u00b1J Ising spin glass. The temperature was decreased according to Tn+1 = bTn , with T0 = 2 until T = 0.1\nis reached. At each temperature 10 MC sweeps were performed. For the upper panel b = 0.5, while b = 0.99 for the\nlower panel.\n\nThis is even more true for excited states. Please note that\nthis is the same for more elaborate algorithms like parallel tempering9 . Since, as already pointed out, at very\nlow temperatures and for system sizes like L = 10 it is\nimpossible to equilibrate the system, other methods have\nto be applied. In this paper, we present a post-processing\ntool, which allows to correct the bias imposed by any algorithm and leads to an equilibrated sample. For sizes\nup to L = 10 and low temperatures up to T < 0.5 the\nadditional effort is moderate, because only the few lowest\nlevels of excited states have to be considered. For larger\ntemperatures, the post-processing methods becomes intractable, but then conventional MC methods can be easily applied.\nThe rest of the paper is organized as follows. First,\nwe explain the algorithms we have applied. In the next\nsection, we present the result for the three-dimensional\n\u00b1J spin glass. Finally, a summary and a discussion are\ngiven.\n\n\f3\nII.\n\nALGORITHMS\n\nThe technique to obtained an equilibrated low-temperature sampling consists of four steps:\n1. Generate configurations for GS and the lowest levels of excitations.\n2. On each energy level: group configurations into\nclusters.\n3. Calculate sizes of clusters.\n4. Generate a sample of states for given temperature\nT , where each cluster contributes with a weight\nproportional to its size and to the G-B factor\nexp(\u2212E/T ), where E is the energy of the configurations in that cluster.\nNow all four steps are explained.\nThe basic method used here to generate the configurations is the cluster-exact approximation (CEA) technique10 , which is a discrete optimization method5 designed especially for spin glasses. In combination with\na genetic algorithm11,12 this method is able to calculate\ntrue GS13 up to L = 14, as well as excited configurations\nas a byproduct. Since the CEA technique is well established and described in several sources, the details are\nskipped here. For each system and each energy level, we\nhave generated 1000 configurations with the pure genetic\nCEA algorithms. We will show below that this number\nof configurations is sufficient up to L = 10 and T = 0.5.\nBy applying pure genetic CEA, one does not obtain\nthe true thermodynamic distribution14 , i.e. not all configurations with the same energy contribute to physical\nquantities proportional to the G-B weight. This means\nthe genetic CEA algorithm is biased. For small system\nsizes up to L = 4 it is possible to avoid the problem by\ngenerating all low-energy configurations; averages can be\nperformed simply by considering each configuration once,\nweighted with the G-B factor. Since the degeneracy increases exponentially with the number N of spins and\ngrows also strongly with the energy level, a complete enumeration is not possible for larger system sizes or higher\nenergies. Instead, one has to choose a subset of all configurations, where each configurations contributes with\na probability proportional to the G-B weight. The procedure described here, consisting of steps 2-4 mentioned\nabove, is applied to ensure that all configurations appear\nwith the correct probability in this selection. Please note\nthat the following methods works for any set of states,\nindependently of the method which has been applied to\ngenerate the states. I.e. also the results of many independent runs of a low-temperature MC simulation can\nbe treated, in case an equilibration was not possible, e.g.\nfor very low temperatures and larger system sizes.\nIn step 2 of our method, we group the configurations into clusters by performing the ballistic-search algorithm15 : All configurations which are accessible via\nflipping of spins having zero local field (called free spins\n\nin the following), i.e. without changing the energy E, are\nconsidered to be in the same cluster. Please note that\nthe Hamiltonian is symmetrical with respect to flipping\nall spins simultaneously. Hence, for the rest of the paper\nand for all analysis steps, a configuration and its mirror\nimage are regarded as being identical. The final result\nis a list of different clusters whose sizes are estimated as\nexplained below. This list does not change if more than\none configuration was initially found in the same cluster,\nsince these cases are recognized and correctly handled.\nFor completeness and to convince the reader that the\nmethod indeed works, we present some details in the following.\nThe algorithm is applied independently for all configurations having the same energy. The starting point is a\nset of nS configurations. For clarity, first the straightforward method to obtain the cluster structure is explained. This method will not be applied finally. Afterward, the method actually used is exposed.\nThe straight-forward construction starts with one arbitrary configuration. It is the first member of the cluster.\nAll configurations which differ only by the orientation of\none free spin are called neighbors. All the neighbors of\nthe starting configuration are added to the cluster. These\nneighbors are treated recursively in the same way: All\ntheir neighbors which are yet not included in the cluster\nare added, etc. After the construction of one cluster is\ncompleted the construction of the next one starts with a\nconfiguration, which has not been visited so far.\nThe construction of the clusters needs only linear\ncomputer-time as function of nS (O(nS )), similar to the\nHoshen-Kopelman technique16 , because each configuration is visited only once. Unfortunately the detection\nof all neighbors, which has to be performed at the beginning, is of O(n2S ) since all pairs of states have to be\ncompared. Even worse, all existing configurations of a\ngiven energy must have been calculated before. As e.g.\na 53 system may exhibit already more than 105 GS and\nmuch more excited states, this algorithm is not suitable.\nInstead we use the following technique, based on the\nballistic-search algorithm15 . The basic idea of ballistic\nsearch is to use a test, which tells whether two configurations are in the same cluster. The test works as follows:\nGiven two independent replicas {\u03c3i\u03b1 } and {\u03c3i\u03b2 } let D\nbe the set of spins, which are different in both states:\nD \u2261 {i|\u03c3i\u03b1 6= \u03c3i\u03b2 }. Now BS tries to build a path of successive flips of free spins, which leads from {\u03c3i\u03b1 } to {\u03c3i\u03b2 }\nwhile using only spins from D. In the simplest version iteratively a free spin is selected randomly from D, flipped\nand removed from D. This test does not guarantee to\nfind a path between two configurations which belong to\nthe same cluster, since it may depend on the order the\nspins are selected whether a path is found or not. But,\nif a path is found, then it is sure that both configurations belong to the same cluster. On the other hand,\nif both configurations belong to the same cluster, then\nthe method finds a path with a certain probability which\ndepends on the size of D. It turns out that the proba-\n\n\f4\nmore states can be obtained easily by just performing a\nE =const Monte-Carlo simulation starting with the initial state. Hence, one can increasing the number of states\navailable quickly. The probability that all clusters have\nbeen identified correctly approaches very quickly unity\nwith increasing number of available states. Detailed tests\ncan be found in15 . For all results presented here, we have\nchecked that the clusters do not change when doubling\nthe number of states.\n\n10\n\n10\n\n0\n\n-4\n\n10\n\n-8\n\np(V)\n\nbility decreases monotonically with |D|. For example for\nN = 83 the method finds a path in 90% of all cases if the\ntwo states differ by 34 spins. More analysis can be found\nin15 .\nThe algorithm for the identification of clusters utilizes\na collective effect, to overcome the problem that sometimes a path is not found, even if two configurations belong to the same cluster. It works as follows: the basic\nidea is to let a configuration represent that part of a cluster which can be found using BS with a high probability\nby starting at this configuration. If a cluster is large it\nhas to be represented by a collection of states, such that\nthe whole cluster is \"covered\". For example a typical\ncluster of a 83 spin glass consisting of 1016 ground states\nis usually represented by only some few ground states\n(e.g. two or three). A detailed analysis of how many\nrepresenting configurations are needed as a function of\ncluster and system size can be found in15 . The details of\nthe algorithm are as follows: in memory a set of clusters\nconsisting each of a set of representing configurations is\nstored. At the beginning the cluster set is empty. Iteratively all available configurations {\u03c3i } are treated: For\nall representing configurations the BS algorithm tries to\nfind a path to the current configuration or to its inverse.\nIf no path is found, a new cluster is created, which is\nrepresented by the actual configuration treated. If {\u03c3i }\nis found to be in exactly one cluster nothing special happens. If {\u03c3i } is found to be in more than one cluster,\nit is called a bridge configuration and all these clusters\nare merged into one single cluster, which is now represented by the union of the states which have represented\nall clusters affected by the merge. After all configurations\nhave been treated the whole process is run again with the\nobtained set of clusters. This allows to find bridge configurations which have not identified in the first iteration,\nbecause accidentally only one cluster had been created\nduring the first iteration, at the time the configuration\nwas treated15 .\nThe BS identification algorithm has some advantages\nin comparison with the straight-forward method: since\neach ground-state configuration represents many ground\nstates, the method does not need to compare all pairs\nof states. Each state is compared only to a few number of representing configurations. Thus, the computer\ntime needed for the calculation grows only a little bit\nfaster than O(nS nC )15 , where nC is the number of clusters, which is much smaller than nS . Consequently, large\nsets of configurations, which appear already for small system sizes like N = 53 , can be treated. Furthermore, the\ncluster structure of even larger systems can be analyzed,\nsince it is sufficient to calculate a small number of configurations per cluster. The main point is that one has\nto be sure that all clusters are identified correctly. This\nis not guaranteed immediately, since for two configurations belonging to the same cluster there is just a certain\nprobability that a path of free flipping spins connecting them is found. But this poses no problem, because\nonce at least one state of a cluster has been found, many\n\n10\n\n10\n\n10\n\n-12\n\nL=3\nL=4\nL=5\nL=6\nL=8\n-1.1\n~V\n\n-16\n\n-20\n\n10\n\n0\n\n10\n\n4\n\n10\n\n8\n\n10\n\n12\n\n10\n\n16\n\n10\n\n20\n\nV\n\nFIG. 2: Cluster-size distributions of GS clusters for small sizes\nL = 3 to L = 8. The straight line represents the function\n2V \u22121.1 .\n\nFurthermore, one has in principle to ensure that really\nall clusters are found, which is simply done by calculating enough configurations, but this is still only a tiny\nfraction of all configurations15. This time, the configurations must be obtained independently, one cannot use the\nE =const MC simulation as above. It is possible to obtain at least one configuration from each cluster roughly\nup to size L = 8 at GS level, resp. L = 6 for first excited\nstates. For sizes like N = 103 , the largest size we have\ntreated in this paper, the number of clusters is too large\nat any energy level. But this is not a problem in principle\nbecause the low-temperature behavior of these systems is\ndominated by large clusters. As an example, in Fig. 2\nthe probability densities of cluster sizes for GS clusters\nare shown. The distributions are for small system sizes\nup to L = 8, were we can be fairly sure17 that all clusters have been found18 . The distributions follow roughly\nan algebraic decrease with a p(V ) \u223c V \u2212\u03b1 behavior with\n\u03b1 \u223c 1.1. This dependence gets straighter with increasing\nsystem size. We are interested in the contribution of a\ncluster of order (or scale) of size V to the behavior. First,\n\n\f5\nthe statistical weight of a cluster is proportional to the\nnumber of states in the cluster, i.e. to the volume V . Second, each scale of cluster sizes contributes proportional\nto the scale itself, because we are integrating over all clusters of a given scale, i.e. this weight is also proportional\nto V . (Or in other words, to translate the probability\ndensities into probabilities on a logarithmic scale, one\nhas to multiply with V .) In total, clusters of sizes with\nscale V contribute with weight V 2 p(V ) = V 2\u2212\u03b1 . Since\n\u03b1 \u2248 1.1 < 2, the largest scale clusters dominate the behavior. On the other hand, since p(V ) rapidly decreases,\nthe number of these dominating clusters is rather small,\ni.e. it is rather simple to obtain an equilibrated sample of\nconfigurations. For the first excited level we have found\n\u03b1 = 1.3 < 2, while at higher excited levels the number of\nclusters is too large to really find all of them. This results\nindicates that at higher levels the distribution becomes\nbroader, which limits the application of the method to\nthe lowest level of excitations. This effect is studied below with more detail. We have restricted our analysis to\nthe first 4 levels of excited states.\nPlease note that the CEA method generates configurations from larger clusters with larger probability19 , hence\nthe large and important clusters are encountered on average first in the calculations. For the system sizes we\nhave treated here, except L = 10 and T = 0.5, about\n90% of all contributing states are typically from the top\n5 largest clusters and further 5% from the next 5 largest\nclusters. Then with the 1000 configurations we generated\nper energy level, we encounter typically up to 100 clusters, and we can be pretty sure that all thermodynamic\nrelevant contributions are considered within the level of\naccuracy given by our statistical fluctuations. Only the\nresults for L = 10 and T = 0.5, where higher level excitations contribute significantly, may not be equilibrated.\nThis is demonstrated at the end of this section, after we\nhave presented the remaining parts of our algorithm.\nThe third step in the algorithm is the estimation of the\ncluster sizes. This works as follows. Let C be a cluster\nwe want to measure in size and let's consider a random\n'reference configuration' {ri } belonging to this cluster.\nP\nWe define a test Hamiltonian H\u0303[s] = \u2212 i ri si for {si } \u2208\nC, being \u1ebc(\u03b2) and S\u0303(\u03b2) the average extensive energy and\nentropy at inverse temperature \u03b2. Then the size of C is\ngiven by exp[S\u0303(0)]. Since the GS of this Hamiltonian\nis unique (it is the reference configuration), i.e. S\u0303(\u221e) =\n0, we obtain from the microcanonical definition of the\ntemperature T = d\u1ebc/dS\u0303\nS\u0303(0) = S\u0303(0) \u2212 S\u0303(\u221e) = \u2206S\u0303 =\n=\n\nZ\n\n0\n\n\u221e\n\n[\u1ebc \u2212 \u1ebc(\u221e)] d\u03b2 =\n\nZ\n\n\u1ebc(0)\n\n\u03b2 d\u1ebc =\n\n\u1ebc(\u221e)\nZ \u221e\n\n(\u1ebc + N ) d\u03b2\n\n,(1)\n\n0\n\nwhere the previous last equality comes from an integration by parts and the last equality from the substitution \u1ebc(\u221e) = \u2212N . In order to calculate this integral,\nwe actually perform a fast MC simulation restricted to\n\nconfigurations {si } \u2208 C while varying w = exp(\u22122\u03b2)\nin [0, 1] and measuring the average energy \u1ebc as a function of w. The final formula is the integral of a smooth\nR 1 +\u1ebc\ndw. The number of MC sweeps\nfunction \u2206S\u0303 = 0 N2w\napplied per integration step was chosen automatically by\nthe program in a way that the resulting entropy did not\nchange by more than 5% of the value when the number of\nMC sweeps was doubled. I.e. the program started always\nwith 10 MC sweeps, calculated the entropy integral, then\napplied 20 MC sweeps and so on. For small clusters, the\ncalculation usually stopped after 20 MC sweeps. For the\nlargest clusters encountered here, the algorithm stopped\nafter the integration using 640 MC sweeps. We have also\nchecked, that for these cases the measured entropy did\nnot depend monotonically on the number of MC sweeps,\ni.e. we are sure that we did not miss a systematic trend\nwhen stopping the calculation at one point.\nIn principle, there could be high entropic barriers,\nwhich prevent the size calculation from converging to the\ncorrect value. Fortunately, the full algorithm is not susceptible to that problem. The reason is that the BS clustering method uses single spin flips at constant energy\nas well to determine the cluster structure, as described\nabove. This means, if two parts of a cluster are connected through a very tiny path (the entropic barrier),\nwhich is not detected by the MC integration, the clustering method is also not able to recognize both subclusters\nas belonging to the same cluster. Hence, if both subclusters are large, the genetic CEA method will have calculated with high probability configurations from both\nsubclusters. In the analysis, because they are not identified as belonging to the same cluster, they will appear as\ntwo independent large cluster, i.e. the correct statistics is\nensured at the end. If on the other hand, one subcluster\nis small, it has a negligible contribution to the overall\nbehavior, like other small clusters.\nAfter estimating the cluster sizes, a certain number of\nconfigurations is selected from each cluster, this is the\nlast step of the algorithm listed in the beginning of this\nsection. This number of configurations is proportional to\nthe size of the cluster and to the G-B factor exp(\u2212E/T ).\nIt means that each cluster contributes with its proper\nweight. This is possible for small temperatures and small\nsizes, where only few low-energy levels contribute to the\nthermodynamical behavior.\nThe selection of the configurations is done in a manner\nthat many small clusters may contribute as a collection\nas well6 . For example, assume that 100 configurations\nare selected from a cluster consisting of 1010 configurations, then for a set of 500 clusters of size 107 each (with\nthe same energy) a total number of 50 configurations is\nselected, i.e. 0.1 configurations per cluster on average.\nThe correct handling of such situations is achieved by\nfirst sorting all clusters in ascending order. Then the generation of configurations starts with the smallest cluster.\nFor each cluster the number of configurations generated\nis proportional to its size, to exp(\u2212E/T ) and to a factor f . If the number of configurations grows too large,\n\n\f6\nonly a certain fraction f2 of the configurations which have\nalready been selected is kept, the factor is recalculated\n(f \u2190 f \u2217 f2 ) and the process continues with the next\ncluster.\nThe configurations representing the clusters are generated from the initial configurations, obtained from the\nheuristic algorithm, by microcanonical MC simulation,\ni.e. iteratively spins are randomly selected and flipped if\nthey are free. Since within a cluster there are no energy\nbarriers, for the system sizes up to L = 10, applying\n100 MC sweeps ensures that all configurations within a\ncluster are visited with the same frequency.\nTo summarize, by applying the algorithm presented\nhere, each cluster appears with a weight proportional to\nits size and to exp(\u2212E/T ) and each configuration within\na cluster appears with the same probability. Therefore,\non total, the correct thermodynamic distribution is obtained.\n\nT=0.5\nT=0.4\nT=0.3\nT=0.1\n\nL=10\n\nx0.5\n\n0.1\n\n0.05\n\nNconf . The configurations were taken in the order they\nappeared in the generation using the genetic CEA, i.e.\nfor a small number of configurations, the large clusters\nare more likely to be represented than the smaller clusters\nsince genetic CEA preferentially generates configurations\nfrom larger clusters. One can see that for low temperatures, even few generated configurations are sufficient\nto yield the true behavior. Please note that the remaining fluctuations are due to the fluctuations between the\ndifferent samples of configurations. The reason that few\nconfigurations are sufficient here is that at low temperatures the GSs dominate and the number of GS clusters is\nfairly small. With increasing temperature, excited states\nbecome more important. For excited states, much more\nclusters exists. Thus, more configurations must be included into the analysis. This is visible in Fig. 3, where\nat e.g. T = 0.5 x0.5 depends strongly on Nconf . For\nNconf = 1000 T = 0.5 seems to be the borderline case,\nwhile for T < 0.5 the result for x0.5 seems to be converged\n(within error bars). We have checked this explicitly by\nfitting algebraic functions to the data points Nconf \u2265 40,\nresulting in an agreement within error bars of the limiting value Nconf \u2192 \u221e with the result we have obtained at\nNconf \u2192 \u221e. Hence we can be again confident that using\n1000 configurations per energy level, the results obtained\nhere up to L = 10 and T < 0.5 represent the true equilibrium behavior or, at least, is so close to the true result\nthat it cannot be distinguished from it at the level of\naccuracy determined by the statistical fluctuations. For\nsmaller sizes, the number of clusters is smaller on each\nenergy level, which means that 1000 configurations per\nrealization and energy level are sufficient for even higher\ntemperatures. But we restrict our analysis to T \u2264 0.5\nhere.\n\n0\n\n1\n\n10\n\n100\n\n1000\n\nNconf\n\nFIG. 3: Result for x0.5 (see Eq. (2) for definition) as a function of the number Nconf of configurations included per energy\nlevel in the analysis. The error bars at the right represent the\nlimiting values Nconf \u2192 \u221e obtained from fitting the data\npoints Nconf \u2265 40 to algebraic functions. For small temperatures T , few configurations are sufficient while at T = 0.5\nmore than 1000 configurations are necessary.\n\nfraction of configurations\n\n1\n\n0.8\n\nL=4\nL=8\nL=10\n\n0.6\n\n0.4\n\nT=0.5\n\n0.2\n\n0\n\n0\n\n1\n\n2\n\n3\n\n4\n\nenergy level\n\nWe have tested whether our generated data represents\nthe equilibrium behavior by calculating the small-overlap\nweight x0.5 , as defined in the beginning of the next section in Eq. (2). x0.5 is obtained for the largest system\nsize L = 10 and for different temperatures T as a function of the number of configurations Nconf included in the\nanalysis per energy level. The result is shown in Fig.3.\nPlease note that the full analysis, as explained in this section, has to be repeated independently for each number\n\nFIG. 4: Fraction of configurations sampled from each energy\nlevel at T = 0.5 for different system sizes. Energy level 0 is\nthe ground state. Lines are guides to the eyes only.\n\nFinally, in Fig. 4, the fraction of configurations sampled at T = 0.5 for the different energy levels is shown for\ndifferent system sizes. For the smallest size L = 4 almost\n\n\f7\nonly GS configurations contribute to the thermodynamics, while increasing system size higher energy configurations become more important. Please note that only\nfor L = 10 configurations from excitation level 3 contribute. There the degeneracy is much larger than for\nthe lower levels. This explains, why the result for L = 10\nand T = 0.5 is probably not equilibrated. The result of\nFig. 4 shows that, when studying the low-temperature\nbehavior of glassy systems, it is not sufficient to study\njust GS configurations since the G-B factor and the size\nof the cluster (i.e. the entropy) must be taken into account. Nevertheless for low temperatures and not too\nlarge system sizes, the energy levels which actually contribute to the partition function are very few.\n\nIII.\n\nRESULTS\n\nWe have calculated ground states and excited configurations up to level four, for system sizes L \u2264 10. Up\nto 3000 realizations of the disorder were considered (900\nfor the largest system size). From the set of configurations, samples of several hundred equilibrium configurations were generated for temperatures T \u2208 [0, 0.5].\n1\n\n10\n\nx0.5\n\n0.2\n\n0.1\nT=0.5\nT=0.4\nT=0.3\nT=0.1\n\nP(|q|)\n\n0.06\n0.04\n\n0\n\n10\n\n2\n\n4\n\n6\n\nT=0.5\n\n8 10\n\nL\nL=4\nL=6\nL=8\nL=10\n\u22121\n\n10\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n|q|\nFIG. 5: Distribution P (|q|) of overlaps at T = 0.5 for different\nsystem sizes. Lines are guides to the eyes only. The inset\nshows the average weight x0.5 of the distribution for |q| \u2264 0.5\nas a function of system size for T = 0.5, 0.4, 0.3, 0.1. The lines\nrepresent fits to functions of the form x(L) = x\u221e + a L\u03bb , with\nx\u221e \u2261 0 and \u03bb = \u22121.10(5) for T = 0.1, x\u221e = 0.051(13) for\nT = 0.3, x\u221e = 0.095(4) for T = 0.4 and x\u221e = 0.122(4) for\nT = 0.5.\n\nFor each disorder realization and each temperature, the\nP\n\u03b2\ndistribution PJ (q) of overlaps q \u2261 N1 i s\u03b1\ni si was calcu\u03b2\nlated, where {s\u03b1\ni }, {si } are two different equilibrium configurations. In Fig. 5 the disorder-averaged distribution\nP (|q|) = [PJ (|q|)]J is shown for T = 0.5, where [. . .]J denotes the average over the quenched disorder. The long\ntail to q = 0 seems to saturate at a finite weight, indicating the existence of a complex low-energy landscape\n\nat finite temperatures. This can be seen even better, by\ncalculating the fraction\nxq0 =\n\nZ\n\nq0\n\nP (q) dq\n\n(2)\n\n\u2212q0\n\nof overlaps smaller than q0 . The result for q0 = 0.5 is\npresented in the inset of Fig. 5. For zero temperatures,\nwhere only GS configurations are sampled, x0.5 converges\nto 0 or to a very small value20 . The rate of convergence\nis described by the finite-size dependence x0.5 (L) \u223c L\u03bb .\nWe find \u03bb = \u22121.10(5), which is compatible with the predicted bound \u03bb \u2264 \u22121 given by the \"TNT\"-scenario21. In\nRef. 7 a larger value \u03bb = \u22120.90(10) was found. This\nslight difference might be due to the different\nensembles\nP\nstudied, since in Ref.7 the constraint hi,ji Jij = 0 was\nnot applied.\nPlease note that for small temperatures we sample only\nGS configurations, due to small system sizes. For larger\ntemperatures T \u2265 0.3, the asymptotic value of x0.5 is\nclearly larger than zero. Please note that the last point\nL = 10, T = 0.5 may not be converged, as discussed\nabove. But, as you can see in Fig. 3, the value of x0.5 is\nan increasing function of the number of states included in\nthe calculation. Hence, the true result (we have obtained\nxL=10\n0.5 (0.5) = 0.137(6) by extrapolating Nconf \u2192 \u221e as\nopposed to 0.126(7) found for Nconf = 1000) is probably\nabove our value, thus supporting even more the conclusion that x0.5 > 0.\nOur results are quantitatively comparable to the data\nfound in Ref. 7 which were obtained by a paralleltempering MC simulation. Although the authors had\nno reliable criterion to check equilibration of the system\n(in contrast to the case with Gaussian distribution of the\ndisorder3 ), by comparison with our results it is very likely\nthat in Ref. 7 indeed thermal equilibrium was obtained.\nA non-trivial distribution of overlaps is not a sufficient\ncriterion for a complex energy landscape. A qualitatively similar overlap distribution with a nonzero weight\nfor small values of q would be obtained also for a system, where various configurations differ by a domain wall\nthrough the system at different positions, e.g. a ferromagnet with antiperiodic boundary conditions in one direction22 .\nTo rule out this scenario, we have calculated also the\ndistributions of box (or window) overlaps23,24 . This overlap is defined as usual, but restricted to a finite \"window\"\nof volume l \u00d7 l \u00d7 l, with l < L fixed independently of the\nsystem size L. Please note that for the aforementioned\nferromagnet, the distribution of box overlaps converges\nto a pair of delta functions at q = \u00b11 when L \u2192 \u221e.\nThe result for l = 3, T = 0.5 is exhibited in Fig. 6. At\nfinite temperature, similar to the conventional overlap,\nthe low-q tails seems to saturate, but more slowly, at a\nnon-zero weight with increasing systems size. This can\nbe seen from the inset of Fig. 6, where x0.5 is shown as a\nfunction of system size for T = 0.1, 0.3, 0.4 and T = 0.5.\nFor T \u2265 0.3, x0.5 clearly converges to a nonzero value.\n\n\f8\n1\n\n10\n\nL=4\nL=6\nL=8\nL=10\n\nx0.5\n\n0.2\n\nPbox(|q|)\n\n0.1\n\nT=0.5\nT=0.4\nT=0.3\nT=0.1\n4\n\n0.08\n\n0\n\n10\n\n0.06\n\n2\n\n6\n\n8 10\n\nL\nT=0.5\n\u22121\n\n10\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n|q|\n\nFIG. 6: Distribution Pbox (|q|) of box overlaps at T = 0.5\nfor different system sizes. Lines are guides to the eyes only.\nThe inset shows the average weight x0.5 of the distribution for\n|q| \u2264 0.5 as a function of system size for T = 0.5, 0.4, 0.3, 0.1.\nThe lines represent fits to functions of the form x(L) = x\u221e\nbox +\n\u221e\nab L\u03bbb , with x\u221e\nbox \u2261 0 and \u03bbb = \u22120.86(5) for T = 0.1, xbox =\n\u221e\n0.05(13) for T = 0.3, x\u221e\nbox = 0.10(1) for T = 0.4 and xbox =\n0.13(1) for T = 0.5.\n\nP\n\u03b1 \u03b1 \u03b2 \u03b2\nPl (ql ) of link overlaps ql \u2261\nhi,ji si sj si sj . The result for T = 0.5 and different system sizes can be observed in Fig. 7. The distribution becomes narrower,\nbut a second small peak seems to emerge. In the inset of RFig. 7 the finite-size dependence of the variance\n1\n\u03c3 2 = 0 (q \u2212 q\u0304)2 Pl (q) dq is shown for different temperatures. In all cases, the width seems to converge toward\nzero. Please note, however, that we cannot exclude that\nthe variance converges to a small but finite value. When\n2\nwe fit it to a function of the form \u03c3 2 (L) = \u03c3\u221e\n+ a\u03c3 L\u03bb\u03c3\n2\nwe obtain, for T = 0.5, \u03c3\u221e\n= 0.0038(28) with \u03c72 per\ndegree of freedom of 0.1, which is a very good fit. Nevertheless, a Pl (ql ) consisting of two peaks at distance of\n0.1 with weights 0.1 and 0.9 respectively has a variance\n\u03c3 2 = 0.0009.\nThe behavior of Pl (ql ) is quantitatively the same for\nthree-dimensional spin glasses with a Gaussian distribution of the interactions3 , which were found with a\nparallel-tempering MC simulation.\n\nIV.\n\nThus, we can conclude that indeed at finite temperatures, three-dimensional spin glasses exhibit a complex\nlow-energy landscape.\nPlease note that the non-trivial behavior occurs for\nlow temperatures, probably for all temperatures T > 0,\nwhich are sufficiently far away from the phase transition\nTc \u2248 1.1. Hence, the effects which were found within a\nMigdal-Kadanoff approximation scheme25 are unlikely to\nexplain the kind of behavior we find.\n7\n\u22121\n\nL=4\nL=6\nL=8\nL=10\n\n10\n\n\u03c32\n\n6\n\nPl(ql)\n\n5\n4\n\nT=0.5\nT=0.1\n\n\u22122\n\n10\n\nT=0.5\n\n3\n2\n\n2\n\n4\n\n6 8 10\n\nL\n\n1\n0\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nql\nFIG. 7: Distribution Pl (ql ) of link overlaps at T = 0.5 for\ndifferent system sizes L. Lines are guides to the eyes only.\nThe inset shows the variance \u03c3 2 as a function of system size\nfor T = 0.1, 0.5. The lines represent fits to functions of the\nform \u03c3 2 (L) = al L\u03bbl (L > 4), with \u03bbl = 0.53(5) for T = 0.1\nand \u03bbl = 0.27(1) for T = 0.5.\n\nFinally, we have computed the average distribution\n\nSUMMARY\n\nSummarizing, we have presented an algorithm which\nallows to investigate the low-temperature behavior of\nIsing systems with high degeneracy by direct sampling of\nGS and excited configurations. The basic idea is to generate configurations with any suitable algorithm, group\nthe configurations into clusters, measure the size of the\nclusters and then obtain a very good estimate of the G-B\nmeasure, to sample configurations with. Similar to MC,\nwhere one has to increase the number of MC sweeps until\nthe system is equilibrated, one has to increase the number of independent configurations until the true behavior\nis obtained. The main difference to MC techniques is\nthat the method presented here works better with decreasing temperature, while MC equilibrates faster with\nincreasing temperatures. In this sense these methods are\ncomplementary.\nWe have applied the algorithm to study the lowtemperature behavior of three-dimensional \u00b1J Ising\nspin glasses. We find that the statistical properties\nof the exponentially many ground state configurations\nare not representative of the low-temperature behavior.\nIn particular we have shown for the three-dimensional\nEdwards-Anderson model that both the distributions of\nthe overlap and of the box-overlap seem to be very narrow functions at T = 0, where only few states contribute\nto the G-B measure, and broad for finite T . Hence the\nmodel does have a complex state space, which seems to\nbecome trivial at T = 0. For this reason one is forced to\nprobe the energy landscape at T > 0. The distribution\nof the link-overlap seems to develop a second peak, but\nthe extrapolation of the asymptotic shape is beyond our\npresent computational capabilities.\n\n\f9\nAcknowledgments\n\nThe work was supported by the the Interdisziplin\u00e4res\nZentrum f\u00fcr Wissenschaftliches Rechnen in Heidelberg\n\n\u2217\n\n\u2020\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n7\n\n8\n\n9\n\nElectronic\naddress:\nhartmann@theorie.physik.unigoettingen.de\nElectronic address: Federico.Ricci@roma1.infn.it\nFor reviews on spin glasses cf.: K. Binder and A.P. Young,\nRev. Mod. Phys. 58, 801 (1986); M. Mezard, G. Parisi,\nM.A. Virasoro, Spin glass theory and beyond, World Scientific, Singapur 1987; K.H. Fisher and J.A. Hertz, Spin\nGlasses, Cambridge University Press, 1991; A.P. Young,\nSpin Glasses and Random Fields, World Scientific, 1998\nD.P. Landau and K. Binder, A Guide to Monte Carlo\nSimulations in Statistical Physics, (Cambridge University\nPress, Cambridge 2000).\nH.G. Katzgraber, M. Palassini and A.P. Young, Phys. Rev.\nB 63, 184422 (2001).\nF. Krzakala and O.C. Martin, Phys. Rev. Lett. 85, 3013\n(2000). M. Palassini and A.P. Young, Phys. Rev. Lett. 85,\n3017 (2000). E. Marinari and G. Parisi, Phys. Rev. B 62,\n11677 (2000); Phys. Rev. Lett. 86, 3887 (2001).\nFor an overview see: A.K. Hartmann and H. Rieger,\nOptimization Algorithms in Physics, (Wiley-VCH, Berlin\n2001).\nA.K. Hartmann, Eur. Phys. J. B 13, 539 (2000).\nM. Palassini and A.P. Young, Phys. Rev. B 63, 140408(R)\n(2001).\nA further analysis15 shows that the GS of this system are\norganized in two clusters, where the GS of each cluster\nare connected by zero-energy flips of single spins. The GS\nfound more often belong to one cluster, the other GS to\nthe second cluster.\nJ.J. Moreno, H.G. Katzgraber, and A.K. Hartmann, ac-\n\nand the Paderborn Center for Parallel Computing by the\nallocation of computer time. AKH acknowledges financial support from the DFG (Deutsche Forschungsgemeinschaft) under grants Ha 3169/1-1 and Zi 209/6-1.\n\n10\n11\n12\n\n13\n14\n\n15\n16\n17\n\n18\n\n19\n20\n\n21\n\n22\n23\n\n24\n\n25\n\ncepted for publication in Int. J. Mod. Phys. C, preprint\ncond-mat/0209248\nA.K. Hartmann, Physica A, 224, 480 (1996).\nK.F. P\u00e1l, Physica A 223, 283 (1996).\nZ. Michalewicz, Genetic Algorithms + Data Structures =\nEvolution Programs, Springer, Berlin 1992\nA.K. Hartmann, Phys. Rev. E 59, 84 (1999)\nA. Sandvik, Europhys. Lett. 45, 745 (1999); A.K. Hartmann, Europhys. Lett. 45, 747 (1999)\nA.K. Hartmann, J. Phys. A 33, 657 (2000).\nJ. Hoshen and R. Kopelman, Phys. Rev. B 14, 3438 (1976)\nA.K. Hartmann, Eur. Phys. J. B 8, 619 (1999); Phys. Rev.\nE 59, 84 (1999); Phys. Rev. E 60, 5135 (1999)\nOn average, systems of size L = 8 have 24.2 GS clusters.\nI.e. it is not difficult to be sure that all clusters have been\nfound.\nA.K. Hartmann, Physica A 275, 1 (1999).\nG. Hed, A. K. Hartmann and E. Domany, Europhys. Lett.\n55, 112 (2001).\nF. Krzakala and O.C. Martin, Europhys. Lett. 53, 749\n(2001)\nD.A. Huse and D.S. Fisher, J. Phys. A 20, L997 (1987)\nC.M. Newman and D.L. Stein, Phys. Rev. E 57, 1356\n(1998).\nE. Marinari, G. Parisi, F. Ricci-Tersenghi, and J.J. RuizLorenzo, J. Phys. A 31 L481, (1998).\nM.A. Moore, H. Bokil, and B. Drossel, Phys. Rev. Lett.\n81, 4252 (1998); B. Drossel, H. Bokil, M.A. Moore, and\nA.J. Bray, Eur. Phys. J. B 13, 369 (2000).\n\n\f"}