{"id": "http://arxiv.org/abs/1101.0082v1", "guidislink": true, "updated": "2010-12-30T13:15:15Z", "updated_parsed": [2010, 12, 30, 13, 15, 15, 3, 364, 0], "published": "2010-12-30T13:15:15Z", "published_parsed": [2010, 12, 30, 13, 15, 15, 3, 364, 0], "title": "Probabilistic Dynamic Logic of Phenomena and Cognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1101.1898%2C1101.1556%2C1101.4318%2C1101.4952%2C1101.5888%2C1101.2099%2C1101.3225%2C1101.3080%2C1101.5691%2C1101.0960%2C1101.5784%2C1101.2153%2C1101.1966%2C1101.4377%2C1101.1140%2C1101.3087%2C1101.1291%2C1101.4197%2C1101.1576%2C1101.3035%2C1101.4756%2C1101.5010%2C1101.5640%2C1101.5099%2C1101.0987%2C1101.1265%2C1101.0734%2C1101.2851%2C1101.2787%2C1101.1820%2C1101.3918%2C1101.0127%2C1101.4695%2C1101.5576%2C1101.1005%2C1101.4876%2C1101.4237%2C1101.1382%2C1101.0549%2C1101.0994%2C1101.0082%2C1101.5447%2C1101.5081%2C1101.4267%2C1101.0004%2C1101.4894%2C1101.5231%2C1101.2391%2C1101.2462%2C1101.1126%2C1101.6014%2C1101.0753%2C1101.3131%2C1101.5305%2C1101.0889%2C1101.4003%2C1101.1106%2C1101.0514%2C1101.0450%2C1101.2755%2C1101.3121%2C1101.5967%2C1101.0372%2C1101.4512%2C1101.5837%2C1101.0897%2C1101.3279%2C1101.1587%2C1101.1040%2C1101.1456%2C1101.6080%2C1101.3810%2C1101.4592%2C1101.0402%2C1101.3314%2C1101.5711%2C1101.0624%2C1101.3243%2C1101.0160%2C1101.0046%2C1101.0316%2C1101.0588%2C1101.3323%2C1101.0581%2C1101.3449%2C1101.3740%2C1101.4721%2C1101.5018%2C1101.0187%2C1101.2119%2C1101.0644%2C1101.4959%2C1101.0909%2C1101.3678%2C1101.4347%2C1101.0422%2C1101.2613%2C1101.3541%2C1101.0899%2C1101.0758%2C1101.0611&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Probabilistic Dynamic Logic of Phenomena and Cognition"}, "summary": "The purpose of this paper is to develop further the main concepts of\nPhenomena Dynamic Logic (P-DL) and Cognitive Dynamic Logic (C-DL), presented in\nthe previous paper. The specific character of these logics is in matching\nvagueness or fuzziness of similarity measures to the uncertainty of models.\nThese logics are based on the following fundamental notions: generality\nrelation, uncertainty relation, simplicity relation, similarity maximization\nproblem with empirical content and enhancement (learning) operator. We develop\nthese notions in terms of logic and probability and developed a Probabilistic\nDynamic Logic of Phenomena and Cognition (P-DL-PC) that relates to the scope of\nprobabilistic models of brain. In our research the effectiveness of suggested\nformalization is demonstrated by approximation of the expert model of breast\ncancer diagnostic decisions. The P-DL-PC logic was previously successfully\napplied to solving many practical tasks and also for modelling of some\ncognitive processes.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1101.1898%2C1101.1556%2C1101.4318%2C1101.4952%2C1101.5888%2C1101.2099%2C1101.3225%2C1101.3080%2C1101.5691%2C1101.0960%2C1101.5784%2C1101.2153%2C1101.1966%2C1101.4377%2C1101.1140%2C1101.3087%2C1101.1291%2C1101.4197%2C1101.1576%2C1101.3035%2C1101.4756%2C1101.5010%2C1101.5640%2C1101.5099%2C1101.0987%2C1101.1265%2C1101.0734%2C1101.2851%2C1101.2787%2C1101.1820%2C1101.3918%2C1101.0127%2C1101.4695%2C1101.5576%2C1101.1005%2C1101.4876%2C1101.4237%2C1101.1382%2C1101.0549%2C1101.0994%2C1101.0082%2C1101.5447%2C1101.5081%2C1101.4267%2C1101.0004%2C1101.4894%2C1101.5231%2C1101.2391%2C1101.2462%2C1101.1126%2C1101.6014%2C1101.0753%2C1101.3131%2C1101.5305%2C1101.0889%2C1101.4003%2C1101.1106%2C1101.0514%2C1101.0450%2C1101.2755%2C1101.3121%2C1101.5967%2C1101.0372%2C1101.4512%2C1101.5837%2C1101.0897%2C1101.3279%2C1101.1587%2C1101.1040%2C1101.1456%2C1101.6080%2C1101.3810%2C1101.4592%2C1101.0402%2C1101.3314%2C1101.5711%2C1101.0624%2C1101.3243%2C1101.0160%2C1101.0046%2C1101.0316%2C1101.0588%2C1101.3323%2C1101.0581%2C1101.3449%2C1101.3740%2C1101.4721%2C1101.5018%2C1101.0187%2C1101.2119%2C1101.0644%2C1101.4959%2C1101.0909%2C1101.3678%2C1101.4347%2C1101.0422%2C1101.2613%2C1101.3541%2C1101.0899%2C1101.0758%2C1101.0611&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The purpose of this paper is to develop further the main concepts of\nPhenomena Dynamic Logic (P-DL) and Cognitive Dynamic Logic (C-DL), presented in\nthe previous paper. The specific character of these logics is in matching\nvagueness or fuzziness of similarity measures to the uncertainty of models.\nThese logics are based on the following fundamental notions: generality\nrelation, uncertainty relation, simplicity relation, similarity maximization\nproblem with empirical content and enhancement (learning) operator. We develop\nthese notions in terms of logic and probability and developed a Probabilistic\nDynamic Logic of Phenomena and Cognition (P-DL-PC) that relates to the scope of\nprobabilistic models of brain. In our research the effectiveness of suggested\nformalization is demonstrated by approximation of the expert model of breast\ncancer diagnostic decisions. The P-DL-PC logic was previously successfully\napplied to solving many practical tasks and also for modelling of some\ncognitive processes."}, "authors": ["Evgenii Vityaev", "Boris Kovalerchuk", "Leonid Perlovsky", "Stanislav Smerdov"], "author_detail": {"name": "Stanislav Smerdov"}, "author": "Stanislav Smerdov", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/IJCNN.2010.5596833", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1101.0082v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1101.0082v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "6 pages, WCCI 2010 IEEE World Congress on Computational Intelligence\n  July, 18-23, 2010 - CCIB, Barcelona, Spain, IJCNN, IEEE Catalog Number:\n  CFP1OUS-DVD, ISBN: 978-1-4244-6917-8, pp. 3361-3366", "arxiv_primary_category": {"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1101.0082v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1101.0082v1", "journal_reference": null, "doi": "10.1109/IJCNN.2010.5596833", "fulltext": "Probabilistic Dynamic Logic of Phenomena and Cognition\n\narXiv:1101.0082v1 [cs.LO] 30 Dec 2010\n\nEvgenii Vityaev, Boris Kovalerchuk, Leonid Perlovsky, Stanislav Smerdov\nAbstract-The purpose of this paper is to develop further\nthe main concepts of Phenomena Dynamic Logic (P-DL) and\nCognitive Dynamic Logic (C-DL), presented in the previous\npaper. The specific character of these logics is in matching\nvagueness or fuzziness of similarity measures to the uncertainty\nof models. These logics are based on the following fundamental notions: generality relation, uncertainty relation, simplicity\nrelation, similarity maximization problem with empirical content\nand enhancement (learning) operator. We develop these notions\nin terms of logic and probability and developed a Probabilistic Dynamic Logic of Phenomena and Cognition (P-DL-PC)\nthat relates to the scope of probabilistic models of brain. In\nour research the effectiveness of suggested formalization is\ndemonstrated by approximation of the expert model of breast\ncancer diagnostic decisions. The P-DL-PC logic was previously\nsuccessfully applied to solving many practical tasks and also\nfor modelling of some cognitive processes.\n\nI. I NTRODUCTION\nIn the paper [1] there was introduced a Phenomena\nDynamic Logic (P-DL) and Cognitive Dynamic Logic (CDL) as a generalization of the Dynamic Logic and Neural\nModelling Fields theory (NMF) introduced in the previous\npapers [2], [3]. Logics P-DL, C-DL provide the most general\ndescription of Dynamic Logic in the following fundamental\nnotionsgenerality relation, uncertainty relation, simplicity\nrelation, similarity maximization problem with empirical\ncontent and enhancement (learning) operator. This generalization provide interpretation of P-DL, C-DL logics in the\nframe of other approaches.\nIn this paper we interpret logics P-DL, C-DL in terms of logic\nand probability: uncertainty we interpret as probability, while\nthe process of learning as a semantic probabilistic inference\n[4], [9], [6], [5]. We also interpret mentioned fundamental\nnotions. The resulting Probabilistic Dynamic Logic of Phenomena and Cognition (P-DL-PC) belong to the scope of\nthe probabilistic models of brain [19], [20]. Thus, through\nlogics P-DL, C-DL we extend the interpretation of Dynamic\nLogic and Neural Modelling Fields theory to probabilistic\nmodels of brain. The P-DL-PC logic as probabilistic model of\nbrain was previously applied to modelling of some cognitive\nprocess [7], [8], [9], [21]. The effectiveness of P-DL-PC logic\nEvgenii Vityaev is with the Department of Mathematical Logic, Sobolev\nInstitute of Mathematics of the Russian Academy of Sciences and with the\nDepartment of Discrete mathematics and Informatics of the Novosibirsk\nState University, 630090, Novosibirsk, Russia, email: vityaev@math.nsc.ru\nBoris Kovalerchuk is with the Department of Computer Science,\nCentral Washington University, Ellensburg, WA 98926-7520, e-mail:\nborisk@cwu.edu\nLeonid Perlovsky is with the Harvard University and the Air\nForce Research Laboratory, Sensors Directorate, Hanscom AFB,\nleonid@seas.harvard.edu\nStanislav Smerdov, Novosibirsk State University, Sobolev Institute of\nMathematics of the Russian Academy of Sciences, 630090, Novosibirsk,\nRussia, email: netid@ya.ru\n\ndemonstrated in this paper by approximation of the expert\nmodel of breast cancer diagnostic decisions.\nII. U NIVERSAL\n\nPRODUCTIONS .\n\nDATA FOR PREDICTION\n\nIn our study learning models will be generated as sets of\nuniversal productions (u-productions), which are introduced\nin this section. Note that every set of universal formulas is\nlogically equivalent to a certain set of u-productions.\nConsider a fixed first-order language L in a countable signature. Hereafter denote AL the set of all atoms; LL \u2013 the\nset of all literals; S0L \u2013 the set of ground sentences. The set\nof ground atoms and the set of ground literals are denoted\nA0L \u21cb AL \u2229 S0L and L0L \u21cb LL \u2229 S0L correspondingly.\nFollowing examples of atoms and literals are given in the\nsection VIII for the task of approximation of the expert\nmodel of breast cancer diagnostic decisions: 'number of\ncalcifications per cm3 less than 20', 'volume of calcifications\nin cm3 not less or equal to 5', 'total number of calcifications\nmore than 30 and etc.\nLet \u0398 be the set of all substitutions and \u03980 \u2286 \u0398 the set of\nground substitutions, that are mappings variables to ground\nterms. All necessary notions from model theory and logic\nprogramming are elementary and can be easily found in\nbooks [12], [13], [14].\nDefinition. A record of the type\n \u0303 (A1 \u2227 * * * \u2227 Am \u21d0 B1 \u2227 * * * \u2227 Bn ) ,\nR\u21cc\u2200\n \u0303 stands for\nwhere A1 , * * * Am , B1 , * * * , Bn are literals, and \u2200\na bloc of quantifiers over all free variables of the formulae\nin brackets (universal closure), is called a u-production. A\nvariant of u-production R is\n \u0303 (A1 \u03b8 \u2227 * * * Am \u03b8 \u21d0 B1 \u03b8 \u2227 * * * \u2227 Bn \u03b8) ,\nR\u03b8 \u21cb \u2200\nwhere \u03b8 is an arbitrary one-to-one correspondence over the\nset of variables. Let Prod be the set of all u-productions.\nFor example in section X presented the following uproduction that was discovered by the learning model:\nIF TOTAL number of calcifications is more than\n30, AND VOLUME is more than 5 cm3 , AND\nDENSITY of calcifications is moderate,\nTHEN Malignant.\nLet Factv \u2282 AL be a set of atoms from A that are\nvalid for verification in algebraic system B appearing in\npractice. Our aim is to investigate as much \"extra\" facts\nabout L as possible, i.e., to predict or explain them. A natural\nassumption is that we can verify (falsify) each element of\n\b\nFacto \u21cc A\u03b8 | \u03b8 \u2208 \u03980 , A \u2208 Factv .\n\n\fCertainly we may postulate our ability to check any literal\nof Fact\u2217v \u21cc Factv \u222a {\u00acA | A \u2208 Factv }. For the rest of the\nliterals (and their conjunctions) the machinery of probabilistic prediction will be defined later on. Note that Fact\u2217o =\n\u00ac\nFacto \u222a Fact\u00ac\no , where Facto \u21cb {\u00acA | A \u2208 Facto } is the\ncomplete set of alternatives allowing a real test.\nThe data are defined as a maximal (logically) consistent\nsubset of the complete set of alternatives, i.e., being given\na mapping \u03b6B : Facto 7\u2192 {\u22a5, \u22a4} (here \u22a5 \u2013 \"false\", \u22a4 \u2013\n\"true\") we conclude that\nData [B] \u21cb {A | A \u2208 Facto and \u03b6B (A) = \u22a4} \u222a\n{\u00acA | A \u2208 Facto and \u03b6B (A) = \u22a5} .\nIII. G ENERALITY RELATION BETWEEN THEORIES\nThe idea of a generality relation between theories can be\nviewed, for example, as a reduction of the set of properties\npredicted by the use of these theories. A more general theory\n(potentially) predicts a greater number of formal features.\nWe start with a generality relation between one-element\nspecifications, i.e., between u-productions.\nDefinition.\nFor\ntwo\nproductions\nR1\n\u2261\n \u0303 (A1 \u2227 * * * \u2227 Am \u21d0 B1 \u2227 * * * \u2227 Bn )\nand\nR2\n\u2261\n\u2200\n1\n1\n \u0303 (C1 \u2227 * * * \u2227 Cm \u21d0 D1 \u2227 * * * \u2227 Dn ) a relation R1 \u227b R2\n\u2200\n2\n2\n(\"more general than\") takes place if and only if there\nexists \u03b8 \u2208 \u0398 such that {B1 \u03b8, * * * , Bn1 \u03b8} \u2286 {D1 , * * * , Dn2 },\n{A1 \u03b8, * * * , Am1 \u03b8} \u2287 {C1 , * * * , Cm2 }, and n1 6 n2 ,\nm1 > m2 , 6\u22a2 R1 \u2261 R2 .\nThe inclusion of the sets of premises designates that the more\ngeneral u-production is, then the wider its field of application.\nThe inverse inclusion (for conclusions) says that R1 predicts\na greater number of properties using a smaller premise.\nLet S \u2286 Prod. Denote Fact [S; B] the set of all A \u2208 L0L\nsuch that for some R \u2208 S and \u03b8 \u2208 \u03980 ,\nR\u03b8 \u2261 (A1 \u2227 * * * \u2227 Am \u21d0 B1 \u2227 * * * \u2227 Bn ), holds\n{B1 , * * * , Bn } \u2286 Data [B] and A \u2208 {A1 , * * * , Am }.\nThus, Fact [S; B] is the set of ground literals predicted\naccording to available data (about the model B) together\nwith u-productions in S.\nIn the sequel let < be a reflexive closure of \u227b. One\nshould pay attention to the fact: R1 < R2 entails that\nFact [{R1 } ; B] contains Fact [{R2 } ; B].\nThereafter it isn't difficult to extend the domain of our\ngenerality relation to subsets of Prod.\nDefinition. Let S, S \u2032 \u2286 Prod, and for any R\u2032 \u2208 S \u2032 we find\nR \u2208 S such that R < R\u2032 . In this case we say 'S is not less\ngeneral than S \u2032 ' (S \u22b2 S \u2032 ).\nIt's straightforward to notice that Fact [S \u2032 ; B] \u2286 Fact [S; B]\nfor S and S \u2032 from the definition above. Remark that S\nmay include u-productions apart from those, which are\ngeneralizations of elements of S \u2032 .\n\nIV. P ROBABILITY / DEGREE\n\nOF BELIEF\n\nThe topic of distributing probability over formulas of propositional logic (as well as over ground statements in a first\norder language) being widely discussed in a literature and\nmeets Kolmogorov's understanding of probability measure\n[11]. The following definition is given on the basis of analysis\ncited in [10].\nDefinition. A probability over F \u2286 S0L closed with respect\nto \u2227, \u2228 and \u00ac, is a function \u03bc : F 7\u2192 [0, 1] satisfying the\nfollowing conditions:\n1) if \u22a2 \u03a6 (\"\u03a6 is a tautology\"), then \u03bc (\u03a6) = 1;\n2) if \u22a2 \u00ac (\u03a6 \u2227 \u03a8), then \u03bc (\u03a6 \u2228 \u03a8) = \u03bc (\u03a6) + \u03bc (\u03a8).\nFor any ground instance of a u-production its probability\nis defined as conditional, i.e.,\n\u03bc (A1 \u2227 * * * Am \u21d0 B1 \u2227 * * * \u2227 Bn ) =\n= \u03bc (A1 \u2227 * * * Am | B1 \u2227 * * * \u2227 Bn ) =\n\u03bc(A1 \u2227***Am \u2227B1 \u2227***\u2227Bn )\n\u03bc(B1 \u2227***\u2227Bn )\n\u03bc\n\nLet R \u2208 Prod. Denote as Sub [R] those substitutions \u03b8 \u2208\n\u0398 , for which the premise of u-production R\u03b8 has a non-zero\nprobability.\n0\n\n\u03bc\n\nProd\u03bc \u21cb {R \u2208 Prod | Sub [R] 6= \u2205};\n\u03bc\n\n\u03bc (R) \u21cb inf {\u03bc (R\u03b8) | \u03b8 \u2208 Sub [R] }, where R \u2208 Prod\u03bc .\nA value of conditional probability serves to characterize our\ndegree of belief (and responsible for an uncertainty relation)\nin reliability of different causal connections included in\ntemporary specification. Note that two productions are not\nnecessary comparable with respect to generality relation\n<; moreover, their premisses may not be contained in the\ncomplete set of alternatives (and so these productions will\nbe not valid for a direct check in a real structure B).\nV. S IMPLICITY\n\nOF PROBABILISTIC THEORIES\n\nAdding comparison of lower probabilistic estimations to\nthe definition of generality relation we obtain the following\ndefinition.\nDefinition. Let S, S \u2032 \u2286 Prod\u03bc . We say that S is more \u03bcgeneral than S \u2032 iff for every C\u2032 \u2208 S \u2032 there exists C \u2208 S\nsuch that C < C\u2032 and \u03bc(C) > \u03bc(C\u2032 ), and in at least one of\nthe cases the strong relation \u227b takes place.\nHence, \u03bc-generalization allows us to define a more general\nset S in such a way that the lower estimations of probabilities\nis not declined. When our belief to the elements of S is no\nless than that of S \u2032 , then we have a simplicity relation \u2013\nthe set S is simpler than S \u2032 in order to describe/predict the\nproperties.\nVI. S IMILARITY\n\nMEASURE WITH THE EMPIRICAL\nCONTENT\n\nBy elaboration of u-productions we mean the gain of its\nconditional probability.\n\n\fDefinition. A relation R1 \u228f R2 ('probabilistic inference')\nfor R1 , R2 \u2208 Prod\u03bc means that R1 \u227b R2 and \u03bc (R1 ) <\n\u03bc (R2 ).\nDefinition. Let \u03c0 be some requirements to be applied to\nelements of Prod\u03bc , i.e. \u03c0 : Prod\u03bc 7\u2192 {\u22a5, \u22a4} (value is\nequal to \u22a5, if u-production satisfies \u03c0, and \u22a4 \u2013 otherwise);\n\u03a0 \u21cc {R \u2208 Prod\u03bc | \u03c0 (R) = \u22a4}. We say that R2 \u2208 \u03a0 is a\nminimal follower of R1 \u2208 Prod\u03bc relative to \u228f in \u03a0 (denoted\nas R1 \u228f\u03c0 R2 ), iff R1 \u228f R2 and there is no intermediate\nu-production R3/2 \u2208 \u03a0 such that R1 \u228f R3/2 \u228f R2 .\nIn the prediction of a literal H the similarity measure for uproductions, which are valid for verification and applicable\nto the goal H, is equal to conditional probability \u03bc (*). Thus\nwe deal with a uniform measure of similarity.\nVII. L EARNING\n\nOPERATOR\n\nDefinition. A production\n \u0303 (A1 \u2227 * * * \u2227 Am \u2190 B1 \u2227 * * * \u2227 Bn )\nR\u2261\u2200\nis called a maximal specific u-production (ums-production)\nfor prediction of a conjunction H \u2261 (H1 \u2227 * * * \u2227 Hk ), where\n{H1 , * * * , Hk } \u2282 LL and m 6 k, iff the following conditions\nare satisfied:\n1) there is a substitution \u03b8 (not necessary ground)\nsuch that {A1 , * * * , Am } \u2286 {H1 \u03b8, * * * , Hk \u03b8},\n{B1 , . . . , Bn } \u2286 {B\u03b8 | B \u2208 Fact\u2217v };\n2) if D \u2208 {A1 , * * * , Am } and \u03b8o \u2208 Sub [R]\u03bc , then\n\u03bc (A1 \u03b8o \u2227 * * * \u2227 Am \u03b8o ) <\n\u03bc (A1 \u03b8o \u2227 * * * \u2227 Am \u03b8o | B1 \u03b8o \u2227 * * * \u2227 Bn \u03b8o )\nand \u03bc (D\u03b8o ) < \u03bc (D\u03b8o | B1 \u03b8o \u2227 * * * \u2227 Bn \u03b8o );\n3) there is no R\u2032 \u2208 Prod\u03bc , for which points (1\u20132) are\nhold along with R \u228f R\u2032 ;\n4) the u-production R can't be generalized up to some\nR\u2032 \u2208 Prod\u03bc satisfying all the previous points (1\u20133)\nwithout decreasing its estimation \u03bc (*).\nThe conditions above (for corresponding ums-productions)\nare denoted as 'point.i', 1 6 i 6 4.\nRemark. Though condition point.4 emphasizes the nature\nof definition, but it isn't necessary for indication. Indeed, if\nR may be generalized up to R\u2032 under preserving point.1\u2013\n3, then \u03bc (R) 6 \u03bc (R\u2032 ) (otherwise we get R\u2032 \u228f R \u2013 that\ncontradicts point.3 for R.\nLet \u03c0 (R) = \u22a4 be fulfilled for R \u2208 Prod\u03bc iff conditions\npoints.1\u20132 are satisfied for R and H (the last one is fixed\nfrom this moment); denote \u03a0 \u21cc \u03c0 \u22121 (\u22a4).\n\u03bc\nDefine the probabilistic fix-point operator T\u03c0 : 2Prod 7\u2192\n\u03bc\n2Prod as follows: for a set S \u2286 Prod\u03bc it produces\nS \u2032 \u21cc {R\u2032 | R \u228f\u03c0 R\u2032 for some R \u2208 S} \u222a\n\u222a {R | R \u2208 S \u2229 \u03a0 and there is no R\u2032 such that R \u228f\u03c0 R\u2032 }.\nTherefore the operator T\u03c0 : S 7\u2192 S \u2032 possess important\nproperties:\n1) the set S \u2032 is always more precise than S (relative to\n<);\n\n2) the conditional probabilities \u03bc (*) increase during the\nconversion to more particular cases (and so fuzziness\ndecreases);\n3) the similarity measure with the empirical content becomes greater for at least one u-production (in S) when\nthe operator converts S to S \u2032 (if not S = S \u2032 , of course);\nAs a result the operator T\u03c0 is the enhancement, or learning,\noperator in the sense of [1].\nDefinition. A fix-point (f.p., for short) S of T\u03c0 is optimal\niff there is no other f.p. S \u2032 of considered operator, which is\nmore \u03bc-general than S.\nStatement. A subset S \u2286 Prod\u03bc is a fix-point of the\noperator T\u03c0 iff every element of S satisfies points.1\u20133 for\nH.\nCorrolary. A subset S \u2286 Prod\u03bc is an optimal fix-point of\nthe operator T\u03c0 iff every element of S is a ums-production\nfor prediction of H.\nUms-productions may be viewed as a result of performing\ngeneralized scheme of the semantic probabilistic inference\n[4], [5], which is realized by the fix-point operator described\nabove. The program system 'Discovery' (see [16], [17], [9],\n[21]) was developed: it carries out the propositional version\nof the probabilistic fix-point (learning) operator and was\nsuccessfully applied to solving many practical tasks [21].\nVIII. E XTRACTION\n\nOF THE EXPERT MODEL OF BREAST\n\nCANCER DIAGNOSTIC DECISIONS\n\nWe applied our method to approximation of the expert\nmodel of breast cancer diagnostic decisions that was obtained\nfrom the radiologist J.Ruiz [17]. At first we extract this model\nfrom the expert by the special procedure using monotone\nboolean functions [17] and then apply the program system\n'Discovery' [16] to approximate this model.\nA. Hierarchical Approach\nAt first we ask an expert to describe particular cases using\nthe binary features. Then we ask a radiologist to evaluate\na particular cases, when features take on specific values. A\ntypical query will have the following format: \"If feature 1\nhas value v1 , feature 2 has value v2 , ..., feature n has value\nvn , then is a case suspicious of cancer or not?\"\nEach set of values (v1 , v2 , ..., vn ) represent a possible\nclinical case. It is practically impossible to ask a radiologist\nto generate diagnosis for thousands of possible cases. A hierarchical approach combined with the use of the property of\nmonotonicity makes the problem manageable. We construct\na hierarchy of medically interpretable features from a very\ngeneralized level to a less generalized level. This hierarchy\nfollows from the definition of the 11 medically oriented\nbinary attributes. The medical expert indicate that the original\n11 binary attributes w1 , w2 , w3 , y1 , y2 , y3 , y4 , y5 , x3 , x4 , x5\ncould be organized in terms of a hierarchy with development\nof two new generalized attributes x1 , depending on attributes\nw1 , w2 , w3 , and x2 , depending on attributes y1 , y2 , y3 , y4 , y5 .\n\n\fA new generalized feature, x1 \u2013 'Amount and volume of\ncalcifications' with grades (0 - 'benign' and 1 - 'cancer')\nwas introduced based on features: w1 \u2013 number of calcifications/cm3, w2 \u2013 volume of calcification, cm3 and w3 \u2013\ntotal number of calcifications. We view x1 as a function\ng(w1 , w2 , w3 ) to be identified. Similarly a new feature x2 \u2013\n'Shape and density of calcification' with grades: (1) for 'cancer' and (0)-'benign' generalizes features: y1 \u2013 'irregularity\nin shape of individual calcifications' y2 \u2013 'variation in shape\nof calcifications' y3 \u2013 'variation in size of calcifications' y4 \u2013\n'variation in density of calcifications' y5 \u2013 'density of calcifications'. We view x2 as a function x2 = h(y1 , y2 , y3 , y4 , y5 )\nto be identified for cancer diagnosis.\nAs result we have a decomposition of our task as follows:\nf (x1 , x2 , x3 , x4 , x5 ) =\nf (g (w1 , w2 , w3 ) , h (y1 , y2 , y3 , y4 , y5 ) , x3 , x4 , x5 ) .\nB. Monotonicity\nGiving the above definitions we can represent clinical\ncases in terms of binary vectors with five generalized features\nas: (x1 , x2 , x3 , x4 , x5 ). Let us consider two clinical cases\nthat are represented by the two binary sequences: (10110)\nand (10100). If radiologist correctly diagnose (10100) as\ncancer, then, by utilizing the property of monotonicity, we\ncan also conclude that the clinical case (10110) should\nalso be cancer. Medical expert agreed with presupposition\nabout monotonicity of the functions f (x1 , x2 , x3 , x4 , x5 ) and\nh (y1 , y2 , y3 , y4 , y5 ).\nLet us describe the interview with an expert using minimal sequence of questions to completely infer a diagnostic\nfunction using monotonicity. This sequence is based on fundamental Hansel lemma [15]. We omit a detailed description\nof the specific mathematical steps. They can be found in [18].\nTable 1 illustrates this.\nC. Expert model extraction\nColumns 2 and 3 present values of above defined\nfunctions f and h. We omit a restoration of function\ng (w1 , w2 , w3 ) because few questions are needed to restore\nthis function. All 32 possible cases with five binary features\nhx1 , x2 , x3 , x4 , x5 i are presented in column 1 in table 1. They\nare grouped and the groups are called Hansel chains [17].\nThe sequence of chains begins with the shortest chain 1 \u2013\n(01100) < (11100) for five binary features. Then largest\nchain 10 consists of 6 ordered cases: (00000) < (00001) <\n(00011) < (00111) < (01111) < (11111). The chains\nare numbered there from 1 to 10 and each case has its\nnumber in the chain, e.g., 1.2 means the second case in\nthe first chain. Asterisks in columns 2 and 3 mark answers\nobtained from an expert, e.g., 1* for case (01100) in column\n3 means that the expert answered 'yes'. The answers for\nsome other chains in column 3 are automatically obtained\nusing monotonicity. The value f(01100) = 1 for case 1.1 is\nextended for cases 1.2, 6.3. and 7.3 in this way. Similarly\nvalues of the monotone Boolean functions h are computed\nusing the table 1. The attributes in the sequence (10010)\n\nare interpreted as y1 , y2 , y3 , y4 , y5 for the function h instead\nof x1 , x2 , x3 , x4 , x5 . The Hansel chains are the same if the\nnumber of attributes is the same five in this case.\nColumn 5 and 6 list cases for extending functions' values\nwithout asking an expert. Column 5 is for extending functions' values from 1 to 1 and column 6 is for extending them\nfrom 0 to 0. If an expert gave an answer opposite (f(01100) =\n0) to that presented in table 1 for function f in the case 1.1,\nthen this 0 value could be extended in column 2 for cases 7.1\n(00100) and 8.1 (01000). These cases are listed in column\n5 for case (01100). There is no need to ask an expert about\ncases 7.1 (00100) and 8.1 (01000). Monotonicity provides\nthe answer. The negative answer f(01100) = 0 can not be\nextended for f(11100). An expert should be queried regarding\nf(11100). If his/her answer is negative f(11100) = 0 then this\nvalue can be extended for cases 5.1. and 3.1 listed in column\n5 for case 1.2. Relying on monotonicity, the value of f for\nthem will also be 0.\nThe total number of cases with asterisk (*) in columns\n2 and 3 are equal to 13 and 12. These numbers show\nthat 13 questions are needed to restore the function\nf (x1 , x2 , x3 , x4 , x5 ) and 12 questions are needed to restore\nthe function h (y1 , y2 , y3 , y4 , y5 ). This is only 37.5% of 32\npossible questions. The full number of questions for the\nexpert without monotonicity and hierarchy is 211 = 2048.\nIX. A PPROXIMATION\n\nOF THE EXPERT MODEL BY\n\nLEARNING OPERATOR\n\nFor the Approximation of the expert model we used the\nprogram system 'Discovery' [16], that realizes the propositional case of the probabilistic fix-point learning operator.\nWe discovered several dozens diagnostic rules that were\nstatistically significant on the 0.01, 0.05 and 0.1 levels\nof (F-criterion). Rules were extracted using 156 cases (73\nmalignant, 77 benign, 2 highly suspicious and 4 with mixed\ndiagnosis). In the Round-Robin test our rules diagnosed 134\ncases and refused to diagnose 22 cases. The total accuracy\nof diagnosis is 86%. Incorrect diagnoses were obtained in\n19 cases (14% of diagnosed cases). The false-negative rate\nwas 5.2% (7 malignant cases were diagnosed as benign)\nand the false-positive rate was 8.9% (12 benign cases were\ndiagnosed as malignant). Some of the rules are shown in table\n2. This table presents examples of discovered rules with their\nstatistical significance. In this table:\n3\n\u2022 'NUM' \u2013 number of calcifications per cm ;\n3\n\u2022 'VOL' \u2013 volume in cm ;\n\u2022 'TOT' \u2013 total number of calcifications;\n\u2022 'DEN' \u2013 density of calcifications;\n\u2022 'VAR' \u2013 variation in shape of calcifications;\n\u2022 'SIZE' \u2013 variation in size of calcifications;\n\u2022 'IRR' \u2013 irregularity in shape of calcifications;\n\u2022 'SHAPE' \u2013 shape of calcifications.\nWe studied three levels of similarity measure: 0.7, 0.85\nand 0.95. A higher level of conditional probability decreases\nthe number of rules and diagnosed patients, but increases\naccuracy of diagnosis.\n\n\f1\nNumber\n(01100)\n(11100)\n(01010)\n(11010)\n(11000)\n(11001)\n(10010)\n(10110)\n(10100)\n(10101)\n(00010)\n(00110)\n(01110)\n(11110)\n(00100)\n(00101)\n(01101)\n(11101)\n(01000)\n(01001)\n(01011)\n(11011)\n(10000)\n(10001)\n(10011)\n(10111)\n(00000)\n(00001)\n(00011)\n(00111)\n(01111)\n(11111)\nQuestions\n\nTable 1. Dynamic sequence of questions to expert\n2\n3\n4\n5\n6\nf\nh\nMonotonic extrapolation\nChain\nDiagnose Form and V\n1 7\u2192 1\n0 7\u2192 0\n1*\n1*\n1.2, 6.3, 7.3\n7.1, 8.1\nChain 1\n1\n1\n6.4, 7.4\n5.1, 3.1\n0*\n1*\n2.2, 6.3, 8.3\n6.1, 8.1\nChain 2\n1*\n1\n6.4, 8.4\n3.1, 6.1\n1*\n1*\n3.2\n8.1, 9.1\nChain 3\n1\n1\n7.4, 8.4\n8.2, 9.2\n0*\n1*\n4.2, 9.3\n6.1, 9.1\nChain 4\n1*\n1\n6.4, 9.4\n6.2, 5.1\n1*\n1*\n5.2\n7.1, 9.1\nChain 5\n1\n1\n7.4, 9.4\n7.2, 9.2\n0\n0*\n6.2, 10.3\n10.1\nChain 6\n1*\n0*\n6.3, 10.4\n7.1\n1\n1\n6.4, 10.5\n1\n1\n10.6\n1*\n0*\n7.2, 10.4\n10.1\nChain 7\n1\n0*\n7.3, 10.4\n10.2\n1\n1*\n7.4, 10.5\n8.2, 10.2\n1\n1\n5.6\n0\n1*\n8.2\n10.1\nChain 8\n1*\n1\n8.3\n10.2\n1\n1\n8.4\n10.3\n1\n1\n10.6\n9.3\n0\n1*\n9.2\n10.1\nChain 9\n1*\n1\n9.3\n10.2\n1\n1\n9.4\n10.3\n1\n1\n10.6\n10.4\n0\n0\n10.2\nChain 10\n0*\n0\n10.3\n1*\n0\n10.4\n1\n1*\n10.5\n1\n1\n10.6\n1\n1\n13\n12\n\nTable 2. Examples of discovered diagnostic rules\nDiagnosis\nf -criteria\nValue. f -criteria Precision\nrule\n0.01 0.05 0.1 on control\nIf 10 < NUM < 20\nNUM\n0.0029\n+\n+\n+\n93.3%\nand VOL > 5\nVOL\n0.0040\n+\n+\n+\nthen malignant\nIf TOT > 30\nTOT\n0.0229\n+\n+\n100.0%\nand VOL > 5\nVOL\n0.0124\n+\n+\nand DEN is moderate\nDEN\n0.0325\n+\n+\nthen malignant\nIf VAR is marked\nVAR\n0.0044\n+\n+\n+\n100.0%\nand 10 < NUM < 20\nNUM\n0.0039\n+\n+\n+\nand IRR is moderate\nIRR\n0.0254\n+\n+\nthen malignant\nIf SIZE is moderate\nSIZE\n0.0150\n+\n+\n92.86%\nand SHAPE is mild\nSHAPE 0.0114\n+\n+\nand IRR is mild\nIRR\n0.0878\n+\nthen benign\n\n7\nCase\n1.1\n1.2\n2.1\n2.2\n3.1\n3.2\n4.1\n4.2\n5.1\n5.2\n6.1\n6.2\n6.3\n6.4\n7.1\n7.2\n7.3\n7.4\n8.1\n8.2\n8.3\n8.4\n9.1\n9.2\n9.3\n9.4\n10.1\n10.2\n10.3\n10.4\n10.5\n10.6\n\n\fResults for them are marked as Discovery1, Discovery2\nand Discovery3. We extracted 44 statistically significant\ndiagnostic rules for 0.05 level of F -criterion with a conditional probability no less than 0.75 (Discovery1). There\nwere 30 rules with a conditional probability no less than\n0.85 (Discovery2) and 18 rules with a conditional probability\nno less than 0.95 (Discovery3). The most reliable 30 rules\ndelivered a total accuracy of 90%, and the 18 most reliable\nrules performed with 96.6% accuracy with only 3 false\npositive cases (3.4%).\nX. D ECISION\n\nRULE ( MODEL ) EXTRACTED FROM THE\n\nEXPERT THROUGH MONOTONE\n\nB OOLEAN\n\nFUNCTIONS\n\nWe obtained Boolean expressions for function\nh (y1 , y2 , y3 , y4 , y5 ) ('shape and density of calcification')\nfrom the information depicted in table 1 with the following\nsteps:\n- Find all the maximal lower units for all chains as\nelementary conjunctions;\n- Take the disjunction of obtained conjunctions;\n- Exclude the redundant terms (conjunctions) from the\nend formula.\nUsing 1 and 3 columns we have\nx2 = h (y1 , y2 , y3 , y4 , y5 ) = y2 y3 \u2228y2 y4 \u2228y1 y2 \u2228y1 y4 \u2228y1 y3 \u2228\n\u2228y2 y3 y5 \u2228 y2 \u2228 y1 \u2228 y3 y4 y5 \u2261 y2 \u2228 y1 \u2228 y3 y4 y5 .\nFunction g (w1 , w2 , w3 ) = w2 \u2228 w1 w3 we may obtain by\ndirect 23 = 8 questions for the expert.\nUsing 1 and 2 columns we have\nf (x) = x2 x3 \u2228 x1 x2 x4 \u2228 x1 x2 \u2228 x1 x3 x4 \u2228 x1 x3 \u2228 x3 x4 \u2228 x3\n\u2228x2 x5 \u2228 x1 x5 \u2228 x4 x5 \u2261 x1 x2 \u2228 x3 \u2228 (x2 x1 x4 ) x5 \u2261\n(w2 \u2228 w1 w3 ) (y1 \u2228 y2 \u2228 y3 y4 y5 ) \u2228 x3 \u2228\n\u2228 (y1 \u2228 y2 \u2228 y3 y4 y5 ) (w2 \u2228 w1 w3 ) x4 x5 .\nXI. C OMPARISON\n\nOF THE EXPERT MODEL WITH ITS\nAPPROXIMATION BY LEARNING OPERATOR\n\nFor compare rules discovered by the learning operator\n(Discovery system) with the expert model we asked the\nexpert to evaluate this rules. Below we present some rules,\ndiscovered by Discovery system, and radiologists comments\nregarding these rules as approximation of his model.\nIF TOTAL number of calcifications is more than\n30, AND VOLUME is more than 5 cm3 , AND\nDENSITY of calcifications is moderate,\nTHEN Malignant.\nf -criterion significant for 0.05. Accuracy of diagnosis for\ntest cases \u2013 100%. Radiologist's comment - this rule might\nhave promise, but I would consider it risky.\nIF VARIATION in shape of calcifications is\nmarked, AND NUMBER of calcifications is between 10 and 20, AND IRREGULARITY in shape\nof calcifications is moderate,\nTHEN Malignant.\n\nf -criterion significant for 0.05. Accuracy of diagnosis for\ntest cases \u2013 100%. Radiologist's comment - I would trust\nthis rule.\nIF variation in SIZE of calcifications is moderate,\nAND variation in SHAPE of calcifications is mild,\nAND IRREGULARITY in shape of calcifications\nis mild, THEN Benign.\nf -criterion significant for 0.05. Accuracy of diagnosis for\ntest cases \u2013 92.86%. Radiologist's comment - I would trust\nthis rule.\nACKNOWLEDGMENT\nThis work partially supported by the Russian Science\nFoundation grant 08-07-00272a and Integration projects of\nthe Siberian Division of the Russian Academy of science\ngrants 47, 111, 119.\nR EFERENCES\n[1] Kovalerchuk B. Ya., Perlovsky L. I. Dynamic logic of phenomena and\ncognition. IJCNN, 2008, pp. 3530\u20133537.\n[2] Perlovsky L. I. Toward physics of the mind: concepts, emotions,\nconsciousness, and symbols // Physics of Life Reviews, 3, 2006,\npp. 23\u201355.\n[3] Perlovsky L. I. Neural Networks, Fuzzy Models and Dynamic Logic //\nR. Kohler and A. Mehler, eds., Aspects of Automatic Text Analysis\n(Festschrift in Honor of Burghard Rieger), Springer, Germany, 2007,\npp. 363-386.\n[4] Vityaev E. E. The logic of prediction // Mathematical Logic in Asia\n2005, Proceedings of the 9th Asian Logic Conference, eds. Goncharov S.S., Downey R. and Ono H., August 16\u201319, Novosibirsk,\nRussia, World Scientific Publisher, 2006, pp. 263\u2013276.\n[5] Smerdov S. O., Vityaev E. E. Probability, logic & learning synthesis:\nformalizing prediction concept // Siberian Electronic Mathematical\nReports, vol. 9, 2009, pp. 340\u2013365., in russian, english abstract.\n[6] Vityaev E. E., Smerdov S. O. New definition of prediction without logical inference // Proceedings of the IASTED international conference on\nComputational Intelligence (CI 2009), ed. Kovalerchuk B. Ya., August\n17-19, Honolulu, Hawaii, USA, pp. 48\u201354.\n[7] Evgenii Vityaev, Principals of brain activity, supported the functional\nsystems theory by P.K. Anokhin and emotional theory by P.V. Simonov, Neiroifformatics, v.3, N1, 2008, pp. 25-78\n[8] Akexander Demin, Evgenii Vityaev, Logical model of adaptive control\nsystem. Neiroifformatics, v.3, N1, 2008, pp. 79-107\n[9] Evgenii Vityaev. Knowledge discovery. Computational cognition. Cognitive processes modeling. Novosibirsk State University, Novosibirsk,\n2006. pp.293.\n[10] Halpern J. Y. An analysis of first-order logics of probability. In:\nArtificial Intelligence, 46, 1990, pp. 311\u2013350.\n[11] Shiryaev A. N. Probability. Springer, 1995.\n[12] Keisler H. J., Chang C. C. Model theory. Elsevier, 1990.\n[13] Maltsev A. I. Algebraic systems. Springer-Verlag, 1973.\n[14] Lloyd J.W. Foundations of logic programming. Springer-Verlag, 1987.\n[15] Hansel G. Sur le nombre des fonctions Boolenes monotones den\nvariables // C. R. Acad. Sci. Paris, vol. 262, 20, 1966, pp. 1088\u2013\n1090.\n[16] Kovalerchuk B. Ya., Vityaev E. E. Data mining in finance: advances\nin relational and hybrid methods. Kluwer Academic Publisher, 2000.\n[17] Kovalerchuk B. Ya., Vityaev E. E., Ruiz J. F. Consistent and complete\ndata and \"expert\" mining in medicine // Medical data mining and\nknowledge discovery, Springer, 2001, pp. 238\u2013280.\n[18] Kovalerchuk B, Talianski V. Comparison of empirical and computed\nfuzzy values of conjunction. Fuzzy Sets and Systems 46: 49-53, 1992.\n[19] The Probabilistic Mind. Prospects for Bayesian cognitive sciense //\nEds. Nick Chater, Mike Oaksford, Oxfor University Press, 2008,\npp.536\n[20] Probabilistic models of cognition // Special issue of the journal Trends\nin cognitive science, v.10, Issue 7, 2006, pp. 287-344\n[21] Scientific Discovery website.\nhttp://math.nsc.ru/AP/ScientificDiscovery\n\n\f"}