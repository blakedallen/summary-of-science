{"id": "http://arxiv.org/abs/math/0702126v1", "guidislink": true, "updated": "2007-02-06T19:28:54Z", "updated_parsed": [2007, 2, 6, 19, 28, 54, 1, 37, 0], "published": "2007-02-06T19:28:54Z", "published_parsed": [2007, 2, 6, 19, 28, 54, 1, 37, 0], "title": "On rates of convergence for posterior distributions under\n  misspecification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0702888%2Cmath%2F0702185%2Cmath%2F0702034%2Cmath%2F0702667%2Cmath%2F0702865%2Cmath%2F0702778%2Cmath%2F0702677%2Cmath%2F0702119%2Cmath%2F0702054%2Cmath%2F0702665%2Cmath%2F0702496%2Cmath%2F0702352%2Cmath%2F0702482%2Cmath%2F0702157%2Cmath%2F0702682%2Cmath%2F0702040%2Cmath%2F0702467%2Cmath%2F0702574%2Cmath%2F0702198%2Cmath%2F0702048%2Cmath%2F0702151%2Cmath%2F0702259%2Cmath%2F0702116%2Cmath%2F0702044%2Cmath%2F0702293%2Cmath%2F0702494%2Cmath%2F0702148%2Cmath%2F0702708%2Cmath%2F0702424%2Cmath%2F0702377%2Cmath%2F0702211%2Cmath%2F0702235%2Cmath%2F0702683%2Cmath%2F0702117%2Cmath%2F0702491%2Cmath%2F0702691%2Cmath%2F0702656%2Cmath%2F0702291%2Cmath%2F0702726%2Cmath%2F0702279%2Cmath%2F0702523%2Cmath%2F0702257%2Cmath%2F0702164%2Cmath%2F0702802%2Cmath%2F0702469%2Cmath%2F0702452%2Cmath%2F0702661%2Cmath%2F0702515%2Cmath%2F0702738%2Cmath%2F0702617%2Cmath%2F0702600%2Cmath%2F0702358%2Cmath%2F0702126%2Cmath%2F0702278%2Cmath%2F0702528%2Cmath%2F0702729%2Cmath%2F0702651%2Cmath%2F0702433%2Cmath%2F0702139%2Cmath%2F0702186%2Cmath%2F0702073%2Cmath%2F0702345%2Cmath%2F0702641%2Cmath%2F0702368%2Cmath%2F0702798%2Cmath%2F0702381%2Cmath%2F0702091%2Cmath%2F0702549%2Cmath%2F0702383%2Cmath%2F0702042%2Cmath%2F0702666%2Cmath%2F0702108%2Cmath%2F0702419%2Cmath%2F0702707%2Cmath%2F0702150%2Cmath%2F0702418%2Cmath%2F0702710%2Cmath%2F0702359%2Cmath%2F0702406%2Cmath%2F0702411%2Cmath%2F0702434%2Cmath%2F0702580%2Cmath%2F0702706%2Cmath%2F0702339%2Cmath%2F0702344%2Cmath%2F0702745%2Cmath%2F0702695%2Cmath%2F0702462%2Cmath%2F0702422%2Cmath%2F0702071%2Cmath%2F0702297%2Cmath%2F0702410%2Cmath%2F0702187%2Cmath%2F0702488%2Cmath%2F0702850%2Cmath%2F0702881%2Cmath%2F0702532%2Cmath%2F0702007%2Cmath%2F0702769%2Cmath%2F0702829%2Cmath%2F0702405&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On rates of convergence for posterior distributions under\n  misspecification"}, "summary": "We extend the approach of Walker (2003, 2004) to the case of misspecified\nmodels. A sufficient condition for establishing rates of convergence is given\nbased on a key identity involving martingales, which does not require\nconstruction of tests. We also show roughly that the result obtained by using\ntests can also be obtained by our approach, which demonstrates the potential\nwider applicability of this method.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0702888%2Cmath%2F0702185%2Cmath%2F0702034%2Cmath%2F0702667%2Cmath%2F0702865%2Cmath%2F0702778%2Cmath%2F0702677%2Cmath%2F0702119%2Cmath%2F0702054%2Cmath%2F0702665%2Cmath%2F0702496%2Cmath%2F0702352%2Cmath%2F0702482%2Cmath%2F0702157%2Cmath%2F0702682%2Cmath%2F0702040%2Cmath%2F0702467%2Cmath%2F0702574%2Cmath%2F0702198%2Cmath%2F0702048%2Cmath%2F0702151%2Cmath%2F0702259%2Cmath%2F0702116%2Cmath%2F0702044%2Cmath%2F0702293%2Cmath%2F0702494%2Cmath%2F0702148%2Cmath%2F0702708%2Cmath%2F0702424%2Cmath%2F0702377%2Cmath%2F0702211%2Cmath%2F0702235%2Cmath%2F0702683%2Cmath%2F0702117%2Cmath%2F0702491%2Cmath%2F0702691%2Cmath%2F0702656%2Cmath%2F0702291%2Cmath%2F0702726%2Cmath%2F0702279%2Cmath%2F0702523%2Cmath%2F0702257%2Cmath%2F0702164%2Cmath%2F0702802%2Cmath%2F0702469%2Cmath%2F0702452%2Cmath%2F0702661%2Cmath%2F0702515%2Cmath%2F0702738%2Cmath%2F0702617%2Cmath%2F0702600%2Cmath%2F0702358%2Cmath%2F0702126%2Cmath%2F0702278%2Cmath%2F0702528%2Cmath%2F0702729%2Cmath%2F0702651%2Cmath%2F0702433%2Cmath%2F0702139%2Cmath%2F0702186%2Cmath%2F0702073%2Cmath%2F0702345%2Cmath%2F0702641%2Cmath%2F0702368%2Cmath%2F0702798%2Cmath%2F0702381%2Cmath%2F0702091%2Cmath%2F0702549%2Cmath%2F0702383%2Cmath%2F0702042%2Cmath%2F0702666%2Cmath%2F0702108%2Cmath%2F0702419%2Cmath%2F0702707%2Cmath%2F0702150%2Cmath%2F0702418%2Cmath%2F0702710%2Cmath%2F0702359%2Cmath%2F0702406%2Cmath%2F0702411%2Cmath%2F0702434%2Cmath%2F0702580%2Cmath%2F0702706%2Cmath%2F0702339%2Cmath%2F0702344%2Cmath%2F0702745%2Cmath%2F0702695%2Cmath%2F0702462%2Cmath%2F0702422%2Cmath%2F0702071%2Cmath%2F0702297%2Cmath%2F0702410%2Cmath%2F0702187%2Cmath%2F0702488%2Cmath%2F0702850%2Cmath%2F0702881%2Cmath%2F0702532%2Cmath%2F0702007%2Cmath%2F0702769%2Cmath%2F0702829%2Cmath%2F0702405&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We extend the approach of Walker (2003, 2004) to the case of misspecified\nmodels. A sufficient condition for establishing rates of convergence is given\nbased on a key identity involving martingales, which does not require\nconstruction of tests. We also show roughly that the result obtained by using\ntests can also be obtained by our approach, which demonstrates the potential\nwider applicability of this method."}, "authors": ["Heng Lian"], "author_detail": {"name": "Heng Lian"}, "author": "Heng Lian", "arxiv_comment": "8 pages, no figures", "links": [{"href": "http://arxiv.org/abs/math/0702126v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0702126v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0702126v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0702126v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0702126v1 [math.ST] 6 Feb 2007\n\n1\n\nOn rates of convergence for posterior distributions\nunder misspecification\nBy HENG LIAN\n182 George St, Division of Applied Mathematics, Brown University,\nProvidence, RI, 02912 USA.\nHeng Lian@brown.edu\n\nSUMMARY\nWe extend the approach of Walker (2003, 2004) to the case of misspecified models.\nA sufficient condition for establishing rates of convergence is given based on a key\nidentity involving martingales, which does not require construction of tests. We also\nshow roughly that the result obtained by using tests can also be obtained by our\napproach, which demonstrates the potential wider applicability of this method.\nSome key words: \u03b1-covering; Bayesian nonparametrics; Prior misspecification.\n\n1\n\nINTRODUCTION\n\nBayesian inference distinguishes itself from the frequentist school by its explicit quantification of uncertainty of the parameter with prior specification. The classical approach uses subjective priors elicited from field experts and domain knowledge. The\nmodern Bayesian school have instead shifted attention more towards the construction\nof priors using formal rules in the hope of dealing with arbitrariness of the prior.\nAsymptotics for infinite-dimensional Bayesian statistics has been receiving a lot\nof attention recently. In these studies, the Bayesian inference is approached from a\nfrequentist point of view, that is, we assume there is a true underlying probability\ndistribution that generates the data. Naturally one desired property is that as more\nand more observations are made from the underlying generating mechanism, we will\nobtain accurate estimate of the true distribution. While traditional Bayesians do not\nbelieve in such an assumption, it is shown by Blackwell & Dubins (1962) that this\nproperty is the same as intersubjective agreement, which means two Bayesians will\neventually come to roughly the same conclusion after seeing enough data.\nThe posterior distribution typically behaves well under regular parametric models.\nDoob showed that consistency is achieved under almost no assumptions on the model,\nexcept for a zero measure set under the prior, although in topological terms this set\ncan be large. For infinite-dimensional models, however, the matter is more subtle.\nStrange behavior can be observed under some priors as documented in Diaconis &\n\n\f2\nFreeman (1986). Given the prior \u03a0 on the set P of probability distribution, the\nposterior is a random measure:\nR Qn\np(Xi )d\u03a0(P )\n\u03a0n (B|X1 , . . . , Xn ) = RBQni=1\ni=1 p(Xi )d\u03a0(P )\n\nFor ease of notation, we will omit the conditioning and only write \u03a0n (B) for the\nposterior distribution. We say that the posterior is consistent if\n\u03a0n (P \u2208 P : d(P, P0) > \u01eb) \u2192 0 in P0n probability.\nwhere P0 is the true distribution and d is some suitable distance function between\nprobability measures.\nTo study rates of convergence, let \u01ebn be a sequence decreasing to zero, we say the\nrate is at least \u01ebn if for sufficiently large constant M\n\u03a0n (P : d(P, P0) \u2265 M\u01ebn ) \u2192 0 in P0n probability.\n\nWe can also have a slightly weaker definition of rates of convergence by replacing M\nwith a sequence Mn and requiring that the above posterior mass converge to zero for\nany sequence Mn that diverges to infinity.\nOn the positive side, Schwartz (1965) shows consistency for specific distributions\nby constructing a sequence of tests of the true distribution against distributions some\npositive distance away. The tests can trivially be constructed for weak neighborhoods.\nThe construction of similar tests for stronger topology (typically measured in Hellinger\ndistance, for example) is not so straightforward and requires extra works. Barron et\nal. (1999) gives sufficient conditions that guarantee consistency of infinite-dimensional\nmodels by bounding the likelihood ratio under bracketing entropy constraint on sieves.\nShen & Wasserman (2001) studied rates of convergence. A related approach by\nconstructing a sequence of tests appeared in Ghosal et al. (2000).\nThe conditions imposed in the above are sufficient but not necessary. It is important to see to what extent these conditions can be relaxed. Another line of work\nparallel to the development above by Stephen Walker and his collaborators proves\nconsistency and rates of convergence under slightly less stringent conditions. These\nresults are established by constructing a certain supermartingale and consistency and\nrates of convergence is shown by focusing on the distance of certain predictive distributions to the true one. This approach does not require construction of sequence\nof tests or sieves. It is shown that this new approach can lead to somewhat weaker\nsufficient conditions or faster rates.\nIn Kleijn & van der Vaart (2006), the authors consider the situation where one\ncannot expect to achieve consistency since the prior is misspecified. In this case, it\nis not surprising that the posterior will converge to the distribution in the support\nof the prior that is closest to the true distribution measured in Kullback-Leibler\ndivergence. Instead of using the usual entropy number or its local version, they used\na new concept called covering number for testing under misspecification and studied\nrates by constructing a sequence of tests between the true distribution P0 and another\n\n\f3\nmeasure that is not necessarily a probability distribution. The new entropy number\ncan be reduced to the usual entropy in the well-specified case. In this paper, we study\nthe posterior distribution also under the misspecified situation, without constructing\na sequence of tests.\nThe goal of this paper is two fold. First, we show that the approach in Walker(2003,\n2004) can be extended to the situation of misspecified prior rather straightforwardly,\nby introducing an \u03b1-entropy condition that is slightly stronger than that of Kleijn &\nvan der Vaart (2006). Second, we show that using a more refined analysis, a result\nsimilar to Theorem 2.2 in Kleijn & van der Vaart (2006) can be recovered. In particular, it shows that under the well-specified case, this approach indeed is more general\nthan the approach of constructing a sequence of tests.\nIn \u00a72, we introduce necessary notations and concepts and present the martingale\nconstruction due to Walker (2003). In \u00a73, we prove the main result and show that\nthis approach is somehow more general than the one presented in Kleijn & van der\nVaart (2006). We end this paper with a discussion in \u00a74.\n\n2\n\nPRELIMINARIES\n\nLet {X1 , X2 , . . .} be independent samples generated from distribution P0 , with corresponding lower case letter p0 denoting the density with respect to some dominating\nmeasure \u03bc. We are given a collection of distributions P, and a prior \u03a0 on it with\n\u03a0(P) = 1. For simplicity, we assume that there exists a unique distribution P \u2217 \u2208 P\nthat achieves minimum value of Kullback-Leibler divergence to the true distribution,\nthat is\nE0 (log\n\np0\np0\n) \u2264 E0 (log ), for all p \u2208 P\n\u2217\np\np\n\nwhere E0 denotesQthe expectation under the true distribution P0 .\nLet Rn (p) = ni=1 p(Xi )/p\u2217 (Xi ), then the posterior mass for a set B is\nR\nRn (p)\u03a0(P )\n\u03a0n (B) = RB\nRn (p)\u03a0(P )\n\n(1)\n\nFollowing Kleijn & van der Vaart (2006), for \u01eb > 0, 0 < \u03b1 < 1 and some suitable\nsemi-metric d on P, we define the \u03b1-covering of the set A = {P \u2208 P : d(P, P \u2217) \u2265 \u01eb}\nas a collection of convex sets {A1 , A2 , . . .} that covers A with the additional property\nthat for any j,\np \u03b1 \u01eb2\ninf \u2212 log E0 ( \u2217 ) \u2265\nP \u2208Aj\np\n4\n\n(2)\n\nand denote by Nt (\u01eb, \u03b1, A) the minimum integer N such that there exists {A1 , . . . , AN }\nthat forms such a cover, if N is finite.\nThis condition appears to be stronger than the concept of covering for testing under misspecification introduced by Kleijn & van der Vaart (2006), which only requires\n\n\f4\nthat\ninf sup \u2212 log E0 (\n\nP \u2208Aj 0<\u03b1<1\n\np \u03b1 \u01eb2\n) \u2265\np\u2217\n4\n\n(3)\n\nIn all the examples they gave in their paper, though, we can find a certain value of\n\u03b1 only depending on the specification of the model that satisfies our condition. As\nshown in Kleijn & van der Vaart (2006), when P is convex, we have d2 (P, P \u2217) \u2264\n\u2212 log E0 (p/p\u2217 )1/2 where d is a generalized Hellinger distance defined by d2 (P1 , P2 ) =\nR 1/2\n1/2\n1\n(p1 \u2212 p2 )2 p0 /p\u2217 d\u03bc, which reduces to the usual Hellinger distance in the well2\nspecified case. In this situation, the 1/2-covering for testing can be replaced by the\nusual covering as shown in Kleijn & van der Vaart (2006). In general, allowing \u03b1 to\nbe different than 1/2 is required, since in the misspecified case, we cannot guarantee\nthat \u2212 log E0 (p/p\u2217 )1/2 > 0, and we are obliged to choose some smaller \u03b1 in order to\nfind the covering.\nThe predictive density constrained to a general set A is defined as\nZ\npnA (x) =\np(x)\u03a0nA (P )\nA\n\n, where \u03a0nA (P ) = 1{P \u2208A} \u03a0n (P )/\u03a0n (A) is the posterior measure conditioned on A.\nThe key identity noted by Walker (2003) is the following:\nZ\nZ\npnA (Xn+1 )\nRn (p)\u03a0(P )\nRn+1 (p)\u03a0(P ) = \u2217\np (Xn+1 ) A\nA\nas can be verified easily. This in turn implies that\nZ\nZ\npnA\n\u03b1\nE0 [( Rn+1 (p)\u03a0(P )) |X1 , . . . , Xn ] = ( Rn (p)\u03a0(P ))\u03b1 E0 ( \u2217 )\u03b1\np\nA\nA\nR\nwhich means that A Rn (p)\u03a0(P ) is a supermartingale when E0 (pnA /p\u2217 )\u03b1 < 1.\n\n3\n\n(4)\n\nRATES OF CONVERGENCE\n\nTo study rates of convergence, for a sequence \u01ebn \u2192 0, we let An = {P \u2208 P :\nd(P, P \u2217) \u2265 M\u01ebn }, and let An,j be an \u03b1-covering of An , i.e., {An,j } are convex sets\nthat covers An and\ninf \u2212 log E0 (\n\nP \u2208An,j\n\nDefine\n(n)\nLk,j\n\n=\n\nand\nIn =\n\nZ\n\np \u03b1 M 2 \u01eb2n\n) \u2265\np\u2217\n4\nRk (p)\u03a0(P )\n\nAn,j\n\nZ\n\nRn (p)\u03a0(P )\nP\n\n(5)\n\n\f5\nTo obtain a lower bound for In , which is the denominator in (1), we also need a\ncondition on the prior mass for a Kullback-Leibler neighborhood of p\u2217 , which is defined\nas\np\np\nB(\u01eb, P \u2217 ; P0 ) = {P \u2208 P : \u2212E0 (log \u2217 ) \u2264 \u01eb2 , E0 (log \u2217 )2 \u2264 \u01eb2 }\np\np\nTheorem 1 Assume that P \u2217 is the unique minimizer in P of the Kullback-Leibler\ndivergence to the true distribution with E0 (log(p0 /p\u2217 )) < \u221e. For a sequence \u01ebn such\nthat \u01ebn \u2192 0 and n\u01eb2n \u2192 \u221e, and An , An,j defined as above. If the following conditions\nhold\nP\n1) e\u2212n\u01ebn K j (An,j )\u03b1 for a sufficiently large constant K\n2\n2) \u03a0(B(\u01ebn , P \u2217 ; P0 )) \u2265 e\u2212Ln\u01ebn for a sufficiently large constant L\nthen \u03a0n (P : d(P, P \u2217) \u2265 M\u01ebn ) \u2192 0 in P0n probability.\nProof. First we observe that PnAn,j \u2208 An,j by the convexity of An,j . From the\ndefinition of \u03b1-covering, inf P \u2208An,j \u2212 log E0 (p/p\u2217 )\u03b1 \u2265 M 2 \u01eb2n /4, so the predictive density\nsatisfies\npnA\n2 2\nE0 ( \u2217n,j )\u03b1 \u2264 e\u2212M \u01ebn /4\np\nTaking expectations in (4), with A replaced by An,j , we get\n(n)\n\n(n)\n\nE0 (Lk+1,j )\u03b1 \u2264 E0 (Lk,j )\u03b1 e\u2212M\n\n2 \u01eb2 /4\nn\n\nand hence\n(n)\n\nE0 (Ln,j )\u03b1 \u2264 e\u2212nM\n\n2 \u01eb2 /4\nn\n\n(\u03a0(An,j ))\u03b1\n\nThe posterior distribution can be bounded as follows:\nX\n\u03a0n (An,j )\n\u03a0n (An ) \u2264\nj\n\n\u2264\n\nX\nj\n\n[\u03a0n (An,j )]\u03b1 =\n\n\u03b1\nX (L(n)\nn,j )\n\nIn\u03b1\n\nj\n\nLemma 7.1 in Kleijn & van der Vaart (2006) shows that when n\u01eb2n \u2192 \u221e, for every\n2\nC > 0, on a set \u03a9n with probability converging to 1, we have In \u2265 \u03a0(B(\u01ebn , P \u2217 ; P0 ))e\u2212n\u01ebn(1+C) ,\nso we can write\nE0 (\u03a0n (An )) = E0 (\u03a0n (An )1\u03a9n ) + E0 (\u03a0n (An )1\u03a9cn )\nP (n)\nE0 j (Ln,j )\u03b1\n+ P0 (\u03a9cn )\n\u2264\n\u03a0(B(\u01ebn , P \u2217 ; P0 ))\u03b1 e\u2212\u03b1n\u01eb2n (1+C)\nX\n2 2\n2\n2\n\u2264 e\u2212nM \u01ebn /4+\u03b1n\u01ebn (1+C)+\u03b1n\u01ebn L\n\u03a0(An,j )\u03b1 + P0 (\u03a9cn )\nj\n\nwhich converges to zero by condition 1) if M is sufficiently large. \u0003\n\n\f6\nFor a compact set of models P, we can use the trivial bound\nX\n\u03a0(An,j )\u03b1 \u2264 Nt (\u01ebn , \u03b1, An )\nj\n\n, which gives the following result similar to Theorem 2.1 in Kleijn & van der Vaart\n(2006), while they used a local version of the entropy instead.\n2\n\nTheorem 2 If instead of condition 1) in Theorem 1, we assume Nt (\u01ebn , \u03b1, An ) \u2264 en\u01ebn ,\nthen for sufficiently large constant M,\n\u03a0n (P : d(P, P \u2217) \u2265 M\u01ebn ) \u2192 0 in probability.\nIn order to get optimal rate for parametric models, Kleijn & van der Vaart (2006)\nused a more refined assumption. In place of condition 2) in Theorem 1 above, they\nassumed\n\u03a0(P : J\u01ebn < d(P, P \u2217) < 2J\u01eb2n )\n2 2\n\u2264 en\u01ebn J /8\n\u2217\n\u03a0(B(\u01ebn , P ; P0 ))\n\n(6)\n\nfor all natural numbers n and J. In order to recover this result, we need a more\ncareful analysis.\nFirst, we define AJn = {P \u2208 P : Mn J\u01ebn \u2264 d(P, P \u2217) < 2Mn J\u01ebn }, with \u03b1\u2212covering\n{AJn,j } defined similarly as before with the property: inf P \u2208AJn,j \u2212 log E0 (p/p\u2217 )\u03b1 \u2265\nMn2 J 2 \u01eb2n /4. Let \u00c3Jn,j = AJn,j \u2229AJn , note that \u00c3Jn,j might not be convex even though AJn,j\n(n),J\nis constrained to be so. Similarly, we can define L\u0303k,j as in (5) with An,j replaced by\n\u00c3Jn,j . It is easy to see that the following still holds:\n(n),J\n\n(n),J\n\nE0 (L\u0303k+1,j )\u03b1 = E0 (L\u0303k,j )\u03b1 E0 (\n\npn\u00c3Jn,j\np\u2217\n\n(n),J\n\n2 2 \u01eb2 /4\nn\n\n)\u03b1 \u2264 E0 (L\u0303k,j )\u03b1 e\u2212Mn J\n\neven though \u00c3Jn,j might be nonconvex, since Pn\u00c3Jn,j is still contained in AJn,j though\nnot necessarily in \u00c3Jn,j .\nWith AJn playing the role of An before, the same strategy in the proof of Theorem\n1 can be followed to show that\nP (n),J \u03b1\nE\n0\nj (L\u0303n,j )\nE0 (\u03a0n (AJn )1\u03a9n ) \u2264\n\u03a0(B(\u01ebn , P \u2217 ; P0 ))\u03b1 e\u2212\u03b1n\u01eb2n (1+C)\nP\nJ \u03b1\n2\n2\n2\n2\nj \u03a0(\u00c3n,j )\n\u2212nMn J \u01ebn /4+\u03b1n\u01eb (1+C)\n\u2264 e\n\u03a0(B(\u01ebn , P \u2217; P0 ))\u03b1\nWe will use the notation NtJ to denote the \u03b1-covering number for AJn . We are now\nready to prove the following:\nTheorem 3 Assume that P \u2217 is the unique minimizer of the Kullback-Leibler divergence to the true distribution with E0 (log(p0 /p\u2217 )) < \u221e. For a sequence \u01ebn such that\n\n\f7\nNJ\n\nt\n\u01ebn \u2192 0 and n\u01eb2n bounded away from zero, and AJn , {AJn,j }j=1\ndefined as above. If the\nfollowing conditions hold\n2\n1) NtJ \u2264 en\u01ebn for all J \u2265 1\n2) (6) is satisfied\nThen we have\n\u03a0n (P : d(P, P \u2217) \u2265 Mn \u01ebn ) \u2192 0\n\nin probability for any sequence Mn \u2192 \u221e\nProof. We start by writing\nE0 (\u03a0n (An )) =\n\n\u221e\nX\n\nE0 (\u03a0n (AJn ))\n\nJ=1\n\n\u2264\n\nX\n\n\u2264\n\nX\n\nE0 (\u03a0n (AJn )1\u03a9n ) + P0 (\u03a9cn )\n\nJ\n\n\u2212nMn2 J 2 \u01eb2n /4+\u03b1n\u01eb2n (1+C)\n\ne\n\nJ\n\nP\n\n\u03a0(\u00c3Jn,j )\u03b1\n+ P0 (\u03a9cn )\n\u03a0(B(\u01ebn , P \u2217; P0 ))\u03b1\nj\n\n(7)\n\nwe can bound the inner sum for each fixed J as\nX\n2\n\u03a0(\u00c3Jn,j )\u03b1 \u2264 NtJ \u03a0(AJn )\u03b1 \u2264 en\u01ebn \u03a0(AJn )\u03b1\nj\n\nsince \u00c3Jn,j \u2282 AJn and using condition 1). Plugging this into (7) and using condition\n2), we get\nX\n2\n2 2\n2\n2\n2\n2 2\nE0 (\u03a0n (An )) \u2264\ne\u2212n\u01ebn Mn J /4+\u03b1n\u01ebn (1+C)+n\u01ebn +\u03b1n\u01ebn Mn J /8 + P0 (\u03a9cn )\nJ\u22651\n\nBy Lemma 7.1 of Kleijn & van der Vaart (2006), P0 (\u03a9cn ) can be made arbitrarily\nsmall by choosing C sufficiently large, under the condition that n\u01eb2n is bounded away\nfrom zero. For any C, the sum above converges to zero since Mn \u2192 \u221e. \u0003\n\n4\n\nDISCUSSION\n\nWe demonstrated that rates of convergence of posterior distribution under misspecification can be established without construction of a sequence of tests. Theorem 3 we\nderived above is slightly weaker than Theorem 2.2 in Kleijn & van der Vaart (2006)\ndue to our use of assumption (2), which is stronger than (3). This said, we are not\naware of any examples where the weaker condition (3) provides any advantage over\n(2). In Walker (2007), the authors demonstrated that using the martingale approach\ncan improve on the rates slightly for some problems. Theorem 3 shows that the results by Kleijn & van der Vaart (2006) is implied by our result, this is precisely true\nfor well-specified problem, while for misspecified problem this is not conclusive due\nto the reason stated above. Unfortunately, we have not been able to construct an\nexample that this approach provides a faster rate.\n\n\f8\nThe extension to the case that the prior \u03a0 depends on n, and the case that there\nexists a finite number of points at minimal Kullback-Leibler divergence to the true\ndistribution should be straightforward.\n\nReferences\nBARRON, A., SCHERVISH, M.J. & WASSERMAN, L. (1999). The consistency of\nposterior distributions in nonparametric problems. Ann. Statist. 27, 536-561.\nBLACKWELL, D. & DUBINS, L. (1962). Merging of opinions with increasing information. Ann. Math. Statist. 33, 882-886.\nDIACONIS, P. & FREEDMAN, D. (1986). On the consistency of Bayes estimates\n(with discussion). Ann. Statist. 14, 1-67.\nGHOSAL, S., GHOSH, J.K. & VAN DER VAART, A.W. (2000). Convergence rates\nof posterior distributions. Ann. Statist. 28, 500-531.\nKLEIJN, B.J.K. & VAN DER VAART, A.W. (2006). Misspecification in infinitedimensional Bayesian statistics. Ann. Statist. 34, 837-877.\nSHEN, X. & WASSERMAN, L. (2001). Rates of convergence of posterior distributions. Ann. Statist. 29, 687-714.\nWALKER, S.G. (2003). On sufficient conditions for Bayesian consistency. Biometrika\n90, 482-488.\nWALKER, S.G. (2004). New approaches to Bayesian consistency. Ann. Statist. 32,\n2028-2043\nWALKER, S.G., LIJOI, A. & Prunster, I. (2007). On rates of convergence for posterior\ndistributions in infinite-dimensional models. Ann. Statist. In press.\nSCHWARTZ, L. (1965). On Bayes Procedures. Z. Wahrsch. Verw. Gabiete 4, 10-26\n\n\f"}