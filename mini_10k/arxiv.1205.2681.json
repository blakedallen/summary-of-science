{"id": "http://arxiv.org/abs/1205.2681v2", "guidislink": true, "updated": "2012-05-14T21:14:11Z", "updated_parsed": [2012, 5, 14, 21, 14, 11, 0, 135, 0], "published": "2012-05-11T19:48:50Z", "published_parsed": [2012, 5, 11, 19, 48, 50, 4, 132, 0], "title": "Detectability of Symbol Manipulation by an Amplify-and-Forward Relay", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1205.0786%2C1205.3946%2C1205.4064%2C1205.1104%2C1205.4244%2C1205.1083%2C1205.0881%2C1205.3464%2C1205.1804%2C1205.2870%2C1205.4286%2C1205.4240%2C1205.1869%2C1205.1646%2C1205.1744%2C1205.4119%2C1205.0399%2C1205.4167%2C1205.2533%2C1205.3939%2C1205.2488%2C1205.4327%2C1205.2148%2C1205.2993%2C1205.1315%2C1205.1221%2C1205.1479%2C1205.0957%2C1205.3632%2C1205.0596%2C1205.1168%2C1205.3557%2C1205.3595%2C1205.1842%2C1205.0887%2C1205.4179%2C1205.4476%2C1205.0684%2C1205.4359%2C1205.3598%2C1205.3106%2C1205.2399%2C1205.0486%2C1205.1194%2C1205.1335%2C1205.1450%2C1205.4015%2C1205.1022%2C1205.4125%2C1205.1029%2C1205.2394%2C1205.4350%2C1205.2212%2C1205.2642%2C1205.0293%2C1205.1810%2C1205.1116%2C1205.0783%2C1205.2440%2C1205.1822%2C1205.3094%2C1205.3479%2C1205.3258%2C1205.2435%2C1205.1299%2C1205.2213%2C1205.4407%2C1205.1679%2C1205.2284%2C1205.2473%2C1205.0042%2C1205.0610%2C1205.2412%2C1205.1586%2C1205.1589%2C1205.3712%2C1205.3940%2C1205.1947%2C1205.2279%2C1205.1520%2C1205.2933%2C1205.4467%2C1205.4469%2C1205.4381%2C1205.0453%2C1205.1735%2C1205.0634%2C1205.2324%2C1205.2681%2C1205.2849%2C1205.2578%2C1205.2526%2C1205.4047%2C1205.0040%2C1205.1817%2C1205.3964%2C1205.2235%2C1205.1205%2C1205.4451%2C1205.1684%2C1205.3794&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Detectability of Symbol Manipulation by an Amplify-and-Forward Relay"}, "summary": "This paper studies the problem of detecting a potential malicious relay node\nby a source node that relies on the relay to forward information to other\nnodes. The channel model of two source nodes simultaneously sending symbols to\na relay is considered. The relay is contracted to forward the symbols that it\nreceives back to the sources in the amplify-and-forward manner. However there\nis a chance that the relay may send altered symbols back to the sources. Each\nsource attempts to individually detect such malicious acts of the relay by\ncomparing the empirical distribution of the symbols that it receives from the\nrelay conditioned on its own transmitted symbols with known stochastic\ncharacteristics of the channel. It is shown that maliciousness of the relay can\nbe asymptotically detected with sufficient channel observations if and only if\nthe channel satisfies a non-manipulable condition, which can be easily checked.\nAs a result, the non-manipulable condition provides us a clear-cut criterion to\ndetermine the detectability of the aforementioned class of symbol manipulation\nattacks potentially conducted by the relay.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1205.0786%2C1205.3946%2C1205.4064%2C1205.1104%2C1205.4244%2C1205.1083%2C1205.0881%2C1205.3464%2C1205.1804%2C1205.2870%2C1205.4286%2C1205.4240%2C1205.1869%2C1205.1646%2C1205.1744%2C1205.4119%2C1205.0399%2C1205.4167%2C1205.2533%2C1205.3939%2C1205.2488%2C1205.4327%2C1205.2148%2C1205.2993%2C1205.1315%2C1205.1221%2C1205.1479%2C1205.0957%2C1205.3632%2C1205.0596%2C1205.1168%2C1205.3557%2C1205.3595%2C1205.1842%2C1205.0887%2C1205.4179%2C1205.4476%2C1205.0684%2C1205.4359%2C1205.3598%2C1205.3106%2C1205.2399%2C1205.0486%2C1205.1194%2C1205.1335%2C1205.1450%2C1205.4015%2C1205.1022%2C1205.4125%2C1205.1029%2C1205.2394%2C1205.4350%2C1205.2212%2C1205.2642%2C1205.0293%2C1205.1810%2C1205.1116%2C1205.0783%2C1205.2440%2C1205.1822%2C1205.3094%2C1205.3479%2C1205.3258%2C1205.2435%2C1205.1299%2C1205.2213%2C1205.4407%2C1205.1679%2C1205.2284%2C1205.2473%2C1205.0042%2C1205.0610%2C1205.2412%2C1205.1586%2C1205.1589%2C1205.3712%2C1205.3940%2C1205.1947%2C1205.2279%2C1205.1520%2C1205.2933%2C1205.4467%2C1205.4469%2C1205.4381%2C1205.0453%2C1205.1735%2C1205.0634%2C1205.2324%2C1205.2681%2C1205.2849%2C1205.2578%2C1205.2526%2C1205.4047%2C1205.0040%2C1205.1817%2C1205.3964%2C1205.2235%2C1205.1205%2C1205.4451%2C1205.1684%2C1205.3794&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper studies the problem of detecting a potential malicious relay node\nby a source node that relies on the relay to forward information to other\nnodes. The channel model of two source nodes simultaneously sending symbols to\na relay is considered. The relay is contracted to forward the symbols that it\nreceives back to the sources in the amplify-and-forward manner. However there\nis a chance that the relay may send altered symbols back to the sources. Each\nsource attempts to individually detect such malicious acts of the relay by\ncomparing the empirical distribution of the symbols that it receives from the\nrelay conditioned on its own transmitted symbols with known stochastic\ncharacteristics of the channel. It is shown that maliciousness of the relay can\nbe asymptotically detected with sufficient channel observations if and only if\nthe channel satisfies a non-manipulable condition, which can be easily checked.\nAs a result, the non-manipulable condition provides us a clear-cut criterion to\ndetermine the detectability of the aforementioned class of symbol manipulation\nattacks potentially conducted by the relay."}, "authors": ["Eric Graves", "Tan Wong"], "author_detail": {"name": "Tan Wong"}, "author": "Tan Wong", "arxiv_comment": "25 pages, 9 figures. Math", "links": [{"href": "http://arxiv.org/abs/1205.2681v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1205.2681v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1205.2681v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1205.2681v2", "journal_reference": null, "doi": null, "fulltext": "1\n\nDetectability of Symbol Manipulation by an\nAmplify-and-Forward Relay\nEric Graves and Tan F. Wong\nDepartment of Electrical & Computer Engineering\nUniversity of Florida, FL 32611\n{ericsgra,twong}@ufl.edu\n\narXiv:1205.2681v2 [cs.IT] 14 May 2012\n\nAbstract\nThis paper studies the problem of detecting a potential malicious relay node by a source node that relies on the relay to forward\ninformation to other nodes. The channel model of two source nodes simultaneously sending symbols to a relay is considered.\nThe relay is contracted to forward the symbols that it receives back to the sources in the amplify-and-forward manner. However\nthere is a chance that the relay may send altered symbols back to the sources. Each source attempts to individually detect such\nmalicious acts of the relay by comparing the empirical distribution of the symbols that it receives from the relay conditioned on its\nown transmitted symbols with known stochastic characteristics of the channel. It is shown that maliciousness of the relay can be\nasymptotically detected with sufficient channel observations if and only if the channel satisfies a non-manipulable condition, which\ncan be easily checked. As a result, the non-manipulable condition provides us a clear-cut criterion to determine the detectability\nof the aforementioned class of symbol manipulation attacks potentially conducted by the relay.\nIndex Terms\nMaliciousness detection, symbol manipulation, amplify-and-forward relay, physical-layer security, trust metric valuation.\n\nI. I NTRODUCTION\nIt is a commonplace in many communication networks that no direct physical link exists between the source and destination\nnodes of an information flow. Thus information needs to be relayed from the source to the destination through intermediate\nnodes. This requirement brings forth a major security question: How is one able to ensure that the intermediate nodes faithfully\nforward information from the source to the destination? Trust management [1]\u2013[3] is a widely researched approach to address\nthis question. In essence, trust management pertains to the establishment, distribution, and maintenance of trust relationships\namong nodes in a network. Based upon such relationships, it is expected that trusted nodes will faithfully operate according\nto some protocols that they have agreed upon.\nThe aforementioned trust relationships are primarily quantified using trust metrics that are evaluated through nodes interacting\nwith and observing the behaviors of each other [4]\u2013[9]. For nodes that do not directly interact with each other, trust relationships\ncan be established and maintained via inference [10]. It is clear that the valuation of trust metrics is critically important in\nthis trust management approach. Many different ways have been proposed to evaluate the trust metrics based on authentication\nkeys [11], [12], [13], reputation [14], [15], and evidence collected from network as well as physical interaction [16], [17],\n[18]. Given the complexity and difficulty involved in quantifying the vague notion of trust, one would expect these valuation\nschemes are naturally ad hoc.\nTo more systematically construct a trust metric, one needs to specify the class of malicious actions against which the metric\nmeasures. In this paper, we consider a class of data manipulation attacks in which intermediate nodes may alter the channel\nsymbols that they are supposed to forward. We cast the trust metric valuation problem as a maliciousness detection problem\nagainst this class of attacks. More precisely, a node (or another trusted node called a watchdog [19]) detects if another node\nrelays manipulated symbols that are different from those originally sent out by the node itself. Observations for detection\nagainst the malicious attack can be made in the physical and/or higher layers.\nMost existing maliciousness detection methods are key-based, requiring at the minimum the source and destination nodes\nto share a secret key that is not privy to the relay node being examined. In [20], keys, which correspond to vectors in a\nnull space, are given to all nodes in a network. Any modification to the encrypted data by a relay node can be checked by\ndetermining whether the observed data falls into the null space or not. In [21], symmetric cryptographic keys are applied to\nthe data at source and destination for the purpose of checking the maliciousness of relay node(s). Another key-based approach\nis considered in [22] by measuring whether only a small amount of packets are dropped by relay nodes. In [23], a cross-layer\napproach based on measurement of channel symbols is taken. Two keys are employed in that scheme; one to create a set\nof known data and another to make the data indistinguishable from the key. When the destination receives the message, the\nprobability of error of the transmitted values of the key can be used to determine if the relay node is acting maliciously.\nIn all, the key-based maliciousness detection schemes described above are far from desirable as they require the support of\nThis paper was presented in part at IEEE INFOCOM 2012.\n\n\f2\n\nFig. 1: Motivating example of a binary-input addition channel.\n\nsome key distribution mechanism, which in turn presumes the existence of inherently trusted nodes in the network. Moreover\nsome key-based methods have been shown insecure in [24] when nondeterminism and bit-level representation of the data is\nconsidered.\nFor the class of symbol manipulation attacks, it is intuitive that maliciousness of a node should be detected by the nearby\nnodes based on measurements obtained at the lower layers, since such measurements are more reliable than those made\nby faraway nodes and at the higher layers as there are fewer chances for potential adversaries to tamper with the former\nmeasurements. Hence we investigate the maliciousness detectability problem from a physical-layer perspective by considering\na model in which two sources want to share information through a potentially untrustworthy relay node that is supposed to\nrelay the information in the amplify-and-forward manner. In [25], we provide a preliminary study on the problem under a\nrestrictive case in which the relay may only modify the channel symbols based on some independent and identically distributed\n(i.i.d) attack model, and the source nodes can perfectly observe the symbols forwarded by the relay. In this paper, we extend\nthe treatment to a general channel model and an effectively general class of symbol manipulation attacks. The details of the\nchannel and attack models are provided in Section III.\nIn Section II, we qualitatively discuss maliciousness detectability in a simple binary-input addition channel in order to motivate\nthe detectability problem. This example has been presented in [25]. It is repeated here for easy reference. In Section IV, we\nstate our main result, which is a necessary and sufficient condition on the channel that guarantees asymptotic detection of\nmaliciousness individually by both source nodes using empirical distributions of their respective observations. We also provide\nalgorithms to check for the stated condition. The results presented in Section IV make clear that maliciousness detectability\nunder our model is a consequence of the stochastic characteristics of the channel and the sources. It works solely based on\nobservations made by the source nodes about the symbols sent by the relay node together with knowledge about the channel.\nNo presumed shared secret between any set of nodes is required or used. Thus the proposed maliciousness detection approach\ncan be used independent of or in conjunction with the key-based methods described above to provide another level of protection\nagainst adversaries\nThe proofs of the results in Section IV are provided later in Section VI. In Section V, we present results from numerical\nsimulation studies of the addition channel example in Section II and other more complicated channels to illustrate the asymptotic\ndetectability results in Section IV with finite observations. Finally we draw a few conclusions about this work in Section VII.\nII. M OTIVATING E XAMPLE\nTo motivate the maliciousness detectability model and results in later sections, let us first consider the simple binary-input\naddition channel shown in Fig. 1, in which two source nodes (Alice & Bob) communicate to one another through a relay node\n(Romeo) in discrete time instants. The source alphabets of Alice and Bob are both binary {0, 1}. The channel from Alice and\nBob to Romeo is defined by the summation of the symbols transmitted by Alice and Bob. Romeo is supposed to broadcast\nhis observed symbol, without modification, back to Alice and Bob. Both Alice and Bob observe the symbol transmitted by\nRomeo perfectly. Thus the input and output alphabets of Romeo and the observation alphabets of both Alice and Bob are all\nternary {0, 1, 2}. Alice, for instance, can obtain Bob's source symbol by subtracting her own source symbol from the symbol\ntransmitted by Romeo.\nNow consider the possibility that Romeo may not faithfully forward the symbol that he observes to Alice and Bob in an\nattempt to impede the communication between them. The main question that we are interested in is whether Alice and Bob\nare able to discern, from their respective observed symbols, if Romeo is acting maliciously by forwarding symbols that are\ndifferent than those he has received. To proceed answering this question, let us first consider a single round of transmission,\ni.e., Alice and Bob transmit their source symbols to Romeo and then Romeo broadcasts a symbol (may be different than what\nhe has received) back to Alice and Bob. Suppose that Alice sends a 0 and receives a 2 back from Romeo. Then it will be\n\n\f3\n\nTABLE I: Possible outcomes of the system in Fig. 1.\nAlice\n\nBob\n\nRomeo\nIn\n\n0\n\n0\n\n0\n\n0\n\n1\n\n1\n\n1\n\n0\n\n1\n\n1\n\n1\n\n2\n\nRomeo\nOut\n0\n1\n2\n0\n1\n2\n0\n1\n2\n0\n1\n2\n\nDetection Outcome\nNot malicious\nNot detected\nAlice & Bob both detect\nBob detects\nNot malicious\nAlice detects\nAlice detects\nNot malicious\nBob detects\nAlice & Bob both detect\nNot detected\nNot malicious\n\nclear to her that Romeo must have modified what he has received. On the other hand, if Alice receives a 1 back, then she will\nnot be able to tell whether Romeo has acted maliciously or not. One can continue this line of simple deduction to obtain all\nthe possible outcomes in Table I. It is clear from the table that neither Alice nor Bob will be able to determine if Romeo is\nmalicious in general from a single round of transmission.\nHowever the situation changes if Alice and Bob know the source distributions of one another and are allowed to decide\non the maliciousness of Romeo over multiple rounds of transmission. To further elaborate, suppose that the source symbols\nof Bob and Alice are i.i.d. Bernoulli random variables with parameter 12 . Then the probabilities of the events that Romeo's\ninput symbol takes on the values 0, 1, and 2 are 14 , 12 , and 14 , respectively. In particular, out of many rounds of transmission\none would expect half of the symbols transmitted by Romeo be 1's. From Table I, we see that for Romeo to be malicious\nand remained undetected by neither Alice nor Bob, he can only change a 0 to a 1 and a 2 to a 1 in any single round of\ntransmission. But if he does so often, the number of 1's that he sends out will be more than half of the number of transmission\nrounds, as expected from normal operation. On the other hand, Romeo can fool one of Alice and Bob by changing a 1 to\neither a 0 or 2. But he is not able to determine in each change whether Alice or Bob is fooled. Hence over many such changes\nthe probability of not being detected become decreasingly small. In summary, Alice and Bob may individually deduce any\nmaliciousness of Romeo by observing the distribution of Romeo's output symbol conditioned on their respective own input\nsymbols. This capability is induced by the restrictions on what Romeo can do that are imposed by the characteristic of the\naddition channel depicted in Fig. 1. It is important to notice that Alice and Bob do not need to possess any shared secret that\nis not privy to Romeo.\nIII. S YSTEM M ODEL\nA. Notation\nLet a be a 1\u00d7m row vector and A be a m\u00d7n matrix. For i = 1, 2, . . . , m and j = 1, 2, . . . , n, ai and [a]i both denote the\nith element of a, and Ai,j and [A]i,j both denote the (i, j)th element of A. Whenever there is no ambiguity, we will employ\nthe unbracketed notation for simplicity. Moreover, we write the ith row of A as Ai . Of course, [Ai ]j = Ai,j . Let the transpose\nof A be denoted by AT . Then the jth column of A is (ATj )T . It is our convention that all column vectors are written\nPm as the\ntransposes of row vectors. For instance, a is\u221aa row vector and aT is a column vector. The L1 -norm of a is kak1 = i=1 |ai |,\nwhile the Euclidean norm of a is kak2 = aaT . The operation vec(A) vectorizes the matrix A by stacking its columns to\nform a mn\u00d71 column vector. We define kAk1 , kvec(A)k1 and kAk2 , kvec(A)k2 . Note that kAk2 is the Frobenius norm\nof A. The identity and zero matrices of any dimension are denoted by the generic symbols I and 0, respectively.\nLet X be a discrete random variable. We use |X| to denote the size of the alphabet of X. Our convention is to use the\ncorresponding lowercase letter to denote the elements in the alphabet of a random variable. For example, the alphabet of X\nis {x1 , x2 , . . . , x|X| }. We denote the probability mass function (pmf) Pr(X = xj ) by p(xj ). In addition, let X and Y be two\ndiscrete random variables. We denote the conditional pmf Pr(Y = yi |X = xj ) by p(yi |xj ) for simplicity. Let xN denote a\nsequence of N symbols drawn from the alphabet of X. The counting function \u03c0(xi ; xN ) denotes the number of occurrences\nof xi , the ith symbol in the alphabet of X as described above, in the sequence xN . Let 1n (xi ; xN ) be the indicator function\nof the condition that the nth symbol in the sequence xN is xi . Then we clearly have\n\u03c0(xi ; xN ) =\n\nN\nX\n\n1n (xi ; xN ).\n\nn=1\n\nThe counting function also trivially extends to give the number of occurrences of a tuple of symbols drawn from the\ncorresponding tuple of alphabets of random variables. For example, if xN and y N are length-N sequences of symbols drawn\n\n\f4\n\n(a) Multiple-access channel (time instants 1, 2 . . . , N )\n\n(b) Broadcast channel (time instants N + 1, N + 2, . . . , 2N )\n\nFig. 2: Amplify-and-forward relaying model.\n\nfrom the alphabets of X and Y , respectively, then\nN\n\nN\n\n\u03c0(xi , yj ; x , y ) =\n\nN\nX\n\n1n (xi ; xN )1n (yj ; y N ).\n\nn=1\n\nThe set of typical X-sequences (e.g., [26, Definition 6.1]) is denoted by\n\uf8f1\n\uf8fc\n|X|\n\uf8f2\n\uf8fd\nX\n1\nN\nT[X],\u03b4\n, xN :\n\u03c0(xi ; xN ) \u2212 p(xi ) \u2264 \u03b4 .\n\uf8f3\n\uf8fe\nN\ni=1\nN\nN\nWhenever there is no confusion, we write for instance \u03c0 N (xi ) and 1N\nn (xi ) in place of \u03c0(xi ; x ) and 1n (xi ; x ), respectively,\nN\nto simplify notation. Finally, let us define the symbol indexing maps \u03c7n (x ), n = 1, 2, . . . , N , by assigning the index value\nj to \u03c7n (xN ) when the nth symbol in the sequence xN is xj , namely, the jth element in the alphabet of X.\n\nB. Channel model\nConsider the channel model shown in Fig. 2. This model serves as a generalization of the motivating example described\nin Section I. Two nodes (1 and 2) simultaneously forward their source symbols to a relay node. The relay node is supposed\nto forward its received symbols back to the two nodes (or to some other nodes) in the amplify-and-forward manner. There is\nsome possibility that the relay may modify its received symbols in an attempt to degrade the performance of the transmission.\nOur goal is to determine if and when it is possible for nodes 1 and 2 to detect any malicious act of the relay by observing\nthe symbols broadcast from the relay in relation to the symbols that they individually transmitted. Note that the above model\nalso covers the perhaps more common scenario in which only one node has information to send while the transmission by the\nother node is regarded as intentional interference.\nMore specifically, let X1 and X2 be two independent discrete random variables that specify the generic distributions of\nthe symbols transmitted by nodes 1 and 2, respectively. At time instants 1, 2, . . . , N , nodes 1 and 2 transmit i.i.d. symbols\nrespectively distributed according to X1 and X2 . The transmission goes through a memoryless multiple-access channel (MAC)\nwith the random variable U describing its generic output symbol. The MAC is specified by the conditional pmf p(uk |x1,i , x2,j ).\nThe relay node, during time instants 1, 2, . . . , N , observes the output symbols of the MAC, processes (or manipulates) them,\nand then broadcasts the processed symbols out to nodes 1 and 2 at time instants N + 1, N + 2, . . . , 2N via a memoryless\nbroadcast channel (BC) with the random variables V describing its generic input symbol and Y1 and Y2 describing the generic\noutput symbols at nodes 1 and 2, respectively. The BC is specified by the conditional pmf p(y1,i , y2,j |vk ). In addition, because\nthe relay is supposed to work in the amplify-and-forward manner, we adopt the reasonable model that the alphabets of U\nand V are of the same size, and there is a one-to-one correspondence ui \u2194 vi , i = 1, 2, . . . , |U |, between elements of the\nalphabets.\n\n\f5\n\nLet uN denote the sequence of N output symbols of the MAC observed by the relay during time instants 1, 2, . . . , N , and\nv denote the sequence of N input symbols of the BC transmitted by the relay during time instants N + 1, N + 2, . . . , 2N .\nThen the mapping v N = \u03c6N (uN ) represents the manipulation performed by the relay. The manipulation map \u03c6N is allowed\nto be arbitrary, deterministic or random, and known to neither node 1 nor 2. The only restriction we impose is the Markovity\nN\nN N\nN\nN\ncondition that p(v N |uN , xN\n1 , x2 ) = p(v |u ), where x1 and x2 denote the symbol sequences transmitted by nodes 1 and\n2, respectively, during time instants 1, 2, . . . , N . That is, the relay may potentially manipulate the transmission based only on\nthe output symbols of the MAC that it observes.\nN\n\nC. Maliciousness of relay\nConsider the |U |\u00d7|U | matrix \u03a6N whose (i, j)th element is defined by\n\u03a6N\ni,j ,\n\n\u03c0 N (vi , uj )\n.\n\u03c0 N (uj )\n\n(1)\n\nIt is obvious that \u03a6N is a stochastic matrix describing a valid conditional pmf of a fictitious channel, which we will refer\nto as the attack channel. Despite omitted from its notation, the attack channel \u03a6N depends on the sequences uN and v N .\nRather than directly acting on the MAC output symbols to produce input symbols for the BC, the attack channel \u03a6N extracts\nthe statistical properties of the manipulation map \u03c6N that are relevant to our purpose of defining (and later detecting) the\nmaliciousness of the action of the relay:\nDefinition 1. (Maliciousness) The relay is said to be non-malicious if k\u03a6N \u2212 Ik1 \u2192 0 in probability as N approaches infinity.\nOtherwise, the relay is considered malicious.\nIn the strictest sense, normal amplify-and-forward relay operation should require \u03a6N = I for all uN and v N and for each N .\nNevertheless it turns out to be beneficial to consider the relaxation in Definition 1 when the primary focus is to check whether\nthe relay is degrading the channel rather than attacking a specific part of the transmission. In particular, the probabilistic and\nlimiting relaxation in Definition 1 allows us to obtain definite results (see Section IV) for the very general class of potential\nmanipulation maps described above by tolerating actions, such as manipulating only a negligible fraction of symbols, that have\nessentially no effect on the information rate across the relay. We point out that it is possible to develop similar results based\non the above-mentioned strictest sense of maliciousness for some more restricted classes of manipulation maps (see [25] for\ninstance).\nD. Maliciousness detection\nDue to symmetry, it suffices to focus on node 1's attempt to detect whether the relay is acting maliciously or not. To that\nend, we are particularly interested in the \"marginalized\" MAC pmf p(ui |x1,j ) and marginal BC pmf p(y1,i |vj ). For better\nbookkeeping, we will write the two conditional pmfs in terms of the |U | \u00d7 |X1 | matrix A and |Y1 | \u00d7 |U | matrix B whose\nelements are respectively defined by\nAi,j , p(ui |x1,j )\nBi,j , p(y1,i |vj ).\nTo complete the bookkeeping process, we define the |Y1 |\u00d7|X1 | matrix \u0393N as\n\u0393N , B\u03a6N A,\n\n(2)\n\nwhich can be interpreted as the conditional pmf of the node 1's observation if the relay were to act in an i.i.d. manner described\nby the attack channel \u03a6N .\nWe assume that node 1 knows A and B. We will refer to the pair (A, B) as the observation channel for node 1, which may\nuse knowledge about the observation channel to detect any maliciousness of the relay. Justifications for this assumption can\nbe made based on applying knowledge of the physical MAC and BC in a game-theoretic argument similar to the one given in\n[23]. Before data communication between the nodes and relay takes place, they must agree on a relaying protocol. During the\nnegotiation process of such protocol, the relay needs to either reveal A and B to the nodes, or provide assistant to the nodes to\nlearn A and B. If the relay provides false information about A and B corresponding to a more favorable channel environment\nthan the actual one, the nodes may use the knowledge of the physical channel to check against the false information. On the\nother hand, it would also not be beneficial for the relay to misinform the nodes with a less favorable channel environment,\nsince in such case the nodes may simply decide not to use the relay.\nWe may also assume that A contains no all-zero rows and that p(x1,j ) > 0 for all x1,j in the alphabet of X1 . If these\nassumptions do not hold, we can reinforce them by removing symbols from the alphabets of X1 and U and deleting the\ncorresponding rows and columns from A, without affecting the system model. In addition, note that relabeling of elements\nin the alphabets of X1 and Y1 amounts to permuting the columns of A and rows of B, respectively. Relabelling of elements\n\n\f6\n\nin the alphabet of U , and hence the corresponding elements in the alphabet of V , requires simultaneous permutation of the\nrows of A and columns of B. It is obvious that all these relabellings, and hence the corresponding permutations of rows and\ncolumns of A and B, do not change the underlying system model. Therefore we will implicitly assume any such convenient\npermutations in the rest of the paper.\nAs mentioned before, detection of maliciousness of the relay is to be done during normal data transmission. That is, the\ndetection is based upon the symbols that node 1 transmits at time instants 1, 2, . . . , N (i.e., xN\n1 ) and the corresponding symbols\nthat node 1 receives at time instant N + 1, N + 2, . . . , 2N (i.e., y1N ). We refer to each pair of such corresponding transmit and\nreceive symbols (e.g., the ones at time instants 1 and N + 1) as a single observation made by node 1. Node 1 is free however\nto use its N observations to detect maliciousness of the relay. For instance, we may employ the following estimator of \u03a6N to\nconstruct a decision statistic for maliciousness detection. First node 1 obtains the conditional histogram estimator \u0393\u0302N of \u0393N\ndefined by its (i, j)th element:\n\u03c0 N (y1,i , x1,j )\n.\n(3)\n\u0393\u0302N\n,\ni,j\n\u03c0 N (x1,j )\nThen it constructs the estimator \u03a6\u0302N from \u0393\u0302N according to:\n\uf8f1\n\uf8f2argmax k\u03a6\u0302 \u2212 Ik1\n\u03a6\u0302\u2208G\u03bc (\u0393\u0302N )\n\u03a6\u0302N =\n\uf8f3I\n\nif G\u03bc (\u0393\u0302N ) is non-empty,\n(4)\notherwise.\n\nIn (4), \u03bc is a small positive constant and G\u03bc (\u0393\u0302) is the set of |U |\u00d7|U | stochastic matrices, for each of which (say denoted by\n\u03a6\u0302), there exists a |Y1 |\u00d7|U | stochastic matrix \u0393\u0303 such that k\u03a0B (\u0393\u0303 \u2212 \u0393\u0302)\u03a0A k1 \u2264 \u03bc and B \u03a6\u0302A = \u03a0B \u0393\u0303\u03a0A , where \u03a0A and \u03a0B\ndenote the orthogonal projectors onto the row space of A and column space of B, respectively. We will employ the estimator\n\u03a6\u0302N specified in (4) to obtain the detectability results in the following sections.\nIV. M ALICIOUSNESS D ETECTABILITY\nTo describe the main results of this paper, we first need to introduce the following notions of normalized, balanced, and\npolarized vectors:\nDefinition 2. (Normalized vector) A non-zero vector \u03c9 is said to be normalized if k\u03c9k1 = 1.\nP\nDefinition 3. (Balanced vector) A vector \u03c9 is said to be balanced if i \u03c9i = 0.\nDefinition 4. (Polarized vectors) For b \u2265 0 and 0 \u2264 \u000f \u2264 b, a vector \u03c9 is said to be (b, \u000f)-polarized at j if\n(\n[b, \u221e)\nfor i = j\n\u03c9i \u2208\n(\u2212\u221e, \u000f] for i 6= j.\nFurther \u03c9 is said to be (b, \u000f)-double polarized at (j, k) if\n\uf8f1\n\uf8f4\n\uf8f2[b, \u221e)\n\u03c9i \u2208 (\u2212\u221e, \u2212b]\n\uf8f4\n\uf8f3\n[\u2212\u000f, \u000f]\n\nfor i = j\nfor i = k\nfor i 6= j, k.\n\nA. Main result\nThe main result of this paper is that detectability of maliciousness of the relay is characterized by the following categorization\nof observation channels:\nDefinition 5. (Manipulable observation channel) The observation channel (A, B) is manipulable if there exists a |U |\u00d7|U |\nnon-zero matrix \u03a5, whose jth column, for each j = 1, 2, . . . , |U |, is balanced and (0, 0)-polarized at j, with the property that\nall columns of \u03a5A are in the right null space of B. Otherwise, (A, B) is said to be non-manipulable.\nN\nN\nLet DN = DN (y1N , xN\n1 ) denote a decision statistic based on the first N observations (y1 , x1 ) that is employed for\nmaliciousness detection. The following theorem states that maliciousness detectability is equivalent to non-manipulablility of\nthe observation channel:\n\nTheorem 1. (Maliciousness detectability) When and only when the observation channel (A, B) is non-manipulable, there\nexists a sequence of decision statistics {DN } with the following properties (assuming \u03b4 > 0 below):\n1) If lim supN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4) > 0, then\n\u0010\n\u0011\nlim sup Pr DN > \u03b4 k\u03a6N \u2212 Ik1 > \u03b4 = 1.\nN \u2192\u221e\n\n\f7\n\n2) If lim inf N \u2192\u221e Pr(k\u03a6N \u2212 Ik1 \u2264 \u03b4) > 0, then\n\u0010\nlim Pr DN > c\u03b4\n\nN \u2192\u221e\n\n\u0011\nk\u03a6N \u2212 Ik1 \u2264 \u03b4 = 0\n\nfor some positive constant c that depends only on A and B.\nThe theorem verifies the previous claim that the attack channel \u03a6N provides us the required statistical characterization\nfor distinguishing between malicious and non-malicious amplify-and-forward relay. In addition, as shown in the proof of the\ntheorem to be provided later in Section VI-C this distinguishability is (asymptotically) observable through the decision statistic\nk\u03a6\u0302N \u2212 Ik1 , where \u03a6\u0302N is the estimator of \u03a6N described in (4), for non-manipulable channels. The requirement of (A, B)\nbeing non-manipulable is not over-restrictive and is satisfied in many practical scenarios.\nTheorem 1 can further be employed to characterize detectability of maliciousness of the relay in the context of Definition 1:\nCorollary 1. Given that (A, B) is non-manipulable, the sequence of decision statistics {DN } in Theorem 1 also satisfies the\nfollowing properties:\n1) If the relay is not malicious (i.e., k\u03a6N \u2212 Ik1 \u2192 0 in probability), then\nlim Pr(DN > \u03b4) = 0\n\nN \u2192\u221e\n\nfor any \u03b4 > 0.\n2) If the relay is malicious (i.e., k\u03a6N \u2212 Ik1 does not converge to 0 in probability), then\nlim sup Pr(DN > \u03b4) \u2265 lim sup Pr(k\u03a6N \u2212 Ik1 > \u03b4)\nN \u2192\u221e\n\nN \u2192\u221e\n\nfor any \u03b4 > 0.\n3) If the relay is malicious and there is a subsequence {\u03a6NM } of attack channels satisfying k\u03a6NM \u2212 \u03a6k1 \u2192 0 in probability\nfor some stochastic \u03a6 6= I, then there exists \u03b4 > 0 such that lim supN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4) = 1, and for every such\n\u03b4,\nlim sup Pr(DN > \u03b4) = 1.\nN \u2192\u221e\nN\n\n4) If the relay is malicious with k\u03a6 \u2212 \u03a6k1 \u2192 0 in probability for some stochastic \u03a6 6= I, then there exists \u03b4 > 0 such\nthat limN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4) = 1, and for every such \u03b4,\nlim Pr(DN > \u03b4) = 1.\n\nN \u2192\u221e\n\nNote that Properties 1 and 2 of the corollary together state that DN \u2192 0 in probability when and only when the relay in\nnot malicious. Properties 3 and 4 provide progressively stronger maliciousness detection differentiation when more restrictions\nare placed on the attack channel \u03a6N .\nB. Checking for non-manipulability\nThe manipulability of the observation channel (A, B) can be checked by solving a linear program as shown below:\nAlgorithm 1. (Non-manipulable?)\n1) Let \u03a9, \u03bd, and \u03bb be a |X1 |\u00d7|Y1 | matrix-valued variable and two 1\u00d7|U | vector-valued variables, respectively.\n2) Solve the following linear program:\nmin\n\n\u03bb,\u03bd,\u03a9\n\n|U |\nX\n\n\u03bbk \u2212 \u03bdk \u2212 [A\u03a9B]k,k\n\nk=1\n\nsubject to\n1 \u2212 \u03bbk \u2264 0\n\nk = 1, 2, . . . , |U |,\n\n\u03bdk + [A\u03a9B]k,k \u2212 \u03bbk \u2264 0\n\nk = 1, 2, . . . , |U |,\n\n\u03bdk + [A\u03a9B]k,l \u2264 0\n\nk 6= l = 1, 2, . . . , |U |.\n\n3) If the optimal value in 2) is 0, then conclude that (A, B) is non-manipulable. Otherwise (i.e., the optimal value is\npositive), conclude that (A, B) is manipulable.\nFor cases where the right null space of B is trivial, checking manipulability of (A, B) is made simple by Theorem 2 below.\nFor notation clarity in expressing the theorem, let us define the following constants that depend only on A:\nX\nAmin , min\nAi,j\ni\n\namin ,\n\nj\n\nAmin\n.\n|U | (|X1 | + Amin )\n\n\f8\n\nNote that both Amin and amin are positive since A does not contain any all-zero row.\nTheorem 2. Suppose that the right null space of B is trivial. Then (A, B) is non-manipulable if and only if the left null space\nof A does not contain any normalized, (amin , 0)-double polarized vectors.\nWe remark that the condition of non-existence of normalized, (amin , 0)-double polarized vectors in the left null space of A\nis relatively easy to check by for instance employing the following algorithm:\nAlgorithm 2. (Double polarized vector in left null space?) Let n = |U | \u2212 rank(A). The following steps can be employed to\ncheck whether the left null space of A contains any normalized, (amin , 0)-double polarized vectors:\n1) If n = 0, then the left null space of A must not contain any normalized, (amin , 0)-double polarized vector.\n2) If n = |U | \u2212 1, then the left null space of A must contain a normalized, (amin , 0)-double polarized vector.\n3) If 1 \u2264 n \u2264 |U | \u2212 2:\na) Find a n\u00d7|U | matrix \u03a5 whose rows form a basis for the left null space of A.\nb) Perform elementary row operations, permuting columns if necessary, to make \u03a5 into the row-reduced echelon form\n\u03a5 = (I \u03a5\u0303), where \u03a5\u0303 is a n\u00d7(|U | \u2212 n) block.\nc) For each i = 1, 2, . . . , n, if all elements of \u03a5\u0303i , except for a single negative element, are zero, then go to 3f).\nd) For each i, j \u2208 {1, 2, . . . , n} and i 6= j, if \u03a5\u0303i = c\u03a5\u0303j for some c > 0, then go to 3f).\ne) Conclude that the left null space of A does not contain any normalized, (amin , 0)-double polarized vector, and\nterminate.\nf) Conclude that the left null space of A contains a normalized, (amin , 0)-double polarized vector.\nPractically speaking, the triviality of the right null space of B guarantees that the pmf of V can be unambiguously obtained\nby node 1 from observing Y1 . This requirement is reasonable if node 1 is expected to be able to observe the behavior of the\nrelay, and is often satisfied in practical scenarios. The requirement of the left null space of A not containing any normalized\ndouble-polarized vector is not over-restrictive, and can be satisfied in many cases by adjusting the source distribution of node 2.\nV. N UMERICAL E XAMPLES\nA. Motivating example\nTo illustrate the use of Theorem 1, let us first reconsider the motivating example in Section II. In the notation of Section III-B,\nX1 and X2 have the same binary alphabet {0, 1}, and the MAC is the binary erasure MAC described by U = X1 + X2 . That\nis, the alphabets of U and V are both {0, 1, 2}. The BC is ideal defined by Y1 = V and Y2 = V . In addition, we assume\nthe usual equally likely source distributions, i.e., X1 and X2 are i.i.d. equally likely binary random variables. Physically, this\nmodel approximates the scenario in which two equal-distance Ethernet nodes send signals (collision) to a bridge node, or the\nscenario in which two power-controlled wireless nodes send phase synchronized signals (collision) to an access point. In both\nscenarios, the signal-to-noise ratio is assumed to be high.\nIt is easy to check that in this case\n\uf8f6\n\uf8eb\n.5 0\nA = \uf8ed.5 .5\uf8f8 and B = I3\u00d73 .\n0 .5\n1\n1\n, and bmin = 12\n. Note that the left null space of A has dimension 1, and the row-reduced echelon\nHence Amin = 21 , amin = 15\nbasis matrix in Algorithm 2 is (1 \u2212 1 1). Thus Algorithm 2 gives the fact that the left null space of A does not contain\nany normalized, (amin , 0)-double polarized vector. By Theorem 1 and its proof in Section VI, we know that the sequence of\ndecision statistics {k\u03a6\u0302N \u2212 Ik1 }, where \u03a6\u0302N is described in (4), satisfies properties 1) and 2) stated in Theorem 1. Thus any\nmalicious relay manipulation is detectable asymptotically.\n1) I.i.d. attacks: To demonstrate the asymptotic maliciousness detection performance promised by Theorem 1, and to\ninvestigate the performance with finite observations, we performed simulations for four different manipulation maps which\ncorrespond to the relay randomly and independently switching its input symbol by symbol according to the conditional pmfs\np(vj |ui ) specified by the matrices\n\uf8eb\n\uf8f6\n.99 .005 .005\n\u03a61 = I3\u00d73 ,\n\u03a62 = \uf8ed.005 .99 .005\uf8f8 ,\n.005 .005 .99\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n.99 .005 0\n.99 0 0\n\u03a63 = \uf8ed.01 .99 .01\uf8f8 ,\nand \u03a64 = \uf8ed.01 1 .01\uf8f8 .\n(5)\n0 .005 .99\n0 0 .99\n\nObviously the case of \u03a61 corresponds to a non-malicious relay and the other cases correspond to a malicious relay. The\nparticular malicious \u03a6's were chosen to represent different ways a relay node may choose to attack. For the case of \u03a62 , the\n\n\f9\n\n(a) i.i.d attacks, N = 103\n\n(b) i.i.d attacks, N = 104\n\n(c) i.i.d attacks, N = 105\n\n(d) non-ergodic attacks, N = 105\n\nFig. 3: Plot of empirical cdfs of k\u03a6\u0302N \u2212 Ik1 obtained in the motivating example with the four relay manipulation maps\ncorresponding to \u03a61 = I, \u03a62 , \u03a63 , and \u03a64 respectively.\n\nrelay node changes 1% of the symbols received without regards to whether or not this will make the manipulation obvious to\nthe source nodes. In contrast, the attack of \u03a63 is more reserved in what it will do. It can be seen that the relay's manipulation\ncan only be instantly detected by one of the source nodes at any given transmitted value. That is, the relay the relay switches\n1% of the received symbols in ways listed out in Table. I except those labeled with \"Alice & Bob both detect.\" Finally the\nattack of \u03a64 is the most cautious and will only take an action that neither source node can recognize as manipulation without\nlooking at multiple observations. For this case, the relay switches 2% of the received symbols with values 0 or 2 to 1. This\ncorresponds to the \"Not detected\" outcomes in Table I. Note that k\u03a6N \u2212 \u03a6i k1 \u2192 0 in probability as N \u2192 \u221e in each case.\nHence property 1) of Corollary 1 applies for the case of \u03a61 and property 4) applies for the cases of \u03a62 , \u03a63 , and \u03a64 .\nIn different simulation runs, we set N = 103 , 104 , and 105 . Five thousand trials were run in each simulation. The empirical\ncumulative distribution functions (cdfs) of k\u03a6\u0302N \u2212 Ik1 obtained from the 5000 trials for each simulation are plotted in Figs. 3a,\n3b, and 3c for the cases of N = 103 , 104 , and 105 , respectively. For these three cases, the values of \u03bc chosen in defining the\nestimator \u03a6\u0302N are 0.2, 0.1, and 0.05, respectively. From Figs. 3b and 3c respectively with N = 104 and N = 105 , as predicted\nby parts 1) and 4) of Corollary 1, the decision statistic k\u03a6\u0302N \u2212 Ik1 succeeds in differentiating between the non-malicious case\n\n\f10\n\n\uf8eb1\nA=\n\n3\n\uf8ec1\n\uf8ec 13\n\uf8ec\n\uf8ec3\n\n\uf8ed0\n0\n\uf8eb\n\n0\n1\n3\n1\n3\n1\n3\n\n0\n\n.99\n\uf8ec.005\n\uf8ec\n\u03a63 = \uf8ec\n\uf8ec.005\n\uf8ed 0\n0\n\n\uf8eb\n\uf8f6\n.99\n0 0 0\n\uf8ec.0025\n\uf8ec\n.7 0 0\uf8f7\n\uf8f7 , \u03a61 = I5\u00d75 , \u03a62 = \uf8ec.0025\n\uf8ec\n.3 .5 0\uf8f8\n\uf8ed.0025\n0 .5 1\n.0025\n\uf8eb\n\uf8f6\n0\n0\n.985\n0\n0\n0\n.01\n\uf8ec.0075 .985 0\n\uf8f7\n0\n0\n3\n\uf8ec\n\uf8f7\n.01\n\uf8ec\n.005\uf8f7\n3\n\uf8f7 , and \u03a64 = \uf8ec.0075 .015 1 .015\n\uf8ed 0\n0\n0 .985\n.99 .005\uf8f8\n.01\n0\n0\n0\n0\n.99\n3\n\n\uf8f6\n\uf8eb\n0\n1\n\uf8f7\n0\uf8f7\n\uf8ec\n1\uf8f7\n\uf8ec0\n3 \uf8f7 , B = \uf8ed0\n1\uf8f8\n3\n0\n1\n3\n.01\n3\n\n.0025\n.99 .0025\n.01\n.99\n3\n.01\n.0025\n3\n0 .0025\n\n.5\n.5\n0\n0\n\n(a) (A, B) non-manipulable\n\n.0025\n.99\n.0025\n.0025\n.0025\n\n.0025\n.0025\n.99\n.0025\n.0025\n\uf8f6\n\n.0025\n.0025\n.0025\n.99\n.0025\n\n\uf8f6\n.0025\n.0025\uf8f7\n\uf8f7\n.0025\uf8f7\n\uf8f7,\n.0025\uf8f8\n.99\n\n0\n0 \uf8f7\n\uf8f7\n.0075\uf8f7\n\uf8f7.\n.0075\uf8f8\n.985\n\n(6)\n\n(b) (A, B) manipulable\n\nFig. 4: Plot of empirical cdfs of k\u03a6\u0302N \u2212 Ik1 for various i.i.d. attacks considered in Sections V-B and V-C.\n\nof \u03a61 and the malicious cases of \u03a62 , \u03a63 , and \u03a64 with very high confidence. For instance, by selecting the decision threshold\nat \u03b4 = 0.065 and \u03b4 = 0.004 respectively for the cases of N = 104 and N = 105 , we are able to obtain very small miss\nand false alarm probabilities for detecting maliciousness of the relay. For N = 103 , we can see from Fig. 3a that there is\nstill differentiation between the empirical cdfs obtained for the non-malicious and malicious cases. However the maliciousness\ndifferentiation confidence achieved is much weaker than the detectors with the larger value of N . This simulation exercise\nillustrates the fact that the decision statistic based on the maximum-norm estimator of (4), while is convenient for proving the\nasymptotic distinguishability result in Theorem 1, may not be a suitable choice for constructing a practical detector when the\nnumber of observations, N , is not large. Other more efficient finite-observation detectors may be needed.\n2) Non-ergodic attacks: To demonstrate part 2) of Corollary 1 with non-i.i.d attacks, we simulated a few non-ergodic\nattacks and considered again the decision statistic k\u03a6\u0302N \u2212 Ik1 . In these non-ergodic attacks, the relay decides whether or not\nto manipulate the symbols depending on if the checksum of all observed symbols is even or not. Conditioning on an even\nchecksum, the relay manipulates the symbols i.i.d. according to \u03a62 , \u03a63 , and \u03a64 as described in (5). Note that the for these\nattacks, limN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4) = 0.5 for all \u03b4 > 0.\nThe results for this simulation with N = 105 and \u03bc = 0.01 are plotted in Fig. 3d. From the figure, the first important note is\nthat the empirical cdfs of the decision statistic exhibit staircase shapes with a step at 0.5 as predicted by part 2) of Corollary 1.\nWhen the relay is being malicious, it is clear that by choosing \u03b4 = 0.07, we can again obtain small miss and false alarm\nprobabilities for detecting maliciousness of the relay.\nB. Higher order example\nLet us consider the addition channel as shown in Fig. 1 with both Alice and Bob choosing their source symbols uniformly\nover the ternary alphabet {0, 1, 2} instead. Hence the input and output alphabets of Romeo is {0, 1, 2, 3, 4} in this case. It is\n\n\f11\n\neasy to verify that the corresponding A matrix is given as in (6) on the next page. Furthermore, suppose that BC from Romeo\nback to Alice and Bob is not ideal. In particular, let us model the marginal BC from Romeo back to Alice by the matrix B\ngiven in (6). Notice that this B has a non-trivial right null space.\nFirst we need to determine if the pair (A, B) is non-manipulable. To do this, we used the Algorithm 1 presented in\nSection IV-B. In particular, we employed the linear programming solver linprog in the optimization toolbox in MATLAB\nto solve the linear program in step 2 of Algorithm 1. The optimal value returned was of the order of 10\u221216 , which is close\nenough to 0 for us to decide (A, B) as non-manipulable. Thus again Theorem 1 and Corollary 1 apply to give that the decision\nstatistic k\u03a6\u0302N \u2212 Ik1 provides maliciousness detectability for this channel.\nAs in Section V-A1, we simulated i.i.d. attacks by Romeo. The four different \u03a6's shown in (6) were the cases that we\nconsidered in the simulation study. The attack of \u03a61 corresponds to the case in which Romeo truthfully forwards the received\nsymbols. For the attacks of \u03a62 , \u03a63 , and \u03a64 , Romeo alters 1% of the symbols that it receives. Each of these three cases was\nonce again chosen for a particular level of maliciousness as in Section V-A1. The case of \u03a62 corresponds to an attack in which\nRomeo returns values that he knows will instantly guarantee detection. The attack of \u03a63 only sends back values for which it\nis possible to not be instantly detected. Finally \u03a64 corresponds to the case in which Romeo is the most cautious, and will not\nsend back any symbol which is instantly detectable.\nThe empirical cdfs of k\u03a6\u0302N \u2212 Ik1 obtained for the four different \u03a6i 's are plotted in Fig. 4a for the simulation run with\nN = 105 and \u03bc = 0.05. As before, by choosing a decision threshold at \u03b4 = 0.07 we can obtain very small miss and false\nalarm probabilities for detecting maliciousness of Romeo.\nC. Counter-example\nTo demonstrate the consequence of having a manipulable observation channel (A, B), reconsider the ternary-input example\nof Section V-B with the marginal BC from Romeo back to Alice specified by the following matrix\n\uf8f6\n\uf8eb\n1 0 0 0 0\n\uf8ec0 .5 0 .3 .2\uf8f7\n\uf8f7\n\uf8ec\n\uf8f7\nB=\uf8ec\n\uf8ec0 0 .5 .2 .3\uf8f7 .\n\uf8ed0 .3 .2 .5 0 \uf8f8\n0 .2 .3 0 .5\nTo check whether (A, B) is manipulable, Algorithm 1 was again employed. The optimal value of the linear program in step 2\nobtained was 3, thus alerting us that (A, B) is manipulable. Indeed it can be readily check that for any \u03c8 \u2208 (0, 1], the matrix\n\uf8f6\n\uf8eb\n0 0\n0 0 0\n\uf8ec0 \u03c8\n0 0 0 \uf8f7\n\uf8f7\n\uf8ec\n0\n0\n\u03c8\n0 \u2212\u03c8 \uf8f7\n\u03a5=\uf8ec\n\uf8f7,\n\uf8ec\n\uf8ed0 \u2212\u03c8\n0 0 0 \uf8f8\n0 0 \u2212\u03c8 0 \u03c8\nis one that satisfies B\u03a5A = 0 required in Definition 5 to make (A, B) manipulable. Therefore Theorem 1 tells us that\nmaliciousness detectability is impossible for this channel.\nAs in Sections V-A1 and V-B, an i.i.d. attack with \u03a62 = I \u2212 \u03a5 was simulated for N = 105 and \u03bc = 0.05. The value\nof \u03c8 = 1 was chosen in the simulation. This choice corresponds to an average of 59 of the symbols are changed by Romeo.\nClearly having this many symbols changed would be catastrophic in most practical communication systems, and is therefore\nundesirable. The empirical cdfs of the non-malicious case and the malicious case of \u03a62 obtained from the simulation are plotted\nin Fig. 4b. It is clear from the figure that the cases for which Romeo is being malicious and not malicious are indistinguishable.\nHence the severe attack of \u03a62 can not be detected.\nVI. P ROOFS OF D ETECTABILITY R ESULTS\nIn order to prove the various results in Section IV, we will need to extend the notion of polarization of vectors given in\nDefinition 4 to matrices:\nDefinition 6. (Polarized matrices) Let 1 \u2264 n \u2264 |U |. For b \u2265 0 and 0 \u2264 \u000f \u2264 b, we say that a n\u00d7|U | matrix \u03a5 is (b, \u000f)-polarized\nif\n(\n[b, \u221e)\nfor j = i\n\u03a5i,j \u2208\n(\u2212\u221e, \u000f] for j 6= i.\nIf, in addition, \u03a5i,j = 0 for all i, j = 1, 2, . . . , n and i 6= j, we say that \u03a5 is (b, \u000f)-diagonal polarized.\nMoreover, by saying a normalized \u03a5 is in the left null space of A, we mean all rows of \u03a5 are normalized vectors in the\nleft null space of A.\n\n\f12\n\nIn addition to the notion of polarized vectors and matrices, we will also employ the following generalization of linear\ndependence:\nDefinition 7. (\u000fs -dependent) A vector \u03c9 is \u000fs -dependent (\u000fs \u2265 0) upon a set of vectors \u03a51 , \u03a52 , . . . , \u03a5n of the same dimension\nif there exists a set of coefficients c1 , c2 , . . . , cn such that\n\u03c9\u2212\n\nn\nX\n\n\u2264 \u000fs .\n\nci \u03a5i\n\ni=1\n\n1\n\nWith these definitions in place, we will first establish a few important and interesting properties of polarized vectors and\nmatrices in the left and right null spaces of A and B, respectively. In addition, we will show that the condition of the observation\nchannel (A, B) being non-manipulable is sufficient in guaranteeing the validity of these properties. Then we will apply some\nof these properties to bound the distance between an estimate of the attack channel and the true attack channel. The distance\nbound is employed to show that a decision statistic constructed from an attack channel estimator based on histogram estimation\nof node 1's conditional pmf of its received symbols given its transmitted symbols provides the needed convergence properties\nin Theorem 1. The aforementioned properties of polarized vectors in the left null space of A will also be used to prove\nAlgorithm 2 and Theorem 2.\nA. Properties concerning polarized vectors and matrices in null spaces of A and B\nLet us first study the left null space of A. The following simple lemma about normalized vectors in the left null space of\nA is critical to many other results in this section:\nLemma 1. Suppose that \u03c5 is a non-zero normalized 1\u00d7|U | vector in the left null space of A. Then \u03c5 must contain at least\none positive element and one negative element, and\nmax \u03c5i \u2265 amin\n\ni:\u03c5i >0\n\nmin \u03c5i \u2264 \u2212amin .\n\ni:\u03c5i <0\n\nProof: Write a = maxi:\u03c5i >0 \u03c5i for convenience, and note that a = 0 by definition if \u03c5 contains no positive element. Since\n\u03c5 is normalized, we have\nX\nX\n|\u03c5i | = 1 \u2212\n|\u03c5i | \u2265 1 \u2212 a|U |.\n(7)\ni:\u03c5i \u22640\n\ni:\u03c5i >0\n\nP\n\nBecause \u03c5 is in the left null space of A, i \u03c5i Ai,j = 0 for all j. That implies\nX\nX\nX\n\u03c5i Ai,j = \u2212\n\u03c5i Ai,j =\n|\u03c5i |Ai,j .\ni:\u03c5i \u22640\n\ni:\u03c5i >0\n\n(8)\n\ni:\u03c5i \u22640\n\nBut, because 0 \u2264 Ai,j \u2264 1, we can make the following inequality\nX\nX\n\u03c5i Ai,j \u2264\n\u03c5i \u2264 a|U |.\ni:\u03c5i >0\n\ni:\u03c5i >0\n\nSubstituting (8) back in, we get\nX\n\na|U | \u2265\n\n|\u03c5i |Ai,j\n\ni:\u03c5i \u22640\n\nwhich must hold for all j. Therefore,\na|U ||X1 | \u2265\n\nX X\nj\n\ni:\u03c5i \u22640\n\n|\u03c5i |Ai,j \u2265\n\nX\n\n|\u03c5i |Amin\n\ni:\u03c5i \u22640\n\nwhich causes a contradiction when a = 0 since Amin > 0. Hence, a must not be 0, and \u03c5 must have at least one positive\nelement. Further, by (7),\na|U ||X1 | \u2265 Amin (1 \u2212 a|U |)\nwhich gives the desired lower bound on a. The proof of existence of a negative element and the fact that the minimum negative\nelement must be no larger than \u2212amin is similar.\nAn immediate, but important later in proving Theorem 5, consequence of the lemma is the following observation:\nLemma 2. Let 0 < \u000f \u2264 amin . Suppose that \u03c9 is a normalized vector in the left null space of A that is not (amin , \u000f)-polarized\nat i. Then there exists a j 6= i such that \u03c9j \u2265 \u000f.\nProof: Since \u03c9 is normalized, \u03c9k \u2265 amin for some k by Lemma 1. If k 6= i, then we have the stated conclusion. Now\nsuppose k = i. If \u03c9j < \u000f for all j 6= i, then we obtain the contradictory conclusion that \u03c9 is (amin , \u000f)-polarized at i.\n\n\f13\n\nLemma 1 also implies the following two lemmas about normalized, diagonal polarized matrices in the left null space of A:\nLemma 3. Let amin \u2264 a \u2264 1 and 2 \u2264 n \u2264 |U |. Let 0 \u2264 \u000fs < amin , and \u000f and \u000fn\u22121 be two positive constants. Define\n\u000f + \u000fs\n\u000f + \u000fn\u22121 + \u000fs + \u000fs \u000fn\u22121\n\u000f0n =\n+ (n \u2212 1)\n.\namin \u2212 \u000fs\na(amin \u2212 \u000fs )\n\n(9)\n\nSuppose that \u000fs , \u000f, and \u000fn\u22121 are chosen small enough to satisfy \u000f0n < amin . Furthermore, suppose that the left null space of A\ncontains a normalized, (a, \u000fn\u22121 )-diagonal polarized, (n\u22121)\u00d7|U | matrix and a normalized, 1\u00d7|U | vector that is (a, \u000f)-polarized\nat n, and is \u000fs -dependent on the rows of the matrix. Then the left null space of A also contains a normalized, 1\u00d7|U | vector\nthat is (amin , \u000f0 )-double polarized at (m, n) for all \u000f0n \u2264 \u000f0 < amin , where m < n.\nProof: Fix \u000f0 \u2208 [\u000f0n , amin ). Let \u03a5 and \u03c5 be the (a, \u000fn\u22121 )-diagonal polarized matrix and the (a, \u000f)-polarized vector,\nrespectively, given in the statement of the lemma. We will show that one row of \u03a5 must be (amin , \u000f0 )-double polarized at\n(m, n), where m < n.\nFirst, since \u03c5 is \u000fs -dependent upon the rows in \u03a5, we know that there exists a set of coefficients c1 , c2 , . . . , cn\u22121 such that\nfor any j = 1, 2, . . . , |U |,\nn\u22121\nX\n\u03c5j \u2212 \u000fs \u2264\nci \u03a5i,j \u2264 \u03c5j + \u000fs .\n(10)\ni=1\n\nIn particular, for i = 1, 2, . . . , n \u2212 1, we have \u03c5i \u2212 \u000fs \u2264 ci \u03a5i,i \u2264 \u03c5i + \u000fs . Using the facts that \u03a5i,i \u2265 a and that \u22121 \u2264 \u03c5i \u2264 \u000f,\nwe can determine that\n\u000f + \u000fs\n\u22121 \u2212 \u000fs\n\u2264 ci \u2264\n.\n(11)\na\na\nFrom Lemma 1, we know that there exists an index m such that \u03c5m \u2264 \u2212amin . To proceed, we want to show that m < n,\nwhich we will do through contradiction. Obviously m 6= n. Suppose m > n and consider (10) with j = m. Separating the\nterms with positive and negative ci 's in the summation and using the upper bound in (10), we have\nX\nX\n|ci |\u03a5i,m \u2265 \u2212\u03c5m \u2212 \u000fs +\nci \u03a5i,m\ni:ci <0\n\ni:ci >0\n\n\u000f + \u000fs\n(12)\na\nwhere the second inequality is obtained by using the upper\nm > n, we have \u03a5i,m \u2264 \u000fn\u22121 .\nP bound on ci in (11). But because\ns\nThen by using the lower bound on ci in (11), we get i:ci <0 |ci |\u03a5i,m \u2264 (n \u2212 1)\u000fn\u22121 1+\u000f\n.\nThus\nwe arrive at the conclusion\na\nthat\n1 + \u000fs\n\u000f + \u000fs\n(n \u2212 1)\u000fn\u22121\n\u2265 amin \u2212 \u000fs \u2212 (n \u2212 1)\n,\na\na\nwhich clearly violates the condition \u000f0n < amin in the statement of the lemma. Therefore m < n. Furthermore we have\ncm \u03a5m,m \u2264 \u03c5m + \u000fs \u2264 \u2212amin + \u000fs < 0, which implies cm < 0 and |cm | \u2265 amin \u2212 \u000fs .\nSimilar to (12), we have, for j > n,\nX\nX\n|ci |\u03a5i,j \u2265 \u2212\u03c5j \u2212 \u000fs +\nci \u03a5i,j\n\u2265 amin \u2212 \u000fs \u2212 (n \u2212 1)\n\ni:ci <0\n\ni:ci >0\n\n\u000f + \u000fs\n(13)\na\nwhere the second inequality is due to the fact that \u03c5j \u2264 \u000f. Further separating the terms with positive and negative \u03a5i,j in the\nsum on the left side of (13), for j > n, we have\nX\n|ci ||\u03a5i,j |\n\u2265 \u2212\u000f \u2212 \u000fs \u2212 (n \u2212 1)\n\ni:ci <0,\u03a5i,j <0\n\n\u2264\n\n\u000f + \u000fs + (n \u2212 1)\n\n\u000f + \u000fs\n+\na\n\nX\n\n|ci |\u03a5i,j\n\ni:ci <0,\u03a5i,j >0\n\n\u000f + \u000fn\u22121 + \u000fs + \u000fs \u000fn\u22121\n\u000f + \u000fs + (n \u2212 1)\n(14)\na\nP\ns\nwhere the second inequality results from the bound i:ci <0,\u03a5i,j >0 |ci |\u03a5i,j \u2264 (n \u2212 1)\u000fn\u22121 1+\u000f\na , as shown above. Because\n\u000f+\u000fn\u22121 +\u000fs +\u000fs \u000fn\u22121\ncm < 0, we know from (14) that if \u03a5m,j < 0, then |cm ||\u03a5m,j | \u2264 \u000f + \u000fs + (n \u2212 1)\n. Further, by the above\na\nderived result that |cm | \u2265 amin \u2212 \u000fs , we get\n\u000f + \u000fs\n\u000f + \u000fn\u22121 + \u000fs + \u000fs \u000fn\u22121\n|\u03a5m,j | \u2264\n+ (n \u2212 1)\n= \u000f0n ,\namin \u2212 \u000fs\na(amin \u2212 \u000fs )\n\u2264\n\nif \u03a5m,j < 0. Therefore, |\u03a5m,j | \u2264 \u000f0 for all j > n.\n\n\f14\n\nCombining all above results, we observe that \u03a5m,m \u2265 a, |\u03a5m,j | \u2264 \u000f0 < amin for j > n, and \u03a5m,j = 0 for all other index\nvalues of j except n. From Lemma 1, we must have \u03a5m,n \u2264 \u2212amin . Thus \u03a5m is (amin , \u000f0 )-double polarized at (m, n).\nLemma 4. Let amin \u2264 a \u2264 1 and 2 \u2264 n \u2264 |U |. Let 0 < \u000fs < amin , and \u000f and \u000fn\u22121 be two positive constants. Define\n\u0014\n\u0015\n\u000fn\u22121\n1\n\u000f + \u000fn\u22121\n\u000f00n =\n+\n\u000f + (n \u2212 1)\n.\na\namin a\u000fs\na\n\n(15)\n\nSuppose that \u000f and \u000fn\u22121 are chosen small enough to satisfy \u000f00n < amin . Furthermore, suppose that the left null space of A\ncontains a normalized, (a, \u000fn\u22121 )-diagonal polarized, (n\u22121)\u00d7|U | matrix and a normalized, 1\u00d7|U | vector that is (a, \u000f)-polarized\nat n, and is not \u000fs -dependent on the rows of the matrix. Then the left null space of A contains a normalized, (amin , \u000f00 )-diagonal\npolarized, n\u00d7|U | matrix, for all \u000f00n \u2264 \u000f00 < amin .\nProof: Fix \u000f00 \u2208 [\u000f00n , amin ). Let \u03a5 and \u03c5 be the (a, \u000fn\u22121 )-diagonal polarized matrix and the (a, \u000f)-polarized vector,\nrespectively, given in the statement of the lemma. We will first construct a normalized, 1 \u00d7 |U | vector \u03c5\u0302 that is (amin , \u000f00 )polarized at n with the additional property that \u03c5\u0302j = 0 for all j = 1, 2, . . . , n \u2212 1. Then we apply elementary row operations\nand normalization to the rows of [\u03a5T \u03c5\u0302 T ]T to obtain the desired normalized, n\u00d7|U |, (amin , \u000f00 )-diagonal polarized matrix.\nFirst, set\nn\u22121\nX \u03c5i\n\u03a5i .\n\u03c5\u0303 = \u03c5 \u2212\n\u03a5i,i\ni=1\nBecause \u03c5 is not \u000fs -dependent upon the rows of \u03a5, we must have k\u03c5\u0303k1 > \u000fs . Hence we can normalize \u03c5\u0303 to obtain \u03c5\u0302, i.e.,\n\u03c5j\n\u03a5j,j = 0, which implies \u03c5\u0302j = 0. For j > n, write\n\u03c5\u0302 = \u03c5\u0303/k\u03c5\u0303k1 . Clearly, for j < n, \u03c5\u0303j = \u03c5j \u2212 \u03a5j,j\n\u03c5\u0303j = \u03c5j \u2212\n\nX |\u03c5i |\n\u03c5i\n\u03a5i,j +\n\u03a5i,j .\n\u03a5i,i\n\u03a5i,i\n>0\ni:\u03c5 <0\n\nX\ni:\u03c5i\n\n(16)\n\ni\n\nBut since \u03a5i,i \u2265 a and \u03c5j \u2264 \u000f for j > n, we have\nX \u03c5i\nX \u000f\n\u000f\n(\u22121) \u2265 \u2212(n \u2212 1)\n\u03a5i,j \u2265\n\u03a5\na\na\ni,i\ni:\u03c5i >0\ni:\u03c5i >0\nX |\u03c5i |\nX 1\n\u000fn\u22121\n\u000fn\u22121 \u2264 (n \u2212 1)\n.\n\u03a5i,j \u2264\n\u03a5\na\na\ni,i\ni:\u03c5 <0\ni:\u03c5 <0\ni\n\ni\n\nApplying these two bounds to (16), we get, for j > n,\n\u03c5\u0303j \u2264 \u000f + (n \u2212 1)\n\n\u000f + \u000fn\u22121\n,\na\n\nwhich implies\n\u0015\n\u0014\n1\n\u000f + \u000fn\u22121\n, \u03b5 \u2264 \u000f00n .\n\u03c5\u0302j \u2264\n\u000f + (n \u2212 1)\n\u000fs\na\nFurther, note that \u03c5\u0302 is a normalized vector in the left null space of A. Hence by Lemma 1 and the fact that \u000f00n < amin ,\n\u03c5\u0302n \u2265 amin . Therefore \u03c5\u0302 is (amin , \u03b5)-polarized at n with the additional property that \u03c5\u0302j = 0 for j < n as claimed.\nNext, for i = 1, 2, . . . , n \u2212 1, set\n\u03a5i,n\n\u03a5\u0303i = \u03a5i \u2212\n\u03c5\u0302.\n\u03c5\u0302n\nClearly, \u03a5\u0303i,n = 0 and \u03a5\u0303i,j = \u03a5i,j for j < n by design. Thus k\u03a5\u0303i k1 \u2265 a. Again, we can normalize \u03a5\u0303i to get \u03a5\u0302i = \u03a5\u0303i /k\u03a5\u0303i k1 .\nNow, consider j > n,\n\u03a5i,n\nmax{\u000fn\u22121 , \u03b5}\n\u03b5\n\u03a5\u0303i,j = \u03a5i,j \u2212\n\u03c5\u0302j \u2264 \u000fn\u22121 +\n= \u000fn\u22121 +\n\u03c5\u0302n\namin\namin\nwhere the second inequality is due to \u22121 \u2264 \u03a5i,n \u2264 \u000fn\u22121 , \u22121 \u2264 \u03c5\u0302j \u2264 \u03b5, and \u03c5\u0302n \u2265 amin , and the last equality results from the\nfact that |U |\u000fs < 1. Hence\n\u000fn\u22121\n\u03b5\n\u03a5\u0302i,j \u2264\n+\n= \u000f00n .\na\namin a\nAs discussed before, \u03a5\u0302i,j = 0 for all i = 1, 2, . . . , n \u2212 1 and j 6= i \u2264 n. Hence, again using Lemma 1, we must have\n\u03a5\u0302i,i \u2265 amin since \u000f00 < amin . Finally, set \u03a5\u0302n = \u03c5\u0302. The matrix \u03a5\u0302 composed by using \u03a5\u03021 , \u03a5\u03022 , . . . , \u03a5\u0302n as rows is the desired\n(amin , \u000f00 )-diagonal polarized matrix.\nTo apply Lemmas 3 and 4, we need to the following lemma to select \u000fn :\n\n\f15\n\n\u0010\nLemma 5. Let \u000fs and \u000f be two positive constants. Suppose that 2 \u2264 n \u2264 |U |. Define \u00e3n\u22121 , a2min 1 +\n\u0010\n\u0011i\u22121\n2\n\u000fi = \u000f \u00e3n\u22121\nfor i = 1, 2, . . . , n. If\n\u000fs\n(\n\"\n\u0012\n\u0013n\u22121 #\namin \u00e3n\u22121\n2\n2\n\u000fs < amin \u00e3n\u22121 amin 1 +\n2\n)\u22121\n\u00e32n\u22121\n+ amin \u00e3n\u22121\n+ (n \u2212 1)(1 + amin )\n2\n\u0011n\u22121\n\u0010\n\u000fs\n, then\nand \u000f < amin \u00e3n\u22121\n2\n\nn\u22121\namin\n\n\u0011\u22121\n\n. Set\n\n(17)\n\n1) \u000f1 \u2264 \u000f2 \u2264 * * * \u2264 \u000fn < amin ,\n2) \u000f0i < amin , i = 2, 3, . . . , n,\n3) \u000f00i \u2264 \u000fi , i = 2, 3, . . . , n,\nwhere \u000f0i and \u000f00i are obtained from \u000fi\u22121 using the formulas given in (9) and (15) with a \u2265 amin , respectively.\n\u000f0n\n\nProof: Part 1) is obvious from the construction. From (9) and 1), we have \u000f02 \u2264 \u000f03 \u2264 . . . \u2264 \u000f0n . Thus it suffices to show\n< amin when establishing 2). Indeed, note that \u000fn\u22121 < amin2\u00e3n\u22121 \u000fs , which together with (9) imply\n(\n\"\n\u0013n\u22121 #\n\u0012\n1\n\u00e3n\u22121 \u000fs\n0\n2\n\u000fn \u2264\namin \u000fs + amin\n(amin \u2212 \u000fs )\u00e3n\u22121\n2\n)\n\u00e32n\u22121 \u000fs\n+ (n \u2212 1)(1 + \u000fs )\n2\n(\n\"\n\u0012\n\u0013n\u22121 #\namin \u00e3n\u22121\n\u000fs\n2\n\u2264\namin 1 +\n(amin \u2212 \u000fs )\u00e3n\u22121\n2\n)\n\u00e32n\u22121\n+ (n \u2212 1)(1 + amin )\n2\n< amin\n\nwhere the last two inequalities result from the upper bound imposed on \u000fs in the statement of the lemma.\nFinally, it is easy to see from (15) that, for i = 2, 3, . . . , n,\n\u000f00i \u2264\n\n1\n2\u000fi\u22121\n(\u000fi\u22121 + \u000f) \u2264\n= \u000fi\n\u00e3n\u22121 \u000fs\n\u00e3n\u22121 \u000fs\n\nwhere the second inequality is due to 1).\nInductively applying Lemmas 3 and 4 with the choice of \u000fn from Lemma 5, we obtain the following theorem:\nTheorem 3. Let 2 \u2264 n \u2264 |U |. Suppose that \u000fs , \u000f, and \u000f1 , \u000f2 , . . . , \u000fn are chosen according to Lemma 5, and that the left null\nspace of A contains a normalized, (amin , \u000f)-polarized, n \u00d7 |U | matrix. Then the left null space contains either a normalized,\n(amin , \u000f0i )-double polarized, 1\u00d7|U | vector for some i = 2, 3, . . . , n, or a normalized, (amin , \u000fn )-diagonal polarized, n\u00d7|U |\nmatrix. In the latter case, no row in the original (amin , \u000f)-polarized matrix can be \u000fs -dependent upon the other rows.\nProof: Let \u03a5 be the original (amin , \u000f)-polarized matrix in the left null space of A given in the statement of the theorem.\nWe will construct the desired (amin , \u000f0i )-double polarized vector or (amin , \u000fn )-diagonal polarized matrix by inductively applying\nLemmas 3 and 4 to the rows of \u03a5.\nFirst, set \u03a5\u0302(1) to be the first row of \u03a5. The assumption of the theorem guarantees that \u03a5\u0302(1) satisfies that requirement of\nbeing a normalized, (amin , \u000f1 )-diagonal polarized, 1\u00d7|U | matrix in the left null space of A. Inductively, suppose that we have\nconstructed, from the first (i \u2212 1) rows of \u03a5, the (i \u2212 1)\u00d7|U | normalized matrix \u03a5\u0302(i\u22121) that is (amin , \u000fi\u22121 )-diagonal polarized\nand in the left null space of A. If the ith row of \u03a5 is \u000fs -dependent on the rows of \u03a5\u0302(i\u22121) (i.e., the first (i \u2212 1) rows of \u03a5), then\nby Lemmas 3 and 5, there exists a normalized, (amin , \u000f0i )-double polarized (at (m, i) with m < i), 1\u00d7|U | vector in the left\nnull space of A. In this case, the induction process terminates. On the other hand, if the ith row of \u03a5 is not \u000fs -dependent on\nthe rows of \u03a5(i\u22121) , then Lemmas 4 and 5 together give an normalized i\u00d7|U | matrix \u03a5\u0302(i) that is (amin , \u000fi )-diagonal polarized\nand in the left null space of A. Also note that the rows of \u03a5\u0302(i) are in the span of the first i rows of \u03a5. The induction process\ncontinues until i = n.\nTheorem 3 leads to the following result that is critical to development in the next section:\n\n\f16\na2\n\n\u000f\n\nmin s\n< \u000f0 < amin . Let the left null space of A\nCorollary 2. Fix 2 \u2264 n \u2264 |U |, a positive \u000fs satisfying (17), and (amin \u2212\u000f\ns )\u00e3n\u22121\n0\ncontain no normalized (amin , \u000f )-double polarized, 1\u00d7|U | vector. Then there exists a positive \u000f that if the left null space of A\ncontains a normalized, (amin , \u000f)-polarized n\u00d7|U | matrix, no row of such matrix can be \u000fs -dependent upon the other rows.\n\u0010\n\u0011i\u22121\n2\nProof: For i = 1, 2, . . . , n \u2212 1, choose \u000fi = \u000f \u00e3n\u22121\nas in Lemma 5. For any \u03b4 > 0, from (9), there exists a\n\u000fs\n\na2\n\na2\n\n\u000f\n\n\u000f\n\nmin s\nmin s\nsmall enough \u000f such that \u000f0n \u2264 (amin \u2212\u000f\n+ \u03b4. Choosing \u03b4 = \u000f0 \u2212 (amin \u2212\u000f\nand using part 1) of Lemma 5 give us\ns )\u00e3n\u22121\ns )\u00e3n\u22121\n0\n0\n0\n0\n\u000f2 \u2264 \u000f3 \u2264 . . . \u2264 \u000fn \u2264 \u000f . Now applying Theorem 3 gives us the desired result.\nThe next lemma states that the observation channel (A, B) being non-manipulable is sufficient for the condition of nonexistence of any normalized (amin , \u000f0 )-double polarized, 1\u00d7|U | vector in the left null space of A required in Corollary 2:\n\nLemma 6. If (A, B) is non-manipulable, then there exists a pair of constants \u000fs and \u000fA respectively satisfying\n(\n\u0013n \u0015\n\u0014\n\u0012\namin \u00e3n\n2\n0 < \u000fs <\nmin amin \u00e3n a2min 1 +\n2\n1\u2264n\u2264|U |\u22121\n)\u22121\n\u00e32n\n+ n(1 + amin )\n+ amin \u00e3n\n,\n2\na2min \u000fs\n< \u000fA < amin ,\n(amin \u2212 \u000fs )\u00e3|U |\u22121\n\n(18)\n(19)\n\nsuch that the left null space of A does not contain any normalized, (amin , \u000fA )-double polarized vectors.\nProof: First we claim that the left null space of A can not contain any normalized, (amin , 0)-double polarized vector if\n(A, B) is non-manipulable. Indeed, suppose on the contrary that \u03c9 is a normalized vector in the left null space of A that is\n(amin , 0)-double polarized at (\u03b1, \u03b2). Construct the |U |\u00d71 column vector (\u03a5T\u03b1 )T whose \u03b1th element is \u03c9\u03b1 , \u03b2th elements is\n\u2212\u03c9\u03b1 , and all other elements are zero. Similarly, construct the |U |\u00d71 column vector (\u03a5T\u03b2 )T whose \u03b1th element is \u03c9\u03b2 , \u03b2th\nelements is \u2212\u03c9\u03b2 , and all other elements are zero. Then it is easy to check that (\u03a5T\u03b1 )T and (\u03a5T\u03b2 )T are (amin , 0)-polarized at\n\u03b1 and at \u03b2, respectively. Further, we also have, for all l = 1, 2, . . . , |X1 |, (\u03a5T\u03b1 )T A\u03b1,l + (\u03a5T\u03b2 )T A\u03b2,l = 0 because \u03c9 is in the\nleft null space of A and \u03c9i = 0 for all i 6= \u03b1 or \u03b2. Hence (A, B) is manipulable.\nNext notice that both the set of normalized, (amin , 0)-double polarized vectors and the left null space of A are closed sets.\nThe former set is also bounded. As a result, if the left null space of A does not contain any normalized, (amin , 0)-double\npolarized vectors, it must also not contain any normalized, (amin , \u000f)-double polarized vectors for all small enough positive \u000f.\nTherefore by choosing \u000fs , satisfying (18), small enough, we obtain an \u000fA that satisfies (19) and that the left null space of A\ncontains no (amin , \u000fA )-double polarized vectors.\nWe now turn our attention to the right null space of B. The following result states that normalized vectors in the right null\nspace of B have similar properties of normalized vectors in the left null space of A as described in Lemma 1:\nLemma 7. The right null space of B consists only of balanced vectors. Suppose that \u03c9 T is a non-zero normalized |U |\u00d71\nvector in the right null space of B. Let\n1\nbmin ,\n.\n|U |(|Y1 | + 1)\nThen\nmax \u03c9j \u2265 bmin\n\nj:\u03c9j >0\n\nmin \u03c9j \u2264 \u2212bmin .\n\nj:\u03c9j <0\n\nProof: Let \u03c9 T be a vector in the right null space of B. Then\n|Y1 | |U |\nX\nX\n\nBi,j \u03c9j = 0.\n\ni=1 j=1\n\nP|Y1 |\nP|U |\nSwapping the order of the two sums and using the fact that i=1\nBi,j = 1, we get j=1 \u03c9j = 0. Furthermore suppose\n\u03c9 T is non-zero and normalized, it must then have at least one positive element and one negative element. Recognizing the\npreceding fact, we can employ essentially the same argument in the proof of Lemma 1 to show maxj:\u03c9j >0 \u03c9j \u2265 bmin and\nminj:\u03c9j <0 \u03c9j \u2264 \u2212bmin .\nBased on Lemma 7, it is easy to check that the results from\u0010 Lemma 3\u0011 to Corollary 2 all apply to B T with amin replaced\n\u22121\n\nn\nby bmin and \u00e3n defined in Lemma 5 replaced by b\u0303n , b2min 1 + bmin\n. That is, the above results are all applicable to\nnormalized, polarized vectors and matrices in the right null space of B with the corresponding modifications.\n\n\f17\n\nFinally, the next theorem states that non-manipulability of the observation channel (A, B) guarantees the existence of a\ncounterpart of Corollary 2 for the right null space of B that is to be used in the proof of Theorem 5. To simplify notation\nin statement of the lemma, let A denote the set of all |U |2 \u00d71 column vectors of the form vec(\u03a5A), where \u03a5 is a |U |\u00d7|U |\nmatrix whose jth column, for j = 1, 2, . . . , |U |, is balanced and (0, 0)-polarized at j, and k\u03a5k2 \u2264 2|U |. It is easy to check\nthat the set A is closed, bounded, and convex. Let \u00c3 denote the cone hull of A. Then it can be readily checked that \u00c3 is the\nset of vectors of the same form that make up A with the norm bound k\u03a5k2 \u2264 2|U | removed.\nTheorem 4. Suppose that the right null space of B is non-trivial, and the observation channel (A, B) is non-manipulable.\nThen there exists a positive \u03ba, which depends only on A and B, satisfying the property that if \u03a8 is a |U |\u00d7|U | matrix whose\ncolumns are vectors in the right null space of B and k\u03a8k1 = 1, then there is a normalized vector \u03c5 simultaneously giving\n\u03c5 vec(\u03a8) \u2265 \u03ba and \u03c5\u03c9 T \u2264 0 for all \u03c9 T \u2208 A.\nProof: Let n = |U | \u2212 rank(B) \u2265 1 be the dimension of the right null space of B. Let \u039e be a |U | \u00d7 n matrix whose\ncolumns form an orthonormal basis of the right null space of B. By flipping the polarities of the columns of \u039e (i.e., the basis\nvectors), we obtain 2n different bases for the right null space of B. Fix a normalized \u03a8 with columns in the right null space\nof B. It is simple to check that |U1|2 \u2264 k\u03a8k22 \u2264 1. For each j = 1, 2, . . . , |U |, employing one, say \u039e(j), among the 2n bases\nPn \b\nabove we can decompose \u03a8Tj as \u03a8Tj = i=1 \u03a8Tj (\u039e(j)Ti )T \u039e(j)Ti with \u03a8Tj (\u039e(j)Ti )T \u2265\nP0n for all i. Let B be the convex hull\nof the set of vectors of the form vec(\u03a6), where \u03a6 is any |U |\u00d7|U | matrix such that \u03a6Tj = i=1 bi,j \u039e(j)Ti for j = 1, 2, . . . , |U |\nPn P|U |\nwith |U1|2 \u2264 i=1 j=1 b2i,j \u2264 1 and bi,j \u2265 0 for i and j. Obviously vec(\u03a8) \u2208 B. By geometric reasoning, B is a bounded\nset that does not contain the origin.\nSince (A, B) is non-manipulable, \u00c3 must intersect trivially with the set of vectors of the form vec(\u03a6\u0303), where \u03a6\u0303 is any\n|U |\u00d7|U | matrix whose columns are vectors in the right null space of B (i.e., the intersection contains only the zero vector).\nHence B and \u00c3 are disjoint. Below we employ a slightly stronger version of the argument given in [27, pp. 48] to show that\nB and \u00c3 can be strictly separated by a hyperplane that passes through the origin.\nGiven the above, we conclude that there exist \u03bcTa \u2208 \u00c3 and \u03bcTb \u2208 B that achieve the minimum (positive) Euclidean distance\nbetween \u00c3 and B. Now let \u03bcT1 be an arbitrary vector in \u00c3. Since \u00c3 is a convex cone, \u03bcTa + t(\u03b1\u03bcT1 \u2212 \u03bcTa ) \u2208 \u00c3 for all \u03b1 > 0\nand 0 < t \u2264 1. Hence k\u03bca + t(\u03b1\u03bc1 \u2212 \u03bca ) \u2212 \u03bcb k22 \u2265 k\u03bca \u2212 \u03bcb k22 for all \u03b1 > 0 and 0 < t \u2264 1, which (by letting t \u2193 0) implies\n\u0001\n1\nk\u03bca \u2212 \u03bcb k22 + k\u03bca k22 \u2212 k\u03bcb k22\n(20)\n(\u03bca \u2212 \u03bcb )\u03bcT1 \u2265\n2\u03b1\nfor all \u03b1 > 0. Further, letting \u03b1 \u2192 \u221e gives\n(\u03bca \u2212 \u03bcb )\u03bcT1 \u2265 0.\n(21)\nSimilarly, if \u03bcT2 be an arbitrary vector in B, then \u03bcTb +t(\u03bcT2 \u2212\u03bcTb ) \u2208 B by the convexity of B. Then k\u03bcb + t(\u03bc2 \u2212 \u03bcb ) \u2212 \u03bca k22 \u2265\nk\u03bca \u2212 \u03bcb k22 for all 0 < t \u2264 1 gives\n\u0001\n1\nk\u03bca \u2212 \u03bcb k22 + k\u03bcb k22 \u2212 k\u03bca k22\n(\u03bcb \u2212 \u03bca )\u03bcT2 \u2265\n2\n\u2265 k\u03bca \u2212 \u03bcb k22\n(22)\nwhere the second inequality is due to the fact that k\u03bcb k22 \u2212 k\u03bca k22 \u2265 k\u03bca \u2212 \u03bcb k22 , which can in turn be verified by letting\nk\u03bc \u2212\u03bc k2\n\u2212\u03bca\n\u03bcT1 = 0 in (20) since 0 \u2208 A. Substituting \u03bc1 = \u03c9, \u03bcT2 = vec(\u03a8), \u03c5 = k\u03bc\u03bcbb\u2212\u03bc\n, and \u03baB = k\u03bcbb \u2212\u03bcaa k21 in (21) and (22) almost\na k1\nestablishes the lemma. The only technicality left to handle is that \u03baB depends on \u03a8. Fortunately, the dependence on \u03a8 is only\nthrough the basis collection \u039e(1), \u039e(2), . . . , \u039e(|U |) that produces B. Since there are only finitely many such collections to start\nwith, the theorem is established by letting the required \u03ba to be the minimum among all the 2n|U | \u03baB 's for the corresponding\nbasis collections.\nB. Bounding attack channel estimation error\nRecall that the attack channel matrix \u03a6N is a |U |\u00d7|U | stochastic matrix. We consider below the stochastic matrix \u0393N =\nB\u03a6N A as defined in (2), as well as estimates \u03a6\u0302 and \u0393\u0302 of \u03a6N and \u0393N , respectively. In particular, we are interested in the\nestimators of \u03a6N in G\u03bc (\u0393\u0302) defined in Section III-D. For the purpose of proving Theorem 1 in the next section, the following\nresult, which bounds the estimation error of estimators in G\u03bc (\u0393\u0302), is important:\nTheorem 5. Let \u0393\u0302 be an estimate of \u0393N based on the observation (y1N , xN\n1 ). Let \u03bc > 0 and \u03a6\u0302 \u2208 G\u03bc (\u0393\u0302) be an estimate of\n\u03a6N . If (A, B) is non-manipulable, then\nk\u03a6N \u2212 \u03a6\u0302k1 \u2264 c1 \u03bc + c2 k\u0393N \u2212 \u0393\u0302k1 + c3 k\u03a6N \u2212 Ik1\nfor some positive constants c1 , c2 , and c3 that depend only on A and B.\n\n\f18\n\nProof: Let \u039eA and \u039eB denote the orthogonal projectors onto the left null space of A and right null space of B, respectively.\nWe decompose \u03a6N \u2212 \u03a6\u0302 into three components as below:\n\u03a6N \u2212 \u03a6\u0302 = (\u03a6N \u2212 \u03a6\u0302)\u039eA + \u039eB (\u03a6N \u2212 \u03a6\u0302)(I \u2212 \u039eA )\n{z\n} |\n{z\n}\n|\n\u0398A \u03a8A\n\n\u039bB\n\nN\n\n+ (I \u2212 \u039eB )(\u03a6 \u2212 \u03a6\u0302)(I \u2212 \u039eA )\n|\n{z\n}\n\n(23)\n\n\u039b\n\nA\n\nA\n\nwhere the rows of \u03a8 are normalized, and \u0398 is a |U |\u00d7|U | diagonal matrices whose strictly positive diagonal elements are\nthe normalization constants for the rows of \u03a8A . Note that the rows of \u03a8A are vectors in the left null space of A. Moreover\nthe columns of \u039bB are vectors in the right null space of B. Also note that we have assumed that \u03a8A does not contain any\nall-zero rows without any loss of generality (see (24) below). Because the rows of \u03a8A are normalized, we have from (23),\nk\u03a6N \u2212 \u03a6\u0302k1 \u2264 k\u039bB + \u039bk1 +\n\n|U |\nX\n\n\u0398A\ni,i .\n\n(24)\n\nI \u2212 \u03a6\u0302 = I \u2212 \u03a6N + \u0398A \u03a8A + \u039bB + \u039b.\n\n(25)\n\ni=1\n\nThus it suffices to bound k\u039bB + \u039bk1 and the diagonal elements of \u0398A .\nWe first bound the diagonal elements of \u0398A . To do this, rewrite (23) as\n\nBecause \u03a6\u0302 is a valid stochastic matrix, all diagonal elements of I \u2212 \u03a6\u0302 must be greater than or equal to 0 and all off-diagonal\nelements must be less than or equal 0. Thus (25) gives\n(\n\u2265 \u2212kI \u2212 \u03a6N k1 \u2212 k\u039bB + \u039bk1 if j = i\nA A\n\u0398i,i \u03a8i,j\n(26)\n\u2264 kI \u2212 \u03a6N k1 + k\u039bB + \u039bk1\nif j 6= i.\nNow by Lemma 6, we have \u000fs and \u000fA respectively satisfy (18) and (19) such that the left null space of A does not contain\nany (amin , \u000fA )-double polarized vectors. Hence we can choose a positive \u000f < amin so that the conclusion in Corollary 2 is\nvalid for all n = 2, 3, . . . , |U |. For this \u000f, define\nS\u000f = {i : \u03a8A\ni is (amin , \u000f)-polarized at i}.\nLet its cardinality be denoted by n\u000f .\nWe bound \u0398A\n/ S\u000f and i \u2208 S\u000f separately. First consider any i \u2208\n/ S\u000f . Lemma 2 states that [\u03a8A\ni,i for i \u2208\ni ]j \u2265 \u000f for some j 6= i.\nThus we have from (26) that\nkI \u2212 \u03a6N k1 + k\u039bB + \u039bk1\n,\n(27)\n\u0398A\n\u2264\ni,i\n\u000f\nfor all i \u2208\n/ S\u000f .\nNext we bound \u0398A\ni,i for i \u2208 S\u000f . If n\u000f = 0, then there is nothing to do. Hence we assume 1 \u2264 n\u000f \u2264 |U | below. Since each\ncolumn of \u039bB are in the right null space of B, it must be balanced\naccording to Lemma\nP|U\nP|U |7. Moreover it is true that each\n|\nA\ncolumn of \u03a6N \u2212 \u03a6\u0302 must also be balanced. As a result, (23) gives i=1 \u0398A\n\u03a8\n=\n\u2212\ni,i i,j\ni=1 \u039bi,j for j = 1, 2, . . . , |U |. The\ntriangle inequality then implies\n|U |\n|U |\nX\nX\nA\n\u0398A\n\u03a8\n\u2264\n|\u039bi,j |.\n(28)\ni,i i,j\ni=1\n\ni=1\n\nSeparating the sum on the left side of (28) into terms with index i in and not in S\u000f , we have, for j = 1, 2, . . . , |U |,\nX\n\nA\n\u0398A\ni,i \u03a8i,j\n\ni\u2208S\u000f\n\n\u2264\n\n|U |\nX\n\n|\u039bi,j | +\n\ni=1\n\nX\ni=1\n\nA\n\u0398A\ni,i |\u03a8i,j |\n\ni\u2208S\n/ \u000f\n\n|U |\n\n\u2264\n\nX\n\n|\u039bi,j | +\n\n\u0001\n|U |\nkI \u2212 \u03a6N k1 + k\u039bB + \u039bk1\n\u000f\n\n(29)\n\n\f19\n\nwhere the second inequality is obtained by using (27) and the fact that the rows of \u03a8A are normalized. For 2 \u2264 n\u000f \u2264 |U |,\nCorollary 2 suggests that for each i \u2208 S\u000f ,\n|U |\nX\nX\n\nA\n\u0398A\nk,k \u03a8k,j\n\n|U |\nX\n\n=\n\n\u0398A\ni,i\n\n>\n\n\u0398A\ni,i \u000fs .\n\nj=1\n\nj=1 k\u2208S\u000f\n\n\u03a8A\ni,j +\n\nX\n\n\u0398A\nk,k\n\nk\u2208S\u000f ,k6=i\n\n\u0398A\ni,i\n\n\u03a8A\nk,j\n(30)\nA\n\nNote that the bound in (30) is also trivially valid for the case of n\u000f = 1 since \u000fs < 1 and the rows of \u03a8\nSubstituting (29) into (30), we obtain that for each i \u2208 S\u000f ,\n\u0001\nk\u039bk1\n|U |2\n\u0398A\n+\nkI \u2212 \u03a6N k1 + k\u039bB + \u039bk1\ni,i <\n\u000fs\n\u000f\u000fs\n\nare normalized.\n\n(31)\n\nA\nBecause \u000fs \u2264 1, the upper bound on \u0398A\n/ S\u000f . Thus we can employ\ni,i for i \u2208 S\u000f is greater than the upper bound on \u0398i,i for i \u2208\nA\n(31) as an upper bound for all \u0398i,i 's. Note that the choices of \u000fA , \u000fs , and \u000f depend only A.\nNext we proceed to bound k\u039bB k1 . Similar to before, write \u039bB A = \u03b8B \u03a8B , where k\u03a8B k1 = 1 and \u03b8B is the non-negative\nscaling factor. If the right null space of B is trivial, \u039bB = 0 and hence \u03b8B = 0. Otherwise, \u03b8B > 0. Without loss of generality,\nsuppose the latter is true below. Because the linear mapping (*)A with domain restricted to the orthogonal complement of the\nleft null space of A is invertible, we have\nk\u039bB k1 \u2264 cA k\u039bB Ak1 = cA \u03b8B\n(32)\n\nfor some constant cA that depends only on A. Thus bounding \u03b8B is sufficient. To that end, right multiply both sides of (25)\nby A to obtain\n(33)\n(I \u2212 \u03a6\u0302)A = \u03b8B \u03a8B + (I \u2212 \u03a6N )A + \u039bA.\n| {z }\n\u2206\n\nSince \u03a6\u0302 is stochastic, vec(\u2206) \u2208 A, where A is the set of |U |2 \u00d7 1 column vectors defined just right before Theorem 4 in\nSection VI-A. As (A, B) is non-manipulable and the left-null space of B is non-trivial, Theorem 4 guarantees the existence\nof a positive constant \u03ba and a normalized vector \u03bd giving \u03bd vec(\u2206) \u2264 0 and \u03bd vec(\u03a8B ) \u2265 \u03ba. Note that \u03ba depends only on A\nand B. Hence left-multiplying both sides of the vectorized version of (33) by \u03bd yields\n\u03bd {vec((I \u2212 \u03a6N )A) + vec(\u039bA)}\n\u03ba\nk(I \u2212 \u03a6N )Ak1 + k\u039bAk1\n\u2264\n\u03ba\np\n\u0001\n|U ||X1 |2\nkI \u2212 \u03a6N k1 + k\u039bk1 .\n\u2264\n\u03ba\nApplying this bound on \u03b8B back to (32), we obtain\np\n\u0001\ncA |U ||X1 |2\nB\nk\u039b k1 \u2264\nkI \u2212 \u03a6N k1 + k\u039bk1 .\n(34)\n\u03ba\nTo complete the proof, we need to bound k\u039bk1 . Note that there exists \u0393\u0303 such that B \u03a6\u0302A = \u03a0B \u0393\u0303\u03a0A and k\u03a0B (\u0393\u0303 \u2212 \u0393\u0302)\u03a0A k1 \u2264\n\u03bc since \u03a6\u0302 \u2208 G\u03bc (\u0393\u0302). Then\n\u03b8B \u2264\n\nB\u039bA = B(\u03a6N \u2212 \u03a6\u0302)A = \u0393N \u2212 \u03a0B \u0393\u0303\u03a0A\n= \u03a0B (\u0393N \u2212 \u0393\u0302)\u03a0A + \u03a0B (\u0393\u0302 \u2212 \u0393\u0303)\u03a0A\nN\n\n(35)\n\nN\n\nwhere the last equality is due to the fact that \u0393 = \u03a0B \u0393 \u03a0A . Note that the linear mapping B(*)A with domain restricted\nsimultaneously to the orthogonal complements of the right null space of B and left null space of A is invertible. Combining\nthis fact and (35), there exists a positive constant cAB , which depends only on A and B, such that\n\u0011\n\u0010p\nk\u039bk1 \u2264 cAB\n|X1 ||Y1 | * k\u0393N \u2212 \u0393\u0302k1 + \u03bc .\n(36)\nFinally, substituting (36), (34), and (31) back into (24), we obtain the desired bound on k\u03a6N \u2212 \u03a6\u0302k1 given in the statement\nof the theorem with\n!\np\n\u0012\n\u0013\ncA |U ||X1 |2\ncAB |U |\n|U |3\nc1 =\n+ cAB 1 +\n1+\n\u000fs\n\u000f\u000fs\n\u03ba\np\nc2 = |X1 ||Y1 | * c1\np\n\u0012\n\u0013\ncA |U ||X1 |2\n|U |3\n|U |3\nc3 =\n+\n1+\n.\n\u000f\u000fs\n\u03ba\n\u000f\u000fs\n\n\f20\n\nC. Proof of Theorem 1 and Corollary 1\n1) Detectability: We prove the detectability portion of the theorem by showing that the sequence of decision statistics\n{DN = k\u03a6\u0302N \u2212 Ik1 }, where \u03a6\u0302N is the estimator for the stochastic matrix \u03a6N defined in (4), satisfies the two desired\nproperties if the observation channel (A, B) is non-manipulable.\nTo that end, first note that \u03a6\u0302N is obtained from the conditional histogram estimator \u0393\u0302N of the stochastic matrix \u0393N defined\nin (3). We need the following convergence property of the sequence {\u0393\u0302N }:\nLemma 8. k\u0393N \u2212 \u0393\u0302N k1 \u2192 0 in probability as N approaches infinity.\nProof: First, define the |U |\u00d7|X1 | stochastic matrix \u03a9N by its (i, j)th element as\n\u03a9N\ni,j ,\n\n\u03c0 N (vi , x1,j )\n.\n\u03c0 N (x1,j )\n\n(37)\n\nFor any \u03bc > 0, it is clear that\n\u0010\n\u0011\nPr k\u0393N \u2212 \u0393\u0302N k1 > \u03bc\n\u0010\n\u0010\n\u03bc\u0011\n\u03bc\u0011\n+ Pr kB\u03a9N \u2212 \u0393N k1 >\n\u2264 Pr kB\u03a9N \u2212 \u0393\u0302N k1 >\n2\n2\n\u0010\n\u03bc\u0011\nN\nN\n\u2264 Pr kB\u03a9 \u2212 \u0393\u0302 k1 >\n2\n!\n\u03bc\n+ Pr k\u03a9N \u2212 \u03a6N Ak1 > p\n.\n2 |X1 ||Y1 | * kBk2\n\n(38)\n\nThus the lemma is proved if we can show that the two probabilities on the right hand side of (38) converge to 0 as N\napproaches infinity.\nTo that end, notice first that\nkB\u03a9N \u2212 \u0393\u0302N k1\n=\n\n|Y1 | |X1 |\nX\nX\n\n|[B\u03a9N ]i,j \u2212 \u0393\u0302N\ni,j |\n\ni=1 j=1\n|Y1 | |X1 | |U |\n\n\u2264\n\nXXX\ni=1 j=1 k=1\n\n\u03c0 N (vk , x1,j ) \u03c0 N (y1,i , vk , x1,j )\n\u2212\np(y1,i |vk ) N\n\u03c0 (x1,j )\n\u03c0 N (x1,j )\n{z\n}\n|\nHi,j,k\n\nwhere the inequality above is due to the fact that \u03c0 N (y1,i , x1,j ) = k \u03c0 N (y1,i , vk , x1,j ). This implies that\n\u0010\n\u03bc\u0011\nPr kB\u03a9N \u2212 \u0393\u0302N k1 >\n2\n\u0013\n|Y1 | |X1 | |U |\nX\nXX \u0012\n\u03bc\n\u2264\nPr |Hi,j,k | >\n.\n2|U ||X1 ||Y1 |\ni=1 j=1\nP\n\n(39)\n\nk=1\n\nBut for any i, j, and k,\n\u0013\n\u03bc\n4|U |2 |X1 |2 |Y1 |2 \u0002 2 \u0003\n\u2264\nE Hi,j,k\n2|U ||X1 ||Y1 |\n\u03bc2\no\n4|U |2 |X1 |2 |Y1 |2 n\nN\nN\n2\nPr(x\n\u2208\n/\nT\n)\n+\nE\n[H\n]\n,\n\u2264\n[X\n],\u03b4\n1\ni,j,k\n[X1 ],\u03b4\n1\n\u03bc2\n\n\u0012\nPr |Hi,j,k | >\n\n(40)\n\n\f21\n\nN\nwhere E[X1 ],\u03b4 [*] denotes that conditional expectation E[*|xN\n1 \u2208 T[X1 ],\u03b4 ]. Further, for any small enough positive \u03b4,\n2\nE[X1 ],\u03b4 [Hi,j,k\n]\n\u0002\n\u0003\nE[X1 ],\u03b4 (p(y1,i |vk )\u03c0 N (vk , x1,j ) \u2212 \u03c0 N (y1,i , vk , x1,j ))2\n\u2264\nN 2 (p(x1,j ) \u2212 \u03b4)2\n\u0003 \u0015\n\u0014 \u0002\nPN\nE (p(y1,i |vk ) \u2212 1n (y1,i ))2 |v N , xN\n1\nE\nn=1 [X1 ],\u03b4\n* 1n (vk , x1,j )\n=\nN 2 (p(x1,j ) \u2212 \u03b4)2\np(y1,i |vk )\n\u2264\nN (p(x1,j ) \u2212 \u03b4)2\n\n(41)\n\nN N\nN\nwhere the equality on the third line above results from the fact that p(y1N |v N , xN\n1 ) = p(y1 |v ) and the elements of y1\nN\nare conditionally independent given v . Combining (41) and\n\u0010 the well known fact,\u0011for example see [26, Theorem 6.2], that\nN\nPr(xN\n\u2208\n/\nT\n)\n\u2192\n0\nas\nN\n\u2192\n\u221e,\nwe\nget\nfrom\n(40)\nthat\nPr\n|Hi,j,k | > 2|U ||X\u03bc1 ||Y1 | \u2192 0 as N \u2192 \u221e. Using (39), we further\n1\n\u0010 [X1 ],\u03b4\n\u0011\nget Pr kB\u03a9N \u2212 \u0393\u0302N k1 > \u03bc2 \u2192 0 as N \u2192 \u221e.\nNext, note that we can rewrite (37) as\n\u03c0 N (ui , x1,j ) X \u03c0 N (vk , ui , x1,j )\n\u03a9N\n\u2212\ni,j =\n\u03c0 N (x1,j )\n\u03c0 N (x1,j )\nk6=i\n\n+\n\nX \u03c0 N (vi , uk , x1,j )\nk6=i\n\n\u03c0 N (x1,j )\n\n.\n\nSimilarly, we have\n\u0002\n\n\u03a6N A\n\n\u0003\ni,j\n\n= p(ui |x1,j ) \u2212\n\nX \u03c0 N (vk , ui )\n\u03c0 N (ui )\n\nk6=i\n\n+\n\nX \u03c0 N (vi , uk )\nk6=i\n\n\u03c0 N (uk )\n\np(ui |x1,j )\n\np(uk |xj ).\n\nLet\n\u03c0 N (ui , x1,j )\n\u2212 p(ui |x1,j )\n\u03c0 N (x1,j )\nX \u03c0 N (vk , ui , x1,j ) \u03c0 N (vk , ui )\n=\n\u2212\np(ui |x1,j )\n\u03c0 N (x1,j )\n\u03c0 N (ui )\n\n1\nHi,j\n=\n2\nHi,j\n\nk6=i\n\n3\nHi,j\n=\n\nX \u03c0 N (vi , uk , x1,j )\nk6=i\n\n\u03c0 N (x\n\n1,j )\n\n\u2212\n\n\u03c0 N (vi , uk )\np(uk |x1,j ).\n\u03c0 N (uk )\n\nThen we have, for each i and j,\nPr\n\n\u03a9N\ni,j\n\nN\n\n\u2212 [\u03a6 A]i,j >\n\n\u03bc\n\np\n2|U ||X1 | |X1 ||Y1 | * kBk2\n!\n3\nX\n\u03bc\nl\np\n\u2264\nPr |Hi,j | >\n.\n6|U ||X1 | |X1 ||Y1 | * kBk2\nl=1\n\n!\n\n(42)\n\nN\nN\nN N\nN\nBy employing the fact that p(xN\ngiven xN\n1 |u , v ) = p(x1 |u ) and the conditional independence of the elements of u\n1 ,\neach of the three probabilities on the right hand side of\u0010(42) can be shown to converge\nto\n0\nas\nN\napproaches\ninfinity\nby\nusing\n\u0011\ntypicality arguments similar to the one that shows Pr |Hi,j,k | > 2|U ||X\u03bc1 ||Y1 | \u2192 0 above. Thus, the probability on the left\n\n\f22\n\nhand side of (42) also converges to 0 as N approaches infinity. Finally,\nN\n\n!\n\n\u03bc\n\nN\n\nPr k\u03a9 \u2212 \u03a6 Ak1 > p\n2 |X1 ||Y1 | * kBk2\n\u2264\n\n|U | |X1 |\nX\nX\n\nPr\n\nN\n\u03a9N\ni,j \u2212 [\u03a6 A]i,j\n\ni=1 j=1\n\n>\n\n\u03bc\n\n!\n\np\n2|U ||X1 | |X1 ||Y1 | * kBk2\n\n\u2192 0\nas N \u2192 \u221e.\nNow we proceed to show detectability in Theorem 1. For any fixed \u03bc > 0, choose \u03a6\u0302N according to (4). It is clear from\n. Thus Lemma 8 implies\nthe definition of G\u03bc (\u0393\u0302N ) in Section III-D that \u03a6N \u2208 G\u03bc (\u0393\u0302N ) whenever k\u0393N \u2212 \u0393\u0302N k1 \u2264 \u221a \u03bc\n|X1 ||Y1 |\n\nthat Pr(\u03a6N \u2208 G\u03bc (\u0393\u0302N )) \u2192 1 as N \u2192 \u221e, and hence the probability that G\u03bc (\u0393\u0302N ) is non-empty approaches 1. We employ this\nproperty below to show that the sequence of decision statistics {k\u03a6\u0302N \u2212 Ik1 } satisfies both Properties 1 and 2 stated in the\ntheorem.\nTo show Property 1 of Theorem 1, first note that\n\u0010\n\u0011\n\\\nPr k\u03a6\u0302N \u2212 Ik1 > \u03b4\nk\u03a6N \u2212 Ik1 > \u03b4\n\u0010\n\\\n\u2265 Pr \u03a6N \u2208 G\u03bc (\u0393\u0302N )\nk\u03a6\u0302N \u2212 Ik1 > \u03b4\n\u0011\n\\\nk\u03a6N \u2212 Ik1 > \u03b4\n\u0010\n\u0011\n\\\n= Pr \u03a6N \u2208 G\u03bc (\u0393\u0302N )\nk\u03a6N \u2212 Ik1 > \u03b4\n\u2265 Pr(k\u03a6N \u2212 Ik1 > \u03b4) \u2212 Pr(\u03a6N \u2208\n/ G\u03bc (\u0393\u0302N ))\nN\n\n(43)\nN\n\nwhere the equality on the third line is due to the definition of \u03a6\u0302 in (4). Hence, if lim supN \u2192\u221e Pr(k\u03a6 \u2212 Ik1 > \u03b4) > 0,\n(43) implies\nlim sup Pr(k\u03a6\u0302N \u2212 Ik1 > \u03b4 | k\u03a6N \u2212 Ik1 > \u03b4) = 1.\nN \u2192\u221e\n\nTo show Property 2 of Theorem 1, consider the constants c1 , c2 , and c3 given in Theorem 5. Let c = 2 + c3 . By choosing\n0 < \u03bc \u2264 2c\u03b41 and making use of Theorem 5, it is easy to check that\n!\n\\\n\u03bc\nN\nN\nN\nPr k\u0393 \u2212 \u0393\u0302 k1 \u2264 p\nk\u03a6 \u2212 Ik1 \u2264 \u03b4\n|X1 ||Y1 |\n\u0010\n\u0011\n\\\n\u2264 Pr k\u03a6\u0302N \u2212 Ik1 \u2264 c\u03b4\nk\u03a6N \u2212 Ik1 \u2264 \u03b4\nwhich in turn implies\n\u0010\n\u0011\n\\\nPr k\u03a6\u0302N \u2212 Ik1 > c\u03b4\nk\u03a6N \u2212 Ik1 \u2264 \u03b4\n!\n\u03bc\nN\nN\n\u2264 Pr k\u0393 \u2212 \u0393\u0302 k1 > p\n.\n|X1 ||Y1 |\n\n(44)\n\nHence by Lemma 8, if lim inf N \u2192\u221e Pr(k\u03a6N \u2212 Ik1 \u2264 \u03b4) > 0, (44) gives\nlim Pr(k\u03a6\u0302N \u2212 Ik1 > c\u03b4 | k\u03a6N \u2212 Ik1 \u2264 \u03b4) = 0.\n\nN \u2192\u221e\n\n2) Corollary 1: Now we can use the results above to prove Corollary 1 by showing the sequence of decision statistics\n{k\u03a6\u0302N \u2212 Ik1 } satisfies the four stated properties under the corresponding special cases:\na) k\u03a6N \u2212 Ik1 \u2192 0 in probability: Since\nPr(k\u03a6\u0302N \u2212 Ik1 > \u03b4)\n\u0012\n\u0013\n\u03b4\n\u2264 Pr k\u03a6\u0302N \u2212 Ik1 > \u03b4 k\u03a6N \u2212 Ik1 \u2264\nc\n\u0012\n\u0013\n\u0012\n\u0013\n\u03b4\n\u03b4\n* Pr k\u03a6N \u2212 Ik1 \u2264\n+ Pr k\u03a6N \u2212 Ik1 >\nc\nc\nfor any \u03b4 > 0, Property 2 of Theorem 1 implies limN \u2192\u221e Pr(k\u03a6\u0302N \u2212 Ik1 > \u03b4) = 0.\n\n\f23\n\nb) k\u03a6N \u2212 Ik1 9 0 in probability: If lim supN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4) = 0, then there is nothing to show. Otherwise,\nLemma 8 and (43) give lim supN \u2192\u221e Pr(k\u03a6\u0302N \u2212 Ik1 > \u03b4) \u2265 lim supN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4).\nc) k\u03a6NM \u2212 \u03a6k1 \u2192 0 in probability and \u03a6 6= I: Note that there exists \u03b4 > 0 such that lim supN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 >\n\u03b4) = 1 in this case. For any such \u03b4, Property 2 just above implies the required result.\nd) k\u03a6N \u2212 \u03a6k1 \u2192 0 in probability and \u03a6 6= I: In this case, there exists \u03b4 > 0 such that limN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 > \u03b4) = 1.\nUsing Lemma 8 and (43) gives the desired result for any such \u03b4.\nN\n3) Converse: Recall that xN\n1 and y1 are the sequences of symbols transmitted and received by node 1 at time instants\nN\n1, 2, . . . , N and N + 1, N + 2, . . . , 2N , respectively. Let DN = DN (xN\n1 , y1 ) be the N th decision statistic in the sequence,\nassumed to exist in the statement of Theorem 1, that satisfies Properties 1 and 2. Suppose that there exists a stochastic \u03a60 6= I\nsuch that B\u03a60 A = BA , \u0393.\nQN\nFor the identity relay manipulation map, i.e., \u03c6N (uN ) = uN , it is easy to check that p(v n |un ) = n=1 I\u03c7n (vN ),\u03c7n (uN ) ,\nQ\nN\n\u03a6N = I, and p(y N |xN ) = n=1 \u0393\u03c7n (y1N ),\u03c7n (xN\n. Since \u03a6N = I for all N , we have for every \u03b4 > 0,\n1 )\n\"N\n#\nX\nY\n\u0393\u03c7n (y1N ),\u03c7n (xN\n* p(x1,\u03c7n (xN\n)\n1 )\n1 )\ni=n\n\nN\nN\nN\nN\n(xN\n1 ,y1 ):D (x1 ,y1 )>\u03b4\n\n{z\n\n|\nPr(DN > \u03b4)\n\u0012\nPr DN > \u03b4\n\n=\n=\n\n}\n\nq(y1N ,xN\n1 )\n\n\u03b4\nk\u03a6 \u2212 Ik1 \u2264\nc\nN\n\n\u0013\n\n\u2192 0\n\n(45)\n\nwhere the convergence on the last line is due to the assumption that Property 2 of Theorem 1 holds, and c is the constant\ndescribed in the property.\nQN\nConsider now the random relay manipulation map that results in p(v n |un ) = n=1 \u03a60\u03c7n (vN ),\u03c7n (uN ) . For this random\nQ\nN\nmanipulation map, it is again easy to check that p(y N |xN ) = n=1 \u0393\u03c7n (y1N ),\u03c7n (xN\n, which is a consequence of the assumption\n1 )\n0\nN\n0\n0\nthat B\u03a6 A = \u0393, and k\u03a6 \u2212 \u03a6 k1 \u2192 0 in probability. Since \u03a6 6= I, there exists a \u03b4 > 0 such that limN \u2192\u221e Pr(k\u03a6N \u2212 Ik1 >\n\u03b4) = 1. For this \u03b4,\nX\nlim sup\nq(y1N , xN\n1 )\nN \u2192\u221e\n\n=\n\u2265\n\nN\nN\nN\nN\n(xN\n1 ,y1 ):D (x1 ,y1 )>\u03b4\n\nlim sup Pr(DN > \u03b4)\nN \u2192\u221e\n\u0010\nlim sup Pr DN > \u03b4\n\nk\u03a6N \u2212 Ik1 > \u03b4\n\n\u0011\n\nN \u2192\u221e\n\n* lim Pr(k\u03a6N \u2212 Ik1 > \u03b4)\nN \u2192\u221e\n\n=\n\n1\n\n(46)\n\nwhere the equality on the last line is due to the assumption that Property 1 of Theorem 1 holds. The conclusions in (45) and\n(46) are clearly in conflict and can not be simultaneously true. Therefore there can not exist a stochastic \u03a60 6= I such that\nB\u03a60 A = BA and Properties 1 and 2 hold.\nTo complete the proof of the converse, we need to show the existence of a stochastic \u03a60 6= I with the property that\nB\u03a60 A = BA when the observation channel (A, B) is manipulable. To that end, first note that the manipulability of (A, B)\nimplies the existence of a non-zero \u03a5 with the property that all columns of \u03a5A are in the right null space of B. In addition,\nand \u03a60 = I \u2212 \u03a5\u0303. It then easy to\n(\u03a5Tj )T is balanced and (0, 0)-polarized at j, for each j = 1, 2, . . . , |U |. Let \u03a5\u0303 = max\u03a5\nj \u03a5j,j\n0\n0\n0\ncheck that this \u03a6 is a valid stochastic matrix, \u03a6 6= 1, and B\u03a6 A = BA.\n\n\f24\n\nD. Justification for Algorithms 1 and 2\nAlgorithm 1: Let \u03a5 be a |U |\u00d7|U | matrix-valued variable and s be a |U |\u00d71 vector-valued variable. Consider the following\nconvex optimization problem:\nmin min{\u2212s1 , \u2212s2 , . . . , \u2212s|U | }\ns,\u03a5\n\nsubject to\nB\u03a5A = 0\n|U |\nX\n\n\u03a5k,l = 0\n\nl = 1, 2, . . . , |U |,\n\nk=1\n\nsk \u2212 \u03a5k,k \u2264 0\n\nk = 1, 2, . . . , |U |,\n\n\u03a5k,k \u2212 1 \u2264 0\n\nk = 1, 2, . . . , |U |,\n\n\u03a5k,l \u2264 0\n\nk 6= l = 1, 2, . . . , |U |.\n\n(47)\n\nIt is clear that the optimal value of (47) is attained and lies inside the interval [\u22121, 0]. This further implies that (A, B) is\nnon-manipulable if and only if the optimal value of (47) is 0.\nNow, let \u03a9 and \u03bd be the |X1 |\u00d7|Y1 | matrix-valued and |U |\u00d71 vector-valued Lagrange multipliers for the equality constraints\nshown in the third and fourth lines of (47). Further, let \u039b be the |U | \u00d7 |U | matrix-valued Lagrange multiplier matrix. The\ndiagonal elements of \u039b correspond to the inequality constraints shown in the fifth line of (47), while the off-diagonal elements\ncorrespond to the inequality constraints shown in the last line of (47). At last, let \u03bd be the |U | \u00d71 vector-valued Lagrange\nmultiplier for the inequality constraints shown in second line of (47). Following the development in [27, Ch. 5], we obtain the\nLagrange dual function of (47) as below:\ng(\u03b3, \u039b, \u03bd, \u03a9)\n\uf8f1 P\n|U |\n\uf8f4\n\u2212 k=1 \u03b3k\nif\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\u039b\n\u2265\n1\nk = 1, 2, . . . , |U |,\nk,k\n\uf8f2\n=\n\u03b3k + \u03bdk + [A\u03a9B]k,k = \u039bk,k k = 1, 2, . . . , |U |,\n\uf8f4\n\uf8f4\n\uf8f4\n\u03bd\nk 6= l = 1, 2, . . . , |U |\n\uf8f4\nk + [A\u03a9B]k,l = \u2212\u039bk,l\n\uf8f4\n\uf8f4\n\uf8f3\u2212\u221e\notherwise.\nConsider the Lagrange dual problem of (47):\nmax g(\u03b3, \u039b, \u03bd, \u03a9)\n\n\u03b3,\u039b,\u03bd,\u03a9\n\nsubject to\n\u03b3k \u2265 0\n\u039bk,l \u2265 0\n\nk = 1, 2, . . . , |U |,\nk, l = 1, 2, . . . , |U |.\n\n(48)\n\nSince the primal problem (47) satisfies the Slater's condition [27, Ch. 5], the optimal duality gap between the primal and dual\nproblems is zero. That is, the optimal value of (48) is the same as the optimal value of (47). Hence (A, B) is non-manipulable\nif and only if the optimal value of (48) is 0. Finally, it is easy to verify that the negation of the optimal value of the linear\nprogram in Step 2 of Algorithm 1 is the optimal value of (48) and vice versa. As a result, Algorithm 1 determines whether\n(A, B) is manipulable.\nProof of Theorem 2: In the proof of Lemma 6, we have shown that the condition of (A, B) being non-manipulable implies\nthat no normalized, (amin , 0)-double polarized vector can be in the left null space of A. It remains to show the reverse\nimplication here.\nGiven that the left null space of A does not contain any (amin , 0)-double polarized vector, we need to show that (A, B) is\nnon-manipulable when the right null space of B is trivial. To that end, let us suppose on the contrary that (A, B) is manipulable.\nSince the right null space of B is trivial, there exists a |U |\u00d7|U | non-zero matrix \u03a5 in the left null space of A, with its jth\ncolumn, (\u03a5Tj )T , for each j = 1, 2, . . . , |U |, is balanced and (0, 0)-polarized at j. Let m be the number of non-zero columns\nof \u03a5. By proper permutation of rows and columns of \u03a5 if necessary, we can assume with no loss of generality that the first\nm columns are non-zero while the remaining |U | \u2212 m columns are zero.\nFirst, we claim that m \u2265 2. Indeed, suppose that m = 1 and only the first column (\u03a5T1 )T is non-zero. Then we have\n\u03a51,1 > 0 and \u03a51,1 A1 = 0. Since it is our assumption that A contains no zero rows, we must have \u03a51,1 = 0, which creates a\ncontradiction.\n\n\f25\n\nNext, let\n\u03a51\nk\u03a51 k1\n\u03a52\n\u03a5\u03032 =\nk\u03a52 k1\n..\n.\nP|U |\ni=m \u03a5i\n\u03a5\u0303m = P|U\n.\n|\nk i=m \u03a5i k1\n\u03a5\u03031 =\n\nPut these m row vectors together to form the m\u00d7|U | matrix \u03a5\u0303. Using the fact that (\u03a5Tj )T is balanced and (0, 0)-polarized at\nj for j = 1, 2, . . . , m together with Lemma 1, it is easy to check that \u03a5\u0303 is a normalized, (amin , 0)-polarized matrix in the left\nnull space of A. Moreover, it is also true that\nm\u22121\nX\ni=1\n\nk\u03a5i k1 \u03a5\u0303i +\n\n|U |\nX\ni=m\n\n\u03a5\u0303m = 0.\n\n\u03a5i\n\n(49)\n\n1\n\nNow, as argued in the proof of Lemma 6, there must exist \u000fs and \u000fA , which respectively satisfy (18) and (19), such that the\nleft null space of A contains no (amin , \u000fA )-double polarized vector. Hence we can apply Corollary 2 to \u03a5\u0303 to deduce that no\nrow of it can be \u000fs -dependent upon the other rows. However, this conclusion contradicts (49). Therefore (A, B) must not be\nmanipulable.\nAlgorithm 2: We use Lemma 1 to show that the Algorithm 2 can be used to check for double polarized vectors in the\nleft null space of A. To that end, recall that n = |U | \u2212 rank(A) is the dimension of the left null space of A. If n = 0, the\nleft null space of A is trivial and hence it can not contain any normalized, (amin , 0)-double polarized vector. For n > 0, let\n\u03a5 = (I \u03a5\u0303) be the row-reduced echelon basis matrix as stated in Step 2) of the algorithm. When n = |U | \u2212 1, \u03a5\u0303i is a scalar,\nfor i = 1, 2, . . . , n. By Lemma 1, \u03a5\u0303i must be negative and the normalized version of \u03a5i must be a (amin , 0)-double polarized\nvector in the left null space of A.\nNow assume 1 \u2264 n \u2264 |U | \u2212 2 and consider the stated steps. First note that any (amin , 0)-double polarized vector in the left\nnull space of A can only be a linear combination of at most two rows of \u03a5. If in Step 3c) there is a \u03a5\u0303i that contains all but one\nzero element, Lemma 1 again forces the non-zero element be negative and the normalized version of \u03a5i be a (amin , 0)-double\npolarized vector in the left null space of A. Otherwise no (normalized) rows of \u03a5 can be (amin , 0)-double polarized. Hence\nit remains to check whether any pair of rows of \u03a5 can be linearly combined to form a double polarized vector. Without loss\nof generality, suppose that the normalized version of c1 \u03a51 + c2 \u03a52 is (amin , 0)-double polarized for some non-zero constants\nc1 and c2 . Then it is easy to see that c1 and c2 must be of opposite signs and \u03a5\u03031 = \u2212 cc12 \u03a5\u03032 . Hence if no pairs of rows of \u03a5\u0303\nsatisfy the condition checked in Step 3d), the left null space of A can not contain any normalized, (amin , 0)-double polarized\nvector.\nVII. C ONCLUSIONS\nWe showed that it is possible to detect whether an amplify-and-forward relay is maliciously manipulating the symbols that it\nforwards to the other nodes by just monitoring the relayed symbols. In particular, we established a non-manipulable condition\non the channel that serves as a necessary and sufficient requirement guaranteeing the existence of a sequence of decision\nstatistics that can be used to distinguish a malicious relay from a non-malicious one.\nAn important conclusion of the result is that maliciousness detectability in the context of Theorem 1 is solely determined\nby the source distributions and the conditional pmfs of the underlying MAC and BC in the channel model, regardless of how\nthe relay may manipulate the symbols. Thus similar to capacity, maliciousness detectability is in fact a channel characteristic.\nThe development of maliciousness detectability in this paper did not take any restrictions on the rate and coding structure\nof information transfer between the sources into account. A joint formulation of maliciousness detectability and information\ntransfer is currently under investigation.\nAnother interesting application of the result is that the necessity of non-manipulability can be employed to show that\nmaliciousness detectability is impossible for non amplify-and-forward relays in many channel scenarios. For instance, if Romeo\nin the motivating example considered in Section II forwards his received symbol modulo-2 instead, we arrive at the physicallayer network coding (PNC) model considered in [28]. The necessity condition of Theorem 1 can be employed to verify the\nimpossibility of maliciousness detectability with the PNC operation represented by the matrix B. For this relaying operation,\nadditional signaling may be needed to allow for maliciousness detection.\n\n\f26\n\nR EFERENCES\n[1] M. Blaze, J. Feigenbaum, and J. Lacy, \"Decentralized trust management,\" in Proc. IEEE Symposium on Security and Privacy, pp. 164\u2013173, May 1996.\n[2] J.-P. Hubaux, L. Butty\u00e1n, and S. Capkun, \"The quest for security in mobile ad hoc networks,\" in Proceedings of the 2nd ACM international symposium\non Mobile ad hoc networking & computing, MobiHoc '01, (New York, NY, USA), pp. 146\u2013155, ACM, 2001.\n[3] L. Buttyan and J.-P. Hubaux, Security and Cooperation in Wireless Networks. Cambridge, UK: Cambridge University Press, 2007.\n[4] R. Changiz, H. Halabian, F. Yu, I. Lambadaris, H. Tang, and C. Peter, \"Trust establishment in cooperative wireless networks,\" in Proc. 2010 IEEE.\nMilitary Commun. Conf., pp. 1074\u20131079, Nov. 2010.\n[5] S. Dehnie, H. Senear, and N. Memon, \"Detecting malicious behavior in cooperative diversity,\" in Proc. 41st Annual Conf. on Inform. Sci. and Syst.,\npp. 895\u2013899, Mar. 2007.\n[6] W. Gong, Z. You, D. Chen, X. Zhao, M. Gu, and K.-Y. Lam, \"Trust based malicious nodes detection in MANET,\" in Proc. 2009 IEEE Int. Conf.\nE-Business and Inform. Syst. Security, pp. 1\u20134, May 2009.\n[7] X. Jiang, C. Lin, H. Yin, Z. Chen, and L. Su, \"Game-based trust establishment for mobile ad hoc networks,\" in Proc. 2009 Int. Conf. Commun. and\nMobile Comput., vol. 3, pp. 475\u2013479, Jan. 2009.\n[8] T. Jiang and J. S. Baras, \"Trust evaluation in anarchy: A case study on autonomous networks,\" in Proc. INFOCOM 2006, pp. 1\u201312, Apr. 2006.\n[9] G. Theodorakopoulos and J. S. Baras, \"Trust evaluation in ad-hoc networks,\" in Proceedings of the 3rd ACM workshop on Wireless security, WiSe '04,\n(New York, NY, USA), pp. 1\u201310, ACM, 2004.\n[10] C. Zhang, X. Zhu, Y. Song, and Y. Fang, \"A formal study of trust-based routing in wireless ad hoc networks,\" in Proc. IEEE INFOCOM 2010, 2010.\n[11] S. Capkun, L. Buttyan, and J.-P. Hubaux, \"Self-organized public-key management for mobile ad hoc networks,\" IEEE Transactions on Mobile Computing,\nvol. 2, pp. 52\u201364, Jan.-Mar. 2003.\n[12] T. Beth, M. Borcherding, and B. Klein, \"Valuation of trust in open networks,\" in Computer Security ESORICS 94 (D. Gollmann, ed.), vol. 875 of\nLecture Notes in Computer Science, pp. 1\u201318, Springer Berlin / Heidelberg, 1994. 10.1007/3-540-58618-0 53.\n[13] C. Zhang, Y. Song, and Y. Fang, \"Modeling secure connectivity of self-organized wireless ad hoc networks,\" in Proc. of INFOCOM 2008, (Phoenix,\nAZ), Apr. 2008.\n[14] Y.-L. Sun, W. Yu, Z. Han, and K. Liu, \"Information theoretic framework of trust modeling and evaluation for ad hoc networks,\" IEEE Journal on\nSelected Areas in Communications, vol. 24, pp. 305\u2013317, Feb. 2006.\n[15] F. Oliviero and S. Romano, \"A reputation-based metric for secure routing in wireless mesh networks,\" in Proc. of IEEE GLOBECOM 2008, (New\nOrleans, LA), Dec. 2008.\n[16] A. J\u00f8sang, \"An algebra for assessing trust in certification chains,\" in Proc. NDSS99, (San Diego, CA), Feb. 1999.\n[17] G. Theodorakopoulos and J. S. Baras, \"On trust models and trust evaluation metrics for ad hoc networks,\" IEEE Journal on Selected Areas in\nCommunications, vol. 24, pp. 318\u2013328, Feb. 2006.\n[18] S. Capkun, J. Hubaux, and L. Buttyan, \"Mobility helps security in ad hoc networks,\" in Proc. MobiHoc 2003, (Annapolis, MD), June 2003.\n[19] S. Marti, T. J. Giuli, K. Lai, and M. Baker, \"Mitigating routing misbehavior in mobile ad hoc networks,\" in Proceedings of the 6th annual international\nconference on Mobile computing and networking, MobiCom '00, (New York, NY, USA), pp. 255\u2013265, ACM, 2000.\n[20] E. Kehdi and B. Li, \"Null keys: Limiting malicious attacks via null space properties of network coding,\" in Proc. 2009 IEEE Int. Conf. Computer\nCommun., pp. 1224\u20131232, Apr. 2009.\n[21] Y.-C. Hu, A. Perrig, and D. B. Johnson, \"Ariadne: A secure on-demand routing protocol for ad hoc networks,\" Wirel. Netw., vol. 11, pp. 21\u201338, Jan.\n2005.\n[22] P. Papadimitratos and Z. Haas, \"Secure data communication in mobile ad hoc networks,\" IEEE Journal on Selected Areas in Communications, vol. 24,\npp. 343\u2013356, Feb. 2006.\n[23] Y. Mao and M. Wu, \"Tracing malicious relays in cooperative wireless communications,\" IEEE Trans. Inform. Forensics and Security, vol. 2, pp. 198\u2013212,\nJune 2007.\n[24] J. Mitchell, A. Ramanathan, A. Scedrov, and V. Teague, \"A probabilistic polynomial-time calculus for analysis of cryptographic protocols: (preliminary\nreport),\" Electronic Notes in Theoretical Computer Science, vol. 45, no. 0, pp. 280\u2013310, 2001. MFPS 2001, Seventeenth Conference on the Mathematical\nFoundations of Programming Semantics.\n[25] E. Graves and T. F. Wong, \"Detection of channel degradation attack by intermediary node in linear networks,\" in Proc. IEEE INFOCOM, (Orlando,\nFL), Mar. 2012.\n[26] R. W. Yeung, Information Theory and Network Coding. New York: Springer, 2008.\n[27] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge University Press, 2004.\n[28] S. Zhang, S. C. Liew, and P. P. Lam, \"Hot topic: physical-layer network coding,\" in Proceedings of the 12th annual international conference on Mobile\ncomputing and networking, MobiCom '06, (New York, NY, USA), pp. 358\u2013365, ACM, 2006.\n\n\f"}