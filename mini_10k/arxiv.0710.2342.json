{"id": "http://arxiv.org/abs/0710.2342v1", "guidislink": true, "updated": "2007-10-11T20:28:44Z", "updated_parsed": [2007, 10, 11, 20, 28, 44, 3, 284, 0], "published": "2007-10-11T20:28:44Z", "published_parsed": [2007, 10, 11, 20, 28, 44, 3, 284, 0], "title": "Theory of input spike auto- and cross-correlations and their effect on\n  the response of spiking neurons", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0710.4735%2C0710.2094%2C0710.5620%2C0710.0827%2C0710.2373%2C0710.2265%2C0710.0674%2C0710.5150%2C0710.3052%2C0710.5039%2C0710.1526%2C0710.0300%2C0710.1106%2C0710.2430%2C0710.5900%2C0710.1930%2C0710.4804%2C0710.5327%2C0710.1407%2C0710.5533%2C0710.1543%2C0710.4961%2C0710.3989%2C0710.0051%2C0710.4978%2C0710.3879%2C0710.5324%2C0710.0752%2C0710.1444%2C0710.2559%2C0710.3276%2C0710.3452%2C0710.2545%2C0710.2171%2C0710.4312%2C0710.1627%2C0710.1849%2C0710.0557%2C0710.3110%2C0710.3894%2C0710.1774%2C0710.5908%2C0710.5204%2C0710.3312%2C0710.1312%2C0710.2885%2C0710.4651%2C0710.1493%2C0710.2020%2C0710.0842%2C0710.5732%2C0710.0398%2C0710.1626%2C0710.2970%2C0710.5420%2C0710.0571%2C0710.1776%2C0710.0498%2C0710.2874%2C0710.2911%2C0710.5847%2C0710.5175%2C0710.2564%2C0710.1672%2C0710.2106%2C0710.4930%2C0710.1621%2C0710.4269%2C0710.1368%2C0710.1902%2C0710.2342%2C0710.3071%2C0710.3487%2C0710.1874%2C0710.1510%2C0710.4986%2C0710.5137%2C0710.4466%2C0710.4339%2C0710.0565%2C0710.3111%2C0710.3667%2C0710.2039%2C0710.3347%2C0710.5136%2C0710.0666%2C0710.2126%2C0710.3598%2C0710.2165%2C0710.0473%2C0710.1599%2C0710.2100%2C0710.2513%2C0710.2431%2C0710.1187%2C0710.1575%2C0710.5005%2C0710.0688%2C0710.5125%2C0710.3354%2C0710.4109&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Theory of input spike auto- and cross-correlations and their effect on\n  the response of spiking neurons"}, "summary": "Spike correlations between neurons are ubiquitous in the cortex, but their\nrole is at present not understood. Here we describe the firing response of a\nleaky integrate-and-fire neuron (LIF) when it receives a temporarily correlated\ninput generated by presynaptic correlated neuronal populations. Input\ncorrelations are characterized in terms of the firing rates, Fano factors,\ncorrelation coefficients and correlation timescale of the neurons driving the\ntarget neuron. We show that the sum of the presynaptic spike trains cannot be\nwell described by a Poisson process. Solutions of the output firing rate are\nfound in the limit of short and long correlation time scales.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0710.4735%2C0710.2094%2C0710.5620%2C0710.0827%2C0710.2373%2C0710.2265%2C0710.0674%2C0710.5150%2C0710.3052%2C0710.5039%2C0710.1526%2C0710.0300%2C0710.1106%2C0710.2430%2C0710.5900%2C0710.1930%2C0710.4804%2C0710.5327%2C0710.1407%2C0710.5533%2C0710.1543%2C0710.4961%2C0710.3989%2C0710.0051%2C0710.4978%2C0710.3879%2C0710.5324%2C0710.0752%2C0710.1444%2C0710.2559%2C0710.3276%2C0710.3452%2C0710.2545%2C0710.2171%2C0710.4312%2C0710.1627%2C0710.1849%2C0710.0557%2C0710.3110%2C0710.3894%2C0710.1774%2C0710.5908%2C0710.5204%2C0710.3312%2C0710.1312%2C0710.2885%2C0710.4651%2C0710.1493%2C0710.2020%2C0710.0842%2C0710.5732%2C0710.0398%2C0710.1626%2C0710.2970%2C0710.5420%2C0710.0571%2C0710.1776%2C0710.0498%2C0710.2874%2C0710.2911%2C0710.5847%2C0710.5175%2C0710.2564%2C0710.1672%2C0710.2106%2C0710.4930%2C0710.1621%2C0710.4269%2C0710.1368%2C0710.1902%2C0710.2342%2C0710.3071%2C0710.3487%2C0710.1874%2C0710.1510%2C0710.4986%2C0710.5137%2C0710.4466%2C0710.4339%2C0710.0565%2C0710.3111%2C0710.3667%2C0710.2039%2C0710.3347%2C0710.5136%2C0710.0666%2C0710.2126%2C0710.3598%2C0710.2165%2C0710.0473%2C0710.1599%2C0710.2100%2C0710.2513%2C0710.2431%2C0710.1187%2C0710.1575%2C0710.5005%2C0710.0688%2C0710.5125%2C0710.3354%2C0710.4109&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Spike correlations between neurons are ubiquitous in the cortex, but their\nrole is at present not understood. Here we describe the firing response of a\nleaky integrate-and-fire neuron (LIF) when it receives a temporarily correlated\ninput generated by presynaptic correlated neuronal populations. Input\ncorrelations are characterized in terms of the firing rates, Fano factors,\ncorrelation coefficients and correlation timescale of the neurons driving the\ntarget neuron. We show that the sum of the presynaptic spike trains cannot be\nwell described by a Poisson process. Solutions of the output firing rate are\nfound in the limit of short and long correlation time scales."}, "authors": ["Ruben Moreno-Bote", "Alfonso Renart", "Nestor Parga"], "author_detail": {"name": "Nestor Parga"}, "author": "Nestor Parga", "links": [{"href": "http://arxiv.org/abs/0710.2342v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0710.2342v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "physics.bio-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0710.2342v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0710.2342v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Theory of input spike\n\narXiv:0710.2342v1 [q-bio.NC] 11 Oct 2007\n\nauto- and cross-correlations and their effect\non the response of spiking neurons\nRub\u00e9n Moreno-Bote (1,2), Alfonso Renart (2,3)\nand N\u00e9stor Parga (2)\n\n(1) Present Address: Center for Neural Science, New York University,\nNew York, NY 10003-6621, USA.\n(2) Dept. de F\u0131\u0301sica Te\u00f3rica. Universidad Aut\u00f3noma de Madrid,\nCantoblanco 28049, Madrid, Spain\n(3) Present Address: Center for Molecular and Behavioral Neuroscience,\nRutgers, The State University of New Jersey, 197 University Avenue,\nNewark, NJ 07102, USA\nAbstract\nSpike correlations between neurons are ubiquitous in the cortex,\nbut their role is at present not understood. Here we describe the firing\nresponse of a leaky integrate-and-fire neuron (LIF) when it receives\na temporarily correlated input generated by presynaptic correlated\nneuronal populations. Input correlations are characterized in terms of\nthe firing rates, Fano factors, correlation coefficients and correlation\ntimescale of the neurons driving the target neuron. We show that\nthe sum of the presynaptic spike trains cannot be well described by\na Poisson process. In fact, the total input current has a non trivial two-point correlation function described by two main parameters:\nthe correlation timescale (how precise the input correlations are in\ntime), and the correlation magnitude (how strong they are). Therefore, the total current generated by the input spike trains is not well\ndescribed by a white noise Gaussian process. Instead, we model the\ntotal current as a colored Gaussian process with the same mean and\ntwo-point correlation function, leading to the formulation of the problem in terms of a Fokker-Planck equation. Solutions of the output\nfiring rate are found in the limit of short and long correlation time\nscales. The solutions described here expand and improve our previous\n\n1\n\n\fresults (Moreno et al., 2002) by presenting new analytical expressions\nfor the output firing rate for general IF neurons, extending the validity of the results for arbitrarily large correlation magnitude, and by\ndescribing the differential effect of correlations on the mean driven or\nnoise dominated firing regimes. Also the details of this novel formalism are given here for the first time. We employ numerical simulations\nto confirm the analytical solutions and to study the firing response to\nsudden changes in the input correlations. We expect this formalism to\nbe useful for the study of correlations in neuronal networks and their\nrole in neural processing and information transmission.\n\n1\n\nIntroduction\n\nA major problem in neuroscience is to understand the way neurons communicate with each other. Because neurons in the cortex are densely connected\nand share common inputs (White, 1989; Braitenberg and Sch\u00fcz, 1991), some\ndegree of correlation between their discharges is unavoidable. Indeed, correlations in the spiking activity of neurons are routinely observed throughout\nthe cortex ((Zohary et al., 1994; deCharms and Merzenich, 1996; Lee et al.,\n1998; Usrey and Reid, 1999; Bair et al., 2001); for a review see Salinas and Sejnowski\n(2001); Averbeck and Lee (2004)). Correlations could have an important\nfunctional role, as the temporal synchronization of neuronal activity has been\nshown to correlate with particular states of behaving animals (Vaadia et al.,\n1995; Riehle et al., 1997; Fries et al., 1997; Steinmetz et al., 2000; Fries et al.,\n2001). From a more traditional point of view, correlations have been considered as a coding dimension independent of the firing rate (deCharms and Merzenich,\n1996; Wehr and Laurent, 1999; Laurent, 2001). However it remains still controversial whether correlated activity has a role in coding, or whether its\nmain role is as a gating mechanism of the flow of information in cortical\ncircuits (Salinas and Sejnowski, 2001; Averbeck and Lee, 2004).\nBefore the functional role of correlations can be addressed, a prime question to solve is how correlations affect the firing properties of neurons. Previous work in this direction has revealed that neurons can be very sensitive even to weak correlations in their inputs (Burkitt and Clark, 1999;\nFeng and Brown, 2000; Salinas and Sejnowski, 2000). However, in most of\nthese studies, only zero time lag correlated inputs (perfect synchronization)\nhas been used. This means that when one spike arrives at one presynaptic\nterminal, another spike is more likely to be found at the same time in other\n2\n\n\fpresynaptic terminal. This perfect synchrony is not expected to be exhibited\nby real neuronal systems, given their finite temporal precision. Instead, synchrony with a non zero time precision \u03c4c seems to be the realistic case, with\n\u03c4c \u223c 15ms in monkey primary auditory cortex (deCharms and Merzenich,\n1996), \u03c4c \u223c 5ms in primary visual cortex of strabismic cats (Fries et al., 1997)\n(in this case the cross-correlogram is accompanied by an oscillatory pattern),\n\u03c4c with very broad values ranging from less than 15ms to more than 200ms\nmediating interactions between areas V 1 and V 2 in monkeys (Nowak et al.,\n1999), or \u03c4c \u223c 10ms in the monkey visual area MT (Bair et al., 2001). In\nthis case, if a spike arrives at time t = 0 at a presynaptic terminal, another\nspike is more, or less, likely than the chance level determined by the firing\nrate, to arrive within a time \u03c4c around t = 0 at other (or the same) terminal.\nWe have shown previously (Moreno et al., 2002) that the total current to\na neuron generated by exponentially correlated afferent spike trains can be\ndescribed (among other parameters) by the correlation time, \u03c4c , and the correlation magnitude, \u03b1 (see definitions in Section (3)). Each parameter carries\nimportant information about the characteristics of the input correlations (either temporal or intensity information). Intuitively, a short correlation time\n\u03c4c means that afferent spikes synchronize within short time windows of size\n\u03c4c . Decreasing \u03c4c will enhance the temporal precision of correlations. The\ncorrelation magnitude, \u03b1, roughly represents how many spikes are expected\nabove chance in a time window \u03c4c given that there was a spike centered in\nthat time window. Therefore, it is a measure of the intensity of the correlations. For uncorrelated spike trains \u03b1 = 0, while for positively correlated\nspike trains \u03b1 > 0, and for negatively correlated \u03b1 < 0. As we will show, the\ncorrelation time and magnitude can also be related to the autocorrelograms\n(ACGs) and cross-correlograms (CCGs) of recorded spike trains. The correlation time measures the typical width of the CCG, while the correlation\nmagnitude is proportional to the area under the CCG curve.\nBoth \u03c4c and \u03b1 can affect the neuron's firing response in complicated ways.\nSeparating their effects was crucial in our previous work (Moreno et al.,\n2002), where the effects of changing the timescale and the magnitude of\nthe input correlations could be studied independently. In particular, one of\nthe main qualitative results was that, if \u03b1 is kept constant, neurons are sensitive to input correlations only when the correlation time is shorter than the\nmembrane time constant. 1 .\n1\n\nThis mechanism is consistent with coincidence detection (Abeles, 1982;\n\n3\n\n\fThe main problem studied in this paper is schematized in Fig.(1) and\ncan be summarized as follows: What is the effect of the magnitude and the\ntimescale of the input spike correlations on the neuron firing response? We\nanswer this question by addressing consecutively several subproblems. First,\nafter presenting the model (Sec 2), we describe the statistical properties of\nthe afferent spike trains which drive a LIF neuron (Sec 3). The spike trains\nare characterized in terms of their firing rates, Fano factors, correlation coefficients and correlation timescale, and are assumed to have exponential autoand cross-correlations. Correlated and uncorrelated Poisson spike trains are\njust special cases of these. The total current generated by the sum of the\nspike trains is described up to second order statistics (the two-point correlation function), and shows exponential correlations (Sec 3.2). Second, to\nsolve the difficulties presented by the non-Markovian character of the input\nstatistics, we seek to transform this input into a colored Gaussian input with\nthe same mean and two-point correlation function as those generated by the\noriginal current. Two different Markovian stochastic processes that generate\nthis colored Gaussian input are found (Sec 4). Then, we obtain the FokkerPlank equations (FPEs) associated to each of these two processes and the\nvoltage of the neuron (Secs 4.1 and 4.2). Third, the output firing rate is\nobtained by solving the FPEs in the limits of short and long values of the\ncorrelation timescale compared to the membrane time constant of the neuron\n(Sec 5). At this point we give a brief summary of the analytical expressions\nand their ranges of validity (Sec 6 and Table 1). An interpolation is then\nemployed to join the two limits, and the analytical results are compared with\nnumerical simulations (Sec 7.1). Finally, we also show that neurons can track\nfast changes in input correlations (Sec 7.2). In the discussion section (Sec\n8) we summarize the main results and discuss possible applications. Several\ncomputational details are provided in a set of appendices.\nSome of these results have been previously published in a brief format\n(Moreno et al., 2002). In the current work we extend the analytical techniques, obtain new results and present a more pedagogical version of our\nwork to facilitate the use of the mathematical expressions as well as the understanding of their derivation. In particular, a more general expression for\nthe output firing rate is found in the presence of exponentially correlated\nBernander et al., 1991; Softky and Koch, 1993; Softky, 1994). Note, however, that these\nauthors consider input spike coincidence detection in the sub-millisecond range, while our\nresults more generally concern the effect of correlation timescale of any size on a neuron\nwith any membrane time constant\n\n4\n\n\finput spike trains that is valid for long \u03c4c and for all positive \u03b1 (Sec 5.2).\nIf the limit of small \u03b1 is taken, this new expression becomes that found in\n(Moreno et al., 2002) in the case of long \u03c4c , and therefore generalizes and\nextends the latter for large correlation magnitudes. The effect of input correlations in the mean driven and noise dominated input regimes is found to\nbe different, and those peculiarities are discussed here (Sec 7.1).\n\n2\n\nModel\n\nWe consider a LIF neuron with membrane potential V (t) and membrane time\nconstant \u03c4m . In the absence of input, the voltage decays exponentially toward\nthe resting potential (here V = 0). In the presence of synaptic current, I(t),\nthe membrane potential evolves according to the equation\nV\u0307 (t) = \u2212\n\nV (t)\n+ I(t) .\n\u03c4m\n\n(1)\n\nIn the model, a spike is generated whenever the membrane potential V (t)\nreaches a threshold value \u0398. Following the spike, the potential is reset to a\nvalue H, from where, after an absolute refractory period \u03c4ref , the neuron can\nstart integrating the synaptic current again.\nWe work in the limit of infinitely fast synaptic time constants, in which\nindividual synaptic currents are represented by delta functions. Thus, the\nafferent current I(t) is\nI(t) = JE\n\nNE X\nX\ni=1 k\n\n\u03b4(t \u2212 tki ) \u2212 JI\n\nk(l)\n\nNI X\nX\n\nj=1 l\n\n\u03b4(t \u2212 tlj ) ,\n\n(2)\n\nwhere ti(j) represents the arrival time of the k-th (l-th) spike from the i-th excitatory (j-th inhibitory) presynaptic neuron, and NE(I) and JE(I) represent,\nrespectively, the number of inputs and the size of the postsynaptic potentials\nfrom the excitatory (inhibitory) afferent populations.\nWe are interested in the case of stationary input statistics, so that the\ninput firing rates do not depend on time (but see our simulation results for\nthe case on non-stationary statistics in Sec. 7.2). Therefore, assuming that\nthe excitatory and inhibitory presynaptic neurons fire at rates \u03bdE and \u03bdI\nrespectively, the mean current hI(t)i is computed as\n\n5\n\n\f\u03bc = hI(t)i = NE JE \u03bdE \u2212 NI JI \u03bdI .\n\n(3)\n\nThis result is independent of the statistics of the afferent spike trains. For\nexample, the mean current generated by correlated or independent Poisson\nspike trains is exactly the same, provided that the processes are stationary\nand described by the same firing rates. However, the second-order statistics\nof the current will be very sensitive to the second order statistical properties of the individual spike trains (e.g., their pair-wise correlations). In the\nnext section we determine the two-point correlation function in terms of the\nstatistical properties of the presynaptic spike trains.\n\n3\n3.1\n\nSecond-order statistical properties of the\ncurrent\nAuto-correlograms\n\nThis section is devoted to the description of the second order statistical properties of each individual spike train impinging on the LIF neuron. In the\nnext section, we will consider the second order statistical properties of pairs\nof those spike trains. Here, we first define the Fano factor of the spike count\nof each input train. Then we introduce the auto-correlation function in the\ncase of an exponentially correlated spike train. Finally, we show that the parameters defining the exponential auto-correlation function can be expressed\nin terms of the firing rate, Fano factor and correlation time of the spike train.\nMost theoretical models have considered afferent spike trains (see eq.\n(2)) as stochastic Poisson processes (see e.g. (Ricciardi, 1977; Tuckwell, 1988;\nBrunel and Sergi, 1998; Feng and Brown, 2000; Nykamp and Tranchina, 2001;\nLaCamera et al., 2004; Richardson and Gerstner, 2005)). In this work, we relax this assumption. The Fano Factor is often used to quantify the reliability\nof neuronal discharge. The Fano factor of the spike count in a time window\nT is defined as the ratio between the variance of the spike count and the\nmean number of spikes in that time window, that is,\n2\n\u03c3N\n(T )\nh(N(T ) \u2212 hN(T )i)2 i\nFN (T ) =\n=\n,\nhN(T )i\nhN(T )i\n\n(4)\n\nwhere N(T ) is the number of spikes counted in the time window T in each\n6\n\n\ftrial and brackets denote an average over trials. Note that, in practice, the\nmean and variance can also be computed using a single long spike train (with\nstationary firing rate) obtained in a single trial, where now the average is\nobtained using non-overlapping consecutive time windows instead of several\ntrials. In either case, typically the time window T is taken to be large, so\nthat at least tens of spikes are observed on average. A Poisson spike train\nhas a Fano factor equal to one. However, Fano factors calculated from spike\ntrains obtained from electrophysiological recordings in vivo usually exceed\none, laying in the interval FN \u223c 1 \u2212 1.5 throughout the cerebral cortex\n(Dean, 1981; Softky and Koch, 1993; Albright, 1993; Shadlen and Newsome,\n1998; Compte et al., 2003), which is inconsistent with the Poisson hypothesis\n(see also (Amarasingham et al., 2006)).\nAnother important second-order statistical property of individual spike\ntrains is the joint probability density of having spikes belonging to that same\nspike train at two times, t and t\u2032 , denoted P (t, t\u2032 ). In fact, from it one can\nderive any other second-order statistical quantity, such as the Fano factor\n(see below). For a Poisson spike train with rate \u03bd, P (t, t\u2032) is a delta function\nat zero-time lag and flat otherwise, as\nPP oisson (t, t\u2032 ) = \u03bd\u03b4(t \u2212 t\u2032 ) + \u03bd 2 .\n\n(5)\n\nC(t, t\u2032 ) = P (t, t\u2032 ) \u2212 \u03bd 2 ,\n\n(6)\n\nThe delta function at t = t\u2032 serves to define P (t, t\u2032 ) at all times; trivially,\nthe probability density of having a spike at time t and a spike at time t\u2032 = t\nis just the delta multiplied by the spike rate in that train, i.e., \u03bd\u03b4(t \u2212 t\u2032 );\nin other words, the presence of one spike is informative of the presence of\na spike at that time (the same spike). For non-zero time lags (t 6= t\u2032 ), this\nprobability is just the product of the probability densities of having spikes\nat two different times, that is, \u03bd 2 . For a general spike train we define the\nautocorrelation function as the quantity\n\nthat is, the joint probability density of having spikes at times t and t\u2032 , from\nwhich the probability of finding them by chance (i.e., the rate to the square)\nis subtracted.\nWhile Poisson trains have an autocorrelation with a single delta function at time lag zero and zero otherwise (i.e. CP oisson (t, t\u2032 ) = \u03bd\u03b4(t \u2212 t\u2032 )),\nauto-correlograms obtained from electrophysiological recordings show a decaying peak at non-zero time lags (disregarding refractory effects) sometimes\n7\n\n\ftogether with a damped oscillatory pattern. A centered decaying peak in\nan auto-correlogram means that spikes tend to occur close together in time,\nforming groups of several spikes. Experimental auto-correlograms with a\nsingle peak and without oscillations can be fitted to an exponential function\n(e.g. Bair et al. (2001)). We therefore consider stochastic spike trains with\nexponential autocorrelations with timescale \u03c4c\n\nCp (t, t ) \u2261\n\n*\n\n=\n\n*\n\n\u2032\n\nX\nk\n\nX\nk,k \u2032\n\n\u03b4(t \u2212\n\ntki )\n\n\u2212 \u03bdp\n\n!\nk\u2032\n\nX\nk\u2032\n\n\u2032\n\n\u03b4(t \u2212\n\n\u2032\ntki )\n\n\u2212 \u03bdp\n\n!+\n\n+\n\n\u03b4(t \u2212 tki )\u03b4(t\u2032 \u2212 ti ) \u2212 \u03bdp2\n\u2032\n\n= \u03bdp \u03b4(t \u2212 t ) + \u03bdp\n\n\u0012\n\nFp \u2212 1\n2\u03c4c\n\n\u0013\n\ne\u2212\n\n|t\u2212t\u2032 |\n\u03c4c\n\n,\n\n(7)\n\nas illustrated in Fig.(2 B). Since we assume that the input statistics is stationary, the input firing rates are time independent and the auto-correlation\nfunction only depends on time through the quantity |t \u2212 t\u2032 |, Here p = E, I; \u03bdp\nand Fp are the firing rate and the Fano factor of the spike count (for infinitely\nlong time windows) of the individual trains coming from population p 2 . The\nconnected two-point correlation function defined above is the joint probability density of finding one spike at time t and another at t\u2032 within the same\nspike train, from where the probability of observing them by chance, \u03bdp2 , is\nsubtracted. Note that this function has two contributions: a delta function\nat zero time lag, coming from the fact that spikes are point events, and an\nexponential dependence measuring the excess probability of finding a spike at\nt\u2032 when it is known that there is another spike at t. While normally spikes in\nthe same train are positively correlated (FN > 1), the auto-correlogram in eq.\n(7) also describes uncorrelated (FN = 1, Poisson) and negatively correlated\nspikes (FN < 1). With the parameterization we have chosen, fixing the Fano\nfactor and changing the correlation time does not keep fixed the amplitude\nof the exponential term in eq. (7). However, this choice allows us to fix the\nvariance of the spike count in a long time window for each individual spike\ntrain while varying the timescale of its correlations. To make this clearer,\n2\n\nFor renewal spike trains, the Fano factors in the above equations are related to the\ncoefficients of variation of their inter-spike-intervals, CVp , as Fp = CVp2 . Note nevertheless\nthat our formalism does not require that afferent spike trains are renewal.\n\n8\n\n\fconsider the total number of presynaptic spikes arriving from the spike train\ni of the population p during a time window T , which is written as\nN(T ) =\n\nZ\n\nT\n\n0\n\ndt\n\nX\nk\n\n\u03b4(t \u2212 tki ) .\n\n(8)\n\nNotice that, since the arrival times tki are random in such a way that the train\nhas the autocorrelation of eq. (7), the number N(T ) is a random variable.\nIts mean value is\n*Z\n\nhNp (T )i =\n\nT\n\n0\n\ndt\n\nX\nk\n\n\u03b4(t \u2212\n\ntki )\n\n+\n\n= \u03bdp T ,\n\n(9)\n\nand its variance can be calculated using the autocorrelation defined in eq.\n(7) as (Renart et al., 2007)\n\n2\n\u03c3N,p\n(T )\n\n=\n\n*Z\n\n=\n\nZ\n\n0\n\nT\n0\n\nT\n\ndt\n\ndt\n\nZ\n\nT\n\nZ\n\n0\n\n0\n\nT\n\n\u2032\n\ndt\n\nX\nk,k \u2032\n\n\u03b4(t \u2212\n\ntki )\u03b4(t\u2032\n\n\u2212\n\n\u2032\ntki )\n\n+\n\n\u2212 hNp (T )i2\n\ndt Cp (t, t\u2032 )\n\n= \u03bdp T + \u03bdp (Fp \u2212 1)(T \u2212 \u03c4c (1 \u2212 e\u2212T /\u03c4c )) .\n\n(10)\n\nTherefore, the variance of the spike count grows linearly with T for long\nwindows T \u226b \u03c4c , where it takes the value\n2\n\u03c3N,p\n(T ) = Fp \u03bdp T .\n\n(11)\n\n(see Fig.(2 C)). Thus, fixing only the Fano factor in the autocorrelation function keeps fixed the variance in the spike count for long T , as this variance\nis independent of \u03c4c . Changing \u03c4c does not alter the total spike count fluctuations, only the temporal precision in which they occur. Notice that the\ninclusion of the Fano factor in the autocorrelation function, eq. (7), is consistent with its definition for long T in eq. (4). Notice also from eq. (10),\nthat the variance of the spike count is \u03bdp T for short T \u226a \u03c4c , and therefore\nthe afferent spike train looks like a Poisson spike train when it is sampled\nduring brief time windows. However, as soon as T is comparable with the\ncorrelation time, the variance of the spike count starts to take into account\nthe temporal correlations in the spike train, and when T becomes very large,\nall effects are included and the variance is Fp \u03bdp T , eq. (11) (see Fig.2). We\n9\n\n\fwill show below that, for the LIF neuron we are considering, whether the\ninput is seen as having significant temporal correlations or not depends on\nhow the timescale of these correlations compares to the neuron's membrane\ntime constant.\n\n3.2\n\nCross-correlograms\n\nWe have also considered the possibility that spikes in different trains are\ncorrelated. When the activity of two neighbouring neurons is recorded, the\ncross-correlogram computed from their discharges can sometimes present a\nsingle peak with or without damped oscillations (e.g. (Perkel et al., 1967;\nAersten et al., 1989; deCharms and Merzenich, 1996)). A prominent peak at\nzero time lag means that the two neurons tend to fire synchronously, while if\na dip is observed, when one neuron fires the other is more likely to be silent.\nVery often, the cross-correlograms can be approximated by an exponential\nfunction (e.g. (deCharms and Merzenich, 1996; Bair et al., 2001)) The crosscorrelogram is therefore modeled here as an exponential,\n\nCpq (t, t\u2032 ) \u2261\n=\n\n=\n\n\uf8f6\uf8eb\n*\uf8eb\nX\nX\nk\n\uf8ed\n\u03b4(t \u2212 t p ) \u2212 \u03bdp \uf8f8 \uf8ed \u03b4(t\u2032\ni\n\nkp\n\n*\n\nX\n\nkp ,kq\n\n\u221a\n\nkq\n\n\u03b4(t \u2212\n\uf8eb\n\n\u03bdp \u03bdq \uf8ed\n\n\u03c1pq\n\nk\nti p )\u03b4(t\u2032\n\nq\n\n\u2212\n\nFp Fq\n\n2\u03c4c\n\nk\ntj q )\n\n\uf8f6\n\uf8f8\n\ne\u2212\n\n+\n\n\uf8f6+\nk\n\u2212 t p ) \u2212 \u03bdq \uf8f8\nj\n\n\u2212 \u03bdp \u03bdq\n\n|t\u2212t\u2032 |\n\u03c4c\n\n,\n\n(12)\n\nwhere Cpq (t, t\u2032 ) is the two-point correlation function between the trains (i, j)\nin populations p and q (p, q = E, I). This cross-correlation function is illustrated in Fig.(3 B). As in the case of the autocorrelation defined in eq.\n(7), the two-point correlation function expresses the probability density of\nfinding a spike of a train in population p at time t along with a spike of a\ntrain in population q at time t\u2032 , from which the probability density of finding\nthem by chance, \u03bdp \u03bdq , is subtracted. The magnitude of the cross-correlations\nis determined by the correlation coefficients \u03c1pq of the spike counts (see its\ndefinition in eq. (14)). For the sake of simplicity, we take all the correlations\nin the problem to have the same time constant \u03c4c .\n10\n\n\fTo better understand the effects of cross-correlations on the input statistics, we calculate the covariance between the count of spikes emitted by the\nneuron i from population p and the count of spikes emitted by the neuron j\nfrom population q as an integral of the cross-correlation function, eq. (12),\nas\nh(Np (T ) \u2212 hNp (T )i) (Nq (T ) \u2212 hNq (T )i)i = hNp (T )Nq (T )i \u2212 \u03bdp \u03bdq T 2\n=\n\n*Z\n\n=\n\nZ\n\n=\n\n0\n\nT\n0\n\n\u221a\n\nT\n\ndt\n\ndt\n\nZ\n\nZ\n\n0\n\n\u0010\n\n0\n\nT\n\nT\n\n\u2032\n\ndt\n\nX\n\nkp ,kq\n\n\u03b4(t \u2212\n\nk\nti p )\u03b4(t\u2032\n\n\u2212\n\nk\ntj q )\n\n+\n\n\u2212 \u03bdp \u03bdq T 2\n\ndt\u2032 Cpq (t \u2212 t\u2032 )\nq\n\n\u03bdp \u03bdq \u03c1pq Fp Fq\n\n\u0011\u0010\n\n\u0011\n\nT \u2212 \u03c4c (1 \u2212 e\u2212T /\u03c4c ) .\n\n(13)\n\nThis covariance measures the correlation in the spike count fluctuations during a time T from two presynaptic spike trains. Notice that for T much\nshorter than the correlation time, this covariance is zero, that is, the spike\ncounts of the two neurons become independent. This is true because for\nshort T the spike trains look like uncorrelated Poisson trains. However, for\ntime windows which are longer than the correlation time, the covariance is\nnon-zero and approaches a linear behavior. This covariance as a function of\nthe integration window is represented in Fig.(3 C).\nThe correlation coefficient is defined as the ratio of the covariance and\nthe product of the deviations in the spike counts of both neurons, as\n\u03c1pq =\n\nh(Np (T ) \u2212 hNp (T )i) (Nq (T ) \u2212 hNq (T )i)i\n\u03c3Np (T )\u03c3Nq (T )\n\n(14)\n\nfor long T . Notice from eq. (13) that the inclusion of the correlation coefficient in the cross-correlation, eq. (12), is consistent with the above definition.\nChanging the correlation time in the cross-correlation, eq. (12), changes its\namplitude, but not the correlation coefficient between the two spike trains.\nThe Fano factors appear in eq. (12) because the time integral of the crosscorrelation has to be zero if one of the trains does not have spike count\nfluctuations (FN = 0).\n\n11\n\n\f3.3\n\nWriting the statistical properties of the total current\n\nThe two-point correlation function of the total afferent current, eq. (2), is\ndefined as\nCcurrent(t, t\u2032 ) \u2261 h(I(t) \u2212 hI(t)i)(I(t\u2032 ) \u2212 hI(t\u2032 )i)i ,\n\n(15)\n\nwhere the mean current hI(t)i is calculated as in eq.(3). The correlation\nfunction should take into account both the auto- and cross-correlations of\nthe spike trains in the E and I populations given in eqs. (7, 12). In Fig. (4)\nwe depict a diagram with the correlations present in the E and I neurons,\nwhose spikes trains impinge on the same target neuron. There are NE excitatory neurons firing at rate \u03bdE and NI inhibitory neurons with rate \u03bdI . We\nassume that only a fraction fEE (fII ) of the NE (NI ) excitatory (inhibitory)\nneurons are correlated with other neurons within the same population, with\na correlation coefficient \u03c1EE (\u03c1II ). Also only a fraction fEI of the excitatory\nneurons are correlated with a fraction fEI of the inhibitory neurons, with a\ncorrelation coefficient \u03c1EI = \u03c1IE .\nThen, the correlation function of the current, eq. (15), contains several\ncontributions:\nCcurrent(t, t\u2032 ) = JE2 NE CE (t \u2212 t\u2032 ) + JI2 NI CI (t \u2212 t\u2032 )\n+JE2 fEE NE (fEE NE \u2212 1) CEE (t \u2212 t\u2032 ) + JI2 fII NI (fII NI \u2212 1) CII (t \u2212 t\u2032 )\n\u22122 JE JI fEI fIE NE NI CEI (t \u2212 t\u2032 ) .\n(16)\nIn this expression, the two first terms come from the auto-correlations of the\nspike trains in the E and I populations. The third and fourth terms take into\naccount the cross-correlation between spike trains in the same E or I population. They are positive because both E and I inputs contribute positively\nto enhance fluctuations. The last term incorporates the cross-correlation\nbetween spike trains one from the E population and the other from the I\nneuronal population, and it is negative. Indeed, positive correlations between\nE and I neurons always reduce synaptic fluctuations because arrival of an\nexcitatory spike can be cancelled out by arrival of another inhibitory spike,\nand this happens with higher than chance probability. Therefore, the effect of\ncorrelations within E or I neurons is always to increase Ccurrent (t, t\u2032 ) in the direction of their cross-correlation functions, CEE (t\u2212t\u2032 ) and CII (t\u2212t\u2032 ), whereas\n12\n\n\fthe effect of correlations between E and I spike trains is always to lower the\ncurrent correlation function in an amount proportional to CEI (t \u2212 t\u2032 ).\nUsing the choices given in eqs. (7, 12), the two-point correlation function\nof the total input current to the neuron can be written as\n\u2032\n\nCcurrent(t, t ) =\n\n\u03c3w2\n\n\u0014\n\n\u2032|\n\u03b1 \u2212 |t\u2212t\n\u03b4(t \u2212 t ) +\ne \u03c4c\n2\u03c4c\n\n\u2032\n\n\u0015\n\n,\n\n(17)\n\nwhere we call \u03c3w2 the white noise variance, and \u03b1 the correlation magnitude.\nThey are expressed in terms of the model parameters as\n\u03c3w2 = JE2 NE \u03bdE + JI2 NI \u03bdI\n\u03b1 \u03c3w2 = JE2 \u03bdE [(FE \u2212 1) + fEE (fEE NE \u2212 1) FE \u03c1EE ]\n+ JI2 NI \u03bdI [(FI \u2212 1) + fII (fII NI \u2212 1) FI \u03c1II ]\nq\n\u221a\n\u2212 2 JE JI fEI fIE NE NI \u03bdE \u03bdI FE FI \u03c1EI .\n\n(18)\n\n2\nWe define the total variance of the current, \u03c3ef\nf , as the sum of the white\nnoise variance and the variance generated by correlations, \u03b1\u03c3w2 , that is,\n2\n2\n\u03c3ef\nf = \u03c3w (1 + \u03b1) .\n\n(19)\n\nThe sign of the correlation magnitude determines the sign of the correlations.\nIf \u03b1 > 0, the current has positive correlations, while if \u03b1 < 0, the current\nhas negative correlations. The minimum physically possible value for the\ncorrelation magnitude is \u03b1 = \u22121 3 . If \u03b1 = 0, the current is uncorrelated.\n2\nNotice that \u03c3ef\nf is very sensitive to the fractions of correlated input trains,\nas these fractions are multiplied by the number of connections from each\npopulation to the square, which typically are of the order of 103 \u2212 104 . Also,\nfrom eq. (18) it is possible to see that increasing the correlations between\n3\n\nFor large enough T (T \u226b \u03c4c ), the variance of the integrated current, or accumulated\nRT\ncharge Q(t) = 0 dtI(t), is calculated as\nV ar[Q(T )] =\n\nZ\n\n0\n\nT\n\ndt\n\nZ\n\nT\n\n2\ndt\u2032 Ccurrent (t, t\u2032 ) = \u03c3ef\nfT .\n\n(20)\n\n0\n\n2\nTherefore, the variance of the current is just the proportionality factor \u03c3ef\nf . Notice that\nsince the variance of the current is non-negative, the correlation magnitude has a lower\nbound at \u03b1 = \u22121. Lower values are not physically possible because the variance of a\nreal-valued stochastic variable cannot be negative.\n\n13\n\n\fexcitatory or inhibitory neurons (either increasing \u03c1EE or \u03c1II ) enhances the\ntotal variance, whereas correlations between excitatory-inhibitory pairs (\u03c1EI )\nalways decrease it (Salinas and Sejnowski, 2000).\nThe parameters \u03c4c and \u03b1 which appear in the definition of the correlation\nfunction of the current, eq. (17), fully characterize both the temporal range\nand the intensity of the correlations relative to the white noise variance \u03c3w2 .\nAlthough it is important to understand the effect of these two parameters\non the neuronal firing response separately, previous studies have not studied\nthis problem. For instance, in Feng and Brown (2000) only the case \u03c4c = 0 is\nconsidered, which precludes the characterization of the temporal scale of the\ncorrelations. On the other hand, Salinas and Sejnowski (2000) have changed\nsimultaneously the values of \u03c4c and \u03b1 in their simulations.\n\n3.4\n\nThe sum of a large number of independent nonPoisson spike trains is not Poisson\n\nOne point deserves clarification at this moment. It refers to the way many\nsimultaneous spike trains add up. The sum of many independent spike trains\nhas been commonly approximated as a Poisson process (e.g. (Daley and Vere-Jones,\n1988; Amit and Brunel, 1997a)). Although this is in some cases a good approximation, it is worth emphasizing that the sum of many independent\npoint processes is not, in general, Poisson. Indeed, the conditions for the sumprocess to be truly Poisson are rather restricted (see e.g., Daley and Vere-Jones\n(1988)). In particular, one of the conditions implies that, on any time interval, only one event can be observed from each individual point process.\nHowever, this is only expected to be a good approximation for time windows\nmuch shorter than the typical inter-spike-interval of each neuron. In general,\na neuron will receive one, two or more spikes from the same presynaptic neuron before it fires, not just at most one spike, as the Poisson approximation\nstrictly requires.\nAs expected from the rules of probability, adding up many independent\nspike trains results in a global spike train with an autocorrelation function\nwhich has exactly the same functional form as those of the individual trains\n(note, however, that higher order properties are not necessarily conserved,\ni.e., the sum of many renewal processes may not be renewal). In particular,\nwhen N independent spike trains with an autocorrelation C(t, t\u2032 ) are added,\nthe summed train has an autocorrelation N \u00d7 C(t, t\u2032 ) ((Moreno et al., 2002),\n14\n\n\fsee also eq. (16) with CEE(II,EI) = 0 and JE(I) = 1). We further noted that\neven in the diffusion limit (i.e. N \u2192 \u221e), when the individual firing rates \u03bd\nare renormalized by \u03bd/N to yield a finite two-point correlation function, the\nauto-correlation function of the total input has exactly the same shape as the\nauto-correlation function of the individual spike trains. Later works have also\nused this property (Renart et al., 2007; Lindner, 2006; Cateau and Reyes,\n2006; Doiron et al., 2006), which is relevant to describe the temporal aspects\nof correlations in networks of spiking neurons.\nHere we exemplify the above result using the expression for the correlation\nfunction of the current, eqs. (17-18). It is easy to see that the total current\nwill show temporal correlations beyond the trivial delta function at zero time\nlag whenever \u03b1 is different from zero and \u03c4c is not infinity. If the afferent spike\ntrains are independent (\u03c1 = 0) but they have exponential auto-correlations,\nas those in eq. (7), then \u03b1 will be different from zero (see eq. (18)). This will\nhappen for any choice of the number of connections and synaptic strengths\n(different from zero). Therefore, no matter which choices of the parameters\nare taken, the correlation-function of the total current can never correspond\nto a Poisson process with a larger rate, since an input Poisson process will\nproduce a correlation function equal to Ccurrent(t, t\u2032 ) = \u03c3w2 \u03b4(t \u2212 t\u2032 ). The\nabove argument does not depend on the condition that the correlations are\nexponential, but rather the same conclusion can be achieved from eq. (16)\nusing any plausible autocorrelation function CE (t, t\u2032 ) and CI (t, t\u2032 ) different\nfrom a delta function (i.e., different from the autocorrelation function of a\nPoisson process).\n\n3.5\n\nWhen the current can be approximated by a Gaussian current\n\nWe have described the statistical properties of the total current, I(t), generated by correlated spike trains. However, the firing response of a neuron\nreceiving that current is not yet completely determined by the mean and\ntwo-point correlation function of the current alone, eqs. (17-18). These\nquantities describe the statistical properties of a stationary current up to\nsecond order, but higher order statistics in the input could also play a role\nin shaping the firing response of the neuron. However, if the current I(t) can\nbe approximated by a Gaussian process, then, the current would be fully described by its mean and two-point correlation function. In fact, Gaussianity\n15\n\n\fnaturally holds when the neuron is receiving a large barrage of uncorrelated\nspikes per second each one inducing a membrane depolarization J very small\ncompared to the distance between the threshold and reset potentials, i.e.,\nJ/(\u0398 \u2212 H) \u226a 1 (Ricciardi, 1977). When inputs are correlated, the net effect\nof correlations is to increase effectively the size of the unitary depolarization\n(for positive correlations), since two or more spikes are more likely to occur\ntogether in time. We have estimated this renormalization in the size of J and\ndetermine that for the Gaussian approximation to be valid with correlated\ninput spike trains the condition\nJF\n(1 + f N\u03c1) \u226a 1\n(\u0398 \u2212 H)\n\n(21)\n\nshould hold. This is a heuristic formula, and it is explained qualitatively\nas follows. The worst condition in the presence of correlations occurs when\nthe correlation time \u03c4c is zero, that is, when there is some chance that two\nor more spikes arrive at the same time, increasing the effective size of each\nspike and worsening the Gaussian approximation. One can estimate the\nmean number of spikes arriving together to be F (1 + f N\u03c1), which grows\nwith the variability of the spike trains, the number of correlated pairs and\ntheir correlation coefficient. As long as this number multiplied by J is small\ncompared to \u0398 \u2212 H, i.e., eq.(21), the Gaussian approximation is expected\nto be appropriate. This indicates that if either F , f N or \u03c1 increases too\nmuch, the Gaussian limit will be broken. When condition (21) is largely\nbroken, as in (Kuhn et al., 2003), the Gaussian approximation is no longer\nvalid. In particular in the limit of large N, it should hold that \u03c1 \u223c 1/f N, so\nthe correlation coefficients cannot remain finite as the size of the population\nof neurons with significant cross-correlations increases. If condition (21) is\nsatisfied, the input current in our problem can be described as a Gaussian\nstochastic current fully defined in terms of the mean \u03bc = JE NE \u03bdE \u2212 JI NI \u03bdI ,\nthe variance \u03c3w2 , the correlation magnitude (\u03b1) and correlation time (\u03c4c ), as\nexpressed in eq. (17).\n\n3.6\n\nChoosing the connectivity and correlation parameters\n\nBecause we are dealing with a model with many free parameters (see eq.\n(18)), here we fix most of them or make choices within a range of real16\n\n\fistic values. A single neuron receives typically NE \u223c 5000 \u2212 60000 excitatory connections from other neurons (Cragg, 1967; DeFelipe and Fari\u00f1as,\n1992). This accounts for 80 per cent of the total number of synapses; the\nremaining 20 per cent corresponds to inhibitory synapses (Abeles, 1991).\nThe dynamical range of cortical neurons lies in the interval \u03bd \u223c 0 \u2212 200Hz\n(Albright, 1993) although lower rates are much more probable than higher\nones (Rolls and Treves, 1998). Synaptic strengths are between J = 0.1\u22121mV\n((Amit and Brunel, 1997a); see the references therein). Assuming a threshold of 20mV above the resting potential of the neuron, these unitary events\nrepresent a fraction in the range J \u223c 5 10\u22123 \u2212 10\u22122 of the total path to be\ntravelled from rest to firing threshold.\nFano factors of the spike count lying in the interval 1 \u2212 1.5 reveal higher\nirregularity in the neuronal discharges than that expected from Poisson trains\n(Dean, 1981; Softky and Koch, 1993; Shadlen and Newsome, 1998; Albright,\n1993; Stevens and Zador, 1998; Compte et al., 2003).\nThe timescale of correlations varies from a few to several hundred milliseconds, \u03c4c \u223c 1 \u2212 100ms (Ts'o et al., 1986; Gochin et al., 1991). For instance, in (deCharms and Merzenich, 1996) the correlated activity of pairs\nof neurons in primary auditory cortex in cats was recorded. The mean\nhalf-width at half-height of the cross-correlograms peaks computed from\nthese pairs was \u223c 10ms, which corresponds to a correlation time scale\n\u03c4c = 10ms/ln2 \u223c 15ms.\nZohary et al. (1994) have reported correlation coefficients of \u03c1 = 0.12 between neighbouring cells in the middle temporal visual area (MT, or V5). If\nany pair of neurons in a group of thousand units were correlated with such a\nmagnitude and projected to a same target neuron, the magnitude of the input\nfluctuations would be unrealistically large (see eq. (18)). In fact, the value\n\u03c1 = 0.12 only holds for units within local circuits, because it is known that\nmore distant neurons display much smaller correlation coefficients (Lee et al.,\n1998). Although a \"mean\" correlation coefficient could have been considered\n4\n, we have taken into account the heterogeneity of pairwise correlations observed in the cortex by assuming that only a fraction fpq of neurons between\npopulations p and q are indeed correlated with the same correlation coefficient \u03c1pq . This fraction could represent the portion of presynaptic neurons\nlocated in the surroundings of the target neuron, and thus embedded in the\n4\n\nA mean correlation\ncoefficient can be obtained by averaging the \u03c1 of each pair of\nR\nneurons: h\u03c1i = f (\u03c1)d\u03c1.\n\n17\n\n\fsame local circuits as this neuron, or a far neuronal population displaying\ncorrelations between its units and projecting to the same target neuron. To\nbound the effects of input correlations, we assume that around one per cent\nof the presynaptic neurons can be correlated. Such a small value of fpq still\nproduces a large effect on the correlation magnitude (see eq. (18)), as will\nbe also clear in section (7.2).\nThe values of \u03bc, \u03c3w2 and \u03b1 therefore lie within rather broad intervals. As\nan example of the typical values they can take, if a neuron receives NE = 104\nexcitatory connections, NI = 2 103 inhibitory connections, with synaptic\nstrengths JE = 5 10\u22123 and JI = 2 10\u22122 (in units of the threshold), and they\nare firing at \u03bdE = \u03bdI = 5Hz, then \u03bc = 50Hz and \u03c3w2 = 5.3Hz. Assuming\nthat there are only correlations between pairs of neurons in the E population\n(\u03c1EI = \u03c1II = 0), being fEE = 0.1 the fraction of those which are correlated,\nthen \u03b1 = 0.85 if FE = FI = 1.5 and the correlation coefficient is \u03c1EE = 0.01,\nor \u03b1 = 4 if \u03c1EE = 0.1. When we present results from numerical simulations,\nthe parameter values considered will be of the order of the ones mentioned\nabove.\n\n4\n\nTwo ways of transforming the non-Markovian\nproblem into a Markovian one\n\nAs we have explained in the introduction, we aim at calculating the output\nfiring rate of a LIF neuron receiving a correlated input as described in the\nprevious sections. The main technical problem to study the response properties of a neuron driven by correlated inputs analytically is that the stochastic\nprocess defined by eq. (1) with a current having correlations as in eq. (17)\nis non-Markovian, that is, the time derivative of the membrane potential at\neach time depends on the past history of the afferent current, not only on\nits present value. This fact complicates the solution of the problem. However, the process defined in eqs. (1, 17) can be expressed in a Markovian\nway by generating the current I(t) with the help of an Ornstein-Uhlenbeck\nprocess (Moreno et al., 2002). The stochastic current I(t) generated in this\nway displays exactly the same exponential correlations as eq. (17). This\nduplicates the number of variables, but puts the problem in a suitable form\n(see eqs. (22, 23) and (32, 33) below). We have found two different ways of\nrepresenting the correlated Gaussian current I(t) satisfying eq. (17). They\n\n18\n\n\fonly differ in the values of \u03b1 for which they hold. While one of them is more\ngeneral because \u03b1 can take any physical value (including both positive and\nnegative correlations), the other is simpler, although it can be only used for\n\u03b1 > 0 (positive correlations).\n\n4.1\n\nThe first Representation for the dynamics of I(t)\n\nThe first representation of the current I(t) that we discuss here generates\nboth positive (\u03b1 > 0) and negative (\u03b1 < 0) correlations. It has the form\n\u03b2\nI(t) = \u03bc + \u03c3w \u03b7(t) + \u03c3w \u221a z(t)\n2\u03c4c\ns\n2\nz\n\u03b7(t) ,\n\u017c(t) = \u2212 +\n\u03c4c\n\u03c4c\n\n(22)\n(23)\n\nwhere \u03b7(t) is a white noise random process with mean\u221azero and unit variance\n(i.e., h\u03b7(t)i = 0 and h\u03b7(t)\u03b7(t\u2032 )i = \u03b4(t \u2212 t\u2032 )), \u03b2 = 1 + \u03b1 \u2212 1 and z(t) is\nan auxiliary colored random process which obeys the Ornstein-Uhlenbeck\nprocess (23) with the same white noise \u03b7(t) (see, e.g., (Risken, 1989)).\nIt is easy to check that the current defined in eqs. (22, 23) generates a\nGaussian waveform with mean hI(t)i = \u03bc and exponential correlations as in\neq. (17). Defining i(t) = (I(t) \u2212 \u03bc)/\u03c3w we have\n*\"\n\n#\"\n\n#+\n\n\u03b2\n\u03b2\nhi(t) i(t )i = \u03b7(t) + \u221a z(t) \u03b7(t\u2032 ) + \u221a z(t\u2032 ) = \u03b4(t \u2212 t\u2032 ) +\n2\u03c4c\n2\u03c4c\n\u03b2\n\u03b2\n\u03b22\n\u221a\nhz(t)z(t\u2032 )i .\n(24)\nh\u03b7(t)z(t\u2032 )i + \u221a\nh\u03b7(t\u2032 )z(t)i +\n2\u03c4c\n2\u03c4c\n2\u03c4c\n\u2032\n\nAssuming that t\u2032 > t without loss of generality (because hi(t) i(t\u2032 )i is symmetric in the steady state), the third term on the right side of the eq. (24)\nvanishes. The second and fourth terms are calculated using the solution of\nthe stochastic equation, eq. (23),\nz(t) =\n\ns\n\n2 \u2212t/\u03c4c\ne\n\u03c4c\n\nZ\n\n0\n\nt\n\nds es/\u03c4c \u03b7(s) ,\n\n(25)\n\nwith the initial condition z(0) = 0. We find that in the stationary state\n(t, t\u2032 \u2192 \u221e, t\u2032 \u2212 t = constant > 0)\n19\n\n\fs\n\n2 \u2212(t\u2032 \u2212t)/\u03c4c\ne\n\u03c4c\n\u2032\nhz(t)z(t\u2032 )i = e\u2212(t \u2212t)/\u03c4c .\n\u2032\n\nh\u03b7(t)z(t )i =\n\nUsing these identities, the correlation function of the current I(t) defined in\neqs.(22-23), denoted Ccurrent(t, t\u2032 ), can be written as\nCcurrent(t, t\u2032 ) \u2261 h(I(t) \u2212 \u03bc)(I(t\u2032 ) \u2212 \u03bc)i\n\"\n#\n\u2032|\n\u03b2(2 + \u03b2) \u2212 |t\u2212t\n\u2032\n2\n\u03c4\n= \u03c3w \u03b4(t \u2212 t ) +\n,\ne c\n2\u03c4c\n\n(26)\n\nfrom where one sees that the correlation magnitude \u03b1 is related to the new\nparameter \u03b2 \u221a\nby \u03b1 = \u03b2(2 + \u03b2), an equation which has two independent\nsolu\u221a\ntions, \u03b2 = \u00b1 1 + \u03b1 \u22121, both equally valid. We have chosen \u03b2 = 1 + \u03b1 \u22121.\nRemember that \u03b1 has a lower bound in \u22121, which is obtained with \u03b2 = \u22121.\nFor each solution there is a one-to-one mapping from \u03b1 \u2208 [\u22121, +\u221e) to \u03b2, and\nthus, all physically realizable positive and negative correlations are included\nin this formalism.\nThe joint process defined by eqs. (1, 22, 23) is Markovian and driven\nby white noise. Thus, the problem of finding the output firing rate can\nbe formulated according to its associated stationary Fokker-Planck equation\n(FPE) (Risken, 1989). The system of eqs. (1, 22, 23) can be simplified by\nthe linear transformation\nV = \u03bc\u03c4m + \u03c3w\n\nr\n\n\u03c4m\nx\n2\n\n(27)\n\nto obtain the set of stochastic equations\nx(t)\n+\n\u1e8b(t) = \u2212\n\u03c4m\nz\n\u017c(t) = \u2212 +\n\u03c4c\n\ns\n\ns\n\n\u03b2\n2\n\u03b7(t) + \u221a\nz(t)\n\u03c4m\n\u03c4m \u03c4c\n\n2\n\u03b7(t) .\n\u03c4c\n\nThe FPE associated to these two equations is derived in detail in Appendix\nB, and is given by\n20\n\n\f[Lx +\n\n\u221a\n2 \u2202 \u2202\n\u03b2z\nLz\n+\n(\n\u2212\n)]P\n(x,\nz)\n=\n\u2212\u03c4\n\u03b4(x\n\u2212\n2\u0124)J\u03b2 (z) ,\n\u03b2\nm\nk2\nk \u2202x \u2202z\n2\n\n(28)\n\n2\n\n\u2202\nwhere\nthe differential operator Lu is defined as Lu = \u2202u\nu + \u2202\u22022 u , and k \u2261\nq\n\u0398\u2212\u03bc\u03c4m\n\u221a m and \u0398\u0302 =\n\u221a\n. The true reset and threshold\n\u03c4c /\u03c4m . Besides, \u0124 = H\u2212\u03bc\u03c4\n\u03c3w \u03c4m\n\u221a \u03c3w \u03c4m \u221a\nvalues in the new variable x are 2\u0124 and 2\u0398\u0302, respectively. The function P\u03b2 (x, z) is the steady state probability density of having the neuron in\nthe state (x, z). Since the problem cannot be solved exactly as in the onedimensional diffusion case (see e.g. (Ricciardi, 1977; Risken, 1989)),\nwe have\nq\n\u22121\nused a perturbative expansion of the FPE in powers of k = \u03c4m /\u03c4c .\nA key quantity is the escape probability density flux at fixed z, J\u03b2 (z).\nAssociated to the FPE (28) there is a probability density vector flux J~\u03b2 (x, z)\ndefined at each point on the plane (x, z) (Risken (1989), Chapter 6, pag.\n133). It measures the direction and the intensity of the probability density\nflux at each point (x, z). For our FPE it has the expression\n\n1\n\u2202\n1 \u2202\n1 \u2202\n1 \u2202\nJ~\u03b2 (x, z) =\n[\u2212 \u2212x\u2212 ( \u2212\u03b2z) , \u2212 2 ( +z)\u2212\n]P\u03b2 (x, z) . (29)\n\u03c4m \u2202x\nk \u2202z\nk \u2202z\nk \u2202x\nThe probability density flux satisfies the so-called continuity equation\n~ J~\u03b2 (x, z) + \u03c4m \u03b4(x \u2212\n\u2207.\n\n\u221a\n\n2\u0124)J\u03b2 (z) = 0 ,\n\n(30)\n\n~ = [ \u2202 , \u2202 ] is the divergence operator. Eq. (30) is equivalent to\nwhere \u2207\n\u2202x \u2202z\nthe FPE (28), and expresses the conservation of the total probability over\ntime. The escape probability density flux J\u03b2 (z) is just the x-component of\nthe probability density flux (29) evaluated at threshold:\n!\n\n1\n\u2202\n1 \u2202\nJ\u03b2 (z) =\n\u2212\n\u2212 x \u2212 ( \u2212 \u03b2z) P\u03b2 (x, z)|x=\u221a2\u0398\u0302 .\n\u03c4m\n\u2202x\nk \u2202z\n\n(31)\n\nThe escape probability density flux appears in eq. (28) as a source term\nrepresenting the reset effect: whenever the potential V reaches the threshold\n\u0398, it is reset to the value H with the same z distribution that it had when\nit escaped. This holds because the particular value of z at the moment of\nthe generation of each spike has to be conserved for the next inter-spike\ninterval since, as opposed to V , z is not reset after an action potential.\n21\n\n\fCrucially, this self-consistency condition complicates the solution of the FPE\n(28). The escape probability density flux in eq. (31) is exact if \u03c4ref = 0\n(or approximately if \u03c4c \u226b \u03c4ref , because in this case the variable z has slow\ndynamics and therefore its probability distribution at a time \u03c4ref after the\nemission of an output spike is very similar to its distribution at the moment\nof the spike).\nLet us notice that this first representation of I(t) can be used not only for\nanalytical calculations but also for the numerical generation of exponentially\ncorrelated currents, as it is shown in Fig. (5), were we show the exponential\ntwo-point correlation function of a current I(t) generated numerically by eqs.\n(22, 23) and that predicted by eq. (26). Additionally, in a later section this\nrepresentation will be employed in the numerical analysis of the response of\nLIF neuron to negative and positive correlations (Sec 7).\n\n4.2\n\nThe second Representation for the dynamics of I(t)\n\nAn afferent current I(t) with non-negative exponential correlations obeying\neq. (17) can also be generated by the set of equations\nI(t) = \u03bc + \u03c3w \u03b7(t) + \u03c3w\ny\n\u1e8f(t) = \u2212 +\n\u03c4c\n\ns\n\ns\n\n2\n\u03b6(t) .\n\u03c4c\n\n\u03b1\ny(t)\n2\u03c4c\n\n(32)\n(33)\n\nHere \u03b7(t) and \u03b6(t) are two independent white noise processes with mean zero\nand unit variance. The two-point correlation of I(t) can be calculated\nas in\n\u221a\neq. (24), with the exceptions that \u03b2 in eq. (24) is replaced by \u03b1 and the\ntwo white noises are not correlated. Then, only the terms\n\u221a analogous to the\nfirst and fourth terms in eq. (24) are nonzero. Because \u03b1 is a real number,\nthe correlation magnitude \u03b1 has to be positive in this representation.\nFrom the set of eqs. (1, 32, 33) and making the linear transformation\ndefined in eq. (27) we obtain the FPE (the derivation is similar to the one\npresented in Appendix B )\n#\n\"\n\u221a\n\u221a\n\u03b1y \u2202\nLy\nP\u03b1 (x, y) = \u2212\u03c4m \u03b4(x \u2212 2\u0124)J\u03b1 (y) .\nLx + 2 \u2212\n(34)\nk\nk \u2202x\nThe linearqdifferential operator Lu has been defined as in Sec. 4.1, and\nagain k \u2261 \u03c4c /\u03c4m . As in the previous representation, the escape probability\n22\n\n\fdensity flux J\u03b1 (y) acts as a source term injecting current at the reset potential\nat the same rate and with the same distribution in y as when it escaped\n(here we have to assume that \u03c4ref = 0, or \u03c4c \u226b \u03c4ref = 0). It represents\nthe probability current in the direction of x evaluated at threshold. The\nprobability density vector flux for this FPE is\n\u221a\n\u03b1y\n1\n\u2202\n1 \u2202\nJ~\u03b1 (x, y) =\n[\u2212\n\u2212x\u2212\n, \u2212 2(\n+ y)]P\u03b1(x, y) .\n(35)\n\u03c4m \u2202x\nk\nk \u2202y\nIts continuity equation is\n~ J~\u03b1 (x, y) + \u03c4m \u03b4(x \u2212\n\u2207.\n\n\u221a\n\n2\u0124)J\u03b1 (y) = 0 ,\n\n(36)\n\nequivalent to the FPE (34), and the escape probability density flux is defined\nas\n\u221a !\n\u03b1y\n1\n\u2202\n\u2212\nP\u03b1 (x, y)|x=\u221a2\u0398\u0302 ,\nJ\u03b1 (y) =\n(37)\n\u2212x\u2212\n\u03c4m\n\u2202x\nk\nThe FPE (34) will be useful for finding aqperturbative solution to the first\npassage time problem in powers of k = \u03c4c /\u03c4m , that is, for short \u03c4c . We\nhave found this representation especially useful for this purpose, since this\nlimit is harder to obtain from the first representation.\n\n4.3\n\nConditions over the probability density distribution and probability density flux\n\nFor both representations of exponential correlations, the probability density\nand the escape probability density flux must be determined such that they\nobey the set of conditions:\n1. Normalization of the probability density,\n\u03c4ref \u03bdout +\n\nZ\n\n\u221a\n\n2\u0398\u0302\n\ndx\n\nZ\n\n\u221e\n\n\u2212\u221e\n\n\u2212\u221e\n\ndw Pr (x, w) = 1\n\n2. Threshold vanishing condition,\n\u221a\nPr ( 2\u0398\u0302, w) = 0\n\n23\n\n(38)\n\n(39)\n\n\f3. The output firing rate is given by\n\u03bdout =\n\nZ\n\n\u221e\n\u2212\u221e\n\ndw Jr (w).\n\n(40)\n\n4. The escape probability density flux has the form\nJr (w) = \u2212\n\n1 \u2202\nPr (x, w)|x=\u221a2\u0398\u0302\n\u03c4m \u2202x\n\n(41)\n\nwhere r = \u03b1, \u03b2 is the representation label, and w stands for both z and\ny. Condition (38) is a normalization condition stating that with probability\n\u03c4ref \u03bdout the neuron is in the refractory period. Condition (39) states that\nat the firing threshold, the probability density has to be zero (notice that\nthe density can be defined to be zero above threshold, so this condition is a\ncontinuity condition at the threshold boundary). This is so because otherwise\nthe flux in eq. (41), which includes a derivative evaluated at threshold,\nwould be infinity. The output firing rate of the neuron, \u03bdout , is obtained by\nintegrating the escape probability density flux over w, condition (40). To\nwrite down Jr (w) in condition (41) we have used the condition (39) applied\nto eqs. (31) and (37). Notice that precisely because of condition (39), the\nescape probability density flux, eq. (41), has exactly the same expression in\nboth representations.\nWhile solving the FPEs in both representations, it is usually easier to\nemploy the exact condition\n\u221a\n\n2\n\ne\u2212w /2\ndx Pr (x, w) = (1 \u2212 \u03bdout \u03c4ref ) \u221a\n,\n(42)\n\u2212\u221e\n2\u03c0\nwhich is directly obtained from the equations for z or y (eqs. (23) and (33)\nrespectively) and the condition that there is a fraction \u03bdout \u03c4ref of neurons in\nthe refractory state. Eq. (42) states that the marginal distribution of w is\na normal distribution, as it corresponds to the stationary distribution of an\nOrnstein-Uhlenbeck process (eqs. (23,33)). Notice that it is consistent with\neq. (38).\nZ\n\n5\n\n2\u0398\u0302\n\nOutput firing rate for long and short \u03c4c\n\nThe next step is to compute the output firing rate using the FPEs. We\nfound feasible to evaluate it from the first representation, eq. (28), for long\n24\n\n\fcorrelation times (\u03c4c \u226b \u03c4m ), and from the second representation, eq. (34),\nfor both short and long correlation times. In the two cases we propose a\nperturbative expansion of the solution Pr (x, w) in powers\nq of a representative\ntemporal scale parameter (a convenient power of k \u2261 \u03c4c /\u03c4m ).\n\n5.1\n\nLong \u03c4c limit using the first representation\n\nIn this limit we expand both the probability density\nand the escape probaq\n\u22121\nbility density flux as a series in powers of k = \u03c4m /\u03c4c ,\nP\u03b2 (x, z) = h0 (x, z) + k \u22121 h1 (x, z) + k \u22122 h2 (x, z) + O(k \u22123 )\nJ\u03b2 (z) = J0,\u03b2 (z) + k \u22121 J1,\u03b2 (z) + k \u22122 J2,\u03b2 (z) + O(k \u22123) .\n\n(43)\n(44)\n\nEach term Ji,\u03b2 in this expansion must satisfy the condition (41),\n1 \u2202\nhi (x, z)|x=\u221a2\u0398\u0302 .\n(45)\n\u03c4m \u2202x\nLet us proceed to the calculation by replacing the expansions (43, 44) into\nthe FPE (28). This substitution generates a set of equations for Pi,\u03b2 that\ncan be solved consistently with conditions (38 - 40). The main steps of the\nprocedure are given in Appendix C.\nThe resulting escape probability density flux J\u03b2 (z) is found to be, up to\nO(k \u22122)\nJi,\u03b2 (z) = \u2212\n\n2\n\ns\n\n3 (2 + \u03b2)\u03bd 2 (R(\u0398\u0302) \u2212 R(\u0124))\ne\u2212z /2\n\u03c4m\n0\n\u221a\nJ\u03b2 (z) =\nz\n[\u03bd0 +\n\u03c4c\n1 \u2212 \u03bd0 \u03c4ref\n2\u03c0\n\u03b1\n\u03b1C\n+ C+ 2\n(z 2 \u2212 1)] ,\n\u03c4c\n\u03b2 \u03c4c (1 \u2212 \u03bd0 \u03c4ref )\n\nC\u2261\n\n2 2\n\u03c4m\n\u03bd0\n\nq\n\n2\n\n\"\n\n\u03c4m \u03bd0 (R(\u0398\u0302) \u2212 R(\u0124))2 \u0398\u0302R(\u0398\u0302) \u2212 \u0124R(\u0124)\n\u221a\n\u2212\n1 \u2212 \u03bd0 \u03c4ref\n2\n\n#\n\n.\n\n2\n\nHere R(t) = \u03c02 et (1 + erf(t)), where erf(t) = \u221a2\u03c0 0t du e\u2212u is the error\nfunction. The rate \u03bd0 is just the firing rate of a LIF neuron driven by a white\nnoise input with variance \u03c3w2 (Ricciardi, 1977)\n\u03bd0\u22121\n\nR\n\n= \u03c4ref +\n\n\u221a\n\n\u03c0\u03c4m\n\nZ\n\n\u0398\u0302\n\n\u0124\n\n25\n\n2\n\ndt et (1 + erf(t)) .\n\n(46)\n\n\fNotice that C is independent of \u03c4c .\nWe then use condition (40) to find the output firing rate valid for long \u03c4c\nand fixed \u03b1\n\u03b1\nC.\n(47)\n\u03c4c\nSeveral important conclusions can be extracted from this simple expression.\nFirst, the effect of correlations is linear on \u03b1 for long \u03c4c . That is, doubling\n\u03b1 doubles the firing rate above the rate without correlations, \u03bd0 . Notice also\nthat \u03b1 can be positive or negative, so for negative correlations the effect on\nthe rate is the opposite than for positive correlations. Second, the firing rate\nof a LIF neuron with exponentially correlated input approaches the firing rate\nin the absence of input correlations as the correlation time increases. This\nhappens because, as the correlation time becomes longer than the membrane\ntime constant (\u03c4c \u226b \u03c4m ), the neuron filters out the fluctuations provoked by\ninput correlations. As a consequence, in the long \u03c4c limit and for finite correlation magnitude, the correlated input to the neuron can be approximated\nby a white noise process. Therefore, in this limit, the observation of only the\noutput firing rate of the neuron does not allow to distinguish a correlated\ninput from other generated by the sum of many Poisson point processes in\nthe diffusion limit. This result is important, as it determines when inputs\nwith complex correlation structure (i.e., with several correlation timescales)\ncan be approximated by white noise.\n\u03bdout = \u03bd0 +\n\n5.2\n\nLong \u03c4c limit using the second representation\n\nIn this section we calculate the firing rate in the long \u03c4c limit using the\nFPE (34). Although the FPE (34) is more restrictive than the FPE (28) (it\nonly describes positive correlations, \u03b1 > 0), it is analyzed here because it is\nmuch simpler and can also be solved in the limit in which \u03b1/\u03c4c is constant,\ni.e., for arbitrarily large \u03b1. In fact, the FPE (28) has been studied in the\nlimit in which \u03b1/\u03c4c approaches to zero as \u03c4c rises, because the correlation\nmagnitude was constant in that case. The real advantage of using the second\nrepresentation is that the predicted firing rate is valid for larger values of \u03b1,\ncompared to the formula (47).\n\u221a\nWe\nqstart from the FPE (34) and assume that the factor \u03b1/k is constant\n(k \u2261 \u03c4c /\u03c4m ). We thus define\n26\n\n\f\u221a\n\n\u03b1\n.\nk\nInserting this parameter in the FPE (34) we obtain\n\u03b3=\n\n(48)\n\n\u221a\n\u2202\nLy\nLx \u2212 \u03b3y\n+ 2 P\u03b1 (x, y) = \u2212\u03c4m \u03b4(x \u2212 2\u0124)J\u03b1 (y) ,\n\u2202x k\n\n\"\n\n#\n\n(49)\n\nwhere J\u03b1 (y) reads as in eq. (41). The solution of the FPE (49) along with\nthe conditions (38-42) in the long \u03c4c limit is found by expanding P\u03b1 (x, y) and\nthe escape probability density flux J\u03b1 (y) in powers of k \u22122 while keeping \u03b3\nfixed as\nP\u03b1 (x, y) = r0 (x, y) + k \u22122 r1 (x, y) + O(k \u22124)\nJ\u03b1 (y) = J\u03b1,0 (y) + k \u22122 J\u03b1,1 (y) + O(k \u22124 ) .\n\n(50)\n\nTo obtain the coefficients ri (x, y) and J\u03b1,i (y) we proceed as in section (5.1).\nIn particular, conditions (38 - 41) are imposed order by order. The main steps\nof the calculation are given in Appendix D. The results are here summarized\nup to order k 0 . The density P\u03b1 (x, y) up to O(k 0 ) is\n\n\u2212\n\nP\u03b1 (x, y) = \u03c4m J\u03b1 (y) e\n\n(x\u2212\u03b3y)2\n2\n\nZ\n\n\u221a\n\n2\u0398\u0302\n\nx\n\ndu e\n\n(u\u2212\u03b3y)2\n2\n\nH(u \u2212\n\n\u221a\n\n2\u0124) ,\n\n(51)\n\n(H(t) = 1 if t > 0 and it is zero otherwise) where the escape probability\ndensity flux J\u03b1 (y) up to the same order is\ny2\n1\nJ\u03b1 (y) = \u221a\ne\u2212 2\n2\u03c0\u03c4m\n\n\"Z\n\n\u221a\n\n\u221a\n\n2\u0398\u0302\u2212\u03b3y\n\n2\u0124\u2212\u03b3y\n\ndu e\n\nu2\n2\n\nZ\n\nu\n\n\u2212\u221e\n\n2\n\n\u2212 v2\n\ndve\n\n#\u22121\n\n.\n\n(52)\n\nThe output firing rate at leading order is obtained by integrating J\u03b1 (y) over\ny as\n\n\u03bdout\n\n\"Z \u221a\n#\u22121\nZ \u221e\nZ u\n2\n2\u0398\u0302\u2212\u03b3y\n1\nv2\nu2\n\u2212\n\u2212 y2\n=\u221a\ndy e\ndve 2\n.\ndue 2\n\u221a\n\u2212\u221e\n2\u0124\u2212\u03b3y\n2\u03c0\u03c4m \u2212\u221e\n\n(53)\n\nNotice that this formula has been derived for \u03c4ref = 0. Notice also that only\nthe leading order k 0 has been calculated. This order, however, gives a firing\n27\n\n\frate which is much more accurate than the firing rate obtained using the first\nrepresentation in the same limit, eq. (47). This is true because the firing\nrate in\n\u221aeq. (53) depends on \u03b3, which is a function of the parameters \u03b1 and k\n(\u03b3 \u2261 \u03b1/k). If the zero-th order firing rate in eq. (53) is expanded in powers\nof k \u22121 for fixed \u03b1, the same firing rate in eq. (47) is found when correlations\nare positive (In particular, if \u03b1 = 0, then \u03b3 = 0 and \u03bdout equals \u03bd0 , i.e., the\nwell-known expression for the firing rate of a LIF neuron driven by white\nnoise (Ricciardi, 1977)). This means that eq. (53) is exact up to O(k \u22122 ),\nand therefore the corrections to the firing rate arising from the terms O(k \u22122 )\nin the expansion (50) should vanish. This is indeed the case, as shown in\nAppendix D. In addition, the higher other corrections found in the expansion\nof eq. (53) improve the prediction provided by eq. (47), especially when \u03b1\nis very large, or when \u03b1/\u03c4c is kept constant (i.e. \u03b3 constant) in the long \u03c4c\nlimit.\nThe firing rate in eq. (53) has a very simple interpretation. Since y\nis slow compared to the voltage dynamics (\u03c4c > \u03c4m ), the firing rate of a\nLIF neuron receiving correlated noise can be calculated by multiplying the\nfiring rate of the LIF neuron receiving a frozen current proportional to y\n(plus mean \u03bc and white noise with amplitude \u03c3w ; this corresponds to the\nfunction into the square brackets, divided by \u03c4m (Ricciardi, 1977) 5 ) and\nthe probability density of having the value y, which in this case is a normal\ndistribution because y obeys an Ornstein-Uhlenbeck process, eq (33). This\nexpression, obtained here to describe the effect of exponentially correlated\ninputs, has also been used to describe the effects of synaptic filtering with\nboth fast and slow linear synapses on the output firing rate of a LIF neuron\n(Moreno-Bote and Parga, 2004).\nOne important feature of the firing rate in the long \u03c4c limit, eq. (53), is\nthat it does not change as \u03b3 is kept fixed, that is, as the ratio \u03b1/\u03c4c is kept\nconstant. This means that to obtain the same output firing rate for a longer\ncorrelation time, one has to increase proportionally the correlation magnitude so that the loss of temporal precision is counterbalanced by an increase\nin the excess of synchronous afferent spikes. This suggests a proportionality law that could be tested experimentally using in vitro current injections\nin which both the magnitude and the temporal precision can be controlled\nindependently (using e.g. eqs. (23)). Furthermore, for non-exponential cor5\n\nNote that the function within the brackets can be expressed in terms of the error\nfunction, similarly to eq. (46)\n\n28\n\n\frelation functions (e.g. oscillatory), it might be possible to define an effective\ncorrelation magnitude and an effective correlation time so that the output\nfiring rate of the neuron will not depend on them individually, but on their\nratio.\n\n5.3\n\nShort \u03c4c limit using the second representation\n\nIn the regime of short \u03c4c the FPE (34) is employed to find the output firing\nrate. Although the set of eqs. (1, 32, 33) only generates positive exponential\ncorrelations, we use them because\nits associated FPE can be solved perturq\n\u221a\nbatively in powers of k = \u03c4c /\u03c4m and \u03b1. We have found the FPE (28)\nincluding both positive and negative correlations too involved to be studied\nin the small k limit. Although the firing rate computed in this limit from the\nFPE (34) is derived only for positive correlations, when the same formula is\nemployed for negative correlations, one finds an excellent agreement with the\nnumerical results. This fact suggests that the analytical continuation of our\nformula to negative correlations (\u03b1 < 0) could match the true expression for\nthat case.\nEven when using the FPE (34), valid for positive correlations, the short\n\u03c4c expansion is not easy to obtain. This is because of the self-consistency\ncondition (41), which is hard to deal with. However, if the correlation time\n\u03c4c is short compared to the refractory time \u03c4ref (\u03c4ref \u226b \u03c4c ), the escape\nprobability density flux can be written as (Doering et al., 1987)\n2\n\nJ\u03b1 (y) = \u03bdout\n\ne\u2212y /2\n\u221a\n,\n2\u03c0\n\n(54)\n\nwhich solves automatically the conditions (40 - 41). This approximation is\ngood because after a spike the variable y approaches its Gaussian stationary\ndistribution in a time \u03c4c , which we are taking shorter than \u03c4ref .\nWe now look for a solution of the FPE (34) of the form\nP\u03b1 (x, y) = f0 (x, y) + kf1 (x, y) + O(k 2 ) ,\n\n(55)\n\nand at the same time we expand the escape probability density flux J\u03b1 in\npowers of k or, equivalently, the unknown output firing rate as\n\u03bdout = \u03bdef f + k\u03bd1 + O(k 2 ) .\n\n29\n\n(56)\n\n\fIt can be shown that the solution f1 (x, y) obtained from the perturbative expansion does not satisfy the vanishing boundary condition (39) (see\nAppendix E). To address this problem, we extend the formalism described\nin (Doering et al., 1987) to solve the short \u03c4c limit. As in (Doering et al.,\n1987), our problem does not have a perturbative solution for short \u03c4c , and\nit is necessary to solve a boundary layer problem. Details of these calculations are given in Appendix E. Briefly, the solution P\u03b1total (x, y) is obtained\nas the sum of the perturbative and an additional solution, valid close to the\nthreshold, that we call boundary solution f1b (x, y):\nP\u03b1total (x, y) = f0 (x, y) + k[f1 (x, y) + f1b (x, y)] + O(k 2 ) .\n\n(57)\n\nIt is now possible to satisfy the condition (39) up to order k. Finally, the\nfiring rate up to order k can be calculated using the condition (38), resulting\n\u221a\n\u03bdout = \u03bdef f (\u03b1) \u2212 \u03b1 \u03c4c \u03c4m \u03bd02 R(\u0398\u0302) ,\n\n(58)\n\nwhere \u03bd0 is defined as in eq. (46) and\n\u22121\n\u03bdef\nf (\u03b1) = \u03c4ref +\n\n\u221a\n\n\u03c0\u03c4m\n\nZ\n\n\u0398\u0302ef f\n\u0124ef f\n\n2\n\ndt et (1 + erf(t)) .\n\nThe effective reset and threshold potentials are defined as \u0398\u0302ef f =\n\n(59)\n\u0398\u2212\u03bc\u03c4\n\u221am\n\u03c3ef f \u03c4m\n\nand\n\n\u221a m . An important implication of eq. (58) is that when \u03c4c = 0\n\u0124ef f = \u03c3H\u2212\u03bc\u03c4\nef f \u03c4m\nthe output rate is \u03bdef f (\u03b1), equivalent to that of a LIF neuron receiving an\nuncorrelated input (white noise) with an effective signal variance\n2\n2\n\u03c3ef\nf = \u03c3w (1 + \u03b1) .\n\n(60)\n\nIn this case, the solution is exact for all \u03b1. When \u03c4c 6= 0, it is correct only\nfor small values of both k and \u03b1 > 0. This expression indicates that when\nthe correlation time is zero, the effect of the input correlations is to increase\nthe white noise variance by a factor equal to 1 + \u03b1.\nA general expression for the firing rate of any IF neuron is presented in\nAppendix F. Again, for \u03c4c = 0, the firing rate is that of the IF neuron with\ninput white noise but with a renormalized variance as in eq. (60). From this\nmaximum firing rate at optimal synchronization, the firing rate decreases as\n\u221a\n\u2212 \u03c4c for fixed \u03b1 (eq. (99), analogous to eq. (58) for a LIF neuron), showing\nthat this large sensitivity to variations in the correlation time of the inputs\nis a general property of IF neurons.\n30\n\n\fShort \u03c4c\n\nFirst Representation\n\nSecond Representation\n\nNot found\n\n\u221a\n\u03bdout = \u03bdef f (\u03b1) \u2212 \u03b1 \u03c4c \u03c4m \u03bd02 R(\u0398\u0302) , eq. (58).\nValid for small and positive \u03b1, and\nexact for all positive \u03b1 when \u03c4c = 0.\n\nLong \u03c4c\n\n\u03bdout = \u03bd0 +\n\n\u03b1\nC\n\u03c4c\n\n2\n\n,\n\nR\u221e\n\u2212 y2\n\u221a 1\n\u2212\u221e dy e\n2\u03c0\u03c4\nm\n\u0014 \u221a\n\u0015\n2 \u22121\nR 2\u0398\u0302\u2212\u03b3y\nu2 R u\n\u2212 v2\n\u221a\n2\ndue\n\u2212\u221e dve\n2\u0124\u2212\u03b3y\n\n\u03bdout =\n\neq. (47).\n\nwith \u03b3 =\nValid for small \u03b1,\npositive and negative.\n\n,\n\nq\n\n\u03b1\u03c4m /\u03c4c , eq. (53).\n\nValid for all (even large) positive \u03b1.\n\nTable 1: Analytical expressions for the output firing rate of a LIF neuron\nreceiving exponentially correlated inputs with magnitude \u03b1 and correlation\ntimescale \u03c4c for the two representations of the current in both the short and\nlong \u03c4c limits.\n\n6\n\nSummary of the analytical results\n\nThe analytical results, obtained in the first and second representations of the\ncurrent, and in the short and long \u03c4c limits, along with the conditions upon\nwhich they are valid, are summarized in Table (1).\nThe second representation allows one to calculate the firing rate for both\nshort and long \u03c4c , while the first representation only allows the calculation\nof the firing rate for long \u03c4c . In (Moreno et al., 2002) we used the second\nrepresentation to obtain the firing rate for short \u03c4c , and therefore the expression shown here is the same at that found there. On the other hand, using\nthe second representation for long \u03c4c , here we have been able to find a new\nexpression for the firing rate, eq. (53), which can be applied for arbitrarily\nlarge \u03b1, while that found in (Moreno et al., 2002) using the first representation, eq. (47), could only be applied for small \u03b1. The expressions valid for\n31\n\n\flong \u03c4c , eq. (47) and eq. (53), are in fact equivalent when the limit \u03b1 \u2192 0\nis taken (Appendix D). Note, however, that eq. (47) can be employed for\nnegative \u03b1, while eq. (53) can only be used for positive \u03b1.\n\n7\n\nThe effect of correlations on the firing response of spiking neurons\n\nIn this section we take advantage of the machinery developed in the previous\nsections. First, the prediction of the firing rate as a function of the timescale\nand magnitude of input correlations is used to study the role of synchrony on\nthe stationary firing response of a LIF neuron. Second, we study the firing\nresponse to modifications of the correlation magnitude. Numerical solutions\nof the voltage and noise equations to generate exponentially correlated noise\nare employed in this case.\n\n7.1\n\nStationary firing response\n\nAlthough we have calculated the output firing rate both in the limit \u03c4c \u226a \u03c4m\nand in the limit \u03c4c \u226b \u03c4m , before the effect of \u03c4c and \u03b1 on the firing rate is\ndescribed, we develop an interpolation procedure that allows us to use a single\nexpression for all values of \u03c4c . The interpolating curves have been determined\nby setting the firing rate in the short correlation time range (\u03c4c < \u03c4m ) as\n\u221a\n\u03bdout = \u03bdef f + A1 \u03c4c + A2 \u03c4c ,\n\n(61)\n\nwhere A1 and A2 are unknown functions of \u03b1 and of the neuron and input\nparameters, while in the long correlation time limit (\u03c4c > \u03c4m ) the expression\ngiven in eq. (47),\n\u03bdout = \u03bd0 + \u03b1C/\u03c4c ,\n\n(62)\n\nwas used. The functions A1 and A2 are determined by interpolating these two\nexpressions with conditions of continuity and differentiability at a convenient\ninterpolation point \u03c4c,inter \u223c \u03c4m . Although we have calculated analytically\nthe function A1 (eq. (58)) for small \u03b1, this procedure takes into account\nhigher order corrections which match more accurately the observed data for\nlarger values of \u03b1, as those used in some of our simulations (see below).\nTherefore, eqs. (61-62) provide an analytical formula for the output firing\n32\n\n\frate of a LIF neuron receiving exponentially correlated input which is valid\nfor all \u03c4c .\nWe have performed numerical simulations of a LIF neuron driven by\nGaussian exponentially correlated input using eqs. (1, 22, 23). We use\nthem to check the analytical results given in eqs. (47, 53, 58) and validate\nthe interpolation made between the regimes of short and long \u03c4c , provided\nby eqs. (61-62). When positive correlations are considered (\u03b1 > 0), the\ninterpolation procedure is robust against changes in \u03bc and \u03c3w2 . Crucially,\nthe interpolating point \u03c4c,inter \u223c \u03c4m does not vary too much, so that it can\nbe maintained approximately fixed for all input parameters. For negative\ncorrelations we have found more convenient to add to the expansion in eq.\n(62) an extra term: \u03bdout = \u03bd0 + \u03b1 C/\u03c4c + B1 /\u03c4c2 . Then, this expression is\nmade to match at \u03c4c,inter \u223c \u03c4m the short \u03c4c regime given by the equation\n\u221a\n\u03bdout = \u03bdef f + B2 \u03c4c .\nThis interpolation is compared with simulation results in Fig. (6), providing good fits. The firing rate increases as \u03c4c decreases (at fixed positive\n\u03b1). This corresponds to the intuitive result that positive correlations between the presynaptic events produce a larger enhancement in the output\nfiring rate as the temporal window over which they occur decreases. On the\nother hand, when negative correlations are present in the input, the effect of\n\u03c4c is reversed: the firing rate increases as \u03c4c increases. Negative correlations\nproduce a deficit in current fluctuations that decreases the firing rate. This\ndeficit is not noticeable if \u03c4c is very long compared with \u03c4m . These results\nshow that correlations with fixed magnitude \u03b1 have different effects on a target neuron depending on the value of their correlation timescale. Correlations\nare not perceived by neurons if the temporal precision they occur is larger\nthan the membrane time constant of those neurons. As it can be appreciated\nin Fig. (6), when \u03c4c is of the order of 40ms (twice longer than \u03c4m ) the output firing rate of the neuron approaches the firing rate obtained by an input\nwithout correlations (\u03b1 = 0, dashed-dotted line). Only if \u03c4c < \u03c4m = 20ms,\nthe presence of correlations is noticeable. As noted above, this implies that,\nfrom the point of view of the output firing rate, correlations in the input\ncan be neglected, i.e., a white-noise input description is appropriate, when \u03c4c\nis significantly longer than \u03c4m (note, however, that there is not an absolute\nvalue of \u03c4c for which correlations can be neglected, rather, this value will\nincrease with \u03b1).\nIn Fig. (7) we use the predictions of eqs. (47,53) valid for long \u03c4c .\nHere, large values of correlation magnitude, \u03b1, are used. The predictions\n33\n\n\fare compared with simulations of neurons in the subthreshold (left) and\nthe suprathreshold (right) regimes. The subthreshold and suprathreshold\nregimes are defined by \u03bc\u03c4m < \u0398 and \u03bc\u03c4m > \u0398 respectively, and they correspond to the fluctuation and drift dominated regimes. The prediction by\neq. (53) is very good even for intermediate \u03c4c \u223c \u03c4m in both regimes. In\ncontrast, the firing rate for long \u03c4c given in eq. (47), provides poorer fits\n(dotted line in the left panel) in the subthreshold regime, and even poorer in\nthe suprathreshold regime when very large values of \u03b1 are used (not shown).\nThis is because the second prediction of the firing rate was obtained for fixed\n\u03b1.\nThe figure also shows that the effect of correlations is quite different for\na neuron receiving subthreshold or suprathreshold inputs. For subthreshold\ninputs, positive correlations always increase the firing rate relative to the\ncase without correlations, and the firing rate decreases as the timescale of\ncorrelations becomes broader. However, for suprathreshold inputs a different qualitative behavior is observed, at least for small white noise variances.\nPositive correlations with long enough \u03c4c give an output firing rate smaller\nthan the basal rate without correlations, although this effect is very small\n(notice the large values of \u03b1 that have been used). A minimum firing rate\nis attained when the correlation timescale is longer than the membrane time\nconstant of the neuron, and the exact value of \u03c4c at which the minimum\noccurs is roughly predicted by the analytical formula (53). When the white\nnoise variances become larger, this counterintuitive effect of correlations disappears, and the profile is much more similar to the subthreshold case, but\nwith much smaller correlation-induced changes.\nOverall, this analysis shows that neurons are more sensitive to correlations in the subthreshold than in the suprathreshold regime, what is not\nsurprising, since in the first regime spiking is driven by input fluctuations\nand correlations enhance them (Moreno et al., 2002; Salinas and Sejnowski,\n2001).\n\n7.2\n\nTransient firing response\n\nAnother important question is how fast a neuron can respond to pure changes\nin the correlation magnitude \u03b1, that is, when both the afferent mean current\nand white noise variance \u03c3w2 are fixed. In our work (Moreno et al., 2002) we\nhave shown that changes in correlation magnitude can be transmitted very\nfast by the firing rate of spiking neurons even when the timescale of those\n34\n\n\fcorrelations is quite large. Those firing responses are also compared here\nwith the response to sudden jumps in mean input current.\nLet us write the instantaneous firing rate for the time dependent FPE,\neither in the first or in the second representation, as (see eq. (41))\n\u221e\n\u03c3 2 (t) \u2202\ndwP (V, w, t)|V =\u0398 .\n(63)\n\u03bdout (t) = \u2212 w\n2 \u2202V \u2212\u221e\nFor the sake of clarity, we have come back to the physical quantity V and used\nits distribution P (V, w, t) (w = z, y). A similar equation for the instantaneous firing rate of a one-dimensional FPE has been used by Silberberg et al.\n(2004) to predict that any instantaneous modification in the white noise variance, \u03c3w2 (t), produces an immediate change in the output firing rate of the\nneuron. Besides, as we have shown before, the exact form of eq. (63) for\n\u03c4c = 0 corresponds to a neuron receiving (uncorrelated) input white noise\n2\n2\nwith effective variance \u03c3ef\nf = \u03c3w (1 + \u03b1), eq. (19). This gives (Moreno et al.,\n2002)\n\nZ\n\nZ\n2\n\u03c3ef\nf (t) \u2202\ndwP (V, w, t)|V =\u0398 .\n(64)\n2 \u2202V\nNow it is clear that any change in \u03b1 will produce an immediate change in\nR\n\u03bdout (t), because the distribution P (V, t) = dwP (V, w, t) can only experience\na smooth change (notice that the trajectories generated by the equations for\nV (e.g, see eqs. (1, 22, 23)) are continuous under changes in \u03b1). This means\nthat when \u03c4c = 0, changes in the correlation magnitude (\u03b1) will be felt\nimmediately by the firing response of the neuron. By analyticity arguments,\nthe response under changes in \u03b1 will be also fast for non-zero \u03c4c .\nThese predictions have been tested with numerical simulations, whose\nresults are shown in Fig. (8). Initially the input statistics is white noise, and\nsome time later either the mean current \u03bc (bottom curve), or the white noise\nvariance \u03c3w (upper curve), or the correlation amplitude \u03b1 (two intermediate\ncurves) are changed independently. Changing abruptly the mean current\nonly produces a slow response with a timescale of the order of the membrane\ntime constant. However, in the absence of correlations, the firing rate changes\ninstantaneously under a sudden modification in the variance of the injected\ncurrent (\u03c3w2 ). In agreement with our prediction, for short \u03c4c the response\nis also very quick when the correlation changes from \u03b1 = 0 to a positive\nvalue. To quantify how fast the response is, we computed the time tcross at\nwhich the instantaneous rate reaches for the first time the value of the final\n\n\u03bdout (t) = \u2212\n\n35\n\n\fstationary firing rate. The inset in Fig. (8) shows that, as a function of\n\u03c4c , tcross initially grows but it soon saturates at about 3ms, even when \u03c4c is\nseveral hundred milliseconds long. Thus, the correlation time is not a limiting\nfactor for fast transmission of information contained in correlation changes.\nThis result shows that information carried by correlated input patterns can\nbe transmitted with a timescale that is not limited by the membrane time\nconstant, what is not the case for signals embedded in the mean input current\n(Moreno et al., 2002). In (Rudolph and Destexhe, 2001) the authors show\nthat correlation changes can be followed very rapidly by a spiking neuron.\nBecause they consider the case of perfect synchrony, \u03c4c = 0, their conclusions\nare similar to those by (Silberberg et al., 2004), because the case \u03c4c = 0\ncorresponds to a simple renormalization of the current variance (\u03c3w2 ), as we\nhave explained before (see eq. (19)).\nThese results show that fast information transmission in cortex using\nspike correlations is theoretically possible. As we have shown, changing\nthe mean afferent current produces slow responses if the neuron is in the\nsubthreshold regime, because the mean current has to be integrated in a\ntimescale \u03c4m . However, because of their fast transmission rate, correlation\nmodulations can be an ideal candidate for transmitting information rapidly.\nThe fact that changes in \u03bc do not evoke rapid responses does not mean\nthat rate codes are inefficient for transmitting information rapidly. Rather,\nchanges in the firing rate of \"noisy\" input spike trains (e.g., as in a Poisson\ntrain) involve both changes in \u03bc and in fluctuations \u03c3w (Ricciardi, 1977) and\nindeed also in \u03b1 (see their definitions in eqs. (18)). Such white noise variance and correlation magnitude modulations can be transmitted very fast,\nwhile the mean current modulations produce a slower response. Therefore,\nan increase in the firing rate of an irregularly spiking presynaptic population\nwill produce an output rate change which contains information in at least\ntwo different timescales (one short and another slow).\n\n8\n\nDiscussion\n\nIn this paper we have provided and thoroughly analyzed a theoretical framework to understand how temporal correlations affect the output firing response of neurons. The main qualitative results we found are\n\u2022 The neuron's output rate is very sensitive to precisely synchronized\ninputs with \u03c4c < \u03c4m .\n36\n\n\f\u2022 The response decreases (increases) with the timescale \u03c4c for positive\n(negative) correlations, and increases (decreases) with their magnitude\n\u03b1.\n\u2022 The neuron response to sudden changes in the size of the correlations\nis very fast, regardless of the magnitude of the change and on the\ncorrelation time.\nAn important question is how our results can be incorporated into the\nmodeling of neural networks. Temporal and spatial correlations are presumably relevant to correctly describe the dynamics of realistic recurrent neuronal\nnetworks. Recently in (Renart et al., 2007) we have proposed an extended\nmean-field approach to determine the firing rate and spiking variability of a\nlarge network of LIF neurons. In the classical mean-field theory, the neurons\nin the network are assumed to fire in a Poisson and independent manner\n(Amit and Brunel, 1997b; Renart et al., 2003), so that the only free dynamical parameter in the dynamics of an homogeneous population of neurons is\nits population firing rate. Our extension goes beyond the classical mean field\ntheory by adding as a free parameter the spiking variability of the network,\nthat is, the coefficient of variation of the inter-spike-intervals, CV . Then,\nthe firing rate as well as the variability of the network can be studied without the assumption that the spike trains are Poisson, corresponding to the\nparticular case CV = 1. In particular, stationary states with CV > 1 would\ncorrespond to states of high spiking variability, while stationary states of the\nnetwork with CV < 1, would correspond to more regular spiking regimes of\nthe neuronal dynamics. The formalism presented in (Renart et al., 2007) is\nbased on the result that when the correlation time of the spike trains is short\nenough (\u03c4c \u226a \u03c4m ), then the input variability can be expressed as (see eqs.\n(60,18); (Moreno et al., 2002))\n2\n2\n2\n2\n2\n\u03c3ef\nf = JE NE CVE \u03bdE + JI NI CVI \u03bdI ,\n\n(65)\n\nassuming that there is no cross-correlations (\u03c1 = 0). Since the output firing\nrate and the output CV of an integrate-and-fire neuron can be calculated\nexactly when the input is white noise (Ricciardi, 1977), then a mapping\nbetween the input rates and CV , and the output rates and CV can be\nconstructed as\n\u03bdout = f\u03bd (\u03bdin , CVin )\n37\n\n\fCVout = fCV (\u03bdin , CVin ) ,\n\n(66)\n\nwhere the functions f\u03bd and fCV are the expressions for the output firing rate\nand CV of the IF neuron receiving white noise input. These equations define an input-output mapping of the neuronal dynamics with independent\nvariables \u03bd and CV . Therefore, under the conditions described above, a\nmean-field theory for the dynamics of the mean and variability of the spiking\nresponse can be formulated. Doiron et al. (2006) have also recently used our\nrenormalization technique of the input variance, as defined in eqs. (65,66),\nto describe the transmission of the activity of non-leaky IF neuron in feedforward networks. As we have said above, (Renart et al., 2007) have addressed the problem of self-consistency in firing rate and CV in recurrent\nnetworks of LIF neurons. Other works have also studied this problem using\ndifferent approaches to find self-consistent equations for the spiking variability of the network (Lerchner et al., 2006).\nHowever, further extensions of our mean-field theory (Renart et al., 2001;\nMoreno et al., 2002; Renart et al., 2007) are required to consider in a selfconsistent way the second order statistics of the neuronal activity in spiking\nrecurrent networks. A first step has been made in (Moreno-Bote and Parga,\n2006), where the auto- and cross-correlation functions of the output response\nof a pair of spiking neurons receiving independent as well as common sources\nof noise have been analytically determined 6 . The self-consistent treatment of\nspike cross-correlation functions (i.e., the input and output cross-correlation\nfunctions should also match each other) to describe more realistic recurrent neuronal networks seems to be an unavoidable step to understand how\nneurons' interactions give rise to network behaviors. The problem can be\nformally stated as follows: find the set of mean-field equations mapping the\ninput values of the relevant dynamical variables of the network (firing rate,\nFN and \u03c1) to their output values\n\u03bdout = f\u03bd (\u03bdin , FN,in , \u03c1in )\nFN,out = fFN (\u03bdin , FN,in , \u03c1in )\n\u03c1out = f\u03c1 (\u03bdin , FN,in , \u03c1in ) .\nThis set of equations are now available at least for a LIF neuron receiving\ncolored noise (Moreno-Bote and Parga, 2006).\n6\n\nFor different approximations of this computation see (Lindner et al., 2005; Masuda,\n2006)\n\n38\n\n\fIn this work we have considered decaying (exponential) correlations, while\nin cortex, damped oscillatory cross-correlograms are also observed (see e.g.\n(Vaadia et al., 1995; Riehle et al., 1997; Fries et al., 1997)). This problem\ncould be addressed by introducing a stochastic current which obeys a secondorder equation driven by white noise: the well-known damped oscillator. A\ncurrent generated in this way can have a cross-correlogram with exponentially\ndecaying oscillations, with frequency and damping value controlled by the\nparameters of the equation. Although relevant, we do not study this problem\nhere, since the new system would involve solving a more complicated FPE\nhaving now three independent variables.\nHere we have not studied neuron models with conductance-based synapses\neither. However, an analogous expression for the firing rate at long \u03c4c can be\nobtained if the noise enters multiplicatively, instead of additively (although\nwe do not present the derivation here, the FPE for neuron models with\nconductance-based synapses can be solved using the techniques in Appendix\nD). Qualitatively, the effect of the correlation magnitude and correlation\ntimescale in conductance-based models is not different from their effects in\ncurrent-based models. Note, however, that in the first case correlations are\nstrongly effective only when \u03c4c is shorter than the effective membrane time\nconstant of the neuron, which now depends on the total conductance (see\ne.g. (Moreno-Bote and Parga, 2005)).\nWe have modelled input spike trains as delta functions (point-processes)\nwithout any further temporal synaptic filtering. This means that the crosscorrelation function of the total input current displays a delta function at\nzero time lag, as shown in eq. (17). When the input spike trains are filtered\nby synapses with a finite synaptic time constant \u03c4s , they generate a train of\nexponential-like current waveforms into the neuron. The delta function in the\ncorrelation function, eq. (17), becomes then an exponential with the same\ntime constant as that of the synaptic filter, \u03c4s (see e.g. (Brunel and Sergi,\n1998; Moreno-Bote and Parga, 2004)). At the same time, the exponential\nterm in the correlation function results after filtering in two additional exponentials, with time constants \u03c4c and \u03c4s , respectively. Then, the result of\n(linearly) filtering correlated input spike trains is an input current whose\ncorrelation function has two kind of exponentials, each with a different time\nconstant (\u03c4c and \u03c4s ). Particular cases of this interesting problem (e.g. when\nthe two timescales are disparate) could be addressed analytically by using the\ntechniques developed to study simultaneous fast and slow synaptic filtering\n(Moreno-Bote and Parga, 2004).\n39\n\n\fTwo differences are expected when synaptic filters are present in the\nmodel. First, synapses filter out fluctuations in the input whose timescale is\nshorter than \u03c4s and convert them into fluctuations with timescale \u03c4s . Fluctuations that are slower than \u03c4s will pass the synapses. Therefore, fast fluctuations produced by precise input synchronization (i.e., short \u03c4c \u2264 \u03c4m ) will not\nbe seen by the neuron: effectively the sharp synchronization of timescale \u03c4c is\nconverted into a coarser synchronization with timescale \u03c4s . Then, we expect\nthat for \u03c4c < \u03c4s the firing rate will depend very little on \u03c4c in that range.\nHowever, when \u03c4c > \u03c4s the rate vs. \u03c4c curve will decay fast until \u03c4c crosses \u03c4m ,\nafter which the effect of input correlation on the rate will be small, similarly\nto Fig. (6). Second, filters introduce a delay in the transient firing response\nto sudden increases of input synchrony. We have run simulations with fast\nfilters (\u03c4s \u2264 5ms) and found that the response was still fast and was delayed\nby the time constant of the synapses.\nIn future work it would be desirable to develop a complete theory that\ndescribes the firing statistics of integrate-and-fire neurons with conductancebased synapses and finite synaptic timescales driven by correlated spike\ntrains. The effect of input correlations in this more complex system could be\nevaluated by extending and combining the techniques developed in this and\nthe above quoted works.\n\nAcknowledgments\nRub\u00e9n Moreno-Bote thanks the Swartz Foundation for financial support.\nSupport was also provided by the Spanish Grant FIS 2006-09294\n\nAppendices\nA\n\nNumerical procedures\n\nThe equations for the voltage of the integrate-and-fire neuron and the correlated Gaussian noise are numerical solved using a simple Euler integration\nprocedure, along with a Monte-Carlo method. This procedure gives an excellent estimate of the the output firing rate (time dependent or independent),\nwhich can be compared to the theoretical predictions. As an example, the dy40\n\n\fnamics of the voltage of a LIF neuron in eq. (1) with the current I(t) defined\nin eqs. (22,23) is integrated using a small time step (\u03b4t = 5 10\u22124ms \u226a \u03c4m )\nas\nV (t)\n\u03b4t + I(t)\u03b4t ,\n\u03c4m\n\u03b2\n\u03c9(t)\nI(t) = \u03bc + \u03c3w \u221a + \u03c3w \u221a z(t) ,\n2\u03c4c\n\u03b4t\ns\n\u221a\nz\n2\nz(t + \u03b4t) = z(t) \u2212 \u03b4t +\n\u03c9(t) \u03b4t ,\n\u03c4c\n\u03c4c\nV (t + \u03b4t) = V (t) \u2212\n\n(67)\n(68)\n(69)\n\nwith the reset condition V = H after a spike is generated (when V \u2265 \u0398).\nThe initial value of the noise variable z is that at the time of the previous\nspike, i.e, z is not reset after each spike. The variable \u03c9(t) is a random\nvariable taken values +1 and \u22121 with equal probability 1/2 at each time step\n\u03b4t, and being drawn independently from time step to time step. Therefore\nh\u03c9(t)i = 0, h\u03c9 2 (t)i = \u221a\n1 and h\u03c9(t)\u03c9(t\u2032)i = 0, where t 6= t\u2032 . This means\nthat the quantity \u03c9(t)/ \u03b4t, which appears in the expressionD for the\nE\n\u221a current\nI(t) above, is an approximation to the delta function, since \u03c9(t)/ \u03b4t = 0,\nh\u03c9 2(t)/\u03b4ti = 1/\u03b4t, and h\u03c9(t)\u03c9(t\u2032)/\u03b4ti = 0. The procedure described above\nis robust and converges to the true stationary process as \u03b4t decreases. The\nMonte-Carlo simulations were run using Fortran90 custom code. Special care\nhas to be taken in choosing an appropriate random generator for \u03c9(t).\n\nB\n\nDerivation of the FPEs\n\nThe FPE (28) is here derived for the set of equations\nx(t)\n\u1e8b(t) = \u2212\n+\n\u03c4m\nz\n\u017c(t) = \u2212 +\n\u03c4c\n\ns\n\ns\n\n2\n\u03b2\n\u03b7(t) + \u221a\nz(t)\n\u03c4m\n\u03c4m \u03c4c\n\n2\n\u03b7(t) ,\n\u03c4c\n\n(70)\n\ncorresponding to the first representation of the current. The FPE (34) associated to the second representation of the current can be obtained using\n41\n\n\fthe same rules described in this section. More formal derivations of similar\nFPEs can be found in (Ricciardi, 1977; Risken, 1989).\nThe system defined by eqs. (70) is fully described by the probability\ndensity function P\u03b2 (x, z, t). This function expresses the probability density\nof having the neuron in the state (x, z) at time t. The FPE is an equation\nwith precisely describes the dynamics (i.e., time evolution) of such a density.\nA first step toward the derivation of the FPE consists in discretizing the time\nin the dynamics, similarly as it has been done in Appendix A. This leads to\n\u221a\n2\n\u03b2\n\u03c9(t) \u03b4t + \u221a\nz(t)\u03b4t\n\u03c4m\n\u03c4m \u03c4c\ns\n\u221a\n2\nz\n\u03c9(t) \u03b4t ,\nz(t + \u03b4t) = z(t) \u2212 \u03b4t +\n\u03c4c\n\u03c4c\nx(t)\nx(t + \u03b4t) = x(t) \u2212\n\u03b4t +\n\u03c4m\n\ns\n\n(71)\n\nwhere \u03b4t represents an infinitesimal time increment, and \u03c9(t) is a random\nvariable taken values +1 and \u22121 with probability p(w = \u00b11) = 1/2 and\ndrawn independently\n\u221a at every infinitesimal time step. The terms in eqs. (71)\nproportional to \u03b4t are approximations to the delta functions in eqs. (70)\nintegrated during the infinitesimal time increment.\nTo determine the FPE associated to eqs. (70), one has to relate the\ndensity at time t + \u03b4t, P\u03b2 (x, z, t + \u03b4t), with the density at a previous time t,\nP\u03b2 (x\u2032 , z \u2032 , t). First, we realize that the probability that we find a neuron in\nan infinitesimal square \u03b4x\u2032 \u03b4z \u2032 around state (x\u2032 , z \u2032 ) at time t has probability\nP\u03b2 (x\u2032 , z \u2032 , t)\u03b4x\u2032 \u03b4z \u2032 . Second, the state square centered at (x\u2032 , z \u2032 ) with surface\n\u03b4x\u2032 \u03b4z \u2032 will be projected at the successive time t + \u03b4t into another square\ncentered at (x, z) with surface \u03b4x\u03b4z close to the previous one, obeying the\nrules defined in eqs. (71). Therefore, by conservation of the probability, we\nhave that\nP\u03b2 (x, z, t + \u03b4t) \u03b4x\u03b4z =\n\nX\n\np(w) P\u03b2 (x\u2032 (w), z \u2032 (w), t) \u03b4x\u2032 \u03b4z \u2032 ,\n\nw=\u00b11\n\nwhere\n\n\u03b2\n2 \u221a\nz\u03b4t\n\u03c9 \u03b4t \u2212 \u221a\n\u03c4m\n\u03c4m \u03c4c\ns\nz\n2 \u221a\nz \u2032 (w) = z + \u03b4t \u2212\n\u03c9 \u03b4t .\n\u03c4c\n\u03c4c\n\nx\nx (w) = x +\n\u03b4t \u2212\n\u03c4m\n\u2032\n\ns\n\n42\n\n(72)\n\n\fNotice that the states (x\u2032 (w), z \u2032 (w)) (w = \u00b11) defined above are the only ones\nfrom where one can arrive to the state (x, z) after an infinitesimal amount of\ntime \u03b4t. In addition, the box around state (x\u2032 , z \u2032 ) is compressed to the box\naround the final state (x, z) by a factor \u03b4x\u03b4y = (1 \u2212 \u03b4t/\u03c4m )(1 \u2212 \u03b4t/\u03c4c )\u03b4x\u2032 \u03b4y \u2032 ,\ngiven by the decaying term in eqs. (70).\n\u221a\n\u03b4t, we find that\nAfter expanding the densities\nin\neq.\n(72)\nin\npowers\nof\n\u221a\nall terms which are order \u03b4t are equal to zero (since h\u03c9i = 0), while the\nterms order \u03b4t do not vanish (either they do not depend on \u03c9, or they are\nproportional to \u03c9 2 , and therefore h\u03c9 2i = 1). After equaling the terms at\nO(\u03b4t), one obtains the FPE\n\u03c4m\n\n\u2202\nLz\n2 \u2202 \u2202\n\u03b2z\nP\u03b2 (x, z, t) = [Lx + 2 +\n( \u2212\n)]P\u03b2 (x, z, t) .\n\u2202t\nk\nk \u2202x \u2202z\n2\n\n(73)\n\n\u2202\nIn the time-independent case, \u2202t\nP\u03b2 (x, z, t) = 0. However, to establish a\nstationary probability density function which does not depend on time, the\nprobability density flux escaping at threshold (probability density flux in the\ndirection of the variable x calculated at threshold) should be reinjected into\nthe\nreset voltage. This enforces conservation of the total probability, that is,\nRR\ndxdz\u03c1(x, z, t) = 1 at all times, and leads to the self-consistent stationary\nFPE (28).\n\nC\n\nLong \u03c4c expansion using the first representation\n\nHere we detail the main steps for calculating the firing rate in eq. (47).\nIntroducing the expansions (43, 44) in eq. (28) we obtain\n\nLx hn + Lz hn\u22122 + 2\n\n\u221a\n\u2202 \u2202\n\u03b2z\n( \u2212\n)hn\u22121 + \u03c4m \u03b4(x \u2212 2\u0124)J\u03b2,n\u22121 (z) = 0 (74)\n\u2202x \u2202z\n2\n\n(hn \u2261 0 for n < 0). The solution to these equations is obtained order by\norder in such a manner that the conditions (38 - 41) are satisfied. After\nsolving them up to order k 2 using the conditions (39, 41) and the fact that\nthe hn 's have to be normalizable, we obtain that\nh0 (x, z) = k0 (x)J\u03b2,0 (z) ,\n43\n\n\f\u2202\n\u2212 \u03b2z)J\u03b2,0 (z) ,\n\u2202z\n\u2202\nh2 (x, z) = k0 (x)J\u03b2,2 (z) + k1 (x)(2 \u2212 \u03b2z)J\u03b2,1 (z)\n\u2202z\n\u2202\n+k2 (x)(2 \u2212 \u03b2z)2 J\u03b2,0 (z) ,\n\u2202z\nwhere the functions ki are\nh1 (x, z) = k0 (x)J\u03b2,1 (z) + k1 (x)(2\n\n2\n\n\u2212 x2\n\nk0 (x) = \u03c4m e\n\nx2\n2\n\nZ\n\n2\n\u2212 x2\n\nZ\n\nk1 (x) = e\u2212\nk2 (x) = e\n\nZ\n\n\u221a\n\nx\n\u221a\n2\u0398\u0302\n\nx\n\u221a\n\n2\u0398\u0302\n\nx\n\n2\u0398\u0302\n\ny2\n\ndye 2 H(y \u2212\n\n\u221a\n\n(75)\n\n2\u0124) ,\n\ny2\n\ndye 2 k0 (y) ,\ny2\n\ndye 2 k1 (y) .\n\nThe coefficients Ji,\u03b2 (z) in eq. (75) have still to\u221abe calculated. This is done\nby integrating first the hn 's over x from \u2212\u221e to 2\u0398\u0302 and using the condition\n(42). After using the condition (40), we find\nJ0 (z) = \u03bd0 Z0 (z) ,\nJ1 (z) =\n\n(2 + \u03b2)\u03bd0\n\nR \u221a2\u0398\u0302\n\u2212\u221e\n\ndxk1 (x)\n\nz Z0 (z) ,\ndxk0 (x)\n#\n\"\n\u03b1C\n\u03b1\n2\nC+ 2\n(z \u2212 1) Z0 (z) ,\nJ2 (z) =\n\u03c4m\n\u03b2 \u03c4m (1 \u2212 \u03bd0 \u03c4ref )\nR \u221a2\u0398\u0302\n\u2212\u221e\n\nC=\n\n\uf8ee R\u221a\n( 2\u0398\u0302 dxk1 (x))2\n\u221a\n\u03c4m \u03bd02 \uf8f0 R\u2212\u221e\n2\u0398\u0302\n\n\u2212z 2 /2\n\n\u221a\n\n\u2212\u221e\n\ndxk0 (x)\n\n\u2212\n\nZ\n\n\u221a\n2\u0398\u0302\n\n\u2212\u221e\n\n\uf8f9\n\ndxk2 (x)\uf8fb ,\n\n(76)\n\nwhere Z0 (z) = e\n/ 2\u03c0. Finally, integrating again Ji,\u03b2 (z) over z gives the\ncontributions to the output firing rate in eq. (47). In the next section we\ncalculate the integrals appearing in the parameter C in eq. (76).\n\nC.1\n\nIntegrals\n\nHere we only present some intermediate steps and the final results for the\nintegrals appearing in C, eq. (76).\nThe last two integrals\ncan be expressed\nq\nR \u221a2t\n2\n\u03c0 t2\nt2\nin terms of the function R(t) = 2 e (1 + erf(t)) = e \u2212\u221e ds e\u2212s /2 as\n44\n\n\f1.\n\nZ\n\n\u221a\n2\u0398\u0302\n\n\u2212\u221e\n\n\u03c4m\n2.\n\nZ\n\n\u221a\n\nZ\n\n\u03c4m\n3.\n\n2\u0398\u0302\n\n2\n\n\u2212 x2\n\ndxe\n\n\u2212\u221e\n\u221a\n2\u0398\u0302\n\ndxk1 (x) =\n\n\u2212\u221e\n\nZ\n\ndxk0 (x) =\n\nZ\n\n\u221a\n\n\u221a\n2\u0124\n\n\u221a\n2\u0398\u0302\n\n\u2212\u221e\n\n2\u0398\u0302\n\ndye\n\ny2\n2\n\nZ\n\n\u221a\n\nx\n\u221a\n\n2\u0398\u0302\n\n2\u0398\u0302\n\ny2\n\ndye 2 H(y \u2212\n2\n\n\u2212 x2\n\ndxe\n\n\u2212\u221e\n\nZ\n\ndxk2 (x) =\n\nZ\n\ny\n\n2\n\u2212 x2\n\ndxe\n\n\u2212\u221e\nZ \u221a2\u0398\u0302\n\u221a\n\n2\u0124\n\n\u221a\n\n2\u0398\u0302\n\nx\n\n2\u0124) =\n\n1 \u2212 \u03bd0 \u03c4m\n.\n\u03bd0\n\ny2\n\ndye 2 k0 (x) =\n\n(y \u2212 x) = \u03c4m (R(\u0398\u0302) \u2212 R(\u0124)) .\n\ny2\n\u03c4m\ndye 2\n2\n\n\u0398\u0302\n\u0124\n\u03c4m ( \u221a R(\u0398\u0302) \u2212 \u221a R(\u0124)) .\n2\n2\n\nD\n\nZ\n\n\u221a\n\nZ\n\ny\n\n\u2212\u221e\n\nx2\n\ndxe\u2212 2 (y \u2212 x)2 =\n\nLong \u03c4c expansion using the second representation\n\nIn this section we derive the output\u221afiring rate formula (53) using the FPE\n(34). Here, we take the ratio \u03b3 \u2261 \u03b1/k to be a parameter independent of\nk, that is, it is fixed. This will allow us to study the case of large \u03b1 in the\nlong \u03c4c limit. From the FPE (34,49) we develop a systematic expansion of\nthe probability distribution P\u03b1 (x, y) and the escape probability density flux\nJ\u03b1 (y) in powers of k \u22122 (see the expansion in (50)), in which \u03b3 is considered\na fixed parameter independent of k. Inserting the expansion in eq. (50) into\nthe FPE (49) produces\n\u221a\n\u2202\n]rn + Ly rn\u22121 + \u03c4m \u03b4(x \u2212 2\u0124)J\u03b1,n (y) = 0 ,\n(77)\n\u2202x\nwhere rn \u2261 0 if n < 0. For simplicity, the set of conditions (38 - 42) is used\nhere when \u03c4ref = 0. Solving the zero-th order in eq. (77) with conditions\n(39, 41) gives\n[Lx \u2212 \u03b3y\n\n\u2212\n\nr\u03b1,0 (x, y) = \u03c4m J\u03b1,0 (y) e\n\n(x\u2212\u03b3y)2\n2\n\nZ\n\n\u221a\n2\u0398\u0302\n\nx\n\n45\n\ndu e\n\n(u\u2212\u03b3y)2\n2\n\nH(u \u2212\n\n\u221a\n\n2\u0124) ,\n\n(78)\n\n\fwhere the escape probability density flux J\u03b1,0 (y) has yet to be determined.\nThis is done by using the condition (42) with \u03c4ref = 0 at zero-th order, to\nobtain\n\"Z \u221a\n#\u22121\nZ u\n2\u0398\u0302\u2212\u03b3y\ny2\nv2\nu2\n1\nJ\u03b1,0 (y) = \u221a\ndve\u2212 2\n.\ndue 2\ne\u2212 2 \u221a\n\u2212\u221e\n2\u0124\u2212\u03b3y\n2\u03c0\u03c4m\n\n(79)\n\nRepeating the same steps as above, the n\u2212th (n > 0) order escape probability\ndensity flux is found to be\n\nJ\u03b1,n+1 (y) =\nZ\n\n\u221a\n2\u0398\u0302\n\n\"Z\n\n\u221a\n\n\u221a\n\ndxe\n\n2\u0398\u0302\u2212\u03b3y\n\ndue\n\n2\u0124\u2212\u03b3y\n\n\u2212(x\u2212\u03b3y)2\n2\n\nZ\n\nu2\n2\n\n\u221a\n2\u0398\u0302\n\nx\n\n\u2212\u221e\n\nu\n\nZ\n\n2\n\n\u2212 v2\n\ndve\n\n\u2212\u221e\n\ndve\n\n(v\u2212\u03b3y)2\n2\n\nLy\n\n#\u22121\n\nZ\n\nu\n\n\u2212\u221e\n\ndvrn (v, y) .\n\n(80)\n\nand the density rn is computed as\n\nrn (x, z) = e\n\n\u2212(x\u2212\u03b3y)2\n2\n\nZ\n\n\u221a\n\n2\u0398\u0302\n\nx\n\n\u2212\n\n+\u03c4m J\u03b1,n (y) e\n\n(x\u2212\u03b3y)2\n2\n\ndve\n\nZ\n\n\u221a\nx\n\n(v\u2212\u03b3y)2\n2\n\n2\u0398\u0302\n\nLy\n\ndu e\n\nZ\n\nu\n\u2212\u221e\n\n(u\u2212\u03b3y)2\n2\n\ndvrn\u22121(v, y)\n\nH(u \u2212\n\n\u221a\n\n2\u0124) .\n\nThe zero-th order rate is obtained by integrating over y the zero-th order\nescape probability density flux in eq. (79) This gives the firing rate in eq.\n(53). For fixed \u03b1, the parameter \u03b3 decreases as \u03c4c grows. In this limit, we\ncould expand the zero-th order firing rate in powers of \u03b3. The firing rate\nobtained from this expansion has a dominant order k \u22122 (O(\u03b3 2)). However,\nother contributions to the total firing rate at order k \u22122 could also come from\nthe non zero-th order firing rate from the expansion (50). In particular, the\nfirst order (n = 1) rate in the expansion (50) is order k \u22122 . However, it is\npossible to see that an expansion in powers of \u03b3 in the term with n = 1 in eq.\n(80) also leads to an extra dominant order k \u22122 , that multiplied by k \u22122 yields\nfinally a correction to the firing rate bigger than O(k \u22122 ). This finally proves\nthat the leading correction to the firing rate for fixed \u03b1 when \u03c4c approaches\ninfinity is order k \u22122 and it is given by the expansion of the zero-th order rate\n(53). Naturally, this expansion matches the output firing rate formula (47)\nfor positive correlation magnitudes.\n46\n\n\fE\nE.1\n\nShort \u03c4c expansion using the second representation\nThe Free Solution\n\nWe introduce an expansion of the form (55, 56) into the FPE (34) and find\nthe set of equations:\nLy f0 = 0 ,\n\u221a\nLy f1 = \u03b1yf0 ,\nLy f2 = \u2212Lx f0 +\n\n\u221a\n\u221a\n\n\u03b1yf1 \u2212 \u03c4m \u03b4(x \u2212\n\n\u221a\n\u221a\n\n(81)\n(82)\n2\u0124)\u03bdef f Z0 (y) ,\n\n(83)\n\n(84)\nLy f3 = \u2212Lx f1 + \u03b1yf2 \u2212 \u03c4m \u03b4(x \u2212 2\u0124)\u03bd1 Z0 (y) ,\n\u221a\n2\nwhere Z0 (y) = e\u2212y /2 / 2\u03c0. After solving eq. (81) we find that the only\nnormalizable solution is\nf0 (x, y) = g0 (x)Z0 (y) ,\n\n(85)\n\nwhere g0 has yet to be determined. The equation at order k gives the expression for f1\n\u221a\n\n\u2202\ng0 (x)]Z0 (y) .\n\u2202x\nAgain, g1 is unknown. The equation at second order satisfies\nf1 (x, y) = [g1 (x) \u2212\n\n\u03b1y\n\nLy f2 (x, y) = \u2212\u03b1yg1 (x)Z0 (y)\n\u221a\n\u22022\n\u2212[Lx g0 (x) + \u03b1 2 g0 (x) \u2212 \u03c4m \u03b4(x \u2212 2\u0124)\u03bdef f ]Z0 (y) .\n\u2202x\n\n(86)\n\n(87)\n\nR\n\nUsing that the integral dyLy f2 (x, y) has to equal zero in order for f2 to be\nintegrable, we can integrate eq. (87) over y and obtain the condition\n\u221a\n\u2202\n\u22022\nx + (1 + \u03b1) 2 ]g0 (x) + \u03c4m \u03bdef f \u03b4(x \u2212 2\u0124) = 0 .\n(88)\n\u2202x\n\u2202 x\nThis equation is the same as that obtained when solving the FPE for a LIF\nneuron driven by white noise input (Ricciardi, 1977), but where the variance\n[\n\n47\n\n\fof the noise has been renormalized by a factor 1 + \u03b1. This equation is solved\nexactly for all \u03b1 using the condition (39):\n\u221a\n\nZ 2\u0398\u0302\n\u221a\ny2\nx2\n\u03c4m \u03bdef f \u2212 2(1+\u03b1)\ndye 2(1+\u03b1) H(y \u2212 2\u0124) .\n(89)\ng0 (x) =\ne\n1+\u03b1\nx\nThe firing rate \u03bdef f (the zero-th order in the expansion in powers of k) is\nobtained by applying the condition (38) to f0 in eq. (85).\nSimilarly, while solving eq. (84) a condition over g1 is obtained, from\nwhere g1 is determined, except for an unknown constant D:\n2\n\nx\n\u2212 2(1+\u03b1)\n\ng1 (x) = De\n\nZ \u221a2\u0398\u0302\n\u221a\ny2\nx2\n\u03c4m \u03bd1 \u2212 2(1+\u03b1)\n+\ne\ndye 2(1+\u03b1) H(y \u2212 2\u0124) .\n1+\u03b1\nx\n\n(90)\n\nThe constant D is needed to match the boundary condition at threshold (39).\nNow it is crucial to realize that the first order solution f1 does not satisfy\nthe boundary condition at threshold (39) for any value of D. Thus, we have\nto add a boundary solution f1b so that the total solution (57) satisfies it up\nto order k. This boundary solution, found in the next section, serves to fix\nthe value for D as\n\u0398\u03022\n\nD = \u03b1 \u03bdef f \u03c4m e (1+\u03b1) .\n\n(91)\n\nUsing the normalization condition (38) on the term order k in the expansion\nof P\u03b1 (x, y), eq. (57) leads to the firing rate at order k in eq. (58) 7 . In that\nequation we have approximated \u03bdef f by \u03bd0 and also all \u03b1 appearing in eq.\n(90) have been made equal to zero. These two approximations are justified\nbecause expanding \u03bdef f and eq. (90) in powers of \u03b1 gives corrections to the\nfiring rate at order k that are higher than O(\u03b1).\n\nE.2\n\nThe Boundary Solution\n\nHere we find the boundary solution, f1b , for the FPE (34) valid close to\nthreshold and for small k. The FPE in this limit takes the form\n\"\n\n\u221a \u2202\n\u22022\n\u22022\n\u2202\n\u2212 \u03b1y\n+ 2 \u2212y\n+ O(k, k 2 ) u(r, y) = 0 .\n2\n\u2202r\n\u2202r \u2202y\n\u2202y\n#\n\n(92)\n\nRR\nNotice below that\nu(r, z) = O(k), and for this reason we can neglect its contribution to the rate at order k.\n7\n\n48\n\n\fb\nWe have replaced f\u221a\n1 (x, y) = u(r, y)Z0(y) and we have made the linear transformation r = (x\u2212 2\u0398\u0302)/k.\n\u221a A complete basis for this linear differential operator is not known, but if \u03b1 = 0 a complete basis for an integrable\nfunction\n\u221a\n\u221a\nof r \u2208 [\u2212\u221e, 0], y \u2208 [\u2212\u221e, \u221e] is given by the set of functions e nr Hn (y/ 2)\nfor all n > 0, where Hn are the Hermite polynomials 8 . We insert into eq.\n\u221a\n(92) a solution u of the form u = u0 + \u03b1u1 + \u03b1u2 + O(\u03b13/2 ) to obtain\n\n\"\n\n\u2202\n\u22022\n\u2202\n\u22022\nui+1 (r, y) = y ui (r, y) .\n+\n\u2212y\n2\n2\n\u2202r\n\u2202y\n\u2202y\n\u2202r\n#\n\n(94)\n\nThe solution f1b has to be added to the perturbative solution f1 , eq (86), to\nmatch the boundary condition (39), that is\n\u221a\n\n\u2202\n(95)\ng0 | \u221a + u(0, y) = 0 .\n\u2202x x= 2\u0398\u0302\n\u221a\n\u221a\n\u0398\u03022\nDefining d = De\u2212 1+\u03b1 and expanding it in powers of \u03b1 as d = d0 + \u03b1d1 +\n\u03b1d2 + O(\u03b13/2 ), as well as the others terms in eq. (95), we obtain the set of\nconditions\n\u0398\u03022\n\nDe\u2212 1+\u03b1 \u2212\n\n\u03b1y\n\nd0 + u0 (0, y) = 0 ,\nd1 + \u03bdef f \u03c4m y + u1 (0, y) = 0 ,\nd2 + u2 (0, y) = 0 .\n\u221a\n\u221a\nNow we express each order ui as a linear combination\nof the \u221a\nfunctions e nr Hn (y/ 2)\n\u221a\nP\nnr\nplus a particular solution as ui (r, y) = \u221e\nHn (y/ 2) + ui,part (r, y).\n1 An,i e\nWe find\n\nu0 = 0 , d0 = 0\nu1 = \u2212\u03bdef f \u03c4m yer ,\n\nd1 = 0\n\u221a\n\nu2 = \u2212\u03bdef f \u03c4m [y 2 \u2212 1]e\n8\n\n2r\n\n+ \u03bdef f \u03c4m [y 2 \u2212 2]er ,\n\nThe Hermite polynomials satisfy the equation\n\u0012\n\u0013\n\u0012 2\n\u0012\n\u0013\n\u0013\ny\n\u2202\n\u2202\ny\n\u221a\n\u221a\nH\n\u2212\ny\n=\n\u2212n\nH\n.\nn\nn\n\u2202y 2\n\u2202y\n2\n2\n\nd2 = \u03bdef f \u03c4m .\n\n(93)\n\nThe first three polynomials H0 (y) = 1, H1 (y) = 2y and H2 (y) = 4y 2 \u2212 2 are used in our\ncalculations.\n\n49\n\n\fWith these solutions, we finally found the value of D up to order \u03b1, eq. (91).\n\nF\n\nShort \u03c4c limit for a generic IF neuron.\n\nIn this section we extend the formalism described in Appendix E to calculate\nthe firing rate of a generic IF neuron receiving a Gaussian exponentially\ncorrelated input in the short \u03c4c limit (Moreno and Parga, 2002). A generic\nIF neuron can be defined by the leak function, f (V ), that determines how the\nvoltage behaves in absence of any input. In this model, the depolarization\nmembrane potential V (t) evolves from the reset voltage H according to the\nstochastic equation\nV\u0307 (t) = \u2212f (V ) + I(t) ,\n\n(96)\n\nwhere I(t) is the synaptic current with exponentially temporal correlations\nas in eq. (17). When the Gaussian current is expressed using the second\nrepresentation, as it is defined in Section (4.2), the FPE associated to this\nmodel neuron is\n\uf8ee\n\n\u2202\n\u03c32 \u2202\n1 \u2202\n\u2202\n\uf8f0\n(f (V ) \u2212 \u03bc + w\n)+\n(y +\n)\u2212\n\u2202V\n2 \u2202V\n\u03c4c \u2202y\n\u2202y\n\n\uf8f9\n\ns\n\n2\u03c3w2 \u03b1 \u2202 \uf8fb\nP = \u2212\u03b4(V \u2212H)J(y) .\n\u03c4c \u2202V\n(97)\nUsing the same procedure as in Appendix E, we find that the output firing\nrate of such a generic neuron is\n\u221a\n\u03bdout = \u03bdef f + \u03bd1 \u03c4c\n\n(98)\n\nwhere\n\n\u22121\n\u03bdef\nf\n\n2\n\nZ\n\n\u0398\n\n2\n\u03c32\nef f\n\nRu\n\u0398\n\ndr(f (r)\u2212\u03bc)\n\n= \u03c4ref + 2\ndue\n\u03c3ef f H\n\u221a\nRv\nZ\n2\u03b1\u03bd02 \u0398\ndr(f (r)\u2212\u03bc)\n\u2212 2\n\u03bd1 = \u2212\n,\ndve \u03c3w2 \u0398\n\u03c3w\n\u2212\u221e\n\nZ\n\nu\n\n\u2212\u221e\n\n\u2212\n\ndve\n\n2\n\u03c32\nef f\n\nRv\n\u0398\n\ndr(f (r)\u2212\u03bc)\n\n(99)\n\nwhich is valid whenever the above integrals are defined. This general formula,\nthat has been previously found in our work (Moreno and Parga, 2002), shows\n\u221a\nthat the \u03c4c decay of the firing rate is universal for IF models with hard\n50\n\n\fthreshold. Using this general formula it is possible to obtain the firing rate\nin the short \u03c4c limit given by eq. (58) for a LIF neuron.\nUsing a different procedure we have been able to calculate exactly the\nfiring rate of a non-leaky IF neuron (f (V ) = 0) with exponential correlations\nwithout the need of the boundary solution to fit the boundary condition at\nthreshold. This formula is valid for all \u03c4c and for small \u03b1. We still require\nthe condition \u03c4c \u226a \u03c4ref . This exact formula, however, allows us to check the\ntechnical procedure described above, and it naturally gives the same result.\nThis firing rate is expressed as\n\u03bdout = \u03bdef f \u2212\n\n\u03b1\u03bd02 [1 \u2212 e(\u03b3\u2212\u03bb)(\u0398\u2212H) ]\n+ O(\u03b12)\n\u03bc(\u03b3 + \u03bb)\n\n(100)\n\nq\n\nwhere \u03b3 = \u03c3\u03bc2 , \u03bb = \u03b3 2 + \u03c322\u03c4c and \u03bdef f is defined below, eq.(101). An\nw\nw\n\u221a\nexpansion of eq. (100) for small \u03c4c leads to the same universal \u03c4c decay\nlaw, and the coefficients are identical to those produced by eqs. (99):\n\u0398\u2212H\n\u03bc\n2\n\u03b1\u03bd \u03c3w\n.\n= \u2212 \u221a0\n2\u03bc\n\n\u22121\n\u03bdef\nf = \u03c4ref +\n\n\u03bd1\n\n51\n\n(101)\n\n\fCross-correlation\n\nTotal Current\n\nIF neuron\n\nResponse ?\n\nAuto-correlation\n(delta included)\n\nN connections\n\nFigure 1:\nCaption 1: Illustration of the problem studied in this paper (a fully\ndetailed description is given in the text). A set of afferent presynaptic\nspike trains impinges on a LIF neuron. Each individual spike train has\nexponentially-shaped auto-correlations, describing the joint probability density of having two spikes separated by a particular time lag (a delta function\nshould be included at zero time lag because the train is made of point events;\nsee text). A fraction of the trains also have exponential cross-correlations,\ndescribing non-independent firing of some of the presynaptic neurons. The\ntotal current generated by the presynaptic bombardment is replaced by a\nGaussian process with the same mean and two-point correlation function\nthan that generated by the superposition of all presynaptic spike trains. The\ngoal is to characterize the spiking response properties of the LIF neuron as\na function of the global magnitude and timescale of the input correlations.\n\n52\n\n\fAUTO-CORRELATION FUNCTION\nA\n\nB\n\ntime\n\nt'\n\nt\n\nCp( |t-t'| ) =\n\ndelta\n\nArea = Fp\u03bdp\n\nheigth =\n\n\u03bdp (Fp -1) / 2\u03c4c\ntime lag = |t-t'|\n\n0\nwidth:\n\n\u03c4c , correlation time scale\n\nFp\u03bdp\n\nC\n2\n(T) / T\nN,p\n\n\u03c3\n\n\u03bdp\nT\nPoisson limit for T << \u03c4c\n\nFigure 2:\n\n53\n\n\fCROSS-CORRELATION FUNCTION\nspike train from\npopulation p\n\nA\n\ntime\n\nt\n\nspike train from\npopulation q\n\nB\n\nt'\n\ntime\n\nCpq( |t-t'| ) =\n\nArea =(\u03bdp\u03bdq )1/2\n\nheigth =\nArea\n\n/ 2\u03c4c\n\n\u03c1pq(FpFq)1/2\n\ntime lag = |t-t'|\n\n0\nwidth:\n\n\u03c4c , correlation time scale\n\nC\n(\u03bdp\u03bdq )1/2 \u03c1pq(FpFq)1/2\n<N'p(T) N'q (T) > / T\n0\n\nT\nUncorrelated trains limit for T << \u03c4c\n\nFigure 3:\n\n54\n\n\f\u03c1II\nfIENI\n\nNI\n\nfIINI\n\n\u03c1IE\n\ntarget\nneuron\n\n\u03c1EI\nfEINE\nfEENE\n\nNE\n\n\u03c1EE\nFigure 4:\n\nCross Correlation (Hz)\n\n300\n\n40\n\n200\n0\n\n100\n-40\n\n0\n\n-100\n\n0\n\n-50\n\n100\n\nTime lag (ms)\n\n0\n\nTime lag (ms)\n\nFigure 5:\n\n55\n\n50\n\n\f20\n\n\u03bdout (Hz)\n\nPositive correlations (\u03b1>0)\n\n\u03b1=0\n\n10\n\nNegative correlations (\u03b1<0)\n\n0\n\n20\n\n40\n\n\u03c4c (ms)\nFigure 6:\n\n25\n\n40\n\n24\n\n\u03bdout (Hz)\n\n30\n23\n20\n22\n\n10\n\n0\n\n21\n20\n\n40\n\n60\n\n80\n\n100\n\n0\n\n100\n\n200\n\n\u03c4c (ms)\n\n\u03c4c (ms)\n\nFigure 7:\n56\n\n300\n\n\ftcross(ms)\n\n4\n\n20\n\n\u03bdout(Hz)\n\n15\n\n3\n2\n1\n0\n\n1\n\n10\n100\n\u03c4c(ms)\n\n1000\n\n10\n\n\u03c4c = 0ms\n\u03c4c = 5ms\n\u03c4c=100ms\n\n5\n0\n\n10\n\n20\n\ntime (ms)\nFigure 8:\n\n57\n\n30\n\n40\n\n\fCaption 2: (A): An individual afferent spike train from population p could\nshow correlations between two times, t and t': the probability of finding a\nspike at one of those times depends on the existence of a spike at the other\ntime. (B): This temporal correlation is described by the auto-correlation\nfunction, Cp (t \u2212 t\u2032 ), assumed to have an exponential shape. The firing rate,\n\u03bdp , Fano factor, Fp , and correlation time, \u03c4c , enters in the definition of the\nshape and size of the exponential as described in the plot. The delta function\npresent at zero time is proportional to \u03bdp , and participates in the total area\nof the autocorrelogram. (C): When the spike count of the spike train is\nintegrated over a time window T , the variance of the count divided by T goes\nexponentially from \u03bdp to FN,p \u03bdp . For small time windows, the count variance\nconverges to that of a Poisson spike train, which is equal to \u03bdp T . However,\nfor longer time windows than the correlation time \u03c4c , the count variance\nscales as FN,p \u03bdp , indicating that then the effect of temporal correlations is\nfully visible.\n\n58\n\n\fCaption 3: (A): The probability of having a spike at time t in an afferent\nspike train belonging to population p could depend on the existence of having\na spike at time t\u2032 on other spike train from population q. (B). This correlation\nis described by the cross-correlation function, Cpq (t \u2212 t\u2032 ), assumed to have\nexponential shape. The firing rates, Fano factors, correlation coefficient of\nthe spike counts, \u03c1pq , and correlation time, \u03c4c , determine the shape of the\nexponential, as illustrated in the figure. (C): When the spike counts of the\nspike trains in the top panel are integrated over a time window T , their\ncovariance divided by T increases exponentially from zero to a finite value\nproportional to the correlation coefficient (here we define N \u2032 (T ) = N(T ) \u2212\nhN(T )i). For short time windows, the covariance is zero and therefore it\nresembles that of two independent spike trains. However, for time windows\nlonger than \u03c4c , correlations are fully visible and the covariance is non-zero.\n\n59\n\n\fCaption 4: Diagram of correlations in excitatory (E) and inhibitory (I)\nneuronal populations presynaptic to the same target neuron. The presynaptic\nE and I populations make NE and NI contacts respectively with the target\nneuron. A fraction fEE(II) of these NE(I) excitatory (inhibitory) neurons are\ncorrelated with each other with a correlation coefficient \u03c1EE(II) . Also there\nare E\u2212I correlations, with a fraction fEI participating from the E population\nand a fraction fIE from the I population, for which the correlation coefficient\nis \u03c1EI (= \u03c1IE ). Since all E neurons in the fraction fEI are correlated with\nany given I neuron in the fraction fIE , these E neurons necessarily have\nE \u2212 E correlations. Therefore, they are considered here to be a group within\nthe fraction fEE , as shown in the figure. The same applies for the I neurons.\n\n60\n\n\fCaption 5: Normalized correlation functions of the current I(t) numerically generated by simulating the process defined in eqs. (22 - 23). The\nnormalized correlation function of the current is defined as \u0108current(s) =\nCcurrent(s)/\u03c3w2 \u2212 \u03b4(s), where Ccurrent(s) is defined in eq. (26). The variable s\nis the time lag s = t \u2212 t\u2032 . With this normalization, the correlation function\nhas units of Hz. For positive correlations (left) we took \u03b2 = 2, which yields\na correlation magnitude \u03b1 = 8; \u03c4c = 15ms. For negative correlations (right)\nwe took \u03b2 = \u22120.5, which corresponds to \u03b1 = \u22120.75; here \u03c4c = 5ms. In\nboth cases, numerical results are compared with the exponential functions\npredicted by eq. (26) (non-fluctuating curves).\n\n61\n\n\fCaption 6: Theoretical predictions (lines) and simulation results (points)\nfor the output firing rate of a LIF neuron driven by exponentially correlated\ninputs as a function of the correlation timescale. Here we use eq. (61) for\nshort \u03c4c and eq. (62) for long \u03c4c , along with a continuous and smooth interpolation between the two limits (the interpolation is made at an intermediate\n\u03c4c,inter \u223c \u03c4m ). The rate decreases when the input correlations are positive\n(\u03b1 > 0, upper curve) and increases when correlations are negative (\u03b1 < 0,\nlower curve). When there are no correlations (\u03b1 = 0), the neuron fires at a\nrate of 10Hz (dashed-dotted line). Maximum rate differences relative to the\nrate with no input correlations are attained when \u03c4c = 0, that is, when the\ninput correlation is exquisitely precise. Differences are substantial whenever\nthe correlation time is shorter than the membrane time constant of the neuron (\u03c4m = 20ms for this case; shaded region). When the correlation time\nbecomes longer than \u03c4m , relative changes are much smaller, and the neuron\nbecomes less sensitive to the input correlations. Correlation magnitudes are\n\u03b1 = 8 (upper curve) and \u03b1 = \u22120.75 (lower curve), and interpolations between the short and long \u03c4c theoretical predictions were performed at the\ninterpolating time \u03c4c,inter = 40ms and 20ms respectively. Other parameters\nare \u03c4ref = 0ms, \u0398 = 1 (in arbitrary units), H = 0, \u03bc = 42s\u22121 , \u03c3w2 = 2s\u22121 .\nAlthough the short \u03c4c expansion requires \u03c4ref 6= 0 the simulation shows that\nthis prediction is good even for zero \u03c4ref .\n\n62\n\n\fCaption 7: Theoretical predictions and simulation results for the firing\nrate of a LIF neuron as function of the correlation timescale for the sub- (left)\nand the suprathreshold regimes (right). Here we use eqs. (47,53), valid for\nlong \u03c4c . For the subthreshold regime, the effect of increasing the correlation\ntime is always to decrease the rate. However, for the suprathreshold regime\nand when the input noise is small, the effect is the opposite for long \u03c4c . As the\ninput noise increases, this effect disappears and the curve becomes as in the\nsubthreshold regime (data not shown). The theoretical predictions (full lines)\nare obtained using the firing rate given in eq. (53) without any interpolation,\nand the discrete points are the simulation results with the same parameters\nas in the theoretical curves. Parameters for the subthreshold regime are:\n\u03bc = 0Hz, \u03c3w2 = 50.5Hz, and \u03b1 = 4 (top full line and squares), \u03b1 = 1\n(bottom full line and circles) and \u03b1 = 0 (straight line). The dotted line has\nthe same parameters as the top full line, but it has been obtained from the\nexpression of the rate in eq. (47). Notice that the prediction from eq. (53),\nstrictly only valid for long \u03c4c , is also good even when \u03c4c \u223c \u03c4m , and it is better\nthan that provided by eq. (47) for all \u03c4c . Parameters for the suprathreshold\nregime are: \u03bc = 100.7Hz, \u03c3w2 = 0.05Hz, and a very large correlation strength\n\u03b1 = 36 (bottom line and triangles), a moderate correlation strength \u03b1 =\n9 (intermediate line and diamonds) and \u03b1 = 0 (straight line). The other\nparameters are as in Fig. (6), except for \u03c4m = 10ms.\n\n63\n\n\fCaption 8: Averaged transient firing responses of a LIF neuron to changes\nin the input statistics. Below t = 0 the input is white noise (\u03b1 = 0) with\n\u03bc = 16s\u22121 and \u03c3w2 = 0.81s\u22121 . Upper curve: instantaneous response when\n\u03c3w2 is increased up to \u03c3w2 = 3.8s\u22121 . Second (third) curve: quick response to\ncorrelation changes, with \u03c4c = 5ms (100ms) and \u03b1 = 6.8 (52.3). Bottom\ncurve: slow response when \u03bc is changed from \u03bc = 16s\u22121 to \u03bc = 19.9s\u22121 and\n\u03c3w2 is kept constant. These values were chosen so that the evoked firing rates\nin the final steady state are roughly the same (\u223c 8Hz, straight line). Inset:\ntime when the firing rate response reaches for the first time the value of the\nfinal stationary rate as a function of \u03c4c . When the correlation timescale is\nvery short, tcross is very small, and it saturates for long \u03c4c . Neuron parameters\nare \u03c4m = 50ms, \u03c4ref = 0 ,\u0398 = 1 and H = 0 (dimensionless).\n\n64\n\n\fReferences\nM. Abeles. Role of the cortical neuron: integrator or coincidence detector.\nIsr. J. Med. Sci., 18:83\u201392, 1982.\nM. Abeles. Corticonics. Neural circuits of the cerebral cortex. Cambridge\nUP, Cambridge UK, 1991.\nA. Aersten, M. Gerstein, G. Habib, and G. Palm. Dynamics of neuronal firing\ncorrelation: modulation of \"effective connectivity\". J. Neurophysiol., 61:\n900\u2013917, 1989.\nT. D. Albright. Cortical processing of visual motion. In: Visual motion and\nits role in the stabilization of gaze. (Miles F. A., Wallman J., eds.), pag\n177-201, New York: Elsevier., 1993.\nA. Amarasingham, T. Chen, S. Geman, M. T. Harrison, D. L. Sheinberg\nSpike Count Reliability and the Poisson Hypothesis. J. of Neurosci,, 26(3):\n801\u2013809, 2006.\nD. J. Amit and N. Brunel. Dynamics of a recurrent network of spiking\nneurons before and following learning. Network, 8:373, 1997a.\nD. J. Amit and N. Brunel. Model of global spontaneous activity and local\nstructured activity during delay periods in the cerebral cortex. Cereb.\nCortex, 7:237\u201352, 1997b.\nB. B. Averbeck and D. Lee. Coding and transmission of information by\nneural ensembles. Trends in Neuroscience, 27(4):225\u201330, 2004.\nW. Bair, E. Zohary, and W. T. Newsome. Correlated firing in macaque visual\narea mt: Time scales and relationship to behavior. J. of Neurosci,, 21(5):\n1676\u201397, 2001.\nO. Bernander, R. J. Douglas, K. A. Martin, and C. Koch. Synaptic background activity influences spatiotemporal integration in single pyramidal\ncells. Proc. Natl. Acad. Sci. USA, 88:11569\u201311573, 1991.\nV. Braitenberg and A. Sch\u00fcz. Anatomy of the Cortex: Statistics and Geometry. Springer Verlag, Berlin, 1991.\n\n65\n\n\fN. Brunel and S. Sergi. Firing frequency of leaky integrate-and-fire neurons\nwith synaptic current dynamics. J. Theor. Biol., 195:87\u201395, 1998.\nA. N. Burkitt and G. M. Clark. Analysis of integrate-and-fire neurons: synchronization of synaptic input and spike output. Neural Comput., 11:\n871\u2013901, 1999.\nH. Cateau and A. Reyes. Relation between single neuron and population\nspiking statistics and effects on network activity. Phys. Rev. Lett., 96:\n058101, 2006.\nA. Compte, C. Constantinidis, J. Tegner, S. Raghavachari, M. V. Chafee,\nP. S. Goldman-Rakic, and X.-J. Wang. Temporally irregular mnemonic\npersistent activity in prefrontal neurons of monkeys during a delayed response task. J Neurophysiol, 90:3441\u20133454, 2003.\nB. G. Cragg. The density of synapses and neurones in the motor and visual\nareas of the cerebral areas. J. Anat., 101:639\u2013654, 1967.\nD. J. Daley and D. Vere-Jones. An introduction to the theory of point processes. Springer, New York, 1988.\nA. F. Dean. The variability of discharge of simple cells in cat striate cortex.\nExp. Brain Res., 44:437\u2013440, 1981.\nR. C. deCharms and M. M. Merzenich. Primary cortical representation of\nsounds by the coordination of action potentials. Nature, 381:610\u2013613, 1996.\nJ. DeFelipe and I. Fari\u00f1as. The pyramidal neuron of the cerebral cortex:\nmorphological and chemical characteristics of the synaptic inputs. Prog.\nNeurobiol., 39:563\u2013607, 1992.\nC. R. Doering, P. S. Hagan, and C. D. Levermore. Bistability driven by\nweakly colored gaussian noise: the fokker-planck equation boundary layer\nand mean first-passage times. Physical Review Letters, 59 (19):2129\u20132132,\n1987.\nB. Doiron, J. Rinzel, and A. Reyes. Stochastic synchronization in finite size\nspiking networks. Physical Review E, 74:030903, 2006.\nJ. Feng and D. Brown. Impact of correlated inputs on the output of the\nintegrate-and-fire model. Neural Computation, 12:671\u2013692, 2000.\n66\n\n\fP. Fries, P. R. Roelfsema, A. K. Engel, P. Konig, and W. Singer. Synchronization of oscillatory responses in visual cortex correlates with perception\nin interocular rivalry. Proc. Natl. Acad. Sci, 94:12699\u2013704, 1997.\nP. Fries, J. H. Reynolds, A. E. Rorie, and R. Desimone. Modulation of\noscillatory neuronal synchronization by selective visual attention. Science,\n291:1560\u20131563, 2001.\nP. M. Gochin, E. K. Miller, C. G. Gross, and G. L. Gerstein. Functional interactions among neurons in inferior temporal cortex of the awake macaque.\nExp. Brain Res., 84:505\u2013516, 1991.\nA. Kuhn, A. Aertsen, and S. Rotter. Higher-order statistics of input ensembles and the response of simple models neurons. Neural Computation, 15:\n67\u2013101, 2003.\nG. LaCamera, A. Rauch, H.-R. Luscher, W. Senn, and S. Fusi. Minimal\nmodels of adapted neuronal response to in vivolike input currents. Neural\nComputation, 16:2101\u20132124, 2004.\nG. Laurent. Odor encoding as an active, dynamical process: experiments,\ncomputation and theory. Ann. Rev. Neurosci., 24:263\u2013297, 2001.\nD. Lee, N. L. Port, W. Kruse1, and A. P. Georgopoulos. Variability and\ncorrelated noise in the discharge of neurons in motor and parietal areas of\nthe primate cortex. The Journal of Neuroscience, 18(3):1161\u201370, 1998.\nA. Lerchner, C. Ursta, J. Hertz, M. Ahmadi, P. Ruffiot, and S. Enemark.\nResponse variability in balanced cortical networks. Neural Computation,\n18:634\u2013659, 2006.\nB. Lindner. Superposition of many independent spike trains is generally not\na poisson process. Phys. Rev. E, 73(2):022901, 2006.\nB. Lindner, B. Doiron, and A. Longtin. Theory of oscillatory firing induced\nby spatially correlated noise and delayed feedback. Physical Review E, 72:\n061919, 2005.\nN. Masuda. Simultaneous rate-synchrony codes in populations of spiking\nneurons. Neural Computation, 18:45\u201359, 2006.\n\n67\n\n\fR. Moreno and N. Parga. Firing rate for a generic integrate-and-fire neuron\nwith exponentially correlated input. 223-8, In Lecture notes in computer\nscience. Ed. J.R. Dorronsoro. Springer Verlag, 2002.\nR. Moreno, J. de la Rocha, A. Renart, and N. Parga. Response of spiking\nneurons to correlated inputs. Physical Review Letters, 89 (28):288101,\n2002.\nR. Moreno-Bote and N. Parga. Role of synaptic filtering on the firing response\nof simple model neurons. Physical Review Letters, 92(2):028102, 2004.\nR. Moreno-Bote and N. Parga. Membrame potential and response properties\nof populations of cortical neurons in the high conductance state. Physical\nReview Letters, 94:088103, 2005.\nR. Moreno-Bote and N. Parga. Auto- and crosscorrelograms for the spike\nresponse of leaky integrate-and-fire neurons with slow synapses. Physical\nReview Letters, 96:028101, 2006.\nL. G. Nowak, M. H. J. Munk, A. C. James, P. Girard, and J. Bullier. Crosscorrelation study of the temporal interactions between areas v1 and v2 of\nthe macaque monkey. J. Neurophysiol., 81:1057\u201374, 1999.\nD. Nykamp and D. Tranchina. A population density approach that facilitates large-scale modeling of neural networks: extension to slow inhibitory\nsynapses. Neural Computation, 13:511\u2013546, 2001.\nD. H. Perkel, G. L. Gerstein, and G. P. Moore. Neuronal spike trains and\nstochastic point processes. ii. simulataneous spike trains. Biophys. J., 7:\n419\u2013440, 1967.\nA. Renart, R. Moreno, J. de la Rocha, E. Rolls, and N. Parga. A model\nof the it-pf network in object working memory which includes balanced\npersistent activity and tuned inhibition. Neurocomputing, 28:1525\u20131531,\n2001.\nA. Renart, N. Brunel, and X. J. Wang. Mean-field theory of recurrent cortical networks: From irregularly spiking neurons to working memory. In\nJ. Feng (Ed.), Computational neuroscience: A comprehensive approach.\nCRC Press, Boca Raton, FL, 2003.\n68\n\n\fA. Renart, R. Moreno-Bote, X.-J. Wang, and N. Parga. Mean-driven and\nfluctuation-driven persistent activity in recurrent networks. Neural Computation, 19:1\u201346, 2007.\nL. M. Ricciardi. Diffusion processes and related topics in biology. SpringerVerlag, Berlin, 1977.\nM. Richardson and W. Gerstner. Synaptic shot noise and conductance fluctuations affect the membrane voltage with equal significance. Neural Computation, 17:923\u2013947, 2005.\nA. Riehle, S. Grun, M. Diesmann, and A. Aertsen. Spike synchronization and\nrate modulation differentially involved in motor cortical function. Science,\n278:1950\u20131953, 1997.\nH. Risken. The Fokker-Planck equation. 2nd Ed. Springer-Verlag, Berlin,\n1989.\nE. T. Rolls and A. Treves. Neural networks and brain function. Oxford\nUniversity Press, Oxford, U.K., 1998.\nM. Rudolph and A. Destexhe. Correlation detection and resonance in neural\nsystems with distributed noise sources. Phyical Review Letters, 86(16):\n3662\u20134, 2001.\nE. Salinas and T. J. Sejnowski. Impact of correlated synaptic input on output\nfiring rate and variability in simple neuronal models. J. Neurosci., 20:\n6193\u20136209, 2000.\nE. Salinas and T. J. Sejnowski. Correlated neuronal activity and the flow of\nneural information. Nature Reviews Neuroscience, 2:539\u2013550, 2001.\nM. N. Shadlen and W. T. Newsome. The variable discharge of cortical neurons: implications for connectivity, computation, and information coding.\nJ. Neurosci., 18:3870\u20133896, 1998.\nG. Silberberg, M. Bethge, H. Markram, K. Pawelzik, and M. Tsodyks. Dynamics of population rate codes in ensembles of neocortical neurons. Journal of Neurophysiology, 91:704\u2013709, 2004.\nW. Softky. Submillisecond coincidence detection in active dendritic trees.\nNeuroscience, 58:13\u201341, 1994.\n69\n\n\fW. Softky and C. Koch. The highly irregular firing of cortical cells is incosistent with temporal integration of random epsp's. J. Neurosci., 13:334\u2013350,\n1993.\nP. N. Steinmetz, A. Roy, P. J. Fitzgerald, S. S. Hsiao, K. O. Johnson, and\nE. Niebur. Attention modulates synchronized neuronal firing in primate\nsomatosensory cortex. Nature, 404:187\u2013190, 2000.\nC. F. Stevens and A. M. Zador. Input synchrony and the irregular firing of\ncortical neurons. Nature Neurosci., 1(3):210\u2013217, 1998.\nD. Y. Ts'o, C. D. Gilbert, and T. N. Wiesel. Relationships between horizontal\ninteractions and functional architecture in cat striate cortex as reveales by\ncross-correlations analysis. J. Neuroscie., 6:1160\u20131170, 1986.\nH. C. Tuckwell. Introduction to theoretical neuroscience. Vol. 1 and 2. Cambridge UP, Cambridge UK, 1988.\nW. M. Usrey and R. C. Reid. Synchronous activity in the visual system.\nAnnu. Rev. Physiol., 61:435\u201356, 1999.\nE. Vaadia, I. Haalman, M. Abeles, H. Bergman, Y. Prut, H. Slovin, and\nA. Aertsen. Dynamics of neuronal interactions in monkey cortex in relation\nto behavioural events. Nature, 373:515\u2013518, 1995.\nM. Wehr and G. Laurent. Relationship between afferent and central temporal\npatterns in the locust olfatory system. J. Neurosci., 19:381\u2013390, 1999.\nE. L. White. Cortical circuits. Birkauser, 1989.\nE. Zohary, M. N. Shadlen, and W. T. Newsome. Correlated neuronal discharge rate and its implication for psychophysical performance. Nature,\n370:140\u2013143, 1994.\n\n70\n\n\f"}