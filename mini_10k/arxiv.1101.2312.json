{"id": "http://arxiv.org/abs/1101.2312v1", "guidislink": true, "updated": "2011-01-12T10:16:11Z", "updated_parsed": [2011, 1, 12, 10, 16, 11, 2, 12, 0], "published": "2011-01-12T10:16:11Z", "published_parsed": [2011, 1, 12, 10, 16, 11, 2, 12, 0], "title": "Automatic segmentation of HeLa cell images", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1101.3306%2C1101.4883%2C1101.3260%2C1101.1002%2C1101.2346%2C1101.1503%2C1101.0971%2C1101.3609%2C1101.2176%2C1101.2621%2C1101.2426%2C1101.0131%2C1101.4532%2C1101.4933%2C1101.2312%2C1101.3259%2C1101.2121%2C1101.3836%2C1101.1209%2C1101.1975%2C1101.2158%2C1101.1484%2C1101.5865%2C1101.5566%2C1101.5197%2C1101.4596%2C1101.5255%2C1101.4022%2C1101.1271%2C1101.5797%2C1101.4135%2C1101.5477%2C1101.2168%2C1101.2469%2C1101.0711%2C1101.5441%2C1101.0201%2C1101.5302%2C1101.0195%2C1101.0646%2C1101.0462%2C1101.1532%2C1101.0473%2C1101.2563%2C1101.2894%2C1101.5821%2C1101.2566%2C1101.1390%2C1101.5708%2C1101.4100%2C1101.0627%2C1101.0634%2C1101.2973%2C1101.2872%2C1101.1177%2C1101.1474%2C1101.0040%2C1101.0314%2C1101.2078%2C1101.4941%2C1101.5044%2C1101.1630%2C1101.1430%2C1101.0768%2C1101.0640%2C1101.1358%2C1101.0023%2C1101.2359%2C1101.5281%2C1101.3043%2C1101.4928%2C1101.0048%2C1101.4765%2C1101.2234%2C1101.5183%2C1101.1487%2C1101.0532%2C1101.0790%2C1101.0116%2C1101.2697%2C1101.2014%2C1101.3012%2C1101.0269%2C1101.1237%2C1101.2236%2C1101.3698%2C1101.2518%2C1101.2800%2C1101.4556%2C1101.2496%2C1101.0363%2C1101.2174%2C1101.5650%2C1101.0125%2C1101.2821%2C1101.1717%2C1101.0609%2C1101.1622%2C1101.3742%2C1101.2948%2C1101.0934&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Automatic segmentation of HeLa cell images"}, "summary": "In this work, the possibilities for segmentation of cells from their\nbackground and each other in digital image were tested, combined and improoved.\nLot of images with young, adult and mixture cells were able to prove the\nquality of described algorithms. Proper segmentation is one of the main task of\nimage analysis and steps order differ from work to work, depending on input\nimages. Reply for biologicaly given question was looking for in this work,\nincluding filtration, details emphasizing, segmentation and sphericity\ncomputing. Order of algorithms and way to searching for them was also\ndescribed. Some questions and ideas for further work were mentioned in the\nconclusion part.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1101.3306%2C1101.4883%2C1101.3260%2C1101.1002%2C1101.2346%2C1101.1503%2C1101.0971%2C1101.3609%2C1101.2176%2C1101.2621%2C1101.2426%2C1101.0131%2C1101.4532%2C1101.4933%2C1101.2312%2C1101.3259%2C1101.2121%2C1101.3836%2C1101.1209%2C1101.1975%2C1101.2158%2C1101.1484%2C1101.5865%2C1101.5566%2C1101.5197%2C1101.4596%2C1101.5255%2C1101.4022%2C1101.1271%2C1101.5797%2C1101.4135%2C1101.5477%2C1101.2168%2C1101.2469%2C1101.0711%2C1101.5441%2C1101.0201%2C1101.5302%2C1101.0195%2C1101.0646%2C1101.0462%2C1101.1532%2C1101.0473%2C1101.2563%2C1101.2894%2C1101.5821%2C1101.2566%2C1101.1390%2C1101.5708%2C1101.4100%2C1101.0627%2C1101.0634%2C1101.2973%2C1101.2872%2C1101.1177%2C1101.1474%2C1101.0040%2C1101.0314%2C1101.2078%2C1101.4941%2C1101.5044%2C1101.1630%2C1101.1430%2C1101.0768%2C1101.0640%2C1101.1358%2C1101.0023%2C1101.2359%2C1101.5281%2C1101.3043%2C1101.4928%2C1101.0048%2C1101.4765%2C1101.2234%2C1101.5183%2C1101.1487%2C1101.0532%2C1101.0790%2C1101.0116%2C1101.2697%2C1101.2014%2C1101.3012%2C1101.0269%2C1101.1237%2C1101.2236%2C1101.3698%2C1101.2518%2C1101.2800%2C1101.4556%2C1101.2496%2C1101.0363%2C1101.2174%2C1101.5650%2C1101.0125%2C1101.2821%2C1101.1717%2C1101.0609%2C1101.1622%2C1101.3742%2C1101.2948%2C1101.0934&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this work, the possibilities for segmentation of cells from their\nbackground and each other in digital image were tested, combined and improoved.\nLot of images with young, adult and mixture cells were able to prove the\nquality of described algorithms. Proper segmentation is one of the main task of\nimage analysis and steps order differ from work to work, depending on input\nimages. Reply for biologicaly given question was looking for in this work,\nincluding filtration, details emphasizing, segmentation and sphericity\ncomputing. Order of algorithms and way to searching for them was also\ndescribed. Some questions and ideas for further work were mentioned in the\nconclusion part."}, "authors": ["Jan Urban"], "author_detail": {"name": "Jan Urban"}, "author": "Jan Urban", "links": [{"href": "http://arxiv.org/abs/1101.2312v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1101.2312v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1101.2312v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1101.2312v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Automatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\nAbstract\nIn this work, the possibilities for segmentation of cells from their background and each other\nin digital image were tested, combined and improoved. Lot of images with young, adult and\nmixture cells were able to prove the quality of described algorithms. Proper segmentation is one of\nthe main task of image analysis and steps order differ from work to work, depending on input\nimages. Reply for biologicaly given question was looking for in this work, including filtration,\ndetails emphasizing, segmentation and sphericity computing. Order of algorithms and way to\nsearching for them was also described. Some questions and ideas for further work were mentioned\nin the conclusion part.\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\nAcknowledgement\nI would like to thank to my supervisors Benny Th\u00f6rnberg and Dalibor \u0160tys for problem\ndiscussions and work encouragement. I would also like to thank to V\u00edt\u011bzslav B\u0159ezina and \u0160t\u011bp\u00e1nka\nKu\u010derov\u00e1 for replying my questions in biological view of the task background. And at last I have to\nthank to all people and staff of Mid Sweden University in Sundsvall for oportunity to spend some\ntime there, and learn new things.\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n1\n\nIntroduction\n\n1.1\n\nTask Description\nThe goal of this work is to analyze the set of images of live HeLa cells, growing\n\nfor experiments focused on cytotoxity in vitro [1] in Laboratory of tissue cultures, Academic\nand University Center of Nov\u00e9 Hrady (Institut of Systems Biology and Ecology of Academy\nof Sciences of the Czech Republic and Institut of Physical Biology of University of South\nBohemia) [2].\nThe cells were observed by inverted microscope OLYMPUS IX51, using phase contrast.\nEvery 2 minutes was taken one image by camera OLYMPUS C-7070.\n\nFigure 1.: Microscope OLYMPUS IX51, source: http://olympuseurope.com\nThe background on all images is the bottom of the NUNC, plastic cultivation ware.\nMonitoring the cells growth \u2013 number of cells in time and their shape specification \u2013 are\nthe knowledges wanted to be reached from the set of images. Because of amount of snapshots\n(3937 jpeg files), it is time expensive to analyze them by human. Then the algorithms of image\nprocessing for automatic analysis were tested and implemented in MATLAB environment [3].\nThe task could be separated into this main steps, that demand to be solved:\ni) object to background segmentation, simply find where is NUNC and where are HeLa cells\nii) independent objects location in the image, means move from \u201eknow where the cells can be\"\nto \u201ewhere the cells are\" and where are the boundaries between them\niii) computation the output parameters \u2013 quantity and sphericity of the found cells\n\n1\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nFinal solution will be used in praxis in Laboratory of tissue cultures in Nov\u00e9 Hrady\nfor further experiments.\n\n1.2\n\nHeLa Cell Line\nOn 4th of October 1951 in Johns Hopkins Hospital in Baltimore died Henrietta Lacks,\n\na black woman in age 31. The reason of her death was cervival cancer. Without her knowledge,\nthe sample of tumor cells were taken by the researches. This cell line survived to the nowadays\nand is still used in laboratories as a model for human cells in thousands of biological experiments,\ncontributing to the understanding of disease processes.\nHeLa cells were propagated into an immortal human cell line by George Otto Gey, scientist\nfrom Tissue Culture Laboratory at Johns Hopkins Hospital. The word \"HeLa\" was devised by him\nusing the first two letters of Mrs. Lacks' first and last names to keep her real name in a secret.\nLacks' cancer cells have evolved into a self-replicating, single-cell life-form and to HeLa\ncells were given the new species name: Helacyton gartleri. The cells are the genetic chimera\nof human papillomavirus HPV18 and human cervical cells. [4]\n\nFigure 2.: Henrietta Lacks, source: http://wikipedia.org/\n\n2\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n1.3\n\nPhase Contrast Microscope\nThe method of phase contrast allow to observe soft, colourless, transparent objects,\n\nespecially living cells. The phase differences of light beams are passing through the cell\nand converted into differences in amplitude. That made them visible for human eye.\nThe principle of phase contrast for microscopy was first time proposed by Dutch scientist\nFrederik Zernike in 1932. His idea was awarded with the Nobel price in Physics in 1953.\nBetween specimen and observer is situated the phase-plate consist of thin annulus, changing\nthe phase by angle \u03c0/2 or -\u03c0/2 for negative or positive phase contrast. For positive phase contrast\n(-\u03c0/2 phase-plate) appear the thicker parts darker.\n\nFigure 3.: Scheme of phase contrast microscope, source: http://nobelprice.org/\nUnfortunately, there are also some important disadvantages. When the specimen was\nstrongly refracted, a halo effect occurs. That means, very shiny boundary overlapped the real object\nboundaries. The next limitation is disappearing of absorbing saturated objects for the observer.\n\n3\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n2\n\nMethod\nImage Analysis is the way how extract hopefuly useful informations from the images\n\nin automatic or semi-automatic methods and their algorithms on computer processing. Plenty\nof them are well described in literature [5, 6] or Image Analysis software guide [3, 7].\nSometimes for solving the tasks is enough to use the most common known and third-party\npreprogrammed algorithms. Then the problem is simply only how to find the proper sequence\nof this algorithms and their parameters. Some tasks are more difficult and need to discovery new\nmathematicaly based method. But the main number of real tasks, given by people not involved\nin Image Analysis, are combination of those two points of view \u2013 use already described methods\nand, where their failed, develop some level of improvement.\nIn this part, the basic methods, used in whole work, will be shortly mentioned\nwith presumtion of poor previous Image Analysis knowledge.\n\n2.1\n\nColour and grayscale representations\nMost common colour representation using by machine for vision or display is RGB (Red,\n\nGreen, Blue) colour space, where each pixel of image is represented by triplet (r,g,b). Value\nof colour channel (triplet element) is equal to intensity of its colour. The value for each channel is\nusually situated in interval <0,255> or <0,1> [5].\n0\n255\n0\n0\n0\n255\n255\n255\n\n0\n0\n255\n0\n255\n0\n255\n255\n\n0\n0\n0\n255\n255\n255\n0\n255\n\nTable 1.: RGB colours\nGrayscale representation is an image in 256 shades of gray <0,255>. There are three ways\nhow to create grayscale image from RGB image. First one is accorded to the relative sensitivity\nof human eye for primary colours:\nY1=0.3\u2217r \ue0830.59\u2217g\ue0830.11\u2217b\n\n4\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nIn the second one, just combination of intensity of all three channels is done with the same\nweight coeficient:\n1\n1\n1\nY2= \u2217r\ue083 \u2217g \ue083 \u2217b\n3\n3\n3\n\nThe last one is weight channels relative to each other [7]:\n2\n\nY3=\n\n2\n\nr \ue083g \ue083b\nr \ue083g\ue083b\n\n2\n\nRGB\n\nY1\n\nY2\n\nY3\n\nFigure 4.: Mid Sweden University in Sundsvall \u2013 RGB and grayscales, source: author\nDuring the grayscale transformation are the informations about colour lost and can not be\nrestored back from grayscale image.\n\n5\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n2.2\n\nIntensity Histogram\nThe Histogram function H (p) is an intensity function, shows count of pixel f(i,j)\n\nwith the intenzity equal p independently on the position (i,j).\nH \ue09e p\ue09f=\u2211 h\ue09ei , j , p\ue09f\ni, j\n\nh \ue09ei , j , p\ue09f=1if f \ue09ei , j\ue09f= p\n=0if f \ue09ei , j\ue09f\u2260 p\n600\n\n500\n\n400\n\n300\n\n200\n\n100\n\n0\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nFigure 5: Histogram function for Y1\n\n2.3\n\nThresholding\nThis method is time cheap and that is why it is often in use. It is searching for local minima\n\nor maxima in intensity histogram for separating image into the objects related to the real objects. It\ntakes from the image parts that corresponding to the threshold parameter(s). Increasing of threshold\nparameters may (but have not to) increase the segmentation result. Automatic selection\nof the threshold(s) value becomes more difficult when the situation in image scene is even\ncomplicated, like overlaping objects or shadows. More precise preprocessing or previous\nknowledge about the objects is necessary [5,6].\n\n2.3.1 Otsu\nOtsu gray level thresholding is a nonparametric method of automatic threshold selection\nfor picture segmentation from intensity histogram H(p). Firstly the histogram functions is\nnormalized:\no p=\n\nH \ue09e p\ue09f\nN\n\nwhere N is the total number of pixels in image.\n6\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nFor separating histogram into two classes, the probabilities of of class occurrence and the class\nmean are computed:\nk\n\n\ue0ce1= \u2211 o p , \ue0ce 2=\np=1\n\nL\n\n\u2211\n\np=k\ue0831\n\nk\n\n\ue0c21=\n\n\u2211 p\u2217o p\np=1\n\n\ue0ce1\n\nop\n\nL\n\n, \ue0c2 2=\n\n\u2211\n\np= k\ue0831\n\np\u2217o p\n\n\ue0ce2\n\ntotal mean level of image:\nL\n\n\ue0c2T =\u2211 p\u2217o p\np=1\n\nand the between class variance:\n2\n\n2\n\n\ue0c8 B=\ue0ce 1\u2217\ue09e\ue0c21\u2212\ue0c2t \ue09f \ue083\ue0ce2\u2217\ue09e\ue0c22\u2212\ue0c2t \ue09f\n\n2\n\nThe optimal threshold k* maximazes \u03c32B [8].\n\n600\n\n500\n\n400\n\n300\n\n200\n\n100\n\n0\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nFigure 6: Histogram function of Y1 with threshold from Otsu segmentation(red)\n\n2.4\n\nMorphological operations\nForcing of objects structure based on nonlinear operations with structural element, the set\n\nof points, smaller then proceeded image. Structural element is moving across the image and\nthe point of the image corresponding to coordinates of the structural element is changed\nin according to the relation betwen structral element and the image [5,6].\nDilation is the Minkowski addition of two sets X and SE and causes objects to grow in size\nand fill small holes inside.\n\ue0baSE \ue09e X \ue09f= X\n\nSE= \u222ase \u2208SE \ue09e X , se \ue09f\n\n7\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nErosion is a dual transformation to dilation, but not inverse function. It is Minkowski\nsubstraction and causes objects to shrink in size.\n\ue0bbSE \ue09e X \ue09f= X\n\nSE= \u2229se \u2208SE \ue09e X , se \ue09f\n\nOpening is an erosion followed by dilation and removes small objects.\n(X\n\nSE)\n\nSE\n\nClosing is a dilation followed by erosion and removes small holes.\n(X\n\nSE)\n\nSE\n\n2.4.1 Beucher gradient\nGradient operators are used in segmentation because they enhance high frequency intensity\nevents in images. These events may be caused by edges of objects, but generally are caused\nby noise. The idea of real edges is somewhat fuzzy. Image objects are not necessary at real object\nboundaries. A cannonical definition of an edge is still to be found, if it exists.\nDiscrete case of Beucher gradient is defined as arithmetic difference between the dilation\nand the erosion of the image with the structural element B:\ng SE=\ue0ba SE \ue09e X \ue09f\u2212\ue0bbSE \ue09e X \ue09f\n\nBeucher gradient represents the maximum variation of the gray level intensity within\nstructural element neighbourhood [9].\n\n2.4.2 Grayscale reconstructin\nReconstruction extracts the connected components of image X (mask) which are marked by\nimage M [10]. Both images are grayscale and of the same size. Value of each pixel from marker\nhave to be smaller or equall to the pixel in mask on the same coordinates:\nm\ue09ei , j\ue09f\ue086 x \ue09ei , j\ue09f\n\nthen the grayscale reconstrution can be defined as a geodesic dilation:\n\ue09e n\ue09f\n\n\ue09en \ue09f\n\n\ue0c7 X \ue09e M \ue09f=min \ue09e\ue0ba X \ue09eM \ue09f , X \ue09f\n\nwhere n is n-th iteration, \ue0ba\ue09eXn\ue09f is dilation\n\ue09e n\ue09f\n\n\ue09en \u22121 \ue09f\n\n\ue0ba X \ue09e M \ue09f=\ue0c7 X\n\n8\n\nSE\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nSE is morphological structural element and\n\ue09e 0\ue09f\n\n\ue0c7 X \ue09e M \ue09f=M\n\nStop condition for increasing n is when\n\ue09e n\ue09f\n\n\ue09e n\u22121\ue09f\n\n\ue0c7 X \ue09e M \ue09f=\ue0c7 X\n\n\ue09eM \ue09f .\n\n2.4.3 Watershed\nNon-parametric detection method for closed contours. Grayscale image is considered\nas a topographic surface. Imagine a drop of watter on this topografic surgace. The watter streams\ndown, reaches a minimum of height and stops there. Therefore the catchment basins and its\nwatershed lines can be defined by means of a flooding process starting from thr minima. Let\np \ue09ei , j\ue09f be the value of a pixel on coordinates \ue09ei , j\ue09f . Then M(p) is the set of the values in the\n\nneighborhood of \ue09ei , j\ue09f , that are stricly higher than p \ue09ei , j\ue09f . The point \ue09ei , j\ue09f ) is constructible if\nand only if the nearest common ancestor of all the components in M(p), has a value equal to or\nhigher than p+1 . The constructible point \ue09ei , j\ue09f is iteratively selected, raised and updated until\nstability [11,12,13] .\n\nFigure 7.: Flooding of a watershed, source http://cmm.ensmp.fr/\n\n9\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n2.5\n\nBoundary curvature ratio\nMerging criterion to improve the oversegmentation of watershed algorithm attempting to\n\nutilize boundary information to more visually appropriate segmentation. For two adjacent reginons\nRu and Rv are computed the curvature ratio k i .\n2\n\nk i=\n\nwhere \ue0ad x i=\n2\n\n\ue0ad x i=\n\n2\n\n\ue0ad x i \ue0ad y i\u2212\ue0ad xi \ue0ad y i\n2\n\n2 1.5\n\n\ue09e\ue0ad xi \ue083\ue0ad y i \ue09f\n\nx i\ue0831\u2212 x i\u22121\ny \u2212y\n, \ue0ad y i= i\ue0831 i\u22121\n2\n2\n\n\ue0ad x i\ue0831\u2212\ue0ad x i\u22121\n\ue0ad y i\ue0831\u2212\ue0ad y i\u22121\n2\n, \ue0ad y i=\n,and\n2\n2\n\n\ue09e x i , y i \ue09f is the coordinate position of i\u2212th pixel in the contour.\n\nThen, BCR of regions Ru and Rv is defined as:\nN u\ue083v\n\n1\nBCR=\n\nN u\ue083v\n1\nN u\ue083N v\n\n\u2211 ki\ni=1\n\nNu\n\nNv\n\ni =1\n\ni=1\n\n\u2211 k i \ue083\u2211 k i\n\nN is the number of pixel in region.\nIf BCR u , v \ue0871 , the need to merge Ru and Rv is considered low and the cost to merge them\nis large. On the other hand, if BCR u , v \ue0861 , the shape integrity of merging them together is better\nthen keep them separately and the cost to merge them is small [14].\n\n10\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n3.\n\nObject to background segmentation\nCorrect object found depends on plenty of factors, like kind of illumination, shadows, level\n\nof presented noise, proper focusing, overlapping to each other or objects dissimilarity to\nbackground. Founding process usually starts from simple techniques to more complicated\nalgorithms, until the results are accetable.\nFor finding HeLa cells in the images from phase contrast microscope can be used the Otsu\nsegmentation method. Because the original images are in RGB colour space representation, may be\nchosen one of grayscale transformations or splitting the colour channels into three different\ngrayscale images \u2013 intensity of red, intensity of green and intensity of blue.\n\nY1\n\nY2\n\nY3\n\nOtsu Y1\n\nOtsu Y2\n\nOtsu Y3\n\nFigure 8.: Grayscale Otsu\n\n11\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\nRGB\n\nRed\n\nOtsu channels\n\nGreen\n\nOtsu Red\n\nOtsu Green\n\nBlue\n\nOtsu Blue\n\ntogether\nFigure 9.: Splitting RGB and Otsu\nAs is saw from Figure 8. and 9., direct using of Otsu did not tend to clear and present cells.\nThere will be necessary to remove the effect of illumination and asperities on NUNC background.\n\n3.1\n\nOrder statistic filtering\nOrder Statistic Filters are filters which rank neighboring pixels in an attempt to remove low\n\nfrequency. The output pixels are computed by selecting a neighborhood of pixels around the input\npoint. Then the pixels in the window are ranked according to their intensity. For minimum filter the\nminimal valued intensity is then assigned as the output value. For maximum filter the output value\nis the maximal valued intensity and for median filter it is the middle valued intensity. Large constant\nregions stay preserved and a thin one pixel line would be removed.\nThe order statistic filter is non-linear in its operation and effects. Higher statistics are used,\nthe image will get brighter, while if lower statistics are used then the image gets darker.\nFirstly for using the Filter on an input image, is important to set the right size of the\nneighborhood, the filtering window.\n12\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n3.1.1 Appropriate range estimation\nAny set of point can be divided into statisticaly appropriate number of equidistant intervals\nusing one of these three equations:\ni)\n\nk =\ue08dn\n\nii)\n\nk \ue0865\u2217log 10 \ue09e n\ue09f\n\niii)\n\nThe Sturges rule: k =1\ue0833.3\u2217log 10 \ue09en\ue09f\n\nwhere n is number of points in set and k is the count of equidistant intervals [15].\nSize of HeLa cell images is 576\u2217720=414720 pixels per one image. It gives these possible\nnumbers of intervals:\ni)\n\n\ue08d 414720\u2248645\n\nii)\n\n5\u2217log 10 \ue09e414720\ue09f\u224828\n\nii)\n\n1\ue0833.3\u2217log 10 \ue09e414720 \ue09f\u224820\n\nBecause HeLa cells are quite small in comparison to the whole image, possibility i) was\nchosen. In that case, the number is also equal to the number of pixels in the window. Let choose the\nshape of it. As the basic shape is considered the square, but again according to the objects looked\nfor, the circle shape of window could be better.\nr=\n\n\ue08d\n\n645\n\u224814\n\ue0c6\n\nThe filter window was determined as circle with radius 14 pixels.\n\n3.1.2 Image border problem\n\nFigure 10: Expanded Image borders\n\n13\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nOn the all borders of the image only the half circle neighborhood is presented, even only\nquarter on the corners. As an extrapolation of the missing neighborhood, the size of whole image is\non the borders expanded by area of thickness equal to the window radius. Value of extended area is\ncomputed as mean value of whole image [16].\n\n3.1.3 Minimum Filter\nOrder statistical filtering with minimal value intensity parameter was separately applied on\nall channels of image with expanded borders. Then the borders were again removed.\n\nFigure 11.: Minimal Filtered Image with and without extended borders\nSmall asperities disappeared after minimal filtration, but this kind of filtering did not correct\nthe influance of illumination. For removing it, more operations with the minimal filtered image\nshould be done. Rate or difference between original and filtered image [7].\nrate=\n\nfiltered\noriginal\n\ndifference=original\u2212 filtered\n\nFigure 12.: Rate(light) and difference(dark) between original and minimal filtered image\n\n14\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n3.1.4 Maximum filter\nThe same procedures with borders and filter window like in minimum filter were done for\nminimal value intensity. In this case in equations for rate and difference the original and filtered\nswitched their places:\nrate=\n\noriginal\nfiltered\n\ndifference= filtered \u2212original\n\nFigure 13.: Rate(light) and difference(dark) between original and maximal filtered image\n\n3.1.5 Median Filter\nAlso, for median value intensity:\nrate=\n\noriginal\nfiltered\n\ndifference=original\u2212 filtered\n\nFigure 14.: Rate(light) and difference(dark) between original and median filtered image\n\n15\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n3.1.6 Otsu after preprocessing\nNow, when the filter functions were runing, the Otsu segmentation method for each channel\nshould be tested again for all solutions from filtering, on both, rate and difference images, to choose\nwhich one is better.\nOriginal\n\nOtsu Rate\n\nOtsu Difference\n\nNegative Otsu Difference\n\nFigure 15.: Otsu of Young HeLa cells, 1st minimal filter, 2nd maximal filter\nOriginal\n\nOtsu Rate\n\nOtsu Difference\n\nNegative Otsu Difference\n\nFigure 16.: Otsu of Adult HeLa cells, 1st minimal filter, 2nd maximal filter\n\n16\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nOriginal\n\nOtsu Rate\n\nOtsu Difference\n\nFigure 17.: Otsu of median filtering, 1st Young HeLa, 2nd Adult HeLa\nComparison of the results bringing the informations about usability of each filter method.\nMaximum filter is not so helpful because of emphasizing mainly the halo efects around the cells.\nThen this one was discard from another computation. Also in minimum filter a bit of halos remain.\nOn the other hand, median filter emphasize only the borders of the cells.\nNot decided yet if the rate could be better then difference, or the opposite statement.\n\n3.2\n\nDetails emphasizing\nAfter filtration, but before Otsu, still some improovement was missing. Three ways how to\n\ndo it were tested. Let p i , j ,k be intensity value of filtered pixel on coordinates i, j and channel k.\nThen f x \ue09ei , j , k \ue09f will be the new intensity value of the point p i , j ,k :\nf a \ue09ei , j\ue09f=\u220f \ue09e pi , j , k \ue09f\n\ni)\n\nprod:\n\nii)\n\nsquare: f b \ue09ei , j , k \ue09f= pi2, j , k\n\niii)\n\nlog:\n\nk\n\nf c \ue09ei , j , k \ue09f=\n\n\ue08d\n\n\u2223 log 10 \ue09e pi , j , k \ue083\n\n1\n\ue09f \u2223\n512\n\nIn case prod all channels are multiplicated together into grayscale image, where the dark\npixels become more darker, and the light become more lighter.\n17\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nCase square simply increase the contrast in image. The most complicated is case log.\nBecause intensity values are between 0 and 1 , applying logarithm function will rapidly increase the\ndifferences between values. The domain range of logarithm function for values from interval <0,1>\nis (-\u221e,0>. For protection against negative infinity, the values were shifted up by small value 1/512.\nAbsolut value operator was then used to convert negative values from logarithm function into\npositive. And finaly the radical was found, again to change the contrast.\n\n3.2.1 Otsu after emphasizing\nOtsu segmentation was repeated on filtered and emphasized imagas to see what changed.\nEmphasized prod\n\nEmphasized square\n\nEmphasize log\n\nFigure 18.: Rate emphasized minimal filter and its Otsu\nIs pretty clear that difference is not the proper comparison of original and filtered image,\nbecause of lot of disappered cells in several emphasizing and the highest occuring of fake\nsegmented objects. In mimimal filtering the objects passing through the otsu segmentation are the\nborders of the HeLa cells, some borders between the cells and some borders inside the cells. The\ndifference between kinds of emphasizing are only in the thickness of this borders. A little bit halo\nstill rest.\n18\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nEmphasized prod\n\nEmphasized square\n\nEmphasized log\n\nFigure 19.: Difference emphasized minimal filter and its Otsu\nEmphasized prod\n\nEmphasized square\n\nFigure 20.: Rate emphasized median filter and its Otsu\n19\n\nEmphasized log\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nEmphasized prod\n\nEmphasized square\n\nEmphasized log\n\nFigure 21.: Difference emphasized median filter and its Otsu\nGenerally, the logarithm emphasizing \u201esurvived\" all types of filtration and comparison of\noriginal and filtrated images (rate or difference), so that probably makes it the most powerfull one\nof them. Moreover it is presented without halo in median filtering.\n\n3.3\n\nSmallest objects clearance\nTo remove objects that passed throught the Otsu segmentation but are not HeLa cells, some\n\nmorphological operations could be used.\n\nFigure 22.: Otsu segmentation, its dilation and erosion\n20\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\nThe contour of the objects and holes were done by Beucher gradient [9] and for all arised\nlines computed their length. Simply lines shorter then the average length were deleted.\n\nFigure 23.: Beucher and Beucher without short lines\nFrom dilated image were counted all objects and computed they area. Similary like in the\nBeucher case, the objects with area less then average area, were deleted.\n\nFigure 24.: Dilation and dilation without small areas\nBut it is still dilated image, that mean all objects are little bit larger then in the started Otsu\nsegmentation. Using dual erosion could created bigger holes inside the objects. Better solution, how\nto shrink the objects is to substract the remaining Beucher gradient lines from remining dilation.\n\nFigure 25.: Cleared objects and original image\n21\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n3.4\n\nBinary image\nResult form prod emphasizing are in binary image (value equal 0 for NUNC background\n\nand 1 for cells) and could be directly used as a mask. But in square and log emphasizing, the results\nare three binary images \u2013 one for each channel. Let p i , j ,k be the point on coordinates i,j and\nchannel k. Then the point in final binary image, is bwi , j . There are three ways how to make\na binary image from three binary channels:\ni)\n\nstrict:\n\nii)\n\npatient:\n\niii)\n\nhalfway:\n\nbwi , j =\u220f p i , j , k\nk\n\nbwi , j =1 if \ue09e \u2211 pi , j , k \ue09f\ue0850\nk\n\n=0 otherwise\nbwi , j =1 if \ue09e \u2211 pi , j , k \ue09f\ue0851\nk\n\n=0 otherwise\n\nIn strict case, the point that is considered as object in all channels together become object\npoint in final binary image. Some points may be lost, because they have not to be presented in all\nchannels congruously. On the other hand, the patient case, allows to all possible points from all\nchannels, to be correctly segmented object points. That can make a lot of fake points. In equilibrium\nbetween first two cases is the halway one, where only points that are in at least two channels,\nremain in the final binary image. There is lower level of lost points than in strict case, and also\nlower level of fake points than in patient case.\n3-channels\n\nstrict\n\npatient\n\nhalfway\n\nFigure 26.: Cleared Otsu segmentation of log emphasized rate of median filtered image\n\n22\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n3.5\n\nCells to background recap\nVarious precesses how to suceed in segmentation were tested and reviewed. Shown how the\n\nsequence of the algorithms were found. Several steps, constisted of described methods and some\ntheir improovements, were defined:\ni)\n\nrate between original image and minimum or median filtration, with estimation of proper\nstructural element.\n\nii)\n\ndetails emphasizing by using log method\n\niii)\n\nstatisticaly based object clearance after otsu segmentation on preprocessed image\n\niv)\n\nhalfway binarizing of three channel binary segmented images\nAfter median filtration with log emphasizing and before otsu segmentation have to be done\n\nnegative transformation to switch the 0 and 1 values into binary opposite.\nPresented steps were running on randomly chosen images to prove their abilities.\nOriginal\n\nmimimum\n\nmedian\n\nFigure 27.: Young and Adult HeLa cells to background segmentation.\nBoth filters, minimum and media, give similar results, but in minimum filter still remain the\nhalo efect. So the more accurate is to using median filtration rate with logarithmic emphasizing\nbefore otsu segmentation folowed by clearence and binarization.\n\n23\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n4\n\nIndependent cells location\nResult from object to background segmentation was a mask, that can be multiply by original\n\nimage to get only the cells on dark background. Looking for individual cells and separating them to\neach other would by done on this masked image.\n\nFigure 28.: Application of mask.\nOne of the simplest contours detection is the Beucher gradient. When it is applied on\nmasked image, the outer boundary of cells clusters were pretty clear. But only some inner boundary\nlittle bit emphasized and some non-boundary pixels joined the show.\n\nFigure 29.: Beucher gradient of masked image\n\n4.1\n\nWatershed morphology\nMore powerful countour detection method is to use the watershed, which is independent on\n\nshape and countour, efficient and accurate. Grayscale image is, according to the method theory,\ndivided into two parts \u2013 the catchment basins and the watersheds.\n\n24\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\nFigure 30.: Watershed and watershed on Beucher gradient,\nwhite for catchment basins, black for watershed lines,\nother for basins in some channel and line in another\nThe main problem of watershed method is the oversegmentation (see Figure 30.). In real\nimages with structured objects, it is able to find a lot of catchment basins and watershed lines, that\nare not actually associated with meaningful regions. Even watershed on Beucher gradient is\noversegmented much more.\n\n4.2\n\nBCR for adjacent segments\nTo reduce number of segments after watershed segmentation, the boundary curvature ratio\n\nwas presented as improovement method. It compute the cost in shape integity of two adjacent\nregions. Firstly, from is necessary to find if two regionts Ru and Rv , resulted from watershed\nsegmentation are adjacent or not.\n\ue0ba R u= R u\n\nSE\n\n\ue0ba Rv =R v\n\nSE\n\n\u2229\ue09e\ue0ba Ru , \ue0ba Rv \ue09f\ue0850\n\nif the intersection of segments dilation is not an empty set, then they are adjacent and their\nboundary curvature ratio can be computed. As the pixels of boundary are considered pixels from\nBoucher gradient of watershed segmentation (do not mismatch with watershed of Boucher gradient,\nit differ in order of operations).\n\n25\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\nFigure 31.: Region 191 (yellow) with region 193 (red), and intersection (white) of their dilations\nAfter computing all boundary curvature ratios, the regions that belongs together according to\ntheir BCR were merged and colorized (see Figure 32.). Unfortunately also the regions, that not\nbelongs together were merged and that show, the BCR technique is not adequate enough for small\nregions of same types but different shapes.\n\nFigure 32.: Region merging after BCR\n\n4.3\n\nOpening-by-reconstruction and closing-by-reconstruction\nOpening-by-reconstruction\n\nis\n\nerosion\n\nfollowed\n\nby\n\nmorphological\n\nreconstrutin,\n\nclosing-by-reconstruction is dual operation to opening-by-reconstruction and it is dilation followed\nby morphological reconstruction. Both techniques are used to clean up the image. They could\nremove small blemishes without affecting the overall shapes of the objects [10].\n\n26\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\nFigure 31.: Opening-by-reconstruction followed by closing-by-reconstruction and its watershed\n\n4.4\n\nIndependent cells location recap\nWatershed segmentation is powerfull method for separating image into regions. The\n\noversegmentation can be reduced by applying opening-by-reconstruction and closing-byreconstruction before using watershed.\n\nFigure 32.: Final segmentation of Young (up) and Adult (down) HeLa cells\n\n27\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n5\n\nOutput parameters\nThe most important parameter for biological point of view is the count of spheric and\n\nnonspherc cells in the image. To count the number of objects is simple, but for counting different\ntypes is necessary to separate them before. Some kind of sphericity have to be computed as a\ntreshold for this separation. How to obtain the sphericity?\nThe perimeter of object can be easilly reached, for example from Beucher gradient. Also the\narea of objects as the number of pixels in object should be known. Now, from the sphere feature:\nperimeter\n2\u2217\ue0c6\n\nradius from perimeter: r p=\nradius from area: r a=\nfor real sphere is true\n\n\ue08d\n\narea\n\ue0c6\n\nrp\n=1\nra\n\nThe one of the most important feature of sphere is that it has the largest area with given\nperimeter, or the smallest perimeter wirh given area. Then as the sphericity can be considered rate\nbetwen r p and r a . How close this rate is to 1, is how close the shape is to sphere.\nThe treshold for sphere was set to 1.1.\n\nFigure 33.: Original image, segmentation, spheric cells, nonspheric\n\n28\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n6\n\nConclusion\nSeveral techniques for segmentation were tested. Cells to background segmentation were\n\ncompletly successful for both types of cells, young or adult. Otsu segmentation is very powerfull\nmethod for binary segmentation, but in this case needs polished preprocessing. Local median\nfiltration, with described appropriate range estimation for structural element, and\n\nfollowing\n\nlogarithmic details emphasizing, was used to improove information differnciability in image, before\nappluing Otsu segmentation.\nFor independent cells loacation, watershed methods was helpfull but with all problems of\nthis methods. Boundary curvature ratio can not solve the oversegmantation in this case, probably\nbecause of poor dissimilarity of independent cell. Applying opening-by-reconstruction and closingby-reconstruction, again with appropriate range estimation for structural element, solve lot of\noversegmentation, but still small amount of oversegmented or nonsegmented cells remain. Accurate\nsegmentation technique is still something that is looking for.\nThe last part of given task, was to express the sphericity of cells, simple but proper\nalgorithm was described and used, even against the small errors from watershed segmentation.\nThe algorithms are able to be used in praxis, only tresholding for possibility of cell size have\nto be done later, to remove noises that were recognized as cells, but are under their size. Comparing\nby average values or standard deviations of the values of pixel din not solve it.\n\n29\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n7\n\nReferences\n\n[1]\n\nBr\u00fa A., Albertos S., Subiza J.L., Garc\u00eda-Asenjo J.L., Br\u00fa I.: \u201eThe Universal Dynamics of\nTumor Growth\", Biophys J. 85(5): 2948\u20132961, 2003\n\n[2]\n\nhttp://www.greentech.cz\n\n[3]\n\nhttp://www.mathworks.com/products/matlab\n\n[4]\n\nVan Valen L., Maiorana V. C.: \u201eHeLa, a new microbial species\", Evolutionary Theory\n10:71-74, 1991\n\n[5]\n\n\u0160onka M., Hlav\u00e1\u010d V., Boyle R.: \u201eImage Processing, Analysis and Machine Vision\",\nBrooks/Cole Publishing Company, 1999\n\n[6]\n\nGonzales R. C., Woods R. E.: \u201eDigital Image Processing\", Addison-Wesley Publishing\nCompany, 1992\n\n[7]\n\nCarpenter et al.: \u201eCellProfiler: image analysis software for identifying and quantifying cell\nphenotypes \", Genome Biology, 7:R100, 2006\n\n[8]\n\nOtsu N.: \u201eA Threshold Selection Method from Gray-Level Histogram,\" IEEE Trans. on\nSystems, Man, and Cybernetics SMC-9, pp. 62--66, 1979\n\n[9]\n\nRivest J.F., Soille P., Beucher S.: \u201eMorphological gradients\" , SPIE \"Image Science and\nTechnology\", 1992.\n\n[10]\n\nVincent L., \u201eMorphological grayscale reconstruction in image analysis: applications and\nefficient alghorithms\", IEEE Transactions on Image Processing, 176-201, 1993\n\n[11]\n\nBeucher S.: \u201eApplications of mathematical morphology in material sciences: A review of\nrecent developments\", International Metallography Conference, pp. 41-46, 1995\n\n[12]\n\nBeucher S.: \u201eExtrema of grey-tone functions and mathematical morphology\", Proc. of the\nColloquium on Math. Morp., Stereol. and Image Analysis, Prague, Tchecoslovaquia,\npp. 59-70, 1982\n\n[13]\n\nBeucher S., Lantuejoui C.: \u201eUse of Watershes in contour detection\", International Workshop\non image processing, real-time edge and motion detection/estimation, Rennes, France, 1979.\n\n[14]\n\nHe X., Yung N.H.C., Chow K.P., Chin F.Y.L, Chung R.H.Y. Wong K.Y.K., Tsang\nK.S.H,:\u201eWatershed Segmentation with Boundary Curvature Ratio based Merging Criterion\",\nThe Ninth IASTED International Conference on Signal and Image Processing 576-178, 2007\n\n30\n\n\fAutomatic segmentation of HeLa cell images\n\n2007\n\nJan Urban\n\n[15]\n\nKasal P., Hlad\u00edkov\u00e1 M.: \u201eStatistical column\", Academic bulletin of 2nd Medical School\nof Charles University, 1995\n\n[16]\n\nVan\u011bk J., Urban J., Gardian Z.: \u201eAutomated detection of photosystems II in electron\nmicroscope photographs\", Technical Computing Prague, p.102, 2006\n\n31\n\n\f"}