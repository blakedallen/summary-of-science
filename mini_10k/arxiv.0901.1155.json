{"id": "http://arxiv.org/abs/0901.1155v2", "guidislink": true, "updated": "2012-09-12T07:22:48Z", "updated_parsed": [2012, 9, 12, 7, 22, 48, 2, 256, 0], "published": "2009-01-09T00:23:33Z", "published_parsed": [2009, 1, 9, 0, 23, 33, 4, 9, 0], "title": "Balanced allocation: Memory performance tradeoffs", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0901.2401%2C0901.4578%2C0901.1537%2C0901.2770%2C0901.1908%2C0901.3128%2C0901.2911%2C0901.4367%2C0901.1272%2C0901.3409%2C0901.4350%2C0901.1654%2C0901.3277%2C0901.0501%2C0901.0120%2C0901.2107%2C0901.3454%2C0901.1189%2C0901.2847%2C0901.1498%2C0901.3427%2C0901.4489%2C0901.0339%2C0901.1887%2C0901.3099%2C0901.2608%2C0901.1512%2C0901.0025%2C0901.0964%2C0901.3569%2C0901.3382%2C0901.2814%2C0901.3087%2C0901.2151%2C0901.1220%2C0901.0408%2C0901.4769%2C0901.4374%2C0901.2049%2C0901.4128%2C0901.1570%2C0901.0129%2C0901.4603%2C0901.4339%2C0901.1248%2C0901.3175%2C0901.1005%2C0901.3567%2C0901.4094%2C0901.0748%2C0901.1821%2C0901.2494%2C0901.0583%2C0901.4584%2C0901.3164%2C0901.3325%2C0901.0010%2C0901.4824%2C0901.3220%2C0901.0434%2C0901.2624%2C0901.2161%2C0901.1098%2C0901.3145%2C0901.2104%2C0901.2550%2C0901.4735%2C0901.3774%2C0901.0360%2C0901.2842%2C0901.3613%2C0901.2855%2C0901.3537%2C0901.3042%2C0901.0036%2C0901.1639%2C0901.3393%2C0901.3918%2C0901.2449%2C0901.1432%2C0901.3841%2C0901.3560%2C0901.2642%2C0901.3645%2C0901.2980%2C0901.3750%2C0901.0303%2C0901.2885%2C0901.4167%2C0901.1953%2C0901.4536%2C0901.1344%2C0901.1776%2C0901.0037%2C0901.1155%2C0901.4822%2C0901.2144%2C0901.3521%2C0901.2233%2C0901.4746%2C0901.2867&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Balanced allocation: Memory performance tradeoffs"}, "summary": "Suppose we sequentially put $n$ balls into $n$ bins. If we put each ball into\na random bin then the heaviest bin will contain ${\\sim}\\log n/\\log\\log n$ balls\nwith high probability. However, Azar, Broder, Karlin and Upfal [SIAM J. Comput.\n29 (1999) 180--200] showed that if each time we choose two bins at random and\nput the ball in the least loaded bin among the two, then the heaviest bin will\ncontain only ${\\sim}\\log\\log n$ balls with high probability. How much memory do\nwe need to implement this scheme? We need roughly $\\log\\log\\log n$ bits per\nbin, and $n\\log\\log\\log n$ bits in total. Let us assume now that we have\nlimited amount of memory. For each ball, we are given two random bins and we\nhave to put the ball into one of them. Our goal is to minimize the load of the\nheaviest bin. We prove that if we have $n^{1-\\delta}$ bits then the heaviest\nbin will contain at least $\\Omega(\\delta\\log n/\\log\\log n)$ balls with high\nprobability. The bound is tight in the communication complexity model.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0901.2401%2C0901.4578%2C0901.1537%2C0901.2770%2C0901.1908%2C0901.3128%2C0901.2911%2C0901.4367%2C0901.1272%2C0901.3409%2C0901.4350%2C0901.1654%2C0901.3277%2C0901.0501%2C0901.0120%2C0901.2107%2C0901.3454%2C0901.1189%2C0901.2847%2C0901.1498%2C0901.3427%2C0901.4489%2C0901.0339%2C0901.1887%2C0901.3099%2C0901.2608%2C0901.1512%2C0901.0025%2C0901.0964%2C0901.3569%2C0901.3382%2C0901.2814%2C0901.3087%2C0901.2151%2C0901.1220%2C0901.0408%2C0901.4769%2C0901.4374%2C0901.2049%2C0901.4128%2C0901.1570%2C0901.0129%2C0901.4603%2C0901.4339%2C0901.1248%2C0901.3175%2C0901.1005%2C0901.3567%2C0901.4094%2C0901.0748%2C0901.1821%2C0901.2494%2C0901.0583%2C0901.4584%2C0901.3164%2C0901.3325%2C0901.0010%2C0901.4824%2C0901.3220%2C0901.0434%2C0901.2624%2C0901.2161%2C0901.1098%2C0901.3145%2C0901.2104%2C0901.2550%2C0901.4735%2C0901.3774%2C0901.0360%2C0901.2842%2C0901.3613%2C0901.2855%2C0901.3537%2C0901.3042%2C0901.0036%2C0901.1639%2C0901.3393%2C0901.3918%2C0901.2449%2C0901.1432%2C0901.3841%2C0901.3560%2C0901.2642%2C0901.3645%2C0901.2980%2C0901.3750%2C0901.0303%2C0901.2885%2C0901.4167%2C0901.1953%2C0901.4536%2C0901.1344%2C0901.1776%2C0901.0037%2C0901.1155%2C0901.4822%2C0901.2144%2C0901.3521%2C0901.2233%2C0901.4746%2C0901.2867&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Suppose we sequentially put $n$ balls into $n$ bins. If we put each ball into\na random bin then the heaviest bin will contain ${\\sim}\\log n/\\log\\log n$ balls\nwith high probability. However, Azar, Broder, Karlin and Upfal [SIAM J. Comput.\n29 (1999) 180--200] showed that if each time we choose two bins at random and\nput the ball in the least loaded bin among the two, then the heaviest bin will\ncontain only ${\\sim}\\log\\log n$ balls with high probability. How much memory do\nwe need to implement this scheme? We need roughly $\\log\\log\\log n$ bits per\nbin, and $n\\log\\log\\log n$ bits in total. Let us assume now that we have\nlimited amount of memory. For each ball, we are given two random bins and we\nhave to put the ball into one of them. Our goal is to minimize the load of the\nheaviest bin. We prove that if we have $n^{1-\\delta}$ bits then the heaviest\nbin will contain at least $\\Omega(\\delta\\log n/\\log\\log n)$ balls with high\nprobability. The bound is tight in the communication complexity model."}, "authors": ["Itai Benjamini", "Yury Makarychev"], "author_detail": {"name": "Yury Makarychev"}, "author": "Yury Makarychev", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/11-AAP804", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0901.1155v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0901.1155v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in at http://dx.doi.org/10.1214/11-AAP804 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0901.1155v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0901.1155v2", "journal_reference": "Annals of Applied Probability 2012, Vol. 22, No. 4, 1642-1649", "doi": "10.1214/11-AAP804", "fulltext": "The Annals of Applied Probability\n2012, Vol. 22, No. 4, 1642\u20131649\nDOI: 10.1214/11-AAP804\nc Institute of Mathematical Statistics, 2012\n\narXiv:0901.1155v2 [cs.DS] 12 Sep 2012\n\nBALANCED ALLOCATION: MEMORY\nPERFORMANCE TRADEOFFS\nBy Itai Benjamini and Yury Makarychev\nWeizmann Institute and Toyota Technological Institute at Chicago\nSuppose we sequentially put n balls into n bins. If we put each ball\ninto a random bin then the heaviest bin will contain \u223c log n/ log log n\nballs with high probability. However, Azar, Broder, Karlin and Upfal\n[SIAM J. Comput. 29 (1999) 180\u2013200] showed that if each time we\nchoose two bins at random and put the ball in the least loaded bin\namong the two, then the heaviest bin will contain only \u223c log log n\nballs with high probability. How much memory do we need to implement this scheme? We need roughly log log log n bits per bin, and\nn log log log n bits in total.\nLet us assume now that we have limited amount of memory. For\neach ball, we are given two random bins and we have to put the ball\ninto one of them. Our goal is to minimize the load of the heaviest\nbin. We prove that if we have n1\u2212\u03b4 bits then the heaviest bin will\ncontain at least \u03a9(\u03b4 log n/ log log n) balls with high probability. The\nbound is tight in the communication complexity model.\n\n1. Introduction. Suppose we sequentially put n balls into n bins. If\nwe put each ball in a bin chosen independently and uniformly at random, the maximum load (the largest number of balls in any bin) will be\n\u223c log n/ log log n with high probability. We can significantly reduce the maximum load by using the \"power of two choices\" scheme of Azar, Broder,\nKarlin and Upfal [2]: if we put each ball in the least loaded of two bins\nchosen independently and uniformly at random, the maximum load will be\n\u223c log log n with high probability. This scheme has numerous applications for\nhashing, server load balancing and low-congestion circuit routing (see [1\u20138]).\nAs an example, consider an implementation of a hash table that uses the\n\"power of two choices\" paradigm. We keep a table of size n; each table entry\ncan store multiple elements (say) in a doubly-linked list. We use two perfectly\nReceived November 2009; revised February 2011.\nAMS 2000 subject classifications. Primary 68Q87; secondary 60C05.\nKey words and phrases. Balls\u2013and\u2013bins process, load balancing, memory performance\ntradeoffs.\n\nThis is an electronic reprint of the original article published by the\nInstitute of Mathematical Statistics in The Annals of Applied Probability,\n2012, Vol. 22, No. 4, 1642\u20131649. This reprint differs from the original in\npagination and typographic detail.\n1\n\n\f2\n\nI. BENJAMINI AND Y. MAKARYCHEV\n\nrandom hash functions h1 and h2 that map elements to table entries. To\ninsert an element e, we find two possible table entries h1 (e) and h2 (e),\nand store the element in the table entry with fewer elements. To find an\nelement e, we search through all elements in entries h1 (e) and h2 (e). This\nrequires only O(log log n) operations for every element e w.h.p.; whereas if\nwe used only one hash function we would need to perform \u03a9(log n/ log log n)\noperations for some elements w.h.p.\nHow many extra bits of memory do we need to implement this scheme?\nWe need roughly log log log n bits per bin (table entry) to store the number\nof balls (elements) in the bin, and n log log log n bits in total.\nLet us assume now that we have limited amount of memory. For each\nball, we are given two random bins (e.g., we are given two hash values) and\nwe have to put the ball into one of them. Can we still guarantee that the\nmaximum load is O(log log n) with high probability?\nThe correct answer is not obvious. One could assume that if the number\nof memory bits is o(n) then the maximum load should be \u223c logloglogn n balls.\nHowever, that is not the case as the following example shows. Let us group all\nbins into n/ log log n clusters; each cluster consists of log log n bins. For each\ncluster, we keep the total number of balls in the bins that form the cluster.\nNow given a ball and two bins, we put the ball into the bin whose cluster\ncontains fewer balls. The result of Azar, Broder, Karlin and Upfal [2] implies\nthat w.h.p. each cluster will contain at most n/ lognlog n + log log n = 2 log log n\nballs. Therefore, each bin will also contain at most 2 log log n balls. This\nn\nscheme uses log log\nn log log log n = o(n) bits of memory.\nIn this paper, we show that if we have n1\u2212\u03b4 bits of memory then the\nmaximum load is \u03a9(\u03b4 log n/ log log n) balls with high probability. We study\nthe problem in the \"communication complexity model.\" In this model, the\nstate of the algorithm is determined by M bits of memory. Before each step,\nwe choose the memory state m \u2208 {1, . . . , 2M }. Then the algorithm gets two\nbin choices i and j. It selects one of them based on m, i, j and independent\nrandom bits. That is, the algorithm chooses i with a certain probability\nf (m, i, j) and j with probability 1 \u2212 f (m, i, j); the choice is independent\nfrom the previous steps.\nUnlike the standard computational model, we do not require that the\nmemory state of the algorithm depends only on m, i, j and the random\nbits in the communication complexity model. In particular, the state can\ndepend on the current load of bins. Hence, algorithms in our model are\nmore powerful than algorithms in the computational model. Consequently,\nour lower bound (Theorem 1.1) applies also to the computational model,\nwhereas our upper bound (Theorem 1.2) applies only to the communication\ncomplexity model.\nFirst, we prove the lower bound on maximum load.\n\n\fBALANCED ALLOCATION: MEMORY PERFORMANCE TRADEOFFS\n\n3\n\nTheorem 1.1. We are sequentially given n balls. We have to put each\nof them into one of two bins chosen uniformly and independently at random\namong n bins. We have only M = n1\u2212\u03b4 bits of memory (\u03b4 > 0 may depend\non n); our choice where to put a ball can depend only on these memory\n\u03b4 log n\nbits and random bits. Then the maximum load will be at least 2 log\nlog n with\nprobability 1 \u2212 o(1).\nThen we show that the bound is essentially tight in the communication\ncomplexity model.\nTheorem 1.2. There exists an algorithm that gets M = n1\u2212\u03b4 bits of advice before each step and uses no other memory, and ensures that the heaviest\n\u03b4 log n\n1\u2212\u03a9(1) ].\nbin contains at most O( log\nlog n ) balls w.h.p. [where \u03b4 \u2265 1/(log n)\nIn Section 2, we prove Theorem 1.1. In Section 3, we prove Theorem 1.2.\n\u03b4 log n\n2. Proof of Theorem 1.1. We assume that 2 log\nlog n \u2265 1, as otherwise the\nstatement of the theorem is trivially true (there is a bin that contains at\nleast one ball).\nConsider one step of the bins\u2013and\u2013balls process: we are given two bins\nchosen uniformly at random, and we put the ball into one of them. Let\n(m)\npi \u2261 pi be the probability that we put the ball into bin i given that the\n\u03b5 = {i : pm < \u03b5/n}.\nmemory state is m \u2208 {1, . . . , 2M }. Let Fm \u2261 Fm\ni\n\nClaim 2.1. (1) For every set of bins S, the probability that we put a ball\n\u03b5 |/n:\nin a bin from S is at least \u03b5|S \\ Fm\n(2)\n\n\u03b5\n|Fm\n| \u2264 \u03b5n.\n\nProof. (1) The desired probability equals\n\u03b5|\nX\nX\n\u03b5|S \\ Fm\n.\npi \u2265\npi \u2265\nn\n\u03b5\ni\u2208S\n\ni\u2208S\\Fm\n\n\u03b5 is |F \u03b5 |2 /n2 . There(2) The probability that both chosen bins are in Fm\nm\n\u03b5 is at least\nfore, the probability t that we put the ball into a bin from Fm\n2\n2\n\u03b5\n|Fm | /n . On the other hand, we have\n\u03b5|\nX\n\u03b5|Fm\n.\npi <\nt=\nn\n\u03b5\ni\u2208Fm\n\nWe conclude that\n\n\u03b5 | \u2264 \u03b5n.\n|Fm\n\n\u0003\n\nWe divide the process into L consecutive phases. In each phase, we put\n\u230an/L\u230b balls into bins. Let Si be the set of bins that contain at least i balls\nat the end of the phase i; let S0 = {1, . . . , n}. Now we will prove a bound on\nthe size of Si that in turn will imply Theorem 1.1.\n\n\f4\n\nI. BENJAMINI AND Y. MAKARYCHEV\n\nLemma 2.2. Let L = \u2308 2\u03b4 log n/ log log n\u2309, \u03b5 = 1/(2L) and \u03b2 = 1/(4L).\nFor every i \u2208 {0, . . . , L}, let Ei be the event that for every m1 , . . . , mL\u2212i \u2208\n{1, . . . , 2M },\n\u001f L\u2212i\n[\n(\u03b2\u03b5)i\nSi\nFmj \u2265\nn.\n2\nj=1\n\nThen for every i\n\nPr(Ei ) = 1 \u2212 o(1).\nIn particular, Pr(|SL | > 0) \u2265 Pr(EL ) = 1 \u2212 o(1), and therefore, in the end,\nthe heaviest bin contains at least L balls w.h.p.\nProof. First, note that the event E0 always holds,\n\u001f[\nL\nS0\nFmj \u2265 n \u2212 L\u03b5n = n/2.\nj=1\n\nNow we shall prove that Pr(E \u0304i |Ei\u22121 ) \u2264 o(1/L) (uniformly for all i), and\nthus\ni\nX\nPr(E0 \u2227 * * * \u2227 Ej\u22121 \u2227 E \u0304j ) \u2212 Pr(E \u03040 )\nPr(Ei ) \u2265 Pr(E0 \u2227 * * * \u2227 Ei ) = 1 \u2212\nj=1\n\n\u22651\u2212\n\ni\nX\n\nPr(E \u0304j \u2227 Ej\u22121 ) \u2265 1 \u2212\n\ni\nX\n\nPr(E \u0304j |Ej\u22121 ) = 1 \u2212 o(1).\n\nj=1\n\nj=1\n\nAssume that Ei\u22121 holds. Fix m1 , . . . , mL\u2212i . We are going to estimate the\nSL\u2212i\nFmj which we put a ball into during the\nnumber of bins in Si\u22121 \\ j=1\nSL\u2212i\nphase i. All those bins are in the set Si \\ j=1\nFmj .\nConsider one step of the process; we are given the tth ball (in the current\nphase) and have to put it in a bin. Let Nt\u22121 be the set of bins in Si\u22121 \\\nSL\u2212i\nj=1 Fmj where we have already put a ball into (during the current phase).\nWe are going to lower bound the probability of\nthe event that we put the\nSL\u2212i\nball into a \"new bin,\" that is, in a bin in Si\u22121 \\ j=1\nFmj \\ Nt\u22121 . Denote the\nindicator variable of this event by qt . Let m be the state of the memory at\ntime t. Since Ei\u22121 holds,\n!\u001f\n\u001f L\u2212i\n[\n(\u03b2\u03b5)i\u22121 n\nFmj\nSi\u22121\nFm \u2265\n.\n2\nj=1\n\nTherefore, by Claim 2.1(1), the probability that qt = 1 is at least\nSL\u2212i\n\u0012\n\u0013\n\u03b5|Si\u22121 \\ j=1\nFmj \\ Fm \\ Nt\u22121 |\n(\u03b2\u03b5)i\u22121 |Nt\u22121 |\n\u2265\n\u2212\n\u03b5.\nn\n2\nn\n\n\fBALANCED ALLOCATION: MEMORY PERFORMANCE TRADEOFFS\n\n5\n\nThus, if |Nt\u22121 | \u2264 (\u03b2\u03b5)i\u22121 n/4,\ndef\n\nPr(qt = 1|q1 , . . . , qt\u22121 ) \u2265 (\u03b2\u03b5)i\u22121 \u00d7 \u03b5/4 = \u03bc.\nNote that |Nt | = |Nt\u22121 | + qt and |Nt | = q1 + * * * + qt . Now we want to apply\nthe Chernoff bound to the random variables {qj }j . However, since they are\nnot necessarily independent, we will need an additional step. Define random\nvariables q\u0303j as follows.\nIf |Nt\u22121 | \u2264 (\u03b2\u03b5)i\u22121 n/4,\n\uf8f1\n\u03bc\n\uf8f4\nif qt = 1,\nlet q\u0303t = 1 w.p.\n;\n\uf8f4\n\uf8f4\nPr(qt = 1|q1 , . . . , qt\u22121 )\n\uf8f2\n\u03bc\nif qt = 1,\nlet q\u0303t = 0 w.p. 1 \u2212\n;\n\uf8f4\n\uf8f4\nPr(qt = 1|q1 , . . . , qt\u22121 )\n\uf8f4\n\uf8f3\nif qt = 0,\nlet q\u0303t = 0.\n\nIf |Nt\u22121 | > (\u03b2\u03b5)i\u22121 n/4,\n\n\u001a\n\nlet q\u0303t = 1 w.p. \u03bc;\nlet q\u0303t = 0 w.p. 1 \u2212 \u03bc.\n\nIt is easy to see that in either case Pr(q\u0303t = 1|q\u03031 , . . . , q\u0303t\u22121 ) = \u03bc. Therefore,\nq\u03031 , . . . , q\u0303t are i.i.d. 0\u20131 Bernoulli random variables with expectation \u03bc. By\nthe Chernoff bound, the probability that q\u03031 + * * * + q\u0303n/L is at least\n1\n1 n\u03bc (\u03b2\u03b5)i n\n\u00d7 E[q\u03031 + * * * + q\u0303n/L ] = \u00d7\n=\n2\n2\nL\n2\ni\n\nis at least 1 \u2212 2 * 2\u2212(\u03b2\u03b5) n/8 . Since qt \u2265 q\u0303t if |Nt\u22121 | < (\u03b2\u03b5)i\u22121 n/4,\n|Nt | = q1 + * * * + qt \u2265 min((\u03b2\u03b5)i\u22121 n/4, q\u03031 + * * * + q\u0303t ).\nFinally, we have\n\u0012\n\u0013\n\u0012\n\u0013\n(\u03b2\u03b5)i n\n(\u03b2\u03b5)i n\ni\u22121\nPr |Nn/L | \u2265\n\u2265 Pr min((\u03b2\u03b5) n/4, q\u03031 + * * * + q\u0303n/L ) \u2265\n2\n2\n\u0013\n\u0012\ni\ni\n(\u03b2\u03b5) n\n\u2265 1 \u2212 2 * 2\u2212(\u03b2\u03b5) n/8 .\n= Pr q\u03031 + * * * + q\u0303n/L \u2265\n2\nSL\u2212i\nSince Si \\ j=1 Fmj \u2283 Nn/L ,\n!\n\u001f L\u2212i\n[\n(\u03b2\u03b5)i\ni\nPr Si\nFmj \u2265\nn Ei\u22121 \u2265 1 \u2212 2 * 2\u2212(\u03b2\u03b5) n/8\n2\nj=1\n\nfor fixed m1 , . . . , mL\u2212i . By the union bound [recall that \u03b5 = 1/(2L) and\n\u03b2 = 1/(4L)]\n!\n\u001f L\u2212i\n[\nFmj \u2265 (\u03b2\u03b5)i n/2 Ei\u22121\nPr for all m1 , . . . , mL\u2212i : Si\nj=1\n\n\f6\n\nI. BENJAMINI AND Y. MAKARYCHEV\n\n(1)\n\ni\n\n\u2265 1 \u2212 2 * (2M )L\u2212i 2\u2212(\u03b5\u03b2) n/8 \u2265 1 \u2212 2M L\u2212(1/(8L\n= 1 \u2212 2n\n\nRecall that\n\n1\u2212\u03b4 L(1\u2212n\u03b4 L(1/(8L2 ))L+1 )\n\n\u03b4 log n\nL = \u2308 2 log\nlog n \u2309.\n\n2 ))L n/8\n\n.\n\nWe have,\n\n(8L2 )L+1 \u2264 (8L2 )2 * (8L2 )\u03b4 log n/(2 log log n) \u2264 (8L2 )2 *\n\n\u0012\n\nlog n\n\u03c9(1)\n\n\u0013\u03b4 log n/ log log n\n\n\u2264 (8L2 )2 n\u03b4 2\u2212\u03c9(L) = n\u03b4 26+4 log L\u2212\u03c9(L) = o(n\u03b4 ).\nTherefore, expression (1) is 1 \u2212 2n\n\n1\u2212\u03b4 L(1\u2212\u03c9(L))\n\n= 1 \u2212 o(1). \u0003\n\n3. Proof of Theorem 1.2. In this section, we will prove that our bound\nis tight in the communication complexity model. Specifically, we present\nan algorithm that gets M = n1\u2212\u03b4 bits of advice before each ball is thrown,\n\u03b4 log n\nand ensures that the maximum load is at most O( log\nlog n ) w.h.p. when \u03b4 \u2265\n1\u2212\u03a9(1)\n1/(log n)\n.\nObserve that no matter which of the two bins we choose at each step,\nthe probability pi that we put the ball in a bin i is at most 2/n. Therefore,\nthe probability that after n steps the total number of balls in the bin i\n2 log(1/\u03b4)\n2\u03b4 log n\nexceeds T = log\nlog n (1 + log(\u03b4 log n) ) is asymptotically at most the probability\nthat a Poisson random variable with \u03bb = 2 exceeds T , that is, it is at most\nT\nT\n\u03b4\ne\u22122 2T ! (1 + o(1)) = o(( 2e\nT ) ) = o(1/(n log n)). Thus the number of bins that\ncontain at least T balls is at most n1\u2212\u03b4 /(2 log n) w.h.p. Before each step,\nour algorithm receives the list L of such bins, and the number of balls in\neach of them. Now if one of the two randomly chosen bins belongs to L and\nthe other does not, the algorithm puts the ball into the bin that is not in L;\nif both bins are in L, the algorithm puts the ball into the bin with fewer\nballs (let us say that we use the \"always-go-left\" tie breaking rule: if both\nbins contain the same number of balls, we put the ball into the left of the\ntwo bins); finally, if both bins are not in L, the algorithm puts the ball into\nan arbitrary bin.\nLet us estimate the maximum load. We say that a ball is an \"extra ball\"\nif we put it into a bin that is in L (at the moment when we put the ball).\nThen the total number of balls in a bin is at most T plus the number of\nextra balls in the bin. Let us now count only extra balls. Note that every\ntime we get a ball, we either:\n\u2022 \"discard it,\" put it into a bin that is not in L, and thus do not count it\nas an extra ball, or\n\u2022 put it into one of the two bins that contains fewer \"extra balls.\"\nThat is, we use a modified scheme of Azar, Broder, Karlin and Upfal, where\nwe sometimes put a ball into one of the two bins that contains fewer \"extra\nballs,\" and sometimes discard it. We claim that each bin contains at most\n\n\fBALANCED ALLOCATION: MEMORY PERFORMANCE TRADEOFFS\n\n7\n\nlog log n extra balls as in the standard \"power of two choices\" scheme of\nAzar, Broder, Karlin and Upfal.\nClaim 3.1. Consider the balls and bins process. Suppose at step i we\nare given the choice of two bins a1i and a2i . Let kij be the number of balls in\nbin j after i steps when we use the standard \"power of two choices\" scheme.\nLet k\u0303ij be the number of extra balls in bin j after i steps when we use our\nmodified \"power of two choices\" scheme. Assume that in both cases we use\nthe \"always-go-left\" tie breaking rule. Then k\u0303ij \u2264 kij , for every 1 \u2264 i, j \u2264 n\n(the statement holds for every sequence {a1i , a2i }i=1,...,n ).\nProof. We prove that k\u0303ij \u2264 kij by induction on i. Initially, all bins\ncontain no balls, k\u03030j = k0j = 0, so the statement holds. Assume that the\nstatement holds for i < i0 , we verify that k\u0303ij \u2264 kij for i = i0 . Fix j. Consider\nseveral cases.\n\u2022 First, suppose that we put the ball into the bin j at step i in both schemes.\nThen k\u0303ij = k\u0303i\u22121,j + 1 \u2264 ki\u22121,j + 1 = kij .\n\u2022 Now suppose that we put the ball into the bin j at step i in the modified\nscheme, however, we put the ball into some bin j \u2032 6= j in the standard\nscheme. Note that if j < j \u2032 then k\u0303i\u22121,j \u2264 k\u0303i\u22121,j \u2032 and ki\u22121,j \u2032 < ki\u22121,j thus\nk\u0303ij = k\u0303i\u22121,j + 1 \u2264 k\u0303i\u22121,j \u2032 + 1 \u2264 ki\u22121,j \u2032 + 1 \u2264 ki\u22121,j = kij ;\nif j \u2032 < j then k\u0303i\u22121,j < k\u0303i\u22121,j \u2032 and ki\u22121,j \u2032 \u2264 ki\u22121,j and thus\nk\u0303ij = k\u0303i\u22121,j + 1 \u2264 k\u0303i\u22121,j \u2032 \u2264 ki\u22121,j \u2032 \u2264 ki\u22121,j = kij .\n\u2022 Finally, suppose that in the modified scheme we put the ball into some\nbin j \u2032 6= j or discard it at step i. Then k\u0303ij = k\u0303i\u22121,j \u2264 ki\u22121,j \u2264 kij . \u0003\nNote that if bins a1i and a2i are chosen uniformly at random, then maxj knj =\nlog log n + \u0398(1) with high probability [2]. Therefore, by the claim, maxj k\u0303nj =\n\u03b4 log n\nlog log n+O(1), and each bin contains at most T +log log n+O(1) = O( log\nlog n )\nballs w.h.p.\nAcknowledgments. Noga Alon showed us the no memory case before\npursuing this work. We would like to thank Noga Alon and Eyal Lubetzky for\nuseful discussions. We thank the anonymous referee for valuable suggestions.\nREFERENCES\n[1] Adler, M., Chakrabarti, S., Mitzenmacher, M. and Rasmussen, L. (1998).\nParallel randomized load balancing. Random Structures Algorithms 13 159\u2013188.\nMR1642570\n[2] Azar, Y., Broder, A. Z., Karlin, A. R. and Upfal, E. (1999). Balanced allocations.\nSIAM J. Comput. 29 180\u2013200. MR1710347\n\n\f8\n\nI. BENJAMINI AND Y. MAKARYCHEV\n\n[3] Berenbrink, P., Czumaj, A., Steger, A. and V\u00f6cking, B. (2006). Balanced allocations: The heavily loaded case. SIAM J. Comput. 35 1350\u20131385. MR2217150\n[4] Byers, J., Considine, J. and Mitzenmacher, M. (2003). Simple load balancing for\ndistributed hash tables. In Peer-to-Peer Systems II. Lecture Notes in Computer\nScience 2735 80\u201387. Springer, Berlin.\n[5] Byers, J. W., Considine, J. and Mitzenmacher, M. (2004). Geometric generalizations of the power of two choices. In Proceedings of the Sixteenth Annual ACM\nSymposium on Parallelism in Algorithms and Architectures 54\u201363. ACM, New\nYork.\n[6] Cole, R., Maggs, B. M., Meyer auf der Heide, F., Mitzenmacher, M.,\nRicha, A. W., Schr\u00f6der, K., Sitaraman, R. K. and V\u00f6cking, B. (1999).\nRandomized protocols for low-congestion circuit routing in multistage interconnection networks. In STOC'98 (Dallas, TX) 378\u2013388. ACM, New York.\nMR1731590\n[7] Mitzenmacher, M., Richa, A. W. and Sitaraman, R. (2001). The power of two\nrandom choices: A survey of techniques and results. In Handbook of Randomized\nComputing, Vol. I, II. Combinatorial Optimization 9 255\u2013312. Kluwer Academic,\nDordrecht. MR1966907\n[8] Talwar, K. and Wieder, U. (2007). Balanced allocations: The weighted case. In\nSTOC'07-Proceedings of the 39th Annual ACM Symposium on Theory of Computing 256\u2013265. ACM, New York. MR2402449\nDepartment of Mathematics\nWeizmann Institute\nRehovot 76100\nIsrael\nE-mail: itai.benjamini@weizmann.ac.il\n\nToyota Technological Institute\nat Chicago\n6045 S. Kenwood Ave.\nChicago, Illinois 60637\nUSA\nE-mail: yury@ttic.edu\n\n\f"}