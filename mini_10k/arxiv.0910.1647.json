{"id": "http://arxiv.org/abs/0910.1647v2", "guidislink": true, "updated": "2010-01-14T00:09:34Z", "updated_parsed": [2010, 1, 14, 0, 9, 34, 3, 14, 0], "published": "2009-10-09T04:18:50Z", "published_parsed": [2009, 10, 9, 4, 18, 50, 4, 282, 0], "title": "Quantum Gibbs Sampling Using Szegedy Operators", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0910.3176%2C0910.5432%2C0910.2417%2C0910.0794%2C0910.5607%2C0910.4331%2C0910.0735%2C0910.0061%2C0910.2470%2C0910.4557%2C0910.2428%2C0910.5169%2C0910.2525%2C0910.2093%2C0910.0616%2C0910.4576%2C0910.1709%2C0910.5033%2C0910.4718%2C0910.1995%2C0910.3671%2C0910.2960%2C0910.1191%2C0910.5879%2C0910.5561%2C0910.4863%2C0910.3670%2C0910.5312%2C0910.1528%2C0910.1742%2C0910.0611%2C0910.0351%2C0910.2029%2C0910.5104%2C0910.1515%2C0910.3164%2C0910.4379%2C0910.2297%2C0910.5049%2C0910.3035%2C0910.0116%2C0910.4982%2C0910.4783%2C0910.1193%2C0910.0894%2C0910.5371%2C0910.1711%2C0910.3401%2C0910.5150%2C0910.5040%2C0910.3516%2C0910.0340%2C0910.5348%2C0910.3635%2C0910.0928%2C0910.2688%2C0910.1011%2C0910.3454%2C0910.1708%2C0910.3773%2C0910.1647%2C0910.3208%2C0910.0856%2C0910.4319%2C0910.2491%2C0910.3574%2C0910.2237%2C0910.4641%2C0910.3385%2C0910.3368%2C0910.1364%2C0910.3805%2C0910.5760%2C0910.0454%2C0910.4018%2C0910.4010%2C0910.3765%2C0910.3200%2C0910.5175%2C0910.3965%2C0910.2186%2C0910.3976%2C0910.0459%2C0910.3586%2C0910.4316%2C0910.4341%2C0910.5654%2C0910.0314%2C0910.0954%2C0910.5386%2C0910.0709%2C0910.1892%2C0910.5610%2C0910.4859%2C0910.4282%2C0910.4971%2C0910.1809%2C0910.4489%2C0910.0270%2C0910.4522%2C0910.3253&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Quantum Gibbs Sampling Using Szegedy Operators"}, "summary": "We present an algorithm for doing Gibbs sampling on a quantum computer. The\nalgorithm combines phase estimation for a Szegedy operator, and Grover's\nalgorithm. For any $\\epsilon>0$, the algorithm will sample a probability\ndistribution in ${\\cal O}(\\frac{1}{\\sqrt{\\delta}})$ steps with precision ${\\cal\nO}(\\epsilon)$. Here $\\delta$ is the distance between the two largest eigenvalue\nmagnitudes of the transition matrix of the Gibbs Markov chain used in the\nalgorithm. It takes ${\\cal O}(\\frac{1}{\\delta})$ steps to achieve the same\nprecision if one does Gibbs sampling on a classical computer.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0910.3176%2C0910.5432%2C0910.2417%2C0910.0794%2C0910.5607%2C0910.4331%2C0910.0735%2C0910.0061%2C0910.2470%2C0910.4557%2C0910.2428%2C0910.5169%2C0910.2525%2C0910.2093%2C0910.0616%2C0910.4576%2C0910.1709%2C0910.5033%2C0910.4718%2C0910.1995%2C0910.3671%2C0910.2960%2C0910.1191%2C0910.5879%2C0910.5561%2C0910.4863%2C0910.3670%2C0910.5312%2C0910.1528%2C0910.1742%2C0910.0611%2C0910.0351%2C0910.2029%2C0910.5104%2C0910.1515%2C0910.3164%2C0910.4379%2C0910.2297%2C0910.5049%2C0910.3035%2C0910.0116%2C0910.4982%2C0910.4783%2C0910.1193%2C0910.0894%2C0910.5371%2C0910.1711%2C0910.3401%2C0910.5150%2C0910.5040%2C0910.3516%2C0910.0340%2C0910.5348%2C0910.3635%2C0910.0928%2C0910.2688%2C0910.1011%2C0910.3454%2C0910.1708%2C0910.3773%2C0910.1647%2C0910.3208%2C0910.0856%2C0910.4319%2C0910.2491%2C0910.3574%2C0910.2237%2C0910.4641%2C0910.3385%2C0910.3368%2C0910.1364%2C0910.3805%2C0910.5760%2C0910.0454%2C0910.4018%2C0910.4010%2C0910.3765%2C0910.3200%2C0910.5175%2C0910.3965%2C0910.2186%2C0910.3976%2C0910.0459%2C0910.3586%2C0910.4316%2C0910.4341%2C0910.5654%2C0910.0314%2C0910.0954%2C0910.5386%2C0910.0709%2C0910.1892%2C0910.5610%2C0910.4859%2C0910.4282%2C0910.4971%2C0910.1809%2C0910.4489%2C0910.0270%2C0910.4522%2C0910.3253&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We present an algorithm for doing Gibbs sampling on a quantum computer. The\nalgorithm combines phase estimation for a Szegedy operator, and Grover's\nalgorithm. For any $\\epsilon>0$, the algorithm will sample a probability\ndistribution in ${\\cal O}(\\frac{1}{\\sqrt{\\delta}})$ steps with precision ${\\cal\nO}(\\epsilon)$. Here $\\delta$ is the distance between the two largest eigenvalue\nmagnitudes of the transition matrix of the Gibbs Markov chain used in the\nalgorithm. It takes ${\\cal O}(\\frac{1}{\\delta})$ steps to achieve the same\nprecision if one does Gibbs sampling on a classical computer."}, "authors": ["Robert R. Tucci"], "author_detail": {"name": "Robert R. Tucci"}, "author": "Robert R. Tucci", "arxiv_comment": "V1-17 pages(8 files:1 .tex, 2 .sty, 5 .eps);V2-many minor changes to\n  improve larity", "links": [{"href": "http://arxiv.org/abs/0910.1647v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0910.1647v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0910.1647v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0910.1647v2", "journal_reference": null, "doi": null, "fulltext": "arXiv:0910.1647v2 [quant-ph] 14 Jan 2010\n\nQuantum Gibbs Sampling\nUsing Szegedy Operators\nRobert R. Tucci\nP.O. Box 226\nBedford, MA 01730\ntucci@ar-tiste.com\nNovember 24, 2018\n\nAbstract\nWe present an algorithm for doing Gibbs sampling on a quantum computer. The\nalgorithm combines phase estimation for a Szegedy operator, and Grover's algorithm.\nFor any \u01eb > 0, the algorithm will sample a probability distribution in O( \u221a1\u03b4 ) steps with\nprecision O(\u01eb). Here \u03b4 is the distance between the two largest eigenvalue magnitudes\nof the transition matrix of the Gibbs Markov chain used in the algorithm. It takes\nO( 1\u03b4 ) steps to achieve the same precision if one does Gibbs sampling on a classical\ncomputer.\n\n1\n\n\f1\n\nIntroduction\n\nIn Ref.[1], Szegedy proposed a quantum walk operator for each classical Markov\nchain. In Ref.[2], Somma et al. proposed a method for doing simulated annealing on\na quantum computer. In Ref.[3], Wocjan et al. showed how to improve the Somma et\nal. algorithm. The algorithms of Somma et al. and Wocjan et al. both use Szegedy\noperators. In Ref.[4], I presented computer programs called QuSAnn and Multiplexor\nExpander that implement ideas of Refs.[2] and [3], and also some of my own ideas\nabout quantum multiplexors.\nIn Ref.[5], I described one particular algorithm for doing Gibbs and MetropolisHastings sampling of a classical Bayesian network (i.e., a probability distribution) on\na quantum computer. In this paper, I describe a different algorithm for doing Gibbs\nsampling on a quantum computer. Unlike my first algorithm, this one uses Szegedy\noperators. For any \u01eb > 0, this new algorithm will sample a Bayesian network in O( \u221a1\u03b4 )\nsteps with precision O(\u01eb). Here \u03b4 is the distance between the two largest eigenvalue\nmagnitudes of the transition matrix of the Gibbs Markov chain used in the algorithm.\nIt takes O( 1\u03b4 ) steps to achieve the same precision if one does Gibbs sampling on a\nclassical computer.\nThis paper assumes that its reader has read the section entitled \"Notation and\nPreliminaries\" in Ref.[5]. The reader should refer to Refs.[5, 4] for clarification when\nany notation of this paper eludes him.\n\n2\n\nDual Gibbs Markov Chains\n\nIn this section, we will discuss dual \"Gibbs\" Markov chains with transition matrices\nM1 and M2 , respectively. These two transition matrices are both defined in terms of\na single classical Bayesian network x.\n\n2.1\n\nDefinitions of M1 and M2\n\nConsider a classical Bayesian net with Nnds nodes, labeled x1 , x2 , . . . , xNnds where\nxj \u2208 Sxj for each j. (As usual in my papers, I indicate random variables by underlining\nthem.) Let x = (x1 , x2 , . . . , xNnds ). Let x assume values in a set Sx which has\nNS = 2NB elements.\nLet\n\u03c0(x) = P (x = x)\n\n(1)\n\nfor all x \u2208 Sx .\nFor Nnds = 3 and x, y \u2208 Sx , let\nM1 (y|x) = Px1 |x2 x3 (y1 |x2 , x3 )Px2 |x3 x1 (y2 |x3 , y1 )Px3 |x1 x2 (y3 |y1 , y2 ) ,\n2\n\n(2)\n\n\fand\nM2 (y|x) = Px1 |x2 x3 (y1 |y2 , y3 )Px2 |x3 x1 (y2 |y3 , x1 )Px3 |x1 x2 (y3 |x1 , x2 ) .\n\n(3)\n\n(M2 (y|x) can be obtained\nand yi in the conditioned arguments of\nP by swapping xi P\nM1 (y|x).) Note that y M1 (y|x) = 1 and y M2 (y|x) = 1. Define M1 and M2 for\narbitrary Nnds using the same pattern. M1 and M2 are transition matrices of the type\ntypical for Gibbs sampling. (See Ref.[5] for an introduction to Gibbs sampling and\nthe more general Metropolis-Hastings sampling).\nYou can check that \u03c0() is not a detailed balance of either M1 nor M2 separately.\nHowever, the following property is true. We will refer to this property by saying that\n\u03c0() is a detailed balance of the pair (M1 , M2 ).\nClaim 1\nM1 (y|x)\u03c0(x) = M2 (x|y)\u03c0(y)\n\n(4)\n\nfor all x, y \u2208 Sx .\nproof:\nLet P (xj , xk , . . .) stand for P (xj = xj , xk = xk , . . .). Assume Nnds = 3 to begin\nwith. One has\nP (y1|x2 , x3 )P (y2|x3 , y1 )P (y3|y1 , y2 )\nM1 (y|x)\n=\nM2 (x|y)\nP (x1 |x2 , x3 )P (x2 |x3 , y1 )P (x3 |y1 , y2 )\nP (y1, x2 , x3 )P (y2, x3 , y1 )P (y3, y1 , y2 )\n=\nP (x1 , x2 , x3 )P (x2 , x3 , y1 )P (x3 , y1 , y2 )\nP (y1 , x2 , x3 )P (y1, y2 , x3 )P (y)\n=\nP (x)P (y1, x2 , x3 )P (y1 , y2, x3 )\nP (y)\n.\n=\nP (x)\n\n(5)\n(6)\n(7)\n(8)\n\nA proof for an arbitrary number Nnds of nodes follows the same pattern.\nQED\n\n2.2\n\nEigenvalues of M1 , M2 and Mhyb\n\nLet\n\u039bj (y|x) =\n\nq\n\nMj (y|x) ,\n\n(9)\n\nfor j = 1, 2 and x, y \u2208 Sx . It's convenient to define a hybrid function of M1 and M2 ,\nas follows:\n3\n\n\fMhyb (y|x) = \u039b2 (x|y)\u039b1(y|x)\n\n(10)\n\nfor x, y \u2208 Sx . (Note that unlike M1 (y|x) and M2 (y|x), Mhyb (y|x) is not a probability\nfunction in y, its first argument.)\nDefine the quantum states\nX\n|(\u03c0)\u03b7 i =\n[\u03c0(x)]\u03b7 |xi\n(11)\nx\n\n1\n, 1.\n2\n\nfor \u03b7 =\n(Note that only the \u03b7 =\nmechanics.)\n\n1\n2\n\nstate is normalized in the sense of quantum\n\nClaim 2\nMj |\u03c0i = |\u03c0i for j = 1, 2 ,\n\n(12)\n\n\u221a\n\u221a\nMhyb | \u03c0i = | \u03c0i .\n\n(13)\n\nand\n\nAlso, M1 , M2 and Mhyb have the same eigenvalues.\nproof:\n\nTaking the square root of both sides of the pair detailed balance statement\nEq.(4), we get\np\np\n\u039b1 (y|x) \u03c0(x) = \u039b2 (x|y) \u03c0(y) .\n\nTherefore,\n\nHence,\n\np\np\n1\n1\nMhyb (y|x) = \u039b2 (x|y) p\n\u039b2 (x|y) \u03c0(y) = p\nM2 (x|y) \u03c0(y) .\n\u03c0(x)\n\u03c0(x)\nX\n\nM1 (y|x)\u03c0(x) =\n\nX\n\nM2 (x|y)\u03c0(y) =\n\nx\n\ny\n\n(14)\n\n(15)\n\nX\n\nM2 (x|y)\u03c0(y) = \u03c0(y) ,\n\n(16)\n\nX\n\nM1 (y|x)\u03c0(x) = \u03c0(x) ,\n\n(17)\n\nx\n\ny\n\nand\nX\nx\n\nX 1\np\np\np\np\np\nMhyb (y|x) \u03c0(x) =\nM2 (x|y) \u03c0(y) \u03c0(x) = \u03c0(y) .\n\u03c0(x)\nx\n\n(18)\n\nOrder the elements of the finite set Sx in some preferred way. Use this preferred\norder to represent M1 , M2 and Mhyb as matrices. Define a diagonal matrix D whose\n4\n\n\fdiagonal entries are the numbers \u03c0(x) for each x \u2208 Sx , with the x ordered in the\npreferred order:\nD = diag[(\u03c0(x))\u2200x ] .\n\n(19)\n\nSince\n1\n\n1\n\nT\nM2T = D \u22121 M1 D , Mhyb\n= D \u2212 2 M2 D 2 ,\n\n(20)\n\ndet(M1 \u2212 \u03bb) = det(M2 \u2212 \u03bb) = det(Mhyb \u2212 \u03bb)\n\n(21)\n\nit follows that\n\nfor any \u03bb \u2208 C.\nQED\nLet the eigenvalues1 of Mhyb (and also of M1 and M2 ) be m0 , m1 , . . . mNS \u22121 \u2208 C\nwith m0 = 1 > |m1 | \u2265 |m2 | . . . \u2265 |mNS \u22121 |. Define |mj i to be the corresponding\neigenvectors of Mhyb (but not necessarily of M1 and M2 ). Thus\nMhyb |mj i = mj |mj i ,\n(22)\n\u221a\nfor j = 0, 1, . . . , NS \u2212 1. In particular, |m0 i = | \u03c0i.\nFor each j, define \u03c6j \u2208 [0, \u03c02 ] and \u03b7j \u2208 [0, 2\u03c0) so that mj = ei\u03b7j cos \u03c6j . (Thus,\ncos \u03c6j \u2265 0). Note that m0 = 1 so \u03c60 = 0. The M1 eigenvalue gap \u03b4 is defined as\n\u03c62\n\u03b4 = 1 \u2212 |m1 |. \u03b4 \u2248 21 when \u03c61 is small.\n\nQ-Embeddings U1 and U2\n\n3\n\nIn this section, we will define a \"q-embedding\" Uj of Mj , for j = 1, 2. (For more\ninformation about q-embeddings, see Ref.[5].)\nFor simplicity, we begin this section by considering a Bayesian net with only\n3 nodes x1 , x2 , x3 , and such that each of these nodes is binary (i.e., Sxj = Bool for\nj = 1, 2, 3). At the end of this section, we will show how to remove these restrictions\nand make our treatment valid for general Bayesian networks.\nUsing the same language as Ref.[5], consider a unitary matrix U1 of the form\nshown in Fig.1, with its multiplexor gates defined as follows. Let xj hki \u2208 Bool\nand x\u2032j hki \u2208 Bool for any j, k. U1 has 3 analogous gates (a.k.a. nodes) labeled\n(x\u20321 h2i, x3 h2i, x2 h2i), (x\u20322 h3i, x\u20321 h3i, x3 h3i), and (x\u20323 h4i, x\u20322 h4i, x\u20321 h4i). Consider the first\nof these for definiteness. Let the probability amplitude A(x\u20321 h2i, x3 h2i, x2h2i|x\u20321 h1i, x3 h1i, x2 h1i)\nof node (x\u20321 h2i, x3 h2i, x2 h2i) satisfy the constraint\n1\n\nThere must be a single eigenvalue 1 and all others must have a magnitude strictly smaller than\none because of the Frobenius-Perron Theorem. The eigenvalues may be complex.\n\n5\n\n\f2\n3\n\nU1 =\n\n4\n\n2\n2\n\n3\n3\n\n4\n\nRy\n\nRy\n\n4\n\nRy\n\nx1\n\n1\n\nx2\n\n1\n\nx3\n\n1\n\nx1\nx2\n\n1\n\nx3\n\n1\n\n1\n\nFigure 1: Unitary matrix U1 expressed as a product of quantum multiplexors.\n\nA(x\u20321 h2i, x3 h2i, x2 h2i|x\u20321 h1i = 0, x3 h1i, x2h1i)\nq\nx h1i x h1i\n=\nPx1 |x3 ,x2 (x\u20321 h2i|x3 h2i, x2 h2i)\u03b4x22h2i \u03b4x33h2i .\n\n(23)\n(24)\n\nIf we indicate non-zero entries by a plus sign,\n\n000\n(x\u20321 , x3 , x2 )= 000\n\n001\n\n+\n+\n\n001\n\n+\n\n010\n\nA =\n\n010\n\n011\n100\n\n+\n+\n\n101\n\n+\n\n110\n111\n\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\nG\n#\n\n\u2192\n\nX\n\n~b\u2208Bool2\n\nei\u03b8~b \u03c3Y \u2297 P~b =\n\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\nG\n#\n\n***\n***\n***\n***\n+ ***\n***\n***\n***\n+ ***\n\n011\n\n,\n\n(25)\n\n(26)\n\nfor some \u03b8~b \u2208 R. Here the right pointing arrow means that the expression at the\norigin of the arrow can be extended to the expression at the target of the arrow.\nFrom the above definition of U1 , it follows that, for x, x\u2032 , y, y \u2032 \u2208 Bool3 ,\n\n6\n\n\fhy|\n|xi\n\u2032 U1\nhy |\n|0i\u22973\n\n|x1 i\n\n\uf8f1\nhy1 |\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nhy2 |\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 hy3 |\n\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b |x i\nG\n#\n2\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\nG\n#\n\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b |x i\nG\n#\n3\n\n\uf8f4\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b G\n\uf8f4\n#\nhy1\u2032 | G\n#\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\n\uf8f4\nhy2\u2032 | G\n#\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\nhy3\u2032 |\n= \u039b1 (y \u2032|x)\u03b4(y, x) .\n\n|0i\n\n=\n\n(27)\n\n|0i\n|0i\n\n(28)\n\nHence,\n\nU1\n\n|xi\n\n|xi\n\n=\n\n|xi\n\n\u039b1\n\n|0i\u22973\n\nRy\n\n4\n4\n\nU2 =\n\nor U1 |0i\u22973 |xi = (\u039b1 |xi)|xi .\n\nRy\n\n4\n\nx1\n\n1\n\nx2\n\n1\n\nx3\n\n1\n\n2\n\nx1\n\n1\n\n2\n\nx2\n\n1\n\nx3\n\n1\n\n3\n3\n3\n\nRy\n\n2\n\n(29)\n\nFigure 2: Unitary matrix U2 expressed as a product of quantum multiplexors.\nBesides U1 , it is convenient to consider another unitary matrix called U2 . We\ndefine U2 to be of the form of Fig.2, where the multiplexors are defined in such a way\nthat U2 satisfies, for all x, x\u2032 , y, y \u2032 \u2208 Bool3 ,\n\nhy|\n|0i\u22973\n\u2032 U2\n|x\u2032 i\nhy |\n\n\uf8f1\n|0i\nhy1 |\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\n\uf8f4\nhy2 | G\n#\n|0i\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 hy | #\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b G\n#\nG\n|0i\n3\n=\n\uf8f4\n\uf8f4\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b #\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b |x\u2032 i\nhy1\u2032 |\n\uf8f4\n#\nG\nG\n1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\u001f\u001e\u001d\u001c\n\u0018\u0019\u001a\u001b |x\u2032 i\n\uf8f4\n#\nG\nhy2\u2032 |\n\uf8f4\n2\n\uf8f4\n\uf8f3\nhy3\u2032 | \u2032\n|x\u20323 i\n\u2032\n\u2032\n= \u039b2 (y|x )\u03b4(y , x ) .\n7\n\n(30)\n\n(31)\n\n\fHence\n\nU2\n\n|0i\u22973\n\n\u039b2\n\n=\n\n\u2032\n\n|x\u2032 i\n\u2032\n\n|x i\n\n|x i\n\nor U2 |x\u2032 i|0i\u22973 = |x\u2032 i(\u039b2 |x\u2032 i) .\n\n(32)\n\nUj is called the q-embedding of Mj for j = 1, 2.\n\nNBa\n\nA=\n\nRy\nRy\n\nNBb\n\nRy\nFigure 3: The unitary matrix A is a quantum embedding of a probability matrix\nP (b|a), where a has NBa bits and b has NBb bits.\nSo far we have considered the q-embeddings U1 and U2 for the case of a classical\nBayesian network x with 3 binary nodes. What if x has Nnds nodes and some of those\nnodes have more than 2 states? In that case, we must use several qubits (horizontal\nlines) for each node xi (and an equal number of qubits for the dual node x\u2032i ) in\nFigs.1 and 2. More specifically, suppose P (x1 |x2 , x3 , . . . , xNnds ) equals P (b|a) where\na \u2208 BoolNBa and b \u2208 BoolNBb . For the number of bits NBa , define the number of\nstates NSa = 2NBa . Likewise, let NSb = 2NBb . The constraint Eq.(24) generalizes to\nA(b, \u00e3|b\u0303 = 0, a) =\n\np\nP (b|a)\u03b4a\u00e3 ,\n\n(33)\n\nwhere a, \u00e3 \u2208 BoolNBa and b, b\u0303 \u2208 BoolNBb . Eq.(33) can be expressed in matrix form\nas follows:\n(b\u0303 = 0, a) \u2192\n(b, \u00e3)\nD 0,0\n[A(b, \u00e3|b\u0303 = 0, a)] =\n,\n\u2193\nD 1,0\n***\nD NSb \u22121,0\n\n(34)\n\nwhere, for all b \u2208 BoolNBb , D b,0 \u2208 RNSa XNSa are diagonal matrices with entries\n(D b,0 )a,\u00e3 =\n\np\nP (b|a)\u03b4a\u00e3 .\n\n8\n\n(35)\n\n\fBy adding more columns to the matrix of Eq.(34), one can extended it (see section\nentitled \"Q-Embeddings\" in Ref.[5]) to a square matrix which can be expressed in\nterms of multiplexors as in Fig.3.\nThe Markov Blanket MB(i) for a node xi of the classical Bayesian network x\nsatisfies (see section entitled \"Notation and Preliminaries\" in Ref.[5])\nP (xi |x{i}c ) = P (xi |xM B(i) ) .\n\n(36)\n\nU = U2\u2020 U1 .\n\n(37)\n\nIf the set MB(i) is strictly smaller than the set {i}c , this property can be used to\nreduce the number of controls for the multiplexor in U1 and U2 corresponding to\nP (xi |x{i}c ).\nGiven the two q-embeddings U1 and U2 for a Bayesian network x, we can define\na unitary matrix U as follows\n\nMatrix U has the following highly desirable property:\nClaim 3 For any j, k \u2208 {0, 1, . . . , NS \u2212 1},\n|mk i\nh0|\n= mj \u03b4jk .\nU\n|0i\nhmj |\n\n(38)\n\nproof:\nh0| \u2020\n|mk i\nU2 U1\nhmj |\n|0i\n\n=\n\nX\n\n=\n\nX\n\ny,x\n\ny,x\n\nhmj |yi\n\n\u0014\n\nhy|\u039bT2\nhy|\n\n\u0015\u0014\n\n|xi\n\u039b1 |xi\n\n\u0015\n\nhmj |yi\u039bT2 (y|x)\u039b1(y|x)hx|mk i\n\n= hmj |Mhyb |mk i = mj \u03b4jk .\n\nhx|mk i\n\n(39)\n(40)\n(41)\n\nQED\n\n4\n\nSzegedy Quantum Walk Operator W\n\nIn this section, we will define a special type of Szegedy quantum walk operator W\ncorresponding to a Bayesian net x. We will then find the eigenvalues of W .\n\n4.1\n\nDefinition of W\n\nAs in Ref.[4], define the projection operator \u03c0\u0302 and its dual projection operator \u03c0\u030c by\n\n9\n\n\f\u03c0\u0302 =\n\n|0ih0|\n-\n, \u03c0\u030c =l \u03c0\u0302 l=\n.\n-\n|0ih0|\n\n(42)\n\nW = U(\u22121)\u03c0\u030c U \u2020 (\u22121)\u03c0\u0302 .\n\n(43)\n\nThen the Szegedy quantum walk operator W for the Bayesian net x is defined by\n\n4.2\n\nEigenvalues of W\n\nTo find the eigenvalues of W , we will use the following identities.\nClaim 4\n\u03c0\u0302|mj 0i = |mj 0i ,\n\n(44a)\n\n\u03c0\u0302(U l)|mj 0i = mj |mj 0i ,\n\n(44b)\n\n\u03c0\u0302(l U \u2020 )|mj 0i = m\u2217j |mj 0i ,\n\n(44c)\n\nfor all j \u2208 {0, 1, . . . , NS \u2212 1}.\nproof:\nFrom the definition of \u03c0\u0302, we see that\n\u03c0\u0302\n\n|0i\n|0i\n.\n=\n|mj i\n|mj i\n\n(45)\n\nAlso,\n\u03c0\u0302(U l)\n\nX\n|0i\n|mj i\n|0ih0|\n|0i\n,\n= mj\nU\n=\n|mj i\n|0i\n|mk ihmk |\n|mj i\n\n(46)\n\n\u03c0\u0302(l U \u2020 )\n\nX |0ihmk |\n|0i\n|0i\n|0i\nU\u2020\n= m\u2217j\n.\n=\n|mk ih0|\n|mj i\n|mj i\n|mj i\n\n(47)\n\nk\n\nand\n\nk\n\nQED\nAn immediate consequence of Claim 4 is that\nhmj 0|U l |mk 0i = hmj 0|\u03c0\u0302U l |mk 0i = mj \u03b4jk ,\n\n(48)\n\nfor j, k \u2208 {0, 1, . . . , NS \u2212 1}.\nNote that since m0 = 1, Eq.(48) implies that\n|m0 0i = U l |m0 0i .\n10\n\n(49)\n\n\fAnother consequence of Claim 4 is that |m0 0i is a stationary state of W .\nIndeed, one has\nW |m0 0i =\n=\n=\n=\n=\n\nU(\u22121)\u03c0\u030c U \u2020 (\u22121)\u03c0\u0302 |m0 0i\nU l (1 \u2212 2\u03c0\u0302) l U \u2020 (\u22121)|m0 0i\n(1 \u2212 2m0 U l)(\u22121)|m0 0i\n(1 \u2212 2)(\u22121)|m0 0i\n|m0 0i .\n\n(50)\n(51)\n(52)\n(53)\n(54)\n\nLet\nj\nVbusy\n= span{|mj 0i, U l |mj 0i}\n\n(55)\n\nfor j \u2208 {0, 1, . . . , NS \u2212 1}. (By \"span\" we mean all linear combinations of these\nvectors with complex coefficients.)\nj\nj\nClaim 5 W Vbusy\n= Vbusy\nfor all j \u2208 {0, 1, . . . , NS \u2212 1}. For j = 0, let\n\n|\u03c80 i = |m0 0i .\n\n(56)\n\n0\n{|\u03c80 i} is an orthonormal basis for Vbusy\nand W |\u03c80 i = |\u03c80 i. For j 6= 0, let\n\n|\u03c8\u00b1j i = \u221a\n\n\u00b1i\n(e\u2212i\u03b7j U l |mj 0i \u2212 e\u00b1i2\u03c6j |mj 0i) .\n2 sin \u03c6j\n\n(57)\n\nj\n{|\u03c8j i, |\u03c8\u2212j i} is an orthonormal basis for Vbusy\nand W |\u03c8\u00b1j i = e\u00b1i2\u03c6j |\u03c8\u00b1j i.\n\nproof:\nUsing the identities of Claim 4, one finds after some algebra that\nW |mj 0i = (\u22121)|mj 0i + (2m\u2217j )U l |mj 0i ,\n\n(58a)\n\nW (U l)|mj 0i = (\u22122mj )|mj 0i + (\u22121 + 4|mj |2 )U l |mj 0i\n\n(58b)\n\nand\n\nfor all j.\nj\nAccording to Eqs.(58), Vbusy\nis invariant under the action of W for each j. By\nj\nvirtue of Eq.(48), Vbusy is 1-dim for j = 0 and 2-dim if j 6= 0. We've already proven\nthat |m0 0i is a stationary state of W .\nNow consider a fixed j 6= 0. Both U(\u22121)\u03c0\u030c U \u2020 and (\u22121)\u03c0\u0302 are reflections, and\nreflections are a special type of orthogonal matrix, so the product of these 2 orthogonal matrices is also an orthogonal matrix. In fact, it's a rotation about the axis\nj\nperpendicular to the planar subspace Vbusy\n. The vectors |mj 0i, and U l |mj 0i} are\n\n11\n\n\f| e 2j\n\ne\n\ni\u03b7\nj\n\nU |mj 0\n\n\u03c6j\n|mj 0 = | e 1j\nFigure 4: Definition of |e1j i and |e2j i.\nindependent but not orthogonal. However, we can express them in terms of orthogonal vectors (see Fig.4) as follows:\n|mj 0i = |e1j i ,\n\n(59a)\n\ne\u2212i\u03b7j U l |mj 0i = cos(\u03c6j )|e1j i + sin(\u03c6j )|e2j i .\n\n(59b)\n\nand\n\nIn the |e1j i, |e2j i basis, we find after substituting mj = ei\u03b7j cos(\u03c6j ) into Eqs.(58) that\n\u0015\n\u0014\ncos(2\u03c6j ) sin(2\u03c6j )\n.\n(60)\nW =\n\u2212 sin(2\u03c6j ) cos(2\u03c6j )\n\nThe eigenvalues of this matrix are e\u00b1i2\u03c6j , with corresponding eigenvectors:\n1\n|\u03c8\u00b1j i = \u221a (|e1j i \u00b1 |e2j i) .\n2\n\n(61)\n\nh\u03c8\u2212j |\u03c8j i = 0 , h\u03c8j |\u03c8j i = h\u03c8\u2212j |\u03c8\u2212j i = 1 .\n\n(62)\n\nThese eigenvectors satisfy\n\nBy expressing |e1j i and |e2j i in Eq.(61) in the original basis, we get Eq.(57).\nQED\nDefine the following vector spaces:\nV = span{|xi \u2297 |yi : x, y \u2208 Sx } ,\n\n(63)\n\nVA = span{|xi \u2297 |0i : x \u2208 Sx } ,\n\n(64)\n\nVB = U l VA ,\n\n(65)\n\nVbusy = VA + VB .\n\n(66)\n\nand\n\n12\n\n\f\u22a5\nV can be expressed as a direct sum of Vbusy and its orthogonal complement Vbusy\n:\n\u22a5\nV = Vbusy \u2295 Vbusy\n.\n\n(67)\n\nj\nFrom Claim 5, it follows that Vbusy is a direct sum of the subspaces Vbusy\n:\n\nVbusy =\n\nN\nS \u22121\nM\nj=0\n\nj\nVbusy\n.\n\n(68)\n\nRecall that matrices M1 , M2 and Mhyb are NS dimensional whereas W is NS2 dimensional. Since the size of Sx is NS , dim(V) = NS2 . From Eq.(68) and Claim 5,\ndim(Vbusy ) = 2NS \u2212 1. Furthermore, {|\u03c8j i : j = 0, \u00b11, \u00b12, . . . , \u00b1(NS \u2212 1)} is an\northonormal basis for Vbusy .\nAt this point we've explained the action of W on Vbusy , but we haven't said\n\u22a5\nanything about the action of W on Vbusy\n. Next we show that W acts simply as the\n\u22a5\n\u22a5\nidentity on Vbusy . (This is what one would expect since the vectors in Vbusy\nare parallel\nto the axis of the W rotation.) Recall that if S and T are subspaces of a vector space\nV, then (S + T )\u22a5 = S \u22a5 \u2229 T \u22a5 . Therefore,\n\u22a5\nVbusy\n= VA\u22a5 \u2229 VB\u22a5 .\n\n(69)\n\nVA\u22a5 = span{|xi \u2297 |yi : x \u2208 Sx , and y \u2208 Sx \u2212 {0}} ,\n\n(70)\n\nVB\u22a5 = U l (VA\u22a5 ) .\n\n(71)\n\nW |\u03c6i = |\u03c6i\n\n(72)\n\nFrom the definitions of VA and VB , it's easy to see that\nand\n\nClaim 6\n\u22a5\nfor all |\u03c6i \u2208 Vbusy\n.\n\n\u22a5\nproof: Let |\u03c6i \u2208 Vbusy\n= VA\u22a5 \u2229 VB\u22a5 . Hence |\u03c6i \u2208 VA\u22a5 and |\u03c6i = U l |\u03b8i for some\n\u22a5\n|\u03b8i \u2208 VA .\n\nU(\u22121)\u03c0\u030c U \u2020 (\u22121)\u03c0\u0302 |\u03c6i =\n=\n=\n=\n\nU l (\u22121)\u03c0\u0302 l U \u2020 (\u22121)0 |\u03c6i\nU l (1 \u2212 2\u03c0\u0302) l U \u2020 U l |\u03b8i\nU l (1 \u2212 2\u03c0\u0302)|\u03b8i\n|\u03c6i .\n\nQED\n13\n\n(73)\n(74)\n(75)\n(76)\n\n\fIt's interesting to compare the present paper with Ref.[4]. For Ref.[4], M1 =\nM2 = M and \u03c0() is a standard detailed balance for M instead of a detailed balance\nfor the pair (M1 , M2 ). For Ref.[4], Mhyb = Msym , mj = m\u2217j , U1 = \u01d3 , U2 = \u00db ,\nU = U2\u2020 U1 = \u00db \u2020 \u01d3 , U =l U \u2020 l. When U =l U \u2020 l as in Ref.[4], Eq.(44b) and Eq.(44c)\nare essentially identical, whereas in the M1 6= M2 case, it's less obvious that these\ntwo equations are true simultaneously.\n\n5\n\nQuantum Gibbs Sampling Algorithm\n\nIn this section, we will describe an algorithm for doing Gibbs sampling on a quantum\ncomputer, utilizing the Szegedy operator W that we have so painstakingly discussed\nin previous sections.\nWe begin by choosing2 some x0 \u2208 Sx for which P (x = x0 ) 6= 0. Now define\n|x0 0i = |x = x0 i \u2297 |0i\u2297NB .\n\n(77)\n\np\n\u221a\nh\u03c80 |x0 0i = h \u03c0|x = x0 i = \u03c0(x0 ) .\n\n(78)\n\nRbeg = (\u22121)|x0 0ihx0 0| ,\n\n(79)\n\nNote that |x0 0i \u2208 Vbusy and\np\n\np\n\n\u03c0(x) = P (x) can be easily evaluated at a single point x = x0 . Our quantum\nGibbs algorithm consists of performing the original Grover algorithm with beginning\nstate |x0 0i and target state |\u03c80 i. Define the following 2 reflection operators\nand\n\nRbeg Rtar\n\nRtar = (\u22121)|\u03c80 ih\u03c80 | .\n(80)\np\nis a rotation by an angle O( \u03c0(x0 )) in space span{|\u03c80 i, |x0 0i} \u2282 Vbusy . Let\n1\n).\nL = O( p\n\u03c0(x0 )\n\n(81)\n\np\n\u221a\nIf \u03c0(x0 ) = O(1/ NS ), then L iterations of Rbeg Rtar will take the beginning state\nto the target state.3 To implement this use of Grover's algorithm, we need to compile\n(with polynomial efficiency) the operator Rbeg Rtar . Rbeg is easy to compile; it's just\na single multiply-controlled phase. Next, we will explain how to compile Rtar .\n2\n\nPerhaps some symmetry of the physical situation being modeled by the Bayesian network x\nwill suggest some x value that has non-zero probability. Alternatively, one can proceed as follows.\nFor definiteness, consider a Bayesian net x = (x1 , x2 , x3 ) with 3 nodes. Suppose P (x3 , x2 , x1 ) =\nP (x3 |x2 , x1 )P (x2 |x1 )P (x1 ) and the functions Px3 |x2 ,x1 Px2 |x1 and Px1 are known. Choose y1 \u2208 Sx1\nsuch that Px1 (y1 ) 6= 0. Then choose y2 \u2208 Sx2 such that Px2 |x1 (y2 |y1 ) 6= 0. Finally, choose y3 \u2208 Sx3\nsuch that Px3 |x2 ,x1 (y3 |y2 , y1 ) 6= 0. Set x0 = (y1 , y2 , yp\n3 ).\n\u221a\n3\nWe will discuss in a future paper what to do if \u03c0(x0 ) is much larger than O(1/ NS ).\n\n14\n\n\fH\n\nH\n\nH\n\nH\n\nH\n\nH\n\nV\u03b2\n\nH\n\nW\n\n2 a-1\n\nW\n\n1\n2\n\nW\n\n0\n2\n\nH\n\nH\n\nH\n\nH\n\nW\n\n2 NB + ac\n\nH\n\n2a-1\n\nW\n\n21\n\nW\n\n20\n\nbits\n\na\nbits\n\n2 NB\nbits\n\nFigure 5: Definition of operator V\u03b2 for Szegedy operator W .\n\nFig.5, which is identical to Fig.18 in Ref.[4], defines an operator V\u03b2 in terms\nof multiple (modified) phase estimation steps. The V\u03b2 of Ref.[4] depends on a parameter \u03b2 (inverse temperature) because the operator M in that paper depends on this\nparameter. V\u03b2 in the present paper does not depend on \u03b2 (because the Bayesian net\nx doesn't) so we will drop the \u03b2 subscript from it henceforth, and refer to it simply\nas V . V does not depend on \u03b2 but it still depends on the positive integers a and c.\n(In the language of Ref.[4], a=number of probe bits for each PE (Phase Estimation)\nstep, and c=number of PE steps). Note that operator W is applied 2a c times by V .\nLet |0ac i = |0i\u2297(ac) , J = {0, \u00b11, \u00b12, . . . , \u00b1(NS \u2212 1)}, and J \u2032 = J \u2212 {0}.\nAccording to Lemma 2 of Ref.[3], for any \u01eb2 > 0, if we adjust the integers a and c so\nthat\n2a \u2248\n\n1\n1\n= O( \u221a ) ,\n\u2206\n\u03b4\n\n(82)\n\nand\n1\nc \u2248 log2 ( \u221a ) ,\n\u01eb2\n\n(83)\n\n(recall \u03b4 = 1 \u2212 |m1 | is the distance between the two largest eigenvalue magnitudes of\nM1 ), then V acts on the space Vbusy \u2297 |0ac i as follows:\nV =\n\nX |\u03c7j ih0ac |\n\u221a\n|0ac ih0ac |\n+ O( \u01eb2 ) ,\n+\n|\u03c8j ih\u03c8j |\n|\u03c80 ih\u03c80 |\n\u2032\n\n(84)\n\nj\u2208J\n\nwhere the |\u03c7j i are states of ac qubits such that h0ac |\u03c7j i = 0. In Eq.(84) and for the\nremainder of this section, the top row represents the ac ancilla qubits shown in Fig.5,\nand the bottom row represents the 2NB qubits on which W operates.\n\n15\n\n\fNow define\n\nac ih0ac |\n\nQ = (\u22121)|0\n\n= 1 \u2212 2|0ac ih0ac | ,\n\n(85)\n\nand\nR\u0303tar = V \u2020\n\nQ\nV .\n-\n\n(86)\n\nIt follows that for any |\u03c8i \u2208 Vbusy ,\nR\u0303tar\n\n|0ac i\n|\u03c8i\n\n\u0015 ac\n|0ac ih0ac |\n|0 i\nV\n= 1 \u2212 2V\n-\n|\u03c8i\n\u0015 ac\n\u0014\nac\nac\n\u221a\n|0 ih0 |\n|0 i\n= 1\u22122\n+ O( \u01eb2 )\n|\u03c80 ih\u03c80 |\n|\u03c8i\nac\nac\n\u221a\n|0 i\n|0 i\n=\n+\n+ O( \u01eb2 )\n|\u03c8i\n(\u22122|\u03c80 ih\u03c80 |)|\u03c8i\n\u221a\n|0ac i\n=\n+ O( \u01eb2 ) .\nRtar |\u03c8i\n\u0014\n\n\u2020\n\n(87)\n(88)\n(89)\n(90)\n\nEq.(90) is the essence of Corollary 2 in Ref.[3]. It means that Rtar acting on Vbusy\ncan be approximated by R\u0303tar acting on Vbusy \u2297 |0ac i. Since we already know how to\ncompile R\u0303tar , we have accomplished our goal of compiling Rtar , at least approximately.\nNext, we will try to estimate the error of our quantum Gibbs algorithm. Suppose \u03c0\u0303() is our estimate of \u03c0(). Note that for any x \u2208 Sx ,\np\np\np\n\u03c0(x) \u2212 \u03c0\u0303(x))( \u03c0(x) + \u03c0\u0303(x))|\np\np\n\u2264 2| \u03c0(x) \u2212 \u03c0\u0303(x)| .\n\n|\u03c0(x) \u2212 \u03c0\u0303(x)| = |(\n\np\n\n(91)\n(92)\n\nSuppose \u01eb > 0 is defined so that\nmax |\nx\n\np\n\n\u03c0(x) \u2212\n\np\n\u03c0\u0303(x)| \u2264 \u01eb .\n\n(93)\n\nThen, since we apply the Rbeg Rtar operator a total of L times, and each time we can\n\u221a\nincur an error of \u01eb2 ,\n\u221a\n\u01eb \u2248 L \u01eb2 .\n\n(94)\n\nIf we define one step as one W application, then the total number of steps for the\nwhole algorithm is O(L2a c) = O( \u221aL\u03b4 log2 ( L\u01eb )). Thus, our algorithm will yield a sample\nof the classical Bayesian net x with precision O(\u01eb), in O( \u221aL\u03b4 log2 ( L\u01eb )) steps. Achieving\nthe same precision with a classical Gibbs sampling algorithm would require O( 1\u03b4 )\nsteps.\n\n16\n\n\fThe Szegedy operator W of this paper can also be used to do quantum simt\nulated annealing and Metropolis-Hastings if the marginals P (xt+1\ni |x{i}c ) can be calculated for each i from the transition matrix P (xt+1 |xt ). (In the case of simulated\nannealing, P (xt+1 |xt ) is different for each \u03b2i of the annealing schedule).\n\nReferences\n[1] Mario Szegedy, \"Spectra\narXiv:quant-ph/0401053\n[2] R. Somma, S. Boixo,\narXiv:0712.1008\n\nof\n\nQuantized\n\nH. Barnum,\n\nWalks\n\nand\n\na\n\n\u221a\n\n\u03b4\u01eb\n\nrule\",\n\n\"Quantum Simulated Annealing\",\n\n[3] Pawel Wocjan, Anura Abeyesinghe, \"Speed-up via Quantum Sampling\",\narXiv:0804.4259\n[4] R.R. Tucci, \"Code\narXiv:0908.1633\n\nGenerator\n\nfor\n\nQuantum\n\nSimulated\n\nAnnealing\",\n\n[5] R.R. Tucci, \"Use of a Quantum Computer to do Importance and MetropolisHastings Sampling of a Classical Bayesian Network\", arXiv:0811.1792\n\n17\n\n\f"}