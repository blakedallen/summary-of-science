{"id": "http://arxiv.org/abs/math/0702095v1", "guidislink": true, "updated": "2007-02-05T12:39:19Z", "updated_parsed": [2007, 2, 5, 12, 39, 19, 0, 36, 0], "published": "2007-02-05T12:39:19Z", "published_parsed": [2007, 2, 5, 12, 39, 19, 0, 36, 0], "title": "Extinction versus unbounded growth; Habilitation Thesis of the\n  University Erlangen-N\u00fcrnberg", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0702075%2Cmath%2F0702500%2Cmath%2F0702385%2Cmath%2F0702648%2Cmath%2F0702501%2Cmath%2F0702194%2Cmath%2F0702671%2Cmath%2F0702386%2Cmath%2F0702336%2Cmath%2F0702230%2Cmath%2F0702046%2Cmath%2F0702084%2Cmath%2F0702348%2Cmath%2F0702392%2Cmath%2F0702265%2Cmath%2F0702518%2Cmath%2F0702591%2Cmath%2F0702752%2Cmath%2F0702002%2Cmath%2F0702489%2Cmath%2F0702766%2Cmath%2F0702703%2Cmath%2F0702735%2Cmath%2F0702552%2Cmath%2F0702627%2Cmath%2F0702569%2Cmath%2F0702202%2Cmath%2F0702155%2Cmath%2F0702512%2Cmath%2F0702303%2Cmath%2F0702610%2Cmath%2F0702748%2Cmath%2F0702102%2Cmath%2F0702699%2Cmath%2F0702032%2Cmath%2F0702492%2Cmath%2F0702097%2Cmath%2F0702448%2Cmath%2F0702299%2Cmath%2F0702618%2Cmath%2F0702179%2Cmath%2F0702704%2Cmath%2F0702289%2Cmath%2F0702542%2Cmath%2F0702172%2Cmath%2F0702144%2Cmath%2F0702170%2Cmath%2F0702420%2Cmath%2F0702519%2Cmath%2F0702815%2Cmath%2F0702886%2Cmath%2F0702611%2Cmath%2F0702318%2Cmath%2F0702334%2Cmath%2F0702875%2Cmath%2F0702851%2Cmath%2F0702128%2Cmath%2F0702653%2Cmath%2F0702564%2Cmath%2F0702589%2Cmath%2F0702269%2Cmath%2F0702628%2Cmath%2F0702043%2Cmath%2F0702563%2Cmath%2F0702660%2Cmath%2F0702693%2Cmath%2F0702162%2Cmath%2F0702095%2Cmath%2F0702675%2Cmath%2F0702780%2Cmath%2F0702200%2Cmath%2F0702281%2Cmath%2F0702593%2Cmath%2F0702583%2Cmath%2F0702636%2Cmath%2F0702587%2Cmath%2F0702019%2Cmath%2F0702189%2Cmath%2F0702206%2Cmath%2F0702471%2Cmath%2F0702094%2Cmath%2F0702868%2Cmath%2F0702397%2Cmath%2F0702090%2Cmath%2F0702773%2Cmath%2F0702005%2Cmath%2F0702662%2Cmath%2F0702783%2Cmath%2F0702357%2Cmath%2F0702261%2Cmath%2F0702678%2Cmath%2F0702330%2Cmath%2F0702891%2Cmath%2F0702379%2Cmath%2F0702616%2Cmath%2F0702781%2Cmath%2F0702827%2Cmath%2F0702553%2Cmath%2F0702264%2Cmath%2F0702338%2Cmath%2F0702173&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Extinction versus unbounded growth; Habilitation Thesis of the\n  University Erlangen-N\u00fcrnberg"}, "summary": "Certain Markov processes, or deterministic evolution equations, have the\nproperty that they are dual to a stochastic process that exhibits extinction\nversus unbounded growth, i.e., the total mass in such a process either becomes\nzero, or grows without bounds as time tends to infinity. If this is the case,\nthen this phenomenon can often be used to determine the invariant measures, or\nfixed points, of the process originally under consideration, and to study\nconvergence to equilibrium. This principle, which has been known since early\nwork on multitype branching processes, is here demonstrated on three new\nexamples with applications in the theory of interacting particle systems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0702075%2Cmath%2F0702500%2Cmath%2F0702385%2Cmath%2F0702648%2Cmath%2F0702501%2Cmath%2F0702194%2Cmath%2F0702671%2Cmath%2F0702386%2Cmath%2F0702336%2Cmath%2F0702230%2Cmath%2F0702046%2Cmath%2F0702084%2Cmath%2F0702348%2Cmath%2F0702392%2Cmath%2F0702265%2Cmath%2F0702518%2Cmath%2F0702591%2Cmath%2F0702752%2Cmath%2F0702002%2Cmath%2F0702489%2Cmath%2F0702766%2Cmath%2F0702703%2Cmath%2F0702735%2Cmath%2F0702552%2Cmath%2F0702627%2Cmath%2F0702569%2Cmath%2F0702202%2Cmath%2F0702155%2Cmath%2F0702512%2Cmath%2F0702303%2Cmath%2F0702610%2Cmath%2F0702748%2Cmath%2F0702102%2Cmath%2F0702699%2Cmath%2F0702032%2Cmath%2F0702492%2Cmath%2F0702097%2Cmath%2F0702448%2Cmath%2F0702299%2Cmath%2F0702618%2Cmath%2F0702179%2Cmath%2F0702704%2Cmath%2F0702289%2Cmath%2F0702542%2Cmath%2F0702172%2Cmath%2F0702144%2Cmath%2F0702170%2Cmath%2F0702420%2Cmath%2F0702519%2Cmath%2F0702815%2Cmath%2F0702886%2Cmath%2F0702611%2Cmath%2F0702318%2Cmath%2F0702334%2Cmath%2F0702875%2Cmath%2F0702851%2Cmath%2F0702128%2Cmath%2F0702653%2Cmath%2F0702564%2Cmath%2F0702589%2Cmath%2F0702269%2Cmath%2F0702628%2Cmath%2F0702043%2Cmath%2F0702563%2Cmath%2F0702660%2Cmath%2F0702693%2Cmath%2F0702162%2Cmath%2F0702095%2Cmath%2F0702675%2Cmath%2F0702780%2Cmath%2F0702200%2Cmath%2F0702281%2Cmath%2F0702593%2Cmath%2F0702583%2Cmath%2F0702636%2Cmath%2F0702587%2Cmath%2F0702019%2Cmath%2F0702189%2Cmath%2F0702206%2Cmath%2F0702471%2Cmath%2F0702094%2Cmath%2F0702868%2Cmath%2F0702397%2Cmath%2F0702090%2Cmath%2F0702773%2Cmath%2F0702005%2Cmath%2F0702662%2Cmath%2F0702783%2Cmath%2F0702357%2Cmath%2F0702261%2Cmath%2F0702678%2Cmath%2F0702330%2Cmath%2F0702891%2Cmath%2F0702379%2Cmath%2F0702616%2Cmath%2F0702781%2Cmath%2F0702827%2Cmath%2F0702553%2Cmath%2F0702264%2Cmath%2F0702338%2Cmath%2F0702173&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Certain Markov processes, or deterministic evolution equations, have the\nproperty that they are dual to a stochastic process that exhibits extinction\nversus unbounded growth, i.e., the total mass in such a process either becomes\nzero, or grows without bounds as time tends to infinity. If this is the case,\nthen this phenomenon can often be used to determine the invariant measures, or\nfixed points, of the process originally under consideration, and to study\nconvergence to equilibrium. This principle, which has been known since early\nwork on multitype branching processes, is here demonstrated on three new\nexamples with applications in the theory of interacting particle systems."}, "authors": ["Jan M. Swart"], "author_detail": {"name": "Jan M. Swart"}, "author": "Jan M. Swart", "arxiv_comment": "Habilitation Thesis 174 pages 4 figures", "links": [{"href": "http://arxiv.org/abs/math/0702095v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0702095v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60K35 (Primary); 82C22; 60J80; 92D25 (Secondary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0702095v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0702095v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0702095v1 [math.PR] 5 Feb 2007\n\nExtinction versus unbounded growth\nHabilitation Thesis of the University Erlangen-N\u00fcrnberg\nJan M. Swart\n\u00daTIA\nPod vod\u00e1renskou v\u011b\u017e\u0131\u0301 4\n18208 Praha 8\nCzech Republic\ne-mail: swart@utia.cas.cz\nJanuary 31, 2007\nAbstract Certain Markov processes, or deterministic evolution equations, have\nthe property that they are dual to a stochastic process that exhibits extinction\nversus unbounded growth, i.e., the total mass in such a process either becomes\nzero, or grows without bounds as time tends to infinity. If this is the case,\nthen this phenomenon can often be used to determine the invariant measures,\nor fixed points, of the process originally under consideration, and to study\nconvergence to equilibrium. This principle, which has been known since early\nwork on multitype branching processes, is here demonstrated on three new\nexamples with applications in the theory of interacting particle systems.\n\n\f2\n\n\fContents\n1 Introduction\n1.1 Interacting particle systems . . . . . . . . . . . . . . . . . . . . . .\n1.2 Extinction versus unbounded growth . . . . . . . . . . . . . . . . .\n1.2.1 Extinction versus unbounded growth in branching theory .\n1.2.2 Extinction versus unbounded growth in the contact process\n1.3 Overview of the habilitation thesis . . . . . . . . . . . . . . . . . .\n1.3.1 Branching processes in renormalization theory . . . . . . .\n1.3.2 Branching-coalescing particle systems . . . . . . . . . . . .\n1.3.3 The contact process seen from a typical site . . . . . . . . .\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n7\n7\n10\n10\n13\n15\n15\n16\n18\n\n2 Renormalization of catalytic WF-diffusions\n2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.1 Linearly interacting diffusions . . . . . . . . . . . . . . . . . . . . . .\n2.1.2 Large space-time behavior . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.3 Hierarchically interacting diffusions . . . . . . . . . . . . . . . . . . .\n2.1.4 Renormalization classes . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.5 Rescaled transformations . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.6 Diffusive clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.7 Numerical solutions to the asymptotic fixed point equation . . . . .\n2.1.8 Known results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2 Catalytic Wright-Fisher diffusions . . . . . . . . . . . . . . . . . . . . . . .\n2.2.1 Main result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2.2 Open problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2.3 Poisson-cluster branching processes . . . . . . . . . . . . . . . . . . .\n2.2.4 The renormalization branching process . . . . . . . . . . . . . . . . .\n2.2.5 Convergence to a time-homogeneous process . . . . . . . . . . . . . .\n2.2.6 Weighted and Poissonized branching processes . . . . . . . . . . . .\n2.2.7 Extinction versus unbounded growth for embedded particle systems\n2.2.8 Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3 The renormalization class Wcat . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3.1 Renormalization classes on compact sets . . . . . . . . . . . . . . . .\n2.3.2 Coupling of catalytic Wright-Fisher diffusions . . . . . . . . . . . . .\n2.3.3 Duality for catalytic Wright-Fisher diffusions . . . . . . . . . . . . .\n2.3.4 Monotone and concave catalyzing functions . . . . . . . . . . . . . .\n2.4 Convergence to a time-homogeneous process . . . . . . . . . . . . . . . . . .\n2.4.1 Convergence of certain Markov chains . . . . . . . . . . . . . . . . .\n2.4.2 Convergence of certain branching processes . . . . . . . . . . . . . .\n2.4.3 Application to the renormalization branching process . . . . . . . . .\n2.5 The super-Wright-Fisher diffusion: introduction . . . . . . . . . . . . . . . .\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n19\n19\n19\n23\n24\n26\n28\n30\n31\n32\n34\n34\n36\n37\n38\n39\n40\n42\n45\n45\n45\n47\n50\n53\n59\n59\n62\n67\n68\n\n3\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n\f4\n\nCONTENTS\n2.5.1 Superprocesses and binary splitting particle systems . . . . . . . . .\n2.5.2 Statement of the problem and motivation . . . . . . . . . . . . . . .\n2.5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.5.4 Methods and related work . . . . . . . . . . . . . . . . . . . . . . . .\n2.6 The super-Wright-Fisher diffusion: preparatory results . . . . . . . . . . . .\n2.6.1 Some general facts about log-Laplace semigroups . . . . . . . . . . .\n2.6.2 Some consequences of the finite ancestry property . . . . . . . . . .\n2.6.3 Smoothness of two log-Laplace semigroups . . . . . . . . . . . . . . .\n2.6.4 Bounds on the absorption probability . . . . . . . . . . . . . . . . .\n2.6.5 The weighted super-Wright-Fisher diffusion . . . . . . . . . . . . . .\n2.6.6 A zero-one law for Markov processes . . . . . . . . . . . . . . . . . .\n2.7 The super-Wright-Fisher diffusion: long-time behavior . . . . . . . . . . . .\n2.7.1 Ergodicity of the compensated v-transformed Wright-Fisher diffusion\n2.7.2 Long-time behavior of the weighted super-Wright-Fisher diffusion . .\n2.7.3 Long-time behavior of the super-Wright-Fisher diffusion . . . . . . .\n2.7.4 Long-time behavior of the log-Laplace semigroup . . . . . . . . . . .\n2.7.5 Smoothness of fixed points . . . . . . . . . . . . . . . . . . . . . . .\n2.8 Renormalization branching process: embedded particles . . . . . . . . . . .\n2.8.1 Weighting and Poissonization . . . . . . . . . . . . . . . . . . . . . .\n2.8.2 Sub- and superharmonic functions . . . . . . . . . . . . . . . . . . .\n2.8.3 Extinction versus unbounded growth . . . . . . . . . . . . . . . . . .\n2.9 Renormalization branching process: extinction on interior . . . . . . . . . .\n2.9.1 Basic facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.9.2 A representation for the Campbell law . . . . . . . . . . . . . . . . .\n2.9.3 The immortal particle . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.10 Proof of the main result . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n3 Branching-coalescing particle systems.\n3.1 Introduction and main results . . . . . . . . . . . . . . . . .\n3.1.1 Introduction . . . . . . . . . . . . . . . . . . . . . .\n3.1.2 Motivation . . . . . . . . . . . . . . . . . . . . . . .\n3.1.3 Preliminaries . . . . . . . . . . . . . . . . . . . . . .\n3.1.4 Main results . . . . . . . . . . . . . . . . . . . . . . .\n3.1.5 Methods . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.7 Outline . . . . . . . . . . . . . . . . . . . . . . . . .\n3.2 Martingale problems . . . . . . . . . . . . . . . . . . . . . .\n3.2.1 Definitions . . . . . . . . . . . . . . . . . . . . . . .\n3.2.2 Duality with error term . . . . . . . . . . . . . . . .\n3.3 Construction and comparison . . . . . . . . . . . . . . . . .\n3.3.1 Finite branching-coalescing particle systems . . . . .\n3.3.2 Monotonicity and subadditivity . . . . . . . . . . . .\n3.3.3 Infinite branching-coalescing particle systems . . . .\n3.3.4 Construction and comparison of resampling-selection\n3.4 Dualities . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.4.1 Duality and self-duality . . . . . . . . . . . . . . . .\n3.4.2 Subduality . . . . . . . . . . . . . . . . . . . . . . .\n3.5 The maximal processes . . . . . . . . . . . . . . . . . . . . .\n3.5.1 The maximal branching-coalescing process . . . . . .\n3.5.2 The maximal resampling-selection process . . . . . .\n3.6 Convergence to the upper invariant measure . . . . . . . . .\n\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\nprocesses\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n. . . . . .\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n68\n69\n71\n72\n74\n74\n77\n80\n81\n82\n84\n84\n84\n85\n86\n87\n88\n90\n90\n91\n98\n103\n103\n104\n107\n107\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n109\n109\n109\n110\n112\n115\n117\n119\n121\n121\n121\n121\n123\n123\n124\n124\n128\n131\n131\n133\n135\n135\n136\n136\n\n\fCONTENTS\n\n5\n\n3.6.1\n3.6.2\n\nExtinction versus unbounded growth . . . . . . . . . . . . . . . . . . . . 136\nConvergence to the upper invariant measure . . . . . . . . . . . . . . . . 139\n\n4 The contact process seen from a typical site\n4.1 Introduction and main results . . . . . . . . . . . .\n4.1.1 Contact processes on countable groups . . .\n4.1.2 Long-time behavior . . . . . . . . . . . . . .\n4.1.3 Results . . . . . . . . . . . . . . . . . . . .\n4.1.4 Methods . . . . . . . . . . . . . . . . . . . .\n4.1.5 Discussion and open problems . . . . . . . .\n4.1.6 Outline . . . . . . . . . . . . . . . . . . . .\n4.2 The law seen from a typical particle . . . . . . . .\n4.2.1 A martingale problem . . . . . . . . . . . .\n4.2.2 The exponential growth rate . . . . . . . .\n4.2.3 Subexponential growth . . . . . . . . . . . .\n4.2.4 Duality and Campbell laws . . . . . . . . .\n4.2.5 Harmonic functions . . . . . . . . . . . . .\n4.2.6 Eventual domination of finite configurations\n4.2.7 Generalization to arbitrary initial states . .\n4.3 Proofs of further results . . . . . . . . . . . . . . .\n4.3.1 Conditioning and size-biasing . . . . . . . .\n4.3.2 Coupling to the maximal process . . . . . .\n4.3.3 Coupling of one-dimensional processes . . .\n4.3.4 Survival on finitely generated groups . . . .\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n143\n143\n143\n145\n146\n149\n151\n153\n154\n154\n154\n156\n157\n158\n159\n160\n161\n161\n162\n165\n166\n\n\f6\n\nCONTENTS\n\n\fChapter 1\n\nIntroduction\n1.1\n\nInteracting particle systems\n\nThis habilitation thesis treats three subjects from probability theory, and more precisely, from\nthe field of interacting particle systems. The binding element is a common technique used to\nstudy these subjects, which gives the title to this thesis, which finds its origin in multitype\nbranching theory, and which is applied here both to branching processes and to processes\nwhich do not have the branching property, but still are in some ways similar to branching\nprocesses, although in other aspects of their behavior they are completely different. In this\nintroductory section, we zoom out a bit more than is usual in a research paper, and take a\nlook at the whole area of probability theory, and the fields of interacting particle systems and\nbranching theory in particular, to see how they arose historically and how they are related.\nProbability theory established itself as a mathematical discipline relatively late in history.\nIts origins are often traced back to an exchange of letters between Pascal and Fermat in the\nmid-17th century [Apo69], although some mention Cardano, one century earlier. The theory\nwas not put on a firm axiomatic basis until the monograph by Kolmogorov in 1933 [Kol33],\nwho based it on abstract measure theory, which had been developed in the preceding decades\nfollowing the work of Lebesgue at the turn of the century. Because of these foundations, some\nauthors claim that probability theory is a subfield of measure theory. Although there are\nmeasures all over the place, this is probably as justified as saying that algebra is a subfield of\nlinear algebra.\nWhen one tries to look for reasons why probability theory rose so late (why, for example,\ndid the Greeks show no interest?), one is reminded of Einstein's remark 'Gott w\u00fcrfelt nicht'\n(God doesn't gamble). Even today, many people, including some mathematicians, associate\nmathematics primarely with beautiful structures that are entirely fixed, like a Penrose tiling,\nwhile an infinite random structure of the type that occurs in percolation theory evokes a\ncertain disdain: 'Why, that can be anything!'. Actually, it can't.\nThe reason is that once random structures get large, many events tend to get extremely\nimprobable, until in the limit, for infinite systems, their probability is actually zero. The\nexample that everybody knows are the laws of large numbers, which pertain to sums of\nindependent identically distributed random variables. Closely related to this is the central\n7\n\n\f8\n\nCHAPTER 1. INTRODUCTION\n\nlimit theorem, which describes exactly how much randomness is left in the limit, and what\nthe limit distribution is. Once a colleague asked what I was just working on. After hearing\nmy explanation, his reaction was: so you are trying to prove a sort of central limit theorem?\nThe answer is both yes and no.\nIndeed, most of probability theory seems to be occupied with proving that certain things\nare certain in the limit that the system size, or time, or both tend to infinity, and that\nother things have a limit law.1 Yet, the methods needed to prove these limit statements are in\ngeneral completely different from those used in the case of independent random variables. The\nindependent case being well-understood, probabilists nowadays investigate systems of highly\ndependent components. And while there is just one way in which things can be independent,\nthere are many ways in which things can depend on each other.\nSeen from this point of view, the \"theory of interacting particle systems\" sounds like the\nnatural culmination point of all of probability theory. That is not quite true. In fact, the\nclassical book by Liggett called 'Interacting Particle Systems' [Lig85] was translated into Russian as 'Markovskije Processy s Lokalnym Vzaimodejstvijem' (Markov Processes with Local\nInteraction), which captures the subject more precisely. Interacting particle systems are always situated in space, which is often Zd , sometimes Rd , and sometimes another discrete or\ncontinuous structure that is in some way translation invariant. At each point in this space,\nthere is some local Markov process going on, that is inherently random, and interacts with\nthe Markov processes surrounding it. Although this interaction is only local, in the long run\ninformation can spread arbitrarily far, and therefore it is the long-time behavior of the process\nthat is usually of interest.\nThis description of interacting particle systems excludes many other dependent systems,\nsuch as random walks in random environment, self-enforced and self-avoiding random walks,\ncellular automata and other deterministic evolutions, random matrices, and percolation theory,\nalthough many of these topics have close links with interacting particle systems. It also\nexcludes, unrighteously, interacting particle systems in quantum probability. And, finally,\nit excludes other active areas of probabilistic research, such as abstract theory of Markov\nprocesses and semigroups, stochastic evolution equations, stochastic analysis, and more.\nThe origin of the field of interacting particle systems lies in 19-th century physics, when\nscientists like Bolzmann, Van der Waals, and others started to look for the molecular basis\nof thermodynamics. Thus, the original motivation was to study particles moving around\nin R3 according to the deterministic rules of classical Hamiltonian dynamics, or, later, its\nquantummechanical counterpart, which in a sense is both deterministic and inherently random.\nThe mathematical problems arising from continuous space and deterministic motion being too\ndifficult, people turned to models on lattices, that moreover have a local source of randomness.\nThis class of models is still extremely rich, and apart from their original physical motivation,\nit was found that models of this type can be used to model many other interesting phenomena\nin a variety of applications in, for example, biology, sociology, and random network theory. Of\nthe four classical models from [Lig85], namely the Ising model, voter model, contact process,\n1\n\nI have to add a caveat here for statisticians, who are sometimes treated as probabilists, and sometimes as\na species of their own, who from a practical point of view also have a lively interest in small samples, and,\ngenerally speaking, seem to be more interested in doing things and managing things, while the probabilist sensu\nstrictu just sits down and tries to understand.\n\n\f1.1. INTERACTING PARTICLE SYSTEMS\n\n9\n\nand exclusion process, only the first and last have a clear physical motivation.\nAs a mathematical discipline, the field of interacting particle systems started around 1970.\nAgain, compared to other branches of mathematics, this is very recent. This time, the reasons\nlie probably not only in a lack of interest (after all, the physical problems had been around for a\ncentury by that time) but also in the inherent difficulty of the subject. Certain special results\ndate back further, to the mid 40ies; this includes work on multitype branching processes,\npercolation, and the famous Onsager solution of the 2-dimensional equilibrium Ising model.\nGradually, people had to get used to the fact that interacting particle systems rarely allow for\nexplicit solutions, and that very little can be said about them in general. Rather, even the\nsimplest-looking among them required the development of new tools suited exactly for them,\nand many naive questions remained open for many years.\nThe systems of interest (interacting particle systems) and the main questions (limit laws\nfor large system sizes and large times) being defined now, we can focus on some more specific\ntopics. The first topic we would like to mention, which motivates much of the work done in\nthe field, is that of phase transitions. Originally referring to the phenomenon that certain\nsubstances (as a general rule with exceptions: pure chemical substances) can either be in a\ngaseous, fluid, or solid phase, and change abruptly between these phases as the temperature\nor pressure pass a certain point, the concept has subsequently been generalized to include\nmore phases (e.g. graphite versus diamond) and then to describe the general phenomenon\nthat many-particle systems may drastically change their behavior when certain parameters\npass certain tresholds, called critical points.\nPhase transitions are a central topic for a number of reasons. First of all, since finite\nsystems running for a finite time generally depend continuously on their parameters, mathematically ideal phase transitions occur only in the limit that the system size, and time, are\nsent to infinity, and therefore are the typical sort of phenomenon that justifies the study of\nlarge or infinite systems. Second, detailed information about them is often hard to get, since\nthey are out of reach of most expansion techniques that tell us something about very high or\nlow values of our parameters. In other words, phase transitions are difficult, and therefore\nprestigious. The third and most important reason is probably the belief, supported by nonrigorous theory developed by theoretical physicists, that phase transitions are highly universal.\nThus, different interacting particle systems may have the 'same' phase transition. Although\nthe exact parameter values where this phase transition takes place may differ from one model\nto the other, zooming in on these phase transitions, and at the same time zooming out in\nspace (and time, if we are not in equilibrium) should always yield roughly the same picture.\nThis can for example be seen from the critical exponents of these phase transitions, which\ndescribe how certain quantities behave according to a certain power law as the critical point\nis approached. The classical paper in physics on this topic is [WK74].\nTrying to prove results about critical phenonema that take place at, or in the immediate\nvicinity of the critical points, in particular, the calculation of critical exponents, has been\na big aim behind much work done on interacting particle systems. Progress has been slow.\nIn a number of cases, expansion techniques, such as the lace expansion, have been used to\nshow that certain systems have 'trivial' exponents, that are the same as those for other,\nnoninteracting systems. Recently, important progress has been made on critical exponents for\ntwo-dimensional systems having conformally invariant scaling limits. The key object in this\n\n\f10\n\nCHAPTER 1. INTRODUCTION\n\nwork is the Stochastic Loewner Equation [Law05]. Apart from these two cases (the 'trivial'\ncritical exponents and those from conformal field theory) there is still little process.\nWhere, in all of this, is the present habilitation thesis situated? No critical exponents will\nbe calculated in what follows, but we will see critical phenomena, and even some universality.\nIn any case, there will be phase transitions around, and we will prove limit laws as time and\nsystem size are sent to infinity. A repeating theme in the proofs will be the exploitation of the\nsimple observation that in certain particle systems, the number of particles either becomes\nzero, or tends to infinity. As far as I am aware off, this idea was first used in multitype\nbranching theory.\nThe theory of branching processes started with a paper by Galton and Watson in 1874\n[WG74], who studied the problem of the extinction of noble names. The problem drew new\ninterest with the rise of probability theory in the 30-ies and with the study of nuclear chain\nreactions, which led to the study of multitype processes. It was only in the mid-70-ies, when\npeople started to consider Zd as the space of types, that the first branching processes were\nstudied that might truly be called interacting particle systems. Even as such, they hardly\ndeserve the name, since they consist of particles independently hopping around on a lattice,\nthat moreover independently of each other split into more particles or die. The only way in\nwhich dependencies arise, which make the model interesting, is through the fact that certain\n'families' of particles all descend from one and the same 'ancestor'. Basic questions about\ntheir ergodic behavior were solved by Kallenberg [Kal77] using his famous 'backward tree\ntechnique'. We will use this technique in Section 2.9.2. It is moreover closely linked to the\nwork in Chapter 4 of this thesis. The main technique that unites all chapters, however, is the\nuse of 'extinction versus unbounded growth', as will be explained in the next section.\n\n1.2\n\nExtinction versus unbounded growth\n\nCertain Markov processes, or deterministic evolution equations, have the property that they\nare dual to a stochastic process that exhibits extinction versus unbounded growth, i.e., the\ntotal mass in such a process either becomes zero, or grows without bounds as time tends\nto infinity. If this is the case, then this phenomenon can often be used to determine the\ninvariant measures, or fixed points, of the process originally under consideration, and to study\nconvergence to equilibrium. In this section, we demonstrate this principle, in the historicaly\ncorrect order, first on multitype branching processes, and then on the contact process.\n\n1.2.1\n\nExtinction versus unbounded growth in branching theory\n\nConsider a collection of particles of n different types. Assume that each particle of type\ni \u2208 {1, . . . , n} gives with birth rate bij birth to a particle of type j \u2208 {1, . . . , n}, and dies with\ndeath rate di . We will assume that bij > 0 and di > 0 for all i, j. Let Yt (i) denote the number\nof particles of type i at time t \u2265 0. Then Y = (Yt )t\u22650 is a Markov process in Nn , which in the\nusual terminology is called a continuous-time multitype binary branching process. We write\nP y for the law of Y started in Y0 = y and denote expectation with respect to P y by E y . It is\n\n\f11\n\n1.2. EXTINCTION VERSUS UNBOUNDED GROWTH\nwell-known that\nEy\n\nn\nhY\ni=1\n\nn\ni Y\n(1 \u2212 ut (i))y(i)\n(1 \u2212 u0 (i))Yt (i) =\ni=1\n\n(t \u2265 0),\n\n(1.2.1)\n\nwhenever ut = (ut (1), . . . , ut (n)) is a [0, 1]n -valued solution to the system of differential equations\n\u2202\n\u2202t ut (i)\n\n=\n\nn\nX\nj=1\n\nbij ut (j)(1 \u2212 ut (i)) \u2212 di ut (i)\n\n(t \u2265 0, i \u2208 {1, . . . , n}).\n\n(1.2.2)\n\nThe map that gives (1 \u2212 ut ) as a function of (1 \u2212 u0 ) and t is what is classically known as the\ngenerating function of the branching process Y (at time t). We prefer to work with ut (and\nnot 1 \u2212 ut ) since this will simplify formulas later on.\nFormula (1.2.1) has a useful interpretation in terms of thinning. By definition, a thinning of\na particle configuration y \u2208 Nn with a vector v \u2208 [0, 1]n is the random particle configuration\nobtained from y in the following manner. Independently for each particle, we decide with\nprobability v(i) (depending on the type i of the particle) whether we will keep it; with the\nremaining probability 1 \u2212 v(i) we throw this particle away. If we denote the thinned collection\nof particles resulting from this procedure by Thinv (y), then the left-hand side of (1.2.1) is just\nthe probability that the configuration Thinut (Yt ) contains no particles. Since the right-hand\nside of (1.2.1) has a similar interpretation, we may rewrite (1.2.1) as\nP y [Thinu0 (Yt ) = 0] = P [Thinut (y) = 0]\n\n(t \u2265 0).\n\n(1.2.3)\n\nThe relation (1.2.1), or its rewrite (1.2.3), are an example of a duality relation, where the dual\nof the Markov process Y is in this case the deterministic process u.\nUsing this duality relation, we can deduce information about Y from u, and vice versa.\nTo demonstrate this, we will show how the fact that the process Y exhibits extinction versus\nunbounded growth gives information about the fixed points of the n-dimensional differential\nequation (1.2.2).\nIt is not hard to see that\n\u2202\n\u2202t E[Yt (i)]\n\n=\n\nn\nX\n\nMji E[Yt (j)]\n\nj=1\n\n(t \u2265 0),\n\n(1.2.4)\n\nwhere Mji = bji \u2212\u03b4ij di (i, j = 1, . . . , n). Since by adding a constant multiple of the identity, we\ncan make M into a matrix with strictly positive entries, it follows from the Perron-Frobenius\ntheorem that M has a maximal eigenvalue, say \u03bb, that corresponds to a positive right and left\neigenvector, which are the only nonnegative eigenvectors. If \u03bb < 0, we say that the branching\nprocess Y is subcritical, if \u03bb = 0 we say that it is critical, and if \u03bb > 0 we say that it is\nsupercritical. In the subcritical and critical cases, Y dies out, i.e.,\n\u0002\n\u0003\nP y \u2203t \u2265 0 s.t. Ys = 0 \u2200s \u2265 t = 1\n\n(y \u2208 Nn ).\n\n(1.2.5)\n\n\f12\n\nCHAPTER 1. INTRODUCTION\n\n(Note that since there is no spontaneous creation of particles, the zero configuration is a trap\nfor the Markov process Y .) On the other hand, in the supercritical case, on which we focus\nfrom now on, Y survives with positive probability, i.e.,\n\u0002\nP y Yt 6= 0 \u2200t \u2265 0] > 0\n(y \u2208 Nn , y 6= 0).\n(1.2.6)\nQ\nIndeed, the probability in (1.2.6) is given by 1 \u2212 ni=1 (1 \u2212 p(i))y(i) , where\n\u0002\np(i) := P \u03b4i Yt 6= 0 \u2200t \u2265 0] > 0\n(i = 1, . . . , n),\n\n(1.2.7)\n\nand \u03b4i denotes the particle configuration with just one particle of type i.\nWe claim that p is the only nonzero fixed point of the differential equation (1.2.2), and\nthe limit point started from any nonzero initial condition. To prove this, we observe that Y\nexhibits extinction versus unbounded growth, in the following sense:\n\u0002\n\u0003\nP y \u2203t \u2265 0 s.t. Ys = 0 \u2200s \u2265 t or lim |Yt | = \u221e = 1\n(y \u2208 Nn ),\n(1.2.8)\nt\u2192\u221e\n\nP\nwhere |y| := ni=1 y(i) denotes the total number of particles in a particle configuration y \u2208 Nn .\nWhy does (1.2.8) hold? We will not give a formal proof here, but just explain the main idea.\n(For a more formal approach, see Lemma 2.80 below.) Since we are assuming that the death\nrates di are all positive, it is not hard to show that\n\u0002\n\u0003\ninf P y \u2203t \u2265 0 s.t. Ys = 0 \u2200s \u2265 t > 0\n(K \u2265 0).\n(1.2.9)\n|y|\u2264K\n\nIndeed, if the process Y is started with no more than K particles, then there is a positive\nchance that all these particles die before they have a chance to branch, and therefore the\nprobability that the process dies out can be estimated from below uniformly in all particle\nconfigurations with no more than K particles. Now imagine that the number of particles |Yt |\nis less than K at a (random) sequence of times tending to infinity. Then the process would\ninfinitely often have a (uniformly) positive chance to die out in the next time interval of a\ncertain length, and therefore it would eventually have to die out. Since this is true for any\nK, the only way for the process to escape extinction is to let the number of particles tend to\ninfinity.\nWe now show how extinction versus unbounded growth (formula (1.2.8)) implies that any\nsolution of (1.2.2) with u0 6= 0 satisfies\nlim ut = p,\n\nt\u2192\u221e\n\n(1.2.10)\n\nwhere p is defined in (1.2.7). Note that P [Thinv (\u03b4i ) 6= 0] = v(i) (v \u2208 [0, 1]n ), and therefore,\nby (1.2.3),\nut (i) = P \u03b4i [Thinu0 (Yt ) 6= 0]\n(t \u2265 0, i = 1, . . . , n).\n(1.2.11)\nSince we are assuming that bij > 0 for all i, j, it is easy to see from (1.2.11) that u0 6= 0\nimplies ut (i) > 0 for all i = 1, . . . , n and t > 0, so by a restart argument we may without loss\nof generality assume that u0 (i) > 0 for all i = 1, . . . , n.\n\n\f1.2. EXTINCTION VERSUS UNBOUNDED GROWTH\n\n13\n\nUsing (1.2.11) once more, and using extinction versus unbounded growth (formula (1.2.8)),\nwe see that for large t there are up to an event with small probability only two situations to\nbe considered. Either Yt = 0, in which case Thinu0 (Yt ) = 0, or |Yt | is large, in which case, by\nthe fact that u0 (i) > 0 for all i, we know that Thinu0 (Yt ) is with large probability nonzero.\nTherefore, P \u03b4i [Thinu0 (Yt ) 6= 0] \u223c\n= P [Yt 6= 0] for large t, and taking the limit t \u2192 \u221e in (1.2.11)\nwe arrive at (1.2.10). This proves that p is the only nonzero fixed point of the differential\nequation (1.2.2), and the limit point started from any nonzero initial condition.\nIn a discrete time setting (but with much more general branching mechanisms), the result\n(1.2.10), including a proof based on extinction versus unbounded growth, can be found in\nHarris [Har63, Theorem II.7.2], who ascribes it to Everett and Ulam [EU48].\nIt is not hard to see that the positivy assumptions on the rates bij and di can be weakened\nconsiderably. In fact, it suffices if at least one of the di is nonzero, and if the bij are irreducible,\nin the sense that for each i, j \u2208 {1, . . . , n}, there exist k0 , . . . , km with k0 = i, km = j, and\nbkl\u22121 ,kl > 0 for all l = 1, . . . , m.\n\n1.2.2\n\nExtinction versus unbounded growth in the contact process\n\nThe standard, nearest neighbor d-dimensional contact process is a Markov process \u03b7 = (\u03b7t )t\u22650\ntaking values in the space of all subsets of Zd , with the following description. If i \u2208 \u03b7t , then\nwe say that the site i \u2208 Zd is infected at time t \u2265 0, otherwise such a site is called healthy.\nInfected sites become healthy with rate 1. Healthy sites become infected with infection rate\n\u03bb times the number of neighboring infected sites. Here, we say that i, j \u2208 Zd are neighbors if\n|i \u2212 j| = 1.\nIt is useful to think about the contact process as a frustated branching process. Think\nof infected sites as being occupied by a particle. Then each particle tries with rate \u03bb to give\nbirth to a particle at each neighboring site. If, however, that site is already occupied by a\nparticle, the birth fails.\nIndeed, it is easy to see that |\u03b7t |, the total number of infected sites, can be bounded from\nabove by a binary branching process with branching rate 2d\u03bb and death rate 1. In particular,\nif \u03bb \u2264 1/(2d), this branching process is (sub)critical, and hence the contact process dies out.\nOn the other hand, with considerably more effort, it is possible to show that for suffiently\nlarge \u03bb, the contact process survives with positive probability, i.e.,\nP A [\u03b7t 6= \u2205 \u2200t \u2265 0] > 0\n\n(A 6= \u2205).\n\n(1.2.12)\n\nIt is easy to show that two contact processes \u03b7, \u03b7\u0303 with infection rates \u03bb, \u03bb\u0303 can be coupled such\nthat \u03b7t \u2264 \u03b7\u0303t , so it follows that there exists a critical infection rate 0 < \u03bbc < \u221e such that the\ncontact process dies out for \u03bb < \u03bbc and survives (with positive probability) for \u03bb > \u03bbc . The\nquestion whether the contact process survives at \u03bb = \u03bbc was open for almost 15 years; its\nsolution by Bezuidenhout and Grimmett in [BG90] was a major milestone in the development\nof the theory of the contact process.\nWe will not touch this subject here, but rather show how the fact that the contact process\nexhibits extinction versus unbounded growth, together with self-duality, can be used to prove\nthat if the contact process survives, then it has a unique nontrivial homogeneous invariant\nlaw. Here, we say that a probability law on the space of all subsets of Zd is nontrivial if it\n\n\f14\n\nCHAPTER 1. INTRODUCTION\n\ngives zero probability to the empty set, and (spatially) homogeneous if it is invariant under\ntranslations.\nIt is well-known that the contact process is self-dual, in the following sense. Fix an infection\nrate \u03bb, and for A \u2282 Zd , let \u03b7 A denote the contact process with this infection rate started in\nthe initial state \u03b70A = A. Then\nP [\u03b7tA \u2229 B = \u2205] = P [A \u2229 \u03b7tB = \u2205]\n\n(t \u2265 0, A, B \u2282 Zd ).\n\n(1.2.13)\n\nSince the contact process is an attractive spin system, it follows from standard theory that\nit has an upper invariant law \u03bd, which is the largest invariant law in the sense of stochastic\nordering, and the limit law as t \u2192 \u221e of the process started with all sites infected:\nd\n\nL(\u03b7tZ ) =\u21d2 \u03bd.\n\n(1.2.14)\n\nt\u2192\u221e\n\nd\n\nZ be a random\nUsing the self-duality (1.2.13) we can give a useful characterization of \u03bd. Let \u03b7\u221e\nd\nZ\nvariable with law L(\u03b7\u221e ) = \u03bd. Then\nd\n\nZ\nP [\u03b7\u221e\n\u2229 A = \u2205] = lim P [Zd \u2229 \u03b7tA = \u2205] = P [\u2203t \u2265 0 s.t. \u03b7tA = \u2205]\nt\u2192\u221e\n\n(1.2.15)\n\nd\n\nfor all finite A \u2282 Zd . Since L(\u03b7tZ ) is homogeneous for each t \u2265 0, so is \u03bd. Using (1.2.15) and\nsurvival, it is not hard to show that \u03bd is nontrivial. We claim that it is the only invariant law\nwith this property and moreover, that\nL(\u03b7t ) =\u21d2 \u03bd\nt\u2192\u221e\n\n(1.2.16)\n\nwhen \u03b7 is a contact process started in any initial law L(\u03b70 ) = \u03bc that nontrivial and homogeneous. To prove this, we observe that the contact process exhibits extinction versus unbounded\ngrowth in the following sense:\n\u0002\n\u0003\n(1.2.17)\nP \u2203t \u2265 0 s.t. \u03b7tA = \u2205 or lim |\u03b7tA | = \u221e = 1\n(AdZ ),\nt\u2192\u221e\n\nwhere |A| denotes the cardinality of a set A. The proof is basically the same as in the case of\nmultitype branching (see formula (1.2.8)). Since it may happen that all infected sites become\nhealthy before any further infection has taken place, it is easy to show that\n\u0002\n\u0003\ninf P \u2203t \u2265 0 s.t. \u03b7tA = \u2205 > 0\n(K \u2265 0).\n(1.2.18)\n|A|\u2264K\n\nThus, the probability that the process will die out can be estimated from below uniformly in\nall configurations with at most K infected sites, and therefore the only way for the process to\navoid extinction is to let the number of infected sites tend to infinity.\nNow let L(\u03b70 ) = \u03bc be nontrivial and homogeneous. Then, with a bit of trouble, it is\npossible to show that for each t > 0, the law L(\u03b7t ) has the property that\nlim\n\nsup P [\u03b7t \u2229 An = \u2205] = 0.\n\nK\u2192\u221e |A|\u2264K\n\n(1.2.19)\n\n\f15\n\n1.3. OVERVIEW OF THE HABILITATION THESIS\n\nTherefore, by a restart argument, we may without loss of generality assume that L(\u03b70 ) has\nthis property. Self-duality (formula (1.2.13)) tells us that\nP [\u03b7t \u2229 A = \u2205] = P [\u03b70 \u2229 \u03b7tA = \u2205]\n\n(t \u2265 0),\n\n(1.2.20)\n\nwhere \u03b70 and \u03b7tA are independent. If t is large, then in evaluating the right-hand side of (1.2.20),\nby extinction versus unbounded growth (1.2.17), up to an event with small probability we need\nto consider only two cases. Either \u03b7tA = \u2205, in which case \u03b70 \u2229 \u03b7tA = \u2205, or |\u03b7tA | is large, in which\ncase \u03b70 \u2229\u03b7tA is with high probability not empty since L(\u03b70 ) has the property (1.2.19). It follows\nthat P [\u03b70 \u2229 \u03b7tA = \u2205] \u223c\n= P [\u03b7tA = \u2205] for large t, and taking the limit t \u2192 \u221e in (1.2.20), using\n(1.2.15), we see that\nZd\nlim P [\u03b7t \u2229 A = \u2205] = P [\u03b7\u221e\n\u2229 A = \u2205],\n(1.2.21)\nt\u2192\u221e\n\nfor all finite A \u2282 Zd , which proves (1.2.16).\nThis argument is due to Harris [Har76, Theorem 9.2], who builds on earlier work of Vasil'ev,\nVasershtein, Leontovich, and others. It can also be found in Ligget's book [Lig85, Theorem VI.4.8].\n\n1.3\n1.3.1\n\nOverview of the habilitation thesis\nBranching processes in renormalization theory\n\nCertain problems in the study of a special type of interacting particle system, namely linearly\ninteracting catalytic Wright-Fisher diffusions, lead one to study a special continuous-mass\ncontinuous- type space branching process, namely, the super-Wright-Fisher diffusion. This is\na Markov process Y = (Yt )t\u22650 , taking values in the space of finite measures on [0, 1], whose\ntransition probabilities are uniquely characterized by its Laplace functionals\n\u0002\n\u0003\nE \u03bc e \u2212hYt , u0 i = e \u2212h\u03bc, ut i\n\n(t \u2265 0),\n\n(1.3.1)\n\nR\nwhere h\u03bc, f i := f d\u03bc and u is a mild solution of the semilinear Cauchy equation\n\u2202\n\u2202t ut (x)\n\n2\n\n\u2202\n= 12 x(1 \u2212 x) \u2202x\n2 ut (x) + \u03b1ut (x)(1 \u2212 ut (x))\n\n(t \u2265 0),\n\n(1.3.2)\n\nwith u0 any nonnegative continuous function on [0, 1]. One should think of (1.3.1) and\n(1.3.2) as continuous analogues of (1.2.1) and (1.2.2), respectively, where the finite type space\n{1, . . . , n} has been replaced by [0, 1] and the space Nn of all n-type particle configurations\nhas been replaced by the space M[0, 1] of all finite measures on [0, 1]. We can think of Yt as\ndescribing a population, consisting of many particles each of which has a very small mass, such\nthat each particle performs a Wright-Fisher diffusion on [0, 1], that is, the Markov process in\n\u22022\n[0, 1] whose generator is (the closure of) the operator 12 x(1 \u2212 x) \u2202x\n2 , and in addition, particles\nbranch in such a way that the offspring of a bit of mass dm at position x during a time interval\nof length dt produces offspring with mean (1 + \u03b1dt)dm and variance \u03b1dt.\nThe way how the super Wright-Fisher diffusion Y arises in a renormalization analysis of\nsystems of linearly interacting catalytic Wright-Fisher diffusions will be explained in Chapter 2\n\n\f16\n\nCHAPTER 1. INTRODUCTION\n\nFor the moment, we take the process in (1.3.1) for granted, and ask about fixed point(s)\nand long-time convergence of solutions u to the Cauchy equation (1.3.2). We would like to\nplay the same game as in Section 1.2.1 and use extinction versus unbounded growth of Y to\nprove convergence of u. Apart from the technical complications arising from continuous type\nspace and continuous mass, we meet a more fundamental problem: our underlying motion, the\nWright-Fisher diffusion, is not irreducible, i.e., it is not possible to get with positive probability\nfrom any point to any other point in the type space.\nIndeed, the Wright-Fisher diffusion Y has two traps: 0 and 1, and the process started in\nany initial state satisfies\n\u0002\n\u0003\nP \u2203\u03c4 < \u221e, r \u2208 {0, 1} s.t. Yt = r \u2200t \u2265 \u03c4 = 1,\n(1.3.3)\n\ni.e., the process gets trapped in finite time. For the measure-valued process Y, this means\nthat with positive probability, in the long run most of the mass gets concentrated in 0, or 1,\nor both. Whether there is also a positive probability that there remains some mass in (0, 1)\nturns out to depend on the parameter \u03b1. For \u03b1 > 1, the answer is yes; otherwise it is no. As\na result, we have to prove extinction versus unbounded growth on each of the part of the type\nspace {0}, {1}, and (0, 1), and we find three or four (depending on \u03b1) different nonzero fixed\npoints of (1.3.2), each with their own domain of attraction.\nThis analysis carried out in Sections 2.5\u20132.7 of Chapter 2. There, a similar analysis is\ncarried out also for a related branching process in discrete time, the description of which is\nsomewhat complicated. An important tool in this analysis is the use of embedded particle\nsystems, as explained in Section 2.2.7. The results in this chapter are joint work with Klaus\nFleischmann (WIAS, Berlin). Part of this has been published in [FS03].\n\n1.3.2\n\nBranching-coalescing particle systems\n\nConsider a model of binary branching random walks, i.e., a collection of particles situated on\na lattice \u039b, where each particle moves independently of the others according to a continuous\ntime random walk that jumps from site i \u2208 \u039b to site j with rate a(i, j), each particle splits\nwith a branching rate b \u2265 0 into two new particles, created on the position of the old one, and\neach particle dies with a death rate d \u2265 0. Let Xt (i) denotes the number of particles at time\nt \u2265 0 at the site i \u2208 \u039b and write Xt := (Xt (i))i\u2208\u039b . Then, in analogy with (1.2.1), one has\nEx\n\nn\nn\ni Y\nhY\n(1 \u2212 ut (i))x(i)\n(1 \u2212 u0 (i))Xt (i) =\ni=1\n\ni=1\n\n(t \u2265 0),\n\n(1.3.4)\n\nwhenever ut = (ut (1), . . . , ut (n)) is a [0, 1]\u039b -valued solution to the system of differential equations\nX\n\u2202\na(j, i)(ut (j) \u2212 ut (i)) + but (i)(1 \u2212 ut (i)) \u2212 dut (i)\n(1.3.5)\n\u2202t ut (i) =\nj\n\n(t \u2265 0, i \u2208 \u039b). For each f \u2208 [0, 1]\u039b , set Ut f := ut (t \u2265 0) where u solves (1.2.2) with\ninitial condition u0 = f ; then (Ut )t\u22650 is the generating semigroup of the branching process\nX = (Xt )t\u22650 .\n\n\f17\n\n1.3. OVERVIEW OF THE HABILITATION THESIS\n\nWhat happens if in the branching system X we also allow for coalescence of particles, i.e.,\nif we let each pair of particles, present on the same site, coalesce with rate 2c (with c \u2265 0) to\none particle? In this case, we lose the branching property, i.e., we obtain a truly interacting\nsystem of particles. It turns out that although there is now no longer a generating semigroup\nin the classical sense, if we replace the deterministic evolution in (1.2.2) by the system of\nstochastic differential equations (SDE's)\ndut (i) =\n\nX\n\na(j, i)(ut (j) \u2212 ut (i)) dt + but (i)(1 \u2212 ut (i)) dt \u2212 dut (i) dt\n\njp\n\n+\n\n2cut (i)(1 \u2212 ut (i)) dBt (i)\n\n(1.3.6)\n\n(t \u2265 0, i \u2208 \u039b),\n\nthen formula (1.3.4) generalizes to the case with coalescence in the sense that\nE\n\nn\nn\ni\ni\nhY\nhY\n(1 \u2212 ut (i))X0 (i)\n(1 \u2212 u0 (i))Xt (i) = E\ni=1\n\ni=1\n\n(t \u2265 0).\n\n(1.3.7)\n\nThe duality (1.3.7) is due to [Shi81, SU86]. It turns out that the behavior of branchingcoalescing particle systems of the type we have just described is very similar to that of the\ncontact process. In fact, the history of this type of models seems to be as least as old as that of\nthe contact process. In particular, our model is a special case of Schl\u00f6gl's first model [Sch72].\nGiven the similarity of X with a contact process, and the similarity of the duality (1.3.7)\nwith the self-duality of the contact process (1.2.13), one can try to mimick the proof of (1.2.16)\nin the present set-up. This was done by Shiga and Uchiyama in [SU86] for solutions u to the\nsystem of SDE's (1.3.6). More precisely, they used extinction versus unbounded growth for\nthe particle system X to prove that the law of the system of SDE's u, started in any nontrivial\nhomogeneous initial law, converges for t \u2192 \u221e to the upper invariant law of u.\nWe note that if the death rate d is positive, then the probability that the process X will get\nextinct can be estimated from below uniformly in all configurations with at most K particles.\nTherefore, extinction versus unbounded growth for X follows by the same argument as in\nSections 1.2.1 and 1.2.2. If d = 0, the process cannot get extinct. In this case, it is not\ncompletely trivial to show that the number of particles tends to infinity, which forced the\nauthors of [SU86] to make some additional technical assumptions.\nIn Chapter 3, we turn the duality (1.3.7) around, and use extinction versus unbounded\ngrowth for the system of SDE's u to prove that the law of the particle system X started in\nany nontrivial homogeneous initial law, converges for t \u2192 \u221e to the upper invariant law of\nX. This also involves some technical difficulties, since we need to show that the continuous\nsystem u may hit zero in finite time, and we need to show that X has an upper invariant law,\nwhich means that we must show that X can be started with infinitely many particles at every\nsite.\nThese problems can be overcome, however, and we end up with results that are stronger\nthan those in [SU86]. Additional tools that we use are a self-duality for the system of SDE's\nu, as well as the fact that the particle system X can be obtained from u by Poissonization.\nThis is joint work with Siva Athreya (Bangalore), and has been published in [AS05].\n\n\f18\n\n1.3.3\n\nCHAPTER 1. INTRODUCTION\n\nThe contact process seen from a typical site\n\nIn the last chapter of this thesis, we return to the classical contact process, but instead of\nstudying the process started in a nontrivial homogeneous initial law as in Section 1.2.2, we\nwish to study the process started in finite initial states. It is known that questions about\nthis sort of initial states are much more difficult than those about homogeneous initial laws.\nNevertheless, a lot is known for the standard, nearest neighbor process on Zd . A central\ntechnical tool in this work is a dynamical block technique due to [BG90], which shows that\nthe contact process, whenever it survives, can be compared with oriented percolation with an\narbitrary high parameter. This technique finds its origin in older (although published later)\nwork on unoriented percolation [GM90, BGN91].\nWhile this technique has been very successful for the symmetric nearest-neighbor contact\nprocess on Zd , and can no doubt be extended to short-range contact processes on the same\nlattice, it is not obvious if it can be adapted to asymmetric processes, or to other lattices\nthan Zd . Nevertheless, the study of contact processes on other lattices than Zd is interesting\nboth from a theoretical and practical poiint of view. The theoretical motivation comes from\nanalogies with unoriented percolation on general transitive graphs, which has proved to be a\nfruitful topic (see, e.g., [BLPS99]). For unoriented percolation, it is known that it is important\nwhether the underlying lattice is amenable (such as Zd ) or not (e.g. a regular tree). Work on\nthe contact process on regular trees by [Pem92, DS95, Lig96, Sta96] makes one suspect that\na similar dichotomy could hold for the contact process.\nIn Chapter 4, we study contact processes on general countable groups \u039b. We use a technique from the theory of branching processes, namely Palm measures, to show that indeed,\ncertain aspects of the behavior of the contact process started in finite initial states depend on\na property of the underlying lattice. The property that turns out to be important is whether\n\u039b has subexponential growth, which is in fact a bit stronger than amenability.\nSomewhat surprisingly, it turns out that in this context, extinction versus unbounded\ngrowth can again be of use to us. We will see that the local law of the process as seen from\na typical 'Palmed' infected site at a typical late time can approximately be described by a\nmonotone, translation invariant, harmonic function of the contact process. It is not hard to\n\u039b is a random variable with law L(\u03b7 \u039b ) = \u03bd, the upper invariant law, then\nsee that if \u03b7\u221e\n\u221e\n\u039b\nf (A) := P [\u03b7\u221e\n\u2229 A 6= \u2205]\n\n(1.3.8)\n\nalso defines an (a priori different) monotone, translation invariant, harmonic function f . The\nkey argument in Chapter 4 uses extinction versus unbounded growth, plus duality, to show\nthat this is up to a multiplicative constant the only such function. This extends the classical\nresult, outlined in Section 1.2.2, that \u03bd is the only nontrivial homogeneous invariant law.\n\n\fChapter 2\n\nRenormalization of catalytic\nWright-Fisher diffusions\n2.1\n2.1.1\n\nIntroduction\nLinearly interacting diffusions\n\nLet D \u2282 Rd be open and convex, let D denote its closure, and assume that 0 \u2208 D. Let \u039b be\na countably infinite group, with group action denoted by (\u03be, \u03b7) 7\u2192 \u03be\u03b7 and unit element 0. Let\na : \u039b \u00d7 \u039b \u2192 R be summable and invariant with respect to left multiplication in the group,\ni.e.,\nX\n|a(\u03be, \u03b7)| < \u221e and a(\u03be, \u03b7) = a(\u03b6\u03be, \u03b6\u03b7) (\u03be, \u03b7, \u03b6 \u2208 \u039b),\n(2.1.1)\n\u03b7\u2208\u039b\n\nand assume that a is irreducible in the sense that for all \u2206 \u2282 \u039b with \u2206 6= \u2205, \u039b, there exist\n\u03be \u2208 \u2206 and \u03b7 \u2208 \u039b\\\u2206 such that either a(\u03be, \u03b7) 6= 0 or a(\u03b7, \u03be) 6= 0. We assume moreove that\na(\u03be, \u03b7) \u2265 0\n\n(\u03be 6= \u03b7).\n\n(2.1.2)\n\nConsider a collection x = (x\u03be )\u03be\u2208\u039b of D-valued processes, solving the martingale problem for\nthe operator\nAf (x) :=\n\nX\n\na(\u03b7, \u03be)\n\n\u03b7,\u03be\u2208\u039b\n\nd\nX\n\nx\u03b7,i \u2202x\u2202\u03be,i f (x) +\n\nd\nXX\n\n2\n\nwij (x\u03be ) \u2202x\u03be,i\u2202\u2202x\u03be,j f (x),\n\n(2.1.3)\n\n\u03be\u2208\u039b i,j=1\n\ni=1\n\n\u039b\n\nwhere we write x = (x\u03be )\u03be\u2208\u039b and x\u03be = (x\u03be,1 , . . . , x\u03be,d ) for a point x \u2208 D , and the domain of A\n\u039b\nconsists of all functions on D that depend only on finitely many coordinates through a C (2)\n\u039b\nfunction of compact support. It is well-known that D -valued (weak) solutions to a system\nof SDE's of the form\nX\n\u221a\n(t \u2265 0, \u03be \u2208 \u039b),\n(2.1.4)\ndx\u03be (t) =\na(\u03b7, \u03be)x\u03b7 (t)dt + 2\u03c3(x\u03be (t))dB\u03be (t)\n\u03b7\u2208\u039b\n\n19\n\n\f20\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nsolve the martingale problem for A, were (B\u03be )x\u2208\u039b is a system of independent d\u2032 -dimensional\nBrownian motions, and the d \u00d7 d\u2032 matrix-valued function \u03c3 is continuous and satisfies\n\u2032\n\nd\nX\n\n\u03c3ik (x)\u03c3jk (x) = wij (x).\n\n(2.1.5)\n\nk=1\n\nConversely (see [EK86, Theorem 5.3.3] for the finite dimensional case), every solution to the\nmartingale problem for A can be represented as a solution to the SDE (2.1.4), where there is\nsome freedom in the choice of the root \u03c3 of the diffusion matrix w.\nEquation (2.1.4) says that x is a system of linearly interacting d-dimensional diffusions. As\na result of assumption (2.1.2), the linear drift causes the components (x\u03be )\u03be\u2208\u039b to be positively\ncorrelated.\nSet\nX\n\u03bb := a(0, 0) \u2212\na(0, \u03be).\n(2.1.6)\n\u03be\n\nFor reasons that will become clear in a moment (see formula (2.1.9) (i) and the remarks below\nit), if \u03bb > 0, we have to assume that D is a cone in order for solutions of (2.1.4) to exist.\nUnder suitable assumptions on the diffusion matrix w, it can then be shown that the system\nof SDE's (2.1.4) defines a strong Markov process in a Ligget-Spitzer space E\u03b3 (\u039b), defined as\n\b\n\u039b X\nE\u03b3 (\u039b) := x \u2208 D :\n\u03b3\u03be |x\u03be | < \u221e ,\n(2.1.7)\n\u03be\u2208\u039b\n\nP\nP\nwhere (\u03b3\u03be )\u03be\u2208\u039b are strictly positive constants such that \u03be\u2208\u039b \u03b3\u03be < \u221e and \u03b7\u2208\u039b a(\u03b7, \u03be)\u03b3\u03b7 \u2264\nK\u03b3\u03be (\u03be \u2208 \u039b), for some K < \u221e. The Markov process x is uniquely defined by the lattice \u039b,\nthe interaction kernel a, the domain D, and the diffusion matrix w.\nBasic information about the process x can be obtained by calculating its mean and covariances. Consider a random walk R = (Rt )t\u22650 on \u039b that jumps from a point \u03be to a point \u03b7\nwith rate a(\u03be, \u03b7) (\u03be 6= \u03b7). This random walk is called the underlying motion of x. Set\nPt (\u03be, \u03b7) := P \u03be [Rt = \u03b7].\n\n(2.1.8)\n\nand recall the definition of \u03bb in (2.1.6). Write x\u03be (t) = (x\u03be,1 (t), . . . , x\u03be,d (t)). Then\nX\nPt (\u03b7, \u03be)E[x\u03b7,i (0)],\n(i)\nE[x\u03be,i (t)] = e\u03bbt\n\u03b7\u2208\u039b\nX\n\n(ii) Cov(x\u03be,i (t), x\u03b7,j (t)) = e2\u03bbt\n+\n\nZ\n\n0\n\nPt (\u03b6, \u03be)Pt (\u03b8, \u03b7)Cov(x\u03b6,i (0), x\u03b8,j (0))\n\n\u03b6,\u03b8\nt\n2\u03bbs\n\ne\n\nX\n\u03b6\n\n(2.1.9)\n\nPs (\u03b6, \u03be)Ps (\u03b6, \u03b7)E[wij (x\u03b6 (t \u2212 s))]ds.\n\n(t \u2265 0, \u03be, \u03b7 \u2208 \u039b, 1 \u2264 i, j \u2264 d). Let us start the process x in an initial law L(x(0)) that is\nhomogeneous in the sense that it is invariant with respect to left multiplication in the group,\ni.e., L((x\u03be (0))\u03be\u2208\u039b ) = L((x\u03b6\u03be (0))\u03be\u2208\u039b ) for each \u03b6 \u2208 \u039b. Then, as a function of the parameter \u03bb,\nthe process x experiences a phase transition at \u03bb = 0. If \u03bb < 0, then in many examples it can\n\n\f21\n\n2.1. INTRODUCTION\n\nbe shown that the process started in any homogeneous initial law converges, as\nR t \u2192 \u221e, to a\nunique homogeneous invariant law \u03bd. Letting t \u2192 \u221e in (2.1.9) (i) we see that \u03bd(dx)x\u03be,i = 0\nfor each \u03be \u2208 \u039b, i = 1, . . . , d. On the other hand, as one may guess from (2.1.9) (i), for \u03bb > 0\nthe process becomes unstable in the sense that the process started in a nonzero homogeneous\ninitial state does not converge to an invariant law, but grows exponentially.\nIn the critical case \u03bb = 0, the long-time behavior of x is more subtle. Let us call\n\u2202w D := {x \u2208 D : wij (x) = 0 \u2200i, j = 1, . . . , d}\n\n(2.1.10)\n\nthe effective boundary of D (associated with w). Note that \u2202w D is the set of traps of the\nprocess x, in the sense that the process started in a constant initial state x\u03be (0) = \u03b8 (\u03be \u2208 \u039b)\nwith \u03b8 \u2208 \u2202w D satisfies x\u03be (t) = \u03b8 (t \u2265 0, \u03be \u2208 \u039b). Let us say an initial law L(x(0)) is nontrivial\nif P [\u2203\u03b8 \u2208 \u2202w D s.t. x\u03be (0) = \u03b8 \u2200\u03be \u2208 \u039b] = 0.\nA natural question is whether x has homogeneous nontrivial invariant laws. In order to\nguess the answer to this question, we must look at the covariance formula (2.1.9) (ii). We\nobserve that\nZ \u221eX\nhZ \u221e\ni\nG(\u03be, \u03b7) :=\nPt (\u03b6, \u03be)Pt (\u03b6, \u03b7)dt = E\n1 \u2020,\u03be\n(2.1.11)\n\u2020,\u03b7 dt\n{Rt = R\u0303t }\n0\n0\n\u03b6\n\nis the expected time spent together by two independent random walks R\u2020,\u03be and R\u0303\u2020,\u03b7 , started\nin R0\u2020,\u03be = \u03be and R\u03030\u2020,\u03b7 = \u03b7, and jumping from a point \u03be to a point \u03b7 with the reversed jump\nrates a\u2020 (\u03be, \u03b7) := a(\u03b7, \u03be). If \u039b is an abelian group, with group action denoted by (\u03be, \u03b7) 7\u2192 \u03be + \u03b7,\nthen the difference Rt\u2020,\u03be \u2212 R\u0303t\u2020,\u03b7 is itself a random walk, with symmetrized jump rates as (\u03be, \u03b7) :=\na(\u03be, \u03b7) + a(\u03b7, \u03be), and G is finite if and only this random walk is recurrent. In particular, this\nis true for finite range jump kernels on Zn if and only if n \u2264 2.\nIt follows from (2.1.9) (ii) that the process x cannot have nontrivial homogeneous invariant\nlaws with finite second moments if G(0, 0) = \u221e. Indeed, it has been verified for a number of\nexamples of finite range models on Zn , that x has nontrivial homogeneous invariant laws if\nand only if n > 2. More precisely, in the transient case n > 2, the process has a nontrivial\nhomogeneous invariant law with mean \u03b8 for each \u03b8 \u2208 D\\\u2202w D, which is the limit law of the\nprocess started in any spatially ergodic initial law with mean \u03b8. This type of behavior is\ncalled stable behavior. On the other hand, in the recurrent case n \u2264 2, the only homogeneous\ninvariant laws of the process are the delta-measures \u03b4\u03b8 on constant configurations \u03b8 \u2208 \u2202w D.\nIn this case, the law of the process started from a spatially ergodic initial law with mean\n\u03b8 \u2208 D\\\u2202w D converges, as time tends to infinity, to a convex combination of these delta\nmeasures. This means that there are regions in space of growing size, called clusters, where\nthe process is approximately constant and equal to some \u03b8 \u2208 \u2202w D. This type of behavior is\ncalled clustering.\nA general result on stable behavior for d = 1 (i.e., for one-dimensional domains D) can\nbe found in [Shi92]. A general result on clustering for d = 1 can be found in [CFG96]. Some\n(weak) general results in dimensions d \u2265 2 for bounded domains D can be found in [Swa00].\nBelow, we list some explicit examples that have been treated in the literature.\nThe Ornstein-Uhlenbeck process D = R, w(x) = \u03b1 > 0. This is a Gaussian model that has\nbeen studied in [Deu89]. This reference also contains results for the subcritical case \u03bb < 0.\n\n\f22\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nThe super-random walk D = [0, \u221e), w(x) = \u03b1x, with \u03b1 > 0. This is the discrete space\nanalogue of the well-known super-Brownian motion [Daw77, Daw93, Eth00]. Both the superrandom walk and the super-Brownian motion are continuous-mass branching processes. For\nthese models, the dichotomy between stable behavior and clustering can be proved with the\nhelp of Kallenberg's backward tree technique [Kal77, GW91].\nThe stepping stone model D = [0, 1], w(x) = \u03b1x(1 \u2212 x), with resampling parameter \u03b1 > 0.\nThis model, on rather general lattices, has been treated by Shiga [Shi80a, Shi80b], who also\ngives results for the subcritical case \u03bb < 0. The diffusion function w(x) = x(1 \u2212 x) is called\nthe Wright-Fisher diffusion function and is motivated by applications in population dynamics.\nGeneralizations to other diffusion functions w : [0, 1] \u2192 R that satisfy w(0) = w(1) = 0 and\nw > 0 on (0, 1) can be found in [NS80, CG94]. The multidimensional\nWright-Fisher diffusion\nPd\nd\nmatrix wij (x) := xi (\u03b4ij \u2212 xj ) on D := {x \u2208 R : xi \u2265 0,\ni=1 xi \u2264 1} can be treated with the\nhelp of Donnelly and Kurtz's look-down construction [DK96, GLW05].\n\u0012\n\u0013\n\u03b1x1\n0\nCatalytic branching D = [0, \u221e)2 , w(x) =\n, with \u03b1, \u03b2 > 0. This model has been\n0 \u03b2x1 x2\nstudied in [Pen04]. A continuous space version of this model, the catalytic super-Brownian\nmotion, has been studied in [DF97a, DF97b, EF98, FK99]. A discrete particle version of this\nmodel has been studied in [GKW99].\n\u0012\n\u0013\n\u03b1x1 x2\n0\n, with \u03b1, \u03b2 > 0. This\nMutually catalytic branching D = [0, \u221e)2 , w(x) =\n0\n\u03b2x1 x2\nmodel has been studied in [DP98]. Its continuous-space analogue, the mutually catalytic\nsuper-Brownian motion, has recieved a lot of attention [DEFMPX02a, DEFMPX02b, DF02,\nDFMPX03].\n\u0012\n\u0013\n\u03b1x1 (1 \u2212 x1 )\n0\nCatalytic Wright-Fisher diffusions D = [0, 1]2 , w(x) =\n,\n0\np(x1 )x2 (1 \u2212 x2 )\nwhere \u03b1 > 0 and the catalyzing function p : [0, 1] \u2192 [0, \u221e) Lipschitz continuous. This\nmodel, with the first component replaced by a voter model (which heuristically corresponds\nto taking \u03b1 = \u221e) has been studied in [GKW01]. This model will also be the main subject of\nour present chapter.\nIn the clustering regime (i.e., the case \u039b = Zn with n \u2264 2, or more generally the case where\nthe quantity G(0, 0) from (2.1.11) is infinite), it is an interesting problem to determine the\nclustering distribution\nlim L(x0 (t))\n(2.1.12)\nt\u2192\u221e\n\nof the process started in a constant initial state x\u03be (0) = \u03b8 (\u03be \u2208 \u039b), for all \u03b8 \u2208 D. If this limit\nexists, then it will be concentrated on the effective boundary \u2202w D. In dimension d = 1, when\n\u2202w D consists of the finite endpoints of the interval D, the clustering distribution is trivial. In\nparticular, if D = [0, 1], then as a result of (2.1.9) (i), it is \u03b8\u03b41 + (1 \u2212 \u03b8)\u03b40 .\nMore generally, for any bounded domain D in dimensions d P\n\u2265 1, let Hw denote the class\n2\nof w-harmonic functions, i.e., functions h \u2208 C (2) (D) satisfying ij wij (x) \u2202x\u2202i \u2202xj h(x) = 0 on\nD. Assume that Hw has the property that\nc\nTx,t\nh(Hw ) \u2282 Hw\n\n(t \u2265 0, c > 0, x \u2208 D),\n\n(2.1.13)\n\n\f23\n\n2.1. INTRODUCTION\nwhere\n\nc\n(2.1.14)\nTx,t\nh(y) := h(x + (y \u2212 x)e\u2212ct ) (t \u2265 0, c > 0, x \u2208 D)\nP\nis the semigroup with generator di=1 c(xi \u2212yi ) \u2202y\u2202 i , i.e., the generator of a deterministic process\nwith a linear drift with strength c towards x. Under this assumption, it has been shown in\n[Swa00] that (2.1.9) (i), in the critical case \u03bb = 0, can be generalized to\n\nE[h(x\u03be,i (t))] =\n\nX\n\nPt (\u03b7, \u03be)E[h(x\u03b7,i (0))]\n\n\u03b7\u2208\u039b\n\n(t \u2265 0, h \u2208 Hw ),\n\n(2.1.15)\n\nand this is enough to determine the clustering distribution uniquely. Indeed, the limit in\n(2.1.12) must be the unique Hw -harmonic measure on \u2202w D with mean x. If (2.1.13) holds then\nwe say that w has invariant harmonics. Diffusion matrices on higher-dimensional domains do\nnot in general have invariant harmonics; this applies in particular to catalytic Wright-Fisher\ndiffusions if the catalyzing function p satisfies p(0) = 0 and p(1) > 0.\nTo get an idea of what the clustering distribution could be in general, we need to analyze\nthe behavior of x on large space and time scales. We start with the large space-time behavior\nof the usual stepping stone model.\n\n2.1.2\n\nLarge space-time behavior\n\nThe behavior of the stepping stone model on Zn , with resampling parameter \u03b1, on large\nspatial and temporal scales can be studied with the help of its moment dual, a system of rate\n\u03b1 coalescing random walks. In fact, it is in particular the \u03b1 \u2192 \u221e limit of these models that\nhas been studied in detail, that is, the voter model and its dual, a system of immediately\ncoalescing random walks. A good reference is [CG86].\nIn this section, we will especially be interested in the case n = 2, which is the critical\ndimension for random walk to be recurrent. Indeed, a 2-dimensional random walk (Rt )t\u22650 is\nrecurrent, but it is only barely so. This is expressed, for example, in the fact that the quantity\nE\n\n\u0002\n\nZ\n\nt\n\n0\n\n1{R = 0}\ns\n\n\u0003\n\n(2.1.16)\n\n(s, t \u2265 0)\n\n(2.1.17)\n\ntends very slowly to infinity as t \u2192 \u221e. (For a precise definition of critical recurrence, see\n[Kle96, formula (1.15)].) As a result, on Z2 we see critical phenomenon associated with the\nphase transition between recurrence and transience.\nLet x be a finite-range stepping stone model on Z2 , started in a constant configuration\nx\u03be (0) = \u03b8 (\u03be \u2208 Z2 ), for some \u03b8 \u2208 [0, 1]. Let\n1 \u2212s\n\n\u2206ts := [0, t 2 e ]2 \u2229 Z2\n\u2212s\n\nbe a block of volume te , and let\nxs (t) :=\n\n1 X\nx\u03be (t)\n|\u2206ts |\nt\n\u03be\u2208\u2206s\n\n(s, t \u2265 0)\n\n(2.1.18)\n\n\f24\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nbe the average of x(t) over \u2206ts . By combining [CG86, Theorem 5] and [FG94, Theorem 2] as\ndescribed in [GKW01, Proposition 3.1], it follows that\n\u0001 f.d.d.\nL (xs (t))s\u22650 =\u21d2 (ys )s\u22650 ,\n\n(2.1.19)\n\nt\u2192\u221e\n\np\nwhere (ys )s\u22650 is a Wright-Fisher diffusion, i.e., a solution to dys = ys (1 \u2212 ys )dBs , started\nin y0 = \u03b8. Here f.d.d. denotes convergence in finite dimensional distributions. (The question\nwhether the convergence in f.d.d. can be replaced by weak convergence in path space is the\nsubject of ongoing research.) Formula (2.1.19) shows how block averages at late times t\nchange as we zoom in in space. Very large block avarages, over blocks of volume t, still show\nthe original intensity \u03b8 that the process x was starting in. As we zoom in on smaller blocks of\n\u2212s\nvolume te , with s \u2265 0, the block averages change in a random way, until after some random\ntime, the Wright-Fisher diffusion ys hits 0 or 1, (with probabilities 1 \u2212 \u03b8 or \u03b8, respectively),\nand from that random scale on, the block avarages are constant.\nNote that the long-time behavior of the limiting diffusion y in (2.1.19) gives us the clustering distribution (2.1.12). It seems likely that similar results hold for other models as well;\nhowever, the limiting diffusion in (2.1.19) will not always be the Wright-Fisher diffusion. To\nfind out what the limit could be more generally, it is helpful to replace the lattice Z2 by the\nhierarchical group, as explained in the next section.\n\n2.1.3\n\nHierarchically interacting diffusions\n\nFor any N \u2265 2, the hierarchical group with freedom N is the set \u03a9N of all sequences \u03be =\n(\u03be1 , \u03be2 , . . .), with coordinates \u03bek in the finite set {0, . . . , N \u2212 1}, which are different from 0 only\nfinitely often, equipped with componentwise addition modulo N . Setting\nk\u03bek := min{n \u2265 0 : \u03bek = 0 \u2200k > n}\n\n(\u03be \u2208 \u03a9N ),\n\n(2.1.20)\n\nk\u03be \u2212 \u03b7k is said to be the hierarchical distance between two sites \u03be and \u03b7 in \u03a9N .\nLet xN = (xN\n\u03be )\u03be\u2208\u03a9N be a critical system of linearly interacting diffusions on \u03a9N with\ninteraction kernel given by\naN (\u03be, \u03b7) :=\n\n\u221e\nX\n\nk=k\u03be\u2212\u03b7k\n\nck\u22121\nN 2k\u22121\n\n(\u03be 6= \u03b7),\n\naN (\u03be, \u03be) := \u2212\n\nX\n\naN (\u03be, \u03b7),\n\n(2.1.21)\n\n\u03b76=\u03be\n\nP\nP\nwhere (ck )k\u22650 are positive migration constants such that the quantity \u03be aN (0, \u03be) = k ck /N k\nis finite. The random walk associated with aN is recurrent if and only if\n\u221e\nX\n1\n= \u221e,\ndk\n\nwhere dk :=\n\n\u221e\nX\nck+n\n\nn=0\n\nk=0\n\nNn\n\n(2.1.22)\n\n(see [DG93a, Kle96]; a similar problem is treated in [DE68]).\nLet \u2206k (\u03be) := {\u03b7 : k\u03be \u2212 \u03b7k \u2264 k} denote the k-block around \u03be and let\nxk\u03be (t) :=\n\n1\n|\u2206k (\u03be)|\n\nX\n\n\u03b7:k\u03be\u2212\u03b7k\u2264k\n\nx\u03b7 (t)\n\n(k \u2265 0).\n\n(2.1.23)\n\n\f25\n\n2.1. INTRODUCTION\n\ndenote the k-block average around \u03be. The sequence (x00 (t), x10 (t), . . .) of block-averages around\nthe origin is called the interaction chain. Heuristic arguments suggest that in the local mean\nfield limit N \u2192 \u221e, the interaction chain converges to a certain well-defined Markov chain. In\norder to charcterize this chain, we need a few definitions.\nDefinition 2.1 (Renormalization class and transformation) Let D \u2282 Rd be nonempty,\nconvex, and open, and let D be its closure. Let W be a collection of continuous functions w\nfrom D into the space M+d of symmetric non-negative definite d \u00d7 d real matrices, such that\n\u03bbw \u2208 W for every \u03bb > 0, w \u2208 W. We call W a prerenormalization class on D if the following\nthree conditions are satisfied:\n(i) For each constant c > 0, w \u2208 W, and x \u2208 D, the martingale problem for the operator\nAc,w\nx is well-posed, where\nAc,w\nx f (y)\n\n:=\n\nd\nX\ni=1\n\nc (xi \u2212\n\nyi ) \u2202y\u2202 i f (y) +\n\nd\nX\n\n2\n\nwij (y) \u2202y\u2202i \u2202yj f (y)\n\ni,j=1\n\n(y \u2208 D),\n\n(2.1.24)\n\nand the domain of Ac,w\nis the space of real functions on D that can be extended to a\nx\ntwice continuously differentiable function on Rd with compact support.\n(ii) For each c > 0, w \u2208 W, and x \u2208 D, the martingale problem for Ac,w\nhas a unique\nx\nstationary solution with invariant law denoted by \u03bdxc,w .\nZ\n\u03bdxc,w (dy)|wij (y)| < \u221e.\n(iii) For each c > 0, w \u2208 W, x \u2208 D, and i, j = 1, . . . , d, one has\nD\n\nIf W is a prerenormalization class, then we define for each c > 0 and w \u2208 W a matrix-valued\nfunction Fc w on D by\nZ\nFc w(x) :=\n(2.1.25)\n\u03bdxc,w (dy)w(y)\n(x \u2208 D).\nD\n\nWe say that W is a renormalization class on D if in addition:\n(iv) For each c > 0 and w \u2208 W, the function Fc w is an element of W.\nIf W is a renormalization class and c > 0, then the map Fc : W \u2192 W defined by (2.1.25) is\ncalled the renormalization transformation on W with migration constant c. In (2.1.24), w is\ncalled the diffusion matrix and x the attraction point.\n\u2666\nFor any renormalization class W and any sequence of (strictly) positive migration constants\n(ck )k\u22650 , we define iterated renormalization transformations F (n) : W \u2192 W, as follows:\nF (n+1) w := Fcn (F (n) w)\n\n(n \u2265 0)\n\nWe set s0 := 0 and\nsn :=\n\nn\u22121\nX\nk=0\n\nwith\n1\nck\n\nF (0) w := w\n\n(1 \u2264 n \u2264 \u221e).\n\n(w \u2208 Wcat ).\n\n(2.1.26)\n\n(2.1.27)\n\nWith these definitions, we can formulate the following conjecture about the behavior of the\ninteraction chain in the local mean field limit N \u2192 \u221e.\n\n\f26\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nConjecture 2.2 Let W be a renormalization\nclass. Fix w \u2208 W, \u03b8 \u2208 D, and positive numbers\nP\n(ck )k\u22650 such that for N large enough, k ck /N k < \u221e. For all N large enough, let xN be a\nsolution to (2.1.4) on \u039b = \u03a9N with a = aN from (2.1.21), and assume that tN are constants\nsuch that, for some n \u2265 1, limN \u2192\u221e N \u2212n tN = T \u2208 [0, \u221e). Then\n\u0010\n\u0011\nN,0\nw\nxN,n\n=\u21d2 (I\u2212n\n, . . . , I0w ),\n(2.1.28)\n0 (tN ), . . . , x0 (tN )\nN \u2192\u221e\n\nw , . . . , I w ) is a Markov chain with transition laws\nwhere (I\u2212n\n0\nw\nw\n= x] = \u03bdxck ,F\n\u2208 dy|I\u2212k\u22121\nP [I\u2212k\n\n(k) w\n\n(dy)\n\n(x \u2208 D, 0 \u2264 k \u2264 n \u2212 1)\n\n(2.1.29)\n\nand initial state\nw\nI\u2212n\n= yT ,\n\nwhere\n\ndyt = cn (\u03b8 \u2212 yt )dt +\n\n\u221a\n\n2\u03c3 (n) (yt )dBt ,\n\ny0 = \u03b8,\n\n(2.1.30)\n\nand \u03c3 (n) is a root of the diffusion matrix F (n) w.\nRigorous versions of conjecture 2.2 have been proved for renormalization classes on D = [0, 1]\nand D = [0, \u221e) in [DG93a, DG93b]. See [DG96, DGV95] for similar results. Note that the\nw , . . . , I w ) is a sort of analogue of the block averages (xs (t))\nMarkov chain I w = (I\u2212n\ns\u22650 defined\n0\nin (2.1.18). As we will see below, for appropriate choices of the constants (ck )k\u22650 , the discrete\nchain I w can be approximated by a diffusion, in the spirit of (2.1.19). In order to see this,\nwe need a few facts about renormalization classes. To keep things as simple as possible, we\nspecialize to renormalization classes on bounded domains, although much of what we will say,\nwith some modifications here and there, can be generalized to unbounded domains.\n\n2.1.4\n\nRenormalization classes\n\nIn this section, we describe some elementary properties that hold generally for (pre-) renormalization classes on bounded domains. The proofs of Lemmas 2.3\u20132.8 can be found in\nSection 2.3.1 below.\nFix a prerenormalization class W on a set D where D \u2282 Rd is open, bounded, and convex.\nThen W is a subset of the cone C(D, M+d ) of continuous M+d -valued functions on D. We equip\nC(D, M+d ) with the topology of uniform convergence. We let M1 (D) denote the space of\nprobability measures on D, equipped with the topology of weak convergence. Our first lemma\nsays that the equilibrium measures \u03bdxc,w and the renormalized diffusion matrices Fc w(x) are\ncontinuous in their parameters.\nLemma 2.3 (Continuity in parameters)\n(a) The map (x, c, w) 7\u2192 \u03bdxc,w from D \u00d7 (0, \u221e) \u00d7 W into M1 (D) is continuous.\n(b) The map (x, c, w) 7\u2192 Fc w(x) from D \u00d7 (0, \u221e) \u00d7 W into M+d is continuous.\n\nIn particular, x 7\u2192 \u03bdxc,w is a continuous probability kernel on D, and Fc w \u2208 C(D, M+d ) for all\nc > 0 and w \u2208 W. Recall from Definition 2.1 that \u03bbw \u2208 W for all w \u2208 W and \u03bb > 0. The\nreason why we have included this assumption is that it is convenient to have the next scaling\nlemma around, which is a consequence of time scaling.\n\n\f27\n\n2.1. INTRODUCTION\n\nLemma 2.4 (Scaling property of renormalization transformations) One has\n\u001b\n(i)\n\u03bdx\u03bbc,\u03bbw = \u03bdxc,w\n(\u03bb, c > 0, w \u2208 W, x \u2208 D).\n(2.1.31)\n(ii) F\u03bbc (\u03bbw) = \u03bbFc w\nThe following simple lemma will play a crucial role in what follows.\nLemma 2.5 (Mean and covariance matrix) For all x \u2208 D and i, j = 1, . . . , d, the mean\nand covariances of \u03bdxc,w are given by\nZ\n\u03bdxc,w (dy)(yi \u2212 xi ) = 0,\n(i)\nZ\nD\n(2.1.32)\n(ii)\n\u03bdxc,w (dy)(yi \u2212 xi )(yj \u2212 xj ) = 1c Fc wij (x).\nD\n\nRecall the definition of the effective boundary associated with a diffusion matrix w in (2.1.10).\nThe next lemma says that the effective boundary is invariant under renormalization.\nLemma 2.6 (Invariance of effective boundary) One has \u2202Fc w D = \u2202w D for all w \u2208 W,\nc > 0.\nFrom now on, let W be a renormalization class, i.e., W satisfies also condition (iv) from\nDefinition 2.1. Fix a sequence of (positive) migration constants (ck )k\u22650 . By definition, the\niterated probability kernels K w,(n) associated with a diffusion matrix w \u2208 W (and the constants\n(ck )k\u22650 ) are the probability kernels on D defined inductively by\nZ\n(n)\nw,(n+1)\nKx\n(dz) :=\n\u03bdxcn,F w (dy)Kyw,(n)(dz) (n \u2265 0) with Kxw,(0) (dy) := \u03b4x (dy),\nD\n\n(2.1.33)\nwith\nas in (2.1.26). Note that\nis the transition probability from time \u2212n to time\n0 of the interaction chain in the local mean-field limit (see Conjecture 2.2):\nF (n)\n\nK w,(n)\n\nw\nKxw,(n)(dy) := P [I0w \u2208 dy|I\u2212n\n= x]\n\n(x \u2208 D, n \u2265 0).\n\n(2.1.34)\n\nNote moreover that\nF\n\n(n)\n\nw(x) =\n\nZ\n\nD\n\nKxw,(n)(dy)w(y)\n\n(x \u2208 D, n \u2265 0).\n\n(2.1.35)\n\nThe next lemma follows by iteration from Lemmas 2.3 and 2.5. It their essence, this lemma\nand Lemma 2.8 below go back to [BCGH95].\nLemma 2.7 (Basic properties of iterated kernels) For each w \u2208 W, the K w,(n) are continuous probability kernels on D. Moreover, for all x \u2208 D, i, j = 1, . . . , d, and n \u2265 0, the\nw,(n)\nmean and covariance matrix of Kx\nare given by\nZ\nKxw,(n)(dy)(yi \u2212 xi ) = 0,\n(i)\nZ\nD\n(2.1.36)\nKxw,(n) (dy)(yi \u2212 xi )(yj \u2212 xj ) = sn F (n) wij (x).\n(ii)\nD\n\n\f28\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nWe equip the space C(D, M1 (D)) of continuous probability kernels on D with the topology of\nuniform convergence (since M1 (D) is compact, there is a unique uniform structure on M1 (D)\ngenerating the topology). For 'nice' renormalization classes, it seems reasonable to conjecture\nthat the kernels K w,(n) converge as n \u2192 \u221e to some limit K w,\u2217 in C(D, M1 (D)). If this\nhappens, then formula (2.1.36) (ii) tells us that the rescaled renormalized diffusion matrices\nsn F (n) w converge uniformly on D to the covariance matrix of K w,\u2217 .\nWe will mainly be interested in the case that limn\u2192\u221e sn = \u221e. Indeed, if the iterated\nkernels converge to a limit K w,\u2217 , then this condition guarantees that this limit is concentrated\non the effective boundary:\nLemma 2.8 (Concentration on the effective boundary) If sn \u2212\u2192 \u221e, then for any\nn\u2192\u221e\n\nf \u2208 C(D) such that f = 0 on \u2202w D:\n\nlim sup\n\nn\u2192\u221e\n\nx\u2208D\n\nZ\n\nD\n\nKxw,(n) (dy)f (y) = 0.\n\n(2.1.37)\n\nP\nNote that sn \u2192 \u221e if and\nP only if k 1/ck = \u221e. We can think of this condition as the N \u2192 \u221e\nlimit of the condition\nk 1/dk = \u221e in (2.1.22). Thus, the condition sn \u2192 \u221e guarantees\nthat the corresponding system of linearly interacting diffusions on the hierarchical group with\nmigration constants (ck )k\u22650 clusters in the local mean field limit.\nMost of the discussion in this section carries over to renormalization classes on unbounded\nD, but in this case, the second moments of the iterated kernels K w,(n) may diverge as n \u2192 \u221e.\nAs a result, because of formula (2.1.36) (ii), the sn may no longer be the right scaling factors\nto find a nontrivial limit of the renormalized diffusion matrices; see, for example, [BCGH97].\n\n2.1.5\n\nRescaled transformations\n\nWe return to renormalization classes on bounded domains, and focus our attention on the\nclustering regime sn \u2192 \u221e. Since we expect sn F (n) w to converge to a limit (namely, the\ncovariance matrix of K w,\u2217 ), we will use Lemma 2.4 to convert the rescaled iterates sn F (n) into\n(usual, not rescaled) iterates of another transformation. For this purpose, it will be convenient\nto modify the definition of our scaling constants sn a little bit. Fix some \u03b2 > 0 and put\nsn := \u03b2 + sn\n\n(n \u2265 0).\n\n(2.1.38)\n\nDefine rescaled renormalization transformations F \u03b3 : W \u2192 W by\nF \u03b3 w := (1 + \u03b3)F1/\u03b3 w\n\n(\u03b3 > 0, w \u2208 W).\n\n(2.1.39)\n\nUsing (2.1.31) (ii), one easily deduces that\nsn F (n) w = F \u03b3n\u22121 \u25e6 * * * \u25e6 F \u03b30 (\u03b2w)\nwhere\n\u03b3n :=\n\n1\nsn cn\n\n(w \u2208 W, n \u2265 1),\n\n(n \u2265 0).\n\n(2.1.40)\n\n(2.1.41)\n\n\f29\n\n2.1. INTRODUCTION\n\nWe can reformulate the condition sn \u2192 \u221e from Lemma 2.8 in terms of the constants\n(\u03b3n )n\u22650 . Indeed, it is not hard to check1 that the following three conditions are equivalent:\nX\n(iii)\n\u03b3n = \u221e.\n(2.1.42)\n(i) sn \u2212\u2192 \u221e,\n(ii) sn \u2212\u2192 \u221e,\nn\u2192\u221e\n\nn\u2192\u221e\n\nn\n\nIn view of (2.1.40), it is natural to assume that the \u03b3n converge to a limit \u03b3 \u2217 \u2208 [0, \u221e]. Since\nsn+1 /sn = 1 + \u03b3n , it is not hard to see that the following conditions are equivalent:\nsn+1\nsn+1\n(i)\n\u2212\u2192 1 + \u03b3 \u2217 ,\n(ii)\n\u2212\u2192 1 + \u03b3 \u2217 ,\n(iii) \u03b3n \u2212\u2192 \u03b3 \u2217 .\n(2.1.43)\nn\u2192\u221e\nsn n\u2192\u221e\nsn n\u2192\u221e\nIf 0 < \u03b3 \u2217 < \u221e, then, in the light of (2.1.40), we expect sn F (n) w to converge to a fixed point\nof the transformation F \u03b3 \u2217 . If \u03b3 \u2217 = 0, the situation is more complex. In this case, we expect\nthe orbit sn F (n) w 7\u2192 sn+1 F (n+1) w 7\u2192 * * * , for large n, to approximate a continuous flow, the\ngenerator of which is\n\u0010\n\u0011\nlim \u03b3 \u22121 F \u03b3 w \u2212 w (x) =\n\n\u03b3\u21920\n\n1\n2\n\nd\nX\n\n2\n\nwij (x) \u2202x\u2202i \u2202xj w(x) + w(x)\n\ni,j=1\n\n(x \u2208 D).\n\n(2.1.44)\n\nTo see that the right-hand side of this equation equals the left-hand side if w is twice continuously differentiable, one needs a Taylor expansion of w together with the moment formulas\n1/\u03b3,w\n(2.1.32) for \u03bdx\n. Under condition condition (2.1.42) (iii), we expect this continuous flow to\nreach equilibrium.\nIn the light if these considerations, we are led to at the following general conjecture.\nConjecture 2.9 (Limits of rescaled renormalized diffusion matrices) Assume that\nsn \u2192 \u221e and sn+1 /sn \u2192 1 + \u03b3 \u2217 for some \u03b3 \u2217 \u2208 [0, \u221e]. Then, for any w \u2208 W,\nsn F (n) w \u2212\u2192 w\u2217 ,\n\n(2.1.45)\n\nn\u2192\u221e\n\nwhere w\u2217 satisfies\nF \u03b3 \u2217 w\u2217 = w\u2217\n\n(i)\n(ii)\n\n1\n2\n\nd\nX\n\ni,j=1\n\n(iii)\n\n2\n\n\u2217\nwij\n(x) \u2202x\u2202i \u2202xj w\u2217 (x) + w\u2217 (x) = 0\n\nlim F \u03b3 w\u2217 = w\u2217\n\n\u03b3\u2192\u221e\n\nif 0 < \u03b3 \u2217 < \u221e,\n(x \u2208 D)\n\nif \u03b3 \u2217 = 0,\n\n(2.1.46)\n\nif \u03b3 \u2217 = \u221e.\n\nWe call (2.1.46) (ii), which is in some sense the \u03b3 \u2217 \u2192 0 limit of the fixed point equation\n(2.1.46) (i), the asymptotic fixed point equation. A version of formula (2.1.46) (ii) occurred in\n[Swa99, formula (1.3.5)] (a minus sign is missing there).\nIn particular, one may hope that for a given effective boundary, the equations in (2.1.46)\nhave a unique solution. Our main result (Theorem 2.17 below) confirms this conjecture for a\nrenormalization class of catalytic Wright-Fisher diffusions and for \u03b3 \u2217 < \u221e. In Section 2.1.7\nbelow, we discuss numerical evidence that supports Conjecture 2.9 in the case \u03b3 \u2217 = 0 for other\nrenormalization classes on compacta as well.\nP\n1\n\u221e] denote the limit of the sn and note that on the one\nn cn ) \u2265\nn 1/(s\nP hand,\nQ\nP To see this, let s\u221e \u2208 (0, Q\n1/(s\nn cn )) = log( n sn+1 /sn ) = log(s\u221e /s1 ), while on the other hand\nn cn ) \u2264\nn\nn (1 +\nn log(1 + 1/(s\nQ\n1/(sn cn )) = n sn+1 /sn = s\u221e /s1 .\n\n\f30\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\n2.1.6\n\nDiffusive clustering\n\nAssuming that the rescaled renormalized diffusion matrices sn F (n) w converge to a limit w\u2217 ,\nwe can make a guess about the limit of the iterated probability kernels K w,(n).\nConjecture 2.10 (Limits of iterated probability kernels) Assume that sn F (n) w \u2192 w\u2217\nas n \u2192 \u221e. Then, for any w \u2208 W,\nK w,(n) \u2212\u2192 K \u2217 ,\n\n(2.1.47)\n\nn\u2192\u221e\n\nwhere K \u2217 has the following description:\n(i) If 0 < \u03b3 \u2217 < \u221e, then\n\n\u2217\n\nKx\u2217 = lim P x [In\u03b3 \u2208 * ],\n\n(2.1.48)\n\nn\u2192\u221e\n\n\u2217\n\n\u2217\n\n\u2217\n\n\u03b3\nwhere (In\u03b3 )n\u22650 is the Markov chain with transition law P [In+1\n\u2208 * |In\u03b3 = x] = \u03bd 1/\u03b3\n\n\u2217 ,w \u2217\n\n.\n\n(ii) If \u03b3 \u2217 = 0, then\nKx\u2217 = lim P x [It0 \u2208 * ],\n\n(2.1.49)\n\nt\u2192\u221e\n\nwhere (Is0 )s\u22650 is the diffusion process with generator\n(iii) If \u03b3 \u2217 = \u221e, then\n\n\u22022\n\u2217\ni,j=1 wij (y) \u2202yi \u2202yj .\n\nPd\n\n\u2217\n\nKx\u2217 = lim \u03bdx1/\u03b3,w .\n\u03b3\u2192\u221e\n\n(2.1.50)\n\nIf \u03b3 \u2217 < \u221e, this conjecture is motivated by the observation that in this case, the Markov chain\nw , . . . , I w ) from Conjecture 2.2 is approximately time homogeneous for n \u2192 \u221e. The case\n(I\u2212n\n0\nw , Iw\n\u03b3 \u2217 = 0 is of particular interest. In this case I\u2212n\n\u2212n+1 , . . . converges, in the right scaling,\n0\nto the diffusion (Is )s\u22650 with diffusion matrix w\u2217 . This is a sort of analogon of the diffusive\nclustering result (2.1.19). Based on this analogy, we can make one more conjecture.\nConjecture 2.11 (Clustering distribution on Z2 ) Let D \u2282 Rd be open, bounded, and\nconvex, and let W be a renormalization class on D. Assume that the asymptotic fixed point\nequation (2.1.46) (ii) has a unique solution w\u2217 in W. Let \u03c3 be a continuous root of a diffusion\nZ2\n\nmatrix w \u2208 W. Let x = (x\u03be )\u03be\u2208Z2 be a D -valued process, solving the system of SDE's\ndx\u03be (t) =\n\nX\n\n\u03b7: |\u03b7\u2212\u03be|=1\n\n\u0001\nx\u03b7 (t) \u2212 x\u03be (t) dt + \u03c3(x\u03be (t))dB\u03be (t),\n\n(2.1.51)\n\nwith initial condition x\u03be (0) = \u03b8 \u2208 D (\u03be \u2208 Z2 ). Then\n0\nL(x0 (t)) =\u21d2 P [I\u221e\n| I00 = \u03b8]\nt\u2192\u221e\n\nwhere (Is0 )s\u22650 is the diffusion with generator\n\nP\n\n(\u03be \u2208 Z2 ),\n2\n\nij\n\n\u2217 (y) \u2202\nwij\n\u2202yi \u2202yj .\n\n(2.1.52)\n\n\f31\n\n2.1. INTRODUCTION\ncase\n\nfixed points w\u2217 of (2.1.53)\n\neffective boundary\nt\n\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\nt\nt\n\n\u0012\n\n1\n\u0012\n\n2\n\nx1 (1 \u2212 x1 )\n0\n0\nx2 (1 \u2212 x2 )\n\n\u0013\nx1 (1 \u2212 x1 )\n0\n0\np\u22170,1,0 (x1 )x2 (1 \u2212 x2 )\n\u0012\n\n3\n\nq \u2217 (x1 , x2 )\n0\n\u2217\n0\nq (x2 , x1 )\n\u0012\n\n4\n\u0012\n\n5\n\nt\n\n\u0013\n\n\u0013\nx1 (1 \u2212 x1 ) 0\n0\n0\n\nx1 (1 \u2212 x1 )1{x2 >0} 0\n0\n0\n\ng\u2217 (x1 , x2 )\n\n6\n\n\u0013\n\nt\n\n\u0012\n\nm11 m12\nm21 m22\n\n\u0013\n\n\u0013\n\nFigure 2.1: Fixed points of the flow (2.1.53).\n\n2.1.7\n\nNumerical solutions to the asymptotic fixed point equation\n\nLet t 7\u2192 w(t, * ) be a solution to the continuous flow with the generator in (2.1.44), i.e., w is\nan M+d -valued solution to the nonlinear partial differential equation\n\u2202\n\u2202t w(t, x)\n\n=\n\n1\n2\n\nd\nX\n\ni,j=1\n\n2\n\nwij (t, x) \u2202x\u2202i \u2202xj w(t, x) + w(t, x)\n\n(t \u2265 0, x \u2208 D).\n\n(2.1.53)\n\nSolutions to (2.1.53) are quite easy to simulate on a computer. We have simulated solutions\nfor all kind of diffusion matrices (including nondiagonal ones) on the unit square [0, 1]2 , with\nthe effective boundaries 1\u20136 depicted in Figure 2.1. For all initial diffusion matrices w(0, * )\nwe tried, the solution converged as t \u2192 \u221e to a fixed point w\u2217 . In all cases except case 6, the\nfixed point was unique. The fixed points are listed in Figure 2.1. The functions p\u22170,1,0 and q \u2217\nfrom Figure 2.1 are plotted in Figure 2.2.\nThe fixed points for the effective boundaries in cases 1,2, and 4 will be described in Theorem 2.17 below. In particular, p\u22170,1,0 is the function from Theorem 2.17 (c). The simulations\nsuggest that the domain of attraction of these fixed points (within the class of \"all\" diffusion\nmatrices on [0, 1]2 ) is actually a lot larger than the classes for which we are able to prove\nconvergence in Theorem 2.17.\nThe function q \u2217 from case 3 satisfies q \u2217 (x1 , 1) = x1 (1 \u2212 x1 ) and is zero on the other parts\n\n\f32\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n1\n0.9\n\n0.25\n\n0.8\n\n0.2\n\n0.7\n\n0.15\n\n0.6\n0.5\n\n0.1\n\n0.4\n\n0.05\n\n0.3\n\n0\n1\n\n0.2\n\n1\n\n0.1\n0\n\n0.5\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n0.5\n0\n\n1\n\n0\n\nFigure 2.2: The functions p\u22170,1,0 and q \u2217 from cases 2 and 3 of Figure 2.1.\n\nof the boundary. In contrast to what one might perhaps guess in view of case 2, q \u2217 is not of\nthe form q \u2217 (x1 , x2 ) = f (x2 )x1 (1 \u2212 x1 ) for some function f .\nCase 5 is somewhat degenerate since in this case the fixed point is not continuous.\nThe only case where the fixed point is not unique is case 6. Here, m can be any positive\ndefinite matrix, while g\u2217 , depending on m, is the unique solution on (0, 1)2 of the equation\nP\n2\n1 + 12 2i,j=1 mij \u2202x\u2202i \u2202xi g\u2217 (x) = 0, with zero boundary conditions. Some diffusion matrices that\nare in the domain of attraction of these fixed points are described in Theorem 2.14 below.\nThe simulations indicate that the true domain of attraction is much larger than what can be\nproved (and includes nonisotropic matrices).\n\n2.1.8\n\nKnown results\n\nIn this section we discuss some results that have been derived previously for renormalization\nclasses on compact sets.\nTheorem 2.12 [BCGH95, DGV95]\n(Universality class of Wright-Fisher models)\nPd\nd\nLet D := {x \u2208 R : xi > 0 \u2200i,\ni=1 xi < 1}, and let {e0 , . . . , ed }, with e0 := (0, . . . , 0) and\n\u2217 (x) := x (\u03b4 \u2212x )\ne1 := (1, 0, . . . , 0), . . . , ed := (0, . . . , 0, 1) be the extremal points of D. Let wij\ni ij\nj\n(x \u2208 D, i, j = 1, . . . , d) denote the standard Wright-Fisher diffusion matrix, and assume that\nW is a renormalization class on D such that w\u2217 \u2208 W and \u2202w D = {e0 , . . . , ed } for all w \u2208 W.\nLet (ck )k\u22650 be migration constants such that sn \u2192 \u221e as n \u2192 \u221e. Then, for all w \u2208 W,\nuniformly on D,\nsn F (n) w \u2212\u2192 w\u2217 .\n(2.1.54)\nn\u2192\u221e\n\nThe convergence in (2.1.54) is a consequence of Lemmas 2.7 and 2.8: The first moment formula\nw,(n)\n(2.1.36) (i) and (2.1.37) show that Kx\nconverges to the unique distribution on {e0 , . . . , ed }\nwith mean x, and by the second moment formula (2.1.36) (ii) this implies the convergence of\nsn F (n) w.\nIn order for the iterates in (2.1.54) to be well-defined, Theorem 2.12 assumes that a\nrenormalization class W of diffusion matrices w on D with effective boundary {e0 , . . . , ed }\nis given. The problem of finding a nontrivial example of such a renormalization class is open\n\n\f33\n\n2.1. INTRODUCTION\n\nin dimensions greater than one. In the one-dimensional case, however, the following result is\nknown.\nLemma 2.13 [DG93b] (Renormalization class on the unit interval) The set\nWDG := {w \u2208 C[0, 1] : w = 0 on {0, 1}, w > 0 on (0, 1), w Lipschitz}\n\n(2.1.55)\n\nis a renormalization class on [0, 1].\nAbout renormalization of isotropic diffusions, the following result is known. Below, \u2202D :=\nD\\D denotes the topological boundary of D.\nTheorem 2.14 [HS98] (Universality class of isotropic models) Let D \u2282 Rd be open,\n\u2217 (x) :=\nbounded, and convex and let m \u2208 M+d be fixed and (strictly) positive definite. Set wij\nP\n2\nmij g\u2217 (x), where g \u2217 is the unique solution of 1 + 12 ij mij \u2202x\u2202i \u2202xj g\u2217 (x) = 0 for x \u2208 D and\ng\u2217 (x) = 0 for x \u2208 \u2202D. Assume that W is a renormalization class on D such that w\u2217 \u2208 W\nand such that each w \u2208 W is of the form\nwij (x) = mij g(x)\n\n(x \u2208 D, i, j = 1, . . . , d),\n\n(2.1.56)\n\nfor some g \u2208 C(D) satisfying g > 0 on D and g = 0 on \u2202D. Let (ck )k\u22650 be migration constants\nsuch that sn \u2192 \u221e as n \u2192 \u221e. Then, for all w \u2208 W, uniformly on D,\nsn F (n) w \u2212\u2192 w\u2217 .\nn\u2192\u221e\n\n(2.1.57)\n\nThe proof of Theorem 2.14 follows the same lines as the proof of Theorem 2.12, with the\ndifference that in this case one needs to generalize the first moment formula (2.1.36) (i) in\nR\nw,(n)\nthe sense that D Kx\n(dy)h(y) = h(x) for any m-harmonic function h, i.e., h \u2208 C (2) (D)\nP\n2\nw,(n)\n\u2202\nnow converges to the msatisfying\nij mij \u2202xi \u2202xj h(x) = 0 for x \u2208 D. The kernel Kx\nharmonic measure on \u2202D with mean x, and this implies (2.1.57).\nAgain, in dimensions d \u2265 2, the problem of finding a 'reasonable' class W satisfying the\nassumptions of Theorem 2.14 is so far unresolved. The problem with verifying conditions (i)\u2013\n(iv) from Definition 2.1 in an explicit set-up is that (i) and (ii) usually require some smoothness\nof w, while (iv) requires that one can prove the same smoothness for Fc w, which is difficult.\nThe proofs of Theorems 2.12 and 2.14 are both based on invariant harmonics (see (2.1.13)).\nSince diffusion matrices of catalytic Wright-Fisher diffusions do not in general have invariant\nharmonics, in order to prove our main result (Theorem 2.17 below), we will need quite different\ntechniques.\nClosely related to this is the fact that in the renormalization classes from Theorems 2.12\nand 2.14, the unique attraction point w\u2217 does not depend on the parameter \u03b3 \u2217 from (2.1.43).\nAs a result, it turns out that the class {\u03bbw\u2217 : \u03bb > 0} is a fixed shape. Here, for any\nprerenormalization class W, a fixed shape is a subclass \u0174 \u2282 W of the form \u0174 = {\u03bbw : \u03bb > 0}\nwith 0 6= w \u2208 W, such that Fc (\u0174) \u2282 \u0174 for all c > 0. The next lemma, which will be proved\nin Section 2.3.1 below, describes how fixed shapes for renormalization classes on compact sets\ntypically arise.\n\n\f34\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nLemma 2.15 (Fixed shapes) Assume that for each 0 < \u03b3 \u2217 < \u221e, there is a 0 6= w\u2217 = w\u03b3\u2217 \u2217 \u2208\nW such that sn F (n) w \u2212\u2192 w\u03b3\u2217 \u2217 whenever w \u2208 W, sn \u2192 \u221e, and sn+1 /sn \u2192 1 + \u03b3 \u2217 . Then:\nn\u2192\u221e\n\n(a) w\u03b3\u2217 \u2217 is the unique solution in W of equation (2.1.46) (i).\n(b) If w\u2217 = w\u03b3\u2217 \u2217 does not depend on \u03b3 \u2217 , then\n\nFc (\u03bbw\u2217 ) = ( \u03bb1 + 1c )\u22121 w\u2217\n\n(\u03bb, c > 0).\n\n(2.1.58)\n\nMoreover, {\u03bbw\u2217 : \u03bb > 0} is the unique fixed shape in W.\n\n(c) If the w\u03b3\u2217 \u2217 for different values of \u03b3 \u2217 are not constant multiples of each other, then W\ncontains no fixed shapes.\nIn our main result (Theorem 2.17 below), we will describe a renormalization class which we\nbelieve contains no fixed shape.\n\n2.2\n2.2.1\n\nCatalytic Wright-Fisher diffusions\nMain result\n\nMotivated by the previous sections, we will now take the abstract definition of a renormalization class as our starting point, and study iterated renormalization transformations on one such\nclass. Earlier work of this sort has been done in [BCGH95, BCGH97, HS98, Sch98, CDG04].\nThe subject of our study will be the following renormalization class on [0, 1]2 .\nDefinition 2.16 (Renormalization class of catalytic Wright-Fisher diffusions) We\nset Wcat := {w\u03b1,p : \u03b1 > 0, p \u2208 H}, where\n\u0012\n\u0013\n\u03b1x1 (1 \u2212 x1 )\n0\n\u03b1,p\nw (x) :=\n(x = (x1 , x2 ) \u2208 [0, 1]2 ),\n(2.2.1)\n0\np(x1 )x2 (1 \u2212 x2 )\nand\nH := {p : p a real function on [0, 1], p \u2265 0, p Lipschitz continuous}.\n\n(2.2.2)\n\nMoreover, we put\n\nHl,r := {p \u2208 H : 1{p(0)>0} = l, 1{p(1)>0} = r}\nl,r\nand set Wcat\n:= {w\u03b1,p : \u03b1 > 0, p \u2208 Hl,r } (l, r = 0, 1).\n\n(l, r = 0, 1),\n\n(2.2.3)\n\u2666\n\n\u03b1,p\n\nSolutions y = (y1 , y2 ) to the martingale problem for Ac,w\n(recall (2.1.24)) can be represented\nx\nas solutions to the SDE\nq\n(i) dyt1 = c (x1 \u2212 yt1 )dt + 2\u03b1yt1 (1 \u2212 yt1 )dBt1 ,\nq\n(2.2.4)\n2\n2\n2\n1\n2\n2\n(ii) dyt = c (x2 \u2212 yt )dt + 2p(yt )yt (1 \u2212 yt )dBt .\n\nWe call y1 the Wright-Fisher catalyst with resampling rate \u03b1 and y2 the Wright-Fisher reactant\nwith catalyzing function p.\nHere is our main result:\n\n\f35\n\n2.2. CATALYTIC WRIGHT-FISHER DIFFUSIONS\n\nTheorem 2.17 (Main result)\nl,r\nl,r\n(a) The set Wcat is a renormalization class on [0, 1]2 and Fc (Wcat\n) \u2282 Wcat\n(c > 0, l, r = 0, 1).\n(b) Fix (positive) migration constants (ck )k\u22650 such that\n(i)\n\nsn \u2212\u2192 \u221e\nn\u2192\u221e\n\nand\n\n(ii)\n\nsn+1\n\u2212\u2192 1 + \u03b3 \u2217\nsn n\u2192\u221e\n\n(2.2.5)\n\nl,r\nfor some \u03b3 \u2217 \u2265 0. If w \u2208 Wcat\n(l, r = 0, 1), then uniformly on [0, 1]2 ,\n\nsn F (n) w \u2212\u2192 w\u2217 ,\n\n(2.2.6)\n\nn\u2192\u221e\n\nl,r\nwhere the limit w\u2217 is the unique solution in Wcat\nto the equation\n\n(1 + \u03b3 \u2217 )F1/\u03b3 \u2217 w\u2217 = w\u2217\n\n(i)\n(ii)\n\n1\n2\n\n2\nX\n\n2\n\n\u2217\nwij\n(x) \u2202x\u2202i \u2202xj w\u2217 (x) + w\u2217 (x) = 0\n\ni,j=1\n\nif \u03b3 \u2217 > 0,\n(x \u2208 [0, 1]2 )\n\nif \u03b3 \u2217 = 0.\n\n(2.2.7)\n\n\u2217\n\n(c) The matrix w\u2217 is of the form w\u2217 = w1,p , where p\u2217 = p\u2217l,r,\u03b3 \u2217 \u2208 Hl,r depends on l, r, and \u03b3 \u2217 .\nOne has\nfor all \u03b3 \u2217 \u2265 0.\n(2.2.8)\np\u22170,0,\u03b3 \u2217 \u2261 0 and p\u22171,1,\u03b3 \u2217 \u2261 1\n\nFor each \u03b3 \u2217 \u2265 0, the function p\u22170,1,\u03b3 \u2217 is concave, nondecreasing, and satisfies p\u22170,1,\u03b3 \u2217 (0) = 0,\np\u22170,1,\u03b3 \u2217 (1) = 1. By symmetry, analoguous statements hold for p\u22171,0,\u03b3 \u2217 .\nConditions (2.2.5) (i) and (ii) are satisfied, for example, for ck = (1 + \u03b3 \u2217 )\u2212k . Note that the\nfunctions p\u22170,0,\u03b3 \u2217 and p\u22171,1,\u03b3 \u2217 are independent of \u03b3 \u2217 \u2265 0. We believe that on the other hand,\np\u22170,1,\u03b3 \u2217 is not constant as a function of \u03b3 \u2217 , but we have not proved this.2 If this is confirmed,\n0,1\nthen by Lemma 2.15, it follows that Wcat\n, unlike all renormalization classes studied previously,\ncontains no fixed shapes.\nThe function p\u22170,1,0 is the unique nonnegative solution to the equation\n1\n2 x(1\n\n2\n\n\u2202\n\u2212 x) \u2202x\n2 p(x) + p(x)(1 \u2212 p(x)) = 0\n\n(x \u2208 [0, 1])\n\n(2.2.9)\n\nwith boundary conditions p(0) = 0 and p(1) > 0. This function occurred before in the work\nof Greven, Klenke, and Wakolbinger [GKW01, formulas (1.10)\u2013(1.11)], who studied linearly\ninteracting catalytic Wright-Fisher diffusions catalyzed by a voter model. They believe their\nresults to hold for a Wright-Fisher catalyst too, i.e., for a model of the form\nq\nX\n\u0001\nx1\u03b7 (t) \u2212 x1\u03be (t) dt + 2\u03b1x1\u03be (t)(1 \u2212 x1\u03be (t)) dB\u03be1 (t),\ndx1\u03be (t) =\n\u03b7: |\u03b7\u2212\u03be|=1\n\ndx2\u03be (t) =\n\nX\n\n\u03b7: |\u03b7\u2212\u03be|=1\n2\n\nq\n\u0001\nx2\u03b7 (t) \u2212 x2\u03be (t) dt + 2p(x1\u03be (t))x2\u03be (t)(1 \u2212 x2\u03be (t)) dB\u03be2 (t),\n1,p\n\n(2.2.10)\n\n1,U\u03b3 p\nIn support of this, if U\u03b3 (\u03b3 > 0) are transformations such that F\nbelow),\n \u0306 \u03b31 \u2032\u2032= w 4 \u2032(see 2(2.2.21)\n \u0304 then a\n\u2217\n2\nheuristic calculation for p = p0,1,0 yields U\u03b3 p(x) = p(x) + \u03b3 x(1 \u2212 x) 2 p (x) \u2212 3 (p (x)) \u2212 34 xp\u2032\u2032\u2032 (x) + O(\u03b3 3 ),\nwhich implies that p\u22170,1,0 6= p\u22170,1,\u03b3 \u2217 for \u03b3 \u2217 small enough.\n\n\f36\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nwhere \u03b1 > 0 is a constant, p is a nonnegative function on [0, 1] satisfying p(0) = 0 and\np(1) > 0, but they could not prove this due to certain technical difficulties that a [0, 1]-valued\ncatalyst would create, compared to the simpler {0, 1}-valued voter model. They determined\nthe clustering distribution of their model on Z2 , which turns out to coincide with the predic\u2217\ntion made based on renormalization theory in Conjecture 2.11, with w\u2217 = w1,p0,1,0 as in our\nTheorem 2.17.\nThe work in [GKW01] not only provides the main motivation for the present chapter, but\nalso inspired some of our techniques for proving Theorem 2.17. This concerns in particular\nthe proof of Proposition 2.18 below, which makes the connection between renormalization\ntransformations and a branching process. We hope that conversely, our techniques may shed\nsome light on the problems left open by [GKW01], in particular, the question whether their\nresults stay true if the voter model catalyst is replaced by a Wright-Fisher catalyst. It seems\nplausible that their results may not hold for the model in (2.2.10) if the catalyzing function\np grows too fast at 0. On the other hand, our proofs suggest that p with a finite slope at\n0 should be OK. (In particular, while deriving formula (2.2.51) below, we use that p can be\nbounded from above by r+ h0,1 for some r+ > 0, which requires that p has a finite slope at 0.)\n\n2.2.2\n\nOpen problems\n\nThe general program of studying renormalization classes in the sense of Definition 2.1 contains\na wealth of open problems. In our proofs, we make heavy use of the single-way nature of the\ncatalyzation in (2.2.4), in particular, the fact that y1 is an autonomous process which allows\none to condition on y1 and consider y2 as a process in a random environment created by y1 .\nAs soon as one leaves the single-way catalytic regime one runs into several difficulties, both\ntechnically (it is hard to prove that a given class of matrices is a renormalization class in the\nsense of Definition 2.1) and conceptually (it is not clear when solutions to the asymptotic\nfixed shape equation (2.1.46) (ii) are unique). Therefore, it seems at present hard to verify the\ncomplete picture for renormalization classes on the unit square that arises from the numerical\nsimulations described in Section 2.1.7 and Figures 2.1 and 2.2, unless one or more essential\nnew ideas are added.\nIn this context, the study of the nonlinear partial differential equation (2.1.53) and its fixed\npoints seems to be a challenging problem. This may be a hard problem from an analytic point\nof view, since the equation is degenerate and not in divergence form. For the renormalization\nclass Wcat , the quasilinear equation (2.1.53) reduces to the semilinear equation (2.2.26), which\nis analytically easier to treat and moreover has a probabilistic interpretation in terms of\na superprocess. We do not know whether solutions to equation (2.1.53) can in general be\nrepresented in terms of a stochastic process of some sort.\nEven for the renormalization class Wcat , several interesting problems are left open. One of\nthe most urgent ones is to prove that the functions p\u22170,1,\u03b3 \u2217 are not constant in \u03b3 \u2217 , and therefore,\n0,1\nby Lemma 2.15 (c), Wcat\ncontains no fixed shapes. Moreover, we have not investigated the\niterated renormalization transformations in the regime \u03b3 \u2217 = \u221e. Also, we believe that the\nconvergence in (2.2.39) (ii) does not hold if the condition that p is Lipschitz is dropped, in\nparticular, if p(0) = 0 and p has an infinite slope at 0. For p \u2208 H0,0 , it seems plausible that\na properly rescaled version of the iterates U (n) p, with U\u03b3 as in (2.2.20) below, converges to a\n\n\f37\n\n2.2. CATALYTIC WRIGHT-FISHER DIFFUSIONS\n\nuniversal limit, but we have not investigated this either. Finally, we have not investigated the\nconvergence of the iterated kernels K w,(n) from (2.1.33) (in particular, we have not verified\nConjecture 2.10) for the renormalization class Wcat .\nOur methods, combined with those in [BCGH95], can probably be extended to study the\naction of iterated renormalization transformations on diffusion matrices of the following more\ngeneral form (compared to (2.2.1)):\nw(x) =\n\n\u0012\n\ng(x1 )\n0\n0\np(x1 )x2 (1 \u2212 x2 )\n\n\u0013\n\n(x =\u2208 [0, 1]2 ),\n\n(2.2.11)\n\nwhere g : [0, 1] \u2192 R is Lipschitz, g(0) = g(1) = 0, g > 0 on (0, 1), and p \u2208 H as before. This\nwould, however, require a lot of extra technical work and probably not generate much new\ninsight. The numerical simulations mentioned in Section 2.1.7 suggest that many diffusion\nmatrices of an even more general form than (2.2.11) also converge under renormalization to\nthe limit points w\u2217 from Theorem 2.17, but we don't know how to prove this.\nIn the next sections, we will show that for the renormalization class Wcat , the rescaled\nrenormalization transformations F \u03b3 from (2.1.39) can be expressed in terms of the log-Laplace\noperators of a discrete time branching process on [0, 1]. This will allow us to use techniques\nfrom the theory of spatial branching processes to verify Conjecture 2.9 for the renormalization\nclass Wcat in the case \u03b3 \u2217 < \u221e.\n\n2.2.3\n\nPoisson-cluster branching processes\n\nWe first need some concepts and facts from branching theory. Finite measure-valued branching\nprocesses (on R) in discrete time have been introduced by Ji\u0159ina [Jir64]. We need to consider\nonly a special class.\nLet E be a separable, locally compact, and metrizable space. We let C(E) and B(E) denote\nthe spaces of all continuous, and bounded Borel measurable, real functions on E, respectively.\nWe put C+ (E) := {f \u2208 C(E) : f \u2265 0} and define B+ (E) analogously. We let M(E) denote\nthe space of all finite measures on E, equipped with the topology of weak convergence. The\nsubspace of probabilityR measures is denoted by M1 (E). For \u03bc \u2208 M(E) and f \u2208 B(E) we use\nthe notation h\u03bc, f i := E f d\u03bc and |\u03bc| := \u03bc(E).\nWe call a continuous map Q from E into M1 (M(E)) a continuous cluster mechanism. By\ndefinition, an M(E)-valued random variable X is a Poisson cluster measure on E with locally\nfinite intensity measure \u03bc and continuous cluster mechanism Q, if its log-Laplace transform\nsatisfies\nZ\nZ\n\u0011\n\u0010\n\u0002 \u2212hX , f i \u0003\n(f \u2208 B+ (E)).\n(2.2.12)\nQ(x, d\u03c7)e \u2212h\u03c7, f i\n\u2212 log E e\n= \u03bc(dx) 1 \u2212\nE\n\nM(E)\n\nFor given \u03bc and Q, such a Poisson cluster measure exists, and is unique in distribution,\nprovided\nthat the\nP right-hand side of (2.2.12) is finite for f = 1. It may be constructed as X =\nP\ni \u03c7xi , where\ni \u03b4xi is a (possibly infinite) Poisson point measure with intensity \u03bc, and given\nx1 , x2 , . . ., the \u03c7x1 , \u03c7x2 , . . . are independent random variables with laws Q(x1 , * ), Q(x2 , * ), . . .,\nrespectively.\n\n\f38\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nNow fix a finite sequence of functions qk \u2208 C+ (E) and continuous cluster mechanisms Qk\n(k = 1, . . . , n), define\nZ\n\u0011\n\u0010\n(x \u2208 E, f \u2208 B+ (E), k = 1, . . . , n),\nQk (x, d\u03c7)e \u2212h\u03c7, f i\nUk f (x) := qk (x) 1 \u2212\nM(E)\n\n(2.2.13)\n\nand assume that\nsup Uk 1(x) < \u221e\n\n(k = 1, . . . , n).\n\n(2.2.14)\n\nx\u2208E\n\nThen Uk maps B+ (E) into B+ (E) for each k, and for each M(E)-valued initial state X0 , there\nexists a (time-inhomogeneous) Markov chain (X0 , . . . , Xn ) in M(E), such that Xk , given Xk\u22121 ,\nis a Poisson cluster measure with intensity qk Xk\u22121 and cluster mechanism Qk . It is not hard\nto see that the process started in \u03bc satisfies\n\u0002\n\u0003\nE \u03bc e \u2212hXn , f i = e \u2212h\u03bc, U1 \u25e6 * * * \u25e6 Un f i\n(\u03bc \u2208 M(E), f \u2208 B+ (E)).\n(2.2.15)\n\nWe call X = (X0 , . . . , Xn ) the Poisson-cluster branching process on E with weight functions\nq1 , . . . , qn and cluster mechanisms Q1 , . . . , Qn . The operator Uk is called the log-Laplace operator of the transition law from Xk\u22121 to Xk . Note that we can write (2.2.15) in the suggestive\nform\n\u0002\n\u0003\n\u0002\n\u0001\n\u0003\nP \u03bc Pois(f Xn ) = 0 = P Pois (U1 \u25e6 * * * \u25e6 Un f )\u03bc = 0 .\n(2.2.16)\n\nHere, if \u03bc is an M(E)-valued random variable, then Pois(\u03bc) denotes an N (E)-valued random\nvariable such that conditioned on \u03bc, Pois(\u03bc) is a Poisson point measure with intensity \u03bc.\n\n2.2.4\n\nThe renormalization branching process\n\nWe will now construct a Poisson-cluster branching process on [0, 1] of a special kind, and show\nthat the rescaled renormalization transformations on Wcat can be expressed in terms of the\nlog-Laplace operators of this branching process.\nBy Lemma 2.30 below, for each \u03b3 > 0 and x \u2208 [0, 1], the SDE\np\n(2.2.17)\ndy(t) = \u03b31 (x \u2212 y(t))dt + 2y(t)(1 \u2212 y(t))dB(t),\n\nhas a unique (in law) stationary solution. We denote this solution by (yx\u03b3 (t))t\u2208R . Let \u03c4\u03b3 be\nan independent exponentially distributed random variable with mean \u03b3, and set\nZ \u03c4\u03b3\n\u03b4yx\u03b3 (\u2212t/2) dt\n(\u03b3 > 0, x \u2208 [0, 1]).\n(2.2.18)\nZx\u03b3 :=\n0\n\nDefine constants q\u03b3 and continuous (by Corollary 2.36 below) cluster mechanisms Q\u03b3 by\nq\u03b3 :=\n\n1\n\u03b3\n\n+1\n\nand\n\nQ\u03b3 (x, * ) := L(Zx\u03b3 )\n\n(\u03b3 > 0, x \u2208 [0, 1]),\n\n(2.2.19)\n\nand let U\u03b3 denote the log-Laplace operator with (constant) weight function q\u03b3 and cluster\nmechanism Q\u03b3 , i.e.,\nZ\n\u0011\n\u0010\n(x \u2208 [0, 1], f \u2208 B+ [0, 1], \u03b3 > 0). (2.2.20)\nQ\u03b3 (x, d\u03c7)e \u2212h\u03c7, f i\nU\u03b3 f (x) := q\u03b3 1 \u2212\nM([0,1])\n\n\f39\n\n2.2. CATALYTIC WRIGHT-FISHER DIFFUSIONS\n\nWe now establish the connection between renormalization transformations on Wcat and logLaplace operators.\nProposition 2.18 (Identification of the renormalization transformation) Let F \u03b3 be\nthe rescaled renormalization transformation on Wcat defined in (2.1.39). Then\nF \u03b3 w1, p = w1, U\u03b3 p\n\n(p \u2208 H, \u03b3 > 0).\n\n(2.2.21)\n\nFix a diffusion matrix w\u03b1,p \u2208 Wcat and migration constants (ck )k\u22650 . Define constants sn\nand \u03b3n as in (2.1.38) and (2.1.41), respectively, where \u03b2 := 1/\u03b1. Then Proposition 2.18 and\nformula (2.1.40) show that\np\nsn F (n) w\u03b1,p = w1, U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b30 ( \u03b1 ) .\n\n(2.2.22)\n\nHere U\u03b3n\u22121 , . . . , U\u03b30 are the log-Laplace operators of the Poisson-cluster branching process X =\n(X\u2212n , . . . , X0 ) with weight functions q\u03b3n\u22121 , . . . , q\u03b30 and cluster mechanisms Q\u03b3n\u22121 , . . . , Q\u03b30 .\nWe call X (started at some time \u2212n in an initial law L(X\u2212n )) the renormalization branching\nprocess. By formulas (2.2.15) and (2.2.22), the study of the limiting behavior of rescaled\niterated renormalization transformations on Wcat reduces to the study of the renormalization\nbranching process X in the limit n \u2192 \u221e.\n\n2.2.5\n\nConvergence to a time-homogeneous process\n\nLet X = (X\u2212n , . . . , X0 ) be the renormalization\nbranching process introduced in the last section.\nP\nIf the constants (\u03b3k )k\u22650 satisfy n \u03b3n = \u221e and \u03b3n \u2192 \u03b3 \u2217 for some \u03b3 \u2217 \u2208 [0, \u221e), then X is\nalmost time-homogeneous for large n. More precisely, we will prove the following convergence\nresult.\nTheorem 2.19 (Convergence to a time-homogenous branching process) Assume that\nL(X\u2212n ) =\u21d2 \u03bc for some probability law \u03bc on M([0, 1]).\nn\u2192\u221e\n\n(a) If 0 < \u03b3 \u2217 < \u221e, then\n\u2217\n\n\u2217\n\nL(X\u2212n , X\u2212n+1 , . . .) =\u21d2 L(Y0\u03b3 , Y1\u03b3 , . . .),\nn\u2192\u221e\n\n(2.2.23)\n\n\u2217\n\nwhere Y \u03b3 is the time-homogenous branching process with log-Laplace operator U\u03b3 \u2217 in each\n\u2217\nstep and initial law L(Y0\u03b3 ) = \u03bc.\n(b) If \u03b3 \u2217 = 0, then\nL\n\n\u0010\n\nX\u2212kn (t)\n\n\u0001\n\nt\u22650\n\n\u0011\n\n=\u21d2 L\n\nn\u2192\u221e\n\n\u0010\n\nYt0\n\n\u0001\n\n\u0011\n,\nt\u22650\n\n(2.2.24)\n\nwhere\nconvergence of laws on path space, kn (t) := min{k : 0 \u2264 k \u2264 n,\nPn\u22121 \u21d2 denotes weak\n1\n0\nl=k \u03b3l \u2264 t}, and Y is the superprocess on [0, 1] with underlying motion generator 2 x(1 \u2212\n\u22022\n0\nx) \u2202x\n2 and activity and growth parameter both identically 1, started in the initial law L(Y0 ) = \u03bc.\n\n\f40\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nWe call the superprocess Y 0 from part (b) the super-Wright-Fisher diffusion. It is the timehomogeneous Markov process in M[0, 1] with continuous sample paths, whose Laplace functionals are given by\n\u0003\n\u0002\n0\n0\nE \u03bc e \u2212hYt , f i = e \u2212h\u03bc, Ut f i\n\n(\u03bc \u2208 M[0, 1], f \u2208 B+ [0, 1], t \u2265 0),\n\nwhere Ut0 f = ut is the unique mild solution of the semilinear Cauchy equation\n(\n1\n\u22022\n\u2202\n\u2202t ut (x) = 2 x(1 \u2212 x) \u2202x2 ut (x) + ut (x)(1 \u2212 ut (x)) (t \u2265 0, x \u2208 [0, 1]),\nu0 = f.\n\n(2.2.25)\n\n(2.2.26)\n\u2217\n\nFor a further study of the renormalization branching process X and its limiting processes Y \u03b3\n(\u03b3 \u2217 \u2265 0) we will use the technique of embedded particle systems, which we explain in the next\nsection.\n\n2.2.6\n\nWeighted and Poissonized branching processes\n\nIn this section, we explain how from a Poisson-cluster branching process it is possible to construct other branching processes by weighting and Poissonization. We first need to introduce\nspatial branching particle systems in some generality.\nLet E again be separable, locally compact, and metrizable. We set C[0,1] (E) := {f \u2208\nC(E) : 0 \u2264 f \u2264 1} and define B[0,1] (E) analogously.\nP We write N (E) for the space of finite\ncounting measures, i.e., measures of the form \u03bd = m\ni=1 \u03b4xi with x1 , . . . , xm \u2208 E (m \u2265 0). We\ninterpret \u03bd as a collection of particles, situated at positions x1 , . . . , xm . For \u03bd \u2208 N (E) and\nf \u2208 B[0,1] (E), we adopt the notation\nf 0 := 1 and\n\nf \u03bd :=\n\nm\nY\ni=1\n\nf (xi )\n\nwhen \u03bd =\n\nm\nX\ni=1\n\n\u03b4xi\n\n(m \u2265 1).\n\n(2.2.27)\n\nWe call a continuous map x 7\u2192 Q(x, * ) from E into M1 (N (E)) a continuous offspring mechanism.\nFix continuous offspring mechanisms Qk P\n(1 \u2264 k \u2264 n), and let (X0 , . . . , Xn ) be a Markov\nchain in N (E) such that, given that Xk\u22121 = m\ni=1 \u03b4xi , the next step of the chain Xk is a sum\nof independent random variables with laws Qk (xi , * ) (i = 1, . . . , m). Then\n\u0002\n\u0003\nE \u03bd (1 \u2212 f )Xn = (1 \u2212 U1 \u25e6 * * * \u25e6 Un f )\u03bd\n(\u03bd \u2208 N (E), f \u2208 B[0,1] (E)),\n(2.2.28)\n\nwhere Uk : B[0,1] (E) \u2192 B[0,1] (E) is defined as\nZ\nQk (x, d\u03bd)(1 \u2212 f )\u03bd\n(1 \u2264 k \u2264 n, x \u2208 E, f \u2208 B[0,1] (E)).\nUk f (x) := 1 \u2212\n\n(2.2.29)\n\nN (E)\n\nWe call Uk the generating operator of the transition law from Xk\u22121 to Xk , and we call X =\n(X0 , . . . , Xn ) the branching particle system on E with generating operators U1 , . . . , Un . It is\noften useful to write (2.2.28) in the suggestive form\n\u0002\n\u0003\n\u0002\n\u0003\nP \u03bd Thinf (Xn ) = 0 = P ThinU1 \u25e6***\u25e6Un f (\u03bd) = 0\n(\u03bd \u2208 N (E), f \u2208 B[0,1] (E)). (2.2.30)\n\n\f41\n\n2.2. CATALYTIC WRIGHT-FISHER DIFFUSIONS\n\nHere, if \u03bd is an N (E)-valued random variable and f \u2208 B[0,1] (E), then Thinf (\u03bd) denotes an\nN (E)-valued random variable such that conditioned on \u03bd, Thinf (\u03bd) is obtained from \u03bd by\nindependently throwing away particles from \u03bd, where a particle at x is kept with probability\nf (x). One has the elementary relations\nD\n\nThinf (Thing (\u03bd)) = Thinf g (\u03bd) and\n\nD\n\nThinf (Pois(\u03bc)) = Pois(f \u03bc),\n\n(2.2.31)\n\nD\n\nwhere = denotes equality in distribution.\nWe are now ready to describe weighted and Poissonized branching processes. Let X =\n(X0 , . . . , Xn ) be a Poisson-cluster branching process on E, with continuous weight functions\nq1 , . . . , qn , continuous cluster mechanisms Q1 , . . . , Qn , and log-Laplace operators U1 , . . . , Un\ngiven by (2.2.13) and satisfying (2.2.14). Let Zxk denote an M(E)-valued random variable\nwith law Qk (x, * ). Let h \u2208 C+ (E) be bounded, h 6= 0, and put E h := {x \u2208 E : h(x) > 0}. For\nf \u2208 B+ (E h ), define hf \u2208 B+ (E) by hf (x) := h(x)f (x) if x \u2208 E h and hf (x) := 0 otherwise.\nProposition 2.20 (Weighting of Poisson-cluster branching processes) Assume that\nthere exists a constant K < \u221e such that Uk h \u2264 Kh for all k = 1, . . . , n. Then there exists a\nPoisson-cluster branching process X h = (X0h , . . . , Xnh ) on E h with weight functions (q1h , . . . , qnh )\ngiven by qkh := qk /h, continuous cluster mechanisms Qh1 , . . . , Qhn given by\nQhk (x, * ) := L(hZxk )\n\n(x \u2208 E h ),\n\n(2.2.32)\n\nand log-Laplace operators U1h , . . . , Unh satisfying\nh Ukh f := Uk (hf )\n\n(f \u2208 B+ (E h )).\n\n(2.2.33)\n\nThe processes X and X h are related by\nL(X0h ) = L(hX0 )\n\nimplies\n\nL(Xkh ) = L(hXk )\n\n(0 \u2264 k \u2264 n).\n\n(2.2.34)\n\nProposition 2.21 (Poissonization of Poisson-cluster branching processes) Assume\nthat Uk h \u2264 h for all k = 1, . . . , n. Then there exists a branching particle system X h =\n(X0h , . . . , Xnh ) on E h with continuous offspring mechanisms Qh1 , . . . , Qhn given by\nQhk (x, * ) :=\n\n\u0003 \u0010\nqk (x) \u0011\nqk (x) \u0002\n\u03b40 ( * )\nP Pois(hZxk ) \u2208 * + 1 \u2212\nh(x)\nh(x)\n\n(x \u2208 E h ),\n\n(2.2.35)\n\nand generating operators U1h , . . . , Unh satisfying\nhUkh f := Uk (hf )\n\n(f \u2208 B[0,1] (E h )).\n\n(2.2.36)\n\nThe processes X and X h are related by\nL(X0h ) = L(Pois(hX0 ))\n\nimplies\n\nL(Xkh ) = L(Pois(hXk ))\n\n(0 \u2264 k \u2264 n).\n\n(2.2.37)\n\n\f42\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nHere, the right-hand side of (2.2.35) is always a probability measure, despite that it may\nhappen that qk (x)/h(x) > 1. The (straightforward) proofs of Propositions 2.20 and 2.21 can\nbe found in Section 2.8.1 below. If (2.2.34) holds then we say that X h is obtained from X\nby weighting with density h. If (2.2.37) holds then we say that X h is obtained from X by\nPoissonization with density h. Proposition 2.21 says that a Poisson-cluster branching process\nX contains, in a way, certain 'embedded' branching particle systems X h . Poissonization relations for superprocesses and embedded particle systems have enjoyed considerable attention,\nsee [FS04] and references therein.\nA function h \u2208 B+ (E) such that Uk h \u2264 h is called Uk -superharmonic. If the reverse\ninequality holds we say that h is Uk -subharmonic. If Uk h = h then h is called Uk -harmonic.\n\n2.2.7\n\nExtinction versus unbounded growth for embedded particle systems\n\nIn this section we explain how embedded particle systems can be P\nused to prove Theorem 2.17.\nThroughout this section (\u03b3k )k\u22650 are positive constants such that n \u03b3n = \u221e and \u03b3n \u2192 \u03b3 \u2217 for\nsome \u03b3 \u2217 \u2208 [0, \u221e), and X = (X\u2212n , . . . , X0 ) is the renormalization branching process on [0, 1]\ndefined in Section 2.2.4. We write\nU (n) := U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b30 .\n\n(2.2.38)\n\nIn view of formula (2.2.22), in order to prove Theorem 2.17, we need the following result.\nProposition 2.22 (Limits of iterated log-Laplace operators) Uniformly on [0, 1],\n(i)\n(ii)\n(iii)\n\nlim U (n) p = 1\n\n(p \u2208 H1,1 ),\n\nlim U\n\n(p \u2208 H0,0 ),\n\nn\u2192\u221e\n\n(n)\n\np=0\n\n(n)\n\np = p\u22170,1,\u03b3 \u2217\n\nn\u2192\u221e\n\nlim U\n\nn\u2192\u221e\n\n(2.2.39)\n\n(p \u2208 H0,1 ),\n\nwhere p\u22170,1,\u03b3 \u2217 : [0, 1] \u2192 [0, 1] is a function depending on \u03b3 \u2217 but not on p \u2208 H0,1 .\nh , . . . , Xh)\nIn our proof of Proposition 2.22, we will use embedded particle systems X h = (X\u2212n\n0\nobtained from X by Poissonization with certain h taken from the classes H1,1 , H0,0 , and H0,1 .\nBelow, P \u2212n,\u03b4x denotes the law of the process started at time \u2212n with one particle at x.\n\nLemma 2.23 (Embedded particle system with h1,1 ) The constant function h1,1 (x) := 1\nis U\u03b3 -harmonic for each \u03b3 > 0. The corresponding embedded particle system X h1,1 on [0, 1]\nsatisfies\n\u0002 h\n\u0003\n(2.2.40)\nP \u2212n,\u03b4x |X0 1,1 | \u2208 * =\u21d2 \u03b4\u221e\nn\u2192\u221e\n\nuniformly3\n\nfor all x \u2208 [0, 1].\n\nIn (2.2.40) and similar formulas below, \u21d2 denotes weak convergence of probability measures\non [0, \u221e]. Thus, (2.2.40) says that for processes started with one particle on the position x at\ntimes \u2212n, the number of particles at time zero converges to infinity as n \u2192 \u221e.\n3\nSince M1 [0, \u221e] is compact in the topology of weak convergence, there is a unique uniform structure\ncompatible with the topology, and therefore we can unambiguously talk about uniform convergence of M1 [0, \u221e] \u0303\n\u02c6 h\nvalued functions (in this case, x 7\u2192 P \u2212n,\u03b4x |X0 1,1 | \u2208 * ).\n\n\f43\n\n2.2. CATALYTIC WRIGHT-FISHER DIFFUSIONS\n\nLemma 2.24 (Embedded particle system with h0,0 ) The function h0,0 (x) := x(1 \u2212 x)\n(x \u2208 [0, 1]) is U\u03b3 -superharmonic for each \u03b3 > 0. The corresponding embedded particle system\nX h0,0 on (0, 1) is critical and satisfies\n\u0002 h\n\u0003\nP \u2212n,\u03b4x |X0 0,0 | \u2208 * =\u21d2 \u03b40\n(2.2.41)\nn\u2192\u221e\n\nlocally uniformly for all x \u2208 (0, 1).\n\nHere, we say that a branching particle system X is critical if each particle produces on average\none offspring (in each time step and independent of its position). Formula (2.2.41) says that\nthe embedded particle system X h0,0 gets extinct during the time interval {\u2212n, . . . , 0} with\nprobability tending to one as n \u2192 \u221e. We can summarize Lemmas 2.23 and 2.24 by saying that\nthe embedded particle system associated with h1,1 grows unboundedly while the embedded\nparticle system associated with h0,0 becomes extinct as n \u2192 \u221e.\nWe will also consider an embedded particle system X h0,1 for a certain h0,1 taken from H0,1 .\nIt turns out that this system either gets extinct or grows unboundedly, each with a positive\nprobability. In order to determine these probabilities, we need to consider embedded particle\n\u2217\nsystems for the time-homogeneous processes Y \u03b3 (\u03b3 \u2217 \u2208 [0, \u221e)) from (2.2.23) and (2.2.24). If\n\u2217\nh \u2208 H0,1 is U\u03b3 \u2217 -superharmonic for some \u03b3 \u2217 > 0, then Poissonizing the process Y \u03b3 with h\n\u2217\n\u2217\n\u2217\nyields a branching particle system on (0, 1] which we denote by Y \u03b3 ,h = (Y0\u03b3 ,h , Y1\u03b3 ,h , . . .).\nLikewise, if h \u2208 H0,1 is twice continuously differentiable and satisfies\n1\n2 x(1\n\n2\n\n\u2202\n\u2212 x) \u2202x\n2 h(x) \u2212 h(x)(1 \u2212 h(x)) \u2264 0,\n\n(2.2.42)\n\nthen Poissonizing the super-Wright-Fisher diffusion Y 0 with h yields a continuous-time branching particle system on (0, 1], which we denote by Y 0,h = (Yt0,h )t\u22650 . For example, for m \u2265 4,\nthe function h(x) := 1 \u2212 (1 \u2212 x)m satisfies (2.2.42).\nLemma 2.25 (Embedded particle system with h0,1 ) The function h0,1 (x) := 1\u2212 (1\u2212 x)7\nis U\u03b3 -superharmonic for each \u03b3 > 0. The corresponding embedded particle system X h0,1 on\n(0, 1] satisfies\n\u0002 h\n\u0003\nP \u2212n,\u03b4x |X0 0,1 | \u2208 * =\u21d2 \u03c1\u03b3 \u2217 (x)\u03b4\u221e + (1 \u2212 \u03c1\u03b3 \u2217 (x))\u03b40 ,\n(2.2.43)\nn\u2192\u221e\n\nlocally uniformly for all x \u2208 (0, 1], where\n( \u03b4\n\u03b3 \u2217 ,h\nP x [Yk 0,1 6= 0 \u2200k \u2265 0]\n\u03c1\u03b3 \u2217 (x) :=\n0,h\nP \u03b4x [Yt 0,1 6= 0 \u2200t \u2265 0]\n\n(0 < \u03b3 \u2217 < \u221e),\n(\u03b3 \u2217 = 0).\n\n(2.2.44)\n\nWe now explain how Lemmas 2.23\u20132.25 imply Proposition 2.22. In doing so, it will be more\nconvenient to work with weighted branching processes than with Poissonized branching processes. A little argument (which can be found in Lemma 2.79 below) shows that Lemmas 2.23\u2013\n2.25 are equivalent to the next proposition.\nProposition 2.26 (Extinction versus unbounded growth) Let h1,1 , h0,0 , and h0,1 be as\nin Lemmas 2.23\u20132.25. For \u03b3 \u2217 \u2208 [0, \u221e), put p\u22171,1,\u03b3 \u2217 (x) := 1, p\u22170,0,\u03b3 \u2217 (x) := 0 (x \u2208 [0, 1]), and\np\u22170,1,\u03b3 \u2217 (0) := 0\n\nand\n\np\u22170,1,\u03b3 \u2217 (x) := h0,1 (x)\u03c1\u03b3 \u2217 (x)\n\n(x \u2208 (0, 1]),\n\n(2.2.45)\n\n\f44\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nwith \u03c1\u03b3 \u2217 as in (2.2.44). Then, for (l, r) = (1, 1), (0, 0), and (0, 1),\n\u0002\n\u0003\n\u2212p\u2217 (x) \u0001\n\u2212p\u2217 (x)\n\u03b4\u221e ,\nP \u2212n,\u03b4x hX0 , hl,r i \u2208 * =\u21d2 e l,r,\u03b3 \u2217 \u03b40 + 1 \u2212 e l,r,\u03b3 \u2217\n\n(2.2.46)\n\nn\u2192\u221e\n\nuniformly for all x \u2208 [0, 1].\n\nFormula (2.2.46) says that the weighted branching process X hl,r exhibits a form of extinction\nversus unbounded growth. More precisely, for large n the total mass of hl,r X0 is close to 0 or\n\u221e with high probability.\nProof of Proposition 2.22 By (2.2.15),\n\u0002\n\u0003\nU (n) p(x) = \u2212 log E \u2212n,\u03b4x e \u2212hX0 , pi\n\n(p \u2208 B+ [0, 1], x \u2208 [0, 1]).\n\n(2.2.47)\n\nWe first prove formula (2.2.39) (ii). For (l, r) = (0, 0), formula (2.2.46) says that\nP \u2212n,\u03b4x [hX0 , h0,0 i \u2208 * ] =\u21d2 \u03b40\n\n(2.2.48)\n\nn\u2192\u221e\n\nuniformly for all x \u2208 [0, 1]. If p \u2208 H0,0 , then we can find r > 0 such that p \u2264 rh0,0 . Therefore,\n(2.2.48) implies that for any p \u2208 H0,0 ,\nP \u2212n,\u03b4x [hX0 , pi \u2208 * ] =\u21d2 \u03b40 .\n\n(2.2.49)\n\nn\u2192\u221e\n\nBy (2.2.47) it follows that\n\u0002\n\u0003\nU (n) p(x) = \u2212 log E \u2212n,\u03b4x e \u2212hX0 , pi \u2212\u2192 0,\n\n(2.2.50)\n\nn\u2192\u221e\n\nwhere the limits in (2.2.49) and (2.2.50) are uniform in x \u2208 [0, 1]. This proves formula\n(2.2.39) (ii). To prove formula (2.2.39) (iii), note that for any p \u2208 H0,1 we can choose 0 <\nr\u2212 < r+ such that r\u2212 h0,1 \u2264 p + h0,0 \u2264 r+ h0,1 . Therefore, (2.2.46) implies that\nP \u2212n,\u03b4x [hX0 , pi + hX0 , h0,0 i \u2208 * ] =\u21d2 e\nn\u2192\u221e\n\n\u2212p\u22170,1,\u03b3 \u2217 (x)\n\n\u03b40 + 1 \u2212 e\n\nUsing moreover (2.2.48), we see that\nP \u2212n,\u03b4x [hX0 , pi \u2208 * ] =\u21d2 e\nn\u2192\u221e\n\nBy (2.2.47), it follows that\n\n\u2212p\u22170,1,\u03b3 \u2217 (x)\n\n\u03b40 + 1 \u2212 e\n\n\u2212p\u22170,1,\u03b3 \u2217 (x) \u0001\n\n\u2212p\u22170,1,\u03b3 \u2217 (x) \u0001\n\n\u03b4\u221e .\n\n\u0002\n\u0003\nU (n) p(x) = \u2212 log E \u2212n,\u03b4x e \u2212hX0 , pi \u2212\u2192 p\u22170,1,\u03b3 \u2217 (x)\nn\u2192\u221e\n\n\u03b4\u221e .\n\n(2.2.51)\n\n(2.2.52)\n\n(2.2.53)\n\nwhere all limits are uniform in x \u2208 [0, 1]. This proves (2.2.39) (iii). The proof of (2.2.39) (i)\nis similar but easier.\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n2.2.8\n\n45\n\nOutline\n\nIn Section 2.3, we verify that Wcat is a renormalization class, we prove Proposition 2.18,\nwhich connects the renormalization transformations Fc to the log-Laplace operators U\u03b3 , and\nwe collect a number of technical properties of the operators U\u03b3 that will be needed later on.\nIn Section 2.4 we prove Theorem 2.19 about the convergence of the renormalization branching\nprocess to a time-homogeneous limit.\nSections 2.5\u20132.7 are devoted to the super-Wright-Fisher diffusio Y 0 , i.e., the limiting process from Theorem 2.19 (b). These sections have been written in such a way that they can\nbe read independently of the rest of this chapter. In fact, we generalize a bit by allowing\nfor an arbitrary positive constant to appear in front of the u(1 \u2212 u) term in (2.2.26). This\ngeneratization reveals that the case where this constant is one is in fact a critical case, marking\nthe boundary between two types of long-time behavior. Section 2.5 gives an introduction to\nthe super-Wright-Fisher diffusion, while Sections 2.6\u20132.7 contain proofs. The central tool in\nthese proofs is a weighted superprocess, rather than embedded particle systems which are our\nmain tool for studying the renormalization branching process X\nIn Section 2.8, we take up the study of X and its embedded particle systems. In particular,\nwe prove the statements from Section 2.2.7 about extinction versus unbounded growth of\nembedded particle systems, with the exception of Lemma 2.24, which is proved in Section 2.9.\nIn Section 2.10, finally, we combine all results derived by that point to prove our main theorem.\n\nAcknowledgements Work sponsored by the DFG. The authors thank Janos Engl\u00e4nder\nfor answering our questions about his work and Jan Seidler for answering questions about\nthe strong Feller property. Achim Klenke, Dmitry Turaev, and Anita Winter are thanked for\nuseful discussions and comments. We than an anonymous referee for comments which lead\nto an improved exposition. We thank Anton Wakolbinger and Martin M\u00f6hle for pointing out\nreference [Ewe04] and the fact that the distribution in (2.3.17) is a \u03b2-distribution.\n\n2.3\n\nThe renormalization class Wcat\n\nIn this section we prove Theorem 2.17 (a) and Proposition 2.18, as well as Lemmas 2.3\u20132.8\nfrom Section 2.1.4, and Lemma 2.15. The section is organized according to the techniques\nused. Section 2.3.1 collects some facts that hold for general renormalization classes on compact\nsets. In Section 2.3.2 we use the SDE (2.2.4) to couple catalytic Wright-Fisher diffusions. In\nSection 2.3.3 we apply the moment duality for the Wright-Fisher diffusion to the catalyst and\nto the reactant conditioned on the catalyst. In Section 2.3.4 we prove that monotone concave\ncatalyzing functions form a preserved class under renormalization.\n\n2.3.1\n\nRenormalization classes on compact sets\n\nIn this section, we prove the lemmas stated in Section 2.1.4, as well as Lemma 2.15. Recall\nthat D \u2282 Rd is open, bounded, and convex, and that W is a prerenormalization class on D,\nequipped with the topology of uniform convergence.\nProof of Lemma 2.3 To see that (x, c, w) 7\u2192 \u03bdxc,w is continuous, let (xn , cn , wn ) be a sequence\nconverging in D \u00d7 (0, \u221e) \u00d7 W to a limit (x, c, w). By the compactness of D, the sequence\n\n\f46\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\n(\u03bdxcnn,wn )n\u22650 is tight, and each limit point \u03bd \u2217 satisfies\nh\u03bd \u2217 , Ac,w\nx fi = 0\n\n(f \u2208 C (2) (D)).\n\n(2.3.1)\n\nTherefore, by [EK86, Theorem 4.9.17], \u03bd \u2217 is an invariant law for the martingale problem\nc,w\n\u2217\nassociated with Ac,w\nand\nx . Since we are assuming uniqueness of the invariant law, \u03bd = \u03bdx\ncn ,wn\nc,w\ntherefore \u03bdxn\n\u21d2 \u03bdx . The continuity of Fc w(x) is a simple consequence of the continuity\nof \u03bdxc,w .\nProof of Lemma 2.4 Formula (2.1.31) (i) follows from the fact that rescaling the time in\nsolutions (yt )t\u22650 to the martingale problem for Ac,w\nby a factor \u03bb has no influence on the\nx\ninvariant law. Formula (2.1.31) (ii) is a direct consequence of formula (2.1.31) (i).\nProof of Lemma 2.5 This follows by inserting the functions f (x) = xi and f (x) = xi xj into\nthe equilibrium equation (2.3.1).\nProof of Lemma 2.6 If x \u2208 \u2202w D, then yt := x (t \u2265 0) is a stationary solution to the\nc,w\nmartingale problem for Ac,w\n= \u03b4x and Fc w(x) = w(x) = 0. On the other\nx , and therefore \u03bdx\nhand, if x 6\u2208 \u2202w D, then Ryt := x (t \u2265 0) is not a stationary solutionP\nto the martingale problem\nand therefore D \u03bdxc,w (dy)|y \u2212 x|2 R> 0. Let tr(w(y)) := R i wii (y) denote the trace\nfor Ac,w\nx\nof w(y). By (2.1.32) (ii), 1c tr(Fc w)(x) = 1c D \u03bdxc,w (dy)tr(w(y)) = D \u03bdxc,w (dy)|y \u2212 x|2 > 0 and\ntherefore Fc w(x) 6= 0.\nFrom now on assume that W is a renormalization class. Note that\nK w,(n) = \u03bd cn\u22121 ,F\n\n(n\u22121) w\n\n* * * \u03bd c0 ,w\n\n(n \u2265 1),\n\nwhere we denote the composition of two probability kernels K, L on D by\nZ\n(KL)x (dz) :=\nKx (dy)Ly (dz).\n\n(2.3.2)\n\n(2.3.3)\n\nD\n\nProof of Lemma 2.7 This is a direct consequence of Lemmas 2.3 and 2.5. In particular, the\nrelations (2.1.36) follow by iterating the relations (2.1.32).\nProof of Lemma 2.8 Recall that tr(w(y)) denotes the trace of w(y). Formulas (2.1.35) and\n(2.1.36) (ii) show that\nZ\nZ\nKxw,(n)(dy) |y \u2212 x|2 = sn Kxw,(n)(dy) tr(w(y)).\n(2.3.4)\nD\n\nD\n\nSince D is compact, the left-hand side of this equation is bounded uniformly in x \u2208 D and\nn \u2265 1, and therefore, since we are assuming sn \u2192 \u221e,\nZ\nlim sup\nKxw,(n) (dy)tr(w(y)) = 0.\n(2.3.5)\nn\u2192\u221e x\u2208D\n\nD\n\nSince w is symmetric and nonnegative definite, tr(w(y)) is nonnegative, and zero if and only if\ny \u2208 \u2202w D. If f \u2208 C(D) satisfies f = 0 on \u2202w D, then, for every \u03b5 > 0, the sets Cm := {x \u2208 D :\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n47\n\n|f (x)| \u2265 \u03b5 + m tr(w(x))} are compact with Cm \u2193 \u2205 as m \u2191 \u221e, so there exists an m (depending\non \u03b5) such that |f | < \u03b5 + m tr(w). Therefore,\nZ\nZ\nw,(n)\nlim sup sup\nKx\n(dy)f (y) \u2264 lim sup sup\nKxw,(n)(dy)|f (y)|\nn\u2192\u221e x\u2208D\nn\u2192\u221e x\u2208D D\nD\nZ\n(2.3.6)\nw,(n)\n\u2264 \u03b5 + m lim sup sup\nKx\n(dy)tr(w(y)) = \u03b5.\nn\u2192\u221e\n\nx\u2208D\n\nD\n\nSince \u03b5 > 0 is arbitrary, (2.1.37) follows.\nProof of Lemma 2.15 By (2.1.40), (2.1.42), and (2.1.43), w\u03b3\u2217 \u2217 = limn\u2192\u221e (F \u03b3 \u2217 )n w for each\nw \u2208 W. By Lemma 2.3 (b), F \u03b3 \u2217 : W \u2192 W is continuous, so w\u03b3\u2217 \u2217 is the unique fixed point of\nF \u03b3 \u2217 . This proves part (a).\nNow let 0 6= w \u2208 W and assume that \u0174 = {\u03bbw : \u03bb > 0} is a fixed shape. Then\n\u0174 \u220b sn F (n) w \u2212\u2192 w\u03b3\u2217 \u2217 whenever sn \u2192 \u221e and sn+1 /sn \u2192 1 + \u03b3 \u2217 for some 0 < \u03b3 \u2217 < \u221e, which\nn\u2192\u221e\n\nshows that \u0174 = {\u03bbw\u03b3\u2217 \u2217 : \u03bb > 0}. Thus, W can contain at most one fixed shape, and if it does,\nthen the w\u03b3\u2217 \u2217 for different values of \u03b3 \u2217 must be constant multiples of each other. This proves\npart (c) and the uniqueness statement in part (b).\nTo complete the proof of part (b), note that if w\u2217 = w\u03b3\u2217 \u2217 does not depend on \u03b3 \u2217 , then\nw\u2217 \u2208 W solves (2.1.46) (i) for all 0 < \u03b3 \u2217 < \u221e, hence Fc w\u2217 = (1 + 1c )\u22121 w\u2217 for all c > 0, and\ntherefore, by scaling (Lemma 2.4), Fc (\u03bbw\u2217 ) = \u03bbFc/\u03bb (w\u2217 ) = \u03bb(1 + \u03bbc )\u22121 w\u2217 = ( \u03bb1 + 1c )\u22121 w\u2217 .\n\n2.3.2\n\nCoupling of catalytic Wright-Fisher diffusions\n\nIn this section we verify condition (i) of Definition 2.1 for the class Wcat , and we prepare for\nthe verification of conditions (ii)\u2013(iv) in Section 2.3.3. In fact, we will show that the larger\nclass W cat := {w\u03b1,p : \u03b1 > 0, p \u2208 C+ [0, 1]} is also a renormalization class, and the equivalents\nof Theorem 2.17 (a) and Proposition 2.18 remain true for this larger class. (We do not know,\nhowever, if the convergence statements in Theorem 2.17 (b) also hold in this larger class; see\nthe discussion in Section 2.2.2.)\nFor each c \u2265 0, w \u2208 W cat and x \u2208 [0, 1]2 , the operator Ac,w\nis a densely defined linear\nx\noperator on C([0, 1]2 ) that maps the identity function into zero and, as one easily verifies,\nsatisfies the positive maximum principle. Since [0, 1]2 is compact, the existence of a solution\n2\nto the martingale problem for Ac,w\nx , for each [0, 1] -valued initial condition, now follows from\ngeneral theory (see [RW87], Theorem 5.23.5, or [EK86, Theorem 4.5.4 and Remark 4.5.5]).\nWe are therefore left with the task of verifying uniqueness of solutions to the martingale\nproblem for Ac,w\nx . By [EK86, Problem 4.19, Corollary 5.3.4, and Theorem 5.3.6], it suffices to\nshow that solutions to (2.2.4) are pathwise unique.\nLemma 2.27 (Monotone coupling of Wright-Fisher diffusions) Assume that 0 \u2264 x \u2264\nx\u0303 \u2264 1, c \u2265 0 and that (Pt )t\u22650 is a progressively measurable, nonnegative process such that\nsupt\u22650,\u03c9\u2208\u03a9 Pt (\u03c9) < \u221e. Let y, \u1ef9 be [0, 1]-valued solutions to the SDE's\np\ndyt = c (x \u2212 yt )dt + p2Pt yt (1 \u2212 yt )dBt ,\n(2.3.7)\nd\u1ef9t = c (x\u0303 \u2212 \u1ef9t )dt + 2Pt \u1ef9t (1 \u2212 \u1ef9t )dBt ,\n\n\f48\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nwhere in both equations B is the same Brownian motion. If y0 \u2264 \u1ef90 a.s., then\nyt \u2264 \u1ef9t\n\n\u2200t \u2265 0\n\na.s.\n\n(2.3.8)\n\nProof\nR \u221e and Watanabe [YW71]. Since\nR dx This is an easy adaptation of a technique due to Yamada\n=\n\u221e,\nit\nis\npossible\nto\nchoose\n\u03c1\n\u2208\nC[0,\n\u221e)\nsuch\nthat\nn\n0 \u03c1n (x)dx = 1 and\n0+ x\n0 \u2264 \u03c1n (x) \u2264\n\n1\n1\n(x)\nnx (0,1]\n\nDefine \u03c6n \u2208 C (2) (R) by\n\u03c6n (x) :=\n\nZ\n\n0\n\nx\u22280\n\ndy\n\nZ\n\n(x \u2265 0).\n\n(2.3.9)\n\ny\n\ndz \u03c1n (z).\n\n(2.3.10)\n\n0\n\nOne easily verifies that \u03c6n (x), x\u03c6\u2032n (x), and x\u03c6\u2032\u2032n (x) are nonnegative and converge, as n \u2192 \u221e,\nto x \u2228 0, x \u2228 0, and 0, respectively. By It\u00f4's formula:\nE[\u03c6n (yt \u2212 \u1ef9t )] = E[\u03c6n (y0 \u2212 \u1ef90 )]\nZ t\nZ t\n\u2032\nE[(ys \u2212 \u1ef9s )\u03c6\u2032n (ys \u2212 \u1ef9s )]ds\nE[\u03c6n (ys \u2212 \u1ef9s )]ds \u2212 c\n+c (x \u2212 x\u0303)\n0\n0\nZ t h \u0010p\n\u00112\ni\np\nE Ps\n+\nys (1 \u2212 ys ) \u2212 \u1ef9s (1 \u2212 \u1ef9s ) \u03c6\u2032\u2032n (ys \u2212 \u1ef9s ) ds.\n\n(i)\n(ii)\n(iii)\n\n0\n\n(2.3.11)\nHere the terms in (ii) are nonpositive, and hence, letting n \u2192 \u221e and using the elementary\nestimate\np\np\n1\n(y, \u1ef9 \u2208 [0, 1]),\n(2.3.12)\n| y(1 \u2212 y) \u2212 \u1ef9(1 \u2212 \u1ef9)| \u2264 |y \u2212 \u1ef9| 2\nthe properties of \u03c6n , and the fact that the process P is uniformly bounded, we find that\nE[0 \u2228 (yt \u2212 \u1ef9t )] \u2264 E[0 \u2228 (y0 \u2212 \u1ef90 )] = 0,\n\n(2.3.13)\n\nby our assumption that y0 \u2264 \u1ef90 . This shows that yt \u2264 \u1ef9t a.s. for each fixed t \u2265 0, and by\nthe continuity of sample paths the statement holds for all t \u2265 0 almost surely.\nCorollary 2.28 (Pathwise uniqueness) For all c \u2265 0, \u03b1 > 0, p \u2208 C+ [0, 1] and x \u2208 [0, 1],\nsolutions to the SDE (2.2.4) are pathwise unique.\nProof Let (y1 , y2 ) and (\u1ef91 , \u1ef92 ) be solutions to (2.2.4) relative to the same pair (B 1 , B 2 ) of\nBrownian motions, with (y01 , y02 ) = (\u1ef901 , \u1ef902 ). Applying Lemma 2.27, with inequality in both\ndirections, we see that y1 = \u1ef91 a.s. Applying Lemma 2.27 two more times, this time using\nthat y1 = \u1ef91 a.s., we see that also y2 = \u1ef92 a.s.\nCorollary 2.29 (Exponential coupling) Assume that x \u2208 [0, 1], c \u2265 0, and \u03b1 > 0. Let\ny, \u1ef9 be solutions to the SDE\np\ndyt = c (x \u2212 yt )dt + 2\u03b1yt (1 \u2212 yt )dBt ,\n(2.3.14)\nrelative to the same Brownian motion B. Then\n\u0002\n\u0003\n\u0002\n\u0003\nE |\u1ef9t \u2212 yt | = e\u2212ct E |\u1ef90 \u2212 y0 | .\n\n(2.3.15)\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n49\n\nProof If y0 = y and \u1ef90 = \u1ef9 are deterministic and y \u2264 \u1ef9, then by Lemma 2.27 and a simple\nmoment calculation\n\u0002\n\u0003\nE |\u1ef9t \u2212 yt | = E[\u1ef9t \u2212 yt ] = e\u2212ct |\u1ef9 \u2212 y|.\n(2.3.16)\nThe same argument applies when y \u2265 \u1ef9. The general case where y0 and \u1ef90 are random follows\nby conditioning on (y0 , \u1ef90 ).\n\nCorollary 2.30 (Ergodicity) The Markov process defined by the SDE (2.2.17) has a unique\ninvariant law \u0393\u03b3x and is ergodic, i.e, solutions to (2.2.17) started in an arbitrary initial law\nL(y0 ) satisfy L(yt ) =\u21d2 \u0393\u03b3x .\nt\u2192\u221e\n\nProof Since our process is a Feller diffusion on a compactum, the existence of an invariant\nlaw follows from a simple time averaging argument. Now start one solution \u1ef9 of (2.2.17) in\nthis invariant law and let y be any other solution, relative to the same Brownian motion.\nCorollary 2.29 then gives ergodicity and, in particular, uniqueness of the invariant law.\nRemark 2.31 (Density of invariant law) It is well-known (see, for example [Ewe04, formula (5.70)]) that \u0393\u03b3x is a \u03b2(\u03b11 , \u03b12 )-distribution, where \u03b11 := x/\u03b3 and \u03b12 := (1 \u2212 x)/\u03b3, i.e.,\n\u0393\u03b3x = \u03b4x (x \u2208 {0, 1}) and\n\u0393\u03b3x (dy) =\n\n\u0393(\u03b11 + \u03b12 ) \u03b11 \u22121\ny\n(1 \u2212 y)\u03b12 \u22121 dy\n\u0393(\u03b11 )\u0393(\u03b12 )\n\n(x \u2208 (0, 1)).\n\n(2.3.17)\n\u2666\n\nWe conclude this section with a lemma that prepares for the verification of condition (iv) in\nDefinition 2.1 for the class Wcat .\nLemma 2.32 (Monotone coupling of stationary Wright-Fisher diffusions) Assume\nthat c > 0, \u03b1 > 0 and 0 \u2264 x \u2264 x\u0303 \u2264 1. Then the pair of equations\np\ndyt = c (x \u2212 yt )dt + p2\u03b1yt (1 \u2212 yt )dBt ,\n(2.3.18)\nd\u1ef9t = c (x\u0303 \u2212 \u1ef9t )dt + 2\u03b1\u1ef9t (1 \u2212 \u1ef9t )dBt\nhas a unique stationary solution (yt , \u1ef9t )t\u2208R . This stationary solution satisfies\nyt \u2264 \u1ef9t\n\n\u2200t \u2208 R\n\na.s.\n\n(2.3.19)\n\nProof Let (yt , \u1ef9t )t\u22650 be a solution of (2.3.18) and let (yt\u2032 , \u1ef9t\u2032 )t\u22650 be another one, relative to the\nsame Brownian motion B. Then, by Lemma 2.29, E[|yt \u2212 yt\u2032 |] \u2192 0 and also E[|\u1ef9t \u2212 \u1ef9t\u2032 |] \u2192 0\nas t \u2192 \u221e. Hence we may argue as in the proof of Corollary 2.30 that (2.3.18) has a unique\ninvariant law and is ergodic. Now start a solution of (2.3.18) in an initial condition such that\ny0 \u2264 \u1ef90 . By ergodicity, the law of this solution converges as t \u2192 \u221e to the invariant law\nof (2.3.18) and using Lemma 2.27 we see that this invariant law is concentrated on {(y, \u1ef9) \u2208\n[0, 1]2 : y \u2264 \u1ef9}. Now consider, on the whole real time axis, the stationary solution to (2.3.18)\nwith this invariant law. Applying Lemma 2.27 once more, we see that (2.3.19) holds.\n\n\f50\n\n2.3.3\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nDuality for catalytic Wright-Fisher diffusions\n\nIn this section we prove Theorem 2.17 (a) and Proposition 2.18. Moreover, we will show that\ntheir statements remain true if the renormalization class Wcat is replaced by the larger class\nW cat := {w\u03b1,p : \u03b1 > 0, p \u2208 C+ [0, 1]}. We begin by recalling the usual moment duality for\nWright-Fisher diffusions.\nFor \u03b3 > 0 and x \u2208 [0, 1], let y be a solution to the SDE\np\ndy(t) = \u03b31 (x \u2212 y(t))dt + 2y(t)(1 \u2212 y(t))dB(t),\n(2.3.20)\n\ni.e., y is a Wright-Fisher diffusion with a linear drift towards x. It is well-known that y has\na moment dual. To be precise, let (\u03c6, \u03c8) be a Markov process in N2 = {0, 1, . . .}2 that jumps\nas:\n(\u03c6t , \u03c8t ) \u2192 (\u03c6t \u2212 1, \u03c8t )\nwith rate \u03c6t (\u03c6t \u2212 1)\n(2.3.21)\n(\u03c6t , \u03c8t ) \u2192 (\u03c6t \u2212 1, \u03c8t + 1)\nwith rate \u03b31 \u03c6t .\nThen one has the following duality relation (see for example Lemma 2.3 in [Shi80a] or Proposition 1.5 in [GKW01])\n\u0002\n\u0003\n\u0002\n\u0003\nE y ytn xm = E (n,m) y \u03c6t x\u03c8t\n(y \u2208 [0, 1], (n, m) \u2208 N2 ),\n(2.3.22)\n\nwhere 00 := 1. The duality in (2.3.22) has the following heuristic explanation. Consider a\npopulation containing a fixed, large number of organisms, that come in two genetic types,\nsay I and II. Each pair of organisms in the population is resampled with rate 2. This means\nthat one organism of the pair (chosen at random) dies, while the other organism produces one\nchild of its own genetic type. Moreover, each organism is replaced with rate \u03b31 by an organism\nchosen from an infinite reservoir where the frequency of type I has the fixed value x. In the\nlimit that the number of organisms in the population is large, the relative frequency yt of type\nI organisms follows the SDE (2.3.20). Now E[ytn ] is the probability that n organisms sampled\nfrom the population at time t are all of type I. In order to find this probability, we follow\nthe ancestors of these organisms back in time. Viewed backwards in time, these ancestors\nlive for a while in the population, until, with rate \u03b31 , they jump to the infinite reservoir.\nMoreover, due to resampling, each pair of ancestors coalesces with rate 2 to one common\nancestor. Denoting the number of ancestors that lived at time t \u2212 s in the population and in\nthe reservoir by \u03c6s and \u03c8s , respectively, we see that the probability that all ancestors are of\ntype I is E y [ytn ] = E (n,0) [y \u03c6t x\u03c8t ]. This gives a heuristic explanation of (2.3.22).\nSince eventually all ancestors of the process (\u03c6, \u03c8) end up in the reservoir, we have\n(\u03c6t , \u03c8t ) \u2192 (0, \u03c8\u221e ) as t \u2192 \u221e a.s. for some N-valued random variable \u03c8\u221e . Taking the limit\nt \u2192 \u221e in (2.3.22), we see that the moments of the invariant law \u0393\u03b3x from Corollary 2.30 are\ngiven by:\nZ\n\u0393\u03b3x (dy)y n = E (n,0) [x\u03c8\u221e ]\n\n(n \u2265 0).\n\n(2.3.23)\n\nIt is not hard to obtain an inductive formula for the moments of \u0393\u03b3x , which can then be solved\nto yield the formula\nZ\nn\u22121\nY x + k\u03b3\n(n \u2265 1).\n(2.3.24)\n\u0393\u03b3x (dy)y n =\n1 + k\u03b3\nk=0\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n51\n\nIn particular, it follows that\nZ\n\n\u0393\u03b3x (dy)y(1 \u2212 y) =\n\n1\nx(1 \u2212 x).\n1+\u03b3\n\n(2.3.25)\n\nThis is the important fixed shape property of the Wright-Fisher diffusion (see formula (2.1.58)).\nWe now consider catalytic Wright-Fisher diffusions (y1 , y2 ) as in (2.2.4) with p \u2208 C+ [0, 1]\nand apply duality to the catalyst y2 conditioned on the reactant y1 . Let (yt1 , yt2 )t\u2208R be a\nstationary solution to the SDE (2.2.4) with c = 1/\u03b3. Let (\u03c6\u0303, \u03c8\u0303) be a N2 -valued process,\ndefined on the same probability space as (y1 , y2 ), such that conditioned on the past path\n1 )\n(y\u2212t\nt\u22640 , the process (\u03c6\u0303, \u03c8\u0303) is a (time-inhomogeneous) Markov process that jumps as:\n(\u03c6\u0303t , \u03c8\u0303t ) \u2192 (\u03c6\u0303t \u2212 1, \u03c8\u0303t )\n(\u03c6\u0303t , \u03c8\u0303t ) \u2192 (\u03c6\u0303t \u2212 1, \u03c8\u0303t + 1)\n\n1 )\u03c6\u0303 (\u03c6\u0303 \u2212 1),\nwith rate p(y\u2212t\nt t\n1\nwith rate \u03b3 \u03c6\u0303t .\n\n(2.3.26)\n\nThen, in analogy with (2.3.22),\n1\n(n,m)\n2 \u03c6\u0303t \u03c8\u0303t\n1\n[(y\u2212t\n) x2 |(y\u2212t\nE[(y02 )n xm\n)t\u22640 ]\n2 |(y\u2212t )t\u22640 ] = E\n\n((n, m) \u2208 N2 , t \u2265 0).\n\n(2.3.27)\n\nWe may interpret (2.3.26) by saying that pairs of ancestors in a finite population coalesce with\n1 ) and ancestors jump to an infinite reservoir with constant rate\ntime-dependent rate 2p(y\u2212t\n1\n\u03b3 . Again, eventualy all ancestors end up in the reservoir, and therefore (\u03c6\u0303t , \u03c8\u0303t ) \u2192 (0, \u03c8\u0303\u221e ) as\n\nt \u2192 \u221e a.s. for some N-valued random variable \u03c8\u0303\u221e . Taking the limit t \u2192 \u221e in (2.3.27) we\nfind that\n1\n(n,m) \u03c8\u0303\u221e\n1\nE[(y02 )n xm\n[x2 |(y\u2212t\n)t\u22640 ]\n2 |(y\u2212t )t\u22640 ] = E\n\n((n, m) \u2208 N2 , t \u2265 0).\n\n(2.3.28)\n\nLemma 2.33 (Uniqueness of invariant law) For each c > 0, w \u2208 W cat , and x \u2208 [0, 1]2 ,\nthere exists a unique invariant law \u03bdxc,w for the martingale problem for Ac,w\nx .\nProof Our process being a Feller diffusion on a compactum, the existence of an invariant\nlaw follows from time averaging. We need to show uniqueness. If (y1 , y2 ) = yt1 , yt2 )t\u2208R is a\n1/c\nstationary solution, then y1 is an autonomous process, and L(y01 ) = \u0393x , the unique invariant\nlaw from Corollary 2.30. Therefore, L((yt1 )t\u2208R ) is determined uniquely by the requirement\nthat (y1 , y2 ) be stationary. By (2.3.28), the conditional distribution of y02 given (yt1 )t\u22640 is\ndetermined uniquely, and therefore the joint distribution of y02 and (yt1 )t\u22640 is determined\nuniquely. In particular, L(y01 , y02 ) = \u03bdxc,w is determined uniquely.\nRemark 2.34 (Reversibility) It seems that the invariant law \u03bdxc,w from Lemma 2.33 is\nreversible. In many cases (densities of) reversible invariant measures can be obtained in\nclosed form by solving the equations of detailed balance. This is the case, for example, for\nthe one-dimensional Wright-Fisher diffusion. We have not attempted this for the catalytic\nWright-Fisher diffusion.\n\u2666\n\n\f52\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nThe next proposition implies Proposition 2.18 and prepares for the proof of Theorem 2.17 (a).\nProposition 2.35 (Extended renormalization class) The set W cat is a renormalization\nclass on [0, 1]2 , and\nF \u03b3 w1, p = w1, U\u03b3 p\n(p \u2208 C+ [0, 1], \u03b3 > 0).\n(2.3.29)\nProof To see that W cat is a renormalization class we need to check conditions (i)\u2013(iv) from\nDefinition 2.1. By Lemma 2.28, the martingale problem for Ac,w\nis well-posed for all c \u2265 0,\nx\nw \u2208 Wcat and x \u2208 [0, 1]2 . By Lemma 2.33, the corresponding Feller process on [0, 1]2 has\na unique invariant law \u03bdxc,w . This shows that conditions (i) and (ii) from Definition 2.1 are\nsatisfied. Note that by the compactness of [0, 1]2 , any continuous function on [0, 1]2 is bounded,\nso condition (iii) is automatically satisfied. Hence W is a prerenormalization class. As a\nconsequence, for any p \u2208 C+ [0, 1], F \u03b3 w1,p is well-defined by (2.1.25) and (2.1.39). We will now\nfirst prove (2.3.29) and then show that W cat is a renormalization class.\nFix \u03b3 > 0, p \u2208 C+ [0, 1], and x \u2208 [0, 1]2 . Let (yt1 , yt2 )t\u2208R be a stationary solution to the\nSDE (2.2.4) with \u03b1 = 1 and c = 1/\u03b3. Then\n1,p\n1,p 1\nF \u03b3 wij\n(x) = (1 + \u03b3)E[wij\n(y0 , y02 )]\n\n(i, j = 1, 2).\n\n(2.3.30)\n\n1,p\n1,p\nSince wij\n= 0 if i 6= j, it is clear that F \u03b3 wij\n(x) = 0 if i 6= j. Since L(y01 ) = \u0393\u03b3x it follows\n1,p\nfrom (2.3.25) that F \u03b3 w11\n(x) = x1 (1 \u2212 x1 ). We are left with the task of showing that\n1,p\nF \u03b3 w22\n(x) = U\u03b3 p(x1 )x2 (1 \u2212 x2 ).\n\n(2.3.31)\n\nHere, by (2.1.32) (ii),\n1,p\nF \u03b3 w22\n(x) = (1 + \u03b3)E[p(y01 )y02 (1 \u2212 y02 )]\n\n= ( \u03b31 + 1)E[(y02 \u2212 x2 )2 ].\n\n(2.3.32)\n\nBy (2.3.28), using the fact that E[y02 ] = x2 (which follows from (2.3.27) or more elementary\nfrom (2.1.36) (i)), we find that\n2\n(2,0)\n\u221e\nE[(y02 \u2212 x2 )2 ] = E[(y02 )2 ] \u2212 (x2 )2 = E (2,0) [x\u03c8\u0303\n[\u03c8\u0303\u221e = 1]x2 (1 \u2212 x2 )\n2 ] \u2212 (x2 ) = P\n\n(t \u2265 0).\n(2.3.33)\nNote that P (2,0) [\u03c8\u0303\u221e = 1] is the probability that the two ancestors coalesce before one of them\nleaves the population. The probability of noncoalescence is given by\n1\n\nR 2 \u03c4\u03b3\n\u0002\n\u0003\n1\nP (2,0) [\u03c8\u0303\u221e = 2] = E e \u2212 0 2p(y\u2212t )dt ,\n\n(2.3.34)\n\nwhere \u03c4\u03b3 is an exponentially distributed random variable with mean \u03b3. Combining this with\n(2.3.32) and (2.3.33) we find that\nR\u03c4\n1\n\u0002\n)dt \u0003\n\u2212 0 \u03b3 p(y\u2212t/2\n1,p\n1\nx2 (1 \u2212 x2 )\nF \u03b3 w22 (x) = ( \u03b3 + 1)E 1 \u2212 e\n\u03b3\n\u0002\n\u0003\n(2.3.35)\n= q\u03b3 E 1 \u2212 e \u2212hZx , pi x2 (1 \u2212 x2 )\n= U\u03b3 p(x1 )x2 (1 \u2212 x2 ),\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n53\n\nwhere we have used the definition of U\u03b3 .\nWe still have to show that W cat satisfies condition (iv) from Definition 2.1. For any \u03b1 > 0\nand p \u2208 C+ [0, 1], by scaling (Lemma 2.4) and (2.3.29),\np\n\nFc w\u03b1, p = \u03b1F \u03b1c w1, \u03b1 = \u03b1(1 +\n\np\n\u03b1 \u22121\n( 1 + 1 )\u22121 , ( \u03b11 + 1c )\u22121 U \u03b1c ( \u03b1p )\n) F \u03b1c w1, \u03b1 = w \u03b1 c\n.\nc\n\n(2.3.36)\n\nBy Lemma 2.3, this diffusion matrix is continuous, which implies that U \u03b1c ( \u03b1p ) is continuous.\nOur proof of Propostion 2.35 has a corollary.\nCorollary 2.36 (Continuity in parameters) The map (x, \u03b3) 7\u2192 Q\u03b3 (x, *) from [0, 1] \u00d7\n(0, \u221e) to M1 (M[0, 1]) and the map (x, \u03b3, p) 7\u2192 U\u03b3 p(x) from [0, 1] \u00d7 (0, \u221e) \u00d7 C+ [0, 1] to R are\ncontinuous.\nProof By Lemma 2.3, the diffusion matrix in (2.3.36) is continuous in x, \u03b3, and p, which\nR\nimplies the continuity of U\u03b3 p(x). It follows that the map (x, \u03b3) 7\u2192 Q\u03b3 (x, d\u03c7)e \u2212h\u03c7, f i is\ncontinuous for all f \u2208 C+ [0, 1], so by [Kal76, Theorem 4.2], (x, \u03b3) 7\u2192 Q\u03b3 (x, *) is continuous.\nProof of Theorem 2.17 (a) We need to show that Wcat is a renormalization class and\nl,r\nthat Fc maps the subclasses Wcat\ninto themselves. Since these classes correspond to the\ndifferent possible effective boundaries of diffusion matrices in Wcat , this latter fact is in fact\na consequence of Lemma 2.6. Since in Proposition 2.35 it has been shown that W cat is a\nrenormalization class, we are left with the task to show that Fc maps Wcat into itself. By\n(2.3.29) and scaling, it suffices to show that U\u03b3 maps H into itself.\nFix 0 \u2264 x \u2264 x\u0303 \u2264 1. By Lemma 2.32, we can couple the processes yx\u03b3 and yx\u0303\u03b3 from (2.2.17)\nsuch that\n(2.3.37)\nyx\u03b3 (t) \u2264 yx\u0303\u03b3 (t) \u2200t \u2264 0 a.s.\n\nSince the function z 7\u2192 1 \u2212 e\u2212z on [0, \u221e) is Lipschitz continuous with Lipschitz constant 1,\nU\u03b3 p(x\u0303) \u2212 U\u03b3 p(x)\nR \u03c4\u03b3\nR \u03c4\u03b3\n\u03b3\n\u03b3\n\u0002\n\u0002\n\u0003\n\u0003\n= ( \u03b31 + 1)E 1 \u2212 e \u2212 0 p(yx\u0303 (\u2212t/2))dt \u2212 ( \u03b31 + 1)E 1 \u2212 e \u2212 0 p(yx (\u2212t/2))dt\ni\nh Z \u03c4\u03b3\n\u2264 ( \u03b31 + 1)E\np(yx\u0303\u03b3 (\u2212t/2)) \u2212 p(yx\u03b3 (\u2212t/2)) dt\ni\nh 0Z \u03c4\u03b3\n1\nyx\u0303\u03b3 (\u2212t/2) \u2212 yx\u03b3 (\u2212t/2) dt\n\u2264 ( \u03b3 + 1)LE\n0\n\n= ( \u03b31 + 1)L\u03b3(x\u0303 \u2212 x) = L(1 + \u03b3)|x\u0303 \u2212 x|,\n\n(2.3.38)\nwhere L is the Lipschitz constant of p and we have used the same exponentially distributed\n\u03c4\u03b3 for yx\u03b3 and yx\u0303\u03b3 .\n\n2.3.4\n\nMonotone and concave catalyzing functions\n\nIn this section we prove that the log-Laplace operators U\u03b3 from (2.2.20) map monotone functions into monotone functions, and monotone concave functions into monotone concave functions. We do not know if in general U\u03b3 maps concave functions into concave functions.\n\n\f54\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nProposition 2.37 (Preservation of monotonicity and concavity) Let \u03b3 > 0. Then:\n(a) If f \u2208 C+ [0, 1] is nondecreasing, then U\u03b3 f is nondecreasing.\n\n(b) If f \u2208 C+ [0, 1] is nondecreasing and concave, then U\u03b3 f is nondecreasing and concave.\n\nProof Our proof of Proposition 2.37 is in part based on ideas from [BCGH97, Appendix A].\nThe proof is quite long and will depend on several lemmas. We remark that part (a) can be\nproved in a more elementary way using Lemma 2.32.\nWe recall some facts from Hille-Yosida theory. A linear operator A on a Banach space V\nis closable and its closure A generates a strongly continuous contraction semigroup (St )t\u22650 if\nand only if\n(i) D(A) is dense,\n(ii) A is dissipative,\n(2.3.39)\n(iii) R(1 \u2212 \u03b1A) is dense for some, and hence for all \u03b1 > 0.\nHere, for any linear operator B on V , D(B) and R(B) denote the domain and range of B,\nrespectively. For each \u03b1 > 0, the operator (1 \u2212 \u03b1A) : D(A) \u2192 V is a bijection and its inverse\n(1 \u2212 \u03b1A)\u22121 : V \u2192 D(A) is a bounded linear operator, given by\nZ \u221e\n\u22121\nSt u \u03b1\u22121 e\u2212t/\u03b1 dt\n(u \u2208 V, \u03b1 > 0).\n(2.3.40)\n(1 \u2212 \u03b1A) u =\n0\n\nIf E is a compact metrizable space and C(E) is the Banach space of continuous real functions\non E, equipped with the supremumnorm, then a linear operator A on C(E) is closable and its\nclosure A generates a Feller semigroup if and only if (see [EK86, Theorem 4.2.2 and remarks\non page 166])\n1 \u2208 D(A) and A1 = 0,\nD(A) is dense,\nA satisfies the positive maximum principle,\nR(1 \u2212 \u03b1A) is dense for some, and hence for all \u03b1 > 0.\n\n(i)\n(ii)\n(iii)\n(iv)\n\n(2.3.41)\n\nIf A generates a Feller semigroup and g \u2208 C(E), then the operator A + g (with domain\nD(A + g) := D(A)) generates a strongly continuous semigroup (Stg )t\u22650 on C(E). If g \u2264 0\nthen (Stg )t\u22650 is contractive. If (\u03bet )t\u22650 is the Feller process with generator A, then one has the\nFeynman-Kac representation\nRt\n\u0003\nStg u(x) = E x [u(\u03be(t))e 0 g(\u03be(s))ds\n(t \u2265 0, x \u2208 E, g, u \u2208 C(E)).\n(2.3.42)\n\nLet C (n) ([0, 1]2 ) denote the space of continuous real functions on [0, 1]2 whose partial derivatives up to n-th order\nand are continuous on [0, 1]2 (including the boundary), and\nT exist\n(\u221e)\n2\n(n)\nput C ([0, 1] ) := n C ([0, 1]2 ). Define a linear operator B on C([0, 1]2 ) with domain\nD(B) := C (\u221e) ([0, 1]2 ) by\n2\n\n\u2202\n1\n\u2202\nBu(x, y) := y(1 \u2212 y) \u2202y\n2 u(x, y) + \u03b3 (x \u2212 y) \u2202y u(x, y).\n\nBelow, we will prove:\n\n(2.3.43)\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n55\n\nLemma 2.38 (Feller semigroup) The closure in C([0, 1]2 ) of the operator B generates a\nFeller semigroup on C([0, 1]2 ).\nWrite\n\n\b\nC+ := u \u2208 C([0, 1]2 ) : u \u2265 0 ,\n\b\n\u2202\n\u2202\nu, \u2202x\nu\u22650 ,\nC1+ := u \u2208 C (1) ([0, 1]2 ) : \u2202y\n\b\n2\n\u2202\n\u22022\n\u22022\nC2+ := u \u2208 C (2) ([0, 1]2 ) : \u2202y\nu\u22650 .\n2 u, \u2202x\u2202y u,\n\u2202x2\n\n(2.3.44)\n\nLet S denote the closure of a set S \u2282 C([0, 1]2 ). We need the following lemma.\n\nLemma 2.39 (Preserved classes) Let g \u2208 C([0, 1]2 ) and let (Stg )t\u22650 be the strongly continuous semigroup with generator B + g. Then, for each t \u2265 0:\n(a) If g \u2208 C1+ , then Stg maps C+ \u2229 C1+ into itself.\n(b) If g \u2208 C1+ \u2229 C2+ , then Stg maps C+ \u2229 C1+ \u2229 C2+ into itself.\nTo see why Lemma 2.39 implies Proposition 2.37, let (x(t), y(t))t\u22650 denote the Feller process\nin [0, 1]2 generated by B. It is easy to see that x(t) = x(0) a.s. for all t \u2265 0. For fixed x(0) = x,\nthe process (y(t))t\u22650 is the diffusion given by the SDE (2.3.20). Therefore, by Feynman-Kac,\nfor each g \u2208 C([0, 1]2 ),\n\u0002 R t g(x, y(s))ds \u0003\ny\nE e 0\n= S g 1(x, y),\n(2.3.45)\nt\n\nC([0, 1]2 ).\n\nwhere 1 denotes the constant function 1 \u2208\nBy (2.2.20),\nZ\nR\n\u0010\n\u03c4\u03b3\n\u0002\n\u0003\u0011\nU\u03b3 f (x) = ( \u03b31 + 1) 1 \u2212 \u0393\u03b3x (dy)E y e \u2212 0 f (yx (s))ds\n(f \u2208 C+ [0, 1]),\n\n(2.3.46)\n\nwhere \u0393\u03b3x is the invariant law of (y(t))t\u22650 from Corollary 2.30 and \u03c4\u03b3 is an exponential time with\nmean \u03b3, independent of (y(t))t\u22650 . Setting g(x, y) := \u2212f (y) in (2.3.45), using the ergodicity\nof (y(t))t\u22650 (see Corollary 2.30), we find that for each z \u2208 [0, 1] and t \u2265 0,\nZ\nZ\n\u0002 \u2212 R t f (y(s))ds \u0003\n\u0002 \u2212 R t g(x, y(s))ds \u0003\n\u03b3\ny\nz\ny\n0\n0\n\u0393x (dy)E e\n= lim\nP [y(r) \u2208 dy] E e\nr\u2192\u221e\n(2.3.47)\n= lim Sr0 Stg 1(x, z).\nr\u2192\u221e\n\nIt follows from Lemma 2.39 that for each fixed r, t, and z, the function x 7\u2192 Sr0 Stg 1(x, z) is\nnondecreasing if f is nonincreasing, and nondecreasing and convex if f is nonincreasing and\nconcave. Therefore, taking the expectation over the randomness of \u03c4\u03b3 , the claims follow from\n(2.3.46) and (2.3.47).\nWe still need to prove Lemmas 2.38 and 2.39.\nProof of Lemma 2.38 It is easy to see that the operator B from (2.3.43) is densely defined,\nsatisfies the positive maximum principle, and maps the constant function 1 into 0. Therefore,\nby Hille-Yosida (2.3.41), we must show that the range R(1 \u2212 \u03b1B) is dense in C([0, 1]2 ) for\nsome, and hence for all \u03b1 > 0. Let Pn denote the space of polynomials on [0, 1]2 of n-th and\nlower order, i.e., the space of functions f : [0, 1]2 \u2192 R of the form\nX\nf (x, y) =\nakl xk y l with ak,l = 0 for k + l > n.\n(2.3.48)\nk,l\u22650\n\n\f56\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nS\nSet P\u221e := n Pn . It is easy to see that B maps the space Pn into itself, for each n \u2265 0. Since\neach Pn is finite-dimensional, a simple argument (see [EK86, Proposition 1.3.5]) shows that\nthe image of P\u221e under 1 \u2212 \u03b1B is dense in C([0, 1]2 ) for all but countably many, and hence for\nall \u03b1 > 0.\nAs a first step towards proving Lemma 2.39, we prove:\nLemma 2.40 (Smooth solutions to Laplace equation) Let \u03b1 > 0, g \u2208 C (2) ([0, 1]), g \u2264 0,\nv \u2208 C([0, 1]2 ), and assume that u \u2208 C (\u221e) ([0, 1]2 ) solves the Laplace equation\n(1 \u2212 \u03b1(B + g))u = v.\n\n(2.3.49)\n\n(a) If g \u2208 C1+ , then v \u2208 C+ \u2229 C1+ implies u \u2208 C+ \u2229 C1+ .\n\n(b) If g \u2208 C1+ \u2229 C2+ , then v \u2208 C+ \u2229 C1+ \u2229 C2+ implies u \u2208 C+ \u2229 C1+ \u2229 C2+ .\n2\n\n\u2202\n\u2202\nProof Let uy := \u2202y\nu, uxy := \u2202x\u2202y\nu, etc. denote the partial derivatives of u and similarly for\nv and g, whenever they exist. Set c := \u03b31 . Define linear operators B \u2032 and B \u2032\u2032 on C([0, 1]2 ) with\ndomains D(B \u2032 ) = D(B \u2032\u2032 ) := C (\u221e) ([0, 1]2 ) by\n\nThen\n\n\u0001\u2202\n1\n\u22022\nB \u2032 := y(1 \u2212 y) \u2202y\n2 + c(x \u2212 y) + 2( 2 \u2212 y) \u2202y ,\n\u0001\u2202\n1\n\u22022\nB \u2032\u2032 := y(1 \u2212 y) \u2202y\n2 + c(x \u2212 y) + 4( 2 \u2212 y) \u2202y .\n\u2202\n\u2032\ny\n\u2202y Bu = (B \u2212 c)u ,\n\u2202\nx\ny\n\u2202x Bu = Bu + cu ,\n\n\u2202\n\u2032\n\u2032\u2032\ny\n\u2202y B u = (B \u2212 c \u2212 2)u ,\n\u2202\n\u2032\n\u2032 x\ny\n\u2202x B u = B u + cu .\n\n(2.3.50)\n\n(2.3.51)\n\nTherefore, it is easy to see that\n(i)\n(1 \u2212 \u03b1(B \u2032 \u2212 c + g))uy = v y + \u03b1g y u,\n(ii)\n(1 \u2212 \u03b1(B + g))ux = v x + \u03b1(cuy + g x u),\n(iii) (1 \u2212 \u03b1(B \u2032\u2032 \u2212 2c \u2212 2 + g))uyy = v yy + \u03b1(2gy uy + gyy u),\n(iv)\n(1 \u2212 \u03b1(B \u2032 \u2212 c + g))uxy = v xy + \u03b1(cuyy + g y ux + g xy u + g x uy ),\n(v)\n(1 \u2212 \u03b1(B + g))uxx = v xx + \u03b1(2cuxy + 2g x ux + gxx u),\n\n(2.3.52)\n\nwhere in (i) and (ii) we assume that v \u2208 C (1) ([0, 1]2 ) and in (iii)\u2013(v) we assume that v \u2208\nC (2) ([0, 1]2 ). By Lemma 2.38, the closure of the operator B generates a Feller processes\nin [0, 1]2 . Exactly the same proof shows that B \u2032 and B \u2032\u2032 also generate Feller processes on\n[0, 1]2 . Therefore, by Feynman-Kac, u is nonnegative if v is nonnegative and uy , . . . , uxx\nare nonnegative if the right-hand sides of the equations (i)\u2013(v) are well-defined and nonnegative. (Instead of using Feynman-Kac, this follows more elementarily from the fact that\nB, B \u2032 , and B \u2032\u2032 satisfy the positive maximum principle.) In particular, if gy , gx \u2265 0 and\nv \u2208 C (1) ([0, 1]2 ), v, v y , v x \u2265 0, then it follows that u, uy , ux \u2265 0. If moreover gyy , gxy , gxx \u2265 0\nand v \u2208 C (2) ([0, 1]2 ), v yy , v xy , v yy \u2265 0, then also uyy , uxy , uyy \u2265 0.\nIn order to prove Lemma 2.39, based on Lemma 2.40, we will show that the Laplace equation\n(2.3.49) has smooth solutions u for sufficiently many functions v. Here 'suffiently many' will\n\n\f2.3. THE RENORMALIZATION CLASS WCAT\n\n57\n\nmean dense in the topology of uniform convergence of functions and their derivatives up to\nsecond order. To this aim, we make C (2) ([0, 1]2 ) into a Banach space by equipping it with the\nnorm\nkuk(2) := kuk + kuy k + kux k + kuyy k + 2kuxy k + kuxx k.\n(2.3.53)\nHere, to reduce notation, we denote the supremumnorm by kf k := kf k\u221e . Note the factor 2\nin the second term from the right in (2.3.53), which is crucial for the next key lemma.\nLemma 2.41 (Semigroup on twice diffferentiable functions) The closure in C (2) ([0, 1]2 )\nof the operator B generates a strongly continuous contraction semigroup on C (2) ([0, 1]2 ).\nProof We must check the conditions (i)\u2013(iii) from (2.3.39). It is well-known (see for example\n[EK86, Proposition 7.1 from the appendix]) that the space P\u221e of polynomials is dense in\nC (2) ([0, 1]2 ). Therefore D(B) = C (\u221e) ([0, 1]2 ) is dense, and copying the proof of Lemma 2.38\nwe see that R(1 \u2212 \u03b1B) is dense for all but countably many \u03b1. To complete the proof, we must\nshow that B is dissipative, i.e., that\nk(1 \u2212 \u03b5B)uk(2) \u2265 kuk(2)\n\n(\u03b5 > 0, u \u2208 C (\u221e) ([0, 1]2 )).\n\n(2.3.54)\n\nUsing (2.3.51), we calculate\n\u2202\n\u2202y (1\n\u2202\n\u2202x (1\n\u22022\n(1\n\u2202y 2\n2\n\u2202\n\u2202x\u2202y (1\n\u22022\n(1\n\u2202x2\n\n\u2212 \u03b5B)u = (1 \u2212 \u03b5(B \u2032 \u2212 c))uy ,\n\n\u2212 \u03b5B)u = (1 \u2212 \u03b5B)ux \u2212 \u03b5cuy ,\n\n\u2212 \u03b5B)u = (1 \u2212 \u03b5(B \u2032\u2032 \u2212 2c \u2212 2))uyy ,\n\n(2.3.55)\n\n\u2212 \u03b5B)u = (1 \u2212 \u03b5(B \u2032 \u2212 c))uxy \u2212 \u03b5cuyy ,\n\n\u2212 \u03b5B)u = (1 \u2212 \u03b5B)uxx \u2212 2\u03b5cuxy .\n\nUsing the disipativity of B, B \u2032 , and B \u2032\u2032 with respect to the supremumnorm (which follows from\n\u03b5\nthe positive maximum principle) we see that k(1 \u2212 \u03b5(B \u2032 \u2212 c))uy k = (1 + \u03b5c)k(1 \u2212 1+\u03b5c\nB)uy k \u2265\ny\n(1 + \u03b5c)ku k etc. We conclude therefore from (2.3.55) that\nk(1 \u2212 \u03b5B)uk(2) \u2265 k(1 \u2212 \u03b5B)uk + k(1 \u2212 \u03b5(B \u2032 \u2212 c))uy k + k(1 \u2212 \u03b5B)ux k \u2212 \u03b5ckuy k\n\n+k(1 \u2212 \u03b5(B \u2032\u2032 \u2212 2c \u2212 2))uyy k + 2k(1 \u2212 \u03b5(B \u2032 \u2212 c))uxy k \u2212 2\u03b5ckuyy k\n\n+k(1 \u2212 \u03b5B)uxx k \u2212 2\u03b5ckuxy k\n\n\u2265 kuk + (1 + \u03b5c)kuy k + kux k \u2212 \u03b5ckuy k\n\n(2.3.56)\n\n+(1 + \u03b5(2c + 2))kuyy k + 2(1 + \u03b5c)kuxy k \u2212 2\u03b5ckuyy k\n\n+kuxx k \u2212 2\u03b5ckuxy k \u2265 kuk(2)\n\nfor each \u03b5 > 0, which shows that B is dissipative with respect to the norm k * k(2) .\nProof of Lemma 2.39 Let g \u2208 C (2) ([0, 1]2 ). Then u 7\u2192 gu is a bounded operator on both\nC([0, 1]2 ) and C (2) ([0, 1]2 ), so we can choose a \u03bb > 0 such that\nkguk \u2264 \u03bbkuk\n\nand kguk(2) \u2264 \u03bbkuk(2)\n\n(2.3.57)\n\n\f58\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nfor all u in C([0, 1]2 ) and C (2) ([0, 1]2 ), respectively. Put g\u0303 := g \u2212 \u03bb. By Lemma 2.38, B + g\u0303\ngenerates a strongly continuous contraction semigroup (Stg\u0303 )t\u22650 = (e\u2212\u03bbt Stg )t\u22650 on C([0, 1]2 ).\nNote that R(1 \u2212 \u03b1(B + g\u0303)) is the space of all v \u2208 C([0, 1]2 ) for which the Laplace equation\n(1 \u2212 \u03b1(B + g\u0303))u = v has a solution u \u2208 C (\u221e) ([0, 1]2 ). Therefore, by Lemma 2.40, for each\n\u03b1 > 0:\n(i) If g \u2208 C1+ , then (1 \u2212 \u03b1(B + g\u0303))\u22121 maps R(1 \u2212 \u03b1(B + g\u0303)) \u2229 C+ \u2229 C1+ into C+ \u2229 C1+ .\n\n(ii) If g \u2208 C1+ \u2229 C2+ , then (1 \u2212 \u03b1(B + g\u0303))\u22121 maps R(1 \u2212 \u03b1(B + g\u0303)) \u2229 C+ \u2229 C1+ \u2229 C2+\ninto C+ \u2229 C1+ \u2229 C2+ .\n(2.3.58)\ng\u0303\n(2)\n2\nBy Lemma 2.41, the restriction of the semigroup (St )t\u22650 to C ([0, 1] ) is strongly continuous\nand contractive in the norm k * k(2) . Therefore, by Hille-Yosida (2.3.39), R(1 \u2212 \u03b1(B + g\u0303)) is\ndense in C (2) ([0, 1]2 ) for each \u03b1 > 0. It follows that R(1 \u2212 \u03b1(B + g\u0303)) \u2229 C+ \u2229 C1+ is dense in\nC+ \u2229 C1+ and likewise R(1 \u2212 \u03b1(B + g\u0303)) \u2229 C+ \u2229 C1+ \u2229 C2+ is dense in C+ \u2229 C1+ \u2229 C2+ , both in the\nnorm k * k(2) . Note that we need density in the norm k * k(2) here: if we would only know that\nR(1 \u2212 \u03b1(B + g\u0303)) is a dense subset of C([0, 1]2 ) in the norm k * k, then R(1 \u2212 \u03b1(B + g\u0303)) \u2229 C+ \u2229 C1+\nmight be empty. By approximation in the norm k * k(2) it follows from (2.3.58) that:\n(i) If g \u2208 C1+ , then (1 \u2212 \u03b1(B + g\u0303))\u22121 maps C+ \u2229 C1+ into itself.\n\n(ii) If g \u2208 C1+ \u2229 C2+ , then (1 \u2212 \u03b1(B + g\u0303))\u22121 maps C+ \u2229 C1+ \u2229 C2+ into itself.\n\n(2.3.59)\n\nUsing also continuity in the norm k * k we find that:\n\n(i) If g \u2208 C1+ , then (1 \u2212 \u03b1(B + g\u0303))\u22121 maps C+ \u2229 C1+ into itself.\n\n(ii) If g \u2208 C1+ \u2229 C2+ , then (1 \u2212 \u03b1(B + g\u0303))\u22121 maps C+ \u2229 C1+ \u2229 C2+ into itself.\n\n(2.3.60)\n\nFor \u03b5 > 0 let\n\n\u0001\nG\u03b5 := \u03b5\u22121 (1 \u2212 \u03b5(B + g\u0303))\u22121 \u2212 1\n\n(2.3.61)\n\nbe the Yosida approximation to B + g\u0303. Then\neG\u03b5 t = e\u2212\u03b5\n\n\u22121 t\n\n\u221e n\nX\nt\n\nn=0\n\nn!\n\n(1 \u2212 \u03b5(B + g\u0303))\u2212n\n\n(t \u2265 0),\n\n(2.3.62)\n\nand therefore, by (2.3.60), for each t \u2265 0:\n\n(i) If g \u2208 C1+ , then eG\u03b5 t maps C+ \u2229 C1+ into itself.\n\nFinally\n\n(ii) If g \u2208 C1+ \u2229 C2+ , then eG\u03b5 t maps C+ \u2229 C1+ \u2229 C2+ into itself.\ne\u2212\u03bbt Stg u = Stg\u0303 u = lim e G\u03b5 t u\n\u03b5\u21920\n\n(t \u2265 0, u \u2208 C([0, 1]2 )),\n\n(2.3.63)\n\n(2.3.64)\n\nso (2.3.63) implies that for each t \u2265 0:\n\n(i) If g \u2208 C1+ , then Stg maps C+ \u2229 C1+ into itself.\n\n(ii) If g \u2208 C1+ \u2229 C2+ , then Stg maps C+ \u2229 C1+ \u2229 C2+ into itself.\n\n(2.3.65)\n\nUsing the continuity of Stg in g (which follows from Feynman-Kac (2.3.42)) we arrive at the\nstatements in Lemma 2.39.\n\n\f59\n\n2.4. CONVERGENCE TO A TIME-HOMOGENEOUS PROCESS\n\n2.4\n\nConvergence to a time-homogeneous process\n\n2.4.1\n\nConvergence of certain Markov chains\n\nSection 2.4 is devoted to the proof of Theorem 2.19. In the present subsection, we start\nby formulating a theorem about the convergence of certain Markov chains to continuoustime processes. In Section 2.4.2 we specialize to Poisson-cluster branching processes and\nsuperprocesses. In Section 2.4.3, finally, we carry out the necessary calculations for the specific\nprocesses from Theorem 2.19.\nLet E be a compact metrizable space. We equip the space C(E) of continuous real functions\non E with the supremumnorm k * k\u221e . By definition, DE [0, \u221e) is the space of cadlag functions\nw : [0, \u221e) \u2192 E, equipped with the Skorohod topology. Let A : D(A) \u2192 C(E) be an operator\ndefined on a domain D(A) \u2282 C(E). We say that a process y = (yt )t\u22650 solves the martingale\nproblem for A if y has sample paths in DE [0, \u221e) and for each f \u2208 D(A), the process (Mtf )t\u22650\ngiven by\nZ\nt\n\nMtf := f (yt ) \u2212\n\nAf (ys )ds\n\n0\n\n(t \u2265 0)\n\n(2.4.1)\n\nis a martingale with respect to the filtration generated by y. We say that existence (uniqueness) holds for the martingale problem for A if for each probability measure \u03bc on E there is\nat least one (at most one (in law)) solution y to the martingale problem for A with initial\nlaw L(y0 ) = \u03bc. If both existence and uniqueness hold we say that the martingale problem\n(n)\n(n)\nis well-posed. For each n \u2265 0, let X (n) = (X0 , . . . , Xm(n) ) (with 1 \u2264 m(n) < \u221e) be a\n(time-inhomogeneous) Markov process in E with k-th step transition probabilities\n\u0002 (n)\n\u0003\n(n)\nPk (x, dy) = P Xk \u2208 dy Xk\u22121 = x\n\n(1 \u2264 k \u2264 m(n)).\n\n(2.4.2)\n\n(n)\n\nWe assume that the Pk are continuous probability kernels on E. Let (\u03b5k )1\u2264k\u2264m(n) be positive\nconstants. Set\n\u0010Z\n\u0011\n(n)\n(n)\nPk (x, dy)f (y) \u2212 f (x)\n(1 \u2264 k \u2264 m(n), f \u2208 C(E)).\n(2.4.3)\nAk f (x) := (\u03b5k )\u22121\nE\n\n(n)\n\nDefine t0\n\n:= 0 and\n(n)\n\ntk :=\n\nk\nX\n\n(n)\n\n\u03b5l\n\nl=1\n\nand put\n\n(1 \u2264 k \u2264 m(n)),\n\n\b\n(n)\nk(n) (t) := max k : 0 \u2264 k \u2264 m(n), tk \u2264 t\n\n(2.4.4)\n\n(t \u2265 0).\n\n(2.4.5)\n\n(n)\n\nDefine processes y(n) = (yt )t\u22650 with sample paths in DE [0, \u221e) by\n(n)\n\nyt\n\n(n)\n\n:= Xk(n) (t)\n\n(t \u2265 0).\n\n(2.4.6)\n\nBy definition, a space A of real functions is called an algebra if A is a linear space and f, g \u2208 A\nimplies f g \u2208 A.\n\n\f60\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n(n)\n\nTheorem 2.42 (Convergence of Markov chains) Assume that L(X0 ) \u21d2 \u03bc as n \u2192 \u221e\nfor some probability law \u03bc on E. Suppose that there exists at most one (in law) solution to the\nmartingale problem for A with initial law \u03bc. Assume that the linear span of D(A) contains an\nalgebra that separates points. Assume that\nm(n)\n\n(i) lim\n\nn\u2192\u221e\n\n(n)\n\nX\n\n\u03b5k\n\nk=1\n\n= \u221e,\n\n(ii) lim\n\nn\u2192\u221e\n\n(n)\n\nsup\nk:\n\n(n)\ntk \u2264T\n\n\u03b5k = 0,\n\n(2.4.7)\n\nand\nlim\n\nn\u2192\u221e\n\n(n)\n\nsup\n(n)\n\nk: tk \u2264T\n\nAk f \u2212 Af k\u221e = 0\n\n(f \u2208 D(A))\n\n(2.4.8)\n\nfor each T > 0. Then there exists a unique solution y to the martingale problem for A with\ninitial law \u03bc and moreover L(y(n) ) \u21d2 L(y), where \u21d2 denotes weak convergence of probability\nmeasures on DE [0, \u221e).\nProof We apply [EK86, Corollary 4.8.15]. Fix f \u2208 D(A). We start by observing that\n(n)\nf (Xk )\n\n\u2212\n\nk\nX\n\n(n)\n\n(n)\n\n(n)\n\n(0 \u2264 k \u2264 m(n))\n\n\u03b5i Ai f (Xi\u22121 )\n\ni=1\n\n(2.4.9)\n\nis a martingale with respect to the filtration generated by X (n) and therefore,\nk (n) (t)\n(n)\nf (yt )\n\nX (n) (n)\n(n)\n\u2212\n\u03b5i Ai f (y (n) )\n\n(t \u2265 0)\n\nti\u22121\n\ni=1\n\n(2.4.10)\n\nis a martingale with respect to the filtration generated by y(n) . Put\n(n)\n\n\u230at\u230b(n) := tk(n) (t)\n\n(t \u2265 0)\n\n(2.4.11)\n\nand set\n(n)\n\n\u03c6t\n\n(n)\n\n(n)\n\n:= Ak(n) (t)+1 f (y\u230at\u230b(n) )1{t<t(n)\n\nm(n)\n\n}\n\n(t \u2265 0)\n\n(2.4.12)\n\nand\n(n)\n\u03bet\n\n:=\n\n(n)\nf (yt ) +\n\nZ\n\nt\n\u230at\u230b(n)\n\n\u03c6s(n) ds\n\n(t \u2265 0).\n\n(2.4.13)\n\nThen we can rewrite the martingale in (2.4.10) as\n(n)\n\n\u03bet\n\n\u2212\n\nZ\n\n0\n\nt\n\n\u03c6s(n) ds.\n\n(2.4.14)\n\n\f2.4. CONVERGENCE TO A TIME-HOMOGENEOUS PROCESS\n\n61\n\nBy [EK86, Corollary 4.8.15] and the compactness of the state space, it suffices to check the\nfollowing conditions on \u03c6(n) and \u03be (n) :\n\u0002 (n) \u0003\nsup sup E |\u03bet | < \u221e,\nn\u2265N t\u2264T\n\u0002 (n) \u0003\n(ii) sup sup E |\u03c6t | < \u221e,\n(i)\n\nn\u2265N t\u2264T\n\n(iii)\n(iv)\n\nr\ni\nh\nY\n(n) \u0001\n(n)\nhi (ys(n)\n)\n= 0,\nlim E \u03beT \u2212 f (yT )\ni\n\nn\u2192\u221e\n\ni=1\n\nlim E\n\nn\u2192\u221e\n\nh\n\n(n)\n\u03c6T\n\nh\nlim E\nsup\nn\u2192\u221e\nt\u2208Q\u2229[0,T ]\n\u0003\n\u0002\n(vi) sup E k\u03c6(n) kp,T < \u221e\n(v)\n\nr\nY\n\ni\nhi (ys(n)\n)\n= 0,\ni\ni=1\ni\n(n)\n(n)\n\u03bet \u2212 f (yt ) = 0,\n\n(n) \u0001\n\u2212 Af (yT )\n\n(2.4.15)\n\nfor some p \u2208 (1, \u221e],\n\nn\u2265N\n\nfor some N \u2265 0 and for eachRT > 0, r R\u2265 1, 0 \u2264 s1 < * * * < sr \u2264 T , and h1 , . . . , hr \u2208 H \u2282 C(E).\nHere H is separating, i.e., hd\u03bc = hd\u03bd for all h \u2208 H implies \u03bc = \u03bd whenever \u03bc, \u03bd are\nprobability measures on E. In (vi):\nkgkp,T :=\n\n\u0010Z\n\nT\n\n0\n\n|g(t)|p dt\n\n\u00111/p\n\n(1 \u2264 p < \u221e)\n\n(2.4.16)\n\nand kgk\u221e,T denotes the essential supremum of g over [0, T ].\nThe conditions (2.4.15) (i)\u2013(vi) are implied by the stronger conditions\n(i)\n(ii)\n\n(n)\n\nlim\n\nsup\n\n\u03bet\n\nlim\n\nsup\n\n\u03c6t\n\nn\u2192\u221e 0\u2264t\u2264T\nn\u2192\u221e 0\u2264t\u2264T\n\n(n)\n\n\u2212 f (yt )\n\n(n)\n\n\u221e\n\n= 0,\n\n(n)\n\n\u2212 Af (yt )\n\n\u221e\n\n(2.4.17)\n\n= 0,\n\nwhere we denote the essential supremumnorm of a real-valued random variable X by kXk\u221e :=\ninf{K \u2265 0 : |X| \u2264 K a.s.}. Condition (2.4.17) (ii) is implied by (2.4.7) (i) and (2.4.8). To see\nthat also (2.4.17) (i) holds, set\nMn := sup\n\n0\u2264t\u2264T\n\n(n)\n\n\u03c6t\n\n\u221e\n\n,\n\n(2.4.18)\n\nand estimate\nsup\n0\u2264t\u2264T\n\n(n)\n\n\u03bet\n\n(n)\n\n\u2212 f (yt )\n\n(n)\n\n\u221e\n\n\u2264 Mn sup{\u03b5k\n\n(n)\n\n: 1 \u2264 k \u2264 m(n), tk \u2264 T }.\n\n(2.4.19)\n\nCondition (2.4.17) (ii) implies that lim supn Mn < \u221e and therefore the right-hand side of\n(2.4.19) tends to zero by assumption (2.4.7) (ii).\n\n\f62\n\n2.4.2\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nConvergence of certain branching processes\n\nIn this section we apply Theorem 2.42 to certain branching processes and superprocesses.\nThroughout this section, E is a compact metrizable space and A : D(A) \u2192 C(E) is a linear\noperator on C(E) such that the closure A of A generates a Feller process \u03be = (\u03bet )t\u22650 in E with\nFeller semigroup (Pt )t\u22650 given by Pt f (x) := E x [f (\u03bet )] (t \u2265 0, f \u2208 C(E)).\nLet \u03b1 \u2208 C+ (E) and \u03b2, f \u2208 C(E). By definition, a function t 7\u2192 ut from [0, \u221e) into C(E) is\na classical solution to the semilinear Cauchy problem\n( \u2202\n2\n(t \u2265 0),\n\u2202t ut = Aut + \u03b2ut \u2212 \u03b1ut\n(2.4.20)\nu0 = f\nif t 7\u2192 ut is continuously differentiable (in C(E)), ut \u2208 D(A) for all t \u2265 0, and (2.4.20) holds.\nWe say that u is a mild solution to (2.4.20) if t 7\u2192 ut is continuous and\nut = Pt f +\n\nZ\n\nt\n0\n\nPt\u2212s (\u03b2us \u2212 \u03b1u2s )ds\n\n(t \u2265 0).\n\n(2.4.21)\n\nLemma 2.43 (Mild and classical solutions) Equation (2.4.20) has a unique C+ (E)-valued\nmild solution u for each f \u2208 C+ (E), and f > 0 implies that ut > 0 for all t \u2265 0. If moreover\nf \u2208 D(A) then u is a classical solution. For each t \u2265 0, ut depends continuously on f \u2208 C+ (E).\nProof It follows from [Paz83, Theorems 6.1.2, 6.1.4, and 6.1.5] that for each f \u2208 C(E), (2.4.20)\nhas a unique solution (ut )0\u2264t<T up to an explosion time T , and that this is a classical solution\nif f \u2208 D(A). Moreover, ut depends continuously on f . Using comparison arguments based\non the fact that A satisfies the positive maximum principle (which follows from Hille-Yosida\n(2.3.41)) one easily proves the other statements; compare [FS04, Lemmas 23 and 24].\nWe denote the (mild or classical) solution of (2.4.20) by Ut f := ut ; then Ut : C+ (E) \u2192 C+ (E)\nare continuous operators and U = (Ut )t\u22650 is a (nonlinear) semigroup on C+ (E).\nSince E is compact, the spaces {\u03bc \u2208 M(E) : \u03bc(E) \u2264 M } are compact for each M \u2265 0. In\nparticular, M(E) is locally compact. We denote its one-point compactification by M(E)\u221e =\nM(E) \u222a {\u221e}. We define functions Ff \u2208 C(M(E)\u221e ) by Ff (\u221e) := 0 and\nFf (\u03bc) := e \u2212h\u03bc, f i\n\n(f \u2208 C+ (E), f > 0, \u03bc \u2208 M(E)).\n\n(2.4.22)\n\nWe introduce an operator G with domain\nD(G) := {Ff : f \u2208 D(A), f > 0},\n\n(2.4.23)\n\ngiven by GFf (\u221e) := 0 and\nGFf (\u03bc) := \u2212h\u03bc, Af + \u03b2f \u2212 \u03b1f 2 i e \u2212h\u03bc, f i\nNote that GFf \u2208 C(M(E)\u221e ) for all Ff \u2208 D(G).\n\n(\u03bc \u2208 M(E)).\n\n(2.4.24)\n\n\f2.4. CONVERGENCE TO A TIME-HOMOGENEOUS PROCESS\n\n63\n\nProposition 2.44 ((A, \u03b1, \u03b2)-superprocesses) The martingale problem for the operator G\nis well-posed. The solutions to this martingale problem define a Feller process Y = (Yt )t\u22650\nin M(E)\u221e with continuous sample paths, called the (A, \u03b1, \u03b2)-superprocess. If Y0 = \u221e then\nYt = \u221e for all t \u2265 0. If Y0 = \u03bc \u2208 M(E) then\n\u0002\n\u0003\nE \u03bc e \u2212hYt , f i = e \u2212h\u03bc, Ut f i\n\n(f \u2208 C+ (E)).\n\n(2.4.25)\n\nProof Results of this type are well-known, see for example [EK86, Theorem 9.4.3], [Fit88],\nand [ER91, Th\u00e9or\u00e8me 7]. Since, however, it is not completely straightforward to derive the\nproposition above from these references, we give a concise autonomous proof of most of our\nstatements. Only for the continuity of sample paths we refer the reader to [Fit88, Corollary (4.7)] or [ER91, Corollaire 9].\nWe are going to extend G to an operator \u011c that is linear and satisfies the conditions of\nthe Hille-Yosida Theorem (2.3.41). For any \u03b3 \u2208 C+ (E) and \u03bc \u2208 M(E), let Clust\u03b3 (\u03bc) denote\na random measure such that on {\u03b3 = 0}, Clust\u03b3 (\u03bc) is equal to \u03bc, and on {\u03b3 > 0}, Clust\u03b3 (\u03bc)\nis a Poisson cluster measure with intensity \u03b31 \u03bc and cluster mechanism Q(x, *) = L(\u03c4\u03b3(x) \u03b4x ),\nwhere \u03c4\u03b3(x) is exponentially distributed with mean \u03b3(x). It is not hard to see that\n\u0002\n\u0003\nE e \u2212hClust\u03b3 (\u03bc), f i = e \u2212h\u03bc, V\u03b3 f i\n\n(f \u2208 C(E), f > 0),\n\n(2.4.26)\n\n1\n+ \u03b3(x))\u22121 . Note that since V\u03b3 1 is bounded, the previously mentioned\nwhere V\u03b3 f (x) := ( f (x)\nPoisson cluster measure mentioned above is well-defined. By definition, we put Clust\u03b3 (\u221e) :=\n\u221e.\nDefine a linear operator G\u03b1 on C(M(E))\u221e ) by\n\u0001\nG\u03b1 F (\u03bc) := lim \u03b5\u22121 E[F (Clust\u03b5\u03b1 (\u03bc))] \u2212 F (\u03bc)\n(2.4.27)\n\u03b5\u21920\n\nwith as domain D(G\u03b1 ) the space of all F \u2208 C(M(E)\u221e ) for which the limit exists. Define a\nlinear operator G\u03b2 by\n\u0001\nG\u03b2 F (\u03bc) := lim \u03b5\u22121 F ((1 + \u03b5\u03b2)\u03bc) \u2212 F (\u03bc)\n(2.4.28)\n\u03b5\u21920\n\nwith domain D(G\u03b2 ) := C(M(E))\u221e ). Define Pt\u2217 : M(E)\u221e \u2192 M(E)\u221e by hPt\u2217 \u03bc, f i := h\u03bc, Pt f i\n(t \u2265 0, f \u2208 C(E), \u03bc \u2208 M(E)) and Pt\u2217 \u221e := \u221e (t \u2265 0). Finally, let GA be the linear operator\non C(M(E))\u221e ) defined by\n\u0001\nGA F (\u03bc) := lim \u03b5\u22121 F (P\u03b5\u2217 \u03bc) \u2212 F (\u03bc) ,\n(2.4.29)\n\u03b5\u21920\n\nwith as domain D(GA ) the space of all F for which the limit exists. Define an operator \u011c by\n\u011c := G\u03b1 + G\u03b2 + GA ,\n\n(2.4.30)\n\nwith domain D(\u011c) := D(G\u03b1 ) \u2229 D(GA ). If f \u2208 D(A), f > 0, and Ff is as in (2.4.22), then it is\nnot hard to see that \u011cFf (\u221e) = 0 and\n\u011cFf (\u03bc) := \u2212h\u03bc, Af + \u03b2f \u2212 \u03b1f 2 i e \u2212h\u03bc, f i\n\n(\u03bc \u2208 M(E)).\n\n(2.4.31)\n\n\f64\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nIn particular, \u011c extends the operator G from (2.4.24). Since D(A) is dense in C(E), it is\neasy to see that {Ff : f \u2208 D(A), f > 0} is dense in C(M(E)\u221e ). Hence D(\u011c) is dense.\nUsing (2.4.27)\u2013(2.4.29) it is not hard to show that \u011c satisfies the positive maximum principle.\nMoreover, by Lemma 2.43, for f \u2208 D(A) with f > 0, the function t 7\u2192 FUt f from [0, \u221e) into\nC(M(E)\u221e ) is continuously differentiable, satisfies FUt f \u2208 D(\u011c) for all t \u2265 0, and\n\u2202\n\u2202t FUt f\n\n= \u011cFUt f\n\n(t \u2265 0).\n\n(2.4.32)\n\nFrom this it is not hard to see that \u011c also satisfies condition (2.3.41) (ii), so the closure of\n\u011c generates a Feller semigroup (St )t\u22650 on C(M(E)\u221e ). It is easy to see that St Ff = FUt f\n(t \u2265 0). By [EK86, Theorem 4.2.7], this semigroup corresponds to a Feller process Y with\ncadlag sample paths in M(E)\u221e . This means that E \u03bc [Ff (Yt )] = FUt f (\u03bc) for all f \u2208 D(A) with\nf > 0. If \u03bc = \u221e this shows that Yt = \u221e for all t \u2265 0. If \u03bc \u2208 M(E) we obtain (2.4.25) for\nf \u2208 D(A), f > 0; the general case follows by approximation.\nNow let (q\u03b5 )\u03b5>0 be continuous weight functions and let (Q\u03b5 )\u03b5>0 be continuous cluster mechanisms on E. Assume that\nZ\nZ\u03b5 (x) := Q\u03b5 (x, d\u03c7)h\u03c7, 1i < \u221e\n(x \u2208 E)\n(2.4.33)\nand define probability kernels K\u03b5 on E by\nZ\nZ\n1\nQ\u03b5 (x, d\u03c7)h\u03c7, f i\nK\u03b5 (x, dy)f (y) :=\nZ\u03b5 (x)\n\n(f \u2208 B(E)).\n\n(2.4.34)\n\n(n)\n\nFor each n \u2265 0, let (\u03b5k )1\u2264k\u2264m(n) (with 1 \u2264 m(n) < \u221e) be positive constants. Let X (n) =\n(n)\n\n(n)\n\n(X0 , . . . , Xm(n) ) be a Poisson-cluster branching process with weight functions q\u03b5(n) , . . . , q\u03b5(n)\n1\n\nand cluster mechanisms Q\u03b5(n) , . . . , Q\u03b5(n) . Define\n1\n\nprocesses Y (n) by\n\nm(n)\n\n(n)\n\nYt\n\n(n)\n\n:= Xk(n) (t)\n\n(n)\ntk\n\nand\n\nk(n) (t)\n\nm(n)\n\nas in (2.4.4)\u2013(2.4.5). Define\n\n(t \u2265 0).\n\n(2.4.35)\n\nTheorem 2.45 (Convergence of Poisson-cluster branching processes) Assume that\n(n)\n(n)\nL(X0 ) \u21d2 \u03c1 as n \u2192 \u221e for some probability law \u03c1 on M(E). Suppose that the constants \u03b5k\nfulfill (2.4.7). Assume that\nZ\n(i)\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, 1i = 1 + \u03b5\u03b2(x) + o(\u03b5),\nZ\n(ii)\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, 1i2 = \u03b5 2\u03b1(x) + o(\u03b5),\n(2.4.36)\nZ\n(iii) q\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, 1i2 1{h\u03c7,1i>\u03b4} = o(\u03b5)\nfor each \u03b4 > 0, and\n\nZ\n\nK\u03b5 (x, dy)f (y) = f (x) + \u03b5Af (x) + o(\u03b5)\n\n(2.4.37)\n\n\f65\n\n2.4. CONVERGENCE TO A TIME-HOMOGENEOUS PROCESS\n\nfor each f \u2208 D(A), uniformly in x as \u03b5 \u2192 0. Then L(Y (n) ) \u21d2 L(Y), where Y is the (A, \u03b1, \u03b2)superprocess with initial law \u03c1.\nHere \u21d2 denotes weak convergence of probability measures on DM(E) [0, \u221e).\n\nProof We apply Theorem 2.42 to the operator G, where we use the fact that if we view\nM1 (DM(E) [0, \u221e)) as a subspace of M1 (DM(E)\u221e [0, \u221e)) (note the compactification), equipped\nwith the topology of weak convergence, then the induced topology on M1 (DM(E) [0, \u221e)) is\nagain the topology of weak convergence.\nBy Proposition 2.44, solutions to the martingale problem for G are unique. Since Ff Fg =\nFf +g and D(A) is a linear space, the linear span of the domain of G is an algebra. Using the\nfact that D(A) is dense in C(E) we see that this algebra separates points. Therefore, we are\nleft with the task to check (2.4.8).\nDefine U\u03b5 : C+ (E) \u2192 C+ (E) by\nZ\n\u0001\nU\u03b5 f (x) := q\u03b5 (x) Q\u03b5 (x, d\u03c7) 1 \u2212 e \u2212h\u03c7, f i\n(x \u2208 E, f \u2208 C+ [0, 1], f > 0, \u03b5 > 0), (2.4.38)\n\nand define transition probabilities P\u03b5 (\u03bc, d\u03bd) on M(E)\u221e by P\u03b5 (\u221e, * ) := \u03b4\u221e and\nZ\nP\u03b5 (\u03bc, d\u03bd)e \u2212h\u03bd, f i = e \u2212h\u03bc, U\u03b5 f i .\n\n(2.4.39)\n\nWe will show that\n\nlim \u03b5\u22121 (U\u03b5 f \u2212 f ) \u2212 (Af + \u03b2f \u2212 \u03b1f 2 )\n\n\u221e\n\n\u03b5\u21920\n\n=0\n\nTogether with (2.4.39) this implies that\nZ\nP\u03b5 (\u03bc, d\u03bd)Ff (\u03bd) = Ff (\u03bc) + \u03b5GFf (\u03bc) + o(\u03b5)\n\n(f \u2208 D(A), f > 0).\n\n(2.4.40)\n\n(f \u2208 D(A), f > 0),\n\n(2.4.41)\n\nuniformly in \u03bc \u2208 M(E)\u221e as \u03b5 \u2192 0. Therefore, the result follows from Theorem 2.42.\nIt remains to prove (2.4.40). Set g(z) := 1 \u2212 z + 12 z 2 \u2212 e\u2212z (z \u2265 0) and write\nZ\n\u0001\n(2.4.42)\nU\u03b5 f (x) = q\u03b5 (x) Q\u03b5 (x, d\u03c7) h\u03c7, f i \u2212 12 h\u03c7, f i2 + g(h\u03c7, f i) .\nSince\n\ng(z) =\n\nZ\n\nz\n\ndy\n0\n\nZ\n\n0\n\ny\n\ndx\n\nZ\n\nx\n\ndt e\u2212t\n\n0\n\n(z \u2265 0),\n\nit is easy to see that g is nondecreasing on [0, \u221e) and (since 0 \u2264 e\u2212t \u2264 1 and\n0 \u2264 g(z) \u2264 12 z 2 \u2227 61 z 3\n\n(z \u2265 0).\n\n(2.4.43)\nRx\n0\n\ndt e\u2212t \u2264 1)\n\n(2.4.44)\n\nUsing these facts and (2.4.36) (ii) and (iii), we find that\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)g(h\u03c7, f i)\nZ\no\nnZ\n\u2264 kf k\u221e q\u03b5 (x)\nQ\u03b5 (x, d\u03c7)g(h\u03c7, 1i)1{h\u03c7,1i\u2264\u03b4} + Q\u03b5 (x, d\u03c7)g(h\u03c7, 1i)1{h\u03c7,1i>\u03b4}\nZ\nn Z\no\n\u2264 kf k\u221e q\u03b5 (x) 16 \u03b4 Q\u03b5 (x, d\u03c7)h\u03c7, 1i2 1{h\u03c7,1i\u2264\u03b4} + 12 Q\u03b5 (x, d\u03c7)h\u03c7, 1i2 1{h\u03c7,1i>\u03b4}\n\u0001\n= 16 \u03b4kf k\u221e \u03b5 2\u03b1(x) + o(\u03b5) + o(\u03b5).\n(2.4.45)\n\n\f66\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nSince this holds for any \u03b4 > 0, we conclude that\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)g(h\u03c7, f i) = o(\u03b5)\nuniformly in x as \u03b5 \u2192 0. By (2.4.36) (i) and (2.4.37),\nZ\nZ\n\u0010\n\u0011\u0010 Z\n\u0011\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f i = q\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, 1i\nK\u03b5 (x, dy)f (y)\n\u0001\n\u0001\n= 1 + \u03b5\u03b2(x) + o(\u03b5) f (x) + \u03b5Af (x) + o(\u03b5)\n\n(2.4.46)\n\n(2.4.47)\n\n= f (x) + \u03b5\u03b2(x)f (x) + \u03b5Af (x) + o(\u03b5).\n\nFinally, write\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f i2\nZ\n\u0001\n= q\u03b5 (x) Q\u03b5 (x, d\u03c7) h\u03c7, f (x)i2 + 2h\u03c7, f (x)ih\u03c7, f \u2212 f (x)i + h\u03c7, f \u2212 f (x)i2 .\n\n(2.4.48)\n\nThen, by (2.4.36) (ii),\n\nq\u03b5 (x)\nWe will prove that\n\nZ\n\n\u0001\nQ\u03b5 (x, d\u03c7)h\u03c7, f (x)i2 = f (x)2 \u03b5 2\u03b1(x) + o(\u03b5) .\n\nq\u03b5 (x)\n\nZ\n\nQ\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)i2 = o(\u03b5).\n\nThen, by H\u00f6lder's inequality, (2.4.36) (ii), and (2.4.50),\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)ih\u03c7, f (x)i\nZ\nZ\n\u00111/2\n\u00111/2 \u0010\n\u0010\n2\n2\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f (x)i\n\u2264 q\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)i\n\u00011/2\n\u2264 o(\u03b5)(2\u03b1(x)\u03b5 + o(\u03b5))\n= o(\u03b5).\n\nInserting (2.4.49), (2.4.50) and (2.4.51) into (2.4.48) we find that\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f i2 = \u03b5 2\u03b1(x)f (x)2 + o(\u03b5).\n\n(2.4.49)\n\n(2.4.50)\n\n(2.4.51)\n\n(2.4.52)\n\nInserting (2.4.46), (2.4.47) and (2.4.52) into (2.4.42), we arrive at (2.4.40). We still need to\nprove (2.4.50). To this aim, we estimate, using (2.4.47),\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)i2 1{h\u03c7,1i\u2264\u03b4}\nZ\n(2.4.53)\n\u2264 \u03b4kf \u2212 f (x)k\u221e q\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)i\n\u0001\n= \u03b4kf \u2212 f (x)k\u221e \u03b5Af (x) + o(\u03b5)\n\n\f2.4. CONVERGENCE TO A TIME-HOMOGENEOUS PROCESS\nand, using (2.4.36) (iii),\nZ\nq\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)i2 1{h\u03c7,1i>\u03b4}\nZ\n\u2264 kf \u2212 f (x)k\u221e q\u03b5 (x) Q\u03b5 (x, d\u03c7)h\u03c7, 1i2 1{h\u03c7,1i>\u03b4} = o(\u03b5).\n\n67\n\n(2.4.54)\n\nIt follows that\nq\u03b5 (x)\n\nZ\n\nQ\u03b5 (x, d\u03c7)h\u03c7, f \u2212 f (x)i2 \u2264 \u03b4\u03b5kf \u2212 f (x)k\u221e Af (x) + o(\u03b5)\n\n(2.4.55)\n\nfor any \u03b4 > 0. This implies (2.4.50) and completes the proof of (2.4.40).\n\n2.4.3\n\nApplication to the renormalization branching process\n\nProof of Theorem 2.19 (a) For any f0 , . . . , fk \u2208 C+ [0, 1] one has\n\u0002\n\u0003\nE e \u2212hX\u2212n , f0 i * * * e \u2212hX\u2212n+k , fk i\n\u0002\n\u0003\n= E e \u2212hX\u2212n , f0 i * * * e \u2212hX\u2212n+k\u22121 , fk\u22121 + U\u03b3n\u2212k fk i\n\u0002\n\u0003\n= * * * = E e \u2212hX\u2212n , gk i ,\n\n(2.4.56)\n\nwhere we define inductively\n\ng0 := fk\n\nand gm+1 := fk\u2212m\u22121 + U\u03b3n\u2212k+m gm .\n\n(2.4.57)\n\nBy the compactness of [0, 1] and Corollary 2.36, the map (\u03b3, f ) 7\u2192 U\u03b3 f from (0, \u221e) \u00d7 C+ [0, 1]\nto C+ [0, 1] (equipped with the supremumnorm) is continuous. Using this fact and (2.4.56) we\nfind that\n\u03b3\u2217\n\u03b3\u2217\n\u0003\n\u0002\n\u0002\n, fk i \u0003\n\u2212hY\u2212n+k\n.\nE e \u2212hX\u2212n , f0 i * * * e \u2212hX\u2212n+k , fk i \u2212\u2192 E e \u2212hY\u2212n , f0 i * * * e\nn\u2192\u221e\n\n(2.4.58)\n\nSince f1 , . . . , fk are arbitrary, (2.2.23) follows.\n\nProof of Theorem 2.19 (b) We apply Theorem 2.45 to the weight functions q\u03b3 and cluster\n\u22022\n(2) [0, 1], and\nmechanisms Q\u03b3 from (2.2.19) and to AWF = x(1\u2212x) \u2202x\n2 with domain D(AWF ) = C\n\u03b1 = \u03b2 = 1. It is well-known that AWF generates a Feller semigroup [EK86, Theorem 8.2.8].\nWe observe that\nZ\nZ\nZ \u03c4\u03b3\n\u0003\n\u0002\n\u0003\n\u0002\n\u03b3\n\u03b3\nf (yx (\u2212t)) = 2E[\u03c4\u03b3 ]E f (yx (0)) = \u03b3 \u0393\u03b3x (dy)f (y), (2.4.59)\nQ\u03b3 (x, d\u03c7)h\u03c7, f i = E 2\n0\n\nwhere\nthat\n\n\u0393\u03b3x\n\nis the equilibrium law of the process yx\u03b3 from Corollary 2.30. It follows from (2.3.24)\nZ\n(i)\n\u0393\u03b3x (dy)(y \u2212 x) = 0,\nZ\n\u03b3x(1 \u2212 x)\n(2.4.60)\n,\n(ii)\n\u0393\u03b3x (dy)(y \u2212 x)2 =\n1+\u03b3\nZ\n(iii)\n\u0393\u03b3x (dy)(y \u2212 x)4 = O(\u03b3 2 ),\n\n\f68\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nuniformly in x as \u03b3 \u2192 0. Therefore, for any \u03b4 > 0,\nZ\n(i)\n\u0393\u03b3x (dy)(y \u2212 x) = 0,\nZ\n(ii)\n\u0393\u03b3x (dy)(y \u2212 x)2 = \u03b3x(1 \u2212 x) + o(\u03b3),\nZ\n(iii)\n\u0393\u03b3x (dy)1{|y\u2212x|>\u03b4} = o(\u03b3),\nuniformly in x as \u03b3 \u2192 0. Consequently, a Taylor expansion of f around x yields\nZ\n\u22022\n\u0393\u03b3x (dy)f (x) = f (x) + \u03b3 21 x(1 \u2212 x) \u2202x\n(f \u2208 C (2) [0, 1]),\n2 f (x) + o(\u03b3)\n\n(2.4.61)\n\n(2.4.62)\n\nuniformly in x as \u03b3 \u2192 0. (For details, in particular the uniformity in x, see for example\n[Swa99, Proposition B.1.1].) This shows that condition (2.4.37) is satisfied. Moreover,\nZ\nQ\u03b3 (x, d\u03c7)h\u03c7, 1i = E[2\u03c4\u03b3 ] = \u03b3,\nZ\nZ \u221e\n2\n2\nz 2 \u03b31 e\u2212z/\u03b3 dz = 2\u03b3 2 ,\nQ\u03b3 (x, d\u03c7)h\u03c7, 1i = E[(2\u03c4\u03b3 ) ] =\n(2.4.63)\nZ\nZ0 \u221e\nz 3 \u03b31 e\u2212z/\u03b3 dz = 6\u03b3 3 ,\nQ\u03b3 (x, d\u03c7)h\u03c7, 1i3 = E[(2\u03c4\u03b3 )3 ] =\n0\n\nwhich, using the fact that q\u03b3 = ( \u03b31 + 1), gives\nZ\nq\u03b3 Q\u03b3 (x, d\u03c7)h\u03c7, 1i = 1 + \u03b3,\nZ\nq\u03b3 Q\u03b3 (x, d\u03c7)h\u03c7, 1i2 = 2\u03b3 + o(\u03b3),\nZ\nq\u03b3 Q\u03b3 (x, d\u03c7)h\u03c7, 1i3 = o(\u03b3).\nThis shows that (2.4.36) is fulfilled. In particular,\nZ\nZ\nq\u03b3 Q\u03b3 (x, d\u03c7)h\u03c7, 1i2 1{h\u03c7,1i>\u03b4} \u2264 \u03b4\u22121 q\u03b3 Q\u03b3 (x, d\u03c7)h\u03c7, 1i3 = o(\u03b3)\n\n(2.4.64)\n\n(2.4.65)\n\nfor all \u03b4 > 0.\n\n2.5\n2.5.1\n\nThe super-Wright-Fisher diffusion: introduction\nSuperprocesses and binary splitting particle systems\n\nLet E be a compact metrizable space, G the generator of a Feller process \u03be = (\u03bet )t\u22650 in E, and\n\u03b1 \u2208 C+ (E), \u03b2 \u2208 C(E). Then, for each f \u2208 B+ (E), the semilinear Cauchy problem in B+ (E)\n\u001a \u2202\n2\n(t \u2265 0),\n\u2202t ut = Gut + \u03b2ut \u2212 \u03b1ut\n(2.5.1)\nu0 = f,\n\n\f2.5. THE SUPER-WRIGHT-FISHER DIFFUSION: INTRODUCTION\n\n69\n\nhas a unique mild solution ut =: Ut f . Moreover, there exists a unique (in law) Markov process\nY with continuous sample paths in the space M(E) of finite measures on E, defined by its\nLaplace functionals\nE \u03bc [e \u2212hYt , f i ] = e \u2212h\u03bc, Ut f i\n\n(t \u2265 0, \u03bc \u2208 M(E), f \u2208 B+ (E)).\n\n(2.5.2)\n\nThe process Y is called the superprocess in E with underlying motion generator G, activity \u03b1\nand growth parameter \u03b2 (the last two terms are our terminology), or in short the (G, \u03b1, \u03b2)superprocess. The operators (Ut )t\u22650 = U = U (G, \u03b1, \u03b2) form a semigroup, called the log-Laplace\nsemigroup of Y.\nThe process Y can be constructed in several ways and is nowadays standard. We outlined\none such construction in Section 2.4.2; see also, e.g., [Fit88, Fit91, Fit92]. We can think of Y\nas describing a population where mass flows with generator G, and during a time interval dt a\nbit of mass dm at position x produces offspring with mean (1 + \u03b2(x)dt)dm and finite variance\n2\u03b1(x)dt dm. For basic facts on superprocesses we refer to [Daw93, Eth00, Dyn02].\nSimilarly, when G is (again) the generator of a Feller process on a compact metrizable\nspace E and \u03b1 \u2208 C+ (E), then, for any f \u2208 B[0,1] (E), the semilinear Cauchy problem\n\u001a\n\n\u2202\n\u2202t ut = Gut\nu0 = f,\n\n+ \u03b1ut (1 \u2212 ut )\n\n(t \u2265 0),\n\n(2.5.3)\n\nhas a unique mild solution ut =: Ut f in B[0,1] (E). Moreover, there exists a unique Markov\nprocess Y with cadlag sample paths in the space N (E) of finite counting measures on E,\ndefined by its generating functionals\n\u0002\n\u0003\nE \u03bd (1 \u2212 f )Yt = (1 \u2212 Ut f )\u03bd\n\n(t \u2265 0, \u03bd \u2208 N (E), f \u2208 B[0,1] (E)).\n\n(2.5.4)\n\nP\nQ\nHere if \u03bd = ni=1 \u03b4xi is a finite counting measure and g \u2208 B[0,1] (E), then g\u03bd := ni=1 g(xi ).\nWe call Y the binary splitting particle system in E with underlying motion generator G and\nsplitting rate \u03b1, or in short the (G, \u03b1)-bin-split-process. The semigroup (Ut )t\u22650 = U = U (G, \u03b1)\nis called the generating semigroup of Y . The process Y consists of particles that independently\nmove according to the generator G, and additionally split with local rate \u03b1 into two new\nparticles, created at the position of the old one.\n\n2.5.2\n\nStatement of the problem and motivation\n\nLet A be the closure in C[0, 1] (equipped with the supremum norm) of the operator\n2\n\n\u2202\nA = 21 x(1 \u2212 x) \u2202x\n2.\n\n(2.5.5)\n\nIt is well-known that A is the generator of a Feller process \u03be on [0, 1], called the (standard)\nWright-Fisher diffusion, see [EK86, Theorem 8.2.8]. We are interested in mild solutions to\nthe Cauchy equation\n\u001a \u2202\n(t \u2265 0),\n\u2202t ut = Aut + \u03b1ut (1 \u2212 ut )\n(2.5.6)\nu0 = f,\n\n\f70\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\n1\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\nFigure 2.3: A system of binary splitting Wright-Fisher diffusions with splitting rate \u03b1 = 1.\nwhere \u03b1 > 0 is a constant. We wish to find all fixed points of (2.5.6) and determine their\ndomains of attraction.\nFor f \u2208 B+ [0, 1], the mild solution of (2.5.6) is given by ut = Ut f , where U = U (A, \u03b1, \u03b1)\nis the log-Laplace semigroup of a superprocess Y in [0, 1] with underlying motion generator\nG = A, and activity and growth parameter both equal to \u03b1. We call Y the super-Wright-Fisher\ndiffusion (with activity and growth parameter \u03b1 > 0).4\nOur main interest is in the case \u03b1 = 1. In this case, we have proved in Theorem 2.19 (b)\nabove that a suitably rescaled version of the renormalization branching process converges to\nY. In particular, we will need Proposition 2.47 below for \u03b1 = 1 in our proof of Lemmas 2.24\nand 2.25 (see Propositions 2.82 (b) and 2.83 (b) below). We will generalize a bit and treat\ngeneral \u03b1 > 0. This will not be much more work and will give a more complete picture. In\nparticular, we will see that the case \u03b1 = 1 is a critical case, since Y dies out on the interior if\nand only if \u03b1 \u2264 1, and the weighted process Y v from (2.5.19) is critical for \u03b1 = 1.\nIf f \u2208 B[0,1] [0, 1], then the solution of (2.5.6) is also given by ut = Ut f , where U = U (A, \u03b1)\nis the generating semigroup of a system Y of binary splitting Wright-Fisher diffusions, with\nsplitting rate \u03b1. The process Y can be obtained from Y by Poissonization with the constant\nfunction 1 (compare Proposition 2.21). In fact, Y is the trimmed tree of Y, i.e., the particles\nin Y correspond to those infinitesimal bits of mass in Y, that have offspring at all later times.\nFor a precise statement of this fact we refer the reader to [FS04].\nSee Figure 2.3 for a simulation of Y for \u03b1 = 1. The points 0, 1 are accessible traps for the\nWright-Fisher diffusion, and therefore a natural question is whether eventually all particles of\nY end up in 0 or 1. This question will be answered for all \u03b1 > 0 in Proposition 2.48 below.\nBinary splitting Wright-Fisher diffusions have been studied before in [GKW01]. In particular, the authors of that paper investigated the function p, which is defined in terms of the\nsystem Y of binary splitting Wright-Fisher diffusions with splitting rate \u03b1 = 1, as\np(x) := lim P \u03b4x [Yt ({1}) > 0] = lim P \u03b4x [Yt ((0, 1]) > 0]\nt\u2192\u221e\n\nt\u2192\u221e\n\n(x \u2208 [0, 1]).\n\n(2.5.7)\n\nIn order to show that the two expressions for p in (2.5.7) are identical, in [GKW01] the authors\n4\nMore generally, if Z is the (A, \u03b1\u2032 , \u03b1)-superprocess, with \u03b1\u2032 , \u03b1 > 0 constants, then\ntherefore this more general case can be reduced to the case \u03b1\u2032 = \u03b1.\n\n\u03b1\nZ\n\u03b1\u2032\n\n= Y in law, and\n\n\f71\n\n2.5. THE SUPER-WRIGHT-FISHER DIFFUSION: INTRODUCTION\n\nnote that both expressions correspond to a fixed point p of the generating semigroup U (A, 1)\nwith boundary conditions p(0) = 0 and p(1) = 1. Assuming that p is sufficiently smooth, the\nfixed point property means that p solves the equation\n1\n2 x(1\n\n2\n\n\u2202\n\u2212 x) \u2202x\n2 p(x) + \u03b1p(x)(1 \u2212 p(x)) = 0\n\n(x \u2208 [0, 1]).\n\n(2.5.8)\n\nThough stated only for the case \u03b1 = 1, the proof of Lemma 1.13 in [GKW01] shows that\nequation (2.5.8) has at most one solution with boundary conditions p(0) = 0 and p(1) = 1\nwhen \u03b1 < z02 /8 \u223c\n= 1.836, where z0 is the smallest non-trivial zero of the Bessel function of the\nfirst kind with parameter 1. The authors do not answer the question whether solutions to\n(2.5.8) with these boundary condions are unique for \u03b1 \u2265 z02 /8, or what solutions may exist for\nother boundary conditions. Proposition 2.47 below settles these questions. We show moreover\nthat all fixed points of U (A, \u03b1) are smooth, a fact tacitly assumed in [GKW01].\n\n2.5.3\n\nResults\n\nThe following theorem is our main result. We write 'eventually' behind an event, depending\non t, to denote the existence of a (random) time \u03c4 < \u221e such that the event holds for all t \u2265 \u03c4 .\nTheorem 2.46 (Long-time behavior of the super-Wright-Fisher diffusion) Let Y\nbe the super-Wright-Fisher diffusion with activity and growth parameter equal to the same\nconstant \u03b1 > 0, started in \u03bc \u2208 M[0, 1]. Set\nv(x) := 6x(1 \u2212 x)\n\n(x \u2208 [0, 1]).\n\n(2.5.9)\n\nThen there exist nonnegative random variables W0 , W1 , W(0,1) (depending on \u03bc) such that\n(i)\n(ii)\n\nlim e\u2212\u03b1t hYt , 1{r} i = Wr\n\na.s.\n\nt\u2192\u221e\n\nlim e\u2212(\u03b1\u22121)t hYt , vi = W(0,1)\n\n(r = 0, 1),\n(2.5.10)\n\na.s.\n\nt\u2192\u221e\n\nand\n(i) {Wr = 0} = {Yt ({r}) = 0 eventually}\n\na.s.\n\n(ii) {W(0,1) = 0} = {Yt ((0, 1)) = 0 eventually}\n\n(r = 0, 1),\n\na.s.\n\n(2.5.11)\n\nMoreover,\n{W(0,1) > 0} \u2282 {W0 > 0} \u2229 {W1 > 0}\n\nIf \u03b1 \u2264 1, then\n\nW(0,1) = 0\n\na.s.\n\na.s.\n\n(2.5.12)\n(2.5.13)\n\nIf \u03b1 > 1, then W(0,1) satisfies\nE \u03bc (W(0,1) ) = h\u03bc, vi\nas well as\n\nand\n\n\u03b1\nh\u03bc, vi\nVar\u03bc (W(0,1) ) \u2264 3 \u03b1\u22121\n\nh\ni\n2\n=0\nlim E \u03bc e\u2212(\u03b1\u22121)t hYt , vf i \u2212 W(0,1) hl, vf i\n\nt\u2192\u221e\n\nwhere l denotes the Lebesgue measure on (0, 1).\n\n\u2200f \u2208 B[0, 1],\n\n(2.5.14)\n(2.5.15)\n\n\f72\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nExcept for the statement about smoothness (of the functions p0,0 , . . . , p1,1 below) and the uniformity of the limit in (2.5.16), the following result about the log-Laplace semigroup U (A, \u03b1, \u03b1)\nis an immediate consequence of Theorem 2.46.\nProposition 2.47 (Long-time behavior of U (A, \u03b1, \u03b1)) Let Y, W0 , W1 , W(0,1) be as in\nTheorem 2.46 and let U = U (A, \u03b1, \u03b1). Then, for all f \u2208 B+ [0, 1], uniformly on [0, 1],\n\uf8f1\n0\nif f (0) = f (1) = hl, f i = 0,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 p0,0 if f (0) = f (1) = 0, hl, f i > 0,\nlim Ut f =\np1,0 if f (0) > 0, f (1) = 0,\n(2.5.16)\nt\u2192\u221e\n\uf8f4\n\uf8f4\np\nif f (0) = 0, f (1) > 0,\n\uf8f4\n\uf8f4\n\uf8f3 0,1\np1,1 if f (0) > 0, f (1) > 0,\nwhere the constant function 0 and\n\np0,0 (x) := \u2212 log P \u03b4x [W(0,1) = 0],\np1,0 (x) := \u2212 log P \u03b4x [W0 = 0] = P \u03b4x [W0 = W(0,1) = 0],\np0,1 (x) := \u2212 log P \u03b4x [W1 = 0] = P \u03b4x [W1 = W(0,1) = 0],\np1,1 (x) := \u2212 log P \u03b4x [W0 = W1 = 0] = P \u03b4x [W0 = W1 = W(0,1) = 0]\n\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8fd\n\uf8f4\n\uf8f4\n\uf8fe\n\n(x \u2208 [0, 1]).\n\n(2.5.17)\nare all fixed points of the log-Laplace semigroup U (A, \u03b1, \u03b1). Here p0,0 = 0 if \u03b1 \u2264 1, and\np0,0 > 0 on (0, 1) if \u03b1 > 1. The functions pl,r (l, r \u2208 {0, 1} satisfy pl,r (0) = l and pl,r (1) = r,\nare twice continuously differentiable on [0, 1], and solve (2.5.8).\nSince conversely, every nonnegative twice continuously differentiable solution to (2.5.8) is a\nfixed point of U (A, \u03b1, \u03b1), we see that (2.5.8) has precisely four solutions when \u03b1 \u2264 1 and\nprecisely five solutions when \u03b1 > 1. The functions p0,0 , . . . , p1,1 are [0, 1]-valued and therefore\nfixed points of the generating semigroup U (A, \u03b1) as well. Our final result describes p0,0 , . . . , p1,1\nin terms of the system Y of binary splitting Wright-Fisher diffusions with splitting rate \u03b1.\nProposition 2.48 (Fixed points of U (A, \u03b1)) The functions p0,0 , . . . , p1,1 in (2.5.17) satisfy\n\uf8fc\np0,0 (x) = P \u03b4x [Yt ((0, 1)) > 0 eventually],\n\uf8f4\n\uf8f4\n\uf8fd\np1,0 (x) = P \u03b4x [Yt ({0}) > 0 eventually] = P \u03b4x [Yt ([0, 1)) > 0 eventually],\n(x \u2208 [0, 1]).\np0,1 (x) = P \u03b4x [Yt ({1}) > 0 eventually] = P \u03b4x [Yt ((0, 1]) > 0 eventually], \uf8f4\n\uf8f4\n\uf8fe\np1,1 (x) = 1\n(2.5.18)\nSee Figure 2.4 for a plot of the functions p0,0 and p0,1 (for \u03b1 = 2).\n\n2.5.4\n\nMethods and related work\n\nAn essential tool in the proof of Theorem 2.46 is the weighted super-Wright-Fisher diffusion\nY v , defined as\nYtv (dx) := v(x)Yt (dx)\n(t \u2265 0),\n(2.5.19)\nwhere v is defined in (2.5.9). Note that v is an eigenfunction of the operator A, with eigenvalue\n\u22121. For convenience, we have normalized v such that hl, vi = 1.\n\n\f73\n\n2.5. THE SUPER-WRIGHT-FISHER DIFFUSION: INTRODUCTION\n1\n\n1\n\np0,0\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0\n\n0\n\n0.2\n\np0,1\n\n0.8\n\n0.4\n\n0.6\n\n0.8\n\n0\n\n1\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n2\n\n\u2202\nFigure 2.4: Two solutions to the differential equation 12 x(1 \u2212 x) \u2202x\n2 p(x) + 2p(x)(1 \u2212 p(x)) = 0.\n\nWhen a superprocess is weighted with a sufficiently smooth density, the result is a new\nsuperprocess, with a new activity and growth parameter and a new underlying motion, which\nis a compensated h-transform of the old one. For the case that the underlying motion is a\nlocally uniformly elliptic diffusion on a open domain D \u2282 Rd , weighted superprocesses were\ndeveloped by [EP99]. In our case, where uniform ellepticity does not hold, the following can\nbe proved without too much effort.\nLemma 2.49 (Weighted super-Wright-Fisher diffusion) Let Y be the super-WrightFisher diffusion with \u03b1 > 0 and let Y v be defined as in (2.5.19). Then Y v is the (Av , \u03b1v, \u03b1\u22121)superprocess in [0, 1], where Av is the closure of the operator\n2\n\n\u2202\n\u2202\n1\nAv := 12 x(1 \u2212 x) \u2202x\n2 + 2( 2 \u2212 x) \u2202x .\n\n(2.5.20)\n\nIndeed, Av generates a Feller process \u03be v in [0, 1], see [EK86, Theorem 8.2.1]. The diffusion \u03be v is\na compensated h-transform (with h = v) of the Wright-Fisher diffusion \u03be. This compensated vtransformed Wright-Fisher diffusion \u03be v is ergodic with invariant law vl (Lemma 2.65 below).\nFor \u03b1 > 1, the (Av , \u03b1v, \u03b1 \u2212 1)-superprocess is supercritical, and in this case one expects\ne\u2212(\u03b1\u22121)t Ytv to converge, in some way, to a random multiple of vl. This is the idea behind\nformula (2.5.15).\nRecently, [ET02], have shown for a certain class of superdiffusions Y in Rd with underlying\nmotion generator G, growth parameter \u03b2 and activity \u03b1, the convergence in law\ne\u2212\u03bbc t hY, gi \u21d2 W h\u03c1, gi\n\nas t \u2192 \u221e,\n\n(2.5.21)\n\nwhere W is a nonnegative random variable, \u03bbc is the generalized principal eigenvalue of G + \u03b2\n(which is assumed to be positive), \u03c1 is a measure on Rd , defined in terms of G + \u03b2, and g is\nany compactly supported continuous function on Rd . In their work, the weighted superprocess\nYt\u03c6 (dx) := \u03c6(x)Yt (dx) plays a central role, where \u03c6 is the principal eigenfunction of the\noperator G + \u03b2. Their dynamical system methods are based on a result on the existence of\nan invariant curve of the log-Laplace semigroup of their superprocess. Using this invariant\n\n\f74\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\ncurve, they give an expression for the Laplace-transform of the law of the random variable\nW in (2.5.21). Their results are in line with our results for the super-Wright-Fisher diffusion\nrestricted to (0, 1), where in our case \u03bbc = \u03b1 \u2212 1 and \u03c6 = v. However, their methods use in\nan essential way the fact that their underlying space is Rd (and not an open subset of Rd , like\n(0, 1)), and therefore their results are not applicable to our situation. It is stated as an open\nproblem by [ET02] whether the random variable W in (2.5.21) in general satisfies P [W = 0] =\nP [Yt = 0 eventually]. For a recent result on local extinction versus local exponential growth\nof superdiffusions on open domains D \u2282 Rd , we refer to [EK04].\nIn our set-up, we can prove that {W(0,1) = 0} = {Yt ((0, 1)) = 0 eventually} because of the\nfollowing property of the weighted super-Wright-Fisher diffusion Y v .\nLemma 2.50 (Finite ancestry) For all \u03b1 > 0, the weighted super-Wright-Fisher diffusion\nY v satisfies\n\u2200t > 0.\n(2.5.22)\ninf P \u03b4x [Ytv = 0] > 0\nx\u2208[0,1]\n\nFormula (2.5.22) has been called the finite ancestry property (of Y v ); for a justification of this\nterminology we refer the reader to [FS04]. A sufficient condition for a superprocess to enjoy\nthe finite ancestry property is that the activity be bounded away from zero (see Lemma 2.55\nbelow). This condition is not necessary. In fact, the activity of Y v is \u03b1v, which is zero on {0, 1}.\nOur proof of Lemma 2.50 is quite long. It is not clear whether the weighted superprocesses\nY \u03c6 occurring in [ET02] will in general satisfy a formula of the form (2.5.22). Therefore, we\nmention as an open problem:\nHow to check, in a practical way, whether a given superprocess has the finite\nancestry property (2.5.22)?\nAnother problem that is left open in here, is whether the L2 -convergence in (2.5.15) can be\nreplaced by almost sure convergence. In fact, we suspect that (2.5.15) can be strengthened to\nlim e\u2212(\u03b1\u22121)t hYt , 1(0,1) f i = W(0,1) hl, f i \u2200f \u2208 B[0, 1]\n\nt\u2192\u221e\n\na.s.,\n\n(2.5.23)\n\nbut we do not have a proof.\nThe following sections are organized as follows. Sections 2.6.1 and 2.6.2 contain some general\nfacts about (G, \u03b1, \u03b2)-superprocesses and on (G, \u03b1, \u03b2)-superprocesses enjoying the finite ancestry property, respectively. After some preparatory work in Sections 2.6.3 and 2.6.4, we prove\nLemmas 2.49 and 2.50 in Section 2.6.5. In Sections 2.7.1 and 2.7.2 we derive some properties\nof the weighted super-Wright-Fisher diffusion Y v , culminating in the proof of Theorem 2.46\nin Section 2.7.3. Finally, Sections 2.7.4\u20132.7.5 contain the proofs of Propositions 2.47 and 2.48.\n\n2.6\n2.6.1\n\nThe super-Wright-Fisher diffusion: preparatory results\nSome general facts about log-Laplace semigroups\n\nLet E be a compact metrizable space and let C(E) be the space of continuous real functions\non E, equipped with the supremum norm k * k\u221e . Let \u03be = (\u03bet )t\u22650 be a Feller process in E with\n\n\f2.6. THE SUPER-WRIGHT-FISHER DIFFUSION: PREPARATORY RESULTS\n\n75\n\nsemigroup St f (x) := E x [f (\u03bet )] (t \u2265 0, x \u2208 E, f \u2208 B(E)). By definition, the (full) generator\nG of \u03be is the linear operator on C(E) given by Gf := limt\u21920 t\u22121 (St f \u2212 f ) where the domain\nD(G) of G is the space of all functions f \u2208 C(E) for which the limit exists in C(E).\nLet \u03b1 \u2208 C+ (E), \u03b2 \u2208 C(E), and f \u2208 C+ (E). By definition, we call u a classical solution\nof the Cauchy problem (2.5.1) if u : [0, \u221e) \u2192 C+ (E) \u2229 D(G) is continuously differentiable in\n\u2202\nut := lims\u2192t s\u22121 (ut+s \u2212 ut ) exists in C(E) for all t \u2265 0 and the map\nC(E) (i.e., the derivative \u2202t\n\u2202\n\u2202t u : [0, \u221e) \u2192 C(E) is continuous) and (2.5.1) holds. A measurable function u : [0, \u221e) \u00d7 E \u2192\n[0, \u221e) is called a mild solution of (2.5.1) if u is bounded on finite time intervals and solves\n(pointwise)\nZ t\n\u0001\nSt\u2212s \u03b2us \u2212 \u03b1u2s ds\nut = St f +\n(t \u2265 0).\n(2.6.1)\n0\n\nEquation (2.5.1) has a unique mild solution for all f \u2208 B+ (E), see [Fit88] and this solution\nis a classical solution if f \u2208 C+ (E) \u2229 D(G). (See [Paz83], Theorems 6.1.4 and 6.1.5. The fact\nthat f is nonnegative and \u03b1 \u2265 0 implies that solutions cannot explode. Our definition of a\nclassical solution is slightly stronger than the one used in [Paz83], since we require u to be\ncontinuously differentiable on [0, \u221e) instead of (0, \u221e). However, the proof of Theorem 6.1.5\nin [Paz83] shows that u is continuously differentiable on [0, \u221e) if f \u2208 C+ (E) \u2229 D(G).)\nThe (G, \u03b1, \u03b2)-superprocess Y is defined as the unique strong Markov process with continuous sample paths in M(E), equipped with the topology of weak convergence, such that\n(2.5.2) holds for all f \u2208 B+ (E); see [Fit88, Fit91, Fit92].\nNote the following elementary properties of the log-Laplace semigroup U (G, \u03b1, \u03b2). Here,\nwe write bp-limn\u2192\u221e fn = f if f is the bounded pointwise limit of the sequence (fn )n\u22650 .\nLemma 2.51 (Continuity and monotonicity of log-Laplace semigroups) For each\nt \u2265 0, Ut : C+ (E) \u2192 C+ (E) is continuous. Moreover, if bp-limn\u2192\u221e fn = f for some sequence\nfn \u2208 B+ (E), then bp-limn\u2192\u221e Ut fn = Ut f . Finally, f \u2264 g implies Ut f \u2264 Ut g (f, g \u2208 B+ (E)).\nProof The continuity of Ut : C+ (E) \u2192 C+ (E) follows from [Paz83, Theorem 6.1.2] and the\nfact that solutions do not explode. Continuity of Ut with respect to bounded pointwise limits\nis obvious from (2.5.2), and the same formula also makes clear that Ut : B+ (E) \u2192 B+ (E) is\nmonotone.\nRecall that (2.5.1) has a classical solution for f \u2208 C+ (E) \u2229 D(G). Because of the following,\nfor many purposes it suffices to work with classical solutions.\nLemma 2.52 (Closure and bp-closure) For t \u2265 0 fixed, {(f, Ut f ) : f \u2208 C+ (E)} is the\nclosure in C(E) of {(f, Ut f ) : f \u2208 C+ (E) \u2229 D(G)}, and {(f, Ut f ) : f \u2208 B+ (E)} is the bpclosure of {(f, Ut f ) : f \u2208 C+ (E)}.\nHere, the bp-closure of a set B is the smallest set B such that B \u2282 B and f \u2208 B whenever\nbp-limn\u2192\u221e fn = f for some sequence fn \u2208 B.\nProof of Lemma 2.52 It follows from the Hille-Yosida Theorem, see [EK86, Theorem 1.2.6]\nthat D(G) is dense in C(E). Since D(G) is a linear space and 1 \u2208 D(G), it is not hard to see\nthat C+ (E) \u2229 D(G) is dense in C+ (E). The fact that {(f, Ut f ) : f \u2208 C+ (E)} is the closure in\nC(E) of {(f, Ut f ) : f \u2208 C+ (E)\u2229D(G)} now follows from the continuity of Ut : C+ (E) \u2192 C+ (E).\n\n\f76\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nIn [EK86, Proposition 3.4.2], it is proved that C(E) is bp-dense in B(E); the argument can\neasily be adapted to show that C+ (E) is bp-dense in B+ (E). Therefore Lemma 2.52 follows\nfrom the continuity of Ut with respect to bounded pointwise limits.\n\nUt f may be defined unambiguously such that (2.5.2) holds also for functions f that are not\nbounded, or even infinite.\nLemma 2.53 (Extension of U to unbounded functions) For each measurable f : E \u2192\n[0, \u221e] and t \u2265 0 there exists a unique measurable Ut f : E \u2192 [0, \u221e] such that (2.5.2) holds for\nall \u03bc \u2208 M(E), where we put e\u2212\u221e := 0.\n\nProof Define Ut f by Ut f (x) := \u2212 log E \u03b4x [e\u2212hYt ,f i ] where log 0 := \u2212\u221e. To see that (2.5.2)\nholds again for all \u03bc \u2208 M(E), choose B+ (E) \u220b fn \u2191 f , note that Ut fn \u2191 Ut f , and take the\nlimit in (2.5.2).\n\nWe will often need the following comparison result, compare [Smo83, Theorem 10.1].\nLemma 2.54 (Sub- and supersolutions) Assume that T > 0 and that \u0169 : [0, T ] \u2192 C+ (E)\u2229\nD(G) is continuously differentiable in C(E) and solves\n\u2202\n\u2202t \u0169t\n\n\u2264 G\u0169t + \u03b2 \u0169t \u2212 \u03b1\u01692t\n\n(t \u2208 [0, T ]).\n\n(2.6.2)\n\nThen \u0169T \u2264 UT \u01690 . The same holds with both inequality signs reversed.\nProof Let g : [0, T ] \u2192 C+ (E) be defined by the formula\n\u2202\n\u2202t \u0169t\n\n= G\u0169t + \u03b2 \u0169t \u2212 \u03b1\u01692t \u2212 gt\n\n(t \u2208 [0, T ]).\n\nSet ut := Ut \u01690 . Then u : [0, T ] \u2192 C+ (E) is the classical solution of\n\u001a \u2202\n2\n(t \u2208 [0, T ]),\n\u2202t ut = Gut + \u03b2ut \u2212 \u03b1ut\nu0 = \u01690 .\nPut \u2206t := ut \u2212 \u0169t (t \u2208 [0, T ]). Then \u2206 solves\n\u001a \u2202\n\u2202t \u2206t = G\u2206t + \u03b2\u2206t \u2212 \u03b1 (ut + \u0169t )\u2206t + gt\n\u22060 = 0.\n\n(t \u2208 [0, T ]),\n\n(2.6.3)\n\n(2.6.4)\n\n(2.6.5)\n\nThe generator G satisfies the positive maximum principle, see [EK86, Theorem 4.2.2] and\ntherefore (2.6.5) implies that \u2206 \u2265 0. For imagine that \u2206t (x) < 0 somewhere on [0, T ] \u00d7 E.\n \u0303 t := eRt \u2206t solves\nLet R be a constant such that \u03b2 \u2212 \u03b1 (ut + \u0169t ) + R < 0. Then \u2206\n( \u2202\nRt\n \u0303\n \u0303\n \u0303\n(t \u2208 [0, T ]),\n\u2202t \u2206t = G\u2206t + {\u03b2 \u2212 \u03b1 (ut + \u0169t ) + R}\u2206t + gt e\n(2.6.6)\n \u0303 0 = 0.\n\u2206\n \u0303 t (x) < 0 for some (t, x) \u2208 [0, T ] \u00d7 E, then \u2206\n \u0303 must assume a negative minimum over\nIf \u2206\n \u0303 0 = 0. But in such a point one would\n[0, T ] \u00d7 E in some point (s, y), with s > 0 since \u2206\n\u2202  \u0303\n \u0303\n \u0303 s (y) + gs (y)eRs > 0, in\nhave \u2202s \u2206s (y) \u2264 0 while G\u2206s (y) + {\u03b2(y) \u2212 \u03b1(y) (us (y) + \u0169s (y)) + R}\u2206\ncontradiction with (2.6.6).\nThe same argument applies when both inequality signs are reversed.\nLemma 2.54 has the following application.\n\n\f2.6. THE SUPER-WRIGHT-FISHER DIFFUSION: PREPARATORY RESULTS\n\n77\n\nLemma 2.55 (Bounds on log-Laplace semigroups) Let U = U (G, \u03b1, \u03b2), U = U (G, \u03b1, \u03b2),\nwhere \u03b1, \u03b1 \u2208 C+ (E) and \u03b2, \u03b2 \u2208 C(E) satisfy\n\u03b1\u2265\u03b1\n\nand\n\n\u03b2 \u2264 \u03b2.\n\n(2.6.7)\n\nThen\nUt f \u2264 U t f for all measurable f : E \u2192 [0, \u221e]\n\n(t \u2265 0).\n\n(2.6.8)\n\nIn particular, if \u03b1, \u03b2 are constants and \u03b1 > 0, then, for t > 0,\nU t\u221e =\n\n\u03b2\n\u03b1 (1 \u2212\n\ne\u2212\u03b2t )\n\n(\u03b2 6= 0)\n\nand\n\nU t\u221e =\n\n1\n\u03b1t\n\n(\u03b2 = 0),\n\n(2.6.9)\n\nand (2.6.8) with f = \u221e gives\nP \u03bc [Yt = 0] \u2265 e \u2212h\u03bc, U t \u221ei\n\n(t > 0).\n\n(2.6.10)\n\nProof For each f \u2208 C+ (E) \u2229 D(G), the function \u0169t := Ut f solves\n\u2202\n\u2202t \u0169t\n\n= G\u0169t + \u03b2 \u0169t \u2212 \u03b1\u01692t \u2264 G\u0169t + \u03b2 \u0169t \u2212 \u03b1\u01692t\n\n(t \u2265 0),\n\n(2.6.11)\n\nand therefore Ut f = \u0169t \u2264 U t f by Lemma 2.54. Using Lemmas 2.52 and 2.53 this is easily\nextended to measurable f : E \u2192 [0, \u221e], giving (2.6.8). Define u by the right-hand side of the\n\u2202\nut = \u03b2ut \u2212 \u03b1u2t (t > 0) with\nequations in (2.6.9). Then it is easy to check that u solves \u2202t\nlimt\u21920 ut = \u221e, and therefore (2.6.10) follows from the fact that\nP \u03bc [Yt = 0] = E \u03bc [e\u2212hYt ,\u221ei ] = e \u2212h\u03bc, Ut \u221ei\n\n(t \u2265 0, \u03bc \u2208 M(E)),\n\n(2.6.12)\n\nand a little approximation argument.\n\n2.6.2\n\nSome consequences of the finite ancestry property\n\nLet Y be a (G, \u03b1, \u03b2)-superprocess as in the last section. In line with Lemma 2.50, we say that\nY has the finite ancestry property if\ninf P \u03b4x [Yt = 0] > 0\n\nx\u2208E\n\n(t > 0).\n\n(2.6.13)\n\nNote that by (2.6.12), property (2.6.13) is equivalent to kUt \u221ek\u221e < \u221e (t > 0). In this section\nwe prove three simple consequences of the finite ancestry property.\nLemma 2.56 (Extinction versus unbounded growth) Assume that the (G, \u03b1, \u03b2)-superprocess Y has the finite ancestry property. Then, for any \u03bc \u2208 M(E),\n\u0002\nP \u03bc Yt = 0 eventually or\n\n\u0003\nlim hYt , 1i = \u221e = 1.\n\nt\u2192\u221e\n\n(2.6.14)\n\n\f78\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nProof We use a general fact about tail events of strong Markov processes, the statement and\nproof of which can be found in Section 2.6.6. Consider the tail event A := {Yt = 0 eventually}.\nBy Lemma 2.64 below,\na.s.\n(2.6.15)\nlim P Yt (A) = 1A\nt\u2192\u221e\n\nFor any fixed T > 0, by (2.6.12),\nP \u03bc (A) \u2265 P \u03bc [YT = 0] = e \u2212h\u03bc, UT \u221ei \u2265 e \u2212h\u03bc, 1ikUT \u221ek\u221e\n\n(\u03bc \u2208 M(E)).\n\n(2.6.16)\n\nHence (2.6.15) implies that\nlim inf e \u2212hYt , 1ikUT \u221ek\u221e \u2264 1A\nt\u2192\u221e\n\na.s.\n\n(2.6.17)\n\nBy the finite ancestry property, kUT \u221ek\u221e < \u221e and therefore limt\u2192\u221e hYt , 1i = \u221e a.s. on Ac .\nThe following is a simple consequence of Lemma 2.56.\nLemma 2.57 (Extinction of (sub-) critical processes) Assume that the (G, \u03b1, \u03b2)-superprocess Y has the finite ancestry property and that \u03b2 \u2264 0. Then, for any \u03bc \u2208 M(E),\n\u0002\n\u0003\n(2.6.18)\nP \u03bc Yt = 0 eventually = 1.\n\nProof Since E \u03bc [hYt , 1i] \u2264 h\u03bc, 1i, P \u03bc [limt\u2192\u221e hYt , 1i = \u221e] = 0. Now the claim follows from\nLemma 2.56.\n\nOur final result of this section is the following.\nLemma 2.58 (Extinction versus exponential growth) Assume that the (G, \u03b1, \u03b2)-superprocess Y has the finite ancestry property and that \u03b2 > 0 is a constant. Then, for any\n\u03bc \u2208 M(E), there exists a nonnegative random variable W , depending on \u03bc, such that\n(i)\n(ii)\n\nlim e\u2212\u03b2t hYt , 1i = W\nP \u03bc \u2212a.s.,\n\u0002\n\u0003\nlim E \u03bc |e\u2212\u03b2t hYt , 1i \u2212 W |2 = 0,\n\nt\u2192\u221e\nt\u2192\u221e\n\n(iii) E \u03bc (W ) = h\u03bc, 1i,\n\u03bc\n\n(iv) Var (W ) \u2264 2\u03b2\n\n\u22121\n\nk\u03b1k\u221e h\u03bc, 1i,\n\n(v) {W = 0} = {Yt = 0 eventually}\n\n(2.6.19)\nP \u03bc \u2212a.s.\n\nProof Put Vt f := e\u03b2t St . The mean and covariance of Y are given by the following formulas,\nsee, for example, [Fit88]:\n\uf8fc\n(i)\nE \u03bc [hYt , f i] = h\u03bc, Vt f i\n\uf8fd\nZ t\n(t \u2265 0, f, g \u2208 B(E)).\n(ii) Cov\u03bc (hYt , f i, hYt , gi) = 2 ds h\u03bc, Vs (\u03b1 (Vt\u2212s f )(Vt\u2212s g))i \uf8fe\n0\n\n(2.6.20)\n\nTherefore,\n\nE \u03bc [hYt , f i] = e\u03b2t h\u03bc, St f i\n\n(t \u2265 0, f \u2208 B(E)),\n\n(2.6.21)\n\n\f2.6. THE SUPER-WRIGHT-FISHER DIFFUSION: PREPARATORY RESULTS\n\n79\n\nand\nZ\n\nt\n\nds e\u03b2s e2\u03b2(t\u2212s) h\u03bc, Ss (\u03b1(St\u2212s f )2 )i\n0\nZ t\n2\n\u03b2t\n\u2264 2k\u03b1k\u221e kf k\u221e h\u03bc, 1ie\nds e\u03b2(t\u2212s)\n\nVar\u03bc (hYt , f i) = 2\n\n0\n2\u03b2t\n\n\u2264 2\u03b2 \u22121 k\u03b1k\u221e kf k2\u221e h\u03bc, 1ie\n\n(2.6.22)\n\n(t \u2265 0, f \u2208 B(E)).\n\nLet (Ft )t\u22650 be the filtration generated by Y and put\n\u1ef8t := e\u2212\u03b2t Yt\n\n(t \u2265 0).\n\n(2.6.23)\n\nThen (2.6.21) and (2.6.22) show that for any 0 \u2264 s \u2264 t and f \u2208 B(E),\n\u0003\n\u0002\nE \u03bc h\u1ef8t , f i Fs = h\u1ef8s , St\u2212s f i a.s.,\n\u0003\n\u0002\n(ii) Var\u03bc h\u1ef8t , f i Fs \u2264 2\u03b2 \u22121 k\u03b1k\u221e kf k2\u221e h\u1ef8s , 1ie\u2212\u03b2s\n(i)\n\na.s.\n\n(2.6.24)\n\nSince St\u2212s 1 = 1, formula (2.6.24) (i) shows that (h\u1ef8t , 1)it\u22650 is a nonnegative martingale, and\nhence there exists a nonnegative random variable W such that (2.6.19) (i) holds. Setting s = 0\nin (2.6.24) (ii), we see that\n\u0002\n\u0003\nVar\u03bc h\u1ef8t , 1i \u2264 2\u03b2 \u22121 k\u03b1k\u221e h\u03bc, 1i\n\n(t \u2265 0).\n\n(2.6.25)\n\nThis implies (2.6.19) (ii), and, using Fatou, (2.6.19) (iv). Moreover, by (2.6.25) the random\nvariables hYt , 1it\u22650 are uniformly integrable, and therefore (2.6.19) (iii) holds.\nWe are left with the task to prove (2.6.19) (v). The inclusion \u2283 is trivial. Formulas\n(2.6.19) (iii) and (2.6.19) (iv) imply that\nh\u03bc, 1i2 P \u03bc [W = 0] \u2264 Var\u03bc (W ) \u2264 2\u03b2 \u22121 k\u03b1k\u221e h\u03bc, 1i,\n\n(2.6.26)\n\nP \u03bc [W > 0] \u2265 1 \u2212 2\u03b2 \u22121 k\u03b1k\u221e h\u03bc, 1i\u22121\n\n(2.6.27)\n\nand therefore\n(\u03bc 6= 0).\n\nNote that {W > 0} is a tail event. Thus, by Lemma 2.64,\nlim P Yt [W > 0] = 1{W >0}\n\nt\u2192\u221e\n\na.s.\n\n(2.6.28)\n\nFormula (2.6.27) shows that\nlim inf P Yt [W > 0] \u2265 1{limt\u2192\u221e hYt ,1i=\u221e} .\nt\u2192\u221e\n\n(2.6.29)\n\nCombining Lemma 2.56 with formulas (2.6.28) and (2.6.29) we see that {Yt = 0 eventually}c \u2282\n{limt\u2192\u221e hYt , 1i = \u221e} \u2282 {W > 0} a.s.\n\n\f80\n\n2.6.3\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nSmoothness of two log-Laplace semigroups\n\nWe return to the special situation E = [0, 1] and G = A or G = Av , where A and Av\nare the closures in C(E) of the operators A in (2.5.5) and Av in (2.5.20), respectively, with\ndomains D(A) = D(Av ) := C (2) [0, 1], the space of real functions on [0, 1] that are twice\ncontinuously differentiable. Let U = U (A, \u03b1, \u03b1) and U v = U (Av , \u03b1v, \u03b1 \u2212 1) denote the logLaplace semigroups of the super-Wright-Fisher diffusion Y and the weighted super-WrightFisher diffusion Y v , respectively, where \u03b1 > 0 is constant. In this section we prove:\nLemma 2.59 (Smoothing property of U and U v ) One has Ut (B+ [0, 1]) \u2282 C+ [0, 1] and\nUtv (B+ [0, 1]) \u2282 C+ [0, 1] for all t > 0. Moreover, if bp-limn\u2192\u221e fn = f for some fn , f \u2208 B+ [0, 1],\nthen limn\u2192\u221e kUt fn \u2212 Ut f k\u221e = 0 and limn\u2192\u221e kUtv fn \u2212 Utv f k\u221e = 0 for all t > 0.\nTo prepare for the proof, we start with the following elementary property of the semigroups\nS and S v generated by A and Av , respectively (recall (2.5.5) and (2.5.20)).\nLemma 2.60 (Strong Feller property) The semigroups S and S v have the strong Feller\nproperty, i.e., St (B[0, 1]) \u2282 C[0, 1] and Stv (B[0, 1]) \u2282 C[0, 1] for all t > 0.\nProof Couple two realizations \u03be x , \u03be y of the process with generator A, started in x, y \u2208 [0, 1], in\nsuch a way that \u03be x and \u03be y move independently up to the random time \u03c4 := inf{t \u2265 0 : \u03betx = \u03bety },\nand such that \u03betx = \u03bety for all t \u2265 \u03c4 . (Here the superscript in \u03be x refers to the initial condition,\nand not, like elsewhere, to a compensated h-transform.) Then it is not hard to see that\nP [\u03bety = \u03betx ] \u2192 1 as\n\ny\u2192x\n\n\u2200t > 0.\n\n(2.6.30)\n\nIn particular, (2.6.30) holds also for x \u2208 {0, 1} since the boundary is attainable. Since |St f (x)\u2212\nSt f (y)| \u2264 2kf k\u221e P [\u03betx 6= \u03bety ], formula (2.6.30) shows that St f \u2208 C[0, 1] for all f \u2208 B[0, 1] and\nt > 0. For the process with generator Av the argument is similar but easier, since in this case\n{0, 1} is an entrance boundary.\nProof of Lemma 2.59 For each f \u2208 B[0, 1], the function ut := Ut f is a mild solution of\n(2.5.6), i.e., (see (2.6.1))\nUt f = S t f +\n\nZ\n\n0\n\nt\n\n\u0001\nSt\u2212s \u03b1Us f (1 \u2212 Us f ) ds\n\n(t \u2265 0).\n\n(2.6.31)\n\nBy the strong Feller property of (St )t\u22650 (Lemma 2.60), the functions St f and St\u2212s (\u03b1Us f (1 \u2212\nUs f )) are continuous for each 0 \u2264 s < t, and therefore Ut f is continuous.\nNow let fn \u2192 f in a bounded pointwise way for some fn , f \u2208 B+ [0, 1], and let t > 0.\nBy Lemma 2.51, Ut fn \u2192 Ut f in a bounded pointwise way. By the strong Feller property\nof (St )t\u22650 and [Rev84, Prop. 1.5.8 and Thm.\n\u0001 1.5.9], St fn converges uniformly to St f and\nthe function (x, s) 7\u2192\nS\n\u03b1U\nf\n(1\n\u2212\nU\nf\n)\n(x) converges uniformly on [0, 1] \u00d7 [0, t \u2212 \u03b5] to\nt\u2212s\ns\nn\ns\nn\n\u0001\nSt\u2212s \u03b1Us f (1 \u2212 Us f ) (x), for all \u03b5 > 0. By (2.6.31), it follows that Ut fn \u2192 Ut f uniformly on\n[0, 1].\nThe same arguments apply to Utv f .\n\n\f2.6. THE SUPER-WRIGHT-FISHER DIFFUSION: PREPARATORY RESULTS\n\n2.6.4\n\n81\n\nBounds on the absorption probability\n\nLet U = U (A, \u03b1, \u03b1). Since the points 0, 1 are traps for the Wright-Fisher diffusion, f (r) = 0\nimplies Ut f (r) = 0 (r = 0, 1). We have already seen (Lemma 2.59) that Ut f is continuous\nfor each t > 0. The following lemma shows that if f (r) = 0, then Ut f has a finite slope at\nr = 0, 1, for all t > 0. By symmetry, it suffices to consider the case r = 0.\nLemma 2.61 (Absorption of the super-Wright-Fisher diffusion) Let U = U (A, \u03b1, \u03b1),\nwith \u03b1 > 0. Then\nUt (\u221e1(0,1] )(x) \u2264 Kt x\n(t > 0, x \u2208 [0, 1]),\n(2.6.32)\n\nwith\n\nKt :=\nNote that (2.6.32) implies that\n\n\u0011\ne\u03b1t/2 \u0010 8\n+\n2\n1 \u2212 e\u2212\u03b1t/2 t\n\nP \u03b4x [Yt ((0, 1]) > 0] \u2264 1 \u2212 e \u2212Kt x \u2264 Kt x\n\n(t > 0).\n\n(2.6.33)\n\n(t > 0, x \u2208 [0, 1]).\n\n(2.6.34)\n\nWe begin with a preparatory lemma.\nLemma 2.62 (Absorption of the Wright-Fisher diffusion) For the Wright-Fisher diffusion \u03be,\n\u0011\n\u00104\n+2 x\n(t > 0, x \u2208 [0, 1]).\n(2.6.35)\nP x [\u03bet > 0] \u2264\nt\nProof For x \u2265 0 put\nf0 (x) := 1{0} (x)\n\nand ft (x) := (1 \u2212 2x)e \u2212\n\n4x\nt 1 1 (x)\n[0, 2 ]\n\n(t > 0).\n\n(2.6.36)\n\nA little calculation shows that for t > 0 and x \u2265 0,\n\u2202\n\u2202t ft (x) = 4x(1\n1\n2 x(1\n\n4x\n\n\u2212 2x)t\u22122 e\u2212 t 1[0, 1 ] (x)\n2\n\n\u2212 x)Dx2 ft (x) = 8x(1 \u2212 x)(1 \u2212 2x)t\u22122 e\u2212\n\u2212 2t\n\n+2e\n\n4x\nt\n\n+ 8x(1 \u2212 x)t\u22121 e\u2212\n\n4x\nt\n\n\u03b4 1 (x),\n2\n\n\u0001\n\n1[0, 1 ] (x)\n2\n\n(2.6.37)\n\nwhere Dx2 denotes the generalized second derivative with respect to x and \u03b4 1 is the deltafunction at 12 . Since 4x \u2264 8x(1 \u2212 x) for all x \u2208 [0, 21 ], it follows that\n\u2202\n\u2202t ft (x)\n\n\u2264 12 x(1 \u2212 x)Dx2 ft (x)\n\n(t > 0, x \u2265 0).\n\n2\n\n(2.6.38)\n\n\u2202\nft \u2264 Aft for t > 0, and\nIf ft were contained in D(A), then (2.6.38) would mean that \u2202t\na standard argument (compare Lemma 2.54) would tell us that ft \u2264 St f0 , where S is the\nsemigroup of \u03be. In the present case, we need a little approximation argument.\nLet \u03c6n \u2265 0 (n \u2265 0) denote C (\u221e) -functions defined on [0, \u221e) with support contained in\n1\n[0, 3 ], say, such that \u03c6n (x)dx are probability measures converging weakly to the \u03b4-measure \u03b40\nas n \u2192 \u221e. Put\nZ \u221e\ndy \u03c6n (y)ft (x + y) =: \u03c6n \u2217 ft (x)\n(t > 0, x \u2265 0).\n(2.6.39)\nftn (x) :=\n0\n\n\f82\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nThen\n\n\u2202 n\n\u2202t ft (x) = \u03c6n\n\u22022 n\nf (x) = \u03c6n\n\u2202x2 t\n\n\u2202\n\u2202t ft (x)\n\u2217 Dx2 ft (x),\n\n\u2217\n\n(2.6.40)\n\nand therefore (2.6.38) shows that\n\u2202 n\n\u2202t ft (x)\n\n2\n\nn\n\u2202\n\u2264 21 x(1 \u2212 x) \u2202x\n2 ft (x)\n\n(t > 0, x \u2265 0, n \u2265 0).\n\n(2.6.41)\n\nSince ftn \u2208 D(A) for all t > 0, the argument mentioned above gives\nn\nft+\u03b5\n\u2264 St f\u03b5n\n\n(t \u2265 0, \u03b5 > 0).\n\n(2.6.42)\n\nLetting n \u2192 \u221e and afterwards \u03b5 \u2192 0 we find that\nft (x) \u2264 St f0 (x) = P x [\u03bet = 0]\n4x\n\n(t \u2265 0, x \u2208 [0, 1]).\n\n(2.6.43)\n\n4x\n\n\u2202\nNote that \u2202x\n(1 \u2212 ft (x)) = (1 \u2212 2x)4t\u22121 e\u2212 t + 2e\u2212 t \u2264 ( 4t + 2) for x \u2208 [0, 21 ]. Therefore (2.6.43)\nimplies (2.6.35). (Note that (2.6.35) is trivial for x \u2208 [ 21 , 1].)\n\nProof of Lemma 2.61 Fix f \u2208 B+ [0, 1] satisfying f (0) = 0 and write Ut f = Ut/2 Ut/2 f . By\n(2.6.10) from Lemma 2.55, Ut/2 f \u2264 (1 \u2212 e\u2212\u03b1t/2 )\u22121 . Since moreover Ut/2 f (0) = 0 because of\nabsorption at zero, we have\nUt f \u2264 Ut/2 ((1 \u2212 e\u2212\u03b1t/2 )\u22121 1(0,1] )\n\n(t > 0).\n\n(2.6.44)\n\nUsing (2.6.8) from Lemma 2.55, we may estimate U (A, \u03b1, \u03b1) in terms of U (A, 0, \u03b1), which is\njust the linear semigroup (e\u03b1t St )t\u22650 . Thus, by Lemma 2.62,\nUt f (x) \u2264 e\u03b1t/2 St/2 ((1 \u2212 e\u2212\u03b1t/2 )\u22121 1(0,1] )(x)\n\u2264 e\u03b1t/2 (1 \u2212 e\u2212\u03b1t/2 )\u22121 ( 8t + 2)x\n\n(t > 0, x \u2208 [0, 1]).\n\n(2.6.45)\n\nLetting f \u2191 \u221e, by monotonicity we arrive at (2.6.32).\n\n2.6.5\n\nThe weighted super-Wright-Fisher diffusion\n\nIn this section we prove Lemmas 2.49 and 2.50. Recall that \u03be, \u03be v are the diffusions in [0, 1] with\ngenerators A, Av defined in (2.5.5) and (2.5.20), and associated semigroups S, S v , respectively,\nand that U = U (A, \u03b1, \u03b1) and U v = U (Av , \u03b1v, \u03b1 \u2212 1).\nLemma 2.63 (v-transformed log-Laplace semigroup) If f \u2208 D(Av ), then vf \u2208 D(A)\nand\nA(vf ) = v (Av \u2212 1)f.\n(2.6.46)\nMoreover,\nUt (vf ) = v Utv f\n\n(t \u2265 0, f \u2208 B+ [0, 1]).\n\n(2.6.47)\n\n\f2.6. THE SUPER-WRIGHT-FISHER DIFFUSION: PREPARATORY RESULTS\n\n83\n\nProof For any f \u2208 C (2) [0, 1], it is easy to check that\nA(vf ) = v (Av \u2212 1)f.\n\n(2.6.48)\n\nFix f \u2208 D(Av ) and choose fn \u2208 C (2) [0, 1] such that fn \u2192 f in C[0, 1]. Then (2.6.48) shows\nthat A(vfn ) \u2192 v (Av \u2212 1)f , which implies that vf \u2208 D(A) and that (2.6.46) holds.\nNow fix f \u2208 C+ [0, 1] \u2229 D(Av ) and put uvt := Utv f (t \u2265 0). Then uv is the classical solution\nof the Cauchy equation\n\u001a\n\n\u2202 v\n\u2202t ut\nuv0\n\n= Av uvt + (\u03b1 \u2212 1)uvt \u2212 \u03b1v (uvt )2\n= f.\n\n(t \u2265 0),\n\n(2.6.49)\n\nIt follows from (2.6.46) that\n\u2202\nv\n\u2202t vut\n\n\u2202 v\n= v \u2202t\nut = vAv uvt + (\u03b1 \u2212 1)vuvt \u2212 \u03b1 (vuvt )2\n\n= A(vuvt ) + \u03b1vuvt \u2212 \u03b1 (vuvt )2\n\n(t \u2265 0),\n\n(2.6.50)\n\ni.e., ut := vuvt is the classical solution to the Cauchy equation\n\u001a\n\n\u2202\n\u2202t ut = Aut\nu0 = vf.\n\n+ \u03b1ut \u2212 \u03b1u2t\n\n(t \u2265 0),\n\n(2.6.51)\n\nThis proves that Ut (vf ) = ut = vuvt = vUtv f for all f \u2208 C+ [0, 1] \u2229 D(Av ). The general case\nfollows from Lemma 2.52 and the fact that the class of f \u2208 B+ [0, 1] for which (2.6.47) holds\nis closed under bounded pointwise limits.\nProof of Lemma 2.49 Set Ft := \u03c3(Ys : 0 \u2264 s \u2264 t). Then by (2.6.47), for all 0 \u2264 s \u2264 t and\nf \u2208 B+ [0, 1],\n\u0003\n\u0003\n\u0002\n\u0002\nE e \u2212hvYt , f i Fs = E e \u2212hYt , vf i Fs = e \u2212hYs , Ut\u2212s (vf )i\nv\n\nv\n\n= e \u2212hYs , vUt\u2212s f i = e \u2212hvYs , Ut\u2212s f i.\n\n(2.6.52)\n\nIt follows that (vYt )t\u22650 is a Markov process and that its transition probabilities coincide with\nthose of the (Av , \u03b1v, \u03b1 \u2212 1)-superprocess. Since Y has continuous sample paths, so has vY.\nProof of Lemma 2.50 We need to prove (2.5.22), which by (2.6.12) is equivalent to the\nstatement that kUtv \u221ek\u221e < \u221e for all t > 0. Assume that f \u2208 B+ [0, 1] satisfies f (0) = f (1) = 0.\nBy Lemma 2.61, Ut f (x) \u2264 Kt x for the constant Kt mentioned there. By symmetry, one\nalso has Ut f (x) \u2264 Kt (1 \u2212 x) and, since x \u2227 (1 \u2212 x) \u2264 31 v(x), Ut f (x) \u2264 13 Kt v(x). Let\ng \u2208 B+ [0, 1]. By formula (2.6.47) and the fact that (vg)(0) = (vg)(1) = 0, we see that\n1\nUtv g(x) = v(x)\nUt (vg)(x) \u2264 13 Kt for all x \u2208 (0, 1). By Lemma 2.60, Utv g is continuous on [0, 1]\nand therefore Utv g(x) \u2264 13 Kt holds also for x = 0, 1. Taking the limit g \u2191 \u221e we see that\nkUtv \u221ek\u221e \u2264 13 Kt < \u221e for all t > 0.\n\n\f84\n\n2.6.6\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nA zero-one law for Markov processes\n\nLet E be a Polish space and let (P x )x\u2208E be a family of probability measures on DE [0, \u221e) (the\nspace of cadlag functions w : [0, \u221e) \u2192 E) such that under (P x )x\u2208E , the coordinate projections\n{w 7\u2192 wt =: \u03bet (w) : t \u2265 0} form a Borel right process in the sense of [Sha88]. This is true, for\nexample, if (P x )x\u2208E are the laws of a Feller process on a locally compact Polish\nspace, or a\nT\n(G, \u03b1, \u03b2)-superprocess as introduced in Section 2.6.1, see [Fit88]. Let T := t\u22650 \u03c3(\u03bes : s \u2265 t)\ndenote the tail-\u03c3-field of \u03be. Let (\u03b8t w)s := wt+s (t, s \u2265 0) be the time-shift on DE [0, \u221e). Then\nthe following holds.\nLemma 2.64 (Zero-one law for Markov processes) Assume that A \u2208 T . Then for each\nx \u2208 E,\n(2.6.53)\nlim P \u03bet (\u03b8t\u22121 (A)) = 1A P x \u2212a.s.\nt\u2192\u221e\n\nProof Let Ft := \u03c3(\u03bes : 0 \u2264 s \u2264 t) (t \u2265 0) be the filtration generated by \u03be and set F\u221e :=\n\u03c3(\u03bes : s \u2265 0). Since \u03be is a Markov process, P \u03bet (\u03b8t\u22121 (A)) = P [A|Ft ] a.s. For any sequence of\ntimes tn \u2191 \u221e one has Ftn \u2191 F\u221e and therefore P [A|Ftn ] \u2192 P [A|F\u221e ] = 1A a.s., see [Loe63,\n\u00a7 29, Complement 10 (b)]. Since \u03be is a right process, the function t 7\u2192 P \u03bet (\u03b8t\u22121 (A)) is a.s.\nright-continuous, see [Sha88, Theorem (7.4.viii)], and we conclude that (2.6.53) holds.\n\n2.7\n2.7.1\n\nThe super-Wright-Fisher diffusion: long-time behavior\nErgodicity of the compensated v-transformed Wright-Fisher diffusion\n\nRecall that \u03be v is the diffusion on [0, 1] with generator Av defined in (2.5.20) and associated\nsemigroup S v . As in Theorem 2.46, l denotes the Lebesgue measure on (0, 1) and v is defined\nby (2.5.9). In this section we prove:\nLemma 2.65 (Ergodicity of the compensated v-transformed Wright-Fisher diffusion) The Markov process \u03be v has the unique invariant law vl and is ergodic:\nlim kStv f \u2212 hvl, f ik\u221e = 0\n\nt\u2192\u221e\n\n\u2200f \u2208 B[0, 1].\n\n(2.7.1)\n\nProof Since\n\u2202 1\n\u2202x 2 x(1\n\n\u0002\n\n\u0003\n\u2212 x)v(x) = 2( 21 \u2212 x)v(x)\n\n(x \u2208 [0, 1]),\n\n(2.7.2)\n\nvl is a (reversible) invariant law for the process with generator Av , see [EK86, Proposition 4.9.2]. Fix x \u2208 [0, 1]. Let \u03be v be the process started in x and let \u03be \u0303v be the process\nstarted in the invariant law vl. Then \u03be v , \u03be \u0303v may represented as solutions to the SDE\nq\n(2.7.3)\nd\u03betv = 2( 21 \u2212 \u03betv )dt + \u03betv (1 \u2212 \u03betv )dBt ,\nrelative to the same Brownian motion B. Using the technique of Yamada & Watanabe (see\n[YW71] or, for example, [EK86, Theorem 5.3.8]), it is easy to prove that\nE[|\u03betv \u2212 \u03be\u0303tv |] = e\u22122t E[|\u03be0v \u2212 \u03be \u03030v |] \u2264 e\u22122t\n\n(t \u2265 0).\n\n(2.7.4)\n\n\f85\n\n2.7. THE SUPER-WRIGHT-FISHER DIFFUSION: LONG-TIME BEHAVIOR\nIt follows that for any function f satisfying |f (y) \u2212 f (z)| \u2264 |y \u2212 z|\n\n(y, z \u2208 [0, 1]),\n\nE[f (\u03betv )] \u2212 hvl, f i \u2264 E[|f (\u03betv ) \u2212 f (\u03be\u0303tv )|] \u2264 e\u22122t .\n\n(2.7.5)\n\nThis implies that the function x 7\u2192 Lx (\u03betv ) from [0, 1] into the space M1 [0, 1] of probability\nmeasures on [0, 1], converges as t \u2192 \u221e uniformly to the constant function vl. This shows that\n(2.7.1) holds for all f \u2208 C[0, 1]. Since \u03be v has the strong Feller property (Lemma 2.60), (2.7.1)\nholds for all f \u2208 B[0, 1].\n\n2.7.2\n\nLong-time behavior of the weighted super-Wright-Fisher diffusion\n\nThe following lemma prepares for the proof of formula (2.5.15) in Theorem 2.46.\nLemma 2.66 (Mean square convergence) Assume that \u03b1 > 1. Let Y v be the (Av , \u03b1v, \u03b1 \u2212\n1)-superprocess started in Y0v = \u03bc \u2208 M[0, 1]. Then there exists a nonnegative random variable\nW , depending on \u03bc, such that\n(i)\n(ii)\nMoreover,\nand\n\nlim e\u2212(\u03b1\u22121)t hYtv , 1i = W a.s.\nh\ni\n2\nlim E \u03bc e\u2212(\u03b1\u22121)t hYtv , f i \u2212 W hvl, f i\n=0\n\nt\u2192\u221e\n\n\u2200f \u2208 B[0, 1].\n\nt\u2192\u221e\n\nE \u03bc (W ) = h\u03bc, 1i\n\nand\n\n\u03b1\nh\u03bc, 1i,\nVar\u03bc (W ) \u2264 3 \u03b1\u22121\n\n{W = 0} = {Ytv = 0 eventually}\n\na.s.\n\n(2.7.6)\n\n(2.7.7)\n(2.7.8)\n\nProof Except for formula (2.7.6) (ii), all statements are direct consequences of the fact that\nY v has the finite ancestry property (Lemma 2.50) and of Lemma 2.58 (note that k\u03b1vk\u221e = 32 \u03b1).\nFix f \u2208 B[0, 1]. Let (Ft )t\u22650 be the filtration generated by Y v and put \u1ef8tv := e\u2212(\u03b1\u22121)t Ytv\n(t \u2265 0). Pick 1 \u2264 sn \u2264 tn such that sn \u2192 \u221e and tn \u2212 sn \u2192 \u221e. Then, by (2.6.24),\ni\nh\n2\n\u03b1\nE \u03bc h\u1ef8tvn , f i \u2212 h\u1ef8svn , Stvn \u2212sn f i Fsn \u2264 3 \u03b1\u22121\nkf k2\u221e h\u1ef8svn , 1ie\u2212(\u03b1\u22121)sn a.s.\n(2.7.9)\nTaking expectations on both sides in (2.7.9), one finds that\nh\ni\n2\n\u03b1\nE \u03bc h\u1ef8tvn , f i \u2212 h\u1ef8svn , Stvn \u2212sn f i\n\u2264 3 \u03b1\u22121\nkf k2\u221e h\u03bc, 1ie\u2212(\u03b1\u22121)sn .\n\n(2.7.10)\n\nBy (2.6.19) (ii),\n\n\u0002\n\u0003\nlim E \u03bc |h\u1ef8tv , 1i \u2212 W |2 = 0.\n\nt\u2192\u221e\n\n(2.7.11)\n\nUsing Lemma 2.65 (about the ergodicity of \u03be v ) and (2.7.11), it is easy to show that\nh\ni\n2\n= 0.\n(2.7.12)\nlim E \u03bc h\u1ef8svn , Stvn \u2212sn f i \u2212 W hvl, f i\nn\u2192\u221e\n\nCombining this with (2.7.10), we see that\nh\ni\n2\n= 0.\nlim E \u03bc h\u1ef8tvn , f i \u2212 W hvl, f i\nn\u2192\u221e\n\nSince this is true for any tn \u2192 \u221e, (2.7.6) (ii) follows.\n\n(2.7.13)\n\n\f86\n\n2.7.3\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nLong-time behavior of the super-Wright-Fisher diffusion\n\nProof of Theorem 2.46 Using Lemma 2.49, we can translate our results on the weighted\nsuper-Wright-Fisher diffusion Y v to the super-Wright-Fisher diffusion Y. Thus, Lemma 2.66\nproves formulas (2.5.10) (ii), (2.5.11) (ii), and (2.5.14)\u2013(2.5.15), where W(0,1) is the random\nvariable W from Lemma 2.66. Formula (2.5.13) follows from Lemma 2.57. To finish the proof\nof Theorem 2.46, it suffices to prove (2.5.10) (i), (2.5.11) (i) and (2.5.12).\n1\u25e6. Proof of formula (2.5.10) (i) One has E \u03bc [hYt , f i] = e\u03b1t h\u03bc, St f i for all t \u2265 0, f \u2208 B[0, 1]\nby (2.6.21). Since the points r = 0, 1 are traps for the Wright-Fisher diffusion, E \u03bc [hYt , 1{r} i] =\ne\u03b1t h\u03bc, St 1{r} i \u2265 e\u03b1t h\u03bc, 1{r} i for all t \u2265 0, r = 0, 1. Thus, the processes (e\u2212\u03b1t hYt , 1{r} i)t\u22650 (r =\n0, 1) are nonnegative submartingales, and hence there exist random variables Wr (r = 0, 1)\nsuch that (2.5.10) (i) holds.\n2\u25e6. Proof of formula (2.5.12) For \u03b1 \u2264 1 the statement is trivial by (2.5.13), so assume\n\u03b1 > 1. By symmetry it suffices to consider the case r = 0. From the L2 -convergence formula\n(2.5.15) we have, for any K > 0,\n\b\n{W(0,1) > 0} \u2282 \u2200T < \u221e \u2203t \u2265 T such that Yt ([ 14 , 13 ]) \u2265 K\na.s.\n(2.7.14)\nAssume for the moment that for some t > 0 and (sufficiently large) K,\ninf\n\n\u03bc: \u03bc([ 14 , 13 ])\u2265K\n\nP \u03bc [W0 > 0] > 0.\n\nThen we see from (2.7.14) and (2.7.15) that\n\b\n{W(0,1) > 0} \u2282 lim P Yt [W0 > 0] = 0\n\nc\n\nt\u2192\u221e\n\n\u2282 {W0 > 0}\n\n(2.7.15)\n\na.s.,\n\n(2.7.16)\n\nwhere the second inclusion follows from the fact that, by Lemma 2.64,\nlim P Yt [W0 > 0] = 1{W0 >0}\n\nt\u2192\u221e\n\na.s.\n\n(2.7.17)\n\nThus, we are done if we can prove (2.7.15). By the branching property, it suffices to prove\n(2.7.15) for measures \u03bc that are concentrated on [ 14 , 13 ]. Fix any t > 0. Formulas (2.6.21) and\n(2.6.22) give\n\u0002\n\u0003\n(i)\nE \u03bc hYt , 1{0} i = h\u03bc, St 1{0} ie\u03b1t ,\n(2.7.18)\n\u0002\n\u0003\n(ii) Var\u03bc hYt , 1{0} i \u2264 2h\u03bc, 1ie2\u03b1t .\nIt follows from formula (2.6.43) (recall (2.6.36)) that\n\ninf St 1{0} (x) > 0.\n\nx\u2208[ 14 , 13 ]\n\nDenoting the infimum by \u03b5, we get the bounds\n\u0002\n\u0003\n(i)\nE \u03bc hYt , 1{0} i \u2265 \u03b5h\u03bc, 1ie\u03b1t ,\n\u0002\n\u0003\n(ii) Var\u03bc hYt , 1{0} i \u2264 2h\u03bc, 1ie2\u03b1t .\n\n(2.7.19)\n\n(2.7.20)\n\n\f2.7. THE SUPER-WRIGHT-FISHER DIFFUSION: LONG-TIME BEHAVIOR\n\n87\n\nThese formulas show that for large h\u03bc, 1i, the standard deviation of hYt , 1{0} i is small compared\nto its mean. Therefore, using Chebyshev's inequality, it is easy to show that for every M > 0\nthere exists a K > 0 such that\ninf\n\n\u03bc\u2208M[ 41 , 31 ]: h\u03bc,1i\u2265K\n\nP \u03bc [hYt , 1{0} i \u2265 M ] > 0.\n\n(2.7.21)\n\nHence, by the Markov property, in order to prove (2.7.15) it suffices to show that for M\nsufficiently large,\ninf\nP \u03bc [W0 > 0] > 0.\n(2.7.22)\n\u03bc: \u03bc({0})\u2265M\n\nBy the branching property, it suffices to prove (2.7.22) for measures \u03bc that are concentrated on\n{0}. In that case, Yt ({0})t\u22650 is an autonomous supercritical Feller's branching diffusion (a superprocess in a single-point space is just a Feller's branching diffusion). Applying Lemma 2.58\nto this Feller's branching diffusion, again using Chebyshev, it is not hard to prove (2.7.22).\nSince the arguments are very similar to those we have already seen, we skip the details.\n3\u25e6. Proof of formula (2.5.11) (i) The inclusion {Wr = 0} \u2283 {Yt ({r}) = 0 eventually} a.s.\nis trivial. By (2.5.12) and (2.5.11) (ii), {Wr = 0} \u2282 {W(0,1) = 0} \u2282 {Yt ((0, 1)) = 0 eventually}\na.s. Therefore, by the strong Markov property, it suffices to prove {Wr = 0} \u2282 {Yt ({r}) =\n0 eventually} a.s. for the process started in \u03bc with \u03bc((0, 1)) = 0. In this case, (Yt ({r}))t\u22650 is\nan autonomous supercritical Feller's branching diffusion, and the statement is easy (see the\nprevious parapraph).\n\n2.7.4\n\nLong-time behavior of the log-Laplace semigroup\n\nProof of Proposition 2.47 We start by proving that for all \u03bc \u2208 M[0, 1] and f \u2208 B+ [0, 1],\nlim e \u2212h\u03bc, Ut f i\nh\b\ni\n\b\n\b\n= P \u03bc f (0) = 0 or W0 = 0 \u2229 f (1) = 0 or W1 = 0 \u2229 hl, f i = 0 or W(0,1) = 0\n\uf8f1\n1 \u0002\nif f (0) = f (1) = hl, f i = 0,\n\uf8f4\n\u0003\n\uf8f4\n\uf8f4\n\u03bc\n\uf8f4\nif f (0) = f (1) = 0, hl, f i > 0,\n\uf8f2 P \u0002W(0,1) =\u0003 0\n\u0002\n\u0003\nif f (0) > 0, f (1) = 0,\n= P \u03bc \u0002W0 = 0\u0003 = P \u03bc \u0002W0 = W(0,1) = 0\u0003\n\uf8f4\n\uf8f4\nP \u03bc W = 0 = P \u03bc\u0003 W1 =\u0002W(0,1) = 0\n\uf8f4\n\uf8f4\n\u0003 if f (0) = 0, f (1) > 0,\n\uf8f3 \u03bc\u0002 1\nP W0 = W1 = 0 = P \u03bc W0 = W1 = W(0,1) = 0 if f (0) > 0, f (1) > 0,\n(2.7.23)\n\u03bc\nwhere P [W(0,1) = 0] < 1 if and only if \u03b1 > 1 and h\u03bc, vi > 0.\nIndeed, by formula (2.5.2),\nt\u2192\u221e\n\n\u0002\n\u0003\ne \u2212h\u03bc, Ut f i = E \u03bc e \u2212f (0)Yt ({0}) e \u2212f (1)Yt ({1}) e \u2212hYt , 1(0,1) f i .\n\n(2.7.24)\n\nBy (2.5.10) (i) and (2.5.11) (i) in Theorem 2.46,\n\nlim e \u2212f (r)Yt ({r}) = 1{f (r)=0\n\nt\u2192\u221e\n\nor Wr =0 }\n\na.s.\n\n(r = 0, 1).\n\n(2.7.25)\n\n\f88\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nNow, if hl, f i = 0 for some f \u2208 B+ [0, 1], then e\u2212hYt ,1(0,1) f i = 1 a.s. for each t > 0. To see\nthis, note that by (2.6.20), E \u03b4x [hYt , 1(0,1) f i] = e\u03b1t h\u03b4x , St 1(0,1) f i = e\u03b1t E x [1(0,1) (\u03bet )f (\u03bet )] where\n\u03be is the Wright-Fisher diffusion. Since the law of the Wright-Fisher diffusion at any time\nt > 0 (started in an arbitrary initial condition) on (0, 1) is absolutely continuous with respect\nto Lebesgue measure, we see that E \u03b4x [hYt , 1(0,1) f i] = 0 and hence hYt , 1(0,1) f i = 0 P \u03b4x -a.s.\n(Actually, since Y is a one-dimensional superprocess, one can prove that Yt , restricted to\n(0, 1), for t > 0 is almost surely absolutely continuous with respect to Lebesgue measure.)\nOn the other hand, if hl, f i > 0, then by formulas (2.5.10) (ii), (2.5.11) (ii), (2.5.13), and\n(2.5.15) in Theorem 2.46,\nP\n.\n(2.7.26)\ne \u2212hYt , 1(0,1) f i \u2212\u2192 1\n{W(0,1) =0}\n\nHence, for general f \u2208 B+ [0, 1],\n\ne \u2212hYt , 1(0,1) f i \u2212\u2192 1{hl,f i=0\nP\n\nor W(0,1) =0} ,\n\n(2.7.27)\n\nP\n\nwhere \u2212\u2192 denotes convergence in probability. Inserting (2.7.25) and (2.7.27) into (2.7.24)\nwe arrive at the first equality in (2.7.23). Using formula (2.5.12) and checking the eight\npossibilities for f (0), f (1), hl, f i to be zero or positive, we find the second equality in (2.7.23).\nIn particular, setting \u03bc = \u03b4x in (2.7.23) we see that Ut f converges in a bounded pointwise\nway to 0 or to one of the functions p0,0 , . . . , p1,1 from (2.5.17), where p0,0 = 0 if \u03b1 \u2264 1 and\np0,0 > 0 on (0, 1) otherwise. It follows from Lemma 2.59 that the convergence in (2.5.16) is in\nfact uniform.\nThe fact that pl,r (0) = l and pl,r (1) = r will follow from Proposition 2.48. The statements\nabout smoothness of fixed points will be proved in Section 2.7.5 below.\nProof of Proposition 2.48 By Proposition 2.47, for the functions p0,0 , . . . , p1,1 from (2.5.17),\np0,0 (x) = limt\u2192\u221e Ut 1(0,1) (x),\np1,0 (x) = limt\u2192\u221e Ut 1{0} (x) = limt\u2192\u221e Ut 1[0,1) (x),\np0,1 (x) = limt\u2192\u221e Ut 1{1} (x) = limt\u2192\u221e Ut 1(0,1] (x),\np1,1 (x) = limt\u2192\u221e Ut 1\n\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8fd\n\uf8f4\n\uf8f4\n\uf8fe\n\n(x \u2208 [0, 1]).\n\n(2.7.28)\n\nSince by formula (2.5.4), for each Borel measurable B \u2282 [0, 1], P \u03b4x [Yt (B) > 0] = Ut 1B =\nUt 1B (x) (t \u2265 0, x \u2208 [0, 1]), we can rewrite the expressions in the right-hand side of (2.7.28)\nas in (2.5.18).\n\n2.7.5\n\nSmoothness of fixed points\n\nIn order to finish the proof of Proposition 2.47 we need to show that the functions p0,0 , . . . , p1,1\noccurring there are twice continuously differentiable on [0, 1]. We begin with the following.\nLemma 2.67 (Smoothness of fixed points)If p \u2208 B+ [0, 1] is a fixed point under U (A, \u03b1, \u03b1),\nthen p \u2208 D(A) and Ap + \u03b1 p(1 \u2212 p) = 0.\n\n\f2.7. THE SUPER-WRIGHT-FISHER DIFFUSION: LONG-TIME BEHAVIOR\n\n89\n\nProof For any t \u2265 0, Lemma 2.59 implies that p = Ut p \u2208 C+ [0, 1]. Moreover, since ut := p\n(t \u2265 0) is a mild solution of (2.5.6) (recall (2.6.31)),\nZ t\n\u0001\n(t \u2265 0).\n(2.7.29)\nSs \u03b1p(1 \u2212 p) ds\np = St p +\n0\n\nHence\n\nZ t\n\u0001\nAp := lim t\u22121 (St p \u2212 p) = \u2212 lim t\u22121 Ss \u03b1 p(1 \u2212 p) ds = \u2212\u03b1 p(1 \u2212 p),\nt\u21920\n\nt\u21920\n\n(2.7.30)\n\n0\n\nwhere the limit exists in C[0, 1].\n\nIn this one-dimensional situation, the domain of A is known explicitly. One has, see [EK86,\nTheorem 8.1.1]\nn\no\n\u22022\nD(A) = f \u2208 C[0, 1] \u2229 C (2) (0, 1) : lim 12 x(1 \u2212 x) \u2202x\n(2.7.31)\n2 f (x) = 0 (r = 0, 1) .\nx\u2192r\n\nHere C[0, 1] \u2229 C (2) (0, 1) denotes the class of continuous real functions on [0, 1] that are twice\ncontinuously differentiable on (0, 1).\n\nProof of the smoothness of fixed points It suffices to show that p0,0 and p0,1 are twice\ncontinuously differentiable on [0, 1] and solve (2.5.8). The statement for p1,0 then follows by\nsymmetry, while for the constant functions 0 and p1,1 = 1 (see Proposition 2.48), the claim\nis obvious. Since p0,0 , p0,1 are fixed points under U (A, \u03b1, \u03b1), it follows from Lemma 2.67 and\nformula (2.7.31) that p0,0 , p0,1 are continuous on [0, 1], twice continuously differentiable on\n(0, 1), and solve equation (2.5.8) on (0, 1). We are done if we can show that their first and\nsecond derivatives can be extended to continuous functions on [0, 1]. (If f is twice continuously\n\u2202\n\u22022\ndifferentiable on (0, 1) and the limits limx\u2192r \u2202x\nf (x) and limx\u2192r \u2202x\n2 f (x) exists (r = 0, 1), then\nthese limits coincide with the one-sided derivatives on the boundary. This follows, for example,\nfrom Corollary 6.3 in the appendix of [EK86].)\nProposition 2.48 shows that p0,0 , p0,1 \u2264 1 and therefore, since they solve (2.5.8) on (0, 1),\np0,0 and p0,1 are concave. Proposition 2.48 also shows that p0,0 (0) = p0,0 (1) = 0 and p0,1 (0) =\n\u2202\np0,0 (x) increases\n0, p0,1 (1) = 1. (See Figure 2.4 as an illustration.) Since p0,0 is concave, \u2202x\nto a limit in (\u2212\u221e, \u221e] as x \u2193 0. Lemma 2.61 implies that this limit is finite, and therefore\n\u2202\n\u2202x p0,0 (x) is continuous at x = 0. Since p0,0 solves (2.5.8) on (0, 1),\n\u22022\n2 p0,0 (x)\n\u2202x\nx\u21920\n\nlim\n\nwhich proves that\n\u22022\n2\n\n2\u03b1p0,0 (x)(1 \u2212 p0,0 (x))\n\u2202\np0,0 (x)\n= \u22122\u03b1 \u2202x\nx\u21920\nx(1 \u2212 x)\n\n= \u2212 lim\n\n\u22022\np (x)\n\u2202x2 0,0\n\nx=0\n\n,\n\nis continuous at x = 0. The same argument proves that\n\u22022\n2\n\n(2.7.32)\n\u2202\n\u2202x p0,0 (x)\n\n\u2202\nand \u2202x p0,0 (x) are continuous at x = 1, and that \u2202x\np0,1 (x) and \u2202x p0,1 (x) are continuous\n\u2202\nat x = 0. Since p0,1 is concave, \u2202x p0,1 (x) decreases to a limit in [\u2212\u221e, \u221e) as x \u2191 1. Since\n\u2202\n\u2202\np0,1 (x) x=1 \u2265 0. Since p0,1 solves (2.5.8) on (0, 1) and \u2202x\n[p0,1 (x)(1\u2212\np0,1 (1) = 1 and p0,1 \u2264 1, \u2202x\n\u2202\np0,1 (x))] x=1 = \u2212 \u2202x p0,1 (x) x=1 ,\n2\n\n\u2202\nlim \u2202x\n2 p0,1 (x) = \u2212 lim\nx\u21911\n\nx\u21911\n\n2\u03b1p0,1 (x)(1 \u2212 p0,1 (x))\n\u2202\n= \u22122\u03b1 \u2202x\np0,1 (x)\nx(1 \u2212 x)\n\nx=1\n\n,\n\n(2.7.33)\n\n\f90\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nwhich proves that\n\n2.8\n\n\u2202\n\u2202x p0,1 (x)\n\nand\n\n\u22022\np (x)\n\u2202x2 0,1\n\nare continuous at x = 1.\n\nThe renormalization branching process: embedded particle systems\n\nIn this section we use embedded particle systems to prove Proposition 2.22. An essential\ningredient in the proofs is Proposition 2.82 (a), which will be proved in the Section 2.9.\n\n2.8.1\n\nWeighting and Poissonization\n\nProof of Proposition 2.20 Obviously qkh \u2208 C+ (E h ) for each k = 1, . . . , n. Since h \u2208 C+ (E)\nand h is bounded, it is easy to see that the map \u03bc 7\u2192 h\u03bc from M(E) into M(E h ) is continuous,\nand therefore the cluster mechanisms defined in (2.2.32) are continuous. Since\nUkh f (x) =\n\n\u0003 Uk (hf )(x)\nqk (x) \u0002\nE 1 \u2212 e \u2212hhZx , f i =\nh(x)\nh(x)\n\n(x \u2208 E h , f \u2208 B+ (E h )),\n\n(2.8.1)\n\nformula (2.2.33) holds on E h . To see that (2.2.33) holds on E\\E h , note that by assumption\nUk h \u2264 Kh for some K < \u221e, so if x \u2208 E\\E h , then Uk h(x) = 0. By monotonicity also\nk h(x)\n\u2264\nUk (hf )(x) = 0, while hUkh f (x) = 0 by definition. Since supx\u2208E h Ukh 1(x) = supx\u2208E h Uh(x)\n\nK < \u221e, the log-Laplace operators Ukh satisfy (2.2.14). If X is started in an initial state X0 ,\nthen the Poisson-cluster branching process X h with log-Laplace operators U1h , . . . , Unh started\nin X0h = hX0 satisfies\n\u0002\n\u0003\n\u0002\n\u0003\nE e \u2212hhXk , f i = E e \u2212hX0 , U1 \u25e6 * * * \u25e6 Uk (hf )i\n\u0003\n\u0003\n\u0002\n\u0002\nh\nh\nh\n= E e \u2212hX0 , hU1 \u25e6 * * * \u25e6 Uk (f )i = E e \u2212hXk , f i\n\n(f \u2208 B+ (E h )),\n(2.8.2)\n\nwhich proves (2.2.34).\n\nProof of Proposition 2.21 We start by noting that by (2.2.13),\n\u0002\n\u0003\nk\nUk f (x) = q(x)E 1 \u2212 e \u2212hZx , f i = qk (x)P [Pois(f Zxk ) 6= 0]\n\n(x \u2208 E, f \u2208 B+ (E)). (2.8.3)\n\nInto (2.2.35), we insert\n\u0002\n\u0003\nP Pois(hZxk ) \u2208 *\n\u0002\n\u0003\n= P Pois(hZxk ) \u2208 * Pois(hZxk ) 6= 0 P [Pois(hZxk ) 6= 0] + \u03b40 P [Pois(hZxk ) = 0].\n\n(2.8.4)\n\nHere and in similar formulas below, if in a conditional probability the symbol Pois( * ) occurs\ntwice with the same argument, then it always refers to the same random variable (and not to\nindependent Poisson point measures with the same intensity, for example). Using moreover\n(2.8.3) we can rewrite (2.2.35) as\nQhk (x, * ) =\n\n\u0003 h(x) \u2212 Uk h(x)\nUk h(x) \u0002\nP Pois(hZxk ) \u2208 * Pois(hZxk ) 6= 0 +\n\u03b40 ( * ).\nh(x)\nh(x)\n\n(2.8.5)\n\n\f2.8. RENORMALIZATION BRANCHING PROCESS: EMBEDDED PARTICLES\n\n91\n\nIn particular, since we are assuming that h is Uk -subharmonic, this shows that Qhk (x, * ) is\na probability measure. Let X h be the branching particle system with offspring mechanisms\nQh1 , . . . , Qhk . Let Zxh,k be random variables such that L(Zxh,k ) = Qhk (x, * ). Then, by (2.2.29),\n(2.2.35), (2.2.31), and (2.8.3),\nqk (x)\nP [Thinf (Pois(hZxk )) 6= 0]\nh(x)\nqk (x)\n1\n=\nP [Pois(hf Zxk ) 6= 0] =\nUk (hf )(x)\n(x \u2208 E h ).\nh(x)\nh(x)\n\nUkh f (x) = P [Thinf (Zxh,k ) 6= 0] =\n\n(2.8.6)\n\nIf x \u2208 E\\E h , then Uk (hf )(x) \u2264 Uk (h)(x) \u2264 h(x) = 0 =: hU h (f )(x). This proves (2.2.36). To\nsee that Qhk is a continuous offspring mechanism, by [Kal76, Theorem 4.2] it suffices to show\nR\nthat x 7\u2192 Qhk (x, d\u03bd)e \u2212h\u03bd, gi is continuous for all bounded g \u2208 C+ (E h ). Indeed, setting f :=\nR\nR\n1\u2212e\u2212g , one has Qh (x, d\u03bd)e \u2212h\u03bd, gi = Qh (x, d\u03bd)(1\u2212f )\u03bd = 1\u2212U h f (x) = 1\u2212U (hf )(x)/h(x)\nk\n\nk\n\nk\n\nk\n\nwhich is continuous on E h by the continuity of qk and Qk .\nTo see that also (2.2.37) holds, just note that by (2.2.30), (2.2.36), and (2.2.16),\nP L(Pois(h\u03bc)) [Thinf (Xnh ) = 0] = P [ThinU h \u25e6***\u25e6Unh f (Pois(h\u03bc)) = 0]\n1\n\n=\n\nP [Pois((hU1h\n\u03bc\n\n\u25e6 ***\n\n\u25e6 Unh f )\u03bc)\n\u03bc\n\n= 0] = P [Pois((U1 \u25e6 * * * \u25e6 Un (hf ))\u03bc) = 0]\n\n(2.8.7)\n\n= P [Pois(hf Xn ) = 0] = P [Thinf (Pois(hXn )) = 0].\n\nHere P L(Pois(h\u03bc)) denotes the law of the process started with initiallaw L(Pois(h\u03bc)). Since this\nformula holds for all f \u2208 B[0,1] (E h ), formula (2.2.37) follows.\nRemark 2.68 (Boundedness of h) Propositions 2.20 and 2.21 generalize to the case that\nh is unbounded, except that in this case the cluster mechanism in (2.2.32) and the offspring\nmechanism in (2.2.35) need in general not be continuous. Here, in order for (2.2.33) and\n(2.2.36) to be well-defined, one needs to extend the definition of Uk f to unbounded functions\nf , which can always be done unambiguously (see Lemma 2.53).\n\u2666\n\n2.8.2\n\nSub- and superharmonic functions\n\nThis section contains a number of pivotal calculations involving the log-Laplace operators\nU\u03b3 from (2.2.20). In particular, we will prove that the functions h1,1 , h0,0 , and h0,1 from\nLemmas 2.23, 2.24, and 2.25, respectively, are U\u03b3 -superharmonic.\nWe start with an observation that holds for general log-Laplace operators.\nLemma 2.69 (Constant multiples) Let U be a log-Laplace operator of the form (2.2.13)\nsatisfying (2.2.14) and let f \u2208 B+ (E). Then U (rf ) \u2264 rU f for all r \u2265 1, and U (rf ) \u2265 rU f\nfor all 0 \u2264 r \u2264 1. In particular, if f is U -superharmonic then rf is U -superharmonic for each\nr \u2265 1, and if f is U -subharmonic then rf is U -superharmonic for each 0 \u2264 r \u2264 1.\nProof If X is a branching process and U is the log-Laplace operator of the transition law from\nX0 to X1 then, using Jensen's inequality, for all r \u2265 1,\n\u0002\n\u0003\n\u0002\n\u0001r \u0003\n\u0002\n\u0003\u0001r\ne \u2212h\u03bc, U (rf )i = E \u03bc e \u2212hX1 , rf i = E \u03bc e \u2212hX1 , f i \u2265 E \u03bc e \u2212hX1 , f i = e \u2212h\u03bc, rU f i.\n(2.8.8)\n\n\f92\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nSince this holds for all \u03bc \u2208 M(E), it follows that U (rf ) \u2264 rU f . The proof of the statements\nfor 0 \u2264 r \u2264 1 is the same but with the inequality signs reversed.\nWe next turn our attention to the functions h1,1 and h0,0 .\nLemma 2.70 (The catalyzing function h1,1 ) One has\nU\u03b3 (rh1,1 )(x) =\n\n1+\u03b3\n1\nr +\u03b3\n\n(\u03b3, r > 0, x \u2208 [0, 1]).\n\n(2.8.9)\n\nIn particular, h1,1 is U\u03b3 -harmonic for each \u03b3 > 0.\nProof Recall (2.2.18)\u2013(2.2.20). Let \u03c31/r be an exponentially distributed random variable with\nmean 1/r, independent of \u03c4\u03b3 . Then\nR \u03c4\u03b3\n\u0002\n\u0003\n\u03b3\nU\u03b3 (rh1,1 )(x) = ( \u03b31 + 1)E 1 \u2212 e \u2212 0 rdt = ( \u03b31 + 1)P [\u03c31/r < \u03c4\u03b3 ] = ( \u03b31 + 1) 1\n, (2.8.10)\nr +\u03b3\nwhich yields (2.8.9).\n\nLemma 2.71 (The catalyzing function h0,0 ) One has U\u03b3 (rh0,0 ) \u2264 rh0,0 for each \u03b3, r > 0.\nProof Let \u0393\u03b3x be the invariant law from Corollary 2.30. Then, for any \u03b3 > 0 and f \u2208 B+ [0, 1],\n\u03b3\n\u0002\n\u0003\nU\u03b3 f (x) = ( \u03b31 + 1)E 1 \u2212 e \u2212hZx , f i \u2264 ( \u03b31 + 1)E[hZx\u03b3 , f i]\nZ\n\u0003\n\u0002 \u03c4\u03b3 \u03b3\n1\nf (yx (\u2212t/2)) dt = (1 + \u03b3)h\u0393\u03b3x , f i\n= ( \u03b3 + 1)E\n0\n\n(x \u2208 [0, 1]),\n\n(2.8.11)\n\nwhere we have used that \u03c4\u03b3 is independent of yx\u03b3 and has mean \u03b3. In particular, setting\nf = rh0,0 and using (2.3.25) we find that U\u03b3 (rh0,0 ) \u2264 rh0,0 .\nThe aim of the remainder of this section is to derive various bounds on U\u03b3 f for f \u2208 H0,1 . We\nstart with a formula for U\u03b3 f that holds for general [0, 1]-valued functions f .\n\nLemma 2.72 (Action of U\u03b3 on [0, 1]-valued functions) Let yx\u03b3 be the stationary solution to (2.2.17) and let \u03c4\u03b3/2 be an independent exponentially distributed random variable with\nmean \u03b3/2. Let (\u03b2i )i\u22651 be independent exponentially\ndistributed random variables with mean\nPk\n\u03b3\n1\n,\nindependent\nof\ny\nand\n\u03c4\n,\nand\nlet\n\u03c3\n:=\n\u03b2\n(k \u2265 0). Then\nx\ni\nk\n\u03b3/2\ni=1\n2\nh\nY\n\u0001i\n1\u2212 U\u03b3 f (x) = E\n(\u03b3 > 0, f \u2208 B[0,1] [0, 1], x \u2208 [0, 1]). (2.8.12)\n1\u2212 f (yx\u03b3 (\u2212\u03c3k ))\nk\u22650: \u03c3k <\u03c4\u03b3\n\nProof By Lemma 2.70, the constant function h1,1 (x) := 1 satisfies U\u03b3 h1,1 = h1,1 for all \u03b3 > 0.\nTherefore, by Proposition 2.21, Poissonizing the Poisson-cluster branching process X with\nh1,1\nh\nthe density h1,1 yields a branching particle system X h1,1 = (X\u2212n\n, . . . , X0 1,1 ) with generating\nh1,1\nh\noperators U\u03b3n\u22121\n, . . . , U\u03b301,1 , where\nh\n\nU\u03b3 1,1 f = U\u03b3 f\n\n(f \u2208 B[0,1] [0, 1], \u03b3 > 0).\n\n(2.8.13)\n\n\f2.8. RENORMALIZATION BRANCHING PROCESS: EMBEDDED PARTICLES\n\n93\n\nBy (2.2.29) and (2.8.5),\n\u03b3\n\u0002\n\u0003\nh\nU\u03b3 1,1 f (x) = 1 \u2212 E (1 \u2212 f )Pois(Zx ) Pois(Zx\u03b3 ) 6= 0\n\n(f \u2208 B[0,1] [0, 1], x \u2208 [0, 1], \u03b3 > 0).\n(2.8.14)\n\nTherefore, (2.8.12) will follow provided that\n\n\u0010\n\u0002\n\u0003\nP Pois(Zx\u03b3 ) \u2208 * Pois(Zx\u03b3 ) 6= 0 = L\n\nX\n\nk\u22650: \u03c3k <\u03c4\u03b3/2\n\n\u0011\n\u03b4yx\u03b3 (\u2212\u03c3k ) .\n\n(2.8.15)\n\nIndeed, it is not hard to see that\nD\n\nPois(Zx\u03b3 ) =\n\nX\n\n\u03b4yx\u03b3 (\u2212\u03c3k ) .\n\n(2.8.16)\n\nk>0: \u03c3k <\u03c4\u03b3/2\n\nThis follows from the facts that Zx\u03b3 = 2\nX\n\nR \u03c4\u03b3/2\n0\n\n\u03b4yx\u03b3 (\u2212s) ds and\nD\n\n\u03b4\u2212\u03c3k = Pois(2 1(\u2212\u03c4\u03b3/2 ,0] ).\n\n(2.8.17)\n\nk>0: \u03c3k <\u03c4\u03b3/2\n\nConditioning Pois(2 1(\u2212\u03c4\u03b3/2 ,0] ) on being nonzero means conditioning on \u03c4\u03b3/2 > \u03c31 . Since\n\u03c4\u03b3/2 \u2212 \u03c31 , conditioned on being nonnegative, is exponentially distributed with mean \u03b3/2,\nusing the stationarity of yx\u03b3 , we arrive at (2.8.15).\nThe next lemma generalizes the duality (2.3.22) to mixed moments of the Wright-Fisher\ndiffusion y at multiple times. We can interpret the left-hand side of (2.8.18) as the probability\nthat m1 , . . . , mn organisms sampled from the population at times t1 , . . . , tn are all of the\ngenetic type I.\nLemma 2.73 (Sampling at multiple times) Fix 0 \u2264 t1 < * * * < tn = t and nonnegative\nintegers m1 , . . . , mn . Let y be the diffusion in (2.3.20). Then\nEy\n\nn\nhY\n\nk=1\n\ni\n\u0003\n\u0002\nytmk k = E y \u03c6t x\u03c8t ,\n\n(2.8.18)\n\nwhere (\u03c6s , \u03c8s )s\u2208[0,t] is a Markov process in N2 started in (\u03c60 , \u03c80 ) = (mn , 0), that jumps deterministically as\n(\u03c6s , \u03c8s ) \u2192 (\u03c6s + mk , \u03c8s ) at time t \u2212 tk (k < n),\n(2.8.19)\nand between these deterministic times jumps with rates as in (2.3.21).\nProof Induction, with repeated application of (2.3.22).\nFor any m \u2265 1, we put\n\nhm (x) := 1 \u2212 (1 \u2212 x)m\n\n(x \u2208 [0, 1]).\n\n(2.8.20)\n\nThe next lemma shows that we have particular good control on the action of U\u03b3 on the\nfunctions hm .\n\n\f94\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nLemma 2.74 (Action of U\u03b3 on the functions hm ) Let m \u2265 1 and let \u03c4\u03b3 be an exponentially\ndistributed random variable with mean \u03b3. Conditional on \u03c4\u03b3 , let (\u03c6\u2032t , \u03c8t\u2032 )t\u22650 be a Markov process\nin N2 , started in (\u03c6\u20320 , \u03c80\u2032 ) = (m, 0) that jumps at time t as:\n(\u03c6\u2032t , \u03c8t\u2032 ) \u2192 (\u03c6\u2032t \u2212 1, \u03c8t\u2032 )\n(\u03c6\u2032t , \u03c8t\u2032 ) \u2192 (\u03c6\u2032t \u2212 1, \u03c8t\u2032 + 1)\n(\u03c6\u2032t , \u03c8t\u2032 ) \u2192 (\u03c6\u2032t + m, \u03c8t\u2032 )\n\nwith rate \u03c6\u2032t (\u03c6\u2032t \u2212 1),\nwith rate \u03b31 \u03c6\u2032t ,\nwith rate 1{\u03c4\u03b3/2 <t} .\n\n\u2032 exists a.s., and\nThen the limit limt\u2192\u221e \u03c8t\u2032 =: \u03c8\u221e\n\u0002\n\u2032 \u0003\nU\u03b3 hm (x) = E (m,0) 1 \u2212 (1 \u2212 x)\u03c8\u221e\n\n(m \u2265 1, x \u2208 [0, 1]).\n\n(2.8.21)\n\n(2.8.22)\n\nProof Let yx\u03b3 , \u03c4\u03b3/2 , and (\u03c3k )k\u22650 be as in Lemma 2.72. Then, by (2.8.12),\nU\u03b3 hm (x) = 1 \u2212 E\n\nh\n\nY\n\nk\u22650: \u03c3k <\u03c4\u03b3/2\n\n\u0001m i\n.\n1 \u2212 yx\u03b3 (\u2212\u03c3k )\n\n(2.8.23)\n\nLet (\u03c6\u2032 , \u03c8 \u2032 ) = (\u03c6\u2032t , \u03c8t\u2032 )t\u22650 be a N2 -valued process started in (\u03c6\u20320 , \u03c80\u2032 ) = (m, 0) such that conditioned on \u03c4\u03b3 and (\u03c3k )k\u22650 , (\u03c6\u2032 , \u03c8 \u2032 ) is a Markov process that jumps deterministically as\n(\u03c6\u2032t , \u03c8t\u2032 ) \u2192 (\u03c6\u2032t + m, \u03c8s\u2032 ) at time \u03c3k\n\n(k \u2265 1 : \u03c3k < \u03c4\u03b3/2 )\n\n(2.8.24)\n\n\u2032 ) as t \u2192 \u221e\nand between these times jumps with rates as in (2.3.21). Then (\u03c6\u2032t , \u03c8t\u2032 ) \u2192 (0, \u03c8\u221e\n\u2032 , and (2.8.22) follows from Lemma 2.73, using the\na.s. for some N-valued random variable \u03c8\u221e\nsymmetry y \u2194 1 \u2212 y. Since \u03c3k+1 \u2212 \u03c3k are independent exponentially distributed random\nvariables with mean one, (\u03c6\u2032 , \u03c8 \u2032 ) is the Markov process with jump rates as in (2.8.21).\n\nThe next result is a simple application of Lemma 2.74.\nLemma 2.75 (The catalyzing function h1 ) The function h1 (x) := x (x \u2208 [0, 1]) is U\u03b3 subharmonic for each \u03b3 > 0.\n\u2032\n\n\u2032 \u2265 1 a.s., one has 1 \u2212 (1 \u2212 x)\u03c8\u221e \u2265 x a.s. (x \u2208 [0, 1]) in (2.8.22). In particular,\nProof Since \u03c8\u221e\nsetting m = 1 yields U\u03b3 h1 \u2265 h1 .\n\nWe now set out to prove that h7 , which is the function h0,1 from Lemma 2.25, is U\u03b3 -super\u2032 . We derive\nharmonic. In order to do so, we will derive upper bounds on the expectation of \u03c8\u221e\ntwo estimates: one that is good for small \u03b3 and one that is good for large \u03b3.\nIn order to avoid tedious formal arguments, it will be convenient to recall the interpretation\nof the process (\u03c6\u2032 , \u03c8 \u2032 ) and Lemma 2.73. Recall from the discussion following (2.3.22) that\n(yx\u03b3 (t))t\u2208R describes the equilibrium frequency of genetic type I as a function of time in a\npopulation that is in genetic exchange with an infinite reservoir. From this population we\nsample at times \u2212\u03c3k (k \u2265 0, \u03c3k < \u03c4\u03b3/2 ) each time m individuals, and ask for the probability\nthat they are not all of the genetic type II. In order to find this probability, we follow the\nancestors of the sampled individuals back in time. Then \u03c6\u2032t and \u03c8t\u2032 are the number of ancestors\n\u2032\nthat lived at time \u2212t in the population and the reservoir, respectively, and E[1 \u2212 (1 \u2212 x)\u03c8\u221e ]\nis the probability that at least one ancestor is of type I.\n\n\f2.8. RENORMALIZATION BRANCHING PROCESS: EMBEDDED PARTICLES\n\n95\n\nLemma 2.76 (Bound for small \u03b3) For each \u03b3 \u2208 (0, \u221e) and m \u2265 1,\nm\u22121\n1 X 1+\u03b3\n1 (m,0) \u2032\nE\n[\u03c8\u221e ] \u2264\n=: \u03c7m (\u03b3).\nm\nm\n1 + i\u03b3\n\n(2.8.25)\n\ni=0\n\nThe function \u03c7m is concave and satisfies \u03c7m (0) = 1 for each m \u2265 1.\nProof Note that\n\u0002\n\u0003\nE {k \u2265 0 : \u03c3k < \u03c4\u03b3/2 } = 1 + \u03b3.\n\n(2.8.26)\n\n\u2032\n] \u2264 (1 + \u03b3)E (m,0) [\u03c8\u221e ],\nE (m,0) [\u03c8\u221e\n\n(2.8.27)\n\nWe can estimate (\u03c6\u2032 , \u03c8 \u2032 ) from above by a process where ancestors from individuals sampled\nat different times cannot coalesce. Therefore,\n\nwhere (\u03c6, \u03c8) is the Markov process in (2.3.21). Note that if (\u03c6, \u03c8) is in the state (m + 1, 0),\nthen the next jump is to (m, 1) with probability\n1\n\u03b3 (m\n1\n\u03b3 (m\n\n+ 1)\n\n+ 1) + m(m + 1)\n\n1\n1 + m\u03b3\n\n=\n\n(2.8.28)\n\nand to (m, 0) with one minus this probability. Therefore,\n\u0010\n1\n1 \u0011 (m,0)\nE\n[\u03c8\u221e ]\nE (m,1) [\u03c8\u221e ] + 1 \u2212\n1 + m\u03b3 \u0010\n1\u0010+ m\u03b3\n\u0011\n\u0011\n1\n1\n=\nE (m,0) [\u03c8\u221e ] + 1 + 1 \u2212\nE (m,0) [\u03c8\u221e ]\n1 + m\u03b3\n1 + m\u03b3\n1\n= E (m,0) [\u03c8\u221e ] +\n.\n1 + m\u03b3\n\nE (m+1,0) [\u03c8\u221e ] =\n\n(2.8.29)\n\nBy induction, it follows that\nE (m,0) [\u03c8\u221e ] =\n\nm\u22121\nX\ni=0\n\n1\n.\n1 + i\u03b3\n\n(2.8.30)\n\nInserting this into (2.8.27) we arrive at (2.8.25). Finally, since\n2i(i \u2212 1)\n\u22022 1 + \u03b3\n2 1 + i\u03b3 = (1 + i\u03b3)3 \u2265 0\n\u2202\u03b3\n\n(i \u2265 0, \u03b3 \u2265 0),\n\n(2.8.31)\n\nthe function \u03c7m is convex.\nLemma 2.77 (Bound for large \u03b3) For each \u03b3 \u2208 (0, \u221e) and m \u2265 1,\nE\n\n(m,0)\n\n\u2032\n[\u03c8\u221e\n]\n\n\u2264\n\n( \u03b31\n\n+ 1)\n\nm\nX\n1\nk=1\n\n3\n+ .\nk 2\n\n(2.8.32)\n\n\f96\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\u2202\n\u2032\n\u2202t E[\u03c8t ]\n\nProof We start by observing that\n\n\u2032\nE[\u03c8\u221e\n]\n\n= \u03b31 E[\u03c6\u2032t ], and therefore\n\n=\n\n1\n\u03b3\n\nZ\n\n\u221e\n\n0\n\nE[\u03c6\u2032t ]dt.\n\n(2.8.33)\n\nUnlike in the proof of the last lemma, this time we cannot fully ignore the coalescence of\nancestors sampled at different times. In order to deal with this we use a trick: at time zero we\nintroduce an extra ancestor that can only jump to the reservoir when t \u2265 \u03c4\u03b3 and there are no\nother ancestors left in the population. We further assume that all other ancestors do not jump\nto the reservoir on their own. Let \u03bet be one as long as this extra ancestor is in the population\nand zero otherwise, and let \u03c6\u2032\u2032t be the number of other ancestors in the population according\nto these new rules. Then we have at a Markov process (\u03be, \u03c6\u2032\u2032 ) started in (\u03be0 , \u03c6\u2032\u20320 ) = (1, m) that\njumps as:\n(\u03bet , \u03c6\u2032\u2032t ) \u2192 (\u03bet , \u03c6\u2032\u2032t \u2212 1)\nwith rate (\u03c6\u2032\u2032t + 1)\u03c6\u2032\u2032t ,\n\u2032\u2032\n\u2032\u2032\n(\u03bet , \u03c6t ) \u2192 (\u03bet , \u03c6t + m)\nwith rate 1{\u03c4\u03b3/2 <t} ,\n(2.8.34)\n1\n\u2032\u2032\n\u2032\u2032\nwith rate \u03b3 1{\u03c4\u03b3/2 \u2265t} 1{\u03c6\u2032\u2032t =0} .\n(\u03bet , \u03c6t ) \u2192 (\u03bet \u2212 1, \u03c6t )\nIt is not hard to show that (\u03be, \u03c6\u2032\u2032 ) and \u03c6\u2032 can be coupled such that \u03bet + \u03c6\u2032\u2032t \u2265 \u03c6\u2032t for all t \u2265 0.\nWe now simplify even further and ignore all coalescence between ancestors belonging to the\n(k)\nprocess \u03c6\u2032\u2032 that are introduced at different times. Let \u03c6t be the number of ancestors in the\n(k)\npopulation that were introduced at the time \u03c3k (k \u2265 0). Thus, for t < \u03c3k one has \u03c6t = 0,\n(k)\n(k)\nfor t = \u03c3k one has \u03c6t = m, while for t > \u03c3k , the process \u03c6t jumps from n to n \u2212 1 with rate\nP\n(k)\n(n + 1)n. Then it is not hard to see that, for an appropriate coupling, \u03c6\u2032\u2032t \u2264 k\u22650:\u03c3k <\u03c4\u03b3/2 \u03c6t\nfor all t \u2265 0. We let \u03be \u2032 be a process such that \u03be0\u2032 = 1 and \u03bet\u2032 jumps to zero with rate\n1\n1\n\u03b3 {\u03c4\u03b3/2 \u2265t}\n\nY\n\n1{\u03c6(k) =0} .\n\n(2.8.35)\n\nt\n\nk\u22650:\u03c3k <\u03c4\u03b3/2\n\nThen for an appropriate coupling \u03bet\u2032 \u2265 \u03bet (t \u2265 0). Thus, we can estimate\nZ\n\n0\n\n\u221e\n\nE[\u03c6\u2032t ]dt\n(k)\n\nSet \u03c1 := inf{t \u2265 \u03c4\u03b3/2 : \u03c6t\nZ\n\n\u221e\n0\n\n\u2264\n\nZ\n\n\u221e\n\n0\n\nE[\u03bet\u2032 ]dt +\n\nZ\n\n\u221e\n\nE\n0\n\nh\n\n(k)\n\nX\n\n\u03c6t\n\nk\u22650:\u03c3k <\u03c4\u03b3/2\n\ni\n\ndt.\n\n(2.8.36)\n\n= 0 \u2200k \u2265 0 with \u03c3k < \u03c4\u03b3/2 } and \u03c0 := inf{t \u2265 0 : \u03bet\u2032 = 0}. Then\n\n3\nE[\u03bet\u2032 ]dt = E[\u03c4\u03b3/2 ] + E[\u03c1 \u2212 \u03c4\u03b3/2 ] + E[\u03c0 \u2212 \u03c1] = \u03b3 + E[\u03c1 \u2212 \u03c4\u03b3/2 ].\n2\n\nSince\nE[\u03c1 \u2212 \u03c4\u03b3/2 ] \u2264\n\u2264\n\nZ\n\n0\n\nZ\n\n0\n\n\u221e\n\n\u221e\n\nh\nE 1{P\nE\n\nh\n\n(k)\nk\u22650:\u03c3k <\u03c4\u03b3/2 \u03c6t 6=0}\n\nX\n\nk\u22650:\u03c3k <\u03c4\u03b3/2\n\ni\n\ndt\n\ni\n1{\u03c6(k) 6=0} dt,\nt\n\n(2.8.37)\n\n(2.8.38)\n\n\f97\n\n2.8. RENORMALIZATION BRANCHING PROCESS: EMBEDDED PARTICLES\nusing moreover (2.8.36) and (2.8.37), we can estimate\nZ \u221e h\nZ \u221e\ni\nX\n3\n(k)\n\u2032\nE\nE[\u03c6t ]dt \u2264 \u03b3 +\n(\u03c6t + 1{\u03c6(k) 6=0} ) dt.\nt\n2\n0\n0\n\n(2.8.39)\n\nk\u22650:\u03c3k <\u03c4\u03b3/2\n\n\u0002\n\u0003\nSince E {k \u2265 0 : \u03c3k < \u03c4\u03b3/2 } = 1 + \u03b3, we obtain\nZ \u221e\nZ \u221e\n3\n(0)\n\u2032\nE[\u03c6t ]dt \u2264 \u03b3 + (1 + \u03b3)\nE[\u03c6t + 1{\u03c6(0) 6=0} ]dt.\nt\n2\n0\n0\n\n(2.8.40)\n(0)\n\n(0)\n\nSince \u03c6t jumps from n to n \u2212 1 with rate (n + 1)n, the expected total time that \u03c6t = n\nequals 1/((n + 1)n), and therefore\nZ \u221e\nm\nm\nX\nX\n1\n1\n(0)\nE[\u03c6t + 1{\u03c6(0) 6=0} ]dt =\n(n + 1{n6=0} ) =\n.\n(2.8.41)\nt\n(n\n+\n1)n\nn\n0\nn=1\n\nn=1\n\nInserting this into (2.8.40), using (2.8.33), we arrive at (2.8.32).\nLemma 2.78 (The catalyzing function h0,1 ) One has U\u03b3 (h0,1 ) \u2264 h0,1 for each \u03b3 > 0.\nMoreover, for each r > 1 and \u03b3 > 0,\nU\u03b3 (rh0,1 )(x)\n< 1.\nrh0,1 (x)\nx\u2208(0,1]\n\n(2.8.42)\n\nsup\n\nProof Recall that h0,1 (x) = h7 (x) = 1 \u2212 (1 \u2212 x)7 (x \u2208 [0, 1]). We will show that\n\u2032\nE (7,0) [\u03c8\u221e\n]<7\n\n(2.8.43)\n\nfor each \u03b3 \u2208 (0, \u221e). The function \u03c7m (\u03b3) from Lemma 2.76 satisfies\nm\n\n\u03c7m (1) =\n\n1 X2\n<1\nm\nn\nn=1\n\n(m \u2265 5).\n\n(2.8.44)\n\nSince \u03c7m (\u03b3) is concave in \u03b3 and satisfies \u03c7m (0) = 1, it follows that \u03c7m (\u03b3) < 1 for all 0 < \u03b3 \u2264 1\nand m \u2265 5. By Lemma 2.77, for all \u03b3 \u2265 1,\n\u2032\nE (m,0) [\u03c8\u221e\n]\u22642\n\nm\nX\n1\nk=1\n\nk\n\n+\n\n3\n<m\n2\n\n(m \u2265 7).\n\n(2.8.45)\n\n\u2032 ] < m. It follows by (2.8.22) and Jensen's inequality\nTherefore, if m \u2265 7, then m\u2032 := E (m,0) [\u03c8\u221e\napplied to the concave function z 7\u2192 1 \u2212 (1 \u2212 x)z that\n\nU\u03b3 hm (x) \u2264 1 \u2212 (1 \u2212 x)E\n\n(m,0) [\u03c8 \u2032 ]\n\u221e\n\n\u2032\n\n= 1 \u2212 (1 \u2212 x)m \u2264 hm (x)\n\n(x \u2208 [0, 1], \u03b3 > 0).\n\n(2.8.46)\n\nThis shows that hm is U\u03b3 -superharmonic for each \u03b3 > 0. By Lemma 2.69, for each r > 1,\n\u2032\n\nU\u03b3 (rhm )(x)\nrU\u03b3 (hm )(x)\n1 \u2212 (1 \u2212 x)m\n\u2264\n\u2264\nrhm (x)\nrhm (x)\n1 \u2212 (1 \u2212 x)m\n\n(x \u2208 (0, 1]).\n\n(2.8.47)\n\n\f98\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nBy Lemma 2.70 and the monotonicity of U\u03b3 ,\nU\u03b3 (rhm )(x)\n1\nU\u03b3 (r)(x)\n1+\u03b3\n\u2264\n\u2264\nrhm (x)\nrhm (x)\n1 + r\u03b3 (1 \u2212 (1 \u2212 x)m )\n\n(x \u2208 (0, 1]).\n\n(2.8.48)\n\nSince the right-hand side of (2.8.47) is smaller than 1 for x \u2208 (0, 1) and tends to m\u2032 /m < 1 as\nx \u2192 0, since the right-hand side of (2.8.48) is smaller than 1 for x in an open neighborhood\nof 1, and since both bounds are continuous, (2.8.42) follows.\n\n2.8.3\n\nExtinction versus unbounded growth\n\nIn this section we show that Lemmas 2.23\u20132.25 are equivalent to Proposition 2.26. (This\nfollows from the equivalence of conditions (i) and (ii) in Lemma 2.79 below.) We moreover\nprove Lemmas 2.23 and 2.25 and prepare for the proof of Lemma 2.24. We start with some\ngeneral facts about log-Laplace operators and branching processes.\nFor the next lemma, let E be a separable, locally compact, metrizable space. For n \u2265 0,\nlet qn \u2208 C+ (E) be continuous weight functions, let Qn be continuous cluster mechanisms on E,\nand assume that the associated log-Laplace operators Un defined in (2.2.13) satisfy (2.2.14).\nAssume that 0 6= h \u2208 C+ (E) is bounded and Un -superharmonic for all n, let E h := {x \u2208 E :\nh(x) > 0}, and define generating operators Unh : B[0,1] (E h ) \u2192 B[0,1] (E) as in (2.2.36). For\n(n)\n\n(n)\n\neach n \u2265 0, let (X0 , X1 ) be a one-step Poisson cluster branching process with log-Laplace\n(n),h\n(n),h\noperator Un , and let (X0 , X1 ) be the one-step branching particle system with generating\nh\noperator Un . (In a typical application of this lemma, the operators Un will be iterates of other\n(n)\n(n)\nlog-Laplace operators, and X0 , X1 will be the initial and final state, respectively, of a\nPoisson cluster branching process with many time steps.)\nLemma 2.79 (Extinction versus unbounded growth) Assume that \u03c1 \u2208 C[0,1] (E h ) and\nput\n\u001a\nh(x)\u03c1(x)\nif x \u2208 E h ,\np(x) :=\n(2.8.49)\n0\nif x \u2208 E\\E h .\nThen the following statements are equivalent:\n\u0002 (n),h\n\u0003\n(i) P \u03b4x |X1 | \u2208 * =\u21d2 \u03c1(x)\u03b4\u221e + (1 \u2212 \u03c1(x))\u03b40\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E h ,\n\u0002 (n)\n\u0003\n\u0001\n(ii) P \u03b4x hX1 , hi \u2208 * =\u21d2 e \u2212p(x) \u03b40 + 1 \u2212 e \u2212p(x) \u03b4\u221e\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E,\n\n(iii) Un (\u03bbh)(x) \u2212\u2192 p(x)\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E\n\n(iv) \u22030 < \u03bb1 < \u03bb2 < \u221e :\n\n\u2200\u03bb > 0,\n\nUn (\u03bbi h)(x) \u2212\u2192 p(x)\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E\n\n(i = 1, 2).\n\n\f2.8. RENORMALIZATION BRANCHING PROCESS: EMBEDDED PARTICLES\n\n99\n\nProof of Lemma 2.79 It is not hard to see that (i) is equivalent to\n(n),h\n\nP \u03b4x [Thin\u03bb (X1\n\n) 6= 0] \u2212\u2192 \u03c1(x)\n\n(2.8.50)\n\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E h , for all 0 < \u03bb \u2264 1. It follows from (2.2.30) and (2.2.36) that\n(n),h\nh(x)P \u03b4x [Thin\u03bb (X1 ) 6= 0] = hU h (\u03bb)(x) = U (\u03bbh)(x) (x \u2208 E), so (i) is equivalent to\n(i)\u2032\n\nUn (\u03bbh)(x) \u2212\u2192 p(x)\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E\n\n\u22000 < \u03bb \u2264 1.\n\nBy (2.2.15), condition (ii) implies that\n\ne \u2212Un (\u03bbh)(x) = E \u03b4x e \u2212\u03bbhX1 , hi \u2212\u2192 e \u2212p(x)\n\u0002\n\n\u0003\n\nn\u2192\u221e\n\n(2.8.51)\n\nlocally uniformly for x \u2208 E for all \u03bb > 0, and therefore (ii) implies (iii). Obviously (iii)\u21d2\n(i)\u2032 \u21d2(iv) so we are done if we show that (iv)\u21d2(ii). Indeed, (iv) implies that\n(n)\n(n)\n\u0003\n\u0002\nE \u03b4x e \u2212\u03bb1 hX1 , hi \u2212 e \u2212\u03bb2 hX1 , hi \u2212\u2192 0\nn\u2192\u221e\n\nlocally uniformly for x \u2208 E, which shows that\n\u0002\n\u0003\n(n)\nP \u03b4x c < hX1 , hi < C \u2212\u2192 0\n\n(2.8.52)\n\n(2.8.53)\n\nn\u2192\u221e\n\nfor all 0 < c < C < \u221e. Using (iv) once more we arive at (ii).\n\nOur next lemma gives sufficient conditions for the n-th iterates of a single log-Laplace operator U to satisfy the equivalent conditions of Lemma 2.79. Let E (again) be separable,\nlocally compact, and metrizable. Let q \u2208 C+ (E) be a weight function, Q a continuous cluster\nmechanism on E, and assume that the associated log-Laplace operator U defined in (2.2.13)\nsatisfies (2.2.14). Let X = (X0 , X1 , . . .) be the Poisson-cluster branching process with logLaplace operator U in each step, let 0 6= h \u2208 C+ (E) be bounded and U -superharmonic, and\nlet X h = (X0h , X1h , . . .) denote the branching particle system on E h obtained from X by\nPoissonization with a U -superharmonic function h, in the sense of Proposition 2.21.\nLemma 2.80 (Sufficient condition for extinction versus unbounded growth) Assume\nthat\nU h(x)\n< 1.\n(2.8.54)\nsup\nx\u2208E h h(x)\nThen the process X h started in any initial law L(X0h ) \u2208 M1 (E h ) satisfies\nlim |Xkh | = \u221e\n\nk\u2192\u221e\n\nor\n\n\u2203k \u2265 0 s.t. Xkh = 0\n\na.s.\n\n(2.8.55)\n\nMoreover, if the function \u03c1 : E h \u2192 [0, 1] defined by\n\u03c1(x) := P \u03b4x [Xnh 6= 0\n\n\u2200n \u2265 0]\n\nsatisfies inf x\u2208E h \u03c1(x) > 0, then \u03c1 is continuous.\n\n(x \u2208 E h )\n\n(2.8.56)\n\n\f100\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nProof of Lemma 2.80 Let A denote the tail event A = {Xnh 6= 0 \u2200n \u2265 0} and let (Fk )k\u22650\nbe the filtration generated by X h . Then, by the Markov property and continuity of the\nconditional expectation with respect to increasing limits of \u03c3-fields (see Complement 10(b)\nfrom [Loe63, Section 29] or [Loe78, Section 32])\nP [Xnh 6= 0 \u2200n \u2265 0|Xk ] = P (A|Fk ) \u2212\u2192 1A\nk\u2192\u221e\n\na.s.\n\n(2.8.57)\n\nh\n= 0|Xkh ] \u2192 0 a.s.\nIn particular, this implies that a.s. on the event A one must have P [Xk+1\nh\nh\n\u03b4\nx\nBy (2.2.30) and (2.2.36), P [X1 6= 0] = U 1(x) = (U h(x))/h(x), which is uniformly bounded\nh\n= 0|Xkh ] \u2192 0 a.s. on A is only possible if the\naway from one by (2.8.54). Therefore, P [Xk+1\nnumber of particles tends to infinity.\nThe continuity of \u03c1 can be proved by a straightforward adaptation of the proof of [FS04,\nProposition 5 (d)] to the present setting with discrete time and noncompact space E. An\nessential ingredient in the proof, apart from (2.8.54), is the fact that the map \u03bd 7\u2192 P \u03bd [Xnh \u2208 * ]\nfrom N (E) to M1 (N (E)) is continuous, which follows from the continuity of Qh .\n\nWe now turn our attention more specifically to the renormalization branching process\nP X . In\nthe remainder of this section, (\u03b3k )k\u22650 is a sequence of positive constants such that n \u03b3n = \u221e\nand \u03b3n \u2192 \u03b3 \u2217 for some \u03b3 \u2217 \u2208 [0, \u221e), and X = (X\u2212n , . . . , X0 ) is the Poisson cluster branching\nprocess on [0, 1] defined in Section 2.2.4. We put U (n) := U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b30 . If 0 6= h \u2208 C[0, 1]\nis U\u03b3k -superharmonic for all k \u2265 0, then X h and X h denote the branching process and the\nbranching particle system on {x \u2208 [0, 1] : h(x) > 0} obtained from X by weighting and\nPoissonizing with h in the sense of Propositions 2.20 and 2.21, respectively.\nProof of Lemma 2.23 By induction, it follows from Lemma 2.70 that\nU\n\n(n)\n\nQn\u22121\n\n(\u03bbh1,1 ) = Qn\u22121\n\nk=0 (1\n\nk=0 (1\n\n+ \u03b3k )\n\n+ \u03b3k ) \u2212 1 +\n\n(\u03bb > 0).\n\n1\n\u03bb\n\n(2.8.58)\n\nIt is not hard to see (compare the footnote at (2.1.42)) that\n\u221e\nY\n\n(1 + \u03b3k ) = \u221e\n\nif and only if\n\nk=0\n\nTherefore, since we are assuming that\n\nP\n\n\u221e\nX\nk=0\n\nn \u03b3n\n\n\u03b3k = \u221e.\n\n(2.8.59)\n\n= \u221e,\n\nU (n) (\u03bbh1,1 ) \u2212\u2192 h1,1 ,\nn\u2192\u221e\n\n(2.8.60)\n\nuniformly on [0, 1] for all \u03bb > 0. The result now follows from Lemma 2.79 (with h = h1,1 and\n\u03c1(x) = 1 (x \u2208 [0, 1])).\nRemark 2.81 (Conditions on (\u03b3n )n\u22650 ) Our proof of Lemma 2.23Pdoes not use that \u03b3n \u2192 \u03b3 \u2217\nfor some \u03b3 \u2217 \u2208 [0, \u221e). On the other hand, the proof shows that n \u03b3n = \u221e is a necessary\ncondition for (2.2.40).\n\u2666\n\n\f101\n\n2.8. RENORMALIZATION BRANCHING PROCESS: EMBEDDED PARTICLES\n\nWe do not know if the assumption that \u03b3n \u2192 \u03b3 \u2217 for some \u03b3 \u2217 \u2208 [0, \u221e) is needed in Lemma 2.24.\nWe guess that it can be dropped, but it will greatly simplify proofs to have it around.\nWe will show that in order to prove Lemmas 2.24 and 2.25, it suffices to prove their ana\u2217\nlogues for embedded particle systems in the time-homogeneous processes Y \u03b3 (\u03b3 \u2217 \u2208 [0, \u221e)).\nMore precisely, we will derive Lemmas 2.24 and 2.25 from the following two results. Below, (Ut0 )t\u22650 is the log-Laplace semigroup of the super-Wright-Fisher diffusion Y 0 , defined in\n(2.2.26). The functions p\u22170,1,\u03b3 \u2217 (\u03b3 \u2217 \u2208 [0, \u221e)) are defined in (2.2.45).\nProposition 2.82 (Time-homogeneous embedded particle system with h0,0 )\n(a) For any \u03b3 \u2217 > 0, one has (U\u03b3 \u2217 )n h0,0 \u2212\u2192 0 uniformly on [0, 1].\nn\u2192\u221e\n\n(b) One has Ut0 h0,0 \u2212\u2192 0 uniformly on [0, 1].\nt\u2192\u221e\n\nProposition 2.83 (Time-homogeneous embedded particle system with h0,1 )\n(a) For any \u03b3 \u2217 > 0, one has (U\u03b3 \u2217 )n (\u03bbh0,1 ) \u2212\u2192 p\u22170,1,\u03b3 \u2217 uniformly on [0, 1], for all \u03bb > 0.\nn\u2192\u221e\n\n(b) One has\n\nUt0 (\u03bbh0,1 )\n\n\u2212\u2192 p\u2217\nt\u2192\u221e 0,1,0\n\nuniformly on [0, 1], for all \u03bb > 0.\n\nPropositions 2.82 (b) and 2.83 (b) follow from Proposition 2.47. Proposition 2.82 (a) will be\nproved in Section 2.9.2.\nProof of Proposition 2.83 (a) By formula (2.8.42) from Lemma 2.78, for each r > 1 the\n\u03b3 \u2217 ,rh0,1\nfunction rh0,1 satisfies condition (2.8.54) from Lemma 2.80. Set \u03c1(x) := P \u03b4x [Yn\n6= 0 \u2200n].\nThen, by (2.2.30) and (2.2.36),\n\u03b3 \u2217 ,rh0,1\n\n\u03c1(x) = lim P \u03b4x [Yn\nn\u2192\u221e\n\nrh\n\n6= 0] = lim (U\u03b3 \u2217 0,1 )n 1(x)\nn\u2192\u221e\n\n(U\u03b3 \u2217 )n (rh0,1 )(x)\nh1 (x)\n\u2265\nn\u2192\u221e\nrh0,1 (x)\nrh0,1 (x)\n\n= lim\n\n(x \u2208 (0, 1]),\n\n(2.8.61)\n\nwhere h1 (x) = x (x \u2208 [0, 1]) is the U\u03b3 \u2217 -subharmonic function from Lemma 2.75. It follows\nthat inf x\u2208(0,1] \u03c1(x) > 0 and therefore, by Lemma 2.80, \u03c1 is continuous in x.\nBy Lemma 2.80, we see that the Poissonized particle system X rh0,1 exhibits extinction\nversus unbounded growth in the sense of Lemma 2.79, which implies the statement in Proposition 2.83 (a).\nWe now show that Propositions 2.82 and 2.83 imply Lemmas 2.24 and 2.25, respectively.\nProof of Lemma 2.24 We start with the proof that the embedded particle system X h0,0 is\ncritical. For any f \u2208 B+ [0, 1] and k \u2265 1, we have, by Poissonization (Proposition 2.21) and\nthe definition of X ,\nh\n\nh\n\n0,0\n0,0\nh0,0 (x)E \u2212k,\u03b4x [hX\u2212k+1\n, f i] = E \u2212k,L(Pois(h0,0 \u03b4x )) [hX\u2212k+1\n, f i] = E \u2212k,\u03b4x [hPois(h0,0 X\u2212k+1 ), f i]\n\n\u03b3\n\n= E \u2212k,\u03b4x [hX\u2212k+1 , h0,0 f i] = ( \u03b31 + 1)E[hZx\u03b3 , h0,0 f i] = ( \u03b31 + 1)h\u0393xk\u22121 , h0,0 f i,\n\nwhere \u0393\u03b3x is the invariant law of yx\u03b3 from Corollary\nh0,0\n|] = h0,0 (x) by (2.3.25).\nh0,0 (x)E \u2212k,\u03b4x [|X\u2212k+1\n\n(2.8.62)\n2.30. In particular, setting f = 1 gives\n\n\f102\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\nTo prove (2.2.41), by Lemma 2.79 it suffices to show that\nU (n) (\u03bbh0,0 ) \u2212\u2192 0\n\n(2.8.63)\n\nn\u2192\u221e\n\nuniformly on [0, 1] for all 0 < \u03bb \u2264 1. We first treat the case \u03b3 \u2217 > 0. Then, by Theorem 2.19 (a),\nfor each fixed l \u2265 1 and f \u2208 C+ [0, 1],\nU\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l f \u2212\u2192 (U\u03b3 \u2217 )l f\n\n(2.8.64)\n\nn\u2192\u221e\n\nuniformly on [0, 1]. Therefore, by a diagonal argument, we can find l(n) \u2192 \u221e such that\n(U\u03b3 \u2217 )l(n) h0,0 \u2212 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l(n) h0,0\n\n\u2212\u2192 0.\n\n\u221e n\u2192\u221e\n\n(2.8.65)\n\nUsing the fact that the function h0,0 is U\u03b3 -superharmonic for each \u03b3 > 0 and the monotonicity\nof the operators U\u03b3 , we derive from Proposition 2.82 (a) that\nU (n) (\u03bbh0,0 ) \u2264 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l(n) h0,0 \u2212\u2192 0\nn\u2192\u221e\n\n(2.8.66)\n\nuniformly on [0, 1] for all 0 < \u03bb \u2264 1. This proves (2.8.63) in the case \u03b3 \u2217 > 0.\nThe proof in the case \u03b3 \u2217 = 0 is similar. In this case, by Theorem 2.19 (b), for each fixed\nt > 0 and f \u2208 C+ [0, 1],\nU\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3kn (t) f (xn ) \u2212\u2192 Ut0 f (x)\nn\u2192\u221e\n\n\u2200xn \u2192 x \u2208 [0, 1],\n\n(2.8.67)\n\nwhich shows that U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3kn (t) f converges to Ut0 f uniformly on [0, 1]. By a diagonal\nargument, we can find t(n) \u2192 \u221e such that\nUt0 (h0,0 ) \u2212 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3kn (t(n)) (h0,0 )\n\n\u2212\u2192 0,\n\n\u221e n\u2192\u221e\n\n(2.8.68)\n\nand the proof proceeds in the same way as before.\nProof of Lemma 2.25 By Lemma 2.79 and the monotonicity of the operators U\u03b3 it suffices\nto show that\n(i) lim sup U (n) (h0,1 ) \u2264 p\u22170,1,\u03b3 \u2217 ,\nn\u2192\u221e\n(2.8.69)\n(ii) lim inf U (n) ( 21 h0,1 ) \u2265 p\u22170,1,\u03b3 \u2217 ,\nn\u2192\u221e\n\nuniformly on [0, 1]. We first consider the case \u03b3 \u2217 > 0. By (2.8.64) and a diagonal argument,\nwe can find l(n) \u2192 \u221e such that\n(U\u03b3 \u2217 )l(n) h0,1 \u2212 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l(n) h0,1\n\n\u2212\u2192 0.\n\n\u221e n\u2192\u221e\n\n(2.8.70)\n\nTherefore, by Proposition 2.83 (a), the fact that h0,1 is U\u03b3k -superharmonic for each k \u2265 0,\nand the monotonicity of the operators U\u03b3 , we find that\nU (n) h0,1 \u2264 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l(n) h0,1 \u2212\u2192 p\u22170,1,\u03b3 \u2217 ,\nn\u2192\u221e\n\n(2.8.71)\n\n\f2.9. RENORMALIZATION BRANCHING PROCESS: EXTINCTION ON INTERIOR 103\nuniformly on [0, 1]. This proves (2.8.69) (i). To prove also (2.8.69) (ii) we use the U\u03b3 subharmonic (for each \u03b3 > 0) function h1 from Lemma 2.75. By Lemma 2.69 also 12 h1 is\nU\u03b3 -subharmonic. By bounding 12 h1 from above and below with multiples of h0,1 it is easy to\nderive from Proposition 2.83 (a) that\n(U\u03b3 \u2217 )n ( 12 h1 ) \u2212\u2192 p\u22170,1,\u03b3 \u2217\n\n(2.8.72)\n\nn\u2192\u221e\n\nuniformly on [0, 1]. Arguing as before, we can find l(n) \u2192 \u221e such that\n(U\u03b3 \u2217 )l(n) ( 12 h1 ) \u2212 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l(n) ( 21 h1 )\n\n\u2212\u2192 0.\n\n\u221e n\u2192\u221e\n\n(2.8.73)\n\nTherefore, by (2.8.72) and the facts that 12 h1 is U\u03b3k -subharmonic for each k \u2265 0 and 21 h1 \u2264\n1\n2 h0,1 ,\n(2.8.74)\nU (n) ( 21 h0,1 ) \u2265 U\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b3n\u2212l(n) ( 21 h1 ) \u2212\u2192 p\u22170,1,\u03b3 \u2217 ,\nn\u2192\u221e\n\nuniformly on [0, 1], which proves (2.8.69) (ii). The proof of (2.8.69) in case \u03b3 \u2217 = 0 is completely\nanalogous.\n\n2.9\n2.9.1\n\nThe renormalization branching process: extinction on the\ninterior\nBasic facts\n\nIn this section we prove Proposition 2.82 (a). To simplify notation, throughout this section\n\u2217\nh denotes the function h0,0 . We fix 0 < \u03b3 \u2217 < \u221e, we let Y h := Y \u03b3 ,h denote the branching\n\u2217\n\u2217\n\u2217\nparticle system on (0, 1) obtained from Y \u03b3 = (Y0\u03b3 , Y1\u03b3 , . . .) by Poissonization with h in the\nsense of Proposition 2.21, and we denote its log-Laplace operator by U\u03b3h\u2217 . We will prove that\n\u0002\n\u0003\n\u03c1(x) := P \u03b4x Ynh 6= 0 \u2200n \u2265 0 = 0\n\n(x \u2208 (0, 1)).\n\n(2.9.1)\n\nSince for each n fixed, x 7\u2192 \u03c1n (x) := P \u03b4x [Ynh 6= 0] is a continuous function that decreases to\n\u03c1(x), (2.9.1) implies that \u03c1n (x) \u2192 0 locally uniformly on (0, 1), which, by an obvious analogon\nof Lemma 2.79, yields Proposition 2.82 (a).\nAs a first step, we prove:\nLemma 2.84 (Continuous survival probability) One has either \u03c1(x) = 0 for all x \u2208 (0, 1)\nor there exists a continuous function \u03c1\u0303 : (0, 1) \u2192 [0, 1] such that \u03c1(x) \u2265 \u03c1\u0303(x) > 0 for all\nx \u2208 (0, 1).\nProof Put p(x) := h(x)\u03c1(x). We will show that either p = 0 on (0, 1) or there exists a\ncontinuous function p\u0303 : (0, 1) \u2192 (0, 1] such that p \u2265 p\u0303 on (0, 1). Indeed,\n\u0002\n\u0003\n\u0002\n\u0003\np(x) = h(x)P \u03b4x Ynh 6= 0 \u2200n \u2265 0 = lim h(x)P \u03b4x Ynh 6= 0\nn\u2192\u221e\n(2.9.2)\n= h(x) lim (U\u03b3h\u2217 )n 1(x) = lim (U\u03b3 \u2217 )n h(x)\n(x \u2208 (0, 1)),\nn\u2192\u221e\n\nn\u2192\u221e\n\n\f104\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\nwhere we have used (2.2.30) and (2.2.36) in the last two steps. Using the continuity of U\u03b3 \u2217\nwith respect to decreasing sequences, it follows that\nU\u03b3 \u2217 p = p.\n\n(2.9.3)\n\nWe claim that for any f \u2208 B[0,1] [0, 1], one has the bounds\nh\u0393\u03b3x , f i \u2264 U\u03b3 f (x) \u2264 (1 + \u03b3)h\u0393\u03b3x , f i\n\n(\u03b3 > 0, x \u2208 [0, 1]).\n\n(2.9.4)\n\nIndeed, by Lemma 2.72, U\u03b3 f (x) \u2265 1 \u2212 E[(1 \u2212 f (yx\u03b3 (0)))] = h\u0393\u03b3x , f i, while the upper bound in\n(2.9.4) follows from (2.8.11).\nBy Remark 2.31, (0, 1) \u220b x 7\u2192 h\u0393\u03b3x , f i is continuous for all f \u2208 B[0,1] [0, 1]. Moreover,\nh\u0393\u03b3x , f i = 0 for some x \u2208 (0, 1) if and only if f = 0 almost everywhere with respect to\nLebesgue measure.\nApplying these facts to f = p and \u03b3 = \u03b3 \u2217 , using (2.9.3), we see that there are two\npossibilities. Either p = 0 a.s. with respect to Lebesgue measure, and in this case p = 0\nby the upper bound in (2.9.4), or p is not almost everywhere zero with respect to Lebesgue\nmeasure, and in this case the function x 7\u2192 p\u0303(x) := h\u0393\u03b3x , f i is continuous, positive on (0, 1),\nand estimates p from below by the lower bound in (2.9.4).\n\n2.9.2\n\nA representation for the Campbell law\n\n(Local) extinction properties of critical branching processes are usually studied using Palm\nlaws. Our proof of formula (2.9.1) is no exception, except that we will use the closely related\nCampbell laws. Loosely speaking, Palm laws describe a population that is size-biased at a\ngiven position, plus 'typical' particle sampled from that position, while Campbell laws describe\na population that is size-biased as a whole, plus a 'typical' particle sampled from a random\nposition.\nR\nLet P be a probability law on N (0, 1) with N (0,1) P(d\u03bd)|\u03bd| = 1. Then the size-biased law\nPsize associated with P is the probability law on N (0, 1) defined by\nZ\nP(d\u03bd) |\u03bd|1{\u03bd \u2208 * } .\n(2.9.5)\nPsize ( * ) :=\nN (0,1)\n\nThe Campbell law associated with P is the probability law on (0, 1) \u00d7 N (0, 1) defined by\nZ\nP(d\u03bd) \u03bd(A)1{\u03bd \u2208 B}\n(2.9.6)\nPCamp (A \u00d7 B) :=\nN (0,1)\n\nfor all Borel-measurable A \u2282 (0, 1) and B \u2282 N (0, 1). If (v, V ) is a (0, 1) \u00d7 N (0, 1)-valued\nrandom variable with law PCamp , then L(V ) = Psize , and v is the position of a 'typical'\nparticle chosen from V .\nLet\n\u0002\nP x,n ( * ) := P \u03b4x Ynh \u2208 * ]\n(2.9.7)\n\n\f2.9. RENORMALIZATION BRANCHING PROCESS: EXTINCTION ON INTERIOR 105\ndenote the law of Y h atRtime n, started at time 0 with one particle at position x \u2208 (0, 1).\nNote that by criticality, N (0,1) P x,n (d\u03bd)|\u03bd| = 1. Using again criticality, it is easy to see that\nin order to prove the extinction formula (2.9.1), it suffices to show that\n\u0001\nx,n\nlim Psize\n{1, . . . , N } = 0\n(x \u2208 (0, 1), N \u2265 1).\n(2.9.8)\nn\u2192\u221e\n\nx,n\nIn order to prove (2.9.8), we will write down an expression for PCamp\n. Let Qh denote the\noffspring mechanism of Y h , and, for fixed x \u2208 (0, 1), let QhCamp (x, * ) denote the Campbell law\nassociated with Qh (x, * ). The next proposition is a time-inhomogeneous version of Kallenberg's famous backward tree technique; see [Lie81, Satz 8.2].\n\nProposition 2.85 (Representation of Campbell law) Let (vk , Vk )k\u22650 be the Markov process in (0, 1) \u00d7 N (0, 1) with transition laws\n\u0002\n\u0003\nP (vk+1 , Vk+1 ) \u2208 * (vk , Vk ) = (x, \u03bd) = QhCamp (x, * )\n((x, \u03bd) \u2208 (0, 1) \u00d7 N (0, 1)), (2.9.9)\n\nstarted in (v0 , V0 ) = (\u03b4x , 0). Let (Y h,(k) )k\u22651 be branching particle systems with offspring\nh,(k)\nmechanism Qh , conditionally independent given (vk , Vk )k\u22650 , started in Y0\n= Vk \u2212 \u03b4vk .\nThen\nn\n\u0010\n\u0011\nX\nh,(k)\nx,n\nPCamp = L vn , \u03b4vn +\nYn\u2212k .\n(2.9.10)\nk=1\n\nFormula (2.9.10) says that the Campbell law at time n arises in such a way, that an 'immortal'\nparticle at positions v0 , . . . , vn sheds off offspring V1 \u2212 \u03b4v1 , . . . , Vn \u2212 \u03b4vn , distributed according\nto the size-biased law with one 'typical' particle taken out, and this offspring then evolve\nunder the usual forward dynamics till time n. Note that the position of the immortal particle\n(vk )k\u22650 is an autonomous Markov chain.\nWe need a bit of explicit control on QhCamp .\nLemma 2.86 (Campbell law) One has\nQhCamp (x, A\n\n\u00d7 B) =\n\n1\n\u03b3\u2217\n\n+1Z\n\nh(x)\n\n\u2217\n\nP [Pois(hZx\u03b3 ) \u2208 d\u03c7]\u03c7(A)1{\u03c7\u2208A} ,\n\n(2.9.11)\n\n\u2217\n\nwhere the random measures Zx\u03b3 are defined in (2.2.18).\nProof By the definition of the Campbell law (2.9.6), and (2.2.35),\nZ\nh\nQCamp (x, A \u00d7 B) = Qh (x, d\u03c7)\u03c7(A)1{\u03c7\u2208B}\nZ\n1\n1\n\u0011\n\u0010\n\u2217\n\u03b3\u2217 + 1\n\u03b3\u2217 + 1\n* 0.\nP [Pois(hZx\u03b3 ) \u2208 d\u03c7]\u03c7(A)1{\u03c7\u2208B} + 1 \u2212\n=\nh(x)\nh(x)\nRecall that by (2.2.18),\n\u2217\n\nZx\u03b3 :=\n\nZ\n\n0\n\n(2.9.12)\n\n\u03c4\u03b3\u2217\n\n\u03b4y\u03b3\u2217 (\u2212t/2) dt,\nx\n\n(2.9.13)\n\n\f106\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\u2217\n\nwhere (yx\u03b3 (t))t\u2208R is a stationary solution to the SDE (2.2.17) with \u03b3 = \u03b3 \u2217 . By Lemma 2.86,\nthe transition law of the Markov chain (vk )k\u22650 from Proposition 2.85 is given by\nP [vk+1 \u2208 dy|vk = x] =\n\u2217\n\n1\n\u03b3\u2217\n\n+1\n\nh(x)\n\n\u2217\n\nE[Pois(hZx\u03b3 )(dy)] =\n\n1 + \u03b3\u2217\n\u2217\nh(y)\u0393\u03b3x (dy),\nh(x)\n\n(2.9.14)\n\n\u2217\n\nwhere \u0393\u03b3x is the invariant law of yx\u03b3 from Corollary 2.30. In the next section we will prove\nthe following lemma.\nLemma 2.87 (Immortal particle stays in interior) The Markov chain (vk )k\u22650 started\nin any v0 = x \u2208 (0, 1) satisfies\n(vk )k\u22650 has a cluster point in (0, 1)\n\na.s.\n\n(2.9.15)\n\nWe now show that Lemma 2.87, together with our previous results, implies Proposition\n2.82 (a).\nProof of Proposition 2.82 (a) We need to prove (2.9.1). By our previous analysis, it suffices\nto prove (2.9.8) under the assumption that \u03c1 6= 0. By Proposition 2.85,\nn\n\u0010\n\u0011\nX\nh,(k)\nx,n\nPsize\n= L \u03b4vn +\nYn\u2212k .\n\n(2.9.16)\n\nk=1\n\nh,(k)\n\nConditioned on (vk , Vk )k\u22650 , the (Yn\u2212k )k=1,...,n are independent random variables with\n\u0002 h,(k)\n\u0003\n\u0002\n\u0003\nP Yn\u2212k 6= 0 \u2265 P Ymh,(k) 6= 0 \u2200m \u2265 0 = P [Thin\u03c1 (Vk \u2212 \u03b4vk ) 6= 0].\n\n(2.9.17)\n\nTherefore, (2.9.8) will follow by Borel-Cantelli provided that we can show that\n\u221e\nX\nk=1\n\nP [Thin\u03c1 (Vk \u2212 \u03b4vk ) 6= 0|vk\u22121 ] = \u221e\n\na.s.\n\n(2.9.18)\n\nDefine f (x) := P [Thin\u03c1 (Vk \u2212 \u03b4vk ) 6= 0|vk\u22121 = x] (x \u2208 (0, 1)). We need to show that\nP\n\u221e\nk=1 f (x) = \u221e a.s. Using Lemma 2.84 and Lemma 2.86 we can estimate\nZ\nQhCamp (x, dy, d\u03bd){1 \u2212 (1 \u2212 \u03c1\u0303)\u03bd\u2212\u03b4y > 0\nf (x) \u2265 P [Thin\u03c1\u0303 (Vk \u2212 \u03b4vk ) 6= 0|vk\u22121 = x] =\nN (0,1)\n\n(2.9.19)\nfor all x \u2208 (0, 1). Since Q\u03b3 \u2217 , defined in (2.2.19), is a continuous cluster mechanism, also\nQhCamp (x, *) is continuous as a function of x, hence the bound in (2.9.19) is locally uniform on\n(0, 1), hence Lemma 2.87 implies that there is an \u03b5 > 0 such that\nP [Thin\u03c1 (Vk \u2212 \u03b4vk ) 6= 0|vk\u22121 ] \u2265 \u03b5\nat infinitely many times k \u2212 1, which in turn implies (2.9.18).\n\n(2.9.20)\n\n\f107\n\n2.10. PROOF OF THE MAIN RESULT\n\n2.9.3\n\nThe immortal particle\n\nProof of Lemma 2.87 Let K(x, dy) denote the transition kernel (on (0, 1)) of the Markov\nchain (vk )k\u22650 , i.e., by (2.9.14),\nK(x, dy) = (1 + \u03b3 \u2217 )\n\ny(1 \u2212 y) \u03b3 \u2217\n\u0393 (dy).\nx(1 \u2212 x) x\n\n(2.9.21)\n\nIt follows from (2.3.24) that\nZ\nx(1 \u2212 x) + \u03b3 \u2217 (1 + \u03b3 \u2217 )\n.\nK(x, dy)y(1 \u2212 y) =\n(1 + 2\u03b3 \u2217 )(1 + 3\u03b3 \u2217 )\nSet\ng(x) :=\nThen\n\nZ\n\nK(x, dy)y(1 \u2212 y) \u2212 x(1 \u2212 x)\n\nMn := vn (1 \u2212 vn ) \u2212\n\nn\u22121\nX\n\ng(vk )\n\nk=0\n\n(x \u2208 (0, 1)).\n(n \u2265 0)\n\n(2.9.22)\n\n(2.9.23)\n\n(2.9.24)\n\ndefines a martingale (Mn )n\u22650 . Since g > 0 in an open neighborhood of {0, 1},\nP [(vk )k\u22650 has no cluster point in (0, 1)] \u2264 P [ lim Mn = \u2212\u221e] = 0,\nn\u2192\u221e\n\n(2.9.25)\n\nwhere in the last equality we have used that (Mn )n\u22650 is a martingale.\n\n2.10\n\nProof of the main result\n\nProof of Theorem 2.17 Part (a) has been proved in Section 2.3.3. It follows from (2.1.42),\n(2.1.43), (2.2.21), and (2.2.22) that part (b) is equivalent to the following statement. Assuming\nthat\n\u221e\nX\n\u03b3n = \u221e\nand\n(ii) \u03b3n \u2212\u2192 \u03b3 \u2217\n(2.10.1)\n(i)\nn\u2192\u221e\n\nn=1\n\nfor some \u03b3 \u2217 \u2208 [0, \u221e), one has, uniformly on [0, 1],\n\nU\u03b3n\u22121 \u25e6 * * * \u25e6 U\u03b30 (p) \u2212\u2192 p\u2217l,r,\u03b3 \u2217 ,\n\n(2.10.2)\n\nn\u2192\u221e\n\nwhere p\u2217l,r,\u03b3 \u2217 is the unique solution in Hl,r of\n(i)\n(ii)\n\n1\n2 x(1\n\n2\n\nU\u03b3 \u2217 p \u2217 = p \u2217\n\n\u2202\n\u2217\n\u2217\n\u2217\n(x \u2208 [0, 1])\n\u2212 x) \u2202x\n2 p (x) \u2212 p (x)(1 \u2212 p (x)) = 0\n\nif 0 < \u03b3 \u2217 < \u221e,\nif \u03b3 \u2217 = 0.\n\n(2.10.3)\n\nIt follows from Proposition 2.22 that the left-hand side of (2.10.2) converges uniformly to a\nlimit p\u2217l,r,\u03b3 \u2217 which is given by (2.2.45). We must show 1\u25e6 that p\u2217l,r,\u03b3 \u2217 \u2208 Hl,r and 2\u25e6 that p\u2217l,r,\u03b3 \u2217\nis the unique solution in this class to (2.10.3). We first treat the case \u03b3 \u2217 > 0.\n\n\f108\n\nCHAPTER 2. RENORMALIZATION OF CATALYTIC WF-DIFFUSIONS\n\n1\u25e6 Since p\u22170,0,\u03b3 \u2217 \u2261 0 and p\u22171,1,\u03b3 \u2217 \u2261 1, it is obvious that p\u22170,0,\u03b3 \u2217 \u2208 H0,0 and p\u22171,1,\u03b3 \u2217 \u2208 H1,1 .\nTherefore, by symmetry, it suffices to show that p\u22170,1,\u03b3 \u2217 \u2208 H0,1 . By Lemmas 2.75 and 2.78,\nx \u2264 p \u2264 1 \u2212 (1 \u2212 x)7 implies x \u2264 U\u03b3k p \u2264 1 \u2212 (1 \u2212 x)7 for each k. Iterating this relation, using\n(2.10.2), we find that\nx \u2264 p\u22170,1,\u03b3 \u2217 (x) \u2264 1 \u2212 (1 \u2212 x)7 .\n(2.10.4)\nBy Proposition 2.37, the left-hand side of (2.10.2) is nondecreasing and concave in x if p is, so\ntaking the limit we find that p\u22170,1,\u03b3 \u2217 is nondecreasing and concave. Combining this with (2.10.4)\nwe conclude that p\u22170,1,\u03b3 \u2217 is Lipschitz continuous. Moreover p\u22170,1,\u03b3 \u2217 (0) = 0 and p\u22170,1,\u03b3 \u2217 (1) = 1 so\np\u22170,1,\u03b3 \u2217 \u2208 H0,1 .\n2\u25e6 Taking the limit n \u2192 \u221e in (U\u03b3 \u2217 )n p = U\u03b3 \u2217 (U\u03b3 \u2217 )n\u22121 p, using the continuity of U\u03b3 \u2217\n(Corollary 2.36) and (2.10.2), we find that U\u03b3 \u2217 p\u2217l,r,\u03b3 \u2217 = p\u2217l,r,\u03b3 \u2217 . It follows from (2.10.2) that\np\u2217l,r,\u03b3 \u2217 is the only solution in Hl,r to this equation.\nFor \u03b3 \u2217 = 0, it has been shown in [FS03, Proposition 3] that p\u2217l,r,0 is the unique solution\nin Hl,r to (2.10.3) (ii). In particular, it has been shown there that p\u22170,1,0 is twice continuously\ndifferentiable on [0, 1] (including the boundary). This proves parts (b) and (c) of the theorem.\n\n\fChapter 3\n\nBranching-coalescing particle\nsystems.\n3.1\n\nIntroduction and main results\n\n3.1.1\n\nIntroduction\n\nIn this chapter we study systems of particles subject to a stochastic dynamics with the following description. 1\u25e6 Each particle moves independently of the others according to a continuous\ntime Markov process on a lattice \u039b, which jumps from site i to site j with rate a(i, j). 2\u25e6\nEach particle splits with rate b \u2265 0 into two new particles, created on the position of the old\none. 3\u25e6 Each pair of particles, present on the same site, coalesces with rate 2c (with c \u2265 0)\nto one particle. 4\u25e6 Each particle dies with rate d \u2265 0. Throughout this chapter, we make the\nfollowing assumptions.\n(i) \u039b is a finite or countably infinite set.\n(ii) The transition rates a(i, j) are irreducible, i.e., if \u2206 \u2282 \u039b is neither \u039b nor \u2205,\nthen there exist i \u2208 \u2206 and j \u2208 \u039b\\\u2206 such that a(i, j) > 0 or a(j, i) > 0.\n(iii) supi\n(iv)\n\nP\n\nj\n\nP\n\nj\n\na(i, j) < \u221e.\n\na\u2020 (i, j) =\n\nP\n\nj\n\na(i, j), where a\u2020 (i, j) := a(j, i).\n\n(v) b, c, and d are nonnegative constants.\nHere and elsewhere sums and suprema over i, j always run over \u039b, unless stated otherwise.\nAssumption (iv) says that the counting measure is an invariant \u03c3-finite measure for the Markov\nprocess with jump rates a. With respect to this invariant measure, the time-reversed process\njumps from i to j with rate a\u2020 (i, j).\n109\n\n\f110\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nLet Xt (i) denote the number of particles present at site i \u2208 \u039b and time t \u2265 0. Then\nX = (Xt )t\u22650 , with Xt = (Xt (i))i\u2208\u039b , is a Markov process with formal generator\nGf (x) :=\n\nX\nij\n\n+c\n\na(i, j)x(i){f (x + \u03b4j \u2212 \u03b4i ) \u2212 f (x)} + b\n\nX\ni\n\nX\n\nx(i){f (x + \u03b4i ) \u2212 f (x)}\n\niX\n\nx(i)(x(i) \u2212 1){f (x \u2212 \u03b4i ) \u2212 f (x)} + d\n\ni\n\nx(i){f (x \u2212 \u03b4i ) \u2212 f (x)},\n\n(3.1.1)\n\nwhere \u03b4i (j) := 1 if i = j and \u03b4i (j) := 0 otherwise. The process X can be defined for finite\ninitial states and also for some infinite initial states in an appropriate Liggett-Spitzer space\n(see Section 3.1.3). We call (Xt )t\u22650 a branching coalescing particle system with underlying\nmotion (\u039b, a), branching rate b, coalescence rate c and death rate d, or shortly the (a, b, c, d)braco-process.\nSome typical examples of underlying motions we have in mind are nearest neighbour random walk on \u039b = Zd and on \u039b = Td , the homogeneous tree of degree d+1. We will not restrict\nourselves to symmetric underlying motions (i.e., a = a\u2020 ) but also allow a(i, j) = 1{j=i+1} on\nZ, for example. The reason why we do not restrict ourselves to graphs, is that we also want\nto include the case \u039b = \u03a9d , the hierarchical group with freedom d, i.e.,\n\u03a9d := {i = (i0 , i1 , . . .) : i\u03b1 \u2208 {0, . . . , d \u2212 1} \u2200\u03b1 \u2265 0, i\u03b1 6= 0 finitely often },\n\n(3.1.2)\n\nequipped with componentwise addition modulo n. On \u03a9d , one typically chooses transition\nrates a(i, j) that depend only on the hierarchical distance |i \u2212 j| := min{\u03b1 \u2265 0 : i\u03b2 = j\u03b2 \u2200\u03b2 \u2265\n\u03b1}. The hierarchical group has found widespread applications in population biology and is\ntherefore a natural choice for the underlying space.\n\n3.1.2\n\nMotivation\n\nOur motivation for studying branching-coalescing particle systems comes from three directions.\nReaction diffusion models, Schl\u00f6gl's first model. Branching-coalescing particle systems are\nknown in the physics literature as a reaction diffusion models. More precisely, our model\nis a special case of Schl\u00f6gl's first model [Sch72], where in the latter there is an additional\nrate with which particles are spontaneously created. For d = 0, our model is known as the\nautocatalytic reaction. Reaction diffusion models have been studied intensively by physicists\nand more recently also by probabilists [DDL90, Mou92, Neu90]. All work that we are aware\nof is restricted to the case \u039b = Zd .\nPopulation dynamics, the contact process. Branching-coalescing particle systems may be\nthought of as a more or less realistic model for the spread and growth of a population of\norganisms. Here, the underlying motion models the migration of organisms, births and deaths\nhave their obvious interpretations, while coalescence of particles should be thought of as\nadditional deaths, caused by local overpopulation. In this respect, our model is similar to\nthe contact process. The latter is often referred to as a model for the spread of an infection,\nbut in fact it is a reasonable model for the population dynamics of many organisms, from\ntrees in a forest to killer bees. There are two striking differences between the contact process\nand branching-coalescing particle systems. First, whereas the total population at one site is\n\n\f111\n\n3.1. INTRODUCTION AND MAIN RESULTS\n\nsubject to a rigid bound in the contact process (namely one), it may reach arbitrarily high\nvalues in a branching-coalescing system. However, when the local population is high, the\ncoalescence (which grows quadratically in the number of organisms) dominates the branching\n(which grows linearly), and in this way the population is reduced. A second difference is that\nin the contact process, if one site infects its neighbor, the original site is still infected. As\nopposed to this, even when the death rate is zero, it is possible that a branching coalescing\nparticle system goes to local extinction due to migration only. Thus, we can say that the\ngain from infection is guaranteed in the contact process, whereas the reward for migration is\nuncertain in a branching-coalescing particle system.\nResampling with selection and negative mutations. Our third motivation also comes from\npopulation dynamics, but from a different perspective. Assume that at each site i \u2208 \u039b there\nlives a large, fixed number of organisms, and that each of these organisms carries a gene\nthat comes in two types: a healthy and a defective one. Let us model the evolution of the\npopulation as follows. 1\u25e6 with rate a(i, j), we let an organism at site i migrate to site j.\n2\u25e6 to model the effect of natural selection, we let each organism with rate b choose another\norganism, living on the same site. If the first organism carries a healthy gene and the second\norganism a defective gene, then the latter is replaced by an organism with a healthy gene. 3\u25e6\nto model the effect of random mating, we resample each pair of organisms living at the same\nsite with rate 2c, i.e., we choose one of the two at random and replace it by an organism with\nthe type of the other one. 4\u25e6 with rate d, we let a healthy gene mutate into a defective gene.\nIn the limit that the number of organisms at each site is large, the frequencies Xt (i) of healthy\norganisms at site i and time t are described by the unique pathwise solution to the infinite\ndimensional stochastic differential equation (SDE) (see [SU86]):\nX\ndXt (i) =\na(j, i)(Xt (j) \u2212 Xt (i)) dt + bXt (i)(1 \u2212 Xt (i)) dt \u2212 dXt (i) dt\n(3.1.3)\njp\n(t \u2265 0, i \u2208 \u039b).\n+ 2cXt (i)(1 \u2212 Xt (i)) dBt (i)\n\nWe call the [0, 1]\u039b -valued process X = (Xt )t\u22650 the resampling-selection process with underlying\nmotion (\u039b, a), selection rate b, resampling rate c and mutation rate d, or shortly the (a, b, c, d)resem-process (the letters in 'resem' standing for resampling, selection and mutation).\nIt is known that branching-coalescing particle systems are dual to resampling-selection\nprocesses. To be precise, for any \u03c6 \u2208 [0, 1]\u039b and x \u2208 N\u039b , write\nY\n\u03c6x :=\n\u03c6(i)x(i) ,\n(3.1.4)\ni\n\nwhere 00 := 1. Let X be the (a, b, c, d)-resem-process and let X \u2020 be the (a\u2020 , b, c, d)-bracoprocess. Then (see Theorem 3.1 (a) below)\n\u2020\n\nE \u03c6 [(1 \u2212 Xt )x ] = E x [(1 \u2212 \u03c6)Xt ].\n\n(3.1.5)\n\nFormula (3.1.5) has the following interpretation: E \u03c6 [(1 \u2212 Xt )x ] is the probability that x organisms, sampled from the population at time t, all have defective genes. If we want to calculate\nthis probability, we must follow back in time those organisms that could possibly be healthy\n\n\f112\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nancestors of these x organisms. In this way we end up with a system of branching coalescing\na\u2020 -random walks, which die when a mutation occurs, coalesce when two potential ancestors\ndescend from the same ancestor, and branch when a selection event takes place. If we end\nup with at least one healthy potential ancestor at time zero, then we know that not all the x\nparticles have defective genes.\nResampling-selection processes of the form (3.1.3) are also known as stepping stone models\n(with selection and one type of mutation). These were studied by Shiga and Uchiyama in\n[SU86], a paper similar in spirit to ours. The duality (3.1.5) is a special case of Lemma 2.1\n[SU86]. Moment duals for genetic diffusions in a more general but non-spatial context go back\nto [Shi81]. The idea of incorporating selection in resampling models by introducing branching\ninto the usual coalescent dual seems to have been independently reinvented in [KN97]. They\nwere probably the first to interpret the duality (3.1.5) in terms of potential ancestors. For\nsome recent versions of this duality, see also [DK99, DG99, BES04]. A SDE that is dual to\nbranching-annihilating random walks occurs in [BEM03, Lemma 2.1]. A SPDE version of\n(3.1.3) (with d = 0) has been derived as the rescaled limit of long-range biased voter models\nin [MT95, Theorem 2].\nNote that for c = 0, the process X is deterministic. In this case, the semigroup (Ut )t\u22650\ndefined by Ut \u03c6 := Xt (t \u2265 0), where X is the deterministic solution of (3.1.3) with initial state\nX0 = \u03c6 \u2208 [0, 1]\u039b , is called the generating semigroup of the branching particle system X \u2020 . (For\nthis terminology, see for example [FS04].) Thus, the duality relation (3.1.5) says that, loosely\nspeaking, branching-coalescing particle systems have a random generating semigroup. The\nSDE (3.1.3) will be our main tool for studying branching-coalescing particle systems.\n\n3.1.3\n\nPreliminaries\n\nIn this section we introduce the notation and definitions that we will use throughout the\nchapter.\n(Inner product and norm notation) For \u03c6, \u03c8 \u2208 [\u2212\u221e, \u221e]\u039b , we write\nX\nX\n\u03c6(i)\u03c8(i)\nand\n|\u03c6| :=\n|\u03c6(i)|,\nh\u03c6, \u03c8i :=\ni\n\n(3.1.6)\n\ni\n\nwhenever the infinite sums are defined.\n\n(Poisson measures) If \u03c6 is a [0, \u221e)\u039b -valued random variable, then by definition a Poisson measure with random intensity \u03c6 is an N\u039b -valued random variable Pois(\u03c6) whose law is\nuniquely determined by\nE[(1 \u2212 \u03c8)Pois(\u03c6) ] = E[e \u2212h\u03c6, \u03c8i ]\n\n(\u03c8 \u2208 [0, 1]\u039b ).\n\n(3.1.7)\n\nIn particular, when \u03c6 is nonrandom, then the components (Pois(\u03c6)(i))i\u2208\u039b are independent\nPoisson distributed random variables with intensity \u03c6(i).\n(Thinned point measures) If x and \u03c6 are random variables taking values in N\u039b and [0, 1]\u039b ,\nrespectively, then by definition a \u03c6-thinning of x is an N\u039b -valued random variable Thin\u03c6 (x)\nwhose law is uniquely determined by\nE[(1 \u2212 \u03c8)Thin\u03c6 (x) ] = E[(1 \u2212 \u03c6\u03c8)x ]\n\n(\u03c8 \u2208 [0, 1]\u039b ).\n\n(3.1.8)\n\n\f113\n\n3.1. INTRODUCTION AND MAIN RESULTS\n\nP\nIn particular, when x and \u03c6 P\nare nonrandom, and x = m\nn=1 \u03b4in , then a \u03c6-thinning of x can be\nm\nconstructed as Thin\u03c6 (x) := n=1 \u03c7n \u03b4in where the \u03c7n are independent {0, 1}-valued random\nvariables with P [\u03c7n = 1] = \u03c6(in ).\nIf \u03c6 and x are both random, then it will always be understood that they are independent. Thus, L(Thin\u03c6 (x)) depends on the laws L(\u03c6) and L(x) alone, and it is only the map\n(L(\u03c6), L(x)) 7\u2192 L(Thin\u03c6 (x)) that is of interest to us. We have chosen the present notation in\nterms of random variables instead of their laws to keep things simple if \u03c6 and x are nonrandom.\nWe leave it to the reader to check the elementary relations\nD\n\nThin\u03c8 (Thin\u03c6 (x)) = Thin\u03c8\u03c6 (x) and\n\nD\n\nThin\u03c8 (Pois(\u03c6)) = Pois(\u03c8\u03c6),\n\n(3.1.9)\n\nD\n\nwhere = denote equality in distribution.\n(Weak convergence) We let N = N \u222a {\u221e} denote the one-point compactification of N, and\n\u039b\n\u039b\n\u03bdn on N converge\nequip N with the product topology. We say that\nR probability measures\nR\nweakly to a limit \u03bd, denoted as \u03bdn \u21d2 \u03bd, when \u03bdn (dx)f (x) \u2192 \u03bd(dx)f (x) for every f \u2208\n\u039b\n\u039b\nC(N ), the space of continuous real functions on N . One has \u03bdn \u21d2 \u03bd if and only if \u03bdn ({x :\nx(i) = y(i) \u2200i \u2208 \u2206}) \u2192 \u03bd({x : x(i) = y(i) \u2200i \u2208 \u2206}) for all finite \u2206 \u2282 \u039b and y \u2208 N\u2206 .\nWe equip the space [0, 1]\u039b with the product topology, and we say that probability\nmeaR\n\u039b converge weakly to a limit \u03bc, denoted as \u03bc \u21d2 \u03bc, when\nsures\n\u03bc\non\n[0,\n1]\n\u03bc\n(d\u03c6)f\n(\u03c6)\n\u2192\nn\nn\nn\nR\n\u039b\n\u03bc(d\u03c6)f (\u03c6) for every f \u2208 C([0, 1] ).\n\u039b\n\n(Monotone convergence) If \u03bd1 , \u03bd2 are probability measures on N , then we say that \u03bd1\n\u039b\nand \u03bd2 are stochastically ordered, denoted as \u03bd1 \u2264 \u03bd2 , if N -valued random variables Y1 , Y2\nwith laws L(Yi ) = \u03bdi (i = 1, 2) can be coupled such that Y1 \u2264 Y2 . We say that a sequence\nof probability measures \u03bdn on N\u039b decreases (increases) stochastically to a limit \u03bd, denoted\nas \u03bdn \u2193 \u03bd (\u03bdn \u2191 \u03bd), if random variables Yn , Y with laws L(Yn ) = \u03bdn and L(Y ) = \u03bd can be\ncoupled such that Yn \u2193 Y (Yn \u2191 Y ). It is not hard to see that \u03bdn \u2193 \u03bd (\u03bdn \u2191 \u03bd) implies \u03bdn \u21d2 \u03bd.\nStochastic ordering and monotone convergence of probability measures on [0, 1]\u039b are defined\nin the same way.\n(Finite systems) We denote the set of finite particle configurations by N (\u039b) := {x \u2208 N\u039b :\n|x| < \u221e} and let\nS(N (\u039b)) := {f : N (\u039b) \u2192 R : |f (x)| \u2264 K|x|k + M for some K, M, k \u2265 0}\n\n(3.1.10)\n\ndenote the space of real functions on N (\u039b) satisfying a polynomial growth condition. For\nfinite initial conditions, the (a, b, c, d)-braco-process X is well-defined as a Markov process in\nN (\u039b) (in particular, X does not explode), f (Xt ) is absolutely integrable for each f \u2208 S(N (\u039b))\nand t \u2265 0, and the semigroup\nSt f (x) := E x [f (Xt )]\n\n(t \u2265 0, x \u2208 N (\u039b), f \u2208 S(N (\u039b)))\n\nmaps S(N (\u039b)) into itself (see Proposition 3.8 below).\n\n(3.1.11)\n\n(Liggett-Spitzer space) Set as (i, j) := a(i, j) + a\u2020 (i, j). It follows from our assumptions on\na that there exist (strictly) positive constants (\u03b3i )i\u2208\u039b such that\nX\nX\n\u03b3i < \u221e and\nas (i, j)\u03b3j \u2264 K\u03b3i (i \u2208 \u039b)\n(3.1.12)\ni\n\nj\n\n\f114\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nfor some K < \u221e. We fix such (\u03b3i )i\u2208\u039b throughout the chapter and define the Liggett-Spitzer\nspace (after [LS81])\nE\u03b3 (\u039b) := {x \u2208 N\u039b : kxk\u03b3 < \u221e},\n(3.1.13)\n\nwhere for x \u2208 Z\u039b we put\n\nkxk\u03b3 :=\n\nX\ni\n\n\u03b3i |x(i)|.\n\n(3.1.14)\n\nWe let CLip (E\u03b3 (\u039b)) denote the class of Lipschitz functions on E\u03b3 (\u039b), i.e., f : E\u03b3 (\u039b) \u2192 R such\nthat |f (x) \u2212 f (y)| \u2264 Lkx \u2212 yk\u03b3 for some L < \u221e.\n(Infinite systems) It is known ([Che87], see also Proposition 3.11 below) that for each\nf \u2208 CLip (E\u03b3 (\u039b)) and t \u2265 0, the function St f defined in (3.1.11) can be extended to a unique\nLipschitz function on E\u03b3 (\u039b), also denoted by St f . Moreover, there exists a time-homogeneous\nMarkov process X in E\u03b3 (\u039b) (also called (a, b, c, d)-braco-process) with transition laws given by\nE x [f (Xt )] = St f (x)\n\n(f \u2208 CLip (E\u03b3 (\u039b)), x \u2208 E\u03b3 (\u039b), t \u2265 0).\n\n(3.1.15)\n\nWe will show (in Proposition 3.11 below) that X has a modification with cadlag sample paths,\na fact that may seem obvious but to our knowledge has not been proved before.\n(Survival and extinction) We say that the (a, b, c, d)-braco-process survives if\nP x [Xt 6= 0 \u2200t \u2265 0] > 0\n\nfor some x \u2208 N (\u039b).\n\n(3.1.16)\n\nIf X does not survive we say that X dies out. Note that the process with death rate d = 0\nsurvives, since the number of particles can no longer decrease once only one particle is left.\nIf \u039b is finite then the (a, b, c, d)-braco-process survives if and only if d = 0, but for infinite \u039b\nsurvival often holds also for some d > 0. For \u039b = Zd and b sufficiently large survival has been\nproved in [SU86, Theorem 3.1]. We plan to study sufficient conditions for survival in more\ndetail in a forthcoming paper.\n\u039b\n\n(Nontrivial measures) We say that a probability measure \u03bd on N is nontrivial if \u03bd({0}) = 0,\n\u039b\nwhere 0 \u2208 N denotes the zero configuration. Likewise, we say that a probability measure \u03bc\non [0, 1]\u039b is nontrivial if \u03bc({0}) = 0.\n(Homogeneous lattices) By definition, an automorphism of (\u039b, a) is a bijection g : \u039b \u2192 \u039b\nsuch that a(gi, gj) = a(i, j) for all i, j \u2208 \u039b. We denote the group of all automorphisms of\n(\u039b, a) by Aut(\u039b, a). We say that a subgroup G \u2282 Aut(\u039b, a) is transitive if for each i, j \u2208 \u039b\nthere exists a g \u2208 G such that gi = j. We say that (\u039b, a) is homogeneous if Aut(\u039b, a) is\ntransitive. We define shift operators Tg : N\u039b \u2192 N\u039b by\nTg x(j) := x(g \u22121 j)\n\n(i \u2208 \u039b, x \u2208 N\u039b , g \u2208 Aut(\u039b, a)).\n\n(3.1.17)\n\nIf G is a subgroup of Aut(\u039b, a), then we say that a probability measure \u03bd on N\u039b is Ghomogeneous if \u03bd \u25e6 Tg\u22121 = \u03bd for all g \u2208 G. For example, if \u039b = Zd and a(i, j) = 1{|i\u2212j|=1}\n(nearest-neighbor random walk), then the group G of translations i 7\u2192 i + j (j \u2208 \u039b) form a\ntransitive subgroup of Aut(\u039b, a) and the G-homogeneous probability measures are the translation invariant probability measures. Shift operators and G-homogeneous measures on [0, 1]\u039b\nare defined analogously.\n\n\f115\n\n3.1. INTRODUCTION AND MAIN RESULTS\n\n3.1.4\n\nMain results\n\nOur first result is a tool that we exploit substantially towards the main result. Part (a) is\nknown [SU86, Lemma 2.1], but we are not aware of parts (b) and (c) occuring anywhere in\nthe literature.\nTheorem 3.1 (Dualities and Poissonization) Let X and X be the (a, b, c, d)-braco-process\nand the (a, b, c, d)-resem-process, respectively, and let X \u2020 denote the (a\u2020 , b, c, d)-resem-process.\nThen the following holds:\n(a) (Duality)\nP x [Thin\u03c6 (Xt ) = 0] = P \u03c6 [ThinX \u2020 (x) = 0]\nt\n\n(t \u2265 0, \u03c6 \u2208 [0, 1]\u039b , x \u2208 E\u03b3 (\u039b)).\n\n(3.1.18)\n\n(b) (Self-duality) Assume c > 0, then\nP \u03c6 [Pois( bc Xt \u03c8) = 0] = P \u03c8 [Pois( bc \u03c6Xt\u2020 ) = 0]\n\n(t \u2265 0, \u03c6, \u03c8 \u2208 [0, 1]\u039b ).\n\n(3.1.19)\n\n(t \u2265 0, \u03c6 \u2208 [0, 1]\u039b ),\n\n(3.1.20)\n\n(c) (Poissonization) Assume c > 0, then\nb\n\nP L(Pois( c \u03c6)) [Xt \u2208 * ] = P \u03c6 [Pois( cb Xt ) \u2208 * ]\n\ni.e., if X is started in the initial law L(Pois( cb \u03c6)) and X is started in \u03c6, then Xt and Pois( bc Xt )\nare equal in law.\nNote that P [Thin\u03c6 (x) = 0] = (1 \u2212 \u03c6)x . Therefore, Theorem 3.1 (a) is just a reformulation of\nthe duality relation (3.1.5). Theorem 3.1 (b) says that resampling-selection processes are in\naddition dual with respect to each other. In particular, if the underlying motion is symmetric,\ni.e., a = a\u2020 , then this is a self-duality. Since P [Pois(\u03c6) = 0] = e\u2212|\u03c6| , formula (3.1.19) can be\nrewritten as\n\u2020 \u0003\nb\nb\n\u0003\n\u0002\n\u0002\n(t \u2265 0, \u03c6, \u03c8 \u2208 [0, 1]\u039b ).\n(3.1.21)\nE \u03c6 e \u2212 c hXt , \u03c8i = E \u03c8 e \u2212 c h\u03c6, Xt i\nWe note that by [Kal83, Lemma 15.5.1], for b > 0, the distribution of Xt is determined uniquely\nb\nby all E[e\u2212 c hXt ,\u03c8i ] with \u03c8 \u2208 [0, 1]\u039b . To convince the reader that the notation in (3.1.18) and\n(3.1.19), which may feel a little uneasy in the beginning, is convenient, we give here the proof\nof the Poissonization formula (3.1.20).\nProof of Theorem 3.1 (c) By (3.1.9) and the duality relations (3.1.18) and (3.1.19),\nb\n\nP L(Pois( c \u03c6)) [Thin\u03c8 (Xt ) = 0] = P \u03c8 [ThinX \u2020 (Pois( bc \u03c6)) = 0]\nt\n\n= P \u03c8 [Pois( bc Xt\u2020 \u03c6) = 0] = P \u03c6 [Pois( cb \u03c8Xt ) = 0] = P \u03c6 [Thin\u03c8 (Pois( bc Xt )) = 0].\n\n(3.1.22)\n\nSince this is true for all \u03c8 \u2208 [0, 1]\u039b , the random variables Xt and Pois( bc Xt ) are equal in\ndistribution.\nOur next result shows that it is possible to start the (a, b, c, d)-braco-process with infinitely\nmany particles at each site. This result (except for parts (b) and (f)) has been proved for\nbranching-coalescing particle systems with more general branching and coalescing mechanisms\non Zd in [DDL90]. Their methods are not restricted to the case \u039b = Zd , but we give an\nindependent proof using duality, which has the additional appeal of yielding the explicit bound\nin part (b).\n\n\f116\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nTheorem 3.2 (The maximal branching-coalescing process) Assume that c > 0. Then\n(\u221e)\nthere exists an E\u03b3 (\u039b)-valued process X (\u221e) = (Xt )t>0 with the following properties:\n(\u221e)\n\n(a) For each \u03b5 > 0, (Xt\n\n(\u221e)\n\n)t\u2265\u03b5 is the (a, b, c, d)-braco-process starting in X\u03b5\n\n.\n\n(b) Set r := b \u2212 d + c. Then\n(\u221e)\nE[Xt (i)]\n\n\u2264\n\n(\n\nr\nc(1\u2212e\u2212rt )\n1\nct\n\nif r 6= 0,\n\n(i \u2208 \u039b, t > 0).\n\nif r = 0\n\n(3.1.23)\n\n(c) If X (n) are (a, b, c, d)-braco-processes starting in initial states x(n) \u2208 E\u03b3 (\u039b) such that\nx(n) (i) \u2191 \u221e\nthen\n\nas n \u2191 \u221e\n\n(\u221e)\n\n(n)\n\nL(Xt ) \u2191 L(Xt\n\n)\n\n(i \u2208 \u039b),\n\nas n \u2191 \u221e\n\n(3.1.24)\n\n(t > 0).\n\n(3.1.25)\n\n(d) There exists an invariant measure \u03bd of the (a, b, c, d)-braco-process such that\n(\u221e)\n\nL(Xt\n\n)\u2193\u03bd\n\nas t \u2191 \u221e.\n\n(3.1.26)\n\n(e) If \u03bd is another invariant measure for the (a, b, c, d)-braco-process, then \u03bd \u2264 \u03bd.\n\n(f ) The measure \u03bd is uniquely characterised by\nZ\n\u03bd(dx)(1 \u2212 \u03c6)x = P \u03c6 [\u2203t \u2265 0 such that Xt\u2020 = 0]\n\n(\u03c6 \u2208 [0, 1]\u039b ),\n\n(3.1.27)\n\nwhere X \u2020 denotes the (a\u2020 , b, c, d)-resem-process.\nWe call X (\u221e) the maximal (a, b, c, d)-braco process and we call \u03bd the upper invariant measure.\nTo see why Theorem 3.2 (f) holds, note that by Theorem 3.1 (a) and Theorem 3.2 (c),\n(\u221e)\n\nP [Thin\u03c6 (Xt\n\n) = 0] = lim P \u03c6 [ThinX \u2020 (x(n) ) = 0] = P \u03c6 [Xt\u2020 = 0]\nn\u2191\u221e\n\n(\u03c6 \u2208 [0, 1]\u039b , t > 0).\n\n(3.1.28)\nNow 0 is an absorbing state for the (a, b, c, d)-resem-process, and therefore P \u03c6 [Xt\u2020 = 0] =\nP \u03c6 [\u2203s \u2264 t such that Xs\u2020 = 0]. Therefore, taking the limit t \u2191 \u221e in (3.1.28) we arrive at\n(3.1.27).\nThe (a, b, c, d)-resem process has an upper invariant measure too. Of our next theorem,\nparts (a)\u2013(c) are simple, but part (d) lies somewhat deeper.\nTheorem 3.3 (The maximal resampling-selection process) Let X 1 denote the (a, b, c, d)resem-process started in X01 (i) = 1 (i \u2208 \u039b). Then the following holds.\n(a) There exists an invariant measure \u03bc of the (a, b, c, d)-resem process such that\nL(Xt1 ) \u2193 \u03bc\n\nas t \u2191 \u221e.\n\n(b) If \u03bc is another invariant measure, then \u03bc \u2264 \u03bc.\n\n(3.1.29)\n\n\f117\n\n3.1. INTRODUCTION AND MAIN RESULTS\n(c) Let X \u2020 denote the (a\u2020 , b, c, d)-braco-process. Then\nZ\n\u03bc(d\u03c6)(1 \u2212 \u03c6)x = P x [\u2203t \u2265 0 such that Xt\u2020 = 0]\n\n(x \u2208 N (\u039b)),\n\n(3.1.30)\n\nand the measure \u03bc is nontrivial if and only if the (a\u2020 , b, c, d)-braco-process survives.\n(d) Assume that c > 0 and that \u039b is infinite. If Y is a random variable such that \u03bc = L(Y),\nthen the upper invariant measure of the (a, b, c, d)-braco-process is given by \u03bd = L(Pois( cb Y)).\nIf \u03bc is nontrivial then so is \u03bd.\nR\nNote that \u03bc(d\u03c6)(1 \u2212 \u03c6)x is the probability that x individuals, sampled from a population\nwith resampling and selection in the equilibrium measure \u03bc, all have defective genes.\nThe following is our main result.\nTheorem 3.4 (Convergence to the upper invariant measure) Assume that (\u039b, a) is\ninfinite and homogeneous, G is a transitive subgroup of Aut(\u039b, a), and c > 0.\n(a) Let X be the (a, b, c, d)-braco process started in a G-homogeneous nontrivial initial law\nL(X0 ). Then L(Xt ) \u21d2 \u03bd as t \u2192 \u221e, where \u03bd is the upper invariant measure.\n(b) Let X be the (a, b, c, d)-resem process started in a G-homogeneous nontrivial initial law\nL(X0 ). Then L(Xt ) \u21d2 \u03bc as t \u2192 \u221e, where \u03bc is the upper invariant measure.\nShiga and Uchiyama [SU86, Theorems 1.3 and 1.4] proved Theorem 3.4 (b) under the additional assumptions that \u039b = Zd and that a satisfies a first moment condition in case the death\nrate d is zero. As we will show below Theorem 3.4 (b) can be derived from Theorem 3.4 (a)\nby Poissonization, but not vice versa.\n\n3.1.5\n\nMethods\n\nA key ingredient in the proofs of Theorem 3.3 (d) and Theorem 3.4 is the following property\nof resampling-selection processes, which is of some interest on its own.\nLemma 3.5 (Extinction versus unbounded growth) Assume that c > 0. Let X be the\nb\n(a, b, c, d)-resem-process starting in an initial state \u03c6 \u2208 [0, 1]\u039b with |\u03c6| < \u221e. Then e\u2212 c |Xt | is\na submartingale, and a martingale if d = 0. If moreover \u039b is infinite, then\nXt = 0\n\nfor some t \u2265 0\n\nor\n\nlim |Xt | = \u221e\n\nt\u2192\u221e\n\na.s.\n\n(3.1.31)\n\nNote that by Theorem 3.1 (b),\n\u2020 \u0003\nb\nb\nb\n\u0003\n\u0002\n\u0002\nE \u03c6 e \u2212 c hXt , 1i = E 1 e \u2212 c h\u03c6, Xt i \u2265 e \u2212 c h\u03c6, 1i\n\n(\u03c6 \u2208 [0, 1]\u039b ),\n\n(3.1.32)\n\nwith equality if d = 0, since 1 is a stationary state for the (a\u2020 , b, c, 0)-resem-process. This shows\nb\nthat e\u2212 c |Xt | is a submartingale, and a martingale if d = 0. By submartingale convergence,\n|Xt | converges a.s. to a limit in [0, \u221e]. All the hard work of Lemma 3.5 consists of proving\nthat this limit is a.s. either 0 or \u221e, and that X gets extinct in finite time if the limit is zero.\n\n\f118\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\nOnce Lemma 3.5 is established the proof of Theorem 3.3 (d) is simple.\n\nProof of Theorem 3.3 (d) Let Y be a random variable such that \u03bc = L(Y) and let Y be a\nrandom variable such that \u03bd = L(Y ). By (3.1.9), Theorem 3.1 (b), and Theorem 3.2 (f)\nP [Thin\u03c6 (Pois( cb Y)) = 0] = lim P 1 [Pois( bc \u03c6Xt ) = 0] = lim P \u03c6 [Pois( cb Xt\u2020 ) = 0]\n!\n\n\u03c6\n\n= P [\u2203t \u2265 0 such\n\nt\u2192\u221e\nthat Xt\u2020 =\n\nt\u2192\u221e\n\n(3.1.33)\n\n0] = P [Thin\u03c6 (Y ) = 0],\n\nwhere we have used Lemma 3.5 in the equality marked with '!'. Since (3.1.33) holds for all\n\u03c6 \u2208 [0, 1]\u039b , the random variables Pois( cb Y) and Y are equal in distribution. By Lemma 3.5,\n|Y| \u2208 {0, \u221e} a.s. and therefore if \u03bc is nontrivial then L(Pois( bc Y)) is nontrivial.\nIn view of Theorem 3.3 (d), it is natural to ask if for infinite lattices, every invariant law of\nthe (a, b, c, d)-braco-process is the Poissonization of an invariant law of the (a, b, c, d)-resemprocess. We do not know the answer to this question.\nIn order to give a very short proof of Theorem 3.4, we need one more lemma.\nLemma 3.6 (Systems with particles everywhere) Assume that (\u039b, a) is infinite and\nhomogeneous and that G is a transitive subgroup of Aut(\u039b, a). Let X be the (a, b, c, d)-braco\nprocess started in a G-homogeneous nontrivial initial law L(X0 ). Then, for any t > 0\nlim P [Thin\u03c6n (Xt ) = 0] = 0,\n\n(3.1.34)\n\nn\u2192\u221e\n\nfor all \u03c6n \u2208 [0, 1]\u039b satisfying |\u03c6n | \u2192 \u221e.\nProof of Theorem 3.4 (a) Let X \u2020 denote the (a\u2020 , b, c, d)-resem-process started in \u03c6. By\nTheorem 3.1 (a), Lemmas 3.5 and 3.6, and Theorem 3.2 (f),\nlim P [Thin\u03c6 (Xt ) = 0] = lim P [ThinX \u2020 (X1 ) = 0]\nt\u2192\u221e\nZt\u22121\n\u2020\n= P [\u2203t \u2265 0 such that Xt = 0] = \u03bd(dx) (1 \u2212 \u03c6)x .\n\nt\u2192\u221e\n\n(3.1.35)\n\nSince this holds for all \u03c6 \u2208 [0, 1]\u039b , it follows that L(Xt ) \u21d2 \u03bd.\nProof of Theorem 3.4 (b) Let X\u221e and X\u221e be random variables with laws \u03bd and \u03bc, respectively. Let X be the (a, b, c, d)-resem-process started in a G-homogeneous nontrivial initial\nlaw L(X0 ). Let X be the (a, b, c, d)-braco-process started in L(X0 ) := L(Pois( bc X0 )). Then by\nTheorem 3.4 (a), L(Xt ) \u21d2 L(X\u221e ) as t \u2192 \u221e. Therefore, by Poissonization (Theorem 3.1 (c))\nand by Theorem 3.3 (d), L(Pois( cb Xt )) \u21d2 L(X\u221e ) = L(Pois( bc X\u221e )). It follows that\nb\n\u0003\n\u0002\nP e \u2212 c hXt , \u03c6i = P [Thin\u03c6 (Pois( cb Xt )) = 0]\n\nb\n\u0003\n\u0002\n=\u21d2 P [Thin\u03c6 (Pois( cb X\u221e )) = 0] = P e \u2212 c hX\u221e , \u03c6i\n\n(3.1.36)\nas t \u2192 \u221e.\n\nSince this holds for all \u03c6 \u2208 [0, 1]\u039b , we conclude that L(Xt ) \u21d2 L(X\u221e ).\nNote that there is no easy way to convert the last argument: if L(X0 ) is homogeneous and nontrivial then we cannot in general find a random variable X0 such that L(X0 ) = L(Pois( cb X0 )).\n\n\f119\n\n3.1. INTRODUCTION AND MAIN RESULTS\n\nFor example, this is the case if X0 (i) \u2264 1 for each i \u2208 \u039b a.s. Therefore, Theorem 3.4 (a) is\nstronger than Theorem 3.4 (b).\nSummarizing, all the hard work for getting Theorem 3.4 is in proving Lemmas 3.5 and 3.6,\nas well as the more basic Theorems 3.1 and 3.2. The heart of the proof of Theorem 3.2 is the\nbound in part (b). We derive this bound using a 'duality' relation with a nonnegative error\nterm, between the (a, b, c, d)-braco-process and a super random walk (Proposition 3.23). We\ncall this relation a subduality. Theorem 3.2 (b) yields a lower bound on the finite time extinction probabilities of the (a, b, c, d)-resem-process started with small initial mass (Lemma 3.24,\nin particular formula (3.6.1)), which plays a key role in the proof of Lemma 3.5.\nOur methods are similar to those of Shiga and Uchiyama [SU86]. Since they prove a version\nof our Theorem 3.4 (b), while our main focus is on proving the stronger Theorem 3.4 (a), the\nroles of X and X are interchanged in their work. Their Lemma 3.2 and Theorem 4.2 are\nanalogues for the (a, b, c, d)-braco-process X of our Lemma 3.5. The proof of the latter is\nconsiderably more involved, however. This is because of the fact that we do not want to use\nspatial homogeneity and we have to prove that |Xt | \u2192 0 implies Xt = 0 for some t \u2265 0, which is\nobvious for the (a, b, c, d)-braco-process X. On the other hand, we can use the submartingale\nb\nproperty of e\u2212 c |Xt | , a very useful fact that has no analogue for the particle system. Lemma 2.5\nin [SU86] is the analogue for the (a, b, c, d)-resem-process X of our Lemma 3.6. By adapting\nelements of their proof to our situation, we were able to simplify and considerably shorten our\noriginal proof of Lemma 3.6.\nOur original proof of Lemma 3.6 assumed that \u039b has a group structure, and used an L2\nspatial ergodic theorem for general countable groups that need not be amenable.\n\n3.1.6\n\nDiscussion\n\nGeneralizing our model, let X be a process in a Liggett-Spitzer subspace of N\u039b , with local\njump rates\nx 7\u2192 x + \u03b4j \u2212 \u03b4i\nwith rate a(i, j)\nPk\n(n) ,\nx 7\u2192 x + \u03b4i\nwith rate\n(3.1.37)\nn=0 bn x\nPk+1\n(n) ,\nx 7\u2192 x \u2212 \u03b4i\nwith rate\nn=1 cn x\n\nwhere x(0) := 1 and x(n) := x(x \u2212 1) * * * (x \u2212 n + 1) (n \u2265 1). In particular, the (a, b, c, d)braco-process corresponds to the case k = 1, b0 = 0, b1 = b, c1 = d, and c2 = c. Processes\nwith jump rates as in (3.1.37) are known as reaction-diffusion systems. It has been known for\na long time that if the coefficients satisfy\na = a\u2020\n\nand\n\nbn = \u03bbcn\n\nfor some\n\n\u03bb \u2265 0,\n\n(3.1.38)\n\nthen L(Pois(\u03bb)) is a reversible equilibrium for the corresponding reaction-diffusion system.\nNote that the (a, b, c, d)-braco-process satisfies (3.1.38) if and only if a = a\u2020 and d = 0.\nThe ergodic behavior of reaction-diffusion systems on \u039b = Zd satisfying the reversibility\ncondition (3.1.38) was studied by Ding, Durrett and Liggett in [DDL90]. For our model\nwith a = a\u2020 and d = 0 on Zd , they show that all homogeneous invariant measures are convex\ncombinations of \u03b40 and L(Pois( cb )). Their proof uses the fact that for a large block in Zd , surface\n\n\f120\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nterms are small compared to volume terms, i.e., Zd is amenable. Such arguments typically\nfail on nonamenable lattices such as trees, and therefore it is not immediately obvious if their\nmethods can be generalized to such lattices. Our Theorem 3.4 (a) shows that all homogeneous\ninvariant measures of the (a, b, c, d)-braco-process are convex combinations of \u03b40 and \u03bd, also\nin the non-reversible case d > 0 and for nonamenable lattices. Thus, neither reversibility nor\namenability are essential here.\nOn the other hand, we believe that amenability is essential for more subtle ergodic properties of reaction-diffusion processes. In analogy with the contact process, let us say that a\nreaction-diffusion process with b0 = 0 exhibits complete convergence, if\nP x [Xt \u2208 * ] \u21d2 \u03c1(x)\u03bd + (1 \u2212 \u03c1(x))\u03b40\n\nas\n\nt\u2192\u221e\n\n(x \u2208 N (\u039b)),\n\n(3.1.39)\n\nwhere \u03c1(x) := P x [Xt 6= 0 \u2200t \u2265 0] denotes the survival probability. It has been shown by\nMountford [Mou92] that complete convergence holds for reaction-diffusion systems on \u039b = Zd\nsatisfying the reversibility condition (3.1.38), b0 = 0, and a first moment condition on a.\nWe conjecture that complete convergence holds more generally if a = a\u2020 and \u039b is amenable,\nbut not in general on nonamenable lattices. As a motivation for this conjecture, we note that\ncomplete convergence holds for the contact process on Zd but not in general on Td ; see Liggett\n[Lig99].\nThe self-duality of resampling-selection processes (Theorem 3.1 (b)) is reminiscent of the\nself-duality of the contact process. It is an interesting question whether our methods can\nbe adapted to the contact process, to show that the upper invariant measure of the contact\nprocess on a countable group is the limit started from any homogeneous nontrivial initial law.\nOther interesting processes that some of our techniques might be applied to are multitype\nbranching-coalescing particle systems. For example, it seems natural to color the particles in a\nbranching-coalescing particle system in two (or more) colors, with the rule that in coalescence\nof differently colored particles, the newly created particle chooses the color of one of its parents\nwith equal probabilities (neutral selection) or with a prejudice towards one color (positive\nselection). More difficult questions refer to what happens when the two colors have different\nparameters b, c, d or even different underlying motions a.\nOne also wonders whether the techniques in this chapter can be generalized to reactiondiffusion processes with higher-order branching and coalescence as in (3.1.37). It seems that\nat least some of these systems have some sort of a resampling-selection dual too, now with\n'resampling' and 'selection' events involving three and more particles.\nWe conclude with an intriguing question. Does survival of the (a, b, c, d)-braco-process X\nimply survival of the (a\u2020 , b, c, d)-braco-process X \u2020 ? If X survives, then Theorem 3.3 (c) and\n(d) and Theorem 3.4 (a) show that the upper invariant measure of X \u2020 is nontrivial, which\nsuggests that X \u2020 should survive. Survival of X \u2020 is obvious if (\u039b, a) and (\u039b, a\u2020 ) are isomorfic,\nas is the case if a = a\u2020 , or if \u039b is an Abelian group, with group action denoted by +, and\na(i, j) depends only on j \u2212 i. However, even when (\u039b, a) is homogeneous, (\u039b, a) and (\u039b, a\u2020 )\nneed in general not be isomorphic, and in this case we don't know the answer to our question.\n\n\f121\n\n3.2. MARTINGALE PROBLEMS\n\n3.1.7\n\nOutline\n\nWe start in Section 3.2 with a few generalities about martingale problems that will be needed\nin our proofs. In Section 3.3 we construct (a, b, c, d)-braco-processes and (a, b, c, d)-resemprocesses and prove some of their elementary properties, such as comparison, approximation\nwith finite systems, moment estimates and martingale problems. Section 3.4 contains the\nproof of Theorem 3.1 and of the subduality between branching-coalescing particle systems\nand super random walks. In Section 3.5 we prove Theorems 3.2 and 3.3. In Section 3.6,\nfinally, we prove Lemma 3.5 and Lemma 3.6, thereby completing the proof of Theorem 3.4.\n\nAcknowledgements We thank Klaus Fleischmann who played a stimulating role during\nthe early stages of this project and answered a question about Laplace functionals, Claudia\nNeuhauser for answering questions about branching-coalescing processes, Olle H\u00e4ggstr\u00f6m for\nanswering questions on nonamenable groups, and Tokuzo Shiga for answering our questions\nabout his work. We thank the referee for drawing our attention to the reference [SU86]. Part\nof this work was carried out during the visits of Siva Athreya to the Weierstrass Institute for\nApplied Analysis and Stochastics, Berlin and to the Friedrich-Alexander University ErlangenNuremberg, and of Jan Swart to the Indian Statistical Institute, Delhi. We thank all these\nplaces for their kind hospitality.\n\n3.2\n3.2.1\n\nMartingale problems\nDefinitions\n\nIf E be a metrizable space, we denote by M (E), B(E) the spaces of real Borel measurable and\nbounded real Borel measurable functions on E, respectively. If A is a linear operator from a\ndomain D(A) \u2282 M (E) into M (E) and X is an E-valued process, then we say that X solves\nthe martingale problem for A if X has cadlag sample paths and for each f \u2208 D(A),\n\u0002\n\n\u0003\nE |f (Xt )| < \u221e\n\nand\n\nZ\n\nt\n\n\u0002\n\u0003\nE |Af (Xs )| ds < \u221e\n\n0\n\nand the process (Mt )t\u22650 defined by\nMt := f (Xt ) \u2212\n\nZ\n\n(t \u2265 0),\n\n(3.2.1)\n\nt\n\nAf (Xs )ds\n0\n\n(t \u2265 0)\n\n(3.2.2)\n\nis a martingale with respect to the filtration generated by X.\n\n3.2.2\n\nDuality with error term\n\nFor later use in Section 3.4, we formulate a theorem giving sufficient conditions for two martingale problems to be dual to each other up to a possible error term. Although the techniques\nfor proving Theorem 3.7 below are well-known (see, for example, [EK86, Section 4.4]), we\ndon't know a good reference for the theorem as is formulated here.\n\n\f122\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nTheorem 3.7 (Duality with error term) Assume that E1 , E2 are metrizable spaces and\nthat for i = 1, 2, Ai is a linear operator from a domain D(Ai ) \u2282 B(Ei ) into M (Ei ). Assume\nthat \u03a8 \u2208 B(E1 \u00d7 E2 ) satisfies \u03a8(*, x2 ) \u2208 D(A1 ) and \u03a8(x1 , *) \u2208 D(A2 ) for each x1 \u2208 E1 and\nx2 \u2208 E2 , and that\n(x1 \u2208 E1 , x2 \u2208 E2 )\n(3.2.3)\nare jointly measurable in x1 and x2 . Assume that X 1 and X 2 are independent solutions to the\nmartingale problems for A1 and A2 , respectively, and that\nZ T Z T\n\u0003\n\u0002\n(T \u2265 0, i = 1, 2).\n(3.2.4)\nds dt E |\u03a6i (Xs1 , Xt2 )| < \u221e\n\u03a61 (x1 , x2 ) := A1 \u03a8(*, x2 )(x1 )\n\n\u03a62 (x1 , x2 ) := A2 \u03a8(x1 , *)(x2 )\n\nand\n\n0\n\n0\n\nThen\n\nE[\u03a8(XT1 , X02 )]\n\n\u2212\n\nE[\u03a8(X01 , XT2 )]\n\n=\n\nwhere R(x1 , x2 ) := \u03a61 (x1 , x2 ) \u2212 \u03a62 (x1 , x2 )\n\nZ\n\nT\n0\n\ndt E[R(Xt1 , XT2 \u2212t )]\n\n(T \u2265 0),\n\n(3.2.5)\n\n(x1 \u2208 E1 , x2 \u2208 E2 ).\n\nProof Put\nF (s, t) := E[\u03a8(Xs1 , Xt2 )]\n\n(s, t \u2265 0).\n\n(3.2.6)\n\nThen, for each T > 0,\nZ T\nZ T\n\b\n\b\ndt F (T \u2212 t, t) \u2212 F (0, t) \u2212 F (T \u2212 t, t) + F (t, 0)\ndt F (t, 0) \u2212 F (0, t) =\n0\nZ T\nZ0 T\n\b\n\b\ndt F (t, T \u2212 t) \u2212 F (t, 0) ,\ndt F (T \u2212 t, t) \u2212 F (0, t) \u2212\n=\n0\n\n0\n\nX1\n\n(3.2.7)\nsolves the martingale\n\nwhere we have subsituted t 7\u2192 T \u2212 t in the term \u2212F (T \u2212 t, t). Since\nproblem for A1 ,\nZ T \u2212t\n\u0002\n\u0003\n\u0002\n\u0003\n\u0002\n\u0003\n1\n1\nds E \u03a61 (Xs1 , x2 )\n(x2 \u2208 E2 ),\nE \u03a8(XT \u2212t , x2 ) \u2212 E \u03a8(X0 , x2 ) =\n\n(3.2.8)\n\n0\n\nand therefore, integrating the x2 -variable with respect to the law of Xt2 , using the independence\nof X 1 and X 2 and (3.2.4), we find that\nZ T\nZ T\n\b \u0002\n\u0003\n\u0002\n\u0003\n\b\ndt E \u03a8(XT1 \u2212t , Xt2 ) \u2212 E \u03a8(X01 , Xt2 )\ndt F (T \u2212 t, t) \u2212 F (0, t) =\n0\n0\nZ T Z t\nZ T Z T \u2212t\n(3.2.9)\n\u0002\n\u0003\n\u0002\n\u0003\n1\n1\n, Xs2 ) .\ndt ds E \u03a61 (Xt\u2212s\nds E \u03a61 (Xs , Xt2 ) =\ndt\n=\n0\n\n0\n\n0\n\n0\n\nTreating the second term in the right-hand side of (3.2.7) in the same way, we find that\nZ T Z t\nZ T Z t\nZ T\n\u0002\n\u0003\n\u0002\n\u0003\n\b\n1\n1\n, Xs2 ) .\n, Xs2 ) \u2212 dt ds E \u03a62 (Xt\u2212s\ndt ds E \u03a61 (Xt\u2212s\ndt F (t, 0) \u2212 F (0, t) =\n0\n\n0\n\n0\n\nDifferentiating with respect to T we arrive at (3.2.5).\n\n0\n\n0\n\n(3.2.10)\n\n\f123\n\n3.3. CONSTRUCTION AND COMPARISON\n\n3.3\n3.3.1\n\nConstruction and comparison\nFinite branching-coalescing particle systems\n\nFor finite initial conditions, the (a, b, c, d)-braco-process X can be constructed explicitly using\nexponentially distributed random variables. The only thing one needs to check is that X does\nnot explode. This is part of the next proposition. Recall the definitions of N (\u039b) and S(N (\u039b))\nfrom (3.1.10) and of G from (3.1.1).\nProposition 3.8 (Finite braco-processes) Let X be the (a, b, c, d)-braco-process started in\na finite state x. Then X does not explode. Moreover, with z hki := z(z + 1) * * * (z + k \u2212 1), one\nhas\n\u0002 hki \u0003\n\u2264 |x|hki ekbt\n(k = 1, 2, . . . , t \u2265 0).\n(3.3.1)\nE x |X|t\nFor each f \u2208 S(N (\u039b)), one has Gf \u2208 S(N (\u039b)) and X solves the martingale problem for the\noperator G with domain S(N (\u039b)).\nProof Introduce stopping times \u03c4N := inf{t \u2265 0 : |Xt | \u2265 N }. Put ftk (x) := |x|hki e\u2212kbt . It is\neasy to see that\n\u2202\n{G + \u2202t\n}ftk (x) \u2264 kb|x|hki e\u2212kbt \u2212 kb|x|hki e\u2212kbt = 0.\n(3.3.2)\n\nThe stopped process (Xt\u2227\u03c4N )t\u22650 is a jump process in {x \u2208 N\u039b : |x| \u2264 N } with bounded jump\nrates, and therefore standard theory tells us that the process (Mt )t\u22650 given by\nZ t\u2227\u03c4N\n\u0001\nk\n\u2202\n}fsk (Xs ) ds\n(t \u2265 0)\n(3.3.3)\nMt := ft\u2227\u03c4N (Xt\u2227\u03c4N ) \u2212\n{G + \u2202s\n0\n\n\u0002\n\u0003\nis a martingale. By (3.3.2), it follows that E x |Xt\u2227\u03c4N |hki e\u2212kb(t\u2227\u03c4N ) \u2264 |x|hki and therefore\n\u0002\n\u0003\nE x |Xt\u2227\u03c4N |hki \u2264 |x|hki ekbt\n\n(k = 1, 2, . . . , t \u2265 0).\n\n(3.3.4)\n\nIn particular, setting k = 1, we see that\n\n\u0002\n\u0003\nN P x [\u03c4N \u2264 t] \u2264 E x |Xt\u2227\u03c4N | \u2264 |x|ebt\n\n(t \u2265 0),\n\n(3.3.5)\n\nwhich shows that limN \u2192\u221e P x [\u03c4N \u2264 t] = 0 for all t \u2265 0, i.e., the process does not explode.\nTaking the limit N \u2191 \u221e in (3.3.4), using Fatou, we arrive at (3.3.1).\nIf f \u2208 S(N (\u039b)) then f is bounded on sets of the form {x \u2208 N\u039b : |x| \u2264 N }, and therefore\nGf is well-defined. By standard theory, the processes (MtN )t\u22650 given by\nZ t\u2227\u03c4N\nGf (Xs )ds\n(t \u2265 0)\n(3.3.6)\nMtN := f (Xt\u2227\u03c4N ) \u2212\n0\n\nmartingales. It is easy to see that f \u2208 S(N (\u039b)) implies Gf \u2208 S(N (\u039b)), and therefore\nRare\nt\nE[|Gf\n(Xs )|ds < \u221e for all t \u2265 0 by (3.3.1). Using (3.3.4), one can now check that for\n0\nfixed t \u2265 0, the random variables {MtN }N \u22651 are uniformly integrable. Taking the pointwise\nlimit in (3.3.6), one can now check that X solves the martingale problem for G with domain\nS(N (\u039b)).\n\n\f124\n\n3.3.2\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nMonotonicity and subadditivity\n\nIn this section we present two simple comparison results for finite branching-coalescing particle\nsystems.\nLemma 3.9 (Comparison of branching-coalescing particle systems) Let X and X\u0303 be\n \u0303\nthe (a, b, c, d)-braco-process and the (a, b\u0303, c\u0303, d)-braco-process\nstarted in finite initial states x and\nx\u0303, respectively. Assume that\nx \u2264 x\u0303,\n\nb \u2264 b\u0303,\n\nc \u2265 c\u0303,\n\n \u0303\nd \u2265 d.\n\n(3.3.7)\n\nThen X and X\u0303 can be coupled in such a way that\nXt \u2264 X\u0303t\n\n(t \u2265 0).\n\n(3.3.8)\n\nProof We will construct a bivariate process (B, W ), say of black and white particles, such\nthat X = B are the black particles and X\u0303 = B + W are the black and white particles together.\nTo this aim, we let the particles evolve in such a way that black and white particles branch\nwith rates b and b\u0303, respectively, and additionally black particles give birth to white particles\nwith rate b\u0303 \u2212 b. Moreover, all pairs of particles coalesce with rate 2c\u0303, where the new particle\nis black if at least one of its parents is black, and additionally each pair of black particles is\nwith rate 2c \u2212 2c\u0303 replaced by a pair consisting of one black and one white particle. Finally,\n \u0303 and additionally, black particles change into white particles with\nall particles die with rate d,\n \u0303\nrate d \u2212 d. It is easy to see that with these rules, X and X\u0303 are the (a, b, c, d)-braco-process\n \u0303\nand the (a, b\u0303, c\u0303, d)-braco-process,\nrespectively.\nThe next lemma has been proved for \u039b = Zd in [SU86, Lemma 2.2]. It can be proved (with\nparticles in three colors) in a similar way as the previous lemma.\nLemma 3.10 (Subadditivity) Let X, Y, Z be (a, b, c, d)-braco-processes started in finite initial states x, y, and x + y, respectively. Then X, Y, Z may be coupled in such a way that X\nand Y are independent and\nZt \u2264 Xt + Yt\n(t \u2265 0).\n(3.3.9)\n\n3.3.3\n\nInfinite branching-coalescing particle systems\n\nIn this section we carry out the construction of branching-coalescing particle systems for\ninfinite initial conditions. We will also derive two results on the approximation of infinite\nsystems with finite systems, that are needed later on. Except for the statement about sample\npaths, the next proposition has been proved in [Che87], but we give a proof here for the sake\nof completeness.\nProposition 3.11 (Construction of branching-coalescing particle systems) For each\nf \u2208 CLip (E\u03b3 (\u039b)) and t \u2265 0, the function St f defined in (3.1.11) can be extended to a unique\nLipschitz function on E\u03b3 (\u039b), also denoted by St f . There exists a unique (in distribution) timehomogeneous Markov process with cadlag sample paths in the space E\u03b3 (\u039b) equipped with the\nnorm k * k\u03b3 , such that\nE x [f (Xt )] = St f (x)\n\n(f \u2208 CLip (E\u03b3 (\u039b)), x \u2208 E\u03b3 (\u039b), t \u2265 0).\n\n(3.3.10)\n\n\f125\n\n3.3. CONSTRUCTION AND COMPARISON\nWe start with the following lemma.\n\nLemma 3.12 (Action of the semigroup on Lipschitz functions) If f : N (\u039b) \u2192 R is\nLipschitz continuous in the norm k * k\u03b3 from (3.1.14), with Lipschitz constant L, and K is the\nconstant from (3.1.12), then\n|St f (x) \u2212 St f (y)| \u2264 Le(K+b\u2212d)t kx \u2212 yk\u03b3\n\n(x, y \u2208 N (\u039b), t \u2265 0).\n\n(3.3.11)\n\n\u2202\nE[f (Xt )] = E[Gf (Xt )] for all f \u2208 S(N (\u039b)),\nProof It follows from Propostion 3.8 that \u2202t\nt \u2265 0. Applying this to the function f (x) := kxk\u03b3 we see that\nX\n\u2202 x\na(i, j)(\u03b3j \u2212 \u03b3i )E[Xt (i)] + (b \u2212 d)E x [kXt k\u03b3 ]\n\u2202t E [kXt k\u03b3 ] =\nij\n\n\u2212c\n\nX\ni\n\n(3.3.12)\n\n\u03b3i E[Xt (i)(Xt (i) \u2212 1)] \u2264 (K + b \u2212 d)E[kXk\u03b3 ],\n\nand therefore\nE x [kXt k\u03b3 ] \u2264 e(K+b\u2212d)t kxk\u03b3\n\n(x \u2208 N (\u039b)).\n\n(3.3.13)\n\nLet X x denote the (a, b, c, d)-braco-process started in x. By Lemma 3.9, we can couple X x ,\nX y , X x\u2227y , and X x\u2228y such that Xtx\u2227y \u2264 Xtx , Xty \u2264 Xtx\u2228y for all t \u2265 0. It follows that\nE[kXtx \u2212 Xty k\u03b3 ] \u2264 E[kXtx\u2228y \u2212 Xtx\u2227y k\u03b3 ].\n\n(3.3.14)\n\nBy Lemma 3.10, we can couple X x\u2227y and X x\u2228y to the process X |x\u2212y| such that Xtx\u2228y \u2264\n|x\u2212y|\nfor all t \u2265 0. Therefore, by (3.3.14) and (3.3.13),\nXtx\u2227y + Xt\n|x\u2212y|\n\nE[kXtx \u2212 Xty k\u03b3 ] \u2264 E[kXt\n\nk\u03b3 ] \u2264 kx \u2212 yk\u03b3 e(K+b\u2212d)t ,\n\n(3.3.15)\n\nwhich implies that\n|St f (x) \u2212 St f (y)| \u2264 E[|f (Xtx ) \u2212 f (Xty )|] \u2264 LE[kXtx \u2212 Xty k\u03b3 ] \u2264 Lkx \u2212 yk\u03b3 e(K+b\u2212d)t , (3.3.16)\nas required.\nSince Lipschitz functions on N (\u039b) have a unique Lipschitz extension to E\u03b3 (\u039b), Lemma 3.12\nimplies that St f can be uniquely extended to a function in CLip (E\u03b3 (\u039b)) for each f \u2208 CLip (E\u03b3 (\u039b)).\nLemma 3.13 (Construction of the process for fixed times) Let X (n) be (a, b, c, d)-bracoprocesses started in initial states x(n) \u2208 N (\u039b) such that x(n) \u2191 x for some x \u2208 E\u03b3 (\u039b). Then\n\u039b\n(n)\nthe X (n) may be coupled such that Xt \u2191 Xt (t \u2265 0) for some N -valued process X = (Xt )t\u22650 .\nThe process X satisfies Xt \u2208 E\u03b3 (\u039b) a.s. \u2200t \u2265 0 and X is a Markov process with semigroup\n(St )t\u22650 .\n(n)\n\n(n+1)\n\nProof It follows from Lemma 3.9 that the X (n) can be coupled such that Xt \u2264 Xt\n\u039b\n(n)\n(t \u2265 0), and therefore Xt \u2191 Xt (t \u2265 0) for some N -valued random variables Xt . By (3.3.15),\n\u0002 (m)\n\u0002\n(n) \u0003\n(n) \u0003\n(3.3.17)\nE kXt \u2212 Xt k\u03b3 = lim E kXt \u2212 Xt k\u03b3 \u2264 kx \u2212 x(n) k\u03b3 e(K+b\u2212d)t .\nm\u2191\u221e\n\n\f126\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nThis shows in particular that E[kXt k\u03b3 ] < \u221e and therefore Xt \u2208 E\u03b3 (\u039b) a.s. \u2200t \u2265 0. If\nf \u2208 CLip (E\u03b3 (\u039b)) has Lipschitz constant L, then by (3.3.17),\n(n)\n\n(n)\n\n|E[f (Xt )] \u2212 E[f (Xt )]| \u2264 E[|f (Xt ) \u2212 f (Xt )|]\n\n(3.3.18)\n\n(n)\n\n\u2264 LE[kXt \u2212 Xt k\u03b3 ] \u2264 Lkx \u2212 x(n) k\u03b3 e(K+b\u2212d)t ,\n\nand therefore\n\n(n)\n\nE[f (Xt )] = lim E[f (Xt )] = lim St f (x(n) ) = St f (x).\n\n(3.3.19)\n\nn\u2191\u221e\n\nn\u2191\u221e\n\nThis proves thatRfor each x \u2208 E\u03b3 (\u039b) and t \u2265 0 there exists a probability measure Pt (x, *) on\nE\u03b3 (\u039b) such that Pt (x, dy)f (y) = St f (x) for all f \u2208 CLip (E\u03b3 (\u039b)). We need to show that X is\nthe Markov process with transition probabilities Pt (x, dy). Let CLip,b (E\u03b3 (\u039b)) denote the class\nof bounded Lipschitz functions on E\u03b3 (\u039b). Then CLip,b (E\u03b3 (\u039b)) is closed under multiplication\nand St maps CLip,b (E\u03b3 (\u039b)) into itself. Therefore, for all 0 \u2264 t0 < * * * < tk and f1 , . . . , fk \u2208\nCLip,b (E\u03b3 (\u039b)), one has\n\u0002\n(n) \u0003\n(n)\nE f1 (Xt1 ) * * * fk (Xtk ) = St1 f1 St2 \u2212t1 f2 * * * Stk \u2212tk\u22121 fk (x(n) ).\n\n(3.3.20)\n\nIt follows from (3.3.17) that\n\nk\nY\nX\n\u0003\n\u0002\n(n) \u0003\n(n)\n(n)\nkfj k\u221e ,\nLi e(K+b\u2212d)tk\nE f1 (Xt1 ) * * * fk (Xtk ) \u2212 E f1 (Xt1 ) * * * fk (Xtk ) \u2264 kx \u2212 x k\u03b3\n\n\u0002\n\ni=1\n\nj6=i\n\n(3.3.21)\nwhere Li is the Lipschitz constant of fi . Taking the limit n \u2191 \u221e in (3.3.20), using (3.3.21), we\nsee that\n\u0003\n\u0002\n(3.3.22)\nE f1 (Xt1 ) * * * fk (Xtk ) = St1 f1 St2 \u2212t1 f2 * * * Stk \u2212tk\u22121 fk (x),\ni.e., X is the Markov process with semigroup (St )t\u22650 .\n\nProof of Proposition 3.11 We need to show that the process X from Lemma 3.13 satisfies\nXt \u2208 E\u03b3 (\u039b) \u2200t \u2265 0 a.s. (and not just for fixed times) and that (Xt )t\u22650 has cadlag sample paths\nwith respect to the norm k * k\u03b3 . It suffices to prove these facts on the time interval [0, 1]. We\nwill do this by constructing an E\u03b3 (\u039b)-valued process Z such that Z makes only upward jumps,\nand the number of upward jumps of Z dominates the number of upward jumps of X.\nCouple the process X (n) from Lemma 3.13 to a process Y (n) such that the joint process\n(n)\n(X , Y (n) ) is the Markov process in N (\u039b) \u00d7 N (\u039b) with generator\nGX,Y f (x, y) :=\nX\nX\na(i, j)x(i){f (x + \u03b4j \u2212 \u03b4i , y + \u03b4i ) \u2212 f (x, y)} +\na(i, j)y(i){f (x, y + \u03b4j ) \u2212 f (x, y)}\nij\n\nij\n\nX\ni\n\nx(i){f (x + \u03b4i , y) \u2212 f (x, y)} + b\n\nX\n\ny(i){f (x, y + \u03b4i ) \u2212 f (x, y)}\ni\ni\nX\nX\n+c\nx(i)(x(i) \u2212 1){f (x \u2212 \u03b4i , y + \u03b4i ) \u2212 f (x, y)} + d\nx(i){f (x \u2212 \u03b4i , y + \u03b4i ) \u2212 f (x, y)}.\n+b\n\ni\n\n(3.3.23)\n\n\f127\n\n3.3. CONSTRUCTION AND COMPARISON\n(n)\n\n(n)\n\nand initial state (X0 , Y0 ) = (x(n) , 0). Indeed, it is not hard to see that the first component\nof the process with generator GX,Y is the (a, b, c, d)-braco-process, and that Z (n) := X (n) +Y (n)\nis the Markov process in N (\u039b) with generator\nX\nX\nGZ f (z) :=\na(i, j)z(i){f (z + \u03b4j ) \u2212 f (z)} + b\nz(i){f (z + \u03b4i ) \u2212 f (z)}\n(3.3.24)\nij\n\ni\n\n(n)\n\nand initial state Z0\n\n= x(n) . In analogy with (3.3.13) it is easy to check that\n(n)\n\nE z [kZt k\u03b3 ] \u2264 kx(n) k\u03b3 e(K+b)t\n\n(z \u2208 N (\u039b), t \u2265 0).\n\n(3.3.25)\n\nZ (n) makes only upward jumps and Z (n) (i) makes at least as many upward jumps as X (n) (i).\nSince X (n) (i) cannot become negative, it follows that\n(n)\n\n(n)\n\n(n)\n\n|{t \u2208 [0, 1] : Xt\u2212 (i) 6= Xt (i)}| \u2264 x(n) (i) + 2Z1 (i).\nSumming with respect to the \u03b3i , taking expectations, using (3.3.25), we see that\nX\n\u0003\n\u0002\n(n)\n(n)\n\u03b3i E |{t \u2208 [0, 1] : Xt\u2212 (i) 6= Xt (i)}| \u2264 kx(n) k\u03b3 (1 + 2eK+b ).\n\n(3.3.26)\n\n(3.3.27)\n\ni\n\nLet Z be the increasing limit of the processes Z (n) . It follows from (3.3.25) that Z1 \u2208 E\u03b3 (\u039b)\na.s. Now\nXt , Xt\u2212 \u2264 Zt \u2264 Z1\n\u2200t \u2208 [0, 1] a.s.,\n(3.3.28)\nand therefore Xt , Xt\u2212 \u2208 E\u03b3 (\u039b) \u2200t \u2208 [0, 1] a.s. Since a.s. all jumps occur at different times,\n(n)\n\n(n)\n\n|{t \u2208 [0, 1] : Xt\u2212 (i) 6= Xt (i)}| \u2191 |{t \u2208 [0, 1] : Xt\u2212 (i) 6= Xt (i)}|\n\nas n \u2191 \u221e.\n\nThus, taking the limit n \u2191 \u221e in (3.3.27) we see that\nX\n\u0002\n\u0003\n\u03b3i E |{t \u2208 [0, 1] : Xt\u2212 (i) 6= Xt (i)}| \u2264 kxk\u03b3 (1 + 2eK+b ).\n\n(3.3.29)\n\n(3.3.30)\n\ni\n\nThis proves that X has a.s. componentwise cadlag sample paths. If 1 \u2265 tn \u2193 t, then Xtn \u2192 Xt\npointwise and |Xtn \u2212 Xt | \u2264 2Z1 , and therefore, by dominated convergence,\nX\nkXtn \u2212 Xt k\u03b3 =\n\u03b3i |Xtn (i) \u2212 Xt (i)| \u2192 0.\n(3.3.31)\ni\n\nThe same argument shows that Xtn \u2192 Xt\u2212 for tn \u2191 t \u2264 1, i.e., X has cadlag sample paths\nwith respect to the norm k * k\u03b3 .\nThe proof of Proposition 3.11 yields a useful corollary.\nCorollary 3.14 (Locally finite number of jumps) The (a, b, c, d)-braco-process X satisfies\nX\n\u0002\n\u0003\n\u03b3i E x |{t \u2208 [0, 1] : Xt\u2212 (i) 6= Xt (i)}| \u2264 kxk\u03b3 (1 + 2eK+b ).\n(3.3.32)\ni\n\n\f128\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nWe can now prove two approximation lemmas.\nLemma 3.15 (Convergence of finite dimensional distributions) Let X xn , X x be the\n(a, b, c, d)-braco-process started in initial states xn , x \u2208 E\u03b3 (\u039b), respectively, such that\nlim kxn \u2212 xk\u03b3 = 0.\n\n(3.3.33)\n\nn\u2192\u221e\n\nThen, for all 0 \u2264 t1 < * * * < tk , one has\n(n)\n\n(n)\n\n(Xt1 , . . . , Xtk ) \u21d2 (Xt1 , . . . , Xtk )\n\nas n \u2192 \u221e.\n\n(3.3.34)\n\nProof Use (3.3.22) for xn and then let n \u2192 \u221e.\nLemma 3.16 (Monotonicities for infinite systems) Lemmas 3.9 and 3.10 also hold for\ninfinite initial states. If X x , X xn are (a, b, c, d)-braco-process started in initial states x, xn \u2208\nE\u03b3 (\u039b), such that xn \u2191 x, then X x , X xn may be coupled such that\nXtxn (i) \u2191 Xtx (i)\n\nas n \u2191 \u221e\n\n\u2200i \u2208 \u039b, t \u2265 0\n\na.s.\n\n(3.3.35)\n\nProof The proof of Proposition 3.11 shows that (3.3.35) holds if the xn are finite. To generalize\nLemma 3.9 to infinite initial states x, x\u0303, it therefore suffices to note that if x \u2264 x\u0303, then there\nexist finite xn \u2264 x\u0303n such that xn \u2191 x and x\u0303n \u2191 x\u0303, and then take the limit n \u2191 \u221e in (3.3.8)\nusing (3.3.35). Lemma 3.10 can be generalized to infinite x, y by approximation with finite\nxn , yn in the same way. Finally, to see that (3.3.35) remains valid if the xn are infinite, note\nthat by Lemma 3.9 (which has now been proved in the infinite case), the processes X xn can\nx\nbe coupled such that Xtxn (i) \u2264 Xt n+1 (i) for all i \u2208 \u039b and t \u2265 0. Denote the increasing limit\nof the X xn by X x . Lemma 3.15 shows that X x has the same finite dimensional distributions\nas the (a, b, c, d)-braco-process started in x and it follows from Corollary 3.14 that X x has\ncomponentwise cadlag sample paths, so X x is a version of the (a, b, c, d)-braco-process started\nin x.\n\n3.3.4\n\nConstruction and comparison of resampling-selection processes\n\nWe equip the space [0, 1]\u039b with the product topology and let C([0, 1]\u039b ) denote the space\n2 ([0, 1]\u039b )\nof continuous real functions on [0, 1]\u039b , equipped with the supremum norm. By Cfin\nwe denote the space of C 2 functions on [0, 1]\u039b depending on finitely many coordinates. By\n2 ([0, 1]\u039b ) is the space of continuous functions f on [0, 1]\u039b such that the partial\ndefinition, Csum\n\u2202\n\u22022\nderivatives \u2202\u03c6(i)\nf (\u03c6) and \u2202\u03c6(i)\u2202\u03c6(j)\nf (\u03c6) exist for each x \u2208 (0, 1)\u039b and such that the functions\n\u0001\n\u0001\n\u22022\n\u2202\nf (\u03c6) i\u2208\u039b and \u03c6 7\u2192 \u2202\u03c6(i)\u2202\u03c6(j)\nf (\u03c6) i,j\u2208\u039b\n\u03c6 7\u2192 \u2202\u03c6(i)\n(3.3.36)\n\ncan be extended to continuous functions from [0, 1]\u039b into the spaces l1 (\u039b) and l1 (\u039b2 ) of\nabsolutely summable sequences on \u039b and \u039b2 , respectively, equipped with the l1 -norm. Define\n2 ([0, 1]\u039b ) \u2192 C([0, 1]\u039b ) by\nan operator G : Csum\nX\nX\n\u2202\n\u2202\nf (\u03c6) + b\n\u03c6(i)(1 \u2212 \u03c6(i)) \u2202\u03c6(i)\nf (\u03c6)\nGf (\u03c6) :=\na(j, i)(\u03c6(j) \u2212 \u03c6(i)) \u2202\u03c6(i)\nij\n\n+c\n\nX\ni\n\n2\n\n\u2202\n\u03c6(i)(1 \u2212 \u03c6(i)) \u2202\u03c6(i)\n2 f (\u03c6) \u2212 d\n\ni\nX\ni\n\n\u2202\nf (\u03c6)\n\u03c6(i) \u2202\u03c6(i)\n\n(\u03c6 \u2208 [0, 1]\u039b ).\n\n(3.3.37)\n\n\f129\n\n3.3. CONSTRUCTION AND COMPARISON\n\n2 ([0, 1]\u039b ), the infinite sums converge in the supremumnorm and\nOne can check that for f \u2208 Csum\nthe result does not depend on the summation order [Swa99, Lemma 3.4.4]. If a [0, 1]\u039b -valued\nprocess X solves the martingale problem for G with domain Cfin ([0, 1]\u039b ), then also for the\nlarger domain Csum ([0, 1]\u039b ) (see [Swa99, Lemma 3.4.5]).\nLet C[0,1]\u039b [0, \u221e) denote the space of continuous functions from [0, \u221e) into [0, 1]\u039b , equipped\nwith the topology of uniform convergence on compacta. If X (n) , X are C[0,1]\u039b [0, \u221e)-valued\nrandom variables, then we say that X (n) converges in distribution to X , denoted as X (n) \u21d2 X ,\nwhen L(X (n) ) converges weakly to L(X ). Convergence in distribution implies convergence of\nthe finite-dimensional distributions (see [EK86, Theorem 3.7.8]). The fact that a C[0,1]\u039b [0, \u221e)valued random variable X solves the martingale problem for G is a property of the law of\nX only. Standard results from [EK86] yield the following (for the details, see for example\nLemma 4.1 in [Swa00]):\n\nLemma 3.17 (Existence and compactness of solutions to the martingale problem)\nFor each \u03c6 \u2208 [0, 1]\u039b , there exists a solution X to the martingale problem for G with initial\nstate X0 = \u03c6, and each solution to the martingale problem for G has continuous sample\npaths. Moreover, the space {L(X ) : X solves the martingale problem for G} is compact in the\ntopology of weak convergence.\nIf X solves the SDE (3.1.3), then X solves the martingale problem for G. Conversely, each\nsolution to the martingale problem for G is equal in distribution to some (weak) solution of\nthe SDE (3.1.3). Thus, existence of (weak) solutions to (3.1.3) follows from Lemma 3.17.\nDistribution uniqueness of solutions to (3.1.3) follows from pathwise uniqueness, which is in\nturn implied by the following comparison result.\nLemma 3.18 (Monotone coupling of linearly interacting diffusions) Let I\nclosed interval, let \u03c3 : I \u2192 R be H\u00f6lder- 12 -continuous, and let b1 , b2 : I \u2192 R be\ncontinuous functions such that b1 \u2264 b2 . Let X \u03b1 (\u03b1 = 1, 2) be solutions, relative to\nsystem of Brownian motions, of the SDE\nX\ndXt\u03b1 (i) =\na(j, i)(Xt\u03b1 (j) \u2212 Xt\u03b1 (i))dt + b\u03b1 (Xt\u03b1 (i))dt + \u03c3(Xt\u03b1 (i))dBt (i).\n\n\u2282 R be a\nLipschitz\nthe same\n\n(3.3.38)\n\nj\n\n(i \u2208 \u039b, t \u2265 0, \u03b1 = 1, 2). Then\nX01 \u2264 X02\n\nimplies\n\nXt1 \u2264 Xt2\n\n\u2200t \u2265 0\n\na.s.\n\n(3.3.39)\n\nProof (sketch) Set \u2206t (i) := Xt1 (i) \u2212 Xt2 (i) and write x+ := x \u2228 0. Using an appropriate\nsmoothing of the function x 7\u2192 x+ in the spirit of [YW71, Theorem 1] and arguing as in the\nproof of [SS80, Theorem 3.2], one can show that\nZ t\n+\nE[k\u2206+\n(3.3.40)\nE[k\u2206t k\u03b3 ] \u2264 (K + L)\ns k\u03b3 ]ds,\n0\n\nwhere k * k\u03b3 is the norm from (3.1.14), K is the constant from (3.1.12), and L is the Lipschitzconstant of b2 . The result now follows from Gronwall's inequality.\n\n\f130\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nCorollary 3.19 (Comparison of resampling-selection processes) Assume that X , X \u0303\nare solutions to the SDE (3.1.3), relative to the same collection of Brownian motions, with\n \u0303 and starting in initial states \u03c6, \u03c6\u0303, respectively. Assume\nparameters (a, b, c, d) and (a, b\u0303, c, d)\nthat\n \u0303\n\u03c6 \u2264 \u03c6\u0303, d \u2212 b \u2265 d \u0303 \u2212 b\u0303, d \u2265 d.\n(3.3.41)\nThen\n\nXt \u2264 X\u0303t\n\n\u2200t \u2265 0\n\na.s.\n\n(3.3.42)\n\n \u0303\nProof Immediate from Lemma 3.18 and the fact that by (3.3.41), bx(1\u2212x)\u2212dx \u2264 b\u0303x(1\u2212x)\u2212dx\nfor all x \u2208 [0, 1].\n\nOur next lemma shows that resampling-selection processes with finite initial mass have finite\nmass at all later times. The estimate (3.3.43) is not very good if b \u2212 d < 0, but it suffices for\nour purposes.\nLemma 3.20 (Summable resampling-selection processes) Let X be the (a, b, c, d)-resemprocess started in x \u2208 [0, 1]\u039b with |x| < \u221e. Set r := (b \u2212 d) \u2228 0. Then\n\u0002\n\u0003\nE x |Xt | \u2264 |x|ert\n(t \u2265 0),\n(3.3.43)\nand |Xt | < \u221e \u2200t \u2265 0 a.s.\n\nProof Without loss of generality we may assume that b \u2265 d; otherwise, using Corollary 3.19,\nwe can bound X from above by a braco-process with a higher b. Set r := b \u2212 d and put\nYt (i) := Xt (i)e\u2212rt . By It\u00f4's formula,\nX\np\ndYt (i) =\na(j, i)(Yt (j) \u2212 Yt (i)) dt \u2212 be\u2212rt Xt (i)2 dt + e\u2212rt cXt (i)(1 \u2212 Xt (i)) dBt (i). (3.3.44)\nj\n\nSet \u03c4N := inf{t \u2265 0 : |Xt | \u2265 N }. Integrate (3.3.44) up to t \u2227 \u03c4N and sum over i. The motion\nterms yield\nZ t\u2227\u03c4NX\na(j, i)(Ys (j) \u2212 Ys (i)) ds\n0\n\n=\n\nZ\n\n0\n\nij\nt\u2227\u03c4NX\nj\n\nX\ni\n\n\u0001\na(j, i) Ys (j) ds \u2212\n\nZ\n\n0\n\nt\u2227\u03c4NX\ni\n\n(3.3.45)\n\nX\nj\n\n\u2020\n\n\u0001\na (i, j) Ys (i) ds = 0,\n\nwhere the infinite sums converge in a bounded pointwise way since |Ys | \u2264 N for s \u2264 \u03c4N . It\nfollows that\nX Z t\u2227\u03c4Np\nX Z t\u2227\u03c4N\n2 \u2212rs\ncXs (i)(1 \u2212 Xs (i)) e\u2212rs dBs (i), (3.3.46)\nXs (i) e ds +\n|Yt\u2227\u03c4N | = |x| \u2212 b\ni\n\n0\n\ni\n\n0\n\nprovided we can show that the infinite sum of stochastic integrals converges. Indeed, for any\nfinite \u2206 \u2282 \u039b, by the It\u00f4 isometry,\nX h Z t\u2227\u03c4Np\n2i\nE\ncXs (i)(1 \u2212 Xs (i)) e\u2212rs dBs (i)\ni\u2208\u2206\n\n0\n\nX hZ\n=c\nE\ni\u2208\u2206\n\nt\u2227\u03c4N\n\n0\n\n\u22122rs\n\nXs (i)(1 \u2212 Xs (i))e\n\ni\n\nds \u2264 cE\n\nhZ\n\nt\u2227\u03c4N\n\n0\n\ni\n|Xs |ds \u2264 ctN,\n\n(3.3.47)\n\n\f131\n\n3.4. DUALITIES\n\nwhich shows that the stochastic integrals in (3.3.46) are absolutely summable in L2 -norm. It\nfollows from (3.3.46) that\nE x [|Xt\u2227\u03c4N |]e\u2212rt \u2264 E x [|Xt\u2227\u03c4N |e\u2212r(t\u2227\u03c4N ) ] = E x [|Yt\u2227\u03c4N |] \u2264 |x|.\n\n(3.3.48)\n\nNow N P x [\u03c4N \u2264 t] \u2264 |x|ert for all t \u2265 0, which shows that \u03c4N \u2191 \u221e as N \u2191 \u221e a.s. Letting\nN \u2191 \u221e in (3.3.48) we arrive at (3.3.43).\nWe conclude this section with two results on the continuity of X in its initial state.\nLemma 3.21 (Convergence in law) Assume that X (n) , X are (a, b, c, d)-resem-processes,\nstarted in x(n) , x \u2208 [0, 1]\u039b , respectively. Then x(n) \u2192 x implies X (n) \u21d2 X .\nProof By Lemma 3.17, the laws L(X (n) ) are tight and each cluster point of the L(X (n) ) solves\nthe martingale problem for G with initial state x. Therefore, by uniqueness of solutions to the\nmartingale problem, X (n) \u21d2 X .\nLemma 3.22 (Monotone convergence) Let X (n) , X be (a, b, c, d)-resem-processes started\nin x(n) , x \u2208 [0, 1]\u039b , respectively, such that\nx(n) \u2191 x\n\nas\n\nn \u2191 \u221e.\n\n(3.3.49)\n\nThen X (n) , X may be defined on the same probablity space such that\n(n)\n\nXt (i) \u2191 Xt (i)\n\n\u2200i \u2208 \u039b, t \u2265 0\n\nas\n\nn\u2191\u221e\n\na.s.\n\n(3.3.50)\n\nProof Let X (n) , X be solutions of the SDE (3.1.3) relative to the same system of Brownian\n(n)\n(n)\nmotions. By Corollary 3.19, X (n) \u2264 X (n+1) and X (n) \u2264 X for all n. Write \u2206t := Xt \u2212 Xt\n(n)\n(n)\nand set \u03c4\u03b5 := inf{t \u2265 0 : \u2206t \u2265 \u03b5}. A calculation as in the proof of Lemma 3.18 shows that\n(n)\n\n(n)\n\ndk\u2206t k\u03b3 \u2264 (K + b)k\u2206t kdt\nIt follows that\n\n+\n\nmartingale terms.\n\n\u0002 (n)\n\u0003\nE k\u2206 (n) k\u03b3 \u2264 kx \u2212 x(n) k\u03b3 e(K+b)t .\n\n(3.3.52)\n\nt\u2227\u03c4\u03b5\n\n(n)\n\n(n)\n\nNow \u03b5P [\u03c4\u03b5 \u2264 t] \u2264 kx \u2212 x(n) k\u03b3 e(K+b)t from which we conclude that \u03c4\u03b5\nevery \u03b5 > 0.\n\n3.4\n3.4.1\n\n(3.3.51)\n\n\u2191 \u221e as n \u2191 \u221e for\n\nDualities\nDuality and self-duality\n\nProof of Theorem 3.1 (a) We first prove the statement for finite x. We apply Theorem 3.7.\nOur duality function is\n\u03a8(x, \u03c6) := (1 \u2212 \u03c6)x\n\n(x \u2208 N (\u039b), \u03c6 \u2208 [0, 1]\u039b ).\n\n(3.4.1)\n\n\f132\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nWe need to check that the right-hand side in (3.2.5) is zero, i.e., that\nG\u03a8(*, \u03c6)(x) = G \u2020 \u03a8(x, *)(\u03c6)\n\n(\u03c6 \u2208 [0, 1]\u039b , x \u2208 N (\u039b)),\n\n(3.4.2)\n\nwhere G be the generator of the (a, b, c, d)-braco-process, defined in (3.1.1), and G \u2020 is the\ngenerator of the (a\u2020 , b, c, d)-resem-process, defined in (3.3.37). Note that since x is finite,\n2 ([0, 1]\u039b ). We check that\n\u03a8(x, *) \u2208 Cfin\nG\u03a8(*, \u03c6)(x)\nX\nX\n=\na(i, j)x(i){(1 \u2212 \u03c6(j)) \u2212 (1 \u2212 \u03c6(i))}(1 \u2212 \u03c6)x\u2212\u03b4i + b\nx(i){(1 \u2212 \u03c6(i)) \u2212 1}(1 \u2212 \u03c6)x\nijX\n\n+c\n\n=\u2212\n+c\n\ni\nX\n\nij\nX\ni\n\ni\n\nx\u2212\u03b4i\n\n+d\nx(i){1 \u2212 (1 \u2212 \u03c6(i)}(1 \u2212 \u03c6)x\u2212\u03b4i\ni\nX\n\u2212b\n\u03c6(i)(1 \u2212 \u03c6(i))x(i)(1 \u2212 \u03c6)x\u2212\u03b4i\n\nx(i)(x(i) \u2212 1){1 \u2212 (1 \u2212 \u03c6(i))}(1 \u2212 \u03c6)\na\u2020 (j, i)(\u03c6(j) \u2212 \u03c6(i))x(i)(1 \u2212 \u03c6)x\u2212\u03b4i\n\ni\n\n\u03c6(i)(1 \u2212 \u03c6(i))x(i)(x(i) \u2212 1)(1 \u2212 \u03c6)x\u22122\u03b4i + d\n\n= G \u2020 \u03a8(x, *)(\u03c6)\n\nX\n\n(\u03c6 \u2208 [0, 1]\u039b , x \u2208 N (\u039b)).\n\nX\ni\n\n\u03c6(i)x(i)(1 \u2212 \u03c6)x\u2212\u03b4i\n\n(3.4.3)\n\nSet\n\u03a6(x, \u03c6) := G\u03a8(*, \u03c6)(x) = G \u2020 \u03a8(x, *)(\u03c6)\n\n(\u03c6 \u2208 [0, 1]\u039b , x \u2208 N (\u039b)).\n\nIt is not hard to see that there exists a constant K such that\n\u0011\n\u0010\n(\u03c6 \u2208 [0, 1]\u039b , x \u2208 N (\u039b)).\n|\u03a6(x, \u03c6)| \u2264 K 1 + |x|2\n\n(3.4.4)\n\n(3.4.5)\n\nTherefore, condition (3.2.4) is satisfied by (3.3.1).\nTo generalize the statement from finite x to general x \u2208 E\u03b3 (\u039b), we apply Lemma 3.16.\nChoose finite x(n) such that x(n) \u2191 x and couple the (a, b, c, d)-braco-processes X (n) , X with\ninitial conditions x(n) , x, respectively, such that X (n) \u2191 X. Then, for each t \u2265 0 and \u03c6 \u2208 [0, 1]\u039b ,\nE \u03c6 [(1 \u2212 Xt )x\n\nand\n\n(n)\n\n] \u2193 E \u03c6 [(1 \u2212 Xt )x ] as n \u2191 \u221e,\n\n(n)\n\nE[(1 \u2212 \u03c6)Xt ] \u2193 E[(1 \u2212 \u03c6)Xt ] as n \u2191 \u221e,\n\n(3.4.6)\n(3.4.7)\n\nwhere we used the continuity of the function x 7\u2192 (1\u2212\u03c6)x with respect to increasing sequences.\nProof of Theorem 3.1 (b) We first prove the statement under the additional assumption\nthat \u03c6 and \u03c8 are summable. Recall that by Lemma 3.20, if X0 is summable then Xt is\nsummable for all t \u2265 0 a.s. Let S := {\u03c6 \u2208 [0, 1]\u039b : |\u03c6| < \u221e} denote the space of summable\nstates. We apply Theorem 3.7. Our duality function is\nb\n\n\u03a8(\u03c6, \u03c8) := e \u2212 c h\u03c6, \u03c8i\n\n(\u03c6, \u03c8 \u2208 S).\n\n(3.4.8)\n\nLet G, G \u2020 denote the generators of the (a, b, c, d)-resem-process and the (a\u2020 , b, c, d)-resemprocess, as in (3.3.37), respectively. We need to show that the right-hand side in (3.2.5) is zero,\n\n\f133\n\n3.4. DUALITIES\n\ni.e., that G\u03a8(*, \u03c8)(\u03c6) = G \u2020 \u03a8(\u03c6, *)(\u03c8). It is not hard to see that \u03a8(*, \u03c8), \u03a8(\u03c6, *) \u2208 Csum ([0, 1]\u039b )\nfor each \u03c8, \u03c6 \u2208 S. We calculate\nnX\nX\nG\u03a8(*, \u03c8)(\u03c6) =\na(j, i)(\u03c6(j) \u2212 \u03c6(i))(\u2212 bc )\u03c8(i) + b\n\u03c6(i)(1 \u2212 \u03c6(i))(\u2212 cb )\u03c8(i)\nij\n\ni\n\no\nb\n\u03c6(i)(\u2212 bc )\u03c8(i) e \u2212 c h\u03c6, \u03c8i\n+c\n\u03c6(i)(1 \u2212 \u03c6(i))(\u2212 bc )2 \u03c8(i)2 \u2212 d\ni\ni\nnX\n\u0010X\n\u0011X\n= \u2212 cb\na(j, i)\u03c6(j)\u03c8(i) \u2212\na(j, i)\n\u03c6(i)\u03c8(i)\nX\n\nX\nij\n\n+b\n\nj\n\nX\ni\n\ni\n\n\u03c6(i)(1 \u2212 \u03c6(i))\u03c8(i)(1 \u2212 \u03c8(i)) \u2212 d\n\n= G \u2020 \u03a8(\u03c6, *)(\u03c8).\n\n(3.4.9)\n\nX\ni\n\no\nb\n\u03c6(i)\u03c8(i) e \u2212 c h\u03c6, \u03c8i\n\nIt is not hard to see that there exists a constant K such that\n|G\u03a8(*, \u03c8)(\u03c6)| \u2264 K|\u03c6| |\u03c8|\n\n(\u03c6, \u03c8 \u2208 S).\n\n(3.4.10)\n\nTherefore, condition (3.2.4) is implied by Lemma 3.20, and Theorem 3.7 is applicable. To\ngeneralize the result to general \u03c6, \u03c8 \u2208 [0, 1]\u039b , we apply Lemma 3.22.\n\n3.4.2\n\nSubduality\n\nFix constants \u03b2 \u2208 R, \u03b3 \u2265 0. Let M(\u039b) := {\u03c6 \u2208 [0, \u221e)\u039b : |\u03c6| < \u221e} be the space of finite\nmeasures on \u039b, equipped with the topology of weak convergence, and let Y be the Markov\nprocess in M(\u039b) given by the unique pathwise solutions to the SDE\nX\np\ndYt (i) =\na(j, i)(Yt (j) \u2212 Yt (i)) dt + \u03b2Yt (i) dt + 2\u03b3Yt (i) dBt (i)\n(3.4.11)\nj\n\n(t \u2265 0, i \u2208 \u039b). Then Y is the well-known super random walk with underlying motion a,\ngrowth parameter \u03b2 and activity \u03b3. One has [Daw93, Section 4.2]\n\u0002\nE \u03c6 e \u2212hYt , \u03c8i ] = e \u2212h\u03c6, Ut \u03c8i\n\n(3.4.12)\n\nfor any \u03c6 \u2208 M(\u039b) and bounded nonnegative \u03c8 : \u039b \u2192 R, where ut = Ut \u03c8 solves the semilinear\nCauchy problem\nX\n\u2202\nu\n(i)\n=\na(j, i)(ut (j) \u2212 ut (i)) + \u03b2ut (i) \u2212 \u03b3ut (i)2\n(i \u2208 \u039b, t \u2265 0)\n(3.4.13)\nt\n\u2202t\nj\n\nwith initial condition u0 = \u03c8. The semigroup (Ut )t\u22650 acting on bounded nonnegative functions\n\u03c8 on \u039b is called the log-Laplace semigroup of Y.\nWe will show that (a, b, c, d)-braco-process and the super random walk with underlying\nmotion a\u2020 , growth parameter b \u2212 d + c and activity c are related by a duality formula with a\nnonnegative error term. In analogy with words such as subharmonic and submartingale, we\ncall this a subduality relation.\n\n\f134\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nProposition 3.23 (Subduality with a branching process) Let X be the (a, b, c, d)-bracoprocess and let Y be the super random walk with underlying motion a\u2020 , growth parameter\nb \u2212 d + c and activity c. Then\n\u0002\n\u0002\nE x e \u2212h\u03c6, Xt i ] \u2265 E \u03c6 e \u2212hYt , xi ]\n\n(x \u2208 E\u03b3 (\u039b), \u03c6 \u2208 M(\u039b)).\n\n(3.4.14)\n\nProof We first prove the statement for finite x. We apply Theorem 3.7 to X and Y considered\nas processes in N (\u039b) and M(\u039b), respectively. The process Y solves the martingale problem\nfor the operator\nX\nX\n\u2202\n\u2202\nf (\u03c6) + (b \u2212 d + c)\n\u03c6(i) \u2202\u03c6(i)\nf (\u03c6)\nHf (\u03c6) :=\na\u2020 (j, i)(\u03c6(j) \u2212 \u03c6(i)) \u2202\u03c6(i)\ni\n\nij\n\n+c\n\n\u22022\n\u03c6(i) \u2202\u03c6(i)\n2 f (\u03c6)\n\nX\ni\n\n\u039b\n\n(\u03c6 \u2208 [0, 1] ),\n\n(3.4.15)\n\n2\n[0, \u221e)\u039b of bounded C 2 functions on [0, \u221e)\u039b depending\ndefined for functions \u03c6 in the space Cfin,b\non finitely many coordinates. Our duality function is \u03a8(x, \u03c6) := e\u2212h\u03c6,xi . We observe that\n2\n\u03a8(x, *) \u2208 Cfin,b\n[0, \u221e)\u039b for all x \u2208 N (\u039b) and calculate\n\nG\u03a8(*, \u03c6)(x) =\n\nnX\nij\n\n+c\n\nX\n\u0001\n\u0001\na(i, j)x(i) e\u03c6(i)\u2212\u03c6(j) \u2212 1 + b\nx(i) e\u2212\u03c6(i) \u2212 1\ni\n\nX\ni\n\nand\nH\u03a8(x, *)(\u03c6) =\n\nX\n\u0001\n\u0001o\nx(i)(x(i) \u2212 1) e\u03c6(i) \u2212 1 + d\nx(i) e\u03c6(i) \u2212 1 e \u2212h\u03c6, xi ,\n\n(3.4.16)\n\ni\n\nnX\n\na\u2020 (j, i)x(i)(\u03c6(i) \u2212 \u03c6(j)) \u2212 (b \u2212 d + c)x(i)\u03c6(i)\nij\no\nX\n+c\nx(i)2 \u03c6(i) e \u2212h\u03c6, xi\n\n(3.4.17)\n\ni\n\n(x \u2208 N (\u039b), \u03c6 \u2208 M(\u039b)). It is not hard to see that there exists a constant K such that\n|G\u03a8(*, \u03c6)(x)| \u2264 K|x|2\n\nand |H\u03a8(x, *)(\u03c6)| \u2264 K|x|2 |\u03c6|\n\n(x \u2208 N (\u039b), \u03c6 \u2208 M(\u039b)). (3.4.18)\n\nand therefore condition (3.2.4) is implied by (3.3.1) and the elementary estimate E[|Yt |] \u2264\ne(b\u2212d+c)t |\u03c6|. One has\nnX\n\u0001\na(i, j)x(i) e\u03c6(i)\u2212\u03c6(j) \u2212 1 \u2212 (\u03c6(i) \u2212 \u03c6(j))\nG\u03a8(*, \u03c6)(x) \u2212 H\u03a8(x, *)(\u03c6) =\nij\n\nX\n\u0001\n\u0001\n\u2212 1 + \u03c6(i) + c\nx(i)(x(i) \u2212 1) e\u03c6(i) \u2212 1 \u2212 \u03c6(i)\ni\nX\n\u0001o \u2212h\u03c6,i xi\n\u03c6(i)\n\u2265 0,\nx(i) e\n\u2212 1 \u2212 \u03c6(i) e\n+d\n\n+b\n\nX\n\n\u2212\u03c6(i)\n\nx(i) e\n\n(3.4.19)\n\ni\n\nand therefore, for finite x, (3.4.14) is implied by Theorem 3.7. The general case follows by\napproximation, using Lemma 3.16.\n\n\f135\n\n3.5. THE MAXIMAL PROCESSES\n\n3.5\n3.5.1\n\nThe maximal processes\nThe maximal branching-coalescing process\n\nUsing Proposition 3.23 we can now prove Theorem 3.2.\nProof of Theorem 3.2 Choose x(n) \u2208 E\u03b3 (\u039b) such that x(n) (i) \u2191 \u221e for all i \u2208 \u039b. By\nLemma 3.16, the (a, b, c, d)-braco processes X (n) started in x(n) , respectively, can be coupled\n\u039b\n(\u221e)\n(n+1)\n(n)\nfor each t \u2265 0. Define X (\u221e) = (Xt )t\u22650 as the N -valued process\nsuch that Xt \u2264 Xt\nthat is the pointwise increasing limit of the X (n) . By Proposition 3.23 and (3.4.12),\n(n) \u0003\n\u0002\n(n)\nE 1 \u2212 e \u2212h\u03b5\u03b4i , Xt i \u2264 1 \u2212 e \u2212h\u03b5\u03b4i , Ut x i\n\n(t, \u03b5 \u2265 0, i \u2208 \u039b).\n\n(3.5.1)\n\nwhere (Ut )t\u22650 is the log-Laplace semigroup of the super random walk with underlying motion\na\u2020 , growth parameter r := b \u2212 d + c and activity c. It follows that\n(n) \u0003\n\u0002\n(n) \u0001\n(n)\nE[Xt (i)] = lim \u03b5\u22121 E 1 \u2212 e \u2212h\u03b5\u03b4i , Xt i \u2264 lim \u03b5\u22121 1 \u2212 e \u2212h\u03b5\u03b4i , Ut x i = Ut x(n) (i) (3.5.2)\n\u03b5\u21930\n\n\u03b5\u21930\n\n(t \u2265 0, i \u2208 \u039b). Using the explicit solution of (3.4.13) for constant initial conditions, it is easy\nto see that Ut x(n) \u2191 Ut \u221e, where\n(\nr\nif r 6= 0,\nc(1\u2212e\u2212rt )\n(3.5.3)\nUt \u221e :=\n1\nif\nr\n=\n0.\nct\n(See formula (2.6.9).) Letting n \u2191 \u221e in (3.5.2) we arrive at Theorem 3.2 (b). Moreover, we\nsee that\nX\n\u0002 (\u221e)\n\u0003\nE kXt (i)k\u03b3 \u2264 Ut \u221e\n\u03b3i < \u221e\n(t > 0),\n(3.5.4)\ni\n\n(\u221e)\n\n\u2208 E\u03b3 (\u039b) a.s. for each t > 0. Part (a) of the theorem now follows from\nand therefore Xt\nLemma 3.16. Using Theorem 3.1 (a) and the continuity of the function x 7\u2192 (1 \u2212 \u03c6)x with\nrespect to increasing sequences, reasoning as in (3.1.28), we see that\n(\u221e)\n\nP [Thin\u03c6 (Xt\n\n) = 0] = P \u03c6 [Xt\u2020 = 0]\n\n(\u03c6 \u2208 [0, 1]\u039b , t \u2265 0),\n\n(3.5.5)\n\nwhere X \u2020 denotes the (a\u2020 , b, c, d)-resem-process. Since formula (3.5.5) determines the distribu(\u221e)\n(\u221e)\ntion of Xt\nuniquely, the law of Xt\ndoes not depend on the choice of the x(n) \u2191 \u221e (t \u2265 0).\nThis completes the proof of part (c) of the theorem.\nTo prove part (d), fix 0 \u2264 s \u2264 t. Choose yn \u2208 E\u03b3 (\u039b), yn (i) \u2191 \u221e \u2200i \u2208 \u039b and let X\u0303 (n) be\n(n)\n(\u221e)\n(n)\n(\u221e)\nthe (a, b, c, d)-braco-process started in X\u03030 := Xt\u2212s \u2228 yn . Then X\u03030 \u2265 Xt\u2212s and therefore,\n(n)\n\n(\u221e)\n\n(n)\n\n(\u221e)\n\nmay be coupled such that X\u0303s \u2265 Xt . By part (c) of the\nby Lemma 3.9, X\u0303s and Xt\n(n)\n(\u221e)\n(n)\n(\u221e)\n(\u221e)\n(\u221e)\ntheorem, X\u0303s and Xs may be coupled such that X\u0303s \u2191 Xs and therefore Xs and Xt\n(\u221e)\n(\u221e)\nmay be coupled such that Xs \u2265 Xt .\n\n\f136\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n(\u221e)\n\n(\u221e)\n\nIt follows that L(Xt ) \u2193 \u03bd for some probability measure \u03bd on E\u03b3 (\u039b). Set \u03c1 := L(X1 )\nand let (St )t\u22650 denote the semigroup of the (a, b, c, d)-braco-process. Recall the definition of\nCLip,b (E\u03b3 (\u039b)) above (3.3.20). One has\nZ\nZ\n\u03bd(dx)f (x) = lim\n\u03c1(dx)St f (x)\n(3.5.6)\nt\u2192\u221e\n\nfor every f \u2208 CLip,b (E\u03b3 (\u039b)). Therefore, since St maps CLip, b (E\u03b3 (\u039b)) into itself,\nZ\nZ\nZ\n\u03bd(dx)Ss f (x) = lim\n(s \u2265 0),\n\u03c1(dx)St Ss f (x) = \u03bd(dx)f (x)\nt\u2192\u221e\n\n(3.5.7)\n\nfor every f \u2208 CLip, b (E\u03b3 (\u039b)), which shows that \u03bd is an invariant measure. If \u03bd is another\n(\u221e)\ninvariant measure, then L(Xt ) \u2265 \u03bd for all t \u2265 0. Letting t \u2192 \u221e, we see that \u03bd \u2265 \u03bd, proving\npart (e) of the theorem. Part (f) has already been proved in the introduction.\n\n3.5.2\n\nThe maximal resampling-selection process\n\nThe proof of Theorem 3.3 (a)\u2013(c) is similar to the proof of Theorem 3.2, but easier. Recall\nthat Theorem 3.3 (d) is proved in Section 3.1.5.\nProof of Theorem 3.3 (a)\u2013(c) Part (a) can be proved in the same way as Theorem 3.2 (d),\nusing Lemma 3.22. The proof of part (b) goes analogue to the proof of Theorem 3.2 (e). To\nsee why (3.1.30) holds, note that for any \u03c6 \u2208 [0, 1]\u039b , by Theorem 3.1 (a),\nZ\n\u03bc(d\u03c6)(1 \u2212 \u03c6)x = lim P 1 [ThinXt (x) = 0] = lim P x [Thin1 (Xt\u2020 ) = 0].\n(3.5.8)\nt\u2192\u221e\n\nt\u2192\u221e\n\nTo complete the proof of part (c) we must show that \u03bc is nontrivial if and only if the (a\u2020 , b, c, d)process survives. Using subadditivity (Lemma 3.10) it is easy to see that the (a\u2020 , b, c, d)-process\nsurvives if and only if P \u03b4i [Xt\u2020 6= 0 \u2200t \u2265 0] > 0 for some i \u2208 \u039b. Formula (3.1.30) implies that\nR\n\u03bc(d\u03c6)\u03c6(i) = P \u03b4i [Xt\u2020 6= 0 \u2200t \u2265 0], which shows that \u03bc = \u03b40 if and only if the (a\u2020 , b, c, d)process survives. If \u03bc 6= \u03b40 then the measure \u03bc conditioned on {\u03c6 : \u03c6 6= 0} is an invariant\nmeasure of the (a, b, c, d)-resem-process that is stochastically larger than \u03bc. By part (b), this\nconditioned measure is \u03bc itself, thus \u03bc({0}) = 0, i.e., \u03bc is nontrivial.\n\n3.6\n3.6.1\n\nConvergence to the upper invariant measure\nExtinction versus unbounded growth\nb\n\nIn this section we prove Lemma 3.5. It has already been proved in Section 3.1.5 that e\u2212 c |Xt |\nis a submartingale. Therefore, if b > 0, then |Xt | converges a.s. to a limit in [0, \u221e]. If b = 0\nthen it is easy to see that |Xt | is a nonnegative supermartingale and therefore also in this\ncase |Xt | converges a.s. Thus, all we have to do is to show that limt\u2192\u221e |Xt | takes values in\n{0, \u221e} a.s. (Proposition 3.25 below), and that X gets extinct in finite time if the limit is zero\n(Lemma 3.24). Throughout this section, c > 0 and X is the (a, b, c, d)-resem-process starting\nin an initial state \u03c6 \u2208 [0, 1]\u039b with |\u03c6| < \u221e.\n\n\f137\n\n3.6. CONVERGENCE TO THE UPPER INVARIANT MEASURE\n\nLemma 3.24 (Finite time extinction) One has Xt = 0 for some t \u2265 0 a.s. on the event\nlimt\u2192\u221e |Xt | = 0.\nProof Choose x(n) \u2208 E\u03b3 (\u039b) such that x(n) (i) \u2191 \u221e for all i \u2208 \u039b. Let X (n)\u2020 denote the\n(a\u2020 , b, c, d)-braco-process started in x(n) and let X (\u221e)\u2020 denote the maximal (a\u2020 , b, c, d)-bracoprocess. By Theorem 3.1 (a) and Theorem 3.2 (b),\n(n)\u2020\n\nP \u03c6 [Xt 6= 0] = lim P \u03c6 [ThinXt (x(n) ) 6= 0] = lim P [Thin\u03c6 (Xt ) 6= 0]\nn\u2191\u221e\nn\u2191\u221e\n\u0002\n(\u221e)\u2020\n(\u221e)\u2020 \u0003\n(\u221e)\u2020\n]i \u2264 |\u03c6|Ut \u221e,\n)| = h\u03c6, E[Xt\n) 6= 0] \u2264 E |Thin\u03c6 (Xt\n= P [Thin\u03c6 (Xt\n\n(3.6.1)\n\nwhere Ut \u221e is the function on the right-hand side in (3.1.23). Choose \u03b5 > 0 and t0 > 0 such\nthat \u03b5Ut0 \u221e \u2264 12 . Let (Ft )t\u22650 denote the filtration generated by X . By (3.6.1),\n1\n2 1{|Xt |\n\n\u2264 \u03b5} \u2264 P [Xt+t0 = 0|Ft ] \u2264 P [\u2203s \u2265 0 s.t. Xs = 0|Ft ].\n\n(3.6.2)\n\nNow\n1{lim\n\u2264 lim inf 1{|X | \u2264 \u03b5} ,\ns\u2192\u221e Xs = 0}\nt\nt\u2192\u221e\n\nwhile\n\nP [\u2203s \u2265 0 s.t. Xs = 0|Ft ] \u2192 1{\u2203s \u2265 0 s.t. X = 0}\ns\n\nas t \u2192 \u221e\n\n(3.6.3)\n\na.s.,\n\n(3.6.4)\n\nby convergence of right-continuous martingales and the fact that the left-hand side is rightcontinuous by a general property of strong Markov processes described in Section 2.6.6 from\nChapter 2. Letting t \u2192 \u221e in (3.6.2), using (3.6.3) and (3.6.4), we find that 12 1{lims\u2192\u221e Xs =0} \u2264\n1{\u2203s\u22650 s.t. Xs =0} a.s.\nTo finish this section, we need to prove:\nProposition 3.25 (Convergence to zero or infinity) Assume that \u039b is infinite. Then\nlimt\u2192\u221e |Xt | \u2208 {0, \u221e} a.s.\nSince the proof of Proposition 3.25 is rather long we break it up into a number of steps. At\neach step, we will skip the proof if it is obvious but tedious. Our first step is:\nLemma 3.26 (Integrable fluctuations) One has\nZ \u221eX\nXt (i)(1 \u2212 Xt (i)) dt < \u221e\n0\n\n(3.6.5)\n\ni\n\na.s. on the event limt\u2192\u221e |Xt | \u2208 [0, \u221e).\n2 ([0, 1]\u039b ) and (compare (3.4.9))\nProof For any \u03c8 \u2208 [0, \u221e)\u039b with |\u03c8| < \u221e one has e\u2212h*,\u03c8i \u2208 Csum\nn X\nX\nG e \u2212h*, \u03c8i (\u03c6) = \u2212\n\u03c6(i)\na\u2020 (j, i)(\u03c8(j) \u2212 \u03c8(i))\nj\no\n(3.6.6)\nXi\nX\n\u0001\n+\n\u03c6(i)(1 \u2212 \u03c6(i)) c\u03c8(i)2 \u2212 b\u03c8(i) + d\n\u03c6(i)\u03c8(i) e \u2212h\u03c6, \u03c8i .\ni\n\ni\n\n\f138\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nSince X solves the martingale problem for G,\nE\n\nhZ\n\nt\n0\n\ni\n\u0002\n\u0003\nG e \u2212h*, \u03c8i (Xs )ds = E e \u2212hXt , \u03c8i \u2212 e \u2212h\u03c6, \u03c8i\n\n(t \u2265 0).\n\n(3.6.7)\n\n\u039b\nChoose \u03bb > 0 such that c\u03bb2 \u2212 b\u03bb =: \u03bc > 0 and \u03c8n \u2208 [0, \u221e)\nP \u2020with |\u03c8n | < \u221e such that \u03c8n \u2191 \u03bb.\nThen the bounded pointwise limit of the function i 7\u2192 j a (j, i)(\u03c8n (j) \u2212 \u03c8n (i)) is zero and\ntherefore, taking the limit in (3.6.7), using Lemma 3.20, we find that\n\nE\n\nhZ t Xn\n0\n\ni\n\no\ni\n\u0002\n\u0003\n\u03bcXs (i)(1 \u2212 Xs (i)) + \u03bbdXs (i) e \u2212\u03bb|Xs | ds = E e \u2212\u03bb|Xt | \u2212 e \u2212h\u03c6, \u03c8i .\n\n(3.6.8)\n\nLetting t \u2191 \u221e, using the fact that the right-hand side of (3.6.8) is bounded by one, we see that\nZ \u221e Xn\no\n\u03bcXt (i)(1 \u2212 Xt (i)) + \u03bbdXt (i) e \u2212\u03bb|Xt | dt < \u221e a.s.,\n(3.6.9)\n0\n\ni\n\nwhich implies (3.6.5).\nLemma 3.27 (Process not started with only zeros and ones) For every 0 < \u03b5 < 41\nthere exists a \u03b4, r > 0 such that\n\u0002\n\u0003\nP \u03c6 Xt (i) \u2208 (\u03b5, 1 \u2212 \u03b5) \u2200t \u2208 [0, r] \u2265 \u03b4\n(i \u2208 \u039b, \u03c6 \u2208 [0, 1]\u039b , \u03c6(i) \u2208 (2\u03b5, 1 \u2212 2\u03b5)). (3.6.10)\n\nP\nProof Since supi j a(i, j) < \u221e and all the components of the (a, b, c, d)-resem-process take\nvalues in [0, 1], the maximal drift that the i-th component Xt (i) can experience (both in the\npositive and negative direction) can be uniformly bounded. Now the proof of (3.6.10) is just\na standard calculation, which we skip.\nLemma 3.28 (Uniform convergence to zero or one) Almost surely on the event that\nlimt\u2192\u221e |Xt | \u2208 [0, \u221e), there exists a set \u2206 \u2282 \u039b such that\nlim inf Xt (i) = 1\n\nt\u2192\u221e i\u2208\u2206\n\nand\n\nlim sup Xt (i) = 0.\n\nt\u2192\u221e i\u2208\u039b\\\u2206\n\n(3.6.11)\n\nProof Imagine that the statement does not hold. Then, by the continuity of sample paths,\nwith positive probability limt\u2192\u221e |Xt | \u2208 [0, \u221e) while there exists 0 < \u03b5 < 14 such that for\nevery T > 0 there exists t \u2265 T and i \u2208 \u039b with Xt (i) \u2208 (2\u03b5, 1 \u2212 2\u03b5). Using Lemma 3.27\nand the strong Markov property, it is then not hard to check that with positive probability\nlimt\u2192\u221e |Xt | \u2208 [0, \u221e) while there exist infinitely many disjoint time intervals [tk , tk + r] and\npoints ik \u2208 \u039b such that Xt (ik ) \u2208 (\u03b5, 1 \u2212 \u03b5) for all t \u2208 [tk , tk + r]. This contradicts Lemma 3.26.\nLemma 3.29 (Convergence to one on a finite nonempty set) Almost surely on the\nevent limt\u2192\u221e |Xt | \u2208 (0, \u221e), the set \u2206 from Lemma 3.28 is finite and nonempty.\n\n\f3.6. CONVERGENCE TO THE UPPER INVARIANT MEASURE\n\n139\n\nProof It is clear that \u2206 is finite a.s. on the event limt\u2192\u221e |Xt | < \u221e. Now imagine that \u2206\nis empty. Then, a.s. on the event limt\u2192\u221e |Xt | > 0, there exists a random time T such that\nXt (i) \u2264 12 for all t \u2265 T and i \u2208 \u039b. Since z(1 \u2212 z) \u2265 21 z on [0, 12 ], it follows that a.s. on the\nevent limt\u2192\u221e |Xt | > 0,\nZ \u221eX\nZ\n1 \u221e\nXt (i)(1 \u2212 Xt (i))dt \u2265\n|Xt | = \u221e.\n(3.6.12)\n2 T\nT\ni\n\nWe arrive at a contradiction with Lemma 3.26.\nProof of Proposition 3.25 Let \u2206 be the random set from Lemma 3.28. We will show that\n\u2206 = \u039b a.s. on the event limt\u2192\u221e |Xt | \u2208 (0, \u221e). In particular, by Lemma 3.29, if \u039b is infinite\nthis implies that the event limt\u2192\u221e |Xt | \u2208 (0, \u221e) has zero probability. Assume that with\npositive probability limt\u2192\u221e |Xt | \u2208 (0, \u221e) and \u2206 6= \u039b. By Lemma 3.29, \u2206 is nonempty, and\ntherefore by irreducibility there exist i \u2208 \u039b\\\u2206 and j \u2208 \u2206 such that a(i, j) > 0 or a(j, i) > 0. If\na(i, j) > 0 then by the fact that the counting measure is an invariant measure for the Markov\nprocess with jump rates a and by the finiteness of \u2206, there must also be an i\u2032 \u2208 \u039b\\\u2206 and\nj \u2032 \u2208 \u2206 such that a(j \u2032 , i\u2032 ) > 0. Thus, there exist i, j \u2208 \u039b such that a(j, i) > 0 and with positive\nprobability limt\u2192\u221e Xt (i) = 0, and limt\u2192\u221e Xt (j) = 1. It is not hard to see that this violates\nthe evolution in (3.1.3). (We skip the details.)\n\n3.6.2\n\nConvergence to the upper invariant measure\n\nIn this section we complete the proof of Theorem 3.4, started in Section 3.1.5, by proving\nLemma 3.6. Throughout this section, (\u039b, a) is infinite and homogeneous and G is a transitive\nsubgroup of Aut(\u039b, a). We fix a reference point 0 \u2208 \u039b. We start with two preparatory lemmas.\nLemma 3.30 (Sparse thinning functions) Assume that \u03c6n \u2208 [0, 1]\u039b , |\u03c6n | \u2192 \u221e. Let\n\u2206 \u2282 \u039b be finite with 0 \u2208 \u2206. Then it is possible to choose constants \u03bbn \u2192 \u221e, finitely supported\nprobability distributions \u03c0n on \u039b, and {gi }i\u2208supp(\u03c0n ) with gi \u2208 G and gi (0) = i such that the\nimages {gi (\u2206)}i\u2208supp(\u03c0n ) are disjoint, and such that \u03bbn \u03c0n \u2264 \u03c6n .\nProof Choose (gi )i\u2208\u039b with gi \u2208 G such that gi (0) = i. Let (\u03bets )t\u22650 be the random walk on\n\u039b that jumps from i to j with the symmetrized jump rates as (i, j) = a(i, j) + a\u2020 (i, j). By\nirreducibility and symmetry, P i [\u03bets = j] > 0 for all t > 0, i, j \u2208 \u039b. Put\n\u0393\u03b5i := {j \u2208 \u039b : P i [\u03be1s = j] \u2265 \u03b5}\n\n(i \u2208 \u039b).\n\n(3.6.13)\n\nWe can choose \u03b5 > 0 small enough such that\nj 6\u2208 \u0393\u03b5i\n\nimplies\n\ngi (\u2206) \u2229 gj (\u2206) = \u2205 (i, j \u2208 \u039b).\n\n(3.6.14)\n\nTo see this, set \u03b4 := mink\u2208\u2206 P 0 [\u03be s1 = k] and put \u03b5 := \u03b42 . Imagine that \u2203k \u2208 gi (\u2206) \u2229 gj (\u2206).\n2\n\nThen P i [\u03be1s = j] \u2265 P i [\u03be s1 = k]P k [\u03be s1 = j] \u2265 \u03b42 = \u03b5 by the symmetry of the random walk and\n2\n\n2\n\n\f140\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\n\nhomogeneity, and therefore j \u2208 \u0393\u03b5i . Now choose inductively i1 , i2 , . . . \u2208 \u039b such that\n\u03c6n assumes its maximum over \u039b\\\n\nk\n[\n\n\u0393\u03b5il in ik+1 .\n\n(3.6.15)\n\nl=1\n\nThen gi1 (\u2206), gi2 (\u2206), . . . are disjoint by (3.6.14). Since K := |\u0393\u03b5i | is finite and does not depend\non i,\n\u221e\nX\n|\u03c6n |\n\u03c6n (il ) \u2265\n,\n(3.6.16)\nK\nl=1\n\nand we can choose kn such that\n\n\u03bbn :=\n\nkn\nX\nl=1\n\nSetting\n\u03c0n :=\n\n\u03c6n (il ) \u2212\u2192 \u221e.\n\n(3.6.17)\n\nn\u2192\u221e\n\n1\n\u03c6n 1{i1 ,...,ikn }\n\u03bbn\n\n(3.6.18)\n\nyields \u03bbn and \u03c0n with the desired properties.\nLet (\u03bet )t\u22650 and (\u03bet\u2020 )t\u22650 denote the random walks on \u039b that jump from i to j with rates a(i, j)\nand a\u2020 (i, j), respectively. Then, for any \u2206 \u2282 \u039b, the sets\nR\u2206 := {i \u2208 \u039b : P i [\u03bet \u2208 \u2206] > 0}\n\nand\n\nR\u2020 \u2206 := {i \u2208 \u039b : P i [\u03bet\u2020 \u2208 \u2206] > 0}\n\n(t > 0)\n\nof points from which \u03be and \u03be \u2020 can enter \u2206 do not depend on t > 0. Indeed\n\b\nR\u2206 = i : \u2203n \u2265 0, i0 , . . . , in s.t. i0 = i, in \u2208 \u2206, a(il\u22121 , il ) > 0 \u2200l = 1, . . . , n\n\n(3.6.19)\n\n(3.6.20)\n\nand similarly for R\u2020 \u2206. In our next lemma, for x \u2208 N\u039b and \u2206 \u2282 \u039b we let x|\u2206 := (xi )i\u2208\u2206\ndenote the restriction of x to \u2206.\nLemma 3.31 (Points from which 0 can be reached) If \u03bc is a G-homogeneous and\nnontrivial probability measure on N\u039b , then\n\u0001\n\u03bc {x : x|R{0} = 0} = 0.\n(3.6.21)\n\nProof Let Y be a N\u039b -valued random variable with law \u03bc. We will show that for any \u2206 \u2282 \u039b,\n\u0002\n\u0003\n\u0002\n\u0003\nP Y |R\u2020 R\u2206 = 0 = P Y |R\u2206 = 0 .\n(3.6.22)\nAssume that (3.6.22) does not hold. Then there exists an i \u2208 R\u2020 R\u2206\\R\u2206 such that with\npositive probability Y (i) 6= 0 and Y |R\u2206 = 0. Since the random walk (\u03bet\u2020 )t\u22650 cannot escape\nfrom R\u2206 this implies that for any t > 0\n\u0002\n\u0003\nP i Y (\u03be0\u2020 ) 6= 0, Y (\u03bes\u2020 ) = 0 \u2200s \u2265 t > 0,\n(3.6.23)\n\n\f3.6. CONVERGENCE TO THE UPPER INVARIANT MEASURE\n\n141\n\nwhich contradicts the fact that (Y (\u03bet\u2020 ))t\u22650 is stationary. This proves (3.6.22). Continuing this\nprocess, we see that\n\u0002\n\u0003\n\u0002\n\u0003\n\u0002\n\u0003\nP Y |R{0} = 0 = P Y |R\u2020 R{0} = 0 = P Y |RR\u2020 R{0} = 0 = * * *\n(3.6.24)\n\nBy irreducibility, the sets R{0}, R\u2020 R{0}, RR\u2020 R{0}, . . . increase to \u039b, and therefore, since \u03bc is\nnontrivial,\n\u0002\n\u0003\n\u0002\n\u0003\nP Y |R{0} = 0 = P Y |\u039b = 0 = 0.\n(3.6.25)\n\nProof of Lemma 3.6 For any finite set \u2206 \u2282 \u039b, let X \u2206 denote the (a, b, c, d)-braco-process\nwith immediate killing outside \u2206. Thus, Xt\u2206 (i) := 0 for all i \u2208 \u039b\\\u2206 and t > 0 and\n(Xt\u2206 (i))i\u2208\u2206, t\u22650 is the Markov process in N\u2206 with generator G\u2206 given by (compare (3.1.1))\nX\nX\nG\u2206 f (x) :=\na(i, j)x(i){f (x + \u03b4j \u2212 \u03b4i ) \u2212 f (x)} +\na(i, j)x(i){f (x \u2212 \u03b4i ) \u2212 f (x)}\ni,j\u2208\u2206\n\n+b\n\n+d\n\nX\n\ni\u2208\u2206\nX\ni\u2208\u2206\n\ni\u2208\u2206,j\u2208\u039b\\\u2206\n\nX\n\nx(i){f (x + \u03b4i ) \u2212 f (x)} + c\n\ni\u2208\u2206\n\nx(i){f (x \u2212 \u03b4i ) \u2212 f (x)}.\n\nx(i)(x(i) \u2212 1){f (x \u2212 \u03b4i ) \u2212 f (x)}\n\n(3.6.26)\nIt is not hard to see that if \u22061 , . . . , \u2206n are disjoint finite sets, then it is possible to couple the\nprocesses X and X \u22061 , . . . , X \u2206n in such a way that\nXt \u2264\n\nn\nX\n\nXt\u2206i\n\n(t \u2265 0)\n\ni=1\n\n(3.6.27)\n\nand the (X \u2206i )i=1,...,n are independent.\nLet X denote the (a, b, c, d)-braco-process and assume that \u03c6n \u2208 [0, 1]\u039b satisfy |\u03c6n | \u2192 \u221e.\nFix t > 0. Assume that \u2206 \u2282 \u039b is a finite set such that 0 \u2208 \u2206 and\nx|\u2206 6= 0\n\n\u21d2\n\nP x [Xt\u2206 (0) > 0] > 0.\n\n(3.6.28)\n\nChoose \u03bbn , \u03c0n , and {gi }i\u2208supp(\u03c0n ) as in Lemma 3.30. Then, for deterministic x \u2208 E\u03b3 (\u039b), we\ncan estimate\n\u0003\n\u0002\n\u0003\n\u0002\nP x Thin\u03c6n (Xt ) = 0 \u2264 P x Thin\u03bbn \u03c0n (Xt ) = 0\nY\n\u0003\n\u0002\ng (\u2206)\n\u2264\nP x Thin\u03bbn \u03c0n (i) (Xt i (i)) = 0\ni\u2208supp(\u03c0n )\n\n\u2264\n\n\u2264\n\nY\n\nP\n\ni\u2208supp(\u03c0n )\n\nY\n\ni\u2208supp(\u03c0n )\n\nP\n\n\u0003\n\u2206\ne \u2212\u03bbn \u03c0n (i)Xt (i)\n\nTg\u22121 x \u0002\ni\n\nT\n\ng \u22121\ni\n\n(3.6.29)\n\n\u0003\u03bb \u03c0 (i)\n\u2206\ne \u2212Xt (i) n n ,\n\nx\u0002\n\nwhere the Tg\u22121 are shift operators as in (3.1.17) and we have used that P [Thin\u03c6 (x) = 0] =\ni\n\nE[(1 \u2212 \u03c6)x ] = E[ehlog(1\u2212\u03c6),xi ] \u2264 E[e\u2212h\u03c6,xi ] for any \u03c6 \u2208 [0, 1]\u039b , x \u2208 N\u039b .\n\n\f142\n\nCHAPTER 3. BRANCHING-COALESCING PARTICLE SYSTEMS.\nIf L(X0 ) is G-homogeneous, then by (3.6.29) and H\u00f6lder's inequality,\nZ\nY\n\u0003\n\u0002\nT \u22121 x \u0002 \u2212X \u2206 (i) \u0003\u03bbn \u03c0n (i)\nt\nP gi\ne\nP Thin\u03c6n (Xt ) = 0 \u2264 P [X0 \u2208 dx]\ni\u2208supp(\u03c0n )\n\n\u2264\n=\n\nY\n\ni\u2208supp(\u03c0\nn)\nZ\n\n\u0010Z\n\nP [X0 \u2208 dx] P\n\nT\n\ng \u22121\ni\n\nx\u0002\n\n\u0002\n\u0003\u03bb\n\u2206\nP [X0 \u2208 dx] P x e \u2212Xt (0) n ,\n\n\u0003\u03bb\n\u2206\ne \u2212Xt (i) n\n\n\u0011\u03c0n (i)\n\nand therefore, by (3.6.28) and the fact that \u03bbn \u2192 \u221e,\n\u0003\n\u0002\n\u0003\n\u0002\nlim sup P Thin\u03c6n (Xt ) = 0 \u2264 P X0 |\u2206 = 0 .\nn\u2192\u221e\n\n(3.6.30)\n\n(3.6.31)\n\nPut\n\n\u2206k :=\n\nk\n[\n\b\n\nn=0\n\ni : \u2203i0 , . . . , in s.t. i0 = i, in = 0, a(il\u22121 , il ) >\n\n1\nk\n\n\u2200l = 1, . . . , n .\n\n(3.6.32)\n\nThen the \u2206k satisfy (3.6.28) and \u2206k \u2191 R{0} as k \u2191 \u221e, where R{0} is defined in (3.6.20).\nTherefore, inserting \u2206 = \u2206k in (3.6.31) and taking the limit k \u2191 \u221e, using Lemma 3.31, we\narrive at (3.1.34).\n\n\fChapter 4\n\nThe contact process seen from a\ntypical infected site\n4.1\n4.1.1\n\nIntroduction and main results\nContact processes on countable groups\n\nThe aim of this chapter is to study contact processes on rather general lattices. In particular,\nwe are interested in the way how a certain property of the lattice, namely subexponential\ngrowth, influences the behavior of the process.\nTo keep things reasonably simple, we assume that the lattice \u039b is a countably infinite\ngroup with group action (i, j) 7\u2192 ij and unit element 0, also referred to as the origin. Each\nsite i \u2208 \u039b can be in one of two states: healthy or infected. Infected sites become healthy with\nrecovery rate \u03b4 \u2265 0. An infected site i infects another site j with infection rate a(i, j) \u2265 0.\nWe assume that the infection rates are invariant with respect to the left action of the group,\nsummable, and statisfy a condition that is a bit stronger than irreducibility:\n(i) a(i, j) = a(ki, kj)\n(i, j, k \u2208 \u039b),\nX\n(ii) |a| :=\na(0, i) < \u221e,\ni\nS\nS\nn \u2212m =\n\u2212n Am = \u039b,\n(iii)\nn\u22650, m\u22650 A A\nn\u22650, m\u22650 A\n\n(4.1.1)\n\nwhere A := {i \u2208 \u039b : a(0, i) > 0}.\n\nHere we adopt the convention that sums over i, j, k always run over \u039b, unless stated otherwise.\nFor i \u2208 \u039b and A, B \u2282 \u039b we put AB := {ij : i \u2208 A, j \u2208 B}, iA := {i}A, Ai := A{i},\nA\u22121 := {i\u22121 : i \u2208 A}, A0 := {0}, An := AAn\u22121 (n \u2265 1), and A\u2212n := (A\u22121 )n = (An )\u22121 . We let\n|A| denote the cardinality of A. Note that property (4.1.1) (iii) is equivalent to the statement\nthat for any two sites i, j there exists a site k from which both i and j can be infected, and a\nset k\u2032 that can be infected both from i and from j.\nIf \u039b has a finite symmetric generating set \u2206, then the (left) Cayley graph G = G(\u039b, \u2206)\nassociated with \u039b and \u2206 is the graph with vertex set V(G) := \u039b and edges E(G) := {{i, j} :\ni\u22121 j \u2208 \u2206}. Examples of Cayley graphs are the d-dimensional integer lattice Zd (d \u2265 1) with\n143\n\n\f144\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nedges between points at distance one, or the regular tree Td (d \u2265 2) in which every vertex has\nd + 1 neighbors. On Cayley graphs, one often considers symmetric nearest-neighbor infection\nrates of the form a(i, j) = \u03bb1{i\u22121 j\u2208\u2206} , with \u03bb > 0. In this case, \u03bb is simply referred to as 'the'\ninfection rate.\nLet \u03b7t be the set of all infected sites at time t \u2265 0. Then \u03b7 = (\u03b7t )t\u22650 is a Markov\nprocess in the space P(\u039b) := {A : A \u2282 \u039b} of all subsets of \u039b, called the contact process on\n\u039b with infection rates a = (a(i, j))i,j\u2208\u039b and recovery rate \u03b4, or shortly the (\u039b, a, \u03b4)-contact\nprocess. If \u03b4 > 0, then by rescaling time we may set \u03b4 = 1, so it is customary so assume that\n\u03b4 = 1. If \u03b4 = 0 then \u03b7 is a special case of first-passage percolation (see [Kes86]). We equip\nP(\u039b) \u223c\n= {0, 1}\u039b with the product topology and the associated Borel-\u03c3-field B(P(\u039b)), and let\nPfin (\u039b) := {A \u2282 \u039b : |A| < \u221e} denote the subspace of finite subsets of \u039b.\nThe contact process can be constructed with the help of Harris' [Har78] graphical representation. Let \u03c9 = (\u03c9 r , \u03c9 i ) be a pair of independent, locally finite random subsets of \u039b \u00d7 R\nand \u039b \u00d7 \u039b \u00d7 R, respectively, produced by Poisson point processes with intensity \u03b4 and local\nintensity (j, k, t) 7\u2192 a(j, k), respectively. This is usually visualized by plotting \u039b \u00d7 R with \u039b\nhorizontally and R vertically. Points (i, s) \u2208 \u03c9 r and (j, k, t) \u2208 \u03c9 i are marked with a recovery\nsymbol \u2217 at (i, s) and an infection arrow from (j, t) to (k, t), respectively. For C, D \u2282 \u039b \u00d7 R,\nsay that there is a path from C to D, denoted by C\nD, if there exist n \u2265 0, i0 , . . . , in \u2208 \u039b,\nand t0 \u2264 * * * \u2264 tn+1 with (i0 , t0 ) \u2208 C and (in , tn+1 ) \u2208 D, such that {ik } \u00d7 [tk , tk+1 ] \u2229 \u03c9 r = \u2205 for\nall k = 0, . . . , n and (ik\u22121 , ik , tk ) \u2208 \u03c9 i for all k = 1, . . . , n. Thus, a path must walk upwards in\ntime, may follow arrows, and must avoid recoveries. For given A \u2208 P(\u039b) and t0 \u2208 R, put\nA\u00d7{t0 }\n\n\u03b7t\n\n:= {i \u2208 \u039b : A \u00d7 {t0 }\n\n(t \u2265 0).\n\n(i, t0 + t)}\n\nA\u00d7{t }\n\n(4.1.2)\nA\u00d7{t }\n\n0\nThen \u03b7 A\u00d7{t0 } = (\u03b7t\n)t\u22650 is a copy of the (\u039b, a, \u03b4)-contact process started in \u03b70 0 = A.\nFor brevity, we put \u03b7 A := \u03b7 A\u00d7{0} . The graphical representation couples processes with different\ninitial states in such a way that\n\n\u03b7tA \u222a \u03b7tB = \u03b7tA\u222aB\n\n(A, B \u2208 P(\u039b), t \u2265 0).\n\n(4.1.3)\n\nDefine reversed infection rates a\u2020 by a\u2020 (i, j) := a(j, i) (i, j \u2208 \u039b). Say that a is symmetric\nif a = a\u2020 . For A \u2208 P(\u039b) and t0 \u2208 R, put\n\u2020 A\u00d7{t0 }\n\n\u03b7t\n\n:= {i \u2208 \u039b : (i, t0 \u2212 t)\n\nA \u00d7 {t0 }}\n\n(t \u2265 0).\n\n(4.1.4)\n\u2020 A\u00d7{t0 }\n\n\u2020 A\u00d7{t }\n\n0\n)t\u22650 is a copy of the (\u039b, a\u2020 , \u03b4)-contact process started in \u03b70\nThen \u03b7 \u2020 A\u00d7{t0 } = (\u03b7t\n\u2020\nA\nA. For brevity, we put \u03b7 := \u03b7 \u2020 A\u00d7{0} . Since for any s \u2264 t and A, B \u2208 P(\u039b), the event\n\n\b\n\b A\u00d7{s}\n\u2020 B\u00d7{t}\n= \u2205 = A \u00d7 {s} 6\n\u03b7u\u2212s \u2229 \u03b7t\u2212u\n\nB \u00d7 {t}\n\n=\n\n(4.1.5)\n\ndoes not depend on u \u2208 [s, t], it follows that the (\u039b, a, \u03b4)-contact process and the (\u039b, a\u2020 , \u03b4)contact process are dual in the sense that\nP [\u03b7tA \u2229 B = \u2205] = P [A \u2229 \u03b7t\u2020 B = \u2205]\n\n(A, B \u2208 P(\u039b), t \u2265 0).\n\n(4.1.6)\n\n\f145\n\n4.1. INTRODUCTION AND MAIN RESULTS\n\nFor any C \u2282 \u039b \u00d7 R, say that C\n\u221e if there is an infinite path with times tk \u2191 \u221e starting\nin C, and define \u2212\u221e\nD analogously. Instead of {(i, s)}\nand\n{(j, t)}, simply write\n(i, s)\nand\n(j, t). We say that the (\u039b, a, \u03b4)-contact process \u03b7 survives if\n\u0002\n\u0003\n\u03c1(A) := P \u03b7tA 6= \u2205 \u2200t \u2265 0 = P [A \u00d7 {0}\n\u221e] > 0\n(4.1.7)\nfor some, and hence for all \u2205 =\n6 A \u2208 Pfin (\u039b). If \u03b7 does not survive then we say that it dies out.\nSet \u03b4c = \u03b4c (\u039b, a) := sup{\u03b4 \u2265 0 : the (\u039b, a, \u03b4)-contact process survives}. Then the (\u039b, a, \u03b4)contact process survives for \u03b4 < \u03b4c and dies out for \u03b4 > \u03b4c . One has \u03b4c \u2264 |a|. If \u039b is finitely\ngenerated, then moreover \u03b4c > 0 (see Section 4.3.4).\n\n4.1.2\n\nLong-time behavior\n\nSince the (\u039b, a, \u03b4)-contact process is an attractive spin system, it has an upper invariant law\n\u03bd, i.e., an invariant law that is maximal with respect to the stochastic order. It may be\nconstructed as \u03bd = P [\u03b7 0 \u2208 * ], where\n\u03b7 t := {i \u2208 \u039b : \u2212\u221e\n\n(i, t)}\n\n(t \u2208 R).\n\n(4.1.8)\n\nNote that\n\u0003\n\u0002\nP \u03b7 0 \u2229 A 6= \u2205 = \u03c1\u2020 (A)\n\n(A \u2208 Pfin (\u039b)),\n\n(4.1.9)\n\nwhere \u03c1\u2020 denotes the survival probability of the (\u039b, a\u2020 , \u03b4)-contact process. It is easy to see\nthat \u03bd is nontrivial if and only if the (\u039b, a\u2020 , \u03b4)-contact process survives. Here, we say that a\nprobability law on P(\u039b) is nontrivial if it gives zero probability to the empty set.\nWe say that a probability law \u03bc on P(\u039b) is homogeneous if \u03bc is shift invariant with respect\nto the left action of the group, i.e., \u03bc({iA : A \u2208 A}) = \u03bc(A) for all A \u2208 B(P(\u039b)). Using\nduality, it can be shown that\nZ\n\u03bc(dA)P [\u03b7tA \u2208 * ] =\u21d2 \u03bd\n\n(4.1.10)\n\nt\u2192\u221e\n\nwhenever the initial law \u03bc is homogeneous and nontrivial (see [Har76], [Lig85, (VI.2.1)], and\n[Lig99, (I.1.10)]). Here \u21d2 denotes weak convergence of probability laws. In particular, (4.1.10)\nshows that if \u03bd is nontrivial, then it is the only nontrivial homogeneous invariant law.\nThe long-time behavior for nonhomogeneous initial laws is more subtle and depends on\nproperties of the lattice \u039b and the infection rates a, such as subexponential growth.\nFor the symmetric nearest-neighbor contact process on Zd started in a finite initial state,\nthe following picture has been rigorously verified. Either the process dies out in finite time,\nor in the long run there is a region in space with linearly growing diameter and deterministic\nlimiting shape, such that most of the infected sites lie within this region and there the process is\nlocally in the upper invariant law [BG90]. In particular, it has been shown that the symmetric\nnearest-neighbor process on Zd exhibits complete convergence, i.e.,\nP [\u03b7tA \u2208 * ] =\u21d2 \u03c1(A)\u03bd + (1 \u2212 \u03c1(A))\u03b40\nt\u2192\u221e\n\n(A \u2208 Pfin (\u039b)).\n\n(4.1.11)\n\nNote that if complete convergence holds and \u03bd is nontrivial, then by monotonicity, it is the\nunique nontrivial invariant law. For other contact processes on Zd the picture is supposedly similar, provided that the infection rates are symmetric and satisfy an appropriate tail\n\n\f146\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\ncondition. If the infection rates are not symmetric, there is probably still a linearly growing\ninfected region with a limiting shape, but this region may walk out to infinity, so that complete\nconvergence does not hold. (For results in the one-dimensional case, see [Sch86].)\nThe behavior of the symmetric nearest-neighbor process on regular trees Td is known\nto be quite different. Here, there is a second critial value \u03b4c\u2032 < \u03b4c such that for recovery\nrates \u03b4 \u2208 [\u03b4c\u2032 , \u03b4c ), the process survives globally but not locally, i.e., \u03c1(A) > 0 but P [\u2203T \u2265\n0 s.t. \u03b7tA \u2229 {0} = \u2205 \u2200t \u2265 T ] = 1 for \u2205 =\n6 A \u2208 Pfin (\u039b). In this regime, there is a multitude\nof nontrivial invariant measures and complete convergence (obviously) does not hold [Lig99,\nSection I.4].\nOne would like to understand which properties of the lattices Zd and Td are responsible\nfor the differences in the behavior of the contact process, and which types of behavior are\npossible on general lattices \u039b. The proofs for Zd and Td use the structure of these lattices in\nan essential way, and are not easily generalized to other lattices.\nIt is known that (unoriented) percolation has quite different properties on Zd and on Td .\nHere, the important property of Zd , that Td lacks, is amenability. For example, the BurtonKeane proof of the uniqueness of the infinite cluster [BK89] works on any amenable graph.\nConversely, it is conjectured that on any nonamenable graph, there exists a range of the\npercolation parameter for which the infinite cluster is not unique. (See [BS01] and [LP05]\nsome partial results in this direction.)\nFor our main theorem, we will need to assume that the expected number of infected sites in\na contact process grows subexponentially. If \u039b is finitely generated, then it turns out that the\n(\u039b, a, \u03b4)-contact process grows subexponentially if a satisfies an exponential moment condition\nand \u039b itself has subexponential growth (see Proposition 4.1 (d) below). Here, by definition, a\nfinitely generated group \u039b has subexponential growth if\nlim\n\nn\u2192\u221e\n\n1\nlog |\u2206n | = 0\nn\n\n(4.1.12)\n\nfor some, and hence for all finite symmetric generating sets \u2206. Observe that \u2206n = {i : |i| \u2264 n}\nwhere |i| denotes the distance of i to the origin in the Cayley graph G(\u039b, \u2206). Subexponential\ngrowth is stronger than amenability. An example of an amenable finitely generated group\nthat does not have subexponential growth is the lamplighter group. (See [MW89, Section 5]\nfor general facts about amenability and subexponential growth, and [LPP96] or [LP05, \u00a7 6.1]\nfor a nice exposition of the lamplighter group.)\n\n4.1.3\n\nResults\n\nIt turns out that every (\u039b, a, \u03b4)-contact process has a well-defined exponential growth rate.\nProposition 4.1 (Exponential growth rate)\n(a) There exists a constant r = r(\u039b, a, \u03b4) \u2208 [\u2212\u03b4, |a| \u2212 \u03b4] such that the (\u039b, a, \u03b4)-contact process\nsatisfies\n\u0002\n\u0003\n(\u2205 =\n6 A \u2208 Pfin (\u039b)).\n(4.1.13)\nlim 1t log E |\u03b7tA | = r\nt\u2192\u221e\n\n(b) If the (\u039b, a, \u03b4)-contact process survives, then r \u2265 0.\n(c) r(\u039b, a, \u03b4) = r(\u039b, a\u2020 , \u03b4).\n\n\f147\n\n4.1. INTRODUCTION AND MAIN RESULTS\n\n(d) Assume that \u039b is finitely generated. Let \u2206 be a finite symmetric generating set and\nlet\nthe distance of j to the origin in the Cayley graph G(\u039b, \u2206). Assume that\nP |j| denote\n\u03b5|j| < \u221e for some \u03b5 > 0 and that \u039b has subexponential growth. Then r \u2264 0.\na(0,\nj)e\nj\n\nThe proof of Proposition 4.1 will be given in Sections 4.2.2\u20134.2.3. Part (a) follows from\nsubadditivity, part (b) is trivial, and part (c) is a consequence of duality. Part (d) follows\nfrom some basic large deviation estimates. The exponential moment condition on a appearing\nin part (d) can perhaps be weakened, but we conjecture that it cannot be dropped altogether.\nIndeed, it seems plausible that even on \u039b = Z, the exponential growth rate can be positive if\na has a sufficiently heavy tail.\nTo formulate the main results of this chapter, we must describe the contact process as\nseen from a 'typical' infected site at a 'typical' late time. Assume that the exponential growth\nrate r from Proposition 4.1 satisfies r \u2264 0. Recall the graphical construction of the (\u039b, a, \u03b4)contact process (see Section 4.1.1). Let (\u03a9, F, P ) be the probability space of the Poisson point\nprocesses used in the graphical representation. For \u03bb > r, we define probability measures P\u0302\u03bbA\non \u039b \u00d7 \u03a9 \u00d7 R+ by\nP\u0302\u03bbA ({i} \u00d7 {d\u03c9} \u00d7 {dt}) :=\n\nwhere\n\u03c0\u03bb (A) :=\n\nZ\n\n\u221e\n0\n\n1\nP (d\u03c9)e\u2212\u03bbt dt,\n1\nA\n\u03c0\u03bb (A) {i \u2208 \u03b7t (\u03c9)}\n\n\u0002\n\u0003\nE |\u03b7tA | e\u2212\u03bbt dt\n\n(A \u2208 Pfin (\u039b), \u03bb > r)\n\n(4.1.14)\n\n(4.1.15)\n\nis a normalizing constant. Using the fact that \u03bb > r, it is easy to see that 0 < \u03c0\u03bb (A) < \u221e, so\nP\u0302\u03bbA is well-defined. Note that the projection of P\u0302\u03bbA on \u03a9 \u00d7 R+ is given by\nP\u03bbA (\u039b \u00d7 {d\u03c9} \u00d7 {dt}) =\n\n1\n|\u03b7 A (\u03c9)|P (d\u03c9)e\u2212\u03bbt dt\n\u03c0\u03bb (A) t\n\n(4.1.16)\n\nIn other words, this projection is is obtained from the product measure P ()e\u2212\u03bbt dt on \u03a9 \u00d7 R+\nby size-biasing with the number of infected sites |\u03b7tA (\u03c9)|. Let \u03b9 and \u03c4 denote the projections\non \u039b and R+ , respectively. Then, under the law P\u0302\u03bbA , the random variable \u03b7\u03c4A describes a sizebiased contact process as a 'typical' time \u03c4 , and \u03b9 is a 'typical' infected site, chosen with equal\nprobabilities from \u03b7\u03c4A . The law P\u0302\u03bbA [(\u03b9, \u03b7\u03c4A ) \u2208 * ] is a Campbell law, which is closely related to\nthe more widely known Palm laws. (For the relation between Campbell and Palm laws, see\n[Eth00, Section 6.4].) The next lemma says that as \u03bb decreases to r, under the laws P\u03bbA , the\n'typical' time \u03c4 tends in probability to \u221e. Thus, the limit \u03bb \u2193 r corresponds to letting time\nto infinity.\nLemma 4.2 (Typical times) For each \u2205 =\n6 A \u2208 Pfin (\u039b),\n\u0002\n\u0003\nP\u0302\u03bbA \u03c4 \u2265 t \u2212\u2192 1\n\u03bb\u2193r\n\n(t > 0).\n\n(4.1.17)\n\nNote that \u03b9\u22121 \u03b7\u03c4 is the process \u03b7\u03c4 , viewed from the position of the typical infected site \u03b9. The\nnext theorem is the main result of this chapter. Recall the definition of \u03b7 in (4.1.8).\n\n\f148\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nTheorem 4.3 (The process seen from a typical infected site) Assume that the upper\ninvariant measure of the (\u039b, a, \u03b4)-contact process is nontrivial and that the exponential growth\nrate from Proposition 4.1 satisfies r = 0. Let \u2205 =\n6 A \u2208 Pfin (\u039b). Then\n(a) One has\n\u0003\n\u0002\n\u0003\n\u0002\nP\u0302\u03bbA \u03b9\u22121 \u03b7\u03c4A \u2208 * =\u21d2 P \u03b7 0 \u2208 * 0 \u2208 \u03b7 0 .\n\n(4.1.18)\n\n\u03bb\u21930\n\n(b) Moreover,\n\n\u0002\n\u0003\nP\u0302\u03bbA \u03b9\u22121 \u03b7\u03c4A \u2229 \u2206 = \u03b9\u22121 \u03b7 \u03c4 \u2229 \u2206 \u2212\u2192 1\n\n(\u2206 \u2208 Pfin (\u039b)),\n\n\u03bb\u21930\n\n(4.1.19)\n\nand the same holds with \u03b7 \u03c4 replaced by \u03b7\u03c4\u039b .\n\nNote that Theorem 4.3 holds when \u039b is a general countable group, but we have only verified\nthat its assumptions are satisfied for certain finitely generated groups (see Proposition 4.1 (d)).\nWe remark that for fixed \u03bb > 0, it is not at all obvious (and as far as we know not true) that\nthe distribution P\u0302\u03bbA [\u03b9\u22121 \u03b7 \u03c4 \u2208 * ] should be the same as P [\u03b7 0 \u2208 * | 0 \u2208 \u03b7 0 ]. Thus, none of the\nstatements (4.1.18) and (4.1.19) trivially implies the other one.\nAs a result of our methods, we can also prove the following fact, which is of some interest\non its own.\nProposition 4.4 (Typical particles descend from every surviving site) Assume that\nthe (\u039b, a, \u03b4)-contact process survives and that the exponential growth rate from Proposition 4.1\nsatisfies r = 0. Then\n{i} \u0002\n\nP\u0302\u03bb\n\n(j, 0)\n\n(\u03b9, \u03c4 ) (j, 0)\n\n\u0003\n\u221e \u2212\u2192 1\n\u03bb\u21930\n\n(i, j \u2208 \u039b).\n\n(4.1.20)\n\nOne of the original motivations of the present chapter was to answer the following question.\nAssuming survival and subexponential growth, is it true that for any i, j \u2208 \u039b,\n\u0002\nP \u2203(k, t) s.t. (i, 0)\n\n(k, t)\n\n\u221e and (j, 0)\n\n(k, t) (i, 0)\n\n\u221e, (j, 0)\n\n\u0003\n\u221e =1\n\n?\n(4.1.21)\nThis property may be interpreted as some sort of analogue of the uniqueness of the infinite\ncluster in (unoriented) percolation. Unfortunately, we do not know how to replace the sizebiased law in (4.1.20) by a law conditioned on survival. Question (4.1.21) has been answered\npositively for oriented percolation on Zd in [GH02]. As a further motivation for (4.1.21), we\nnote that in the one-dimensional nearest-neighbor case, a considerably stronger statement\nholds.\nLemma 4.5 (Coupling of one-dimensional processes) Consider a (Z, a, \u03b4)-contact process with a(i, j) = 0 for |i \u2212 j| =\n6 1. Assume that the process survives, and assume either \u03b4 > 0\nor a(0, 1) \u2227 a(1, 0) > 0. Then, for any i, j \u2208 Z,\n\u0002\n{j}\n{i}\nP inf{t \u2265 0 : \u03b7t = \u03b7t } < \u221e (i, 0)\n\n\u221e, (j, 0)\n\n\u0003\n\u221e = 1.\n\n(4.1.22)\n\n\f149\n\n4.1. INTRODUCTION AND MAIN RESULTS\n\n4.1.4\n\nMethods\n\nIn this section we describe the main line of our proof of Theorem 4.3 (a). The first ingredient\nis a chararacterization of the laws P\u0302\u03bbA [\u03b9\u22121 \u03b7\u03c4A \u2208 * ] and P [\u03b7 0 \u2208 * | 0 \u2208 \u03b7 0 ] in terms of the dual\n{0}\n(\u039b, a\u2020 , \u03b4)-contact process \u03b7 \u2020 . For simplicity, we only present the argument for P\u0302\u03bb . Let \u03c0\u03bb (A)\nbe the normalizing constant in (4.1.15). Recall the definition of the survival probability \u03c1 in\n(4.1.7). We write \u03c0 \u03bb and \u03c1 for the functions \u03c0\u03bb and \u03c1 normalised to one in the point {0}:\n\u03c1(A) :=\n\n\u03c1(A)\n\u03c1({0})\n\nand \u03c0 \u03bb (A) :=\n\n\u03c0\u03bb (A)\n.\n\u03c0\u03bb ({0})\n\n(4.1.23)\n\nWe let \u03c1\u2020 , \u03c0\u03bb\u2020 , \u03c1\u2020 , and \u03c0 \u2020\u03bb denote the analogues of \u03c1, \u03c0\u03bb , \u03c1, and \u03c0 \u03bb for the dual (\u039b, a\u2020 , \u03b4)-contact\nprocess.\nLemma 4.6 (Characterization of laws seen from an infected site)\n(a) One has\n\u0003\n{0} \u0002\n(A \u2208 Pfin (\u039b), \u03bb > r).\nP\u0302\u03bb A \u2229 \u03b9\u22121 \u03b7\u03c4{0} = \u2205 = \u03c0 \u2020\u03bb (A \u222a {0}) \u2212 \u03c0 \u2020\u03bb (A)\n(b) Moreover,\n\u0003\n\u0002\nP A \u2229 \u03b7 0 = \u2205 0 \u2208 \u03b7 0 = \u03c1\u2020 (A \u222a {0}) \u2212 \u03c1\u2020 (A)\n\n(A \u2208 Pfin (\u039b)).\n\n(4.1.24)\n\n(4.1.25)\n\nIt is not hard to see that the law of a P(\u039b)-valued random variable \u03b7 is uniquely characterized\nby all probabilities of the form P [A \u2229 \u03b7 = \u2205] with A \u2208 Pfin (\u039b). Therefore, by Lemma 4.6\nand the compactness of P(\u039b) \u223c\n= {0, 1}\u039b , in order to prove Theorem 4.3, it suffices to prove\nthat under the assumptions there, \u03c0 \u2020\u03bb \u2192 \u03c1\u2020 pointwise as \u03bb \u2193 0. In order to reduce notation,\nwe reverse the role of \u03b7 and \u03b7 \u2020 . Thus, we will prove that pointwise lim\u03bb\u21930 \u03c0 \u03bb = \u03c1, under the\nassumptions that the (\u039b, a, \u03b4)-contact process survives and its exponential growth rate is zero.\n(By (4.1.9) and Proposition 4.1 (c), this is equivalent to the (\u039b, a\u2020 , \u03b4)-contact process having\na nontrivial upper invariant law and exponential growth rate zero.)\nIt is not hard to show (see Section 4.2.1 below) that the (\u039b, a, \u03b4)-contact process started\nin a finite initial state solves the martingale problem for the operator\nX\nX\nGf (A) :=\na(i, j)1{i\u2208A} {f (A \u222a {j}) \u2212 f (A)} + \u03b4\n1{i\u2208A} {f (A\\{i}) \u2212 f (A)}, (4.1.26)\nij\n\ni\n\nwith domain D(G) := S(Pfin (\u039b)), where\n\nS(Pfin (\u039b)) := {f : Pfin (\u039b) \u2192 R : |f (A)| \u2264 K|A|k + M for some K, M, k \u2265 0}.\n\n(4.1.27)\n\nIt can be shown in a few lines that \u03c1 is shift invariant, monotone (i.e., A \u2282 B implies \u03c1(A) \u2264\n\u03c1(B)), \u03c1 \u2208 S(Pfin (\u039b)), and\nG\u03c1 = 0.\n(4.1.28)\nFormula (4.1.28) says that \u03c1 is a harmonic function for the (\u039b, a, \u03b4)-contact process. It is not\nhard to see that \u03c0\u03bb shift invariant, monotone, \u03c0\u03bb \u2208 S(Pfin (\u039b)), and\nG\u03c0\u03bb (A) = \u03bb\u03c0\u03bb (A) \u2212 |A|\nAs a consequence, one obtains:\n\n(A \u2208 Pfin (\u039b), \u03bb > r).\n\n(4.1.29)\n\n\f150\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nLemma 4.7 (Cluster points of the rescaled expected population size) The functions\n(\u03c0 \u03bb )\u03bb>r are relatively compact with respect to the product topology on RPfin (\u039b) . Each pointwise\nlimit\n(A \u2208 Pfin (\u039b))\n(4.1.30)\n\u03c0 r (A) := lim \u03c0 \u03bbn (A)\nn\u2192\u221e\n\nalong a sequence \u03bbn \u2193 r is shift invariant, monotone in A, satisfies \u03c0 r \u2208 S(Pfin (\u039b)), and\nG\u03c0 r = r\u03c0 r .\n\n(4.1.31)\n\nIn particular, if r = 0 and the (\u039b, a, \u03b4)-contact process survives, it turns out that Lemma 4.7\ngives us enough information to determine \u03c0 0 uniquely. Combined with the next proposition,\nLemma 4.7 shows that \u03c0 \u03bb \u2192 \u03c1 pointwise as \u03bb \u2193 0, thereby completing the proof of Theorem 4.3.\nProposition 4.8 (Shift invariant monotone harmonic functions) Assume that the\n(\u039b, a, \u03b4)-contact process survives. Assume that f : Pfin (\u039b) \u2192 R is shift invariant, monotone,\nf (\u2205) = 0, f \u2208 S(Pfin (\u039b)), and Gf = 0. Then there exists a constant c \u2265 0 such that f = c\u03c1.\n\nWe note that if \u03bd is a homogeneous invariant measure for the (\u039b, a\u2020 , \u03b4)-contact process, then\nby duality, f (A) := \u03bd({A : A \u2229 B 6= \u2205}) defines a shift invariant, monotone, bounded harmonic\nfunction f for the (\u039b, a, \u03b4)-contact process. Therefore, in view of (4.1.9), Proposition 4.8 is a\nstrengthening of the statement that all homogeneous invariant measures are convex combinations of \u03bd and \u03b40 .\nIn order to prove Proposition 4.8, we need one more lemma.\nLemma 4.9 (Eventual domination of finite configurations) Assume that the (\u039b, a, \u03b4)contact process survives. Then\n\u0002\nlim P \u2203i \u2208 \u039b s.t. \u03b7tA \u2265 iB \u03b7tA 6= \u2205] = 1\n(A, B \u2208 Pfin (\u039b), A 6= \u2205).\n(4.1.32)\nt\u2192\u221e\n\nFormula (4.1.32) says that \u03b7 exhibits a form of extinction versus unbounded growth. More\nprecisely, either \u03b7t gets extinct or \u03b7t is eventually larger than a suitable shift (depending on\n\u03b7t ) of any finite configuration. We remark that Lemma 4.9 is no longer true if assumption\n(4.1.1) (iii) is replaced by the weaker assumption that {i \u2208 \u039b : a(0, i) > 0} generates \u039b.\n\nProof of Proposition 4.8 Since the (\u039b, a, \u03b4)-contact process solves the martingale problem\nfor G, and Gf = 0, the process f (\u03b7tA ) is a martingale. In particular:\nf (A) = E[f (\u03b7tA )]\n\n(A \u2208 Pfin (\u039b), t \u2265 0).\n\nEquip \u039b with an arbitrary linear ordering, and for A, B \u2208 Pfin (\u039b), put\n\u001a\nmin{i \u2208 \u039b : A \u2265 iB}\nif {i \u2208 \u039b : A \u2265 iB} is nonempty,\n\u0131\u0302A,B :=\n0\notherwise.\n\n(4.1.33)\n\n(4.1.34)\n\nSince f is monotone and shift invariant, we have, using Lemma 4.9,\nf (A) = lim E[f (\u03b7tA )]\nt\u2192\u221e\n\nf (\u0131\u0302\nB)]\n\u2265 lim sup E[1\n{\u2203i \u2208 \u039b s.t. \u03b7tA \u2265 iB} \u03b7tA ,B\nt\u2192\u221e\n= f (B) lim sup P [\u2203i \u2208 \u039b s.t. \u03b7tA \u2265 iB] \u2265 f (B)\u03c1(A)\nt\u2192\u221e\n\n(4.1.35)\n(A, B \u2208 Pfin (\u039b)).\n\n\f151\n\n4.1. INTRODUCTION AND MAIN RESULTS\nIn particular, this shows that\nf (B) \u2264\n\nf ({0})\n<\u221e\n\u03c1({0})\n\n(B \u2208 Pfin (\u039b)),\n\n(4.1.36)\n\nhence f is bounded. Now let An , Bm \u2208 Pfin (\u039b) be sequences such that \u03c1(An ) \u2192 1 and\n\u03c1(Bn ) \u2192 1. Then, by (4.1.35),\nlim inf f (An ) \u2265 lim inf f (Bm )\u03c1(An ) = f (Bm ) \u2200m,\n\n(4.1.37)\n\nlim inf f (An ) \u2265 lim sup f (Bm ).\n\n(4.1.38)\n\nn\u2192\u221e\n\nn\u2192\u221e\n\nand therefore\nn\u2192\u221e\n\nm\u2192\u221e\n\nThis proves that the limit\nlim\n\n\u03c1(An )\u21921\n\nf (An ) =: f (\u221e)\n\n(4.1.39)\n\nexists and does not depend on the choice of the sequence An with \u03c1(An ) \u2192 1. By the Markov\nproperty and continuity of the conditional expectation with respect to increasing limits of\n\u03c3-fields (see Complement 10(b) from [Loe63, Section 29] or [Loe78, Section 32]),\n\u0002\n\u0003\n\u03c1(\u03b7tA ) = P \u03b7sA 6= 0 \u2200s \u2265 0 \u03b7tA \u2192 1 A\n{\u03b7s 6= 0 \u2200s \u2265 0}\n\na.s. as t \u2192 \u221e.\n\n(4.1.40)\n\nWe conclude that\n\nf (A) = lim E[f (\u03b7tA )] = \u03c1(A)f (\u221e)\nt\u2192\u221e\n\n(A \u2208 Pfin (\u039b)),\n\n(4.1.41)\n\nwhich shows that f is a scalar multiple of \u03c1.\n\n4.1.5\n\nDiscussion and open problems\n\nPalm and Campbell laws are standard tools in the study of (critical) spatial branching processes. In this context, they can be described by Kallenberg's backward tree technique; see,\nfor example, [Kal77] or [GW91]. In the context of contact processes, it is less obvious that\n{0}\nthey should be of any use. For example, size-biasing with |\u03b7t \u2229 {i}| for fixed i and t is just\nthe same as conditioning on (0, 0)\n(i, t). In this case there seems to be no easy way to prove\n{0}\n\u22121\nstatements about i \u03b7t .\nHowever, by looking at the process seen from a randomly chosen infected site rather than a\nfixed site, i.e., by looking at Campbell laws rather than Palm laws, we can make a connection\n{0}\nwith the growth of E[|\u03b7t |] as t \u2192 \u221e, and in this way obtain a result. A disadvantage of\nthis approach is that one ends up with statements about size-biased laws, where one would\nprobably be more interested in laws conditioned on survival. Nevertheless, it seems that the\nstatements in Theorem 4.3 do catch a phenomenon that depends in a crucial way on a property\nof the underlying lattice, in this case, subexponential growth.\nWe next state some open problems and questions, and then comment on them.\n\n\f152\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\n1. Problem Replace the random time \u03c4 in by a deterministic time t and prove the analogue\nof Theorem 4.3 for t \u2192 \u221e.\n2. Problem Study the contact process seen from a typical infected site in case the exponential growth rate is positive.\n3. Problem Study the contact proces seen from a typical infected site chosen from a\nprocess conditioned to survive, instead of size-biased on the number of infected sites.\n4. Problem Prove (4.1.21) assuming survival and subexponential growth.\n5. Problem Assuming survival and subexponential growth, prove that conditional on\n{j}\n{i}\n(i, 0)\n\u221e and (j, 0)\n\u221e, eventually most sites in \u03b7t are also in \u03b7t .\n{i}\n\n6. Question With the same set-up as in the previous problem, is it even true that \u03b7t\n{j}\nand \u03b7t are eventually equal? (Compare Lemma 4.5.)\n\n7. Problem Prove that \u03b4c > 0 for a contact process on a group \u039b that is not finitely\ngenerated, for example on the hierarchical group.\n8. Problem Give an example of a contact process on Z for which the exponential growth\nrate is positive.\n9. Question Assuming that \u039b has exponential growth, is it true that the (\u039b, a, \u03b4)-contact\nprocess survives if and only if r(\u039b, a, d) > 0?\n10. Question Does survival of the (\u039b, a, \u03b4)-contact process imply survival of the (\u039b, a\u2020 , \u03b4)contact process?\nIf one tries to solve Problem 1 in a naive way, by mimicking the techniques in this chapter, it\nseems one would have to strengthen Proposition 4.1 (a) in the sense that\n\u0002\n\u0003\n\u2202\nlog E |\u03b7tA | = r\n(\u2205 =\n6 A \u2208 Pfin (\u039b)).\n(4.1.42)\nlim \u2202t\nt\u2192\u221e\n\n\u0003 \u0002 {0} \u0003\n\u0002\nThen it would follow that each cluster point \u03c0 \u221e of the functions \u03c0 t (A) := E |\u03b7tA | /E |\u03b7t |\nsatisfies G\u03c0 \u221e = 0. However, (4.1.42) does not simply follow from subadditivity and seems\nhard to establish in general. Even random times \u03c4 that are uniformly distributed\nR T \u0002 on\u0003intervals\n\u2202\n[0, T ] seem difficult to treat, since they would require that limT \u2192\u221e \u2202T\nlog 0 E |\u03b7tA | dt = r.\nIn order to solve Problem 2, generalizing Proposition 4.8, one would like to show that the\nequation G\u03c0 r = r\u03c0 r has a unique shift invariant, monotone solution \u03c0 r with \u03c0 r (\u2205) = 0 and\n\u03c0 r ({0}) = 1 (perhaps also using that \u03c0 r is subadditive).\nProblems 3\u20135 and Question 6 have been discussed before. The difficulty is to replace sizebiased laws by laws conditioned on survival in statements like Proposition 4.4. Although sizebiasing and conditioning are asymptotically equivalent in a 'local' sense (see Proposition 4.14\nbelow), this does not seem easy. Note that if (4.1.21) holds for the (\u039b, a\u2020 , \u03b4)-contact process,\nthen the limit law in Theorem 4.3 (a) may also be written as P [\u03b7\u03020 \u2208 * | \u2212 \u221e\n(0, 0)], where\n\u03b7\u0302t := {i \u2208 \u039b : \u2203(j, s) s.t. \u2212 \u221e\n(j, s)\n(0, 0) and (j, s)\n(i, t)} (t \u2208 R). This construction\n\n\f4.1. INTRODUCTION AND MAIN RESULTS\n\n153\n\nis similar to Kallenberg's backward tree technique, and also somewhat reminiscent of the\nconstruction of the the second lowest extremal invariant measure of the contact process in\n[SS97, SS99].\nProblem 7 seems interesting, since the hierarchical group has found applications in population biology, and the usual comparison with one-dimensional oriented percolation cannot\nwork here.\nProblem 8 and Question 9 are naturally motivated by Proposition 4.1 (d). Related to\nQuestion 9 is the more general question: what does the behavior of E[|\u03b7t |] for t \u2192 \u221e tell us\nabout survival? Especially for critical processes, it seems conceivable that limt\u2192\u221e E[|\u03b7t |] = \u221e\nwhile the process dies out.\nRelated to this is Question 10, which has been asked before for branching-coalescing particle systems in [AS05]. For symmetric processes or for processes on abelian groups, the answer\nis obviously positive, but in general (\u039b, a) and (\u039b, a\u2020 ) need not be isomorphic. However, in for{0}\n\u2020 {0}\nmula (4.2.14) below, it is shown that E[|\u03b7t |] = E[|\u03b7t |] for all t \u2265 0. (On the other hand,\ndropping the assumption that \u039b is a group, by considering contact processes on transitive\n\u2020 {0}\n{0}\ngraphs that are not unimodular, it is easy to construct examples where E[|\u03b7t |] 6= E[|\u03b7t |]\nand where \u03b7 survives but \u03b7 \u2020 dies out.) An example of a model on Z2 where nontriviality of\nthe upper invariant law and survival are not equivalent is the NEC model due to A. Toom\n[BG85, DLSS91].\nRelated to Question 10 (compare also Question 6) is the following question: is it always\n{0}\ntrue that inf{t \u2265 0 : \u03b7t \u2282 \u03b7 t } is a.s. finite? Note that if the answer is positive, then extinction\nof the (\u039b, a\u2020 , \u03b4)-contact process implies extinction of the (\u039b, a, \u03b4)-contact process, since in this\ncase \u03b7 \u2261 0.\n\n4.1.6\n\nOutline\n\nSection 4.2 is devoted to the proof of Theorem 4.3 (a). In Section 4.2.1 we prove that contact\nprocesses started in finite initial states solve the martingale problem for the operator G in\n(4.1.26). We establish Proposition 4.1 (a)\u2013(c) in Section 4.2.2, and part (d) in Section 4.2.3.\nIn Section 4.2.4, we establish Lemmas 4.2 and 4.6. In Section 4.2.5, we prove basic facts\nabout the functions \u03c1 and \u03c0\u03bb ; in particular, formulas (4.1.28) and (4.1.29), and Lemma 4.7.\nIn Section 4.2.6, we prove Lemma 4.9, thereby completing the proof of Theorem 4.3 in the\ncase A = {0}. In Section 4.2.7 we show how the arguments may be generalized to arbitrary\n\u2205=\n6 A \u2208 Pfin (\u039b).\nSection 4.3 contains proofs of all results that are not directly needed for Theorem 4.3 (a).\nIn Section 4.3.1, we prove that size-biasing and conditioning on survival are equivalent in\na 'local' sense. Section 4.3.2 contains the proofs of Theorem 4.3 (b) and Proposition 4.4.\nSection 4.3.3 contains the proof of Lemma 4.5. For completeness, we prove in Section 4.3.4\nthe fact mentioned in the text that \u03b4c > 0 whenever \u039b is finitely generated.\n\nAcknowledgements The author thanks Geoffrey Grimmmett, Olle H\u00e4ggstr\u00f6m, Russel\nLyons, and Roberto Schonmann for useful email conversations about the contact process,\noriented percolation, and amenability.\n\n\f154\n\n4.2\n4.2.1\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nThe law seen from a typical particle\nA martingale problem\n\nIn this section we prove that the (\u039b, a, \u03b4)-contact process started in finite initial states solves\nthe martingale problem for the operator G in (4.1.26)\u2013(4.1.27).\nProposition 4.10 (Martingale problem and moment estimate) For each f \u2208 S(Pfin (\u039b))\nand A \u2208 Pfin (\u039b), the process\nZ t\nGf (\u03b7sA )ds\n(t \u2265 0)\n(4.2.1)\nMt := f (\u03b7tA ) \u2212\n0\n\nis\na martingale with respect to the filtration generated by \u03b7 A . Moreover, setting z hki :=\nQk\u22121\ni=0 (z + i), one has\n\u0002\n\u0003\nE |\u03b7tA |hki \u2264 |A|hki ek(|a|\u2212\u03b4)t\n(A \u2208 Pfin (\u039b), k \u2265 1, t \u2265 0).\n(4.2.2)\n\nProof The proof of [AS05, Proposition 8] can in a straightforward way be adapted to the\npresent set-up. Set fk (A) := |A|hki . Then\nX\nX\nGfk (A) =\na(i, j)1{i\u2208A} 1{j6\u2208A} {(|A| + 1)hki \u2212 |A|hki } + \u03b4\n1{i\u2208A} {(|A| \u2212 1)hki \u2212 |A|hki },\nij\n\ni\n\n\u2264 (|a| \u2212 \u03b4)|A|{(|A| + 1)hki \u2212 |A|hki } = k(|a| \u2212 \u03b4)|A|hki .\n\n(4.2.3)\nhas\n\u2265 N }. The stopped process\nDefine stopping times \u03c4N := inf{t \u2265 0 :\nbounded jump rates, and therefore standard theory tells us that for each N \u2265 1 and f \u2208\nS(Pfin (\u039b)), the process\nZ t\u2227\u03c4N\nA\n)\n\u2212\nGf (\u03b7sA )ds\n(t \u2265 0)\n(4.2.4)\nMtN := f (\u03b7t\u2227\u03c4\nN\n|\u03b7tA |\n\nA\n)\n(\u03b7t\u2227\u03c4\nN t\u22650\n\n0\n\nis a martingale. Moreover, it easily follows from (4.2.3) that\n\u0002 A hki \u0003\n|\n\u2264 |A|hki ek(|a|\u2212\u03b4)t\n(k \u2265 1, t \u2265 0).\nE |\u03b7t\u2227\u03c4\nN\n\n(4.2.5)\n\nIt is easy to see that f \u2208 S(Pfin (\u039b)) implies Gf \u2208 S(Pfin (\u039b)). Using this fact and (4.2.5)\nfor some sufficiently high k (depending on f ), one can show that for fixed t \u2265 0, the random\nvariables (MtN )N \u22651 are uniformly integrable. Therefore, letting N \u2192 \u221e in (4.2.4), one finds\nthat the process in (4.2.1) is a martingale. Letting N \u2192 \u221e in (4.2.5) yields (4.2.2).\n\n4.2.2\n\nThe exponential growth rate\n\nIn this section we prove Proposition 4.1 (a)\u2013(c).\nProof of Proposition 4.1 (a) By a slight abuse of notation, let us write (compare (4.1.15))\n\u0002\n\u0003\n\u03c0t (A) := E |\u03b7tA |\n(A \u2208 Pfin (\u039b), t \u2265 0).\n(4.2.6)\n\n\f155\n\n4.2. THE LAW SEEN FROM A TYPICAL PARTICLE\nWe start by showing that\n\u03c0s+t ({0}) \u2264 \u03c0s ({0})\u03c0t ({0})\n\n(s, t \u2265 0).\n\n(4.2.7)\n\nBy (4.1.3),\ni X \u0002\nh [\n\u0002 {0} \u0003\n\u0002\n\u0003\n{i} \u0003\n{i}\n\u2264\nE |\u03b7t | = |A|E |\u03b7t | ,\nE |\u03b7tA | = E\n\u03b7t\n\n(4.2.8)\n\ni\u2208A\n\ni\u2208A\n\nwhere in the last step we have used shift invariance. As a consequence,\n\u03c0s+t ({0}) =\n\nZ\n\nP [\u03b7s{0}\n\n\u2208 dA]E\n\n\u0002\n\n|\u03b7tA |\n\n\u0003\n\n\u2264\n\nZ\n\n\u0002 {0} \u0003\nP [\u03b7s{0} \u2208 dA]|A|E |\u03b7t | = \u03c0s ({0})\u03c0t ({0}).\n\n(4.2.9)\nThis proves (4.2.7). It follows that t \u2192\n7 log \u03c0t ({0}) is subadditive and therefore, by [Lig99,\nTheorem B.22], the limit\nlim 1\nt\u2192\u221e t\n\nlog \u03c0t ({0}) =: r \u2208 [\u2212\u221e, \u221e]\n\n(4.2.10)\n\nexists. By monotonicity and (4.2.8),\n\u03c0t ({0}) \u2264 \u03c0t (A) \u2264 |A|\u03c0t ({0})\n\n(A \u2208 Pfin (\u039b)).\n\n(4.2.11)\n\nTaking logarithms, dividing by t, and letting t \u2192 \u221e we arrive at (4.1.13). Since \u03b7 can be\nbounded from below by a simple death process and from above by a branching process (see\n(4.2.15) below), one has\n\u0002 {0} \u0003\ne\u2212\u03b4t \u2264 E |\u03b7t | \u2264 e(|a|\u2212\u03b4)t\n\n(t \u2265 0),\n\n(4.2.12)\n\nwhich implies that \u2212\u03b4 \u2264 r \u2264 |a| \u2212 \u03b4.\n\nProof of Proposition 4.1 (b) If the (\u039b, a, \u03b4)-contact process survives, then\n{0}\n\n\u03c0t ({0}) \u2265 P [\u03b7t\n\n6= 0] \u2212\u2192 P [\u03b7s{0} 6= 0 \u2200s \u2265 0] > 0,\nt\u2192\u221e\n\n(4.2.13)\n\nwhich implies that r \u2265 0.\nProof of Proposition 4.1 (c) By duality (formula (4.1.6)) and shift invariance,\n\u0003\n\u0003 X \u0002\n\u0002 {0} \u0003 X \u0002 {0}\n\u2020 {i}\n6= \u2205\n6 \u2205 =\nP {0} \u2229 \u03b7t\nP \u03b7t \u2229 {i} =\nE |\u03b7t | =\ni\nX\n\u0003 i \u0002 \u2020 {0} \u0003\n\u0002\n\u2020 {0}\n6= \u2205 = E |\u03b7t | ,\n=\nP {i\u22121 } \u2229 \u03b7t\ni\n\nwhich implies that r(\u039b, a, \u03b4) = r(\u039b, a\u2020 , \u03b4).\n\n(4.2.14)\n\n\f156\n\n4.2.3\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nSubexponential growth\n\nProof of Proposition 4.1 (d) Consider a branching process on \u039b, started with one particle\nin the origin, where a particle at i produces a new particle at j with rate a(i, j), and each\nparticle dies with rate \u03b4. Let Bt (i) denote the number of particles at site i \u2208 \u039b and time t \u2265 0.\nIt is not hard to see that \u03b7 {0} and B may be coupled such that\n1\u03b7{0} \u2264 Bt\nt\n\n(t \u2265 0).\n\n(4.2.15)\n\nLet (\u03bet )t\u22650 be a random walk on \u039b that jumps from i to j with rate a(i, j), started in \u03be0 = 0.\nThen it is not hard to see that (compare [Lig99, Proposition I.1.21])\nE[Bt (i)] = P [\u03bet = i]e(|a|\u2212\u03b4)t\n\n(i \u2208 \u039b, t \u2265 0).\n\n(4.2.16)\n\nLet \u03b3 > 0 be a constant, to determined later. It follows from (4.2.15) and (4.2.16) that\n\u0001\n\u0002 {0} \u0003 X\n1 \u2227 P [\u03bet = i]e(|a|\u2212\u03b4)t\nE |\u03b7t | \u2264\n(4.2.17)\ni\n= |{i \u2208 \u039b : |i| \u2264 \u03b3t}| + P [|\u03bet | > \u03b3t]e(|a|\u2212\u03b4)t\n(t \u2265 0).\n1 P\nLet (Yi )i\u22651 be i.i.d. N-valued random variables with P [Yi = k] = |a|\nj: |j|=k a(0, j) (k \u2265 0),\nlet N be a Poisson-distributed random variable with mean |a|, independent\nof the (Yi )i\u22651 ,\nPN\nand let (Xm )m\u22651 be i.i.d. random variables with law P [Xm \u2208 * ] = P [ i=1 Yi \u2208 * ]. Since the\nrandom walk \u03be makes jumps whose sizes are distributed in the same way as the Yi , and the\nnumber of jumps per unit of time is Poisson distributed with mean |a|, it follows that\n\u2308t\u2309\nh 1 X\nt i\nXm > \u03b3\nP [|\u03bet | > \u03b3t] \u2264 P\n\u2308t\u2309\n\u2308t\u2309\n\n(t > 0),\n\n(4.2.18)\n\nm=1\n\nwhere \u2308t\u2309 denotes t rounded up to the next integer. By our assumptions,\n\n\u221e\nX\n\u0002 \u03b5X \u0003\n\u0002 \u03b5 PN Y \u0003\n\u03b5Y1\n|a|n \u0002 \u03b5Y1 \u0003n\n\u2212|a|\nm\nk\ni=1\nE e\n= e \u2212|a|(1 \u2212 E[e ]) < \u221e, (4.2.19)\nE e\n=E e\n=e\nn!\nn=0\n\nfor some \u03b5 > 0. Therefore, by [DZ98, Theorem 2.2.3 and Lemma 2.2.20], for each R > 0 there\nexists a \u03b3 > 0 and K < \u221e such that\nP\n\nn\nh1 X\n\nn m=1\n\ni\nXm > \u03b3 \u2264 K e \u2212nR\n\n(n \u2265 1).\n\nChoosing \u03b3 such that (4.2.20) holds for some R > |a| \u2212 \u03b4 yields, by (4.2.18)\n\u0002\n\u0003\nlim P |\u03bet | > \u03b3t e(|a|\u2212\u03b4)t = 0.\nt\u2192\u221e\n\n(4.2.20)\n\n(4.2.21)\n\nInserting this into (4.2.17) we find that the exponential growth rate r = r(\u039b, a, \u03b4) satisfies\nr \u2264 lim sup\nt\u2192\u221e\n\n1\nlog |{i \u2208 \u039b : |i| \u2264 \u03b3t}| = 0,\nt\n\nwhere we have used that \u039b is subexponential.\n\n(4.2.22)\n\n\f4.2. THE LAW SEEN FROM A TYPICAL PARTICLE\n\n4.2.4\n\n157\n\nDuality and Campbell laws\n\nProof of Lemma 4.6 (a) This follows by writing\nXZ \u221e \u0002\n\u0003 (1)\n\u0003\n{0} \u0002\n{0}\n{0}\n\u22121 {0}\n\u22121\nP\u0302\u03bb A \u2229 \u03b9 \u03b7\u03c4 = \u2205 = \u03c0\u03bb ({0})\nP i \u2208 \u03b7t , A \u2229 i\u22121 \u03b7t = \u2205 e\u2212\u03bbt dt\n0\ni\nXZ \u221e \u0002\n\u0003\n(2)\n{i\u22121 }\n{i\u22121 }\n\u22121\n= \u2205 e\u2212\u03bbt dt\n, A \u2229 \u03b7t\nP 0 \u2208 \u03b7t\n= \u03c0\u03bb ({0})\n0\ni\nX Z \u221en \u0002\n\u0003o\n\u0003\n\u0002\n(3)\n{j}\n{j}\nP (A \u222a {0}) \u2229 \u03b7t 6= \u2205 \u2212 P A \u2229 \u03b7t 6= \u2205 e\u2212\u03bbt dt\n= \u03c0\u03bb ({0})\u22121\nj Z0\n\u221en \u0002\nX\n\u0003\n\u0002\n\u0003o\n(4) \u2020\n\u2020 A\u222a{0}\n\u2229 {j} =\n6 \u2205 \u2212 P \u03b7t\u2020 A \u2229 {j} =\n6 \u2205 e\u2212\u03bbt dt\nP \u03b7t\n= \u03c0\u03bb ({0})\u22121\n0\nZj \u221e n\n\u0002\n\u0003o\n\u0002 \u2020 A\u222a{0} \u0003\n(5) \u2020\n| \u2212 E |\u03b7t\u2020 A | e\u2212\u03bbt dt\nE |\u03b7t\n= \u03c0\u03bb ({0})\u22121\n0\n\b\n(6) \u2020\n(7)\n= \u03c0\u03bb ({0})\u22121 \u03c0\u03bb\u2020 (A \u222a {0}) \u2212 \u03c0\u03bb\u2020 (A) = \u03c0 \u2020\u03bb (A \u222a {0}) \u2212 \u03c0 \u2020\u03bb (A).\n\n(4.2.23)\n\nHere, in step (2) we have used shift invariance, in step (3) we have changed the summation\n{j}\n{j}\n{j}\n{j}\norder and used that {0 \u2208 \u03b7\u03c4 , A \u2229 \u03b7\u03c4 = \u2205} = {(A \u222a {0}) \u2229 \u03b7\u03c4 6= \u2205}\\{A \u2229 \u03b7\u03c4 6= \u2205}, and in\nstep (4) we have used duality (formula (4.1.6)) and formula (4.2.14).\n\nProof of Lemma 4.6 (b) We have\n\u0003\n\u0003 (1) \u0002\n\u0003\u22121 \u0002\n\u0002\nP A \u2229 \u03b70 = \u2205 0 \u2208 \u03b7 0 = P 0 \u2208 \u03b7 0 P 0 \u2208 \u03b70, A \u2229 \u03b7 0 = \u2205\n\u0003\u22121 \b \u0002\n\u0003\n\u0002\n\u0003\n(2) \u0002\nP (A \u222a {0}) \u2229 \u03b7 0 6= \u2205 \u2212 P A \u2229 \u03b7 0 6= \u2205\n= P {0} \u2229 \u03b7 0 6= \u2205\n\b\n(3) \u2020\n(4)\n= \u03c1 ({0}) \u03c1\u2020 (A \u222a {0}) \u2212 \u03c1\u2020 (A) = \u03c1\u2020 (A \u222a {0}) \u2212 \u03c1\u2020 (A),\n(4.2.24)\nwhere in step (3) we have used (4.1.9).\nAs a preparation for the proof of Lemma 4.2, we prove:\nLemma 4.11 (Expected population size) One has lim\u03bb\u2193r \u03c0\u03bb (A) = \u221e for all \u2205 =\n6 A \u2208\nPfin (\u039b).\nProof We start with the case A = {0}. Recall that Proposition 4.1 (a) is a consequence of\n{0}\nthe subadditivity of the function t 7\u2192 log E[|\u03b7t |]. In fact, subadditivity gives us a little more.\nBy [Lig99, Theorem B.22],\n1\nt\u2192\u221e t\n\nlim\n\n\u0002 {0} \u0003\nlog E |\u03b7t | = inf\n\n1\nt>0 t\n\n\u0002 {0} \u0003\nlog E |\u03b7t | = r,\n\n(4.2.25)\n\nwhere r = r(\u039b, a, \u03b4) \u2208 [\u2212\u03b4, |a| \u2212 \u03b4] is the exponential growth rate. Formula (4.2.25) says that\n{0}\nE[|\u03b7t |] = ert t where limt\u2192\u221e rt = inf t>0 rt = r. Thus, for every \u03b5 > 0, there exists a T\u03b5 < \u221e\nsuch that\n\u0002 {0} \u0003\n(t \u2265 T\u03b5 ).\n(4.2.26)\nert \u2264 E |\u03b7t | \u2264 e(r+\u03b5)t\n\n\f158\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nIt follows from the lower bound in (4.2.26) and monotone convergence that\nZ \u221e\n\u0002 {0} \u0003\nE |\u03b7t | e\u2212rt dt = \u221e.\nlim \u03c0\u03bb ({0}) =\n\n(4.2.27)\n\nProof of Lemma 4.2 By Lemma 4.11,\nR t \u0002 A \u0003 \u2212\u03bbs\nR t \u0002 A \u0003 \u2212rs\n\u0002\n\u0003\nE |\u03b7s | e\nds\nE |\u03b7s | e\nds\nA\n0\nP\u0302\u03bb \u03c4 < t = R \u221e \u0002 A \u0003 \u2212\u03bbs\n\u2212\u2192 0.\n\u2264 0\n\u03bb\u2193r\n\u03c0\u03bb (A)\nds\n0 E |\u03b7s | e\n\n(4.2.28)\n\n\u03bb\u2193r\n\n0\n\nThe generalization to arbitrary \u2205 =\n6 A \u2208 Pfin (\u039b) is immediate, since \u03c0\u03bb is monotone.\n\nfor any t > 0.\n\n4.2.5\n\nHarmonic functions\n\nIn this section we prove formulas (4.1.28) and (4.1.29), and Lemma 4.7.\nProof of (4.1.28) The shift invariance and monotonicity of \u03c1 follow from the corresponding\nproperties of the contact process. Since \u03c1 is bounded, obviously \u03c1 \u2208 S(Pfin (\u039b)). Since \u03b7 A\nsolves the martingale problem for G, for any f \u2208 S(Pfin (\u039b)), one has\nZ t\nE[Gf (\u03b7sA )]ds = E[f (\u03b7tA )] \u2212 f (A)\n(A \u2208 Pfin (\u039b)),\n(4.2.29)\n0\n\nand therefore\n\b\nGf (A) = lim t\u22121 E[f (\u03b7tA )] \u2212 f (A)\n\n(A \u2208 Pfin (\u039b)).\n\nt\u21920\n\n(4.2.30)\n\nBy the Markov property,\n\n\u0002\n\u0003\n\u0002\n\u0003\n\u03c1(\u03b7tA ) = E \u03b7sA 6= 0 \u2200s \u2265 0 \u03b7tA = E \u03b7sA 6= 0 \u2200s \u2265 0 FtA ,\n\n(4.2.31)\n\nwhere (FtA )t\u22650 denotes the filtration generated by \u03b7 A . It follows that \u03c1(\u03b7tA ) is a martingale,\nand therefore, by (4.2.30), G\u03c1 = 0.\nProof of (4.1.29) The shift invariance and monotonicity of \u03c0\u03bb follow from the corresponding\nproperties of the contact process. It follows from (4.1.3) that \u03c0\u03bb (A) \u2264 \u03c0\u03bb ({0})|A|, which\nshows that \u03c0\u03bb \u2208 S(Pfin (\u039b)). Moreover,\n\b\nt\u22121 E[\u03c0\u03bb (\u03b7tA )] \u2212 \u03c0\u03bb (A)\nZ \u221en\n\u0002 A \u0003\n\u0002\n\u0003o\n\u22121\nE |\u03b7t+s\n| \u2212 E |\u03b7sA | e\u2212\u03bbs ds\n=t\nZ \u221e\no\nn 0Z \u221e \u0002\n\u0002\n\u0003\n\u0003 \u2212\u03bb(s\u2212t)\n(4.2.32)\nA\n\u22121\nE |\u03b7sA | e\u2212\u03bbs ds\nE |\u03b7s | e\nds \u2212\n=t\n0\nt\nZ \u221e\nZ t\n\u0002 A \u0003 \u2212\u03bbs\n\u0002\n\u0003\n\u03bbt \u22121\n\u22121 \u03bbt\nds \u2212 e t\nE |\u03b7s | e\n= t (e \u2212 1)\nE |\u03b7sA | e\u2212\u03bbs ds.\n0\n\n0\n\nLetting t \u2192 0, using (4.2.30), it follows that\n\nG\u03c0\u03bb (A) = \u03bb\u03c0\u03bb (A) \u2212 |A|\n\n(A \u2208 Pfin (\u039b), \u03bb > r),\n\n(4.2.33)\n\n\f4.2. THE LAW SEEN FROM A TYPICAL PARTICLE\n\n159\n\nas desired.\nProof of Lemma 4.7 It follows from (4.1.24) that \u03c0 \u03bb (A) \u2264 |A|, which shows that the\nfunctions (\u03c0 \u03bb )\u03bb>r are relatively compact, and each pointwise limit \u03c0 \u221e along a sequence \u03bbn \u2193 r\nsatisfies \u03c0 \u221e \u2208 S(Pfin (\u039b)). Since each \u03c0 \u03bbn is shift invariant an monotone, the same is true for\n\u03c0 \u221e . If fn , f \u2208 S(Pfin (\u039b)), fn \u2192 f pointwise, and the fn are uniformly bounded on sets of the\nform {A \u2208 Pfin (\u039b) : |A| \u2264 K}, then it is not hard to see that pointwise\nlim Gfn = Gf.\n\nn\u2192\u221e\n\n(4.2.34)\n\nApplying this to the functions \u03c0 \u03bbn , which satisfy the uniform bound \u03c0 \u03bbn (A) \u2264 |A|, using\n(4.1.29) and Lemma 4.11, we find that\nG\u03c0 \u221e (A) = lim\n\nn\u2192\u221e\n\n|A|\n\u03bbn \u03c0\u03bbn (A) \u2212 |A|\n= lim \u03bbn \u03c0 \u03bbn (A) \u2212\n= r\u03c0 r (A)\nn\u2192\u221e\n\u03c0\u03bbn ({0})\n\u03c0\u03bbn ({0})\n\n(A \u2208 Pfin (\u039b)),\n(4.2.35)\n\nas required.\n\n4.2.6\n\nEventual domination of finite configurations\n\nIn this section we prove Lemma 4.9. We start with two preparatory lemmas.\nLemma 4.12 (Local creation of finite configurations) For each B \u2208 Pfin (\u039b) and t > 0,\nthere exists a finite \u2206 \u2282 \u039b and j \u2208 \u039b such that\n\u0003\n\u0002 {0}\n\u03b5 := P \u03b7t \u2283 jB and \u03b7s{0} \u2282 \u2206 \u22000 \u2264 s \u2264 t > 0.\n\n(4.2.36)\n\n\u0002 {j \u22121 }\n\u2283\nProof It follows from assumption (4.1.1) (iii) that there exists a site j \u22121 \u2208 \u039b with P \u03b7t\n\u0002 {0}\nS\n{0}\nB] > 0, and therefore P \u03b7t \u2283 jB] > 0. Since 0\u2264s\u2264t \u03b7s is a.s. finite, we can choose a finite\nbut large enough \u2206 such that (4.2.36) holds.\nLemma 4.13 (Domination of finite configurations) For each B \u2208 Pfin (\u039b), t > 0, and\nAn \u2208 Pfin (\u039b) satisfying limn\u2192\u221e |An | = \u221e, one has\nlim P [\u2203i \u2208 \u039b s.t. \u03b7tAn \u2265 iB] = 1.\n\nn\u2192\u221e\n\n(4.2.37)\n\nProof Let \u2206, j, and \u03b5 be as in Lemma 4.12. We can find \u00c3n \u2282 An such that |\u00c3n | \u2192 \u221e as\nn \u2192 \u221e, and for fixed n, the sets (k\u2206)k\u2208\u00c3n are disjoint. It follows that\nP [\u2203i \u2208 \u039b s.t. \u03b7tAn \u2265 iB]\nY\n\u0003\u0001\n\u0002 {k}\n\u22651\u2212\n1 \u2212 P \u03b7t \u2283 kjB and \u03b7s{k} \u2282 k\u2206 \u22000 \u2264 s \u2264 t\nk\u2208\u00c3n\n\n= 1 \u2212 (1 \u2212 \u03b5)|\u00c3n | \u2212\u2192 1,\nn\u2192\u221e\n\n(4.2.38)\n\n\f160\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nwhere we have used (4.2.36) and the fact that events concerning the graphical representation\nin disjoint parts of space are independent.\nProof of Lemma 4.9 If \u03b4 = 0, then obviously limt\u2192\u221e |\u03b7tA | = \u221e a.s. If \u03b4 > 0, then it is easy\nto see that inf{\u03c1(A) : |A| \u2264 M } < 1 for all M < \u221e. Therefore, by (4.1.40),\n\u03b7tA = \u2205 for some t \u2265 0 or\n\n|\u03b7tA | \u2212\u2192 \u221e\nt\u2192\u221e\n\na.s.\n\n(4.2.39)\n\nFix \u2205 =\n6 B \u2208 Pfin (\u039b) and set \u03c8t (A) := P [\u2203i \u2208 \u039b s.t. \u03b7tA \u2265 iB] (A \u2208 Pfin (\u039b), t \u2265 0). Then,\nfor each t > 0,\nlim P [\u2203i \u2208 \u039b s.t. \u03b7TA \u2283 iB] = lim E[\u03c8t (\u03b7TA\u2212t )] = \u03c1(A),\n\nT \u2192\u221e\n\nT \u2192\u221e\n\n(4.2.40)\n\nwhere we have used Lemma 4.13 and (4.2.39).\n\n4.2.7\n\nGeneralization to arbitrary initial states\n\nIn this section, we show how the proof of Theorem 4.3 (a) must be adapted to cover general\ninitial states \u2205 =\n6 A \u2208 P(\u039b).\nProof of Theorem 4.3 (a) for general initial states For A, B \u2208 Pfin (\u039b) with A 6= \u2205, we\nobserve that i \u2208 BA\u22121 \u21d4 B \u2229 iA 6= \u2205, and therefore\n|BA\u22121 | =\n\nX\ni\n\n1{B \u2229 iA 6= \u2205} .\n\n(4.2.41)\n\nWe define\n\u03c0A,\u03bb (B) :=\n\nZ\n\n\u221e\n0\n\n\u0002\n\u0003\n\u03c0A,\u03bb (B)\nE |\u03b7t A\u22121 | e\u2212\u03bbt dt and \u03c0 A,\u03bb (B) :=\n,\n\u03c0A,\u03bb ({0})\n\n(4.2.42)\n\n\u2020\nand let \u03c0A,\u03bb\nand \u03c0 \u2020A,\u03bb denote the analogues of \u03c0A,\u03bb and \u03c0 A,\u03bb for the (\u039b, a\u2020 , \u03b4)-contact process.\nGeneralizing the proof of Lemma 4.6 (a), we find that\n\n\u0002\n\u0003\nP\u0302\u03bbA B \u2229 \u03b9\u22121 \u03b7\u03c4A = \u2205 = \u03c0 \u2020A,\u03bb (B \u222a {0}) \u2212 \u03c0 \u2020A,\u03bb (B).\n\n(4.2.43)\n\nSince |B| \u2264 |BA\u22121 | \u2264 |A| |B| for any A, B \u2208 Pfin (\u039b) with A 6= \u2205, it follows that\n1\nt\u2192\u221e t\n\nlim\n\n\u0002\n\u0003\nlog E |\u03b7tB A\u22121 | = r\n\n(\u2205 =\n6 B \u2208 Pfin (\u039b)),\n\n(4.2.44)\n\nwhere r is the exponential growth rate from Proposition 4.1. The proofs of (4.1.29) and\nLemma 4.7 now carry over to the functions (\u03c0 A,\u03bb )\u03bb>r without a change, and therefore the\narguments in Section 4.1.4 show that Theorem 4.3 (a) holds for general initial states \u2205 =\n6 A\u2208\nP(\u039b).\n\n\f161\n\n4.3. PROOFS OF FURTHER RESULTS\n\n4.3\n\nProofs of further results\n\nRecall that \u03c9 = (\u03c9 r , \u03c9 i ) is the pair of Poisson point processes used in the graphical representation. We construct \u03c9 on the canonical probability space \u03a9 := Ploc (\u039b \u00d7 R) \u00d7 Ploc (\u039b \u00d7 \u039b \u00d7 R),\nwhere Ploc (\u039b \u00d7 R) and Ploc (\u039b \u00d7 \u039b \u00d7 R) denote the spaces of locally finite subsets of \u039b \u00d7 R\nand \u039b \u00d7 \u039b \u00d7 R, respectively. These spaces can in a natural way be identified with subspaces\nof the spaces of locally finite counting measures on \u039b \u00d7 R and \u039b \u00d7 \u039b \u00d7 R, respectively. Using this identification, we equip Ploc (\u039b \u00d7 R) and Ploc (\u039b \u00d7 \u039b \u00d7 R) with the vague topology.\nWe equip \u03a9 with the product topology and the associated Borel-\u03c3-field F, and let P be the\nprobability measure on (\u03a9, F) such that under P , the coordinate functions \u03c9 r , \u03c9 i are Poisson\npoint processes as described in the introduction.\nWe equip \u039b\u00d7R and \u039b\u00d7\u039b\u00d7R with a group structure by putting (i, s)(j, t) := (ij, s+t) and\n(i, j, s)(k, l, t) := (ik, jl, s + t), respectively. In line with our earlier notation, for any subset\n\u03b1 \u2282 \u039b \u00d7 R, we write (i, s)\u03b1 := {(ij, s + t) : (j, t) \u2208 \u03b1}. For \u03b2 \u2282 \u039b \u00d7 \u039b \u00d7 R, we define (i, j, s)\u03b2\nanalogously. We define shift operators \u03b8i,t : \u03a9 \u2192 \u03a9 by\n\u03b8i,t (\u03b1, \u03b2) := ((i, t)\u03b1, (i, i, t)\u03b2)\n\n(4.3.1)\n\n(i \u2208 \u039b, t \u2208 R, (\u03b1, \u03b2) \u2208 \u03a9). Thus, \u03b8i,t shifts a graphical representation by left-multiplication\nwith i and increasing all times by t.\n\n4.3.1\n\nConditioning and size-biasing\n\nIn this section, we prove that size-biasing and conditioning on survival are asymptotically\nequivalent in a 'local' sense. Let\n\u0001\n\u03c9t := (\u03c9 r \u2229 \u039b \u00d7 (\u2212\u221e, t] , \u03c9 i \u2229 \u039b \u00d7 \u039b \u00d7 (\u2212\u221e, t]\n(4.3.2)\n\ndenote the restriction of the Poisson point processes used in the graphical representation to\nthe time interval (\u2212\u221e, t].\nProposition 4.14 (Conditioning and size-biasing) Assume that the (\u039b, a, \u03b4)-contact process survives and that the exponential growth rate satisfies r(\u039b, a, \u03b4) = 0. Then, for any\n\u2205=\n6 A \u2208 Pfin (\u039b),\n\u0002\n\u0003\n\u0002\n\u0003\nP\u0302\u03bbA \u03c9t \u2208 * \u2212\u2192 P \u03c9t \u2208 * A \u00d7 {0}\n\u221e\n(t \u2208 R).\n(4.3.3)\n\u03bb\u21930\n\nProof It suffices to prove the claims for t > 0. For any A \u2208 F, write\n\u0002\n\u0003\n\u0002\n\u0002\n\u0003\n\u0002\n\u0003\nP\u0302\u03bbA \u03c9t \u2208 A = P\u0302\u03bbA \u03c9t \u2208 A \u03c4 \u2265 t] P\u0302\u03bbA \u03c4 \u2265 t + P\u0302\u03bbA \u03c9t \u2208 A, \u03c4 < t ,\n\n(4.3.4)\n\nand observe that\nP\u0302\u03bbA\n\n\u0002\n\n=\n\n\u03c9t \u2208 A \u03c4 \u2265 t] =\n\nR\u221e\n\nE[\u03c0\u03bb (\u03b7tA )1{\u03c9t \u2208A} ]\nE[\u03c0\u03bb (\u03b7tA )]\n\n0\n\nR\u221e\nA | | \u03c9 ]e\u2212\u03bbs ds1\nA |1\n\u2212\u03bbs ds\nE[ 0 E[|\u03b7t+s\nE[|\u03b7t+s\nt\n{\u03c9t \u2208A} ]\n{\u03c9t \u2208A} ]e\nR\u221e\nR\n=\n\u221e\nA\nA\n\u2212\u03bbs\n\u2212\u03bbs\nds\nE[ 0 E[|\u03b7t+s | | \u03c9t ]e\nds]\n0 E[|\u03b7t+s |]e\n\n=\n\nE[\u03c0 \u03bb (\u03b7tA )1{\u03c9t \u2208A} ]\nE[\u03c0 \u03bb (\u03b7tA )]\n\n\u2212\u2192\n\u03bb\u21930\n\nE[\u03c1(\u03b7tA )1{\u03c9t \u2208A} ]\nE[\u03c1(\u03b7tA )]\n\n,\n\n(4.3.5)\n\n\f162\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nwhere we have used that \u03c0 \u03bb \u2192 \u03c1 pointwise as \u03bb \u2193 0 by Lemma 4.7 and Proposition 4.8, and\nbounded convergence, using the uniform bound \u03c0\u03bb \u2264 | * |. Since\nE[\u03c1(\u03b7tA )1{\u03c9t \u2208A} ]\n\n=\n\nE[\u03c1(\u03b7tA )1{\u03c9t \u2208A} ]\n\nE[\u03c1(\u03b7tA )]\nE[\u03c1(\u03b7tA )]\n\u0002\nE[P [A \u00d7 {0}\n\u221e | \u03c9t ]1{\u03c9t \u2208A} ]\n= P \u03c9t \u2208 A A \u00d7 {0}\n=\nE[P [A \u00d7 {0}\n\u221e | \u03c9t ]]\n\nformula (4.3.3) follows from Lemma 4.2, (4.3.4), and (4.3.5).\n\n4.3.2\n\n(4.3.6)\n\u0003\n\n\u221e ,\n\nCoupling to the maximal process\n\nIn this section we prove Theorem 4.3 (b) and Proposition 4.4. In analogy with (4.1.14), we\nput\nP\u0302\u03bb\u2020 A ({i} \u00d7 {d\u03c9} \u00d7 {dt}) := \u03c0\u03bb\u2020 (A)\u22121 1\nP (d\u03c9)e\u2212\u03bbt dt,\n(4.3.7)\n{i \u2208 \u03b7t\u2020 A (\u03c9)}\n\nwhich is well-defined for any \u2205 =\n6 A \u2208 Pfin (\u039b) and \u03bb > r. Recall that \u03b7\u03c4\u2020 A = {i \u2208 \u039b : (i, \u2212\u03c4 )\nA \u00d7 {0}}. We can view \u03b7t\u2020 A as the set of all 'ancestors' at time \u2212t of the set A at time 0.\nAs before, let \u03b9 and \u03c4 denote the projections on \u039b and R+ , respectively. Then, under the law\nP\u0302\u03bb\u2020 A , the random variables \u03b9 and \u03c4 describe a 'typical' ancestor of A and a 'typical' time \u2212\u03c4 .\nIn the next lemma, we shift the graphical representation \u03c9 in such a way that the 'typical'\n{0}\ninfected site and time (\u03b9, \u03c4 ), chosen with respect to P\u0302\u03bb , are mapped to the point (0, 0). Note\nthat under such a shift, the origin is mapped to \u03b9\u22121 . Thus, the next lemma can be described\nby saying that if we start the contact process with only the origin infected, then seen from a\ntypical infected site, the origin is a typical ancestor.\nLemma 4.15 (Origin seen from a typical infected site) Assume that r(\u039b, a, \u03b4) \u2264 0.\nThen\n\u0003\n\u0003\n\u2020 {0} \u0002\n{0} \u0002\n(\u03b9, \u03c9, \u03c4 ) \u2208 * .\n(4.3.8)\nP\u0302\u03bb (\u03b9\u22121 , \u03b8\u03b9\u22121 ,\u2212\u03c4 \u03c9, \u03c4 ) \u2208 * = P\u0302\u03bb\n\u03c9\n\nProof Let us write (i, s)\n(j, t) when (i, s) can be connected to (j, t) along a path in the\ngraphical representation \u03c9. Then\n\u0003\n\u0003\n{0} \u0002\n= j, \u03b8\u03b9\u22121 ,\u2212\u03c4 \u03c9 \u2208 A, \u03c4 \u2208 (a, b) = P\u0302\u03bb \u03b9 = j \u22121 , \u03b8\u03b9\u22121 ,\u2212\u03c4 \u03c9 \u2208 A, \u03c4 \u2208 (a, b)\nZ b\n\u0003\n\u0002\n{0}\n= \u03c0\u03bb ({0})\u22121\nP j \u22121 \u2208 \u03b7t , \u03b8j,\u2212t\u03c9 \u2208 A e\u2212\u03bbt dt\nZa b\n\u0002\n\u0003\n\u03c9\n\u22121\n= \u03c0\u03bb ({0})\nP (0, 0)\n(j \u22121 , t), \u03b8j,\u2212t\u03c9 \u2208 A e\u2212\u03bbt dt\nZa b\n\u0002\n\u0003\n\u03b8j,\u2212t \u03c9\n= \u03c0\u03bb ({0})\u22121\nP (j, \u2212t)\n(0, 0), \u03b8j,\u2212t \u03c9 \u2208 A e\u2212\u03bbt dt\nZa b\n\u0002\n\u0003\n\u03c9\n\u22121\n= \u03c0\u03bb ({0})\nP (j, \u2212t)\n(0, 0), \u03c9 \u2208 A e\u2212\u03bbt dt\nZa b\n\u0003\n\u0003\n\u0002\n\u2020 {0} \u0002\n\u2020 {0}\n\u2020\n\u22121\n\u03b9 = j, \u03c9 \u2208 A, \u03c4 \u2208 (a, b) ,\n= \u03c0\u03bb ({0})\nP j \u2208 \u03b7t , \u03c9 \u2208 A e\u2212\u03bbt dt = P\u0302\u03bb\n\n{0} \u0002 \u22121\n\nP\u0302\u03bb\n\n\u03b9\n\na\n\n(4.3.9)\n\n\f163\n\n4.3. PROOFS OF FURTHER RESULTS\nwhere we have used (4.2.14).\nIn order to prove Theorem 4.3 (b), we need two more lemmas.\n\nLemma 4.16 (Large populations) Assume that the (\u039b, a, \u03b4)-contact process survives and\nthat the exponential growth rate satisfies r(\u039b, a, \u03b4) \u2264 0. Then, for any \u2205 =\n6 A \u2208 Pfin (\u039b),\n\u0002\n\u0003\nP\u0302\u03bbA |\u03b7\u03c4A | \u2265 K \u2212\u2192 1\n(K < \u221e).\n(4.3.10)\n\u03bb\u21930\n\nProof Let \u03c4\u03bb be an exponentially distributed reandom variable with mean 1/\u03bb, independent\nof the Poisson processes used in the graphical representation. Then\n\u0003\n\u0002\nE |\u03b7\u03c4A\u03bb |1 A\n\u0002\n\u0003\n|\n\u2265\nK}\n{|\u03b7\n\u0002 \u03c4\u03bb \u0003\nP\u0302\u03bbA |\u03b7\u03c4A | \u2265 K =\nA\nE\n\u0003\n\u0002 A |\u03b7\u03c4\u03bb |\n\u03b7 A 6= \u2205\nE |\u03b7\u03c4\u03bb |1 A\n\u0003\n\u0002\n{|\u03b7\u03c4\u03bb | \u2265 K} \u03c4\u03bb\nA\n\u0002\n\u0003\n=\n=\n6\n\u2205\n\u2212\u2192 1,\n\u03b7\n\u2265\nE\n1\nA\n\u03c4\n\u03bb\n{|\u03b7\u03c4\u03bb | \u2265 K}\n\u03bb\u21930\nE |\u03b7\u03c4A\u03bb | \u03b7\u03c4A\u03bb 6= \u2205\n(4.3.11)\nwhere we have used (4.2.39), and the fact that |\u03b7\u03c4A\u03bb | and 1{\u03b7\u03c4A \u2265K} are positively correlated\n\u03bb\nsince the functions z 7\u2192 z and z 7\u2192 1{z\u2265K} are nondecreasing.\nRecall that in the proof (in Section 4.1.4) of Proposition 4.8, sequences An \u2208 Pfin (\u039b) such\nthat \u03c1(An ) \u2192 1 played an important role. Although we did not need this fact there, the next\nlemma implies that for \u03b4 > 0, actually \u03c1(An ) \u2192 1 if and only if |An | \u2192 \u221e.\nLemma 4.17 (High survival probabilities) Assume that the (\u039b, a, \u03b4)-contact process survives, and An \u2208 Pfin (\u039b). Then |An | \u2192 \u221e implies \u03c1(An ) \u2192 1.\nProof By (4.1.40) there exist Bm \u2208 Pfin (\u039b) with \u03c1(Bm ) \u2192 1. Now if An \u2208 Pfin (\u039b) satisfy\n|An | \u2192 \u221e, then by Lemma 4.13,\nlim inf \u03c1(An )\nn\u2192\u221e\n\n\u0003\n\u0003 \u0002\n\u0002\n\u2265 lim inf P \u03b7sAn 6= \u2205 \u2200s \u2265 t \u2203i \u2208 \u039b s.t. \u03b7tAn \u2265 iBm P \u2203i \u2208 \u039b s.t. \u03b7tAn \u2265 iBm\nn\u2192\u221e\n\n(4.3.12)\n\n\u2265 \u03c1(Bm ),\n\nfor each t > 0 and m. Letting m \u2192 \u221e yields the claim.\nWe now first prove Theorem 4.3 (b) in the case A = {0}, and then indicate how the arguments\nmay be generalised to \u2205 =\n6 A \u2208 Pfin (\u039b). We will obtain Proposition 4.4 as a corollary to our\nproofs in the case A = {0}.\nProof of Theorem 4.3 (b) in the case A = {0} By Lemma 4.15, we must show that\nfor fixed \u2206 \u2208 Pfin , the sets {j \u2208 \u2206 : (\u03b9, \u2212\u03c4 )\n(j, 0)}, {j \u2208 \u2206 : \u2212\u221e\n(j, 0)}, and\n\u2020 {0}\n{j \u2208 \u2206 : \u039b \u00d7 {\u2212\u03c4 }\n(j, 0)} are asymptotically equal under the laws P\u0302\u03bb\nas \u03bb \u2193 0. It suffices\nto show that for any j \u2208 \u039b,\n\u0003\n\u2020 {0} \u0002\n(\u03b9, \u2212\u03c4 )\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n(j, 0) \u2212\u2192 1.\n(4.3.13)\nP\u0302\u03bb\n\u03bb\u21930\n\n\f164\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nand\n\n\u2020 {0} \u0002\n\nP\u0302\u03bb\n\n\u2212\u221e\n\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n\n\u0003\n(j, 0) \u2212\u2192 1.\n\u03bb\u21930\n\n(4.3.14)\n\nReversing the direction of time and interchanging the roles of \u03b7 and \u03b7 \u2020 , this then yields\nProposition 4.4 as a corollary.\nFor any t > 0, by Proposition 4.14,\n\u0003\n\u0003\n\u2020 {0} \u0002 \u2020 {j}\n\u2020 {0} \u0002\n\u03b7\u03c4\n6= \u2205\n\u039b \u00d7 {\u2212\u03c4 }\n(j, 0) = P\u0302\u03bb\nP\u0302\u03bb\n\u0003\n\u0002 \u2020 {j}\n\u0003\n\u0003\n(4.3.15)\n\u2020 {0} \u0002\n\u2020 {0} \u0002 \u2020 {j}\n6= \u2205 \u2212 \u221e\n\u03c4 < t \u2212\u2192 P \u03b7t\n(0, 0) .\n6= \u2205 + P\u0302\u03bb\n\u03b7t\n\u2264 P\u0302\u03bb\n\u03bb\u21930\n\nLetting t \u2192 \u221e yields\n\u2020 {0} \u0002\nlim sup P\u0302\u03bb\n\u039b \u00d7 {\u2212\u03c4 }\n\u03bb\u21930\n\n\u0003\n\u0002\n(j, 0) \u2264 P \u2212 \u221e\n\n(j, 0) \u2212 \u221e\n\n\u0003\n(0, 0) =: \u03c6(j).\n\nBy Lemma 4.15 and Theorem 4.3 (a),\n\u0003\n\u0003\n\u0002\n\u0003\n\u2020 {0} \u0002\n{0} \u0002\nlim P\u0302\u03bb\n(\u03b9, \u2212\u03c4 )\n(j, 0) = lim P\u0302\u03bb j \u2208 \u03b9\u22121 \u03b7\u03c4{0} = P j \u2208 \u03b7 0 0 \u2208 \u03b7 0 = \u03c6(j).\n\u03bb\u21930\n\n\u03bb\u21930\n\n(4.3.16)\n\n(4.3.17)\n\nCombining (4.3.16) and (4.3.17) we arrive at (4.3.13).\n\u2020 {0}\nSince conditional on \u03b7\u03c4 , the typical site \u03b9 is chosen with equal probabilities from the\n\u2020 {0}\nsites in \u03b7\u03c4 ,\n\u2020 {0} \u0002\n\nP\u0302\u03bb\n\n(\u03b9, \u2212\u03c4 )\n\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n\nh \u2020 {j} \u2229 \u03b7 \u2020 {0} |\n\u0003\n\u03c4\n\u2020 {0} |\u03b7\u03c4\n(j, 0) = \u00ca\u03bb\n\u039b \u00d7 {\u2212\u03c4 }\n\u2020 {0}\n|\u03b7\u03c4 |\n\nTherefore, (4.3.13) and Lemma 4.16 imply that\n\u2020 {0} \u0002 \u2020 {j}\n|\u03b7\u03c4 | \u2265 K \u039b \u00d7 {\u2212\u03c4 }\nlim P\u0302\u03bb\n\u03bb\u21930\n\nwhich by Lemma 4.17 implies (4.3.14).\n\n\u0003\n(j, 0) = 1\n\n(K < \u221e),\n\ni\n(j, 0) .\n\n(4.3.18)\n\n(4.3.19)\n\nGeneralization to arbitrary initial states In analogy with (4.3.7), we define, for any\n\u2205=\n6 A, B \u2208 Pfin (\u039b),\n\u2020B\n\u2020\nP\u0302A,\u03bb\n({i} \u00d7 {d\u03c9} \u00d7 {dt}) := \u03c0A,\u03bb\n(B)\u22121 1 \u2020 B\nP (d\u03c9)e\u2212\u03bbt dt,\n{\u03b7t (\u03c9) \u2229 iA 6= \u2205}\n\n(4.3.20)\n\n\u2020\nwhere \u03c0A,\u03bb\n(B)\u22121 is defined below (4.2.42). Note that this is a probability measure by (4.2.41).\n\n\u2020B\nAs before, let \u03b9 denote the projection on \u039b. Then, under the law P\u0302A,\u03bb\n, the random variable\n\u03b9 describes a 'typical' site such that \u03b9A \u00d7 {\u2212\u03c4 }\nB \u00d7 {0}. By an obvious analogue of\nLemma 4.15, we must prove the following generalisations of (4.3.13) and (4.3.14):\n\u0003\n\u2020 {0} \u0002\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n(j, 0) \u2212\u2192 1,\n(i) P\u0302A,\u03bb \u03b9A \u00d7 {\u2212\u03c4 }\n\u03bb\u21930\n(4.3.21)\n\u0003\n\u2020 {0} \u0002\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n(j, 0) \u2212\u2192 1.\n(ii)\nP\u0302A,\u03bb \u2212 \u221e\n\u03bb\u21930\n\n\f165\n\n4.3. PROOFS OF FURTHER RESULTS\n\u2020 {0}\n\nDefine a measure P\u0303A,\u03bb on \u039b \u00d7 \u039b \u00d7 \u03a9 \u00d7 R+ by\ni\nh\n\u2020 {0}\n\u2020 {0}\n1{i} \u00d7 {d\u03c9} \u00d7 {dt} .\nP\u0303A,\u03bb ({k} \u00d7 {i} \u00d7 {d\u03c9} \u00d7 {dt}) := \u00caA,\u03bb |\u03b7\u03c4\u2020 {0} \u2229 iA|\u22121 1\n\u2020 {0}\n{k \u2208 \u03b7\u03c4\n\u2229 iA}\n(4.3.22)\nLet \u03ba, \u03b9 : \u039b \u00d7 \u039b \u00d7 \u03a9 \u00d7 R+ \u2192 \u039b denote the projections on the first and second coordinate,\n\u2020 {0}\nrespectively. Then, under the law P\u0303A,\u03bb , the random variable \u03ba describes a site chosen with\n\u2020 {0}\n\nequal probabilities from \u03b7\u03c4\n\n\u2229 \u03b9A. Therefore, in order to prove (4.3.21), it suffices to prove:\n\n\u2020 {0} \u0002\n(i) P\u0303A,\u03bb (\u03ba, \u2212\u03c4 )\n\u2020 {0} \u0002\n(ii) P\u0303A,\u03bb \u2212 \u221e\n\n\u0003\n(j, 0) \u2212\u2192 1,\n\u03bb\u21930\n\u0003\n(j, 0) \u2212\u2192 1.\n\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n(j, 0) \u039b \u00d7 {\u2212\u03c4 }\n\n(4.3.23)\n\n\u03bb\u21930\n\n\u2020 {0} \u0002\n\u2020 {0} \u0002\n(\u03b9, \u03c9, \u03c4 ) \u2208 * ] that\nWe claim that P\u0303A,\u03bb (\u03ba, \u03c9, \u03c4 ) \u2208 * ] has a density with respect to P\u0302\u03bb\nis uniformly bounded away from 0 and \u221e, and therefore (4.3.23) follows from (4.3.13) and\n(4.3.14). Indeed, by (4.3.20) and (4.3.22),\n\u2020 {0}\n\nP\u0303A,\u03bb ({k} \u00d7 \u039b \u00d7 {d\u03c9} \u00d7 {dt})\nX \u0002\n\u0003\n\u2020\nE |\u03b7\u03c4\u2020 {0} \u2229 iA|\u22121 1\n1 \u2020 {0}\n1{d\u03c9} e\u2212\u03bbt dt\n= \u03c0A,\u03bb\n({0})\u22121\n\u2020 {0}\n{k \u2208 \u03b7\u03c4\n\u2229 iA} {\u03b7\u03c4\n\u2229 iA 6= \u2205}\ni\u0002\n\u0002\n\u0003\n\u0003\n\u2020\n{0}\n\u2020\n\u2212\u03bbt\nZF (k)1{k} \u00d7 {d\u03c9} \u00d7 {dt} ,\n= Z\u03c0\u03bb ({0})\u22121 E F 1\ndt = \u00ca\u03bb\n\u2020 {0} 1{d\u03c9} e\n{k \u2208 \u03b7\u03c4 }\n(4.3.24)\n\u2020\nwhere Z := \u03c0\u03bb\u2020 ({0})/\u03c0A,\u03bb\n({0}) satisfies |A|\u22121 \u2264 Z \u2264 1 and\nF (k) :=\n\nX\ni\n\n|\u03b7\u03c4\u2020 {0} \u2229 iA|\u22121 1{k \u2208 iA} =\n\nX\n\ni\u2208kA\u22121\n\n|\u03b7\u03c4\u2020 {0} \u2229 iA|\u22121\n\n(4.3.25)\n\nsatisfies 1 \u2264 F (k) \u2264 |A|.\n\n4.3.3\n\nCoupling of one-dimensional processes\n\nProof of Lemma 4.5 For any point (i, s) such that (i, s)\nrs,t (i) := max{j \u2208 Z : (i, s)\n\n(j, t)\n\n\u221e, set\n\n\u221e}\n\n(t \u2265 s).\n\n(4.3.26)\n\nThen (rs,t (i))t\u2265s is the right-most path to infinity starting at (i, s). By symmetry and the\nnearest-neighbor property, it suffices to show that for any (i, s) and (j, s) such that (i, s)\n\u221e\nand (j, s)\n\u221e, there exists a t \u2265 s such that rs,t (i) = rs,t (j). Imagine that this is not the\ncase. Then, for any i \u2208 Z and s \u2264 t, the maximum\nRs,t (i) := max{j \u2208 Z : rt,u (j) = rs,u (i) for some u \u2265 t}\n\n(4.3.27)\n\nexists. Set\n\u03c7s := {i \u2208 Z : Rs,s (i) = i}\n\n(s \u2208 R).\n\n(4.3.28)\n\n\f166\n\nCHAPTER 4. THE CONTACT PROCESS SEEN FROM A TYPICAL SITE\n\nIt is not hard to see that Rs,t maps Z into \u03c7t and that Rs,t : \u03c7s \u2192 \u03c7t is one-to-one. We claim\nthat Rs,t : \u03c7s \u2192 \u03c7t is with positive probability not surjective if s < t. Indeed, since we are\nassuming that \u03b4 > 0 or a(0, 1) \u2227 a(1, 0) > 0, it is easy to see that with positive probability\nthere exist i, j, k \u2208 \u03c7t with i < j < k such that\nmax{i\u2032 \u2208 Z : (0, s)\n\n(i\u2032 , t)} = i\n\nand\n\nmax{k\u2032 \u2208 Z : (1, s)\n\n(k\u2032 , t)} = k.\n\n(4.3.29)\n\nIt follows that Rs,t (0) = i and Rs,t (1) = k, and therefore, since Rs,t is monotone, there is no\nn \u2208 Z with Rs,t (n) = j.\nThis 'obviously' violates stationarity. More formally, fix s < t and define f : Z \u00d7 Z \u2192 R\nby\nf (i, j) := P [i \u2208 \u03c7s , j \u2208 \u03c7t , j = Rs,t (i)].\n(4.3.30)\nThen\nX\nj\n\nf (0, j) = P [0 \u2208 \u03c7s , \u2203j \u2208 \u03c7t s.t. j = Rs,t (0)]\n\n= P [0 \u2208 \u03c7s ] > P [\u2203i \u2208 \u03c7s s.t. 0 \u2208 \u03c7t , 0 = Rs,t (i)] =\n\nP\n\nP\n\nX\n\nf (i, 0).\n\n(4.3.31)\n\ni\n\nP\n\nSince j f (0, j) = j f (\u2212j, 0) = i f (i, 0) (this equality is a special case of the mass transport principle; see [Hag97], [BLPS99, Section 3], or [LP05, Chapter 7]), we arrive at a contradiction.\n\n4.3.4\n\nSurvival on finitely generated groups\n\nIn this section we prove:\nLemma 4.18 (Survival for low recovery rates) If \u039b is finitely generated, then \u03b4c > 0.\nProof Let \u2206 be a finite generating set for \u039b. Since {i : a(0, i) > 0} generates \u039b, there exists\na finite subset A \u2282 {i : a(0, i) > 0} that generates \u2206, and thereby all of \u039b. Therefore, we can\nfind i0 , i1 , . . . \u2208 \u039b, all different, such that inf k\u22650 a(ik , ik+1 ) > 0. We will use comparison to\noriented site percolation to show that P ((i0 , 0)\n\u221e) > 0 if \u03b4 is sufficiently small. Fix T > 0.\n2\nCall a point (n, m) with n, m \u2208 N good if in the grapical representation, in the time interval\n[T m, T (m + 1)), there is an arrow from in to in+1 and there are no recoveries in in and in+1 .\nBy choosing T large enough and \u03b4 small enough, the probability that a point is good can be\nmade arbitrarily high, uniformly in n. If this probability is larger than the critical parameter\nfor independent 2-dimensional oriented site percolation, then with positive probability there\nis an upward path along good points, and therefore the contact process survives.\n\n\fBibliography\n[Apo69]\n\nT.M. Apostol. Calculus, Vol. II. Wiley, 1969.\n\n[AS05]\n\nS.R. Athreya and J.M. Swart. Branching-coalescing particle systems. Prob. Theory\nRelat. Fields. 131(3), 376\u2013414, 2005.\n\n[BCGH95] J.-B. Baillon, Ph. Cl\u00e9ment, A. Greven, and F. den Hollander. On the attracting\norbit of a non-linear transformation arising from renormalization of hierarchically\ninteracting diffusions. I. The compact case. Canad. J. Math. 47(1): 3\u201327, 1995.\n[BCGH97] J.-B. Baillon, Ph. Cl\u00e9ment, A. Greven, and F. den Hollander. On the attracting\norbit of a non-linear transformation arising from renormalization of hierarchically\ninteracting diffusions. II. The non-compact case. J. Funct. Anal. 146: 236\u2013298,\n1997.\n[BEM03]\n\nJ. Blath, A.M. Etheridge, and M.E. Meredith. Coexistence in locally regulated\ncompeting populations. University of Oxford, preprint, 2003.\n\n[BES04]\n\nN.H. Barton, A.M. Etheridge, and A.K. Sturm. Coalescence in a random background. Ann. Appl. Probab. 14(2), 754\u2013785, 2004.\n\n[BG85]\n\nC. Bennett and G. Grinstein. Role of irreversibility in stabilizing complex and\nnonergodic behavior in local interacting discrete systems. Phys. Rev. Lett. 55,\n657\u2013660, 1985.\n\n[BG90]\n\nC. Bezuidenhout and G. Grimmett. The critical contact process dies out. Ann.\nProbab. 18(4), 1462\u20131482, 1990.\n\n[BGN91]\n\nD.J. Barsky, G.R. Grimmett, and C.M. Newman. Percolation in half-spaces:\nEquality of critical densities and continuity of the percolation probability. Probab.\nTheory Relat. Fields 90(1), 111\u2013148, 1991.\n\n[BK89]\n\nR.M. Burton and M. Keane. Density and uniqueness in percolation. Commun.\nMath. Phys. 121, 501\u2013505, 1989.\n\n[BLPS99] I. Benjamini, R. Lyons, Y. Peres, O. Schramm. Group-invariant percolation on\ngraphs. Geom. Funct. Anal. 9(1), 29\u201366, 1999.\n[BS01]\n\nI. Benjamini and O. Schramm. Percolation in the hyperbolic plane. J. Am. Math.\nSoc. 14, 487\u2013507, 2001.\n167\n\n\f168\n\nBIBLIOGRAPHY\n\n[CDG04]\n\nJ.T. Cox, D.A. Dawson, and A. Greven. Mutually catalytic super branching random walks: Large finite systems and renormalization analysis. Mem. Am. Math.\nSoc. 809, 2004.\n\n[CFG96]\n\nJ.T. Cox, K. Fleischmann, and A. Greven. Comparison of interacting diffusions and\nan application to their ergodic theory. Probab. Theory Relat. Fields 105, 513\u2013528,\n1996.\n\n[CG86]\n\nJ.T. Cox and D. Griffeath. Diffusive clustering in the two dimensional voter model.\nAnn. Probab. 14(2), 347\u2013370, 1986.\n\n[CG94]\n\nJ.T. Cox and A. Greven. Ergodic theorems for infinite systems of locally interacting\ndiffusions. Ann. Probab. 22(2), 833\u2013853, 1994.\n\n[Che87]\n\nM.F. Chen. Existence theorems for interacting particle systems with non-compact\nstate space. Sci. China Ser. A 30, 148\u2013156, 1987.\n\n[Daw77]\n\nD.A. Dawson. The critical measure diffusion process. Z. Wahrscheinlichkeitstheor.\nVerw. Geb. 40, 125\u2013145, 1977.\n\n[Daw93]\n\nD.A. Dawson. Measure-valued Markov processes. Ecole d'Et de probabilits de SaintFlour XXI. Lect. Notes Math. 1541, 1-260, Springer, Berlin, 1993.\n\n[DDL90]\n\nW. Ding, R. Durrett, and T.M. Liggett. Ergodicity of reversible reaction diffusion\nprocesses. Probab. Theory Relat. Fields 85(1), 13\u201326, 1990.\n\n[DE68]\n\nD.A. Darling and P. Erd\u0151s. On the recurrence of a certain chain. Proc. Am. Math.\nSoc. 19(1): 336-338, 1968.\n\n[DEFMPX02a] D.A. Dawson, A. Etheridge, K. Fleischmann, L. Mytnik, E.A. Perkins, and\nJ. Xiong. Mutually catalytic branching in the plane: Finite measure states. Ann.\nProbab. 30(4), 1681\u20131762, 2002.\n[DEFMPX02b] D.A. Dawson, A. Etheridge, K. Fleischmann, L. Mytnik, E.A. Perkins, and\nJ. Xiong. Mutually catalytic branching in the plane: Infinite measure states. Electron. J. Probab. 7, paper no. 15, 61 pp., 2002.\n[Deu89]\n\nJ.-D. Deuschel. Invariance principle and empirical mean large deviations of the\ncritical Ornstein-Uhlenbeck process. Ann. Probab. 17(1), 74\u201390, 1989.\n\n[DF97a]\n\nD.A. Dawson and K. Fleischmann. A continuous super-Brownian motion in a\nsuper-Brownian medium. J. Theoret. Probab. 10(1), 213\u2013276, 1997.\n\n[DF97b]\n\nD.A. Dawson and K. Fleischmann. Longtime behavior of a branching process controlled by branching catalysts. Stoch. Process. Appl. 71(2), 241\u2013257, 1997.\n\n[DF02]\n\nD.A. Dawson and K. Fleischmann. Catalytic and mutually catalytic superBrownian motions In R.C. Dalang (ed.) Seminar on stochastic analysis, random\nfields and applications III. Proceedings of the 3rd seminar, Ascona, Switzerland,\nSeptember 20-24, 1999. Prog. Probab. 52, 89\u2013110, Birkh\u00e4user, Basel, 2002.\n\n\fBIBLIOGRAPHY\n\n169\n\n[DFMPX03] D.A. Dawson, K. Fleischmann, L. Mytnik, E.A. Perkins, and J. Xiong. Mutually\ncatalytic branching in the plane: Uniqueness. Ann. Inst. Henri Poincar, Probab.\nStat. 39(1), 135\u2013191, 2003.\n[DG93a]\n\nD.A. Dawson and A. Greven. Hierarchical models of interacting diffusions: Multiple time scale phenomena, phase transition and pattern of cluster-formation.\nProbab. Theory Related Fields 96(4): 435\u2013473, 1993.\n\n[DG93b]\n\nD.A. Dawson and A. Greven. Multiple time scale analysis of interacting diffusions.\nProbab. Theory Related Fields 95(4): 467\u2013508, 1993.\n\n[DG96]\n\nD.A. Dawson and A. Greven. Multiple space-time scale analysis for interacting\nbranching models. Electron. J. Probab. 1, paper no. 14, 84 pp., 1996.\n\n[DG99]\n\nD.A. Dawson and A. Greven. Hierarchically interacting Fleming-Viot processes\nwith selection and mutation: Multiple space time scale analysis and quasiequilibria. Electron. J. Probab. 4, Paper no. 4, 81 p., 1999.\n\n[DGV95]\n\nD.A. Dawson, A. Greven and J. Vaillancourt. Equilibria and quasi-equilibria for\ninfinite collections of interacting Fleming-Viot processes. Trans. Amer. Math.\nSoc. 347(7): 2277\u20132360, 1995.\n\n[DK96]\n\nP. Donnelly and T.G. Kurtz. A countable representation of the Fleming-Viot\nmeasure-valued diffusion. Ann. Probab. 24(2), 698\u2013742, 1996.\n\n[DK99]\n\nP. Donelly and T.G. Kurtz. Genealogical processes for Fleming-Viot models with\nselection and recombination. Ann. Appl. Probab. 9, 1091\u20131148, 1999.\n\n[DLSS91] B. Derrida, J.L. Lebowitz, E.R. Speer, and H. Spohn. Dynamics of an anchored\nToom interface. J. Phys. A: Math. Gen. 24, 4805\u20134834, 1991.\n[DP98]\n\nD.A. Dawson and E.A. Perkins. Long-time behavior and coexistence in a mutually\ncatalytic branching model. Ann. Probab. 26(3), 1088-1138, 1998.\n\n[DS95]\n\nR. Durrett and R. Schinazi. Intermediate phase for the contact process on a tree.\nAnn. Probab. 23(2), 668\u2013673, 1995.\n\n[Dyn02]\n\nE. Dynkin. Diffusions, superdiffusions and partial differential equations. Vol. 50 of\nAmerican Mathematical Society Colloquium Publications. AMS, Providence, RI,\n2002.\n\n[DZ98]\n\nA. Dembo and O. Zeitouni. Large Deviations Techniques and Applications. 2. ed.\nSpringer, New York, 1998.\n\n[EF98]\n\nA. Etheridge and K. Fleischmann. Persistence of a two-dimensional superBrownian motion in a catalytic medium. Probab. Theory Relat. Fields 110(1), 1\u201312,\n1998.\n\n\f170\n\nBIBLIOGRAPHY\n\n[EK86]\n\nS.N. Ethier and T.G. Kurtz. Markov Processes; Characterization and Convergence.\nJohn Wiley & Sons, New York, 1986.\n\n[EK04]\n\nJ. Engl\u00e4nder and A.E. Kyprianou. Local extinction versus local exponential growth\nfor spatial branching processes. Ann. Probab. 32(1A), 78\u201399, 2004.\n\n[EP99]\n\nJ. Engl\u00e4nder and R.G. Pinsky. On the construction and support properties of\nmeasure-valued diffusions on D \u2286 Rd with spatially dependent branching. Ann.\nProbab., 27(1): 684\u2013730, 1999.\n\n[ER91]\n\nN. El Karoui and S. Roelly. Propri\u00e9t\u00e9s de martingales, explosion et repr\u00e9sentation\nde L\u00e9vy- Khintchine d'une classe de processus de branchement \u00e0 valeurs mesures.\nStoch. Proc. Appl. 38(2): 239\u2013266, 1991.\n\n[ET02]\n\nJ. Engl\u00e4nder and D. Turaev. A scaling limit for a class of superdiffussions. Ann.\nProbab. 30(2), 683\u2013722, 2002.\n\n[Eth00]\n\nA. Etheridge. An Introduction to Superprocesses. University Lecture Series 20,\nAMS, Providence, 2000.\n\n[EU48]\n\nC.J. Everett and S. Ulam. Multiplicative systems in several variables, I. Los Alamos\nScientific Laboratory, LA-683, 1948.\n\n[Ewe04]\n\nW.J. Ewens. Mathematical Population Genetics. I: Theoretical Introduction. 2nd\ned. Interdisciplinary Mathematics 27. Springer, New York, 2004.\n\n[FG94]\n\nK. Fleischmann and A. Greven. Diffusive clustering in an infinite system of hierarchically interacting diffusions. Probab. Theory Relat. Fields 98(4), 517\u2013566,\n1994.\n\n[Fit88]\n\nP.J. Fitzsimmons. Construction and regularity of measure-valued branching processes. Isr. J. Math. 64(3): 337\u2013361, 1988.\n\n[Fit91]\n\nP.J. Fitzsimmons. Correction to \"Construction and regularity of measure-valued\nbranching processes\". Isr. J. Math., 73(1): 127, 1991.\n\n[Fit92]\n\nP.J. Fitzsimmons. On the martingale problem for measure-valued Markov branching processes. pp 39\u201351 in: Seminar on Stochastic Processes, 1991. Progress in\nProbability 29, Birkh\u00e4user, Boston, 1992.\n\n[FK99]\n\nK. Fleischmann and A. Klenke. Smooth density field of catalytic super-Brownian\nmotion. Ann. Appl. Probab. 9, 298\u2013318, 1999.\n\n[FS03]\n\nK. Fleischmann and J.M. Swart. Extinction versus exponential growth in a supercritical super-Wright-Fischer diffusion. Stoch. Proc. Appl. 106(1): 141\u2013165, 2003.\n\n[FS04]\n\nK. Fleischmann and J.M. Swart. Trimmed trees and embedded particle systems.\nAnn. Probab. 32(3a): 2179\u20132221, 2004.\n\n\fBIBLIOGRAPHY\n[GH02]\n\n171\n\nG. Grimmett and P. Hiemer. Directed percolation and random walk. Pages 273\u2013297\nin: V. Sidoravicius (ed.), In and Out of Equilibrium. Prog. Probab. 51. Birkh\u00e4user,\nBoston, 2002\n\n[GKW99] A. Greven, A. Klenke, and A. Wakolbinger. The longtime behavior of branching\nrandom walk in a catalytic medium. Electron. J. Probab. 4, paper no. 12, 80 pp.,\n1999.\n[GKW01] A. Greven, A. Klenke, and A. Wakolbinger. Interacting Fisher-Wright diffusions\nin a catalytic medium. Probab. Theory Related Fields 120(1): 85\u2013117, 2001.\n[GLW05]\n\nA. Greven, V. Limic, and A. Winter. Representation theorems for interacting\nMoran models and interacting Fisher-Wright models, and applications. Electron.\nJ. Probab. 10, paper no. 39, 1286\u20131358, 2005.\n\n[GM90]\n\nG.R. Grimmett and J.M. Marstrand. The supercritical phase of percolation is well\nbehaved. Proc. R. Soc. Lond., Ser. A 430, no. 1879, 439\u2013457, 1990.\n\n[GW91]\n\nL.G. Gorostiza and A. Wakolbinger. Persistence criteria for a class of critical\nbranching particle systems in continuous time. Ann. Probab. 19(1), 266\u2013288, 1991.\n\n[Hag97]\n\nO. H\u00e4ggstr\u00f6m. Infinite clusters in dependent automorphism invariant percolation\non trees. Ann. Probab. 25(3), 1423\u20131436, 1997.\n\n[Har63]\n\nT.E. Harris. The theory of branching processes. Springer, Berlin, 1963.\n\n[Har76]\n\nT.E. Harris. On a class of set-valued Markov processes. Ann. Probab. 4, 175\u2013194,\n1976.\n\n[Har78]\n\nT.E. Harris. Additive set-valued Markov processes and graphical methods. Ann.\nProbab. 6, 355\u2013378, 1978.\n\n[HS98]\n\nF. den Hollander and J.M. Swart. Renormalization of hierarchically interacting\nisotropic diffusions. J. Stat. Phys. 93: 243\u2013291, 1998.\n\n[Jir64]\n\nM. Ji\u0159ina. Branching processes with measure-valued states. In Trans. Third Prague\nConf. Information Theory, Statist. Decision Functions, Random Processes (Liblice,\n1962), pages 333\u2013357, Czech. Acad. Sci., Prague, 1964.\n\n[Kal76]\n\nO. Kallenberg. Random Measures. Akademie-Verlag, Berlin, 1976.\n\n[Kal77]\n\nO. Kallenberg. Stability of critical cluster fields. Math. Nachr. 77, 7\u201343, 1977.\n\n[Kal83]\n\nO. Kallenberg. Random measures, 3rd rev. and enl. ed. Akademie-Verlag, Berlin,\n1983.\n\n[Kes86]\n\nH. Kesten. Aspects of first passage percolation. Pages 125\u2013264 in: P.L. Hennequin (ed.), \u00c9cole d'\u00e9t\u00e9 de probabilit\u00e9s de Saint-Flour XIV - 1984. Lect. Notes\nMath. 1180, Springer, Berlin, 1986.\n\n\f172\n\nBIBLIOGRAPHY\n\n[Kle96]\n\nA. Klenke. Different clustering regimes in systems of hierarchically interacting\ndiffusions. Ann. Probab. 24(2): 660\u2013697, 1996.\n\n[KN97]\n\nS.M. Krone and C. Neuhauser. Ancestral processes with selection. Theor. Popul.\nBiol. 51(3), 210\u2013237, 1997.\n\n[Kol33]\n\nA. Kolmogorov. Grundbegriffe der Wahrscheinlichkeitsrechnung. Ergebnisse der\nMathematik, 1933.\n\n[Law05]\n\nG.F. Lawler. Conformally Invariant Processes in the Plane. AMS, 2005.\n\n[Lie81]\n\nA. Liemant. Kritische Verzweigungsprozesse mit allgemeinem Phasenraum. IV.\nMath. Nachr. 102: 235\u2013254, 1981.\n\n[Lig85]\n\nT.M. Liggett. Interacting Particle Systems. Springer, New York, 1985.\n\n[Lig96]\n\nT.M. Liggett. Branching random walks and contact processes on homogeneous\ntrees. Probab. Theory Relat. Fields 106(4), 495\u2013519, 1996.\n\n[Lig99]\n\nT.M. Liggett. Stochastic Interacting Systems: Contact, Voter and Exclusion Process. Springer, Berlin, 1999.\n\n[Loe63]\n\nM. Lo\u00e8ve. Probability Theory 3rd ed. Van Nostrand, Princeton, 1963.\n\n[Loe78]\n\nM. Lo\u00e8ve. Probability Theory II 4th ed. Graduate Texts in Mathematics 46.\nSpringer, New York, 1978.\n\n[LP05]\n\nR. Lyons and Y. Peres. Probability on trees and networks. Draft available from\nhttp://mypage.iu.edu/ \u0303rdlyons/prbtree/prbtree.html, 2005.\n\n[LPP96]\n\nR. Lyons, R. Pemantle, and Y. Peres. Random walks on the lamplighter group.\nAnn. Probab. 24(4), 1993\u20132006, 1996.\n\n[LS81]\n\nT.M. Liggett and F. Spitzer. Ergodic theorems for coupled random walks and\nother systems with locally interacting components. Z. Wahrsch. verw. Gebiete 56,\n443\u2013468, 1981.\n\n[Mou92]\n\nT.S. Mountford. The ergodicity of a class of reversible reaction-diffusion processes.\nProbab. Theory Relat. Fields 92(2), 259\u2013274, 1992.\n\n[MT95]\n\nC. M\u00fcller and R. Tribe. Stochastic p.d.e.'s arising from the long range contact and\nlong range voter processes. Probab. Theory Relat. Fields 102(4), 519\u2013545, 1995.\n\n[MW89]\n\nB. Mohar and W. Woess. A survey on spectra of infinite graphs. Bull. Lond. Math.\nSoc. 21(3), 209\u2013234, 1989.\n\n[Neu90]\n\nC. Neuhauser. An ergodic theorem for Schl\u00f6gl models with small migration. Probab.\nTheory Relat. Fields 85(1), 27\u201332, 1990.\n\n\fBIBLIOGRAPHY\n\n173\n\n[NS80]\n\nM. Notohara and T. Shiga. Convergence to genetically uniform state in stepping\nstone models of population genetics. J. Math. Biology 10, 281\u2013294, 1980.\n\n[Pat88]\n\nA.L.T. Paterson. Amenability. AMS, Providence, 1988.\n\n[Paz83]\n\nA. Pazy. Semigroups of Linear Operators and Applications to Partial Differential\nEquations. Springer, New York, 1983.\n\n[Pem92]\n\nR. Pemantle. The contact process on trees. Ann. Probab. 20(4), 2089\u20132116, 1992.\n\n[Pen04]\n\nC. Penssel. Interacting Catalytic Feller Diffusions: Finite System Scheme and\nRenormalisation. Logos, Berlin, 2004.\n\n[Rev84]\n\nD. Revuz. Markov chains. 2nd rev. ed. North-Holland Mathematical Library,\nVol 11. North-Holland, Amsterdam, 1984.\n\n[RW87]\n\nL.C.G. Rogers and D. Williams. Diffusions, Markov Processes, and Martingales,\nVolume 2: Ito Calculus. Wiley, Chichester, 1987.\n\n[Sch72]\n\nF. Schl\u00f6gl. Chemical reaction models and non-equilibrium phase transitions.\nZ. Phys. 253, 147\u2013161, 1972.\n\n[Sch86]\n\nR.H. Schonmann. The asymmetric contact process. J. Stat. Phys. 44, 505\u2013534,\n1986.\n\n[Sch98]\n\nF. Schiller. Application of the Multiple Space-Time Scale Analysis on a System\nof R-valued, Hierarchically Interacting, Stochastic Differential Equations. Master\nthesis, Universtity Erlangen-N\u00fcrnberg, 1998.\n\n[SF83]\n\nS. Sawyer and J. Felsenstein. Isolation by distance in a hierarchically clustered\npopulation. J. Appl. Probab. 20: 1\u201310, 1983.\n\n[Sha88]\n\nM. Sharpe. General Theory of Markov Processes. Academic Press, Boston, 1988.\n\n[Shi80a]\n\nT. Shiga. An interacting system in population genetics. J. Math. Kyoto Univ.\n20(2), 213\u2013242, 1980.\n\n[Shi80b]\n\nT. Shiga. An interacting system in population genetics, II. J. Math. Kyoto\nUniv. 20(4), 723\u2013733, 1980.\n\n[Shi81]\n\nT. Shiga. Diffusion processes in population genetics. J. Math. Kyoto Univ. 21,\n133\u2013151, 1981.\n\n[Shi92]\n\nT. Shiga. Ergodic theorems and exponential decay of sample paths for certain\ninteracting diffusion systems. Osaka J. Math. 29, 789\u2013807, 1992.\n\n[Smo83]\n\nJ. Smoller. Shock Waves and Reaction-diffusion Equations. Vol. 258 of Grundlehren\nMath. Wiss., Springer, New York, 1983.\n\n\f174\n\nBIBLIOGRAPHY\n\n[SS80]\n\nT. Shiga and A. Shimizu. Infinite dimensional stochastic differential equations and\ntheir applications. J. Math. Kyoto Univ. 20, 395\u2013416, 1980.\n\n[SS97]\n\nM. Salzano and R.H. Schonmann. The second lowest extremal invariant measure\nof the contact process. Ann. Probab. 25(4), 1846\u20131871, 1997.\n\n[SS99]\n\nM. Salzano and R.H. Schonmann. The second lowest extremal invariant measure\nof the contact process. II. Ann. Probab. 27(2), 845\u2013875, 1999.\n\n[Sta96]\n\nA.M. Stacey. The existence of an intermediate phase for the contact process on\ntrees. Ann. Probab. 24(4), 1711\u20131726, 1996.\n\n[SU86]\n\nT. Shiga and K. Uchiyama. Stationary states and their stability of the stepping\nstone model involving mutation and selection. Probab. Theory Relat. Fields 73,\n87\u2013117, 1986.\n\n[Swa99]\n\nJ.M. Swart. Large Space-Time Scale Behavior of Linearly Interacting Diffusions.\nPhD thesis, Katholieke Universiteit Nijmegen, 1999. http://helikon.ubn.kun.nl/\nmono/s/swart /largspscb.pdf.\n\n[Swa00]\n\nJ.M. Swart. Clustering of linearly interacting diffusions and universality of their\nlong-time limit distribution. Prob. Theory Related Fields 118: 574\u2013594, 2000.\n\n[WG74]\n\nH.W. Watson and F. Galton. On the probability of the extinction of families. J.\nAnthropol. Inst. Great Britain and Ireland 4, 138\u2013144, 1874.\n\n[WK74]\n\nK.G. Wilson and J. Kogut. The renormalization group and the \u03b5-expansion. Phys.\nRep. 12C, 75\u2013200, 1974.\n\n[YW71]\n\nT. Yamada and S. Watanabe. On the uniqueness of solutions of stochastic differential equations. J. Math. Kyoto Univ. 11: 155\u2013167, 1971.\n\n\f"}