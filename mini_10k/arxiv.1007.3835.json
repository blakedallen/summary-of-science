{"id": "http://arxiv.org/abs/1007.3835v1", "guidislink": true, "updated": "2010-07-22T09:28:10Z", "updated_parsed": [2010, 7, 22, 9, 28, 10, 3, 203, 0], "published": "2010-07-22T09:28:10Z", "published_parsed": [2010, 7, 22, 9, 28, 10, 3, 203, 0], "title": "Applying Prolog to Develop Distributed Systems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.3231%2C0810.5549%2C0810.4855%2C0810.0469%2C0810.5553%2C0810.1765%2C0810.2673%2C0810.5300%2C0810.0268%2C0810.1490%2C0810.4878%2C0810.0443%2C0810.3900%2C0810.2507%2C0810.2605%2C0810.4744%2C0810.1240%2C0810.0921%2C0810.4391%2C0810.4137%2C0810.0441%2C0810.1444%2C0810.4050%2C0810.1507%2C0810.0723%2C0810.0754%2C0810.3608%2C0810.5560%2C0810.4130%2C0810.5376%2C0810.1024%2C0810.2879%2C0810.1679%2C1007.2580%2C1007.5471%2C1007.1020%2C1007.4130%2C1007.0403%2C1007.2206%2C1007.4757%2C1007.1258%2C1007.0308%2C1007.2153%2C1007.0234%2C1007.5435%2C1007.5305%2C1007.3355%2C1007.3627%2C1007.1715%2C1007.0263%2C1007.4613%2C1007.5135%2C1007.0562%2C1007.5467%2C1007.2517%2C1007.2196%2C1007.3003%2C1007.5439%2C1007.4057%2C1007.4212%2C1007.3200%2C1007.3835%2C1007.3861%2C1007.3011%2C1007.0736%2C1007.2809%2C1007.0575%2C1007.1963%2C1007.1421%2C1007.1666%2C1007.2022%2C1007.0081%2C1007.4948%2C1007.1422%2C1007.3595%2C1007.2275%2C1007.4515%2C1007.2362%2C1007.1657%2C1007.2005%2C1007.2283%2C1007.4907%2C1007.2084%2C1007.2080%2C1007.4943%2C1007.4368%2C1007.1151%2C1007.0922%2C1007.0047%2C1007.2703%2C1007.2759%2C1007.4730%2C1007.5429%2C1007.1248%2C1007.1895%2C1007.4029%2C1007.0874%2C1007.2618%2C1007.4595%2C1007.1306%2C1007.2015&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Applying Prolog to Develop Distributed Systems"}, "summary": "Development of distributed systems is a difficult task. Declarative\nprogramming techniques hold a promising potential for effectively supporting\nprogrammer in this challenge. While Datalog-based languages have been actively\nexplored for programming distributed systems, Prolog received relatively little\nattention in this application area so far. In this paper we present a\nProlog-based programming system, called DAHL, for the declarative development\nof distributed systems. DAHL extends Prolog with an event-driven control\nmechanism and built-in networking procedures. Our experimental evaluation using\na distributed hash-table data structure, a protocol for achieving Byzantine\nfault tolerance, and a distributed software model checker - all implemented in\nDAHL - indicates the viability of the approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.3231%2C0810.5549%2C0810.4855%2C0810.0469%2C0810.5553%2C0810.1765%2C0810.2673%2C0810.5300%2C0810.0268%2C0810.1490%2C0810.4878%2C0810.0443%2C0810.3900%2C0810.2507%2C0810.2605%2C0810.4744%2C0810.1240%2C0810.0921%2C0810.4391%2C0810.4137%2C0810.0441%2C0810.1444%2C0810.4050%2C0810.1507%2C0810.0723%2C0810.0754%2C0810.3608%2C0810.5560%2C0810.4130%2C0810.5376%2C0810.1024%2C0810.2879%2C0810.1679%2C1007.2580%2C1007.5471%2C1007.1020%2C1007.4130%2C1007.0403%2C1007.2206%2C1007.4757%2C1007.1258%2C1007.0308%2C1007.2153%2C1007.0234%2C1007.5435%2C1007.5305%2C1007.3355%2C1007.3627%2C1007.1715%2C1007.0263%2C1007.4613%2C1007.5135%2C1007.0562%2C1007.5467%2C1007.2517%2C1007.2196%2C1007.3003%2C1007.5439%2C1007.4057%2C1007.4212%2C1007.3200%2C1007.3835%2C1007.3861%2C1007.3011%2C1007.0736%2C1007.2809%2C1007.0575%2C1007.1963%2C1007.1421%2C1007.1666%2C1007.2022%2C1007.0081%2C1007.4948%2C1007.1422%2C1007.3595%2C1007.2275%2C1007.4515%2C1007.2362%2C1007.1657%2C1007.2005%2C1007.2283%2C1007.4907%2C1007.2084%2C1007.2080%2C1007.4943%2C1007.4368%2C1007.1151%2C1007.0922%2C1007.0047%2C1007.2703%2C1007.2759%2C1007.4730%2C1007.5429%2C1007.1248%2C1007.1895%2C1007.4029%2C1007.0874%2C1007.2618%2C1007.4595%2C1007.1306%2C1007.2015&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Development of distributed systems is a difficult task. Declarative\nprogramming techniques hold a promising potential for effectively supporting\nprogrammer in this challenge. While Datalog-based languages have been actively\nexplored for programming distributed systems, Prolog received relatively little\nattention in this application area so far. In this paper we present a\nProlog-based programming system, called DAHL, for the declarative development\nof distributed systems. DAHL extends Prolog with an event-driven control\nmechanism and built-in networking procedures. Our experimental evaluation using\na distributed hash-table data structure, a protocol for achieving Byzantine\nfault tolerance, and a distributed software model checker - all implemented in\nDAHL - indicates the viability of the approach."}, "authors": ["Nuno P. Lopes", "Juan A. Navarro", "Andrey Rybalchenko", "Atul Singh"], "author_detail": {"name": "Atul Singh"}, "author": "Atul Singh", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1017/S1471068410000360", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1007.3835v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1007.3835v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1007.3835v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1007.3835v1", "arxiv_comment": null, "journal_reference": "Theory and Practice of Logic Programming, 26th Int'l. Conference\n  on Logic Programming (ICLP'10) Special Issue, 10(4-6):691-707, July 2010", "doi": "10.1017/S1471068410000360", "fulltext": "Under consideration for publication in Theory and Practice of Logic Programming\n\n1\n\nApplying Prolog to Develop Distributed Systems\n\narXiv:1007.3835v1 [cs.PL] 22 Jul 2010\n\nNuno P. Lopes\u2217 , Juan A. Navarro\u2020, Andrey Rybalchenko\u2020 , and Atul Singh\u2021\n\u2217\n\nINESC-ID / Instituto Superior T\u00e9cnico, Technical University of Lisbon\n\u2020\n\u2021\n\nTechnische Universit\u00e4t M\u00fcnchen\n\nNEC Research Labs, Princeton, NJ\n\nNote: This article has been published in Theory and Practice of Logic Programming,\n26th Int'l. Conference on Logic Programming (ICLP'10) Special Issue, 10(4-6):691707, July 2010, c Cambridge University Press.\n\nAbstract\nDevelopment of distributed systems is a difficult task. Declarative programming techniques hold a promising potential for effectively supporting programmer in this challenge.\nWhile Datalog-based languages have been actively explored for programming distributed\nsystems, Prolog received relatively little attention in this application area so far. In this\npaper we present a Prolog-based programming system, called DAHL, for the declarative\ndevelopment of distributed systems. DAHL extends Prolog with an event-driven control\nmechanism and built-in networking procedures. Our experimental evaluation using a distributed hash-table data structure, a protocol for achieving Byzantine fault tolerance, and\na distributed software model checker \u2013 all implemented in DAHL \u2013 indicates the viability\nof the approach.\n\n1 Introduction\nDeclarative Networking is a promising direction in the quest for distributed programming systems that meet the challenges of building reliable and efficient distributed applications (Loo et al. 2005). As the name suggests, Declarative Networking advocates a high-level programming paradigm where the programmer specifies what has to be computed and communicated over the network, and then\nthe compiler translates the specification into executable code. Its main applications are various network protocols, including sensor networks (Chu et al. 2007),\nfault tolerance protocols (Singh et al. 2008; Alvaro et al. 2010), distributed hash\ntables (Loo et al. 2005), and data replication systems (Belaramani et al. 2008).\nCurrent implementations of Declarative Networking adapt Datalog for the domain of networking applications. The resulting programming languages have a\nbottom-up evaluation semantics where the evaluation of (Datalog) clauses causes\nthe execution of corresponding networking actions. Since Datalog is a not a general purpose programming language, its adaptation for Declarative Networking required a reformulation of the language to allow the developer some control over\nthe flow of execution, to make available expressive data types, and to maintain\n\n\f2\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n\na mutable state. Programmers often include C/C++ fragments on ordinary occasions (Singh et al. 2008), while research efforts are invested to better couple\nthe required additional features with the Datalog evaluation model (Mao 2010;\nAlvaro et al. 2009).\nIn this paper we explore the applicability of Prolog as a basis for Declarative\nNetworking. In contrast to Datalog, Prolog is a general purpose programming language. Since Prolog is considered to be a practical tool for programming in logic,\nits adaptation to distributed programming can focus only on the networked communication aspects. In the process, we put Prolog into an event-driven execution\nenvironment, where each node interprets messages received from the network as\nqueries on its own local database, and provide a collection of procedures for communication via message passing. As a result, we obtain an extension of Prolog that\ncan be applied for distributed programming. Its implementation, called DAHL1 ,\nconsists of a bytecode compiler and a runtime environment. DAHL builds upon\nan existing Prolog infrastructure (The Intelligent Systems Laboratory 2009) and a\nnetworking library (Mathewson and Provos 2009).\nWe evaluate DAHL on a range of distributed applications including the\nChord distributed hash table (Stoica et al. 2001), the Byzantine fault tolerance protocol Zyzzyva (Kotla et al. 2007), and a distributed software model\nchecker (Lopes and Rybalchenko 2010). DAHL implementations are comparable to\nexisting Declarative Networking approaches in terms of succinctness, and do not require any C/C++ workarounds. Moreover, we also show that DAHL's performance\nis competitive with C++ runtimes produced with Mace, a tool that supports the\ndevelopment of robust distributed systems (Killian et al. 2007), while significantly\nreducing code size.\nIn this paper we present the following contributions:\n\u2022 We demonstrate that Prolog is a suitable basis for the design of a programming language for Declarative Networking. Our approach exploits Prolog's\nstrengths to provide general purpose programming features, while retaining\nits conceptual ties with the declarative paradigm.\n\u2022 We provide an efficient and robust programming system for DAHL that includes a compiler and a runtime environment.\n\u2022 We demonstrate the practicality of DAHL via an experimental evaluation on\na range of distributed applications.\nWe organize the paper in the following way: In Section 2, we introduce DAHL\nusing a simple spanning-tree protocol as example. The programmer interface that\nallows the development of distributed applications is described in Section 3. We\npresent implementation details of DAHL in Section 4, and evaluation results in\nSection 5. We also give a review of the related work in Section 6, and then conclude\nin Section 7.\n\n1\n\nAvailable at: http://www7.in.tum.de/tools/dahl/\n\n\fApplying Prolog to Develop Distributed Systems\n\n3\n\n:- event span_tree/2.\nspan_tree(Root, Parent) :\\+ tree(Root, _),\nassert(tree(Root, Parent)),\nthis_node(ThisAddr),\nsendall(\nNode,\nneighbor(Node),\nspan_tree(Root, ThisAddr)\n).\n\nFig. 1. DAHL program to compute a spanning-tree overlay.\n\n2 DAHL by example\nIn this section, we illustrate DAHL by using an example program that\nimplements a simple protocol for constructing a spanning-tree overlay in\na computer network. Tree-based overlay networks have received significant\nattention from the academic community (Castro et al. 2003; Chu et al. 2004;\nJannotti et al. 2000; Banerjee et al. 2002) and have also seen successful commercial deployment (Li et al. 2007). In these tree overlays, after some network node\nhas been selected to be the root node, we require that each other node is able to\nforward messages to the root node. After the spanning-tree overlay is constructed,\neach node can send a message to the root by either using a direct link, if available,\nor relying on the ability of some neighbor to forward messages to the root. If a node\nis not connected to the root via a sequence of links then the node cannot send any\nmessages to the root.\nThe overlay is constructed by propagating among the network nodes the information on how to forward to the root node. This information is given by the address\nof the next node towards the root. We assume that initially each node stores the\naddresses of its immediate neighbors in the (local) database. This information is\nloaded at startup by each node (e.g., at the command line or from a configuration\nfile) into the neighbor(Node) table.\nA node can directly access its neighbors by sending messages over the corresponding network links. At the initial step of the overlay construction, the designated root\nnode, say Root, is triggered by sending it a message span tree(Root,Root). Then,\nthe root node sends span tree(Root,Root) to each neighbor node. At a neighbor, say Node, this message leads to the addition of the fact tree(Root,Root) to\nthe database, thus, recording the possibility of reaching the tree root in a single\nstep. Furthermore, Nodepropagates this information to its neighbors by sending\na message span tree(Root,Node). Upon reception, each Node's neighbor adds\ntree(Root,Node) to its database and continues the propagation.\nOur implementation of the spanning-tree protocol relies on a combination of\nProlog with networking and distribution-specific extensions to achieve the goal,\nsee Figure 1. When the initial message span tree(Root,Root) arrives at Root, it\nis interpreted as a Prolog query. The query execution is carried out by the cor-\n\n\f4\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n\nresponding procedure span tree/2, which is authorized to execute queries that\narrive from the network due to the declaration event span tree/2. The procedure span tree/2 uses standard Prolog predicates as well as our extensions. First,\nspan tree/2 checks if the information how to reach the root node is already available. If it is the case, the execution of the procedure fails, and since the initiating\nquery was issued by the network, DAHL ignores the failure and continues with the\nnext message as soon as it arrives. Otherwise, a fact recording the root's reachability is added to the database. We propagate the corresponding information to\nthe neighbors, whose addresses are stored by each node as facts neighbor/1 in the\ndatabase. The message that is sent to each neighbor contains the sender address,\nwhich is required for the overlay construction. We obtain this address by using a\nDAHL built-in predicate this node/1. The communication with the neighbors is\nimplemented using a DAHL built-in procedure sendall/3, which is inspired by the\n\"all solutions\" predicates provided by Prolog, e.g., findall/3 or setof/3. For each\naddress that can be bound to Node by evaluating neighbor(Node), the execution\nof sendall sends a message span tree(Root,ThisAddr), i.e., the message is sent\nto all neighbors.\nIn summary, our example shows that we can apply Prolog for developing distributed protocols by putting it into an event-driven execution environment and by\nextending the standard library with networking-specific built-in procedures. A more\ncomplex example is shown in Figure 6, which is an excerpt of our implementation\nof the Zyzzyva Byzantine fault tolerant protocol. In the rest of the paper, we briefly\nintroduce the extensions and describe their interplay with Prolog for implementing\na distributed hash-table data structure, a protocol achieving the Byzantine fault\ntolerance, and a distributed version of a software model-checking algorithm.\n3 Programming interface for distributed applications\nWe now present the interface for developers to implement distributed applications.\nThe interface consists of an event driven control and a set of primitives to send\nmessages over the network. Our implementation of this interface is described later\nin Section 4.\nMessages and event handlers Nodes communicate by exchanging messages represented by Prolog terms. When a message is received by a node, it triggers the\nevaluation of the matching event handler. An event handler corresponds to a Prolog\npredicate definition and its evaluation is done as a Prolog query.\nThe declaration\n:- event PredSpec, ..., PredSpec.\nturns each predicate specified by PredSpec into an event handler for messages that\nmatch its specification. A predicate specification is an expression of the form p/n\nwhere p is a predicate name and n its arity. For example,\n:- event q/2.\nq(X, Y) :- Body.\n\n\fApplying Prolog to Develop Distributed Systems\n\n5\n\ndeclares the q/2 predicate as the event handler for messages of the form q(X, Y).\nIn other words, the event declaration allows the evaluation of a predicate to be\ntriggered when a matching message is received from the network.\nIn a running application, a node waits until a message is received from the network. When a message is received, and if the corresponding predicate is declared\nas an event, Prolog's standard evaluation strategy is used to compute the first\nsolution to the message as if it was posed as a query. As the query is evaluated, the\nevent handler can modify the local state of the node, e.g., with assert/retract,\nor produce messages to send to other nodes. The solution to this query, or the\nfailure to find a solution, is discarded, but the side effects of the evaluation are\nnot. Messages that are not declared as events are also discarded. Event handlers\ntriggered by different messages are evaluated atomically in sequence, i.e., the evaluation of a new message does not start until the evaluation of the previous one\nhas finished. Atomic evaluation avoids concurrency issues that could arise when\nprocessing multiple messages at once.\nDAHL provides the send/2 and sendall/3 built-in predicates to send messages\nover the network. The predicate\nsend(Address, Message)\nsends Message to the node at Address. Evaluation of the predicate succeeds as soon\nas the underlying transport protocol reports the message as sent, and evaluation\nof the rest of the query continues. If an error occurs (e.g., Address is unreachable),\nthe predicate fails and backtracks, e.g., to find an alternate destination. This is the\ndefault behavior and can be configured to throw exceptions or ignore errors instead.\nLow level details, such as opening and closing network connections, are abstracted\naway and handled automatically by the DAHL runtime. If needed, developers can\nalso access low level primitives to open/close connections themselves.\nMultiple messages can be sent using\nsendall(Address, Generator, Message)\nwhich, for every solution of Generator, sends a Message to Address. A developer can\nuse this predicate to broadcast a message to all neighbors of a node. For example,\nsendall(N, neighbor(N), ping)\nsends a ping message to every node N which is a solution to neighbor(N). Moreover,\nboth the Address and the Message of the sendall operation can be determined by\nthe Generator. For example,\nsendall(N, (task(T), assign(T, N)), solve(T)).\ndistributes a number of tasks among a set of nodes.\nLow level implementations can optimize for particular usages of sendall. As\nan example, when Message does not depend on Generator, a network-level multicast/broadcast protocol can be used to provide a more efficient operation.\nAnother feature provided by the DAHL interface is that of alarms. Alarms are\n\n\f6\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n\nused by nodes to cause the evaluation of a local event handler at a specified time\nin the future. Similar to events, the declaration\n:- alarm PredSpec, ..., PredSpec.\nturns each predicate specified by PredSpec into an alarm handler. The predicate\nalarm(Message, MSecs )\nsucceeds after setting up a reminder to insert Message in the local queue after MSecs\nhave elapsed. The alarm/2 predicate can also be used to trigger event handlers\ndeclared with the event directive; but a predicate declared as alarm will never\nrespond to messages from the network (e.g., produced with send or sendall).\nAuthentication When running a distributed protocol over an untrusted network, it\nis often required for messages to be signed in order to authenticate their origin.\nDAHL's interface allows an application to be easily augmented with authentication\nby replacing send/2 with the predicate\nsend_signed(Address, Message)\nthat attaches authentication metadata to the Message sent to Address. Similarly,\nthe sendall_signed/3 predicate, analogous to sendall/3, is provided.\nOn the receiving end, the predicates\nsigned_by(Address, Signature)\nsigned_by(Address)\nsigned\ncheck on demand whether the incoming message (and whose event handler is being\nevaluated) was properly signed. Additionally, if present, Address is unified with the\naddress of the sender and Signature with the signature metadata. If the message\nwas not signed, or had an invalid signature, these predicates fail.\nSince cryptographic operations are often computing intensive, these predicates\nallow the programmer to schedule the validation of signatures at an appropriate\ntime in the evaluation of an event handler. For example,\nrequest(Req) :- valid(Req), signed_by(Addr), ...\nchecks the validity of a request before performing a, possibly more expensive, validation of the signature. This strategy is applied in the definition of request/1 in\nour implementation of Zyzzyva (Figure 6).\nAuthenticity in DAHL is based on OpenSSL's implementation of HMAC for\nsigning messages and MD5 for computing message digests. Alternative cryptoalgorithms can be selected and accessed through the same high-level interface.\n\n4 Implementation\nThe software architecture of DAHL is shown in Figure 2. It consists of a DAHL compiler (based on SICStus Prolog compiler from\nThe Intelligent Systems Laboratory 2009), a high-performance event dispatching\nlibrary (libevent from Mathewson and Provos 2009), the OpenSSL library to provide the cryptographic primitives in the language, the DAHL runtime, and DAHL\n\n\fApplying Prolog to Develop Distributed Systems\n\n7\n\nFig. 2. The DAHL software stack.\napplications. We use the off-the-shelf SICStus Prolog compiler to quickly build the\nDAHL system and utilize its industrial-strength performance and robustness for\nachieving high performance. We do not describe the details of how we interfaced\nlibevent and OpenSSL since they are standard, instead we describe in detail the\nnovel aspects of DAHL: how the runtime works, some optimizations that were implemented, and the networking aspects.\nRuntime DAHL's runtime consists of a library written in Prolog (with around 460\nlines of code), which implements the built-in predicates, and a networking back-end\nwritten in C (around 450 lines). It is the networking back-end that interfaces with\nboth libevent and OpenSSL. This back-end interfaces with Prolog through stubs\ngenerated automatically by the SICStus Prolog compiler.\nDAHL programs are interpreted directly by the SICStus Prolog compiler, but\nunder the DAHL runtime control. The main program in execution is a loop that is\npart of the runtime, and a DAHL program's code is only called when an appropriate\nevent arrives from the network, or when a timer is triggered. Those events are\nprocessed by libevent.\nFigure 3 shows the execution flow for processing a message that arrives from the\nnetwork (steps 1\u20134), and for a message that is sent from an application (steps 5\u20136)\nin more detail. When a message arrives from the network, the operating system dispatches it to libevent (step 1), which queues the message. Then, when the DAHL\nruntime asks for the next message, libevent picks one arbitrarily and delivers it to\nthe DAHL network back-end (step 2). The DAHL network back-end then deserializes the message and calls the runtime dispatcher (in Prolog) through a stub (step\n3). Finally, the dispatcher calls the corresponding event handler of the application\n(step 4). When a DAHL application sends a message, the message is first handed\nover to the DAHL runtime through a stub (step 5). The runtime then serializes the\nmessage and delegates the network transmission to the operating system (step 6).\nOptimizations We implemented several optimizations in the DAHL runtime to improve its performance. Here, we present these optimizations in detail. The deserialization of network messages was a CPU-intensive operation since the SICStus\nProlog compiler implements this operation in Prolog through a complex process\nchain. Since each message sent was serialized to a single atom, it led to an explo-\n\n\f8\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n\nFig. 3. Internals of DAHL runtime shown by tracing the flow of message processing.\nsion in memory usage because the SICStus Prolog compiler aggressively caches all\natoms. We therefore implemented our own custom deserialization in C to improve\nthe performance. This resulted in a performance improvement of the deserialization\nfunction of about 70%.\nAs described before, the main loop is implemented in Prolog, and it calls a function in C that \"produces\" events through libevent, which are then dispatched from\nwithin the Prolog environment. The loop is implemented as a Prolog rule that first\ncalls the external C function, and then fails and backtracks to the beginning of the\nrule in order to iterate. This provides an important advantage, which is that every\nevent/alarm handler is executed in a \"clean\" environment, as all the garbage possibly left by a previous handler is discarded. Moreover, it improves the performance\nof the garbage collector (GC), as the SICStus Prolog compiler will delete most of\nsuch garbage when backtracking as an optimization, reducing the overhead of the\nGC. Our tests show that without this environment cleanup, the overhead of the\nGC would be noticeable (from 8% to 45%).\nNetwork Support Currently all the network messages are sent using the TCP protocol, which requires establishing a connection before the first contact. The DAHL\nruntime automatically establishes these connections when needed, and caches them\nindefinitely for future contacts. It is straightforward to replace TCP with UDP,\nthough the application needs to have mechanisms to handle message loss.\n5 Evaluation\nIn this section, we present an evaluation of DAHL in terms of run-time performance,\nlanguage expressiveness, and succinctness of programs. Implementations of networking protocols, like Chord (Stoica et al. 2001) and Zyzzyva (Kotla et al. 2007),\n\n\fApplying Prolog to Develop Distributed Systems\n\n9\n\nTable 1. Comparing raw network performance of P2, DAHL, Mace, Mace compiled\nwith '-O2' optimizations, and plain C as the maximum number of pings responded\nby the server in a second.\nP2\n\nDAHL\n\nMace\n\nMace (w/ -O2)\n\nC\n\n230\n\n14,000\n\n14,221\n\n21,937\n\n142,800\n\nas well as CPU-bound applications like D'ARMC (Lopes and Rybalchenko 2010)\ndemonstrate the applicability of DAHL in the development of real-life and complex\nsystems. We compare the results with alternative implementations of these protocols in P2 (Loo et al. 2006), the original implementation of Declarative Networking,\nand Mace (Killian et al. 2007), an extension of C++ with networking capabilities\nand a state-machine specification language.\n\n5.1 Raw Performance\nTo evaluate the performance of the DAHL runtime, we performed a test to compare\nthe performance of P2, Mace, C, and DAHL. We performed a simple network pingpong experiment. One of the machines (called a client) sends a small 20-byte 'ping'\nmessage to the other machine (called a server) which immediately responds with\na small 20-byte 'pong' message. We used as many client machines as needed to\nsaturate the server in order to measure its raw throughput. The measurement of\nthe number of requests served per second was done at the server. The machines\nwere connected by a gigabit switch with a round trip latency of 0.09 ms, and both\nthe network and the machines were unloaded. The results are presented in Table 1.\nFirst, we note that the DAHL runtime outperforms P2's performance. We believe\nthat the reason behind P2's poor performance is that the runtime of P2 is not yet\noptimized while DAHL uses the SICStus 4 compiler that has been already optimized. Second, DAHL is as fast as Mace. However, given that Mace is a restricted\nform of C++, it can exploit powerful C++ optimizing compilers. For example,\nwith the '-O2' set of optimizations of gcc 4.1, Mace's performance improves by\n60%. As an upper bound on the performance, we also present the performance of a\nC implementation and note that all the systems that strive to improve the analysis capability-by providing higher level programming abstractions which are also\nmore amenable to static analysis and program verification techniques-are an order\nof magnitude slower.\n\n5.2 Chord\nIn this subsection, we evaluate the performance of an implementation of Chord\n(a distributed hash table) in DAHL. Our implementation of Chord implements all\nfeatures detailed in the original paper (Stoica et al. 2001). To compare with the\n\n\f10\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n1\n\nCDF\n\n0.8\n0.6\n0.4\n0.2\n\n100\n500\n\n0\n0\n\n0.5\n\n1\nLatency (s)\n\n1.5\n\n2\n\nFig. 4. Chord: Lookup latency distribution.\nP2 Chord implementation, we obtained the latest release of P2.2 Unfortunately, we\nwere unable to get P2 Chord running in our local setup. We therefore cite results\nfrom their paper (Loo et al. 2005).\nSetup We used ModelNet (Vahdat et al. 2002) to emulate a GT-ITM transit-stub\ntopology consisting of 100 to 500 stubs and ten transit nodes. The stub-transit links\nhad a latency of 2 ms and 10 Mbps of bandwidth, while transit-transit links had a\nlatency of 50 ms and 100 Mbps of bandwidth. We used 10 physical hosts, each with\ndual-core AMD Opteron 2.6 GHz processor with 8GB of RAM, and running Linux\nkernel version 2.6.24. We ran 10 to 50 virtual nodes on each physical node, producing\na population of 100 to 500 nodes. In each experiment, neither the CPU nor the RAM\nwere the bottleneck. This setup reproduces the topology used by the P2 experiments\nin (Loo et al. 2005), although they used Emulab (White et al. 2002).\nStatic Membership Our first goal was to see if the DAHL implementation met\nthe high-level properties of Chord. We have first evaluated our implementation\nby performing 10,000 DHT 'lookup' requests generated from random nodes in the\nnetwork for a random set of keys. The lookups were generated after waiting for five\nminutes after the last node joined in order to let the network stabilize.\nIn Figure 4, we present the cumulative distribution of latency incurred to receive the response to the lookup requests with 100 and 500 nodes. The results are\ncomparable or better than the published results for P2 Chord (Loo et al. 2005).\nIn Figure 5, we present the frequency distribution of the number of hops taken to\ncomplete the lookups. As expected, the maximum number of hops taken is under\nthe theoretical upperbound of \u2308log N \u2309.\nDynamic Membership Our implementation of Chord in DAHL also handles churn.\nIn this experiment, we used 500 nodes, each one maintaining four successors and\nperforming finger fixing every 10 seconds and successor stabilization every 5 seconds.\nThis configuration is similar to the setup of P2 Chord. We generated artificial churn\nin our experiment by killing and joining nodes at random with different session times\nby following the methodology presented in (Rhea et al. 2004).\n2\n\nVersion 3570 in https://svn.declarativity.net/p2/trunk.\n\n\fApplying Prolog to Develop Distributed Systems\n\n11\n\n0.3\n\nFrequency\n\n0.25\n0.2\n0.15\n0.1\n100\n500\n\n0.05\n0\n0\n\n2\n\n4\n\n6\n8\nHop Count\n\n10\n\n12\n\n14\n\nFig. 5. Chord: Hop count distribution.\nWe obtained lookup consistency of 96% for average session times of 60 minutes,\nwhich is comparable with other implementations of Chord.\nSummary Our results show that our implementation of Chord in DAHL covers\nthe major algorithmic aspects of the protocol and that its run-time performance is\ncompetitive with P2 Chord.\n5.3 Zyzzyva\nIn this subsection, we evaluate the implementation of Zyzzyva in DAHL. For\nreference, and to give a flavor of the code written in DAHL, we include a\nfragment of the implementation of its first phase in Figure 6. We present\nthe peak throughput for the normal case, and the throughput after killing\na backup replica. The goal of our experiments is to show that our implementation covers a significant part of Zyzzyva protocol and to show that its\nperformance is reasonable. We compare the performance of DAHL Zyzzyva\nwith the publicly available C++ implementation of Zyzzyva (available from\nhttp://cs.utexas.edu/~kotla/RESEARCH/CODE/ZYZZYVA/).\nSetup We use four physical machines as servers to tolerate one Byzantine faulty\nserver and vary the number of clients to measure the peak throughput. Both the\nserver and client machines have identical characteristics as previous experiment.\nThe clients send requests with an empty payload, the execution cost of each operation at the servers is zero, and we measure the peak throughput sustained by the\nservers.\nImplementation We use OpenSSL's HMAC+MD5 cryptographic hash function in\nDAHL to perform critical digest and signing operations. Our implementation uses\nTCP as the transport protocol, we do not yet use network broadcast feature, and do\nnot implement batching. Our implementation takes checkpoint at the rate of every\n128 requests, which is standard in existing implementations. We do not implement\nstate transfer mechanism to bring the slow replicas up-to-date.\nFirst case performance In this experiment, we present the peak throughput of\nZyzzyva without failures where requests are completed in single phase. This result\n\n\f12\n1:\n2:\n3:\n4:\n5:\n6:\n7:\n8:\n9:\n10:\n11:\n12:\n13:\n14:\n15:\n16:\n17:\n18:\n19:\n20:\n21:\n22:\n23:\n24:\n25:\n26:\n27:\n28:\n29:\n30:\n31:\n32:\n33:\n34:\n35:\n36:\n37:\n38:\n39:\n40:\n41:\n42:\n43:\n44:\n45:\n46:\n47:\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n:- dynamic seqno/1, pending/3, cache/4.\n:- event request/1, process/2.\n\nProgram state, and\nevent declarations.\n\nrequest(Req) :this_node(ThisAddr),\nprimary(ThisAddr),\nsigned_by(Src),\n\\+ pending(_, Src, Req),\ncount(pending(_, _, _), N),\u2020\nId is N + 1,\nassert(pending(Id, Src, Req)),\nbatch_size(Size),\nId =:= Size,\nstart_new_batch.\n\nWhen I get a request . . .\nFind my own address,\nif I'm the primary,\nand got a signed request,\nwhich I haven't seen before,\ncount the previous requests,\nto produce a new id, and\nadd the new request as pending.\nRecall the size of a batch,\nif there are enough requests,\nstart the protocol for this batch.\n\nstart_new_batch :findall(\n(Id, Src, Req),\nretract(pending(Id, Src, Req)),\nBatch\n),\nretract(seqno(Seq)),\nsendall_signed(\nNode,\nreplica(Node),\nprocess(Batch, Seq)\n),\nNext is Seq + 1,\nassert(seqno(Next)).\n\nWhen starting a new batch . . .\n\nprocess(Batch, Seq) :primary(Primary),\nsigned_by(Primary),\nfindall(_, (\nmember((Id, Src, Req), Batch),\nprocess_req(Seq-Id, Src, Req)\n), _).\n\nWhen processing a batch . . .\nLook up who is the primary,\nas this should be the one asking.\n\nprocess_req(Seq, Src, Req) :( cache(Seq, Src, Req, Out) ->\nsend_signed(Src, reply(Seq, Req, Out))\n;\n\\+ cache(Seq, _, _, _)),\ncompute_output(Req, Out),\nassert(cache(Seq, Src, Req, Out)),\nsend_signed(Src, reply(Seq, Req, Out))\n).\n\nWhen processing a request . . .\nIf I've seen this request before\nreply with the cached response.\nOtherwise,\nif it's a new sequence no.,\ncompute the output,\nstore it on the cache,\nand send it back to the client.\n\nCollect all the pending requests,\nremoving them from the store,\nand group them in a batch.\nGet the next sequence number.\nAsk all nodes,\nthat happen to be replicas,\nto process this batch.\nIncrement the sequence no.,\nand store the new value.\n\nUnpack the batch,\nand process each request.\n\nFig. 6. Initial phase of Zyzzyva with batching optimization.\n\u2020 count/2\n\nis a non-standard Prolog extension that counts the number of solutions of a given goal.\n\n\fApplying Prolog to Develop Distributed Systems\n\n13\n\nTable 2. Zyzzyva: single phase and two phase performance for empty payload.\n\nSingle phase\nSecond phase\n\nDAHL Zyzzyva\n\nC++ Zyzzyva\n\n4.5 k req/s\n2.5 k req/s\n\n40 k req/s\n20 k req/s\n\nserves to measure the baseline functionality of Zyzzyva. The results are presented\nin Table 2. We observe that the performance of DAHL's Zyzzyva is about 10 times\nslower than the C++ implementation. However, as Clement et al. (2009) observe,\nthe penalty of using DAHL over C++ will diminish as the application-level overhead\nstarts to dominate. For example, with an application that consumes approximately\n100 \u03bcs per operation, Zyzzyva will deliver throughput of 9 k req/s while the implementation in DAHL will deliver approximately 3 k req/s, bringing down the penalty\nto 3X.\nSecond phase performance In this experiment, we present the peak throughput of\nZyzzyva when upto F replicas are faulty and prevent requests from completing in\nthe single phase. This requires client to initiate the second phase, requiring more\ncomputation and network resources at the replicas, resulting in lower performance\ncompared to the previous result based on single phase. Again, our results show that\nDAHL implementation is slower compared to its counterpart in C++ owing to a\nslower runtime.\nSummary The primary goal of our evaluation was to check if our implementation is\ncomprehensive and faithful, and to evaluate its performance. Our results show that\nthe current implementation covers a significant portion of the protocol features but\nthe performance is lower compared to C++ implementation.\n\n5.4 D'ARMC\nD'ARMC (Lopes and Rybalchenko 2010) is a distributed software model checker\nthat was implemented in DAHL. D'ARMC is a CPU-bound application, and therefore shows that DAHL can be used to implement more applications than mere\nnetwork protocols. The median speedup achieved by D'ARMC in a set of benchmarks is shown in Figure 7. The benchmarks consist in a set of automata-theoretic\nmodels from the transportation domain and a standard hybrid-system example.\nAs can be seen in Figure 7, D'ARMC shows a linear speedup with a varying\nnumber of machines, and the efficiency is about 50%. A more extensive evaluation\ncan be found in (Lopes and Rybalchenko 2010).\n\n\f14\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n20\nmedian\n\nSpeedup\n\n15\n10\n5\n0\n5\n\n10\n\n20\nNumber of nodes\n\n40\n\nFig. 7. Median speedup of D'ARMC with varying number of nodes.\n5.5 Code Size\nOur implementations of both Chord and Zyzzyva are comparable in size to the\nP2 implementations in terms of lines of code (LoC). For example, DAHL Chord is\nimplemented in 215 LoC while the P2 Chord is implemented in 211 LoC. These sizes\nare an order of magnitude more succinct compared to a C/C++ implementation.\n6 Related work\nIn the previous section we have already compared DAHL with two other\nrelated systems that help the programmer to build distributed applications,\nP2 (Loo et al. 2006) and Mace (Killian et al. 2007). Both languages have been successfully used for the implementation of important networked systems and protocols, and serve as a research platform for the development of specialized variants\n- see http://declarativity.net for further pointers - as well as verification\ntools (Killian et al. 2007; Yabandeh et al. 2010; Navarro and Rybalchenko 2009;\nWang et al. 2009; P\u00e9rez et al. 2009).\nAlternative approaches that attempt to extend Datalog for use\nin a distributed environment, while trying to overcome the pitfalls of early Declarative Networking implementations, are Meld\n(Ashley-Rollman et al. 2007; Ashley-Rollman et al. 2009), WIND (Mao 2010)\nand Netlog (Grumbach and Wang 2010). A common feature of these projects is\nthat they all argue that a 'pure' Datalog based language is not appropriate for\nthe development of stateful applications. The authors of Meld show that a limited\ndeclarative language can be used to program behavior in ensembles; the authors\nof WIND propose the use of syntactic 'salt' to discourage, but still allow, the\nuse of imperative features; while the authors of Netlog augment Datalog rules\nwith annotations to explicitly control whether tuples are stored or sent over the\nnetwork.\nIn the broader picture of designing high-level languages for concurrent and distributed programming, a prime example is Erlang (Armstrong et al. 1993). Erlang\nis based on the functional programming paradigm and, similar to our approach,\nincorporates distribution via explicit message passing between processes. A related\n\n\fApplying Prolog to Develop Distributed Systems\n\n15\n\napproach suggests using the Lua programming language to implement distributed\nsystems (Leonini et al. 2009).\nSome projects also aim to exploit the use of functional programming languages\nat lower layers of the network protocol deign. Foxnet, for example, implements the\nstandard TCP/IP networking protocol stack in ML (Biagioni et al. 2001); while\nMelange provides a language to describe Internet packet protocols, and generates\nfast code to parse/create these packets (Madhavapeddy et al. 2007). Similarly, the\nKL1 logic based language has been used to model and exploit physical parallelism\nin the PIM operating system (Bal 1993).\nPrevious work has also explored the use of Prolog to deal with concurrency and\nparallelism, a comprehensive review is given by Gupta et al. (2001). Most of this\nwork, however, deals with the problem of using Prolog to paralellize an otherwise sequential task. Recent advances in this direction are discussed by (Casas et al. 2008).\nOur work explores, instead, the use of Prolog as a general purpose programming\nlanguage to implement distributed applications.\n7 Conclusion\nFrom our experience with applying Prolog for distributed programming we draw\nthe following conclusions.\nIn combination with event-driven control and networked communication primitives, Prolog offers a programming language that is sufficiently expressive and\nwell-suited for the implementation of distributed protocols. In our experiments, we\ndid not rely on any C/C++ extensions as there was no need to compensate absence\nof certain programming constructs, as it is common for the P2 system for declarative networking that is Datalog-based. Instead, we used the data type, control\nstructures, and the database facility provided by Prolog. By using Prolog as a basis\nwe avoided any major compiler/runtime/libraries implementation efforts, which often become an obstacle when implementing a new programming language. By not\nstarting from scratch and relying on the existing Prolog infrastructure, we obtain\na fully-featured programming environment for distributed systems out of the box.\nReferences\nAlvaro, P., Condie, T., Conway, N., Elmeleegy, K., Hellerstein, J. M., and\nSears, R. C. 2009. BOOM: Data-Centric Programming in the Datacenter. Tech.\nRep. UCB/EECS-2009-98, EECS Department, University of California, Berkeley.\nAlvaro, P., Condie, T., Conway, N., Hellerstein, J. M., and Sears, R. 2010. I Do\nDeclare: Consensus in a Logic Language. ACM SIGOPS Oper. Syst. Rev. 43, 4, 25\u201330.\nArmstrong, J., Virding, R., Wikstr\u00f6m, C., and Williams, M. 1993. Concurrent\nProgramming in ERLANG. Prentice Hall.\nAshley-Rollman, M., Goldstein, S., Lee, P., Mowry, T., and Pillai, P. 2007.\nMeld: A declarative approach to programming ensembles. In IEEE/RSJ International\nConference on Intelligent Robots and Systems. 2794 \u20132800.\nAshley-Rollman, M. P., Lee, P., Goldstein, S. C., Pillai, P., and Campbell,\nJ. D. 2009. A Language for Large Ensembles of Independently Executing Nodes. In\n\n\f16\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n\nICLP '09: Proceedings of the 25th International Conference on Logic Programming.\nSpringer-Verlag, Berlin, Heidelberg, 265\u2013280.\nBal, H. E. 1993. Evaluation of KL1 and the inference machine. Future Gener. Comput.\nSyst. 9, 2, 119\u2013125.\nBanerjee, S., Bhattacharjee, B., and Kommareddy, C. 2002. Scalable Application\nLayer Multicast. In SIGCOMM '02: Proceedings of the 2002 conference on Applications,\ntechnologies, architectures, and protocols for computer communications. ACM, New\nYork, NY, USA, 205\u2013217.\nBelaramani, N., Zheng, J., Nayate, A., Soul\u00e9, R., Dahlin, M., and Grimm, R.\n2008. PADRE: A Policy Architecture for building Data REplication Systems. Tech.\nRep. TR-08-25, University of Texas at Austin. May.\nBiagioni, E., Harper, R., and Lee, P. 2001. A Network Protocol Stack in Standard\nML. Higher Order Symbol. Comput. 14, 4, 309\u2013356.\nCasas, A., Carro, M., and Hermenegildo, M. V. 2008. A High-Level Implementation\nof Non-deterministic, Unrestricted, Independent And-Parallelism. In ICLP '08: Proceedings of the 24th International Conference on Logic Programming. Springer-Verlag,\nBerlin, Heidelberg, 651\u2013666.\nCastro, M., Druschel, P., Kermarrec, A.-M., Nandi, A., Rowstron, A., and\nSingh, A. 2003. SplitStream: High-Bandwidth Multicast in Cooperative Environments.\nIn SOSP '03: Proceedings of the nineteenth ACM symposium on Operating systems\nprinciples. ACM, New York, NY, USA, 298\u2013313.\nChu, D., Popa, L., Tavakoli, A., Hellerstein, J. M., Levis, P., Shenker, S., and\nStoica, I. 2007. The Design and Implementation of a Declarative Sensor Network\nSystem. In SenSys '07: Proceedings of the 5th international conference on Embedded\nnetworked sensor systems. ACM, New York, NY, USA, 175\u2013188.\nChu, Y.-h., Ganjam, A., Ng, T. S. E., Rao, S. G., Sripanidkulchai, K., Zhan, J.,\nand Zhang, H. 2004. Early Experience with an Internet Broadcast System Based on\nOverlay Multicast. In ATEC '04: Proceedings of the annual conference on USENIX\nAnnual Technical Conference. USENIX Association, Berkeley, CA, USA, 12\u201312.\nClement, A., Wong, E., Alvisi, L., Dahlin, M., and Marchetti, M. 2009. Making\nByzantine Fault Tolerant Systems Tolerate Byzantine Faults. In NSDI'09: Proceedings of the 6th USENIX symposium on Networked systems design and implementation.\nUSENIX Association, Berkeley, CA, USA, 153\u2013168.\nGrumbach, S. and Wang, F. 2010. Netlog, a rule-based language for distributed programming. In PADL'10: Proceedings of the Eleventh International Symposium on Practical Aspects of Declarative Languages. Number 5937 in Lecture Notes in Computer\nScience. Springer, 88\u2013103.\nGupta, G., Pontelli, E., Ali, K. A., Carlsson, M., and Hermenegildo, M. V.\n2001. Parallel Execution of Prolog Programs: A Survey. ACM Trans. Program. Lang.\nSyst. 23, 4, 472\u2013602.\nJannotti, J., Gifford, D. K., Johnson, K. L., Kaashoek, M. F., and O'Toole, Jr.,\nJ. W. 2000. Overcast: Reliable Multicasting with an Overlay Network. In OSDI'00:\nProceedings of the 4th conference on Symposium on Operating System Design & Implementation. USENIX Association, Berkeley, CA, USA, 14\u201314.\nKillian, C. E., Anderson, J. W., Braud, R., Jhala, R., and Vahdat, A. M. 2007.\nMace: Language Support for Building Distributed Systems. In PLDI '07: Proceedings\nof the 2007 ACM SIGPLAN conference on Programming language design and implementation. ACM, New York, NY, USA, 179\u2013188.\nKillian, C. E., Anderson, J. W., Jhala, R., and Vahdat, A. 2007. Life, Death, and\nthe Critical Transition: Finding Liveness Bugs in Systems Code. In NSDI'07: Proceed-\n\n\fApplying Prolog to Develop Distributed Systems\n\n17\n\nings of the 4th USENIX symposium on Networked systems design and implementation.\nUSENIX Association, Berkeley, CA, USA.\nKotla, R., Alvisi, L., Dahlin, M., Clement, A., and Wong, E. 2007. Zyzzyva:\nSpeculative Byzantine Fault Tolerance. ACM SIGOPS Oper. Syst. Rev. 41, 6, 45\u201358.\nLeonini, L., Rivi\u00e8re, E., and Felber, P. 2009. SPLAY: Distributed Systems Evaluation\nMade Simple. In NSDI'09: Proceedings of the 6th USENIX symposium on Networked\nsystems design and implementation. USENIX Association, Berkeley, CA, USA, 185\u2013198.\nLi, B., Xie, S., Keung, G., Liu, J., Stoica, I., Zhang, H., and Zhang, X. 2007. An\nEmpirical Study of the Coolstreaming+ System. Selected Areas in Communications,\nIEEE Journal on 25, 9 (Dec.), 1627\u20131639.\nLoo, B. T., Condie, T., Garofalakis, M., Gay, D. E., Hellerstein, J. M., Maniatis,\nP., Ramakrishnan, R., Roscoe, T., and Stoica, I. 2006. Declarative Networking:\nLanguage, Execution and Optimization. In SIGMOD '06: Proceedings of the 2006 ACM\nSIGMOD international conference on Management of data. ACM, New York, NY, USA,\n97\u2013108.\nLoo, B. T., Condie, T., Hellerstein, J. M., Maniatis, P., Roscoe, T., and Stoica,\nI. 2005. Implementing Declarative Overlays. ACM SIGOPS Oper. Syst. Rev. 39, 5,\n75\u201390.\nLopes, N. P. and Rybalchenko, A. 2010. Distributed and Predictable Software Model\nChecking. draft manuscript.\nMadhavapeddy, A., Ho, A., Deegan, T., Scott, D., and Sohan, R. 2007. Melange:\nCreating a \"Functional\" Internet. In EuroSys '07: Proceedings of the 2nd ACM\nSIGOPS/EuroSys European Conference on Computer Systems 2007. ACM, New York,\nNY, USA, 101\u2013114.\nMao, Y. 2010. On the Declarativity of Declarative Networking. ACM SIGOPS Oper.\nSyst. Rev. 43, 4, 19\u201324.\nMathewson, N. and Provos, N. 2009. libevent Documentation. Release 1.4.9.\nNavarro, J. A. and Rybalchenko, A. 2009. Operational Semantics for Declarative Networking. In PADL '09: Proceedings of the 11th International Symposium on Practical\nAspects of Declarative Languages. Springer-Verlag, Berlin, Heidelberg, 76\u201390.\nP\u00e9rez, J. A., Rybalchenko, A., and Singh, A. 2009. Cardinality Abstraction for\nDeclarative Networking Applications. In CAV '09: Proceedings of the 21st International\nConference on Computer Aided Verification. Springer-Verlag, Berlin, 584\u2013598.\nRhea, S., Geels, D., Roscoe, T., and Kubiatowicz, J. 2004. Handling Churn in a\nDHT. In ATEC '04: Proceedings of the annual conference on USENIX Annual Technical\nConference. USENIX Association, Berkeley, CA, USA, 10\u201310.\nSingh, A., Das, T., Maniatis, P., Druschel, P., and Roscoe, T. 2008. BFT Protocols\nUnder Fire. In NSDI'08: Proceedings of the 5th USENIX Symposium on Networked\nSystems Design and Implementation. USENIX Association, Berkeley, CA, USA, 189\u2013\n204.\nStoica, I., Morris, R., Karger, D., Kaashoek, M. F., and Balakrishnan, H. 2001.\nChord: A Scalable Peer-to-Peer Lookup Service for Internet Applications. ACM SIGCOMM Comput. Commun. Rev. 31, 4, 149\u2013160.\nThe Intelligent Systems Laboratory. 2009. SICStus Prolog User's Manual. Swedish\nInstitute of Computer Science. Release 4.0.5.\nVahdat, A., Yocum, K., Walsh, K., Mahadevan, P., Kosti\u0107, D., Chase, J., and\nBecker, D. 2002. Scalability and Accuracy in a Large-Scale Network Emulator. ACM\nSIGOPS Oper. Syst. Rev. 36, SI, 271\u2013284.\nWang, A., Basu, P., Loo, B. T., and Sokolsky, O. 2009. Declarative Network Veri-\n\n\f18\n\nN. Lopes, J. Navarro, A. Rybalchenko and A. Singh\n\nfication. In PADL '09: Proceedings of the 11th International Symposium on Practical\nAspects of Declarative Languages. Springer-Verlag, Berlin, Heidelberg, 61\u201375.\nWhite, B., Lepreau, J., Stoller, L., Ricci, R., Guruprasad, S., Newbold, M.,\nHibler, M., Barb, C., and Joglekar, A. 2002. An Integrated Experimental Environment for Distributed Systems and Networks. ACM SIGOPS Oper. Syst. Rev. 36, SI,\n255\u2013270.\nYabandeh, M., Kne\u017eevi\u0107, N., Kosti\u0107, D., and Kuncak, V. 2010. Predicting and\nPreventing Inconsistencies in Deployed Distributed Systems. ACM Trans. Comput.\nSyst. 28, 1, 1\u201349.\n\n\f"}