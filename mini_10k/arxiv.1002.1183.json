{"id": "http://arxiv.org/abs/1002.1183v2", "guidislink": true, "updated": "2010-06-08T12:51:28Z", "updated_parsed": [2010, 6, 8, 12, 51, 28, 1, 159, 0], "published": "2010-02-05T10:25:33Z", "published_parsed": [2010, 2, 5, 10, 25, 33, 4, 36, 0], "title": "Random sampling of lattice paths with constraints, via transportation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1002.3941%2C1002.1183%2C1002.3727%2C1002.2206%2C1002.0359%2C1002.4715%2C1002.4558%2C1002.1002%2C1002.0444%2C1002.0168%2C1002.1726%2C1002.1872%2C1002.3825%2C1002.3870%2C1002.0570%2C1002.1958%2C1002.0561%2C1002.1440%2C1002.0421%2C1002.2398%2C1002.4914%2C1002.0087%2C1002.2492%2C1002.3686%2C1002.3841%2C1002.2044%2C1002.4216%2C1002.4797%2C1002.4765%2C1002.2338%2C1002.2243%2C1002.3539%2C1002.2897%2C1002.4197%2C1002.5001%2C1002.1565%2C1002.4557%2C1002.4494%2C1002.2468%2C1002.0698%2C1002.3799%2C1002.3331%2C1002.4187%2C1002.2539%2C1002.4070%2C1002.0035%2C1002.3356%2C1002.2445%2C1002.3104%2C1002.1911%2C1002.1111%2C1002.3374%2C1002.2554%2C1002.3035%2C1002.1296%2C1002.4636%2C1002.4613%2C1002.1437%2C1002.1796%2C1002.4860%2C1002.1586%2C1002.2904%2C1002.0835%2C1002.4098%2C1002.0529%2C1002.1184%2C1002.4342%2C1002.2514%2C1002.3710%2C1002.3457%2C1002.3775%2C1002.0240%2C1002.0256%2C1002.1362%2C1002.0642%2C1002.3764%2C1002.4614%2C1002.4217%2C1002.1817%2C1002.1648%2C1002.3948%2C1002.2346%2C1002.1789%2C1002.4033%2C1002.2771%2C1002.1925%2C1002.0229%2C1002.3394%2C1002.2255%2C1002.2113%2C1002.0720%2C1002.2155%2C1002.1122%2C1002.3328%2C1002.1835%2C1002.4718%2C1002.4570%2C1002.1497%2C1002.0030%2C1002.2172%2C1002.3904&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Random sampling of lattice paths with constraints, via transportation"}, "summary": "We discuss a Monte Carlo Markov Chain (MCMC) procedure for the random\nsampling of some one-dimensional lattice paths with constraints, for various\nconstraints. We show that an approach inspired by optimal transport allows us\nto bound efficiently the mixing time of the associated Markov chain. The\nalgorithm is robust and easy to implement, and samples an \"almost\" uniform path\nof length $n$ in $n^{3+\\eps}$ steps. This bound makes use of a certain\ncontraction property of the Markov chain, and is also used to derive a bound\nfor the running time of Propp-Wilson's CFTP algorithm.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1002.3941%2C1002.1183%2C1002.3727%2C1002.2206%2C1002.0359%2C1002.4715%2C1002.4558%2C1002.1002%2C1002.0444%2C1002.0168%2C1002.1726%2C1002.1872%2C1002.3825%2C1002.3870%2C1002.0570%2C1002.1958%2C1002.0561%2C1002.1440%2C1002.0421%2C1002.2398%2C1002.4914%2C1002.0087%2C1002.2492%2C1002.3686%2C1002.3841%2C1002.2044%2C1002.4216%2C1002.4797%2C1002.4765%2C1002.2338%2C1002.2243%2C1002.3539%2C1002.2897%2C1002.4197%2C1002.5001%2C1002.1565%2C1002.4557%2C1002.4494%2C1002.2468%2C1002.0698%2C1002.3799%2C1002.3331%2C1002.4187%2C1002.2539%2C1002.4070%2C1002.0035%2C1002.3356%2C1002.2445%2C1002.3104%2C1002.1911%2C1002.1111%2C1002.3374%2C1002.2554%2C1002.3035%2C1002.1296%2C1002.4636%2C1002.4613%2C1002.1437%2C1002.1796%2C1002.4860%2C1002.1586%2C1002.2904%2C1002.0835%2C1002.4098%2C1002.0529%2C1002.1184%2C1002.4342%2C1002.2514%2C1002.3710%2C1002.3457%2C1002.3775%2C1002.0240%2C1002.0256%2C1002.1362%2C1002.0642%2C1002.3764%2C1002.4614%2C1002.4217%2C1002.1817%2C1002.1648%2C1002.3948%2C1002.2346%2C1002.1789%2C1002.4033%2C1002.2771%2C1002.1925%2C1002.0229%2C1002.3394%2C1002.2255%2C1002.2113%2C1002.0720%2C1002.2155%2C1002.1122%2C1002.3328%2C1002.1835%2C1002.4718%2C1002.4570%2C1002.1497%2C1002.0030%2C1002.2172%2C1002.3904&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We discuss a Monte Carlo Markov Chain (MCMC) procedure for the random\nsampling of some one-dimensional lattice paths with constraints, for various\nconstraints. We show that an approach inspired by optimal transport allows us\nto bound efficiently the mixing time of the associated Markov chain. The\nalgorithm is robust and easy to implement, and samples an \"almost\" uniform path\nof length $n$ in $n^{3+\\eps}$ steps. This bound makes use of a certain\ncontraction property of the Markov chain, and is also used to derive a bound\nfor the running time of Propp-Wilson's CFTP algorithm."}, "authors": ["Lucas Gerin"], "author_detail": {"name": "Lucas Gerin"}, "author": "Lucas Gerin", "links": [{"href": "http://arxiv.org/abs/1002.1183v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.1183v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.1183v2", "affiliation": "MODAL'X", "arxiv_url": "http://arxiv.org/abs/1002.1183v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:1002.1183v2 [math.PR] 8 Jun 2010\n\nRandom sampling of lattice paths with constraints, via\ntransportation\nLucas Gerin\nJune 8, 2018\nAbstract\nWe investigate Monte Carlo Markov Chain (MCMC) procedures for the random sampling of some one-dimensional lattice paths with constraints, for various constraints. We\nwill see that an approach inspired by optimal transport allows us to efficiently bound the\nmixing time of the associated Markov chain. The algorithm is robust and easy to implement, and samples an \"almost\" uniform path of length n in n3+\u03b5 steps. This bound makes\nuse of a certain contraction property of the Markov chain, and is also used to derive a bound\nfor the running time of Propp-Wilson's Coupling From The Past algorithm.\n\n1\n\nLattice Paths with Constraints\n\nWe are interested in this paper in some families of one-dimensional lattices paths. We fix three\nintegers n, a, b > 0, and consider the paths of length n, with steps +a/ \u2212 b, that is, the words of\nn letters taken in the alphabet {a, \u2212b}. Such a word s = (s1 , s2 , . . . , sn ) is identified to the path\nS = (S1 , . . . , Sn ) := (s1 , s1 + s2 , . . . , s1 + s2 + * * * + sn ).On the right, one sees the lattice path\nS = (1, 2, 0, 1, 2, 3, 1) associated to the word s = (1, 1, \u22122, 1, 1, 1, \u22122). The problem we discuss\nhere is to efficiently sample uniform (or almost uniform) paths in a sub-family An of paths, with\nMarkov chains.\nTo illustrate the methods and the results, we focus on three particular sub-families.\n1. Discrete meanders, denoted by Mn , which are simply the non-negative paths: S \u2208 Mn if\nfor any i \u2264 n we have Si \u2265 0. This example is mainly illustrative because the combinatorial\nproperties of meanders make it possible to perform exact sampling very efficiently (an\nalgorithm running in O(n1+\u03b5 ) steps is given in [3], an order that we cannot get in the\npresent paper).\n2. Paths with walls. A path with a wall of height h between r and s is a path such that Si \u2265 h\nfor any r \u2264 i \u2264 s (see Fig. 1 for an example). These are denoted by Wn = Wn (h, r, s),\nthey appear in statistical mechanics as toy models for the analysis of random interfaces\nand polymers (see examples in [6]).\n\n1\n\n\f3. Culminating paths, denoted by Cn , which are non-negative paths whose maximum is attained at the last step: for any i we have 0 \u2264 Si \u2264 Sn . They have been introduced in [3],\nmotivated in particular by the analysis of some algorithms in bioinformatics.\n\nFigure 1: A path of steps +1/ \u2212 2, with a wall of height h = 6 between i = 10 and j = 15.\n\nRemark 1. The methods discussed here apply to any values of (a, b), but we have in mind the\nchallenging case b > a: for our three families the ratio card(An )/card(Pn ) decreases exponentially fast, making impossible a naive rejection algorithm.\n\n2\n\nSampling with Markov chains\n\nWe will consider Markov chains in a family An , where all the probability transitions are symmetric. For a modern introduction to Markov chains, we refer to [7]. Hence we are given a\ntransition matrix (pi,j ) of size |An | \u00d7 |An | with\npi,j = pj,i whenever i 6= j,\nX\npi,i = 1 \u2212\npi,j .\nj6=i\n\nLemma 2. If such a Markov chain is irreducible, then it admits as unique stationnary distribution the uniform distribution \u03c0 = \u03c0(An ) on An .\nProof. The equality \u03c0(i)pi,j = \u03c0(j)pj,i holds for any two vertices i, j. This shows that the\nprobability distribution \u03c0 is reversible for (pi,j ), and hence stationnary. It is unique if the chain\nis irreducible.\nThis lemma already provides us with a scheme for sampling an almost uniform path in An ,\nwithout knowing much about An . To do so, we define a \"flip\" operator on paths. Fix an integer\ni \u2208 {1, 2, . . . , n \u2212 1} and a path S = (S1 , . . . , Sn ) ; let (s1 , . . . , sn ) be the corresponding word.\nThe path \u03c6(S, i, \u2191) is defined as follows : if (si , si+1 ) = (\u2212b, a) =\n\nthen these two steps\n\nare exchanged into (a, \u2212b) =\n. The n \u2212 2 other steps remain unchanged. For the case i = n,\n\u03c6(S, n, \u2191) is simply the path associated to the word\n(s1 , . . . , sn\u22121 , a).\n\n2\n\n\fThe path \u03c6(S, i, \u2193) is defined equally: if (si , si+1 ) =\n, it turns into\n. The path \u03c6(S, n, \u2191)\nis the path associated to (s1 , . . . , sn\u22121 , \u2212b).\nFor the family An = Cn , we have to use another definition of \u03c6(S, n, \u2191) and \u03c6(S, n, \u2193,), if we\nwant the chain to be irreducible. Notice that since the maximum is reached at n, the \u2308b/a\u2309 + 1\nlast steps are necessarily\n(a, a, . . . , a) or (\u2212b, a, . . . , a).\nWe thus define \u03c6(S, n, \u2191) as the path obtained by changing the \u2308b/a\u2309 + 1 last steps into\n(a, a, . . . , a) (regardless of their initial values in S) and \u03c6(S, n, \u2193) as the path obtained by changing the \u2308b/a\u2309 + 1 last steps into (\u2212b, a, . . . , a)\nWe are also given a probability distribution p = (pi )1\u2264i\u2264n , and we assume that pi > 0 for\neach i. We will consider a particular sequence p later on, but at this point we can take the\nuniform distribution in {1, . . . , n}. We can now describe the algorithm.\nAlgorithm 1 MCMC: Approximate sampling of a path in An\ninitialize S \u2208 An\nI1 , I2 , * * * \u2190 i.i.d. r.v. with law p\n\u03b51 , \u03b52 , * * * \u2190 i.i.d. uniform r.v. in {\u2191, \u2193}\nfor t = 1 to T do\nif \u03c6(S, It , \u03b5t ) is in An then\nS \u2190 \u03c6(S, It , \u03b5t )\nend if\nend for\nIn other words, this algorithm performs the Markov chain in An with transition matrix\nP = (PR,S )R,S\u2208An defined as follows:\n(\nPR,S = pi /2, if S = \u03c6(R, i, \u03b5) for some \u03b5 and 0 otherwise,\nP\nPR,R = 1 \u2212 S6=R PR,S .\nProposition 3. Denote by S(t) the path sampled by the t-th run of the loop in Algorithm 1.\nWhen t \u2192 \u221e, the sequence S(t) converges in law to the uniform distribution in An .\n\nProof. We have to check that the chain is aperiodic and irreducible. Aperiodicity comes from\nthe (many) loops. Irreducibility will follow from Lemma 5.\nWe choose now the distribution (pi ). Instead of pi = 1/n, we will use the weights defined by\n(see the plot of i 7\u2192 pi for n = 100 below):\npi :=\n\ni(i + 1)\n4i\n\u2212 \u03ba0\nn(n + 1)\n2\n\n( for i = 1, . . . , n),\n\n(1)\n\n6\nwhere \u03ba0 = n(n+1)(n+2)\n\u223c 6n\u22123 . We let the reader check that (pi )i\u2264n is indeed a probability\ndistribution.\n\n3\n\n\fThe reason for which we use this particular distribution will appear in the proof of Proposition\n6. We will then need the following relation: for each 1 \u2264 i \u2264 n \u2212 1,\n2pi \u2212 pi\u22121 \u2212 pi+1 = \u03ba0 .\n\n(2)\n\nRemark 4. There are obviously many other Markov chains which are reversible with respect to\nthe uniform measure, and some of them may seem more natural to the reader. However, such\nMarkov chains are in general neither monotonous (see later Section 4) nor of positive Ricci\ncurvature (Section 3). The latter condition is essential for our purpose.\n\n2.1\n\nAnalysis of Algorithm 1\n\nWe could deduce from a brief glance at Algorithm 1 that time-complexity is always linear in T ,\nbut we have to pay attention to what is hidden behind each run of the for loop.\n\u2022 If It < n, the time needed for the test \"\u03c6(S, It , \u03b5t ) is in An \" can be considered as constant,\nsince we only have to compare 0, S(i), S(n).\n\u2022 If It = n, the new value S(n) is compared with the maximum of S, which can be done in\nO(n). Fortunately, this occurs with probability pn = O(n\u22121 ), so that the time-complexity\nof each loop is, on average, a O(1).\nFor Algorithm 1 to be efficient, we need to know how S(T ) is close in law to \u03c0. This question\nis related to the spectral properties of the matrix P . In particular, the speed of convergence is\ngoverned by the spectral gap (i.e. 1 \u2212 \u03bb, where \u03bb is the largest of the modulus of the eigenvalues\ndifferent from one, see [9] for example), but this quantity is not known in general. Some\ngeometrical methods [5] allow to bound from below 1 \u2212 \u03bb, but they assume a precise knowledge\nof the structure of the graph defined by the chain P . It seems that such results do not apply\nhere.\nInstead, we will study the metric properties of the chain P with respect to a natural distance\non An , and show that it satisfies a certain contraction property.\n\n3\n\nError estimates with contraction\n\nGoing back to a more general setting, we consider a Markov chain in a finite set V , endowed\nwith a metric d. For a vertice x \u2208 V and a transition matrix P , we denote by P \u03b4x (resp. P t \u03b4x )\nthe law of the Markov chain associated to P at time 1 (resp. t), when starting from x. For\nx, y \u2208 V , the main assumption made on P is that there is a coupling between P \u03b4x , P \u03b4y (that is,\nlaw\nlaw\na random variable (X1 , Y1 ) with X1 = P \u03b4x , Y1 = P \u03b4Y ) such that\nE [d(X1 , Y1 )] \u2264 (1 \u2212 \u03ba)d(x, y),\n\n(3)\n\nfor some \u03ba > 0, which is called the Ricci curvature of the chain, by analogy with the Ricci\ncurvature in differential geometry1 . If the inequality holds, then it implies that P admits a\nunique stationnary measure \u03c0 and that, for any x,\nk P t \u03b4x \u2212 \u03c0 kTV \u2264 (1 \u2212 \u03ba)t diam(V ),\n1 The\n\n(4)\n\nRicci curvature is actually the largest positive number such that (3) holds, for all the couplings of\nP \u03b4x , P \u03b4y ; here we should rather say that Ricci curvature is larger than \u03ba.\n\n4\n\n\fwhere diam(V ) is the diameter of the graph with vertices V induced by the Markov chain and\nk . kTV stands, as usual, for the Total Variation distance\nk \u03bc1 \u2212 \u03bc2 kTV := sup |\u03bc1 (A) \u2212 \u03bc2 (A)| .\nA\u2282V\n\nHence, a positive Ricci curvature gives the exponential convergence to the stationnary measure,\nwith an exact (again, exact means non-asymptotic) bound. In many situations, a smart choice\nfor the coupling between X1 , X2 gives a sharp rate of convergence in eq. (4) (see [10]).\n\n3.1\n\nMetric properties of P\n\nTo apply the Ricci curvature machinery, we endow each An with the L1 -distance\nn\n\nd1 (S, S \u2032 ) =\n\n1 X\n|Si \u2212 Si\u2032 |.\na + b i=0\n\n(Notice that |Si \u2212 Si\u2032 | is always a multiple of a + b.) For our purpose, it is fundamental that this\nmetric space is geodesic.\nLemma 5 (Families An are geodesic). Each An , equipped with the distance d1 , is geodesic\nin the following sense: for any two S, T \u2208 An with d1 (S, T ) = k, there exist k + 1 paths\nS0 = S, S1 , . . . , Sk = T in An such that for each i\n\u2022 d1 (Si , Si+1 ) = 1 ;\n\u2022 Si and Si+1 are neighbours in the Markov chain P .\nThis implies in particular that P is irreducible and that the diameter of P is smaller than\nmaxS,T d1 (S, T ) \u2264 n(n + 1)/2.\nProof. The proof goes by induction on k. We fix S 6= T (and denote by s, t the corresponding\nwords) ; we want to decrease d1 (S, T ) by one, by applying the operator \u03c6(*, i, \u03b5) with proper i, \u03b5.\nWe denote by i0 \u2208 {1, . . . , n} the first index for which S 6= T :\nS0 = T0 , S1 = T1 , . . . , Si0 \u22121 = Ti0 \u22121 , Si0 6= Ti0 .\nFor instance we have Ti0 = Si0 + a + b. Let j be the position of the left-most peak in T in\n{i0 + 1, i0 + 2, . . . , n}, if such a peak exists. Then S \u2032 := \u03c6(T, j, \u2193) is also in An : it is immediate\nfor the three families Mn , Wn , Cn . We have d1 (S, S \u2032 ) = k \u2212 1.\nIf there is no peak in T after i0 , then (ti0 +1 , ti0 +2 , . . . , tn ) = (a, a, . . . , a). Hence we try to\nincrease the final steps of S by one. To do so, we choose S \u2032 := \u03c6(S, n, \u2191) if S 6= \u03c6(S, n, \u2191), or\nS \u2032 = \u03c6(S, j, \u2191) where j is the position of the right-most valley otherwise.\nWe will show that Ricci curvature of P w.r.t. this distance is (at least) of order 1/n3 .\nProposition 6. For the three families Mn , Cn , Wn , the Ricci curvature of the associated Markov\nchain, with weights defined as in (1), is larger than \u03ba0 .\nProof. Fix S, T in An \u2208 {Mn , Cn , Wn }, we first assume that S, T are neighbours, for instance\nT = \u03c6(S, i, \u2191) for some i, as in Fig. 2. Let (S1 , S2 ) be the random variable in An \u00d7 An whose\nlaw is defined by\n(law)\n(S1 , S2 ) = (\u03c6(S, I, E), \u03c6(T, I, E)) ,\n5\n\n\fFigure 2: The paths S, T differ at i.\n\nwhere I is a r.v. {1, . . . , n} with distribution p and E is uniform in {\u2191, \u2193}. In other words, we\nrun one loop of Algorithm 1 simultaneously on the both paths.\nWe want to show that S1 , S2 are, on average, closer than S, T. Three cases may occur:\nCase 1. I = i This occurs with probability pi and, no matter the value of E, we have S1 = S2 .\nCase 2. I = i \u2212 1 or i + 1. We consider the case i \u2212 1. Since S and T coincide everywhere\nbut in i, we necessarily have one of these two cases:\n\u2022 there is a peak in S at i \u2212 1 and neither peak nor valley in T at i \u2212 1 (as in the figure on\nthe right) ;\n\u2022 there is a valley in T at i \u2212 1 and neither peak nor valley in S at i \u2212 1.\nIn the first case for instance, then we may have d1 (S1 , S2 ) = 2 if E =\u2193, while the distance\nremains unchanged if E =\u2191. The case I = i + 1 is identical. This shows that with a probability\nsmaller than pi\u22121 /2 + pi+1 /2 we have d1 (S1 , S2 ) = 2.\nIn this case, S and T are possibly modified in I, but if there is\nCase 3. I 6= i \u2212 1, i, i + 1\na modification it occurs in both paths. It is immediate for the families Mn , Wn , less apparent\nfor Cn . In the latter we have to check that if \u03c6(T, I, \u2191) is in Cn , so is \u03c6(S, I, \u2191). But this\nis true because we have maxj Sj = Sn = Tn . Hence a flip in S at I does not violate the\nmaximum-at-last-position condition, because it does not violate this condition for T.\nThus, we have proven that when S, T only differ at i\n\u0002\n\u0003\nE d1 (S1 , S2 ) \u2264 2 \u00d7 (pi\u22121 /2 + pi+1 /2) + 0 \u00d7 pi + 1 \u00d7 (1 \u2212 pi \u2212 pi\u22121 /2 \u2212 pi+1 /2)\n\n(5)\n\n\u2264 (1 \u2212 \u03ba0 ) \u00d7 1 = (1 \u2212 \u03ba0 )d1 (S, T ).\n\nWhat makes Ricci curvature very useful is that if this inequality holds for pairs of neighbours\nthen it holds for any pair, as noticed in [4]. Indeed, take k paths S0 = S, S1 , . . . , Sk = T as in\nLemma 5 and apply the triangular inequality for d1 :\nE [d1 (\u03c6(S, I, E), \u03c6(T, I, E))] \u2264\n\nk\u22121\nX\n\nE [d1 (\u03c6(Si , I, E), \u03c6(Si+1 , I, E))]\n\ni=0\n\n\u2264 (1 \u2212 \u03ba0 )k = (1 \u2212 \u03ba0 )d1 (S, T ).\n\nRemark 7. It is easy to exhibit some \u0002S, T such that\n\u0003 ineq. (5) is in fact an equality. In the case\nwhere pi = 1/n, this equality reads E d1 (S1 , S2 ) = d1 (S, T ), and we cannot obtain a positive\nRicci curvature (though this does not prove that there is not another coupling or another distance\nfor which we could get a \u03ba > 0 in the case pi = 1/n.).\n6\n\n\fCombining Proposition 6 with Eq. (4) gives our main result.\nTheorem 8. For each family An , Algorithm 1 returns an almost uniform sample of \u03c0, as soon\nas T \u226b n3 :\n\u0013\n\u0012\n6T\n2\n.\nk S(T ) \u2212 \u03c0 kTV \u2264 n /2 exp \u2212\nn(n + 1)(n + 2)\n\n3.2\n\nRelated works\n\nBounding mixing times via a contraction property over the transportation metric is quite a\nstandard technique, the main ideas dating back to Dobrushin (1950's). A modern introduction\nis made in [9]. For geodesic spaces, this technique has been developped in [4] under the name\npath coupling.\nThe Markov chain P on lattice paths has in fact already been introduced2 by D.Wilson [12]\nfor lattice paths with a fixed end-point (as a first step for the sampling of random tilings), with\nuniform weights pi = 1/n. The author also proves a mixing time of order n3 log n, by showing\nthat (3) holds with a different distance (namely, a kind of Fourier transform of the heights of\nthe paths). It does not seem to us that his method can be applied for paths with our kinds of\nconstraints (when the end-point is not fixed).\nMore generally, we do believe that it is difficult to build a Markov chain for these kinds of\nlattice paths which has a mixing time much smaller than n3 , with the constraint that each step\nof the chain is fast to compute (in addition to [12], see also [2] for some related results in the\ncontext of quasicrystals: the weights are also uniform with yet another distance).\n\n4\n\nCoupling From The Past with P\n\nPropp-Wilson's Coupling From The Past (CFTP) [11] is a very general procedure for the exact\nsampling of the the stationnary distribution of a Markov chain. It is efficient if the chain\nis monotonous with respect to a certain order relation \u0016 on the set V of vertices, with two\nextremal points denoted 0\u0302, 1\u0302 (i.e. such that 0\u0302 \u0016 x \u0016 1\u0302 for any vertice x). This is the case here\nfor our three families, with the partial order\nS \u0016 T iff Si \u2264 Ti for any i.\nFor the family M10 with a = 1, b = \u22122 for instance, we have\n0\u0302 = 0\u0302meanders = (1, 1, \u22122, 1, 1, \u22122, 1, 1, \u22122, 1),\n1\u0302 = 1\u0302meanders = (1, 1, 1, 1, 1, 1, 1, 1, 1, 1).\nIt is easy to check that for each n, families Cn and Wn also admit extremal points 0\u0302, 1\u0302.\nWe describe CFTP, with our notations, in Algorithm 2.\nWe refer to ([7],Chap.10) for a very clear introduction to CFTP, and we only outline here\nthe reasons why this indeed gives an exact sampling of the stationnary distribution.\n\u2022 The output of the algorithm (if it ever ends!) is the state of the chain P which has been\nrunning \"since time \u2212\u221e\", and thus has reached stationnarity.\n\u2022 The exit condition S = T ensures that it is not worth running the chain from T steps\nearlier, since the trajectory of any lattice path 0\u0302 \u0016 R \u0016 1\u0302 is \"sandwiched\" between those\nof 0\u0302, 1\u0302, and therefore ends at the same value.\n\n7\n\n\fAlgorithm 2 CFTP: Exact sampling of a path in An\nS \u2190 0\u0302, T \u2190 1\u0302\n. . . , I\u22122 , I\u22121 \u2190 i.i.d. r.v. with law p\n. . . , \u03b5\u22122 , \u03b5\u22121 \u2190 i.i.d. uniform r.v. in {\u2191, \u2193}\n\u03c4 =1\nrepeat\nS \u2190 0\u0302, T \u2190 1\u0302\nfor t = \u2212\u03c4 to 0 do\nif \u03c6(S, It , \u03b5t ) is in An then S \u2190 \u03c6(S, It , \u03b5t )\nif \u03c6(T, It , \u03b5t ) is in An then T \u2190 \u03c6(T, It , \u03b5t )\nend for\n\u03c4 \u2190 2\u03c4\nuntil S = T\n\nFigure 3: A sketchy representation of CFTP : trajectories starting from 0\u0302, 1\u0302 at time \u2212T /2 don't\nmeet before time zero, while those starting at time \u2212T do.\n\nProposition 9. Algorithm 2 ends with probability 1 and returns a exact sample of the uniform\ndistribution over An . This takes on average O(n3 (log n)2 ) time units.\nWe recall that CFTP has a major drawback compared to MCMC. For the algorithm to be\ncorrect, we have to reuse the same random variables It , \u03b5t , so that space-complexity is in fact\nlinear in n3 (log n)2 . This may become an issue when n is large.\nProof. It is shown in [11] that Algorithm 2 returns an exact sampling in O(tmix log H) runs of\nthe chain, with\n\u001b\n\u001a\nt\n\u22121\n.\ntmix := t \u2265 0 ; sup k P \u03b4v \u2212 \u03c0 kTV \u2264 e\nv\u2208V\n\nThe number H is the length of the longest ordered chain of states between 0\u0302 and 1\u0302. It is a\nconsequence of the proof of Lemma 5 that H = O(n2 ). Regarding tmix , we have, for instance\nby ([9], p.189),\n1\n(log(diamV ) + 1) ,\ntmix \u2264\n\u03ba0\nhence tmix = O(n3 log n). (Recall that under Section 2.1, each test in Algorithm 2 takes, on\naverage, O(1) time units.)\n2 It is considered in [12] 2d-paths from (0, 0) to (x, y) with steps East/North. These are, up to a linear\ntransformation, one-dimensional paths of length x + y with steps +x/ \u2212 y, starting and ending at zero.\n\n8\n\n\f5\n\nConcluding remarks and simulations\n\n1. In Fig.4, we show simulations of the three kinds of paths, for n = 600. The final height of\nthe culminating path is very low (about 30), it would be interesting to use our algorithms to\ninvestigate the behaviour of this height when n \u2192 \u221e ; this question was left open in [3].\n\nFigure 4: (Almost) uniform paths of length 600. From top to bottom: a culminating path, a\nmeander, a path with wall (shown by an arch).\n2. One may wonder to what extent this work applies to other families An of paths. The main\nassumption is that the family of paths should be a geodesic space w.r.t. distance d1 . This is\ntrue for example if the following condition on An is fulfilled:\n(R, T \u2208 An and R \u0016 S \u0016 T ) \u21d2 S \u2208 An .\nNotice however that this is quite a strong requirement, and it is not verified for culminating\npaths for instance.\n3. A motivation to sample random paths is to make and test guesses for some functionals of these\npaths, taken on average overP\nAn . Consider a function f : An \u2192 R, we want an approximate\nvalue of \u03c0(f ) := card(An )\u22121 s\u2208An f (s), if the exact value is out of reach by calculation. We\nestimate this quantity by\nT\n1 X\n\u03c0\u0302(f ) :=\nf (S(t)) ,\n(6)\nT t=1\n\n(recall that S(t) is the value of the chain at time t). For Algorithm 1 to be efficient in practice,\nwe have to bound\nP (|\u03c0(f ) \u2212 \u03c0\u0302(f )| > r) ,\n(7)\n9\n\n\ffor any fixed r > 0, by a non-asymptotic (in T ) quantity. This can be done with ([8], Th.4-5),\nin which one can find concentration inequalities for (7). The sharpness of these inequalities\ndepends on \u03ba and on the geometrical structure of An .\nAknowledgements. This work was done while I was enjoying a post-doctoral position granted\nby Anr Gamma ; many thanks to Fr\u00e9d\u00e9rique Bassino and the other members of the Anr for\nthe support. I also would like to thank \u00c9lie Ruderman for the English corrections.\n\nReferences\n[1] C. Banderier and Ph. Flajolet. Basic Analytic Combinatorics of Directed Lattice Paths,\nTheoretical Computer Science 281 (1):37-80 (2002).\n[2] O. Bodini, Th. Fernique and D. Regnault. Stochastic flips on two-letter words. To appear\nin Proceedings of ANALCO'10 (2010).\n[3] M.Bousquet-M\u00e9lou and Y. Ponty. Culminating paths, Discrete Math and Theoretical Computer Science 10 (2):125-152 (2008).\n[4] R.Bubley and M. Dyer. Path coupling: A technique for proving rapid mixing in Markov\nchains. Proceedings of the 38th Annual Symposium on Foundations of Computer Science,\np.223-231 (1997).\n[5] P.Diaconis and D.W.Stroock. Geometric Bounds for Eigenvalues of Markov Chains, Annals\nof Applied Probability 1 (1):36-61 (1991).\n[6] M.E.Fisher. Walks, Walls, Wetting, and Melting. Journal of Statistical Physics 34 (5):667729 (1984).\n[7] O.H\u00e4ggstr\u00f6m. Finite Markov Chains and Algorithmic Applications. London Mathematical\nSociety (2002).\n[8] A.Joulin and Y.Ollivier. Curvature, concentration, and error estimates for Markov chain\nMonte Carlo. preprint, arXiv:0904.1312 (2009).\n[9] D.A.Levin, Y.Peres, and E.L.Wilmer. Markov Chains and Mixing Times. American Mathematical Society (2009).\n[10] Y.Ollivier. Ricci curvature of Markov chains on metric spaces. Journal of Functional Analysis 256 (3):810-864 (2009).\n[11] J.G. Propp and D.B. Wilson. Exact sampling with coupled Markov chains and applications\nto statistical mechanics. Random Structures and Algorithms, 9(1):223-252, (1996).\n[12] D.B.Wilson. Mixing times of Lozenge tiling and card shuffling Markov chains. Annals of\nApplied Probability 14 (1):274\u2013325 (2004).\n\n10\n\n\farXiv:1002.1183v2 [math.PR] 8 Jun 2010\n\nRandom sampling of lattice paths with constraints, via\ntransportation\nLucas Gerin\nJune 8, 2018\nAbstract\nWe investigate Monte Carlo Markov Chain (MCMC) procedures for the random sampling of some one-dimensional lattice paths with constraints, for various constraints. We\nwill see that an approach inspired by optimal transport allows us to efficiently bound the\nmixing time of the associated Markov chain. The algorithm is robust and easy to implement, and samples an \"almost\" uniform path of length n in n3+\u03b5 steps. This bound makes\nuse of a certain contraction property of the Markov chain, and is also used to derive a bound\nfor the running time of Propp-Wilson's Coupling From The Past algorithm.\n\n1\n\nLattice Paths with Constraints\n\nLattice paths arise in several areas in probability and combinatorics, either in their own interest\n(as realizations of random walks, or because of their interesting combinatorial properties: see [1]\nfor the latter) or because of fruitful bijections with various families of trees, tilings, words. The\nproblem we discuss here is to efficiently sample uniform (or almost uniform) paths in a family\nof paths with constraints.\nThere are several reasons for which one may want to generate uniform samples of lattice\npaths: to make and try conjectures on the behaviour of a large \"typical\" path, test algorithms\nrunning on paths (or words, trees,...). In view of random sampling, it is often very efficient to\nmake use of the combinatorial structure of the family of paths under study. In some cases, this\nyields linear-time (in the length of the path) ad-hoc algorithms [2, 6]. However, the nature of\nthe constraints makes sometimes impossible such an approach, and there is a need for robust\nalgorithms that work in lack of combinatorial knowledge.\nLuby,Randall and Sinclair [11] design a Markov chain that generate sets of non-intersecting\nlattice paths. This was motivated by a classical (and simple, see illustrations in [4, 14]) correspondence between dimer configurations on an hexagon, rhombae tilings of this hexagon and\nfamilies of non-intersecting lattice paths. As the first step for the analysis of this chain, Wilson\n[14] introduces a peak/valley Markov chain (see details below) over some simple lattice paths\nand obtain sharp bounds for its mixing time. We present in this paper a variant of this Markov\nchain, which is valid for various constraints and whose analysis is simple. It generates an \"almost\" uniform path of length n in n3+\u03b5 steps, this bound makes use of a certain contraction\nproperty of the chain.\nAppart from the algorithmic aspect, the peak/valley process seems to have a physical relevancy as a simplified model for the evolution of quasicrystals (see a discussion on a related\nprocess in the introduction of [4]). In particular, the mixing time of this Markov seems to have\nsome importance.\n\n1\n\n\fNotations\n\nFigure 1: The lattice path S = (1, 2, 0, 1, 2, 3, 1) associated with the word (1, 1, \u22122, 1, 1, 1, \u22122).\n\nWe fix three integers n, a, b > 0, and consider the paths of length n, with steps +a/ \u2212 b,\nthat is, the words of n letters taken in the alphabet {a, \u2212b}. Such a word s = (s1 , s2 , . . . , sn ) is\nidentified to the path S = (S1 , . . . , Sn ) := (s1 , s1 + s2 , . . . , s1 + s2 + * * * + sn ).\nTo illustrate the methods and the results, we focus on some particular sub-families An \u2282\nn\n{a, \u2212b} :\n1. Discrete meanders, denoted by Mn , which are simply the non-negative paths: S \u2208 Mn if\nfor any i \u2264 n we have Si \u2265 0. This example is mainly illustrative because the combinatorial\nproperties of meanders make it possible to perform exact sampling very efficiently (an\nalgorithm running in O(n1+\u03b5 ) steps is given in [2], an order that we cannot get in the\npresent paper).\n2. Paths with walls. A path with a wall of height h between r and s is a path such that Si \u2265 h\nfor any r \u2264 i \u2264 s (see Fig. 2 for an example). These are denoted by Wn = Wn (h, r, s),\nthey appear in statistical mechanics as toy models for the analysis of random interfaces\nand polymers (see examples in [7]).\n3. Excursions, denoted by En , which are non-negative paths such that Sn = 0. In the case\na = b = 1, these correspond to well-parenthesed words and are usually called Dyck words.\nIn the general case, Duchon [6] proposes a rejection algorithm which generates excursions\nin linear time.\n4. Culminating paths of size n, denoted further by Cn , which are non-negative paths whose\nmaximum is attained at the last step: for any i we have 0 \u2264 Si \u2264 Sn . They have\nbeen introduced in [2], motivated in particular by the analysis of some algorithms in\nbioinformatics.\n\nFigure 2: A path of steps +1/ \u2212 2, with a wall of height h = 6 between i = 10 and j = 15.\n\n2\n\n\f2\n\nSampling with Markov chains\n\nWe will consider Markov chains in a family An , where all the probability transitions are symmetric. For a modern introduction to Markov chains, we refer to [8]. Hence we are given a\ntransition matrix (pi,j ) of size |An | \u00d7 |An | with\npi,j = pj,i whenever i 6= j,\nX\npi,i = 1 \u2212\npi,j .\nj6=i\n\nLemma 1. If such a Markov chain is irreducible, then it admits as unique stationary distribution\nthe uniform distribution \u03c0 = \u03c0(An ) on An .\nProof. The equality \u03c0(i)pi,j = \u03c0(j)pj,i holds for any two vertices i, j. This shows that the\nprobability distribution \u03c0 is reversible for (pi,j ), and hence stationary. It is unique if the chain\nis irreducible.\nThis lemma already provides us with a scheme for sampling an almost uniform path in An ,\nwithout knowing much about An . To do so, we define a \"flip\" operator on paths, this is an\noperator\n\u03c6 : An \u00d7 {1, . . . , n} \u00d7 {\u2193, \u2191} \u00d7 {+, \u2212} \u2192\nAn\n(S, i, \u03b5, \u03b4)\n7\u2192 \u03c6(S, i, \u03b5, \u03b4).\nWhen i \u2208 {1, 2, . . . , n \u2212 1} the path \u03c6(S, i, \u2191, \u03b4) is defined as follows : if (si , si+1 ) = (\u2212b, a) =\nthen these two steps are changed into (a, \u2212b) =\n. The n \u2212 2 other steps remain\nunchanged. If (si , si+1 ) 6= (\u2212b, a) then \u03c6(S, i, \u2191)\u03b4 = S. Note that in the case i \u2208 {1, 2, . . . , n \u2212 1}\nthe value of \u03c6 does not depend on \u03b4.\nFor the case i = n, if \u03b4 = +, we define \u03c6(S, n, \u03b5)\u03b4 as before as if there would be a +a as the\nend if the path. For instance, in the case where Sn = \u2212b, the path \u03c6(S, n, \u2191)+, the n-th step is\nturned into a.\n, it turns into\n.\nThe path \u03c6(S, i, \u2193)\u03b4 is defined equally: if i < n and (si , si+1 ) =\nWhen \u03b4 = \u2212, one flips as if there would be a \u2212b at the end of the path.\nFor culminating paths, we have to take another definition of \u03c6(S, n, \u2191)\u03b4, \u03c6(S, n, \u2193)\u03b4, see Section 2.1.\nWe are also given a probability distribution p = (pi )1\u2264i\u2264n , and we assume that pi > 0 for\neach i. We will consider a particular sequence p later on, but at this point we can take the\nuniform distribution in {1, . . . , n}. We describe the algorithm below in Algorithm 1.\nAlgorithm 1 Approximate sampling of a path in An\ninitialize S = (+a, +a, +a, . . . , +a)\nI1 , I2 , * * * \u2190 i.i.d. r.v. with law p\n\u03b51 , \u03b52 , * * * \u2190 i.i.d. uniform r.v. in {\u2191, \u2193}\n\u03b41 , \u03b42 , * * * \u2190 i.i.d. uniform r.v. in {+, \u2212}\nfor t = 1 to T do\nif \u03c6(S, It , \u03b5t )\u03b4t is in An then\nS \u2190 \u03c6(S, It , \u03b5t )\u03b4t\nend if\nend for\n\n3\n\n\fIn words, this algorithm performs the Markov chain in An with transition matrix P =\n(PR,S )R,S\u2208An defined as follows:\n\uf8f1\n\uf8f4\n\uf8f2PR,S\nPR,S\n\uf8f4\n\uf8f3\nPR,R\n\n= pi /2, if S 6= R and S = \u03c6(R, i, \u03b5)\u03b4 for some i, \u03b5, \u03b4\n= 0 otherwise,\nP\n= 1 \u2212 S6=R PR,S .\n\nProposition 2. Denote by S(t) the random path obtained after the t-th run of the loop in\nAlgorithm 1. When t \u2192 \u221e, the sequence S(t) converges in law to the uniform distribution in\nAn . Moreover, the execution of Algorithm 1 until time T is linear in T .\nProof. For the first claim, we have to check that the chain is aperiodic and irreducible. Aperiodicity comes from the (many) loops. Irreducibility will follow from Lemma 4. For the second\nclaim, notice that the time needed for the test \"\u03c6(S, It , \u03b5t ) is in An \" can be considered as constant, since for the families Mn and En we only have to compare 0, Si while for the family Wn\nwe only have to compare Si with the height of the wall at i. For the case of the culminating\npaths, see below in Section 2.1.\nWe now choose the distribution (pi ). Instead of pi = 1/n, we will use the probability\ndistribution defined by\npi := i(2n \u2212 i)\u03ba0 + a\n\n( for i = 1, . . . , n),\n\n(1)\n\nwhere\n\u03ba0 =\n\n3\n2n2 (n\n\n+ 1)\n\na = 1/4n3 .\nWe let the reader check that (pi )i\u2264n is indeed a probability distribution. The reason for which\nwe use this particular distribution will appear in the proof of Proposition 5. We will then need\nthe following relation: for each 1 \u2264 i \u2264 n \u2212 1,\npi \u2212 pi\u22121 /2 \u2212 pi+1 /2 = \u03ba0 .\n\n(2)\n\nFor Algorithm 1 to be efficient, we need to know how S(T ) is close in law to \u03c0. This question\nis related to the spectral properties of the matrix P . In particular, the speed of convergence is\ngoverned by the spectral gap (i.e. 1 \u2212 \u03bb, where \u03bb is the largest of the modulus of the eigenvalues\ndifferent from one, see [10] for example), but this quantity is not known in general. Some\ngeometrical methods [5] allow to bound from below 1 \u2212 \u03bb, but they assume a precise knowledge\nof the structure of the graph defined by the chain P . It seems that such results do not apply\nhere.\nInstead, we will study the metric properties of the chain P with respect to a natural distance\non An , and show that it satisfies a certain contraction property.\n\n2.1\n\nThe variant of Algorithm 1 for culminating paths\n\nUnchanged, our Markov chain P cannot generate culminating paths since the path S = (a, a, . . . , a)\nwould then be isolated: it has no peak/valley and \u03c6(S, n, \u2193)\u2212 = (a, a, . . . , \u2212b) which is not culminating.\n\n4\n\n\fThus we propose a slight modification for the family Cn . We only change the definition of\n\u03c6(S, i, \u03b5)\u03b4 when i = n (it won't depend on \u03b4). Since the maximum is reached at n, the \u2308b/a\u2309 + 1\nlast steps are necessarily\n(a, a, . . . , a) or (\u2212b, a, . . . , a).\nWe thus define \u03c6(S, n, \u2191)\u03b4 as the path obtained by changing the \u2308b/a\u2309 + 1 last steps into\n(a, a, . . . , a) (regardless of their initial values in S) and \u03c6(S, n, \u2193)\u03b4 as the path obtained by\nchanging the \u2308b/a\u2309 + 1 last steps into (\u2212b, a, . . . , a).\nNotice that despite this change the execution time of each loop of Algorithm 1 is still a O(1):\n\u2022 If It < n, the time needed for the test \"\u03c6(S, It , \u03b5t )\u03b4t is in An \" can be considered as\nconstant, since we only have to compare 0, Si , Sn .\n\u2022 If It = n, the new value Sn is compared with the maximum of S, which can be done in\nO(n). Fortunately, this occurs with probability pn = O(1/n), so that the time-complexity\nof each loop is, on average, a O(1).\n\n3\n\nError estimates with contraction\n\nGoing back to a more general setting, we consider a Markov chain in a finite set V , endowed\nwith a metric d. For a vertice x \u2208 V and a transition matrix P , we denote by P \u03b4x (resp. P t \u03b4x )\nthe law of the Markov chain associated with P at time 1 (resp. t), when starting from x. For\nx, y \u2208 V , the main assumption made on P is that there is a coupling between P \u03b4x , P \u03b4y (that is,\nlaw\nlaw\na random variable (X1 , Y1 ) with X1 = P \u03b4x , Y1 = P \u03b4y ) such that\nE [d(X1 , Y1 )] \u2264 (1 \u2212 \u03ba)d(x, y),\n\n(3)\n\nfor some \u03ba > 0, which is called the Ricci curvature of the chain, by analogy with the Ricci\ncurvature in differential geometry1 . If the inequality holds, then it implies ([10],p.189) that P\nadmits a unique stationary measure \u03c0 and that, for any x,\nk P t \u03b4x \u2212 \u03c0 kTV \u2264 (1 \u2212 \u03ba)t diam(V ),\n\n(4)\n\nwhere diam(V ) is the diameter of the graph with vertices V induced by the Markov chain.\nThe notation k . kTV stands, as usual, for the Total Variation distance over the probability\ndistributions on V defined by\nk \u03bc1 \u2212 \u03bc2 kTV := sup |\u03bc1 (A) \u2212 \u03bc2 (A)| .\nA\u2282V\n\nHence, a positive Ricci curvature gives the exponential convergence to the stationary measure,\nwith an exact (i.e. (4) is non-asymptotic in t) bound. In many situations, a smart choice for\nthe coupling between X1 , X2 gives a sharp rate of convergence in eq. (4) (see some striking\nexamples in [12]).\n\n3.1\n\nMetric properties of P\n\nTo apply the Ricci curvature machinery, we endow each An with the L1 -distance\nn\n\nd1 (S, S \u2032 ) =\n\n1 X\n|Si \u2212 Si\u2032 |.\na + b i=0\n\n1 The Ricci curvature is actually the largest positive number such that (3) holds, for all the couplings of\nP \u03b4x , P \u03b4y ; here we should rather say that Ricci curvature is larger than \u03ba.\n\n5\n\n\f(Notice that |Si \u2212 Si\u2032 | is always a multiple of a + b.) For our purpose, it is fundamental that this\nmetric space is geodesic.\nDefinition 3. A Markov chain P in a finite set V is said to be geodesic with respect to the\ndistance d on V if for any two x, y \u2208 V with d(x, y) = k, there exist k + 1 vertices x0 =\nx, x1 , . . . , xk = y in V such that for each i\n\u2022 d(xi , xi+1 ) = 1 ;\n\u2022 xi and xi+1 are neighbours in the Markov chain P (i.e. P (xi , xi+1 ) > 0).\nThis implies in particular that P is irreducible and that the diameter of P is smaller than\nmaxx,y d(x, y).\nLemma 4. For each family Cn ,Wn ,En ,Mn the Markov chain of Algorithm 1 is geodesic with\nrespect to d1 .\nProof of Lemma 4. The proof goes by induction on k. We fix S 6= T (and denote by s, t the\ncorresponding words) ; we want to decrease d1 (S, T ) by one, by applying the operator \u03c6 with\nproper i, \u03b5. We denote by i0 \u2208 {1, . . . , n} the first index for which S 6= T . For instance we have\nTi0 = Si0 + a + b. Let j be the position of the left-most peak in T in {i0 + 1, i0 + 2, . . . , n},\nif such a peak exists. Then S \u2032 := \u03c6(T, j, \u2193)\u03b4 is also in An : it is immediate for the families\nMn , Wn , Cn , En . We have d1 (S, S \u2032 ) = k \u2212 1.\nIf there is no peak in T after i0 , then (ti0 +1 , ti0 +2 , . . . , tn ) = (a, a, . . . , a). Hence we try to\nincrease the final steps of S by one. To do so, we choose S \u2032 := \u03c6(S, n, \u2191)\u03b4 if S 6= \u03c6(S, n, \u2191)\u03b4, or\nS \u2032 = \u03c6(S, j, \u2191)\u03b4 where j is the position of the right-most \u2212b otherwise (we choose the right-most\none to ensure that \u03c6(S, j, \u2191)\u03b4 remains culminating in the case where An = Cn .).\nFor meanders, excursions and walls, we will show that the Ricci curvature of P with respect\nto the distance d1 is (at least) of order 1/n3 .\nProposition 5. For the three families Mn , En , Wn , the Ricci curvature of the associated Markov\nchain, with weights (pi ) defined as in (1), is larger than \u03ba0 .\n\nProof of Proposition 5.\nFix S, T in An \u2208 {Mn , En , Wn }, we first assume that S, T are neighbours, for instance\nT = \u03c6(S, i, \u2191) for some i. Let (S1 , S2 ) be the random variable in An \u00d7 An whose law is defined\nby\n(law)\n(S1 , S2 ) = (\u03c6(S, I, E), \u03c6(T, I, E)) ,\nwhere I is a r.v. taking values in {1, . . . , n} with distribution p and E is uniform in {\u2191, \u2193}. In\nother words, we run one loop of Algorithm 1 simultaneously on both paths.\nWe want to show that S1 , S2 are, on average, closer than S, T. Different cases may occur,\ndepending on I and on the index i where S, T differ.\nCase 1. i = 1, 2, . . . , n \u2212 2.\n\n6\n\n\fCase 1a. I = i. This occurs with probability pi and, no matter the value of E, we have\nS1 = S2 .\nCase 1b. I = i \u2212 1 or i + 1. We consider the case i \u2212 1. Since S and T coincide everywhere\nbut in i, we necessarily have one of these two cases:\n\u2022 there is a peak in S at i \u2212 1 and neither a peak nor a valley in T at i \u2212 1 (as in the figure\non the right) ;\n\u2022 there is a valley in T at i \u2212 1 and neither a peak nor a valley in S at i \u2212 1.\nIn the first case for instance, then we may have d1 (S1 , S2 ) = 2 if E =\u2193, while the distance\nremains unchanged if E =\u2191. The case I = i + 1 is identical. This shows that with a probability\nsmaller than pi\u22121 /2 + pi+1 /2 we have d1 (S1 , S2 ) = 2.\nCase 1c. I 6= i \u2212 1, i, i + 1 and I 6= n. In this case, S and T are possibly modified in I, but\nif there is a modification it occurs in both paths. It is immediate since for the families Mn ,Wn\nand En since the constraints are local.\nCase 2. i = n \u2212 1. In this case, it is easy to check that, because of our definition of \u03c6(S, n, \u03b5)\u03b4,\nwe have\n\u0002\n\u0003\nE d1 (S1 , S2 ) \u2264 1 \u2212 pn\u22121 + pn\u22122 /2 + pn /2 = 1 \u2212 \u03ba0 .\nCase 3. i = n.\n\nWe have\n\n\u0002\n\u0003\nE d1 (S1 , S2 ) \u2264 1 + pn\u22121 /2 \u2212 pn /2 = 1 \u2212 \u03ba0 .\nThus, we have proven that when S, T only differ at i\n\u0002\n\u0003\nE d1 (S1 , S2 ) \u2264 2 \u00d7 (pi\u22121 /2 + pi+1 /2) + 0 \u00d7 pi + 1 \u00d7 (1 \u2212 pi \u2212 pi\u22121 /2 \u2212 pi+1 /2)\n\n(5)\n\n\u2264 (1 \u2212 \u03ba0 ) \u00d7 1 = (1 \u2212 \u03ba0 )d1 (S, T ).\n\nWhat makes Ricci curvature very useful is that if this inequality holds for pairs of neighbours\nthen it holds for any pair, as noticed in [3]. Indeed, take k + 1 paths S0 = S, S1 , . . . , Sk = T as\nin Lemma 4 and apply the triangular inequality for d1 :\nE [d1 (\u03c6(S, I, E), \u03c6(T, I, E))] \u2264\n\nk\u22121\nX\n\nE [d1 (\u03c6(Si , I, E), \u03c6(Si+1 , I, E))]\n\ni=0\n\n\u2264 (1 \u2212 \u03ba0 )k = (1 \u2212 \u03ba0 )d1 (S, T ).\n\nRemark 6. It is easy to exhibit some \u0002S, T such that\n\u0003 ineq. (5) is in fact an equality. In the case\nwhere pi = 1/n, this equality reads E d1 (S1 , S2 ) = d1 (S, T ), and we cannot obtain a positive\nRicci curvature (though this does not prove that there is not another coupling or another distance\nfor which we could get a \u03ba > 0 in the case pi = 1/n.).\nWe recall that for each family An , diam(An ) = max d1 (S, T) \u2264 n(n+1)/2. Hence, combining\nProposition 5with Eq. (4) gives our main result:\nTheorem 7. For meanders, excursions and path with walls, Algorithm 1 returns an almost\nuniform sample of \u03c0, as soon as T \u226b n3 . Precisely, for any itinialization of Algorithm 1,\n\u0012\n\u0013\nn(n + 1)\n3\nk S(T ) \u2212 \u03c0 kTV \u2264 diam(An )(1 \u2212 \u03ba)T \u2264\nexp \u2212 2\nT .\n2\n2n (n + 1)\n7\n\n\fAnother formulation of this result is that the mixing time of the associated Markov chain,\ndefined as usual by\n\u001b\n\u001a\nt\n\u22121\n(6)\ntmix := inf t \u2265 0 ; sup k P \u03b4v \u2212 \u03c0 kTV \u2264 e\nv\u2208V\n\n2\n\n\u22121\n\n(e is here by convention), is smaller than n (n+ 1) log n. For culminating paths, the argument\nof Case 1c fails and (5) does not hold, we are not able to prove such a result as Theorem 7.\nHowever, it seems empirically that the mixing time is also of order n3 log n (with a constant\nstrongly dependent on a, b). A way to prove this could be the following observation: take\n(S0 , T0 ) = (S, T) two any culminating paths, and define\n(St+1 , Tt+1 ) = (\u03c6(St , It , \u03b5t , \u03b4t ), \u03c6(Tt , It , \u03b5t , \u03b4t )),\nwhere It , \u03b5t , \u03b4t are those in Algorithm 1. The sequence (k St \u2212 Tt k\u221e )t is decreasing throughout\nthe process. Unfortunately we cannot get a satisfactory bound for the time needed for this\nquantity to decrease by one.\n\n3.2\n\nRelated works\n\nBounding mixing times via a contraction property over the transportation metric is quite a\nstandard technique, the main ideas dating back to Dobrushin (1950's). A modern introduction\nis made in [10]. For geodesic spaces, this technique has been developped in [3] under the name\npath coupling.\nAs mentioned in the introduction, the Markov chain P on lattice paths with uniform weights\npi = 1/n has in fact already been introduced for paths starting and ending at zero (sometimes\ncalled bridges) in [11], and its mixing time has been estimated in [14]. Wilson also proves a\nmixing time of order n3 log n, by showing that (3) holds with a different distance (namely, a\nkind of Fourier transform of the heights of the paths)2 . This is the concavity of this Fourier\ntransform which gives a good mixing time, exactly as the concavity of our pi 's speeds up the\nconvergence of our chain.\nWilson's method is developped only for bridges in [14] and it is not completely straightforward to use it when the endpoints are not fixed. For instance, take n = 7 and a = b = 1, and\nconsider the paths + + + \u2212 \u2212 + + and \u2212 \u2212 \u2212 + + \u2212 \u2212. There are more \"bad moves\" (moves\nthat take away these paths) than \"good moves\".\n\n4\n\nCoupling From The Past with P\n\nPropp-Wilson's Coupling From The Past (CFTP) [13] is a very general procedure for the exact sampling of the stationary distribution of a Markov chain. It is efficient if the chain is\nmonotonous with respect to a certain order relation \u0016 on the set V of vertices, with two extremal points denoted 0\u0302, 1\u0302 (i.e. such that 0\u0302 \u0016 x \u0016 1\u0302 for any vertex x). This is the case here for\neach family Cn ,Wn ,En ,Mn , with the partial order\nS \u0016 T iff Si \u2264 Ti for any i.\nFor the family M10 with a = 1, b = \u22122 for instance, we have\n0\u0302 = 0\u0302meanders = (1, 1, \u22122, 1, 1, \u22122, 1, 1, \u22122, 1),\n1\u0302 = 1\u0302meanders = (1, 1, 1, 1, 1, 1, 1, 1, 1, 1).\n2 Notice that a, b do not have the same meaning in Wilson's paper: a (resp. b) stands for the number of\npositive (resp. negative) steps.\n\n8\n\n\fWe describe CFTP, with our notations, in Algorithm 2.\nAlgorithm 2 CFTP: Exact sampling of a path in An\nS \u2190 0\u0302, T \u2190 1\u0302\n. . . , I\u22122 , I\u22121 \u2190 i.i.d. r.v. with law p\n. . . , \u03b5\u22122 , \u03b5\u22121 \u2190 i.i.d. uniform r.v. in {\u2191, \u2193}\n. . . , \u03b4\u22122 , \u03b4\u22121 \u2190 i.i.d. uniform r.v. in {+, \u2212}\n\u03c4 =1\nrepeat\nS \u2190 0\u0302, T \u2190 1\u0302\nfor t = \u2212\u03c4 to 0 do\nif \u03c6(S, It , \u03b5t ) is in An then S \u2190 \u03c6(S, It , \u03b5t )\u03b4t\nif \u03c6(T, It , \u03b5t ) is in An then T \u2190 \u03c6(T, It , \u03b5t )\u03b4t\nend for\n\u03c4 \u2190 2\u03c4\nuntil S = T\nWe refer to ([8],Chap.10) for a very clear introduction to CFTP, and we only outline here\nthe reasons why this indeed gives an exact sampling of the stationary distribution.\n\u2022 The output of the algorithm (if it ever ends!) is the state of the chain P that has been\nrunning \"since time \u2212\u221e\", and thus has reached stationnarity.\n\u2022 The exit condition S = T ensures that it is not worth running the chain from T steps\nearlier, since the trajectory of any lattice path 0\u0302 \u0016 R \u0016 1\u0302 is \"sandwiched\" between those\nof 0\u0302, 1\u0302, and therefore ends at the same value.\n\nFigure 3: A sketchy representation of CFTP : trajectories starting from 0\u0302, 1\u0302 at time \u2212T /2 don't\nmeet before time zero, while those starting at time \u2212T do.\n\nProposition 8. Algorithm 2 ends with probability 1 and returns an exact sample of the uniform\ndistribution over An . For the families Wn ,En ,Mn , this takes on average O(n3 (log n)2 ) time\nunits.\nLet us mention that in the case where the mixing time is not rigorously known, Algorithm\n2 (when it ends) outputs an exact uniform sample and therefore is of main practical interest\ncompared to MCMC.\nProof of Proposition 8. It is shown in [13] that Algorithm 2 returns an exact sampling in\nO(tmix log H) runs of the chain, where tmix is defined in (6) and H is the length of the longest\nchain of states between 0\u0302 and 1\u0302. It is a consequence of the proof of Lemma 4 that H = O(n2 ).\nWe have seen that tmix = O(n3 log n). (Recall that each test in Algorithm 2 takes, on average,\nO(1) time units.)\n9\n\n\fWe recall that CFTP has a major drawback compared to MCMC. For the algorithm to be\ncorrect, we have to reuse the same random variables It , \u03b5t , \u03b4t , so that space-complexity is in fact\nlinear in n3 (log n)2 . This may become an issue when n is large.\n\n5\n\nConcluding remarks and simulations\n\n1. In Fig.4, we show simulations of the three kinds of paths, for a = 1, b = 2, n = 600.\nWe observe that the final height of the culminating path is very low (about 30), it would be\ninteresting to use our algorithm to investigate the behaviour of this height when n \u2192 \u221e ; this\nquestion was left open in [2].\n\nFigure 4: (Almost) uniform paths of length 600, with a = 1, b = 2. From top to bottom: a\nculminating path, a meander, a path with wall (shown by an arch).\n2. One may wonder to what extent this work applies to other families An of paths. The main\nassumption is that the family of paths should be a geodesic space w.r.t. distance d1 . This is\ntrue for example if the following condition on An is fulfilled:\n(R, T \u2208 An and R \u0016 S \u0016 T ) \u21d2 S \u2208 An .\nNotice however that this is quite a strong requirement, and it is not verified for culminating\npaths for instance.\n3. A motivation to sample random paths is to make and test guesses for some functionals of these\npaths, taken on average overP\nAn . Consider a function f : An \u2192 R, we want an approximate\nvalue of \u03c0(f ) := card(An )\u22121 s\u2208An f (s), if the exact value is out of reach by calculation. We\n10\n\n\festimate this quantity by\n\u03c0\u0302(f ) :=\n\nT\n1 X\nf (S(t)) ,\nT t=1\n\n(7)\n\n(recall that S(t) is the value of the chain at time t). For Algorithm 1 to be efficient in practice,\nwe have to bound\nP (|\u03c0(f ) \u2212 \u03c0\u0302(f )| > r) ,\n(8)\nfor any fixed r > 0, by a non-asymptotic (in T ) quantity. This can be done with ([9], Th.4-5),\nin which one can find concentration inequalities for (8). The sharpness of these inequalities\ndepends on \u03ba and on the geometrical structure of An .\nAknowledgements. Many thanks to Fr\u00e9d\u00e9rique Bassino and the other members of Anr\nGamma for the support ; I also would like to thank \u00c9lie Ruderman for the English corrections.\nA referee raised a serious error in the first version of this paper, I am grateful to them.\n\nReferences\n[1] C. Banderier and Ph. Flajolet. Basic Analytic Combinatorics of Directed Lattice Paths,\nTheoretical Computer Science 281 (1):37-80 (2002).\n[2] M.Bousquet-M\u00e9lou and Y. Ponty. Culminating paths, Discrete Math and Theoretical Computer Science 10 (2):125-152 (2008).\n[3] R.Bubley and M. Dyer. Path coupling: A technique for proving rapid mixing in Markov\nchains. Proceedings of the 38th Annual Symposium on Foundations of Computer Science,\np.223-231 (1997).\n[4] N.Destainville. Flip dynamics in octagonal rhombus tiling sets, Physical Review Letters 88\n(2002).\n[5] P.Diaconis and D.W.Stroock. Geometric Bounds for Eigenvalues of Markov Chains, Annals\nof Applied Probability 1 (1):36-61 (1991).\n[6] Ph.Duchon. On the enumeration and generation of generalized Dyck words. Discrete Mathematics 225 (1-3)121\u2013135 (2000).\n[7] M.E.Fisher. Walks, Walls, Wetting, and Melting. Journal of Statistical Physics 34 (5):667729 (1984).\n[8] O.H\u00e4ggstr\u00f6m. Finite Markov Chains and Algorithmic Applications. London Mathematical\nSociety (2002).\n[9] A.Joulin and Y.Ollivier. Curvature, concentration, and error estimates for Markov chain\nMonte Carlo. To appear in Annals of Probability, arXiv:0904.1312 (2009).\n[10] D.A.Levin, Y.Peres, and E.L.Wilmer. Markov Chains and Mixing Times. American Mathematical Society (2009).\n[11] M.Luby, D.Randall, A.Sinclair. Markov chain algorithms for planar lattice structures. SIAM\nJournal on Computing, 31 (1):167\u2013192 (2001).\n[12] Y.Ollivier. Ricci curvature of Markov chains on metric spaces. Journal of Functional Analysis 256 (3):810-864 (2009).\n11\n\n\f[13] J.G. Propp and D.B. Wilson. Exact sampling with coupled Markov chains and applications\nto statistical mechanics. Random Structures and Algorithms, 9 (1):223-252, (1996).\n[14] D.B.Wilson. Mixing times of Lozenge tiling and card shuffling Markov chains. Annals of\nApplied Probability 14 (1):274\u2013325 (2004).\n\n12\n\n\f"}