{"id": "http://arxiv.org/abs/1005.4379v1", "guidislink": true, "updated": "2010-05-24T17:03:47Z", "updated_parsed": [2010, 5, 24, 17, 3, 47, 0, 144, 0], "published": "2010-05-24T17:03:47Z", "published_parsed": [2010, 5, 24, 17, 3, 47, 0, 144, 0], "title": "A Meta-Programming Approach to Realizing Dependently Typed Logic\n  Programming", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1005.4395%2C1005.2536%2C1005.1321%2C1005.4379%2C1005.2594%2C1005.0978%2C1005.4576%2C1005.5573%2C1005.3664%2C1005.4425%2C1005.0356%2C1005.2526%2C1005.5234%2C1005.0162%2C1005.0111%2C1005.3505%2C1005.4183%2C1005.2650%2C1005.0242%2C1005.1998%2C1005.2278%2C1005.3060%2C1005.2527%2C1005.0503%2C1005.5576%2C1005.3583%2C1005.3377%2C1005.0118%2C1005.3093%2C1005.3200%2C1005.4037%2C1005.1768%2C1005.4529%2C1005.4661%2C1005.1269%2C1005.2190%2C1005.0914%2C1005.1799%2C1005.5464%2C1005.4561%2C1005.1738%2C1005.1574%2C1005.1325%2C1005.1498%2C1005.0729%2C1005.2906%2C1005.3634%2C1005.2359%2C1005.0923%2C1005.0775%2C1005.4184%2C1005.3658%2C1005.2030%2C1005.2880%2C1005.4626%2C1005.0210%2C1005.4502%2C1005.3890%2C1005.5126%2C1005.2892%2C1005.4479%2C1005.1960%2C1005.4004%2C1005.2407%2C1005.2172%2C1005.1908%2C1005.2514%2C1005.0631%2C1005.3070%2C1005.1173%2C1005.2392%2C1005.5341%2C1005.5236%2C1005.0993%2C1005.3504%2C1005.5265%2C1005.5418%2C1005.1281%2C1005.4258%2C1005.1206%2C1005.2711%2C1005.5197%2C1005.5285%2C1005.2130%2C1005.3944%2C1005.0632%2C1005.3938%2C1005.1644%2C1005.5355%2C1005.3029%2C1005.1155%2C1005.2830%2C1005.4794%2C1005.2613%2C1005.5321%2C1005.0904%2C1005.5174%2C1005.2083%2C1005.4989%2C1005.5624%2C1005.5557&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Meta-Programming Approach to Realizing Dependently Typed Logic\n  Programming"}, "summary": "Dependently typed lambda calculi such as the Logical Framework (LF) can\nencode relationships between terms in types and can naturally capture\ncorrespondences between formulas and their proofs. Such calculi can also be\ngiven a logic programming interpretation: the Twelf system is based on such an\ninterpretation of LF. We consider here whether a conventional logic programming\nlanguage can provide the benefits of a Twelf-like system for encoding type and\nproof-and-formula dependencies. In particular, we present a simple mapping from\nLF specifications to a set of formulas in the higher-order hereditary Harrop\n(hohh) language, that relates derivations and proof-search between the two\nframeworks. We then show that this encoding can be improved by exploiting\nknowledge of the well-formedness of the original LF specifications to elide\nmuch redundant type-checking information. The resulting logic program has a\nstructure that closely resembles the original specification, thereby allowing\nLF specifications to be viewed as hohh meta-programs. Using the Teyjus\nimplementation of lambdaProlog, we show that our translation provides an\nefficient means for executing LF specifications, complementing the ability that\nthe Twelf system provides for reasoning about them.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1005.4395%2C1005.2536%2C1005.1321%2C1005.4379%2C1005.2594%2C1005.0978%2C1005.4576%2C1005.5573%2C1005.3664%2C1005.4425%2C1005.0356%2C1005.2526%2C1005.5234%2C1005.0162%2C1005.0111%2C1005.3505%2C1005.4183%2C1005.2650%2C1005.0242%2C1005.1998%2C1005.2278%2C1005.3060%2C1005.2527%2C1005.0503%2C1005.5576%2C1005.3583%2C1005.3377%2C1005.0118%2C1005.3093%2C1005.3200%2C1005.4037%2C1005.1768%2C1005.4529%2C1005.4661%2C1005.1269%2C1005.2190%2C1005.0914%2C1005.1799%2C1005.5464%2C1005.4561%2C1005.1738%2C1005.1574%2C1005.1325%2C1005.1498%2C1005.0729%2C1005.2906%2C1005.3634%2C1005.2359%2C1005.0923%2C1005.0775%2C1005.4184%2C1005.3658%2C1005.2030%2C1005.2880%2C1005.4626%2C1005.0210%2C1005.4502%2C1005.3890%2C1005.5126%2C1005.2892%2C1005.4479%2C1005.1960%2C1005.4004%2C1005.2407%2C1005.2172%2C1005.1908%2C1005.2514%2C1005.0631%2C1005.3070%2C1005.1173%2C1005.2392%2C1005.5341%2C1005.5236%2C1005.0993%2C1005.3504%2C1005.5265%2C1005.5418%2C1005.1281%2C1005.4258%2C1005.1206%2C1005.2711%2C1005.5197%2C1005.5285%2C1005.2130%2C1005.3944%2C1005.0632%2C1005.3938%2C1005.1644%2C1005.5355%2C1005.3029%2C1005.1155%2C1005.2830%2C1005.4794%2C1005.2613%2C1005.5321%2C1005.0904%2C1005.5174%2C1005.2083%2C1005.4989%2C1005.5624%2C1005.5557&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Dependently typed lambda calculi such as the Logical Framework (LF) can\nencode relationships between terms in types and can naturally capture\ncorrespondences between formulas and their proofs. Such calculi can also be\ngiven a logic programming interpretation: the Twelf system is based on such an\ninterpretation of LF. We consider here whether a conventional logic programming\nlanguage can provide the benefits of a Twelf-like system for encoding type and\nproof-and-formula dependencies. In particular, we present a simple mapping from\nLF specifications to a set of formulas in the higher-order hereditary Harrop\n(hohh) language, that relates derivations and proof-search between the two\nframeworks. We then show that this encoding can be improved by exploiting\nknowledge of the well-formedness of the original LF specifications to elide\nmuch redundant type-checking information. The resulting logic program has a\nstructure that closely resembles the original specification, thereby allowing\nLF specifications to be viewed as hohh meta-programs. Using the Teyjus\nimplementation of lambdaProlog, we show that our translation provides an\nefficient means for executing LF specifications, complementing the ability that\nthe Twelf system provides for reasoning about them."}, "authors": ["Zachary Snow", "David Baelde", "Gopalan Nadathur"], "author_detail": {"name": "Gopalan Nadathur"}, "author": "Gopalan Nadathur", "links": [{"href": "http://arxiv.org/abs/1005.4379v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1005.4379v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "D.3.2; F.4.1", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1005.4379v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1005.4379v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:1005.4379v1 [cs.LO] 24 May 2010\n\nA Meta-Programming Approach to Realizing\nDependently Typed Logic Programming\nZachary Snow\n\nDavid Baelde\n\nGopalan Nadathur\n\nComputer Science and Engineering\nUniversity of Minnesota\n200 Union Street SE\nMinneapolis, MN 55455\nsnow@cs.umn.edu\n\nComputer Science and Engineering\nUniversity of Minnesota\n200 Union Street SE\nMinneapolis, MN 55455\ndbaelde@cs.umn.edu\n\nComputer Science and Engineering\nUniversity of Minnesota\n200 Union Street SE\nMinneapolis, MN 55455\ngopalan@cs.umn.edu\n\nAbstract\nDependently typed \u03bb-calculi such as the Logical Framework (LF)\ncan encode relationships between terms in types and can naturally\ncapture correspondences between formulas and their proofs. Such\ncalculi can also be given a logic programming interpretation: the\nTwelf system is based on such an interpretation of LF. We consider here whether a conventional logic programming language can\nprovide the benefits of a Twelf-like system for encoding type and\nproof-and-formula dependencies. In particular, we present a simple\nmapping from LF specifications to a set of formulas in the higherorder hereditary Harrop (hohh) language, that relates derivations\nand proof-search between the two frameworks. We then show that\nthis encoding can be improved by exploiting knowledge of the wellformedness of the original LF specifications to elide much redundant type-checking information. The resulting logic program has a\nstructure that closely resembles the original specification, thereby\nallowing LF specifications to be viewed as hohh meta-programs.\nUsing the Teyjus implementation of \u03bbProlog, we show that our\ntranslation provides an efficient means for executing LF specifications, complementing the ability that the Twelf system provides\nfor reasoning about them.\nCategories and Subject Descriptors D.3.2 [Programming Languages]: Language Classifications- Constraint and logic languages; F.4.1 [Mathematical Logic and Formal Languages]: Mathematical Logic- Lambda calculus and related systems, Logic and\nconstraint programming, Proof theory\nGeneral Terms\n\nTheory, Languages\n\nKeywords logical frameworks, dependently typed lambda calculi,\nhigher-order logic programming, translation\n\n1. Introduction\nThere is a significant, and growing interest in mechanisms for specifying, prototyping and reasoning about formal systems that are described by syntax-directed rules. Dependently typed \u03bb-calculi such\nas the Logical Framework (LF) [11] provide many conveniences\n\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. To copy otherwise, to republish, to post on servers or to redistribute\nto lists, requires prior specific permission and/or a fee.\nPPDP'10, July 26\u201328, 2010, Hagenberg, Austria.\nCopyright c 2010 ACM 978-1-4503-0132-9/10/07. . . $10.00\n\nfrom a specification perspective in this context. Such calculi facilitate the use of a higher-order approach to describing the syntax of formal objects and they allow relationships between terms\nto be captured in an elegant way through type dependencies. Furthermore, dependently typed \u03bb-calculi enjoy a well-known isomorphism between formulas and types [12], leading to a unification of\nthe concept of a proof of a formula with an inhabitant of a given\ntype. Thus, the search for type inhabitants can be identified with\nproof-search and can thereby be given a logic programming interpretation. The Twelf system [19] that we consider here exploits\nthese possibilities relative to LF. As such, it has been used successfully in specifying and prototyping varied formal systems, and\nmechanisms have also been built into it to reason about specifications.\nPredicate logics are also capable of encoding syntax-directed\nspecifications, and provide the basis for logic programming languages in the familiar tradition of Prolog. Within this framework,\nthe logic of higher-order hereditary Harrop (hohh) formulas [15]\nthat underlies the language \u03bbProlog [16] provides a builtin ability to treat binding notions in syntax and thus has particular usefulness in representing formal systems. However, unlike LF, this\nlogic cannot reflect dependencies between objects into types and\ndoes not directly represent the relationship between formulas and\ntheir proofs. While such correspondences can always be encoded\nby hand through auxiliary predicate definitions, it is of interest\nto understand if a systematic encoding is possible. A specific\nform to this question is if Twelf specifications can be translated\ninto \u03bbProlog programs, allowing such specifications to be seen as\n\u03bbProlog \"meta-programs.\" There are benefits to such a possibility:\nthe convenience of writing specifications using dependent types can\nbe combined with the ability both to execute them via an efficient\n\u03bbProlog implementation, and to reason about them using logics and\nsystems meant for analyzing hohh descriptions [2, 7, 10, 14].\nA partial answer to the question raised above has been provided\nby Felty, who described a translation of LF specifications to hohh\nformulas and then showed that LF derivations correspond exactly\nto hohh derivations of the translated LF judgment [5, 6]. The focus\non matching derivations allows Felty to assume the existence of\na complete LF judgment, and, in particular, of an LF object in\nher translation. However, this assumption is inappropriate in our\ncontext, given that we are interested in constructing proof terms\nthat show particular types are inhabited, i.e., in proof search that\nplays a fundamental role in the logic programming setting. We\ntherefore refine the earlier mapping to remove this assumption and\nshow that the resulting translation preserves derivability in a sense\nrelevant to the logic programming interpretation; an important part\nof our proof is showing how to extract an LF object satisfying\n\n\fa type from a derivation constructed using the hohh version of\nthe specification. Our first encoding may include redundant typechecking judgments which obscure the translated specification and\ncan result in poor execution behavior. We design conditions for\neliminating some of these judgments, resulting in an improved\ntranslation that corresponds closely to the intention of the orginal\nLF specification. This part of our work relies on an analysis of the\nstructure of LF expressions and also has relevance, for example,\nto providing compact representations of proof terms. Finally, we\ndemonstrate that the execution of the translated form by means of\nthe Teyjus implementation [9] of \u03bbProlog [16] provides an effective\nmeans for animating Twelf programs.\nIn the next two sections, we describe a relevant fragment of the\nhohh logic and the Twelf specification language. Section 4 then\npresents our first translation. In the following section, we describe\nand exploit a property of LF expressions and type-checking to refine the earlier translation, producing a more efficient and transparent version. Section 6 provides experimental data towards supporting the use of this translation as a means for executing Twelf programs. We conclude the paper with a discussion of related work and\npossible future directions. This work has been developed in [24];\nwe refer the reader to that document for complete proofs and more\ndetailed discussions.\n\n2. A Higher-Order Predicate Logic for\nDescribing Computations\nThe logic of hohh formulas is based on an intuitionistic version\nof Church's simple theory of types [4]. Both logics are built over\na typed form of the \u03bb-calculus. The types are constructed using\n\u2192, the infix, right associative function type constructor, starting\nfrom a finite collection of atomic types that includes o, the type of\npropositions, and at least one other type.1 We assume that we are\ngiven sets of variables and constants, each with an associated type.\nThe full collection of (typed) terms is generated from these by the\nusual abstraction and (left associative) application operators. Terms\nthat differ only in the names of their bound variables are not distinguished. We further assume a notion of equality between terms\nthat is generated by \u03b2- and \u03b7-reduction. It is well-known that every term has a unique normal form under these reduction operations in this simply-typed setting. All terms are to be converted into\nsuch a form prior to their consideration in any context. We write\nt[s1 /x1 , . . . , sn /xn ] to denote the result of simultaneously replacing the variables x1 , . . . , xn with the terms s1 , . . . , sn in the term\nt, renaming bound variables as needed to avoid accidental capture.\nThis substitution operation is defined only when si and xi are of\nthe same type for 1 \u2264 i \u2264 n.\nWe will use only a fragment of the full hohh logic here; this\nfragment still possesses the proof-theoretic properties that are fundamental to the logic programming interpretation of the hohh logic.\nThe constants from which terms are constructed are differentiated\ninto nonlogical ones that constitute a signature and logical ones.\nWe do not permit o to appear in the type of the arguments of nonlogical constants and variables. The logical constants are restricted\nto \u22a4 of type o, \u2283 of type o \u2192 o \u2192 o that is written in the customary infix form and, for each type \u03b1, \u03a0 of type (\u03b1 \u2192 o) \u2192 o. \u03a0\nrepresents the universal quantifier as a function over sets. We abbreviate \u03a0 (\u03bbx.F ) by \u2200x.F . An atomic formula, denoted by A, is\na term of type o of the form p t1 . . . tn where p is a nonlogical\nconstant. The logic of interest is characterized by two collections\nof terms called G- and D-formulas that are defined mutually recursively by the following syntax rules:\n1 Other, non-interpreted type constructors can be added but are not discussed here for simplicity.\n\nG\nD\n\n:=\n:=\n\n\u22a4 | A | D \u2283 G | \u2200x.G\nA | G \u2283 D | \u2200x.D\n\nA specification or logic program is a finite collection of closed Dformulas that are also called program clauses and a goal or a query\nis a closed G-formula.\nComputation corresponds to searching for a derivation of a sequent of the form \u03a3; \u0393 \u2212\u2192 G where \u03a3 is the initial (language) signature, \u0393 is a logic program and G is a goal. Figure 1 presents the\nrules for constructing such a derivation. Read in a proof search direction, the \u2200R rule leads to an expansion of the signature in the sequent whose derivation is sought and the \u2283 R rule similarly causes\nan addition to the logic program. The expression \"t is a \u03a3-term\" in\nthe \u2200L rule means that t is a closed term all of whose nonlogical\nconstants are contained in \u03a3. The derivation rules manifest a goaldirected character: to find a derivation for \u03a3; \u0393 \u2212\u2192 G, we simplify\nG based on its logical structure and then use the decide rule to select\na formula from the logic program for solving an atomic goal. Notice also that the decide rule initiates the consideration of a focused\nsequence of rules that is similar to backchaining.2 In particular, if\nthe formula selected from \u0393 has the structure\n(\u2200x1 .F1 \u2283 . . . \u2283 \u2200xn .(Fn \u2283 A\u2032 ) . . .)\nthen this sequence is equivalent to the rule\n\u03a3; \u0393 \u2212\u2192 F1\u2032\n\n...\n\u03a3; \u0393 \u2212\u2192 Fn\u2032\nbackchain\n\u03a3; \u0393 \u2212\u2192 A\n\nwhich has the proviso that for some \u03a3-terms t1 , . . . , tn that have\nthe same types as x1 , . . . , xn , respectively, it is the case that A is\nequal to A\u2032 [t1 /x1 , . . . , tn /xn ] and, for 1 \u2264 i \u2264 n, Fi\u2032 is equal to\nFi [t1 /x1 , . . . , ti /xi ].\nThe logic that we have described has been given an efficient implementation in the Teyjus system [9]. It is possible also to reason\nin sophisticated ways about specifications that are constructed using it. To begin with, the logic has strong meta-theoretic properties\narising from the fact that derivability in it corresponds exactly to intuitionistic provability. Moreover, it is possible to construct logics\nincorporating mechanisms such as induction to reason powerfully\nabout what does and does not follow from a given specification\n[1, 8, 10, 14]. In fact, systems such as Abella [7] and Tac [2] have\nbeen constructed to provide computer support for such reasoning.\n\n3. Logic Programming Using the Twelf\nSpecification Language\nThere are three categories of expressions in LF: kinds, types or type\nfamilies that are classified by kinds and objects or terms that are\nclassified by types. We assume two denumerable sets of variables,\none for objects and the other for types. We use x and y to denote\nobject variables, u and v to denote type variables and w to denote\neither. Letting K range over kinds, A and B over types, and M and\nN over object terms, the syntax of LF expressions is given by the\nfollowing rules:\nK\nA\nM\n\n:=\n:=\n:=\n\nType | \u03a0x:A.K\nu | \u03a0x:A.B | \u03bbx:A.B | A M\nx | \u03bbx:A.M | M N\n\nExpressions of any of these kinds will be denoted by P and Q.\nHere, \u03a0 and \u03bb are operators that associate a type with a variable\n2 For\n\nthe reader unfamiliar with such presentations, the expression\nD\n\n\u03a3; \u0393 \u2212\u2192 A corresponds essentially to the selection of the program clause\nD as the one to backchain on. This then leads to instantiations of universally\nquantified variables and to the solution of the \"body\" goals of the clause using the rules \u2200L and \u2283 L, culminating eventually in solving the atomic goal\nby matching it with the head of the clause using the init rule.\n\n\f\u03a3; \u0393 \u2212\u2192 \u22a4\n\nc\u2208\n/ \u03a3 \u03a3 \u222a {c}; \u0393 \u2212\u2192 G[c/x]\n\u2200R\n\u03a3; \u0393 \u2212\u2192 \u2200x.G\n\n\u03a3; \u0393 \u222a {D} \u2212\u2192 G\n\u2283R\n\u03a3; \u0393 \u2212\u2192 D \u2283 G\n\n\u22a4R\n\nD\n\nD \u2208 \u0393 \u03a3; \u0393 \u2212\u2192 A\ndecide\n\u03a3; \u0393 \u2212\u2192 A\nD[t/x]\n\nt is a \u03a3-term\n\n\u03a3; \u0393 \u2212\u2192 A\n\u2200x.D\n\n\u2200L\n\ninit\n\nA\n\n\u03a3; \u0393 \u2212\u2192 A\n\n\u03a3; \u0393 \u2212\u2192 G\n\nD\n\n\u03a3; \u0393 \u2212\u2192 A\nG\u2283D\n\n\u2283L\n\n\u03a3; \u0393 \u2212\u2192 A\n\n\u03a3; \u0393 \u2212\u2192 A\n\nFigure 1. Derivation rules for the hohh logic\nand bind its free occurrences over the expression after the period.\nTerms that differ only in the names of bound variables are identified. As with the hohh logic, P [N1 /x1 , . . . , Nn /xn ] denotes a\nsimultaneous substitution with renaming to avoid variable capture.\nWe write A \u2192 P for \u03a0x:A.P when x does not appear free in P .\n\u2212\n\u2212\u2192\nWe abbreviate \u03a0x1 :A1 . . . . \u03a0xn :An .P by \u03a0x:A.P .\nLF expressions are equipped with a notion of \u03b2-reduction defined through the rule (\u03bbx:A.P ) N \u2192\u03b2 P [N/x]. All LF expressions that are well-formed in the sense formalized below normalize strongly under this reduction relation [11]. Moreover any welltyped expression P has a unique normal form up to changes in\nbound variable names. We denote this normal form by P \u03b2 .\nThe type correctness of LF expressions is assessed relative to\ncontexts that are finite collections of assignments of types and kinds\nto variables. Formally, contexts, denoted by \u0393, are given by the rule\n\u0393\n\n:=\n\n* | \u0393, u : K | \u0393, x : A\n\nHere, * denotes the empty collection. We write dom(\u0393) to denote\nthe variables with assignments in \u0393. We are concerned with assertions of the following four forms:\n\u22a2 \u0393 ctx\n\n\u0393 \u22a2 K kind\n\n\u0393 \u22a2 A:K\n\n\u0393 \u22a2 M :A\n\nThe first assertion signifies that \u0393 is a well-formed context. The\nremaining assertions mean respectively that, relative to a (wellformed) context \u0393, K is a well-formed kind, A is a well-formed\ntype of kind K and M is a well-formed object of type A. Figure 2\npresents the rules for deriving such assertions. Notice that for a\ncontext to be well-formed it must not contain multiple assignments\nto the same variable. To adhere to this requirement, bound variable\nrenaming may be entailed in the use of the pi-kind, pi-fam, abs-fam\nand abs-obj rules. The inference rules allow for the derivation of an\nassertion of the form \u0393 \u22a2 M : A only when A is in normal form.\nTo verify such an assertion when A is not in normal form, we first\nderive \u0393 \u22a2 A : Type and then verify \u0393 \u22a2 M : A\u03b2 . A similar\nobservation applies to \u0393 \u22a2 A : K.\nA variable w that appears in an LF expression P that is wellformed with respect to a context \u0393 has a kind or type of kind\nType associated with it through either an assignment in \u0393 or a\nbinding operator. Moreover, the normal form of this kind or type\nmust have a prefix of \u03a0s. If the length of this prefix is n, then an\noccurrence of w is fully applied if it appears in a subterm of the\nform w M1 . . . Mn . Further, P is canonical with respect to \u0393 if\nit is in normal form and if every variable occurrence in it is fully\napplied. A well-formed context \u0393 is canonical if the type or kind it\nassigns to each variable is canonical relative to \u0393. A well-formed\ntype of the form u M1 . . . Mn that is fully applied is called a base\ntype. The LF system admits a notion of \u03b7-expansion using which\nany well-formed expression can be converted into a canonical form.\nIn later sections we shall consider LF derivations in which\nall expressions in the end assertion are in normal form. Notice\nthat every expression in the entire derivation must then also be in\nsuch a form. This in turn means that in judgments of the forms\n\n(\u03bbx:A.B) : (\u03a0x:A\u2032 .K) and (\u03bbx:A.M ) : (\u03a0x:A\u2032 .B) it must be\nthe case that A and A\u2032 are identical. Finally, normalization need not\nbe considered in the use of the var-fam and var-obj rules.\nThe following \"transitivity\" property for LF derivations that\nfollows easily from the results in [11] will be useful later; here\n\u03b1 stands for any judgment, and substitution and normalization\nover \u03b1 and \u0393 corresponds to distributing these operations to the\nexpressions appearing in them.\nProposition 1 (Substitution). Let \u03931 , \u03932 be canonical contexts,\nand A be a type in canonical form. If \u03931 \u22a2 M : A has a derivation,\nand \u03931 , x : A, \u03932 \u22a2 \u03b1 has a derivation, then \u03931 , (\u03932 [M/x])\u03b2 \u22a2\n(\u03b1[M/x])\u03b2 has a derivation as well.\nAdditionally we will use a second property of LF derivations,\nwhich follows from Proposition 1.\nProposition 2 (Renaming). Let P be a canonical type or kind,\n\u0393 = \u03931 , x : P, \u03932 be a canonical context, and \u03b1 a canonical\njudgment. Let y be a variable not bound in \u0393, and not occurring\nin \u03b1. Then \u03931 , x : P, \u03932 \u22a2 \u03b1 has a derivation if and only if\n\u03931 , y : P, \u03932 [y/x] \u22a2 \u03b1[y/x] has one.\nThe logic programming interpretation of LF is based on viewing\ntypes as formulas. More specifically, a specification or program in\nthis setting is given by a context. This starting context, also called\na signature, essentially describes the vocabulary for constructing\ntypes and asserts the existence of particular inhabitants for some of\nthese types. Against this backdrop, questions can be asked about\nthe existence of inhabitants for certain other types. Formally, this\namounts to asking if an assertion of the form \u0393 \u22a2 M : A has\na derivation. However, the object M is left unspecified-it is to\nbe extracted from a successful derivation. Thus, the search for a\nderivation of the assertion is driven by the structure of A and the\ntypes available from the context.\nA concrete illustration of the paradigm is useful for later discussions.3 Consider a signature or context \u0393 comprising the following\nassignments in sequence:\nnat : Type\nz : nat\ns : nat \u2192 nat\nlist : Type\nnil : list\ncons : nat \u2192 list \u2192 list\nappend : list \u2192 list \u2192 list \u2192 Type\nappN il : \u03a0K:list.append nil K K\nappCons : \u03a0X:nat.\u03a0L:list.\u03a0K:list.\u03a0M :list.\n3 The\n\nexample of appending lists has been chosen here for its conciseness\nand because it allows for an easy connection with more traditional forms\nof logic programming. The primary application domain of Twelf is in\nspecifying (and reasoning about) formal systems such as evaluators and\ninterpreters for languages, type assignment calculi and proof systems. This\norientation informs the choice of benchmarks used in Section 6.\n\n\f\u22a2 * ctx\n\nnull-ctx\n\n\u0393 \u22a2 K kind \u22a2 \u0393 ctx u \u2208\n/ dom(\u0393)\nkind-ctx\n\u22a2 \u0393, u : K ctx\n\u0393 \u22a2 A : Type \u22a2 \u0393 ctx x \u2208\n/ dom(\u0393)\ntype-ctx\n\u22a2 \u0393, x : A ctx\n\u22a2 \u0393 ctx\ntype-kind\n\u0393 \u22a2 Type kind\n\n\u0393 \u22a2 A : Type \u0393, x : A \u22a2 K kind\npi-kind\n\u0393 \u22a2 \u03a0x:A.K kind\n\n\u22a2 \u0393 ctx u : K \u2208 \u0393\n\u22a2 \u0393 ctx x : A \u2208 \u0393\nvar-obj\nvar-fam\n\u03b2\n\u0393 \u22a2 u:K\n\u0393 \u22a2 x : A\u03b2\n\u0393 \u22a2 A : Type \u0393, x : A \u22a2 B : Type\npi-fam\n\u0393 \u22a2 (\u03a0x:A.B) : Type\n\u0393 \u22a2 A : Type\n\n\u0393, x : A \u22a2 B : K\n\u03b2\n\n\u0393 \u22a2 (\u03bbx:A.B) : (\u03a0x:A .K)\n\u0393 \u22a2 A : Type\n\n\u0393, x : A \u22a2 M : B\n\n\u0393 \u22a2 (\u03bbx:A.M ) : (\u03a0x:A\u03b2 .B)\n\nabs-fam\n\n\u0393 \u22a2 A : \u03a0x:B.K \u0393 \u22a2 M : B app-fam\n\u0393 \u22a2 (A M ) : (K[M/x])\u03b2\n\nabs-obj\n\n\u0393 \u22a2 M : \u03a0x:A.B \u0393 \u22a2 N : A app-obj\n\u0393 \u22a2 (M N ) : (B[N/x])\u03b2\n\nFigure 2. Rules for Inferring LF Assertions\n(append L K M ) \u2192\n(append (cons X L) K (cons X M ))\nWe can ask if there is some term M such that the judgment\n\u0393 \u22a2 M : append (cons z nil)\n(cons (s z) nil)\n(cons z (cons (s z) nil))\nis derivable. Assuming that \u0393 is given by the ambient environment,\nsuch a query can be posed in Twelf simply by presenting the type\nexpression. The logic programming interpreter of Twelf will find\nthat the proof term\n(appCons z nil (cons (s z) nil)\n(cons (s z) nil)\n(appN il (cons (s z) nil)))\ninhabits this type and hence will succeed on the query. In reaching\nthis conclusion, the interpreter will use the types involving append\nthat are present in \u0393. Further it will do this in a way that bears\na close resemblance to the use of clauses in a Prolog-like setting,\ninterpreting \u03a0 like a universal quantifier and \u2192 like an implication.\nThe simple example we have considered here will suffice to illustrate most of the later ideas in this paper but it does not bring\nout the richness of dependent types in specifications. We leave this\ndemonstration to the many discussions already in the literature. We\nalso note that Twelf has many additional features like allowing \u03a0\nquantification in types to be left implicit and permitting instantiatable variables in queries whose values are to be found through\nunification. While these aspects are treated in our implementation,\nto keep the theoretical discussions focused, we shall assume that\nthe only capability that is to be emulated is that of determining the\nderivability of an assertion of the form \u0393 \u22a2 M : A in which \u0393\nand A are in canonical form (and M is left unspecified). This assumption is easily justified: these will be \"type-checked\" prior to\nconducting a search and the Twelf system assumes equality under\n\u03b7-conversion.\n\n4. From Twelf Specifications to Predicate\nFormulas\nFelty has previously shown how to translate LF specifications and\njudgments into hohh formulas [5, 6]. Her translation proceeds in\ntwo steps. First, she describes a coarse mapping of LF expressions\ninto (simply typed) \u03bb-terms. This mapping loses information about\ndependencies in types and kinds and also does not reflect the correspondences between objects and types and types and kinds. These\nrelationships are encoded later through binary predicates over \u03bbterms.\nThe general structure of Felty's translation is applicable in the\ncontext of interest to us. However, the details of her mapping do\nnot quite fit our needs because of her focus on derivations in\nthe LF and hohh logics. One manifestation of this is that her\ntranslation is not based exclusively on types, but assumes also\nthe availability of the objects they are intended to qualify. This\nis not acceptable in the context of proof search where the task is\nprecisely to determine the existence of those objects: we need a\ntranslation that is only based on the type, and which can be applied\nto an hohh metavariable to correspond to an LF query whose\nobject is left unspecified as a metavariable. Second, the correctness\nresult only states an equivalence between LF derivability and hohh\nderivability for known LF assertions, and does not consider, for\nexample, whether it is possible for non-canonical or ill-formed\nobjects to be produced in the course of searching for proofs from\nthe hohh specification. In contrast, our completeness result will\nguarantee that after running a query with a metavariable standing\nfor the (encoding of the) object, the only possible instantiations of\nthat metavariable are actual encodings of terms.\nThe first step towards producing a translation into hohh that\ncan be used to interpret Twelf specifications is to adapt Felty's\ntranslation in a way that makes it acceptable in logic programming\ndiscussions. Our translation shall only account for judgments of the\nform \u0393 \u22a2 M : A since these are the only ones of interest in the\nlogic programming setting described in the previous section. The\nadequacy of this restriction actually relies on an auxiliary, easily\nverified, fact: if \u0393 \u22a2 A : Type is known to have a derivation and\nthe last rule in a purported derivation of \u0393 \u22a2 M : A is an abs-obj,\n\n\f\u03c6(A) := lf-obj when A is a base type\n\u03c6(\u03a0x:A.P ) := \u03c6(A) \u2192 \u03c6(P )\n\u03c6(Type) := lf-type\nhu M1 . . . Mn i := u hM1 i . . . hMn i\nhx M1 . . . Mn i := x hM1 i . . . hMn i\nh\u03bbx:A.M i := \u03bb\u03c6(A) x.hM i\n{{\u03a0x:A.B}} := \u03bbM. \u2200x. ({{A}} x) \u2283 ({{B}} (M x))\n{{A}} := \u03bbM. hastype M hAi where A is a base type\nFigure 3. Encoding of types, objects, and simplified translation of LF judgments to hohh\nhastype z nat\n\u2200n. hastype n nat \u2283 hastype (s n) nat\nhastype nil list\n\u2200n. hastype n nat \u2283 \u2200l. hastype l list \u2283 hastype (cons n l) list\n\u2200l. hastype l list \u2283 hastype (appN il l) (append nil l l)\n\u2200x. hastype x nat \u2283 \u2200l. hastype l list \u2283 \u2200k. hastype k list \u2283 \u2200m. hastype m list \u2283\n\u2200a. hastype a (append l k m) \u2283 hastype (appCons x l k m a) (append (cons x l) k (cons x m))\nFigure 4. Simple translation of the LF specification for append\nthen the left premise for the latter derivation must have a proof and\nhence does not need to be encoded by the translation.\nOur translation is presented in Figure 3. This translation first\nencodes LF objects and types in hohh terms by dropping a lot\nof typing information; as mentioned already, this information will\nbe recovered later in the encoding of LF judgments. Under this\ntranslation, an object (type) of type (kind) P is represented by an\nhohh term of simple type \u03c6(P ), built from the atomic types lf-type\nand lf-obj. The encoding of an object or base type Q is then given\nby hQi; note that in the process we assume a reuse of (LF) variable\nnames with an appropriate type as part of the corresponding hohh\nsignature. As an example, the LF signature at the end of the last\nsection leads to the following hohh signature:\nnat : lf-type\nz : lf-obj\ns : lf-obj \u2192 lf-obj\nlist : lf-type\nnil : lf-obj\ncons : lf-obj \u2192 lf-obj \u2192 lf-obj\nappend : lf-obj \u2192 lf-obj \u2192 lf-obj \u2192 lf-type\nappN il : lf-obj \u2192 lf-obj\nappCons : lf-obj \u2192 lf-obj \u2192\nlf-obj \u2192 lf-obj \u2192 lf-obj \u2192 lf-obj\nFurther, the LF type append nil nil nil gets translated to the same\nterm in hohh, where it has type lf-type. This translation behaves\nwell with respect to substitution and \u03b2-conversion, and is injective\nfor objects (types) of the same type (kind). Finally, we take up the\ntranslation of LF type assignments and judgments in the last two\nclauses in Figure 3. To emphasize reliance only on the structure of\ntypes, these clauses describe explicitly only the translation of an LF\ntype A. Such a type is mapped into an hohh predicate denoted by\n{{A}} that, intuitively, codifies the property of being a translation of\nan LF object of type A. This translation is defined on all canonical\ntypes and uses the hohh predicate hastype of type lf-obj \u2192\nlf-type \u2192 o. If A is a base type, {{\u03a0x1 :B1 . . . . \u03a0xn :Bn .A}} has\ntype \u03c4 \u2192 o where \u03c4 is lf-obj \u2192 . . . \u2192 lf-obj \u2192 lf-obj with n\nnegative occurrences of lf-obj. Once the translation of LF types is\nin place, we define {{M : A}} derivatively to be ({{A}} hM i).\nTwelf specifications are encoded by dropping all kind assignments and translating each type assignment they contain. As an ex-\n\nample, the Twelf specification of append translates into the clauses\nin Figure 4. From these clauses, we can, for example, derive the\ngoal hastype (cons (s z) nil) list and we could search for terms\nX satisfying the goal\nhastype X (append (cons z nil)\n(cons (s z) nil)\n(cons z (cons (s z) nil))).\nLet \u0393\u2032 be the translation of an LF context \u0393 and \u03b1\u2032 be the\ntranslation of the LF judgment \u03b1. These translations are based on\nan implicit hohh signature \u03a3. In the case that all the free variables\nin \u03b1 belong to dom(\u0393), then, in fact, \u03a3 consists of an isomorphic\ncopy of the symbols in dom(\u0393). Henceforth, we shall assume \u03a3\nto be just such an hohh signature and we shall write \u0393\u2032 \u2212\u2192 \u03b1\u2032\nas a shorthand for \u03a3; \u0393\u2032 \u2212\u2192 \u03b1\u2032 . The correctness of the (simple)\ntranslation is then the content of the following theorem.\nTheorem 1. Let \u0393 be a well-formed canonical LF context and\nlet A be a canonical LF type such that \u0393 \u22a2 A : Type has a\nderivation. If \u0393 \u22a2 M : A has a derivation for a canonical object\nM , then there is a derivation of {{\u0393}} \u2212\u2192 {{M : A}}. Conversely,\nif {{\u0393}} \u2212\u2192 ({{A}} M ) has a derivation for any hohh term M of\nappropriate type, then there is a canonical LF object M \u2032 such that\nM = hM \u2032 i and \u0393 \u22a2 M \u2032 : A has a derivation.\nProof outline Completeness can be proved by a simple induction\non the LF derivation, building an hohh derivation that mimics its\nstructure. Soundness is more involved: we proceed by induction\non the hohh derivation, gradually recovering the structure of M \u2032 ,\nmaintaining the derivability of \u0393 \u22a2 A : Type that allows us to\nbuild an LF derivation even in the case that abs-obj was the last\nrule used. The detailed proof is presented in Appendix A.\nThe simple translation presented in this section cannot be the\nbasis of a practical implementation of logic programming in LF.\nProof search using a program it produces may involve repeatedly\nproving goals of the form hastype M A for (encodings of) the\nsame object M and type A. This can be seen from the example in\nFigure 4: at every step of deriving an instance of append, the lists\nmust be checked to be well-typed, which artificially introduces a\nquadratic complexity. An important point to note, however, is that\nthis redundancy in \"type-checking\" is not easily detectable from\nthe hohh program that is generated. Rather, it must be determined,\n\n\f\u0393; *; x \u228fo Ai for some Ai\n\u2192\n\u2212\n\u0393; x \u228ft c A\n\nAPPt\n\nyi \u2208 \u03b4 for each yi yi distinct\n\u2192\n\u0393; \u03b4; x \u228fo x \u2212\ny\n\u0393, y; x \u228ft B\n\u0393; x \u228ft \u03a0y:A.B\n\nINITo\n\nPIt\n\ny\u2208\n/ \u0393 and \u0393; \u03b4; x \u228fo Mi for some i\n\u2212\n\u2192\n\u0393; \u03b4; x \u228fo y M\n\u0393; \u03b4, y; x \u228fo M\n\u0393; \u03b4; x \u228fo \u03bby:A.M\n\nAPPo\n\nABSo\n\nFigure 5. Rigidly occurring variables in types and objects\nand shown to be safely eliminable, based on deeper properties of\nLF terms. It is this issue that we take up in the next section.\n\n5. An Improved Translation of Twelf\nSpecifications\nIn order to make the translation of LF specifications into hohh\npractical from an implementation standpoint, we make two optimizations.\nThe first, and main, optimization exploits the fact that we are\nconsidering derivations of the form \u0393 \u22a2 M : A where \u0393 and A\nhave already been type-checked. For example, we may be wanting\nto determine whether the LF type\nappend (cons z nil) nil (cons z nil)\nis inhabited. Before attempting to do this, we would have already\ndetermined that append (cons z nil) nil (cons z nil) is a valid\ntype, which means, for instance, that we would have checked that\n(cons z nil) is a valid object of type list. Therefore, there is no\nneed to show again that (cons z nil) has this property in the course\nof searching for an inhabitant of the displayed type. Our optimized\ntranslation takes advantage of this kind of observation by statically\nremoving some run-time checking from the translation of LF typing. More specifically, our optimization is based on the following\nidea. Suppose we can determine that, for a particular i, ti must always appear in the type (A[t1 /x1 , . . . , tn /xn ])\u03b2 . Then the translation of the type \u03a0x1 :B1 . . . . \u03a0xn :Bn .A does not need to include\nexplicit type-checking over the instantiation of xi . We characterize\nsome of these cases by using the notion of a rigid occurrence of xi\n\u2192\nin A that is expressed formally through the judgment \u2212\nx ; xi \u228ft A\ndefined by the rules in Figure 5; the rules APPt and PIt in this figure act on LF types, and the rules INITo , APPo , and ABSo act on LF\nobjects. We shall allow type checking over instantiations of rigid\nvariables to be eliminated from the simple translation. By doing so,\nwe shall both reap an efficiency benefit and also make the result of\ntranslation correspond more closely to the original LF type.\nThe second optimization is more transparent, not depending on\ndeep properties of dependent types. The essential observation is the\nfollowing. Instead of producing predicates of the form\nhastype X (append L K M )\nand hastype L list, we can specialize them to append X L K M\nand list L. This results in a hohh program that is much clearer,\nand more closely related to the original LF specification. Moreover,\nthis simple transformation can also lead to better performance in a\nlogic programming setting because it allows for the exploitation of\na common optimization, namely, the indexing on a predicate name\n\nthat speeds up the determination of candidate clauses on which to\nbackchain.\nThe improved translation that uses these two ideas is presented\non Figure 6. The J\u2022K+\n\u0393 translation is used on type assignments appearing negatively (notably context items) and J\u2022K\u2212 on positive\ntyping judgments (notably the conclusion of LF assertions). As before, that translation is entirely guided by the type, and defined\nfor all canonical types. We shall use the notation JM : AK\u2212 for\n(JAK\u2212 hM i), and define J\u0393K+ as the result of applying J\u2022K+\n* to\neach context item, dropping kind assignments. Note that instead\nof replacing unnecessary typing judgments with \u22a4 we could simply elide them all together; we use \u22a4 as a placeholder because it\nsimplifies later proofs. This translation is illustrated by its application to the example Twelf specification considered in Section 3 that\nyields the clauses shown in Figure 7. These clauses should be contrasted with the ones in Figure 4 that are produced by the earlier,\nnaive translation.\nWe shall now establish the correctness of the optimized translation. We first prove a fundamental lemma concerning rigidly occurring variables, that is in fact an observation about LF: for an LF\nbase type A, if we have derivations of\n\u0393 \u22a2 \u03a0x1 :B1 . . . . \u03a0xn :Bn .A : Type\n\u0393 \u22a2 A[t1 /x1 . . . tn /xn ] : Type\n\nand\n\n\u2192\nand there is a rigid occurrence of xi in A, i.e., \u2212\nx ; xi \u228ft A has a\nderivation, then \u0393 \u22a2 ti : Bi [t1 /x1 . . . ti\u22121 /xi\u22121 ] has a derivation.\n\u2192\nThe idea of the proof is as follows. The judgment \u2212\nx ; xi \u228ft A gives\na path in A that leads to xi , and this path can never be erased by the\nconsidered substitution; following this path simultaneously in the\ntwo LF derivations, one eventually finds on one side a derivation\nof \u0393 \u22a2 xi : Bi and on the other side the expected derivation of\n\u0393 \u22a2 ti : Bi [t1 /x1 , . . . , ti\u22121 /xi\u22121 ].\nIn order to be able to use this observation in our correctness argument, we formulate a stronger, rather technical lemma that deals\ndirectly with encoded types that are the result of instantiations of\n(a priori) arbitrary hohh terms, and ensures that discovered hohh\nterms are in fact encodings of LF objects. These technical details\nconcerning encodings are tedious but shallow, and the essential\nstructure of the proof follows the lines sketched above.\n\u2192\n\u2212\n\u2192\nDefinition 1. Let t be a vector of hohh terms, and \u2212\nx a vector of\nvariables of the same length. If M and N are LF objects, then we\nwrite (M \u223c N )[t1 /x1 . . . tn /xn ] when\nhM i = hN i[t1 /x1 . . . tn /xn ].\nFor LF types A and B, we write (A \u223c B)[t1 /x1 . . . tn /xn ] when\nthe two types are equal up to (\u2022 \u223c \u2022)[t1 /x1 . . . tn /xn ] on objects\nwithin. Finally we extend this notion to contexts of the same length\nby pushing it down to the types bound by the context. We shall omit\n\u2192\n\u2212\n\u2192\nt and \u2212\nx when they are obvious from the context, simply writing\nP \u223c Q.\n\u2192\n\u2212\n\u2192\nLemma 1. Let t be a vector of hohh terms, \u2212\nx a vector of\n\u2192\n\u2212\nvariables, and B of canonical LF types, all of same length, such\nthat tj = ht\u2032j i for j < i. Let \u03930 = x1 : B1 , . . . , xn : Bn .\n1. Let \u0393 and \u2206 be LF contexts, M an LF object and A a type, all\nbeing assumed canonical. Let \u03b4 be dom(\u2206). Suppose that there\n\u2192\nare derivations of \u2212\nx ; \u03b4; xi \u228fo M and \u0393, \u03930 , \u2206 \u22a2 M : A\n\u2032\nand \u0393, \u2206 \u22a2 M \u2032 : A\u2032 , with A\u2032 \u223c A, M \u2032 \u223c M and\n\u2206\u2032 \u223c \u2206. Then ti is of the form ht\u2032i i and there is a derivation of\n\u0393 \u22a2 t\u2032i : Bi [t\u20321 /x1 , . . . , t\u2032i\u22121 /xi\u22121 ].\n\u2212\u2212\u2192\n2. Let \u03a0x:B.A be a canonical type, where A is a base type.\n\u2212\u2212\u2192\n\u2192\nx ; xi \u228ft A have\nSuppose that \u0393 \u22a2 \u03a0x:B.A : Type and \u2212\nderivations. Further, for some A\u2032 such that A\u2032 \u223c A, suppose\n\n\f(\n\n\u03bbM. \u2200x. \u22a4 \u2283 JBK+\nif \u0393; x \u228ft B\n\u0393,x (M x)\n\u03bbM. \u2200x. JAK\u2212 (x) \u2283 JBK+\n(M\nx)\notherwise\n\u0393,x\n\u2212\n\u2212\n\u2192\n\u2192\n\u2212\nJu N K+\n\u0393 := \u03bbM. u M hN i\n\nJ\u03a0x:A.BK+\n\u0393\n\n:=\n\n\u2212\nJ\u03a0x:A.BK\u2212 := \u03bbM. \u2200x. JAK+\n* (x) \u2283 JBK (M x)\n\u2212\n\u2212\n\u2192\n\u2192\n\u2212\nJu N K\u2212 := \u03bbM. u M hN i\n\nFigure 6. Optimized translation of LF specifications and judgments to hohh\nnat z\n\u2200n. nat n \u2283 nat (s n)\nlist nil\n\u2200n. nat n \u2283 \u2200l. list l \u2283 list (cons n l)\n\u2200l. \u22a4 \u2283 append (appN il l) nil l l\n\u2200x. \u22a4 \u2283 \u2200l. \u22a4 \u2283 \u2200k. \u22a4 \u2283 \u2200m. \u22a4 \u2283\n\u2200a. append a l k m \u2283 append (appCons x l k m a) (cons x l) k (cons x m)\nFigure 7. Optimized translation of the LF specification for append\nthat \u0393 \u22a2 A\u2032 : Type has a derivation. Then ti = ht\u2032i i and there\nis a derivation of \u0393 \u22a2 t\u2032i : Bi [t\u20321 /x1 , . . . , t\u2032i\u22121 /xi\u22121 ].\nProof. We prove part (1) by induction on the structure of the deriva\u2192\ntion of \u2212\nx ; \u03b4; xi \u228fo M . In the argument below, we let D be the\nderivation of \u0393, \u03930 , \u2206 \u22a2 M : A, and D\u2032 be the derivation of\n\u0393, \u2206\u2032 \u22a2 M \u2032 : A\u2032 .\n\u2192\n\u2192\n\u2022 In the base case of INIT , M = x \u2212\ny where \u2212\ny are distinct\ni\n\no\n\nWe have hAi[t1 /x1 . . . tn /xn ] = hA[t\u20321 /x1 . . . t\u2032i\u22121 /xi\u22121 ]i\nand A\u2032 \u223c A, from which we obtain, by injectivity of h\u2022i,\nthat A\u2032 = A[t\u20321 /x\u20321 . . . t\u2032i\u22121 /xi\u22121 ]. The same goes for Ci\u2032\n\u2212\n\u2212\n\u2192 \u2192 \u2212\nand Ci . Since Bi = \u03a0z:C.A[\u2212\nz /\u2192\ny ], and the substitutions\n\u2032\n\u2032\n\u2032\n\u2212\n\u2192\n\u2212\n\u2192\n[t1 /x1 . . . ti\u22121 /xi\u22121 ] and [ z / y ] permute, we have:\n\u2212\u2212\u2192\n\u2192\n\u2192\n\u03a0z:C \u2032 .A\u2032 [\u2212\nz /\u2212\ny ] = Bi [t\u20321 /x\u20321 . . . t\u2032i\u22121 /xi\u22121 ]\n\nbound variables from \u03b4. The derivation D must consist of n\napp-obj rules and a var-obj rule on xi , whose type Bi must be\n\u2212\n\u2212\n\u2192\n\u2192\n\u2192\nof the form \u03a0z:C.D, with A = D[\u2212\ny /\u2212\nz ]. Note that, because\nthe variables yi are distinct bound variables that are fresh with\nrespect to D, this substitution can be inverted, and we thus\n\u2192\n\u2192\nhave A[\u2212\nz /\u2212\ny ] = D. The other subderivations of the chain\nof app-obj applications are instances of var-obj establishing\n\u2192\n\u2192\n\u2192\n\u2192\nyi : Ci [\u2212\ny /\u2212\nz ], hence (yi : Ci\u2032 [\u2212\ny /\u2212\nz ]) \u2208 \u2206\u2032 for Ci\u2032 \u223c Ci .\nWe next determine t\u2032i . By \u03b7-equivalence we can assume that ti\nis of the form \u03bbz1 . . . \u03bbzn .u. We have\n\u2192\n\u2192\n\u2192\ny = u[\u2212\ny /\u2212\nz ],\nhM \u2032 i = t \u2212\n\n\u2022 In the ABSo case, we have M = \u03bby:A1 .N and D ends with the\n\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\nhence u = hM \u2032 i[\u2212\nz /\u2212\ny ] = hM \u2032 [\u2212\nz /\u2212\ny ]i. Let u\u2032 = M \u2032 [\u2212\nz /\u2212\ny]\n\u2212\n\u2212\n\u2192\n\u2032\n\u2032 \u2032\nand ti = \u03bbz:C .u . We have\n\u2192\n\u2192\nht\u2032 i = \u03bbz . . . \u03bbz . hM \u2032 i[\u2212\nz /\u2212\ny]\n\n\u2192\n\u2022 In the APPo case, we have M = y N1 . . . Nm , y 6\u2208 \u2212\nx and\n\ni\n\n1\n\ni\n\n=\n\nn\n\n\u03bbz1 . . . \u03bbzn . u = ti .\n\nWe know that D\u2032 derives \u0393, \u2206\u2032 \u22a2 M \u2032 : A\u2032 . From this we\nobtain a derivation of\n\u2192\n\u2192\n\u2192\n\u2192\n\u0393, \u2206\u2032 [\u2212\nz /\u2212\ny ] \u22a2 u\u2032 : A\u2032 [\u2212\nz /\u2212\ny]\n\u2192\n\u2192\nby renaming variables \u2212\ny into \u2212\nz , employing Proposition 2. The\n\u2032 \u2212\n\u2192\n\u2192\n\u2212\ncontext \u2206 [ z / y ] contains assignments (zi : Ci\u2032 ) and the other\n\u2192\n\u2192\nvariables in its domain do not occur in u\u2032 nor A\u2032 [\u2212\nz /\u2212\ny ] (since\n\u2032\n\u2192\n\u2212\n\u2192\n\u2212\nA \u223c A, A = D[ y / z ] and D is a subterm of Bi which\ncannot contain any yi ). We then have\n\u2212\u2212\u2192\n\u2212\u2212\u2192\n\u2192\n\u2192\n\u0393 \u22a2 (\u03bbz:C \u2032 .u\u2032 ) : (\u03a0z:C \u2032 .A\u2032 [\u2212\nz /\u2212\ny ])\nby weakening unused variables and using abs-obj to introduce\n\u2192\nthe variables \u2212\nz . This is a typing derivation for t\u2032i ; we must now\nshow that the associated type is actually the expected one:\nBi [t\u20321 /x1 . . . t\u2032i\u22121 /xi\u22121 ]\n\nabs-obj rule as follows:\n\u0393, \u03930 , \u2206 \u22a2 A1 : Type \u0393, \u03930 , \u2206, y : A1 \u22a2 N : A2\n\u0393, \u03930 , \u2206 \u22a2 (\u03bby:A1 .N ) : (\u03a0y:A1 .A2 )\nThen A\u2032 \u223c \u03a0y:A1 .A2 , and hence A\u2032 must be of the form\n\u03a0y:A\u20321 .A\u20322 where A\u2032i \u223c Ai . Similarly, we obtain that M \u2032 is\nof the form \u03bby:A\u20321 .N \u2032 with N \u2032 \u223c N . Then, D\u2032 must contain a\nderivation of\n\u0393, \u2206\u2032 , y : A\u20321 \u22a2 N \u2032 : A\u20322 ,\nand we conclude by the inductive hypothesis.\n\n\u2192\n\u2212\nx ; \u03b4; xi \u228fo Nj . Let \u03a0z1 :C1 . . . . \u03a0zm :Cm .D be the type of y\nin (\u0393, \u2206). The derivation D starts with a chain of app-obj applications, followed by var-obj on y. The premise corresponding\nto Nj establishes that\n\n\u0393, \u03930 , \u2206 \u22a2 Nj : Cj [N1 /z1 , . . . , Nj\u22121 /zj\u22121 ]\n\u2212\u2212\u2192\nIn (\u0393, \u2206\u2032 ), the variable y is assigned the type \u03a0z:C \u2032 .D\u2032 with all\n\u2032\n\u2032\nCk \u223c Ck . Moreover, since M \u223c (y N1 . . . Nm ) and since y\n\u2192\nis not affected by the instantiation of \u2212\nx , it must be that M \u2032 is of\n\u2032\nthe form (y N1\u2032 . . . Nm\n) with all Nj\u2032 \u223c Nj . The derivation D\u2032\nmust proceed in a similar fashion, namely a chain of app-obj\napplications followed by var-obj on y. Therefore we have a\nderivation of\n\u2032\n\u0393, \u2206\u2032 \u22a2 Nj\u2032 : Cj\u2032 [N1\u2032 /z1 , . . . , Nj\u22121\n/zj\u22121 ]\n\nWe can conclude by the inductive hypothesis because\n\u2032\nCj\u2032 [N1\u2032 /z1 . . . Nj\u22121\n/zj\u22121 ] \u223c Cj [N1 /z1 . . . Nj\u22121 /zj\u22121 ]\n\u2192\n\u2192\n(which relies on the disjointness of \u2212\nx and \u2212\nz ).\n\n\fThe proof of (2) follows a similar pattern. First, by a straightforward inspection of the first rules of the derivation of\n\u2212\u2212\u2192\n\u0393 \u22a2 \u03a0x:B.A : Type\nwe extract a derivation of \u0393, \u03930 \u22a2 A : Type. Then, since A is a\nbase type, it must be (by rule APPt ) that xi rigidly occurs in one\nof its arguments M . Note that A and A\u2032 have the same structure\non the path leading to M , since no object is involved there. Hence,\na simultaneous inspection of the first rules of the derivations of\n\u0393, \u03930 \u22a2 A : Type and \u0393 \u22a2 A\u2032 : Type yields derivations of\n\u0393, \u03930 \u22a2 M : T and \u0393 \u22a2 M \u2032 : T \u2032 for M \u2032 \u223c M and T \u2032 \u223c T . We\ncan conclude using part (1).\nThe definition of rigidity described above might seem restrictive. In particular, one might want to allow\n\u2192\n\u2212\n\u0393; \u03b4; x \u228fo x N\nin INITo . However, with such a rule the rigidity lemma described\nabove is no longer true. For example, in a signature \u0393 containing\nnum : nat \u2192 Type and numn : \u03a0n:nat.(num n), the object\nt = numn provides a counter-example to Lemma 1, part (1):\nwe have \u0393, x : (nat \u2192 num z) \u22a2 (x z) : (num z) and\n\u0393 \u22a2 (t z) : (num z) but not \u0393 \u22a2 t : nat \u2192 num z. This\nexample highlights a crucial aspect of our definition: the applications allowed in INITo should always induce invertible substitutions.\nAs in higher-order pattern unification [13, 18], we achieve this by\nrestricting to applications involving a simple form of \u03b2-reductions\ncalled \u03b20 -reductions that are similar to renaming.\nWe now use Lemma 1 to prove the correctness of the optimized\ntranslation.\nTheorem 2. Let \u0393 be an LF context, A an LF type, both canonical,\nsuch that \u22a2 \u0393 ctx and \u0393 \u22a2 A : Type are derivable. Then when M\nis an arbitrary hohh term, {{\u0393}} \u2212\u2192 {{A}}(M ) has a derivation if\nand only if J\u0393K+ \u2212\u2192 JAK\u2212 (M ) has a derivation.\nProof. We establish the soundness direction by induction on the\nderivation of the optimized translation, maintaining the assumptions about \u0393 and A.\n\u2032\n\nIf A is of the form \u03a0x:B.A our derivation ends as follows:\nJ\u0393, x : BK+ \u2212\u2192 JA\u2032 K\u2212 (M x)\n\u2200 R, \u2283 R\nJ\u0393K+ \u2212\u2192 J\u03a0x:B.A\u2032 K\u2212 (M )\nFirst, \u0393 \u22a2 B : Type, \u22a2 (\u0393, x : B) ctx and \u0393, x : B \u22a2 A\u2032 : Type\nmust have derivations since \u0393 and A are well-formed. We can thus\napply the inductive hypothesis, obtaining that\n{{\u0393, x : B}} \u2212\u2192 {{A\u2032 }}(M x)\nhas a derivation. By \u2200R and \u2283 R, {{\u0393}} \u2212\u2192 {{\u03a0x:B.A\u2032 }}(M ) has\none as well.\nIf A is a base type, then our derivation starts with a backchaining\n\u2212\u2212\u2192\non the encoding of some (y : \u03a0x:B.A\u2032 ) \u2208 \u0393, i.e., on\n\u2200x1 . (JB1 K\u2212 (x1 ) \u2283 . . . \u2283\n\u2212\u2212\u2192\n\u2192\n\u2200xn . (JBn K\u2212 (xn ) \u2283 (u (y \u2212\nx ) hN i))).\nIn particular, this rule application has the form\nJ\u0393K+ \u2212\u2192 F1\n\n. . . J\u0393K+ \u2212\u2192 Fn\nbackchain\n\u2212\u2212\u2192 \u2212\u2192\n\u2192\nJ\u0393K+ \u2212\u2192 (u(y \u2212\nx )hN i)[t/x]\n\nwhere Fi is either (JBi K\u2212 (xi ))[t1 /x1 , . . . , ti /xi ] or \u22a4. We perform an inner induction on i \u2264 n, showing that for all j \u2264 i,\ntj = ht\u2032j i for some LF object t\u2032j , and that we have derivations of\n{{\u0393}} \u2212\u2192 ({{Bj [t\u20321 /x1 , . . . , t\u2032j\u22121 /xj\u22121 ]}} t\u2032j )\n\nand\n\u0393 \u22a2 t\u2032j : Bj [t\u20321 /x1 , . . . , t\u2032j\u22121 /xj\u22121 ].\n\u2022 We first treat the case where Fi = \u22a4, i.e., there is a derivation\n\n\u2192\nof \u2212\nx ; xi \u228ft A\u2032 . We assumed that \u0393 \u22a2 A : Type, and since \u0393\n\u2212\u2212\u2192\nis valid we also have a derivation of \u0393 \u22a2 \u03a0x:B.A\u2032 : Type.\n\u2032\nWe can thus apply Lemma 1, to obtain ti and a derivation\nof \u0393 \u22a2 t\u2032i : Bi [t\u20321 /x1 , . . . , t\u2032i\u22121 /xi\u22121 ], and we conclude by\nTheorem 1.\n\u2022 When Fi 6= \u22a4, we can see that within the derivation of\n\u2212\u2212\u2192\n\u0393 \u22a2 \u03a0x:B.A\u2032 : Type\nthere is a derivation of\n\u0393, x1 : B1 , . . . , xi\u22121 : Bi\u22121 \u22a2 Bi : Type.\nBy substituting (Proposition 1) the derivations provided by the\ninner inductive hypothesis on this formula we construct a derivation of\n\u0393 \u22a2 Bi [t\u20321 /x1 , . . . , t\u2032i\u22121 /xi\u22121 ] : Type.\nWe can now apply the outer inductive hypothesis on Fi , to\nconclude that {{\u0393}} \u2212\u2192 ({{Bi [t\u20321 /x1 , . . . , t\u2032i\u22121 /xi\u22121 ]}} ti ) has\na derivation. By Theorem 1, we finally obtain that ti is of the\nform ht\u2032i i.\nWe compose all derivations\n\n{{\u0393}} \u2212\u2192 {{Bi [t\u20321 /x1 , . . . , t\u2032i\u22121 /xi\u22121 ]}} ti\n\u2212\u2212\u2192\nby backchain on the encoding of (y : \u03a0x:B.A\u2032 ) \u2208 \u0393, obtaining the\nexpected derivation of\n\u2212\u2212\u2192 \u2212\u2192\n\u2212\n\u2192\n{{\u0393}} \u2212\u2192 hastype (y t ) (u hN i)[t/x]\nCompleteness is proved by an induction on the derivation of\nthe simple translation. This direction is rather straightforward as\nit consists only of dropping information. Details can be found in\nAppendix A.\nTherefore, by Theorems 1 and 2, intuitionistic provability under\nthe optimized translation is equivalent to provability in LF, and the\nfollowing is a theorem.\nTheorem 3 (Optimized translation correctness). Let \u0393 be an LF\nspecification such that \u22a2 \u0393 ctx has a derivation, A an LF type\nsuch that \u0393 \u22a2 A : Type has a derivation. Then, for any LF object\nM such that \u0393 \u22a2 M : A has a derivation, J\u0393K+ \u2212\u2192 JM : AK\u2212\nis derivable. Moreover, if J\u0393K+ \u2212\u2192 JAK\u2212 (M ) for an arbitrary\nhohh term M , then it must be that M = hM \u2032 i for some canonical\nLF object such that \u0393 \u22a2 M \u2032 : A has a derivation.\n\n6. Performance Comparisons\nWe have claimed two properties for our translation: that it produces\nan hohh program which corresponds closely to the original LF\nspecification, and that this program provides an effective means for\nexecuting the specification. Evidence for the first claim is provided\nby the translation of the append specification presented in Figure 7,\nespecially when one uses the easily applied simplification of a\nformula of the form \u22a4 \u2283 F to F . Notice also the correspondence\nof the definition of the append predicate to the one that one might\nin, e.g., Prolog, if one drops the first \"proof term\" argument of the\npredicate. To fully appreciate this benefit, it is necessary to consider\nlarger examples that space does not allow us to do in this paper.\nHowever, such examples are available with the implementation\n[23]. We suggest that the reader look especially at the example of\nthe evaluator for Mini-ML with terms that are not indexed by their\ntype that is described below in the collection of benchmarks: the\n\n\fExample\nreverse(10)\nreverse(20)\nreverse(30)\nreverse(40)\nreverse(50)\nminiml(50)\nminiml(100)\nminiml(150)\nminiml(200)\ntyped miniml(50)\ntyped miniml(100)\ntyped miniml(150)\ntyped miniml(200)\nperm(10)\nperm(20)\nperm(30)\nperm(40)\nperm(50)\nnum(64)\nnum(128)\nnum(256)\nnum(512)\n\nTwelf\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n\nSimple\n0.40\n0.57\n0.63\n0.41\n0.46\n0.74\n1.25\n1.75\n2.89\n2.27\n2.22\n3.49\n3.70\noverflow\noverflow\noverflow\noverflow\noverflow\n158.19\n\u221e\n\u221e\n\u221e\n\nOptimized\n0.14\n0.19\n0.20\n0.13\n0.15\n0.25\n0.44\n0.56\n0.83\n1.07\n0.76\n1.44\n0.92\n3.13\n1.75\n3.05\n3.95\n5.05\n0.25\n0.10\n0.15\n0.003\n\nTyped Optimized\n0.07\n0.12\n0.14\n0.10\n0.10\n0.18\n0.30\n0.41\n0.62\n0.57\n0.49\n0.67\n0.67\n0.94\n0.78\n1.52\n2.15\n2.88\n0.23\n0.10\n0.14\n0.003\n\nIndexing\n0.08\n0.11\n0.11\n0.07\n0.08\n0.08\n0.17\n0.25\n0.41\n0.48\n0.38\n0.55\n0.55\n0.72\n0.44\n0.81\n1.14\n1.59\n0.21\n0.07\n0.13\n0.003\n\nFigure 8. Performance comparison results\ntranslation results in an hohh program that is what one might write\nin hohh directly.\nTo test the second claim, we have carried out performance comparisons between the Twelf implementation that interprets LF specifications directly via a Standard ML program and an implementation obtained by translating these specifications into hohh programs and then executing these using the Teyjus system. We present\nresults here over programs that have a few different characteristics:\n\u2022 First, as we are interested in logic programming in LF, the\n\ntraditional logic program for naively reversing a list a n times\nis included.\n\u2022 The encoding of evaluators for various languages is a common\n\nusage of LF. We have therefore used an encoding of Mini-ML\nalong with an encoding of addition as another sample program.\nThis benchmark, called miniml, consists of adding n to 10 using\nthe encoding.\n\u2022 The miniml specification does not make essential use of depen-\n\ndent types. The typed miniml benchmark, which consists of an\nevaluator for Mini-ML in which terms are indexed by their type,\nuses dependent types to ensure that terms are well-formed. The\nMini-ML program that was run is a typed version of the encoding of addition.\n\u2022 An implementation of a meta-interpreter for intuitionistic non-\n\ncommutative linear logic (INCLL) has been proposed as a test\nprogram [21]. The perm benchmark tests list permutation encoded in INCLL and run using the meta-interpreter on lists of\nlength n.\n\u2022 The last benchmark, referred to as num, involves rewriting arith-\n\nmetic expressions into an equivalent normal form. This example again makes essential use of dependent types by associating\nwith each equivalence of two such terms a proof of their equivalence. The benchmark tests rewriting expressions of size n.\nThe third through fifth columns of Figure 8 present data comparing the simple translation, the translation with redundant typing judgments removed, and the fully optimized translation against\nthe standard of Twelf with default optimizations on these bench-\n\nmarks.4 As described in Figure 6, the fully optimized translation\ninserts the proof term as the first argument of the predicate generated. Since this term is to be determined by proof search, advantage\ncannot be taken of the capability Teyjus possesses of indexing on\nthe first argument. The last column presents data for the case where\nwe make the proof term the last argument instead. In the data presented, overflow indicates a heap overflow in the Teyjus simulator,\nand \u221e means that the program ran more than 1000 times longer\nthan Twelf.\nThe most optimized translation leads to better performance in\nmost cases, often significantly so. On the other hand, the simple\ntranslation yields a program that is generally slower than Twelf. In\nparticular, performance tends to deteriorate with larger problems\nsizes, in keeping with the difficulty that we noted with this translation. However, the simple translation is still comparable to Twelf\non the first three benchmarks. On the perm benchmark, Twelf does\nquite well and even out-performs Teyjus with the optimized translation on problems of large size. We have yet to pinpoint the reason\nfor this-the program is large and difficult to analyze in detail-but\nwe suspect that the linear head optimization that delays expensive\nunification computation till after simpler checks have been made\nmay have something to do with this. The fact that term indexing\ncauses significant improvement with Teyjus gives credence to this\nobservation.\nFor problems of very large size with all the benchmarks, the\nperformance of Twelf deteriorates quite dramatically; this is seen,\nfor example, in the case of num(n) for a problem of size 512. This\nphenomenon is linked to the fact that Twelf consumes excessive\namounts of memory. The ultimate source of this problem is perhaps\nthe fact that Twelf is implemented in SML: it has been argued that\nrealizing a logic programming language in a functional programming setting can lead to poor memory reclamation and eventually\nto shortage of space [3].\n\n4 This\n\nsetting with Twelf leads to the best performance on these examples.\n\n\f7. Conclusion and Future Work\nWe have considered in this paper a translation of Twelf specifications into logic programs in the hohh language. An important part\nof our ideas is the recognition of certain situations in which type\ninformation is redundant in LF expressions and hence its checking can be avoided. Our eventual translation produces a program\nthat corresponds closely to the original specification and we have\nargued that it can be the basis for an effective animation of Twelf\ndescriptions.\nThe specific work undertaken here can be extended in a few different ways. As an extension to our notion of rigidity, we might\n\u2212\u2212\u2192\nobserve that, when applying a variable of type \u03a0x:B.A, we could\nidentify redundant type information, not only between a Bi and A,\nbut also between a Bi and a different Bj . It would also be interesting to relate our work to the ideas of Reed [22] who describes\na notion of strictness similar to rigidity, used for the different purpose of identifying sub-terms of LF objects that could be reconstructed if elided \u2013 in contrast, we avoid redundant type checking but still generate a complete LF object. Such an understanding\nmight lead both to an improvement of our translation and to the\nability to shorten LF terms that are needed in applications such as\nthat of proof-carrying-code [17]. From an implementation perspective, another possible optimization is to avoid constructing an LF\nobject explicitly when the task has been identified as that of only\ndetermining whether a type has an inhabitant: experiments in this\ndirection indicate in some cases a ten-fold performance improvement over the optimized translation. Techniques from the area of\nextracting programs from proofs that pertain to isolating parts of a\nproof that do not contribute to its overall computational content-\ne.g.,, see [25]-are potentially useful to the application of such an\noptimization; these techniques might provide the basis for noting\ncomponents of a type whose inhabitants do not participate in the\nterm corresponding to the overall type.\nWe have focused here on realizing Twelf through a translation\nto \u03bbProlog. A different approach, worthy of investigation, is that of\ncompiling Twelf specifications directly to bytecode for the virtual\nmachine underlying the Teyjus system. Such an approach would\nmake it possible to realize optimizations that have been developed\nfor the direct implementation of Twelf [20, 21]. Of special note here\nare optimizations like the linear heads treatment of unification described by Pientka and Pfenning [21] for minimizing occurs checking, that could make a difference in examples such as the perm program considered in the previous section: direct compilation would\nallow us to regain opportunities for such improvements that might\nbe lost by translating first to \u03bbProlog and then relying on its implementation that is not specially optimized to treat Twelf-specific\nprograms.\nA more ambitious line of development concerns meta-reasoning\nover specifications. Existing tools might be used to reason about\nLF programs via the translation, the transparency of the translation\nbecoming essential. Anecdotal evidence suggests that this transparency is not only enabling, it is also elucidating: that the generated hohh program is easier to reason about because it highlights\nthose types that could have logical importance, and elides those that\ndo not.\n\nReferences\n[1] D. Baelde. A linear approach to the proof-theory of least and greatest\nfixed points. PhD thesis, Ecole Polytechnique, Dec. 2008. URL\nhttp://www.lix.polytechnique.fr/~ dbaelde/thesis/.\n[2] D. Baelde, D. Miller, and Z. Snow. Focused inductive theorem proving. In J. Giesl and R. Haehnle, editors, IJCAR, Lecture Notes in\nComputer Science. Springer-Verlag, 2010. (to appear).\n[3] P. Brisset and O. Ridoux. The architecture of an implementation\nof lambda-prolog: Prolog/mali. In ILPS Workshop: Implementation\nTechniques for Logic Programming Languages, 1994.\n[4] A. Church. A formulation of the simple theory of types. J. of Symbolic\nLogic, 5:56\u201368, 1940.\n[5] A. Felty. Specifying and Implementing Theorem Provers in a HigherOrder Logic Programming Language. PhD thesis, University of Pennsylvania, Aug. 1989.\n[6] A. Felty and D. Miller. Encoding a dependent-type \u03bb-calculus in a\nlogic programming language. In M. Stickel, editor, Proceedings of\nthe 1990 Conference on Automated Deduction, volume 449 of LNAI,\npages 221\u2013235. Springer, 1990.\n[7] A. Gacek. The Abella interactive theorem prover (system description). In A. Armando, P. Baumgartner, and G. Dowek, editors, Fourth International Joint Conference on Automated Reasoning, volume 5195 of LNCS, pages 154\u2013161. Springer, 2008. URL\nhttp://arxiv.org/abs/0803.2305.\n[8] A. Gacek. A Framework for Specifying, Prototyping, and Reasoning\nabout Computational Systems. PhD thesis, University of Minnesota,\n2009.\n[9] A. Gacek, S. Holte, G. Nadathur, X. Qi, and Z. Snow. The\nTeyjus system \u2013 version 2, Mar. 2008.\nAvailable from\nhttp://teyjus.cs.umn.edu/ .\n[10] A. Gacek, D. Miller, and G. Nadathur. Combining generic judgments\nwith recursive definitions. In F. Pfenning, editor, 23th Symp. on Logic\nin Computer Science, pages 33\u201344. IEEE Computer Society Press,\n2008.\n[11] R. Harper, F. Honsell, and G. Plotkin. A framework for defining logics.\nJournal of the ACM, 40(1):143\u2013184, 1993.\n[12] W. A. Howard. The formulae-as-type notion of construction. In J. P.\nSeldin and R. Hindley, editors, To H. B. Curry: Essays in Combinatory\nLogic, Lambda Calculus, and Formalism, pages 479\u2013490. Academic\nPress, New York, 1980.\n[13] D. Miller. A logic programming language with lambda-abstraction,\nfunction variables, and simple unification. J. of Logic and Computation, 1(4):497\u2013536, 1991.\n[14] D. Miller and A. Tiu. A proof theory for generic judgments. ACM\nTrans. on Computational Logic, 6(4):749\u2013783, Oct. 2005.\n[15] D. Miller, G. Nadathur, F. Pfenning, and A. Scedrov. Uniform proofs\nas a foundation for logic programming. Annals of Pure and Applied\nLogic, 51:125\u2013157, 1991.\n[16] G. Nadathur and D. Miller. An Overview of \u03bbProlog. In Fifth International Logic Programming Conference, pages 810\u2013827, Seattle, Aug.\n1988. MIT Press.\n[17] G. C. Necula. Proof-carrying code. In Conference Record of the 24th\nSymposium on Principles of Programming Languages 97, pages 106\u2013\n119, Paris, France, 1997. ACM Press.\n[18] T. Nipkow. Functional unification of higher-order patterns. In\nM. Vardi, editor, Proc. 8th IEEE Symposium on Logic in Computer\nScience (LICS 1993), pages 64\u201374. IEEE, June 1993.\n\n8. Acknowledgements\n\n[19] F. Pfenning and C. Sch\u00fcrmann. System description: Twelf - A metalogical framework for deductive systems. In H. Ganzinger, editor, 16th\nConference on Automated Deduction (CADE), number 1632 in LNAI,\npages 202\u2013206, Trento, 1999. Springer.\n\nThis work has been supported by the NSF grants CCR-0429572 and\nCCF-0917140. Opinions, findings, and conclusions or recommendations expressed in this papers are those of the authors and do not\nnecessarily reflect the views of the National Science Foundation.\n\n[20] B. Pientka. Eliminating redundancy in higher-order unification: A\nlightweight approach. In U. Furbach and N. Shankar, editors, IJCAR,\nvolume 4130 of Lecture Notes in Computer Science, pages 362\u2013376.\nSpringer, 2006. ISBN 3-540-37187-7.\n\n\f[21] B. Pientka and F. Pfenning. Optimizing higher-order pattern unification. In 19th International Conference on Automated Deduction, pages\n473\u2013487. Springer-Verlag, 2003.\n[22] J. Reed. Redundancy elimination for LF. Electron. Notes Theor.\nComput. Sci., 199:89\u2013106, 2008. ISSN 1571-0661. doi: http://dx.\ndoi.org/10.1016/j.entcs.2007.11.014.\n[23] Z. Snow. Parinati. http://www.cs.umn.edu/~ snow/parinati,\n2010.\n[24] Z. Snow. Realizing the dependently typed \u03bb-calculus. Master's thesis,\nUniversity of Minnesota, 2010.\n[25] Y. Takayama. Extraction of redundancy-free programs from constructive natural deduction proofs. Journal of Symbolic Computation, 12\n(1):29\u201369, 1991.\n\nA. Proofs of Theorems\nA.1 Correctness of the simplified encoding\n(Theorem 1)\nA.1.1 Completeness\nWe use induction on the derivation of \u0393 \u22a2 M : A to build one for\n{{\u0393}} \u2212\u2192 {{M : A}}. We proceed by case analysis on the canonical\ntype A.\nIf A is of the form \u03a0x:B.A\u2032 then M must be of the form \u03bbx:B.M \u2032\nand the LF derivation must end with an abs-obj rule, i.e., a rule of\nthe form\n\u0393 \u22a2 A\u2032 : Type \u0393, x : B \u22a2 M :\u2032 A\u2032\nabs-obj\n\u0393 \u22a2 (\u03bbx:B.M \u2032 ) : (\u03a0x:B.A\u2032 )\nThe induction hypothesis gives us a derivation for\n\u2032\n\n\u2032\n\n{{\u0393, x : B}} \u2212\u2192 {{M : A }}.\nBy applying the rules \u2200R and \u2283 R to this, we get a derivation for\n{{\u0393}} \u2212\u2192 \u2200x. {{x : B}} \u2283 {{M \u2032 : A\u2032 }}. The righthand side of this\nsequent is the expected goal:\n{{(\u03bbx:B.M \u2032 ) : (\u03a0x:B.A\u2032 )}} =\n\u2200x. {{x : B}} \u2283 ({{A\u2032 }} (h\u03bbx:B.M \u2032 i x)),\nand hM \u2032 i = (h\u03bbx:B.M \u2032 i x) by virtue of \u03b7-conversion.\nIf A is a base type then M must be of the form x N1 . . . Nn and\nthe canonical LF derivation must end with a chain of app-obj rules\nfollowing a var-obj rule that reveals that\n\u2032\n\nx : \u03a0y1 :B1 . . . . \u03a0yn :Bn .A \u2208 \u0393.\n\u2032\n\nMoreover, A must be A [N1 /y1 , . . . , Nn /yn ] and, from looking at\nthe right upper premise of the app-obj rules, there must be shorter\nderivations of\n\u0393 \u22a2 Ni : Bi [N1 /x1 , . . . , Ni\u22121 /xi\u22121 ]\nfor 1 \u2264 i \u2264 n. By the induction hypothesis we obtain derivations\nDi of {{\u0393}} \u2212\u2192 {{Ni : Bi [N1 /x1 , . . . , Ni\u22121 /xi\u22121 ]}}. Further,\n{{\u0393}} must contain\n\nA.1.2 Soundness\nWe prove the soundness direction by induction on the derivation\nof {{\u0393}} \u2212\u2192 ({{A}} M ): assuming that \u0393 \u22a2 A : Type has a\nderivation, we establish that M = hM \u2032 i for some canonical object\nM \u2032 and we build a derivation of \u0393 \u22a2 M \u2032 : A. A case analysis on\nthe structure of the canonical type A will guide us.\nIf A is of the form \u03a0x:B.A\u2032 then the structure of {{A}} forces the\nhohh derivation to conclude as follows:\n{{\u0393, x : B}} \u2212\u2192 ({{A\u2032 }} (M x))\n\u2200R, \u2283 R\n{{\u0393}} \u2212\u2192 \u2200x. ({{B}} x) \u2283 ({{A\u2032 }} (M x))\nSince A is a valid Type under \u0393, B must also be, and A\u2032 must be\nvalid under (\u0393, x : B). We can thus apply the inductive hypothesis,\nand we obtain that M x = hM \u2032 i and that \u0393, x : B \u22a2 M \u2032 : A\u2032\nis derivable for some canonical object M \u2032 . Since x does not occur\nfree in M , we conclude that\nM = (\u03bbx.hM \u2032 i) = h\u03bbx:B.M \u2032 i,\nand we derive \u0393 \u22a2 (\u03bbx:B.M \u2032 ) : (\u03a0x:B.A\u2032 ) using the abs-obj\nrule and our derivation of \u0393 \u22a2 B : Type.\nOtherwise, A is a base type, and the derivation we are considering\nis that of {{\u0393}} \u2212\u2192 hastype M hAi. This derivation must end in a\nbackchain rule that uses some clause in {{\u0393}} of the form\n\u2200y1 . ({{B1 }} y1 ) \u2283 . . . \u2283\n\u2200yn . ({{Bn }} yn ) \u2283 hastype (x y1 . . . yn ) hA\u2032 i;\nnote that the variables y1 , . . . , yi\u22121 can appear in {{Bi }} here. Thus,\nfor some hohh terms N1 , . . . , Nn ,\nhAi = hA\u2032 i[N1 /y1 , . . . , Nn /yn ],\nM = (x N1 . . . Nn ), and, for each i such that 1 \u2264 i \u2264 n, there is\na shorter derivation of\n{{\u0393}} \u2212\u2192 ({{Bi }} yi )[N1 /y1 , . . . , Ni /yi ],\ni.e., of {{\u0393}} \u2212\u2192 ({{Bi }}[N1 /y1 , . . . , Ni\u22121 /yi\u22121 ] Ni ). Further,\nwe know that x : \u03a0y1 :B1 . . . . \u03a0yn :Bn .A\u2032 \u2208 \u0393 for some x. We\nnow claim that, for 1 \u2264 i \u2264 n, Ni = hNi\u2032 i for some canonical\n\u2032\nLF object Ni\u2032 and that \u0393 \u22a2 Ni\u2032 : Bi [N1\u2032 /y1 . . . Ni\u22121\n/yi\u22121 ] has\na derivation. If this claim is true, then, we can use the var-obj rule\nto derive \u0393 \u22a2 x : \u03a0y1 :B1 . . . . \u03a0yn :Bn .A\u2032 and follow this by a\nsequence of app-obj rule applications to prove\n\u0393 \u22a2 (x N1\u2032 . . . Nn\u2032 ) : A\u2032 [N1\u2032 /y1 . . . Nn\u2032 /yn ].\nNow, evidently M = hx N1\u2032 . . . Nn\u2032 i and, since substitution\npermutes with encoding, A = A\u2032 [N1\u2032 /y1 , . . . , Nn\u2032 /yn ]. Thus, the\ndesired result would be proven.\nIt only remains to establish the claim. We actually strengthen it\nto include also the assertion that, for 1 \u2264 i \u2264 n,\n\u2032\n\u0393 \u22a2 Bi [N1\u2032 /y1 . . . Ni\u22121\n/yi\u22121 ] : Type\n\nhas a derivation. To prove it, we use an inner induction on i. Since\n\u0393 is a well-formed context, and x : \u03a0y1 :B1 . . . . \u03a0yn :Bn .A\u2032 \u2208 \u0393,\nthere must be a derivation of\n\n\u2200y1 . ({{B1 }} y1 ) \u2283 . . . \u2283\n\u2200yn . ({{Bn }} yn ) \u2283 hastype (x y1 . . . yn ) hA\u2032 i,\ni.e., the encoding of x : \u03a0y1 :B1 . . . . \u03a0yn :Bn .A\u2032 . By applying\nbackchain on that clause, choosing hNi i for yi and using the derivations Di , we obtain a derivation of\n{{\u0393}} \u2212\u2192 hastype (x hN1 i . . . hNn i)\n(hA\u2032 i[hN1 i/y1 , . . . hNn i/yn ]).\nThe right side of this sequent is precisely\n{{(x N1 . . . Nn ) : A\u2032 [N1 /y1 , . . . , Nn /yn ]}}.\n\n\u0393, x1 : B1 , . . . , xi\u22121 : Bi\u22121 \u22a2 Bi : Type\nfor 1 \u2264 i \u2264 n. Using Proposition 1 and the induction hypothesis\nwe see that there must be a derivation of\n\u2032\n\u0393 \u22a2 Bi [N1\u2032 /y1 . . . Ni\u22121\n/yi\u22121 ] : Type.\n\nNoting that\n{{Bi }}[N1 /y1 , . . . , Ni\u22121 /yi\u22121 ] = {{Bi [N1 /y1 , . . . , Ni\u22121 /yi\u22121 ]}},\nthe outer induction hypothesis and the shorter derivation of\n{{\u0393}} \u2212\u2192 ({{Bi }}[N1 /y1 , . . . , Ni\u22121 /yi\u22121 ] Ni )\n\n\fallows us to conclude that Ni = hNi\u2032 i for some canonical LF term\nNi\u2032 and that there is a derivation of\n\u2032\n\u0393 \u22a2 Ni\u2032 : Bi [N1\u2032 /y1 . . . Ni\u22121\n/yi\u22121 ],\n\nthus verifying the claim.\nA.2 Completeness of the optimized encoding (Theorem 2)\nIf {{\u0393}} \u2212\u2192 {{A}}M has a derivation, then J\u0393K+ \u2212\u2192 JAK\u2212 M\nhas a derivation as well. Note that for this direction of the proof\nwe are simply dropping information (subderivations) and so we\ndo not rely on \u0393 being a valid specification or A being a valid\ntype. We proceed by induction on the structure of the derivation\nof {{\u0393}} \u2212\u2192 {{A}}M , followed by case analysis on A.\nIf A is of the form \u03a0x:B.A\u2032 our derivation ends as follows:\n{{\u0393, x : B}} \u2212\u2192 {{A\u2032 }} (M x)\n\u2200R, \u2283 R\n{{\u0393}} \u2212\u2192 {{\u03a0x:B.A\u2032 }} M\nBy the inductive hypothesis J\u0393, x : BK+ \u2212\u2192 JA\u2032 K\u2212 (M x) has a\nderivation, and by applying \u2200R and \u2283 R to this derivation we can\nconstruct a derivation of\nJ\u0393K+ \u2212\u2192 J\u03a0x:B.A\u2032 K\u2212 M\nOtherwise, A is a base type and our derivation proceeds by backchain\u2212\u2212\u2192\ning on some (y : \u03a0x:B.A\u2032 ) \u2208 \u0393, with hAi = hA\u2032 i[t1 /x1 . . . tn /xn ]:\n{{\u0393}} \u2212\u2192 F1\n\n...\n\n{{\u0393}} \u2212\u2192 Fn\nbackchain\n\u2192\n\u2212\n{{\u0393}} \u2212\u2192 {{A}} (y t )\n\nHere, Fi = ({{Bi }} xi )[t1 /x1 . . . tn /xn ]. As in the completeness\nproof of the simplified encoding, we obtain by an inner induction\nthat each ti is of the form ht\u2032i i and thus that\nFi = {{Bi [t\u20321 /x1 . . . t\u2032n /xn ]}}(ti ).\n\u2192\n\u2212\nWe shall build the derivation of J\u0393K+ \u2212\u2192 JAK\u2212 (y t ) by using\n\u2212\u2212\u2192 \u2032\nbackchain on the optimized encoding of (y : \u03a0x:B.A ) \u2208 \u0393, by\n\u2192\n\u2212\n\u2192\nchoosing t for \u2212\nx . The resulting premises are either\nJ\u0393K+ \u2212\u2192 JBi [t\u20321 /x1 . . . t\u2032n /xn ]K\u2212 ti\nwhen xi does not occur rigidly in A\u2032 , and this case is provided for\nby the inductive hypothesis, or \u22a4 otherwise, which we derive using\n\u22a4 R.\n\n\f"}