{"id": "http://arxiv.org/abs/physics/0607007v4", "guidislink": true, "updated": "2006-10-28T22:06:19Z", "updated_parsed": [2006, 10, 28, 22, 6, 19, 5, 301, 0], "published": "2006-07-02T23:16:18Z", "published_parsed": [2006, 7, 2, 23, 16, 18, 6, 183, 0], "title": "Thermal noise driven computing", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=physics%2F0607220%2Cphysics%2F0607014%2Cphysics%2F0607284%2Cphysics%2F0607069%2Cphysics%2F0607248%2Cphysics%2F0607264%2Cphysics%2F0607154%2Cphysics%2F0607174%2Cphysics%2F0607082%2Cphysics%2F0607167%2Cphysics%2F0607021%2Cphysics%2F0607209%2Cphysics%2F0607092%2Cphysics%2F0607162%2Cphysics%2F0607031%2Cphysics%2F0607010%2Cphysics%2F0607199%2Cphysics%2F0607127%2Cphysics%2F0607011%2Cphysics%2F0607210%2Cphysics%2F0607061%2Cphysics%2F0607289%2Cphysics%2F0607132%2Cphysics%2F0607215%2Cphysics%2F0607059%2Cphysics%2F0607279%2Cphysics%2F0607026%2Cphysics%2F0607192%2Cphysics%2F0607227%2Cphysics%2F0607017%2Cphysics%2F0607089%2Cphysics%2F0607255%2Cphysics%2F0607207%2Cphysics%2F0607007%2Cphysics%2F0607275%2Cphysics%2F0607116%2Cphysics%2F0607141%2Cphysics%2F0607077%2Cphysics%2F0607258%2Cphysics%2F0607206%2Cphysics%2F0607004%2Cphysics%2F0607250%2Cphysics%2F0607263%2Cphysics%2F0607252%2Cphysics%2F0607268%2Cphysics%2F0607106%2Cphysics%2F0607219%2Cphysics%2F0607241%2Cphysics%2F0607030%2Cphysics%2F0607274%2Cphysics%2F0607158%2Cphysics%2F0607009%2Cphysics%2F0607025%2Cphysics%2F0607102%2Cphysics%2F0607087%2Cphysics%2F0607008%2Cphysics%2F0607094%2Cphysics%2F0607295%2Cphysics%2F0607236%2Cphysics%2F0607023%2Cphysics%2F0607185%2Cphysics%2F0607208%2Cphysics%2F0607048%2Cphysics%2F0607063%2Cphysics%2F0607095%2Cphysics%2F0607230%2Cphysics%2F0607140%2Cphysics%2F0607125%2Cphysics%2F0607171%2Cphysics%2F0607237%2Cphysics%2F0607177%2Cphysics%2F0607005%2Cphysics%2F0607228%2Cphysics%2F0607232%2Cphysics%2F0607226%2Cphysics%2F0607281%2Cphysics%2F0607024%2Cphysics%2F0607115%2Cphysics%2F0607078%2Cphysics%2F0607156%2Cphysics%2F0607036%2Cphysics%2F0607244%2Cphysics%2F0607015%2Cphysics%2F0607075%2Cphysics%2F0607269%2Cphysics%2F0607212%2Cphysics%2F0607142%2Cphysics%2F0607229%2Cphysics%2F0607117%2Cphysics%2F0607097%2Cphysics%2F0607049%2Cphysics%2F0607058%2Cphysics%2F0607062%2Cphysics%2F0607019%2Cphysics%2F0607161%2Cphysics%2F0607273%2Cphysics%2F0607222%2Cphysics%2F0607198%2Cphysics%2F0607129%2Cphysics%2F0607006%2Cphysics%2F0607104&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Thermal noise driven computing"}, "summary": "The possibility of a new type of computing, where thermal noise is the\ninformation carrier and the clock in a computer, is studied. The information\nchannel capacity and the lower limit of energy requirement/dissipation are\nstudied in a simple digital system with zero threshold voltage, for the case of\nerror probability close to 0.5, when the thermal noise is equal to or greater\nthan the digital signal. In a simple hypothetical realization of a thermal\nnoise driven gate, the lower limit of energy needed to generate the digital\nsignal is 1.1*kT/bit. The arrangement has potentially improved energy\nefficiency and it is free of leakage current, crosstalk and ground plane\nelectromagnetic interference problems. Disadvantage is the large number of\nredundancy elements needed for low-error operation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=physics%2F0607220%2Cphysics%2F0607014%2Cphysics%2F0607284%2Cphysics%2F0607069%2Cphysics%2F0607248%2Cphysics%2F0607264%2Cphysics%2F0607154%2Cphysics%2F0607174%2Cphysics%2F0607082%2Cphysics%2F0607167%2Cphysics%2F0607021%2Cphysics%2F0607209%2Cphysics%2F0607092%2Cphysics%2F0607162%2Cphysics%2F0607031%2Cphysics%2F0607010%2Cphysics%2F0607199%2Cphysics%2F0607127%2Cphysics%2F0607011%2Cphysics%2F0607210%2Cphysics%2F0607061%2Cphysics%2F0607289%2Cphysics%2F0607132%2Cphysics%2F0607215%2Cphysics%2F0607059%2Cphysics%2F0607279%2Cphysics%2F0607026%2Cphysics%2F0607192%2Cphysics%2F0607227%2Cphysics%2F0607017%2Cphysics%2F0607089%2Cphysics%2F0607255%2Cphysics%2F0607207%2Cphysics%2F0607007%2Cphysics%2F0607275%2Cphysics%2F0607116%2Cphysics%2F0607141%2Cphysics%2F0607077%2Cphysics%2F0607258%2Cphysics%2F0607206%2Cphysics%2F0607004%2Cphysics%2F0607250%2Cphysics%2F0607263%2Cphysics%2F0607252%2Cphysics%2F0607268%2Cphysics%2F0607106%2Cphysics%2F0607219%2Cphysics%2F0607241%2Cphysics%2F0607030%2Cphysics%2F0607274%2Cphysics%2F0607158%2Cphysics%2F0607009%2Cphysics%2F0607025%2Cphysics%2F0607102%2Cphysics%2F0607087%2Cphysics%2F0607008%2Cphysics%2F0607094%2Cphysics%2F0607295%2Cphysics%2F0607236%2Cphysics%2F0607023%2Cphysics%2F0607185%2Cphysics%2F0607208%2Cphysics%2F0607048%2Cphysics%2F0607063%2Cphysics%2F0607095%2Cphysics%2F0607230%2Cphysics%2F0607140%2Cphysics%2F0607125%2Cphysics%2F0607171%2Cphysics%2F0607237%2Cphysics%2F0607177%2Cphysics%2F0607005%2Cphysics%2F0607228%2Cphysics%2F0607232%2Cphysics%2F0607226%2Cphysics%2F0607281%2Cphysics%2F0607024%2Cphysics%2F0607115%2Cphysics%2F0607078%2Cphysics%2F0607156%2Cphysics%2F0607036%2Cphysics%2F0607244%2Cphysics%2F0607015%2Cphysics%2F0607075%2Cphysics%2F0607269%2Cphysics%2F0607212%2Cphysics%2F0607142%2Cphysics%2F0607229%2Cphysics%2F0607117%2Cphysics%2F0607097%2Cphysics%2F0607049%2Cphysics%2F0607058%2Cphysics%2F0607062%2Cphysics%2F0607019%2Cphysics%2F0607161%2Cphysics%2F0607273%2Cphysics%2F0607222%2Cphysics%2F0607198%2Cphysics%2F0607129%2Cphysics%2F0607006%2Cphysics%2F0607104&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The possibility of a new type of computing, where thermal noise is the\ninformation carrier and the clock in a computer, is studied. The information\nchannel capacity and the lower limit of energy requirement/dissipation are\nstudied in a simple digital system with zero threshold voltage, for the case of\nerror probability close to 0.5, when the thermal noise is equal to or greater\nthan the digital signal. In a simple hypothetical realization of a thermal\nnoise driven gate, the lower limit of energy needed to generate the digital\nsignal is 1.1*kT/bit. The arrangement has potentially improved energy\nefficiency and it is free of leakage current, crosstalk and ground plane\nelectromagnetic interference problems. Disadvantage is the large number of\nredundancy elements needed for low-error operation."}, "authors": ["Laszlo B. Kish"], "author_detail": {"name": "Laszlo B. Kish"}, "author": "Laszlo B. Kish", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1063/1.2359293", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/physics/0607007v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/physics/0607007v4", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Reference data added", "arxiv_primary_category": {"term": "physics.gen-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "physics.gen-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/physics/0607007v4", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/physics/0607007v4", "journal_reference": "Applied Physics Letters 89 (2006) 144104 (October 2)", "doi": "10.1063/1.2359293", "fulltext": "Published: Applied Physics Letters 89, 144104 (2006) (October 2)\narxiv.org/abs/physics/0607007\n\nThermal noise driven computing\n\nLaszlo B. Kisha)\nTexas A&M University, Department of Electrical and Computer Engineering, College\nStation, TX 77843-3128, USA; email: Laszlo.Kish@ece.tamu.edu\n\n(July 2, 29; 2006)\n\nAbstract. A new type of computing, where thermal noise is the information carrier and\nthe clock in a computer, is proposed. The energy requirement/dissipation are studied in a\nsimple digital system with zero threshold voltage, when the thermal noise is equal to or\ngreater than the digital signal. In a simple realization of a thermal noise driven gate, the\nlower limit of energy needed to generate the digital signal is o 1.1* kT / bit . The\narrangement has potentially improved energy efficiency and it is free of leakage current,\ncrosstalk and ground plane electromagnetic interference problems. Disadvantage is the\nlarger number of required elements.\n\nKeywords: Johnson noise; energy dissipation; suprathreshold stochastic resonator;\nleakage current.\n\na)\n\nUntil 1999: L.B. Kiss\n\n1\n\n\fRecently, it has been shown [1-4] that modulated thermal noise (Johnson noise)\ncan be a special type of information carrier and it can be used for stealth communication\n[1], totally secure non-quantum communication [2,3], and the realization of totally secure\nclassical networks [4]. These results inspire a further question:\n\nIf Johnson noise is such a peculiar information carrier, can it perhaps be applied to data\nprocessing and computing, too?\n\nThough, we do not know the full answer to this question, in this Letter, we shall\nshow a potential application of Johnson noise to reduce the problems of energy\ndissipation, leakage current, crosstalk and ground plane electromagnetic interference\n(EMI) in microprocessors. This idea may first look strange because the ultimate lower\nlimits of energy dissipation in computers is dictated by Johnson noise, see [5-8] and\nreferences therein. However, here we attempt to put thermal noise to work for us by\ndriving the logic devices. We shall analyze how much is the information channel capacity\nof a particular realization of the thermal noise driven digital information channel and\nwhat is the lower limit of the energy requirement of transferring information through\nsuch a channel. Our other inspiration is the fact that neural signals are stochastic, which\nindicates that the brain is using noise as an information carrier [9], and at the same time\nthe brain is an extremely energy efficient signal processor [10]. It is tempting to assume\nthat the great energy efficiency of the brain is somehow related to the stochastic nature of\nneural signals [10].\n\nNote that John von Neumann [11]; Forshaw and coworkers [12,13]; and Palem\nand coworkers [14,15] have been proposing efficient ways of working with probabilistic\nswitches, which are noisy digital logic units with relatively high error probability. Palem\n2\n\n\fand coworkers have pointed out that this may be a way to reduce power dissipation\n[14,15]. However, though these approaches can be relevant to future developments of the\nideas outlined in the present paper, they are very different from our present approach. The\nsystem we propose is working in the regime of huge error probability, o 0.5 , with zero\nlogic threshold voltage and in the sub-noise signal amplitude limit, out of the range used\nby others. In the thermal noise driven computer the voltage in the channel is basically a\nnoise and the statistical properties of this noise carry the information. Moreover, we base\nour study on Shannon's channel coding theorem because we believe that this theory is the\nproper application tool to characterize the ultimate information channel capacity and the\nenergy efficiency in the relevant digital channels.\n\nTherefore, the thermal noise driven computer is a computer where (most of) the\nlogic gates are driven by a very small DC digital signal voltage U s , which is zero in the\n\"low\" logic state, U sL = 0 , and it is equal to or less than the effective Johnson noise\nvoltage s in the \"high\" logic state U sH \u00a7 s . This situation will produce an extremely\nhigh error rate, close to the limit of 0.5 error probability in the digital channel, which is\nthe case of zero information content. Thus the information channel has very low\ninformation content however, as we shall show, the energy requirement of creating the\ndigital signal is also very low. Concerning the energy efficiency of such a computer, the\nimportant question is the energy requirement of handling a single bit (Joule/bit). We shall\ncalculate the lower limit of this energy requirement.\n\nThe highest possible information rate in a digital channel is given by Shannon's\nchannel coding theorem:\n\nC dig = fc [1+ p log 2 p + (1- p) log 2 (1- p)] ,\n\n3\n\n(1)\n\n\fwhere C dig is the information channel capacity, fc is the clock frequency, p is the\nprobability of correct bit and 1- p is the error probability, see Figure 1. Though Eq. (1)\nprovides the exact value of the information channel capacity, it does not show us what\nkind of encoding is needed to approach this limit.\n\nThe lowest (second) order of the Taylor expansion of Eq. 1 around the value\np = 0.5 yields\n\nC dig\n\npo0.5\n\n= ( Dp)\n\n2\n\n2\nfc ,\nln2\n\n(2)\n\nwhere Dp = p - 0.5 . The parabolic approximation given by Eq. (2) is very accurate in the\ninteresting range ( p o 0.5 ). Even at p = 1, which is far out of our range and where the\ninaccuracy of approximation is maximal; the relative inaccuracy is less than 30%. We\nwill see that not only C dig but also the electrical power requirement to generate the signal\n\n( )\n\nis scaling with Dp\n\n2\n\nin the interesting range. Therefore, when the error rate is\n\napproaching 0.5 and the information content goes to zero, the energy requirement of\ngenerating a bit converges to a fixed value, where this value may depend on the\nrealization of the computer.\n\nFor a possible realization of the thermal noise driven computing, let us suppose\nthat a weak digital signal U s (t) , where the \"l o w \" and \"h i g h \" levels satisfy\n\nU sL = 0 and 0 < U sH \u00a7s , drives a simple comparator [16] with zero reference voltage\nU ref = 0 , see Fig. (2). The internal resistance of the output of the driving logic gate is\nrepresented by the resistance R and the total driven capacitance (given by the sum of the\n4\n\n\fcomparator's input capacitance and the parasite capacitances) is represented by the\ncapacitor C. The comparator is a logic representation of the input stage of the subsequent\ngate and we do not deal with the rest of logic operations by that gate. The output of the\ncomparator provides a digital voltage via the signum operation [16,17]: if the input\nvoltage is greater than zero, the output is \"hi\" and if the input voltage is less than zero, the\noutput is \"low\".\n\nWhen the computer is running, in the case of U S (t) = 0 (\"low\" input), the\ncomparator output shows p = 0.5 because the Johnson-noise has zero mean with a\nsymmetric (Gaussian) amplitude density function around zero. However, for U s (t) = U sH\n(\"high\" input), the input Johnson noise will be superimposed on the nonzero DC signal\n\nU sH thus p > 0.5 due to the small asymmetry of the resultant amplitude density function\naround zero. Note comparator units driven with analog signals and additive noise have\nbeen used by Stocks [16,17] to propose and demonstrate the so-called suprathreshold\nstochastic resonance, where the noise acts as an information carrier of the analog signal.\nThe noise was band-limited Gaussian white noise.\n\nIn this Letter, we avoid any practical question concerning the practical realization\nof this computer, including the problem of the comparator. We are allowed to do that\nbecause we are looking for the lower limit of the energy requirement of processing a\nsingle bit. Because the digital signal must be generated in the information channel to run\nthe computer, the energy requirement of generating the digital signal at idealistic\nconditions is an absolute lower limit of the energy dissipation.\n\nIf we alternate the channel signal between \"low\" and \"high\" levels with the clock\nfrequency, see Fig. (2), then at each clock period we dissipate the charging energy of the\n5\n\n\fcapacitor C two times, first when we charge the capacitor and second when we discharge\nit [7], thus the power dissipation to generate the digital signal is given by:\n\n1\n2\nPs = fc CU sH\n2\n\n(3)\n\nBy approximating the Gaussian shape of the amplitude distribution g(U ) of the thermal\nnoise with its top value g(0) (in our regime where p o 0.5 ) and use the s = kT / C\nJohnson relation [7], we get:\n\nDp o g(0)U s =\n\nUs\n2p s\n\n=\n\nUs\n2pkT / C\n\n.\n\n(4)\n\nSupposing a symmetric time distribution of \"low\" and \"high\" bits, the effective Dp is the\naverage of the two cases, and from Eqs. (2,3) we obtain:\n\nC dig\n\n=\npo0.5\n\n2\nU sH\nfc\np ln2 kT / C\n\n.\n\n(5)\n\nThus, from Eqs. (3,5) we find that the mean energy cost/bit operation is constant:\n\nPs\nC dig\n\npo0.5\n\n=\n\np ln2\nkT / bit o 1.1 kT / bit .\n2\n\nConversely, the energy efficiency h of the data processing is impressive:\n\n6\n\n(6)\n\n\fh=\n\nC dig\n\npo0.5\n\nPs\n\n=\n\n2\nbit / kT o 0.9 bit / kT o 2.3*10 20 bit / Joule\np ln2\n\n(7)\n\nIt is interesting to note that the above results contradict to the general opinion that\nno digital signal can be used if the energy difference between logic levels is less than\nkT * ln(2) or, if not, then a potential barrier of similar height should be between the two\nstates. Such a statement is valid at most for certain types of digital memories. The\nexistence of Shannon's Eq. (1) and the results above indicate that digital signal channels\nwithout information storage elements can process information at arbitrary, nonzero\nenergy difference between the logic states.\n\nToday's microprocessors dissipate >>25,000 kT / bit energy [8] (though for the\nlow-error operation o 70 kT/bit would be enough [6-8] so the present 1.1*kT/bit value\nmay look promising. However, we should keep in mind that today's Turing type generalpurpose computers need error-free operation, and that would require error correcting\nunits (redundancy) and/or error correcting algorithms to function. The error correction\nneed could increase the energy dissipation in the thermal noise driven computer\npotentially by orders of magnitude and though the information channel capacity would\nalso increase, the resulting Ps / C dig is a non-trivial problem. These results strongly\ndepend on the way of error correction [11-13] and computer architecture.\n\nIn conclusion, the main advantage of such a hypothetical thermal noise driven\ncomputer would be a potentially improved energy efficiency and an obvious lack of\nleakage current, cross-talk and ground EMI problems due the very low DC voltages. An\napparent disadvantage is the large number of extra (redundancy) elements required for\nerror reduction [11-13].\n\n7\n\n\fFinally, we list some of the most important open questions we have not been able\nto address here:\n\n1. Do we need error correction at all (except input/output operations) when we want to\nsimulate the way the brain works?\n\n2. Is there any way to realize a non-Turing machine with stochastic elements without\nexcessive hardware/software based redundance?\n\n3. How should redundancy and error correction be efficiently used to run the thermal\nnoise driven computer as a Turing machine?\n\n4. How much energy would such error correction cost?\n\n5. How much energy is needed to feed the comparator?\n\n6. What is the impact of the noise of the comparator and how to reduce it?\n\nThough, all these questions are relevant for the ultimate energy dissipation of\nthermal noise driven computers, the lower limit given in this Letter stays valid because\nthis is the energy need to generate the digital signal.\n\n8\n\n\fReferences\n\n1.\n\nL.B. Kish, Appl. Physics Lett. 87 (2005), Art. No. 234109.\n\n2.\n\nL.B. Kish, Phys. Lett. A 352, 178-182, (2006);\nalso at http://arxiv.org/physics/0509136.\n\n3.\n\nA. Cho, Science 309, 2148, (2005).\n\n4.\n\nL.B. Kish and P. Mingesz, Fluct. Noise Lett. 6, C9-C21, (2006).\n\n5.\n\nW. Porod, Appl. Phys. Lett. 52, 2191 (1988); and references therein; W. Porod, R.O.\nGrondin, D.K. Ferry, Phys. Rev. Lett. 52, 232-235, (1984); W. Porod, R.O.\nGrondin, D.K. Ferry, G. Porod, Phys. Rev. Lett. 52, 1206, (1984); and references\ntherein.\n\n6.\n\nR.K. Cavin, V.V. Zhirnov, J.A. Hutchby, G.I Bourianoff, Fluct. Noise Lett. 5, C2938, (2005).\n\n7.\n\nL.B. Kish, Phys. Lett. A 305, 144\u2013149, (2002).\n\n8.\n\nL.B. Kish, \"On the fundamental limits of digital computing\", Emerging Research\nDevice Architectures Workshop by Semiconductor Research Corporation and\nInternational Technology Roadmap for Semiconductors and National Science\nFoundation, 9th July 2006, San Francisco. (Relevant paper under preparation).\n\n9\n\n\f9.\n\nG. Balazsi, L.B. Kish, Phys. Lett. A 265, 304 \u2013 316, (2000).\n\n10.\n\nS.M. Bezrukov, L.B. Kish, Smart Mater. Struct. 11 (2002) 800\u2013803.\n\n11.\n\nJ. von Neumann, in Automata Studies, eds. C.E. Shannon, J. McCarthy, Princeton\nUniv. Press, 329-378, (1956).\n\n12.\n\nK. Nikolic, A. Sadek, M. Forshaw, Nanotechnology 13, 357-362, (2002).\n\n13. A.S. Sadek, K. Nikolic, M. Forshaw, Nanotechnology 15, 192-21, (2004); and\nreferences therein.\n\n14.\n\nK.V. Palem, IEEE Trans. Comput. 54, 1123, (2005); and references therein.\n\n15. P. Korkmaz, B.E.S. Akgul, K.V. Palem, L.N. Chakrapani, Jap. Journ. Appl. Phys.\n45, 3307-3316, (2006).\n\n16.\n\nN.G. Stocks, Phys. Lett. A 279, 308-312 (2001).\n\n17.\n\nN.G. Stocks, Phys. Rev E 63, 041114, 1-9, (2001).\n\n10\n\n\fFigure caption\n\nFigure 1.\nShannon's channel capacity of digital channels and the working regimes of the thermal\nnoise driven and classical computers, respectively.\n\nFigure 2.\nModel circuitry of the information channel of a possible realization of the thermal noise\ndriven computer. The U th (t) is the inherent Johnson noise voltage of the resistor R .\n\n11\n\n\f\fUth(t)\nR\n\n1\nUsH\n\n2\n\nC\nU ref = 0\n\n\f"}