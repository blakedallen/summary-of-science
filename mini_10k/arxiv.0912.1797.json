{"id": "http://arxiv.org/abs/0912.1797v2", "guidislink": true, "updated": "2010-12-15T14:41:05Z", "updated_parsed": [2010, 12, 15, 14, 41, 5, 2, 349, 0], "published": "2009-12-09T16:49:00Z", "published_parsed": [2009, 12, 9, 16, 49, 0, 2, 343, 0], "title": "On a Model for Mass Aggregation with Maximal Size", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0912.0083%2C0912.4867%2C0912.5209%2C0912.3998%2C0912.1729%2C0912.4484%2C0912.4001%2C0912.0604%2C0912.4761%2C0912.4527%2C0912.2509%2C0912.2327%2C0912.3233%2C0912.1138%2C0912.1206%2C0912.4262%2C0912.3531%2C0912.0215%2C0912.3411%2C0912.0499%2C0912.4002%2C0912.5480%2C0912.4376%2C0912.5013%2C0912.1035%2C0912.2975%2C0912.3335%2C0912.1926%2C0912.0548%2C0912.4718%2C0912.1639%2C0912.2171%2C0912.2650%2C0912.4429%2C0912.5426%2C0912.5510%2C0912.0901%2C0912.0309%2C0912.5057%2C0912.1379%2C0912.4217%2C0912.3469%2C0912.2764%2C0912.2629%2C0912.2511%2C0912.1896%2C0912.2688%2C0912.4367%2C0912.1880%2C0912.3121%2C0912.2634%2C0912.4840%2C0912.0989%2C0912.0808%2C0912.2494%2C0912.5131%2C0912.1873%2C0912.3597%2C0912.0506%2C0912.4095%2C0912.0869%2C0912.0821%2C0912.5256%2C0912.1889%2C0912.2190%2C0912.1845%2C0912.3762%2C0912.3264%2C0912.1374%2C0912.0260%2C0912.2101%2C0912.4602%2C0912.1699%2C0912.2893%2C0912.0038%2C0912.3339%2C0912.3298%2C0912.2803%2C0912.0391%2C0912.2354%2C0912.2348%2C0912.1033%2C0912.3509%2C0912.2445%2C0912.0973%2C0912.2009%2C0912.2052%2C0912.0048%2C0912.1377%2C0912.2516%2C0912.0875%2C0912.4329%2C0912.1681%2C0912.3507%2C0912.3326%2C0912.4054%2C0912.0571%2C0912.1797%2C0912.1850%2C0912.1227%2C0912.2726&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On a Model for Mass Aggregation with Maximal Size"}, "summary": "We study a kinetic mean-field equation for a system of particles with\ndifferent sizes, in which particles are allowed to coagulate only if their\nsizes sum up to a prescribed time-dependent value. We prove well-posedness of\nthis model, study the existence of self-similar solutions, and analyze the\nlarge-time behavior mostly by numerical simulations. Depending on the parameter\n$\\Dconst$, which controls the probability of coagulation, we observe two\ndifferent scenarios: For $\\Dconst>2$ there exist two self-similar solutions to\nthe mean field equation, of which one is unstable. In numerical simulations we\nobserve that for all initial data the rescaled solutions converge to the stable\nself-similar solution. For $\\Dconst<2$, however, no self-similar behavior\noccurs as the solutions converge in the original variables to a limit that\ndepends strongly on the initial data. We prove rigorously a corresponding\nstatement for $\\Dconst\\in (0,1/3)$. Simulations for the cross-over case\n$\\Dconst=2$ are not completely conclusive, but indicate that, depending on the\ninitial data, part of the mass evolves in a self-similar fashion whereas\nanother part of the mass remains in the small particles.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0912.0083%2C0912.4867%2C0912.5209%2C0912.3998%2C0912.1729%2C0912.4484%2C0912.4001%2C0912.0604%2C0912.4761%2C0912.4527%2C0912.2509%2C0912.2327%2C0912.3233%2C0912.1138%2C0912.1206%2C0912.4262%2C0912.3531%2C0912.0215%2C0912.3411%2C0912.0499%2C0912.4002%2C0912.5480%2C0912.4376%2C0912.5013%2C0912.1035%2C0912.2975%2C0912.3335%2C0912.1926%2C0912.0548%2C0912.4718%2C0912.1639%2C0912.2171%2C0912.2650%2C0912.4429%2C0912.5426%2C0912.5510%2C0912.0901%2C0912.0309%2C0912.5057%2C0912.1379%2C0912.4217%2C0912.3469%2C0912.2764%2C0912.2629%2C0912.2511%2C0912.1896%2C0912.2688%2C0912.4367%2C0912.1880%2C0912.3121%2C0912.2634%2C0912.4840%2C0912.0989%2C0912.0808%2C0912.2494%2C0912.5131%2C0912.1873%2C0912.3597%2C0912.0506%2C0912.4095%2C0912.0869%2C0912.0821%2C0912.5256%2C0912.1889%2C0912.2190%2C0912.1845%2C0912.3762%2C0912.3264%2C0912.1374%2C0912.0260%2C0912.2101%2C0912.4602%2C0912.1699%2C0912.2893%2C0912.0038%2C0912.3339%2C0912.3298%2C0912.2803%2C0912.0391%2C0912.2354%2C0912.2348%2C0912.1033%2C0912.3509%2C0912.2445%2C0912.0973%2C0912.2009%2C0912.2052%2C0912.0048%2C0912.1377%2C0912.2516%2C0912.0875%2C0912.4329%2C0912.1681%2C0912.3507%2C0912.3326%2C0912.4054%2C0912.0571%2C0912.1797%2C0912.1850%2C0912.1227%2C0912.2726&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We study a kinetic mean-field equation for a system of particles with\ndifferent sizes, in which particles are allowed to coagulate only if their\nsizes sum up to a prescribed time-dependent value. We prove well-posedness of\nthis model, study the existence of self-similar solutions, and analyze the\nlarge-time behavior mostly by numerical simulations. Depending on the parameter\n$\\Dconst$, which controls the probability of coagulation, we observe two\ndifferent scenarios: For $\\Dconst>2$ there exist two self-similar solutions to\nthe mean field equation, of which one is unstable. In numerical simulations we\nobserve that for all initial data the rescaled solutions converge to the stable\nself-similar solution. For $\\Dconst<2$, however, no self-similar behavior\noccurs as the solutions converge in the original variables to a limit that\ndepends strongly on the initial data. We prove rigorously a corresponding\nstatement for $\\Dconst\\in (0,1/3)$. Simulations for the cross-over case\n$\\Dconst=2$ are not completely conclusive, but indicate that, depending on the\ninitial data, part of the mass evolves in a self-similar fashion whereas\nanother part of the mass remains in the small particles."}, "authors": ["Ondrej Bud\u00e1\u010d", "Michael Herrmann", "Barbara Niethammer", "Andrej Spielmann"], "author_detail": {"name": "Andrej Spielmann"}, "author": "Andrej Spielmann", "links": [{"title": "doi", "href": "http://dx.doi.org/10.3934/krm.2011.4.427", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0912.1797v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0912.1797v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "new version with revised proofs; 13 pages, several figures", "arxiv_primary_category": {"term": "math.AP", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.AP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.MP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "45K05, 82C22", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0912.1797v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0912.1797v2", "journal_reference": "Kinetic and Related Models, vol. 4, no. 2, pp. 427-439, 2012", "doi": "10.3934/krm.2011.4.427", "fulltext": "On a Model for Mass Aggregation with Maximal Size\n\narXiv:0912.1797v2 [math.AP] 15 Dec 2010\n\nOndrej Bud\u00e1\u010d\u2217 Michael Herrmann\u2020 Barbara Niethammer\u2021 Andrej Spielmann\u00a7\nNovember 3, 2018\n\nAbstract\nWe study a kinetic mean-field equation for a system of particles with different sizes, in\nwhich particles are allowed to coagulate only if their sizes sum up to a prescribed timedependent value. We prove well-posedness of this model, study the existence of self-similar\nsolutions, and analyze the large-time behavior mostly by numerical simulations. Depending\non the parameter k0 , which controls the probability of coagulation, we observe two different\nscenarios: For k0 > 2 there exist two self-similar solutions to the mean field equation, of\nwhich one is unstable. In numerical simulations we observe that for all initial data the\nrescaled solutions converge to the stable self-similar solution. For k0 < 2, however, no selfsimilar behavior occurs as the solutions converge in the original variables to a limit that\ndepends strongly on the initial data. We prove rigorously a corresponding statement for\nk0 \u2208 (0, 1/3). Simulations for the cross-over case k0 = 2 are not completely conclusive, but\nindicate that, depending on the initial data, part of the mass evolves in a self-similar fashion\nwhereas another part of the mass remains in the small particles.\n\nKeywords:\n\naggregation with maximal size, self-similar solutions,\ncoarsening in coagulation models\n\nMSC (2000):\n\n45K05, 82C22\n\n1\n\nIntroduction\n\nMass aggregation is a fundamental process that appears in a large range of applications, such as\nformation of aerosols, polymerization, clustering of stars or ballistic aggregation, see for instance\n[2, 6, 12]. In all these applications, certain types of 'particles' form clusters that are characterized\nby their 'size' or 'mass' x. Smoluchowski's [11] classical mesoscopic mean-field description of\nirreversible aggregation processes describes the evolution of the number density g(t, x) of clusters\nof size x per unit volume at time t. Clusters of size x and y can coalesce by binary collisions to\nform clusters of size x + y at a rate given by a kernel K(x, y), such that the dynamics of g is\ngiven by\nZ \u221e\nZ\n1 x\n\u2202\ng(t, x) =\nK(x, y)g(t, y) dy .\n(1)\nK(y, x \u2212 y)g(t, x \u2212 y)g(t, y) dy \u2212 g(t, x)\n\u2202t\n2 0\n0\nAn issue of fundamental interest in the mathematical analysis of coagulation processes is the\nphenomenon of dynamic scaling for homogeneous kernels. This means that for initial data from a\n\u2217\n\nVrije Universiteit Amsterdam, ondrob@gmail.com\nOxford Centre for Nonlinear PDE (OxPDE), michael.herrmann@maths.ox.ac.uk\n\u2021\nOxford Centre for Nonlinear PDE (OxPDE), niethammer@maths.ox.ac.uk\n\u00a7\n\u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne, andrej.spielmann@epfl.ch\n\n\u2020\n\n1\n\n\fcertain class the solution to (1) converges to a certain self-similar solution. Unfortunately, except\nfor some special kernels such as the constant one, this question is still only poorly understood\n(see e.g. [8] for an overview). While it has been common belief in the applied literature that\nself-similar solutions are unique, it has recently been shown for some special kernels [9] that there\nis a whole one-parameter family of self-similar solutions. These solutions can be distinguished\nby their tail behavior, and their respective domains of attraction are characterized by the tail\nbehavior of the initial data.\nIn contrast to this, very little is known for other homogeneous kernels. The existence of\nfast-decaying self-similar solutions for a range of kernels is established in [3, 4], but both the\nexistence of solutions with algebraic tail and the uniqueness of solutions are still open problems.\nIn general, unless explicit methods such as the Laplace transform work, just proving existence\nof self-similar solutions to a coagulation equation can be a formidable task.\nThus, despite their fundamental role, many properties of mean-field models for coagulation\nprocesses, in particular with respect to dynamic scaling, are not well understood. Motivated\nby an application of elasto-capillary coalescence of wetted polyester lamellas [1], we investigate\nthis question for a special singular coagulation kernel K. This kernel allows only those clusters\nto coagulate that can form clusters of a given maximal size. To our knowledge this is the first\nmathematical analysis for such type of kernels. Even though tails of the size distribution do not\nplay a role here, we find that self-similar solutions are still not unique and the analysis of the\nlong-time behavior turns out to be delicate.\nIn model considered here, two particles can coagulate only if the sum of their sizes is equal to\nM (t), where M is a given increasing function of time. This means that at time t only particles\nof size M (t) are emerging and the amount of particles of all smaller sizes is decreasing. This\ncorresponds to K(x, y, t) \u223c \u03b40 (x + y \u2212 M (t)), where \u03b40 denotes the delta-distribution in 0 and\nthe factor of proportionality may depend on time.\nAs above, we denote the number density of particles of size x at time t by g(t, x). The total\nR M (t)\nnumber of particles per unit volume at time t is then N (t) = 0\ng(t, x)dx. At time t, the\ndensity of particles of any size x < M (t) is decreasing at a rate proportional to the probability\ndensity of a particle of size x meeting a particle of size M (t) \u2212 x. The coagulation process can\nhence be described by\ng(t, x) g(t, M (t) \u2212 x)\n\u2202g\n(t, x) = \u2212K(t)\n\u2202t\nN (t)\nN (t)\nwhere K(t) is a rate function proportional to the expected number of coagulation events per\nunit time. Motivated by [1] we make the ansatz K(t) = k0 M \u2032 (t)N (t), where k0 is a constant\nof proportionality that depends on the particular physical process. The above equation hence\nreads\nk0 M \u2032 (t)\n\u2202g\n(t, x) = \u2212\ng(t, x)g(t, M (t) \u2212 x).\n(2)\n\u2202t\nN (t)\nThe coagulation process described above neither creates nor destroys mass, which is expressed\nby the mass conservation equation\nZ M (t)\nxg(t, x)dx = \u03c3\n(3)\n0\n\nwhere \u03c3 is a constant. From (2) and (3) we will derive an equivalent condition for g(t, M (t)),\nsee Equation (7) below.\nFor x > M (t), g(t, x) is not changing since particles of size greater than M (t) can not form\na particle of size M (t) by coagulation. Hence \u2202g\n\u2202t (t, x) = 0 for x > M (t). We are normally\n2\n\n\finterested in processes where the value of M at the starting time is greater than the size of all\nparticles existing initially, and hence we also assume g(t, x) = 0 for x > M (t).\nAn important feature of Equation (2) is its invariance under reparametrization of time. As a\nconsequence M (t) is not determined by the initial data but can be prescribed to be an arbitrary\nincreasing function of time (see also [7, 10], where such an invariance has been crucial in the\nanalysis of a model for min-driven clustering). In the following we choose M (t) = t and also\nnormalize the mass by setting \u03c3 = 1. Consequently, in what follows we study the system of\nequations\nZ t\nZ t\nk0\n\u2202g\nxg(t, x)dx = 1\n(4)\ng(t, x)dx,\n(t, x) = \u2212\ng(t, x)g(t, t \u2212 x), N (t) =\n\u2202t\nN (t)\n0\n0\nwith t \u2265 1 and 0 \u2264 x \u2264 t.\nThe first aim of this article is to establish well-posedness of the initial value problem and\nto study the long time behavior of solutions to (4). To this end, we prove global existence and\nuniqueness of mild solutions in Section 2, Theorem 1 by rewriting (4) as a fixed point equation.\nIn contrast to coagulation equations with more regular kernels, for which well-posedness can\noften be proved in the space of probability measures [5], here we need to work with functions\nthat are continuous up to the points x = 1 and x = t. The reason that the fixed-point argument\nis not quite straightforward is that at any time there is an influx of particles of the largest size\nM (t) that leads to a nontrivial boundary condition.\nIn Section 3 we study the existence of self-similar solutions. Combining rigorous arguments\nwith numerical simulations, we identify k0 = 2 as a critical value: For k0 < 2 no self-similar\nsolutions exist but for k0 > 2 we find two self-similar solutions which have different shape and\nstability properties. Section 4 is devoted to numerical simulations of initial value problems. Our\nresults for k0 > 2 suggest that, after a suitable rescaling, each solution converges to the second\nself-similar solution. For k0 < 2, however, g converges to a steady state g\u221e (x), x \u2208 R+ , whose\nshape depends strongly on the initial data. We finally prove this assertion in Proposition 6 for\nk0 < 13 .\n\n2\n\nGlobal existence and uniqueness of solutions\n\nIn this section we derive a notion\nR t of mild solutions to (4) that relies on an appropritate reformulation of the mass constraint 0 xg(t, x)dx = 1. We then use Banachs's Contraction Mapping\nTheorem to prove the local existence and uniqueness of mild solutions, and finally employ some\na priori estimates to show that these mild solutions exist globally in time.\n\n2.1\n\nNotion of mild solutions and main result\n\nTo reformulate the mass constraint (4)3 we suppose that a piecewise smooth solution g(t, x) to\n(4)1 and (4)2 is given. We then have\n0 =\n\nd\ndt\n\nZ\n\nt\n\nxg(t, x)dx =\n\n0\n\nZ\n\nt\n\nx\n0\n\n\u2202g\n(t, x)dx + tg(t, t),\n\u2202t\n\n(5)\n\nand due to (4)1 we obtain\nk0\ntg(t, t) =\nN (t)\n\nZ\n\nt\n\nxg(t, x)g(t, t \u2212 x)dx.\n\n0\n\n3\n\n(6)\n\n\fMoreover, substituting x\nx \u2212 t we find\nZ t\nZ t\nZ t\nxg(t, t \u2212 x)g(t, x)dx,\ng(t, t \u2212 x)g(t, x)dx \u2212\nxg(t, x)x(t, t \u2212 x)dx = t\n0\n\n0\n\n0\n\nso (6) implies\nk0\ng(t, t) =\n2N (t)\n\nZ\n\nt\n\ng(t, x)g(t, t \u2212 x)dx.\n\n(7)\n\n0\n\nThis condition is equivalent to (4)3 provided that g(t, x) solves (4)1 , and for the ease of notation\nwe introduce the operator B : g 7\u2192 B[g] by\nB[g](t) :=\n\nk0\n2N (t)\n\nZ\n\nt\n\ng(t, x)g(t, t \u2212 x)dx,\n\n0\n\nwhere N depends on g via (4)2 .\nIn what follows we fix some T > 0 and introduce X as the space of all functions g that\nsatisfy\ni) g : \u03a9 = [1, T ] \u00d7 [0, T ] \u2192 R+\n0,\nii) g(1, x) = gini (x) for all x \u2208 [0, 1],\niii) g(t, x) = 0 if x > t,\niv) g is continuous in all points (t, x) with x 6= 1 and x 6= t,\nwhere the initial data gini are supposed to satisfy\nZ\n\ngini \u2208 C([0, 1]; R+ ),\n\n1\n\nxgini (x)dx = 1.\n\n0\n\nTo introduce the notion of mild solutions we now define the operator \u0393 : X \u2192 X by\n\u0012\n\u0013\nZ t\n\uf8f1\ng(s, s \u2212 x)\n\uf8f4\n\uf8f4\ng\n(x)\nexp\n\u2212k\nds\nfor x < 1,\n\uf8f4\nini\n0\n\uf8f4\nN (s)\n\uf8f4\n1\n\uf8f2\n\u0013\n\u0012\nZ t\ng(s, s \u2212 x)\n\u0393[g](t, x) =\n\uf8f4\nds\nfor 1 \u2264 x \u2264 t,\nB[g](x) exp \u2212k0\n\uf8f4\n\uf8f4\nN (s)\n\uf8f4\nx\n\uf8f4\n\uf8f3\n0\nfor t < x,\n\n(8)\n\nRt\nwith N (t) = 0 g(t, x)dx. Notice that \u0393 maps X into itself, and that for each g\u0303 \u2208 X the function\ng = \u0393[g\u0303] satisfies in almost all points (t, x) the linear differential equation\n\uf8f1\n\uf8f4\n\uf8f2 \u2212 k0 g(t, x)g\u0303(t, t \u2212 x)\nx < t,\n\u2202g\n\u00d1 (t)\n(t, x) =\n(9)\n\uf8f4\n\u2202t\n\uf8f30\nx>t\nwith \u00d1 (t) =\nas follows.\n\nRt\n0\n\ng\u0303(t, x)dx and initial data g(1, x) = gini (x) . Our main result can be summarized\n\nTheorem 1. For given initial data gini with (5) and any T > 0 there exists a unique mild\nsolution u \u2208 X to (4) that satisfies (8) with \u0393[g] = g.\n\n4\n\n\f2.2\n\nExistence proof for fixed points of \u0393\n\nTo employ the Contraction Mapping Principle we identify a subset S \u2282 X that is invariant\nunder \u0393 and a metric such that X is complete, S is closed, and \u0393 is a contraction. In what\nfollows S is given by\n\u001b\n\u001a\nZ t\n3\n1\nyg\u0303(t, y)dy \u2264\n,\nS = g\u0303 \u2208 X \u2200(t, x) \u2208 \u03a9 : 0 \u2264 g\u0303(t, x) \u2264 f (x), \u2264\n2\n2\n0\nwhere f : [0, T ] \u2192 R+ will be identified below. This set S is invariant under \u0393 provided that\neach g\u0303 \u2208 S satisfies\n0 \u2264 \u0393[g\u0303](t, x) \u2264 f (x)\nZ t\n1\n3\nx\u0393[g\u0303](t, x)dx \u2264\n\u2264\n2\n2\n0\n\n\u2200(t, x) \u2208 \u03a9,\n\n(10)\n\n\u2200t \u2208 [1, T ].\n\n(11)\n\nTowards (10) we estimate\n\u00d1 (t) =\n\nZ\n\nt\n0\n\n1\ng\u0303(t, x)dx \u2265\nT\n\nZ\n\nt\n\nxg\u0303(t, x)dx \u2265\n\n0\n\n1\n,\n2T\n\nand this implies 1/\u00d1 (t) \u2264 2T . Moreover,\ni) if x \u2264 1, then\n\u0012\n\n\u0393[g\u0303](t, x) = gini (x) exp \u2212k0\n\nZ\n\nt\n1\n\ng\u0303(s, s \u2212 x)\nds\n\u00d1 (s)\n\n\u0013\n\n\u2264 gini (x) \u2264 h0 := kgini k\u221e ,\n\nii) if t < x, then \u0393[g\u0303](t, x) = 0 \u2264 f (x),\niii) if 1 \u2264 x \u2264 t, then\n\u0012\nZ\n\u0393[g\u0303](t, x) = B[g\u0303](x) exp \u2212k0\n\nt\nx\n\ng\u0303(s, s \u2212 x)\nds\n\u00d1 (s)\n\nTherefore, f satisfies (10) provided that\nZ x\nf (x)\nf (y)f (x \u2212 y)dy \u2264\nfor all x \u2265 1,\nT k0\n0\n\n\u0013\n\n\u2264 B[g\u0303](x) \u2264 T k0\n\nand\n\nZ\n\nx\n\nf (y)f (x \u2212 y)dy.\n0\n\nf (x) \u2265 h0 for all x \u2264 1.\n\n(12)\n\n3\n\nLemma 2. There exists a constant D > 0 such that f (x) = h0 eDx satisfies (12).\nProof. There is nothing to show for x \u2264 1. For x \u2265 1, condition (12) can be rewritten as\nZ x\nZ x\n1\nD(y 3 +(x\u2212y)3 \u2212x3 )\ne\u22123Dxy(x\u2212y) dy.\ne\ndy =\n\u2265\nT k0\n0\n0\nNow suppose that A \u2208 [0, 1/2] is given. Then for all x \u2265 1 we have x \u2265 x \u2212\nthis implies\n\"Z A Z\nZ x #\nZ x\nx\u2212 A\nx\nx\n\u22123Dxy(x+y)\n+\ne\u22123Dxy(x+y) dy\n+\ne\ndy =\nA\nx\n\n0\n\n0\n\n\u2264\n\nx\u2212 A\nx\n\nA\nA\n2A\n2A\n+ xe\u22123Dx x (x+ x ) \u2264\n+ xe\u22123DAx .\nx\nx\n\n5\n\nA\nx\n\n\u2265\n\nA\nx\n\n\u2265 0, and\n\n\fFor the first inequality we have estimated the integrand in the first and third part of the integral\nby 1, and in the second part by its value on the boundaries, which can be done since the integrand\nis a convex function. The second inequality then follows as A, D, and x are non-negative.\n1\nWe now choose A with A < (4T k0 )\u22121 , and this implies 2A\nx < 2T k0 for all x \u2265 1. Next\nwe choose D large enough so that e\u22123DA < 2T1k0 and 3DA > 1. Since the function xe\u22123DAx\nis decreasing for x \u2265 1 we find xe\u22123DAx < 2T1k0 for all x \u2265 1. Hence our choice of A and D\nguarantees (12).\nWe now define\nMT := max{f (t) : t \u2208 [0, T ]}.\nNotice that g\u0303 \u2208 S implies g\u0303(t, x) \u2264 MT for all (t, x) \u2208 \u03a9.\nLemma 3. We can choose T > 0 such that (11) is satisfied for all c\u0303 \u2208 S.\nProof. For g\u0303 \u2208 S we have\nk0\n\u2202\n\u0393[g\u0303](t, x) = \u2212\n\u0393[g\u0303](t, x)g\u0303(t, t \u2212 x)\n\u2202t\n\u00d1(t)\nbecause \u0393[g\u0303] is piecewise Rcontinuously differentiable in t and satisfies (9). The continuity propt\nerties of \u0393[g\u0303] imply that 0 x\u0393[g\u0303](t, x)dx is differentiable in time, and we estimate\nt\n\nZ t\n\u2202\n\u0393[g\u0303](t, x)dx\nt\u0393[g\u0303](t, t) \u2212\n\u2202t\n0\n0\nZ t\nZ t\nk0\nk0\nxg\u0303(t, x)g\u0303(t, t \u2212 x)dx \u2212\nx\u0393[g\u0303](t, x)g\u0303(t, t \u2212 x)dx\n=\n\u00d1 (t) 0\n\u00d1 (t) 0\nZ t\nk0\n\u2264\nxg\u0303(t, t \u2212 x) |g\u0303 \u2212 \u0393[g\u0303]| (t, x)dx\n\u00d1 (t) 0\n\u2264 4k0 T 3 MT2 .\nR1\nR1\nFor t = 1 we have 0 x\u0393[g\u0303](1, x)dx = 0 xgini (x)dx = 1, so using the above bound we can choose\nRt\nT such that 0 \u0393[g\u0303](t, x)dx stays between 1/2 and 3/2 for all t \u2208 [1, T ].\nd\ndt\n\nZ\n\nx\u0393[g\u0303](t, x)dx\n\n=\n\nWe have now shown that S is invariant under \u0393, and that there exists a constant MT such\nthat c\u0303(t, x) \u2264 MT holds for all g\u0303 \u2208 S and all (t, x) \u2208 \u03a9.\nIn the next step we construct a norm for X such that \u0393 is a contraction on S. To this end,\nwe define\nZ T\nkg\u0303k1 := sup |g\u0303(t, x)|,\nkg\u0303k2 := sup\n|g\u0303(t, x)|dx,\n(t,x)\u2208\u03a9\n\nt\u2208[1,T ] 0\n\nand derive an estimate for k\u0393[g\u03031 ] \u2212 \u0393[g\u03032 ]k1,2 in terms of kg\u03031 \u2212 g\u03032 k1,2 . Afterwards we show that\n\u0393 is a contraction with respect to some linear combination of these norms.\nLemma 4. There exists a constant L > 0 such that for any g\u03031 , g\u03032 \u2208 S\nk\u0393[g\u03031 ] \u2212 \u0393[g\u03032 ]k1 \u2264 L(T \u2212 1)kg\u03031 \u2212 c\u03032 k1 + Lkg\u03031 \u2212 g\u03032 k2 ,\nk\u0393[g\u03031 ] \u2212 \u0393[g\u03032 ]k2 \u2264 L(T \u2212 1)kg\u03031 \u2212 c\u03032 k1 + L(T \u2212 1)kg\u03031 \u2212 g\u03032 k2 .\n\n6\n\n\fProof. Let (t, x) \u2208 \u03a9. Since |ea \u2212eb | \u2264 |a\u2212b| for all a, b > 0, we obtain the following inequalities.\nFor x < 1 we find that\nZ t\ng\u03031 (s, s \u2212 x) g\u03032 (s, s \u2212 x)\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)| \u2264 h0 k0\n\u2212\nds\n\u00d11 (s)\n\u00d12 (s)\n1\n)\nZ t(\n|\u00d11 (s) \u2212 \u00d12 (s)|\n2T |g\u03031 (s, s \u2212 x) \u2212 g\u03032 (s, s \u2212 x)| + MT\n\u2264 h0 k0\nds\n\u00d11 (s)\u00d12 (s)\n1\nZ t\n(13)\n2\n\u2264 (2h0 T k0 kg\u03031 \u2212 g\u03032 k1 + 4T MT h0 k0 kg\u03031 \u2212 g\u03032 k2 )\nds\n1\n\n\u2264 2h0 T k0 (T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + 4T 2 MT h0 k0 (T \u2212 1)kg\u03031 \u2212 g\u03032 k2 .\nRt\nds). Then,\nNow let x \u2265 1, and set E[g\u0303](t, x) := exp(\u2212k0 x g\u0303(s,s\u2212x)\n\u00d1 (s)\n\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)| = |B[g\u03031 ](x)E[g\u03031 ](t, x) \u2212 B[g\u03032 ](x)E[g\u03032 ](t, x)|\n\u2264 |B[g\u03031 ](x) \u2212 B[g\u03032 ](x)| * |E[g\u03031 ](t, x)|+\n|B[g\u03032 ](x)| * |E[g\u03031 ](t, x) \u2212 E[g\u03032 ](t, x)|\n\u2264 |B[g\u03031 ](x) \u2212 B[g\u03032 ](x)| + T 2 k0 MT2 |E[g\u03031 ](t, x) \u2212 E[g\u03032 ](t, x)|.\n\nWe treat the last two summands separately. Analogously to (13) we estimate\n|B[g\u03031 ](x) \u2212 B[g\u03032 ](x)| \u2264 (2T MT k0 + 2k0 MT2 T 3 )kg\u03031 \u2212 g\u03032 k2 .\nOn the other hand, we can estimate |E[g\u03031 ](t, x) \u2212 E[g\u03032 ](t, x)| by\nZ\n\nx\n\nt\b\n\n2T k0 |g\u03031 (s, s \u2212 x) \u2212 g\u03032 (s, s \u2212 x)| + 4MT T 2 k0 |\u00d11 (s) \u2212 \u00d12 (s)| ds\n\u2264 2T k0 (T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + 4T 3 k0 kg\u03031 \u2212 g\u03032 k2 .\n\nCombining these results we find a constant L\u2032 that depends polynomially on k0 , T, MT such that\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)| \u2264 L\u2032 (T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + L\u2032 (T \u2212 1)kg\u03031 \u2212 g\u03032 k2 , x < 1,\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)| \u2264 L\u2032 (T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + L\u2032 kg\u03031 \u2212 g\u03032 k2 ,\n\nx \u2265 1.\n\n(14)\n\nTo derive the bounds for the second norm we split the interval [0, T ] = [0, 1] \u222a [1, t] \u222a [t, T ], and\nusing (14) we find\nZ\n\nT\n\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)|dx \u2264 L\u2032 T (T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + 2L\u2032 (T \u2212 1)kg\u03031 \u2212 g\u03032 k2 .\n\n0\n\nWith L := max{T L\u2032 , 2L\u2032 } we then derive from (14), (15) that\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)| \u2264 L(T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + Lkg\u03031 \u2212 g\u03032 k2 ,\nZ\n\nT\n\n|\u0393[g\u03031 ](t, x) \u2212 \u0393[g\u03032 ](t, x)|dx \u2264 L(T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + L(T \u2212 1)kg\u03031 \u2212 g\u03032 k2 .\n\n0\n\nThe assertions now follow by taking the supremum in the above inequalities.\n\n7\n\n(15)\n\n\fNow let \u03b2 \u2265 2L, where L is as in the proof of Lemma 4, and define a norm on X by\nk*k := k*k1 + \u03b2k*k2 .\nFor any g\u03031 , g\u03032 \u2208 S we then have\nk\u0393[g\u03031 ] \u2212 \u0393[g\u03032 ]k \u2264 L(1 + \u03b2)(T \u2212 1)kg\u03031 \u2212 g\u03032 k1 + L(1 + \u03b2(T \u2212 1))kg\u03031 \u2212 g\u03032 k2 ,\nand it is possible to choose T such that \u03b2(T \u2212 1) < 1/2 and L(1 + \u03b2)(T \u2212 1) < 1/2. Hence\nL(1 + \u03b2(T \u2212 1)) < 3\u03b2/4, and this gives\n1\n3\n3\nk\u0393[g\u03031 ] \u2212 \u0393[g\u03032 ]k \u2264 kg\u03031 \u2212 g\u03032 k1 + \u03b2kg\u03031 \u2212 g\u03032 k2 \u2264 kg\u03031 \u2212 g\u03032 k.\n2\n4\n4\nX equipped with k*k is a Banach Space and S is a closed and bounded subset, so the Banach\nFixed Point Theorem guarantees that \u0393 has a unique fixed point g \u2208 S. By construction, this\nfixed point solves the differential equation (4)1 for t \u2264 T . Moreover, since g(t, t) = B[g](t), it\nalso satisfies condition (7), which is equivalent to (4)3 .\nIt remains to prove that there exists a solution for all 1 < T < \u221e. This can be done by standard\nmethods because (i) for each\nR t T > 1 there exists a constant D = D(T ) > 0 as in Lemma 2, and\n(ii) each solution satisfies 0 x\u0393[g\u0303](t, x)dx = 1 for all 1 \u2264 t \u2264 T .\n\n3\n\nSelf-similar solutions\n\nIn this section we describe self-similar solutions to (4). These satisfy\n\uf8f1\n\u0010 \u0011\n\uf8f2 \u03b1(t)G x\nx \u2264 t,\nt\ng(t, x) =\n\uf8f30\nx > t,\n\nwhere G : [0, 1] \u2192 R+\n0 is a continuously differentiable function, and the mass constraint (4)3\nrequires\nZ 1\nZ t\nZ t\n\u0010x\u0011\n2\ndx = t \u03b1(t)\nyG(y)dy.\n1=\nxg(t, x)dx =\nx\u03b1(t)G\nt\n0\n0\n0\n\nThis means t2 \u03b1(t) is a positive constant. By rescaling \u03b1 and G we can ensure that this constant\n\u22122\nRis1 1, so each mass preserving self-similar solution takes the form g(t, x) = t G(x/t) with\n0 yG(y)dy = 1. Using this relation in (4), and substituting y = x/t, we get\nZ 1\nk0\n\u2032\n2G(y) + yG (y) = G(y)G(1 \u2212 y), N =\nG(y)dy.\n(16)\nN\n0\n\nWe first consider a simplified problem\n\n2G(y) + yG\u2032 (y) = DG(y)G(1 \u2212 y),\n\n(17)\n\nwhere D > 0 is an arbitrary constant and we do not impose the mass constraint on G. At first,\nwe notice that each solution G to (17) provides a solution G\u0303 to (16) via\nZ 1\nG(y)\nG(x)dx,\nG\u0303(y) = R 1\nk0 = D\n.\n(18)\n0\n0 xG(x)dx\nWe also observe that (17) is invariant under the scaling G\n\u03bbG, D\n\u03bb\u22121 D. Consequently, in\norder to characterize the solution set of (16), we have to investigate (17) for only one value of\nD, and then consider how the corresponding solutions transform under (18).\n8\n\n\fLemma 5. For any given D > 0 and G(1/2) > 0 there exists a unique positive solution of (17)\non (0, 1).\nProof. We multiply (17) by y and substitute F (y) = G(y)y 2 to obtain\nF \u2032 (y) =\n\nF (y)F (1 \u2212 y)\n.\ny(1 \u2212 y)2\n\n(19)\n\nNext, we decompose F into its odd and even parts with respect to 1/2 by setting\nF (y) = Fe (y) + Fo (y),\nF (1 \u2212 y) = Fe (y) \u2212 Fo (y),\nso (19) transforms into\n\u0012\n\u0013\nD(Fe (y)2 \u2212 Fo (y)2 )\n1\n=\ny\u2212\n,\ny 2 (1 \u2212 y)2\n2\nD(Fe (y)2 \u2212 Fo (y)2 )\nFo\u2032 (y) =\n.\n2y 2 (1 \u2212 y)2\nFe\u2032 (y)\n\n(20)\n\nSince (20) is locally Lipschitz for y \u2208 (0, 1), the local existence and uniqueness of solutions to the\ninitial value problems is granted. In particular, for given values Fo (1/2) = 0 and Fe (1/2) > 0\nwe find the smallest a \u2208 [0, 1/2) such that there exists a unique solution to (20) on (a, 1 \u2212 a).\nThe function F (y) = Fe (y) + Fo (y) then solves (19) on (a, 1 \u2212 a), and satisfies\n!\nZ y\nDF (1 \u2212 z)\ndz .\nF (y) = F (1/2) exp\n2\n1/2 z(1 \u2212 z)\nIn particular, F is positive and by (19) it is also increasing on (a, 1 \u2212 a). If a = 0 then we are\ndone. Otherwise we know that DF (1 \u2212 y)y \u22121 (1 \u2212 y)\u22122 is bounded for y \u2208 [1/2, 1 \u2212 a), which\nmeans that F does not blow-up at 1 \u2212 a. Thus, Fe , Fo are also bounded on (a, 1 \u2212 a) and we\ncan extend the solution to [a, 1 \u2212 a]. Due to the local existence result, we can then extend the\nsolution to an interval (b, 1 \u2212 b) with b \u2208 [0, a), which contradicts the minimality of a. Hence we\nhave a = 0, and the proof is complete.\n\n12.\n\nmoment of solution\n\nsupercritical solutions\n\nsubcritical solutions\n\n8.\n4.\n\n7.\n5.\n2.\n2.\n0.\n\n.5\n\n1. 0.\n\n.5\n\n2.\n1. 0.\n\n2.\n\n8.\n\nFigure 1: Solutions G(y) to (17) with D = 1 forR y \u2208 [0, 1] for different values of G(1/2) < 2\n1\n(left) and G(1/2) > 2 (center); moment N (G) = 0 G(y)dy in dependence on G(1/2) (right).\n\nWe next discuss some numerical ODE simulations that illustrate how the solutions of (17)\nwith D = 1 depend on the value of G(1/2). For G(1/2) = 2 we get the trivial solution G \u2261 2.\nFrom now on, we refer to solutions with G(1/2) > 2 as supercritical and to those with G(1/2) < 2\nas subcritical. These two types behave rather differently, see Figure 1, which shows the solutions\n9\n\n\ffor G(1/2) \u2208 {0.2, 0.6, 1.0, 1.4, 1.8} and G(1/2) \u2208 {2.0, 2.4, 2.8, 3.2, 3.6, 4.0}. Our numerical\nresults indicate that each supercritical solution has precisely one local maximum between 1/2\nand 1 but no local minimum. On the other hand, a subcritical solution has two local maxima\nclose to 0 and 1, and a local minimum between 1/2 and 1, compare Figure 2, where 'variation\nnear 1' refers to G(y) \u2212 G(1).\nsubcritical solutions near 0\n\nsubcritical solutions near 1\n\nsubcritical variations near 1\n\n5.\n\n+.004\n\n4.\n\n2.\n2.\n\n-.004\n0.00\n\n.001 0.95\n\n1.00\n\n0.999\n\n1.00\n\nFigure 2: Subcritical solutions from Figure 1 for y \u2248 0 and y \u2248 1.\nR1\nFigure 1 also shows how 0 G(y)dy depends on G(1/2). Based on this, we conjecture that\nfor every k0 > 2 there exist two solutions to (16), one having a subcritical and the other having\na supercritical shape. For k0 = 2 there is a trivial self-similar solution. For k0 < 2 there seem to\nbe no self-similar solution. To support this conjecture, we now prove that there is no self-similar\nsolution for k0 \u2264 1: Integrating (16) we find lim\nR 1z\u21921 G(z) = N , so each solution to (16) satisfies\nG(y) \u223c y \u22122+k0 as y \u2192 0, which contradicts 0 G(y)dy < \u221e. For 1 < k0 < 2, however, this\nargument does not apply but our numerical results indicate there is still no singular solution.\n\n4\n\nLong-time behavior\n\nTo investigate the long time behaviour of solutions to (4) by numerical simulations we derive a\ndiscrete \"box model\" which follows naturally from the physical interpretation. We assume the\nnumber of initial boxes Mb is sufficiently large (we choose Mb = 200 for all simulations) and\nconsider the discrete times t = \u03b5j with j \u2208 N and \u03b5 = 1/Mb . Moreover, we denote by G(j, i)\nthe number of particles with size x \u2208 (\u03b5i \u2212 \u03b5, \u03b5i) at time t = 1 + \u03b5j, that means\n\u22121\n\nG(j, i) = \u03b5\n\nZ\n\n\u03b5i\n\ng(1 + \u03b5j, x)dx\n\n\u03b5(i\u22121)\n\nfor all integers j \u2265 0 and i = 1, . . . , Mb + j. The disrete analogue to the evolution equation (4)\nis then given by\n\uf8f1\nk0\nG(j, i)G(j, Mb + j + 1 \u2212 i)\n0 < i \u2264 j + Mb ,\nG(j + 1, i) \u2212 G(j, i) \uf8f2 \u2212\nN (j)\n=\n\uf8f3\n\u03b5\n0\ni > j + Mb + 1,\nwhere N (j) = \u03b5\nof mass, i.e.,\n\nPj+Mb\ni=1\n\nG(j, i) and the value of G(j, j+Mb +1) is determined by the conservation\n\nj+M\n\u03b5 Xb k0\nG(j, j + Mb + 1) =\nG(j, i)G(j, Mb + j + 1 \u2212 i).\n2\nN (j)\ni=1\n\nWe now present our numerical results for three different values of k0 and three different sets\n10\n\n\fof initial data. More precisely, we consider k0 = 1, 2, 3 and assume that the initial data have\nGaussian distributions with dispersion 0.3 and center at either 0.25, 0.5, or 0.75.\nFor k0 > 2 we expect convergence to one of the self-similar solutions. Numerical simulations\nsuggest that the solution converges as t \u2192 \u221e to the supercritical self-similar solution that\ncorresponds to k0 . The same happens if the initial data is very close to the subcritical selfsimilar solution, and thus we can conclude that subcritical solutions are unstable. We failed to\nfind a rigorous proof for this assertion, but the numerical evidence is strong. In Figure 3, we\nplot the scaled distributions after 0, 200, 1000 and 25000 steps (0, 1000, 25000 and 150000 if\nthe center is at 0.25) for the three sets of initial data described above. The corresponding times\nare given by 0, 1, 5, and 125 (0, 5, 125, and 750). Along with these smooth curves we dotted\nthe graph of the self-similar solution for k0 = 3. As we see, the convergence is slowest when the\ncenter of the initial data is at 0.25.\nCenter=0.25, k0=3\n\nCenter=0.5, k0=3\n\n8.\n\nCenter=0.75, k0=3\n\n4.\n\n4.\n\n2.\n\n2.\n\n6.\n\n4.\n\n2.\n\n0.\n\n.5\n\n1.\n\n0.\n\n.5\n\n1.\n\n0.\n\n.5\n\n1.\n\nFigure 3: Convergence to self-similar form for k0 = 3\nFor k0 < 2 we observe a completely different behaviour. We do not see any convergence\nin the self-similar scaling. On the contrary, the solutions apparently converge pointwise in the\noriginal variables to a limit that depends on the initial data. We will prove the corresponding\nstatement rigorously in Proposition 6 for k0 < 1/3. Figure 4 shows the unscaled distributions\nfor k0 = 1, the initial data is the same as before. The five smooth curves represents numerical\ndistributions after 0, 200, 1000, 5000 and 25000 steps.\nCenter=0.25, k0=1\n\nCenter=0.5, k0=1\n\nCenter=0.75, k0=1\n\n2.\n\n2.\n\n2.\n\n1.\n\n1.\n\n1.\n\n0.\n\n1.\n\n2.\n\n3.\n\n0.\n\n1.\n\n2.\n\n3.\n\n0.\n\n1.\n\n2.\n\n3.\n\n4.\n\n5.\n\nFigure 4: Convergence in the original variables for k0 = 1\nFor k0 = 2 we expect convergence to the trivial self-similar solution but the numerical\nsimulations do not support this assertion. We can conclude that either the long time behaviour\nis more complicated or the convergence is extremely slow. Figure 5 contains the distributions\nafter 0, 1000, 5000, 25000 and 150000 steps and the dotted plot of the self-similar solution.\nIn the first picture we observe a behavior similar to that for k0 < 2, that means the mass is\ncumulated near the origin. It will possibly eventually disappear but this was not the case after\nany number of steps that we were able to simulate. This happens also for k0 > 2 if the initial\ndata is more cummulated. For example, if we choose dispersion equal to 0.2 then 150000 steps\nis not enough to see the convergence for k0 = 3 and center at 0.25. This observation is not\nsurprising because if the initial data is supported on [0, 1/2), then the evolution cannot start at\n11\n\n\fCenter=0.25, k0=2\n\nCenter=0.5, k0=2\n\n8.\n\nCenter=0.75, k0=2\n\n4.\n\n4.\n\n2.\n\n2.\n\n6.\n\n4.\n\n2.\n\n0.\n\n.5\n\n1.\n\n0.\n\n.5\n\n1.\n\n0.\n\n.5\n\n1.\n\nFigure 5: Evolution in self-similar variables for d = 2\nall.\nWe conclude this section with a rigorous proof of a theorem supporting the conjecture that\nfor k0 < 2 there exists a limit function\nlim g(t, x) =: g\u221e (x) > 0.\n\n(21)\n\nt\u2192\u221e\n\nNotice that (21) implies that the rescaled function t2 g(t, yt) : [0, 1] \u2192 R converges, in the sense\nof probability measures, to a Dirac measure with positive mass.\nProposition 6.\ni) If there exists c0 > 0 such that N (t) \u2265 c0 for all t \u2265 1, then the relation\n(21) is satisfied.\nii) If k0 < 1/3 then N (t) > N (1)/2 for all t \u2265 1.\nProof. i) Suppose that N (t) \u2265 c0 . From (4) and (8) with g\u0303 = g we infer that\n!\nZ t\ng(s, s \u2212 x)\nds .\ng(t, x) = g(max(1, x), x) exp \u2212k0\nN (s)\nmax(1,x)\nBy assumption, we also have\nZ t\nmax(1,x)\n\n1\ng(s, s \u2212 x)\nds \u2264\nN (s)\nc0\n\nt\n\nZ\n\ng(s, s \u2212 x)ds < \u221e,\n\nmax(1,x)\n\nso g(t, x) is bounded from below. Since it is also decreasing in t for all x, there exists g\u221e (x) as\nin (21).\nRt\nii) Due to (4), we have \u22122N (t)N \u2032 (t) = k0 0 g(t, x)g(t, t \u2212 x)dx and by integration we obtain\nZ tZ s\nN (1)2 \u2212 N (t)2 = k0\ng(s, x)g(s, s \u2212 x)dxds\n1\n0\nZ tZ t\n= k0\ng(s, x)g(s, s \u2212 x)dsdx\n0\n\n\u2264 k0\n\u2264 k0\n\nZ\n\nZ\n\nmax(1,x)\n\nt\n\ng(max(1, x), x)\n0\nt\n\ng(max(1, x), x)\n0\n\n\u2264 k0 (2N (1) \u2212 N (t))2 ,\n\nZ\n\nZ\n\nt\n\ng(s, s \u2212 x)dsdx\nmax(1,x)\nt\n\ng(max(1, s), s)dsdx\n0\n\nwhere the last inequality holds since\nZ t\nZ 1\nZ t\ng(s, s)ds = N (1) + (N (1) \u2212 N (t)).\ng(1, s)ds +\ng(max(1, s), s)ds =\n0\n\n(22)\n\n1\n\n0\n\nNow suppose that there exists t > 1 such that N (t) = N (1)/2. By (22) we get k0 \u2265 1/3 and\nusing the continuity of N , we conclude that k0 < 1/3 implies N (t) > N (1)/2 for all t.\n12\n\n\fAcknowledgment This work was supported by the EPSRC Science and Innovation award\nto the Oxford Centre for Nonlinear PDE (EP/E035027/1). Ondrej Bud\u00e1\u010d also gratefully acknowledges support through the SPP Foundation and by the Slovak Research and Development\nAgency under the contract No. APVV-0414-07.\n\nReferences\n[1] A. Boudaoud, J. Bico and B. Roman, Elastocapillary coalescence: Aggregation and fragmentation with maximal size, Phys. Rev. E 76, 060102 (2007).\n[2] R. L. Drake, A general mathematical survey of the coagulation equation. In G.M. Hidy\nand J.R. Brock eds., Topics in current aerosol research (Part 2); International reviews in\nAerosol Physics and Chemistry, Pergamon (1972), 201-376\n[3] M. Escobedo, S. Mischler and M. Rodriguez Ricard, On self-similarity and stationary problems for fragmentation and coagulation models, Ann. Inst. H. Poincar\u00e9 Anal. Non Lin\u00e9aire\n22 (2005), 99-125.\n[4] N. Fournier and P. Lauren\u00e7ot, Existence of self-similar solutions to Smoluchowski's coagulation equation, Comm. Math. Phys. 256, (2005) 589-609\n[5] N. Fournier and P. Lauren\u00e7ot, Well-posedness of Smoluchowski's coagulation equation for\na class of homogeneous kernels, J. Funct. Anal. 233, (2006) 351-379\n[6] S. K. Friedlander, Smoke, dust and haze: Fundamentals of aerosol dynamics. Wiley, New\nYork, 1977.\n[7] T. Gallay and A. Mielke, Convergence results for a coarsening model using global linearization, J. Nonlinear Science 13 (2003), 311-346\n[8] F. Leyvraz, Scaling theory and exactly solvable models in the kinetics of irreversible aggregation, Phys. Reports 383 2/3 (2003), 95-212\n[9] G. Menon and R. L. Pego, Approach to self-similarity in Smoluchowski's coagulation equations, Comm. Pure Appl. Math. 57 9 (2004), 1197-1232\n[10] G. Menon, B. Niethammer and R. L. Pego, Dynamics and self-similarity in min-driven\nclustering, Trans. AMS 362, 12 (2010), 6551-6590\n[11] M. Smoluchowski, Drei Vortr\u00e4ge \u00fcber Diffusion, Brownsche Molekularbewegung und Koagulation von Kolloidteilchen, Phys. Zeitschr. 17 (1916), 557-599\n[12] R. M. Ziff, Kinetics of polymerization, 23, J. Statist. Phys. 23 (1980), 241-263\n\n13\n\n\f"}