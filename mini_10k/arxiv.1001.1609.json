{"id": "http://arxiv.org/abs/1001.1609v1", "guidislink": true, "updated": "2010-01-11T09:17:42Z", "updated_parsed": [2010, 1, 11, 9, 17, 42, 0, 11, 0], "published": "2010-01-11T09:17:42Z", "published_parsed": [2010, 1, 11, 9, 17, 42, 0, 11, 0], "title": "Optimal rates of convergence for estimating the null density and\n  proportion of nonnull effects in large-scale multiple testing", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1001.3968%2C1001.4166%2C1001.1167%2C1001.5399%2C1001.3510%2C1001.1597%2C1001.0408%2C1001.2768%2C1001.2397%2C1001.0300%2C1001.4601%2C1001.5470%2C1001.1498%2C1001.3427%2C1001.3477%2C1001.1178%2C1001.3838%2C1001.4124%2C1001.4574%2C1001.4281%2C1001.0392%2C1001.0178%2C1001.3704%2C1001.0667%2C1001.2628%2C1001.3519%2C1001.5300%2C1001.0614%2C1001.2126%2C1001.3894%2C1001.4159%2C1001.0192%2C1001.0219%2C1001.0632%2C1001.0023%2C1001.4074%2C1001.0107%2C1001.4810%2C1001.2643%2C1001.0460%2C1001.4187%2C1001.4169%2C1001.1620%2C1001.3713%2C1001.4437%2C1001.5213%2C1001.1254%2C1001.1762%2C1001.4113%2C1001.2351%2C1001.3234%2C1001.4003%2C1001.3358%2C1001.4613%2C1001.4887%2C1001.3479%2C1001.4392%2C1001.0843%2C1001.2266%2C1001.4323%2C1001.4595%2C1001.3476%2C1001.2818%2C1001.2634%2C1001.3306%2C1001.4834%2C1001.2338%2C1001.1609%2C1001.2883%2C1001.4444%2C1001.0813%2C1001.5286%2C1001.4739%2C1001.2974%2C1001.2390%2C1001.4289%2C1001.5215%2C1001.2306%2C1001.2650%2C1001.2719%2C1001.3116%2C1001.0822%2C1001.1182%2C1001.4545%2C1001.2473%2C1001.5417%2C1001.2242%2C1001.5122%2C1001.3058%2C1001.3948%2C1001.1898%2C1001.1508%2C1001.2682%2C1001.1379%2C1001.4490%2C1001.2335%2C1001.2341%2C1001.2191%2C1001.2688%2C1001.1057%2C1001.4900&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Optimal rates of convergence for estimating the null density and\n  proportion of nonnull effects in large-scale multiple testing"}, "summary": "An important estimation problem that is closely related to large-scale\nmultiple testing is that of estimating the null density and the proportion of\nnonnull effects. A few estimators have been introduced in the literature;\nhowever, several important problems, including the evaluation of the minimax\nrate of convergence and the construction of rate-optimal estimators, remain\nopen. In this paper, we consider optimal estimation of the null density and the\nproportion of nonnull effects. Both minimax lower and upper bounds are derived.\nThe lower bound is established by a two-point testing argument, where at the\ncore is the novel construction of two least favorable marginal densities $f_1$\nand $f_2$. The density $f_1$ is heavy tailed both in the spatial and frequency\ndomains and $f_2$ is a perturbation of $f_1$ such that the characteristic\nfunctions associated with $f_1$ and $f_2$ match each other in low frequencies.\nThe minimax upper bound is obtained by constructing estimators which rely on\nthe empirical characteristic function and Fourier analysis. The estimator is\nshown to be minimax rate optimal. Compared to existing methods in the\nliterature, the proposed procedure not only provides more precise estimates of\nthe null density and the proportion of the nonnull effects, but also yields\nmore accurate results when used inside some multiple testing procedures which\naim at controlling the False Discovery Rate (FDR). The procedure is easy to\nimplement and numerical results are given.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1001.3968%2C1001.4166%2C1001.1167%2C1001.5399%2C1001.3510%2C1001.1597%2C1001.0408%2C1001.2768%2C1001.2397%2C1001.0300%2C1001.4601%2C1001.5470%2C1001.1498%2C1001.3427%2C1001.3477%2C1001.1178%2C1001.3838%2C1001.4124%2C1001.4574%2C1001.4281%2C1001.0392%2C1001.0178%2C1001.3704%2C1001.0667%2C1001.2628%2C1001.3519%2C1001.5300%2C1001.0614%2C1001.2126%2C1001.3894%2C1001.4159%2C1001.0192%2C1001.0219%2C1001.0632%2C1001.0023%2C1001.4074%2C1001.0107%2C1001.4810%2C1001.2643%2C1001.0460%2C1001.4187%2C1001.4169%2C1001.1620%2C1001.3713%2C1001.4437%2C1001.5213%2C1001.1254%2C1001.1762%2C1001.4113%2C1001.2351%2C1001.3234%2C1001.4003%2C1001.3358%2C1001.4613%2C1001.4887%2C1001.3479%2C1001.4392%2C1001.0843%2C1001.2266%2C1001.4323%2C1001.4595%2C1001.3476%2C1001.2818%2C1001.2634%2C1001.3306%2C1001.4834%2C1001.2338%2C1001.1609%2C1001.2883%2C1001.4444%2C1001.0813%2C1001.5286%2C1001.4739%2C1001.2974%2C1001.2390%2C1001.4289%2C1001.5215%2C1001.2306%2C1001.2650%2C1001.2719%2C1001.3116%2C1001.0822%2C1001.1182%2C1001.4545%2C1001.2473%2C1001.5417%2C1001.2242%2C1001.5122%2C1001.3058%2C1001.3948%2C1001.1898%2C1001.1508%2C1001.2682%2C1001.1379%2C1001.4490%2C1001.2335%2C1001.2341%2C1001.2191%2C1001.2688%2C1001.1057%2C1001.4900&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "An important estimation problem that is closely related to large-scale\nmultiple testing is that of estimating the null density and the proportion of\nnonnull effects. A few estimators have been introduced in the literature;\nhowever, several important problems, including the evaluation of the minimax\nrate of convergence and the construction of rate-optimal estimators, remain\nopen. In this paper, we consider optimal estimation of the null density and the\nproportion of nonnull effects. Both minimax lower and upper bounds are derived.\nThe lower bound is established by a two-point testing argument, where at the\ncore is the novel construction of two least favorable marginal densities $f_1$\nand $f_2$. The density $f_1$ is heavy tailed both in the spatial and frequency\ndomains and $f_2$ is a perturbation of $f_1$ such that the characteristic\nfunctions associated with $f_1$ and $f_2$ match each other in low frequencies.\nThe minimax upper bound is obtained by constructing estimators which rely on\nthe empirical characteristic function and Fourier analysis. The estimator is\nshown to be minimax rate optimal. Compared to existing methods in the\nliterature, the proposed procedure not only provides more precise estimates of\nthe null density and the proportion of the nonnull effects, but also yields\nmore accurate results when used inside some multiple testing procedures which\naim at controlling the False Discovery Rate (FDR). The procedure is easy to\nimplement and numerical results are given."}, "authors": ["T. Tony Cai", "Jiashun Jin"], "author_detail": {"name": "Jiashun Jin"}, "author": "Jiashun Jin", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/09-AOS696", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1001.1609v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1001.1609v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in at http://dx.doi.org/10.1214/09-AOS696 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "62G05, 62G10 (Primary), 62G20 (Secondary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1001.1609v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1001.1609v1", "journal_reference": "Annals of Statistics 2010, Vol. 38, No. 1, 100-145", "doi": "10.1214/09-AOS696", "fulltext": "arXiv:1001.1609v1 [math.ST] 11 Jan 2010\n\nThe Annals of Statistics\n2010, Vol. 38, No. 1, 100\u2013145\nDOI: 10.1214/09-AOS696\nc Institute of Mathematical Statistics, 2010\n\nOPTIMAL RATES OF CONVERGENCE FOR ESTIMATING THE\nNULL DENSITY AND PROPORTION OF NONNULL EFFECTS IN\nLARGE-SCALE MULTIPLE TESTING\nBy T. Tony Cai1 and Jiashun Jin2\nUniversity of Pennsylvania and Carnegie Mellon University\nAn important estimation problem that is closely related to largescale multiple testing is that of estimating the null density and the\nproportion of nonnull effects. A few estimators have been introduced\nin the literature; however, several important problems, including the\nevaluation of the minimax rate of convergence and the construction\nof rate-optimal estimators, remain open.\nIn this paper, we consider optimal estimation of the null density\nand the proportion of nonnull effects. Both minimax lower and upper\nbounds are derived. The lower bound is established by a two-point\ntesting argument, where at the core is the novel construction of two\nleast favorable marginal densities f1 and f2 . The density f1 is heavy\ntailed both in the spatial and frequency domains and f2 is a perturbation of f1 such that the characteristic functions associated with\nf1 and f2 match each other in low frequencies. The minimax upper\nbound is obtained by constructing estimators which rely on the empirical characteristic function and Fourier analysis. The estimator is\nshown to be minimax rate optimal.\nCompared to existing methods in the literature, the proposed procedure not only provides more precise estimates of the null density\nand the proportion of the nonnull effects, but also yields more accurate results when used inside some multiple testing procedures which\naim at controlling the False Discovery Rate (FDR). The procedure is\neasy to implement and numerical results are given.\n\n1. Introduction. Large-scale multiple testing is an important area in\nmodern statistics with a wide range of applications including DNA microarReceived November 2008; revised February 2009.\nSupported in part by NSF Grant DMS-06-04954.\n2\nSupported in part by NSF Grants DMS-05-05423 and DMS-09-08613.\nAMS 2000 subject classifications. Primary 62G05, 62G10; secondary 62G20.\nKey words and phrases. Characteristic function, empirical characteristic function,\nFourier analysis, minimax lower bound, multiple testing, null distribution, proportion of\nnonnull effects, rate of convergence, two-point argument.\n1\n\nThis is an electronic reprint of the original article published by the\nInstitute of Mathematical Statistics in The Annals of Statistics,\n2010, Vol. 38, No. 1, 100\u2013145. This reprint differs from the original in pagination\nand typographic detail.\n1\n\n\f2\n\nT. T. CAI AND J. JIN\n\nray studies, functional Magnetic Resonance Imaging analyses (fMRI) and\nastronomical surveys. Since the seminal paper by Benjamini and Hochberg\n(1995) on false discovery rate (FDR) control, research in this area has been\nvery active. See, for example, Efron et al. (2001), Storey (2002), Genovese\nand Wasserman (2004), van der Laan, Dudoit and Pollard (2004) and Sun\nand Cai (2007). Properties of FDR-controlling procedures have been studied, for example, in Finner, Dickhaus and Roters (2009) and Neuvial (2008).\nSee also Abramovich et al. (2006) and Donoho and Jin (2006) for estimation\nusing a multiple testing approach.\nIn large-scale multiple testing, one tests simultaneously a large number of\nnull hypotheses\n(1.1)\n\nH1 , H2 , . . . , Hn .\n\nFrequently, associated with each hypothesis Hj is a test statistic Xj , which\ncan be a z-score, a p-value, a summary statistic, etc., depending on the\nsituation. The goal is to use the test statistics to determine which hypotheses\nare true and which are false. We call Xj a null effect if Hj is true and a\nnonnull effect otherwise.\nA commonly used and effective framework for large-scale multiple testing\nis the so-called two-group random mixture model which assumes that each\nhypothesis has a given probability of being true and the test statistics are\ngenerated from a mixture of two densities; see, for example, Efron et al.\n(2001), Newton et al. (2001), Storey (2002) and Sun and Cai (2007). In\ndetail, let \u03b8 = (\u03b81 , . . . , \u03b8n ) be independent Bernoulli(\u03b5) variables, where \u03b5 \u2208\n(0, 1) and \u03b8j = 0 indicates that the null hypothesis Hj is true and \u03b8j = 1\notherwise. When \u03b8j = 0, Xj is generated from a density f null (x). When \u03b8j =\n1, Xj is generated from another (alternative) density f alt (x). Marginally, Xj\nobeys the following two-group random mixture model:\n(1.2)\n\ni.i.d.\n\nXj \u223c (1 \u2212 \u03b5)f null + \u03b5f alt \u2261 f,\n\nj = 1, . . . , n,\n\nwhere f null , f alt and \u03b5 are called the null density, nonnull density and proportion of nonnull effects, respectively.\nAn important estimation problem that is closely related to multiple testing is that of estimating f null , \u03b5 and f . In fact, many commonly used multiple testing procedures require good estimators of some or all of these three\nquantities. See Benjamini and Hochberg (2000), Efron et al. (2001), Storey\n(2002), Genovese and Wasserman (2004), Benjamini, Krieger and Yekutieli\n(2006), Blanchard and Roquain (2007) and Sun and Cai (2007). For example, in an empirical Bayes framework, Efron et al. (2001) introduced the\nlocal false discovery rate (Lfdr) which is defined as\n(1.3)\n\nLfdr(x) =\n\n(1 \u2212 \u03b5)f null (x)\n.\nf (x)\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n3\n\nLfdr has a useful Bayesian interpretation as the a posteriori probability of a\nhypothesis being in the null group given the value of the test statistic. See\nalso M\u00fcller et al. (2004). Sun and Cai (2007) considered the multiple testing\nproblem from a compound decision theoretical point of view and showed\nthat the Lfdr is a fundamental quantity which can be used directly for the\noptimal FDR control. Calculating the Lfdr clearly requires the knowledge\nof \u03b5, f null and f . In real applications, the proportion \u03b5 and the marginal\ndensity f are unknown and thus need to be estimated from the data. The\nnull density f null is more subtle. In many studies the null distribution is\nassumed to be known and can be used directly for multiple testing. However, somewhat surprisingly, Efron (2004) demonstrated convincingly that\nin some applications such as the analysis of microarray data on breast cancer\nand human immunodeficiency virus (HIV) the true null distribution of the\ntest statistic can be quite different from the theoretical null, and possible\ncauses for such a phenomenon include but are not limited to unobserved\ncovariates, correlations across different arrays and different genes. It is further illustrated in Jin and Cai (2007) that two seemingly close choices of the\nnull distribution can lead to substantially different testing results. Hence, a\ncareful study on how to estimate the null distribution is also indispensable.\nIn the present paper we study the problem of optimal estimation of the\nnull density f null and the proportion \u03b5. We should mention that estimating the marginal density f is a standard density estimation problem and is\nwell understood. See, for example, Silverman (1986). Several methods for\nestimating the null density f null and the proportion \u03b5 have been introduced\nin the literature. See Efron (2004, 2008) and Jin and Cai (2007) for estimating f null and \u03b5, and see Genovese and Wasserman (2004), Meinshausen\nand Rice (2006), Cai, Jin and Low (2007), Jin (2008) and Celisse and Robin\n(2008) for estimating \u03b5 [also see Storey (2002), Efron et al. (2001), Swanepoel\n(1999)]. Unfortunately, despite the encouraging progress in these works, the\noptimality of the estimators is largely unknown [it is, however, not hard to\nshow that some of these estimators are generally inconsistent in the nonsparse case; see, e.g., Jin and Cai (2007)]. It is hence of significant interest\nto understand how well f null and \u03b5 can be estimated and to what extend\nimproving the estimation accuracy of f null and \u03b5 can help to enhance the\nperformance of leading contemporary multiple testing procedures [including\nbut not limited to those by Benjamini and Hochberg (1995), Efron et al.\n(2001) and Sun and Cai (2007)]. Multiple testing procedures that adapt to\n\u03b5, without estimating it directly, have also been proposed recently in Blanchard and Roquain (2007) and Finner, Dickhaus and Roters (2009).\nIn this paper, we focus on the Gaussian mixture model as in Efron (2004).\nWe model f null as Gaussian, but both the mean and the variance are un-\n\n\f4\n\nT. T. CAI AND J. JIN\n\nknown and need to be estimated:\n\u0012\n\u0013\nx \u2212 u0\n1\nnull\n(1.4)\n,\nf (x) = \u03c6\n\u03c30\n\u03c30\n\n\u03c6: density of N (0, 1).\n\nWe shall use the terminology in Efron (2004) by calling \u03c302 the null variance\nparameter, u0 the null mean parameter, and together the null parameters.\nThe Gaussian model for f null is somewhat idealized, but it is a reasonable\nchoice. On one hand, assuming f null as Gaussian helps to re-normalize the\nnull distribution and is therefore a good starting point in large-scale multiple\ntesting. On the other hand, allowing f null to be in a much broader class will\nlead to identifiability problems. The nonnull distribution f alt is modeled by\na Gaussian location-scale mixture,\n\u0012\n\u0013\nZ Z\n1\nx\u2212u\nf alt (x) =\n\u03c6\n(1.5)\ndH(u, \u03c3),\n\u03c3\n\u03c3\n\nwhere H is called the mixing distribution. Additional to the mathematical\ntractability that it offers, model (1.5) also offers great flexibility. For example, it is well known that under the L1 -metric, the set of Gaussian mixing\ndensities of the form in (1.5) is dense in the set of all density functions. Also,\nmodel (1.5) is able to capture the essence of many application examples. See\nJin (2008) for an example on the analysis of gene microarray data on breast\ncancer and an example on the study of the abundance of the Kuiper Belt\nObjects.\nWe consider the asymptotic minimax estimation problem and address\nseveral inter-connected questions: what are the optimal rates of convergence?\nwhat are the best estimation tools, and where do the difficulties of the\nestimation problem come from? Our analysis reveals that the optimal rates\nof convergence for estimating the proportion and the null parameters depend\non the smoothness of H(u, \u03c3) (more specifically, the conditional density of u\ngiven \u03c3 associated with H). For an intuitive explanation, we note that f null\nand f alt are the convolution of the standard Gaussian with the point mass\nconcentrated at (u0 , \u03c30 ) and H, respectively. Therefore, the smoother H is,\nthe more \"different\" it is from a point mass, and the less similar that f null\nand f alt are. Consequently, it is easier to separate one from the other, and\nhence a faster convergence rate in estimating the proportion and the null\nparameters.\nSince the smoothness of a density can be conveniently characterized by\nthe tail behavior of its characteristic function, this suggests that frequency\ndomain techniques can be naturally used for studying the optimal rate of\nconvergence. Along this line, we first derive a minimax lower bound by\na careful analysis of the tail behavior of the characteristic functions and\nby a two-point testing technique. We then establish the upper bound by\nconstructing estimators with the risks converging to zero at the same rate\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n5\n\nas that of the lower bound-such estimators are then rate optimal. The\nprocedures are closely related to our recent work Jin and Cai (2007) and Jin\n(2008) which to the best of our knowledge are the only frequency-domainbased approach to estimating the null parameters and the proportion of\nnonnull effects. We should emphasize that the upper bound does not follow\ntrivially from that in Jin and Cai (2007) and Jin (2008). For example, it\nis seen that the procedure for estimating the proportion proposed in Jin\nand Cai (2007) and Jin (2008) is not optimal, and careful modifications are\nneeded to make it optimal. Also, to prove the optimality of the procedures\nhere, we need much more delicate analysis than that in Jin and Cai (2007)\nand Jin (2008), where the scope of the study is limited to the consistency of\nthe procedures.\nIn addition to the asymptotic analysis, we also investigate the finite n\nperformance of the estimators using simulated data. The proposed procedures are easy to implement. The goal for the simulation study is two-fold:\nhow accurate the parameters are estimated and how the errors in the point\nestimation affect the results of the subsequent multiple testing. The numerical study shows that our estimators enjoy superior performance both in\nparameter estimation (measured by mean squared errors) and in the subsequent multiple testing. Our estimator of the proportion performs well uniformly in all the cases in comparison to the estimators proposed in Storey\n(2002) and Efron (2004). In particular, it is robust under many different\nchoices of nonnull distribution and sparsity level. The multiple testing results are generally sensitive to the changes in the null parameters as well as\nthe proportion. In our numerical study, we compare the performance of our\nestimators with those of Storey (2002) and Efron (2004) using two specific\nmultiple testing procedures, the adaptive p-value based procedure of Benjamini and Hochberg (2000) which requires estimation of the proportion \u03b5,\nand the AdaptZ procedure of Sun and Cai (2007) which requires estimation\nof \u03b5, f and f null . The simulation study shows that our estimators yield the\nmost accurate multiple testing results in both cases in comparison to the\nother two estimators.\nThe paper is organized as follows. In Section 2, after basic notation and\ndefinitions are introduced, we consider the minimax lower bound for estimating the null parameters. We then derive the minimax rates of convergence\nby showing that the lower bound is in fact sharp. This is accomplished by\nconstructing rate-optimal estimators using the empirical characteristic functions. Section 3 studies the minimax estimation of the proportion. We first\nconsider the simpler case where the null parameters are given and then extend the result to the case where the null parameters are unknown. Section\n4 investigates the numerical performance of our procedure by a simulation\nstudy. Section 5 discusses possible extensions of our work and its connections with the nonparametric deconvolution problem. The proofs of the main\n\n\f6\n\nT. T. CAI AND J. JIN\n\nresults are given in Section 6 and the Appendix contains the proofs of the\ntechnical lemmas that are used to prove the main results.\n2. Estimating the null parameters: Minimax risk and rate optimal estimators. In this section, we study the minimax risks for estimating the\nnull parameters. The minimax lower bounds are established by a two-point\ntesting argument in Section 2.1. At the core of the argument is the construction of two underlying densities whose corresponding null parameters\nare different but whose characteristic functions match with each other in\nlow frequencies. We then derive the minimax upper bounds by constructing\nand studying rate optimal estimators in Section 2.2.\nReturn to the Gaussian mixture model\n\u0012\n\u0012\n\u0013\n\u0013\nZ\n1\nx \u2212 u0\nx\u2212u\n1\ni.i.d.\n\u03c6\n+\u03b5\n(2.1) Xj \u223c (1 \u2212 \u03b5) \u03c6\ndH(u, \u03c3) \u2261 f (x).\n\u03c30\n\u03c30\n\u03c3\n\u03c3\n\nFor any mixing distribution H(u, \u03c3) under consideration, let H(\u03c3) be the\nmarginal distribution of \u03c3 and let H(u|\u03c3) be the conditional distribution of\nu given \u03c3.\nDefinition 2.1. We call a density f eligible if it has the form as in (2.1)\nwhere H(u, \u03c3) satisfies that H(\u03c3) is supported on [\u03c30 , \u221e) and that H(u|\u03c3)\nhas a density h(u|\u03c3) for any \u03c3 \u2265 \u03c30 . We denote the set of all eligible f by\nF.\nTwo examples for eligible f are (1). H(\u03c3) is supported in [\u03c30 + \u03b4, \u221e) for\nsome constant \u03b4 > 0, and (2). H(\u03c3) is the point mass at \u03c30 , and H(u|\u03c30 )\nhas a density.\nIn this paper, we focus on eligible f , so that the null parameters and the\nproportion of nonnull effects are both identifiable. See Jin and Cai (2007)\nfor more discussion on identifiability.\nWe shall define the parameter space of f for the minimax theory. First,\nwe suppose that for some fixed constant q > 0 and A > a > 0,\nZ\n(2.2)\n\u03c30 \u2265 a,\n|x|q f (x) dx \u2264 Aq ,\nso that \u03c302 and u0 are uniformly bounded across the whole parameter space.\nSecond, fix \u03b1 > 0. We assume\n(2.3)\n\nlim sup {|t|\u03b1 |\u0125(t|\u03c3)|} \u2264 A,\n\nt\u2192\u221e \u03c3\u2265\u03c30\n\nlim sup {|t|\u03b1+1 |h\u0303\u2032 (t|\u03c3)|} \u2264 A,\n\nt\u2192\u221e \u03c3\u2265\u03c30\n\nwhere h(u|\u03c3) is the aforementioned conditional density, \u0125(t|\u03c3) is the corresponding characteristic function and\nZ\n(2.4)\nh\u0303(t|\u03c3) = h\u0303(t|\u03c3; u0 ) = eitu h(u + u0 |\u03c3) du.\n\n\f7\n\nOPTIMAL RATES OF CONVERGENCE\n\nRoughly speaking, (2.3) requires h(u|\u03c3) to be sufficiently smooth so that\n\u0125(t|\u03c3) decays at a rate not slower than that of |t|\u2212\u03b1 . We shall see below that\nthe minimax risk depends on the smoothness parameter \u03b1. Note that in (2.2)\nand (2.3), different constants A can be used in different places. However, this\ndoes not change the minimax rate of convergence, so we use the same A for\nsimplicity.\nLast, we calibrate the proportion \u03b5. In the literature, the proportion is a\nwell-known measure for sparsity; see, for example, Abramovich et al. (2006)\nand Jin and Cai (2007). In this paper, we focus on the moderately sparse\n\u221a\ncase where the proportion\n\u03b5 = \u03b5n can be small but not smaller than 1/ n.\n\u221a\nThe case \u03b5n \u226a 1/ n is called the very sparse case and has been proven\nto be much more challenging for statistical inference; see Donoho and Jin\n(2004) and Cai, Jin and Low (2007) for detailed discussion. In light of this,\nwe suppose that for some fixed parameters \u03b50 \u2208 (0, 1) and \u03b2 \u2208 [0, 1/2),\n(2.5)\n\n\u03b5n \u2264 \u03b7n\n\nwhere \u03b7n = \u03b7n (\u03b50 , \u03b2) \u2261 \u03b50 n\u2212\u03b2 .\n\nNote that \u03b7n = \u03b50 when \u03b2 = 0. For this reason, we require \u03b50 < 1 so that the\nnull component will not be vanishingly small.\nIn summary, the parameter space we consider for the minimax risk is\n(2.6)\n\nF0 = F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n)\n= {f \u2208 F and satisfies (2.2), (2.3) and (2.5)}.\n\nWe measure the performance of an estimator for the null parameters by\nmean squared errors, and measure the level of difficulty for the problem\nof estimating the null parameters \u03c302 and u0 by the minimax risks defined,\nrespectively, by\no\nn\nRn\u03c3 = Rn\u03c3 (F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n)) = inf\nsup\nE[\u03c3\u0302 2 \u2212 \u03c302 ]2\n\u03c3\u030202\n\nand\n\nRnu = Rnu (F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n)) = inf\n\u00fb0\n\nF0 (\u03b1,\u03b2,\u03b50 ,q,a,A;n)\n\nn\n\nsup\n\nF0 (\u03b1,\u03b2,\u03b50 ,q,a,A;n)\n\no\nE[\u00fb0 \u2212 u0 ]2 .\n\n2.1. Lower bound for the minimax risk. In this section, we establish the\nlower bound for the minimax risk of estimating \u03c302 and u0 . As the discussions\nare similar, we shall focus on that for \u03c302 . We use the well-known two-point\ntesting argument to show the lower bound [see, e.g., Ibragimov, Nemirovskii\nand Khas'minskii (1986) and Donoho and Liu (1991)], where the key is to\nconstruct two density functions in F0 -f1 (x) and f2 (x)-such that the null\nvariance parameters associated with them differ by a small amount, say \u03b4n ,\nbut two densities are indistinguishable in the sense that their \u03c72 -distance\nZ\n(f2 (x) \u2212 f1 (x))2\nd(f1 , f2 ) \u2261\n(2.7)\ndx\nf1 (x)\n\n\f8\n\nT. T. CAI AND J. JIN\n\nis of a smaller order than that of 1/n. In fact, once such densities f1 and f2\nare constructed, then there is a constant C > 0 such that\n(2.8)\n\nRn\u03c3 \u2265 C\u03b4n2\n\nand C\u03b4n2 is a lower bound for the minimax risk; see Ibragimov, Nemirovskii\nand Khas'minskii (1986) and Donoho and Liu (1991) for details.\nTo this end, let\na2n = a2 + \u03b4n ,\nwhere \u03b4n > 0 to be determined. Our construction of f1 and f2 has the form\nof\n\u0012 \u0013\n\u0012\n\u0013\nZ\nx\nx\u2212u\n1\n1\n\u03c6\nf1 (x) = (1 \u2212 \u03b7n ) \u03c6\n(2.9)\n+ \u03b7n\nh1 (u) du,\na\na\na\na\n\u0012 \u0013\n\u0012\n\u0013\nZ\n1\nx\nx\u2212u\n1\nf2 (x) = (1 \u2212 \u03b7n ) \u03c6\n\u03c6\n(2.10)\n+ \u03b7n\nh2 (u) du,\nan\nan\nan\nan\nwhere a and \u03b7n are as in the definition of F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n), h1 (u) and\nh2 (u) are two density functions to be determined (note that the null variance\nparameters associated with f1 and f2 differ by an amount of \u03b4n ). There are\ntwo key elements in our construction. First, the characteristic functions of\nf1 and f2 match with each other in low frequencies, that is, for a constant\n\u03c4 = \u03c4n to be determined,\n(2.11)\n\nf\u02c61 (t) = f\u02c62 (t)\n\n\u2200|t| \u2264 \u03c4n .\n\nSecond, f1 is heavy-tailed in the spatial domain,\n(2.12)\n\nf1 (x) \u2265 C\u03b7n (1 + |x|)\u2212k\n\n\u2200x,\n\nwhere k > 0 is an integer to be determined. Below, we first show that the\n\u03c72 -distance between f1 and f2 equals to o(1/n) if we take the \u03c4n in (2.11)\nto be\n1p\n(2.13)\n3 log n.\n\u03c4n =\na\n\nWe then sketch how to construct f1 and f2 to satisfy (2.11) and (2.12), and\ndiscuss how large \u03b4n could be so that such a construction is possible. We\nconclude this subsection with the statement for the minimax lower bounds.\nTo focus on the main ideas, we try to be simple and heuristic in this section\nand leave proof details to Section 6.\nWe now begin by investigating the \u03c72 -distance. First, the heavy-tailed\nproperty of f1 largely simplifies the calculation of the \u03c72 -distance. In fact, by\n(2.12) and the well-known Parseval formula [Mallat (1998)], the \u03c72 -distance\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n9\n\nis proportional to the L2 -distance in the spatial domain, and so the L2 distance in the frequency domain,\nZ\nd(f1 , f2 ) \u2264 C logk/2 (n)\u03b7n\u22121 (f2 (x) \u2212 f1 (x))2 dx\n= C log\n\nk/2\n\n(n)\u03b7n\u22121\n\nZ\n\n(f\u02c61 (t) \u2212 f\u02c62 (t))2 dt.\n\nSee Section 6 for the proof. Moreover, since that f\u02c61 and f\u02c62 match each other\n2 2\nin low frequencies, and that |f\u02c6j (t)| \u2264 Ce\u2212a t /2 for j = 1, 2,\nZ\nZ\nZ\n2 2\ne\u2212a t /2 dt.\n(f\u02c61 (t) \u2212 f\u02c62 (t))2 dt \u2264 C\n(f\u02c61 (t) \u2212 f\u02c62 (t))2 dt =\n|t|\u2265\u03c4n\n\n|t|\u2265\u03c4n\n\nPutting these together,\n2 2\n\nd(f1 , f2 ) \u2264 C logk/2 (n)\u03b7n\u22121 e\u2212a \u03c4n /2 = C\u03b7n\u22121 logk/2 (n)n\u22123/2 .\n\u221a\nSince \u03b7n \u226b 1/ n, this show that the \u03c72 -distance d(f1 , f2 ) = o(1/n).\nNext, we sketch the idea for constructing f1 and f2 . Consider f1 first. We\nconstruct h1 as a perturbation of the standard normal density,\n(2.14)\n\n(2.15)\n\nh1 (u) = \u03c6(u) + \u03b80 w1 (u).\n\nThe key is to show that for an appropriate constant \u03b80 > 0 and a function\nw1 , h1 is indeed a density function, and f1 satisfies the heavy-tailed requirement (2.12). Let k be an even number, we construct w1 (u) through\nk/2\n\n\u03c0 k\u22121\nin the vicinits characteristic function as follows: \u01751 (t) = (\u22121)\n(k\u22121)! |t|\n\u2212\u03b1\nity of 0, \u01751 (t) = |t|\nfor large |t|, and is smooth in between [details are\nRgiven later in (6.1)]. By elementary Fourier analysis, first, we note that\nw1 (u) du = \u01751 (0) = 0. Second, we note that the tail behavior of w1 is\ndetermined by the only singular point of \u01751 (which is t = 0); in fact, by repeatedly using integration by parts, we have that for large u, w1 (u) \u223c |u|\u2212k ,\nthat is,\n\n(2.16)\n\nlim w1 (u)|u|k = 1.\n\n|u|\u2192\u221e\n\nWe shall see that, first, (2.16) implies the heavy-tailed property of f1 , and\nsecond, (2.16) ensures that w1 (u) is positive for sufficiently large u, so h1 is\na density function for an appropriately small \u03b80 > 0. Additionally, we will\njustify later that f1 belongs to F0 . Therefore, f1 constructed this way meets\nall the desired requirements.\nNow consider f2 . Similarly, we construct h2 as a perturbation of a normal\ndensity,\n\u0012\n\u0013\n1\nu\nh2 (u) = \u221a\n\u03c6 \u221a\n(2.17)\n+ \u03b80 w2 (u)\n1 \u2212 \u03b4n\n1 \u2212 \u03b4n\n\n\f10\n\nT. T. CAI AND J. JIN\n\nand the key is to construct w2 so that f\u02c61 and f\u02c62 match in low frequencies.\nNote that\n2\n2\n2 2\nf\u02c61 (t) = \u03b7n e\u2212(a +1)t /2 + e\u2212a t /2 [(1 \u2212 \u03b7n ) + \u03b80 \u03b7n \u01751 (t)]\n\nand\n2\n2\n2 2\nf\u02c62 (t) = \u03b7n e\u2212(a +1)t /2 + e\u2212an t /2 [(1 \u2212 \u03b7n ) + \u03b80 \u03b7n \u01752 (t)].\n\nBy direct calculations, in order for f\u02c61 and f\u02c62 to match in low frequencies, it\nis necessary that\n(2.18)\n\n\u01752 (t) = w\u0303(t)\n2 /2\n\nfor all |t| \u2264 \u03c4n where w\u0303(t) \u2261 e\u03b4n t\n\n\u01751 (t) +\n\n1 1 \u2212 \u03b7n \u03b4n t2 /2\n[e\n\u2212 1].\n\u03b80 \u03b7n\n\nIn light of this, we construct w2 through its characteristic function as follows:\n\u01752 (t) = w\u0303(t) for |t| \u2264 \u03c4n , \u01752 (t) = 0 for |t| > \u03c4n + 1, and is smooth in between.\nFigure 1 illustrates the construction of \u01751 and \u01752 ; see details therein.\nWe now investigate what is the largest \u03b4n so that f2 constructed this way\nbelongs to F0 . By the definition of F0 , it is necessary that |\u01252 (t)| \u2264 A|t|\u2212\u03b1\nfor all t, and especially that |\u01252 (\u03c4n )| \u2264 A\u03c4n\u2212\u03b1 . Recall that \u01751 (\u03c4n ) = \u03b80 \u03c4n\u2212\u03b1 ,\nwe have\n\u0012\n\u0013\n\u03b4n 2\n1 1 \u2212 \u03b7n \u03b4n \u03c4n2 /2\n\u2212\u03b1\n\u03b4n t2 /2\n[e\n\u2212 1] \u223c O \u03c4n +\n\u03c4 .\n\u01252 (\u03c4n ) = e\n\u01751 (\u03c4n ) +\n\u03b80 \u03b7n\n\u03b80 \u03b7n n\nTogether, these require that\n\u03b4n \u2264 C\u03b7n \u03c4n\u2212(\u03b1+2) .\nIn light of this, we calibrate \u03b4n as\n\u03b4n = \u03b80 \u03b80 \u03b7n \u03c4n\u2212(\u03b1+2) ,\n\n(2.19)\n\nwhere \u03b80 > 0 is a constant to be determined. Interestingly, it turns out that\nfor an appropriately small \u03b80 , w2 constructed in this way ensures that h2 is\na density function and that f2 lives F0 (see Section 6). Therefore, the largest\n\u2212(\u03b1+2)\npossible \u03b4n is of the order of O(\u03b7n \u03c4n\n).\nWe are now ready to state the minimax lower bounds. Let Mq be the qth\nmoment of the standard normal [i.e., Mq = E|X|q with X \u223c N (0, 1)], the\nfollowing theorem is proved in Section 6.\nTheorem 2.1. Fix \u03b1 > 2, \u03b2 \u2208 [0, 1/2), \u03b50 \u2208 (0, 1), q > 0, a > 0 and A >\n1/q\na2 + 1Mq . There is a constant C > 0 which depends on \u03b1, \u03b2, \u03b50 , q, a and\nA such that,\n\n\u221a\n\nlim n2\u03b2 * (log n)(\u03b1+2) * Rn\u03c3 (F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n)) \u2265 C\n\nn\u2192\u221e\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n11\n\nFig. 1. The first three panels illustrate \u01751 (t) (red), w\u0303(t) (blue) and \u01752 (t) (green). Note\nthat w\u0303 is not a characteristic function as w\u0303(t) > 1 for large |t|, and that \u01752 is a truncated\nversion of w\u0303. The last panel is the overlay and zoom in of the first three panels.\n\nand\nlim n2\u03b2 * (log n)(\u03b1+1) * Rnu (F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n)) \u2265 C.\n\nn\u2192\u221e\n\nDue to the calibrations we choose in (2.3) and (2.5), the optimal rate is\nexpressed in terms of parameters \u03b1, \u03b2. Such calibrations are mainly for the\nsimplicity in the presentation: Theorem 2.1 (as well as Theorems 2.2, 3.1 and\n3.2 below) can be extended to more general settings. Here is an example. Fix\n\u03b50 \u2208 (0, 1) and \u03b2 \u2208 [0, 1/2), suppose we (a) modify the calibration of \u03b5n in\n(2.5) into that \u03b7n \u2264 \u03b5n \u2264 \u03b50 with \u03b7n being a sequence satisfying \u03b7n \u2265 \u03b50 n\u2212\u03b2 ,\nand (b) change the parameter space from F0 to F0\u2032 = F0\u2032 (\u03b1, q, a, A, \u03b7n ; n),\nwhere\nF0\u2032 (\u03b1, \u03b2, q, a, A, \u03b7n ; n)\n= {f \u2208 F and satisfies (2.2), (2.3), and constraints on \u03b5n above}.\nThe following corollary can be proved similarly as that of Theorem 2.1.\n\n\f12\n\nT. T. CAI AND J. JIN\n\nCorollary 2.1. Fix \u03b1 > 2, \u03b2 \u2208 [0, 1/2), \u03b50 \u2208 (0, 1), q > 0, a > 0 and\n\u221a\n1/q\nA > a2 + 1Mq , let \u03b5n and F0\u2032 be calibrated as above. There is a constant\nC > 0 which depends on \u03b1, \u03b2, \u03b50 , q, a and A such that\nlim \u03b7n\u22122 * (log n)(\u03b1+2) * Rn\u03c3 (F0\u2032 (\u03b1, \u03b2, q, a, A, \u03b7n ; n)) \u2265 C\n\nn\u2192\u221e\n\nand\nlim \u03b7n\u22122 * (log n)(\u03b1+1) * Rnu (F0\u2032 (\u03b1, \u03b2, q, a, A, \u03b7n ; n)) \u2265 C.\n\nn\u2192\u221e\n\n\u221a\n1/q\nWe remark that for the case \u03b2 > 0, the condition A > a2 + 1Mq can\n1/q\nbe relaxed to that of A > aMq . The latter is the minimum requirement for\notherwise F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n) is an empty set. Theorem 2.1 shows that the\nminimax risk for estimating \u03c302 cannot converge to 0 faster than O(n\u22122\u03b2 *\n(log n)\u2212(\u03b1+2) ), and that for estimating u0 cannot be faster than O(n\u22122\u03b2 *\n(log n)\u2212(\u03b1+1) ). In next section, we shall show that these rates can indeed be\nattained and thus establish the minimax rates of convergence.\n2.2. Rate optimal estimators for the null parameters. In this section, we\nseek estimators of the null parameters whose risks converge at the same\nrates as those of the lower bounds. Once such estimators are constructed,\nthen their risks give upper bounds for the minimax risks, and the estimators\nthemselves are rate optimal.\nGiven that estimating the null parameters is a relatively new problem,\nthere are only a small number of methods in the literature. One straightforward approach is the method of moments, and another approach, proposed\nby Efron (2004), is to use the half-width of the central peak of the histogram.\nHowever, these approaches are only consistent in the sparse case where the\nproportion \u03b5 = \u03b5n tends to 0 as n tends to \u221e. See Jin and Cai (2007) for\nmore discussion.\nIn our recent work [Jin and Cai (2007)], we demonstrated that the null\ncomponent can be well isolated in high-frequency Fourier coefficients, and\nbased on this observation, we introduced a Fourier approach for estimating\nthe null parameters. In detail, for any t and complex-valued differentiable\nfunction \u03be, let Im(\u03be) be the imaginary part and \u03be\u0304 be the complex conjugate,\nwe introduce two functionals as follows:\n\u0012\n\u0013\nd/ds|\u03be(s)|\n2\n\u03c30 (t; \u03be) = \u2212\n,\ns|\u03be(s)|\ns=t\n(2.20)\n\u0013\n\u0012\n1\n\u2032\n.\n* Im(\u03be\u0304(s)\u03be (s))\nu0 (t; \u03be) =\n|\u03be(s)|2\ns=t\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n13\n\nNext, fix \u03b3 \u2208 (0, 1/2), let \u03c6n (t) be the empirical characteristic function,\nn\n\n(2.21)\n\n\u03c6n (t) =\n\n1 X itXj\ne\nn\nj=1\n\nand\n(2.22)\n\nt\u0302n (\u03b3) = min{t : t > 0, |\u03c6n (t)| \u2264 n\u2212\u03b3 }.\n\nWe define the estimators for \u03c302 and u0 as\n\u03c3\u030202 (\u03b3) = \u03c302 (t\u0302n (\u03b3); \u03c6n ),\n\n\u00fb0 (\u03b3) = u0 (t\u0302n (\u03b3); \u03c6n ).\n\nTo illustrate the idea behind the construction of these estimators, we\nconsider a simplified case where f is a homoscedastic Gaussian location\nmixture:\n\u0012\n\u0013\n1\nx \u2212 u0\nf (x) = (1 \u2212 \u03b5) \u03c6\n\u03c30\n\u03c30\n\u0012\n\u0013\nZ\n1\nx\u2212u\n+\u03b5\n\u03c6\nh(u) du,\nh: a univariate density.\n\u03c30\n\u03c30\nFirst, the empirical characteristic function approximates the underlying characteristic function \u03c6(t) = \u03c6(t; f ) \u2261 E[eitXj ],\n2 2 /2\n\n\u03c6n (t) \u2248 \u03c6(t) = e\u2212\u03c30 t\n\n[(1 \u2212 \u03b5)eiu0 t + \u03b5\u0125(t)].\n\nSecond, by the well-known Riemann\u2013Lebesgue lemma, for large t, \u0125(t) \u2248 0,\nso\n2 2 /2\n\n\u03c6(t) \u2248 (1 \u2212 \u03b5)e\u2212\u03c30 t\n\neiu0 t \u2261 \u03c60 (t).\n\nLast, t\u0302n (\u03b3) approximates its nonstochastic counterpart tn (\u03b3),\n(2.23)\n\ntn (\u03b3) = min{t : t > 0, |\u03c6(t)| \u2264 n\u2212\u03b3 }.\n\nPutting these together, we have that, heuristically,\n\u03c3\u030202 (\u03b3) \u2248 \u03c302 (tn (\u03b3), \u03c60 ) \u2261 \u03c302 ,\n\n\u00fb0 (\u03b3) \u2248 u0 (tn (\u03b3), \u03c60 ) \u2261 u0 ,\n\nwhere \"\u2261\" follow from direct calculations. See more discussions in Jin and\nCai (2007).\nThe above approach has been studied in Jin and Cai (2007), where it\nwas shown to be uniformly consistent across a wide class of cases. However,\nwhether any of these estimators attains the optimal rate of convergence remains an open question. The difficulty is two-fold. First, compared to the\nstudy on consistency as in Jin and Cai (2007), the study on the optimal rate\nof convergence needs a much more delicate analysis on several small probability events. Tighter bounds on such events are not necessary for showing\n\n\f14\n\nT. T. CAI AND J. JIN\n\nthe consistency, but they are indispensable for proving the optimal rate of\nconvergence. Second, a major technical difficulty is that the frequency t\u0302n (\u03b3)\nis stochastic and is not independent of the samples Xj . The stochasticity\nand dependence pose challenges in evaluating the estimation risks, and are\nthe culprits for the lengthy analysis.\nIn this paper, we develop new analytical tools to solve these problems. The\nnew analysis provides better probability bounds on several nuisance events\nand better control on the stochastic fluctuation of t\u0302n (\u03b3), \u03c3\u030202 (\u03b3) and \u00fb0 (\u03b3).\nThe analysis reveals that the estimators \u03c3\u030202 (\u03b3) and \u00fb0 (\u03b3) are in fact rateoptimal under minimum regularity conditions. This is the following theorem,\nwhich is proved in Section 6.\nTheorem 2.2. Fix \u03b3 \u2208 (0, 1/2), \u03b1 > 2, \u03b2 \u2208 [0, 1/2), \u03b50 \u2208 (0, 1), q \u2265 4,\n\u221a\n1/q\na > 0 and A > a2 + 1Mq . There is a constant C > 0 which only depends\non \u03b3, \u03b1, \u03b2, \u03b50 , q, a and A such that\nsup\nF0 (\u03b1,\u03b2,\u03b50 ,q,a,A;n)\n\nE[\u03c3\u030202 (\u03b3) \u2212 \u03c302 ]2 \u2264 C(n\u22122\u03b2 log\u2212(\u03b1+2) (n) + log(n) * n2\u03b3\u22121 )\n\nand\nsup\nF0 (\u03b1,\u03b2,\u03b50 ,q,a,A;n)\n\nE[\u00fb0 (\u03b3) \u2212 u0 ]2 \u2264 C(n\u22122\u03b2 log\u2212(\u03b1+1) (n) + log2 (n) * n2\u03b3\u22121 ).\n\nTaking \u03b3 < 1/2 \u2212 \u03b2 in Theorem 2.2, it then follows from Theorems 2.1\nand 2.2 that the minimax rate of convergence for estimating the null parameters \u03c302 and u0 are n\u22122\u03b2 log\u2212(\u03b1+2) (n) and n\u22122\u03b2 log\u2212(\u03b1+1) (n), respectively.\nFurthermore, the estimators \u03c3\u030202 (\u03b3) and \u03bc\u03020 (\u03b3) with \u03b3 < 1/2 \u2212 \u03b2 are rate optimal. Different choices of \u03b3 does not affect the convergence rate but may\naffect the constant. In Section 4, we investigate how to choose \u03b3 in practice\nwith simulated data. We find that in many situations, the mean square error\nis relatively insensitive to the choice of \u03b3, provided that it falls in the range\nof (0.15, 0.25).\nWe mention that the logarithmic term in the minimax risk bears some\nsimilarity with the conventional deconvolution problem. See Section 5 for\nfurther discussion.\n3. Estimating the proportion of nonnull effects. We now turn to the\nminimax estimation of the proportion. First, we consider the case where the\nnull parameters are known. We show that, with careful modifications, the\napproach proposed in our earlier work [Jin and Cai (2007) and Jin (2008)]\nattains the optimal rate of convergence. We then extend the optimality to\nthe case where the null parameters (u0 , \u03c302 ) are unknown.\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n15\n\n3.1. Estimating the proportion when the null parameters are known. When\nthe null parameters (u0 , \u03c302 ) are known, we can always use them to renormalize the test statistics Xj . So without loss of generality, we assume\nu0 = 0 and \u03c30 = 1. As a result, the marginal density of Xj obeys a simplified\nform,\n\u0013\nZ \u0012\nx\u2212u\ni.i.d.\n(3.1)\ndH(u, \u03c3) \u2261 f.\nXj \u223c (1 \u2212 \u03b5)\u03c6(x) + \u03b5 \u03c6\n\u03c3\nThe problem of estimating the proportion has received much recent attention. See, for example, Storey (2002), Genovese and Wasserman (2004),\nMeinshausen and Rice (2006) [see also Efron et al. (2001) and Swanepoel\n(1999)]. A necessary condition for the consistency of several of these approaches is that the marginal density of the nonnull effects (i.e., f alt ) is\npure, a notion introduced in Genovese and Wasserman (2004). Unfortunately, the purity condition is generally not satisfied in the current setting;\nsee Jin (2008) for a detailed discussion.\nIn our recent work Jin and Cai (2007) and Jin (2008), we proposed a\nFourier approach to estimating the proportion which is described as follows. Let \u03c9(\u03be) be a bounded, continuous, and symmetric density function\nsupported in (\u22121, 1). Define a so-called phase function\nZ\n2 2\n\u03c8n (t; \u03c9) = \u03c8n (t; \u03c9, X1 , X2 , . . . , Xn ) = \u03c9(\u03be)et \u03be /2 \u03c6n (t\u03be) d\u03be,\nP\nwhere as before \u03c6n (t) = n1 nj=1 eitXj is the empirical characteristic function.\nFix \u03b3 \u2208 (0, 1/2) and let tn = tn (\u03b3) be as in (2.23), the estimator is defined\nas\n(3.2)\n\n\u03b5\u0302n (\u03b3; \u03c9) = \u03b5\u0302n (\u03b3; \u03c9, X1 , X2 , . . . , Xn ) = 1 \u2212 Re(\u03c8n (tn (\u03b3); \u03c9)),\n\nwhere Re(z) stands for the real part of z. In Jin and Cai (2007) and Jin\n(2008), three different choices of \u03c9(\u03be) are recommended, namely the uniform\ndensity, the triangle density and the smooth density that is proportional to\n1\nexp(\u2212 1\u2212|\u03be|\n2 ) * 1{|\u03be|<1} .\nThe advantage of the Fourier approach is that it is no longer tied to\nthe purity condition and can be shown to be consistent for the proportion\nuniformly for all eligible H(u, \u03c3); see details in Jin and Cai (2007) and Jin\n(2008). However, unfortunately, it is not hard to show that these estimators\nare not rate optimal with any of these three \u03c9.\nIn this paper, we propose the following estimator:\n!\nn\n1 X t2 /2\ne\ncos(tXj )\n\u03b5\u0302n (\u03b3) = 1 \u2212\nn\n\u221a\nj=1\n\n= 1 \u2212 n\u2212(1\u2212\u03b3)\n\nt= 2\u03b3 log n\n\nn\nX\nj=1\n\np\ncos( 2\u03b3 log nXj ).\n\n\f16\n\nT. T. CAI AND J. JIN\n\nIn comparison, \u03b5\u0302n (\u03b3) is a special case of \u03b5\u0302n (\u03b3; \u03c9), where instead of being a\ndensity function as in (3.2), \u03c9 is a point mass concentrated at 1. We shall\nshow that under mild conditions, the proposed estimator \u03b5\u0302n (\u03b3) attains the\noptimal rate of convergence. In detail, fix \u03b1 > 0, \u03b2 \u2208 [0, 1/2), \u03b50 \u2208 (0, 1),\n\u221a\n1/2\nq \u2265 2, and A > 2Mq , let \u03b7n = \u03b50 n\u2212\u03b2 be as before. Consider the following\nparameter space for the minimax theory on estimating the proportion:\n\u001a\n\u001b\nZ\nq\nq\n(3.3) F\u0303 = F\u0303(\u03b1, \u03b2, \u03b50 , q, A; n) = f \u2208 F : \u03b5 \u2264 \u03b7n , |x| f (x) dx \u2264 A .\nThe minimax risk for estimating the proportion when the null parameters\nare known is\nn\no\nRn\u03b5,a = Rn\u03b5,a (F\u0303(\u03b1, \u03b2, \u03b50 , q, A; n)) = inf\n(3.4)\nsup\nE[\u03b5\u0302 \u2212 \u03b5]2 .\n\u03b5\u0302\n\nF\u0303 (\u03b1,\u03b2,\u03b50 ,q,A;n)\n\nWe have the following theorem.\nTheorem 3.1. Fix \u03b3 \u2208 (0, 1/2), \u03b1 > 0, \u03b2 \u2208 [0, 1/2), \u03b50 \u2208 (0, 1), q \u2265 2,\n\u221a\n1/q\nA > 2Mq . There is a generic constant C > 0 which only depends on \u03b1,\n\u03b2, \u03b50 , q, A and \u03b3 such that for sufficiently large n,\nRn\u03b5,a (F\u0303(\u03b1, \u03b2, \u03b50 , q, A; n)) \u2265 Cn\u22122\u03b2 log\u2212\u03b1 (n)\nand\nsup\nF\u03030 (\u03b1,\u03b2,\u03b50 ,q,A;n)\n\nE[\u03b5\u0302(\u03b3) \u2212 \u03b5]2 \u2264 C(n\u22122\u03b2 log\u2212\u03b1 (n) + n2\u03b3\u22121 ).\n\nIn particular, if \u03b3 < 1/2 \u2212 \u03b2, then \u03b5\u0302n (\u03b3) attains the optimal rate of convergence.\nThe proof of Theorem 3.1 is similar (but significantly simpler) than Theorem 3.2 below, which deals with the case where the null parameters are\nunknown. For reasons of space, we provide the proof of Theorem 3.2 in\nSection 6 but omit that of Theorem 3.1.\n3.2. Estimating the proportion when the null parameters are unknown.\nWe now turn to the case where the null parameters are unknown. A natural\napproach is to first estimate the null parameters with (\u03c3\u03020 (\u03b3), \u00fb0 (\u03b3)) and\nthen plug them into \u03b5\u0302n (\u03b3) to obtain an estimate of the proportion. In other\nwords, fix \u03b3 \u2208 (0, 1/2), the plug-in estimator is\n\u0012\u0014\n\u0015\u0013\nn\nXj \u2212 \u00fb0 (\u03b3)\n1 X t2 /2\n\u2217\n(3.5)\n.\ne\ncos t\n\u03b5\u0302n (\u03b3) = 1 \u2212\n\u221a\nn\n\u03c3\u03020 (\u03b3)\n{t= 2\u03b3 log n}\nj=1\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n17\n\nWe consider the minimax risk over the parameter space F0 . The minimax\nrisk for estimating the proportion when the null parameters are unknown is\nthen\no\nn\n(3.6) Rn\u03b5,b = Rn\u03b5,b (F0 (\u03b1, \u03b2, \u03b50 , q, A, a; n)) = inf\nsup\nE[\u03b5\u0302 \u2212 \u03b5]2 .\n\u03b5\u0302\n\nF0 (\u03b1,\u03b2,\u03b50 ,q,a,A;n)\n\nThe following theorem, proved in Section 6, shows that the plug-in estimator\nis rate optimal.\n\nTheorem 3.2. Fix \u03b3 \u2208 (0, 1/2), \u03b1 > 2, \u03b2 \u2208 [0, 1/2), \u03b50 \u2208 (0, 1), q > 4 +\n\u221a\n1/q\n2\u03b3, a > 0 and A > a2 + 1Mq . There is a generic constant C > 0 which\nonly depends on \u03b3, \u03b1, \u03b2, \u03b50 , q, a and A such that for sufficiently large n,\nRn\u03b5,b \u2265 Cn\u22122\u03b2 log\u2212\u03b1 (n)\nand\nsup\nF0 (\u03b1,\u03b2,\u03b50 ,q,a,A;n)\n\nE[\u03b5\u0302\u2217n (\u03b3) \u2212 \u03b5]2 \u2264 C(n\u22122\u03b2 log\u2212\u03b1 (n) + log3 (n) * n2\u03b3\u22121 ).\n\nEspecially if \u03b3 < 1/2 \u2212 \u03b2, then \u03b5\u0302\u2217n (\u03b3) attains the optimal rate of convergence.\nCompare Theorem 3.2 with Theorem 3.1, we see that except for the small\ndifference in the upper bound [one has the log3 (n) term and the other does\nnot], the minimax rates of convergence are the same whether the null parameters are known or not. The log3 (n) is the price we pay for the extra\nvariability in estimation when the null parameters are unknown. Therefore,\nthe plug-in estimator \u03b5\u0302\u2217n (\u03b3) given in (3.5) is rate-optimal under almost the\nsame conditions as in the case where the null parameters are known.\n4. Simulation study. The procedures for estimating the proportion and\nnull parameters presented in Sections 2 and 3 are easy to implement. In this\nsection, we investigate the numerical performance of the procedure with\nsimulated data.\nThe numerical study has several goals. The first is to consider the effect\nof the tuning parameter \u03b3 on mean squared error (MSE) of the estimators\nand to make a recommendation on the choice of \u03b3. The second is to compare\nthe performance of the estimators with different n. The third is to compare\nthe procedure with those in the literature. Several different combinations\nof the proportion and the nonnull distributions are used for such comparisons. The fourth is to investigate the performance of the estimators when\nthe assumptions on eligibility and independence do not hold. The last and\nthe most important goal is to study the effect of the estimation accuracy\nover the subsequent multiple testing procedures. Along this line, we consider two specific multiple testing procedures in our numerical study. One\n\n\f18\n\nT. T. CAI AND J. JIN\n\nis the adaptive p-value based procedure (AP) introduced in Benjamini and\nHochberg (2000) which requires an estimation of the proportion \u03b5. This is\nthe original Benjamini\u2013Hochberg step-up procedure with an adjusted FDR\nlevel accounting for the sparsity. Another is the AdaptZ procedure (AZ)\nproposed in Sun and Cai (2007). This procedure thresholds the ranked Lfdr\nstatistic (1.3) and requires estimations of \u03b5, f and f null . The procedure is\nasymptotically optimal in the sense that it minimizes the false nondiscovery\nrate asymptotically when the estimators of \u03b5, f and f null are consistent.\nUnless specified otherwise, the simulation results given in this section are\nbased on n = 10,000, 1000 replications and the following Gaussian mixture\nmodel:\n\u03b5\n\u03b5\nXi \u223c (1 \u2212 \u03b5)N (\u03bc0 , \u03c302 ) + N (\u03bc1i , \u03c3 2 ) + N (\u03bc2i , \u03c3 2 ),\n(4.1)\n2\n2\nwhere \u03bc1i and \u03bc2i are drawn from some distributions that may change from\none case to another. Below, we report the simulation results along with the\nfive aforementioned directions.\nFirst, we study the effect of the tuning parameter \u03b3 on the performance\nof the estimators. To this end, we consider the following setting.\nSetting 1. We take \u03bc0 = 0, \u03c30 = 1, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5), \u03b5 = 0.2 and \u03c3 = 1.2.\nTable 1 tabulates the MSE of the three estimators \u03b5\u0302\u2217n (\u03b3), \u00fb0 (\u03b3) and \u03c3\u030202 (\u03b3).\nThe results suggest that \u03b5\u0302\u2217n and \u03c3\u030202 perform well in terms of the MSE when\n\u03b3 is in a neighborhood of 0.2, ranging from 0.14 to 0.26 (note that, however,\nthe estimator \u03bc\u03020 favors a smaller \u03b3). Additional simulations show similar\npatterns. In light of this, we conclude that an overall good choice is \u03b3 = 0.2.\nWe recommend this choice for practical use in general, and use it in the rest\nof simulation study in this paper.\nSecond, we investigate how the number of hypotheses n affects the estimation accuracy. The setting we consider is the same as Setting 1, but with\ndifferent n.\nSetting 2. We take \u03bc0 = 0, \u03c30 = 1, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5), \u03b5 = 0.2, \u03c3 = 1.2 and n ranges from 2000 to 500,000.\nTable 1\nMSE (in unit of 10\u22124 ) of the estimators \u03b5\u0302\u2217n (\u03b3), \u00fb0 (\u03b3) and \u03c3\u030202 (\u03b3) for different \u03b3\n\u03b3\nMSE(\u03b5\u0302\u2217n )\nMSE(\u00fb0 )\nMSE(\u03c3\u030202 )\n\n0.08\n\n0.11\n\n0.14\n\n0.17\n\n0.20\n\n0.23\n\n0.26\n\n0.29\n\n0.32\n\n0.35\n\n0.38\n\n15.1\n0.37\n2.31\n\n11.8\n0.93\n1.57\n\n8.58\n1.79\n1.07\n\n5.90\n3.11\n0.78\n\n4.14\n5.40\n0.68\n\n3.81\n9.65\n0.77\n\n6.33\n17.8\n1.08\n\n16.5\n33.3\n1.70\n\n46.1\n63.0\n2.83\n\n91.6\n114\n4.89\n\n142\n204\n8.84\n\n\f19\n\nOPTIMAL RATES OF CONVERGENCE\nTable 2\nComparison of MSE (in unit of 10\u22125 ) for different n under Setting 2.\nThe tuning parameter \u03b3 is set at 0.2\nn\n\n2000\n\n5000\n\n10,000\n\n15,000\n\n20,000\n\n50,000\n\n100,000\n\n500,000\n\nMSE(\u03b5\u0302\u2217n )\nMSE(\u03bc\u03020 )\nMSE(\u03c3\u030202 )\n\n306.6\n596.6\n74.6\n\n102.6\n143.8\n19.6\n\n43.9\n60.5\n7.1\n\n26.1\n31.7\n3.95\n\n17.7\n19.3\n2.5\n\n4.6\n5.8\n0.6\n\n1.7\n1.9\n0.2\n\n0.2\n0.2\n0.01\n\nTable 2 summarizes the MSE of the estimators under Setting 2. The\nresults show that the accuracy of the estimators improves quickly as n increases.\nWe now move to our third goal and compare the proposed estimator\nfor the proportion with those in the literature, namely Efron's estimator\n\u03b5\u0302E [Efron (2004)] and Storey's estimator \u03b5\u0302S [Storey (2002), Genovese and\nWasserman (2004)], assuming the null distribution is known. To distinguish\nfrom \u03b5\u0302n (\u03b3), we denote the special case of \u03b3 = 0.2 by\n\u03b5\u0302CJ\nn = \u03b5\u0302n (0.2)\nand may drop the subscript n for simplicity. We compare these three estimators with data generated with different proportion \u03b5 (Setting 3a) and\ndifferent heteroscedasticity parameter \u03c3 (Setting 3b).\nSetting 3a. We take \u03bc0 = 0, \u03c30 = 1, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5) and \u03c3 = 1.2. The value of \u03b5 varies from 0.03 to 0.30. The\ngoal is to see how the performance of the three estimators depends on the\nsparsity.\nSetting 3b. We set \u03bc0 = 0, \u03c30 = 1, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5) and \u03b5 = 0.2. The value of \u03c3 varies from 1.2 to 2.1. The goal\nis to study the effect of the nonnull distribution on the estimation accuracy\nof the proportion estimators.\nTable 3 tabulates the MSEs of these three point estimators. It is clear that\nour estimator \u03b5\u0302CJ performs well uniformly in all the cases. In particular it\nis robust under the various settings of nonnull distribution and sparsity.\nTable 3 shows that the MSE of \u03b5\u0302CJ increases gradually from 5.7 \u00d7 10\u22125\nto 10.1 \u00d7 10\u22125 as \u03b5 increases from 0.03 to 0.30. In comparison, the other\ntwo estimators \u03b5\u0302S and \u03b5\u0302E perform well in the sparse case but poorly in the\nnonsparse case. The MSEs of \u03b5\u0302E and \u03b5\u0302S increase about 120 times and 80\ntimes, respectively, and they can sometimes be more than 10 times (some\ntimes even 39 times) larger than the MSE of \u03b5\u0302CJ .\n\n\f20\n\nT. T. CAI AND J. JIN\nTable 3\nComparison of MSE (in unit of 10\u22125 ) of three-point estimators \u03b5\u0302CJ , \u03b5\u0302E and \u03b5\u0302S\nSetting 3a\n\n\u03b5\n\n0.03\n\n0.06\n\n0.09\n\n0.12\n\nMSE(\u03b5\u0302CJ )\nMSE(\u03b5\u0302E )\nMSE(\u03b5\u0302S )\n\n5.7\n3.3\n2.4\n\n7.7\n14.6\n8.9\n\n9.0\n33.4\n19.5\n\n9.9\n60.3\n32.9\n\n\u03c3\n\n1.2\n\n1.3\n\n1.4\n\n1.5\n\nMSE(\u03b5\u0302 ) 67.3\nMSE(\u03b5\u0302E ) 172\nMSE(\u03b5\u0302S )\n89.0\n\n53.7\n164\n81.6\n\n41.8\n153\n72.2\n\n31.7\n146\n67.7\n\n0.15\n9.3\n95.8\n49.9\n\n0.18\n\n0.21\n\n0.24\n\n0.27\n\n0.30\n\n10.3\n139\n72.8\n\n10.0\n190\n99.7\n\n11.2\n249\n130\n\n11.5\n316\n163\n\n10.1\n394\n195\n\n1.6\n\n1.7\n\n1.8\n\n1.9\n\n2.0\n\n2.1\n\n24.0\n138\n61.9\n\n17.6\n129\n55.4\n\n13.2\n122\n50.3\n\n9.4\n114\n46.7\n\n7.0\n108\n43.5\n\n4.8\n100\n41.0\n\nSetting 3b\nCJ\n\nNext, we consider the case where either the assumption on eligibility or\nthe assumption on independence is violated. Consider the eligible assumption first. Denote by DE(\u03bc, \u03c4 ) the double exponential distribution with the\n1 \u2212|x\u2212\u03bc|/\u03c4\ne\n. We shall generate Xi as\ndensity function f (x; \u03bc, \u03c4 ) = 2\u03c4\n\u03b5\n\u03b5\nDE(\u03bc1i , \u03c4 ) + DE(\u03bc2i , \u03c4 ).\n2\n2\nSince the double exponential can be viewed as a scale Gaussian mixture\n[West (1987)], it is seen that the eligible condition does not hold. Two different settings are considered.\n(4.2)\n\nXi \u223c (1 \u2212 \u03b5)N (\u03bc0 , \u03c302 ) +\n\nSetting 4a. We take \u03bc0 = 0, \u03c30 = 1 and assume the null parameters\n\u03bc0 and \u03c30 are known. First generate \u03bc1i from U (\u22120.9, \u22120.1) and \u03bc2i from\nU (0.5, 1.5), then generate Xi as in (4.2) with \u03c4 = 1.2. The proportion \u03b5 varies\nfrom 0.03 to 0.30.\nSetting 4b. We take \u03bc0 = 0, \u03c30 = 1 and assume the null parameters\n\u03bc0 and \u03c30 are unknown. First generate \u03bc1i from U (\u22120.9, \u22120.1) and \u03bc2i from\nU (0.5, 1.5), then generate Xi as in (4.2) with \u03b5 = 0.2. The value of \u03c4 varies\nfrom 1.2 to 2.1.\nTable 4 gives the MSEs in Settings 4a and 4b. In Setting 4a, Efron's\nmethod is often found to be divergent numerically and is thus excluded\nfrom comparison. For small \u03b5, Storey's method and our method yield similar results and both perform well. For moderate to large \u03b5, however, our\nmethod demonstrates great superiority. In Setting 4b, Efron's method is\nagain found to be divergent, and Storey's method does not apply as it requires the information of the null parameters. We therefore exclude both of\n\n\f21\n\nOPTIMAL RATES OF CONVERGENCE\nTable 4\nMSE (in unit of 10\u22124 ) in Settings 4 a and 4 b\nSetting 4a\n\u03b5\n\n0.03\n\n0.06\n\n0.09\n\n0.12\n\n0.15\n\n0.18\n\n0.21\n\n0.24\n\n0.27\n\n0.30\n\nMSE(\u03b5\u0302CJ )\nMSE(\u03b5\u0302S )\n\n8.17\n3.25\n\n7.28\n6.79\n\n6.35\n9.76\n\n5.65\n14.35\n\n4.92\n19.93\n\n4.20\n19.69\n\n3.78\n23.68\n\n3.02\n21.67\n\n2.51\n21.01\n\n2.01\n20.18\n\nSetting 4b\n\u03c4\nMSE(\u03b5\u0302\u2217n )\nMSE(\u03bc\u03020 )\nMSE(\u03c3\u030202 )\n\n1.2\n\n1.3\n\n1.4\n\n1.5\n\n1.6\n\n1.7\n\n1.8\n\n1.9\n\n2.0\n\n2.1\n\n11.9\n0.16\n4.1\n\n10.7\n0.18\n4.1\n\n9.7\n0.19\n4.2\n\n8.7\n0.18\n4.2\n\n7.9\n0.19\n4.0\n\n7.1\n0.19\n3.9\n\n6.5\n0.20\n3.7\n\n5.8\n0.22\n3.6\n\n5.3\n0.23\n3.5\n\n4.8\n0.23\n3.3\n\nthem from comparison. In both settings, despite that the eligible condition\nis violated, our method continues to perform well.\nThe unsatisfactory behavior of Efron's estimator and Storey's estimator\ncan be explained as follows. It is known in the literature that a necessary\ncondition for Efron's estimator or Storey's estimator to be consistent is that\nthe alternative density has a thinner tail than that of the null density either\nto the left or to the right [this is the so-called purity condition; see, e.g.,\nGenovese and Wasserman (2004), Jin and Cai (2006) and Jin (2008)]. In\nSettings 4a and 4b, due to the heavy tail of the double exponential density,\nthe purity condition is violated. It can be shown that asymptotically the bias\nof either Efron's estimator or Storey's estimator has the same magnitude as\nthat of the true proportion. This explains why Efron's method does not\nalways converge, and Storey's method has a reasonable performance when\nthe underlying proportion is small, but behaves increasingly unsatisfactory\nas the proportion gets larger. This also suggests that, when the alternative\ndensity has a heavy tail, relying on the tail area for inference (as that in\nEfron's/Storey's method) can lead to a large bias. A promising alternative\nis the proposed Fourier-based method.\nWe now consider a case where the assumption on independence is violated.\nTo do so, let L be an integer that ranges from 0 to 50 with an increment of 10.\nFor each L, we generate n + L samples w1 , w2 , . . . , wn+L from N (0, 1), then\nPj+L\n1\nlet zj = \u221aL+1\nl=j wl . The samples zj generated in this way are blockwise\ndependent with a block size L (note that L = 0 corresponds the independent\ncase). The setting we consider is as follows, where the null parameters are\nassumed as unknown.\nSetting 4c. Fix \u03b5 = 0.2 and \u03c3 = 1.2. Generate Xi = zi for i = 1, 2, . . . ,\n8000, Xi = \u03bci1 + \u03c3zi for 8001 \u2264 i \u2264 9000, and Xi = \u03bci2 + \u03c3zi for 9001 \u2264 i \u2264\n10,000, where \u03bc1i from U (\u22120.9, \u22120.1) and \u03bc2i from U (0.5, 1.5).\n\n\f22\n\nT. T. CAI AND J. JIN\nTable 5\nMSE (in unit of 10\u22123 ) in Setting 4 c\n\nL\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\nMSE(\u03b5\u0302CJ )\nMSE(\u03bc\u0302CJ\n0 )\nMSE(\u03c3\u03020CJ )\n\n8.8\n10.4\n5.4\n\n10.3\n37.5\n13.5\n\n16.6\n63.8\n23.0\n\n25.2\n94.4\n34.8\n\n34.7\n131.7\n49.3\n\n43.2\n150.0\n52.1\n\nMSE(\u03b5\u0302E )\nMSE(\u03bc\u0302E\n0)\nMSE(\u03c3\u03020E )\n\n34.3\n1.2\n14.7\n\n34.1\n2.8\n18.1\n\n33.5\n4.0\n21.7\n\n33.2\n5.4\n28.1\n\n33.2\n7.0\n34.7\n\n32.3\n8.8\n33.5\n\nTable 5 summarizes the results. In terms of MSE, the estimation accuracy decreases as the range of dependence increases. However, the MSE are\nstill relatively small, especially those correspond to proportion and the null\nvariance parameter \u03c302 . In comparison to Efron's method, correlation has a\nrelatively larger impact on our method. The performance of our estimation\nprocedure is better than Efron's when the correlation is weak to moderate.\nHowever, Efron's method is better when the correlation is strong.\nThe insight lies in the effect of correlation over the bias and variance.\nFor all these estimators, the bias contains mainly marginal effects so the\ncorrelation does not have much effect on it. The correlation, however, may\nhave important effect on the variance [see Jin and Cai (2006) and Jin (2008)].\nIn comparison, despite that our methods have a smaller bias, it gives relative\nlarger MSE because it has a larger variance and is relatively more vulnerable\nwhen the correlation is strong.\nFinally, we investigate how the point estimators affect the results of subsequent multiple testing procedures. First, we use the adaptive p-value based\nprocedure [Benjamini and Hochberg (2000)] to compare the effect of the\nthree point estimators of the proportion in the subsequent multiple testing.\nTo this end, we consider the following two settings (which are the same as\nSetting 3a and 3b, respectively, but we restate them to avoid confusion).\nSetting 5a. We take \u03bc0 = 0, \u03c30 = 1, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5) and \u03c3 = 1.2. The value of \u03b5 varies from 0.03 to 0.30.\nSetting 5b. We set \u03bc0 = 0, \u03c30 = 1, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5) and \u03b5 = 0.2. The value of \u03c3 varies from 1.2 to 2.1.\nIt is known that the original step-up procedure of Benjamini and Hochberg\n(1995) is conservative: it controls the FDR level at (1 \u2212 \u03b5)\u03b1 instead of\nthe nominal level \u03b1. To remedy this shortcoming, Benjamini and Hochberg\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n23\n\n(2000) proposed an adaptive BH procedure which applies the original stepup procedure at level \u03b1\u2032 = \u03b1/(1 \u2212 \u03b5\u0302) instead of \u03b1, where \u03b5\u0302 is an estimate of\n\u03b5. Clearly the true FDR level of the adaptive BH procedure depends on the\nestimation accuracy of \u03b5\u0302.\nWe now compare the actual FDR level of the adaptive BH procedure using\n\u03b5\u0302CJ , \u03b5\u0302S , and \u03b5\u0302E . In addition we also use the deviations of the false discovery\nproportion (FDP) from the nominal FDR level as a measure of the accuracy\nof the testing procedure. The FDP is a notion that is closely related to\nFDR: the FDP is the proportion of false positives among all rejections, and\nthe FDR is the expected value of the FDP; see, for example, Genovese and\nWasserman (2004). The deviations of the FDP from the nominal FDR level\nare naturally summarized by mean squared error. Denote the FDP of the\nadaptive BH procedure with the proportion being estimated by \u03b5\u0302E , \u03b5\u0302S and\n\u03b5\u0302CJ by FDPE , FDPS and FDPCJ .\nFigure 2 compares the actual FDR levels as well as the MSEs of FDPE ,\nFDPS and FDPCJ . The two right panels are the ratios of the MSEs of FDPE ,\nFDPS and FDPCJ to MSE(FDPCJ ). In each of these settings, overall, the\ntrue FDR level of the adaptive BH procedure using \u03b5\u0302CJ is closest to the\nnominal level. The other two estimators, \u03b5\u0302E and \u03b5\u0302S , tend to under-estimate\nthe proportion \u03b5 and consequently yield conservative testing procedure with\nthe true FDR level below the nominal value. The FDP plots indicate that\noverall FDPE has larger deviations from the nominal FDR level in individual\nrealizations than that of FDPS which is itself larger than that of FDPCJ .\nThese results show that our estimator \u03b5\u0302CJ yields the most accurate testing\nprocedure: compared to FDPS and FDPE , FDPCJ is not only smaller in\nbiases, but also smaller in variances.\nNext, we compare again our estimator of the null parameters with that by\nEfron (2004). But this time we do so by investigating the effect of different\npoint estimators over the subsequent multiple testing procedures, namely\nthe adaptiveZ procedure by Sun and Cai (2007). In detail, we consider the\nfollowing setting.\nSetting 5c. We take \u03bc0 = 0, \u03bc1i \u223c Uniform(\u22120.9, \u22120.1), \u03bc2i \u223c\nUniform(0.5, 1.5), \u03b5 = 0.2, and \u03c3 = 1.3. The value of \u03c30 varies from 0.5 to 1.\nIn this setting we estimate both the proportion \u03b5 and the null parameters\n\u03bc0 and \u03c30 .\nWe now compare the performance of our estimators of the proportion and\nthe null parameters with those of Efron (2004). [Storey (2002) assumed a\nknown null distribution and did not provided estimators for the null parameters, so we exclude it from the comparison.] We compare the performance\nof these estimators as measured by the accuracy of the actual FDR level\nof the adaptive testing procedure introduced in Sun and Cai (2007). The\n\n\f24\n\nT. T. CAI AND J. JIN\n\nAdaptZ procedure given in Sun and Cai (2007) aims to minimize the false\nnondiscovery rate subject to the constraint that the FDR level is controlled\nat a pre-specified level. This procedure thresholds the ordered Lfdr statistic\nd i ) = (1 \u2212 \u03b5\u0302)f \u0303null (zi )/f \u0303(zi ),\nLfdr(z\n\nwhere f \u0303null and f \u0303 are estimators of f null and f , respectively. The marginal\ndensity f is estimated by a kernel density estimator with bandwidth chosen\nby cross-validation.\nFigure 3 plots the true FDR levels of the AdaptZ procedure using our estimators of \u03b5 and f \u0303null with those of the same procedure using the estimators of\n\u03b5 and f \u0303null given in Efron (2004). Figure 3 also displays the ratio of the MSEs\nof the FDP of the two testing procedures, MSE(FDPE )/MSE(FDPCJ ). The\n\nFig. 2. The actual FDR levels (left panels) and the MSEs of the FDP (right panels) of\nthe adaptive BH procedure using the proportion estimators \u03b5\u0302E (\u25e6 line), \u03b5\u0302S (\u25b3 line) and\n\u03b5\u0302CJ (+ line). The nominal level is 0.10. Top row: Setting 5 a. The horizontal axis is the\nproportion \u03b5. Bottom row: Setting 5 b. The horizontal axis is the parameter \u03c3.\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n25\n\nFig. 3. The actual FDR levels (left panel) and the relative MSEs of the FDP (right\npanel) of the AdaptZ procedure using the estimated null parameters and proportion: Efron's\nestimators (\u25e6 line) and our estimators (\u25b3 line). The nominal FDR level is 0.10 and the\nhorizontal axis is the parameter \u03c30 .\n\nresults clearly show that the true FDR level of the testing procedure with\nour estimator is much closer to the nominal level than that with the estimators given in Efron (2004) and the FDP has smaller deviations from the\nnominal FDR level. Indeed, the MSE(FDPCJ ) can sometimes be 15 times\nsmaller than MSE(FDPE ) [see Panel (b)].\nWe conclude this section by mentioning that the proposed estimators\nusually yield a more accurate point estimation for the proportion and the\nnull parameters than those by Efron (2004) and Storey (2002), not only\nasymptotically, but also for finite n. The accuracy of the proportion and the\nnull parameters directly affects the performance of the subsequent testing\nprocedures. Our estimators yield more accurate testing results than those\nby in Efron (2004) and Storey (2002).\n5. Discussion. We derived the optimal rates of convergence for estimating the null parameters and the proportion of nonnull effects in large-scale\nmultiple testing using a Gaussian mixture model. It was shown that the\nconvergence rates depend on the smoothness of the mixing density h(u|\u03c3).\nThe empirical characteristic function and Fourier analysis are crucial tools\nin our analysis of the optimality results. The proposed estimators not only\nare asymptotically rate-optimal but also enjoy superior finite n performance.\n\n\f26\n\nT. T. CAI AND J. JIN\n\nBoth theoretical and numerical results show that these estimators outperform the commonly used estimators in the literature. The improvement in\nthe parameter estimation leads directly to more precise results in the subsequent multiple testing.\nThe minimax rates of convergence are proportional to the square of the\ntrue proportion multiplied by some logarithmic factors. The slowly convergent logarithmic factors can be attributed to the super-smooth nature of\nthe Gaussian density, which attributes to the thin-tailed behavior of the\ncorresponding characteristic function. As a result, even a relatively large\nperturbation in the true null parameters or in the true proportion may only\nresult in a small difference in the L2 -norm of the characteristic function,\nwhich makes the perturbation hard to detect. The logarithmic terms are\nreminiscent of that found in the study of the conventional nonparametric\ndeconvolution with Gaussian errors [e.g., Zhang (1990) and Fan (1991)],\nwhere the culprit for the slow convergence is also the super-smoothness of\nthe Gaussian density. However, we should note that the problem considered\nhere is different from the deconvolution problem; this explains the difference\nin the rate of minimax risk, the need for new procedures and the need for\nnew approaches to derive the minimax risk bounds.\nThe work presented in this paper can be extended in several directions.\nFirst, while we have focused on the case where the characteristic function\nof h decays at a polynomial rate, the results can be conveniently extended\nto the case where it has an exponential tail. Consider, for example, the\nfollowing case:\n|\u0125(t)| \u2264 C exp(\u2212|t|\u03b1 ).\nThe bias of the proposed estimator for the null parameters (and that for the\nproportion is similar) is of the order of\nexp(\u2212C log\u03b1/2 (n)).\nWhen 0 < \u03b1 < 2, the bias is still larger than the variance and the rate of\nconvergence is basically\nexp(\u2212C log\u03b1/2 (n)). When \u03b1 > 2, the bias tends to\n\u221a\n0 faster than 1/ n. In this case, the variance dominates the MSE, and we\nhave O(1/n) convergence rate. Second, while we focus on the case where\nXj are independent, extensions to the case of weak dependence is possible. Jin and Cai (2007) considered two dependent structures: the strongly\n\u03b1-mixing case and the short-range dependent case and showed that the estimators constructed in that paper continue to be uniformly consistent under\nthese dependent settings; see details therein. We expect that some of the results given in this paper are also extendable to the weakly dependent case.\nThird, while we focus on Gaussian mixtures in this paper, extensions to\nnon-Gaussian mixtures is possible; see Jin (2008) for more discussion. An\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n27\n\ninteresting example along this line is to replace the Gaussian mixture by\nthe Laplace mixture. Due to the singularity of the Laplace density around\nthe origin, the associated characteristic function decays much slower than\nthat of the Gaussian density. As a result, the minimax risks for estimating\nthe null parameters and the proportion are expected to have faster rates\nof convergence than those presented here. Last, while we focus on squared\nerror loss here, the results can be extended to general loss functions.\nWe conclude this section by mentioning some possible future research\ndirections. First, two key assumptions we make in this paper are the Gaussian mixture structure of the marginal density of the z-scores, and the independence among different z-scores. An interesting direction is to study\nthe extend to which the presented results continue to hold when these assumptions are violated. An equally interesting direction is to study how\nto normalize/pre-process the data such that the assumptions hold approximately. Given the considerable efforts on normalization and pre-processing\nby the gene microarray community in recent years, the research along this\ndirection could be very fruitful. Second, it would also be interesting to develop an adaptive approach to select the tuning parameter \u03b3 in our proposed\nprocedure. Given the overwhelming practical interest in large-scale multiple\ntesting, this is an interesting problem for further study.\n6. Proof of the main results. In this section, we prove the main results:\nTheorems 2.1, 2.2 and 3.2.\n6.1. Proof of Theorem 2.1. The proofs of the minimax lower bounds for\nestimating the null parameters \u03c302 and u0 are similar. We present a detailed\nproof for the first claim and only a brief outline for the second one.\nConsider the first claim. The key is to flesh out the ideas sketched in\nSection 2.1. We begin by filling in the details of the construction of w1 and\nw2 . Let k be the smallest even number that is greater than 2q + 1, let\n\uf8f1\n\uf8f2 (\u22121)k/2 \u03c0 k\u22121\n|t| ,\n0 \u2264 t \u2264 1,\n\u03be(t) =\n(k \u2212 1)!\n\uf8f3 \u2212\u03b1\n|t| ,\nt > 1,\n\nand let s1 and s2 be two symmetric smooth functions, where s1 satisfies\n(1). 0 \u2264 s1 (t) \u2264 1, (2). s1 (t) = 1 when |t \u2212 1| > 2/3, and (3). s1 (t) = 0 when\n|t \u2212 1| < 1/3, and s2 satisfies (1). 0 \u2264 s2 (t) \u2264 1, (2). s2 (t) = 1 when 0 < |t| <\n\u03c4n + 1/3, and (3). s2 (t) = 0 when |t| > \u03c4n + 2/3. The existence of such smooth\nfunction is well known in the literature; see Erdelyi (1956), for example. We\nconstruct w1 and w2 through their characteristic functions by\n(6.1)\n\n\u01751 (t) = s1 (t)\u03be(t)\n\n\f28\n\nT. T. CAI AND J. JIN\n\nand\n(6.2)\n\n\u0012\n\n\u03b4n t2 /2\n\n\u01752 (t) = s2 (t) * e\n\n\u01751 (t) +\n\n\u0012\n\n\u0013\n\u0013\n1 1 \u2212 \u03b7n\n\u03b4n t2 /2\n[e\n\u2212 1] ;\n\u03b80 \u03b7n\n\nsee Figure 1 for illustrations.\nNow, to show the claim, it remains to show (a) h1 and h2 are indeed\ndensities, (b) the \u03c72 -distance between f1 and f2 is equal to o(1/n) and (c)\nthe densities f1 and f2 in (2.9) and (2.10) satisfy the constraints (2.2) and\n(2.3) and therefore live in F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n). To do so, we need some\nlemmas.\nLet g be the Gaussian mixing density\n\u0012\n\u0013\nZ\nx\u2212u\n1\n\u03c6\ng(x) = g(x; w1 , a) =\nw1 (u).\na\na\nBy the way f1 is defined in [see (2.9)], it is not hard to see that\nf1 (x) = (1 \u2212 \u03b7n )\u03c6a (x) + \u03b7n \u03c6\u221aa2 +1 (x) + \u03b80 \u03b7n g(x),\n\n(6.3)\n\nwhere \u03c6a denotes the density of N (0, a2 ). The following lemma characterizes\nthe tail behavior of w1 , and so that of g and f1 .\nLemma 6.1. For large |u|, w1 (u) \u223c |u|\u2212k . As a result, for sufficiently\nsmall \u03b80 > 0, there is a constant C > 0,\n|g(x)| \u2264 C(1 + |x|)\u2212k ,\n\n(6.4)\n\nf1 (x) \u2265 C\u03b7n (1 + |x|)\u2212k .\n\nHere, C > 0 is a generic constant which only depends on (some or all) the\nparameters \u03b1, \u03b2, \u03b50 , q, a, A, k, \u03b80 and \u03b80 . The same rule applies below.\nNext, the following lemma elaborates the tail behavior of w2 .\nLemma 6.2.\nsuch that\n\nFor sufficiently large |u| and n, there is a constant C > 0\n||u|k w2 (u) \u2212 1| \u2264 C/|u|.\n\n(6.5)\n\nLast, the following lemma describes how close f1 and f2 are in the frequency domain.\nLemma 6.3. When 0 \u2264 |t| \u2264 \u03c4n , f\u02c61 (t) = f\u02c62 (t). When |t| > \u03c4n , there is a\nconstant C > 0 such that for sufficiently large n,\n(m)\n\n|f\u02c61\n\n2 2\n(m)\n(t) \u2212 f\u02c62 (t)| \u2264 C|t|m e\u2212a t /2 ,\n\nm = 0, 1, . . . , k/2.\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n29\n\nLemmas 6.1\u20136.3 are proved in the Appendix.\nWe are now ready to prove (a)\u2013(c). Consider (a) first. By Lemmas 6.1\nand 6.2, both w1 and w2 are positive for sufficiently large |u|. Therefore, (a)\nholds once we take \u03b80 sufficiently small.\nR\nConsider (b) next. Recall that the \u03c72 -distance is d(f1 , f2 ) = [(f1 (x) \u2212\nf1 (x))2 /f1 (x)] dx. By (6.4) in Lemma 6.1,\nZ\nZ\n|f2 (x) \u2212 f1 (x)|2\n\u22121\ndx \u2264 C\u03b7n\n(1 + |x|)k |f2 (x) \u2212 f1 (x)|2 dx\nf1 (x)\n(6.6)\n\u2264 Cn\u03b2 (I + II),\nR\nR\nwhere I = |f2 (x) \u2212 f1 (x)|2 dx and II = |x|k (f2 (x) \u2212 f1 (x))2 dx. Now, by\nParseval's formula [Mallat (1998)], for any integers 0 \u2264 m \u2264 k/2,\nZ\nZ\nx2m |f2 (x) \u2212 f1 (x)|2 dx = |xm f2 (x) \u2212 xm f1 (x)|2 dx\n(6.7)\n\n=\n\nZ\n\n(m)\n\n|f\u02c62\n\n(m)\n(t) \u2212 f\u02c61 (t)|2 dt,\n\nwhere by Lemma 6.3, the last term satisfies that\nZ\nZ\n2 2\n2m\n2\n(6.8)\n|t|m e\u2212a t /2 dt.\nx |f2 (x) \u2212 f1 (x)| dx \u2264 C\n|t|>\u03c4n\n\nNow, applying (6.8) to the case of m = 0 and m = l gives\nZ\n2 2\n2 2\n(6.9)\n(1 + |t|k/2 )e\u2212a t /2 dt \u2264 C\u03c4nk/2\u22121 e\u2212a \u03c4n /2\nI + II \u2264 C\n|t|>\u03c4n\n\n\u221a\nand (b) follows by that \u03b2 < 1/2 and that a\u03c4n = 3 log n.\nLast, we show (c). It is sufficient to check both f1 and f2 satisfy (2.2)\nand (2.3). Consider f1 first. Recall that Mq is the qth moment of N (0, 1),\ncombining (6.3) and (6.4) gives\nZ\n|x|q f (x) dx \u2264 [(1 \u2212 \u03b7n )aq + \u03b7n (a2 + 1)q/2 ]Mq + C\u03b80 \u03b7n\n\n\u2264 (a2 + 1)q/2 Mq + C\u03b80 \u03b50 .\n\u221a\n1/q\nTherefore, by the assumption of A > a2 + 1Mq , (2.2) is satisfied once\n2\nwe take \u03b80 sufficiently small. At the same time, recall that \u01251 (t) = e\u2212t /2 +\n\u03b80 \u01751 (t) and that \u01751 (t) = |t|\u2212\u03b1 when |t| \u2265 4/3, so (2.3) is also satisfied.\nConsider f2 next. By Lemma 6.1 and the choice of k, the 2q-moment of f1\nis finite. Using H\u00f6lder's inequality and (b),\n\u00131/2\n\u0012Z\n\u00131/2 \u0012Z\nZ\n(f1 (x) \u2212 f2 (x))2\nq\n2q\ndx\n|x| |f1 (x) \u2212 f2 (x)| dx \u2264\n|x| f1 (x) dx\nf1 (x)\n\u221a\n= o(1/ n).\n\n\f30\n\nT. T. CAI AND J. JIN\n\nR\nR\n\u221a\nNow, by the triangle inequality, |x|q f2 (x) dx \u2264 |x|q f1 (x) + o(1/ n), so\nf2 satisfies the moment constraint in (2.2). At the same time, recall that\n2\n\u01252 (t) = e\u2212(1\u2212\u03b4n )t /2 + \u03b80 w\u02c62 (t) and that\n(\n1 1 \u2212 \u03b7n \u03b4n t2 /2\n2\ne\u03b4n t /2 \u01751 (t) +\n[e\n\u2212 1],\n|t| \u2264 \u03c4n ,\n\u01752 (t) =\n\u03b80 \u03b7n\n0,\n|t| \u2265 \u03c4n + 1.\n\nBy elementary calculus and the choice of \u03c4n and \u03b4n , there is a constant C > 0\nsuch that for sufficiently large n and |t| > 4/3,\n|\u01752 (t) \u2212 \u01751 (t)| \u2264 C\u03b80 \u03c4n\u2212(\u03b1+2) t2 \u2264 C\u03b80 |t|\u2212\u03b1 ,\n\n|\u01752\u2032 (t) \u2212 \u01751\u2032 (t)| \u2264 C\u03b80 \u03c4n\u2212(\u03b1+2) t \u2264 C\u03b80 |t|\u2212(\u03b1+1) ,\n\nwhere we have used w1 (t) = |t|\u2212\u03b1 for |t| \u2265 4/3. Combining these we conclude\nthat for a sufficiently small \u03b80 , h2 satisfies (2.3). This concludes the proof of\n(c) and the first claim of Theorem 2.1.\nWe now consider the second claim of Theorem 2.1. Similarly, the goal is\nto construct two density functions (say f3 and f4 ) in F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n)\nsuch that the null mean parameter u0 associated with them differ by a small\namount, and their \u03c72 -distance is equal to o(1/n). Let \u03c4n , s2 , and w1 be the\nsame as in the proof associated with \u03c302 , and let \u03b80 > 0 be a constant to be\ndetermined. Define\n\u03b4n = \u03b80 \u03b80 \u03b7n \u03c4n\u2212(\u03b1+1) ,\n\n(6.10)\n\nw3 = w1\n\nand define w4 through its characteristic function by\n\u0012\n\u0013\u0013\n\u0012\n\u03b4n t\n2i 1 \u2212 \u03b7n\nsin\n.\n\u01754 (t) = s2 (t) * \u01753 (t) \u2212\n\u03b80 \u03b7n\n2\nWe construct\n\n2 /2\n\n\u01253 (t) = ei\u03b4n t/2 [e\u2212t\n\n+ \u03b80 * \u01753 (t)],\n\n2 /2\n\n\u01254 (t) = e\u2212i\u03b4n t/2 [e\u2212t\n\n+ \u03b80 * \u01754 (t)],\n\nand\n\n\u0012 \u0013\n\u0012\n\u0013\nZ\nx\nx\u2212u\n1\n1\n\u03c6\n(6.11) f3 (x) = (1 \u2212 \u03b7n ) \u03c6\n+ \u03b7n\nh3 (u) du,\na\na\na\na\n\u0012\n\u0012\n\u0013\n\u0013\nZ\n1\nx \u2212 \u03b4n\nx \u2212 \u03b4n \u2212 u\n1\n\u03c6\n(6.12) f4 (x) = (1 \u2212 \u03b7n ) \u03c6\n+ \u03b7n\nh4 (u) du.\na\na\na\na\n\nNote that the null parameters associated with f3 and f4 differ by an amount\nof \u03b4n . We are able to show that for appropriately small constants \u03b80 > 0 and\n\u03b80 > 0, h3 and h4 are indeed densities, and f3 and f4 live in F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n).\nAlso, the \u03c72 -distance between f3 and f4 is equal to o(1/n). As the proofs\nare similar to that associated with \u03c302 , we skip them for reasons of space.\n\n\f31\n\nOPTIMAL RATES OF CONVERGENCE\n\n6.2. Proof of Theorem 2.2. Since the proofs are similar, we only prove\nthe first claim. The following lemmas are proved in the Appendix.\nLemma 6.4. Fix q \u2265 4 and \u03b3 \u2208 (0, 1/2). For sufficiently large n, and any\nevent Bn with P {Bnc } \u2264 C/n, E[\u03c302 (\u03c6n , t\u0302n (\u03b3)) \u2212 \u03c302 )2 * 1{Bnc } ] \u2264 Cn2\u03b3\u22121 .\nLemma 6.5.\n\nFix q \u2265 4 and \u03b3 \u2208 (0, 1/2). For sufficiently large n,\nE[\u03c6\u2032n (t\u0302n (\u03b3)) \u2212 \u03c6\u2032 (t\u0302(\u03b3))]2 \u2264 C log(n)/n.\n\nWe now proceed to show the theorem. Fix q1 > 3, introduce the event\n( n\n1X\nD0 =\n|Xj | \u2264 m1 + 1,\nn\nj=1\n(6.13)\n)\nn\np\n\u221a\n1X 2\nXj \u2264 m2 + 1, W0 (\u03c6n ; n) \u2264 2q1 log n/ n ,\nn\nj=1\n\nwhere m1 and m2 are the first two moments of X1 and\nW0 (\u03c6n ; n) = W0 (\u03c6n ; n, X1 , X2 , . . . , Xn ) =\n\nsup\n{0\u2264t\u2264log n}\n\n|\u03c6n (t) \u2212 \u03c6(t)|.\n\nNote that, first, by Chebyshev's inequality,\n)\n( n\n)\n( n\n1X 2\n1X\n|Xj | > m1 + 1 \u2264 C/n,\nP\nXj > m2 + 1 \u2264 C/n.\nP\nn\nn\nj=1\n\nj=1\n\nSecond, by Lemma A.2 of Jin and Cai (2007),\np\n\u221a\nP {W0 (\u03c6n ; n) > 2q1 log n/ n} . 4 log2 (n)n\u2212q1 /3 .\n\nRecall that q1 > 3, it thus follows that P {Dnc } \u2264 C/n. By Lemma 6.4, Dnc\nonly has a negligible contribution to the mean squared errors:\n(6.14)\n\nE[(\u03c302 (\u03c6n , t\u0302n (\u03b3)) \u2212 \u03c302 )2 * 1{D0c } ] \u2264 Cn2\u03b3\u22121\n\nand all remains to show is\n(6.15)\n\nE[(\u03c302 (\u03c6n , t\u0302n (\u03b3)) \u2212 \u03c302 )2 * 1{D0 } ]\n\u2264 C[n\u22122\u03b2 log\u2212(\u03b1+2) (n) + log(n)n2\u03b3\u22121 ].\n\nWe now show (6.15). Write for short t\u0302n = t\u0302n (\u03b3) and tn = tn (\u03b3). By the\ntriangle inequality,\n|\u03c302 (\u03c6n , t\u0302n ) \u2212 \u03c302 | \u2264 |\u03c302 (\u03c6n , t\u0302n ) \u2212 \u03c302 (\u03c6, t\u0302n )| + |\u03c302 (\u03c6, t\u0302n ) \u2212 \u03c302 (\u03c6, tn )|\n+ |\u03c302 (\u03c6, tn ) \u2212 \u03c302 |.\n\n\f32\n\nT. T. CAI AND J. JIN\n\nSo to show (6.15), all we need to show are\n(6.16)\n(6.17)\n\nE[(\u03c302 (\u03c6n , t\u0302n ) \u2212 \u03c302 (\u03c6, t\u0302n ))2 * 1{D0 } ] \u2264 C log(n)n2\u03b3\u22121 ,\nE[(\u03c302 (\u03c6, t\u0302n ) \u2212 \u03c302 (\u03c6, tn ))2 * 1{D0 } ] \u2264 Cn2\u03b3\u22121\n\nand\n(6.18)\n\n|\u03c302 (\u03c6, tn ) \u2212 \u03c302 | \u2264 Cn\u2212\u03b2 log\u2212(\u03b1+2)/2 (n)\n\nover D0 .\n\nBelow, we show (6.16)\u2013(6.18) separately.\nConsider (6.16) first. By Lemmas A.2 and A.3 of Jin and Cai (2007), over\nthe event D0 ,\np\n\u221a\n(6.19) |\u03c6n (t\u0302n ) \u2212 \u03c6(t\u0302n )| \u2264 C log n/ n,\n|t\u0302n \u2212 tn | \u2264 c0 n\u03b3\u22121/2 ,\np\nwhere c0 > \u03c30 q1 /\u03b3 is a constant. Apply Lemma 6.1 of Jin and Cai (2006)\nwith f = \u03c6n , g = \u03c6, and t = t\u0302n ,\n(6.20)\n\n|\u03c302 (\u03c6n , t\u0302n ) \u2212 \u03c302 (\u03c6, t\u0302n )|\n\u0014\n\u0015\n1 \u2032\n\u03b3\n2\n\u2032\n. n 3\u03c30 |\u03c6n (t\u0302n ) \u2212 \u03c6(t\u0302n )| + |\u03c6n (t\u0302n ) \u2212 \u03c6 (t\u0302n )| .\nt\u0302n\n\nCombining (6.19) and (6.20) gives that, over the event D0 ,\n\u0014\u221a\n\u0015\nlog n\n1 \u2032\n2\n2\n\u03b3\n\u2032\n\u221a\n|\u03c30 (\u03c6n , t\u0302n ) \u2212 \u03c30 (\u03c6, t\u0302n )| \u2264 Cn\n+ |\u03c6n (t\u0302n ) \u2212 \u03c6 (t\u0302n )|\nn\ntn\nand applying the Lemma 6.5 gives (6.16).\nd 2\nConsider (6.17) next. Direct calculations show that | dt\n\u03c30 (\u03c6, t)| \u2264 C for\nsufficiently large t. Using the second part of (6.19),\n(6.21)\n\n|\u03c302 (\u03c6, t\u0302n ) \u2212 \u03c302 (\u03c6, tn )| \u2264 C|t\u0302n \u2212 tn | \u2264 Cn\u03b3\u22121/2\n\nover D0 ,\n\nand (6.17) follows directly.\nLast, we consider (6.18). Similar to Lemma 6.5 of Jin and Cai (2007),\nR\n\u2032\n2\n2 2\n|\u03c302 (\u03c6, tn ) \u2212 \u03c302 | \u2264 C |\u03c8 t(tnn )| , where \u03c8(t) = \u03b5n eit(u\u2212u0 )\u2212(\u03c3 \u2212\u03c30 )t /2 \u00d7\nh(u|\u03c3) dH(\u03c3). By direct calculations,\nZ\n2\n2 2\n\u2032\n|\u03c8 (t)| = \u03b5n (i(u \u2212 u0 ) \u2212 (\u03c3 2 \u2212 \u03c302 )t)eit(u\u2212u0 )\u2212(\u03c3 \u2212\u03c30 )t /2 h(u|\u03c3) dH(\u03c3)\n\u2264 I + II,\n\nwhere\nI = \u03b5n\n\nZ\n\n(u \u2212 u0 )eit(u\u2212u0 )\u2212(\u03c3\n\n2 \u2212\u03c3 2 )t2 /2\n0\n\nh(u|\u03c3) dH(\u03c3)\n\n\f33\n\nOPTIMAL RATES OF CONVERGENCE\n\nand\nII = \u03b5n\n\nZ\n\n(\u03c3 2 \u2212 \u03c302 )teit(u\u2212u0 )\u2212(\u03c3\n\n2 \u2212\u03c3 2 )t2 /2\n0\n\nh(u|\u03c3) dH(\u03c3) .\n\nBy elementary Fourier analysis and the definition of \u0125(t|\u03c3) and h\u0303(t|\u03c3) [see\n(2.4)],\nZ\nZ\n2\n2 2\nI = \u03b5n\nh\u0303\u2032 (t|\u03c3)e\u2212(\u03c3 \u2212\u03c30 )t /2 dH(\u03c3) \u2264 \u03b5n |h\u0303\u2032 (t|\u03c3)| dH(\u03c3)\nand\nII \u2264 \u03b5n\n\nZ\n\n\u0125(t|\u03c3)(\u03c3\n\n2\n2 2\n\u2212 \u03c302 )te\u2212(\u03c3 \u2212\u03c30 )t /2 dH(\u03c3)\n\n2\n\n\u2264 C(\u03b5n /t)\n\nZ\n\n|\u0125(t|\u03c3)| dH(\u03c3),\n\n2\n\nwhere we have used the fact that supa\u22650 {ate\u2212at /2 } \u2264 C/t. Combining these\nwith (2.3) and (2.5) gives (6.18). This concludes the proof of Theorem 2.2.\n6.3. Proof of Theorem 3.2. Consider the first claim first. Similar to the\nconstruction of the minimax lower bound for estimating the null parameter \u03c302 , the goal is to construct two density functions (say f5 and f6 ) in\nF0 (\u03b1, \u03b2, \u03b50 , q, a, A; n) such that the proportion associated with them differ\nby a small amount, and their \u03c72 -distance is equal to o(1/n).\nWe construct f5 and f6 as follows. Let \u03c4n , w1 , and s2 be the same as in\nSection 6.1. Similarly, for a constant \u03b80 > 0 to be determined, let\n\u03b4n = \u03b80 \u03b80 \u03b7n \u03c4n\u2212\u03b1 ,\n\n(6.22)\n\nw5 \u2261 w1\nand\n\u01756 (t) = s2 (t) *\n\n\u0012\n\n\u0013\n\u03b7n \u2212 \u03b4n\n1 \u03b4n\n\u2212t2 /2\n\u01755 (t) +\n(1 \u2212 e\n) .\n\u03b7n\n\u03b80 \u03b7n\n\nWe define h5 and h6 as\n2 /2\n\n\u01255 (t) = e\u2212t\n\n+ \u03b80 * \u01755 (t),\n\n2 /2\n\n\u01256 (t) = e\u2212t\n\n+ \u03b80 * \u01756 (t),\n\nand\n\n\u0012 \u0013\n\u0012\n\u0013\nZ\nx\nx\u2212u\n1\n1\n\u03c6\n(6.23) f5 (x) = (1 \u2212 \u03b7n + \u03b4n ) \u03c6\n+ (\u03b7n \u2212 \u03b4n )\nh5 (u) du,\na\na\na\na\n\u0012 \u0013\n\u0012\n\u0013\nZ\n1\nx\nx\u2212u\n1\n\u03c6\n(6.24) f6 (x) = (1 \u2212 \u03b7n ) \u03c6\n+ \u03b7n\nh6 (u) du.\na\na\na\na\nNote that the proportion associated with f5 and f6 differ by an amount of \u03b4n .\nWe are able to show that for appropriately small constants \u03b80 > 0 and \u03b80 > 0,\n\n\f34\n\nT. T. CAI AND J. JIN\n\nh5 and h6 are indeed densities, and f5 and f6 live in F0 (\u03b1, \u03b2, \u03b50 , q, a, A; n).\nAlso, the \u03c72 -distance between f5 and f6 is equal to o(1/n). As the proofs\nare similar to the case for \u03c302 , we skip them for reasons of space.\nWe now consider the second claim. Write for short \u03b5\u0302\u2217n = \u03b5\u0302\u2217n (\u03b3), \u03c3\u030202 = \u03c302 (\u03b3),\nand \u00fb0 = \u00fb0 (\u03b3), introduce the nonstochastic counterparts of \u03c3\u030202 and \u00fb0 , respectively, by\n\u03c3\u030402 = \u03c30 (\u03c6, tn ),\n\n\u016b0 = u0 (\u03c6, tn ),\n\nwhere tn is defined in (2.23). The following lemma is a direct result of Theorem 1 of Jin and Cai (2007), which elaborates the stochastic fluctuation of\n\u03c3\u030202 and \u00fb0 .\nLemma 6.6. Let \u03b3 \u2208 (0, 1/2) and q > 4 + 2\u03b3 be as in the theorem. There\nis an event Bn such that P {Bnc } = o(1/n) and over the event Bn ,\n(6.25)\n\n|\u03c3\u030202 \u2212 \u03c3\u030402 | \u2264 C log1/2 (n)n\u03b3\u22121/2 ,\n\n|\u00fb0 \u2212 \u016b0 | \u2264 C log(n)n\u03b3\u22121/2 .\n\nNow, by replacing \u00fb0 with \u016b0 in the definition of \u03b5\u0302\u2217n , we introduce the\nfollowing pseudo-estimator:\n\u0013\n\u0012\nn\nX\np\nXj \u2212 \u016b0\n\u03b3\u22121\n2\u03b3 log n\n(6.26) \u03b5\u0303n = \u03b5\u0303n (\u03b3, X1 , . . . , Xn , \u016b0 ) = 1 \u2212 n\n.\ncos\n\u03c3\u03020\nj=1\n\nThe pseudo-estimator plays a key role in the proof. To see the point, we need\nsome notation. Let \u03c6\u0303n be the empirical characteristic function corresponding\nto (Xj \u2212 \u016b0 )/\u03c3\u03040 ,\nn\n\n(6.27)\n\n1 X it(Xj \u2212\u016b0 )/\u03c3\u03040\ne\n,\n\u03c6\u0303n (t) = \u03c6\u0303n (t; X1 , . . . , Xn ; \u016b0 , \u03c3\u03040 ) =\nn\nj=1\n\nlet \u03c6\u0303(t) be the corresponding (underlying) characteristic function\n\u03c6\u0303(t) = \u03c6\u0303(t; f, \u016b0 , \u03c3\u03040 ) \u2261 E[\u03c6\u0303n (t)]\n\nR\nand denote the real part of \u03c6\u0303n and \u03c6\u0303 by \u03c6\u0303R\nn and \u03c6\u0303 , respectively. Observe\nthat if we denote\n\u03c3\u03040 p\nt\u0303n = t\u0303n (\u03b3; \u03c3\u03020 , \u03c3\u03040 ) =\n(6.28)\n2\u03b3 log n,\n\u03c3\u03020\n\nthen \u03b5\u0303n can be rewritten as\n(6.29)\n\n\u03b5\u0303n = 1 \u2212 n\u03b3 \u03c6\u0303R\nn (t\u0303n ).\n\nThe advantage of introducing \u03b5\u0303n is two-fold. First, by elementary trigonometrics, the difference between \u03b5\u0302\u2217n and \u03b5\u0303 has a very simple form. This is the\nfollowing lemma, whose proof is elementary so we omit it.\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n35\n\nLemma 6.7.\n\n\u0013\n\u0012\n\u0013\u0015\u0013\n\u0012\n\u0014\n\u0012\n\u016b0 \u2212 \u00fb0\nt\u0303n \u016b0 \u2212 \u00fb0\n\u2212 i sin t\u0303n\n.\n\u03b5\u0302\u2217n \u2212 \u03b5\u0303n = n\u03b3 Re \u03c6\u0303n (t\u0303n ) * sin2\n2\n\u03c3\u03040\n\u03c3\u03040\n\nSecond, the stochastic fluctuation of \u03b5\u0303n can be conveniently bounded\nthrough the maximum deviation of \u03c6\u0303n (t) over the interval, say, [0, log(n)].\nIn detail, fix a constant q1 > 3, introduce the following event:\nn\np\n\u221a o\nD\u03030 =\nsup {|\u03c6\u0303n (t) \u2212 \u03c6\u0303(t)|} \u2264 2q1 log n/ n .\n{0\u2264t\u2264log n}\n\nThe following lemma can be proved similarly as that of Lemma A.2 in Jin\nand Cai (2007), so we omit it.\nLemma 6.8.\n\nP {D\u03030c } . 4 log2 (n)n\u2212q1 /3 .\n\nA direct consequence of Lemma 6.8 is that\nh\ni\nE|\u03c6\u0303n (t\u0303n ) \u2212 \u03c6\u0303(t\u0303n )|2 \u2264 E\nsup {|\u03c6\u0303n (t) \u2212 \u03c6\u0303(t)|2 } + o(1/n)\n{0\u2264t\u2264log n}\n\n(6.30)\n\n\u2264 C log(n)/n.\nR\nGiven the lemmas\n\u221a above, what remains to analyze is \u03c6\u0303 (t\u0303n ). Note that t\u0303n\nfluctuates around 2\u03b3 log n. We have the following lemma, which is proved\nin the Appendix.\n\nLet Bn be the event as in Lemma 6.6. We have\np\nover Bn\n|\u03c6\u0303R (t\u0303n ) \u2212 \u03c6\u0303R ( 2\u03b3 log n)| \u2264 C log3/2 (n)n\u22121/2\n\nLemma 6.9.\n\nand\n\n|(1 \u2212 \u03b5n ) \u2212 n\u03b3 \u03c6\u0303R (\n\np\n\n2\u03b3 log n)| \u2264 C log\u2212\u03b1/2 (n)n\u2212\u03b2 .\n\nWe are now ready to show the theorem. By the triangle inequality and\nthe Cauchy\u2013Schwarz inequality,\n|\u03b5\u0302\u2217n \u2212 \u03b5n |2\n(6.31)\n\n\u2264 (|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n | + |\u03b5\u0303n \u2212 (1 \u2212 n\u03b3 \u03c6\u0303R (t\u0303n ))| + |(1 \u2212 n\u03b3 \u03c6\u0303R (t\u0303n )) \u2212 \u03b5n |)2\n\n\u2264 C(|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 + |\u03b5\u0303n \u2212 (1 \u2212 \u03c6\u0303R (t\u0303n ))|2 + |(1 \u2212 n\u03b3 \u03c6\u0303R (t\u0303n )) \u2212 \u03b5n |2 ).\n\nFirst, by (6.29) and (6.30),\nR\n2\n2\u03b3\u22121\n(6.32) E|\u03b5\u0303n \u2212 (1 \u2212 n\u03b3 \u03c6\u0303R (t\u0303n ))|2 = n2\u03b3 E|\u03c6\u0303R\n.\nn (t\u0303n ) \u2212 \u03c6\u0303 (t\u0303n )| \u2264 C log(n)n\n\n\f36\n\nT. T. CAI AND J. JIN\n\nSecond, by Lemma 6.9 and the Cauchy\u2013Schwarz inequality,\n(6.33)\n\nE|(1 \u2212 \u03b5n ) \u2212 n\u03b3 \u03c6\u0303R (t\u0303n )|2 \u2264 C[log\u2212\u03b1/2 (n)n\u2212\u03b2 + log3/2 (n)n\u03b3\u22121/2 ]2\n\u2264 C[log\u2212\u03b1 (n)n\u22122\u03b2 + log3 (n)n2\u03b3\u22121 ].\n\nPlugging this into (6.31) gives\n(6.34) E|\u03b5\u0302\u2217n \u2212 \u03b5n |2 \u2264 C[E|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 + log\u2212\u03b1 (n)n\u22122\u03b2 + log3 (n)n2\u03b3\u22121 ].\nCompare (6.34) with the theorem. All that remains to show is\n(6.35)\nso\n\nE|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 \u2264 C log3 (n)n2\u03b3\u22121 .\n\nWe now show (6.35). Note that |\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 \u2264 n2\u03b3 and P {D\u03030c \u222a Bnc } = o(1/n),\nE[|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 * 1{D\u0303c \u222aB c } ] \u2264 o(n2\u03b3\u22121 )\n0\n\nn\n\nand all we need to show is\n(6.36)\n\nE[|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 * 1{D\u03030 \u2229Bn } ] \u2264 C log3 (n)n2\u03b3\u22121 .\n\nTo this end, note that over the event D\u03030 \u2229 Bn , by Lemma 6.7 and that\n|sin(x)| \u2264 C|x| for all x,\n(6.37)\n\n|\u03b5\u0302\u2217n \u2212 \u03b5\u0303n |2 \u2264 C t\u03032n |\u03c6n (t\u0303n )|2\n\nNow, first, by Lemma 6.6,\np\nt\u0303n \u223c 2 log n,\n(6.38)\n\n(\u00fb0 \u2212 \u016b0 )2\n.\n\u03c3\u0304 2\n\n|\u00fb0 \u2212 \u016b0 | \u2264 C log(n)n\u03b3\u22121/2 (n).\n\nSecond, by Lemma 6.8 and the Cauchy\u2013Schwarz inequality,\n\u221a\n2q1 log n 2\n2\n\u221a\n|\u03c6n (t\u0303n )| \u2264 \u03c6\u0303(t\u0303n ) +\n,\nn\nwhere according to Lemma 6.9,\n\u03c6(t\u0303n ) \u2264 Cn\u2212\u03b3 .\n\nTherefore, over the event D\u03030 \u2229 Bn ,\n(6.39)\n\n|\u03c6n (t\u0303n )|2 \u2264 Cn\u22122\u03b3 .\n\nInserting (6.38) and (6.39) into (6.37) gives (6.36), and concludes the proof\nof the theorem.\nAPPENDIX\nWe shall prove in this section the technical lemmas which are used in the\nproofs of the main results in the previous sections.\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n37\n\nA.1. Proof of Lemma 6.1. Consider the first claim first. The symmetry\nof \u0175 implies\nZ\nZ\n1 \u221e\n1\n\u2212itu\ncos(tu)\u01751 (t) dt.\ne\n\u01751 (t) dt =\nw1 (u) =\n2\u03c0\n\u03c0 0\n(k\u22121)\n\nNote that \u01751 is smooth in (0, \u221e) and \u01751\n(0) = (\u22121)k/2 \u03c0. Repeatedly\nusing integration by parts k times yields\nZ\n1 \u221e\n(A.1)\ncos(tu)\u01751 (t) dt = u\u2212k + r1 (u),\nu > 0,\n\u03c0 0\nwhere\nZ \u221e\nZ \u221e\n1\n1\n(k)\n(k+1)\ncos(tu)\u01751 (t) dt =\nsin(tu)\u01751\n(t) dt .\n|r1 (u)| =\n\u03c0|u|k 0\n\u03c0|u|k+1 0\nDirect calculations show that there is a constant C = C(\u03b1, k) > 0 such that\n(k+1)\n\n|\u01751\n\nso\n\n(t)| \u2264 C(1 + |t|)\u2212(\u03b1+k+1) ,\n\n|r1 (u)| \u2264 C|u|\u2212(k+1) .\n\n(A.2)\n\nCombining (A.1) and (A.2) gives the claim.\nNext, consider the second claim. It is sufficient to show that for sufficiently\nlarge x,\ng(x) \u2265 C|x|\u2212k .\n\n(A.3)\nBy the way g is defined,\n(A.4)\nwhere\nI=\n\ng(x) =\nZ\n\n|u|\u2265x/2\n\nFirst, we have\n(A.5)\n\nZ\n\n\u03c6a (x)w1 (x \u2212 u) du = I + II,\n\nw1 (x \u2212 u)\u03c6a (u) du,\n\nII =\n\nZ\n\n|u|<x/2\n\nw1 (x \u2212 u)\u03c6a (u) du.\n\n|I| \u2264 C\u03c6a (x/2).\n\nSecond, by the first claim, there are generic constants C2 > C1 > 0 such that\nfor sufficiently large x and |u| < x/2,\nand so\n(A.6)\n\nC1 |x|\u2212k \u2264 w1 (x \u2212 u) \u2264 C2 |x|\u2212k ,\nC1 (1 + |x|)\u2212k \u2264 II \u2264 C2 |x|\u2212k .\n\nInserting (A.5) and (A.6) into (A.4) gives (A.3).\nLast, consider the third claim. Recall that [i.e., (6.3)]\nf1 (x) = (1 \u2212 \u03b7n )\u03c6a (x) + \u03b7n \u03c6\u221aa2 +1 (x) + \u03b80 \u03b7n g(x).\n\nOnce we take \u03b80 appropriately small, the claim follows from (A.3).\n\n\f38\n\nT. T. CAI AND J. JIN\n\nA.2. Proof of Lemma 6.2. Similarly, write\nZ\n1\nw2 (u) =\ncos(tu)\u01752 (u) du = u\u2212k + r2 (u),\n\u03c0\n\nwhere\n\n1\n|r2 (u)| \u2264\n\u03c0|u|k+1\n\n(A.7)\n\n1\n=\n\u03c0|u|k+1\n\nZ\nZ\n\n\u221e\n0\n\n(k+1)\n\n|\u01752\n\n\u03c4n +1\n\n(t)| dt\n\n(k+1)\n\n|\u01752\n\n0\n\nu > 0,\n\n(t)| dt.\n\nCompare (A.7) with the lemma; it is sufficient to show that for sufficiently\nlarge n,\nZ \u03c4n +1\n(k+1)\n(A.8)\n|\u01752\n(t)| dt \u2264 C,\n0\n\nwhich is equivalent to\nZ\n\n(A.9)\n\n\u03c4n +1\n\n(k+1)\n\n|\u01752\n\n2\n\n(t)| dt \u2264 C.\n\nWe now show (A.9). To do so, we limit our attention to 2 \u2264 |t| \u2264 \u03c4n + 1.\nRecall that \u01752 (t) = s2 (t)w\u0303(t), where\n2 /2\n\nw\u0303(t) = e\u03b4n t\n\n\u01751 (t) +\n\n1 1 \u2212 \u03b7n \u03b4n t2 /2\n(e\n\u2212 1).\n\u03b80 \u03b7n\n\nFirst, by the way \u03b4n is defined,\n|w\u0303(t)| \u2264 C[|t|\u2212\u03b1 + t2 \u03c4n\u2212(\u03b1+2) ] \u2264 C|t|\u2212\u03b1 .\n\n(A.10)\n\nSecond, fix m = 1, 2, . . . , k + 1, write\n(A.11)\n\nw\u0303(m) (t) =\n\nm\nX\n1 1 \u2212 \u03b7n \u03b4n t2 /2 (m)\n2\n(j)\n(e\u03b4n t /2 )(m\u2212j) \u01751 (t) +\n(e\n) .\n\u03b80 \u03b7n\nj=0\n\nRecall that \u01751 (t) = |t|\u2212\u03b1 . By elementary calculus, there is a constant C =\nC(k) > 0 such that\n(A.12)\n\n2 /2\n\n|(e\u03b4n t\n\n)(m) | \u2264 C\u03b4n t,\n\n(m)\n\n|\u01751 (t)| \u2264 C|t|\u2212\u03b1 .\n\nCombining (A.11) and (A.12) gives\n\n(A.13)\n\n|w\u0303(m) (t)| \u2264 C\u03b4n |t|1\u2212\u03b1 + C\n\n\u03b4n t\n\u03b80 \u03b7n\n\n\u2264 C\u03b4n |t|1\u2212\u03b1 + C\u03c4n\u2212(\u03b1+1) ,\n\nm = 1, 2, . . . , k + 1.\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n39\n\nLast, direct calculations show that\n(m)\n\n(A.14)\n\n|s2 (t)| \u2264 C,\n\nm = 0, 1, . . . , k.\n\nCombining (A.10), (A.13) and (A.14) gives\n(A.15)\n\n(k+1)\n\n|\u01752\n\n(t)| \u2264 C[\u03b4n |t|1\u2212\u03b1 + \u03c4n\u2212(\u03b1+1) + |t|\u2212\u03b1 ]\n\nand (A.9) follows directly.\nA.3. Proof of Lemma 6.3. The first claim follows by the way that f\u02c62 is\nconstructed. Consider the second claim. Recall that\n2\n2\n2 2\nf\u02c61 (t) = \u03b7n e\u2212(a +1)t /2 + e\u2212a t /2 [(1 \u2212 \u03b7n ) + \u03b80 \u03b7n \u01751 (t)],\n\nand that\n2\n2\n2 2\nf\u02c62 (t) = \u03b7n e\u2212(a +1)t /2 + e\u2212an t /2 [(1 \u2212 \u03b7n ) + \u03b80 \u03b7n \u01752 (t)].\n\nFix 0 \u2264 m \u2264 k. On one hand,\n2 t2 /2\n\n|(e\u2212a\n\n2 t2 /2\n\n)(m) (t)| \u2264 C|t|m e\u2212a\n\n.\n\nOn the other hand, by the proof of Lemma 6.2,\n(m)\n\n|\u01751 (t)| \u2264 C,\n\n(m)(t)\n\n|\u01752\n\n| \u2264 C.\n\nCombining these gives the claim.\nA.4. Proof of Lemma 6.4. Write for short t\u0302 = t\u0302n (\u03b3). By elementary calculus, for any t > 0,\n(A.16)\n\n|\u03c6n (t) \u2212 1| \u2264\n\nn\n\nn\n\nj=1\n\nj=1\n\ntX\n1 X itXj\n|e\n\u2212 1| \u2264\n|Xj |.\nn\nn\n\nNote that for sufficiently large n, |\u03c6n (t\u0302n )| = n\u2212\u03b3 \u2264 1/2. Applying (A.16)\nwith t = t\u0302n gives\n(A.17)\n\nn/2\n|1 \u2212 \u03c6n (t\u0302n )| \u2265 Pn\n.\nj=1 |Xj |\nj=1 |Xj |\n\nt\u0302n \u2265 Pn\n\nn\n\nNow, first, by direct calculations and the H\u00f6lder inequality,\n\n(A.18)\n\n|\u03c302 (\u03c6n , t\u0302)| \u2264\n\n| Re(\u03c6n (t\u0302)) Re(\u03c6\u2032n (t\u0302)) + Im(\u03c6n (t\u0302)) Im(\u03c6\u2032n (t\u0302))|\nt\u0302|\u03c6n (t\u0302)|\n\n\u2264 n\u03b3 |\u03c6\u2032n (t\u0302)|/t\u0302,\n\n\f40\n\nT. T. CAI AND J. JIN\n\nwhere in the last step we have used |\u03c6n (t\u0302)| = n\u2212\u03b3 . Second, note that for any\nt,\nn\n\nn\n\nj=1\n\nj=1\n\n1X\niX\nXj eitXj \u2264\n|Xj |.\n|\u03c6 (t)| \u2264\nn\nn\n\u2032\n\n(A.19)\n\nCombine (A.17), (A.18) and (A.19) and use the Cauchy\u2013Schwarz inequality,\n!\n!2\nn\nn\nX\nX\n2\n\u03b3 1\n2\n\u03b3 1\n(A.20)\n|\u03c30 (\u03c6n , t\u0302)| \u2264 2n\n|Xj | \u2264 2n\nXj .\nn\nn\nj=1\n\nj=1\n\nHence, to show the claim, it is sufficient to show\n#\n!\n\"\nn\n1X 2\n(A.21)\nXj * 1{Bnc } \u2264 C/n.\nE\nn\nj=1\n\nWe now show (A.21). Recall that m2 denotes the second moment of X1 ,\nwe write\nn\n1X 2\nz\nXj = m2 + \u221a ,\n(A.22)\nn\nn\nj=1\n\nwhere z =\ninequality,\n(A.23)\n\n\u221a\n\n1 Pn\n\n2\nj=1 Xj\n\nn[ n\n\n\u0014\n\n\u2212 m2 ]. It is seen that Ez 2 \u2264 C, so by the H\u00f6lder\n\n1\nE \u221a z * 1{Bnc }\nn\n\n\u0015\n\n\u2264\n\n\u0012\n\n\u00131/2\n1 2\nc\n\u2264 C/n.\nEz * P {Bn }\nn\n\nInserting (A.23) into (A.22) gives (A.21). This concludes the proof.\nA.5. Proof of Lemma 6.5. Before we show the Lemma 6.5, we need some\nnotation and lemmas. Introduce the event\np\n\u001b\n\u001a\nm2 ( (q \u2212 2) log n + 2m2 )\n\u221a\n(A.24)\n,\nD1 = W1 (\u03c6n ; n) \u2264\nn\nwhere\nW1 (\u03c6n ; n) = W1 (\u03c6n ; n, X1 , X2 , . . . , Xn ) =\n\nsup\n{|t\u2212tn |\u2264c0\n\n|\u03c6\u2032n (t) \u2212 \u03c6\u2032 (t)|,\n\nn\u03b3\u22121/2 }\n\nm2 is the second moment of X1 , and c0 is a constant defined in (6.19). We\nhave the following lemmas.\nLemma A.1.\n\nFix q \u2265 4 and \u03b3 \u2208 (0, 1/2). For sufficiently large n,\nP {D1c } \u2264 \u014d(n\u03b3\u22121 ).\n\n\fOPTIMAL RATES OF CONVERGENCE\n\nLemma A.2.\n(A.25)\n\n41\n\nFix q \u2265 4 and \u03b3 \u2208 (0, 1/2). For sufficiently large n,\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \\D1 } ] \u2264 C/n.\n\nHere, \u014d(na ) denotes a term which equals o(na+\u03b4 ) for any \u03b4 > 0. The proof\nof Lemma A.1 is similar to that of Lemma 6.4 of Jin and Cai (2006) so\nwe skip it. Lemma A.2 is the tricky part of the proof of Lemma 6.5 and is\nproved in Section A.5.1.\nWe now proceed to prove Lemma 6.5. Write for short t\u0302n = t\u0302n (\u03b3) and\ntn = tn (\u03b3). By triangle inequality,\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 ]\n\n\u2264 E[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \u2229D1 } ]\n\n(A.26)\n\n+ E[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0c } ]\n+ E[\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \\D1 } ].\n\nFirst, recall that over the event D0 [i.e., (6.19)],\n|t\u0302n \u2212 tn | \u2264 c0 n\u03b3\u22121/2 ,\nso by the definition of the event D1 ,\np\n\u221a\n|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )| \u2264 C log(n)/ n\n\nover D0 \u2229 D1\n\nand\n\n(A.27)\n\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \u2229D1 } ] \u2264 C log(n)/n.\n\nSecond, note that for all t,\n|\u03c6\u2032n (t) \u2212 \u03c6\u2032 (t)| \u2264\n\nn\n\nn\n\nj=1\n\nj=1\n\n1X\n1X\n[|Xj | + m1 ] \u2264 2m1 +\n(|Xj | \u2212 m1 ),\nn\nn\n\nwhere m1 is the first moment of X1 . It follows that\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0c } ]\n(A.28)\n\"\n!2\n#\n!\nn\n1X\nc\n\u2264C E\n(|Xj | \u2212 m1 ) * 1{D0c } + 2m1 P {Dn } .\nn\nj=1\n\n1 Pn\n\nMoreover, note that E[ n j=1 (|Xj | \u2212 m1 )]4 \u2264 C/n2 , by the H\u00f6lder inequality,\n#\n!2\n\"\nn\n1X\n(|Xj | \u2212 m1 ) * 1{D0c }\nE\nn\nj=1\n\n\f42\n\nT. T. CAI AND J. JIN\n\n!1/2\n#4\nn\n1X\n(|Xj | \u2212 m1 ) * P {D0c }\n\u2264 E\nn\n\"\n\n(A.29)\n\nj=1\n\n\u2264 o(1/n).\nCombining (A.28) and (A.29) gives\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0c } ] \u2264 C/n\n\n(A.30)\n\nand the claim follows by inserting (A.25), (A.27) and (A.30) into (A.26).\nA.5.1. Proof of Lemma A.2. We prove it for the case \u03b3 \u2264 1/3 and the\ncase \u03b3 > 1/3 separately.\nConsider the case \u03b3 \u2264 1/3 first. By the Taylor expansion, for some \u03be that\nfalls between tn and t\u0302n ,\n(A.31) \u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n ) = \u03c6\u2032n (tn ) \u2212 \u03c6\u2032 (tn ) + (\u03c6\u2032\u2032n (\u03be) \u2212 \u03c6\u2032\u2032 (\u03be)) * (t\u0302n \u2212 tn ).\nBy direct calculations and the definition of D0 ,\nn\n\n(A.32)\n\n|\u03c6\u2032\u2032n (\u03be) \u2212 \u03c6\u2032\u2032 (\u03be)| \u2264\n\n1X 2\n(Xj + E[Xj2 ]) \u2264 C\nn\n\nover D0 .\n\nj=1\n\nAlso, recall that\n|t\u0302n \u2212 tn | \u2264 c0 n\u03b3\u22121/2 .\n\n(A.33)\n\nInserting (A.33) and (A.32) into (A.31) gives\n|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )| \u2264 |\u03c6\u2032n (tn ) \u2212 \u03c6\u2032 (tn )| + Cn\u03b3\u22121/2 ,\nwhich implies\n|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 \u2264 C(|\u03c6\u2032n (tn ) \u2212 \u03c6\u2032 (tn )|2 + n2\u03b3\u22121 ).\nIt follows that\n(A.34)\n\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \\D1 } ]\n\u2264 C(E[|\u03c6\u2032n (tn ) \u2212 \u03c6\u2032 (tn )|2 ] + n2\u03b3\u22121 * P {D0 \\ D1 }).\n\nBy Lemma A.1 and elementary statistics,\n(A.35)\n\nP {D0 \\ D1 } \u2264 \u014d(n\u03b3\u22121 ),\n\nE[|\u03c6\u2032n (tn ) \u2212 \u03c6\u2032 (tn )|2 ] \u2264 C/n,\n\ninserting (A.35) into (A.34) gives\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \\D1 } ] = C/n + \u014d(n3\u03b3\u22121 )\nand the claim follows by \u03b3 < 1/3.\n\n\f43\n\nOPTIMAL RATES OF CONVERGENCE\n\nNext, consider the case \u03b3 \u2265 1/3. Fix \u03b4 \u2208 (\u03b3, 2 \u2212 3\u03b3) and let\nK = K(n, c0 , \u03b3, \u03b4) = c0 n\u03b3+\u03b4/2\u22121/2 .\n\nNote here that\n\u03b3 + \u03b4/2 \u2212 1/2 >\n\n3\u03b3 \u2212 1\n\u2265 0.\n2\n\nLay out a grid sk = tn + (k \u2212 K \u2212 1)n\u2212\u03b4/2 , k = 1, 2, . . . , 2K + 1. Observe that\nfor any t \u2208 [sk , sk+1 ],\n\n|\u03c6\u2032n (t) \u2212 \u03c6\u2032 (t)| \u2264 |\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|\n(A.36)\n\u0010\n+ n\u2212\u03b4/2 *\nsup\n\n|\u03be\u2212tn |\u2264c0 *n\u03b3\u22121/2\n\n\u0011\n|\u03c6\u2032\u2032n (\u03be) \u2212 \u03c6\u2032\u2032 (\u03be)| .\n\nCombining (A.36) with (A.32) gives\n|\u03c6\u2032n (t) \u2212 \u03c6\u2032 (t)| \u2264 |\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )| + Cn\u2212\u03b4/2\n\nover D0 .\n\nNow, note that the endpoints of the grid are\ntn \u00b1 Kn\u2212\u03b4/2 = tn \u00b1 c0 n\u03b3\u22121/2\nand that over the event D0 ,\n|t\u0302n \u2212 tn | \u2264 c0 n\u03b3\u22121/2 ;\nit follows that\n|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )| \u2264\n\nmax\n\n|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )| + Cn\u2212\u03b4/2 .\n\n{1\u2264k\u22642K+1}\n\nTherefore, by the Cauchy\u2013Schwarz inequality,\n\u0011\n\u0011\n\u0010\u0010\n(A.37) |\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 \u2264 C\nmax\n|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|2 + n\u2212\u03b4 .\n{1\u2264k\u22642K+1}\n\nRecall that\n\nP {D0 \\ D1 } \u2264 \u014d(n\u03b3\u22121 ).\n\n(A.38)\n\nIt follows from (A.37) and (A.38) that\n\n(A.39)\n\nE[|\u03c6\u2032n (t\u0302n ) \u2212 \u03c6\u2032 (t\u0302n )|2 * 1{D0 \\D1 } ]\ni\n\u0011\n\u0010 h\u0010\n\u2264C E\nmax\n|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|2 * 1{D0 \\D1 }\n{1\u2264k\u22642K+1}\n\n=C\n\n2K+1\nX\nk=1\n\n\u0011\n+ n\u2212\u03b4 P {D0 \\ D1 }\n\nE[|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|2 * 1{D0 \\D1 } ] + o(n\u22121 ),\n\n\f44\n\nT. T. CAI AND J. JIN\n\nwhere in the last step we have used \u03b4 > \u03b3.\nNow, for any k = 1, 2, . . . , 2K + 1, observe that by elementary statistics,\nE[|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|4 ] \u2264 C/n2 .\nBy the H\u00f6lder inequality and (A.38),\nE[|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|2 * 1{D0 \\D1 } ]\n\u2264 (E|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|4 * P {D0 \\ D1 })1/2\n\u2264 \u014d(n(\u03b3\u22123)/2 ),\n\nso by K \u2264 Cn\u03b3+\u03b4/2\u22121/2\n\n(A.40)\n\nK\nX\nk=1\n\nE[|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|2 * 1{D0 \\D1 } ] \u2264 \u014d(Kn(\u03b3\u22123)/2 )\n= \u014d(n3\u03b3/2+\u03b4/2\u22122 ).\n\nRecall \u03b4 < 2 \u2212 3\u03b3, it follows from (A.40) that\n(A.41)\n\nK\nX\nk=1\n\nE[|\u03c6\u2032n (sk ) \u2212 \u03c6\u2032 (sk )|2 * 1{D0 \\D1 } ] = o(1/n)\n\nand the claim follows by plugging (A.41) into (A.39).\n\u221a A.6. Proof of Lemma 6.9. Consider the first claim. Write for short t\u0304n =\n2\u03b3 log n. By the definition and elementary Fourier analysis,\n\u0012\n\u0013\nu0 \u2212 \u016b0\n2 2\n\u03c6\u0303R (t) = (1 \u2212 \u03b5n )e\u22121/2(\u03c30 /\u03c3\u03040 ) t cos t\n\u03c3\u03040\n(A.42)\n\u0012\n\u0013\nZ\nu \u2212 \u016b0\n\u22121/2(\u03c3/\u03c3\u03040 )2 t2\ncos t\n+ \u03b5n e\nh(u|\u03c3) dH(\u03c3).\n\u03c3\u03040\nBy Lemma 6.6, we have that over the event Bn ,\n(A.43)\n\n|\u03c3\u03020 \u2212 \u03c3\u03040 | \u2264 C log1/2 (n)n\u03b3\u22121/2 ,\n\n|\u00fb0 \u2212 \u016b0 | \u2264 C log(n)n\u03b3\u22121/2 .\n\nAs a result, by the Taylor expansion and that t\u0303n =\n(A.44)\n\n\u03c3\u03040\n\u03c3\u03020 t\u0304n ,\n\n|\u03c6\u0303R (t\u0303n ) \u2212 \u03c6\u0303R (t\u0304n )| . |(\u03c6\u0303R )\u2032 (t\u0304n )| * |t\u0303n \u2212 t\u0304n |\n\u2264 C log(n)n\u03b3\u22121/2 |(\u03c6\u0303R )\u2032 (t\u0304n )|,\n\nwhere\n(A.45)\n\n2 *t\u03042\nn\n\n|(\u03c6\u0303R )\u2032 (t\u0304n )| \u2264 C t\u0304n e\u22121/2(\u03c30 /\u03c3\u03040 )\n\n\u2264 C log1/2 (n)n\u2212\u03b3 .\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n45\n\nCombining (A.44) and (A.45) gives the first claim.\nConsider the second claim. Introduce a bridging quantity\n\u0013\u0015\n\u0014 \u0012\nX1 \u2212 u0\n(A.46)\n.\nE cos t\u0304n\n\u03c30\nBy the triangle inequality,\n(A.47)\n\n|(1 \u2212 \u03b5n ) \u2212 n\u03b3 \u03c6\u0303R (t\u0304n )| \u2264 I + II,\n\n0\n0\nwhere I = |(1 \u2212 \u03b5n ) \u2212 n\u03b3 E[cos(t\u0304n X1\u03c3\u2212u\n)]| and II = n\u03b3 |E[cos(t\u0304n X1\u03c3\u2212u\n)] \u2212\n0\n0\n2\n\n\u03c6\u0303R (t\u0304n )|. Consider I first. By direct calculations and et\u0304n /2 = n\u03b3 ,\n\u0013\u0015\n\u0014 \u0012\nX1 \u2212 u0\n\u03b3\n(1 \u2212 \u03b5n ) \u2212 n E cos t\u0304n\n\u03c30\n(A.48)\n\u0014Z\n\u0012\n\u0013\n\u0015\nZ\nu \u2212 u0\n2\n2\n= \u2212\u03b5n e\u22121/2[(\u03c3/\u03c30 ) \u22121]t\u0304n\ncos t\u0304n\nh(u|\u03c3) dH(\u03c3).\n\u03c30\n\nNote that by elementary Fourier analysis,\n\u0013\u0013\n\u0013\n\u0012 \u0012\n\u0012\nZ\nt\nu \u2212 u0\n\u03c3\n.\nh(u|\u03c3) = Re h\u0303\ncos t\n\u03c30\n\u03c30\n\nSince H is eligible and obeys the constraint (2.3), we have\n\u0014 \u0012\n\u0013\u0015\nX1 \u2212 u0\n\u03b3\n(1 \u2212 \u03b5n ) \u2212 n E cos t\u0304n\n\u03c30\n\u0013\n\u0012\nZ\nt\u0303n\n\u22121/2[(\u03c3/\u03c30 )2 \u22121]t\u03042n\n(A.49)\n\u03c3 dH(\u03c3)\n\u2264 \u03b5n e\nh\u0303\n\u03c30\n\u2264 C\u03b5n t\u0304\u2212\u03b1\nn .\n\nConsider II next. It follows from the proof of Theorem 2.2 [i.e., (6.18)]\nthat\n|\u03c3\u03040 \u2212 \u03c30 | \u2264 C\u03b5n log\u2212(\u03b1+2)/2 (n),\n\n(A.50)\n\n|\u016b0 \u2212 u0 | \u2264 C\u03b5n log\u2212(\u03b1+1)/2 (n).\n\nCompare (A.48) with (A.42),\n\u0014 \u0012\n\u0013\u0015\nX1 \u2212 u0\nR\n\u03c6\u0303 (t\u0304n ) \u2212 E cos t\u0304n\n\u03c30\n\u0014\n\u2264 Cn\u2212\u03b3 (1 \u2212 \u03b5n )(|\u03c3\u030402 \u2212 \u03c302 |t\u03042n + |\u016b0 \u2212 u0 |t\u0304n )\n+ \u03b5n\n\nZ\n\n(\u03c3 2 t\u03042n |\u03c3\u030402\n\n\u2212 \u03c302 | + |ut\u0304n ||\u016b0\n\n\u0015\n\u2212 u0 |) dH(u, \u03c3) .\n\n\f46\n\nT. T. CAI AND J. JIN\n\nNote that E|u| \u2264 C and E|\u03c3 2 \u2212 \u03c302 | \u2264 C, it follows from (A.50) that\n\u0013\u0015\n\u0014 \u0012\nX1 \u2212 u0\nR\n(A.51)\n\u2264 C\u03b5n n\u2212\u03b3 log\u2212\u03b1/2 (n).\n\u03c6\u0303 (t\u0304n ) \u2212 E cos t\u0304n\n\u03c30\nInserting (A.49) and (A.51) to (A.47) gives\n|(1 \u2212 \u03b5n ) \u2212 n\u03b3 \u03c6\u0303R (t\u0304n )| \u2264 C\u03b5n log\u2212\u03b1/2 (n).\nThis concludes the proof of the second claim of the lemma.\nAcknowledgments. We would like to thank Wenguang Sun for his help\non programming and numerical simulations. We also thank the Associate\nEditor and two referees for thorough and useful comments which have helped\nto improve the presentation of the paper.\nREFERENCES\nAbramovich, F., Benjamini, Y., Donoho, D. and Johnstone, I. (2006). Adapting to\nunknown sparsity by controlling the false discovery rate. Ann. Statist. 34 584\u2013653.\nMR2281879\nBenjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: A practical\nand powerful approach to multiple testing. J. Roy. Statist. Soc. Ser. B 57 289\u2013300.\nMR1325392\nBenjamini, Y. and Hochberg, Y. (2000). On the adaptive control of the false discovery\nrate in multiple testing with independent statistics. J. Educ. Behav. Statist. 25 60\u201383.\nBenjamini, Y., Krieger, A. M. and Yekutieli, D. (2006). Adaptive linear step-up procedures that controls the false discovery rate. Biometrika 93 491\u2013507. MR2261438\nBlanchard, G. and Roquain, \u00c9. (2007). Adaptive FDR control under independence and\ndependence. Available at arxiv:0707.0536v2.\nCai, T., Jin, J. and Low, M. (2007). Estimation and confidence sets for sparse normal\nmixtures. Ann. Statist. 35 2421\u20132449. MR2382653\nCelisse, A. and Robin, S. (2008). A leave-p-out based estimation of the proportion of\nnull hypotheses. Available at arxiv:0804.1189. MR2411944\nDonoho, D. and Jin, J. (2004). Higher criticism for detecting sparse heterogeneous mixtures. Ann. Statist. 32 962\u2013994. MR2065195\nDonoho, D. and Jin, J. (2006). Asymptotic minimaxity of false discovery rate thresholding\nfor sparse exponential data. Ann. Statist. 34 2980\u20133018. MR2329475\nDonoho, D. and Liu, R. C. (1991). Geometrizing rates of convergence, II. Ann. Statist.\n19 633\u2013667. MR1105839\nEfron, B. (2004). Large-scale simultaneous hypothesis testing: The choice of a null hypothesis. J. Amer. Statist. Assoc. 99 96\u2013104. MR2054289\nEfron, B. (2008). Microarrays, empirical Bayes and the two-groups model. Statist. Sci.\n23 1\u201322. MR2431866\nEfron, B., Tibshirani, R., Storey, J. and Tusher, V. (2001). Empirical Bayes analysis\nof a microarray experiment. J. Amer. Statist. Assoc. 96 1151\u20131160. MR1946571\nErdelyi, A. (1956). Asymptotic Expansions. Dover, New York. MR0078494\nFan, J. (1991). On the optimal rates of convergence for nonparametric deconvolution\nproblems. Ann. Statist. 19 1257\u20131272. MR1126324\n\n\fOPTIMAL RATES OF CONVERGENCE\n\n47\n\nFinner, H., Dickhaus, T. and Roters, M. (2009). On the false discovery rate and on\nasymptotically optimal rejection curve. Ann. Statist. 37 596\u2013618. MR2502644\nGenovese, C. and Wasserman, L. (2004). A stochastic process approach to false discovery control. Ann. Statist. 32 1035\u20131061. MR2065197\nIbragimov, I. A., Nemirovskii, A. S. and Khas'minskii, R. Z. (1986). Some problems on\nnonparametric estimation in Gaussian white noise. Theory Probab. Appl. 31 391\u2013406.\nMR0866866\nJin, J. and Cai, T. (2006). Estimating the null and the proportion of nonnull effects in\nlarge-scale multiple comparisons. Available at arxiv.math/0611108v1. MR2325113\nJin, J. and Cai, T. (2007). Estimating the null and the proportion of nonnull effects in\nlarge-scale multiple comparisons. J. Amer. Statist. Assoc. 102 495\u2013506. MR2325113\nJin, J. (2008). Proportion of nonzero normal means: Universal oracle equivalences and\nuniformly consistent estimations. J. R. Stat. Soc. Ser. B Stat. Methodol. 70(3) 461\u2013\n493.\nMallat, S. (1998). A Wavelet Tour of Signal Processing, 2nd ed. Academic Press, New\nYork. MR1614527\nMeinshausen, M. and Rice, J. (2006). Estimating the proportion of false null hypothesis\namong a large number of independent tested hypotheses. Ann. Statist. 34 373\u2013393.\nMR2275246\nM\u00fcller, P., Parmigiani, G., Robert, C. and Rousseau, J. (2004). Optimal sample size\nfor multiple testing: The case of gene expression microarrays. J. Amer. Statist. Assoc.\n99 990\u20131001. MR2109489\nNewton, M., Kendziorski, C., Richmond, C., Blattner, F. and Tsui, K. (2001). On\ndifferential variability of expression ratios: Improving statistical inference about gene\nexpression changes from microarray data. J. Comput. Biol. 8 37\u201352.\nNeuvial, P. (2008). Asymptotic properties of false discovery rate controlling procedures\nunder independence. Electron. J. Stat. 2 1065\u20131110. MR2460858\nSilverman, B. W. (1986). Density Estimation for Statistics and Data Analysis. Chapman\nand Hall, London. MR0848134\nStorey, J. D. (2002). A direct approach to false discovery rate. J. R. Stat. Soc. Ser. B\nStat. Methodol. 64 479\u2013498. MR1924302\nSun, W. and Cai, T. (2007). The oracle and compound decision rules for false discovery\nrate control. J. Amer. Statist. Assoc. 102 901\u2013912. MR2411657\nSwanepoel, J. W. H. (1999). The limiting behavior of a modified maximal symmetric\n2s-spacing with applications. Ann. Statist. 27 24\u201335. MR1701099\nvan der Laan, M., Dudoit, S. and Pollard, K. (2004). Multiple testing (III): Augmentation procedures for control of the generalized family-wise error rate and tail probabilities for the proportion of false positives. Technical report, Dept. Biostatistics, Univ.\nCalifornia, Berkeley.\nWest, M. (1987). On scale mixtures of normal distributions. Biometrika 3 646\u2013648.\nMR0909372\nZhang, C.-H. (1990). Fourier methods for estimating mixing densities and distributions.\nAnn. Statist. 18 806\u2013831. MR1056338\nDepartment of Statistics\nThe Wharton School\nUniversity of Pennsylvania\nPhiladelphia, Pennsylvania 19104\nUSA\nE-mail: tcai@wharton.upenn.edu\n\nDepartment of Statistics\nCarnegie Mellon University\nPittsburgh, Pennsylvania 15213\nUSA\nE-mail: jiashun@stat.cmu.edu\n\n\f"}