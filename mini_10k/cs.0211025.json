{"id": "http://arxiv.org/abs/cs/0211025v3", "guidislink": true, "updated": "2003-01-06T02:28:07Z", "updated_parsed": [2003, 1, 6, 2, 28, 7, 0, 6, 0], "published": "2002-11-21T04:46:02Z", "published_parsed": [2002, 11, 21, 4, 46, 2, 3, 325, 0], "title": "Effective Strong Dimension, Algorithmic Information, and Computational\n  Complexity", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0108018%2Ccs%2F0108009%2Ccs%2F0211012%2Ccs%2F0211027%2Ccs%2F0211009%2Ccs%2F0211010%2Ccs%2F0211004%2Ccs%2F0211014%2Ccs%2F0211015%2Ccs%2F0211032%2Ccs%2F0211002%2Ccs%2F0211035%2Ccs%2F0211020%2Ccs%2F0211017%2Ccs%2F0211016%2Ccs%2F0211025%2Ccs%2F0211026%2Ccs%2F0211013%2Ccs%2F0211022%2Ccs%2F0211011%2Ccs%2F0211036%2Ccs%2F0211005%2Ccs%2F0211001%2Ccs%2F0211038%2Ccs%2F0211003%2Ccs%2F0211039%2Ccs%2F0211033%2Ccs%2F0211006%2Ccs%2F0211042%2Ccs%2F0211019%2Ccs%2F0211031%2Ccs%2F0211024%2Ccs%2F0211030%2Ccs%2F0211018%2Ccs%2F0211040%2Ccs%2F0211029%2Ccs%2F0211028%2Ccs%2F0211041%2Ccs%2F0211037%2Ccs%2F0211023%2Ccs%2F0211007%2Ccs%2F0211021%2Ccs%2F0203024%2Ccs%2F0203026%2Ccs%2F0203030%2Ccs%2F0203023%2Ccs%2F0203029%2Ccs%2F0203018%2Ccs%2F0203013%2Ccs%2F0203015%2Ccs%2F0203021%2Ccs%2F0203027%2Ccs%2F0203003%2Ccs%2F0203014%2Ccs%2F0203007%2Ccs%2F0203012%2Ccs%2F0203008%2Ccs%2F0203016%2Ccs%2F0203005%2Ccs%2F0203006%2Ccs%2F0203010%2Ccs%2F0203028%2Ccs%2F0203022%2Ccs%2F0203004%2Ccs%2F0203017%2Ccs%2F0203011%2Ccs%2F0203020%2Ccs%2F0203001%2Ccs%2F0203009%2Ccs%2F0203002%2Ccs%2F0203019%2Ccs%2F0203025%2Ccs%2F0606088%2Ccs%2F0606095%2Ccs%2F0606080%2Ccs%2F0606081%2Ccs%2F0606033%2Ccs%2F0606006%2Ccs%2F0606019%2Ccs%2F0606068%2Ccs%2F0606003%2Ccs%2F0606050%2Ccs%2F0606092%2Ccs%2F0606110%2Ccs%2F0606122%2Ccs%2F0606104%2Ccs%2F0606118%2Ccs%2F0606013%2Ccs%2F0606094%2Ccs%2F0606113%2Ccs%2F0606005%2Ccs%2F0606087%2Ccs%2F0606121%2Ccs%2F0606079%2Ccs%2F0606064%2Ccs%2F0606027%2Ccs%2F0606055%2Ccs%2F0606034%2Ccs%2F0606040%2Ccs%2F0606032%2Ccs%2F0606124&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Effective Strong Dimension, Algorithmic Information, and Computational\n  Complexity"}, "summary": "The two most important notions of fractal dimension are {\\it Hausdorff\ndimension}, developed by Hausdorff (1919), and {\\it packing dimension},\ndeveloped by Tricot (1982).\n  Lutz (2000) has recently proven a simple characterization of Hausdorff\ndimension in terms of {\\it gales}, which are betting strategies that generalize\nmartingales. Imposing various computability and complexity constraints on these\ngales produces a spectrum of effective versions of Hausdorff dimension.\n  In this paper we show that packing dimension can also be characterized in\nterms of gales. Moreover, even though the usual definition of packing dimension\nis considerably more complex than that of Hausdorff dimension, our gale\ncharacterization of packing dimension is an exact dual of -- and every bit as\nsimple as -- the gale characterization of Hausdorff dimension.\n  Effectivizing our gale characterization of packing dimension produces a\nvariety of {\\it effective strong dimensions}, which are exact duals of the\neffective dimensions mentioned above.\n  We develop the basic properties of effective strong dimensions and prove a\nnumber of results relating them to fundamental aspects of randomness,\nKolmogorov complexity, prediction, Boolean circuit-size complexity,\npolynomial-time degrees, and data compression.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0108018%2Ccs%2F0108009%2Ccs%2F0211012%2Ccs%2F0211027%2Ccs%2F0211009%2Ccs%2F0211010%2Ccs%2F0211004%2Ccs%2F0211014%2Ccs%2F0211015%2Ccs%2F0211032%2Ccs%2F0211002%2Ccs%2F0211035%2Ccs%2F0211020%2Ccs%2F0211017%2Ccs%2F0211016%2Ccs%2F0211025%2Ccs%2F0211026%2Ccs%2F0211013%2Ccs%2F0211022%2Ccs%2F0211011%2Ccs%2F0211036%2Ccs%2F0211005%2Ccs%2F0211001%2Ccs%2F0211038%2Ccs%2F0211003%2Ccs%2F0211039%2Ccs%2F0211033%2Ccs%2F0211006%2Ccs%2F0211042%2Ccs%2F0211019%2Ccs%2F0211031%2Ccs%2F0211024%2Ccs%2F0211030%2Ccs%2F0211018%2Ccs%2F0211040%2Ccs%2F0211029%2Ccs%2F0211028%2Ccs%2F0211041%2Ccs%2F0211037%2Ccs%2F0211023%2Ccs%2F0211007%2Ccs%2F0211021%2Ccs%2F0203024%2Ccs%2F0203026%2Ccs%2F0203030%2Ccs%2F0203023%2Ccs%2F0203029%2Ccs%2F0203018%2Ccs%2F0203013%2Ccs%2F0203015%2Ccs%2F0203021%2Ccs%2F0203027%2Ccs%2F0203003%2Ccs%2F0203014%2Ccs%2F0203007%2Ccs%2F0203012%2Ccs%2F0203008%2Ccs%2F0203016%2Ccs%2F0203005%2Ccs%2F0203006%2Ccs%2F0203010%2Ccs%2F0203028%2Ccs%2F0203022%2Ccs%2F0203004%2Ccs%2F0203017%2Ccs%2F0203011%2Ccs%2F0203020%2Ccs%2F0203001%2Ccs%2F0203009%2Ccs%2F0203002%2Ccs%2F0203019%2Ccs%2F0203025%2Ccs%2F0606088%2Ccs%2F0606095%2Ccs%2F0606080%2Ccs%2F0606081%2Ccs%2F0606033%2Ccs%2F0606006%2Ccs%2F0606019%2Ccs%2F0606068%2Ccs%2F0606003%2Ccs%2F0606050%2Ccs%2F0606092%2Ccs%2F0606110%2Ccs%2F0606122%2Ccs%2F0606104%2Ccs%2F0606118%2Ccs%2F0606013%2Ccs%2F0606094%2Ccs%2F0606113%2Ccs%2F0606005%2Ccs%2F0606087%2Ccs%2F0606121%2Ccs%2F0606079%2Ccs%2F0606064%2Ccs%2F0606027%2Ccs%2F0606055%2Ccs%2F0606034%2Ccs%2F0606040%2Ccs%2F0606032%2Ccs%2F0606124&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The two most important notions of fractal dimension are {\\it Hausdorff\ndimension}, developed by Hausdorff (1919), and {\\it packing dimension},\ndeveloped by Tricot (1982).\n  Lutz (2000) has recently proven a simple characterization of Hausdorff\ndimension in terms of {\\it gales}, which are betting strategies that generalize\nmartingales. Imposing various computability and complexity constraints on these\ngales produces a spectrum of effective versions of Hausdorff dimension.\n  In this paper we show that packing dimension can also be characterized in\nterms of gales. Moreover, even though the usual definition of packing dimension\nis considerably more complex than that of Hausdorff dimension, our gale\ncharacterization of packing dimension is an exact dual of -- and every bit as\nsimple as -- the gale characterization of Hausdorff dimension.\n  Effectivizing our gale characterization of packing dimension produces a\nvariety of {\\it effective strong dimensions}, which are exact duals of the\neffective dimensions mentioned above.\n  We develop the basic properties of effective strong dimensions and prove a\nnumber of results relating them to fundamental aspects of randomness,\nKolmogorov complexity, prediction, Boolean circuit-size complexity,\npolynomial-time degrees, and data compression."}, "authors": ["Krishna B. Athreya", "John M. Hitchcock", "Jack H. Lutz", "Elvira Mayordomo"], "author_detail": {"name": "Elvira Mayordomo"}, "author": "Elvira Mayordomo", "arxiv_comment": "35 pages", "links": [{"href": "http://arxiv.org/abs/cs/0211025v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0211025v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "F.1.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0211025v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0211025v3", "journal_reference": null, "doi": null, "fulltext": "arXiv:cs/0211025v3 [cs.CC] 6 Jan 2003\n\nEffective Strong Dimension, Algorithmic Information,\nand Computational Complexity\nKrishna B. Athreya\n\n1\n\n1\n\nJohn M. Hitchcock\nElvira Mayordomo 4\n\n2\n\nJack H. Lutz\n\n3\n\nSchool of Operations Research and Industrial Engineering, Cornell University, Ithaca, NY 14853,\nUSA and Departments of Mathematics and Statistics, Iowa State University, Ames, IA 50011, USA.\nkba@iastate.edu. This research was supported in part by Air Force Office of Scientific Research Grant\nITSI F 49620-01-1-0076.\n2\nDepartment of Computer Science, Iowa State University, Ames, IA 50011, USA.\njhitchco@cs.iastate.edu. This research was supported in part by National Science Foundation\nGrant 9988483.\n3\nDepartment of Computer Science, Iowa State University, Ames, IA 50011, USA. lutz@cs.iastate.edu.\nThis research was supported in part by National Science Foundation Grant 9988483.\n4\nDepartamento de Inform\u00e1tica e Ingenier\u0131\u0301a de Sistemas, Universidad de Zaragoza, 50015 Zaragoza,\nSPAIN. elvira@posta.unizar.es. This research was supported in part by Spanish Government MEC\nproject PB98-0937-C04-02 and by National Science Foundation Grant 9988483. It was done while visiting\nIowa State University.\n\n\fAbstract\nThe two most important notions of fractal dimension are Hausdorff dimension, developed by Hausdorff (1919), and packing dimension, developed independently by Tricot (1982) and Sullivan (1984).\nBoth dimensions have the mathematical advantage of being defined from measures, and both have\nyielded extensive applications in fractal geometry and dynamical systems.\nLutz (2000) has recently proven a simple characterization of Hausdorff dimension in terms of\ngales, which are betting strategies that generalize martingales. Imposing various computability\nand complexity constraints on these gales produces a spectrum of effective versions of Hausdorff\ndimension, including constructive, computable, polynomial-space, polynomial-time, and finite-state\ndimensions. Work by several investigators has already used these effective dimensions to shed\nsignificant new light on a variety of topics in theoretical computer science.\nIn this paper we show that packing dimension can also be characterized in terms of gales.\nMoreover, even though the usual definition of packing dimension is considerably more complex\nthan that of Hausdorff dimension, our gale characterization of packing dimension is an exact dual\nof \u2013 and every bit as simple as \u2013 the gale characterization of Hausdorff dimension.\nEffectivizing our gale characterization of packing dimension produces a variety of effective strong\ndimensions, which are exact duals of the effective dimensions mentioned above. In general (and in\nanalogy with the classical fractal dimensions), the effective strong dimension of a set or sequence is\nat least as great as its effective dimension, with equality for sets or sequences that are sufficiently\nregular.\nWe develop the basic properties of effective strong dimensions and prove a number of results\nrelating them to fundamental aspects of randomness, Kolmogorov complexity, prediction, Boolean\ncircuit-size complexity, polynomial-time degrees, and data compression. Aside from the above\ncharacterization of packing dimension, our two main theorems are the following.\n1. If \u03b2~ = (\u03b20 , \u03b21 , . . .) is a computable sequence of biases that are bounded away from 0 and R is\n~ then the dimension and strong dimension of R are the lower and\nrandom with respect to \u03b2,\n~\nupper average entropies, respectively, of \u03b2.\n2. For each pair of \u220602 -computable real numbers 0 \u2264 \u03b1 \u2264 \u03b2 \u2264 1, there exists A \u2208 E such that\nthe polynomial-time many-one degree of A has dimension \u03b1 in E and strong dimension \u03b2 in\nE.\nOur proofs of these theorems use a new large deviation theorem for self-information with respect\n~\nto a bias sequence \u03b2.\n\n\f1\n\nIntroduction\n\nHausdorff dimension \u2013 a powerful tool of fractal geometry developed by Hausdorff [12] in 1919\n\u2013 was effectivized in 2000 by Lutz [20, 21]. This has led to a spectrum of effective versions of\nHausdorff dimension, including constructive, computable, polynomial-space, polynomial-time, and\nfinite-state dimensions. Work by several investigators has already used these effective dimensions\nto illuminate a variety of topics in algorithmic information theory and computational complexity\n[20, 21, 1, 7, 26, 16, 15, 11, 13, 14, 10]. (See [25] for a survey of some of these results.) This work has\nalso underscored and renewed the importance of earlier work by Ryabko [27, 28, 29, 30], Staiger\n[36, 37, 38], and Cai and Hartmanis [5] relating Kolmogorov complexity to classical Hausdorff\ndimension. (See Section 6 of [21] for a discussion of this work.)\nThe key to all these effective dimensions is a simple characterization of classical Hausdorff\ndimension in terms of gales, which are betting strategies that generalize martingales. (Martingales,\nintroduced by L\u00e9vy [18] and Ville [44] have been used extensively by Schnorr [31, 32, 33] and others\nin the investigation of randomness and by Lutz [22, 23] and others in the development of resourcebounded measure.) Given this characterization, it is a simple matter to impose computability\nand complexity constraints on the gales to produce the above-mentioned spectrum of effective\ndimensions.\nIn the 1980s, a new concept of fractal dimension, called the packing dimension, was introduced\nindependently by Tricot [41] and Sullivan [39]. Packing dimension shares with Hausdorff dimension\nthe mathematical advantage of being based on a measure. Over the past two decades, despite its\ngreater complexity (requiring an extra optimization over all countable decompositions of a set in\nits definition), packing dimension has become, next to Hausdorff dimension, the most important\nnotion of fractal dimension, yielding extensive applications in fractal geometry and dynamical\nsystems [8, 9].\nThe main result of this paper is a proof that packing dimension can also be characterized in\nterms of gales. Moreover, notwithstanding the greater complexity of packing dimension's definition\n(and the greater complexity of its behavior on compact sets, as established by Mattila and Mauldin\n[24]), our gale characterization of packing dimension is an exact dual of \u2013 and every bit as simple\nas \u2013 the gale characterization of Hausdorff dimension. (This duality and simplicity are in the\nstatement of our gale characterization; its proof is perforce more involved than its counterpart for\nHausdorff dimension.)\nEffectivizing our gale characterization of packing dimension produces for each of the effective dimensions above an effective strong dimension that is its exact dual. Just as the Hausdorff dimension\nof a set is bounded above by its packing dimension, the effective dimension of a set is bounded above\nby its effective strong dimension. Moreover, just as in the classical case, the effective dimension\ncoincides with the strong effective dimension for sets that are sufficiently regular.\nAfter proving our gale characterization and developing the effective strong dimensions and some\nof their basic properties, we prove a number of results relating them to fundamental aspects of\nrandomness, Kolmogorov complexity, prediction, Boolean circuit-size complexity, polynomial-time\ndegrees, and data compression. Our two main theorems along these lines are the following.\n1. If \u03b4 > 0 and \u03b2~ = (\u03b20 , \u03b21 , . . .) is a computable sequence of biases with each \u03b2i \u2208 [\u03b4, 21 ], then\nevery sequence R that is random with respect to \u03b2~ has dimension\nn\u22121\n\n1X\nH(\u03b2i )\ndim(R) = lim inf\nn\u2192\u221e n\ni=0\n\n1\n\n\fand strong dimension\nn\u22121\n\n1X\nH(\u03b2i ),\nDim(R) = lim sup\nn\u2192\u221e n\ni=0\n\nwhere H(\u03b2i ) is the Shannon entropy of \u03b2i .\n\n2. For every pair of \u220602 -computable real numbers 0 \u2264 \u03b1 \u2264 \u03b2 \u2264 1 there is a decision problem\nA \u2208 E such that the polynomial-time many-one degree of A has dimension \u03b1 in E and strong\ndimension \u03b2 in E.\nIn order to prove these theorems, we prove a new large deviation theorem for the self-information\nlog \u03b2~1 , where \u03b2~ is as in 1 above.\n\u03bc (w)\nPn\u22121\nA corollary of theorem 1 above is that, if the average entropies n1 i=0\nH(\u03b2i ) converge to a\n~\n~\nlimit H(\u03b2) as n \u2192 \u221e, then dim(R) = Dim(R) = H(\u03b2). Since the convergence of these average\nentropies is a much weaker condition than the convergence of the biases \u03b2n as n \u2192 \u221e, this corollary\nsubstantially strengthens Theorem 7.7 of [21].\nOur remaining results are much easier to prove, but their breadth makes a strong prima facie\ncase for the utility of effective strong dimension. They in several cases explain dual concepts that\nhad been curiously neglected in earlier work, and they are likely to be useful in future applications.\nIt is to be hoped that we are on the verge of seeing the full force of fractal geometry applied\nfruitfully to difficult problems in the theory of computing.\n\n2\n\nPreliminaries\n\nWe use the set Z of integers, the set Z+ of (strictly) positive integers, the set N of natural numbers\n(i.e., nonnegative integers), the set Q of rational numbers, the set R of real numbers, and the set\n[0, \u221e) of nonnegative reals. All logarithms in this paper are base 2.\nA string is a finite, binary string w \u2208 {0, 1}\u2217 . We write |w| for the length of a string w and\n\u03bb for the empty string. For i, j \u2208 {0, . . . , |w| \u2212 1}, we write w[i..j] for the string consisting of the\nith through the j th bits of w and w[i] for w[i..i], the ith bit of w. Note that the 0th bit w[0] is the\nleftmost bit of w and that w[i..j] = \u03bb if i > j. A sequence is an infinite, binary sequence. If S is\na sequence and i, j \u2208 N, then the notations S[i..j] and S[i] are defined exactly as for strings. We\nwork in the Cantor space C consisting of all sequences. A string w \u2208 {0, 1}\u2217 is a prefix of a sequence\nS \u2208 C, and we write w \u2291 S, if S[0..|w| \u2212 1] = w. The cylinder generated by a string w \u2208 {0, 1}\u2217 is\nCw = {S \u2208 C|w \u2291 S}. Note that C\u03bb = C.\nGiven a set A \u2286 {0, 1}\u2217 and n \u2208 N, we use the abbreviations A=n = A \u2229 {0, 1}n and A\u2264n =\nA \u2229 {0, 1}\u2264n . A prefix set is a set A \u2286 {0, 1}\u2217 such that no element of A is a prefix of another\nelement of A.\nFor each i \u2208 N we define a class Gi of functions from N into N as follows.\nG0 = {f | (\u2203k)(\u2200\u221e n)f (n) \u2264 kn}\nGi+1 = 2Gi (log n) = {f | (\u2203g \u2208 Gi )(\u2200\u221e n)f (n) \u2264 2g(log n) }\nWe also define the functions \u011di \u2208 Gi by \u011d0 (n) = 2n, \u011di+1 (n) = 2\u011di (log n) . We regard the functions in\nthese classes as growth rates. In particular, G0 contains the linearly bounded growth rates and G1\ncontains the polynomially bounded growth rates. It is easy to show that each Gi is closed under\n2\n\n\fcomposition, that each f \u2208 Gi is o(\u011di+1 ), and that each \u011di is o(2n ). Thus Gi contains superpolynomial growth rates for all i > 1, but all growth rates in the Gi -hierarchy are subexponential.\nLet CE be the class of computably enumerable languages. Within the class DEC of all decidable languages, we are interested in the exponential complexity classes Ei = DTIME(2Gi\u22121 ) and\nEi SPACE = DSPACE(2Gi\u22121 ) for i \u2265 1. The much-studied classes E = E1 = DTIME(2linear ),\nE2 = DTIME(2polynomial ), and ESPACE = E1 SPACE = DSPACE(2linear ) are of particular interest.\nWe use the following classes of functions.\nall = {f | f : {0, 1}\u2217 \u2192 {0, 1}\u2217 }\ncomp = {f \u2208 all | f is computable}\npi = {f \u2208 all | f is computable in Gi time} (i \u2265 1)\npi space = {f \u2208 all | f is computable in Gi space} (i \u2265 1)\n(The length of the output is included as part of the space used in computing f .) We write p for\np1 and pspace for p1 space.\nA constructor is a function \u03b4 : {0, 1}\u2217 \u2192 {0, 1}\u2217 that satisfies x\u228f\n6= \u03b4(x) for all x. The result\nof a constructor \u03b4 (i.e., the language constructed by \u03b4) is the unique language R(\u03b4) such that\n\u03b4n (\u03bb) \u2291 R(\u03b4) for all n \u2208 N. Intuitively, \u03b4 constructs R(\u03b4) by starting with \u03bb and then iteratively\ngenerating successively longer prefixes of R(\u03b4). We write R(\u2206) for the set of languages R(\u03b4) such\nthat \u03b4 is a constructor in \u2206. The following facts are the reason for our interest in the above-defined\nclasses of functions.\nR(all) = C.\nR(comp) = DEC.\nFor i \u2265 1, R(pi )=Ei .\nFor i \u2265 1, R(pi space) = Ei SPACE.\nIf D is a discrete domain (such as N, {0, 1}\u2217 , N \u00d7 {0, 1}\u2217 , etc.), then a function f : D \u2212\u2192 [0, \u221e)\nis \u2206-computable if there is a function f\u02c6 : N \u00d7 D \u2212\u2192 Q \u2229 [0, \u221e) such that |f\u02c6(r, x) \u2212 f (x)| \u2264 2\u2212r\nfor all r \u2208 N and x \u2208 D and f\u02c6 \u2208 \u2206 (with r coded in unary and the output coded in binary). We\nsay that f is exactly \u2206-computable if f : D \u2212\u2192 Q \u2229 [0, \u221e) and f \u2208 \u2206. We say that f is lower\nsemicomputable if there is a computable function f\u02c6 : D \u00d7 N \u2192 Q such that\n(a) for all (x, t) \u2208 D \u00d7 N, f\u02c6(x, t) \u2264 f\u02c6(x, t + 1) < f (x), and\n(b) for all x \u2208 D, limt\u2192\u221e f\u02c6(x, t) = f (x).\nLet k be a positive integer. A k-account finite-state gambler (k-account FSG) is a tuple G =\n(Q, \u03b4, \u03b2, q0 , c~0 ) where\n\u2022 Q is a nonempty, finite set of states,\n\u2022 \u03b4 : Q \u00d7 {0, 1} \u2192 Q is the transition function,\n\u2022 \u03b2 : {1, . . . , k} \u00d7 Q \u00d7 {0, 1} \u2192 Q \u2229 [0, 1] is the betting function,\n\u2022 q0 \u2208 Q is the initial state, and\n\u2022 c~0 is the initial capital vector, a sequence of k nonnegative rational numbers.\nThe betting function satisfies \u03b2(i, q, 0) + \u03b2(i, q, 1) = 1 for each q \u2208 Q and 1 \u2264 i \u2264 k. We use the\nstandard extension \u03b4\u2217 : \u03a3\u2217 \u2192 Q of \u03b4 defined recursively by \u03b4\u2217 (\u03bb) = q0 and \u03b4\u2217 (wb) = \u03b4(\u03b4\u2217 (w), b) for\nall w \u2208 {0, 1}\u2217 and b \u2208 {0, 1}.\n3\n\n\f3\n\nFractal Dimensions\n\nIn this section we briefly review the classical definitions of some fractal dimensions and the relationships among them. Since we are primarily interested in binary sequences and (equivalently)\ndecision problems, we focus on fractal dimension in the Cantor space C.\nFor each k \u2208 N, we let Ak be the collection of all prefix sets A such that A<k = \u2205. For each\nX \u2286 C, we then define the families\n)\n(\n[\nCw ,\nAk (X) =\nA \u2208 Ak X \u2286\nw\u2208A\n\nBk (X) = {A \u2208 Ak |(\u2200w \u2208 A)Cw \u2229 X 6= \u2205 } .\n\nIf A \u2208 Ak (X), then we say that the prefix set A covers the set X. If A \u2208 Bk (X), then we call the\nprefix set A a packing of X. For X \u2208 C, s \u2208 [0, \u221e), and k \u2208 N, we then define\nX\ninf\n2\u2212s|w| ,\nHks (X) =\nA\u2208Ak (X)\n\nPks (X)\n\n=\n\nsup\n\nw\u2208A\n\nX\n\n2\u2212s|w|.\n\nA\u2208Bk (X) w\u2208A\n\nSince Hks (X) and Pks (X) are monotone in k, the limits\nH s (X) =\ns\nP\u221e\n(X) =\n\nlim Hks (X),\n\nk\u2192\u221e\n\nlim Pks (X)\n\nk\u2192\u221e\n\nexist, though they may be infinite. We then define\n)\n(\u221e\n\u221e\n[\nX\ns\ns\nXi .\nP\u221e (Xi ) X \u2286\nP (X) = inf\n\n(3.1)\n\ni=0\n\ni=0\n\nThe set functions H s and P s have the technical properties of an outer measure [8], and the\n(possibly infinite) quantities H s (X) and P s (X) are thus known as the s-dimensional Hausdorff\n(outer) measure of X and the s-dimensional packing (outer) measure of X, respectively. The set\ns is not an outer measure; this is the reason for the extra optimization (3.1) in the\nfunction P\u221e\ndefinition of the packing measure.\nDefinition. Let X \u2286 C.\n1. The Hausdorff dimension of X is dimH (X) = inf{s \u2208 [0, \u221e)|H s (X) = 0}.\n2. The packing dimension of X is dimP (X) = inf{s \u2208 [0, \u221e)|P s (X) = 0}.\nThe proof of our main result uses a well-known characterization of packing dimension as a\nmodified box dimension. For each X \u2286 C and n \u2208 N, let\nNn (X) = {w \u2208 {0, 1}n |(\u2203S \u2208 X)w \u2291 S} .\n\n4\n\n\fThen the upper box dimension of X is\ndimB (X) = lim sup\nn\u2192\u221e\n\nlog Nn (X)\n.\nn\n\n(3.2)\n\nThe lower box dimension dimB (X), which we do not use here, is obtained by using a limit inferior\nin place of the limit superior in (3.2). When dimB (X) = dimB (X), this quantity, written dimB (X),\nis called the box dimension of X.\nBox dimensions are over 60 years old, have been re-invented many times, and have been named\nmany things, including Minkowski dimension, Kolmogorov entropy, Kolmogorov dimension, topological entropy, metric dimension, logarithmic density, and information dimension. Box dimensions\nare often used in practical applications of fractal geometry because they are easy to estimate, but\nthey are not well-behaved mathematically. The modified upper box dimension\n)\n(\n\u221e\n[\n(3.3)\nXi\ndimMB (X) = inf sup dimB (Xi ) X \u2286\ni\n\ni=0\n\nis much better behaved. (Note that (3.3), like (3.1), is an optimization over all countable decompositions of X.) In fact, the following relations are well-known [8].\nTheorem 3.1. For all X \u2286 C, 0 \u2264 dimH (X) \u2264 dimMB (X) = dimP (X) \u2264 dimB (X) \u2264 1.\nThe above dimensions are monotone, i.e., X \u2286 Y implies dim(X) \u2264 dim(Y ), and stable, i.e.,\ndim(X \u222a Y ) = max{dim(X), dim(Y )}. The Hausdorff and packing dimensions are also countably\nstable, i.e., dim(\u222a\u221e\ni=0 Xi ) = sup{dim(Xi )|i \u2208 N}.\n\n4\n\nGale Characterizations\n\nIn this section we review the gale characterization of Hausdorff dimension and prove our main\ntheorem, which is the dual gale characterization of packing dimension.\nDefinition. Let s \u2208 [0, \u221e).\n1. An s-supergale is a function d : {0, 1}\u2217 \u2212\u2192 [0, \u221e) that satisfies the condition\nd(w) \u2265 2\u2212s [d(w0) + d(w1)]\n\n(4.1)\n\nfor all w \u2208 {0, 1}\u2217 .\n2. An s-gale is an s-supergale that satisfies (4.1) with equality for all w \u2208 {0, 1}\u2217 .\n3. A supermartingale is a 1-supergale.\n4. A martingale is a 1-gale.\nIntuitively, we regard a supergale d as a strategy for betting on the successive bits of a sequence\nS \u2208 C. More specifically d(w) is the amount of capital that d has after betting on the prefix w\nof S. If s = 1, then the right-hand side of (4.1) is the conditional expectation of d(wb) given that\nw has occurred (when b is a uniformly distributed binary random variable). Thus a martingale\nmodels a gambler's capital when the payoffs are fair. (The expected capital after the bet is the\nactual capital before the bet.) In the case of an s-gale, if s < 1, the payoffs are less than fair; if\ns > 1, the payoffs are more than fair.\nWe use the following known generalization of the Kraft inequality.\n5\n\n\fLemma 4.1. (LutzP\n[20]) Let s \u2208 [0, \u221e). If d is an s-supergale and B \u2286 {0, 1}\u2217 is a prefix set, then\n\u2217\nfor all w \u2208 {0, 1} , u\u2208B 2\u2212s|u| d(wu) \u2264 d(w).\nWe now define two criteria for the success of a gale or supergale.\n\nDefinition. Let d be an s-supergale, where s \u2208 [0, \u221e).\n1. We say that d succeeds on a sequence S \u2208 C if\nlim sup d(S[0..n \u2212 1]) = \u221e.\n\n(4.2)\n\nn\u2192\u221e\n\nThe success set of d is S \u221e [d] = {S \u2208 C|d succeeds on S}.\n2. We say that d succeeds strongly on a sequence S \u2208 C if\nlim inf d(S[0..n \u2212 1]) = \u221e.\nn\u2192\u221e\n\n(4.3)\n\n\u221e [d] = {S \u2208 C|d succeeds strongly on S}.\nThe strong success set of d is Sstr\n\nWe have written conditions (4.2) and (4.3) in a fashion that emphasizes their duality. Condition\n(4.2) says simply that the set of values d(S[0..n \u2212 1]) is unbounded, while condition (4.3) says that\nd(S[0..n \u2212 1]) \u2192 \u221e as n \u2192 \u221e.\nNotation. Let X \u2286 C.\n1. G(X) is the set of all s \u2208 [0, \u221e) for which there exists an s-gale d such that X \u2286 S \u221e [d].\n\u221e [d].\n2. G str (X) is the set of all s \u2208 [0, \u221e) for which there exists an s-gale d such that X \u2286 Sstr\n\nb\n3. G(X)\nis the set of all s \u2208 [0, \u221e) for which there exists an s-supergale d such that X \u2286 S \u221e [d].\n\n\u221e [d].\n4. Gbstr (X) is the set of all s \u2208 [0, \u221e) for which there exists an s-supergale d such that X \u2286 Sstr\n\nb\nNote that s\u2032 \u2265 s \u2208 G(X) implies that s\u2032 \u2208 G(X), and similarly for the classes G str (X), G(X),\nstr\nb\nand G (X). The following fact is also clear.\n\nb\nObservation 4.2. For all X \u2286 C, G(X) = G(X)\nand G str (X) = Gbstr (X).\nFor Hausdorff dimension, we have the following known fact.\n\nTheorem 4.3. (Gale Characterization of Hausdorff Dimension \u2013 Lutz [20]) For all X \u2286 C,\ndimH (X) = inf G(X).\nOur main result is the following dual of Theorem 4.3.\nTheorem 4.4. (Gale Characterization of Packing Dimension) For all X \u2286 C, dimP (X) = inf G str (X).\nb\nBy Observation 4.2, we could equivalently use G(X)\nand Gbstr (X) in Theorems 4.3 and 4.4,\nrespectively. We will use the following lemma to prove Theorem 4.4.\nS\nLemma 4.5. For each family of sets {Xk \u2286 C |k \u2208 N }, inf G str ( k Xk ) = supk inf G str (Xk ).\n6\n\n\fS\nstr (\nstr\nProof. The inequality inf GS\nk Xk ) \u2265 supk inf G (Xk ) holds trivially.\nstr\nstr\nTo prove that inf G ( k Xk ) \u2264 supk inf G (Xk ), let s > supk inf G str (Xk ). Then for each\n\u221e [d ]. We define an s-gale d by\nk \u2208 N there is an s-gale dk such that Xk \u2286 Sstr\nk\nd(w) =\n\nX 2\u2212k\n* dk (w)\ndk (\u03bb)\n\nk\u2208N\n\nfor all w \u2208 {0, 1}\u2217 . Then for each k, for any S \u2208 Xk , we have\nd(S[0..n \u2212 1]) \u2265\n\u221e [d]. Therefore\nfor all n, so S \u2208 Sstr\n\nS\n\nk\n\n2\u2212k\n* dk (S[0..n \u2212 1])\ndk (\u03bb)\n\n\u221e [d] and the lemma follows.\nXk \u2286 Sstr\n\nProof of Theorem 4.4. Let X \u2286 C. By Theorem 3.1, it suffices to show that dimMB (X) =\ninf G str (X).\nTo see that dimMB (X) \u2264 inf G str (X), let s > inf G str (X). It suffices to show that dimMB (X) \u2264 s.\n\u221e [d]. For each n \u2208 N, let\nBy our choice of s, there is an s-gale d such that X \u2286 Sstr\nBn = {w \u2208 {0, 1}n |d(w) > d(\u03bb)}\nand\nYn = {S \u2208 C|S[0..n \u2212 1] \u2208 Bn }.\nFor each i \u2208 N, let\nXi =\n\n\u221e\n\\\n\nYn ,\n\n\u221e\n[\n\nXi .\n\nn=i\n\nand note that\nX\u2286\n\n(4.4)\n\ni=0\n\nFor all n \u2265 i \u2208 N, we have Xi \u2286 Yn , whence the generalized Kraft inequality (Lemma 4.1) tells us\nthat\nNn (Xi ) \u2264 Nn (Yn ) = |Bn | < 2sn .\nIt follows that, for all i \u2208 N,\ndimB (Xi ) = lim sup\nn\u2192\u221e\n\nlog Nn (Xi )\n\u2264 s,\nn\n\nwhence by (4.4),\ndimMB (X) \u2264 sup dimB (Xi ) \u2264 s.\ni\u2208N\n\nTo see that inf G str (X) \u2264 dimMB (X), let s > s\u2032 > s\u2032\u2032 > dimMB (X). It suffices to show\nS that\ninf G str (X) \u2264 s. Since s\u2032\u2032 > dimMB (X), there exist sets X0 , X1 , . . . \u2286 C such that X = \u221e\ni=0 Xi\nand dimB (Xi ) < s\u2032\u2032 for all i \u2208 N. By Lemma 4.5, it suffices to show that s \u2208 G str (Xi ) for all i \u2208 N.\nFix i \u2208 N. Since dimB (Xi ) < s\u2032\u2032 , there exists n0 \u2208 N such that, for all n \u2265 n0 , log Nnn (Xi ) < s\u2032\u2032 ,\n\u2032\u2032\ni.e., Nn (Xi ) < 2s n . For each n \u2265 n0 , let\nAn = {S[0..n \u2212 1]|S \u2208 Xi }\n7\n\n\f(noting that |An | = Nn (Xi )), and define dn : {0, 1}\u2217 \u2192 [0, \u221e) by\n\uf8f1\nX\n\u2032\n(s\u2212s\u2032 )|w|\n\uf8f4\n2\u2212s |u|\nif |w| \u2264 n\n\uf8f22\nu\ndn (w) =\nwu\u2208An\n\uf8f4\n\uf8f3 (s\u22121)(|w|\u2212n)\n2\ndn (w[0..n \u2212 1]) if |w| > n.\n\n\u2032\n\nIt is routine to verify that dn P\nis an s-gale for each n \u2265 n0 . Note also that dn (w) = 2(s\u2212s )n for all\nn \u2265 n0 and w \u2208 An . Let d = \u221e\nn=n0 dn . Then\nd(\u03bb) =\n<\n\n\u221e\nX\n\nn=n0\n\u221e\nX\n\ndn (\u03bb) =\n\n\u221e\nX\n\n\u2032\n\n|An |2\u2212s n =\n\n\u2032\u2032 \u2212s\u2032 )n\n\n\u2032\n\nNn (Xi )2\u2212s n\n\nn=n0\n\nn=n0\n\n2(s\n\n\u221e\nX\n\n< \u221e,\n\nn=n0\n\nso d is an s-gale by linearity. Let S \u2208 Xi . Then, for all n \u2265 n0 , S[0..n \u2212 1] \u2208 An , so\n\u2032\n\nd(S[0..n \u2212 1]) \u2265 dn (S[0..n \u2212 1]) \u2265 2(s\u2212s )n .\n\u221e [d]. This shows that X \u2286 S \u221e [d], whence s \u2208 G str (X ).\nThus S \u2208 Sstr\ni\ni\nstr\n\n5\n\nEffective Strong Dimensions\n\nTheorem 4.3 has been used to effectivize Hausdorff dimension at a variety of levels. In this section\nwe review these effective dimensions while using Theorem 4.4 to develop the dual effective strong\ndimensions.\nWe define a gale or supergale to be constructive if it is lower semicomputable. For any s \u2208 [0, \u221e)\n(s)\nand any k-account FSG G an s-gale dG is defined as follows [7]. (Recall that finite-state gamblers\n(s)\nwere defined in Section 2.) For each 1 \u2264 i \u2264 k we define an s-gale dG,i by the recursion\n(s)\n\ndG,i (\u03bb) = c0,i\n(s)\n\n(s)\n\ndG,i (wb) = 2s dG,i (w)\u03b2(i, \u03b4\u2217 (w), b)\nfor all w \u2208 {0, 1}\u2217 and b \u2208 {0, 1}. Then\n(s)\ndG\n\n=\n\nk\nX\n\n(s)\n\ndG,i .\n\ni=1\n\n(s)\n\nWe define an s-gale d to be finite-state if there is a finite-state gambler (FSG) G such that dG = d.\nFor the rest of this paper, \u2206 denotes one of the classes all, comp, p, pspace, p2 , p2 space, etc. defined\nin Section 2.\nFor each \u0393 \u2208 {constr, \u2206, FS} and X \u2286 C, we define the sets G\u0393 (X), G\u0393str (X), Gb\u0393 (X), and\nb\nGb\u0393str (X) just as the classes G(X), G str (X), G(X),\nand Gbstr (X) were defined in Section 4, but with\nthe following modifications.\n(i) If \u0393 = constr, then d is required to be constructive.\n8\n\n\f(ii) If \u0393 = \u2206, then d is required to be \u2206-computable.\nstr (X), d is required to be finite-state.\n(iii) In GFS (X) and GFS\nstr (X) are not defined.\n(iv) GbFS (X) and GbFS\n\nThe following effectivizations of Hausdorff and packing dimension are motivated by Theorems\n4.3 and 4.4.\nDefinition. Let X \u2286 C and S \u2208 C.\n1. [21] The constructive dimension of X is cdim(X) = inf Gconstr (X).\nstr\n2. The constructive strong dimension of X is cDim(X) = inf Gconstr\n(X).\n\n3. [21] The dimension of S is dim(S) = cdim({S}).\n4. The strong dimension of S is Dim(S) = cDim({S}).\n5. [20] The \u2206-dimension of X is dim\u2206 (X) = inf G\u2206 (X).\nstr (X).\n6. The \u2206-strong dimension of X is Dim\u2206 (X) = inf G\u2206\n\n7. [20] The dimension of X in R(\u2206) is dim(X|R(\u2206)) = dim\u2206 (X \u2229 R(\u2206)).\n8. The strong dimension of X in R(\u2206) is Dim(X|R(\u2206)) = Dim\u2206 (X \u2229 R(\u2206)).\n9. [7] The finite-state dimension of X is dimFS (X) = inf GFS (X).\nstr (X).\n10. The finite-state strong dimension of X is DimFS (X) = inf GFS\n\n11. [7] The finite-state dimension of S is dimFS (S) = dimFS ({S}).\n12. The finite-state strong dimension of S is DimFS (S) = DimFS ({S}).\nIn parts 1,2,5, and 6 of the above definition, we could equivalently use the \"hatted\" sets\nstr (X) in place of their unhatted counterparts. In the case of\nstr\n(X), Gb\u2206 (X), and Gb\u2206\nGbconstr (X), Gbconstr\nparts 5 and 6, this follows from Lemma 4.7 of [20]. In the case of parts 1 and 2, it follows from the\nmain theorem in [14] (which answered an open question in [21], where Gbconstr (X) was in fact used\nin defining cdim(X)).\nThe polynomial-time dimensions dimp (X) and Dimp (X) are also called the feasible dimension\nand the feasible strong dimension, respectively. The notation dimp (X) for the p-dimension is all\ntoo similar to the notation dimP (X) for the classical packing dimension, but confusion is unlikely\nbecause these dimensions typically arise in quite different contexts.\nNote that the classical Hausdorff and packing dimensions can each now be written in three\ndifferent ways, i.e.,\ndimH (X) = dimall (X) = dim(X|C)\nand\ndimP (X) = Dimall (X) = Dim(X|C).\nObservations 5.1.\n1. Each of the dimensions that we have defined is monotone (e.g., X \u2286 Y\nimplies cdim(X) \u2264 cdim(Y )).\n9\n\n\f2. Each of the effective strong dimensions is bounded below by the corresponding effective dimension (e.g., cdim(X) \u2264 cDim(X)).\n3. Each of the dimensions that we have defined is nonincreasing as the effectivity constraint is\nrelaxed (e.g., dimH (X) \u2264 cdim(X) \u2264 dimpspace (X) \u2264 dimFS (X)).\n4. Each of the dimensions that we have defined is nonnegative and assigns C the dimension 1.\nLemma 5.2. The finite-state dimensions are stable, i.e., for all X, Y \u2286 C,\ndimFS (X \u222a Y ) = max{dimFS (X), dimFS (Y )}\nand\nDimFS (X \u222a Y ) = max{DimFS (X), DimFS (Y )}.\nProof. The stability of finite-state dimension was proved in [7]. The same arguments establish\nstability for finite-state strong dimension.\nDefinition. Let X, X0 , X1 , X2 , . . . \u2286 C.\nS\n1. We say that X is a \u2206-union of the \u2206-dimensioned sets {Xk |k \u2208 N} if X = \u221e\nk=0 Xk and for\neach s > supk\u2208N dim\u2206 (Xk ) with 2s rational, there is a function d : N \u00d7 {0, 1}\u2217 \u2192 [0, \u221e) with\nthe following three properties.\n(i) d is \u2206-computable.\n(ii) For each k \u2208 N, if we write dk (w) = d(k, w), then the function dk is an s-gale.\n(iii) For each k \u2208 N, Xk \u2286 S \u221e [dk ].\nAnalogously, X is a \u2206-union of the \u2206-strong dimensioned sets {Xk |k \u2208 N} if there is a d\nwith the above properties that also satisfies\n\u221e [d ].\n(iv) For each k \u2208 N, Xk \u2286 Sstr\nk\n\n2. We say that X is a \u2206-union of the sets {Xk |k \u2208 N} dimensioned in R(\u2206) if X =\nand X \u2229 R(\u2206) is an \u2206-union of the \u2206-dimensioned sets {Xk \u2229 R(\u2206)|k \u2208 N}.\n\nS\u221e\n\nk=0 Xk\n\nAnalogously, X is \u2206-union of the sets {Xk |k \u2208 N} strong dimensioned in R(\u2206) if X =\nS\n\u221e\nk=0 Xk and X \u2229 R(\u2206) is an \u2206-union of the \u2206-strong dimensioned sets {Xk \u2229 R(\u2206)|k \u2208 N}.\n\nLemma 5.3. The dimensions defined from \u2206 are \u2206-countably stable, i.e., if X is a \u2206-union of\nthe \u2206-dimensioned sets X0 , X1 , X2 , . . . , then\ndim\u2206 (X) = sup dim\u2206 (Xk ),\nk\u2208N\n\nand if X is a \u2206-union of the \u2206-strong dimensioned sets X0 , X1 , X2 , . . ., then\nDim\u2206 (X) = sup Dim\u2206 (Xk ),\nk\u2208N\n\nand similarly for dimension and strong dimension in R(\u2206).\nProof. The stability of dim\u2206 over \u2206-unions was proved in [20]. The proof for strong dimension is\nanalogous.\n10\n\n\fLemma 5.4. The constructive dimensions are absolutely stable, i.e., for all X \u2286 C,\ncdim(X) = sup dim(S)\nS\u2208X\n\nand\ncDim(X) = sup Dim(S).\nS\u2208X\n\nProof. The absolute stability of constructive dimension was proved in [21] using optimal constructive supergales. The same argument works for constructive strong dimension.\n\n6\n\nAlgorithmic Information\n\nIn this section we present a variety of results and observations in which constructive and computable\nstrong dimensions illuminate or clarify various aspects of algorithmic information theory. Included\nis our second main theorem, which says that every sequence that is random with respect to a\ncomputable sequence of biases \u03b2i \u2208 [\u03b4, 1/2] has the lower and upper average entropies of (\u03b20 , \u03b21 , . . .)\nas its dimension and strong dimension, respectively. We also present a result in which finite-state\nstrong dimension clarifies an issue in data compression.\nMayordomo [26] proved that for all S \u2208 C,\ndim(S) = lim inf\nn\u2192\u221e\n\nK(S[0..n \u2212 1])\n,\nn\n\n(6.1)\n\nwhere K(w) is the Kolmogorov complexity of w [19]. Subsequently, Lutz [21] used termgales to\ndefine the dimension dim(w) of each (finite!) string w \u2208 {0, 1}\u2217 and proved that\ndim(S) = lim inf dim(S[0..n \u2212 1])\n\n(6.2)\n\nK(w) = |w|dim(w) \u00b1 O(1)\n\n(6.3)\n\nn\u2192\u221e\n\nfor all S \u2208 C and\nfor all w \u2208 {0, 1}\u2217 , thereby giving a second proof of (6.1). The following theorem is a dual of (6.2)\nthat yields a dual of (6.1) as a corollary.\nTheorem 6.1. For all S \u2208 C,\nDim(S) = lim sup dim(S[0..n \u2212 1]).\nn\u2192\u221e\n\nProof. This proof is analogous to the one for the dual statement (6.2) given in [21].\nCorollary 6.2. For all S \u2208 C,\nDim(S) = lim sup\nn\u2192\u221e\n\nK(S[0..n \u2212 1])\n.\nn\n\nBy Corollary 6.2, the \"upper algorithmic dimension\" defined by Tadaki [40] is precisely the\nconstructive strong dimension.\nThe rate at which a gambler can increase its capital when betting in a given situation is a\nfundamental concern of classical and algorithmic information and computational learning theories.\nIn the setting of constructive gamblers, the following quantities are of particular relevance.\n11\n\n\fDefinition. Let d be a supermartingale, let S \u2208 C, and let X \u2286 C.\n1. The lower d-Lyapunov exponent of S is \u03bbd (S) = lim inf n\u2192\u221e\n\nlog d(S[0..n\u22121])\n.\nn\n\n2. The upper d-Lyapunov exponent of S is \u039bd (S) = lim supn\u2192\u221e\n\nlog d(S[0..n\u22121])\n.\nn\n\n3. The lower Lyapunov exponent of S is \u03bb(S) = sup{\u03bbd (S)|d is a constructive supermartingale}.\n4. The upper Lyapunov exponent of S is \u039b(S) = sup{\u039bd (S)|d is a constructive supermartingale}.\n5. The lower Lyapunov exponent of X is \u03bb(X) = inf S\u2208X \u03bb(S).\n6. The upper Lyapunov exponent of X is \u039b(X) = inf S\u2208X \u039b(S).\nLyapunov exponents such as these were investigated by Schnorr [32, 34], Ryabko [30], and\nStaiger [37, 38] (using slightly different notations) prior to the effectivization of Hausdorff dimension.\nThe quantities \u03bbd (S) and \u039bd (S) are also called \"exponents of increase\" of d on S. It is implicit in\nStaiger's paper [37] that\n\u039bcomp (S) = 1 \u2212 dimcomp (S)\nfor all S \u2208 C, where \u039bcomp (S) is defined like \u039b(S) above, but with d required to be a computable\nmartingale. Similar reasoning leads to the following characterizations of the Lyapunov exponents.\nTheorem 6.3. Let S \u2208 C and X \u2286 C. Then \u039b(S) = 1 \u2212 dim(S), \u03bb(S) = 1 \u2212 Dim(S), \u039b(X) =\n1 \u2212 cdim(X), and \u03bb(X) = 1 \u2212 cDim(X).\nProof. We will show that \u039b(S) = 1 \u2212 dim(S). A similar argument shows that \u03bb(S) = 1 \u2212 Dim(S).\nBy Lemma 5.4, \u039b(X) = 1 \u2212 cdim(X) and \u03bb(X) = 1 \u2212 cDim(X) follow from the statements about\nsequences.\nLet t < s < \u039b(S) with t computable, and let d be a constructive martingale for which \u03bbd (S) >\ns. Then for infinitely many n, d(S[0..n \u2212 1]) > 2sn . Define a constructive (1 \u2212 t)-gale d\u2032 by\nd\u2032 (w) = 2\u2212t|w| d(w) for all w \u2208 {0, 1}\u2217 . Then for infinitely many n, we have d\u2032 (S[0..n \u2212 1]) =\n2\u2212tn d(S[0..n \u2212 1]) > 2(s\u2212t)n , so S \u2208 S \u221e [d]. Therefore dim(S) < 1 \u2212 t. This holds for all computable\nt < \u039b(S), so dim(S) \u2264 1 \u2212 \u039b(S).\nLet s > dim(S) be computable, and let d be a constructive s-gale with S \u2208 S \u221e [d]. Define a\nconstructive martingale d\u2032 by d\u2032 (w) = 2(1\u2212s)|w| d(w) for all w \u2208 {0, 1}\u2217 . For infinitely many n, we\nhave d(S[0..n \u2212 1]) > 1, and for each of these n, d\u2032 (S[0..n \u2212 1]) > 2(1\u2212s)n . Therefore \u039bd\u2032 (S) \u2265 1 \u2212 s,\nso \u039b(S) \u2265 1 \u2212 s. This holds for all s > dim(S), so \u039b(S) \u2265 1 \u2212 dim(S).\nConstructive strong dimension can also be used to characterize entropy rates of the type investigated by Staiger [36, 37] and Hitchcock [15].\nDefinition. Let A \u2286 {0, 1}\u2217 .\n1. The entropy rate of A \u2286 {0, 1}\u2217 is HA = lim supn\u2192\u221e\n\nlog |A=n |\n.\nn\n\n2. We define the sets of sequences\nAi.o. = {S \u2208 C|(\u2203\u221e n)S[0..n \u2212 1] \u2208 A}\nand\nAa.e. = {S \u2208 C|(\u2200\u221e n)S[0..n \u2212 1] \u2208 A}.\n12\n\n\fDefinition. Let X \u2286 C. The constructive entropy rate of X is\nHCE (X) = inf{HA |X \u2286 Ai.o. and A \u2208 CE}\nand the constructive strong entropy rate of X is\nstr\nHCE\n(X) = inf{HA |X \u2286 Aa.e. and A \u2208 CE}.\n\nHitchcock [15] proved that\nHCE (X) = cdim(X)\n\n(6.4)\n\nfor all X \u2286 C. We have the following dual of (6.4).\nstr (X) = cDim(X).\nTheorem 6.4. For any X \u2286 C, HCE\n\nProof. This proof is analogous to the proof of (6.4) given in [15].\nIn the classical case, Tricot [41] has defined a set to be regular if its Hausdorff and packing\ndimensions coincide, and defined its irregularity to be the difference between these two fractal\ndimensions. Analogously, we define the c-irregularity (i.e., constructive irregularity) of a sequence\nS \u2208 C to be Dim(S) \u2212 dim(S), and we define the c-irregularity of a set X \u2286 C to be cDim(X) \u2212\ncdim(X). We define a sequence or set to be c-regular (i.e., constructively regular) if its c-irregularity\nis 0.\nAs the following result shows, the c-irregularity of a sequence may be any real number in [0, 1].\nTheorem 6.5. For any two real numbers 0 \u2264 \u03b1 \u2264 \u03b2 \u2264 1, there is a sequence S \u2208 C such that\ndim(S) = \u03b1 and Dim(S) = \u03b2.\nProof. Let R be a Martin-L\u00f6f random sequence. It is well-known that\nK(R[0..n \u2212 1]) \u2265 n \u2212 O(1).\nWrite R = r1 r2 r3 . . . where |rn | = 2n \u2212 1 for all n. Note that |r1 * * * rn | = n2 .\nFor each n, define\n(\n1\u2212\u03b1\nif log\u2217 n is odd\n\u03b1\n\u03b3n = 1\u2212\u03b2\nif log\u2217 n is even,\n\u03b2\nand let\nkn = \u2308|rn |\u03b3n \u2309 .\nWe now define S \u2208 C as\nS = r1 0k1 r2 0k2 * * * rn 0kn * * * .\nNote that for all n,\n|rn 0kn | = \u2308|rn |(1 + \u03b3n )\u2309\n(\u0006 1\n\u0007\n\u2217\n\u03b1 |rn |m if log n is odd\nl\n=\n1\nif log\u2217 n is even.\n\u03b2 |rn |\n\nLet w \u2291 S. Then for some n,\n\nw = r1 0k1 * * * rn\u22121 0kn\u22121 rn\u2032 0j\n13\n\n(6.5)\n\n\fwhere rn\u2032 \u2291 rn and 0 \u2264 j \u2264 kn . We have\nK(w) \u2264 K(r1 * * * rn\u22121 rn\u2032 ) + K(k1 ) + * * * K(kn\u22121 ) + K(j) + O(1)\n\u2264 |r1 * * * rn\u22121 rn\u2032 | + O(n log n)\n\n(6.6)\n\n2\n\n\u2264 (n \u2212 1) + O(n log n).\nAlso,\nK(r1 * * * rn\u22121 rn\u2032 ) \u2264 K(w) + K(k1 ) + * * * + K(kn\u22121 ) + K(j) + O(1)\n\u2264 K(w) + O(n log n),\nso by (6.5),\nK(w) \u2265 K(r1 * * * rn\u22121 rn\u2032 ) \u2212 O(n log n)\n\u2265 |r1 * * * rn\u22121 rn\u2032 | \u2212 O(n log n)\n\n(6.7)\n\n2\n\n\u2265 (n \u2212 1) \u2212 O(n log n).\nWe bound the length of w in terms of n as\n|w| \u2265 |r1 |(1 + \u03b31 ) + * * * + |rn\u22121 |(1 + \u03b3n\u22121 ) + |rn\u2032 |\n|r1 * * * rn\u22121 |\n\u2265\n\u03b2\n1\n= (n \u2212 1)2\n\u03b2\n\n(6.8)\n\nand\n\n|w| \u2264 |r1 |(1 + \u03b31 ) + * * * + |rn\u22121 |(1 + \u03b3n\u22121 ) + |rn |(1 + \u03b3n ) + n\n|r1 * * * rn\u22121 rn |\n+n\n\u2264\n\u03b1\n1\n\u2264 (n + 1)2 .\n\u03b1\nFrom (6.6) and (6.8), we have\nlim sup\nm\u2192\u221e\n\n(6.9)\n\nK(S[0..m \u2212 1])\n(n \u2212 1)2 + O(n log n)\n= \u03b2,\n\u2264 lim sup\n1\n2\nm\nn\u2192\u221e\n\u03b2 (n \u2212 1)\n\n(6.10)\n\nK(S[0..m \u2212 1])\n(n \u2212 1)2 \u2212 O(n log n)\n= \u03b1.\n\u2265 lim inf\n1\n2\nn\u2192\u221e\nm\n\u03b1 (n + 1)\n\n(6.11)\n\nand (6.7) and (6.9) yield\nlim inf\nm\u2192\u221e\n\nFor each n, let\nwn = r1 0k1 * * * rn 0kn .\nDefine the sequence of towers tj by t0 = 1 and tj+1 = 2tj . If j is even, then for all tj\u22121 < i \u2264 tj ,\n\n14\n\n\f\u03b3i =\n\n1\u2212\u03b2\n\u03b2 .\n\nThen\n|wtj | \u2264 tj +\n\ntj\nX\n\n|ri |(1 + \u03b3i )\n\ni=1\ntj\u22121\n\n= tj +\n\nX\n\n|ri |(1 + \u03b3i ) +\n\ni=1\n\n\u2264 tj +\n\u2264\n\n1\n\u03b2\n\ntj\nX\n\n|ri |\n\ni=tj\u22121 +1\n\n1 2\n1\ntj\u22121 + (t2j \u2212 t2j\u22121 )\n\u03b1\n\u03b2\n\n(6.12)\n\n1 2\nt + tj + O((log tj )2 ).\n\u03b2 j\n\nSimilarly, if j is odd, we have\n|wtj | \u2265\n\ntj\nX\n\n|ri |(1 + \u03b3i )\n\ni=1\ntj\u22121\n\n=\n\nX\n\n|ri |(1 + \u03b3i ) +\n\ni=1\n\n1\n\u03b1\n\ntj\nX\n\n|ri |\n\ni=tj\u22121 +1\n\n(6.13)\n\n1\n1\ntj\u22121 2 + (t2j \u2212 t2j\u22121 )\n\u03b2\n\u03b1\n1 2\n\u2265 tj \u2212 O((log tj )2 ).\n\u03b1\n\n\u2265\n\nCombining (6.7) and (6.12), we have\nlim sup\nm\u2192\u221e\n\nK(S[0..m \u2212 1])\nK(wt2n )\n\u2265 lim sup\n\u2265 \u03b2.\nm\n|wt2n |\nn\u2192\u221e\n\n(6.14)\n\nPutting (6.6) together with (6.13) yields\nlim inf\nm\u2192\u221e\n\nK(wt2n+1 )\nK(S[0..m \u2212 1])\n\u2264 lim inf\n\u2264 \u03b1.\nn\u2192\u221e\nm\n|wt2n+1 |\n\n(6.15)\n\nBy (6.1), (6.11), and (6.15), we have dim(S) = \u03b1. By Corollary 6.2, (6.10), and (6.14), we have\nDim(S) = \u03b2.\nWe now come to the main theorem of this section. The following notation simplifies its statement\nand proof.\nNotation. Given a bias sequence \u03b2~ = (\u03b20 , \u03b21 , . . .), n \u2208 N, and S \u2208 C, let\nn\u22121\n\n~ =\nHn (\u03b2)\n\n1X\nH(\u03b2i ),\nn\ni=0\n\n~ = lim inf Hn (\u03b2),\n~\nH \u2212 (\u03b2)\nn\u2192\u221e\n\n~ = lim sup Hn (\u03b2).\n~\nH (\u03b2)\n+\n\nn\u2192\u221e\n\n~ and H + (\u03b2)\n~ the lower and upper average entropies, respectively, of \u03b2.\n~\nWe call H \u2212 (\u03b2)\n15\n\n\fTheorem 6.6. If \u03b4 \u2208 (0, 21 ] and \u03b2~ is a computable bias sequence with each \u03b2i \u2208 [\u03b4, 21 ], then for\n~\n\nevery sequence R \u2208 RAND\u03b2 ,\n~ and Dim(R) = H + (\u03b2).\n~\ndim(R) = H \u2212 (\u03b2)\nTheorem 6.6 says that every sequence that is random with respect to a suitable bias sequence \u03b2~\nhas the lower and upper average entropies of \u03b2~ as its dimension and strong dimension, respectively.\n~\nSince there exist \u03b2-random\nsequences in \u220602 when \u03b2~ is computable, this gives a powerful and\nflexible method for constructing \u220602 sequences with given (\u220602 -computable) dimensions and strong\ndimensions.\nWe now develop a sequence of results that are used in our proof of Theorem 6.6.\nLemma 6.7. Assume that \u03b4 > 0, \u01eb > 0, and that, for each \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4], \u03b7\u03b2 is a bounded random\nvariable such that E\u03b7\u03b2 \u2264 \u2212\u01eb and Eet\u03b7\u03b2 is a continuous function of \u03b2 for each t > 0. Then there\nexists \u03b8 > 0 such that, for all \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4] and t \u2208 (0, \u03b8],\nEet\u03b7\u03b2 < 1 \u2212\n\nt\u01eb\n.\n2\n\nProof. Assume the hypothesis. Then the Dominated Convergence Theorem [3] tells us that, for all\n\u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4],\nlim\n\nt\u21920+\n\nEet\u03b7\u03b2 \u2212 1\nt\n\net\u03b7\u03b2 \u2212 1\nlim E\nt\nt\u21920+\n\u0013\n\u0012\net\u03b7\u03b2 \u2212 1\n= E lim\nt\nt\u21920+\n\u0012\n\u0013\net\u03b7\u03b2 \u2212 1\n= E \u03b7\u03b2 lim\nt\u03b7\u03b2\nt\u21920+\n= E\u03b7\u03b2\n=\n\n\u2264 \u2212\u01eb.\nHence, for each \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4], there exists t\u03b2 > 0 such that, for all t \u2208 (0, t\u03b2 ],\nEet\u03b7\u03b2 \u2212 1\n3\u01eb\n<\u2212 .\nt\n4\nIt follows by our continuity hypothesis that, for each \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4], there is an open neighborhood\nN\u03b2 of \u03b2 such that, for all t \u2208 (0, t\u03b2 ] and \u03b3 \u2208 N\u03b2 \u2229 [\u03b4, 1 \u2212 \u03b4],\n\u01eb\nEet\u03b7\u03b3 \u2212 1\n<\u2212 .\nt\n2\nThe family G = {N\u03b2 | \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4]} is an open cover of the compact set [\u03b4, 1 \u2212 \u03b4], so there is a finite\nset B \u2286 [\u03b4, 1 \u2212 \u03b4] such that the subcollection G \u2032 = {N\u03b2 | \u03b2 \u2208 B} is also a cover of [\u03b4, 1 \u2212 \u03b4]. Let\n\u03b8 = min{t\u03b2 | \u03b2 \u2208 B}.\nThen \u03b8 > 0 and, for all \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4] and t \u2208 (0, \u03b8],\n\u01eb\nEet\u03b7\u03b2 \u2212 1\n<\u2212 ,\nt\n2\n16\n\n\fwhence\nEet\u03b7\u03b2 < 1 \u2212\n\nt\u01eb\n.\n2\n\nCorollary 6.8. For each \u03b4 > 0 and \u01eb > 0, there exists \u03b8 > 0 such that, for all \u03b2 \u2208 [\u03b4, 1 \u2212 \u03b4], if we\nchoose a \u2208 {0, 1} with Prob[a = 1] = \u03b2, and if\n\u03b7 = \u03be \u2212 H(\u03b2) \u2212 \u01eb\nor\n\u03b7 = H(\u03b2) \u2212 \u03be \u2212 \u01eb,\nwhere\n\n1\n1\n+ a log ,\n1\u2212\u03b2\n\u03b2\n\n\u03be = (1 \u2212 a) log\nthen\n\nEe\u03b8\u03b7 < 1 \u2212\n\n\u03b8\u01eb\n.\n2\n\nProof. The random variables\n\u03b71,\u03b2 = \u03be \u2212 H(\u03b2) \u2212 \u01eb,\n\u03b72,\u03b2 = H(\u03b2) \u2212 \u03be \u2212 \u01eb\nsatisfy the hypothesis of Lemma 6.7 with E\u03b71,\u03b2 = E\u03b72,\u03b2 = \u2212\u01eb, so we can choose \u03b81 > 0 for \u03b71,\u03b2 and\n\u03b82 > 0 for \u03b72,\u03b2 as in that lemma. Letting \u03b8 = min{\u03b81 , \u03b82 } establishes the corollary.\nNotation. Given a bias sequence \u03b2~ = (\u03b20 , \u03b21 , . . .), n \u2208 N, and S \u2208 C, let\n~\nLn (\u03b2)(S)\n= log\n\n1\n\u03bc\u03b2~ (S[0..n \u2212 1])\n\nwhere\n\u03bei (S) = (1 \u2212 S[i]) log\n\n=\n\nn\u22121\nX\n\n\u03bei (S),\n\ni=0\n\n1\n1\n+ S[i] log\n1 \u2212 \u03b2i\n\u03b2i\n\nfor 0 \u2264 i < n.\n~ \u03be0 , . . . , \u03ben\u22121 are random variables with\nNote that Ln (\u03b2),\n~ =\nELn (\u03b2)\n\nn\u22121\nX\ni=0\n\nE\u03bei =\n\nn\u22121\nX\n\n~\nH(\u03b2i ) = nHn (\u03b2).\n\ni=0\n\n~ is very unlikely to deviate significantly\nThe following large deviation theorem tells us that Ln (\u03b2)\nfrom this expected value.\nTheorem 6.9. For each \u03b4 > 0 and \u01eb > 0, there exists \u03b1 \u2208 (0, 1) such that, for all bias sequences\n~ and Hn (\u03b2)\n~ are defined as above,\n\u03b2~ = (\u03b20 , \u03b21 , . . .) with each \u03b2i \u2208 [\u03b4, 1 \u2212 \u03b4] and all n \u2208 Z+ , if Ln (\u03b2)\nthen\n\u0002\n\u0003\n~ \u2212 nHn (\u03b2)|\n~ \u2265 \u01ebn < 2\u03b1n ,\nP |Ln (\u03b2)\n~\n\nwhere the probability is computed according to \u03bc\u03b2 .\n\n17\n\n\fProof. Let \u03b4 > 0 and \u01eb > 0, and choose \u03b8 > 0 as in Corollary 6.8. Let \u03b1 = 1 \u2212 \u03b8\u01eb\n2 , noting that\n+\n~\n~\n~\n\u03b1 \u2208 (0, 1). Let \u03b2 be as given, and let n \u2208 Z . Let L = Ln (\u03b2), H = Hn (\u03b2), and \u03be0 , \u03be1 , . . . be as\nabove. The proof is in two parts.\n1. For each i \u2208 N, let \u03b7i = \u03bei \u2212H(\u03b2i )\u2212\u01eb. Then Markov's inequality, independence, and Corollary\n6.8 tell us that\nP[L \u2212 nH \u2265 \u01ebn] = P [e\u03b8(L\u2212nH) \u2265 e\u03b8\u01ebn ]\n\u2264 e\u2212\u03b8\u01ebn Ee\u03b8(L\u2212nH)\n= Ee\u03b8(L\u2212nH)\u2212\u01eb\u03b8n\nP n\u22121\n\n= Ee\u03b8 i=0 \u03b7i\nn\u22121\nY\ne\u03b8\u03b7i\n= E\n=\n\ni=0\nn\u22121\nY\n\nEe\u03b8\u03b7i\n\ni=0\nn\n\n< \u03b1 .\n\n2. Arguing as in part 1 with \u03b7i = H(\u03b2i ) \u2212 \u03bei \u2212 \u01eb shows that P[nH \u2212 L \u2265 \u01ebn] < \u03b1n .\nBy parts 1 and 2 of this proof, we now have\nP[|L \u2212 nH| \u2265 \u01ebn] < 2\u03b1n .\n\nSome of our arguments are simplified by the following constructive version of a classical theorem\nof Kakutani [17]. Say that two bias sequences \u03b2~ and \u03b2~ \u2032 are square-summably equivalent, and write\n\u221e\nP\n\u03b2~ \u22482 \u03b2~ \u2032 , if\n(\u03b2i \u2212 \u03b2i\u2032 )2 < \u221e.\ni=0\n\nTheorem 6.10. (van Lambalgen [42, 43], Vovk [45]) Let \u03b4 > 0, and let \u03b2~ and \u03b2~ \u2032 be computable\nbias sequences with \u03b2i , \u03b2i\u2032 \u2208 [\u03b4, 1 \u2212 \u03b4] for all i \u2208 N.\n~\n~\u2032\n1. If \u03b2~ \u22482 \u03b2~ \u2032 , then RAND\u03b2 = RAND\u03b2 .\n~T\n~\u2032\n2. If \u03b2~ 6\u22482 \u03b2~ \u2032 , then RAND\u03b2 RAND\u03b2 = \u2205.\n\nCorollary 6.11. If \u03b4 > 0 and \u03b2~ is a computable bias sequence with each \u03b2i \u2208 [\u03b4, 1 \u2212 \u03b4], then there\n~\n~\u2032\nis an exactly computable bias sequence \u03b2~ \u2032 with each \u03b2i\u2032 \u2208 [ 2\u03b4 , \u03b2i ] satisfying RAND\u03b2 = RAND\u03b2 .\nProof. Assume the hypothesis. Then there is a\u0006 computable\nfunction g : N \u00d7 N \u2192 Q such that\n\u0007\n|g(i, r) \u2212 \u03b2i | \u2264 2\u2212r for all i, r \u2208 N. Let m = 2 + log 1\u03b4 , and let\n\u03b2i\u2032 = g(i, m + i) \u2212 2\u2212(m+i)\n\n~\nfor all i \u2208 N. It is easily verified that \u03b2~ \u2032 is exactly computable, each \u03b2i\u2032 \u2208 [ 2\u03b4 , \u03b2i ], and \u03b2~ \u2032 \u22482 \u03b2,\n~\u2032\n\n~\n\nwhence Theorem 6.10 tells us that RAND\u03b2 = RAND\u03b2 .\n18\n\n\fLemma 6.12. If \u03b4 > 0 and \u03b2~ is a computable bias sequence with each \u03b2i \u2208 [\u03b4, 1 \u2212 \u03b4], then every\n~\nsequence R \u2208 RAND\u03b2 satisfies\n~\n~ + o(n)\nLn (\u03b2)(R)\n= nHn (\u03b2)\nas n \u2192 \u221e.\nProof. Assume the hypothesis. By Corollary 6.11, we can assume that \u03b2~ is exactly computable.\nLet \u01eb > 0. For each n \u2208 N, define the set\no\nn\n~\n~ \u2265 \u01ebn ,\n\u2212 nHn (\u03b2)|\nYn = S \u2208 C |Ln (\u03b2)(S)\nand let\n\nX\u01eb = {S \u2208 C | (\u2203\u221e n)S \u2208 Yn }.\n~\n\nIt suffices to show that \u03bc\u03b2comp (X\u01eb ) = 0.\nFor each n \u2208 N and w \u2208 {0, 1}\u2217 , let\n( ~\n\u03bc\u03b2 (Yn |Cw )\ndn (w) =\ndn (w[0..n \u2212 1])\n\nif |w| \u2264 n\nif |w| > n.\n\n~\nIt is easily verified that each dn is a \u03b2-martingale\nand that the function (n, w) 7\u2192 dn (w) is\n1\ncomputable. It is clear that Yn \u2286 S [dn ] for all n \u2208 N. Finally, by Theorem 6.9, the series\n\u221e\nP\ndn (\u03bb) is computably convergent, so the computable first Borel-Cantelli Lemma [22] tells us\nn=0\n\n~\n\nthat \u03bc\u03b2comp (X\u01eb ) = 0.\n\n~\nLemma 6.13. If \u03b4 > 0 and \u03b2~ is a computable bias sequence with each \u03b2i \u2208 [\u03b4, 12 ], then cdim(RAND\u03b2 ) \u2264\n~\n~ and cDim(RAND\u03b2~ ) \u2264 H + (\u03b2).\nH \u2212 (\u03b2)\n\nProof. Assume the hypothesis. By Corollary 6.11, we can assume that \u03b2~ is exactly computable.\nLet s \u2208 [0, \u221e) be computable.\nDefine d : {0, 1}\u2217 \u2192 [0, \u221e) by\n~\nd(w) = 2s|w| \u03bc\u03b2 (w)\nfor all w \u2208 {0, 1}\u2217 . Then d is a constructive (in fact, computable) s-gale. For each R \u2208 C and\nn \u2208 N, if we write zn = R[0..n \u2212 1], then\n~\n\nlog d(zn ) = sn + log \u03bc\u03b2 (zn )\n~\n\nfor all n. In particular, if R \u2208 RAND\u03b2 , if follows by Lemma 6.12 that\n~ + o(n)\nlog d(zn ) = n[s \u2212 Hn (\u03b2)]\n\n(6.16)\n\nas n \u2192 \u221e. We now verify the two parts of the lemma. For both parts, we let\n~ < s \u2212 \u01eb}.\nI\u01eb = {n \u2208 N | Hn (\u03b2)\n~\n~ let s > H \u2212 (\u03b2),\n~ and let \u01eb =\nTo see that cdim(RAND\u03b2 ) \u2264 H \u2212 (\u03b2),\n~\n\u03b2\n\nS \u221e [d],\n\n~\ns\u2212H \u2212 (\u03b2)\n.\n2\n~\n\u03b2\n\nThen the set I\u01eb is\n\nwhence cdim(RAND ) \u2264 s.\ninfinite, so (6.16) tells us that RAND \u2286\n~\n~\n\u03b2\n~ let s > H + (\u03b2),\n~ and let \u01eb = s\u2212H + (\u03b2)\n. Then the set I\u01eb is\nTo see that cDim(RAND ) \u2264 H + (\u03b2),\n2\n~\n\n~\n\n\u221e [d], whence cDim(RAND\u03b2 ) \u2264 s.\ncofinite, so (6.16) tells us that RAND\u03b2 \u2286 Sstr\n\n19\n\n\fLemma 6.14. Assume that \u03b4 > 0, \u03b2~ is a computable bias sequence with each \u03b2i \u2208 [\u03b4, 1 \u2212 \u03b4],\ns \u2208 [0, \u221e) is computable, and d is a constructive s-gale.\n~ then S \u221e [d]\n1. If s < H \u2212 (\u03b2),\n\nT\n\n~\n\nRAND\u03b2 = \u2205.\n\n~ then S \u221e [d] T RAND\u03b2~ = \u2205.\n2. If s < H + (\u03b2),\nstr\n\nProof. Assume the hypothesis. Define d\u2032 : {0, 1}\u2217 \u2192 [0, \u221e) by\nd\u2032 (w) =\n\nd(w)\n2s|w| \u03bc\u03b2~ (w)\n\n~\nfor all w \u2208 {0, 1}\u2217 . Then d\u2032 is a \u03b2-martingale,\nand d\u2032 is clearly constructive.\n~\nLet R \u2208 RAND\u03b2 . Then d\u2032 does not succeed on R, so there is a constant c > 0 such that, for all\nn \u2208 N, if we write zn = R[0..n \u2212 1], then d\u2032 (zn ) \u2264 2c , whence\n~\n\nlog d(zn ) \u2264 c + sn + log \u03bc\u03b2 (zn ).\nIt follows by Lemma 6.12 that\n~ + o(n)\nlog d(zn ) \u2264 c + n[s \u2212 Hn (\u03b2)]\nas n \u2192 \u221e. Hence, for any \u01eb > 0, if we let\n~ \u2212 \u01eb},\nI\u01eb = {n \u2208 Z+ | s < Hn (\u03b2)\nthen log d(zn ) < c for all sufficiently large n \u2208 I\u01eb . We now verify the two parts of the lemma.\n~\n~ let \u01eb = H \u2212 (\u03b2)\u2212s\n. Then I\u01eb is cofinite, so log d(zn ) < c for all sufficiently large\n1. If s < H \u2212 (\u03b2),\n2\nn \u2208 Z+ , so R 6\u2208 S \u221e [d].\n\n~ let \u01eb =\n2. If s < H + (\u03b2),\n\u221e\nso R 6\u2208 Sstr [d].\n\n~\nH + (\u03b2)\u2212s\n.\n2\n\nThen I\u01eb is infinite, so log d(zn ) < c for infinitely many n \u2208 Z+ ,\n\nWe now have all we need to prove the main theorem of this section.\n~\n\nProof of Theorem 6.6. Assume the hypothesis, and let R \u2208 RAND\u03b2 . By Lemma 6.13, dim(R) \u2264\n~ and Dim(R) \u2264 H + (\u03b2).\n~ To see that dim(R) \u2265 H \u2212 (\u03b2)\n~ and Dim(R) \u2265 H + (\u03b2),\n~ let s, t \u2208 [0, \u221e)\nH \u2212 (\u03b2)\n\u2212\n+\n\u2212\n~\n~\nbe computable with s < H (\u03b2) and t < H (\u03b2), let d be a constructive s-gale, and let d+ be\n\u221e [d+ ]. But these follow\na constructive t-gale. It suffices to show that R 6\u2208 S \u221e [d\u2212 ] and R 6\u2208 Sstr\n~\nimmediately from Lemma 6.14 and the \u03b2-randomness of R.\n~ = lim Hn (\u03b2)\n~ \u2208\nCorollary 6.15. If \u03b2~ is a computable sequence of coin-toss biases such that H(\u03b2)\nn\u2192\u221e\n\n~ is c-regular, with dim(R) =\n(0, 1), then every sequence R \u2208 C that is random with respect to \u03b2\n~\nDim(R) = H(\u03b2).\n\n20\n\n\f~ is\nNote that Corollary 6.15 strengthens Theorem 7.6 of [21] because the convergence of Hn (\u03b2)\n~\na weaker hypothesis than the convergence of \u03b2.\nGeneralizing the construction of Chaitin's random real number \u03a9 [6], Mayordomo [26] and,\nindependently, Tadaki [40] defined for each s \u2208 (0, 1] and each infinite, computably enumerable set\nA \u2286 {0, 1}\u2217 , the real number\no\nX n |\u03c0|\ns\n\u03b8A\n=\n2 s \u03c0 \u2208 {0, 1}\u2217 and U (\u03c0) \u2208 A ,\n\nwhere U is a universal self-delimiting Turing machine. Given (6.1) and Corollary 6.2 above, the\nfollowing fact is implicit in Tadaki's paper.\nTheorem 6.16. (Tadaki [40]) For each s \u2208 (0, 1] and each infinite, computably enumerable set\ns is c-regular with dim(\u03b8 s ) = Dim(\u03b8 s ) = s.\nA \u2286 {0, 1}\u2217 , the (binary expansion of the) real number \u03b8A\nA\nA\nWe define a set X \u2286 C to be self-similar if it has the form\nX = A\u221e = {S \u2208 C|S = w0 w1 w2 . . . for some w0 , w1 , w2 , . . . \u2208 A}\n\nwhere is A \u2286 {0, 1}\u2217 is a finite prefix set. Self-similar sets are examples of c-regular sets.\nTheorem 6.17. Let X = A\u221e be self-similar\nwhere A is a finite prefix set. Then X is c-regular,\nP\nwith cdim(X) = cDim(X) = inf{s| w\u2208A 2\u2212s|w| \u2264 1}.\n\nProof. We say that a string w is composite\nP if there are strings w1 , . . . , wk \u2208 A such that w =\nw1 * * * wk . Let s be computable such that w\u2208A 2\u2212s|w| \u2264 1. For any computable \u01eb > 0 we define\na constructive (s + \u01eb)-supergale d as follows. Let w \u2208 {0, 1}\u2217 , and let v be the maximal composite\nproper prefix of w. Then\nX\nd(w) =\n2\u01eb|w| 2\u2212s(|vu|\u2212|w|) .\nu\u2208A:w\u2291vu\n\n\u221e [d], and therefore\nFor all composite strings w, we have d(w) = 2\u01eb|w|. It follows that A\u221e \u2286 Sstr\n\u221e\ncDim(A ) \u2264 s + \u01eb. P\nLet s such that w\u2208A 2\u2212s|w| > 1 and let d be a s-gale. To show that cdim(A\u221e ) > s, it suffices\nto construct a sequence S \u2208 A\u221e \u2212 S \u221e [d]. Initially, we let w0 = \u03bb. Assume that wn has been\ndefined, and let u \u2208 A such that d(wn u) \u2264 d(wn ). We know that such a u exists because of our\nchoice of s. Then we let wn+1 = wn u. Our sequence S is the unique one that has wn \u2291 S for all\nn.\n\nDai, Lathrop, Lutz, and Mayordomo [7] investigated the finite-state compression ration \u03c1FS (S),\ndefined for each sequence S \u2208 C to be the infimum, taken over all information-lossless finite-state\ncompressors C (a model defined in Shannon's 1948 paper [35]) of the (lower) compression ratio\n\u03c1C (S) = lim inf\nn\u2192\u221e\n\n|C(S[0..n \u2212 1])|\n.\nn\n\nThey proved that\n\u03c1FS (S) = dimFS (S)\n\n(6.17)\n\nfor all S \u2208 C. However, it has been pointed out that the compression ratio \u03c1FS (S) differs from the\none investigated by Ziv [46]. Ziv was instead concerned with the ratio RFS (S) defined by\nRFS (S) = inf lim sup inf\n\nk\u2208N n\u2192\u221e C\u2208Ck\n\n21\n\n|C(S[0..n \u2212 1])|\n,\nn\n\n\fwhere Ck is the set of all k-state information-lossless finite-state compressors. The following result,\ntogether with (6.17), clarifies the relationship between \u03c1FS (S) and RFS (S).\nTheorem 6.18. For all S \u2208 C, RFS (S) = DimFS (S).\nThe proof of Theorem 6.18 is based on the following lemma.\nLemma 6.19. Let C be the set of all finite-state compressors. For all S \u2208 C,\nRFS (S) = inf lim sup\n\n|C(S[0..n \u2212 1])|\n.\nn\n\n\u2032\nRFS\n(S) = inf lim sup\n\n|C(S[0..n \u2212 1])|\n.\nn\n\nC\u2208C n\u2192\u221e\n\nProof. Let\nC\u2208C n\u2192\u221e\n\n\u2032 (S) is trivial. We use several results from [7] to obtain for each k \u2208 N\nThe inequality RFS (S) \u2264 RFS\nand \u01eb > 0 a finite-state compressor Ck,\u01eb that is nearly optimal for all compressors in Ck . From\nLemma 7.7 in [7] we obtain a finite-state gambler for each C \u2208 Ck . By Lemma 3.7 in [7], we can\ncombine these gamblers into a single finite-state gambler. Theorem 4.5 and Lemma 3.11 in [7]\nconvert this single gambler into a 1-account nonvanishing finite-state gambler and finally Lemma\n7.10 converts this to the finite-state compressor Ck,\u01eb . Combining the five cited constructions in [7]\nwe obtain that there is a constant ck,\u01eb such that for all w \u2208 {0, 1}\u2217 and C \u2208 Ck ,\n\n|Ck,\u01eb (w)| \u2264 |C(w)| + \u01eb|w| + ck,\u01eb .\nThen for all k \u2208 N and \u01eb > 0,\n|Ck,\u01eb (S[0..n \u2212 1])|\nn\nn\u2192\u221e\n|C(S[0..n \u2212 1])|\n+ \u01eb,\n\u2264 lim sup inf\nn\nn\u2192\u221e C\u2208Ck\n\n\u2032\n(S) \u2264 lim sup\nRFS\n\n\u2032 (S) \u2264 R (S).\nso RFS\nFS\n\nProof of Theorem 6.18. The equality\nDimFS (S) = inf lim sup\nC\u2208C n\u2192\u221e\n\n|C(S[0..n \u2212 1])|\nn\n\nhas a proof analogous to that of (6.17) given in [7]. Together with Lemma 6.19, this implies that\nRFS (S) = DimFS (S).\nThus, mathematically, the compression ratios \u03c1FS (S) and RFS (S) are both natural: they are\nthe finite-state effectivizations of the Hausdorff and packing dimensions, respectively.\n\n22\n\n\f7\n\nComputational Complexity\n\nIn this section we prove our third main theorem, which says that the dimensions and strong dimensions of polynomial-time many-one degrees in exponential time are essentially unrestricted.\nOur proof of this result uses convenient characterizations of p-dimension and strong p-dimension\nin terms of feasible unpredictability.\nDefinition. A predictor is a function \u03c0 : {0, 1}\u2217 \u00d7 {0, 1} \u2192 [0, 1] such that for all w \u2208 {0, 1}\u2217 ,\n\u03c0(w, 0) + \u03c0(w, 1) = 1.\nWe interpret \u03c0(w, b) as the predictor's estimate of the probability that the bit b will occur next\ngiven that w has occurred. We write \u03a0(p) for the class of all feasible predictors.\nDefinition. Let w \u2208 {0, 1}\u2217 , S \u2208 C, and X \u2286 C.\n1. The cumulative log-loss of \u03c0 on w is\n|w|\u22121\n\nLlog (\u03c0, w) =\n\nX\n\nlog\n\ni=0\n\n1\n.\n\u03c0(w[0..i \u2212 1], w[i])\n\n2. The log-loss rate of \u03c0 on S is\nLlog (\u03c0, S[0..n \u2212 1])\n.\nn\n\nLlog (\u03c0, S) = lim inf\nn\u2192\u221e\n\n3. The strong log-loss rate of \u03c0 on S is\nLlog\nstr (\u03c0, S) = lim sup\nn\u2192\u221e\n\nLlog (\u03c0, S[0..n \u2212 1])\n.\nn\n\n4. The (worst-case) log-loss of \u03c0 on X is\nLlog (\u03c0, X) = sup Llog (\u03c0, S).\nS\u2208X\n\n5. The (worst-case) strong log-loss of \u03c0 on X is\nlog\nLlog\nstr (\u03c0, X) = sup Lstr (\u03c0, S).\nS\u2208X\n\n6. The feasible log-loss unpredictability of X is\nlog\nunpredlog\np (X) = inf L (\u03c0, X).\n\u03c0\u2208\u03a0(p)\n\n7. The feasible strong log-loss unpredictability of X is\nlog\nUnpredlog\np (X) = inf Lstr (\u03c0, X).\n\u03c0\u2208\u03a0(p)\n\n23\n\n\fHitchcock [13] showed that feasible dimension exactly characterizes feasible log-loss unpredictability, that is,\nunpredlog\n(7.1)\np (X) = dimp (X)\nfor all X \u2286 C. We have the following dual result for strong dimension.\nTheorem 7.1. For all X \u2286 C, Unpredlog\np (X) = Dimp (X).\nThe following theorem is the main result of this section. This theorem and its proof are motivated by analogous, but simpler arguments by Ambos-Spies, Merkle, Reimann and Stephan [1].\nTheorem 7.2. For every pair of \u220602 -computable real numbers x, y with 0 \u2264 x \u2264 y \u2264 1, there exists\nA \u2208 E such that\ndimp (degpm (A)) = dim(degpm (A)|E) = x\nand\nDimp (degpm (A)) = Dim(degpm (A)|E) = y.\nWe now develop the proof of Theorem 7.2. Our proof uses several preliminary results.\nThe first part of the following theorem is due to Ambos-Spies, Merkle, Reimann and Stephan\n[1]. The second part is an exact dual of the first part.\nTheorem 7.3. Let A \u2208 E.\n1. dimp (degpm (A)) = dimp (Pm (A)) and dim(degpm (A)|E) = dim(Pm (A)|E).\n2. Dimp (degpm (A)) = Dimp (Pm (A)) and Dim(degpm (A)|E) = Dim(Pm (A)|E).\nThe following lemma is a time-bounded version of Lemma 6.14.\nLemma 7.4. Assume that k, l \u2208 Z+ , \u03b4 > 0, \u03b2~ is an exactly nl -time-computable bias sequence with\neach \u03b2i \u2208 Q \u2229 [\u03b4, 1 \u2212 \u03b4], s \u2208 Q \u2229 [0, \u221e), and d is an nk -time-computable s-gale.\n~ then S \u221e [d]\n1. If s < H \u2212 (\u03b2),\n~ then S \u221e [d]\n2. If s < H + (\u03b2),\nstr\n\nT\n\nT\n\n~\n\nRAND\u03b2 (nk+2l+1 ) = \u2205.\n~\n\nRAND\u03b2 (nk+2l+1 ) = \u2205.\n\nProof. We proceed exactly as in the proof of Lemma 6.14, noting that our present hypothesis\n~\nimplies that the \u03b2-martingale\nd\u2032 is O(nk+2l+1 )-time-computable.\nOur proof of Theorem 7.2 also uses the martingale dilation technique, which was introduced by\nAmbos-Spies, Terwijn, and Zheng [2] and extended by Breutzmann and Lutz [4].\nDefinition. The restriction of a string w \u2208 {0, 1}\u2217 to a language A \u2286 {0, 1}\u2217 is the string w \u21be A\ndefined by the following recursion.\n1. \u03bb \u21be A = \u03bb.\n2. For w \u2208 {0, 1}\u2217 and b \u2208 {0, 1},\n(wb) \u21be A =\n\n\u001a\n\n(w \u21be A)b if s|w| \u2208 A,\nw\u21beA\nif s|w| 6\u2208 A.\n\n24\n\n\f(That is, w \u21be A is the concatenation of the successive bits w[i] for which si \u2208 A.)\nDefinition. A function f : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 is strictly increasing if, for all x, y \u2208 {0, 1}\u2217 ,\nx < y =\u21d2 f (x) < f (y),\nwhere < is the standard ordering of {0, 1}\u2217 .\nNotation. If f : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 , then for each n \u2208 N, let nf be the unique integer such that\nf (sn ) = snf .\nDefinition. If f : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 is strictly increasing and \u03b2~ is a bias sequence, then the\nf -dilation of \u03b2~ is the bias sequence \u03b2~ f given by \u03b2nf = \u03b2nf for all n \u2208 N.\nObservation 7.5. If f : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 is strictly increasing and A \u2286 {0, 1}\u2217 , then for all\nn \u2208 N,\n\u03c7f \u22121 (A) [0..n \u2212 1] = \u03c7A [0..nf \u2212 1] \u21be range(f ).\nDefinition. If f : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 is strictly increasing and d is a martingale, then then the\nf -dilation of d is the function f\u02c6d : {0, 1}\u2217 \u2212\u2192 [0, \u221e),\nf\u02c6d(w) = d(w \u21be range(f )).\nIntuitively, the f -dilation of d is a strategy for betting on a language A, assuming that d itself\nis a good betting strategy for betting on the language f \u22121 (A). Given an opportunity to bet on\nthe membership of a string y = f (x) in A, f\u02c6d bets exactly as d would bet on the membership or\nnonmembership of x in f \u22121 (A).\nThe following result is a special case of Theorem 6.3 in [4].\nTheorem 7.6. (Martingale Dilation Theorem - Breutzmann and Lutz [4]) Assume that \u03b2~ is a bias\nsequence with each \u03b2i \u2208 (0, 1), f : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 is strictly increasing, and d is a \u03b2~ f -martingale.\n~\nThen f\u02c6d is a \u03b2-martingale\nand, for every language A \u2286 {0, 1}\u2217 , if d succeeds on f \u22121 (A), then f\u02c6d\nsucceeds on A.\nk\n\nNotation. For each k \u2208 Z+ , define gk : {0, 1}\u2217 \u2212\u2192 {0, 1}\u2217 by gk (x) = 0|x| 1x. Note that each gk\nis strictly increasing and computable in polynomial time.\n~\nLemma 7.7. Assume that \u03b2~ is a bias sequence with each \u03b2i \u2208 (0, 1), and R \u2208 RAND\u03b2 (n2 ). Then,\n\u22121\n\u03b1\n~\nfor each k \u2265 2, gk (R) \u2208 RAND (nk ), where \u03b1\n~ = \u03b2~ gk .\n\n~ k, and \u03b1\nProof. Let \u03b2,\n~ be as given, and assume that gk\u22121 (R) 6\u2208 RAND\u03b1~ (nk ). Then there is an\nnk -time-computable \u03b1\n~ -martingale d that succeeds on gk\u22121 (R). It follows by Theorem 7.6 that gk\u02c6d\n~\nis a \u03b2-martingale\nthat succeeds on R. The time required to compute gk\u02c6d(w) is O(|w|2 + |w\u2032 |k )\n\u2032\nsteps, where w = w \u21be range(gk ). (This allows O(|w|2 ) steps to compute w\u2032 and then O(|w|k steps\nto compute d(w\u2032 ).) Now |w\u2032 | is bounded above by the number of strings x such that |x|k + |x| + 1 \u2264\n1\n\n|s|w| | = \u230alog(1 + |w|)\u230b, so |w\u2032 | \u2264 21+log(1+|w|) k , so the time required to compute gk\u02c6d(w) is\n1\n\nO(|w|2 + 2k 2k(log(1+|w|)) k ) = O(|w|2 )\n~\n~\nsteps. Thus gk\u02c6d(w) is is an n2 -time computable \u03b2-martingale,\nso R 6\u2208 RAND\u03b2 (n2 ).\n\n25\n\n\fNotation. From here through the proof of Theorem 7.2, we assume that \u03b1 and \u03b2 are \u220602 computable real numbers with 0 \u2264 \u03b1 \u2264 \u03b2 \u2264 1/2. It is well-known that a real number is \u220602 computable if and only if there is a computable sequence of rationals that converge to it. Slowing\ndown this construction gives polynomial-time functions \u03b1\u0302, \u03b2\u0302 : N \u2192 Q such that lim \u03b1\u0302(n) = \u03b1 and\nn\u2192\u221e\n\nlim \u03b2\u0302(n) = \u03b2. We also assume that\n\nn\u2192\u221e\n\n1\nn\n\n\u2264 \u03b1\u0302(n) \u2264 \u03b2\u0302(n) for all n. For each n, we let\n\n\u03ba(n) =\n\n(\n\n\u03b1\u0302(n) if n is even\n\u03b2\u0302(n) if n is odd\n\nand define a special-purpose bias sequence ~\u03b3 by\n\u03b3n = \u03ba(log\u2217 n).\n1\nlog\u2217 n\n\nNote that ~\u03b3 is O(n)-time-computable,\n\n\u2264 \u03b3n for all n, H \u2212 (~\u03b3 ) = H(\u03b1), and H + (~\u03b3 ) = H(\u03b2).\n\nWe now use the unpredictability characterizations from the beginning of this section to establish\nupper bounds on the dimensions and strong dimensions of lower spans of sequences random relative\nto ~\u03b3 .\nLemma 7.8. For each R \u2208 RAND~\u03b3 (n5 ),\ndimp (Pm (R)) \u2264 H(\u03b1)\nand\nDimp (Pm (R)) \u2264 H(\u03b2).\nProof. For now, fix a polynomial-time function f : {0, 1}\u2217 \u2192 {0, 1}\u2217 . The collision set of f is\nCf = {j | (\u2203i < j)f (si ) = f (sj )}.\nFor each n \u2208 N, let\n#Cf (n) = |Cf \u2229 {0, . . . , n \u2212 1}|.\nWe use f to define the predictors\n(\n1\n2\n\nw[i])1\u2212b\n\nif |w| 6\u2208 Cf\nif |w| \u2208 Cf and i = min{j | f (sj ) = f (s|w|)}\n\n(\n(\u03b3nf )b (1 \u2212 \u03b3nf )1\u2212b\n=\nw[i]b (1 \u2212 w[i])1\u2212b\n\nif |w| 6\u2208 Cf\nif |w| \u2208 Cf and i = min{j | f (sj ) = f (s|w|)}\n\n\u03c00f (w, b) =\n\nw[i]b (1\n\n\u2212\n\nand\n\u03c01f (w, b)\n\nfor all w \u2208 {0, 1}\u2217 and b \u2208 {0, 1}.\nFor each S \u2208 C, we now define several objects to facilitate the proof. First, we let\nAf (S) = f \u22121 (S);\nthat is, Af (S) is the language \u2264pm -reduced to S by f . Observe that for all w \u2291 Af (S),\nLlog (\u03c00f , w) = |w| \u2212 #Cf (|w|).\n26\n\n(7.2)\n\n\fDefine the sequence of towers tj by t0 = 1 and tj+1 = 2tj . For any j \u2208 N and tj < n \u2264 tj+1 , define\nthe entropy quantity\nX\nH(\u03b3nf )\nHnf =\ni<n\ni6\u2208Cf and if >tj\u22121\n\nand the random variable\nX\n\nLfn (S) =\n\nlog\n\ni<n\ni6\u2208Cf and if >tj\u22121\n\n1\n\u03c01f (Af (S)[0..i\n\n\u2212 1]), Af (S)[i])\n\n.\n\n(Recall that if is the unique number such that f (si ) = sif .) We have\nLlog (\u03c01f , Af (S)[0..n \u2212 1]) =\n\nX\n\nlog\n\ni<n\n\n=\n\nX\n\ni<n\ni6\u2208Cf\n\n1\n\u03c01f (Af (S[0..i\n\nlog\n\n\u2212 1]), Af (S[i]))\n1\n\n\u03c01f (Af (S[0..i \u2212 1]), Af (S[i]))\n\n= Lfn (S) +\n\nX\n\nlog\n\ni<n\ni6\u2208Cf and if \u2264tj\u22121\n\n\u2264 Lfn (S) +\n\nX\n\n1\n\u03c01f (Af (S[0..i\n\n\u2212 1]), Af (S[i]))\n\n(7.3)\n\nlog log\u2217 if\n\ni<n\ni6\u2208Cf and if \u2264tj\u22121\n\n\u2264 Lfn (S) + (tj\u22121 + 1) log(j \u2212 1)\n\u2264 Lfn (S) + (1 + log n) log\u2217 n,\nfor all n. (Here we used the fact that \u03b3i \u2265 log1\u2217 i for all i.) Finally, for any \u01eb > 0 and \u03b8 \u2208 (0, 1),\ndefine the set\nf\nJ\u03b8,\u01eb\n(S) = {n | #Cf (n) < (1 \u2212 \u03b8)n and Lfn (S) \u2265 Hnf + \u01ebn}\nof natural numbers.\nClaim. For any rational \u03b8 \u2208 (0, 1) and \u01eb > 0,\n\u0010\n\u0011\nf\n\u03bc~\u03b3n5 {S | J\u03b8,\u01eb\n(S) is finite} = 1.\n\nProof of Claim. The argument is similar to the proof of Lemma 6.12. For each n \u2208 N, define the\nset\n(\n\u2205\nif #Cf (n) \u2265 (1 \u2212 \u03b8)n\nYn =\nf\nf\n{S | Ln (S) \u2265 Hn + \u01ebn} otherwise,\nand let\nX\u01eb = {S \u2208 C|(\u2203\u221e n)S \u2208 Yn }.\nTo prove the claim, we will show that \u03bc~n\u03b3 5 (X\u01eb ) = 0.\n\n27\n\n\fFor each n \u2208 N and w \u2208 {0, 1}\u2217 , let\n(\n\u03bc~\u03b3 (Yn |Cw )\ndn (w) =\ndn (w[0..n \u2212 1])\n\nif |w| \u2264 n\nif |w| > n.\n\nIt is clear that each dn is a ~\u03b3 -martingale and that Yn \u2286 S 1 [dn ] for all n \u2208 N.\nLet S \u2208 C. For each n, j \u2208 N, let\nIjn = {if | i < n, i 6\u2208 Cf , and log\u2217 if = j}.\nAlso, define S + = {i | S[i] = 1} and S \u2212 = {i | S[i] = 0}. Then, if n is large enough to ensure that\nlog\u2217 if \u2264 1 + log\u2217 n for all i < n, we have\n(log\u2217 n)+1\n\nX\n\nLfn (S) =\n\nIkn \u2229 S + log\n\nk=(log\u2217 n)\u22121\n\n1\n1\n+ Ikn \u2229 S \u2212 log\n.\n\u03ba(k)\n1 \u2212 \u03ba(k)\n\nFor any n and k, write i(n, k) = |Ikn |. Let Tn be the set of all tuples (l\u22121 , l0 , l1 ) satisfying 0 \u2264 lr \u2264\ni(n, j + r) for \u22121 \u2264 r \u2264 1 and\n1\nX\n\nlr log\n\nr=\u22121\n\n1\n1\n+ (i(n, j + r) \u2212 lr ) log\n\u2265 Hnf + \u01ebn,\n\u03ba(j + r)\n1 \u2212 \u03ba(j + r)\n\nwhere j = log\u2217 n. Then we have\n~\u03b3\n\n\u03bc (Yn ) =\n\nX\n\n(l\u22121 ,l0 ,l1 )\u2208Tn\n\n\u0013\n1 \u0012\nY\ni(n, j + r)\n\u03ba(j + r)lr (1 \u2212 \u03ba(j + r))i(n,j+r)\u2212lr .\nl\nr\nr=\u22121\n\nWe can write a similar formula for \u03bc~\u03b3 (Yn |Cw ) when w 6= \u03bb. From this it follows that the mapping\n(n, w) 7\u2192 dn (w) is exactly computable in O(n3 ) time.\nBy Theorem 6.9, there exists \u03b4 \u2208 (0, 1) such that for all n \u2208 N with Yn 6= \u2205, we have\n\u03bc~\u03b3 (Yn ) < 2\u03b4n\u2212#Cf (n) < 2\u03b4\u03b8n .\nIt follows that the series\n\n\u221e\nP\n\ndn (\u03bb) is p-convergent, so a routine extension of the polynomial-time\n\nn=0\n\nfirst Borel-Cantelli Lemma [22] tells us that \u03bc~n\u03b3 5 (X\u01eb ) = 0.\n\u0003 Claim.\nf\n~\u03b3 5\nLet R \u2208 RAND (n ). Let \u01eb > 0 and \u03b8 < H(\u03b1) be rational. Then by the above claim, J\u03b8,\u01eb\n(R)\nis finite. That is, for all but finitely many n,\n#Cf (n) \u2265 (1 \u2212 \u03b8)n or Lfn (R) < Hnf + \u01ebn.\n\n(7.4)\n\nWriting wn = Af (R)[0..n \u2212 1], (7.4) combined with (7.2) and (7.3) implies that\n\nor\n\nLlog (\u03c00f , wn ) \u2264 \u03b8n < H(\u03b1)n\n\n(7.5)\n\nLlog (\u03c01f , wn ) < Hnf + \u01ebn + (1 + log n) log\u2217 n.\n\n(7.6)\n\n28\n\n\fAs\n\nHnf\nlim sup\n\u2264 H(\u03b2),\nn\nn\u2192\u221e\n\nit follows that\nlim sup\nn\u2192\u221e\n\nmin{Llog (\u03c00f , wn ), Llog (\u03c01f , wn )}\n\u2264 H(\u03b2) + \u01eb.\nn\n\n(7.7)\n\nIf (7.5) holds for infinitely many n, then\nLlog (\u03c00f , Af (R)) \u2264 H(\u03b1).\n\n(7.8)\n\nOtherwise, (7.6) holds for almost all n. Assuming\nlim inf\nn\u2192\u221e\n\nin this case we have\n\nHnf\n\u2264 H(\u03b1),\nn\n\n(7.9)\n\nLlog (\u03c01f , Af (R)) \u2264 H(\u03b1) + \u01eb.\n\n(7.10)\n\nWe now verify (7.9). For each n, let m(n) = t2n . Then for sufficiently large n, we have if < tn+1\nfor all i < m(n). Using the sets Ink from the proof of the claim, we then have\nf\n=\nHm(n)\n\nm(n)\n\nInm(n) H(\u03ba(n)) + In+1 H(\u03ba(n + 1))\n\n\u2264 (tn + 1)H(\u03ba(n)) + m(n)H(\u03ba(n + 1)).\nAs tn = o(m(n)) and \u03ba(2n) \u2192 \u03b1 as n \u2192 \u221e, we have\nf\nHm(2n+1)\nHnf\n\u2264 lim inf\n\u2264 H(\u03b1).\nlim inf\nn\u2192\u221e m(2n + 1)\nn\u2192\u221e n\n\nFor each polynomial-time reduction f , we have defined and analyzed two predictors \u03c00f and \u03c01f .\nWe now show how to combine all these predictors into a single predictor that will establish the\nlemma.\nLet {fj | j \u2208 N} be a uniform enumeration of all polynomial-time functions fj : {0, 1}\u2217 \u2192 {0, 1}\u2217\nsuch that fj (x) is computable in O(2|x| + j) steps. For any predictor \u03c1, define a probability measure\n\u03bc[\u03c1] by\n|w|\u22121\nY\n\u03bc[\u03c1](w) =\n\u03c1(w[0..i \u2212 1], w[i])\ni=0\n\nfor all w \u2208\n\n{0, 1}\u2217 .\n\nFor each m \u2208 N and w \u2208 {0, 1}m , let\n\u2212(2m+1)\n\n\u03bcm (w) = 2\n\n+\n\nm\u22121\nX\n\n\u2212(2j+3)\n\n2\n\nj=0\n\n29\n\n\u0012\n\nf\n\u03bc[\u03c00j ](w)\n\n\u0013\n1\nfj\n+ \u03bc[\u03c01 ](w) .\n2\n\n\fThen\n\u0012\n\u0013\n1\nf\nf\n2\u2212(2j+3) \u03bc[\u03c00j ](w0) + \u03bc[\u03c01j ](w0)\n2\nj=0\n\u0013\n\u0012\nm\nX\n1\nfj\nfj\n\u2212(2j+3)\n\u2212(2m+3)\n2\n\u03bc[\u03c00 ](w1) + \u03bc[\u03c01 ](w1)\n+2\n+\n2\nj=0\n\u0012\n\u0013\nm\nX\n1\nfj\nfj\n\u2212(2j+3)\n\u2212(2m+2)\n2\n\u03bc[\u03c00 ](w) + \u03bc[\u03c01 ](w)\n2\n+\n2\nj=0\n\u0012\n\u0013\n1\nfm\nfm\n\u2212(2m+3)\n2\n2 + \u03bc[\u03c00 ](w) + \u03bc[\u03c01 ](w) + \u03bcm (w) \u2212 2\u2212(2m+1)\n2\n\u0012\n\u0013\n1\n\u03bcm (w) + 2\u2212(2m+3) 3 +\n\u2212 2\u2212(2m+1)\n2\n\u03bcm (w).\n\n\u03bcm+1 (w0) + \u03bcm+1 (w1) = 2\u2212(2m+3) +\n\n=\n=\n\u2264\n<\n\nm\nX\n\nNow define a predictor \u03c0 by\n\u03bc|w|+1 (w1)\n\u03bc|w| (w)\n\u03c0(w, 0) = 1 \u2212 \u03c0(w, 1).\n\n\u03c0(w, 1) =\n\nThen for all w \u2208 {0, 1}\u2217 and b \u2208 {0, 1},\n\u03bc|w|+1 (wb)\n.\n\u03bc|w| (w)\n\n\u03c0(w, b) \u2265\n\nFor all w \u2208 {0, 1}\u2217 , i \u2208 {0, 1}, and j < |w|, we have\n|w|\u22121\n\nLlog (\u03c0, w) =\n\nX\n\nlog\n\n1\n\u03c0(w[0..i \u2212 1], w[i])\n\nlog\n\n\u03bci (w[0..i \u2212 1])\n\u03bci+1 (w[0..i])\n\ni=0\n\n|w|\u22121\n\n\u2264\n\nX\ni=0\n\n= log\n\u2264 log\n\n\u03bc0 (\u03bb)\n\u03bc|w| (w)\n22j+3+i\nf\n\n\u03bc[\u03c0i j ](w)\nf\n\n= 2j + 3 + i + Llog (\u03c0i j , w).\nFor any j \u2208 N, it follows that\n\nfj\nLlog\nstr (\u03c0, A (R)) \u2264 H(\u03b2) + \u01eb\n\nby using f = fj in (7.7). Also, since either (7.8) or (7.10) holds for f = fj , we have\nLlog (\u03c0, Afj (R)) \u2264 H(\u03b1) + \u01eb.\n30\n\n\fAs \u03c0 is (exactly) polynomial-time computable, this establishes that\nPm (R) = {Afj (R) | j \u2208 N}\nhas p-dimension at most H(\u03b1) + \u01eb by (7.1) and strong p-dimension at most H(\u03b2) + \u01eb by Theorem\n7.1. As \u01eb > 0 was arbitrary, the lemma follows.\nProof of Theorem 7.2. in the case x = H(\u03b1), y = H(\u03b2), where \u03b1, \u03b2 \u2208 Q and 0 < \u03b1 \u2264 \u03b2 \u2264 1/2.\nBy a routine diagonalization, there is a language A \u2208 RAND~\u03b3 (n5 ) \u2229 E. By Theorem 7.3, it\nsuffices to prove that\ndimp (Pm (A)) = dim(Pm (A)|E) = H(\u03b1)\nand\nDimp (Pm (A)) = Dim(Pm (A)|E) = H(\u03b2).\nBy Lemma 7.8, then, it suffices to prove that\ndim(Pm (A)|E) \u2265 H(\u03b1)\nand\nDim(Pm (A)|E) \u2265 H(\u03b2).\nTo see that these hold, let s, t \u2208 Q with s < H(\u03b1) and t < H(\u03b2), let k \u2208 Z+ , let d\u2212 be an nk -time\ncomputable s-gale, and let d+ be an nk -time computable t-gale. It suffices to show that\nPm (A) \u2229 E 6\u2286 S \u221e [d\u2212 ]\n\n(7.11)\n\nand\n\u221e +\n[d ]\nPm (A) \u2229 E 6\u2286 Sstr\n\n(7.12)\n~\u03b3 \u2032\n\n\u22121\n(A). It is clear that B \u2208 Pm (A) \u2229 E. Also, by Lemma 7.7, B \u2208 RAND (nk ), where\nLet B = gk+3\n~\u03b3 \u2032 = ~\u03b3 gk+3 . Since\ns < H(\u03b1) = H \u2212 (~\u03b3 ) = H \u2212 (~\u03b3 \u2032 )\n\nand\nt < H(\u03b2) = H + (~\u03b3 ) = H + (~\u03b3 \u2032 )\n\u221e [d+ ]. Thus 7.11\nand ~\u03b3 \u2032 is O(n)-time-computable, Lemma 7.4 tells us that B 6\u2208 S \u221e [d\u2212 ] and B 6\u2208 Sstr\nand 7.12 hold.\n\nIn light of Theorem 7.2, the following question concerning the relativized feasible dimension of\nNP is natural.\nOpen Question 7.9. For which pairs of real numbers \u03b1, \u03b2 \u2208 [0, 1] does there exist an oracle A\nsuch that dimpA (NPA ) = \u03b1 and DimpA (NPA ) = \u03b2?\nWe conclude this section with two brief observations.\nFortnow and Lutz [11] have recently established a tight quantitative relationship between pdimension and feasible predictability. Specifically, for each X \u2286 C, they investigated the quantity\nPredp (X) which is the supremum, for all feasible predictors \u03c0, of the (worst-case, upper) success\nrate\n\u03c0 + (S) = inf lim sup \u03c0 + (S[0..n \u2212 1])\n(7.13)\nS\u2208X\n\nn\u2192\u221e\n\n31\n\n\fwhere\n\n|w|\u22121\n+\n\n\u03c0 (w) =\n\nX\n\n\u03c0(w[0..i \u2212 1], w[i])\n\ni=0\n\nis the expected number of correct predictions that \u03c0 will make on w. They proved that Predp (X)\nis related to the p-dimension of X by\n2(1 \u2212 Predp (X)) \u2264 dimp (X) \u2264 H(Predp (X))\n\n(7.14)\n\n(where H(\u03b1) is the Shannon entropy of \u03b1) and that these bounds are tight. If we call Predp (X)\nthe upper feasible predictability of X and define the lower feasible predictability of X, predp (X), in\nthe same fashion, but with the limit superior in (7.13) replaced by a limit inferior, then we have\nthe following dual of (7.14).\nTheorem 7.10. For all X \u2286 C,\n2(1 \u2212 predp (X)) \u2264 Dimp (X) \u2264 H(predp (X)).\nFor each s : N \u2192 N, let SIZE(s(n)) be the class of all (characteristic sequences of) languages\nA \u2286 {0, 1}\u2217 such that, for each n \u2208 N, A=n is decided by a Boolean circuit consisting of at most\ns(n) gates.\nn\n\nTheorem 7.11. For each \u03b1 \u2208 [0, 1], the class X\u03b1 = SIZE(\u03b1* 2n ) is pspace-regular, with dimpspace (X\u03b1 ) =\nDimpspace (X\u03b1 ) = dim(X\u03b1 |ESPACE) = Dim(X\u03b1 |ESPACE) = \u03b1.\nProof. It was shown in [20] that dimpspace (X\u03b1 ) = dim(X\u03b1 |ESPACE) = \u03b1. This proof also shows\nthat the strong dimensions are \u03b1.\nAcknowledgment. The third author thanks Dan Mauldin for extremely useful discussions.\n\nReferences\n[1] K. Ambos-Spies, W. Merkle, J. Reimann, and F. Stephan. Hausdorff dimension in exponential\ntime. In Proceedings of the 16th IEEE Conference on Computational Complexity, pages 210\u2013\n217, 2001.\n[2] K. Ambos-Spies, S. A. Terwijn, and X. Zheng. Resource bounded randomness and weakly\ncomplete problems. Theoretical Computer Science, 172:195\u2013207, 1997.\n[3] P. Billingsley. Probability and Measure. John Wiley and Sons, New York, N.Y., third edition,\n1995.\n[4] J. M. Breutzmann and J. H. Lutz. Equivalence of measures of complexity classes. SIAM\nJournal on Computing, 29:302\u2013326, 2000.\n[5] J. Cai and J. Hartmanis. On Hausdorff and topological dimensions of the Kolmogorov complexity of the real line. Journal of Computer and Systems Sciences, 49:605\u2013619, 1994.\n[6] G. J. Chaitin. A theory of program size formally identical to information theory. Journal of\nthe Association for Computing Machinery, 22:329\u2013340, 1975.\n32\n\n\f[7] J. J. Dai, J. I. Lathrop, J. H. Lutz, and E. Mayordomo. Finite-state dimension. Theoretical\nComputer Science. To appear.\n[8] K. Falconer. Fractal Geometry: Mathematical Foundations and Applications. John Wiley &\nSons, 1990.\n[9] K. Falconer. Techniques in Fractal Geometry. John Wiley & Sons, 1997.\n[10] S. A. Fenner. Gales and supergales are equivalent for defining constructive Hausdorff dimension. Technical Report cs.CC/0208044, Computing Research Repository, 2002.\n[11] L. Fortnow and J. H. Lutz. Prediction and dimension. In Proceedings of the 15th Annual\nConference on Computational Learning Theory, pages 380\u2013395, 2002.\n[12] F. Hausdorff. Dimension und \u00e4usseres Mass. Mathematische Annalen, 79:157\u2013179, 1919.\n[13] J. M. Hitchcock. Fractal dimension and logarithmic loss unpredictability. Theoretical Computer\nScience. To appear.\n[14] J. M. Hitchcock. Gales suffice for constructive dimension. Information Processing Letters. To\nappear.\n[15] J. M. Hitchcock. Correspondence principles for effective dimensions. In Proceedings of the 29th\nInternational Colloquium on Automata, Languages, and Programming, pages 561\u2013571, 2002.\n[16] J. M. Hitchcock. MAX3SAT is exponentially hard to approximate if NP has positive dimension.\nTheoretical Computer Science, 289(1):861\u2013869, 2002.\n[17] S. Kakutani. On the equivalence of infinite product measures. Annals of Mathematics, 49:214\u2013\n224, 1948.\n[18] P. L\u00e9vy. Th\u00e9orie de l'Addition des Variables Aleatoires. Gauthier-Villars, 1937 (second edition\n1954).\n[19] M. Li and P. M. B. Vit\u00e1nyi. An Introduction to Kolmogorov Complexity and its Applications.\nSpringer-Verlag, Berlin, 1997. Second Edition.\n[20] J. H. Lutz. Dimension in complexity classes. SIAM Journal on Computing. To appear.\n[21] J. H. Lutz. The dimensions of individual strings and sequences. Information and Computation.\nTo appear.\n[22] J. H. Lutz. Almost everywhere high nonuniform complexity. Journal of Computer and System\nSciences, 44:220\u2013258, 1992.\n[23] J. H. Lutz. Resource-bounded measure. In Proceedings of the 13th IEEE Conference on\nComputational Complexity, pages 236\u2013248, 1998.\n[24] P. Mattila and R. Mauldin. Measure and dimension functions: measurability and densities.\nMathematical Proceedings of the Cambridge Philosophical Society, 121:81\u2013100, 1997.\n[25] E. Mayordomo. Effective Hausdorff dimension. In Proceedings of Foundations of the Formal\nSciences III. Kluwer Academic Press. To appear.\n33\n\n\f[26] E. Mayordomo. A Kolmogorov complexity characterization of constructive Hausdorff dimension. Information Processing Letters, 84:1\u20133, 2002.\n[27] B. Ya. Ryabko. Coding of combinatorial sources and Hausdorff dimension. Soviet Mathematics\nDoklady, 30:219\u2013222, 1984.\n[28] B. Ya. Ryabko. Noiseless coding of combinatorial sources. Problems of Information Transmission, 22:170\u2013179, 1986.\n[29] B. Ya. Ryabko. Algorithmic approach to the prediction problem. Problems of Information\nTransmission, 29:186\u2013193, 1993.\n[30] B. Ya. Ryabko. The complexity and effectiveness of prediction problems. Journal of Complexity, 10:281\u2013295, 1994.\n[31] C. P. Schnorr. A unified approach to the definition of random sequences. Mathematical Systems\nTheory, 5:246\u2013258, 1971.\n[32] C. P. Schnorr. Zuf\u00e4lligkeit und Wahrscheinlichkeit. Lecture Notes in Mathematics, 218, 1971.\n[33] C. P. Schnorr. Process complexity and effective random tests. Journal of Computer and System\nSciences, 7:376\u2013388, 1973.\n[34] C. P. Schnorr. A survey of the theory of random sequences. In R. E. Butts and J. Hintikka,\neditors, Basic Problems in Methodology and Linguistics, pages 193\u2013210. D. Reidel, 1977.\n[35] C. E. Shannon. A mathematical theory of communication. Bell System Technical Journal,\n27:379\u2013423, 623\u2013656, 1948.\n[36] L. Staiger. Kolmogorov complexity and Hausdorff dimension. Information and Computation,\n103:159\u201394, 1993.\n[37] L. Staiger. A tight upper bound on Kolmogorov complexity and uniformly optimal prediction.\nTheory of Computing Systems, 31:215\u201329, 1998.\n[38] L. Staiger. How much can you win when your adversary is handicapped?\nInformation and Complexity, pages 403\u2013412. Kluwer, 2000.\n\nIn Numbers,\n\n[39] D. Sullivan. Entropy, Hausdorff measures old and new, and limit sets of geometrically finite\nKleinian groups. Acta Mathematica, 153:259\u2013277, 1984.\n[40] K. Tadaki. A generalization of Chaitin's halting probability \u03c9 and halting self-similar sets.\nHokkaido Mathematical Journal, 31:219\u2013253, 2002.\n[41] C. Tricot. Two definitions of fractional dimension. Mathematical Proceedings of the Cambridge\nPhilosophical Society, 91:57\u201374, 1982.\n[42] M. van Lambalgen. Random Sequences. PhD thesis, Department of Mathematics, University\nof Amsterdam, 1987.\n[43] M. van Lambalgen. Von Mises' definition of random sequences reconsidered. Journal of\nSymbolic Logic, 52:725\u2013755, 1987.\n34\n\n\f[44] J. Ville. \u00c9tude Critique de la Notion de Collectif. Gauthier\u2013Villars, Paris, 1939.\n[45] V. G. Vovk. On a randomness criterion. Soviet Mathematics Doklady, 35:656\u2013660, 1987.\n[46] J. Ziv. Coding theorems for individual sequences. IEEE Transactions on Information Theory,\n24:405\u2013412, 1978.\n\n35\n\n\f"}