{"id": "http://arxiv.org/abs/0909.3978v2", "guidislink": true, "updated": "2012-05-07T17:36:38Z", "updated_parsed": [2012, 5, 7, 17, 36, 38, 0, 128, 0], "published": "2009-09-22T12:33:56Z", "published_parsed": [2009, 9, 22, 12, 33, 56, 1, 265, 0], "title": "A Generalized Fourier Transform Approach to Risk Measures", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5273%2C0909.0189%2C0909.3384%2C0909.3857%2C0909.4923%2C0909.5461%2C0909.1648%2C0909.1292%2C0909.1128%2C0909.2173%2C0909.4871%2C0909.3198%2C0909.3377%2C0909.1920%2C0909.5692%2C0909.2124%2C0909.4132%2C0909.2454%2C0909.5460%2C0909.3125%2C0909.2039%2C0909.0977%2C0909.1747%2C0909.3414%2C0909.0291%2C0909.2681%2C0909.5338%2C0909.0434%2C0909.1972%2C0909.1061%2C0909.5568%2C0909.5662%2C0909.2190%2C0909.4161%2C0909.0440%2C0909.2970%2C0909.2331%2C0909.2363%2C0909.2965%2C0909.1235%2C0909.2003%2C0909.0450%2C0909.2200%2C0909.2139%2C0909.2323%2C0909.0691%2C0909.0743%2C0909.5538%2C0909.0154%2C0909.5687%2C0909.0425%2C0909.1263%2C0909.3269%2C0909.4262%2C0909.4026%2C0909.4031%2C0909.2865%2C0909.3624%2C0909.0582%2C0909.1634%2C0909.5657%2C0909.1159%2C0909.5612%2C0909.4783%2C0909.3639%2C0909.0878%2C0909.0875%2C0909.5422%2C0909.3245%2C0909.0959%2C0909.0701%2C0909.0482%2C0909.0802%2C0909.5113%2C0909.4171%2C0909.3978%2C0909.1373%2C0909.1576%2C0909.0735%2C0909.2776%2C0909.1261%2C0909.5285%2C0909.0466%2C0909.1853%2C0909.0960%2C0909.4182%2C0909.0595%2C0909.1533%2C0909.5436%2C0909.5092%2C0909.5337%2C0909.0039%2C0909.3828%2C0909.2076%2C0909.5504%2C0909.0719%2C0909.4201%2C0909.5071%2C0909.3088%2C0909.5221%2C0909.5371&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Generalized Fourier Transform Approach to Risk Measures"}, "summary": "We introduce the formalism of generalized Fourier transforms in the context\nof risk management. We develop a general framework to efficiently compute the\nmost popular risk measures, Value-at-Risk and Expected Shortfall (also known as\nConditional Value-at-Risk). The only ingredient required by our approach is the\nknowledge of the characteristic function describing the financial data in use.\nThis allows to extend risk analysis to those non-Gaussian models defined in the\nFourier space, such as Levy noise driven processes and stochastic volatility\nmodels. We test our analytical results on data sets coming from various\nfinancial indexes, finding that our predictions outperform those provided by\nthe standard Log-Normal dynamics and are in remarkable agreement with those of\nthe benchmark historical approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5273%2C0909.0189%2C0909.3384%2C0909.3857%2C0909.4923%2C0909.5461%2C0909.1648%2C0909.1292%2C0909.1128%2C0909.2173%2C0909.4871%2C0909.3198%2C0909.3377%2C0909.1920%2C0909.5692%2C0909.2124%2C0909.4132%2C0909.2454%2C0909.5460%2C0909.3125%2C0909.2039%2C0909.0977%2C0909.1747%2C0909.3414%2C0909.0291%2C0909.2681%2C0909.5338%2C0909.0434%2C0909.1972%2C0909.1061%2C0909.5568%2C0909.5662%2C0909.2190%2C0909.4161%2C0909.0440%2C0909.2970%2C0909.2331%2C0909.2363%2C0909.2965%2C0909.1235%2C0909.2003%2C0909.0450%2C0909.2200%2C0909.2139%2C0909.2323%2C0909.0691%2C0909.0743%2C0909.5538%2C0909.0154%2C0909.5687%2C0909.0425%2C0909.1263%2C0909.3269%2C0909.4262%2C0909.4026%2C0909.4031%2C0909.2865%2C0909.3624%2C0909.0582%2C0909.1634%2C0909.5657%2C0909.1159%2C0909.5612%2C0909.4783%2C0909.3639%2C0909.0878%2C0909.0875%2C0909.5422%2C0909.3245%2C0909.0959%2C0909.0701%2C0909.0482%2C0909.0802%2C0909.5113%2C0909.4171%2C0909.3978%2C0909.1373%2C0909.1576%2C0909.0735%2C0909.2776%2C0909.1261%2C0909.5285%2C0909.0466%2C0909.1853%2C0909.0960%2C0909.4182%2C0909.0595%2C0909.1533%2C0909.5436%2C0909.5092%2C0909.5337%2C0909.0039%2C0909.3828%2C0909.2076%2C0909.5504%2C0909.0719%2C0909.4201%2C0909.5071%2C0909.3088%2C0909.5221%2C0909.5371&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We introduce the formalism of generalized Fourier transforms in the context\nof risk management. We develop a general framework to efficiently compute the\nmost popular risk measures, Value-at-Risk and Expected Shortfall (also known as\nConditional Value-at-Risk). The only ingredient required by our approach is the\nknowledge of the characteristic function describing the financial data in use.\nThis allows to extend risk analysis to those non-Gaussian models defined in the\nFourier space, such as Levy noise driven processes and stochastic volatility\nmodels. We test our analytical results on data sets coming from various\nfinancial indexes, finding that our predictions outperform those provided by\nthe standard Log-Normal dynamics and are in remarkable agreement with those of\nthe benchmark historical approach."}, "authors": ["G. Bormetti", "V. Cazzola", "G. Livan", "G. Montagna", "O. Nicrosini"], "author_detail": {"name": "O. Nicrosini"}, "author": "O. Nicrosini", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/1742-5468/2010/01/P01005", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0909.3978v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0909.3978v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Feller's condition removed, some typos in Appendix A amended", "arxiv_primary_category": {"term": "q-fin.RM", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-fin.RM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "q-fin.CP", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0909.3978v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0909.3978v2", "journal_reference": "J. Stat. Mech. (2010) P01005", "doi": "10.1088/1742-5468/2010/01/P01005", "fulltext": "FNT/T 2009/04\n\nA Generalized Fourier Transform Approach to Risk Measures\nGiacomo Bormetti,1, 2, \u2217 Valentina Cazzola,1, 3, 2 Giacomo Livan,3, 2 Guido Montagna,3, 2, 1 and Oreste Nicrosini2, 1\n1\n\narXiv:0909.3978v2 [q-fin.RM] 7 May 2012\n\n3\n\nIstituto Universitario di Studi Superiori, Centro Studi Rischio e Sicurezza\nViale Lungo Ticino Sforza 56, 27100 Pavia, Italy\n2\nIstituto Nazionale di Fisica Nucleare, Sezione di Pavia\nVia Bassi 6, 27100 Pavia, Italy\nDipartimento di Fisica Nucleare e Teorica, Universit\u00e0 degli Studi di Pavia\nVia Bassi 6, 27100 Pavia, Italy\n(Dated: October 27, 2018)\n\nWe introduce the formalism of generalized Fourier transforms in the context of risk management.\nWe develop a general framework to efficiently compute the most popular risk measures, Valueat-Risk and Expected Shortfall (also known as Conditional Value-at-Risk). The only ingredient\nrequired by our approach is the knowledge of the characteristic function describing the financial\ndata in use. This allows to extend risk analysis to those non-Gaussian models defined in the Fourier\nspace, such as L\u00e9vy noise driven processes and stochastic volatility models. We test our analytical\nresults on data sets coming from various financial indexes, finding that our predictions outperform\nthose provided by the standard Log-Normal dynamics and are in remarkable agreement with those\nof the benchmark historical approach.\nPACS numbers: 89.65.Gh\n\nI.\n\nINTRODUCTION\n\nSeptember 2008 financial crisis has dramatically highlighted the need for reliable, easy to understand and implement instruments to measure and manage risk. The\nhigh volatility of financial markets during the Nineties\ninduced academics and practitioners to design sophisticated risk management tools. According to the recently\nrevised capital adequacy framework, commonly known\nas Basel II accord [1], any financial institution has to\nmeet stringent capital requirements in order to cover the\nvarious sources of risk to be faced as a result of normal\noperations. Today the most widely used measure to manage market risk in the financial industry is Value-at-Risk\n(VaR). VaR refers to the maximum potential loss over\na given period at a certain confidence level (CL) and\ncan be used to measure the risk of individual assets and\nportfolios of assets as well. Because of its conceptual simplicity, VaR has been extensively adopted by regulators\nand it generally provides a reasonably accurate estimate\nof risk. However, VaR is known to suffer from important\ndrawbacks: it can violate the sub-additivity rule for portfolio risk, which is a required property for any consistent\nmeasure of risk [2, 3], and it does not quantify the typical\nloss incurred when the risk threshold is exceeded. The\nexpected shortfall (ES), defined as the expected loss conditional on the VaR threshold being exceeded, overcomes\nthese disadvantages and leads to more consistent results.\nThree main approaches are known in the literature and\nused in practice to compute VaR and ES: the parametric\napproach, the historical one, and Monte Carlo simulations of the stochastic dynamics of a given stock price re-\n\n\u2217 Electronic\n\naddress: Giacomo.Bormetti@pv.infn.it\n\nturns model. The parametric approach usually relies on\nthe normality assumption for the returns distribution, although some analytical results using non-Gaussian functional forms are available in the literature [2, 4\u20136]. However, it is well known that empirical price returns exhibit heavy tails and a certain degree of asymmetry; the\nhistorical simulation approach is often used in order to\ncapture their leptokurtic nature. The last approach consists of Monte Carlo simulations of the return dynamics,\nbut it usually requires very intensive simulations to get\nto acceptably accurate risk estimates. As a result of the\npresent situation, reliable and hopefully fast methods to\ncalculate financial risk are mandatory.\nIn this article we shall present a general framework to\ncompute VaR and ES by only relying on the knowledge\nof the closed-form characteristic function (CF) describing\nthe distribution of the financial returns under analysis.\nOur approach draws on the original ideas developed in\n[7, 8] by A. L. Lewis and A. Lipton, who introduced generalized Fourier calculus in the context of option pricing, and extends them to the risk management framework. The advantage of our approach is manifold. The\nequations we obtain for risk measures are intuitive and\neasy to read, since both VaR and ES turn out to be expressed in terms of one same function evaluated for different arguments. Moreover, the evaluation of such formulae is computationally efficient, since running twice a\nfast Fourier transform (FFT) algorithm yields both VaR\nand ES values over wide ranges of the CL. This is a remarkable feature, since under standard approaches risk\nmeasures would need to be recomputed every time the\nCL is changed. Fourier inversion based approaches can\nbe found in literature; the first attempt dates back to\nthe work of Rouvinez [9], and later developments are discussed in [10\u201315]. However, the Fourier inversion is usually employed to compute an approximation of the cumu-\n\n\f2\nlative function through the Inversion Theorem [16], then\nthe quantile corresponding to the fixed CL is computed\nby root-finding algorithms. However, this final step has\nto be iterated over the entire set of desired CLs, while our\napproach directly provides the risk estimates. A very useful and easy to interpret graphical representation of the\nresults can also be sketched. Finally, being based on the\nuse of CFs, our method is readily applicable to a number of interesting distributions whose probability density\nfunction (PDF) is not known analytically. Remarkable\nexamples are represented by the class of L\u00e9vy distributions, both in their original and truncated versions.\nIn this article we focus on Truncated L\u00e9vy Distributions (TLDs), which, given their ability to reproduce\nsome of the stylized facts observed in real market data,\nhave been introduced and applied in the context of financial analysis by several authors [17\u201320]. The approach we\npropose can also deal with stochastic volatility models\n(SVMs), which have already been successfully used in the\ncontext of derivative pricing. Interestingly, to the best of\nour knowledge, these models have never been employed\nin risk management before. Our framework is naturally\nsuited to models that are well defined in terms of the CF\nsuch as the Stein-Stein [21, 22], Heston [23, 24], Sch\u00f6belZhu [25], and exponential Ornstein-Uhlenbeck [26\u201329]\nmodels. We choose to work with the Heston model,\nwhose popularity is rapidly growing amongst financial\npractitioners [30]. A further feature of SVMs we wish\nto investigate in the present work is their ability to provide high order normalized cumulants with different time\nscalings w.r.t. those implied by the Central Limit Theorem (CLT). We plan to test their performances when\nprojecting risk estimates over time.\nThe paper is organized as follows: in Section II the\ntechnical definitions of VaR and ES are recalled, and their\nexpressions in terms of the CF are derived. In Section III\nthe models we use to test our approach are presented. In\nSection IV the fitting procedures and the data analysis\nwe performed are described, and the numerical results\nobtained for the risk measures are detailed. In Section V\nsome conclusions are drawn.\n\nII.\n\nThe Value-at-Risk (VaR) is defined as the maximum\npotential loss \u2212\u2206\u2217 (with \u2206\u2217 > 0) not to be exceeded\nat a given significance level P\u2217 \u2208 (0, 1) over a fixed time\nhorizon \u2206t. Thus, when considering the price variation\n\u2206S = S \u2212 S0 of some asset or index, VaR is implicitly\ndefined by the integral equation\nP =\n\nZ\n\n\u2212\u2206\u2217\n\nd(\u2206S) p\u0302(\u2206S)\n\n\u2217\n\nP =\n\n(1)\n\n\u2212S0\n\nwhere p\u0302 is the PDF describing \u2206S. When switching to\n.\nthe centered logarithmic returns x = ln(1 + \u2206S/S0 ) \u2212\n\u03bc\u2206t, with \u03bc the linear returns mean, equation (1) can be\n\n\u2212L\u2217\n\nZ\n\ndx p(x)\n\n(2)\n\n\u2212\u221e\n\n.\nwhere p is the PDF associated with x and L\u2217 = \u2212 ln(1 \u2212\n\u2206\u2217 /S0 )+\u03bc\u2206t. It is worth mentioning that \u2206\u2217 represents\nVaR in monetary units; we shall often use the normal.\nized VaR \u039b\u2217 = \u2206\u2217 /S0 , which is usually presented as a\npercentage quantity (percentage VaR).\nIn order to derive new expressions for VaR, we adapt\nthe approach developed by A. L. Lewis and, independently, by A. Lipton in the context of derivative pricing\nunder stochastic volatility [7, 8]. Let us represent the\nPDF p in terms of the generalized Fourier transform f\nZ +\u221e+i\u03bd\n1\np(x) =\nd\u03c6 f (\u03c6) e\u2212i\u03c6x .\n2\u03c0 \u2212\u221e+i\u03bd\nIn this integral expression \u03c6 = \u03c9 + i\u03bd is a complex variable (\u03c9, \u03bd \u2208 R), whose imaginary part \u03bd belongs to the\nproper strip of regularity (\u03bd\u2212 , \u03bd+ ) of the extended characteristic function (ECF) f . Such a strip is delimited\nby the possible singularities of f (which can be shown\nto be purely imaginary under suitable conditions [7]) lying closest to the origin in the complex upper (lower)\nhalf plane, whose imaginary part reads \u03bd+ (\u03bd\u2212 ). With\nthese positions, we can plug the previous expression in\nequation (2) and switch the integration order. Thus, we\nobtain\nZ +\u221e+i\u03bd\nZ \u2212L\u2217\n1\n\u2217\nd\u03c6 f (\u03c6)\nP =\ndx e\u2212i\u03c6x\n2\u03c0 \u2212\u221e+i\u03bd\n\u2212\u221e\nand to ensure convergence of the second integral we require \u03bd to be strictly positive. So, restricting \u03bd \u2208 (0, \u03bd+ )\nequation (2) eventually becomes\nP\n\n\u2217\n\ni\n=\n2\u03c0\n\nZ\n\n+\u221e+i\u03bd\n\n\u2212\u221e+i\u03bd\n\u2217 Z +\u221e\n\ne\u2212\u03bdL\n=\n2\u03c0\n=\n\nFORMULAE FOR RISK ESTIMATION\n\n\u2217\n\nrewritten as\n\ne\n\nd\u03c9\n\n\u2212\u221e\n\n\u2212\u03bdL\u2217\n\n\u03c0\n\nei\u03c6L\nd\u03c6 f (\u03c6)\n\u03c6\n\nRe\n\n\u0014Z\n\n0\n\n+\u221e\n\n\u2217\n\nf (\u03c9 + i\u03bd) ei\u03c9L\n\u03bd \u2212 i\u03c9\n\n\u2217\n\nf (\u03c9 + i\u03bd) ei\u03c9L\nd\u03c9\n\u03bd \u2212 i\u03c9\n\n\u2217\n\n\u0015\n\nwhere the final equality is obtained by exploiting the symmetries of the real and imaginary parts of the ECF. Then,\ndefining the function\nZ +\u221e\n\u2217\nf (\u03c9 + i\u03bd) i\u03c9L\u2217\n.\ne\n(3)\nG\u03bd (L\u2217 , \u03b8) = e\u2212\u03b8L\nd\u03c9\n\u03b8 \u2212 i\u03c9\n0\nallows us to write\nP\u2217 =\n\nRe G\u03bd (L\u2217 , \u03bd)\n.\n\u03c0\n\n(4)\n\nWe now follow a similar line of reasoning for the Expected Shortfall (ES), defined as the average potential\n\n\f3\nloss when the VaR threshold for a fixed P\u2217 is exceeded.\nWith the same notation as above, in terms of the linear\nand centered logarithmic returns, we can write for the\nES E \u2217\nZ \u2212\u2206\u2217 (P\u2217 )\n1\nd(\u2206S) \u2206S p\u0302(\u2206S)\nE \u2217 (P\u2217 ) = \u2212 \u2217\nP \u2212S0\n\u2217\n\u2217\nZ\n\u0001\nS0 \u2212L (P )\ndx p(x) ex+\u03bc\u2206t \u2212 1 , (5)\n= \u2212 \u2217\nP \u2212\u221e\nwhere we have made explicit the dependence of E \u2217 , \u2206\u2217\nand L\u2217 on P\u2217 . From now on we shall drop this dependence and we shall assume S0 = 1. As we did before, we\ncan plug the generalized Fourier transform of p into the\nprevious equation and switch the integration order\nE\n\n\u2217\n\nZ\ne\u03bc\u2206t +\u221e+i\u03bd\n= \u2212\nd\u03c6 f (\u03c6)\n2\u03c0P\u2217 \u2212\u221e+i\u03bd\nZ \u2212L\u2217\n\u0011\n\u0010\n\u00d7\ndx e(1\u2212i\u03c6)x \u2212 e\u2212\u03bc\u2206t\u2212i\u03c6x .\n\n(6)\n\n\u2212\u221e\n\nWhen we pose \u03c6 = \u03c9 + i\u03bd, the first of the two integrands\nin dx requires \u03bd > \u22121 to be evaluated, while the second one requires \u03bd > 0. So, all in all, we are again left\nwith \u03bd \u2208 (0, \u03bd+ ) and, recalling the definition (3) of G\u03bd ,\nequation (6) reads\nE \u2217 = 1 \u2212 e\u03bc\u2206t\n\nRe G\u03bd (L\u2217 , \u03bd + 1)\n.\nRe G\u03bd (L\u2217 , \u03bd)\n\n(7)\n\nFormulae (4) and (7) do represent the first main contribution of this work and let us now see what the main\nadvantage in their use is. Usually, VaR and ES are evaluated in correspondence of a single fixed significance level\nP\u2217 by means of different techniques, see [2] and the online repository at www.gloriamundi.org for an exhaustive review. In the best case scenario, the financial prac-\n\n\u2217\n.\nI\u03bd (L , \u03b8) = Re G\u03bd (L\u2217 , \u03b8) = e\u2212\u03b8L\n\n\u2217\n\nZ\n\n+\u221e\n\nZ\n\n+\u221e\n\n0\n\n\u2212 e\u2212\u03b8L\n\n\u2217\n\n0\n\nI\u03bd (L\u2217 , \u03bd + 1)\nI\u03bd (L\u2217 , \u03bd)\n, E \u2217 = 1 \u2212 e\u03bc\u2206t\n.\n\u03c0\nI\u03bd (L\u2217 , \u03bd)\n\nLet us now mention that the real part of the G\u03bd function can be put into a different form. In fact, we can\ndefine the function\n\n\u0002\n\u0003o\nd\u03c9 n\n\u2217\ncos(\u03c9L\n)\n\u03b8\nRef\n(\u03c9\n+\ni\u03bd)\n\u2212\n\u03c9\nImf\n(\u03c9\n+\ni\u03bd)\n\u03b82 + \u03c9 2\n\u0002\n\u0003o\nd\u03c9 n\n\u2217\nsin(\u03c9L\n)\n\u03c9\nRef\n(\u03c9\n+\ni\u03bd)\n+\n\u03b8\nImf\n(\u03c9\n+\ni\u03bd)\n\u03b82 + \u03c9 2\n\nand we can consequently rewrite the equations for risk\nmeasures as\nP\u2217 =\n\ntitioner is provided with a closed-form expression dependent on distributional assumptions and parametric in the\nquantile of a standardized PDF and in few free parameters to be calibrated on the financial time series in use,\nsee e.g. [6, 31, 32]. However, every time the value of\nP\u2217 is changed, risk measures need to be re-computed.\nMoreover, as anticipated in the introduction, up to now\nthere are no efficient ways to conjugate risk estimation\nwith models fully characterized in terms of the CF. Indeed, this is the case for the class of L\u00e9vy stable distributions and their exponentially damped version [17, 18] and\nfor all those dynamical models emerging in the context\nof option pricing under stochastic volatility, such as the\nStein-Stein, Heston, Schobel-Zhu, exponential OrnsteinUhlenbeck models [21\u201328] and their extensions dealing\nwith jump diffusion, e.g. [33]. The use of the G\u03bd function can overcome all these drawbacks. As a matter of\nfact, once the ECF of the financial dynamics at hand\nis known in closed-form, a grid of \u03c9 values can be set\nand G\u03bd (L\u2217 , \u03bd) (for an admissible value of \u03bd) can be efficiently evaluated via FFT algorithms. This leaves us\nwith a vector L\u2217 , which can be easily converted into a\nvector \u039b\u2217 of VaR estimates. So, inserting L\u2217 in equation\n(4), we are quickly and efficiently provided with the full\nrelation between the VaR estimates and the corresponding appropriate significance levels. Analogously, the FFT\ncomputation of G\u03bd (L\u2217 , \u03bd + 1) provides us with the E \u2217\nspectrum over a whole range of significance levels. Thus,\nequations (4) and (7) provide a global information about\nthe VaR and ES distributions over a wide range of P\u2217\nvalues. These results lead to a very intuitive and easy to\nread graphical representation that we shall discuss in the\nfinal section.\n\n(9)\n\nNow, the I\u03bd function in (8), being the sum of sine and\ncosine transforms, is perfectly suited to numerical evaluation by means of trapezoidal integration algorithms, and\nthis partially prevents the risk estimates in (9) from be-\n\n(8)\n\ning affected by the FFT approximations, which, in turn,\ncan be made negligible only by setting a large \u03c9 grid.\nThe equations in (9) may prove to be very helpful to\nthe evaluation of risk measures at a few specific values\nof the significance level P\u2217 with a very high precision. It\nis also worth stressing again that, remarkably, the only\ninput those equations require is the ECF of the financial\ndynamics under study. As we shall discuss in the next\nsection, this fact makes it possible to introduce and suc-\n\n\f4\ncessfully employ a number of models in the framework of\nrisk management.\nIII.\n\nMODELS\n\nOne of the crucial points in risk analysis is the evaluation of risk measures over different time lags. So, generally, a projection over the desired time horizons of the\nPDFs employed to model financial returns has to be performed. The most interesting case, being the one required by regulators [1], is to project from one to ten\ntrading days. Equations (4), (7) and (9) provide a very\nnatural framework where different time scaling behaviors\ncan be compared. In this section we discuss those arising when considering two class of models: the first one\nof purely additive processes governed by the CLT and a\nsecond class of SVMs.\nAs it has already been stressed, the main ingredient\nrequired by our approach is the knowledge of the closedform ECF associated with the model in use. As a representative member of the class of additive process, we\nconsider a very simple one given by an arithmetic motion whose driving noise is described by a TLD [17]. The\nmost appealing feature of the TLD is the ability to reproduce some of the stylized facts commonly observed in\nfinancial markets, such as the asymmetry and the excess\nof kurtosis [34]. As it is well known, the time scaling\nis governed by the CLT and this causes high order nor-\n\nH(\u03c6) = \u2212\n\npT L (x)\n\n\u2212\u2192\n\nA.\n\nTruncated L\u00e9vy Distributions\n\nThe CF of a TLD can be expressed as f (\u03c6) =\nexp(H(\u03c6)), where the cumulant generating function, or\nHamiltonian, H is given by [18, 35, 36]\n\no\n\u0002\n\u0003\n\u0002\n\u0003\n\u03a32 \u03bb2\u2212\u03b3 n\n(1 + \u03b2) exp \u03b3 log(\u03bb + i\u03c6) + (1 \u2212 \u03b2) exp \u03b3 log(\u03bb \u2212 i\u03c6) \u2212 2\u03bb\u03b3\n2 \u03b3(1 \u2212 \u03b3)\n\nand this gives rise to the following asymptotic behavior\nfor the PDF pT L :\n|x|\u2192+\u221e\n\nmalized cumulants to decrease monotonically with time.\nThe scaling behavior is governed by a power law whose\ncharacteristic exponent is specific for the order of the cumulant, e.g. the skewness scales as t\u22120.5 while the kurtosis scales according to the t\u22121 law. On the other hand,\nSVMs are naturally provided with a different, exponentially damped time scalings, not necessarily monotonic,\nwhich could be able to better capture real market data\ntime scalings. In this article we want to test the ability\nof these models to capture the projection over horizon\nof risk measures in comparison with historical estimates\nand the standard Log-Normal dynamics. Since the most\ncommonly used SVMs are well characterized in terms of\nthe CF, formulae (4) and (7) allow for a proper comparison and the extension of the risk analysis to the context\nof these models does represent the second main contribution of our work. In the following we focus on the Heston\nmodel [23], since it represents a benchmark model in the\noption pricing framework. However, our approach could\nalso be easily applied to other SVMs [21, 25, 28, 29] and\nextended models dealing, for example, with jump diffusion [33].\n\ne\u2212\u03bb|x|\nC\u03a3,\u03b3,\u03bb,\u03b2 1+\u03b3 [1 + \u03b2 sign(x)].\n|x|\n\n(11)\n\nC\u03a3,\u03b3,\u03bb,\u03b2 is a constant depending on the four free parameters which define the distribution. As it is clear from\n(11), \u03b2 determines the level of asymmetry of the PDF,\n\u03b3 \u2208 (0, 2] is the tail exponent (\u03b3 = 2 reducing to the Normal case), while \u03bb > 0 is the decay factor; \u03a3 > 0 defines\nthe level of the second moment of the distribution. The\nvalues of such parameters single out a particular TLD\nunivocally. However, in our case, a corrective positional\nterm has to be added to the Hamiltonian function (10).\nThis is because we work with centered log-returns empirical distribution and so we need to correctly center the\nTLD on the real\ndata. Thus we consider the modified\n\u2032\nHamiltonian H (\u03c6)\n\u0012\n\u0013\n\u2032\n\u03a32\nH (\u03c6) = H(\u03c6) \u2212 i k1 +\n\u03c6\n(12)\n2\n\nwhere k1 = \u2212i\n\ndH\nd\u03c6 \u03c6=0 .\n\n(10)\n\nThe singularity of the model rel-\n\nevant for the strip of regularity is readily found by solving\nthe equation \u03c9 + i\u03bd+ = i\u03bb.\nThe presence of an exponential damping in (11) guarantees the finiteness of the variance, which can be shown\nto be equal to \u03a32 , and of all the higher order moments.\nThe CLT applies and this has immediate consequences\non the time scaling of many relevant quantities. As a\nmatter of fact, upon the addition of N independent identically distributed (i.i.d.) TLD variables the generic n-th\norder cumulant kn scales linearly with N . Then, for the\nskewness \u03b6 and kurtosis \u03ba we have\nk4 (N )\n\u223c N \u22121 .\nk22 (N )\n(13)\nAs it will be discussed in the next paragraph, the Heston\nstochastic volatility model leads to a much richer time\nevolution of the cumulants.\n\u03b6(N ) =\n\nk3 (N )\n\n3/2\nk2 (N )\n\n\u223c N \u22121/2 ,\n\n\u03ba(N ) =\n\n\f5\nB.\n\nHeston dynamics\n\nThe Heston model is defined by the two following coupled stochastic differential equations (SDEs)\np\n(14)\ndS(t) = \u03bcS(t)dt + v(t)S(t)dW1 (t)\np\n2\ndv(t) = \u03b1(\u03c3 \u2212 v(t))dt + k v(t)dW2 (t) (15)\n\nunder the initial conditions S(0) = S0 , v(0) = \u03c3 2 , and for\nstrictly positive \u03b1 and k. The noise W2 (t) is defined in\nterms of the standard Brownian increments dW1 (t) and\n\ndW (t) through the usual relation dW2 (t) = \u03c1dW1 (t) +\np\n1 \u2212 \u03c12 dW (t) and \u03c1 \u2208 [\u22121; 1]. In the following, we shall\nwork with centered log-returns X, whose SDE can be\nderived from the previous ones:\ndX(t) = \u2212\n\np\nv(t)\ndt + v(t)dW1 (t)\n2\n\nwith X0 = 0. By means of standard techniques [23, 24,\n37] the cumulant generating function of the model can\nbe shown to be\n\n\u0001\n\u0001\n\u0001i \u03c3 2 \u03be(\u03c6) \u2212 \u03b7(\u03c6)\n\u0001\n1 \u2212 e\u2212\u03b7(\u03c6)t\n\u03b1\u03c3 2 h\n\u2212\u03b7(\u03c6)t\n+ 2 ln 1 \u2212 g(\u03c6) +\nH(\u03c6) = 2 \u03be(\u03c6) \u2212 \u03b7(\u03c6) t \u2212 2 ln 1 \u2212 g(\u03c6)e\n2\nk\nk\n1 \u2212 g(\u03c6)e\u2212\u03b7(\u03c6)t\n\nwith\n\nA.\n\n\u03be(\u03c6) = \u03b1 \u2212 i\u03c1k\u03c6\np\n\u03b7(\u03c6) =\n\u03be 2 (\u03c6) + k 2 \u03c6(i + \u03c6)\n\u03be(\u03c6) \u2212 \u03b7(\u03c6)\n.\ng(\u03c6) =\n\u03be(\u03c6) + \u03b7(\u03c6)\nFrom (17) the cumulants of the Heston model PDF can\nbe derived explicitly, and their analytical expressions\nare reported in Appendix A. The identification of the\nstrip (0, \u03bd+ ) is more tricky for the Heston case. The\na\nrelevant singular points solve the equations \u03b7(i\u03bd+\n) = 0\nb\n\u2212\u03b7(i\u03bd\n)t\nb\n+\nand 1 \u2212 g(i\u03bd+\n)e\n= 0. Restricting to the case\na\n\u03c1\nhave \u03bd+\n=\nh \u2208 (\u22121, 1),pfrom the former equationi we\n\u0002\n\u0003\n2\n2\u03b1\u03c1 \u2212 k + (2\u03b1\u03c1 \u2212 k)2 + 4\u03b12 (1 \u2212 \u03c12 ) / 2k(1 \u2212 \u03c1 ) ;\nthe latter can not be solved explicitly but, once a set of\nparameters values has been fixed, we can numerically\nb\na\ncheck if there is any positive \u03bd+\n< \u03bd+\n. However, for\ntypical values of \u03b1 \u223c 102 and k \u223c 10, and for \u03bd \u2208 (0, 1]\nwe obtain positive \u03b7 and \u03be of order 102 ; so, for each\nb\nt > 0, a candidate \u03bd+\nhas to be strictly greater than one.\nThus, if we fix \u03bd = 1 when integrating equations (4) and\na\n(7), we have only to check that \u03bd+ = \u03bd+\n> 1.\n\nIV.\n\nDATA ANALYSIS AND NUMERICAL\nRESULTS\n\nAs already remarked, our aim is to capture the empirical scaling of the returns and to exploit it in order to\nend up with reliable risk estimates projections over the\ntime horizons of interest. Both in the TLD and in the\nHeston model case, we perform this task by focusing on\nthe calibration on the first four cumulants time scalings.\n\n(16)\n\n(17)\n\nData Sets and Calibration\n\nTLDs are fitted on empirical distributions by means of\na simple step-by-step procedure according to which the\nfree parameters in (10), \u03a3, \u03b3, \u03b2 and \u03bb, are evaluated one\nat a time. First, extending the approaches developed in\n[17, 19] to the case of asymmetric TLDs, the tail exponent\n\u03b3 is fitted exploiting the time scaling of the empirical zero\nreturn probability. Actually, the quantity pL (X = 0) of a\nL\u00e9vy distribution (a good approximation for the central\nregion of a TLD, since the exponential damping mainly\naffects the tail regions) is used. Such a point can be\nshown to scale linearly with time t on a log-log scale\n(t)\n\nlog pL (0) = log\n\nf (\u03b3, \u03b2) 1\n\u2212 log t\nc\u03c0\u03b3\n\u03b3\n\n(18)\n\nwhere c is a constant, while f is a function of the \u03b3 and \u03b2\nparameters. Clearly, from the slope of this linear relation\nthe value of \u03b3 can be estimated. Moreover, we consider\nthe following relations [35] valid for the variance, skewness and kurtosis of a TLD over an horizon t\nk2 (t) = \u03a32 t\n\u03ba(t) = (2 \u2212 \u03b3)(3 \u2212 \u03b3)/(\u03bb2 \u03a32 t)\n\u221a\n\u03b6(t) = \u03b2(2 \u2212 \u03b3)/(\u03bb \u03a32 t).\n\n(19)\n\n\u03a3 can be readily estimated from the first relation, while\n\u03bb and \u03b2 can be obtained from the remaining ones. Both\nlast two relations can be rearranged into linear ones on\na log - log scale. Thus, the parameters of interest can all\nbe estimated via Marquardt-Levenberg linear fits.\nThe Heston model calibration is performed differently.\nBy imposing the initial condition v0 = \u03c3 2 , we assumed\nthe model to be in its stationary volatility state. The\nempirical mean \u03bc is estimated from the linear returns\ndirectly. Moreover, it is clear from the analytical expression reported in Appendix A that \u03c3 can be fitted on the\n\n\f6\nof the original time series and this is done by means of a\nGARCH(1,1) model to preserve the correlation structure\nof the volatility. Such a model is defined by the following\ncouple of equations\n\ntime scaling of the first cumulant. This leaves us with\nthree more parameters to be estimated, i.e. \u03b1, \u03c1 and k.\nWe obtain the optimal values by solving the following\nminimization problem numerically\n\u03b1\u2217 , \u03c1\u2217 , k \u2217 =\n\nargmin\n\n\u00152\n4 \u0014 E\n10 X\nX\nk (j\u2206t) \u2212 ki (j\u2206t)\ni\n\n\u03c1\u2208(\u22121,1); \u03b1,k>0 j=1 i=2\n\n\u01ebki (j\u2206t)\n\nIn the previous equation the first sum runs over trading days (\u2206t = 3.98 \u00d7 10\u22123 years), while the second one\nruns over the cumulants: kiE represents the i\u2212th empirically estimated cumulant, with statistical uncertainty \u01ebki ,\nwhereas ki represents the i\u2212th analytical cumulant.\nThe calibration has been performed on three different data sets, made of 5000 daily returns each, from the\nGerman DAX 30 Index (from November 14th 1988 to\nSeptember 9th 2008), the French CAC 40 Index (from\nNovember 10th 1988 to September 9th 2008) and the\nDow Jones EURO STOXX 50 (SX5E) Index (from March\n10th 1989 to September 9th 2008). In Table I all of the\nrelevant parameter estimates, both for the TLD and the\nHeston model, are reported. In Figure 1 the different\ntime scalings obtained from such parameters are compared with the empirical ones. In the two upper figures\nthe time scaling of the mean and variance is considered.\nAn excellent agreement is observed for both the TLD\nand the Heston model. In the lower figures, even though\nthe calibration was performed over the cumulants, we\nreport the skewness and kurtosis time scaling because\nof their major relevance in risk analysis. Due to error\npropagation, the error bars look much more irregular in\nthese cases. As it can be seen, the Heston model better\ndescribes the empirical scaling than the TLD model, especially for the kurtosis data. For the skewness scaling,\nHeston slightly outperforms the TLD approach, as confirmed in Figure 2 for the SX5E Index case. We shall see\nin the next section how this behaviour is translated in\nterms of the risk estimates.\nB.\n\nRisk Estimates\n\nIn this section we detail and discuss all of the risk estimates we obtained. We present the results based on the\nTLD and Heston models under the generalized Fourier\ntransform approach. As already discussed, this essentially amounts to the use of formulae (3), (4) and (7).\nAs benchmark models we consider the Log-Normal dynamics and the historical approach. The former is meant\nto provide a comparison with the results obtained under\nthe standard normality assumption for the returns; the\nlatter, instead, provides some insight into the actual risk\nlevels of an asset. Historical estimates are obtained with\nstandard methodologies (see [6] for example).\nWe also employ the calibration procedure described in\nthe above section in a bootstrap framework in order to\nprovide the risk estimates with 68% CL intervals. For\neach data set we generate MB = 1000 synthetic copies\n\n.\n\nYt = C + \u03c3t zt\n2\n2\n2\n\u03c3t2 = K + G\u03c3t\u22121\n+ A\u03c3t\u22121\nzt\u22121\n,\n\n(20)\n\nwhere Yt is the log-return at time t, \u03c3t describes its\nvolatility and the zt 's, often referred to as innovations,\ncorrespond to a Gaussian white noise; C, K, G and\nA are constant quantities. The model calibration can\nbe succesfully performed with the help of R software\n(www.r-project.org). Being i.i.d. Gaussian variables,\nthe bootstrap technique can be applied to the innovations in order to generate replicas of the original time\nseries preserving the volatility clustering. In our analysis, the TLD and Heston model calibrations have been\ncarried out on each bootstrap copy. This provides us\nwith a different set of parameter values for each copy\nthat can be plugged into the ECF and consequently into\nequations (4) and (7) to obtain copy-dependent risk estimates \u03b8j\u2217 for j = 1, . . . , MB , where \u03b8 can represent either\nVaR or ES. Then, bootstrap confidence levels are defined\n\u2217\nas [\u03b8\u03b1\u2217 ; \u03b81\u2212\u03b1\n], with the boundaries of the interval satisfy\u2217\ning the following relation: Prob(\u03b8\u2217 \u2264 \u03b8\u03b1,1\u2212\u03b1\n) = \u03b1, 1 \u2212 \u03b1.\nThus, a 68% CL interval requires \u03b1 = 16%. The bootstrap technique allows us to draw statistically robust conclusions. In Figure 3 we report two example bootstrap\n\u2217\nhistograms of \u039b\u2217H and EH\nfor the CAC 40 Index; from\ntheir analysis we can identify the extremes of the confidence intervals at the desired CL.\nAs already mentioned, one of the main motivations to\nour approach is the need for a natural projection over\nhorizon framework. As required by regulators, we focus on risk measures evaluation at 1 day and 10 days\nhorizons. Besides this, VaR and ES are evaluated at\nP\u2217 = 1%, this also being requested by regulators, and at\nP\u2217 = 5%. In Table II and Table III the risk estimates\nfor P\u2217 = 1% at 1 day and 10 days horizons are detailed;\nthe \"Hist\" subscript refers to historical estimates, while\nN refers to the Normal ones, T and H to the TLD and\nHeston models, respectively. A few comments need now\nto be made. First of all, the best agreement with histor\u2217\nical estimates is found for \u039b\u2217H and EH\n, and it is remark\u2217\nable for the P = 1%, 1 day VaR. The agreement slightly\nworsens for the TLD, while the Normal estimates widely\n\u2217\nunderestimate \u039b\u2217Hist and EHist\n. These results confirm the\nability of both the Heston and TLD models to better describe tail events of the empirical distributions than the\nLog-Normal model. When considering a 10 days horizon\nthe errors get much larger, since the empirical risk estimates are evaluated on the basis of 500 returns only.\nThe Heston and historical values are in best statistical\nagreement, while TLD and Normal estimates definitely\nworsen, and they get much closer as a consequence of\nthe CLT, as expected. These results suggest that the\nprojection over time horizon associated with the dynamics of the Heston model can provide a better description\n\n\f7\n\nTABLE I: Values of \u03bc (left) and of the TLD (center) and Heston (right) models parameters as estimated from the data sets.\n\u03a32 (%)\n4.64\n4.11\n3.55\n\n\u03bc(\u00d710\u22122 )\n11.02\n7.47\n8.73\n\nDAX\nCAC\nSX5E\n\n\u03b3\n1.77\n1.84\n1.78\n\n5.0\n\n\u03bb\n10.74\n11.78\n13.60\n\n\u03b1\n86\n330\n287\n\nk\n4.67\n8.08\n8.82\n\n\u03c1\n-0.17\n-0.06\n-0.12\n\n2.0\n\nMarket Data\nHeston\nTLD\n\n2.5\n\n1.5\n\nVariance (10\u22123 )\n\nMean (10\u22123 )\n\n\u03c3 2 (%)\n4.71\n4.21\n3.88\n\n\u03b2\n-0.38\n-0.21\n-0.33\n\n0.0\n\n-2.5\n\n1.0\n\n0.5\n\n-5.0\n\n0.0\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n0\n\n2\n\n4\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n6\n\n8\n\n10\n\n1.5\n\n0.5\n\n0.0\n\nKurtosis (10)\n\nSkewness\n\n1.0\n\n-0.5\n\n0.5\n\n-1.0\n\n0.0\n-1.5\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nTrading Days\n\nTrading Days\n\nFIG. 1: Comparison between the empirical, TLD and Heston time scaling of the mean, variance, skewness and kurtosis for the\nCAC 40 Index time series over a 10 days horizon.\n\n1.5\n\n0.5\nMarket Data\nHeston\nTLD\n0.0\nKurtosis (10)\n\nSkewness\n\n1.0\n\n-0.5\n\n0.5\n\n-1.0\n\n0.0\n-1.5\n0\n\n2\n\n4\n\n6\nTrading Days\n\n8\n\n10\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nTrading Days\n\nFIG. 2: Comparison between the empirical, TLD and Heston time scaling of the skewness and kurtosis for the SX5E Index\nover a 10 days horizon.\n\n\f8\n140\n\n120\n\n120\n\nNumber of Events\n\n100\n\n100\n\n80\n\n80\n60\n60\n40\n\n40\n\n20\n\n0\n\n20\n\n3\n\n3.5\n\n4\n\n4.5\n\n5\n\n0\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nE \u2217 (%)\n\n\u039b\u2217 (%)\n\nFIG. 3: VaR and ES bootstrap histograms for the Heston model; both plots refer to P\u2217 = 1% over a 1 day horizon for the\nCAC 40 Index.\n17.50\n\n7.00\n\n15.00\n\n\u039b\u2217 (%)\n\n5.00\n\n\u039b\u2217H\n\u2217\nEH\n\u039b\u2217L\nEL\u2217\n\u039b\u2217G\n\u2217\nEG\n\n3.62\n3.00\n\n9.97\n\n\u039b\u2217Hist\n\u2217\nEHist\n5.00\n1.00\n\n0\n\n1.00\n\n2.50\n\n4.64\n\n7.50\n\n10.00\n\n1.00\n\n0 1.00\n\n5.00\n\nP \u2217 (%), E \u2217 (%)\n\n10.00\n\n12.31\n\n15.00\n\n20.00\n\nP \u2217 (%), E \u2217 (%)\n\nFIG. 4: Plot of \u039b\u2217 vs P\u2217 and E \u2217 over 1 day (left) and 10 days (right) horizons for the SX5E Index.\n\nTABLE II: Historical, Normal, TLD and Heston VaR and ES\nestimates at P\u2217 = 1% over a 1 day horizon.\nDAX\nCAC\nSX5E\nDAX\nCAC\nSX5E\n\n\u039b\u2217Hist (%)\n3.94+0.18\n\u22120.17\n3.54+0.15\n\u22120.15\n3.62+0.15\n\u22120.16\n\u2217\nEHist\n(%)\n5.25+0.42\n\u22120.40\n4.55+0.27\n\u22120.29\n4.71+0.35\n\u22120.39\n\n\u039b\u2217N (%)\n3.10+0.09\n\u22120.10\n2.95+0.07\n\u22120.07\n2.82+0.09\n\u22120.09\n\u2217\nEN\n(%)\n3.60+0.10\n\u22120.12\n3.38+0.07\n\u22120.07\n3.25+0.11\n\u22120.09\n\n\u039b\u2217T (%)\n3.36+0.28\n\u22120.28\n3.01+0.20\n\u22120.20\n3.16+0.26\n\u22120.26\nET\u2217 (%)\n4.78+0.57\n\u22120.59\n4.03+0.43\n\u22120.40\n4.67+0.54\n\u22120.50\n\n\u039b\u2217H (%)\n3.69+0.40\n\u22120.39\n3.53+0.26\n\u22120.26\n3.61+0.36\n\u22120.33\n\u2217\nEH\n(%)\n4.52+0.90\n\u22120.87\n4.44+0.46\n\u22120.48\n4.63+0.84\n\u22120.73\n\nof the risk level for low P\u2217 than the one induced by the\nCLT. As far as a higher P\u2217 level is concerned, we consider\nP\u2217 = 5% (see Table IV and Table V). One can see that,\nboth for the daily and 10 days horizon, the difference between the different VaR estimates reduces. For the ES,\nwhich by definition exibits a higher sensitivity to the tail\nbehaviour than VaR, we again find the best performance\n\nTABLE III: Historical, Normal, TLD and Heston VaR and\nES estimates at P\u2217 = 1% over a 10 days horizon.\nDAX\nCAC\nSX5E\nDAX\nCAC\nSX5E\n\n\u039b\u2217Hist (%)\n13.01+1.56\n\u22121.52\n11.98+1.30\n\u22121.42\n9.85+1.44\n\u22121.45\n\u2217\nEHist\n(%)\n16.39+2.16\n\u22122.21\n15.12+1.81\n\u22121.76\n11.16+2.12\n\u22122.30\n\n\u039b\u2217N (%)\n9.27+0.36\n\u22120.34\n8.89+0.27\n\u22120.29\n8.50+0.34\n\u22120.34\n\u2217\nEN\n(%)\n10.58+0.38\n\u22120.38\n10.13+0.29\n\u22120.30\n9.69+0.37\n\u22120.37\n\n\u039b\u2217T (%)\n9.38+0.57\n\u22120.63\n8.72+0.44\n\u22120.43\n8.76+0.65\n\u22120.62\nET\u2217 (%)\n11.57+1.03\n\u22121.07\n10.48+0.65\n\u22120.62\n11.07+1.09\n\u22121.01\n\n\u039b\u2217H (%)\n11.71+1.07\n\u22121.07\n9.80+0.71\n\u22120.70\n9.95+1.03\n\u22120.95\n\u2217\nEH\n(%)\n14.81+1.55\n\u22121.65\n11.83+1.05\n\u22121.06\n12.28+1.61\n\u22121.47\n\nfor the Heston model. In particular, when switching to\nthe 10 days horizon, the Heston model definitely leads\nto the best overall agreement with historical estimates.\nFinally, we present a graphical representation, very effective for practical applications. In Figure 4, left panel, we\nplot \u039b\u2217 against the significance level over a daily horizon;\nthe curves are obtained via an adaptive trapezoidal inte-\n\n\f9\nTABLE IV: Historical, Normal, TLD and Heston VaR and\nES estimates at P\u2217 = 5% over a 1 day horizon.\nDAX\nCAC\nSX5E\nDAX\nCAC\nSX5E\n\n\u039b\u2217Hist (%)\n2.13+0.06\n\u22120.06\n2.08+0.05\n\u22120.05\n1.91+0.05\n\u22120.05\n\u2217\nEHist\n(%)\n3.26+0.12\n\u22120.12\n3.00+0.10\n\u22120.10\n2.94+0.10\n\u22120.11\n\n\u039b\u2217N (%)\n2.19+0.07\n\u22120.07\n2.09+0.05\n\u22120.05\n1.99+0.07\n\u22120.07\n\u2217\nEN\n(%)\n2.75+0.08\n\u22120.09\n2.63+0.07\n\u22120.07\n2.51+0.09\n\u22120.09\n\n\u039b\u2217T (%)\n2.01+0.08\n\u22120.08\n1.93+0.06\n\u22120.06\n1.78+0.07\n\u22120.06\nET\u2217 (%)\n2.95+0.20\n\u22120.21\n2.68+0.14\n\u22120.14\n2.71+0.20\n\u22120.19\n\n\u039b\u2217H (%)\n2.28+0.13\n\u22120.10\n2.08+0.08\n\u22120.07\n2.01+0.11\n\u22120.11\n\u2217\nEH\n(%)\n3.17+0.24\n\u22120.24\n3.00+0.17\n\u22120.17\n3.01+0.23\n\u22120.21\n\nTABLE V: Historical, Normal, TLD and Heston VaR and ES\nestimates at P\u2217 = 5% over a 10 days horizon.\nDAX\nCAC\nSX5E\nDAX\nCAC\nSX5E\n\n\u039b\u2217Hist (%)\n6.53+0.52\n\u22120.51\n6.04+0.47\n\u22120.46\n5.64+0.45\n\u22120.46\n\u2217\nEHist\n(%)\n9.99+0.87\n\u22120.91\n9.06+0.76\n\u22120.77\n7.70+0.84\n\u22120.86\n\n\u039b\u2217N (%)\n6.55+0.29\n\u22120.30\n6.31+0.23\n\u22120.25\n6.01+0.28\n\u22120.28\n\u2217\nEN\n(%)\n8.22+0.33\n\u22120.32\n7.89+0.26\n\u22120.27\n7.52+0.32\n\u22120.32\n\n\u039b\u2217T (%)\n6.09+0.30\n\u22120.31\n5.87+0.24\n\u22120.26\n5.53+0.29\n\u22120.29\nET\u2217 (%)\n8.18+0.52\n\u22120.52\n7.66+0.35\n\u22120.38\n7.60+0.52\n\u22120.50\n\n\u039b\u2217H (%)\n6.74+0.36\n\u22120.36\n6.36+0.30\n\u22120.31\n6.12+0.36\n\u22120.36\n\u2217\nEH\n(%)\n9.73+0.80\n\u22120.78\n8.49+0.55\n\u22120.54\n8.49+0.75\n\u22120.71\n\ngration of the I\u03bd (L\u2217 , \u03b8) function to increase the numerical accuracy w.r.t. FFT based approaches. We consider\na grid of one hundred equally spaced P\u2217 values ranging\nfrom 0.1% to 10% and \u03bd = 1. Triangles represent historical estimates and the matching with the Heston curve is\nquite evident. We explicitly draw a vertical dotted line\nfor P\u2217 = 1%. The crossing point with the Heston curve\nidentifies the VaR estimate for the specified significance\nlevel. If we translate the estimate over the ES curve we\nobtain a new crossing point, whose projection over the\nhorizontal axis returns the desired ES value. In the right\npanel of the same figure the analysis is performed for\na 10 days horizon. This graphical approach shows how\nstraightforward it is to obtain the risk estimates and to\ncompare performances provided by different models.\nV.\n\nCONCLUSIONS\n\nIn this paper we have shown how the extension of the\nCF to the complex domain can be successfully employed\nto derive compact formulae describing VaR and ES, the\ntwo market risk measures most financial industries ordinarily use. The same technique has already been widely\n\nadopted and tested in the context of option pricing under stochastic volatility. The analogy is not so surprising when noticing that the integral equation linking L\u2217\nand P\u2217 , see equation (2), clearly resembles the relation\nbetween the strike and the price of an option with a\ndigital payoff. A similar argument applies to the ES,\neven though in this case the payoff function looks a little\n\u0001\nbit more complicated, i.e. [1 \u2212 \u0398(x + L\u2217 )] ex+\u03bc\u2206t \u2212 1 ,\nwhere \u0398 is the Heaviside step function, see equation (5).\nExploiting these analogies, we have obtained new integral\nrepresentation of risk in terms of the function G\u03bd (L\u2217 , \u03b8),\nparticularly suited to efficient numerical integration using\nFFT algorithms. Based on the function I\u03bd (L\u2217 , \u03b8) and on\nadaptive trapezoidal algorithms, we have also suggested\nan alternative approach to perform an accurate integration of our formulae. Our focus was on two types of logreturns stochastic dynamics. The first one is a simple\narithmetic motion whose random increments correspond\nto a Truncated L\u00e9vy noise, while the second is the Heston stochastic volatility dynamics. Both models are analytically well-defined in terms of the CF; moreover, the\nCLT applies to the former predicting a power-law scaling\nwith time of high order normalized cumulants. In the\nHeston case, instead, their time evolution obeys an exponentially damped scaling. Since the risk measure projection over time horizons is one of the points addressed\nby regulators, we have compared the performances provided by these conceptually quite different models. We\nhave tested our analytical formulae on a data set of financial indexes, the German DAX 30 Index, the French\nCAC 40 and the European Dow Jones EURO STOXX\n50. The results we obtained both for the TLD and Heston cases have shown an excellent agreement with the\nhistorical benchmark values, within the bootstrap 68%\nCL . In particular, at the significance level required by\nregulators, i.e. P\u2217 = 1%, the Heston model was found\nto provide the best risk characterization, at least for the\ndata we took into account.\nPossible perspectives of the present work concern the\napplication of the approach to the evaluation of risk measures using other SVMs, such as exponential OrnsteinUhlenbeck models and their extensions with jump diffusion.\n\nAppendix A: Heston model cumulants\n\nIn the following we report the analytical expressions of\nthe Heston model cumulants\n\n\f10\n\n1\nk1 = \u2212 \u03c3 2 t,\n2\n\u0003\n\u03c32 \u0002\nk2 =\n\u2212 k 2 e\u22122\u03b1t + 4ke\u2212\u03b1t (k \u2212 2\u03b1\u03c1) + 2\u03b1t(4\u03b12 + k 2 \u2212 4\u03b1k\u03c1) + k(8\u03b1\u03c1 \u2212 3k) ,\n3\n8\u03b1\n\u0002\nk\u03c3 2 n 3 \u22123\u03b1t\nk e\n\u2212 3\u03b1ke\u22122\u03b1t [\u2212kt(k \u2212 2\u03b1\u03c1) \u2212 2(\u03b1 \u2212 k\u03c1)] \u2212 3e\u2212\u03b1t 2\u03b1kt(k \u2212 2\u03b1\u03c1)2 + 3k 3 \u2212 8\u03b13 \u03c1 \u2212 16\u03b1k 2 \u03c1\nk3 =\n5\n8\u03b1\no\n\u0003\n\u0002\n\u0003\n+8\u03b12 k(1 + 2\u03c12 ) + 3\u03b1t \u2212k 3 + 8\u03b13 \u03c1 + 6\u03b1k 2 \u03c1 \u2212 4\u03b12 k(1 + 2\u03c12 ) + 8k 3 \u2212 24\u03b13 \u03c1 \u2212 42\u03b1k 2 \u03c1 + 6\u03b12 k(3 + 8\u03c12 ) ,\nh\n\u0002\n\u0003\n3k 2 \u03c3 2 n\n2\n2\n\u22122\u03b1t\n4 \u22124\u03b1t\n2 \u22123\u03b1t\nk4 =\n4\u03b12 k 2 t2 (k \u2212 2\u03b1\u03c1)2\n2\u03b1kt(k\n\u2212\n2\u03b1\u03c1)\n+\n4\u03b1\n+\nk\n\u2212\n6\u03b1k\u03c1\n\u2212\n4e\n\u2212\n3k\ne\n\u2212\n8k\ne\n64\u03b17\ni\n\u0002\n\u0003\n+2\u03b1kt k 3 \u2212 16\u03b13 \u03c1 \u2212 12\u03b1k 2 \u03c1 + 4\u03b12 k(3 + 4\u03c12 ) + 8\u03b14 \u2212 3k 4 \u2212 32\u03b13 k\u03c1 + 8\u03b1k 3 \u03c1 + 16\u03b12 k 2 \u03c12\nh\n\u0002\n\u0003\n\u22128e\u2212\u03b1t \u2212 2\u03b12 kt2 (k \u2212 2\u03b1\u03c1)3 \u2212 8\u03b1t k 4 \u2212 7\u03b1k 3 \u03c1 + 4\u03b14 \u03c12 \u2212 8\u03b13 k\u03c1(1 + \u03c12 ) + \u03b12 k 2 (3 + 14\u03c12 ) \u2212 9k 4 + 70\u03b1k 3 \u03c1\ni\n\u0002\n+32\u03b13 k\u03c1(4 + 3\u03c12 ) \u2212 16\u03b14 (1 + 4\u03c12 ) \u2212 4\u03b12 k 2 (9 + 40\u03c12 ) + 4\u03b1t 5k 4 \u2212 40\u03b1k 3 \u03c1 \u2212 32\u03b13 k\u03c1(3 + 2\u03c12 ) + 16\u03b14 (1 + 4\u03c12 )\no\n\u0003\n+24\u03b12 k 2 (1 + 4\u03c12 ) \u2212 73k 4 + 544\u03b1k 3 \u03c1 + 128\u03b13 k\u03c1(7 + 6\u03c12 ) \u2212 32\u03b14 (3 + 16\u03c12 ) \u2212 64\u03b12 k 2 (4 + 19\u03c12 ) .\n\n[1] Basel II: International convergence of capital measurement and capital standards. A revised framework (2006),\nBasel Committee on Banking Supervision Technical Document.\n[2] P. Jorion, Value at Risk: The New Benchmark for Managing Financial Risk (McGraw-Hill, New York, 2001).\n[3] C. Acerbi and D. Tasche, J. Banking Finance 26, 1487\n(2001).\n[4] V. Heikkinen and A. Kanto, Journal of Risk 4, 77 (2002).\n[5] J. Kamdem, Int. J. Theoretical and Appl. Finance 8, 537\n(2005).\n[6] G. Bormetti, E. Cisana, G. Montagna, and O. Nicrosini,\nPhysica A 376, 532 (2007).\n[7] A. L. Lewis, A simple option formula for general jumpdiffusion and other exponential L\u00e9vy processes (2001),\nhttp://ssrn.com/abstract=282110.\n[8] A. Lipton, Mathematical Methods For Foreign Exchange:\nA Financial Engineer's Approach (World Scientific Publishing, Singapore, 2001).\n[9] C. Rouvinez, Risk 10, 57 (1997).\n[10] J. Cardenas, E. Fruchard, E. Koehler, C. Michel, and\nI. Thomazeau, Risk 10, 72 (1998).\n[11] M. Britten-Jones and S. M. Schaefer, Eur. Finance Rev.\n2, 161 (1999).\n[12] J. Mina and A. Ulmer, Delta-gamma four ways Technical\nreport RiskMetrics Group (1999).\n[13] D. Duffie and J. Pan, Finance Stochastics 5, 155 (2001).\n[14] P. Glasserman, P. Heidelberger, and P. Shahabuddin,\nMath. Finance 12, 239 (2002).\n[15] C. Albanese, K. Jackson, and P. Wiberg, Quant. Finance\n4, 328 (2004).\n[16] J. Gil-Pelaez, Biometrika 38, 481 (1951).\n[17] R. N. Mantegna and H. E. Stanley, Phys. Rev. Lett. 73,\n2946 (1994).\n[18] I. Koponen, Phys. Rev. E 52, 1197 (1995).\n\n[19] A. Matacz, Int. J. Theoretical Appl. Finance 3, 143\n(2000).\n[20] R. N. Mantegna and H. E. Stanley, An Introduction to\nEconophysics: Correlations and Complexity in Finance\n(Cambridge University Press, Cambridge UK, 2000).\n[21] E. Stein and J. Stein, Rev. Finan. Stud. 4, 727 (1991).\n[22] J. Masoliver and J. Perell\u00f3, Int. J. Theoretical Appl. Finance 5, 541 (2002).\n[23] S. L. Heston, Rev. Finan. Stud. 6, 327 (1993).\n[24] A. A. Drag\u016dlescu and V. M. Yakovenko, Quant. Finance\n2, 443 (2002).\n[25] R. Sch\u00f6bel and J. Zhu, Eur. Finance Rev. 4, 23 (1999).\n[26] L. Scott, J. Finan. Quant. Anal. 22, 419 (1987).\n[27] J. Masoliver and J. Perell\u00f2, Quant. Finance 6, 423 (2006).\n[28] G. Bormetti, V. Cazzola, G. Montagna, and O. Nicrosini,\nJ. Stat. Mech. p. JSTAT11(2008)013 (2008).\n[29] G. Bormetti, V. Cazzola, and D. Delpini, Option pricing under Ornstein-Uhlenbeck stochastic volatility (2009),\narXiv:0905.1882 [q-fin.PR].\n[30] G. Bormetti and G. Livan, Submitted (2009).\n[31] J. Mina and J. Y. Xiao, Return to RiskMetrics. The\nEvolution of a Standard (RiskMetrics Group, New York,\n2001).\n[32] G. Bormetti, M. E. De Giuli, D. Delpini, and C. Tarantola, Bayesian Value-at-Risk with Product Partition\nmodels (2009), arXiv:0809.0241v2 [q-fin.RM].\n[33] A. Lipton and A. Sepp, J. Physics A 41, 344012 (2008).\n[34] J. P. Bouchaud and M. Potters, Theory of Financial Risk\nand Derivative Pricing: From Statistical Physics to Risk\nManagement (Cambrigde University Press, Cambridge,\n2003).\n[35] H. Kleinert, Physica A 311, 536 (2002).\n[36] H. Kleinert, Path Integrals in Quantum Mechanics,\nStatistics, Polymer Physics, and Financial Markets\n(World Scientific, Singapore, 2009).\n\n\f11\n[37] R. Lord and C. Kahl, Why the rotation count algorithm\nworks Tinbergen Institute Discussion Paper (2006).\n\n\f"}