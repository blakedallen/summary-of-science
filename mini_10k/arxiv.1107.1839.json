{"id": "http://arxiv.org/abs/1107.1839v1", "guidislink": true, "updated": "2011-07-10T07:18:52Z", "updated_parsed": [2011, 7, 10, 7, 18, 52, 6, 191, 0], "published": "2011-07-10T07:18:52Z", "published_parsed": [2011, 7, 10, 7, 18, 52, 6, 191, 0], "title": "Interference Networks with General Message Sets: A Random Coding Scheme", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1107.4485%2C1107.1802%2C1107.1645%2C1107.3366%2C1107.3395%2C1107.1407%2C1107.1703%2C1107.1213%2C1107.4866%2C1107.0303%2C1107.5363%2C1107.0549%2C1107.3729%2C1107.0484%2C1107.3141%2C1107.3444%2C1107.0111%2C1107.0998%2C1107.5068%2C1107.3523%2C1107.0335%2C1107.4313%2C1107.2607%2C1107.0268%2C1107.2094%2C1107.3495%2C1107.3947%2C1107.4994%2C1107.2926%2C1107.4627%2C1107.3576%2C1107.3253%2C1107.1275%2C1107.5580%2C1107.3400%2C1107.5604%2C1107.4062%2C1107.4207%2C1107.0613%2C1107.2181%2C1107.0760%2C1107.0420%2C1107.2448%2C1107.0475%2C1107.4028%2C1107.3194%2C1107.2077%2C1107.2397%2C1107.3212%2C1107.5798%2C1107.1975%2C1107.1881%2C1107.4266%2C1107.2119%2C1107.2601%2C1107.4816%2C1107.1374%2C1107.4199%2C1107.0018%2C1107.2712%2C1107.5909%2C1107.4001%2C1107.0826%2C1107.0412%2C1107.3823%2C1107.1638%2C1107.2317%2C1107.1590%2C1107.3998%2C1107.3407%2C1107.5780%2C1107.1095%2C1107.3378%2C1107.3722%2C1107.5590%2C1107.0372%2C1107.4747%2C1107.4308%2C1107.2837%2C1107.2790%2C1107.4222%2C1107.5668%2C1107.5834%2C1107.4165%2C1107.2557%2C1107.1899%2C1107.3754%2C1107.4740%2C1107.5095%2C1107.2086%2C1107.4659%2C1107.1163%2C1107.3825%2C1107.1702%2C1107.5111%2C1107.4407%2C1107.5088%2C1107.1835%2C1107.5970%2C1107.1839%2C1107.0462&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Interference Networks with General Message Sets: A Random Coding Scheme"}, "summary": "In this paper, the Interference Network with General Message Sets (IN-GMS) is\nintroduced in which several transmitters send messages to several receivers:\nEach subset of transmitters transmit an individual message to each subset of\nreceivers. For such a general scenario, an achievability scheme is presented\nusing the random coding. This scheme is systematically built based on the\ncapacity achieving scheme for the Multiple Access Channel (MAC) with common\nmessage as well as the best known achievability scheme for the Broadcast\nChannel (BC) with common message. A graphical illustration of the random\ncodebook construction procedure is also provided, by using which the\nachievability scheme is easily understood. Some benefits of the proposed\nachievability scheme are described. It is also shown that the resulting rate\nregion is optimal for a class of orthogonal INs-GMS, which yields the capacity\nregion. Finally, it is demonstrated that how this general achievability scheme\ncan be used to derive capacity inner bounds for interference networks with\ndifferent distribution of messages; in most cases, the proposed achievability\nscheme leads to the best known capacity inner bound for the underlying channel.\nCapacity inner bounds can also be derived for new communication scenarios.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1107.4485%2C1107.1802%2C1107.1645%2C1107.3366%2C1107.3395%2C1107.1407%2C1107.1703%2C1107.1213%2C1107.4866%2C1107.0303%2C1107.5363%2C1107.0549%2C1107.3729%2C1107.0484%2C1107.3141%2C1107.3444%2C1107.0111%2C1107.0998%2C1107.5068%2C1107.3523%2C1107.0335%2C1107.4313%2C1107.2607%2C1107.0268%2C1107.2094%2C1107.3495%2C1107.3947%2C1107.4994%2C1107.2926%2C1107.4627%2C1107.3576%2C1107.3253%2C1107.1275%2C1107.5580%2C1107.3400%2C1107.5604%2C1107.4062%2C1107.4207%2C1107.0613%2C1107.2181%2C1107.0760%2C1107.0420%2C1107.2448%2C1107.0475%2C1107.4028%2C1107.3194%2C1107.2077%2C1107.2397%2C1107.3212%2C1107.5798%2C1107.1975%2C1107.1881%2C1107.4266%2C1107.2119%2C1107.2601%2C1107.4816%2C1107.1374%2C1107.4199%2C1107.0018%2C1107.2712%2C1107.5909%2C1107.4001%2C1107.0826%2C1107.0412%2C1107.3823%2C1107.1638%2C1107.2317%2C1107.1590%2C1107.3998%2C1107.3407%2C1107.5780%2C1107.1095%2C1107.3378%2C1107.3722%2C1107.5590%2C1107.0372%2C1107.4747%2C1107.4308%2C1107.2837%2C1107.2790%2C1107.4222%2C1107.5668%2C1107.5834%2C1107.4165%2C1107.2557%2C1107.1899%2C1107.3754%2C1107.4740%2C1107.5095%2C1107.2086%2C1107.4659%2C1107.1163%2C1107.3825%2C1107.1702%2C1107.5111%2C1107.4407%2C1107.5088%2C1107.1835%2C1107.5970%2C1107.1839%2C1107.0462&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper, the Interference Network with General Message Sets (IN-GMS) is\nintroduced in which several transmitters send messages to several receivers:\nEach subset of transmitters transmit an individual message to each subset of\nreceivers. For such a general scenario, an achievability scheme is presented\nusing the random coding. This scheme is systematically built based on the\ncapacity achieving scheme for the Multiple Access Channel (MAC) with common\nmessage as well as the best known achievability scheme for the Broadcast\nChannel (BC) with common message. A graphical illustration of the random\ncodebook construction procedure is also provided, by using which the\nachievability scheme is easily understood. Some benefits of the proposed\nachievability scheme are described. It is also shown that the resulting rate\nregion is optimal for a class of orthogonal INs-GMS, which yields the capacity\nregion. Finally, it is demonstrated that how this general achievability scheme\ncan be used to derive capacity inner bounds for interference networks with\ndifferent distribution of messages; in most cases, the proposed achievability\nscheme leads to the best known capacity inner bound for the underlying channel.\nCapacity inner bounds can also be derived for new communication scenarios."}, "authors": ["Reza K. Farsani", "Farokh Marvasti"], "author_detail": {"name": "Farokh Marvasti"}, "author": "Farokh Marvasti", "arxiv_comment": "13 pages, with Appendix, Submitted for Conference Publication", "links": [{"href": "http://arxiv.org/abs/1107.1839v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1107.1839v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1107.1839v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1107.1839v1", "journal_reference": null, "doi": null, "fulltext": "Interference Networks with General Message Sets: A\nRandom Coding Scheme\nReza Khosravi-Farsani, Farokh Marvasti\nAdnaced Communications research Institue (ACRI)\nDepartment of Electrical Engineering, Sharif University of Technology, Tehran, Iran\nEmail: reza_khosravi@alum.sharif.ir, marvasti@sharif.ir\n\nAbstract-In this paper, the Interference Network with General\nMessage Sets (IN-GMS) is introduced in which several\ntransmitters send messages to several receivers: Each subset of\ntransmitters transmit an individual message to each subset of\nreceivers. For such a general scenario, an achievability scheme is\npresented using the random coding. This scheme is systematically\nbuilt based on the capacity achieving scheme for the Multiple\nAccess Channel (MAC) with common message as well as the best\nknown achievability scheme for the Broadcast Channel (BC) with\ncommon message. A graphical illustration of the random\ncodebook construction procedure is also provided, by using\nwhich the achievability scheme is easily understood. Some\nbenefits of the proposed achievability scheme are described. It is\nalso shown that the resulting rate region is optimal for a class of\northogonal INs-GMS, which yields the capacity region. Finally, it\nis demonstrated that how this general achievability scheme can\nbe used to derive capacity inner bounds for interference networks\nwith different distribution of messages; in most cases, the\nproposed achievability scheme leads to the best known capacity\ninner bound for the underlying channel. Capacity inner bounds\ncan also be derived for new communication scenarios.\nKeywords- Interference Networks; General Message Sets;\nBroadcast Channel; Mutiple Access Channel.\n\nI.\n\nINTRODUCTION\n\nThe interference networks are of the most important multiuser\nscenarios due to the wide range of practical communications\nsystems for which these models are fitted. Up to know these\nnetworks have been extensively studied, however, our knowledge\nregarding the behavior of information flow in them is still limited.\nFor instance, a computable characterization of the capacity region\nfor the two-user Classical Interference Channel (CIC) is unknown\n[1], unlike its simple configuration. The best achievability scheme\nfor this channel is due to Han-Kobayashi (HK) [2] proposed in\n1981. The multiuser interference networks recently have been\nwidely investigated in the literature. Nevertheless, they are far\nless understood [3].\nIn this paper, we introduce the Interference Networks with\nGeneral Message Sets (IN-GMS), a network scenario where\nseveral transmitters send messages to several receivers: Each\nsubset of transmitters transmit an individual message to each\nsubset of receivers. In fact, this scenario unifies all interference\nchannel models with diverse distribution of messages. For\nexample, the two-transmitter/two-receiver IN-GMS contains the\nCIC, the Multiple Access Channel (MAC) with common message\n[4], the Broadcast Channel (BC) with common message, the\ncognitive radio channel [5], the X-channel [6], the Z-channel [7],\nthe cognitive interference channel with degraded message sets [8]\nand etc, as special cases. In this paper, we present a random coding\nscheme for such a general scenario. Having at hand an achievable\nrate region for this channel in the general case sheds light on\ninformation flow, not only for the system itself but also for its subchannels. Specifically, we demonstrate that all previously derived\nachievable rate regions for different interference networks can be\ndeduced from our general scheme [9].\nTo building achievability schemes with\nperformance for such large networks, it is required:\n\nsatisfactory\n\n1.\n2.\n3.\n\nTo recognize the main building blocks involved in the\nnetwork.\nTo know the best encoding/decoding strategy for each\nbuilding block.\nTo combine systematically the best achievability\nschemes of the building blocks.\n\nIn this paper, regarding the first step, we justify that the MAC\nwith common messages and the BC with common messages are\ntwo main building blocks of the IN-GMS, which should be\nfocused on to derive a high performance achievability scheme for\nthis network. We then discuss in details the best\nencoding/decoding strategy for these two models. Precisely\nspeaking, for the MAC with common messages it was shown [4]\nthat superposition coding achieves the capacity. Regarding the BC,\nthe capacity region is still unknown; the best achievability scheme\nfor the two-user BC is due to Marton [10]. In this paper, we\nprovide a graphical illustration for the superposition structures\namong the generated codewords in a random coding scheme, by\nwhich the encoding procedure is easily understood. Based on this\ngraphical representation, we argue that the superposition structures\namong the generated codewords in the Marton's coding for the\ntwo-user BC with common message is exactly the same as that one\nin the MAC with common message. We examine some other\ncoding strategies for the two-user BC and mention that the\nresulting achievable rate region by them is equivalent to Marton's\none or include in it as its subsets. Using these general insights, we\npropose a random coding scheme for the multi-receiver BC with\ncommon messages (for each subset of the receivers there exist a\ncommon message), in which the superposition structures among\nthe generated codewords are exactly similar to the multitransmitter MAC with common messages.\nAs the last step, we combine systematically these two encoding\nstrategies, i.e., the capacity achieving scheme for the MAC with\ncommon messages and the proposed coding for the BC with\ncommon messages, to building an achievability scheme for the INGMS. As one of the useful properties our achievability scheme is\nthat the superposition structures among the RVs is such that each\nreceiver decodes only its respective messages (using a jointly\ntypical decoder) and it is not required to decode non-intended\nmessages at some receivers. We also demonstrate that our\nachievable rate region is optimal for a class of orthogonal INMAC. Then, we describe that how our general achievability\nscheme can be used to derive capacity inner bounds for\ninterference networks with diverse distribution of messages.\nIt should be mentioned that due to simplicity of exposition, in\nthis conference version of our paper, we only discuss the\nachievability scheme for the two-transmitter/two-receiver case;\nnevertheless, our systematic approach is such that all the rules in\nderivation of the coding scheme directly extend to the case with\narbitrary number of transmitters and receivers, as will be reported\nin [9]. Moreover, to analyze the error probability of the proposed\ncoding, we exploit a covering lemma proved in [3, p. 15-40].\nUsing a novel application of this lemma the necessary conditions\nfor vanishing the error probability in the encoding steps are readily\nderived, which makes the analysis significantly concise. Also, the\nanalysis of the decoding steps is performed by constructing a table\nof decoding errors, in a clear framework with a few computations.\n\n\fFigure 1. The two-transmitter/two-receiver Interference Network with General Message Sets (IN-GMS).\n\nIn the rest of the paper, we briefly state the preliminaries and\nchannel model definitions in Section II. The main results are given\nin Section III. Due to space limitations, some steps in the analysis\nof the coding scheme are omitted here, but they can be found in\n[11]. The generalization of the coding scheme for networks with\narbitrary number of transmitters and receivers is given in [9].\n\nII.\n\nPRELIMINARIES AND DEFINITIONS\n\nThroughout the paper the following notations are used:\nRandom Variables (RV) are denoted by upper case letters (e.g. )\nand lower case letters are used to show their realization (e.g. ).\nThe range set of a RV is represented by . The Probability\n, and\nDistribution Function (PDF) of a RV is denoted by\nthe conditional PDF of given is denoted by | | ; also, in\nrepresenting PDFs, the arguments are sometimes omitted for\nbrevity. The probability of the event is expressed by\n. The\nset of nonnegative real numbers and positive integers are denoted\n, and\n, respectively. The notation 1:\nwhere is a\nby\npositive integer, represents the set 1, ... , . The set of all jointly\n-letter typical -sequences\nwith respect to the PDF\n,\n, is denoted by\n, (To see the definition of such\nsequences and their properties refer to [12]). Also, given the\n, the set of all -sequences\nwhich are jointly\nsequence\ntypical with\n, , is denoted by\nwith respect to the PDF\n|\n. Finally,\ndenotes the minimum positive\nvalue of .\nInterference Networks with General Message Sets: Here,\nwe briefly discuss the communications scenario of the IN-GMS in\nthe two-transmitter/two-receiver case. The detailed definitions are\ngiven in [9] wherein the general network from the viewpoint of\nthe number of transmitters and receivers is considered.\nConsider a two-transmitter/two-receiver interference network\nwherein the transmitters intend to send nine messages over the\nchannel; there exist three sets of triple messages where one\nmessage set is transmitted over the channel by both transmitters\ncooperatively, and the two other message sets are transmitted\nseparately, one set by each transmitter. In each message set there\nexist three messages: two private messages, one for each receiver,\nand also a common message for both receivers. Therefore, each\nreceiver is required to decode six messages three of which are\ncommon between both receivers. This channel indeed includes all\npossible schemes of transmitting messages over a two-user\ninterference network. Hence, we refer to as Interference Network\nwith General Message Sets (IN-GMS). Figure 1 illustrates the\nchannel model.\nThis network is determined by the conditional PDF\nwhich describes the relation between inputs and\n, | ,\noutputs of the network. The network is assumed to be\nmemoryless. For a lengthblock code,\n, the\n\ntransmitter encodes its respective messages using the codewords\nand the\nreceiver decodes its intended messages by the\nreceived sequence , ,\n1,2. The explicit definitions of the\nencoding and decoding procedures and the capacity region for the\nIN-GMS can be found in [9]. As usual, every subset of the\ncapacity region of the network is called an achievable rate region.\nIn the next section, we present an achievable rate region for\nthis network using the random coding.\n\nIII.\n\nMAIN RESULTS\n\nIn this section, we aim at establishing an achievability scheme\nfor the IN-GMS depicted in Fig. 1. Due to presence of several\nmessages which are required to transmit over the channel, one can\nconsider numerous achievability schemes for this network. But the\nquestion is that what is the best transmission strategy?\nTo respond to this question, first, we discuss the main building\nblocks involved in the network as well as the best\nencoding/decoding strategy for each one. To recognize the main\nbuilding blocks of the IN-GMS, we look at the encoding and the\ndecoding sides of the network. Let us examine Fig. 1. From the\nviewpoint of the encoding side, we have a multiple access problem\nwith common message. On the other hand, from the viewpoint of\nthe decoding side, we have a broadcasting problem, (both common\nand private messages). Therefore, it is required to investigate the\nMAC with common message and also the BC with common\nmessage, in details. Consider the MAC with a common message,\nas shown in Fig. 2.\n\nThe capacity region of this channel was determined in [4]\nwhich is given as:\n,\n\n:\n; |\n; |\n\n|\n\n|\n\n,\n,\n,\n\n; |\n, ;\n(1)\n\nFor this channel, it was shown that the superposition coding\nachieves the capacity. As a brief discussion regarding this coding\nscheme, we mention that the common message\nis encoded by a\ncodeword constructed by the RV based on . Then, for each\nof the private messages a codeword is generated superimposing on\nis\nthe common message codeword : The private message\nbased on\nencoded using a codeword constructed by\n| ,\nover\ntransmitter,\n1,2, then sends\n,\n1,2. The\nthe channel. The decoder decodes the messages using a jointly\ntypical decoder. Figure 3 graphically illustrates the encoding\nscheme.\n\n\fFigure 4. The two-user BC with common message.\n\nFigure 2. The two-user MAC with a common message.\n\nFigure 3. The graphical illustration of the generated codewords for the\nMAC with a common message. Every two codewords connected by an arrow\nbuild a superposition structure: The codeword at the beginning of the arrow is\nthe cloud center and that one at the end of the arrow is the satellite. The ellipse\nbeside each codeword shows what contains that codeword, in addition to those\nones in its cloud centers.\n\nIn this illustration, we use a directed graph to represent the\nsuperposition structures among the generated codewords: Every\ntwo codewords connected by an arrow (directed age) build a\nsuperposition structure where the codeword at the beginning of the\narrow is the cloud center and that one at the end of the arrow is the\nsatellite. The ellipse beside each codeword shows what contains\nthat codeword, in addition to those ones in its cloud centers. This\ngraphical representation is very useful to understand an\nachievability scheme, especially for large networks.\nThen, consider the two-user BC with common information, as\nshown in Fig. 4. The capacity region of the BC is still an unsolved\nproblem in network information theory. To date, the best capacity\ninner bound for this channel is due to Marton [10], (see also [13])\nwhich is given by:\n,\n\n,\n, ;\n, ;\n, ;\n;\n\n2\n\n|\n, ;\n\n;\n\n|\n; |\n, ;\n; |\n, ;\n; |\n\n(2)\n\nHere, we briefly discuss the Marton's coding scheme. Roughly\nis encoded by a codeword\nspeaking, the common message\nconstructed of based on . For each of the private messages, a\nbin of codewords is randomly generated superimposing on the\nis\ncommon message codeword\n: The bin respective to\nis constructed\nconstructed by based on | and that one for\nby based on | . These bins are explored against each other to\nfind a jointly typical pair of codewords. Using the mutual covering\nlemma [3], the sizes of the bins are selected sufficiently large such\nthat the existence of such typical pair of codewords is guaranteed.\nSuperimposing on the designated codewords , , , the encoder\n,\nthen generates its codewords constructed by based on |\nand sends it over the channel. Each receiver decodes its respective\ncodewords (the first one decodes , and the second one decodes\n, ) using a jointly typical decoder. The resulting achievable rate\nregion is further enlarged and reaches to (2) by the fact that if the\n, ,\nis achievable for the BC, then\nrate triple\n,\n,\nis also achievable. The\ngraphical representation of the Marton's coding has been shown in\nFig. 5.\n\nFigure 5. The graphical illustration of the generated codewords for the BC\nwith a common message in the Marton's scheme. This figure depicts the\nsuperposition structures among the generated codewords. The parameters ,\nindicate the bin indices.\n\nThe superposition structures among the generated codewords\nin the Marton's coding scheme for the two-user BC with common\nmessage are exactly the same as the MAC with common message,\nas shown in Fig. 3. The only difference in the encoding scheme is\nthat, unlike the MAC, for the BC since all the messages are\navailable at one transmitter, it is possible to apply the binning\ntechnique. Using the binning scheme we can construct the\ntransmitted codewords jointly typical with the PDF\n, which\nyields a larger achievable rate region than the case where the\nmessages are encoded only using the superposition coding\naccording to the PDF\n.\n|\n|\n|\nIt should also be mentioned that one can consider some new\ncoding schemes for the two-user BC other than the Marton's one.\nFor example, it is possible to encode all the messages (both\ncommon and private messages) only using the binning technique,\ni.e., without superposition coding. In this scheme, roughly\nspeaking, respective to each message a bin of codewords is\ngenerated (the bins are generated independently) and then these\nthree bins are explored against each other to find a jointly typical\ntriple. Using the multivariate covering lemma [3] the sizes of the\nbins are selected such large to guarantee that there exists such\ntriple of codewords. The transmitter then generates its codeword\nsuperimposing on this jointly typical triple and sends it over the\nchannel. Each receiver decodes its respective messages using a\njointly typical decoder. Other coding strategies are also available.\nWe have examined these coding schemes [9] and found that all the\nresulting achievable rate regions are equivalent to the Marton's\none or include in it as its subset. Therefore, we can conclude that to\nbroadcasting both common and private messages, it is more\nbeneficial to encode the private messages superimposing on the\ncommon messages.\nUsing this general insight, in [9] we propose an achievability\nscheme for transmission of the general message sets over the\nmulti-receiver BC such that the superposition structure among the\ngenerated codeword is exactly similar to the multi-transmitter\nMAC with common messages [4]. To derive this superposition\nstructure it is sufficient to look at the receivers of the BC from the\nviewpoint of the respective messages, as the transmitters of a\nMAC. The details can be found in [9].\nThe Marton's achievable rate region (2) for the two-user BC is\noptimal in all special cases for which the capacity region is known;\nspecifically, the degraded BCs, the more-capable BCs, the semideterministic BCs [3]. It is also optimal for the Gaussian multipleinput multiple-output BCs [3].\nNow, let us turn to the IN-GMS depicted in Fig. 1. In the\nfollowing, we first derive an achievable rate region for this\nnetwork and then we show that some known results, specifically,\n\n\fthe HK rate region [2] for the two-user CIC can be derived from\nour coding scheme as special cases.\nConsider the IN-GMS as depicted in Fig. 1. In this model,\n,\n,\n,\n,\n,\n,\nthree sets of messages, i.e.,\n,\n,\n, are sent over the channel where from the view\npoint of each set we have a broadcasting scenario: One private\nmessage for each receiver and a common message for both. As\nmentioned before, the main building blocks of the network are the\ntwo-user BC with common message and also the two-user MAC\nwith common message. Therefore, to derive a satisfactory\nachievability scheme for this network, it is required to combine\nsystematically the best coding schemes for these main building\nblocks. Note that by considering transmission of only one of the\nmessage sets\n,\n,\n,\n,\n,\n,\n,\n,\n,\nthe IN-GMS reduces to the two-user BC; therefore, we build our\nachievability scheme such that when it is specialized for these\nsub-channels, the Marton's inner bound (2) for the two-user BC\nresults.\nNote that here we describe our coding scheme in details only\nfor the two-transmitter/two-receiver IN-GMS; nevertheless, due\nto our systematic approach, all the rules applied here to establish\nthe achievability scheme directly extend to the case of arbitrary\nnumber of transmitters and receivers, as will be reported in [9].\nAlso, it is worth noting that, however, our achievability scheme\nmay seem complex at the first glance, but indeed this is not the\ncase. Due to symmetry in the encoding and decoding steps, the\nanalysis of the proposed random coding is very simple. In\naddition, in the encoding steps we exploit a multivariate covering\nlemma proved in [3, p. 15-40] to obtain an admissible source\nregion for the two-user BC. Using a novel application of this\nlemma, the necessary conditions for vanishing error probability in\nencoding steps are readily derived, which makes the analysis\nsignificantly concise; see [11] for details. In the following\ntheorem we state our main result.\nTheorem 1) Define the rate region\nas given in the\nis an achievable rate region for the\nnext page. The set\nIN-GMS depicted in Fig. 1.\nRemarks:\n1. The rate region\n\nis convex.\n\ncan be further enlarged by\n2. The rate region\nconsidering\nthe\nfact\nthat\nif\n,\n,\n,\n,\n,\n,\n,\n,\nis achievable,\nthen the following 9-tuples are also achievable:\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n. Let\n:\nbe a bijection.\nDefinition: Suppose\ninduced by\n, is\n. on the set\nThe order relation\ndefined as follows. For every\nand\nin\n,...,\n,...,\nwhere\n, we have:\n,...,\n,...,\n,...,\n\n,...,\n,...,\n\n,...,\n\n, denoted by min ,\nAlso, the \"min\" operator with respect to\nis defined as follows. Let be a nonempty subset of\n. We\nhave:\nmin\nmin\n(4)\n. denotes the inverse function. The \"max\" operator\nwhere\ncould be defined, similarly.\n,\n,\n,\n,\n,\n,\n,\n,\n, and the\nLet\n, ,\n0,1,2, be a RV uniformly distributed over the\nmessage\n:\nand\n:\nbe two\n. Also, let\nset 1: 2\narbitrary bejections with the \"min\" operators min and min ,\nrespectively, as defined by (4). As a convention, denote\n1,1 and min\n1,1,1 .\nmin\nEncoding steps: The encoding is performed in three steps:\n,\n,\nStep 1: At the first step the messages\nwhich are\nsent by both transmitters cooperatively, are encoded. These\nmessages are encoded exactly similar to Marton's coding scheme:\nFix the PDFs\n,\n. Let\n,\nbe a\n| ,\n|\nnonnegative pair of real numbers. These serve as the sizes of the\nbins.\n1. Generate at random 2\n\u220f\naccording to\n, where\n1: 2\n\n.\n\nindependent codewords\n, . Label these codewords\n\n2. For each\ngenerate 2\n\u220f\n,\n,\n\n, where\n1: 2\n, randomly\nindependent codewords\naccording to\n. Label these codewords\n|\n,\n,\n, where\n1: 2\n1: 2\nand\n.\n\n3. For each\ngenerate 2\n\u220f\n,\n,\n\n, where\n1: 2\n, randomly\nindependent codewords\naccording to\n. Label these codewords\n|\n,\n,\n, where\n1: 2\n1: 2\nand\n.\n\n,\n\nGiven\n\n,\n\n,\n,\n\n,\n\n, define the pair\n,\n\nmin\n,\n,\n\nwhere\n, ,\n. This fact is adapted from the same\nobservation for the BC, as discussed before.\n3. One of the useful properties our achievability scheme is that\nthe superposition structures among the RVs is such that each\nreceiver decodes only its respective messages (using a jointly\ntypical decoder) and it is not required to decode non-intended\nmessages at some receivers. This is important, since usually\ndecoding non-intended messages at one receiver causes rate loss.\nFor the special cases of the two-user MAC with common message\nand the BC with common message our achievable rat region (after\napplying the technique mentioned in Remark 2) reduces to the (1)\nand (2), respectively.\n\n(3)\n\nas follows:\n1: 2\n,\n,\n,\n,\n\n,\n\n1,2\n\n,\n(5)\n\nIn other words,\nis the minimum pair\n,\nrespect to\n) such that the codewords\n, ,\n,\ntypical. If there is no such codewords, then\n\n,\n\n(with\nare jointly\n1,1 .\n\nIn the first step, the designated codewords for transmission are:\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n(6)\n\nProof of Theorem 1)\n\nUsing the mutual covering lemma [3], we can select the sizes\nof the bins\n,\nsufficiently large to guarantee that the\n.\ncodewords (6) are jointly typical with respect to\n\nWe derive the achievability of\ngiven by (7) using a\nrandom coding argument. To encode each of the messages\n,\n,\n,\n,\n,\n,\n, we use an\nauxiliary RV. Inspired by Marton's region characterization given\n,\n,\n,\n0,1,2 , by\nby (2), we encode the messages\n, , , respectively.\n\n,\n,\nIn the next two steps, the two message sets\nwhich are sent by transmitter 1 and 2,\nand\n,\n,\nrespectively, are encoded. The codewords generated in Step 1\nare now served as cloud centers for the new codewords (which\nare generated in Steps 2 and 3) in such a fashion as depicted in\nFig. 6.\n\n\f,\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n; |\n, ;\n, ;\n, ;\n, ;\n\n,\n\n|\n|\n|\n|\n\n,\n\n1,2\n; |\n; |\n; |\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n\n,\n,\n,\n\n1,2\n1,2\n,\n\n0,1,2 , ,\n\n; |\n\n,\n\n,\n\n,\n\n1,2\n\n0,0 ,\n\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n(7)\nwhere,\n;\n;\n\n|\n|\n\n,\n,\n\n|\n|\n\n;\n;\n\n,\n\n,\n,\n\n,\n\n;\n;\n\n,\n\n|\n|\n\n,\n\n,\n,\n\n,\n\n;\n\n,\n\n|\n\n,\n(8)\n\n; |\n; |\n,\n\n;\n\n,\n,\n|\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n;\n\n|\n\n,\n\n,\n\n,\n\n,\n\n;\n\n|\n\n,\n\n,\n\n;\n\n,\n|\n\n,\n\n,\n\n,\n\n,\n\n;\n\n|\n\n,\n\n,\n\n,\n\n,\n\n;\n\n|\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n;\n\n|\n\n;\n\n|\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n; | ,\n, ; |\n\n,\n\n,\n\n,\n\n,\n\n,\n\n;\n(9)\n\nAlso,\n,...,\nand\n,...,\nare given similar to\n0,1,2, everywhere. Moreover,\nby and by ,\n\n,...,\nand\n,...,\n, respectively, except\ndenotes the set of all joint PDFs\n|\n\nshould be replaced\nsatisfying:\n\n|\n\n(10)\nIn Fig. 6, every two codewords connected by a directed edge\narranged in a superposition manner: The codeword at\nbeginning of the edge is the cloud center and the codeword at\nend of the edge is the satellite. For example, the codeword\nthe cloud center for all other codewords. Also, in addition to\n\nare\nthe\nthe\nis\n,\n\nboth the codewords\nand\nare cloud centers for the codeword\n. In other words, the codeword\nis superimposed on three\ncodewords\n,\n, , where\nitself is also a cloud center for\nboth\n, . Other relations among generated codewords can be\nunderstood from Fig. 6, similarly.\n\n\fFigure 6. The graphical illustration of the generated codewords for the IN-GMS. This figure depicts the superposition structures among the generated codewords.\nThe ellipses beside each codeword show what contains that codeword, in addition to those ones in its cloud centers.\n\nFigure 6 clearly depicts the systematic combination of the capacity\nachieving scheme for the MAC with common message with the\nMarton's coding for the BC with common message. The\nsuperposition structures among the generated codewords is such\nthat each\n-triple (which performs a broadcasting) is\nconfigured in the Marton's scheme, while the triplets\n,\n,\nare configured in the capacity achieving\nscheme for the MAC with common message. This representation\nis also useful to clarify the factorization of the joint PDFs in\nconsideration of which the resulting rate region is evaluated (10).\nThis factorization is derived as follows:\nEach RV in the capacity achieving scheme for the MAC with\ncommon messages is replaced by the situated broadcasts RVs.\nUsing this general direction, the factorization (10) can be\nperceived by the joint PDFs respective to the regions (1) and (2).\n\n1: 2\n, and\n, randomly generate 2\n1: 2\naccording to:\nindependent codewords\n|\n\n,\n\n,\n\n,\n\n, define\n\n,\n\nwhich are sent by\nFix\nthe\nPDFs\n,\n,\nbe a\n\n, where\n1: 2\n, generate at\nindependent codewords\naccording to\n. Label these codewords\n|\n,\n,\n, where\n1: 2\n1: 2\nand\n.\n\n1. For each\nrandom 2\n\u220f\n,\n,\n2.\n\nFor\neach\ntriple\ncodewords\n,\n,\n,\nwhere\n,\n,\n,\n,\n1: 2\n1: 2\n1: 2\n,\n,\n,\n1: 2\n, and\n, randomly generate 2\n1: 2\nindependent codewords\naccording to:\n\n.\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\nthe triple\n\n,\n,\n\n,\nas\n\n,\n,\n\n,\n\n,\n\n,\n\n1: 2\n\n,\n\n0,1,2\n\n,\nmin\n\n,\n\nIn the following, we describe the random codebook generation in\nSteps 2 and 3, in details.\nStep 2: In this step the messages\n,\ntransmitter\n1,\nare\nencoded.\n, and\n. Let\n| ,\n|\n|\nnonnegative triple of real numbers.\n\n,\n,\n1: 2\n\nLabel these codewords\nwhere\n1: 2\nand\nGiven\nfollows:\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n,\n,\n,\n\n,\n,\n\n,\n,\n,\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n,\n,\n\n(11)\nIn other words,\nis the minimum triple\n, ,\n, ,\n(with respect to\n) such that the codewords\n, ,\n,\n, ,\nare jointly typical with respect to the PDF\n. If there is no such triple codewords, then\n1,1,1 . Note that, in the definition (11), the pair\n, ,\nhave been defined in Step 1 by (5).\n,\nIn this step, the designated codewords are as:\n,\n,\n\n,\n,\n\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n\n,\n(12)\n\n|\n\nLabel these codewords\n1: 2\nand\nwhere\n3.\n\nFor\n,\n1: 2\n\n,\n,\n\neach\n,\n,\n1: 2\n\n,\n\n,\n,\n1: 2\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n\n,\n\n.\n\ntriple\n,\n,\n1: 2\n\ncodewords\n,\nwhere\n,\n\nUsing the lemma proved in [3, p 15-40], we can select the sizes of\n,\n,\nsufficiently large to guarantee that the\nthe bins\ncodeowrds (12) are jointly typical with those in (6), with respect to\nthe PDF\n.\nGiven the messages\n,\n,\n,\ntransmitter generates a codewords\ncodewords (6) and (12), according to:\n\n, the first\n,\n,\nsuperimposing on the\n\n\f|\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\nDefinition: The IN-GMS is said to be orthogonal if the alphabets\ntransmitters are of the form\n,\n1,2 , and the\nchannel transition probability function satisfies:\n\n,\n\n| ,\n\n,\n\nand sends it over the channel.\n\n,\n\n,\n(16)\n\n,\n,\nwhich are sent by\nStep 3: In this step the messages\ntransmitter 2, are encoded. The encoding scheme is exactly similar\nto Step 2. Here, the random codewords are generated based on the\nPDFs\n, |\n, and by following the same\n| ,\n|\nlines as in Step 2 where the messages\n,\n,\nare replaced\nby\n,\n,\n, the RVs\n, , ,\nby\n, , , , the\n,\n,\nby\n,\n,\n, and the\ntriple\nindices\n, ,\nby\n,\n,\n, respectively. We omit the\ndetails to avoid repetition.\n\nIn the following theorem, we provide a full characterization of the\ncapacity region of the orthogonal IN-GMS.\nTheorem 2) The capacity region of the orthogonal IN-GMS (16)\ndenoted by\n, is given as follows:\n\n,\n\n,\n\n,\n\n,\n;\n\nDecoding steps: Each decoder uses a jointly typical decoder to\ndecode its respective codewords. The encoding procedure at each\nreceiver is as follows:\n1. At receiver 1, assume that the sequence\nThe\ndecoder\ntries\nto\nfind\na\n,\n,\n,\n, ,\n, ,\n,\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n;\n\n,\n\n;\n\nhas been received.\nunique\n11-tuple\n,\nsuch that:\n\n,\n\n,\n,\n\n;\n\n,\n\n;\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n;\n\n,\n\n;\n\n;\n(17)\n\ndenotes the set of all joint PDFs as:\n\nwhere\n\n|\n\n|\n\n|\n\n|\n\n(18)\n\n(13)\nIf there exists such 11-tuple, then the decoder estimates its\nrespective transmitted messages by the corresponding\n. If there is no such 11-tuple or\n,\n,\n,\n,\n,\nthere is more than one, then the decoder produces an arbitrary\noutput and declares an error.\n2. Similarly, at receiver 2 assume that the sequence\nhas been\nreceived. The decoder tries to find a unique 11-tuple\n,\n,\n,\n, ,\n, ,\n,\n,\n,\nsuch that:\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\nRemarks:\n1. The rate region\n\ngiven by (17), is convex.\n\n2. Theorem 2 shows that the essential foundation of the\northogonal IN-GMS is combined of two MACs with common\nmessage, and the capacity achieving scheme for this channel is\nbased on a twin treatment of the superposition coding applied in\n[4] for the MAC with common information. This also evidences\nthat the MAC with common message is one of the main building\nblocks of IN-GMS.\nProof of Theorem 2) To prove the direct part, we make use of the\nachievable rate region for the IN-GMS given in (7). By setting:\n,\n,\n\n(14)\nIf there exists such 11-tuple, then the decoder estimates its\nrespective transmitted messages by the corresponding\n,\n,\n,\n,\n,\n. If there is no such 11-tuple or\nthere is more than one, then the decoder produces an arbitrary\noutput and declares an error.\nAnalysis\nof\nerror\nprobability:\nLet\n0\nas the\n. Denote\naverage error probability of decoding at the\nreceiver,\n1,2.\nAlso, denote\nas the total average probability of the code.\nTherefore, we have:\n\nin (7) and restricting the joint PDF (10) as follows:\n|\n\nNext, we present a class of INs-GMS for which the achievable rate\nregion derived in Theorem 1 is optimal which yields the capacity.\n\n|\n\n|\n\n|\n\n(19)\nwe derive the following achievable rate region for the channel:\n,\n,\n,\n,\n,\n,\n,\n,\n;\n,\n;\n\n,\n,\n\n(15)\nDue to symmetry of the problem it is only required to analyze the\nerror probability at the first receiver. The necessary conditions for\nvanishing the average probability of error at the first receiver can\nbe readily extended to the second receiver by exchanging some of\nthe parameters, as stated in the characterization of the rate region\ngiven by (7). The details of the analysis of error\nprobability in decoding at the first receiver can be found in [11]. \u25a0\n\n,\n,\n\n;\n\n,\n\n;\n\n,\n,\n\n;\n,\n\n,\n\n;\n\n,\n\n,\n\n;\n\n;\n(20)\n\nwhere\n\ndenotes the set of all joint PDFs as in (19).\n\nNow, consider the rate region (17). Given the PDFs\n,\n, with\n, define two\n| ,\n| ,\n| ,\n|\nand with the range of\nas follows:\nindependent RVs\n\n\f,\n\n1,2\n.|\n.|\n\n|\n|\n\n|\n|\n\n.|\n.|\n\n(21)\n, ,\nas\nThen, by substituting\n| ,\n| ,\n| ,\n|\ndefined by (21) in (20), the resulting rate region is equivalent to\n(17). The converse part will be given in [9]. \u25a0\nNow, by an example we show that how one can establish\ncapacity inner bounds for different sub-channels of IN-GMS\nusing the general achievability scheme presented in Theorem 1\nfor this network, as well as the rate splitting technique.\nConsider the two-user CIC in Fig. 7 as one of the sub-channels of\nthe IN-GMS. We aim at extracting the HK achievable rate region\n[2] for this channel from the coding scheme presented for the INGMS. To this end, as depicted in Fig. 7, each of the messages\nand\nand thereby their respective communication rates\nand\nare split in two parts:\n,\n\n,\n\n,\n\n1,2\n\n(22)\n\nNow, consider the achievability scheme presented in Theorem 1\nfor the IN-GMS. In this coding scheme, let us restrict our\nattention to the case of communicating only the messages\n,\nat transmitter 1 and the messages\n,\nat transmitter\n2. Therefore, in the rate region (7) the communication rates\n,\n,\n,\n,\n, as\nrespective to the other messages, i.e.,\nwell as the auxiliary RVs used to encode them (except\n) are\nnullified. The RV\nis used to serve as the time-sharing\nparameter. Accordingly, in the rate region (7) we set:\n0\n\nFigure 7. The two-user Classical Interference Channel (CIC).\n\nand\nin the resulting rate region\nThen, by setting\nand applying Fourier-Motzkin elimination to remove\n,\n,\n,\n, the HK achievable rate region for the two-user\nCIC is derived, (see also [14]).\nNote that the procedure described above to derive the HK rate\nregion for the two-user CIC can also be followed for other subchannels of IN-GMS. We follow this approach for other channel\nmodels in [9] and derive capacity inner bounds for new\ncommunication scenarios.\n\nCONCLUSION\nIn this paper, we introduced the IN-GMS and proposed an\nachievability scheme for it using the random coding. This scheme\nis systematically built based on the capacity achieving scheme for\nthe MAC with common message as well as the best known\nachievability scheme for the BC with common message. We also\nprovided a graphical illustration of the random codebook\nconstruction procedure, by using which the achievability scheme is\neasily understood. Moreover, we proved that the resulting rate\nregion is optimal for a class of orthogonal INs-GMS, which yields\nthe capacity region. Finally, we demonstrated that how this general\nachievability scheme can be used to derive capacity inner bounds\nfor interference networks with different distribution of messages.\nIn ongoing work [9], we investigate our achievable rate region for\ninterference networks with different distribution of messages.\n\nREFERENCES\n(23)\n[1]\n\nThereby, the distribution of the remaining RVs is given by:\n|\n\n|\n\n(24)\n\nOn the one hand, by this assumptions we can set all the binning\n,\n,\n,\n,\n,\n,\n,\n, equal to zero. One\nrates, i.e.,\ncan easily verify that the resulting rate region by these conditions\nis described by the following constraints:\n\n; | ,\n, ; |\n; | ,\n, ; |\n, , ;\n\n,\n,\n,\n,\n|\n\n|\n, ;\n; |\n, ;\n, ,\n\n,\n,\n,\n,\n|\n\n;\n\n,\n|\n,\n|\n;\n\n[2]\n\n[3]\n[4]\n\n[5]\n\n[6]\n\n[7]\n\n[8]\n\n(25)\n,\n,\n,\nsatisfying (25),\nThe union of all rates\ntaken over the set of joint PDFs as (24), is achievable for the twois correctly decoded at the\nuser interference channel in which\nreceiver and\nat both receivers,\n1,2. Then, note that for\nis a part of the first\nthe two-user CIC, according to (22),\ntransmitter message and\na part of the second transmitter\nmessage, and hence it is required to decode only at their\nrespective receiver, correctly. On the one hand, the constraints\n; | , ,\nand\n; | , ,\ngiven in\nat\n(25) are the cost we have to paid to correctly decode\nreceiver 1 and\nat receiver 2, respectively. Hence, one can\nremove these constraints from (25) and take the others with\ndefinitions (22) as an achievable rate region for the two-user CIC.\n\n[9]\n[10]\n[11]\n[12]\n\n[13]\n[14]\n\nA. S. Motahari and A. K. Khandani. Capacity bounds for the Gaussian\ninterference channel. IEEE Transactions on Information Theory, vol.55,\nno.2:620\u2013643, February 2009.\nT. Han and K. Kobayashi, \"A New Achievable Rate Region for the\nInterference Channel,\" IEEE Trans. Inf. Theory, vol. 27, no. 1, pp. 49\u2013\n60, Jan 1981.\nA. El Gamal and Y.-H. Kim, \"Lecture notes on network information\ntheory,\" preprint at arXiv:1001.3404, 2010.\nD. Slepian and J. K. Wolf, \"A coding theorem for multiple access\nchannels with correlated sources,\" Bell Syst. Tech. J., vol. 52, pp 1037\u2013\n1076, 1973.\nN. Devroye, P. Mitran, and V. Tarokh, \"Achievable rates in cognitive\nradio channels,\" IEEE Trans. Inf. Theory, vol. 52, pp. 1813\u20131827, May\n2006.\nM. Maddah-Ali, A. Motahari, and A. Khandani, \"Communication Over\nX Channel: Signalling and Multiplexing Gain,\" Univ. Waterloo,\nWaterloo, ON, Canada, 2006, Tech. Rep. UW-ECE-2006-12.\nS. Vishwanath, N. Jindal, and A. Goldsmith, \"The \"Z\" channel,\" in\nProc. IEEE Global Telecommunications Conf., San Francisco, CA, Dec.\n2003, vol. 3, pp. 1726\u20131730.\nY. Liang, A. Somekh-Baruch, V. Poor, S. Shamai, and S. Verd\u00fa,\n\"Cognitive interference channels with confidential messages,\" in Proc.\n45th Annual Allerton Conf., 2007.\nR. Khosravi-Farsani and F. Marvasti, \"Interference networks with\ngeneral message sets\" preprint.\nK. Marton, \"A coding theorem for the discrete memoryless broadcast\nchannel,\" IEEE Trans. on Inf. Theory, vol. 25, pp. 60-64, no. 3, 1979.\nR. Khosravi-Farsani and F. Marvasti, \"Interference networks with\ngeneral message sets: a random coding scheme\" available at: Arxiv.\nG. Kramer, \"Topics in multi-user information theory,\" Foundations and\nTrends in Communications and Information Theory, vol. 4, no. 4/5, pp.\n265\u2013444, 2007.\nY. Liang and G. Kramer, \"Rate region for relay broadcast channels,\"\nIEEE Trans. Info. Theory, vol. 53, no. 10, pp. 3517\u20133535, Oct. 2007.\nH. F. Chong, M. Motani, H. K. Garg, and H. E. Gamal, \"On the Han\u2013\nKobayashi region for the interference channel,\" IEEE Trans. Inf. Theory,\nvol. 54, no. 7, pp. 3188\u20133195, Jul. 2008.\n\n\fAPPENDIX\n3\u20444\n\nAnalysis of error probability for the proposed coding scheme in Theorem I\n\nwhere\n,\n,\n,\n,\n,\n,\n,\n,\nGiven the 9-tuple\n, , , , and also the decoding error events at the first receiver ,\n\n1: 2\n, ,\n0,1,2, the encoding error events\n,...,\n, are defined as follows:\n\nEncoding errors:\n1: 2\n\n,\n\n1: 2\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n(26)\n\n,\n\n1: 2\n\n,\n\n1: 2\n\n1: 2\n\n,\n,\n\n,\n,\n,\n,\n\n,\n\n,\n,\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n\n,\n,\n,\n\n,\n,\n\n(27)\n,\n\n1: 2\n\n,\n\n1: 2\n\n1: 2\n\n,\n,\n\n,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n,\n\n,\n\n,\n,\n,\n\n,\n,\n\n(28)\n,\n,\n\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n,\n,\n,\n,\n,\n,\n\n,\n\n,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n,\n\n,\n,\n\n,\n,\n,\n,\n,\n,\n,\n,\n,\n\n,\n,\n,\n,\n,\n,\n,\n,\n\n,\n\n,\n,\n\n(29)\nDecoding errors at receiver 1:\nTwo types of decoding error may be occurred at the receiver: The first one is the error event where the transmitted codewords do\nnot satisfy the decoding condition (13). This error event, denoted by , is given as follows:\n,\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n\n,\n\n,\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\n(30)\nThe second type is that there exist some codewords other than the transmitted ones, which satisfy the decoding error condition\nsuch that:\n,\n,\n,\n, ,\n,\n,\n,\n,\n,\n(13). In other words, there exist some 11-tuple\n\nwith\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n\f,\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n\n,\n,\n\n,\n\n,\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\n,\n,\n\nIt should be noted that when two codewords construct a superposition structure, incorrect decoding of the cloud center codeword\nleads to incorrect decoding of the satellite one. Consequently, using the graphical illustration in Fig. 6, one can consider 13\ndifferent decoding error events of the second type at the receiver, as described in Table 1.\n-\n\n,\n9\n9\n9\n9\n9\n9\n9\n*\n9\n*\n*\n*\n*\n\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n*\n\n,\n9\n9\n9\n*\n9\n*\n9\n9\n*\n*\n9\n*\n*\n\n,\n*\n9\n*\n*\n9\n*\n*\n*\n*\n*\n*\n*\n*\n\n,\n9\n9\n9\n9\n*\n9\n*\n9\n*\n9\n*\n*\n*\n\n,\n9\n*\n*\n9\n*\n*\n*\n*\n*\n*\n*\n*\n*\n\nTable 1. The decoding errors at receiver 1.\n\nIn this table, the sign \"*\" indicates incorrect decoding of the respective codeword.\nEvaluation of\n\n:\n, we can write:\n\nNow, for the error probability of decoding at the first receiver, i.e.,\n1\n\u2211\n\n2\n\n...\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n\n|\n\n1\n\u2211\n\n2\n\nwhere\n\n.\n\n.\n\nthe following analysis,\ndefine:\n\n|\n\n,\n\n|\n\n,\n\n(31)\n,\n,\n,\n,\n,\n, , and\ndenotes the complement of the set . Next, we bound the summands in (31). In\n,\n,\ndenotes a deterministic function of , with\n0 as\n0. Also, for notational convenience, we\n,\n\n,\n\n0,1,2 ,\n\n,\n\n0,0\n(32)\n\nFirst we analysis the encoding errors. For the error event\n0 provided that:\n\n, using the mutual covering lemma [3] it is readily derived\n;\n\n|\n(33)\n\nand . To derive the conditions under which the probability of these error events vanishes, we\nThen, consider the events\nfinely exploit a multivariate covering lemma proved in [3, 15-40]. First, we restate this lemma in the following.\nLemma 1) [3, p. 15-40] Consider a joint PDF\n, , , ,\n| ,\n| ,\n, and\n. Let 0\n|\n|\nnon-negative real numbers. Given a pair of deterministic -sequences\n,\nfollows:\n1.\n\nRandomly generate 2\nindependent codewords\n, where\n.\n1: 2\n\naccording to\n\nand its marginal PDFs\n,\n,\n,\n. Also, let\n, ,\nbe a triple of\n, a random codebook is generated as\n\u220f\n\n,\n\n. Label these codewords as\n\n\f2.\n\n3.\n\n0 as\n\nThen, there exists\n\n, randomly generate 2\n1: 2\n.\nLabel\nthese codewords as\n,\n\nwhere\n\nFor the given deterministic -sequences\nand for each\n\u220f\nindependent codewords\naccording to\nwhere\n.\n, ,\n1: 2\nFor the given deterministic -sequences\nand for each\n\u220f\nindependent codewords\naccording to\nwhere\n.\n, ,\n1: 2\n\n|\n\n,\n\n,\n\n,\n\n, randomly generate 2\n1: 2\n.\nLabel\nthese codewords as\n,\n\nwhere\n|\n\n,\n\n,\n\n,\n\n0, where if:\n, ;\n, ;\n, ;\n, ;\n\n; | ,\n; | ,\n; | ,\n\n,\n\n;\n\n| ,\n(34)\n\nwe have:\n\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n0\n\n, ,\n:\n\n(35)\nNote that, as a simple variation of Lemma 1, one can consider the case in which all codewords are generated superimposing on\nanother one, e.g.,\n). In this case, for vanishing the probability (35)\n, (for a given joint PDF\n, , , , ,\nwherein conditioning on\nis now replaced by\n, the mutual information functions in (34) should be reformed to\n,\n, ,\n. In fact, we use this variation of the lemma in proving our achievability scheme for the general INcontain conditioning on\nGMS. Considering this variation of the lemma, we have depicted the superposition structures among the generated codwords in\nFig. 8.\n\nFigure 8. The graphical illustration of the generated codewords in Lemma 1. This figure depicts the superposition structures among the generated codewrods. The\ndashed arrows indicate the variation of the lemma where all codewords are generated superimposing on\n.\n\nInterestingly, the superposition structures among the codewords in Lemma 1 are exactly the same as the respective codewords of\n|\nand also\nthe achievability scheme in Theorem 1, as shown in Fig. 6. Therefore, we can directly apply it to evaluate\n|\n. We have:\n|\n\n,\n,\n\n,\n\n|\n\n,\n\n,\n\n,\n\n(34)\nwhere\n\n,\n\nis given as follows:\n\n,\n\n,\n\n,\n:\n, ,\n\n,\n,\n\n,\n,\n\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n,\n\n,\n,\n\n,\n\n,\n\n,\n(35)\n\n\fUsing Lemma 1, one can deduce that\n\n,\n\n|\n\n0 (and hence,\n\n,\n\n,\n,\n,\n,\n\n|\n|\n|\n|\n\n;\n;\n;\n;\n\n|\n|\n|\n\n;\n;\n;\n\n,\n,\n,\n\n0) provided that:\n\n,\n,\n,\n\n,\n\n|\n\n;\n\n,\n\n,\n(36)\n\n|\n\nSymmetrically,\n\n0 provided that:\n,\n,\n,\n,\n\n|\n|\n|\n|\n\n;\n;\n;\n;\n\n|\n|\n|\n\n;\n;\n;\n\n,\n,\n,\n\n,\n,\n,\n\n,\n\n|\n\n;\n\n,\n\n,\n(37)\n\nFor the event\n|\n,\n\n, because\n,\n\nforms a Markov chain by the Markov lemma [3] we have\n0.\n\nforms a Markov chain we\nThen, consider the decoding errors. For the event , because\n0, (note that conditioning on\nthere is no encoding error). To analyze the decoding errors indicated\nhave\nin Table 1, let us first evaluate the probability of the error event . We have:\n,\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n(38)\nwhere\n,\n\n,\n,\n\n,\n\n,\n,\n\n,\n\n,\n\nis given as follows:\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n,\n\n|\n,\n\n2\n\n2\n\n|\n\n,\n\n|\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n|\n\n|\n\n,\n\n,\n\n,\n\n2\n\n,\n\n,\n\n,\n\n,\n\n,\n\n(39)\nwhere (a) is due to [12, Th. 1.2 ]. Therefore,\n|\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n\n|\n\n0) provided that:\n\n0, (and thereby\n\n,\n\n,\n\n,\n\n,\n\n,\n\n,\n(40)\n\nThe probability of other decoding errors can be evaluated, similarly. In fact, the following general direction can be easily deduced:\n0, provided that:\nRates respective to incorrect decoded\nmessages and bin indices\n\n,\n\n1, ... ,13\n(41)\n\nwhere,\n\nis a cloud center for\n\nis incorrectly decoded\n\nis correctly decoded\n\n,\n(42)\n\nNow, using the error decoding table and also the graphical illustration in Fig. 6 which depicts the superposition structures among\n,...,\nare given by (9). This completes the proof. \u25a0\nthe generated codewords, one can easily check that\n\n\fIt should be noted that Lemma 1 used here to analyze the encoding errors can be naturally extended to the case where the\ngenerated codewords are such that the superposition structures among them configure an arbitrary directed graph without directed\ncycles. This extension will be used to analyze the proposed achievability scheme for the IN-GMS with arbitrary number of\ntransmitters and receivers [9]. Also, the general direction given by (41) and (42) to analyze the decoding errors are valid for other\nnetworks with arbitrarily large size. Using these general treatments, the derivation of the resulting achievable rate region is\nconsiderably simple [9].\n\n\f"}