{"id": "http://arxiv.org/abs/cond-mat/0506652v2", "guidislink": true, "updated": "2005-09-14T16:51:10Z", "updated_parsed": [2005, 9, 14, 16, 51, 10, 2, 257, 0], "published": "2005-06-24T14:17:37Z", "published_parsed": [2005, 6, 24, 14, 17, 37, 4, 175, 0], "title": "The theoretical capacity of the Parity Source Coder", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0506456%2Ccond-mat%2F0506735%2Ccond-mat%2F0506809%2Ccond-mat%2F0506426%2Ccond-mat%2F0506044%2Ccond-mat%2F0506066%2Ccond-mat%2F0506659%2Ccond-mat%2F0506434%2Ccond-mat%2F0506665%2Ccond-mat%2F0506269%2Ccond-mat%2F0506088%2Ccond-mat%2F0506026%2Ccond-mat%2F0506784%2Ccond-mat%2F0506782%2Ccond-mat%2F0506382%2Ccond-mat%2F0506578%2Ccond-mat%2F0506758%2Ccond-mat%2F0506649%2Ccond-mat%2F0506211%2Ccond-mat%2F0506807%2Ccond-mat%2F0506052%2Ccond-mat%2F0506398%2Ccond-mat%2F0506497%2Ccond-mat%2F0506138%2Ccond-mat%2F0506332%2Ccond-mat%2F0506600%2Ccond-mat%2F0506186%2Ccond-mat%2F0506448%2Ccond-mat%2F0506072%2Ccond-mat%2F0506071%2Ccond-mat%2F0506338%2Ccond-mat%2F0506021%2Ccond-mat%2F0506748%2Ccond-mat%2F0506196%2Ccond-mat%2F0506786%2Ccond-mat%2F0506383%2Ccond-mat%2F0506232%2Ccond-mat%2F0506420%2Ccond-mat%2F0506247%2Ccond-mat%2F0506486%2Ccond-mat%2F0506101%2Ccond-mat%2F0506047%2Ccond-mat%2F0506744%2Ccond-mat%2F0506290%2Ccond-mat%2F0506686%2Ccond-mat%2F0506655%2Ccond-mat%2F0506149%2Ccond-mat%2F0506407%2Ccond-mat%2F0506514%2Ccond-mat%2F0506077%2Ccond-mat%2F0506176%2Ccond-mat%2F0506574%2Ccond-mat%2F0506565%2Ccond-mat%2F0506580%2Ccond-mat%2F0506069%2Ccond-mat%2F0506652%2Ccond-mat%2F0506110%2Ccond-mat%2F0506717%2Ccond-mat%2F0506438%2Ccond-mat%2F0506100%2Ccond-mat%2F0506725%2Ccond-mat%2F0506140%2Ccond-mat%2F0506700%2Ccond-mat%2F0506161%2Ccond-mat%2F0506377%2Ccond-mat%2F0506692%2Ccond-mat%2F0506011%2Ccond-mat%2F0506199%2Ccond-mat%2F0506322%2Ccond-mat%2F0506259%2Ccond-mat%2F0506796%2Ccond-mat%2F0506783%2Ccond-mat%2F0506287%2Ccond-mat%2F0506079%2Ccond-mat%2F0506227%2Ccond-mat%2F0506203%2Ccond-mat%2F0506414%2Ccond-mat%2F0506494%2Ccond-mat%2F0506454%2Ccond-mat%2F0506583%2Ccond-mat%2F0506262%2Ccond-mat%2F0506043%2Ccond-mat%2F0506424%2Ccond-mat%2F0506526%2Ccond-mat%2F0506522%2Ccond-mat%2F0506689%2Ccond-mat%2F0506544%2Ccond-mat%2F0506284%2Ccond-mat%2F0506642%2Ccond-mat%2F0506541%2Ccond-mat%2F0506033%2Ccond-mat%2F0506651%2Ccond-mat%2F0506705%2Ccond-mat%2F0506470%2Ccond-mat%2F0506621%2Ccond-mat%2F0506569%2Ccond-mat%2F0506406%2Ccond-mat%2F0506251%2Ccond-mat%2F0506388%2Ccond-mat%2F0506039%2Ccond-mat%2F0506393&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The theoretical capacity of the Parity Source Coder"}, "summary": "The Parity Source Coder is a protocol for data compression which is based on\na set of parity checks organized in a sparse random network. We consider here\nthe case of memoryless unbiased binary sources. We show that the theoretical\ncapacity saturate the Shannon limit at large K. We also find that the first\ncorrections to the leading behavior are exponentially small, so that the\nbehavior at finite K is very close to the optimal one.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0506456%2Ccond-mat%2F0506735%2Ccond-mat%2F0506809%2Ccond-mat%2F0506426%2Ccond-mat%2F0506044%2Ccond-mat%2F0506066%2Ccond-mat%2F0506659%2Ccond-mat%2F0506434%2Ccond-mat%2F0506665%2Ccond-mat%2F0506269%2Ccond-mat%2F0506088%2Ccond-mat%2F0506026%2Ccond-mat%2F0506784%2Ccond-mat%2F0506782%2Ccond-mat%2F0506382%2Ccond-mat%2F0506578%2Ccond-mat%2F0506758%2Ccond-mat%2F0506649%2Ccond-mat%2F0506211%2Ccond-mat%2F0506807%2Ccond-mat%2F0506052%2Ccond-mat%2F0506398%2Ccond-mat%2F0506497%2Ccond-mat%2F0506138%2Ccond-mat%2F0506332%2Ccond-mat%2F0506600%2Ccond-mat%2F0506186%2Ccond-mat%2F0506448%2Ccond-mat%2F0506072%2Ccond-mat%2F0506071%2Ccond-mat%2F0506338%2Ccond-mat%2F0506021%2Ccond-mat%2F0506748%2Ccond-mat%2F0506196%2Ccond-mat%2F0506786%2Ccond-mat%2F0506383%2Ccond-mat%2F0506232%2Ccond-mat%2F0506420%2Ccond-mat%2F0506247%2Ccond-mat%2F0506486%2Ccond-mat%2F0506101%2Ccond-mat%2F0506047%2Ccond-mat%2F0506744%2Ccond-mat%2F0506290%2Ccond-mat%2F0506686%2Ccond-mat%2F0506655%2Ccond-mat%2F0506149%2Ccond-mat%2F0506407%2Ccond-mat%2F0506514%2Ccond-mat%2F0506077%2Ccond-mat%2F0506176%2Ccond-mat%2F0506574%2Ccond-mat%2F0506565%2Ccond-mat%2F0506580%2Ccond-mat%2F0506069%2Ccond-mat%2F0506652%2Ccond-mat%2F0506110%2Ccond-mat%2F0506717%2Ccond-mat%2F0506438%2Ccond-mat%2F0506100%2Ccond-mat%2F0506725%2Ccond-mat%2F0506140%2Ccond-mat%2F0506700%2Ccond-mat%2F0506161%2Ccond-mat%2F0506377%2Ccond-mat%2F0506692%2Ccond-mat%2F0506011%2Ccond-mat%2F0506199%2Ccond-mat%2F0506322%2Ccond-mat%2F0506259%2Ccond-mat%2F0506796%2Ccond-mat%2F0506783%2Ccond-mat%2F0506287%2Ccond-mat%2F0506079%2Ccond-mat%2F0506227%2Ccond-mat%2F0506203%2Ccond-mat%2F0506414%2Ccond-mat%2F0506494%2Ccond-mat%2F0506454%2Ccond-mat%2F0506583%2Ccond-mat%2F0506262%2Ccond-mat%2F0506043%2Ccond-mat%2F0506424%2Ccond-mat%2F0506526%2Ccond-mat%2F0506522%2Ccond-mat%2F0506689%2Ccond-mat%2F0506544%2Ccond-mat%2F0506284%2Ccond-mat%2F0506642%2Ccond-mat%2F0506541%2Ccond-mat%2F0506033%2Ccond-mat%2F0506651%2Ccond-mat%2F0506705%2Ccond-mat%2F0506470%2Ccond-mat%2F0506621%2Ccond-mat%2F0506569%2Ccond-mat%2F0506406%2Ccond-mat%2F0506251%2Ccond-mat%2F0506388%2Ccond-mat%2F0506039%2Ccond-mat%2F0506393&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The Parity Source Coder is a protocol for data compression which is based on\na set of parity checks organized in a sparse random network. We consider here\nthe case of memoryless unbiased binary sources. We show that the theoretical\ncapacity saturate the Shannon limit at large K. We also find that the first\ncorrections to the leading behavior are exponentially small, so that the\nbehavior at finite K is very close to the optimal one."}, "authors": ["Stefano Ciliberti", "Marc Mezard"], "author_detail": {"name": "Marc Mezard"}, "author": "Marc Mezard", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/1742-5468/2005/10/P10003", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0506652v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0506652v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Added references, minor changes", "arxiv_primary_category": {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0506652v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0506652v2", "journal_reference": "J. Stat Mech P10003 (2005)", "doi": "10.1088/1742-5468/2005/10/P10003", "fulltext": "The theoretical capacity of the Parity Source Coder\nStefano Ciliberti1 and Marc M\u00e9zard1\n\narXiv:cond-mat/0506652v2 [cond-mat.dis-nn] 14 Sep 2005\n\n1\nLaboratoire de Physique Th\u00e9orique et Mod\u00e8les Statistiques,\nUniversit\u00e9 de Paris-Sud, b\u00e2timent 100, 91405, Orsay Cedex, France\n\nThe Parity Source Coder is a protocol for data compression which is based on a set of parity checks\norganized in a sparse random network. We consider here the case of memoryless unbiased binary\nsources. We show that the theoretical capacity saturate the Shannon limit at large K. We also find\nthat the first corrections to the leading behavior are exponentially small, so that the behavior at\nfinite K is very close to the optimal one.\n\nI.\n\nINTRODUCTION\n\nThe Parity Source Coder (PSC) is a new scheme for lossy data compression, which uses a kind of dual approach [1]\nto the LDPC codes used in channel coding [2]. It has been introduced in [3], and discussed recently in [4] and [5]. We\ndiscuss here its theoretical performances.\nThe idea of the PSC is to use the M bits xM \u2261 {x1 , . . . xM } that we want to compress to build M parity-checks\non a low-density graph involving N (< M ) boolean variables yN \u2261 {y1 , . . . yN }. From the theoretical point of view\nwe will be interested in the 'thermodynamic' limit where N and M go to infinity while the rate R \u2261 N/M is kept\nfixed. The topology is defined as follows: Each constraint is connected to exactly K variables chosen at random. This\nimplies that the probability distribution of the variable connectivity is Poissonian (as in Erd\u00f6s-Renyi random graphs)\nwith mean K\u03b1. This is the general setting for a number of constraint satisfaction problems [6]. In our case such a\ngraph (cfr. Fig. 1) defines a set of M linear equations for the N variables:\nyia1 + yia2 + . . . + yiaK = xa mod 2 ,\n\na = 1, . . . M,\n\n(1)\n\nwhere xi , yi \u2208 {0, 1}, and the indices ia1 , ia2 , . . . , iaK are chosen in {1, . . . , N } with uniform distribution (the repetition\nof two indices in the same constraint can be forbidden, but this is irrelevant in the large N limit which interests us\nhere). This problem is called K-XORSAT [7] and it has been recently studied in [8] and [9]. It is also a diluted\nversion of the p-spin model used in spin glass theory [10]. Here we use it to set up a data compressor, following [4].\nThe encoded word corresponds to the solution of the linear system (1) which minimizes the number of errors. In the\nthermodynamic limit, it has been shown that the critical value \u03b1c that signals the K-XORSAT problem has a phase\ntransition at a critical value \u03b1c of the ratio \u03b1 = M/N . For \u03b1 < \u03b1c a random instance is satisfiable (in the sense that\nthere exists an assignment of the N variables satisfying all M equations) with probability one. This is the SAT phase.\nFor \u03b1 > \u03b1c a random instance is unsatisfiable with probability one: there is no assignment satisfying all constraints.\nThe critical density of constraints \u03b1c increases with K and goes exponentially fast to 1 as K increases (Fig. 2), as\ncan be computed using the formalism introduced in [8, 9]. The K-XORSAT can be used for data compression by\nworking in the UNSAT phase with \u03b1 > 1. As the encoding step xM \u2192 yN consists in finding the string yN which\nviolates the smallest number of constraints in (1), the compression rate is R = 1/\u03b1. Once we have the encoded word,\nthe decompression step yN \u2192 x\u2217M is done by setting x\u2217a = 0 or 1 according to eq. (1). The distortion is defined as the\nnumber of bits which are not properly recovered, divided by the total number of bits M . We can look at the problem\nin terms of a \"cost\" function \u03b5a (yia1 . . . yiaK |xa ) which is 0 if eq. (1) is verified and 2 otherwise. The total cost E of the\ncompression process is then twice the total number of unsatisfied equations in the linear system (1). The distortion\nis related to it by\nD=\n\nE\nE\n=\n.\n2M\n2N \u03b1\n\n(2)\n\nWe consider here the simplest\nQversion of the lossy compression problem: We deal with uncorrelated unbiased binary\nsources, i.e. prob(x1 , . . . xM )= a=1,M prob(xa ) and prob(xa =0)=prob(xa =1)=1/2. The rate distortion theorem [11]\nstates that a distortion D can be achieved if and only if the rate is large enough, R \u2265 R\u2217 , where the Shannon bound\nR\u2217 is given by\nR\u2217 = 1 \u2212 H2 (D) ,\nand H2 (x) = \u2212x log x \u2212 (1 \u2212 x) log(1 \u2212 x) is the binary entropy. Basically the proof of achievability in this theorem\nrelies on a choice of codewords (the set of all possible encoded words) which is a random set. This is intimately related\nto the random energy model (REM) [12]. On the other hand, our PSC can be argued to become a random energy\n\n\f2\n\nx2\n\nx1\n\nx4\n\nx3\n\nx5\n\nx6\n\nx7\n\nPSfrag replacements\n\ny1\n\ny2\n\ny3\n\ny4\n\nFIG. 1: A Tanner graph for a PSC with M = 7 checks and N = 4 variables. In this example the string to be compressed is\n{x1 , x2 , . . . x7 } \u2261 1001101. The constraints x1 , x4 , x5 , x7 impose the sum of the variables yi involved in each constraint to be 1\nmod 2, while x2 , x3 , x6 require that the variables add up to 0 mod 2.\n\nmodel in the large K limit, in the same way as the p-spin models becomes a REM in the large p limit [12, 13]. Seen\nfrom this point of view, it is not surprising that the performances of the PSC converge to the Shannon bound in the\nlimit of large K, as we shall prove here. In fact the same optimal performance has been found in a recent work [14]\nusing a a non-monotonic perceptron. Again in such a device each bit of the decoded word is chosen to be a function\nof the complete encoded word, which is the same as letting K = N , i.e. infinity in the thermodynamic limit, in our\nlanguage.\nHowever all these \"optimal\" source coding devices, based either on a random codebook like in the REM, on a\nfully connected perceptron, or on the PSC at K \u2192 \u221e, have a serious drawback: there is no known fast algorithm\nto perform the encoding. Physically, the encoding step is a search of the ground state, the one which minimizes the\nnumber of violated constraints. This has to take place in the UNSAT phase \u03b1 > 1 where these systems are frustrated.\nFinding the exact ground state is an NP-complete problem, but it turns out that we don't even have good heuristics to\nfind approximate ground states. Such a heuristic of course cannot exist for the REM, but one could hope to find one\nfor the PSC with finite K. For instance in the related problem of K-satisfiability [15], or source coding devices based\non random nodes [4], there exist good heuristics based on the message passing \"survey propagation\" (SP) algorithm\nwhich can be seen as a generalization of the celebrated 'belief propagation' algorithm [16, 17]. While this algorithm,\nas such, does not work for the PSC, it seems possible that one could develop powerful algorithms for the finite-K PSC\nin the future. Actually, a very recent work [18] proposes a message passing algorithm, inspired by SP, which seems\nto show very good performance. This motivates the present study of the theoretical capacity of the PSC at finite K.\nIn this note we compute explicitely the distortion of the PSC in the limit where the clause connectivity K becomes\nlarge. We first show that for K \u2192 \u221e the distortion becomes optimal (it saturates the Shannon bound). As for the\nfinite K corrections, we find that, for a given value of the rate R = 1/\u03b1, the distortion is\n\u221a\n(3)\nD = DSh + a Ke\u2212K\u2206 (1 + O(1/K)) ,\nwhere DSh satisfies 1 \u2212 H2 (DSh ) = 1/\u03b1 and the coefficients a and \u2206 depend on \u03b1. In particular, the actual \u2206 lies\nin [log 2, 1], and goes to log 2 in the large K limit. The fact that the first finite-K corrections are exponentially small\nmust be stressed: This means that also a parity source coder with K = 5 or 6 is in practice nearly optimal. A good\nencoding algorithm for this case could thus turn this PSC into a very good compressor. We stress that the range of\nvalidity of the result of this paper is limited to the case of uncorrelated sources. This is confirmed by the statistical\ndescription of a family of code ensembles presented in [19]. On the other hand, the hypothesis of a non-biased input\nmessage does not seem to play a role.\nAs we mentioned previously, a protocol very similar to this PSC (the only difference being the underlying graph\ntopology) has been introduced in [3], and Murayama [20] has shown that some belief-propagation based algorithm\ncan be used for encoding in the K = 2 case. Our result shows that the optimal capacity (i.e. Shannon's bound) can\nbe obtained only in the limit of large K, at variance with some of the statements in [3]. It gives the analog, for source\ncoding, to the result of Kabashima and Saad [21] on channel capacity of error-correcting codes at large K.\n\n\f3\n0\n\n10\n\nexp(-K)\n\n-1\n\n10\n\n-2\n\n1-\u03b1c\n\n10\n\n-3\n\n10\n\n-4\n\n10\n\n-5\n\n10\n\n-6\n\n10\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\nK\nFIG. 2: The critical value of the control parameter marking the transition between SAT/UNSAT is plotted versus K. Following [8], one can show that the leading behavior at large K is \u03b1c (K) = 1 \u2212 e\u2212K \u2212 (K 2 \u2212 K/2)e\u22122K + O(K 5 e\u22123K ) .\nII.\n\nCAVITY EQUATIONS\n\nIn order to deal with the K-XORSAT problem we take advantage of the cavity method as explained in [15]. This\nmethod is heuristic (the main assumptions that can be checked self-consistently) but it is believed to be exact. As\nfor the K-XORSAT problem, its range of validity has been rigorously established in [8] and [22]. In particular, the\ncavity result for the critical threshold \u03b1c is exact. For \u03b1 > \u03b1c (the regime where we use it) this method finds the\ncorrect ground-state energy up to a threshold value \u03b1G , which is \u2243 3.07 for K = 3 [22] and increases with K as one\ncan see from numerics.\nFor the sake of simplicity, we pass from boolean variables to Ising spins, thus taking values in {\u22121, +1}. The general\nidea behind the cavity approach is summarized in Fig. 3. Since the local structure of the random graph is tree-like,\nwe focus on a single clause and look at the variables connected to it. We introduce two types of messages, cavity\nbiases ua\u2192i going from clause a to variable i, and cavity fields hi\u2192a going from variable i to clause a. A cavity bias\ncan be 0 (which means that, as for the clause a, variable i is free to assume any value), or \u00b11 (meaning that this\nis the value that i should take in order to satisfy clause a). The message sent from clause a must take into account\nall the other variables connected to it;P\neach of these sends to a a cavity field which is nothing but the sum of all the\nother incoming cavity biases: hj\u2192a = b\u2208j\u2212a ub\u2192j . In the most general case, the space of low-energy configurations\nis broken into many disconnected components (clustering). The general object we need to deal with this is then a\nfunctional distribution Q[q(u)] giving the probability that, if one link a \u2192 i is chosen at random, the probability (with\nrespect to the choice of the cluster) of observing a bias ua\u2192i is qa\u2192i (ua\u2192i ). The same holds for the distribution of\ncavity fields, P[p(h)]. We thus suppose to have a population of q(u)'s and p(h)'s. In order to simplify the notations,\nwe shall simply call u0 the bias on variable 0, with no regards about the clause it is coming from. According to [8],\nwe iterate the following self-consistent equations:\n\u0012\n\u0013\nK\u22121\nX\nY\n(pK\u22121 )\n(p1 )\nfK\u03b1 (pi )\n(4)\nq0 (u0 ) =\np1 (h1 ) * * * p(K\u22121) (h(K\u22121) )\u03b4 u, S(Jh1 * * * h(K\u22121) ) , with prob.\ni=1\n\nh1 ,...h(K\u22121)\n\np(p) (h) =\n\n1\nA(p) (y) u\n\nX\n\n1 ,...up\n\n(p)\n\nA\n\n(y) =\n\nX\n\nu1 ,...up\n\nq1 (u1 ) * * * qp (up )\u03b4\n\nh,\n\np\nX\n\na=1\n\nua\n\n!\n\n\u001a X\n\u001b\np\np\nX\nexp y\n|ua | ,\nua \u2212 y\na=1\n\n\u001a X\n\u001b\np\np\nX\nq1 (u1 ) * * * qp (up ) exp y\nua \u2212 y\n|ua | .\na=1\n\n(5)\n\na=1\n\n(6)\n\na=1\n\nHere S(x) \u2261 sign(x) for x 6= 0, S(0) \u2261 0, and fK\u03b1 (*) is the Poisson distribution with mean K\u03b1. The first of these\nequations is the direct implementation of the recursion illustrated in Fig. 3: The delta function ensures that clause\n\n\fPSfrag replacements\n\n4\n\n2\n\n1\nh1\u2192a\n\n3\n\nh2\u2192a\n\nh3\u2192a\n\n4\n\nh4\u2192a\n\na\nua\u21920\n0\n\nFIG. 3: The iterative idea behind the cavity equations is illustrated here for K = 5.\n\na sends the proper value to variable 0. In the second equation, a reweighting term is present [15]. This is due\nto the fact that if we add one variable and want to compute the new probability distributions at a given value of\nthe energy E, then we need all the contributions from the states at energy E \u2212 \u2206E, where \u2206E is the energy shift\ncaused by the addition of one variable. If the number of clusters at energy E is exp(N \u03a3(E/N )), then the expansion\n\u03a3(E) \u2243 \u03a3(E \u2212\u2206E)\u2212y\u2206E leads to a reweighting exp(\u2212y\u2206E), with y = \u2202\u03a3/\u2202E. The knowledge of these distributions\nallows to compute the free energy \u03a6(y):\n\u03a6(y) = \u03a61 (y) \u2212 (K \u2212 1)\u03b1\u03a62 (y) ,\n1\n\u03a61 (y) = \u2212 log A(p) (y) ,\ny\nX\nX\n1\nq(u; {pi })\np(p) (h)ey(|u+h|\u2212|u|\u2212|h|) ,\n\u03a62 (y) = \u2212 log\ny\nu\n\n(7)\n(8)\n(9)\n\nh\n\nwhere the average is taken over the random graph ensemble and over the population of the distributions q(u)'s and\np(h)'s. The free energy in (7) is obtained by adding one variable (and a certain number of clauses) to a system with N\nvariables and computing the contribution arising from the corresponding shift in energy, exp(\u2212y\u03a61 ) = hexp(\u2212y\u2206E)i.\nThe correction term is due to the fact that in the (N + 1)\u2212variables system the probability of generating the clauses is\nslightly lower thus we have to cancel a fraction of them at random (see [15] for a detailed derivation). The ground-state\nenergy is then evaluated as the miny \u03a6(y).\nActually, the nature of messages allow for a simplification of the cavity equations: We write\nq(u) = \u03b7\u03b4u,0 +\n\n1\u2212\u03b7\n[\u03b4u,\u22121 + \u03b4u,+1 ] .\n2\n\n(10)\n\nAlso, it should be clear that, as for the p(h), what matters is only the sign of the field h, then:\np(p) (h) =\n\n\u0011\n1 \u0010 (p)\n(p)\n(p)\nw\n\u03b4\n+\nw\n\u03b4\n+\nw\n\u03b4\n,\nS(h),0\nS(h),+1\nS(h),\u22121\n+\n\u2212\n0\nA(p)\n\n(11)\n\nwith A = w0 + w+ + w\u2212 and w+ = w\u2212 because of the up-down symmetry of the problem. In practice, one needs to\nwork with a single population of real numbers \u03b7i , that leads to a stationary distribution \u03c1(\u03b7). For any fixed value of\ny, the self-consistent equations (4, 5, 6) are solved as follows:\n1. Consider a population of \u03b7i randomly distributed in [0, 1].\n2. Do K \u2212 1 times:\n\u2022 Pick a random integer p with probability fK\u03b1 (p).\n\n\f5\n\u2022 Choose p values \u03b71 , . . . \u03b7p and compute a probability distribution p(h) according to (5). Given (11), this\namounts to computing two real numbers: w0 and the normalization A.\n\u2022 Compute \u03a61 as in (8) through this A.\n3. Using these K \u2212 1 distributions p(h)'s, compute a new q(u) according to (4). Given (10) this is the same as\ncomputing a new value \u03b70 .\n4. Use this new q(u) and a new extracted p(h) to compute \u03a62 as in (9). The total free energy can now be evaluated\nvia (7).\n5. Replace an \u03b7 value randomly chosen in the distribtion with the new value \u03b70 .\n6. Go to step 2 until a stationary distribution \u03c1(\u03b7) is reached. (The free energy attains then a stationary value.)\nWe are now going to discuss the cavity equations for large K and we will use the algorithm we have just described\nto check numerically our asymptotic results.\nIII.\n\nTHE SHANNON BOUND\n\nThe cavity equations (4, 5, 6) have been discussed in [8] mainly concerning the value of \u03b1c (K) and the behavior of\nthe ground state energy E0 (K) close to \u03b1c (K). We want to compute E0 (K) at any \u03b1 in the large-K limit.\nFor large K, there is a self-consistent solution of the cavity equations such that all the w0 are very small, in fact\nexponentially small. We just need to assume that the typical value of a w0 is much smaller than 1/K. This condition\non w0 's shows that \u03b7 is zero to leading order, because from eq. (4) one finds that\n\u03b7 =1\u2212\n\nK\u22121\nY\u0010\ni=1\n\n(pi )\n\n1 \u2212 w0\n\n\u0011\n\n.\n\n(12)\n\nWe shall be more precise below as we verify self-consistently the assumption on w0 and will be able to compute the\nfirst non-zero term. Here we work directly with \u03b7 = 0. We need to compute the new value of w0 and w+ using eq. (5).\nIf K is large, p is generically large (it is Poisson distributed with mean K\u03b1). If p is even (the case of p odd is an\nimmediate generalization) one finds:\n\u0012\n\u0013\np e\u2212py\n2e\u2212py\n(p)\n\u221a\nw0 =\n\u2243\n,\n(13)\np/2 2p\n2\u03c0p\np\n\u0012 \u0013\nZ 1/2\n2 \u22121\nn\no\np \u2212qy\np\n1 X\ndx\n(p)\np\nexp p (\u2212x log x \u2212 (1 \u2212 x) log(1 \u2212 x) \u2212 xy) ,\n(14)\ne\n\u2243 p\nw+ = p\n2 q=0 q\n2 0\n2\u03c0px(1 \u2212 x)\n(p)\n\nw\u2212\n\n(p)\n\n= w+ .\n\n(15)\n\nThe integral can be evaluated for p large by the saddle point method (the saddle point being x\u2217 = \u2212y + log(1 + ey ))\nand we have\n\u0012\n\u0013p\n1 + e\u22122y\n(p)\nw+ =\n.\n2\nSince for any finite y this is exponentially larger than w0 , the leading term in the normalization constant is just\n\u0012\n\u0013p\n1 + e\u22122y\n(p)\n(p)\nA (y) = 2w+ = 2\n.\n(16)\n2\nNow, it is not difficult to show that eq. (9) can be rewritten as\n\u0012 (p+1) \u0013\nA\n(y)\n1\n,\n\u03a62 (y) = \u2212 log\n(p)\ny\nA (y)\nand thus the free-energy can be computed from the normalization (16) alone. We find that\n\u0012 (p+1) \u0013!\n\u0014\n\u0012\n\u0013\u0015\n1\nA\n(y)\n1 + e\u22122y\n1\n(p)\nlog A (y) \u2212 (K \u2212 1)\u03b1log\n= \u2212 log 2 + \u03b1 log\n\u2261 \u03a6\u221e (y) .\n\u03a6(y) = \u2212\ny\ny\n2\nA(p) (y)\n\n(17)\n\n(18)\n\n\f6\nThe ground state energy is the maximum of \u03a6(y) [15] and, according to eq. (2), this gives a distortion D for the parity\nsource coder at large K\nD=\n\n1\nmax \u03a6\u221e (y) .\n2\u03b1 y\n\n(19)\n\nThe Shannon bound says that the minimum distortion satisfies 1 \u2212 H2 (DSh ) = 1/\u03b1. A few lines of computation show\nthat the distortion in (19) actually saturates the Shannon bound. Let's call z the value of y where \u03a6\u221e (y) is maximal.\nIt satisfies:\nlog 2 = \u03b1 (z tanh z \u2212 log cosh z)\n\n(20)\n\nThen one gets\n\u03a6\u221e (z)\n1\n= 2z\n2\u03b1\ne +1\n\n\u21d2\n\nH2\n\n\u0012\n\n\u03a6\u221e (z)\n2\u03b1\n\n\u0013\n\n1\n=\nlog 2\n\n\u0012\n\u2212 log\n\n1\ne2z\n\u2212\n2z\ne2z + 1\ne2z + 1\n\n\u0013\n\n.\n\nAfter some algebra one can derive from this the seeked result:\n\u0012\n\u0013\n\u03a6\u221e (z)\n1\nH2\n=1\u2212 .\n2\u03b1\n\u03b1\n\n(21)\n\n(22)\n\nThis shows that at very large K the XORSAT problem gives exactly the Shannon limit. We now look at finite-K\ncorrections in order to see how this asymptotic performance is reached.\nIV.\n\nCORRECTIONS\n\nIn order to compute the first order corrections to the leading behavior we compute the normalization constant in (6)\nunder the hypothesis of small (but finite) \u03b7:\n(p)\n\nA\n\n(y) =\n\n\u0013\np \u0012\nY\n1 \u2212 \u03b7a\n\na=1\n\n2\n\ne\n\n\u2212py\n\np \u0012 \u0013\nX\np\nq=0\n\nq\n\ne\n\ny|p\u22122q|\n\n+ p\u03b71\n\n\u0013\np \u0012\nY\n1 \u2212 \u03b7a\n\na=2\n\n2\n\ne\n\n\u2212(p\u22121)y\n\n\u0013\np\u22121 \u0012\nX\np \u2212 1 y|p\u22121\u22122q|\ne\n+ ...\nq\nq=0\n\np\nX\ne\u2212py\ne\u2212(p\u22121)y\ne\u2212(p\u22122)y\n2\n=\n\u03b7\n+\nO(p\u03b7)\n)\n+\np\u03b7\ng\n(y)(1\n\u2212\ng\n(y)(1\n+\nO(p\u03b7))\n+\ngp\u22122 (y)O(p\u03b7)2 + . . . ,(23)\na\np\np\u22121\np\u22121\np\u22122\n2p\n2\n2\na=1\np \u0012 \u0013\nX\np y|p\u22122q|\ngp (y) \u2261\ne\n.\n(24)\nq\nq=0\n\nAs we have shown above, the whole free energy can be computed from the knowledge of A(p) (y). In order to calculate\nit, we compute the function gp (y) in the large p limit. We first notice that it can be written as\n#\n\"\np\nX\nX\n\u03c3i ,\n(25)\nexp y\ngp (y) =\n\u03c31 ,...\u03c3p\n\ni=1\n\nwhere \u03c3i are Ising spins. Thus,\ngp (y) + gp (\u2212y) =\n\ni Xh P\ni\nXh P\nP\nP\ney| i \u03c3i | + e\u2212y| i \u03c3i | =\ney i \u03c3i + e\u2212y i \u03c3i = 2(2 cosh y)p .\n\n{\u03c3i }\n\n(26)\n\n{\u03c3i }\n\nWe use a Fourier transformation to express gp (\u2212y):\ngp (\u2212y) =\n\ny\n\u03c0\n\nZ\n\nZ\np \u0012 \u0013\nX\np \u2212i2qk\ndk\ny\ny p dk(cos k)p\nikp\ne\n2\n= 2p\ne\n=\n2 + y2\nk2 + y2\n\u03c0\nk\n\u03c0\nq\nq=0\n\nr\n\n2\u03c0\np\n\n\u0012 \u0013\u0013 X\n\u0012\n+\u221e\n1\n1\n(\u22121)np\n+O\n,\n1\u2212\n2\n4p\np\n(\u03c0n)2 + y 2\nn=\u2212\u221e\n\nThe sum can be done exactly and we have\ngp\n\neven (\u2212y)\n\n1\n2p+1\n(1 \u2212 1/4p + O(1/p2 )) ,\n=\u221a\n2\u03c0p tanh y\n\ngp\n\nodd (\u2212y)\n\n1\n2p+1\n= \u221a\n(1 \u2212 1/4p + O(1/p2 )) .\n2\u03c0p sinh(y)\n\n(27)\n\n\f7\nUsing (26), we get for p even\ngp (y) = 2\n\np+1\n\np\n\n(cosh y)\n\n\u0014\n\n(cosh y)\u2212p\n1\u2212 \u221a\n2\u03c0p(tanh y)\n\n\u0012\n\u0012 \u0013\u0013\u0015\n1\n1\n1\u2212\n,\n+O\n4p\np2\n\n(28)\n\nwith the replacement tanh y \u2192 sinh y if p is odd. To the leading order we have thus\n\u0013p\n\u0012\n\u0001\n1 + e\u22122y\n(p)\nA (y) = 2\n1 + O(p\u03b3 e\u2212p ) ,\n2\n\n(29)\n\nwith some exponent \u03b3 which depends on the actual order of magnitude of \u03b7. To compute it we first need to know\nthe weight for h = 0. If p is even we use eq. (5) and we note that the main contribution (in the same hypothesis of \u03b7\nsmall) is given by\n\u0012\n\u0013 Y\np\n1\np\n1\n(p even)\n\u2212py\n(1 \u2212 \u03b7a ) + O(p\u03b7)\n= (p) e\nw0\np/2 2p a=1\nA (y)\n\u0012\n\u0013\u2212p\n\u0012 \u0013\u0013\n\u0012\n\u0001 \u2212py 2p+1\n1 1 + e\u22122y\n1\n1\n1\n\u03b3 \u2212p\n\u221a\n=\n1 + O(p e ) e\n(1 + O(p\u03b7))\n+O\n1\u2212\n2\n2\n2\n4p\np\n2p\n2\u03c0p\n\u0001\n(cosh y)\u2212p\n\u221a\n=\n1 \u2212 1/4p + O(1/p2 ) + O(p\u03b7) .\n(30)\n2\u03c0p\n\n(Here we have also assumed that p > 0, since w0 = 1 if p = 0.) On the other hand, if p is odd we have\n\u0012\n\u0013\np\u22121\np\u22121\n1 Y\n1\n(p odd)\n\u2212(p\u22121)y\n(1 \u2212 \u03b7a ) + O(p\u03b7)2\np\nw0\n= \u03b7 (p) e\n(p \u2212 1)/2 2p\u22121 a=1\nA (y)\nr\np y\n=\n\u03b7e (cosh y)\u2212p (1 + O(1/p)) .\n2\u03c0\nTo the leading order, \u03b7 does not fluctuate and takes the value\n\u03b7 \u2243 \u2212 log(1 \u2212 \u03b7) \u2243\n\nK\u22121\nX\ni=1\n\n(pi )\n\nw0\n\nh\n(p\n= (K \u2212 1) e\u2212K\u03b1 + e\u2212K\u03b1 (cosh(K\u03b1) \u2212 1)w0\n\u2243\n\n\u0012 \u0013\u0013\u0015\n\u0014\n\u0012\n1\n1\nK \u2212 1 (cosh y)\u2212p\n\u221a\n+O\n1\u2212\n2\n4p\np2\n2\u03c0p\np\n\neven)\n\n(p odd)\n\n+ e\u2212K\u03b1 sinh(K\u03b1)w0\np>0\n\neven>0\n\ni\n\n+ O(Ke\u2212K\u03b1 ) + O(\u03b7 2 ) ,\n\nsince the two other terms (p = 0 and p odd) are exponentially subleading. In order to perform this average we use\nZ\n1\n1\n=\ndt tz\u22121 e\u2212pt\n(31)\npz\n\u0393(z)\n\nto express the denominator. This allows to perform the average over p even. We then have\n\u0012\n\u0013\u001a Z\nZ\n\u0010\n\u0011\u001b\nKe\u2212K\u03b1\n1\n\u22121/2\n\u2212t\n1/2\n\u2212t\n\u22125/2\n\u221a\n\u03b7 =\n1\u2212\n2 dt t\n(cosh(\u03b2e ) \u2212 1) \u2212 dt t (cosh(\u03b2e ) \u2212 1) + O \u03b2\n+ O(Ke\u2212K\u03b1 )\nK\n4\u03c0 2\n\u0012\n\u0013\n\u0013\u0012\nZ\nt\n1\nKe\u2212K\u03b1\n1/2 \u2212t\n\u2212t\n2\n\u221a 4\u03b2 dt t e sinh(\u03b2e ) 1 \u2212 + O(t )\n+ O(Ke\u2212K\u03b1 )\n1\u2212\n=\n6\nK\n4\u03c0 2\nwhere \u03b2 \u2261 K\u03b1/ cosh y. We then set t = \u03c4 /\u03b2 and expand in 1/\u03b2. This gives\n\"\n\u221a\n\u0012\n\u00132 #\n\u0013\n\u0012\n1 cosh y\ncosh y\ncosh y 1/2 \u2212K\u03b1(1\u22121/ cosh y)\n\u03b7= \u221a\nK e\n1+\n+ O(Ke\u2212K\u03b1 ) ,\n\u22121 +O\nK\n8\u03b1\nK\u03b1\n2 2\u03c0\u03b1\n\n(32)\n\nwhich shows a posteriori that the small \u03b7 hypothesis is consistent. We now go back to (23) and get:\n\u0013p\n\u0012\n\u0002\n\u0003\n1 + e\u22122y\n1 \u2212 p\u03b7 tanh y + O(p\u03b7)2\nA(p) (y) = 2\n2\n\u221a\n\u0013p \"\n\u0012\n\u00132 !\n\u0013\n\u0012\n\u0012\np tanh y cosh y 1/2 \u2212K\u03b1(1\u22121/ cosh y)\n1 cosh y\ncosh y\n1 + e\u22122y\n\u221a\n1\u2212\n1+\n+\n\u22121 +O\n= 2\nK e\n2\nK\n8\u03b1\nK\u03b1\n2 2\u03c0\u03b1\n\u0015\n\u2212K\u03b1\n+O(pKe\n) .\n(33)\n\n\f8\nFrom this result and from eq. (9) one finds that\n\u0013\n\u0012 \u0012\n\u0013\n1\n1 + e\u22122y\n2\n.\nlog\n\u2212 \u03b7 tanh y + O(K\u03b7)\n\u03a62 (y) = \u2212\ny\n2\n\n(34)\n\nMoreover,\n\u03a61 (y) = \u2212\n\n1\ny\n\n\u0013\n\u0012\n\u0012\n\u0013\n1 + e\u22122y\n2\n.\nlog 2 + K\u03b1 log\n+ K\u03b1\u03b7 tanh y + O(K\u03b7)\n2\n\n(35)\n\nWe can now compute\nthe total free energy (7). One\ncan check directly that the leading corrections to the infinite K\nh\n\u0001i\n3/2\nlimit, of order O K exp \u2212 K\u03b1(1 \u2212 1/ cosh y) , vanish. We are then left with\n\n\u0012\n\u0014\n\u0012\n\u0013\u0015 \u221a\n\u0012\n\u0013\u0013\n\u0013\n\u0012\ncosh y tanh y\n1\n1 cosh y\n1 + e\u22122y\n1\n\u221a\n(\u03b1K)1/2 e\u2212K\u03b1(1\u22121/ cosh y) 1 +\nlog 2 + \u03b1 log\n+\n\u22121 +O\ny\n2\nK\n8\u03b1\nK2\n2y 2\u03c0\n= \u03a6\u221e (y) + \u2206\u03a6K (y) ,\n(36)\n\n\u03a6(y) = \u2212\n\nwhere limK\u2192\u221e \u2206\u03a6K = 0. We assume that the maximum of the \u03a6(y) in (36) is at y = z + \u03b5, where \u03b5 is exponentially\nsmall at large K (we shall verify self-consistently this hypothesis) and z is the solution of eq. (20). The condition\n\u03a6\u2032 (y) = 0 then results in\n\u03b5=\u2212\n\n\u0010\n\u0011\n\u2206\u03a6\u2032K (z)\n\u22121/2 \u2212K\u03b1(1\u22121/ cosh z)\n=\nO\nK\ne\n,\n\u03a6\u2032\u2032\u221e (z)\n\n(37)\n\nwhere the dependence\nof z on \u03b1 is extracted from (20). One finds that z is a monotonic decreasing function. In\np\nparticular, z \u223c 2log2/\u03b1 at large \u03b1 while z diverges as (\u22121/2)log(\u03b1 \u2212 1) as \u03b1 \u2192 1: It follows that \u03b5 is exponentially\nsmall in any case. Coming back to eq. (19), it is then easy to see that to the leading order\nD=\n\n1\n(\u03a6\u221e (z) + \u2206\u03a6K (z)) = DSh + CK (\u03b1) ,\n2\u03b1\n\nwhere the corrections CK (\u03b1) are finally\n\u221a\n\u0012\n\u0012\n\u0013\u0013 \u0010\n\u0013\n\u0012\n\u0010\n\u0011\u0011\n1 cosh z\n1\ncosh z tanh z 1/2 \u2212K\u03b1(1\u22121/ cosh z)\n1/2 \u2212K\u03b1\n\u221a\n1+\nK e\nCK (\u03b1) =\n\u22121 +O\n1\n+\nO\nK\ne\n,\nK\n8\u03b1\nK2\n4z 2\u03c0\u03b1\n\n(38)\n\n(39)\n\nz being the solution of eq. (20).\nWe now look at numerical data in order to verify our analytical prediction. In Fig. 4 we plot the difference between\nthe actual distortion of the PSC as obtained from the numerical solution of the cavity equations at \u03b1 = 1.3 and\nthe corresponding Shannon value. The curve is the theoretical prediction in (39), where we neglected the 1/K 2\ncorrections. The same plot but for \u03b1 = 2 is shown in Fig. 5. In both cases there is a very good agreement with the\nanalytical prediction.\nV.\n\nCONCLUSIONS\n\nWe have shown that the theoretical capacity of the Parity Source Coder is optimal at large K and that the\ncorrections to the leading behaviour are exponentially small. Nevertheless, due to the smallness of \u2206 (cfr. Fig. 6),\nthe exponential decreases quite slowly, and 1/K corrections are needed to take into account the deviations from the\nleading behavior at relatively small values of K.\nAcknowledgments. We thank O. Rivoire M. Wainwright, J.S. Yedidia and R. Zecchina for important discussions,\nand an anonimous referee for useful suggestions and references. S. C. is supported by EC through the network MTR\n2002-00307, DYGLAGEMEM. This work has been supported in part by the EC through the network MTR 2002-00319\nSTIPCO and the FP6 IST consortium EVERGROW.\n\n[1] E. Martinian, J. S. Yedidia, MERL report 2003.\n\n\fD(K)-DShannon\n\n9\n10\n\n-2\n\n10\n\n-3\n\n10\n\n-4\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nK\n\nD(K)-DShannon\n\nFIG. 4: Theoretical capacity of the PSC, \u03b1 = 1.3.\n10\n\n-2\n\n10\n\n-3\n\n10\n\n-4\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nK\n\nFIG. 5: Theoretical capacity of the PSC, \u03b1 = 2.0.\n\n[2]\n[3]\n[4]\n[5]\n[6]\n[7]\n[8]\n[9]\n[10]\n[11]\n[12]\n[13]\n\nD. J. C. MacKay, Information Theory, Inference and Learning Algorithms, (Cambridge University Press, 2003).\nT. Murayama, M. Okada, J. Phys. A: Math. Gen. 36, 11123 (2003).\nS. Ciliberti, M. M\u00e9zard, R. Zecchina, Phys. Rev. Lett. 95, 038701 (2005).\nM.J. Wainwright and E. Maneva, cs.IT/0508068, to appear in International Symposium on Information Theory, Adelaide,\nAustralia.\nF. R. Kschischang, B. J. Frey, H.-A. Loeliger, IEEE Trans. Inform. Theory 47, 498 (2002).\nT. J. Schaefer, in Proceeding of the 10th STOC, San Diego (CA, USA), ACM, 216 (New York, 1978).\nM. M\u00e9zard, F. Ricci-Tersenghi, R. Zecchina, J. Stat. Phys. 111, 505 (2003).\nS. Cocco, O. Dubois, J. Mandler, R. Monasson, Phys. Rev. Lett. 90, 047205 (2003).\nD. J. Gross, M. M\u00e9zard, Nucl. Phys. B240, 431 (1984).\nT. M. Cover, J. A. Thomas, Elements of Information Theory, (Wiley, New York, 1991).\nB. Derrida, Phys. Rev. B 24, 2613 (1981).\nThis point, along with the \"hardening\" of the constraints at large K, is discussed with some detail in O. Rivoire, Ph. D.\nThesis, Universit\u00e9 de Paris-Sud (2005).\n\n\f10\n\n1\n3\n2\nz\n\n0.92\n\n\u2206\n\n1\n0.84\n\n0\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n\u03b1\n0.76\nlog 2\n0.68\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n\u03b1\nFIG. 6: The value of \u2206 \u2261 \u03b1(1\n\u221a \u2212 1/ cosh z), z being the solution of eq. (20), is plotted vs \u03b1. One finds that \u2206 = log 2 + O(1/\u03b1)\nat large \u03b1, while \u2206 = 1 \u2212 2 \u03b1 \u2212 1 + O(\u03b1 \u2212 1) as \u03b1 \u2192 1+ . Inset: The actual value of z as a function of \u03b1, as given by eq. (20).\nIt diverges as \u2212 log(\u03b1 \u2212 1) as \u03b1 \u2192 1+ .\n[14]\n[15]\n[16]\n[17]\n[18]\n[19]\n[20]\n[21]\n[22]\n\nT. Hosaka, Y. Kabashima, H. Nishimori, Phys. Rev. E 66, 066126 (2002).\nM. M\u00e9zard, R. Zecchina, Phys. Rev. E 66, 056126 (2002).\nA. Braunstein, M. M\u00e9zard and R. Zecchina, Rand. Struct. Alg.\" 27 (2005) 201.\nA. Braunstein, R. Zecchina, cond-mat/0312483.\nE. Maneva, E. Mossel and M. J. Wainwright, cs.CC/0409012.\nT. Hosaka, Y. Kabashima, J. Phys. Soc. Jpn. 74, 488 (2005).\nT. Murayama, Phys. Rev. E 69, 035105(R) (2004).\nY. Kabashima, D. Saad, Europhys. Lett. 45 (1), 97 (1999).\nA. Montanari, F. Ricci-Tersenghi, G. Parisi, J. Phys. A 37, 2073 (2004).\n\n\f"}