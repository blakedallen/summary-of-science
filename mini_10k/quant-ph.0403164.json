{"id": "http://arxiv.org/abs/quant-ph/0403164v2", "guidislink": true, "updated": "2005-04-29T17:25:50Z", "updated_parsed": [2005, 4, 29, 17, 25, 50, 4, 119, 0], "published": "2004-03-23T13:07:44Z", "published_parsed": [2004, 3, 23, 13, 7, 44, 1, 83, 0], "title": "Quantum Branching Programs and Space-Bounded Nonuniform Quantum\n  Complexity", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=quant-ph%2F0403178%2Cquant-ph%2F0403070%2Cquant-ph%2F0403027%2Cquant-ph%2F0403052%2Cquant-ph%2F0403173%2Cquant-ph%2F0403139%2Cquant-ph%2F0403142%2Cquant-ph%2F0403183%2Cquant-ph%2F0403194%2Cquant-ph%2F0403091%2Cquant-ph%2F0403140%2Cquant-ph%2F0403148%2Cquant-ph%2F0403088%2Cquant-ph%2F0403207%2Cquant-ph%2F0403112%2Cquant-ph%2F0403068%2Cquant-ph%2F0403024%2Cquant-ph%2F0403048%2Cquant-ph%2F0403231%2Cquant-ph%2F0403118%2Cquant-ph%2F0403164%2Cquant-ph%2F0403146%2Cquant-ph%2F0403028%2Cquant-ph%2F0403075%2Cquant-ph%2F0403085%2Cquant-ph%2F0403205%2Cquant-ph%2F0403202%2Cquant-ph%2F0403099%2Cquant-ph%2F0403195%2Cquant-ph%2F0403130%2Cquant-ph%2F0403097%2Cquant-ph%2F0403102%2Cquant-ph%2F0403126%2Cquant-ph%2F0403104%2Cquant-ph%2F0403006%2Cquant-ph%2F0403189%2Cquant-ph%2F0403223%2Cquant-ph%2F0403115%2Cquant-ph%2F0403192%2Cquant-ph%2F0403062%2Cquant-ph%2F0403131%2Cquant-ph%2F0403149%2Cquant-ph%2F0403077%2Cquant-ph%2F0403065%2Cquant-ph%2F0403220%2Cquant-ph%2F0403103%2Cquant-ph%2F0403166%2Cquant-ph%2F0403043%2Cquant-ph%2F0403094%2Cquant-ph%2F0403193%2Cquant-ph%2F0403066%2Cquant-ph%2F0403108%2Cquant-ph%2F0403049%2Cquant-ph%2F0403123%2Cquant-ph%2F0403159%2Cquant-ph%2F0403017%2Cquant-ph%2F0403214%2Cquant-ph%2F0403172%2Cquant-ph%2F0403211%2Cquant-ph%2F0403089%2Cquant-ph%2F0403226%2Cquant-ph%2F0403218%2Cquant-ph%2F0403042%2Cquant-ph%2F0403003%2Cquant-ph%2F0403081%2Cquant-ph%2F0403234%2Cquant-ph%2F0403217%2Cquant-ph%2F0403038%2Cquant-ph%2F0403095%2Cquant-ph%2F0403143%2Cquant-ph%2F0403203%2Cquant-ph%2F0403154%2Cquant-ph%2F0403162%2Cquant-ph%2F0403092%2Cquant-ph%2F0403002%2Cquant-ph%2F0403022%2Cquant-ph%2F0403058%2Cquant-ph%2F0403079%2Cquant-ph%2F0403041%2Cquant-ph%2F0403083%2Cquant-ph%2F0403199%2Cquant-ph%2F0403147%2Cquant-ph%2F0403008%2Cquant-ph%2F0403177%2Cquant-ph%2F0403209%2Cquant-ph%2F0403087%2Cquant-ph%2F0403138%2Cquant-ph%2F0403225%2Cquant-ph%2F0403015%2Cquant-ph%2F0403187%2Cquant-ph%2F0403059%2Cquant-ph%2F0403110%2Cquant-ph%2F0403157%2Cquant-ph%2F0403034%2Cquant-ph%2F0403040%2Cquant-ph%2F0403023%2Cquant-ph%2F0403025%2Cquant-ph%2F0403016%2Cquant-ph%2F0403182%2Cquant-ph%2F0403121%2Cquant-ph%2F0403156&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Quantum Branching Programs and Space-Bounded Nonuniform Quantum\n  Complexity"}, "summary": "In this paper, the space complexity of nonuniform quantum computations is\ninvestigated. The model chosen for this are quantum branching programs, which\nprovide a graphic description of sequential quantum algorithms. In the first\npart of the paper, simulations between quantum branching programs and\nnonuniform quantum Turing machines are presented which allow to transfer lower\nand upper bound results between the two models. In the second part of the\npaper, different variants of quantum OBDDs are compared with their\ndeterministic and randomized counterparts. In the third part, quantum branching\nprograms are considered where the performed unitary operation may depend on the\nresult of a previous measurement. For this model a simulation of randomized\nOBDDs and exponential lower bounds are presented.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=quant-ph%2F0403178%2Cquant-ph%2F0403070%2Cquant-ph%2F0403027%2Cquant-ph%2F0403052%2Cquant-ph%2F0403173%2Cquant-ph%2F0403139%2Cquant-ph%2F0403142%2Cquant-ph%2F0403183%2Cquant-ph%2F0403194%2Cquant-ph%2F0403091%2Cquant-ph%2F0403140%2Cquant-ph%2F0403148%2Cquant-ph%2F0403088%2Cquant-ph%2F0403207%2Cquant-ph%2F0403112%2Cquant-ph%2F0403068%2Cquant-ph%2F0403024%2Cquant-ph%2F0403048%2Cquant-ph%2F0403231%2Cquant-ph%2F0403118%2Cquant-ph%2F0403164%2Cquant-ph%2F0403146%2Cquant-ph%2F0403028%2Cquant-ph%2F0403075%2Cquant-ph%2F0403085%2Cquant-ph%2F0403205%2Cquant-ph%2F0403202%2Cquant-ph%2F0403099%2Cquant-ph%2F0403195%2Cquant-ph%2F0403130%2Cquant-ph%2F0403097%2Cquant-ph%2F0403102%2Cquant-ph%2F0403126%2Cquant-ph%2F0403104%2Cquant-ph%2F0403006%2Cquant-ph%2F0403189%2Cquant-ph%2F0403223%2Cquant-ph%2F0403115%2Cquant-ph%2F0403192%2Cquant-ph%2F0403062%2Cquant-ph%2F0403131%2Cquant-ph%2F0403149%2Cquant-ph%2F0403077%2Cquant-ph%2F0403065%2Cquant-ph%2F0403220%2Cquant-ph%2F0403103%2Cquant-ph%2F0403166%2Cquant-ph%2F0403043%2Cquant-ph%2F0403094%2Cquant-ph%2F0403193%2Cquant-ph%2F0403066%2Cquant-ph%2F0403108%2Cquant-ph%2F0403049%2Cquant-ph%2F0403123%2Cquant-ph%2F0403159%2Cquant-ph%2F0403017%2Cquant-ph%2F0403214%2Cquant-ph%2F0403172%2Cquant-ph%2F0403211%2Cquant-ph%2F0403089%2Cquant-ph%2F0403226%2Cquant-ph%2F0403218%2Cquant-ph%2F0403042%2Cquant-ph%2F0403003%2Cquant-ph%2F0403081%2Cquant-ph%2F0403234%2Cquant-ph%2F0403217%2Cquant-ph%2F0403038%2Cquant-ph%2F0403095%2Cquant-ph%2F0403143%2Cquant-ph%2F0403203%2Cquant-ph%2F0403154%2Cquant-ph%2F0403162%2Cquant-ph%2F0403092%2Cquant-ph%2F0403002%2Cquant-ph%2F0403022%2Cquant-ph%2F0403058%2Cquant-ph%2F0403079%2Cquant-ph%2F0403041%2Cquant-ph%2F0403083%2Cquant-ph%2F0403199%2Cquant-ph%2F0403147%2Cquant-ph%2F0403008%2Cquant-ph%2F0403177%2Cquant-ph%2F0403209%2Cquant-ph%2F0403087%2Cquant-ph%2F0403138%2Cquant-ph%2F0403225%2Cquant-ph%2F0403015%2Cquant-ph%2F0403187%2Cquant-ph%2F0403059%2Cquant-ph%2F0403110%2Cquant-ph%2F0403157%2Cquant-ph%2F0403034%2Cquant-ph%2F0403040%2Cquant-ph%2F0403023%2Cquant-ph%2F0403025%2Cquant-ph%2F0403016%2Cquant-ph%2F0403182%2Cquant-ph%2F0403121%2Cquant-ph%2F0403156&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper, the space complexity of nonuniform quantum computations is\ninvestigated. The model chosen for this are quantum branching programs, which\nprovide a graphic description of sequential quantum algorithms. In the first\npart of the paper, simulations between quantum branching programs and\nnonuniform quantum Turing machines are presented which allow to transfer lower\nand upper bound results between the two models. In the second part of the\npaper, different variants of quantum OBDDs are compared with their\ndeterministic and randomized counterparts. In the third part, quantum branching\nprograms are considered where the performed unitary operation may depend on the\nresult of a previous measurement. For this model a simulation of randomized\nOBDDs and exponential lower bounds are presented."}, "authors": ["M. Sauerhoff", "D. Sieling"], "author_detail": {"name": "D. Sieling"}, "author": "D. Sieling", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.tcs.2004.12.031", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/quant-ph/0403164v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/quant-ph/0403164v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "45 pages, 3 Postscript figures. Proofs rearranged, typos corrected", "arxiv_primary_category": {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/quant-ph/0403164v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/quant-ph/0403164v2", "journal_reference": "Theoretical Computer Science 334, pp. 177-225, 2005", "doi": "10.1016/j.tcs.2004.12.031", "fulltext": "Quantum Branching Programs and\nSpace-Bounded Nonuniform Quantum Complexity\n\narXiv:quant-ph/0403164v2 29 Apr 2005\n\nMartin Sauerhoff\u2217 and Detlef Sieling\u2217\u2217\nFB Informatik, Univ. Dortmund, 44221 Dortmund, Germany\nEmail: {sauerhoff|ds01}@ls2.cs.uni-dortmund.de\nAbstract. In this paper, the space complexity of nonuniform quantum algorithms\nis investigated using the model of quantum branching programs (QBPs). In order to\nclarify the relationship between QBPs and nonuniform quantum Turing machines,\nsimulations between these two models are presented which allow to transfer upper and lower bound results. Exploiting additional insights about the connection\nbetween the running time and the precision of amplitudes, it is shown that nonuniform quantum Turing machines with algebraic amplitudes and QBPs with a suitable\nanalogous set of amplitudes are equivalent in computational power if both models\nwork with bounded or unbounded error. Furthermore, quantum ordered binary\ndecision diagrams (QOBDDs) are considered, which are restricted QBPs that can\nbe regarded as a nonuniform analog of one-way quantum finite automata. Upper\nand lower bounds are proved that allow a classification of the computational power\nof QOBDDs in comparison to usual deterministic and randomized variants of the\nmodel. Finally, an extension of QBPs is proposed where the performed unitary\noperation may depend on the result of a previous measurement. A simulation of\nrandomized BPs by this generalized QBP model as well as exponential lower bounds\nfor its ordered variant are presented.\n\n1. Introduction\nThe intriguing open question behind the research on quantum computing is whether there are\nproblems that can be solved more efficiently by quantum computers than by classical ones.\nShor's famous quantum algorithm for factoring integers in polynomial time [35] provides the\nmost conclusive evidence so far in favor of an affirmative answer of this question. The notion of a\nquantum algorithm is made precise by models of computation such as quantum Turing machines\n(QTMs), quantum circuits, quantum finite automata (QFAs), and quantum communication\nprotocols. For an introduction to these models, we refer to the textbooks of Gruska [13],\nKitaev, Shen, and Vyalyi [18], and Nielsen and Chuang [26].\nApart from the obviously important computation time, different other complexity measures for\nquantum algorithms have been investigated. Space is a crucial resource due to inherent technical constraints in the current physical realizations of quantum computers. As pointed out by\nAmbainis and Freivalds [7], the goal of obtaining systems with a small quantum mechanical part\nwas one of the motivations for considering quantum finite automata. In his seminal paper [39]\nand its later extensions [40, 41], Watrous investigated the space complexity of quantum algorithms in the more general model of quantum Turing machines. The quantum Turing machines\nconsidered by Watrous may have algebraic transition amplitudes and are unidirectional, i. e.,\n\u2217\n\u2217\u2217\n\nSupported by DFG grant Sa 1053/1-1.\nSupported by DFG grant Si 577/1-1.\n\n1\n\n\fthe direction of the head movements is a function of the state entered in a computation step.\nAmong other results, he has shown for this scenario that space O(s) probabilistic Turing machines with unbounded error and quantum Turing machines with unbounded error are equivalent\nin computational power, where s is a space-constructible function. It is open whether similar\nstatements hold for other types of error, e. g., bounded error. It is also not known whether the\nrequirement of algebraic transition amplitudes is crucial for space-restricted quantum Turing\nmachines, despite the results of Adleman, DeMarrais, and Huang [3] that allow us to restrict the\nset of amplitudes to {0, \u00b13/5, \u00b14/5, \u00b11} for polynomial time, bounded error quantum Turing\nmachines. Finally, even the standard assumption of unidirectionality remains to be justified for\nQTMs with sublinear space-bounds, since the known simulations for the time-bounded case due\nBernstein and Vazirani [11] and Yao [43] or Nishimura and Ozawa [27] can not be applied in an\nobvious way.\nAlready classical Turing machines have turned out to be a quite cumbersome device for proving\nupper and lower bounds. Branching programs are a graphic representation of boolean functions\nand as such are more amenable to combinatorial arguments than Turing machines. Furthermore, it is well-known that the logarithm of the size of branching programs is asymptotically\nequal to the space complexity for the nonuniform (advice taking) variant of Turing machines\n(Cobham [12], Pudl\u00e1k and \u017d\u00e1k [30]). Recently obtained lower bound results for branching programs [8,5,6,9,10], which imply time-space tradeoffs for sequential computations, underline the\nsignificance of branching programs in the investigation of space complexity.\nIn this paper we deal with a quantum variant of branching programs. In order to give a feeling\nof how quantum branching programs (QBPs) work, we consider the example in Figure 1. For\nthe formal definition and the technical details we refer to Definitions 2.4 and 2.5. The QBP\nin the figure represents a boolean function depending on the variables x1 and x2 . Each node\nv \u2208 V = {v1 , . . . , v6 } of the QBP is associated with a vector |vi of an orthonormal basis of\nthe Hilbert space H = C|V | . Each intermediate state of the computation of the QBP is a\nvector in H. The initial state of the QBP is |v1 i, where v1 is the start node of the QBP. Each\ncomputation step consists of a first phase, where a projective measurement is used to decide\nwhether the computation continues or whether it stops with the result 0 or 1, and a second phase,\nwhere a unitary transformation described by the edge labels is applied to the state. If xi = 0\n(xi = 1), only the dashed (solid) edges leaving each xi -node contribute to this transformation.\nIn our example the projections describing the measurement are Econt = |v1 ihv1 | + * * * + |v4 ihv4 |,\nE0 = |v5 ihv5 |, and E1 = |v6 ihv6 |, i. e., the projections on the subspaces spanned by the vectors\ncorresponding to interior nodes and sinks labeled by 0 and 1, resp. Assume that x1 = x2 = 0.\nThe initial state is |v1 i. The projective measurement yields that the\n\u221a computation is continued\n2, hence, the next state is\nwith\nprobability\n1.\nThe\ndashed\nedges\nleaving\nv\nare\nlabeled\nby\n1/\n1\n\u221a\n(1/ 2)(|v2 i + |v3 i). In the second step the computation again continues with probability 1 and\naccording to the labels of the edges leaving v2 and v3 the next state is |v6 i. Hence, in the third\nstep the computation stops with probability 1 and the result is 1.\nThe most important complexity measures for QBPs are the size of the QBP, i. e., its number of\nnodes, and the (expected or worst-case) computation time. QBPs may be cyclic or acyclic. For\nacyclic QBPs one can furthermore consider the width of the QBP, i. e., the maximum number\nof nodes with the same distance from the start node. Before we present our results on the\nrelationship between the complexity measures for QBPs and other complexity measures for\nboolean functions, in particular the space complexity of quantum Turing machines, we discuss\nprevious work on QBPs.\nAblayev, Gainutdinova, and Karpinski [1] and Nakanishi, Hamaguchi, and Kashiwabara [24]\nhave introduced quantum OBDDs (quantum ordered binary decision diagrams), i. e., acyclic\n2\n\n\fstart node\nx1 v1\n\u221a1\n2\n\nv2\n\nx2\n\n\u221a1\n2\n\n1\n\n\u221a1\n2\n\nv3\n\u2212 \u221a12\n\n1\n\nx2\n\n\u221a1\n2\n\n\u221a1\n2\n\nv5 0\n\n1\n\n\u221a1\n2\n\u221a1\n\nx1\n\nv4\n\n2\n\nv6 1\n\nFigure 1: An example of a QBP.\nQBPs where the input variables may only be read once in a fixed order during each computation. Ablayev, Gainutdinova, and Karpinski have presented a function that requires linear\nwidth in the input length for deterministic OBDDs, but only logarithmic width for quantum\nOBDDs. Nakanishi, Hamaguchi, and Kashiwabara have obtained a similar gap, but their lower\nbound even holds for randomized OBDDs. More recently, Ablayev, Moore, and Pollett [2] have\nproved that the class of functions that can be exactly computed by oblivious width-2 QBPs\nof polynomial size coincides with the class NC1 , while width 5 is necessary classically unless\nNC1 = ACC. Finally, \u0160palek [37] has studied a general model of QBPs and has independently\ncome up with a definition similar to that used here. Furthermore, he has also presented exact\nsimulations between QBPs whose transition function is composed of unitary matrices from a\nfinite basis and quantum Turing machines defined analogously. In the following, we describe\nthe contributions of our paper. For the sake of a clearer presentation, we group the results into\nthree parts.\nFirst Part: Simulations (Sections 2\u20135). In Sections 2 and 3 we define quantum branching programs and extend the definition of quantum Turing machines (QTMs) to the nonuniform case.\nFollowing Watrous [39, 40, 41], we include unidirectionality as a part of our definition of QBPs\nand we usually consider unidirectional nonuniform QTMs. Simulations between QBPs and unidirectional nonuniform QTMs are presented in Section 4. Our first result shows that unidirectional nonuniform QTMs using space O(log S) can be simulated by QBPs of size poly(S) taking\nthe same number of computation steps as the simulated machine. In the opposite direction,\nwe obtain an approximate simulation of QBPs of size S by unidirectional nonuniform QTMs\nthat carry out T simulation steps with approximation error \u03b5 in space poly(S + log log(T /\u03b5))\nand time poly(S, T, log(1/\u03b5)). These results are for QBPs and QTMs whose amplitudes are\narbitrary complex numbers.\nAs remarked above, the standard set of transition amplitudes for QTMs in the space-bounded\nscenario are algebraic numbers. As an analogous standard set for QBPs we propose short\namplitudes, i. e., amplitudes that can be represented in polynomial bit length in the size of the\nQBP as rational polynomials on finitely many algebraic numbers. Using our general simulation\nresults and additional insights about the connection between running time and the precision\nof amplitudes, we show that in the case of bounded and unbounded error, QBPs with short\namplitudes and size poly(S) and unidirectional nonuniform QTMs with algebraic amplitudes\nusing space O(log S) are of the same computational power.\nIn Section 5, we justify our standard assumption of unidirectionality for the considered models.\nWe provide a space-efficient approximate simulation of (general) nonuniform QTMs by unidirectional ones. In particular, this result yields that O(log S) space nonuniform QTMs, O(log S)\n3\n\n\fspace unidirectional nonuniform QTMs, and poly(S) size QBPs are of the same computational\npower if these models work with algebraic and short amplitudes, resp., and with bounded or unbounded error. Altogether, these arguments show that QBPs are a suitable model for exploring\nspace-bounded nonuniform quantum complexity.\nSecond Part: QOBDDs (Section 6). We explore the relationship between the size of quantum\nOBDDs (QOBDDs) and classical OBDDs. First, we design polynomial size QOBDDs for a\nfunction that classical deterministic OBDDs can only represent in exponential size, as well as\nfor a partially defined function for which even randomized OBDDs require exponential size.\nOn the other hand, even very simple functions can be hard for QOBDDs. We show that for\nthe disjointness function (x1 \u2228 x2 ) \u2227 (x3 \u2228 x4 ) \u2227 * * * \u2227 (xn\u22121 \u2228 xn ) as well as the inner product\nfunction x1 x2 \u2295 x3 x4 \u2295 * * * \u2295 xn\u22121 xn , QOBDDs require exponential size, while deterministic\nOBDDs can represent these functions in linear size. Finally, we prove that zero error QOBDDs\nof polynomial size are no more powerful than polynomial size reversible OBDDs.\nThird Part: QBPs with Generalized Measurements (Section 7). For quantum OBDDs as well\nas for quantum finite automata, the unitarity requirement of quantum algorithms is a serious\nrestriction. Intuitively, the problem is that it is difficult in these models to forget input already\nread. In Section 7 we study the question of whether it may help to allow measurements to choose\nthe unitary transformation for the next computation step (apart from checking whether the\ncomputation has stopped). For quantum circuits this question has already been considered by\nAharonov, Kitaev and Nisan [4], who have proposed to describe the states and the computations\nof quantum circuits by mixed states and superoperators, resp. We define natural variants of\nQBPs and QOBDDs with generalized measurements and investigate some of their properties.\nQBPs and QOBDDs with generalized measurements can simulate their randomized counterpart\nwithout increase in size. On the other hand, we prove an exponential lower bound on the size\nof QOBDDs with generalized measurements for all so-called k-stable functions. This class\nincludes, e. g., the function checking for the presence of a clique in a graph and the determinant\nof a boolean matrix.\n\n2. Quantum Branching Programs\nIn this section, we define classical and quantum variants of branching programs and discuss\nbasic properties of the quantum variant. An extensive survey of results for classical branching\nprograms is given in the monograph of Wegener [42].\nDefinition 2.1: A (deterministic) branching program (BP) on the variable set X = {x1 , . . . , xn }\nis a directed acyclic graph with a designated start node and two sinks. The sinks are labeled\nby the constants 0 and 1, resp. Each interior node is labeled by a variable from X and has\ntwo outgoing edges carrying labels 0 and 1, resp. This graph computes a boolean function f\ndefined on X as follows. To compute f (a) for some input a = (a1 , . . . , an ) \u2208 {0, 1}n , start at\nthe start node. For an interior node labeled by xi , follow the edge labeled by ai (this is called\ntesting the variable). Iterate this until a sink is reached, whose label gives the value f (a). For\na fixed input a, the sequence of nodes visited in this way is called the computation path for\na. The size |G| of a branching program is the number of its nodes. Its width is the maximum\nnumber of nodes with the same distance from the start node. The branching program size of a\nfunction f is the minimum size of a branching program that computes it.\n\n4\n\n\fBPs are a nonuniform model of computation, so we usually consider a sequence (Gn )n\u2208N of\nBPs representing a sequence of boolean functions (fn )n\u2208N , where Gn represents the function\nfn : {0, 1}n \u2192 {0, 1}. We will encounter the following variants of BPs.\nDefinition 2.2:\n\u2013 A BP is called read-once if, for each variable xi , each of the paths in the BP contains at\nmost one node labeled by xi .\n\u2013 A BP is called leveled if the set of its nodes can be partitioned into disjoint sets V1 , . . . , Vl ,\nwhere Vi is called the ith level, such that for 1 \u2264 i \u2264 l \u2212 1, each edge leaving a node in Vi\nreaches a node in Vi+1 .\n\u2013 An OBDD (ordered binary decision diagram) is a read-once BP where on each computation\npath the variables are tested according to the same order. For the variable order \u03c0 it is also\ncalled \u03c0-OBDD.\nDefinition 2.3: A randomized BP is defined as a deterministic BP, but may additionally\ncontain unlabeled randomized nodes with two unlabeled outgoing edges, may contain cycles,\nand may have sinks labeled by 0, 1, or \"?\". The computation for an input a is carried out\nby starting at the start node, following the outgoing edge labeled by ai for an xi -node as for\ndeterministic BPs, and taking one of the outgoing edges with probability 1/2 for randomized\nnodes until a sink is reached, where different randomized decisions are independent of each other.\nThe probability that the randomized BP computes the output r \u2208 {0, 1, ?} for the input a is\nthe probability that the computation for a reaches a sink labeled by r.\nDifferent modes of acceptance with unbounded, bounded (two-sided), one-sided, and zero error\nare defined as usual (see, e. g., [32, 42]). Randomized variants of the restricted models of BPs\nfrom Definition 2.2 are obtained by applying the respective restriction to the nodes labeled by\nvariables.\nNext, we define a quantum variant of BPs. This definition contains the alternative definitions\nin the literature as special cases.\nDefinition 2.4: A quantum branching program (QBP) over the variable set X = {x1 , . . . , xn } is\na directed multigraph G = (V, E) with a start node s \u2208 V , a set F \u2286 V of sinks, and (transition)\namplitudes \u03b4 : V \u00d7 V \u00d7 {0, 1} \u2192 C. Each node v \u2208 V \u2212 F is labeled by a variable xi \u2208 X and\nwe define var(v) = i. Each node v \u2208 F carries a label from {0, 1, ?}, denoted by label(v). Each\nedge (v, w) \u2208 E is labeled by a boolean constant b \u2208 {0, 1} and the amplitude \u03b4(v, w, b). An\nedge with boolean label b is called b-edge for short. We assume that there is at most one edge\ncarrying the same boolean label between a pair of nodes and set \u03b4(v, w, b) = 0 for all (v, w) 6\u2208 E\nand b \u2208 {0, 1}.\nThe graph G is required to satisfy the following two constraints. First, it has to be well-formed,\nmeaning that for each pair of nodes u, v \u2208 V \u2212 F and all assignments a = (a1 , . . . , an ) to the\nvariables in X,\n\u001a\nX\n1, if u = v; and\n(W)\n\u03b4\u2217 (u, w, avar(u) )\u03b4(v, w, avar(v) ) =\n0, otherwise.\nw\u2208V\n\nSecond, G has to be unidirectional, which means that for each w \u2208 V , all nodes v \u2208 V such\nthat \u03b4(v, w, b) 6= 0 for some b \u2208 {0, 1} are labeled by the same variable.\n\n5\n\n\fThe well-formedness constraint implies that the QBP has a unitary time evolution operator\n(see below) and is, therefore, motivated by the laws of quantum theory. Unidirectionality is a\nproperty that makes understanding and manipulating models of quantum computation much\neasier. We discuss this issue in more detail in Section 3. Since unidirectionality is crucial for\nour simulations, we include this requirement in the definitions of QBPs. Next, we define the\nsemantics of QBPs.\nDefinition 2.5 (Computation of a QBP): Let G = (V, E) be a QBP on n variables with\nstart node s \u2208 V , sinks F \u2286 V , and transition amplitudes \u03b4. Let H = C|V | and let (|vi)v\u2208V be\nan orthonormal basis of H. Let a = (a1 , . . . , an ) be an assignment to the variables of G. Let\nL(a) be the linear transformation from the subspace spanned by all |vi, v \u2208 V \u2212 F , into H such\nthat for v \u2208 V \u2212 F ,\nX\nL(a)|vi =\n\u03b4(v, w, avar(v) )|wi.\nw\u2208V\n\nDue to the well-formedness constraint (W), L(a) can be extended to a unitary transformation U (a) on H. Call U (a) a time evolution operator of the QBP for input a. Define projection\noperators on H by setting\nX\nX\nX\nEcont =\n|vihv|, Estop =\n|vihv|, and Er =\n|vihv|, for r \u2208 {0, 1, ?}.\nv\u2208V \u2212F\n\nv\u2208F\n\nv\u2208V, label(v)=r\n\nFor T \u2208 N0 and r \u2208 {0, 1, ?} define\npG, r (a, T ) =\n\nT\nX\nt=0\n\nEr (U (a)Econt )t |si\n\n2\n\nand\n\npG, r (a) = pG, r (a, \u221e),\n\nthe probability that G outputs r for input a during the first T time steps and the (absolute)\nprobability that G outputs r for input a, resp.\nQBPs computing a function f : {0, 1}n \u2192 {0, 1} with unbounded error, bounded (two-sided)\nerror, and one-sided error are defined in the straightforward way. We say that G computes f\nwith zero error and failure probability \u03b5, 0 \u2264 \u03b5 < 1, if pG, \u00acf (a) (a) = 0 and pG, ? (a) \u2264 \u03b5 for all\na \u2208 {0, 1}n . We say that G computes f exactly if it computes f with zero error and failure\nprobability 0.\nLet the (worst-case) running time of G on a be\nTG (a) = min{T | T \u2208 N0 \u222a {\u221e}, pG, 0 (a, T ) + pG, 1 (a, T ) + pG, ? (a, T ) = 1}.\nThe running time can be in\ndefined by\n\nN0 , infinite, or undefined.\n\nT G (a) =\n\n\u221e\nX\nt=0\n\nThe expected running time of G on a is\n2\n\nt * Estop (U (a)Econt )t |si .\n\nWe say that G runs in time T if TG (a) \u2264 T for all a \u2208 {0, 1}n . Furthermore, G runs in expected\ntime T if T G (a) \u2264 T for all a \u2208 {0, 1}n .\nSince the QBP does not have edges leaving the sinks, the time evolution operator is merely an\nextension of the mapping L(a) and, therefore, not necessarily uniquely determined.\nIn the remainder of this section we discuss the relationship between (classical) BPs and QBPs,\nand some variants of the definition of QBPs. Because of the well-formedness and the unidirectionality requirements of QBPs it is not obvious whether functions with small size BPs also have\nsmall size QBPs. In order to prove such a statement, we introduce the notion of reversibility.\n6\n\n\fDefinition 2.6: A BP is reversible if each node is reachable from at most one node v by a\n0-edge and from at most one node w by a 1-edge and v and w are labeled by the same variable.\nReversible BPs are obviously special QBPs. Furthermore, as proved by \u0160palek [37] using a\nsimilar construction of Lange, McKenzie, and Tapp [23] for Turing machines, any (possibly\nnon-reversible) BP of size s(n) = \u03a9(n) can efficiently be simulated by a reversible one of\nsize poly(s(n)). This implies:\nProposition 2.7 ([37]): If the sequence of functions (fn )n\u2208N has BPs (Gn )n\u2208N of size s(n) =\n\u03a9(n), it also has QBPs (G\u2032n )n\u2208N of size poly(s(n)).\nAdleman, DeMarrais, and Huang [3] have shown that uniform QTMs with arbitrary complex\namplitudes can decide certain languages of arbitrarily high Turing degree in polynomial time\nand are thus too powerful to be realistic. For randomized classical as well as quantum models of\ncomputation, practical considerations (depending on the details of the physical implementation\nof the model) lead to restrictions on the set of allowed amplitudes. However it is not obvious\nwhat a natural restriction in the nonuniform, space-bounded scenario is. The following definition\nis motivated by the goal of finding the least restrictive definition that still allows the resulting\nQBPs to be simulated efficiently by the corresponding standard QTM model. Recall that an\nalgebraic number (over Q) is an x \u2208 C such that there is a rational polynomial with root x.\n\nDefinition 2.8: A sequence (Gn )n\u2208N of QBPs has short amplitudes if for some number k\nindependent from the input length there are algebraic numbers \u03b11 , . . . , \u03b1k , such that each\namplitude of each Gn can be written as p(\u03b11 , . . . , \u03b1k ) for some k-variate rational polynomial p\nof degree poly(|Gn |) whose coefficients are fractions with numerator and denominator each of\nbit length at most poly(|Gn |).\nThe requirements of this definition are obviously satisfied in the special case that the sequence\nof QBPs uses only amplitudes from a fixed, finite set of algebraic numbers. This is the situation\ninvestigated for uniform, space-restricted QTMs by Watrous [40, 41]. Among other results, we\nshow in Section 4 that unidirectional nonuniform QTMs with algebraic amplitudes and QBPs\nwith short amplitudes are equivalent in computational power under space restrictions, which\nserves as a motivation for the above definition.\nWe conclude the discussion on reasonable restrictions for the amplitudes with some simple observations. First, QBPs with complex amplitudes can be transformed into equivalent QBPs\nwith real amplitudes, where the number of nodes increases by a factor of at most 2 (cf. Proposition 5.3 in [41]). The main idea is to replace each node v with two nodes vr and vi such that\nthe corresponding vectors |vr i and |vi i carry the real and imaginary part of the amplitude of\n|vi, resp. Second, in Definition 2.8 the number k of algebraic numbers can be replaced with\n1, since by the primitive element theorem from algebra, the algebraic numbers \u03b11 , . . . , \u03b1k can\nbe represented as polynomials in a single algebraic number \u03b1. Since k as well as \u03b11 , . . . , \u03b1k\nare independent from the input size, these polynomials have a constant number of constant\ncoefficients such that the resulting QBP still has short amplitudes. Finally, since the bit lengths\nof the denominators of all coefficients are bounded by poly(|Gn |) and the numbers of edges and,\ntherefore, the number of denominators is bounded by 2|Gn |2 , all the coefficients have a common\ndenominator m of bit length poly(|Gn |). We obtain the following result.\n\nProposition 2.9: Each sequence (Gn )n\u2208N of QBPs with short amplitudes can be simulated by\na sequence (G\u2032n )n\u2208N of QBPs with |G\u2032n | \u2264 2|Gn | such that there is a single algebraic number\n\u2032\n\u03b1 and a number m = 2poly(|Gn |) such that each amplitude of G\u2032n can be written as p(\u03b1)/m for\nan integer polynomial p with a degree bounded by poly(|G\u2032n |) and coefficients bounded above in\n\u2032\nabsolute value by 2poly(|Gn |) .\n7\n\n\fAs for classical BPs, it is possible to simplify the structure of QBPs without increasing their\nsize too much. The following has been observed by \u0160palek [37].\nProposition 2.10 ([37]): Let G be a QBP and let t \u2208 N0 . Then there is a leveled QBP G\u2032\nwith t + 1 levels that for each input a computes an output r \u2208 {0, 1, ?} with probability pG,r (a, t)\nafter carrying out exactly t computation steps and that does not stop before. The size of G\u2032 is\nbounded above by (t + 1)2 |G|.\nFor the construction of QBPs, it is convenient to allow unlabeled nodes with an arbitrary number\nof outgoing edges carrying only amplitude labels. An unlabeled node v can be understood as an\nabbreviation for a node that is labeled by some input variable, where the value of this variable\ndoes not influence the computation. This means that each edge leading from the unlabeled\nnode v to w has to be replaced with a 0-edge and a 1-edge from v to w which both have the\nsame amplitude label as the original edge from v to w. When using unlabeled nodes we have to\nmake sure that the QBP resulting from this transformation is unidirectional and well-formed.\n\n3. Definitions and Tools for Quantum Turing Machines\nWe first introduce a nonuniform variant of quantum Turing machines (QTMs). The definition is similar to those of Bernstein and Vazirani [11] and Nishimura and Ozawa [27] for the\nuniform setting. Afterwards, we collect tools for approximately performing arbitrary unitary\ntransformations by QTMs.\nDefinition 3.1: A nonuniform (or advice-taking) quantum Turing machine is a QTM M =\n(Q, \u03a3, \u03b4) together with an advice function adv : N \u2192 \u03a3\u2217 , where Q is a finite set containing q0 , qf\nand \u03a3 = \u03a31 \u00d7 * * * \u00d7 \u03a3k with finite sets \u03a31 , . . . , \u03a3k each containing {0, 1, ?, B}. The QTM M\nhas the initial state q0 and the unique final state qf , and \"B\" is used as the blank symbol. The\nmachine is equipped with three tapes, a read-only input tape, a read-only advice tape, and the\nwork tape. All tapes are two-way infinite and indexed by Z and each is split into k separate tracks\nthat may contain symbols from \u03a31\u0001, . . . , \u03a3k . We have \u03b4 : (Q\u00d7\u03a33 )\u00d7(Q\u00d7\u03a3\u00d7{\u22121, 0, 1}3 ) \u2192 C, and\n\u2032 , d , d , d ) is the amplitude for a transition from state q, with symbols\n\u03b4 (q, \u03c3i , \u03c3a , \u03c3w ), (q \u2032 , \u03c3w\ni a w\n\u2032 on the work tape\n\u03c3i , \u03c3a , \u03c3w on the input, advice, and work tape, resp., to state q \u2032 , writing \u03c3w\nand moving the heads on the three tapes according to di , da , dw . Upon start of the machine, the\ninput tape is loaded with the input string x \u2208 {0, 1}\u2217 at positions 0, . . . , |x| \u2212 1 of the first track.\nThe advice tape is loaded with the advice string adv(|x|) \u2208 \u03a3\u2217 at positions 0, . . . , | adv(|x|)| \u2212 1.\nAll other tape positions contain blanks, all heads are at position 0 and the finite control of M\nis in its initial state. A configuration of M is a tuple (q, w, i, j, k), with the current state of the\nfinite control q \u2208 Q, the contents w \u2208 \u03a3\u2217 of the work tape, and the positions i, j, k \u2208 Z of the\nheads on the input, advice, and work tape, resp. Let Cn (M ) be the set of all configurations of M\nfor inputs of length n. Let H = C|Cn (M )| be the Hilbert space spanned by all configurations from\nCn (M ), which we identify with vectors from an orthonormal basis. The time evolution operator\nU (a) describes the application of the transition function \u03b4 to a superposition of configurations,\nwhere the input is a. The well-formedness constraint requires U (a) to be unitary for all inputs\na.\nDefinition 3.2 (Computation of a nonuniform QTM): Let M = (Q, \u03a3, \u03b4) be as in the\nabove definition. A QTM indicates stopping by entering qf and signals its output by an entry\nat position 0, called the output cell, of a designated track of the work tape, called the output\ntrack. Define Estate (A) as the projection operator over H onto the subspace spanned by all\nconfigurations with state in A \u2286 Q. Then the projections Estate ({qf }), Estate (Q\u2212{qf }) describe\n8\n\n\fthe measurement checking whether the current state is equal to qf . This measurement is\nperformed before each computation step. If the QTM does not stop, U (a) is applied to the\nstate after the measurement. Let Eresult (r), r \u2208 {0, 1, ?}, be the projection onto the subspace\nspanned by the configurations with result r in the output cell. If stopping of the QTM has\nbeen detected, the measurement described by these latter projections is carried out in order to\ndetermine the result of the computation. For T \u2208 N0 and r \u2208 {0, 1, ?}, let\npM, r (a, T ) =\n\nT\nX\nt=0\n\nEresult (r)Estate ({qf })(U (a)Estate (Q \u2212 {qf }))t |si\n\n2\n\nbe the probability that M outputs r on input a during the first T computation steps. Based\non these probabilities, acceptance of the QTM with different types of error is defined as usual.\nThe (expected) running time of M on a, denoted by TM (a) (T M (a)), is defined analogously to\nQBPs (Definition 2.5). The space used by M on input a \u2208 {0, 1}\u2217 is the maximum number\nof cells on the work tape between the leftmost and rightmost non-blank symbol taken over all\nconfigurations which are reached with nonzero amplitude during the computation on input a and\nin which the machine has not yet halted. The (total) space sM (a) used by M on input a \u2208 {0, 1}\u2217\nis defined as the sum of the space on the work tape and \u2308log | adv(|a|)|\u2309. Finally, we say that\nM runs in space s : N \u2192 N0 if for all a \u2208 {0, 1}n , sM (a) \u2264 s(n).\nDefinition 3.3: A reversible Turing machine (RTM) is a deterministic TM where each configuration has at most one predecessor. A TM or QTM M is called unidirectional if each state can\nbe entered from only one direction on each tape, i. e.,\u0001 if there are functions Di , Da , Dw : Q \u2192\n\u2032 , d , d , d ) 6= 0 only if D (q \u2032 ) = d , D (q \u2032 ) = d and\n{\u22121, 0, 1} such that \u03b4 (q, \u03c3i , \u03c3a , \u03c3w ), (q \u2032 , \u03c3w\ni a w\ni\ni\na\na\n\u2032\nDw (q ) = dw .\nUnidirectionality is a crucial property of QTMs that makes working with them much easier.\nThe property has first been investigated by Bernstein and Vazirani [11] for single-tape QTMs\nthat are additionally two-way, i. e., are required to move their head in each computation step.\nTheir results include that single-tape RTMs (even with stationary tape heads allowed) are\nautomatically unidirectional and, furthermore, that single-tape two-way QTMs can be simulated\ntime and space efficiently by unidirectional ones. Furthermore, it is well known that also QTMs\nwith stationary tape heads allowed can be time efficiently simulated by unidirectional ones using\nthe simulations of QTMs by quantum circuits and vice versa due to Yao [43] and Nishimura\nand Ozawa [27]. These results cannot be applied in an obvious way in the space-bounded\nscenario. Already for TMs with only one additional input tape, reversibility does no longer\nimply unidirectionality, as simple examples show. In Section 5 we show that general nonuniform\nQTMs with sublinear space can be space efficiently simulated by unidirectional ones.\nFor constructing unidirectional nonuniform QTMs, we need the usual toolbox of programming\nprimitives that allows us to work with multiple tracks, combine TMs, construct looping TMs and\nso on. We use appropriate versions of lemmas for these tasks due to Bernstein and Vazirani [11].\nWe only remark that, by going through their proofs, it is straightforward to extend these lemmas\nto unidirectional RTMs and unidirectional QTMs, resp., with an arbitrary number of read-only\ninput tapes. This includes nonuniform machines as a special case.\nIn simulations of other models of quantum computation by QTMs, we face the problem of\ncarrying out an arbitrary given unitary transformation over a finite-dimensional Hilbert space\nusing only a finite program for the QTM. For doing this, we use a result due to Harrow,\nRecht, and Chuang [14] that allows us to approximate any unitary operator over a finite-dimensional Hilbert space by a product of \"few\" elements from a finite collection of \"simple\"\n9\n\n\funitary transformations. The approximation is with respect to the operator norm, defined for\nan operator A over a Hilbert space H by kAk = sup{kAxk | x \u2208 H, kxk \u2264 1}. We say that A\u2032\nis an \u03b5-approximation of A or approximates A with error \u03b5 if kA\u2032 \u2212 Ak \u2264 \u03b5.\nDefine the unitary matrices\n\u0013\n\u0012\n\u221a \u0013\n\u0012\n\u0012\n\u221a\n\u0013\n1\n1\n1 1 + 2 \u22121\n1\n2\n1\n2\n\u2212\n1\n0\n\u221a\n\u221a\n, V2 = \u221a\n.\nV1 = \u221a\n, and V3 = \u221a\n1\n0\n1 \u2212 2 \u22121\n5 2 \u22121\n5 \u22122 1\n5\n\nFor i \u2208 {1, 2, 3} let Vi+3 = Vi\u22121 . Let G2 = {V1 , . . . , V6 }. For i \u2208 {1, . . . , 6} and j \u2208 {1, . . . , d \u2212 1}\ndefine the unitary d \u00d7 d-matrix Wi,j by setting\n\uf8f1\n\uf8f4\n\uf8f2(Vi )1,1 |ji + (Vi )2,1 |j + 1i, if k = j;\nWi,j |ki = (Vi )1,2 |ji + (Vi )2,2 |j + 1i, if k = j + 1;\n\uf8f4\n\uf8f3\n|ki,\notherwise.\n\nLet Gd be the set of all Wi,j with i \u2208 {1, . . . , 6} and j \u2208 {1, . . . , d \u2212 1}. Recall that SU(d)\ndenotes the set of all unitary d \u00d7 d-matrices. Harrow, Recht, and Chuang [14] have proved the\nfollowing lemma, where we have added the estimate of the bound for k depending on d, while\nin [14] the dimension is regarded as a constant.\nLemma 3.4 ([14]): There is a constant c > 0 such that for all \u03b5 > 0, U \u2208 SU(d), and\nk = \u2308cd2 log(d/\u03b5)\u2309, there are U1 , . . . , Uk \u2208 Gd such that kU \u2212 U1 * * * Uk k \u2264 \u03b5.\nCall the matrices Wi,j with i \u2208 {1, . . . , 6} and j \u2208 {1, . . . , d \u2212 1} elementary. Let d = 2m\nand let |\u03c8i \u2208 Cd be encoded in m = log d qubits on the work tape of a QTM. Given i, j\nas additional inputs, we would like to compute Wi,j |\u03c8i, as required for the application of\nLemma 3.4. Bernstein and Vazirani [11] have shown how to implement this for a different\nset of two-dimensional transformations. By an easy adaptation of their construction and an\napplication of the simulation of single-tape two-way QTMs by unidirectional ones also from\ntheir paper, we obtain:\nLemma 3.5 ([11]): There is a unidirectional single-tape QTM Melem with multiple tracks that\nworks as follows. Let d = 2m and let |\u03c8i \u2208 Cd be a superposition of m qubits. Let c(i, j) consist\nof the binary codes of i \u2208 {1, . . . , 6} and j \u2208 {1, . . . , d \u2212 1}. Started with |\u03c8i in tape cells\n0, . . . , m \u2212 1 of the first track and |c(i, j)i in the tape cells 0, . . . , |c(i, j)| \u2212 1 of the second track,\nMelem computes the output Wi,j |\u03c8i on the first track, replacing |\u03c8i, in time and space O(m).\nFurthermore, the running time of Melem only depends on m, the length of the contents on the\nfirst track.\nCombining Lemmas 3.4 and 3.5, we can use a QTM to compute a good approximation of any\ndesired finite-dimensional unitary transformation. We still have to make sure that measuring\nthe state after applying the approximate transformation gives a result that agrees with that\nafter applying the original transformation with high probability. This can be shown using the\nfollowing statements. The first one is due to Bernstein and Vazirani [11], the proof of second\none is analogous to that of a similar statement in [26], page 195.\nProposition 3.6: Let U , U1 , . . . , Un , and V1 , . . . , Vn be operators over a Hilbert space H with\nkUi k, kVi k \u2264 1 and kUi \u2212 Vi k \u2264 \u03b5i for i = 1, . . . , n. Then kU1 * * * Un \u2212 V1 * * * Vn k \u2264 \u03b51 + * * * + \u03b5n .\n\nLemma 3.7: Let \u03b5 > 0 and t \u2208 N. Let U and U \u2032 be unitary operators over a Hilbert space H\nwith kU \u2212 U \u2032 k \u2264 \u03b5. Let P, Q be projections over H. Let |vi \u2208 H with k|vik = 1. Define\np = kQ(U P )t |vik2 and p\u2032 = kQ(U \u2032 P )t |vik2 . Then |p \u2212 p\u2032 | \u2264 2t\u03b5.\n10\n\n\f4. Equivalence of QBPs and Space-Bounded Unidirectional Nonuniform QTMs\nWe prove our simulation results for QBPs and unidirectional nonuniform QTMs. We first\nprovide a basic theorem that allows a step-by-step simulation of unidirectional nonuniform\nQTMs by QBPs and vice versa. Each step of a QBP can only be done approximately by a\nunidirectional nonuniform QTM. In order to control the total error, we have to specify the\nnumber of simulation steps in advance. This raises the problem of bounding the computation\ntime of space-bounded algorithms that is studied afterwards. We first define a suitable notion\nof simulations.\nDefinition 4.1: Let M1 , M2 be nonuniform QTMs or QBPs. As defined in Sections 2 and 3, let\npMi ,r (a, T ) be the probability that Mi computes the output r on the input a during the first T\ncomputation steps. We say that M1 simulates T steps of M2 in T \u2032 steps with accuracy \u03b5 \u2265 0, if\nfor all a \u2208 {0, 1}\u2217 and r \u2208 {0, 1, ?}: |pM1 , r (a, T \u2032 ) \u2212 pM2 , r (a, T )| \u2264 \u03b5. We say that M1 simulates\nM2 if M1 simulates T steps of M2 in the same number of steps with accuracy \u03b5 = 0 for\narbitrary T .\n4.1. Basic Step-by-Step Simulations\nTheorem 4.2:\n(i) Let M be a unidirectional nonuniform QTM that runs in space S(n) = \u03a9(log n). Then\nthere is a sequence of QBPs (Gn )n\u2208N with |Gn | = 2O(S(n)) that simulate M .\n\n(ii) Let (Gn )n\u2208N be a sequence of QBPs with |Gn | = \u03a9(n). Let \u03b5 : N \u2192 (0, 1) and T : N \u2192 N0 .\nThen there is a unidirectional nonuniform QTM that for each n \u2208 N simulates T (n)\nsteps of Gn in poly(|Gn |, T (n), log(1/\u03b5(n))) steps with accuracy \u03b5(n) and runs in space\nO(log |Gn | + log log(T (n)/\u03b5(n))).\nWe discuss the consequences of this theorem for the motivation of our QBP model and the\nrelationship between QBPs and QTMs in detail in Section 4.2.\nProof of Theorem 4.2, Part (i). This follows by an easy adaptation of the proof of the analogous\nresult for classical BPs and TMs. Let M = (Q, \u03a3, \u03b4) be a unidirectional nonuniform QTM with\nadvice function adv : N \u2192 \u03a3\u2217 that runs in space S(n) = \u03a9(log n). We ensure that the heads on\nthe input and advice tape stay in the area consisting of the non-blank cells (see [38] for details).\nThen M has at most 2O(S(n)) configurations.\nWe construct the QBP G over the variable set X = {x0 , . . . , xn\u22121 } with Cn (M ) as its node\nset. For a configuration c \u2208 Cn (M ) of M where the head on the input tape is at position i \u2208\n{0, . . . , n \u2212 1}, define var(c) = i in G (recall that var(c) denotes the index of the variable with\nwhich a QBP node is labeled). For an input with bit b \u2208 {0, 1} at position i on the input tape\nof M , let the application of the transition function \u03b4 of M to |ci yield the superposition\nX\n\u03b1(c, c\u2032 , b)|c\u2032 i, \u03b1(c, c\u2032 , b) \u2208 C.\nc\u2032 \u2208Cn (M )\n\nFor each \u03b1(c, c\u2032 , b) 6= 0, we add a b-edge from c to c\u2032 in G and use \u03b1(c, c\u2032 , b) as the amplitude\nlabel of this edge. We define the start node of G as the initial configuration of M and identify\nthe set of final nodes F with the set of final configurations of M .\n\n11\n\n\fThe graph G defined above fulfills the well-formedness requirement of QBPs since the time\nevolution operator of the QTM M is unitary. In order to prove that G is unidirectional assume\nfor a contradiction that the node v has predecessors v1 and v2 labeled by different variables.\nThen during the transitions of M that correspond to the transition of v1 to v and v2 to v the\nhead on the input tape makes different moves in contradiction to the unidirectionality of M .\nSince |Cn (M )| = 2O(S(n)) , the branching program is of the required size. It is easy to verify that\nG simulates M because of the similarity of the definitions of the semantics for the two models.\n\u0003\nProof of Theorem 4.2, Part (ii). Let G be the QBP to be simulated and let X = {x0 , . . . , xn\u22121 }\nbe the variable set of G. In a first step, we show how to transform G into an equivalent QBP\nG\u2032 which has the additional property that all nodes that are reachable from the start node\nby a path of length t are labeled by xt mod n . This allows us to decompose the time evolution\noperator into n factors where each factor only depends on the value of one of the variables. In\na second step we construct a nonuniform QTM and its advice string from the decomposed time\nevolution operator of G\u2032 and prove the claims on the resources required by this QTM.\nLet G = (V, E) and let s and F denote the start node and the set of sinks of G, resp. Due to the\nunidirectionality of G, all predecessors of a node v \u2208 V are labeled by the same variable, whose\nindex is denoted by pre(v). If the start node does not have any predecessor, let pre(s) = n \u2212 1.\nFurthermore, we set var(v) = 0 for v \u2208 F .\n\n\u2032\n\u2032\n\u2032\n\u2032\nWe\n\b construct the QBP G = (V , E ) from G by adding \u2032 dummy nodes. Let V =\n(v, i) v \u2208 V, i \u2208 {pre(v) + 1, . . . , n \u2212 1, 0, . . . , var(v)} . Let s = (s, 0) be the start node\nof G\u2032 and let F \u2032 = {(v, 0) | v \u2208 F } be its set of sinks. Define var(v, i) = i for all\nv \u2208 V and label(v, 0) = label(v) for all v \u2208 F . For each (v, w) \u2208 E, add an edge\n((v, var(v)), (w, (pre(w) + 1) mod n)) to E \u2032 that inherits all labels of the edge (v, w). Furthermore, for each w \u2208 V , i \u2208 {pre(w) + 1, . . . , n \u2212 1, 0, . . . , var(w) \u2212 1}, and b \u2208 {0, 1}, add an\nedge ((w, i), (w, (i + 1) mod n)) to E \u2032 with boolean label b and amplitude 1. Let \u03b4\u2032 be the transition amplitudes of G\u2032 defined in this way. It is easy to see that G\u2032 is a QBP. Well-formedness\nand unidirectionality of G\u2032 follow from the respective properties of G for the subgraph induced\nby the nodes in {(v, var(v)), (v, (pre(v) + 1) mod n) | v \u2208 V } and are obvious for the rest of the\ngraph. It is easy to see that |G\u2032 | = O(n|G|).\n\nClaim. G\u2032 simulates T steps of G in nT steps with accuracy 0. Furthermore, there are unitary\noperators Ui (b) with 0 \u2264 i \u2264 n \u2212 1 and b \u2208 {0, 1} such that for any time evolution operator U \u2032 (a)\n\u2032\nof G\u2032 with a \u2208 {0, 1}n , the projection Econt\nto the space spanned by the non-sink nodes of G\u2032 , the\n\u0001T \u2032\n\u2032\n\u2032\n)nT |s\u2032 i = (Un\u22121 (an\u22121 ) * * * * * U0 (a0 ))Econt\n|s i.\nstart node s\u2032 of G\u2032 , and any T \u2208 N0 , (U \u2032 (a)Econt\nProof of the claim. For the proof that G\u2032 simulates T steps of G with nT of its own steps,\nlet \u03c6 be the linear embedding of the superpositions of G into those of G\u2032 induced by setting\n\u03c6(|vi) = |(v, 0)i for v \u2208 V . Let U (a) and U \u2032 (a) be time evolution operators of G and G\u2032 ,\n\u2032\n, Er\u2032 be the projections to the spaces\nresp., for the input a \u2208 {0, 1}n . Let Econt , Er and Econt\nspanned by the non-sink nodes and nodes with output label r, resp., for the graphs G and G\u0001\u2032 ,\n\u2032\n)nT |s\u2032 i = \u03c6 (U (a)Econt )T |si .\nresp. An easy induction shows that for each T \u2208 N0 , (U \u2032 (a)Econt\n\u2032\nFurthermore, Er \u03c6(|vi) = \u03c6(Er |vi) for all v \u2208 V . Hence, pG\u2032 ,r (a, nT ) = pG,r (a, T ) for all T \u2208 N0\nand G\u2032 simulates T steps of G with nT steps.\n\nFurthermore, it is also easy to prove by induction that for any T \u2208 N0 , i = T mod n, and\n\u2032\n\u2032\n\u2032\nany v \u2208 V \u2032 \u2212 F \u2032 with var(v) 6= i, hv|Econt\n(U \u2032 (a)Econt\n)T |s\u2032 i = hv|(U \u2032 (a)Econt\n)T |s\u2032 i = 0. Hence,\ninstead of applying U \u2032 (a) in the (T + 1)-st computation\nstep, we may apply a unitary extension\nP\n\u2032 (v, w, a )|wi for v \u2208 V \u2032 with var(v) = i,\n\u03b4\nUi (ai ) of the mapping defined by |vi 7\u2192\n\u2032\ni\nw\u2208V\n12\n\n\fwithout changing the computed superposition. Finally, for all v \u2208 F \u2032 and T mod n 6= 0, we have\n\u2032\n\u2032\n)nT |s\u2032 i =\n)T | s\u2032 i = 0. By induction, it follows that for any T \u2208 N0 , (U \u2032 (a)Econt\nhv | (U \u2032 (a)Econt\n\u0001\nT\n\u2032\n(Un\u22121 (an\u22121 ) * * * * * U0 (a0 ))Econt\n|s\u2032 i, as claimed.\n\u0003\nNow we describe the second step of the proof, the construction of the QTM from G\u2032 . Let\ns = O(n|G|) be the number of nodes of G\u2032 . Let m = \u2308log s\u2309. It is convenient to assume that\nthe node numbers have the length m + 2, where the numbers of interior nodes begin with 00\nand the numbers of 0- and 1-sinks with 01 and 11, resp. Furthermore, we assume that the start\nnode has the number 0.\n\nConstruction of the advice string. First, we define approximate representations for each matrix\nUi (b), 0 \u2264 i \u2264 n \u2212 1 and b \u2208 {0, 1}, as a list of elementary matrices using Lemma 3.4. Choosing\n\u03b5\u2032 = \u03b5/(2nT 2 ) as the error bound and s as the dimension of the Hilbert space, Lemma 3.4\nyields s \u00d7 s-matrices Ui,0 (b), . . . , Ui,k\u22121 (b) whose product is an \u03b5\u2032 -approximation of Ui (b), where\nk = O(s2 log(s/\u03b5\u2032 )) = O(s2 log(nsT /\u03b5)) is the number of matrices obtained from the lemma.\nObserve that the number of elementary matrices in the representation of Ui (b) is the same for all\ni and b. Elementary matrices are encoded such that the corresponding unitary transformations\ncan be applied using the QTM provided in Lemma 3.5. The code for an elementary matrix\nWj,j \u2032 consists of the binary codes of j \u2208 {1, . . . , 6} and j \u2032 \u2208 {1, . . . , s \u2212 1}.\nOn the advice tape, we store the codes of the elementary matrices Ui,l (b) for 0 \u2264 i \u2264 n \u2212 1,\nb \u2208 {0, 1}, and l \u2208 {0, . . . , k \u2212 1}, as well as some additional administrative information. The\ninformation is organized using four tracks, where the non-blank part of each track starts at\nposition 0:\nTrack 1: Binary code of the input length n.\nTrack 2: Binary code of k.\nTrack 3: Binary code of the length of the code for an elementary matrix.\nTrack 4: List of codes for all Ui,l (b).\nThe length of the code of each elementary matrix is O(log s). Each of the 2n matrices Ui (0) and\nUi (1) is encoded using O(k log s) bits. We have k = O(s2 log(nsT /\u03b5)). Hence, the length of the\ninformation on track 4 is bounded by O(2n * k log s) = poly(s, log(T /\u03b5)), which is also a bound\non the overall length of the advice string. The logarithm of this, O(log s + log log(T /\u03b5)) =\nO(log |G| + log log(T /\u03b5)), is the contribution of the advice tape to the space.\nConstruction of the QTM. The QTM uses the following tracks on the work tape:\nTrack 1: Output track. The output of the QTM is in cell 0 of this track upon termination.\nTrack 2: Node register consisting of m + 2 cells that contains the current superposition of node\nnumbers of G\u2032 .\nTrack 3: Buffer for the code of Ui,l (xi ).\nTrack 4: Counter i with values in {0, . . . , n \u2212 1}.\n\nTrack 5: Counter l with values in {0, . . . , k \u2212 1}.\n\nTrack 6: Buffer for the value of the current input bit.\nTrack 7: Buffer for the position of the currently applied Ui,l (xi ) on the advice tape.\n\nInitially, the work tape only contains blanks. By choosing an appropriate encoding of binary\nnumbers (see, e. g., [39]), we ensure that a string of blanks represents the number 0. Hence, the\ncounters on track 4 and track 5 are initialized with 0. Since the start node has the number 0,\nthe blanks from the initialization of the node register encode the start node.\n13\n\n\f1. Forever do\n2.\nTermination check. Swap the contents of cell 0 of the node register (signaling\nthe output if the current node is a sink) and the output cell. If cell 1 of the\nnode register contains a 1 (signaling a sink), enter qf . Otherwise, swap again the\ncontents of cell 0 of the node register and the output cell.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n\nFor i := 0 to n \u2212 1 do\nXOR track 6 with the value of xi .\nFor l := 0 to k \u2212 1 do\nXOR track 7 with the position of the code of Ui,l (xi ) on the advice tape.\nXOR track 3 with the code of Ui,l (xi ) from the advice tape.\nApply Ui,l (xi ) to the node register.\nRepeat step 7; this erases track 3.\nRepeat step 6; this erases track 7.\nRepeat step 4; this erases track 6.\nFigure 2: Algorithm for the nonuniform QTM simulating G\u2032 .\n\nThe algorithm performed by the QTM is shown in Figure 2. The algorithm consists of an\ninfinite loop whose body, steps 2\u201311, simulates one computation step of the QBP G\u2032 . The loop\nis left and the algorithm terminates in step 2 if a sink has been reached. We only bother to\nsimulate the first nT computation steps of G\u2032 and thus the first T computation steps of G with\nsufficient accuracy. In the following, we describe how this algorithm is implemented.\nWe construct unidirectional RTMs for steps 2, 4, 6, and 7 with the following additional properties. We ensure that these machines only use the space already allotted on the work tape,\nthat the time can be bounded by O(1) and O(n) for step 2 and 4, resp., and by a polynomial\nin the length of the advice tape, i. e., poly(s, log(T /\u03b5)), for steps 6 and 7. For step 2, we additionally take care that the running time only depends on the length of the node register, but\nnot on the actual contents of the node register. It is not hard to construct these machines from\nscratch. Furthermore, Lemma 3.5 yields a unidirectional QTM for step 8 that has space and\nrunning time bounded by the length of the node register, i. e., O(log s) and whose running time\nis independent of the actual contents of the node register.\nFor constructing the final QTM from these basic RTMs, we apply appropriate versions of the\nlemmas of Bernstein and Vazirani [11] for dealing with unidirectional nonuniform RTMs and\nunidirectional nonuniform QTMs. The finite loops are realized as described by Watrous [39]. At\nthe beginning of a loop, we check a starting/stopping condition for the loop and switch the state\nof being outside or inside the loop, resp., when this condition is met. For the loops beginning\nin step 3 and 5, we use counters modulo n and k, resp., and check as the starting/stopping\ncondition whether the counter is equal to zero.\nUsing these tools, we first combine the machines for the steps 4 and 6\u201311, implementing the\nloops in step 3 and 5 as described above, to get a QTM M3\u201311 for steps 3\u201311. The outermost,\nendless loop is then realized by modifying the RTM for step 2. We use a simple unidirectional\nRTM constructed from scratch that carries out the described termination check, enters two\nspecial states as placeholders depending on the value of cell 1 of the node register, and then\nrestarts its computation. We insert M3\u201311 into the state for the value 0 of cell 1 (non-sink) and\nreplace the state for the value 1 (sink) with the final state qf of the whole QTM. This yields\nthe desired QTM for simulating G\u2032 and thus G.\n14\n\n\fWe note that a space-bounded RTM performing an infinite loop cannot carry out initialization\nsteps before the loop. By our choice of the encoding of the contents of the tracks, we do not\nneed such an initialization. Furthermore, we have ensured that the running time for the body of\nthe outermost loop is the same for all possible classical inscriptions in the node register. Hence,\neven if the simulated QBP is in a superposition, step 2 is always reached simultaneously for all\nnodes in the superposition.\nSpace and time requirements. The space on tracks 1\u20136 of the work tape is obviously bounded\nby O(1), O(log s), O(log s), O(log n), O(log k) = O(log s + log log(T /\u03b5)), and O(1), resp. The\nspace on track 7 is bounded above by the logarithm of the length of the advice string, which\nis O(log s + log log(T /\u03b5)) as computed above. Since this is also the contribution of the advice\nstring to the space, the overall space complexity is of the same order. We can estimate the\nrunning time for simulating one computation step of G\u2032 (steps 2\u201311 of the algorithm) as follows.\nThe running time of steps 4 and 11 is O(n). The running time of steps 6, 7, 9, and 10 is\ndominated by the length of the advice tape, which is of order poly(s, log(T /\u03b5)). Step 8 can be\nperformed in time proportional to the length of the node register, i. e., O(log s). Hence, also\nthe overall time for one computation step is of order poly(s, log(T /\u03b5)) = poly(|G|, log(T /\u03b5)).\nCorrectness. Let us assume for a moment that the product Ui,k\u22121 (xi ) * * * Ui,0 (xi ) equals Ui (xi ).\nThen it is easy to see that steps 4\u201310 exactly apply Ui (xi ) and that steps 3\u201311 exactly apply\nUn\u22121 (xn\u22121 ) * * * U0 (x0 ) to the node register. Together with the termination check in step 2\n\u2032\nto the non-sink nodes of G\u2032 , steps 2\u201311 exactly apply\nwhich realizes the projection Econt\n\u2032\nUn\u22121 (xn\u22121 ) * * * U0 (x0 )Econt\nto the node register if the QTM does not stop. Due to the above\nclaim, we know that this simulates n successive computation steps of G\u2032 and thus one computation step of the original QBP G.\nHowever, the product Ui,k\u22121 (xi ) * * * Ui,0 (xi ) is merely an \u03b5\u2032 -approximation of Ui (xi ), where\n\u03b5\u2032 = \u03b5/(2nT 2 ). By Proposition 3.6 we may estimate the error in the application of\nU0 (x0 ), . . . , Un\u22121 (xn\u22121 ) by n\u03b5\u2032 . Let p\u0302G,r (a, t) be the probability that G halts after exactly t\nsteps at a sink labeled by r \u2208 {0, 1, ?}. Let p\u0302M,r (a, t) be the probability that M halts after\nexactly t iterations of steps 2\u201311 and outputs r. As remarked above, the error of one iteration\nof the outer loop is bounded by n\u03b5\u2032 . By Lemma 3.7, |p\u0302G,r (a, t) \u2212 p\u0302M,r (a, t)| \u2264 2t\u03b5\u2032 n \u2264 \u03b5/T for\nall t = 0, . . . , T . Hence,\nT\nX\nt=0\n\np\u0302G,r (a, t) \u2212\n\nT\nX\n\np\u0302M,r (a, t)\n\nt=0\n\n\u2264\n\nT\nX\nt=0\n\n|p\u0302G,r (a, t) \u2212 p\u0302M,r (a, t)| \u2264 \u03b5.\n\nAltogether, we have proved that M simulates T steps of G in poly(|G|, T, log(1/\u03b5)) steps with\naccuracy \u03b5.\n\u0003\n4.2. High-Level Simulation Theorems\nHere we use the basic, technical simulations from the last subsection for proving that the\nlogarithm of the size of QBPs and the space complexity of QTMs asymptotically agree for\nthe standard models of QBPs and QTMs. On the way, we investigate the relationship between\nprecision and running time for QBPs. All proofs are given in Section 4.3. We assume throughout\nthis subsection that the logarithm of the size of the considered QBPs and the space complexity\nof the QTMs are at least logarithmic in the input length.\nWe begin with a simple corollary from the basic simulations. If we want to apply the approximate simulation of QBPs by QTMs, we have to specify a bound \u03b5 on the simulation error and\na bound T on the number of simulation steps in advance. These parameters turn up in a term\n15\n\n\fof O(log log(T /\u03b5)) in the space complexity of the simulating machine. If we restrict ourselves to\nbounded error computation and to exponential running time, Theorem 4.2 immediately yields:\nCorollary 4.3: The logarithm of the size of QBPs and the space complexity of unidirectional\nnonuniform QTMs are asymptotically equal if both models are restricted to bounded error and\nexponential running time in the worst case. Furthermore, the classes of functions computable by\nsequences of QBPs with polynomial size and by unidirectional nonuniform QTMs with logarithmic space are the same if both models are restricted to bounded error and polynomial running\ntime.\nIt is obviously practically motivated to work with bounded running time, but it is not clear\nwhat kind of bounds can be chosen without restricting the computational power of the spacebounded models considered here. In [38] and implicitly also in [39], Watrous has investigated\nthis question for unidirectional uniform QTMs and has obtained answers analogous to the\nsituation for probabilistic TMs. He has shown that unidirectional uniform QTMs with rational\namplitudes and running in space S(n) = \u03a9(log n) have an expected running time that is at\nmost doubly exponential in S(n). This result can be extended to unidirectional uniform QTMs\nwith algebraic amplitudes using the ideas from his later papers [40, 41].\nThese considerations provide the motivation to look at the relationship between the precision\nallowed for the amplitudes and the running time also for the nonuniform model of QBPs. In\nturns out that short amplitudes take over a role analogous to algebraic amplitudes for QTMs.\nTheorem 4.4:\n(i) Sequences of QBPs (Gn )n\u2208N with bounded error and short amplitudes and sequences of\n\u2032\nQBPs (G\u2032n )n\u2208N with bounded error and expected running time 2poly(|Gn |) have polynomially\nrelated size complexities.\n(ii) Sequences of QBPs (Gn )n\u2208N with unbounded error and short amplitudes can be simulated by\n\u2032\nsequences of QBPs (G\u2032n )n\u2208N of size poly(|Gn |) and with expected running time 2poly(|Gn |) .\nOur final and main result of this subsection provides a justification to regard QBPs with short\namplitudes as the natural standard variant of the model analogous to QTMs with algebraic\namplitudes.\nTheorem 4.5: The logarithm of the size of QBPs with bounded or unbounded error and short\namplitudes and the space complexity of unidirectional nonuniform QTMs with algebraic amplitudes and the same type of error are asymptotically equal.\n4.3. Proofs of Theorems 4.4 and 4.5\nFor the proofs of the theorems we need a couple of technical lemmas, which are concerned with\nthe analysis of a matrix series that describes the acceptance probability of a QBP. Using these\nlemmas we provide two results on QBPs with short amplitudes, which are the basic tools for\nproving Theorems 4.4 and 4.5. First, even in the case of unbounded error there is some gap\nbetween the error probability and 1/2. Second, in QBPs with short amplitudes a probabilistic\nclock can be added by which computations lasting too long are aborted.\nFor the following, consider an arbitrary QBP G with s nodes. For any fixed input a for G let\nU = U (a) be a unitary time evolution matrix of G. Recall that Econt is the projection operator in\nthe measurement of the output label which belongs to the result \"no label.\" Let D = U Econt and\nM = D \u2297 D, where D denotes the matrix obtained from D by taking the complex conjugate\n16\n\n\fof each of its entries. Let N = s2 denote the dimension of M and let |1i, . . . , |N i be the\nstandard basis of CN . For v \u2208 {1, . . . , s}, define iv = v + s(v \u2212 1) \u2208 {1, . . . , N }. Then, for any\nv, w \u2208 {1, . . . , s}, Miw ,iv = (hw| \u2297 hw|)M (|vi \u2297 |vi).\nLemma 4.6:\n(i) The probability that the node w is reached after exactly k computation steps in G when\nstarting at the node v is equal to (M k )iw ,iv .\n(ii) The absolute value of each eigenvalue of M is bounded above by 1.\nk\n\nk\n\nProof. Part (i) follows from (M k )iw ,iv = (hw| \u2297 hw|)(D \u2297 D k )(|vi \u2297 |vi) = (D )w,v * (D k )w,v =\n|((U Econt )k )w,v |2 , which is obviously the desired probability.\n\nFor part (ii) it suffices to prove that kM k \u2264 1, since kM k provides an upper bound\non the absolute value of the eigenvalues of M (see, e. g., [15], page 45).\nWe have\nM \u2020 M = (D \u2297 D)\u2020 (D \u2297 D) = ((D)\u2020 D) \u2297 (D \u2020 D). Furthermore, D \u2020 D = (U Econt )\u2020 (U Econt ) =\n\u2020\nEcont\nEcont = Econt . The eigenvalues of D \u2020 D are thus from {0, 1}, and the same holds for (D)\u2020 D.\nSince the eigenvalues of M \u2020 M are obtained as products of the eigenvalues of (D)\u2020 D and D \u2020 D,\nit follows that kM k \u2264 1.\n\u0003\n\u0001\nPk\nl\nThe above lemma yields that, for each pair of nodes (v, w) in G, limk\u2192\u221e\nl=0 M iw ,iv is the\nprobability of reaching node w from node v in G. In particular, the acceptance probability of G\ncan expressed as the sum of all such terms where v is the start node and w is a 1-sink.\n\u0001\nP\u221e\nl\nWe use the technique of Watrous [39, 40, 41] to analyze the series\nl=0 M iw ,iv . Since the\nP\u221e\nP\u221e\nl\nl\nmatrix series\nl=0 (zM ) for\nl=0 M does not converge in general, we look at the series\nsome z \u2208 [0, 1) instead and let z tend to 1 afterwards.\n\u0001 the restrictions on the involved\nP\u221e Using\nl\ncan be approximated with\n(zM\n)\nnumbers, we then show two facts: First, limz\u21911\nl=0\niw ,iv\n\u0001\nP\u221e\n\u2212\npoly(N\n)\nl\nsufficient precision by choosing z = 1 \u2212 2\n. Second, if the limit\nl=0 M iw ,iv is not\nexactly 1/2, then it can be bounded away from 1/2 by a gap of size at least 2\u2212 poly(N ) .\n\nFor a multivariate polynomial f , the height of f , denoted by kf k, is the maximum absolute\nvalue of any of its coefficients and deg(f ) is the maximum degree of f with respect to any of its\nvariables. Using the form of the entries of U = U (a) obtained by Proposition 2.9, it is easy to see\nthat there is a real algebraic number \u03b1 not depending on N and a number m = 2poly(N ) such that\neach entry of M = U Econt \u2297 U Econt can be written as p(\u03b1)/m for an integer polynomial p with\ndeg(p) = poly(N ) and kpk = 2poly(N ) . The following three technical lemmas yield properties of\ngeneral matrices of this form (not necessarily derived from QBPs). The first two lemmas are\nextracted from [41] (Lemma 4.6 and its proof and the beginning of the proof of Lemma 4.2,\nresp.).\nLemma 4.7 ([41]): Let \u03b1 be any real algebraic number.\n(i) If f is a univariate polynomial with kf k \u2264 2d , deg(f ) \u2264 d and f (\u03b1) 6= 0, then\n2\n|f (\u03b1)| \u2265 2\u2212O(d ) .\n\n(ii) Let f , g be bivariate integer polynomials with kf k, kgk \u2264 2d , deg(f ), deg(g) \u2264 d and\n2\ng(\u03b1, 1) 6= 0. Then there is a constant c > 0 such that for any \u03b4 with 0 < \u03b4 < 2\u2212cd\nand d sufficiently large,\n2\nf (\u03b1, 1) f (\u03b1, 1 \u2212 \u03b4)\n\u2264 \u03b4 2cd .\n\u2212\ng(\u03b1, 1)\ng(\u03b1, 1 \u2212 \u03b4)\n\n17\n\n\fLemma 4.8 ([41]): Let \u03b1 be any real algebraic number and let m \u2208 R. Let M be an N \u00d7 N matrix such that for each entry x there is an integer polynomial p with x = p(\u03b1)/m and deg(p) =\npoly(N ), kpk = 2poly(N ) . Further suppose that thePeigenvalues\nof M are bounded above in\n\u0001\n\u221e\nl\nabsolute value by 1. Let 1 \u2264 i, j \u2264 N and let S =\nM\nbe\nconvergent. For z \u2208 [0, 1),\nl=0\ni,j\n\u0001\nP\n\u221e\nl\ne\n(zM )\n. Then there are bivariate integer polynomials f, g such that\ndefine S(z)\n=\n\nkf k, kgk \u2264\n\nl=0\nN\npoly(N\n),\nm 2\n\ni,j\n\ndeg(f ), deg(g) = poly(N ), g(\u03b1, 1) 6= 0, and\n\ne\nf (\u03b1, z)/g(\u03b1, z) = S(z),\nfor z \u2208 [0, 1), and\n\nf (\u03b1, 1)/g(\u03b1, 1) = S.\n\npoly(N ) . Let M be an N \u00d7 N -matrix as in the previous lemma. Let\nLemmaP4.9: Let\n\u0001 m=2\n\u221e\nl\nSi,j =\nl=0 M i,j for 1 \u2264 i, j \u2264 N .\n\u0001\nP\u221e\nl\n(i) Suppose that Si,j converges. For z \u2208 [0, 1), let Sei,j (z) =\nl=0 (zM ) i,j . Then there is a\npolynomial p such that for any z = 1 \u2212 \u03b4 with 0 < \u03b4 < 2\u2212p(N ) , |Si,j \u2212 Sei,j (z)| \u2264 \u03b42p(N ) .\n\n2\n(ii) Let\nS =\nP I \u2286 {1, . . . , N } and suppose that for each (i, j) \u2208 I, Si,j converges. Let\n\u2212p(N ) .\nS\n.\nThen\nthere\nis\na\npolynomial\np\nsuch\nthat\nS\n=\n6\n1/2\nimplies\n|S\n\u2212\n1/2|\n\u2265\n2\ni,j\n(i,j)\u2208I\n\nProof. Part (i): Use Lemma 4.8 to get bivariate integer polynomials fi,j , gi,j such that\nfi,j (\u03b1, z)/gi,j (\u03b1, z) = Sei,j (z), for z \u2208 [0, 1), and\n\nfi,j (\u03b1, 1)/gi,j (\u03b1, 1) = Si,j .\n\nBy the lemma and the fact m = 2poly(N ) , there is a polynomial q such that kfi,j k, kgi,j k \u2264 2q(N )\nand deg(fi,j ), deg(gi,j ) \u2264 q(N ) and, furthermore, gi,j (\u03b1, 1) 6= 0. By Lemma 4.7(ii) applied to fi,j\n2\nand gi,j with d = q(N ), it follows that there is a constant c > 0 such that for all 0 < \u03b4 < 2\u2212cq(N )\nand N sufficiently large,\n|Si,j \u2212 Sei,j (1 \u2212 \u03b4)| =\n\nfi,j (\u03b1, 1) fi,j (\u03b1, 1 \u2212 \u03b4)\n\u2212\ngi,j (\u03b1, 1) gi,j (\u03b1, 1 \u2212 \u03b4)\n\n2\n\n\u2264 \u03b4 2cq(N ) .\n\nChoosing p(N ) = cq(N )2 yields the desired bound for any z = 1 \u2212 \u03b4 with 0 < \u03b4 < 2\u2212p(N ) .\n\nPart (ii): By Lemma 4.8, it follows that for each (i, j) \u2208 I,\nSi,j =\n\n\u221e\n\u0010X\n\nMl\n\nl=0\n\n\u0011\n\ni,j\n\n=\n\nfi,j (\u03b1, 1)\n,\ngi,j (\u03b1, 1)\n\nwhere fi,j and gi,j are bivariate integer polynomials with kfi,j k, kgi,j k \u2264 2q(N ) and\ndeg(fi,j ), deg(gi,j ) \u2264 q(N ) for some polynomial q, and gi,j (\u03b1, 1) 6= 0 for all i, j \u2208 I. Then\nS=\n\nX fi,j (\u03b1, 1)\nX\nY\n6= 1/2 \u21d2 2\nfi,j (\u03b1, 1)\ngi,j (\u03b1, 1)\n\u2032 \u2032\n\n(i,j)\u2208I\n\n(i,j)\u2208I\n\ngi\u2032 ,j \u2032 (\u03b1, 1) \u2212\n\n(i ,j )6=(i,j)\n\nY\n\n(i,j)\u2208I\n\ngi,j (\u03b1, 1) 6= 0.\n\nThe left hand side of the last inequality is a polynomial in \u03b1 with height at most 2O(|I|*q(N )) =\n2poly(N ) and degree at most |I| * q(N ) = poly(N ), since |I| \u2264 N 2 . Lemma 4.7(i) implies that\n\u2032\nthe absolute value of this expression is lower bounded by 2\u2212q (N ) for a suitable polynomial q \u2032\nand N large enough. Hence,\nX fi,j (\u03b1, 1) 1\n\u2212\ngi,j (\u03b1, 1) 2\n\n(i,j)\u2208I\n\n\u2265 Q\n18\n\n\u2032\n\n2\u2212q (N )\u22121\n.\n(i,j)\u2208I |gi,j (\u03b1, 1)|\n\n\fWe have kgi,j k \u2264 2q(N ) , deg(gi,j ) \u2264 q(N ), and \u03b1, \u03b12 , . . . , \u03b1q(N ) = 2poly(N ) since \u03b1 is a constant.\n\u2032\u2032\nThis implies that |gi,j (\u03b1, 1)| \u2264 2q (N ) for a polynomial q \u2032\u2032 and N sufficiently large. Thus,\n\u2032\n\n|S \u2212 1/2| \u2265\n\n2\u2212q (N )\u22121\n\u2265 2\u2212p(N )\n2|I|*q\u2032\u2032 (N )\n\nfor p(N ) = q \u2032 (N ) + N 2 q \u2032\u2032 (N ) + 1, which proves the claim.\n\n\u0003\n\nNow we can state and prove our first main lemma that allows us to bound the error probability\nof QBPs away from 1/2.\nLemma 4.10: For each QBP G with short amplitudes there exists a polynomial q such that for\neach input a \u2208 {0, 1}n , pG,1 (a) > 1/2 implies pG,1 (a) \u2265 1/2 + 2\u2212q(|G|) and pG,1 (a) < 1/2 implies\npG,1 (a) \u2264 1/2 \u2212 2\u2212q(|G|) .\nProof. Let G be a QBP with short amplitudes on n variables. By Proposition 2.9 we may\nassume that the amplitudes in G are of the form p(\u03b1)/m, where p is an integer polynomial\nwith deg(p) = poly(|G|) and kpk = 2poly(|G|) and where \u03b1 is the same algebraic number and\nm = 2poly(|G|) is the same natural number for all amplitudes. Let v be the start node of G and\nlet F1 = {w | w is a 1-sink of G }. Let N = |G|2 and let the N \u00d7 N -matrix M describing the\ncomputation of G on an input a \u2208 {0, 1}n as well as the indices iv \u2208 {1, . . . , N } corresponding\nto nodes v \u2208 {1, . . . , |G|} be defined\nThen the probability of G accepting a in the\nPas above.\nk)\nkth computation step is given by\n(M\niw ,iv , and the total probability of accepting a\nw\u2208F1\n\u0001\nP\nP\u221e\nk\nis pG,1 (a) =\nw\u2208F1\nk=0 M iw ,iv . Since G only contains labels of the form p(\u03b1)/m, the\nentries of M are of the form p\u2032 (\u03b1)/m\u2032 , where p\u2032 is a polynomial with deg(p\u2032 ) = poly(|G|) and\nkp\u2032 k = 2poly(|G|) and m\u2032 = m2 = 2poly(|G|) . Hence, part (ii) of Lemma 4.9 yields the claimed\nresult.\n\u0003\nThe other main argument in our proofs is the construction of a probabilistic clock, which works\nin the case of bounded as well as unbounded error.\nLemma 4.11: For each sequence of QBPs (Gn )n\u2208N with bounded or unbounded error and short\namplitudes, there is a sequence of QBPs (G\u2032n )n\u2208N for the same function with short amplitudes,\n\u2032\nthe same type of error, size poly(|Gn |), and expected running time 2poly(|Gn |) .\nProof. The main idea is similar to that of Simon [36] for limiting the running time of probabilistic\nTuring machines. We simulate G step-by-step. Before each simulation step, we stop and reject\nthe input with fixed, small probability. A similar construction for unidirectional QTMs has\nbeen given in Lemma 4.6 of Watrous [39].\nLet G be a QBP on n variables of size s. By Proposition 2.9 we may assume that the\namplitudes of G are the fraction of some integer polynomial in an algebraic number and a\ncommon denominator m = 2poly(s) . Let q be some polynomial. We construct a QBP G\u2032\nwith size polynomial in s, expected running time 2poly(s) , and such that for all a \u2208 {0, 1}n ,\npG,1 (a) \u2212 2\u2212q(s) \u2264 pG\u2032 ,1 (a) \u2264 pG,1 (a). Together with Lemma 4.10, this implies the claim.\n\nLet t = t(s) = q(s) + p(s) + log s, where p(s) is a polynomial defined later on. Let v1 , . . . , vs\nbe the nodes of G. The new QBP G\u2032 is obtained from the QBP G\u20320 shown schematically in\nFigure 3. We use unlabeled nodes introduced in Section 2 to simplify the presentation. The\nstart node of G\u20320 is w1 . The edges in the upper part of the figure represent the transformation\n|wi i 7\u2192 \u03b2|wi\u2032 i + \u03b3|wi\u2217 i, where\n\u03b2 =\n\n22t+1 + 2t+1\n22t+1 + 2t+1 + 1\n\nand \u03b3 =\n19\n\n2t+1 + 1\n.\n22t+1 + 2t+1 + 1\n\n\fw1\n\nws\n\u03b2\n\n. . .\n\n\u03b3\n0\n\nw1\u2032\n\n\u03b2\n\n\u03b3\n0\n\nws\u2032\n\nw1\u2217\n\nws\u2217\n\nG\nw1\u2032\u2032\n\n. . . . . . .\n\nws\u2032\u2032\n\nFigure 3: The QBP G\u20320 used in the proof of Lemma 4.11.\nThen \u03b2 2 + \u03b3 2 = 1, which is used to prove that the QBP is well-formed. Each node wi\u2032 ,\ni \u2208 {1, . . . , s}, is a copy of the node vi in G and is labeled by the same variable as vi . For\neach edge (vi , vj ) in G, an edge (wi\u2032 , wj\u2032\u2032 ) is inserted in G\u20320 that carries the same labels. The\nshaded part in the figure represents these edges. The node wi\u2032\u2032 is a sink if the corresponding\nnode vi in G is, and each non-sink node wi\u2032\u2032 is unlabeled and has an outgoing edge with amplitude 1 to node wi (not shown in the figure). The only nodes labeled by variables are w1\u2032 , . . . , ws\u2032 ,\nall other nodes are unlabeled. We remove all unlabeled nodes from G\u20320 to obtain the desired\nQBP G\u2032 . It is easy to see that G\u2032 constructed in this way is well-formed and unidirectional.\nThe only numbers added as amplitudes here, 1, \u03b2, and \u03b3, are rational and have representations\nof polynomial length. Hence, G\u2032 also has short amplitudes.\nWe observe that the probability of G\u2032 terminating during a traversal of the upper part is\n\u03b4 = |\u03b3|2 \u2264 2\u22122t . Hence, its expected running time is bounded by 2O(t) = 2poly(s) . Furthermore,\nfor all inputs a \u2208 {0, 1}n , pG\u2032 ,1 (a) \u2264 pG,1 (a). It remains to show that for all inputs a, pG\u2032 ,1 (a) \u2265\npG,1 (a) \u2212 2\u2212q(s) .\n\nFix any input a \u2208 {0, 1}n . Let N = s2 , let the N \u00d7 N -matrix M describing the computation of the original QBP G on a, and let the mapping of nodes v \u2208 {1, . . . , s} to indices iv \u2208 {1, . . . , N } be defined as above. Let v be the start node of G and let F1 =\n{w | w is a 1-sink ofPG }. As\nin the \u0001proof of Lemma 4.10, the total probability of G acceptP\u221e\n\u2032\nk\ning a is pG,1 (a) =\nw\u2208F1\nk=0 M iw ,iv . Now recall that G performs the same computation\nas G with the only exception that it terminates the computation with the probability \u03b4 before\neach step of G. Hence, the probability of G\u2032 accepting a in the P\nkth simulation step \u0001of G after\nnot rejecting k times in the first phase of the computation is w\u2208F1 (1 \u2212 \u03b4)k M k iw ,iv . We\nobtain\n\u221e\n\u0011\nX \u0010X\npG\u2032 ,1 (a) =\n(1 \u2212 \u03b4)k M k\n.\nw\u2208F1\n\niw ,iv\n\nk=0\n\nNow choose p as the polynomial obtained when Lemma 4.9(i) is applied with z = 1 \u2212 \u03b4,\nSi,j = pG,1 (a), and Sei,j (z) = pG\u2032 ,1 (a). The lemma implies that\n\u221e\n\u0011\nX \u0010X\n|pG\u2032 ,1 (a) \u2212 pG,1 (a)| \u2264\n(1 \u2212 \u03b4)k M k\nw\u2208F1\n\niw ,iv\n\nk=0\n\n\u2212\n\n\u221e\n\u0010X\nk=0\n\nMk\n\n\u0011\n\niw ,iv\n\n\u2264 |F1 | * \u03b4 * 2p(s) ,\n\nprovided that 0 < \u03b4 < 2\u2212p(s) . The restriction on \u03b4 is easily seen to be satisfied since \u03b4 \u2264 2\u22122t\nand t = t(s) = p(s) + q(s) + log s. Using that |F1 | \u2264 s, we obtain\n|F1 | * \u03b4 * 2p(s) \u2264 |F1 | * 2\u22122(q(s)+p(s)+log s) * 2p(s) \u2264 2\u2212q(s)\n20\n\n\fand thus |pG\u2032 ,1 (a) \u2212 pG,1 (a)| \u2264 2\u2212q(s) . Hence, G\u2032 has all required properties.\n\n\u0003\n\nNow we have collected all tools for the proofs of Theorems 4.4 and 4.5. For the convenience of\nthe reader, we restate the theorems here. We begin with the proof of Theorem 4.5.\nTheorem 4.5 (restatement): The logarithm of the size of QBPs with bounded or unbounded\nerror and short amplitudes and the space complexity of unidirectional nonuniform QTMs with\nalgebraic amplitudes and the same type of error are asymptotically equal.\nProof. A simulation of unidirectional nonuniform QTMs by QBPs is already provided in Theorem 4.2. It is easy to see that the resulting QBP has short amplitudes if the amplitudes of the\nQTM are algebraic numbers.\nNow let a sequence (Gn )n\u2208N of QBPs with short amplitudes be given. By Lemma 4.11 we can\nsimulate Gn by a QBP G\u2032n with size poly(|Gn |), the same type of error, short amplitudes and\n\u2032\nexpected running time T (n) = 2poly(|Gn |) . In the case of bounded error, let \u03b5 be the error bound\nof G\u2032n . In the case of unbounded error, by Lemma 4.10, there is some polynomial q(n) such\n\u2032\nthat the acceptance and rejection probabilities of G\u2032n are strictly larger than 1/2 + 2\u2212q(|Gn |) or\n\u2032\n\u2032\nstrictly smaller than 1/2 \u2212 2\u2212q(|Gn |) , resp. In this case let \u03b5 = \u03b5(n) = 1/2 \u2212 2\u2212q(|Gn |) be the\n\u2032\nerror bound of G\u2032n . We choose \u03b5\u2032 = (1/2 \u2212 \u03b5)/3 and T \u2032 (n) = T (n)/\u03b5\u2032 = 2poly(|Gn |) . Then we\napply the simulation of QBPs by QTMs from Theorem 4.2 for the accuracy \u03b5\u2032 and the running\ntime T \u2032 (n). The space complexity of the QTM is O(log |G\u2032n | + log log(T \u2032 (n)/\u03b5\u2032 )) = O(log |Gn |).\nBy Markov's inequality, the probability that the running time of G\u2032n and thus the number of\nperformed simulation steps exceeds T \u2032 (n) = T (n)/\u03b5\u2032 is bounded by \u03b5\u2032 . Hence, the probability of\nan error caused by running more than T \u2032 (n) simulation steps is bounded by \u03b5\u2032 and the overall\nerror probability is bounded by \u03b5 + 2\u03b5\u2032 = 1/2 \u2212 \u03b5\u2032 .\n\u0003\nTheorem 4.4 (restatement):\n(i) Sequences of QBPs (Gn )n\u2208N with bounded error and short amplitudes and sequences of\n\u2032\nQBPs (G\u2032n )n\u2208N with bounded error and expected running time 2poly(|Gn |) have polynomially\nrelated size complexities.\n(ii) Sequences of QBPs (Gn )n\u2208N with unbounded error and short amplitudes can be simulated by\n\u2032\nsequences of QBPs (G\u2032n )n\u2208N of size poly(|Gn |) and with expected running time 2poly(|Gn |) .\nProof. A simulation of QBPs (Gn )n\u2208N with short amplitudes by QBPs (G\u2032n )n\u2208N with expected\n\u2032\nrunning time 2poly(|Gn |) for bounded and unbounded error is contained in Lemma 4.11. This\nproves one direction of part (i) as well as part (ii). It remains to prove the missing direction of\npart (i), i. e., to provide a simulation of QBPs with bounded error and an expected exponential\nrunning time by QBPs with bounded error and short amplitudes. Let (Gn )n\u2208N be a sequence of\nQBPs with expected running time 2poly(|Gn |) and error probability \u03b5 \u2208 [0, 1/2). As in the proof\nof Theorem 4.5, we choose \u03b5\u2032 = (1/2 \u2212 \u03b5)/3 and T \u2032 (n) = T (n)/\u03b5\u2032 = 2poly(s(n)) and apply the\nsimulation of QBPs by QTMs of Theorem 4.2 for the accuracy \u03b5\u2032 and the running time T \u2032 (n).\nBy the same arguments as in the proof of Theorem 4.5, we obtain a unidirectional nonuniform\nQTM simulating the given QBP with bounded error, expected running time T (n), and space\ncomplexity O(log |Gn |). The transition function of the QTM only contains a constant number\nof algebraic numbers.\nIn a second step we apply the simulation of unidirectional nonuniform QTMs by QBPs from\nTheorem 4.2. The resulting QBP has an error probability of at most \u03b5\u2032 . Its size is bounded\nabove by 2O(log |Gn |) = poly(|Gn |). The amplitudes occurring in the QBP are the amplitudes of\nthe transition function of the QTM and thus are short.\n\u0003\n21\n\n\f5. Simulation of Nonuniform QTMs by Unidirectional Nonuniform QTMs\nIn this section, we consider nonuniform RTMs and QTMs that are, different from the previous\nsections, not necessarily unidirectional. We show that they can be simulated space-efficiently\nby their unidirectional counterparts. We discuss some consequences of the simulation result at\nthe end of this section.\nOur simulation result uses the construction of the universal QTM due to Yao [43] and Nishimura\nand Ozawa [27] based on a simulation of QTMs by quantum circuits and vice versa as intermediate steps. The original simulations cannot be applied since they use markers on the work tape\nof the simulating machine to store the positions of the simulated tape heads and (which is more\nserious) generate a quantum circuit for the simulated machine online on the work tape. Both of\nthis is too costly in terms of space. These obstacles are overcome here by using a space-efficient\nencoding of the positions of the input tape heads and by storing a representation of the required\nquantum circuit on the advice tape.\nAs a preparation for the proof of our simulation result, we state a simple necessary property\nof the transition function of QTMs with two read-only input tapes which is extracted from the\nproof of Theorem 4.5 in [28]. In the following the expression [A = B] has the value 1, if A = B,\nand 0 otherwise.\nLemma 5.1 ([28]): Let M = (Q, \u03a3, \u03b4) be a QTM with two read-only input tapes. Let p, p\u2032 \u2208 Q,\n\u2206 = (\u22061 , \u22062 ) \u2208 Z2 and a1 , a2 , a\u20321 , a\u20322 , v, w, v \u2032 , w\u2032 \u2208 \u03a3.\nX\n(i) 0 =\n\u03b4(p, (a1 , a2 , v), q, w, (d, d\u2032\u2032 \u2212 1))\u2217\n\u0002\n\u0003\n* \u03b4(p\u2032 , (a\u20321 , a\u20322 , v \u2032 ), q, w\u2032 , (d\u2032 , d\u2032\u2032 )) * d\u2032 \u2212 d = \u2206 .\nq\u2208Q, d\u2032\u2032 \u2208{0,1},\nd,d\u2032 \u2208{\u22121,0,1}2\n\n(ii) 0\n\n=\n\nX\n\n\u03b4(p, (a1 , a2 , v), q, w, (d, \u22121))\u2217\n\u0002\n\u0003\n* \u03b4(p\u2032 , (a\u20321 , a\u20322 , v \u2032 ), q, w\u2032 , (d\u2032 , 1)) * d\u2032 \u2212 d = \u2206 .\n\nq\u2208Q,\nd,d\u2032 \u2208{\u22121,0,1}2\n\nNow we can state and prove our result.\nTheorem 5.2:\n(i) Each nonuniform RTM that runs in space S at least logarithmic in the input length and\ntime T can be simulated by a unidirectional nonuniform RTM running in time poly(S, T )\nand space O(S).\n(ii) Let \u03b5 > 0 and T : N \u2192 N0 . For each nonuniform QTM M running in space S at\nleast logarithmic in the input length, there is a unidirectional nonuniform QTM that\nsimulates M for T steps in poly(2O(S) , T, log(1/\u03b5)) steps with accuracy \u03b5 using space\nO(S + log log(T /\u03b5)).\nProof. In the main part of the proof, we deal with part (ii). We handle necessary changes for\npart (i) and RTMs at the end. We first describe how we encode the information about the\nsimulated machine on the work tape of the simulating machine. Then we present a high-level\nalgorithm carrying out a whole simulation step and define a unitary transformation realizing a\nsingle transition of the simulated machine. Afterwards, this unitary transformation is implemented approximately by the simulating unidirectional nonuniform QTM.\nStorage layout on the work tape. Let M = (Q, \u03a3, \u03b4) be a nonuniform QTM that is to be\nsimulated unidirectionally. We regard the advice tape simply as an additional read-only input\ntape. We assume that for input length n and space bound S \u2265 log n the heads on the input\n22\n\n\ftapes i \u2208 {1, 2} of M only reach the positions 0, . . . , ni \u2212 1, where n1 = n + 2, n2 = poly(n),\nand that the work tape head only reaches the positions 0, . . . , n3 \u2212 1 with n3 = S + 2 (this may\nbe achieved using end markers). We assume that {0, 1, 2} \u2286 \u03a3.\n\nLet l = l1 + 6l2 + 1 with l1 = \u2308log |Q|\u2309 and l2 = max{\u2308log ni \u2309 | i \u2208 {1, 2, 3}} = O(S), and\nassume w. l. o. g. that l \u2265 3. The information about the simulated machine is stored on two\ntracks of the work tape of the simulating machine as shown below.\nq\n\nTrack 1:\nTrack 2:\n\nw1\n\nw2\n\nw3\n\ni\u22121\n\ni\n\ni+1\n\n\u03c6\n\n\u03be = (\u03be1 , \u03be2 , \u03be3 )\n\n\u03bd = (\u03bd1 , \u03bd2 , \u03bd3 )\n\ni+l\u22122\n\nTrack 2 contains the work tape of the simulated machine. In l consecutive cells on track 1, which\nare called the info block, we encode all administrative information for the simulation. The position of the info block is used to indicate the position of the head on the work tape in a classical\nconfiguration. If the cells of the info block are located at positions i \u2212 1, i, i + 1, . . . , i + l \u2212 2\non the work tape as shown in the figure, we say that the info block is at position i. In this\nsituation, the inscription in the info block together with the symbols w1 , w2 , w3 \u2208 \u03a3 in cells\ni \u2212 1, i, i + 1 on track 2 are called the info window induced by the info block.\n\nThe information stored in the info block consists of the local state q \u2208 Q of the simulated\nmachine encoded in binary, a flag \u03c6 \u2208 {0, 1} showing whether the actual transition step has\nalready been carried out, and vectors \u03be = (\u03be1 , \u03be2 , \u03be3 ), \u03bd = (\u03bd1 , \u03bd2 , \u03bd3 ) in {0, . . . , n1 \u2212 1} \u00d7 * * * \u00d7\n{0, . . . , n3 \u2212 1} encoded in binary. The coordinates of \u03be are the positions of the tape heads of\nthe simulated machine. Similarly, \u03bd1 and \u03bd2 are the positions of the heads on the input tapes\nof the simulating machine. Finally, \u03bd3 is the position of the info block. We write the contents\nof the info window shown above as (q, \u03c6, \u03be, \u03bd, w), where w = (w1 , w2 , w3 ).\n\nCarrying out a simulation step. We first give an outline of our approach. For the simulation\nof a single step of M , we let the input tape heads of the simulating machine as well as the info\nblock on the work tape successively move to all combinations of positions in {0, . . . , n1 \u2212 1} \u00d7\n* * *\u00d7{0, . . . , n3 \u22121} on the tapes that may be accessed. If during this sweep the machine reaches\na configuration where the positions of the heads of the input tapes as well as the position of the\ninfo block, which are encoded in \u03bd, all agree with the stored positions of those of the simulated\nmachine and \u03c6 = 0, then a local transition of the simulated machine is applied, for which we\nupdate the contents of the info window and set \u03c6 = 1. After the sweep through all positions is\ncomplete, the flag \u03c6 is negated.\nIn Figure 4 this is described in more detail as a high-level algorithm. We use the following notation. For x = (x1 , x2 , x3 ) \u2208 {0, . . . , n1 \u2212 1} \u00d7 * * * \u00d7 {0, . . . , n3 \u2212 1}, let |x| = x3 n2 n1 + x2 n1 + x1 .\nFurthermore, let |q, \u03c6, \u03be, \u03bd, w1 w2 w3 i denote an ON-basis indexed by the different possible classical inscriptions of the info window.\nRealizing a Transition Unitarily. Next we show that step 2 of the high-level algorithm can\nbe described by a unitary transformation. For this, let the heads on the input tapes of the\nsimulating machine as well as the info block on the work tape be at fixed positions. Let a1 , a2 \u2208 \u03a3\nbe the symbols under the input tape heads. Our goal is to specify a unitary transformation\nUtrans = Utrans (a1 , a2 ) that changes the contents of the info window according to the high-level\nalgorithm. Using an idea due to Yao [43], we only carry out the identity in step 2.2 for those\ninscriptions of the info window that can actually arise during the computation at this point.\n\n23\n\n\fLoop with starting/stopping condition \u03bd = (0, 0, 0):\n1. Move the real input tape heads and the info block on the work tape to the positions\nin \u03bd.\n2. Transition: Let (p, \u03c6, \u03be, \u03bd, (w1 , w2 , w3 )) be the contents of the current info window and\nlet a1 , a2 \u2208 \u03a3 be the symbols under the input tape heads.\n2.1. If \u03be = \u03bd and \u03c6 = 0, replace the contents of the info window with the superposition\nX\n\u0001\n\u03b4 p, (a1 , a2 , w2 ), q, b, d |q, 1, \u03be + d, \u03be, w1 b w3 i.\nq\u2208Q,b\u2208\u03a3,\nd\u2208{\u22121,0,1}3\n\n2.2. For all inscriptions of the info window that do not satisfy the condition of step 2.1\nand can actually arise during the computation, do nothing.\n3. Move real input tape heads and the info block on the work tape to positions (0, 0, 0).\n4. Update \u03bd to a new vector \u03bd \u2032 such that |\u03bd \u2032 | \u2261 (|\u03bd| + 1) mod n1 * n2 * n3 .\nSet \u03c6 = 1 \u2212 \u03c6. End of simulation step.\nFigure 4: High-level description of the simulation step.\n(1)\n\nvp,\u03be,w1 ,w2 ,w3\n(2)\n\nvp,\u03be,w1 ,w2 ,w3\n\n= |p, 0, \u03be, \u03be, w1 w2 w3 i\nX\n\u0001\n=\n\u03b4 p, (a1 , a2 , w2 ), q, b, d |q, 1, \u03be + d, \u03be, w1 b w3 i\nq,b,d\n\n(3)\n\nvp,\u03be,\u03bd,w1 ,w2 ,w3\n(4)\n\nvp,\u03be,\u03bd1 ,\u03bd2 ,w,w2 ,w3\n\n= |p, \u03c6, \u03be, \u03bd, w1 w2 w3 i with \u03c6 = 0 \u2227 \u03bd 6= \u03be or \u03c6 = 1 \u2227 \u03bd3 \u2265 \u03be3 + 2\nX\n\u0001\n\u03b4 p, (a1 , a2 , w), q, b, d) q, 1, \u03be+d, (\u03bd1 , \u03bd2 , \u03be3 +1), b w2 w3\n=\nq,b,d with\nd3 \u2208{0,1}\n\n(5)\n\nvp,\u03be,\u03bd1 ,\u03bd2 ,w,b,w1 ,w2 ,w3 =\n\nX\n\nq,d with\nd3 =1\n\n\u0001\n\u03b4 p, (a1 , a2 , w), q, b, d q, 1, \u03be+d, (\u03bd1 , \u03bd2 , \u03be3 +2), w1 w2 w3\n\nFigure 5: Vectors for the definition of Utrans .\nThis is required to allow the transformations of steps 2.1 and 2.2 to be combined to a unitary\none.\nFor a precise definition of Utrans , we introduce the collections of vectors in Figure 5. For these\ndefinitions, let p \u2208 Q, \u03be = (\u03be1 , \u03be2 , \u03be3 ), \u03bd = (\u03bd1 , \u03bd2 , \u03bd3 ) \u2208 {0, . . . , n1 \u2212 1}\u00d7 * * * \u00d7 {0, . . . , n3 \u2212 1}, and\nw, b, w1 , w2 , w3 \u2208 \u03a3. The summations are over all q \u2208 Q, b \u2208 \u03a3, and d = (d1 , d2 , d3 ) \u2208 {\u22121, 0, 1}3\nif not indicated otherwise. Let Vi be the set of vectors with upper index i \u2208 {1, . . . , 5}.\n\nWe require that the transformation Utrans satisfies\n(1)\n\nUtrans vp,\u03be,w1,w2 ,w3\n\n(2)\n\n= vp,\u03be,w1,w2 ,w3\n\nfor all p, \u03be, and w1 , w2 , w3 and that Utrans |vi = |vi for all |vi \u2208 V3 \u222a V4 \u222a V5 . The following claim\nimplies that the above requirements can be satisfied by a unitary operator Utrans , completing\nthis part of the proof.\n\n24\n\n\fClaim. The sets V1 , V2 , and V3 \u222a V4 \u222a V5 are mutually orthogonal and the vectors in V2 form\nan ON-basis.\nProof of the claim. The claim follows from the fact that M is a legal QTM and thus has a\nunitary time evolution operator. We use the notion \"superposition of M \" to describe a unit\nvector from the Hilbert space spanned by the classical configurations of M as an ON-basis.\nThe vectors in V2 form an ON-basis: We regard the vectors in V1 and V2 as unique descriptions\nof superpositions of M . This is possible since the contents of the work tape of M that is outside\n(2)\nthe three symbols in the info window is fixed. Each vector vp,\u03be,w1,w2 ,w3 uniquely describes\n(1)\n\nthe image of the classical configuration described by vp,\u03be,w1,w2 ,w3 under the time evolution\noperator of M . Since this time evolution operator is unitary and the vectors in V1 obviously\nform an ON-basis, the vectors from V2 also form an ON-basis.\nThe vectors in V1 , V2 , V3 \u222a V4 \u222a V5 are mutually orthogonal: We write M1 \u22a5M2 for two sets\nof vectors M1 and M2 if hv | wi = 0 for all v \u2208 M1 and w \u2208 M2 and prove the statement by\nconsidering all possible pairs of sets in the list.\nV1 \u22a5V2 , V1 \u22a5V3 \u222a V4 \u222a V5 , V2 \u22a5V3 : This follows immediately, since either the component for the\nflag \u03c6 or that for the position vector \u03bd distinguishes vectors from the considered sets.\n(2)\n\n(4)\n\nV2 \u22a5V4 : We consider any pair of vectors vp,\u03be,w1,w2 ,w3 and vp\u2032 ,\u03be \u2032 ,\u03bd \u2032 ,\u03bd \u2032 ,w\u2032 ,w\u2032 ,w\u2032 . We may assume\n1 2\n2 3\nthat w3\u2032 = w3 , \u03bdi\u2032 = \u03bei for i \u2208 {1, 2} and \u03be3\u2032 = \u03be3 \u2212 1 since otherwise the inner product of these\nvectors is obviously zero. By keeping only the summands in the inner product for which the\nbasis vectors meet, we get\n(4)\n\n(2)\n\nvp,\u03be,w1,w2 ,w3 | vp\u2032 ,(\u03be \u2032 ,\u03be \u2032 ,\u03be3 \u22121),\u03be1 ,\u03be2 ,w\u2032 ,w\u2032 ,w3 =\n2\nX 1 2\n\u0001\u2217\n\u03b4 p, (a1 , a2 , w2 ), q, w2\u2032 , d\n\u0001 \u0002\n\u0003\n* \u03b4 p\u2032 , (a\u20321 , a\u20322 , w\u2032 ), q, w1 , d\u2032 * d\u2032 \u2212 d = \u03be \u2212 \u03be \u2032 .\nq\u2208Q,d,d\u2032 \u2208{\u22121,0,1}3 ,\nwith d\u20323 \u2208{0,1}\n\nFor the d, d\u2032 over which the summation is done, it is required that d\u20323 \u2212 d3 = \u03be3 \u2212 \u03be3\u2032 = 1, i. e.,\nd3 = d\u20323 \u2212 1. The sum may thus be rewritten as\nX\n\u0001\u2217\n\u03b4 p, (a1 , a2 , w2 ), q, w2\u2032 , (d, d\u2032\u2032 \u2212 1)\n\u0001 \u0002\n\u0003\n* \u03b4 p\u2032 , (a\u20321 , a\u20322 , w\u2032 ), q, w1 , (d\u2032 , d\u2032\u2032 ) * d\u2032 \u2212 d = (\u03be1 , \u03be2 ) \u2212 (\u03be1\u2032 , \u03be2\u2032 ) .\nq\u2208Q, d\u2032\u2032 \u2208{0,1},\nd,d\u2032 \u2208{\u22121,0,1}2\n\nFor \u2206 = (\u03be1 , \u03be2 ) \u2212 (\u03be1\u2032 , \u03be2\u2032 ), Lemma 5.1(i) implies that the sum takes the value 0. Thus the\nconsidered vectors are orthogonal.\nV2 \u22a5V5 : This case is handled similarly to the latter one now using part (ii) of Lemma 5.1.\n\n\u0003\n\nConstructing the Simulating QTM. We now describe how the QTM simulating the given\nQTM M unidirectionally is constructed. This simulating QTM carries out an endless loop\nexecuting single simulation steps until the simulated machine terminates, similar to the machine constructed for part (ii) of Theorem 4.2. It is initialized as follows.\n\u2013 The info block belonging to the initial configuration of M is located at position 0 of track 1\nof the work tape. The complete contents of the respective info window is then (q0 , 0, \u03be, \u03bd, w),\nwhere q0 is the initial state of M , \u03be = \u03bd = (0, 0, 0), and w only consists of blanks.\n\u2013 All input tape heads of the simulating machine are at position 0.\n\n25\n\n\fAs in the last section, this initialization is realized by choosing the encoding for the information\non the work tape such that the blank tape is consistent with the above requirements.\nWe realize the high-level algorithm by first constructing a unidirectional RTM for everything\nexcept for step 2, for which the RTM has a special state as a placeholder. This is easy by\nputting together machines for basic tasks using appropriate versions of the lemmas of Bernstein\nand Vazirani [11], as in the last section. Afterwards, we insert a QTM for carrying out step 2\nwhich has still to be constructed. We ensure that the running time of this QTM is independent\nof the inscriptions of the info window. Then the complete QTM for the high-level algorithm\nobtained by the insertion has a running time independent of the contents of the different tapes.\nThe transformation Utrans operates on a Hilbert space of dimension O(l) = O(S). The number of iterations of the loop is n1 n2 n3 = poly(n)S. Reusing the calculations in the proof of\nTheorem 4.2(ii), it follows that a description of Utrans with accuracy \u03b5\u2032 = \u03b5/(2n1 n2 n3 T 2 ) by\nelementary matrices adds O(S + log log(T /\u03b5)) to the total space complexity if it is stored on\nthe advice-tape. This is within the required bound for part (ii) of the theorem. The chosen\naccuracy \u03b5\u2032 is sufficient to carry out the T simulation steps with accuracy \u03b5. This corresponds\nto n1 n2 n3 T executions of Utrans . The transformation Utrans is realized by carrying out the\nrespective elementary transformations as described in the last section, using Lemma 3.5.\nResources. The running time for carrying out Utrans is dominated by the length of its description\non the advice tape and can be estimated by 2O(S) log(T /\u03b5). The number of iterations of the\nloop is poly(n)S. Thus the total time required for one simulation step can be estimated by\nO(poly(n)2O(S) log(T /\u03b5)) = poly(2O(S) , log(T /\u03b5)).\nCorrectness. We show that each single computation step is performed correctly. We first\nconsider step 2.1 of the high-level algorithm and the case that the condition in this step is\nmet. We assume that the current configuration of the simulating machine is consistent with\nour described invariants, that track 2 and the info block contain classical inscriptions, and that\nthe latter is at a fixed position. Then it is easy to see that Utrans correctly realizes a single\ntransition of M .\nIt remains to check that step 2.2 does not change anything. We observe that before the transition of M has been carried out in step 2.1, Utrans performs the identity in step 2.2, since\nall encountered info window inscriptions correspond to vectors from V3 . Immediately after the\ntransition, the info window operated upon contains a vector |vi \u2208 V2 . If after one or two shifts\nof the info window to the right on the work tape we adapt |vi by inserting the new \u03bd, this yields\na vector from V4 or V5 , resp., on which Utrans also performs the identity. If the window is shifted\nfurther to the right, the distance of the info window from the stored position of the work tape\nhead in each classical inscription contained in the current superposition is at least two. Then\nthe vector obtained by adapting |vi as described belongs to V3 and Utrans also performs the\nidentity. Hence, Utrans behaves as desired. Altogether, we have completed the proof of part (ii).\nSimulation of RTMs. We can use the same construction as above, but replace the implementation of Utrans . In this case, Utrans is just a permutation of inscriptions of the info window.\nThis permutation can be computed exactly by a reversible circuit of size poly(l) consisting\nonly of Toffoli gates. The description of this circuit on the advice tape adds an amount of\nO(log l) = O(log S) to the space complexity and its simulation takes time poly(l) = poly(S),\nwhich yields an overall bound on the time of poly(S, T ). Hence, also part (i) follows.\n\u0003\nSince the simulation of QTMs in Theorem 5.2 is done only approximately and the space\nO(S + log log(T /\u03b5)) needed for the simulation increases with the running time we again obtain\n26\n\n\fthe question in which cases we can bound the running time without restricting the computational power of the model. Here we need a statement for bounding the error probability away\nfrom 1/2 in the case of unbounded error and a construction of a probabilistic clock for QTMs.\nLemma 5.3: For each nonuniform QTM M with algebraic amplitudes and running in space\nS(n) there exists a polynomial q such that for each input a \u2208 {0, 1}n , pM,1 (a) > 1/2 implies\nS(n)\nS(n)\npM,1 (a) \u2265 1/2 + 2\u2212q(2 ) and pM,1 (a) < 1/2 implies pM,1 (a) \u2264 1/2 \u2212 2\u2212q(2 ) .\nLemma 5.4: For each nonuniform QTM M with bounded or unbounded error, algebraic amplitudes and running in space S(n), there is a QTM for the same function with algebraic amO(S(n))\n.\nplitudes, the same type of error, the space bound O(S(n)) and expected running time 22\nLemma 5.3 is proved in the same way as Lemma 4.10 since the matrix describing the transition\nprobabilities in the proof in the same way describes transition probabilities of nonuniform QTMs.\nFor the proof of Lemma 5.4 we modify the given QTM M in a way similar to the construction\nof the QBP in the proof of Lemma 4.11. Using the proof of Lemma 4.6 in Watrous [39] it is\neasy to construct a QTM Mt that for an appropriate t = 2O(S) stops with probability 2\u2212\u0398(t)\nand continues with probability 1 \u2212 2\u2212\u0398(t) . Using suitable versions of the lemmas of Bernstein\nand Vazirani [11] for the construction of QTMs we modify M in such a way that, before\neach computation step, it additionally performs Mt . By a reasoning similar to the proof of\nLemma 4.11 we obtain a QTM with the behavior claimed in Lemma 5.4. Using these results\nwe easily obtain the following.\nTheorem 5.5: The space complexity of nonuniform QTMs with algebraic amplitudes and\nbounded or unbounded error is asymptotically equal to the space complexity of unidirectional\nnonuniform QTMs with the same kind of amplitudes and the same type of error, provided that\nthese space complexities are at least logarithmic in the input length.\nProof. Applying Lemmas 5.3 and 5.4 to a nonuniform QTM that according to the hypothesis\nO(S)\n.\nruns in space S, we obtain a nonuniform QTM of the same kind running in expected time 22\nAnalogously to the proofs in the last section, using Markov's inequality to estimate the error of\nO(S)\n, Theorem 5.2 yields a unidirectional nonuniform\ncomputations that take longer than time 22\nQTM of the desired kind running in space O(S).\n\u0003\n\n6. Quantum OBDDs\nSince for unrestricted branching programs no powerful lower bound methods are known, restricted variants of branching programs have been investigated in order to develop lower bound\nmethods and to compare different modes of nondeterminism and randomization. A simple\nvariant of branching programs closely related to the uniform model of DFAs and to one-way\ncommunication complexity are ordered binary decision diagrams (OBDDs). OBDDs are also\nused as a data structure for the representation and manipulation of boolean functions, see, e. g.,\nWegener [42]. Hence, it is natural to investigate also the quantum variant of OBDDs.\nDefinition 6.1: A quantum OBDD (QOBDD) is a read-once QBP where on each path the\nvariables are tested according to the same order.\nBelow, we prove upper and lower bound results for QOBDDs. Before we do that, we discuss\nthe definition of QOBDDs and their relationship to quantum finite automata. Furthermore,\nwe define complexity classes in terms of the size of QOBDDs and compare them with the\ncorresponding complexity classes for OBDDs.\n27\n\n\fSince on each path from the start node to a sink each variable is tested at most once, QOBDDs\nare always acyclic. Because of the definition of QBPs, also QOBDDs are unidirectional. Different from Definition 6.1, Ablayev, Gainutdinova, and Karpinski [1] require QOBDDs to be\nleveled such that there are edges only between adjacent levels. Proposition 2.10 shows that this\nrestriction is not crucial, because QOBDDs according to Definition 6.1 can be transformed into\nleveled QOBDDs where the size increases by a factor of at most (n + 1)2 .\nDespite their superficial similarity, there are some important differences between QOBDDs and\n(1-way) quantum finite automata (QFAs). At the definition level, observe that, unlike QFAs,\nQOBDDs may read their input in an order different from x1 , . . . , xn . Furthermore, they are a\nnonuniform model while QFAs are uniform. This implies two less obvious differences between\nQOBDDs and QFAs. In general, measuring whether the computation has stopped and, if yes,\nwith which result, is allowed also during the computation of a QOBDD. The more restrictive\ndefinition that allows end nodes to be reached only after exactly n computation steps have been\nperformed is equivalent to our definition because of Proposition 2.10. On the other hand, it\nis known that QFAs with and without such intermediate measurements are of different power\n(Kondacs and Watrous [20]). Furthermore, one can decrease the error probability of a QOBDD\nwith bounded error by probability amplification below any given constant, as for randomized\nOBDDs (see [42] for the randomized case). Again, this does not work for QFAs: Ambainis and\nFreivalds [7] have shown that the language {a}\u2217 {b}\u2217 can be recognized by QFAs with two-sided\nerror 0.318, but not with error smaller than 2/9.\nFor QOBDDs, we distinguish the same types of error as for general QBPs (see Definition 2.5).\nFor characterizing the relative power of the resulting different types of QOBDDs, it is useful to\ndefine complexity classes with a naming convention analogous to that used for QTMs. The class\nof functions that can be computed exactly by polynomial size QOBDDs is called EQP-OBDD,\nand the class of functions with polynomial size zero error (bounded-error) QOBDDs is called\nZQP-OBDD (BQP-OBDD). Similarly, the classes P-OBDD and BPP-OBDD of functions with\npolynomial size deterministic OBDDs and polynomial size randomized OBDDs with bounded\nerror are defined. Furthermore, let Rev-OBDD denote the class of functions with polynomial size\nreversible OBDDs. The inclusions Rev-OBDD \u2286 EQP-OBDD \u2286 ZQP-OBDD \u2286 BQP-OBDD\nand Rev-OBDD \u2286 P-OBDD \u2286 BPP-OBDD immediately follow from the definitions.\n\nIn this section we present simple, concrete example functions in order to prove that QOBDDs\nwith bounded error and classical, deterministic OBDDs are incomparable in power, i. e.,\nP-OBDD 6\u2286 BQP-OBDD and BQP-OBDD 6\u2286 P-OBDD. We also present a partially defined\nfunction in order to show a similar result for QOBDDs and classical, randomized OBDDs for\npartial functions. Finally, we study the power of zero error and exact quantum computation\nfor OBDDs. We prove that ZQP-OBDD \u2286 Rev-OBDD, i. e., zero error QOBDDs can at best\nbe as good as reversible OBDDs. This implies that the three classes Rev-OBDD, EQP-OBDD,\nand ZQP-OBDD coincide and are strictly contained in P-OBDD.\n6.1. A Function with Small QOBDDs that Requires Large Deterministic OBDDs\nThe permutation matrix test function PERMn is defined on n2 boolean variables that are arranged in a quadratic matrix. The function takes the value 1 iff each row and each column\ncontains exactly one entry 1. It is well-known that PERM = (PERMn )n\u2208N does not have polynomial size read-once branching programs (Krause, Meinel and Waack [21]) and, therefore, no\npolynomial size OBDDs either. In [33] (see also [42]), a polynomial size randomized OBDD\nwith one-sided error for PERM has been designed using the so-called fingerprinting technique.\nWe show here how this construction can be modified to work for QOBDDs.\n28\n\n\fLet X P\ndenote the input matrix and let xj = (xj,0 , . . . , xj,n\u22121 ) denote the jth row of X. Let\n|xj | = k xj,k 2k denote the value of the jth row interpreted as a binary number. The crucial\nobservation is that\nPERMn (X) = 1 \u21d4\n\nn\u22121\nX\nj=0\n\n|xj | \u2212 (2n \u2212 1) = 0 \u2227 each xj contains exactly one entry 1.\n\nPn\u22121\nThe exact evaluation of the sum S = j=0\n|xj | \u2212 (2n \u2212 1) requires OBDDs of exponential size.\nHence, S is evaluated modulo a randomly chosen prime number p. It is straightforward to\nconstruct a reversible OBDD G(p) that evaluates S mod p and simultaneously checks that each\nxj contains exactly one entry 1. In G(p) the variables are tested in a rowwise order. For each\nrow it has to be stored whether an entry 1 has already been found. If a second 1 is found in\nsome row, a 0-sink is reached. Furthermore, in each level the OBDD stores the partial sum\nof the terms corresponding to the bits already read. Since the partial sums are only stored\nmodulo p, this increases the width merely by a factor of p. Altogether, each level contains at\nmost 2p interior nodes. Hence, the size of G(p) is O(pn2 ). It only accepts if S mod p is equal to\n0.\nNow we construct a QOBDD G for PERMn . Let m = 2n2 and let p1 , . . . , pm denote the m\nsmallest primes. By the prime number theorem, pm = O(m log m) = O(n2 log n). We construct\nG(1) , . . . , G(pm ) and combine these reversible OBDDs by a node labeled by the first variable\n\u221a\nwith m outgoing c-edges with amplitudes 1/ m leading to the c-successors of the start nodes\nof G(1) , . . . , G(pm ) . This realizes a random choice between G(p1 ) , . . . , G(pm ) . The size of G is\nbounded by O(n6 log n).\nWe estimate the error probability. The sum S is bounded above by n2n . Hence, if S is different\nfrom 0, it has at most n + log n prime factors. Thus the probability of randomly choosing a\nprime dividing S is bounded above by (n + log n)/(2n2 ) \u2264 1/n. This is also an upper bound on\nthe error probability of G. The error is one-sided, i. e., if PERMn (X) = 1, then the QOBDD G\nalways computes 1, while it may err if PERMn (X) = 0. The probability can even be made\nsmaller than 1/p(n) for any polynomial p by increasing the number of primes, which only\nincreases the size of G polynomially. We have proved:\nTheorem 6.2: There are QOBDDs for \u00acPERMn with one-sided error 1/n and size O(n6 log n).\nCorollary 6.3: BQP-OBDD 6\u2286 P-OBDD.\n6.2. Functions with Small Deterministic OBDDs that Require Large QOBDDs\nThe disjointness function and the inner product function are defined by DISJn (x1 , . . . , xn ) =\n(x1 \u2228 x2 ) \u2227 (x3 \u2228 x4 ) \u2227 * * * \u2227 (xn\u22121 \u2228 xn ) and IP(x1 , . . . , xn ) = x1 x2 \u2295 * * * \u2295 xn\u22121 xn , where n\nis an even number. Both functions are extensively investigated in communication complexity,\nsee, e. g., [22]. For the variable order x1 , . . . , xn they have OBDD size O(n), since it suffices to\nstore at most two bits at each level of the OBDD, namely, the value of the variable read in the\nlast step and the value that the function takes on the variables up to the last variable with an\neven index. However, both functions are difficult for QOBDDs and, therefore, also for reversible\nOBDDs, since these OBDD models have difficulties in \"forgetting\" variables read.\nThe lower bound proof uses some ideas due to Nayak [25] based on quantum information\ntheory. We briefly introduce the required notions and facts. For a proper introduction to\nquantum information theory we refer to [26]. Recall that a mixed state of a quantum system\nis a probability distribution of pure quantum states. A mixed state is usually described by\n29\n\n\fits density matrix, which is a positive P\nmatrix with unit trace. The density matrix for the\nprobability distribution (pi , |\u03c6i i)i is \u03c3 = i pi |\u03c6i ih\u03c6i |. A state resulting from the application of\nthe unitary transformation U to the state described by the density matrix \u03c3 is described by the\ndensity matrix U \u03c3U \u2020 . Now assume that (|\u03c8i i)i is an orthonormal basis of eigenvectors of \u03c3 and\nthat \u03bbi is P\nthe eigenvalue belonging to |\u03c8i i. Then the von Neumann entropy of \u03c3 is defined as\nS(\u03c3) = \u2212 i \u03bbi log \u03bbi . The von Neumann entropy is invariant under unitary transformations U ,\ni. e., S(U \u03c3U \u2020 ) = S(\u03c3). Furthermore, if \u03c3 is a density matrix over a (finite-dimensional) Hilbert\nspace H, then S(\u03c3) \u2264 log(dim(H)). Finally, we formally introduce the kind of measurements\nthat are relevant here.\nDefinition 6.4: Let J be a finite index set and let M = (PP\ni )i\u2208J be a family of projection\noperators over the finite-dimensional Hilbert space H with\ni\u2208J Pi = I. Then call M a\nprojective measurement over H with results in J. For any density matrix \u03c3 over H, define the\nprobability of measuring result i \u2208 J in the state described by \u03c3 by Pr{M(\u03c3) = i} = tr(\u03c3Pi ).\nThe following lemma is due to Nayak. In the lemma, H(p) denotes the binary entropy function\ndefined by H(p) = \u2212p log p \u2212 (1 \u2212 p) log(1 \u2212 p).\nLemma 6.5 ([25]): Let \u03c30 and \u03c31 be density matrices over the finite-dimensional Hilbert\nspace H and let \u03c3 = 1/2 * (\u03c30 + \u03c31 ). Suppose there is a projective measurement M = (P0 , P1 )\nover H with results in {0, 1} such that for b \u2208 {0, 1}, Pr{M(\u03c3b ) = b} \u2265 p \u2265 1/2. Then\nS(\u03c3) \u2265 (S(\u03c30 ) + S(\u03c31 ))/2 + (1 \u2212 H(p)).\nNow we are ready to prove the main result of this section, which is stated in the following\ntheorem. The corollary directly follows from the upper bound on the OBDD size mentioned\nabove.\nTheorem 6.6: The size of each QOBDD with bounded error for DISJn or IPn is 2\u03a9(n) .\nCorollary 6.7: P-OBDD 6\u2286 BQP-OBDD.\nProof of Theorem 6.6. We only prove the statement for disjointness, the claim for the inner\nproduct follows in the same way. Let a QOBDD G with some variable order \u03c0 for DISJn\nbe given. W.l.o.g. let G be leveled. Due to the symmetry of the OR-function, we may assume\nw.l.o.g. that for each i \u2208 {1, . . . , n/2} the variable x2i\u22121 is tested before x2i in \u03c0. Let p = 1/2+\u03b5\nbe a lower bound on the success probability of G. We generate random inputs x for DISJn in\nthe following way. Each variable with an odd index gets one of the values 0 and 1 with a\nprobability of 1/2 each. All variables with an even index get the value 0. Let \u03c3(k) denote the\ndensity matrix describing the state of the QOBDD after reading the kth variable with an odd\nindex. By induction we prove S(\u03c3(k)) \u2265 (1 \u2212 H(p))k. Since the state of the QOBDD before\nreading the first randomly chosen variable is a pure state, we have S(\u03c3(0)) = 0. Now let k \u2265 1.\nBy induction hypothesis S(\u03c3(k \u2212 1)) \u2265 (1\u2212 H(p))(k \u2212 1). Let xi be the kth variable with an odd\nindex. Let U0 and U1 be the unitary transformations performed by the QOBDD while reading\nall the variables after the (k \u2212 1)-st variable with an odd index and up to xi inclusively, where\nthe latter gets the value 0 or 1, resp. Since xi is chosen to be 0 or 1 at random,\n\u0011\n1\u0010\nU0 \u03c3(k \u2212 1)U0\u2020 + U1 \u03c3(k \u2212 1)U1\u2020 .\n\u03c3(k) =\n2\n\n30\n\n\fLet U denote the composition of the unitary transformations performed by the QOBDD if the\npartner xi+1 of xi gets the value 1 and all other variables read after xi get the value 0. Then\nthe function DISJn attains the value c \u2208 {0, 1} if xi = c. Let \u03c3 = U \u03c3(k)U \u2020 . Since the QOBDD\ncomputes the function DISJn , the measurement of the QOBDD on \u03c3 yields the result c with\na probability of at least p if xi has the value c. By Lemma 6.5 and the invariance of the von\nNeumann entropy under unitary transformations,\n\u0011\n1\u0010\nS(\u03c3(k)) = S(\u03c3) \u2265\nS(U U0 \u03c3(k \u2212 1)U0\u2020 U \u2020 ) + S(U U1 \u03c3(k \u2212 1)U1\u2020 U \u2020 ) + 1 \u2212 H(p)\n2\n1\n\u2265\n(S(\u03c3(k \u2212 1)) + S(\u03c3(k \u2212 1))) + 1 \u2212 H(p).\n2\nThen the claim follows by the induction hypothesis. We obtain the lower bound (1 \u2212 H(p)) * n/2\non the von Neumann entropy of the density matrix describing the state of G after reading all\nvariables with odd indices. By the above remark, this implies the lower bound 2(1\u2212H(p))*n/2 on\nthe dimension of the state space of G and, therefore, also on the size of G.\n\u0003\n6.3. A Partial Function with Small QOBDDs that Requires Large Randomized\nOBDDs\nAn OBDD or QOBDD for a partially defined function has to compute the correct value of the\nfunction only on the domain of the function, while it may compute an arbitrary result on inputs\noutside the domain. We present a partially defined function with polynomial size QOBDDs but\nonly exponential size randomized OBDDs. The idea behind the construction of the function is\nbased on a result of Raz [31] for communication protocols.\nThe function we consider gets unitary matrices as inputs. In order to obtain a finitely representable function, we redundantly encode sufficiently precise approximations of the desired\nmatrices by boolean variables. The redundancy in the encoding will allow us to prove a lower\nbound for arbitrary variable orders.\nFor the following, fix an even n \u2208 N and let \u03b5 > 0. Let b = 6(n \u2212 1) and let W0 , . . . , Wb\u22121 be\nsome fixed enumeration of the matrices in Gn from Lemma 3.4. Let k = k(n, \u03b5) = O(n2 log(n/\u03b5))\nbe the number from this lemma. For l \u2265 k and m \u2265 b \u2212 1 the universal (\u03b5, l, m)-code of n \u00d7 nmatrices consists of the l(m + 1) boolean variables xi,j , 1 \u2264 i \u2264 l, 1 \u2264 j \u2264 m + 1. For 1 \u2264 i \u2264 l\nlet xi = (xi,1 , . . . , xi,m+1 ) and v(xi ) = xi,1 + * * * + xi,m . Let\n\u001a\nW(v(x1 )+***+v(xi )) mod b , if xi,m+1 = 1;\nUi =\nI,\nif xi,m+1 = 0.\nThen the variable vector x = (x1 , . . . , xl ) encodes the matrix\nW (x) = Ul * Ul\u22121 * * * * * U1 .\nNote that the variables xi,m+1 only switch between W(v(x1 )+***+v(xi )) mod b and the identity matrix. In particular, they do not influence the sum (v(x1 ) + * * * + v(xi )) mod b. By Lemma 3.4,\nfor each unitary n \u00d7 n-matrix U there is a setting to the x-variables such that kU \u2212 W (x)k \u2264 \u03b5.\nIn the following, l is much larger than k such that there are many settings to obtain a certain\nunitary matrix in the product approximating U .\n\n31\n\n\fNow we define the considered function. Let |1i, . . . , |ni be the standard basis of Cn . Let V0\nand V1 denote\n\u221a the subspaces spanned by the first and last n/2 of these basis vectors. Let\n0 < \u03b8 < 1/ 2. The input for the function R\u03b8,l,m,n consists of 3l(m + 1) boolean variables\nai,j , bi,j , ci,j , 1 \u2264 i \u2264 l, 1 \u2264 j \u2264 m + 1, which are interpreted as universal (\u03b5, l, m)-codes for three\nunitary n \u00d7 n-matrices A, B, C, where \u03b5 = 1/(3n). The function takes the value z \u2208 {0, 1} if the\nEuclidean distance between CBA|1i and Vz is at most \u03b8. Otherwise the function is undefined.\nWe first prove the upper bound on the size of QOBDDs.\n\u221a\nTheorem 6.8: Let 0 < \u03b8 < 1/ 2. The function R\u03b8,3k,9kb,n with an input size of N =\n81 k2 b + 9 k = O(n5 log2 n) has QOBDDs with error at most \u03b82 and size O(N 9/5 / log8/5 N ).\nProof. Set l = 3k and m = 9kb. We choose the variable order that starts with the a-variables\nordered as a1,1 , . . , a1,m+1 , a2,1 , . . , a2,m+1 , . . . , al,1 , . . , al,m+1 . Afterwards the b-variables and\nthen the c-variables are tested in analogous orders. We first describe a subgraph GA of the\nQOBDD evaluating the a-variables. Analogous subgraphs GB and GC are constructed for the\nb- and c-variables, resp.\nThe nodes of GA are arranged in bn columns, which we label by (r, s) with 0 \u2264 r \u2264 b \u2212 1 and\n1 \u2264 s \u2264 n, and in levels 1, . . . , l(m + 1) + 1. Let |ri|si|ti be the vector from an orthonormal\nbasis that corresponds to the node of the tth level in column (r, s). The nodes in each of the\nfirst l(m + 1) levels are labeled by the same a-variable according to the variable order. The\nlast level consists of sinks. Let p \u2208 {1, . . . , l}. For j \u2208 {1, . . . , m}, the node labeled by ap,j in\ncolumn (r, s) is left by a single 0-edge with amplitude 1 leading to the node of the next level of\nthe same column and a single 1-edge with amplitude 1 leading to the node of the next level in\ncolumn ((r + 1) mod b, s). For a node labeled by ap,m+1 in column (r, s), a single 0-edge with\namplitude 1 leaving this node leads to the node in column (r, s) of the subsequent level. There\nare 1-edges connecting this node to the nodes of the subsequent level such that the mapping\n|ri|si|ti 7\u2192 |ri(Wr |si)|t + 1i is performed, where t = (p \u2212 1)(m + 1) + m + 1.\n\nIt is easy to verify that the graph GA constructed in this way is well-formed and unidirectional.\nWe evaluate GA according to the semantics of QBPs starting from a node on the first level\nin column (r, s), i. e., with the superposition |ri|si|1i. Then after reading the variable vectors\na1 , . . . , ap , where ai = (ai,1 , . . . , ai,m+1 ), we reach the superposition |r \u2032 i(Up * * * * * U1 |si)|ti with\nr \u2032 = (r + v(a1 ) + * * * + v(ap )) mod b and t = (p \u2212 1)(m + 1) + m + 2.\n\nThe QOBDD for R\u03b8,l,m,n starts with GA , where the node on the first level in column (0, 1) is\nchosen as the start node. Then the amplitude for reaching a node of the (l(m + 1) + 1)-st level\nin column (r, s) of GA is exactly the sth coordinate of A|1i, if r is the sum modulo b of all\na-variables, and 0 otherwise. After reading the a-variables, the value of r is no longer needed;\nhowever, it cannot be erased in a QOBDD. Hence, for each possible value r we add a copy of a\nsubgraph GB processing the variables encoding B in the same way as described before for A.\nThe sink in column (r, s) of the (l(m + 1) + 1)-st level of the subgraph GA for A is identified\nwith the node (0, s) of the rth copy of the subgraph GB for B. Altogether b copies of the\nsubgraph GB are sufficient. In the same way b2 copies of a subgraph GC for processing C are\nsufficient. In each copy of GC , the sink in column (r, s) of the last level is a 0-sink if s \u2264 n/2,\nand a 1-sink otherwise. For each input, there is exactly one copy of GC and exactly one r\nsuch that for all s the amplitude of the node in column (r, s) of the last level equals the sth\ncoordinate of CBA|1i. For all other copies of GC and for all other r the amplitudes are 0.\nLet Ez denote the projection to the subspace Vz . If |yi = CBA|1i has distance at most \u03b8\nfrom the subspace Vz , we have \u03b82 \u2265 k|yi \u2212 Ez |yik2 = 1 \u2212 kEz |yik2 . The equality follows by\nan easy calculation. Hence, the measurement on the level of the sinks leads to the result z\n32\n\n\fwith probability kEz |yik2 \u2265 1 \u2212 \u03b82 . The size of the QOBDD is dominated by the b2 copies\nof GC . Each of these copies has size O(bnN ). Hence, the size can be estimated by O(b3 nN ) =\nO(n9 log2 n) = O(N 9/5 / log8/5 N ).\n\u0003\nIn order to prove the lower bound, we apply arguments from communication complexity (see,\ne. g., [16, 22] for an introduction). We first state a result of Raz [31], who has proved a lower\n0 . Using two rectangular\nbound on the communication complexity for a different function R\u03b8,n\nreductions, which are defined below, we transfer this lower bound to a lower bound on the\ncommunication complexity of R\u03b8,l,m,n for any l \u2265 k and m \u2265 b \u2212 1. Finally, by a standard lower\nbound technique for randomized OBDDs, the lower bound on the communication complexity\nimplies a lower bound on the size of randomized OBDDs.\n0 due to Raz by describing the corresponding communication problem.\nWe define the function R\u03b8,n\n\u221a\nLet 0 < \u03b8 < 1/ 2. The input of Alice consists of a unit vector x \u2208 Rn and two orthogonal\nsubspaces S0 and S1 of Rn of dimension n/2 each. Bob gets an orthogonal real-valued n \u00d7 nmatrix T as input. The output is c \u2208 {0, 1} if T x has distance at most \u03b8 from Sc , and\narbitrary otherwise. We remark that the usual definition of communication complexity can\neasily be extended to the case of infinite input sets which is considered here. Raz has proved\nthe following result.\n\u221a\nTheorem 6.9 ([31]): Let 0 < \u03b8 < 1/ 2. Each randomized communication protocol with\n0\nrequires \u03a9(n1/2 ) bits of communication.\nbounded error for R\u03b8,n\n\nWe note that the considered communication problems are partially defined. On inputs for\nwhich such a problem is not defined, both outputs 0 and 1 are allowed. A partially defined\ncommunication problem on input sets X and Y can also be described by a relation R \u2286 X \u00d7\nY \u00d7 {0, 1}, where (x, y, z) \u2208 R iff z is a valid output for (x, y). In particular, if the problem\nis undefined for (x, y), we have (x, y, 0), (x, y, 1) \u2208 R. A rectangular reduction from R\u2032 \u2286\nX \u2032 \u00d7 Y \u2032 \u00d7 {0, 1} to R \u2286 X \u00d7 Y \u00d7 {0, 1} consists of two mappings f : X \u2032 \u2192 X and g : Y \u2032 \u2192 Y\nsuch that (f (x), g(y), z) \u2208 R \u21d2 (x, y, z) \u2208 R\u2032 . It is easy to see that a lower bound on the\ncommunication complexity for R\u2032 implies the same lower bound for R if there is a rectangular\nreduction from R\u2032 to R.\n0 can easily be reduced to the following infinite precision variant\nWe observe that the problem R\u03b8,n\n\u2032\n\u2032\nconsists of unitary n \u00d7 n-matrices\nof the considered problem R\u03b8,l,m,n . The input of R\u03b8,n\nR\u03b8,n\nA, B and C, where Alice gets A and C, and Bob gets B. Their task is to compute z \u2208 {0, 1}\nif the distance between CBA|1i and Vz is bounded by \u03b8. (Again, V0 = span{|1i, . . . , |n/2i}\n\u2032 . Instead of an\n0\nis a special case of R\u03b8,n\nand V1 = span{|n/2 + 1i, . . . , |ni}.) Obviously, R\u03b8,n\northogonal matrix T , a unitary matrix B is allowed. The vector x and the subspaces V0 and V1\nare now encoded by the unitary matrices A and C. Hence, the lower bound from Theorem 6.9\n\u2032 . The second rectangular reduction is given in the following lemma.\nalso holds for R\u03b8,n\n\u221a\nLemma 6.10: For all constants \u03b8, \u03b8\u2032 with 0 \u2264 \u03b8\u2032 < \u03b8 < 1/ 2, for all l \u2265 k and m \u2265 b \u2212 1,\nand for sufficiently large n, R\u03b8\u2032 \u2032 ,n is reducible to R\u03b8,l,m,n .\n\nProof. Let (A\u2032 , B \u2032 , C \u2032 ) be an arbitrary input for R\u03b8\u2032 \u2032 ,n . We map this input to an input for\nR\u03b8,l,m,n consisting of the universal (\u03b5, l, m)-codes of unitary n \u00d7 n-matrices A, B, C with\nkA \u2212 A\u2032 k \u2264 \u03b5,\n\nkB \u2212 B \u2032 k \u2264 \u03b5,\n\nand kC \u2212 C \u2032 k \u2264 \u03b5,\n\nwhere \u03b5 = 1/(3n). By Lemma 3.4, we can find such an input (A, B, C) for R\u03b8,l,m,n . We show\nthat this mapping is even a rectangular reduction. Let E0 and E1 be the projections on the\nsubspaces V0 and V1 , resp. Let |yi = CBA|1i and |y \u2032 i = C \u2032 B \u2032 A\u2032 |1i.\n33\n\n\fLet w. l. o. g. 0 be a solution of R\u03b8,l,m,n for the input (A, B, C). Then either k|yi \u2212 E0 |yik \u2264 \u03b8,\ni. e., the only valid output is 0, or k|yi \u2212 E0 |yik > \u03b8 \u2227 k|yi \u2212 E1 |yik > \u03b8, i. e., the outputs 0 and\n1 are allowed. This is equivalent to k|yi \u2212 E1 |yik > \u03b8. We prove that 0 is also a solution of the\nproblem R\u03b8\u2032 \u2032 ,n for the input (A\u2032 , B \u2032 , C \u2032 ) by showing that k|y \u2032 i \u2212 E1 |y \u2032 ik > \u03b8\u2032 .\n\nBy the choice of A, B and C and by Proposition 3.6, we obtain k|y \u2032 i \u2212 |yik \u2264 3\u03b5 = 1/n. By\n\u00011/2\nthe assumption, kE0 |yik = k|yi \u2212 E1 |yik > \u03b8. Hence, k|yi \u2212 E0 |yik = 1 \u2212 kE0 |yik2\n<\n\u0001\n1/2\n1 \u2212 \u03b82\nand thus\nkE1 |y \u2032 ik \u2264 kE1 (|y \u2032 i \u2212 |yi)k + kE1 |yik \u2264 k|y \u2032 i \u2212 |yik + k|yi \u2212 E0 |yik <\n\n\u00011/2\n1\n+ 1 \u2212 \u03b82\n.\nn\n\nThis implies k|y \u2032 i \u2212 E1 |y \u2032 ik2 = 1 \u2212 kE1 |y \u2032 ik2 > \u03b82 \u2212 o(1). Since \u03b8\u2032 < \u03b8 and both \u03b8, \u03b8\u2032 are\nconstants, it follows that k|y \u2032 i \u2212 E1 |y \u2032 ik > \u03b8\u2032 for sufficiently large n. Hence, 0 is a solution of\n\u0003\nR\u03b8\u2032 \u2032 ,n for the input (A\u2032 , B \u2032 , C \u2032 ).\nAltogether we obtain a lower bound on the communication complexity of R\u03b8,l,m,n for l \u2265 k and\nm \u2265 b \u2212 1.\n\u221a\nCorollary 6.11: Let 0 < \u03b8 < 1/ 2, l \u2265 k, and m \u2265 b \u2212 1. Each randomized communication\nprotocol with bounded error for R\u03b8,l,m,n where Alice has the matrices A and C and Bob the\nmatrix B requires \u03a9(n1/2 ) bits of communication.\nNow we can prove the second part of the main result of this section, the lower bound on the\nsize of randomized OBDDs with bounded error.\n\u221a\nTheorem 6.12: Let 0 < \u03b8 < 1/ 2. Each randomized OBDD with bounded error for the\n1/5\n1/10\nfunction R\u03b8,3k,9kb,n on N = 81k2 b + 9k = O(n5 log2 n) variables has size 2\u03a9(N / log N ) .\nIt remains open to find an example of a total function with polynomial size QOBDDs but only\nexponential size randomized OBDDs. Using the currently available techniques, this seems to\nbe difficult since the known lower bound techniques for randomized OBDDs, which are based\non randomized communication complexity, also work in the quantum case (see Klauck [19]).\nProof of Theorem 6.12. Let G be a given randomized OBDD for R\u03b8,l,m,n with l = 3k and\nm = 9kb and with an arbitrary variable order. In general, the variables encoding the matrices\nA, B, and C do not occur as contiguous groups in the variable order. Because of the redundancy\nof the encoding of the matrices we can construct a suborder where the variables of each of the\nencodings of A, B, and C are grouped together such that the corresponding subproblem of\nR\u03b8,l,m,n is still hard. Then we can apply the above communication complexity lower bound.\nLet \u03c0 denote the order of the variables ai,j , bi,j , ci,j , 1 \u2264 i \u2264 l, 1 \u2264 j \u2264 m, in G. For A (and\nsimilarly B and C) call each set of variables ai,1 , . . . , ai,m in its encoding a block. The variables\nai,m+1 , bi,m+1 , and ci,m+1 do not occur in any block or in \u03c0.\nClaim. There is a suborder \u03c0 \u2032 of \u03c0 such that for each matrix of A, B and C there are exactly k\nconsecutive blocks in \u03c0 \u2032 that each contain exactly b variables.\nProof of the claim. Think of \u03c0 as a list of all variables (except ai,m+1 , bi,m+1 , and ci,m+1 ) in the\nprescribed order. Observe that there are 9k blocks of m = 9kb variables each encoding some\nmatrix from the set Gn .\n\n34\n\n\fWe divide \u03c0 into 9k contiguous parts such that for each block there is a part that contains\nat least b of its variables and such that for different blocks there are different parts with this\nproperty. The first of these parts is chosen by searching for the first position in the variable\norder \u03c0 where for some block b variables have been tested (and hence for all other blocks less\nthan b variables have been tested). Then this block is chosen and the other variables up to\nthe chosen position are eliminated. Furthermore, all other variables of the chosen block are\neliminated. An easy induction shows that this procedure can be iterated until 9k parts are\nchosen. Thus we are left with 9k smaller blocks with exactly b variables each and such that for\neach original block there is a smaller block in the list.\nWe now use the same idea to partition the list of variable blocks obtained in the first step into\nthree parts such that for each of the three matrices there is a part containing at least k of its\nblocks and such that for different matrices there are different parts with this property. Again we\neliminate variables in order to ensure that for each matrix exactly k consecutive blocks remain\nin the variable order. In this way, we obtain a variable order \u03c0 \u2032 with the desired properties. \u0003\nWe replace all eliminated variables with 0 and remove the nodes labeled by these variables in the\nrandomized OBDD and redirect incoming edges to the 0-successor. Furthermore, if all variables\nai,1 , . . . , ai,m of a block are eliminated, we also replace ai,m+1 with 0 and modify the randomized\nOBDD accordingly. The same is done for the eliminated blocks of b- and c-variables. This yields\na randomized OBDD G\u2032 for R\u03b8,k,b,n that is at most as large as G.\nWe prove the desired lower bound for G\u2032 using the standard lower bound technique for randomized OBDDs (see, e. g., [42]). Observe that the variable order \u03c0 \u2032 consists of three parts belonging\nto the different matrices A, B, C in some arbitrary order. Let C1 be the set of nodes which are\nreached by some path on which exactly the variables for the first matrix according to \u03c0 \u2032 have\nbeen tested, and let C2 be the set of nodes which are reached by some path on which exactly\nthe variables in the first two matrices have been tested. The OBDD can be used to build a\nrandomized one- or two-round communication protocol for R\u03b8,k,b,n where Alice has the variables\nfor A and C and Bob the variables for B. The players jointly follow a computation path in the\nOBDD from the start node to a sink, using random bits for decisions at random nodes of the\nOBDD and communicating the numbers of nodes in the sets C1 and C2 . The communication\ncomplexity of this protocol is bounded by \u2308log |C1 |\u2309 + \u2308log |C2 |\u2309 \u2264 2(log |G\u2032 | + 1). Together with\nCorollary 6.11, this yields the claimed lower bound.\n\u0003\n6.4. Las Vegas QOBDDs Versus Reversible OBDDs\nThe main result of this section is that ZQP-OBDD \u2286 Rev-OBDD. This means that even the\nzero-error QOBDD model with some failure probability is no more powerful with respect to\npolynomial size than reversible OBDDs.\nThe essence of the proof is as follows. Given a reversible OBDD G and a Las Vegas QOBDD G\u2032\nfor the same function and with the same variable order, we show that G\u2032 induces collections\nof measurements, called measurement schemes here, that allow to distinguish the subfunctions\nrepresented at each of the levels of G. We further prove that for such a measurement scheme, the\ndimension of the underlying Hilbert space can be lower bounded in terms of the number of those\nsubfunctions. Altogether, we obtain a lower bound on the size of the Las Vegas QOBDD G\u2032 in\nterms of the size of the reversible OBDD G.\nDefinition 6.13: Let H be a finite-dimensional Hilbert space and let |v1 i, . . . , |vm i \u2208 H be\ndifferent pure quantum states. Let X = {1, . . . , m} and Y = {1, . . . , n}. Call an m \u00d7 n-matrix\nA = (aij ) with entries in {0, 1, \u2217} and projective measurements Mj = (Mj,0 , Mj,1 , Mj,? ) with\n35\n\n\fpossible results {0, 1, ?}, where j = 1, . . . , n, a measurement scheme for |v1 i, . . . , |vm i with zero\nerror and failure probability \u03b5, 0 \u2264 \u03b5 < 1, if\n\n(i)\n\nfor all different i, j \u2208 X there is a k \u2208 Y such that aik , ajk \u2208 {0, 1} and aik 6= ajk ;\n\n(ii) for all i \u2208 X and j \u2208 Y , if aij = \u2217, then aik = \u2217 for all j \u2264 k \u2264 n; and\n\n(iii) for all i \u2208 X and j \u2208 Y , if aij \u2208 {0, 1}, then Pr{Mj (|vi i) = aij } \u2265 1 \u2212 \u03b5 and\nPr{Mj (|vi i) = \u00acaij } = 0.\nA measurement scheme allows us to distinguish any pair of vectors from |v1 i, . . . , |vm i \u2208 H by\nzero error measurements. Our aim is to prove a lower bound on the dimension of H in terms\nof m. For this, we use the following lemma due to Klauck [19], which is a Las Vegas variant of\nLemma 6.5.\nLemma 6.14 ([19]): Let \u03c30 , \u03c31 be density matrices over H and let 0 \u2264 p \u2264 1. Suppose that\nthere is a projective measurement M = (M0 , M1 , M? ) with possible results {0, 1, ?} such that\nPr{M(\u03c3b ) = b} \u2265 1 \u2212 \u03b5 and Pr{M(\u03c3b ) = \u00acb} = 0 for all b \u2208 {0, 1}. Let \u03c3 = p\u03c30 + (1 \u2212 p)\u03c31 .\nThen S(\u03c3) \u2265 pS(\u03c30 ) + (1 \u2212 p)S(\u03c31 ) + (1 \u2212 \u03b5)H(p).\nThe following lemma extends a result of Klauck [19] that gives a lower bound on the Las Vegas\none-way quantum communication complexity in terms of deterministic one-way communication complexity. The proof of Klauck provides the main idea of the proof of Lemma 6.15 for\nmeasurement schemes without \"\u2217\"-entries.\nLemma 6.15: Let |v1 i, . . . , |vm i \u2208 H be different pure quantum states. If there is a measurement scheme for |v1 i, . . . , |vm i with zero error and failure probability \u03b5, then dim(H) \u2265 m1\u2212\u03b5 .\nProof. Let A be the m \u00d7 n-matrix with entries from {0, 1, \u2217}, and let M1 , . . . , Mn be the projective measurements in the given measurement scheme for |v1 i, . . . , |vm i. Let X = {1, . . . , m}\nand Y = {1, . . . , n}. Call two rows of a A distinguishable if they differ in a column where both\nof them have boolean values. Thus the rows of A are pairwise distinguishable according to the\nhypothesis.\nIn the following we inductively define a mixed state over H with large von Neumann entropy\nin order to obtain the lower bound on the dimension of H. The mixed states that we consider\nare convex combinations of the pure states \u03c3i = |vi ihvi |, i = 1, . . . , m. For any I \u2286 X, j \u2208 Y ,\nand b \u2208 {0, 1} let Ij,b = {i \u2208 I | aij = b}.\n(i) For I \u2286 X with |I| \u2265 2 and j \u2208 Y such that all rows in the submatrix I \u00d7 {j, j + 1, . . . , n}\nof A are distinguishable, let \u03c3(I, j) = (|Ij,1 |/|I|) * \u03c3(Ij,1 , j + 1) + (|Ij,0 |/|I|) * \u03c3(Ij,0 , j + 1).\n(ii) Let \u03c3({i}, j) = \u03c3i for i \u2208 X and 1 \u2264 j \u2264 n + 1.\n\nIf the rows in the submatrix I \u00d7 {j, j + 1, . . . , n} of A are distinguishable, by condition (ii) of\nDefinition 6.13 the jth column of the submatrix only contains the entries 0 and 1: If it contained\nan entry \"\u2217\", the whole row would consist of \"\u2217\" and would thus not be distinguishable from\nthe other rows. It follows that \u03c3(X, 1) is well defined by a recursive application of the above\ndefinition, since (by induction), all rows in I are pairwise distinguishable as long as |I| \u2265 2,\nin which case part (i) is applicable. After some applications of part (i), finally part (ii) is\napplicable.\nClaim. For each I \u2286 X and j \u2208 Y such that all rows in the submatrix I \u00d7 {j, j + 1, . . . , n} of\nA are distinguishable, S(\u03c3(I, j)) \u2265 (1 \u2212 \u03b5) log |I|.\n\n36\n\n\fBy the claim S(\u03c3(X, 1)) \u2265 (1 \u2212 \u03b5) log m and dim(H) \u2265 2S(\u03c3(X,1)) \u2265 m1\u2212\u03b5 , which implies\nLemma 6.15. It remains to prove the claim by an induction on the definition of \u03c3(I, j).\nInduction base (Part (ii) of the definition): Then S(\u03c3({i}, j)) = 0 for all i \u2208 X and 1 \u2264 j \u2264 n+1.\nInduction step (Part (i) of the definition): We consider \u03c3(I, j) = p * \u03c3(Ij,0 , j + 1) +\n(1 \u2212 p) * \u03c3(Ij,1 , jP\n+ 1), where p = |Ij,0 |/|I|. Observe that I = Ij,0 \u222a Ij,1Pand that for b \u2208 {0, 1},\n\u03c3(Ij,b , j + 1) = i\u2208Ij,b pi \u03c3i for suitable probabilities pi , i \u2208 Ij,b , with i\u2208Ij,b pi = 1 (the latter\ncan also be proved by an easy induction on the definition of the \u03c3(I, j)). Thus, applying the\nmeasurement Mj to \u03c3(Ij,b , j + 1) yields\nPr{Mj (\u03c3(Ij,b , j + 1)) = b} \u2265 1 \u2212 \u03b5 and\n\nPr{Mj (\u03c3(Ij,b , j + 1)) = \u00acb} = 0.\n\nBy Lemma 6.14, this implies\nS(\u03c3(I, j)) \u2265 p * S(\u03c3(Ij,0 , j + 1)) + (1 \u2212 p) * S(\u03c3(Ij,1 , j + 1)) + (1 \u2212 \u03b5)H(p).\nBy the induction hypothesis, S(\u03c3(Ij,b , j + 1)) \u2265 (1 \u2212 \u03b5) log |Ij,b | for b \u2208 {0, 1}. Thus,\nS(\u03c3(I, j)) \u2265 p(1 \u2212 \u03b5) log |Ij,0 | + (1 \u2212 p)(1 \u2212 \u03b5) log |Ij,1 | + (1 \u2212 \u03b5)H(p)\n\u0001\n= (1 \u2212 \u03b5) p log |Ij,0 | + (1 \u2212 p) log |Ij,1 | + H(p) .\n\nUsing that p|I| = |Ij,0 | and (1 \u2212 p)|I| = |Ij,1 |, we get\n\n\u0001\nS(\u03c3(I, j) \u2265 (1 \u2212 \u03b5) p log(p|I|) + (1 \u2212 p) log((1 \u2212 p)|I|) + H(p)\n\u0001\n= (1 \u2212 \u03b5) p log p + (1 \u2212 p) log(1 \u2212 p) + H(p) + log |I| = (1 \u2212 \u03b5) log |I|,\n\nas desired. This completes the proof of the claim and thus the proof of Lemma 6.15.\n\n\u0003\n\nNow we can state and prove the main result.\nTheorem 6.16: Let G be a minimum size, leveled, reversible \u03c0-OBDD for f . Let G\u2032 be a\nleveled \u03c0-QOBDD that computes f with zero error and failure probability \u03b5, 0 \u2264 \u03b5 < 1. For\ni = 1, . . . , n+1, let Li and L\u2032i be the sets of nodes on level i in G and G\u2032 , resp. Then |L\u2032i | \u2265 |Li |1\u2212\u03b5\nfor i = 1, . . . , n + 1. In particular, |G\u2032 | \u2265 |G|1\u2212\u03b5 .\nCorollary 6.17: Rev-OBDD = EQP-OBDD = ZQP-OBDD.\nProof of Theorem 6.16. W.l.o.g. let G = (V, E) and G\u2032 = (V \u2032 , E \u2032 ) have the variable order\nx1 , . . . , xn . From G and G\u2032 we construct some set of vectors which are intermediate states\nof the computation of G\u2032 . We exploit the relation to G in order to construct a measurement\nscheme for these vectors such that the lower bound follows from Lemma 6.15.\nW. l. o. g. f depends on all variables. Let \u03b4 : V \u2032 \u00d7V \u2032 \u00d7{0, 1} \u2192 C denote the transition amplitudes\nof G\u2032 . Let H be the Hilbert space spanned by an orthonormal basis (|vi)v\u2208V \u2032 whose elements\nare identified with the nodes of G\u2032 . Let s \u2208 V and s\u2032 \u2208 V \u2032 be the start nodes of G and G\u2032 ,\nresp., and let F \u2286 V \u2032 be the set of sinks of G\u2032 . For a partial input assignment a to x1 , . . . , xi ,\nlet |\u03c6(a)i \u2208 H be the superposition reached in G\u2032 by carrying out its computation on a. Let\nMsink = (Msink,0 , Msink,1 , Msink,? ) be the projective measurement of the output\nlabel at the sinks\nP\n\u2032\nin G . For b \u2208 {0, 1}, fix a unitary operator Ub on H such that Ub |vi = w\u2208V \u2032 \u03b4(v, w, b)|wi for\nall v \u2208 V \u2032 \u2212 F . Such an operator exists due to the well-formedness of G\u2032 .\n\n37\n\n\fBy the assumptions of the theorem, Li is the set of all nodes of G reached by partial assignments\nto x1 , . . . , xi\u22121 , for i = 1, . . . , n+1. Observe that L1 = {s} and, since G is leveled and f depends\non all variables, all nodes in Li , 1 \u2264 i \u2264 n, are labeled by xi . For a node v \u2208 V , let fv denote\nthe subfunction of f represented at v according to the usual semantics of deterministic OBDDs.\nWe recursively construct mappings asni for i = 1, . . . , n + 1 such that asni maps a node v \u2208 Li\nto a partial assignment to x1 , . . . , xi\u22121 reaching that node from the start node of G. First, we\nchoose asn1 (s) as the empty assignment. Next consider a level Li with i > 1. Let v1 , . . . , vl be all\nnodes representing one of the subfunctions fsub represented at nodes in Li . Since G is reversible\nand of minimum size, there are a constant b \u2208 {0, 1} and different nodes u1 , . . . , ul \u2208 Li\u22121\nsuch that (fuj )|xi\u22121 =b = fsub and there is a b-edge from uj to vj for j = 1, . . . , l. Define\nasni (vj ) = (asni\u22121 (uj ), b) for j = 1, . . . , l. For i = 1, . . . , n + 1, let Ci = {|\u03c6(asni (v))i | v \u2208 Li }.\nClaim. For each i = 1, . . . , n + 1, there is a measurement scheme for Ci with zero error and\nfailure probability \u03b5.\nBy Lemma 6.15, the claim implies |L\u2032i | \u2265 dim(span(Ci )) \u2265 |Li |1\u2212\u03b5 and thus the first part of\nthe theorem. Since (x1 + * * * + xk )c \u2265 xc1 + * * * + xck for all c \u2265 1 and x1 , . . . , xk \u2208 R+\n0 , also\n|G\u2032 | \u2265 |G|1\u2212\u03b5 follows.\nWe prove the claim by induction on i. For i = 1 and C1 = {|\u03c6(asn1 (s))i} = {|s\u2032 i} the empty\nmeasurement scheme has the required properties.\n\nLet i > 1 and Li = {v1 , . . . , vm }. Let Y = {y1 , . . . , yN }, N = 2n\u2212i+1 , be the set of assignments\nto xi , . . . , xn . Define the m \u00d7 N -matrix A = (ajk ) by setting ajk = fvj (yk ) for 1 \u2264 j \u2264 m and\n1 \u2264 k \u2264 N . For k = 1, . . . , N let Mk = (Mk,0 , Mk,1 , Mk,? ) be the projective measurement with\nMk,x = Msink,x Uyk where x \u2208 {0, 1, ?} and Uyk is the unitary transformation carried out by G\u2032\nfor the partial input yk when started on a superposition of the basis vectors (|vi)v\u2208L\u2032i .\nObviously, A is a boolean matrix where two rows j, j \u2032 \u2208 {1, . . . , m} differ iff the corresponding\nsubfunctions fvj and fvj\u2032 differ on an input from Y . Hence, for a each set of pairwise different\nrows of A chosen as representatives for the different subfunctions and vectors in Ci chosen accordingly, the above definitions yield a measurement scheme due to the fact that G\u2032 computes f\nwith zero error and failure probability \u03b5. Our goal is to extend the matrix A and the collection\nof measurements such that we obtain a measurement scheme for all vectors in Ci . We remark\nthat A does not have entries \"\u2217\".\nConsider a subset of rows of A belonging to the same subfunction fsub and thus containing\nidentical vectors. W. l. o. g., let v1 , . . . , vl be the respective nodes in Li representing fsub . Let\nu1 , . . . , ul \u2208 Li\u22121 and b \u2208 {0, 1} be as in the definition of the assignments asni (vj ) above. In\nparticular, b is the same constant for u1 , . . . , ul . Then Ub |\u03c6(asni\u22121 (uj ))i = |\u03c6(asni\u22121 (uj ), b)i =\n|\u03c6(asni (vj ))i. By induction hypothesis, there is measurement scheme for Ci\u22121 . Let D be the\nmatrix of this measurement scheme, which is of size |Ci\u22121 | \u00d7 p for some p. Consider the subscheme for the vectors |\u03c6(asni\u22121 (uj ))i, j = 1, . . . , l, which we obtain from D by deleting the\nrows corresponding to the other vectors. Let this measurement scheme be described by the\nl \u00d7 p-matrix B = (bjk ) and the projective measurements Pk = (Pk,0 , Pk,1 , Pk,? ), k = 1, . . . , p.\n\u2020\n\u2032 , P \u2032 , P \u2032 ), k = 1, . . . , l, by P \u2032 = P\nDefine Pk\u2032 = (Pk,0\nk,x Ub for x \u2208 {0, 1, ?}.\nk,x\nk,?\nk,1\nThen for j \u2208 {1, . . . , l} and k \u2208 {1, . . . , p} such that bjk \u2208 {0, 1},\n\n\u2032\nPr{Pk\u2032 (|\u03c6(asni (vj ))i) = bjk } = kPk,b\n|\u03c6(asni (vj ))ik2 = kPk,bjk Ub\u2020 |\u03c6(asni (vj ))ik2\njk\n\n= kPk,bjk Ub\u2020 Ub |\u03c6(asni\u22121 (uj ))ik2\n\n= Pr{Pk (|\u03c6(asni\u22121 (uj ))i) = bjk }.\n38\n\n\fHence, the measurements Pk\u2032 , k = 1, . . . , p, satisfy property (iii) in the definition of measurement\nschemes with respect to the matrix B.\nLet B1 , . . . , BR be all submatrices of D obtained by the above construction for the different\nsubfunctions of fv , v \u2208 Li . Since in the construction of B1 , . . . , BR no columns of D are\ndeleted, the columns of B1 , . . . , BR are labeled by the same measurements. Hence, we can\nattach the matrices B1 , . . . , BR to A as submatrices in the columns m + 1, . . . , m + p and\nfill up the remaining entries with \"\u2217\" such that the new matrix A\u2032 obtained in this way and\nthe measurements M1 , . . . , MN , P1\u2032 , . . . , Pp\u2032 comprise a measurement scheme for Ci with zero\nerror and failure probability \u03b5. Since A does not have any \"\u2217\"-entries, also property (ii) of\nDefinition 6.13 is fulfilled.\n\u0003\nThe above lower bound on the size of zero error QOBDDs in terms of the size of reversible\nOBDDs is essentially optimal, as the following example shows. For n = 2l define the index\nfunction INDn : {0, 1}n+l \u2192 {0, 1}P\non variable vectors x = (x0 , . . . , xn\u22121 ) and y = (y0 , . . . , yl\u22121 )\nl\u22121\nby INDn (x, y) = x|y| , where |y| = i=0\nyi 2i .\n\nProposition 6.18: For the variable order \u03c0 described by (x0 , . . . , xn\u22121 , y0 , . . . , yl\u22121 ), each deterministic \u03c0-OBDD representing INDn requires size 2n , while the same function can be computed by zero error \u03c0-QOBDDs with failure probability \u03b5 of size 2(1\u2212\u03b5)n+O(log n) .\nHromkovi\u010d and Schnitger [17] have used a similar function to prove an analogous result for\nclassical Las Vegas and deterministic one-way communication complexity and the special case\nof failure probability \u03b5 = 1/2. The proof of the proposition is by a straightforward adaptation\nof a simple randomized OBDD to the quantum case.\nProof. The lower bound for deterministic OBDDs is well known and follows from the fact that\nINDn has maximal one-way communication complexity with respect to the partition of variables\nwhere Alice obtains x and Bob obtains y. In the following, we briefly sketch the upper bound\nconstruction.\nFor \u03b5 \u2265 1/2, partition x into k = \u230a1/(1 \u2212 \u03b5)\u230b blocks of size approximately (1\u2212\u03b5)n. The QOBDD\nchooses one of these blocks at random by an unlabeled node at the top (which can be removed\n\u221a\nlater on similarly to the proof of Theorem 6.2) with outgoing edges having amplitudes 1/ k.\nThese edges lead to sub-QOBDDs where the complete chosen block is read and stored, which\nrequires a binary tree with O(2(1\u2212\u03b5)n ) nodes for each block. At each leaf of such a tree, append\na tree of size O(n) reading y and computing |y|. Finally, a sink with the correct output value\nis reached if |y| lies in the chosen block, which happens with probability at least 1/k \u2265 1 \u2212 \u03b5.\nOtherwise, the \"?\"-sink is reached.\nFor \u03b5 < 1/2, we select k = \u23081/\u03b5\u2309 blocks of x-variables of size approximately (1 \u2212 \u03b5)n that cover\neach single variable exactly k \u2212 1 times. The rest of the construction is the same as above. The\nfailure probability is obviously bounded above by 1/k \u2264 \u03b5.\n\u0003\n6.5. Comparison of QOBDDs and Read-Once QBPs\nIn this section we observe that, similarly to the classical case, QOBDDs are a more restricted\nmodel of QBPs than read-once QBPs. A function separating these two models with respect to\npolynomial size is the so-called indirect storage access function, which is defined in the following\nway. Let n = 2k . The input of ISAn consists of the variables y0 , . . . , yk\u22121 and x0 , . . . , xn\u22121 .\nThe y-variables are interpreted as a binary number s. The x-variables are partitioned into\nb = \u230an/k\u230b blocks of size k = log n, which are numbered beginning with 0. If s \u2265 b, the output\n39\n\n\fis 0. Otherwise the sth block is again interpreted as a binary number t and the output is xt . It\nis straightforward to construct a decision tree for ISAn of size O(n2 / log n), which can also be\nregarded as a read-once QBP.\nThe lower bound for QOBDDs for all variable orders is a straightforward combination of two\nresults. Klauck [19] proved the lower bound \u03a9(n) on the quantum one-way communication\ncomplexity of INDn , where Alice gets the x-variables and Bob the y-variables. This lower\nbound directly implies the lower bound 2\u03a9(n) on the size QOBDDs for INDn , where the xvariables are tested before the y-variables. Using a rectangular reduction, it has been shown\nin [34] that an OBDD for ISAn and an arbitrary variable order cannot be smaller than an OBDD\nfor IND\u230an/ log n\u230b\u22121 and the variable order mentioned before. This also holds for QOBDDs such\nthat we obtain the lower bound 2\u03a9(n/ log n) on the size for QOBDDs for ISAn and an arbitrary\nvariable order.\n\n7. QBPs with Generalized Measurements\nThe usual unitary quantum mode of computation has turned out to be only of limited use\nfor such restricted models as quantum OBDDs and quantum finite automata. In this section\nwe consider a generalization of QBPs where in each step the performed unitary operation is\ndetermined by the result of a previous measurement. We first present the definition of QBPs\nwith generalized measurements and we discuss the relationship to QBPs and to randomized\nBPs. Afterwards, we prove a generic lower bound on the size of QOBDDs with generalized\nmeasurements for so-called k-stable functions.\nDefinition 7.1: Let k \u2208 N with k \u2265 3. A quantum branching program with generalized measurements (gmQBP) over the variable set X = {x1 , . . . , xn } is a directed multigraph G = (V, E)\nwith a start node s \u2208 V , a set of sinks F \u2286 V , and transition amplitudes \u03b4. Nodes and edges\nare labeled in the same way as in a usual QBP (see Definition 2.4). Additionally, there is a\npartition (V0 , V1 , V2 , . . . , Vk\u22121 ) of V such that V0 and V1 consist of the 0- and 1-sinks of G,\nresp. The edge labels of the gmQBP G have to fulfill the following modified well-formedness\nconstraint. Let u, v \u2208 Vl , l \u2208 {2, . . . , k \u2212 1}, be interior nodes with var(u) = i and var(v) = j,\nresp. Then for all assignments a = (a1 , . . . , an ) to the variables in X,\n\u001a\nX\n1, if u = v;\n\u2217\n(W\u2217 )\n\u03b4 (u, w, ai )\u03b4(v, w, aj ) =\n0, otherwise.\nw\u2208V\n\nFurthermore, gmQBPs are unidirectional, i. e., for each w \u2208 V , all v \u2208 V for which a b \u2208 {0, 1}\nexists such that \u03b4(v, w, b) 6= 0 are labeled by the same variable.\nWe remark that the well-formedness condition for gmQBPs is weaker than the well-formedness\ncondition for ordinary QBPs, because it has only to hold for pairs of nodes of the same set Vl .\nWe now define the semantics of gmQBPs. As in the definition of usual QBPs, nodes correspond to vectors in an orthonormal basis (|vi)v\u2208V of H = C|V | and intermediate results of the\ncomputation are superpositions of these vectors. As for QBPs, a computation step consists of\na measurement and the subsequent transition to successor nodes according to the transition\namplitudes \u03b4. In a gmQBP, the measurement generalizes that allowed for QBPs as follows.\nThe gmQBP performs the projective measurement M = (P0 , P1 , P2 , . . . , Pk\u22121 ) with results\n{0, 1, 2 . . . , k \u2212 1}, where\nX\n|vihv|, r \u2208 {0, 1, 2, . . . , k \u2212 1}.\nPr =\nv\u2208Vr\n\n40\n\n\fThe probability of obtaining the result r is kPr |vik2 . If the result r is 0 or 1, the computation\nstops with output r. If r \u2265 2, the computation continues with the normalized projection\nX\nPr |\u03c8i\n\u03b1v |vi.\n=\n|\u03c8 \u2032 i =\nkPr |\u03c8ik\nv\u2208Vr\n\nThen for each node v \u2208 Vr with var(v) = i the gmQBP follows the edges with boolean label ai\naccording to their amplitudes. This yields the new superposition\nX\nX\n\u03b4(v, w, avar(v) )|wi.\n\u03b1v\n|\u03c8 \u2032\u2032 i =\nv\u2208Vr\n\nw\u2208V\n\nThe above definition does not allow \"?\" outputs for simplicity, since we do not consider\nLas Vegas gmQBPs, anyway. The modified well-formedness constraint implies that for each\nresult of the measurement the corresponding mapping can be extended to a unitary transformation. Computation time and acceptance modes are defined analogously to QBPs. Also the\ndefinition of QOBDDs with generalized measurements (gmQOBDDs) is straightforward: The\nvariables are required to be tested according to a fixed variable order. We remark that gmQBPs\nhave a simple graphic representation. Additionally to the representation of QBPs there is merely\na partition of the nodes.\nThe physical realizability of gmQBPs depends on the ability to perform measurements during\na computation. Based on a standard argument using Neumark's theorem (see, e. g., [29]),\nsuch measurements can be described by unitary transformations in an extended Hilbert space.\nFurthermore, intermediate measurements are also possible, e. g., in the quantum circuit model\ndefined in the textbook of Nielsen and Chuang [26] as well as in the model of Aharonov, Kitaev\nand Nisan [4] which allows gates computing general quantum operations (superoperators).\nIt is obvious that a QBP is a gmQBP with three possible measurement results. We show that\nrandomized BPs can easily be transformed into gmQBPs.\nProposition 7.2: For each randomized BP G computing some function f there is a gmQBP G\u2032\ncomputing the same function with the same acceptance mode, and the size of G\u2032 is bounded above\nby the size of G.\nProof. We remove all randomized nodes from G by allowing each node to have several outgoing\n0- and 1-edges labeled by appropriate probabilities. In the corresponding gmQBP there are the\n\u221a\nsame edges, where the probability p is replaced with the amplitude p. The partition of the\nnode set consists of the set of 0-sinks, the set of 1-sinks and sets each containing exactly one\ninterior node. An easy induction shows that for each input the acceptance probabilities of G\nand G\u2032 coincide.\n\u0003\nWith the currently available techniques we cannot prove superpolynomial lower bounds for BPs\nand for QBPs either (cf. Proposition 2.7). Thus we are not able to prove that polynomial size\ngmQBPs are more powerful than polynomial size QBPs. However, for QOBDDs this is easy,\neven for k = 4, i. e., the smallest k where gmQOBDDs are a generalization of QOBDDs. In\nTheorem 6.6 we have proved exponential lower bounds on the size of QOBDDs for the function\nDISJ and IP. On the other hand, it is easy to construct linear size deterministic OBDDs for\nDISJ and IP. A careful inspection shows that each node of these OBDDs has at most two\nincoming 0-edges and at most one incoming 1-edge. We partition the internal nodes into two\nsets V2 and V3 such that each pair of nodes with the same 0-successor is not in the same set.\nFurthermore, by duplicating the sinks we ensure that each sink has at most one predecessor.\nThe sets V0 and V1 are the sets of 0- and 1-sinks, resp., that are obtained in this way. We obtain\nthe following result.\n41\n\n\fProposition 7.3: There are gmQOBDDs of linear size with k = 4 possible measurement results\nthat exactly compute DISJn and IPn .\nFinally, we prove a generic lower bound on the size of gmQOBDDs for k-stable functions. A\nfunction f : {0, 1}n \u2192 {0, 1} is called k-stable if for each set V of variables of size k and each\nvariable xi \u2208 V there is a setting of the variables outside V such that the resulting subfunction\nis xi or xi . It is well known that k-stable functions only have read-once branching programs\nof size 2k\u22121 , and it has been shown in [34] that also randomized OBDDs require size 2\u03a9(k) .\nExamples for such functions include the determinant of an n \u00d7 n-matrix over Z2 , which is\n(n \u2212 1)-stable, and the function checking whether a graph on n vertices has an n/2-clique,\nwhich is (n/4 + 1)-stable. For these and other examples, see Wegener [42].\nWe remark that the state of a gmQOBDD after performing a measurement during a computation\ncan be described as a mixed state, i. e., a probability distribution over pure states. Now we can\napply a lower bound on the quantum communication complexity for the index function (defined\nat the end of Section 6.4) due to Klauck [19].\nTheorem 7.4: Each gmQOBDD with bounded error for a k-stable functions has size 2\u03a9(k) .\nProof. W. l. o. g. let k = 2l . Klauck [19] has observed that the quantum one-way communication\ncomplexity of the function INDk is lower bounded by \u03a9(k) for the partition where the first player\nAlice gets the input vector x = (x0 , . . . , xk\u22121 ) and the second player Bob gets y = (y0 , . . . , yl\u22121 ).\nThis lower bound also holds for the two-sided error model and if Alice may send a mixed state\nto Bob. Let a gmQOBDD for a k-stable function f be given. Then INDk can be computed\nby a quantum one-way protocol in the following way: Alice may choose the first k variables in\nthe variable order and Bob the remaining variables. By the property of k-stable functions, for\neach of Alice's variables, Bob can fix his variables such that the gmQOBDD outputs the value\nof the variable or its complement. Hence, it suffices for Alice to perform the computation of\nthe gmQOBDDs of the first k levels for the given setting of her x-variables and to send the\n(mixed) state of the gmQOBDD after her computation to Bob. Bob can then compute the\noutput as described. The communication complexity is bounded above by the logarithm of the\nsize (or even the width) of the gmQOBDD. Together with the lower bound on the quantum\ncommunication complexity for INDk , the theorem follows.\n\u0003\n\n8. Open Problems\nIn this paper, we have explored the foundations of space-bounded nonuniform quantum complexity to some extent, but several interesting problems nevertheless remain open.\n\u2013 It is not clear whether algebraic amplitudes for nonuniform QTMs and short amplitudes for\nQBPs are the most general reasonable sets of amplitudes. Is it possible to provide some formal\nargument that excludes more general sets of amplitudes (as done by Adleman, DeMarrais,\nand Huang [3] for the uniform case and arbitrary complex amplitudes)?\n\u2013 For space-bounded nonuniform QTMs with algebraic amplitudes we have proved that the\ngeneral model can be simulated by the unidirectional one. It is open so far whether an analogous simulation also exists for the uniform case. Furthermore, for QBPs it is straightforward\nto define a variant without the requirement of unidirectionality. Can this generalized model\nbe simulated by the unidirectional model or is it unreasonably powerful?\n\n42\n\n\f\u2013 It remains open whether there is a space-efficient simulation of QBPs by nonuniform QTMs for\nthe cases of error-free and exact quantum computation and, if not, to provide some evidence\nshowing that such a simulation is unlikely to exist.\n\u2013 With respect to the comparison of OBDDs and QOBDDs, the relationship between the classes\nBQP-OBDD and BPP-OBDD for total functions is left open.\n\u2013 Prove lower bounds for more general variants of QBPs. While lower bounds for QOBDDs\ncan be obtained using tools from quantum communication complexity, already the proof of\nlower bounds for (possibly unordered) read-once QBPs seems to require new arguments.\n\u2013 The model of gmQBPs remains largely open to investigation. In particular, the relationship\nbetween the standard model of QBPs and gmQBPs needs to be further clarified. Show\nseparation results as that for QOBDDs and gmQOBDDs presented here also for more general\nvariants of QBPs or investigate simulations of gmQBPs by usual QBPs.\n\nReferences\n[1] F. M. Ablayev, A. Gainutdinova, and M. Karpinski. On computational power of quantum\nbranching programs. In Proc. of 13th Conf. on Fundamentals of Computation Theory,\nLNCS 2138, 59\u201370. Springer, Berlin, 2001. http://arxiv.org/pdf/quant-ph/0302022.\n[2] F. M. Ablayev, C. Moore, and C. Pollett. Quantum and stochastic branching programs\nof bounded width. In Proc. of 29th ICALP, LNCS 2380, 343\u2013354. Springer, Berlin, 2002.\nhttp://eccc.uni-trier.de/eccc-reports/2002/TR02-013.\n[3] L. M. Adleman, J. Demarrais, and M.-D. Huang. Quantum computability. SIAM Journal\nof Computing, 26(5):1524\u20131540, 1997.\n[4] D. Aharonov, A. Kitaev, and N. Nisan. Quantum circuits with mixed states. In Proc. of\n30th STOC, 20\u201330, 1998. http://arxiv.org/abs/quant-ph/9806029.\n[5] M. Ajtai. Determinism versus nondeterminism for linear time RAMs with memory restrictions.\nJournal of Computer and System Sciences, 65(1): 2\u201337, 2002.\nhttp://www.eccc.uni-trier.de/eccc-reports/1998/TR98-077.\n[6] M. Ajtai. A non-linear time lower bound for Boolean branching programs. In Proc. of 40th\nFOCS, 60\u201370, 1999. http://www.eccc.uni-trier.de/eccc-reports/1999/TR99-026.\n[7] A. Ambainis and R. Freivalds. 1-way quantum finite automata: strengths, weaknesses and\ngeneralizations. In Proc. of 39th FOCS, 332\u2013341, 1998.\nhttp://arxiv.org/abs/quant-ph/9802062.\n[8] P. Beame, T. S. Jayram, and M. Saks. Time-space tradeoffs for branching programs.\nJournal of Computer and System Sciences, 63(4):542\u2013572, 2001.\nhttp://eccc.uni-trier.de/eccc-reports/1998/TR98-053.\n[9] P. Beame, M. Saks, X. Sun, and E. Vee. Time-space trade-off lower bounds for randomized computation of decision problems. Journal of the ACM, 50(2):154\u2013195, 2003.\nhttp://eccc.uni-trier.de/eccc-reports/2000/TR00-025.\n[10] P. Beame and E. Vee. Time-space tradeoffs, multiparty communication complexity, and\nnearest neighbor problems. In Proc. of 34th STOC, 688\u2013697, 2002.\n\n43\n\n\f[11] E. Bernstein and U. Vazirani. Quantum complexity theory. SIAM Journal of Computing,\n26(5):1411\u20131473, 1997.\n[12] A. Cobham. The recognition problem for the set of perfect squares. In Proc. of the 7th\nSymposium on Switching and Automata Theory, 78\u201387, 1966.\n[13] J. Gruska. Quantum Computing. McGraw-Hill, London, 1999.\n[14] A. W. Harrow, B. Recht, and I. L. Chuang. Efficient discrete approximations of quantum\ngates. Journal of Mathematical Physics, 43(9):4445\u20134451, 2002.\nhttp://arxiv.org/abs/quant-ph/0111031.\n[15] A. S. Householder. The Theory of Matrices in Numerical Analysis. Blaisdell Publishing\nCompany, New York, NY, second printing, 1965.\n[16] J. Hromkovi\u010d. Communication Complexity and Parallel Computing. EATCS Texts in\nTheoretical Computer Science. Springer, Berlin, 1997.\n[17] J. Hromkovi\u010d and G. Schnitger. On the power of Las Vegas for one-way communication\ncomplexity, OBDDs, and finite automata. Information and Computation, 169(2):284\u2013296,\n2001.\n[18] A. Y. Kitaev, A. H. Shen, and M. N. Vyalyi. Classical and Quantum Computation. American Mathematical Society, Providence, RI, 2002.\n[19] H. Klauck. On quantum and probabilistic communication: Las Vegas and oneway protocols. In Proc. of 32nd STOC, 644\u2013651, 2000.\n[20] A. Kondacs and J. Watrous. On the power of quantum finite state automata. In Proc. of\n38th FOCS, 66\u201375, 1997.\n[21] M. Krause, C. Meinel, and S. Waack. Separating the eraser Turing machine classes Le ,\nNLe , co-NLe and Pe . Theoretical Computer Science, 86:267\u2013275, 1991.\n[22] E. Kushilevitz and N. Nisan. Communication Complexity. Cambridge University Press,\nCambridge, 1997.\n[23] K.-J. Lange, P. McKenzie, and A. Tapp. Reversible space equals deterministic space.\nJournal of Computer and System Sciences, 60(2): 354\u2013367, 2000.\n[24] M. Nakanishi, K. Hamaguchi, and T. Kashiwabara. Ordered quantum branching programs\nare more powerful than ordered probabilistic branching programs under a bounded-width\nrestriction. In Proc. of 6th COCOON, LNCS 1858, 467\u2013476. Springer, Berlin, 2000.\n[25] A. Nayak. Optimal lower bounds for quantum automata and random access codes. In\nProc. of 40th FOCS, 369\u2013377, 1999. http://arxiv.org/abs/quant-ph/9904093.\n[26] M. A. Nielsen and I. L. Chuang. Quantum Computation and Quantum Information. Cambridge University Press, Cambridge, 2000.\n[27] H. Nishimura and M. Ozawa. Computational complexity of uniform quantum circuit families and quantum Turing machines. Theoretical Computer Science, 276:147\u2013181, 2002.\nhttp://arxiv.org/abs/quant-ph/9906095.\n\n44\n\n\f[28] M. Ozawa and H. Nishimura.\nLocal transition functions of quantum Turing\nmachines.\nTheoretical Informatics and Applications (RAIRO), 34:379\u2013402, 2000.\nhttp://arxiv.org/abs/quant-ph/9811069.\n[29] A. Peres. Quantum Theory: Concepts and Methods. Kluwer Academic Publishers, Dordrecht, 1995.\n[30] P. Pudl\u00e1k and S. Z\u00e1k. Space complexity of computations. Technical report, Univ. Prague,\n1983.\n[31] R. Raz. Exponential separation of quantum and classical communication complexity. In\nProc. of 31st STOC, 358\u2013367, 1999. http://arxiv.org/abs/quant-ph/0010057.\n[32] M. Saks. Randomization and derandomization in space-bounded computation. In Proc. of\n11th Conf. on Computational Complexity, 128\u2013149, 1996.\n[33] M. Sauerhoff. Lower bounds for randomized read-k-times branching programs. In Proc. of\n15th STACS, LNCS 1373, 105\u2013115. Springer, Berlin, 1998.\n[34] M. Sauerhoff. On the size of randomized OBDDs and read-once branching programs for\nk-stable functions. Computational Complexity, 10:155\u2013178, 2001.\n[35] P. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms\non a quantum computer.\nSIAM Journal of Computing, 26(5):1484\u20131509, 1997.\nhttp://arxiv.org/abs/quant-ph/9508027.\n[36] J. Simon. Space-bounded probabilistic Turing machine complexity classes are closed under\ncomplement. In Proc. of 13th STOC, 158\u2013167, 1981.\n[37] R. \u0160palek. Space Complexity of Quantum Computation. Master's thesis, Charles University\nPrague, 2002. http://homepages.cwi.nl/~sr/papers/qbp-masters-thesis.ps.gz.\n[38] J. Watrous. Space-Bounded Quantum Computation. Ph. D. thesis, University of Wisconsin,\nMadison, 1998. http://www.cpsc.ucalgary.ca/~jwatrous/papers/thesis.ps.\n[39] J. Watrous. Space-bounded quantum complexity. Journal of Computer and System Sciences, 59:281\u2013326, 1999.\n[40] J. Watrous. On quantum and classical space-bounded processes with algebraic transition\namplitudes. In Proc. of 40th FOCS, 314\u2013324, 1999.\n[41] J. Watrous. On the complexity of simulating space-bounded quantum computations. Computational Complexity, 12:48\u201384, 2003.\n[42] I. Wegener. Branching Programs and Binary Decision Diagrams-Theory and Applications.\nMonographs on Discrete and Applied Mathematics. SIAM, Philadelphia, PA, 2000.\n[43] A. C.-C. Yao. Quantum circuit complexity. In Proc. of 34th FOCS, 352\u2013361, 1993.\n\n45\n\n\f"}