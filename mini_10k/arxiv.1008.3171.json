{"id": "http://arxiv.org/abs/1008.3171v2", "guidislink": true, "updated": "2010-10-07T03:30:14Z", "updated_parsed": [2010, 10, 7, 3, 30, 14, 3, 280, 0], "published": "2010-08-18T20:17:09Z", "published_parsed": [2010, 8, 18, 20, 17, 9, 2, 230, 0], "title": "The Two Quadrillionth Bit of Pi is 0! Distributed Computation of Pi with\n  Apache Hadoop", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1008.1875%2C1008.0789%2C1008.4526%2C1008.4542%2C1008.0892%2C1008.3258%2C1008.1754%2C1008.2217%2C1008.5192%2C1008.2722%2C1008.4606%2C1008.2220%2C1008.1783%2C1008.3389%2C1008.4560%2C1008.4607%2C1008.4929%2C1008.4483%2C1008.1522%2C1008.2676%2C1008.4364%2C1008.2012%2C1008.3041%2C1008.4856%2C1008.3617%2C1008.2316%2C1008.0146%2C1008.0152%2C1008.2178%2C1008.3843%2C1008.5032%2C1008.2352%2C1008.1571%2C1008.0103%2C1008.4042%2C1008.4170%2C1008.3171%2C1008.4424%2C1008.0882%2C1008.3093%2C1008.3968%2C1008.0653%2C1008.2262%2C1008.0995%2C1008.5003%2C1008.2355%2C1008.1800%2C1008.1092%2C1008.0832%2C1008.2094%2C1008.4932%2C1008.5170%2C1008.0686%2C1008.3028%2C1008.3981%2C1008.2765%2C1008.2375%2C1008.4103%2C1008.3575%2C1008.1131%2C1008.1833%2C1008.2349%2C1008.3845%2C1008.0750%2C1008.3377%2C1008.3191%2C1008.1083%2C1008.1645%2C1008.1158%2C1008.0177%2C1008.3768%2C1008.1621%2C1008.0503%2C1008.3320%2C1008.5328%2C1008.1678%2C1008.1790%2C1008.4816%2C1008.2550%2C1008.2686%2C1008.4548%2C1008.4776%2C1008.5261%2C1008.4768%2C1008.3916%2C1008.4311%2C1008.1302%2C1008.0627%2C1008.4917%2C1008.4899%2C1008.0090%2C1008.4008%2C1008.5226%2C1008.1650%2C1008.3855%2C1008.4554%2C1008.0012%2C1008.4757%2C1008.1613%2C1008.2294%2C1008.1000&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The Two Quadrillionth Bit of Pi is 0! Distributed Computation of Pi with\n  Apache Hadoop"}, "summary": "We present a new record on computing specific bits of Pi, the mathematical\nconstant, and discuss performing such computations on Apache Hadoop clusters.\nThe specific bits represented in hexadecimal are 0E6C1294 AED40403 F56D2D76\n4026265B CA98511D 0FCFFAA1 0F4D28B1 BB5392B8. These 256 bits end at the\n2,000,000,000,000,252nd bit position, which doubles the position and quadruples\nthe precision of the previous known record. The position of the first bit is\n1,999,999,999,999,997 and the value of the two quadrillionth bit is 0. The\ncomputation is carried out by a MapReduce program called DistBbp. To\neffectively utilize available cluster resources without monopolizing the whole\ncluster, we develop an elastic computation framework that automatically\nschedules computation slices, each a DistBbp job, as either map-side or\nreduce-side computation based on changing cluster load condition. We have\ncalculated Pi at varying bit positions and precisions, and one of the largest\ncomputations took 23 days of wall clock time and 503 years of CPU time on a\n1000-node cluster.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1008.1875%2C1008.0789%2C1008.4526%2C1008.4542%2C1008.0892%2C1008.3258%2C1008.1754%2C1008.2217%2C1008.5192%2C1008.2722%2C1008.4606%2C1008.2220%2C1008.1783%2C1008.3389%2C1008.4560%2C1008.4607%2C1008.4929%2C1008.4483%2C1008.1522%2C1008.2676%2C1008.4364%2C1008.2012%2C1008.3041%2C1008.4856%2C1008.3617%2C1008.2316%2C1008.0146%2C1008.0152%2C1008.2178%2C1008.3843%2C1008.5032%2C1008.2352%2C1008.1571%2C1008.0103%2C1008.4042%2C1008.4170%2C1008.3171%2C1008.4424%2C1008.0882%2C1008.3093%2C1008.3968%2C1008.0653%2C1008.2262%2C1008.0995%2C1008.5003%2C1008.2355%2C1008.1800%2C1008.1092%2C1008.0832%2C1008.2094%2C1008.4932%2C1008.5170%2C1008.0686%2C1008.3028%2C1008.3981%2C1008.2765%2C1008.2375%2C1008.4103%2C1008.3575%2C1008.1131%2C1008.1833%2C1008.2349%2C1008.3845%2C1008.0750%2C1008.3377%2C1008.3191%2C1008.1083%2C1008.1645%2C1008.1158%2C1008.0177%2C1008.3768%2C1008.1621%2C1008.0503%2C1008.3320%2C1008.5328%2C1008.1678%2C1008.1790%2C1008.4816%2C1008.2550%2C1008.2686%2C1008.4548%2C1008.4776%2C1008.5261%2C1008.4768%2C1008.3916%2C1008.4311%2C1008.1302%2C1008.0627%2C1008.4917%2C1008.4899%2C1008.0090%2C1008.4008%2C1008.5226%2C1008.1650%2C1008.3855%2C1008.4554%2C1008.0012%2C1008.4757%2C1008.1613%2C1008.2294%2C1008.1000&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We present a new record on computing specific bits of Pi, the mathematical\nconstant, and discuss performing such computations on Apache Hadoop clusters.\nThe specific bits represented in hexadecimal are 0E6C1294 AED40403 F56D2D76\n4026265B CA98511D 0FCFFAA1 0F4D28B1 BB5392B8. These 256 bits end at the\n2,000,000,000,000,252nd bit position, which doubles the position and quadruples\nthe precision of the previous known record. The position of the first bit is\n1,999,999,999,999,997 and the value of the two quadrillionth bit is 0. The\ncomputation is carried out by a MapReduce program called DistBbp. To\neffectively utilize available cluster resources without monopolizing the whole\ncluster, we develop an elastic computation framework that automatically\nschedules computation slices, each a DistBbp job, as either map-side or\nreduce-side computation based on changing cluster load condition. We have\ncalculated Pi at varying bit positions and precisions, and one of the largest\ncomputations took 23 days of wall clock time and 503 years of CPU time on a\n1000-node cluster."}, "authors": ["Tsz-Wo Sze"], "author_detail": {"name": "Tsz-Wo Sze"}, "author": "Tsz-Wo Sze", "arxiv_comment": "9 pages, 2 figures, 3 tables", "links": [{"href": "http://arxiv.org/abs/1008.3171v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1008.3171v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.NT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68Q85, 68M14, 11-04", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1008.3171v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1008.3171v2", "journal_reference": null, "doi": null, "fulltext": "The Two Quadrillionth Bit of \u03c0 is 0!\nDistributed Computation of \u03c0 with Apache Hadoop\nTsz-Wo Sze\n\narXiv:1008.3171v2 [cs.DC] 7 Oct 2010\n\nYahoo! Cloud Computing\ntsz@yahoo-inc.com\nOctober 6, 2010\n\nAbstract\nWe present a new record on computing specific bits of \u03c0, the mathematical constant,\nand discuss performing such computations on Apache Hadoop clusters. The specific bits\nrepresented in hexadecimal are\n0E6C1294 AED40403 F56D2D76 4026265B CA98511D 0FCFFAA1 0F4D28B1 BB5392B8.\nThese 256 bits end at the 2, 000, 000, 000, 000, 252nd bit position\u2020 , which doubles the\nposition and quadruples the precision of the previous known record [12]. The position of\nthe first bit is 1, 999, 999, 999, 999, 997 and the value of the two quadrillionth bit is 0.\nThe computation is carried out by a MapReduce program called DistBbp. To effectively utilize available cluster resources without monopolizing the whole cluster, we develop an elastic computation framework that automatically schedules computation slices,\neach a DistBbp job, as either map-side or reduce-side computation based on changing\ncluster load condition. We have calculated \u03c0 at varying bit positions and precisions, and\none of the largest computations took 23 days of wall clock time and 503 years of CPU\ntime on a 1000-node cluster.\n\n1\n\nIntroduction\n\nThe computation of the mathematical constant \u03c0 has drawn a great attention from mathematicians and computer scientists over the centuries [4, 10]. The computation of \u03c0 also\nserves as a vehicle for testing and benchmarking computer systems. There are two types of\nchallenges,\n(i) computing the first n digits of \u03c0, and\n(ii) computing only the nth bit of \u03c0.\nIn this paper, we discuss our experience on computing the nth bit of \u03c0 with Apache Hadoop\n(http://hadoop.apache.org), an open-source distributed computing software. To the best\nof our knowledge, the result obtained by us, the Yahoo! Cloud Computing Team, is a new\nworld record as this paper being written.\n\u2020\nWhen \u03c0 is represented in binary, we have \u03c0 = 11.0010 0100 0011 1111 . . . Bit position is counted starting\nafter the radix point. For example, the eight bits starting at the ninth bit position are 0011 1111 in binary or,\nequivalently, 3F in hexadecimal.\n\n1\n\n\fIn 1996, Bailey, Borwein and Plouffe discovered a new formula (equation (1.1)) to compute\n\u03c0, which is now called the BBP formula [1],\n\u03c0=\n\n\u0012\n\u0013\n\u221e\nX\n1\n4\n2\n1\n1\n.\n\u2212\n\u2212\n\u2212\n24k 8k + 1 8k + 4 8k + 5 8k + 6\n\n(1.1)\n\nk=0\n\nThe remarkable discovery leads to the first digit-extraction algorithm for \u03c0 in base 2. In\nother words, it allows computing the nth bit of \u03c0 without computing the earlier bits. Soon\nafter, Bellard has discovered a faster BBP-type formula [3],\n\u0012\n\u221e\nX\n(\u22121)k\n\n\u0013\n22\n1\n2\u22124\n2\u22124\n2\u22126\n2\u22121\n2\u22126\n\u03c0=\n.\n\u2212\n\u2212\n\u2212\n+\n\u2212\n\u2212\n10k + 1 10k + 3 10k + 5 10k + 7 10k + 9 4k + 1 4k + 3\n210k\nk=0\n(1.2)\nHe computed 152 bits of \u03c0 ending at the 1, 000, 000, 000, 151st bit position in 1997 [2]. The\ncomputation took 12 days with more than 20 workstations and 180 days of CPU time. In 1998,\nPercival started a distributed computing project called PiHex to calculate the five trillionth\nbit, the forty trillionth bit and the quadrillionth bit of \u03c0 [12]. The best result obtained was\n64 bits of \u03c0 ending at the 1, 000, 000, 000, 000, 060th position in 2000. The entire calculation\ntook two years and required 250 CPU years, using idle time slices of 1734 machines in 56\ncountries. The \"average\" computer participating was a 450 MHz Pentium II. For a survey\non \u03c0 computations, see [5].\nThe remainder of the paper is organized as follows. The results are presented in next\nsection. We discuss the BBP digit-extraction algorithm and our implementation in Section\n3 and Section 4, respectively.\n\n2\n\nResults\n\nWe have developed a program called DistBbp, which uses equation (1.2) to compute the nth\nbit of \u03c0 with arbitrary precision arithmetic. DistBbp employs the MapReduce programming\nmodel [8] and runs on Hadoop clusters. It has been used to compute 256 bits of \u03c0 around\nthe two quadrillionth bit position as shown in Table 2.1. This is a new record, which doubles\nthe position and quadruples the precision of the previous record obtained by PiHex.\nBit Position n\n1,999,999,999,999,997\n\nBits of \u03c0 Starting at The nth Bit Position\n(in Hexadecimal)\n0E6C1294 AED40403 F56D2D76 4026265B CA98511D\n0FCFFAA1 0F4D28B1 BB5392B8\n(256 bits)\n\nTable 2.1: The 256 bits of \u03c0 starting at the (2 * 1015 \u2212 3)th bit position and ending at the\n(2 * 1015 + 252)nd bit position.\nWe have also computed the first one billion bits and the bits at positions n = 10m + 1\nfor m \u2264 15. Table 2.2 below shows the results for 13 \u2264 m \u2264 15. The results for n < 1013\nare omitted since the corresponding bit values are well-known. It appears that the results\nfor 13 \u2264 m \u2264 14 are new, although their computation requirements are not as heavy as\nthe one for m = 15. The result for m = 15 is similar to the one obtained by PiHex except\n2\n\n\fthat the starting positions are slightly different and our result has a longer bit sequence.\nThese computations were executed on the idle slices of the Hadoop clusters in Yahoo!. The\ncluster sizes range from 1000 to 4000 machines. Each machine has two quad-core CPUs with\nclock speed ranging from 1.8 GHz to 2.5 GHz. We have run at least two computations at\ndifferent bit positions, usually n and n \u2212 4, for each row in Tables 2.1 and 2.2. Only the bit\nvalues covered by two computations are considered as valid results in order to detect machine\nerrors and transmission errors. Table 2.3 below shows the running time information for some\ncomputations.\nm\n\nBit Position n = 10m + 1\n\n13\n\n10,000,000,000,001\n\n14\n\n100,000,000,000,001\n\n15\n\n1,000,000,000,000,001\n\nBits of \u03c0 Starting at\n(in Hexadecimal)\n896DC3D3 6A09E2E9\n4C78723F 814F2EB4\n74CCD953 94FB7045\n0CDB80EF 72B70912\nBD5163E1 FC582BFE\nC0334D55 297ADDEB\n858929EA D8\n(1000 bits)\nC216EC69 7A098CC4\nD062B83B 52C5C205\nE62401AB B69AF82C\nA94B99F7 4DDE5102\n75CB8BAC 2003BA93\nE3FFE685 480637BF\n8E2EB177\n(992 bits)\n6216B069 CB6C1D36\nD95CC79A C84E60D2\n(228 bits)\n\nThe nth Bit Position\n29CA6F91\n6D417E5A\n3F7B48AE\nE20281FC\nFB4D8F9A\n1DACB0EF\n\n66FBA8DC\n4337FB1C\nE758BDD2\n76FD0A10\nF4A771E8\nB572D927\n\nF000C4A6\nC2EB474F\nDD7B1371\nCDE2ADD8\nBA9F0B58\nDBDDB68D\n\nB9AF60D0\nCDA35F4D\nCE885230\nA5142280\n27B731EA\n5C5BAE91\n\n5AE28EA9\nBCD0E9C3\n03D4FC01\n46B0055A\n40341861\n3AFB7EA7\n\n36873682\n785CBFA7\n7C620B11\n636715D3\n27419284\n45B4C955\n\n117099E4 3646A6D4 48D887CC\n3\n\nTable 2.2: The bits of \u03c0 starting at the (10m + 1)st positions for 13 \u2264 m \u2264 15.\n\n3\n\nThe BBP Digit-Extraction Algorithm\n\nWe briefly describe the BBP digit-extraction algorithm in this section (see [1] for more details). Any BBP-type formula, such as equation (1.1) or equation (1.2), can be used in the\nalgorithm. For simplicity, we discuss the algorithm with equation (1.1) in this section.\nIn order to obtain the (n + 1)th bit, compute {2n \u03c0}, where\ndef\n\n{x} = x \u2212 bxc\ndenotes the fraction part of x. By equation (1.1), we have\n) (\u221e\n) (\u221e\n) (\u221e\n))\n(( \u221e\nX 2n\u22121\u22124k\nX 2n\u22124k\nX 2n\u22121\u22124k\nX 2n+2\u22124k\nn\n\u2212\n\u2212\n\u2212\n. (3.1)\n{2 \u03c0} =\n8k + 1\n2k + 1\n8k + 5\n4k + 3\nk=0\n\nk=0\n\nk=0\n\n3\n\nk=0\n\n\fStarting Bit Position\n\nPrecision (bits)\n\nTime Useda\n\nCPUb Time\n\nDate Completed\n\n1\n800,000,001\n999,999,997\n1,000,000,001\n9,999,999,997\n10,000,000,001\n99,999,999,997\n100,000,000,001\n999,999,999,997\n1,000,000,000,001\n9,999,999,999,997\n10,000,000,000,001\n99,999,999,999,997\n100,000,000,000,001\n999,999,999,999,993\n1,000,000,000,000,001\n1,999,999,999,999,993\n1,999,999,999,999,997\n\n800,001,000\n200,001,000\n1024\n1024\n1024\n1024\n1024\n1024\n1024\n1024\n1024\n1024\n1024\n1024\n288\n256\n288\n288\n\n10 days\n3 days\n102 seconds\n96 seconds\n2 minutes\n4 minutes\n10 minutes\n9 minutes\n105 minutes\n98 minutes\n10 hours\n8 hours\n4 days\n5 days\n13 days\n25 days\n23 days\n23 days\n\n19 years\n8 years\n51 minutes\n54 minutes\n21 hours\n21 hours\n12 days\n11 days\n121 days\n121 days\n4 years\n4 years\n37 years\n40 years\n248 years\n283 years\n582 years\n503 years\n\nJune 23, 2010\nJune 22, 2010\nJune 10, 2010\nJune 11, 2010\nJune 8, 2010\nJune 8, 2010\nJune 6, 2010\nJune 6, 2010\nJune 7, 2010\nJune 7, 2010\nJune 2, 2010\nJune 1, 2010\nJune 11, 2010\nJune 7, 2010\nJuly 2, 2010\nJuly 6, 2010\nJuly 29, 2010\nJuly 25, 2010\n\nTable 2.3: The running time used in each computation.\na\nb\n\nNote that Time Used is not equivalent to \"cluster time\" since there were other jobs running on the cluster.\nNote that the CPUs in a cluster may be slightly different.\n\nThen, evaluate each sum as below,\n)\n(\u221e\nX 2n+x\u22124k\nk=0\n\nwhere\ndef\n\nAk =\n\nyk + z\n\n=\n\n\uf8f1\n\uf8f4\n\uf8f2\n\nX\n\nAk +\n\n\uf8f4\n\uf8f30\u2264k< n+x\n4\n\n2n+x\u22124k mod (yk + z)\nyk + z\n\nand\n\nX\nn+x\n\u2264k\n4\n\ndef\n\nBk =\n\nBk\n\n\uf8fc\n\uf8f4\n\uf8fd\n\n,\n\n(3.2)\n\n\uf8f4\n\uf8fe\n1\n\n24k\u2212n\u2212x (yk\n\n+ z)\n\n.\n\n(3.3)\n\nThe number of terms in the first sum of equation (3.2) is linear to n. Each term is a modular\nexponentiation followed by a floating point division. In the second sum, it is only required\nto evaluate the first O(p/ log p) terms such that Bk > \u03b5 = 2\u2212p\u22121 (see equation (3.6)) when\nworking on p-bit precision. Each term is a reciprocal computation. For all the terms in both\nsums, all the operands are integers with O(log n) bits.\nThe running time of the algorithm is\nO(p(n1+\u000f + p))\n\n(3.4)\n\nbit operations for any \u000f > 0. Note that p is required to be \u03a9(log n) due to rounding error; see\nSection 3.1. When the algorithm is used to compute the nth bit with a small p, the running\ntime is essentially linear in n. However, when the algorithm is used to compute the first p\nbits (i.e. n = 0), the running time is quadratic in p. In this case, there are faster algorithms\n[6, 13] and [7], which run in essentially linear time.\n4\n\n\fIt is easy to see that the required space for the BBP algorithm is\nO(p + log n)\n\n(3.5)\n\nbits. For p small, the computation task is CPU-intensive but not data-intensive.\nThe algorithm is embarrassingly parallel because it mainly evaluates summations with a\nlarge number of terms. Evaluating these summations can be computed in parallel with little\nadditional overhead.\n\n3.1\n\nRounding Error\n\nSince the outputs of the BBP algorithm are the exact bits of \u03c0, it is important to understand the rounding errors that arose in the computation and how they impact the results.\nOne simple way for diminishing the rounding error effect is to increase the precision in the\ncomputation. In practice, at least two independent computations at different bit positions,\nusually n and n\u22124, are performed in order to verify the results. For example, the bit sequence\nshown in Table 2.1 was obtained by two computations shown at the last two rows of Table\n2.3. We discuss rounding error in more details in the rest of the section.\nWhen a real number is represented in p-bit precision, the absolute relative rounding error\nis bounded above by\n\u03b5 = 0.5 ulp = 2\u2212p\u22121 ,\n(3.6)\nwhere ulp is the unit in the last place [9]. For computing the nth bit of \u03c0 with precision p, the\nnumber of terms in the summations is m = O(n + p). The cumulative absolute relative error\nis bounded above by m\u03b5. For example, when computing the (1015 )th bit of \u03c0 with IEEE 754\n64-bit floating point, we have m \u2248 7 * 1014 (see equation (1.2)), p = 52 and \u03b5 = 2\u221253 . Then,\nm\u03b5 \u2248 0.0777 > 2\u22124 , which means that even the third bit may be incorrect due to rounding\nerror. In practice, around 28 bits are calculated correctly in this case.\nThe long correct bit sequence can be explained by analyzing rounding\nP errors with a\nprobability model as follows. Let \u03b5k be the error in the k th term and E =\n\u03b5k be the error\nof the sum. Suppose each \u03b5k follows a uniform distribution over the closed interval [\u2212\u03b5, \u03b5],\n\u03b5k \u223c U (\u2212\u03b5, \u03b5).\nThen, E follows a uniform sum distribution (a.k.a. Irwin-Hall distribution) with mean 0 and\nvariance \u03c3 2 = m\u03b52 /3. The random variables \u03b5k 's are independent, identically distributed and\nm is large. By the Central Limit Theorem, the sum distribution can be approximated by a\nnormal distribution with the same mean and variance, i.e.\nE \u223c N (0, m\u03b52 /3).\nFor m \u2248 7 * 1014 and \u03b5 = 2\u221253 , we have 72.79% confidence of |E| < 2\u221229 , 97.20% confidence\nof |E| < 2\u221228 and 99.999 989% confidence of |E| < 2\u221227 .\nNote that |E| < 2\u2212b\u22121 does not imply b correct bits because it is possible to have consecutive 0's or 1's affected by the error. For example, we have used 64-bit floating point to\ncompute bits starting at the (1015 + 53)rd position and obtained the following 52 bits.\nPosition:\nHex\n:\nBinary :\n\n53\n57\n61\n65\n69\n73\nD\n3\n6\n1\n1\n6\n1101 0011 0110 0001 0001 0110\n^\n5\n\n77\n81\n85\n89\n93\n97\n101\nF\nA\n8\n5\n8\n1\nA\n1111 1010 1000 0101 1000 0001 1010\n^^^^\n\n\fThe corresponding true bit values are shown below.\nPosition:\nHex\n:\nBinary :\n\n53\n57\n61\n65\n69\n73\nD\n3\n6\n1\n1\n7\n1101 0011 0110 0001 0001 0111\n^\n\n77\n81\n85\n89\n93\n97\n101\n0\n9\n9\nE\n4\n3\n6\n0000 1001 1001 1110 0100 0011 0110\n^^^^\n\nWe have 2\u221229 < |E| < 2\u221228 but only the first 23 bits are correct due to the rounding error\nat the last of the four consecutive 0's in the true bit values.\n\n4\n\nMapReduce\n\nIn this section, we discuss our Hadoop MapReduce implementation of the BBP algorithm.\nFor computing the bits of \u03c0 starting at position n with precision p, the algorithm basically\nevaluates the sum\nX\nS=\nTi ,\ni\u2208I\n\nwhere each term Ti consists of a few arithmetic operations; see Section (4.2). We consider\np is small, i.e. p = O(log n), throughout this section. Then, the size of the index set I is\nroughly 0.7n; see equation (1.2). For n = 1015 , the size of I is approximately 7 * 1014 .\nA straightforward approach is to partition the index set I into m pairwise disjoint sets\ndef P\nI1 , * * * , Im . Then, evaluate each summation \u03c3j =\ni\u2208Ij Ti by a mapper and compute the\nP\nfinal sum S = 1\u2264j\u2264m \u03c3j by a reducer. However, such implementation, which mainly relies\non map-side computation, does not utilize a cluster because a cluster usually has a fixed ratio\nbetween map and reduce task capacities. Most of the reduce slots are not used in this case.\nThe second problem is that the MapReduce job possibly runs for a long time; see Table 2.3. It\nis desirable to have a mechanism to persist the intermediate results, so that the computation\nis interruptible and resumable.\nIn our design, we have multi-level partitioning.\nAs before, the summation is first parP\ntitioned into m smaller summations \u03a3j = i\u2208Ij Ti such that the value of m is also small.\nEach \u03a3j is computed by an individual MapReduce job. A controller program executed on\na gateway machine is responsible for submitting\nthese jobs. The summations \u03a3j are further\nP\npartitioned into tiny summations \u03c3j,k = i\u2208Ij,k Ti , where {Ij,1 , * * * , Ij,mj } is a partition of\nIj . Each \u03a3j job has mj tiny summations, which can be computed on either the map-side or\nthe reduce-side; see Section 4.1 below. Each tiny summation task is then assigned to a node\nmachine by the MapReduce system. In the task level, if there are more than one available\nCPU cores in the node machine, the tiny summation is partitioned again so that each part is\nexecuted by a separated thread. The task outputs \u03c3j,k 's are written to HDFS, a persistent\nstorage of the Hadoop\ncluster [14]. Then, the controller program reads \u03c3j,k 's from HDFS,\nP\ncompute \u03a3j =\n1\u2264k\u2264mj \u03c3j,k and write \u03a3j back to HDFS. These intermediate results are\npersisted in HDFS. Therefore, the computation can possibly be interrupted at any time by\nkilling the controllerP\nprogram and all the running jobs, and then be resumed in the future.\nThe final sum S = 1\u2264j\u2264m \u03a3j can be efficiently computed because m is relatively small.\n\n6\n\n\fThe multi-level partitioning is summarized below.\nFinal Sum:\n\nS=\n\nX\n\n\u03a3j\n\n1\u2264j\u2264m\n\nJobs:\n\n\u03a3j =\n\nX\n\n\u03c3j,k\n\n1\u2264k\u2264mj\n\nTasks:\n\n\u03c3j,k =\n\nX\n\nsj,k,t\n\n1\u2264t\u2264mj,k\n\nThreads:\n\nsj,k,t =\n\nX\n\nTi\n\ni\u2208Ij,k,t\n\n4.1\n\nMap-side & Reduce-side Computations\n\nIn order to utilize the cluster resources, we have developed a general framework to execute\ncomputation tasks on either the map-side or the reduce-side. Applications only have to define\ntwo functions:\n1. partition(c, m): partition the computation c into m parts c1 , . . . , cm ;\n2. compute(c): execute the computation c.\nA map-side job contains multiple mappers and zero reducers. The input computation c\nis partitioned into m parts by a PartitionInputFormat and then each part is executed by a\nmapper. See Figure 4.1 below.\n\nFigure 4.1: Map-side computation.\nIn contrast, a reduce-side job contains a single mapper and multiple reducers. A SingletonInputFormat is used to launch a single PartitionMapper, which is responsible to partition\nthe computation c into m parts. Then, the parts are forwarded to an Indexer, which creates\nindexes for launching m reducers. See Figure 4.2 below.\n\nFigure 4.2: Reduce-side computation.\n\n7\n\n\fNote that the utility classes PartitionInputFormat, Mapper, SingletonInputFormat, PartitionMapper, Indexer and Reducer are provided by our framework. For map-side (or reduce-side)\njobs, the user defined functions partition(c, m) and compute(c) are executed in PartitionInputFormat (or PartitionMapper) and Mapper (or Reducer), respectively.\nThe map and reduce task slots in a Hadoop cluster are statically configured. This framework allows computations utilizing both map and reduce task slots.\n\n4.2\n\nEvaluating The Terms\n\nAs shown in equations (3.2) and (3.3), there are two types of terms, Ak and Bk , in the\nsummations of the BBP algorithm. The terms Ak involve a modular exponentiation and a\nfloating point division. Modular exponentiation can be evaluated by the successive squaring\nmethod. When the modulus is large, we use Montgomery method [11], which is faster than\nsuccessive squaring in this case.\nFloating point division is implemented with arbitrary precision because of the rounding\nerror issue discussed in Section 3.1. For the terms Bk in equation (3.3), the division first is\ndone first by shifting b = 4k \u2212 n \u2212 x bits and then followed by floating point division with\n(p \u2212 b)-bit precision, where p is the selected precision.\n\n4.3\n\nUtilizing Cluster Idle Slices\n\nOne of our goals is to utilize the idle slices in a cluster. The controller program mentioned\npreviously also monitors the cluster status. When there are sufficient available map (or\nreduce) slots, the controller program submits a map-side (or reduce-side) job. Each job is\nsmall so that it holds cluster resource only for a short period of time.\nIn one of our computations (see the last row in Table 2.3), we had n = 2 * 1015 \u2212 3 and\np = 288. The summation had approximately 1.4 * 1015 terms. It was executed in a 1000-node\ncluster. Each node had two quad-core CPUs with clock speed ranging from 2.0 GHz to 2.5\nGHz, and was configured to support four map tasks and two reduce tasks. The computation\nwas divided into 35,000 jobs. Depending on the cluster load condition, the controller program\nmight submit up to 60 concurrent jobs at any time. A job had 200 mappers with one thread\neach or 100 reducers with two threads each. Each thread computed a summation with roughly\n200,000,000 terms and took around 45 minutes. The entire computation took 23 days of real\ntime and 503 years of CPU time.\n\n5\n\nConclusions & Future Works\n\nIn this paper, we present our latest results on computing \u03c0 using Apache Hadoop. We extend\nthe previous record of calculating specific bits of \u03c0 from position around the one quadrillionth\nbit to position around the two quadrillionth bit, and from 64-bit precision to 256-bit precision.\nThe distributed computation is done through a MapReduce program called DistBbp. Our\nelastic computation framework automatically schedules computation slices as either map-side\nor reduce-side computation to fully exploit idle cluster resources.\nA natural extension of this work is to compute the bits of \u03c0 at higher positions, say the\nten quadrillionth bit position, or even the quintillionth bit position. Besides, it is interesting\nto compute all the first n digits of \u03c0 with Hadoop clusters. Such computation task is not\nonly CPU-intensive but also data-intensive.\n\n8\n\n\fAcknowledgment\nWe thank Robert Chansler and Hong Tang for providing helpful review comments and suggestions for this paper. Owen O'Malley, Chris Douglas, Arun Murthy and Milind Bhandarkar\nhave provided many useful ideas and help in developing DistBbp. We also thank Eric Baldeschwieler, Kazi Atif-Uz Zaman and Pei Lin Ong for supporting this project.\n\nReferences\n[1] David Bailey, Peter Borwein, and Simon Plouffe. On the rapid computation of various\npolylogarithmic constants. Mathematics of Computation, 66(216):903\u2013913, apr 1997.\n[2] Fabrice Bellard. The 1000 billionth binary digit of pi is '1' !, 1997. http://bellard.\norg/pi-challenge/announce220997.html.\n[3] Fabrice Bellard. A new formula to compute the n'th binary digit of pi, 1997. Available\nat http://bellard.org/pi/pi_bin.pdf.\n[4] Lennart Berggren, Jonathan Borwein, and Peter Borwein. Pi: A Source Book. Springer,\nNew York, NY, USA, 3rd edition, 2004.\n[5] Jonathan Borwein. The life of Pi: From Archimedes to Eniac and beyond, 2010. Preprint\n(http://www.carma.newcastle.edu.au/~jb616/pi-2010.pdf).\n[6] Richard Brent. Multiple-precision zero-finding methods and the complexity of elementary function evaluation. Analytic Computational Complexity, pages 151\u2013176, 1976.\n[7] David Chudnovsky and Gregory Chudnovsky. The computation of classical constants.\nProceedings of the National Academy of Science USA, 86:8178\u20138182, 1989.\n[8] Jeffrey Dean and Sanjay Ghemawat. MapReduce: simplified data processing on large\nclusters. In OSDI'04: Proceedings of the 6th conference on Symposium on Operating\nSystems Design & Implementation, pages 137\u2013150, Berkeley, CA, USA, 2004. USENIX\nAssociation.\n[9] David Goldberg. What every computer scientist should know about floating point arithmetic. ACM Computing Surveys, 23(1):5\u201348, 1991.\n[10] Donald Knuth. The Art of Computer Programming, Volume 2: Seminumerical Algorithms. Addison-Wesley, Reading, MA, USA, 3rd edition, 1997.\n[11] Peter Montgomery. Modular multiplication without trial division. Mathematics of Computation, 44(170):519\u2013521, 1985.\n[12] Colin Percival. PiHex: A distributed effort to calculate Pi, 2000. http://oldweb.cecm.\nsfu.ca/projects/pihex.\n[13] Eugene Salamin. Computation of \u03c0 using arithmetic-geometric mean. Mathematics of\nComputation, 30(135):565\u2013570, jul 1976.\n[14] Konstantin Shvachko, Hairong Kuang, Sanjay Radia, and Robert Chansler. The Hadoop\nDistributed File System. In MSST'10: 26th IEEE Symposium on Massive Storage Systems and Technologies, Lake Tahoe, NV, USA, 2010.\n\n9\n\n\f"}