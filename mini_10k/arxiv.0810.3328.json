{"id": "http://arxiv.org/abs/0810.3328v1", "guidislink": true, "updated": "2008-10-18T16:54:14Z", "updated_parsed": [2008, 10, 18, 16, 54, 14, 5, 292, 0], "published": "2008-10-18T16:54:14Z", "published_parsed": [2008, 10, 18, 16, 54, 14, 5, 292, 0], "title": "A Simple Introduction to Particle Physics", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.1058%2C0810.2956%2C0810.5409%2C0810.0535%2C0810.0147%2C0810.5233%2C0810.0476%2C0810.4176%2C0810.1220%2C0810.3086%2C0810.2183%2C0810.5748%2C0810.5773%2C0810.1710%2C0810.3869%2C0810.2455%2C0810.2793%2C0810.1661%2C0810.3067%2C0810.0185%2C0810.3941%2C0810.5021%2C0810.4395%2C0810.0277%2C0810.2368%2C0810.4626%2C0810.1603%2C0810.3205%2C0810.0566%2C0810.2201%2C0810.3070%2C0810.4198%2C0810.1717%2C0810.5446%2C0810.0937%2C0810.2770%2C0810.4768%2C0810.5487%2C0810.3771%2C0810.1498%2C0810.5324%2C0810.3533%2C0810.2279%2C0810.5533%2C0810.0135%2C0810.2722%2C0810.3297%2C0810.1260%2C0810.1846%2C0810.2590%2C0810.2945%2C0810.0401%2C0810.0473%2C0810.3912%2C0810.3749%2C0810.1732%2C0810.0799%2C0810.2938%2C0810.4126%2C0810.4277%2C0810.0174%2C0810.1160%2C0810.2444%2C0810.3328%2C0810.0689%2C0810.2942%2C0810.3503%2C0810.1187%2C0810.5607%2C0810.5508%2C0810.2805%2C0810.1628%2C0810.3836%2C0810.1379%2C0810.2231%2C0810.1324%2C0810.4590%2C0810.5357%2C0810.2708%2C0810.1705%2C0810.4378%2C0810.4755%2C0810.2730%2C0810.4420%2C0810.1039%2C0810.3042%2C0810.5365%2C0810.5356%2C0810.2510%2C0810.2624%2C0810.3788%2C0810.5747%2C0810.3272%2C0810.0152%2C0810.0057%2C0810.4228%2C0810.2850%2C0810.2982%2C0810.0440%2C0810.1958%2C0810.2916&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Simple Introduction to Particle Physics"}, "summary": "This is the first of a series of papers in which we present a brief\nintroduction to the relevant mathematical and physical ideas that form the\nfoundation of Particle Physics, including Group Theory, Relativistic Quantum\nMechanics, Quantum Field Theory and Interactions, Abelian and Non-Abelian Gauge\nTheory, and the SU(3)xSU(2)xU(1) Gauge Theory that describes our universe apart\nfrom gravity. These notes are not intended to be a comprehensive introduction\nto any of the ideas contained in them. Among the glaring omissions are CPT\ntheorems, evaluations of Feynman Diagrams, Renormalization, and Anomalies. The\ntopics were chosen according to the authors preferences and agenda. These notes\nare intended for a student who has completed the standard undergraduate physics\nand mathematics courses. Furthermore, these notes should not and will not in\nany way take the place of the related courses, but rather provide a primer for\ndetailed courses in QFT, Gauge Theory, String Theory, etc., which will fill in\nthe many gaps left by this paper.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.1058%2C0810.2956%2C0810.5409%2C0810.0535%2C0810.0147%2C0810.5233%2C0810.0476%2C0810.4176%2C0810.1220%2C0810.3086%2C0810.2183%2C0810.5748%2C0810.5773%2C0810.1710%2C0810.3869%2C0810.2455%2C0810.2793%2C0810.1661%2C0810.3067%2C0810.0185%2C0810.3941%2C0810.5021%2C0810.4395%2C0810.0277%2C0810.2368%2C0810.4626%2C0810.1603%2C0810.3205%2C0810.0566%2C0810.2201%2C0810.3070%2C0810.4198%2C0810.1717%2C0810.5446%2C0810.0937%2C0810.2770%2C0810.4768%2C0810.5487%2C0810.3771%2C0810.1498%2C0810.5324%2C0810.3533%2C0810.2279%2C0810.5533%2C0810.0135%2C0810.2722%2C0810.3297%2C0810.1260%2C0810.1846%2C0810.2590%2C0810.2945%2C0810.0401%2C0810.0473%2C0810.3912%2C0810.3749%2C0810.1732%2C0810.0799%2C0810.2938%2C0810.4126%2C0810.4277%2C0810.0174%2C0810.1160%2C0810.2444%2C0810.3328%2C0810.0689%2C0810.2942%2C0810.3503%2C0810.1187%2C0810.5607%2C0810.5508%2C0810.2805%2C0810.1628%2C0810.3836%2C0810.1379%2C0810.2231%2C0810.1324%2C0810.4590%2C0810.5357%2C0810.2708%2C0810.1705%2C0810.4378%2C0810.4755%2C0810.2730%2C0810.4420%2C0810.1039%2C0810.3042%2C0810.5365%2C0810.5356%2C0810.2510%2C0810.2624%2C0810.3788%2C0810.5747%2C0810.3272%2C0810.0152%2C0810.0057%2C0810.4228%2C0810.2850%2C0810.2982%2C0810.0440%2C0810.1958%2C0810.2916&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This is the first of a series of papers in which we present a brief\nintroduction to the relevant mathematical and physical ideas that form the\nfoundation of Particle Physics, including Group Theory, Relativistic Quantum\nMechanics, Quantum Field Theory and Interactions, Abelian and Non-Abelian Gauge\nTheory, and the SU(3)xSU(2)xU(1) Gauge Theory that describes our universe apart\nfrom gravity. These notes are not intended to be a comprehensive introduction\nto any of the ideas contained in them. Among the glaring omissions are CPT\ntheorems, evaluations of Feynman Diagrams, Renormalization, and Anomalies. The\ntopics were chosen according to the authors preferences and agenda. These notes\nare intended for a student who has completed the standard undergraduate physics\nand mathematics courses. Furthermore, these notes should not and will not in\nany way take the place of the related courses, but rather provide a primer for\ndetailed courses in QFT, Gauge Theory, String Theory, etc., which will fill in\nthe many gaps left by this paper."}, "authors": ["M. Robinson", "K. Bland", "G. Cleaver", "J. Dittmann"], "author_detail": {"name": "J. Dittmann"}, "author": "J. Dittmann", "arxiv_comment": "standard latex document, 139 pages", "links": [{"href": "http://arxiv.org/abs/0810.3328v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0810.3328v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-th", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-th", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0810.3328v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0810.3328v1", "journal_reference": null, "doi": null, "fulltext": "BU-HEPP-08-20\n\nA Simple Introduction to Particle Physics\nPart I - Foundations and the Standard Model\nMatthew B. Robinson, 1 Karen R. Bland, 2\nGerald B. Cleaver, 3 and Jay R. Dittmann 4\n\narXiv:0810.3328v1 [hep-th] 18 Oct 2008\n\nDepartment of Physics, One Bear Place # 97316\nBaylor University\nWaco, TX 76798-7316\nAbstract\nThis is the first of a series of papers in which we present a brief introduction to the relevant mathematical and physical ideas that form the foundation of Particle Physics, including Group Theory, Relativistic Quantum Mechanics, Quantum Field Theory and\nInteractions, Abelian and Non-Abelian Gauge Theory, and the SU (3) \u2297 SU (2) \u2297 U (1)\nGauge Theory that describes our universe apart from gravity. Our approach, at first, is\nan algebraic exposition of Gauge Theory and how the physics of our universe comes\nout of Gauge Theory.\nWith an algebraic understanding of Gauge Theory and the relevant physics of the\nStandard Model from this paper, in a subsequent paper we will \"back up\" and reformulate Gauge Theory from a geometric foundation, showing how it connects to the\nalgebraic picture initially built in these notes.\nFinally, we will introduce the basic ideas of String Theory, showing both the geometric\nand algebraic correspondence with Gauge Theory as outlined in the first two parts.\nThese notes are not intended to be a comprehensive introduction to any of the ideas\ncontained in them. Their purpose is to introduce the \"forest\" rather than the \"trees\".\nThe primary emphasis is on the algebraic/geometric/mathematical underpinnings\nrather than the calculational/phenomenological details. Among the glaring omissions are CPT theorems, evaluations of Feynman Diagrams, Renormalization, and\nAnomalies. The topics were chosen according to the authors' preferences and agenda.\nThese notes are intended for a student who has completed the standard undergraduate physics and mathematics courses. The material in the first part is intended as a\nreview and is therefore cursory. Furthermore, these notes should not and will not in\nany way take the place of the related courses, but rather provide a primer for detailed\ncourses in QFT, Gauge Theory, String Theory, etc., which will fill in the many gaps left\nby this paper.\n1\n\nm robinson@baylor.edu\nkaren bland@baylor.edu\n3\ngerald cleaver@baylor.edu\n4\njay dittmann@baylor.edu\n2\n\n\fContents\n1\n\nPart I - Preliminary Concepts\n\n5\n\n1.1\n\nReview of Classical Physics . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n5\n\n1.1.1\n\nHamilton's Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n5\n\n1.1.2\n\nNoether's Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n6\n\n1.1.3\n\nConservation of Energy . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n7\n\n1.1.4\n\nLorentz Transformations . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n7\n\n1.1.5\n\nA More Detailed Look at Lorentz Transformations . . . . . . . . . . .\n\n9\n\n1.1.6\n\nClassical Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\n1.1.7\n\nClassical Electrodynamics . . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n1.1.8\n\nClassical Electrodynamics Lagrangian . . . . . . . . . . . . . . . . . . 12\n\n1.1.9\n\nGauge Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n1.2\n2\n\nReferences and Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 14\n\nPart II - Algebraic Foundations\n2.1\n\n2.2\n\n15\n\nIntroduction to Group Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.1\n\nWhat is a Group? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n\n2.1.2\n\nFinite Discrete Groups and Their Organization . . . . . . . . . . . . . 17\n\n2.1.3\n\nGroup Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n\n2.1.4\n\nRepresentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\n2.1.5\n\nReducibility and Irreducibility - A Preview . . . . . . . . . . . . . . 23\n\n2.1.6\n\nAlgebraic Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n\n2.1.7\n\nReducibility Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n\nIntroduction to Lie Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n2.2.1\n\nClassification of Lie Groups . . . . . . . . . . . . . . . . . . . . . . . . 34\n\n1\n\n\f2.2.2\n\nGenerators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\n2.2.3\n\nLie Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n\n2.2.4\n\nThe Adjoint Representation . . . . . . . . . . . . . . . . . . . . . . . . 42\n\n2.2.5\n\nSO(2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n\n2.2.6\n\nSO(3) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n\n2.2.7\n\nSU (2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\n2.2.8\n\nSU (2) and Physical States . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\n2.2.9\n\nSU (2) for j =\n\n1\n2\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n\n2.2.10 SU (2) for j = 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n2.2.11 SU (2) for Arbitrary j . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n2.2.12 Root Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n2.2.13 Adjoint Representation of SU (2) . . . . . . . . . . . . . . . . . . . . . 57\n2.2.14 SU (2) for Arbitrary j . . . Again . . . . . . . . . . . . . . . . . . . . . . 59\n2.2.15 SU (3) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n2.2.16 What is the Point of All of This? . . . . . . . . . . . . . . . . . . . . . 64\n2.3\n3\n\nReferences and Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 65\n\nPart III - Quantum Field Theory\n3.1\n\n66\n\nA Primer to Quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n3.1.1\n\nQuantum Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\n3.1.2\n\nSpin-0 Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n\n3.1.3\n\nWhy SU (2) for Spin? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n\n3.1.4\n\nSpin\n\n3.1.5\n\nThe Lorentz Group . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n\n3.1.6\n\nThe Dirac Sea Interpretation of Antiparticles . . . . . . . . . . . . . . 73\n\n3.1.7\n\nThe QFT Interpretation of Antiparticles . . . . . . . . . . . . . . . . . 74\n\n1\n2\n\nParticles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n\n2\n\n\f3.1.8\n\nLagrangians for Scalars and Dirac Particles . . . . . . . . . . . . . . . 75\n\n3.1.9\n\nConserved Currents . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n\n3.1.10 The Dirac Equation with an Electromagnetic Field . . . . . . . . . . . 76\n3.1.11 Gauging the Symmetry . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n3.2\n\nQuantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n3.2.1\n\nReview of What Quantization Means . . . . . . . . . . . . . . . . . . 81\n\n3.2.2\n\nCanonical Quantization of Scalar Fields . . . . . . . . . . . . . . . . . 82\n\n3.2.3\n\nThe Spin-Statistics Theorem . . . . . . . . . . . . . . . . . . . . . . . . 86\n\n3.2.4\n\nLeft-Handed and Right-Handed Fields . . . . . . . . . . . . . . . . . 87\n\n3.2.5\n\nCanonical Quantization of Fermions . . . . . . . . . . . . . . . . . . . 89\n\n3.2.6\n\nInsufficiencies of Canonical Quantization . . . . . . . . . . . . . . . . 90\n\n3.2.7\n\nPath Integrals and Path Integral Quantization . . . . . . . . . . . . . 91\n\n3.2.8\n\nInterpretation of the Path Integral . . . . . . . . . . . . . . . . . . . . 93\n\n3.2.9\n\nExpectation Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n\n3.2.10 Path Integrals with Fields . . . . . . . . . . . . . . . . . . . . . . . . . 95\n3.2.11 Interacting Scalar Fields and Feynman Diagrams . . . . . . . . . . . 98\n3.2.12 Interacting Fermion Fields . . . . . . . . . . . . . . . . . . . . . . . . . 102\n3.3\n\nFinal Ingredients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n3.3.1\n\nSpontaneous Symmetry Breaking . . . . . . . . . . . . . . . . . . . . 104\n\n3.3.2\n\nBreaking Local Symmetries . . . . . . . . . . . . . . . . . . . . . . . . 106\n\n3.3.3\n\nNon-Abelian Gauge Theory . . . . . . . . . . . . . . . . . . . . . . . . 107\n\n3.3.4\n\nRepresentations of Gauge Groups . . . . . . . . . . . . . . . . . . . . 109\n\n3.3.5\n\nSymmetry Breaking Revisited . . . . . . . . . . . . . . . . . . . . . . . 110\n\n3.3.6\n\nSimple Examples of Symmetry Breaking . . . . . . . . . . . . . . . . 112\n\n3.3.7\n\nA More Complicated Example of Symmetry Breaking . . . . . . . . . 114\n\n3\n\n\f3.4\n\n3.5\n4\n\n5\n\nParticle Physics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n3.4.1\n\nIntroduction to the Standard Model . . . . . . . . . . . . . . . . . . . 115\n\n3.4.2\n\nThe Gauge and Higgs Sector . . . . . . . . . . . . . . . . . . . . . . . 116\n\n3.4.3\n\nThe Lepton Sector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n\n3.4.4\n\nThe Quark Sector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n\nReferences and Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 126\n\nThe Standard Model - A Summary\n\n127\n\n4.1\n\nHow Does All of This Relate to Real Life? . . . . . . . . . . . . . . . . . . . . 127\n\n4.2\n\nThe Fundamental Forces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n\n4.3\n\nCategorizing Particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\n\n4.4\n\nElementary Particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n4.4.1\n\nElementary Fermions . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n\n4.4.2\n\nElementary Bosons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n\n4.5\n\nComposite Particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\n\n4.6\n\nVisualizing It All . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n\nA Look Ahead\n\n135\n\n4\n\n\f1\n\nPart I - Preliminary Concepts\n\n1.1\n1.1.1\n\nReview of Classical Physics\nHamilton's Principle\n\nNearly all physics begins with what is called a Lagrangian for a particle, which is initially\ndefined as the kinetic energy minus the potential energy,\nL\u2261T \u2212V\nwhere T = T (q, q\u0307) and V = V (q). Then, the Action is defined as the integral of the\nLagrangian from an initial time to a final time,\nZ tf\nS\u2261\ndtL(q, q\u0307)\nti\n\nIt is important to realize that S is a \"functional\" of the particle's world-line in (q, q\u0307) space,\nnot a function. This means that it depends on the entire path (q, q\u0307), rather than a given\npoint on the path. The only fixed points on the path are q(ti ), q(tf ), q\u0307(ti ), and q\u0307(tf ). The\nrest of the path is generally unconstrained, and the value of S depends on the entire path.\nHamilton's Principle says that nature extremizes the path a particle will take in going\nfrom q(ti ) at time ti to position q(tf ) at time tf . In other words, the path that extremizes\nthe action will be the path the particle will travel.\nBut, because S is a functional, depending on the entire path in (q, q\u0307) space rather than a\npoint, it cannot be extremized in the \"Calculus I\" sense of merely setting the derivative\nequal to 0. Instead, we must find the path for which the action is \"stationary\". This means\nthat the first-order term in the Taylor Expansion around that path will vanish, or \u03b4S = 0\nat that path.\nTo find this, consider some arbitrary path (q, q\u0307). If it is a path that minimizes the action,\nthen we will have\nZ tf\nZ tf\n0 = \u03b4S = \u03b4\ndtL(q, q\u0307) =\ndtL(q + \u03b4q, q\u0307 + \u03b4 q\u0307) \u2212 S\nti\nti\n\u0013\nZ tf\nZ tf \u0012\n\u2202L\n\u2202L\n\u2212S\n+ \u03b4 q\u0307\n=\ndtL(q, q\u0307) +\ndt \u03b4q\n\u2202q\n\u2202 q\u0307\nti\nti\n\u0013\nZ tf \u0012\n\u2202L \u2202L d\n=\ndt \u03b4q\n+\n\u03b4q\n\u2202q\n\u2202 q\u0307 dt\nti\nIntegrating the second term by parts, and taking the variation of \u03b4q to be at 0 at ti and tf ,\n\u0013 Z tf\n\u0013\n\u0012\nZ tf \u0012\nd \u2202L\nd \u2202L\n\u2202L\n\u2202L\n\u03b4S =\ndt \u03b4q\n\u2212 \u03b4q\n=\ndt\u03b4q\n\u2212\n=0\n\u2202q\ndt \u2202 q\u0307\n\u2202q\ndt \u2202 q\u0307\nti\nti\n5\n\n\fThe only way to guarantee this for an arbitrary variation \u03b4q from the path (q, q\u0307) is to\ndemand\nd \u2202L \u2202L\n\u2212\n=0\ndt \u2202 q\u0307\n\u2202q\nThis equation is called the Euler-Lagrange equation, and it produces the equations of\nmotion of the particle.\nThe generalization to multiple coordinates qi (i = 1, . . . , n) is straightforward:\nd \u2202L \u2202L\n\u2212\n=0\ndt \u2202 q\u0307i \u2202qi\n1.1.2\n\n(1.1)\n\nNoether's Theorem\n\nGiven a Lagrangian L = L(q, q\u0307), consider making an infinitesimal transformation\nq \u2192 q + \u000f\u03b4q\nwhere \u000f is some infinitesimal constant. This transformation will give\n\u2202L\n\u2202L\n+ \u000f\u03b4 q\u0307\nL(q, q\u0307) \u2192 L(q + \u000f\u03b4q, q\u0307 + \u000f\u03b4 q\u0307) = L(q, q\u0307) + \u000f\u03b4q\n\u2202q\n\u2202 q\u0307\nIf the Euler-Lagrange equations of motion are satisfied, so that \u2202L\n= dtd \u2202L\n, then under\n\u2202q\n\u2202 q\u0307\nq \u2192 q + \u000f\u03b4q,\n\u0012\n\u0013\n\u2202L\n\u2202L\nd \u2202L\n\u2202L d\nd \u2202L\nL \u2192 L + \u000f\u03b4q\n+ \u000f\u03b4 q\u0307\n= L + \u000f\u03b4q\n+\u000f\n\u03b4q = L +\n\u000f\u03b4q\n\u2202q\n\u2202 q\u0307\ndt \u2202 q\u0307\n\u2202 q\u0307 dt\ndt \u2202 q\u0307\nSo, under q \u2192 q + \u000f\u03b4q, we have \u03b4L =\n\nd \u2202L\n\u000f\u03b4q\ndt \u2202 q\u0307\n\nj\u2261\n\n\u0001\n. We define the Noether Current, j, as\n\n\u2202L\n\u03b4q\n\u2202 q\u0307\n\nNow, if we can find some transformation \u03b4q that leaves the action invariant, or in other\ndj\nwords such that \u03b4S = 0, then dt\n= 0, and therefore the current j is a constant in time. In\nother words, j is conserved.\nAs a familiar example, consider a projectile, described by the Lagrangian\n1\nL = m(\u1e8b2 + \u1e8f 2 ) \u2212 mgy\n(1.2)\n2\nThis will be unchanged under the transformation x \u2192 x + \u000f, where \u000f is any constant\n\u03b4q = m\u1e8b is\n(here, \u03b4q = 1 in the above notation), because x \u2192 x + \u000f \u21d2 \u1e8b \u2192 \u1e8b. So, j = \u2202L\n\u2202 q\u0307\nconserved. We recognize m\u1e8b as the momentum in the x-direction, which we expect to be\nconserved by conservation of momentum.\nSo in summary, Noether's Theorem merely says that whenever there is a continuous\nsymmetry in the action, there is a corresponding conserved quantity.\n6\n\n\f1.1.3\n\nConservation of Energy\n\nConsider the quantity\ndL\nd\n\u2202L dq \u2202L dq\u0307 \u2202L\n= L(q, q\u0307) =\n+\n+\ndt\ndt\n\u2202q dt\n\u2202 q\u0307 dt\n\u2202t\n= 0, and therefore\nBecause L does not depend explicitly on time, \u2202L\n\u2202t\n\u0012\n\u0013\n\u0012\n\u0013\ndL\n\u2202L\n\u2202L\nd \u2202L\n\u2202L\nd \u2202L\n=\nq\u0307 +\nq\u0308 =\nq\u0307 +\nq\u0308 =\nq\u0307\ndt\n\u2202q\n\u2202 q\u0307\ndt \u2202 q\u0307\n\u2202 q\u0307\ndt \u2202 q\u0307\nwhere we have\n\u0001 used the Euler-Lagrange equation to get the second equality. So, we have\ndL\nd \u2202L\n=\nq\u0307\n, or\ndt\ndt \u2202 q\u0307\n\u0013\n\u0012\nd \u2202L\nq\u0307 \u2212 L = 0\ndt \u2202 q\u0307\nFor a general non-relativistic system, L = T \u2212 V , so\nonly, and normally\nT \u221d q\u0307 2\n\n(1.3)\n\n\u2202L\n\u2202 q\u0307\n\n=\n\n\u2202T\n\u2202 q\u0307\n\nbecause V is a function of q\n\n\u2202L\nq\u0307 = 2T\n\u2202 q\u0307\n\n\u21d2\n\nSo, \u2202L\nq\u0307\u2212L = 2T \u2212(T \u2212V ) = T +V = E, the total energy of the system, which is conserved\n\u2202 q\u0307\naccording to (1.3). We identify T + V \u2261 H as the Hamiltonian, or total energy function,\nof the system.\nFurthermore, we define \u2202L\n\u2261 p to be the momentum of the system. Then, the relationship\n\u2202 q\u0307\nbetween the Lagrangian and the Hamiltonian is the Legendre transformation\npq\u0307 \u2212 L = H\n\n1.1.4\n\nLorentz Transformations\n\nConsider some event that occurs at spatial position (x, y, z)T , at time t. (The superscript\nT denotes the transpose, so this is a column vector.) We arrange this event in a column\n4-vector as (ct, x, y, z)T , where c is the speed of light (the units of c give each element the\nsame units). A more useful notation is to refer to this vector as a\u03bc = (ct, x, y, z)T , where\n\u03bc = 0, 1, 2, 3. This 4-vector, with the \u03bc index raised, is called a \"vector\", or a \"contravariant\nvector\". Then, we define the row vector a\u03bc = (\u2212ct, x, y, z). This is called a \"covector\", or\na \"covariant vector\". In general, the sign of the 0th component (the component in the first\nposition) changes when going from vector to covector.\n\n7\n\n\fThere is something very deep going on here regarding the geometrical picture between\nvectors and covectors, but we will not discuss it until the next paper in this series.\nThe dot product between two such vectors (a covector and vector) is then defined as the\nproduct with one index raised and the other lowered. Whenever indices are contracted\nin such a way, it is understood that they are to be summed over.1\na * b = a\u03bc b\u03bc = a0 b0 + a1 b1 + a2 b2 + a3 b3 = \u2212a0 b0 + a1 b1 + a2 b2 + a3 b3\nOr, plugging in the spacetime notation from above, where\na\u03bc = (ct1 , x1 , y1 , z1 )T\n\nand\n\nb \u03bc = (ct2 , x2 , y2 , z2 )T\n\nwe have\na * b = a\u03bc b\u03bc = \u2212c2 t1 t2 + x1 x2 + y1 y2 + z1 z2\nWe can also discuss the differential version of this. If s\u03bc = (ct, x, y, z), then ds2 = \u2212c2 dt2 +\ndx2 + dy 2 + dz 2 .\nIn his theory of Special Relativity, Einstein postulated that all inertial reference frames\nare equivalent, and that the speed of light is the same in all frames. To put this in more\nmathematical terms, if observers in different inertial frames 1 and 2 each see an event,\nthey will see, respectively,\nds21 = \u2212c2 dt21 + dx21 + dy12 + dz12\nds22 = \u2212c2 dt22 + dx22 + dy22 + dz22\nWe then demand that ds21 = ds22 . To do this, we must find a modification of the standard\nGalilean transformations that will leave ds2 unchanged. The derivation for the correct\ntransformations can be found in any introductory or modern physics text, so we merely\nquote the result. If we assume that frame 2 is moving only in the z-direction with respect\nto frame 1 (and that their x, y, and z axes are aligned), then we find that the transformations are\nt2 = \u03b3(ct1 \u2212 \u03b2z1 )\nz2 = \u03b3(z1 \u2212 \u03b2ct1 )\nwhere \u03b2 =\n\nv\nc\n\nand \u03b3 = \u221a 1\n\n1\u2212\u03b2 2\n\n(1.4)\n\n. These transformations, which preserve ds2 when transform-\n\ning one frame to another, are called Lorentz Transformations.\nDiscussions of the implications of these transformations, including time dilation, length\ncontraction, and the relationship between energy and mass can be found in most introductory texts. You are encouraged to review the material if you are not familiar with\nit.\n1\n\nbecause we are summing over components, we can write a\u03bc b\u03bc or a\u03bc b\u03bc - they mean the same thing\n\n8\n\n\f1.1.5\n\nA More Detailed Look at Lorentz Transformations\n\nAs we have seen, we have a quantity ds2 = \u2212c2 dt2 + dx2 + dy 2 + dz 2 , which does not\nchange under transformations (1.4). Thinking of physical ideas this way, in terms of\n\"what doesn't change when something else changes\", will prove to be an extraordinarily\npowerful approach. In order to understand Special Relativity in such a way, we begin\nwith a simpler example.\nConsider a spatial rotation around, say, the z-axis (or, equivalently, mixing the x and y\ncoordinates). Such a transformation is called an Euler Transformation, and takes the\nform\nt0\nx0\ny0\nz0\n\n=\n=\n=\n=\n\nt\nx cos \u03b8 + y sin \u03b8\n\u2212x sin \u03b8 + y cos \u03b8\nz\n\n(1.5)\n\nwhere \u03b8 is the angle of rotation, called the Euler Angle. We can simultaneously express a\nLorentz transformation as a sort of \"rotation\" that mixes a spatial dimension and a time\ndimension, as follows (these transformations are equivalent to (1.4):\nt0\nx0\ny0\nz0\n\n=\n=\n=\n=\n\nt cosh \u03b8 \u2212 x sinh \u03b8\n\u2212t sinh \u03b8 + x cosh \u03b8\ny\nz\n\n(1.6)\n\nwhere \u03b8 is defined by the relationship \u03b2 = tan \u03b8.\nWe denote a transformation mixing two spatial dimensions simply a Rotation, whereas\na transformation mixing a spatial dimension and a time dimension is a Boost. Any two\nframes whose origins coincide at t = t0 = 0 can be transformed into each other through\nsome combination of rotations and boosts.\nTo rephrase this in more precise language, given a 4-vector x\u03bc , it will be related to the\nequivalent 4-vector in another frame, x0\u03bc , by some matrix L, according to x0\u03bc = L\u03bc\u03bd x\u03bd\n(where the summation convention discussed earlier is in effect for the repeated index).\nWe also introduce what is called the Metric matrix,\n\uf8eb\n\u22121 0 0\n\uf8ec\n0 1 0\n\u03b7\u03bc\u03bd = \u03b7 \u03bc\u03bd = \uf8ec\n\uf8ed0 0 1\n0 0 0\nIn general, \u03b7 \u03bc\u03bd \u2261 (\u03b7\u03bc\u03bd )\u22121 .\n9\n\n\uf8f6\n0\n0\uf8f7\n\uf8f7\n0\uf8f8\n1\n\n\fUsing the metric, the dot product of any 4-vector x\u03bc = (ct, x, y, z)T can be easily written\nas x2 = x\u03bc x\u03bc = \u03b7\u03bc\u03bd x\u03bc x\u03bd = \u2212c2 t2 + x2 + y 2 + z 2 . In general, a Lorentz transformation can be\ndefined as a matrix L\u03bc\u03bd (including boosts and rotations) that leaves \u03b7\u03bc\u03bd x\u03bc x\u03bd unchanged.\nFor example, a scalar, or an object with no uncontracted indices, like \u03c6 or x\u03bc x\u03bc , is simply\ninvariant under Lorentz transformations (\u03c6 \u2192 \u03c6, x\u03bc x\u03bc \u2192 x\u03bc x\u03bc ).\nA vector, or an object with only one uncontracted index, like x\u03bc or a\u03bc b\u03bd\u03bc , transforms according to x0\u03bc = L\u03bc\u03bd x\u03bd , or (a\u03bc b\u03bd\u03bc )0 = L\u03bd\u03b1 (a\u03bc b\u03b1\u03bc ).\nNow, consider the dot product x2 = x\u03bc x\u03bc = \u03b7\u03bc\u03bd x\u03bc x\u03bd . If x2 is invariant, then x02 = x2 \u21d2\n\u03b7\u03bc\u03bd x0\u03bc x0\u03bd = \u03b7\u03bc\u03bd L\u03bc\u03b1 L\u03bd\u03b2 x\u03b1 x\u03b2 demands that \u03b7\u03bc\u03bd L\u03bc\u03b1 L\u03bd\u03b2 = \u03b7\u03b1\u03b2 . So, the constraint for Lorentz\ntransformations is that they are the set of all matrices such that\n\u03b7\u03bc\u03bd L\u03bc\u03b1 L\u03bd\u03b2 = \u03b7\u03b1\u03b2\nWe take this to be the defining constraint for a Lorentz transformation.\n\n1.1.6\n\nClassical Fields\n\nWhen deriving the Euler-Lagrange\nequations, we started with an action S which was an\nR\nintegral over time only (S \u2261 dtL). If we are eventually interested in a relativistically\nacceptable theory, this is obviously no good because it treats time and space differently\n(the action is an integral over time but not over space).\nSo, let's consider an action defined not in terms of the Lagrangian, but of the \"Lagrangian\nper unit volume\", or the Lagrangian\nbe the\nR n Density L. The Lagrangian will naturally\nn\nintegral of L over all space, L = d xL. The integral is in n-dimensions, so d x means\ndx1 dx2 dx2 * * * dxn .\nR\nR\nNow, the action will be S = dtL = Rdtdn xL. In the\n1+3 dimensional Minkowski\nR normal\n3\n4\nspacetime we live in, this will be S = dtd xL = d xL.\nBefore, L depended not on t, but on the path q(t), q\u0307(t). In a similar sense, L will not\ndepend on x\u0304 and t, but on what we will refer to as Fields, \u03c6(x\u0304, t) = \u03c6(x\u03bc ), which exist in\nspacetime.\nFollowing a nearly identical argument as the one leading to (1.1), we get the relativistic\nfield generalization\n\u0013\n\u0012\n\u2202L\n\u2202L\n\u2212\n=0\n\u2202\u03bc\n\u2202(\u2202\u03bc \u03c6i )\n\u2202\u03c6i\nfor multiple fields \u03c6i (i = 1, . . . , n).\n\n10\n\n\fNoether's Theorem says that, for \u03c6 \u2192 \u03c6 + \u000f\u03b4\u03c6, we have a current j \u03bc \u2261 \u2202(\u2202\u2202L\u03bc \u03c6) \u03b4\u03c6, and if \u03c6 \u2192\n0\n \u0304 * j\u0304 = 0, where j 0 is the Charge Density,\n\u03c6 + \u000f\u03b4\u03c6 leaves \u03b4L = 0, then \u2202\u03bc j \u03bc = 0 \u21d2 \u2212 \u2202j\u2202t + \u2207\nR\nand j\u0304 is the Current Density. The total charge will naturally be Q \u2261 all space d3 xj 0 .\nFinally, we also have a Hamiltonian Density and momentum\n\u2202L\n\u03c6\u0307\u03bc \u2212 L\n\u2202 \u03c6\u0307\u03bc\n\u2202L\n\u2261\n\u2202 \u03c6\u0307\u03bc\n\nH \u2261\n\u03a0\u03bc\n\n(1.7)\n(1.8)\n\nOne final comment for this section. For the remainder of these notes, we will ultimately\nbe seeking a relativistic field theory, and therefore we will never make use of Lagrangians.\nWe will always use Lagrangian densities. We will always use the notation L instead of L,\nbut we will refer to the Lagrangian densities simply as Lagrangians. We drop the word\n\"densities\" for brevity, and because there will never be ambiguity.\n\n1.1.7\n\nClassical Electrodynamics\n\nWe choose our units so that c = \u03bc0 = \u000f0 = 1. So, the magnitude of the force between two\nq1 q2\ncharges q1 and q2 is F = 4\u03c0r\n2 . In these units, Maxwell's equations are\n \u0304 * \u0112\n\u2207\n \u0304 \u00d7 B\u0304 \u2212 \u2202 \u0112\n\u2207\n\u2202t\n \u0304 * B\u0304\n\u2207\n \u0304 \u00d7 \u0112 + \u2202 B\u0304\n\u2207\n\u2202t\n\n= \u03c1\n\n(1.9)\n\n= J \u0304\n\n(1.10)\n\n= 0\n\n(1.11)\n\n= 0\n\n(1.12)\n\n \u0304 \u00d7 \u0100 and\nIf we define the Potential 4-vector A\u03bc = (\u03c6, \u0100), then we can define B\u0304 = \u2207\n \u0304 \u2212 \u2202 \u0100 . Writing B\u0304 and \u0112 this way will automatically solve the homogenous\n\u0112 = \u2212\u2207\u03c6\n\u2202t\nMaxwell equations, (1.11) and (1.12).\nThen, we define the totally antisymmetric Electromagnetic Field Strength Tensor F \u03bc\u03bd as\n\uf8eb\n\uf8f6\n0 \u2212Ex \u2212Ey \u2212Ez\n\uf8ecEx\n0\n\u2212Bz By \uf8f7\n\uf8f7\nF \u03bc\u03bd \u2261 \u2202 \u03bc A\u03bd \u2212 \u2202 \u03bd A\u03bc = \uf8ec\n\uf8edEy Bz\n0\n\u2212Bx \uf8f8\nEz \u2212By Bx\n0\n \u0304 It is straightforward, though tedious, to\nWe define the 4-vector current as J \u03bc = (\u03c1, J).\n\n11\n\n\fshow that\n \u0304 * B\u0304 = 0 and \u2207\n \u0304 \u00d7 \u0112 + \u2202 B\u0304 = 0\n\u2202 \u03bb F \u03bc\u03bd + \u2202 \u03bd F \u03bb\u03bc + \u2202 \u03bc F \u03bd\u03bb = 0 \u21d2 \u2207\n\u2202t\n\u2202\n \u0304 * \u0112 = \u03c1 and \u2207\n \u0304 \u00d7 B\u0304 \u2212 \u0112 = J \u0304\n\u2202\u03bc F \u03bc\u03bd = J \u03bd \u21d2 \u2207\n\u2202t\n1.1.8\n\nClassical Electrodynamics Lagrangian\n\nBringing together the ideas of the previous sections, we now want to construct a Lagrangian density L which will, via Hamilton's Principle, produce Maxwell's equations.\nFirst, we know that L must be a scalar (no uncontracted indices). From our intuition with\n\"Physics I\" type Lagrangians, we know that kinetic terms are quadratic in the derivatives\nof the fundamental coordinates (i.e. 21 m\u1e8b2 = 12 m( dx\n) * ( dx\n)). The natural choice is to take\ndt\ndt\n\u03bc\nA as the fundamental field. It turns out that the correct choice is\n1\nLEM = \u2212 F\u03bc\u03bd F \u03bc\u03bd \u2212 J \u03bc A\u03bc\n4\n(note that the F 2 term is quadratic in \u2202 \u03bc A\u03bd ). So,\n\u0015\n\u0014\nZ\n1\n\u03bc\u03bd\n\u03bc\n4\nS = d x \u2212 F\u03bc\u03bd F \u2212 J A\u03bc\n4\n\n(1.13)\n\n(1.14)\n\nTaking the variation of (1.14) with respect to A\u03bc ,\n\u0014\n\u0015\nZ\n1\n1\n4\n\u03bc\u03bd\n\u03bc\u03bd\n\u03bc\n\u03b4S =\nd x \u2212 F\u03bc\u03bd \u03b4F \u2212 \u03b4F\u03bc\u03bd F \u2212 J \u03b4A\u03bc\n4\n4\n\u0015\n\u0014\nZ\n1\n4\n\u03bc\u03bd\n\u03bc\n=\nd x \u2212 F\u03bc\u03bd \u03b4F \u2212 J \u03b4A\u03bc\n2\n\u0014\n\u0015\nZ\n1\n4\n\u03bc\n\u03bd\n\u03bd\n\u03bc\n\u03bc\n=\nd x \u2212 F\u03bc\u03bd (\u2202 \u03b4A \u2212 \u2202 \u03b4A ) \u2212 J \u03b4A\u03bc\n2\n\u0014\n\u0015\nZ\n4\n\u03bc\n\u03bd\n\u03bc\n=\nd x \u2212 F\u03bc\u03bd \u2202 \u03b4A \u2212 J \u03b4A\u03bc\nIntegrating the first term by parts, and choosing boundary conditions so that \u03b4A vanishes\nat the boundaries,\n\u0014\n\u0015\nZ\n4\n\u03bc\u03bd\n\u03bd\n=\nd x \u2202\u03bc F \u03b4A\u03bd \u2212 J \u03b4A\u03bd\n\u0014\n\u0015\nZ\n4\n\u03bc\u03bd\n\u03bd\n=\nd x \u2202\u03bc F \u2212 J \u03b4A\u03bd\nSo, to have \u03b4S = 0, we must have \u2202\u03bc F \u03bc\u03bd = J \u03bd , and if this is written out one component\nat a time, it will give exactly the inhomogenous Maxwell equations (1.9) and (1.10). And\n12\n\n\fas we already pointed out, the homogenous Maxwell equations become identities when\nwritten in terms of A\u03bc .\nAs a brief note, the way we have chosen to write equation (1.13), in terms of a \"potential\"\nA\u03bc , and the somewhat mysterious antisymmetric \"field strength\" F\u03bc\u03bd , is indicative of an\nextremely deep and very general mathematical structure that goes well beyond classical\nelectrodynamics. We will see this structure unfold as we proceed through these notes.\nWe just want to mention now that this is not merely a clever way of writing electric and\nmagnetic fields, but a specific example of a general theory.\n\n1.1.9\n\nGauge Transformations\n\nGauge Transformations are usually discussed toward the end of an undergraduate\ncourse on E&M. Students are typically told that they are extremely important, but the\nreason why is not obvious. We will briefly introduce them here, and while their significance may still not be transparent, we will return to them several times throughout these\nnotes.\nGiven some specific potential A\u03bc , we can find the field strength action as in (1.14). However, A\u03bc does not uniquely specify the action. We can take any arbitrary function \u03c7(x\u03bc ),\nand the action will be invariant under the transformation\nA\u03bc \u2192 A0\u03bc = A\u03bc + \u2202 \u03bc \u03c7\n\n(1.15)\n\nor\nA\u03bc \u2192 A0\u03bc = (\u03c6 \u2212\n\n\u2202\u03c7\n \u0304\n, \u0100 + \u2207\u03c7)\n\u2202t\n\nUnder this transformation, we have\nF 0\u03bc\u03bd = \u2202 \u03bc A0\u03bd \u2212 \u2202 \u03bd A0\u03bc = \u2202 \u03bc (A\u03bd + \u2202 \u03bd \u03c7) \u2212 \u2202 \u03bd (A\u03bc + \u2202 \u03bc \u03c7)\n= \u2202 \u03bc A\u03bd \u2212 \u2202 \u03bd A\u03bc + \u2202 \u03bc \u2202 \u03bd \u03c7 \u2212 \u2202 \u03bc \u2202 \u03bd \u03c7\n= F \u03bc\u03bd\n\n(1.16)\n\nSo, F 0\u03bc\u03bd = F \u03bc\u03bd .\nFurthermore, J \u03bc A\u03bc \u2192 J \u03bc A\u03bc + J \u03bc \u2202\u03bc \u03c7. Integrating the second term by parts with the usual\nboundary conditions,\nZ\nZ\n4\n\u03bc\nd xJ \u2202\u03bc \u03c7 = \u2212 d4 x(\u2202\u03bc J \u03bc )\u03c7\nBut, according to Maxwell's equations, \u2202\u03bc J \u03bc = \u2202\u03bc \u2202\u03bd F \u03bc\u03bd \u2261 0 because F \u03bc\u03bd is totally antisymmetric. So, both F \u03bc\u03bd and J \u03bc \u2202\u03bc \u03c7 are invariant under (1.15), and therefore the action of\nS is invariant under (1.15).\n13\n\n\fWhile the importance of gauge transformations may not be obvious at this point, it will\nbecome perhaps the most important idea in particle physics. As a note before moving on,\nrecall previously when we mentioned the idea of \"what doesn't change when something\nelse changes\" when talking about Lorentz transformations. A gauge transformation is\nexactly this (in a different context): the fundamental fields are changed by \u03c7, but the\nequations which govern the physics are unchanged.\nIn the next section, we provide the mathematical tools to understand why this idea is so\nimportant.\n1.2\n\nReferences and Further Reading\n\nThe material in this section can be found in nearly any introductory text on Classical\nMechanics, Classical Electrodynamics, and Relativity. The primary sources for these notes\nare [3], [12], and [13].\nFor further reading, we recommend [6], [18], [19], [22], [33], and [34].\n\n14\n\n\f2\n\nPart II - Algebraic Foundations\n\n2.1\n\nIntroduction to Group Theory\n\nThere are several symbols in this section which may not be familiar. We therefore provide\na summary of them for reference.\nN = {0, 1, 2, 3, . . .}\nZ = {0, \u00b11, \u00b12, \u00b13, . . .}\nQ = Rational Numbers\nR = Real Numbers\nC = Complex Numbers\nZn = Z mod n\n\n\u21d2 is read \"implies\"\niff is read \"if and only if\"\n\u2200 is read \"for every\"\n\u2203 is read \"there exists\"\n\u2208 is read \"in\"\n3 is read \"such that\"\n\n=\n \u0307 is \"represented by\"\n\u2282 is \"subset of\"\n\u2261 is \"defined as\"\n\nNow that we have reviewed the primary ideas of classical physics, we are almost ready to\nstart talking about particle physics. However, there is a bit of mathematical \"machinery\"\nwe will need first. Namely, Group Theory.\nGroup theory is, in short, the mathematics of symmetry. We are going to begin talking\nabout what will seem to be extremely abstract ideas, but eventually we will explain how\nthose ideas relate to physics. As a preface of what is to come, the most foundational idea\nhere is, as we said before, \"what doesn't change when something else changes\". A group\nis a precise and well-defined way of specifying the thing or things that change.\n\n2.1.1\n\nWhat is a Group?\n\nTo begin with, we define the notion of a Group. This definition may seem cryptic, but it\nwill be explained in the paragraphs that follow.\nA group, denoted (G, ?), is a set of objects, denoted G, and some operation on those objects, denoted ?, subject to the following:\n1.\n2.\n3.\n4.\n\n\u2200 g1 , g2 \u2208 G, g1 ? g2 \u2208 G also. (closure)\n\u2200 g1 , g2 , g3 \u2208 G, it must be true that (g1 ? g2 ) ? g3 = g1 ? (g2 ? g3 ). (associativity)\n\u2203g \u2208 G, denoted e, 3 \u2200gi \u2208 G, e ? gi = gi ? e = gi . (identity)\n\u2200g \u2208 G, \u2203h \u2208 G 3 h ? g = g ? h = e, (so h = g \u22121 ). (inverse)\n\nNow we explain what this means. By \"objects\" we literally mean anything. We could be\ntalking about Z or R, or we could be talking about a set of Easter eggs all painted different\ncolors.\n\n15\n\n\fThe meaning of \"some operation\", which we are calling ?, can literally be anything you\ncan do to those objects. A formal definition of what ? means could be given, but it will be\neasier to understand with examples.\nNote: The definition of a group doesn't demand that gi ? gj = gj ? gi . This is a very\nimportant point, but we will discuss it in more detail later. We mention it now so it is not\nnew later.\nExample 1:\n\n(G, ?) = (Z, +)\n\nConsider the set G to be Z, and the operation to be ? = +, or simply addition.\nWe first check closure. If you take any two elements of Z and add them together, is the result in Z? In other words, if a, b \u2208 Z, is a + b \u2208 Z? Obviously\nthe answer is yes; the sum of two integers is an integer, so closure is met.\nNow we check associativity. If a, b, c \u2208 Z, it is trivially true that a + (b + c) =\n(a + b) + c. So, associativity is met.\nNow we check identity. Is there an element e \u2208 Z such that when you add e\nto any other integer, you get that same integer? Clearly the integer 0 satisfies\nthis. So, identity is met.\nFinally, is there an inverse? For any integer a \u2208 Z, will there be another integer\nb \u2208 Z such that a + b = e = 0? Again, this is obvious, a\u22121 = \u2212a in this case. So,\ninverse is met.\nSo, (G, ?) = (Z, +) is a group.\nExample 2:\n\n(G, ?) = (R, +)\n\nObviously, any two real numbers added together is also a real number.\nAssociativity will hold (of course).\nThe identity is again 0.\nAnd finally, once again, \u2212a will be the inverse of any a \u2208 R.\nExample 3:\n\n(G, ?) = (R, *) (multiplication)\n\nCloser is met; two real numbers multiplied together give a real number.\nAssociativity obviously holds.\nIdentity also holds. Any real number a \u2208 R, when multipled by 1 is a.\nInverse, on the other hand, is trickier. For any real number, is there another\nreal number you can multiply by it to get 1? The instinctive choice is a\u22121 = a1 .\nBut, this doesn't quite work because of a = 0. This is the only exception, but\nbecause there's an exception, (R, *) is not a group.\nNote: If we take the set R \u2212 {0} instead of R, then (R \u2212 {0}, *) is a group.\n16\n\n\fExample 4:\n\n(G, ?) = ({1}, *)\n\nThis is the set with only the element 1, and the operation is normal multiplication. This is indeed a group, but it is extremely uninteresting, and is called the\nTrivial Group.\nExample 5:\n\n(G, ?) = (Z3 , +)\n\nThis is the set of integers mod 3, containing only the elements 0, 1, and 2\n(3 mod 3 is 0, 4 mod 3 is 1, 5 mod 3 is 2, etc.)\nYou can check yourself that this is a group.\n\n2.1.2\n\nFinite Discrete Groups and Their Organization\n\nFrom the examples above, several things should be apparent about groups. One is that\nthere can be any number of objects in a group. We have a special name for the number of\nobjects in the group's set. The Order of a group is the number of elements in it.\nThe order of (Z, +) is infinite (there are an infinite number of integers), as is the order of\n(R, +) and (R \u2212 {0}, *). But, the order of ({1}, *) is 1, and the order of (Z3 , +) is 3.\nIf the order of a group is finite, the group is said to be Finite. Otherwise it is Infinite.\nIt is also clear that the elements of groups may be Discrete, or they may be Continuous.\nFor example, (Z, +), ({1}, *), and (Z3 , +) are all discrete, while (R, +) and (R \u2212 {0}, *) are\nboth continuous.\nNow that we understand what a discrete finite group is, we can talk about how to organize one. Namely, we use what is called a Multiplication Table. A multiplication table is\na way of organizing the elements of a group as follows:\n(G, ?)\ne\ng1\ng2\n..\n.\n\ne\ne?e\ng1 ? e\ng2 ? e\n..\n.\n\ng1\ne ? g1\ng1 ? g 1\ng2 ? g 1\n..\n.\n\ng2\ne ? g2\ng1 ? g2\ng2 ? g2\n..\n.\n\n***\n***\n***\n***\n...\n\nWe state the following property of multiplication tables without proof. A multiplication\ntable must contain every element of the group exactly one time in every row and every column. A\nfew minutes thought should convince you that this is necessary to ensure that the definition of a group is satisfied.\n\n17\n\n\fAs an example, we will draw a multiplication table for the group of order 2. We won't\nlook at specific numbers, but rather call the elements g1 and g2 . We begin as follows:\n(G, ?)\ne\ng1\n\ne\n?\n?\n\ng1\n?\n?\n\nThree of these are easy to fill in from the identity:\n(G, ?)\ne\ng1\n\ne\ne\ng1\n\ng1\ng1\n?\n\nAnd because we know that every element must appear exactly once, the final question\nmark must be e. So, there is only one possible group of order 2.\nWe will consider a few more examples, but we stress at this point that the temptation to\nplug in numbers should be avoided. Groups are abstract things, and you should try to\nthink of them in terms of the abstract properties, not in terms of actual numbers.\nWe can proceed with the multiplication table for the group of order 3. You will find that,\nonce again, there is only one option. (Doing this is instructive and it would be helpful to\nwork this out yourself.)\n(G, ?)\ne\ng1\ng2\n\ne\ne\ng1\ng2\n\ng1\ng1\ng2\ne\n\ng2\ng2\ne\ng1\n\nYou are encouraged to work out the possibilities for groups of order 4. (Hint: there are 4\npossibilities.)\n\n2.1.3\n\nGroup Actions\n\nSo far we have only considered elements of groups and how they relate to each other. The\npoint has been that a particular group represents nothing more than a structure. There\nare a set of things, and they relate to each other in a particular way. Now, however, we\nwant to consider an extremely simple version of how this relates to nature.\n18\n\n\fExample 6\nConsider three Easter eggs, all painted different colors (red, orange, and yellow), which we denote R, O, and Y. Now, assume they have been put into a\nrow in the order (ROY). If we want to keep them lined up, not take any eggs\naway, and not add any eggs, what we can we do to them? We can do any of\nthe following:\n1. Let e be doing nothing to the set, so e(ROY ) = (ROY ).\n2. Let g1 be a cyclic permutation of the three, g1 (ROY ) = (OY R)\n3. Let g2 be a cyclic permutation in the other direction, g2 (ROY ) = (Y RO)\n4. Let g3 be swapping the first and second, g3 (ROY ) = (ORY )\n5. Let g4 be swapping the first and third, g4 (ROY ) = (Y OR)\n6. Let g5 be swapping the second and third, g5 (ROY ) = (RY O)\nYou will find that these 6 elements are closed, there is an identity, and each has\nan inverse.2 So, we can draw a multiplication table (you are strongly encouraged to write at least part of this out on your own):\n(G, ?)\ne\ng1\ng2\ng3\ng4\ng5\n\ne\ne\ng1\ng2\ng3\ng4\ng5\n\ng1\ng1\ng2\ne\ng4\ng5\ng3\n\ng2\ng2\ne\ng1\ng5\ng3\ng4\n\ng3\ng3\ng5\ng4\ne\ng2\ng1\n\ng4\ng4\ng3\ng5\ng1\ne\ng2\n\ng5\ng5\ng4\ng3\ng2\ng1\ne\n\nThere is something interesting about this group. Notice that g3 ? g1 = g4 , whereas g1 ? g3 =\ng5 . So, we have the surprising result that in this group it is not necessarily true that\ngi ? gj = gj ? gi .\nThis leads to a new way of classifying groups. We say a group is Abelian if gi ? gj = gj ? gi\n\u2200gi , gj \u2208 G. If a group is not Abelian, it is Non-Abelian.\nAnother term commonly used is Commute. If gi ? gj = gj ? gi , then we say that gi and\ngj commute. So, an Abelian group is Commutative, whereas a Non-Abelian group is\nNon-Commutative.\n2\n\nWe should be very careful to draw a distinction between the elements of the group and the objects the\ngroup acts on. The objects in this example are the eggs, and the permutations are the results of the group\naction. Neither the eggs nor the permutations of the eggs are the elements of the group. The elements of\nthe group are abstract objects which we are assigning to some operation on the eggs, resulting in a new\npermutation\n\n19\n\n\fThe Easter egg group of order 6 above is an example of a very important type of group. It\nis denoted S3 , and is called the Symmetric Group. It is the group that takes three objects\nto all permutations of those three objects.\nThe more general group of this type is Sn , the group that takes n objects to all permutations of those objects. You can convince yourself that Sn will always have order n! (n\nfactorial).\nThe idea above with the 3 eggs is that S3 is the group, while the eggs are the objects that\nthe group acts on. The particular way an element of S3 changes the eggs around is called\nthe Group Action of that element. And each element of S3 will move the eggs around\nwhile leaving them lined up. This ties in to our overarching concept of \"what doesn't\nchange when something else changes\". The fact that there are 3 eggs with 3 particular\ncolors lined up doesn't change. The order they appear in does.\n\n2.1.4\n\nRepresentations\n\nWe suggested above that you think of groups as purely abstract things rather than trying\nto plug in actual numbers. Now, however, we want to talk about how to see groups,\nor the elements of groups, in terms of specific numbers. But, we will do this in a very\nsystematic way. The name for a specific set of numbers or objects that form a group is\na Representation. The remainder of this section (and the next) will primarily be about\ngroup representations.\nWe already discussed a few simple representations when we discussed (Z, +), (R\u2212{0}, *),\nand (Z3 , +). Let's focus on (Z3 , +) for a moment (the integers mod 3, where e = 0, g1 = 1,\n2\u03c0i\ng2 = 2, with addition). Notice that we could alternatively define e = 1, g1 = e 3 , and g2 =\n4\u03c0i\ne 3 , and let ? be multiplication. So, in the \"representation\" with (0, 1, 2) and addition, we\nhad for example\ng1 ? g2 = (1 + 2) mod 3 = 3 mod 3 = 0 = e\nwhereas now with the multiplicative representation we have\ng1 ? g2 = e\n\n2\u03c0i\n3\n\n*e\n\n4\u03c0i\n3\n\n= e2\u03c0i = e0 = 1 = e\n\nSo the structure of the group is preserved in both representations.\nWe have two completely different representations of the same group. This idea of different ways of expressing the same group is of extreme importance, and we will be using it\nthroughout the remainder of these notes.\nWe now see a more rigorous way of coming up with representations of a particular group.\nWe begin by introducing some notation. For a group (G, ?) with elements g1 , g2 , . . ., we\ncall the Representation of that group D(G), so that the elements of G are D(e), D(g1 ),\n20\n\n\fD(g2 ) (where each D(gi ) is a matrix of some dimension). We then choose ? to be matrix\nmultiplication. So, D(gi ) * D(gj ) = D(gi ? gj ).\nIt may not seem that we have done anything profound at this point, but we most definitely have. Remember above that we encouraged seeing groups as abstract things, rather\nthan in terms of specific numbers. This is because a group is fundamentally an abstract\nobject. A group is not a specific set of numbers, but rather a set of abstract objects with a\nwell-defined structure telling you how those elements relate to each other.\nAnd the beauty of a representation D is that, via normal matrix multiplication, we have\na sort of \"lens\", made of familiar things (like numbers, matrices, or Easter eggs), through\nwhich we can see into this abstract world. And because D(gi ) * D(gj ) = D(gi ? gj ), we\naren't losing any of the structure of the abstract group by using a representation.\nSo now that we have some notation, we can develop a formalism to figure out exactly\nwhat D is for an arbitrary group.\nWe will use Dirac vector notation, where the column vector\n\uf8eb \uf8f6\nv1\n\uf8ecv2 \uf8f7\n\uf8ec \uf8f7\nv\u0304 = \uf8ecv \uf8f7 = |vi\n\uf8ed 3\uf8f8\n..\n.\nand the row vector\n\u0001\nv\u0304 T = v1 v2 v3 * * * = hv|\nSo, the dot product between two vectors is\n\uf8eb \uf8f6\nu1\n\uf8ec\n\u0001 \uf8ecu2 \uf8f7\n\uf8f7\nv\u0304 * \u016b = v1 v2 v3 * * * \uf8ecu \uf8f7 = v1 u1 + v2 u2 + v3 u3 + * * * \u2261 hv|ui\n\uf8ed 3\uf8f8\n..\n.\nNow, we proceed by relating each element of a finite discrete group to one of the standard\northonormal unit vectors:\ne \u2192 |ei = |\u00ea1 i\n\ng1 \u2192 |g1 i = |\u00ea2 i\n\ng2 \u2192 |g2 i = |\u00ea3 i\n\nAnd we define the way an element in a representation D(G) acts on these vectors to be\nD(gi )|gj i = |gi ? gj i\nNow, we can build our representation. We will (from now on unless otherwise stated)\nrepresent the elements of a group G using matrices of various sizes, and the group operation ? will be standard matrix multiplication. The specific matrices that represent a given\n21\n\n\felement gk of our group will be given by\n[D(gk )]ij = hgi |D(gk )|gj i\n\n(2.1)\n\nAs an example, consider again the group of order 2 (we wrote out the multiplication table\nabove on page 18). First, we find the matrix representation of the identity, [D(e)]ij ,\n[D(e)]11 = he|D(e)|ei\n[D(e)]12 = he|D(e)|g1 i\n[D(e)]21 = hg1 |D(e)|ei\n[D(e)]22 = hg1 |D(e)|g1 i\n\nhe|e ? ei = he|ei = 1\nhe|e ? g1 i = he|g1 i = 0\nhg1 |e ? ei = hg1 |ei = 0\nhg1 |e ? g1 i = hg1 |g1 i = 1\n\u0012\n\u0013\n1 0\nSo, the matrix representation of the identity is D(e) =\n \u0307\n. It shouldn't be surprising\n0 1\nthat the identity element is represented by the identity matrix.\n=\n=\n=\n=\n\nNext we find the representation of D(g1 ):\n[D(g1 )]11 = he|D(g1 )|ei\n[D(g1 )]12 = he|D(g1 )|g1 i\n[D(g1 )]21 = hg1 |D(g1 )|ei\n[D(g1 )]22 = hg1 |D(g1 )|g1 i\n\n= he|g1 ? ei = he|g1 i = 0\n= he|g1 ? g1 i = he|ei = 1\n= hg1 |g1 ? ei = hg1 |g1 i = 1\n= hg1 |g1 ? g1 i = hg1 |ei = 0\n\u0012\n\u0013\n0 1\nSo, the matrix representation of g1 is D(g1 ) =\n \u0307\n. It is straightforward to check that\n1 0\nthis is a true representation,\n\u0012\n\u0013\u0012\n\u0013 \u0012\n\u0013\n1 0\n1 0\n1 0\ne?e=\n=\n=e\nX\n0 1\n0 1\n0 1\n\u0012\n\u0013\u0012\n\u0013 \u0012\n\u0013\n1 0\n0 1\n0 1\ne ? g1 =\n=\n= g1\nX\n0 1\n1 0\n1 0\n\u0012\n\u0013\u0012\n\u0013 \u0012\n\u0013\n0 1\n1 0\n0 1\ng1 ? e =\n=\n= g1\nX\n1 0\n0 1\n1 0\n\u0012\n\u0013\u0012\n\u0013 \u0012\n\u0013\n0 1\n0 1\n1 0\ng1 ? g1 =\n=\n=e\nX\n1 0\n1 0\n0 1\nInstead of considering the next obvious example, the group of order 3, consider the group\nS3 from above (the multiplication table is on page 19). The identity representation D(e) is\neasy - it is just the 6\u00d76 identity matrix. We encourage you to work out the representation\nof D(g1 ) on your own, and check to see that it is\n\uf8eb\n\uf8f6\n0 0 1 0 0 0\n\uf8ec1 0 0 0 0 0\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec0 1 0 0 0 0\uf8f7\n\uf8ec\n\uf8f7\nD(g1 ) =\n \u0307 \uf8ec\n(2.2)\n\uf8f7\n0\n0\n0\n0\n1\n0\n\uf8ec\n\uf8f7\n\uf8ed0 0 0 0 0 1\uf8f8\n0 0 0 1 0 0\n22\n\n\fAll 6 matrices can be found this way, and multiplying them out will confirm that they do\nindeed satisfy the group structure of S3 .\n\n2.1.5\n\nReducibility and Irreducibility - A Preview\n\nYou have probably noticed that equation (2.1) will always produce a set of n \u00d7 n matrices, where n is the order of the group. There is actually a name for this particular\nrepresentation. The n \u00d7 n matrix representation of a group of order n is called the Regular\nRepresentation. More generally, the m \u00d7 m matrix representation of a group (of any order) is\ncalled the m-dimensional representation.\nBut, as we have seen, there is more than one representation for a given group (in fact,\nthere are an infinite number of representations).\nOne thing we can immediately see is that any group that is Non-Abelian cannot have a\n1 \u00d7 1 matrix representation. This is because scalars (1 \u00d7 1 matrices) always commute,\nwhereas matrices in general do not.\nWe saw above in equation (2.2) that we can represent the group Sn by n! \u00d7 n! matrices.\nOr, more generally, we can represent any group using m \u00d7 m matrices, were m equals\norder(G). This is the regular representation. But it turns out that it is usually possible to\nfind representations that are \"smaller\" than the regular representation.\nTo pursue how this might be done, note that we are working with matrix representations\nof groups. In other words, we are representing groups in linear spaces. We will therefore\nbe using a great deal of linear algebra to find smaller representations. This process, of\nfinding a smaller representation, is called Reducing a representation. Given an arbitrary\nrepresentation of some group, the first question that must be asked is \"is there a smaller\nrepresentation?\" If the answer is yes, then the representation is said to be Reducible. If\nthe answer is no, then it is Irreducible.\nBefore we dive into the more rigorous approach to reducibility and irreducibility, let's\nconsider a more intuitive example, using S3 . In fact, we'll stick with our three painted\nEaster eggs, R, O, and Y :\n1.\n2.\n3.\n4.\n5.\n6.\n\ne(ROY ) = (ROY )\ng1 (ROY ) = (OY R)\ng2 (ROY ) = (Y RO)\ng3 (ROY ) = (ORY )\ng4 (ROY ) = (Y OR)\ng5 (ROY ) = (RY O)\n\n23\n\n\f\uf8eb \uf8f6\nR\n\uf8ed\nWe will represent the set of eggs by a column vector |Ei = O \uf8f8.\nY\nNow, by inspection, what matrix would do to |Ei what g1 does to (ROY )? In other words,\nhow can we fill in the ?'s in\n\uf8eb\n\uf8f6\uf8eb \uf8f6 \uf8eb \uf8f6\n? ? ?\nR\nO\n\uf8ed? ? ?\uf8f8 \uf8edO \uf8f8 = \uf8edY \uf8f8\n? ? ?\nY\nR\nto make the equality hold? A few moments thought will show that the appropriate matrix\nis\n\uf8eb\n\uf8f6\uf8eb \uf8f6 \uf8eb \uf8f6\n0 1 0\nR\nO\n\uf8ed0 0 1\uf8f8 \uf8edO \uf8f8 = \uf8edY \uf8f8\n1 0 0\nY\nR\nContinuing this reasoning, we can see that the rest of the matrices are\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n1 0 0\n0 1 0\n0 0 1\nD(e) =\n \u0307 \uf8ed0 1 0\uf8f8 ,\nD(g1 ) =\n \u0307 \uf8ed0 0 1\uf8f8 ,\nD(g2 ) =\n \u0307 \uf8ed1 0 0\uf8f8\n0 0 1\n1 0 0\n0 1 0\n\uf8eb\n\n\uf8f6\n0 1 0\nD(g3 ) =\n \u0307 \uf8ed1 0 0\uf8f8 ,\n0 0 1\n\n\uf8eb\n\uf8f6\n0 0 1\nD(g4 ) =\n \u0307 \uf8ed0 1 0\uf8f8 ,\n1 0 0\n\n\uf8eb\n\n\uf8f6\n1 0 0\nD(g5 ) =\n \u0307 \uf8ed0 0 1\uf8f8\n0 1 0\n\nYou can do the matrix multiplication to convince yourself that this is in fact a representation of S3 .\nSo, in equation (2.2), we had a 6 \u00d7 6 matrix representation. Here, we have a new representation of consisting of 3 \u00d7 3 matrices. We have therefore \"reduced\" the representation.\nIn the next section, we will look at more mathematically rigorous ways of reducing representations.\n\n2.1.6\n\nAlgebraic Definitions\n\nBefore moving on, we must spend this section learning the definitions of several terms\nwhich are used in group theory.\nIf H is a subset of G, denoted H \u2282 G, such that the elements of H form a group, then we say that\nH forms a Subgroup of G. We make this more precise with examples.\n\n24\n\n\fExample 7\nConsider (as usual) the group S3 , with the elements labeled as before:\n1.\n2.\n3.\n4.\n5.\n6.\n\ng0 (ROY ) = (ROY )\ng1 (ROY ) = (OY R)\ng2 (ROY ) = (Y RO)\ng3 (ROY ) = (ORY )\ng4 (ROY ) = (Y OR)\ng5 (ROY ) = (RY O)\n\n(where we are relabeling g0 \u2261 e for later convenience). The multiplication\ntable is given on page 19.\nNotice that {g0 , g1 , g2 } form a subgroup. You can see this by noticing that the\nupper left 9 boxes in the multiplication table (the g0 , g1 , g2 rows and columns)\nall have only g0 's, g1 's, and g2 's. So, here is a group of order 3 contained in S3 .\nExample 8\nConsider the subset of S3 consisting of g0 and g3 only. Both g0 and g3 are their\nown inverses, so the identity exists, and the group is closed. Therefore, we can\nsay that {g0 , g3 } \u2282 S3 is a subgroup of S3 .\nIn fact, if you write out the multiplication table for g0 and g3 only, you will\nsee that it is exactly equivalent to the group of order 2 considered above. This\nmeans that we can say that S3 contains the group of order 2 (and we know from\nlast time that there is only one such group, though there are an infinite number\nof representations of it). The way we understand this is that the abstract entity\nS3 , of which there is only one, contains the group of order 2, of which there\nis only one. However, the representations of S3 , of which there are an infinite\nnumber, will each contain the group of order 2 (of which there are also an\ninfinite number of representations).\nExample 9\nNotice that the sets {g0 , g3 }, {g0 , g4 }, and {g0 , g5 } (all \u2282 S3 ), are all the same as\nthe group of order 2. This means that S3 actually contains exactly three copies\nof the group of order 2 in addition to the single copy of the group of order 3.\nAgain, this is speaking in terms of the abstract entity S3 . We can see this\nthrough the \"lens\" of representation by the fact that any representation of S3\nwill contain three different copies of the group of order 2.\n\n25\n\n\fExample 10\nAs a final example of subgroups, there are two subgroups of any group, no\nmatter what the group. One is the subgroup consisting of only the identity,\n{g0 } \u2282 G. All groups contain this, but it is never very interesting.\nSecondly, \u2200G, G \u2282 G, and therefore G is always a subgroup of itself. We call\nthese subgroups the \"trivial\" subgroups.\nWe now introduce another important definition.\nIf G is a group, and H is a subgroup of G (H \u2282 G), then\n\u2022 The set gH = {g ? h|h \u2208 H} is called the Left Coset of H in G\n\u2022 The set Hg = {h ? g|h \u2208 H} is called the Right Coset of H in G\nThere is a right (or left) coset for each element g \u2208 G, though they are not necessarily all\nunique. This definition should be understood as follows; a coset is a set consisting of the\nelements of H all multiplied on the right (or left) by some element of G.\nExample 11\nFor the subgroup H = {g0 , g1 } \u2282 S3 discussed above, the left cosets are\ng0 {g0 , g1 } = {g0 ? g0 , g0 ? g1 } = {g0 , g1 }\ng1 {g0 , g1 } = {g1 ? g0 , g1 ? g1 } = {g1 , g2 }\ng2 {g0 , g1 } = {g2 ? g0 , g2 ? g1 } = {g2 , g0 }\ng3 {g0 , g1 } = {g3 ? g0 , g3 ? g1 } = {g3 , g4 }\ng4 {g0 , g1 } = {g4 ? g0 , g4 ? g1 } = {g4 , g5 }\ng5 {g0 , g1 } = {g5 ? g0 , g5 ? g1 } = {g5 , g3 }\nSo, the left cosets of {g0 , g1 } in S3 are {g0 , g1 }, {g1 , g2 }, {g2 , g0 }, {g3 , g4 }, {g4 , g5 },\nand {g5 , g3 }.\nWe can now understand the following definition. H is a Normal Subgroup of G if \u2200h \u2208 H,\ng \u22121 ? h ? g \u2208 H. Or, in other words, if H denotes the subgroup, it is a normal subgroup if\ngH = Hg, which says that the left and right cosets are all equal.\nAs a comment, saying gH and Hg are equal doesn't mean that each individual element\nin the coset gH is equal to the corresponding element in Hg, but rather that the two\ncosets contain the same elements, regardless of their order. For example, if we had the\ncosets {gi , gj , gk } and {gj , gk , gi }, they would be equal because they contain the same three\nelements.\n26\n\n\fThis definition means that if you take a subgroup H of a group G, and you multiply the\nentire set on the left by some element of g \u2208 G, the resulting set will contain the exact same\nelements it would if you had multiplied on the right by the same element g \u2208 G. Here is\nan example to illustrate.\nExample 12\nConsider the order 2 subgroup {g0 , g3 } \u2282 S3 . Multiplying on the left by, say,\ng4 , gives\ng4 ? {g0 , g3 } = {g4 ? g0 , g4 ? g3 } = {g4 , g2 }\nAnd multiplying on the right by g4 givs\n{g0 , g3 } ? g4 = {g0 ? g4 , g3 ? g4 } = {g4 , g1 }\nSo, because the final sets do not contain the same elements, {g4 , g2 } 6= {g4 , g1 },\nwe conclude that the subgroup {g0 , g3 } is not a normal subgroup of S3 .\nExample 13\nAbove, we found that {g0 , g1 , g2 } \u2282 S3 is a subgroup of order 3 in S3 . To use a\nfamiliar label, remember that we previously called the group of order 3 (Z3 , +).\nSo, dropping the '+0 , we refer to the group of order 3 as Z3 . Is this subgroup\nnormal? We leave it to you to show that it is.\nExample 14\nConsider the group of integers under addition, (Z, +). And, consider the subgroup Zeven \u2282 Z, the even integers under addition (we leave it to you to show\nthat this is indeed a group).\nNow, take some odd integer nodd and act on the left:\nnodd + Zeven = {nodd + 0, nodd \u00b1 2, nodd \u00b1 4, . . .}\nand then on the right:\nZeven + nodd = {0 + nodd , \u00b12 + nodd , \u00b14 + nodd , . . .}\nNotice that the final sets are the same (because addition is commutative). So,\nZeven \u2282 Z is a normal subgroup.\nWith a little thought, you can convince yourself that all subgroups of Abelian groups are\nnormal.\nIf G is a group and H \u2282 G is normal, then the Factor Group of H in G, denoted G/H (read \"G\nmod H\"), is the group with elements in the set G/H \u2261 {gH|g \u2208 G}. The group operation ? is\nunderstood to be\n(gi H) ? (gj H) = (gi ? gj )H\n27\n\n\fExample 15\nConsider again Zeven . Notice that we can call Zeven = 2Z because 2Z =\n2{0, \u00b11, \u00b12\u00b13, . . .} = {0, \u00b12, \u00b14, . . .} = Zeven . We know that 2Z \u2282 Z is normal,\nso we can build the factor group Z/2Z as\nZ/2Z = {0 + 2Z, \u00b11 + 2Z, \u00b12 + 2Z, . . .}\nBut, notice that\nneven + 2Z = Zeven\nnodd + 2Z = Zodd\nSo, the group Z/2Z only has 2 elements; the set of all even integers, and the set\nof all odd integers. And we know from before that there is only one group of\norder 2, which we denote Z2 . So, we have found that Z/2Z = Z2 .\nYou can also convince yourself of the more general result\nZ/nZ = Zn\nExample 16\nFinally, we consider the factor groups G/G and G/e.\n\u2022 G/G - The set G = {g0 , g1 , g2 , . . .} will be the same coset for any element\nof G multiplied by it. Therefore this factor group consists of only one\nelement, and therefore G/G = e, the trivial group.\n\u2022 G/e - The set {e} will be a unique coset for any element of G, and therefore G/e = G.\nSomething that might help you understand factor groups better is this: the factor group\nG/H is the group that is left over when everything in H is \"collapsed\" to the identity\nelement. Think about the above examples in terms of this picture.\nIf G and H are both groups (not necessarily related in any way), then we can form the Product\nGroup, denoted K \u2261 G \u2297 H, where an arbitrary element of K is (gi , hj ). If the group operation\nof G is ?G , and the group operation of H is ?H , then two elements of K are multiplied according\nto the rule\n(gi , hj ) ?K (gk , hl ) \u2261 (gi ?G gk , hj ?H hl )\n\n28\n\n\f2.1.7\n\nReducibility Revisited\n\nNow that we understand subgroups, cosets, normal subgroups, and factor groups, we\ncan begin a more formal discussion of reducing representations. Recall that in deriving\nequation (2.1), we made the designation\ng0 \u2192 |\u00ea1 i\n\ng1 \u2192 |\u00ea2 i\n\ng2 \u2192 |\u00ea3 i\n\netc.\n\nThis was used to create an order(G)-dimensional Euclidian space which, while not having\nany \"physical\" meaning, and while obviously not possessing any structure similar to the\ngroup, was and will continue to be of great use to us.\nWe have an n-dimensional space spanned by the orthonormal vectors |g0 i, |g1 i, . . . , |gn\u22121 i,\nwhere g0 is understood to always refer to the identity element. This brings us to the first\ndefinition of this section. For a group G = {g0 , g1 , g2 , . . .}, we call the Algebra of G the set\nC[G] \u2261\n\n\u001aX\nn\u22121\n\n\u001b\nci |gi i ci \u2208 C \u2200i\n\ni=0\n\nIn other words, C[G] is the set of all possible linear combinations of the vectors |gi i with\ncomplex coefficients.\nWe could have defined the algebra over Z or R, but we used C for generality at this point.\nAddition of two elements of C[G] is merely normal addition of linear combinations,\nn\u22121\nX\ni=0\n\nci |gi i +\n\nn\u22121\nX\n\ndi |gi i =\n\ni=0\n\nn\u22121\nX\n(ci + di )|gi i\ni=0\n\nThis definition amounts to saying that, in the n-dimensional Euclidian space we have created, with n = order(G), you can choose any point in the space with complex coefficients,\nand this will correspond to a particular linear combination of elements of G.\nNow that we have defined an algebra, we can talk about group actions. Recall that the\ngi 's don't act on the |gj i's, but rather the representation D(gi ) does. We define the action\nD(gi ) on an element of C[G] as follows:\nD(gi ) *\n\nn\u22121\nX\n\ncj |gj i = D(gi ) * (c0 |g0 i + c1 |g1 i + * * * + cn\u22121 |gn\u22121 i)\n\nj=0\n\n= c0 |gi ? g0 i + c1 |gi ? g1 i + * * * + cn\u22121 |gi ? gn\u22121 i =\n\nn\u22121\nX\n\ncj |gi ? gj i\n\nj=0\n\nPreviously, we discussed how elements of a group act on each other, and we also talked\nabout how elements of a group act on some other object or set of objects (like three painted\n29\n\n\feggs). We now generalize this notion to a set of q abstract objects a group can act on,\ndenoted M = {m0 , m1 , m2 , . . . , mq\u22121 }. Just as before, we build a vector space, similar to\nthe one above used in building an algebra. The orthonormal vectors here will be\nm0 \u2192 |m0 i,\n\nm1 \u2192 |m1 i,\n\nmq\u22121 \u2192 |mq\u22121 i\n\n...\n\nThis allows us to understand the following definition.\nThe set\nCM \u2261\n\n\u001aX\nq\u22121\n\n\u001b\nci |mi i ci \u2208 C \u2200i\n\ni=0\n\nis called the Module of M . (We don't use the square brackets here to distinguish modules\nfrom algebras). In other words, the space spanned by the |mi i is the module.\nExample 17\nConsider, once again, S3 . However, we generalize from three eggs to three\n\"objects\" m0 , m1 , and m2 . So, CM is all points in the 3-dimensional space of\nthe form c0 |m0 i + c1 |m1 i + c2 |m2 i with ci \u2208 C \u2200i.\nThen, operating on a given point with, say, g1 gives\ng1 (c0 |m0 i + c1 |m1 i + c2 |m2 i) = (c0 |g1 m0 i + c1 |g1 m1 i + c2 |g1 m2 i)\nand from the multiplication table on page 19, we know\ng1 m0 = m1 ,\n\ng1 m1 = m0 ,\n\ng1 m2 = m2\n\nSo,\n(c0 |g1 m0 i + c1 |g1 m1 i + c2 |g1 m2 i) = (c0 |m1 i + c1 |m0 i + c2 |m2 i)\n= c1 |m0 i + c0 |m1 i + c2 |m2 i\nSo, the effect of g1 was to swap c1 and c0 . This can be visualized geometrically\nas a reflection in the c0 = c1 plane in the 3-dimensional module space. We can\nvisualize every element of G in this way. They each move points around the\nmodule space in a well-defined way.\nThis allows us to give the following definition. If CV is a module, and CW is\na subspace of CV that is closed under the action of G, then CW is an Invariant\nSubspace of CV.\nExample 18\nWorking with S3 , we know that S3 acts on a 3-dimensional space spanned by\n|m0 i = (1, 0, 0)T ,\n\n|m1 i = (0, 1, 0)T ,\n30\n\nand\n\n|m2 i = (0, 0, 1)T\n\n\fNow, consider the subspace spanned by\nc(|m0 i + |m1 i + |m2 i)\n\n(2.3)\n\nwhere c \u2208 C, and c ranges over all possible complex numbers. If we restrict\nc to R, we can visualize this more easily as the set of all points in the line\nthrough the origin defined by \u03bb(\u00ee + \u0135 + k\u0302) (where \u03bb \u2208 R). You can write out the\naction of any element of S3 on any point in this subspace, and you will see that\nthey are unaffected. This means that the space spanned by (2.3) is an invariant\nsubspace.\nAs a note, all modules CV have two trivial invariant subspaces.\n\u2022 CV is a trivial invariant subspace of CV\n\u2022 Ce is a trivial invariant subspace of CV\nFinally, we can give a more formal definition of reducibility. If a representation D of a group\nG acts on the space of a module CM, then the representation D is said to be Reducible if CM\ncontains a non-trivial invariant subspace. If a representation is not reducible, it is Irreducible.\nWe encouraged you to write out the entire regular representation of S3 above. If you have\ndone so, you may have noticed that every 6 \u00d7 6 matrix appeared with non-zero elements\nonly in the upper left 3 \u00d7 3 elements, and the lower right 3 \u00d7 3 elements. The upper\nright and lower left are all 0. This means that, for every element of S3 , there will never\nbe any mixing of the first 3 dimensions with the last 3. So, there are two 3-dimensional\ninvariant subspaces in the module for this particular representation of S3 (the regular\nrepresentation).\nWe can now begin to take advantage of the fact that representations live in linear spaces\nwith the following definition.\nIf V is any n-dimensional space spanned by n linearly independent basis vectors, and U and W\nare both subspaces of V , then we say that V is the Direct Sum of U and W if every vector v\u0304 \u2208 V\ncan be written as the sum v\u0304 = \u016b + w\u0304, where \u016b \u2208 U and w\u0304 \u2208 W , and every operator X acting on\nelements of V can be separated into parts acting individually on U and W . The notation for this\nis V = U \u2295 W .\nIn order to make this clearer, if Xn is an n \u00d7 n matrix, it is the direct sum of m \u00d7 m matrix Am\nand k \u00d7 k matrix Bk , denoted Xn = Am \u2295 Bk , iff X is in Block Diagonal form,\n\u0012\n\u0013\nAm 0\nXn =\n0 Bk\nwhere n = m + k, and Am , Bk , and the 0's are understood as matrices of appropriate dimension.\n31\n\n\fWe can generalize the previous definition as follows,\n\uf8eb\n\uf8f6\nAn1 0 * * * 0\n\uf8ec 0 Bn2 * * * 0 \uf8f7\n\uf8ec\n\uf8f7\n..\nXn = An1 \u2295 Bn2 \u2295 * * * \u2295 Cnk = \uf8ec ..\n..\n. ***\uf8f7\n.\n\uf8ed .\n\uf8f8\n..\n0\n0\n. Cnk\nwhere n = n1 + n2 + * * * + nk .\nExample 19\n\uf8eb\n\n\uf8f6\n\u0012\n\u0013\n1 1 \u22122\n1\n2\nLet A3 = \uf8ed \u22121 5 \u03c0 \uf8f8, and let B2 =\n.\n3 4\n\u221217 4 11\n\uf8eb\n1 2 0 0\n\uf8ec3 4 0 0\n\uf8ec\nB2 \u2295 A3 = \uf8ec\n\uf8ec0 0 1 1\n\uf8ed0 0 \u22121 5\n0 0 \u221217 4\n\nThen,\n\uf8f6\n0\n0\uf8f7\n\uf8f7\n\u22122\uf8f7\n\uf8f7\n\u03c0\uf8f8\n11\n\nTo take stock of what we have done so far, we have talked about algebras, which are the\nvector spaces spanned by the elements of a group, and about modules, which are the vector spaces that representations of groups act on. We have also defined invariant subspaces\nas follows: Given some space and some group that acts on that space, moving the points\naround in a well-defined way, an invariant subspace is a subspace which always contains\nthe same points. The group doesn't remove any points from that subspace, and it doesn't\nadd any points to it. It merely moves the points around inside that subspace. Then, we\ndefined a representation as reducible if there are any non-trivial invariant subspaces in\nthe space that the group acts on.\nAnd what this amounts to is the following: a representation of any group is reducible if it\ncan be written in block diagonal form.\nBut this leaves the question of what we mean when we say \"can be written\". How can\nyou \"rewrite\" a representation? This leads us to the following definition. Given a matrix\nD and a non-singular matrix S, the linear transformation\nD \u2192 D0 = S \u22121 DS\nis called a Similarity Transformation.\nThen, we can give the following definition. Two matrices related by a similarity transformation are said to be Equivalent.\nBecause similarity transformations are linear transformations, if D(G) is a representation\nof G, then so is S \u22121 DS for literally any non-singular matrix S. To see this, if gi ? gj = gk ,\n32\n\n\fthen D(gi )D(gj ) = D(gk ), and therefore\nS \u22121 D(gi )S * S \u22121 D(gj )S = S \u22121 D(gi )D(gj )S = S \u22121 D(gk )S\nSo, if we have a representation that isn't in block diagonal form, how can we figure out\nif it is reducible? We must look for a matrix S that will transform it into block diagonal\nform.\nYou likely realize immediately that this is not a particularly easy thing to do by inspection.\nIt turns out that there is a very straightforward and systematic way of taking a given representation and determining whether or not it is reducible, and if so, what the irreducible\nrepresentations are.\nHowever, the details of how this can be done, while very interesting, are not necessary\nfor the agenda of these notes. Therefore, for the sake of brevity, we will not pursue them.\nWhat is important is that you understand not only the details of general group theory and\nrepresentation theory (which we outlined above), but also the concept of what it means\nfor a group to be reducible or irreducible.\n2.2\n\nIntroduction to Lie Groups\n\nIn section 2.1, we considered groups which are of finite order and discrete, which allowed\nus to write out a multiplication table.\nHere, however, we examine a different type of group. Consider the unit circle, where\neach point on the circle is specified by an angle \u03b8, measured from the positive x-axis.\n\nWe will refer to the point at \u03b8 = 0 as the \"starting point\" (like ROY was for the Easter\neggs). Now, just as we considered all possible orientations of (ROY ) that left the eggs\nlined up, we consider all possible rotations the wheel can undergo. With the eggs there\n33\n\n\fwere only 6 possibilities. Now however, for the wheel there are an infinite number of\npossibilities for \u03b8 (any real number \u2208 [0, 2\u03c0)).\nAnd note that if we denote the set of all angles as G, then all the rotations obey closure\n(\u03b81 + \u03b82 = \u03b83 \u2208 G, \u2200\u03b81 , \u03b82 \u2208 G), associativity (as usual), identity (0 + \u03b8 = \u03b8 + 0 = \u03b8), and\ninverse (the inverse of \u03b8 is \u2212\u03b8).\nSo, we have a group that is parameterized by a continuous variable \u03b8. So, we are no longer\ntalking about gi 's, but about g(\u03b8).\nNotice that this particular group (the circle) is Abelian, which is why we can (temporarily)\nuse addition to represent it. Also, note that we obviously cannot make a multiplication\ntable because the order of this group is \u221e.\nOne simple representation is the one we used above: taking \u03b8 and\nA\n\u0012 using addition.\n\u0013\ncos \u03b8 sin \u03b8\nmore familiar (and useful) representation is the Euler matrix g(\u03b8) =\n \u0307\nwith\n\u2212 sin \u03b8 cos \u03b8\nthe usual matrix multiplication:\n\u0013\n\u0013\u0012\ncos \u03b82 sin \u03b82\ncos \u03b81 sin \u03b81\n\u2212 sin \u03b82 cos \u03b82\n\u2212 sin \u03b81 cos \u03b81\n\u0012\n\u0013\ncos \u03b81 cos \u03b82 \u2212 sin \u03b81 sin \u03b82\ncos \u03b81 sin \u03b82 + sin \u03b81 cos \u03b82\n=\n\u2212 sin \u03b81 cos \u03b82 \u2212 cos \u03b81 sin \u03b82 \u2212 sin \u03b81 sin \u03b82 + cos \u03b81 cos \u03b82\n\u0012\n\u0013\ncos(\u03b81 + \u03b82 ) sin(\u03b81 + \u03b82 )\n=\n\u2212 sin(\u03b81 + \u03b82 ) cos(\u03b81 + \u03b82 )\n\u0012\n\n(2.4)\n(2.5)\n(2.6)\n\nThis will prove to be a much more useful representation than \u03b8 with addition.\nGroups that are parameterized by one or more continuous variables like this are called\nLie Groups. Of course, the true definition of a Lie group is much more rigorous (and complicated), and that definition should eventually be understood. However, the definition\nwe have given will suffice for the purposes of these notes.\n\n2.2.1\n\nClassification of Lie Groups\n\nThe usefulness of group theory is that groups represent a mathematical way to make\nchanges to a system while leaving something about the system unchanged. For example,\nwe moved (ROY ) around, but the structure \"3 eggs with different colors lined up\" was\npreserved. With the circle, we rotated it, but it still maintained its basic structure as a\ncircle. It is in this sense that group theory is a study of Symmetry. No matter which of\n\"these\" transformations you do to the system, \"this\" stays the same-this is symmetry.\nTo see the usefulness of this in physics, recall Noether's Theorem (section 1.1.2). When\nyou do a symmetry transformation to a Lagrangian, you get a conserved quantity. Think\n34\n\n\fback to the Lagrangian for the projectile (1.2). The transformation x \u2192 x + \u000f was a symmetry because \u000f could take any value, and the Lagrangian was unchanged (note that \u000f\nforms the Abelian group (R, +)).\nSo, given a Lagrangian, which represents the structure of a physical system, a symmetry represents a way of changing the Lagrangian while preserving that structure. The\nparticular preserved part of the system is the conserved quantity j we discussed in sections 1.1.2 and 1.1.6. And as you have no doubt noticed, nearly all physical processes are\ngoverned by Conservation Laws: conservation of momentum, energy, charge, spin, etc.\nSo, group theory, and in particular Lie group theory, gives us an extremely powerful way\nof understanding and classifying symmetries, and therefore conserved charges. And because it allows us to understand conserved charges, group theory can be used to understand the entirety of the physics in our universe.\nWe now begin to classify the major types of Lie groups we will be working with in these\nnotes. To start, we consider the most general possible Lie group in an arbitrary number of\ndimensions, n. This will be the group that, for any point p in the n-dimensional space, can\ncontinuously take it anywhere else in the space. All that is preserved is that the points in\nthe space stay in the space. This means that we can have literally any n\u00d7n matrix, or linear\ntransformation, so long as the matrix is invertible (non-singular). Thus, in n dimensions\nthe largest and most general Lie group is the group of all n \u00d7 n non-singular matrices. We\ncall this group GL(n), or the General Linear group. The most general field of numbers\nto take the elements of GL(n) from is C, so we begin with GL(n, C). This is the group of\nall n \u00d7 n non-singular matrices with complex elements. The preserved quantity is that all\npoints in Cn stay in Cn .\nThe most obvious subgroup of GL(n, C) is GL(n, R), or the set of all n \u00d7 n invertible\nmatrices with real elements. This leaves all points in Rn in Rn .\nTo find a further subgroup, recall from linear algebra and vector calculus that in n dimensions, you can take n vectors at the origin such that for a parallelepiped, we could\nobtain\n\n35\n\n\fThen, if you arrange the components of the n vectors into the rows (or columns) of a\nmatrix, the determinant of that matrix will be the volume of the parallelepiped.\nSo, consider now the set of all General Linear transformations that transform all vectors\nfrom the origin (or in other words, points in the space) in such a way that the volume of\nthe corresponding parallelepiped is preserved. This will demand that we only consider\nGeneral Linear matrices with determinant 1. Also, the set of all General Linear matrices\nwith unit determinant will form a group because of the general rule det |A * B| = det |A| *\ndet |B|. So, if det |A| = 1 and det |B| = 1, then det |A * B| = 1. We call this subgroup of\nGL(n, C) the Special Linear group, or SL(n, C). The natural subgroup of this is SL(n, R).\nThis group preserves not only the points in the space (as GL did), but also the volume, as\ndescribed above.\nNow, consider the familiar transformations on vectors in n-dimensional space of generalized Euler angles. These are transformations that rotate all points around the origin. These rotation transformations leave the radius squared (r2 ) invariant. And, because r\u03042 = r\u0304T * r\u0304, if we transform with a rotation matrix R, then r\u0304 \u2192 r\u03040 = Rr\u0304, and\nr\u0304T \u2192 r\u03040T = r\u0304T RT , so r\u03040T * r\u03040 = r\u0304T RT * Rr\u0304. But, as we said, we are demanding that the\nradius squared be invariant under the action of R, and so we demand r\u0304T RT * Rr\u0304 = r\u0304T * r\u0304.\nSo, the constraint we are imposing is RT *R = I, which implies RT = R\u22121 . This tells us that\nthe rows and columns of R are orthogonal. Therefore, we call the group of generalized\nrotations, or generalized Euler angles in n dimensions, O(n), or the Orthogonal group.\nWe don't specify C or R here because it will be understood that we are always talking\nabout R.\nAlso, note that because det |RT * R| = det |I| \u21d2 (det |R|)2 = 1 \u21d2 det |R| = \u00b11. We again\ndenote the subgroup with det |R| = +1 the Special Orthogonal group, or SO(n). To\nunderstand what this means, consider an orthogonal matrix with determinant \u22121, such\nas\n\uf8eb\n\uf8f6\n1 0 0\nM = \uf8ed0 1 0 \uf8f8\n0 0 \u22121\nThis matrix is orthogonal, and therefore is an element of the group O(3), but the determinant is \u22121. This matrix will take the point (x, y, z)T to the point (x, y, \u2212z)T . This changes\nthe handedness of the system (the right hand rule will no longer work). So, if we limit\nourselves to SO(n), we are preserving the space, the radius, the volume, and the handedness of the space.\nFor vectors in C space, we do not define orthogonal matrices (although we could). Instead, we discuss the complex version of the radius, where instead of r\u03042 = r\u0304T * r\u0304, we have\nr\u03042 = r\u0304\u2020 * r\u0304, where the dagger denotes the Hermitian conjugate, r\u0304\u2020 = (r\u0304? )T , where ? denotes\ncomplex conjugate.\nSo, with the elements in R being in C, we have r\u0304 \u2192 Rr\u0304, and r\u0304\u2020 \u2192 r\u0304\u2020 R\u2020 . So, r\u0304\u2020 *r\u0304 \u2192 r\u0304\u2020 R\u2020 *Rr\u0304,\nand by the same argument as above with the orthogonal matrices, this demands that\n36\n\n\fR\u2020 * R = I, or R\u2020 = R\u22121 . We denote such matrices Unitary, and the set of all such n \u00d7 n\ninvertible matrices form the group U (n). Again, we understand the unitary groups to\nhave elements in C, so we don't specify that. And, we will still have a subset of unitary\nmatrices R with det |R| = 1 called SU (n), the Special Unitary groups.\nWe can summarize the hierarchy we have just described in the following diagram:\n\nWe will now describe one more category of Lie groups before moving on. We saw above\nthat the group SO(n) preserves the radius squared in real space. In coordinates, this\nmeans that r\u03042 = x21 + x22 + * * * + x2n , or more generally the dot product x\u0304 * \u0233 = x1 y1 + x2 y2 +\n* * * + xn yn is preserved.\nHowever, we can generalize this to form a group action that preserves not the radius\nsquared, but the value (switching to indicial notation for the dot product) xa ya = \u2212x1 y1 \u2212\nx2 y2 \u2212* * *\u2212xm ym +xm+1 ym+1 +* * *+xm+n ym+n . We call the group that preserves this quantity\n37\n\n\fSO(m, n). The space we are working in is still Rm+n , but we are making transformations\nthat preserve something different than the radius.\nNote that SO(m, n) will have an SO(m) subgroup and an SO(n) subgroup, consisting of\nrotations in the first m and last n components separately.\nFinally, notice that the specific group of this type, SO(1, 3), is the group that preserves the\nvalue s2 = \u2212x1 y1 +x2 y2 +x3 y3 +x4 y4 , or written more suggestively, s2 = \u2212c2 t2 +x2 +y 2 +z 2 .\nTherefore, the group SO(1, 3) is the Lorentz Group. Any action that is invariant under\nSO(1, 3) is said to be a Lorentz Invariant theory (as all theories should be). We will find\nthat thinking of Special Relativity in these terms, rather than in the terms of Part I, will be\nmuch more useful.\nIt should be noted that there are many other types of Lie groups. We have limited ourselves to the ones we will be working with in these notes.\n\n2.2.2\n\nGenerators\n\nNow that we have a good \"birds eye view\" of Lie groups, we can begin to pick apart the\ndetails of how they work.\nAs we said before, a Lie group is a group that is parameterized by a set of continuous\nparameters, which we call \u03b1i for i = 1, . . . , n, where n is the number of parameters the\ngroup depends on. The elements of the group will then be denoted g(\u03b1i ).\nBecause all groups include an identity element, we will choose to parameterize them in\nsuch a way that g(\u03b1i ) \u03b1i =0 = e, the identity element. So, if we are going to talk about\nrepresentations, Dn (g(\u03b1i )) \u03b1i =0 = I, where I is the n \u00d7 n identity matrix for whatever\ndimension (n) representation we want.\nNow, take \u03b1i to be very small with \u03b4\u03b1i << 1. So, Dn (g(0 + \u03b4\u03b1i )) can be Taylor expanded:\nDn (g(\u03b4\u03b1i )) = I + \u03b4\u03b1i\nThe terms\n\n\u2202Dn\n\u2202\u03b1i \u03b1i =0\n\n\u2202Dn (g(\u03b1i ))\n\u2202\u03b1i\n\n\u03b1i =0\n\n+ ***\n\nare extremely important, and we give them their own expression:\nXi \u2261 \u2212i\n\n\u2202Dn\n\u2202\u03b1i\n\n(2.7)\n\u03b1i =0\n\n(we have included the \u2212i in order to make Xi Hermitian, which will be necessary later).\nSo, the representation for infinitesimal \u03b4\u03b1i is then\nDn (\u03b4\u03b1i ) = I + i\u03b4\u03b1i Xi + * * *\n38\n\n\f(where we have switched our notation from Dn (g(\u03b1)) to Dn (\u03b1) for brevity).\nThe Xi 's are constant matrices which we will determine later.\nNow, let's say that we want to see what the representation will look like for a finite value\nof \u03b1i rather than an infinitesimal value. A finite transformation will be the result of an\ninfinite number of infinitesimal transformations. Or in other words, \u03b1i = N \u03b4\u03b1i as N \u2192 \u221e.\nSo, \u03b4\u03b1i = \u03b1Ni , and an infinite number of infinitesimal transformations is\nlim (1 + i\u03b4\u03b1i Xi )N = lim 1 + i\n\nN \u2192\u221e\n\nN \u2192\u221e\n\n\u03b1i \u0001 N\nXi\nN\n\nIf you expand this out for several values of N , you will see that it is exactly\nlim 1 + i\n\nN \u2192\u221e\n\n\u03b1i \u0001 N\nXi = ei\u03b1i Xi\nN\n\nWe call the Xi 's the Generators of the group, and there is one for each parameter required\nto specify a particular element of the group. For example, consider SO(3), the group\nof rotations in 3 dimensions. We know from vector calculus that an element of SO(3)\nrequires 3 angles, usually denoted \u03b8, \u03c6, and \u03c8. Therefore, SO(3) will require 3 generators,\nwhich will be denoted X\u03b8 , X\u03c6 , and X\u03c8 . We will discuss how the generators can be found\nsoon.\nIn general, there will be several (in fact, infinite) different sets of Xi 's that define a given\ngroup (just as there are an infinite number of representations of any finite group). What\nwe will find is that up to a similarity transformation, a particular set of generators defines\na particular representation of a group.\nSo, Dn (\u03b1i ) = ei\u03b1i Xi for any group (the i index in the exponent is understood to be summed\nover all parameters and generators). The best way to think of the parameter space for the\ngroup is as a vector space, where the generators describe the behavior near the identity,\nbut form a basis for the entire vector space. By analogy, think of the unit vectors \u00ee, \u0135,\nand k\u0302 in R3 . They are defined at the origin, but they can be combined with real numbers/parameters to specify any arbitrary point in R3 . In the same way, the generators are\nthe \"unit vectors\" of the parameter space (which in general is a much more complicated\nspace than Euclidian space), and the parameters (like \u03b8, \u03c6, and \u03c8) specify where in the\nparameter space you are in terms of the generators. That point in the parameter space\nwill then correspond to a particular element of the group.\nWe call the number of generators of a group (or equivalently the number of parameters\nnecessary to specify an element), the Dimension of the group. For example, the dimension of SO(3) is 3. The dimension of SO(2) (rotations in the plane) however is only 1 (only\n\u03b8 is needed), so there will be only one generator.\n\n39\n\n\f2.2.3\n\nLie Algebras\n\nIn section 2.1 we discussed algebras. An algebra is a space spanned by elements of the\ngroup with C coefficients parameterizing the Euclidian space we defined. Obviously we\ncan't define an algebra in the same way for Lie groups, because the elements are continuous. But, as discussed in the last section, a particular element of a Lie group is defined by\nthe values of the parameters in the parameter space spanned by the generators. We will\nsee that the generators will form the algebras for Lie groups.\nConsider two elements of the same group with generators Xi , one with parameter values\n\u03b1i and the other with parameter values \u03b2i . The product of the 2 elements will then be\nei\u03b1i Xi ei\u03b2j Xj . Because we are assuming this is a group, we know that the product must be\nan element of the group (due to closure), and therefore the product must be specified by\nsome set of parameters \u03b4k , so ei\u03b1i Xi ei\u03b2j Xj = ei\u03b4k Xk . Note that the product won't necessarily\nsimply be ei\u03b1i Xi ei\u03b2j Xj = ei(\u03b1i Xi +\u03b2j Xj ) because the generators are matrices and therefore\ndon't in general commute.\nSo, we want to figure out what \u03b4i will be in terms of \u03b1i and \u03b2i . We do this as follows.\ni\u03b4i Xk = ln(ei\u03b4k Xk ) = ln(ei\u03b1i Xi e\u03b2j Xj ) = ln(1 + ei\u03b1i Xi e\u03b2j Xj \u2212 1) \u2261 ln(1 + x)\nwhere we have defined x \u2261 ei\u03b1i Xi e\u03b2j Xj \u2212 1. We will proceed by expanding only to second\norder in \u03b1i and \u03b2j , though the result we will obtain will hold at arbitrary order. By Taylor\nexpanding the exponential terms,\n1\n1\nei\u03b1i Xi e\u03b2j Xj \u2212 1 = (1 + i\u03b1i Xi + (i\u03b1i Xi )2 + * * * )(1 + i\u03b2j Xj + (i\u03b2j Xj )2 + * * * ) \u2212 1\n2\n2\n1\n1\n= 1 + i\u03b2j Xj \u2212 (\u03b2j Xj )2 + i\u03b1i Xi \u2212 \u03b1i Xi \u03b2j Xj \u2212 (\u03b1i Xi )2 \u2212 1\n2\n2\n\u0001\n1\n= i(\u03b1i Xi + \u03b2j Xj ) \u2212 \u03b1i Xi \u03b2j Xj \u2212 (\u03b1i Xi )2 + (\u03b2j Xj )2\n2\nThen, using the general Taylor expansion ln(1 + x) = x \u2212\n\n40\n\nx2\n2\n\n+\n\nx3\n3\n\n\u2212\n\nx4\n4\n\n+ * * * , and again\n\n\fkeeping terms only to second order in \u03b1 and \u03b2, we have\n\u0014\n\u0015\nx2\n1\n2\n2\nx\u2212\n= i(\u03b1i Xi + \u03b2j Xj ) \u2212 \u03b1i Xi \u03b2j Xj \u2212 [(\u03b1i Xi ) + (\u03b2j Xj ) ]\n2\n2\n\u0014\n\u00152\n1\n1\n2\n2\n\u2212 i(\u03b1i Xi + \u03b2j Xj ) \u2212 \u03b1i Xi \u03b2j Xj \u2212 [(\u03b1i Xi ) + (\u03b2j Xj ) ]\n2\n2\n\u0015\n\u0014\n1\n2\n2\n= i(\u03b1i Xi + \u03b2j Xj ) \u2212 \u03b1i Xi \u03b2j Xj \u2212 (\u03b1i Xi ) + (\u03b2j Xj )\n2\n\u0014\n\u0015\n1\n\u2212 \u2212 (\u03b1i Xi + \u03b2j Xj )(\u03b1i Xi + \u03b2j Xj )\n2\n\u0015\n\u0014\n1\n2\n2\n= i(\u03b1i Xi + \u03b2j Xj ) \u2212 \u03b1i Xi \u03b2j Xj \u2212 (\u03b1i Xi ) + (\u03b2j Xj )\n2\n\u0014\n\u0015\n1\n2\n2\n+ (\u03b1i Xi ) + (\u03b2j Xj ) + \u03b1i \u03b2j (Xi Xj + Xj Xi )\n2\n1\n= i(\u03b1i Xi + \u03b2j Xj ) + \u03b1i \u03b2j (Xj Xi \u2212 Xi Xj )\n2\n1\n= i(\u03b1i Xi + \u03b2j Xj ) \u2212 \u03b1i \u03b2j [Xi , Xj ]\n2\n1\n= i(\u03b1i Xi + \u03b2j Xj ) \u2212 [\u03b1i Xi , \u03b2j Xj ]\n2\nSo finally we can see\n1\ni\u03b4k Xk = i(\u03b1i Xi + \u03b2j Xj ) \u2212 [\u03b1i Xi , \u03b2j , Xj ]\n2\nor\n1\n\nei\u03b1i Xi ei\u03b2j Xj = ei(\u03b1i Xi +\u03b2j Xj )\u2212 2 [\u03b1i Xi , \u03b2j Xj ]\n\n(2.8)\n\nEquation (2.8) is called the Baker-Campbell-Hausdorff formula, and it is one of the most\nimportant relations in group theory and in physics. Notice that, if the generators commute, this reduces to the normal equation for multiplying exponentials. You can think of\nequation (2.8) as the generalization of the normal exponential multiplication rule.\nNow, it is clear that the commutator [Xi , Xj ] must be proportional to some linear combination of the generators of the group (because of closure). So, it must be the case that\n[Xi , Xj ] = ifijk Xk\n\n(2.9)\n\nfor some set of constants fijk . These constants are called the Structure Constants of the\ngroup, and if they are completely known, the commutation relations between all the generators are known, and so the entire group can be determined in any representation you\nwant.\nThe generators, under the specific commutation relations defined by the structure constants, form the Lie Algebra of the group, and it is this commutation structure which\nforms the structure of the Lie group.\n41\n\n\f2.2.4\n\nThe Adjoint Representation\n\nWe will talk about several representations for each group we discuss, but we will mention a very important one now. We mentioned before that the structure constants fijk\ncompletely determine the entire structure of the group.\nWe begin by using the Jacobi identity,\n\u0002\n\u0003 \u0002\n\u0003 \u0002\n\u0003\nXi , [Xj , Xk ] + Xj , [Xk , Xi ] + Xk , [Xi , Xj ] = 0\n\n(2.10)\n\n(if you aren't familiar with this identity, try multiplying it out. You will find that it is\nidentically true - all the terms cancel exactly). But, from equation (2.9), we can write\n\u0002\n\u0003\nXi , [Xj , Xk ] = ifjka [Xi , Xa ] = ifjka fiab Xb\nPlugging this into (2.10) we get\nifjka fiab Xb + ifkia fjab Xb + ifija fkab Xb = 0\n\u21d2 (fjka fiab + fkia fjab + fija fkab )iXb = 0\n\u21d2 fjka fiab + fkia fjab + fija fkab = 0\n\n(2.11)\n\nSo, if we define the matrices\n[T a ]bc \u2261 \u2212ifabc\n\n(2.12)\n\nthen it is easy to show that (2.11) leads to\n[T a , T b ] = ifabc T c\nSo, the structure constants themselves form a representation of the group (as defined by\n(2.12). We call this representation the Adjoint Representation, and it will prove to be\nextremely important.\nNotice that the indices labeling the rows and columns in (2.12) each run over the same\nvalues as the indices labeling the T matrices. This tells us that the adjoint representation\nis made of n \u00d7 n matrices, where n is the dimension of the group, or the number of\nparameters in the group. For example, SO(3) requires 3 parameters to specify an element\n(\u03b8, \u03c6, \u03c8), so the adjoint representation of SO(3) will consist of 3 \u00d7 3 matrices. SO(2) on the\nother hand is Abelian, and therefore all of the structure constants vanish. Therefore there\nis no adjoint representation of SO(2).\nWe now go on to consider several specific groups in detail.\n\n42\n\n\f2.2.5\n\nSO(2)\n\nWe start by looking at an extremely simple\u0012group,\nSO(2). This is the group of rotations in\n\u0013\n\u0001\nx\nthe plane that leaves r\u03042 = x2 +y 2 = x y *\n= v\u0304 T *v\u0304 invariant. So for some generator X\ny\nT\n(which we will now find) of SO(2), v\u0304 \u2192 R(\u03b8)v\u0304 = ei\u03b8X v\u0304, and v\u0304 T \u2192 v\u0304 T ei\u03b8X . So, expanding\nT\nto first order only, v\u0304 T ei\u03b8X ei\u03b8X v\u0304 = v\u0304 T (1 + i\u03b8X T + i\u03b8X)v\u0304 = v\u0304 T * v\u0304 + v\u0304 T i\u03b8(X + X T )v\u0304. And\nbecause we demand that r2 be invariant, we demand that X + X T = 0 \u21d2 X = \u2212X T . So,\nX must be antisymmetric. Therefore we take\n\u0012\n\u0013\n1 0 1\nX\u2261\ni \u22121 0\n(the 1i is included to balance the i we inserted in equation (2.7) to ensure that X is Hermitian).\nSo, an arbitrary element of SO(2) will be\n0\n\nei\u03b8X =\n=\n=\n=\n=\n\n1\n\n0\n\n1\n\n0 1A\n0 1A\n\u03b8@\n\u22121 0 = e \u22121 0\ne\n\u0012\n\u00131\n\u0012\n\u00130\n\u0012\n\u00132\n1 2 0 1\n0 1\n0 1\n+ \u03b8\n+\u03b8\n+ ***\n\u22121 0\n\u22121 0\n\u22121 0\n2\n\u0012\n\u0013\n\u0012\n\u0013\n\u0012\n\u0013\n\u0012\n\u0013\n1 2 1 0\n1 3 0 1\n1 0\n0 1\n+\u03b8\n\u2212 \u03b8\n\u2212 \u03b8\n+ ***\n0 1\n\u22121 0\n0 1\n\u22121 0\n2\n3!\n\u0012\n\u0013\n\u03b8 \u2212 3!1 \u03b83 + * * *\n1 \u2212 21 \u03b82 + * * *\n\u2212(\u03b8 \u2212 3!1 \u03b83 + * * * ) 1 \u2212 21 \u03b82 + * * *\n\u0012\n\u0013\ncos \u03b8 sin \u03b8\n\u2212 sin \u03b8 cos \u03b8\ni\u03b8 1i @\n\nwhich is exactly what we would expect for a matrix describing rotations in the plane.\nAlso, notice that because SO(2) is Abelian, the commutation relations trivially vanish\n([X, X] \u2261 0), and so all of the structure constants are zero.\nNow that we have found an explicit example of a generator, and seen an example of how\ngenerators relate to group elements, we move on to slightly more complicated examples.\n\n2.2.6\n\nSO(3)\n\nWe could easily generalize the argument from the proceeding section and find the generators of SO(3) in the same way, but in order to illustrate more clearly how generators work,\nwe will approach SO(3) differently by working backwards. Above, we found the generators and used them to calculate the group elements. Here, we begin with the known\n43\n\n\fgroup elements of SO(3), which are just the standard Euler matrices for rotations in 3dimensional space:\n\uf8eb\n\uf8f6\n1\n0\n0\nRx (\u03c6) = \uf8ed0 cos \u03c6 sin \u03c6 \uf8f8\n(2.13)\n0 \u2212 sin \u03c6 cos \u03c6\n\uf8eb\n\uf8f6\ncos \u03c8 0 \u2212 sin \u03c8\n1\n0 \uf8f8\nRy (\u03c8) = \uf8ed 0\n(2.14)\nsin \u03c8 0 cos \u03c8\n\uf8eb\n\uf8f6\ncos \u03b8 sin \u03b8 0\nRz (\u03b8) = \uf8ed\u2212 sin \u03b8 cos \u03b8 0\uf8f8\n(2.15)\n0\n0\n1\nNow, recall the definition of the generators, equation (2.7). We\ngenerators of SO(3), which we will denote Jx , Jy , and Jz .\n\uf8eb\n\uf8eb\n\uf8f6\n0\n0\n0\n0\n1\uf8ed\n1\uf8ed\n1 dRx (\u03c6)\n\uf8f8\n0 \u2212 sin \u03c6 cos \u03c6\n0\n=\n=\nJx =\ni d\u03c6 \u03c6=0\ni\ni\n0 \u2212 cos \u03c6 sin \u03c6 \u03c6=0\n0\n\ncan use it to find the\n\uf8f6\n0 0\n0 1\uf8f8\n\u22121 0\n\nAnd similarly\n\uf8eb\n\uf8f6\n0 0 \u22121\n1\nJy = \uf8ed0 0 0 \uf8f8 ,\ni\n1 0 0\n\n\uf8eb\n\n\uf8f6\n0 1 0\n1\nJz = \uf8ed\u22121 0 0\uf8f8\ni\n0 0 0\n\nYou can plug these into the exponentials with the appropriate parameters (\u03c6, \u03c8, or \u03b8) and\nfind that ei\u03c6Jx , ei\u03c8Jy , and ei\u03b8Jz reproduce (2.13), (2.14), and (2.15), respectively.\nFurthermore, you can multiply out the commutators to find\n[Jx , Jy ] = iJz ,\n\n[Jy , Jz ] = iJx ,\n\n[Jz , Jx ] = iJy\n\nor\n[Ji , Jj ] = i\u000fijk Jk\nwhich tells us that the structure constants for SO(3) are\nfijk = \u000fijk\n\n(2.16)\n\nwhere \u000fijk is the totally antisymmetric tensor. The structure constants being non-zero is\nconsistent with SO(3) being a non-Abelian group.\n\n44\n\n\f2.2.7\n\nSU (2)\n\nWe will approach SU (2) yet another way: by starting with the structure constants. It turns\nout they are the same as the structure constants for SO(3):\n(2.17)\n\nfijk = \u000fijk\n\nTo see why, recall that SU (2) are rotations\u0012in two\n\u0013 complex dimensions. The most general\na b\nform of such a matrix U \u2208 SU (2) is U =\n. The \"Special\" part of SU (2) demands\nc d\nthat the determinant be equal to 1, or\nad \u2212 bc = 1\nand the \"Unitary\" part demands that U \u22121 = U \u2020 . So,\n\u0012\n\u0013\n\u0012 ? ?\u0013\nd \u2212b\na c\n\u22121\n\u2020\nU =\n=U = ? ?\n\u2212c a\nb d\nor in other words,\n\u0012\nU=\n\na\nb\n\u2212b? a?\n\n\u0013\n\nwhere we demand |a|2 + |b|2 = 1.\nBoth a and b are in C, and therefore have 2 real components each, so U has 4 real parameters. The constraint |a|2 + |b|2 = 1 fixes one of them, leaving 3 real parameters, just like\nin SO(3). This is a loose explanation of why SU (2) and SO(3) have the same structure\nconstants. They are both rotational groups with 3 real parameters.\nThis also tells us that SU (2) will have 3 generators.\n\n2.2.8\n\nSU (2) and Physical States\n\nThe elements of any Lie group (in a d-dimensional representation consisting of d \u00d7 d ma\u0001T\ntrices) will act on vectors, just like the 3 \u00d7 3 matrices representing S3 acted on R O Y\nin section 2.1.5. The most natural way to understand the space a Lie group acts on is to\nstudy the eigenvectors and eigenvalues of the generators of the representation you are\nusing (the reason for this is beyond the scope of these notes at this point, but will become more clear as we proceed). These eigenvectors will obviously form a basis of the\neigenspace of the physical space the group is acting on.\nUsing similarity transformations, one or more of the generators of a Lie group can be diagonalized. For now, trust us that with SU (2), it is only possible to diagonalize one of the\n45\n\n\fthree generators at a time (you may convince yourself of this by studying the commutation relations). We will call the generators of SU (2) J 1 , J 2 , and J 3 , and by convention we\ntake J 3 to be the diagonal one. So, consequently, the eigenvectors of J 3 will be the basis\nvectors of the physical vector space upon which SU (2) acts.\nNow, we know that J 3 (whatever it is ... we don't know at this point) will in general\nhave more than one eigenvalue. Let's call the greatest eigenvalue of J 3 (whatever it is)\nj, and the eigenvectors of J 3 will be denoted |j; mi (the first j is merely a label - the\nsecond value describes the vector), where m is the eigenvalue of the eigenvector. The\neigenvector corresponding to the greatest eigenvalue j will obviously then be |j; ji. So,\nJ 3 |j; ji = j|j; ji, or more generally J 3 |j; mi = m|j; mi.\nNow let's assume that we know |j; ji. There is a trick we can employ to find the rest of\nthe states. Define the following linear combinations of the generators:\n1\nJ \u00b1 \u2261 \u221a (J 1 \u00b1 iJ 2 )\n2\n\n(2.18)\n\nNow, using the fact that the SU (2) generators obey the commutation relations in equation\n(2.16), it is easy to show the following relations,\n[J 2 , J \u00b1 ] = \u00b1J \u00b1\n\nand\n\n[J + , J \u2212 ] = J 3\n\n(2.19)\n\nNotice that, because by definition J i are all Hermitian, we have\n(J \u2212 )\u2020 = J +\n\n(2.20)\n\nConsider some arbitrary eigenvector |j; mi. We know the eigenvalue of this will be m, so\nJ 3 |j; mi = m|j; mi. But now let's create some new state by acting on |j; mi with either of\nthe operators (2.18). The new state will be J \u00b1 |j; mi, but what will the J 3 eigenvalue be?\nUsing the commutation relations in (2.19),\nJ 3 J \u00b1 |j; mi = (\u00b1J \u00b1 + J \u00b1 J 3 )|j; mi = (m \u00b1 1)J \u00b1 |j; mi\nSo, the vector J + |j; mi is the eigenvector with eigenvalue m + 1, and the vector J \u2212 |j; mi\nis the eigenvector with eigenvalue m \u2212 1.\nIf we have some arbitrary eigenvector |j; mi, we can use J \u00b1 to move up or down to the\neigenvector with the next highest or lowest eigenvalue. For this reason, J \u00b1 are called the\nRaising and Lowering operators. They raise and lower the eigenvalue of the state by one.\nClearly, the eigenvector with the greatest eigenvalue j, with eigenvector |j; ji, cannot\nbe raised any higher, so we define J + |j; ji \u2261 0. We will see that there is also a lowest\neigenvalue j 0 , so we similarly define J \u2212 |j; j 0 i \u2261 0.\nNow, considering once again |j; ji. We know that if we operate on this state with J \u2212 , we\nwill get the eigenvector with the eigenvalue j \u2212 1. But, we don't know exactly what this\n46\n\n\fstate will be (knowing the eigenvalue doesn't mean we know the actual state). But, we\nknow it will be proportional to |j; j \u2212 1i. So, we set J \u2212 |j; ji = Nj |j; j \u2212 1i, where Nj is the\nproportionality constant. To find Nj , we take the inner product (and using (2.20)):\nhj; j|J + J \u2212 |j; ji = |Nj |2 hj; j \u2212 1|j; j \u2212 1i\nBut we can also write\n\u0003\n\u0002\nhj; j|J + J \u2212 |j; ji = hj; j|(J + J \u2212 \u2212 J \u2212 J + )|j; ji = hj; j| J + , J \u2212 |j; ji\n= hj; j|J 3 |j; ji = jhj; j|j; ji = j\n\n(2.21)\n\nwhere we used the fact that J + |j; ji = 0 to get the first equality, and (2.19) to get the third\nequality. We also assumed that |j; ji is normalized.\nSo, (2.21) tells us\nhj; j \u2212 1|j; j \u2212 1i = 1 \u21d0\u21d2 Nj \u2261\n\np\nj\n\n(2.22)\n\nAnd our normalized state is therefore\nJ\u2212\nJ\u2212\n|j; ji = \u221a |j; ji = |j; j \u2212 1i\nNj\nj\nRepeating this to find Nj\u22121 , we have\n|Nj\u22121 |2 hj; j \u2212 2|j; j \u2212 2i = hj; j \u2212 1|J + J \u2212 |j; j \u2212 1i\nJ+\nJ\u2212\n= hj; j| \u221a J + J \u2212 \u221a |j; ji\nj\nj\n1\nhj; j|J + J + J \u2212 J \u2212 |j; ji\n=\nj\n1\n=\nhj; j|J + (J 3 + J \u2212 J + )J \u2212 |j; ji\nj\n1\n=\nhj; j|(J + J 3 J \u2212 + J + J \u2212 J + J \u2212 )|j; ji\nj\n1\n=\nhj; j|(J + (\u2212J \u2212 + J \u2212 J 3 ) + J + J \u2212 (J 3 + J \u2212 J + ))|j; ji\nj\n1\n=\n[hj; j|(\u2212J + J \u2212 + jJ + J \u2212 + jJ + J \u2212 )|j; ji]\nj\n1\n=\nhj; j|(\u2212[J + , J \u2212 ] + 2j[J + , J \u2212 ])|j; ji\nj\n1\n=\nhj; j|(\u2212J 3 + 2jJ 3 )|j; ji\nj\n1 2\n=\n(2j \u2212 j) = 2j \u2212 1\n(2.23)\nj\n\u221a\nSo, |Nj\u22121 |2 = 2j \u2212 1, or Nj\u22121 = 2j \u2212 1.\n47\n\n\fWe can continue this process, and we will find that the general result is\n1 p\nNj\u2212k = \u221a\n(2j \u2212 k)(k + 1)\n2\n\n(2.24)\n\nand the general states are defined by\n|j; j \u2212 ki =\n\n1\nNj\u2212k\n\n(J \u2212 )k |j; ji\n\nNotice that these expressions recover (2.22) and (2.23) for k = 0 and k = 1, respectively.\nFurthermore, notice that when k = 2j,\n1 p\nNj\u22122j = \u221a\n(2j \u2212 2j)(2j + 1) \u2261 0\n2\nSo, the state |j; j \u2212 ki\ntion J \u2212 |j; \u2212ji \u2261 0.\n\nk=2j\n\n= |j; \u2212ji is the state with the lowest eigenvalue, and by defini-\n\nSo, in a general representation of SU (2), we have 2j + 1 states:\n{j, j \u2212 1, j \u2212 2, . . . , \u2212j + 2, \u2212j + 1, \u2212j}\nThis therefore demands that j = n2 for some integer n. In other words, the highest eigenvalue of an SU (2) eigenvector can be 0, 12 , 1, 32 , 2, etc.\nFurthermore, using these states, it is easy to show\nhj; m0 |J 3 |j; mi = m\u03b4m0 ,m\n1 p\nhj; m0 |J + |j; mi = \u221a\n(j + m + 1)(j \u2212 m)\u03b4m0 ,m+1\n2\n1 p\nhj; m0 |J \u2212 |j; mi = \u221a\n(j + m)(j \u2212 m + 1)\u03b4m0 ,m\u22121\n2\n\n2.2.9\n\nSU (2) for j =\n\n(2.25)\n\n1\n2\n\nWe will skip the j = 0 case because it is trivial (though we will discuss it later when we\nreturn to physics).\nFor j = 21 , the two eigenvalues of J 3 will be 12 and 21 \u22121 = \u2212 12 . So, denoting the J 3 generator\n3\nof SU (2) when j = 21 as J1/2\n, we have\n3\nJ1/2\n\n\u0012\n=\n\n\u0013\n1/2 0\n0 1/2\n48\n\n\fNow, inverting (2.18) to get\n1\nJ 1 = \u221a (J \u2212 + J + )\n2\n\nand\n\ni\nJ 2 = \u221a (J \u2212 \u2212 J + )\n2\n\nand using the standard matrix equation [Jja ]m0 ,m = hj, m0 |J a |j, mi, and the explicit products in (2.25), we can find (for example)\n\u001d \u001c\n\u001d\n\u001c\n1 1 1\n1\n1 1 1 1 1\n\u2212\n+ 1\n;\u2212 J\n;\u2212\n=\n; \u2212 \u221a (J + J ) ; \u2212\n= *** = 0\n2 2\n2 2\n2 2 2\n2 2\nSo [J 1 ]11 = 0. Then,\n\u001c\n\u001d \u001c\n\u001d\n1 1 1 1 1\n1 1 1\n1\n\u2212\n+ 1 1\n;\u2212 J\n;\n=\n; \u2212 \u221a (J + J ) ;\n= *** =\n2 2\n2 2\n2 2 2\n2 2\n2\nSo [J 1 ]12 = 21 .\nWe can continue this to find all the elements for each generator for j = 1/2. The final\nresult will be\n\u0012\n\u0013\n\u0012\n\u0013\n\u0012\n\u0013\n1 0 1\n\u03c31\n1 0 \u2212i\n\u03c32\n1 1 0\n\u03c33\n1\n2\n3\nJ1/2 =\n= , J1/2 =\n= , J1/2 =\n=\n(2.26)\n2 1 0\n2\n2 i 0\n2\n2 0 \u22121\n2\nwhere the \u03c3 i matrices are the Pauli Spin Matrices. This is no accident! We will discuss this\nin much, much more detail later, but for now recall that we said that SU (2) is the group of\ntransformations in 2-dimensional complex space (with one of the real parameters fixed,\nleaving 3 real parameters). We are going to see that SU (2) is the group which represents\nquantum mechanical spin, where j is the value of the spin of the particle. In other words,\nparticles with spin 1/2 are described by the j = 1/2 representation (the 2\u00d72 representation\nin (2.26)), and particles with spin 1 are described by the j = 1 representation, and so on.\nIn other words, SU (2) describes quantum mechanical spin in 3 dimensions in the same\nway that SO(3) describes normal \"spin\" in 3 dimensions. We will talk about the physical\nimplications, reasons, and meaning of this later.\nHowever, as a warning, be careful at this point not to think too much in terms of physics.\nYou have likely covered SU (2) in great detail in a quantum mechanics course (though\nyou may not have known it was called \"SU (2)\"), but the approach we are taking here\nhas a different goal than what you have likely seen before. The properties of SU (2) we\nare seeing here are actually very, very specific and simplified illustrations of much deeper\nconcepts in Lie groups, and in order to understand particle physics we must understand\nLie groups in this way. So for now, try to fight the temptation to merely understand\neverything we are doing in terms of the physics you have seen before and learn this as\nwe are presenting it: pure mathematics. We will focus on how it applies to physics later,\nin its fuller and more fundamental way than introductory quantum mechanics makes\napparent.\n\n49\n\n\f2.2.10 SU (2) for j = 1\nYou can follow the same procedure we used above to find\n\uf8eb\n\uf8eb\n\uf8eb\n\uf8f6\n\uf8f6\n\uf8f6\n0 1 0\n0 \u2212i 0\n1 0 0\n1\n1\nJ11 = \u221a \uf8ed1 0 1\uf8f8 , J12 = \u221a \uf8ed i 0 \u2212i\uf8f8 , J13 = \uf8ed0 0 0 \uf8f8\n2 0 1 0\n2 0 i\n0\n0 0 \u22121\n\n(2.27)\n\nNotice that only J13 is diagonal (as before), and that the eigenvalues are {1, 0, \u22121}, or\n{j, j \u2212 1, j \u2212 2 = \u2212j} as we'd expect.\n\n2.2.11 SU (2) for Arbitrary j\nFor any given j, we have 3 generators Jj1 , Jj2 , and Jj3 , and for whatever dimension (d =\n2j + 1) the physical space we are working in, we have d eigenvectors\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n1\n0\n0\n0\n\uf8ec0\uf8f7\n\uf8ec1\uf8f7\n\uf8ec0\uf8f7\n\uf8ec0\uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n|j; ji = \uf8ec0\uf8f7 , |j; j \u2212 1i = \uf8ec0\uf8f7 , |j; j \u2212 2i = \uf8ec1\uf8f7 , * * * |j; \u2212ji = \uf8ec0\uf8f7\n\uf8ec .. \uf8f7\n\uf8ec .. \uf8f7\n\uf8ec .. \uf8f7\n\uf8ec .. \uf8f7\n\uf8ed.\uf8f8\n\uf8ed.\uf8f8\n\uf8ed.\uf8f8\n\uf8ed.\uf8f8\n0\n0\n0\n1\nwith eigenvalues {j, j \u2212 1, j \u2212 2, * * * , \u2212j}, respectively.\nThen, for any j, we can form the linear combinations Jj\u00b1 \u2261 \u221a12 (Jj1 \u00b1 iJj2 ).\nj = 1/2 these are\n\u0014 \u0012\n\u0013\n\u0012\n\u0013\u0015\n\u0012\n\u0013\n\u0012\n1 1 0 1\ni 0 \u2212i\n1\n1 0\n0 2\n+\nJ1/2 = \u221a\n+\n= \u221a\n=\u221a\n2 i 0\n2 2 1 0\n2 2 0 0\n2 0\n\nFor example, for\n\n1\n0\n\n\u0013\n\nand similarly\n\u2212\nJ1/2\n\n1\n= *** = \u221a\n2\n\n\u0012\n\u0013\n0 0\n1 0\n\n\u0012 \u0013\n\u0012 \u0013\n1\n0\n1\n1\nSo, the two j = 1/2 eigenvectors will be\n=\nand 2 ; \u2212 2 i =\n. So,\n0\n1\n\u001d\n\u0012\n\u0013\u0012 \u0013\n1 0 1\n1\n+ 1 1\nJ1/2 ;\n=\u221a\n=0\n0\n2 2\n2 0 0\n\u001d\n\u0012\n\u0013\u0012 \u0013\n1\n1 0 0\n0\n\u2212 1\n=\u221a\n=0\nJ1/2 ; \u2212\n1\n2 2\n2 1 0\n1 1\n; i\n2 2\n\n50\n\n\fand similarly\n\u2212\nJ1/2\n+\nJ1/2\n\n\u001d\n\u001d\n1 1\n1 1\n;\n= ;\u2212\n2 2\n2 2\n\u001d\n\u001d\n1 1\n1 1\n;\u2212\n= ;\n2 2\n2 2\n\nwhich is exactly what we would expect.\nThe same calculation can be done for the j = 1 case and we will find the same results,\nexcept that the j = 1 state (the first eigenvector) can be lowered twice. The first time\n\u2212\nJ1/2\nacts it takes it to the state with eigenvalue 0, and the second time it acts it takes it\nto the state with eigenvalue \u22121. Acting a third time will destroy the state (take it to 0).\nAnalogously, the lowest state, with eigenvalue j = \u22121 can be raised twice.\nWe can do the same analysis for any j = integer or half integer.\nAs we said before, we interpret j as the quantum mechanical spin of a particle, and the\ngroup SU (2) describes that rotation. It is important to recognize that quantum spin is\nnot a rotation through spacetime (it would be described by SO(3) if it was), but rather\nthrough the mathematically constructed spinor space. We will talk more about this space\nlater.\nSo for a given particle with spin, we can talk about both its rotation through physical\nspacetime using SO(3), as well as its rotation through complex spinor space using SU (2).\nBoth values will be physically measurable and will be conserved quantities. The total\nangular momentum of the particle will be the combination of both spin and spacetime\nangular momentum. Again, we will talk much more about the spin of physical particles\nwhen we return to a discussion of physics. We only mention this now to give a preview\nof where this is going. However, spin is not the only thing SU (2) describes. We will also\nfind that it is the group which governs the weak nuclear force (whereas U (1) describes\nthe electromagnetic force, and SU (3) describes the strong force ... much, much more on\nthis later).\n\n2.2.12\n\nRoot Space\n\nAs a comment before beginning this section, it is likely that you will find this to be the\nmost difficult section of these notes. The material here is both extremely difficult (especially the first time it is encountered), and extremely important to the development of\nparticle physics. In fact, this section is the most central to what will come later in these\nnotes. If the contents are not clear you are encouraged to read this section multiple times\nuntil it becomes clear. It may also be helpful to study this section while looking closely\nat the examples in the sections forming the remainder of this part of these notes. They\nillustrate the point of where we are going with all of this.\n51\n\n\fWe saw in the previous section that we can view the physical space that a group is acting\non by using the eigenvectors of the diagonal generators as a basis. These eigenvectors\ncan be arranged in order of decreasing eigenvalue. Then, the non-diagonal generators\ncan be used to form linear combinations that act as raising and lowering operators, which\ntransform one eigenvector to another, changing the eigenvalue by an amount defined by\nthe commutation relations of the generators.\nWe now see that this generalizes very nicely.\nAn arbitrary Lie group is defined in terms of its generators. As we said at the end of\nsection 2.2.2, it is best to think of the generators as being analogous to the basis vectors\nspanning some space. Of course, the space the generators span is much more complicated\nthan Rn in general, but the generators span the space the same way. In this sense, the\ngenerators form a linear vector space. So, we must define an inner product for them. For\nreasons that are beyond the scope of these notes, we will choose the generators and inner\nproduct so that, for generators T a and T b ,\n1\nTr (T a T b ) = \u03b4 ab\n\u03ba\nwhere \u03ba is some normalization constant.\nhT a , T b i \u2261\n\n(2.28)\n\nAlso, in the set of generators of a Lie group, there will be a closed subalgebra of generators\nwhich all commute with each other, but not with generators outside of this subalgebra.\nIn other words, this is the set of generators which can be simultaneously diagonalized\nthrough some similarity transformation. For SU (2), we saw that there was only one generator in this subalgebra which we chose to be Jj3 (recall that a matrix will only commute\nwith all other matrices if it is equal to the identity matrix times a constant, whereas two\ndiagonal matrices will always commute regardless of what their diagonal elements are).\nLet's say that a particular Lie group has N generators total, or is an N -dimensional group.\nThen, let's say that there are M < N generators in the mutually commuting subalgebra.\nWe call those M generators the Cartan Subalgebra, and the generators in it are called\nCartan Generators. We define the number M as the Rank of the group.\nBy convention we will label the Cartan generators H i (i = 1, . . . , M ) and the non-Cartan\ngenerators E i (i = 1, . . . , N \u2212 M ).\nFor example, with SU (2) we had H 1 = Jj3 , and E 1 = Jj1 , E 2 = Jj2 .\nBefore moving on, we point out that this should seem familiar. If you think back to an\nintroductory class in quantum mechanics, recall that we always choose some set of variables that all commute with each other (usually we choose either position or momentum\nbecause [x, p] 6= 0). Then, we expand the physical states in terms of the position or momentum eigenvectors. Here, we are doing the exact same thing, only in a much more\ngeneral context.\nNow, the H i 's are simultaneously diagonalized, so we will write the physical states in\n52\n\n\fterms of their eigenvalues. In an n-dimensional representation Dn , the generators are n\u00d7n\nmatrices, so the eigenvectors are n-dimensional. So, there will be a total of n eigenvectors,\nand each will have one eigenvalue with each of the M Cartan generators H i . So, for each\nof these eigenvectors, which we temporarily denote |ji, for j = 1, . . . , n, we have the\nM eigenvalues with M Cartan generators, which we call tij (where j = 1, . . . , n labels\nthe eigenvectors, and i = 1, . . . , M labels the eigenvalues), and we form what is called a\nWeight Vector\n\uf8eb 1\uf8f6\ntj\n\uf8ec t2 \uf8f7\n\uf8ec j\uf8f7\n\uf8ec 3\uf8f7\nt\u0304j \u2261 \uf8ec tj \uf8f7\n(2.29)\n\uf8ec .. \uf8f7\n\uf8ed . \uf8f8\ntM\nj\nwhere j = 1, . . . , n. The individual components of these vectors, the tij 's, are called the\nWeights.\nSo for a given representation Dn , we now denote the state |Dn ; t\u0304j i (instead of |ji). So, our\neigenvalues will be\nH i |Dn ; t\u0304j i = tij |Dn ; t\u0304j i\n\n(2.30)\n\nAs we mentioned before, the adjoint representation is a particularly important representation. If you do not remember the details of the adjoint representation, go reread section\n2.2.4. Here, the generators are defined by equation (2.12), [T a ]bc \u2261 \u2212ifabc . Recall that each\nindex runs from 1 to N , so that the generators in the adjoint representation are N \u00d7 N\nmatrices, and the eigenvectors are N -dimensional.\nAlso, as a point of nomenclature, weights in the adjoint representation are called Roots,\nand the corresponding vectors (as in (2.29)) are called Root Vectors.\nThis means that there is exactly one eigenvector for each generator, and therefore one\nroot vector for each generator. So, in equation (2.29), j = 1, . . . , N . We make this more\nobvious by explicitly assigning each eigenvector to a generator as follows. First, because\nwe now have the same number of generators, eigenvectors, and root vectors, we label the\ngenerators by the root vectors T t\u0304j instead of T j . Also, we now refer to general eigenstates\nas |Adj; T t\u0304j i, where j = 1, . . . , N and t\u0304j is the M -dimensional root vector corresponding\nto T t\u0304j . And, we also divide the states |Adj; T t\u0304j i into two groups: those corresponding\nto the M Cartan generators |Adj; H h\u0304j i (where j = 1, . . . , M and h\u0304j is the M -dimensional\nroot vector corresponding to H h\u0304j ), and those corresponding to the N \u2212 M non-Cartan\ngenerators |Adj; E \u0113j i (where j = 1, . . . N \u2212 M and \u0113j is the M -dimensional root vector\ncorresponding to E \u0113j ).\nDon't be alarmed by the superscripts being vectors. We are using this notation for later\nconvenience, and T t\u0304i here means the same thing T j did before (the j th generator). This\n53\n\n\fnotation, which we use only for the adjoint representation, is simply taking advantage\nof the fact that in the adjoint representation, the total number of generators, the number\nof eigenvectors of the Cartan generators, the dimension of the representation, and the\nnumber of weight/root vectors is the same.\nAlso, with the adjoint representation states |Adj; T t\u0304j i, we can use equation (2.28) to define\nthe inner product between states as\nhAdj; T t\u0304j |Adj; T t\u0304k i =\n\n1\nTr (T t\u0304j T t\u0304k ) = \u03b4 jk\n\u03ba\n\n(2.31)\n\nWe will make use of this equation soon.\nThe matrix elements of a given generator will then be given by the familiar equation\n\u2212 ifabc = [T t\u0304a ]bc \u2261 hAdj; T t\u0304b |T t\u0304a |Adj; T t\u0304c i\nWe want to know what an arbitrary generator T t\u0304a will do to an arbitrary state |Adj; T t\u0304b i\nin the adjoint representation. So,\nX\nX\nT t\u0304a |Adj; T t\u0304b i =\n|Adj; T t\u0304c ihAdj; T t\u0304c |T t\u0304a |Adj; T t\u0304b i =\n|Adj; T t\u0304c i[T t\u0304a ]cb\nc\n\n=\n\nc\n\nX\n\nt\u0304c\n\n|Adj; T i(\u2212ifacb ) =\n\nX\n\nt\u0304c\n\nifabc |Adj; T i\n\nc\n\nc\n\nAnd, because there is exactly one eigenvector for each generator, the state |Adj; T t\u0304c i corresponds to the generator T c . And because we know that\nifabc T t\u0304c = [T t\u0304a , T t\u0304b ]\n(where c is understood to be summed) by definition of the structure constants, we can\ninfer that\nX\nT t\u0304a |Adj; T t\u0304b i =\nifabc |Adj; T t\u0304c i = |Adj; [T t\u0304a , T t\u0304b ]i\n(2.32)\nc\n\nwhere [T t\u0304a , T t\u0304b ] is simply the commutator.\nThe derivation of equation (2.32) is extremely important, and it is vital that you understand it. However, it is also one of the more difficult results of this already difficult section. You are therefore encouraged (again) to read through this section, comparing it with\nexamples several times until it becomes clear.\nSo, let's apply this to combinations of the two types of generators we have, H h\u0304a 's and\nE \u0113a 's. If we have a Cartan generator acting on a state corresponding to a Cartan generator,\nwe have (from equation (2.30))\nH h\u0304a |Adj; H h\u0304b i = hab |Adj; H h\u0304b i\n54\n\n\fBut from (2.32) we have\nH h\u0304a |Adj; H h\u0304b i = |Adj; [H h\u0304a , H h\u0304b ]i\nBy definition, the Cartan generators commute, so [H t\u0304a , H t\u0304b ] \u2261 0, and therefore\nh\u0304b \u2261 0\n\n(2.33)\n\nSo we can drop them from our notation, leaving the eigentstates corresponding to nonCartan generators denoted |Adj; H j i.\nOn the other hand, if we have a Cartan generator acting on an eigenstate corresponding\nto a non-Cartan generator, equation (2.30) gives\nH a |Adj; E \u0113b i = eab |Adj; [H a , E \u0113b ]i\n\n(2.34)\n\nH a |Adj; E \u0113b i = |Adj; [H a , E \u0113b ]i\n\n(2.35)\n\nAnd equation (2.32) gives\n\nNow, we don't know a priori what [H a , E \u0113b ] is, but comparing (2.34) and (2.35), we see\n|Adj; eab E \u0113b i = |Adj; [H a , E \u0113b ]i\nAnd because we know that each of these vectors corresponds directly to the generators,\nwe have the final result\n[H a , E \u0113b ] = eab E \u0113b\n\n(2.36)\n\nNow we want to know what a non-Cartan generator does to a given eigentstate. Consider\nan arbitrary state |Adj; T t\u0304b i with H c eigenvalue tcb . We can act on this with E \u0113a to create\nthe new state E \u0113a |Adj; T t\u0304b i. So what will the H c eigenvalue of this new state be? Using\n(2.36),\nH c E \u0113a |Adj; T t\u0304b i = (H c E \u0113a \u2212 E \u0113a H c + E \u0113a H c )|Adj; T t\u0304b i = ([H c , E \u0113a ] + E \u0113a H c )|Adj; T t\u0304b i\n= (eca E \u0113a + E \u0113a tcb )|Adj; T t\u0304b i = (tcb + eca )E \u0113a |Adj; T t\u0304b i\n= (t\u0304b + \u0113a )c E \u0113a |Adj; T t\u0304b i\n(2.37)\nSo, by acting on the one of the eigenstates with a non-Cartan generator E \u0113a , we have\nshifted the H c eigenvalue by one of the coordinates of the root vector. What this means\nis that the non-Cartan generators play a role analogous to the raising and lowering operators we saw in SU (2), except instead of merely shifting the state \"up\" and \"down\", it\nmoves the states around through some M -dimensional space.\nFrom this, we can also see that if there is an operator that can transform from one state\nto another, there must be a corresponding operator that will make the opposite transformation. Therefore, for every operator E \u0113a , we expect to have the operator E \u2212\u0113a , and\ncorresponding eigenstate |Adj; E \u2212\u0113a i.\n55\n\n\fFinally, consider the state E \u0113a |Adj; E \u2212\u0113a i. We know from (2.32) that E \u0113a |Adj; E \u2212\u0113a i =\n|Adj; [E \u0113a , E \u2212\u0113a ]i. The eigenvalue of this state can be found using equation (2.37):\nH b E \u0113a |Adj; E \u2212\u0113a i = (\u2212\u0113a + \u0113a )b E \u0113a |Adj; E \u2212\u0113a i \u2261 0\nBut according to equation (2.33), states with 0 eigenvalue are states corresponding to Cartan generators. Therefore we conclude that the state E \u0113a |Adj; E \u2212\u0113a i is proportional to\nsome linear combination of the Cartan states,\nX\nE \u0113a |Adj; E \u2212\u0113a i =\nNb |Adj; H b i\n(2.38)\nb\n\nwhere the Nb 's are the constants of proportionality. To find the constants Nb , we follow\nan approach similar to the one we used in deriving (2.24). Taking the inner product and\nusing (2.32),\nX\nX\nNb \u03b4 cb = Nc\n(2.39)\nNb hAdj; H c |Adj; H b i =\nhAdj; H c |E \u0113a |Adj; E \u2212\u0113a i =\nb\n\nb\nc\n\n\u0113a\n\n\u21d2 hAdj; H |Adj; [E , E\n\n\u2212\u0113a\n\n]i = Nc\n\nThen, using (2.31)\nhAdj; H c |Adj; [E \u0113a , E \u2212\u0113a ]i =\n=\n=\n=\n=\n\n1\nTr (H c [E \u0113a , E \u2212\u0113a ])\n\u03ba\n1\nTr (E \u2212\u0113a [H c , E \u0113a ])\n\u03ba\n1 c\ne Tr (E \u2212\u0113a E \u0113a )\n\u03ba a\neca \u03b4 aa\neca\n\nSo,\nNc = eca\nAnd therefore equation (2.38) is now\nE \u0113a |Adj; E \u2212\u0113a i = |Adj; [E \u0113a , E \u2212\u0113a ]i = eba |Adj; H b i\nwhere the sum over b is understood. This leads to our final result,\n[E \u0113a , E \u2212\u0113a ] = eba H b\n\n(2.40)\n\nThough we did all of this using the adjoint representation we have seen before, this structure is the same in any representation, and therefore everything we have said is valid\nin any Dn . We worked in the adjoint simply because that makes the results easiest to\nobtain. The extensive use we made of labeling the eigenvectors with the generators can\n56\n\n\fonly be done in the adjoint representation because only in the adjoint does the number of\neigenvectors equal the number of eigenstates. However, this will not be a problem. The\nimportant results from this section are (2.36) and (2.40), which are true in any representation. Part of what we will do later is find these structures in other representations.\nThe importance of the ideas in this section cannot be stressed enough. However, the\nmaterial is somewhat abstract. So, we consider a few examples of how all this works.\n\n2.2.13\n\nAdjoint Representation of SU (2)\n\nWe now illustrate what we did in section 2.2.12 with SU (2). We will work in the adjoint\nrepresentation to make the correspondence with section 2.2.12 as transparent as possible.\nSU (2) has 3 generators, and therefore the adjoint representation will consist of 3 \u00d7 3 matrices. This is simply the j = 1 representation, which we wrote out in equation (2.27).\nFirst, it is easy to verify that (2.28) and (2.31) hold for \u03ba = 2.\nNext we look at the eigenstates. We know they will be the normal vectors\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n1\n0\n0\nv1 = \uf8ed0\uf8f8 ,\nv2 = \uf8ed1\uf8f8 ,\nv3 = \uf8ed0\uf8f8\n0\n0\n1\n(we will relabel them to be consistent with section 2.2.12 shortly).\nObviously only J13 is diagonal, so SU (2) has rank M = 1. We define\n\n\uf8eb\n\nH 1 = J13\n\n\uf8f6\n1 0 0\n= \uf8ed0 0 0 \uf8f8\n0 0 \u22121\n\n\uf8eb\n\n\uf8f6\n0 1 0\n1\nE 1 = J11 = \uf8ed1 0 1\uf8f8 ,\n2\n0 1 0\n\n\uf8eb\n\n\uf8f6\n0 \u2212i 0\n1\nE 2 = J12 = \uf8ed i 0 \u2212i\uf8f8\n2\n0 i\n0\n\nBecause the rank is 1, the root vectors will be 1-dimensional vectors, or scalars. We find\nthem easily by finding the eigenvalues of each eigenvector with H 1 :\nH 1 v1 = (+1)v1 ,\n\nH 1 v2 = (0)v2 ,\n\nH 1 v3 = (\u22121)v3\n\nSo the root vectors are\nt\u03041 = t1 = +1\n\nt\u03042 = t2 = 0\n\nWe can graph these on the real line as shown below,\n57\n\nt\u03043 = t3 = \u22121\n\n(2.41)\n\n\fNow our initial guess will be to associate v3 with J13 = H 1 , and then v1 = E 1 and v2 = E 2 .\nBut we want to exploit what we learned in section 2.2.12, and therefore we must make\nsure that (2.36) and (2.40) hold.\nStarting with (2.36), we check (leaving the tedious matrix multiplication up to you)\n\uf8eb\n\uf8f6\n0\n1 0\n1\n[H 1 , E 1 ] = * * * = \uf8ed\u22121 0 1\uf8f8\n(2.42)\n2\n0 \u22121 0\n\uf8eb\n\uf8f6\n0 1 0\ni\n[H 1 , E 2 ] = * * * = \u2212 \uf8ed1 0 1\uf8f8\n(2.43)\n2\n0 1 0\nBut we have a problem. According to (2.36), [H 1 , E i ] should be proportional to E i , but\nthis is not the case here. However notice that in (2.42),\n\uf8eb\n\uf8f6\n0\n1 0\n1\uf8ed\n\u22121 0 1\uf8f8 = iE 2\n2\n0 \u22121 0\nand in (2.43),\n\uf8eb\n\n\uf8f6\n0 1 0\ni\n\u2212 \uf8ed1 0 1\uf8f8 = \u2212iE 1\n2\n0 1 0\n58\n\n\fWriting this more suggestively,\n[H 1 , E 1 ] = iE 2 ,\n\n[H 1 , iE 2 ] = E 1\n\n(2.44)\n\nSo, if we take the linear combinations of equations (2.44), we get [H 1 , \u03b1E 1 \u00b1 \u03b2iE 2 ] =\n\u03b2E 1 \u00b1 \u03b1iE 2 , which has the correct form of equation (2.36) as long as \u03b1 = \u03b2. Therefore we\nare now working with the operators E \u00b1 \u2261 \u03b1(E 1 \u00b1 iE 2 ).\nNow we seek to impose (2.40). We start by evaluating\n[E + , E \u2212 ] =\n=\n=\n=\n\n\u03b12 [E 1 + iE 2 , E 1 \u2212 iE 2 ]\n\u0001\n\u03b12 [E 1 , E 1 ] \u2212 i[E 1 , E 2 ] + i[E 2 , E 1 ] + [E 2 , E 2 ]\n\u22122i\u03b12 [E 1 , E 2 ] = * * *\n\u22122i\u03b12 iH 1 = 2\u03b12 H 1\n\nThen, from equations (2.41) and the definition of E \u00b1 , we see that \u00b1e11 = \u00b1(t1 \u2212 t2 ) =\n\u00b1(1 \u2212 0) = \u00b11. So we therefore set \u03b12 = 21 \u21d2 \u03b1 = \u221a12 , and we find that the appropriate\nnon-Cartan generators (including the 1 to be consistent with the notation in section 2.2.12)\nare\n1\nE \u00b11 = \u221a (E 1 \u00b1 iE 2 )\n2\n\n(2.45)\n\nwhich is exactly what we had in equation (2.18) above. So, we have derived the trick used\nto understand quantum mechanical spin in introductory quantum courses!\n\n2.2.14 SU (2) for Arbitrary j . . . Again\nNow that we have our operators in the adjoint representation, we can consider any arbitrary representation. As we saw in section 2.2.11, we can form the linear combinations in\nequation (2.45) for any j = integer or half integer. The weight vectors will always look like\nthose in the diagram on page 58 (in other words, raising and lowering operators always\nraise or lower their eigenvalue by 1).\n\n59\n\n\fThe space of physical states, on the other hand, changes for each representation. For\nj = 12 , we have\n\nFor j = 1,\n\n60\n\n\fFor j = 3/2,\n\nand so on.\nNotice that the vectors graphed in the diagram on page 58 are the exact vectors required\nto move from point to point in each of these graphs. This is obviously not a coincidence.\n\n2.2.15 SU (3)\nNow that we have said pretty much everything we can about SU (2), which is only Rank 1\n(and therefore not all that interesting), we move on to SU (3). However, we will expedite\nthe process by stating the structure constants up front. The non-zero structure constants\nare\n\u221a\n3\n1\nf123 = 1, f147 = f165 = f246 = f257 = f345 = f376 = , f458 = f678 =\n2\n2\nThe most convenient representation is the Fundamental Representation (consisting of\n\n61\n\n\f3 \u00d7 3 matrices). They are T a = 12 \u03bba for a = 1, . . . , 8, where\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n0 1 0\n0 \u2212i 0\n1 0 0\n0 0 1\n\u03bb1 = \uf8ed1 0 0\uf8f8 , \u03bb2 = \uf8ed i 0 0\uf8f8 , \u03bb3 = \uf8ed0 \u22121 0\uf8f8 , \u03bb4 = \uf8ed0 0 0\uf8f8\n0 0 0\n0 0 0\n0 0 0\n1 0 0\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\n\uf8f6\n1 0 0\n0 0 \u2212i\n0 0 0\n0 0 0\n1\n\u03bb5 = \uf8ed0 0 0 \uf8f8 , \u03bb6 = \uf8ed0 0 1\uf8f8 , \u03bb7 = \uf8ed0 0 \u2212i\uf8f8 , \u03bb8 = \u221a \uf8ed0 1 0 \uf8f8\n3 0 0 \u22122\ni 0 0\n0 1 0\n0 i 0\n(2.46)\nClearly, only two of these are diagonal, \u03bb3 and \u03bb8 . So, SU (3) is a rank 2 group.\nBefore moving on, we summarize a few results (without proofs). An arbitrary SU (n)\ngroup will always have n2 \u2212 1 generators, and will be rank n \u2212 1. An arbitrary SO(n)\ngroup (for n even) will always have n(n\u22121)\ngenerators. We won't worry about the rank of\n2\nthe orthogonal groups.\nWorking in the adjoint representation of SU (3) would involve 8\u00d78 matrices, which would\nobviously be very tedious. So, we exploit the fact that the techniques we developed in section 2.2.12 are valid in any representation, and stick with the Fundamental Representation\ndefined by the generators in (2.46).\nProceeding as in section 2.2.13, we note that the eigenvectors will again be\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n1\n0\n0\n\uf8ed\n\uf8ed\n\uf8f8\n\uf8ed\n\uf8f8\nv1 = 0 , v2 = 1 , v3 = 0\uf8f8\n0\n0\n1\n(we will relabel them to be consistent with section 2.2.12 shortly).\nThen, the Cartan generators are\n\uf8eb\n\uf8f6\n1 0 0\n1\nH 1 = \uf8ed0 \u22121 0\uf8f8 ,\n2\n0 0 0\n\n\uf8eb\n\n\uf8f6\n1 0 0\n1\nH 2 = \u221a \uf8ed0 1 0 \uf8f8\n2 3 0 0 \u22122\n\nand the non-Cartan Generators are simply\nE 1 = T 1,\n\nE 2 = T 2,\n\nE 3 = T 4,\n\nE 4 = T 5,\n\nE 5 = T 6,\n\nE6 = T 7\n\nSo we have 6 eigenvalues to find,\n\u0012 \u0013\n\u0012\n\u0013\n1\n1\n1\n1\nH v1 =\nv1 ,\nH v2 = \u2212\nv2 , H 1 v3 = (0)v3\n2\n2\n\u0012\n\u0013\n\u0012\n\u0013\n\u0012\n\u0013\n1\n1\n1\n2\n2\n2\n\u221a v1 , H v2 =\n\u221a v2 , H v3 = \u2212 \u221a v3\nH v1 =\n2 3\n2 3\n3\n62\n\n\fSo the weight vectors will be 2-dimensional (because the rank is 2). They are\n\u0010\n\u0011T\n\u0011T\n\u0011T\n\u0010\n\u0010\nt\u03041 = 12 2\u221a1 3 , t\u03042 = \u2212 12 2\u221a1 3 , t\u03043 = 0 \u2212 \u221a13\n\n(2.47)\n\nWe can graph these in R2 as shown below,\n\nNow, repeating nearly the identical argument we started with equation (2.42) and repeating it for all 6 non-Cartan generators, we find that in order to maintain (2.36) and (2.40),\nwe must work with the operators\n1\n\u221a (T 1 \u00b1 iT 2 ) =\n2\n1\n\u221a (T 4 \u00b1 iT 5 ) =\n2\n1\n\u221a (T 6 \u00b1 iT 7 ) =\n2\n\n1\n\u221a (E 1 \u00b1 iE 2 )\n2\n1\n\u221a (E 3 \u00b1 iE 4 )\n2\n1\n\u221a (E 5 \u00b1 iE 6 )\n2\n\n(2.48)\n\nThe weight vectors associated with these will be, respectively,\n\u0012 \u0013\n\u0012\n\u0013\n\u0012\n\u0013\n1/2\n\u22121/2\n1\n\u00b1 (t\u03041 \u2212 t\u03042 ) = \u00b1\n, \u00b1(t\u03041 \u2212 t\u03043 ) = \u00b1 \u221a\n, and \u00b1 (t\u03042 \u2212 t\u03043 ) = \u00b1 \u221a\n0\n3/2\n3/2\n(2.49)\nSo, the non-Cartan generators are\n0 1\n\n1\n\u00b1@ A\nE 0 ,\n\n0\n\n1\n\n1/2 A\n\u00b1 @\u221a\n3/2 ,\nE\n63\n\n0\n\n1\n\n\u22121/2A\n\u00b1@\u221a\n3/2\nE\n\n\fWe are no longer in the adjoint representation, so we had to be more deliberate about\nchoosing these linear combinations than we could be in section 2.2.13. What we did here is\nmore general; we chose them to be the differences in the three weight vectors in equation\n(2.47), so that these vectors would naturally transform from one eigenvector to another\n(just as the raising and lowering operators do, as we found for SU (2) and more generally\nin section 2.2.12). The remarkable property of Lie groups is that this is always possible in\nany representation.\nWe can graph the 6 vectors in (2.49), along with the two Cartan weight vectors, which we\nknow from (2.33) are 0:\n\nAnd again, just as with SU (2), notice that the 6 non-zero vectors are the exact vectors\nthat would be necessary to move from point to point on the diagram on page 63. So once\nagain, we see that the non-Cartan generators act as raising and lowering operators which\ntransform between the eigenstates of the Cartan generators. Notice that there were 6 nonCartan generators, and they formed linear combinations to form 6 raising and lowering\noperators.\n\n2.2.16\n\nWhat is the Point of All of This?\n\nBefore finally getting back to physics, we give a spoiler of how Lie theory is used in\nphysics. What we are going to find is that some physical interaction (electromagnetism,\nweak force, strong force) will ultimately be described by a Lie group in some particular\n64\n\n\frepresentation. The particles that interact with that force will be described by the eigenvectors of the Cartan generators of the group, and the eigenvalues of those eigenvectors\nwill be the physically measurable charges. Clearly, the number of charges associated with\nthe interaction is equal to the number of dimensions of the representation. For example,\nyou likely are aware that the strong force has 3 charges, called \"colors\" (red, green, and\nblue). So, the strong force (we will see) will be in a 3-dimensional representation of the\ngroup that describes it.\nWe will find that all forces carrying particles (photons, gluons, W and Z bosons) will be\ndescribed by the generators of their respective Lie group. The Cartan generators will be\nforce-carrying particles which can interact with any particle charged under that group\nby transferring energy and momentum, but do not change the charge (photons and Z\nbosons). This makes sense because Cartan generators are not raising or lowering operators. On the other hand, the non-Cartan generators will be force carrying particles which\ninteract with any particle charged under that group by not only transferring energy and\nmomentum, but also changing the charge (W bosons and gluons).\nWe won't be able to come back to discussing how this works until much later, and until\nexamples are worked out, this may not be clear. We merely wanted to give an idea of\nwhere we are going with this.\n2.3\n\nReferences and Further Reading\n\nThe material in section 2.1 came primarily from [9] and [30]. The material in 2.2 came\nfrom [9], [10], and [15]. The sections on SU (2) also came from [31].\nFor further reading, we recommend [2], [8], [16], [17], and [28].\n\n65\n\n\f3\n\nPart III - Quantum Field Theory\n\n3.1\n3.1.1\n\nA Primer to Quantization\nQuantum Fields\n\nOur ultimate goal in the exposition that follows is to formulate a relativistic quantum mechanical theory of interactions. So, beginning with the fundamental equation of quantum\nmechanics, Schroedinger's equation,\nH\u03a8 = i~\n\n\u2202\u03a8\n\u2202t\n\nwe know that for a non-interacting, non-relativistic particle, H =\n\u2212\n\n~  \u03042\n\u2202\u03a8\n\u2207 \u03a8 = i~\n2m\n\u2202t\n\np\u03042\n2m\n\n~  \u03042\n= \u2212 2m\n\u2207 , so\n\n(3.1)\n\nOf course, \u03a8 is in this case a Scalar Field , and therefore only has one state. So, it describes\na spin-0 particle (or, in the language we have learned in the previous sections, it sits in a\nj = 0 representation of SU (2), which is the trivial representation). And, since \u03a8 does not\nhave any spacetime indices, it also transforms trivially under the Lorentz group SO(1, 3).\nNotice, however, that we have a fundamental barrier in making a relativistic theory - the\n \u0304 2 ), whereas the time derivative is linear.\nspatial derivative in (3.1) acts quadratically (\u2207\nClearly, treating space and time differently in this way is unacceptable for a relativistic\ntheory. That is a hint of a much more fundamental problem with quantum mechanics;\nspace is always treated as an operator, but time is always treated as a parameter. This\nfundamental asymmetry is what ultimately prevents a straightforward generalization to\nrelativistic quantum theory.\nTo fix this problem, we have two choices: either promote time to an operator along with\nspace, or demote space back to a parameter and quantize in a new way.\nThe first option would result in the Hermitian operators X\u0302, \u0176 , \u1e90, and T\u0302 . It turns out that\nthis approach is very difficult and less useful as far as building a relativistic quantum\ntheory. So, we will take the second option.\nIn demoting position to a parameter along with time, we obviously have sacrificed the\noperators which we imposed commutation relations on to get a \"quantum\" theory in the\nfirst place. And because we obviously can't impose commutation relations on parameters\n(because they are scalars), quantization appears impossible. So, we are going to have to\nmake a fairly radical reinterpretation.\n\n66\n\n\fRather than letting the coordinates be Hermitian operators that act on the state in the\nHilbert space representing a particle, we now interpret the particle as the Hermitian operator,\nand this operator (or particle) will be parameterized by the spacetime coordinates. The\nphysical state that the particle operators act on is then the vacuum itself, |0i. So, whereas\nbefore you acted on the \"electron\" |\u03a8i with the operator x\u0302, now the \"electron\"\n(parame\u0001\n\u03bc\n\u03bc\nterized by x) \u03a8(x ) acts on the vacuum |0i, creating the state \u03a8(x )|0i . In other words,\nthe operator representing an electron excites the vacuum (empty space) resulting in an\nelectron. We will see that all quantum fields contain appropriate raising and lowering\noperators to do just this.\nThis approach, where the quantum mechanical entities are no longer the coordinates acting on the fields, but the fields themselves, is called Quantum Field Theory (QFT).\nSo, whereas before, quantization was defined by imposing commutation relations on the\ncoordinate operators [x, p] 6= 0, we now quantize by imposing commutation relations on\nthe field operators, [\u03a81 , \u03a82 ] 6= 0.\nBecause we must still write down the equations of motion which govern the dynamics\nof the fields, we will need to spend the rest of this section coming up with the classical\nequations governing the fields we want to work with. We will quantize them in the next\nsection.\n\n3.1.2\n\nSpin-0 Fields\n\nAs we said above, Schroedinger's equation (3.1) describes the time evolution of a spin-0\nfield, or a scalar field. Generalizing to higher spins will come later. Now, we see how to\nmake this description relativistic.\nThe most obvious guess for a relativistic form is to simply plug in the standard relativistic\nHamiltonian\np\n(3.2)\nH = p\u03042 c2 + m2 c4\n\u221a\nNote that, using the standard Taylor expansion 1 + x2 \u2248 1 + 12 x for x << 1 gives H \u2248\np\u03042\nmc2 + 2m\n, for p\u03042 << c2 , which is the standard non-relativistic form (plus a constant) we'd\nexpect from a low speed limit.\nPlugging (3.2) into (3.1), we have\ni~\n\n\u2202\u03c6 p 2 2  \u0304 2\n= \u2212~ c \u2207 + m2 c4 \u03c6\n\u2202t\n\nBut there are two problems with this:\n1. The space and time derivatives are still treated differently, so this is inadequate as a\nrelativistic equation, and\n67\n\n\f2. Taylor expanding the square root will give an infinite number of derivatives acting\non \u03c6, making this theory non-local.\nOne solution is to square the operator on both sides, giving\n2\u2202\n\n\u2212~\n\n2\n\n\u03c6\n\u2202t2\n\n \u0304 2 + m2 c4 )\u03c6\n= (\u2212~2 c2 \u2207\n2 2\n \u0304 2 \u2212 m c )\u03c6 = 0\n\u21d2 (\u2212\u2202 0 \u22020 + \u2207\n~2\n\nOr, if we choose the so called \"natural units\" or \"God units\", where c = ~ = 1, we have\n(\u2202 2 \u2212 m2 )\u03c6 = 0\n\n(3.3)\n\nEquation (3.3) is called the Klein Gordon equation. It is nothing more than an operator\nversion of the standard relativistic relation E 2 = m2 c4 + p\u03042 c2 .\nNote that because we will be quantizing fields and not coordinates, there is absolutely\nnothing \"quantum\" about the Klein Gordon equation. It is, at this point, merely a relativistic wave equation for a classical, spinless, non-interacting field.\nFinally, we note one major\np problem with the Klein Gordon equation. When we squared\nthe Hamiltonian\nm2 c4 + p\u03042 c2 to get H 2 = m2 c4 + p\u03042 c2 , the energy eigenvalues\npH =\nbecame E = \u00b1 m2 c4 + p\u03042 c2 . It appears that we have a negative energy eigenvalue! Obviously this is unacceptable in a physically meaningful theory, because negative energy\nmeans that we don't have a true vacuum, and therefore a particle can cascade down forever, giving off an infinite amount of radiation.\nWe will see that this problem plagues the spin-1/2 particles as well, so we wait to talk\nabout the solution until then.\n\n3.1.3\n\nWhy SU (2) for Spin?\n\nBecause we are talking about particles \"spinning\", a common question is why don't we\nuse SO(3) instead of SU (2)? The original answer to the question is historical. The experiments done in the early days of quantum mechanics were not consistent with the particles\nhaving a rotational degree of freedom in spacetime. Rather, the data indicated that, along\nany given axis, the spin could have only one of two possible values, and SO(3) does not\nexplain this. Here, however, we consider a more mathematical explanation.\nFirst, recall that spin is a purely quantum mechanical phenomenon, with no classical\nanalogue. Because the data demanded two possible\n\u0012 \u0013 spin states, the field describing the\n\u03a81\nparticle had to have 2 spin components, \u03a8 =\n. Now, if we seek a 2-dimensional\n\u03a82\n68\n\n\frepresentation of SO(3), we find that there is only one: D0 \u2295 D0 , the trivial representation\nconsisting of all 1's. This means\n\u0012 0\u0013\n\u0012 \u0013 \u0012\n\u0013\u0012 \u0013 \u0012 \u0013\n\u03a81\n\u03a81\n1 0\n\u03a81\n\u03a81\n= D0 \u2295 D0\n=\n=\n\u03a802\n\u03a82\n0 1\n\u03a82\n\u03a82\nwhich is no transformation. This is the only 2-dimensional representation of SO(3) that\nis possible.\nThe solution to the problem is found in one of the many peculiarities of quantum mechanics. The only physically measurable quantity in quantum theory is \u0012\nthe probability\n\u0013\n\u03a81\namplitude, which is proportional to the square of \u03a8. Therefore, the state\nis physi\u03a82\n\u0012\n\u0013\n\u2212\u03a81\ncally identical to\n.\n\u2212\u03a82\nNow consider a general element of SO(3): ei(\u03c6Jx +\u03c8Jy +\u03b8Jz ) . On the other hand, a general\n\u03c3y\n\u03c3z\n\u03c3x\nelement of SU (2) will be ei(\u03c6 2 +\u03c8 2 +\u03b8 2 ) .\nNow consider rotating the system by an angle of 2\u03c0 around, say, the z axis. The SO(3)\nelement corresponding to this rotation will be ei2\u03c0Jz , while the SU (2) element will be\nei\u03c0\u03c3z . The factor of 1/2 difference means that the spinor space rotates through only half\nthe angle of the SO(3) does. So, in the 2\u03c0 rotation, U \u2208 SU (2) \u2192 \u2212U , whereas R \u2208\nSO(3) \u2192 R. Therefore, both U and \u2212U correspond to R. There is a 2 to 1 correspondence\nbetween SU (2) and SO(3).\nAnd, as we said above, spin is a purely quantum mechanical effect and experimentally\nonly allows 2 values, but SO(3) has no such representation, whereas the j = 1/2 representation of SU (2) does. We therefore use SU (2). And, because SU (2) is 2 \u2192 1 with\nSO(3), but spin is quantum mechanical, both U and \u2212U can consistently correspond to\nthe same R \u2208 SO(3). The minus sign difference is not subject to measurement; only |\u03a8|2\nis physically measurable.\nAn important thing to understand is that \"spin\" is not a rotation through spacetime in any\nmeaningful way. It is a rotation in \"spinor space\", which is an internal degree of freedom.\nLike many things in quantum mechanics, spinor space is a mathematical structure. All\nwe can say for certain is what we can measure, or know (|\u03a8|2 ), not what \"is\".\n\n3.1.4\n\nSpin\n\n1\n2\n\nParticles\n\nFinding equation (3.3) was easy because scalar fields have no spacetime indices and no\nspinor indices, and they therefore transform trivially under SU (2) and the Lorentz group.\nA particle of spin 1/2 however, will have two complex components, one for spin +1/2,\n\n69\n\n\fand the other for spin \u22121/2. So, we describe such a particle as the two-component Spinor\n\u0012 \u0013\n\u03c81\n\u03c8=\n\u03c82\nwhere \u03c81 and \u03c82 are both \u2208 C. So, we want some differential operator in the form of 2 \u00d7 2\nmatrices to act on such a field to form the equation of motion.\nFollowing Dirac's approach, he reasoned that given such a 2 \u00d7 2 operator, the equation of\nmotion should somehow \"imply\" the Klein Gordon equation (which merely makes the\ntheory relativistic). So his goal (and our goal) is to find an equation with a 2 \u00d7 2 matrix\ndifferential operator acting on \u03c8 that results in (3.3).\nDirac's approach was to find an operator of the form\n6D = \u03b3 \u03bc \u2202\u03bc = \u03b3 0 \u22020 + \u03b3 1 \u22021 + \u03b3 2 \u22022 + \u03b3 3 \u22023\nwhere the \u03b3's are 2 \u00d7 2 matrices, and the equation of motion is then 6D\u03c8 = \u2212im\u03c8. The\nchallenge is in finding the appropriate 2 \u00d7 2 \u03b3 matrices. Dirac reasoned that, in order to\nbe properly relativistic, operating twice with 6D should give the Klein Gordon equation.\nIn other words,\n6D = \u2212im\u03c8 \u21d2 6D6D\u03c8 = \u2212im6D\u03c8\n\u21d2 \u03b3 \u03bc \u2202\u03bc \u03b3 \u03bd \u2202\u03bd \u03c8 = \u2212im(\u2212im\u03c8)\n\u21d2 \u03b3 \u03bc \u03b3 \u03bd \u2202\u03bc \u2202\u03bd \u03c8 = \u2212m2 \u03c8\n\u0001\n\u21d2 \u03b3 \u03bc \u03b3 \u03bd \u2202\u03bc \u2202\u03bd + m2 \u03c8 = 0\n\n(3.4)\n\nThis will yield the Klein Gordon equation if \u03b3 \u03bc \u03b3 \u03bd = \u2212\u03b7 \u03bc\u03bd I. Or, using the symmetry of the\nsum in (3.4), it will yield the Klein Gordon equation if we demand 12 (\u03b3 \u03bc \u03b3 \u03bd +\u03b3 \u03bd \u03b3 \u03bc ) = \u2212\u03b7 \u03bc\u03bd I.\nConsider\n{\u03b3 \u03bc , \u03b3 \u03bd } = \u03b3 \u03bc \u03b3 \u03bd + \u03b3 \u03bd \u03b3 \u03bc = \u22122\u03b7 \u03bc\u03bd I\n\n(3.5)\n\nIf the \u03b3 matrices satisfy (3.5), then (3.4) gives\n(\u03b3 \u03bc \u03b3 \u03bd \u2202\u03bc \u2202\u03bd + m2 )\u03c8 = 0 \u21d2 (\u2212\u03b7 \u03bc\u03bd \u2202\u03bc \u2202\u03bd + m2 )\u03c8 = 0 \u21d2 (\u2202 2 \u2212 m2 )\u03c8 = 0\nwhich is exactly the Klein Gordon equation (3.3).\nSo, we have the Dirac equation\n\u0001\n6D + im \u03c8 = 0\n\n(3.6)\n\nbut we still have a problem. Namely, there does not exist a set of 2 \u00d7 2 matrices that solve\n(3.5). Nor does there exist a set of 3 \u00d7 3 matrices. The smallest possible size where this is\npossible is 4 \u00d7 4. Obviously, if we want to describe a spin-1/2 particle with exactly 2 spin\n70\n\n\fstates, using 4 spin components does not seem right. But, we will accept the necessity of\n4 \u00d7 4 Dirac matrices and move on.\n\u0012 \u0013\n\u03c81\nInstead of using \u03c8 =\n, we will define the two 2-dimensional spinors\n\u03c82\n\u0012 \u0013\n\u0012 \u0013\n\u03c81\n\u03c83\n\u03c8L \u2261\nand\n\u03c8R \u2261\n(3.7)\n\u03c82\n\u03c84\nand the 4-component spinor\n\u0012\n\u03c8\u2261\n\n\u03c8L\n\u03c8R\n\n\u0013\n(3.8)\n\nNow it is possible to solve (3.5). Such a problem is actually very familiar to algebraists,\nand we will not delve into the details of how this is done. Instead, we merely state one\nsolution (there are many, up to a similarity transformation). We define the 4 \u00d7 4 matrices\n\u0013\n\u0013\n\u0012\n\u0012\n0 \u03c30\n0 \u2212\u03c3 i\n0\ni\n(3.9)\nand\n\u03b3 =\n\u03b3 =\n\u03c30 0\n\u03c3i 0\nwhere \u03c3 0 is the 2 \u00d7 2 identity matrix, and \u03c3 i are the Pauli spin matrices. It should be no\nsurprise that they show up in attempting to describe spin-1/2 particles. What is interesting is that we did not assume them-we derived them using (3.5).\nBefore moving on, notice that we have initiated a convention that will be used throughout\nthe rest of these notes. Whenever a greek index is used, it runs over all spacetime indices.\nWhenever a latin index is used, it runs over only the spatial part. So in (3.9), i runs 1, 2, 3.\nNow that we have an explicit form of the Dirac gamma matrices, we can write out (3.6)\nexplicitly:\n\uf8eb\n\uf8f6\uf8eb \uf8f6\n\uf8eb \uf8f6\n0\n0\n\u22020 \u2212 \u22023 \u2212\u22021 + i\u22022\n\u03c81\n\u03c81\n\uf8ec 0\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n0\n\u2212\u2202\n\u2212\ni\u2202\n\u2202\n+\n\u2202\n\u03c8\n\u03c82 \uf8f7\n1\n2\n0\n3 \uf8f7 \uf8ec 2\uf8f7\n\uf8ec\n\uf8f7\n= \u2212im \uf8ec\n\uf8ed \u22020 + \u22023 \u22021 \u2212 i\u22022\n\uf8f8\n\uf8ed\n\uf8f8\n\uf8ed\n0\n0\n\u03c83\n\u03c83 \uf8f8\n\u22021 + i\u22022 \u22020 \u2212 \u22023\n0\n0\n\u03c84\n\u03c84\nOr, in terms of \u03c8L and \u03c8R ,\ni\u03c3\u0304 \u03bc \u2202\u03bc \u03c8R = +m\u03c8L\ni\u03c3 \u03bc \u2202\u03bc \u03c8L = +m\u03c8R\nwhere we have defined the 4-vectors \u03c3 \u03bc = (\u03c3 0 , \u03c3 1 \u03c3 2 , \u03c3 3 ) and \u03c3\u0304 \u03bc = (\u03c3 0 , \u2212\u03c3 1 , \u2212\u03c3 2 , \u2212\u03c3 3 ).\n\n3.1.5\n\nThe Lorentz Group\n\nThis section is intended to give a deeper understanding of why we were unable to find a\n2 \u00d7 2 matrix representation to solve (3.5).\n71\n\n\fRecall that the driving idea behind the derivation of the Dirac equation (3.6) was to make\nit imply the Klein Gordon equation, or in other words to be a relativistic theory. Put\nanother way, it was to create a theory that was invariant under the Lorentz group SO(1, 3).\nSo, let's take a closer look at the Lorentz group.\nWe know from section 1.1.5 that the Lorentz group consists of 3 rotations and 3 boosts.\nWe gave the general forms of these transformations in equations (1.5) and (1.6). It is\neasy, using those general expressions in addition to (2.7), to find all 6 generators, and\nthen multiply them out to get the commutation relations. We spare the (easy but tedious)\ndetails and simply state the commutation relations. If we label the generators of rotation\nJ i (i = 1, 2, 3), and the generators of boosts K i (i = 1, 2, 3), then the commutation relations\nare\n[J i , J j ] = i\u000fijk J k\n[J i , K j ] = i\u000fijk K k\n[K i , K j ] = \u2212i\u000fijk J k\nIn order to make the actual structure of this group more obvious, we define two new\nlinear combinations of these generators:\n1\nN i = (J i \u2212 iK i )\n2\n\n1\nN i\u2020 = (J i + iK i )\n2\n\nWriting out the commutation relations for N i and N i\u2020 , we get\n[N i , N j ] = i\u000fijk N k\n[N i\u2020 , N j\u2020 ] = i\u000fijk N k\u2020\n[N i , N j\u2020 ] = 0\nSo, both N i and N i\u2020 separately form an SU (2). In more mathematical terms, we say that\nSO(1, 3) is Isomorphic to SU (2) \u2297 SU (2), which we denote SO(1, 3) \u223c\n= SU (2) \u2297 SU (2).\nWhile the idea of an isomorphism is a very rich mathematical idea, for now you can\nsimply think of it as a way of saying that two groups have the same group structure.\nSo, because a given representation of SU (2) is defined by the value of j, we can see that\na particular representation of the Lorentz group SO(1, 3) \u223c\n= SU (2) \u2297 SU (2) is defined\n0\nby two values of j, or by the doublet (j, j ). The smallest possible representation then is\n(j, j 0 ) = (0, 0). This has one state from j = 0 and one state from j 0 = 0, and therefore has\n1 \u00d7 1 = 1 state total. Therefore, this representation describes a scalar field.\nThen, there is the state (0, 1/2), which will have one state from j = 0, but two states from\nj = 1/2, for a total of 1 \u00d7 2 = 2 states. Therefore, this describes a single spin-1/2 field. We\ncall this field \u03c8L , and the (0, 1/2) representation the Left-Handed Spinor Representation\nof the Lorentz group.\n72\n\n\fClearly, we will also have the representation (1/2, 0), which also has 2 states, corresponding to the \u03c8R field. This is called the Right-Handed Spinor Representation of the Lorentz\ngroup. This is the reason for the notation used in (3.7). The left-handed (0, 1/2) representation acts on \u03c8L and the right-handed (1/2, 0) representation acts on \u03c8R .\nNext is the representation (1/2, 1/2), which has two states from j = 1/2 and two from the\nj 0 = 1/2 for a total of 2 \u00d7 2 = 4 states. It turns out that this representation is the spacetime vector representation we use to act on spacetime vectors for the standard Lorentz\ntransformations discussed in section 1.1.5.\nNow, an SU (2) representation specified by some j is an irreducible representation, and\ntherefore the tensor products SU (2)\u2297SU (2) specified by the doublet (j, j 0 ) are irreducible.\nThis means that there are no irreducible subspaces, and so given a representation (j, j 0 ),\nthere is a particular transformation taking the state (j, j 0 ) to (j 0 , j). For the (0, 0) and\n(1/2, 1/2) representations this doesn't affect anything. However, this fact means that the\n(0, 1/2) and (1/2, 0) representations must always appear together. To put this in more\nmathematical language, our choices for representations of the Lorentz group are\n(0, 0),\n\n(1/2, 1/2)\n\nand\n\n(1/2, 0) \u2295 (0, 1/2)\n\nwhich are 1, 4, and 4-dimensional representations, respectively. Furthermore, they are\nthe representations which transform Klein Gordon scalar/spinor-0 fields, spacetime 4vectors, and spin-1/2 spinors, respectively.\nThe physical meaning of this fact is that relativity demands that if you want a theory\nwith spin-1/2 particles, you cannot have them existing by themselves. They must come\nin pairs, each transforming under an SU (2) representation of opposite handedness. In\nthe next two sections we will discuss ways of interpreting this fact, starting with Dirac's\noriginal approach which, while brilliant, didn't ultimately work. Then we will consider\nwhat appears to be the correct view.\n\n3.1.6\n\nThe Dirac Sea Interpretation of Antiparticles\n\nInitially, it may seem that the impossibility of finding a 2 \u00d7 2 matrix solution to (3.5)\nmeans that we can't have fields with 2 spinor states. However, we saw in the last section\nthat we aren't limited to scalars and spacetime 4-component spinors. We can also have\ntwo fields, \u03c8L and \u03c8R , \u0012\nwhich\n\u0013 can be paired together to form two spin-1/2 fields in a 4\u03c8L\ncomponent spinor \u03c8 =\n. So, Dirac was faced with the challenge of both interpreting\n\u03c8R\nthis, while at the same time dealing with the negative energy states mentioned in section\n3.1.2.\nDirac's solution, though today abandoned, was brilliant enough to mention. He suggested that because spin-1/2 particles obey the Pauli Exclusion Principle, there could be\n73\n\n\fan infinite number of particles already in the negative energy levels, and so they are already occupied, preventing any more particles from falling down and giving off infinite\nenergy. Thus, the negative energy problem was solved.\nFurthermore, he said that it is possible for one of the particles in this infinite negative sea\nto be excited and jump up into a positive energy state, leaving behind a hole. This would\nappear to us, experimentally, as a particle with the same mass, but the opposite charge.\nHe called such particles Antiparticles. For example, the antiparticle of the electron is the\nantielectron, or the positron (same mass, opposite charge). The positron is not a particle\nin the same sense as the electron, but rather is a hole in an infinite sea of electrons. And\nwhere this negative charge is missing, all that is left is a hole which appears as a positively\ncharged particle.\nSo, \u03c8L describes a particle, and due to the infinite sea of negative particles, there can\nalways be a hole, which will be described by \u03c8L . Everything about this worked out mathematically, and when antiparticles were detected about 5 years after Dirac's prediction of\nthem, it appeared that Dirac's suggestion was correct.\nHowever, there were two major problems with Dirac's idea, and they ultimately proved\nfatal to the \"Dirac Sea\" interpretation:\n1. This theory, which was supposed to be a theory of single particles, now requires an\ninfinite number of them.\n2. Particles like photons, pions, mesons, or Klein-Gordon scalars don't obey the Pauli\nExclusion Principle, but still have negative energy states, and therefore Dirac's argument doesn't work.\nHowever, his labeling them \"antiparticles\" has stuck, and we therefore still refer to the\nright-handed part of the spin-1/2 field as the antiparticle, whereas the left-handed part is\nstill the particle.\nFor these reasons, we must have some other way of understanding the existence of the\nantiparticles.\n\n3.1.7\n\nThe QFT Interpretation of Antiparticles\n\nIn presenting the problem of negative energy states, we have been somewhat intentionally sloppy. To take stock, we have two equations of motion: the Klein Gordon (3.3) for\nscalar/spin-0 fields, and the Dirac equation (3.6) for spin-1/2 particles.\nAnd in our discussion of negative energy states, we were \"pretending\" that the \u03c8's and\n\u03c6's are \"states\" with negative energy. But, as we said in section 3.1.1, QFT offers a different\ninterpretation of the fields. Namely, the fields are not states - they are operators. And\n74\n\n\fconsequently they can't have energy. A state is made by acting on the vacuum with either\nof the operators \u03c6 or \u03c8, and then the state \u03c6|0i or \u03c8|0i has some energy.\nSo, QFT allows us to see the antiparticle as a real, actual particle, rather than the absence\nof a particle. And, we do not need the conceptually difficult idea of an infinite sea of\nnegative energy particles. The vacuum |0i, with no particles in it, is now our state with\nthe lowest possible energy level. And, as we will see, there are never negative energy\nstates with these particles.\nHow exactly |0i works will become clearer when we quantize. The point to be understood\nfor now is that QFT solves the problem of negative energy by reinterpreting what is a state\nand what is an operator. The fields \u03c6 and \u03c8 are operators, not states, and therefore they\ndo not have energy associated with them (any more than the operator x\u0302 or p\u0302x did in nonrelativistic quantum mechanics). So, without any problems of negative energy, we merely\naccept that nature, due to relativity, demands that particles come in particle/antiparticle\npairs, and we move on.\n\n3.1.8\n\nLagrangians for Scalars and Dirac Particles\n\nNow that we have the equations of motion (3.3) and (3.6), we want to know the actions\nthat lead to these equations of motion. In order to save time, we will merely write down\nthe answers and let you take the variations to see that they do indeed lead to the Klein\nGordon and Dirac equations of motion for \u03c6 and \u03c8.\nThey are\n1\n1\nLKG = \u2212 \u2202 \u03bc \u03c6\u2202\u03bc \u03c6 \u2212 m2 \u03c6\n2\n2\n\u2020 \u03bc\nLD = i\u03c8L \u03c3\u0304 \u2202\u03bc \u03c8L + i\u03c8R\u2020 \u03c3 \u03bc \u2202\u03bc \u03c8R \u2212 m(\u03c8L\u2020 \u03c8R + \u03c8R\u2020 \u03c8L )\n\n(3.10)\n(3.11)\n\nwhere the dagger represents the Hermitian conjugate, \u03c8L\u2020 = (\u03c81? , \u03c82? ), \u03c8R\u2020 = (\u03c83? , \u03c84? ), as\nusual. You can actually take the variation of LD with respect to either \u03c8L\u2020 and \u03c8R\u2020 to get\nthe equations of motion for \u03c8L and \u03c8R , or you can take the variations with respect to\n\u03c8L and \u03c8R to get the equations for \u03c8L\u2020 and \u03c8R\u2020 . The two sets of equations are simply the\nconjugates of each other, and therefore represent a single set of equations.\nIn order to simplify (3.11), the convention is to use the Dirac gamma matrices (3.9) to\ndefine \u03c8\u0304 \u2261 \u03c8 \u2020 \u03b3 0 (where \u03c8 here is the 4-component spinor in equation (3.8)). Using this,\nall 4 terms in (3.11) can be summarized as\nLD = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8\n\n75\n\n(3.12)\n\n\f3.1.9\n\nConserved Currents\n\nIn Part I we discussed how symmetries and conserved quantities are related. Let's consider a few examples of this using the Lagrangians we have now defined.\nConsider a massless Klein Gordon scalar particle, described by L = \u2212 12 \u2202 \u03bc \u03c6\u2202\u03bc \u03c6. Following\nwhat we did starting with equation (1.2), consider the transformation \u03c6 \u2192 \u03c6 + \u000f, where\n\u000f is a constant. Because \u2202 \u03bc \u03c6 \u2192 \u2202 \u03bc \u03c6 + \u2202 \u03bc \u000f = \u2202 \u03bc \u03c6, the Lagrangian is invariant. So (using\n\u03b4\u03c6 = 1), our conserved quantity is\nj\u03bc =\n\n\u2202L\n\u03b4\u03c6 = \u2212\u2202 \u03bc \u03c6\n\u2202(\u2202\u03bc \u03c6)\n\nOr, consider the Klein Gordon Lagrangian with complex scalar fields \u03c6 and \u03c6\u2020 , which\nwe write as L = \u2212\u2202 \u03bc \u03c6\u2020 \u03c6\u03bc \u03c6 \u2212 m2 \u03c6\u2020 \u03c6. We can make the transformation \u03c6 \u2192 ei\u03b1 \u03c6 and\n\u03c6\u2020 \u2192 \u03c6\u2020 e\u2212i\u03b1 (where \u03b1 is an arbitrary real constant). This type of transformation is called a\nU (1) transformation, because ei\u03b1 is an element of the group of all 1 \u00d7 1 unitary matrices,\nas discussed in section 2.2.1.\nThe conserved quantity associated with this U (1) symmetry is\nj\u03bc =\n\n\u2202L\n\u2202L\n\u03b4\u03c6 +\n\u03b4\u03c6\u2020 = i(\u03c6\u2202 \u03bc \u03c6\u2020 \u2212 \u03c6\u2020 \u2202 \u03bc \u03c6)\n\u2202(\u2202\u03bc \u03c6)\n\u2202(\u2202\u03bc \u03c6\u2020 )\n\nOr consider the Dirac Lagrangian. Notice that it is invariant under the U (1) transformation \u03c8 \u2192 ei\u03b1 , with current\nj \u03bc = \u03c8\u0304\u03b3 \u03bc \u03c8\n\n(3.13)\n\nIn both of the previous examples, notice that the U (1) symmetry changes the field at all\npoints in space at once, and all in the same way. In other words, it is a single overall constant phase ei\u03b1 . We therefore call such a symmetry a Global Symmetry. The implications\nof this are likely not clear at this point. We merely wish to call your attention to the fact\nthat ei\u03b1 has no spacetime dependence.\n\n3.1.10\n\nThe Dirac Equation with an Electromagnetic Field\n\nPreviously we found the Lagrangian for an electromagnetic field (1.13). Our goal now is\nto find a Lagrangian that describes the electromagnetic field and a spin-1/2 particle that\ncouples to the electromagnetic field, and additionally the interaction between them. We\nstart by writing down a Lagrangian without any interaction. This will simply be the sum\nof the two terms,\n1\nL = LD + LEM = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8 \u2212 F\u03bc\u03bd F \u03bc\u03bd \u2212 J \u03bc A\u03bc\u03bd\n4\n76\n\n(3.14)\n\n\fBut, because the Dirac part has no terms in common with the electromagnetic part, the\nequations of motion and the conserved quantities for both \u03c8 and A\u03bc will be exactly the\nsame, as if the other weren't present at all. In other words, both fields go about their way\nas if the other weren't there-there is no interaction in this theory. Because this makes for\na boring universe (and horrible phenomenology), we need to find some way of coupling\nthe two fields together to produce some sort of interaction.\nInteraction is added to a physical theory by adding another term to the Lagrangian called\nthe Interaction Term. So, the final Lagrangian will have the form L = LD + LEM + Lint .\nNow, for reasons that will become clear in the next section (and even more clear when\nwe quantize), we do this by coupling the electromagnetic field A\u03bc to the current resulting\nfrom the U (1) symmetry in LD , which we discussed in section 3.1.9, and wrote out in\nequation (3.13). In other words, our interaction term will be proportional to A\u03bc j\u03bc .\nSo, adding a constant of proportionality q (which we will see has the physical interpretation of a coupling constant, weighting the probability of an interaction to take place, or\nequivalently the physical interpretation of electric charge), our Lagrangian is now\n1\nL = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8 \u2212 F\u03bc\u03bd F \u03bc\u03bd \u2212 J \u03bc A\u03bc \u2212 qj \u03bc A\u03bc\n4\n1\n= \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8 \u2212 F\u03bc\u03bd F \u03bc\u03bd \u2212 (J \u03bc + q \u03c8\u0304\u03b3 \u03bc \u03c8)A\u03bc\n4\n\n(3.15)\n\nNotice that L is still invariant under the global U (1) symmetry, and the U (1) current is\nstill J \u03bc = \u03c8\u0304\u03b3 \u03bc \u03c8.\nAlso, notice that the Lagrangians in (3.14) and (3.15) are the same except for a shift in the\n \u0304 represents the charge\ncurrent term, J \u03bc \u2192 J \u03bc + qj \u03bc . Recall that physically, J \u03bc = (\u03c1, J)\nand current creating the field. The fact that J \u03bc has shifted in (3.15) simply means that the\nspin-1/2 particle in this theory contributes to the field, which is exactly what we would\nexpect it to do.\nIf we set q = e, the electric charge, this Lagrangian becomes upon quantization the Lagrangian of Quantum Electrodynamics (QED), which to date makes the most accurate\nexperimental predictions ever.\nIn the next section, we will re-derive this Lagrangian in a more fundamental way.\n\n3.1.11\n\nGauging the Symmetry\n\nPhysically speaking, this section is among the most important in these notes. Read this\nsection again and again until you understand every step.\nConsider once again the Dirac Lagrangian (3.6). As we said in section 3.1.9, it is invariant\nunder the global U (1) transformation \u03c8 \u2192 ei\u03b1 \u03c8. It is global in that it acts on the field the\n77\n\n\fexact same way at every point in spacetime. The idea behind this section is that we are\ngoing to make this symmetry Local, so that \u03b1 depends on spacetime (\u03b1 = \u03b1(x\u03bc )), and then\ntry to force the Lagrangian to maintain its invariance under the local U (1) transformation.\nMaking a global symmetry local is referred to as Gauging the symmetry.\nWe start by making the local U (1) transformation:\nL = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8 \u2192 \u03c8\u0304e\u2212\u03b1(x) (i\u03b3 \u03bc \u2202\u03bc \u2212 m)ei\u03b1(x) \u03c8\nand because the differential operators will now act on \u03b1(x) as well as \u03c8, we get extra\nterms:\nL \u2192 \u03c8\u0304e\u2212\u03b1(x) (i\u03b3 \u03bc \u2202\u03bc \u2212 m)ei\u03b1(x) \u03c8 = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8 \u2212 \u03c8\u0304\u03b3 \u03bc \u03c8\u2202\u03bc \u03b1(x)\n= \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m \u2212 \u03b3 \u03bc \u2202\u03bc \u03b1(x))\u03c8\nIf we want to demand that L still be invariant under this local U (1) transformation, we\nmust find a way of canceling the \u03c8\u0304\u03b3 \u03bc \u03c8\u2202\u03bc \u03b1(x) term. We do this in the following way.\nDefine some arbitrary field A\u03bc which under the U (1) transformation ei\u03b1(x) transforms according to\n1\nA\u03bc \u2192 A\u03bc \u2212 \u2202\u03bc \u03b1(x)\nq\n\n(3.16)\n\nWe call A\u03bc the Gauge Field for reasons that will be clear soon, and q is a constant we have\nincluded for later convenience.\nWe introduce A\u03bc by replacing the standard derivative \u2202\u03bc with the Covariant Derivative\nD\u03bc \u2261 \u2202\u03bc + iqA\u03bc\n\n(3.17)\n\nIf you have studied general relativity or differential geometry at any point, you are familiar with covariant derivatives. There is an incredibly rich geometric picture of all of this,\nbut it is beyond the scope of these notes. We will deal with it later in this series, however.\nAs a comment regarding vocabulary, to say that a particle \"carries charge\" mathematically means that it has the corresponding term in its covariant derivative. So, if a particle's covariant derivative is equal to the normal differential operator \u2202 \u03bc , then the particle\nhas no charge, and it will not interact with anything. But if it carries charge, it will have a\nterm corresponding to that charge in its covariant derivative. This will become clearer as\nwe proceed.\nSo, our Lagrangian is now\nL = \u03c8\u0304(i\u03b3 \u03bc D\u03bc \u2212 m)\u03c8 = \u03c8\u0304(i\u03b3 \u03bc [\u2202\u03bc + iqA\u03bc ] \u2212 m)\u03c8 = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m \u2212 q\u03b3 \u03bc A\u03bc )\u03c8\n\n78\n\n\fAnd under the local U (1) we have\n1\nL \u2192 \u03c8\u0304e\u2212i\u03b1(x) (i\u03b3 \u03bc \u2202\u03bc \u2212 m \u2212 q\u03b3 \u03bc [A\u03bc \u2212 \u2202\u03bc \u03b1(x)])ei\u03b1(x) \u03c8\nq\n\u03bc\n\u03bc\n\u03bc\n= \u03c8\u0304(i\u03b3 \u2202\u03bc \u2212 m \u2212 \u03b3 \u2202\u03bc \u03b1(x) \u2212 q\u03b3 A\u03bc + \u03b3 \u03bc \u2202\u03bc \u03b1(x))\u03c8\n= \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m \u2212 q\u03b3 \u03bc A\u03bc )\u03c8 = \u03c8\u0304(i\u03b3 \u03bc D\u03bc \u2212 m)\u03c8\n= L\nSo, the addition of the field A\u03bc has indeed restored the U (1) symmetry. Notice that now it\nis not only invariant under this local U (1), but also still under the global U (1) we started\nwith, with the same conserved U (1) current j \u03bc = \u03c8\u0304\u03b3 \u03bc \u03c8. This allows us to rewrite the\nLagrangian as\nL = \u03c8\u0304(i\u03b3 \u03bc D\u03bc \u2212 m)\u03c8 = \u03c8\u0304(i\u03b3 \u03bc \u2202\u03bc \u2212 m)\u03c8 \u2212 qj \u03bc A\u03bc\n\n(3.18)\n\nBut we have a problem. If we want to know what the dynamics of A\u03bc will be, we naturally take the variation of the Lagrangian with respect to A\u03bc . But because there are\n\u2202L\nno derivatives of A\u03bc , the Euler-Lagrange equation is merely \u2202A\n= \u2212q \u03c8\u0304\u03b3 \u03bc \u03c8 = 0. But\n\u03bc\n\u2212q \u03c8\u0304\u03b3 \u03bc \u03c8 = \u2212qj \u03bc . So the equation of motion for A\u03bc says that the current vanishes, or that\nj \u03bc = 0, and so the Lagrangian is reduced back to (3.12), which was not invariant under\nthe local U (1).\nWe can state this problem in another way. All physical fields have some sort of dynamics.\nIf they don't then they are merely a constant background field that never changes and\ndoes nothing. As it is written, equation (3.18) has a field A\u03bc but A\u03bc has no kinetic term,\nand therefore no dynamics.\nSo, to fix this problem we must include some sort of dynamics, or kinetic terms, for A\u03bc .\nThe way to do this turns out to involve a considerable amount of geometry which would\nbe out of place in these notes. We will cover the necessary ideas in a later paper in this\nseries and derive the following expressions. For now we merely give the results and ask\nyou for patience until we have the machinery to derive them.\nFor an arbitrary field A\u03bc , the appropriate gauge-invariant kinetic term is\n1\nLKin,A = \u2212 F\u03bc\u03bd F \u03bc\u03bd\n4\nwhere\ni\nF \u03bc\u03bd \u2261 [D\u03bc , D\u03bd ]\nq\n\n(3.19)\n\nand q is the constant of proportionality introduced in the transformation of A\u03bc in equation\n(3.16). D\u03bc is the covariant derivative defined in (3.17).\n79\n\n\fWriting out (3.19) (and using an arbitrary test function f (x)),\nF \u03bc\u03bd f (x) =\n=\n=\n\n=\n\n=\n\ni \u03bc \u03bd\n[D , D ]f (x)\nq\n\u0003\ni\u0002 \u03bc\n(\u2202 + iqA\u03bc )(\u2202 \u03bd + iqA\u03bd ) \u2212 (\u2202 \u03bd + iqA\u03bd )(\u2202 \u03bc + iqA\u03bc f (x)\nq\ni\u0002 \u03bc \u03bd\n\u2202 \u2202 f (x) + iq\u2202 \u03bc (A\u03bd f (x)) + iqA\u03bc \u2202 \u03bd f (x) \u2212 q 2 A\u03bc A\u03bd f (x)\nq\n\u0003\n\u2212\u2202 \u03bd \u2202 \u03bc f (x) + iq\u2202 \u03bd (A\u03bc f (x)) + iqA\u03bd \u2202 \u03bc f (x) \u2212 q 2 A\u03bd A\u03bc f (x)\ni\u0002\niqf (x)\u2202 \u03bc A\u03bd + iqA\u03bd \u2202 \u03bc f (x) + iqA\u03bc \u2202 \u03bd f (x) \u2212 q 2 A\u03bc A\u03bd f (x)\nq\n\u0003\n\u2212iqf (x)\u2202 \u03bd A\u03bc \u2212 iqA\u03bc \u2202 \u03bd f (x) \u2212 iqA\u03bd \u2202 \u03bc f (x) + q 2 A\u03bd A\u03bc f (x)\n\u0002 \u03bc \u03bd\n\u0003\n\u2202 A \u2212 \u2202 \u03bd A\u03bc + iq[A\u03bc , A\u03bd ] f (x)\n\nBut for each value of \u03bc, A\u03bc is a scalar function, so the commutator term vanishes, leaving\n(dropping the test function f (x))\ni\nF \u03bc\u03bd = [D\u03bc , D\u03bd ] = \u2202 \u03bc A\u03bd \u2212 \u2202 \u03bd A\u03bc\nq\n\n(3.20)\n\nSo, writing out the entire Lagrangian we have\n1\nL = \u03c8\u0304(i\u03b3 \u03bc D\u03bc \u2212 m)\u03c8 \u2212 F\u03bc\u03bd F \u03bc\u03bd\n4\nAnd finally, because A\u03bc is obviously a physical field, we can naturally assume that there\nis some source term causing it, which we simply call J \u03bc . This makes our final Lagrangian\n1\nL = \u03c8\u0304(i\u03b3 \u03bc D\u03bc \u2212 m)\u03c8 \u2212 F\u03bc\u03bd F \u03bc\u03bd \u2212 J \u03bc A\u03bc\n4\nComparing this to (3.15) we see that they are exactly the same. So what have we done?\nWe started with nothing but a Lagrangian for a spin-1/2 particle, which had a global U (1)\nsymmetry. Then, all we did was promote the U (1) symmetry to a local symmetry (we\ngauged the symmetry), and then imposed what we had to impose to get a consistent\ntheory. The gauge field A\u03bc was forced upon us, and the form of the kinetic term for A\u03bc is\ndemanded automatically by geometric considerations we did not delve into.\nIn other words, we started with nothing but a non-interacting particle, and by specifying nothing but U (1) we have created a theory with not only that same particle, but also\nelectromagnetism. The A\u03bc field, which upon quantization will be the photon, is a direct\nconsequence of the U (1).\nThis is what we meant at the end of section 2.2.11 when we said that electromagnetism is\ndescribed by U (1). We will talk more about the weak and strong forces later, as well as\nthe groups that give rise to them.\n80\n\n\fTheories of this type, where we generate forces by specifying a Lie group, are called\nGauge Theories, or Yang-Mills Theories.\nFinally, notice that (3.16) has exactly the same form as (1.15). This is why we call A\u03bc a\ngauge field. The gauge symmetry in electromagnetism is a sort of remnant of the much\ndeeper and more fundamental U (1) structure of the theory.\n3.2\n3.2.1\n\nQuantization\nReview of What Quantization Means\n\nIn quantum mechanics (not QFT), quantization is done by taking certain dynamical quantities and making use of the Heisenberg Uncertainty Principle. Normally we take position x\u0304 and momentum p\u0304 and, according to Heisenberg, the measurement of the particle's\nposition will effect its momentum and vice-versa.\nTo make this more precise, we promote x and p from merely being variables to being\nHermitian operators x\u0302 and p\u0302 (which can be represented by matrices) acting on some vector\nspace. Calling a vector in this space |\u03c8i, physically measurable quantities (like position\nor momentum) become the eigenvalues of the operators x\u0302 and p\u0302,\nx\u0302|\u03c8i = x|\u03c8i\np\u0302|\u03c8i = p|\u03c8i\nHeisenberg Uncertainty says that measuring x will affect the value of p, and vice-versa.\nIt is the act of measuring which enacts this effect. It is not an engineering problem in\nthe sense that there is no better measurement technique which would undo this. It is a\nfundamental fact of quantum mechanics (and therefore the universe) that measurement\nof one variable affects another.\nSo, if we measure x (using x\u0302) and then p (using p\u0302), we will in general get different values\nfor both than if we measured p and then x. More mathematically, x\u0302p\u0302 6= p\u0302x\u0302. Put another\nway,\n[x\u0302, p\u0302] \u2261 x\u0302p\u0302 \u2212 p\u0302x\u0302 6= 0\nFor reasons learned in an introductory quantum course, the actual relation is\n[x\u0302, p\u0302] = i~\n\n(3.21)\n\nwhere ~ is Planck's Constant. We call (3.21) the Canonical Commutation Relation, and it\nis this structure which allows us to determine the physical structure of the theory.\nMore generally, we choose some set of operators that all commute with each other, and\nthen label a physical state by its eigenvectors. For example x\u0302, \u0177 and \u1e91 all commute with\n81\n\n\feach other, so we may label a physical state by its eigenvectors |\u03c8r i = |x, y, zi. Or,\nbecause p\u0302x , p\u0302y , and p\u0302z all commute, we may call the state |\u03c8p i = |px , py , pz i. We may\nalso include some other values like spin and angular momentum, to have (for example)\n|\u03c8i = |x, y, z, sz , Lz , . . .i.\nAs discussed in section 3.1.1, when we make the jump to QFT, the fields are no longer the\nstates but the operators. We are therefore going to impose commutation relations on the\nfields, not on the coordinates.\nFurthermore, whereas before the states were eigenvectors of the coordinate operators, we\nnow will expand the fields in terms of the eigenvectors of the Hamiltonian.\n\n3.2.2\n\nCanonical Quantization of Scalar Fields\n\nWe begin with the Klein Gordon Lagrangian in equation (3.10), but we make the slight\nmodification of adding an arbitrary constant \u03a9,\n1\n1\nLKG = \u2212 \u2202 \u03bc \u03c6\u2202\u03bc \u03c6 \u2212 m2 \u03c62 + \u03a9\n2\n2\nNote that \u03a9 has absolutely no affect whatsoever on the physics.\nQuantization then comes about by defining the field momentum and Hamiltonian (using\n(1.7) and (1.8)) to get\n\u03a0 =\n\n\u2202L\n= \u03c6\u0307\n\u2202 \u03c6\u0307(x)\n\n(3.22)\n\n1  \u0304 2 1 2 2\n1\n+ m \u03c6 \u2212\u03a9\nH = \u03a0\u03c6\u0307 \u2212 L = \u03a02 + (\u2207\u03c6)\n2\n2\n2\n\n(3.23)\n\nNow, using the canonical commutation relations (3.21) as guides, we impose\n[\u03c6(t, x\u0304), \u03c6(t0 , x\u03040 )] = 0\n[\u03a0(t, x\u0304), \u03a0(t0 , x\u03040 )] = 0\n[\u03c6(t, x\u0304), \u03a0(t0 , x\u03040 )] = i\u03b4(t \u2212 t0 )\u03b4(x\u0304 \u2212 x\u03040 )\n\n(3.24)\n\n(where we have set ~ = 1).\nWe can see more clearly what this means if we expand the solutions of the Klein Gordon\nequation. One solution is plane waves, eik\u0304*x\u0304 \u00b1 i\u03c9t , where\np\n\u03c9 = + k\u0304 2 + m2\n(3.25)\nand k\u0304 is the standard wave vector.\n82\n\n\fSo, we write the field \u03c6 as\nZ\n\u03c6(t, x\u0304) =\n\n\u0003\nd3 k\u0304 \u0002\na(k\u0304)eik\u0304*x\u0304 \u2212 i\u03c9t + b(k\u0304)eik\u0304*x + i\u03c9t\nf (k\u0304)\n\nwhere f (x) is a redundant function which we have included for later convenience. For\nnow, both a(k\u0304) and b(k\u0304) are merely arbitrary coefficients (integration constants) used to\nexpand \u03c6(t, x\u0304) in terms of individual solutions.\nWe demand that \u03c6(t, x\u0304) be Hermitian. This requires\n\u03c6\u2020 = \u03c6 \u21d2 \u03c6? = \u03c6 \u21d2 b? (k\u0304) = a(\u2212k\u0304)\nThen, changing the sign of the integration variable k\u0304 on the second term in the integral\nallows us to use 4-vector notation, so\nZ 3\n\u0003\nd k\u0304 \u0002\n\u03c6(x) =\na(k\u0304)eik*x + a? (k\u0304)e\u2212ik*x\nf (k\u0304)\nwhere k * x = k \u03bc x\u03bc .\nNow notice that the integration measure, d3 k\u0304, is not invariant under Lorentz transformations (because it integrates over the spatial part but not over the time part). We therefore\nchoose f (k\u0304) to restore Lorentz invariance.\nWe know that the measure d3 k would be invariant, as would \u03b4 functions and \u0398 (step)\nfunctions. So, consider the invariant combination\nd4 k\u03b4(k 2 + m2 )\u0398(k 0 )\n\n(3.26)\n\nThe \u03b4 function merely requires that relativity hold (k 2 + m2 is simply the relativistic relation (3.2), and the \u0398 function preserves causality. So this is a physically acceptable Lorentz\ninvariant integration measure.\nRecall the general \u03b4 function identity,\nZ \u221e\nX\ndx\u03b4(g(x)) =\n\u2212\u221e\n\ni\n\n1\ndg(x)\n|\ndx x=xi\n\nwhere the xi 's are the zeros of the function g(x). We can do the k 0 integral over measure\n(3.26), and using the fact that the zeros of k 2 + m2 = k\u0304 2 \u2212 k 0 k0 + m2 in terms of k 0 are\nk 0 k0 = k\u0304 2 + m2 = \u03c9 2 , we get\nZ\nZ 3\nd k\u0304\n3\n0\n2\n2\n0\nd k\u0304dk \u03b4(k + m )\u0398(k ) =\n2\u03c9\nSo, adding a factor of (2\u03c0)3 for later convenience, we take our invariant measure to be\nd3 k\u0304\n(2\u03c0)3 2\u03c9\n83\n\n\fSo finally,\nZ\n\u03c6(x) =\nf\u2261\nwhere we have defined dk\n\n\u0003\n\u0002\nf a(k\u0304)eik*x + a? (k\u0304)e\u2212ik*x\ndk\n\n(3.27)\n\nd3 k\u0304\n.\n(2\u03c0)3 2\u03c9\n\nThe commutation relations we defined in (3.24) will now hold provided we impose\n[a(k\u0304), a(k\u0304 0 )] = 0\n[a\u2020 (k\u0304), a\u2020 (k\u0304 0 )] = 0\n[a(k\u0304), a\u2020 (k\u0304 0 )] = (2\u03c0)3 2\u03c9\u03b4 3 (k\u0304 \u2212 k\u0304 0 )\n\n(3.28)\n\n(showing this is fairly tedious, but we encourage you to work it out). We are using \u2020\ninstead of ? to emphasize that, in the quantum theory, we are talking about Hermitian\noperators. The operators a(k\u0304) and a\u2020 (k\u0304) are scalars, so in this case a? = a\u2020 .\nFurthermore, we can write the Hamiltonian H in terms of (3.27):\n\u0012\n\u0013\nZ\nZ\n1 2 1  \u0304 2 1 2 2\n3\n3\nH =\nd xH = d x \u03a0 + (\u2207\u03c6) + m \u03c6 \u2212 \u03a9\n2\n2\n2\nZ\n1 f f0 3\n0\n0\n=\ndk dk d x[(\u2212i\u03c9a(k\u0304)eik*x + i\u03c9a? (k\u0304)e\u2212ik*x )(\u2212i\u03c9 0 a(k\u0304 0 )eik\u0304 *x + i\u03c9 0 a? (k\u0304 0 )e\u2212ik *x )\n2\n0\n0\n+(ik\u0304a(k\u0304)eik*x \u2212 ik\u0304a? (k\u0304)e\u2212ik*x ) * (ik\u0304 0 a(k\u0304 0 )eik *x \u2212 ik\u0304 0 a? (k\u0304 0 )e\u2212ik *x )\nZ\n2\nik*x\n?\n\u2212ik*x\n0 ik0 *x\n? 0 \u2212ik0 *x\nm (a(k\u0304)e + a (k\u0304)e\n)(a(k\u0304 )e\n+ a (k\u0304 )e\n)] \u2212 d3 x\u03a9\nZ\n1 f f0 3\n0\n0\n=\ndk dk d x[(\u2212\u03c9\u03c9 0 a(k\u0304)a(k\u0304 0 )ei(k+k )*x + \u03c9\u03c9 0 a(k\u0304)a? (k\u0304 0 )ei(k\u2212k )*x\n2\n0\n0\n+\u03c9\u03c9 0 a? (k\u0304)a(k\u0304 0 )e\u2212i(k\u2212k )* \u2212 \u03c9\u03c9 0 a? (k\u0304)a? (k\u0304 0 )e\u2212i(k+k )*x )\n0\n0\n+(\u2212k\u0304 * k\u0304 0 a(k\u0304)a(k\u0304 0 )ei(k+k )*x + k\u0304 * k\u0304 0 a(k\u0304)a? (k\u0304 0 )ei(k\u2212k )*x\n0\n0\n+k\u0304 * k\u0304 0 a? (k\u0304)a(k\u0304 0 )e\u2212i(k\u2212k )*x \u2212 k\u0304 * k\u0304 0 a? (k\u0304)a? (k\u0304 0 )e\u2212i(k+k )*x )\n0\n0\n+m2 (a(k\u0304)a(k\u0304 0 )ei(k+k )*x + a(k\u0304)a? (k\u0304 0 )ei(k\u2212k )*x\n0\n0\n+a? (k\u0304)a(k\u0304 0 )e\u2212i(k\u2212k )*x + a? (k\u0304)a? (k\u0304 0 )e\u2212i(k+k )*x )\n\u2212V \u03a9\nR\nwhere\nthe volume of the space resulting from the d3 x integral. Then, from the fact\nR V3 isix\u0304*\u0233\nthat d xe\n= (2\u03c0)3 \u03b4 3 (\u0233), we have\nZ\n1\n3\nfdk\nf0 [\u03b4 3 (k\u0304 \u2212 k\u0304 0 )(\u03c9\u03c9 0 + k\u0304 * k\u0304 0 + m2 )(a? (k\u0304)a(k\u0304 0 )e\u2212i(\u03c9\u2212\u03c90 )t + a(k\u0304)a? (k\u0304 0 )e\u2212i(\u03c9\u2212\u03c90 )t )\n(2\u03c0)\ndk\nH =\n2\n0\n0\n+\u03b4 3 (k\u0304 + k\u0304 0 )(\u2212\u03c9\u03c9 0 \u2212 k\u0304 * k\u0304 0 + m2 )(a(k\u0304)a(k\u0304 0 )e\u2212i(\u03c9+\u03c9 )t + a? (k\u0304)a? (k\u0304 0 )ei(\u03c9+\u03c9 )t )\n\u2212V \u03a9\nZ\n1 f 1\n=\ndk [(\u03c9 2 + k\u0304 2 + m2 )(a? (k\u0304)a(k\u0304) + a(k\u0304)a? (k\u0304))\n2\n2\u03c9\n+(\u2212\u03c9 2 + k\u0304 2 + m2 )(a(k\u0304)a(\u2212k\u0304)e\u22122i\u03c9t + a? (k\u0304)a? (\u2212k\u0304)e2i\u03c9t )] \u2212 V \u03a9\n84\n\n\fand finally, using the definition of \u03c9 (equation (3.25)), this becomes\nZ\n1 f\nH=\ndk \u03c9(a? (k\u0304)a(k\u0304) + a(k\u0304)a? (k\u0304)) \u2212 V \u03a9\n2\nAnd now, using (3.28), we can rewrite this as (switching from ? to \u2020 to emphasize the\nHermitian nature)\nZ\n1 f\ndk \u03c9(a\u2020 (k\u0304)a(k\u0304) + a(k\u0304)a\u2020 (k\u0304)) \u2212 V \u03a9\nH =\n2\nZ\n1 f\n=\ndk \u03c9(a\u2020 (k\u0304)a(k\u0304) + (2\u03c0)3 2\u03c9\u03b4 3 (k\u0304 \u2212 k\u0304) + a\u2020 (k\u0304)a(k\u0304)) \u2212 V \u03a9\n2\nZ\nZ\n\u2020\nf \u03c9a (k\u0304)a(k\u0304) + dk\nf \u03c9(2\u03c0)3 \u03b4 3 (0) \u2212 V \u03a9\n=\ndk\nd3 k\u0304\n\u03c9(2\u03c0)3 \u03b4 3 (0) \u2212 V \u03a9\n(2\u03c0)3 2\u03c9\nZ\nZ\n1 3\n\u2020\nf\ndk\u03c9a (k\u0304)a(k\u0304) + \u03b4 (0) d3 k\u0304 \u2212 V \u03a9\n=\n2\nZ\n\n=\n\nZ\n\n\u2020\n\nf\ndk\u03c9a\n(k\u0304)a(k\u0304) +\n\nNotice that both the second and third terms are infinite (assuming the volume V of the\nspace we are in is infinite). This may be troubling, but remember that \u03a9 is an arbitrary\nconstant we can set to be anything we want. So, let's define\nZ\n1 3\n\u03a9\u2261\n\u03b4 (0) d3 k\u0304\n2V\nleaving\nZ\nH=\n\nf \u03c9a\u2020 (k\u0304)a(k\u0304)\ndk\n\n(3.29)\n\nRemember that measurement can only detect changes in energy, and therefore the infinity we subtracted off does not affect the value we will measure experimentally. What\nwe have done here, by subtracting off the infinite part in a way that doesn't change the\nphysics, is a very primitive example of Renormalization. Often, for various reasons,\nmeasurable quantities in QFT are plagued by different types of infinities. However, it is\npossible to subtract off those infinities in a well-defined way, leaving a finite part. It turns\nout that this finite part is the correct value seen in nature. The reasons for this are very\ndeep, and we will not discuss them (or general renormalization theory) in much depth in\nthese notes. For correlating theoretical results with experiment, being able to renormalize\nresults correctly is vital. However, our goal is not to understand the subtleties of renormalization, but to understand the overall structure of particle physics. When you take a\ncourse on QFT you will spend a great, great deal of time on renormalization, and a deeper\nunderstanding of it will emerge.\n85\n\n\fSo, we have our field expansion (3.27) and commutation relations (3.28). Notice that\n(3.28) have the exact form of a simple harmonic oscillator, which you learned about in\nintroductory quantum mechanics. Therefore, because they have the same structure as\nthe harmonic oscillator, they will have the same physics. By doing nothing but imposing\nrelativity, we have found that scalar fields, which are Hermitian operators, act as raising\nand lowering (or synonymously creation and annihilation) operators on the vacuum (just\nlike the simple harmonic oscillator).\nComparing (3.28) with the standard harmonic oscillator operators, it is clear that a\u2020 (k\u0304)\ncreates a \u03c6 particle with momentum k\u0304 and energy \u03c9, whereas a(k\u0304) annihilates a \u03c6 particle\nwith momentum k\u0304 and energy \u03c9. A normalized state will be\n\u221a\n(3.30)\n|k\u0304i = 2\u03c9a\u2020 (k\u0304)|0i\nThe entire spectrum of states can be studied by acting on |0i with creation operators, and\nprobability amplitudes for one state to be found in another, hk\u0304f |k\u0304i i, are straightforward\nto calculate (and positive semi-definite). Naturally this theory does not discuss any interactions between particles, and therefore we will have to do a great deal of modification\nbefore we are done. But this simple exercise of merely imposing the standard commutation relations (3.24) between the field and its momentum, we have gained complete\nknowledge of the quantum mechanical states of the theory.\n\n3.2.3\n\nThe Spin-Statistics Theorem\n\nNotice that the states coming from (3.30) will include the two particle state\n\u221a\n|k\u0304; k\u0304 0 i = 2 \u03c9\u03c9 0 a\u2020 (k\u0304)a\u2020 (k\u0304 0 )|0i\n\n(3.31)\n\nBut the commutation relations (3.28) tell us that a\u2020 (k\u0304)a\u2020 (k\u0304 0 ) = a\u2020 (k\u0304 0 )a\u2020 (k\u0304). So, this theory\nalso allows the state\n\u221a\n|k\u0304 0 ; k\u0304i = 2 \u03c9 0 \u03c9a\u2020 (k\u0304 0 )a\u2020 (k\u0304)|0i\n(3.32)\nRecall from a chemistry or modern physics course that particles with half-integer spin\nobey the Pauli Exclusion Principle, whereas particles of integer spin do not. Our Klein\nGordon scalar fields \u03c6 are spinless (j = 0), and therefore we would expect that they do not\nobey Pauli exclusion. The fact that our commutation relations have allowed both states\n(3.31) and (3.32) is therefore expected. This is an indication that we quantized correctly.\nBut notice that this statistical result (that the scalar fields do not obey Pauli exclusion)\nis entirely a result of the commutation relations. Therefore, if we attempt to quantize a\nspin-1/2 field in the same way, they will obviously not obey Pauli exclusion either. We\nmust therefore quantize spin-1/2 differently.\n\n86\n\n\fIt turns out that the correct way to quantize spin-1/2 fields is to use, instead of commutation relations like we used for for scalar fields, anticommutation relations. If the operators\nof our spin-1/2 fields obey\n{a\u20201 , a\u20202 } = a\u20201 a\u20202 = 0 \u21d2 a\u20201 a\u20202 = \u2212a\u20202 a\u20201\nthen if we try to act twice with the same operator, we have\na\u20201 a\u20201 |0i = \u2212a\u20201 a\u20201 |0i \u21d2 a\u20201 a\u20201 |0i = 0\nIn other words, if we quantize with anticommutation relations, it is not possible for two\nparticles to occupy the same state simultaneously.\nThis relationship between the spin of a particle and the statistics it obeys (which demands\nthat integer spin particles be quantized by commutation relations and half-integer spin\nparticles to be quantized with anticommutation relations) is called the Spin-Statistics\nTheorem.\nAnd, because particles obeying Pauli exclusion are said to have Bose-Einstein statistics,\nand particles that do not obey Pauli exclusion are said to have Fermi-Dirac statistics, we\ncall particles with integer spin Bosons, and particles with half-integer spin Fermions.\n\n3.2.4\n\nLeft-Handed and Right-Handed Fields\n\nRecall that in\n\u0012 the\u0013Dirac Lagrangian (3.12), our fundamental field was the 4-component\n\u03c8L\nwhere \u03c8L transforms under the left-handed (0, 1/2) representation of\nspinor \u03c8 =\n\u03c8R\nthe Lorentz group, and \u03c8R transforms under the right-handed (1/2, 0) representation.\nIn general, we refer to these 2-component spinors as Weyl fields (usually pronounced\n\"vile\"). So, the fermion is the spinor combination of two Weyl fields, one being the lefthanded particle, and the other being the right-handed antiparticle.\nAlso in (3.12) was the field we defined as \u03c8\u0304 = \u03c8 \u2020 \u03b3 0 = (\u03c8R\u2020 , \u03c8L\u2020 ). If we interpret \u03c8\u0304 as the\nconjugate of \u03c8 (which the form of the Dirac Lagrangian implies we should), then we see\nthat the right-handed field is the conjugate of the left, and vice versa. Or, in other words,\n\u03c8L\u2020 = \u03c8R\n\nand\n\n\u03c8R\u2020 = \u03c8L\n\nWe take advantage of the fact by writing all fields in terms of left-handed Weyl fields. For\nexample, given the\n\u0012 two\n\u0013 left-handed Weyl fields \u03c7 and \u03be, we can form the 4-component\n\u03c7\nspinor field \u03c8 =\n, and so \u03c8\u0304 = (\u03be, \u03c7\u2020 ). We will refer to such a field as a Dirac Field,\n\u03be\u2020\nand denote it \u03c8D .\n87\n\n\fOn the other hand, we\n\u0012 could\n\u0013 define a 4-component spinor in terms of a single left-handed\n\u03c7\nWeyl field \u03c7, or \u03c8 =\n. But now notice that \u03c8\u0304 = (\u03c7, \u03c7\u2020 ), which is equal simply to the\n\u03c7\u2020\ntranspose of \u03c8. We refer to such a field (whose conjugate is equal to its transpose) as a\nMajorana Field, and denote it \u03c8M .\nRecall that an antiparticle has the same mass but opposite charge and opposite handedness of its particle. So, working with the Dirac field \u03c8D , we can change the charge by\nmerely swapping \u03c7 and \u03be, using the Charge Conjugation operator C defined by\n\u0012 \u0013 \u0012 \u0013\n\u03c7\n\u03be\nC\u03c8D = C \u2020 =\n\u03be\n\u03c7\u2020\nAlso, consider\n\u0012 the\n\u0013 transpose of \u03c8\u0304D (which is just returning the conjugate of \u03c8D to column\n\u03be\nT\nform), \u03c8\u0304D\n=\n. Acting on this with C gives\n\u03c7\u2020\n\u0012 \u0013 \u0012 \u0013\n\u03be\n\u03c7\nT\nC \u03c8\u0304D = C\n= \u2020 = \u03c8D\n\u2020\n\u03c7\n\u03be\nSo, we have\nT\nC\u03c8D = \u03c8\u0304D\n\nand\n\nT\nC \u03c8\u0304D\n= \u03c8D\n\nT\nWe therefore say that \u03c8D and \u03c8\u0304D\nare Charge Conjugate to each other.\n\nHowever, notice that with the Majorana field,\n\u0012 \u0013 \u0012 \u0013\n\u03c7\n\u03c7\nC\u03c8M = C\n=\n= \u03c8M\n\u2020\n\u03c7\n\u03c7\u2020\nand\nT\nT\nC \u03c8\u0304M\n= \u03c8\u0304M\n= \u03c8M\n\nSo in summary, Dirac fields are not equal to their charge conjugate, while Majorana fields\nare. By analogy with scalars (where the complex conjugate of a real number is equal\nto itself, whereas the complex conjugate of a complex number is not), we often refer to\nMajorana fields as Real, and to Dirac fields as Complex.\nSo, we can now write out the Lagrangian for Dirac and Majorana fields in terms of their\nWeyl fields:\nLD = i\u03c7\u2020 \u03c3\u0304 \u03bc \u2202\u03bc \u03c7 + i\u03be \u2020 \u03c3\u0304 \u03bc \u2202\u03bc \u03be \u2212 m(\u03c7\u03be + \u03c7\u2020 \u03be \u2020 )\n1\nLM = i\u03c7\u2020 \u03c3\u0304 \u03bc \u2202\u03bc \u03c7 \u2212 m(\u03c7\u03c7 + \u03c7\u2020 \u03c7\u2020 )\n2\n88\n\n(3.33)\n(3.34)\n\n\f3.2.5\n\nCanonical Quantization of Fermions\n\nWe first quantize the Dirac fermion. The general solution to the Dirac equation is\n\u03c8D (x) =\n\n2 Z\nX\n\nf s (k\u0304)us (k\u0304)eik*x + d\u2020 (k\u0304)vs (k\u0304)e\u2212ik*x ]\ndk[b\ns\n\ns=1\n\nwhere s =1, 2 are the two spin states, bs and d\u2020s are (respectively) the lowering operator for\nthe particle and the raising operator for the antiparticle. The charge conjugate of \u03c8D will\nhave the raising operator for the particle and the lowering operator for the antiparticle.\nThe us and vs are constant 4-component vectors which act as a basis for all particle/antiparticle states in the spinor space (for our purposes, they are merely present to\nmake \u03c8D a 4-component field).\nWe quantize, as we said in section 3.2.3, using anti-commutation relations. Writing only\nthe non-zero relation,\n{\u03c8\u03b1 (t, x\u0304), \u03c8\u0304\u03b2 (t, x\u0304)} = \u03b4 3 (x\u0304 \u2212 x\u03040 )(\u03b3 0 )\u03b1\u03b2\nThese imply that the only non-zero commutation relations in terms of the operators are\n{bs (k\u0304), b\u2020s0 (k\u0304 0 )} = (2\u03c0)3 \u03b4 3 (k\u0304 \u2212 k\u0304 0 )2\u03c9\u03b4ss0\n{d\u2020s (k\u0304), ds0 (k\u0304 0 )} = (2\u03c0)3 \u03b4 3 (k\u0304 \u2212 k\u0304 0 )2\u03c9\u03b4ss0\nOnce again, these form the algebra of a simple harmonic oscillator, and we can therefore\nfind the entire spectrum of states by acting on |0i with b\u2020s and d\u2020s .\nThen, following a series of calculations nearly identical to the ones in section 3.2.2, we\narrive at the Hamiltonian\nH=\n\n2 Z\nX\n\nf \u03c9[b\u2020 (k\u0304)bs (k\u0304) + d\u2020 (k\u0304)ds (k\u0304)] \u2212 \u03bb\ndk\ns\ns\n\n(3.35)\n\ns=1\n\nwhere \u03bb is an infinite constant we can merely subtract off and therefore ignore.\nComparing (3.29) and (3.35), we see that they both have essentially the same form; \u03c9\n(which is energy) to the left of the creation operator, which is to the left of the annihilation\noperator. To understand the meaning of this, we will see how it generates energy eigenvalues. We will use equation (3.29) for simplicity. Consider acting with the Hamiltonian\n\n89\n\n\foperator on some arbitrary state |p\u0304i with momentum p\u0304. Using (3.30),\nZ\nZ\np\n\u2020\nf\nf k a\u2020 (k\u0304)a(k\u0304) 2\u03c9p a\u2020 (p\u0304)|0i\nH|p\u0304i =\ndk\u03c9k a (k\u0304)a(k\u0304)|p\u0304i = dk\u03c9\nZ\np\n\u0001\nf k 2\u03c9p a\u2020 (k\u0304) (2\u03c0)3 2\u03c9p \u03b4 3 (k\u0304 \u2212 p\u0304) + a\u2020 (p\u0304)a(k\u0304) |0i\ndk\u03c9\n=\nZ\np\nf k 2\u03c9p a\u2020 (k\u0304)(2\u03c0)3 2\u03c9p \u03b4 3 (k\u0304 \u2212 p\u0304)|0i\n=\ndk\u03c9\nZ\np\nd3 k\u0304\n\u03c9k 2\u03c9p a\u2020 (k\u0304)(2\u03c0)3 2\u03c9p \u03b4 3 (k\u0304 \u2212 p\u0304)|0i\n=\n3\n(2\u03c0) 2\u03c9k\nZ\np\n=\nd3 k\u0304 2\u03c9p a\u2020 (k\u0304)\u03c9p \u03b4 3 (k\u0304 \u2212 p\u0304)|0i\np\n= \u03c9p 2\u03c9p a\u2020 |0i = \u03c9p |p\u0304i\nSo, H|p\u0304i = \u03c9p |p\u0304i, where \u03c9p = p\u03042 + m2 , which is the relativistic equation for energy as in\nequation (3.25). So, the Hamiltonian operator gives the appropriate energy eigenvalue on\nour physical quantum states.\nFor the Dirac Hamiltonian the eigenvalue will be a linear combination of the energies of\neach type of particle. If we denote the states as |p\u0304b , sb ; p\u0304d , sd i, where the first two elements\ngive the state of a b type particle and the second of the d type particle, we have\nH|p\u0304b , sb ; p\u0304d , sd i = * * * = (\u03c9pb + \u03c9pd )|p\u0304b , sb ; p\u0304d , sd i\nFor Majorana fields things are simpler. We only have one type of particle, so\n\u03c8M (x) =\n\n2 Z\nX\n\n\u0002\n\u0003\nf bs (k\u0304)us (k\u0304)eik*x + b\u2020 (k\u0304)vs (k\u0304)e\u2212ik*x\ndk\ns\n\ns=1\n\nAnd quantization with anticommutation relations will give\nH=\n\n2 Z\nX\n\nf \u03c9 b\u2020 (k\u0304)bs (k\u0304)\ndk\ns\n\ns=1\n\n3.2.6\n\nInsufficiencies of Canonical Quantization\n\nWhile the Canonical Quantization procedure we have carried out in the past several sections has given us a tremendous amount of information (the entire spectrum of states\nfor bosons, Dirac fermions, and Majorana fermions), it is still lacking quite a bit. As we\nsaid at the beginning of section 3.1.1, we ultimately want a relativistic quantum mechanical theory of interactions. Canonical Quantization has provided a relativistic quantum\nmechanical theory, but we aren't close to being able to incorporate interactions into our\ntheory. While it is possible to incorporate interactions, it is very difficult, and in order to\nsimplify we will need a new way of quantizing.\n90\n\n\f3.2.7\n\nPath Integrals and Path Integral Quantization\n\nPerhaps the most fundamental experiment in quantum mechanics is the Double Slit experiment. In brief, what this experiment tells us is that, when a single electron moves\nthrough a screen with two slits, and no observation is made regarding which slit it goes\nthrough, it actually goes through both slits, and until a measurement is made (for example, when it hits the observation screen behind the double slit), it exists in a superposition\nof both paths. As a result, the particle exhibits a wave nature, and the pattern that emerges\non the observation screen is an interference pattern-the same as if a classical wave was\npassing through the double slit\u2013all paths in the superposition of the single electron are\ninterfering with each other, both destructively and constructively. Once the electron is\nobserved on the observation screen, it collapses probabilistically into one of its possible\nstates (a particular location on the observation screen).\nIf, on the other hand, you set up some mechanism to observe which of the two slits the electron travels through, then the observation has been made before the observation screen,\nand you no longer have the superposition, and therefore you no longer see any indication of an interference pattern. The electrons are behaving, in a sense, classically from the\ndouble slit to the observation screen in this case.\nThe meaning of this is that a particle that has not been observed will actually take every\npossible path at once. Once an observation has been made, there is some probability\nassociated with each path. Some paths are very likely, and others are less likely (some\nare nearly impossible). But until observation, it actually exists in a superposition of all\npossible states/paths.\nSo, to quantize, we will create a mathematical expression for a \"sum over all possible\npaths\". This expression is called a Path Integral, and will prove to be a much more useful\nway to quantize a physical system.\nWe begin this construction by considering merely the amplitude for a particle at position\nq1 at time t1 to propagate to q2 at time t2 . This amplitude will be given by\nhq2 , t2 |q1 , t1 i = hq2 |eiH(t2 \u2212t1 ) |q1 i\nTo evaluate this, we begin by dividing the time interval T \u2261 t2 \u2212 t1 into N + 1 equal intervals of length \u03b4t = NT+1 each. So, we can insert N complete sets of position eigenstates,\nZ\nhq2 , t2 |q1 , t1 i =\n\nN\n\u221e Y\n\ndQi hq2 |e\u2212iH\u03b4t |QN ihQN |e\u2212iH\u03b4t |QN \u22121 i * * * hQ1 |e\u2212iH\u03b4t |q1 i\n\n(3.36)\n\n\u2212\u221e i=1\n\nLet's look at a single one of these amplitudes. We know that in nearly all physical theories,\nP2\n+ V (Q). So, using the completeness of\nwe can break the Hamiltonian up as H = 2m\n\n91\n\n\fmomentum eigenstates,\n\u2212iH\u03b4t\n\nhQi+1 |e\n\n\u2212i\n\n|Qi i = hQi+1 |e\n\nP2\n+V\n2m\n\n\u0001\n\n(Q) \u03b4t\n\n|Qi i\n\nP2\n\u2212i\u03b4t 2m\n\n= hQi+1 |e\ne\u2212i\u03b4tV (Q) |Qi i\nZ\nP2\n=\ndP 0 hQi+1 |e\u2212i\u03b4t 2m |P 0 ihP 0 |e\u2212i\u03b4tV (Q) |Qi i\nZ\nP 02\n=\ndP 0 e\u2212i\u03b4t 2m e\u2212i\u03b4tV (Qi ) hQi+1 |P 0 ihP 0 |Qi i\nZ\niP 0 Qi+1 \u2212iP 0 Qi\n02\ne\n0 \u2212i\u03b4t P2m \u2212i\u03b4tV (Qi ) e\n\u221a\n\u221a\ne\n=\ndP e\n2\u03c0\n2\u03c0\nZ\n0\ndP iH\u03b4t iP 0 (Qi+1 \u2212Qi )\ne\ne\n=\n2\u03c0\nZ\n\u0002\n\u0003\ndP 0 i P 0 (Qi+1 \u2212Qi )\u2212H\u03b4t\n=\ne\n2\u03c0\nZ\n\u0002\n\u0001 \u0003\ndP 0 i\u03b4t P 0 Qi+1\u03b4t\u2212Qi \u2212H\ne\n=\n2\u03c0\nAnd taking the limit as \u03b4t \u2192 0, Qi+1\u03b4t\u2212Qi \u2192 Q\u0307i . So,\nZ\n\u0002\n\u0001 \u0003 Z\ndP 0 i\u03b4t P 0 Qi+1\u03b4t\u2212Qi \u2212H\ndP 0 idti+1 [P 0 Q\u0307i \u2212H]\ne\ne\n=\n2\u03c0\n2\u03c0\nwhere the subscript on dt merely indicates where the infinitesimal time interval \"ends\".\nSo, we can plug this into (3.36) and taking the limit as \u03b4t \u2192 0,\nZ\nhq2 , t2 |q1 , t1 i =\n\nN\n\u221e Y\n\ndQi hq2 |e\u2212iH\u03b4t |QN ihQN |e\u2212iH\u03b4t |QN \u22121 i * * * hQ1 |e\u2212iH\u03b4t |q1 i\n\n\u2212\u221e i=1\n\nZ\n= lim\n\nN \u2192\u221e\n\nZ\n\n\u221e\n\nN\n\u221e Y\n\nZ\ndQi\n\ndPi0 idt2 [PN0 Q\u0307N \u2212H] idtN [PN0 \u22121 Q\u0307N \u22121 \u2212H]\n0\ne\ne\n* * * eidt1 [P1 Q\u03071 \u2212H]\n2\u03c0\n\n\u2212\u221e i=1\nRt\n\u2212i t 2 dt(pq\u0307\u2212H)\n\nDpDq e\n\n1\n\n\u2212\u221e\n\nwhere Dp =\n\nQ\u221e\n\ni=1 dpi and Dq =\n\nQ\u221e\n\ni=1\n\ndqi .\n2\n\np\nAnd if p shows up quadratically (as it always does; 2m\n), then we can merely do the Gaussian integral over p, resulting in an overall constant which we merely absorb back into\nthe measure when we normalize. Then, recognizing that the integrand in the exponent is\npq\u0307 \u2212 H = L, we have\nZ\nZ\nRt\ni t 2 dtL\n1\nhq2 , t2 |q1 , t1 i = Dq e\n= DqeiS\n(3.37)\n\nFormally, the measure of (3.37) has an infinite number of differentials, and therefore evaluating it would require doing an infinite number of integrals. This is to be expected, since\n92\n\n\fthe point of the path integral is a sum over every possible path, of which there are an\ninfinite number. So, because we obviously can't do an infinite number of integrals, we\nwill have to find a clever way of evaluating (3.37). But before doing so, we discuss what\nthe path integral means.\n\n3.2.8\n\nInterpretation of the Path Integral\n\nEquation (3.37) says that, given an initial and final configuration (q1 , t1 ) and (q2 , t2 ), absolutely any path between them is possible. This is the content of the Dq part: it is the sum\nover all paths.\nThen, for each of those paths, the integral assigns a statistical weight of eiS to it, where the\naction S is calculated using that path (recall our comments in section 1.1.1 about S being\na functional, not a function).\nSo, consider an arbitrary path q0 , which receives statistical weight eiS[q0 ] . Now, consider\na path q 0 very close to q0 , only varying by a small amount: q 0 = q0 + \u000f\u03b4q0 . This will have\nstatistical weight eiS[q0 +\u000f\u03b4q0 ] = eiS[q0 ]+i\u000f\u03b4q0\n(1.1)\n\n\u03b4S[q0 ]\n\u03b4q\n\n, where\n\n\u03b4S\n\u03b4q\n\nis the Euler Lagrange derivative\n\n\u03b4S\nd \u2202S \u2202S\n=\n\u2212\n\u03b4q\ndt \u2202 q\u0307\n\u2202q\nTo make our intended\nresultR more obvious, we do a Wick rotation, taking t \u2192 it, so\nR\ndt \u2192 idt, and S = dtL \u2192 i dtL = iS, and eiS \u2192 e\u2212S . Now, the path q 0 = q0 + \u000f\u03b4q0 gets\nweight eiS[q0 ] e\u2212i\u000f\u03b4q0\n\n\u03b4S[q0 ]\n\u03b4q\n\n.\n\nSo, if \u03b4S\nis very large, then the weight becomes exponentially small. In other words, the\n\u03b4q\nlarger the variation of the action is, the less probable that path is.\nSo the most probable path is the one for the smallest value of \u03b4S\n, or the path at which\n\u03b4t\n\u03b4S\n= 0. And as we discussed in 1.1.1, this is the path of Least Action. Thus, we have\n\u03b4q\nrecovered classical mechanics as the first order approximation of quantum mechanics.\nSo, the meaning of the path integral is that all imaginable paths are possible for the particle to travel in moving from one configuration to another. However, not all paths are\nequally probable. The likelihood of a given path is given by the action exponentiated, and\ntherefore the most probable paths are the ones which minimize the action. This is the reason that, macroscopically, the world appears classical. The likelihood of every particle in,\nsay, a baseball, simultaneously taking a path noticeably far from the path of least action\nis negligibly small.\nWe will find that path integral quantization provides an extremely powerful tool with\nwhich to create our relativistic quantum theory of interactions.\n93\n\n\f3.2.9\n\nExpectation Values\n\nNow that we have a way of finding hq2 , t2 |q1 , t1 i, the natural question to ask next is how do\nwe find expectation values like hq2 , t2 |Q(t0 )|q1 , t1 i or hq2 , t2 |P (t0 )|q1 , t1 i. By doing a similar\nderivation as in the last section, it is easy to show that\nZ\n0\nhq2 , t2 |Q(t )|q1 , t1 i = * * * = Dq Q(t0 )eiS\n\nWe will find that evaluating integrals of this form is simplified greatly through making\nuse of Functional Derivatives. For some function f (x), the functional derivative is defined by\n\u03b4\nf (x) \u2261 \u03b4(x \u2212 y)\n\u03b4f (y)\nNext, we modify our path integral by adding an Auxiliary External Source function, so\nthat\nL \u2192 L + f (t)Q(t) + h(t)P (t)\nSo we now have\nZ\nhq2 , t2 |q1 , t1 if,h =\n\nR\n\nDq e\n\ndt(L+f Q+hP )\n\nwhich allows us to write out expectation values in the simple form\nZ\nR\n1 \u03b4\n0\n0 iS+i dt(f Q+hP )\nhq\n,\nt\n|q\n,\nt\ni\nhq2 , t2 |Q(t )|q1 , t1 i =\n=\nDqQ(t\n)e\n2\n2\n1\n1\nf,h\ni \u03b4f (t0 )\nf,h=0\nZ\n=\nDqQ(t0 )eiS\n\nf,h=0\n\nor\n1 \u03b4\nhq2 , t2 |q1 , t1 if,h\nhq2 , t2 |P (t )|q1 , t1 i =\ni \u03b4h(t0 )\nZ\n=\nDqP (t0 )eiS\n\nZ\n\n0\n\n=\nf,h=0\n\nDqP (t0 )eiS+i\n\nR\n\ndt(f Q+hP )\nf,h=0\n\nSo, once we have hq2 , t2 |q1 , t1 i, we can find any expectation value we want simply by\ntaking successive functional derivatives.\n\n94\n\n\f3.2.10\n\nPath Integrals with Fields\n\nBecause we can build whatever state we want by acting on the vacuum, the important\nquantity for us to work with will be the Vacuum to Vacuum expectation value, or VEV,\nh0|0i, and the various expectation values we can build through functional derivatives\n(h0|\u03c6\u03c6|0i, h0|\u03c8\u03c6\u03c6|0i, etc.).\nFor simplicity let's consider a scalar boson \u03c6. The Lagrangian is given in equation (3.10).\nUsing this, we can write the path integral\nZ\n\u0003 Z\n\u0002\nR\nR 4\ni d4 x \u2212 12 \u2202 \u03bc \u03c6\u2202\u03bc \u03c6\u2212 21 m2 \u03c62\n\u2261 D\u03c6ei d xL0\nh0|0i = D\u03c6e\n\nWe will eventually want to find expectation values, so we introduce the auxiliary field J,\ncreating\nZ\nR 4\nh0|0iJ = D\u03c6ei d x(L0 +J\u03c6)\n(3.38)\nSo, for example, h0|\u03c6|0i =\n\n1 \u03b4\nh0|0iJ J=0 .\ni \u03b4J\n\nOf course, we still have a path integral with an infinite number of integrals to evaluate.\nBut, we are finally able to discuss how we can do the evaluation.\nWe define Z0 (J) \u2261 h0|0iJ . Then, making use of the Fourier Transform of \u03c6,\nZ\nZ\nd4 k ikx e\n4\n\u2212ikx\ne\n\u03c6(k) = d x e\n\u03c6(x)\n\u03c6(x) =\ne \u03c6(k)\n(2\u03c0)4\nwe begin with the L0 part:\n\u0012\n\u0013\nZ\nZ\n1 \u03bc\n1 2 2\n4\n4\nS0 =\nd xL0 = d x \u2212 \u2202 \u03c6\u2202\u03bc \u03c6 \u2212 m \u03c6\n2\n2\n\u0012Z\n\u0013 \u0012Z 4 0\n\u0013\n\u0014\nZ\n4\nd k ik0 *x e 0\n1 \u03bc\nd k ik*x e\n4\n=\ndx \u2212 \u2202\ne \u03c6(k) \u2202\u03bc\ne \u03c6(k )\n2\n(2\u03c0)4\n(2\u03c0)4\n\u0012Z\n\u0013\u0012 Z 4 0\n\u0013\n1 2\nd4 k ik*x e\nd k ik0 *x e 0\n\u2212 m\ne \u03c6(k)\ne \u03c6(k )\n2\n(2\u03c0)4\n(2\u03c0)4\n\u0014 Z 4 4 0\n\u0015\nZ\n1\nd kd k ik*x ik0 *x e e 0 \u03bc 0\n2\n4\n=\ndx\ne e \u03c6(k)\u03c6(k )(k k\u03bc \u2212 m )\n2\n(2\u03c0)8\nZ 4 4 0\nZ\n1\nd kd k e e 0 \u03bc 0\n0\n2\n=\n\u03c6(k)\u03c6(k )(k k\u03bc \u2212 m ) d4 xei(k+k )*x\n8\n2\n(2\u03c0)\nZ 4 4 0\n1\nd kd k e e 0 \u03bc 0\n=\n\u03c6(k)\u03c6(k )(k k\u03bc \u2212 m2 )(2\u03c0)4 \u03b4 4 (k + k 0 )\n2\n(2\u03c0)8\nZ\n1\nd4 k e\ne\n= \u2212\n\u03c6(k)(k 2 + m2 )\u03c6(\u2212k)\n2\n(2\u03c0)4\n95\n\n\fThen, transforming the auxiliary field part,\n\u0012Z\n\u0013\u0012 Z 4 0\n\u0013\nZ\nZ\nd4 k ik*x e\nd k ik0 *x e 0\n4\n4\nd xJ(x)\u03c6(x) =\ndx\ne J(k)\ne \u03c6(k )\n(2\u03c0)4\n(2\u03c0)4\nZ 4 4 0\nZ\nd kd k e e 0\n0\n=\nJ(k)\u03c6(k ) d4 xei(k+k )*x\n8\n(2\u03c0)\nZ 4 4 0\nd kd k e e 0\nJ(k)\u03c6(k )(2\u03c0)4 \u03b4 4 (k + k 0 )\n=\n(2\u03c0)8\nZ\nd4 k e e\n=\nJ(k)\u03c6(\u2212k)\n(2\u03c0)4\nAnd because the integral is over all k \u03bc , we can rewrite this as\nZ\nZ\n\u0001\nd4 k e e\nd4 k e e\n1\ne\ne\nJ(k)\n\u03c6(\u2212k)\n=\nJ(k)\n\u03c6(\u2212k)\n+\nJ(\u2212k)\n\u03c6(k)\n(2\u03c0)4\n2\n(2\u03c0)4\n(we did this to get the factor of 1/2 out front in order to have the same coefficient as the\nL0 part from above).\nSo,\n1\nS=\n2\n\nZ\n\n\u0014\n\u0015\nd4 k\n2\n2 e\ne\ne\ne\ne\ne\n\u2212 \u03c6(k)(k + m )\u03c6(\u2212k) + J(k)\u03c6(\u2212k) + J(\u2212k)\u03c6(k)\n(2\u03c0)4\n\nNow, we make a change of variables,\ne \u2212\n\u03c7\ne(k) \u2261 \u03c6(k)\n\ne\nJ(k)\nk 2 + m2\n\n(Note that this leaves the measure of the path integral unchanged: D\u03c6 \u2192 D\u03c7.)\nPlugging this in, we have,\n\u0014\n\u0012\n\u0013\n\u0012\n\u0013\nZ\ne\ne\nd4 k\nJ(k)\nJ(\u2212k)\n1\n2\n2\n\u2212\n\u03c7\ne(k) + 2\n(k + m ) \u03c7\ne(\u2212k) + 2\nS=\n2\n(2\u03c0)4\nk + m2\nk + m2\n\u0013\n\u0012\n\u0013\n\u0012\ne\ne\nJ(k)\nJ(\u2212k)\ne\ne\n+ J(\u2212k) \u03c7\ne(k) + 2\n+ J(k) \u03c7\ne(\u2212k) + 2\nk + m2\nk + m2\n\u0014\n\u0015\nZ\ne J(\u2212k)\ne\n1\nJ(k)\nd4 k\n2\n2\n=\n\u2212\u03c7\ne(k)(k + m )e\n\u03c7(\u2212k) + 2\n2\n(2\u03c0)4\nk + m2\n(The point of all of this is that, in this form, we have all of the \u03c6, or equivalently \u03c7, dependence in the first term, with no \u03c6 or \u03c7 dependence on the second term.)\nFinally, our path integral (3.38) is\nZ\nR\ni\nh0|0iJ = D\u03c7e 2\n\nd4 k\n(2\u03c0)4\n\n\u0002\n\n\u2212e\n\u03c7(k)(k2 +m2 )e\n\u03c7(\u2212k)+\n\n96\n\ne\ne\nJ(k)\nJ(\u2212k)\nk2 +m2\n\n\u0003\n\n\fNow, using some clever physical reasoning, we can see how to evaluate the infinite number of integrals in this expression. Notice that if we set J = 0, we have a free theory in\nwhich no interactions take place. This means that if we start with nothing (the vacuum),\nthe probability of having nothing later is 100%. Or,\n\u0003\nZ\nR d4 k \u0002\ni\n\u2212e\n\u03c7(k)(k2 +m2 )e\n\u03c7(\u2212k)\n4\n2\nh0|0iJ J=0 = 1 = D\u03c7e (2\u03c0)\nAnd if that part is 1, then we have\nZ\nh0|0iJ =\n\ni\n\nD\u03c7e 2\n\nR\n\ne\ne\nJ(\u2212k)\nd4 k J(k)\n(2\u03c0)4 k2 +m2\n\nAnd remarkably, the integrand has no \u03c7 dependence! Therefore, the infinite number of\nintegrals over all possible paths becomes nothing more than a constant we can absorb\ninto the normalization, leaving\ni\n\nh0|0iJ = e 2\n\nR\n\ne\ne\nJ(\u2212k)\nd4 k J(k)\n(2\u03c0)4 k2 +m2\n\nWe can Fourier Transform back to coordinate space to get\ni\n\nZ0 (J) = h0|0iJ = e 2\n\nR\n\nd4 xd4 x0 J(x)\u2206(x\u2212x0 )J(x0 )\n\n(3.39)\n\nwhere\nZ\n\n0\n\n\u2206(x \u2212 x ) \u2261\n\n0\n\nd4 k eik*(x\u2212x )\n(2\u03c0)4 k 2 + m2\n\nis called the Feynman Propagator for the scalar field.\nWe can then find expectation values by operating on this with\n3.2.9.\n\n1 \u03b4\ni \u03b4J\n\nas described in section\n\nWe can repeat everything we have just done for fermions, and while it is a great deal more\ncomplicated (and tedious), it is in essence the same calculation. We begin by adding the\n\u03b4\nauxiliary function \u03b7\u0304\u03c8 + \u03c8\u0304\u03b7, to get expectation values of \u03c8\u0304 and \u03c8 by using 1i \u03b4\u03b7\nand 1i \u03b4\u03b4\u03b7\u0304 ,\nrespectively.\nWe then Fourier Transform every term in the exponent and find that we can separate out\nthe \u03c8\u0304 and \u03c8 dependence, allowing us to set the term which does depend on \u03c8 and \u03c8\u0304 equal\nto 1. Fourier Transforming back then gives\nZ0 (\u03b7, \u03b7\u0304) = ei\n\nR\n\nd4 xd4 x0 \u03b7\u0304(x)S(x\u2212x0 )\u03b7(x0 )\n\n(3.40)\n\nwhere\n0\n\nS(x \u2212 x ) =\n\nZ\n\n0\n\nd4 k (\u2212\u03b3 \u03bc k\u03bc + m)eik*(x\u2212x )\n(2\u03c0)4\nk 2 + m2\n97\n\n\fis the Feynman propagator for fermion fields.\nRecall that we are calling the auxiliary fields J, \u03b7, and \u03b7\u0304 Source Fields. Comparing the\nform of the Lagrangian in equation (3.38) to (1.13) reveals why. J, \u03b7, and \u03b7\u0304 behave mathematically as sources, giving rise to the field they are coupled to, in the same way that the\nelectromagnetic source J \u03bc gives rise to the electromagnetic field A\u03bc . The meaning behind\nequations (3.39) (and (3.40)) is that J (or \u03b7 and \u03b7\u0304) act as sources for the fields, creating a \u03c6\n(or \u03c8 and \u03c8\u0304) at spacetime point x, and absorbing it at point x0 . The terms \u2206(x \u2212 x0 ) and\nS(x \u2212 x0 ) then represent the expression giving the probability amplitude h0|0i for that particular event to occur. In other words, the propagator is the statistical weight of a particle\ngoing from x to x0 .\n\n3.2.11\n\nInteracting Scalar Fields and Feynman Diagrams\n\nWe can now consider how to incorporate interactions into our formalism, allowing us to\nfinally have our relativistic quantum theory of interactions.\nBeginning with the free scalar Lagrangian (3.10), we can add an interaction term L1 . At\nthis point, we only have one type of particle, \u03c6, so we can only have \u03c6's interacting with\nother \u03c6's. Terms proportional to \u03c6 or \u03c62 are either constant or linear in the equations\nof motion, and therefore aren't valid candidates for interaction terms. So, the simplest\nexpression we can have is\nL1 =\n\n1 3\ng\u03c6\n3!\n\nwhere 3!1 is a conventional normalization, and g is a Coupling Constant. So our total\nLagrangian is\n1\n1\n1\nL = L0 + L1 = \u2212 \u2202 \u03bc \u03c6\u2202\u03bc \u03c6 \u2212 m2 \u03c62 + g\u03c63\n2\n2\n6\nand the path integral is\nZ(J) = h0|0iJ\nZ\nR 4\n=\nD\u03c6ei d x[L0 +L1 +J\u03c6]\nZ\nR 4\nR 4\n=\nD\u03c6ei d xL1 ei d x[L0 +J\u03c6]\nZ\nZ\nR\nR 4\ni d4 xL1\n=\nD\u03c6e\nZ0 (J) = D\u03c6ei d xL1 h0|0iJ\nBut, recall that we can bring out a factor of \u03c6 from h0|0iJ using the functional derivative\n1 \u03b4\n. So, we can make the replacement\ni \u03b4J\n\u0012\n\u0013\n\u0012\n\u00133\n1 \u03b4\n1 3\ng 1 \u03b4\nL1 (\u03c6) \u2192 L1\n\u21d2 g\u03c6 \u2192\ni \u03b4J\n6\n6 i \u03b4J\n98\n\n\fAnd notice that once this is done, there is no longer any \u03c6 dependence in Z(J). So, with\nthe free theory, we were able to remove the \u03c6 dependence, leading to (3.39). And here,\nwe were able to remove it from the interaction term as well. So, once again, the infinite\nnumber of integrals in (3.37) will merely give a constant which we can absorb into the\nnormalization.\nThis leaves the result\nZ(J) = e\n\ni\ng\n6\n1\n\nR\n\n= e\u2212 6 g\n\nd4 x\nR\n\nd4 x\n\n1\n\u03b4\ni \u03b4J(x)\n\u03b4\n\u03b4J(x)\n\n\u00013\nZ0 (J)\n\u00013\n\ni\n\ne2\n\nR\n\nd4 xd4 x0 J(x)\u2206(x\u2212x0 )J(x0 )\n\nNow, we can do two separate Taylor expansions to these two exponentials,\n\u0014\n\u0012\n\u00133 \u0015V X\n\u0014 Z\n\u0015P\nZ\n\u221e\n\u221e\nX\n1\ng\n\u03b4\n1 i\n4\n4\n4\nZ(J) =\n\u2212\ndx\n\u00d7\nd yd zJ(y)\u2206(y \u2212 z)J(z)\nV!\n6\n\u03b4J(x)\nP! 2\nV =0\nP =0\n(3.41)\n\u03b4\n, will remove a J term. Furthermore, after\nNow, recall that a functional derivative 1i \u03b4J\ntaking the functional derivatives, we will set J = 0 to get the physical result. So, for a term\nto survive, the 2P sources must all be exactly removed by the 3V functional derivatives.\n\nSo, using (3.41), we can expand in orders of g (the coupling constant), keeping only the\nterms which survive, and after removing the sources, evaluate the integrals over the propagators \u2206. The value of the integral will then be the physical amplitude for a particular\nevent.\nIn practice, a slightly different formalism is used to organize and keep track of each term\nin this expansion. Note that there will be P propagators \u2206. We can represent each of these\nterms diagrammatically, by making each source a solid dot, each propagator a line, and\nlet the g terms be vertices joining the lines together. There will be a total of V vertices,\neach joining 3 lines (matching the fact that we are looking at \u03c63 theory; there would be 4\nlines at each vertex for \u03c64 theory, etc.).\nFor example, for V = 0 and P = 1,\nZ\ni\nZ(J) =\nd4 yd4 zJ(y)\u2206(y \u2212 z)J(z)\n2\nWe have two sources, one located at z and the other located at y, so we draw two dots,\ncorresponding to those locations. Then, the propagator \u2206(y \u2212 z) connects them together,\nso we draw a line between the two dots. The diagram should look like this:\n\n99\n\n\fOf course, once we set J = 0, this will vanish because it contains two sources.\nAs another example, consider V = 0 and P = 2. Now,\n\u0012 \u00132 Z\n\u0001\n\u0001\n1 i\nZ(J) =\nd4 yd4 zd4 y 0 d4 z 0 J(y)\u2206(y \u2212 z)J(z) J(y 0 )\u2206(y 0 \u2212 z 0 )J(z 0 )\n2! 2\nThis corresponds to four sources, located at y, z, y 0 and z 0 , with propagator lines connecting y to z, and connecting y 0 to z 0 . But, there are no lines connecting an unprimed source\nto a primed source, so this results in two disconnected diagrams:\n\nAs another example, consider V = 1 and P = 2,\n\u0012\n\u00133\nZ\n\u03b4\ng\n4\ndx\nZ(J) = \u2212\n6\n\u03b4J(x)\n\u0012 \u00132 Z\n\u0001\n\u0001\n1 i\n\u00d7\nd4 yd4 zd4 y 0 d4 z 0 J(y)\u2206(y \u2212 z)J(z) J(y 0 )\u2206(y 0 \u2212 z 0 )J(z 0 )\n2! 2\nZ\ng\nd4 xd4 yd4 zd4 y 0 d4 z 0 \u03b4(y \u2212 x)\u2206(y \u2212 z)\u03b4(z \u2212 x)\u03b4(y 0 \u2212 x)\u2206(y 0 \u2212 z 0 )J(z 0 )\n=\n48\nZ\ng\n=\nd4 xd4 z 0 \u2206(x \u2212 x)\u2206(x \u2212 z 0 )J(z 0 )\n48\nThis will correspond to\n\nwhere the source J is located at the dot, and the vertex joining the line to the loop is at x.\nYou can work out the following out, and see that there are multiple possible diagrams for\nV = 3, P = 5\n100\n\n\fAnd for V = 2, P = 4,\n\nAnd for V = 1, P = 3,\n\nand so on.\nThrough a series of combinatoric and physical arguments, it can be shown that only connected diagrams will contribute, and the P1! and V1! terms will always cancel exactly.\nSo, to calculate the amplitude for a particular interaction to happen (say N \u03c6's in and M\n\u03c6's out), draw every connected diagram that is topologically distinct, and has the correct\nnumber of in and out particles. Then, through a set of rules which you will learn formally\nin a QFT course, you can reconstruct the integrals which we started with in (3.41).\nWhen you take a course on QFT, you will spend a tremendous amount of time learning\nhow to evaluate these integrals for low order (they cannot be evaluated past about second\norder in most cases). While this is extremely important, it is not vital for the agenda of\nthese notes, and we therefore do not discuss how they are evaluated.\nThe idea is that each diagram represents one of the possible paths the particle can take,\nalong with the possible interactions it can be a part of. Because this is a quantum mechanical theory, we know it is actually in a superposition of all possible paths and interactions.\n101\n\n\fWe don't make a measurement or observation until the particles leave the area in which\nthey collide, so we have no idea about what is going on inside the accelerator. We know\nthat if this goes in and this comes out, we can draw a particular set of diagrams which\nhave the correct input and output, and the nature of the interaction terms (which determines what types of vertices you can have) tells us what types of interactions we can\nhave inside the accelerator. Evaluating the integrals then tells us how much that particular event/diagram contributes towards the total probability amplitude. So, if you want\nto know how likely a certain incoming/outgoing set of particles is, write down all the\ndiagrams, evaluate the corresponding integrals, and add them up.\nAnd as we pointed out above, the classical behavior (which is more probable) is closer\nto the first order approximation of the quantum behavior. Therefore, even though in\ngeneral we can't evaluate the integrals past about second order, the first few orders tell us\nto a reasonable (in fact, exceptional in most cases) degree of accuracy what the amplitude\nis. If we want more accuracy, we can seek to evaluate higher orders, but usually lower\norders suffice for experiments at energy levels we can currently attain.\nOne of the difficulties encountered with evaluating these integrals is that you almost always find that they yield infinite amplitudes. Since an amplitude (which is a probability)\nshould be between 0 and 1, this is obviously unacceptable. The process of finding the\ninfinite parts and separating them from the finite parts of the amplitude is a very well\ndefined mathematical construct called Renormalization. The basic idea is that any infinite term consists of a pure infinity and a finite part. For example (trust us for now) the\ninfinite sum:\n\u221e\nX\nn=1\n\n1\n1\n\u2212\n2\nx\u21920 x\n12\n\nn = lim\n\nThere is a part which is a pure infinity (the first term on the right hand side), and a term\nwhich is finite. While this may seem strange and extremely unfamiliar (and a bit like\nhand waving), it is actually a very rigorous and very well understood mathematical idea.\nMuch of what particle physicists attempt to do is find theories (and types of theories) that\ncan be renormalized and theories that cannot. For example, the action which leads to\nGeneral Relativity leads to a quantum theory which cannot be renormalized. Renormalization is a fascinating and deep topic, and will be covered in great depth in any standard\nQFT text or course. Unfortunately, we will not discuss it further.\n\n3.2.12\n\nInteracting Fermion Fields\n\nThe analysis we performed above for scalar fields \u03c6 above is almost identical for fermions,\nand we therefore won't repeat it. The main difference is that the interaction terms will\nhave a field \u03c8 interacting with \u03c8\u0304, and so the vertices will be slightly different. We won't\nbother with those details.\n102\n\n\fFinally, we can have a Lagrangian with both scalars and fermions. Then, naturally, you\ncould have interaction terms where the scalars interact with fermions. While there are\ncountless interaction terms of this type, the one that will be the most interesting to us is\nthe Yukawa term,\nLY uk = g\u03c6\u03c8\u0304\u03c8\n\n(3.42)\n\nIf we represent \u03c6 by a dotted line, \u03c8 by a line with an arrow in the forward time direction,\nand \u03c8\u0304 with an arrow going backwards in time, this interaction term will show up in a\nFeynman diagram as\n\nOnce each diagram is drawn, there are well defined rules to write down an integral corresponding to each diagram.\n3.3\n\nFinal Ingredients\n\nThe purpose of the previous section was merely to introduce the idea of Feynman Diagrams as a tool to calculate amplitudes for physical processes. In doing so, we have met\nthe goal set out in section 3.1.1, a relativistic quantum mechanical theory of interactions.\nWe achieve such a theory by finding a Lagrangian of a classical theory (both with and\nwithout interaction terms), and using equation (3.41) (and the analogous equation for\nfermions) to write down integrals which, when evaluated, give a contribution to a total\namplitude. It is important to remember that we will eventually set all sources J to zero,\nand a functional derivative (as contained in the interaction term L1 ) will set any term\nwithout J's to zero. So, the only non-zero terms will be the ones where all of the J's are\nexactly removed by the functional derivatives.\nA large portion of understanding QFT is learning how to set these integrals up in greater\ndetail, and learning several methods to evaluate them. We will not delve into those details\nof Perturbative Quantum Field Theory, where amplitudes are studied order by order,\nhere. The goal of these notes is merely to explain how, once given a Lagrangian, that\nLagrangian can be turned into a physically measurable quantity.\n103\n\n\fWith this done, we now set out to find the Lagrangian for the Standard Model of Particle\nPhysics, the theory which seems to explain our universe (apart from gravity). Once this\nLagrangian has been explained, we trust you have a general concept of what to do with\nit from the previous sections.\nHowever, before we are able to explain the Standard Model Lagrangian, there are a few\nfinal concepts we need. They will be the subject of this section. Namely, we will be studying the ideas of Spontaneous Symmetry Breaking and Gauge Theories. In section 3.1.11,\nwe discussed the simple U (1) gauge theory, where we made a global U (1) symmetry of\nthe free Dirac Lagrangian a local U (1) symmetry, or a gauged symmetry, and showed that\nconsistency demanded the introduction of a gauge field A\u03bc , and consequently a kinetic\nterm and a source term. Thus we recovered the entire electromagnetic force from nothing\nbut U (1). Later in this section, we generalize this to arbitrary Lie group. Because U (1)\nis an Abelian group, we refer to the gauge theory of section 3.1.11 as an abelian gauge\ntheory. For a more general, non-Abelian group, we refer to the theory resulting as a\nNon-Abelian Gauge Theory. Such theories introduce a great deal of complexity, and we\ntherefore consider them in detail in this section before moving on to the Standard Model.\nHowever, we begin with the idea of spontaneous symmetry breaking.\n\n3.3.1\n\nSpontaneous Symmetry Breaking\n\nConsider a complex scalar boson \u03c6 and \u03c6\u2020 . The Lagrangian will be\n1\n1\nL = \u2212 \u2202 \u03bc \u03c6\u2020 \u2202\u03bc \u03c6 \u2212 m2 \u03c6\u2020 \u03c6\n2\n2\nNaturally we can write this as\n1\nL = \u2212 \u2202 \u03bc \u03c6\u2020 \u2202\u03bc \u03c6 \u2212 V (\u03c6\u2020 , \u03c6)\n2\nwhere\n1\nV (\u03c6\u2020 , \u03c6) = m2 \u03c6\u2020 \u03c6\n2\nThis Lagrangian has the U (1) symmetry we discussed in 3.1.11.\nAlso, notice that we can graph V (\u03c6\u2020 , \u03c6), plotting V vs. |\u03c6|,\n\n104\n\n(3.43)\n\n\fWe see a \"bowl\" with Vminimum at |\u03c6|2 = 0. The vacuum of any theory ends up being at the\nlowest potential point, and therefore the vacuum of this theory is at \u03c6 = 0, as we would\nexpect.\nNow, let's change the potential. Consider\n1\nV (\u03c6\u2020 , \u03c6) = \u03bbm2 (\u03c6\u2020 \u03c6 \u2212 \u03a62 )2\n2\n\n(3.44)\n\nwhere \u03bb and \u03a6 are real constants. Notice that the Lagrangian will still have the global\nU (1) symmetry from before. But, now if we graph V vs. |\u03c6|, we get\n\nwhere now the vacuum Vminimum is represented by the circle at |\u03c6| = \u03a6. In other words,\nthere are an infinite number of vacuums in this theory. And because the circle drawn\nin the figure above represents a rotation through field space, this degenerate vacuum is\nparameterized by ei\u03b1 , the global U (1). There will be a vacuum for every value of \u03b1, located\nat |\u03c6| = \u03a6.\nIn order to make sense of this theory, we must choose a vacuum by hand. Because the\ntheory is completely invariant under the choice of the U (1) ei\u03b1 , we can choose any \u03b1 and\n105\n\n\fdefine that as our true vacuum. So, we choose \u03b1 to make our vacuum at \u03c6 = \u03a6, or where\n\u03c6 is real and equal to \u03a6. We have thus, in a sense, Gauged Fixed the symmetry in the\nLagrangian, and the U (1) symmetry is no longer manifest.\nNow we need to rewrite this theory in terms of our new vacuum. We therefore expand\naround the constant vacuum value \u03a6 to have the new field\n\u03c6 \u2261 \u03a6 + \u03b1 + i\u03b2\nwhere \u03b1 and \u03b2 are new real scalar fields (so \u03c6\u2020 = \u03a6 + \u03b1 \u2212 i\u03b2). We can now write out the\nLagrangian as\n1\n1\nL = \u2212 \u2202 \u03bc [\u03b1 \u2212 i\u03b2]\u2202\u03bc [\u03b1 + i\u03b2] \u2212 \u03bbm2 [(\u03a6 + \u03b1 \u2212 i\u03b2)(\u03a6 + \u03b1 + i\u03b2) \u2212 \u03a62 ]2\n2\n\u0015\n\u00142\n\u0014\n\u0015\n1 \u03bc\n1\n1 \u03bc\n1\n3\n2\n4\n2 2\n4\n2 2 2\n2\n=\n\u2212 \u2202 \u03b1\u2202\u03bc \u03b1 \u2212 4\u03bbm \u03a6 \u03b1 \u2212 \u2202 \u03b2\u2202\u03bc \u03b2 \u2212 \u03bbm 4\u03a6\u03b1 + 4\u03a6\u03b1\u03b2 + \u03b1 + \u03b1 \u03b2 + \u03b2\n2\n2\n2\n2\n(3.45)\n\u221a\nThis is now a theory of a massive real scalar field \u03b1 (with mass = 4\u03bbm2 \u03a62 ), a massless real\nscalar field \u03b2, and five different types of interactions (one allowing three \u03b1's to interact,\nthe second allowing one \u03b1 and two \u03b2's, the third allowing four \u03b1's, the fourth allowing\ntwo \u03b1's and two \u03b2's, and the last allowing four \u03b2's.) In other words, there are five different\ntypes of vertices allowed in the Feynman diagrams for this theory.\nFurthermore, notice that this theory has no obvious U (1) symmetry. For this reason, writing the field in terms of fluctuations around the vacuum we choose is called \"breaking\"\nthe symmetry. The symmetry is still there, but it can't be seen in this form.\nFinally, notice that breaking the symmetry has resulted in the addition of the massless\nfield \u03b2. It turns out that breaking global symmetries as we have done always results in a\nmassless boson. Such particles are called Goldstone Bosons.\n\n3.3.2\n\nBreaking Local Symmetries\n\nIn the previous section, we broke a global U (1) symmetry. In this section, we will break\na local U (1) and see what happens. We begin with the Lagrangian for a complex scalar\nfield with a gauged U (1):\nL=\u2212\n\n\u0001 \u0003\u0002\n\u0001 \u0003 1\n1\u0002 \u03bc\n\u2202 \u2212 iqA\u03bc \u03c6\u2020 \u2202\u03bc + iqA\u03bc \u03c6 \u2212 F\u03bc\u03bd F \u03bc\u03bd \u2212 V (\u03c6\u2020 , \u03c6)\n2\n4\n\nwhere we have taken the external source J \u03bc = 0. Let's once again assume V (\u03c6\u2020 , \u03c6) has the\nform of equation (3.44), so the vacuum has the U (1) degeneracy at |\u03c6| = \u03a6.\nBecause our U (1) is now local, we choose \u03b1(x) so that not only is the vacuum real, but\nalso so that \u03c6 is always real. We therefore expand\n\u03c6=\u03a6+h\n106\n\n(3.46)\n\n\fwhere h is a real scalar field representing fluctuations around the vacuum we chose.\nNow,\n\u0001\n\u0001\u0003\u0002\n\u0001\n\u0003 1\n1\u0002 \u03bc\n\u2202\u03bc + iqA\u03bc \u03a6 + h) \u2212 F\u03bc\u03bd F \u03bc\u03bd\n\u2202 \u2212 iqA\u03bc \u03a6 + h\n2\n4\n\u0003\n\u0002\n\u0001\n\u0001\n1\n2 2\n2\n\u2212 \u03bbm \u03a6 + h \u03a6 + h \u2212 \u03a6\n2\n= ***\n1\n1\n1\n1\n= \u2212 \u2202 \u03bc h\u2202\u03bc h \u2212 4\u03bbm2 \u03a62 h2 \u2212 F \u03bc\u03bd F\u03bc\u03bd \u2212 q 2 \u03a62 A2 + Linteractions\n2\n2\n4\n2\n\nL = \u2212\n\nwhere the allowed interaction terms include a vertex connecting an h and two A\u03bc 's, four\nh's, and three h's.\nSo, before breaking, we had a complex scalar field \u03c6 and a massless vector field A\u03bc with\ntwo polarization\nstates (because it is a photon). Now, we have a single real scalar h with\n\u221a\n2\nmass = 4\u03bbm \u03a62 and a field A\u03bc with mass = q\u03a6. In other words, our force-carrying\nparticle A\u03bc has gained mass! We started with a theory with no mass, and by merely\nbreaking the symmetry, we have introduced mass into our theory.\nThis mechanism for introducing mass into a theory, called the Higgs Mechanism, was\nfirst discovered by Peter Higgs, and the resulting field h is called the Higgs Boson.\nSo, whereas the consequence of global symmetry breaking is a massless boson called a\nGoldstone boson, the consequence of a local symmetry breaking is that the gauge field,\nwhich came about as a result of the symmetry being local, acquires mass.\n\n3.3.3\n\nNon-Abelian Gauge Theory\n\nWe are now ready to generalize what we did in section 3.1.11 to an arbitrary Lie group.\nConsider a Lagrangian L with N scalar (or spinor) fields \u03c6i (i = 1, . . . , N ) that is invariant\nunder a continuous SO(N ) or SU (N ) symmetry, \u03c6i \u2192 Uij \u03c6j , where Uij is an N \u00d7 N matrix\nof SO(N ) or SU (N ).\nIn section 3.1.11, we saw that if the group is U (1), gauging it demands the introduction of\nthe gauge field A\u03bc to preserve the symmetry, which shows up in the covariant derivative\nD\u03bc = \u2202\u03bc \u2212 ieA\u03bc . To say a field carried some sort of charge means that it has the corresponding term in its covariant derivative. We then added a kinetic term for A\u03bc as well as\nan external source J \u03bc . Then, higher order interaction terms can be included in whatever\nway is appropriate for the theory.\nTo generalize this, let's say for the sake of concreteness that our Lie group is SU (N ). An\na\na\narbitrary element of SU (N ) is eig\u03b8 (x)T , where g is a constant we have added for later\nconvenience, \u03b8a are the N 2 \u2212 1 parameters of the group (cf. section 2.2.15), and the T a are\n107\n\n\fthe generator matrices for the group. Notice that we have gauged the symmetry (in that\n\u03b8(x) is a function of spacetime).\nBy definition, we know that the generators T a will obey the commutation relations\n[T a , T b ] = ifabc T c\n(cf equation (2.9)), where fabc are the structure constants of the group.\nWhen gauging the U (1) in section 3.1.11, the transformation of the gauge field was given\nby equation (3.16). For the more general transformation \u03c6i \u2192 Uij \u03c6j , the gauge field transforms according to\ni\nA\u03bc \u2192 U (x)A\u03bc U \u2020 (x) + U (x)\u2202 \u03bc U \u2020 (x)\ng\n(where we have removed the indicial notation and it is understood that matrix multiplication is being discussed). If U (x) is an element of U (1) (so it is eig\u03b8(x) ), then this transformation reduces to\ni\nA\u03bc \u2192 eig\u03b8(x) A\u03bc e\u2212ig\u03b8(x) + eig\u03b8(x) (\u2212ig\u2202 \u03bc \u03b8(x))e\u2212ig\u03b8(x) = A\u03bc + \u2202 \u03bc \u03b8(x)\ng\nwhich is exactly what we had in (1.15). For general SU (N ), however, the U 's are elements\nof a Non-Abelian group, and the A\u03bc 's are matrices of the same size.\nGeneralizing, we find that a general element of the SU (N ) is (changing notation slightly)\nU (x)e\u2212ig\u0393\n\na (x)T a\n\nwith N 2 \u2212 1 real parameters \u0393a . We then build the covariant derivative in the exact same\nway as in equation (3.17) by adding a term proportional to the gauge field\nD\u03bc = IN \u00d7N \u2202\u03bc \u2212 igA\u03bc\n(Remember that each component of A\u03bc is an N \u00d7 N matrix. They were scalars for U (1)\nbecause U (1) is a 1 \u00d7 1 matrix.) Or, acting on the fields, the covariant derivative is\n(D\u03bc \u03c6)j = \u2202\u03bc \u03c6j (x) \u2212 ig[A\u03bc (x)]jk \u03c6k (x)\n\n(3.47)\n\nwhere k is understood to be summed on the last term. It will be understood from now\non that the normal partial derivative term (the first term) has an N \u00d7 N identity matrix\nmultiplied by it.\nThen, just as in (3.19), we have the field strength\ni\nF\u03bc\u03bd (x) \u2261 [D\u03bc , D\u03bd ] = \u2202\u03bc A\u03bd \u2212 \u2202\u03bd A\u03bc \u2212 ig[A\u03bc , A\u03bd ]\ng\n\n(3.48)\n\nwhere the commutator term doesn't vanish for arbitrary Lie group as it did for Abelian\nU (1).\n108\n\n\fRecall from equation (1.16) that for U (1), F\u03bc\u03bd is invariant under the gauge transformation (1.15) on its own, because the commutator term vanishes. In general, however, the\ncommutator term does not vanish, and we must therefore be careful in writing down the\ncorrect kinetic term. It turns out that the correct choice is\n1\nLKin = \u2212 Tr (F\u03bc\u03bd F \u03bc\u03bd )\n2\n\n(3.49)\n\nIt may not be obvious, but this form is actually a consequence of (2.28). There is algebraic\nmachinery working under the surface of this that, while extremely interesting, is unfortunately beyond the scope of what we are doing. We will discuss all of these ideas in much\ngreater depth later in this series.\nSo, starting with a non-interacting Lagrangian that is invariant under the global SU (N ),\nwe can gauge the SU (N ) to create a theory with a gauge field (or synonymously a \"force\ncarrying\" field) A\u03bc , which is an N \u00d7N matrix. So, every Lie group gives rise to a particular\ngauge field (which is a force carrying particle, like the photon), and therefore a particular\nforce.\nFor this reason, we discuss forces in terms of Lie groups, or synonymously Gauge\nGroups. Each group defines a force. As we said at the very end of section 2.2.11, U (1) represents the electromagnetic force (as we have seen in section 3.1.11, while SU (2) describes\nthe weak force, and SU (3) describes the strong color force.\n\n3.3.4\n\nRepresentations of Gauge Groups\n\nAs we discussed in section 2.2, given a set of structure constants fabc , which define the\nLie algebra of some Lie group, we can form a representation of that group, which we\ndenote R. So, R will be a set of D(R) \u00d7 D(R) matrices, where D is the dimension of the\nrepresentation R. We then call the generators of the group (in the representation R) TRa ,\nand they naturally obey [TRa , TRb ] = ifabc TRc .\nOne representation which exists for any of the groups we have considered is the representation of SO(N ) or SU (N ) consisting of N \u00d7 N matrices. We denote this the Fundamental\nRepresentation (also called Defining Representation in some books). Clearly, the fundamental representations of SO(2), SO(3), SU (2), and SU (3) are the 2 \u00d7 2, 3 \u00d7 3, 2 \u00d7 2, and\n3 \u00d7 3 matrix representations, respectively. We will denote the fundamental representation\nfor a given group by writing the number in bold. So, the fundamental representation of\nSU (2) will be denoted 2, and the generators for SU (2) in the fundamental representation\nwill be denoted T2a . Obviously, the fundamental representation of SU (3) will be 3 with\ngenerators T3a .\nFurthermore, let's say we have some arbitrary representation generated by TRa , obeying\n[TRa , TRb ] = ifabc TRc . We can take the complex conjugate of the commutation relations to get\n[TR?a , TR?b ] = \u2212ifabc TR?c . So, notice that if we define the new set of generators TR0a \u2261 \u2212TR?a ,\n109\n\n\fthen the TR0a will obey the correct commutation relations, and will therefore form a representation of the group as well. If it turns out that TR0a = \u2212(TRa )? = TRa , or if there is\nsome unitary similarity transformation TRa \u2192 U \u22121 TRa U such that TR0a = \u2212(TRa )? = TRa , then\nwe call the representation Real, and the complex conjugate of the TRa 's is the same representation. However, if no such transformation exists, then we have a new representation,\ncalled the Complex Conjugate representation to R, or the Anti-R representation, which\nwe denote R\u0304.\nFor example, there is the fundamental representation of SU (3), denoted 3, generated by\nT3a , and then there is the anti-fundamental representation 3\u0304, generated by T3\u0304a .\nThe representations of a group which will be important to us are the fundamental, antifundamental, and adjoint.\n\n3.3.5\n\nSymmetry Breaking Revisited\n\nAs we said in section 3.3.3, given a field transforming in a particular representation R, the\ngauge fields A\u03bc will be D(R) \u00d7 D(R) matrices.\nOnce we know what representation we are working in, and therefore know the generators\nTRa , it turns out that it is always possible to write the gauge fields in terms of the generators. Recall in sections 2.2.2 and 2.2.12, we encouraged you to think of the generators as\nbasis vectors which span the parameter space for the group. Because the gauge fields live\nin the N \u00d7 N space as well, we can write them in terms of the generators. That is, instead\nof the gauge fields being N \u00d7 N matrices on their own, we will use the N \u00d7 N matrix\ngenerators as basis vectors, and then the gauge fields can be written as scalar coefficients\nof each generator:\nA\u03bc = A\u03bca TRa\n\n(3.50)\n\nwhere a is understood to be summed, and each A\u03bca is now a scalar function rather than a\nD(R) \u00d7 D(R) matrix (the advantage of this is that we can continue to think of the gauge\nfields as scalars with an extra index, rather than as matrices). As a note, we haven't\ndone anything particularly profound here. We are merely writing each component of the\nD(R) \u00d7 D(R) matrix A\u03bc in terms of the D(R) \u00d7 D(R) generators, allowing us to work\nwith a scalar field A\u03bca rather than the matrix field A\u03bc . We now actually view each A\u03bca as a\nseparate field. So, if a group has N generators, we say there are N gauge fields associated\nwith it, each one having 4 spacetime components \u03bc.\nIn matrix components, we will have\n(A\u03bc )ij = (A\u03bca TRa )ij\nThen, the covariant derivative in (3.47) will be\n(D\u03bc \u03c6)j = \u2202\u03bc \u03c6j (x) \u2212 ig[A\u03bca (x)TRa ]jk \u03c6k (x)\n110\n\n(3.51)\n\n\fWe may assume that the field strength F \u03bc\u03bd can also be expressed in terms of the generators, so that we have\nF \u03bc\u03bd = Fa\u03bc\u03bd T a\n\n(3.52)\n\n(F \u03bc\u03bd )ij = (Fa\u03bc\u03bd T a )ij\n\n(3.53)\n\nor\n\nNow, using (2.28) (and taking \u03ba = 1/2 by convention), we can write (3.49) in terms of the\nnew basis:\n1\n1\nLKin = \u2212 Tr (F\u03bc\u03bd F \u03bc\u03bd ) = \u2212 Tr (Fa\u03bc\u03bd T a F\u03bc\u03bdb T b )\n2\n2\n1\n= \u2212 Fa\u03bc\u03bd F\u03bc\u03bdb T r(T a T b )\n2\n1\n= \u2212 Fa\u03bc\u03bd F\u03bc\u03bdb \u03ba\u03b4 ab\n2\n1\na\n= \u2212 Fa\u03bc\u03bd F\u03bc\u03bd\n\u03ba\n2\n1\na\n= \u2212 Fa\u03bc\u03bd F\u03bc\u03bd\n4\n\n(3.54)\n\n(we have raised the index a on the second field strength term in the last two lines simply\nto explicitly imply the summation over it. The fact that it is raised doesn't change its value\nin this case; it is merely notational).\nFurthermore, we can use (2.28) to invert (3.52):\nF \u03bc\u03bd = Fa\u03bc\u03bd T a \u21d2 F \u03bc\u03bd T b = Fa\u03bc\u03bd T a T b\n\u21d2 Tr (F \u03bc\u03bd T b ) = Fa\u03bc\u03bd Tr (T a T b )\n\u21d2 Tr (F \u03bc\u03bd T b ) = Fa\u03bc\u03bd \u03ba\u03b4 ab\n1\n\u21d2 Tr (F \u03bc\u03bd T b ) = Fb\u03bc\u03bd\n2\n\u21d2 Fa\u03bc\u03bd = 2 Tr (F \u03bc\u03bd T a )\n\n(3.55)\n\nIn sections 3.3.1 and 3.3.2, we broke the U (1) symmetry, which only had one generator.\nHowever, if we break larger groups we may only break part of it. For example, we will\nsee that SU (3) has an SU (2) subgroup. It is actually possible to break only the SU (2) part\nof the SU (3). So, three of the SU (3) generators are broken (the three corresponding to\nthe SU (2) subgroup/subalgebra), and the other five are unbroken. Because we are now\nwriting our gauge fields using the generators as a basis, this means that three of the gauge\nfields are broken, while five of the gauge fields are not.\nFinally, recall from section 3.3.2 that breaking a local symmetry results in a gauge field\ngaining mass. We seek now to elucidate the relationship between breaking a symmetry\n111\n\n\fand a field gaining mass. First, we can summarize as follows: Gauge fields corresponding\nto broken generators get mass, while those corresponding to unbroken generators do not. The\nunbroken generators form a new gauge group that is smaller than the original group that was\nbroken.\nIn 3.3.2, we saw that breaking a symmetry gave the gauge field mass. Now, we see that\ngiving a gauge field mass will break the symmetry.\nTo make this clearer, we begin with a very simple example, then move on to a more\ncomplicated example.\n\n3.3.6\n\nSimple Examples of Symmetry Breaking\n\nConsider a theory with three real massless scalar fields \u03c6i (i = 1, 2, 3) and with Lagrangian\n1\nL = \u2212 \u2202 \u03bc \u03c6i \u2202\u03bc \u03c6i\n2\nwhich is clearly invariant under the global SO(3) rotation\n\u03c6i \u2192 Rij \u03c6j\nwhere Rij is an element of SO(3), because the Lagrangian is merely a dot product in field\nspace, and we know that dot products are invariant under SO(3).\nNow, let's say that one of the fields, say \u03c61 , gains mass. The new Lagrangian will then be\n1\n1\nL = \u2212 \u2202 \u03bc \u03c6i \u2202\u03bc \u03c6i \u2212 m2 \u03c621\n2\n2\nSo this Lagrangian is no longer invariant under the full SO(3) group, which mixes any\ntwo of the three fields. Rather, it is only invariant under rotations in field space that mix\n\u03c62 and \u03c63 or SO(2). In other words, giving one field mass broke SO(3) to the smaller\nSO(2).\nAs another simple example, if we started with five massless complex scalar fields \u03c6i , with\nLagrangian\n1\nL = \u2212 \u2202 \u03bc \u03c6\u2020i \u2202\u03bc \u03c6i\n2\nThis will be invariant under any SU (5) transformation.\nThen let's say we give two of the fields, \u03c61 and \u03c62 (equal) mass. The new Lagrangian will\nbe\n1\n1\nL = \u2212 \u2202 \u03bc \u03c6\u2020i \u2202\u03bc \u03c6i \u2212 m(\u03c6\u20201 \u03c61 + \u03c6\u20202 \u03c62 )\n2\n2\n112\n\n\fSo now, we no longer have the full SU (5) symmetry, but we do have the special unitary\ntransformations mixing \u03c63 , \u03c64 , and \u03c65 . This is an SU (3) subgroup. Furthermore, we can\ndo a special unitary transformation mixing \u03c61 and \u03c62 . This is an SU (2) subgroup. So, we\nhave broken SU (5) \u2192 SU (3) \u2297 SU (2).\nBefore considering a more complicated example of this, we further discuss the connection\nbetween symmetry breaking and fields gaining mass.\nWhen we introduced spontaneous symmetry breaking in section 3.3.1, recall that we\nshifted the potential minimum from Vminimum at \u03c6 = 0 to Vminimum at |\u03c6| = \u03a6. But we\nwere discussing this in very classical language. We can interpret all of this in a more\n\"quantum\" way in terms of VEV's. As we said, the vacuum of a theory is defined as the\nminimum potential field configuration. For the Vminimum at \u03c6 = 0 potential, the VEV of\nthe field \u03c6 was at 0, or\nh0|\u03c6|0i = 0\nHowever, for the Vminimum at |\u03c6| = \u03a6 potential, we have\nh0|\u03c6|0i = \u03a6\nSo, in quantum mechanical language, symmetry breaking occurs when a field, or some\ncomponents of a field, take on a non-zero VEV.\nThis seems to be what is happening in nature. At higher energies, there is some \"Master Theory\" with some gauge group defining the physics, and all of the fields involved\nhave 0 VEV's. At lower energies, for whatever reason (the reason for this is not well understood at the time of this writing), some of the fields take on non-zero VEV's, which\nbreak the symmetry into smaller groups, giving mass to certain fields through the Higgs\nMechanism discussed in section 3.3.2. We call the theory with the unbroken gauge symmetry at higher energies the more fundamental theory (analogous to equation (3.43)), and\nthe Lagrangian which results from breaking the symmetry (analogous to (3.45)) the Low\nEnergy Effective Theory.\nAnd this is how mass is introduced into the Standard Model. It turns out that if a theory\nis renormalizable one can prove that any lower energy effective theory that results from\nbreaking the original theory's symmetry is also renormalizable, even if it doesn't appear\nto be. And, because the actions that appear to describe the universe at the energy level\nwe live at (and the levels attainable by current experiment) are not renormalizable when\nthey have mass terms, we work with a larger theory which has no massive particles but\ncan be renormalized, and use the Higgs Mechanism to give various particles mass. So,\nwhereas the physics we see at low energies may not appear renormalizable, if we can find\na renormalizable theory which breaks down to our physics, we are safe.\nNow, we consider a slightly more complicated (and realistic) example of symmetry breaking.\n113\n\n\f3.3.7\n\nA More Complicated Example of Symmetry Breaking\n\nConsider the gauge group SU (N ), acting on N complex scalar fields \u03c6i (i = 1, . . . , N ) in\nthe fundamental representation N. Recall that in section 3.3.2, in order to get equation\n(3.46), we made use of the U (1) symmetry to make the vacuum, or the VEV, real. We can\nnow do something similar: we make use of the SU (N ) to not only make the VEV real, but\nalso to rotate it to a single component of the field, \u03c6N . In other words, we do an SU (N )\nrotation so that\nh0|\u03c6i |0i = 0\nh0|\u03c6N |0i = \u03a6\n\nfor\n\ni = 1, . . . , N \u2212 1\n\nSo, we expand \u03c6N around this new vacuum:\n\u03c6i = \u03c6i\nfor\n\u03c6N = \u03a6 + \u03c7\n\ni = 1, . . . , N \u2212 1\n\nThis means that, in the vacuum configuration, the fields will have the form\n\uf8eb \uf8f6\n\uf8eb \uf8f6\n\u03c61\n0\n\uf8ec \u03c62 \uf8f7\n\uf8ec0\uf8f7\n\uf8ec \uf8f7\n\uf8ec \uf8f7\n= \uf8ec .. \uf8f7\n\uf8ec .. \uf8f7\n\uf8ed . \uf8f8\n\uf8ed.\uf8f8\n\u03c6N vacuum\n\u03a6\nSo, how will the action of SU (N ) be affected by this VEV? If we consider a general element\nof SU (N ) acting on this,\n\uf8f6\uf8eb \uf8f6 \uf8eb\n\uf8f6\n\uf8eb\nU11 U12 * * * U1N\n0\nU1N\n\uf8ec U21 U22 * * * U2N \uf8f7 \uf8ec 0 \uf8f7 \uf8ec U2N \uf8f7\n\uf8f7\n\uf8f7\uf8ec \uf8f7 \uf8ec\n\uf8ec .\n..\n=\n..\n\uf8f7\n\uf8ec\n\uf8ec\n\uf8f7\n\uf8ec .\n.\n.\n. * * * \uf8f8 \uf8ed .. \uf8f8 \uf8ed .. \uf8f7\n.\n\uf8f8\n\uf8ed .\n..\n\u03a6\nUN N\nUN 1 UN 2 . UN N\nSo, only elements of SU (N ) with non-zero elements in the last column will be affected by\nthis VEV. But the other N \u2212 1 elements' rows and columns are unaffected. This means\nthat we have an SU (N \u2212 1) symmetry left. Or in other words, we have broken SU (N ) \u2192\nSU (N \u2212 1) with this VEV.\nLet's consider a specific example of this. Consider SU (3). The generators are written out\nin (2.46). Notice that exactly three of them have all zeros in the last column; \u03bb1 , \u03bb2 , and\n\u03bb3 . We expect these three to give an SU (3 \u2212 1) = SU (2) subgroup. And looking at the\nupper left 2\u00d72 boxes in those three generators, we can see that they are the Pauli matrices,\nthe generators of SU (2). So, if we give a non-zero VEV to the fields transforming under\nSU (3), we see that they do indeed break the SU (3) to SU (2). The other five generators of\nSU (3) will be affected by the VEV, and consequently the corresponding fields will acquire\nmass.\n114\n\n\f3.4\n3.4.1\n\nParticle Physics\nIntroduction to the Standard Model\n\nWe are finally ready to study the Standard Model of Particle Physics, which (except for\ngravity) appears to be the theory which explains our universe. To state the Standard\nModel in the simplest possible terms, it is\n\nA Yang-Mills (Gauge) Theory with Gauge Group\nSU (3) \u2297 SU (2) \u2297 U (1)\nwith left-handed Weyl fields fields in three copies of the representation\n(1, 2, \u22121/2) \u2295 (1, 1, 1) \u2295 (3, 2, 1/6) \u2295 (3\u0304, 1, \u22122, 3) \u2295 (3\u0304, 1, 1/3)\n(where the last entry specifies the value of the U (1) hypercharge),\nand a single copy of a complex scalar field in the representation\n(1, 2, \u22121/2)\n\nAdmittedly, our exposition will be somewhat cursory. This is largely because every concept and tool we use in this section has been discussed in detail in the previous sections.\nThe purpose of these notes is to provide an introduction to the primary concepts and\nmathematical tools used in Particle Physics, not to give the details of the theory. We will\ncover the main points of the Standard Model, but there is tremendous detail we are skipping over. A second reason the following section is cursory is that we will not be working\nout every step in detail, as we have been doing. For nearly all calculations being done in\nthis section, we have worked out a similar tedious calculation previously. We will therefore frequently refer to previous sections/equations. It will be worthwhile to go back and\ncarefully study the parts which we refer to.\nBecause this section is slightly more experimental, or at least phenomenological, than the\nrest, and because the general purpose of these notes is to develop the mathematical tools\nand framework of particle physics (especially gauge theory), undue attention should not\nbe given to this section. The purpose is merely to show, as briefly as possible, where\neverything we have done so far lines up with experiment. It will be useful to read through\nthis section, but do not spend too much time bogged down in the details.\nBefore diving into this in detail, look over the general structure of the Standard Model on\npage 139.\n115\n\n\f3.4.2\n\nThe Gauge and Higgs Sector\n\nWe begin our exposition with the Electroweak part of the Standard Model gauge group,\nthe SU (2) \u2297 U (1) part, as well as the Higgs.\nBeginning with the Higgs, a scalar field in the (2, \u22121/2) representation of SU (2)\u2297U (1), the\nfirst step is to write down the covariant derivative as in (3.51). We denote the generators\na\n(the Pauli matrices) and the gauge fields\nof the 2 representation of SU (2) as T2a \u0012= 21 \u03c3\u0013\n1 0\nas Aa\u03bc . The generator of U (1) is Y = C\nwhere C is the hypercharge (\u22121/2 in this\n0 1\ncase), and the U (1) gauge field is B\u03bc . So, the covariant derivative is\n(D\u03bc \u03c6)i = \u2202\u03bc \u03c6i \u2212 i[g2 Aa\u03bc T2a + g1 B\u03bc Y ]ij \u03c6j\n\n(3.56)\n\nwhere g1 and g2 are coupling constants for the U (1) part and the SU (2) part, respectively.\nIf the reason we wrote it down this way isn't clear, compare this expression to equation\n(3.51), and remember that we are saying the field carries two charges; one for SU (2) and\none for U (1). Therefore, it has two terms in its covariant derivative. And, as usual, \u03bc is a\nspacetime index.\nKnowing that the generators of SU (2) are the Pauli matrices, we can expand the second\npart of the covariant derivative in matrix form,\ng2 Aa\u03bc T2a + g1 B\u03bc Y\n\ng2 1 1\ng1\n(A\u03bc \u03c3 + A2\u03bc \u03c3 2 + A3\u03bc \u03c3 3 ) \u2212 B\u03bc I2\u00d72\n2\u0012\n2 \u0013\n1\n3\n1 g2 A\u03bc \u2212 g1 B\u03bc g2 (A\u03bc \u2212 iA2\u03bc )\n=\n2 g2 (A1\u03bc + iA2\u03bc ) \u2212g2 A3\u03bc \u2212 g1 B\u03bc\n=\n\nSo, the full covariant derivative is\n\u0012\n\u0013 \u0012\n\u0013\n\u2202\u03bc \u03c61 + 2i (g2 A3\u03bc \u2212 g1 B\u03bc )\u03c61 + ig22 (A1\u03bc \u2212 iA2\u03bc )\u03c62\nD\u03bc \u03c61\n(D\u03bc \u03c6)i =\n \u0307\n=\nD\u03bc \u03c62\n\u2202\u03bc \u03c62 + ig22 (A1\u03bc + iA2\u03bc )\u03c61 \u2212 2i (g2 A3\u03bc + g1 B\u03bc )\u03c62\n\n(3.57)\n\nNow, we know that the Lagrangian will have the kinetic term and some potential:\n1\nL = \u2212 D\u03bc \u03c6\u2020i D\u03bc \u03c6i \u2212 V (\u03c6\u2020 , \u03c6)\n2\n\n(3.58)\n\nLet's assume that the potential has a similar form as equation (3.44) (we add the factors\nof one-half here for the sake of convention; they don't amount to anything other than a\nrescaling of \u03bb and \u03a6),\n\u00132\n\u0012\n1\n1 2\n\u2020\n\u2020\nV (\u03c6 , \u03c6) = \u03bb \u03c6 \u03c6 \u2212 \u03a6\n(3.59)\n4\n2\nClearly the minimum field configuration is not at \u03c6 = 0, but at |\u03c6| = \u221av2 . So, following\nwhat we did in section 3.3.7, we make a global SU (2) transformation to put the entire\n116\n\n\fVEV on the first component of \u03c6, and then make a global U (1) transformation to make the\nfield real. So,\n\u0012 \u0013\n1 v\n(3.60)\nh0|\u03c6|0i = \u221a\n2 0\nand we expand \u03c6 around this new vacuum:\n\u0012\n\u0013\n1 v + h(x)\n\u03c6(x) = \u221a\n0\n2\n\n(3.61)\n\nRemember that we have chosen our SU (2) to keep the second component 0 and our U (1)\nto keep the first component real. So, h(x) is a real scalar field.\nClearly, plugging this into the covariant derivative (3.57) will give the exact same expression as before, but with \u03c61 replaced by \u221a12 h(x) and \u03c62 replaced by 0, plus an extra term\nfor v. When we plug this extra term into the kinetic term in the Lagrangian (3.58), we get\nthat it is\n\u0013\u0012\n\u0013\u0012 \u0013\n\u0012\n\u0001 g2 A3\u03bc \u2212 g1 B\u03bc g2 (A1\u03bc \u2212 iA2\u03bc\n1 2\ng2 A3\u03bc \u2212 g1 B \u03bc g2 (A1\u03bc \u2212 iA2\u03bc )\n1\n\u2212 v 1 0\n1\u03bc\n2\u03bc\n3\u03bc\n\u03bc\n3\n2\n1\ng2 (A + iA ) \u2212g2 A \u2212 g1 B\n0\ng2 (A\u03bc + iA\u03bc \u2212g2 A\u03bc \u2212 g1 B\u03bc\n8\n(3.62)\nBefore multiplying this out, we employ a trick. Define the Weak Mixing Angle\n\u0012 \u0013\ng1\n\u22121\n\u03b8w \u2261 tan\ng2\nand the shorthand notation\nsw \u2261 sin \u03b8w\n\nand\n\ncw \u2261 cos \u03b8w\n\nAnd finally, we can define four new gauge fields as linear combinations of the four we\nhave been using:\n1\nW\u03bc+ \u2261 \u221a (A1\u03bc \u2212 iA2\u03bc )\n2\n1\nW\u03bc\u2212 \u2261 \u221a (A1\u03bc + iA2\u03bc )\n2\nZ\u03bc \u2261 cw A3\u03bc \u2212 sw B\u03bc\nA\u03bc \u2261 sw A3\u03bc + cw B\u03bc\n\n(3.63)\n(3.64)\n(3.65)\n(3.66)\n\nThese can easily be inverted to give the old fields in terms of the new fields,\n1\nA1\u03bc = \u221a (W\u03bc+ + W\u03bc\u2212 )\n2\ni\nA2\u03bc = \u221a (W\u03bc+ \u2212 W\u03bc\u2212 )\n2\n3\nA\u03bc = cw Z\u03bc + sw A\u03bc\nB\u03bc = \u2212sw Z\u03bc + cw A\u03bc\n117\n\n(3.67)\n(3.68)\n(3.69)\n(3.70)\n\n\fWe make a few observations about these fields before moving on. First of all, they are\nmerely linear combinations of the gauge fields introduced in equation (3.56). Second,\nnotice that the two fields W\u03bc\u00b1 are both linear combinations of fields corresponding to nonCartan generators of SU (2), whereas Z\u03bc and A\u03bc are both linear combinations of fields\ncorresponding to Cartan generators of SU (2) and U (1). So, according to our discussion in\nsection 2.2.16, we expect that Z\u03bc and A\u03bc will interact but not change the charge, and that\nW\u03bc\u00b1 will interact and change the charge. Incidentally, notice that W\u03bc\u00b1 has the exact form\nof the raising and lowering operators defined in (2.18).\nWith these fields defined, we can now rewrite (3.62) as\n\u221a\n\u0012\n\u00132 \u0012 \u0013\n\u0001 c1 Z\u03bc\n1\n1 2 2\n2W\u03bc+\n1\n2\n\u221a\n= \u2212Mw2 W +\u03bc W\u03bc\u2212 \u2212 MZ2 Z \u03bc Z\u03bc\n\u2212 g2 v 1 0\n\u2212\n0\n8\n2\n2W\u03bc\n?\n(the ? is there because that matrix element will always be multiplied by 0, so we don't\nbother writing it), where we have defined\ng2 v\nMw\ng2 v\nand\nMZ =\n=\n2\ncw\n2cw\nSo, we see that, by symmetry breaking, we have given mass to the W\u03bc+ , the W\u03bc\u2212 , and the\nZ\u03bc fields. However, the A\u03bc has not gained mass.\nMw =\n\nThese particles are the W and Z vector bosons, which are the force carrying particles of\nthe Weak Force. Each of these particles has an extremely large mass (MW \u2248 80.4 GeV,\nand MZ \u2248 91.2 GeV), which explains why they only act over a very short range (\u2248 10\u221218\nmeters).\nAlso note that the A\u03bc remains massless, implying that it did not acquire a VEV, and because it is a single generator, we see that a single U (1) remains unbroken. This U (1) and\nA\u03bc are the gauge group and field of Electromagnetism, as discussed in section 3.1.11.\nThe idea of all of this is that at very high energies (above the breaking of the SU (2)\u2297U (1)),\nwe have only a Higgs complex scalar field, along with four identical massless vector\nboson gauge fields (A1\u03bc , A2\u03bc , A3\u03bc , B\u03bc ), each of which behave basically like a photon. At\nlow energies, however, the SU (2) \u2297 U (1) symmetry of the Higgs is broken, and the low\nenergy effective theory consists of a linear combination of the original four fields. Three\nof those linear combinations have gained mass, and one remains massless, retaining the\nphoton-like properties from before symmetry breaking. The theory above the symmetry\nbreaking scale is called the Electroweak Theory (with four photon-like force carrying\nparticles), whereas below the breaking scale they become two separate forces; the Weak\nand the Electromagnetic. This is the first and most basic example of unification we have\nin our universe. At low energies, the electromagnetic and weak forces are separate. At\nhigh energies, they unify into a single theory that is described by SU (2) \u2297 U (1).\nWe can express the new fields as simple Euler rotations of the old fields:\n\u0012 \u0013 \u0012 3\n\u0013\n\u0012 \u0013\n\u0012 3\u0013\nA\u03bc cos \u03b8w \u2212 B\u03bc sin \u03b8w\nA\u03bc\nZ\u03bc\nZ\u03bc\n=\n\u21d2\n= R(\u03b8w )\n3\nA\u03bc\nA\u03bc sin \u03b8w + B\u03bc cos \u03b8w\nA\u03bc\nB\u03bc\n118\n\n\fSo, the Z\u03bc is a massive linear combination of the A3\u03bc and B\u03bc , while the photon A\u03bc is a\nmassless linear combination of the two.\nWe can do the same type of analysis for the W\u03bc\u00b1 , where they are both massive linear\ncombinations of A1\u03bc and A2\u03bc . The Z\u03bc and A\u03bc are both made up of a mixture of the SU (2)\nand U (1) gauge groups, whereas the W\u03bc\u00b1 come solely from the SU (2) part.\nBefore moving on to include leptons (and then hadrons), we first write out the full Lagrangian for the effective field theory for h(x) and the gauge fields.\nWe start with the complete Lagrangian term for h(x). We have written the original field \u03c6\nas in equation (3.61). So, our potential in equation (3.59) is now\n1\n1\n1\n1\n1\nV (\u03c6\u2020 , \u03c6) = \u03bb(\u03c6\u2020 \u03c6 \u2212 v 2 )2 = * * * = \u03bbv 2 h2 + \u03bbvh3 + \u03bbh4\n4\n2\n4\n4\n16\nTheq\nfirst term on the right hand side is clearly a mass term giving the mass of the Higgs\n(=\n\n\u03bb\nv),\n2\n\nand the second two terms are interaction vertices. The kinetic term for the\n\nHiggs will be the usual \u2212 12 \u2202\u03bc h\u2202 \u03bc h.\nNow, following loosely what we did in section 3.1.11, we want to find kinetic terms for\nthe gauge fields. We start by finding them for the original gauge fields before symmetry\nbreaking (A1\u03bc , A2\u03bc , A3\u03bc and B\u03bc ). Using (3.55), (3.48), and (3.50), and the SU (2) structure\nconstants given in equation (2.17), we have\n1\nF\u03bc\u03bd\n= 2 Tr (F\u03bc\u03bd T 1 )\n\n= 2 Tr (\u2202\u03bc A\u03bd \u2212 \u2202\u03bd A\u03bc \u2212 ig2 [A\u03bc , A\u03bd ])T 1\n\n\u0001\n\n= 2 Tr (\u2202\u03bc Aa\u03bd T a \u2212 \u2202\u03bd Aa\u03bc T a \u2212 ig2 Aa\u03bc Ab\u03bd [T a , T b ])T 1\n\n\u0001\n\n= 2 Tr (\u2202\u03bc Aa\u03bd T a T 1 \u2212 \u2202\u03bd Aa\u03bc T a T 1 \u2212 ig2 Aa\u03bc Ab\u03bd if abd T c T 1 )\n= \u2202\u03bc Aa\u03bd \u03b4 a1 \u2212 \u2202\u03bd Aa\u03bc \u03b4 a1 + g2 Aa\u03bc Ab\u03bd f abc \u03b4 c1\n= \u2202\u03bc A1\u03bd \u2212 \u2202\u03bd A1\u03bc + g2 Aa\u03bc Ab\u03bd f ab1\n= \u2202\u03bc A1\u03bd \u2212 \u2202\u03bd A1\u03bc + g2 Aa\u03bc Ab\u03bd \u000fab1\n= \u2202\u03bc A1\u03bd \u2212 \u2202\u03bd A1\u03bc + g2 (A2\u03bc A3\u03bd \u2212 A2\u03bd A3\u03bc )\nAnd similarly,\n2\nF\u03bc\u03bd\n= \u2202\u03bc A2\u03bd \u2212 \u2202\u03bd A2\u03bc + g2 (A3\u03bc A1\u03bd \u2212 A3\u03bd A1\u03bc )\n3\nF\u03bc\u03bd\n= \u2202\u03bc A3\u03bd \u2212 \u2202\u03bd A3\u03bc + g2 (A1\u03bc A2\u03bd \u2212 A1\u03bd A2\u03bc )\n\nAnd the gauge field corresponding to the U (1) will be defined as in (3.20):\nB\u03bc\u03bd = \u2202\u03bc B\u03bd \u2212 \u2202\u03bd B\u03bc\nSo, we can now write the kinetic term for our fields according to equation (3.54):\n1\n1\na\n\u2212 B \u03bc\u03bd B\u03bc\u03bd\nLKin = \u2212 Fa\u03bc\u03bd F\u03bc\u03bd\n4\n4\n119\n\n\fWe can then use (3.67\u20133.70) to translate these kinetic terms into the new fields. We will\nspare the extremely tedious detail and skip right to the Lagrangian:\n1\n1\nLef f = \u2212 F \u03bc\u03bd F\u03bc\u03bd \u2212 Z \u03bc\u03bd Z\u03bc\u03bd \u2212 D\u2020\u03bc W \u2212\u03bd D\u03bc W\u03bd+ + D\u2020\u03bc W \u2212\u03bd D\u03bd W\u03bc+\n4\n4\n\u03bc\u03bd\n+ie(F + cot \u03b8w Z \u03bc\u03bd )W\u03bc+ W\u03bd\u2212\n\u0012\n\u0013\n1\ne2\n\u2212\n(W +\u03bc W\u03bc\u2212 W +\u03bd W\u03bd\u2212 \u2212 W +\u03bc W\u03bc+ W \u2212\u03bd W\u03bd\u2212 )\n2 sin2 \u03b8w\n\u0012\n\u00132\n1 2 \u03bc\nh\n2\n+\u03bc\n\u2212\n\u2212(MW W W\u03bc + MZ Z Z\u03bc ) 1 +\n2\nv\n2\n1 mh 3 1 m2h 4\n1\n1\n= \u2212 \u2202 \u03bc h\u2202\u03bc h \u2212 m2h h2 \u2212\nh \u2212\nh\n2\n2\n2 v\n8 v2\nwhere we have chosen the following definitions:\nF\u03bc\u03bd = \u2202\u03bc A\u03bd \u2212 \u2202\u03bd A\u03bc\n(Electromagnetic Field Strength)\nZ\u03bc\u03bd = \u2202\u03bc Z\u03bd \u2212 \u2202\u03bd Z\u03bc\n(Kinetic term for Z\u03bc )\nD\u03bc = \u2202\u03bc \u2212 ie(A\u03bc + cot \u03b8w Z\u03bc )\nand the rest of the terms were defined previously in this section.\n\n3.4.3\n\nThe Lepton Sector\n\nWe now turn to the lepton sector (which is still in the SU (2) \u2297 U (1) part of the Standard\nModel gauge group). A Lepton is a spin-1/2 particle that does not interact with the SU (3)\ncolor group (the strong force). There are six Flavors of leptons arranged into three Families, or Generations. The table on page 139 explains this. The first generation consists of\nthe electron (e) and the electron neutrino (\u03bde ), the second generation the muon (\u03bc) and the\nmuon neutrino (\u03bd\u03bc ), and the third the tau (\u03c4 ) and tau neutrino (\u03bd\u03c4 ). Each family behaves\nexactly the same way, so we will only discuss one generation in this section (e and \u03bde ). To\nincorporate the physics of the other families, merely change the e to either a \u03bc or \u03c4 , and\nthe \u03bde to a \u03bd\u03bc or \u03bd\u03c4 in the following notes.\nWhat we will see is that, in a sense, the neutrinos don't really interact with anything on\ntheir own (which is why they are incredibly difficult to detect). For this reason, neutrinos\ndon't have their own place in a representation of SU (3) \u2297 SU (2) \u2297 U (1) (see table on 139).\nElectrons on the other hand, do interact with other things on their own, and we therefore\nsee them in the (1, 1) representation.\nHowever, the neutrino does interact with other things as part of an SU (2) doublet with the\nelectron,\n\u0012 \u0013\n\u03bd\nl= e\n(3.71)\ne\n120\n\n\fThis is why it is arranged as it is on page 139 with the electron under the (2, \u22121/2) representation of SU (2) \u2297 U (1).\nThis may seem confusing, but we hope the following will make it clear. We will proceed\nin what we believe is the clearest way to see this (primarily following [32]). We start with\n2 fields, \u0113 and l, where \u0113 is a single left-handed Weyl field (see section 3.2.4), and l is\ndefined in (3.71). As we have said, l is in the (2, \u22121/2) representation, \u0113 is in the (1, 1)\nrepresentation, and \u03bde has no representation of its own.\nSo, mimicking what we did in equation (3.56) in the previous section, we can write down\nthe covariant derivative for each field,\n(D\u03bc l)i = \u2202\u03bc li \u2212 ig2 Aa\u03bc (T a )ij lj \u2212 ig1 B\u03bc Yl li\nD\u03bc \u0113 = \u2202\u03bc \u0113 \u2212 ig1 B\u03bc Y\u0113 \u0113\n\n(3.72)\n(3.73)\n\nThe field \u0113 has no SU (2) term in its covariant derivative because the 1 representation of\nSU (2) is the trivial representation - this means it doesn't carry SU (2) charge. Also, we\nknow that\n\u0012\n\u0013\n1 1 0\n(3.74)\nYl = \u2212\n2 0 1\nand\n\u0012\n\u0013\n1 0\nY\u0113 = (1)\n0 1\n\n(3.75)\n\nFollowing the Lagrangian for the spin-1/2 fields we wrote out in equation (3.11), we can\nwrite out the kinetic term for both (massless) fields:\nLKin = il\u2020i \u03c3\u0304 \u03bc (D\u03bc l)i + i\u0113\u2020 \u03c3\u0304 \u03bc D\u03bc \u0113\n\n(3.76)\n\nAt the end of section 3.2.2 and of section 3.2.11, we briefly discussed the idea of renormalization. We said that certain theories can be renormalized and others cannot. It turns out\n(for reasons beyond the scope of these notes) that while the theory we have outlined so\nfar is renormalizable, if we try to add mass terms for and l and \u0113 fields, the theory breaks\ndown. Therefore we cannot add a mass term. But, we know experimentally that electrons\nand neutrinos have mass, so obviously something is wrong. We must incorporate mass\ninto the theory, but in a more subtle way than merely adding a mass term. It turns out\nthat we can use the Higgs mechanism as follows.\nWhile adding mass terms renders the theory inconsistent, we can add a Yukawa term (cf.\nequation (3.42)),\nLY uk = \u2212y\u000fij \u03c6i lj \u0113 + h.c.\n\n121\n\n\fwhere y is another coupling constant, \u000fij is the totally antisymmetric tensor, and h.c. is the\nHermitian Conjugate of the first term.\nNow that we have added LY uk to the Lagrangian, we want to break the symmetry exactly\nas we did in the previous section. First, we replace \u03c61 with \u221a12 (v + h(x)) and \u03c62 with 0,\nexactly as we did in equation (3.61). So,\nLY uk = \u2212y\u000fij \u03c6i lj \u0113 + h.c.\n= \u2212y(\u03c61 l2 \u2212 \u03c62 l1 )\u0113 + h.c.\n1\n= \u2212 \u221a y(v + h)l2 \u0113 + h.c.\n2\n1\n1\n= \u2212 \u221a y(v + h)e\u0113 \u2212 \u221a y(v + h)\u0113e\n2\n2\n1\n= \u2212 \u221a y(v + h)\u0112E\n2\n\n(3.77)\n\n\u0012 \u0013\ne\nwhere E =\nis the Dirac field for the electron (e is the electron and \u0113\u2020 is the anti\u0113\u2020\nelectron, or positron). Comparing (3.77) with (3.12), we see that it is a mass term for the\nelectron and positron.\nNow we want a kinetic term for the neutrino. It is believed that neutrinos\n\u0012 are\n\u0013 described\n\u03bd\ne\nby Majorana fields (see section 3.2.4), so we begin with the field N 0 =\n. Now, we\n\u03bde\u2020\nemploy a trick. Referring back to equations (3.33) and (3.34), the kinetic term for Majorana\nfields has only one term (because Majorana fields have only one Weyl spinor), whereas\nthe Dirac field sums over both Weyl spinors composing it. So, instead of working with\nthe Majorana field N 0 , we can instead work with the Dirac field\n\u0012 \u0013\n\u03bd\nN = e\n0\nSo, the Dirac kinetic term iN\u0304 \u03b3 \u03bc \u2202\u03bc N will clearly result in the correct kinetic term from\n(3.76), or i\u03bd \u2020 \u03c3\u0304 \u03bc \u2202\u03bc \u03bd.\nNow, continuing with the symmetry breaking, we want to write the covariant derivative\n(3.72) and (3.73) in terms of our low energy gauge fields (3.63\u20133.66).\nWe said in the previous section (which echoed our discussion in section 2.2.16) that the\ngauge fields corresponding to Cartan generators (A\u03bc and Z\u03bc ) act as force carrying particles, but do not change the charge of the particles they interact with. On the other hand,\nthe non-Cartan generators' gauge fields (W\u03bc\u00b1 ) are force carrying particles which do change\nthe charge of the particle they interact with. Therefore, to make calculations simpler, we\nwill break the covariant derivative up into the non-Cartan part and the Cartan part.\n\n122\n\n\fThe non-Cartan part of the covariant derivative (3.72) is\n\u0012 \u0012\n\u0013\n\u0012\n\u0013\u0013\n1\n0 1\n0 \u2212i\n1 1\n2 2\n1\n2\ng2 (A\u03bc T + A\u03bc T ) =\ng2 A\u03bc\n+ A\u03bc\n1 0\ni 0\n2\n\u0013\n\u0012\n1\n1\n0\nA\u03bc \u2212 iA2\u03bc\ng2\n=\n0\nA1\u03bc + iA2\u03bc\n2\n\u0012\n\u0013\n+\ng2\n0 W\u03bc\n= \u221a\n\u2212\n0\nW\n2\n\u03bc\nand the Cartan part is\ng2 A3\u03bc T 3 + g1 B\u03bc Y\n\ne\ne\n(sw A\u03bc + cw Z\u03bc )T 3 + (cw A\u03bc \u2212 sw Z\u03bc )Y\nsw\ncw\n3\n= e(A\u03bc + cot \u03b8w Z\u03bc )T + e(A\u03bc \u2212 tan \u03b8w Z\u03bc )Y\n= e(T 3 + Y )A\u03bc + e(cot \u03b8w T 3 \u2212 tan \u03b8w Y )Z\u03bc\n=\n\nWe have noted before that A\u03bc is the photon, or the electromagnetic field, and e is the\nelectromagnetic charge. Therefore, the linear combination T 3 + Y must be the generator\nof electric charge. Notice that the electromagnetic generator is in a linear combination of\nthe two Cartan generators of SU (2) \u2297 U (1).\nWe know that T 3 = 21 \u03c3 3 , and Yl and Y\u0113 are defined in equations (3.74) and (3.75), so we\ncan write\n\u0012\n\u0013\u0012 \u0013\n\u0012 \u0013\n1 1 0\n1 \u03bde\n\u03bde\n3\nT l =\n=\ne\n2 0 \u22121\n2 \u2212e\n\u0012\n\u0013\u0012 \u0013\n\u0012 \u0013\n1 1 0\n1 \u03bde\n\u03bde\nYl l = \u2212\n=\u2212\ne\n2 0 1\n2 e\nAnd we know that \u0113 carries no T 3 charge, so its T 3 eigenvalue is 0, while Y\u0113 is +1. So,\nsummarizing all of this,\n1\nT 3 \u03bde = + \u03bde\n2\n1\nY \u03bde = \u2212 \u03bde\n2\n\n1\nT 3e = \u2212 e\n2\n1\nYe=\u2212 e\n2\n\nT 3 \u0113 = 0\nY \u0113 = +\u0113\n\nThen defining the generator of electric charge to be Q \u2261 T 3 + Y , we have\nQ\u03bde = 0\n\nQe = \u2212e\n\nQ\u0113 = +\u0113\n\nSo the neutrino \u03bde has no electric charge, the electron e has negative electric charge, and\nthe antielectron, or positron, has plus one electric charge-all exactly what we would\nexpect.\nWe can now take all of the terms we have discussed so far and write out a complete\nLagrangian. However, doing so is both tedious and unnecessary for our purposes.\n123\n\n\fThe primary idea is that electrons/positrons and neutrinos all interact with the SU (2) \u2297\nU (1) gauge particles, the W \u00b1 , Z\u03bc , and A\u03bc . The Z\u03bc and A\u03bc (the Cartan gauge particles)\ninteract but do not affect the charge. On the other hand, the W \u00b1 act as SU (2) raising\nand lowering operators (as can easily be seen by comparing (3.63) and (3.64) to equation\n(2.18)). The SU (2) doublet state acted on by these raising and lowering operators is the\ndoublet in equation (3.71). The W + interacts with a left-handed electron, raising its electric charge from minus one to zero, turning it into a neutrino. However W + does not\ninteract with left-handed neutrinos. On the other hand, W \u2212 will lower the electric charge\nof a neutrino, making it an electron. But W \u2212 will not interact with an electron.3\n\n3.4.4\n\nThe Quark Sector\n\nA Quark is a spin-1/2 particle that interacts with the SU (3) color force. Just as with leptons, there are six flavors of quarks, arranged in three families or generations (see the\ntable on page 139).\nFollowing very closely what we did with the leptons, we work with only one generation.\n \u0304\nExtending to the other generators is then trivial. To begin, define three fields: q, \u016b, and d,\nin the representations (3, 2, +1/6), (3\u0304, 1, \u22122/3), and (3\u0304, 1, +1/2) of SU (3) \u2297 SU (2) \u2297 U (1).\nThe field q will be the SU (2) doublet\n\u0012 \u0013\nu\nq=\n(3.78)\nd\nThis is exactly analogous to equation (3.71).\nAgain, following what we did with the leptons, we can write out the covariant derivative\nfor all three fields:\n\u0012 \u0013\n1\na\na \u03b2\na\na j\nB\u03bc q\u03b1i\n(3.79)\n(D\u03bc q)\u03b1i = \u2202\u03bc q\u03b1i \u2212 ig3 A\u03bc (T2 )\u03b1 q\u03b2i \u2212 ig2 A\u03bc (T2 )i q\u03b2j \u2212 ig1\n6\n\u0012\n\u0013\n2\n\u03b1\n\u03b1\na\na \u03b1 \u03b2\n(D\u03bc \u016b) = \u2202\u03bc \u016b \u2212 ig3 A\u03bc (T3 )\u03b2 \u016b \u2212 ig1 \u2212\nB\u03bc \u016b\u03b1\n(3.80)\n3\n\u0012 \u0013\n1\n\u03b1\n\u03b1\na\n\u03b1 \u03b1  \u0304\u03b2\n \u0304\n \u0304\n(D\u03bc d) = \u2202\u03bc d \u2212 ig3 A\u03bc (T3 )\u03b2 d \u2212 ig1\nB\u03bc d \u0304\u03b1\n(3.81)\n3\nwhere i is an SU (2) index and \u03b1 is an SU (3) index. The SU (3) index is lowered for the 3\nrepresentation and raised for the 3\u0304 representation.\nJust as with leptons, we cannot write down a mass term for these particles, but we can\ninclude a Yukawa term coupling these fields to the Higgs:\nLY uk = \u2212y 0 \u000fij \u03c6i q\u03b1j d \u0304\u03b1 \u2212 y 00 \u03c6\u2020i q\u03b1i \u016b\u03b1 + h.c.\n3\nThis does not mean that no vertex in the Feynman diagrams will include a W \u2212 and an electron field,\nbut rather that if you collide an electron and a W \u2212 , there will be no interaction\n\n124\n\n\fAs with the leptons, we can break the symmetry according to equation (3.61), and writing\nout this Yukawa term, we get\n1\n1\nLY uk = \u2212 \u221a y 0 (v + h)(d\u03b1 d \u0304\u03b1 + d \u0304\u2020\u03b1 d\u2020\u03b1 ) \u2212 \u221a y 00 (v + h)(u\u03b1 \u016b\u03b1 + \u016b\u2020\u03b1 u\u2020\u03b1 )\n2\n2\n1\n1\n= \u2212 \u221a y 0 (v + h)D\u0304\u03b1 D\u03b1 \u2212 \u221a y 00 (v + h)\u016a \u03b1 U\u03b1\n2\n2\nwhere we have defined the Dirac fields for the up and down quarks:\n\u0012 \u0013\n\u0012 \u0013\nd\u03b1\nu\u03b1\nD\u03b1 \u2261  \u0304\u2020\nU\u03b1 \u2261\nd\u03b1\n\u016b\u2020\u03b1\nNotice that, whereas both the up and down quarks were massless before breaking, they\nhave now acquired masses\ny0v\nmd = \u221a\n2\n\ny 00 v\nmu = \u221a\n2\n\nWriting out the non-Cartan and Cartan parts of the covariant derivatives in terms of the\nlower energy SU (2) \u2297 U (1) gauge fields, we get\n\u0013\n\u0012\ng2\n0 W\u03bc+\n1 1\n2 2\ng2 A\u03bc T + g2 A\u03bc T = \u221a\n\u2212\n0\n2 W\u03bc\ne\ng2 A3\u03bc T 3 + g1 B\u03bc Y = eQA\u03bc +\n(T 3 \u2212 s2w Q)Z\u03bc\ns w cw\nAnd it is again straightforward to find the electric charge eigenvalue for each field:\n2\nQu = + u\n3\n\n1\nQd = \u2212 d\n3\n\n2\nQ\u016b = \u2212 \u016b\n3\n\n1\nQd \u0304 = + d \u0304\n3\n\nAgain, we can collect all of these terms and write out a complete Lagrangian. But, doing\nso is extremely tedious and unnecessary for our purposes.\nThe primary idea to take away is that the SU (2) doublet (3.78) behaves exactly as the lepton doublet in (3.71) when interacting with the \"raising\" and \"lowering\" gauge particles\nW \u00b1 . This is why the u and d are arranged in the SU (2) doublet q in (3.78), and why q\ncarries the SU (2) index i in the covariant derivative (3.79), whereas \u016b and d \u0304 carry only the\nSU (3) index.\nThe SU (3) index runs from 1 to 3, and the 3 values are conventionally denoted red, green,\nand blue (r, g, b). These obviously are merely labels and have nothing to do with the colors\nin the visible spectrum.\n125\n\n\fThe eight gauge fields associated with the eight SU (3) generators are called Gluons, and\nthey are represented by the matrices in (2.48). We label each gluon as follows:\n\uf8eb\n\uf8f6\nrr\u0304 r\u1e21 rb\u0304\n \u0307 \uf8edgr\u0304 g\u1e21 g b\u0304\uf8f8\ng\u03b1\u03b2 =\nbr\u0304 b\u1e21 bb\u0304\nso that the upper index is the anti-color index, and denotes the column of the matrix,\nand the lower index is the color index denoting the row of the matrix. Then, from (2.48),\nconsider the gluon\n\uf8eb\n\uf8f6\n0 1 0\ngr\u1e21 \u221d \uf8ed0 0 0\uf8f8\n0 0 0\nand the quarks\n\uf8eb \uf8f6\n1\nqr = \uf8ed0\uf8f8\n0\n\n\uf8eb \uf8f6\n0\nqg = \uf8ed1\uf8f8\n0\n\n\uf8eb \uf8f6\n0\nqb = \uf8ed0\uf8f8\n1\n\nIt is easy to see that this gluon will interact as\ngr\u1e21 qr = 0\n\ngr\u1e21 qg = qr\n\ngr\u1e21 qb = 0\n\nOr in other words, the gluon with the anti-green index will only interact with a green\nquark. There will be no interaction with the other quarks. Multiplying this out, and\nlooking more closely at the behavior of the SU (3) generators and eigentstates as discussed\nin sections 2.2.12\u20132.2.15, you can work out all of the interaction rules between quarks and\ngluons. You will see that they behave exactly according to the root space of SU (3).\n3.5\n\nReferences and Further Reading\n\nThe primary source for these notes is [32], which is an exceptionally clear introduction to\nQuantum Field Theory. We also used a great deal of meterial from [3], [24], [29], and [35],\nall of which are outstanding QFT texts. The derivation of the Dirac equation came from\n[21], which is written mostly above the scope of these notes, but is an excellent survey of\nsome of the mathematical ideas of Non-Perturbative QFT and Gauge Theory.\nThe sections on the Standard Model come almost entirely from [32] with little change, in\nthat Srednicki's exposition could hardly be improved upon for the scope of these notes.\nFor further reading, we also recommend [1], [11], [23], [26], and [27].\n\n126\n\n\f4\n\nThe Standard Model - A Summary\n\n4.1\n\nHow Does All of This Relate to Real Life?\n\nIn the fifth century B.C., a Greek named Empedocles took the ideas of several others\nbefore him and combined them to say that matter is made up of earth, wind, fire, and\nwater, and that there are two forces, Love and Strife, that govern the way they grow and\nact. More scientifically, he was saying that matter is made of smaller substances that\ninteract with each other through repulsion and attraction. Democritus, a contemporary\nof Empedocles, went a step further to say that all matter is made of fundamental particles\nthat are indestructible. He called these particles atoms, meaning \"indivisible\"4 [14].\nThe field of particle physics seeks to continue studying these same concepts. Are there\nfundamental, indivisible particles and if so, what are they? How do they behave? How\ndo they group together to form the matter that we see? How do they interact with each\nother?\nThe current answer to these questions is called the Standard Model, the theory we spent\nthis paper developing. We have now spent more than one hundred pages expositing a series of mathematical tricks for various types of \"fields\". In doing so, we talked about\n\"massless scalars with U (1) charge\", and about things \"in a j = 12 representation of\nSU (2)\". But one could easily be left wondering how exactly this relates to the things\nwe see in nature. We only discussed 25 particles in the previous section and in the table\non page 139 (particles and antiparticles), but you are likely aware that there are hundreds\nof particles in nature. What about those? How does the mathematical framework detailed\nso far form the building blocks for the universe?\nWhile we wish to reiterate that the primary purpose of these notes is to provide the mathematical tools with which particle physics is done, and not to outline the phenomenological details of the theory, we are physicists still-not mathematicians. Therefore, before\nconcluding this paper, we will take a brief hiatus from the mathematical rigor and look at\na qualitative summary of particle physics.\nThroughout this section, the footnotes will provide brief explanations of the analogous\nmathematical ideas from above. This section5 can be read with or without paying attention to them. We provide them merely for those curious.\n4\n\nOf course, our modern use of the word is different. At their discovery, it was thought that different\nelements were the indivisible particles sought for, so the name atom seemed appropriate\n5\nNearly everything in this section is adapted from [4], including the tables on page 134\n\n127\n\n\f4.2\n\nThe Fundamental Forces\n\nThe two forces most familiar to people are Gravity and Electromagnetism. Just the act\nof standing on the ground or sitting in a chair makes use of both, and every \"Physics I\"\nstudent has drawn a free body diagram with a gravitational force going down and a\nnormal force (caused by the electromagnetic repulsion between the two objects) going\nup. However, these two are only half of the four fundamental forces in our universe (that\nwe know of).\nWe can think about the third by first considering a compact nucleus which we know to be\nmade of protons and neutrons. From electromagnetism we know that the protons should\nrepel each other because of their like charge. But the nuclei of atoms somehow hold together, which is evidence for some stronger force that causes these particles to attract.\nThis force, which overcomes the electromagnetic repulsions and allows atomic nuclei to\nremain stable, is called the Strong force.6 Just as electrically-charged particles are subject to the electromagnetic force, some particles have a property similar to charge, called\nColor, and are subject to the strong force. The field theory that describes this is called\nQuantum Chromodynamics (QCD)7 and was first proposed in 1965 by Han, Nambu,\nand Greenberg [20]. This theory predicts the existence of the gluon, which is the mediator\nof the strong force between two matter particles.\nThe fourth force is the one we have the least familiarity with. It is responsible for certain\ntypes of radioactive decays; for example, permitting a proton to turn into a neutron and\nvice versa. It is called the Weak force.8\nIn the 1960's, Sheldon Glashow, Abdus Salum, and Steven Weinburg independently developed a gauge-invariant theory that unified the electromagnetic and weak force [20].\nAt sufficiently high energies it is observed that the difference between these two separate\nforces is negligible and that they instead act together as the Electroweak force.9 For processes at lower energy scales, the symmetry between the electromagnetic and the weak\nforce is broken and we observe two different forces with different properties. Similar\nto QCD, electroweak theory predicts four force-carrier particles10 that mediate the force\nbetween matter particles. The mediating particle for electromagnetism is the neutral photon, and those for the weak force are the W + (with +1 electron charge), W \u2212 (with \u22121\nelectron charge) and Z 0 (neutral) bosons.\nThe electromagnetic, weak, and strong forces forces described above form what is called\nthe Standard Model of Particle Physics. The Standard Model is an incomplete theory\nin the sense that it fails to describe gravitation, the force that acts on matter. Physicists\n6\n\nThe SU (3) color force\nAgain, the study of the SU (3) color force\n8\nThe SU (2) part that is left over when SU (2) \u2297 U (1) is broken\n9\nThe unbroken SU (2) \u2297 U (1) force\n10\nCorresponding to the 3 generators of SU (2) and the 1 in U (1). Two of them are Cartan and are, therefore, uncharged, while two are non-Cartan and therefore carry charge\n7\n\n128\n\n\fcontinue to work towards a theory that describes all four fundamental forces, with String\nTheory currently the most promising. The papers later in this series will discuss these\nideas. For the rest of the sections in this review, however, it should be assumed that we are\ntalking about physics under the Standard Model only11 which, despite the shortcoming\nof not explaining gravity, has tremendous experimental support.\n4.3\n\nCategorizing Particles\n\nIn the last century, experimenters were surprised as they discovered new particle after\nnew particle. It seemed disorganized and overwhelming that there could be so many\nelementary objects. Eventually, however, the properties of these particles became better\nunderstood and it was found that there really is just a small, finite set of fundamental\nparticles, some of which can be grouped together to make up larger objects. In the next\ntwo sections, we will introduce the elementary particles and then will discuss the types\nof composite particles.\nOne property of the \"zoo\" of discovered particles that helps in our organizing them is\ntheir intrinsic spin.12 Any particle, elementary or composite, that is of half-integer spin13\nis a Fermion. Those with integer spin are Bosons.14 The spins govern the statistics of a set\nof such particles, so fermions and bosons may also be defined according to the statistics\nthey obey.\nNamely, fermions obey Fermi-Dirac statistics and therefore also obey the Pauli Exclusion\nPrinciple. This means that no two identical fermions can be found in the same quantum\nstate at the same time. Furthermore, to accurately display this behavior it is found that\nthe wave function of a system with fermions must be antisymmetric; swapping any two\nlike fermions causes a change in sign of the overall wave function.\nBosons on the other hand obey Bose-Einstein statistics; any number of the same type of\nparticle can be in the same state at the same time. In contrast to fermions, the wavefunction of a system of bosons is symmetric.15\nThe Venn diagrams on page 138, the table provided on page 139, and the table below\nshould be referenced as you read through what follows.\n11\nWe are not assuming Supersymmetry in this paper, though we will consider Supersymmetry in a later\npaper\n12\nOr in other words, which representation of SU (2) they sit in\n13\nIs in the j = 12 or j = 32 representation of SU (2)\n14\nIs in the j = 0 or j = 1 representation of SU (2)\n15\nCf. section 3.2.3\n\n129\n\n\f4.4\n\nElementary Particles\n\nThe elementary particles are those that are considered fundamental, or in other words,\nare not composed of smaller particles.16 They can be divided into two groups: matter\nparticles and non-matter particles.\nThe elementary matter particles all have half-integer spin (so are fermions) and the elementary non-matter particles all have integer spin (so are bosons). We can then observe\nthat an equivalent grouping is made if we divide the elementary particles instead by their\nintrinsic spin, which is commonly done. Then an elementary matter particle is the same\nthing as an elementary fermion, and similarly for the bosons. The two terms are used\ninterchangeably in the discussion below.\n\n4.4.1\n\nElementary Fermions\n\nThe elementary fermions are the building blocks of all other matter. For example, the\nproton and neutron are made up of different combinations of three elementary quarks.\nElectrons, which are also elementary, cloud around the protons and neutrons, and when\nall three group together in a particular way, an atom is formed. Less familiar examples\ninclude those that are unstable, such as the muon, which decay into something else fairly\nquickly.\nFor every elementary (and sometimes composite) matter particle, there is also a corresponding particle with the same mass but of different charge and magnetic moment.17\nGenerally the name of such a particle is the same as the corresponding \"normal\" matter\nparticle, but with the prefix \"anti\" in front of it (e.g. antiquark, antilepton, etc.). In this\npaper, whenever we discuss matter and its properties, it is implied that the antimatter\ncounterparts have similar properties.\nNow we further divide the elementary fermions into two groups, quarks and leptons. A\nconvenient way to distinguish these two sets is by whether or not they interact via the\nstrong force: quarks may interact via the strong force, while leptons do not.\nQuarks\nExperiments involving high energy collisions of electrons and protons led Murray GellMann to suggest in 1964 [25] that protons and neutrons are actually composite particles,\nmade of three point-like, spin-1/2 particles whose charges are either \u22121/3 or +2/3 units\nof electron charge. He called these particles Quarks. Through further experiments it has\nbeen found that there are six flavors of quarks total, grouped into three generations with\n16\n17\n\nThese are the ones that are in some representation of SU (3) \u2297 SU (2) \u2297 U (1) on the table on page 139\nCf. material on spin-1/2 particles in section 3.1\n\n130\n\n\fthe first generation containing the up and down quarks, the second generation containing\nthe more massive charm and strange quarks, and the third generation containing the even\nmore massive top and bottom quarks.\nAs electrically charged particles are subject to the electromagnetic force, quarks have a\nproperty similar to charge, called color, and any colored particle is subject to the strong\nforce. It is found that there are three different types of colors: (defined as) red, green,\nand blue (plus three more for antiquarks: antired, antigreen, and antiblue). Quarks are\ngrouped together to make composite particles that are colorless (the color charges cancel\nout), which is why the concept of color was only discovered after quarks themselves were\nfound. The addition of color to the quark model also ensures that any quarks contained\nin a composite particle will not violate the exclusion principle since each has a different\ncolor. Again, QCD is the field theory that describes these properties.\nAnother interesting feature of quarks is that they are never found alone, but rather always\ninside of a composite particle. This phenomenon is called Confinement.18 It is more\na property of the strong force, which increases in strength as two colored particles are\npulled away from each other, just as would happen when the ends of a piece of elastic are\npulled apart. We can consider reaching a distance between the two quarks where there\nis sufficient potential energy built up that it can be converted to matter, creating a quarkantiquark pair. The pair will separate and the resulting particles will recombine with\nthe original quarks. As this process repeats, and more quark-antiquark pairs are created,\nthe end result in the whole process is a multiplication of the number of quarks and of the\nnumber of composite particles. In the opposite extreme, as two quarks get closer together,\nthe strong force between them becomes weaker until the quarks move around freely and\nmore independently. This is a called Asymptotic Freedom.\nQuarks also interact with other particles via the weak force, which is the only force that\ncan cause a change of flavor (changing an up into a down, for example). When this\nhappens, a quark either turns into a heavier quark by absorbing a W boson, or it emits a\nW boson and then decays to a lighter quark. Beta decay, a common radioactive process,\nis caused by this mechanism. Instead of just thinking of beta decay as a neutron in the\nnucleus of an atom decaying, or splitting, into a proton, electron, and antineutrino, we\ncan go a step further with our understanding of quarks subject to the weak force. We add\nthat, really, it is one of the down quarks in the neutron that emits a W \u2212 boson and then\ndecays to the lighter up quark, keeping charge conserved in the process.19 The neutron,\nwhich used to have one up and two down quarks, now has one down and two up quarks,\nwhich is the composition of a proton. The electron and antineutrino are created from the\ndecay of the W \u2212 boson.\n\n18\nWe did not discuss confinement in the main body of this paper, though it can be derived from what we\ndid discuss\n19\nOther conserved quantities are momentum, energy, quark number, lepton number, and (approximately) lepton generation number\n\n131\n\n\fLeptons\nLeptons interact with other matter via the electromagnetic, the weak, and gravitational\nforces, but not through the strong force.20 There are three charged leptons, grouped, like\nthe quarks, into three different generations based on their masses.21 The electron is the\nlightest of the charged leptons, then the muon, and the tau. There are also three neutral\nleptons, called neutrinos (\"little neutral one\"), one type for each of the charged leptons:\nthe electron neutrino, the muon neutrino, and the tau neutrino.\nSome quantities in lepton events are found to be conserved.22 If we define lepton number as the number of leptons minus the number of antileptons, then lepton number is\nconstant in all interactions. Additionally, the lepton number within each generation is also\napproximately conserved. For example, the number of electrons and electron neutrinos\nminus the number of antielectrons and electron antineutrinos is found to be constant in\nmost particle reactions.\nAn interesting exception is in neutrino oscillations, where a neutrino changes lepton flavors as it travels. For example, we can take a measurement and observe an electron\nneutrino, even though it was known to have been created as a muon neutrino. These\noscillations of flavor only occur if neutrinos have mass (even just very small mass), so the\nfact that the Standard Model currently predicts them to be massless demonstrates that\nthere are some parameters in the theory that need to be adjusted.\n\n4.4.2\n\nElementary Bosons\n\nThroughout the development of the Standard Model it was found that some elementary\nparticles play a different role than the ordinary matter particles that make up the stuff of\nthe universe. Both the gauge bosons and the Higgs boson fall into this group.\nGauge Bosons\nIn the mathematical formulation of quantum field theory, the Lagrangian can be made\ninvariant under a local gauge transformation by the addition of a vector field called a\ngauge field. As with the more familiar example of an electron, the quanta of the gauge\nfield is a type of particle, which in this case is called a Gauge Boson. There are three\ntypes of gauge bosons described by the Standard Model.23 They are the photon, which\n20\n\nThis means that leptons carry SU (2) \u2297 U (1) terms in their covariant derivatives, but not SU (3) terms\nThis is equivalent to the statement above that there are three copies of the Standard Model Gauge Group\n- Cf. page 115\n22\nThese conservation laws can all be derived from the rules we discussed above, though they are typically\ntreated separately because they are extremely useful when talking about specific interactions\n23\nThis is equivalent to saying that there are three gauge groups, each with their own set of generators\n21\n\n132\n\n\fcarries the electromagnetic force, the W and Z bosons, which carry the weak force, and\nthe gluons which carry the strong force. Each of these bosons have been experimentally\ndetected.\nEvidence for the neutral photon first came in 1905 when Einstein proposed an explanation\nof the photoelectric effect, that light was quantized into energy packets [7]. Confirmation\nof the W + , W \u2212 , and Z 0 bosons came in 1983 through proton-proton collisions at the European Organization for Nuclear Research (CERN) [5].\nThe gluons were first experimentally observed in 1979 in the electron-position collider\nat the German Electron Synchroton (DESY) in Hamburg [5]. Further experiments have\ndemonstrated that the gluons have eight different color states and that, because they interact via the strong force, they have properties similar to quarks, such as confinement.\nTaking into account their possible charge or color, we find that there are 12 gauge bosons\nin all, one for the electromagnetic force, three for the weak force, and eight for the strong\nforce.\nThe Higgs Boson\nThe Higgs boson is the only Standard Model particle that has not yet been observed. It is\nalso the only elementary boson that is not a gauge boson. Rather, it is the carrier particle\nof the scalar Higgs field from which other particles acquire mass. The existence of the\nHiggs would explain why some particles have mass and others do not. For example,\nthe W and Z bosons are very massive, whereas the photon is massless. One of the main\ngoals of the Large Hadron Collider (LHC), located at CERN in Switzerland, is to provide\nevidence for the Higgs. It is expected to be in full operation in 2009.\n4.5\n\nComposite Particles\n\nExamples of composite particles include hadrons, nuclei, atoms, and molecules. The latter\nthree are well known and will not be described here.\nHadrons are made up of bound quarks and interact via the strong force. They can be\neither fermions or bosons, depending on the number of quarks that make them up. An\nodd number of bound quarks create a spin-1/2 or spin-3/2 hadron, which is called a\nbaryon, and an even number of quarks create spin-0 or spin-1 hadrons, called mesons.\nExperimentally, only combinations of three quarks or two quarks have been found, so the\nterms baryon and meson often just refer to three or two bound quarks, respectively.\nYou can understand why mesons and baryons have the spin that they do by considering\nhow many spin-1/2 quarks compose them. A meson has two quarks, and therefore the\ntotal spin of a meson is the sum of an even number of half-integer spin particles, which\n133\n\n\fwill be integer spin. And because there are only two of them, it is either spin 0 or 1.\nBaryons, on the other hand, will have a linear combination of three particles with halfinteger spin, which will of course be half-integer: 1/2 or 3/2.\nThe most well known examples of baryons are protons and neutrons. Protons are made\nof two up quarks and one down quark, or |uudi, and neutrons are made of two down\nand one up, or |uddi. The baryons are made of \"normal\" quarks only and their antimatter\ncounterparts are made of the corresponding antiquarks.\nThe mesons are made of a quark and an antiquark pair, though not necessarily of the\n \u0304 and K + |us\u0304i.\nsame generation. Examples include the \u03c0 + |udi\nOne of the reasons for the zoo of particles discovered in the past century is because of\nthe numerous possible combinations of six quarks put into a three-quark or two-quark\nhadron. Additionally, each of these combinations can be in different quantum mechanical\nstates, thereby displaying different properties. For example, a rho meson \u03c1 has the same\ncombination of quarks as a pion \u03c0, but the \u03c1 is spin-1 whereas the pion is spin-0.\n4.6\n\nVisualizing It All\n\nFinally, we provide a few tables which should help you see all of this more clearly.\nInteractions\nStrong\nElectromagnetism\nWeak\nGravity\n\nActs On\nHadrons\nElectric Charges\nLeptons and Hadrons\nMass\n\nStrength\n1\n10\u22122\n10\u22125\n10\u221239\n\nRange\n10\u221215 m\n\u221e (1/r2 )\n10\u221218 m\n\u221e (1/r2 )\n\nwhere the relative strengths have been normalized to unity for the strong force.\nAlso, the four classes of force-carrying gauge bosons are shown below;24\nInteraction\nStrong\nElectromagnetism\nWeak\nGravity\n\nGauge Boson\nGluon\nPhoton\nW \u00b1, Z \u2212,\nGraviton\n\n24\n\nSpin\n1\n1\n1\n2\n\nActs On\nHadrons\nElectric Charges\nLeptons and Hadrons\nMass\n\nThe graviton is a the hypothetical carrying particle for the gravitational force; it is not described by the\nStandard Model\n\n134\n\n\f5\n\nA Look Ahead\n\nNow that we have completed our introduction to basic particle theory, we can begin our\nuphill climb towards more fundamental concepts. As a preview, notice that everything\nwe have done so far has been an exposition of how gauge theories work. Our investigation into gauge theories has been purely algebraic (working entirely from group theory, as\nPart II demonstrates). As gauge theory seems to be the correct approach to understanding our universe, everything we do for the remainder of this series will be focused on a\nmore fundamental understanding of gauge theory, culminating in String Theory.\nAs we just stated, we have been treating gauge theory as a purely algebraic construct.\nHowever String Theory, if true, must obviously be able to reproduce the same general\nframework we have seen so far. But, String Theory is fundamentally a geometric construct. As we will see, String Theory will reproduce literally everything we have seen\nabout gauge theory, but from a geometric framework.\nThis should not be entirely foreign, though. Recall that, for electromagnetism, the gauge\ngroup is U (1). We can \"draw\" this geometrically as a circle in the complex plane. The\nWeak force is represented by the gauge group SU (2), which we have seen is parameterized by three numbers, and therefore has three generators. As we discussed in these\nnotes, we should think of these spaces as vector spaces and the generators as basis vectors\nspanning the entire space. The same is true of SU (3), though it is an eight-dimensional\nspace. So, because there is a space associated with each of these groups, it should be\nsomewhat obvious that there is a natural geometric picture associated with a Lie group.\nWhile the idea of the parameter space of a Lie group having a geometric picture associated with it may seem straightforward, the geometry undergirding gauge theory can be\nextremely complicated, and we therefore must spend a significant amount of time investigating it. Therefore, the next paper in this series will be an introduction to the geometric\nstructure of gauge theory. Just as we have built gauge theory from algebra, we will in a\nsense start over and rebuild it using geometry. However, because we have already covered a great deal of detail in the physics and mathematics of gauge theory and particle\nphysics in general, we will move much more quickly to avoid being repetitive.\nWhen we finally get to String Theory (later in this series), we will see that the geometric\nand algebraic pictures come together beautifully, and that a thorough understanding of\nboth will be necessary to understand what may be the \"ultimate\" theory of our universe.\n\n135\n\n\fReferences\n[1] D. Bailin and A. Love, \"Introduction to Gauge Field Theory\", Taylor and Francis\n(1993)\n[2] R. Cahn, \"Semi-Simple Lie Groups and Their Representations\", Dover (2006)\n[3] W. N. Cottingham and D. A. Greenwood, \"Introduction to the Standard Model\",\nCambridge University Press (2007)\n[4] R. Dunlap, \"An Introduction to the Physics of Nuclei and Particles\", Brooks Cole\n(2003)\n[5] V. Ezhela and B. Armstrong, \"Particle Physics: One Hundred Years of Discoveries:\nAn Annotated Chronological Bibliography\", Springer (1996)\n[6] R. P. Feynman, R. B. Leighton, and M. Sands, \"The Feynman Lectures Vols. I-III\",\nAddison Wesley (2005)\n[7] K. Ford, \"The Quantum World\", Harvard University Press (2005)\n[8] J. B. Fraleigh, \"A First Course in Abstract Algebra\", Addison Wesley (2002)\n[9] H. Georgi, \"Lie Algebras and Particle Physics\", Westview Press (1999)\n[10] R. Gilmore, \"Lie Groups, Lie Algebras, and Some of Their Applications\", Dover\n(2006)\n[11] R. Gilmore, \"Lie Groups, Physics, and Geometry\", Cambridge University Press\n(2008)\n[12] H. Goldstein, C. P. Poole, and J. L. Safko, \"Classical Mechanics\", Addison Wesley\n(2001)\n[13] D. J. Griffiths, \"Introduction to Classical Electrodynamics\", Benjamin Cummings\n(1999)\n[14] J. Hakim, \"The Story of Science: Aristotle Leads the Way\", Smithsonian Books (2004)\n[15] B. C. Hall, \"Lie Groups, Lie Algebras, and Representations\", Springer (2004)\n[16] J. E. Humphreys, \"Introduction to Lie Algebras and Representation Theory\",\nSpringer (1994)\n[17] T. W. Hungerford, \"Algebra\", Springer (2003)\n[18] J. D. Jackson, \"Classical Electrodynamics\", Wiley (1998)\n[19] J. V. Jose and E. J. Saletan, \"Classical Dynamics: A Contemporary Approach\", Cambridge University Press (1998)\n136\n\n\f[20] J. Mehra and H. Rechenberg, \"The Historical Development of Quantum Theory; v.6\",\nSpringer (2001)\n[21] G. Naber, \"Topology, Geometry, and Gauge Fields: Interactions\", Springer (2000)\n[22] G. Naber, \"The Geometry of Minkowski Spacetime\", Dover (2003)\n[23] M. Nakahara, \"Geometry, Topology, and Physics\", Taylor and Francis (2003)\n[24] M. E. Peskin and D. V. Schroeder, \"An Introduction to Quantum Field Theory\", Westview Press (1995)\n[25] A. Pickering, \"Constructing Quarks: A Sociological History of Particle Physics\", University of Chicago Press (1984)\n[26] P. Ramond, \"Field Theory: A Modern Primer\", Westview Press (2001)\n[27] P. Ramond, \"Journeys Beyond the Standard Model\", Westview Press (2003)\n[28] J. Rotman, \"An Introduction to the Theory of Groups\", Springer (1999)\n[29] L. H. Ryder, \"Quantum Field Theory\", Cambridge University Press (1996)\n[30] B. Sagan, \"The Symmetric Group\", Springer (2001)\n[31] J. J. Sakurai, \"Modern Quantum Mechanics\", Addison Wesley (1993)\n[32] M. Srednicki, \"Quantum Field Theory\", Cambridge University Press (2007)\n[33] J. Schwinger, \"Classical Electrodynamics\", Westview Press (1998)\n[34] N. M. J. Woodhouse, \"Special Relativity\", Springer (2007)\n[35] A. Zee, \"Quantum Field Theory in a Nutshell\", Princeton University Press (2003)\n\n137\n\n\fParticles\nFermions\nFundamental\nLeptons (Spin-1/2)\nQuarks (Spin-1/2)\n\u03bde \u03bd\u03bc \u03bd\u03c4\nu c t\ne \u03bc \u03c4\nd s b\nComposite\nBaryons\nSpin-1/2\nSpin-3/2\n++\nproton = |uudi\n\u2206 = |uuui\nneutron = |uddi\n\u2206\u2212 = |dddi\n\nSpin-0\nHiggs\n\nBosons\nFundamental\nGauge\nSpin-1\nSpin-2\n\u03bc\n\u03bc\nA Z\nGraviton\nW \u00b1 gi\n\nComposite\nMesons\nSpin-0\nSpin-1\n \u0304\n\u03c0 + = |udi\n+\nK = |us\u0304i\n\n \u0304\n\u03c1+ = |udi\n?+\nK = |us\u0304i\n\n138\n\n\f139\n\nGeneration 3\n\nGeneration 2\n\nGeneration 1\n\nLeptons\n\u0012 (1, 2, \u20131/2) \u0013\nelectron neutrino\nelectron\n\u0012\n\u0013\nmuon neutrino\n\u0012 muon \u0013\ntau neutrino\ntau\ntau\n\nmuon\n\nelectron\n\n(1, 1, 1)\n\nHadrons\n(3,\n\u0012 2, 1/6)\n\u0013\nup\n\u0012 down \u0013\ncharm\nstrange\n\u0012\n\u0013\ntop\nbottom\ntop\n\ncharm\n\nup\n\n(3, 1, \u20132/3)\n\nbottom\n\nstrange\n\ndown\n\n(3, 1, 1/3)\n\n1 Generation Only\n\nHiggs\n(1, 2, \u20131/2)\n\n\f"}