{"id": "http://arxiv.org/abs/cond-mat/0201464v1", "guidislink": true, "updated": "2002-01-25T14:21:26Z", "updated_parsed": [2002, 1, 25, 14, 21, 26, 4, 25, 0], "published": "2002-01-25T14:21:26Z", "published_parsed": [2002, 1, 25, 14, 21, 26, 4, 25, 0], "title": "On the correct entropic form for systems with power-law behaviour: the\n  case of dissipative maps", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0201152%2Ccond-mat%2F0201170%2Ccond-mat%2F0201513%2Ccond-mat%2F0201464%2Ccond-mat%2F0201394%2Ccond-mat%2F0201537%2Ccond-mat%2F0201461%2Ccond-mat%2F0201223%2Ccond-mat%2F0201476%2Ccond-mat%2F0201511%2Ccond-mat%2F0201442%2Ccond-mat%2F0201316%2Ccond-mat%2F0201024%2Ccond-mat%2F0201282%2Ccond-mat%2F0201161%2Ccond-mat%2F0201382%2Ccond-mat%2F0201117%2Ccond-mat%2F0201155%2Ccond-mat%2F0201541%2Ccond-mat%2F0201029%2Ccond-mat%2F0201272%2Ccond-mat%2F0201261%2Ccond-mat%2F0201118%2Ccond-mat%2F0201344%2Ccond-mat%2F0201132%2Ccond-mat%2F0201392%2Ccond-mat%2F0201172%2Ccond-mat%2F0201484%2Ccond-mat%2F0201452%2Ccond-mat%2F0401422%2Ccond-mat%2F0401265%2Ccond-mat%2F0401381%2Ccond-mat%2F0401430%2Ccond-mat%2F0401144%2Ccond-mat%2F0401191%2Ccond-mat%2F0401543%2Ccond-mat%2F0401111%2Ccond-mat%2F0401525%2Ccond-mat%2F0401322%2Ccond-mat%2F0401094%2Ccond-mat%2F0401080%2Ccond-mat%2F0401634%2Ccond-mat%2F0401249%2Ccond-mat%2F0401330%2Ccond-mat%2F0401017%2Ccond-mat%2F0401208%2Ccond-mat%2F0401022%2Ccond-mat%2F0401210%2Ccond-mat%2F0401487%2Ccond-mat%2F0401092%2Ccond-mat%2F0401569%2Ccond-mat%2F0401207%2Ccond-mat%2F0401535%2Ccond-mat%2F0401331%2Ccond-mat%2F0401149%2Ccond-mat%2F0401180%2Ccond-mat%2F0401024%2Ccond-mat%2F0401145%2Ccond-mat%2F0401378%2Ccond-mat%2F0401161%2Ccond-mat%2F0401469%2Ccond-mat%2F0401576%2Ccond-mat%2F0401166%2Ccond-mat%2F0401280%2Ccond-mat%2F0401252%2Ccond-mat%2F0401069%2Ccond-mat%2F0401291%2Ccond-mat%2F0401070%2Ccond-mat%2F0401644%2Ccond-mat%2F0401120%2Ccond-mat%2F0401359%2Ccond-mat%2F0401138%2Ccond-mat%2F0401531%2Ccond-mat%2F0401627%2Ccond-mat%2F0401250%2Ccond-mat%2F0401179%2Ccond-mat%2F0401619%2Ccond-mat%2F0401651%2Ccond-mat%2F0401558%2Ccond-mat%2F0401156%2Ccond-mat%2F0401616%2Ccond-mat%2F0401465%2Ccond-mat%2F0401636%2Ccond-mat%2F0401155%2Ccond-mat%2F0401637%2Ccond-mat%2F0401021%2Ccond-mat%2F0401016%2Ccond-mat%2F0401262%2Ccond-mat%2F0401261%2Ccond-mat%2F0401594%2Ccond-mat%2F0401603%2Ccond-mat%2F0401591%2Ccond-mat%2F0401082%2Ccond-mat%2F0401160%2Ccond-mat%2F0401475%2Ccond-mat%2F0401394%2Ccond-mat%2F0401468%2Ccond-mat%2F0401542%2Ccond-mat%2F0401533%2Ccond-mat%2F0401125%2Ccond-mat%2F0401357&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On the correct entropic form for systems with power-law behaviour: the\n  case of dissipative maps"}, "summary": "Maximum entropy principle does not seem to distinguish between the use of\nTsallis and Renyi entropies as either of them may be used to derive similar\npower-law distributions. In this paper, we address the question whether the\nRenyi entropy is equally suitable to describe those systems with power-law\nbehaviour, where the use of the Tsallis entropy is relevant. We discuss a\nspecific class of dynamical systems, namely, one dimensional dissipative maps\nat chaos threshold and make our study from two aspects: i) power-law\nsensitivity to the initial conditions and the rate of entropy increase, ii)\ngeneralized bit cumulants. We present evidence that the Tsallis entropy is the\nmore appropriate entropic form for such studies as opposed to Renyi form.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0201152%2Ccond-mat%2F0201170%2Ccond-mat%2F0201513%2Ccond-mat%2F0201464%2Ccond-mat%2F0201394%2Ccond-mat%2F0201537%2Ccond-mat%2F0201461%2Ccond-mat%2F0201223%2Ccond-mat%2F0201476%2Ccond-mat%2F0201511%2Ccond-mat%2F0201442%2Ccond-mat%2F0201316%2Ccond-mat%2F0201024%2Ccond-mat%2F0201282%2Ccond-mat%2F0201161%2Ccond-mat%2F0201382%2Ccond-mat%2F0201117%2Ccond-mat%2F0201155%2Ccond-mat%2F0201541%2Ccond-mat%2F0201029%2Ccond-mat%2F0201272%2Ccond-mat%2F0201261%2Ccond-mat%2F0201118%2Ccond-mat%2F0201344%2Ccond-mat%2F0201132%2Ccond-mat%2F0201392%2Ccond-mat%2F0201172%2Ccond-mat%2F0201484%2Ccond-mat%2F0201452%2Ccond-mat%2F0401422%2Ccond-mat%2F0401265%2Ccond-mat%2F0401381%2Ccond-mat%2F0401430%2Ccond-mat%2F0401144%2Ccond-mat%2F0401191%2Ccond-mat%2F0401543%2Ccond-mat%2F0401111%2Ccond-mat%2F0401525%2Ccond-mat%2F0401322%2Ccond-mat%2F0401094%2Ccond-mat%2F0401080%2Ccond-mat%2F0401634%2Ccond-mat%2F0401249%2Ccond-mat%2F0401330%2Ccond-mat%2F0401017%2Ccond-mat%2F0401208%2Ccond-mat%2F0401022%2Ccond-mat%2F0401210%2Ccond-mat%2F0401487%2Ccond-mat%2F0401092%2Ccond-mat%2F0401569%2Ccond-mat%2F0401207%2Ccond-mat%2F0401535%2Ccond-mat%2F0401331%2Ccond-mat%2F0401149%2Ccond-mat%2F0401180%2Ccond-mat%2F0401024%2Ccond-mat%2F0401145%2Ccond-mat%2F0401378%2Ccond-mat%2F0401161%2Ccond-mat%2F0401469%2Ccond-mat%2F0401576%2Ccond-mat%2F0401166%2Ccond-mat%2F0401280%2Ccond-mat%2F0401252%2Ccond-mat%2F0401069%2Ccond-mat%2F0401291%2Ccond-mat%2F0401070%2Ccond-mat%2F0401644%2Ccond-mat%2F0401120%2Ccond-mat%2F0401359%2Ccond-mat%2F0401138%2Ccond-mat%2F0401531%2Ccond-mat%2F0401627%2Ccond-mat%2F0401250%2Ccond-mat%2F0401179%2Ccond-mat%2F0401619%2Ccond-mat%2F0401651%2Ccond-mat%2F0401558%2Ccond-mat%2F0401156%2Ccond-mat%2F0401616%2Ccond-mat%2F0401465%2Ccond-mat%2F0401636%2Ccond-mat%2F0401155%2Ccond-mat%2F0401637%2Ccond-mat%2F0401021%2Ccond-mat%2F0401016%2Ccond-mat%2F0401262%2Ccond-mat%2F0401261%2Ccond-mat%2F0401594%2Ccond-mat%2F0401603%2Ccond-mat%2F0401591%2Ccond-mat%2F0401082%2Ccond-mat%2F0401160%2Ccond-mat%2F0401475%2Ccond-mat%2F0401394%2Ccond-mat%2F0401468%2Ccond-mat%2F0401542%2Ccond-mat%2F0401533%2Ccond-mat%2F0401125%2Ccond-mat%2F0401357&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Maximum entropy principle does not seem to distinguish between the use of\nTsallis and Renyi entropies as either of them may be used to derive similar\npower-law distributions. In this paper, we address the question whether the\nRenyi entropy is equally suitable to describe those systems with power-law\nbehaviour, where the use of the Tsallis entropy is relevant. We discuss a\nspecific class of dynamical systems, namely, one dimensional dissipative maps\nat chaos threshold and make our study from two aspects: i) power-law\nsensitivity to the initial conditions and the rate of entropy increase, ii)\ngeneralized bit cumulants. We present evidence that the Tsallis entropy is the\nmore appropriate entropic form for such studies as opposed to Renyi form."}, "authors": ["Ramandeep S. Johal", "Ugur Tirnakli"], "author_detail": {"name": "Ugur Tirnakli"}, "author": "Ugur Tirnakli", "arxiv_comment": "16 pages Revtex, 6 postscript Figs", "links": [{"href": "http://arxiv.org/abs/cond-mat/0201464v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0201464v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0201464v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0201464v1", "journal_reference": null, "doi": null, "fulltext": "On the correct entropic form for systems with power-law\n\narXiv:cond-mat/0201464v1 [cond-mat.stat-mech] 25 Jan 2002\n\nbehaviour: the case of dissipative maps\nRamandeep S. Johal1 and Ugur Tirnakli2\n1\n\nInstitut f\u00fcr Theoretische Physik, Technische Universit\u00e4t Dresden,\n01062 Dresden, Germany\n\n2 Department\n\nof Physics, Faculty of Science, Ege University, 35100\nIzmir, Turkey\n\nrjohal@theory.phy.tu-dresden.de , tirnakli@sci.ege.edu.tr\n\nAbstract\nMaximum entropy principle does not seem to distinguish between the use of\nTsallis and Renyi entropies as either of them may be used to derive similar\npower-law distributions. In this paper, we address the question whether\nthe Renyi entropy is equally suitable to describe those systems with powerlaw behaviour, where the use of the Tsallis entropy is relevant. We discuss\na specific class of dynamical systems, namely, one dimensional dissipative\nmaps at chaos threshold and make our study from two aspects: i) powerlaw sensitivity to the initial conditions and the rate of entropy increase,\nii) generalized bit cumulants. We present evidence that the Tsallis entropy\nis the more appropriate entropic form for such studies as opposed to Renyi\nform.\nPACS Number(s): 05.45.-a, 05.20.-y, 05.70.Ce\n\n1\n\n\fI. INTRODUCTION\n\nAs it is evident, an enormous variety of systems in Nature fall into the domain of validity of Boltzmann-Gibbs (BG) thermostatistics. On the other hand, it is also well-known\nsince long that a variety of anomalous systems exists for which the powerful BG formalism\nexhibits serious difficulties. Some of the examples for such anomalous cases could be the\nlong-ranged interacting systems [1], two-dimensional turbulence [2], nonmarkovian processes [3], granular matter [4], cosmology [5], high energy collisions [6], among others. In\norder to handle some of these anomalous systems, an attempt has been performed in 1988\n[7], which is based on the generalization of the standard BG formalism by postulating a\nnonextensive entropy (Tsallis entropy) of the form\nq\n1\u2212 W\ni=1 pi\nSq \u2261\n(q \u2208 R) ,\nq\u22121\n\nP\n\nand it recovers the standard BG entropy S1 = \u2212\n\nPW\n\ni=1\n\n(1)\n\npi ln pi in the q \u2192 1 limit. This\n\ngeneralization is usually called in the literature as Nonextensive thermostatistics or Tsallis\nthermostatistics (TT) [8], and it has been (still continues to be!) a matter of intensive\nstudies during the past decade [9] both from the point of theoretical foundations of the\nformalism and its applications to various physical systems. The apparent success of TT\ngave rise to an increase of the studies with new entropy definitions [10]. At this point,\nwe would like to mention a trivial but important issue: TT by no means intends to cover\nall of the anomalous physical systems where BG statistics seems to fail. It appears to\nbe useful only for a large class of cases where power-law behaviour is observed. In this\nsense, alternate forms of entropy could of course be useful for other subexponential cases\nand therefore other possible generalizations of the standard formalism could always be\nprojected using different entropic forms. One of these attempts, based on the Renyi\nentropy, has become popular nowadays [11,12]. The form of this entropy is [13]\nSqR\n\nln i pqi\n.\n\u2261\n1\u2212q\nP\n\n2\n\n(2)\n\n\fIt is an extensive quantity (unlike Tsallis entropy), concave for 0 < q < 1 and it recovers\nthe usual BG entropy as a special case when q \u2192 1. It is worth mentioning that the Renyi\nentropy has already been used in the multifractal theory [14]. On the other hand, the\nefforts of establishing a thermostatistics from this entropy seem to be originated from the\nfact that the maximum entropy principle yields the same form of distribution function (of\npower-law type) for both Tsallis and Renyi entropies since they are monotonic functions\nof each other. At this level, there is no a priori reason to choose one of these entropies as\nthe correct entropic form for the systems which exhibit power-law type behaviour. This is\nnot the case for the standard BG entropy, namely, everybody knows that any monotonic\nfunction of the BG entropy also gives the same distribution function of exponential type,\nbut still the correct description of entropy is of course BG. This unclear situation of the\ngeneralized formalism seems to force some authors, for example Arimitsu and Arimitsu,\nto use unclear statements like \"An analytical expression of probability density function of\nvelocity fluctuation is derived with the help of the statistics based on the Tsallis entropy\nor the Renyi entropy\" [15].\nFrom the above discussion, a straightforward question arises naturally: Which of these\ntwo entropic forms is the correct definition for systems exhibiting power-law behaviour ?\nOur motivation in this paper is to try to provide an answer (at least to make the first\nstep) to this important and intriguing question. As already seen, since maximum entropy\nprinciple cannot provide an answer, in order to accomplish this task, we shall focus on\ntwo different issues and make use of the results coming from them. These issues are\ni) power-law sensitivity to the initial conditions and entropy increase rates, ii) generalized\nbit cumulant theory.\n\n3\n\n\fII. POWER-LAW SENSITIVITY TO THE INITIAL CONDITIONS AND\nENTROPY INCREASE RATES\n\nAs is well-known from the theory of dynamical systems (see for example [16,17]), for\none-dimensional dissipative systems, it is possible to introduce a sensitivity function of\ntype\n\u03be(t) \u2261\n\n\u2206x(t)\n,\n\u2206x(0)\u21920 \u2206x(0)\nlim\n\n(3)\n\nwhere \u2206x(0) and \u2206x(t) are discrepancies of the initial conditions at times 0 and t respectively, and it satisfies the differential equation d\u03be/dt = \u03bb1 \u03be, where \u03bb1 is the standard\nLyapunov exponent, thus \u03be(t) is of exponential type (\u03be(t) = e\u03bb1 t ). Consequently, when\n\u03bb1 > 0, the system is strongly sensitive to the initial conditions, whereas it is strongly\ninsensitive if \u03bb1 < 0. On the other hand, there is an infinite number of points for which\n\u03bb1 = 0. This case is called the marginal case and no further analysis of this case is possible within the standard theory. It has been conjectured recently that [18] whenever \u03bb1\nvanishes, the sensitivity function becomes of power-law type\n\u03be(t) = [1 + (1 \u2212 q)\u03bbq t]1/(1\u2212q) ,\n\n(4)\n\nwhich is the solution of the differential equation d\u03be/dt = \u03bbq \u03be q . This new definition of the\nsensitivity function recovers the standard exponential one in the q \u2192 1 limit and here,\n\u03bbq is the generalized Lyapunov exponent and it scales with time inversely as \u03bb1 does, but\nthis time exhibits a power-law behaviour. Consequently, if \u03bbq > 0 and q < 1 (\u03bbq < 0 and\nq > 1), then the system is weakly sensitive (insensitive) to the initial conditions. Most\nimportant case which is in the domain of this scenario is of course the chaos threshold. At\nthis point (where \u03bb1 = 0 but \u03bbq 6= 0), the sensitivity function presents strong fluctuations\nwith time and delimits the power-law growth of the upper bounds of a complex time\ndependence of the sensitivity to the initial conditions. These upper bounds allow us, on\na log-log plot, to measure the slope (\u03be(t) \u221d t1/(1\u2212q) ) from where the proper q = q \u2217 value\n4\n\n\fof the dynamical system under consideration can be estimated. This constitutes method\nI for determining q \u2217 value of a dynamical system at the edge of chaos (or at any point\nwhere \u03bb1 = 0) and it has already been successfully used for a variety of one-dimensional\ndissipative maps such as the standard logistic [18], z-logistic [19], circle [20], z-circular\n[21], single-site [22] and asymmetric logistic [23] maps. At this stage, there is no a priori\nreason for relating this q index with that of the Tsallis entropy. It might well be that the\ncorresponding entropy is the Renyi entropy since it also produces the power-law behaviour.\nThe above concluding statement is also valid for method II of obtaining the q \u2217 value\nof a dynamical system. This method is based on the multifractal geometrical aspects of\nchaotic attractor at the edge of chaos. This geometry is characterized by the multifractal\nsingularity spectrum f (\u03b1), which reflects the fractal dimension of the subset with singularity strenght \u03b1 [14,17]. The f (\u03b1) function is a down-ward parabola-like concave curve\nand at the end points of this curve, the singularity strenght is associated with the most\nconcentrated (\u03b1min ) and the most rarefied (\u03b1max ) regions of the attractor. The scaling\nbehaviour of these regions has been used to propose a new scaling relation as\n1\n1\n1\n=\n\u2212\n,\n\u2217\n1\u2212q\n\u03b1min \u03b1max\n\n(5)\n\nwhich constitutes a completely different way of calculating the proper q \u2217 value of a given\ndynamical system [20]. It is evident from the previous works that, for all dissipative\nsystems studied so far, the results of these two methods for the proper q \u2217 value coincide\nwithin a good precision.\nFinally, the connection between these q \u2217 values and the index q of the Tsallis entropy\nbecame evident after the introduction of method III for finding q \u2217 values . This method\nbasically makes use of a specific generalization of Kolmogorov-Sinai (KS) entropy K1 . For\na chaotic dynamical system, the rate of loss of information can be characterized by this\nentropy and it is defined as the increase of the BG entropy per unit time. Since the Pesin\nequality [24] states that K1 = \u03bb1 if \u03bb1 > 0 and K1 = 0 otherwise, it is clear that the KS\nentropy is deeply related to the Lyapunov exponents. Moreover, the KS entropy could be\n5\n\n\fdefined through\nS1 (t)\n,\nt\u2192\u221e W \u2192\u221e N \u2192\u221e\nt\n\nK1 \u2261 lim lim lim\n\n(6)\n\nwhere t is the number of discrete time steps in case of maps, W is the number of regions\nin the partition of the phase space and N is the number of initial conditions that are\nevolving with time. Analogously, for the marginal cases, a generalized version of the KS\nentropy Kq has been introduced recently [18] by replacing the BG entropy with the Tsallis\nentropy, namely,\nKq \u2261 lim lim lim\n\nt\u2192\u221e W \u2192\u221e N \u2192\u221e\n\nSq (t)\n.\nt\n\n(7)\n\nConsistently, the Pesin equality is expected to become Kq = \u03bbq if \u03bbq > 0 and Kq = 0\notherwise. Using these ideas, the method III [25,26] is based on the conjecture that (i) a\nunique value of q \u2217 exists such that Kq is finite for q = q \u2217 , vanishes for q > q \u2217 and diverges\nfor q < q \u2217 ; (ii) this q \u2217 value coincides with that coming from methods I and II. Latora et\nal. have examined numerically the standard logistic map\nxt+1 = 1 \u2212 a x2t ,\n\n(8)\n\n(where 0 < a \u2264 2 and \u22121 \u2264 xt \u2264 1) both in the chaotic region and at the chaos threshold\n[25]. In the chaotic region (for example, a = 2 case), they numerically verified that Kq\nvanishes (diverges) for any value of q > 1 (q < 1), being finite only for q = 1 (see Fig.1\nof [25]), which implies that the proper q \u2217 value is unity as expected. On the other hand,\nat the chaos threshold, the same structure has also been observed, but this time with an\nimportant exception: Kq vanishes (diverges) for any value of q > q \u2217 (q < q \u2217 ), being finite\nonly for q = q \u2217 = 0.24... (see Fig.4 of [25]). This value coincides with the value of the\nproper q \u2217 coming from other two methods. This structure has been verified not only for\nthe standard logistic map but also a variety of other map families as well [22,23,26].\nNow we are ready to proceed with our main purpose in this effort. We conjecture\nhere that if the Tsallis and Renyi entropies are both the correct choices for a system with\n6\n\n\fpower-law behaviour, then the Renyi entropy should also give us the proper q \u2217 values\nwhenever we use this entropic form instead of the Tsallis entropy in method III. Before\ndemonstrating our results, let us describe the numerical procedure: Firstly, we partition\nthe phase space into W equal cells, then we choose one of these cells and select N initial\nconditions all inside the chosen cell. As time evolves, these N points spread within the\nphase space and it gives a set {Ni (t)} with\n\nPW\n\ni=1\n\nNi (t) = N, \u2200t, which consequently yields\n\na set of probabilities from where one can calculate the entropy. In order to compare our\nresults to those of Latora et al., we numerically check the Renyi entropy case for the\nstandard logistic map both in the chaotic region and at the chaos threshold. The results\nare illustrated in Fig.1. Surprisingly, the expected structure has not been observed. For\nthe chaotic region (Fig.1a), it is seen that, for q = 1 case, the linear entropy increase is\nrealized but very strangely other values of q also give the same result! This shows that\nRenyi entropy is a much less sensitive function as compared to Tsallis entropy with respect\nto changes in the value of q. Similarly, at the chaos threshold (Fig.1b), Renyi entropy does\nnot allow us to distinguish the correct q \u2217 value for which a linear rate is expected. Note\nthat rate of increase of Renyi entropy can be linear if we plot the entropy with respect\nto ln(t) variable, which follows due to the relation between Tsallis and Renyi entropy,\n(compare (1) and (2)). This is another reason for unsuitability of the Renyi entropy;\nfor Tsallis entropy we get the result of strong chaos (BG entropy proportional to t) in\nthe q \u2192 1 limit, but for Renyi entropy, q \u2192 1 implies that BG entropy is proportional\nto ln(t). These observations strongly suggest that the Renyi entropy is not the suitable\nentropic form for these dynamical systems which exhibit power-law behaviour at their\nmarginal points (where \u03bb1 = 0). Although the results which led us to make this claim\nseem rather convincing, it would be no doubt convenient to seek further evidences which\ncan strengthen this claim. This is what we shall try to do in the remainder of the paper\nby making use of the generalized bit cumulants.\n\n7\n\n\fIII. GENERALIZED BIT CUMULANTS\n\nBit statistics is a tool to describe the complicated probability distributions, such as\ngenerated by chaotic systems [17]. In this framework, the first cumulant is the BG entropy\nitself, the second cumulant gives the variance (a measure of fluctuations) of the 'classical'\nbit number bi = \u2212ln pi , and so on. Particularly, the second bit cumulant which is a\ngeneralization of specific heat, can be applied in the context of equilibrium and nonequilibrium phase transitions [27]. The classical bit cumulants can be generalized [28]\nwithin TT formalism. They were applied to symmetric logistic and z-logistic family of\nmaps given by\nxt+1 = 1 \u2212 a|xt |z ,\n\n(9)\n\nwhere the inflexion parameter z > 1, 0 < a \u2264 2 and \u22121 \u2264 x \u2264 1 and t = 0, 1, 2, ....\nApplications have also been found for asymmetric family of logistic maps [29], given by\n\nxt+1 =\n\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f3\n\nz1\n\n1 \u2212 a|xt | , if xt \u2265 0\nz2\n\n1 \u2212 a|xt | , if xt \u2264 0\n\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8fd\n\n,\n\n(10)\n\n\uf8f4\n\uf8f4\n\uf8fe\n\nwhere zi > 1. We briefly summarise the motivation and also the information obtained\nfrom these applications, as we intend to apply this approach to elucidate the difference in\nthe use of Renyi and Tsallis entropies.\nThe generalized second bit cumulant, which gives variance of the Tsallis bit number\n\u2212[ai ]q \u2261\n\n(pi )q\u22121 \u22121\n,\n1\u2212q\n\nis given by\n(T )\nC2\n\n\"\n\n#\n\nX\nX\n1\n2q\u22121\n(p\n)\n\u2212\n(\n(pi )q )2 .\n=\ni\n2\n(1 \u2212 q)\ni\ni\n\n(11)\n\nFor q \u2192 1, (11) approaches the standard bit variance,\nC2 =\n\nX\n\n(ln pi )2 pi \u2212 (\n\nX\n\npi ln pi )2 .\n\n(12)\n\ni\n\ni\n\n(T )\n\nIt was observed in [28] that the ratio C2 /C2 evaluated in the chaotic region of the map\n(9), gives a scaling factor referred to as 'slope' in this paper (see Figs.), whose value\n8\n\n\fdepends on values of q as well as the inflexion parameter z. Naturally, the slope tends\nto unity for q \u2192 1. Less trivially, it was observed that the slope tends to unity also for\nz \u2192 \u221e. In other words, increasing z value within the map-family, has the same effect\non the quantifier 'slope' as the effect of taking to unity, the q parameter entering in its\ndefinition. Thus the otherwise free parameter q in (11) behaves analogous to the proper q \u2217\nvalue, which shows a monotonic decrease with increasing z values [19]. This observation\nwas used to conjecture the behaviour of proper index q \u2217 versus (z1 , z2 ) pairs [29] in maps\n(10) at chaos threshold. The actual behaviour obtained from finding q \u2217 values for these\nmaps by using the previously introduced methods [23], agree with the conjecture of [29].\nThis implies that generalized second bit cumulant (11) can be consistently applied in such\nan analysis.\nCan we have generalization of bit-cumulants based on the Renyi entropy ? If such\na possibility exists, then these new quantities may be used to study the implications on\nthe above mentioned maps, and a comparison be made of the predictions derived from\nTsallis based bit-cumulants and Renyi based ones. This task of a new generalization is\nnot a straightforward one, in view of the fact that there is no generalized bit number\ncorresponding to the Renyi entropy, i.e., the latter cannot be written as usual mean\nover some bit numbers, unlike the cases of BG and Tsallis entropies. In fact, Renyi\nentropy can be expressed only as a kind of nonlinear average [30]. Recently, however,\na step was made in this direction by one of the authors [31]. Specifically, the discrete\nderivative operator can be used to generate two types of bit cumulants, say type A and\ntype B. Type A cumulants are Tsallis type, of the kind formulated in [28]. These are\nnonextensive quantities with respect to independent subsystems and preserve the standard\nrelations between bit-moments and cumulants, as do the cumulants and moments of a\nprobability distribution for a certain random variable. Type B 'cumulants' are however\nextensive quantites but do not preserve the standard relations between bit-moments and\ncumulants. Still, the approach allows us to clearly distinguish the separate origins of\nTsallis and Renyi entropies, based on the use of discrete derivative. Particularly, the first\n9\n\n\fbit cumulant of type B is the Renyi entropy, the second bit cumulant is another positive\nvalued q-generalization of the standard bit variance,\n(R)\nC2\n\n#\n\n\"\n\nX\nX\n1\n2q\u22121\n(pi )q ,\n(p\n)\n\u2212\n2ln\n=\nln\ni\n(1 \u2212 q)2\ni\ni\n\n(13)\n\nIt also recovers the form (12) in the limit q \u2192 1. Thus it is interesting to see the\napplication of (13) analogous to that of (11) for the 1-d dissipative maps. We expect that\nany difference in the predictions based on (13) as compared to those of (11), also reflects\nthe separate implications for Renyi and Tsallis entropies for such systems.\nIn the following, we compare the results obtained from using the generalized second\nbit-cumulants (11) and (13). In Fig. 2a, the results for symmetric maps (9) are given. The\n(R)\n\nslope which implies the ratio C2 /C2 , shows a non-monotonic behaviour with increasing\n(T )\n\nz values. This can be contrasted with the monotonic decrease of the ratio C2 /C2 , as\nshown in Fig. 2b. Similarly, for asymmetric maps (10), we see separate trends as is clear\nby comparing Figs. 3a and 3b.\nThis makes us to conclude that while the q parameter in the definition of generalized\n(T )\n\ncumulant C2\n\nbehaves like the q \u2217 parameter inferred from the sensitivity to initial con(R)\n\nditions at chaos threshold (method I), the q parameter in the definition C2\n\nserves no\n\nsuch connection. Thus this generalization of the standard cumulants, which are related\nto Renyi entropy, are inappropriate for such studies. This clearly strengthens our claim\nthat the Renyi entropy is not the appropriate entropic form for such dynamical systems\nexhibiting power-law behaviour.\n\nIV. RATE OF ENTROPY INCREASE REVISITED\n\nSo far, we have argued and shown that although it is expected to be applicable to systems exhibiting power law behaviour, Renyi entropy is not a suitable measure to quantify\nthe rate of entropy increase at points of power-law sensitivity in 1-d maps. However,\nTsallis entropy qualifies as the appropriate measure for this purpose. A natural question\n10\n\n\ffollows: Is Tsallis entropy the unique measure in this regard ? In this section, we propose\nthat Tsallis entropy is not the unique measure of entropy which can give a linear rate of\nincrease at chaos threshold. We exemplify below by proposing an alternative nonextensive\nentropy which can also yield a linear rate of increase. However, our conjecture is that the\nTsallis entropy seems to be the unique entropy which yields the same q \u2217 as obtained from\nthe modified sensitivity function (4) and multifractal spectrum (5), i.e., methods I and II\nto determine q \u2217 . To understand this role of the Tsallis entropy, we have to appreciate the\nimplication of Pesin's equality.\nFirst, let us discuss the case of strong exponential sensitivity \u03bb1 > 0. In (6) assuming\nequiprobability, pi = 1/M(t), where M(t) are the number of microstates or cells occupied\nat time t, we have\nK1 = lim lim lim\n\nt\u2192\u221e W \u2192\u221e N \u2192\u221e\n\n1\nln M(t).\nt\n\n(14)\n\nStandard Pesin's equality K1 = \u03bb1 allows us to relate the above expression with exponential sensitivity function. As a result, we get\n\u03be(t) = M(t).\n\n(15)\n\nIn other words, for strong exponential sensitivity the number of states increase linearly\nwith the distance between trajectories for all times t > 0.\nWhen \u03bb1 = 0, the use of modified sensitivity function (4) is suggested. Then we have\n\u03bbq > 0. Using the definition (7) of Kq and assuming equiprobability, we get\n1 M(t)1\u2212q \u2212 1\n.\nt\u2192\u221e W \u2192\u221e N \u2192\u221e t\n1\u2212q\n\nKq = lim lim lim\n\n(16)\n\nNow postulating the generalized Pesin equality for the proper q \u2217 value of the entropic\nindex (which yields the linear rate of entropy increase), Kq\u2217 = \u03bbq\u2217 , we get from (4) and\n(16), the same relation as (15) even for points of power-law sensitivity. Thus the use of the\nTsallis entropy in the definition of Kq ensures that the linear relation (15) is preserved.\nFinally, this automatically implies that the critical q \u2217 value obtained in methods I and III\nare identical.\n11\n\n\fNow consider an alternate entropic form\nSq =\n\n1\u2212\n\n(1+ln q)\n\npi\nq\u22121\n\nP\n\ni\n\n(q \u2208 R+ ) ,\n\n(17)\n\nwhich has the same nonextensive property as the Tsallis entropy. It approximates the\nTsallis entropy for values of q very near to one, and thus goes to BG entropy in the limit\nq \u2192 1. For this entropy, we can also obtain a linear rate of increase at chaos threshold,\nfor certain critical value of q = qc . But in this case, qc 6= q \u2217 , where q \u2217 is calculated\nfrom methods I and II. Instead, we have 1 + ln qc = q \u2217 . A more thorough understanding\nof generalized Pesin's equality is required to relate such other entropies with the issue\nof power-law sensitivity. At the moment, we only state that there are other entropic\nforms which can give a linear rate of increase, but the entropic form compatible with the\ngeneralized sensitivty function (4), in the sense that methods I and III should yield same\nq \u2217 values, is the Tsallis entropy.\n\nV. CONCLUSIONS\n\nIn this study, the appropriate entropic form for systems exhibiting power-law behaviour\nhas been tried to be determined. To accomplish this task, two different issues have been\nanalysed. One of these issues is the sensitivity to initial conditions and the entropy\nincrease rates, the other one is the generalized bit cumulants. From the investigation of\nboth issues, for the dynamical systems at marginal points (where the standard Lyapunov\nexponent vanishes), it is verified that the suitable entropic form is the Tsallis entropy.\nThis could be considered as the first step towards the answer of the intriguing question:\nWhat is the correct entropic form for systems exhibiting power-law behaviour ?\nThe reasons for the success of the Tsallis entropy, we believe, are two-fold: i) Tsallis\nentropy as function of time t, reproduces the correct q \u2192 1 limit of BG entropy proportional to t, ii) Tsallis entropy is a much more sensitive function than Renyi entropy with\nrespect to changes in q value, which helps to determine the proper q \u2217 value in method III.\n12\n\n\fA crucial property of Tsallis entropy is its nonextensivity. It is not certain whether this\nproperty plays significant role in such studies. As has been argued in [32], a conditional\nentropy which is nonextensive for generic values of q, becomes extensive for the proper\nvalue of q = q \u2217 . It seems that, for such kind of systems with power-law behaviour, what\nis important is NOT to be extensive for all q values, but rather, to be extensive for only\na special value of q (namely q \u2217 ), the value that gives the correct entropy for the system\nunder investigation.\nFinally, it is worth mentioning that we also show that the Tsallis entropy is not the\nunique entropic form which gives a linear entropy increase rate, but on the other hand,\nit seems to be the unique one which provides q \u2217 values consistent with those obtained\nfrom the other two methods (i.e., from the sensitivity function and from the multifractal\nscaling relation).\n\nACKNOWLEDGMENTS\n\nRSJ is grateful to Alexander von Humboldt Foundation, Germany, for financial support.\n\n13\n\n\fREFERENCES\n[1] M.E. Fisher, Arch. Rat. Mech. Anal. 17 (1964) 377; L. Tisza, Annals Phys. 1 (1961)\n1; W. Thirring, Foundations of Physics 20 (1990) 1103; P.T. Landsberg, J. Stat.\nPhys. 35 (1984) 159; D. Pavon, Gen. Rel. and Gravit. 19 (1987) 375.\n[2] X.P. Huang and C.F. Driscoll, Phys. Rev. Lett. 72 (1994) 2187.\n[3] M.O. Caceres, Braz. J. Phys. 29 (1999) 124.\n[4] Y.H. Taguchi and H. Takayashu, Europhys. Lett. 30 (1995) 499.\n[5] H.P. de Oliveira et al., Phys. Rev. D 60 (1999) 121301.\n[6] G. Wilk and Z. Wlodarcsyk, Phys. Rev. D 50 (1994) 2318; T. Alber et al., Eur. Phys.\nJ. C 2 (1998) 643.\n[7] C. Tsallis, J. Stat. Phys. 52 (1988) 479.\n[8] E.M.F. Curado and C. Tsallis, J. Phys. A 24 (1991) L69 [corrigenda: 24 (1991)\n3187 and 25 (1992) 1019]; C. Tsallis, R.S. Mendes and A.R. Plastino, Physica A 261\n(1998) 534.\n[9] C. Tsallis, in \"Nonextensive statistical mechanics and thermodynamics\" eds: S. Abe\nand Y. Okamoto, Series Lecture Notes in Physics (Heidelberg, Springer, 2001).\n[10] E.M.F. Curado, Braz. J. Phys. 29 (1999) 36; P.T. Landsberg and V. Vedral, Phys.\nLett. A 242 (1998) 296; A.R.R. Papa, J. Phys. A 31 (1998) 5271; R.S. Johal, Phys.\nRev. E 58 (1998) 4147.\n[11] E.K. Lenzi, R.S. Mendes and L.R. da Silva, Physica A 280 (2000) 337.\n[12] J. Naudts and M. Czachor, arXiv: cond-mat/0106324 and arXiv: cond-mat/0110077.\n[13] A. Renyi, Probability theory, (North Holland, 1970).\n[14] T.C. Halsey et al, Phys. Rev. A 33 (1986) 1141.\n14\n\n\f[15] T. Arimitsu and N. Arimitsu, Physica A 295 (2001) 177; arXiv: cond-mat/0109132.\n[16] R.C. Hilborn, Chaos and Nonlinear Dynamics (Oxford University Press, New York,\n1994)\n[17] C. Beck and F. Schlogl, Thermodynamics of chaotic systems (Cambridge University\nPress, Cambridge, 1993)\n[18] C. Tsallis, A.R. Plastino and W.-M. Zheng, Chaos, Solitons and Fractals 8 (1997)\n885.\n[19] U.M.S. Costa, M.L. Lyra, A.R. Plastino and C. Tsallis, Phys. Rev. E 56 (1997) 245.\n[20] M.L. Lyra and C. Tsallis, Phys. Rev. Lett. 80 (1998) 53.\n[21] U. Tirnakli, C. Tsallis and M.L. Lyra, Eur. Phys. J. B 11 (1999) 309.\n[22] U. Tirnakli, Physica A 305 (2002) 118.\n[23] U. Tirnakli, C. Tsallis and M.L. Lyra, Phys. Rev. E (March 2002), in press.\n[24] Ya. Pesin, Russ. Math. Surveys 32 (1977) 55.\n[25] V. Latora, M. Baranger, A. Rapisarda and C. Tsallis, Phys. Lett. A 273 (2000) 97.\n[26] U. Tirnakli, G.F.J. Ananos and C. Tsallis, Phys. Lett. A 289 (2001) 51.\n[27] F. Schl\u00f6gl, Z. Phys. B 52 (1983) 51.\n[28] R. Rai and R.S. Johal, Physica A 294 (2001) 155.\n[29] U. Tirnakli, Phys. Rev. E 62 (2000) 7857.\n[30] A. Kolmogorov, Atti della R. Accademia Nazionale dei Lincei 12, 388 (1930); M.\nNagumo, Japan. J. Math. 7, 71 (1930).\n[31] R.S. Johal, arXiv: cond-mat/0110310, to appear in Phys. Lett. A.\n[32] W. Tatsuaki and S. Takeshi, Physica A 301 (2001) 284; Physica A 305 (2002) 185.\n15\n\n\fFigure Captions\n\nFigure 1 - Time evolution of the Renyi entropy at the chaotic region (a) and at the\nchaos threshold (b) for various q values. Inset of (b): The behaviour of the Renyi entropy\nfor lnt .\n\nFigure 2 - The behaviour of the slope as a function of the map inflexion parameter\nz for the Renyi (a) and Tsallis (b) cases.\n\nFigure 3 - The behaviour of the slope as a function of the map inflexion parameter\npairs (z1 , z2 ) for the Renyi (a) and Tsallis (b) cases.\n\n16\n\n\fFig 1a\n14\n\n(a)\n\nq=1\nq=1.2\nq=0.6\nq=0.1\n\n12\n\nRenyi entropy\n\n10\n\n8\n\n6\n\n4\n\na=1.99\n\n2\n\n0\n0\n\n5\n\n10\n\n15\n\ntime\n\n20\n\n25\n\n\fFig 1b\n\n2\n\nRenyi entropy\n\n(b)\n\nq=0.24\nq=0.5\nq=1\nq=0.1\n\na=1.40115518909\n\n2\n\n1\n\n1\n\n1\n\n10\n\n0\n0\n\n5\n\n10\n\n15\n\n20\n\ntime\n\n25\n\n30\n\n35\n\n40\n\n\fFig 2a\n1.00\n\n(a)\n\nRenyi\n0.99\n\nq=0.98\n\nslope\n\n0.98\n\n0.97\n\n0.96\n\n0.95\n\nq=0.97\n\n0.94\n\n0.93\n0\n\n2\n\n4\n\n6\n\nz\n\n8\n\n10\n\n12\n\n\fFig 2b\n1.9\n\nTsallis\n\n(b)\n\n1.8\n\n1.7\n\nslope\n\nq=0.97\n1.6\n\n1.5\n\n1.4\n\n1.3\n\nq=0.98\n1.2\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nz\n\n7\n\n8\n\n9\n\n10\n\n11\n\n\fFig 3a\n1.00\n\nRenyi\n\n(a)\n\n0.99\n0.98\n\n(2,z2)\n\n(z1,2)\n\nslope\n\n0.97\n0.96\n0.95\n0.94\n\nq=0.97\n\n0.93\n0.92\n-12 -10 -8\n\n-6\n\n-4\n\n-2\n\n0\n\nz2\u2212z1\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n\fFig 3b\n1.9\n\n(b)\n\nTsallis\n1.8\n\n1.7\n\nslope\n\n(z1,2)\n\n(2,z2)\n\n1.6\n\n1.5\n\n1.4\n\n1.3\n\nq=0.97\n1.2\n-12 -10 -8\n\n-6\n\n-4\n\n-2\n\n0\n\nz2\u2212z1\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n\f"}