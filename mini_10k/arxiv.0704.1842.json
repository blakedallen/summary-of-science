{"id": "http://arxiv.org/abs/0704.1842v2", "guidislink": true, "updated": "2007-09-13T15:08:17Z", "updated_parsed": [2007, 9, 13, 15, 8, 17, 3, 256, 0], "published": "2007-04-13T23:11:27Z", "published_parsed": [2007, 4, 13, 23, 11, 27, 4, 103, 0], "title": "Fairness Provision in the IEEE 802.11e Infrastructure Basic Service Set", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0704.2593%2C0704.1503%2C0704.1204%2C0704.1701%2C0704.2222%2C0704.1737%2C0704.0974%2C0704.3082%2C0704.0825%2C0704.3006%2C0704.2662%2C0704.3690%2C0704.0204%2C0704.3205%2C0704.1279%2C0704.2590%2C0704.2007%2C0704.0585%2C0704.3889%2C0704.0474%2C0704.0463%2C0704.2069%2C0704.2308%2C0704.2299%2C0704.1576%2C0704.0777%2C0704.1679%2C0704.0810%2C0704.3282%2C0704.2680%2C0704.3448%2C0704.0382%2C0704.1686%2C0704.2850%2C0704.1066%2C0704.3736%2C0704.1469%2C0704.0249%2C0704.1944%2C0704.1401%2C0704.1538%2C0704.0935%2C0704.1547%2C0704.3127%2C0704.1266%2C0704.1061%2C0704.0995%2C0704.1792%2C0704.1416%2C0704.3219%2C0704.2862%2C0704.0391%2C0704.1096%2C0704.3412%2C0704.3295%2C0704.3852%2C0704.0614%2C0704.2356%2C0704.1008%2C0704.3924%2C0704.3187%2C0704.1591%2C0704.1288%2C0704.1842%2C0704.1069%2C0704.1558%2C0704.1754%2C0704.3667%2C0704.3270%2C0704.0298%2C0704.3827%2C0704.0251%2C0704.0425%2C0704.0297%2C0704.3753%2C0704.1781%2C0704.2938%2C0704.0553%2C0704.2975%2C0704.1224%2C0704.1577%2C0704.1484%2C0704.0771%2C0704.3820%2C0704.1419%2C0704.3672%2C0704.0434%2C0704.1475%2C0704.1729%2C0704.3392%2C0704.2947%2C0704.0427%2C0704.1293%2C0704.0181%2C0704.1969%2C0704.0926%2C0704.0487%2C0704.1873%2C0704.1490%2C0704.3773%2C0704.2830&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Fairness Provision in the IEEE 802.11e Infrastructure Basic Service Set"}, "summary": "Most of the deployed IEEE 802.11e Wireless Local Area Networks (WLANs) use\ninfrastructure Basic Service Set (BSS) in which an Access Point (AP) serves as\na gateway between wired and wireless domains. We present the unfairness problem\nbetween the uplink and the downlink flows of any Access Category (AC) in the\n802.11e Enhanced Distributed Channel Access (EDCA) when the default settings of\nthe EDCA parameters are used. We propose a simple analytical model to calculate\nthe EDCA parameter settings that achieve weighted fair resource allocation for\nall uplink and downlink flows. We also propose a simple model-assisted\nmeasurement-based dynamic EDCA parameter adaptation algorithm. Moreover, our\ndynamic solution addresses the differences in the transport layer and the\nMedium Access Control (MAC) layer interactions of User Datagram Protocol (UDP)\nand Transmission Control Protocol (TCP). We show that proposed Contention\nWindow (CW) and Transmit Opportunity (TXOP) limit adaptation at the AP provides\nfair UDP and TCP access between uplink and downlink flows of the same AC while\npreserving prioritization among ACs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0704.2593%2C0704.1503%2C0704.1204%2C0704.1701%2C0704.2222%2C0704.1737%2C0704.0974%2C0704.3082%2C0704.0825%2C0704.3006%2C0704.2662%2C0704.3690%2C0704.0204%2C0704.3205%2C0704.1279%2C0704.2590%2C0704.2007%2C0704.0585%2C0704.3889%2C0704.0474%2C0704.0463%2C0704.2069%2C0704.2308%2C0704.2299%2C0704.1576%2C0704.0777%2C0704.1679%2C0704.0810%2C0704.3282%2C0704.2680%2C0704.3448%2C0704.0382%2C0704.1686%2C0704.2850%2C0704.1066%2C0704.3736%2C0704.1469%2C0704.0249%2C0704.1944%2C0704.1401%2C0704.1538%2C0704.0935%2C0704.1547%2C0704.3127%2C0704.1266%2C0704.1061%2C0704.0995%2C0704.1792%2C0704.1416%2C0704.3219%2C0704.2862%2C0704.0391%2C0704.1096%2C0704.3412%2C0704.3295%2C0704.3852%2C0704.0614%2C0704.2356%2C0704.1008%2C0704.3924%2C0704.3187%2C0704.1591%2C0704.1288%2C0704.1842%2C0704.1069%2C0704.1558%2C0704.1754%2C0704.3667%2C0704.3270%2C0704.0298%2C0704.3827%2C0704.0251%2C0704.0425%2C0704.0297%2C0704.3753%2C0704.1781%2C0704.2938%2C0704.0553%2C0704.2975%2C0704.1224%2C0704.1577%2C0704.1484%2C0704.0771%2C0704.3820%2C0704.1419%2C0704.3672%2C0704.0434%2C0704.1475%2C0704.1729%2C0704.3392%2C0704.2947%2C0704.0427%2C0704.1293%2C0704.0181%2C0704.1969%2C0704.0926%2C0704.0487%2C0704.1873%2C0704.1490%2C0704.3773%2C0704.2830&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Most of the deployed IEEE 802.11e Wireless Local Area Networks (WLANs) use\ninfrastructure Basic Service Set (BSS) in which an Access Point (AP) serves as\na gateway between wired and wireless domains. We present the unfairness problem\nbetween the uplink and the downlink flows of any Access Category (AC) in the\n802.11e Enhanced Distributed Channel Access (EDCA) when the default settings of\nthe EDCA parameters are used. We propose a simple analytical model to calculate\nthe EDCA parameter settings that achieve weighted fair resource allocation for\nall uplink and downlink flows. We also propose a simple model-assisted\nmeasurement-based dynamic EDCA parameter adaptation algorithm. Moreover, our\ndynamic solution addresses the differences in the transport layer and the\nMedium Access Control (MAC) layer interactions of User Datagram Protocol (UDP)\nand Transmission Control Protocol (TCP). We show that proposed Contention\nWindow (CW) and Transmit Opportunity (TXOP) limit adaptation at the AP provides\nfair UDP and TCP access between uplink and downlink flows of the same AC while\npreserving prioritization among ACs."}, "authors": ["Feyza Keceli", "Inanc Inan", "Ender Ayanoglu"], "author_detail": {"name": "Ender Ayanoglu"}, "author": "Ender Ayanoglu", "links": [{"href": "http://arxiv.org/abs/0704.1842v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0704.1842v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.OH", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.OH", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0704.1842v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0704.1842v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "1\n\nFairness Provision in the IEEE 802.11e\nInfrastructure Basic Service Set\n\n\u2020\n\narXiv:0704.1842v2 [cs.OH] 13 Sep 2007\n\nFeyza Keceli, Inanc Inan, and Ender Ayanoglu\nCenter for Pervasive Communications and Computing\nDepartment of Electrical Engineering and Computer Science\nThe Henry Samueli School of Engineering\nUniversity of California, Irvine, 92697-2625\nEmail: {fkeceli, iinan, ayanoglu}@uci.edu\n\nAbstract\nMost of the deployed IEEE 802.11e Wireless Local Area Networks (WLANs) use infrastructure Basic Service\nSet (BSS) in which an Access Point (AP) serves as a gateway between wired and wireless domains. We present\nthe unfairness problem between the uplink and the downlink flows of any Access Category (AC) in the 802.11e\nEnhanced Distributed Channel Access (EDCA) when the default settings of the EDCA parameters are used. We\npropose a simple analytical model to calculate the EDCA parameter settings that achieve weighted fair resource\nallocation for all uplink and downlink flows. We also propose a simple model-assisted measurement-based dynamic\nEDCA parameter adaptation algorithm. Moreover, our dynamic solution addresses the differences in the transport\nlayer and the Medium Access Control (MAC) layer interactions of User Datagram Protocol (UDP) and Transmission\nControl Protocol (TCP). We show that proposed Contention Window (CW) and Transmit Opportunity (TXOP) limit\nadaptation at the AP provides fair UDP and TCP access between uplink and downlink flows of the same AC while\npreserving prioritization among ACs.\n\nI. I NTRODUCTION\nIEEE 802.11 Wireless Local Area Network (WLAN) is built around a Basic Service Set (BSS) [1].\nWhile a number of stations may gather to form an independent BSS with no connectivity to the wired\nnetwork, the common deployment is the infrastructure BSS which includes an Access Point (AP). The\nAP provides the connection to the wired network.\nThe IEEE 802.11 standard [1] defines Distributed Coordination Function (DCF) as a contention based\nMedium Access Control (MAC) mechanism. The 802.11e standard [2] updates the MAC layer of the\n\u2020\n\nThis work is supported by the Center for Pervasive Communications and Computing, and by National Science Foundation under Grant\nNo. 0434928. Any opinions, findings, and conclusions or recommendations expressed in this material are those of authors and do not\nnecessarily reflect the view of the National Science Foundation.\n\n\f2\n\nformer 802.11 standard for Quality-of-Service (QoS) provision. In particular, the Enhanced Distributed\nChannel Access (EDCA) function of 802.11e is an enhancement of the DCF. The EDCA scheme (similarly\nto DCF) uses Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) and slotted Binary\nExponential Backoff (BEB) mechanism as the basic access method. The major enhancement to support\nQoS is that EDCA differentiates packets using different priorities and maps them to specific Access\nCategories (ACs) that use separate queues at a station. Each ACi within a station (0 \u2264 i \u2264 3) contends for\nthe channel independently of the others. Levels of services are provided through different assignments of\nthe AC-specific EDCA parameters; Contention Window (CW) sizes, Arbitration Interframe Space (AIFS)\nvalues, and Transmit Opportunity (TXOP) limits.\nThe DCF and the EDCA are defined such that each station in a BSS uses the same contention parameter\nset. Therefore, fair access can be achieved in the MAC layer for all the contending stations in terms of the\naverage number of granted transmissions, over a sufficiently long interval. However, this does not translate\ninto achieving fair share of bandwidth between uplink and downlink flows in the 802.11e infrastructure\nBSS. An AC of the AP which serves all downlink flows has the same access priority with the same AC\nof the stations that serve uplink flows. Therefore, an approximately equal number of accesses that an\nuplink AC may get is shared among all downlink flows in the same AC of the AP. This leads to the\nuplink/downlink unfairness problem in the WLAN where each individual downlink flow gets comparably\nlower bandwidth than each individual uplink flow gets at high load. This phenomenon will be described\nfurther in Section II-A.\nWe deal with weighted fair channel access between the uplink and the downlink flows of the same\nAC in the IEEE 802.11e infrastructure BSS. Using a simple analytical approach, we calculate the EDCA\nparameter settings that achieve a given utilization ratio between the uplink and the downlink transmissions.\nComparing with simulation results, we noticed that sticking only with analytical results that are based\non ideal condition assumptions may result in inaccuracies in a real WLAN scenario. Therefore, we also\npropose a simple model-assisted measurement-based dynamic EDCA parameter adaptation algorithm that\nprovides weighted fair resource allocation in an arbitrary scenario.\nMost of the data traffic in the Internet is carried by Transmission Control Protocol (TCP), while\nmost of the real-time applications use User Datagram Protocol (UDP). UDP employs one-way unreliable\ncommunication. On the other hand, TCP defines reliable bi-directional communication where the forward\nlink data rate depends on the rate of received Acknowledgment (ACK) packets in the backward link.\n\n\f3\n\nAnother key contribution of this study is that our solution considers the effects of this difference on the\ndesign of the weighted fairness support algorithm.\nII. BACKGROUND\nIn this section, we first present the uplink/downlink unfairness problem in the IEEE 802.l1(e) WLAN\nat high traffic load. Next, we provide a brief review of the literature on this subject.\nA. Problem Definition\nIn the 802.11e WLAN, at high load, a bandwidth asymmetry exists between contending upload and\ndownload flows which use the same AC. This is due to the fact that the MAC layer contention parameters\nare all equal for the AP and the stations. If n stations and an AP are always contending for the access to\nthe wireless channel using the same AC, each host ends up having approximately 1/(n + 1) share of the\ntotal transmissions over a long time interval. This results in n/(n + 1) of the transmissions to be in the\nuplink, while only 1/(n + 1) of the transmissions belonging to the downlink flows. This is the WLAN\nuplink/downlink unfairness problem stated previously. The uneven bandwidth share results in downlink\nflows experiencing significantly lower throughput and larger delay. The congestion at the AP may result\nin considerable packet loss depending on the size of interface buffers.\nThe results may even be more catastrophic in the case of TCP flows. The TCP receiver returns TCP\nACK packets to the TCP transmitter in order to confirm the successful reception of data packets. In the\ncase of multiple uplink and downlink flows in the WLAN, returning TCP ACKs of upstream TCP data\nare queued at the AP together with the downstream TCP. When the bandwidth asymmetry in the forward\nand reverse path builds up the queue in the AP, the dropped packets impair the TCP flow and congestion\ncontrol mechanisms which assume equal transmission rate both in the forward and reverse path [3].\nTCP's timeout mechanism initiates a retransmission of a data packet if it has not been acknowledged\nduring a timeout duration. However, any received TCP ACK can cumulatively acknowledge all the data\npackets sent before the data packet for which the ACK is intended to. When the packet loss is severe in the\nAP buffer, downstream flows will experience frequent timeouts resulting in significantly low throughput.\nOn the other hand, due to the cumulative property of TCP ACK mechanism, upstream flows with high\ncongestion windows will not experience such frequent timeouts. In this case, it is a low probability\nthat many consecutive TCP ACK losses occur for the same flow. Conversely, flows with low congestion\nwindow (fewer packets currently on flight) may experience frequent timeouts and decrease their congestion\n\n\f4\n\nwindows even more. Therefore, a number of upstream flows may starve in terms of throughput while\nothers enjoy a high throughput. This results in unfairness between the TCP upstream flows on top of the\nunfairness between the uplink and the downlink.\nFig. 3 shows the average throughput of individual flows for a scenario of 10 uplink UDP, 10 downlink\nUDP, 10 uplink TCP and 10 downlink TCP connections in an ns-2 simulation [4],[5]. Each connection\nis initiated by a separate station. All stations employ 54 Mbps data rate at the physical layer. The packet\nsize is 1500 bytes for all flows. UDP flows are mapped to an AC with CWmin = 31 and CWmax = 511.\nTCP flows use an AC with CWmin = 63 and CWmax = 1023. For both ACs, AIFSN values are set to 2\nand TXOP limits are 0. Other simulation parameters are as stated in Section IV. The results illustrate the\nthroughput unfairness of the uplink and the downlink flows. The throughput unfairness between uplink\nTCP connections is also significant. Moreover, data packet losses at the AP buffer have almost shut down\nall downlink TCP connections.\nB. Related Work\nThere are two groups of studies in the literature related to this work.\nThe first group works within the constraints of the default 802.11 contention parameters. In [6], the\neffect of the AP buffer size in the wireless channel bandwidth allocation for TCP is studied. The proposed\nsolution of [6] is to manipulate advertised receiver windows of the TCP packets at the AP. Uplink/downlink\nfairness problem is studied in [7] using per-flow queueing. A simplified approach is proposed in [8] where\ntwo separate queues for TCP data and ACKs are used. In our previous work, we proposed using congestion\ncontrol and filtering techniques at the MAC layer to solve the TCP uplink unfairness problem [9]. Two\nqueue management strategies are proposed in [10] to improve TCP fairness. A rate-limiter approach is\nused in [11] which requires available instantaneous WLAN bandwidth estimation in both directions.\nThe second group proposes changes at the MAC layer access parameters to achieve improved fairness.\nOur work also falls into this category. AIFS and CW differentiation is proposed for improved fairness and\nchannel utilization in [12]. A simulation-based analysis is carried out for a specific scenario consisting\nof TCP and audio flows both in the uplink and the downlink. An experimental study is carried out in\n[13] to decide on CW and TXOP values of the AP and the stations for a scenario with TCP uplink and\ndownlink flows. Both solutions propose that individual uplink and downlink streams use separate ACs. No\nguidelines are provided on how to decide on the EDCA parameters that achieve fair resource allocation\nfor an arbitrary scenario. Also, the interaction of TCP flow and congestion control mechanisms with\n\n\f5\n\nthe MAC is not addressed. In [14], it is proposed that the AP accesses the channel in Point Interframe\nSpace (PIFS) completion without any backoff when the interface queue size goes over a threshold. The\nuse of TXOP is evaluated in [15] for temporal fairness provisioning among stations employing different\ndata rates. Achieving weighted fairness between uplink and downlink in DCF is studied through mean\nbackoff distribution adjustment in [16]. A mechanism that dynamically tunes CW and TXOP values in\norder to prevent delay asymmetry of realtime UDP flows is proposed in [17]. An adaptive priority control\nmechanism is employed in [18] to balance the uplink and downlink delay of VoIP traffic.\nIII. W EIGHTED FAIR ACCESS\n\nBETWEEN\n\nU PLINK\n\nAND\n\nD OWNLINK F LOWS\n\nIn this section, we first describe the simple analytical model we propose in order to find the AIF S,\nCWmin , and T XOP settings of the ACs that provide weighted fairness between uplink and downlink\nflows. Next, we propose a parameter adaptation algorithm which dynamically updates the analytically\ncalculated CW and TXOP values of the AP regarding simple network measurements. As we will describe\nin Section III-D, our dynamic solution also addresses the effects of the slow-start phase of TCP.\nEvery beacon interval, the AP announces the values of the AC-specific EDCA parameters to the stations.\nThe stations overwrite their EDCA parameter settings with the new values if any change is detected. Due\nto the specific design of the EDCA Parameter Set element in the beacon packet, the stations can only\nemploy CW values that are integer powers of 2, i.e., the AP encodes the corresponding 4-bit fields of\nCWmin and CWmax in an exponent form. A key point which the studies in the literature have missed is\nthat the CW settings of the ACs at the AP are not restricted to the powers of 2. The ACs at the AP may\nuse any value and this value does not have to be equal to what is announced via beacons.\nA. Analytical Model\nFair access between uplink and downlink flows using the same AC can be provided by assigning\ndifferent EDCA parameters for the AP and the stations. This results in two Traffic Classes (TCs) using\nthe same AC. While uplink flows constitute the first TC, downlink flows constitute the second TC. In the\nanalysis, we will treat the case with one AC (thus 2 TCs), since we address the weighted fairness problem\nbetween the uplink and downlink flows that are mapped to the same AC. Moreover, we only formulate\nthe situation when there is only one TC per station, therefore no internal collisions can occur. Note that,\nthis does not cause any loss of generality, since the analysis can be extended for larger number of ACs\nor TCs as in [19], and larger number of ACs per station as in [20],[21].\n\n\f6\n\nOur analysis considers the fact that the difference in AIFS creates the so-called contention zones\nas shown in Fig. 1 [19],[22],[23],[21]. First, we calculate the average collision probability of each TC\naccording to the long term occupancy of AIFS and backoff slots in saturation. The average collision\nprobability of a TC is a function of transmission probabilities of all TCs. Next, we formulate the average\ntransmission probability for each TC, which is a function of average collision probability of the same TC.\nThis results in a set of nonlinear equations which can be solved numerically.\nWe define pci,x as the probability that TCi experiences a collision given that it has observed the medium\nidle for AIF Sx and transmits in the current slot (note AIF Sx \u2265 AIF Si should hold). For notational simplicity, let uplink flows belong to TC0 and downlink flows belong to TC1 . Let di = AIF SNi \u2212AIF SNmin\nwhere AIF SNmin = min(AIF SN0 , AIF SN1 ) and AIF Si = SIF S + AIF SNi * Tslot . Following the\nslot homogeneity assumption of [24], assume that each TCi transmits with constant probability, \u03c4i . Also,\nlet the total number of TCi in the BSS be Ni (note that N1 = 1). Then,\nQ\n(1 \u2212 \u03c4i\u2032 )Ni\u2032\npci,x = 1 \u2212\n\ni\u2032 :di\u2032 \u2264dx\n\n(1 \u2212 \u03c4i )\n\n.\n\n(1)\n\nWe use the Markov chain shown in Fig. 2 to find the long term occupancy of contention zones. Each\nstate represents the nth backoff slot after completion of the AIFSmin idle interval following a transmission\nperiod. The Markov analysis uses the fact that a backoff slot is reached if no transmission occurs in the\nprevious slot. Moreover, the number of states is limited by the maximum idle time between two successive\ntransmissions which is Wmin = min(CWi,max ) for a saturated scenario. The probability that at least one\ntransmission occurs in a backoff slot in contention zone x is\nptr\nx = 1\u2212\n\nY\n\n(1 \u2212 \u03c4i\u2032 )Ni\u2032 .\n\n(2)\n\ni\u2032 :di\u2032 \u2264dx\n\nThe long term occupancy of the backoff slots b\u2032n in Fig. 2 can be obtained from the steady-state solution.\nThen, the average collision probability pci is found by weighing zone specific collision probabilities pci,x\naccording to the long term occupancy of contention zones (thus backoff slots)\npc i =\n\nPWmin\n\n\u2032\nn=di +1 pci,x bn\nPWmin \u2032\nn=di +1 bn\n\n(3)\n\n\u0010\n\u0011\nwhere x = max y | dy = max(dz | dz \u2264 n) which shows x is assigned the highest index value within\nz\n\na set of TCs that have AIFSN smaller than equal to n + AIF SNmin .\n\n\f7\n\nGiven pci , we can calculate the expected number of backoff slots Ei [tbo ] that TCi waits before attempting\na transmission. Let Wi,k = 2min(k,mi ) (CWi,min + 1) \u2212 1 be the CW size of TCi at backoff stage k where\nCWi,max = 2mi (CWi,min + 1) \u2212 1, 0 \u2264 mi < ri . Note that, when the retry limit ri is reached, any packet\nis discarded.\nEi [tbo ] =\n\n\u221e\nX\n\n(prcii )n\n\nn=0\n\nr\nX\nk=1\n\npck\u22121\n(1\ni\n\nr\nWi,k\nWi,k\n1 X k\u22121\n\u2212 pc i )\npci (1 \u2212 pci )\n=\n.\nri\n2\n1 \u2212 pci k=1\n2\n\n(4)\n\nThen as also shown in [23], the transmission probability of TCi can be calculated as\n\u03c4i =\n\n1\n.\nEi [tbo ] + 1\n\n(5)\n\nThe nonlinear system of equations (1)-(5) can be solved numerically to calculate average collision\nand transmission probabilities of each TCi for an arbitrary setting of EDCA parameters. We provide the\nvalidation of the proposed analytical model in [19].\n\nB. Weighted Fairness between Uplink and Downlink Flows\nLet \u03b3i be the probability that the transmitted packet belongs to an arbitrary user from TCi given that\nthe transmission is successful. Also, let psi,n be the probability that a successfully transmitted packet at\nbackoff slot n belongs to ACi . Then,\nW\nmin\nX\n\nps\nb\u2032n P i,n ,\npsj,n\nn=d +1\n\n(6)\n\n\uf8f1\nY\n\uf8f4\n\uf8f2 Ni \u03c4i\n(1 \u2212 \u03c4i\u2032 )Ni\u2032 , if n \u2265 di + 1\n= (1 \u2212 \u03c4i ) i\u2032 :di\u2032 \u2264n\u22121\n\uf8f4\n\uf8f3\n0,\nif n < di + 1.\n\n(7)\n\n\u03b3i =\n\ni\n\npsi,n\n\n\u2200j\n\nLet U denote the utilization ratio between the downlink and the uplink transmissions of an AC. Let\nNT XOP,i denote the maximum number of packets that can fit in one TXOP of TCi . Then, for our running\nexample with one AC,\nU=\n\n\u03b31 * NT XOP,1\n.\n\u03b30 * NT XOP,0\n\n(8)\n\n1) Implementation of the Numerical Solution: Without loss of generality, the EDCA parameters of the\nstations, AIF S0 , CWmin,0 , and NT XOP,0, are fixed at predetermined values . Then, the EDCA parameters\nof the TC at the AP, AIF S1 , CWmin,1 , and NT XOP,1 , that achieve a required utilization ratio Ur can be\n\n\f8\n\ncalculated numerically as follows.\n1) We assume AIFS differentiation is only used for the prioritization between the ACs not the TCs (thus\nAIF S0 = AIF S1 ).\n2) When AIF S0 = AIF S1 , after some algebra on (6)-(8),\nU=\n\n\u03c41 * (1 \u2212 \u03c40 ) * NT XOP,1\n.\n\u03c40 * (1 \u2212 \u03c41 ) * NT XOP,0\n\n(9)\n\nTherefore, \u03c41 can be written in terms of \u03c40 , NT XOP,0, NT XOP,1 , and Ur . A numerical solution for \u03c40\nand \u03c41 for given Ur and a fixed value of NT XOP,1 (initially, NT XOP,1 = 1) is obtained using (1)-(5).\n3) CWmin,1 can be calculated as follows (the formula below is obtained using (8) and (9) in [25, Section\nIV-A]),\nCWmin,i =\n\n(1 \u2212 prcii )(1 \u2212 2pci )(1 \u2212 pci )\n2 \u2212 \u03c4i\n*\n\u2212 1.\n\u03c4i\n(1 \u2212 pci )2 (1 \u2212 (2pci )mi +1 ) + 2mi pcmi i +1 (1 \u2212 2pci )(1 \u2212 pci )(1 \u2212 prcii \u2212mi \u22121 )\n(10)\n\n4) A simple controller block checks whether the prioritization among ACs are maintained or not for the\nnew configuration. This block ensures that CWmin of a low priority AC (at the AP or a station) is\nnot smaller than CWmin of a higher priority AC. Therefore, if analytically calculated CWmin,1 value\ndoes not satisfy the controller block requirements, NT XOP,1 is doubled and the algorithm returns to\nstep 3. The larger NT XOP,1 is, the larger CWmin,1 will be.\n5) If the calculated CWmin,1 is not an integer, it is rounded to the closest integer value.\nA few remarks on the implementation are as follows.\n\u2022\n\nA numerical solution also exists when AIF S0 and AIF S1 are not equal, but the implementation\ndiffers since (9) does not hold. In such a case, AIF S1 is also assigned an initial value as NT XOP,1\nand the nonlinear system of equations (1)-(8) is solved numerically. According to the controller block\nrequirements on CWmin,1 , the procedure may be repeated for updated values of AIF S1 and NT XOP,1.\n\n\u2022\n\nAs previously mentioned, our formulation is valid for the situation when there is only one TC per\nstation (including the AP). As an approximation, we assume that (1)-(8) still holds when there are\nmultiple TCs at the AP. Indeed as only a few collisions are avoided when the internal collision\nprocedure is run at the AP [26], the solution of (1)-(8) will be very close to an extension that exactly\nformulates the virtual collisions at the AP. In this case, if the AIFS values of TCs within an AC\nremains equal, it can be shown that (9) still holds for the TCs of the same AC. Therefore, we use\n\n\f9\n\nthe implementation procedure previously stated for scenarios when larger number of ACs exist as\nlong as there is one AC (or TC) per station and multiple TCs at the AP.\n2) Proposed BEB Algorithm for non-integer CW values: As specified in [2], the initial value of CW\nis set to the AC-specific CWmin . At each unsuccessful transmission, the value of CW is doubled until\nthe maximum AC-specific CWmax limit is reached. The value of CW is reset to the AC-specific CWmin\nif the transmission is successful, or the retry limit is reached thus the packet is dropped.\nThe proposed analytical calculation for weighted fairness may decide a non-integer value of CWmin,1\nthus W1,k , k < r1 . The simplest approach is rounding to the closest integer and employing the rounded\nvalue in the BEB.\n\u2032\nInstead, we also propose the AP to choose integer W1,k\nvalues from a probability distribution that satis\u2032\nfies E[W1,k\n] = W1,k . For example, it is straightforward to show a simple discrete probability distribution\n\u2032\n\u2032\nsuch as Pr(W1,k\n= \u230aW1,k \u230b) = \u2308W1,k \u2309 \u2212 W1,k and Pr(W1,k\n= \u2308W1,k \u2309) = W1,k \u2212 \u230aW1,k \u230b holds. According\n\u2032\nto the proposed algorithm, the EDCA function at the AP decides on the interval (0, W1,k\n) to select the\n\nbackoff value regarding the given simple discrete probability distribution.\nFig. 4 shows the downlink/uplink access ratio for increasing number of uplink and downlink flows.\nWe assume equal AIF SN = 2 for all the stations and the AP, and analytically calculate CWmin,1 that\nachieves downlink/uplink access ratio of Ur = 1 when CWmin,0 = 127, NT XOP,0 = 1, and NT XOP,1\nis varied from 1 to 4. The performance of rounding the analytically calculated CW values is compared\nwith the performance of the proposed BEB algorithm that uses the stated discrete probability distribution\nfunction. As the results imply, the proposed BEB algorithm maintains perfect weighted fairness while\nrounding the analytically calculated value may result in slight inaccuracies in terms of utilization ratio.\nAs the number of uplink stations increase, CWmin,1 that achieves Ur = 1 decreases. As Fig. 4 shows\nthe effect of rounding is much more noticeable when CWmin,1 is small. The effect of rounding becomes\nnegligible as NT XOP,1 (thus CWmin,1 ) is increased.\n\nC. Dynamic Parameter Adaptation\nThe IEEE 802.11 infrastructure BSS exhibits some non-ideal conditions which most of the analytical\nmodels ignore to maintain simplicity. For example,\n\u2022\n\nAccurate information on the instantaneous number of active flows may not always be available to\nthe AP [27].\n\n\f10\n\n\u2022\n\nIf a station and the AP collide, the station's transmission results in failure since the destination (the\nAP) is not in listen mode. However, there is some probability that the transmission of the AP results\nin success as a consequence of the capture effect depending on the spatial distribution and the power\nlevels of the stations [28].\n\nSuch non-ideal conditions make finding the optimum EDCA setting analytically hard for any scenario.\nThis also limits the use of proposed BEB algorithm for non-integer CW values. We propose a simple\nmodel-assisted measurement-based dynamic algorithm to adapt the analytically calculated CWmin values\nfor such scenarios.\nThe AP carries out the dynamic adaptation for each AC every \u03b2 beacon intervals which is called an\nadaptation interval in the sequel. If it is detected as a new flow starting transmission or as an old flow\nbecoming inactive at the last adaptation interval, the algorithm decides on new good EDCA parameters\nusing the proposed analytical model which results in weighted fair resource allocation for the estimated\nnumber of uplink and downlink flows in ideal conditions. Otherwise, fine tuning on the CW and the\nT XOP values of the AC at the AP is carried out to make measured U as close as to Ur .\nWe use a simple algorithm to estimate the number of active flows. More advanced approaches [27]\ncan also be used. The AP counts the number of unique source and destination MAC addresses observed\nfrom incoming frames to estimate the number of uplink and downlink flows respectively. Let nu and nd\ndenote the number of uplink and downlink flows labeled as active. If the AP receives a packet with the\ncorresponding MAC address not on its list, it adds the new MAC address to the list and increments nu or\nnd . If the AP does not receive any packet with the corresponding MAC address during the last adaptation\ninterval, it deletes the MAC address from the list and decrements nu or nd . Then, we define the required\nutilization ratio as\nUr =\n\nnd\n.\nnu\n\n(11)\n\nIf Ur has been changed during the last adaptation interval, EDCA parameters are analytically calculated\nfor U = Ur and the fine tuning phase is skipped. Otherwise, solely fine tuning on CWmin is performed\nas follows. Every adaptation interval, the AP measures the number of successful uplink and downlink\ntransmissions, ntu and ntd respectively where ntd /ntu is the measured U of the last adaptation interval.\nIf\n\nntd\nntu\n\n< (1 \u2212 \u03b1) * Ur , then CWmin,1 is decremented (where 0 \u2264 \u03b1 \u2264 1). Similarly, if\n\nntd\nntu\n\n> (1 + \u03b1) * Ur ,\n\nthen CWmin,1 is incremented. Otherwise, no action is taken. Note that using steps equal in value to 1 in\nthe CWmin adaptation is sufficient since the analytical calculation will provide a good initial guess.\n\n\f11\n\nD. TCP-MAC Interactions\nTCP defines a reliable bi-directional communication where the forward link data rate depends on the rate\nof the received ACK packets in the backward link. This behavior of TCP constitutes the main difference\nbetween TCP and UDP access in the WLAN. The key observation is that, if we assume there are no\npacket losses in TCP connections (infinitely large interface buffers at the AP and the stations), the TCP\naccess is fair irrespective of the EDCA parameter selection (which is not the case for UDP). This is due\nto the fact that the slow link limits the throughput for all TCP flows. However, when the buffer size at the\nAP (bottleneck) is limited, significant unfairness and low channel utilization is experienced as previously\nshown in Fig. 3. Therefore, for fair resource allocation and high channel utilization, packet losses at the\nAP buffer should be minimized. We configure our adaptation algorithm considering the TCP dynamics to\nachieve this objective.\nNone of the work in the literature on IEEE 802.11 MAC upload/download fairness considered the\nasymmetry in the forward and backward link packet rate during the slow-start phase of the TCP connections. During the slow-start phase, the packet rate in the forward link is twice the packet rate in the\nbackward link. When the congestion avoidance phase is entered, the forward and the backward link packet\nrates become equal. When this asymmetry during slow-start is neglected, the download traffic is penalized\nwith longer queueing delays. Depending on the buffer availability, significant packet loss may even occur\nduring the slow-start. These may considerably affect the short-term fairness and the channel utilization.\nOur solution is simple yet effective. Considering each TCP data and ACK streams of each connection\nas individual active flows, the parameter adaptation algorithm of Section III-C is used. Since TCP is\nfair irrespective of the EDCA parameter selection as long as there are no packet losses, fine tuning on\nCWmin is always skipped. Therefore, the AP does not have to measure ntu and ntd . On the other hand,\nfine tuning is carried out on TXOP assignments to overcome increased rate of downlink TCP data flows\nduring slow-start. Since the forward to backward link packet rate ratio is 2 during the slow-start, the\nanalytically calculated TXOP duration is multiplied by 2. Our approach is adapting the duration of the\nTXOP depending on the number of packets buffered at the interface queue. If the number of packets goes\nover a threshold value th, doubled TXOPs are enabled until the number goes below the threshold again.\nAssigning best-effort data flows a non-zero TXOP or a small CWmin may not be a favorable approach\nwhen multimedia flows coexist in the WLAN. The controller block located at the AP should check whether\nthe QoS for admitted realtime flows is preserved or not in the WLAN with the CWmin and T XOP values\n\n\f12\n\ncalculated for uplink/downlink fairness.\nIV. N UMERICAL\n\nAND\n\nS IMULATION R ESULTS\n\nWe carried out simulations in ns-2 [4] in order to evaluate the performance of the proposed weighted\nfairness adaptation algorithm. For the simulations, we employ the IEEE 802.11e EDCA MAC simulation\nmodule for ns-2.28 [5].\nWe consider a network topology where each wireless station initiates a connection with a wired station\nwhere the WLAN traffic is relayed to the wired network through the AP. The stations are uniformly\ndistributed on a circle and the AP is located at the center. The power thresholds are set so that every\nstation can hear the other's transmission. The data connections use either UDP or TCP NewReno. The\nUDP traffic uses a Constant Bit Rate (CBR) application. The TCP traffic uses a File Transfer Protocol\n(FTP) agent which models bulk data transfer. The default TCP NewReno parameters in ns-2 are used.\nThe UDP traffic is mapped to a higher priority AC than the TCP traffic. All the stations are assumed to\nhave 802.11g PHY using 54 Mbps and 6 Mbps as the data and basic rate respectively [29]. The packet\nsize is 1500 bytes for all flows. The buffer size at the stations and the AP is set to 200 packets. We found\n\u03b2 = 5, \u03b1 = 0.5, and th = 50 packets to be appropriate through extensive simulations.\nFig. 5 shows the average throughput of individual flows for a scenario of 10 uplink UDP, 10 downlink\nUDP, 10 uplink TCP and 10 downlink TCP connections (same scenario as in Fig. 3). At the stations,\nUDP flows are mapped to an AC with CWmin = 31 and CWmax = 511. TCP flows use an AC with\nCWmin = 63 and CWmax = 1023. For both ACs, AIFSN values are set to 2 and TXOP limits are 0.\nUnless otherwise stated, all data connections of the stations in other experiments use these ACs (thus these\nEDCA parameters). At the AP, we run the proposed algorithm designed for weighted fairness support\nin the downlink and uplink. Since the number of downlink and uplink flows are equal for both ACs,\nwe define the downlink/uplink utilization requirement as Ur = 1. The analytical model decides on the\nCW and the T XOP that achieves Ur = 1. Fine tuning on CW is carried out for the fairness of UDP\nflows. The T XOP is adaptively doubled according to the proposed algorithm for TCP flows. The results\nillustrate that U = 1 is perfectly achieved in terms of throughput for both UDP and TCP flows.\nWe have tested the proposed algorithm for a range of network conditions.\na) Experiment 1: In the first set of experiments, we generate an equal number of TCP and UDP\nflows both in the uplink and downlink. Each flow starts at the same time and the simulation duration is\n100 seconds. The wired link delay (denoted as Round Trip Time (RTT) in the titles of the figures) is\n\n\f13\n\nequal for all flows (30 ms). Fig. 6 shows the total throughput of TCP and UDP flows in each direction for\nthe proposed algorithm. The results for the default 802.11e EDCA are also included for comparison. As\nthe results depict, U = 1 is perfectly achieved in terms of average throughput for the proposed algorithm,\nwhile the default scheduler cannot maintain fair access. Fig. 7 shows the total throughput of TCP and\nUDP flows as well as the total system throughput for the proposed algorithm and the default case. The\nproposed algorithm can maintain more efficient channel utilization than the default EDCA while providing\nfair access. In Fig. 8, we present the performance in terms of fairness between individual TCP or UDP\nflows in the same direction for the proposed algorithm and the default EDCA. The performance metric\nwe use is the widely used fairness index [30]. The fairness index, f , is defined as follows: if there are n\nconcurrent connections and the throughput achieved by connection i is equal to xi , 1 \u2264 i \u2264 n, then\nP\n2\n( ni=1 xi )\nf = Pn 2 .\nn i=1 xi\n\n(12)\n\nAs the results imply, the proposed algorithm also provides fair access between UDP and TCP flows of\nthe same direction. However, the default EDCA results in unfair resource allocation even between the\nTCP flows of the same direction. As we have described in Section II-A, the unfairness is more significant\nbetween TCP uplink flows. Although no unfair behavior is expected between UDP flows in the same\ndirection, we have included these results in Fig. 8 for the sake of completeness.\nb) Experiment 2: We have repeated the simulation set of experiment 1 when the wired link delay is\nvaried for TCP flows. The wired link delay of the first TCP connection is set to 24 ms and each newly\ngenerated TCP connection is assigned 4 ms larger wired link delay than the previous one. Therefore,\nthe second TCP connection has 28 ms wired link delay, the third one has 32 ms wired link delay and\nso on. This holds for both uplink and downlink connections. UDP wired link delay is constant for each\nconnection. Fig. 9 shows the average throughput of each TCP and UDP flow in each direction. Fig. 10\nshows the total throughput of TCP and UDP flows as well as the total system throughput. Fig. 11 shows\nthe performance in terms of fairness between individual TCP or UDP flows in the same direction. As the\nresults show, the performance of the proposed algorithm in terms of fair resource allocation is independent\nof the duration of the wired link delay. High channel utilization and perfect fairness is maintained. On\nthe other hand, as the comparison of Fig. 8 and Fig. 11 imply, the performance of default EDCA depends\non the duration of the wired link delay. In the case of varying wired link delays, the unfairness between\nindividual TCP flows both in the downlink and uplink is even worse.\n\n\f14\n\nc) Experiment 3: In the third set of experiments, we also generate an equal number of TCP and UDP\nflows both in the uplink and downlink. In this scenario, each uplink or downlink flow starts at different\ntimes and the simulation duration is 300 seconds. The wired link delay is equal for all flows. The first\ndownlink UDP connection starts at t = 5 s. The first uplink UDP connection starts at t = 10 s. The first\nuplink TCP connection starts at t = 7 s. The first downlink TCP connection starts at t = 12 s. Then,\na new flow of the same type arrives every 10 s. No other flow arrives after 200 s. Fig. 12 and Fig. 13\nshow the instantaneous UDP and TCP throughput of individual uplink and downlink flows respectively for\ndefault EDCA. The unfairness between uplink and downlink for both UDP and TCP and the unfairness\nbetween individual TCP flows both in the uplink and downlink are evident. Fig. 14 and Fig. 15 show the\ninstantaneous UDP and TCP throughput of individual uplink and downlink flows respectively when the\nproposed algorithm is enabled. As the results imply, the proposed algorithm adaptively updates EDCA\nparameters and always maintains instantaneous Ur (as calculated in (11).\nd) Experiment 4: We have repeated the simulation set of experiment 3 when the wired link delay is\nvaried for TCP flows. We set different wired link delays using the way as previously stated. Fig. 16 and\nFig. 17 show the instantaneous UDP and TCP throughput of individual uplink and downlink flows respectively for default EDCA. The unfairness between individual TCP flows both in the uplink and downlink\nare more pronounced when compared with the equal wired link delay scenario. Fig. 18 and Fig. 19 show\nthe instantaneous UDP and TCP throughput of individual uplink and downlink flows respectively for the\nproposed algorithm. Since the proposed algorithm adaptively updates EDCA parameters, it maintains fair\nresource allocation. The downlink flows does not starve in terms of throughput.\ne) Experiment 5: We have repeated the simulation set of experiment 3 when half of the TCP flows\nmodel short flows. The flow generation times follow the rules of experiment 3. The simulation duration\nis 450 s. No other flow arrives after 300 s. The short and long TCP flows are alternatively initiated both\nin the downlink and uplink. The short TCP flows consist of 31 packets and leave the system after all the\ndata is transferred. Fig. 20 shows the total transmission duration for individual short TCP flows for the\nproposed algorithm and the default EDCA. Note that flow indices from 1 to 15 represent uplink TCP flows\nwhile flow indices from 16 to 30 represent downlink TCP flows. The file transfers with short durations\ncan be completed in a considerably shorter time when the proposed algorithm is used. At high load,\nshort flows experience significantly long delays and connection timeouts when default constant EDCA\nparameter selection is used.\n\n\f15\n\nf) Experiment 6: We have repeated the simulation set of experiment 5 when the wired link delay\nis varied for TCP flows. We set different wired link delays using the way as previously stated. Fig. 21\nshows the total transmission duration for individual short TCP flows for the proposed algorithm and the\ndefault EDCA. The comparison of Fig. 20 and Fig. 21 reveals that the proposed algorithm performance\nin terms of short TCP flow completion time is independent of varying wired link delays among the flows.\ng) Experiment 7: In another set of experiments, we consider three types of traffic sources; audio,\nvideo, and data. The audio traffic model implements a Voice-over-IP (VoIP) application as a Constant\nBit Rate (CBR) traffic profile at 24 kbps. The constant audio packet size is 60 bytes. Although not\npresented here, similar results and discussion hold when the silence suppression scheme is used and the\naudio traffic exhibits on-off traffic characteristics. For the video source models, we have used traces of\nreal H.263 video streams [31]. The mean and maximum video payload size is 2419 bytes and 3112\nbytes respectively. The mean video data rate is 255 kbps. The audio flows are mapped to an AC with\nCWmin = 7 and CWmax = 15. The video flows use an AC with CWmin = 15 and CWmax = 31. For both\nACs, AIFSN values are set to 2 and TXOP limits are 0. Fig. 22 shows the average throughput of uplink\nand downlink data flows when there are 5 voice and 5 video flows both in the uplink and downlink (a\ntotal of 20 flows with QoS requirements). Similarly, Fig. 23 shows the average throughput of uplink and\ndownlink data flows when there are 10 voice and 10 video flows both in the uplink and downlink. We also\ncompare the results with the proposed algorithm of [13]. As the results of default EDCA and [13] imply,\nsticking with constant EDCA parameters for any number of flows does not result in fair access no matter\nwhich EDCA parameter setting is used. On the other hand, the proposed adaptive algorithm effectively\nmanages fair resource allocation for any number of stations. Note that we have not included the average\nthroughput of the flows with QoS requirements in Fig. 22 and Fig. 23, since all audio and video flows\nget necessary bandwidth to serve offered load with zero packet loss rate. Fig. 24 compares the average\ndelay of each QoS flow in each direction for default EDCA and the proposed algorithm when there are\na total of 20 flows with QoS requirements. Similarly, Fig. 25 compares the average delay of each QoS\nflow in each direction for default EDCA and the proposed algorithm when there are a total of 40 flows\nwith QoS requirements. As the results show, the QoS flows experience slightly larger delays when the\nproposed algorithm is used (due to smaller CW and larger TXOP assignment for data flows). On the other\nhand, the delay increase is well within the limits of QoS requirements. Moreover, fair resource allocation\nfor data flows is provided.\n\n\f16\n\nV. C ONCLUSIONS\nWe have proposed a model-assisted measurement-based dynamic EDCA parameter adaptation algorithm\nthat achieves a predetermined utilization ratio between uplink and downlink flows of the same AC while\nkeeping the prioritization among ACs. The key contribution is that depending on simple network measures,\nthe proposed algorithm dynamically adapts the EDCA parameters calculated via a proposed analytical\nmodel. Another key insight is that the proposed algorithm differentiates the way of adaptation between\nUDP and TCP flows regarding their characteristics.\nThe proposed algorithm is fully compliant with the 802.11e standard. We propose AP to use any CW\nvalue, not necessarily exponents of 2. Our observation is that the 802.11e standard does not restrict the\nCW settings of the ACs at the AP to be the powers of 2, while the CW setting of the ACs at the STA\nshould be powers of 2 due to the definition of specific fields in the beacon packet. Our approach provides\nthe AP the freedom of satisfying any required utilization ratio through fine tuning on CW settings.\nVia simulations, it is shown that fair resource allocation between uplink and downlink flows of an AC\ncan be maintained in a wide-range of scenarios when the proposed model-assisted measurement-based\ndynamic EDCA parameter adaptation algorithm is used. The performance of the proposed algorithm in\nterms of fair resource allocation is shown to be independent of the duration of the round trip time of a\nconnection. Short flows experience significantly low delays and no connection timeouts. Therefore, we\nconclude that the proposed method also provides short-term fairness. The QoS requirements of existing\naudio and video flows in the 802.11e WLAN are maintained. Our results also show that sticking with\nconstant EDCA parameters at any scenario does not result in fair access no matter which EDCA parameter\nsetting is used.\nR EFERENCES\n[1] IEEE Standard 802.11: Wireless LAN medium access control (MAC) and physical layer (PHY) specifications, IEEE 802.11 Std., 1999.\n[2] IEEE Standard 802.11: Wireless LAN medium access control (MAC) and physical layer (PHY) specifications: Medium access control\n(MAC) Quality of Service (QoS) Enhancements, IEEE 802.11e Std., 2005.\n[3] H. Balakrishnan, V. Padmanabhan, and R. H. Katz, \"The Effects of Asymmetry on TCP Performance,\" ACM Baltzer Mobile Networks\nand Applications (MONET), 1999.\n[4] (2006) The Network Simulator, ns-2. [Online]. Available: http://www.isi.edu/nsnam/ns\n[5] IEEE 802.11e HCF MAC model for ns-2.28. [Online]. Available: http://newport.eecs.uci.edu/$\\sim$fkeceli/ns.htm\n[6] S. Pilosof, R. Ramjee, D. Raz, Y. Shavitt, and P. Sinha, \"Understanding TCP Fairness over Wireless LAN,\" in Proc. IEEE Infocom\n'03, April 2003.\n\n\f17\n\n[7] Y. Wu, Z. Niu, and J. Zheng, \"Study of the TCP Upstream/Downstream Unfairness Issue with Per-flow Queueing over Infrastructuremode WLANs,\" Wireless Communications and Mobile Computing, pp. 459\u2013471, June 2005.\n[8] J. Ha and C.-H. Choi, \"TCP Fairness for Uplink and Downlink Flows in WLANs,\" in Proc. IEEE Globecom '06, November 2006.\n[9] F. Keceli, I. Inan, and E. Ayanoglu, \"TCP ACK Congestion Control and Filtering for Fairness Provision in the Uplink of IEEE 802.11\nInfrastructure Basic Service Set,\" to appear in Proc. IEEE ICC '07.\n[10] M. Gong, Q. Wu, and C. Williamson, \"Queue Management Strategies to Improve TCP Fairness in IEEE 802,11 Wireless LANs,\" in\nProc. IEEE WiOpt '06, April 2006.\n[11] N. Blefari-Melazzi, A. Detti, A. Ordine, and S. Salsano, \"Controlling TCP Fairness in WLAN access networks using a Rate Limiter\napproach,\" in Proc. ISWCS '05, September 2005.\n[12] C. Casetti and C. F. Chiasserini, \"Improving Fairness and Throughput for Voice Traffic in 802.11e EDCA,\" in Proc. IEEE PIMRC '04,\nSeptember 2004.\n[13] D. J. Leith, P. Clifford, D. Malone, and A. Ng, \"TCP Fairness in 802.11e WLANs,\" IEEE Commun. Lett., pp. 964\u2013966, November\n2005.\n[14] S. W. Kim, B.-S. Kim, and Y. Fang, \"Downlink and Uplink Resource Allocation in IEEE 802.11 Wireless LANs,\" IEEE Trans. Veh.\nTechnol., pp. 320\u2013327, January 2005.\n[15] I. Tinnirello and S. Choi, \"Efficiency Analysis of Burst Transmissions with Block ACK in Contention-Based 802.11e WLANs,\" in\nProc. IEEE ICC '05, May 2005.\n[16] J. Jeong, S. Choi, and C.-K. Kim, \"Achieving Weighted Fairness between Uplink and Downlink in IEEE 802.11 DCF-based WLANs,\"\nin Proc. IEEE QSHINE '05, August 2005.\n[17] J. Freitag, N. L. S. da Fonseca, and J. F. de Rezende, \"Tuning of 802.11e Network Parameters,\" IEEE Commun. Lett., pp. 611\u2013613,\nAugust 2006.\n[18] S. Shin and H. Schulzrinne, \"Balancing Uplink and Downlink De;ay of VoIP Traffic in WLANs using Adaptive Priority Control (APC),\"\nin Proc. IEEE QSHINE '06, August 2006.\n[19] I. Inan, F. Keceli, and E. Ayanoglu, \"Performance Analysis of the IEEE 802.11e Enhanced Distributed Coordination Function using\nCycle Time Approach,\" Center for Pervasive Communications and Computing, University of California, Irvine, Tech. Rep., March\n2007. [Online]. Available: http://newport.eecs.uci.edu/$\\sim$iinan/publications.htm\n[20] Z. Kong, D. H. K. Tsang, B. Bensaou, and D. Gao, \"Performance Analysis of the IEEE 802.11e Contention-Based Channel Access,\"\nIEEE J. Select. Areas Commun., pp. 2095\u20132106, December 2004.\n[21] I. Inan, F. Keceli, and E. Ayanoglu, \"Saturation Throughput Analysis of the 802.11e Enhanced Distributed Channel Access Function,\"\nto appear in Proc. IEEE ICC '07.\n[22] J. W. Robinson and T. S. Randhawa, \"Saturation Throughput Analysis of IEEE 802.11e Enhanced Distributed Coordination Function,\"\nIEEE J. Select. Areas Commun., pp. 917\u2013928, June 2004.\n[23] J. Hui and M. Devetsikiotis, \"A Unified Model for the Performance Analysis of IEEE 802.11e EDCA,\" IEEE Trans. Commun., pp.\n1498\u20131510, September 2005.\n[24] G. Bianchi, \"Performance Analysis of the IEEE 802.11 Distributed Coordination Function,\" IEEE Trans. Commun., pp. 535\u2013547, March\n2000.\n[25] H. Wu, Y. Peng, K. Long, S. Cheng, and J. Ma, \"Performance of Reliable Transport Protocol over IEEE 802.11 Wireless LAN: Analysis\nand Enhancement,\" in Proc. IEEE Infocom '02, June 2002.\n[26] A. Banchs and L. Vollero, \"Throughput Analysis and Optimal Configuration of IEEE 802.11e EDCA,\" Comp. Netw., pp. 1749\u20131768,\nAugust 2006.\n\n\f18\n\n[27] G. Bianchi and I. Tinnirello, \"Kalman Filter Estimation of the Number of Competing Terminals in an IEEE 802.11 Network,\" in Proc.\nIEEE Infocom '03, April 2003.\n[28] J. H. Kim and J. K. Lee, \"Capture Effects of Wireless CSMA/CA Protocols in Rayleigh and Shadow Fading Channels,\" IEEE Trans.\nVeh. Technol., pp. 1277\u20131286, July 1999.\n[29] IEEE Standard 802.11: Wireless LAN medium access control (MAC) and physical layer (PHY) specifications: Further Higher Data\nRate Extension in the 2.4 GHz Band, IEEE 802.11g Std., 2003.\n[30] R. Jain, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and\nModeling.\n\nJohn Wiley and Sons, 1991.\n\n[31] P. Seeling, M. Reisslein, and B. Kulapala, \"Network Performance Evaluation Using Frame Size and Quality Traces of Single-Layer\nand Two-Layer Video: A Tutorial,\" IEEE Communications Surveys and Tutorials, vol. 6, no. 2, pp. 58\u201378, Third Quarter 2004.\n[Online]. Available: http://www.eas.asu.edu/trace\n\n\f19\n\nAIFSN0\nAIFSN1\n\nTransmission/\nCollision period\n\nNo Tx\n\nTC0 in Backoff\nTC1 in Backoff\n\nZone 1\n\nSIFS\nFig. 1.\n\nEDCA backoff after busy medium.\n\nZone 0\n\n\f20\n\n1-p1tr\np1tr\n\n1-p1tr\n2\n\n1\np1tr\n\nFig. 2.\n\nd0\np1tr\n\n1-p0tr\nd0+1\n\np0tr\n\nd0+2\np0tr\n\nTransition through backoff slots in different contention zones for the example given in Fig.1.\n\nWmin\n1\n\n\f21\n\n2.5\n\nThroughput (Mbps)\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\n0\n\n5\n\n10\n\n15\n\n20\nFlow index\n\n25\n\n30\n\n35\n\n40\n\nFig. 3. Total throughput of 10 uplink UDP (indices 1-10), 10 downlink UDP (indices 11-20), 10 uplink TCP (indices 21-30) and 10\ndownlink TCP (indices 31-40 flows) when the AP and the stations use equal EDCA parameters.\n\n\f22\n\n1.1\nnon\u2212integer\nround, NTXOP,1=1\nround, N\n=2\nTXOP,1\nround, N\n=4\n\n1.08\n\nTXOP,1\n\nDownlink/Uplink Access Ratio\n\n1.06\n\n1.04\n\n1.02\n\n1\n\n0.98\n\n0.96\n\n0.94\n\n0\n\n5\n\nFig. 4.\n\n10\n15\nNumber of active uplink and downlink flows\n\n20\n\nThe downlink/uplink access ratio for increasing number of uplink and downlink flows.\n\n25\n\n\f23\n\n1\n\n0.9\n\n0.8\n\nThroughput (Mbps)\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n\n0\n\n5\n\n10\n\n15\n\n20\n25\nFlow index\n\n30\n\n35\n\n40\n\n45\n\nFig. 5. Total throughput of 10 uplink UDP (indices 1-10), 10 downlink UDP (indices 11-20), 10 uplink TCP (indices 21-30) and 10\ndownlink TCP (indices 31-40 flows) when the AP uses the proposed adaptation algorithm to achieve Ur = 1.\n\n\f24\n\n4\n\n2.5\n\nEqual RTT for each TCP flow\n\nx 10\n\nThroughput (kbps)\n\n2\nDefault \u2212 UDP\nuplink\nDefault \u2212 UDP\ndownlink\nDefault \u2212 TCP\nuplink\nDefault \u2212 TCPdownlink\nProposed \u2212 UDP\nuplink\nProposed \u2212 UDP\ndownlink\nProposed \u2212 TCP\nuplink\nProposed \u2212 TCPdownlink\n\n1.5\n\n1\n\n0.5\n\n0\n\n5\n\n10\n\nFig. 6.\n\n15\n20\nNumber of TCP/UDP flows at each direction\n\nThe total throughput of TCP and UDP flows in each direction (experiment 1).\n\n25\n\n\f25\n\nEqual RTT for each TCP flow\n30\n\nTotal Throughput (Mbps)\n\n25\n\n20\n\n15\n\n10\n\nDefault \u2212 UDP\nDefault \u2212 TCP\nDefault \u2212 Total\nProposed \u2212 UDP\nProposed \u2212 TCP\nProposed \u2212 Total\n\n5\n\n0\n\n5\n\n10\n\nFig. 7.\n\n15\n20\nNumber of TCP/UDP flows at each direction\n\nThe total throughput of TCP and UDP flows as well as the total system throughput (experiment 1).\n\n25\n\n\f26\n\nEqual RTT for each TCP flow\n1\n\n0.9\n\nFairness Index\n\n0.8\n\n0.7\n\n0.6\nDefault \u2212 UDPuplink\nDefault \u2212 UDP\ndownlink\nDefault \u2212 TCP\nuplink\nDefault \u2212 TCP\ndownlink\nProposed \u2212 UDPuplink\nProposed \u2212 UDP\ndownlink\nProposed \u2212 TCP\nuplink\nProposed \u2212 TCP\n\n0.5\n\ndownlink\n\n0.4\n\n5\n\n10\n\nFig. 8.\n\n15\n20\nNumber of TCP/UDP flows at each direction\n\nFairness index of individual TCP or UDP flows in the same direction (experiment 1).\n\n25\n\n\f27\n\n4\n\n2.5\n\nDifferent RTT for each TCP flow\n\nx 10\n\nThroughput (kbps)\n\n2\nDefault \u2212 UDP\nuplink\nDefault \u2212 UDPdownlink\nDefault \u2212 TCPuplink\nDefault \u2212 TCP\ndownlink\nProposed \u2212 UDP\nuplink\nProposed \u2212 UDP\ndownlink\nProposed \u2212 TCPuplink\nProposed \u2212 TCP\n\n1.5\n\ndownlink\n\n1\n\n0.5\n\n0\n\n5\n\n10\n\nFig. 9.\n\n15\n20\nNumber of TCP/UDP flows at each direction\n\nThe total throughput of TCP and UDP flows in each direction (experiment 2).\n\n25\n\n\f28\n\nDifferent RTT for each TCP flow\n30\n\nTotal Throughput (Mbps)\n\n25\n\n20\n\n15\n\n10\n\nDefault \u2212 UDP\nDefault \u2212 TCP\nDefault \u2212 Total\nProposed \u2212 UDP\nProposed \u2212 TCP\nProposed \u2212 Total\n\n5\n\n0\n\n5\n\n10\n\nFig. 10.\n\n15\n20\nNumber of TCP/UDP flows at each direction\n\nThe total throughput of TCP and UDP flows as well as the total system throughput (experiment 2).\n\n25\n\n\f29\n\nDifferent RTT for each TCP flow\n1\n\n0.95\n\n0.9\n\nFairness Index\n\n0.85\n\n0.8\n\n0.75\n\n0.7\n\n0.65\n\nDefault \u2212 UDPuplink\nDefault \u2212 UDP\ndownlink\nDefault \u2212 TCPuplink\nDefault \u2212 TCP\ndownlink\nProposed \u2212 UDPuplink\nProposed \u2212 UDPdownlink\nProposed \u2212 TCPuplink\nProposed \u2212 TCPdownlink\n\n0.6\n\n0.55\n\n0.5\n\n5\n\n10\n\nFig. 11.\n\n15\n20\nNumber of TCP/UDP flows at each direction\n\nFairness index of individual TCP or UDP flows in the same direction (experiment 2).\n\n25\n\n\f30\n\n4\n\n3\n\nUDP: Equal RTT for each TCP flow, Default\n\nx 10\n\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\n0\n\nFig. 12.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\nThe instantaneous UDP throughput of individual uplink and downlink flows for default EDCA (experiment 3).\n\n300\n\n\f31\n\nTCP: Equal RTT for each TCP flow, Default\n8000\nUplink\nDownlink\n\n7000\n\nIndividual Throughput (kbps)\n\n6000\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n\n0\n\nFig. 13.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\nThe instantaneous TCP throughput of individual uplink and downlink flows for default EDCA (experiment 3).\n\n300\n\n\f32\n\n4\n\n3\n\nUDP: Equal RTT for each TCP flow, Proposed\n\nx 10\n\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\n0\n\nFig. 14.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\n300\n\nThe instantaneous UDP throughput of individual uplink and downlink flows for the proposed algorithm (experiment 3).\n\n\f33\n\nTCP: Equal RTT for each TCP flow, Proposed\n6000\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n5000\n\n4000\n\n3000\n\n2000\n\n1000\n\n0\n\n0\n\nFig. 15.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\n300\n\nThe instantaneous TCP throughput of individual uplink and downlink flows for the proposed algorithm (experiment 3).\n\n\f34\n\n4\n\n3\n\nUDP: Different RTT for each TCP flow, Default\n\nx 10\n\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\n0\n\nFig. 16.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\nThe instantaneous UDP throughput of individual uplink and downlink flows for default EDCA (experiment 4).\n\n300\n\n\f35\n\n4\n\n3\n\nUDP: Different RTT for each TCP flow, Proposed\n\nx 10\n\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n\n0\n\nFig. 17.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\nThe instantaneous TCP throughput of individual uplink and downlink flows for default EDCA (experiment 4).\n\n300\n\n\f36\n\nTCP: Different RTT for each TCP flow, Default\n3000\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n2500\n\n2000\n\n1500\n\n1000\n\n500\n\n0\n\n0\n\nFig. 18.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\n300\n\nThe instantaneous UDP throughput of individual uplink and downlink flows for the proposed algorithm (experiment 4).\n\n\f37\n\nTCP: Different RTT for each TCP flow, Proposed\n3000\nUplink\nDownlink\n\nIndividual Throughput (kbps)\n\n2500\n\n2000\n\n1500\n\n1000\n\n500\n\n0\n\n0\n\nFig. 19.\n\n50\n\n100\n\n150\nTime (s)\n\n200\n\n250\n\n300\n\nThe instantaneous TCP throughput of individual uplink and downlink flows for the proposed algorithm (experiment 4).\n\n\f38\n\nEqual RTT for each TCP flow\n80\nDefault\nProposed\n\n70\n\nTransmission Duration (s)\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\n0\n\n0\n\n5\n\nFig. 20.\n\n10\n\n15\nFlow index\n\n20\n\nThe total transmission duration for individual short TCP flows(experiment 5).\n\n25\n\n30\n\n\f39\n\nDifferent RTT for each TCP flow\n180\nDefault\nProposed\n\n160\n\nTransmission Duration (s)\n\n140\n\n120\n\n100\n\n80\n\n60\n\n40\n\n20\n\n0\n\n0\n\n5\n\nFig. 21.\n\n10\n\n15\nFlow index\n\n20\n\n25\n\nThe total transmission duration for individual short TCP flows (experiment 6).\n\n30\n\n\f40\n\nEqual RTT for each TCP flow, number of QoS Flows: 4*5\n25\n\nThroughput (Mbps)\n\n20\n\n15\n\n10\n\nDefault \u2212 TCPuplink\nDefault \u2212 TCP\ndownlink\nProposed \u2212 TCP\nuplink\nProposed \u2212 TCPdownlink\n[13] \u2212 TCP\nuplink\n[13] \u2212 TCPdownlink\n\n5\n\n0\n\n5\n\n10\n\n15\nNumber of TCP flows at each direction\n\n20\n\n25\n\nFig. 22. The average throughput of uplink and downlink data flows when there are 5 voice and 5 video flows both in the uplink and\ndownlink (experiment 7).\n\n\f41\n\nEqual RTT for each TCP flow, number of QoS Flows: 4*10\n16\n\n14\n\nThroughput (Mbps)\n\n12\n\n10\n\n8\n\n6\n\n4\nDefault \u2212 TCPuplink\nDefault \u2212 TCP\ndownlink\nProposed \u2212 TCP\nuplink\nProposed \u2212 TCPdownlink\n[13] \u2212 TCP\nuplink\n[13] \u2212 TCPdownlink\n\n2\n\n0\n\n5\n\n10\n\n15\nNumber of TCP flows at each direction\n\n20\n\n25\n\nFig. 23. The average throughput of uplink and downlink data flows when there are 10 voice and 10 video flows both in the uplink and\ndownlink (experiment 7).\n\n\f42\n\nEqual RTT for each TCP flow , number of QoS Flows: 4*5\n5\n\nDefault \u2212 VoIP\nuplink\nDefault \u2212 VoIP\ndownlink\nDefault \u2212 Video\nuplink\nDefault \u2212 Videodownlink\nProposed \u2212 VoIPuplink\nProposed \u2212 VoIP\ndownlink\nProposed \u2212 Video\nuplink\nProposed \u2212 Videodownlink\n\n4.5\n\n4\n\nAverage Delay (ms)\n\n3.5\n\n3\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\nFig. 24.\n\n5\n\n10\n\n15\nNumber of TCP flows at each direction\n\n20\n\n25\n\nThe average delay of each QoS flow in each direction when there are a total of 20 flows with QoS requirements (experiment 7).\n\n\f43\n\nEqual RTT for each TCP flow , number of QoS Flows: 4*10\n5.5\n\n5\n\n4.5\n\nAverage Delay (ms)\n\n4\n\n3.5\nDefault \u2212 VoIP\nuplink\nDefault \u2212 VoIP\ndownlink\nDefault \u2212 Video\nuplink\nDefault \u2212 Videodownlink\nProposed \u2212 VoIPuplink\nProposed \u2212 VoIP\ndownlink\nProposed \u2212 Video\nuplink\nProposed \u2212 Video\n\n3\n\n2.5\n\n2\n\ndownlink\n\n1.5\n\n1\n\n0.5\n\nFig. 25.\n\n5\n\n10\n\n15\nNumber of TCP flows at each direction\n\n20\n\n25\n\nThe average delay of each QoS flow in each direction when there are a total of 40 flows with QoS requirements (experiment 7).\n\n\f"}