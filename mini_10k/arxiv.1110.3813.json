{"id": "http://arxiv.org/abs/1110.3813v1", "guidislink": true, "updated": "2011-10-17T20:37:18Z", "updated_parsed": [2011, 10, 17, 20, 37, 18, 0, 290, 0], "published": "2011-10-17T20:37:18Z", "published_parsed": [2011, 10, 17, 20, 37, 18, 0, 290, 0], "title": "On Time Reversal of Piecewise Deterministic Markov Processes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1110.6839%2C1110.2758%2C1110.5583%2C1110.1782%2C1110.4214%2C1110.2286%2C1110.0683%2C1110.5994%2C1110.5975%2C1110.4070%2C1110.5246%2C1110.3388%2C1110.0884%2C1110.3794%2C1110.5926%2C1110.3597%2C1110.4547%2C1110.2534%2C1110.5339%2C1110.3384%2C1110.5059%2C1110.2093%2C1110.4287%2C1110.5292%2C1110.2060%2C1110.6368%2C1110.0176%2C1110.5540%2C1110.0753%2C1110.4510%2C1110.6426%2C1110.1017%2C1110.2277%2C1110.1558%2C1110.5514%2C1110.4833%2C1110.5260%2C1110.1519%2C1110.1198%2C1110.4771%2C1110.3857%2C1110.5261%2C1110.6874%2C1110.5598%2C1110.6567%2C1110.3153%2C1110.4470%2C1110.5288%2C1110.6751%2C1110.2766%2C1110.2762%2C1110.0232%2C1110.5037%2C1110.2052%2C1110.3903%2C1110.2064%2C1110.3036%2C1110.2026%2C1110.1261%2C1110.1416%2C1110.3444%2C1110.5769%2C1110.3617%2C1110.5248%2C1110.4227%2C1110.2323%2C1110.4856%2C1110.2081%2C1110.1653%2C1110.2282%2C1110.1419%2C1110.4864%2C1110.1413%2C1110.1585%2C1110.2968%2C1110.4971%2C1110.3944%2C1110.6859%2C1110.5372%2C1110.0357%2C1110.0568%2C1110.4253%2C1110.0017%2C1110.2013%2C1110.0354%2C1110.1616%2C1110.3185%2C1110.0473%2C1110.4276%2C1110.1597%2C1110.6144%2C1110.4782%2C1110.2706%2C1110.6595%2C1110.1001%2C1110.5373%2C1110.5343%2C1110.0977%2C1110.3546%2C1110.2783%2C1110.3813&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On Time Reversal of Piecewise Deterministic Markov Processes"}, "summary": "We study the time reversal of a general PDMP. The time reversed process is\ndefined as $X_{(T-t)-}$, where $T$ is some given time and $X_t$ is a stationary\nPDMP. We obtain the parameters of the reversed process, like the jump intensity\nand the jump measure.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1110.6839%2C1110.2758%2C1110.5583%2C1110.1782%2C1110.4214%2C1110.2286%2C1110.0683%2C1110.5994%2C1110.5975%2C1110.4070%2C1110.5246%2C1110.3388%2C1110.0884%2C1110.3794%2C1110.5926%2C1110.3597%2C1110.4547%2C1110.2534%2C1110.5339%2C1110.3384%2C1110.5059%2C1110.2093%2C1110.4287%2C1110.5292%2C1110.2060%2C1110.6368%2C1110.0176%2C1110.5540%2C1110.0753%2C1110.4510%2C1110.6426%2C1110.1017%2C1110.2277%2C1110.1558%2C1110.5514%2C1110.4833%2C1110.5260%2C1110.1519%2C1110.1198%2C1110.4771%2C1110.3857%2C1110.5261%2C1110.6874%2C1110.5598%2C1110.6567%2C1110.3153%2C1110.4470%2C1110.5288%2C1110.6751%2C1110.2766%2C1110.2762%2C1110.0232%2C1110.5037%2C1110.2052%2C1110.3903%2C1110.2064%2C1110.3036%2C1110.2026%2C1110.1261%2C1110.1416%2C1110.3444%2C1110.5769%2C1110.3617%2C1110.5248%2C1110.4227%2C1110.2323%2C1110.4856%2C1110.2081%2C1110.1653%2C1110.2282%2C1110.1419%2C1110.4864%2C1110.1413%2C1110.1585%2C1110.2968%2C1110.4971%2C1110.3944%2C1110.6859%2C1110.5372%2C1110.0357%2C1110.0568%2C1110.4253%2C1110.0017%2C1110.2013%2C1110.0354%2C1110.1616%2C1110.3185%2C1110.0473%2C1110.4276%2C1110.1597%2C1110.6144%2C1110.4782%2C1110.2706%2C1110.6595%2C1110.1001%2C1110.5373%2C1110.5343%2C1110.0977%2C1110.3546%2C1110.2783%2C1110.3813&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We study the time reversal of a general PDMP. The time reversed process is\ndefined as $X_{(T-t)-}$, where $T$ is some given time and $X_t$ is a stationary\nPDMP. We obtain the parameters of the reversed process, like the jump intensity\nand the jump measure."}, "authors": ["Andreas L\u00f6pker", "Zbigniew Palmowski"], "author_detail": {"name": "Zbigniew Palmowski"}, "author": "Zbigniew Palmowski", "links": [{"href": "http://arxiv.org/abs/1110.3813v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1110.3813v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1110.3813v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1110.3813v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "On Time Reversal of Piecewise Deterministic\nMarkov Processes\nAndreas L\u00f6pker and Zbigniew Palmowski\n\narXiv:1110.3813v1 [math.PR] 17 Oct 2011\n\nAbstract: We study the time reversal of a general PDMP. The time reversed process is\ndefined as X(T \u2212t)\u2212 , where T is some given time and Xt is a stationary PDMP. We obtain\nthe parameters of the reversed process, like the jump intensity and the jump measure.\n\n1. Introduction\nThe aim of this paper is to introduce the time reversal of a general piecewise deterministic\nMarkov process (PDMP). Given a stationary version Xt of such a process we let Xt? =\nX(T \u2212t)\u2212 and study the characteristics of this reversed process.\nThe concept of reversing the direction of time for Markov processes can be found already\nin the works of Kolmogorov ([34, 35] and even earlier [51]). The general idea is to study\nthe process Xt? = X(T \u2212t)\u2212 , where T > 0 is either a fixed point in time or a suitably defined\nrandom time. However, it is not clear whether the process Xt? is a Markov process at\nall and if it is, whether properties like time-homogeneity, the strong-Markov property and\nothers hold. Such questions have been answered until the 1970s in several publications\nregarding time reversion (see e.g. [43, 44, 17, 54]). Other researchers applied time reversal\nto special classes of Markov processes, like L\u00e9vy processes ([31]), stochastic networks ([33]),\nbirth and death processes ([52]) and Markov chains ([45]).\nPDMPs evolve deterministically on an open subset of Rd , interrupted by random jumps\nthat happen either inside the state space or at the boundary. Piecewise deterministic paths\ncan be observed for Markov processes in a variety of applications. We mention risk process\n([1, 48, 19, 20, 25]), growth collapse and stress release models ([9, 53, 58, 12, 41]), queueing\nmodels ([14, 11]), earthquake models ([46]), repairable systems ([38]), storage models ([15,\n27, 28]) and TCP data transmission ([39, 40, 24]). The mathematical framework that is\nused in this paper was introduced by Davis [22, 21]. Other approaches to PDMPs and\nrelated processes can be found in [32, 56, 50, 49], see also [8, 18, 23, 47]. However, it seems\nthat time-reversal has not been a subject of detailed study for PDMPs, at least not in a\ngeneral framework (see [26] for time-reversal arguments for a special subclass). To fill this\ngap we study the reversed process of a general PDMP, allowing also for what is called a\nnon-empty active boundary, i.e. forced jumps that occur whenever the process hits the\nboundary of its state space.\nThis paper is divided into three sections. In the first section, after recalling the definition\nof PDMPs, we investigate the imbedded Markov chains (Wk )k=1,2,... and (Qk )k=1,2,... obtained by observing the process just before and right after the jumps. Among other things\nwe derive a formula for the stationary distribution of Zk = (Wk , Qk ). Also in Section 1 we\nderive some sufficient conditions to ensure that the stationary distribution \u03bd of the original\nPDMP is absolutely continuous.\nDate: October 30, 2018.\n1\n\n\fTIME REVERSAL OF PDMPS\n\n2\n\nIn Section 2 we define the reversed Markov process (Xt? )t\u22650 (we use an asterisk to denote\nvariables related to the reversed process) and show that it is a PDMP. Moreover, we prove\nthat \u03c0(A, B) = \u03c0 ? (B, A), where \u03c0 and \u03c0 ? denote the stationary distribution of Zk and Zk? .\nMore specifically we find the crucial relation\n\u03bcx (dy)(\u03bb(x)\u03bd(dx) + \u03c3(dx)) = \u03bc?y (dx)(\u03bb? (y)\u03bd(dy) + \u03c3 ? (dy)),\n\n(1)\n\nwhere \u03c3 denotes the measure that is equal to the average number of visits to the boundary.\nThis formula can be used to derive the jump intensity \u03bb? (x) and the jump measure \u03bc?x (A)\nof the reversed process \u2013 one of the main aims of the paper. We also rediscover that in our\nsetting the well known property of the generator A? of X ? to be the adjoint of A holds.\nSection 3 is devoted to PDMPs on the real line, that is PDMPs with state space E \u2286 R.\nWe derive an integral equation for the stationary distribution and study some special cases.\nWe will introduce certain conditions for the process to hold. More specifically, we have\nconditions (A) to ensure that Xt is a proper PDMP, conditions (B) and (D) to be able\nto revert the process and condition (C) to obtain an absolutely continuous stationary\ndistribution.\n1.1. Preliminaries. Throughout the article we use the following notations. We let `d\ndenote be the d-dimensional Lebesgue measure and write \u03bc1 \u001c \u03bc2 if a measure \u03bc1 is\nabsolutely continuous with respect to another measure \u03bc2 . In this case the symbol d\u03bc1 /d\u03bc2\nstands for the Radon-Nikodym derivative. If \u03bc2 is the Lebesgue-measure we shortly write\n\u03bc01 instead of d\u03bc1 /d`. The same notation f 0 is used for the Radon-Nikodym derivative of\nan absolutely continuous function f . Given some measure \u03bc we denote \u03bc|A (B) = \u03bc(A \u2229 B)\nthe restriction of \u03bc to A.\nWe use the abbreviations E\u03bc and P\u03bc for the expectation and probability, given that the\nprocess Xt starts with initial probability distribution \u03bc (which will often be the stationary\ndistribution \u03bd). In particular, if \u03bc({x}) = 1 then we write Ex and Px . Given a set A \u2286 Rd ,\nB(A) indicates the Borel-\u03c3-field of subsets of A.\nThe typical feature of a PDMP is of course its eponymous path that consist of random\njumps and piecewise deterministic segments. The jumps are steered by a jump intensity\nfunction, allowing the jump times to depend on the current state of the process, and\na jump measure, determining the distribution of the destination of the random jumps.\nAdditionally the process is allowed to change its state continuously between the jumps.\nIn general, if \u03c6(x, t) denotes the position of the process at time t, given that there were\nno jumps and that the process started in x, the appropriate condition on \u03c6 in order to\nobtain a deterministic time homogeneous Markov process is to form a flow, that is to fulfil\nthe relation \u03c6(\u03c6(x, t), s) = \u03c6(x, s + t) for s, t \u2265 0 (see e.g. [30, 49]). If one wants to keep\nit general, this would be the only restriction to the deterministic paths and no further\nregularity and continuity conditions have to be imposed.\nIn this paper we instead follow the more restrictive (and more popular) set-up demonstrated in the book of Davis [22] (see also [18, 21, 48]), where the deterministic paths\nof the process are governed by a differential equation as follows. Let E\u25e6i \u2286 Rdi , di \u2208 N,\ni \u2208 K = {1, 2, . . . , k}, k \u2208 N be a collection of open sets and let \u2202Ei denote the boundary of\nE\u25e6i . We assume that on each component E\u25e6i there is a vector field defined with unique integral curve \u03c6i : E\u25e6i \u00d7 R \u2192 E\u25e6i , having no explosions. The idea is that, given that X0 = (x, i)\nwith x \u2208 Ei and there was no jump during [0, t], the position of Xt is given by \u03c6i (x, t). We\nassume that there are functions ri = (ri,1 , . . . , ri,di ) : E\u25e6i \u2192 R, locally Lipschitz-continuous,\n\n\fTIME REVERSAL OF PDMPS\n\n3\n\nsuch that for all x \u2208 E\u25e6i , the integral curve \u03c6(x, t) is the unique solution of the ordinary\n\u2202\ndifferential equation \u2202t\n\u03c6i (x, t) = ri (\u03c6i (x, t)). For differentiable functions f : Ei \u2192 R we\ncan represent the integral curve using the Lie derivative\nd\n\ni\nX\n\u2202\n\u2202\nf (x).\nf (\u03c6i (x, t)) =\nri,j (x)\nt\u21920 \u2202t\n\u2202xj\nj=1\n\nXi f (x) = lim\n\nMore generally, we understand the symbol Xi f (x) as a solution of\nZ t\n\nf (\u03c6i (x, t)) = f (x) +\n\nXi f (\u03c6(x, s)) ds,\n\n0\n\nallowing f to be only absolutely continuous. The process (Xt )t\u22650 evolves on a subset of\nthe disjoint union of the E\u25e6i \u222a \u2202Ei and the elements of K represent the outer states of the\nprocess. In order to give a complete specification of the actual state space of the process we\ndistinguish between the following subsets of the boundary \u2202Ei . First, the so called active\nboundary of points that can be reached from within E\u25e6i ,\n\u0393i = {z \u2208 \u2202Ei : z = \u03c6(x, t)\n\nfor some x \u2208 E\u25e6i , t > 0}\n\nand secondly, what we call (in lack of a more appropriate term) the passive boundary, the\nset of points on the boundary from where points in E\u25e6i can be reached:\n\u0393?i = {z \u2208 \u2202Ei : z = \u03c6(x, \u2212t) for some x \u2208 E\u25e6i , t > 0},\nof course, as the asterisk indicates, this set will serve as active boundary for the reversed\nprocess. We also define Ei = E\u25e6i \u222a \u0393?i and E?i = E\u25e6i \u222a \u0393i . For each set Si \u2208 {\u0393i , \u0393?i , Ei , E?i }\nwe define the disjoint union S = {(x, i) : i \u2208 K, x \u2208 Si }. For example the state space of Xt\nbecomes\nE = {(x, i) : i \u2208 K, x \u2208 Ei },\nwhile the active boundary is \u0393 = {(x, i) : i \u2208 K, x \u2208 \u0393i }. Before we proceed we agree on\nthe following convention. We will throughout the paper omit the outer states, e.g. write\nx \u2208 E instead of (x, i) \u2208 E, or X f (x) instead of Xi f (x). Only if the notations are necessary\nto avoid ambiguity we well indicate the outer states.\nAs explained in the introduction, the process Xt jumps at certain random times (Ti )i=1,2,... .\nThis will either happen from within E (voluntary jumps) or if the process hits the active boundary \u0393 (forced jumps). The times at which forced jumps occur are denoted by\n(Ti+ )i=1,2,... . Let \u03c4 (x) = inf{t \u2265 0 : \u03c6(x, t) \u2208 \u0393} denote the first time the latter happens,\ngiven the process starts in x \u2208 E and no jumps occurred (with the usual convention that the\ninfimum is equal to \u221e if there is no such t). Two random mechanisms determine the jumps:\nthe jump intensity is a non-negative, continuous measurable function \u03bb : E \u2192 [0, \u221e), with\nthe interpretation that the probability of a jump during [t, t + h], given that the process\nis in the state x, is \u03bb(x)h + o(1) and the probability of more than one jump is o(1) as\nh \u2192 0. Formally this will follow from the continuity of \u03bb and from the representation of\nthe probability distribution of the first jump time T1 given by\nPx (T1 > t) = 1{t<\u03c4 (x)} \u039bx (t),\nRt\n\n(2)\n\nwhere we use the abbreviation \u039by (t) = exp(\u2212 0 \u03bb(\u03c6(y, u)) du). Secondly, the jump measure \u03bcx (A) determines the probability of a jump from x \u2208 E? into a measurable set\nA \u2286 B(E). Let Nt = sup{n : Tn \u2264 t} denote the number of jumps (forced and voluntary) and Nt+ = sup{n : Tn+ \u2264 t} the number of forced jumps occurring during [0, t].\n\n\fTIME REVERSAL OF PDMPS\n\n4\n\nThroughout we assume the following standard conditions (c.f. [22]):\nCondition A.\nR \u03b5(x)\n\n(A1 ) For all x \u2208 E there is an \u03b5(x) > 0, such that 0 \u03bb(\u03c6(x, s)) ds < \u221e (local integrability\nof \u03bb along \u03c6);\nR\n(A2 ) 0\u221e \u03bb(\u03c6(x, s)) ds = \u221e for all x \u2208 E with \u03c4 (x) = \u221e (first jump happens in finite\ntime);\n(A3 ) Ex (Nt ) < \u221e for all x \u2208 E and all t > 0 (there are no explosions);\n(A4 ) \u03bcx ({x}) = 0 for all x \u2208 E (no jumps of size zero);\nAdditionally we assume further conditions to ensure that we can define a proper reversed\nprocess and to be able to derive formulas for the parameters of the reversed process. In\nwhat follows we define\n\u2202h B = {x \u2208 E : \u03c4 (x, B) < h}\nfor any set B \u2208 B(E \u222a \u0393) to denote the locations from which the process can reach B\nwithin h time units.\nCondition B. In this paper we always assume the following conditions.\n(B1 )\n(B2 )\n(B3 )\n(B4 )\n(B5 )\n\nThere\nexists a stationary distribution \u03bd of Xt on E;\nR\nE \u03bb(x)\u03bd(dx) < \u221e;\n\u03bb is continuous;\nFor any A \u2208 B(E) and every x \u2208 E we have \u03bc\u03c6(x,h) (A) \u2192 \u03bcx (A) as h \u2192 0.\n\u03bcx (\u2202h \u0393) \u2192 0 uniformly for x \u2208 \u0393 as h \u2192 0.\n\nRemark 1. Condition (B1 ) assumes the existence of a stationary distribution of the process.\nThis will be crucial for the definition of the time reversal in Section 2. Giving appropriate\nconditions for a general PDMP to possess a stationary distribution, to be ergodic, positive\nrecurrent or Harris recurrent is a difficult if not impossible task. Different efforts have\nbeen made to solve these problems for special cases ([36, 58, 18]). We take the liberty to\nkeep away from these intricate questions and just assume our process to posses a unique\nstationary distribution, being aware of the difficulties that we leave untouched.\nRemark 2. Condition (B5 ) prevents the process from becoming cascading near the boundary, i.e. to jump more and more often from \u0393 into a smaller and smaller neighbourhood of\n\u0393.\nRemark 3. With these conditions holding there are no hybrid jumps, that is, we do not\nallow the situation where there is an x \u2208 E such that Xt jumps with a certain probability\np(x) once it reaches x and with probability 1 \u2212 p(x) it stays on the flow. This restriction\nbecomes important for the reversed process.\nWe will also need the following substitution rules. Let \u03c4 (x, y) = t if y = \u03c6(x, t) for some\nt \u2265 0 and \u03c4 (x, y) = \u221e else. Then \u03c4 (x, y) represents the time the process needs to run\nfrom x to y if no jumps occur. Let \u03a6yx = \u222at\u22650 {\u03c6(x, s) \u2208 E : s \u2208 [0, t], and y = \u03c6(x, t)} and\n\u03a6+\nx = {\u03c6(x, s) \u2208 E : s \u2208 [0, \u03c4 (x))} denote the curve segments starting from x and ending\nat y and at the active boundary, respectively. Then we can rewrite the line integral over\n\u03a6yx as\nZ \u03c4 (x,y)\n\nZ\n\u03a6yx\n\nf (u) du =\n\nf (\u03c6(x, s))|r(\u03c6(x, s))| ds,\n0\n\n(3)\n\n\fTIME REVERSAL OF PDMPS\n\n5\n\nwhere |r(u)| = ( di=1 ri2 (u))1/2 . Similarly, provided that |r(u)| > 0 on \u03a6yx , the integral over\nf (\u03c6(x, s)) with s \u2208 [0, \u03c4 (x, y)] can be written as\nP\n\nZ \u03c4 (x,y)\n\nZ\n\nf (\u03c6(x, s)) ds =\n0\n\nIt follows in particular that \u03c4 (x, y) =\n\nR\n\n\u03a6yx\n\n\u03a6yx\n\nf (u)\ndu.\n|r(u)|\n\n(4)\n\n1/|r(u)| du.\n\nLet M denote the class of measurable functions f : E? \u2192 R and M 0 the class of those\nmembers f \u2208 M , for which t \u2192 f (\u03c6(x, t)) is absolutely continuous (so f is absolutely\ncontinuous along the flow). We define the linear operator\nAf (x) = X f (x) + \u03bb(x)Qf (x),\n\n(5)\n\nR\n\nwhere Qf (x) = E (f (y) \u2212 f (x)) \u03bcx (dy). A is the full generator of the Markov process Xt\nand we denote by D(A) the domain of A, so that for f \u2208 D(A) the process f (Xt )\u2212f (X0 )\u2212\nRt\n0 Af (Xs ) ds becomes a martingale. These functions are characterized in [22, Th. (26.14)\nand Rem. (26.16)]. Note that the class of bounded functions f \u2208 M 0 with Qf (x) = 0 for\nall x \u2208 \u0393 is contained in the domain. We let Mb0 denote the bounded functions in M 0 . We\nnote that for all f \u2208 Mb0\nf (Xt ) \u2212 f (X0 ) \u2212\n\nZ t\n\nAf (Xs ) ds \u2212\n\n0\n\nZ t\n0\n\nQf (Xs\u2212 ) dNs+\n\n(6)\n\nis also a martingale.\n1.2. Stationarity. The process Xt\u2212 will hit the active boundary \u0393 at certain times\n(Tn+ )n\u22650 and is then forced to jump. Let Nt+ (B) denote the number of hits of a set\nB \u2208 B(\u0393) during the time interval [0, t] and Nt+ = Nt (\u0393). It is shown in [22, Theorem\n34.15] ([18, Proposition 2]) that there exists a finite measure \u03c3 on the active boundary\n\u0393 such that \u03c3 measures the time-average of the number of visits to B, namely \u03c3(B) =\nE\u03bd (Nt+ (B))/t for every t > 0. That is, for any bounded function f \u2208 M and any t > 0,\nt\n1\n(7)\nf (x)\u03c3(dx) = E\u03bd ( f (Xs\u2212 ) dNs+ ).\nt\n0\n\u0393\nMany of the upcoming results of this paper are based on the following crucial relation.\nTaking expectations in (6) with respect to \u03bd and taking into account that E\u03bd (f (Xt )) =\nR\nE\u03bd (f (X0 )), we obtain tE\u03bd (Af (Xs )) + E\u03bd ( 0t Qf (Xs\u2212 ) dNs+ ) = 0 for every f \u2208 Mb0 , so that\nwe have the identity (see [22, Theorem 34.19]):\n\nZ\n\nZ\n\nZ\nE\n\nAf (x)\u03bd(dx) +\n\nZ\n\nQf (x)\u03c3(dx) = 0.\n\n(8)\n\n\u0393\n\nEquation (8) is the usual starting point to find expressions of \u03bd in terms of the parameters\n\u03bb and \u03bcx of the process. In general however there is not much hope to find explicit formulas\nand only for a few PDMP models the stationary distribution \u03bd is explicitly known. Even in\nthe one-dimensional case often all that can be done is to derive integro-differential equations\nfor \u03bd (see Section 3 for examples) and even these equations give rise to challenging problems\nthemselves.\nAnother interesting question is, whether it is possible to further describe the measure\n\u03c3 and express it in terms of the stationary measure \u03bd on E\u25e6 . In fact, \u03c3 is determined by\nthe values of \u03bd on arbitrary small neighbourhoods of \u0393 and for B \u2208 B(\u0393) the measure\n\u03c3(B) is given by the limit probability to find Xt in short distance to B (measured in time\n\n\fTIME REVERSAL OF PDMPS\n\n6\n\nunits needed to reach B). Let \u03c4 (x, B) = \u03c4 (x, y) if y = \u03c6(x, t) \u2208 B for some t \u2265 0 and\n\u03c4 (x, B) = \u221e else.\nProposition 1. For B \u2208 B(\u0393) the measure \u03c3(B) is given by the limit\n\u03c3(B) = lim\n\nh\u21920\n\n\u03bd(\u2202h B)\n.\nh\n\n(9)\n\nProof. The function fh : E? \u2192 [0, 1]\n\u03c4 (x, B) \u0001\n* 1{x\u2208\u2202h B}\nh\nis absolutely continuous, bounded and vanishes on E \\ \u2202h B; in particular fh \u2208 Mb0 and\nfh (x) = 1 \u2212\n\n1{x\u2208\u2202h B}\n1\nd\nd\nfh (\u03c6(x, t)) = \u2212 1{x\u2208\u2202h B} lim \u03c4 (\u03c6(x, t), B) =\n.\nt\u21920 dt\nt\u21920 dt\nh\nh\nApplication of (8) to fh then yields\nX fh (x) = lim\n\n1\n\u03bd(\u2202h B) +\nh\n=\u2212\n\nZ\n\nZ\n\u0393\n\nZ\n\n\u0001\n\n\u03bb(x)\n\u2202h B\n\n\u2202h B\n\nZ\n\n\u03bcx (dy) \u2212 fh (x) \u03bd(dx)\n\u0001\n\n\u2202h B\n\nfh (y)\u03bcx (dy) \u2212 fh (x) \u03c3(dx),\n\nfrom which it follows that\nZ\nZ Z\n\u0001\n1\n\u03bb(x) \u03bcx (\u2202h B) \u2212 fh (x) \u03bd(dx).\nfh (y)\u03bcx (dy)\u03c3(dx) \u2212\n\u03bd(\u2202h B) = \u03c3(B) \u2212\nh\n\u2202h B\n\u0393 \u2202h B\nNote that\nZ Z\n\u0393 \u2202h B\n\n\u2264\n\nfh (y)\u03bcx (dy)\u03c3(dx) \u2212\n\nZ\n\nZ\n\u2202h B\n\n\u0001\n\n\u03bb(x) \u03bcx (\u2202h B) \u2212 fh (x) \u03bd(dx)\n\nZ\n\n\u03bcx (\u2202h B)\u03c3(dx) +\n\u0393\n\n\u03bb(x)\u03bd(dx).\n\u2202h B\n\nAs h \u2192 0 the integrals on the right tend to zero by dominated convergence, where we used\ncondition (B2 ) and \u03bd(\u0393) = 0.\n\u0003\n1.3. The embedded processes. To gain insight into the behaviour of the process it is\nuseful to study the continuous time process (Xt )t\u22650 sampled at the jump times (Ti )i=1,2,... .\nTo this end we define the two-dimensional process Zk = (Wk , Qk ), where Wk = XTk\u2212 and\nQk = XTk denote the embedded discrete time Markov processes, obtained by observing Xt\njust after and right before the jumps. Note that due to the forced jumps the state space\nof W is E? , whereas Q lives on E, so that EZ = E? \u00d7 E is the state space of Z.\nIf Xt is stationary then still Wk and Qk are usually not stationary and vice versa.\nHowever, if Wk is stationary then so is Qk . If \u03bd is the stationary distribution of Xt , then\nwe will show how to find a stationary distribution for Zk .\nLet for A \u2208 B(E? ) and B \u2208 B(E)\np(h; A, B) = P\u03bd (X0 \u2208 A, Xh \u2208 B, T1 \u2208 [0, h])\ndenote the probability that (under \u03bd) X0 \u2208 A, Xh \u2208 B and the process is going to jump\nduring the time interval [0, h].\n\n\fTIME REVERSAL OF PDMPS\n\n7\n\nProposition 2. For all A \u2208 B(E? ) and B \u2208 B(E) the limit p(h; A, B)/h exists as h \u2192 0\nand it is given by:\nZ\nZ\np(h; A, B)\n=\n\u03bb(x)\u03bcx (B)\u03bd(dx) +\n\u03bcx (B)\u03c3(dx).\n(10)\n\u03be(A, B) = lim\nh\u21920\nh\nA\u2229E\nA\u2229\u0393\nProof. Suppose first that B is open. The probability p(h; A, B) is a sum of the probabilities\nof the following four events:\n1) We have X0 \u2208 (A \u2229 E) \\ \u2202h (A \u2229 \u0393), i.e. X0 is not close to the boundary and a jump\noccurs within h time units, say at time s. Moreover, Xs \u2208 \u2202h\u2212s B and no further jumps\noccur, so that the process will end up in B at time h, as desired. The probability of this\nevent is given by\nZ hZ\n\nZ\n\np1 =\n0\n(A\u2229E)\\\u2202h (A\u2229\u0393)\n\n\u2202h\u2212s B\n\n\u039bz (h \u2212 s)\u03bc\u03c6(x,s) (dz)\u039bx (ds) \u03bd(dx).\n\nSince B is open, we have that 1{zh \u2208\u2202h\u2212s B} \u039bzh (h \u2212 s) \u2192 1{z\u2208B} for any sequence {zh } \u2208 E\nwith zh \u2192 z, z \u2208 E as h \u2192 0 and by condition\n(B4 ) it follows that \u03bc\u03c6(x,s) (\u2202h\u2212s B) \u2192 \u03bcx (B)\nR\nas h \u2192 0. Hence, by Theorem 5.5 in [7] \u2202h\u2212s B \u039bz (h \u2212 s)\u03bc\u03c6(x,s) (dz) \u2192 \u03bcx (B) as h \u2192 0.\nSince \u039bx (ds) = \u03bb(\u03c6(x, s))\u039bx (s) ds and \u039bx (s) \u2192 1 as h \u2192 0, it follows from the continuity\nof \u03bb (condition (B3 )) that\nZ\n\nZ\n\n\u03bb(x)\u03bcx (B) \u03bd(dx) + o(h) = h\n\np1 = h\n\n\u03bb(x)\u03bcx (B) \u03bd(dx) + o(h).\n\nA\u2229E\n\n(A\u2229E)\\\u2202h (A\u2229\u0393)\n\nThe last equality is a consequence of the fact that \u03bd(\u2202h (A \u2229 \u0393)) \u2192 0 as h \u2192 0 since\n\u03bd(\u0393) = 0.\n2) The event that X0 \u2208 \u2202h (A \u2229 \u0393), a unforced jump occurs at time s before the process\nreaches \u0393, Xs \u2208 \u2202h\u2212s B and no further jumps occur is given by\nZ \u03c4 (x) Z\n\nZ\n\np2 =\n\u2202h (A\u2229\u0393) 0\n\n\u2202h\u2212s B\n\n\u039bz (h \u2212 s)\u03bc\u03c6(x,s) (dz)\u039bx (ds) \u03bd(dx).\n\nSince \u03c4 (x) \u2192 0 and \u03bd(\u2202h (A \u2229 \u0393)) \u2192 0 as h \u2192 0, it follows by similar arguments as before\nthat p2 = o(h).\n3) X0 \u2208 \u2202h (A \u2229 \u0393), the process reaches \u0393 at time \u03c4 (x), Xs \u2208 \u2202h\u2212s B and no further jumps\noccur. The probability is given by\nZ\n\nZ\n\np3 =\n\u2202h (A\u2229\u0393) \u2202h\u2212\u03c4 (x) B\n\n\u039bz (h \u2212 \u03c4 (x))\u03bc\u03c6(x,\u03c4 (x)) (dz)\u039bx (\u03c4 (x)) \u03bd(dx).\n\nAs in 1) we have that 1{z\u2208\u2202h\u2212\u03c4 (x) B} \u039bz (h \u2212 \u03c4 (x)) tends to 1{z\u2208B} for any sequence {zh } \u2208 E\nwith zh \u2192 z, z \u2208 E as h \u2192 0 and \u03bc\u03c6(x,\u03c4 (x)) (\u2202h\u2212\u03c4 (x) B) \u2192 \u03bcx (B). Consequently\nZ\n\u2202h\u2212\u03c4 (x) B\n\n\u039bz (h \u2212 \u03c4 (x))\u03bc\u03c6(x,\u03c4 (x)) (dz)\u039bx (\u03c4 (x)) \u2192 \u03bcx (B).\n\nFrom Proposition 1 it follows that \u03bd(\u2202h (A \u2229 \u0393)) = h\u03c3(A \u2229 \u0393) + o(h). Hence\nZ\n\np3 = h\n\n\u03bcx (B)\u03c3(dx) + o(h).\nA\u2229\u0393\n\n4) We finally investigate the case, where more than one jump occurs during the time period\n[0, h]. The probability of this event is o(h) as h \u2192 0. This follows immediately from the\n\n\fTIME REVERSAL OF PDMPS\n\n8\n\ndefinition, if the process does not reach the boundary. If on the other hand X0 \u2208 \u2202h \u0393 (the\nprobability being O(h)) then the probability to jump to \u2202h \u0393 again is o(1) by Condition\n(B5 ).\nAltogether we obtain\nZ\n\nZ\n\np(h; A, B) = h\n\n\u03bb(x)\u03bcx (B) \u03bd(dx) + h\nA\u2229E\n\n\u03bcx (B)\u03c3(dx) + o(h).\n\n(11)\n\nA\u2229\u0393\n\nThis completes the proof for the case, where B is open. The general case follows using\nclassical arguments.\n\u0003\nThe total mass k\u03bek = \u03be(E? , E) = E \u03bb(u) \u03bd(du) + \u03c3(\u0393) is finite due to (B2 ) and it has\nbeen shown in [18, Proposition 5] (and [22, Theorem (34.21)]) that k\u03bek is strictly positive.\nConsequently, we can define a probability measure\nR\n\n\u03c0(A, B) = \u03be(A, B)/k\u03bek =\n\n1 \u0010\nk\u03bek\n\nZ\n\nZ\n\n\u03bb(x)\u03bcx (B)\u03bd(dx) +\n\n\u0011\n\n\u03bcx (B)\u03c3(dx)\n\nA\u2229E\n\n(12)\n\nA\u2229\u0393\n\non EZ .\nTheorem 1. \u03c0 defined in (12) is a stationary measure for the Markov chain Z.\nRemark 4. Compare with [22, Theorem (34.21)] and [18, Theorem 1], where it is shown\nthat the marginal distribution \u03c0(E, *) is a stationary distribution for Q. The present proof\nfollows partly along the lines of the proofs presented there.\nProof of Theorem 1. Let fb(y) = E(f (Wk , Qk )|Qk\u22121 = y) \u2208 Mb0 for some function f \u2208 Mb0 .\nConditioning with respect to the first jump time of the process we obtain:\nZ \u03c4 (y) Z\n\nf (\u03c6(y, s), u) \u03bc\u03c6(y,s) (du)\u03bb(\u03c6(y, s))\u039by (s) ds\n\nfb(y) =\n0\n\nE\n\nZ\n\nf (\u03c6(y, \u03c4 (y)), u) \u03bc\u03c6(y,\u03c4 (y)) (du)\u039by (\u03c4 (y)).\n\n+\nE\n\nIt follows from the flow property \u03c6(\u03c6(x, t), s) = \u03c6(x, s + t), that\nZ \u03c4 (y) Z\n\nfb(\u03c6(y, t)) =\n\n=\n\n\u039by (s)\nds\n\u039by (t)\nt\nE\nZ\n\u039by (\u03c4 (y))\n+ f (\u03c6(y, \u03c4 (y)), u) \u03bc\u03c6(y,\u03c4 (y)) (du)\n\u039by (t)\nE\nZ tZ\n\u0011\n\u0010\n1\nfb(y) \u2212\nf (\u03c6(y, s), u) \u03bc\u03c6(y,s) (du)\u03bb(\u03c6(y, s))\u039by (s) ds .\n\u039by (t)\n0 E\nf (\u03c6(y, s), u) \u03bc\u03c6(y,s) (du)\u03bb(\u03c6(y, s))\n\nd b\nSince X fb(y) = limt\u21920 dt\nf (\u03c6(y, t)), we obtain X fb(y) = \u03bb(y)(fb(y) \u2212\nfollows that the generator applies to fb in the following way,\n\nAfb(y) =\n=\n=\n\n\u0010\n\n\u03bb(y) fb(y) \u2212\n\nZ\n\nR\n\nE f (y, u) \u03bcy (du)).\n\nIt\n\n\u0011\n\nf (y, u) \u03bcy (du) + Qfb(y)\n\nZE\n\nZ\n\u0011\nb\n\u03bb(y) f (y) \u2212 f (y, u) \u03bcy (du) + (fb(u) \u2212 fb(y)) \u03bcy (du)\nE\nE\nZ\nb\n\u03bb(y) (f (u) \u2212 f (y, u)) \u03bcy (du).\n\u0010\n\nE\n\n(13)\n\n\fTIME REVERSAL OF PDMPS\n\n9\n\nNext we show thatR \u03be is an invariant measure forRZ, i.e. \u03be fb = \u03bef , where we use the usual\nabbreviation \u03bef = EZ f (x, y)\u03be(dx, dy) and \u03be fb = EZ fb(y)\u03be(dx, dy). It follows from (8) and\n(13) that\nZ\n\nZ\n\n\u03bb(y)\nE\n\n(fb(u) \u2212 f (y, u)) \u03bcy (du) \u03bd(dy) +\n\nZ Z\n\n(fb(u) \u2212 fb(y)) \u03bcy (du) \u03c3(dy) = 0.\n\n\u0393 E\n\nE\n\nR\nHence, using the identity fb(y) = E f (y, u) \u03bcy (du) for y \u2208 \u0393, we have:\nZ\nZ\nZ Z\nb\n\u03bb(y) f (u) \u03bcy (du) \u03bd(dy) +\nfb(u) \u03bcy (du) \u03c3(dy)\nE\n\n\u0393 E\n\nE\n\nZ\n\nZ\n\nZ Z\n\n\u03bb(y)\n\n=\nE\n\nf (y, u) \u03bcy (du) \u03bd(dy) +\n\nf (y, u) \u03bcy (du) \u03c3(dy)\n\u0393 E\n\nE\n\nproving that \u03be fb = \u03bef .\n\n\u0003\n\nIt follows immediately that a stationary distributions of Wk (the state of the process\njust before the jump) is given by\n\u03c0W (A) =\n\n1 \u0010\nk\u03bek\n\nZ\n\n\u0011\n\n\u03bb(x)\u03bd(dx) + \u03c3(A \u2229 \u0393) ,\n\n(14)\n\nA\u2229E\n\nfor A \u2208 B(E? ). The restricted measure \u03c0W |E is absolutely continuous with respect to \u03bd with\nRadon-Nikodym derivative \u03bb, whereas on the active boundary \u03c0W |\u0393 is a constant multiple\nof the measure \u03c3. Note that for an empty active boundary and a constant jump rate\nthe above relation shows that the PASTA property (Poisson Arrivals See Time Average)\n\u03c0W (A) = \u03bd(A) holds.\nBy Theorem 1 a stationary distribution for the observations Qk of the process right after\nthe jumps is given by\nZ\n\n\u03c0Q (B) =\n=\n\nE?\n\n\u03bcx (B)\u03c0W (dx)\n\n1 \u0010\nk\u03bek\n\nZ\n\n(15)\nZ\n\n\u03bb(x)\u03bcx (B)\u03bd(dx) +\nE\n\n\u0011\n\n\u03bcx (B)\u03c3(dx) ,\n\u0393\n\nfor B \u2208 B(E), confirming the results in [22, 18]. Note that the formula for \u03c0Q follows from\n(14) after conditioning on the jump size.\n1.4. Absolute continuity of the stationary measure. It is interesting to ask under\nwhich conditions \u03bd is an absolutely continuous measure (w.r.t. Lebesgue measure). This\nproperty jointly with absolutely continuity of the jump measure or stationary measure \u03c0Q\nsimplifies the identification of the parameters of the reversed process. For one-dimensional\nmodels on the real line \u03bd was found to be absolutely continuous under very mild conditions,\nsee [58, 9, 10, 36, 37, 18]. This is in accordance with countless observations of absolutely\ncontinuous stationary distributions for PDMP type stochastic models in the literature (e.g.\n[3, 12, 13, 27, 6, 5, 40]). However, in general, i.e. for higher dimensions, it seems very hard\nto give necessary and sufficient criteria.\nWe introduce one more condition on the process Xt .\nCondition C. E\u03c0Q (T1 ) < \u221e.\nRemark 5. The condition is satisfied in the vast majority of cases. The reason to introduce\nit is the following useful converse to (15). If E\u03c0Q (T1 ) < \u221e then the stationary measure \u03bd\n\n\fTIME REVERSAL OF PDMPS\n\n10\n\ncan be reconstructed from \u03c0Q by an argument from regeneration theory. Note that under\n\u03c0Q the time until the first jumps occurs forms a cycle, hence, by [3, Corollary VII 1.4],\nE\u03bd (f (X0 )) =\n\nE\u03c0Q (\n\nR T1\n\n0 f (Xs ) ds)\n;\nE\u03c0Q (T1 )\n\n(16)\n\n(c.f. with [18, equation (12)]) for bounded continuous functions f .\nRecall that the state space E consists of a disjoint union of components Ei : E = {(x, i) :\ni \u2208 K, x \u2208 Ei }. The following proposition gives a criterion for absolute continuity of \u03bd on\none of these Ei , i \u2208 K.\nProposition 3. Suppose that, additionally to Condition (C), r(x) 6= 0 for all x \u2208 Ei . If\nd(i) = 1 then \u03bd is absolutely continuous on Ei . In general, \u03bd is absolutely continuous on\nEi if \u03c0Q is absolutely continuous there and r is continuously differentiable.\nProof. It follows from (16) that\n\u03bd(A) \u2264 cE\u03c0Q (\n\nZ T1\n\n1{Xs \u2208A} ds)\n\n0\n\n(17)\n\nwith some constant c > 0. If d(i) = 1 and r(x) 6= 0, then `1 (A \u2229 \u03a6+\nx ) = 0 for all Lebesgue\nR T1\nnull sets A \u2208 B(R) and in particular Ex ( 0 1{Xs \u2208A} ds) = 0. It follows from (17) that\n\u03bd(A) = 0, showing that \u03bd is absolutely continuous. In the general case, i.e. if d(i) \u2265 1,\nsuppose that \u03c0Q is absolutely continuous. We have\nZ T1\n\nE\u03c0Q (\n\n0\n\n1{Xs \u2208A} ds) \u2264\n\nZ\n\nEx (T1 ) \u03c0Q (dx),\n\n(18)\n\nCA\n\nR \u03c4 (x)\n\nwhere CA = {x \u2208 Ei : 0 1{\u03c6(x,s)\u2208A} ds 6= 0}. If we can show that CA is a Lebesgue null\nset, then it follows that \u03c0Q (CA ) = 0, since \u03c0Q is absolutely continuous. But then the right\nhand side of (18) is zero and absolutely continuity of \u03bd follows from (16). To show that\n`d(i) (CA ) = 0, suppose the converse. Then\nZ \u221eZ\n\nZ Z \u221e\n\n0<\nE 0\n\n1{s<\u03c4 (x),\u03c6(x,s)\u2208A} ds dx =\n\n0\n\n1{s<\u03c4 (x),\u03c6(x,s)\u2208A} dx ds.\n\n(19)\n\nEi\n\nIf r is continuously differentiable then \u03b6t : x 7\u2192 \u03c6(x, \u2212t) is also continuously differentiable\n(e.g. [29, p.95]). It follows that \u03b6t maps Lebesgue\nnull sets to Lebesgue null sets (see\nR\n[57, Proposition 26.3]) and that the integral of Ei 1{s<\u03c4 (x),\u03c6(x,s)\u2208A} dx over the indicator\nfunction of the image \u03b6s (A) of A, must be zero, contradicting (19). Hence `d(i) (CA ) = 0\nand \u03bd is absolutely continuous.\n\u0003\nRemark 6. The condition on r can be relaxed. In fact it is enough to require that \u03b6t fulfils\nthe weaker condition\nsup lim\n\nx\u2208E x\u2192y\n\n|\u03b6t (x) \u2212 \u03b6t (y)|\n< \u221e.\n|x \u2212 y|\n\n(20)\n\nIn that case \u03b6t fulfils what is called Lusin's condition (N), that is \u03b6t maps null sets to null\nsets ([57, Proposition 26.2]).\n\n\fTIME REVERSAL OF PDMPS\n\n11\n\n2. The reversed process\n2.1. Definition. We now assume Xt to be stationary, that is, the process starts with\ninitial distribution \u03bd and then has the same distribution for all t \u2265 0. We pick a fixed\ntime T > 0 and define the reversed process for t \u2208 [0, T ] by Xt? = X(T \u2212t)\u2212 (we indicate\nvariables belonging to the reversed process with a star). Then Xt? is a right-continuous\nstationary stochastic process with state space E? and initial distribution \u03bd. Obviously the\nactive boundary of the reversed process is given by \u0393? and conversely the passive boundary\nis now \u0393. It is known (see [43] and [44, Theorem 2.1.1]) that Xt? , constructed in this way, is\nagain a time homogeneous Markov process. Obviously Xt? inherits from Xt the property to\nhave piecewise deterministic paths with random jumps and no explosions. So Xt? would in\nfact be a PDMP if we could show that Xt? has a regular jump intensity \u03bb? , in the sense that\nthe conditions (A1 ) and (A2 ) for \u03bb have to be fulfilled also for \u03bb? (this is not self-evident,\nsee the example below). Therefore, we have to impose two more conditions on the process\nXt , namely \u03c0Q has to be absolutely continuous on E\u25e6 (allowing a mass on \u0393? = E \\ E\u25e6 )\nwith a locally integrable Radon-Nikodym derivative, which in Proposition 4 below will be\nseen to be our jump intensity function for the reversed process.\nCondition D. From now on we assume:\n(D1 ) \u03c0Q |E\u25e6 \u001c \u03bd with Radon-Nikodym derivative \u03b2(x) = d\u03c0Q |E\u25e6 /d\u03bd(x), x \u2208 E\u25e6 .\nR \u03b5(x)\n(D2 ) For all x \u2208 E there is an \u03b5(x) > 0, such that 0 \u03b2(\u03c6(x, \u2212s)) ds < \u221e.\nProposition 4. Under Condition (D) the reversed process is a PDMP, fulfilling the conditions (A1 )-(A4 ), with intensity function given by \u03bb? (x) = k\u03bek\u03b2(x).\nProof. According to (11) the probability p? (h; B, E? ) that Xt? \u2208 B \u2286 E\u25e6 and that the\nprocess has a voluntary jump during [t, t + h] is given by\n?\n\n?\n\np (h; B, E ) = h *\n\nZ\n\n\u03bb? (x)\u03bd(dx) + o(h).\n\nB\n\nOn the other hand, by construction of Xt? , p? (h; B, E? ) is equal to the probability p(h; E? , B)\nand hence equal to\n?\n\np(h; E , B) = h *\n\n\u0010Z\n\nZ\n\n\u03bcx (B)\u03c3(dx) + o(1)\n\n\u03bb(x)\u03bcx (B)\u03bd(dx) +\n\n\u0011\n\n(21)\n\n\u0393\n\nE\n\nZ\n\n= hk\u03bek\u03c0Q (B) + o(h) = h\n\nk\u03bek\u03b2(x) \u03bd(dx) + o(h),\n\nB\n\nyielding \u03bb? (x) = k\u03bek\u03b2(x). Condition (D) ensures that \u03bb? fulfills (A1 ). Moreover the\ncondition (A2 ), i.e. P (T1? < \u221e) = 1, certainly holds. Indeed \u03bb? (x) is a proper intensity\nfunction for the PDMP Xt? .\n\u0003\nRemark 7. Since\nZ\n\n\u03bb? (x)\u03bd(dx) = k\u03bek\n\nE?\n\nZ\nE?\n\n\u03b2(x)\u03bd(dx) = k\u03bek\u03c0Q (E? ) < \u221e,\n\nit follows that (B2 ) always holds.\nRemark 8. Condition (D) is not always fulfilled, as the following simple counterexample\nshows. Consider Xt on [0, 1] with X f (x) = f 0 (x) (linear growth with rate one), \u0393 = {1},\n\n\fTIME REVERSAL OF PDMPS\n\n12\n\n\u03bb(x) = 0 for x \u2208 [0, 1), \u03bc1 (A) = 12 (1{1/2\u2208A} + 1{0\u2208A} ), so that jumps can go from \u0393 to 0\nand 1/2 only, each with probability 1/2. It is not difficult to show that\n1{x<1/2} 2x + 1{x\u22651/2} (4x \u2212 1)\n,\n3\nhence the stationary measure is absolutely continuous, but \u03c0Q is certainly not. What\nhappens is that the reversed process X ? is not a proper PDMP since with a positive\nprobability the process is forced to jump when reaching 1/2.\n\u03bd([0, x]) =\n\n2.2. The parameters of the reversed process. The following theorem shows that\nthe stationary distribution of the reversed Markov chain Zk? = (Wk? , Q?k ) is given by the\nmeasure \u03c0, but with reversed arguments.\nTheorem 2. For all A \u2208 B(E? ), B \u2208 B(E) we have \u03c0(A, B) = \u03c0 ? (B, A).\nProof. The probability p? (h; B, A) that X ? \u2208 B and that the process jumps during [t, t+h]\ninto the set A is equal to (c.f. (21)):\np? (h; B, A) = hk\u03be ? k\u03c0 ? (B, A) + o(h).\nAt the same time, by the definition of the reversed process, p? (h; B, A) = p(h; A, B)\nso k\u03be ? k\u03c0 ? (B, A) = k\u03bek\u03c0(A, B) + o(1), implying first k\u03be ? k = k\u03bek and then \u03c0 ? (B, A) =\n\u03c0(A, B).\n\u0003\nWe can also write this as\n\u03bc?y (dx)(\u03bb? (y)\u03bd(dy) + \u03c3 ? (dy)) = \u03bcx (dy)(\u03bb(x)\u03bd(dx) + \u03c3(dx)).\nIntegrating over y \u2208 A \u2286 E, x \u2208 B \u2286\nZ\ny\u2208A\n\n\u03bc?y (B)(\u03bb? (y)\u03bd(dy)\n\nE?\n?\n\n(22)\n\nwe obtain\nZ\n\n\u03bcx (A)(\u03bb(x)\u03bd(dx) + \u03c3(dx)).\n\n+ \u03c3 (dy)) =\nx\u2208B\n\nThe terms in the parentheses in (22) coincide with the stationary distributions of W and\nW ? respectively. Hence we obtain the shorter representation\n?\n\u03bcx (dy)\u03c0W (dx) = \u03bc?y (dx)\u03c0W\n(dy).\n\n(23)\n\nIn particular the stationary distributions of the imbedded Markov chains correspond to\n? and \u03c0\n?\neach other: \u03c0Q = \u03c0W\nW = \u03c0Q .\nFrequently the jump measure \u03bcx is absolutely continuous with respect to some other\nmeasure \u03bc for every x \u2208 E? . If this is the case, the same is true for the jump measure of\nthe reversed process as the following corollary of Theorem 2 shows.\nProposition 5. Suppose that \u03bcx \u001c \u03bc with some measure \u03bc on E for every x \u2208 E? .\n\u03c0Q \u001c \u03bc and\nd\u03bcx\nd\u03c0Q\n(y)\u03bc?y (dx) =\n(y)\u03c0W (dx).\nd\u03bc\nd\u03bc\nThe jump intensity of the reversed process fulfils\nd\u03c0Q\n\u03bb? (y)\u03bd(dy) = k\u03bek\n(y) \u03bc|E? (dy).\nd\u03bc\nFor the boundary measure we have \u03c3 ? \u001c \u03bc|\u0393? and\nd\u03c0Q\n\u03c3 ? (dy) = k\u03bek\n(y) \u03bc|\u0393? (dy).\nd\u03bc\n\nThen\n(24)\n\n(25)\n\n(26)\n\n\fTIME REVERSAL OF PDMPS\n\n13\n\nRemark 9. If \u03bcx is absolutely continuous for every x \u2208 E? and r is continuously differentiable then by Proposition 3 the stationary measure \u03bd is absolutely continuous, which\nsimplifies most calculations.\nProof. It follows from (15) that the stationary distribution of Q is absolutely continuous\nw.r.t. \u03bc, with derivative given by:\nd\u03c0Q\n(y) =\nd\u03bc\n\nZ\nx\u2208E?\n\nd\u03bcx\n(y)\u03c0W (dx).\nd\u03bc\n\n(27)\n\n? = \u03c0 it follows that\nBy Theorem 2, equation (23) and the fact that \u03c0W\nQ\n\nd\u03c0Q\nd\u03bcx\n?\n(y)\u03bc(dy)\u03c0W (dx) = \u03bc?y (dx)\u03c0W\n(dy) = \u03bc?y (dx)\u03c0Q (dy) =\n(y)\u03bc?y (dx)\u03bc(dy),\nd\u03bc\nd\u03bc\nimplying (24). From (22) and (24) it follows now that\n\u03bb? (y)\u03bd(dy) + \u03c3 ? (dy) = k\u03bek\n\nd\u03c0Q\n(y) \u03bc(dy),\nd\u03bc\n\u0003\n\nfrom which (25) and (26) can be deduced.\n\nRemark 10. We have \u03bcx \u001c \u03bc for example if \u03bcx (A) = \u03bc(A \u2229 Bx )/\u03bc(Bx ) for some set Bx\nwith \u03bc(Bx ) > 0. Then the Radon-Nikodym derivative is given by\n1{y\u2208Bx }\nd\u03bcx\n(y) =\n.\nd\u03bc\n\u03bc(Bx )\nFor example, if \u03bc is the Lebesgue-measure then \u03bcx is the uniform distribution on Bx .\nRemark 11. Suppose that Qi = gWi (Bi ), where gx : Rd \u2192 E is continuously differentiable\nwith det Dgx 6= 0 (here D is the Jacobian) and B1 , B2 , . . . are i.i.d. random variables with\nvalues in C = {z \u2208 Rd : gx (z) \u2208 E, \u2200x \u2208 E} (we assume that E is such that C is non-empty)\nand an absolutely continuous distribution with density f . Then\nZ\n\nZ\n\n\u03bcx (A) =\nC\n\n1{gx (y)\u2208A} f (y) dy =\n\ngx (C)\n\n1{y\u2208A} f (gx\u22121 (y))\ndy =\n| det Dgx (y)|\n\nZ\nA\n\n1{y\u2208gx (C)} f (gx\u22121 (y))\ndy,\n| det Dgx (y)|\n\nso that \u03bcx \u001c ` with density\n\u03bc0x (y) = 1{y\u2208gx (C)}\n\nf (gx\u22121 (y))\n.\n| det Dgx (y)|\n\nSuppose for example that the frequent situation where Qi = Wi + Bi is present, so that\nthe jumps are random translations. Then gx (y) = x + y, C = {z : z + x \u2208 E, \u2200x \u2208 E} and\n\u03bcx is absolutely continuous with density\n\u03bc0x (y) = 1{y\u2208C+x} f (y \u2212 x).\nAccording to the classic literature on reversed Markov processes (see [43, 44]) one would\nexpect that the generator A? of X ? is the adjoint operator of A, that is\nZ\n\nZ\n\ng(x)Af (x)\u03bd(dx) =\nE\n\nf (x)A? g(x)\u03bd(dx),\n\nE?\n\nfor bounded functions f, g in D(A) \u2229 D(A? ). This is indeed true and in the case of PDMPs\nthis result takes the following form:\n\n\fTIME REVERSAL OF PDMPS\n\n14\n\nTheorem 3. For f, g \u2208 Mb0 we have\nZ\n\nZ\n\ng(x)Af (x)\u03bd(dx) +\n\ng(x)Qf (x)\u03c3(dx)\n\u0393\n\nE\n\nZ\n\nf (x)A? g(x)\u03bd(dx) +\n\n=\nE?\n\nZ\n\nf (x)Q? g(x)\u03c3 ? (dx).\n\n(28)\n\n\u0393?\n\nProof. Using the representation Af (x) = X f (x) + \u03bb(x)Qf (x), it follows that\nZ\n\nZ\n\ng(x)Af (x)\u03bd(dx) +\n\ng(x)Qf (x)\u03c3(dx)\n\u0393\n\nE\n\nZ\n\nZ\n\n\u0002\n\ng(x)X f (x)\u03bd(dx) +\n\n=\n\n\u0003\n\ng(x)Qf (x) \u03bb(x)\u03bd(dx) + \u03c3(dx) .\n\n(29)\n\nE?\n\nE\n\nLeibnitz's rule X (f g) = X f * g + f * X g and the definition of Q imply that the r.h.s. of\n(29) is equal to\nZ\n\nX (f g)(x)\u03bd(dx) \u2212\n\nE\n\nZ\n\nf (x)X g(x)\u03bd(dx)\nE\n\nZ\n\nZ\n\n\u0002\n\nE?\n\n\u0003\n\n(g(x)f (y) \u2212 g(x)f (x))\u03bcx (dy) \u03bb(x)\u03bd(dx) \u2212 \u03c3(dx) .\n\n+\n\n(30)\n\nE\n\nIt follows from (8) that the integrals w.r.t. \u03bd of X (f g)(x) and \u2212\u03bb(x)Q(f g)(x) coincide.\nHence (30) equals:\n\u2212\n\nZ\n\n\u03bb(x)Q(f g)(x)\u03bd(dx) \u2212\n\nE\n\nZ\n\nf (x)X g(x)\u03bd(dx)\nE\n\nZ\n\nZ\n\n\u0002\n\nE?\n\n\u0003\n\n(g(x)f (y) \u2212 g(x)f (x))\u03bcx (dy) \u03bb(x)\u03bd(dx) \u2212 \u03c3(dx) ,\n\n+\nE\n\nwhich, again by the definition of Q, produces:\n\u2212\n\nZ\n\nZ\n\nZ\n\n\u0002\n\nE?\n\nE\n\n\u0003\n\n(g(x)f (y) \u2212 g(y)f (y))\u03bcx (dy) \u03bb(x)\u03bd(dx) \u2212 \u03c3(dx) .\n\nf (x)X g(x)\u03bd(dx) +\nE\n\nSince \u03bcx (dy) \u03bb(x)\u03bd(dx)\u2212\u03c3(dx) = \u03bc?y (dx) \u03bb? (y)\u03bd(dy)\u2212\u03c3 ? (dy) by Theorem 2, this is equal\nto\n\u0002\n\n\u2212\n\n\u0003\n\n\u0002\n\nZ Z\n\nZ\n\nE\n\nZ\n\n?\n\n(g(x)f (y) \u2212 g(y)f (y))\u03bc?y (dx) \u03bb? (y)\u03bd(dy) \u2212 \u03c3 ? (dy)\n\u0002\n\nf (x)X g(x)\u03bd(dx) +\nE?\n\nE?\n\nZ\n\nf (x)A g(x)\u03bd(dx) +\n\n=\nE?\n\n\u0003\n\nf (x)Q? g(x)\u03c3 ? (dx).\n\n\u0393?\n\n\u0003\n\n\u0003\n\n3. Processes on the real line\n3.1. Introduction. In this section we assume that Xt has values in R and that t 7\u2192 \u03c6(x, t)\nis strictly increasing, that is X f (x) = r(x)f 0 (x) with some locally Lipschitz-continuous\nfunction r : E \u2192 R with r(x) > 0, x \u2208 E\u25e6 . The state space of Xt is a real interval [w, \u03b3),\nw < \u03b3, where it is allowed to have either w = \u2212\u221e (then E = (\u2212\u221e, \u03b3)) or \u03b3 = \u221e (then\nE = [w, \u221e)) or both (in which case E = R). We assume that \u03c4 (x) < \u221e for some (and\nthen all) x \u2208 E, whenever \u03b3 < \u221e, so that {\u03b3} can be reached in finite time (otherwise one\ncould transform the state space to obtain the \u03b3 = \u221e case). Hence, the active boundary is\nempty if \u03b3 = \u221e and is equal to {\u03b3} else.\nThe following figure shows typical sample paths for the case where \u03bb(x) = 1 (Nt is a\nPoisson process), r(x) = 4 \u2212 x i.e. \u03c6(x, t) = 4 \u2212 (4 \u2212 x)e\u2212t , \u03b3 = 2 (so \u0393 = {2} and\n\n\fTIME REVERSAL OF PDMPS\n\n15\n\nE = (\u2212\u221e, 2)) and \u03bcx (dy) = e\u2212y dy, i.e.the process jumps from x to x \u2212 Z, where Z is\nexponential with mean one.\n\nConditions for the existence of a stationary distribution \u03bd can be found in [58, 36]. The\nboundary measure \u03c3 is determined by the single value \u03c3({\u03b3}) which can be calculated as\nfollows. According to (9) we have\n\u03bd({x : \u03c4 (x, \u03b3) < h})\n1\n= lim\nh\u21920\nh\u21920 h\nh\n\nZ\n\n\u03c3({\u03b3}) = lim\n\n1\nh\u21920 h\n\nZ h\n\n= lim\n\n[w,\u03b3]\n\n1{\u03c4 (x,\u03b3)<h} \u03bd(dx)\n\nr(\u03c6(\u03b3, \u2212s))\u03bd 0 (\u03c6(\u03b3, \u2212s)) ds = r(\u03b3)\u03bd 0 (\u03b3).\n\n0\n\nThe following Theorem generalizes known formulas for the stationary density (see e.g. [3,\np.383], [6, Theorem 2.1], [40, Theorem 1], [12, Proposition 4], c.f. [37, Proposition 2.2]).\nTheorem 4. The stationary distribution \u03bd is absolutely continuous on [w, \u03b3). The density\n\u03bd 0 of \u03bd fulfills the integro-differential equation:\nr(x)\u03bd 0 (x) =\n\nZ \u03b3\n\n\u03bb(z)\u03b8(x, z)\u03bd 0 (z) dz + \u03c3({\u03b3})\u03b8(x, \u03b3),\n\nx \u2208 (w, \u03b3),\n\n(31)\n\nw\n\nwhere \u03b8(x, z) = 1{x\u2264z} \u03bcz ([w, x)) \u2212 1{x>z} \u03bcz ([x, \u03b3)) = \u03bcz ([w, x)) \u2212 1{x>z} .\n0\nf is absolutely continuous and f (y) \u2212 f (x) =\nProof.\nR y 0 Suppose that f \u2208 Mb . 0 Then\n\u25e6 \u2192 R. Hence, using Fubini's theorem,\nf\n(u)\ndu,\nwith\na\nmeasurable\nf\n:\nE\nx\n\nZ \u03b3\n\nQf (z) =\n\n(f (y) \u2212 f (z)) \u03bcz (dy) =\n\nZw\u03b3 Z \u03b3\n\nw\n0\n\nw\n\nf 0 (x) dx \u03bcz (dy)\n\nz\n\n1{z<x\u2264y} \u03bcz (dy)f (x) dx \u2212\n\n=\nZw\u03b3\n\nZ \u03b3Z y\n\nZ \u03b3Z \u03b3\nw\n\nw\n\n1{y<x<z} \u03bcz (dy)f 0 (x) dx\n\n1{x>z} \u03bcz ([x, \u03b3)) \u2212 1{x\u2264z} \u03bcz ([w, x)) f 0 (x) dx.\n\u0001\n\n=\nw\n\nIt follows from (8), applying Fubini once again, that\nZ\n\nr(x)f 0 (x)\u03bd(dx) = \u2212\n\n[w,\u03b3)\n\n=\n\nZ\n\n\u03bb(z)Qf (z)\u03bd(dz) \u2212 \u03c3({\u03b3})Qf (\u03b3).\n\n[w,\u03b3)\n\nZ \u03b3 \u0010Z\nw\n\n\u2212\n\n\u03bb(z)\u03bcz ([w, x))\u03bd(dz)\n\n[x,\u03b3)\n\nZ\n\n\u0011\n\n\u03bb(z)\u03bcz ([x, \u03b3))\u03bd(dz) + \u03c3({\u03b3})\u03bc\u03b3 ([w, x)) f 0 (x) dx.\n\n(32)\n\n[w,x)\n\nHence \u03bd is absolutely continuous with density \u03bd 0 fulfilling (31).\n\n\u0003\n\n\fTIME REVERSAL OF PDMPS\n\n16\n\n3.2. The reversed process. Given a PDMP on the real line and a fixed time T > 0,\nwe define Xt? = X(T \u2212t)\u2212 as before. As in the general case, under the Condition (D) this\nreversed process is a PDMP. Its deterministic path is decreasing with r? (x) = \u2212r(x) and\nthe active boundary is {w} if w > \u2212\u221e. In contrast to the higher dimensional setting, in\nthe present situation the integro-differential equation (31) for \u03bd enables us to express \u03bb?\nmore explicitly.\nRemark 12. In practical applications one may use the following sufficient conditions to\nensure that the conditions (A1 )\u2013(D1 ) hold.\n(1) \u03bb is continuous, bounded and bounded away from zero. This condition implies\n(A1 ), (A2 ), (B2 ), (B3 ) and (C).\n(2) For all x \u2208 E? , \u03bcx (B) is absolutely continuous with density \u03bc0x (y), which is a\ncontinuous function of x. This implies (A4 ) and (B4 ).\n(3) there exists a stationary distribution \u03bd (which is necessarily absolutely continuous,\nsee Proposition 3) with density fulfilling \u03bd 0 (x) 6= 0 for x \u2208 E\u25e6 ; then (B1 ) is obvious\nand since\nR\n0\n0\nd\u03c0Q (z)\n? \u03bc (z)\u03bb(x)\u03bd (x) dx\n= E x\n.\n(33)\nd\u03bd(z)\n\u03bd 0 (z)\nit follows that also (D1 ) is implied, too.\n(4) there is no active boundary or there exists \u000f > 0 such that \u03bcx (\u03c4 (x) > \u000f) = 1 for all\nx \u2208 \u0393, implying (B5 ) as well as (A3 ) (along with (1), see [22, (26.4), p. 60]).\nCondition (D2 ), local integrability of \u03bb? , has to be checked in each particular case. If for\nexample \u03bc0x is bounded and 1/\u03bd 0 (z) is locally integrable, then (D2 ) is fulfilled (see equation\n(33)).\nTheorem 5. If \u03bcx is absolutely continuous for all x \u2208 E with density \u03bc0x and r is absolutely\ncontinuous then so is \u03bd 0 (with derivative \u03bd 00 ) and if \u03bd 0 (x) 6= 0, then\n\u03bb? (x) = \u03bb(x) + r0 (x) + r(x)\n\u03bb(y)\u03bd 0 (y) 0\n\u03bc (x),\n\u03bb? (x)\u03bd 0 (x) y\n\u03c3({\u03b3}) 0\n\u03bc (x),\n?\n\u03bb (x)\u03bd 0 (x) \u03b3\n\n\u03bc?0\nx (y) =\n\u03bc?x ({\u03b3}) =\n\n\u03bd 00 (x)\n,\n\u03bd 0 (x)\n\nx \u2208 E? ,\n\n(34)\n\nx \u2208 E, y \u2208 E? ,\n\n(35)\n\nx \u2208 E? .\n\n(36)\n\nProof. From Theorem 4 it follows that \u03bd 0 is absolutely continuous and by (25) and (15) we\nhave:\n0\n\n?\n\n\u0001\n\n\u03bd (u) \u03bb (u) \u2212 \u03bb(u) =\n\nZ\n\n\u03bb(x)\u03bc0x (u)\u03bd 0 (x) dx\n\nE\n\nZ\n\n+\n\u0393\n\n\u03bc0x (u)\u03c3(dx) \u2212 \u03bb(u)\u03bd 0 (u).\n\n(37)\n\nHence from (31) it follows that\n\u03bd 0 (u) \u03bb? (u) \u2212 \u03bb(u) =\n\u0001\n\nZ\n[u,\u03b3)\n\n\u03bb(x)\u03bc0x (u)\u03bd 0 (x) dx \u2212 \u03bb(u)\u03bd 0 (u)\u03bcu ([u, \u03b3))\n\nZ\n\n+\n(\u2212\u221e,u)\n\n\u03bb(x)\u03bc0x (u)\u03bd 0 (x) dx \u2212 \u03bb(u)\u03bd 0 (u)\u03bcu ((\u2212\u221e, u)) + \u03c3({\u03b3})\u03bc0\u03b3 (u)\n\n= (r(u)\u03bd 0 (u))0\n\n\fTIME REVERSAL OF PDMPS\n\n17\n\nwhich proves (34). The relation (35) follows from Proposition 5 since\n0 (y)\n0 (y)\n\u03c0W\n\u03c0W\n\u03bb(y)\u03bd 0 (y) 0\n0\n0\n\u03bc\n(x)\n=\n\u03bc\n(x)\n=\n\u03bc (x).\n0 (x) y\n0 (x) y\n\u03c0Q\n\u03c0W\n\u03bb? (x)\u03bd 0 (x) y\n?\n\n\u03bc?0\nx (y) =\n\n\u0003\n\nThe proof of (36) is similar.\nRemark 13. It follows from (34) that\n\u00010\n\n\u03bb? (x) \u2212 \u03bb(x) = r(x) log(r(x)\u03bd 0 (x))\n\nSuppose that we observe the stationary process in state x. If (log(r(x)\u03bd 0 (x)))0 is positive\n(negative) then it is more likely (less likely) to find a jump in the near past than to find a\njump in the near future.\nLet assume that the processes Xt , Wk , Qk have been continued to the left. This can\n? for t < 0, where Y ? is the time reversal of\neasily be achieved by setting Xt equal to Y\u2212t\nan independent version (Yt )t\u22650 of the PDMP. Then Q\u22121 denotes the state of Xt just after\nthe last jump before time 0.\nCorollary 1. If \u03bcx is absolutely continuous for all x \u2208 E, then\nr(y)\u03bd 0 (y)Py (W1 > x) = r(x)\u03bd 0 (x)Px (Q\u22121 < y),\n\ny \u2264 x \u2208 E.\n\n(38)\n\nProof. Dividing (34) by \u03bd 0 (u) and integrating yields\nZ x ?\n\u03bb (u) \u2212 \u03bb(u)\ny\n\nUsing\n\nr? (x)\n\nr(u)\n\ndu =\n\nZ x\n(r(u)\u03bd 0 (u))0\n\nr(u)\u03bd 0 (u)\n\ny\n\ndu = log\n\nr(x)\u03bd 0 (x) \u0001\n.\nr(y)\u03bd 0 (y)\n\n= \u2212r(x), we obtain:\n0\n\nr(y)\u03bd (y)e\n\n\u2212\n\nRx\n\n\u03bb(u)\ny r(u)\n\ndu\n\n0\n\n= r(x)\u03bd (x)e\n\n\u2212\n\n\u03bb? (u)\nx r ? (u)\n\nRy\n\ndu\n\n.\n\nBy (4) this is equivalent to\nr(y)\u03bd 0 (y)e\u2212\n\nR \u03c4 (x,y)\n0\n\n\u03bb(\u03c6(y,s)) ds\n\n= r(x)\u03bd 0 (x)e\u2212\n\nR \u03c4 ? (x,y)\n0\n\n\u03bb? (\u03c6(x,s)) ds\n\n,\n\nwhich is equivalent to (38).\n\n\u0003\n\nWe assume in the following examples that the conditions (A1 )\u2013(B4 ) and Condition (D)\nare satisfied. See Remark 12 for sufficient conditions.\n3.3. Renewal age process.\n\nFig.: Forward recurrence time Xt with F being a half-normal distribution with mean 1.\n\n\fTIME REVERSAL OF PDMPS\n\n18\n\nConsider the classic renewal process Nt with renewal times T1 , T2 , . . .. If the distribution\nof T1 is absolutely continuous with distribution F (x) and density f (x) then the backward\nrecurrence time Xt = t \u2212 TNt is a PDMP with r(x) = 1 and \u03bb(x) being equal to the hazard\nrate f (x)/(1 \u2212 F (x)). The associated jump measure is, independently of x, concentrated\nin zero and the active boundary is empty (hence w = 0 and \u03b3 = \u221e). It follows from (31)\nthat, provided that E(T1 ) is finite, the density of the stationary distribution fulfills:\n\u03bd 0 (x) =\n\nZ\n[x,\u221e)\n\nf (z)\n\u03bd 0 (z) dz.\n1 \u2212 F (z)\n\nThis leads to the well known fact that \u03bd is equal to the equilibrium or stationary excess\ndistribution of F :\n\u03bd 0 (x) =\n\n1 \u2212 F (x)\n.\nE(T1 )\n\nThe reversed process Xt? is the forward recurrence time process of the same renewal process.\nApplying Theorem 2 we see that \u03bb? (y) = 0 for y \u2208 E? and that\nf (x) dx = \u03bc?0 (dx)\u03c3 ? ({0})\nfrom which, upon integration, \u03c3 ? ({0}) = 1/E(T1 ) follows (the average number of visits to\n0) and hence \u03bc?0 (dx) = f (x) dx, which is not surprising: the upward jumps of the reversed\nprocess are just i.i.d. jumps with distribution F . Hence, for the trivial case of the renewal\nprocess our formulas yield the correct results.\n3.4. Generalized TCP window size process.\n\nFig.: Generalized TCP window size process with \u03b1 = 1/2, \u03b2 = 1, \u03b3 = 1.\n\nIn [40] a generalized model for the TCP window size has been studied (see also [2, 24,\n16, 39, 4, 42]). We assume that Xt is a process with \u03bb(x) = \u03bbx\u03b2 , r(x) = rx\u03b1 , \u03b2 > \u03b1 \u2212 1\n1/\u03b3\nand \u03bcx ((0, y]) = (y/x)\u03b3 , which means that Qk = UK * Wk , where the Uk are independent\nrandom variables with uniform distribution on (0, 1). In other words, at jump times the\n1/\u03b3\nprocess is multiplied by the random number Uk .\nUsing Theorem 4 it can be shown that under the condition \u03b2 > \u03b1 \u22121 a unique stationary\ndistribution \u03bd exists and\n\u0001\n\u03bb\n\u03bd 0 (x) = Cx\u03b3\u2212\u03b1 exp \u2212\nx\u03b2\u2212\u03b1+1\nr(\u03b2 \u2212 \u03b1 + 1)\n(see (27) in [40] for the normalizing constant C). Surprisingly, it follows from\n\u03bd 00 (x)\n\u03b3 \u2212 \u03b1 \u03bbx\u03b2\u2212\u03b1\n=\n\u2212\n\u03bd 0 (x)\nx\nr\n\n\fTIME REVERSAL OF PDMPS\n\n19\n\nthat the jump intensity of the reversed process is of the same form as \u03bb:\n\u03bb? (x) = \u03bb(x) + r0 (x) + r(x)\n\n\u03bd 00 (x)\n= r\u03b3x\u03b1\u22121 .\n\u03bd 0 (x)\n\nAs long as \u03b2 > 0 the reversed process X ? cannot reach 0 in finite time. If \u03b2 \u2264 0 then\nthe process could reach 0, but since \u03b1 \u2212 1 < \u03b2 \u2264 \u22121, it follows that \u03bb? is not integrable\non [0, \u03b5) for any \u03b5: the process will almost surely (and by construction even surely) jump\nbefore it reaches 0.\nThe jump measure of the reversed process is of a different form than the one for the\noriginal process, namely\n\u03bc?0\nx (y) =\n\n\u0010\n\u0011\n\u03bb(y)\u03bc0y (x)\u03bd 0 (y)\n\u03bb \u03b2\u2212\u03b1\n\u03bb\n\u03b2\u2212\u03b1+1\n\u03b2\u2212\u03b1+1 \u0001\n=\ny\nexp\nx\n\u2212\ny\n,\n\u03bb? (x)\u03bd 0 (x)\nr\nr(\u03b2 \u2212 \u03b1 + 1)\n\n(39)\n\nfor y \u2265 x, so that we obtain a Weibull-type distribution\n\u03bc?x ((x, y]) = exp\n\n\u0010\n\n\u0001\u0011\n\u03bb\nx\u03b2\u2212\u03b1+1 \u2212 y \u03b2\u2212\u03b1+1 .\nr(\u03b2 \u2212 \u03b1 + 1)\n\n(40)\n\nIf \u03b1 = \u03b2 then the upward jumps of X ? follow an exponential distribution with mean r/\u03bb\nand the reversed process has additive jumps whereas the original process has multiplicative\njumps (this has been observed in [55]).\n3.5. Jumps independent of the current state.\n\nFig.: r(x) = 1, \u03bb(x) = 1, \u03bcx (A) = `(A \u2229 [0, 10]), \u03b3 = 10.\n\nSuppose that \u03bcz (A) = \u03bc(A) for all z \u2208 E and some absolutely continuous measure \u03bc on\n[w, \u03b3). Then it follows from (31) that\n0\n\nZ \u03b3\n\nr(x)\u03bd (x) =\n\n\u03bb(z)\u03b8(x, z)\u03bd 0 (z) dz + \u03c3({\u03b3})\u03b8(x, \u03b3),\n\nx \u2208 (w, \u03b3),\n\nw\n\nwhere \u03b8(x, z) = \u03bc([w, x)) \u2212 1{x>z} , implying that\n0\n\nr(x)\u03bd (x) = k\u03bek\u03bc([w, x)) \u2212\n\nZ x\n\n\u03bb(z)\u03bd 0 (z) dz,\n\nw\n\nwhere k\u03bek =\n\nR\u03b3\nw\n\n\u03bb(z)\u03bd 0 (z) dz\n\n+ \u03c3({\u03b3}). It follows that\n\nr(x)\u03bd 00 (x) + (r0 (x) + \u03bb(x))\u03bd 0 (x) = k\u03bek\u03bc0 (x)\nand hence, using \u03bd 0 (w) = 0,\n1\n\u03bd (x) = k\u03bek\nr(x)\n0\n\nZ x\nRx\n\u2212\nu\n\ne\n\nw\n\n\u03bb(y)\nr(y)\n\ndy\n\nd\u03bc(u).\n\n(41)\n\n\fTIME REVERSAL OF PDMPS\n\n20\n\nThen it follows from (34) and (41) that\n\u03bb? (x) = k\u03bek\n\n\u03bc0 (x)\n,\n\u03bd 0 (x)\n\nwhich is nothing else than (25) since \u03c0Q = \u03bc here. Note that k\u03bek can be found from the\nnormalizing condition \u03bd(E) = 1.\n3.6. Reflection. Suppose that Xt is a real valued PDMP with decreasing paths with the\nadditional feature that once the process reaches 0 the process stays in 0 for an exponentially\ndistributed time with mean 1/\u03bb(0). We assume that r(x) < 0 for all x > 0, so 0 can actually\nbe reached. Moreover the time to reach zero has finite mean. Technically this process is\nnot a PDMP on the real line. Instead the process can be modelled as a PDMP with two\nouter states. We let E\u25e61 = (0, \u03c2] with active boundary \u03931 = {0} and introduce a second\ncomponent E\u25e62 which includes the point {0}. Also let r(x) = 0 for all x \u2208 E\u25e62 . Then the\nstate space of Xt is {(x, i)|x \u2208 E\u25e6i , i \u2208 1, 2}. Once Xt hits (0, 1) it jumps to (0, 2) and stays\nthere until it jumps back to E\u25e61 . However, we avoid this cumbersome notation and just\nwrite E = [0, \u03c2] and \u0393 = {0} and thereby allow E \u2229 \u0393 6= \u2205. Note that the reversed process\nXt? , after jumping to 0, stays there for an exponentially distributed sojourn time until it\nstarts decreasing again.\nTheorem 6. The stationary distribution \u03bd is absolutely continuous on the interval (0, w).\nThe density \u03bd 0 of \u03bd fulfills the integro-differential equation:\nZ \u03c2\n\n0\n\nr(x)\u03bd (x) =\n\n\u03bb(z)\u03b8(x, z)\u03bd 0 (z) dz + \u03bb(0)\u03bd({0})\u03b8(x, 0),\n\nx \u2208 (0, \u03c2),\n\n(42)\n\n0\n\nwhere \u03b8(x, z) = 1{x\u2264z} \u03bcz ([0, x)) \u2212 1{x>z} \u03bcz ([x, \u03c2)) = \u03bcz ([0, x)) \u2212 1{x>z} .\nProof. As in the proof of Theorem 4 let f \u2208 Mb0 . By Fubini's theorem\nQf (z) =\n\nZ \u03c2\n\n(f (y) \u2212 f (z)) \u03bcz (dy) =\n\n0\n\n0\n\nZ \u03c2Z \u03c2\n\n=\nZ0\u03c2 0\n\n=\n0\n\nZ \u03c2Z y\n\nf 0 (x) dx \u03bcz (dy)\n\nz\n\n0\n\n1{z<x\u2264y} \u03bcz (dy)f (x) dx \u2212\n\nZ \u03c2Z \u03c2\n0\n\n0\n\n1{y<x<z} \u03bcz (dy)f 0 (x) dx\n\n1{x>z} \u03bcz ([x, \u03c2)) \u2212 1{x\u2264z} \u03bcz ([0, x)) f 0 (x) dx.\n\u0001\n\nIt follows from (8) and Qf (\u03b3) = 0 that\nZ\n\nr(x)f 0 (x)\u03bd(dx) = \u2212\n\n(0,\u03c2)\n\nZ\n\n\u03bb(z)Qf (z)\u03bd(dz)\n(0,\u03c2)\n\n=\u2212\n\nZ\n(0,\u03c2)\n\n\u0010Z \u03c2\n\n\u0011\n\n\u03bb(z)\u03b8(x, z)\u03bd(dz) + \u03bb(0)\u03b8(x, 0)\u03bd({0}) f 0 (x) dx,\n\n0\n\nso \u03bd is absolutely continuous and (42) holds.\n\n\u0003\n\nThe parameters of the reversed process are given in Theorem 5 applied for \u2212Xt and\n\u03b3 = 0, w = \u2212\u03c2.\n\n\fTIME REVERSAL OF PDMPS\n\n21\n\n3.7. Workload of the single server queue M/G/1.\n\nFig.: Risk process\n\nThe workload (also virtual waiting time) process of a Markovian single server queue is\ndefined as the amount of work left at the server at time t. This is a special case of the\nreflected process with \u03c2 = \u221e, where r(x) = \u22121, \u03bb(x) = \u03bb is constant and \u03bcz ((x, \u221e]) =\n1 \u2212 F (x\nR \u2212 z) for z \u2264 x, where F is a probability distribution on (0, \u221e). We assume that\n% = \u03bb 0\u221e (1 \u2212 F (u)) du < 1, so that it can be shown that unique stationary distribution \u03bd\nexists. It then follows from (42) that\n\u03bd 0 (x) = \u03bb\n\nZ x\n\n(1 \u2212 F (x \u2212 z))\u03bd 0 (z) dz + \u03bb\u03bd({0})(1 \u2212 F (x)).\n\n(43)\n\n0\n\nIntegrating yields 1 \u2212 \u03bd({0}) = %(1 \u2212 \u03bd({0})) + \u03bd({0})% with % = \u03bb/ 0\u221e (1 \u2212 F (u)) du, from\nwhich \u03bd({0}) = 1 \u2212 % follows.\nThe renewal type equation (43) can be solved at least for numerical purposes in form\nof an infinite series of convolutions (the Pollaczek-Khintchine formula in the queueing\ncontext). Alternatively one can take Laplace transforms and find an equivalent relation\nfor the transform.\nProvided that F is absolutely continuous with density function f , Theorem 5 implies:\n\u03bd 00 (x)\n, x > 0,\n\u03bb? (x) = \u03bb + 0\n\u03bd (x)\n\u03bb\u03bd 0 (y)\n\u03bc?0\nf (x \u2212 y), x \u2265 0, y < x,\nx (y) =\n?\n\u03bb (x)\u03bd 0 (x)\n\u03bb(1 \u2212 %)\n\u03bc?x ({0}) = ?\nf (x), x > 0.\n\u03bb (x)\u03bd 0 (x)\nRemark 14. It is interesting to look for conditions to obtain a constant jump rate for the\nreversed process. We have \u03bb? = \u03bb + C for some constant C, iff \u03bd 00 (x)/\u03bd 0 (x) = C, that is,\nif \u03bd 0 (x) = DeCx is an exponential density with additional mass at zero. Then\nR\n\n\u03bc?0\nx (y) =\n\n\u03bb\n\u03bb\u03bd 0 (y)\nf (y \u2212 x) =\neC(y\u2212x) f (y \u2212 x)\n0\n00\n\u03bb\u03bd (x) + \u03bd (x)\n\u03bb+C\n\n\u03bb\ndepends only on (y \u2212x). If we interpret g(y) = (\u03bb+C)\neCy f (y) as the density of the workload\nof an M/G/1 queue, then it follows from the fact that \u03bd is a mixture of an exponential\ndistribution with a mass at zero (see e.g. [3], Theorem 9.1) that g(x) is also exponential\nwith mean 1/\u03b2 and \u03b2 = \u03bb? \u2212 C = \u03bb.\n\nRemark 15. Specializing Remark 13, if we ask ourself whether it is more probable, if we\nobserve Xt in steady state, to have a claim in the near future than to have a claim in the\nnear past, (44) shows that \u03bb? (x) > \u03bb if log \u03bd 0 is increasing at x and \u03bb? (x) < \u03bb if log \u03bd 0 is\ndecreasing at x (no matter which claim size distribution is present).\n\n\fTIME REVERSAL OF PDMPS\n\n22\n\nReferences\n[1] H. Albrecher and S. Thonhauser. Optimality results for dividend problems in insurance. Rev. R. Acad.\nCien. Serie A. Mat., 103(2), 2009.\n[2] E. Altman, K. Avrachenkov, A. Kherani, and B. Prabhu. Performance Analysis and Stochastic Stability\nof Congestion Control Protocols. Technical Report RR-5262, INRIA, Sophia-Antipolis, France, 2004.\n[3] S. Asmussen. Applied probability and queues. Applications of Mathematics 51. Springer, 2nd edition,\n2003.\n[4] F. Baccelli, K. B. Kim, and D.R. McDonald. Equilibria of a class of transport equations arising in\ncongestion control. Queueing Syst., 55(1):1\u20138, 2007.\n[5] S.K. Bar-Lev, M. Parlar, and D. Perry. On the EOQ model with inventory-level-dependent demand\nrate and random yield. Oper. Res. Lett., 16(3):167\u2013176, 1994.\n[6] R. Bekker, S.C. Borst, O.J. Boxma, and O. Kella. Queues with workload-dependent arrival and service\nrates. Queueing Syst., 46(3-4):537\u2013556, 2004.\n[7] P. Billingsley. Convergence of probability measures. Wiley, 1968.\n[8] K. Borovkov and A. Novikov. On a piece-wise deterministic Markov process model. Stat. Probab. Lett.,\n53(4):421\u2013428, 2001.\n[9] K. Borovkov and D. Vere-Jones. Explicit formulae for stationary distributions of stress release processes.\nJ. Appl. Probab., 37:315\u2013321, 2000.\n[10] K. Borovkov and G. Last. On level crossings for a general class of piecewise-deterministic Markov\nprocesses. : Adv. Appl. Probab., 40(3):815\u2013834, 2008.\n[11] O. Boxma, H. Kaspi, O. Kella, and D. Perry. On/off storage systems with state-dependent input,\noutput, and switching rates. Probab. Eng. Inf. Sci., 19(1):1\u201314, 2005.\n[12] O. Boxma, D. Perry, W. Stadje, and S. Zacks. A Markovian growth-collapse model. Adv. Appl. Probab.,\n38(1):221\u2013243, 2006.\n[13] P.J. Brockwell. Stationary distributions for dams with additive input and content dependent release\nrate. Adv. Appl. Probab., 9:645\u2013663, 1977.\n[14] S. Browne and K. Sigman. Work-modulated queues with applications to storage processes. J. Appl.\nProbab., 29:699\u2013712, 1992.\n[15] E. \u00c7inlar and M. Pinsky. A stochastic integral in storage theory. Z. Wahrscheinlichkeitstheor. Verw.\nGeb., 17:227\u2013240, 1971.\n[16] D. Chafa\u00ef, F. Malrieu, and K. Paroux. On the long time behavior of the TCP window size process.\nStoch. Proc. Appl., 120(8):1518\u20131534, 2010.\n[17] K.L. Chung and J.B. Walsh. To reverse a Markov process. Acta Math., 123:225\u2013251, 1969.\n[18] O.L.V. Costa. Stationary distributions of piecewise-deterministic Markov processes. J. Appl. Prob.,\n27:60\u201373, 1990.\n[19] A. Dassios and P. Embrechts. Martingales and insurance risk. Commun. Stat., Stochastic Models,\n5(2):181\u2013217, 1989.\n[20] A. Dassios and J. Jang. The distribution of the interval between events of a Cox process with shot\nnoise intensity. Journal of Applied Mathematics and Stochastic Analysis, 2008.\n[21] M.H.A. Davis. Piecewise deterministic Markov Processes: A General Class of Non-diffusion Stochastic\nModels. J. Roy. Stat. Soc. B, 46:253\u2013388, 1984.\n[22] M.H.A. Davis. Markov Models and Optimization., volume 49 of Monographs on Statistics and Applied\nProbability. London: Chapman & Hall, 1993.\n[23] F. Dufour and O.L.V. Costa. Stability of piecewise-deterministic Markov processes. Siam J. Control\nOptim., 37(5):1483\u20131502, 1999.\n[24] V. Dumas, F. Guillemin, and Ph. Robert. A Markovian analysis of additive-increase, multiplicativedecrease (AIMD) algorithms. Adv. Appl. Probab., 34(1):85\u2013111, 2002.\n[25] P. Embrechts and H. Schmidli. Ruin estimation for a general insurance risk model. Adv. Appl. Probab.,\n26(2):404\u2013422, 1994.\n[26] A. Faggionato, D. Gabrielli, and M. Ribezzi Crivellari. Non-equilibrium thermodynamics of piecewise\ndeterministic Markov processes. J. Stat. Phys., 137(2):259\u2013304, 2009.\n[27] J.M. Harrison and S.I. Resnick. The stationary distribution and first exit probabilities of a storage\nprocess with general release rule. Math. Oper. Res., 1:347\u2013358, 1976.\n[28] J.M. Harrison and S.I. Resnick. The recurrence classification of risk and storage processes. Math. Oper.\nRes., 1978.\n\n\fTIME REVERSAL OF PDMPS\n\n23\n\n[29] P. Hartman. Ordinary differential equations. 2nd ed. Reprint. Boston - Basel- Stuttgart: Birkh\u00e4user.\nXV, 1982.\n[30] M. Jacobsen. Point process theory and applications. Marked point and picewise deterministic processes.\nProbability and Its Applications. Boston: Birkh\u00e4user. 2006.\n[31] J. Jacod and P. Protter. Time reversal on L\u00e9vy processes. Ann. Probab., 16(2):620\u2013641, 1988.\n[32] J. Jacod and A.V. Skorohod. Jumping filtrations and martingales with finite variation. Az\u00e9ma, Jacques\n(ed.) et al., S\u00e9minaire de Probabilit\u00e9s XXVIII. Berlin: Springer-Verlag. Lect. Notes Math. 1583, 21-35,\n1994.\n[33] F.P. Kelly. Reversibility and Stochastic Networks. 1979.\n[34] A. Kolmogoroff. Zur Theorie der Markoffschen Ketten. Math. Ann., 112:155\u2013160, 1935.\n[35] A. Kolmogoroff. Zur Umkehrbarkeit der statistischen Naturgesetze. Math. Ann., 113:766\u2013772, 1936.\n[36] G. Last. Ergodicity properties of stress release, repairable system and workload models. Adv. Appl.\nProbab., 36(2):471\u2013498, 2004.\n[37] G. Last and K. Borovkov. On level crossings for a general class of piecewise-deterministic Markov\nprocesses. Adv. Appl. Probab., 40(3):815\u2013834, 2008.\n[38] G. Last and R. Szekli. Stochastic comparison of repairable systems. J. Appl. Probab., 35:348\u2013370, 1998.\n[39] J.S.H. van Leeuwaarden and A.H. L\u00f6pker. Transient moments of the TCP window size process. J.\nAppl. Probab., 45(1):163\u2013175, 2008.\n[40] J.S.H. van Leeuwaarden, A.H. L\u00f6pker, and T.J. Ott. TCP and iso-stationary transformations. Queueing\nSyst., 63(1-4):459\u2013475, 2009.\n[41] A.H. L\u00f6pker and W. Stadje. Hitting times and the running maximum of Markovian growth collapse\nprocesses. J. Appl. Probab., 48(2):295\u2013312, 2011.\n[42] K. Maulik and B. Zwart. Tail asymptotics for exponential functionals of L\u00e9vy processes. Stoch. Proc.\nAppl., 116(2):156\u2013177, 2006.\n[43] M. Nagasawa. Time reversions of Markov processes. Nagoya Math. J., 24:177\u2013204, 1964.\n[44] M. Nagasawa. Time reversal of Markov processes and relativistic quantum theory. Chaos Solitons\nFractals, 8(11):1711\u20131772, 1997.\n[45] J.R. Norris. Markov chains. Reprint. Cambridge Series in Statistical and Probabilistic Mathematics,\n2. Cambridge: Cambridge Univ. Press, 1998.\n[46] Y. Ogata and D. Vere-Jones. Inference for earthquake models: A self-correcting model. Stoch. Proc.\nAppl., 17:337\u2013347, 1984.\n[47] Z. Palmowski and T. Rolski. A technique for exponential change of measure for Markov processes.\nBernoulli, 8(6):767\u2013785, 2002.\n[48] T. Rolski, H. Schmidli, V. Schmidt, and J. Teugels. Stochastic processes for insurance and finance.\nChichester: John Wiley & Sons, 1999.\n[49] Sch\u00e4l, M. Sprungprozesse. Lecture Notes, University of Bonn, 1997.\n[50] Sch\u00e4l, M. On piecewise deterministic Markov control processes: Control of jumps and of risk processes\nin insurance. Insur. Math. Econ., 22(1):75\u201391, 1998.\n[51] E. Schr\u00f6dinger. \u00dcber die Umkehrung der Naturgesetze. 1931.\n[52] H. Tanaka. Time reversal of random walks in one dimension. Tokyo J. Math., 12(1):159\u2013174, 1989.\n[53] D. Vere-Jones. On the variance properties of stress release models. Austral. J. Statist., 30A:123\u2013135,\n1988.\n[54] J.B. Walsh. Time reversal and the completion of Markov processes. Invent. Math., 10:57\u201381, 1970.\n[55] G. Weiss. Time-reversibility of linear stochastic processes. J. Appl. Probab., 12:831\u2013836, 1975.\n[56] R. Wobst. On jump processes with drift. Diss. Math., 1983.\n[57] J. Yeh. Lectures on real analysis. Singapore: World Scientific, 2000.\n[58] X. Zheng. Ergodic theorems for stress release processes. Stoch. Proc. Appl., 37:239\u2013258, 1991.\nHelmut Schmidt University Hamburg, Postfach 700822, 22008 Hamburg\nE-mail address: lopker@hsu-hh.de\nUniversity of Wroc\u0142aw, pl. Grunwaldzki 2/4, 50-384 Wroc\u0142aw, Poland\nE-mail address: zpalma@math.uni.wroc.pl\n\n\f"}