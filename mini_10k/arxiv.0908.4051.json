{"id": "http://arxiv.org/abs/0908.4051v1", "guidislink": true, "updated": "2009-08-27T19:44:59Z", "updated_parsed": [2009, 8, 27, 19, 44, 59, 3, 239, 0], "published": "2009-08-27T19:44:59Z", "published_parsed": [2009, 8, 27, 19, 44, 59, 3, 239, 0], "title": "Training-Based Schemes are Suboptimal for High Rate Asynchronous\n  Communication", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0908.1434%2C0908.1000%2C0908.4467%2C0908.0442%2C0908.0208%2C0908.2602%2C0908.3116%2C0908.2815%2C0908.4096%2C0908.1564%2C0908.3802%2C0908.0892%2C0908.3880%2C0908.4386%2C0908.2334%2C0908.2684%2C0908.1625%2C0908.1744%2C0908.4548%2C0908.3567%2C0908.4171%2C0908.4315%2C0908.4369%2C0908.1443%2C0908.0776%2C0908.2748%2C0908.3403%2C0908.3450%2C0908.1663%2C0908.2260%2C0908.4051%2C0908.3140%2C0908.0441%2C0908.1538%2C0908.2117%2C0908.0068%2C0908.2463%2C0908.1128%2C0908.3939%2C0908.1598%2C0908.3812%2C0908.0240%2C0908.2237%2C0908.2751%2C0908.3327%2C0908.0041%2C0908.4545%2C0908.1518%2C0908.2233%2C0908.1520%2C0908.3455%2C0908.2972%2C0908.0439%2C0908.0930%2C0908.3276%2C0908.2851%2C0908.1523%2C0908.1438%2C0908.1163%2C0908.0275%2C0908.1040%2C0908.0986%2C0908.2242%2C0908.4558%2C0908.1301%2C0908.3732%2C0908.2031%2C0908.1325%2C0908.3594%2C0908.0859%2C0908.0823%2C0908.0936%2C0908.2455%2C0908.2869%2C0908.2183%2C0908.1403%2C0908.1353%2C0908.3701%2C0908.3605%2C0908.3759%2C0908.1706%2C0908.3590%2C0908.0695%2C0908.3032%2C0908.3031%2C0908.0894%2C0908.2943%2C0908.1429%2C0908.0260%2C0908.3485%2C0908.1560%2C0908.1721%2C0908.2836%2C0908.2154%2C0908.0640%2C0908.0035%2C0908.0185%2C0908.3586%2C0908.3230%2C0908.2652%2C0908.3357&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Training-Based Schemes are Suboptimal for High Rate Asynchronous\n  Communication"}, "summary": "We consider asynchronous point-to-point communication. Building on a recently\ndeveloped model, we show that training based schemes, i.e., communication\nstrategies that separate synchronization from information transmission, perform\nsuboptimally at high rate.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0908.1434%2C0908.1000%2C0908.4467%2C0908.0442%2C0908.0208%2C0908.2602%2C0908.3116%2C0908.2815%2C0908.4096%2C0908.1564%2C0908.3802%2C0908.0892%2C0908.3880%2C0908.4386%2C0908.2334%2C0908.2684%2C0908.1625%2C0908.1744%2C0908.4548%2C0908.3567%2C0908.4171%2C0908.4315%2C0908.4369%2C0908.1443%2C0908.0776%2C0908.2748%2C0908.3403%2C0908.3450%2C0908.1663%2C0908.2260%2C0908.4051%2C0908.3140%2C0908.0441%2C0908.1538%2C0908.2117%2C0908.0068%2C0908.2463%2C0908.1128%2C0908.3939%2C0908.1598%2C0908.3812%2C0908.0240%2C0908.2237%2C0908.2751%2C0908.3327%2C0908.0041%2C0908.4545%2C0908.1518%2C0908.2233%2C0908.1520%2C0908.3455%2C0908.2972%2C0908.0439%2C0908.0930%2C0908.3276%2C0908.2851%2C0908.1523%2C0908.1438%2C0908.1163%2C0908.0275%2C0908.1040%2C0908.0986%2C0908.2242%2C0908.4558%2C0908.1301%2C0908.3732%2C0908.2031%2C0908.1325%2C0908.3594%2C0908.0859%2C0908.0823%2C0908.0936%2C0908.2455%2C0908.2869%2C0908.2183%2C0908.1403%2C0908.1353%2C0908.3701%2C0908.3605%2C0908.3759%2C0908.1706%2C0908.3590%2C0908.0695%2C0908.3032%2C0908.3031%2C0908.0894%2C0908.2943%2C0908.1429%2C0908.0260%2C0908.3485%2C0908.1560%2C0908.1721%2C0908.2836%2C0908.2154%2C0908.0640%2C0908.0035%2C0908.0185%2C0908.3586%2C0908.3230%2C0908.2652%2C0908.3357&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider asynchronous point-to-point communication. Building on a recently\ndeveloped model, we show that training based schemes, i.e., communication\nstrategies that separate synchronization from information transmission, perform\nsuboptimally at high rate."}, "authors": ["Venkat Chandar", "Aslan Tchamkerten", "Gregory W. Wornell"], "author_detail": {"name": "Gregory W. Wornell"}, "author": "Gregory W. Wornell", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ITW.2009.5351435", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0908.4051v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0908.4051v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "To appear in the proceedings of the 2009 IEEE Information Theory\n  Workshop (Taormina)", "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0908.4051v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0908.4051v1", "journal_reference": null, "doi": "10.1109/ITW.2009.5351435", "fulltext": "1\n\nTraining-Based Schemes are Suboptimal for High\nRate Asynchronous Communication\n\narXiv:0908.4051v1 [cs.IT] 27 Aug 2009\n\nVenkat Chandar, Aslan Tchamkerten, and Gregory W. Wornell\n\nAbstract-We consider asynchronous point-to-point\ncommunication. Building on a recently developed model,\nwe show that training based schemes, i.e., communication\nstrategies that separate synchronization from information\ntransmission, perform suboptimally at high rate.\nIndex Terms-detection and isolation; sequential decoding; synchronization; training-based schemes\n\nI. M ODEL\n\nAND\n\nR EVIEW\n\nOF\n\nR ESULTS\n\nWe consider the asynchronous communication setting developed in [1], which provides an extension to\nShannon's original point-to-point model for synchronous\ncommunication [2].\nWe recall the setting in [1]. Communication takes\nplace over a discrete memoryless channel characterized\nby its finite input and output alphabets X and Y, respectively, and transition probability matrix Q(y|x), for\nall y \u2208 Y and x \u2208 X. There are M \u2265 2 messages\n{1, 2, . . . , M }. For each message m there is an associated codeword cN (m) , c1 (m)c2 (m) . . . cN (m), a\nstring of length N composed of symbols from X.1 The\nM codewords form a codebook CN . The transmitter\nselects a message m, randomly and uniformly over\nthe message set, and starts sending the corresponding\ncodeword cN (m) at a random time \u03bd , unknown to the receiver, independent of cN (m), and uniformly distributed\nin {1, 2, . . . , A}. The transmitter and the receiver know\nthe integer A \u2265 1, which we refer to as the asynchronism\nlevel between the transmitter and the receiver. If A = 1\nthe channel is said to be synchronized. The capacity of\nthe synchronized channel Q is denoted C , or C(Q) when\nnecessary for clarity.\nDuring information transmission the receiver observes\na noisy version of the sent codeword, while before and\nThis work was supported in part by the National Science Foundation under Grant No. CCF-0635191, and by a University IR&D\nGrant from Draper Laboratory.\nV. Chandar and G. W. Wornell are with the Dept.\nEECS, Massachusetts\nInstitute of\nTechnology.\n(Email:\n{vchandar,gww}@mit.edu). A. Tchamkerten is with Telecom\nParisTech, COMELEC. (Email: aslan.tchamkerten@telecomparistech.fr).\n1\nThe symbol ',' stands for 'equal by definition.'\n\nafter the information transmission it observes only noise.\nConditioned on the event {\u03bd = k}, k \u2208 {1, 2, . . . , A},\nand on the message m to be conveyed, the receiver\nobserves independent symbols Y1 , Y2 , . . . distributed as\nfollows. If i \u2208 {1, 2, . . . , k \u2212 1} or i \u2208 {k + N, k + N +\n1, . . . , A + N \u2212 1}, the distribution of Yi is\nQ\u22c6 (*) , Q(*|\u22c6)\n\nfor some fixed \u22c6 \u2208 X. At any time i \u2208 {k, k + 1, . . . , k +\nN \u2212 1}, the distribution of Yi is\nQ(*|ci\u2212k+1 (m)) .\n\nIt should be emphasized that the transition probability\nmatrix Q(*|*), together with the 'no-input' symbol \u22c6,\ncharacterizes the communication channel. In particular,\nthe \u22c6 is not a parameter of the transmitter, i.e., the system\ndesigner cannot designate which symbol in the input\nalphabet is \u22c6. This symbol can, however, be used for\nthe codebook design. Throughout the paper, whenever\nwe refer to a certain channel Q, we implicitly assume\nthat the \u22c6 symbol is given.\nThe decoder consists of a sequential test (\u03c4N , \u03c6N ),\nwhere \u03c4N is a stopping time - bounded by A + N \u2212 1\n- with respect to the output sequence Y1 , Y2 , . . . indicating when decoding happens, and where \u03c6N denotes a\ndecision rule that declares the decoded message. Recall\nthat a stopping time \u03c4 (deterministic or randomized)\nis an integer-valued random variable with respect to a\nsequence of random variables {Yi }\u221e\ni=1 so that the event\n{\u03c4 = n}, conditioned on the realizations of {Yi }ni=1 ,\nis independent of those of {Yi }\u221e\ni=n+1 , for all n \u2265 1.\nThe function \u03c6N is then defined as any F\u03c4N -measurable\nmap taking values in {1, 2, . . . , M }, where F1 , F2 , . . .\nis the natural filtration induced by the output process\nY1 , Y2 , . . . .\nWe are interested in reliable and quick decoding.\nTo that aim we first define the average decoding error\nprobability (given a codebook and a decoder) as\nM\nA\n1 1 XX\nPm,k (E),\nP(E) ,\nAM\nm=1 k=1\n\nwhere E indicates the event that the decoded message\ndoes not correspond to the sent message, and where the\n\n\f2\n\nsubscripts 'm,k ' indicate the conditioning on the event\nthat message m starts being sent at time k.\nSecond, we define the average communication rate\nwith respect to the average delay it takes the receiver\nto react to a sent message, i.e.2\nln M\nln |CN |\nR,\n,\n+\nE(\u03c4N \u2212 \u03bd)\nE(\u03c4N \u2212 \u03bd)+\n\nwhere E(\u03c4N \u2212 \u03bd)+ is defined as\nM\nA\n1 1 XX\nE(\u03c4N \u2212 \u03bd) ,\nEm,k (\u03c4N \u2212 k)+ ,\nAM\n+\n\nm=1 k=1\n\nwhere Em,k denotes the expectation with respect to\nPm,k , and where x+ denotes max{0, x}. With the above\ndefinitions, we now recall the notions of (R, \u03b1) coding\nscheme and capacity function.\nDefinition 1 ((R, \u03b1) coding scheme). Given a channel\nQ, a pair (R, \u03b1) is achievable if there exists a sequence\n{(CN , (\u03c4N , \u03c6N )}N \u22651 of codebook/decoder pairs that\nasymptotically achieves a rate R at an asynchronism\nexponent \u03b1. This means that, for any \u03b5 > 0 and all\nN large enough, the pair (CN , (\u03c4N , \u03c6N ))\n\u2022 operates under asynchronism level A = e(\u03b1\u2212\u03b5)N ;\n\u2022 yields an average rate at least equal to R \u2212 \u03b5;\n\u2022 achieves an average error probability P(E) at most\nequal to \u03b5.\nGiven a channel Q, an (R, \u03b1) coding scheme is a\nsequence {(CN , (\u03c4N , \u03c6N ))}N \u22651 that achieves a rate R\nat an asynchronism exponent \u03b1 as N \u2192 \u221e.\nDefinition 2 (Capacity of an asynchronous discrete\nmemoryless channel). The capacity of an asynchronous\ndiscrete memoryless channel with (synchronized) capacity C(Q) is the function\n[0, C(Q)] \u2192 R+\nR 7\u2192 \u03b1(R, Q),\n\nwhere \u03b1(R, Q) is the supremum of the set of asynchronism exponents that are achievable at rate R.\nIt turns out that the exponential scaling of the asynchronism exponent with respect to the codeword length\nin Definition 1 is natural: asynchronism induces a rate\nloss with respect to the capacity of the synchronous\nchannel only when it grows at least exponentially with\nthe codeword length [1].\nThe following theorem, given in [4], provides a nontrivial lower bound to the capacity of asynchronous\nchannels:\n2\n\nln denotes the natural logarithm.\n\nTheorem 1. For a given channel Q, let \u03b1 \u2265 0 and let\nP be a distribution over X such that\nmin max{D(V k(P Q)Y), D(V kQ\u22c6 )} > \u03b1\nV\n\nwhere the minimization is over all distributions over\nY, and wherePthe distribution (P Q)Y is defined as\n(P Q)Y(y) = x\u2208X P (x)Q(y|x), y \u2208 Y. Then, the pair\n(R = I(P Q), \u03b1) is achievable.\nCorollary 1. At capacity, it is possible to achieve a\nstrictly positive asynchronism exponent, except for the\ncase when Q\u22c6 corresponds to the capacity-achieving output distribution of the synchronous channel.3 Moreover,\nthe asynchronism exponent achievable at capacity can\nbe arbitrarily large, depending on the channel.\nThis is in contrast with training-based schemes. The\ncontribution of this paper, given in the next section, is\nto show that training-based scheme, in general, achieve\na vanishing asynchronism exponent in the limit of the\nrate going to capacity.\nII. T RAINING -BASED S CHEMES\nThe usual approach to communication is a trainingbased architecture. In such schemes, each codeword is\ncomposed of two parts. The first part, the sync preamble,\nis a sequence of symbols common to all the codewords,\nhence carries no information; its only purpose is to help\nthe decoder to locate the sent message. The second part\ncarries information. The decoder operates according to a\ntwo-step procedure. First it tries to locate the codeword\nby seeking the sync preamble. Once the sync preamble\nis located, it declares a message based on the subsequent\nsymbols. A formal definition of a training-based scheme\nfollows.\nDefinition 3. A training-based scheme is a coding\nscheme {(CN , (\u03c4N , \u03c6N ))}N \u22651 with the following properties. For some \u03b5 > 0, \u03b7 \u2208 [0, 1], and all integers N \u2265 1\ni. each codeword in CN starts with a string of size\n\u03b7N that is common to all codewords;4\nii. the decision time \u03c4N is such that the event\n{\u03c4N = n}, conditioned on the \u03b7N observations\n3\n\nTo see this, recall that, given the channel Q, all capacity-achieving\ninput distributions P induce the same output distribution (P Q)Y .\nWhenever (P Q)Y differs from Q\u22c6 , the min-max expression in\nTheorem 1 is strictly positive. Therefore capacity is achievable at\na strictly positive asynchronism exponent.\n4\nTo be precise, the string size should be an integer, and instead of\nhaving it equal to \u03b7N we should have it equal to \u230a\u03b7N \u230b. However,\nsince we are interested in the asymptotic N \u2192 \u221e, this discrepancy\ntypically vanishes. Similar discrepancies are ignored throughout the\npaper.\n\n\f3\nn\u2212N +\u03b7N 5\nYn\u2212N\n+1 , is independent of all other past obn\nservations, i.e., Y1n\u2212N and Yn\u2212N\n+\u03b7N +1 ;\niii. the codebook CN and the decoding time \u03c4N satisfy\n\nmaximization becomes D2 = D(Q||Q\u22c6 |P ) (since D1 =\nD(Q||Q|P ) = 0). Maximizing over P yields\nmax D(Q||Q\u22c6 |P ) = max D(Q(*|x)||Q\u22c6 )\nP\n\nP(\u03c4N \u2265 k + 2N \u2212 1|\u03c4N \u2265 k + N, \u03bd = k) \u2265 \u03b5\n\nfor all k \u2208 {1, 2, . . . , A} .\nCondition i. specifies the size of the sync preamble.\nCondition ii. indicates that the decoding time should\ndepend only on the sync preamble. Condition iii. imposes\nthat the codeword symbols that follow the sync preamble\nshould not be used to help the decoder locate the codeword. If we remove Condition iii., one could imagine\nhaving information symbols with a 'sufficiently biased'\ndistribution to help the decoder locate the codeword\nposition (the 'information symbols' could even start with\na second preamble!). In this case the sync preamble is\nfollowed by a block of information symbols that also\nhelps the decoder to locate the sent codeword. To avoid\nthis, we impose Condition iii. which says that, once the\nsync preamble is missed (this is captured by the event\n{\u03c4N \u2265 k + N, \u03bd = k}, the decoder's decision to stop\nwill likely no more depend on the sent codeword since\nit will occur after k + 2N \u2212 1.\nFinally, it can be shown that a large class of trainingbased schemes considered in practice satisfy the above\nthree conditions.\nTheorem 2. A training-based scheme that achieves a\nrate R \u2208 (0, C(Q)] operates at an asynchronism exponent \u03b1 upper bounded as\n\u0012\n\u0013\nR\n\u03b1\u2264 1\u2212\nmax min max{D1 , D2 },\nP\nW\nC\nwhere D1 , D(W kQ|P ), and D2 , D(W kQ\u22c6 |P ).6 The\nfirst maximization is over all distributions over X and the\nminimization is over all conditional distributions defined\nover X \u00d7 Y.\nThe following result is a consequence of Theorem 2.\nCorollary 2. Unless the no-input symbol \u22c6 does not generate a particular channel output symbol (i.e., Q(y|\u22c6) =\n0 for some y \u2208 Y), training-based schemes achieve a\nvanishing asynchronism exponent as R \u2192 C(Q).\nProof of Corollary 2: We consider the inequality\nof Theorem 2 and first upper bound the minimization\nby choosing W = Q. With this choice, the inner\nWe use Yij for Yi , Yi+1 , . . . , Yj (for i \u2264 j).\nWe use the standard notation D(W kQ|P ) for the KullbackLeibler distance between the joint distributions P (*)W (*|*) and\nP (*)Q(*|*) (see, e.g., [5, p. 31]).\n5\n\n6\n\nx\u2208X\n\nwhich is bounded when Q(y|\u22c6) > 0 for all y \u2208 Y.\nTherefore the max-min-max term in the inequality of\nTheorem 2 is finite and gets multiplied by a term that\nvanishes as R \u2192 C(Q).\nThus, except for degenerate cases, training-based\nschemes achieve a vanishing asynchronism exponent in\nthe limit of the rate going to capacity. In contrast, from\nTheorem 1 one deduces that it is possible, in general, to\nachieve a non-zero asynchronism exponent at capacity,\nas we saw above.\nThis suggests that to achieve a high rate under strong\nasynchronism, separating synchronization from information transmission is suboptimal; the codeword symbols\nshould all play the dual role of information carriers and\n'information flags.'\nSketch of Proof of Theorem 2\nConsider\na\ntraining-based\nscheme\n{(CN , (\u03c4N , \u03c6N ))}N \u22651 . For simplicity, we assume\nthat the sync preamble distribution of CN is the same,\nequal to P , for all N \u2265 1. The case of different\npreamble distributions for different values of N requires\na minor extension. The proof consists in showing that\nif the following two inequalities hold\n\u03b7D(W ||Q|P ) < \u03b1\n\n(1)\n\n\u03b7D(W ||Q\u22c6 |P ) < \u03b1\n\n(2)\n\nfor some conditional distribution W , then the average\nreaction delay achieved by {(CN , (\u03c4N , \u03c6N ))}N \u22651 grows\nexponentially with N . This, in turn, can be shown to\nimply that the rate is asymptotically equal to zero. Therefore, maximizing over the sync preamble distributions,\nit is necessary that\n\u03b1 \u2264 \u03b7 max min max{D(W ||Q|P ), D(W ||Q\u22c6 |P )}\nP\n\nW\n\nin order to achieve a strictly positive rate R. The second\npart of the proof, omitted in this paper, consists in\nshowing that the highest value of \u03b7 compatible with rate\nR communication is upper bounded by (1 \u2212 R/C(Q)).\nThis with the above inequality yields the desired result.\nBelow we sketch the argument that shows that, if\nboth (1) and (2) hold, the average reaction delay grows\nexponentially with N .\nTo keep the presentation simple, in the equations\nbelow we omit terms that go to zero in the limit N \u2192 \u221e.\nThus, although the equations may not be valid as written,\nthey become valid in that limit.\n\n\f4\n\nLet {(CN , (\u03c4N , \u03c6N ))}N \u22651 be a training-based scheme\nwith preamble empirical distribution equal to P . By\nproperty ii., the stopping time \u03c4N is such that the\nevent {\u03c4N = n} depends only on the realizations of\nn\u2212N +\u03b7N\nYn\u2212N\n+1 . For simplicity, instead of \u03c4N , we are going\n\u2032 , \u03c4 \u2212(1\u2212\u03b7)N\nto consider the shifted stopping time \u03c4N\nN\nwhose decision to stop at a certain moment depends on\n\u2032\nimmediate \u03b7N previously observed symbols. Clearly, \u03c4N\ncan be written as\n\u2032\n\u03c4N\n= inf{i \u2265 1 : Si = 1},\n\nwhere each Si is some (decision) function defined over\ni\nYi\u2212\u03b7N\n+1 and that take on the values 0 or 1.\n\u2032 becomes\nThe condition iii. in terms of \u03c4N\n\u2032\nP(\u03c4N\n\n\u2265 k + N + \u03b7N \u2212\n\n\u2032\n1|\u03c4N\n\n\u2265 k + \u03b7N, \u03bd = k) \u2265 \u03b5\n(3)\n\nfor all k \u2208 {1, 2, . . . , A}.\nLet us define the events\n\u2032\nE1 = {\u03c4N\n\u2265 \u03bd + \u03b7N }\n\nE2 = {Si = 0 for i \u2208 {\u03bd + N + \u03b7N \u2212 1, . . . , 3A/4}}\n\u2032\nE3 = {\u03c4N\n\u2265 \u03bd + N + \u03b7N \u2212 1}\n\nE4 = {\u03bd \u2264 A/4} .\n\nWe lower bound the reaction delay as\n\u2032\n\u2032\nE((\u03c4N\n\u2212 \u03bd)+ ) \u2265 E((\u03c4N\n\u2212 \u03bd)+ |E1 , E4 )P(E1 , E4 ), (4)\n\nand consider the two terms on the right-side separately.\n\u2032 \u2212 \u03bd)+ |E , E ) = \u03a9(A).7 We\nWe first show that E((\u03c4N\n1\n4\nhave\n\u2032\nE((\u03c4N\n\u2212 \u03bd)+ |E1 , E4 )\n\u2032\n\u2265 E((\u03c4N\n\u2212 \u03bd)+ |E1 , E2 , E3 , E4 )P(E2 , E3 |E1 , E4 )\n\u2032\n= E((\u03c4N\n\u2212 \u03bd)+ |E2 , E3 , E4 )P(E2 , E3 |E1 , E4 )\n\u2032\n\u2032\n= E((\u03c4N\n\u2212 \u03bd)+ |\u03c4N\n\u2265 3A/4, \u03bd \u2264 A/4)P(E2 , E3 |E1 , E4 )\nA\n\u2265 P(E2 , E3 |E1 , E4 )\n(5)\n2\n\nwhere the first equality holds since E3 \u2282 E1 , and\nwhere the second equality holds since E2 \u2229 E3 =\n\u2032 > 3A/4}. We now prove that P(E |E , E ) and\n{\u03c4N\n2 1\n4\nP(E3 |E1 , E4 ) have large probabilities for large N . This\nimplies that P(E2 , E3 |E1 , E4 ) has a probability bounded\naway from zero for N large enough. This together with\n\u2032 \u2212\u03bd)+ |E , E ) = \u03a9(A) as claimed\n(5) implies that E((\u03c4N\n1\n4\nabove.\n7\n\n\u03a9(*) refers to the standard Landau order notation.\n\nFor P(E2 |E1 , E4 ) we have\nP(E2 |E1 , E4 ) = P(E2 |E4 )\nA/4\n\n= P(S\u03bd+N +\u03b7N \u22121 = 0|\u03bd \u2264 A/4)\nA/4\n\n=\n\n1 X\nA/4\nP(Sk+N +\u03b7N \u22121 = 0|\u03bd = k)\nA/4\nk=1\nA/4\n\n=\n\n1 X\nA/4\nP\u22c6 (Sk+N +\u03b7N \u22121 = 0)\nA/4\nk=1\n\nA/4\n1 X\nA/4\nP\u22c6 (S1 = 0)\n\u2265\nA/4\n\n=\n=\n\nk=1\nA/4\nP\u22c6 (S1 = 0)\n\u2032\nP\u22c6 (\u03c4N\n> 3A/4)\n\n(6)\n\nwhere P\u22c6 denotes the output distribution under pure\nnoise, i.e., when the Yi 's are i.i.d. according to Q\u22c6 .\nFor the first equality we used the independence between\nE2 and E1 conditioned on E4 . For the fourth equality\nwe noted that, conditioned on {\u03bd = k}, the event\n3A/4\nSk+N +\u03b7N \u22121 is independent of the sent codeword (prefix\nand information sequence), hence its probability is P\u22c6 .\n\u2032 > 3A/4} only depends on the\nNow, the event {\u03c4N\noutput symbols up to time 3A/4. The probability of this\nevent under P\u22c6 is thus the same as under the probability\ndistribution induced by the sending of a message after\ntime 3A/4. Therefore, since the probability of error\nvanishes for large N , and that a message starts being\nsent after time 3A/4 with (large) probability 1/4, we\n\u2032 > 3A/4) \u2248 1 for large N . Hence\nmust have P\u22c6 (\u03c4N\nfrom (6) we have\nP(E2 |E1 , E4 ) \u2248 1\n\n(7)\n\nfor large N . Now consider P(E3 |E1 , E4 ). Using (3), we\nhave\nP(E3 |E1 , E4 ) \u2265 \u03b5.\n\n(8)\n\nFrom (7) and (8) we deduce that P(E2 , E3 |E1 , E4 ) is\nthe (conditional) probability of the intersection of two\nlarge probability events. Therefore P(E2 , E3 |E1 , E4 ) has\na probability bounded away from zero as N \u2192 \u221e.\nHence, we have shown that\n\u2032\nE((\u03c4N\n\u2212 \u03bd)+ |E1 , E4 ) = \u03a9(A)\n\n(9)\n\nas claimed earlier.\nSecond, we prove that\nP(E1 , E4 ) = \u03a9(e\u2212\u03b7N D1 poly(N )),\n\n(10)\n\nwhere D1 = D(W kQ|P ), P denotes the type of the\npreamble, and poly(N ) denotes a quantity that goes to\n0 at most polynomially quickly as a function of N .\n\n\f5\n\nNow, assuming that \u03b1 > \u03b7D2 , one can show that\n\nWe expand P(E1 , E4 ) as\nA/4\n\n1 X\n\u2032\nP(E1 , E4 ) =\nPk (\u03c4N\n\u2265 k + \u03b7N ),\nA\n\n(11)\n\nA/4\nX\n\n\u03b7N\n\u2032\nP\u22c6 (\u03c4N\n\u2265 k+\u03b7N, Ykk+\u03b7N \u22121 \u2208 TW\n(P )) = \u03a9(Ae\u2212\u03b7D2 )\n\nk=1\n\nk=1\n\nwhere Pk represents the probability distribution of the\noutput conditioned on the event {\u03bd = k}. Further, by\npicking a conditional distribution W defined over X \u00d7 Y\n\u03b7N\nsuch that Pk (Ykk+\u03b7N \u22121 \u2208 TW\n(P )) > 0,8 we lower the\nterm in the above sum as\n\nusing the union bound. Therefore, under the above\nassumption we get from (15) the desired claim that\nP(E1 , E4 ) = \u03a9(e\u2212\u03b7N D1 poly(N )) .\n\n(16)\n\nFrom (4), (9), and (16), we conclude that if \u03b1 > \u03b7D2\nthen\n\u03b7N\n\u2032\n\u2032\nPk (\u03c4N\n\u2265 k + \u03b7N ) \u2265Pk (\u03c4N\n\u2265 k + \u03b7N |Ykk+\u03b7N \u22121 \u2208 TW\n(P ))\n\u2032\nE((\u03c4N\n\u2212 \u03bd)+ ) \u2265 \u03a9(Ae\u2212\u03b7N D1 poly(N )) .\nk+\u03b7N \u22121\n\u03b7N\n\u00d7 Pk (Yk\n\u2208 TW (P )) .\nTherefore, letting A = eN \u03b1 , we deduce that, if, in\n(12)\naddition to the inequality \u03b1 > \u03b7D2 , we also have\n\u2032 \u2212\u03bd)+ ) grows\nWe lower bound each of the two terms on the right-side \u03b1 > \u03b7D1 , the average reaction delay E((\u03c4N\nof (12).\nexponentially with N .\nFor the first term, a change of measure argument\nC ONCLUDING R EMARKS\nreveals that\n\u03b7N\n\u2032\n\u2265 k + \u03b7N |Ykk+\u03b7N \u22121 \u2208 TW\n(P ))\nPk (\u03c4N\n\u03b7N\n\u2032\n= P\u22c6 (\u03c4N\n\u2265 k + \u03b7N |Ykk+\u03b7N \u22121 \u2208 TW\n(P )) . (13)\n\nTo see this, one expands\n\u03b7N\n\u2032\n(P ))\nPk (\u03c4N\n\u2265 k + \u03b7N |Yki+\u03b7N \u22121 \u2208 TW\n\nby further conditioning on individual sequences in\n\u03b7N\nTW\n(P ). Then, one uses the fact that, conditioned on a\nparticular such sequence, the channel outputs outside the\ntime window {k, k + 1, . . . , k + \u03b7N \u2212 1} are distributed\naccording to noise, i.e., i.i.d. according to Q\u22c6 .\nFor the second term we have\n\u03b7N\nPk (Ykk+\u03b7N \u22121 \u2208 TW\n(P )) \u2265 poly(N )e\u2212\u03b7N D1\n\n(14)\n\nusing [5, Lemma 2.6, p. 32], where D1 , D(W kQ|P ).\nCombining (11), (12), (13), and (14) we get\nP(E1 , E4 )\n\u2265poly(N )\n\u00d7\n\nA/4\nX\n\ne\u2212\u03b7N D1\n\u00d7\nA\n\n\u03b7N\n\u2032\nP\u22c6 (\u03c4N\n\u2265 i + \u03b7N |Ykk+\u03b7N \u22121 \u2208 TW\n(P ))\n\nk=1\n\ne\u2212\u03b7N (D1 \u2212D2 )\n\u00d7\n\u2265poly(N )\nA\nA/4\nX\n\u03b7N\n\u2032\n\u00d7\nP\u22c6 (\u03c4N\n\u2265 i + \u03b7N, Yki+\u03b7N \u22121 \u2208 TW\n(P )) , (15)\nk=1\n\nwhere D2 , D(W kQ\u22c6 |P ), and where for the second\ninequality we again used [5, Lemma 2.6, p. 32].\n\u03b7N\nThe set TW\n(P ) corresponds to all output sequences y \u03b7N that,\ntogether with the preamble, have joint type equal to P (*)W (*|*).\n8\n\nSynchronization and information transmission of virtually all practical communication systems are performed\nseparately, on the basis of different communication bits.\nMoreover, in general, the rate of these strategies is computed with respect to the information transmission time\nperiod, ignoring the delay overhead caused by various\nhand-shake protocols used to guarantee synchronization.\nIn these cases, the notions of 'high rate' or 'capacityachieving' communication strategies clearly raises questions.\nBuilding on an extension of Shannon's original pointto-point synchronous communication channel model to\nassess the overall rate performance of asynchronous\ncommunication systems, we showed that training-based\nschemes perform suboptimally at high rates. In this\nregime, it is necessary to envision communication\nstrategies that integrate synchronization into information\ntransmission.\nACKNOWLEDGMENTS\nWe thank the reviewer for valuable comments.\nR EFERENCES\n[1] A. Tchamkerten, V. Chandar, and G. Wornell, \"Communication\nunder strong asynchronism,\" to appear in IEEE Trans. Inform. Th. (http://arxiv.org/abs/0707.4656).\n[2] C. E. Shannon, \"A mathematical theory of communication,\" The\nBell Sys. Tech. Journal, vol. 27, pp. 379\u2013423, October 1948.\n[3] T. Cover and J. Thomas, Elements of information theory. New\nYork: Wiley, 2006.\n[4] A. Tchamkerten, V. Chandar, and G. Wornell, \"On the capacity\nregion of asynchronous channels,\" in IEEE Intl. Sympo. on Info.\nTh. (ISIT), 2008.\n[5] I. Csisz\u00e0r and J. K\u00f6rner, Information Theory: Coding Theorems\nfor Discrete Memoryless Channels. New York: Academic Press,\n1981.\n\n\f"}