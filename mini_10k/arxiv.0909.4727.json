{"id": "http://arxiv.org/abs/0909.4727v2", "guidislink": true, "updated": "2010-05-06T01:37:10Z", "updated_parsed": [2010, 5, 6, 1, 37, 10, 3, 126, 0], "published": "2009-09-25T15:54:33Z", "published_parsed": [2009, 9, 25, 15, 54, 33, 4, 268, 0], "title": "A regularity lemma, and low-weight approximators, for low-degree\n  polynomial threshold functions", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5587%2C0909.1768%2C0909.5537%2C0909.2594%2C0909.4684%2C0909.1625%2C0909.4035%2C0909.3330%2C0909.1795%2C0909.1974%2C0909.4892%2C0909.0503%2C0909.1329%2C0909.5067%2C0909.3483%2C0909.0717%2C0909.0610%2C0909.5152%2C0909.0489%2C0909.2949%2C0909.4974%2C0909.3531%2C0909.4883%2C0909.1006%2C0909.5126%2C0909.4860%2C0909.0609%2C0909.5350%2C0909.5112%2C0909.2251%2C0909.0519%2C0909.4331%2C0909.3397%2C0909.5104%2C0909.4378%2C0909.0403%2C0909.3371%2C0909.5685%2C0909.2605%2C0909.4387%2C0909.3556%2C0909.4727%2C0909.3392%2C0909.5284%2C0909.4959%2C0909.0783%2C0909.1593%2C0909.0146%2C0909.1519%2C0909.0874%2C0909.4837%2C0909.0203%2C0909.2072%2C0909.5335%2C0909.3646%2C0909.2543%2C0909.2362%2C0909.0398%2C0909.5230%2C0909.1368%2C0909.4657%2C0909.2037%2C0909.4277%2C0909.3928%2C0909.4578%2C0909.4503%2C0909.2117%2C0909.2177%2C0909.5477%2C0909.5008%2C0909.0100%2C0909.0846%2C0909.3473%2C0909.1591%2C0909.2276%2C0909.4816%2C0909.1048%2C0909.2122%2C0909.4639%2C0909.0882%2C0909.2231%2C0909.2963%2C0909.0158%2C0909.3803%2C0909.0011%2C0909.3131%2C0909.3199%2C0909.1167%2C0909.2806%2C0909.2210%2C0909.3085%2C0909.0810%2C0909.3671%2C0909.1312%2C0909.1966%2C0909.3077%2C0909.5145%2C0909.0012%2C0909.2553%2C0909.4863%2C0909.4116&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A regularity lemma, and low-weight approximators, for low-degree\n  polynomial threshold functions"}, "summary": "We give a \"regularity lemma\" for degree-d polynomial threshold functions\n(PTFs) over the Boolean cube {-1,1}^n. This result shows that every degree-d\nPTF can be decomposed into a constant number of subfunctions such that almost\nall of the subfunctions are close to being regular PTFs. Here a \"regular PTF is\na PTF sign(p(x)) where the influence of each variable on the polynomial p(x) is\na small fraction of the total influence of p.\n  As an application of this regularity lemma, we prove that for any constants d\n\\geq 1, \\eps \\geq 0, every degree-d PTF over n variables has can be\napproximated to accuracy eps by a constant-degree PTF that has integer weights\nof total magnitude O(n^d). This weight bound is shown to be optimal up to\nconstant factors.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5587%2C0909.1768%2C0909.5537%2C0909.2594%2C0909.4684%2C0909.1625%2C0909.4035%2C0909.3330%2C0909.1795%2C0909.1974%2C0909.4892%2C0909.0503%2C0909.1329%2C0909.5067%2C0909.3483%2C0909.0717%2C0909.0610%2C0909.5152%2C0909.0489%2C0909.2949%2C0909.4974%2C0909.3531%2C0909.4883%2C0909.1006%2C0909.5126%2C0909.4860%2C0909.0609%2C0909.5350%2C0909.5112%2C0909.2251%2C0909.0519%2C0909.4331%2C0909.3397%2C0909.5104%2C0909.4378%2C0909.0403%2C0909.3371%2C0909.5685%2C0909.2605%2C0909.4387%2C0909.3556%2C0909.4727%2C0909.3392%2C0909.5284%2C0909.4959%2C0909.0783%2C0909.1593%2C0909.0146%2C0909.1519%2C0909.0874%2C0909.4837%2C0909.0203%2C0909.2072%2C0909.5335%2C0909.3646%2C0909.2543%2C0909.2362%2C0909.0398%2C0909.5230%2C0909.1368%2C0909.4657%2C0909.2037%2C0909.4277%2C0909.3928%2C0909.4578%2C0909.4503%2C0909.2117%2C0909.2177%2C0909.5477%2C0909.5008%2C0909.0100%2C0909.0846%2C0909.3473%2C0909.1591%2C0909.2276%2C0909.4816%2C0909.1048%2C0909.2122%2C0909.4639%2C0909.0882%2C0909.2231%2C0909.2963%2C0909.0158%2C0909.3803%2C0909.0011%2C0909.3131%2C0909.3199%2C0909.1167%2C0909.2806%2C0909.2210%2C0909.3085%2C0909.0810%2C0909.3671%2C0909.1312%2C0909.1966%2C0909.3077%2C0909.5145%2C0909.0012%2C0909.2553%2C0909.4863%2C0909.4116&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We give a \"regularity lemma\" for degree-d polynomial threshold functions\n(PTFs) over the Boolean cube {-1,1}^n. This result shows that every degree-d\nPTF can be decomposed into a constant number of subfunctions such that almost\nall of the subfunctions are close to being regular PTFs. Here a \"regular PTF is\na PTF sign(p(x)) where the influence of each variable on the polynomial p(x) is\na small fraction of the total influence of p.\n  As an application of this regularity lemma, we prove that for any constants d\n\\geq 1, \\eps \\geq 0, every degree-d PTF over n variables has can be\napproximated to accuracy eps by a constant-degree PTF that has integer weights\nof total magnitude O(n^d). This weight bound is shown to be optimal up to\nconstant factors."}, "authors": ["Ilias Diakonikolas", "Rocco A. Servedio", "Li-Yang Tan", "Andrew Wan"], "author_detail": {"name": "Andrew Wan"}, "author": "Andrew Wan", "arxiv_comment": "23 pages, 0 figures", "links": [{"href": "http://arxiv.org/abs/0909.4727v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0909.4727v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "F.1.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0909.4727v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0909.4727v2", "journal_reference": null, "doi": null, "fulltext": "A Regularity Lemma, and Low-weight Approximators, for\nLow-degree Polynomial Threshold Functions\nIlias Diakonikolas\u2217\n\nRocco A. Servedio\u2020\n\nLi-Yang Tan\u2021\n\narXiv:0909.4727v2 [cs.CC] 6 May 2010\n\nAndrew Wan\u00a7\nDepartment of Computer Science\nColumbia University\n{ilias, rocco, liyang, atw12}@cs.columbia.edu\n\nOctober 25, 2018\n\nAbstract\nWe give a \"regularity lemma\" for degree-d polynomial threshold functions (PTFs) over the Boolean\ncube {\u22121, 1}n. Roughly speaking, this result shows that every degree-d PTF can be decomposed into a\nconstant number of subfunctions such that almost all of the subfunctions are close to being regular PTFs.\nHere a \"regular\" PTF is a PTF sign(p(x)) where the influence of each variable on the polynomial p(x)\nis a small fraction of the total influence of p.\nAs an application of this regularity lemma, we prove that for any constants d \u2265 1, \u01eb > 0, every\ndegree-d PTF over n variables can be approximated to accuracy \u01eb by a constant-degree PTF that has\ninteger weights of total magnitude O(nd ). This weight bound is shown to be optimal up to logarithmic\nfactors.\n\n\u2217\n\nSupported by NSF grant CCF-0728736, and by an Alexander S. Onassis Foundation Fellowship. Part of this work was done\nwhile visiting IBM Almaden.\n\u2020\nSupported by NSF grants CCF-0347282, CCF-0523664 and CNS-0716245, and by DARPA award HR0011-08-1-0069.\n\u2021\nSupported by DARPA award no. HR0011-08-1-0069 and NSF CyberTrust grant no. CNS-0716245.\n\u00a7\nSupported by NSF CyberTrust award CNS-0716245.\n\n\f1 Introduction\nA polynomial threshold function (henceforth PTF) is a Boolean function f : {\u22121, 1}n \u2192 {\u22121, 1}, f (x) =\nsign(p(x)), where p : {\u22121, 1}n \u2192 R is a polynomial with real coefficients. If p has degree d, we say that\nf is a degree-d PTF. Low-degree PTFs are a natural generalization of linear threshold functions (the case\nd = 1) and hence are of significant interest in complexity theory, see e.g. [ABFR94, Bru90, OS03b, OS03a,\nDRST09, GL94, HKM09, MZ09, Sak93, She09] and many other works.\nn\nThe influence of coordinate i on a function g : {\u22121,\nP 1} \u21922 R measures\nP the extent to which xi affects\nthe output of g. More precisely, we have Inf i (g) = S\u220bi b\ng(S) , where S\u2286[n] b\ng(S)\u03c7S (x) is the Fourier\nP\nexpansion of g. The total influence of g is the sum of all n coordinate influences, Inf(g) = ni=1 Inf i (g).\nSee [O'D07a, KS06] for background on influences.\nWe say that a polynomial p : {\u22121, 1}n \u2192 R is \"\u03c4 -regular\" if the influence of each coordinate on p is at\nmost a \u03c4 fraction of p's total influence (see Section 2 for a more detailed definition). A PTF f is said to be\n\u03c4 -regular if f = sign(p), where p is \u03c4 -regular. Roughly speaking, regular polynomials and PTFs are useful\nbecause they inherit some nice properties of PTFs and polynomials over Gaussian (rather than Boolean)\ninputs; this intuition can be made precise using the \"invariance principle\" of Mossel et al. [MOO05]. This\npoint of view has been useful in the d = 1 case for constructing pseudorandom generators [DGJ+ 09],\nlow-weight approximators [Ser07, DS09], and other results for LTFs [OS08, MORS09].\n\n1.1 Our results\nA regularity lemma for degree-d PTFs. A number of useful results in different areas, loosely referred\nto as \"regularity lemmas,\" show that for various types of combinatorial objects an arbitrary object can\nbe approximately decomposed into a constant number of \"pseudorandom\" sub-objects. The best-known\nexample of such a result is Szemer\u00e9di's classical regularity lemma for graphs [Sze78], which (roughly) says\nthat any graph can be decomposed into a constant number of subsets such that almost every pair of subsets\ninduces a \"pseudorandom\" bipartite graph. Another example is Green's recent regularity lemma for Boolean\nfunctions [Gre05]. Results of this sort are useful because different properties of interest are sometimes\neasier to establish for pseudorandom objects, and via regularity lemmas it may be possible to prove the\ncorresponding theorems for general objects. We note also that results of this sort play an important part in\nthe \"structure versus randomness\" paradigm that has been prominent in recent work in combinatorics and\nnumber theory, see e.g. [Tao07].\nWe prove a structural result about degree-d PTFs which follows the above pattern; we thus refer to it as\na \"regularity lemma for degree-d PTFs.\" Our result says that any low-degree PTF can be decomposed as a\nsmall depth decision tree, most of whose leaves are close to regular PTFs:\nTheorem 1. Let f (x) = sign(p(x)) be any degree-d PTF. Fix any \u03c4 > 0. Then f is equivalent to a decision\ntree T , of depth\n1 \u0001O(d)\n1\ndepth(d, \u03c4 ) := * d log\n\u03c4\n\u03c4\nwith variables at the internal nodes and a degree-d PTF f\u03c1 = sign(p\u03c1 ) at each leaf \u03c1, with the following\nproperty: with probability at least 1 \u2212 \u03c4 , a random path1 from the root reaches a leaf \u03c1 such that f\u03c1 is\n\u03c4 -close to some \u03c4 -regular degree-d PTF.\nRegularity is a natural way to capture the notion of pseudorandomness for PTFs, and results of interest can\nbe easier to establish for regular PTFs than for arbitrary PTFs (this is the case for our main application,\nconstructing low-weight approximators, as we describe below). Our regularity lemma provides a general\ntool to reduce questions about arbitrary PTFs to regular PTFs; it has already been used in this way as an\n1\n\nA random path corresponds to the standard uniform random walk on the tree.\n\n1\n\n\fessential ingredient in the recent proof that bounded independence fools all degree-2 PTFs [DKN09]. We\nnote that the recent construction of pseudorandom generators for degree-d PTFs of [MZ09] also crucially\nuses a decomposition result which is very similar to our regularity lemma; we discuss the relation between\nour work and [MZ09] in more detail below and in Appendix C.\nApplication: Every low-degree PTF has a low-weight approximator. [Ser07] showed that every linear\nthreshold function (LTF) over {\u22121, 1}n can be \u01eb-approximated by an LTF with integer weights w1 , . . . , wn\nP\n2\nsuch that i wi2 = n * 2\u00d5(1/\u01eb ) . (Here and throughout the paper we say that g is an \u01eb-approximator for f if\nf and g differ on at most \u01eb2n inputs from {\u22121, 1}n .) This result and the tools used in its proof found several\nsubsequent applications in complexity theory and learning theory, see e.g. [DGJ+ 09, OS08].\nWe apply our regularity lemma for degree-d PTFs to prove an analogue of the [Ser07] result for lowdegree polynomial threshold functions. Our result implies that for any constants d, \u01eb, any degree-d PTF has\nan \u01eb-approximating PTF of constant degree and (integer) weight O(nd ).\nWhen we refer to the weight of a PTF f = sign(p(x)), we assume that all the coefficients of p are\nintegers; by \"weight\" we mean the sum of the squares of p's coefficients. We prove\nTheorem 2. Let f (x) = sign(p(x)) be any degree-d PTF. Fix any \u01eb > 0. Then there is a polynomial q(x)\nO(d)\n* nd such that sign(q(x)) is \u01eb-close to f .\nof degree D = (d/\u01eb)O(d) and weight 2(d/\u01eb)\nA result on the existence of low-weight \u01eb-approximators for PTFs P\nis implicit in the recent work [DRST09].\nThey show that any degree-d PTF f has Fourier concentration |S|>1/\u01ebO(d) fb(S)2 \u2264 \u01eb, and this easily\nimplies that f can be \u01eb-approximated by a PTF with integer weights. (Indeed, recall that the learning\nalgorithm of [LMN93] works by constructing such a PTF as its hypothesis.) The above Fourier concentration\nO(d)\nwhich \u01eb-approximates f . In contrast,\nbound implies that there is a PTF of degree 1/\u01ebO(d) and weight n1/\u01eb\nour Theorem 2 can give a weaker degree bound (if d = 1/\u01eb\u03c9(1) ), but always gives a much stronger weight\nbound in terms of the dependence on n. We mention here that Podolskii [Pod09] has shown that for every\nd\nconstant d \u2265 2, there is a degree-d PTF for which any exact representation requires weight n\u03a9(n ) .\ne d ) is required to \u01eb-approximate degree-d PTFs for\nWe also prove lower bounds showing that weight \u03a9(n\nsufficiently small constant \u01eb; see Section 3.3.\n\nTechniques. An important ingredient in our proof of Theorem 1 is a case analysis based on the \"critical\nindex\" of a degree-d polynomial (see Section 2 for a formal definition). The critical index measures the first\npoint (going through the variables from most to least influential) at which the influences \"become small;\"\nit is a natural generalization of the definition of the \"critical index\" of a linear form [Ser07] that has been\nuseful in several subsequent works [OS08, DGJ+ 09, DS09]. Roughly speaking we show that\n\u2022 If the critical index of p is large, then a random restriction fixing few variables (the variables with\nlargest influence in p) causes sign(p) to become a close-to-constant function with non-negligible\nprobability; see Section 2.1. (Note that a constant function is trivially a regular PTF.)\n\u2022 If the critical index of p is positive but small, then a random restriction as described above causes p to\nbecome regular with non-negligible probability; see Section 2.2.\n\u2022 If the critical index of p is zero, then p is already a regular polynomial as desired.\nRelated Work. The results of Sections 2.1 and 2.2 strengthen earlier results with a similar flavor in [DRST09].\nThose earlier results had quantitative bounds that depended on n in various ways: getting rid of this dependence is essential for our low-weight approximator application and for the application in [DKN09].\nSimultaneously and independently of this work, Ben-Eliezer et al. [BELY09], Harsha et al. [HKM09],\nand Meka and Zuckerman [MZ09] have proved similar structural results for PTFs. In particular, [HKM09]\ngive a result which is very similar to Lemma 11, the main component in our proof of Theorem 1. By\napplying the result from [HKM09], Meka and Zuckerman [MZ09] give a result which is quite similar to our\n2\n\n\fTheorem 1. However, their definition of regularity is somewhat different from ours, and as a consequence\ntheir structural results and ours are quantitatively incomparable, as we discuss in Appendix C. Ben-Eliezer\net al. give a result of similar flavor as our Theorem 1. They establish the existence of a decision tree such that\nmost leaves are \u03c4 -regular (as opposed to \u03c4 -close to being \u03c4 -regular). The depth of their tree is exponential\nin 1/\u03c4 , which makes it quantitatively weaker for applications.\n\n1.2 Preliminaries\nWe start by establishing some basic notation. We write [n] to denote {1, 2, . . . , n} and [k, l] to denote\n{k, k + 1, . . . , l}. We write E[X] and Var[X] to denote expectation and variance of a random variable X,\nwhere the underlying distribution will be clear from the context. For x \u2208 {\u22121, 1}n and A \u2286 [n] we write\nxA to denote (xi )i\u2208A .\nWe assume familiarity with the basic elements of Fourier analysis over {\u22121, 1}n ; aP\nconcise review of\nthe necessary background is given in Appendix A.1. Let p : {\u22121, 1}n \u2192 R and p(x) = S pb(S)\u03c7S (x) be\ndef P\nits Fourier expansion.\nThe influence of variable i on p is Inf i (p) = S\u220bi pb(S)2 , and the total influence of\nPn\np is Inf(p) = i=1 Inf i (p). For a function f : {\u22121, 1}n \u2192 R and q \u2265 1, we denote by kf kq its lq norm,\ndef\n\ni.e. kf kq = Ex [|p(x)|q ]1/q , where the intended distribution over x will always be uniform over {\u22121, 1}n .\nFor Boolean functions f, g : {\u22121, 1}n \u2192 {\u22121, 1} the distance between f and g, denoted dist(f, g), is\nthe Prx [f (x) 6= g(x)] where the probability is over uniform x \u2208 {\u22121, 1}n .\nOur proofs will use various bounds from probability theory, which we collect for easy reference in\nAppendices A.2 and A.3. We call the reader's attention in particular to Theorem 7; throughout the paper, C\n(which will be seen to play an important role in our proofs) denotes C02 , where C0 is the universal constant\nfrom that theorem.\n\n2 Main Result: a regularity lemma for low-degree PTFs\nLet f : {\u22121, 1}n \u2192 {\u22121, 1} be a degree-d PTF. Fix a representation f (x) = sign(p(x)), where p :\n{\u22121, 1}n \u2192 R is a degree-d polynomial which (w.l.o.g.) we may take to have Var[p] = 1. We assume\nw.l.o.g. that the variables are ordered in such a way that Inf i (p) \u2265 Inf i+1 (p) for all i \u2208 [n \u2212 1].\nWe now define the notion of the \u03c4 -critical index of a polynomial [DRST09] and state its basic properties.\nDefinition 1. Let p : {\u22121, 1}n \u2192 R and \u03c4 > 0. Assume the variables are ordered such that Inf j (p) \u2265\nInf j+1 (p) for all j \u2208 [n \u2212 1]. The \u03c4 -critical index of p is the least i such that:\nInf i+1 (p) \u2264 \u03c4 *\n\nn\nP\n\nInf j (p).\n\n(1)\n\nj=i+1\n\nIf (1) does not hold for any i we say that the \u03c4 -critical index of p is +\u221e. If p has \u03c4 -critical index 0, we\nsay that p is \u03c4 -regular.\nNote that if p is a \u03c4 -regular polynomial then maxi Inf i (p) \u2264 d\u03c4 since the total influence of p is at most\nd. If f (x) = sign(p(x)), we say f is \u03c4 -regular when p is \u03c4 -regular, and we take the \u03c4 -critical index of f\n2\nto\nPnbe that of p. The following lemma (see Appendix B for the easy proof) says that the total influence\ni=j+1 Inf i (p) goes down geometrically as a function of j prior to the critical index:\nLemma 1. Let p : {\u22121, 1}n \u2192 R and \u03c4 > 0. Let k be the \u03c4 -critical index of p. For j \u2208 [0, k] we have\nn\nP\nInf i (p) \u2264 (1 \u2212 \u03c4 )j * Inf(p).\ni=j+1\n\n2\nStrictly speaking, \u03c4 -regularity is a property of a particular representation and not of a PTF f , which could have many different\nrepresentations. The particular representation we are concerned with will always be clear from context.\n\n3\n\n\fWe will use the fact that in expectation, the influence of an unrestricted variable in a polynomial does\nnot change under random restrictions (again see Appendix B for the easy proof):\nLemma 2. Let p : {\u22121, 1}n \u2192 R. Consider a random assignment \u03c1 to the variables x1 , . . . , xk and fix\nl \u2208 [k + 1, n]. Then E\u03c1 [Inf l (p\u03c1 )] = Inf l (p).\nNotation: For S \u2286 [n], we write \"\u03c1 fixes S\" to indicate that \u03c1 \u2208 {\u22121, 1}|S| is a restriction mapping xS , i.e.\neach coordinate in S, to either \u22121 or 1 and leaving coordinates not in S unrestricted.\n\n2.1 The large critical index case\nThe main result of this section is Lemma 3, which says that if the critical index of f is large, then a noticeable\nfraction of restrictions \u03c1 of the high-influence variables cause f\u03c1 to become close to a constant function.\nLemma 3. Let f : {\u22121, 1}n \u2192 {\u22121, 1} be a degree-d PTF f = sign(p). Fix \u03b2 > 0 and suppose that f has\ndef\n\n\u03c4 -critical index at least K = \u03b1/\u03c4 , where \u03b1 = \u03a9(d log log(1/\u03b2) + d log d). Then, for at least a 1/(2C d )\nfraction of restrictions \u03c1 fixing [K], the function f\u03c1 is \u03b2-close to a constant function.\ndef\n\nProof. Partition the coordinates into a \"head\" part H = [K] (the high-influence coordinates) and a \"tail\"\n\u2032 (x ) is the truncation\npart T = [n] \\ H. We can write p(x) = p(xH , xT ) = p\u2032 (xH ) + q(xH , xT ), where pP\nH\n\u2032\nof p comprising only the monomials all of whose variables are in H, i.e. p (xH ) = S\u2286H pb(S)\u03c7S (xH ).\nNow consider a restriction \u03c1 of H and the corresponding polynomial p\u03c1 (xT ) = p(\u03c1, xT ). It is clear that\nthe constant term of this polynomial is exactly p\u2032 (\u03c1). To prove the lemma, we will show that for at least\na 1/(2C d ) fraction of all \u03c1 \u2208 {\u22121, 1}K , the (restricted) degree-d PTF f\u03c1 (xT ) = sign(p\u03c1 (xT )) satisfies\nPrxT [f\u03c1 (xT ) 6= sign(p\u2032 (\u03c1))] \u2264 \u03b2. Let us define the notion of a good restriction:\nDefinition 2. A restriction \u03c1 \u2208 {\u22121, 1}K that fixes H is called good iff the following two conditions are\n\u0001\u2212d/2\ndef\n.\nsimultaneously satisfied: (i) |p\u2032 (\u03c1)| \u2265 t\u2217 = 1/(2C d ), and (ii) kq(\u03c1, xT )k2 \u2264 t\u2217 * \u0398(log(1/\u03b2)\n\nIntuitively condition (i) says that the constant term p\u2032 (\u03c1) of p\u03c1 has \"large\" magnitude, while condition (ii)\nsays that the polynomial q(\u03c1, xT ) has \"small\" l2 -norm. We claim that if \u03c1 is a good restriction then the\ndegree-d PTF f\u03c1 satisfies PrxT [f\u03c1 (xT ) 6= sign(p\u2032 (\u03c1))] \u2264 \u03b2. To see this claim, note that for any fixed \u03c1 we\nhave f\u03c1 (xT ) 6= sign(p\u2032 (\u03c1)) only if |q(\u03c1, xT )| \u2265 |p\u2032 (\u03c1)|, so to show this claim it suffices to show that if \u03c1 is\na good restriction then PrxT [|q(\u03c1, xT )| \u2265 |p\u2032 (\u03c1)|] \u2264 \u03b2. But for \u03c1 a good restriction, by conditions (i) and\n(ii) we have\nh\n\u0001d/2 i\nPrxT [|q(\u03c1, xT )| \u2265 |p\u2032 (\u03c1)|] \u2264 PrxT |q(\u03c1, xT )| \u2265 kq(\u03c1, xT )k2 * \u0398(log(1/\u03b2)\nwhich is at most \u03b2 by the concentration bound (Theorem 6), as desired. So the claim holds: if \u03c1 is a good\nrestriction then f\u03c1 (xT ) is \u03b2-close to sign(p\u2032 (\u03c1)). Thus to prove Lemma 3 it remains to show that at least a\n1/(2C d ) fraction of all restrictions \u03c1 to H are good.\nWe prove this in two steps. First we show (Lemma 4) that the polynomial p\u2032 is not too concentrated:\nwith probability at least 1/C d over \u03c1, condition (i) of Definition 2 is satisfied. We then show (Lemma 5)\nthat the polynomial q is highly concentrated: the probability (over \u03c1) that condition (ii) is not satisfied is at\nmost 1/(2C d ). Lemma 3 then follows by a union bound.\n\u0002\n\u0003\nLemma 4. We have that Pr\u03c1 |p\u2032 (\u03c1)| \u2265 t\u2217 \u2265 1/C d .\n\nProof. Using the fact that the critical index of p is large, we will show that the polynomial p\u2032 has large\nvariance (close to 1), and hence we can apply the anti-concentration bound Theorem 7.\n\n4\n\n\f\u2032 ] lies in the range [1/2, 1]. To see this, first recall that for g :\nWe start by establishing that Var[p\nP\n{\u22121, 1}n \u2192 R we have Var[g] =\nb2 (S). It is thus clear that Var[p\u2032 ] \u2264 Var[p] = 1. To\n\u22056=S\u2286[n] g\nestablish the lower bound we use the property that the \"tail\" T has \"very small\" influence in p, which is a\nconsequence of the critical index of p being large. More precisely, Lemma 1 yields\nP\nInf i (p) \u2264 (1 \u2212 \u03c4 )K * Inf(p) = (1 \u2212 \u03c4 )\u03b1/\u03c4 * Inf(p) \u2264 d * e\u2212\u03b1\n(2)\ni\u2208T\n\nwhere the last inequality uses the fact that Inf(p) \u2264 d. Therefore, we have:\nVar[p\u2032 ] = Var[p] \u2212\n\nP\n\nT \u2229S6=\u2205,S\u2286[n]\n\npb(S)2 \u2265 1 \u2212\n\nP\n\ni\u2208T\n\nInf i (p) \u2265 1 \u2212 de\u2212\u03b1 \u2265 1/2\n\nP\nwhere the first inequality uses the fact that Inf i (p) = i\u2208S\u2286[n] pb(S)2 , the second follows from (2) and the\nthird from our choice of \u03b1. We have thus established that indeed Var[p\u2032 ] \u2208 [1/2, 1].\nAt this point, we would like to apply Theorem 7 for p\u2032 . Note however that E[p\u2032 ] = E[p] = pb(\u2205) which\nis not necessarily zero. To address this minor technical point we apply Theorem 7 twice: once for the\npolynomial p\u2032\u2032 = p\u2032 \u2212 pb(\u2205) and once for \u2212p\u2032\u2032 . (Clearly, E[p\u2032\u2032 ] = 0 and Var[p\u2032\u2032 ] = Var[p\u2032 ] \u2208 [1/2, 1].) We\nthus get that, independent of the value of pb(\u2205), we have Pr\u03c1 [|p\u2032 (\u03c1)| > 2\u22121/2 * C \u2212d ] \u2265 C \u2212d , as desired.\n\u0002\n\u0001\u2212d/2 \u0003\nLemma 5. We have that Pr\u03c1 kq(\u03c1, xT )k2 > t\u2217 * \u0398(log(1/\u03b2)\n\u2264 1/(2C d ).\nProof. To obtain the desired concentration bound we must show that the degree-2d polynomial Q(\u03c1) =\n6.\nkq(\u03c1, xT )k22 has \"small\" variance. The desired bound then follows by an application of Theorem\nP\nWe thus begin by showing that kQk2 \u2264 3d de\u2212\u03b1 . To see this, we first note that Q(\u03c1) = \u22056=S\u2286T pb\u03c1 (S)2 .\nHence an application of the triangle inequality for norms and hypercontractivity (Theorem 5) yields:\nP\nP\nkQk2 \u2264\nkpb\u03c1 (S)k24 \u2264 3d\nkpb\u03c1 (S)k22 .\n\u22056=S\u2286T\n\n\u22056=S\u2286T\n\nWe now proceed to bound from above the RHS term by term:\ni\ni\nhP\nh P\n\u0002\n\u0003\nP\nP\nInf i (p\u03c1 )\npb\u03c1 (S)2 \u2264 E\u03c1 Inf(p\u03c1 ) = E\u03c1\nE\u03c1 [pb\u03c1 (S)2 ] = E\u03c1\nkpb\u03c1 (S)k22 =\n\u22056=S\u2286T\n\n\u22056=S\u2286T\n\n\u22056=S\u2286T\n\n=\n\nP\n\ni\u2208T\n\n\u0002\n\u0003 P\nInf i (p) \u2264 de\u2212\u03b1\nE\u03c1 Inf i (p\u03c1 ) =\n\ni\u2208T\n\n(3)\n\ni\u2208T\n\nP\nwhere the first inequality uses the fact Inf(p\u03c1 ) \u2265 \u22056=S\u2286T pb\u03c1 (S)2 , the equality in (3) follows from Lemma 2,\nand the last inequality is Equation (2). We have thus shown that kQk2 \u2264 3d de\u2212\u03b1 .\nWe now upper bound Pr\u03c1 [Q(\u03c1) > (t\u2217 )2 * \u0398(log(1/\u03b2))\u2212d ]. Since kQk2 \u2264 3d de\u2212\u03b1 , Theorem 6 implies\nthat for all t > ed we have Pr\u03c1 [Q(\u03c1) > t * 3d de\u2212\u03b1 ] \u2264 exp(\u2212\u03a9(t1/d )). Taking t to be \u0398(dd lnd C) this\nupper bound is at most 1/(2C d ). Our choice of the parameter \u03b1 gives t * d3d * e\u2212\u03b1 \u2264 (t\u2217 )2 * \u0398(log(1/\u03b2))\u2212d .\nThis completes the proof of Lemma 5, and thus also the proof of Lemma 3.\n\n2.2 The small critical index case\nIn this section we show that if the critical index of p is \"small\", then a random restriction of \"few\" variables\ncauses p to become regular with non-negligible probability. We do this by showing that no matter what the\ncritical index is, a random restriction of all variables up to the \u03c4 -critical index causes p to become \u03c4 \u2032 -regular,\nfor some \u03c4 \u2032 not too much larger than \u03c4 , with probability at least 1/(2C d ). More formally, we prove:\nLemma 6. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial with \u03c4 -critical index k \u2208 [n]. Let \u03c1 be a random\nrestriction that fixes [k], and let \u03c4 \u2032 = (C \u2032 * d ln d * ln \u03c41 )d * \u03c4 for some suitably large absolute constant C \u2032 .\nWith probability at least 1/(2C d ) over the choice of \u03c1, the restricted polynomial p\u03c1 is \u03c4 \u2032 -regular.\n5\n\n\fProof. We must show that with probability at least 1/(2C d ) over \u03c1 the restricted polynomial p\u03c1 satisfies\nInf l (p\u03c1 )/\n\nn\nP\n\nj=k+1\n\nInf j (p\u03c1 ) \u2264 \u03c4 \u2032\n\n(4)\n\nP\nfor all l \u2208 [k + 1, n]. Note that before the restriction, we have Inf l (p) \u2264 \u03c4 * nj=k+1 Inf j (p) for all\nl \u2208 [k + 1, n] because the \u03c4 -critical index of p is k.\nLet us give an intuitive explanation of the proof. We first show (Lemma 7) that with probability at least\n\u2212d\nC the denominator in (4) does not decrease under a random restriction. This is an anti-concentration\nstatement that follows easily from Theorem 7. We then show (Lemma 8) that with probability at least\n1 \u2212 C \u2212d /2 the numerator in (4) does not increase by much under a random restriction, i.e. no variable\ninfluence Inf l (p\u03c1 ), l \u2208 [k + 1, n], becomes too large. Thus both events occur (and p\u03c1 is \u03c4 \u2032 -regular) with\nprobability at least C \u2212d /2.\nWe note that while each individual influence Inf l (p\u03c1 ) is indeed concentrated around its expectation (see\nClaim 9), we need a concentration statement for n \u2212 k such influences. This might seem difficult to achieve\nsince we require bounds that are independent of n. We get around this difficulty by a \"bucketing\" argument\nthat exploits the fact (at many different scales) that all but a few influences Inf l (p) must be \"very small.\"\nP\ndef \b\nIt\nremains\nto\nstate\nand\nprove\nLemmas\n7\nand\n8.\nConsider\nthe\nevent\nE\n= \u03c1 \u2208 {\u22121, 1}k | nl=k+1 Inf l (p\u03c1 ) \u2265\nPn\nl=k+1 Inf l (p) . We first show:\nLemma 7. Pr\u03c1 [E] \u2265 C \u2212d .\n\ndef Pn\nProof. It follows from Fact 14 and the Fourier expressionPof Inf l (p\u03c1 ) that A(\u03c1) =\nl=k+1 Inf l (p\u03c1 ) is a\ndegree-2d polynomial. By Lemma 2 we get that E\u03c1 [A] = nl=k+1 Inf l (p) > 0. Also observe that A(\u03c1) \u2265 0\nfor all \u03c1 \u2208 {\u22121, 1}k . We may now apply Theorem 7 to the polynomial A\u2032 = A \u2212 E\u03c1 [A], to obtain:\n\nPr\u03c1 [E] = Pr[A\u2032 \u2265 0] \u2265 Pr[A\u2032 \u2265 C0\u22122d * \u03c3(A\u2032 )] > C0\u22122d = C \u2212d .\ndef \b\nWe now turn to Lemma 8. Consider the event J = \u03c1 \u2208 {\u22121, 1}k | maxl\u2208[k+1,n] Inf l (p\u03c1 ) >\nP\n\u03c4 \u2032 nj=k+1 Inf j (p) . We show:\nLemma 8. Pr\u03c1 [J ] \u2264 (1/2) * C \u2212d .\n\nThe rest of this subsection consists of the proof of Lemma 8. A useful intermediate claim is that the\ninfluences of individual variables do not increase by a lot under a random restriction (note that this claim,\nproved in Appendix B, does not depend on the value of the critical index):\nClaim 9. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial. Let \u03c1 be a random restriction fixing [j].\nFix any t > e2d and any l \u2208 [j + 1, n]. With probability at least 1 \u2212 exp(\u2212\u03a9(t1/d )) over \u03c1, we have\nInf l (p\u03c1 ) \u2264 3d tInf l (p).\nClaim 9 says that for any given coordinate, the probability that its influence after a random restriction\nincreases by a t factor decreases exponentially in t. Note that Claim 9 and a naive union bound over all\ncoordinates in [k + 1, n] does not suffice to prove Lemma 8. Instead, we proceed as follows: We partition\nthe coordinates in [k + 1, n] into \"buckets\" according to their influence in the tail of p. In particular, the i-th\nbucket (i \u2265 0) contains all variables l \u2208 [k + 1, n] such that\nInf l (p)/\n\nn\nP\n\nj=k+1\n\nInf j (p) \u2208 [\u03c4 /2i+1 , \u03c4 /2i ].\n\nWe analyze the effect of a random restriction \u03c1 on the variables of each bucket i separately and then conclude\nby a union bound over all the buckets.\n\n6\n\n\fSo fix a bucket i. Note that, by definition, the number of variables in the i-th bucket is at most 2i+1 /\u03c4 .\nWe bound from above the probability of the event B(i)\nPthat there exists a variable l in bucket i that violates\nthe regularity constraint, i.e. such that Inf l (p\u03c1 ) > \u03c4 \u2032 nl=k+1 Inf l (p). We will do this by a combination of\nClaim 9 and a union bound over the variables in the bucket. We will show:\nClaim 10. We have that Pr\u03c1 [B(i)] \u2264 2\u2212(i+2) * C \u2212d .\n\nThe above claim completes the proof of Lemma 8 by a union bound across buckets. Indeed, assuming\nthat any variable l \u2208P[k + 1, n] violates the condition Inf l (p\u03c1 ) \u2264\nP the claim, the probability\nP\n\u221e\n\u2212d 2\u22122\ni\n\u2212d .\n\u03c4 \u2032 nl=k+1 Inf l (p) is at most \u221e\nPr\n\u03c1 [B(i)] \u2264 C\ni=0 (1/2) = (1/2) * C\ni=0\nIt thus remains to prove Claim 10. Fix a variable l in the i-th bucket. We apply Claim 9 selecting a\nd i+2\ndef\nt \u2264 c\u2032d (d + i + ln \u03c41 )d for some absolute constant c\u2032 . As a\nvalue of t = e\nt = (ln C 4\u03c4 )d . It is clear that e\nconsequence, there is an absolute constant C \u2032 such that for every i,\n1\ne\nt \u2264 3\u2212d C \u2032d 2i (d ln d ln )d .\n(5)\n\u03c4\n(To see this, note that for i \u2264 10d ln d we have d+ i+ ln \u03c41 < 11d ln d ln \u03c41 , from which the claimed bound is\neasily seen to hold. For i > 10d ln d, we use d+i+ln \u03c41 < di ln \u03c41 and the fact that id < 2i for i > 10d ln d.)\nInequality (5) can be rewritten as 3d * e\nt * 2\u03c4i \u2264 \u03c4 \u2032 . Hence, our assumption on the range of Inf l (p) gives\n3d * e\nt * Inf l (p) \u2264 \u03c4 \u2032 *\n\nn\nP\n\nInf j (p).\n\nj=k+1\n\nP\nTherefore, by Claim 9, the probability that coordinate l violates the condition Inf l (p\u03c1 ) \u2264 \u03c4 \u2032 nj=k+1 Inf j (p)\nis at most \u03c4 /(C d 4i+2 ) by our choice of e\nt. Since bucket i contains at most 2i+1 /\u03c4 coordinates, Claim 10\nfollows by a union bound. Hence Lemma 8, and thus Lemma 6, is proved.\n\n2.3 Putting Everything Together: Proof of Theorem 1\nThe following lemma combines the results of the previous two subsections (see Appendix B for a proof):\nLemma 11. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial and 0 < \u03c4e, \u03b2 < 1/2. Fix \u03b1 = \u0398(d log log(1/\u03b2)+\nd log d) and \u03c4e\u2032 = \u03c4e * (C \u2032 d ln d ln(1/e\n\u03c4 ))d , where C \u2032 is a universal constant. (We assume w.l.o.g. that the\nvariables are ordered s.t. Inf i (p) \u2265 Inf i+1 (p), i \u2208 [n \u2212 1].) One of the following statements holds true:\n1. The polynomial p is \u03c4e-regular.\n\n2. With probability at least 1/(2C d ) over a random restriction \u03c1 fixing the first \u03b1/e\n\u03c4 (most influential)\nvariables of p, the function sign(p\u03c1 ) is \u03b2-close to a constant function.\n3. There exists a value k \u2264 \u03b1/e\n\u03c4 , such that with probability at least 1/(2C d ) over a random restriction\n\u03c1 fixing the first k (most influential) variables of p, the polynomial p\u03c1 is \u03c4e\u2032 -regular.\n\nProof of Theorem 1. We begin by observing that any function f on {\u22121, 1}n is equivalent to a decision\ntree where each internal node of the tree is labeled by a variable, every root-to-leaf path corresponds to a\nrestriction \u03c1 that fixes the variables as they are set on the path, and every leaf is labeled with the restricted\nsubfunction f\u03c1 . Given an arbitrary degree-d PTF f = sign(p), we will construct a decision tree T of the\nform described in Theorem 1. It is clear that in any such tree every leaf function f\u03c1 will be a degree-d PTF;\nwe must show that T has depth depth(d, \u03c4 ) and that with probability 1 \u2212 \u03c4 over the choice of a random\nroot-to-leaf path \u03c1, the restricted subfunction f\u03c1 = sign(p\u03c1 ) is \u03c4 -close to a \u03c4 -regular degree-d PTF.\nFor a tree T computing f = sign(p), we denote by N (T ) its set of internal nodes and by L(T ) its set of\nleaves. We call a leaf \u03c1 \u2208 L(T ) \"good\" if the corresponding function f\u03c1 is \u03c4 -close to being \u03c4 -regular. We\ncall a leaf \"bad\" otherwise. Let GL(T ) and BL(T ) be the sets of \"good\" and \"bad\" leaves in T respectively.\n7\n\n\fThe basic approach for the proof is to invoke Lemma 11 repeatedly in a sequence of at most 2C d ln(1/\u03c4 )\nstages. In the first stage we apply Lemma 11 to f itself; this gives us an initial decision tree. In the\nsecond stage we apply Lemma 11 to those restricted subfunctions f\u03c1 (corresponding to leaves of the initial\ndecision tree) that are still \u03c4 -far from being \u03c4 -regular; this \"grows\" our initial decision tree. Subsequent\nstages continue similarly; we will argue that after at most 2C d ln(1/\u03c4 ) stages, the resulting tree satisfies the\nrequired properties for T . In every application of Lemma 11 the parameters \u03b2 and \u03c4e\u2032 are both taken to be \u03c4 ;\nnote that taking \u03c4e\u2032 to be \u03c4 sets the value of \u03c4e in Lemma 11 to a value that is less than \u03c4 .\nWe now provide the details. In the first stage, the initial application of Lemma 11 results in a tree T1 .\nThis tree T1 may consist of a single leaf node that is \u03c4e-regular (if f is \u03c4e-regular to begin with \u2013 in this case,\nsince \u03c4e < \u03c4 , we are done), or a complete decision tree of depth \u03b1/e\n\u03c4 (if f had large critical index), or a\ncomplete decision tree of depth k < \u03b1/e\n\u03c4 (if f had small critical index). Note that in each case the depth of\nT1 is at most \u03b1/e\n\u03c4 . Lemma 11 guarantees that:\nPr\u03c1\u2208T1 [\u03c1 \u2208 BL(T1 )] \u2264 1 \u2212 1/(2C d ),\nwhere the probability is over a random root-to-leaf path \u03c1 in T1 .\nIn the second stage, the \"good\" leaves \u03c1 \u2208 GL(T1 ) are left untouched; they will be leaves in the final\ntree T . For each \"bad\" leaf \u03c1 \u2208 BL(T1 ), we order the unrestricted variables in decreasing order of their\ninfluence in the polynomial p\u03c1 , and we apply Lemma 11 to f\u03c1 . This \"grows\" T1 at each bad leaf by replacing\neach such leaf with a new decision tree; we call the resulting overall decision tree T2 .\nA key observation is that the probability that a random path from the root reaches a \"bad\" leaf is significantly smaller in T2 than in T1 ; in particular\nPr\u03c1\u2208T2 [\u03c1 \u2208 BL(T2 )] \u2264 (1 \u2212 1/(2C d ))2 .\nWe argue this as follows: Let \u03c1 be any fixed \"bad\" leaf in T1 , i.e. \u03c1 \u2208 BL(T1 ). The function f\u03c1 is not\n\u03c4e\u2032 -regular and consequently not \u03c4e-regular. Thus, either statement (2) or (3) of Lemma 11 must hold when\nthe Lemma is applied to f\u03c1 . The tree that replaces \u03c1 in T0 has depth at most \u03b1/e\n\u03c4 , and a random root-to-leaf\nd\npath \u03c11 in this tree reaches a \"bad\" leaf with probability at most 1 \u2212 1/(2C ). So the overall probability that\na random root-to-leaf path in T2 reaches a \"bad\" leaf is at most (1 \u2212 1/(2C d ))2 .\nContinuing in this fashion, in the i-th stage we replace all the bad leaves of Ti\u22121 by decision trees\naccording to Lemma 11 and we obtain the tree Ti . An inductive argument gives that\nPr\u03c1\u2208Ti [\u03c1 \u2208 BL(Ti )] \u2264 (1 \u2212 1/(2C d ))i ,\n\nwhich is at most \u03c4 for\n\ndef\n\ni\u2217 = 2C d ln(1/\u03c4 ).\n\nThe depth of the overall tree will be the maximum number of stages (2C d ln(1/\u03c4 )) times the maximum\ndepth added in each stage (at most \u03b1/e\n\u03c4 , since we always restrict at most this many variables), which is at\nmost (\u03b1/e\n\u03c4 ) * i\u2217 . Since \u03b2 = \u03c4 , we get \u03b1 = \u0398(d log log(1/\u03c4 ) + d log d). Recalling that \u03c4e\u2032 in Lemma 11 is\n\u0001O(d)\n. By substitution we get that the depth of the tree is upper\nset to \u03c4 , we see that \u03c4e = \u03c4 / C \u2032 d ln d ln(1/\u03c4 )\nO(d)\nO(d)\nbounded by d\n* (1/\u03c4 ) * log(1/\u03c4 )\nwhich concludes the proof of Theorem 1.\n\n3 Every degree-d PTF has a low-weight approximator\nIn this section we apply Theorem 1 to prove Theorem 2, which we restate below:\nTheorem 2 Let f (x) = sign(p(x)) be any degree-d PTF. Fix any \u01eb > 0 and let \u03c4 = (\u0398(1) * \u01eb/d)8d . Then\nthere is a polynomial q(x) of degree D = d + depth(d, \u03c4 ) and weight nd * 24depth(d,\u03c4 ) * (d/\u01eb)O(d) , which is\nsuch that the PTF sign(q(x)) is \u01eb-close to f .\nTo prove Theorem 2, we first show that any sufficiently regular degree-d PTF over n variables has a lowweight approximator, of weight roughly nd . Theorem 1 asserts that almost every leaf \u03c1 of T is close to a\n8\n\n\fregular PTF; at each such leaf \u03c1 we use the low-weight approximator of the previous sentence to approximate\nthe regular PTF, and thus to approximate f\u03c1 . Finally, we combine all of these low-weight polynomials to\nget an overall PTF of low weight which is a good approximator for f. We give details below.\n\n3.1 Low-weight approximators for regular PTFs\nIn this subsection we prove that every sufficiently regular PTF has a low-weight approximator of degree d:\nLemma 12. Given \u01eb > 0, let \u03c4 = (\u0398(1) * \u01eb/d)8d . Let p : {\u22121, 1}n \u2192 R be a \u03c4 -regular degree-d polynomial\nwith Var[p] = 1. There exists a degree-d polynomial q : {\u22121, 1}n \u2192 R of weight nd * (d/\u01eb)O(d) such that\nsign(q(x)) is an \u01eb-approximator for sign(p(x)).\nProof. The polynomial q is obtained by rounding the weights of p to an appropriate granularity, similar to\nthe regular case in [Ser07] for the d = 1 case. To show that this works, we use the fact that regular PTFs\nhave very good anti-concentration. In particular we will use the following claim, which is proved using the\ninvariance principle [MOO05] and Gaussian anti-concentration [CW01] (see Appendix D for the proof):\nClaim 13. Let p : {\u22121, 1}n \u2192 R be a \u03c4 -regular degree-d polynomial with Var[p] = 1. Then Prx [|p(x)| \u2264\n\u03c4 ] \u2264 O(d\u03c4 1/8d ).\nWe turn to the detailed proof of Lemma 12. We first note that if the constant coefficient pb(\u2205) of P has\nmagnitude greater than (O(log(1/\u01eb)))d/2 , then Theorem 6 (applied to p(x) \u2212 pb(\u2205)) implies that sign(p(x))\nagrees with sign(b\np(\u2205)) for at least a 1 \u2212 \u01eb fraction of inputs x. So in this case sign(p(x)) is \u01eb-close to a\nconstant function, and the conclusion of the Lemma certainly holds. Thus we henceforth assume that |b\np(\u2205)|\nd/2\nis at most (O(log(1/\u01eb))) .\nLet\n\u03b1 = \u03c4 /(Kn * ln(4/\u01eb))d/2\nwhere K > 0 is an absolute constant (specified later). For each S 6= \u2205 let qb(S) be the value obtained\nby rounding pb(S) toPthe nearest integer multiple of \u03b1, and let qb(\u2205) equal pb(\u2205). This defines a degree-d\npolynomial q(x) = S qb(S)\u03c7S (x). It is easy to see that rescaling by \u03b1, all of the non-constant coefficients\nof q(x)/\u03b1 are integers. Since each coefficient qb(S) has magnitude at most twice that of pb(S), we may bound\nthe sum of squares of coefficients of q(x)/\u03b1 by\nP\np(S)2\n(O(log(1/\u01eb)))d\npb(\u2205)2\nS6=\u2205 4b\n+\n\u2264\n\u2264 nd * (d/\u01eb)O(d) .\n2\n2\n\u03b1\n\u03b1\n\u03b12\nWe now observe that the constant coefficient pb(\u2205) of q(x) can be rounded to an integer multiple of \u03b1 without\nchanging the value of sign(q(x)) for any input x. Doing this, we obtain a polynomial q \u2032 (x)/\u03b1 with all integer\ncoefficients, weight nd * (d/\u01eb)O(d) , and which has sign(q \u2032 (x)) = sign(q(x)) for all x.\nIn the rest of our analysis we shall consider the polynomial q(x) (recall that the constant coefficient of\nq(x) is precisely pb(\u2205)). It remains to show that sign(q) is an \u01eb-approximator for sign(p).\nP For each S 6= \u2205\nlet eb(S) equal pb(S) \u2212 qb(S). This defines a polynomial (with constant term 0) e(x) = S eb(S)xS , and we\nhave q(x) + e(x) = p(x). (The coefficients eb(S) are the \"errors\" induced by approximating pb(S) by qb(S).)\nRecall that \u03c4 = (\u0398(1) * \u01eb/d)8d . For any input x, we have that sign(q(x)) 6= sign(p(x)) only if either (i)\n\u03c4\n|e(x)| \u2265 \u03c4, or (ii) |p(x)| \u2264 \u03c4. Since each coefficient of e(x) satisfies |b\ne(S)| \u2264 \u03b1/2 \u2264 2(Kn*ln(4/\u01eb))\nd/2 , the\nsum of squares of all (at most nd ) coefficients of e is at most\nP\nS\n\ne(S)2 \u2264\nb\n\n\u03c42\n,\n4(K ln(4/\u01eb))d\n\nand thus\n\n9\n\nkek \u2264\n\n\u03c4\n.\n2(K ln(4/\u01eb))d/2\n\n\fApplying Theorem 6, we get that Prx [|e(x)| \u2265 \u03c4 ] \u2264 \u01eb/2 (for a suitable absolute constant choice of K), so\nwe have upper bounded the probability of (i).\nFor (ii), we use the anti-concentration bound for regular polynomials, Claim 13. This directly gives us\nthat Prx [|p(x)| \u2264 \u03c4 ] \u2264 O(d\u03c4 1/8d ) \u2264 \u01eb/2.\nThus the probability, over a random x, that either (1) or (2) holds is at most \u01eb. Consequently sign(q) is\nan \u01eb-approximator for sign(p), and Lemma 12 is proved.\n\n3.2 Proof of Theorem 2\nLet f = sign(p) be an arbitrary degree-d PTF over n Boolean variables, and let \u01eb > 0 be the desired\napproximation parameter. We invoke Theorem 1 with its \"\u03c4 \" parameter set to \u03c4 = (\u0398(1) * (\u01eb/2)/d)8d (i.e.\nour choice of \u03c4 is obtained by plugging in \"\u01eb/2\" for \u01eb in the first sentence of Lemma 12). For each leaf \u03c1 of\nthe tree T as described in Theorem 1 (we call these \"good\" leaves), let g (\u03c1) be a \u03c4 -regular degree-d PTF that\nis \u03c4 -close to f\u03c1 . By Lemma 12, for each such leaf \u03c1 there is a degree-d polynomial of weight nd * (d/\u01eb)O(d) ,\nwhich we denote q (\u03c1) , such that g(\u03c1) is \u01eb/2-close to sign(q (\u03c1) ). For each of the other leaves in T (which are\nreached by at most a \u03c4 fraction of all inputs to T \u2013 we call these \"bad\" leaves), for which f\u03c1 is not \u03c4 -close\nto any \u03c4 -regular degree-d PTF, let q (\u03c1) be the constant-1 function.\nFor each leaf \u03c1 of depth r in T , let P\u03c1 (x) be the unique multilinear polynomial of degree r which\noutputs 2r iff x reaches \u03c1 and outputs 0 otherwise. (As an example, if \u03c1 is a leaf which is reached by the\npath \"x3 = \u22121, x6 = 1, x2 = 1\" from the root in T , then P\u03c1 (x) would be (1 \u2212 x3 )(1 + x6 )(1 + x2 ).) Our\nfinal PTF is\nP\ng(x) = sign(Q(x)), where Q(x) =\nP\u03c1 (x)q (\u03c1) (x).\n\u03c1\n\nIt is easy to see that on any input x, the value Q(x) equals 2|\u03c1x | * q (\u03c1x ) (x), where we write \u03c1x to denote\nthe leaf of T that x reaches and |\u03c1x | to denote the depth of that leaf. Thus sign(Q(x)) equals sign(q (\u03c1x ) (x))\nfor each x, and from this it follows that Prx [g(x) 6= f (x)] is at most \u03c4 + \u03c4 + \u01eb/2 < \u01eb. Here the first \u03c4 is\nbecause a random input x may reach a bad leaf with probability up to \u03c4 ; the second \u03c4 is because for each\ngood leaf \u03c1, the function g(\u03c1) is \u03c4 -close to f\u03c1 ; and the \u01eb/2 is because sign(q (\u03c1) ) is \u01eb/2-close to g(\u03c1) .\nSince T has depth depth(d, \u03c4 ), it is easy to see that Q has degree at most depth(d, \u03c4 )+ d. It is clear that\nthe coefficients of Q are all integers, so it remains only to bound the sum of squares of these coefficients.\nEach polynomial addend P\u03c1 (x)q (\u03c1) (x) in the sum is easily seen to have sum of squared coefficients\n\u0010\n\u0011\nP\\\nP\u03c1 q (\u03c1) (S)2 = E[(P\u03c1 * q (\u03c1) )2 ] \u2264 max P\u03c1 (x)2 * E[q (\u03c1) (x)2 ] \u2264 22depth(d,\u03c4 ) * nd * (d/\u01eb)O(d) .\n(6)\nx\n\nS\n\nSince T has depth depth(d, \u03c4 ), the number of leaves \u03c1 is at most 2depth(d,\u03c4 ) , and hence for each S by\nCauchy-Schwarz we have\n!2\nP\nP\n2\n2\n\\\n(\u03c1)\nb\n\u2264 2depth(d,\u03c4 ) * P\\\n(7)\nP\u03c1 q (\u03c1) (S)\nQ(S)\n=\n\u03c1 q (S) .\n\u03c1\n\n\u03c1\n\nThis implies that the total weight of Q is\n\nPb 2\nP\\\nP\u03c1 q (\u03c1) (S)2\nQ(S) \u2264 2depth(d,\u03c4 ) *\nS\n\n\u03c1,S\n\n2depth(d,\u03c4 )\n\n\u2264 2\n\n4depth(d,\u03c4 )\n\n\u2264 2\n\n\u0012\n\nP\\\nmax\nP\u03c1 q (\u03c1) (S)2\n\u03c1\n\nd\n\nS\n\n* n * (d/\u01eb)O(d) ,\n\nand Theorem 2 is proved.\n10\n\n(using (7))\n\u0013\n(using (6))\n\n\fe d )-weight approximators\n3.3 Degree-d PTFs require \u03a9(n\n\nIn this section we give two lower bounds on the weight required to \u01eb-approximate certain degree-d PTFs.\n(We use the notation \u03a9d () below to indicate that the hidden constant of the big-Omega depends on d.)\nTheorem 3. For all sufficiently large n, there is a degree-d n-variable PTF f (x) with the following property:\nLet K(d) be any positive-valued function depending only on d. Suppose that g(x) = sign(q(x)) is a degreedef\n\nK(d) PTF with integer coefficients qb(S) such that dist(f, g) \u2264 \u01eb\u22c6 where \u01eb\u22c6 = C \u2212d /2. Then the weight of q\nis \u03a9d (nd / log n).\n\nTheorem 4. For all sufficiently large n, there is a degree-d n-variable PTF f (x) with the following property: Suppose that g(x) = sign(q(x)) is any PTF (of any degree) with integer coefficients qb(S) such that\ndef\n\ndist(f, g) \u2264 \u01eb\u22c6 where \u01eb\u22c6 = C \u2212d /2. Then the weight of q is \u03a9d (nd\u22121 ).\n\nViewing d and \u01eb as constants, Theorem 3 implies that the O(nd ) weight bound of our \u01eb-approximator\nfrom Theorem 2 (which has constant degree) is essentially optimal for any constant-degree \u01eb-approximator.\nTheorem 4 says that there is only small room for improving our weight bound even if arbitrary-degree PTFs\nare allowed as approximators. We prove these results in Appendix D.2.\n\nReferences\n[ABFR94] J. Aspnes, R. Beigel, M. Furst, and S. Rudich. The expressive power of voting polynomials.\nCombinatorica, 14(2):1\u201314, 1994.\n[AH09]\n\nPer Austrin and Johan H\u00e5stad. Randomly supported independence and resistance. In Proc. 41st\nAnnual ACM Symposium on Theory of Computing (STOC), pages 483\u2013492. ACM, 2009.\n\n[BELY09] I. Ben-Eliezer, S. Lovett, and A. Yadin. Polynomial Threshold Functions: Structure, Approximation and Pseudorandomness. Available at http://arxiv.org/abs/0911.3473, 2009.\n[Bon70]\n\nA. Bonami. Etude des coefficients fourier des fonctiones de lp (g). Ann. Inst. Fourier (Grenoble), 20(2):335\u2013402, 1970.\n\n[Bru90]\n\nJ. Bruck. Harmonic analysis of polynomial threshold functions. SIAM Journal on Discrete\nMathematics, 3(2):168\u2013177, 1990.\n\n[CW01]\n\nA. Carbery and J. Wright. Distributional and Lq norm inequalities for polynomials over convex\nbodies in Rn . Mathematical Research Letters, 8(3):233\u2013248, 2001.\n\n[DFKO06] Irit Dinur, Ehud Friedgut, Guy Kindler, and Ryan O'Donnell. On the Fourier tails of bounded\nfunctions over the discrete cube. In Proc. 38th ACM Symp. on Theory of Computing, pages\n437\u2013446, 2006.\n[DGJ+ 09] I. Diakoniokolas, P. Gopalan, R. Jaiswal, R. Servedio, and E. Viola. Bounded independence\nfools halfspaces. In Proc. 50th IEEE Symposium on Foundations of Computer Science (FOCS),\npages 171\u2013180, 2009.\n[DKN09]\n\nI. Diakonikolas, D.M. Kane, and J. Nelson. Bounded Independence Fools Degree-2 Threshold\nFunctions. Available at http://arxiv.org/abs/0911.3389, 2009.\n\n[DRST09] I. Diakonikolas, P. Raghavendra, R. Servedio, and L.-Y. Tan. Average sensitivity and noise\nsensitivity of polynomial threshold functions, 2009. Available at http://arxiv.org/abs/0909.5011.\n11\n\n\f[DS09]\n\nI. Diakonikolas and R. Servedio. Improved approximation of linear threshold functions. In\nProc. 24th Annual IEEE Conference on Computational Complexity (CCC), pages 161\u2013172,\n2009.\n\n[GL94]\n\nC. Gotsman and N. Linial. Spectral properties of threshold functions. Combinatorica, 14(1):35\u2013\n50, 1994.\n\n[Gre05]\n\nB. Green. A szemer\u00e9di-type regularity lemma in abelian groups, with applications. Geometric\nand Functional Analysis (GAFA), 15:340\u2013376, 2005.\n\n[Gro75]\n\nL. Gross. Logarithmic Sobolev inequalities. Amer. J. Math., 97(4):1061\u20131083, 1975.\n\n[HKM09]\n\nP. Harsha, A. Klivans, and R. Meka. Bounding the sensitivity of polynomial threshold functions.\nAvailable at http://arxiv.org/abs/0909.5175, 2009.\n\n[KKL88]\n\nJ. Kahn, G. Kalai, and N. Linial. The influence of variables on boolean functions. In Proc. 29th\nAnnual Symposium on Foundations of Computer Science (FOCS), pages 68\u201380, 1988.\n\n[KS06]\n\nG. Kalai and S. Safra. Threshold phenomena and influence. In A.G. Percus, G. Istrate, and\nC. Moore, editors, Computational Complexity and Statistical Physics, pages 25\u201360. Oxford\nUniversity Press, 2006.\n\n[LMN93]\n\nN. Linial, Y. Mansour, and N. Nisan. Constant depth circuits, Fourier transform and learnability.\nJournal of the ACM, 40(3):607\u2013620, 1993.\n\n[MOO05]\n\nE. Mossel, R. O'Donnell, and K. Oleszkiewicz. Noise stability of functions with low influences: invariance and optimality. In Proc. 46th Symposium on Foundations of Computer Science (FOCS), pages 21\u201330, 2005.\n\n[MORS09] K. Matulef, R. O'Donnell, R. Rubinfeld, and R. Servedio. Testing halfspaces. In Proc. SODA,\npages 256\u2013264, 2009.\n[MZ09]\n\nR. Meka and D. Zuckerman. Pseudorandom Generators for Polynomial Threshold Functions.\nAvailable at http://arxiv.org/abs/0910.4122, 2009.\n\n[O'D07a]\n\nR. O'Donnell. Analysis of boolean functions.\nanalysis/, 2007.\n\n[O'D07b]\n\nR.\nO'Donnell.\nLecture\n16:\nThe\nhypercontractivity\nhttp://www.cs.cmu.edu/ odonnell/boolean-analysis/lecture16.pdf, 2007.\n\n[OS03a]\n\nR. O'Donnell and R. Servedio. Extremal properties of polynomial threshold functions. In\nProceedings of the Eighteenth Annual IEEE Conference on Computational Complexity, pages\n325\u2013334, 2003.\n\n[OS03b]\n\nRyan O'Donnell and Rocco A. Servedio. New degree bounds for polynomial threshold functions. In Proc. 35th Annual ACM Symposium on Theory of Computing (STOC), pages 325\u2013334.\nACM, 2003.\n\n[OS08]\n\nR. O'Donnell and R. Servedio. The Chow Parameters Problem. In Proc. 40th Annual ACM\nSymposium on Theory of Computing (STOC), pages 517\u2013526, 2008.\n\n[Pod09]\n\nV. V. Podolskii. Perceptrons of large weight. Problems of Information Transmission, 45(1):46\u2013\n53, 2009.\n12\n\nhttp://www.cs.cmu.edu/ odonnell/booleantheorem.\n\n\f[Sak93]\n\nM. Saks. Slicing the hypercube. Surveys in Combinatorics 1993, pages 211\u2013257, 1993.\n\n[Ser07]\n\nR. Servedio. Every linear threshold function has a low-weight approximator. Computational\nComplexity, 16(2):180\u2013209, 2007.\n\n[She09]\n\nA. Sherstov. The intersection of two halfspaces has high threshold degree. In Proc. 50th IEEE\nSymposium on Foundations of Computer Science (FOCS), 2009.\n\n[Sze78]\n\nE. Szemer\u00e9di. Regular partitions of graphs. Colloq. Internat. CNRS: Probl\u00e8mes combinatoires\net th\u00e9orie des graphes, 260:399\u2013401, 1978.\n\n[Tao07]\n\nT. Tao. Structure and randomness in combinatorics. In Proc. 48th IEEE Symposium on Foundations of Computer Science (FOCS), 2007.\n\nA\n\nUseful Background Results\n\nA.1 Fourier Analysis over {\u22121, 1}n .\n\nWe consider functions f : {\u22121, 1}n \u2192 R (though we often focus on Boolean-valued functions which map\nto {\u22121, 1}), and we think of the inputs x to f as being distributed according to the uniform probability\ndistribution. The set of such functions forms a 2n -dimensional inner product space\nQwith inner product given\nby hf, gi = E[f (x)g(x)]. The set of functions (\u03c7S )S\u2286[n] defined by \u03c7S (x) = i\u2208S xi forms a complete\northonormal basis for this space. Given a function f : {\u22121, 1}n \u2192 R we define its Fourier coefficients by\nP\ndef\nfb(S) = E[f (x)\u03c7S (x)], and we have that f (x) = S fb(S)\u03c7S (x). We refer to the maximum |S| over all\nnonzero fb(S) as the Fourier degree of f.\nP\nAs an easy consequence of orthonormality we have Plancherel's identity hf, gi = S fb(S)b\ng (S), which\nP b 2\n2\nhas as a special case Parseval's identity, E[f (x) ] = S f (S) . From this it follows that for every f :\nP\n{\u22121, 1}n \u2192 {\u22121, 1} we have S fb(S)2 = 1. We recall the well-known fact (see e.g. [KKL88]) that the\nP\ntotal influence Inf(f ) of any Boolean function equals S fb(S)2 |S|. Note that, in this setting, the expectation\nand\ncan be expressed in terms of the Fourier coefficients of f by E[f ] = fb(\u2205) and Var[f ] =\nP the variance\n2\nb\nf (S) .\n\u22056=S\u2286[n]\n\nA.2 Useful Probability Bounds for Section 2\n\nWe first recall the following moment bound for low-degree polynomials, which is equivalent to the wellknown hypercontractive inequality of [Bon70, Gro75]:\nTheorem 5. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial and q > 2. Then\nkpkq \u2264 (q \u2212 1)d/2 kpk2 .\nThe following concentration bound for low-degree polynomials, a simple corollary of hypercontractivity, is well known (see e.g. [O'D07b, DFKO06, AH09]):\nTheorem 6. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial. For any t > ed , we have\nPrx [|p(x)| \u2265 tkpk2 ] \u2264 exp(\u2212\u03a9(t2/d )).\nWe will also need the following weak anti-concentration bound for low-degree polynomials over the\ncube:\n13\n\n\fTheorem 7 ([DFKO06, AH09]). There is a universal constant C0 > 1 such that for any non-zero degree-d\npolynomial p : {\u22121, 1}n \u2192 R with E[p] = 0, we have\nPrx [p(x) > C0\u2212d * kpk2 ] > C0\u2212d .\nThroughout this paper, we let C = C02 , where C0 is the universal constant from Theorem 7. Note that since\nC > C0 , Theorem 7 holds for C as well.\n\nA.3 Useful Probability Bounds for Section 3\nWe denote by N n the standard n-dimensional Gaussian distribution N (0, 1)n .\nThe following two facts will be useful in the proof of Theorem 2, in particular in the analysis of the regular case. The first fact is a powerful anti-concentration bound for low-degree polynomials over independent\nGaussian random variables:\nTheorem 8 ([CW01]). Let p : Rn \u2192 R be a nonzero degree-d polynomial. For all \u01eb > 0 we have\nPrG\u223cN n [|p(G)| \u2264 \u01ebkpk2 ] \u2264 O(d\u01eb1/d ).\nWe note that the above bound is essentially tight, even for multi-linear polynomials.\nThe second fact is a version of the invariance principle of Mossel, O'Donnell and Oleszkiewicz, specifically Theorem 3.19 under hypothesis H4 in [MOO05]:\nP\nTheorem 9 ([MOO05]). Let p(x) = S\u2286[n],|S|\u2264d pb(S)\u03c7S (x) be a degree-d multilinear polynomial with\nVar[p] = 1. Suppose each coordinate i \u2208 [n] has Inf i (p) \u2264 \u03c4 . Then,\nsup |Prx [p(x) \u2264 t] \u2212 PrG\u223cN n [p(G) \u2264 t]| \u2264 O(d\u03c4 1/(8d) ).\nt\u2208R\n\nB Omitted Proofs from Section 2\nB.1\n\nProof of Lemma 1\n\nRecall Lemma 1:\nLemma 1. Let p : {\u22121, 1}n \u2192 R and \u03c4 > 0. Let k be the \u03c4 -critical index of p. For j \u2208 [0, k] we have\nn\nP\n\ni=j+1\n\nInf i (p) \u2264 (1 \u2212 \u03c4 )j * Inf(p).\n\nProof.\nsince j is at most k, we have that Inf j (p) \u2265 \u03c4 *\nPn The lemma trivially holds\nPn for j = 0. In general,P\nn\ni=j Inf i (p), or equivalently\ni=j+1 Inf i (p) \u2264 (1\u2212\u03c4 )*\ni=j Inf i (p) which yields the claimed bound.\n\nB.2\n\nProof of Lemma 2\n\nTo prove Lemma 2, we first recall an observation about the expected value of Fourier coefficients under\nrandom restrictions (see e.g. [LMN93]):\nFact 14. Let p : {\u22121, 1}n \u2192 R. Consider\na random assignment \u03c1 to the variables xP\n1 , . . . , xk . Fix any\nP\nS \u2286 [k + 1, n]. Then we have pb\u03c1 (S) = T \u2286[k] pb(S \u222a T )\u03c1T and therefore E\u03c1 [pb\u03c1 (S)2 ] = T \u2286[k] pb(S \u222a T )2 .\n14\n\n\fIn words, the above fact says that all the Fourier weight on sets of the form S \u222a {any subset of restricted\nvariables} \"collapses\" down onto S in expectation. Consequently, the influence of an unrestricted variable\ndoes not change in expectation under random restrictions:\nLemma 2. Let p : {\u22121, 1}n \u2192 R. Consider a random assignment \u03c1 to the variables x1 , . . . , xk and fix\nl \u2208 [k + 1, n]. Then E\u03c1 [Inf l (p\u03c1 )] = Inf l (p).\nProof. We have\nE\u03c1 [Inf l (p\u03c1 )] = E\u03c1\n=\n\n\u0002\n\nP\n\nl\u2208S\u2286[k+1,n]\n\nP\n\nl\u2208U \u2286[n]\n\nB.3\n\n2\n\n\u0003\nP\npb\u03c1 (S)2 =\n\nP\n\nT \u2286[k] l\u2208S\u2286[k+1,n]\n\npb(U ) = Inf l (p).\n\npb(S \u222a T )2\n\nProof of Claim 9\n\nRecall Claim 9:\nClaim 9. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial. Let \u03c1 be a random restriction fixing [j].\nFix any t > e2d and any l \u2208 [j + 1, n]. With probability at least 1 \u2212 exp(\u2212\u03a9(t1/d )) over \u03c1, we have\nInf l (p\u03c1 ) \u2264 3d tInf l (p).\nP\nProof. The identity Inf l (p\u03c1 ) = l\u2208S\u2286[j+1,n] pb\u03c1 (S)2 and Fact 14 imply that Inf l (p\u03c1 ) is a degree-2d polynomial in \u03c1. Hence the claim follows from the concentration bound, Theorem 6, assuming we can appropriately\nupper bound the l2 norm of the polynomial Inf l (p\u03c1 ). So to prove Claim 9 it suffices to show that\nkInf l (p\u03c1 )k2 \u2264 3d Inf l (p).\n\n(8)\n\nThe proof of Equation (8) is similar to the argument establishing that kQk2 \u2264 3d de\u2212\u03b1 in Section 2.1.\nThe triangle inequality tells us that we may bound the l2 -norm of each squared-coefficient separately:\nP\nkb\np\u03c1 (S)2 k2 .\nkInf l (p\u03c1 )k2 \u2264\nl\u2208S\u2286[j+1,n]\n\nSince pb\u03c1 (S) is a degree-d polynomial, Theorem 5 yields that\n\nkb\np\u03c1 (S)2 k2 = kb\np\u03c1 (S)k24 \u2264 3d kb\np\u03c1 (S)k22 ,\n\nhence\nkInf l (p\u03c1 )k2 \u2264 3d\n\nP\n\nl\u2208S\u2286[j+1,n]\n\nkb\np\u03c1 (S)k22 = 3d Inf l (p),\n\nwhere the last equality is a consequence of Fact 14. Thus Equation (8) holds, and Claim 9 is proved.\n\n15\n\n\fB.4\n\nProof of Lemma 11\n\nRecall Lemma 11:\nLemma 11. Let p : {\u22121, 1}n \u2192 R be a degree-d polynomial and 0 < \u03c4e, \u03b2 < 1/2. Fix \u03b1 = \u0398(d log log(1/\u03b2)+\nd log d) and \u03c4e\u2032 = \u03c4e * (C \u2032 d ln d ln(1/e\n\u03c4 ))d , where C \u2032 is a universal constant. (We assume w.l.o.g. that the\nvariables are ordered s.t. Inf i (p) \u2265 Inf i+1 (p), i \u2208 [n \u2212 1].) One of the following statements holds true:\n1. The polynomial p is \u03c4e-regular.\n\n2. With probability at least 1/(2C d ) over a random restriction \u03c1 fixing the first \u03b1/e\n\u03c4 (most influential)\nvariables of p, the function sign(p\u03c1 ) is \u03b2-close to a constant function.\n3. There exists a value k \u2264 \u03b1/e\n\u03c4 , such that with probability at least 1/(2C d ) over a random restriction\n\u03c1 fixing the first k (most influential) variables of p, the polynomial p\u03c1 is \u03c4e\u2032 -regular.\n\nProof. The proof is by a case analysis based on the value l of the \u03c4e-critical index of the polynomial p. If\nl = 0, then by definition p is \u03c4e-regular, hence the first statement of the lemma holds. If l > \u03b1/e\n\u03c4 , then we\nrandomly restrict the first \u03b1/e\n\u03c4 many variables. Lemma 3 says that for a random restriction \u03c1 fixing these\nvariables, with probability at least 1/(2C d ) the (restricted) degree-d PTF sign(p\u03c1 ) is \u03b2-close to a constant.\nHence, in this case, the second statement holds. To handle the case l \u2208 [1, \u03b1/e\n\u03c4 ], we apply Lemma 6.\nThis lemma says that with probability at least 1/(2C d ) over a random restriction \u03c1 fixing variables [l], the\npolynomial p\u03c1 is \u03c4e\u2032 -regular, so the third statement of Lemma 11 holds.\n\nC\n\nComparison with [MZ09]\n\nWe comment on the relation of our main result, Theorem 1, with a very similar decomposition result of\nMeka and Zuckerman [MZ09]. They obtain a small-depth decision tree such that most leaves are \u01eb-close to\nbeing \u01eb-regular under a stronger definition of regularity, which we will call \"\u01eb-regularity in l2 \" to distinguish\nit from our notion.\nLet p : {\u22121, 1}n \u2192 R be a polynomial and \u01eb > 0. We say that the polynomial p is \"\u01eb-regular in l2 \" if\nv\nu n\nn\nX\nuX\n2\nt\nInf i (p).\nInf i (p) \u2264 \u01eb *\ni=1\n\ni=1\n\nRecall that in our definition of regularity, instead of upper bounding the l2 -norm of the influence vector\nI = (Inf 1 (p), . . . , Inf n (p)) by \u01eb times the total influence of p (i.e. the l1 norm of I), we upper bound the l\u221e\nnorm (i.e. the maximum influence). We may thus call our notion \"\u01eb-regularity in l\u221e \".\nNote that if a polynomial is \u01eb-regular in l2 , then it is also \u01eb-regular in l\u221e . (And this implication is\neasily seen to be essentially tight, e.g. if we have many variables with tiny influence and one variable with\nan \u01eb-fraction of the total influence.) For the other direction, if a polynomial is \u01eb-regular in l\u221e , then it is\n\u221a\n\u01eb-regular in l2 . (This is also tight if we have 1/\u01eb many variables with influence \u01eb.)\nMeka and Zuckerman prove the following statement:\nEvery degree-d PTF f = sign(p) can be expressed as a decision tree of depth 2O(d) *(1/\u01eb2 ) log2 (1/\u01eb)\nwith variables at the internal nodes and a degree-d PTF f\u03c1 = sign(p\u03c1 ) at each leaf \u03c1, such that\nwith probability 1\u2212\u01eb, a random root-to-leaf path reaches a leaf \u03c1 such that f\u03c1 is \u01eb-close to being\n\u01eb-regular in l2 . (In particular, for a \"good\" leaf \u03c1, either p\u03c1 will be \u01eb-regular in l2 or f\u03c1 will be\n\u01eb-close to a constant).\n16\n\n\fTheorem 1 shows exactly the same statement as the one above if we replace \"l2 \" by \"l\u221e \" and the depth of\nthe tree by (1/\u01eb) * (d log(1/\u01eb))O(d) .\nSince \u01eb-regularity in l2 implies \u01eb-regularity in l\u221e , the result of [MZ09] implies a version of Theorem 1\nwhich has depth of 2O(d) *(1/\u01eb2 ) log2 (1/\u01eb). Hence the [MZ09] result and our result are quantitatively incomparable to each other. Roughly, if d is a constant (independent of \u01eb), then our Theorem 1 is asymptotically\nbetter when \u01eb becomes small. This range of parameters is quite natural in the context of pseudo-random generators. In particular, in the recent proof that poly(1/\u01eb)-wise independence \u01eb-fools degree-2 PTFs [DKN09],\nusing [MZ09] instead of Theorem 1, would give a worse bound on the degree of independence (namely,\ne \u221218 ) as opposed to O(\u01eb\ne \u22129 )). On the other hand, if d = \u03a9(log(1/\u01eb)),\ne\nO(\u01eb\nthen the result of [MZ09] is better.\n\nD\n\nOmitted Proofs from Section 3\n\nD.1 Proof of Claim 13\nClaim 13. Let p : {\u22121, 1}n \u2192 R be a \u03c4 -regular degree-d polynomial with Var[p] = 1. Then Prx [|p(x)| \u2264\n\u03c4 ] \u2264 O(d\u03c4 1/8d ).\nProof. We recall that, since Var[p] = 1 and p is of degree d, it holds Inf(p) \u2264 d. Thus, since p is \u03c4 -regular,\nwe have that maxi\u2208[n] Inf i (p) \u2264 d\u03c4. An application of the invariance principle (Theorem 9) in tandem with\nanti-concentration in gaussian space (Theorem 8) yields\nPrx [|p(x)| \u2264 \u03c4 ] \u2264 O(d * (d\u03c4 )1/8d ) + PrG\u223cN n [|p(G)| \u2264 \u03c4 ]\n\u2264 O(d\u03c4 1/8d ) + O(d\u03c4 1/d ) = O(d\u03c4 1/8d ),\n\nand the claim follows.\n\nD.2 Proof of Lower Bound Theorems 3 and 4\nTheorems 3 and 4 are both consequences of the following theorem:\nTheorem 10. There exists a set C = {f1 , . . . , fM } of M = 2\u03a9d (n\n1 \u2264 i < j \u2264 M , we have dist(fi , fj ) \u2265 C \u2212d .\n\nd)\n\ndegree-d PTFs fi such that for any\n\nProof of Theorems 3 and 4 assuming Theorem 10: First we prove Theorem 3. We begin by claiming that\n\u0010\n\u0001\u0011A\nn\nthere are at most 3 \u2264K(d)\nmany integer-weight PTFs of degree K(d) and weight at most A. This is\nbecause any such PTF can be obtained\nby making a sequence of A steps, where at each step either \u22121, 0, or\nn \u0001\n1 is added to one of the \u2264K(d) many monomials of degree at most K(d). Each step can be carried out in\n\u0001\nn\n3 \u2264K(d)\nways, giving the claimed bound.\nBy Theorem 10, there are M distinct degree-d PTFs f1 , . . . , fM any two of which are C \u2212d -far from\neach other. Consequently any Boolean function (in particular, any weight-A degree-K(d) PTF g) can have\n\u0011A\n\u0010\nn \u0001\ndist(g, fi ) \u2264 C \u2212d /2 for at most one fi . Since there are only 3 \u2264K(d)\nmany weight-A degree-K(d)\n\u0011A\n\u0010\n\u0001\nn\nPTFs, and 3 \u2264K(d)\nis less than M for some A = \u03a9d (nd / log n), it follows that some fi must have\n\ndistance at least C \u2212d /2 from every weight-A, degree-K(d) PTF. This gives Theorem 3.\nThe proof of Theorem 4 is nearly identical. We now use the fact that there are at most (3 * 2n )A many\ninteger-weight PTFs of weight at most A (and any degree), and use the fact that (3 * 2n )A is less than M for\nsome A = \u03a9d (nd\u22121 ).\nIt remains to prove Theorem 10.\n17\n\n\fD.2.1 Proof of Theorem 10\nThe proof is by the probabilistic P\nmethod. We define the following distribution D over n-variable degree-d\npolynomials. A draw of p(x) = S\u2282[n],|S|=d pb(S)\u03c7S (x) from D is obtained in the following way: each of\n\u0001\nthe nd coefficients pb(S) is independently and uniformly selected from {\u22121, 1}.\nWe will prove Theorem 10 using Lemma 15, which says that it is extremely likely the polynomial c \u2013\nthe product of two independent draws a and b from D \u2013 will have both small bias and large variance.\nLemma 15. Let a(x) and b(x) be two degree-d polynomials drawn independently from D, and let c(x) =\nd\na(x)b(x). Then with probability at least 1 \u2212 2\u2212\u03a9d (n ) we have:\n\u0001\n1. |b\nc(\u2205)| \u2264 14 C \u2212d n/2\nd , and\ndef\n\n2. Var[c] =\n\nP\n\nc(S)2\n|S|>0 b\n\n\u2265\n\n\u0001\n1 n/2 2\n.\n12 d\n\nSuppose that Lemma 15 holds. Let a(x) and b(x) be independent draws from D and let c(x) = a(x)b(x)\nwhich satisfies the conclusions of the lemma. Then the constant term b\nc(\u2205) is small compared with the\nvariance of c(x). Let us rescale so the variance is 1; i.e. define the polynomial\ndef\n\ne(x) =\n\nc(x)\nVar[c]1/2\n\nso Var[e] = 1 and |b\ne(\u2205)| < C \u2212d . We now apply Theorem 7 to the degree-2d polynomial q(x) = \u2212e(x) +\neb(\u2205), and we see that with probability at least C \u2212d (over a random uniform draw of x) we have \u2212e(x) +\neb(\u2205) > C \u2212d , and hence Prx [sign(e(x)) < 0] > C \u2212d .\nWe now observe that sign(e(x)) < 0 if and only if sign(a(x)) 6= sign(b(x)), and consequently\nPrx [sign(e(x)) < 0] is precisely dist(sign(a), sign(b)). We thus have that for a(x), b(x) drawn from\nd\nD as described above, the probability that dist(sign(a), sign(b)) is less than C \u2212d is at most 2\u2212\u03b1d n for\nsome absolute constant \u03b1d > 0 (depending only on d).\nd\nNow let us consider M = 2\u0001(\u03b1d /2)n many independent draws of polynomials a1 , a2 , . . . , aM from D.\nd\nA union bound over all the M\n< 2\u03b1d n pairs (i, j) with 1 \u2264 i < j \u2264 M gives that with nonzero\n2\nprobability, every ai , aj pair satisfies dist(sign(ai ), sign(aj )) \u2265 C \u2212d . Thus there must be some outcome\nfor the polynomials a1 , a2 , . . . , aM such that dist(sign(ai ), sign(aj )) \u2265 C \u2212d for all 1 \u2264 i < j \u2264 M.\nSetting fi = sign(ai ) for this outcome, Theorem 10 is proved.\nIt remains only for us to prove Lemma 15.\nD.2.2 Proof of Lemma 15\nP\nP\nLet us consider a(x) = |S|=d b\na(S)\u03c7S (x) and b(x) = |S|=d bb(S)\u03c7S (x) drawn independently from D.\nWe will show that the bias of the polynomial c(x) = a(x)b(x) fails to satisfy the bound in item 1 with\nd\nd\nprobability 2\u2212\u03a9d (n ) . Then we show the variance of c fails to satisfy item 2 with probability 2\u2212\u03a9d (n ) , and\nthe lemma follows from a union bound.\nTo bound the bias of c, we begin by noting that:\nX\nc(\u2205) =\nb\nb\na(S)bb(S).\nS\u2286[n]\n\nEach term b\na(S)bb(S) inP\nthe summand is uniform, i.i.d in {\u22121, 1}. Define the random variable XS = 1/2 \u2212\nn d\nb\n) , we may apply the\n(1/2)b\na(S)b(S). Then S\u2286[n] XS is binomially distributed and setting t = 41 C \u2212d ( 2d\n18\n\n\fChernoff bound to obtain:\n1\nn\nt2\nd\nPr[b\nc(\u2205) < \u2212 C \u2212d ( )d ] = Pr[X > E[X] + t] \u2264 exp (\u22122 n\u0001 ) = 2\u2212\u03a9d (n )\n4\n2d\nd\n\n\u0001\nn d\n) , this\nThe same analysis gives a bound on the magnitude in the negative direction. Since n/2\n\u2265 ( 2d\nd\nconcludes the analysis for the first item of the lemma.\nNow we show that item 2 of the lemma also fails with very small probability. The following terminology\nwill be useful. Let T \u2282 [n] be a subset of size exactly |T | = 2d (we think of T as the set of variables defining\ndef\n\ndef\n\nsome monomial of degree 2d). For such a T we let first(T ) = T \u2229[n/2] and second(T ) = T \u2229[n/2+1, n].\n\u00012\nWe say that such a T is balanced if |first(T )| = |second(T )| = d. Note that there are exactly n/2\nmany\nd\nbalanced subsets T .\nWe say that a subset U \u2282 [n], |U | = d is pure if U is contained entirely in [n/2 + 1, n].\nP\nP\nLet us consider a(x) = |S|=d b\na(S)\u03c7S (x) and b(x) = |S|=d b\nb(S)\u03c7S (x) drawn independently from\n\u0001\nn\nD. Fix any outcome for a (i.e. for the values of all d coefficients b\na(S)), and fix any outcome for b\nb(U )\nfor every U which is not pure. \u0001Thus the only \"remaining randomness\" is the value (drawn uniformly from\n{\u22121, 1}}) for each of the n/2\ncoefficients bb(U ) for pure U. We will show that with probability at least\nd\n\u00012\nd\nn/2\u00012\nof\nthe\nmany balanced subsets T have\n1 \u2212 2\u2212\u03a9d (n ) over the remaining randomness, at least 61 n/2\nd\nd\nb\nc(T ) 6= 0. Since each value b\nc(T ) which is nonzero is at least 1 in magnitude, this suffices to prove the\nlemma.\nConsider any fixed pure subset U \u2282 [n], |U | = d (for example U = {n \u2212 d + 1, . . . , n}). Let T be\n\u0001\na balanced subset of n (so |T | = 2d) such that second(T ) equals U . (There are precisely n/2\nbalanced\nd\nn/2\u0001\nsubsets T with this property; let TU denote the collection of all d of them.) Consider the value b\nc(T ):\nthis is\nX\nc(T ) =\nb\nb\na(S)bb(T \u2212 S).\nS\u2286T,|S|=d\n\nThe only \"not-yet-fixed\" part of the above expression is the single coefficient bb(U ); everything else has been\nfixed. Since the coefficient b\na(T \u2212 U ) of b\nb(U ) is a nonzero integer, there are two possible outcomes for\nb\nthe value of b\nc(T ), depending on whether b(U ) is set to +1 or -1. These two possible values differ by 2;\nconsequently, there is at most one possible outcome of bb(U ) that will cause b\nc(T ) to be zero. (Note that it\nmay well be the case that no outcome for b\nb(U ) would cause b\nc(T ) to become zero.)\n\u0001\nof the\nLet us say that an outcome of b\nb(U ) is pernicious if it has the following property: at most 13 n/2\nd\nn/2\u0001\nb\nTU have b\nc(T ) take a nonzero value under that outcome of b(U ). (Equivalently, at least\nd \u0001elements T \u2208\nn/2\u0001\n2 n/2\nof the d elements T \u2208 TU have b\nc(T ) become zero under that outcome of bb(U ).) It may be the\n3 d\ncase that neither outcome in {\u22121, 1} for bb(U ) is pernicious (e.g. if each outcome makes at least 95% of the\nb\nc(T ) values come out nonzero). It cannot be the case that both outcomes {\u22121, 1} for bb(U ) are pernicious\nc(T ) values evaluate to\n(for if there were two pernicious outcomes, this would mean that at least 31 of the b\nb\n0 under both outcomes for b(U ), but it is impossible for any b\nc(T ) to evaluate to 0 under two outcomes for\nbb(U )). Consequently we have\nPr[the outcome of bb(U ) is pernicious] \u2264 1/2.\n\n\u0001\nThis is true independently for each of the n/2\nmany pure subsets U. As a result, a simple analysis gives\nd\n\u0012\n\u0013\nn/2\nd\nPr[at least 3/4 of the\npure subsets U have a pernicious outcome] \u2264 2\u2212\u03a9d (n ) .\nd\n19\n\n\f\u0001\nThus we may assume that fewer than 3/4 of the n/2\npure subsets U have a pernicious outcome. So at\nd\n\u0001\n\u0001\n1 n/2\nleast 4 d of the pure subsets U are non-pernicious. For each such non-pernicious U , more than 13 n/2\nd\n\u0001\n\u0001\n1 n/2 2\nmany balanced\nof the n/2\nelements\nin\nT\nhave\nb\nc\n(T\n)\ntake\na\nnonzero\nvalue.\nConsequently,\nat\nleast\nU\n12 d\nd\nsubsets T overall have b\nc(T ) 6= 0. This proves the lemma.\n\n20\n\n\f"}