{"id": "http://arxiv.org/abs/0812.1194v1", "guidislink": true, "updated": "2008-12-05T18:50:20Z", "updated_parsed": [2008, 12, 5, 18, 50, 20, 4, 340, 0], "published": "2008-12-05T18:50:20Z", "published_parsed": [2008, 12, 5, 18, 50, 20, 4, 340, 0], "title": "Adversarial Scheduling in Evolutionary Game Dynamics", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0812.0029%2C0812.4408%2C0812.2200%2C0812.3910%2C0812.4487%2C0812.2528%2C0812.2425%2C0812.3827%2C0812.1434%2C0812.2889%2C0812.3905%2C0812.0492%2C0812.4291%2C0812.0184%2C0812.0791%2C0812.4325%2C0812.0003%2C0812.4784%2C0812.0346%2C0812.4924%2C0812.0207%2C0812.0512%2C0812.3710%2C0812.4280%2C0812.0138%2C0812.4318%2C0812.3383%2C0812.1194%2C0812.3183%2C0812.3067%2C0812.1288%2C0812.3950%2C0812.1687%2C0812.0636%2C0812.0604%2C0812.2179%2C0812.2760%2C0812.1068%2C0812.1203%2C0812.4955%2C0812.4284%2C0812.2413%2C0812.3936%2C0812.1574%2C0812.1784%2C0812.2906%2C0812.0600%2C0812.0529%2C0812.3746%2C0812.3142%2C0812.0500%2C0812.4329%2C0812.3840%2C0812.4165%2C0812.2228%2C0812.2995%2C0812.1787%2C0812.1523%2C0812.0333%2C0812.2194%2C0812.4200%2C0812.1620%2C0812.3361%2C0812.3464%2C0812.1124%2C0812.3851%2C0812.0787%2C0812.2271%2C0812.4020%2C0812.2801%2C0812.3496%2C0812.2187%2C0812.3440%2C0812.1513%2C0812.4121%2C0812.1886%2C0812.1692%2C0812.1625%2C0812.4163%2C0812.3233%2C0812.2842%2C0812.0533%2C0812.0060%2C0812.2584%2C0812.2468%2C0812.1131%2C0812.1009%2C0812.4998%2C0812.2762%2C0812.3736%2C0812.0377%2C0812.4331%2C0812.4134%2C0812.0749%2C0812.4695%2C0812.2642%2C0812.4419%2C0812.1739%2C0812.5097%2C0812.1107%2C0812.3677&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Adversarial Scheduling in Evolutionary Game Dynamics"}, "summary": "Consider a system in which players at nodes of an underlying graph G\nrepeatedly play Prisoner's Dilemma against their neighbors. The players adapt\ntheir strategies based on the past behavior of their opponents by applying the\nso-called win-stay lose-shift strategy. This dynamics has been studied in\n(Kittock 94), (Dyer et al. 2002), (Mossel and Roch, 2006).\n  With random scheduling, starting from any initial configuration with high\nprobability the system reaches the unique fixed point in which all players\ncooperate. This paper investigates the validity of this result under various\nclasses of adversarial schedulers. Our results can be sumarized as follows:\n  1. An adversarial scheduler that can select both participants to the game can\npreclude the system from reaching the unique fixed point on most graph\ntopologies. 2. A nonadaptive scheduler that is only allowed to choose one of\nthe participants is no more powerful than a random scheduler. With this\nrestriction even an adaptive scheduler is not significantly more powerful than\nthe random scheduler, provided it is \"reasonably fair\".\n  The results exemplify the adversarial scheduling approach we propose as a\nfoundational basis for the generative approach to social science (Epstein\n2007).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0812.0029%2C0812.4408%2C0812.2200%2C0812.3910%2C0812.4487%2C0812.2528%2C0812.2425%2C0812.3827%2C0812.1434%2C0812.2889%2C0812.3905%2C0812.0492%2C0812.4291%2C0812.0184%2C0812.0791%2C0812.4325%2C0812.0003%2C0812.4784%2C0812.0346%2C0812.4924%2C0812.0207%2C0812.0512%2C0812.3710%2C0812.4280%2C0812.0138%2C0812.4318%2C0812.3383%2C0812.1194%2C0812.3183%2C0812.3067%2C0812.1288%2C0812.3950%2C0812.1687%2C0812.0636%2C0812.0604%2C0812.2179%2C0812.2760%2C0812.1068%2C0812.1203%2C0812.4955%2C0812.4284%2C0812.2413%2C0812.3936%2C0812.1574%2C0812.1784%2C0812.2906%2C0812.0600%2C0812.0529%2C0812.3746%2C0812.3142%2C0812.0500%2C0812.4329%2C0812.3840%2C0812.4165%2C0812.2228%2C0812.2995%2C0812.1787%2C0812.1523%2C0812.0333%2C0812.2194%2C0812.4200%2C0812.1620%2C0812.3361%2C0812.3464%2C0812.1124%2C0812.3851%2C0812.0787%2C0812.2271%2C0812.4020%2C0812.2801%2C0812.3496%2C0812.2187%2C0812.3440%2C0812.1513%2C0812.4121%2C0812.1886%2C0812.1692%2C0812.1625%2C0812.4163%2C0812.3233%2C0812.2842%2C0812.0533%2C0812.0060%2C0812.2584%2C0812.2468%2C0812.1131%2C0812.1009%2C0812.4998%2C0812.2762%2C0812.3736%2C0812.0377%2C0812.4331%2C0812.4134%2C0812.0749%2C0812.4695%2C0812.2642%2C0812.4419%2C0812.1739%2C0812.5097%2C0812.1107%2C0812.3677&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Consider a system in which players at nodes of an underlying graph G\nrepeatedly play Prisoner's Dilemma against their neighbors. The players adapt\ntheir strategies based on the past behavior of their opponents by applying the\nso-called win-stay lose-shift strategy. This dynamics has been studied in\n(Kittock 94), (Dyer et al. 2002), (Mossel and Roch, 2006).\n  With random scheduling, starting from any initial configuration with high\nprobability the system reaches the unique fixed point in which all players\ncooperate. This paper investigates the validity of this result under various\nclasses of adversarial schedulers. Our results can be sumarized as follows:\n  1. An adversarial scheduler that can select both participants to the game can\npreclude the system from reaching the unique fixed point on most graph\ntopologies. 2. A nonadaptive scheduler that is only allowed to choose one of\nthe participants is no more powerful than a random scheduler. With this\nrestriction even an adaptive scheduler is not significantly more powerful than\nthe random scheduler, provided it is \"reasonably fair\".\n  The results exemplify the adversarial scheduling approach we propose as a\nfoundational basis for the generative approach to social science (Epstein\n2007)."}, "authors": ["Gabriel Istrate", "Madhav V. Marathe", "S. S. Ravi"], "author_detail": {"name": "S. S. Ravi"}, "author": "S. S. Ravi", "links": [{"href": "http://arxiv.org/abs/0812.1194v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0812.1194v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0812.1194v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0812.1194v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Adversarial Scheduling in Evolutionary Game\nDynamics\n\narXiv:0812.1194v1 [cs.DM] 5 Dec 2008\n\nGabriel Istrate1\u22c6 , Madhav V. Marathe2 , and S.S. Ravi3\n1\n\n2\n\ne-Austria Institute, V.P\u00e2rvan 4, cam. 045B, Timi\u015foara RO-300223, Romania\nNetwork Dynamics and Simulation Science Laboratory, Virginia Tech, 1880 Pratt\nDrive Building XV, Blacksburg, VA 24061. Email: mmarathe@vbi.vt.edu\n3\nComputer Science Dept., S.U.N.Y. at Albany, Albany, NY 12222, U.S.A.\nEmail:ravi@cs.albany.edu\n\nAbstract. Consider a system in which players at nodes of an underlying\ngraph G repeatedly play Prisoner's Dilemma against their neighbors.\nThe players adapt their strategies based on the past behavior of their\nopponents by applying the so-called win-stay lose-shift strategy. This\ndynamics has been studied in [Kit94,DGG+ 02,MR06].\nWith random scheduling, starting from any initial configuration with\nhigh probability the system reaches the unique fixed point in which all\nplayers cooperate. This paper investigates the validity of this result under\nvarious classes of adversarial schedulers. Our results can be summarized\nas follows:\n\u2013 An adversarial scheduler that can select both participants to the\ngame can preclude the system from reaching the unique fixed point\non most graph topologies.\n\u2013 A nonadaptive scheduler that is only allowed to choose one of the\nparticipants is no more powerful than a random scheduler. With\nthis restriction even an adaptive scheduler is not significantly more\npowerful than the random scheduler, provided it is \"reasonably fair\".\nThe results exemplify the adversarial scheduling approach we propose as\na foundational basis for the generative approach to social science [Eps07].\n\nKeywords: evolutionary games, self stabilization, discrete dynamical systems, adversarial analysis\n\n1\n\nIntroduction\n\nEvolutionary game theory [Wei95] and agent-based simulation in the social sciences [BW00,TJ06,GT05] share the object of study and a significant set of concerns, and are largely distinguished only by the method of choice (mathematical\nreasoning versus computational experiments). In particular, the two areas deal\nwith fairly similar models (see, e.g. [Wil06,BEM05]). A particular class of such\nmodels assumes a large population of agents located at the vertices of a graph.\n\u22c6\n\ncorresponding author. Email: gabrielistrate@acm.org\n\n\fAgents interact by playing a fixed game, and update their behavior based on the\noutcome of this interaction (according to a pre-specified rule).\nHow does one interpret properties of such systems, be they obtained through\nmathematical analysis or computational simulations ? A possible answer is that\nresults characterizing dynamical properties of such models provide insights (and\npossible explanations) for features observed in \"real-world\" social dynamics. For\ninstance, the primary intuition behind the concept of stochastically stable strategies in evolutionary game theory is that a small amount of \"noise\" (or, equivalently, small deviations from rationality) in game dynamics can solve the equilibrium selection problem, by focusing the system on one particular equilibrium.\nSimilarly, in agent-based social theory, Epstein [Eps07,Eps99] (see also [AE96])\nhas advocated a generative approach to social science. The goal is to explain a\ngiven social phenomenon by generating it using multiagent simulations4 . Related\nconcerns have been recently voiced throughout analytical social science, with a\nparticular emphasis on mechanism-based explanations [Hed05,HS06].\nGiven that game theory and agent-based simulation are emerging as tools\nfor guiding political decision-making (see e.g. [BEM05,ECC+ 04,EGK+ 04,TRA]),\nit is important to make sure that the conclusions that we derive from these\ntechniques are robust to small variations in model specification5 .\nIn this paper we consider the effect of one particular factor that can affect the\nrobustness of results of agent-based simulations and evolutionary game theory:\nagent scheduling, i.e. the order in which agents get to update their strategies.\nMany models in the literature assume one of two popular alternatives:\n\u2013 synchronous update: every player can update at every moment (in either\ndiscrete or continuous time); this is the model implicitly used by \"large\npopulation\" models in evolutionary game theory.\n\u2013 uniform matching: agents are vertices of a (hyper)graph. At each step we\nchoose a (hyper)edge uniformly at random and all players corresponding to\nthis hyperedge are updated using the local update function.\nInstead of postulating one of these two update mechanisms, we advocate\nthe study of social dynamics under an approach we call adversarial scheduling.\nWe exemplify adversarial scheduling by studying, in such a setting, the Iterated\nPrisoners' Dilemma game with win-stay lose-shift strategy. This dynamics (originally motivated by the colearning model in [ST94]) have received substantial\nattention in the game-theoretic literature[Kit94,DGG+ 02,MR06].\nWe are, of course, far from being the first researchers to recognize the crucial role of scheduling/activation order on the properties of social dynamics (to\n4\n\n5\n\ncf. [Eps07], Chapter 1: \"if you didn't grow it [the social phenomenon, n.n.], you\ndidn't explain its emergence\".\nThe importance of stability has been previously recognized in the literature, for instance, in [AE96] (pp. 35), where emergent phenomena are defined as \"stable macroscopic patterns arising from local of interaction of agents\".\n\n\fonly give two examples, see [HG93,Axt00]). However, what we advocate is a\n(somewhat) more systematic approach, based on the following principles:\n(i) Start with a \"base case\" result P , stated under a particular scheduling model.\n(ii) Identify several structural properties of the scheduling model that impact the\nvalidity of P . Ideally, these properties should be selected by careful examination of the proof of P , which should reveal their importance.\n(iii) Identify those properties (or combinations of properties) that are necessary/sufficient for the validity of P . Correspondingly, identify properties\nthat that are inconsequential to the validity of P .\n(iv) The process outlined so far can continue by recursively applying steps (i)(iii). In the process we may need to reformulate the original statement in\na way that makes it hold under larger classes of schedulers, thus making it\nmore robust. The precise reformulation(s) normally arise from inspecting the\ncases when the proof of P fails in an adversarial setting.\nThe intended benefits of the adversarial scheduling approach are multiple\n(see [Ist06] for further discussions). The aim of this paper is to show that these\nbenefits do not come at the expense of mathematical tractability: at least for\none nontrivial dynamics, adversarial scheduling (as outlined in the five point\napproach above) is feasible and can lead to interesting results.\n\n2\n\nPreliminaries\n\nFirst we define two classes of graphs that we will frequently consider in this\npaper. The line graph Ln , n \u2265 1 consists of n vertices v1 , . . . vn and edges\n(vi , vi+1 ), 1 \u2264 i \u2264 n \u2212 1. We will use Line to denote the set of all line graphs.\nA star graph Starn , n \u2265 1, is the complete bipartite graph K1,n . We will use\nStar to denote the set of all star graphs.\n2.1\n\nBasic Model: Prisoner's Dilemma with Pavlov dynamics\n\nNext we describe the basic mathematical model for Prisoner's Dilemma with\nPavlov dynamics; see [Kit94,MR06,DGG+ 02] for additional discussion. We are\ngiven an undirected graph G(V, E), |V | = n and |E| = m. Each vertex v \u2208 V\nrepresents an agent. Each agent has a label from the set {0, 1}. These labels\ndenote the strategies that the players follow: 0 can also be equivalently viewed\nas cooperation and 1 can be viewed as defection. Without loss of generality, we\nassume that G is connected, otherwise the dynamics will reduce to independent\ndynamics on the connected components of G. We will also assume that the graph\ncontains at least two edges.\nTime will be discrete. At time t = 0 all nodes are assigned a label from {0, 1}.\nAt each subsequent step, certain nodes/agents change their label (strategy) according to the rules given below. We will use xt (v) to denote the label of node\n\n\fv. At each step t + 1 an edge e = (u, v) is selected according to some rule and\nthe states of u and v are updated as follows:\nx(t+1) (u) \u2190 (xt (u) + xt (v)) (mod 2)\nx(t+1) (v) \u2190 (xt (u) + xt (v)) (mod 2)\nWe will use Xt to denote the vector (xt (v1 ), . . . xt (vn )) representing the states of\nthe nodes v1 , . . . vn . This will be sometimes referred to as the global configuration.\nSometime we will omit the subscript t for ease of exposition and its value will\nbe clear from context. With this terminology, each step of the dynamics can be\nviewed as a global update function F . It takes as input an element e = (vi , vj ) \u2208\nE, X = (x(v1 ), . . . x(vn )) and returns the next global Y = (y(v1 ), . . . y(vn ))\ngiven as follows: \u2200vk , s.t. k 6= i and k 6= j, y(vk ) = x(vk ); and y(vi ) = y(vj ) =\n(x(vi )+x(vj )) (mod 2). In this case Y is said to be reachable from X in one step.\nA global configuration X is said to be a fixed point if \u2200e \u2208 E, F (X, e) = X.\nIt is easy to see the dynamical system studied here has a unique fixed point\n0 = (0, . . . , 0). Following dynamical systems literature, a configuration X is\ncalled a Garden of Eden configuration if the configuration is not reachable from\nany other configuration. For the rest of this paper, we will use X, Y, . . . to\ndenote global configurations. An instance of the Prisoner's Dilemma with Pavlov\ndynamics (PDPD) can thus be represented as a (G, f ), where G is the underlying\ninteraction graph and f is the local function associated with each node. In the\nremainder of this paper, since f is always fixed, an instance will be specified\nsimply by G.\n2.2\n\nThe base-case result\n\nThe following property of the PDPD is easily seen to hold under random matching: for all interaction graphs G with no isolated vertices the system converges\nwith probability 1 \u2212 o(1) to the \"all zeros\" configuration (henceforth denoted 0)\nWith a slight abuse of convention, we will refer to this event as self-stabilization.\nThis will the statement we will aim to study in an adversarial setting.\nWe will also be interested in the convergence time of the dynamics. Under\nrandom scheduling Dyer et al. [DGG+ 02] prove that the number of steps needed\nto self-stabilize is O(n log n) on Cn (the simple cycle on n nodes) and exponential\nin n on Kn (the complete graph on n nodes). The convergence time was further\ninvestigated by Mossel and Roch [MR06].\n2.3\n\nTypes of scheduler\n\nA schedule S is specified as an infinite string over E, i.e. S \u2208 E \u2217 . Given a schedule\nS = (e1 , e2 , . . . , et , . . .), the graph G and an initial configuration I, the dynamics\nof the system evolve as follows. At time t = 0 the system is in state I. At time\nt, we pick the tth edge from S. Call this edge et . If the configuration at the\n\n\fbeginning of time t is X then the configuration Y at the beginning of time t + 1\nis given by Y \u2190 F (X, et ). The iterated global transition function F \u2217 is defined\nas\nF \u2217 (I, (e1 , e2 , . . . , et , . . .)) \u2261 F \u2217 (F (I, e1 ), (e2 , . . . , et , . . .))\nWe say that a system G self stabilizes for a given initial configuration I\nand a schedule S = (e1 , . . . , et , . . .)6 if \u2203t \u2265 1 such that the system starting in I reaches the (unique fixed point) configuration 0 after t time steps, i.e.\n0 \u2190 F (I, (e1 , . . . , et )). G is said to self stabilize for a schedule S if G eventually reaches a fixed point when started at any initial configuration I, i.e.\n\u2200I, F (I, S) \u2192 0. Conversely, a schedule S can preclude self stabilization of\nG if \u2203I such that F (I, S) does not ever reach 0. Given a set of schedules, a\nscheduler is simply an algorithm (possibly randomized) that chooses a schedule.\nThe schedulers considered here are all polynomial time algorithms and the set\nof feasible schedules are described below.\nSchedulers can be adaptive or non-adaptive. An adaptive scheduler decides\non the next edge or node based on the current global configuration. A nonadaptive scheduler decides on a schedule in advance by looking at the graph (and\npossibly the initial configuration). This schedule is then fixed for remainder of\nthe dynamic process. One particularly restricted class of non-adaptive schedules\nis a fixed permutation of nodes/edges repeated periodically and independent of\nthe initial state of the system. For node updates, this is the model employed in\nsequential dynamical systems [BHM+ 03,BEM05].\nThere are several distinctions that can be made, concerning the power of a\nscheduler. The first one concerns the number of players that the scheduler is able\nto choose. There are two possibilities.\n\u2013 An edge-daemon (or edge-scheduler) is able to choose both players of the\ninteracting pair. In other words, an edge daemon constructs S by selecting\nedges ei \u2208 E in some order.\n\u2013 A node-daemon (or node-scheduler) can choose only one of the players. We\ncan let this player choose its partner. A natural model is to consider the\ncase where partner is chosen uniformly at random among the neighbors of\nthe first player. In such a case, we say that the node-scheduler model has\nrandom choice, or random-choice node-scheduler.\n2.4\n\nSummary of results\n\nOur results can be summarized as follows:\n\u2013 Not surprisingly, some amount of fairness is a necessary to extend selfstabilization in an adversarial setting.\n\u2013 The power given to the scheduler makes a big difference in whether or not\nthe system self stabilizes:\n6\n\nNote that ei and ej in the sequence need not be distinct\n\n\f(i) if the scheduler can exogenously choose both participants in the game\nthen (Theorems 2,3) it can preclude convergence on most graphs, even\nwhen bounded by fairness constraints.\n(ii) On the other hand schedulers that allow a limited amount of endogeneity\nin agent interactions7 , by only choosing one of the participants are no\nmore powerful than the random scheduler (Theorem 4) when nonadaptive, and are not significantly more powerful (Theorem 5) when adaptive\nbut \"reasonably fair\".\nWe also investigate experimentally (in Section 7) the convergence time of\nthe colearning dynamics for a few nonadaptive schedulers, in a case when the\nconvergence time for the random scheduler is known rigorously.\n2.5\n\nRelated work\n\nOur approach is naturally related to the theory of self-stabilization of distributed\nsystems [Dol00]. Multi-agent systems, like the ones considered in the evolutionary\ngame dynamics, have many of the characteristics of a distributed system: a number of entities (the agents) capable of performing certain computations (changing\ntheir strategies) based on local information. Randomized models of this type (including the model we study in this paper) have been in fact recently considered\nin the context of self-stabilization [FMP05]. There are, however, a number of\ndifferences. First, in self-stabilization the computational entities (processors) are\ncapable of executing a wide-range of activities (subject to certain constraints,\nfor example the requirement that all processors run the same program, in the\ncontext of so-called uniform self-stabilizing systems). The goal of such systems\nis to achieve a certain goal (legal state) in spite of transient errors and malicious\nscheduling. In contrast, in our setup, there is no \"goal\", the computations are\nfixed, and restricted to steps of the evolutionary dynamics. The only source of\nuncertainty arises from the scheduling model. A second difference is in the nature of the update rule. Usually, in self-stabilizing systems there is a difference\nbetween enabled processors, that intend to take a step, and those that indeed\ntake it. Such a notion is not so natural in the context of game-theoretic models.\nAs mentioned earlier, the dynamics, can be easily recast in the context of Prisoner's Dilemma: let 1 encode \"defection\" and 0 encode \"cooperation\". Then the\nupdate rule corresponds to the so-called win-stay, lose-shift [Pos97], or Pavlov\nstrategy. This rule specifies that agents defect on the next move precisely when\nthe strategy they used in the last interaction was different from the strategy\nused by the other player. It was the object of much attention in the context\nof Iterated Prisoner's Dilemma [Axe84], [NS93],[Axe97]. Related versions of the\ndynamics have an even longer history in the Psychology literature, where they\n7\n\nThe importance of this property has been recognized [Vri06] in the agent-based\nsimulation literature\n\n\fwere proposed to model emergence of cooperation in situations where players do\nnot know precisely the payoffs of the game in which they are participating, and\nmight even be unaware they are playing a game: Sidowski [Sid57] has proposed\nthe \"minimal social situation\" (MSS), a two-person experiment representing an\nextremely simple form of interaction between two agents. MSS was first viewed\nas a game by Thibaut and Kelley [TK59] who called it \"Mutual Fate Control\".\nAn explanation for the empirical observations in [TK59] was proposed by Kelley,\nThibaut, Radloff and Mundy [HKM62], that raised the possibility that players\nwere acting according to the Pavlov dynamics. MSS was generalized to multiplayer games by Colman et al. [ACT91,Col05], who obtained mathematical\ncharacterization for the emergence of cooperation.\n\n3\n\nFairness in scheduling\n\nA necessary restriction on schedulers we will be concerned with is fairness. In\nself-stabilization this is usually taken to mean that each node is updated infinitely\noften in an infinite schedule. We will also consider notions of bounded fairness.\nA natural definition is the following:\nDefinition 1. Let b \u2265 1. A scheduler that can choose one item among a set of\nm elements is (worst-case) b-fair if for every agent x, no other agent is scheduled\nmore than b times between two consecutive times that x is scheduled.\nIt is easy to see that a 1-fair edge scheduler chooses a fixed permutation\nof edges uses this as a periodic schedule. A 1-fair node daemon selects a fixed\npermutation of nodes and for each node selects a random neighbor and repeats\nthe same permutation (with possibly different partners) periodically.\nThe fact that we want to investigate properties of the random scheduler\nsuggest investigating fairness of probabilistic schedulers. For such schedulers,\nthe worst-case fairness in Definition 1 is far too restrictive.\nDefinition 2. A probabilistic scheduler is weakly fair if for any node x and any\ninitial schedule y, the probability that x will eventually be scheduled, given that\nthe scheduler selected nodes according to y is positive.\nThe random scheduler is weakly fair. Not every scheduler is weakly fair, and\na scheduler need not be weakly fair to make the system self-stabilize. On the\nother hand, the base-case result does not extend to the adversarial setting when\nweak fairness is not required:\nTheorem 1 The following are true:\n(i) There exists an edge scheduler that is not weakly fair and that makes the\nsystem self-stabilize no matter what its starting configuration is.\n\n\f(ii) For any graph G there exists an edge/node scheduler that is not weakly fair\nand that prevents the system from self-stabilizing on some initial configuration.\nAnother restatement of Theorem 1 is that weak fairness is necessary to preclude some \"degenerate\" schedulers like the ones we construct for the proof of\npoint (ii).\nProof. (i) Consider an edge scheduler that works as follows:\n\u2013 Choose an edge e that has not yet self-stabilized, i.e. at least one of its\nendpoints is 1.\n\u2013 Turn nodes of e to 0 by playing e twice.\n\u2013 The scheduler never schedules e subsequently.\n(ii) Consider a node (edge) scheduler that repeatedly schedules the same node\n(edge). It is easy to see that the system does not self-stabilize unless the\ngraph consists of a single edge (a star in the case of a node scheduler when\nthe center node is the scheduled one).\nDefinition 3. A probabilistic scheduler is O(f (n))-node fair w.h.p. if the following condition is satisfied while the system has not reached the fixed point: For\nany schedule W (call its last scheduled node x), every node y and every \u01eb > 0\nthere exists C\u01eb > 0 such that, with probability at least 1 \u2212 \u01eb node y will be\nscheduled at most C\u01eb * f (n) times before x is scheduled again..\nA scheduler is boundedly node fair w.h.p. if it is O(f (n))-node fair w.h.p.\nfor some function f (n).\nWe emphasize the fact that Definition 2 applies to edge schedulers as well,\nwhen a node x is considered to occur at stage t if some edge containing x is\nscheduled at that step.\nWith these definitions we have:\nTheorem 2 Let S be a (node or edge) weakly fair probabilistic scheduler such\nthat the following result holds: for any initial configuration, the probability that\nthe system self-stabilizes tends to one. Then the scheduler is boundedly node fair.\nProof. We will consider both node and edge schedulers at the same time. Let \u01eb >\n0 and let T = T (\u01eb, n) be an integer such that, no matter in which configuration\nS we start the system, the probability that the system does not self-stabilize\n(taken over all the coin tosses of the scheduler) is at most \u01eb.\nConsider any state S of the system after a node x has be scheduled, and\nassume that S is not the absorbing state 0. Run the system for T steps. The\nprobability that the system does not self-stabilize is at most \u01eb. On the other\nhand, if some node y is not played at all during the T steps then the system has\nno chance to self-stabilize. It follows that the maximum number of times a given\nnode can be scheduled before x is scheduled again is at most T \u2212 1.\n\n\f4\n\nThe Power of Edge-Schedulers\n\nFrom now on we will restrict ourselves to boundedly fair schedulers. This section\naims to show that edge-schedulers are too powerful. Indeed, it is easy to show\nthat there exist graphs on which even 1-fair edge-schedulers can prevent selfstabilization. The following two results provide a modest improvement, showing\nthat even 2-fair edge-daemons on any graph are too strong :\nTheorem 3 Let G be an instance of PDPD. Then there exists an initial configuration I and a 2-fair edge-scheduler S that precludes self-stabilization on G\nstarting in configuration I.\nProof. Consider a sequence of edges e0 , . . . ek (with repetitions allowed) such\nthat\n\u2013 every edge of G appears in the list.\n\u2013 for every i = 0, . . . , k, ei and ei+1 have exactly one vertex in common (where\nek+1 = e0 ).\n\u2013 Every edge appears in the sequence at most twice.\nWe will show that an enumeration F (G) with these properties can be found\nfor any connected graph with more than one edge. Such a sequence specifies in a\nnatural (via its periodic extension) a 2-fair edge daemon. It is easy to see that the\nonly states that can lead to the fixed point are the fixed point and states leading\nto it in one step: such a state has exactly two (adjacent) ones. But such a state\ncannot be reached from any other state according to the previously described\nscheduler, since the edge that would have been \"touched\" immediately before\nhas unequal labels on its extremities, which cannot be the case after updating\nit.\nWe now have to show how to construct the enumeration F (G). First we give\nthe enumeration in the case graph G is a tree. In this case we perform a walk\non G, listing the edges as follows: suppose the root r is connected, via vertices\nv1 , . . . , vk to subtrees T1 , . . . , Tk . Then define recursively\nF (G) = (v, t1 )F (T1 )(t1 , v)(v, t2 )F (t2 )(t2 , v) . . . (tk\u22121 , v)(v, tk )F (Tk )(tk , v), (1)\nwhere, if the list of edges thus constructed contains two consecutive occurrences of the same edge we eliminate the second occurrence.\nConsider now the general case of a connected graph G, and let S(G) be a\nspanning tree in G. Edges of G belong to two categories:\n(i) Edges of the spanning tree S(G).\n(ii) Edges in E(G) \\ E(S(G)).\nDefine F (G) as the list of edges obtained from F (S(G)) in the following\nway: whenever F (S(G)) first touches a new vertex w in G insert the edges in\n\n\fE(G) \\ E(S(G)) adjacent to w (in some arbitrary order); continue then with\nF (S(G)). It is easy to see that each edge e is listed at most twice in F (G). To\nprove this consider the two cases, e \u2208 E(S(G)) and e \u2208 E(G) \\ E(S(G)). The\nstatement follows in the first case by the recursive definition 1. In the second\ncase it follows by construction, since a nontree edge is visited only when one of\nits endpoints is first touched in E(S(G)).\nEven the most restricted edge-schedulers, 1-fair edge-schedulers, are able to\npreclude self stabilization on a large class of graphs. To see that define\n(i) G1 to be the class of graphs G that contain a cycle of length at least four.\n(ii) G2 to be the class of graphs G that contain no cycles of length at least four\nand m, the number of edges of G is even.\n(iii) G3 to be the class of trees with n = 4k vertices.\nTheorem 4 Let G be a connected graph in G1 \u222a G2 \u222a G3 . Then there exists an\ninitial configuration on G and a 1-fair edge-schedule S that is able to forever\npreclude self-stabilization on G.\nIn other words, connected graphs for which the system self-stabilizes for all\n1-fair schedulers have an odd number of edges and all their cycles (if any) have\nlength 3.\n(i,j)\n\nProof. Define \u2206i,j = (dk,l ) a n \u00d7 n matrix over Z2 by\n\u001a\n1 , if (k, l) = (i, j)\n(i,j)\ndk,l =\n0 , otherwise.\n\n(2)\n\nSuppose we represent configurations of the system as vectors in Zn2 .\nTaking one step of the dynamics on an arbitrary configuration X with the\nscheduled edge being (i, j) leads to configuration X = Ai,j * X, where matrix\nAi,j is given by\nAi,j = In + \u2206i,j + \u2206j,i .\n\n(3)\n\nIndeed, the only nondiagonal elements of matrix Ai,j that are nonzero are in\npositions (i, j) and (j, i). This means that all elements of a configuration X in\npositions other than i, j are preserved under multiplication with Ai,j . It is easy\nto see that labels in positions i, j change according to the specified dynamics.\nConsider a graph G with m edges, E(G) = {(i1 , j1 ), . . . , (im , jm )}. The action\nof a 1-fair edge schedule S (specified by permutation \u03c0 of {1, . . . , m}) on a\nconfiguration X corresponds to multiplication of X by\n\u03c0(S) = Ai\u03c0[1] ,j\u03c0[1] * Ai\u03c0[2] ,j\u03c0[2] * . . . * Ai\u03c0[m] ,j\u03c0[m] .\n\n(4)\n\nAn edge-schedule cannot prevent self-stabilization implies that starting at\nany initial configuration, the system reaches a fixed point. In other words, \u2200I \u2208\n\n\fZn2 \u2203k \u2208 N s.t.[\u03c0(S)]k * I = 0. Since the number of vectors I is finite, this is\nequivalent to saying that \u2203k1 \u2208 N, \u2200I, [\u03c0(S)]k1 * X = 0. Equivalently this means\nthat [\u03c0(S)]k = 0, i.e. matrix \u03c0[S] is nilpotent. Thus, what we want to show is\nLemma 4. For any graph G there exists a schedule S such that the corresponding matrix \u03c0[S] is not nilpotent.\nConsider now an arbitrary ordering of vertices in G and let \u03c0 be the permutation corresponding to the induced lexicographic ordering of edges of G (where\nan edge is seen as an ordered pair, with the vertex of lower index appearing\nfirst).\nIt is easy to see that\n\u2206i,j * \u2206k,l =\n\n\u001a\n\n\u2206i,l , if j = k\n0 , otherwise.\n\n(5)\n\n(i,j)\n\nIndeed, if \u2206i,j = (am,n )m,n\u22651 , then the only wat for some element cm,n of the\n(i,j)\n(k,l)\nproduct \u2206i,j * \u2206k,l to be nonzero is that there exists at least one term dm,p * dp,n\nthat is nonzero. But this is only possible for (i, j) = (m, p) and (p, n) = (k, l),\nin other words for m = i, n = l and p = j = k, which immediately yields\nequation (5).\nLet us now consider the integer matrix \u03a0[S] obtained by interpreting equations (3) and (4) as equations over integers. Because integer addition and multiplication commute with taking the modulo 2 value, matrix \u03c0[S] can be obtained\nby applying reduction modulo 2 to every element of \u03a0[S].\nLet Pi,j = \u2206i,j + \u2206j,i . From the definition of matrix \u03c0(S) in equation (4)\nand the definition of matrices Ai,j in equation ( 3) we see that \u03c0[S] is a sum of\nproducts, each term in a product corresponding to either a Pi,j or to the identity\nmatrix. Thus\n\u03a0[S] = I +\n\nX\n\n(\n\nY\n\nPi\u03c0[k] ,j\u03c0[k] ).\n\n(6)\n\n\u22056=S\u2286{1,...,m} k\u2208S\n\nConsider the directed graph G obtained from G by duplicating every edge\n{i, j} of G into two directed edges (i, j), (j, i) in G. Label every edge e \u2208 E(G) by\nthe (unique) integer k such that e = {i\u03c0[k] , j\u03c0[k] }, and apply the same labelling to\nthe two oriented versions of edge e in G. Then equation (5) shows that nonzero\nproducts of matrices \u2206 are in bijective correspondence to directed paths of length\ntwo with increasing labels, when read from the starting to the end node of\nthe path. Inductively generalizing these observations to all sets S we see that\nproducts in (6) are nonzero exactly when they specify a directed path in G (i.e.\na path in G) from a vertex k to a vertex l with increasing labels when read from\nk to l, in which case they are equal to \u2206k,l .\n\n\fTherefore \u03a0[S] = I + C, where C = (ci,j ) is given by\n\u001a\n# of paths from i to j with increasing labels, if such paths exist\nci,j =\n0,\notherwise.\n\n(7)\nThe matrix \u03c0[S] is, of course, obtained by reducing modulo 2 the elements\nof \u03a0[S]. A well known result in linear algebra8 is that the the characteristic\npolynomial of a nonzero nilpotent matrix A is xn . Thus, one strategy to show that\na given matrix \u03c0[S] is not nilpotent is to make sure that for some p, 0 \u2264 p \u2264 n,\nthe sum sp of its principal minors of order p is non-zero. This is equivalent to\nmaking sure that the sum of the corresponding minors of the associated integer\nmatrix is odd. The proof consists of three cases:\nCase (a) G \u2208 G1 : We will prove the following\nLemma 5. There exist two permutations \u03c31 and \u03c32 with corresponding matrices\nover integers A1 = \u03a0[\u03c31 ] and A2 = \u03a0[\u03c32 ] such that\ntrace(A2 ) \u2261 (trace(A1 ) + 1)(mod 2).\nGiven Lemma 4, the proof of Lemma 3 for Case (a) follows since matrices\n\u03c0[\u03c31 ] and \u03c0[\u03c32 ] cannot both be nilpotent. This is true since the trace(A1 ) and\ntrace(A2 ) have different parities. We will prove Lemma 4 using a multistep\nargument, combining the conclusions of Lemmas 3-5 below. Consider first the\nfollowing \"basic\" graphs: K4 , K3 \u25b3 K3 (the graph obtained by merging two\ntriangles on a common edge), and Cn , n \u2265 4.\nLemma 6. The conclusion of Lemma 4 is valid for the \"basic\" graphs.\nProof. By the previous result on the value of coefficients ci,j the value of the\ntrace of a matrix A can be easily computed from the number of cycles with\nincreasing labels. Also, note the following:\n\u2013 Any cycle C contributes a one to at most one ci,i , for some vertex i appearing\nin C. This is because of the restriction on the increasing labels, who might\nbe verified for at most one node of the cycle.\n\u2013 Moreover, any triangle contributes a 1 to exactly one ci,i . Therefore, in considering the trace of matrix A triangles add the same quantity irrespective\nof permutation, and can thus be ignored.\nThis observation leads to a simple solution when the underlying graph is a\nsimple cycle Cn , n \u2265 4, or the graph K3 \u25b3 K3 . Note that these graphs contain\na unique cycle C of length atleast 4. Consider an ordering of the edges of this\ncycle, corresponding to moving around the cycle. We will create two labellings\n8\n\njustified as follows: a classical result states that the characteristic and the minimal\npolynomial of a matrix have the same roots (with different multiplicities). But it is\neasy to see that the minimal polynomial of a nilpotent matrix is xk for some k \u2264 n.\n\n\fcorresponding to this ordering. The first one assigns labels 1 to |C| in this order.\nThe other labelling assigns labels 1, 2, . . . , |C| \u2212 2, |C|, |C| \u2212 1 in this order. It\nis easy to see that the first ordering contributes a 1 to exactly one diagnonal\nelement, while the second one does not contribute a 1 to any element. Hence the\ntraces of the corresponding matrices differ by exactly 1.\nFor graph K4 we first label the diagonal edges by 5 and 6. There are three\ncycles of length 4 in the graph K4 \u2013 one that uses no diagonal edges, the other\ntwo using them both. For the outer cycle consisting of no diagonal edges, we\nconsider the two orderings described in the previous case on the outer cycle C4 .\nThis as before shows that the traces of the corresponding matrices differe exactly\nby 1. Next, note that irrespective of the labelling of the non-diagonal edges, the\ntwo cycles containing the diagonal edges cannot be traversed in increasing label\norder, so they do not contribute to the trace of the associated matrix. Therefore,\nthe result follows for graph K4 as well. This completes the proof of Lemma 3.\nLemma 7. Let G be a graph and let G2 be a subgraph of G induced by a subset\nof the vertices in G. If the conclusion of Lemma 3 holds for G2 , then it holds for\nG.\nProof. Extend a permutation of the edges in G2 to a permutation of the edges\nin G via a fixed labelling of the edges in E(G) \\ E(G2 ) such that\n(i) The index of any edge with both ends in G2 is strictly smaller than the index\nof all edges not in this class.\n(ii) The index of any edge with exactly one end in G2 is strictly larger than the\nindex of any edge not in this class.\nThe trace of the resulting matrix is determined by the cycles with strictly\nincreasing labels. There are several types of such cycles:\n(i) Cycles in G \\ G2 . Whether such a cycle can be traversed in increasing label\norder does not depend on the precise labelling on edges of G2 as long as the\nconditions of the extension are those described before.\n(ii) Cycles containing some edges in G2 , as well as additional edges from G \\ G2 .\nBecause of the restriction we placed on the labelings, the only such cycles\nthat can have increasing labels are the triangles with two vertices in G2 and\none vertex in G \\ G2 . Since there exist an unique way to \"read\" a triangle in\nthe increasing order of the edge labels, their contribution to the total trace\nis equal to the number of such triangles, and does not depend on the precise\nlabeling of edges in G2 , as long as the restriction of the labeling is met.\n(iii) Cycles entirely contained in G2 .\nLet now \u03c31 , \u03c32 be labelings on G2 verifying the conclusion of Lemma 2 and\n\u03c31 , \u03c32 extensions to G verifying the stated restriction. The conclusion of the previous analysis analysis is that a difference in the parity of the traces of matrices\ncorresponding to the labelings \u03c3i on G2 directly translates into a difference in\nthe parity of the traces of matrices corresponding to labelings \u03c3i on G.\n\n\fFinally, we reduce the case of a general graph to that of a base case graph\nvia the following result.\nLemma 8. Let G be a graph that contains a cycle of length \u2265 4 and is minimal\n(any induced subgraph H does not contain a cycle of length \u2265 4 any more). Then\nG is one of the \"basic\" graphs from Lemma 3.\nProof. Let G be minimal with the property that it contains a cycle of length\n\u2265 4, let n be the number of nodes in G and let C be a cycle of length \u2265 4 in G.\nBecause of minimality, C contains all the vertices of G (otherwise G would not\nbe minimal, since one could eliminate nodes outside C). Thus C is a Hamiltonian\ncycle. If no other edge is present then we get the cycle Cn . Moreover, no other\nedge can be present unless n = 4 (otherwise G would contain a smaller cycle of\nlength \u2265 4 and thus would not be minimal). In this case the two possibilities are\nK4 and K3 \u25b3 K3 .\nCase (b) G \u2208 G2 : Consider the ordering <sum on the edges of G so that\n{i, j} <sum {k, l} when either\ni+j <k+l\nor\ni + j = k + l and min{i, j} < min{k, l}.\nIn this case ck,k = 0 for every k, except when k is the middle-index vertex of\na triangle (i.e. a triangle with vertex labels i, j, k such that i < k < j).\nWe infer that s1 = trace(A) is congruent (mod 2) to n plus the number of\ntriangles in G, that is to m + 1 (mod 2) (where m is the number of edges of G).\nCase (c) G \u2208 G3 : Consider the sum s2 of principal minors of size 2 of A. In\na tree there can be at most one path between two nodes. Since we are counting\npaths with increasing labels, the only way for ai,j = aj,i = 1 to hold is that\nvertices i and j be adjacent. But in this case the corresponding minor is zero. It\nfollows that s2 is the number of sets of different nonadjacent vertices in G, that\nis\n\u0012 \u0013\n(n \u2212 1)(n \u2212 2)\nn\n= 1 mod 2\ns2 =\n\u2212 (n \u2212 1) =\n2\n2\nif n = 4k.\nOne might suspect that Theorem 2 (ii) extends to all graphs, thus strenghtening the statement of Theorem 1 to 1-fair daemons. This is not the case: Let\nthe line graph L6 be an instance of PDPD. Then for all 1-fair edge-schedulers\nS and for all initial configurations I the system self-stabilizes starting at I. We\nverified this statement via computer simulation, by running PDPD for all 6!\n1-fair daemons. A result that rendered this experiment computationally feasible\nis the state-reduction technique highlighted in the proof of (ii): to prove selfstabilization we only needed to consider those initial configurations with exactly\n\n\fone 1. Thus we had to run 6 \u00d7 6! simulations. It is an open problem to find all\ngraphs for which this happens. However, Theorem 2 (ii) shows that the class of\nsuch graphs is really limited.\n\n5\n\nNonadaptive node-schedulers\n\nAs we saw, even 1-fair edge schedulers are able to prevent self-stabilization. What\nif we only allow the scheduler to choose one of the nodes ? In this section we\nstudy the Prisoners dilemma with Pavlov dynamics when adversaries are 1-fair\nnode-schedulers. Because only one of the nodes of the scheduled edge is chosen\nby the adversary and the other one is chosen randomly, the self-stabilization of\nthe system is a stochastic event.\nTheorem 5 Let Starn be an instance of PDPD. Then Sn self-stabilizes with\nprobability 1 against any 1-fair scheduler.\nProof. One can assume, without loss of generality, that the first node to be\nscheduled is the center (labeled 0) and the rest of the nodes are scheduled in the\norder 1, 2, . . . , n. Indeed, if the center was scheduled later in the permutation\nof nodes, it is enough to prove self-stabilization from the configuration that\ncorresponds to first running the system up to just before the center is scheduled,\nand then viewing the run as initialized at the new configuration, and with a new\nperiodic schedule (that now starts with node 0). As for the order in which the\nother nodes get scheduled, by relabelling the nodes we may assume without loss\nof generality that this is 1, 2, . . . , n.\nLet a0 , a1 , . . . , an be the labels of nodes at the beginning of the process. It\nis useful to first consider a deterministic version of the dynamics in question,\nspecified as a game between two players\n\u2013 The first player is choosing one node to be scheduled. It is required that the\nsequence of nodes chosen by this player forms a periodic sequence \u03c0. The\ngoal of the first player is to prevent self-stabilization.\n\u2013 Given a node choice by the first player, the second player is responding with\na choice of the second node to be scheduled. Unlike the first player, the\nsequence of nodes chosen by the second player can potentially vary between\nsuccessive repetitions of the permutation \u03c0. The goal of the second player is\nto make the system converge to state 0.\nThe game above is an example of the scheduler-luck games from the selfstabilization literature [DIM95]. We will provide a strategy for the second player\nthat (when applied) will turn any configuration into the \"all zeros\" configuration.\nBut a winning strategy for the second player in the scheduler-luck game will\nbe played with positive probability in any round of the scheduler. Thus with\nprobability going to one (as the number of rounds goes to infinity) this strategy\nwill be played at least in one round, making the system converge to state 0.\n\n\fThe crux of the strategy is to carefully use the \"partner node\" of node 0,\nwhen this is scheduled, to create a segment of nodes 1, 2, . . . i (with i nondecreasing, and eventually reaching n) with labels zero at the beginning of a round of\nscheduling.\nThis is simple to do at the very beginning: if node 0 plays node 1 (when 0 is\nscheduled), then the labels of the two node will be identical, thus when node 1\nis scheduled (and plays again node 0) the label of node 1 will be zero.\nIf at the beginning of a round the label of node 0 is 1, we make it play (when\nscheduled at the beginning of a round) the node of smallest positive index (i + 1)\nstill labelled 1. This will turn the labels of both nodes to 0. Further scheduling\nof nodes 1 to i + 1 will not change this, and at the end of the round, nodes 1 to\ni + 1 will still be labelled 0.\nIf, on the other hand at the beginning of the round node 0 is labelled 0, we\nmake it keep this label (and, thus, not affect the zero labels of nodes 1 to 1) by\nmaking it play (when scheduled) against another node labelled 0 (say node 1).\nTo complete the argument it remains to show that for any configuration\nx0 , . . . xn different from the \"all zeros\" configuration, in a finite number of rounds\nwe will reach a configuration where the first case applies, and thus the length of\nthe \"all zero\" initial segment increases.\nIndeed, assume that x(0) = 0 and it stays that way throughout the process.\nThen, denoting by Yt = (x(1)t , . . . x(n)t )T the labels of the nodes 1 to n at the\nbeginning of the t'th round, it is easy to see that the dynamics of the system is\ndescribed by the recurrence\nYt+1 = B * Yt ,\nwith B = (bi,j ) is a matrix of order n over Z2 specified by\n\u001a\n1 , if i \u2265 j\nbi,j =\n0 , otherwise.\n\nConsider now B as a matrix over Z, rather than Z2 . It is immediate to show\n(k)\nby induction that B k = (bi,j ) given by\n\u001a i\u2212j+k\u22121\u0001\n, if i \u2265 j\n(k)\nk\u22121\nbi,j =\n0\n, otherwise.\nThe k'th power over Z2 is obtained, of course, by reducing these values mod\n2. In particular define St to be the sum x(1)t + . . . x(n)t . It is easy to see that\nSt = x(0)t+1 thus by our hypothesis St has to be zero. On the other hand a\nconsequence of the previous result is that\n#\n\" n \u0012\nX n \u2212 i + t \u2212 1\u0013\n* xi ( mod 2).\nSt =\nt\u22121\ni=1\nIn particular\n\n\u2206xt := St+1 \u2212 St =\n\n\"n\u22121 \u0012\nX n \u2212 i + t \u2212 1\u0013\ni=1\n\nt\n\n#\n\n* xi ( mod 2).\n\n\fBy induction and algebraic manipulation we generalize this to higher order\nof iterated differences \u2206k xt = \u2206(\u2206k\u22121 xt ) as:\n#\n\"n\u2212k \u0012\nX n \u2212 i + t \u2212 1\u0013\n* xi (mod 2).\n\u2206 xt =\nt+k\u22121\ni=1\nk\n\nLet i0 be the smallest index such that x(i0 ) = 1. Then, by the previous\nrelation\n\"i \u0012\n\u0013\n\u0013 # \u0012\n0\nX\nn \u2212 i0 + t \u2212 1\nn\u2212i+t\u22121\nn\u2212i0\n* xi0 = xi0 = 1 (mod 2).\nxi =\nxt =\n\u2206\nn \u2212 i0 + t \u2212 1\nt+k\u22121\ni=1\nBut this contradicts the fact that St = 0 for every value of t and completes\nthe proof.\nA 1-adaptive scheduler keeps repeating the nodes to choose according to a\nfixed permutation. Thus, for a fixed scheduler and interaction graph we can talk\nabout the probability of stabilization in the limit. Also, for a given fixed scheduler, the event that this limit is one is a deterministic statement. Consequently\nwe can talk of the probability that this event happens when the interaction graph\nis sampled from a class of random graphs. As noted, for a random scheduler the\ncondition that G has no isolated vertices is necessary and sufficient to guarantee\nself-stabilization with probability 1. This is also true for the adversarial model\nin the case of non-adaptive (1-fair) daemons. This is in case with the case of an\nedge daemon, when even non-adaptive daemons could preclude stabilization.\nTheorem 6 Let G be an instance of PDPD such that G has no isolated vertices.\nThen for any 1-fair node-scheduler and any initial configuration the system G\nreaches state 0 with probability 1.\nThe results of Theorem 5 should be contrasted with the corresponding result\nfor edge schedulers, for which, as we showed, even non-adaptive daemons could\npreclude stabilization.\nThe proof consists of the following three components:\n(i) our earlier result that guarantees a winning strategy for scheduler-luck game\nassociated to the dynamics when the underlying graph is Sn ,\n(ii) the partition of a spanning forest of G into node disjoint stars and\n(iii) the fact that the existence of such a winning strategy is a monotone graph\nproperty w.r.t to edge insertions. This is formally stated in the following\nLemma 9. Suppose H is a graph such that a winning strategy W exists for the\nscheduler-luck game on a graph H. Let e 6\u2208 E(H), and let L = H \u222a {e}. Then\nW is also a winning strategy for any graph L.\n\n\fProof. Given any node choice by the first player, the second player can choose\nthe corresponding node according to strategy W (thus never scheduling the\nadditional edge e). The outcome of the game is, therefore, identical on H and L.\nProof of Theorem 5. By Lemma 6 it is enough to show the existence of a\nwinning strategy for the second player in the scheduler-luck game on a graph G,\nwhen G is a tree. We decompose tree G into a set {S1 , . . . , Sp } of node-disjoint\nstars as follows.\n\u2013 Root G at an arbitrary node r.\n\u2013 Consider the star formed by the root and its children. Call it S1 .\n\u2013 Remove the nodes in S1 and all edges with one end point incident on nodes\nin S1\n\u2013 Recursively apply the procedure on each forest created by the above operation.\nNow consider a 1-fair schedule \u03c0 on graph G, corresponding to a strategy of\nthe first player in the schedule-luck game on G. For every star Si , the projection\n\u03c0i of the schedule on the nodes of Si (that amounts to only considering scheduled\nnodes that belong to Si ) specifies a 1-fair schedule on Si . According to Theorem\n5, the second player has a winning strategy Wi for the scheduler-luck game on\nSi when the first player acts according to the schedule \u03c0i .\nNext, we devise a strategy W for the scheduler-luck game on graph G, by\nby \"composing\" the winning strategies Wi . Specifically if the node chosen by\nthe first player belongs to star S, strategy W will employ Wi to choose the\ncorresponding second node. Since on each star Si the labels of the node will\neventually be 0, W is a winning strategy for the second player in the schedulerluck game on G.\n\n6\n\nAdaptive node schedulers\n\nNonadaptive schedulers could not preclude self-stabilization. In contrast, as the\nfollowing theorem shows, 3-fair nonadaptive node-schedulers are still powerful\nenough to preclude self-stabilization with complete certainty, and so are 2-fair\nadaptive9 schedulers.\nTheorem 7 The following are true:\n(i) Let the star graph Sn (K1,n ) be an instance of PDPD. Then there exists\nan initial configuration I and a 3-fair nonadaptive scheduler that precludes\nself-stabilization on Starn starting in I.\n(ii) Let the triangle K3 be an instance of PDPD. Then there exists an initial configuration I and a 2-fair adaptive scheduler that precludes self-stabilization\non K3 starting in I.\n9\n\nobviously, there are no 1-fair adaptive schedulers.\n\n\fProof. (i) Consider the star graph Sn (K1,n ), with the center labeled 0 and the\nrest of the nodes labeled 1, 2, . . . , n. We have to provide an example of a 3-fair\nscheduler that precludes self-stabilization on some initial configuration. This\ninitial configuration has two 1's, at nodes 1 and 2. The scheduler repeats the\nschedule [0, 1, 1, 3, 4, . . . n \u2212 2, 2, 1, n \u2212 1, n \u2212 1]. After the scheduling of 0 1\n1 the effect is that both nodes have label 0. Thus the scheduling of nodes\n3, 4, . . . , n \u2212 2 does not change any label. With node 2 the label of node 0\nwill change to 1, thus changing in the next step the label of node 1 back to\n1. Finally scheduling the node n \u2212 1 twice turns back the label of node 0 to\n0, thus yielding the initial configuration. It is easy to see that the scheduler\nis 3-fair.\n(ii) Start with configuration I consisting of all ones. The scheduler will adaptively schedule the nodes, in sequences of three, so that at the end of such\na 3-block the system is guaranteed to be in configuration I again. Figure 1\ndescribes the strategy of the scheduler, assuming that node 1 is scheduled\nfirst.\n\n1\n001[3]\n2\n\n101[2]\n1,3\n\n2\n2,3\n\n111[1]\n\n111\n\n011[1]\n3\n\n3\n\n010[2]\n\n1\n1,2\n110[3]\n\nFig. 1. A round of the 2-fair adaptive scheduler\n\nElements in the rectangle represent the state of the system, followed by the\nscheduled node (in square brackets). choices. Labels on the edges represent\nthe possible probabilistic choices of the partner node, with multiple (inconsequential) choices separated by a comma. Note that the scheduler has similar\nstrategies if one of the nodes 2,3 is scheduled first. Also, note that a 3-block\nconsists of either a permutation of a node, or two nodes, with the initial and\nthe final node in the block being identical. The scheduler proceeds now to\ncreate an infinite schedule consisting of 3-blocks according to the following\nrule:\n\n\f(a) If a given block B is a permutation then start the next block with the\nsame starting element as B.\n(b) Otherwise if the given block B is missing node z, start the next block\nby first scheduling z.\nIt is easy to see that the scheduler we constructed is 2-adaptive and precludes\nself-stabilization.\nAlthough formal definition of the probability of self-stabilization is more\ncomplicated in this case, we can talk of the probability of self-stabilization for\nadaptive daemons as well. However, as we have seen, the result of Theorem 5 is\nno longer true: on stars, 1-fairness is stronger than 2-fair adaptive scheduling.\nIt would seem that this result shows that nonadaptiveness is important for selfstabilization. However, we will see that the class of network topologies where\nthis happens is reasonably limited. Indeed, we next study self-stabilization on\nErd\u0151s-Renyi random graphs G(n, p). We will choose p in such a way that with\nhigh probability a random sample from G(n, p) has no isolated vertices10 . In\nother words, we require that necessary condition on the topology of G holds\nwith probability 1 \u2212 o(1). Call a graph G to be good if for any scheduler of\nbounded fairness and any starting configuration I, G starting at I converges to\n0 with probability 1 \u2212 o(1), as the number of steps goes to infinity.\nTheorem 8 Let p be s.t. np \u2212 log n \u2192 \u221e. Then with probability 1 \u2212 o(1) a\nrandom graph G \u2208 G(n, p) is good.\nOf course, a natural question is whether such a weakening of the original\nresult, from any graph topology satisfying a given condition to a generic random\ngraph satisfying the same condition, is reasonable. We are, however, not the\nfirst ones to propose such an approach. Indeed, except for a handful of cases the\nnetwork that a given social dynamics takes place on is not known in its entirety.\nInstead, a lot of recent work (see e.g. [PSV07,NBW06,Dur06] for presentations)\nhas resorted to the study of generic properties of random network models that\nshare some of the observable properties of a fixed network (such as the Internet\nor the World Wide Web.\nProof. The plan of the proof is similar to that for 1-fair schedulers. Define a\nround of a b-fair scheduler to consist of a consecutive sequence of b(n \u2212 1) + 1\nsteps.\n(i) We prove that for graphs from a class B of \"base case\" graphs (Lemma 7\nbelow) the second player has a winning strategy in the scheduler-luck game\nassociated to any scheduler of bounded fairness, where the games corresponds\nto a finite number of rounds of the scheduler.\n(ii) We use the monotonicity of the existence of a strategy.\n10\n\nA random sample from G(n, p) has no isolated vertices with probability 1 \u2212 o(1)\nwhen [JLR00] np \u2212 log n \u2192 \u221e.\n\n\f(iii) We show that with probability 1 \u2212 o(1) the vertices of a random sample\ngraph G from the graph process can be partitioned such that all the induced\nsubgraphs are isomorphic with one graph in G.\nLemma 10. The following are true:\n(i) Let G be a graph with a perfect matching. Then for any scheduler S of\nbounded fairness, and any initial configuration on G, the second player has\na winning strategy for the scheduler-luck game corresponding to one round\nof the scheduler.\n(ii) Let the line Ln , n \u2265 6 be an instance of PDPD. Then for any node-scheduler\nS of bounded fairness and every initial configuration I, the second player has\na winning strategy in the scheduler-luck game associated with two consecutive\nrounds of S.\nProof. (i) A perfect matching M of G specifies a winning strategy in a schedulerluck game: each node plays (when scheduled) against its partner in M . Since\nevery node is scheduled at least once in a round of scheduling, every edge of\nM is played at least twice. Therefore, irrespective of the initial configuration,\nthe final configuration is 0.\n(ii) The lemma only needs to be proved in the case when n is odd (in the\nother case the strategy based on perfect matchings applies). In this case\nthe winning strategy is specified as follows:\n(a) In the first round turn the leftmost L4 portion of Ln into the all zero\nstate by playing the matching based winning strategy.\n(b) In the second round nodes in the leftmost L3 will only choose to play\nagainst each other when scheduled, thus remaining at 0. The remaining\nnodes form a graph isomorphic to Ln\u22123 , and in this round we use the\nperfect matching based strategy for this graph.\nWe now note now that the statement of Lemma 6 extends to scheduler-luck\ngames associated to node daemons of bounded fairness. The proof is similar (a\nstrategy for the game on G is also a strategy for the game on a graph with a\nlarger set of edges). Theorem 7 immediately follows if n is even: a classical result\nin random graph theory (see e.g. [JLR00] pp. 82-85) asserts that with probability\n1 \u2212 o(1) G will have a perfect matching.\nTo complete the proof of Theorem 7 we only need to deal with the case when\nn is odd. For a graph G and a set of vertices V denote by G|V the subgraph\ninduced by vertex set V .\nLemma 11. With probability 1 \u2212 o(1) G can be partitioned into V = V1 \u222a V2\nsuch that:\n(i) G|V1 contains L7 as an edge-induced subgraph.\n(ii) G|V2 is a graph with a perfect matching.\n\n\fTheorem 7 follows from Lemma 8, since for both G|V1 and G|V2 the second\nplayer has a winning strategy in the scheduler-luck game. A winning strategy for\nthe corresponding game on G proceeds by using the winning strategy for G|V1 ,\nwhen the scheduled node is in V1 and the winning strategy for G|V2 when the\nscheduled node is in V2 .\nThe proof of Lemma 8 goes along lines similar to that of the proof of the\nexistence of a perfect matching in a random grapg(see [JLR00] pp. 82-85). The\nfirst step is to show that w.h.p. G does not contain a set of distinct vertices\nx0 , x1 , x2 , x3 , x4 such that:\n\u2013 degG (x0 ) = degG (x4 ) = 1.\n\u2013 For every i = 0, 3, xi and xi+1 are adjacent.\nThis is easy to see, since the expected number of such structures is O(n5 p4 (1\u2212\np)\n) = O(n5 p4 e\u22122np ) = o(1), since p = \u0398( log(n)\nn ).\nConsider now a random graph G, conditioned on not containing such a structure, and a vertex x0 in G of degree one. Since this information only exposes\ninformation on the edges with one endpoint at x0 , with probability 1 \u2212 o(1)\ngraph H = G \\ {x0 } has a perfect matching. Let x1 be the node in G \\ {x0 }\nadjacent to x0 , and let x2 be the node matched to x1 in H. With probability\n1 \u2212 o(1) x2 has another neighbor x3 in H, (otherwise G would contain a cherry,\ni.e. two vertices of degree one at distance exactly 2 in G (see Figure 2). But (see\n[JLR00] pp. 86) a random sample from G(n, p) only contains a cherry with probability o(1). Let x4 be the node x3 is matched to in H. Again, with probability\n1 \u2212 o(1) x4 has a neighbor x5 in H different from x3 (otherwise the five vertices\nx0 to x4 would form a structure we have conditioned on not occurring in G).\nFinally let x6 be the node matched to x5 in H. Then the restriction of G to the\nset V1 = {x0 , . . . , x6 } contains a copy of L7 , and G restricted to V2 = V \\ V1\ncontains a perfect matching (induced by the perfect matching on H).\n2(n\u22121)\n\nFig. 2. A cherry in a graph (with bold lines)\n\n\f7\n\nSpeed of convergence\n\nThe previous theorems have shown that results concerning convergence to a fixed\npoint can be studied in (and extend to) an adversarial framework. Perhaps what\nis not preserved as well in the adversarial framework is results on the computational efficiency of convergence to equilibrium. Such results include, for instance,\nthe above mentioned O(n log n) bound of [DGG+ 02]. The proof of this theorem\ndisplays an interesting variation on the idea of a potential function. It uses such\na function, but in this case the value of the function only diminishes \"on the average\", rather than for every possible move. Therefore bounding the convergence\ntime seems to critically use the \"global\" randomness introduced in the dynamics\nby random matching, and does not trivially extend to adversarial versions. On\nthe other hand, the proof of Theorem 4 only guarantees an exponential upper\nbound on expected convergence time.\nWe have investigated experimentally the convergence time on Cn for some\nclasses of 1-fair schedulers (permutations). Some of our results are presented\nin Figure 3, where we present the average number of rounds, rather than steps,\nover 1000 samples at each point. The symbol id denotes the identity permutation\n(12 . . . n), p3 is the permutation \u03c3[i] = 3i(mod n), (13) refers to permutations\nwith pattern (13245768 . . .), and rd refers to the maximum average number of\nrounds, taken over 10 random permutations. In all cases the convergence time is\nconsistent with the above-mentioned O(n log n) result.\n\n\u03c0|n\nid\np3\nrd\n(13)\n\u03c0|n\nid\np3\nrd\n(13)\n\n4\n2.486\n2.469\n2.289\n2.168\n256\n16.091\n14.323\n17.342\n18.504\n\n8\n4.225\n4.039\n4.499\n4.656\n512\n17.954\n16.054\n20.518\n20.346\n\n16\n6.401\n5.807\n6.527\n7.069\n1024\n20.331\n19.826\n22.336\n20.392\n\n32\n8.33\n7.662\n8.781\n9.837\n\n64\n10.498\n9.639\n11.161\n12.653\n\n128\n13.135\n11.718\n14.151\n14.859\n\nFig. 3. Rounds on Cn under 1-fair scheduling.\n\nWe are unable to obtain such a result (and leave it as an interesting open\nproblem)11 . It is even more interesting to study the dependency of the mixing\ntime of the dynamics [DGG+ 02] on the underlying network topology. While\nthere are superficial reasons for optimism (for some models in evolutionary game\ntheory, e.g. [Mor00], the impact of network topology on the convergence speed\n11\n\nA promising approach is outlined in [FM05]\n\n\fof a given dynamics is reasonably well understood), the reader is directed to\n[MR06] (especially the concluding remarks) for a discussion on the difficulties\nof connecting network topology and convergence speed for the specific dynamics\nwe study.\n\n8\n\nDiscussion of Results and Conclusions\n\nWe have advocated the study of evolutionary game-theoretic models under adversarial scheduling, similar to the ones in the theory of self-stabilization. As an\nillustration we studied the Iterated Prisoners'Dilemma with the win-stay loseshift strategy.\nOur results are an illustration of the adversarial approach as follows:\n(i) Start with some result P , valid under random scheduling. The original statement is presented in Subsection 2.2.\n(ii) Identify several structural properties of a random scheduler that\nimpact the validity of P . The random scheduler is\n\u2013 fair more precisely O(n log n) fair w.h.p. by the Coupon Collector Lemma.\n\u2013 endogeneous, since the next edge to be scheduled is not fixed in advance.\n\u2013 nonadaptive, since the next edge to be scheduled does not depend on the\nconfiguration of the system.\n(iii) Identify those properties (or combinations of properties) that are\nnecessary/sufficient for the validity of P .\nTheorem 1 shows that fairness is a necessary condition for the extension of\nthe original result to adversarial settings. Next, the definition of node and\nedge schedulers illustrates another important property of random schedulers:\nendogeneity of agent interactions: an edge scheduler completely specifies the\ndynamics of interaction. In contrast, node schedulers provide perhaps the\nweakest possible form of endogeneity: the underlying social network is still\nfixed, but the agents can choose a neigbor among his neighbors to interact\nwith (or simply play a random one).\nTheorems 4 and 5 show that, in contrast with the case of edge schedulers,\neven this limited amount of endogeneity is sufficient to recover the original\nresult for random scheduler. Moreover, the proofs illuminate the role of endogeneity, that was somehat obscured in the (trivial) original proof that the\nPavlov dynamics (under random matching) converges with high probability\nto the \"all zeros\" fixed-point. This proof implicitly relies on the fact that\nfrom every state there exists a sequence of \"right\" moves, that \"funnels\" the\nsystem towards the fixed point. For node schedulers the existence of a such\na set of right moves is proved by explicit construction and is more difficult\nin the adversarial setting. The existence of such a set of moves is precisely\nwhat exogeneous choice of agents is able to preclude.\n\n\f(iv) Correspondingly, identify those properties that are inessential to\nthe validity of P . In the process one can reformulate (if needed)\nthe original statement in a way that makes it more robust.\nTheorem 6 shows that, if we allow schedulers to be adaptive, then network topology becomes important, and can invalidate the original result in\nan adversarial setting. However adaptiveness (or, equivalently, the amount of\nfairness) is inesential if we require the convergence result to only hold generically with respect to the class of network topologies described by Erd\u0151s-Renyi\nrandom graphs.\nThe results we proved also highlight a number of techniques from the theory\nof self-stabilization that might be useful in developing a general theory:\n\u2013 the concept of scheduler-luck game.\n\u2013 composition of strategies by partitioning the interaction topology.\n\u2013 monotonicity and \"generic preservation\" via threshold properties.\nObviously, a reconsideration of more central game-theoretic models under\nadversarial scheduling is required (and would be quite interesting).\n\nAcknowledgments.\nThis work has been supported by the Romanian CNCSIS through a PN II/Parteneriate\nGrant, by the U.S. Department of Energy under contract W-705-ENG-36 and\nLos Alamos National Laboratory through the LANL LDRD program, and by by\nNSF Grant CCR-97-34936.\n\nReferences\n[ACT91]\n\n[AE96]\n[Axe84]\n[Axe97]\n\n[Axt00]\n\n[BEM05]\n\nA. Colman A. Coleman and R.M. Thomas. Cooperation without awareness:\nA multiperson generalization of the minimal social situation. Behavioral\nScience, 35:115\u2013121, 1991.\nR. Axtell and J. Epstein. Growing Artificial Societies: Social Science from\nthe Bottom Up. The MIT Press, 1996.\nR. Axelrod. The Evolution of Cooperation. Basic Books, 1984.\nR. Axelrod. The Complexity of Cooperation. Agent-Based Models of Competition and Cooperation. Princeton Studies in Complexity. Princeton University Press, 1997.\nRobert Axtell. Effects of interaction topology and activation regime in\nseveral multi-agent systems. In Proceedings of the Second Conference on\nMultigent Based Simulations, pages 33\u201348, 2000.\nC. Barrett, S. Eubank, and M. Marathe. Modeling and simulation of large\nbiological, information and socio-technical systems: An interaction based\napproach. In D. Goldin, S. Smolka, and P. Wegner, editors, Interactive\nComputation: The New Paradigm. Springer Verlag, 2005.\n\n\f[BHM+ 03] C. Barrett, H. Hunt, M.V. Marathe, S.S. Ravi, D. Rosenkrantz, and\nR. Stearns. Reachability problems for sequential dynamical systems with\nthreshold functions. Theoretical Computer Science, 295(1-3):41\u201364, 2003.\n[BW00]\nJ. Ballot and G. Weisbuch. Introduction: Why simulation in the social\nsciences. Advances in Complex Systems, 3(1\u20134):9\u201316, 2000.\n[Col05]\nA. Colman. Cooperation in multi-player minimal social situations: An experimental investigation. British Academy Larger Research Grants Scheme\nGrant No. LRG-37265, 2004\u20132005.\n[DGG+ 02] M. Dyer, C. Greenhill, L. Goldberg, G. Istrate, and M. Jerrum. The convergence of iterated prisoner's dilemma game. Combinatorics, Probability\nand Computing, 11:135\u2013147, 2002.\n[DIM95] S. Dolev, A. Israeli, and S. Moran. Analyzing expected time by schedulerluck games. I.E.E.E. Transactions on Software Engineering, 21(5):429\u2013439,\n1995.\n[Dol00]\nS. Dolev. Self-stabilization. M.I.T. Press, 2000.\n[Dur06]\nR. Durrett. Random Graph Dynamics. Cambridge University Press, 2006.\n[ECC+ 04] J.M. Epstein, D. Cummings, S. Chakravarty, R. Singa, and D. Burke. Toward a Containment Strategy for Smallpox Bioterror. An Individual-Based\nComputational Approach. Brookings Institution Press, 2004.\n[EGK+ 04] S. Eubank, H. Guclu, V.S. Anil Kumar, M.V. Marathe, A. Srinivasan,\nZ. Toroczkai, and N. Wang. Monitoring and mitigating smallpox epidemics:\nStrategies drawn from a census data instantiated virtual city. Nature, May\n13 2004.\n[Eps99]\nJ. Epstein. Agent-based computational models and generative social science.\nComplexity, 4(5):41\u201360, 1999.\n[Eps07]\nJ. Epstein. Generative Social Science: Studies in Agent-based Computational\nModeling. Princeton University Press, 2007.\n[FM05]\nL. Fribourg and S. Messika. Brief announcement: Coupling for markov decision processes - application to self-stabilization with arbitrary schedulers.\nIn Proceedings of the Twenty-Fourth Annual ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing (PODC'05), July 2005.\n[FMP05] L. Fribourg, S. Messika, and C. Picaronny. Coupling and self-stabilization.\nDistributed Computing (to appear), 2005. A preliminary version has appeared in the Proceedings of DISC'2004, Lecture Notes in Computer Science\nVol. 3274, Springer Verlag.\n[GT05]\nN. Gilbert and K. Troizch. Simulation for social scientists (second edition).\nOpen University Press, 2005.\n[Hed05]\nP. Hedstr\u00f6m. Dissecting the social: on the principles of analytical sociology.\nCambridge University Press, 2005.\n[HG93]\nB. Huberman and N. Glance. Evolutionary games and computer simulations. Proceedings of the National Academy of Science of the USA, 90:7716\u2013\n7718, 1993.\n[HKM62] R. Radloff H. Kelley, J. Thibaut and D. Mundy. The development of cooperation in the minimal social situation. In Psychological Monographs,\nvolume 76. 1962.\n[HS06]\nP. Hedstr\u00f6m and R. Swedberg, editors. Social Mechanisms: An Analytical\nApproach to Social Theory. Cambridge University Press, 2006.\n[Ist06]\nG. Istrate. Adversarial analysis of evolutionary models and multiagent\nsystems: towards theoretical foundations for generative social science.\n(manuscript in progress), 2006.\n\n\f[JLR00]\n\nS. Janson, T. Luczak, and A. Ruczinski. Random Graphs. John Wiley &\nSons, 2000.\n[Kit94]\nJ. Kittock. Emergent conventions and the structure of multi-agent systems.\nIn Lynn Nadel and Daniel Stein, editors, 1993 Lecture Notes in Complex\nSystems: the proceedings of the 1993 Complex Systems Summer School, volume VI of Santa Fe Institute Studies in the Sciences of Complexity. Santa\nFe Institute, Addison Wesley Publishing Co, 1994.\n[Mor00]\nS. Morris. Contagion. The Review of Economic Studies, 67(1):57\u201378, 2000.\n[MR06]\nE. Mossel and S. Roch. Slow emergence of cooperation for win-stay lose-shift\non trees. Machine Learning, 7(1\u20132):7\u201322, 2006.\n[NBW06] M. Newman, A.L. Barab\u00e1si, and D. Watts, editors. The Structure and\nDynamics of Networks. Princeton University Press, 2006.\n[NS93]\nM. Nowak and K. Sigmund. A strategy of win-stay, lose-shift that outperforms tit-for-tat in the prisoner's dilemma game. Nature, 364:56\u201368, 1993.\n[Pos97]\nM. Posch. Win stay-lose shift: An elementary learning rule for normal\nform games. Technical Report 97-06-056, the Santa Fe Institute, 1997.\n[PSV07] R. Pastor-Santorras and A. Vespigniani. Evolution and Structure of the\nInternet: A Statistical Physics approach. Cambridge University Press, 2007.\n[Sid57]\nJ. Sidowski. Reward and punishment in the minimal social situation. Journal of Experimental Psychology, 54:318\u2013326, 1957.\n[ST94]\nY. Shoham and M. Tennenholtz. On the emergence of social conventions:\nmodelling, analysis and simulations. Artificial Intelligence, 1994.\n[TJ06]\nL. Tesfatsion and K.L. Judd, editors. Handbook of Computational Economics. Volume 2: Agent-based computational economics. North Holland,\n2006.\n[TK59]\nJ. Thibaut and H. Kelley. The social Psychology of Groups. Wiley, 1959.\n[TRA]\nTRANSIMS web page. http://transims.tsasa.lanl.gov/.\n[Vri06]\nN. Vriend. ACE models of endogeneous interaction. In L. Tesfatsion\nand K.L. Judd, editors, Handbook of Computational Economics. Volume\n2: Agent-based computational economics. North Holland, 2006.\n[Wei95]\nJ. Weibull. Evolutionary Game Theory. MIT Press, 1995.\n[Wil06]\nA. Wilhite. Economic activity on fixed networks. In L. Tesfatsion and K.L.\nJudd, editors, Handbook of Computational Economics. Volume 2: Agentbased computational economics. North Holland, 2006.\n\n\f"}