{"id": "http://arxiv.org/abs/math/0107154v1", "guidislink": true, "updated": "2001-07-20T22:18:46Z", "updated_parsed": [2001, 7, 20, 22, 18, 46, 4, 201, 0], "published": "2001-07-20T22:18:46Z", "published_parsed": [2001, 7, 20, 22, 18, 46, 4, 201, 0], "title": "Distribution Functions for Random Variables for Ensembles of positive\n  Hermitian Matrices", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0107047%2Cmath%2F0107227%2Cmath%2F0107148%2Cmath%2F0107053%2Cmath%2F0107168%2Cmath%2F0107151%2Cmath%2F0107005%2Cmath%2F0107118%2Cmath%2F0107037%2Cmath%2F0107092%2Cmath%2F0107065%2Cmath%2F0107056%2Cmath%2F0107157%2Cmath%2F0107063%2Cmath%2F0107105%2Cmath%2F0107088%2Cmath%2F0107075%2Cmath%2F0107182%2Cmath%2F0107023%2Cmath%2F0107030%2Cmath%2F0107015%2Cmath%2F0107132%2Cmath%2F0107143%2Cmath%2F0107164%2Cmath%2F0107196%2Cmath%2F0107187%2Cmath%2F0107124%2Cmath%2F0107046%2Cmath%2F0107112%2Cmath%2F0107155%2Cmath%2F0107085%2Cmath%2F0107198%2Cmath%2F0107109%2Cmath%2F0107078%2Cmath%2F0107004%2Cmath%2F0107096%2Cmath%2F0107099%2Cmath%2F0107027%2Cmath%2F0107082%2Cmath%2F0107087%2Cmath%2F0107042%2Cmath%2F0107145%2Cmath%2F0107134%2Cmath%2F0107055%2Cmath%2F0107086%2Cmath%2F0107060%2Cmath%2F0107128%2Cmath%2F0107061%2Cmath%2F0107146%2Cmath%2F0107210%2Cmath%2F0107215%2Cmath%2F0107225%2Cmath%2F0107077%2Cmath%2F0107153%2Cmath%2F0107161%2Cmath%2F0107221%2Cmath%2F0107172%2Cmath%2F0107116%2Cmath%2F0107149%2Cmath%2F0107233%2Cmath%2F0107152%2Cmath%2F0107142%2Cmath%2F0107003%2Cmath%2F0107043%2Cmath%2F0107154%2Cmath%2F0107064%2Cmath%2F0107107%2Cmath%2F0107098%2Cmath%2F0107095%2Cmath%2F0107191%2Cmath%2F0107231%2Cmath%2F0107111%2Cmath%2F0107102%2Cmath%2F0107076%2Cmath%2F0107121%2Cmath%2F0501215%2Cmath%2F0501225%2Cmath%2F0501470%2Cmath%2F0501306%2Cmath%2F0501426%2Cmath%2F0501049%2Cmath%2F0501465%2Cmath%2F0501452%2Cmath%2F0501054%2Cmath%2F0501105%2Cmath%2F0501119%2Cmath%2F0501534%2Cmath%2F0501214%2Cmath%2F0501356%2Cmath%2F0501268%2Cmath%2F0501501%2Cmath%2F0501495%2Cmath%2F0501206%2Cmath%2F0501522%2Cmath%2F0501360%2Cmath%2F0501475%2Cmath%2F0501376%2Cmath%2F0501483%2Cmath%2F0501341%2Cmath%2F0501005%2Cmath%2F0501340&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Distribution Functions for Random Variables for Ensembles of positive\n  Hermitian Matrices"}, "summary": "Distribution functions for random variables that depend on a parameter are\ncomputed asymptotically for ensembles of positive Hermitian matrices. The\ninverse Fourier transform of the distribution is shown to be a Fredholm\ndeterminant of a certain operator that is an analogue of a Wiener-Hopf\noperator. The asymptotic formula shows that up to the terms of order $o(1)$,\nthe distributions are Gaussian.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0107047%2Cmath%2F0107227%2Cmath%2F0107148%2Cmath%2F0107053%2Cmath%2F0107168%2Cmath%2F0107151%2Cmath%2F0107005%2Cmath%2F0107118%2Cmath%2F0107037%2Cmath%2F0107092%2Cmath%2F0107065%2Cmath%2F0107056%2Cmath%2F0107157%2Cmath%2F0107063%2Cmath%2F0107105%2Cmath%2F0107088%2Cmath%2F0107075%2Cmath%2F0107182%2Cmath%2F0107023%2Cmath%2F0107030%2Cmath%2F0107015%2Cmath%2F0107132%2Cmath%2F0107143%2Cmath%2F0107164%2Cmath%2F0107196%2Cmath%2F0107187%2Cmath%2F0107124%2Cmath%2F0107046%2Cmath%2F0107112%2Cmath%2F0107155%2Cmath%2F0107085%2Cmath%2F0107198%2Cmath%2F0107109%2Cmath%2F0107078%2Cmath%2F0107004%2Cmath%2F0107096%2Cmath%2F0107099%2Cmath%2F0107027%2Cmath%2F0107082%2Cmath%2F0107087%2Cmath%2F0107042%2Cmath%2F0107145%2Cmath%2F0107134%2Cmath%2F0107055%2Cmath%2F0107086%2Cmath%2F0107060%2Cmath%2F0107128%2Cmath%2F0107061%2Cmath%2F0107146%2Cmath%2F0107210%2Cmath%2F0107215%2Cmath%2F0107225%2Cmath%2F0107077%2Cmath%2F0107153%2Cmath%2F0107161%2Cmath%2F0107221%2Cmath%2F0107172%2Cmath%2F0107116%2Cmath%2F0107149%2Cmath%2F0107233%2Cmath%2F0107152%2Cmath%2F0107142%2Cmath%2F0107003%2Cmath%2F0107043%2Cmath%2F0107154%2Cmath%2F0107064%2Cmath%2F0107107%2Cmath%2F0107098%2Cmath%2F0107095%2Cmath%2F0107191%2Cmath%2F0107231%2Cmath%2F0107111%2Cmath%2F0107102%2Cmath%2F0107076%2Cmath%2F0107121%2Cmath%2F0501215%2Cmath%2F0501225%2Cmath%2F0501470%2Cmath%2F0501306%2Cmath%2F0501426%2Cmath%2F0501049%2Cmath%2F0501465%2Cmath%2F0501452%2Cmath%2F0501054%2Cmath%2F0501105%2Cmath%2F0501119%2Cmath%2F0501534%2Cmath%2F0501214%2Cmath%2F0501356%2Cmath%2F0501268%2Cmath%2F0501501%2Cmath%2F0501495%2Cmath%2F0501206%2Cmath%2F0501522%2Cmath%2F0501360%2Cmath%2F0501475%2Cmath%2F0501376%2Cmath%2F0501483%2Cmath%2F0501341%2Cmath%2F0501005%2Cmath%2F0501340&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Distribution functions for random variables that depend on a parameter are\ncomputed asymptotically for ensembles of positive Hermitian matrices. The\ninverse Fourier transform of the distribution is shown to be a Fredholm\ndeterminant of a certain operator that is an analogue of a Wiener-Hopf\noperator. The asymptotic formula shows that up to the terms of order $o(1)$,\nthe distributions are Gaussian."}, "authors": ["Estelle L. Basor"], "author_detail": {"name": "Estelle L. Basor"}, "author": "Estelle L. Basor", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1007/s002200050167", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/math/0107154v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0107154v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.FA", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.FA", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.MP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "47A75 82B", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0107154v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0107154v1", "arxiv_comment": null, "journal_reference": "Communications in Mathematical Physics 188, 327-350", "doi": "10.1007/s002200050167", "fulltext": "arXiv:math/0107154v1 [math.FA] 20 Jul 2001\n\nDistribution Functions for Random Variables for\nEnsembles of Positive Hermitian Matrices\nEstelle L. Basor \u2217\nDepartment of Mathematics\nCalifornia Polytechnic State University\nSan Luis Obispo, CA 93407, USA\n\nAbstract\nDistribution functions for random variables that depend on a parameter are computed asymptotically for ensembles of positive Hermitian matrices. The inverse Fourier\ntransform of the distribution is shown to be a Fredholm determinant of a certain operator that is an analogue of a Wiener-Hopf operator. The asymptotic formula shows\nthat up to the terms of order o(1), the distributions are Gaussian.\n\n1\n\nIntroduction\n\nIn the theory of random matrices one is led naturally to consider the probability distribution\non the set of eigenvalues of the matrices. For N \u00d7N random Hermitian matrices one can show\nthat under reasonable assumptions, the probability density that the eigenvalues \u03bb1 , . . . , \u03bbN\nlie in the intervals\n(x1 , x1 + dx1 ), . . . , (xN , xN + dxN )\nis given by the formula\nPN (x1 , . . . , xN ) =\n\n1\ndet K(xi , xj ) |N\ni,j=1\nN!\n\n(1)\n\nN\n\u22121\nX\n\n(2)\n\nwhere\nKN (x, y) =\n\ni=0\n\n\u03c6i (x)\u03c6i (y)\nn\n\n2\n\no\n\nand \u03c6i is obtained by orthonormalizing the sequence xi e\u2212x /2 over R.\nFor N \u00d7 N positive Hermitian matrices the probability density has the samen form except\no\nthat \u03c6i is replaced by the functions obtained by orthonormalizing the sequence x\u03bd/2 e\u2212x/2 xi\nover R+ . We will not describe here exactly how these particular densities arise but instead\nrefer the reader to [8].\n\u2217\n\nebasor@calpoly.edu. Supported in part by NSF Grant DMS-9623278.\n\n1\n\n\fWe can define a random variable on the space of eigenvalues by considering f (x1 , . . . , xN )\nwhere f is any symmetric function of the xi 's. A particular case of interest is a random\nP\nvariable of the form N\ni=1 f (xi ), where f is a function of a real variable. Such a random\nvariable is generally called a linear statistic.\nIn previous work [8, 3, 1, 6], the variance of the random variable was computed in the\nlarge N limit. More precisely, the function f and the kernel KN (x, y) were suitably rescaled\nso that the limit as N \u2192 \u221e of the variance could be computed. The precise details of this\nare in the next section.\nOur goal in this paper is to compute the distribution function for a class of the linear\nstatistics that depend on a parameter \u03b1. We now describe the sections of the paper and\nmain results. In the next section we outline the random matrix theory and show how the\ndistribution functions can be computed using Fredholm determinants. In section 3 we replace\nthe function f (x) in the linear statistic by f\u03b1 (x) = f (x/\u03b1). For random variables of this\ntype we show that the inverse Fourier transform of the distribution function \u03c6\u030c(k) has an\nasymptotic expansion of the form\n2\n\u03c6\u030c(k) \u223c eak +bk\n(3)\n\nas \u03b1 \u2192 \u221e. This of course implies that the actual distribution is asymptotically Gaussian.\nHere a and b depend on f and \u03b1. This is proved for both the Hermitian matrices and positive\nHermitian matrices. In the latter case with \u03bd = \u22121/2, a very simple proof is given in Section\n3. For \u03bd > \u22121/2, a completely different proof is obtained in Section 4.\nMost of the results are obtained by using simple operator theory identities in the theory of Wiener-Hopf operators. The central idea is that the various quantities which yield\ninformation about random variables can all be computed in terms of traces or determinants\nof integral operators. Some of the computations lead directly to a familiar problem in the\ntheory of Wiener-Hopf operators, while others require modifications and generalizations of\nthese results.\n\n2\n\nPreliminaries\n\nIn this section we show how to compute the mean, variance, and inverse Fourier transform\nof the distribution of the random variable. Computations for the mean and variance have\nbeen given before in many places. However, we reproduce all of these here for completeness\nsake and also to highlight the use of operator theory ideas.\nWe begin by considering PN for N \u00d7 N random Hermitian matrices. We want to consider\nlarge matrices and thus we let N \u2192 \u221e, but this leads to a trivial result unless we rescale\nKN in a particular way. We replace KN (x, y) with\n1\n\u221a KN\n2N\n\ny\nx\n\u221a ,\u221a\n2N\n2N\n\n!\n\n.\n\n(4)\n\nRescaling KN is equivalent to rescaling the mean spacing of the eigenvalues. (See [12] for\ndetails.)\nFrom the theory of Hermite polynomials it is easy to see that as N \u2192 \u221e,\n1\n\u221a KN\n2N\n\ny\nx\n\u221a ,\u221a\n2N\n2N\n2\n\n!\n\n\u2192\n\nsin(x \u2212 y)\n.\n\u03c0(x \u2212 y)\n\n(5)\n\n\fThis last function is known as the sine kernel. Now consider a random variable of the form\nN\nX\n\n\u221a\nf (xi 2N )\n\ni=1\n\nwhere in all that follows f is a continuous\u221areal-valued function belonging to L1 (R) and which\nvanishes at \u00b1\u221e. The appearance of the 2N should not be surprising here since the above\nrescaling spreads out the eigenvalues and hence should be reflected in the random variable.\nThe mean \u03bcN is\nZ\nZ X\nN\n\u221a\nf (xi 2N)PN (x1 , . . . , xN )dx1 * * * dxN .\n***\n(6)\ni=1\n\nNow the function PN has the important property [8]\nN!\n(N \u2212 n)!\n\nZ\n\n***\n\nZ\n\nPN (x1 , . . . , xn , xn+1 , . . . , xN )dxn+1 * * * dxN = det K(xi , xj ) |ni,j=1 .\n\n(7)\n\nThus, (6) is easily seen to be\nZ\n\n\u221e\n\n\u2212\u221e\n\n\u221a\nf (x 2N)KN (x, x) dx\n\n(8)\n\n\u221a\nwhich, after changing x to x/ 2N, becomes\nZ\n\ny\nx\n\u221a ,\u221a\n2N\n2N\n\n1\nf (x) \u221a KN\n\u2212\u221e\n2N\n\u221e\n\nThus, as N \u2192 \u221e,\n\n\u03bcN \u2192 \u03bc =\n\nZ\n\n\u221e\n\n\u2212\u221e\n\n!\n\ndx.\n\nf (x)K(x, x) dx\n\n(9)\n\nwhere K(x, y) is the sine kernel.\nA very similar computation for the variance varN f , again using (7), yields\nvar f := lim varN f = \u2212\nN \u2192\u221e\n\nZ Z\n\n2\n\nf (x)f (y)K (x, y) dx dy +\n\nZ\n\nf 2 (x)K(x, x) dx.\n\n(10)\n\nBoth the mean and the variance can be interpreted as traces of certain Wiener-Hopf operators. To see this, consider the operator A(f ) on L2 (\u22121, 1) with kernel\n1 Z\u221e\nf (t)e\u2212it(x\u2212y) dt.\n2\u03c0 \u2212\u221e\n\n(11)\n\nThis operator can easily be seen to be the product F Mf F \u22121 P where P g = \u03c7(\u22121,1) g, Mf g =\nf g and F is the Fourier transform. A moment's thought shows that \u03bc = tr {A(f )} and\nvar f = tr {A(f 2 ) \u2212 (A(f ))2 }.\nA more difficult, yet also straightforward problem, is to find an expression for the distribution function of a random variable of this type. A fundamental formula from probability\ntheory shows that if we call the probability distribution function \u03c6N , then\n\u03c6\u030cN (k) =\n\nZ\n\n\u221e\n\n\u2212\u221e\n\n***\n\nZ\n\n\u221e\n\n\u2212\u221e\n\nik\n\ne\n\nPN\n\nj=1\n\nf (xj\n\n\u221a\n\n3\n\n2N )\n\nPN (x1 , . . . , xN )dx1 * * * dxN .\n\n(12)\n\n\fThus,\n\u03c6\u030cN (k) =\n\nZ\n\n=\n\nZ\n\n=\n\nZ\n\n\u221e\n\n\u2212\u221e\n\u221e\n\n\u2212\u221e\n\u221e\n\n\u2212\u221e\n\n***\n\nZ\n\n***\n\nZ\n\n***\n\nZ\n\nN\nY\n\n\u221e\n\n\u2212\u221e j=1\nN\nY\n\n\u221e\n\neikf (xj\n\n\u221a\n\n((eikf (xj\n\n2N )\n\n\u221a\n\nPN (x1 , . . . , xN ) dx1 * * * dxN\n\n2N )\n\n\u2212\u221e j=1\n\u221e\n\n\u2212\u221e\n\n{1 +\n\nN\nX\n\n(eikf (xj\n\n\u2212 1) + 1)PN (x1 , . . . , xN ) dx1 * * * dxN\n\n\u221a\n2N )\n\nj=1\n\n\u2212 1) +\n\nN\nX\n\n(eikf (xj\n\n\u221a\n2N )\n\nj<l\n\n\u2212 1)(eikf (xl\n\n\u221a\n\n2N )\n\n\u2212 1) + . . .}\n\n\u00d7PN (x1 , . . . , xN ) dx1 * * * dxN\nZ\n1 \u221e ikf (x\u221a2N )\n(e\n= 1+\n\u2212 1)KN (x, x) dx\n1! \u2212\u221e\nZ \u221e Z \u221e\n\u221a\n\u221a\n1\n(eikf (x1 2N ) \u2212 1)(eikf (x2 2N ) \u2212 1) det(KN (xj , xl )) |1\u2264j,l\u22642 dx1 dx2\n+\n2! \u2212\u221e \u2212\u221e\nZ \u221e Y\nN\n\u221a\n1 Z\u221e\n(eikf (xj 2N ) \u2212 1)PN (x1 , . . . , xN ) dx1 * * * dxN .\n***\n+***+\nN! \u2212\u221e\n\u2212\u221e j=1\nIn each integral we rescale to obtain\nZ\n\nZ\n\nZ\n\n1 \u221e \u221e \u2032\nK (x1 , x1 ) dx1 +\nK (x1 , x2 ) dx1 dx2\n2! \u2212\u221e \u2212\u221e\n\u2212\u221e\nZ \u221e\nZ \u221e\n1\n***\nK \u2032 (x1 , . . . , xN ) dx1 * * * dxN\n+***+\nN! \u2212\u221e\n\u2212\u221e\n\n1\n\u03c6\u030cN (k) = 1 +\n1!\n\n\u221e\n\n\u2032\n\nwhere\n\u2032\n\nikf (xj )\n\nK (x1 , . . . , xn ) = det (e\n\nxl\n1\nxj\n\u2212 1)KN ( \u221a , \u221a ) \u221a\n2N\n2N\n2N\n\n!\n\n.\n\n(13)\n\n(14)\n\n1\u2264j,l\u2264n\n\nLetting N \u2192 \u221e we see this is the formula for the Fredholm determinant det(I + K) where\nK has kernel\nsin(x \u2212 y)\nK(x, y) = (eikf (x) \u2212 1)\n.\n(15)\n\u03c0(x \u2212 y)\n\nAs before we can express this last quantity in terms of the operator A(\u03c3)\n\u03c6\u030c(k) = lim \u03c6\u030cN (k) = det(I + A(\u03c3))\nN \u2192\u221e\n\n(16)\n\nwhere \u03c3(x) = eikf (x) \u2212 1.\nThe preceding computations can all be carried out in the case of positive Hermitian\nmatrices. In this case we replace KN (x, y) with\n1\nx y\nKN (\n,\n)\n4N\n4N 4N\nand from the theory of Laguerre polynomials we see that as N \u2192 \u221e\n\u221a\n\u221a\n\u221a \u221a\n\u221a\n\u221a\nJ\u03bd ( x) yJ\u03bd \u2032 ( y) \u2212 xJ\u03bd \u2032 ( x)J\u03bd ( y)\nx y\n1\nKN (\n,\n)\u2192\n4N\n4N 4N\n2(x \u2212 y)\n4\n\n(17)\n\n\fwhere J\u03bd is the Bessel function of order \u03bd. The details of this are found in [13]. The rescaling\nhere forces the eigenvalue density to be bounded near zero and is called \"scaling at the hard\nedge.\" The kernel (17) is known as the Bessel kernel.\nWe can again write the mean, the variance, and the Fourier transform of the distribution\nin terms of operators. This time the relevant operator B(f ) is defined on L2 (0, 1) with kernel\ngiven by\nZ \u221e\n\u221a\nt xyf (t)J\u03bd (tx)J\u03bd (ty) dt.\nK(x, y) =\n(18)\n0\n\u221a\nIf we begin with the linear statistic (the x is merely for convenience, and we again assume\nthat f is continuous, in L1 (R+ ) and vanishes at +\u221e)\nN\nX\ni=1\n\nq\n\nf ( xi 4N),\n\n(19)\n\nthen nearly identical computations show that\n\u03bc = tr B(f )\nvar f = tr {B(f 2 ) \u2212 (B(f ))2 }\n\u03c6\u030c(k) = det(I + B(\u03c3))\nwhere \u03c3 = eikf (x) \u2212 1. We summarize these results in the following:\n\u221a\nP\nTheorem 1 (a) Given a random variable of the form N\ni=1 f (xi 2N ) defined on the space\nof eigenvalues of N \u00d7 N Hermitian matrices with probability distribution given in (1), we\nhave\n\u03bc := limN \u2192\u221e \u03bcN\n= tr (A(f ))\nvar f := limN \u2192\u221e varN f = tr {A(f 2 ) \u2212 (A(f ))2 }\n\u03c6\u030c(k) := limN \u2192\u221e \u03c6\u030cN (k) = det(I + A(\u03c3))\nwhere \u03c3(x) = eikf (x) \u2212 1.\n\u221a\nP\n(b) Given a random variable of the form N\ni=1 f ( xi 4N) defined on the space of eigenvalues of positive N \u00d7 N Hermitian matrices, we have\n\u03bc := limN \u2192\u221e \u03bcN\n= tr (B(f ))\nvar f := limN \u2192\u221e varN f = tr {B(f 2 ) \u2212 (B(f ))2 }\n\u03c6\u030c(k) := limN \u2192\u221e \u03c6\u030cN (k) = det(I + B(\u03c3))\nwhere \u03c3(x) = eikf (x) \u2212 1.\nWhen linear statistics are considered [3, 10], one is often concerned with a statistic of\nP\nthe form N\ni=1 f (xi /\u03b1) where \u03b1 is a real parameter approaching infinity. This is the case, for\nexample, in the study of disordered conductors where large \u03b1 corresponds to a high density\nmetallic regime. The above formulas still hold, of course, but now they depend on the\nparameter. We will call the operators that depend on the parameter \u03b1 by A\u03b1 (f ) and B\u03b1 (f ),\nrespectively. In the next sections we will compute the mean, variance, and distribution\nfunction asymptotically as \u03b1 \u2192 \u221e.\n5\n\n\f3\n\nThe Mean, Variance, and Distribution Function as\n\u03b1\u2192\u221e\n\nFor random Hermitian matrices, computing the various limits are applications of the continuous analogues of the Strong Szeg\u00f6 Limit Theorem. For then, A\u03b1 (f ) is just the classical\nWiener-Hopf operator defined on the interval (\u2212\u03b1, \u03b1), and all of the quantities are known\nasymptotically as \u03b1 \u2192 \u221e. We provide the answers here for completeness.\nTheorem 2 Assume that f \u2208 L1 (R) is continuous, and vanishes at \u00b1\u221e and that in addition\nits Fourier transform f\u02c6 satisfies\nZ\n\n\u221e\n\n|x||f\u02c6(x)|2 dx < \u221e.\n\n\u2212\u221e\n\nThen\n\u03b1\n2\u03c0Z\n\n\u03bc =\n\nvar f = 2\nand\n\n\u001a\n\n\u03b1\n\u03c6\u030c(k) \u223c exp\n2\u03c0\n\nZ\n\n\u221e\n\n\u2212\u221e\n\nZ\n\n\u221e\n\n\u2212\u221e\n\u221e\n\nf (x) dx\n\nxf\u02c6(x)f\u02c6(\u2212x) dx + o(1)\n\n0\n\nikf (x) dx \u2212 k\n\n2\n\nZ\n\n\u221e\n0\n\n\u001b\n\nxf\u02c6(x)f\u02c6(\u2212x) dx .\n\nThe Bessel case is significantly more complicated. There is no corresponding Szeg\u00f6 type\ntheorem. We begin by computing the mean. The operator B\u03b1 (\u03c3) has kernel\nZ\n\n\u221e\n0\n\n\u221a\n\nxytf (t/\u03b1)J\u03bd (tx)J\u03bd (ty) dt.\n\nThus the mean \u03bc is given by\n\u03bc =\n\nZ\n\n1\n\n0\n\n= \u03b12\n= \u03b12\nNow\n\nZ\n\n0\n\nand\n\n1\n\nZ\n\nZ\n\n\u221e\n\n0\n\u221e\n\n0\n\nZ\n\nxtf (t/\u03b1)J\u03bd2 (tx) dt dx\nZ\n\n0\n\n\u221e\n\n0\n\nxJ\u03bd2 (\u03b1tx) dx =\n\n1\n\nxtf (t)J\u03bd2 (\u03b1tx) dx dt\n\nf (t)\n\nZ\n\n0\n\n1\n\nxtJ\u03bd2 (\u03b1tx) dx dt.\n\n(20)\n\no\n1n 2\nJ\u03bd (\u03b1t) \u2212 J\u03bd+1 (\u03b1t)J\u03bd\u22121 (\u03b1t)\n2\n\nJ\u03bd\u22121 (\u03b1t) = \u2212J\u03bd+1 (\u03b1t) +\n\n2\u03bd\nJ\u03bd (\u03b1t).\n\u03b1t\n\nTherefore the integral (20) becomes\n\u03b1\n\nZ\n\n0\n\n\u221e\n\nf (t)\n\n\u001a\n\n\u001b\n\n2\u03bd\n\u03b1t\n2\nJ\u03bd2 (\u03b1t) + J\u03bd+1\n(\u03b1t) \u2212 J\u03bd+1 (\u03b1t)J\u03bd (\u03b1t) dt\n2\n\u03b1t\n6\n\n\for\n\nZ \u221e\no\n\u03b1t n 2\n2\nJ\u03bd (\u03b1t) + J\u03bd+1 (\u03b1t) dt \u2212 \u03b1\u03bd\nf (t)J\u03bd+1 (\u03b1t)J\u03bd (\u03b1t) dt.\n(21)\n\u03b1\nf (t)\n2\n0\n0\nThe first integral equals\nZ\n\u03b1 \u221e\nf (t) dt + o(1)\n(22)\n\u03c0 0\nwhich can be easily seen by using the asymptotic properties of Bessel functions. The second\nintegral is asymptotically\n\u03bd\nf (0) + o(1).\n2\nR\nThis uses the identity 0\u221e J\u03bd+1 (x)J\u03bd (x) dx = 12 .\nThus we have\nZ\n\n\u221e\n\nZ\n\n\u03b1 \u221e\n\u03bd\n(23)\nf (t) dt \u2212 f (0) + o(1).\n\u03c0 0\n2\nFor the variance we refer to [1] where the calculation was already done. There it was\nshown that\nZ\n1 \u221e\nvarf \u223c 2\n|M(f )(2iy)|2 y tanh(\u03c0y)dy.\n(24)\n\u03c0 \u2212\u221e\nWe note however, that this can also be written as\n\u03bc=\n\nvarf \u223c\nR\n\n1 Z\u221e\nx(C(f )2 ) dx\n\u03c02 0\n\n(25)\n\nwhere C(f )(x) = 0\u221e f (y) cos(xy)dy denotes the cosine transform of f . This is an exercise\ninvolving the properties of the Mellin transform, and we leave it to the reader.\nTo compute the distribution function, we first turn our attention to the case where\n\u03bd = \u22121/2. Our operator B\u03b1 (\u03c3) has kernel\nZ\n\n2 \u221e\n\u03c3(t/\u03b1) cos xt cos ytdt\n\u03c0 0\nZ\n1 \u221e\n=\n\u03c3(t/\u03b1)(cos((x \u2212 y)t) + cos((x + y)t)) dt\n\u03c0 0\n\u03b1\n(C(\u03c3)((x \u2212 y)\u03b1) + C(\u03c3)((x + y)\u03b1)).\n=\n\u03c0\nThis is unitarily equivalent to the operator on L2 (0, \u03b1) with kernel\n1\n(C(\u03c3)(x \u2212 y) + C(\u03c3)(x + y)).\n\u03c0\n\n(26)\n\nThe operator with kernel \u03c01 (C(\u03c3)(x \u2212 y)) is the finite Wiener-Hopf operator, usually\ndenoted as W\u03b1 (\u03c3), and the operator with kernel \u03c01 (C(\u03c3)(x + y)) is the Hankel operator\nH\u03b1 (\u03c3). (The only difference between this definition of a finite Wiener-Hopf operator and the\none given earlier for A\u03b1 is the difference in the domain. The two are unitarily equivalent.)\nIf we consider the operators on L2 (0, \u221e) in what follows, we will denote them by W (\u03c3) and\nH(\u03c3) respectively. Also, whenever it is necessary to consider the extension of \u03c3 to the entire\nreal axis, it will always be the even extension.\n7\n\n\fThus the problem of finding the distribution function asymptotically becomes the same\nas computing the Fredholm determinant det(I + B\u03b1 (\u03c3)) = det(I + W\u03b1 (\u03c3) + H\u03b1 (\u03c3)) asymptotically. To do this we need some basic facts about Wiener-Hopf operators and we collect\nthem in the following theorem. These are well-known and can all be found in [4].\nTheorem 3 a) Suppose \u03c6 and \u03c8 are even bounded functions in L1 (R). Then\nW (\u03c6)H(\u03c8) + H(\u03c6)W (\u03c8) = H(\u03c6\u03c8)\nand\nW (\u03c6)W (\u03c8) = W (\u03c6\u03c8) \u2212 H(\u03c6)H(\u03c8).\nb) Suppose \u03c6 and \u03c8 are bounded functions in L1 (R). If the Fourier transform \u03c6\u0302(x)\nvanishes for x negative, then W (\u03c8)W (\u03c6) = W (\u03c6\u03c8) and if \u03c6\u0302(x) vanishes for x positive,\nthen W (\u03c6)W (\u03c8) = W (\u03c6\u03c8).\nWe define W (\u03c3) and H(\u03c3) with \u03c3 = 1 + f and f in L1 by W (\u03c3) = I + W (f ) and\nH(\u03c3) = H(f ). Both of these definitions are natural when thought of in a distributional\nsetting, and the above theorem holds with these definitions as well.\nThe next theorem is of primary importance in the computations that follow.\nTheorem 4 Suppose \u03c6 = 1 + f, \u03c6\u22121 = 1 + g where f and g are bounded even functions.\nThen the inverse of W (\u03c6) + H(\u03c6) is W (\u03c6\u22121) + H(\u03c6\u22121 ).\nProof: Using Theorem 3 parts a) and b) we have,\n(W (\u03c6) + H(\u03c6))(W (\u03c6\u22121) + H(\u03c6\u22121 ))\n= W (\u03c6)W (\u03c6\u22121) + H(\u03c6)W (\u03c6\u22121) + W (\u03c6)H(\u03c6\u22121) + H(\u03c6)H(\u03c6\u22121)\n= I \u2212 H(\u03c6)H(\u03c6\u22121) + H(\u03c6\u03c6\u22121) + H(\u03c6)H(\u03c6\u22121)\n= I + H(1) = I.\nThe same computation holds for (W (\u03c6\u22121 ) + H(\u03c6\u22121 ))(W (\u03c6) + H(\u03c6)), and so we have shown\nthat these operators are inverses of each other.\nIt is well known from the theory of Wiener-Hopf operators that under appropriate conditions det(I + W\u03b1 (\u03c3)) has the asymptotic expansion G(\u03c3)\u03b1 E(\u03c3) where\n1 Z\u221e\nG(\u03c3) = exp\nlog(1 + \u03c3(\u03be))d\u03be\n2\u03c0 \u2212\u221e\nand E(\u03c3) = det(W (\u03c6)W (\u03c6\u22121)) with \u03c6 = 1 + \u03c3. This is simply another version of Theorem\n2. With additional assumptions on \u03c6, it is very easy to adapt this proof to the Bessel case\n\u03bd = \u22121/2 to show that\ndet(I + W\u03b1 (\u03c3) + H\u03b1 (\u03c3)) \u223c G(\u03c3)\u03b1 E \u2032 (\u03c3)\n\n(27)\n\nand E \u2032 (\u03c3) = det((W (\u03c6) + H(\u03c6))W (\u03c6\u22121)). Thus to compute the distribution, we need to\nknow the form of the above determinant. This is contained in the next theorem.\n8\n\n\fTheorem 5 Suppose \u03c3 = eikf \u2212 1 where f is even, continuous, piecewise C 2 and vanishes\nat infinity. Suppose also that f \u2208 L1 and the function\n\u03be \u2192 (1 + \u03be 2 )(|f \u2032\u2032 (\u03be)| + |f \u2032(\u03be)|2 ) \u2208 L2 .\n\nThen as \u03b1 \u2192 \u221e, we have\nZ\n\nZ\n\nik\nk2 \u221e\n\u03b1 \u221e\nikf (x) dx + f (0) \u2212 2\nx|C(f )(x)|2 dx}. (28)\ndet(I + W\u03b1 (\u03c3) + H\u03b1 (\u03c3)) \u223c exp{\n\u03c0 0\n4\n2\u03c0 0\nProof: The conditions on \u03c3 ensure that the above integrals converge, and that the operators\nH(\u03c6) and H(f ) are trace class. The reader is referred to [2] for details. These\nassumptions\nR\nalso guarantee that (27) holds. It is also easy to see that G(\u03c6) = exp{ \u03b1\u03c0 0\u221e ikf (x) dx}. To\ncomplete the proof we need a concrete representation for det((W (\u03c6)+H(\u03c6))W (\u03c6\u22121)). Define\nh(k) = log det((W (\u03c6) + H(\u03c6))W (\u03c6\u22121))\nwhere \u03c6 = eikf . Let h(k) = log det((W (\u03c6) + H(\u03c6))W (\u03c6\u22121)). We need to show the second\nderivative of h is constant in k. A standard formula [5] yields\nh\u2032 (k) = tr((W (\u03c6\u22121 ))\u22121 (W (\u03c6) + H(\u03c6))\u22121 \u00d7\n\nd(W (\u03c6) + H(\u03c6))W (\u03c6\u22121)\n)\ndk\n\n= tr((W (\u03c6\u22121 ))\u22121 (W (\u03c6) + H(\u03c6))\u22121)\n\u00d7{(W (\u03c6) + H(\u03c6))W (\u03c6\u22121(\u2212if )) + W (\u03c6if )W (\u03c6\u22121) + H(\u03c6if )W (\u03c6\u22121)}\n= tr{(W (\u03c6\u22121 ))\u22121 W (\u03c6\u22121 (\u2212if )) + (W (\u03c6\u22121 ))\u22121 W (\u03c6\u22121 )W (\u03c6if )W (\u03c6\u22121)\n+(W (\u03c6\u22121))\u22121 W (\u03c6\u22121 )H(\u03c6if )W (\u03c6\u22121) + (W (\u03c6\u22121))\u22121 H(\u03c6\u22121 )W (\u03c6if )W (\u03c6\u22121)\n+(W (\u03c6\u22121))\u22121 H(\u03c6\u22121 )H(\u03c6if )W (\u03c6\u22121)}.\n\nThis uses Theorem 4. Simplifying further and using the fact that H(\u03c6\u22121) is trace class we\nhave\nh\u2032 (k) = tr{(W (\u03c6\u22121))\u22121 W (\u03c6\u22121(\u2212if )) + W (\u03c6if )W (\u03c6\u22121)\n+H(\u03c6if )W (\u03c6\u22121) + H(\u03c6\u22121)W (\u03c6if ) + H(\u03c6\u22121)H(\u03c6if )}.\nNow apply Theorem 3, part a) and the fact that tr(AB) = tr(BA) to find\nh\u2032\u2032 (k) = tr{(W (\u03c6\u22121 ))\u22121 W ((\u03c6\u22121)(if )2 )\n\u2212(W (\u03c6\u22121 ))\u22121 W (\u03c6\u22121(\u2212if ))(W (\u03c6\u22121 ))\u22121 W (\u03c6\u22121 (\u2212if ))}.\nThe conditions on \u03c6 guarantee that the function \u03c6 has a factorization \u03c6 = (g\u2212 + 1)(g+ + 1)\nsuch that the Fourier transforms of g+ and g\u2212 vanish for positive and negative real values\nrespectively. Then using Theorem 3, part b),it is easy to see that we can write\nW (\u03c6) = W (g\u2212 + 1)W (g+ + 1), W (\u03c6\u22121)\u22121 = W (g+ + 1)W (g\u2212 + 1).\nA repeated application of these identities allows us to write h\u2032\u2032 (k) = trH(if )H(if ), and h\u2032\u2032 (k)\nis independent of k. Thus at this point we have h(k) = ak 2 +bk+c where 2a = \u2212tr((H(f ))2 . A\nR\ndirect computation\nshows that a = \u2212 2\u03c01 2 0\u221e x|C(f )(x)|2 dx. To compute b, notice that h\u2032 (0)\nR\nis trH(if ) = 2\u03c0i 0\u221e C(f (x)) dx. Also h(0) = tr log(I) = 0. Thus the last theorem holds.\n9\n\n\f4\n\nThe General Case\n\nIn this section we show that under certain conditions, the distribution function for general \u03bd\nhas the same form as in the case of \u03bd = \u22121/2. The only difference is in the mean which was\ncomputed in the last section. The attack on the problem is entirely different here. Instead\nof computing determinants asymptotically, we compute the traces of the operators (B\u03b1 (\u03c3))n\nand then piece together the answers to get an answer for the trace of log(I + B\u03b1 (\u03c3)) and\nfrom that to the desired determinant.\nTo begin we need to show that tr f (B\u03b1 (\u03c3)) makes sense for a class of analytic functions\nf . Just as we can associate the Wiener-Hopf operator with the Fourier transform and a\nmultiplication operator, we can also write\nB\u03b1 (\u03c3) = P HM\u03c3 H\nwhere H is the Hankel transform and P is the projection on L2 (0, 1). Since the Hankel\ntransform is unitary on L2 (0, \u221e) ([11]), the operator norm ||B\u03b1 (\u03c3)|| is less than the infinity\nnorm ||\u03c3||\u221e of \u03c3. Thus f (B\u03b1 (\u03c3)) is defined for f analytic on a disk centered at the origin\nwith radius ||\u03c3||\u221e + \u03b4, \u03b4 > 0. The operator B\u03b1 (\u03c3) is also trace class for \u03c3 in L1 by Mercer's\nTheorem ([5] Ch.III) as is f (B\u03b1 (\u03c3)) for f satisfying the above and f (1) = 0.\nWe need some lemmas that will prove to be useful. These may be known already, but\nwe include them for completeness.\nLemma 6 Suppose \u22121 < p < 1, 0 < \u03bb, \u03b4 < 1, \u03bc < 0, p + \u03bc + \u03b4 < 0 and 0 < t < 1. Then\nZ\n\n\u221e\n0\n\nsp (1+s)\u03bc |1\u2212s|\u22121+\u03bb |1\u2212ts|\u22121+\u03b4 ds \u2264 A max(|1\u2212t|\u22121+\u03bb , |1\u2212t|\u22121+\u03b4 ) max(t\u2212\u03bb , t\u2212p\u2212\u03bb ) (29)\n\nwhere A is some constant independent of t.\nProof: We have\nZ\n\n\u221e\n\n0\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1 \u2212 ts|\u22121+\u03b4 ds\nZ\n\n= t\u22121+\u03b4\n\n1\n\n0\n\n+t\u22121+\u03b4\n\u22121+\u03b4\n\n+t\n\nZ\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds\n1/t\n\nZ1\u221e\n1/t\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds.\n\nWe consider each of the above integrals. In each, A is a possibly different constant independent of t but can depend on the other parameters. First,\nZ\n\n0\n\n1\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds\n\n\u2264 |1/t \u2212 1|\n\u2264 A|t \u2212 1|\n\n\u22121+\u03b4\n\nZ\n\n1\n\n0\n\u22121+\u03b4 1\u2212\u03b4\n\nt\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb ds\n.\n\n10\n\n\fNext,\nZ\n\n1/t\n\n1\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds\n\u2212p\n\n\u2264 A max(1, t )\n\nZ\n\n1/t\n\n|1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds\n\n1\n\n= A max(1, t\u2212p )|1/t \u2212 1|\u22121+\u03bb+\u03b4\n= A max(1, t\u2212p )t\u2212\u03bb\u2212\u03b4+1 |1 \u2212 t|\u22121+\u03bb+\u03b4\n\u2264 A max(1, t\u2212p )t\u2212\u03bb\u2212\u03b4+1 |1 \u2212 t|\u22121+\u03bb .\nFinally,\nZ\n\n\u221e\n\n1/t\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1/t \u2212 s|\u22121+\u03b4 ds.\n\n\u2264 |1 \u2212 1/t|\n\n\u22121+\u03bb\n\nZ\n\n\u221e\n\nsp+\u03bc |1/t \u2212 s|\u22121+\u03b4 ds\n\n1/t\n\u22121+\u03bb \u2212p\u2212\u03bc\u2212\u03b4\n\n\u2264 |1 \u2212 1/t|\nt\nA\n\u22121+\u03bb \u2212p\u2212\u03bc\u2212\u03b4\u2212\u03bb+1\n= A|t \u2212 1|\nt\n.\nPutting this together we have that the original integral is bounded by\nA max(|1 \u2212 t|\u22121+\u03bb , |1 \u2212 t|\u22121+\u03b4 ) max(1, t\u2212\u03bb , t\u2212p\u2212\u03bb).\n\nLemma 7 Suppose \u22121 < p < 1, 0 < \u03bb, \u03b4 < 1, \u03bc < 0, p + \u03bc + \u03bb < 0 and t > 1. Then\nZ\n\n0\n\n\u221e\n\nsp (1 + s)\u03bc |1 \u2212 s|\u22121+\u03bb |1 \u2212 ts|\u22121+\u03b4 ds \u2264 A max(|1 \u2212 t|\u22121+\u03bb , |1 \u2212 t|\u22121+\u03b4 ) max(1, t\u2212p ) (30)\n\nwhere A is some constant independent of t.\nProof: The proof of this is almost identical to the previous lemma, and we leave the details\nto the reader.\nLemma 8 Suppose |x| < 1, Re c > 0, Re (c \u2212 b) > 0, and Re (c \u2212 a \u2212 b) < 0. Then the\nhypergeometric function F (a, b, c, x) satisfies the estimate\n|F (a, b, c, x)| \u2264 A|1 \u2212 x|Re (c\u2212a\u2212b)\nwith A independent of x.\nProof: The hypergeometric function satisfies the identity F (a, b, c, x) = (1 \u2212 x)c\u2212a\u2212b F (c \u2212\na, c \u2212 b, c, x). Using Euler's integral formula for F , we have\nZ 1\n\u0393(c)\nF (c \u2212 a, c \u2212 b, c, x) =\ntc\u2212b\u22121 (1 \u2212 t)b\u22121 (1 \u2212 tx)\u2212c+a dx.\n\u0393(b)\u0393(c \u2212 b) 0\n\n11\n\n(31)\n\n\fR\nRe (a+b\u2212c)) .\nThe last integral is bounded by 01 tRe (c\u2212b\u22121) (1 \u2212 t)Re (a+b\u2212c\u22121) dx or \u0393(Re (c\u2212b))\u0393(\n\u0393(Re a)\nWe next find an integral expression for the trace of (B\u03b1 (\u03c3))n . We proceed informally at\nfirst and later state things rigorously. Using (18) we can write this trace as\nZ\n\n\u221e\n\n0\n\n...\n\nZ\n\n\u221e\n\n0\n\nZ\n\n1\n\n0\n\n...\n\nZ\n\nn\n1Y\n\n0 i=1\n\nsi xi \u03c3(xi /\u03b1)J\u03bd (xi si )J\u03bd (xi si+1 ) ds1 . . . dsn dx1 . . . dxn\n\nwhere s1+n = s1 . Let \u03c3\u0302 be the Mellin transform of \u03c3 where c > 0. Then the above becomes\nZ 1Y\nZ \u221eZ 1\nZ c+i\u221e Z \u221e\nn\n1 Z c+i\u221e\n{si xi1\u2212zi J\u03bd (xi si )J\u03bd (xi si+1 )\u03c3\u0302(zi )}\n.\n.\n.\n.\n.\n.\n.\n.\n.\n(2\u03c0i)n c\u2212i\u221e\n0\n0 i=1\n0\n0\nc\u2212i\u221e\n\n\u00d7\u03b1z1 +...zn ds1 . . . dsn dx1 . . . dxn dz1 . . . dzn .\nNow use the formula\n\nZ\n\n\u221e\n\n0\n\nx\u2212\u03bb J\u03bd (ax)J\u03bd (bx)dx\n\n(ab)\u03bd \u0393(\u03bd + 1\u2212\u03bb\n)\n1\n4ab\n1\u2212\u03bb\n2\n, \u03bd + ; 2\u03bd + 1;\n),\n= \u03bb\n\u03bb F (\u03bd +\n2\u03bd\u2212\u03bb+1\n2\n2\n(a + b)2\n2 (a + b)\n\u0393(1 + \u03bd)\u0393(1/2 + 2 )\nwhere F (a, b; c; z) is the hypergeometric function 2 F1 , n times in the integral to get the\nexpression\nZ 1\nZ c+i\u221e\nZ c+i\u221e Z 1\n1\n.\n.\n.\n\u03b1z1 +...+zn\n.\n.\n.\n(2\u03c0i)n c\u2212i\u221e\n0\n0\nc\u2212i\u221e\n\u00d7\n\nn\nY\n\n\u03c3\u0302(zi )\n\ni si+1\ns2\u03bd+1\n\u0393(\u03bd + 1 \u2212 zi /2)F (\u03bd + 1 \u2212 zi /2, \u03bd + 21 ; 2\u03bd + 1; (s4s\n2)\ni\ni +si+1 )\n\n2zi \u22121 \u0393(1 + \u03bd)\u0393(zi /2)(si + si+1 )2\u03bd\u2212zi +2\n\ni=1\n\n\u00d7ds1 . . . dsn dz1 . . . dzn .\nNext we make the change of variables\ns1 = s\u20321\ns2 = s\u20322 s\u20321\n..\n.\nsn = s\u2032n . . . s\u20321\nand the integral becomes\n1\nZ c+i\u221e Z 1 Z 1\nZ\n\u0393(\u03bd + 1 \u2212 zn /2)\n1 Z c+i\u221e\ns1\ns1 ...sn\u22121\nz1 +...+zn n\n.\n.\n.\n.\n.\n.\n(\u03b1/2)\n2\n\u03c3\u0302(z\n)\nn\n(2\u03c0i)n c\u2212i\u221e\n\u0393(1 + \u03bd)\u0393(zn /2)\n0\nc\u2212i\u221e\n0\n0\n\n1\n4sn . . . s2\n\u00d7sz11 +...+zn \u22121 (1 + sn . . . s2 )\u22122\u03bd+zn \u22122 F (\u03bd + 1 \u2212 zn /2, \u03bd + ; 2\u03bd + 1;\n)\n2\n(1 + sn . . . s2 )2\n\u00d7\n\nn\u22121\nY\ni=1\n\n{\n\n\u03c3\u0302(zi )\u0393(\u03bd + 1 \u2212 zi /2) 2\u03bd+1+zi+1 +...zn\u22121\nsi+1\n(1 + si+1 )\u22122\u03bd+zi \u22122\n\u0393(1 + \u03bd)\u0393(zi /2)\n12\n\n\f4si+1\n1\n)}dsn . . . ds1 dz1 . . . dzn .\n\u00d7F (\u03bd + 1 \u2212 zi /2, \u03bd + ; 2\u03bd + 1;\n2\n(1 + si+1 )2\nWrite the inside integral as\nZ\n\n1\n\n0\n\nZ\n\n1\ns1\n\n0\n\n...\n\nZ\n\n1\ns1 ...sn\u22121\n\n. . . dsn . . . d1 \u2212\n\n0\n\nZ\n\n+\n\n1\n\nZ\n\n\u221e\n\n...\n\n0\n\n0\n\nZ\n\n\u221e\n\n0\n\nZ\n\n0\n\n1\n\nZ\n\n\u221e\n0\n\n...\n\nZ\n\n\u221e\n\n0\n\n. . . dsn . . . ds1\n\n. . . dsn . . . ds1 .\n\nThe last integral in the above sum, inserted in the main integral, is the same as tr (B\u03b1 (\u03c3 n )).\nAfter reversing the order of integration to ds1 . . . dsn , the first two terms combine to yield\nlimits of integration\nZ\nZ\nZ\nZ\n\u221e\n\n\u221e\n\n\u2212\n\n0\n\n0\n\n...\n\n1\n\n\u221e\n\nmin(1, s1 ,..., s\n\n0\n\n2\n\n1\n)\n2 ...sn\n\nand then the first integration can be done. The result is that\ntr (B\u03b1 (\u03c3))n = tr B\u03b1 (\u03c3 n ) + C(\u03c3)\nwhere C(\u03c3) is given by the expression\n\u22121\n(2\u03c0i)n\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\nZ\n\nZ\n\n...\n\nc+i\u221e\nc\u2212i\u221e\n\nZ\n\n(\u03b1/2)z1+...+zn\n\nn\nY\n\n\u03c3\u0302(zi )2\u0393(\u03bd + 1 \u2212 zi /2)\n\u0393(1 + \u03bd)\u0393(zi /2)\ni=1\n\n1\n1 \u2212 (min(1, s12 , . . . , s2 ...s\n))z1 +...+zn\nn\nz1 + z2 + . . . + zn\n0\n0\n1\n4sn . . . s2\n\u00d7(1 + sn . . . s2 )\u22122\u03bd+zn \u22122 F (\u03bd + 1 \u2212 zn /2, \u03bd + ; 2\u03bd + 1;\n)\n2\n(1 + sn . . . s2 )2\n\n\u00d7\n\n\u00d7{\n\nn\nY\n\n2\u03bd+1+zi +...zn\u22121\n\nsi\n\ni=2\n\n\u221e\n\n...\n\n\u221e\n\n1\n4si\n(1 + si )\u22122\u03bd+zi\u22121 \u22122 \u00d7 F (\u03bd + 1 \u2212 zi\u22121 /2, \u03bd + ; 2\u03bd + 1;\n)}\n2\n(1 + si )2\n\u00d7dsn . . . ds2 dz1 . . . dzn .\n\nWe next write this integral as\n\u22121\n(2\u03c0i)n\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n...\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\nG(zi )\n\nZ\n\n\u221e\n\n0\n\n...\n\nZ\n\n\u221e\n0\n\nH(zi ; si )dsn . . . ds2 dz1 . . . dzn .\n\nThe idea from here on out is to evaluate this integral asymptotically using complex analysis.\nThis will be done in several stages and by breaking the integral into several parts. To begin\nwe first consider the interior integration\nZ\n\n0\n\n\u221e\n\n...\n\nZ\n\n\u221e\n0\n\nH(zi ; si )ds2 . . . dsn .\n\nConsider this as an integral over R1 \u222a R2 where R1 is a union of disjoint sets, R1 = \u222ani=2 Ui\nsuch that on Ui , si is bounded away from 1 and where R2 is the complement of R1 .\n\n13\n\n\fLemma 9 Suppose that \u22122\u03bd \u2212 1 < 0. The integral of H(zi ; si ) over Ui is bounded and the\nzi variables can be changed in such a way so that the integrated function is analytic in a\nparticular z variable to the left of the imaginary axis.\nProof: For convenience let i = 2 (although the proof is the same for any i) and let z1 + . . . +\n\u2032\nzn = z1 with the other variables remaining the same. Suppose that Re zi = c for i = 3, . . . , n\n\u2032\nand that c > 0. Suppose also that Re z1 = b with |b| < c. We now refer to z1\u2032 as z. Our goal\nis to show that this integral is bounded and that as a function of z is analytic to the left\nof the imaginary axis. By repeated application of Lemma 8, we can say that the integral is\nbounded by a constant times\nZ\n\n|s2 \u22121|\u2265B\n\nZ\n\n\u221e\n\n0\n\n\u00d7\n\n...\n\nZ\n\nn\nY\n\n(1 + si )\u22122\u03bd\u22121 si\n\n\u221e\n\n0\n\n|\n\n1\n))z1 +...+zn\n1 \u2212 (min(1, s12 , . . . , s2 ...s\nn\n|\nz1 + z2 + . . . + zn\n(n\u2212i)c\n\ni=3\n\n|1 \u2212 si |c\u22121\n\n\u00d7s2b\u22122c (1 + s2 )\u22122\u03bd\u22121 |1 \u2212 s2 |b\u22121 |1 \u2212 s2 . . . sn |c\u22121\n\u00d7ds2 . . . dsn .\n\nThis is valid as long as 2\u03bd + 1 > 0 and Re zi \u2212 1/2 < 0, which is the case here if we assume\nthat c is small enough. Next, we estimate\n1\n1 \u2212 (min(1, s12 , . . . , s2 ...s\n))z1 +...+zn\nn\n|\n|\nz1 + z2 + . . . + zn\n\u2032\nby using the fact that |1 \u2212 xz | \u2264 max |z|xRe z | ln x| where the max is taken over the z \u2032 values\non a line connecting 0 and z, x between 0 and 1. Thus, |1 \u2212 xz | \u2264 K|z|xRe z x\u2212\u01eb for some\npositive \u01eb chosen shortly. Inserting this in the integral we have that the integral is bounded\nby a constant times\n\nZ\n\n|s2 \u22121|\u2265B\n\nZ\n\n\u221e\n0\n\n...\n\n\u00d7\n\nZ\n\nn\nY\n\n0\n\nn\n\u221eX\n\n{max(1, (s2 . . . sj )\u01eb (s2 . . . sj )\u2212b+\u01eb )}\n\nj=2\n\n(n\u2212i)c\n\n(1 + si )\u22122\u03bd\u22121 si\n\ni=3\n\n\u00d7sb\u22122c\n(1\n2\n\n|1 \u2212 si |c\u22121\n\n+ s2 )\u22122\u03bd\u22121 |1 \u2212 s2 |b\u22121 |1 \u2212 s2 . . . sn |c\u22121\n\u00d7ds2 . . . dsn .\n\nThe reason for both terms in the \"max\" part of the integral is that b could be either positive\nor negative. Now lets begin with the sn integration. Then the first interior integral has the\nform\nZ \u221e\nspn (1 + sn )\u22122\u03bd\u22121 |1 \u2212 sn |c\u22121 |1 \u2212 s2 . . . sn |\u22121+c dsn .\n0\n\nThe value for p is either \u00b1a where a = |b \u2212 \u01eb| < c. The next step is to apply Lemmas 6\nand 7. We use \u03bb = \u03b4 = c and p as above. The result is that this integral is bounded by a\nconstant times\n|1 \u2212 s2 . . . sn\u22121 |c\u22121 \u00d7 max(1, (s2 . . . sn\u22121 )\u2212c , (s2 . . . sn\u22121 )\u2212c\u2212p (s2 . . . sn\u22121 )\u2212p ).\n14\n\n\fWe collect powers and use the lemmas twice with respect to the sn\u22121 integration and powers\nof p = \u00b1(2c). At the next integration step the powers of p = \u00b13c and so on until we arrive\nat the s2 integration. Here we will have\nZ\n\nsp2 |1 \u2212 s2 |q |1 + s2 |\u22122\u03bd\u22121 ds2\n\n|s2 \u22121|\u2265B\n\nwhere p and q are appropriate powers. These integrals satisfy all the conditions necessary\nfor the lemmas as long as c and b are small enough. We will have at most 2n integrals in this\nprocess. Hence the integral of H over Ui is analytic in the z variable in a strip |Re z| < c by\nthe application of Morera's Theorem and Fubini's Theorem.\nWe remark here that this proof also is easily modified to show that the interchange of\nintegrals done at the beginning of the section are valid and the expression C(\u03c3) is the one\nof interest.\nLemma 10 Suppose that \u03c3 has [\u03bd] + 2 derivatives all in L1 and that that \u22122\u03bd \u2212 1 < 0. Then\nthe integral\nZ\nZ\nZ\nZ\nc+i\u221e\n\nc\u2212i\u221e\n\nc+i\u221e\n\n...\n\nc\u2212i\u221e\n\nG(zi )\n\n...\n\nR1\n\nH(zi ; si )ds2 . . . dsn dz1 . . . dzn\n\nis O(\u03b1\u2212\u03b4 ) where \u03b4 > 0.\nProof: Note that the condition in the hypothesis implies that\nZ\n\nc+\u221e\n\nc\u2212i\u221e\n\n|\u03c3\u0302(z)||z|\u03bd+1/2 < \u221e.\n\n(32)\n\nWe first replace the inside integral with a sum of integrals over Ui . For each of these\nwe change variables as in the last lemma. We can then perform the integration over the z\nvariable by moving it to a line to the left of the imaginary axis. Thus we have that each of\nthese integrals is bounded by a constant times\n\u03b1b\n(\u03c0)n 2b\n\nZ\n\n\u03c3\u0302(z \u2212\n\nP\n\n\u00d7|\n\nZ\n\nb+i\u221e\n\nc+i\u221e\n\nc\u2212i\u221e\n\nb\u2212i\u221e\n\n...\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n|\n\nn\nY\n\n\u03c3\u0302(zi )\u0393(\u03bd + 1 \u2212 zi /2)\n|\n\u0393(1 + \u03bd)\u0393(zi /2)\ni=2\nP\n\nzj )\u0393(\u03bd + 1 \u2212 (z \u2212 zj 6=z zj )/2)\n|dzdz2 . . . dzn .\nP\n\u0393(1 + \u03bd)\u0393((z \u2212 zj 6=z zj )/2)\nzj 6=z\n\nThis last integral is bounded by a product of integrals all of the form\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n|\u03c3\u0302(z)||\n\n\u0393(\u03bd + 1 \u2212 z/2)\n|dz\n\u0393(z/2)\n\nand these in turn are bounded by (32) using the basic asymptotics properties of the Gamma\nfunction.\nWe now turn our attention to the region R2 . To begin we make another change of variables.\n1\n= 1 \u2212 s\u20322\ns2\n15\n\n(33)\n\n\f1\n= 1 \u2212 s\u20322 \u2212 s\u20323\ns2 s3\n..\n.\n1\n= 1 \u2212 s\u20322 \u2212 s\u20323 \u2212 . . . \u2212 s\u2032n .\ns2 . . . sn\n\n(34)\n(35)\n(36)\n\nUnder the change of variables, the region R2 is transformed to a region R3 which can be\nassumed to be a symmetric region containing the origin, and where the sum\n|s2 + . . . + sj | \u2264 a < 1\n(we drop the \"primes\" again) for some a. Notice that the exact form of R1 was unnecessary\nin the previous computation. Thus the integral over R2 is transformed to\nZ\n\nwhere\nI(zi ; si ) =\n\n...\nR3\n\nZ\n\nI(zi ; si )ds2 . . . dsn\n\n1 \u2212 (1 \u2212 max(0, s2, . . . , s2 + . . . + sn ))z1 +...+zn\nz1 + . . . + zn\n\n\u00d7|s2 |z2 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121\n\u00d7f (s2 , . . . , sn , z1 , . . . , zn )\nwhere the function f is smooth in the s variables.\nThe following lemmas will help keep track of the contribution of the R3 integral.\nLemma 11 Suppose Re zi = c, 0 < c < 1, for i \u2265 3. Then the integral\nZ\n\n...\nR3\n\nZ\n\n|s2 |z1 +1 |s3 |z2 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . sn |zn \u22121 ds2 . . . dsn\n\ncan be thought of as an analytic function in the z1 variable that can be extended to a strip\ncontaining the imaginary axis.\nProof: First note that the following integral with z and w real and between zero and one\nsatisfies\nZ b\n|x|z\u22121 |x + y|w\u22121dx \u2264 A|y|z+w\u22121\na\n\nwhere the constant only depends on the z and w variable. A repeated application of this\nestimate in the above integral yields a final integration of\nZ\n\nb\n\na\n\n|s2 |Re z1 +(n\u22122)c ds2 .\n\nThus, once again the analytic continuation argument holds.\n\n16\n\n\fLemma 12 Suppose Re zi = c, 0 < c < 1, for i \u2265 2 and Re z1 = d. Then the integral\nZ\n\n...\nR3\n\nZ\n\n|s2 |z1 |s3 |z2 |s4 |z3 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . sn |zn \u22121 ds2 . . . dsn\n\ncan be thought of as an analytic function in the z1 variable that can be extended to a strip\ncontaining the imaginary axis.\nProof: We begin the integration just as in the previous integral. After n \u2212 3 integrations we\narrive at an integral with an estimate of the form\nZ\n\nb\n\nZ\n\nb\n\na\n\na\n\n|s2 |d |s3 |c |s3 + s2 |(n\u22123)c\u22121 ds2 ds3 .\n\nWe can estimate this by looking at three integrals\nZ\n\nb\n\na\n\nZ\n\nZ\n\n1\n\n|s2 |d+(n\u22122)c |s3 |c |s3 + 1|(n\u22123)c\u22121 ds3 ds2 ,\n\n\u22121\n\nbZ\n\na\n\nand\n\nZ\n\nb/s2\n\n1\n\nb\n\na\n\nZ\n\n\u22121\n\na/s2\n\n|s2 |d+(n\u22122)c |s3 |c |s3 + 1|(n\u22123)c\u22121 ds3 ds2 ,\n|s2 |d+(n\u22122)c |s3 |c |s3 + 1|(n\u22123)c\u22121 ds3 ds2 .\n\nWe can say, for example, that the last integral is less than a constant times\nZ\n\nb\n\na\n\n|s2 |d\u2212(n\u22124)c ds2\n\nand thus is finite for Re z1 in a strip about the imaginary axis. The other two integrals are\nhandled in the same manner. So by our standard argument the analytic extension is defined.\nNow let us return to our function I(zi ; si ). We can write the expression\n1 \u2212 (1 \u2212 max(0, s2 , . . . , s2 + . . . + sn ))z1 +...zn\nz1 + . . . + zn\nas\nmax(0, s2 , . . . , s2 + . . . sn ) + (max(0, s2, . . . , s2 + . . . sn ))2 \u00d7 g(z1 + . . . + zn , s2 , . . . sn )\nwhere the last function is a bounded continuous function in the variables.\nLemma 13 The contribution of\n\u22121\n(2\u03c0i)n\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n...\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\nG(zi )\n\nZ\n\n...\n\nZ\n\nR2\n\n(max(0, s2, . . . , s2 + . . . sn ))2\n\n\u00d7|s2 |z1 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121\n\n\u00d7f (s2 , . . . , sn , z1 , . . . , zn )g(z1 + . . . + zn , s2 , . . . sn )\n\u2212\u03b4\n\nis O(\u03b1 ).\n\n\u00d7dsn . . . ds2 dz1 . . . dzn\n17\n\n\fProof: We simply consider the set where say s1 + s2 + . . . + sj is the maximum of the the\nterms. We then expand the square so that we have a term of the form si sk . We then apply\nthe above lemmas after an appropriate re-ordering of the variables and the lemma holds.\nThe next step is to replace the function f in the expression for I(zi ; si ) with the first term\nof its Taylor expansion. This expansion gives an \"extra\" si (combined with the ones from\nthe max(0, s2, . . . , s2 + . . . + sn )) term in the estimates which, as the above lemmas show,\nis all we need to show that this part of the integral does not contribute in the asymptotic\nexpansion.\nSo we are finally at the one critical term that gives a contribution in the expansion. This\nterm is\nZ c+i\u221e\nZ\nZ\n\u22121 Z c+i\u221e\n.\n.\n.\nG(z\n)\n.\n.\n.\nmax(0, s2 , . . . , s2 + . . . + sn )\ni\n(2\u03c0i)n c\u2212i\u221e\nc\u2212i\u221e\nR3\n\u00d7|s2 |z1 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121\n\u00d7f (0, 0, . . . , 0, z1 , . . . , zn )dsn . . . ds2 dz1 . . . dn .\nWe can easily compute f (0, 0, . . . , 0, z1 , . . . , zn ) to see that it equals\nn\nY\n\n2\u22122\u03bd\u22121 \u0393(2\u03bd + 1)\u0393(\u2212zi /2 + 1/2)\n.\n\u0393(\u03bd + 1/2)\u0393(\u03bd + 1 \u2212 zi /2)\n\n1\n\nWe can simplify further using the formula for G(zi ) and the duplication formula for the\nGamma function to arrive at\nC(\u03c3) =\n\n\u22121\n(2\u03c0i)n\n\nZ\n\nc+i\u221e\nc\u2212i\u221e\n\n\u00d7\n\nZ\n\n...\n...\n\nZ\n\nc+i\u221e\nc\u2212i\u221e\n\nZ\n\nR3\n\n(\u03b1/2)z1+...+zn \u03c0 \u2212n/2\n\nn\nY\n1\n\n\u03c3\u0302(zi )\u0393(\u2212zi /2 + 1/2)\n\u0393(zi /2)\n\nmax(0, s2 , . . . , s2 + . . . + sn )\n\n\u00d7 |s2 |z1 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 ds2 . . . dsn dz1 . . . dzn + O(\u03b1\u2212\u03b4 ).\n\n(37)\n\nNotice that this expression is now independent of \u03bd. Our final steps are to compute the\ncontribution from the above integral and we, by the way, finally have an integral which will\nyield a contribution. We begin with a well-known identity due to Mark Kac, which was used\noriginally to prove the continuous analogue of the Strong Szeg\u00f6 Limit Theorem. It reads\nX\n\nmax(0, a\u03c31 , a\u03c31 + a\u03c32 , . . . , a\u03c31 + . . . + a\u03c3n ) =\n\n\u03c3\n\nn\nXX\n\na\u03c31 \u03b8(a\u03c31 + . . . + a\u03c3k )\n\n\u03c3 k=1\n\nwhere \u03b8(x) = 1 if x > 0 and \u03b8(x) = 0 otherwise and the sums are taken over all permutations\nin n variables.\nBecause of this identity we can rewrite the integral in (37) as\nn\nX\n\n\u22121\nn\nj=2 (2\u03c0i)\n\u00d7\n\nZ\n\n...\n\nZ\n\nZ\n\nc+i\u221e\nc\u2212i\u221e\n\nR3 \u2229{s2 +...+sj >0}\n\n...\n\nZ\n\nc+i\u221e\nc\u2212i\u221e\n\n(\u03b1/2)\n\nz1 +...+zn\n\n\u03c0\n\n\u2212n/2\n\nn\nY\n1\n\n\u03c3\u0302(zi )\u0393(\u2212zi /2 + 1/2)\n\u0393(zi /2)\n\ns2 |s2 |z1 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 ds2 . . . dsn dz1 . . . . dzn . (38)\n18\n\n\fIt is straightforward to see how this identity can be used if the integrand is symmetric in\nthe variables. In our case, the integrand is not obviously symmetric in the variables, but can\nalways be made so by changing the z variables. Thus we can apply the identity.\nWe once again consider the inner integral and call z = z1 + . . . + zn leaving the other\nvariables as is, and show how this inner integral can be thought of as analytic in z in a strip\ncontaining the imaginary axis. The difference is that in this case there will be a pole at\nz = 0.\nNow we suppose that j > 2. For j = 2 the following computation is almost identical and\nthe conclusion is the same. Let us rewrite the inner integral in (38) as two integrals\nZ\n\nb\n\n0\n\nZ\n\n+\n\nZ\n0\n\n\u2212b\n\n...\nB\n\nZ\n\nZ\n\n...\nB\n\ns2 |s2 |z\u2212z2\u2212z3 \u2212...zn \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 dsn . . . ds2\nZ\n\ns2 |s2 |z\u2212z2 \u2212z3 \u2212...zn \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 dsn . . . ds2\n\nwhere B is some n \u2212 2 dimensional set. In the first (the computations for the second integral\nbeing almost identical) of these we make yet another change of variables:\ns3 = s\u20323 s\u20322\n..\n.\nsn = s\u2032n s\u20322\nto arrive at\nZ\n\nb\n\n0\n\nsz\u22121\n2\n\nZ\n\n...\nB/s2\n\nZ\n\n|s3 |z2 \u22121 . . . |sn |zn\u22121 \u22121 |1 + s3 + . . . + sn |zn \u22121 dsn . . . ds3 ds2 .\n\nThe original set R3 was chosen to be symmetric and contain the origin. So here we chose\nit to be something convenient, say a cube C with size length l. With this choice we can\nwrite B/s2 as C/s2 \u2229 {s3 + . . . + sn + 1 > 0}. Next integrate by parts with respect to the s2\nvariable. The result is that the above integral becomes:\nsz2 k(s2 )\nwhere\nk(s2 ) =\n\nZ\n\n...\nB/s2\n\nZ\n\n\u2212\n\nZ\n\n0\n\nb\n\nsz2 d/ds2(k(s2 ))ds2\n\n|s3 |z2 \u22121 . . . |sn |zn\u22121 \u22121 |1 + s3 + . . . + sn |zn \u22121 dsn . . . ds3 .\n\nThe function k(s2 ) has a derivative given by the formula\nk \u2032 (s2 ) = \u2212s\u22121\n2\n\nZ\n\nD\n\nf (s3 , . . . , sn ) (~n * s\u22121\n2 (s3 , . . . , sn ))dS\n\nwhere D is the boundary of the set C/s2 which lies in the half-space defined by {s3 + . . . +\nsn + 1 > 0}, the vector ~n is the outward normal to the surface, the function f is simply the\none given in the above integral restricted to the surface, and dS is surface measure. We can\n(n\u22122)c\nestimate the derivative of k(s2 ) on any boundary edge to be at most a constant times s2\nfor Re zi = c. Thus we have proved the following:\n19\n\n\fLemma 14 The function of z defined by\nZ\n\nb\n\n0\n\n+\n\nZ\n\nZ\n0\n\n\u2212b\n\n...\nB\n\nZ\n\nZ\n\n...\nB\n\ns2 |s2 |z\u2212z2\u2212z3 \u2212...zn \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 dsn . . . ds2\nZ\n\ns2 |s2 |z\u2212z2 \u2212z3 \u2212...zn \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 dsn . . . ds2\n\nis analytic in a strip containing the imaginary axis except at the point z = 0. Further, the\ncontribution of this integral with the z integration moved to a line to the left of the axis is\ngiven by the residue at z = 0 plus O(\u03b1\u2212\u03b4 ).\nWe note here that there are no other poles given our conditions on \u03c3 , ( 32) and the\nformula for G(zi ).\nFor j > 2, the above computation also shows exactly what the residue is, namely:\nZ\n\n...\n\nZ\n\n|s3 |z2 \u22121 . . . |sn |zn\u22121 \u22121 |1 + s3 + . . . + sn |zn \u22121 dsn . . . ds3\n\nRn\u22122 \u2229{s3 +...+sj >\u22121}\n\nZ\n\n\u2212\n\n...\n\nZ\n\n|s3 |z2 \u22121 . . . |sn |zn\u22121 \u22121 | \u2212 1 + s3 + . . . + sn |zn \u22121 dsn . . . ds3 .\n\nRn\u22122 \u2229{s3 +...+sj >\u22121}\n\nTo find an explicit formula for this integral we start with the following formula that can\nbe easily proved using formulas for the Beta function.\nFor\n0 < Re p, Re q < 1, Re (p + q) < 1\nZ\n\n\u221e\n\u2212\u221e\n\n|x|p\u22121|x + y|q\u22121dx = |y|p+q\u22121\n\n2\u0393(p)\u0393(q) cos(\u03c0p/2) cos(\u03c0q/2)\n.\n\u0393(p + q) cos((p + q)\u03c0/2)\n\n(39)\n\nDefine t(p, q) to be\n2\u0393(p)\u0393(q) cos(\u03c0p/2) cos(\u03c0q/2)\n.\n\u0393(p + q) cos((p + q)\u03c0/2)\nThe residue is then (B is the Beta function)\nB(z2 + . . . + zj\u22121 , zj + . . . + zn )\n\nn\u22121\nY\n\nt(zk , zn + . . . + zk+1 )\n\nk=j\n\nj\u22122\nY\n\nt(zk , zk+1 + . . . + zj\u22121 ).\n\nk=2\n\nWe leave this as an exercise to the reader. For j = 2 the residue can also be easily computed\nusing the definition of t(p, q) and it is seen to be\nn\u22121\nY\n\nt(zk , zn + . . . + zk+1 ).\n\nk=2\n\nCombining all of the above results we are left with the following theorem.\n\n20\n\n\fTheorem 15 Suppose \u03c3 has [\u03bd] + 2 continuous derivatives in L1 . Then\ntr (B\u03b1 (\u03c3))n = tr B\u03b1 (\u03c3 n ) + C(\u03c3)\nwhere\n\nX1\n\u22121 n\u22121\nC(\u03c3) = 2\n\u03c0 j=1 j\n\nZ\n\n\u221e\n\n0\n\nxC(\u03c3 j )(x)C(\u03c3 n\u2212j )(x)dx + o(1).\n\nProof: Recall we were computing the integral\nn\nX\n\n\u22121\nn\nj=2 (2\u03c0i)\n\u00d7\n\nZ\n\n...\n\nZ\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\nR3 \u2229{s2 +...+sj >0}\n\n...\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n(\u03b1/2)\n\nz1 +...+zn\n\n\u03c0\n\n\u2212n/2\n\nn\nY\n1\n\n\u03c3\u0302(zi )\u0393(zi /2 + 1/2)\n\u0393(zi /2)\n\ns2 |s2 |z1 \u22121 . . . |sn |zn\u22121 \u22121 |s2 + . . . + sn |zn \u22121 ds2 . . . dsn dz1 . . . . dzn . (40)\n\nFor each j we rename the variables and compute the residue as above. For j > 2 the residue\nis\nZ c+i\u221e\nZ c+i\u221e\nn\nY\n\u22121\n\u03c3\u0302(zi )\u0393(\u2212zi /2 + 1/2)\n\u2212n/2\n.\n.\n.\n\u03c0\nn\u22121\n(2\u03c0i)\n\u0393(zi /2)\nc\u2212i\u221e\nc\u2212i\u221e\n2\n\u00d7\n\n\u03c3\u0302(\u2212z2 \u2212 . . . \u2212 zn )\u0393((z2 + . . . + zn )/2 + 1/2)\nB(z2 + . . . + zj\u22121 , zj + . . . + zn )\n\u0393((\u2212z2 \u2212 . . . \u2212 zn )/2)\n\u00d7\n\nn\u22121\nY\n\nt(zk , zn + . . . + zk+1 )\n\nk=j\n\nj\u22122\nY\n\nt(zk , zk+1 + . . . + zj\u22121 )dz2 . . . dzn .\n\n(41)\n\nk=2\n\nNotice that\nt(p, q)t(p + q, r) = 22\n\n\u0393(p)\u0393(q)\u0393(r) cos(p) cos(q) cos(r)\n.\n\u0393(p + q + r) cos((p + q + r)\u03c0/2)\n\nUsing this identity in (4) we have that the above integral is\n\u22121\n(2\u03c0i)n\u22121\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n...\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n2n\u22123\u03c0 \u2212n/2\n\nn\nY\n\n\u03c3\u0302(zi )\u0393(zi ) cos(zi \u03c0/2)\u0393(\u2212zi /2 + 1/2)\n\u0393(zi /2)\ni=2\n\n\u03c3\u0302(\u2212z2 \u2212 . . . \u2212 zn )\u0393((z2 + . . . + zn )/2 + 1/2)\ndz2 . . . dzn .\n\u0393((\u2212z2 \u2212 . . . \u2212 zn )/2)\u0393(z2 + . . . + zn ) cos((z2 + . . . + zj\u22121 )\u03c0/2) cos((zj + . . . + zn )\u03c0/2)\n(42)\nFrom the duplication formula for the Gamma function, this can be simplified to\n\u00d7\n\nZ c+i\u221e\nn\nY\n\u22121 Z c+i\u221e\n\u22122 \u22121\n\u03c3\u0302(zi )\n.\n.\n.\n2\n\u03c0\n(2\u03c0i)n\u22121 c\u2212i\u221e\nc\u2212i\u221e\ni=2\n\n\u00d7\n\n\u03c3\u0302(\u2212z2 \u2212 . . . \u2212 zn )(z2 + . . . + zn ) sin((z2 + . . . + zn )\u03c0/2)\ndz2 . . . dzn .\ncos((z2 + . . . + zj\u22121 )\u03c0/2) cos((zj + . . . + zn )\u03c0/2)\n\nNow we change variables with\nzj\u22121 = z2 + . . . + zj\u22121 , zn = zj + . . . + zn\n21\n\n(43)\n\n\fand the above integral becomes\n\u22121\n(2\u03c0i)n\u22121\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n...\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n2\u22122 \u03c0 \u22121 (\n\nj\u22122\nY\n\n\u03c3\u0302(zi ))\u03c3\u0302(zj\u22121 \u2212 . . . \u2212 z2 )\n\ni=2\n\n\u00d7 \u03c3\u0302(zn \u2212 . . . \u2212 zj )\u03c3\u0302(\u2212zj\u22121 \u2212 zn )(zj\u22121 + zn )\n\nn\u22121\nY\n\n\u03c3\u0302(zi )\n\ni=j\n\nsin((zj\u22121 + zn )\u03c0/2)\ndz2 . . . dzn .\ncos(zj\u22121 \u03c0/2) cos(zn \u03c0/2)\n\n(44)\n\nThe convolution theorem for the Mellin transform shows that this can be reduced to the\nintegral\nZ c+i\u221e Z c+i\u221e\n\u22121\n\u02c6 (zj\u22121 )\u03c3 n\u2212j\n\u02c6 (zn )\n2\u22122 \u03c0 \u22121 \u03c3 j\u22122\n(2\u03c0i)2 c\u2212i\u221e c\u2212i\u221e\n\u00d7 \u03c3\u0302(\u2212zj\u22121 \u2212 zn )(zj\u22121 + zn )\n\nsin((zj\u22121 + zn )\u03c0/2)\ndzj\u22121 dzn .\ncos(zj\u22121 \u03c0/2) cos(zn \u03c0/2)\n\n(45)\n\nNotice this can also be written as\n\u22121\n(2\u03c0i)2\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\n\u02c6 (zj\u22121)\u03c3 n\u2212j+1\n\u02c6 (zn )\n2\u22122 \u03c0 \u22121 \u03c3 j\u22122\n\n\u00d7 \u03c3\u0302(\u2212zj\u22121 \u2212 zn )(zj\u22121 + zn )\n\nsin(zj\u22121 \u03c0/2)\ndzj\u22121 dzn\ncos(zj\u22121\u03c0/2)\n\n(46)\n\n1 Z c+i\u221e Z c+i\u221e \u22122 \u22121 j\u22122\n\u02c6 (zn )\n2 \u03c0 \u03c3 \u02c6 (zj\u22121 )\u03c3 n\u2212j+1\n\u2212\n(2\u03c0i)2 c\u2212i\u221e c\u2212i\u221e\n\u00d7 \u03c3\u0302(\u2212zj\u22121 \u2212 zn )(zj\u22121 + zn )\n\nsin(zn \u03c0/2)\ndzj\u22121 dzn .\ncos(zn \u03c0/2)\n\n(47)\n\nBefore we proceed further we need three formulas from the theory of Mellin transforms.\nThese are\nZ \u221e\nthe Mellin transform of\n\u03c6(x)dx = z \u22121 \u03a6(z + 1)\nx\n\nwhere \u03a6 is the transform of \u03c6,\n\nthe Mellin transform of x\u03c6\u2032 (x) = \u2212z\u03a6(z)\nwhere \u03a6 is the transform of \u03c6, and finally\n2\n\u03c0\n\nZ\n\n\u221e\n\n0\n\n1\nxC(\u03c6)(x)C(\u03c8)(x)dx =\n2\u03c0i\n\nZ\n\nc+\u221e\n\nc\u2212i\u221e\n\n\u03a6(z)\u03a8(\u2212z)z tan(z\u03c0/2)dz.\n\nThese can be found in any standard table of transforms, although the third requires a\nstraightforward computation combined with the convolution theorem.\nSo now we apply the second formula along with convolution with respect to the zn variable\nand we have for each 2 < j < n\nsin(zj\u22121 \u03c0/2)\n1 Z c+i\u221e d\nd \u03c3 \u2032 (\u2212z\nj\u22122 (z\nn\u2212j+1\n\u03c3\n)\nx\u03c3\n)\ndzj\u22121\nj\u22121\nj\u22121\n8\u03c0 2 i c\u2212i\u221e\ncos(zj\u22121 \u03c0/2)\n22\n\n(48)\n\n\f1\n+ 2\n8\u03c0 i\n\nZ\n\nc+i\u221e\n\nc\u2212i\u221e\n\nd (z\nd\nj\u22122 \u03c3 \u2032 (\u2212z\n\u03c3 n\u2212j+1\nj\u22121 )x\u03c3\nj\u22121 )\n\nsin(zj\u22121 \u03c0/2)\ndzj\u22121 .\ncos(zj\u22121 \u03c0/2)\n\n(49)\n\nNext apply the first formula after inserting a factor of zj\u22121 /zj\u22121 to write the above as\n1\n2\u03c0 2\n+\nor\n\nZ\n\n1\n2\u03c0 2\n\n\u221e\n\n0\n\nZ\n\n0\n\nxC(\u03c3\n\n\u221e\n\nj\u22122\n\n)(x)C(\n\nZ\n\n\u221e\n\nx\n\nxC(\u03c3 n\u2212j+1 )(x)C(\nZ\n\n\u03c3 n\u2212j+1\u03c3 \u2032 )(x)dx\n\n(50)\n\nZ\n\n(51)\n\n\u221e\n\nx\n\n\u03c3 j\u22122 \u03c3 \u2032 )(x)dx\n\n\u221e\n\u22121\n1\nxC(\u03c3 j\u22122 )(x)C(\u03c3 n\u2212j+2(x) dx\n(52)\n2\u03c0 2 n \u2212 j + 2 0\nZ \u221e\n\u22121 1\n+ 2\nxC(\u03c3 j\u22121 )(x)C(\u03c3 n\u2212j+1 (x) dx.\n(53)\n2\u03c0 j \u2212 1 0\nWe can do the j = 2, j = n cases separately just as easily (the above formulas are not even\nall required in that case) and putting the two cases together and reindexing when necessary\nwe arrive at the conclusion of the theorem.\nOur final step is to extend this to functions other than powers. The standard uniformity\narguments used in the Wiener-Hopf theory apply here if we can show that\n\n||tr f (B\u03b1 (\u03c3)) \u2212 tr B\u03b1 (f (\u03c3))||1 = O(1)\nuniformly for \u03c3 replaced by 1 \u2212 \u03bb + \u03bb\u03c3 and \u03bb in some complex neighborhood of [0, 1].\nThe details of this are found in [14]. The norm above is the trace norm. Given sufficient\nanalyticity conditions on f , it is only necessary to prove ||B\u03b1 (\u03c31 )B\u03b1 (\u03c32 )\u2212B\u03b1 (\u03c31 \u03c32 )||1 = O(1)\nwhere the O(1) here depends on properites of \u03c3i . A trace norm of a product can always be\nestimated by the product of two Hilbert-Schmidt norms and in this case we need to estimate\nthe Hilbert Schmidt norm of the operator with kernel\nZ \u221e\n\u221a\nX(1,\u221e) (z)\n\u03c3i (t/\u03b1) xztJ\u03bd (xt)J\u03bd (tz)dt.\n0\n\nUsing integration by parts, and integration formulas for Bessel functions this is easily estimated to be bounded. For analogous details see [14]. Thus for suitably defined f we can\nextend our previous theorem to the more general case. The f of interest is log(1 + z). This\nwill satisfy the necessary analyticity conditions if we consider small enough k. The necessary\nconditions are collected in the following:\nTheorem 16 Suppose f is a real-valued function with [\u03bd] + 2 derivatives all contained in\nL1 . Then for sufficiently small k (say k < ||\u03c3||\u22121\n\u221e)\n(\n\n)\n\u03b1Z \u221e\nik\u03bd\nk2 Z \u221e\n2\n\u03c6\u030c(k) \u223c exp\nikf (x)dx \u2212\nxC(f ) (x)dx .\nf (0) \u2212 2\n\u03c0 0\n2\n2\u03c0 0\n\nProof: The form of the answer follows from the computation of the mean given earlier and\nfrom the fact that the constant term in the previous theorem is exactly half of the answer\nin Szeg\u00f6's Theorem. Thus the above answer for the log function must be half as well.\nThe author would like to thank both Craig Tracy and Harold Widom for many useful\nand helpful conversations.\n23\n\n\fReferences\n[1] E. L. Basor, C. A. Tracy. Variance calculations and the Bessel kernel, J. Statistical\nPhysics 73 (1993).\n[2] E. L. Basor, H. Widom. Toeplitz and Wiener-Hopf determinants with piecewise continuous symbols, J.Functional Analysis 50 (1983) 387-413.\n[3] C. W. J. Beenakker. Universality in the random-matrix theory of quantum transport,\nPhys. Rev. Letts. 70 (1993) 1155-1158.\n[4] A. B\u00f6ttcher, B. Silbermann. Analysis of Toeplitz Operators, Springer, Berlin, 1990.\n[5] I.C. Gohberg, M.G. Krein. Introduction to the Theory of Linear Nonselfadjoint Operators, vol 18, Translations of Mathematical Monographs, Amer Math Soc, 1969.\n[6] K. Johannsson. On Fluctuations of Eigenvalues of Random Hermitian Matrices,\npreprint.\n[7] M. Kac,. Toeplitz matrices, translation kernels, and a related problem in probability\ntheory. Duke Math.J. 21 (1954) 501-509.\n[8] M. L. Mehta. Random Matrices, Academic Press, San Diego, 1991.\n[9] P. Sarnak. Arithmetic quantum chaos, preprint.\n[10] A. D. Stone, P. A. Mello, K. A. Muttalib, and J.-L. Pichard, Random theory and maximum entropy models for disordered conductors, in Mesoscopic Phenomena in Solids,\neds. B. L. Altshuler, P. A. Lee, and R. A. Webb, North-Holland, Amsterdam, 1991.\n(Ch. 9, pp. 369\u2013448.)\n[11] A. Unterberger, J. Unterberger. La Serie discrete de SL(2, R) et les operateurs pseudodifferentiels sur une demi-droite, Ann. Scient. Ec Norm. Sup. 4 serie, 17, (1984) 83-116.\n[12] C. A. Tracy, H. Widom. Introduction to random matrices, in Proc. 8th Scheveningen\nConf., Springer Lecture Notes in Physics, 1993.\n[13] C. A. Tracy, H.Widom. Level spacing distributions and the Bessel kernel, Commun.\nMath Phys. 161 (1994) 289-309.\n[14] H. Widom. Szeg\u00f6's limit theorem: the higher-dimensional matrix case, J. of Func. Anal.\n39 (1980) 182-198.\n\n24\n\n\f"}