{"id": "http://arxiv.org/abs/0712.0179v1", "guidislink": true, "updated": "2007-12-03T19:20:44Z", "updated_parsed": [2007, 12, 3, 19, 20, 44, 0, 337, 0], "published": "2007-12-03T19:20:44Z", "published_parsed": [2007, 12, 3, 19, 20, 44, 0, 337, 0], "title": "Rates of convergence for minimal distances in the central limit theorem\n  under projective criteria", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0712.0990%2C0712.3200%2C0712.0207%2C0712.1374%2C0712.2179%2C0712.4163%2C0712.1525%2C0712.2662%2C0712.0476%2C0712.4131%2C0712.0590%2C0712.0179%2C0712.1185%2C0712.0792%2C0712.1862%2C0712.1703%2C0712.3911%2C0712.2440%2C0712.3661%2C0712.3041%2C0712.1389%2C0712.0465%2C0712.0192%2C0712.3949%2C0712.2183%2C0712.3567%2C0712.2984%2C0712.3750%2C0712.3941%2C0712.0421%2C0712.2306%2C0712.3262%2C0712.3365%2C0712.0865%2C0712.3746%2C0712.1454%2C0712.1902%2C0712.2387%2C0712.2198%2C0712.1979%2C0712.1913%2C0712.3438%2C0712.3705%2C0712.0282%2C0712.1174%2C0712.3084%2C0712.3685%2C0712.3066%2C0712.0271%2C0712.3996%2C0712.1883%2C0712.0902%2C0712.3743%2C0712.2171%2C0712.0059%2C0712.3467%2C0712.1860%2C0712.1988%2C0712.0778%2C0712.3360%2C0712.1864%2C0712.2467%2C0712.1541%2C0712.1380%2C0712.0136%2C0712.3625%2C0712.0946%2C0712.2875%2C0712.0114%2C0712.1281%2C0712.2509%2C0712.3759%2C0712.0331%2C0712.2537%2C0712.4157%2C0712.0545%2C0712.0929%2C0712.2918%2C0712.0934%2C0712.1372%2C0712.1635%2C0712.4186%2C0712.1952%2C0712.3614%2C0712.0063%2C0712.3545%2C0712.0351%2C0712.1804%2C0712.3894%2C0712.3791%2C0712.4363%2C0712.3019%2C0712.1833%2C0712.4069%2C0712.0283%2C0712.3646%2C0712.1068%2C0712.3023%2C0712.2836%2C0712.3872%2C0712.1015&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Rates of convergence for minimal distances in the central limit theorem\n  under projective criteria"}, "summary": "In this paper, we give estimates of ideal or minimal distances between the\ndistribution of the normalized partial sum and the limiting Gaussian\ndistribution for stationary martingale difference sequences or stationary\nsequences satisfying projective criteria. Applications to functions of linear\nprocesses and to functions of expanding maps of the interval are given.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0712.0990%2C0712.3200%2C0712.0207%2C0712.1374%2C0712.2179%2C0712.4163%2C0712.1525%2C0712.2662%2C0712.0476%2C0712.4131%2C0712.0590%2C0712.0179%2C0712.1185%2C0712.0792%2C0712.1862%2C0712.1703%2C0712.3911%2C0712.2440%2C0712.3661%2C0712.3041%2C0712.1389%2C0712.0465%2C0712.0192%2C0712.3949%2C0712.2183%2C0712.3567%2C0712.2984%2C0712.3750%2C0712.3941%2C0712.0421%2C0712.2306%2C0712.3262%2C0712.3365%2C0712.0865%2C0712.3746%2C0712.1454%2C0712.1902%2C0712.2387%2C0712.2198%2C0712.1979%2C0712.1913%2C0712.3438%2C0712.3705%2C0712.0282%2C0712.1174%2C0712.3084%2C0712.3685%2C0712.3066%2C0712.0271%2C0712.3996%2C0712.1883%2C0712.0902%2C0712.3743%2C0712.2171%2C0712.0059%2C0712.3467%2C0712.1860%2C0712.1988%2C0712.0778%2C0712.3360%2C0712.1864%2C0712.2467%2C0712.1541%2C0712.1380%2C0712.0136%2C0712.3625%2C0712.0946%2C0712.2875%2C0712.0114%2C0712.1281%2C0712.2509%2C0712.3759%2C0712.0331%2C0712.2537%2C0712.4157%2C0712.0545%2C0712.0929%2C0712.2918%2C0712.0934%2C0712.1372%2C0712.1635%2C0712.4186%2C0712.1952%2C0712.3614%2C0712.0063%2C0712.3545%2C0712.0351%2C0712.1804%2C0712.3894%2C0712.3791%2C0712.4363%2C0712.3019%2C0712.1833%2C0712.4069%2C0712.0283%2C0712.3646%2C0712.1068%2C0712.3023%2C0712.2836%2C0712.3872%2C0712.1015&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper, we give estimates of ideal or minimal distances between the\ndistribution of the normalized partial sum and the limiting Gaussian\ndistribution for stationary martingale difference sequences or stationary\nsequences satisfying projective criteria. Applications to functions of linear\nprocesses and to functions of expanding maps of the interval are given."}, "authors": ["J\u00e9r\u00f4me Dedecker", "Florence Merlev\u00e8de", "Emmanuel Rio"], "author_detail": {"name": "Emmanuel Rio"}, "author": "Emmanuel Rio", "links": [{"href": "http://arxiv.org/abs/0712.0179v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0712.0179v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60 F 05", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0712.0179v1", "affiliation": "LM-Versailles", "arxiv_url": "http://arxiv.org/abs/0712.0179v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Rates of convergence for minimal distances in the central\nlimit theorem under projective criteria\nJ\u00e9r\u00f4me Dedecker a , Florence Merlev\u00e8de\n\nb\n\nand Emmanuel Rio\n\nc\n\na\n\narXiv:0712.0179v1 [math.ST] 3 Dec 2007\n\nUniversit\u00e9 Paris 6, LSTA, 175 rue du Chevaleret, 75013 Paris, FRANCE.\nE-mail: dedecker@ccr.jussieu.fr\nb\n\nUniversit\u00e9 Paris 6, LPMA and C.N.R.S UMR 7599, 175 rue du Chevaleret, 75013 Paris,\nFRANCE. E-mail: merleve@ccr.jussieu.fr\nc\n\nUniversit\u00e9 de Versailles, Laboratoire de math\u00e9matiques, UMR 8100 CNRS, B\u00e2timent Fermat,\n45 Avenue des Etats-Unis, 78035 Versailles, FRANCE. E-mail: rio@math.uvsq.fr\n\nKey words: Minimal and ideal distances, rates of convergence, Martingale difference sequences, stationary sequences, projective criteria, weak dependence, uniform mixing.\nMathematical Subject Classification (2000): 60 F 05\nAbstract\nIn this paper, we give estimates of ideal or minimal distances between the distribution of the\nnormalized partial sum and the limiting Gaussian distribution for stationary martingale difference sequences or stationary sequences satisfying projective criteria. Applications to functions\nof linear processes and to functions of expanding maps of the interval are given.\n\n1\n\nIntroduction and Notations\n\nLet X1 , X2 , . . . be a strictly stationary sequence of real-valued random variables (r.v.) with mean\nzero and finite variance. Set Sn = X1 + X2 + * * * + Xn . By Pn\u22121/2 Sn we denote the law of n\u22121/2 Sn\nand by G\u03c32 the normal distribution N(0, \u03c3 2 ). In this paper, we shall give quantitative estimates\nof the approximation of Pn\u22121/2 Sn by G\u03c32 in terms of minimal or ideal metrics.\nLet L(\u03bc, \u03bd) be the set of the probability laws on R2 with marginals \u03bc and \u03bd. Let us consider\nthe following minimal distances (sometimes called Wasserstein distances of order r)\n\uf8f1\nnZ\no\n\uf8f4\n\uf8f2 inf\n|x \u2212 y|r P (dx, dy) : P \u2208 L(\u03bc, \u03bd)\nif 0 < r < 1\nZ\nWr (\u03bc, \u03bd) =\nn\u0010\n\u00111/r\no\n\uf8f4\n\uf8f3 inf\n|x \u2212 y|r P (dx, dy)\n: P \u2208 L(\u03bc, \u03bd) if r \u2265 1 .\n1\n\n\fIt is well known that for two probability measures \u03bc and \u03bd on R with respective distributions\nfunctions (d.f.) F and G,\n\u0010Z 1\n\u00111/r\nWr (\u03bc, \u03bd) =\n|F \u22121 (u) \u2212 G\u22121 (u)|r du\nfor any r \u2265 1.\n(1.1)\n0\n\nWe consider also the following ideal distances of order r (Zolotarev distances of order r). For\ntwo probability measures \u03bc and \u03bd, and r a positive real, let\nZ\nnZ\no\n\u03b6r (\u03bc, \u03bd) = sup\nf d\u03bc \u2212 f d\u03bd : f \u2208 \u039br ,\nwhere \u039br is defined as follows: denoting by l the natural integer such that l < r \u2264 l + 1, \u039br is\nthe class of real functions f which are l-times continuously differentiable and such that\n|f (l) (x) \u2212 f (l) (y)| \u2264 |x \u2212 y|r\u2212l for any (x, y) \u2208 R \u00d7 R .\n\n(1.2)\n\nIt follows from the Kantorovich-Rubinstein theorem (1958) that for any 0 < r \u2264 1,\nWr (\u03bc, \u03bd) = \u03b6r (\u03bc, \u03bd) .\n\n(1.3)\n\nFor probability laws on the real line, Rio (1998) proved that for any r > 1,\nWr (\u03bc, \u03bd) \u2264 cr \u03b6r (\u03bc, \u03bd)\n\n\u00011/r\n\n,\n\n(1.4)\n\nwhere cr is a constant depending only on r.\nFor independent random variables, Ibragimov (1966) established that if X1 \u2208 Lp for p \u2208]2, 3],\nthen W1 (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2 ) (see his Theorem 4.3). Still in the case of independent\nr.v.'s, Zolotarev (1976) obtained the following upper bound for the ideal distance: if X1 \u2208 Lp for\np \u2208]2, 3], then \u03b6p (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2 ). From (1.4), the result of Zolotarev entails that, for\np \u2208]2, 3], Wp (Pn\u22121/2 Sn , G\u03c32 ) = O(n1/p\u22121/2 ) (which was obtained by Sakhanenko (1985) for any\np > 2). From (1.1) and H\u00f6lder's inequality, we easily get that for independent random variables\nin Lp with p \u2208]2, 3],\nWr (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u2212(p\u22122)/2r ) for any 1 \u2264 r \u2264 p.\n\n(1.5)\n\nIn this paper, we are interested in extensions of (1.5) to sequences of dependent random\nvariables. More precisely, for X1 \u2208 Lp and p in ]2, 3] we shall give Lp -projective criteria under\nwhich: for r \u2208 [p \u2212 2, p] and (r, p) 6= (1, 3),\nWr (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u2212(p\u22122)/2 max(1,r) ) .\n2\n\n(1.6)\n\n\fAs we shall see in Remark 2.3, (1.6) applied to r = p \u2212 2 provides the rate of convergence\np\u22122\nO(n\u2212 2(p\u22121) ) in the Berry-Esseen theorem.\nWhen (r, p) = (1, 3), Dedecker and Rio (2007) obtained that W1 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 )\nfor stationary sequences of random variables in L3 satisfying L1 projective criteria or weak\ndependence assumptions (a similar result was obtained by P\u00e8ne (2005) in the case where the\nvariables are bounded). In this particular case our approach provides a new criterion under\nwhich W1 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log n).\nOur paper is organized as follows. In Section 2, we give projective conditions for stationary\nmartingales differences sequences to satisfy (1.6) in the case (r, p) 6= (1, 3). To be more precise,\nlet (Xi )i\u2208Z be a stationary sequence of martingale differences with respect to some \u03c3-algebras\n(Fi )i\u2208Z (see Section 1.1 below for the definition of (Fi )i\u2208Z ). As a consequence of our Theorem\n2.1, we obtain that if (Xi )i\u2208Z is in Lp with p \u2208]2, 3] and satisfies\n\u221e\nX\nn=1\n\n1\nn2\u2212p/2\n\n\u0011\n\u0010 S2\nn\nF0 \u2212 \u03c3 2\nE\nn\n\np/2\n\n< \u221e,\n\n(1.7)\n\nthen the upper bound (1.6) holds provided that (r, p) 6= (1, 3). In the case r = 1 and p = 3, we\nobtain the upper bound W1 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log n).\nIn Section 3, starting from the coboundary decomposition going back to Gordin (1969), and\nusing the results of Section 2, we obtain Lp -projective criteria ensuring (1.6) (if (r, p) 6= (1, 3)).\nFor instance, if (Xi )i\u2208Z is a stationary sequence of Lp random variables adapted to (Fi )i\u2208Z , we\nobtain (1.6) for any p \u2208]2, 3[ and any r \u2208 [p \u2212 2, p] provided that (1.7) holds and the series\nE(Sn |F0 ) converge in Lp . In the case where p = 3, this last condition has to be strengthened.\nOur approach makes also possible to treat the case of non-adapted sequences.\nSection 4 is devoted to applications. In particular, we give sufficient conditions for some\nfunctions of Harris recurrent Markov chains and for functions of linear processes to satisfy the\nbound (1.6) in the case (r, p) 6= (1, 3) and the rate O(n\u22121/2 log n) when r = 1 and p = 3. Since\nprojective criteria are verified under weak dependence assumptions, we give an application to\nfunctions of \u03c6-dependent sequences in the sense of Dedecker and Prieur (2007). These conditions\napply to unbounded functions of uniformly expanding maps.\n\n1.1\n\nPreliminary notations\n\nThroughout the paper, Y is a N(0, 1)-distributed random variable. We shall also use the following notations. Let (\u03a9, A, P) be a probability space, and T : \u03a9 7\u2192 \u03a9 be a bijective bimeasurable\ntransformation preserving the probability P. For a \u03c3-algebra F0 satisfying F0 \u2286 T \u22121 (F0 ),\nT\nwe define the nondecreasing filtration (Fi )i\u2208Z by Fi = T \u2212i (F0 ). Let F\u2212\u221e = k\u2208Z Fk and\n3\n\n\fW\nF\u221e = k\u2208Z Fk . We shall denote sometimes by Ei the conditional expectation with respect to\nFi . Let X0 be a zero mean random variable with finite variance, and define the stationary sequence (Xi )i\u2208Z by Xi = X0 \u25e6 T i .\n\n2\n\nStationary sequences of martingale differences.\n\nIn this section we give bounds for the ideal distance of order r in the central limit theorem for\nstationary martingale differences sequences (Xi )i\u2208Z under projective conditions.\nNotation 2.1. For any p > 2, define the envelope norm k . k1,\u03a6,p by\nZ 1\nkXk1,\u03a6,p =\n(1 \u2228 \u03a6\u22121 (1 \u2212 u/2))p\u22122QX (u)du\n0\n\nwhere QX denotes the quantile function of |X|, and \u03a6 denotes the d.f. of the N(0, 1) law.\nTheorem 2.1. Let (Xi )i\u2208Z be a stationary martingale differences sequence with respect to (Fi )i\u2208Z .\nLet \u03c3 denote the standard deviation of X0 . Let p \u2208]2, 3]. Assume that E|X0 |p < \u221e and that\n\u221e\nX\nn=1\n\nand\n\n1\nn2\u2212p/2\n\n\u0011\n\u0010 S2\nE n F0 \u2212 \u03c3 2\nn\n\n\u221e\n\u0011\n\u0010 S2\nX\n1\nn\nF\n\u2212 \u03c32\nE\n0\n2/p\nn\nn\nn=1\n\n1,\u03a6,p\n\np/2\n\n< \u221e,\n\n< \u221e.\n\n(2.1)\n\n(2.2)\n\nThen, for any r \u2208 [p \u2212 2, p] with (r, p) 6= (1, 3), \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2 ), and for p = 3\n\u03b61 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log n).\nRemark 2.1. Under the assumptions of Theorem 2.1, \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u2212r/2 ) if r < p \u2212 2.\nIndeed, let p\u2032 = r + 2. Since p\u2032 < p, if the conditions (2.1) and (2.2) are satisfied for p, they also\nhold for p\u2032 . Hence Theorem 2.1 applies with p\u2032 .\nFrom (1.3) and (1.4), the following result holds for the Wasserstein distances of order r.\nCorollary 2.1. Under the conditions of Theorem 2.1, Wr (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u2212(p\u22122)/2 max(1,r) )\nfor any r in [p \u2212 2, p], provided that (r, p) 6= (1, 3).\nRemark 2.2. For p in ]2, 3], Wp (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u2212(2\u2212p)/2p ). This bound was obtained by\nSakhanenko (1985) in the independent case. For p < 3, we have W1 (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2 ).\nThis bound was obtained by Ibragimov (1966) in the independent case.\n4\n\n\fRemark 2.3. Let \u03a0n be the Prokhorov distance between the law of n\u22121/2 Sn and the normal\ndistribution N(0, \u03c3 2 ). From Markov's inequality,\n\u03a0n \u2264 (Wr (Pn\u22121/2 Sn , G\u03c32 ))1/(r+1) for any 0 < r \u2264 1 .\nTaking r = p \u2212 2, it follows that under the assumptions of Theorem 2.1,\np\np\u22122\n\u03a0n = O(n\u2212 2(p\u22121) ) if p < 3 and \u03a0n = O(n\u22121/4 log n) if p = 3.\n\n(2.3)\n\nP\nFor p in ]2, 4], under (2.2), we have that k ni=1 E(Xi2 \u2212 \u03c3 2 |Fi\u22121)kp/2 = O(n2/p ) (apply Theorem\n2 in Wu and Zhao (2006)). Applying then the result in Heyde and Brown (1970), we get that if\n(Xi )i\u2208Z is a stationary martingale difference sequence in Lp such that (2.2) is satisfied then\np\u22122 \u0001\n\u2212 2(p+1)\n\nkFn \u2212 \u03a6\u03c3 k\u221e = O n\n\n.\n\nwhere Fn is the distribution function of n\u22121/2 Sn and \u03a6\u03c3 is the d.f. of G\u03c32 . Now\n\u0001\nkFn \u2212 \u03a6\u03c3 k\u221e \u2264 1 + \u03c3 \u22121 (2\u03c0)\u22121/2 \u03a0n .\n\nConsequently the bounds obtained in (2.3) improve the one given in Heyde and Brown (1970),\nprovided that (2.1) holds.\nRemark 2.4. Notice that if (Xi )i\u2208Z is a stationary martingale difference sequence in L3 such\nthat E(X02 ) = \u03c3 2 and\nX\nk \u22121/2 kE(Xk2 |F0 ) \u2212 \u03c3 2 k3/2 < \u221e,\n(2.4)\nk>0\n\nthen the conditions (2.1) and (2.2) hold for p = 3. Consequently, if (2.4) holds, then Remark\n\u0001\n\u221a\n2.3 gives kFn \u2212 \u03a6\u03c3 k\u221e = O n\u22121/4 log n . This result has to be compared with Theorem 6 in\nP\n2\n2\nJan (2001), which states that kFn \u2212 \u03a6\u03c3 k\u221e = O(n\u22121/4 ) if\nk>0 kE(Xk |F0 ) \u2212 \u03c3 k3/2 < \u221e.\nRemark 2.5. Notice that if (Xi )i\u2208Z is a stationary martingale differences sequence, then the\nconditions (2.1) and (2.2) are respectively equivalent to\nX\nX\n2j(p/2\u22121) k2\u2212j E(S22j |F0 ) \u2212 \u03c3 2 k1,\u03a6,p < \u221e, and\n2j(1\u22122/p) k2\u2212j E(S22j |F0 ) \u2212 \u03c3 2 kp/2 < \u221e .\nj\u22650\n\nj\u22650\n\n\u0001\n\u0001\nTo see this, let An = kE(Sn2 |F0 \u2212 E(Sn2 )k1,\u03a6,p and Bn = kE(Sn2 |F0 \u2212 E(Sn2 )kp/2 . We first\nshow that An and Bn are subadditive sequences. Indeed, by the martingale property and the\nstationarity of the sequence, for all positive i and j\n\u0001\nAi+j = kE(Si2 + (Si+j \u2212 Si )2 |F0 \u2212 E(Si2 + (Si+j \u2212 Si )2 )k1,\u03a6,p\n\u0001\n\u2264 Ai + kE (Si+j \u2212 Si )2 \u2212 E(Sj2 ) |F0 k1,\u03a6,p .\n5\n\n\fProceeding as in the proof of (4.6), p. 65 in Rio (2000), one can prove that, for any \u03c3-field A\nand any integrable random variable X, kE(X|A)k1,\u03a6,p \u2264 kXk1,\u03a6,p . Hence\n\u0001\n\u0001\nkE (Si+j \u2212 Si )2 \u2212 E(Sj2 ) |F0 k1,\u03a6,p \u2264 kE((Si+j \u2212 Si )2 \u2212 E(Sj2 ) |Fi k1,\u03a6,p .\n\nBy stationarity, it follows that Ai+j \u2264 Ai + Aj . Similarly Bi+j \u2264 Bi + Bj . The proof of the\nequivalences then follows by using the same arguments as in the proof of Lemma 2.7 in Peligrad\nand Utev (2005).\n\n3\n\nRates of convergence for stationary sequences\n\nIn this section, we give estimates for the ideal distances of order r for stationary sequences which\nare not necessarily adapted to Fi .\nTheorem 3.1. Let (Xi )i\u2208Z be a stationary sequence of centered random variables in Lp with\np \u2208]2, 3[, and let \u03c3n2 = n\u22121 E(Sn2 ). Assume that\nX\nX\nE(Xn |F0 ) and\n(X\u2212n \u2212 E(X\u2212n |F0 )) converge in Lp ,\n(3.1)\nn>0\n\nn>0\n\nand\nX\nn\u22651\n\nThen the series\n\nP\n\nk\u2208Z\n\nn\u22122+p/2 k n\u22121 E(Sn2 |F0 ) \u2212 \u03c3n2 kp/2 < \u221e .\n\n(3.2)\n\nCov(X0 , Xk ) converges to some nonnegative \u03c3 2 , and\n\n1. \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2) for r \u2208 [p \u2212 2, 2],\n2. \u03b6r (Pn\u22121/2 Sn , G\u03c3n2 ) = O(n1\u2212p/2 ) for r \u2208]2, p].\nRemark 3.1. According to the bound (5.35), we infer that, under the assumptions of Theorem\n3.1, the condition (3.2) is equivalent to\nX\nn\u22651\n\nn\u22122+p/2 k n\u22121 E(Sn2 |F0 ) \u2212 \u03c3 2 kp/2 < \u221e .\n\n(3.3)\n\nThe same remark applies to the next theorem with p = 3.\nRemark 3.2. The result of item 1 is valid with \u03c3n instead of \u03c3. On the contrary, the result of\nitem 2 is no longer true if \u03c3n is replaced by \u03c3, because for r \u2208]2, 3], a necessary condition for\n\u03b6r (\u03bc, \u03bd) to be finite is that the two first moments of \u03bd and \u03bc are equal. Note that under the\n\n6\n\n\fassumptions of Theorem 3.1, both Wr (Pn\u22121/2 Sn , G\u03c32 ) and Wr (Pn\u22121/2 Sn , G\u03c3n2 ) are of the order of\nn\u2212(p\u22122)/2 max(1,r) . Indeed, in the case where r \u2208]2, p], one has that\nWr (Pn\u22121/2 Sn , G\u03c32 ) \u2264 Wr (Pn\u22121/2 Sn , G\u03c3n2 ) + Wr (G\u03c3n2 , G\u03c32 ) ,\nand the second term is of order |\u03c3 \u2212 \u03c3n | = O(n\u22121/2 ).\nIn the case where p = 3, the condition (3.1) has to be strengthened.\nTheorem 3.2. Let (Xi )i\u2208Z be a stationary sequence of centered random variables in L3 , and let\n\u03c3n2 = n\u22121 E(Sn2 ). Assume that\nX1 X\nE(Xk |F0 )\nn k\u2265n\nn\u22651\n\n3\n\n< \u221e and\n\nX1 X\n(X\u2212k \u2212 E(X\u2212k |F0 ))\nn k\u2265n\nn\u22651\n\n3\n\n< \u221e.\n\n(3.4)\n\nAssume in addition that\nX\nn\u22651\n\nThen the series\n\nP\n\nk\u2208Z\n\nn\u22121/2 k n\u22121 E(Sn2 |F0 ) \u2212 \u03c3n2 k3/2 < \u221e .\n\n(3.5)\n\nCov(X0 , Xk ) converges to some nonnegative \u03c3 2 and\n\n1. \u03b61 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log n),\n2. \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 ) for r \u2208]1, 2],\n3. \u03b6r (Pn\u22121/2 Sn , G\u03c3n2 ) = O(n\u22121/2 ) for r \u2208]2, 3].\n\n4\n4.1\n\nApplications\nMartingale differences sequences and functions of Markov chains\n\nRecall that the strong mixing coefficient of Rosenblatt (1956) between two \u03c3-algebras A and B\nis defined by \u03b1(A, B) = sup{|P(A \u2229 B) \u2212 P(A)P(B)| : (A, B) \u2208 A \u00d7 B }. For a strictly stationary\nsequence (Xi )i\u2208Z , let Fi = \u03c3(Xk , k \u2264 i). Define the mixing coefficients \u03b11 (n) of the sequence\n(Xi )i\u2208Z by\n\u03b11 (n) = \u03b1(F0 , \u03c3(Xn )) .\nLet Q be the quantile function of |X0 |, that is the cadlag inverse of the tail function x \u2192\nP(|X0 | > x). According to the results of Section 2, the following proposition holds.\n\n7\n\n\fProposition 4.1. Let (Xi )i\u2208Z be a stationary martingale difference sequence. Assume moreover\nthat the series\n\u00112/p\nX 1 \u0010 Z \u03b11 (k)\nX 1 Z \u03b11 (k)\n(p\u22122)/2 2\np\n(1\n\u2228\nlog(1/u))\nQ\n(u)du\nand\nQ\n(u)du\n(4.1)\n2\u2212p/2\n2/p\nk\nk\n0\n0\nk\u22651\nk\u22651\nare convergent.Then the conclusions of Theorem 2.1 hold.\nRemark 4.1. From Theorem 2.1(b) in Dedecker and Rio (2007), a sufficient condition to get\nW1 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log n) is\nXZ\nk\u22650\n\n\u03b11 (n)\n0\n\nQ3 (u)du < \u221e .\n\nThis condition is always strictly stronger than the condition (4.1) when p = 3.\nWe now give an example. Consider the homogeneous Markov chain (Yi )i\u2208Z with state space\nZ described at page 320 in Davydov (1973). The transition probabilities are given by pn,n+1 =\np\u2212n,\u2212n\u22121 = an for n \u2265 0, pn,0 = p\u2212n,0 = 1 \u2212 an for n > 0, p0,0 = 0, a0 = 1/2 and 1/2 \u2264 an < 1\nfor n \u2265 1. This chain is irreducible and aperiodic. It is Harris positively recurrent as soon\nP\nn\u22121\nas\nn\u22652 \u03a0k=1 ak < \u221e. In that case the stationary chain is strongly mixing in the sense of\nRosenblatt (1956).\nDenote by K the Markov kernel of the chain (Yi )i\u2208Z . The functions f such that K(f ) = 0\nalmost everywhere are obtained by linear combinations of the two functions f1 and f2 given by\nf1 (1) = 1, f1 (\u22121) = \u22121 and f1 (n) = f1 (\u2212n) = 0 if n 6= 1, and f2 (0) = 1, f2 (1) = f2 (\u22121) = 0\nand f2 (n + 1) = f2 (\u2212n \u2212 1) = 1 \u2212 a\u22121\nn if n > 0. Hence the functions f such that K(f ) = 0 are\nbounded.\nIf (Xi )i\u2208Z is defined by Xi = f (Yi ), with K(f ) = 0, then Proposition 4.1 applies if\n\u03b11 (n) = O(n1\u2212p/2 (log n)\u2212p/2\u2212\u01eb ) for some \u01eb > 0,\n\n(4.2)\n\nwhich holds as soon as P0 (\u03c4 = n) = O(n\u22121\u2212p/2 (log n)\u2212p/2\u2212\u01eb ), where P0 is the probability of the\nn\u22121\nchain starting from 0, and \u03c4 = inf{n > 0, Xn = 0}. Now P0 (\u03c4 = n) = (1 \u2212 an )\u03a0i=1\nai for n \u2265 2.\nConsequently, if\np\u0010\n1 + \u01eb\u0011\nai = 1 \u2212\n1+\nfor i large enough ,\n2i\nlog i\nthe condition (4.2) is satisfied and the conclusion of Theorem 2.1 holds.\n\nRemark 4.2. If f is bounded and K(f ) 6= 0, the central limit theorem may fail to hold for\nP\nSn = ni=1 (f (Yi ) \u2212 E(f (Yi ))). We refer to the Example 2, page 321, given by Davydov (1973),\nwhere Sn properly normalized converges to a stable law with exponent strictly less than 2.\n8\n\n\fProof of Proposition 4.1. Let B p (F0 ) be the set of F0 -measurable random variables such\nthat kZkp \u2264 1. We first notice that\nkE(Xk2 |F0 ) \u2212 \u03c3 2 kp/2 =\n\nsup\nZ\u2208B p/(p\u22122) (F0 )\n\nCov(Z, Xk2) .\n\nApplying Rio's covariance inequality (1993), we get that\n\u0010 Z \u03b11 (k)\n\u00112/p\n2\n2\np\nkE(Xk |F0 ) \u2212 \u03c3 kp/2 \u2264 2\nQ (u)du\n,\n0\n\nwhich shows that the convergence of the second series in (4.1) implies (2.2). Now, from Fr\u00e9chet\n(1957), we have that\n\b\nkE(Xk2 |F0 ) \u2212 \u03c3 2 k1,\u03a6,p = sup E((1 \u2228 |Z|p\u22122)| E(Xk2 |F0) \u2212 \u03c3 2 | ), Z F0 -measurable, Z \u223c N (0, 1) .\n\nHence, setting \u03b5k = sign(E(Xk2 |F0) \u2212 \u03c3 2 ),\n\n\b\nkE(Xk2 |F0 ) \u2212 \u03c3 2 k1,\u03a6,p = sup Cov(\u03b5k (1 \u2228 |Z|p\u22122 ), Xk2), Z F0 -measurable, Z \u223c N (0, 1) .\n\nApplying again Rio's covariance inequality (1993), we get that\n\u0010 Z \u03b11 (k)\n\u0011\n2\n2\nkE(Xk |F0 ) \u2212 \u03c3 k1,\u03a6,p \u2264 C\n(1 \u2228 log(u\u22121 ))(p\u22122)/2 Q2 (u)du ,\n0\n\nwhich shows that the convergence of the first series in (4.1) implies (2.1).\n\n4.2\n\nLinear processes and functions of linear processes\n\nP\nTheorem 4.1. Let (ai )i\u2208Z be a sequence of real numbers in l2 such that i\u2208Z ai converges to\nsome real A. Let (\u03b5i )i\u2208Z be a stationary sequence of martingale differences in Lp for p \u2208]2, 3].\nP\n2\n\u22121\n2\nLet Xk =\nj\u2208Z aj \u03b5k\u2212j , and \u03c3n = n E(Sn ). Let b0 = a0 \u2212 A and bj = aj for j 6= 0. Let\nP\nP\nAn = j\u2208Z ( nk=1 bk\u2212j )2 . If An = o(n), then \u03c3n2 converges to \u03c3 2 = A2 E(\u03b520 ). If moreover\n\u221e\nX\nn=1\n\n1\n\nn2\u2212p/2\n\nn\n\u00101\u0010X\n\u00112 \u0011\nE\n\u03b5j F0 \u2212 E(\u03b520 )\nn j=1\n\np/2\n\n< \u221e,\n\n(4.3)\n\nthen we have\n1. If An = O(1), then \u03b61 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log(n)), for p = 3,\n2. If An = O(n(r+2\u2212p)/r ), then \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2), for r \u2208 [p \u2212 2, 1] and p 6= 3,\n3. If An = O(n3\u2212p ), then \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2 ), for r \u2208]1, 2],\n9\n\n\f4. If An = O(n3\u2212p ), then \u03b6r (Pn\u22121/2 Sn , G\u03c3n2 ) = O(n1\u2212p/2 ), for r \u2208]2, p].\nRemark 4.3. If the condition given by Heyde (1975) holds, that is\n\u221e \u0010X\nX\nn=1\n\nak\n\nk\u2265n\n\n\u00112\n\n\u221e \u0010 X\nX\n\n< \u221e and\n\nn=1\n\nak\n\nk\u2264\u2212n\n\n\u00112\n\n< \u221e,\n\n(4.4)\n\nthen An = O(1), so that it satisfies all the conditions of items 1-4. On the other and, one has\nthe bound\nn \u0010\u0010 X\n\u00112 \u0010 X\n\u00112 \u0011\nX\nAn \u2264 4Bn , where Bn =\n|aj | +\n|aj |\n.\n(4.5)\nk=1\n\nj\u2265k\n\nj\u2264\u2212k\n\nProof of Theorem 4.1. We start with the following decomposition:\nSn = A\n\nn\nX\n\n\u03b5j +\n\nj=1\n\n\u221e \u0010X\nn\nX\n\nj=\u2212\u221e\n\nk=1\n\n\u0011\nbk\u2212j \u03b5j .\n\n(4.6)\n\nP\nPn\n2\n2\n\u22121/2\nLet Rn = \u221e\nkRn k2 , the\nj=\u2212\u221e (\nk=1 bk\u2212j )\u03b5j . Since kRn k2 = An k\u03b50 k2 and since |\u03c3n \u2212 \u03c3| \u2264 n\nfact that An = o(n) implies that \u03c3n converges to \u03c3. We now give an upper bound for kRn kp .\nFrom Burkholder's inequality, there exists a constant C such that\nkRn kp \u2264 C\n\n\u221e \u0010X\nn\nX\n\nn\n\nj=\u2212\u221e\n\nbk\u2212j\n\nk=1\n\n\u00112\n\n\u03b52j\n\np/2\n\no1/2\n\n\u2264 Ck\u03b50 kp\n\np\n\nAn .\n\n(4.7)\n\nP\nThe result follows by applying Theorem 2.1 to the martingale A nk=1 \u03b5k (this is possible because\nof (4.3)), and by using Lemma 5.2 with the upper bound (4.7). To prove Remark 4.3, note first\nthat\n\u2212j\nn \u0010 X\n\u221e\n\u221e \u0010 n+i\u22121\n\u221e \u0010\n\u2212i\n\u00112 X\n\u00112\nX\nX\nX \u00112 X\nX\nAn =\nal +\nal +\nal +\nal .\nj=1\n\nl=\u2212\u221e\n\ni=1\n\nl=n+1\u2212j\n\nl=i\n\ni=1\n\nl=\u2212i\u2212n+1\n\nIt follows easily that An = O(1) under (4.4). To prove the bound (4.5), note first that\nAn \u2264 3Bn +\nLet Ti =\n\nP\u221e\n\nl=i\n\n|al | and Qi =\n\ni=n+1\n\nP\u2212i\n\nl=\u2212\u221e\n\n\u221e \u0010 n+i\u22121\nX\nX\n\ni=n+1\n\u221e\nX\n\ni=n+1\n\n\u0010\n\n\u221e \u0010 n+i\u22121\nX\nX\n\nl=i\n\n\u2212i\nX\n\nl=\u2212i\u2212n+1\n\nl=i\n\n|al |\n\n\u00112\n\n+\n\n\u221e \u0010\nX\n\ni=n+1\n\n\u2212i\nX\n\nl=\u2212i\u2212n+1\n\n|al |\n\n\u00112\n\n.\n\n|al |. We have that\n\n|al |\n\n\u00112\n\n\u2264 Tn+1\n\n|al |\n\n\u00112\n\n\u2264 Qn+1\n10\n\n\u221e\nX\n\n2\n(Ti \u2212 Tn+i ) \u2264 nTn+1\n\ni=n+1\n\u221e\nX\n\n(Qi \u2212 Qn+i ) \u2264 nQ2n+1 .\n\ni=n+1\n\n\f2\nSince n(Tn+1\n+ Q2n+1 ) \u2264 Bn , (4.5) follows. \u0003\n\nIn the next result, we shall focus on functions of real-valued linear processes\n\u0010X\n\u0011\n\u0010 \u0010X\n\u0011\u0011\nXk = h\nai \u03b5k\u2212i \u2212 E h\nai \u03b5k\u2212i ,\ni\u2208Z\n\n(4.8)\n\ni\u2208Z\n\nwhere (\u03b5i )i\u2208Z is a sequence of iid random variables. Denote by wh (., M) the modulus of continuity\nof the function h on the interval [\u2212M, M], that is\nwh (t, M) = sup{|h(x) \u2212 h(y)|, |x \u2212 y| \u2264 t, |x| \u2264 M, |y| \u2264 M} .\nTheorem 4.2. Let (ai )i\u2208Z be a sequence of real numbers in l2 and (\u03b5i )i\u2208Z be a sequence of iid\nrandom variables in L2 . Let Xk be defined as in (4.8) and \u03c3n2 = n\u22121 E(Sn2 ). Assume that h is\n\u03b3-H\u00f6lder on any compact set, with wh (t, M) \u2264 Ct\u03b3 M \u03b1 , for some C > 0, \u03b3 \u2208]0, 1] and \u03b1 \u2265 0. If\nfor some p \u2208]2, 3],\nE(|\u03b50 |\nthen the series\n\n2\u2228(\u03b1+\u03b3)p\n\nX\n\n) < \u221e and\n\nP\n\nk\u2208Z Cov(X0 , Xk )\n\np/2\u22121\n\ni\n\ni\u22651\n\n\u0010X\n\na2j\n\n|j|\u2265i\n\n\u0011\u03b3/2\n\n< \u221e,\n\n(4.9)\n\nconverges to some nonnegative \u03c3 2 , and\n\n1. \u03b61 (Pn\u22121/2 Sn , G\u03c32 ) = O(n\u22121/2 log n), for p = 3,\n2. \u03b6r (Pn\u22121/2 Sn , G\u03c32 ) = O(n1\u2212p/2) for r \u2208 [p \u2212 2, 2] and (r, p) 6= (1, 3),\n3. \u03b6r (Pn\u22121/2 Sn , G\u03c3n2 ) = O(n1\u2212p/2 ) for r \u2208]2, p].\nProof of Theorem 4.2. Theorem 4.2 is a consequence of the following proposition:\nProposition 4.2. Let (ai )i\u2208Z , (\u03b5i )i\u2208Z and (Xi )i\u2208Z be as in Theorem 4.2. Let (\u03b5\u2032i )i\u2208Z be an\nP\nindependent copy of (\u03b5i )i\u2208Z . Let V0 = i\u2208Z ai \u03b5\u2212i and\nM1,i = |V0 | \u2228\n\nX\nj<i\n\naj \u03b5\u2212j +\n\nX\nj\u2265i\n\nIf for some p \u2208]2, 3],\n\u0011\n\u0010 X\nX\nip/2\u22121 wh\naj \u03b5\u2212j , M1,i\ni\u22651\n\nj\u2265i\n\np\n\naj \u03b5\u2032\u2212j\n\nand M2,i = |V0 | \u2228\n\n< \u221e and\n\nthen the conclusions of Theorem 4.2 hold.\n\n11\n\nX\ni\u22651\n\nip/2\u22121 wh\n\nX\nj<i\n\naj \u03b5\u2032\u2212j +\n\n\u0010 X\n\nj<\u2212i\n\nX\nj\u2265i\n\naj \u03b5\u2212j .\n\naj \u03b5\u2212j , M2,\u2212i\n\n\u0011\n\np\n\n< \u221e,\n(4.10)\n\n\fTo prove Theorem 4.2, it remains to check (4.10). We only check the first condition. Since\nwh (t, M) \u2264 Ct\u03b3 M \u03b1 and the random variables \u03b5i are iid, we have\n\u0010 X\n\u0011\nX\nX\n\u03b3\n\u03b3\nwh\nk|V0 |\u03b1 kp ,\naj \u03b5\u2212j , M1,i\n\u2264 C\naj \u03b5\u2212j |V0 |\u03b1 + C\naj \u03b5\u2212j\np\n\nj\u2265i\n\np\n\nj\u2265i\n\np\n\nj\u2265i\n\nso that\nwh\n\n\u0010 X\nj\u2265i\n\naj \u03b5\u2212j , M1,i\n\n\u0011\n\n\u0010\n\u2264 C 2\u03b1\n\np\n\nX\nj\u2265i\n\naj \u03b5\u2212j\n\n\u03b1+\u03b3\np\n\n+\n\nX\nj\u2265i\n\naj \u03b5\u2212j\n\n\u03b3\np\n\n\u0010\n\nk|V0 |\u03b1 kp + 2\u03b1\n\nX\nj<i\n\naj \u03b5\u2212j\n\n\u03b1\np\n\n\u0011\u0011\n\n.\n\nFrom Burkholder's inequality, for any \u03b2 > 0,\nX\nj\u2265i\n\naj \u03b5\u2212j\n\n\u03b2\np\n\n=\n\nX\nj\u2265i\n\naj \u03b5\u2212j\n\n\u03b2\n\u03b2p\n\n\u2264K\n\n\u0010X\nj\u2265i\n\na2j\n\n\u0011\u03b2/2\n\nk\u03b50k\u03b22\u2228\u03b2p .\n\nApplying this inequality with \u03b2 = \u03b3 or \u03b2 = \u03b1 + \u03b3, we infer that the first part of (4.10) holds\nunder (4.9). The second part can be handled in the same way. \u0003\nProof of Proposition 4.2. Let Fi = \u03c3(\u03b5k , k \u2264 i). We shall first prove that the condition (3.2)\nof Theorem 3.1 holds. We write\nkE(Sn2 |F0) \u2212 E(Sn2 )kp/2 \u2264 2\n\u2264 4\n\nn X\nn\nX\ni=1 k=i\n\nn X\nn\u2212i\nX\ni=1 k=0\n\nkE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2\n\nkE(Xi Xk+i |F0 )kp/2 + 2\n\nn X\ni\nX\ni=1 k=1\n\nkE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2 .\n\nWe first control the second term. Let \u03b5\u2032 be an independent copy of \u03b5, and denote by E\u03b5 (*) the\nconditional expectation with respect to \u03b5. Define\nX\nX\nX\nX\nYi =\naj \u03b5i\u2212j , Yi\u2032 =\naj \u03b5\u2032i\u2212j , Zi =\naj \u03b5i\u2212j , Zi\u2032 =\naj \u03b5\u2032i\u2212j\nj<i\n\nj<i\n\nj\u2265i\n\nj\u2265i\n\nand m1,i = |Yi\u2032 + Zi | \u2228 |Yi\u2032 + Zi\u2032 |. Taking Fl = \u03c3(\u03b5i , i \u2264 l), and setting h0 = h \u2212 E(h(\nwe have\n\nP\n\ni\u2208Z\n\nkE(Xi Xk+i |F0) \u2212 E(Xi Xk+i )kp/2\n\u0011\n\u0010\n\u0011\n\u0010\n\u2032\n\u2032\n\u2032\n)\n+ Zk+i\n+ Zk+i ) \u2212 E\u03b5 h0 (Yi\u2032 + Zi\u2032 )h0 (Yk+i\n= E\u03b5 h0 (Yi\u2032 + Zi )h0 (Yk+i\n12\n\nai \u03b5i )),\n\np/2\n\n.\n\n\fHence,\n\u2032\nkE(Xi Xk+i |F0) \u2212 E(Xi Xk+i )kp/2 \u2264 kh0 (Yk+i\n+ Zk+i )kp wh\n\n+ kh0 (Yi\u2032 + Zi\u2032 )kp wh\nBy subadditivity,\n\u0010 X\n\u0011\nwh\naj (\u03b5i\u2212j \u2212 \u03b5\u2032i\u2212j ) , m1,i\nj\u2265i\n\np\n\n\u2264\n\nwh\n\n\u0010 X\n\n\u2264 2 wh\n\n\u0010 X\nj\u2265i\n\n\u0010 X\n\nj\u2265k+i\n\nj\u2265i\n\n\u0010 X\nj\u2265i\n\nIn the same way\n\u0010 X\n\u0011\nwh\naj (\u03b5k+i\u2212j \u2212 \u03b5\u2032k+i\u2212j ) , m1,k+i\nj\u2265k+i\n\np\n\naj \u03b5\u2212j , M1,i\n\n\u2264 2 wh\n\n\u0011\n\n, m1,i\n\n\u0011\n\np\n\n\u0011\n\u0011\naj (\u03b5k+i\u2212j \u2212 \u03b5\u2032k+i\u2212j , m1,k+i\n\n\u0011\n\naj \u03b5i\u2212j , m1,i\n\naj (\u03b5i\u2212j \u2212 \u03b5\u2032i\u2212j\n\np\n\n\u0011\n\n+ wh\n\np\n\n\u0010 X\n\nj\u2265k+i\n\n\u0010 X\n\naj \u03b5\u2032i\u2212j , m1,i\n\nj\u2265i\n\np\n\n\u0011\n\n.\n\np\n\n.\n\naj \u03b5\u2212j , M1,k+i\n\n\u0011\n\np\n\n.\n\nConsequently\nX\nn\u22651\n\n1\nn3\u2212p/2\n\nn X\ni\nX\ni=1 k=1\n\nkE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2 < \u221e\n\nprovided that the first condition in (4.10) holds.\nP P\nWe turn now to the control of ni=1 nk=i kE(Xi Xk+i |F0)kp/2 . We first write that\n\u0001\n\u0001\nkE(Xi Xk+i |F0)kp/2 = kE (Xi \u2212 E(Xi |Fi+[k/2] ))Xk+i |F0 kp/2 + kE E(Xi |Fi+[k/2] )Xk+i |F0 kp/2\n= kX0 kp kXi \u2212 E(Xi |Fi+[k/2] )kp + kX0 kp kE(Xk+i |Fi+[k/2])kp .\n\nLet b(k) = k \u2212 [k/2]. Since kE(Xk+i |Fi+[k/2])kp = kE(Xb(k) |F0 )kp , we have that\nkE(Xk+i |Fi+[k/2])kp\n\u0010 \u0010 X\n\u0011\n\u0010 X\n\u0011\u0011\nX\nX\n\u2032\n\u2032\n\u2032\n= E\u03b5 h\naj \u03b5b(k)\u2212j +\naj \u03b5b(k)\u2212j \u2212 h\naj \u03b5b(k)\u2212j +\naj \u03b5b(k)\u2212j\nj<b(k)\n\nj\u2265b(k)\n\nj<b(k)\n\nUsing the same arguments as before, we get that\n\u0010 X\n\u0011\naj \u03b5\u2212j , M1,b(k)\nkE(Xk+i |Fi+[k/2] )kp \u2264 2 wh\nj\u2265b(k)\n\nj\u2265b(k)\n\np\n\np\n\n.\n\n.\n\nIn the same way,\nXi \u2212 E(Xi |Fi+[k/2])\np\n\u0010 \u0010 X\n\u0011\n\u0010 X\n\u0011\u0011\nX\nX\n\u2032\n= E\u03b5 h\naj \u03b5i\u2212j +\naj \u03b5i\u2212j \u2212 h\naj \u03b5i\u2212j +\naj \u03b5i\u2212j\nj<\u2212[k/2]\n\nj\u2265\u2212[k/2]\n\nj<\u2212[k/2]\n\n13\n\nj\u2265\u2212[k/2]\n\np\n\n,\n\n\fso that\nXi \u2212 E(Xi |Fi+[k/2] )\nConsequently\nX\nn\u22651\n\n1\nn3\u2212p/2\n\np\n\n\u2264 2 wh\n\nn X\nn\nX\ni=1 k=i\n\n\u0010\n\nX\n\nj<\u2212[k/2]\n\naj \u03b5\u2212j , M2,\u2212[k/2]\n\n\u0011\n\np\n\n.\n\nkE(Xi Xk+i |F0 )kp/2 < \u221e\n\nprovided that (4.10) holds. This completes the proof of (3.2). Using the same arguments, one\ncan easily check that the condition (3.1) of Theorem 3.1 (and also the condition (3.4) of Theorem\n3.2 in the case p = 3) holds under (4.10). \u0003\n\n4.3\n\nFunctions of \u03c6-dependent sequences\n\nIn order to include examples of dynamical systems satisfying some correlations inequalities, we\nintroduce a weak version of the uniform mixing coefficients (see Dedecker and Prieur (2007)).\nDefinition 4.1. For any random variable Y = (Y1 , * * * , Yk ) with values in Rk define the function\ngx,j (t) = 1It\u2264x \u2212 P(Yj \u2264 x). For any \u03c3-algebra F , let\n\u03c6(F , Y ) =\n\nsup\n(x1 ,...,xk )\u2208Rk\n\nk\nk\n\u0011\n\u0010Y\n\u0011\n\u0010Y\ngxj ,j (Yj )\nE\ngxj ,j (Yj ) F \u2212 E\nj=1\n\nj=1\n\n\u221e\n\n.\n\nFor a sequence Y = (Yi )i\u2208Z , where Yi = Y0 \u25e6 T i and Y0 is a F0 -measurable and real-valued r.v.,\nlet\n\u03c6k,Y (n) = max\nsup \u03c6(F0, (Yi1 , . . . , Yil )).\n1\u2264l\u2264k il >...>i1 \u2265n\n\nDefinition 4.2. For any p \u2265 1, let C(p, M, PX ) be the closed convex envelop of the set of\nfunctions f which are monotonous on some open interval of R and null elsewhere, and such that\nE(|f (X)|p ) < M.\nProposition 4.3. Let p \u2208]2, 3] and s \u2265 p. Let Xi = f (Yi ) \u2212 E(f (Yi )), where Yi = Y0 \u25e6 T i and f\nbelongs to C(s, M, PY0 ). Assume that\nX\ni\u22651\n\ni(p\u22124)/2+(s\u22122)/(s\u22121) \u03c62,Y (i)(s\u22122)/s < \u221e .\n\n(4.11)\n\nThen the conclusions of Theorem 4.2 hold.\nRemark 4.4. Notice that if s = p = 3, the condition (4.11) becomes\nP\nif s = \u221e, the condition (4.11) becomes i\u22651 i(p\u22122)/2 \u03c62,Y (i) < \u221e.\n14\n\nP\n\ni\u22651\n\n\u03c62,Y (i)1/3 < \u221e , and\n\n\fProof of Proposition 4.3. Let B p (F0 ) be the set of F0 -measurable random variables such\nthat kZkp \u2264 1. We first notice that\nkE(Xk |F0)kp \u2264 kE(Xk |F0 )ks =\n\nsup\n\nCov(Z, f (Yk )) .\n\nZ\u2208B s/(s\u22121) (F0 )\n\nAccording to Corollary 6.2 and since \u03c6(\u03c3(Z), Yk ) \u2264 \u03c61,Y (k) , we get that\nkE(Xk |F0 )ks \u2264 8M 1/s (\u03c61,Y (k))(s\u22121)/s .\n\n(4.12)\n\nIt follows that the conditions (3.1) (for p \u2208]2, 3[) or (3.4) (for p = 3) are satisfied under (4.11).\nThe condition (3.2) follows from the following lemma by taking b = (4 \u2212 p)/2.\nLemma 4.1. Let Xi be as in Proposition 4.3, and let b \u2208]0, 1[.\nIf\n\nX\ni\u22651\n\ni\u2212b+(s\u22122)/(s\u22121) \u03c62,Y (i)(s\u22122)/s < \u221e,\n\nthen\n\nX 1\nkE(Sn2 |F0 ) \u2212 E(Sn2 )kp/2 < \u221e .\n1+b\nn\nn>1\n\nProof of Lemma 4.1. Since,\nkE(Sn2 |F0)\n\n\u2212\n\nE(Sn2 )kp/2\n\n\u22642\n\nn X\nn\u2212i\nX\ni=1 k=0\n\nkE(Xi Xk+i |F0) \u2212 E(Xi Xk+i )kp/2 ,\n\nwe infer that there exists C > 0 such that\nXX\nX 1\n1\n2\n2\nkE(S\n|F\n)\n\u2212\nE(S\n)k\n\u2264\nC\nkE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2 . (4.13)\n0\np/2\nn\nn\n1+b\nn\n(i + k)b\ni>0 k\u22650\nn>1\nWe shall bound up kE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2 in two ways. First, using the stationarity\nand the upper bound (4.12), we have that\nkE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2 \u2264 2kX0 E(Xk |F0 )kp/2 \u2264 16kX0 kp M 1/s (\u03c61,Y (k))(s\u22121)/s .\nNext, using again Corollary 6.2,\nkE(Xi Xk+i |F0 ) \u2212 E(Xi Xk+i )kp/2 \u2264\n\nsup\nZ\u2208B s/(s\u22122) (F0 )\n\nCov(Z, Xi Xk+i ) \u2264 32M 2/s (\u03c62,Y (i))(s\u22122)/s .\n\nFrom (4.13) and the above upper bounds, we infer that the conclusion of Lemma (4.1) holds\nprovided that\n(s\u22122)/(s\u22121) ]\n\nX \u0010 [i X\ni>0\n\nk=1\n\n(s\u22121)/(s\u22122) ]\n\nX \u0010 [k X\n1 \u0011\n(s\u22122)/s\n(\u03c62,Y (i))\n+\n(i + k)b\ni=1\nk\u22650\n15\n\n1 \u0011\n(\u03c61,Y (k))(s\u22121)/s < \u221e .\n(i + k)b\n\n\fHere, note that\n[i(s\u22122)/(s\u22121) ]\n\nX\nk=1\n\n[k (s\u22121)/(s\u22122) ]\n\ns\u22122\n1\n\u2264 i\u2212b+ s\u22121\nb\n(i + k)\n\nX\n\nand\n\ni=1\n\n1\n\u2264\n(i + k)b\n\n[2k (s\u22121)/(s\u22122) ]\n\nX\n\nm=1\n\n(s\u22121)\n1\n(1\u2212b) (s\u22122)\n,\n\u2264\nDk\nmb\n\nfor some D > 0. Since \u03c61,Y (k) \u2264 \u03c62,Y (k), the conclusion of lemma (4.1) holds provided\nX\n\ns\u22122\n\ni\u2212b+ s\u22121 \u03c62,Y (i)\n\ni\u22651\n\ns\u22122\ns\n\nX\n\n< \u221e and\n\nk\n\n(1\u2212b) (s\u22121)\n(s\u22122)\n\nk\u22651\n\n\u03c62,Y (k)\n\ns\u22121\ns\n\n< \u221e.\n\nOne can prove that the second series converges provided the first one does. \u0003\n4.3.1\n\nApplication to Expanding maps\n\nLet BV be the class of bounded variation functions from [0, 1] to R. For any h \u2208 BV , denote\nby kdhk the variation norm of the measure dh.\nLet T be a map from [0, 1] to [0, 1] preserving a probability \u03bc on [0, 1], and let\nSn (f ) =\n\nn\nX\nk=1\n\n(f \u25e6 T k \u2212 \u03bc(f )) .\n\nDefine the Perron-Frobenius operator K from L2 ([0, 1], \u03bc) to L2 ([0, 1], \u03bc) via the equality\nZ 1\nZ 1\n(Kh)(x)f (x)\u03bc(dx) =\nh(x)(f \u25e6 T )(x)\u03bc(dx) .\n(4.14)\n0\n\n0\n\nA Markov Kernel K is said to be BV -contracting if there exist C > 0 and \u03c1 \u2208 [0, 1[ such that\nkdK n (h)k \u2264 C\u03c1n kdhk .\n\n(4.15)\n\nThe map T is said to be BV -contracting if its Perron-Frobenius operator is BV -contracting.\nLet us present a large class of BV -contracting maps. We shall say that T is uniformly\nexpanding if it belongs to the class C defined in Broise (1996), Section 2.1 page 11. Recall that\nif T is uniformly expanding, then there exists a probability measure \u03bc on [0, 1], whose density\nf\u03bc with respect to the Lebesgue measure is a bounded variation function, and such that \u03bc is\ninvariant by T . Consider now the more restrictive conditions:\n(a) T is uniformly expanding.\n(b) The invariant measure \u03bc is unique and (T, \u03bc) is mixing in the ergodic-theoretic sense.\n(c)\n\n1\n1f >0 is a bounded variation function.\nf\u03bc \u03bc\n16\n\n\fStarting from Proposition 4.11 in Broise (1996), one can prove that if T satisfies the assumptions\n(a), (b) and (c) above, then it is BV contracting (see for instance Dedecker and Prieur (2007),\nSection 6.3). Some well known examples of maps satisfying the conditions (a), (b) and (c) are:\n1. T (x) = \u03b2x \u2212 [\u03b2x] for \u03b2 > 1. These maps are called \u03b2-transformations.\n2. I is the finite union of disjoint intervals (Ik )1\u2264k\u2264n , and T (x) = ak x+bk on Ik , with |ak | > 1.\n3. T (x) = a(x\u22121 \u2212 1) \u2212 [a(x\u22121 \u2212 1)] for some a > 0. For a = 1, this transformation is known\nas the Gauss map.\nProposition 4.4. Let \u03c3n2 = n\u22121 E(Sn2 (f )). If T is BV -contracting, and if f belongs to C(p, M, \u03bc)\nP\nwith p \u2208]2, 3], then the series \u03bc((f \u2212 \u03bc(f ))2 ) + 2 n>0 \u03bc(f \u25e6 T n * (f \u2212 \u03bc(f ))) converges to some\nnonnegative \u03c3 2 , and\n1. \u03b61 (Pn\u22121/2 Sn (f ) , G\u03c32 ) = O(n\u22121/2 log n), for p = 3,\n2. \u03b6r (Pn\u22121/2 Sn (f ) , G\u03c32 ) = O(n1\u2212p/2 ) for r \u2208 [p \u2212 2, 2] and (r, p) 6= (1, 3),\n3. \u03b6r (Pn\u22121/2 Sn (f ) , G\u03c3n2 ) = O(n1\u2212p/2 ) for r \u2208]2, p].\nProof of Proposition 4.4. Let (Yi )i\u22651 be the Markov chain with transition Kernel K and\ninvariant measure \u03bc. Using the equation (4.14) it is easy to see that (Y0 , . . . , Yn ) it is distributed\nas (T n+1 , . . . , T ). Consequently, to prove Proposition 4.4, it suffices to prove that the sequence\nXi = f (Yi ) \u2212 \u03bc(f ) satisfies the condition (4.11) of Proposition 4.3.\nAccording to Lemma 1 in Dedecker and Prieur (2007), the coefficients \u03c62,Y (i) of the chain\n(Yi )i\u22650 with respect to Fi = \u03c3(Yj , j \u2264 i) satisfy \u03c62,Y (i) \u2264 C\u03c1i for some \u03c1 \u2208]0, 1[ and some\npositive constant C. It follows that (4.11) is satisfied for s = p.\n\n5\n\nProofs of the main results\n\nFrom now on, we denote by C a numerical constant which may vary from line to line.\nNotation 5.1. For l integer, q in ]l, l + 1] and f l-times continuously differentiable, we set\n|f |\u039bq = sup{|x \u2212 y|l\u2212q |f (l) (x) \u2212 f (l) (y)| : (x, y) \u2208 R \u00d7 R}.\n\n17\n\n\f5.1\n\nProof of Theorem 2.1\n\nWe prove Theorem 2.1 in the case \u03c3 = 1. The general case follows by dividing the random\nvariables by \u03c3. Since \u03b6r (PaX , PaY ) = |a|r \u03b6r (PX , PY ), it is enough to bound up \u03b6r (PSn , Gn ). We\nfirst give an upper bound for \u03b6p,N := \u03b6p (PS2N , G2N ).\nProposition 5.1. Let (Xi )i\u2208Z be a stationary martingale differences sequence. Let Mp =\nE(|X0 |p ). Then for any p in ]2, 3] and any natural integer N,\n2/p\n2\u22122N/p \u03b6p,N\n\nN\n\u00112/p 2\n1 X K(p/2\u22122)\n2\nkZK k1,\u03a6,p\n+ \u2206N ,\n\u2264 Mp + \u221a\np\n2 2 K=0\n\n\u0010\n\nwhere ZK = E(S22K |F0 ) \u2212 E(S22K ) and \u2206N =\n\nPN \u22121\n\nK=0 2\n\n\u22122K/p\n\n(5.1)\n\nkZK kp/2 .\n\nProof of Proposition 5.1. The proof is done by induction on N. Let (Yi )i\u2208N be a sequence\nof N(0, 1)-distributed independent random variables, independent of the sequence (Xi )i\u2208Z . For\nm > 0, let Tm = Y1 + Y2 + * * * + Ym . Set S0 = T0 = 0. For f numerical function and m \u2264 n, set\nfn\u2212m (x) = E(f (x + Tn \u2212 Tm )).\nThen, from the independence of the above sequences,\nE(f (Sn ) \u2212 f (Tn )) =\n\nn\nX\n\nm=1\n\n\u0001\nDm with Dm = E fn\u2212m (Sm\u22121 + Xm ) \u2212 fn\u2212m (Sm\u22121 + Ym ) .\n\n(5.2)\n\nNext, from the Taylor integral formula at order two, for any two-times differentiable function g\nand any q in ]2, 3],\nZ 1\n2\n\u2032\n1 2 \u2032\u2032\n(1 \u2212 t)|g \u2032\u2032 (x + th) \u2212 g \u2032\u2032 (x)|dt\n|g(x + h) \u2212 g(x) \u2212 g (x)h \u2212 2 h g (x)| \u2264 h\n0\nZ 1\n(1 \u2212 t)|th|q\u22122 |g|\u039bq dt,\n\u2264 h2\n0\n\nwhence\n\nLet\n\n1\n1\n|h|q |g|\u039bq .\n|g(x + h) \u2212 g(x) \u2212 g \u2032 (x)h \u2212 h2 g \u2032\u2032 (x)| \u2264\n2\nq(q \u2212 1)\n\n(5.3)\n\n\u2032\n\u2032\u2032\n2\n\u2032\u2032\n2\nDm\n= E(fn\u2212m\n(Sm\u22121 )(Xm\n\u2212 1)) = E(fn\u2212m\n(Sm\u22121 )(Xm\n\u2212 Ym2 ))\n\nFrom (5.3) applied twice with g = fn\u2212m , x = Sm\u22121 and h = Xm or h = Ym together with the\nmartingale property,\n1 \u2032\n1\nDm \u2212 Dm\n\u2264\n|fn\u2212m |\u039bp E(|Xm |p + |Ym|p ).\n2\np(p \u2212 1)\n18\n\n\fNow E(|Ym |p ) \u2264 p \u2212 1 \u2264 (p \u2212 1)Mp . Hence\n\u2032\n|Dm \u2212 (Dm\n/2)| \u2264 Mp |fn\u2212m |\u039bp\n\n(5.4)\n\nMoreover, if f belongs to \u039bp , then the smoothed function fn\u2212m belongs to \u039bp . Hence, summing\non m, we get that\nE(f (Sn ) \u2212 f (Tn )) \u2264 nMp + (D \u2032 /2) where D \u2032 = D1\u2032 + D2\u2032 + * * * + Dn\u2032 .\n\n(5.5)\n\nSuppose now that n = 2N . To bound up D \u2032 , we introduce a dyadic scheme.\nP\ni\nNotation 5.2. Set m0 = m \u2212 1 and write m0 in basis 2: m0 = N\ni=0 bi 2 with bi = 0 or bi = 1\nPN\n(note that bN = 0). Set mL = i=L bi 2i , so that mN = 0. Let IL,k =]k2L , (k + 1)2L ] \u2229 N (note\nP\nP\n(k)\n(k)\nthat IN,1 =]2N , 2N +1 ]), UL = i\u2208IL,k Xi and \u0168L = i\u2208IL,k Yi . For the sake of brevity, let\n(0)\n\n(0)\n\nUL = UL and \u0168L = \u0168L .\n\nSince mN = 0, the following elementary identity is valid\n\u2032\nDm\n\n=\n\nN\n\u22121\nX\nL=0\n\n\u0010\n\u0011\n\u2032\u2032\n\u2032\u2032\n2\nE (fn\u22121\u2212mL (SmL ) \u2212 fn\u22121\u2212mL+1 (SmL+1 ))(Xm \u2212 1) .\n\nNow mL 6= mL+1 only if bL = 1, then in this case mL = k2L with k odd. It follows that\n\u2032\n\nD =\n\nN\n\u22121\nX\nL=0\n\nX\n\nk\u2208IN\u2212L,0\nk odd\n\n\u0010\n\u2032\u2032\n\u2032\u2032\nE (fn\u22121\u2212k2\nL (Sk2L ) \u2212 fn\u22121\u2212(k\u22121)2L (S(k\u22121)2L ))\n\n\u0011\n\n(5.6)\n\n\u0010\n\u0001 (k) \u0011\n\u2032\u2032\n\u2032\u2032\nL\nL\nL\nL\nE fn\u22121\u2212k2\n(S\n)\n\u2212\nf\n(S\n+\nT\n\u2212\nT\n)\nZL .\nL\nk2\n(k\u22121)2\nk2\n(k\u22121)2\nn\u22121\u2212k2L\n\n(5.7)\n\nX\n\n2\n(Xm\n\n{m:mL =k2L }\n\n2\n\n\u2212\u03c3 ) .\n\nNote that {m : mL = k2L } = IL,k . Now by the martingale property\n\u0011\n\u0010 X\n(k)\n(k)\n(k)\n(Xi2 \u2212 \u03c3 2 ) = Ek2L ((UL )2 ) \u2212 E((UL )2 ) := ZL .\nEk2L\ni\u2208IL,k\n\nSince (Xi )i\u2208N and (Yi )i\u2208N are independent, we infer that\nD\u2032 =\n\nN\n\u22121\nX\nL=0\n\nX\n\nk\u2208IN\u2212L,0\nk odd\n\nBy using (1.2), we get that\n\u2032\n\nD \u2264\n\nN\n\u22121\nX\nL=0\n\nX\n\n(k\u22121)\n\nE(|UL\n\nk\u2208IN\u2212L,0\nk odd\n\n19\n\n(k\u22121) p\u22122\n\n\u2212 \u0168L\n\n|\n\n(k)\n\n|ZL |) .\n\n\fFrom the stationarity of (Xi )i\u2208N and the above inequality,\nD\u2032 \u2264\n\nN \u22121\n1 X N \u2212K\n(1)\n2\nE(|UK \u2212 \u0168K |p\u22122 |ZK |).\n2 K=0\n\n(5.8)\n\nNow let VK be the N(0, 2K )-distributed random variable defined from UK via the quantile\ntransformation, that is\nVK = 2K/2 \u03a6\u22121 (FK (UK \u2212 0) + \u03b4K (FK (UK ) \u2212 FK (UK \u2212 0)))\nwhere FK denotes the d.f. of UK , and (\u03b4K ) is a sequence of independent uniformly distributed\nr.v.'s, independent of the underlying random variables. Now, from the subadditivity of x \u2192 xp\u22122 ,\n|UK \u2212 \u0168K |p\u22122 \u2264 |UK \u2212 VK |p\u22122 + |VK \u2212 \u0168K |p\u22122 . Hence\n(1)\n\n(1)\n\n(1)\n\np\u22122\nE(|UK \u2212 \u0168K |p\u22122 |ZK |) \u2264 kUK \u2212 VK kp\u22122\n|ZK |) .\np kZK kp/2 + E(|VK \u2212 \u0168K |\n\n(5.9)\n\nBy definition of VK , the real kUK \u2212 VK kp is the so-called Wasserstein distance of order p between\n(0)\nthe law of UK and the N(0, 2K ) normal law. Therefrom, by Theorem 3.1 of Rio (2007) (which\nimproves the constants given in Theorem 1 of Rio (1998)), we get that\nkUK \u2212 VK kp \u2264 2(2(p \u2212 1)\u03b6p,K )1/p .\n\n(5.10)\n\nNow, since VK and \u0168K are independent, their difference has the N(0, 2K+1) distribution. Hence,\nby definition of the envelope norm k . k1,\u03a6,p,\n(1)\n\nE(|VK \u2212 \u0168K |p\u22122 |ZK |) \u2264 2(K+1)(p/2\u22121) kZK k1,\u03a6,p .\n\n(5.11)\n\nFrom (5.9), (5.10) and (5.11), we get that\nE(|UK \u2212 \u0168K |\n\np\u22122\n\n(1)\n|ZK |)\n\n\u22642\n\np\u22124/p\n\np\u22122\np\n\n\u03b6p,K kZK kp/2 + 2(K+1)(p/2\u22121) kZK k1,\u03a6,p .\n\n(5.12)\n\nThen, from (5.5), (5.8) and (5.12), we get\n2\nwhere \u2206\u2032N =\n\nPN \u22121\n\n\u2212N\n\nK=0 2\n\n\u03b6p,N \u2264 Mp + 2\n\nK(p/2\u22122)\n\n2\n\n\u2212N\n\np/2\u22123\n\n\u2206\u2032N\n\n+2\n\np\u22122\u22124/p\n\nN\n\u22121\nX\n\nK=0\n\np\u22122\n\np\nkZK kp/2 ,\n2\u2212K \u03b6p,K\n\nkZK k1,\u03a6,p . Consequently we get the induction inequality\n\n\u03b6p,N\n\nN \u22121\n\np\u22122\nX\n1\np\n\u2264 Mp + \u221a \u2206\u2032N +\nkZK kp/2 .\n2\u2212K \u03b6p,K\n2 2\nK=0\n\n20\n\n(5.13)\n\n\fWe now prove (5.1) by induction on N. Assume that \u03b6p,L satisfies (5.1) for any L in [0, N \u2212 1].\nStarting from (5.13), using the induction hypothesis and the fact that \u2206\u2032K \u2264 \u2206\u2032N , we get that\n2\n\n\u2212N\n\n\u03b6p,N\n\nN \u22121\n\n\u0010\u0010\n\u00112/p 2\n\u0011p/2\u22121\nX\n1\n1\n\u22122K/p\n\u2032\n\u2032\n2\nkZK kp/2 Mp + \u221a \u2206N\n+ \u2206K\n\u2264 Mp + \u221a \u2206N +\n.\np\n2 2\n2 2\nK=0\n\nNow 2\u22122K/p kZK kp/2 = \u2206K+1 \u2212 \u2206K . Consequently\n2\n\n\u2212N\n\n\u03b6p,N\n\n1\n\u2264 Mp + \u221a \u2206\u2032N +\n2 2\n\nZ\n\n0\n\n\u2206N\n\n\u0010\u0010\n\n\u00112/p 2 \u0011p/2\u22121\n1\n\u2032\ndx ,\nMp + \u221a \u2206N\n+ x\np\n2 2\n\nwhich implies (5.1) for \u03b6p,N . \u0003\nIn order to prove Theorem 2.1, we will also need a smoothing argument. This is the purpose\nof the lemma below.\n\u221a\nLemma 5.1. For any r in )0, p], \u03b6r (PSn , Gn ) \u2264 2\u03b6r (PSn \u2217 G1 , Gn \u2217 G1 ) + 4 2.\nProof of Lemma 5.1. Throughout the sequel, let Y be a N(0, 1)-distributed random variable,\nindependent of the \u03c3-field generated by the random variables (Xi )i and (Yi )i .\nFor r \u2264 2, since \u03b6r is an ideal metric with respect to the convolution,\n\u03b6r (PSn , Gn ) \u2264 \u03b6r (PSn \u2217 G1 , Gn \u2217 G1 ) + 2\u03b6r (\u03b40 , G1 ) \u2264 \u03b6r (PSn \u2217 G1 , Gn \u2217 G1 ) + 2E|Y |r\nwhich implies Lemma 5.1 for r \u2264 2. For r > 2, from (5.3), for any f in \u039br ,\nf (Sn ) \u2212 f (Sn + Y ) + f \u2032 (Sn )Y \u2212 12 f \u2032\u2032 (Sn )Y 2 \u2264\n\n1\n|Y |r .\nr(r\u22121)\n\nTaking the expectation and noting that E|Y |r \u2264 r \u2212 1 for r in ]2, 3], we infer that\nE(f (Sn ) \u2212 f (Sn + Y ) \u2212 21 f \u2032\u2032 (Sn )) \u2264 1r .\nObviously this inequality still holds for Tn instead of Sn and \u2212f instead of f , so that adding the\nso obtained inequality,\nE(f (Sn ) \u2212 f (Tn ) \u2264 E(f (Sn + Y ) \u2212 f (Tn + Y )) + 12 E(f \u2032\u2032 (Sn ) \u2212 f \u2032\u2032 (Tn )) + 1.\nIt follows that\n\u03b6r (PSn , Gn ) \u2264 \u03b6r (PSn \u2217 G1 , Gn \u2217 G1 ) + 21 \u03b6r\u22122 (PSn , Gn ) + 1.\nNow r \u2212 2 \u2264 1. Hence\n\u03b6r\u22122 (PSn , Gn ) = Wr\u22122 ((PSn , Gn ) \u2264 (Wr (PSn , Gn ))r\u22122 .\n21\n\n\fNext, by Theorem 3.1 in Rio (2007), Wr (PSn , Gn ) \u2264 (32\u03b6r (PSn , Gn ))1/r . Furthermore\n(32\u03b6r (PSn , Gn ))1\u22122/r \u2264 \u03b6r (PSn , Gn )\n\n\u221a\nas soon as \u03b6r (PSn , Gn ) \u2265 2(5r/2)\u22125 . This condition holds for any r in ]2, 3] if \u03b6r (PSn , Gn ) \u2265 4 2.\nThen, from the above inequalities\n\u03b6r (PSn , Gn ) \u2264 \u03b6r (PSn \u2217 G1 , Gn \u2217 G1 ) + 21 \u03b6r (PSn , Gn ) + 1,\nwhich implies Lemma 5.1 \u0003\nWe go back to the proof of Theorem 2.1. We will first complete the proof in the case p = r.\nNext we will derive the general case at the end of the proof.\n\u2217\n\u2217\nby induction on N. Let n \u2208]2N , 2N +1 ].\nLet \u03b6p,N\n= supn\u22642N \u03b6p (PSn , Gn ). We will bound up \u03b6p,N\nHence n = 2N + l with l \u2208 [1, 2N ]. We first notice that\n\u03b6r (PSn , Gn ) \u2264 \u03b6r (PSn , PSl \u2217 G2N ) + \u03b6r (PSl \u2217 G2N , Gl \u2217 G2N ) .\nNow, with the same notation as in the proof of Proposition 5.1, we have\n\u03b6r (PSl \u2217 G2N , Gl \u2217 G2N ) = sup E(f2N (Sl ) \u2212 f2N (Tl )) \u2264 |f \u2217 \u03c62N/2 |\u039bp \u03b6p (PSl , Gl ) .\nf \u2208\u039br\n\nApplying Lemma 6.1, we infer that\n\u03b6r (PSn , Gn ) \u2264 \u03b6r (PSn , PSl \u2217 G2N ) + cr,p 2N (r\u2212p)/2 \u03b6p (PSl , Gl ) .\n\n(5.14)\n\nOn the other hand, setting S\u0303l = X1\u2212l + * * * + X0 , we have that Sn is distributed as S\u0303l + S2N .\nUsing Lemma 5.1, we then derive that\n\u221a\n\u03b6r (PSn , PSl \u2217 G2N ) \u2264 4 2 + 2 sup E(f (S\u0303l + S2N + Y ) \u2212 f (S\u0303l + T2N + Y ))\n\n(5.15)\n\nf \u2208\u039br\n\n\u2032\n2\nLet Dm\n= E(f2\u2032\u2032N \u2212m+1 (S\u0303l + Sm\u22121 )(Xm\n\u2212 1)). Following the proof of Proposition 5.1, we get that\n\nE(f (S\u0303l + S2N + Y ) \u2212 f (S\u0303l + T2N + Y )) = (D1\u2032 + * * * + D2\u2032 N )/2 + R1 + * * * + R2N ,\n\n(5.16)\n\nwhere, as in (5.4),\nRm \u2264 Mp |f2N \u2212m+1 |\u039bp .\nIn the case r = p \u2212 2, we will need the more precise upper bound\n\u0010\n\u0001\u0011 1 (3)\n1 (3)\n2\nRm \u2264 E Xm\nkf2\u2032\u2032N \u2212m+1 k\u221e \u2227 kf2N \u2212m+1 k\u221e |Xm | + kf2N \u2212m+1 k\u221e E(|Ym |3 ) ,\n6\n6\n22\n\n(5.17)\n\n(5.18)\n\n\fwhich is derived from the Taylor formula at orders two and three. From (5.17) and Lemma 6.1,\nwe have that\nR := R1 + * * * + R2N = O(2N (r\u2212p+2)/2 ) if r > p \u2212 2, and R = O(N) if (r, p) = (1, 3) . (5.19)\nIt remains to consider the case r = p \u2212 2 and r < 1. Applying Lemma 6.1, we get that for\ni \u2265 2,\n(i)\n(5.20)\nkf2N \u2212m+1 k\u221e \u2264 cr,i (2N \u2212 m + 1)(r\u2212i)/2 .\nIt follows that\n\u221e\n2N\n\u0010\nX\nX\n\u0001\u0011\n(3)\n2\n\u2032\u2032\n\u2264 C\nE Xm kf2N \u2212m+1 k\u221e \u2227 kf2N \u2212m+1 k\u221e |Xm |\n\nm=1\n\nm=1\n\n1\nm1\u2212r/2\n\nE\n\n\u0012\n\nX02\n\n[X02 ]\n\u0010X\n\u2264 CE\n\nX02\n+\n1\u2212r/2\nm\nm=1\n\n\u0010\n\n\u0013\n|X0 | \u0011\n1\u2227 \u221a\nm\n\u221e\nX\n\nm=[X02 ]+1\n\n|X0 |3 \u0011\n.\nm(3\u2212r)/2\n\nConsequently for r = p \u2212 2 and r < 1,\nR1 + * * * + R2N \u2264 C(Mp + E(|Y |3 )) .\n\n(5.21)\n\nWe now bound up D1\u2032 + * * * + D2\u2032 N . Using the dyadic scheme as in the proof of Proposition\n5.1, we get that\n\u2032\nDm\n\n=\n:=\n\nN\n\u22121\nX\nL=0\n\u2032\u2032\nDm\n\n\u0010\n\u0011\n\u2032\u2032\n\u2032\u2032\n2\n2\nE (f2N \u2212mL (S\u0303l + SmL ) \u2212 f2N \u2212mL+1 (S\u0303l + SmL+1 )(Xm \u2212 1) + E(f2\u2032\u2032N (S\u0303l )(Xm\n\u2212 1))\n2\n+ E(f2\u2032\u2032N (S\u0303l )(Xm\n\u2212 1)) .\n\nNotice first that\nN\n\n2\nX\n\nm=1\n\n(0)\n\n2\nE(f2\u2032\u2032N (S\u0303l )(Xm\n\u2212 1)) = E((f2\u2032\u2032N (S\u0303l ) \u2212 f2\u2032\u2032N (Tl ))ZN ) .\n\nHence using Lemma 6.1, we get that\nN\n\n2\nX\n\nm=1\n\n(0)\n\n2\nE(f2\u2032\u2032N (S\u0303l )(Xm\n\u2212 1)) \u2264 C2N (r\u2212p)/2 E(|S\u0303l \u2212 Tl |p\u22122|ZN |) .\n\nProceeding as to get (5.12), we have that\n(0)\n\n(0)\n\n(0)\n\nE(|S\u0303l \u2212 Tl |p\u22122 |ZN |) \u2264 2p\u22124/p (\u03b6p (PSl , Gl ))(p\u22122)/p kZN kp/2 + (2l)p/2\u22121 kZN k1,\u03a6,p .\n23\n\n\f(0)\n\n(0)\n\nUsing Remark 2.5, (2.1) and (2.2) entail that kZN kp/2 = o(22N/p ) and kZN k1,\u03a6,p = o(2N (2\u2212p/2 ).\nHence, for some \u01eb(N) tending to 0 as N tends to infinity, one has\nD1\u2032 + * * * + D2\u2032 N \u2264 C(\u01eb(N)2N ((r\u2212p)/2+2/p (\u03b6p (PSl , Gl ))(p\u22122)/p + 2N (r+2\u2212p)/2 ) .\n\n(5.22)\n\nNext, proceeding as in the proof of (5.7), we get that\nN\n\n2\nX\n\n\u2032\u2032\nDm\n\nm=1\n\n\u2264\n\nN\n\u22121\nX\n\n\u0010\n\u0001 (k) \u0011\n\u2032\u2032\n\u2032\u2032\nE f2N \u2212k2L (S\u0303l + Sk2L ) \u2212 f2N \u2212k2L (S\u0303l + S(k\u22121)2L + Tk2L \u2212 T(k\u22121)2L ) ZL .\n\nX\n\nL=0\n\nk\u2208IN\u2212L,0\nk odd\n\nIf r > p \u2212 2 or (r, p) = (1, 3), from Lemma 6.1, the stationarity of (Xi )i\u2208N and the above\ninequality,\nN\n\n2\nX\n\nm=1\n\nN\n\u22121\nX\n\n\u2032\u2032\nDm\n\u2264 C\n\nL=0\n\nX\n\nk\u2208IN\u2212L,0\nk odd\n\n(1)\n\n(2N \u2212 k2L )(r\u2212p)/2 E |UL \u2212 \u0168L |p\u22122 ZL\n\n\u0001\n\n.\n\nIt follows that\nN\n\n2\nX\n\n\u2032\u2032\nDm\n\nm=1\n\n\u2264 C2\n\nN (r+2\u2212p)/2\n\nL=0\n\nN\n\n2\nX\n\nm=1\n\nN\nX\n\n\u2032\u2032\nDm\n\u2264 CN\n\nN\nX\nL=0\n\n2\u2212L E UL \u2212 \u0168L\n(1)\n\n2\u2212L E UL \u2212 \u0168L ZL\n\nIn the case r = p \u2212 2 and r > 1, we have\nN\n\n2\nX\n\n\u2032\u2032\nDm\n\nm=1\n\n\u2264 C\n\nN\n\u22121\nX\nL=0\n\nX\n\nk\u2208IN\u2212L,0\nk odd\n\n\u0001\n\np\u22122\n\n(1)\n\nZL\n\n\u0001\n\nif r > p \u2212 2,\n\nif r = 1 and p = 3.\n\n(5.23)\n\n(5.24)\n\n\u0010\n\u0001 (1) \u0011\n\u2032\u2032\n\u2032\u2032\u2032\nE kf2N \u2212k2L k\u221e \u2227 kf2N \u2212k2L k\u221e UL \u2212 \u0168L ZL\n.\n\nApplying (5.20) to i = 2 and i = 3, we obtain\nN\n\n2\nX\n\n\u2032\u2032\nDm\n\nm=1\n\n\u2264C\n\nN\nX\n\n2\n\n(r\u22122)L/2\n\nL=0\n\nN\u2212L\n2X\n\u0010\n(1)\nk (r\u22122)/2 1 \u2227\nE ZL\n\nk=1\n\nProceeding as to get (5.21), we have that\nN\u2212L\n2X\n\nk\n\n(r\u22122)/2\n\nk=1\n\nIt follows that\n\n\u0001\u0011\n1\n\u221a UL \u2212 \u0168L\n,\n2L/2 k\n\n\u221e\n\u0001 X\n\u0001\n1\n1\nr\n\u221a UL \u2212 \u0168L \u2264\n\u221a UL \u2212 \u0168L \u2264 C|UL \u2212 \u0168L .\n1\u2227\nk (r\u22122)/2 1 \u2227\n2L/2 k\n2L/2 k\nk=1\nN\n\n2\nX\n\nm=1\n\n\u2032\u2032\nDm\n\n\u2264C\n\nN\nX\nL=0\n\n2\n\n\u2212L\n\n\u0010\nE UL \u2212 \u0168L\n\nr\n\n24\n\n(1)\nZL\n\n\u0011\n\nif r = p \u2212 2 and r < 1.\n\n(5.25)\n\n\fNow by Remark 2.5, (2.1) and (2.2) are respectively equivalent to\nX\nX\n2K(p/2\u22122) kZK k1,\u03a6,p < \u221e , and\n2\u22122K/p kZK kp/2 < \u221e .\nK\u22650\n\nK\u22650\n\nNext, by Proposition 5.1, \u03b6p,K = O(2K ) under (2.1) and (2.2). Therefrom, taking into account\nthe inequality (5.12), we derive that under (2.1) and (2.2),\n\u0010\n\u0011\np\u22122\n(1)\n\u2212L\n2 E UL \u2212 \u0168L\nZL\n\u2264 C2\u22122L/p kZL kp/2 + C2L(p/2\u22122) kZK k1,\u03a6,p .\n(5.26)\nConsequently, combining (5.26) with the upper bounds (5.23), (5.24) and (5.25), we obtain that\n(\n2N\nX\nO(2N (r+2\u2212p)/2 ) if r \u2265 p \u2212 2 and (r, p) 6= (1, 3)\n\u2032\u2032\n(5.27)\nDm\n=\nO(N)\nif\nr\n=\n1\nand\np\n=\n3.\nm=1\n\nFrom (5.14), (5.15), (5.16), (5.19), (5.21), (5.22) and (5.27), we get that if r \u2265 p \u2212 2 and\n(r, p) 6= (1, 3),\n\u03b6r (PSn , Gn ) \u2264 cr,p 2N (r\u2212p)/2 \u03b6p (PSl , Gl ) + C(2N (r+2\u2212p)/2 + 2N ((r\u2212p)/2+2/p) \u01eb(N)(\u03b6p (PSl , Gl ))(p\u22122)/p )\n(5.28)\nand if r = 1 and p = 3,\n\u03b61 (PSn , Gn ) \u2264 C(N + 2\u2212N \u03b63 (PSl , Gl ) + 2\u2212N/3 (\u03b63 (PSl , Gl ))1/3 ) .\n\n(5.29)\n\n\u2217\nSince \u03b6p,N\n= supn\u22642N \u03b6p (PSn , Gn ), we infer from (5.28) applied to r = p that\nN\n2N/p\n\u2217\n\u2217\n\u2217\n)(p\u22122)/p ) .\n\u01eb(N)(\u03b6p,N\n\u03b6p,N\n+1 \u2264 \u03b6p,N + C(2 + 2\n\u2217\nLet N0 be such that C\u01eb(N) \u2264 1/2 for N \u2264 N0 , and let K \u2265 1 be such that \u03b6p,N\n\u2264 K2N0 .\n0\n\u2217\nChoosing K large enough such that K \u2265 2C, we can easily prove by induction that \u03b6p,N\n\u2264 K2N\nfor any N \u2265 N0 . Hence Theorem 2.1 is proved in the case r = p.\n\u2217\nFor r in [p \u2212 2, p[, Theorem 2.1 follows by taking into account the bound \u03b6p,N\n\u2264 K2N , valid\nfor any N \u2265 N0 , in the inequalities (5.28) and (5.29).\n\n5.2\n\nProof of Theorem 3.1\n\nBy (3.1), we get that (see Voln\u00fd (1993))\nX0 = D0 + Z0 \u2212 Z0 \u25e6 T,\n\n(5.30)\n\nwhere\nZ0 =\n\n\u221e\nX\nk=0\n\nE(Xk |F\u22121 ) \u2212\n\n\u221e\nX\nk=1\n\n(X\u2212k \u2212 E(X\u2212k |F\u22121)) and D0 =\n25\n\nX\nk\u2208Z\n\nE(Xk |F0) \u2212 E(Xk |F\u22121 ) .\n\n\fNote that D0 \u2208 Lp , D0 is F0 -measurable, and E(D0 |F\u22121) = 0. Let Di = D0 \u25e6T i , and Zi = Z0 \u25e6T i .\nWe obtain that\nSn = Mn + Z1 \u2212 Zn+1 ,\n(5.31)\nPn\nwhere Mn = j=1 Dj . We first bound up E(f (Sn ) \u2212 f (Mn )) by using the following lemma\nLemma 5.2. Let p \u2208]2, 3] and r \u2208 [p \u2212 2, p]. Let (Xi )i\u2208Z be a stationary sequence of centered\nrandom variables in L2\u2228r . Assume that Sn = Mn + Rn where (Mn \u2212 Mn\u22121 )n>1 is a strictly\nstationary sequence of martingale differences in L2\u2228r , and Rn is such that E(Rn ) = 0. Let\nn\u03c3 2 = E(Mn2 ), n\u03c3n2 = E(Sn2 ) and \u03b1n = \u03c3n /\u03c3.\n1. If r \u2208 [p \u2212 2, 1] and E|Rn |r = O(n(r+2\u2212p)/2 ), then \u03b6r (PSn , PMn ) = O(n(r+2\u2212p)/2 ).\n2. If r \u2208]1, 2] and kRn kr = O(n(3\u2212p)/2 ), then \u03b6r (PSn , PMn ) = O(n(r+2\u2212p)/2 ).\n3. If r \u2208]2, p], \u03c3 2 > 0 and kRn kr = O(n(3\u2212p)/2 ), then \u03b6r (PSn , P\u03b1n Mn ) = O(n(r+2\u2212p)/2 ).\n4. If r \u2208]2, p], \u03c3 2 = 0 and kRn kr = O(n(r+2\u2212p)/2r ), then \u03b6r (PSn , Gn\u03c3n2 ) = O(n(r+2\u2212p)/2 ).\nRemark 5.1. All the assumptions of Lemma 5.2 are satisfied as soon as supn>0 kRn kp < \u221e.\nProof of Lemma 5.2. For r \u2208]0, 1], \u03b6r (PSn , PMn ) \u2264 E(|Rn |r ), which implies item 1. If f \u2208 \u039br\nwith r \u2208]1, 2], from the Taylor integral formula and since E(Rn ) = 0, we get\nZ 1\n\u0010 \u0010\n\u0011\u0011\n\u2032\n\u2032\n\u2032\n\u2032\nE(f (Sn ) \u2212 f (Mn )) = E Rn f (Mn ) \u2212 f (0) +\n(f (Mn + t(Rn )) \u2212 f (Mn ))dt\n0\n\n\u2032\n\n\u2032\n\n\u2264 kRn kr kf (Mn ) \u2212 f (0)kr/(r\u22121) + kRn krr \u2264 kRn kr kMn krr\u22121 + kRn krr .\n\u221a\nSince kMn kr \u2264 kMn k2 = n\u03c3, we infer that \u03b6r (PSn , PMn ) = O(n(r+2\u2212p)/2 ).\nNow if f \u2208 \u039br with r \u2208]2, p] and if \u03c3 > 0, we define g by\ng(t) = f (t) \u2212 tf \u2032 (0) \u2212 t2 f \u2032\u2032 (0)/2 .\n\nThe function g is then also in \u039br and is such that g \u2032(0) = g \u2032\u2032 (0) = 0. Since \u03b1n2 E(Mn2 ) = E(Sn2 ),\nwe have\nE(f (Sn ) \u2212 f (\u03b1n Mn )) = E(g(Sn ) \u2212 g(\u03b1n Mn )) .\n(5.32)\nNow from the Taylor integral formula at order two, setting R\u0303n = Rn + (1 \u2212 \u03b1n )Mn ,\n\n1\nE(g(Sn ) \u2212 g(\u03b1n Mn )) = E(R\u0303n g \u2032 (\u03b1n Mn )) + E((R\u0303n )2 g \u2032\u2032 (\u03b1n Mn ))\n2\nZ 1\n\u0001\n+E (R\u0303n )2\n(1 \u2212 t)(g \u2032\u2032(\u03b1n Mn + tR\u0303n ) \u2212 g \u2032\u2032 (\u03b1n Mn ))dt\n0\n\n1\n1\n1\nE(|R\u0303n ||\u03b1n Mn |r\u22121 ) + kR\u0303n k2r kg \u2032\u2032 (\u03b1n Mn )kr/(r\u22122) + kR\u0303n krr\n\u2264\nr\u22121\n2\n2\n1\n1\n\u2264\n\u03b1r\u22121 kR\u0303n kr kMn krr\u22121 + \u03b1nr\u22122 kR\u0303n k2r kMn krr\u22122 + kR\u0303n krr .\nr\u22121 n\n2\n26\n\n\fNow \u03b1n = O(1) and kR\u0303n kr \u2264 kRn kr + |1 \u2212 \u03b1n |kMn kr . Since |kSn k2 \u2212 kMn k2 | \u2264 kRn k2 , we infer\nthat |1 \u2212 \u03b1n | = O(n(2\u2212p)/2 ). Hence, applying Burkh\u00f6lder's inequality for martingales, we infer\nthat kR\u0303n kr = O(n(3\u2212p)/2 ), and consequently \u03b6r (PSn , P\u03b1n Mn ) = O(n(r+2\u2212p)/2 ).\n\u221a\n\u221a\nIf \u03c3 2 = 0, then Sn = Rn . Using that E(f (Sn ) \u2212 f ( n\u03c3n Y )) = E(g(Rn ) \u2212 g( n\u03c3n Y )), and\napplying again Taylor's formula, we obtain that\n\u221a\n\u221a\n1\n1\nkR\u0304n kr k n\u03c3n Y krr\u22121 + kR\u0304n k2r k n\u03c3n Y krr\u22122 + kR\u0304n krr ,\nr\u22121\n2\nf \u2208\u039br\n\u221a\n\u221a\nwhere R\u0304n = Rn \u2212 n\u03c3n Y . Since n\u03c3n = kRn k2 = O(n(r+2\u2212p)/2r ), the result follows. \u0003\n\u221a\nsup |E(f (Sn ) \u2212 f ( n\u03c3n Y ))| \u2264\n\nBy (5.31), we can apply Lemma 5.2 with Rn := Z1 \u2212 Zn+1 . Then for p \u2212 2 \u2264 r \u2264 2, the\nresult follows if we prove that under (3.2), Mn satisfies the conclusion of Theorem 2.1. Now if\n2 < r \u2264 p and \u03c3 2 > 0, we first notice that\n\u03b6r (P\u03b1n Mn , Gn\u03c3n2 ) = \u03b1nr \u03b6r (PMn , Gn\u03c32 ) .\nSince \u03b1n = O(1), the result will follow by Item 3 of Lemma 5.2, if we prove that under (3.2),\nMn satisfies the conclusion of Theorem 2.1. We shall prove that\nX 1\nkE(Mn2 |F0) \u2212 E(Mn2 )kp/2 < \u221e .\n(5.33)\n3\u2212p/2\nn\nn\u22651\nIn this way, both (2.1) and (2.2) will be satisfied. Suppose that we can show that\nX\nn\u22651\n\n1\nn3\u2212p/2\n\nkE(Mn2 |F0 ) \u2212 E(Sn2 |F0)kp/2 < \u221e ,\n\n(5.34)\n\nthen by taking into account the condition (3.2), (5.33) will follow. Indeed, it suffices to notice\nthat (5.34) also entails that\nX\nn\u22651\n\n1\nn3\u2212p/2\n\n|E(Sn2 ) \u2212 E(Mn2 )| < \u221e ,\n\n(5.35)\n\nand to write that\nkE(Mn2 |F0 ) \u2212 E(Mn2 )kp/2 \u2264 kE(Mn2 |F0 ) \u2212 E(Sn2 |F0)kp/2\n\n+kE(Sn2 |F0) \u2212 E(Sn2 )kp/2 + |E(Sn2 ) \u2212 E(Mn2 )| .\n\nHence, it remains to prove (5.34). Since Sn = Mn + Z1 \u2212 Zn+1 , and since Zi = Z0 \u25e6 T i is in Lp ,\n(5.34) will be satisfied provided that\nX\nn\u22651\n\n1\nn3\u2212p/2\n\nkSn (Z1 \u2212 Zn+1 )kp/2 < \u221e .\n27\n\n(5.36)\n\n\fNotice that\nkSn (Z1 \u2212 Zn+1)kp/2 \u2264 kMn kp kZ1 \u2212 Zn+1 kp + kZ1 \u2212 Zn+1 k2p .\n\n\u221a\nFrom Burkholder's inequality, kMn kp = O( n) and from (3.1), supn kZ1 \u2212 Zn+1 kp < \u221e. Consequently (5.36) is satisfied for any p in ]2, 3[.\n\n5.3\n\nProof of Theorem 3.2\n\nStarting from (5.31) we have that\nMn := Sn + Rn + R\u0303n ,\n\n(5.37)\n\nwhere\nRn =\n\nX\n\nk\u2265n+1\n\nX\nX\nX\nE(Xk |Fn )\u2212\nE(Xk |F0 ) and R\u0303n =\n(X\u2212k \u2212E(X\u2212k |F0 ))\u2212\n(X\u2212k \u2212E(X\u2212k |Fn )) .\nk\u22651\n\nk\u22650\n\nk\u2265\u2212n\n\nArguing as in the proof of Proposition 3.1 the proposition will follow from (3.5), if we prove that\n\u221e\nX\n1\nkE(Mn2 |F0 ) \u2212 E(Sn2 |F0)k3/2 < \u221e .\n3/2\nn\nn\u22651\n\n(5.38)\n\nUnder (3.4), supn\u22651 kRn k3 < \u221e and supn\u22651 kR\u0303n k3 < \u221e. Hence (5.38) will be verified as soon as\n\u221e\nX\n1\nkE(Sn (Rn + R\u0303n )|F0 )k3/2 < \u221e .\n3/2\nn\nn=1\n\n(5.39)\n\nWe first notice that the decomposition (5.37) together with Burkholder's inequality for martingales and the fact that supn kRn k3 < \u221e and supn kR\u0303n k3 < \u221e, implies that\n\u221a\nkSn k3 \u2264 C n .\n\nNow to prove (5.39), we first notice that\n\u0010 X\n\u0011\nE Sn\nE(Xk |F0 ) F0\nk\u22651\n\n3/2\n\n\u2264 kE(Sn |F0 )k3\n\n(5.40)\n\nX\nk\u22651\n\nE(Xk |F0)\n\n3\n\n,\n\nwhich is bounded by using (3.4). Now write\n\u0011\n\u0011\n\u0010\n\u0010\nX\nX\nE(Xk |Fn ) F0 + E(Sn E(S2n \u2212 Sn |Fn )|F0 ) .\nE(Xk |Fn ) F0 = E Sn\nE Sn\nk\u2265n+1\n\nk\u22652n+1\n\n28\n\n(5.41)\n\n\fClearly\n\u0011\n\u0010\nX\nE(Xk |Fn ) F0\nE Sn\nk\u22652n+1\n\n3/2\n\n\u2264 kSn k3\n\u221a\n\u2264 C n\n\nX\n\nk\u22652n+1\n\nX\n\nk\u2265n+1\n\nE(Xk |Fn )\n\nE(Xk |F0 )\n\n3\n\n3\n\n,\n\n(5.42)\n\nby using (5.40). Considering the bounds (5.41) and (5.42) and the condition (3.4), in order to\nprove that\n\u221e\nX\n1\nkE(Sn Rn |F0)k3/2 < \u221e ,\n(5.43)\n3/2\nn\nn=1\nit is sufficient to prove that\n\n\u221e\nX\n1\nkE(Sn E(S2n \u2212 Sn |Fn )|F0 )k3/2 < \u221e .\n3/2\nn\nn=1\n\u221a\nWith this aim, take pn = [ n] and write\n\nE(Sn E(S2n \u2212 Sn |Fn )|F0 ) = E((Sn \u2212 Sn\u2212pn )E(S2n \u2212 Sn |Fn )|F0 )\n+E(Sn\u2212pn E(S2n \u2212 Sn |Fn )|F0 ).\n\n(5.44)\n\n(5.45)\n\nBy stationarity and (5.40), we get that\n\u221e \u221a\n\u221e\nX\nX\npn\n1\nkE((Sn \u2212 Sn\u2212pn )E(S2n \u2212 Sn |Fn )|F0 )k3/2 \u2264 C\nkE(Sn |F0)k3 ,\n3/2\n3/2\nn\nn\nn=1\nn=1\n\u221a\nwhich is finite under (3.4), since pn = [ n]. Hence from (5.45), (5.44) will follow if we prove\nthat\n\u221e\nX\n1\n(5.46)\nkE(Sn\u2212pn E(S2n \u2212 Sn |Fn )|F0 )k3/2 < \u221e .\n3/2\nn\nn=1\n\nWith this aim we first notice that\n\nkE((Sn\u2212pn \u2212 E(Sn\u2212pn |Fn\u2212pn )E(S2n \u2212 Sn |Fn )|F0)k3/2\n\n\u2264 kSn\u2212pn \u2212 E(Sn\u2212pn |Fn\u2212pn )k3 kE(S2n \u2212 Sn |Fn )k3 ,\n\nwhich is bounded under (3.4). Consequently (5.46) will hold if we prove that\n\u221e\nX\n1\nkE(E(Sn\u2212pn |Fn\u2212pn )E(S2n \u2212 Sn |Fn )|F0 )k3/2 < \u221e .\n3/2\nn\nn=1\n\nWe first notice that\nE(E(Sn\u2212pn |Fn\u2212pn )E(S2n \u2212 Sn |Fn )|F0 ) = E(E(Sn\u2212pn |Fn\u2212pn )E(S2n \u2212 Sn |Fn\u2212pn )|F0) ,\n29\n\n(5.47)\n\n\fand by stationarity and (5.40)\nkE(E(Sn\u2212pn |Fn\u2212pn )E(S2n \u2212 Sn |Fn\u2212pn )|F0 )k3/2 \u2264 kSn\u2212pn k3 kE(S2n \u2212 Sn |Fn\u2212pn )k3\n\u221a\n\u2264 C nkE(Sn+pn \u2212 Spn |F0 )k3 .\nHence (5.47) will hold provided that\nX1\nn\nn\u22651\n\nX\n\n\u221a\nk\u2265[ n]\n\nE(Xk |F0 )\n\n3\n\n< \u221e.\n\n(5.48)\n\nThe fact that (5.48) holds under the first part of the condition (3.4) follows from the following\nP\nelementary lemma applied to h(x) = k k\u2265[x] E(Xk |F0)k3 .\n\u221a\n\u221a\nLemma 5.3. Assume that h is a positive function on R+ satisfying h( x + 1) = h( n) for any\nP\nP\n\u221a\nx in [n \u2212 1, n[. Then n\u22651 n\u22121 h( n) < \u221e if and only if n\u22651 n\u22121 h(n) < \u221e.\nIt remains to show that\n\n\u221e\nX\n1\nkE(Sn R\u0303n |F0)k3/2 < \u221e .\n3/2\nn\nn=1\n\nWrite\nSn R\u0303n = Sn\n\n\u0010X\nk\u22650\n\n(X\u2212k \u2212 E(X\u2212k |F0 )) \u2212\n\n\u0010\n\n= Sn E(Sn |Fn ) \u2212 Sn +\n\nX\nk\u22650\n\nX\n\n(5.49)\n\n(X\u2212k \u2212 E(X\u2212k |Fn ))\n\nk\u2265\u2212n\n\n\u0011\n\n\u0011\n\n(E(X\u2212k |Fn ) \u2212 E(X\u2212k |F0)) .\n\nNotice first that\n\u0001\n\u0001\nkE Sn (Sn \u2212 E(Sn |Fn ))|F0 k3/2 = kE (Sn \u2212 E(Sn |Fn ))2 |F0 k3/2\n\u2264 kSn \u2212 E(Sn |Fn )k23 ,\n\n\u221a\nwhich is bounded under the second part of the condition (3.4). Now for pn = [ n], we write\nX\nX\nX\n(E(X\u2212k |Fpn ) \u2212E(X\u2212k |F0 )).\n(E(X\u2212k |Fn ) \u2212E(X\u2212k |F0 )) =\n(E(X\u2212k |Fn ) \u2212E(X\u2212k |Fpn )) +\nk\u22650\n\nNote that\nX\n(E(X\u2212k |Fpn ) \u2212 E(X\u2212k |F0))\nk\u22650\n\nk\u22650\n\nk\u22650\n\n3\n\n=\n\nX\nk\u22650\n\n\u2264\n\nX\nk\u22650\n\n(X\u2212k \u2212 E(X\u2212k |F0 )) \u2212\n(X\u2212k \u2212 E(X\u2212k |F0 ))\n30\n\n3\n\nX\nk\u22650\n\n+\n\n(X\u2212k \u2212 (E(X\u2212k |Fpn ))\nX\n\nk\u2265pn\n\n3\n\n(X\u2212k \u2212 (E(X\u2212k |F0 ))\n\n3\n\n,\n\n\fwhich is bounded under the second part of the condition (3.4). Next, since the random variable\nP\nk\u22650 (E(X\u2212k |Fpn ) \u2212 E(X\u2212k |F0 )) is Fpn -measurable, we get\n\u0011\n\u0010 X\nE Sn\n(E(X\u2212k |Fpn ) \u2212 E(X\u2212k |F0 ))|F0\n3/2\n\nk\u22650\n\n\u0011\n\u0010\nX\n(E(X\u2212k |Fpn ) \u2212 E(X\u2212k |F0 ))|F0\n\u2264 E Sp n\nk\u22650\n\n+kE(Sn \u2212 Spn |Fpn )k3\n\nX\nk\u22650\n\n3/2\n\n(E(X\u2212k |Fpn ) \u2212 E(X\u2212k |F0))\n\n3\n\n\u0011 X\n\u0010\n(E(X\u2212k |Fpn ) \u2212 E(X\u2212k |F0))\n\u2264 kSpn k3 + kE(Sn\u2212pn |F0)k3\nk\u22650\n\n3\n\n\u221a\n\u2264 C pn ,\n\n\u221a\nby using (3.4) and (5.40). Hence, since pn = [ n], we get that\n\n\u221e\n\u0011\n\u0010 X\nX\n1\nF\n)\n\u2212\nE(X\n|F\n))\n(E(X\n|F\nE\nS\n0\n\u2212k\n0\n\u2212k\npn\nn\nn3/2\nn=1\nk\u22650\n\n3/2\n\n< \u221e.\n\n3/2\n\n< \u221e.\n\nIt remains to show that\n\u221e\n\u0011\n\u0010 X\nX\n1\n))\nF\nE\nS\n(E(X\n|F\n)\n\u2212\nE(X\n|F\n0\nn\n\u2212k\nn\n\u2212k\npn\nn3/2\nn=1\nk\u22650\n\nNote first that\nX\n(E(X\u2212k |Fn ) \u2212 E(X\u2212k |Fpn ))\nk\u22650\n\n3\n\nX\n\n=\n\nk\u22650\n\nX\n\n\u2264\n\nk\u2265n\n\nIt follows that\n\u0011\n\u0010 X\nE Sn\n(E(X\u2212k |Fn ) \u2212 E(X\u2212k |Fpn ))|F0\nk\u22650\n\n(X\u2212k \u2212 E(X\u2212k |Fn )) \u2212\n\nX\nk\u22650\n\n(X\u2212k \u2212 E(X\u2212k |F0 ))k3 + k\n\n(5.50)\n\n(X\u2212k \u2212 (E(X\u2212k |Fpn ))\nX\n\nk\u2265pn\n\n3\n\n(X\u2212k \u2212 (E(X\u2212k |F0))\n\n3/2\n\n\u221a \u0010 X\n\u2264C n\n(X\u2212k \u2212 (E(X\u2212k |F0)) +\nk\u2265pn\n\n3\n\n+\n\nX\nk\u2265n\n\n(X\u2212k \u2212 (E(X\u2212k |F0 ))\n\n3\n\n\u0011\n\n.\n\nby taking into account (5.40). Consequently (5.50) will follow as soon as\nX1\nn\nn\u22651\n\nX\n\n(X\u2212k \u2212 E(X\u2212k |F0 ))\n\n\u221a\nk\u2265[ n]\n\n3\n\n< \u221e,\n\nwhich holds under the second part of the condition (3.4), by applying Lemma 5.3 with h(x) =\nP\nk k\u2265[x] (X\u2212k \u2212 E(X\u2212k |F0 ))k3 . This ends the proof of the theorem.\n31\n\n3\n\n.\n\n\f6\n6.1\n\nAppendix\nA smoothing lemma.\n\nLemma 6.1. Let r > 0 and f be a function such that |f |\u039br < \u221e (see Notation 5.1 for the\ndefinition of the seminorm | * |\u039br ). Let \u03c6t be the density of the law N(0, t2 ). For any real p \u2265 r\nand any positive t, |f \u2217 \u03c6t |\u039bp \u2264 cr,p tr\u2212p |f |\u039br for some positive constant cr,p depending only on r\nand p. Furthermore cr,r = 1.\nRemark 6.1. In the case where p is a positive integer, the result of Lemma 6.1 can be written\n(p)\nas kf \u2217 \u03c6t k\u221e \u2264 cr,p tr\u2212p |f |\u039br .\nProof of Lemma 6.1. Let j be the integer such that j < r \u2264 j + 1. In the case where p is a\npositive integer, we have\nZ\n\u0001 (p\u2212j)\n(p)\n(f \u2217 \u03c6t ) (x) =\nf (j) (u) \u2212 f (j) (x) \u03c6t\n(x \u2212 u)du\nsince p \u2212 j \u2265 1 .\n\nSince |f (j)(u) \u2212 f (j) (x)| \u2264 |x \u2212 u|r\u2212j |f |\u039br , we obtain that\nZ\nZ\n(p\u2212j)\nr\u2212j (p\u2212j)\n(p)\n(u)|du .\n(x \u2212 u)|du \u2264 |f |\u039br |u|r\u2212j |\u03c6t\n|(f \u2217 \u03c6t ) (x)| \u2264 |f |\u039br |x \u2212 u| |\u03c6t\n(p\u2212j)\n\n(p\u2212j)\n\nUsing that \u03c6t\n(x) = t\u2212p+j\u22121\u03c61 (x/t), we conclude that Lemma 6.1 holds with the constant\nR r\u2212j p\u2212j\ncr,p = |z| \u03c61 (z)dz.\nThe case p = r is straightforward. In the case where p is such that j < r < p < j + 1, by\ndefinition\n|f (j) \u2217 \u03c6t (x) \u2212 f (j) \u2217 \u03c6t (y)| \u2264 |f |\u039br |x \u2212 y|r\u2212j .\nAlso, by Lemma 6.1 applied with p = j + 1,\n|f (j) \u2217 \u03c6t (x) \u2212 f (j) \u2217 \u03c6t (y)| \u2264 |x \u2212 y|kf (j+1) \u2217 \u03c6t k\u221e \u2264 |f |\u039br cr,j+1tr\u2212j\u22121 |x \u2212 y| .\nHence by interpolation,\n(p\u2212r)/(j+1\u2212r)\n\n|f (j) \u2217 \u03c6t (x) \u2212 f (j) \u2217 \u03c6t (y)| \u2264 |f |\u039br tr\u2212p cr,j+1\n\n|x \u2212 y|p\u2212j .\n\nIt remains to consider the case where r \u2264 i < p \u2264 i + 1. By Lemma 6.1 applied successively\nwith p = i and p = i + 1, we obtain that\n|f (i+1) \u2217 \u03c6t (x)| \u2264 |f |\u039br cr,i+1 tr\u2212i\u22121 and |f (i) \u2217 \u03c6t (x)| \u2264 |f |\u039br cr,i tr\u2212i .\nConsequently\n|f (i) \u2217 \u03c6t (x) \u2212 f (i) \u2217 \u03c6t (y)| \u2264 |f |\u039br tr\u2212i (2cr,i \u2227 cr,i+1 t\u22121 |x \u2212 y|) ,\nand by interpolation,\np\u2212i\n|f (i) \u2217 \u03c6t (x) \u2212 f (i) \u2217 \u03c6t (y)| \u2264 |f |\u039br tr\u2212p (2cr,i )1\u2212p+i cp\u2212i\n.\nr,i+1 |x \u2212 y|\n\n32\n\n\f6.2\n\nCovariance inequalities.\n\nIn this section, we give an upper bound for the expectation of the product of k centered random\nvariables \u03a0ki=1 (Xi \u2212 E(Xi )).\nProposition 6.1. Let X = (X1 , * * * , Xk ) be a random variable with values in Rk . Define the\nnumber\n\u03c6(i) = \u03c6(\u03c3(Xi ), X1 , . . . , Xi\u22121 , Xi+1 , . . . , Xk )\n(6.1)\nk\nk\n\u0010 Y\n\u0011\n\u0010 Y\n\u0011\n= sup E\n(1IXj >xi \u2212 P(Xi > xi ))|\u03c3(Xi ) \u2212 E\n(1IXj >xi \u2212 P(Xi > xi ))\n.\nx\u2208Rk\n\nj=1,j6=i\n\nj=1,j6=i\n\n\u221e\n\nLet Fi be the distribution function of Xi and Qi be the quantile function of |Xi | (see Section 4.1 for\nthe definition). Let Fi\u22121 be the generalized inverse of Fi and let Di (u) = (Fi\u22121 (1 \u2212 u) \u2212 Fi\u22121 (u))+ .\nWe have the inequalities\nZ\nk\n\u0010Y\n\u0011\nE\nXi \u2212 E(Xi ) \u2264\n\n0\n\ni=1\n\nand\n\n1\n\nZ\nk\n\u0010Y\n\u0011\nk\nE\nXi \u2212 E(Xi ) \u2264 2\ni=1\n\nk\n\u0010Y\ni=1\n\n1\n0\n\n\u0011\nDi (u/\u03c6 ) du\n\nk\n\u0010Y\ni=1\n\n(i)\n\n\u0011\nQi (u/\u03c6(i) ) du .\n\n(6.2)\n\n(6.3)\n\nIn addition, for any k-tuple (p1 , . . . , pk ) such that 1/p1 + . . . + 1/pk = 1, we have\nk\nk\n\u0010Y\n\u0011\nY\nk\nE\nXi \u2212 E(Xi ) \u2264 2\n(\u03c6(i) )1/pi kXi kpi .\ni=1\n\n(6.4)\n\ni=1\n\nProof of Proposition 6.1. We have that\nk\nk\n\u0010Y\n\u0011 Z \u0010Y\n\u0011\nE\nXi \u2212 E(Xi ) = E\n1IXi >xi \u2212 P(Xi > xi ) dx1 . . . dxk .\ni=1\n\n(6.5)\n\ni=1\n\nNow for all i,\nk\n\u0010Y\n\u0011\nE\n1IXi >xi \u2212 P(Xi > xi )\ni=1\n\n!\nk\nk\n\u0010 \u0010 Y\n\u0011\n\u0010 Y\n\u0011\u0011\n= E 1IXi >xi E\n(1IXj >xi \u2212 P(Xi > xi ))|\u03c3(Xi ) \u2212 E\n(1IXj >xi \u2212 P(Xi > xi ))\nj=1,j6=i\n\nj=1,j6=i\n\n!\nk\nk\n\u0010 \u0010 Y\n\u0011\n\u0010 Y\n\u0011\u0011\n.\n= E 1IXi \u2264xi E\n(1IXj >xi \u2212 P(Xi > xi ))|\u03c3(Xi ) \u2212 E\n(1IXj >xi \u2212 P(Xi > xi ))\nj=1,j6=i\n\nj=1,j6=i\n\n33\n\n\fConsequently, for all i,\nk\n\u0010Y\n\u0011\nE\n1IXi >xi \u2212 P(Xi > xi ) \u2264 \u03c6(i) P(Xi \u2264 xi ) \u2227 P(Xi > xi ) .\n\n(6.6)\n\ni=1\n\nHence, we obtain from (6.5) and (6.6) that\nZ 1\u0010Y\nk\nk Z\n\u0010Y\n\u0011\n\u0011\nE\nXi \u2212 E(Xi )\n\u2264\n1Iu/\u03c6(i) <P(Xi >xi ) 1Iu/\u03c6(i) \u2264P(Xi \u2264xi ) dxi du\n0\n\ni=1\n\n\u2264\n\nZ\n\ni=1\n\n1\n\n0\n\nk Z\n\u0010Y\n\n\u0011\n1IFi\u22121 (u/\u03c6(i) )\u2264xi <Fi\u22121 (1\u2212u/\u03c6(i) ) dxi du,\n\ni=1\n\nand (6.2) follows. Now (6.3) comes from (6.2) and the fact that Di (u) \u2264 2Qi (u) (see Lemma 6.1\nin Dedecker and Rio (2006)). \u0003\nDefinition 6.1. For a quantile function Q in L1 ([0, 1], \u03bb), let F (Q, PX ) be the set of functions f\nwhich are nondecreasing on some open interval of R and null elsewhere and such that Q|f (X)| \u2264 Q.\nP\nLet C(Q, PX ) denote the set of convex combinations \u221e\ni=1 \u03bbi fi of functions fi in F (Q, PX ) where\nP\u221e\nP\u221e\ni=1 \u03bbi fi (X) converges almost surely and in L1 (PX )).\ni=1 |\u03bbi | \u2264 1 (note that the series\n\nCorollary 6.1. Let X = (X1 , * * * , Xk ) be a random variable with values in Rk and let the \u03c6(i) 's\nbe defined by (6.1). Let (fi )1\u2264i\u2264k be k functions from R to R, such that fi \u2208 C(Qi , PXi ). We\nhave the inequality\nZ 1Y\nk\nk\n\u0010Y\n\u0011\n\u0010 u \u0011\n2k\u22121\nE\nfi (Xi ) \u2212 E(fi (Xi )) \u2264 2\nQi (i) du .\n\u03c6\n0 i=1\ni=1\nP\u221e\nP\nProof of Corollary 6.1. Write for all 1 \u2264 i \u2264 k, fi = \u221e\nj=1 |\u03bbj,i | \u2264 1 and\nj=1 \u03bbj,i fj,i where\nfj,i \u2208 F (Qi , PXi ). Clearly\nk\n\u0010Y\n\u0011\nE\nfi (Xi ) \u2212 E(fi (Xi ))\ni=1\n\n\u2264\n\u2264\n\n\u221e\nX\n\nj1 =1\n\n***\n\n\u221e \u0010Y\nk\nX\n\njk =1\n\nsup\nj1 \u22651,...,jk \u22651\n\ni=1\n\nk\n\u0011\n\u0011 \u0010Y\nfji ,i (Xi ) \u2212 E(fji ,i (Xi ))\n|\u03bbji,i | E\ni=1\n\nk\n\u0010Y\n\u0011\nE\nfji ,i (Xi ) \u2212 E(fji ,i (Xi )) .\ni=1\n\nSince each fji ,i is nondecreasing on some interval,\n\n\u03c6(\u03c3(fji ,i (Xi )), fj1,1 (X1 ), . . . , fji\u22121 ,i\u22121 (Xi\u22121 ), fji+1 ,i+1(Xi+1 ), . . . , fjk ,k (Xk )) \u2264 2k\u22121 \u03c6(i) .\nThen applying (6.3) on the right hand side of (6.7), we derive that\nZ 1Y\nk\nk\n\u0010Y\n\u0011\n\u0010 u \u0011\nk\nE\nfi (Xi ) \u2212 E(fi (Xi )) \u2264 2\nQi k\u22121 (i) du ,\n2 \u03c6\n0 i=1\ni=1\n34\n\n(6.7)\n\n\fand the result follows by a change-of-variables. \u0003\nRecall that for any p \u2265 1, the class C(p, M, PX ) has been introduced in the definition 4.2.\nCorollary 6.2. Let X = (X1 , * * * , Xk ) be a random variable with values in Rk and let the \u03c6(i) 's\nbe defined by (6.1). Let a k-tuple (p1 , . . . , pk ) such that 1/p1 + . . . + 1/pk = 1 and let (fi )1\u2264i\u2264k\nbe k functions from R to R, such that fi \u2208 C(pi , Mi , PXi ). We have the inequality\nk\nk\n\u0010Y\n\u0011\nY\n1/p\n2k\u22121\nE\nfi (Xi ) \u2212 E(fi (Xi )) \u2264 2\n(\u03c6(i) )1/pi Mi i .\ni=1\n\ni=1\n\nReferences\n[1] Broise, A., Transformations dilatantes de l'intervalle et th\u00e9or\u00e8mes limites. \u00c9tudes spectrales\nd'op\u00e9rateurs de transfert et applications. Ast\u00e9risque. 238. 1-109. (1996).\n[2] Davydov, Yu. A., Mixing conditions for Markov chains. Theor. Probab. Appl. 18. 312-328. (1973).\n[3] Dedecker, J. and Prieur, C., An empirical central limit theorem for dependent sequences. Stoch.\nProcesses. Appl. 117, 121-142. (2007).\n[4] Dedecker, J. and Rio, E., On mean central limit theorems for stationary sequences. to appear in\nAnn. Inst. H. Poincar\u00e9 Probab. Statist. (2007)\n[5] Fr\u00e9chet, M., Sur la distance de deux lois de probabilit\u00e9s. C. R. Acad. Sci. Paris. 244, 689-692.\n(1957).\n[6] Gordin, M. I., The central limit theorem for stationary processes, Dokl. Akad. Nauk SSSR. 188.\n739-741. (1969).\n[7] Heyde, C. C. and Brown, B. M., On the departure from normality of a certain class of martingales.\nAnn. Math. Statist. 41. 2161\u20132165. (1970).\n[8] Ibragimov, I. A., On the accuracy of Gaussian approximation to the distribution functions of sums\nof independent variables. Theor. Probab. Appl. 11. 559-579. (1966).\n[9] Jan, C., Vitesse de convergence dans le TCL pour des processus associ\u00e9s \u00e0 des syst\u00e8mes dynamiques\net aux produits de matrices al\u00e9atoires. Th\u00e8se de l'universit\u00e9 de Rennes 1. (2001).\n[10] Kantorovich, L.V. and Rubinstein G.Sh., Sur un espace de fonctions compl\u00e8tement additives.\nVestnik Leningrad Univ., 13 (Ser. Mat. Astron. 2), 52-59. (1958)\n[11] Peligrad, M. and Utev, S., A new maximal inequality and invariance principle for stationary\nsequences. The Annals of Probability 33, 798\u2013815. (2005).\n\n35\n\n\f[12] P\u00e8ne F., Rate of convergence in the multidimensional central limit theorem for stationary processes.\nApplication to the Knudsen gas and to the Sinai billiard. Annals of applied probability 15, no. 4.\n2331-2392. (2005).\n[13] Rio, E., Covariance inequalities for strongly mixing processes. Ann. Inst. H. Poincar\u00e9 Probab.\nStatist., 29, 587-597. (1993)\n[14] Rio, E., Distances minimales et distances id\u00e9ales. C. R. Acad. Sci. Paris S\u00e9rie I, 326, 1127-1130\n(1998).\n[15] Rio, E., Th\u00e9orie asymptotique des processus al\u00e9atoires faiblement d\u00e9pendants. Math\u00e9matiques et\napplications de la SMAI. 31. Springer. (2000).\n[16] Rio, E., Upper bounds for minimal distances in the central limit theorem. Submitted to Ann. Inst.\nH. Poincar\u00e9 Probab. Statist. (2007).\n[17] Rosenblatt, M., A central limit theorem and a strong mixing condition, Proc. Nat. Acad. Sci. U.\nS. A. 42 43-47 (1956).\n[18] Sakhanenko, A. I., Estimates in an invariance principle. Trudy Inst. Mat., 5, \"Nauka\" Sibirsk.\nOtdel., Akad. Nauka SSSR, Novosibirsk. 5. 27-44 (1985)\n[19] Voln\u00fd, D., Approximating martingales and the central limit theorem for strictly stationary processes. Stoch. Processes Appl., 44, 41-74 (1993).\n[20] Wu, W. B. and Zhao, Z., Moderate deviations for stationary processes. Technical Report 571,\nUniversity of Chicago. (2006)\n[21] Zolotarev, V. M., Metric distances in spaces of random variables and their distributions. Math.\nURSS. Sbornik. 30, 373-401. (1976).\n\n36\n\n\f"}