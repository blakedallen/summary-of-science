{"id": "http://arxiv.org/abs/cs/0508003v5", "guidislink": true, "updated": "2006-03-09T17:30:20Z", "updated_parsed": [2006, 3, 9, 17, 30, 20, 3, 68, 0], "published": "2005-07-31T18:33:43Z", "published_parsed": [2005, 7, 31, 18, 33, 43, 6, 212, 0], "title": "Model Checking Probabilistic Pushdown Automata", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0508012%2Ccs%2F0508014%2Ccs%2F0508124%2Ccs%2F0508097%2Ccs%2F0508021%2Ccs%2F0508044%2Ccs%2F0508107%2Ccs%2F0508103%2Ccs%2F0508008%2Ccs%2F0508083%2Ccs%2F0508120%2Ccs%2F0508132%2Ccs%2F0508119%2Ccs%2F0508085%2Ccs%2F0508032%2Ccs%2F0508067%2Ccs%2F0508053%2Ccs%2F0508003%2Ccs%2F0603111%2Ccs%2F0603015%2Ccs%2F0603126%2Ccs%2F0603024%2Ccs%2F0603026%2Ccs%2F0603091%2Ccs%2F0603067%2Ccs%2F0603057%2Ccs%2F0603007%2Ccs%2F0603092%2Ccs%2F0603036%2Ccs%2F0603088%2Ccs%2F0603132%2Ccs%2F0603014%2Ccs%2F0603008%2Ccs%2F0603041%2Ccs%2F0603054%2Ccs%2F0603009%2Ccs%2F0603108%2Ccs%2F0603028%2Ccs%2F0603082%2Ccs%2F0603001%2Ccs%2F0603040%2Ccs%2F0603076%2Ccs%2F0603099%2Ccs%2F0603037%2Ccs%2F0603112%2Ccs%2F0603059%2Ccs%2F0603033%2Ccs%2F0603095%2Ccs%2F0603003%2Ccs%2F0603013%2Ccs%2F0603039%2Ccs%2F0603032%2Ccs%2F0603048%2Ccs%2F0603130%2Ccs%2F0603105%2Ccs%2F0603062%2Ccs%2F0603042%2Ccs%2F0603017%2Ccs%2F0603004%2Ccs%2F0603125%2Ccs%2F0603110%2Ccs%2F0603047%2Ccs%2F0603100%2Ccs%2F0603084%2Ccs%2F0603096%2Ccs%2F0603011%2Ccs%2F0603094%2Ccs%2F0603010%2Ccs%2F0603074%2Ccs%2F0603022%2Ccs%2F0603038%2Ccs%2F0603063%2Ccs%2F0603030%2Ccs%2F0603052%2Ccs%2F0603120%2Ccs%2F0603016%2Ccs%2F0603045%2Ccs%2F0603056%2Ccs%2F0603083%2Ccs%2F0603118%2Ccs%2F0603080%2Ccs%2F0603058%2Ccs%2F0603029%2Ccs%2F0603065%2Ccs%2F0603093%2Ccs%2F0603069%2Ccs%2F0603051%2Ccs%2F0603107%2Ccs%2F0603079%2Ccs%2F0603078%2Ccs%2F0603050%2Ccs%2F0603098%2Ccs%2F0603116%2Ccs%2F0603075%2Ccs%2F0603023%2Ccs%2F0603049%2Ccs%2F0603127%2Ccs%2F0603102%2Ccs%2F0603123%2Ccs%2F0603087%2Ccs%2F0603089&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Model Checking Probabilistic Pushdown Automata"}, "summary": "We consider the model checking problem for probabilistic pushdown automata\n(pPDA) and properties expressible in various probabilistic logics. We start\nwith properties that can be formulated as instances of a generalized random\nwalk problem. We prove that both qualitative and quantitative model checking\nfor this class of properties and pPDA is decidable. Then we show that model\nchecking for the qualitative fragment of the logic PCTL and pPDA is also\ndecidable. Moreover, we develop an error-tolerant model checking algorithm for\nPCTL and the subclass of stateless pPDA. Finally, we consider the class of\nomega-regular properties and show that both qualitative and quantitative model\nchecking for pPDA is decidable.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0508012%2Ccs%2F0508014%2Ccs%2F0508124%2Ccs%2F0508097%2Ccs%2F0508021%2Ccs%2F0508044%2Ccs%2F0508107%2Ccs%2F0508103%2Ccs%2F0508008%2Ccs%2F0508083%2Ccs%2F0508120%2Ccs%2F0508132%2Ccs%2F0508119%2Ccs%2F0508085%2Ccs%2F0508032%2Ccs%2F0508067%2Ccs%2F0508053%2Ccs%2F0508003%2Ccs%2F0603111%2Ccs%2F0603015%2Ccs%2F0603126%2Ccs%2F0603024%2Ccs%2F0603026%2Ccs%2F0603091%2Ccs%2F0603067%2Ccs%2F0603057%2Ccs%2F0603007%2Ccs%2F0603092%2Ccs%2F0603036%2Ccs%2F0603088%2Ccs%2F0603132%2Ccs%2F0603014%2Ccs%2F0603008%2Ccs%2F0603041%2Ccs%2F0603054%2Ccs%2F0603009%2Ccs%2F0603108%2Ccs%2F0603028%2Ccs%2F0603082%2Ccs%2F0603001%2Ccs%2F0603040%2Ccs%2F0603076%2Ccs%2F0603099%2Ccs%2F0603037%2Ccs%2F0603112%2Ccs%2F0603059%2Ccs%2F0603033%2Ccs%2F0603095%2Ccs%2F0603003%2Ccs%2F0603013%2Ccs%2F0603039%2Ccs%2F0603032%2Ccs%2F0603048%2Ccs%2F0603130%2Ccs%2F0603105%2Ccs%2F0603062%2Ccs%2F0603042%2Ccs%2F0603017%2Ccs%2F0603004%2Ccs%2F0603125%2Ccs%2F0603110%2Ccs%2F0603047%2Ccs%2F0603100%2Ccs%2F0603084%2Ccs%2F0603096%2Ccs%2F0603011%2Ccs%2F0603094%2Ccs%2F0603010%2Ccs%2F0603074%2Ccs%2F0603022%2Ccs%2F0603038%2Ccs%2F0603063%2Ccs%2F0603030%2Ccs%2F0603052%2Ccs%2F0603120%2Ccs%2F0603016%2Ccs%2F0603045%2Ccs%2F0603056%2Ccs%2F0603083%2Ccs%2F0603118%2Ccs%2F0603080%2Ccs%2F0603058%2Ccs%2F0603029%2Ccs%2F0603065%2Ccs%2F0603093%2Ccs%2F0603069%2Ccs%2F0603051%2Ccs%2F0603107%2Ccs%2F0603079%2Ccs%2F0603078%2Ccs%2F0603050%2Ccs%2F0603098%2Ccs%2F0603116%2Ccs%2F0603075%2Ccs%2F0603023%2Ccs%2F0603049%2Ccs%2F0603127%2Ccs%2F0603102%2Ccs%2F0603123%2Ccs%2F0603087%2Ccs%2F0603089&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider the model checking problem for probabilistic pushdown automata\n(pPDA) and properties expressible in various probabilistic logics. We start\nwith properties that can be formulated as instances of a generalized random\nwalk problem. We prove that both qualitative and quantitative model checking\nfor this class of properties and pPDA is decidable. Then we show that model\nchecking for the qualitative fragment of the logic PCTL and pPDA is also\ndecidable. Moreover, we develop an error-tolerant model checking algorithm for\nPCTL and the subclass of stateless pPDA. Finally, we consider the class of\nomega-regular properties and show that both qualitative and quantitative model\nchecking for pPDA is decidable."}, "authors": ["Javier Esparza", "Antonin Kucera", "Richard Mayr"], "author_detail": {"name": "Richard Mayr"}, "author": "Richard Mayr", "links": [{"title": "doi", "href": "http://dx.doi.org/10.2168/LMCS-2(1:2)2006", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cs/0508003v5", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0508003v5", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "D.2.4; F.1.1; G.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0508003v5", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0508003v5", "arxiv_comment": null, "journal_reference": "Logical Methods in Computer Science, Volume 2, Issue 1 (March 7,\n  2006) lmcs:2256", "doi": "10.2168/LMCS-2(1:2)2006", "fulltext": "Logical Methods in Computer Science\nVol. 2 (1:2) 2006, pp. 1\u201331\nwww.lmcs-online.org\n\nSubmitted\nPublished\n\nDec. 9, 2004\nMar. 6, 2006\n\nMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\nJAVIER ESPARZA a , ANTON\u00cdN KU\u010cERA b , AND RICHARD MAYR c\na\n\nInstitute for Formal Methods in Computer Science, University of Stuttgart, Universit\u00e4tsstr. 38,\n70569 Stuttgart, Germany.\ne-mail address: esparza@informatik.uni-stuttgart.de\n\nb\n\nFaculty of Informatics, Masaryk University, Botanick\u00e1 68a, CZ-60200 Brno, Czech Republic\ne-mail address: tony@fi.muni.cz\n\nc\n\nDepartment of Computer Science, North Carolina State University, 900 Main Campus Drive,\nCampus Box 8207, Raleigh NC 27695, USA.\ne-mail address: mayr@csc.ncsu.edu\nAbstract. We consider the model checking problem for probabilistic pushdown automata\n(pPDA) and properties expressible in various probabilistic logics. We start with properties\nthat can be formulated as instances of a generalized random walk problem. We prove that\nboth qualitative and quantitative model checking for this class of properties and pPDA\nis decidable. Then we show that model checking for the qualitative fragment of the logic\nPCTL and pPDA is also decidable. Moreover, we develop an error-tolerant model checking\nalgorithm for PCTL and the subclass of stateless pPDA. Finally, we consider the class of\n\u03c9-regular properties and show that both qualitative and quantitative model checking for\npPDA is decidable.\n\n1. Introduction\nProbabilistic systems can be used for modeling systems that exhibit uncertainty, such\nas communication protocols over unreliable channels, randomized distributed systems, or\nfault-tolerant systems. Finite-state models of such systems often use variants of probabilistic\nautomata whose underlying semantics is defined in terms of homogeneous Markov chains,\nwhich are also called \"fully probabilistic transition systems\" in this context. For fully\nprobabilistic finite-state systems, algorithms for various (probabilistic) temporal logics like\nLTL, PCTL, PCTL\u2217 , probabilistic \u03bc-calculus, etc., have been presented in [LS82, HS84,\n2000 ACM Subject Classification: D.2.4, F.1.1, G.3.\nKey words and phrases: Pushdown automata, Markov chains, probabilistic model checking.\na\nPartially supported by the DFG-project \"Algorithms for Software-Model-Checking\" and by the EPSRCGrant GR/93346 \"An Automata-theoretic Approach to Software-Model-Checking\".\nb\nOn leave at the Institute for Formal Methods in Computer Science, University of Stuttgart. Supported\nby the Alexander von Humboldt Foundation and by the research center Institute for Theoretical Computer\nScience (ITI), project No. 1M0021620808.\nc\nSupported by Landesstiftung Baden\u2013W\u00fcrttemberg, grant No. 21\u2013655.023.\n\nl\n\nLOGICAL METHODS\nIN COMPUTER SCIENCE\n\nc\nDOI:10.2168/LMCS-2 (1:2) 2006\n\nCC\n\nJ. Esparza, A. Ku\u010dera, and R. Mayr\nCreative Commons\n\n\f2\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nVar85, CY88, HJ94, ASB+ 95, CY95, HK97, CSS03]. As for infinite-state systems, most\nworks so far considered probabilistic lossy channel systems [IN97] which model asynchronous\ncommunication through unreliable channels [BE99, ABIJ05, AR03, BS03]. A notable recent\nresult is the decidability of quantitative model checking of liveness properties specified by\nB\u00fcchi-automata for probabilistic lossy channel systems [Rab03]. In fact, this algorithm is\nerror tolerant in the sense that the quantitative model checking is solved only up to an\narbitrarily small (but non-zero) given error.\nIn this paper we consider probabilistic pushdown automata (pPDA), which are a natural\nmodel for probabilistic sequential programs with possibly recursive procedure calls. There is\na large number of results about model checking of non-probabilistic PDA or similar models\n(see for instance [AEY01, BS97, EHRS00, Wal01]), but the probabilistic extension has so\nfar not been considered. As a related work we can mention [MO98], where it is shown\nthat a restricted subclass of pPDA (where essentially all probabilities for outgoing arcs are\neither 1 or 1/2) generates a richer class of languages than non-deterministic PDA. Another\nwork [AMP99] shows the equivalence of pPDA and probabilistic context-free grammars.\nThere are also recent results of [BKS05, EY05, EY] which are directly related to the results\npresented in this paper. A detailed discussion is postponed to Section 6.\nHere we consider model checking problems for pPDA and its natural subclass of stateless\npPDA denoted pBPA1 and various probabilistic logics. We start with a class of properties\n. . . oo\nDDZ\n\nx\n1\u2212x\n\n?//89\n>:\n=<;oo\nDZ\n\nx\n1\u2212x\n\n?8// 9\n>:\n=<;oo\nZ\n\nx\n1\u2212x\n\n?8// 9\n>:\n=<;oo\n\nx\n\n// . . .\n\n1\u2212x\n\nIZ\n\nIIZ\n\nFigure 1: Bernoulli random walk as a pBPA\nthat can be specified as a generalized random walk problem. To get a better intuition\nabout this class of problems, realize that some random walks can easily be specified by\npBPA systems. For example, consider a pBPA with just three stack symbols Z, I, D and\nx\n1\u2212x\nx\n1\u2212x\n1\u2212x\nx\ntransitions Z \u2192 IZ, Z \u2192 DZ, I \u2192 II, I \u2192 \u03b5, D \u2192 DD, and D \u2192 \u03b5, where x \u2208 [0, 1]\nx\nand \u03b5 denotes the empty string. A transition X \u2192 w means that if the current top stack\nsymbol is X,then it can be replaced by w with probability x. The transition graph of this\npBPA with Z as initial stack content (see Fig. 1) is the well-known Bernoulli walk. A typical\nquestion examined in the theory of random walks is \"Do we eventually revisit a given state\n(with probability one)?\", or more generally \"What is the probability of reaching a given\nstate from another given state?\" For example, it is a standard result that the state Z of\nFig. 1 is revisited with probability 1 iff x = 1/2. This simple example indicates that answers\nto qualitative questions about pPDA (i.e., whether something holds with probability 1 or\n0) depend on the exact probabilities of individual transitions. This is different from finitestate systems where qualitative properties depend only on the topology of a given finite-state\nMarkov chain [HJ94].\nThe generalized random walk problem is formulated as follows: Let C1 and C2 be subsets\nof the set of states of a given Markov chain, and let s be a state of C1 . What is the probability\nthat a run initiated in s hits a state of C2 via a path leading only through the states of C1 ?\n1This is a standard notation adopted in concurrency theory. The subclass of stateless PDA corresponds\n\nto a natural subclass of ACP known as Basic Process Algebra [BW90].\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n3\n\nLet us denote this probability by P(s, C1 U C2 ). The problem of computing P(s, C1 U C2 )\nhas previously been considered (and solved) for finite-state systems, where this probability\ncan be computed precisely [HJ94, CY95]. In Section 3, we propose a solution for pPDA\napplicable to those sets C1 , C2 which are regular, i.e., recognizable by finite-state automata\n(realize that pPDA configurations can be written as words of the form p\u03b1, where p is\na control state and \u03b1 a sequence of stack symbols). More precisely, we show that the\nproblem whether P(s, C1 U C2 ) \u223c \u033a, where \u223c \u2208 {\u2264, <, \u2265, >, =} and \u033a \u2208 [0, 1], is decidable.\nInterestingly, this is achieved without explicitly computing the probability P(s, C1 U C2 ).\nMoreover, for an arbitrary precision 0 < \u03bb < 1 we can compute rational lower and upper\napproximations P l , P u \u2208 [0, 1] such that P l \u2264 P(s, C1 U C2 ) \u2264 P u and P u \u2212 P l \u2264 \u03bb.\nIn Section 4, we consider the model checking problem for pPDA and the logic PCTL.\nThis is a more general problem than the one about random walks (the class of properties\nexpressible in PCTL is strictly larger). In Section 4.1, we give a model checking algorithm\nfor the qualitative fragment of PCTL and pPDA processes. For general PCTL formulas and\npBPA processes, an error tolerant model checking algorithm is developed in Section 4.2.\nThe question whether this result can be extended to pPDA is left open.\nFinally, in Section 5 we prove that both qualitative and quantitative model checking for\nthe class of \u03c9-regular properties is decidable for pPDA. In [EKM04], it was shown that the\nqualitative and quantitative model-checking problem is decidable for pPDA and a subclass\nof \u03c9-regular properties that are definable by deterministic B\u00fcchi automata. Later, it has\nbeen observed in [BKS05] that the technique can easily be generalized to Muller automata,\nand thus the decidability result was extended to all \u03c9-regular properties (in [BKS05], some\ncomplexity results were also presented). The construction presented in this paper is a\nslightly generalized and polished version of the algorithms given in [EKM04, BKS05], which\ncan now be seen as instances of a more abstract result.\nIn Section 6 we conclude by remarks on open problems and recent related work of\n[BKS05, EY05, EY].\n2. Preliminary Definitions\nDefinition 2.1. A probabilistic transition system is a triple T = (S, \u2192, Prob) where S is a\nfinite or countably infinite set of states, \u2192 \u2286 S \u00d7 S is a transition relation, and Prob is a\nfunction which to each transition s \u2192 t of T assigns its probability Prob(s \u2192 t) \u2208 (0, 1] so\nthat for every s \u2208 S we have\nX\nProb(s \u2192 t) \u2208 {0, 1}\ns\u2192t\n\nThe sum above is 0 iff s does not have any outgoing transitions.\nx\n\nIn the rest of this paper we also write s \u2192 t instead of Prob(s \u2192 t) = x. A path in\nT is a finite or infinite sequence w = s0 ; s1 ; * * * of states such that si \u2192 si+1 for every i.\nWe also use w(i) to denote the state si of w (by writing w(i) = s we implicitly impose the\ncondition that the length of w is at least i + 1). A run is a maximal path, i.e., a path which\ncannot be prolonged. The sets of all finite paths, all runs, and all infinite runs of T are\ndenoted FPath, Run, and IRun, respectively2. Similarly, the sets of all finite paths, runs,\nand infinite runs that start in a given s \u2208 S are denoted FPath(s), Run(s), and IRun(s),\nrespectively.\n2In this paper, T is always clear from the context.\n\n\f4\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nEach w \u2208 FPath determines a basic cylinder Run(w) which consists of all runs that\nstart with w. To every s \u2208 S we associate the probabilistic space (Run(s), F, P) where\nF is the \u03c3-field generated by all basic cylinders Run(w) such that w starts with s, and\nP : F \u2192 [0, 1] is the unique probability function such that P(Run(w)) = \u03a0m\u22121\ni=0 xi where\nxi\nw = s0 ; * * * ; sm and si \u2192 si+1 for every 0 \u2264 i < m (if m = 0, we put P(Run(w)) = 1).\n2.1. The Logic PCTL. PCTL, the probabilistic extension of CTL, was defined in [HJ94].\nLet Ap = {a, b, c, . . . } be a countably infinite set of atomic propositions. The syntax of\nPCTL3 is given by the following abstract syntax equation:\n\u03c6 ::= tt | a | \u00ac\u03c6 | \u03c61 \u2227 \u03c62 | X \u223c\u033a \u03c6 | \u03c61 U \u223c\u033a \u03c62\n\nHere a ranges over Ap, \u033a \u2208 [0, 1], and \u223c \u2208 {\u2264, <, \u2265, >}. Let T = (S, \u2192, Prob) be a\nprobabilistic transition system. For all s \u2208 S, all C, C1 , C2 \u2286 S, and all k \u2208 N0 , let\n\u2022 Run(s, X C) = {w \u2208 Run(s) | w(1) \u2208 C}\n\u2022 Run(s, C1 U C2 ) = {w \u2208 Run(s) | \u2203i \u2265 0 : w(i) \u2208 C2 and w(j) \u2208 C1 for all 0 \u2264 j < i}\n\u2022 FPath k (s, C1 U C2 ) = {s0 ; * * *; sl \u2208 FPath(s) | 0 \u2264 l \u2264 k, sl \u2208 C2 and sj \u2208 C1 rC2 for all 0 \u2264\nj < l}\nS\nk\n\u2022 FPath(s, C1 U C2 ) = \u221e\nk=0 FPath (s, C1 U C2 )\n\nThe set Run(s, X C) is clearly P-measurable, and the same holds for Run(s, C1 U C2 ) because\nX\nP(Run(s, C1 U C2 )) =\nP(Run(w)).\nw\u2208FPath(s,C1 U C2 )\n\nIn the rest of this paper, we will usually write P(s, X C) and P(s, C1 U C2 ) instead of\nP(Run(s, X C)) and P(Run(s, C1 U C2 )), respectively.\nLet \u03bd : Ap \u2192 2S be a valuation. The denotation of a PCTL formula \u03c6 over T w.r.t. \u03bd,\ndenoted [[\u03c6]]\u03bd , is defined inductively as follows:\n[[tt]]\u03bd\n[[a]]\u03bd\n[[\u00ac\u03c6]]\u03bd\n[[\u03c61 \u2227 \u03c62 ]]\u03bd\n[[X \u223c\u033a \u03c6]]\u03bd\n[[\u03c61 U \u223c\u033a \u03c62 ]]\u03bd\n\n=\n=\n=\n=\n=\n=\n\nS\n\u03bd(a)\nS r [[\u03c6]]\u03bd\n[[\u03c61 ]]\u03bd \u2229 [[\u03c62 ]]\u03bd\n{s \u2208 S | P(s, X [[\u03c6]]\u03bd ) \u223c \u033a}\n{s \u2208 S | P(s, [[\u03c61 ]]\u03bd U [[\u03c62 ]]\u03bd ) \u223c \u033a}\n\nAs usual, we write s |=\u03bd \u03c6 instead of s \u2208 [[\u03c6]]\u03bd .\nThe qualitative fragment of PCTL is obtained by restricting the allowed operator/\nnumber combinations to '\u2264 0' and '\u2265 1', which will be also written as '= 0' and '= 1',\nresp. (Observe that '< 1', '> 0' are definable from '\u2264 0', '\u2265 1', and negation; for example,\na U <1 b \u2261 \u00ac(a U \u22651 b).)\n2.2. Probabilistic PDA.\nDefinition 2.2. A probabilistic pushdown automaton (pPDA) is a tuple \u2206 = (Q, \u0393, \u03b4, Prob )\nwhere Q is a finite set of control states, \u0393 is a finite stack alphabet, \u03b4 \u2286 Q \u00d7 \u0393 \u00d7 Q \u00d7 \u0393\u2217\nis a finite transition relation (we write pX \u2192 q\u03b1 instead of (p, X, q, \u03b1) \u2208 \u03b4), and Prob is a\n3For simplicity we omit the bounded 'until' operator of [HJ94].\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n5\n\nfunction which\nP to each transition pX \u2192 q\u03b1 assigns its probability Prob(pX \u2192 q\u03b1) \u2208 (0, 1]\nand satisfies pX\u2192q\u03b1 Prob(pX \u2192 q\u03b1) \u2208 {0, 1} for all p \u2208 Q and X \u2208 \u0393.\nA pBPA is a pPDA with just one control state. Formally, a pBPA is understood as a\ntriple \u2206 = (\u0393, \u03b4, Prob) where \u03b4 \u2286 \u0393 \u00d7 \u0393\u2217 .\nx\n\nIn the rest of this paper we adopt a more intuitive notation, writing pX \u2192 q\u03b1 instead\nof Prob(pX \u2192 q\u03b1) = x. A configuration of \u2206 is an element of Q \u00d7 \u0393\u2217 . The set of all\nconfigurations of \u2206 is denoted by C(\u2206). We also assume (w.l.o.g.) that if pX \u2192 q\u03b1 \u2208 \u03b4,\nthen |\u03b1| \u2264 2. It is easy to transform an arbitrary pair (\u2206, F ), where \u2206 is a pPDA and F is a a\nPCTL formula or \u03c9-property, into another pair (\u2206\u2032 , F \u2032 ) such that \u2206\u2032 satisfies the assumption\nabove and \u2206 satisfies F if and only if \u2206\u2032 satisfies F \u2032 . Moreover, the transformation takes\nx\nlinear time. For instance, a transition rule pX \u2192 qY ZW of \u2206 is transformed into two\n1\nx \u2032 \u2032\ntransitions pX \u2192 p Y W and p\u2032 Y \u2032 \u2192 qY Z in \u2206\u2032 , where p\u2032 , Y \u2032 are a fresh control state and\na fresh stack symbol, respectively.\nTo \u2206 we associate the probabilistic transition system T\u2206 where C(\u2206) is the set of states\nx\nand the probabilistic transition relation is determined as follows: pX\u03b2 \u2192 q\u03b1\u03b2 is a transition\nx\nof T\u2206 iff pX \u2192 q\u03b1 is a transition of \u2206 and \u03b2 \u2208 \u0393\u2217 .\nThe model checking problem for pPDA configurations and PCTL formulate (i.e., the\nquestion whether p\u03b1 |=\u03bd \u03c6 for given p\u03b1, \u03c6, and \u03bd) is clearly undecidable for general valuations. Therefore, we restrict ourselves to regular valuations which to every a \u2208 Ap assign a\nregular set of configurations:\nDefinition 2.3. A \u2206-automaton is a triple A = (St, \u03b3, Acc) where St is a finite set of states\ns.t. Q \u2286 St, \u03b3 : St \u00d7 \u0393 \u2192 St is a (total) transition function, and Acc \u2286 St a set of accepting\nstates.\nThe function \u03b3 is extended to the elements of \u0393\u2217 in the standard way. Each \u2206automaton A determines a set C(A) \u2286 C(\u2206) given by p\u03b1 \u2208 C(A) iff \u03b3(p, \u03b1R ) \u2208 Acc.\nHere \u03b1R is the reverse of \u03b1, i.e., the word obtained by reading \u03b1 from right to left.\nWe say that a set C \u2286 C(\u2206) is regular iff there is a \u2206-automaton A such that C = C(A).\n\nIn other words, regular sets of configurations are recognizable by finite-state automata\nwhich read the stack bottom-up (the bottom-up direction was chosen just for technical\nconvenience).\nAn important technical step is that one can reduce the model-checking problem for regular valuations to the problem for simple valuations that assign to each atomic proposition\na simple set of configurations. Loosely speaking, a set of configurations is simple if we can\ndecide whether a configuration belongs to the set by inspecting only its control state and\nits top stack symbol.\n\nDefinition 2.4. A set of configurations C \u2286 C(\u2206) is simple if there is a set G \u2286 Q\u00d7(\u0393\u222a{\u03b5})\nsuch that for each p\u03b1 \u2208 C(\u2206) we have that p\u03b1 \u2208 C iff either \u03b1 = \u03b5 and p\u03b5 \u2208 G, or \u03b1 = X\u03b2\nand pX \u2208 G.\n\nThe reason why we only need to consider simple valuations is a bisimilarity property.\nLet C1 , * * * , Ck \u2286 C(\u2206) be regular sets of configurations, and assume that all we can observe\nfrom a configuration is whether it belongs to Ci for every 1 \u2264 i \u2264 k. Loosely speaking,\nLemma 2.5 below states that we can effectively construct another pPDA \u2206\u2032 and simple sets\nof configurations C1\u2032 , * * * , Ck\u2032 \u2286 C(\u2206) such that \u2206 and \u2206\u2032 are bisimilar with respect to these\nobservables (in the usual definition of bisimilarity one observes transitions between configurations, while here we observe the configurations themselves, but otherwise the notion is\n\n\f6\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nthe same). The idea of the construction is to take \u2206-automata A1 , * * * , Ak accepting the\nsets C1 , * * * , Ck , and construct \u2206\u2032 such that the following holds: If the current configuration\nof \u2206 is p\u03b1, then in the simulating configuration of \u2206\u2032 the topmost stack symbol stores the\nstates reached by the \u2206-automata after reading \u03b1R from the initial state p. Although this\nconstruction is standard (see, e.g., [EKS03]), we include an explicit proof for the sake of\ncompleteness.\nLemma 2.5. For each pPDA \u2206 = (Q, \u0393, \u03b4, Prob) and regular sets C1 , * * * , Ck \u2286 C(\u2206) there\neffectively exists a pPDA \u2206\u2032 = (Q, \u0393\u2032 , \u03b4\u2032 , Prob \u2032 ), simple sets C1\u2032 , * * * , Ck\u2032 \u2286 C(\u2206\u2032 ), and an\ninjective mapping G : C(\u2206) \u2192 C(\u2206\u2032 ) such that for each p\u03b1 \u2208 C(\u2206) the following conditions\nare satisfied:\n\u2022 for each 1 \u2264 j \u2264 k we have p\u03b1 \u2208 Cj iff G(p\u03b1) \u2208 Cj\u2032 ;\nx\nx\n\u2022 if p\u03b1 \u2192 q\u03b2, then G(p\u03b1) \u2192 G(q\u03b2);\nx\nx\n\u2022 if G(p\u03b1) \u2192 s for some s \u2208 C(\u2206\u2032 ), then there is p\u03b1 \u2192 q\u03b2 such that G(q\u03b2) = s.\n\nMoreover, if C \u2286 C(\u2206\u2032 ) is regular, then G \u22121 (C) is also regular.\n\nProof. For each 1 \u2264 i \u2264 k, let Ai = (St i , \u03b3i , Acc i ) be a \u2206-automaton such that C(Ai ) = Ci .\nQ Q\nLet States = ki=1 p\u2208Q St i . For given ~s \u2208 States, 1 \u2264 i \u2264 k, and p \u2208 Q, we denote by\n~s(i, p) the component of ~s which corresponds to i and p.\nWe put \u0393\u2032 = \u0393 \u00d7 States. The transition function \u03b4\u2032 and probabilities Prob \u2032 are defined\nas follows:\nx\n\nx\n\n\u2022 if pX \u2192 q\u03b5 \u2208 \u03b4, then p(X, ~s) \u2192 q\u03b5 for each ~s \u2208 States;\nx\nx\n\u2022 if pX \u2192 qY \u2208 \u03b4, then p(X, ~s) \u2192 q(Y, ~s) for each ~s \u2208 States;\nx\nx\n\u2022 if pX \u2192 qY Z \u2208 \u03b4, then p(X, ~s) \u2192 q(Y, ~t)(Z, ~s) for all ~s, ~t \u2208 States such that \u03b3i (~s(i, r), Z) =\n~t(i, r) for all 1 \u2264 i \u2264 k and r \u2208 Q.\n\nSo, the \u2206-automata A1 , * * * , Ak are simulated \"on-the-fly\" by storing the vector of current\nstates directly in the stack. Hence, the information whether a given Ai accepts the current\nconfiguration is available in the topmost stack symbol. For every 1 \u2264 i \u2264 k, the underlying\nset Gi of Ci\u2032 (see Definition 2.4) is defined by\nGi = {p(X, ~s) | \u03b3i (~s(i, p), X) \u2208 Acc i } \u222a {p\u03b5 | p\u03b5 \u2208 Ci }\n\nThe function G is defined by G(p\u03b5) = p\u03b5, and G(pX1 * * * Xk ) = p(X1 , ~s1 ) * * * (Xk , ~sk ), where\n~sk (i, q) = q, and ~sj (i, q) = \u03b3i (~sj+1 (i, q), Xj+1 ) for all 1 \u2264 j < k. It follows immediately\nfrom the definition of \u03b4\u2032 and Prob \u2032 that the parts of T\u2206 and T\u2206\u2032 which are reachable from\np\u03b1 and G(p\u03b1) are isomorphic (for every p\u03b1 \u2208 C(\u2206)).\nLet C \u2286 C(\u2206\u2032 ) be a regular set of configurations. Since some configurations of C can\nbe \"inconsistent\" in the sense that the vectors of states that are stored together with the\noriginal stack symbols do not correspond to a valid computation of the Ai automata, the\nset G \u22121 (C) is not a simple projection of C \"forgetting\" the vectors of states from the stack\nsymbols. Fortunately, G(C(\u2206)) is (obviously) a regular set, so we can construct a \u2206\u2032 automaton recognizing the set C \u2229 G(C(\u2206)) and apply the mentioned projection.\n3. Random Walks on pPDA Graphs\nIn this section we address the following problem. Let \u2206 be a pPDA, let p1 \u03b11 be an\ninitial configuration, let C1 , C2 be two simple sets of configurations, and let \u03c1 be a threshold\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n7\n\nprobability. Is the probability of executing a run p1 \u03b11 ; p2 \u03b12 ; p3 \u03b13 * * * that satisfies C1 U C2 ,\ndenoted by P(p1 \u03b11 , C1 U C2 ), at least \u03c1? We show that the problem is decidable.\nThe plan of the section is as follows. First, we show in Lemma 3.4 that P(p1 \u03b11 , C1 U C2 )\nis equal to a polynomial expression in the following probabilities:\n\u2022 Let pX be an initial configuration (notice that there is only one symbol on the stack),\nand let q be a control state q. The probability of reaching q\u03b5 visiting only configurations\nof C1 r C2 along the way is denoted by [pXq]\n\u2022 Let pX be an initial configuration and let \u03c4 be a threshold probability. The probability\nof reaching some configuration of C2 with nonempty stack, visiting only configurations of\nC1 along the way, is denoted by [pX\u2022].\n\nSecond, in Theorem 3.5, we show that the probabilities [pXq] and [pX\u2022] are the least\nsolution of a system of quadratic equations. So our original problem reduces to determining\nwhether a polynomial expression on this least solution has at least the value \u03c1. Finally, we\nobserve in Theorem 3.7 that this question can be reduced to deciding the truth of a formula\nin the first-order arithmetic of the reals (i.e., in the theory (R, +, \u2217, \u2264)). Since this theory\nis known to be decidable [Tar51], our original question is decidable.\nFor the rest of this section, let us fix a pPDA \u2206 = (Q, \u0393, \u03b4, Prob) and two simple sets\nC1 , C2 \u2286 C(\u2206). Let G1 , G2 \u2286 Q \u00d7 (\u0393 \u222a {\u03b5}) be the sets associated to C1 , C2 in the sense of\nDefinition 2.4.\nDefinition 3.1. To simplify our notation, we adopt the following conventions:\n\u2022 For each C \u2286 C(\u2206), let C \u2022 = C r (Q\u00d7{\u03b5}). Observe that if C is simple, then so is C \u2022 .\n\u2022 For every C \u2286 C(\u2206) and every \u03b2 \u2208 \u0393\u2217 , the symbol C\u03b2 denotes the set {p\u03b1\u03b2 | p\u03b1 \u2208 C}.\n\u2022 For all p, q \u2208 Q and X \u2208 \u0393, we use [pXq] to abbreviate P(pX, C1 rC2 U {q\u03b5}), and [pX\u2022]\nto abbreviate P(pX, C1 U C2\u2022 ).\n\u2022 Let A be a set of finite paths which end in the same state t, and let B a set of finite or\ninfinite paths that start in t. Then the symbol A \u2299 B denotes the set of paths {v; w | v \u2208\nA, t; w \u2208 B}.\nThe proof of Lemma 3.4. our first milestone, requires the following two auxiliary results:\nLemma 3.2. Let T = (S, \u2192, Prob) be a probabilistic transition system. Let s, t \u2208 S and\nC1 , C2 \u2286 S. Further, let A = FPath(s, (C1 rC2 ) U {t}) and B = FPath(t, C1 U C2 ). Then\nX\nX\nX\nP(Run(w)) =\nP(Run(w)) *\nP(Run(w)).\nw\u2208A\u2299B\n\nw\u2208A\n\nw\u2208B\n\nProof. Immediate.\nLemma 3.3. For all p\u03b1 \u2208 C(\u2206) and \u03b2 \u2208 \u0393\u2217 we have that P(p\u03b1, C1 U C2 ) is equal to\nP(p\u03b1\u03b2, C1\u2022 \u03b2 U C2 \u03b2).\n\nProof. For every finite path w = p1 \u03b11 ; * * * ; pn \u03b1n of FPath(p\u03b1), let w+\u03b2 denote the finite\npath p1 \u03b11 \u03b2; * * * ; pn \u03b1n \u03b2 of FPath(p\u03b1\u03b2). Realize that P(Run(w)) = P(Run(w+\u03b2 )), because\nw and w+\u03b2 execute the same transitions. One can easily verify that w \u2208 FPath(p\u03b1, C1 U C2 )\n\n\f8\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\niff w+\u03b2 \u2208 FPath(p\u03b1\u03b2, C1\u2022 \u03b2 U C2 \u03b2). From this we get\nX\nP(p\u03b1, C1 U C2 ) =\n\nw\u2208FPath(p\u03b1,C1 U C2 )\n\nX\n\n=\n\nw\u2208FPath(p\u03b1\u03b2,C1\u2022 \u03b2\n\n=\n\nP(p\u03b1\u03b2, C1\u2022 \u03b2 U\n\nP(Run(w))\n\nU C2 \u03b2)\n\nP(Run(w))\n\nC2 \u03b2)\n\nNow we show how to compute P(pX1 * * * Xn , C1 U C2 ) from the finite family of all [pXq],\n[pX\u2022] probabilities. First, realize that\nX\nP(pX1 * * * Xn , C1 U C2 ) = [pX1 \u2022] +\n[pX1 q] * P(qX2 * * * Xn , C1 U C2 )\nq\u2208Q\n\nThe meaning of this equation is intuitively clear. If we repeatedly expand the probabilities\nof the form P(qXj * * * Xn , C1 U C2 ) in the above equation (until j becomes n), we obtain the\nequation presented in the following lemma:\nLemma 3.4. For each pX1 * * * Xn \u2208 C(\u2206) where n \u2265 0 we have that P(pX1 * * * Xn , C1 U C2 )\nis equal to\nn\nX\n\nX\n\ni=1 (q1 ,*** ,qi )\u2208Qi\nwhere p=q1\n\n[qi Xi \u2022] *\n\ni\u22121\nY\n\n[qj Xj qj+1 ] +\n\nj=1\n\nX\n\nn\nY\n\n[qj Xj qj+1 ]\n\nj=1\n(q1 ,*** ,qn+1 )\u2208Qn+1\nwhere p=q1 and qn+1 \u03b5\u2208C2\n\nwith the convention that empty sum is equal to 0 and empty product is equal to 1.\nProof. By induction on n. For n = 0 we have that P(p\u03b5, C1 U C2 ) is equal either to 1 or 0,\ndepending on whether p\u03b5 belongs to C2 or not, resp. Now let n \u2265 1, and let \u03b2 denote the\nsequence X2 * * * Xn . The set Run(pX1 \u03b2, C1 U C2 ) is equal to\n]\nRun(w)\nw\u2208FPath(pX1 \u03b2,C1 U C2 )\n\nLet\n\nC\u2032\n\n= {q\u03b1\u03b2 | q \u2208 Q, \u03b1 \u2208\n\n\u0393+ }.\n\nWe have that\n\nFPath(pX1 \u03b2, C1 U C2 ) = FPath(pX1 \u03b2, C1 \u2229C \u2032 U C2 \u2229C \u2032 ) \u228e\n]\nFPath(pX1 \u03b2, (C1 rC2 )\u2229C \u2032 U {q\u03b2}) \u2299 FPath(q\u03b2, C1 U C2 )\nq\u2208Q\n\nNow observe that for every simple set C \u2286 C(\u2206) we have that C \u2229 C \u2032 = C \u2022 \u03b2. Hence, the\nabove equation can be rewritten as follows:\nFPath(pX1 \u03b2, C1 U C2 ) = FPath(pX1 \u03b2, C1\u2022 \u03b2 U C2\u2022 \u03b2) \u228e\n]\nFPath(pX1 \u03b2, (C1 rC2 )\u2022 \u03b2 U {q\u03b2}) \u2299 FPath(q\u03b2, C1 U C2 )\nq\u2208Q\n\nUsing Lemma 3.3 and Lemma 3.2, we obtain that\n\nP(pX1 \u03b2, C1 U C2 ) = P(pX1 , C1 U C2\u2022 ) +\nP\nq\u2208Q P(pX1 \u03b2, (C1 rC2 ) U {q\u03b2}) * P(q\u03b2, C1 U C2 )\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n9\n\nThis can also be written as\nP(pX1 \u03b2, C1 U C2 ) = [pX1 \u2022] +\n\nX\n\nq\u2208Q\n\n[pX1 q] * P(q\u03b2, C1 U C2 )\n\nNow it suffices to apply induction hypothesis to P(q\u03b2, C1 U C2 ) and restructure the resulting\nexpression.\nNow we show that the probabilities [pXq], [pX\u2022] form the least solution of an effectively\nconstructible system of quadratic equations. This can be seen as a generalization of a similar\nresult for finite-state systems [HJ94, CY95]. In the finite-state case, the equations are linear\nand can be further modified so that they have a unique solution (which is then computable,\ne.g., by Gauss elimination). In the case of pPDA, the equations are not linear and cannot be\ngenerally solved by analytical methods. The question whether the equations can be further\nmodified so that they have a unique solution is left open; we just note that the method used\nfor finite-state systems is insufficient (this is demonstrated by Example 3.6).\nLet V = {hpXqi, hpX\u2022i | p, q \u2208 Q, X \u2208 \u0393} be a set of \"variables\". Let us consider the\nsystem of recursive equations constructed as follows:\n\u2022 if pX 6\u2208 G1 rG2 , then hpXqi = 0 for each q \u2208 Q; otherwise, we put\nX\nX\nX\nhpXqi =\nx*\nhrY ti * htZqi +\nx * hrY qi +\nx\n\npX \u2192rY Z\n\nx\n\nt\u2208Q\n\npX \u2192rY\n\nX\n\nx\n\nx\n\npX \u2192q\u03b5\n\n\u2022 if pX \u2208 G2 , then hpX\u2022i = 1; if pX 6\u2208 G1 \u222a G2 , then hpX\u2022i = 0; otherwise we put\nX\nX\nX\nhpX\u2022i =\nx * (hrY \u2022i +\nhrY ti * htZ\u2022i) +\nx * hrY \u2022i\nx\n\npX \u2192rY Z\n\nt\u2208Q\n\nx\n\npX \u2192rY\n\nThe intuition behind these equations is easy to understand. For the sake of simplicity,\nassume G1 = Q \u00d7 \u0393 and G2 = \u2205 (this corresponds to C1 = C(\u2206) and C2 = \u2205). In this case,\nwe only have the two \"long\" equations. Consider the first one, the intuition for the second\none being similar. In order to reach q\u03b5 from pX, the pPDA must make at least one move.\nx\nSince we assume than the transitions pX \u2192 q\u03b1 of a pPDA satisfy |\u03b1| \u2264 2, here are three\npossible kinds of moves: moves that increase the stack length by one, moves that do not\nchange the stack length, and moves that decrease the stack length. The three summands in\nthe equations correspond to these three kinds of moves. Since no transition can be executed\nwhen the stack is empty, the only way to reach q\u03b5 by means of a length-decreasing move\nx\nis to apply a transition pX \u2192 q\u03b5, if it exists (third summand). If the first transition is\nx\nlength-keeping, i.e., of the form pX \u2192 rY , then, after the transition, we must reach q\u03b5\nfrom rY (second summand). Finally, if the first transition is of the form pX \u2192 rY Z, then\nthe pPDA must first go from rY Z to some configuration tZ along a path of configurations\nhaving with Z as bottom stack symbol, and then from tZ to q\u03b5. Intuitively (see the next\ntheorem for the formal proof), the probability of reaching tZ from rY Z along such a path\nis equal to the probability of reaching t\u03b5 from rY , and so we get the first summand.\nFor given t \u2208 [0, 1]| V | , p, q \u2208 Q, and X \u2208 \u0393 we use hpXqit and hpX\u2022it to denote the\ncomponent of t which corresponds to the variable hpXqi and hpX\u2022i, respectively. The above\ndefined system of equations determines a unique operator F : [0, 1]| V | \u2192 [0, 1]| V | where F(t)\nis the tuple of values obtained by evaluating the right-hand sides of the equations where all\nhpXqi and hpX\u2022i are substituted with hpXqit and hpX\u2022it , respectively.\n\n\f10\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nTheorem 3.5. The operator F has the least fixed-point \u03bc. Moreover, for all p, q \u2208 Q and\nX \u2208 \u0393 we have that hpXqi\u03bc = [pXq] and hpX\u2022i\u03bc = [pX\u2022].\nW\nk ~\nProof. Since F is monotonic and continuous, it has the least fixed point \u03bc = \u221e\nk=0 F (0),\nwhere ~0 is the tuple of zeros. One can readily check that the tuple \u03c0 of all [pXq] and\n[pX\u2022] probabilities forms a solution of the above system; this is done just by partitioning\nthe associated sets of runs into appropriate disjoint subsets similarly as in the proof of\nLemma 3.4. Hence, \u03bc \u2264 \u03c0. To prove that also \u03c0 \u2264 \u03bc, we approximate the [pXq] and [pX\u2022]\nprobabilities in the following way: For each k \u2208 N0 we define\nX\n\u2022 [pXq]k =\nP(Run(w))\nw\u2208FPath k (pX,C1 rC2 U {q\u03b5})\n\n\u2022 [pX\u2022]k =\n\nX\n\nk\n\nw\u2208FPath (pX,C1 U\n\nC2\u2022 )\n\nP(Run(w))\n\nLet \u03c0 k be the tuple of all [pXq]k and [pX\u2022]k probabilities. Clearly \u03c0 = limk\u2192\u221e \u03c0 k . By\ninduction on k we prove that \u03c0 k \u2264 \u03bc for each k \u2208 N0 , hence also \u03c0 \u2264 \u03bc as needed.\nThe base case (k = 0) follows immediately. We show that if [pXq]k \u2264 hpXqi\u03bc and\n[pX\u2022]k \u2264 hpXqi\u03bc , then also [pXq]k+1 \u2264 hpXqi\u03bc and [pX\u2022]k+1 \u2264 hpXqi\u03bc . If pX 6\u2208 G1 rG2 ,\nthen [pXq]k+1 = hpXqi\u03bc = 0. Otherwise, by applying the definitions we obtain\nX\nX\nx*\nP(Run(w))\n[pXq]k+1 =\nx\n\npX \u2192rY Z\n\n+\n\nX\n\nx*\n\nX\n\nx\n\nx\n\npX \u2192rY\n\n+\n\nw\u2208FPath k (rY Z,C1 rC2 U {q\u03b5})\n\nk\n\nX\n\nw\u2208FPath (rY,C1 rC2 U {q\u03b5})\n\nP(Run(w))\n\nx\n\npX \u2192q\u03b5\n\nand\nhpXqi\u03bc =\n\nX\nx\n\npX \u2192rY Z\n\nx*\n\nSince\n\nX\nt\u2208Q\n\nhrY ti\u03bc * htZqi\u03bc +\n\nk\n\n=\n\n[rY q]k ,\n\nX\n\nP(Run(w))\n\n\u2264\n\nhrY qi\u03bc\n\nX\n\nP(Run(w))\n\nby induction hypothesis. Further,\nX\nx*\npX \u2192rY Z\n\npX \u2192rY\n\nP(Run(w))\n\nw\u2208FPath (rY,C1 rC2 U {q\u03b5})\n\nx\n\nx\n\nx * hrY qi\u03bc +\n\nX\n\nw\u2208FPath k (rY,C1 rC2 U {q\u03b5})\n\nwe have\n\nX\n\nk\n\nw\u2208FPath (rY Z,C1 rC2 U {q\u03b5})\n\nis surely bounded by\nX\nx\n\npX \u2192rY Z\n\nx*\n\nX\nt\u2208Q\n\n[rY t]k * [tZq]k ,\n\nX\nx\n\npX \u2192q\u03b5\n\nx\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n11\n\nwhich is bounded by\nX\nx\n\npX \u2192rY Z\n\nx*\n\nX\nt\u2208Q\n\nhrY ti\u03bc * htZqi\u03bc\n\nby induction hypothesis. To sum up, we have that [pXq]k+1 \u2264 hpXqi\u03bc . The inequality\n\n[pX\u2022]k+1 \u2264 hpX\u2022i\u03bc is proved similarly.\n\nExample 3.6. Let us consider the pBPA system \u2206 of Fig. 1, and let C1 = \u0393\u2217 , C2 = {Z}.\nThen we obtain the following system of equations (since \u2206 has only one control state p, we\nwrite hX, \u2022i and hX, \u03b5i instead of hpX\u2022i and hpXpi, resp.):\nhZ, \u2022i\nhZ, \u03b5i\nhI, \u2022i\nhI, \u03b5i\nhD, \u2022i\nhD, \u03b5i\n\n=\n=\n=\n=\n=\n=\n\n1\nxhI, \u03b5ihZ, \u03b5i + (1\u2212x)hD, \u03b5ihZ, \u03b5i\nx(hI, \u2022i + hI, \u03b5ihI, \u2022i)\nxhI, \u03b5ihI, \u03b5i + 1\u2212x\n(1\u2212x)(hD, \u2022i + hD, \u03b5ihD, \u2022i)\n(1\u2212x)hD, \u03b5ihD, \u03b5i + x\n\nAs the least solution we obtain the probabilities [Z, \u2022] = 1, [Z, \u03b5] = 0, [I, \u2022] = 0, [I, \u03b5] =\nmin{1, (1\u2212x)/x}, [D, \u2022] = 0, [D, \u03b5] = min{1, x/(1\u2212x)}. By applying Lemma 3.4 we further\nobtain that, e.g., P(IIZ, C1 U C2 ) = [I, \u2022] + [I, \u03b5] * ([I, \u2022] + [I, \u03b5] * [Z, \u2022]) = min{1, (1\u2212x)2 /x2 }.\n2\nIn Example 3.6 it is possible to compute a closed form for the least solution of the\nsystem of equations, but in general this is not true. However, many important properties\nof the least solution are decidable, because the decision problem can be reduced to the\nproblem of deciding the truth of a formula in the first-order theory of the reals. For our\npurposes, it suffices to consider the class of properties defined in the next theorem.\nTheorem 3.7. Let Const = Q \u222a {[pXq], [pX\u2022] | p, q \u2208 Q and X \u2208 \u0393}, where Q is the set\nof all rational constants. Let E1 , E2 be expressions built over Const using '*' and '+', and\nlet \u223c \u2208 {<, =}. It is decidable whether E1 \u223c E2 .\nProof. We show that, due to Theorem 3.5, E1 \u223c E2 is effectively expressible as a closed\nformula of (R, +, \u2217, \u2264). Hence, the theorem follows from the decidability of first-order\narithmetic of reals [Tar51].\nFor all p, q \u2208 Q and X \u2208 \u0393, let x(pXq), x(pX\u2022), y(pXq), and y(pX\u2022) be first order\n~ and Y\n~ be the vectors of all x(pXq), x(pX\u2022), and y(pXq), y(pX\u2022)\nvariables, and let X\nvariables, respectively. Let us consider the formula \u03a6 constructed as follows:\n~ : ~0 \u2264 X\n~ \u2264 ~1 \u2227 X\n~ = F(X)\n~\n\u2203X\n~ : (~0 \u2264 Y\n~ \u2264 ~1 \u2227 Y\n~ = F(Y\n~ )) \u21d2 X\n~ \u2264Y\n~ ))\n\u2227 (\u2200Y\n~\n~\n\u2227 E1 [X/\u03c0]\n\u223c E2 [X/\u03c0]\n\n~ = F(X)\n~ and Y\n~ = F(Y\n~ ) are expressible only using multipliObserve that the conditions X\n~\n~\ncation, summation, and equality. The expressions E1 [X/\u03c0]\nand E2 [X/\u03c0]\nare obtained from\nE1 and E2 by substituting all [pXq] and [pX\u2022] with x(pXq) and x(pX\u2022), respectively. It\nfollows immediately that E1 \u223c E2 iff \u03a6 holds.\n\n\f12\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nInput: pX \u2208 C(\u2206), 0 < \u03bb < 1\nOutput: P l , P u\n\n1: P l := 0; P u := 1;\n2: for i = 1 to P\n\u2308\u2212 log2 \u03bb\u2309\n3:\nif [pX\u2022] + q\u03b5\u2208C2 [pXq] \u2265 (P u \u2212 P l )/2\n4:\nthen P l := (P u \u2212 P l )/2\n5:\nelse P u := (P u \u2212 P l )/2\n6:\nfi\n\nFigure 2: Computing P l , P u\nAn immediate consequence of Theorem 3.7 is the following:\nTheorem 3.8. Let p\u03b1 \u2208 C(\u2206), \u033a \u2208 Q \u2229 [0, 1], \u223c \u2208 {\u2264, <, \u2265, >} and 0 < \u03bb < 1. It is\ndecidable whether P(p\u03b1, C1 U C2 ) \u223c \u033a. Moreover, there effectively exist rational numbers\nP l , P u such that P l \u2264 P(p\u03b1, C1 U C2 ) \u2264 P u and P u \u2212 P l \u2264 \u03bb.\n\nProof. We\nP can assume w.l.o.g. that \u03b1 = X for some X \u2208 \u0393. Note that P(pX, C1 U C2 ) \u223c \u033a iff\n[pX\u2022] + q\u03b5\u2208C2 [pXq] \u223c \u033a by Lemma 3.4. Hence, we can apply Theorem 3.7. The numbers\nP l , P u are computable, e.g., by the algorithm of Fig. 2.\n4. Model Checking PCTL for pPDAs\nIn this section we study the model-checking problem for PCTL formulas with regular\nvaluations and pPDA.\n4.1. Qualitative Fragment of PCTL. We give a model checking algorithm for the qualitative fragment of PCTL, i.e., for the fragment in which only 0 and 1 are allowed as\nprobability thresholds.\nRecall that in order to check if a CTL formula \u03c6 holds of a finite state system we\nfirst recursively compute the sets of states that satisfy the subformulas of \u03c6 lying right\nbelow \u03c6 in the syntax tree, and then we apply a semantic operator that gets these sets\nof states as inputs and produces the set of states satisfying \u03c6 as output. In the case of a\nPDA (no probabilities), these sets of states (they are now sets of configurations) can be\ninfinite. Therefore, in order to apply a similar algorithm it is necessary to prove that the\nsets have a finite representation. This was done in [BEM97]: It was shown that in the case\nof regular valuations the sets are always regular, and so can be finitely represented by, say,\nfinite automata. In this section we prove that the same property also holds for pPDA and\nfor the qualitative fragment of PCTL, and that the constructions showing the regularity of\nthe sets are effective.\nBy Lemma 2.5, we only need to show that if the sets of configurations satisfying the\nsubformulas of \u03c6 are simple, then the set of configurations satisfying \u03c6 is regular. We need\nto consider four cases, corresponding to formulas of the form X =0 \u03c6, X =1 \u03c6, \u03c61 U =0 \u03c62 , and\n\u03c61 U =1 \u03c62 . they are dealt with in Lemma 4.1, Lemma 4.2, and Lemma 4.3.\nFor the rest of this section we fix a pPDA \u2206 = (Q, \u0393, \u03b4, Prob).\nLemma 4.1. Let C \u2286 C(\u2206) be a simple set. The sets {p\u03b1 \u2208 C(\u2206) | P(p\u03b1, X C) = 1} and\n{p\u03b1 \u2208 C(\u2206) | P(p\u03b1, X C) = 0} are effectively regular.\n\nProof. Follows immediate from the fact that p\u03b1 has only finitely many successors in the\nprobabilistic transition system associated to \u2206..\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n13\n\nLemma 4.2. Let C1 , C2 \u2286 C(\u2206) be simple sets. The set {p\u03b1 \u2208 C(\u2206) | P(p\u03b1, C1 U C2 ) = 1}\nis effectively regular.\nProof. Let R(pX) = {q \u2208 Q | [pXq] > 0} for all p \u2208 Q, X \u2208 \u0393. For each i \u2208 N0 we define\nthe set Si \u2286 C(\u2206) inductively as follows:\n\n\u2217\n\u2022 S0 = {q\u03b5 | q\u03b5 \u2208 C2 } \u222a {qX\u03b1\nP | [qX\u2022] = 1, \u03b1 \u2208 \u0393 }\n\u2022 Si+1 = {pX\u03b2 | [pX\u2022] + q\u2208R(pX) [pXq] = 1 and \u2200q \u2208 R(pX) : q\u03b2 \u2208 Si }\nS\nUsing Lemma 3.4, weScan easily check that \u221e\ni=0 Si = {p\u03b1 \u2208 C(\u2206) | P(p\u03b1, C1 U C2 ) = 1}.\nTo see that the set \u221e\nS\nis\neffectively\nregular,\neach p \u2208 Q we construct a finite\ni\ni=0\nSfor\n\u221e\n\u2217 | p\u03b1 \u2208\nautomaton\nM\nsuch\nthat\nL(M\n)\n=\n{\u03b1\n\u2208\n\u0393\np\np\ni=0 Si }. A \u2206-automaton A recognizing\nS\nthe set \u221e\nS\ncan\nthen\nbe\nconstructed\nusing\nstandard\nalgorithms of automata theory (in\ni=0 i\nparticular, note that regular languages are effectively closed under reverse). The states of\nMp are all subsets of Q, {p} is the initial state, \u0393 is the input alphabet, the final states\nare those T \u2286 Q where for every q \u2208 T we have that q\u03b5 \u2208 C2 (in particular, note that \u2205 is\nX\n\na final state), and the transition function is given by T \u2192 U iff for every q \u2208 T we have\nP\nS\nX\nthat [qX\u2022] + r\u2208R(qX) [qXr] = 1 and U = q\u2208T R(qX). Note that \u2205 \u2192 \u2205 for each X \u2208 \u0393.\nThe definition of Mp is effective\ndue to Theorem 3.7. It is straightforward to check that\nS\nL(Mp ) = {\u03b1 \u2208 \u0393\u2217 | p\u03b1 \u2208 \u221e\nS\n}.\ni=0 i\n\nLemma 4.3. Let C1 , C2 \u2286 C(\u2206) be simple sets. The set {p\u03b1 \u2208 C(\u2206) | P(p\u03b1, C1 U C2 ) = 0}\nis effectively regular.\n\nProof. Let R(pX) = {q \u2208 Q | [pXq] > 0} for all p \u2208 Q, X \u2208 \u0393. For each i \u2208 N0 we define\nthe set Si \u2286 C(\u2206) inductively as follows:\n\u2022 S0 = {q\u03b5 | q\u03b5 6\u2208 C2 }\n\u2022 Si+1 = {pX\u03b2 | [pX\u2022] = 0 and \u2200q \u2208 R(pX) : q\u03b2 \u2208 Si }\nS\nThe factS \u221e\ni=0 Si = {p\u03b1 \u2208 C(\u2206) | P(p\u03b1, C1 U C2 ) = 0} follows immediately from Lemma 3.4.\n\u221e\nThe set i=0 Si is effectively regular, whichScan be shown by constructing a finite automaton\nMp recognizing the set {\u03b1 \u2208 \u0393\u2217 | p\u03b1 \u2208 \u221e\ni=0 Si }. This construction and the rest of the\nargument are very similar to the ones of the proof of Lemma 4.2. Therefore, they are not\ngiven explicitly.\n\nTheorem 4.4. Let \u03c6 be a qualitative PCTL formula and \u03bd a regular valuation. The set\n{p\u03b1 \u2208 C(\u2206) | p\u03b1 |=\u03bd \u03c6} is effectively regular.\nProof. By induction on the structure of \u03c6. The cases when \u03c6 \u2261 tt and \u03c6 \u2261 a follow\nimmediately. For Boolean connectives we use the fact that regular sets are closed under\ncomplement and intersection. The other cases are covered by Lemma 4.1, 4.2, and 4.3.\nHere we also need Lemma 2.5, because the regular sets of configurations must effectively be\nreplaced with simple ones before applying Lemma 4.1, 4.2, and 4.3.\n4.2. Model Checking PCTL for pBPA Processes. In this section we consider arbitrary\nPCTL properties with regular valuations, but restrict ourselves to pBPA processes. We\nprovide an error-tolerant model-checking algorithm. Since it is not so obvious what is meant\nby error tolerance in the context of PCTL model checking, this notion is defined formally.\nMore precisely, we first show that for every formula there is an equivalent negation-free\nformula, and then we provide a definition for negation-free formulas.\n\n\f14\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nLet T = (S, \u2192, Prob) be a probabilistic transition system and 0 < \u03bb < 1, let \u03c6 be a\nPCTL formula, and let \u03bd be a regular valuation (i.e., for every atomic proposition a the\nset \u03bd(a) of configurations is regular). We observe that there is a negation-free formula \u03c6\u2032\n\u2032\nand a regular valuation \u03bd \u2032 such that [[\u03c6]]\u03bd = [[\u03c6\u2032 ]]\u03bd . First, negations can be \"pushed inside\"\nto atomic propositions using dual connectives (note that, e.g., \u00ac(\u03c6 U \u2265\u033a \u03c8) is equivalent to\n\u03c6 U <\u033a \u03c8). Moreover, since regular sets are closed under complement, [[\u00aca]]\u03bd is also regular\nfor every a. We construct \u03c6\u2032 by replacing each negation \u00aca by a fresh atomic proposition\nb, and we extend \u03bd to \u03bd \u2032 by defining \u03bd(b) = [[\u00aca]]\u03bd .\nFor every negation-free PCTL formula \u03c6 and valuation \u03bd we define the denotation of\n\u03c6 over T w.r.t. \u03bd with error tolerance \u03bb, denoted [[\u03c6]]\u03bd\u03bb , in the same way as [[\u03c6]]\u03bd . The only\nexception is \u03c61 U \u223c\u033a \u03c62 where\n\u2022 if \u223c \u2208 {<, \u2264}, then [[\u03c61 U \u223c\u033a \u03c62 ]]\u03bd\u03bb = {s \u2208 S | P(s, [[\u03c61 ]]\u03bd\u03bb U [[\u03c62 ]]\u03bd\u03bb ) \u223c \u033a + \u03bb}\n\u2022 if \u223c \u2208 {>, \u2265}, then [[\u03c61 U \u223c\u033a \u03c62 ]]\u03bd\u03bb = {s \u2208 S | P(s, [[\u03c61 ]]\u03bd\u03bb U [[\u03c62 ]]\u03bd\u03bb ) \u223c \u033a \u2212 \u03bb}\n\nNotice that every negation-free formula \u03c6 satisfies [[\u03c6]]\u03bd \u2286 [[\u03c6]]\u03bd\u03bb .\nAn error tolerant PCTL model checking algorithm is an algorithm which, for each PCTL\nformula \u03c6, valuation \u03bd, s \u2208 S, and 0 < \u03bb < 1, outputs YES/NO so that\n\u2022 if s \u2208 [[\u03c6]]\u03bd , then the answer is YES;\n\u2022 if the answer is YES, then s \u2208 [[\u03c6]]\u03bd\u03bb .\n\nFor the rest of this section, let us fix a pBPA \u2206 = (\u0393, \u03b4, Prob ). Since \u2206 has just one (or\n\"none\") control state p, we write [X, \u2022] and [X, \u03b5] instead of [pX\u2022] and [pXp], respectively.\nWe need the following obvious generalization of Lemma 4.1 (use the same proof):\nLemma 4.5. Let C \u2286 C(\u2206) be a simple set, \u033a \u2208 [0, 1], and \u223c \u2208 {\u2264, <, \u2265, >}. The set\n{\u03b1 \u2208 C(\u2206) | P(\u03b1, X C) \u223c \u033a} is effectively regular.\nProof. Immediate.\nThe following lemma presents the crucial part of the algorithm. This is the place where\nwe need the assumption that \u2206 is a pBPA.\nLemma 4.6. Let C1 , C2 \u2286 C(\u2206) be simple sets. For all \u033a \u2208 [0, 1] and 0 < \u03bb < 1 there\neffectively exist \u2206-automata A\u2265 and A\u2264 such that for all \u03b1 \u2208 C(\u2206) we have that\n\n\u2022 if P(\u03b1, C1 U C2 ) \u2265 \u033a (or P(\u03b1, C1 U C2 ) \u2264 \u033a), then \u03b1 \u2208 C(A\u2265 ) (or \u03b1 \u2208 C(A\u2264 ), respectively.)\n\u2022 if \u03b1 \u2208 C(A\u2265 ) (or \u03b1 \u2208 C(A\u2264 )), then P(\u03b1, C1 U C2 ) \u2265 \u033a \u2212 \u03bb (or P(\u03b1, C1 U C2 ) \u2264 \u033a + \u03bb,\nrespectively.)\n\nProof. We describe just the construction of A\u2265 (the \u2206-automaton A\u2264 is constructed similarly). Let S = {X \u2208 \u0393 | [X, \u03b5] 6= 1}. For each \u03b2 \u2208 S \u2217 we define the set Cl(\u03b2) = {\u03b1 \u2208 \u0393\u2217 |\n\u03b1|S = \u03b2}, where \u03b1|S is the word obtained by deleting in \u03b1 all occurrences of symbols in\n\u0393 r S. It follows directly from Lemma 3.4 that for all \u03b2 \u2208 S \u2217 S\nand \u03b1 \u2208 Cl(\u03b2) we have that\nP(\u03b2, C1 U C2 ) = P(\u03b1, C1 U C2 ). Further, for all n \u2208 N0 and \u03b2 \u2208 ni=0 S i we define the set\n(\nCl (\u03b2)\nif \u03b1 \u2208 S i \u2227 i < n\nGen n (\u03b2) =\n{\u03b1\u03b1\u2032 | \u03b1 \u2208 Cl (\u03b2), \u03b1\u2032 \u2208 \u0393\u2217 } if \u03b1 \u2208 S n\nS\nWe prove that for every 0 < \u03bb < 1 there effectively exist n \u2208 N0 and G \u2286 ni=0 S i such that\nfor every \u03b1 \u2208 \u0393\u2217 we have that\nS\n\u2022 if P(\u03b1, C1 U C2 ) \u2265 \u033a, then \u03b1 \u2208 \u03b2\u2208G Gen n (\u03b2);\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n15\n\nInput: pBPA \u2206, 0 < \u03bb < 1\nOutput: n, \u03ba, \u03bd, [X, \u2022]l , [X, \u03b5]l , [X, \u2022]u , [X, \u03b5]u\n\n1: S := {X \u2208 \u0393 | [X, \u03b5] 6= 1};\n2: \u03bd := 1; n := \u221e;\n3: for each X \u2208 S do\n4:\n[X, \u03b5]l := 0; [X, \u2022]l := 0; [X, \u03b5]u := 1; [X, \u2022]u := 1;\n5: done\n6: repeat\n7:\nfor each X \u2208 \u0393 do\n8:\navg\u03b5 := ([X, \u03b5]u \u2212 [X, \u03b5]l )/2;\n9:\navg\u2022 := ([X, \u2022]u \u2212 [X, \u2022]l )/2;\n10:\nif [X, \u03b5] \u2265 avg\u03b5 then [X, \u03b5]l := avg\u03b5 ;\n11:\nelse [X, \u03b5]u := avg\u03b5 ;\n12:\nif [X, \u2022] \u2265 avg\u2022 then [X, \u2022]l := avg\u2022 ;\n13:\nelse [X, \u2022]u := avg\u2022 ;\n14:\ndone\n15:\n\u03bd := \u03bd/2;\n16:\n\u03ba := max{[X, \u03b5]u | X \u2208 S};\n17:\nif \u03ba < 1 then n := \u2308(log(\u03bb/3)/ log \u03ba\u2309\n18: until \u03ba < 1 and n(\u03bd + \u03bd(n + 1)(1 + \u03bd)n ) \u2264 \u03bb/3\nFigure 3: A part of the algorithm for pBPA\nS\n\nGen n (\u03b2), then P(\u03b1, C1 U C2 ) \u2265 \u033a \u2212 \u03bb.\nS\nThis suffices for our purposes, because the set \u03b2\u2208G Gen n (\u03b2) is clearly recognizable by an\neffectively constructible \u2206-automaton A\u2265 .\nThe crucial part of the algorithm for computing the set G is shown in Fig. 3. The\nalgorithm starts by computing the set S (note that S is effectively computable due to\nTheorem 3.7). For each X \u2208 S, there are four rational variables [X, \u03b5]l , [X, \u03b5]u , [X, \u2022]l ,\nand [X, \u2022]u whose values are lower and upper approximations of the probabilities [X, \u03b5] and\n[X, \u2022], resp. These variables are initialized in lines 3\u20135 and successively refined in lines\n7\u201314. Note that the conditions of the if statements in lines 10 and 12 are effective due to\nTheorem 3.7. The current \"precision\", i.e., the difference between the upper and the lower\napproximation is stored in the rational variable \u03bd. The subtle point is the termination\ncondition. First, one necessary condition for termination is that \u03ba = max{[X, \u03b5]u | X \u2208 S}\nbecomes less than one. This must happen eventually, because [X, \u03b5] < 1 for every X \u2208 S.\nAn important observation is that \u03ba can only decrease by performing the assignment in\nline 16. This means that n = \u2308log(\u03bb/3)/ log \u03ba\u2309 also only decreases (since both \u03bb and \u03ba\nare less than 1, we have log(\u03bb/3)/ log \u03ba = | log(\u03bb/3)|/| log \u03ba|; and if 0 < \u03ba\u2032 < \u03ba < 1,\nthen | log \u03ba\u2032 | > | log \u03ba|). Therefore, we eventually find a sufficiently small \u03bd such that\nn(\u03bd + \u03bd(n + 1)(1 + \u03bd)n ) \u2264 \u03bb/3.\nThe output of the algorithm of Fig. 3 are the (values of the) variables n, \u03bd, \u03ba, [X, \u03b5]l ,\n[X, \u03b5]u , [X, \u2022]l , and [X, \u2022]u where X ranges over S. For each \u03b2 \u2208 S \u2217 , let P l (\u03b2, C1 U C2 ) and\nP u (\u03b2, C1 U C2 ) be the lower and upper approximations of P(\u03b2, C1 U C2 ) obtained by using\nthe formula of Lemma 3.4 where [X, \u03b5]l , [X, \u2022]l , and [X, \u03b5]u , [X, \u2022]u are used instead of\n\u2022 if \u03b1 \u2208\n\n\u03b2\u2208G\n\n\f16\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\n[X, \u03b5], [X, \u2022], respectively. The set G is constructed as follows:\n\nG = {\u03b2 \u2208 S i | 0 \u2264 i < n, P u (\u03b2, C1 U C2 ) \u2265 \u033a}\n\u222a {\u03b2 \u2208 S n | P u (\u03b2, C1 U C2 ) \u2265 \u033a \u2212 \u03bb/3}\n\nTo verify that the set G has the properties mentioned above, we need to formulate two\nauxiliary observations.\n(a) for all \u03b2 \u2208 S n and \u03b1 \u2208 \u0393\u2217 we have that\n\n|P(\u03b2, C1 U C2 ) \u2212 P(\u03b2\u03b1, C1 U C2 )| \u2264 \u03bb/3\n\nThis follows immediately from the following (in)equalities:\n\nP(\u03b2\u03b1, C1 U C2 ) = P(\u03b2, C1 U C2\u2022 ) + P(\u03b2, C1 rC2 U {\u03b5}) * P(\u03b1, C1 U C2 )\nP(\u03b2, C1 U C2 ) \u2264 P(\u03b2, C1 U C2\u2022 ) + P(\u03b2, C1 rC2 U {\u03b5})\n\nP(\u03b2, C1 rC2 U {\u03b5}) \u2264 \u03bb/3\n\nThe first two (in)equalities are obtained just by applying Lemma 3.4. The last one is\nderived as follows: P(\u03b2, C1 rC2 U {\u03b5}) is surely bounded by \u03ban (by Lemma 3.4 and the\ndefinition of \u03ba). Since n = \u2308log(\u03bb/3)/ log \u03ba\u2309, we have n * log \u03ba \u2264 log(\u03bb/3). Hence,\nlog \u03ban \u2264 log(\u03bb/3),\n\u03ban \u2264 \u03bb/3.\nSn thus\ni\n(b) for each \u03b2 \u2208 i=0 S we have that\nP u (\u03b2, C1 U C2 ) \u2212 P(\u03b2, C1 U C2 ) \u2264 \u03bb/3\n\nLet k = length(\u03b2). A straightforward induction on k reveals that P u (\u03b2, C1 U C2 ) \u2264 (k +\n1) * (1 + \u03bd)k . Now we prove (again by induction on k) that\nP u (\u03b2, C1 U C2 ) \u2212 P(\u03b2, C1 U C2 ) \u2264 k(\u03bd + \u03bd(k + 1)(1 + \u03bd)k )\n\nThe base case (when k = 0) is immediate, because P u (\u03b5, C1 U C2 ) = P(\u03b5, C1 U C2 ). Now\nlet \u03b2 = X\u03b2 \u2032 . By definition, P u (X\u03b2 \u2032 , C1 U C2 ) \u2212 P(X\u03b2 \u2032 , C1 U C2 ) is equal to\nSince\n\n[X, \u2022]u + [X, \u03b5]u * P u (\u03b2 \u2032 , C1 U C2 ) \u2212 ([X, \u2022] + [X, \u03b5] * P(\u03b2 \u2032 , C1 U C2 ))\n\n(4.1)\n\n\u03bd + [X, \u03b5] * (P u (\u03b2 \u2032 , C1 U C2 ) \u2212 P(\u03b2 \u2032 , C1 U C2 )) + \u03bd * P u (\u03b2 \u2032 , C1 U C2 )\n\n(4.2)\n\n[X, \u2022]u\n\n\u2264 [X, \u2022] + \u03bd and\n\n[X, \u03b5]u\n\n\u2264 [X, \u03b5] + \u03bd, the expression (4.1) is bounded by\nP u (\u03b2, C\n\nBy applying induction hypothesis and the facts that [X, \u03b5] \u2264 1 and\n1 U C2 ) \u2264\n(k + 1) * (1 + \u03bd)k (see above), we obtain that the expression (4.2) is bounded by\n\u03bd + k(\u03bd + \u03bd(k + 1)(1 + \u03bd)k ) + \u03bd(k + 1)(1 + \u03bd)k\n\nwhich is bounded by (k +1)(\u03bd +\u03bd(k +2)(1+\u03bd)k+1 ) as required. This finishes the inductive\nstep.\nSince n(\u03bd + \u03bd(n + 1)(1 + \u03bd)n ) \u2264 \u03bb/3 and k \u2264 n, we have P u (\u03b2, C1 U C2 ) \u2212 P(\u03b2, C1 U C2 ) \u2264\nk(\u03bd + \u03bd(k + 1)(1 + \u03bd)k ) \u2264 \u03bb/3.\n\nNow we are ready to prove that the set G has the required properties. Let \u03b1 \u2208 \u0393\u2217 such that\nP(\u03b1, C1 U C2 ) \u2265 \u033a, and let \u03b2 = \u03b1|S . There are two possibilities:\nS\n\u2022 length(\u03b2) < n. Then P u (\u03b2, C1 U C2 ) \u2265 \u033a, hence \u03b2 \u2208 G and \u03b1 \u2208 \u03b2\u2208G Gen n (\u03b2).\n\u2022 length(\u03b2) \u2265 n. Let \u03b2 = \u03b3\u03b3 \u2032 where length(\u03b3) = n. Due to the observation (a) above we\nhave that P(\u03b3, C1 U CS2 ) \u2265 \u033a \u2212 \u03bb/3, hence also P u (\u03b3, C1 U C2 ) \u2265 \u033a \u2212 \u03bb/3, which means that\n\u03b3 \u2208 G and thus \u03b1 \u2208 \u03b2\u2208G Gen n (\u03b2).\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n17\n\nNow let \u03b1 \u2208 Gen n (\u03b2) for some \u03b2 \u2208 G. Again, we distinguish two possibilities:\n\n\u2022 length(\u03b2) < n. Then P u (\u03b2, C1 U C2 ) \u2265 \u033a, which means that P(\u03b2, C1 U C2 ) \u2265 \u033a \u2212 \u03bb/3 by\nthe observation (b) above. Hence, P(\u03b1, C1 U C2 ) \u2265 \u033a \u2212 \u03bb/3.\n\u2022 length(\u03b2) = n. Then P u (\u03b2, C1 U C2 ) \u2265 \u033a\u2212 \u03bb/3, which means that P(\u03b2, C1 U C2 ) \u2265 \u033a\u2212 2\u03bb/3\ndue to the observation (b). Further, for every \u03b1\u2032 \u2208 \u0393 we have that P(\u03b2\u03b1\u2032 , C1 U C2 ) \u2265 \u033a \u2212 \u03bb\ndue to the observation (a) above. Hence, P(\u03b1, C1 U C2 ) \u2265 \u033a \u2212 \u03bb as required.\n\nThe automaton A\u2264 is constructed similarly. Here, the set G is computed using the\nlower approximations [X, \u2022]l and [X, \u03b5]l . Since this construction is analogous to the one\njust presented, it is not given explicitly.\nTheorem 4.7. There is an error-tolerant PCTL model checking algorithm for pBPA processes.\nProof. The proof is similar to the one of Theorem 4.4, using Lemma 4.5 and 4.6 instead of\nLemma 4.1, 4.2, and 4.3. Note that Lemma 2.5 is applicable also to pBPA (the system \u2206\u2032\nconstructed in Lemma 2.5 has the same set of control states as the original system \u2206).\n5. Model Checking \u03c9-regular Specifications\n\nIn this section we show that the qualitative and quantitative model-checking problem\nfor pPDA and \u03c9-regular properties are decidable. At the very core of our result are observations leading to the definition of a finite Markov chain M\u2206 . Intuitively, each transition\nof M\u2206 corresponds to a sequence of transitions of the probabilistic transition system T\u2206\nassociated to \u2206. This allows to reduce the model-checking problem to a problem about\nM\u2206 , which, since M\u2206 is finite, can be solved using well-known techniques. In [EKM04], the\nMarkov chain M\u2206 was used to show that the qualitative and quantitative model-checking\nproblem for properties expressible by deterministic B\u00fcchi automata is decidable. Later,\nit was observed in [BKS05] that the technique can easily be generalized to deterministic\nMuller automata. Thus, the decidability result was extended to all \u03c9-regular properties.\nIn this paper we go a bit further, and prove the decidability of a slightly larger class. The\nprevious result about the \u03c9-regular case follows as a corollary.\nThe section is structured as follows. Given a pPDA \u2206, we first introduce the notion of\nminima of a run and \u2206-observing automaton. We use observing automata as specifications:\nan infinite run satisfies the specification iff it is accepted by the automaton (section 5.1).\nUsing the notion of minima, we define the finite Markov chain M\u2206 (section 5.2), and\nshow that the probability that a run is accepted by a \u2206-observing automaton is effectively\nexpressible in (R, +, \u2217, \u2264) (section 5.3). Finally, we show that the model-checking problem\nfor \u03c9-regular properties is a special case of the problem of deciding if a run is accepted by\na \u2206-observing automaton with at least a given probability (section 5.4).\nFor the rest of this section, we fix a pPDA \u2206 = (Q, \u0393, \u03b4, Prob).\n5.1. Minima of a run.\nLoosely speaking, a configuration of a run is a minimum if all\nconfigurations placed after it in the run have the same or larger stack length.\nDefinition 5.1. Let w = p1 \u03b11 ; p2 \u03b12 , * * * be an infinite run in T\u2206 . A configuration pi \u03b1i is a\nminimum of w if |\u03b1i | \u2264 |\u03b1j | for every j \u2265 i. We say that pi \u03b1i is the kth minimum of w if\npi \u03b1i is a minimum and there are exactly k \u2212 1 indices j < i such that pj \u03b1j is a minimum.\nWe denote the kth minimum of w by mink (w).\n\n\f18\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nSometimes we abuse language and use mini (w) to denote not only a configuration, but the\nparticular occurrence of the configuration that corresponds to the ith minimum.\nExample 5.2. In the run w1 = (Z; DZ)\u03c9 of the pBPA shown in the introduction we have\nmini (w1 ) = Z for every i \u2265 1. In the run w2 = Z; DZ; DDZ; . . . we have min1 (w2 ) = Z\nand mini (w2 ) = D for every i \u2265 2. Every odd configuration of w1 is a minimum, and every\nconfiguration of w2 is a minimum.\n2\nSince stack lengths are bounded from below, every infinite run has infinitely many\nminima, and so it can be divided into an infinite sequence of fragments, or \"jumps\", each\nof them leading from one minimum to the next.\nWe are interested in those properties of a run that can be decided by extracting a\nfinite amount of information from each jump, independently of its length. Consider for\ninstance the property \"the control state p is visited infinitely often along the run\". It can\nbe reformulated as \"there are infinitely many jumps along which the state p is visited\".\nIn order to decide the property all we need is a bit of information for each jump, telling\nwhether it is \"visiting\" or \"non-visiting\". We consider properties in which this finite amount\nof information can be extracted by letting a finite automaton go over the jump reading the\nheads of the configurations:\nDefinition 5.3. Given a configuration pX\u03b1 of \u2206, we call pX the head and \u03b1 the tail of\npX\u03b1. The set Q \u00d7 \u0393 of all heads of \u2206 is also denoted by H(\u2206).\nMore precisely, we consider automata with the set of heads as alphabet. An oracle tells\nthe automaton to start reading heads immediately after the run leaves a minimum (i.e., the\nfirst head read is the one of the configuration immediately following the minimum), stop\nafter reading the head of the next minimum, report its state, and reset itself to an initial\nstate that depends on the head of the minimum.\nDefinition 5.4. A \u2206-observing automaton is a tuple A = (A, \u03be, ao , Acc) where A is finite\nset of observing states, \u03be : A \u00d7 H(\u2206) \u2192 A is a (total) transition function, a0 \u2208 A is an\ninitial state, and Acc is a set of subsets of A, also called an acceptance set.\nLet w be an infinite run in T\u2206 and let i \u2208 N. The ith observation of A over w, denoted\nObs i (w), is the state reached by A after reading the heads of all configurations between\nmini (w) and mini+1 (w), including mini+1 (w) but not including mini (w). 4 The observation\nof A on w, denoted by Obs(w), is the sequence Obs 1 (w)Obs 2 (w) . . ..\nWe say that an infinite run w \u2208 Run(pX) is accepting if the set of states of A that\noccur infinitely often in Obs(w) belongs to Acc; otherwise, w is rejecting.\nExample 5.5. Figure 4 shows a \u2206-observing automaton for the pBPA of the introduction\n(see also Figure 1). For every infinite run w and every i \u2265 0, we have Obs i (w) = b if some\nconfiguration of the ith jump has Z as topmost stack symbol. So a run is accepting iff it\nvisits configurations with head Z infinitely often.\n2\nFor the rest of the section we fix a \u2206-observing automaton A = (A, \u03be, a0 , Acc). Let\nRun(pX, Acc) be the set of all accepting runs initiated in pX. Our aim is to show that\nP(Run(pX, Acc)) is effectively definable in (R, +, \u2217, \u2264).\n4Notice that the automaton starts observing after the first minimum of the run.\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\nI,D\n\n\u001f\u001f\n?8// 9\n>\n=\na:\n0 <;\n\n19\n\nZ,I,D\nZ\n\n\u001f\u001f\n?//89\n>\n=\na:\n1 <;\n\nAcc = {{a1 }}\n\nFigure 4: An observing automaton\n5.2. The Markov chain M\u2206 .\nFor all pX \u2208 H(\u2206) and all i \u2208 N we define a random\n(i)\n(i)\nvariable VpX over Run(pX). Loosely speaking, VpX assigns to a run starting at the configuration pX the head of its ith minimum, and the ith observation of the \u2206-observing\n(i)\nautomaton A. Formally, the possible values of VpX are pairs of the form (qY, a), where\nqY \u2208 H(\u2206) and a \u2208 A. There is also a special value \u22a5, where \u22a5 6\u2208 H(\u2206) \u00d7 A. For a given\n(i)\n(i)\nw \u2208 Run(pX), the value VpX (w) is determined as follows: If w is finite, then VpX (w) = \u22a5;\n(i)\n\notherwise, VpX (w) = (qY, Obs i (w)), where qY is the head of mini (w). Notice that the\nrandom variables are well defined, because they assign to each run exactly one value.\n(1)\n(n)\nGiven possible values v1 , . . . , vn for the variables VpX , . . . , VpX , we are going to prove\nthe following two results:\n(1)\n\n(n)\n\n\u2022 the probability that a run satisfies VpX = v1 , . . . , VpX = vn is expressible in (R, +, \u2217, \u2264)\n(Lemma 5.10); and\n(i)\n(i+1)\n\u2022 the probability that VpX = vi+1 depends only on the value of VpX , but neither on i nor\n(k)\n\non the value of VpX for k < i (Lemma 5.11 and 5.12).\n\nThe second result will allow us to define the finite Markov chain M\u2206 , while the first one\nwill show that its transition probabilities are expressible in (R, +, \u2217, \u2264).\nThe proof of Lemma 5.10 is rather technical (as we shall, see, Lemma 5.11 and 5.12 are\neasy corollaries of Lemma 5.10). We need three auxiliary lemmas. Intuitively, the first one\nstates that the probability of executing an infinite run from a configuration pX is equal to\nthe probability of executing an infinite run from pX\u03b2 such that the stack content never goes\n\"below\" \u03b2. For every finite or infinite path w = p1 \u03b11 ; p2 \u03b12 ; * * * in T\u2206 and every \u03b2 \u2208 \u0393\u2217 , the\nsymbol w+\u03b2 denotes the path p1 \u03b11 \u03b2; p2 \u03b12 \u03b2; * * * obtained from w by concatenating \u03b2 to the\nstack content in every configuration. Similarly, if R is a set of paths in T\u2206 and \u03b2 \u2208 \u0393\u2217 , then\n[R]+\u03b2 denotes the set {w+\u03b2 | w \u2208 R}.\n\nLemma 5.6. Let pX \u2208 Q\u00d7\u0393 and \u03b2 \u2208 \u0393\u2217 . Then P([IRun(pX)]+\u03b2 ) = P(IRun(pX)).\n\nProof. Let Dead = Q\u00d7{\u03b5} \u222a {qY \u03b1 | qY has no transitions in \u03b4, \u03b1 \u2208 \u0393\u2217 }. We have that\nP([IRun(pX)]+\u03b2 ) = 1 \u2212 P(pX\u03b2, C(\u2206)\u2022 \u03b2 U Dead \u03b2)\n= 1 \u2212 P(pX, C(\u2206) U Dead) (by Lemma 3.3)\n= P(IRun(pX)).\n\nThe second lemma states that prefixing a measurable set of runs with a finite path\nyields a measurable set of runs, and relates the probabilities of both sets.\nLemma 5.7. Let s0 ; * * * ; sn be a path in a probabilistic transition system, and let R be a\nmeasurable subset of Run(sn ). Then {s0 ; * * * ; sn } \u2299 R is a measurable subset of Run(s0 ),\n\n\f20\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nxi+1\n\nand moreover P({s0 ; * * * ; sn } \u2299 R) = \u03a0ni=1 xi * P(R), where si \u2212\u2192 si+1 for every 0 \u2264 i < n.\n(The '\u2299' operator has been introduced in Definition 3.1.)\nProof. Standard.\nThe third lemma shows that the probability of starting from the configuration qY\nreaching the configuration q\u03b5 with the observing automaton in state a is expressible in\n(R, +, \u2217, \u2264).\n\nDefinition 5.8. Let R be a P-measurable set of runs of T\u2206 starting at the same initial\nconfiguration. We say that P(R) is well-definable if there effectively exist a pPDA \u2206\u2032 and\na finite family of probabilities of the form P(Run(qY, C1 U C2 )), where qY \u2208 H(\u2206\u2032 ) and\nC1 , C2 \u2286 C(\u2206\u2032 ) are simple sets, such that P(R) is effectively definable from this family of\nprobabilities using only summation, multiplication, and rational constants.\nNote that if P(R) is well-definable, it can be expressed in (R, +, \u2217, \u2264) using the results of\nSection 3.\nFor all qY \u2208 H(\u2206), r \u2208 Q, Z \u2208 \u0393, and a \u2208 A, let Run(qY, r, Z, a) \u2286 Run(qY ) be the\nset of all runs w = s0 ; * * * ; sn such that s0 = qY , sn = r\u03b5, and the automaton A reaches\nthe state a after reading the heads of configurations s0 , * * * , sn\u22121 , rZ.\nLemma 5.9. P(Run(qY, r, Z, a)) is well-definable.\n\nProof. We put \u2206\u2032 = (Q\u00d7A, \u0393, \u03b4\u2032 , Prob \u2032 ) to be the synchronized product of \u2206 and A, i.e.,\nx\nx\n(p, \u0101)X \u2192 (t, \u00e2)\u03b1 is a rule of \u2206\u2032 iff pX \u2192 t\u03b1 is a rule of \u2206 and \u03be(\u0101, pX) = \u00e2. Let\n\u0100 = {\u0101 \u2208 A | \u03be(\u0101, rZ) = a}. Now we can easily check that P(Run(qY, r, Z, a)) is equal to\nP( (q, a0 )Y, C(\u2206\u2032 ) U {(r, \u0101)\u03b5})\n\nWe can now prove our main technical result:\nLemma 5.10. For all pX \u2208 H(\u2206), n \u2208 N, and v1 , * * * , vn \u2208 (H(\u2206)\u00d7A) \u222a {\u22a5}, the proba(n)\n(1)\nbility of VpX =v1 \u2227 * * * \u2227 VpX =vn is well-definable. In particular, for every rational constant\ny there is an effectively constructible formula of (R, +, \u2217, \u2264) which holds if and only if\n(n)\n(1)\nP(VpX =v1 \u2227 * * * \u2227 VpX =vn ) = y.\n(n)\n\n(1)\n\nProof. By induction on n we prove that P(VpX =v1 \u2227 * * * \u2227 VpX =vn ) is well-definable. The\n(1)\n\nbase case when n = 1 follows immediately, because P(VpX =v1 ) equals either P(IRun(pX)),\n1 \u2212 P(IRun(pX)), or 0, depending on whether v1 = (pX, a0 ), v1 = \u22a5, or (pX, a0 ) 6= v1 6=\n\u22a5, respectively. Observe that P(IRun(pX)) = 1 \u2212 P(pX, C(\u2206) U Dead ), where Dead =\nQ\u00d7{\u03b5} \u222a {qY \u03b1 | qY has no transitions in \u03b4, \u03b1 \u2208 \u0393\u2217 }.\nNow let n \u2265 2. For each 1 \u2264 i \u2264 n, let Sat i be the set of all runs that satisfy\n(i)\n(1)\nVpX =v1 \u2227 * * * \u2227 VpX =vi . If P(Sat n\u22121 ) = 0, which is decidable by induction hypothesis, then\nP(Sat n ) = 0 as well. If P(Sat n\u22121 ) 6= 0 and there is an i \u2264 n \u2212 1 such that vi = \u22a5, then for\nall j \u2264 n \u2212 1 we have that vj = \u22a5, and P(Sat n ) is equal either to P(Sat n\u22121 ) or 0, depending\non whether vn = \u22a5 or not, respectively. If P(Sat n\u22121 ) 6= 0, vi 6= \u22a5 for all i \u2264 n \u2212 1, and\nvn = \u22a5, then P(Sat n ) = 0. So, the only interesting case is when P(Sat n\u22121 ) 6= 0 and vi 6= \u22a5\nfor all i \u2264 n. Since\n(n)\nP(VpX =vn | Sat n\u22121 )\nP(Sat n ) =\nP(Sat n\u22121 )\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n21\n\nand P(Sat n\u22121 ) is well-definable by induction hypothesis, it suffices to show that the con(n)\nditional probability P(VpX =vn | Sat n\u22121 ) is also well-definable. For this we use a general\nresult of basic probability theory saying that if A, B are events and B = \u228ei\u2208I Bi , where I is\na finite or countably infinite index set, then\nP\nP(A | Bi ) * P(Bi )\nP(A | B) = i\u2208I\nP(B)\n\nAn immediate consequence of this equation is that if the probability P(A|Bi ) is independent\n(n)\nof i, then P(A|B) = P(A|Bi ). In our case, A is the event VpX =vn , and B is Sat n\u22121 . Let\nChop = {w(0); * * * ; w(minn\u22121 (w)) | w \u2208 Sat n\u22121 }.\n\nObserve that if y \u2208 Chop, then the last configuration of y is of the form pn\u22121 Xn\u22121 \u03b1. We\ndenote the \u03b1 by Stack (y). For every y \u2208 Chop, let\nSat n\u22121 (y) = {y} \u2299 [IRun(pn\u22121 Xn\u22121 )]+Stack (y)\n\n(5.1)\n\nNow we can easily check that\n\nSat n\u22121 =\n\n]\n\nSat n\u22121 (y)\n\ny\u2208Chop\n\nHence, Chop plays the role of I, and Sat n\u22121 (y) plays the role of Bi . We show that\n(n)\nP(VpX =vn | Sat n\u22121 (y)) is independent of y, which means that\n(n)\n\n(n)\n\nP(VpX =vn | Sat n\u22121 (y)) = P(VpX =vn | Sat n\u22121 ).\n\nBy definition of conditional probability,\n\n(n)\n\n(n)\nP(VpX =vn\n\n| Sat n\u22121 (y)) =\n\nP(VpX =vn \u2227 Sat n\u22121 (y))\n\n(5.2)\n\nP(Sat n\u22121 (y))\n\nThe denominator of the fraction in equation (5.2) is well-definable, because\nP(Sat n\u22121 (y)) = P(Run(y)) * P(IRun(pn\u22121 Xn\u22121 ))\n\n(n)\n\nHere we used Lemma 5.6, Lemma 5.7, and equation (5.1). Now we show that P(VpX =vn \u2227\n(n)\n\nSat n\u22121 (y)) is also well-definable. Let R be the set of all runs satisfying VpX =vn \u2227Sat n\u22121 (y),\nand let vn = (pn Xn , an ) and \u03b1 = Stack (y). Obviously, each w \u2208 R starts with y. Now let\nus consider what transitions can be performed from the final state pn\u22121 Xn\u22121 \u03b1 of y.\n\n\u2022 Obviously, transitions which decrease the stack cannot be performed, because pn\u22121 Xn\u22121 \u03b1\nwould not be a minimum then (i.e., w would not belong to R).\nx\n\u2022 If a transition of the form pn\u22121 Xn\u22121 \u03b1 \u2192 rZ\u03b1 is performed, then rZ\u03b1 must be the n-th\nminimum, because the stack cannot be decreased below Z (otherwise, pn\u22121 Xn\u22121 \u03b1 would\nnot be a minimum). So, if w \u2208 R, we must have that rZ = pn Xn and \u03be(a0 , rZ) = an .\nx\n\u2022 If a transition of the form pn\u22121 Xn\u22121 \u03b1 \u2192 rP Q\u03b1 is performed, then the stack cannot be\ndecreased below Q. Now there are two possibilities:\n\u2212 If the stack is never decreased below P , then the configuration rP Q\u03b1 is the n-th minimum. Hence, if w \u2208 R, we must have that rP = pn Xn and \u03be(a0 , rP ) = an .\n\n\f22\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\n\u2212 If the stack is decreased below P , i.e., if a sequence of transitions is performed of\nthe form rP Q\u03b1 \u2192\u2217 tQ\u03b1 (where the stack is never decreased to Q\u03b1 except in the last\nconfiguration), then tQ\u03b1 is the n-th minimum. Hence, if w \u2208 R, we must have that\ntQ = pn Xn and the automaton A reaches an by reading the word consisting of heads\nof configurations in the sequence rP Q\u03b1 \u2192\u2217 tQ\u03b1.\n\nFrom the above discussion, it follows that R can be partitioned as follows:\n]\nR =\n{y} \u2299 {pn\u22121 Xn\u22121 \u03b1; , pn Xn \u03b1} \u2299 [IRun(pn Xn )]+\u03b1\nx\n\npn\u22121 Xn\u22121 \u2192pn Xn\n\n]\n\nx\n\npn\u22121 Xn\u22121 \u2192pn Xn Y\nY \u2208\u0393\n\n]\n\nx\n\npn\u22121 Xn\u22121 \u2192qY Xn\nq\u2208Q,Y \u2208\u0393\n\n{y} \u2299 {pn\u22121 Xn\u22121 \u03b1; pn Xn Y \u03b1} \u2299 [IRun(pn Xn )]+Y \u03b1\n\n{y} \u2299 [Run(qY, pn , Xn , an )]+\u03b1 \u2299 [IRun(pn Xn )]+\u03b1\n\nUsing Lemma 5.6, Lemma 5.7, Lemma 5.9 and the above equation, we obtain that\n(n)\n\nP(VpX =vn \u2227 Sat n\u22121 (y)) = P(Run(y)) * P(IRun(pn Xn )) * S\n\nwhere\n\nS =\n\nX\n\nx\n\nX\n\nx * P(Run(qY, pn , Xn , an ))\n\nX\n\n+\n\nx\n\npn\u22121 Xn\u22121 \u2192pn Xn\n\nx\n\npn\u22121 Xn\u22121 \u2192qY Xn\nq\u2208Q,Y \u2208\u0393\n\nx\n\n+\n\nx\n\npn\u22121 Xn\u22121 \u2192pn Xn Y\nY \u2208\u0393\n\n(5.3)\n\nEquation (5.2) can now be rewritten to\n(n)\n\nP(VpX =vn | Sat n\u22121 (y)) =\n\nP(IRun(pn Xn ))\n*S\nP(IRun(pn\u22121 Xn\u22121 ))\n\n(5.4)\n\n(n)\n\nwhere the meaning of S is given by equation (5.3). So, P(VpX =vn | Sat n\u22121 (y)) is indeed\n(n)\n\nindependent of y, and hence equation (5.4) also defines the probability P(VpX =vn | Sat n\u22121 ).\n\nLoosely speaking, the following lemma proves the memoryless property required to define\n(n\u22121)\n(n)\na Markov chain: The probability of VpX = vn depends only on the value of VpX , not on\n(n\u22122)\n\nthe values of VpX\n\n(1)\n\n, . . . , VpX .\n(n)\n\n(1)\n\nLemma 5.11. The conditional probability of VpX = vn on the hypothesis VpX = v1 \u2227\n(n\u22121)\n\n* * * \u2227 VpX\n\n(n\u22121)\n\n(n)\n\n= vn\u22121 is equal to the probability of VpX = vn conditioned on VpX\n\nassuming that the probability of\n\n(1)\nVpX\n\n= v1 \u2227 * * * \u2227\n\n(n\u22121)\nVpX\n\n= vn\u22121 ,\n\n= vn\u22121 is non-zero.\n\nProof. The result follows immediately from Equation (5.4) in the proof of Lemma 5.10: The\n(1)\n(n\u22122)\nright side on the equation does not depend on the values of VpX , . . . , VpX .\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n23\n\n(n)\n\nFinally, as another consequence of Lemma 5.10 we obtain that the probability of VpX =\nvn does not depend on n:\n(n)\n\n(n\u22121)\n\n=\n\n(1)\nVqY\n\n=\n\nLemma 5.12. The conditional probability of VpX = (q \u2032 Y \u2032 , a\u2032 ) on the hypothesis VpX\n(qY, a) is equal to the conditional probability of\n(qY, a0 ), assuming that\nsatisfies\n\n(1)\nVqY (w)\n\n(n\u22121)\nP(VpX\n\n(2)\nVqY\n\n=\n\n(q \u2032 Y \u2032 , a\u2032 )\n\non the hypothesis\n\n= (qY, a)) 6= 0. Moreover, the hypothesis that a run w\n\n= (qY, a0 ) is the same as the hypothesis that w \u2208 IRun(qY ).\n\nProof. The first part follows immediately from the fact that n appears only as an index in\nEquation (5.4). For the second, observe that, by definition, a run w starting at qY satisfies\n(1)\nVqY (w)=qY if (1) it is infinite and (2) its first minimum has head qY . But (1) and the\nfact that all configurations of an infinite run have length 1 or greater imply that the first\nconfiguration of the run is also its first minimum, and so, since w starts at qY , they imply\n(1)\n(2). So a run w starting at qY satisfies VqY =qY iff it is infinite, i.e., iff w \u2208 IRun(qY ).\nExample 5.13. In order to give some intuition for these results, and in particular for the\nproof of Lemma 5.10, consider the special case in which the initial configuration is pX for\nsome p \u2208 P, X \u2208 \u0393, and the observing automaton A has one single state. In this case, the\n(n)\nautomaton always makes the same observation, and so we can write VpX = qY instead of\n(2)\n\n(n)\n\nVpX = (qY, a). We wish to obtain an expression for P(VpX =qY ). By the second part of\nLemma 5.12 we have\n(1)\nP(VpX =pX) = P(IRun(pX))\nand therefore\n(1)\n(2)\n(2)\nP(VpX =qY ) = P(VpX =qY | VpX =pX) * P(IRun(pX))\nNow we can apply equation 5.3 in the proof of Lemma 5.10 and obtain\n(2)\n\nand, by Equation 5.2\n(2)\n\nP(VpX =qY ) =\n\nP(VpX =qY ) = P(IRun(qY )) * S\nX\nx\n\npX \u2192qY\n\nx * P(IRun(qY ))\n\n+\n\nX\n\nx * P(IRun(qY ))\n\nX\n\nx * P(rZ, (Q \u00d7 \u0393\u2217 ) U {q\u03b5}) * P(IRun(qY ))\n\nx\n\npX \u2192qY Z\nZ\u2208\u0393\n\nx\n\npX \u2192rZY\nr\u2208Q,Z\u2208\u0393\n\n+\n\n(5.5)\n\nLet us interpret this equation. In order to reach the second minimum at qY there are\nonly three possibilities for the first move. The first possibility is to move directly from pX\nto qY ; in this case we must continue with any run that never terminates, since every infinite\nrun of the form pX; qY ; * * * necessarily has qY as second minimum. The probability of this\ncase is captured by the first summand of Equation 5.5. The second possibility is to move\n\n\f24\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nfrom pX to qY Z for some Z \u2208 \u0393; in this case we must continue with an infinite run in\nwhich the stack content always has at least length 2, i.e., with a run of the form\npX; qY Z; q1 \u03b11 Z; . . . ; qi \u03b1i Z; . . .\nwhere all the \u03b1's are nonempty. This gives the second summand. Finally, the third possibility is to move from pX to rZY for some r \u2208 P, Z \u2208 \u0393; we must then continue with a run\nthat eventually \"pops the Z\" while entering state q, i.e., with a run of the form\npX; rZY ; r1 \u03b11 Y ; . . . ; rn \u03b1n Y ; qY ; q1 \u03b21 ; . . . ; qi \u03b2i ; . . .\nwhere all the \u03b1's and \u03b2's are nonempty. This gives the third summand.\n\n2\n\nLemma 5.11 and 5.12 allow us to define the finite Markov chain M\u2206 .\nDefinition 5.14. The finite-state Markov chain M\u2206 has the following set of states\n(1)\n\n{(qY, a) | qY \u2208 H(\u2206), a \u2208 A, P(VqY =(qY, a0 )) > 0} \u222a H(\u2206) \u222a {\u22a5}\n\nand the following transition probabilities:\n\n\u2022 Prob(\u22a5 \u2192 \u22a5) = 1,\n(1)\n\u2022 Prob(pX \u2192 (qY, a0 )) = P(VpX =(qY, a0 )),\n(1)\n\n\u2022 Prob(pX \u2192 \u22a5) = P(VpX =\u22a5),\n\n(2)\n\n(1)\n\n\u2022 Prob((qY, a) \u2192 (q \u2032 Y \u2032 , a\u2032 )) = P(VqY =(q \u2032 Y \u2032 , a\u2032 ) | VqY =(qY, a0 )).\nOne can readily check that M\u2206 is indeed a Markov chain, i.e., for every state s of M\u2206\nwe have that the sum of probabilities of all outgoing transitions of s is equal to one. Observe\nalso that if both (qY, a) and (qY, a\u2032 ) are states of M\u2206 , then they have the \"same\" outgoing\nx\nx\narcs (i.e., (qY, a) \u2192 (rZ, \u0101) iff (qY, a\u2032 ) \u2192 (rZ, \u0101), where x > 0).\nExample 5.15. We construct the Markov Chain M\u2206 for the pBPA \u2206 of Figure 1 and\nthe observing automaton A of Figure 4. In fact, as we shall see, the states and transition\nprobabilities of the chain depend on the value of the parameter x.\nSince the pBPA has one single control state, we omit it. The set of heads is then\nH(\u2206) = {Z, I, D} and the set of states of the observing automaton is A = {a0 , a1 }. In\norder to determine the states of the Markov chain we have to compute the pairs (Y, a) such\n(1)\n(1)\nthat P(VY = (Y, a)) \u2265 0. Recall the definition of P(VY = (Y, a)). This is the probability\nof, starting at the configuration Y , executing an infinite run such that (i) the head of the\nfirst minimum is Y , and (ii) the first observation of A is the state a. Since the initial\nconfiguration Y has the shortest possible length in an infinite run, (i) always holds. So\n(1)\nP(VY = (Y, a)) is the probability of executing an infinite run such that (ii) holds. Recall\nthat the first observation of an observing automaton is the state it reaches after reading\nthe sequence of heads between the first and the second minimum, excluding the first, but\nincluding the second. In the case of the automaton A of Figure 4, the first observation is\na0 if the sequence of heads does not contain the head Z, and a1 otherwise.\n(1)\nThe values of P(VX = (X, a)) for X \u2208 {Z, I, D} and a \u2208 {a0 , a1 } are as follows:\n(1)\n\nP(VX\n\n\uf8f1\nmin{2x, 2 \u2212 2x}\n\uf8f4\n\uf8f4\n\uf8f2\nmax{0, (2x \u2212 1)/x}\n= (X, a)) =\nmax{0, (1 \u2212 2x)/(1 \u2212 x)}\n\uf8f4\n\uf8f4\n\uf8f3\n0\n\nif X = Z and a = a1\nif X = I and a = a0\nif X = D and a = a0\notherwise\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n25\n\nThese values can be obtained using the definitions, but in this simple case we can also\n(1)\nuse more direct methods. Consider for instance P(VZ = (Z, a1 )). This is the probability\nof, starting at Z, executing an infinite run and visiting again a configuration with head Z\nbefore reaching the second minimum. Observe that all runs that start at Z are infinite, that\nthe only configuration they visit with head Z is Z itself, and that Z is always a minimum. So\n(1)\nP(VZ = (Z, a1 )) is the probability of, starting at the configuration Z, eventually reaching\nZ again. This probability is equal to x * [I, \u03b5] + (1 \u2212 x) * [D, \u03b5], where [I, \u03b5] and [D, \u03b5] are\ndefined in Example 3.6. We get\n(1)\n\nP(VZ\n\n= (Z, a1 )) = x * [I, \u03b5] + (1 \u2212 x) * [D, \u03b5]\n= x * min{1, (1 \u2212 x)/x} + (1 \u2212 x) * min{1, x/(1 \u2212 x)}\n= min{2x, 2 \u2212 2x}\n\nObserve that the states of M\u2206 depend on x. The states are \u22a5, Z, I, D and\n(D, a0 )\nif x = 0,\n(Z, a1 ), (D, a0 ) if 0 < x < 1/2,\n(Z, a1 )\nif x = 1/2,\n(Z, a1 ), (I, a0 ) if 1/2 < x < 1,\n(I, a0 )\nif x = 1.\nThe Markov chain for the cases x = 1/2 and 1/2 < x < 1 are shown in Figure 5.\n2\u22122x\n1\n\nZ\n1\n\n\u001f\u001f\n\n1\n\n\u22a5 ggOoo OO\n\nOOO\n1 O\n\nI\nD\n\n1\n\n2\u22122x\n\nZ GG\nGG\n\n\u007f\u007f\n// (Z, a1 )\n\n\u007f\u007f\n// (Z, a1 )\n\nGG\nGG\nGG 2x\u22121\n## \u000f\u000f\n// (Z, a0 )\n__\n2x\u22121\n\n2x\u22121\n\n1\n\n\u001f\u001f\n\n\u22a5 ooccGG\n\n1\u2212x\nx\n\nI\n\nx\n\nGG\nGG\nGG\n1 GGG\n\n1\n\nD\nFigure 5: The Markov chain M\u2206 for x = 1/2 (left) and for 1/2 < x < 1 (right)\nLet us obtain the transition probability from (I, a0 ) to itself in the case 1/2 < x < 1.\n(1)\n(2)\nAccording to Definition 5.14, the probability is equal to P(VI = (I, a0 ) | VI = (I, a0 )),\ni.e., to the probability of, assuming the first minimum has head I, reaching the second\nminimum at head I again, visiting no configuration with head Z in-between. Let us see\nthat this probability is 1. If the first minimum is I\u03b1 for some \u03b1 \u2208 {Z, I, D}\u2217 , then all\nsubsequent configurations of the run are of the form \u03b2\u03b1 for a nonempty \u03b2 (notice that we\nassume that the run is infinite, because finite runs have no minima). So \u03b2 must have head\nI and so, in particular, the next minimum will also have head I.\n2\nNot every run of \u2206 is \"represented\" in the Markov chain M\u2206 . Consider for instance the\ncase x = 1/2 and its corresponding chain M\u2206 on the left of Figure 5. Every configuration\nof the run Z; IZ; IIZ; IIIZ; . . . is a minimum, but its sequence of heads, i.e., ZI \u03c9 , does not\n\n\f26\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\ncorrespond to any path of M\u2206 . We show, however, that the \"not represented\" runs have\nprobability 0.\nA trajectory in M\u2206 is an infinite sequence \u03c3(0)\u03c3(1) * * * of states of M\u2206 , where for\nevery i \u2208 N0 , Prob(\u03c3(i) \u2192 \u03c3(i + 1)) > 0. To every run w \u2208 Run(pX) of \u2206 we associate its\nfootprint, denoted \u03c3w , which is an infinite sequence of states of M\u2206 defined as follows:\n\u2022 \u03c3w (0) = pX\n\u2022 if w is finite, then for every i \u2208 N we have \u03c3w (i) = \u22a5;\n\u2022 if w is infinite, then for every i \u2208 N we have \u03c3w (i) = (pi Xi , Obs i (w)), where pi Xi is the\nhead of mini (w).\nWe say that a given w \u2208 Run(pX) is good if \u03c3w is a trajectory in M\u2206 . Our next lemma\nreveals that almost all runs are good.\nLemma 5.16. Let pX \u2208 H(\u2206), and let Good be the subset of all good runs of Run(pX).\nThen P(Good) = 1.\n\nProof. Let Bad = Run(pX) r Good. Let Fail be the set of all finite sequences v0 * * * vi+1 of\nstates of M\u2206 such that i \u2208 N0 , v0 = pX, v0 * * * vi is a trajectory in M\u2206 , and Prob(vi \u2192\nvi+1 ) = 0, where Prob is the probability assignment of M\u2206 . UEach y \u2208 Fail determines a\nset Bady = {w \u2208 Bad | \u03c3w starts with y}. Obviously, Bad = y\u2208Fail Bady . We prove that\nP(Bady ) = 0 for each y \u2208 Fail. Let y = v0 * * * vi+1 . By applying definitions, we obtain\nP(Bady ) =\n\n(1)\n\n(i+1)\n\nP(VpX =v1 \u2227 * * * \u2227 VpX\n(i+1)\n\n=\n(i)\n\n(1)\n\nP(VpX\n\n=vi+1 )\n\n(i)\n\n(1)\n\n=vi+1 | VpX =vi \u2227 * * * \u2227 VpX =v1 )\n(i)\n\n(1)\n\nP(VpX =vi \u2227 * * * \u2227 VpX =v1 )\n\nSince P(VpX =vi \u2227 * * * \u2227 VpX =v1 ) 6= 0, the last fraction makes sense and it is equal to\nProb(vi \u2192 vi+1 )\n\nwhich equals zero.\n\n(i)\nP(VpX =vi\n\n(1)\n\n\u2227 * * * \u2227 VpX =v1 )\n\n5.3. P(Run(pX, Acc)) is effectively definable in (R, +, \u2217, \u2264).\nRecall that our aim is\nto show that P(Run(pX, Acc)) is effectively definable in (R, +, \u2217, \u2264). We will achieve this\nin Theorem 5.22 as an easy corollary of Lemma 5.20. This lemma states that P(pX, Acc)\nis the probability of, starting at pX, hitting so-called accepting bottom strongly connected\ncomponent of M\u2206 . As usual, a strongly connected component of M\u2206 is a maximal set\nof mutually reachable states, and bottom strongly connected components are those from\nwhich no other strongly connected components can be reached.\nDefinition 5.17. Let C be a bottom strongly connected component of M\u2206 . We say that\nC is accepting if C 6= {\u22a5} and the set {a \u2208 A | (qY, a) \u2208 C for some qY \u2208 H(\u2206)} is an\nelement of Acc (remember that Acc is the acceptance set introduced after Definition 5.4).\nOtherwise, C is rejecting.\nWe say that a given pair (qY, a), where qY \u2208 H(\u2206) and a \u2208 A, is recurrent, if it belongs\nto some bottom strongly connected component of M\u2206 .\nWe say that a run w \u2208 Run(pX) hits a pair (qY, a) \u2208 H(\u2206)\u00d7A if there is some i \u2208 N\nsuch that the head of mini (w) is qY and Obs i (w) = a. The next lemma says that an infinite\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n27\n\nrun eventually hits a recurrent pair. In this lemma and the next we use the following wellknown results for finite Markov chains (see e.g. [Fel66]):\n\u2022 A run visits some bottom strongly connected component of the chain with probability 1.\n\u2022 If a run visits some state of a bottom strongly connected component C, then it visits all\nstates of C infinitely often with probability 1.\nLemma 5.18. Let us assume that P(IRun(pX)) > 0. Then the conditional probability that\nw \u2208 Run(pX) hits a recurrent pair on the hypothesis that w is infinite is equal to one.\nProof. Let Rec denote the event that a run of Run(pX) hits a recurrent pair. Due to\nLemma 5.16, we have that\nP(Rec | IRun(pX)) = P(Rec | IRun(pX) \u2229 Good)\n\n(5.6)\n\nA run belongs to IRun(pX) \u2229 Good iff its footprint is a trajectory in M\u2206 that does not\nhit the state \u22a5. A run w \u2208 IRun(pX) \u2229 Good satisfies Rec iff its footprint hits (some)\nrecurrent pair (qY, a). It follows directly from the definition of M\u2206 that the right-hand side\nof equation (5.6) is equal to the probability that a trajectory from pX in M\u2206 hits a bottom\nstrongly connected component on the hypothesis that the state \u22a5 is not visited. Since M\u2206\nis finite, this happens with probability one.\nSo, an infinite run eventually hits a recurrent pair. Now we prove that if this pair\nbelongs to an accepting/rejecting bottom strongly connected component of M\u2206 , then the\nrun will be accepting/rejecting with probability one.\nLemma 5.19. The conditional probability that w \u2208 Run(pX) is accepting/rejecting on the\nhypothesis that the first recurrent pair hit by w belongs to an accepting/rejecting bottom\nstrongly connected component of M\u2206 is equal to one.\nProof. The argument is similar as in the proof of Lemma 5.18. Let C be a bottom strongly\nconnected component of M\u2206 . By ergodicity, the conditional probability that an infinite\ntrajectory in M\u2206 hits each state of C infinitely often on the hypothesis that the trajectory\nhits C is equal to one.\nA simple consequence of Lemma 5.19 is:\nLemma 5.20. (cf. Proposition 4.1.5 of [CY95]) Let pX \u2208 H(\u2206). P(pX, Acc) is equal to\nthe probability that a trajectory from pX in M\u2206 hits an accepting bottom strongly connected\ncomponent of M\u2206 .\nExample 5.21. Consider the pBPA of Figure 1 and the observing automaton of Figure 4.\nP(Z, Acc) is the probability of, starting at Z, executing a run that visits configurations with\nhead Z infinitely often. In the case x = 1/2, the bottom strongly connected components\nof M\u2206 are {\u22a5} and {(Z, a1 )}, which are rejecting and accepting, respectively. Starting at\nthe state Z of M\u2206 , the probability of hitting {(Z, a1 )} is 1, and so P(Z, Acc) = 1. In the\ncase 1/2 < x < 1, the bottom strongly connected components of M\u2206 are {\u22a5} and {(I, a0 )},\nwhich are both rejecting, and so P(Z, Acc) = 0.\nSince the probability of hitting a given bottom strongly connected component of a given\nfinite-state Markov chain is effectively definable in (R, +, \u2217, \u2264) by the results of Section 3,\nand the transition probabilities in M\u2206 are well-definable too, we can conclude the following:\n\n\f28\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nTheorem 5.22. P(Run(pX, Acc)) is effectively expressible in (R, +, \u2217, \u2264). In particular,\nfor every rational constant y and every \u223c \u2208 {\u2264, <, \u2265, >, =} there effectively exists a formula\nof (R, +, \u2217, \u2264) which holds iff P(Run(pX, Acc)) \u223c y.\n5.4. Decidability of \u03c9-regular properties.\nAs a simple corollary of Theorem 5.22, we\nobtain the decidability of the qualitative/quantitative model-checking problem for pPDA\nand \u03c9-regular properties. Recall that a language of infinite words over a finite alphabet is\n\u03c9-regular iff it can be accepted by a (deterministic) Muller automaton.\nDefinition 5.23. A deterministic Muller automaton is a tuple B = (\u03a3, B, \u033a, bI , F), where\n\u03a3 is a finite alphabet, B is a finite set of states, \u033a : B \u00d7 \u03a3 \u2192 B is a (total) transition function\na\n(we write b \u2192 b\u2032 instead of \u033a(b, a) = b\u2032 ), bI is the initial state, and F \u2286 2B is a set of\naccepting sets.\nAn infinite word w over the alphabet \u03a3 is accepted by B if Inf (w) \u2208 F, where Inf (w)\nis the set of all b \u2208 B that appear infinitely often in the unique run of B over the word w.\nWe consider specifications given by Muller automata having H(\u2206) as their alphabet. It\nis well known that every LTL formula whose atomic propositions are interpreted over simple\nsets can be encoded into a deterministic Muller automaton having H(\u2206) as alphabet. Our\nresults can be extended to atomic propositions interpreted over arbitrary regular sets of\nconfigurations using the same technique as in [EKS03].\nLet us fix a deterministic Muller automaton B = (H(\u2206), B, \u033a, bI , F). An infinite run w\nof T\u2206 is accepted by B if the associated sequence of heads of configurations in w is accepted\nby B. Let Run(pX, B) be the set of all w \u2208 Run(pX) that are accepted by B. We show\nthat Run(pX, B) is effectively expressible in (R, +, \u2217, \u2264), and so we can decide if it is larger\nthan, smaller than, or equal to some threshold \u03c1.\nLoosely speaking, we proceed as follows. We compute the synchronized product \u2206\u2032 of\n\u2206 and B. Then, we define a \u2206\u2032 -observing automaton A whose states are sets of states of\nB. The automaton observes heads of \u2206\u2032 , which are of the form (p, b)X, where pX is a\nhead of \u2206 and b is a state of b. At the end of a \"jump\", A returns the set of states of B\nthat were visited during the jump. Hence, the observation Obs(w) of the automaton on a\nrun w is a sequence B1 B2 . . . of sets of states of B containing full information about which\nstates were visited in which jump. Now it is just a matter of setting the acceptance set of\nA adequately: The acceptance sets of A are the sets {b1 , . . . , bn } of states of A such that\nthe union b1 \u222a . . . \u222a bn is an element of F.\nTheorem 5.24. P(Run(pX, B)) is effectively expressible in (R, +, \u2217, \u2264). In particular, for\nevery rational constant y and every \u223c \u2208 {\u2264, <, \u2265, >, =} there effectively exists a formula\nof (R, +, \u2217, \u2264) which holds iff P(Run(pX, B)) \u223c y. (Hence, for each 0 < \u03bb < 1 we can\ncompute rationals P l , P u such that P l \u2264 P(pX, Acc) \u2264 P u and P u \u2212 P l \u2264 \u03bb.)\nx\n\nProof. Let \u2206\u2032 = (Q\u00d7B, \u0393, \u03b4\u2032 , Prob \u2032 ) be the synchronized product of \u2206 and B, i.e., (p, b)X \u2192\nx\n(t, b\u2032 )\u03b1 is a rule of \u2206\u2032 iff pX \u2192 t\u03b1 is a rule of \u2206 and \u033a(b, pX) = b\u2032 . Consider the \u2206\u2032 observing automaton A = (A, \u03be, I, Acc) where A = 2B , a0 = \u2205, \u03be(M, (p, b)Y ) = M \u222a {b} for\nall M \u2286 B and (p, b)Y \u2208 H(\u2206\u2032 ), and Acc is defined as follows: for every a1 , . . . , an \u2208 2B ,\n{a1 , . . . , an } \u2208 Acc iff a1 \u222a . . . \u222a an \u2208 F.\nIt is easy to check that\nP(Run(pX, B)) = P(Run((p, bI )X, Acc))\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n29\n\nNow it suffices to apply Theorem 5.22.\n6. Conclusions\nWe have provided model checking algorithms for probabilistic pushdown automata\nagainst PCTL specifications, and against \u03c9-regular specifications represented by Muller\nautomata. Contrary to the case of probabilistic finite automata, qualitative properties (i.e.,\nwhether a property holds with probability 0 or 1), depend on the exact values of transition\nprobabilities.\nThere are many possibilities for future work. An obvious question is what is the complexity of the obtained algorithms. Of course, this depends on the complexity of the corresponding fragments of first order arithmetic of reals. It is known that the fragment obtained\nby fixing the alternation depth of quantifiers is decidable in exponential time [Gri88], and\nthat the existential fragment (and hence also the universal fragment) is decidable even in\npolynomial space [Can88]. The formulas constructed in Section 3 have a fixed alternation\ndepth, and so we can conclude that the qualitative/quantitative random walk problem is\ndecidable in exponential time. Actually, we can do even better-if we are interested whether\nP(pX, C1 U C2 ) \u2264 \u033a, we can simply ask if there is some solution of the corresponding system\nof quadratic equations (cf. Theorem 3.5) such that the component of the solution which\ncorresponds to P(pX, C1 U C2 ) is less than or equal to \u033a. Obviously, the minimal solution\n(i.e., the probability of P(pX, C1 U C2 )) can only be smaller. Hence, the existential fragment is sufficient for deciding whether P(pX, C1 U C2 ) \u2264 \u033a, and similarly we can use the\nuniversal fragment to decide whether P(pX, C1 U C2 ) \u2265 \u033a. To sum up, the problem whether\nP(pX, C1 U C2 ) \u223c \u033a, where \u223c \u2208 {<, \u2264, >, \u2265, =}, is decidable in polynomial space.\nRecently, deeper results concerning the complexity of the reachability problem for pPDA\nand pBPA have been presented by Etessami and Yannakakis in [EY05]. In particular, they\nshow that the qualitative reachability problem for pBPA processes (i.e., the question whether\na given configuration is visited with probability 1) is decidable in polynomial\nIt is also\nP time.\n\u221a\nshown that the Square-Root-Sum problem (i.e., the question whether ni=1 ai \u2264 c for a\ngiven tuple (a1 , . . . , an , c) of natural numbers) is polynomially reducible to the quantitative\nreachability problem for pBPA, and to the qualitative reachability problem for pPDA. The\ncomplexity of the Square-Root-Sum problem is a famous open problem in the area of\nexact numerical algorithms. It is known that the problem is solvable in polynomial space,\nbut no lower bound (like NP or co-NP hardness) is known. This means that the PSPACE\nupper bound for the quantitative pBPA reachability and the qualitative pPDA reachability\ncannot be improved without achieving an improvement in the complexity of the SquareRoot-Sum problem.\nSome of the problems which were left open in [EKM04] were solved later in [BKS05].\nIt was shown that the model-checking problems for PCTL and pPDA, and for PCTL\u2217\nand pBPA, are undecidable (PCTL\u2217 is the probabilistic extension of CTL\u2217 ). On the other\nhand, the decidability result about qualitative/quantitative model-checking pPDA against\ndeterministic B\u00fcchi specifications was extended to Muller automata. In the qualitative case,\nthe algorithm runs in time which is singly exponential in the size of a given pPDA and a\ngiven Muller automaton. In the quantitative case, the algorithm needs exponential space.\nFinally, it was shown that the model-checking problem for the qualitative fragment of the\nlogic PECTL\u2217 and pPDA processes is also decidable. The complexity bounds are essentially\nthe same as for Muller properties.\n\n\f30\n\nJ. ESPARZA, A. KU\u010cERA, AND R. MAYR\n\nThe complexity of model-checking \u03c9-regular properties (encoded by B\u00fcchi automata)\nfor pPDA and pBPA processes was studied also in [EY]. The complexity bounds improve\nthe ones given in [BKS05]. In particular, it is shown that the qualitative model-checking\nproblem for pPDA and B\u00fcchi specifications is EXPTIME-complete.\nAn interesting open problem is the decidability of the model-checking problem for\nPCTL and pBPA processes, i.e., whether there is an \"exact\" algorithm apart from the\nerror-tolerant one given in Section 4.2. Another area of open problems is generated by\nconsidering model-checking problems for a more general class of pushdown automata whose\nunderlying semantics is defined in terms of Markov decision processes (this model combines\nthe paradigms of non-deterministic and probabilistic choice).\n7. Acknowledgments\nThe authors would like to thank Stefan Schwoon and two anonymous referees for many\nhelpful insights and comments.\nReferences\n[ABIJ05] P.A. Abdulla, C. Baier, S.P. Iyer, and B. Jonsson. Simulating perfect channels with probabilistic\nchannel systems. Information and Computation, 197(1\u20132):22\u201340, 2005.\n[AEY01] R. Alur, K. Etessami, and M. Yannakakis. Analysis of recursive state machines. In Proceedings of\nCAV 2001, volume 2102 of Lecture Notes in Computer Science, pages 207\u2013220. Springer, 2001.\n[AMP99] A. Abney, D. McAllester, and F. Pereira. Relating probabilistic grammars and automata. In\nProceedings of ACP'99, pages 542\u2013549, 1999.\n[AR03]\nP.A. Abdulla and A. Rabinovich. Verification of probabilistic systems with faulty communication.\nIn Proceedings of FoSSaCS 2003, volume 2620 of Lecture Notes in Computer Science, pages 39\u201353.\nSpringer, 2003.\n[ASB+ 95] A. Aziz, V. Singhal, F. Balarin, R. Brayton, and A. Sangiovanni-Vincentelli. It usually works:\nThe temporal logic of stochastic systems. In Proceedings of CAV'95, volume 939 of Lecture Notes\nin Computer Science, pages 155\u2013165. Springer, 1995.\n[BE99]\nC. Baier and B. Engelen. Establishing qualitative properties for probabilistic lossy channel systems: an algorithmic approach. In Proceedings of 5th International AMAST Workshop on RealTime and Probabilistic Systems (ARTS'99), volume 1601 of Lecture Notes in Computer Science,\npages 34\u201352. Springer, 1999.\n[BEM97] A. Bouajjani, J. Esparza, and O. Maler. Reachability analysis of pushdown automata: application\nto model checking. In Proceedings of CONCUR'97, volume 1243 of Lecture Notes in Computer\nScience, pages 135\u2013150. Springer, 1997.\n[BKS05] T. Br\u00e1zdil, A. Ku\u010dera, and O. Stra\u017eovsk\u00fd. On the decidability of temporal properties of probabilistic pushdown automata. In Proceedings of STACS'2005, volume 3404 of Lecture Notes in\nComputer Science, pages 145\u2013157. Springer, 2005.\n[BS97]\nO. Burkart and B. Steffen. Model checking the full modal mu-calculus for infinite sequential\nprocesses. In Proceedings of ICALP'97, volume 1256 of Lecture Notes in Computer Science, pages\n419\u2013429. Springer, 1997.\n[BS03]\nN. Bertrand and Ph. Schnoebelen. Model checking lossy channel systems is probably decidable. In\nProceedings of FoSSaCS 2003, volume 2620 of Lecture Notes in Computer Science, pages 120\u2013135.\nSpringer, 2003.\n[BW90] J.C.M. Baeten and W.P. Weijland. Process Algebra. Number 18 in Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, 1990.\n[Can88] J. Canny. Some algebraic and geometric computations in PSPACE. In Proceedings of STOC'88,\npages 460\u2013467. ACM Press, 1988.\n[CSS03] J.M. Couvreur, N. Saheb, and G. Sutre. An optimal automata approach to LTL model checking\nof probabilistic systems. In Proceedings of LPAR 2003, volume 2850 of Lecture Notes in Computer\nScience, pages 361\u2013375. Springer, 2003.\n\n\fMODEL CHECKING PROBABILISTIC PUSHDOWN AUTOMATA\n\n31\n\n[CY88]\n\nC. Courcoubetis and M. Yannakakis. Verifying temporal properties of finite-state probabilistic\nprograms. In Proceedings of FOCS'88, pages 338\u2013345. IEEE Computer Society Press, 1988.\n[CY95]\nC. Courcoubetis and M. Yannakakis. The complexity of probabilistic verification. Journal of the\nAssociation for Computing Machinery, 42(4):857\u2013907, 1995.\n[EHRS00] J. Esparza, D. Hansel, P. Rossmanith, and S. Schwoon. Efficient algorithms for model checking\npushdown systems. In Proceedings of CAV 2000, volume 1855 of Lecture Notes in Computer\nScience, pages 232\u2013247. Springer, 2000.\n[EKM04] J. Esparza, A. Ku\u010dera, and R. Mayr. Model-checking probabilistic pushdown automata. In Proceedings of LICS 2004, pages 12\u201321. IEEE Computer Society Press, 2004.\n[EKS03] J. Esparza, A. Ku\u010dera, and S. Schwoon. Model-checking LTL with regular valuations for pushdown\nsystems. Information and Computation, 186(2):355\u2013376, 2003.\n[EY]\nK. Etessami and M. Yannakakis. Algorithmic verification of recursive probabilistic systems. Technical Report, School of Informatics, U. of Edinburgh, 2005.\n[EY05]\nK. Etessami and M. Yannakakis. Recursive Markov chains, stochastic grammars, and monotone\nsystems of non-linear equations. In Proceedings of STACS'2005, volume 3404 of Lecture Notes in\nComputer Science, pages 340\u2013352. Springer, 2005.\n[Fel66]\nW. Feller. An Introduction to Probability Theory and Its Applications. Wiley & Sons, 1966.\n[Gri88]\nD. Grigoriev. Complexity of deciding Tarski algebra. Journal of Symbolic Computation, 5(1\u20132):65\u2013\n108, 1988.\n[HJ94]\nH. Hansson and B. Jonsson. A logic for reasoning about time and reliability. Formal Aspects of\nComputing, 6:512\u2013535, 1994.\n[HK97]\nM. Huth and M.Z. Kwiatkowska. Quantitative analysis and model checking. In Proceedings of\nLICS'97, pages 111\u2013122. IEEE Computer Society Press, 1997.\n[HS84]\nS. Hart and M. Sharir. Probabilistic temporal logic for finite and bounded models. In Proceedings\nof POPL'84, pages 1\u201313. ACM Press, 1984.\n[IN97]\nS.P. Iyer and M. Narasimha. Probabilistic lossy channel systems. In Proceedings of TAPSOFT'97,\nvolume 1214 of Lecture Notes in Computer Science, pages 667\u2013681. Springer, 1997.\n[LS82]\nD. Lehman and S. Shelah. Reasoning with time and chance. Information and Control, 53:165\u2013198,\n1982.\n[MO98]\nI. Macarie and M. Ogihara. Properties of probabilistic pushdown automata. Theoretical Computer\nScience, 207:117\u2013130, 1998.\n[Rab03] A. Rabinovich. Quantitative analysis of probabilistic lossy channel systems. In Proceedings of\nICALP 2003, volume 2719 of Lecture Notes in Computer Science, pages 1008\u20131021. Springer,\n2003.\n[Tar51]\nA. Tarski. A Decision Method for Elementary Algebra and Geometry. Univ. of California Press,\nBerkeley, 1951.\n[Var85]\nM. Vardi. Automatic verification of probabilistic concurrent finite-state programs. In Proceedings\nof FOCS'85, pages 327\u2013338. IEEE Computer Society Press, 1985.\n[Wal01]\nI. Walukiewicz. Pushdown processes: Games and model-checking. Information and Computation,\n164(2):234\u2013263, 2001.\n\nThis work is licensed under the Creative Commons Attribution-NoDerivs License. To view\na copy of this license, visit http://creativecommons.org/licenses/by-nd/2.0/ or send a\nletter to Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305, USA.\n\n\f"}