{"id": "http://arxiv.org/abs/cs/0405065v1", "guidislink": true, "updated": "2004-05-18T16:55:00Z", "updated_parsed": [2004, 5, 18, 16, 55, 0, 1, 139, 0], "published": "2004-05-18T16:55:00Z", "published_parsed": [2004, 5, 18, 16, 55, 0, 1, 139, 0], "title": "Efficiency Enhancement of Genetic Algorithms via Building-Block-Wise\n  Fitness Estimation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0405012%2Ccs%2F0405025%2Ccs%2F0405109%2Ccs%2F0405049%2Ccs%2F0405024%2Ccs%2F0405089%2Ccs%2F0405082%2Ccs%2F0405110%2Ccs%2F0405019%2Ccs%2F0405006%2Ccs%2F0405016%2Ccs%2F0405073%2Ccs%2F0405005%2Ccs%2F0405052%2Ccs%2F0405031%2Ccs%2F0405030%2Ccs%2F0405077%2Ccs%2F0405068%2Ccs%2F0405090%2Ccs%2F0405053%2Ccs%2F0405083%2Ccs%2F0405057%2Ccs%2F0405003%2Ccs%2F0405086%2Ccs%2F0405020%2Ccs%2F0405035%2Ccs%2F0405038%2Ccs%2F0405039%2Ccs%2F0405071%2Ccs%2F0405096%2Ccs%2F0405092%2Ccs%2F0405098%2Ccs%2F0405013%2Ccs%2F0405087%2Ccs%2F0405066%2Ccs%2F0405051%2Ccs%2F0405014%2Ccs%2F0405094%2Ccs%2F0405075%2Ccs%2F0405065%2Ccs%2F0405085%2Ccs%2F0405032%2Ccs%2F0405034%2Ccs%2F0405070%2Ccs%2F0405002%2Ccs%2F0405050%2Ccs%2F0405105%2Ccs%2F0405026%2Ccs%2F0405022%2Ccs%2F0405058%2Ccs%2F0405007%2Ccs%2F0405048%2Ccs%2F0405043%2Ccs%2F0405008%2Ccs%2F0405010%2Ccs%2F0405055%2Ccs%2F0405045%2Ccs%2F0505054%2Ccs%2F0505021%2Ccs%2F0505088%2Ccs%2F0505016%2Ccs%2F0505057%2Ccs%2F0505042%2Ccs%2F0505063%2Ccs%2F0505037%2Ccs%2F0505052%2Ccs%2F0505036%2Ccs%2F0505001%2Ccs%2F0505039%2Ccs%2F0505007%2Ccs%2F0505022%2Ccs%2F0505006%2Ccs%2F0505004%2Ccs%2F0505012%2Ccs%2F0505081%2Ccs%2F0505051%2Ccs%2F0505079%2Ccs%2F0505076%2Ccs%2F0505031%2Ccs%2F0505038%2Ccs%2F0505048%2Ccs%2F0505030%2Ccs%2F0505055%2Ccs%2F0505062%2Ccs%2F0505015%2Ccs%2F0505083%2Ccs%2F0505047%2Ccs%2F0505087%2Ccs%2F0505085%2Ccs%2F0505049%2Ccs%2F0505058%2Ccs%2F0505023%2Ccs%2F0505034%2Ccs%2F0505073%2Ccs%2F0505017%2Ccs%2F0505009%2Ccs%2F0505026%2Ccs%2F0505044%2Ccs%2F0505003%2Ccs%2F0505061%2Ccs%2F0505045&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Efficiency Enhancement of Genetic Algorithms via Building-Block-Wise\n  Fitness Estimation"}, "summary": "This paper studies fitness inheritance as an efficiency enhancement technique\nfor a class of competent genetic algorithms called estimation distribution\nalgorithms. Probabilistic models of important sub-solutions are developed to\nestimate the fitness of a proportion of individuals in the population, thereby\navoiding computationally expensive function evaluations. The effect of fitness\ninheritance on the convergence time and population sizing are modeled and the\nspeed-up obtained through inheritance is predicted. The results show that a\nfitness-inheritance mechanism which utilizes information on building-block\nfitnesses provides significant efficiency enhancement. For additively separable\nproblems, fitness inheritance reduces the number of function evaluations to\nabout half and yields a speed-up of about 1.75--2.25.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0405012%2Ccs%2F0405025%2Ccs%2F0405109%2Ccs%2F0405049%2Ccs%2F0405024%2Ccs%2F0405089%2Ccs%2F0405082%2Ccs%2F0405110%2Ccs%2F0405019%2Ccs%2F0405006%2Ccs%2F0405016%2Ccs%2F0405073%2Ccs%2F0405005%2Ccs%2F0405052%2Ccs%2F0405031%2Ccs%2F0405030%2Ccs%2F0405077%2Ccs%2F0405068%2Ccs%2F0405090%2Ccs%2F0405053%2Ccs%2F0405083%2Ccs%2F0405057%2Ccs%2F0405003%2Ccs%2F0405086%2Ccs%2F0405020%2Ccs%2F0405035%2Ccs%2F0405038%2Ccs%2F0405039%2Ccs%2F0405071%2Ccs%2F0405096%2Ccs%2F0405092%2Ccs%2F0405098%2Ccs%2F0405013%2Ccs%2F0405087%2Ccs%2F0405066%2Ccs%2F0405051%2Ccs%2F0405014%2Ccs%2F0405094%2Ccs%2F0405075%2Ccs%2F0405065%2Ccs%2F0405085%2Ccs%2F0405032%2Ccs%2F0405034%2Ccs%2F0405070%2Ccs%2F0405002%2Ccs%2F0405050%2Ccs%2F0405105%2Ccs%2F0405026%2Ccs%2F0405022%2Ccs%2F0405058%2Ccs%2F0405007%2Ccs%2F0405048%2Ccs%2F0405043%2Ccs%2F0405008%2Ccs%2F0405010%2Ccs%2F0405055%2Ccs%2F0405045%2Ccs%2F0505054%2Ccs%2F0505021%2Ccs%2F0505088%2Ccs%2F0505016%2Ccs%2F0505057%2Ccs%2F0505042%2Ccs%2F0505063%2Ccs%2F0505037%2Ccs%2F0505052%2Ccs%2F0505036%2Ccs%2F0505001%2Ccs%2F0505039%2Ccs%2F0505007%2Ccs%2F0505022%2Ccs%2F0505006%2Ccs%2F0505004%2Ccs%2F0505012%2Ccs%2F0505081%2Ccs%2F0505051%2Ccs%2F0505079%2Ccs%2F0505076%2Ccs%2F0505031%2Ccs%2F0505038%2Ccs%2F0505048%2Ccs%2F0505030%2Ccs%2F0505055%2Ccs%2F0505062%2Ccs%2F0505015%2Ccs%2F0505083%2Ccs%2F0505047%2Ccs%2F0505087%2Ccs%2F0505085%2Ccs%2F0505049%2Ccs%2F0505058%2Ccs%2F0505023%2Ccs%2F0505034%2Ccs%2F0505073%2Ccs%2F0505017%2Ccs%2F0505009%2Ccs%2F0505026%2Ccs%2F0505044%2Ccs%2F0505003%2Ccs%2F0505061%2Ccs%2F0505045&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper studies fitness inheritance as an efficiency enhancement technique\nfor a class of competent genetic algorithms called estimation distribution\nalgorithms. Probabilistic models of important sub-solutions are developed to\nestimate the fitness of a proportion of individuals in the population, thereby\navoiding computationally expensive function evaluations. The effect of fitness\ninheritance on the convergence time and population sizing are modeled and the\nspeed-up obtained through inheritance is predicted. The results show that a\nfitness-inheritance mechanism which utilizes information on building-block\nfitnesses provides significant efficiency enhancement. For additively separable\nproblems, fitness inheritance reduces the number of function evaluations to\nabout half and yields a speed-up of about 1.75--2.25."}, "authors": ["Kumara Sastry", "Martin Pelikan", "David E. Goldberg"], "author_detail": {"name": "David E. Goldberg"}, "author": "David E. Goldberg", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/CEC.2004.1330930", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cs/0405065v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0405065v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "IEEE International Conference on Evolutionary Computation (CEC-2004)", "arxiv_primary_category": {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "G.1.6; G.3; I.2.6; I.2.8", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0405065v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0405065v1", "journal_reference": null, "doi": "10.1109/CEC.2004.1330930", "fulltext": "arXiv:cs/0405065v1 [cs.NE] 18 May 2004\n\nEfficiency Enhancement of Genetic Algorithms\nvia Building-Block-Wise Fitness Estimation\n\nKumara Sastry\nMartin Pelikan\nDavid E. Goldberg\n\nIlliGAL Report No. 20040010\nFebruary, 2004\n\nIllinois Genetic Algorithms Laboratory (IlliGAL)\nDepartment of General Engineering\nUniversity of Illinois at Urbana-Champaign\n117 Transportation Building\n104 S. Mathews Avenue, Urbana, IL 61801\n\n\fEfficiency Enhancement of Genetic Algorithms\nvia Building-Block-Wise Fitness Estimation\nKumara Sastry\nIllinois Genetic Algorithms Laboratory (IlliGAL), and\nDepartment of Material Science & Engineering\nUniversity of Illinois at Urbana-Champaign\nksastry@uiuc.edu\nMartin Pelikan\nDepartment of Math & Computer Science\nUniversity of Missouri, St. Louis\nmpelikan@cs.umsl.edu\nDavid E. Goldberg\nIllinois Genetic Algorithms Laboratory (IlliGAL), and\nDepartment of General Engineering\nUniversity of Illinois at Urbana-Champaign\ndeg@uiuc.edu\n\nAbstract\nThis paper studies fitness inheritance as an efficiency enhancement technique for a class of\ncompetent genetic algorithms called estimation distribution algorithms. Probabilistic models of\nimportant sub-solutions are developed to estimate the fitness of a proportion of individuals in\nthe population, thereby avoiding computationally expensive function evaluations. The effect of\nfitness inheritance on the convergence time and population sizing are modeled and the speed-up\nobtained through inheritance is predicted. The results show that a fitness-inheritance mechanism\nwhich utilizes information on building-block fitnesses provides significant efficiency enhancement.\nFor additively separable problems, fitness inheritance reduces the number of function evaluations\nto about half and yields a speed-up of about 1.75\u20132.25.\n\n1\n\nIntroduction\n\nSince the inception of genetic and evolutionary algorithms (GEAs), significant advances have been\nmade in the theory, design and application to complex real-world problems. A decomposition\nmethodology has been proposed for a successful design of GEAs (Goldberg, 1991; Goldberg, Deb, & Clark, 1992;\nGoldberg, 2002). Based on the design-decomposition theory several competent GEAs-genetic\nalgorithms (GAs) that solve hard problems quickly, reliably, and accurately-have been proposed (Goldberg, 2002). Competent GEAs successfully solve boundedly difficult problems, oftentimes requiring polynomial-in terms of problem size-number of function evaluations. In\nessence, competent GEAs take problems that were intractable with first generation GAs, and\n1\n\n\frender them tractable. One such class of competent GAs is the probabilistic model-building GAs\n(PMBGAs) (Pelikan, Lobo, & Goldberg, 2002; Larra\u00f1aga & Lozano, 2002; Pelikan, 2002), wherein\na traditional crossover is replaced by a two step process: (1) Building of probabilistic models that identify important sub-solutions (or building blocks (BBs)). (2) Sampling the probabilistic models to efficiently mix the sub-solutions to create the offspring population. PMBGAs\nhave solved problems of bounded difficulty (both regular as well as hierarchical) requiring only\nquadratic number of function evaluations (Pelikan, 2002; Pelikan, Goldberg, & Cant\u00fa-Paz, 2000b;\nPelikan & Goldberg, 2001; Pelikan, Sastry, & Goldberg, 2003).\nHowever, for large-scale problems, especially if the fitness function is a complex simulation,\nmodel, or computation, the task of computing even subquadratic number of evaluations can be\ndaunting. This places a premium on a variety of efficiency-enhancement techniques (EETs).\nIn essence, while competence leads us from intractability to tractability, efficiency enhancement\ntakes us from tractability to practicality. Various EETs can be broadly classified into four broad\nclasses (Goldberg, 2002): parallelization, hybridization, time-utilization and evaluation relaxation.\nIn evaluation-relaxation schemes the computationally expensive, but accurate, fitness function is\nreplaced by a cheap, but approximate, fitness function, there by speeding-up the GA process.\nOne such evaluation-relaxation technique is fitness inheritance (Smith, Dike, & Stegmann, 1995;\nSastry, Goldberg, & Pelikan, 2001). In fitness inheritance, a certain proportion of the offspring\nderive their fitness values from parental fitnesses rather than through function evaluations.\nThis paper analyzes fitness inheritance in PMBGAs, specifically extended compact genetic\nalgorithm (eCGA) (Harik, 1999). In our study, the inherited fitness is derived and estimated from\nthe probabilistic model constructed by eCGA. The purpose of this paper is to model such an\ninheritance mechanism and predict the scalability, speed-up and the optimal inheritance parameter\nthat yields greatest speed-up. The approach used in this study is along the lines of those reported\nelsewhere for fitness inheritance in simple GAs (Sastry, Goldberg, & Pelikan, 2001). The analysis,\nin which the inherited fitness of an offspring was the average of its parental fitness values, predicted\nthat using inherited fitness for 50% of the offspring population yielded a maximum speed-up of\n30%. This was in contrast to a much more significant empirical speed-up observed by Smith, Dike,\nand Stegmann (Smith, Dike, & Stegmann, 1995). The purpose of this paper is also to investigate if\nan inheritance mechanism that incorporate knowledge of building block (or sub-solution) fitnesses\nwould provide greater speed up than a simple inheritance procedure.\nThis paper is organized as follows. The next section reviews the literature on fitness inheritance\nin GAs, followed by a brief description of extended compact genetic algorithm in Section 3. We\nderive facetwise models for convergence time and population sizing required for the successful design\nof eCGA with fitness inheritance in Section 4. Subsequently, we use the convergence-time and\npopulation-sizing models to predict the scalability and speed-up obtained via fitness inheritance.\nSection 6 discusses possible directions of future research, followed by conclusions.\n\n2\n\nLiterature Review\n\nSmith, Dike and Stegmann (Smith, Dike, & Stegmann, 1995) proposed fitness inheritance in GAs.\nThey proposed two ways of inheriting fitness, one by taking the average fitness and the other by\ntaking a weighted average of the fitness of the two parents. Their results indicated that GAs with\nfitness inheritance outperformed those without inheritance in both the OneMax and an aircraft\nrouting problem. However, they did not investigate the effect of fitness inheritance on convergence\n2\n\n\ftime, population sizing, and scalability of GAs. Though the original study showed very encouraging\nresults, unfortunately there have been very few follow up studies on fitness inheritance. Zheng,\nJulstrom, and Cheng (Zheng, Julstrom, & Cheng, 1997) used fitness inheritance for the design of\nvector quantization codebooks.\nSastry, Goldberg, and Pelikan (Sastry, Goldberg, & Pelikan, 2001) provided theoretical analysis of fitness inheritance in simple GAs, in which facetwise models for convergence time and\npopulation sizing were derived and utilized for predicting the scalability and speed-up obtained by\nusing fitness inheritance. The analysis predicted that an optimal speed-up of 30% can be achieved\nwhen 50% of the offspring population received inherited fitness. Chen, Goldberg, Ho, and Sastry\n(Chen, Goldberg, Ho, & Sastry, 2002) extended the analysis of fitness inheritance to multiobjective\nproblems and predicted that a speed-up of 25% can be achieved when 50-55% of the offspring population received inherited fitness. Ducheyne, De Baets, and De Wulf (Ducheyne, De Baets, & De Wulf, 2003)\nstudied the utility of fitness inheritance in convex and non-convex multiobjective problems. Pelikan and Sastry (Pelikan & Sastry, 2004) have proposed fitness inheritance for the efficiencyenhancement of Bayesian optimization algorithm.\n\n3\n\nExtended Compact Genetic Algorithm (eCGA)\n\nThe extended compact GA proposed by Harik (Harik, 1999) is based on a key idea that the choice\nof a good probability distribution is equivalent to linkage learning. The measure of a good distribution is quantified based on minimum description length (MDL) models. The key concept behind\nMDL models is that all things being equal, simpler distributions are better than more complex\nones. The MDL restriction penalizes both inaccurate and complex models, thereby leading to an\noptimal probability distribution. Thus, MDL restriction reformulates the problem of finding a\ngood distribution as an optimization problem that minimizes both the probability model as well\nas population representation. The probability distribution used in eCGA is a class of probability\nmodels known as marginal product models (MPMs). MPMs are formed as a product of marginal\ndistributions on a partition of the genes and are similar to those of the compact GA (CGA)\n(Harik, Lobo, & Goldberg, 1998) and PBIL (Baluja, 1994). Unlike the models used in CGA and\nPBIL, MPMs can represent probability distributions for more than one gene at a time. MPMs also\nfacilitate a direct linkage map with each partition separating tightly linked genes. For example,\nthe following MPM, [1,3][2][4], for a four-bit problem represents that the 1st and 3rd genes are\nlinked and 2nd and 4th genes are independent. Additionally, the MPM consists of the marginal\nprobabilities: {p(x1 = 0, x3 = 0), p(x1 = 0, x3 = 1), p(x1 = 1, x3 = 0), p(x1 = 1, x3 = 1), p(x2 = 0),\np(x2 = 1), p(x4 = 0), p(x4 = 1)}, where xi is the value of the ith gene.\nThe eCGA can be algorithmically outlined as follows:\n1. Initialization: The population is usually initialized with random individuals. However, other\ninitialization procedures can also be used.\n2. Evaluate the fitness value of the individuals\n3. Selection: The eCGA uses s-wise tournament selection (Goldberg, Korb, & Deb, 1989). However, other selection procedures can be used instead of tournament selection.\n4. Build the probabilistic model: In eCGA, both the structure and the parameters of the model\n3\n\n\fare searched. A greedy search heuristic is used to find an optimal model of the selected\nindividuals in the population.\n5. Create new individuals: In eCGA, new individuals are created by sampling the probabilistic\nmodel.\n6. Replace the parents with the offspring.\n7. Repeat steps 2\u20136 until some termination criteria are met.\nTwo things need further explanation, one is the identification of MPM using MDL and the other\nis the creation of a new population based on MPM. The identification of MPM is formulated as a\nconstrained optimization problem,\nMinimize\n\nCm + Cp\n\n(1)\n\n2ki \u2264 n \u2200i \u2208 [1, m].\n\n(2)\n\nSubject to\n\nwhere Cm is the model complexity which represents the cost of a complex model.In essence, the\nmodel complexity, Cm , quantifies the model representation size in terms of number of bits required\nto store all the marginal probabilities. Let, a given problem of size l with binary alphabets, have m\nP\npartitions with ki genes in the ith partition, such that m\ni=1 ki = l. Then each partition i requires\nk\n2 \u2212 1 independent frequencies to completely define its marginal distribution. Furthermore, each\nfrequency is of size log2 (n), where n is the population size. Therefore, the model complexity Cm ,\nis given by\nCm = log2 (n)\n\nm \u0010\nX\ni=1\n\n\u0011\n\n2ki \u2212 1 .\n\n(3)\n\nThe compressed population complexity, Cp , represents the cost of using a simple model as\nagainst a complex one. In essence, the compressed population complexity, Cp , quantifies the data\ncompression in terms of the entropy of the marginal distribution over all partitions. Therefore, Cp\nis evaluated as\nk\n\nCp = n\n\nm X\n2 i\nX\n\ni=1 j=1\n\n\u2212pij log2 (pij )\n\n(4)\n\nwhere pij is the frequency of the j th gene sequence of the genes belonging to the ith partition.\nIn other words, pij = Nij /n, where Nij is the number of chromosomes in the population (after\nselection) possessing bit-sequence j \u2208 [1, 2ki ] 1 for ith partition. The constraint (Equation 2) arises\ndue to finite population size.\nThe following greedy search heuristic is used to find an optimal or near-optimal probabilistic\nmodel:\n1. Assume each variable is independent of each other. The model is a vector of probabilities.\n2. Compute the model complexity and population complexity values of the current model.\n1\nNote that a BB of length k has 2k possible sequences where the first sequence denotes be 00* * *0 and the last\nsequence 11* * *1\n\n4\n\n\f3. Consider all possible 12 l(l \u2212 1) merges of two variables.\n4. Evaluate the model and compressed population complexity values for each model structure.\n5. Select the merged model with lowest combined complexity.\n6. If the combined complexity of the best merged model is better than the combined complexity\nof the model evaluated in step 2., replace it with the best merged model and go to step 2.\n7. If the combined complexity of the best merged model is less than or equal to the combined\ncomplexity, the model cannot be improved and the model of step 2. is the probabilistic model\nof the current generation.\nThe offspring population are generated by randomly choosing subsets from the current individuals\naccording to the probabilities of the subsets as calculated in the probabilistic model.\n\n4\n\nFitness Inheritance in eCGA\n\nThe previous section outlined the key steps and mechanisms of eCGA. In this section we discuss the\nenhancements and modifications made on eCGA to enable the incorporation of fitness inheritance.\nSimilar to earlier studies on fitness inheritance, all the individuals in the initial population\nare evaluated and subsequently a portion of the offspring population receives inherited fitness\nand the others receive actual fitness evaluation. That is, an offspring receives inherited fitness\nwith a probability pi , or an evaluated fitness with a probability 1 \u2212 pi . However, unlike previous\nworks, which used either average or weighted average of parental fitnesses as the inherited fitness,\nhere we employ the probabilistic model built by eCGA and estimates of linkage-group fitnesses in\ndetermining the inherited fitness. Specifically, individuals from parental population that received\nevaluated fitnesses (that is, individuals whose fitnesses were not inherited) are used to determine\nthe fitnesses of schemata that are defined by the probabilistic model. The schema fitness from\ndifferent partitions are then used to estimate the fitness of an offspring. The fitness-inheritance\nprocedure is detailed in the following paragraphs.\nAfter the probabilistic model is built and the linkage map is obtained (step 4 of the eCGA\nalgorithm outlined in the previous section), we estimate the fitness of schemata using only those\nP\nki\nindividuals whose fitnesses were not inherited. In all, we estimate the fitness of a total of m\ni=1 2\nschemas. Considering our previous example (Section 3) of a four-bit problem, whose model is\n[1,3][2][4], the schemata whose fitnesses are estimated are: {0*0*, 0*1*, 1*0*, 1*1*, *0**,\n*1**, ***0, ***1}.\nThe fitness of a schema, h, is defined as the difference between the average fitness of individuals\nthat contain the schema and the average fitness of all the individuals. That is,\n1\nf\u02c6s (h) =\nnh\n\n\u2032\n\nn\n1 X\nf (xi ) \u2212 \u2032\nf (xi )\nn i=1\n{i|x \u2283h}\n\nX\n\n(5)\n\ni\n\nwhere nh is the total number of individuals that contain the schema h, xi is the ith individual and\nf (xi ) is its fitness, n\u2032 is the total number of individuals that were evaluated. If a particular schema\nis not present in the population, its fitness is arbitrarily set to zero. Furthermore, it should be\n5\n\n\fnoted that the above definition of schema fitness is not unique and other estimates can be used.\nThe key point however is the use of the probabilistic model in determining the schema fitnesses.\nOnce the schema fitnesses across partitions are estimated, the offspring population is created\nas outlined in Section 3. An offspring receives inherited fitness with a probability pi , referred to as\nthe inheritance probability. The inherited fitness is computed as follows:\n\u2032\n\nn\nm\nX\n1 X\nfinh (y) = \u2032\nf (xi ) +\nf\u02c6s (hi \u2208 y)\nn i=1\ni=1\n\n(6)\n\nwhere y is the offspring individual. It should be noted that the eCGA model yields non-overlapping\nlinkage groups and might not be appropriate for problems with overlapping BBs. However, similar concepts can be incorporated in other PMBGAs such as the Bayesian optimization algorithm (BOA) (Pelikan, Goldberg, & Cant\u00fa-Paz, 2000b) which can handle overlapping BBs. Moreover, the inherited fitness can be computed by other methods, some of which are outlined in\n(Pelikan & Sastry, 2004), but the key is to use the estimates of substructure fitnesses in the computation.\nWith this understanding of the inheritance mechanism, we will now model the effects of fitness\ninheritance on population sizing and convergence time in the next sections. These models are then\nused to predict the speed-up (or efficiency enhancement) obtained through fitness inheritance.\n\n5\n\nModeling Fitness Inheritance\n\nTo ease the analytical burden, we assume a non-overlapping population of fixed size and a generationwise eCGA. We consider binary strings of fixed length as the chromosomes. Furthermore,\nthe models assume additively separable (nearly separable) uniformly-scaled problems. That is, we\nassume that the BBs are non-overlapping and the contribution of each BB to fitness is equal. Many\nof the above assumptions are made for simplifying the models and can be relaxed in a straightforward manner. We also assume that the probabilistic model accurately map to the building blocks\nof the problem. However, the effect of a wrong model is not significant as we will see later in the\nverification of the models.\n2 .\nAssuming that the actual fitness distribution, F, is Gaussian with mean \u03bcf and variance \u03c3f,t\n\u0010\n\n\u0011\n\n2\nF = N \u03bcf,t , \u03c3f,t\n,\n\nand that the distribution of fitness with inheritance, F\u2032 is Gaussian with mean \u03bcf \u2032 ,t and variance\n\u03c3f2 \u2032 ,t .\n\u0010\n\n\u0011\n\nF \u2032 = N \u03bcf \u2032 ,t , \u03c3f2 \u2032 ,t .\nThe above assumptions are reasonable since crossover has a normalizing effect.\nFrom (Sastry, Goldberg, & Pelikan, 2001) we know that fitness inheritance can be modeled as\nan addition of external noise to the actual fitness.\n\u0010\n\n2\nF \u2032 = F + N 0, pi \u03c3i,t\n\n\u0011\n\n(7)\n\n2 is variance of error\nwhere pi is the probability of and individual receiving inherited fitness, and \u03c3i,t\nbetween the inherited and actual fitnesses. Since the inherited fitness, finh , is equal to the sum of\n\n6\n\n\f2 is given\nestimated building-block fitnesses, for additively separable uniformly scaled problems \u03c3i,t\nby\n2\n\u03c3i,t\n=\n\nm\nX\n\nj=1\n\n\u0011\n\n\u0010\n\n\u03c3 2 f\u02c6BBj \u2212 fBBj ,\n\n2\n= m\u03c3BB,inh\n,\n\n(8)\n\n2\nwhere \u03c3BB,inh\nis the variance of the estimated fitness of a building block. Since the noise in the\nestimate of a BB comes from the other m \u2212 1 partitions (Goldberg, Deb, & Clark, 1992),\n2\n2\n2\n\u03c3BB,inh\n\u2248 [(m \u2212 1)/m]\u03c3BB\n\u2248 \u03c3BB\n.\n2\nwhere \u03c3BB\nis the actual BB variance. This approximation however is not valid for very high\ninheritance-probability values as the BB fitness is estimated from very few individuals which in2\ncrease the error in the estimate significantly. Empirically, we observed that \u03c3BB,inh\nbecomes significantly higher than the above approximation when pi \u2265 0.85.\nTherefore, the noise variance due to fitness inheritance is given by\n2\n2\n2\n\u03c3i,t\n= m\u03c3BB\n= \u03c3f,t\n.\n\n(9)\n\nFrom the above equation and Equations 5 and 7, we can write the fitness distribution with inheritance as\n\u0010\n\u0011\n(10)\nF \u2032 = N \u03bcf,t , (1 + pi ) \u03c3f2 \u2032 ,t .\n\nWe now proceed to develop population-sizing and convergence-time models.\n\n5.1\n\nPopulation Sizing\n\nPopulation sizing is one of the important factors that determine GA success. Therefore it is\nessential to appropriately size the population to incorporate the effects of fitness inheritance. Goldberg, Deb, and Clark (Goldberg, Deb, & Clark, 1992) proposed population-sizing models for correctly deciding between competing BBs. They incorporated noise arising from other partitions\ninto their model. However, they assumed that if wrong BBs were chosen in the first generation, the GAs would be unable to recover from the error. Harik, Cant\u00fa-Paz, Goldberg, and\nMiller (Harik, Cant\u00fa-Paz, Goldberg, & Miller, 1999) refined the above model by incorporating cumulative effects of decision making over time rather than in first generation only. Harik et al.\n(Harik, Cant\u00fa-Paz, Goldberg, & Miller, 1997) modeled the decision making between the best and\nsecond best BBs in a partition as a gambler's ruin problem. This model is based on the assumption that the selection process used is tournament selection without replacement. Miller\n(Miller, 1997) extended the gambler's ruin model to incorporate external noise. Pelikan, Goldberg, and Cant\u00fa-Paz (Pelikan, Goldberg, & Cant\u00fa-Paz, 2000a) and Pelikan, Sastry, and Goldberg\n(Pelikan, Sastry, & Goldberg, 2003) developed population-sizing models for PMBGAs, specifically\nfor BOA. Sastry and Goldberg (Sastry & Goldberg, 2000) empirically demonstrated that the population sizing of eCGA is similar to that of BOA.\nThe population-sizing model which incorporates the effect of model-building and its accuracy\non the population sizing of the GA, is given by\n\u0010\n\n\u0011\n\n2\nn = \u2212cn log(\u03b1)2k \u03c3f2 + \u03c3N\n,\n\n7\n\n\fwhere n is the population size, cn is a problem-dependent constant, k is the BB length, \u03b1 is the\n2 is the external noise variance. From\nprobability of failure, and \u03c3f2 is the fitness variance, and \u03c3N\n2 = p \u03c3 2 . Therefore, the population-size equation can be written as\nEquation 10, we can see that \u03c3N\ni f\nn = \u2212cn log(\u03b1)2k \u03c3f2 (1 + pi ) .\n\n(11)\n\nThe effect of fitness inheritance on population sizing can be predicted by dividing the above\nequation by the population size required when no inheritance is used. That is, by the populationsizing ratio, n/n(pi = 0):\nn\n= (1 + pi ) .\n(12)\nnr =\nn (pi = 0)\n\n5.2\n\nTime to Convergence\n\nUnderstanding convergence time is one of the key factors in the design of GAs and in predicting their\nscalability (Goldberg, 2002). M\u00fchlenbein and Schlierkamp-Voosen (M\u00fchlenbein & Schlierkamp-Voosen, 1993)\nderived the convergence-time model for the breeder GA using the notion of selection intensity\n(Bulmer, 1985) from population genetics. Thierens and Goldberg (Thierens & Goldberg, 1994)\nderived convergence-time models for different selections schemes including binary tournament selection. B\u00e4ck (B\u00e4ck, 1994) derived estimates of selection intensity for s-wise tournament and (\u03bb, \u03bc)\nselection. Miller and Goldberg (Miller & Goldberg, 1995) developed convergence-time models for\ns-wise tournament selection and incorporated the effects of external noise. B\u00e4ck (B\u00e4ck, 1995)\ndeveloped convergence-time models for (\u03bb, \u03bc) selection.\nThe assumptions used in developing the convergence-time model of Miller and Goldberg (Miller & Goldberg, 199\nare applicable to PMBGAs and the model is therefore valid for BOA and eCGA as well (Pelikan, Goldberg, & Cant\u00fa\nAn approximate form of the convergence-time model for noisy function evaluations can be written\nas (Goldberg, 2002):\nv\nu\n\u221a\nu\n\u03c32\n(13)\ntc = ct m * kt1 + N2 .\n\u03c3f\nwhere ct is a problem dependent constant. A detailed derivation of the above equation and other\napproximations are given elsewhere (Sastry & Goldberg, 2002; Sastry, 2001).\nAgain the effect of fitness inheritance on the convergence time can be predicted by dividing the\n2 = p \u03c32 ,\nabove equation by the convergence time when no inheritance is used. Recognizing that \u03c3N\ni f\nthe convergence-time ratio, tc /tc (pi = 0) is given by\ntc,r =\n\n5.3\n\np\ntc\n= 1 + pi .\ntc (pi = 0)\n\n(14)\n\nSpeed-Up\n\nWe now use the convergence-time and population-sizing models in the previous sections to predict\nthe number of function evaluations required for eCGA success. The total number of function\nevaluations can be written as\nnf e = n + n (tc \u2212 1) (1 \u2212 pi ) .\n(15)\nRecall that all the individuals in the initial population are evaluated and there after on an average\nn(1 \u2212 pi ) individuals are evaluated.\n8\n\n\fTo isolate the effect of fitness inheritance on the scalability of eCGA, we consider the ratio of\ntotal number of function evaluations required with fitness inheritance and that required without\nfitness inheritance. That is, we consider the function-evaluation ratio,\nnf e\nn + n (tc \u2212 1) (1 \u2212 pi )\n=\n,\nnf e (pi = 0)\nn(pi = 0)tc (pi = 0)\n\u0014\n\u0015\npi\n= nr tc,r (1 \u2212 pi ) +\n,\ntc (pi = 0)\n\u2248 nr * tc,r (1 \u2212 pi ) .\n\nnf e,r =\n\nnf e,r\n\n(16)\n(17)\n\nSubstituting Equations 12 and 14, in the above equation and simplifying, we get\nnf e,r \u2248 (1 + pi )1.5 (1 \u2212 pi )\n\n(18)\n\nThe speed-up that can be obtained through fitness inheritance is given by the inverse of the\nfunction-evaluation ratio:\n1\n\u03b7inh =\n.\n(19)\n1.5\n(1 + pi ) (1 \u2212 pi )\n\nEquation 18 indicates that the function-evaluation ratio increases (or the speed-up reduces) at\nlow pi values, reaches a maximum at pi = 0.2. When pi = 0.2 the number of function evaluations\nrequired is 5% more than that required without inheritance. In other words, the speed-up at\npi = 0.2 is 0.95. For inheritance probabilities above 0.2 the function-evaluation ratio decreases\n(speed-up increases) with the inheritance probability. Equation 19 predicts that the speed-up is\nmaximum when pi = 1.0, however, it should be noted that the models derived are not entirely valid\nfor higher pi values (pi \u2265 0.95). Empirically we observed that even when pi = 0.95, we obtained\na speed-up of 1.8\u20132.0. However, when pi = 1.0, the number of function evaluations required were\nfour times than that required without inheritance (speed-up of 0.25). The optimal inheritance\nprobability therefore should be around the value where the model prediction deviates.\nThe models developed in these sections are empirically verified with the help of two test functions\nin the next section.\n\n5.4\n\nModel Verification\n\nBefore discussing the empirical verification of the models developed in the previous sections, we\nbriefly describe the two test functions used for the model verification. Our approach in verifying\nthe models and observing if fitness inheritance yields speed-up is to consider bounding adversarial\nproblems that exploit one or more dimensions of problem difficulty (Goldberg, 2002). Particularly,\nwe are interested in problems where building-block identification is critical for the GA success.\nAdditionally, the problem solver (eCGA) should not have any knowledge of the BB structure of\nthe problem, but should be known to researchers for verification.\nThe two test functions with the above properties and used in this study are:\n1. OneMax problem, which is a GA-easy problem and in which each variable is independent\nof the others. While the optimization of the OneMax problem is easy, the probabilistic models\nbuilt by eCGA (or PMBGAs) for OneMax, however, are known to be only partially correct\nand include spurious linkages (Sastry & Goldberg, 2000; Pelikan, Goldberg, & Sastry, 2001).\nTherefore, the inheritance results on the OneMax problem will indicate if the effect of using\n9\n\n\f1.7\n10 4\u2212Trap: s = 4\n10 4\u2212Trap, s = 8\n100\u2212bit OneMax, s = 4\n100\u2212bit OneMax, s = 8\nTheory\n\ni\n\n1.6\n1.5\n\nc c\n\n2\n\nConvergence\u2212time ratio, t /t (p = 0)\n\n10 4\u2212Trap: s = 4\n10 4\u2212Trap, s = 8\n100\u2212bit OneMax, s = 4\n100\u2212bit OneMax, s = 8\nTheory\n\ni\n\nPopulation\u2212size ratio, n/n(p = 0)\n\n2.2\n\n1.8\n\n1.6\n\n1.4\n\n1.2\n\n1.4\n1.3\n1.2\n1.1\n1\n\n1\n0\n\n0.2\n\n0.4\n\n0.6\n\nProportion of inheritance, p\n\n0.8\n\n0\n\ni\n\n(a) Verification of population-size-ratio model\n\n0.2\n\n0.4\n\n0.6\n\nProportion of inheritance, p\n\n0.8\ni\n\n(b) Verification of convergence-time-ratio model\n\nFigure 1: Verification of the population-size-ratio model (Equation 11) and convergence-time-ratio\nmodel (Equation 14) for various inheritance proportions with empirical results for 100-bit OneMax\nand 10 4-Trap problems. The population size is determined by a bisection method such that\nthe failure probability averaged over 30\u2013100 independent runs is 1/m (that is, \u03b1 = 1/m). The\nconvergence-time is determined by the number of generations required to achieve convergence on\nm \u2212 1 out of m BBs correctly. The results are averaged over 30 independent bisection runs.\npartially correct linkage mapping on the inherited fitness is significant. We use a 100-bit\nOneMax problem for verifying the convergence-time and population-sizing models.\n2. m k-Deceptive trap problem, which consists of additively separable deceptive functions\n(Goldberg, 1987; Deb & Goldberg, 1993; Deb & Goldberg, 1994). Deceptive functions are\ndesigned to thwart the very mechanism of selectorecombinative search by punishing any\nlocalized hillclimbing and requiring mixing of whole building blocks at or above the order of\ndeception. Using such adversarially designed functions is a stiff test-in some sense the stiffest\ntest-of algorithm performance. The idea is that if an algorithm can beat an adversarially\ndesigned test function, it can solve other problems that are equally hard or easier than the\nadversary.\nWe use a tournament selection with tournament sizes of 4 and 8 in obtaining the empirical\nresults. An eCGA run is terminated when all the individuals in the population converge to the\nsame fitness value. The average number of BBs correctly converged are computed over 30\u2013100\nindependent runs. The minimum population size required such that m \u2212 1 BBs converge to the\ncorrect value is determined by a bisection method (Sastry, 2001). The results of population-size and\nconvergence-time ratio is averaged over 30 such bisection runs, while the results for the functionevaluation ratio is averaged over 900\u20133000 independent runs.\nThe population-size-ratio model (Equation 12) is verified with empirical results for OneMax\nand m k-Trap in Figure 1(a). The standard deviation for the empirical runs are very small (\u03c3 \u2208\n10\n\n\f10 4\u2212Trap: s = 4\n10 4\u2212Trap, s = 8\n100\u2212bit OneMax, s = 4\n100\u2212bit OneMax, s = 8\nTheory\n\n2.25\n\n1\n\n2\n\nSpeed\u2212Up, \u03b7\n\ninh\n\nfe\n\nfe\n\ni\n\nFunction evaluation ratio, n /n (p = 0)\n\n1.2\n\n1.75\n\n0.8\n\n0.6\n\n1.25\n\n10 4\u2212Trap: s = 4\n10 4\u2212Trap, s = 8\n100\u2212bit OneMax, s = 4\n100\u2212bit OneMax, s = 8\nTheory\n\n0.4\n0\n\n0.2\n\n0.4\n\n1.5\n\n1\n\n0.6\n\nProportion of inheritance, p\n\n0.8\n\n0\n\ni\n\n(a) Verification of function-evaluation-ratio model\n\n0.2\n\n0.4\n\n0.6\n\nProportion of inheritance, p i\n\n0.8\n\n(b) Verification of speed-up model\n\nFigure 2: Verification of the function-evaluation-ratio model (Equation 18) and the speed-up model\n(Equation 19) with empirical results on 100-bit OneMax and 10 4-Trap problems. The total number\nof function evaluations is determined such that the failure probability of an eCGA run is at most\n1/m. The results are averaged over 900\u20133000 independent runs.\n[4 \u00d7 10\u22124 , 1.8\u00d7\u22122 ]), and therefore the error bars are not shown in Figure 1(a). As shown in the\nfigure, the empirical results agrees with the model. The population size required to ensure that,\non an average, eCGA fails to converge on at most one out of m BBs, increases linearly with\nthe inheritance probability, pi . The population sizes required at very high inheritance-probability\nvalues, pi \u2265 0.85 deviates from the predicted values. This is because the noise introduced due to\ninheritance increases significantly at higher pi values because of limited number of individuals with\nevaluated fitness that take part in the estimate of schemata fitnesses.\nThe verification of the convergence-time-ratio model (Equation 14 with empirical results for\nOneMax and m k-Trap are shown in Figure 1(b). The standard deviation for the empirical runs are\nvery small (\u03c3 \u2208 [2 \u00d7 10\u22124 , 2.7 \u00d7 10\u22122 ]), and therefore the error bars are not shown. As shown in the\nfigure, the agreement between the empirical results and the model are slightly poor when compared\nto that for population-size ratio. This is because of the approximations used in deriving the\nconvergence time model and more accurate, but complex, models exist that improve the predictions\n(Sastry, 2001). However, as we will see later, this disagreement between the model and experiments\ndoes not significantly affect the prediction of speed-up, which is the key objective. The empirical\nconvergence-time ratio deviates from the predicted value at slightly lower inheritance probabilities,\npi \u2265 0.75 than the population-size ratio. This is to be expected as the population sizing is largely\ndictated by the fitness and noise variances in the initial few generations, while the convergence\ntime is dictated by the fitness and noise variances over the GA run. Therefore, the effect of high\npi values, or less number of evaluated individuals, is cumulative over time and leads to deviation\nfrom theory at lower pi values than the population size.\n\n11\n\n\fThe predicted values of function-evaluation-ratio (Equation 18) and the speed-up (Equation 19)\nare verified with empirical results for OneMax and m k-Trap in Figures 2(a) and 2(b), respectively.\nThe standard deviation for the empirical runs are very small (\u03c3 \u2208 [7 \u00d7 10\u22125 , 7 \u00d7 10\u22123 ]), and\ntherefore are not shown. As shown in Figures 2(a) and 2(b), the empirical results agree with\nthe analytical models. Furthermore, the agreement for the OneMax problem with the models\nis good even though the building-block identification for the OneMax problem is only partially\ncorrect. The results show that the required number of function evaluations is almost of halved\nwith the use of fitness inheritance thereby leading to a speed-up of 1.75\u20132.25. This is a significant\nimprovement over a speed-up of 1.3 observed for simple GAs with a simple inheritance mechanism\n(Sastry, Goldberg, & Pelikan, 2001). Furthermore, fitness inheritance yields speed-up even when\nthe inheritance probability is very high (as high as 0.95), which agrees with the empirical observation\nof Smith, Dike, and Stegmann (Smith, Dike, & Stegmann, 1995).\nOverall, the results suggest that significant efficiency enhancement can be achieved through an\ninheritance mechanism that incorporates knowledge of important sub-solutions of a problem and\ntheir partial fitnesses.\n\n6\n\nFuture Work\n\nIn this paper, we have introduced and analyzed a fitness inheritance mechanism that incorporates\nthe knowledge of building-block structure and fitness. The BB structure and fitnesses are identified\nand estimated with the help of extended compact genetic algorithm, a competent GA. The results\nshow that significant speed-up can be obtained through fitness inheritance and warrants further\nresearch and enhancements in many avenues some of which are listed in the following:\n\u2022 Problems with overlapping building blocks: While this paper considered problems with\nnon-overlapping building blocks, many problems have different building blocks that share\ncommon components. While considering problems with overlapping building blocks, eCGA\nmight not be the appropriate search method, however the fitness inheritance mechanism\nshould still be valid which can be used in other more advanced PMBGAs such as the Bayesian\noptimization algorithm (Pelikan & Sastry, 2004).\n\u2022 Non-Uniformly scaled problems: In this paper, all the building blocks of a problem had\nequal salience, which might not be the case in real-world problems. The non-uniform scaling\ninduces sequentiality in the identification and convergence of the building blocks. The effect\nof non-uniform building-block salience on the speed-up and optimal inheritance proportion\nshould be investigated.\n\u2022 Hierarchical problems: One of the important class of nearly decomposable problems is hierarchical problems (Pelikan & Goldberg, 2001), in which the building-block interactions are\npresent at more than a single level. Such problems can be successfully solved in polynomial\ntime by the hierarchical Bayesian optimization algorithm . The fitness inheritance mechanism used in this study could be enhanced and incorporated into hBOA and the efficiency\nenhancement provided by inheritance can be investigated.\n\u2022 Additional dimensions of problem difficulty: In this paper we considered one of the\ndimensions of GA problem difficulty, deception. However, there are other dimensions of problem difficulty (Goldberg, 2002) such as epistasis and external noise. This factors should be\n12\n\n\fincluded in isolation or in conjunction with other factors of problem difficulty in determining\na complete picture of efficiency enhancement provided by fitness inheritance.\n\u2022 Real-World problems: One of the key objectives of analyzing and developing fitnessinheritance mechanism is to aid the principled design of such a mechanism in competent\ngenetic algorithms for successfully solving complex real-world problems in practical time.\n\u2022 Interactive and Human-Based evolutionary algorithms: In interactive evolutionary\nalgorithms the fitness of a solution is given by a human being rather than by a computation\n(Takagi, 2001). In human-based GAs, both fitness evaluations and genetic operations such as\nselection, crossover, and mutation are performed by users (Kosorukoff & Goldberg, 2002). To\navoid overwhelming the users, it is often infeasible to use large populations even if the search\nproblem might warrant one. Fitness inheritance can be used in such cases to alleviate this\nrestriction. While only a small portion of the population gets the fitness from the users, the\nrest can receive inherited fitness, thereby allowing larger population sizes but still maintaining\nthe same number of function evaluations from the users.\n\n7\n\nConclusions\n\nIn this paper, we introduced a fitness inheritance mechanism that estimates the fitness by schema\nfitness. The sub-solutions (or schemata) are automatically and adaptively identified by a probabilistic model building genetic algorithm called extended compact genetic algorithm. We have also\ndeveloped a theoretical basis for fitness inheritance and have derived models for convergence time\nand population sizing. The convergence-time and population-sizing models were in turn used to\npredict the effect of fitness inheritance on the scalability of eCGA and also to predict the speed-up\nobtained via fitness inheritance. We observed that the fitness inheritance mechanism that incorporates information of building-block structure and fitness provides a significant speed-up. For\nadditively separable problems, the results show that using evaluations for only about 5-15% of the\npopulation, fitness inheritance can yield a speed-up of around 1.75\u20132.25.\n\nacknowledgments\nWe gratefully acknowledge Robert E. Smith for his helpful suggestions. We also thank Martin\nButz, Ying-ping Chen, Xavier Llora, Kei Ohnishi, and Tian-Li Yu for many useful discussions.\nThis work was sponsored by the Air Force Office of Scientific Research, Air Force Materiel Command, USAF, under grant F49620-00-0163 and F49620-03-1-0129, the National Science Foundation\nunder ITR grant DMR-99-76550 (at Materials Computation Center), and ITR grant DMR-0121695\n(at CPSD), and the Dept. of Energy under grant DEFG02-91ER45439 (at Fredrick Seitz MRL).\nThe U.S. Government is authorized to reproduce and distribute reprints for government purposes\nnotwithstanding any copyright notation thereon.\nThe views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied,\nof the Air Force Office of Scientific Research, the National Science Foundation, or the U.S. Government.\n\n13\n\n\fReferences\nB\u00e4ck, T. (1994). Selective pressure in evolutionary algorithms: A characterization of selection\nmechanisms. Proceedings of the First IEEE Conference on Evolutionary Computation, 57\u201362.\nB\u00e4ck, T. (1995). Generalized convergence models for tournament-and (\u03bc, \u03bb)-selection. Proceedings of the Sixth International Conference on Genetic Algorithms, 2\u20138.\nBaluja, S. (1994). Population-based incremental learning: A method of integrating genetic search\nbased function optimization and competitive learning (Technical Report CMU-CS-94-163).\nCarnegie Mellon University.\nBulmer, M. G. (1985). The mathematical theory of quantitative genetics. Oxford: Oxford University Press.\nChen, J.-H., Goldberg, D. E., Ho, S.-Y., & Sastry, K. (2002). Fitness inheritance in multiobjective optimization. Proceedings of the Genetic and Evolutionary Computation Conference, 319\u2013326. (Also IlliGAL Report No. 2002017).\nDeb, K., & Goldberg, D. E. (1993). Analyzing deception in trap functions. Foundations of Genetic\nAlgorithms, 2 , 93\u2013108. (Also IlliGAL Report No. 91009).\nDeb, K., & Goldberg, D. E. (1994). Sufficient conditions for deceptive and easy binary functions.\nAnnals of Mathematics and Artificial Intelligence, 10 , 385\u2013408. (Also IlliGAL Report No.\n92001).\nDucheyne, E., De Baets, B., & De Wulf, R. (2003). Is fitness inheritance useful for real-world\napplications? Proceedings of the Evolutionary Multi-Objective Conference, 31\u201342.\nGoldberg, D. E. (1987). Simple genetic algorithms and the minimal, deceptive problem. In Davis,\nL. (Ed.), Genetic algorithms and simulated annealing (Chapter 6, pp. 74\u201388). Los Altos, CA:\nMorgan Kaufmann.\nGoldberg, D. E. (1991). Theory tutorial. (Tutorial presented with G. Liepens at the 1991 International Conference on Genetic Algorithms, La Jolla, CA).\nGoldberg, D. E. (2002). Design of innovation: Lessons from and for competent genetic algorithms. Boston, MA: Kluwer Acadamic Publishers.\nGoldberg, D. E., Deb, K., & Clark, J. H. (1992). Genetic algorithms, noise, and the sizing of\npopulations. Complex Systems, 6 , 333\u2013362. (Also IlliGAL Report No. 91010).\nGoldberg, D. E., Korb, B., & Deb, K. (1989). Messy genetic algorithms: Motivation, analysis,\nand first results. Complex Systems, 3 (5), 493\u2013530. (Also IlliGAL Report No. 89003).\nHarik, G. (1999, January). Linkage learning via probabilistic modeling in the ECGA (IlliGAL\nReport No. 99010). Urbana, IL: University of Illinois at Urbana-Champaign.\nHarik, G., Cant\u00fa-Paz, E., Goldberg, D. E., & Miller, B. L. (1997). The gambler's ruin problem,\ngenetic algorithms, and the sizing of populations. Proceedings of the IEEE International\nConference on Evolutionary Computation, 7\u201312. (Also IlliGAL Report No. 96004).\nHarik, G., Cant\u00fa-Paz, E., Goldberg, D. E., & Miller, B. L. (1999). The gambler's ruin problem,\ngenetic algorithms, and the sizing of populations. Evolutionary Computation, 7 (3), 231\u2013253.\n(Also IlliGAL Report No. 96004).\n14\n\n\fHarik, G., Lobo, F., & Goldberg, D. E. (1998). The compact genetic algorithm. Proceedings of\nthe IEEE International Conference on Evolutionary Computation, 523\u2013528. (Also IlliGAL\nReport No. 97006).\nKosorukoff, A., & Goldberg, D. (2002). Evolutionary computation as a form of organization. Proceedings of the Genetic and Evolutionary Computation Conference, 965\u2013972. (Also IlliGAL\nReport No. 2001004).\nLarra\u00f1aga, P., & Lozano, J. A. (Eds.) (2002). Estimation of distribution algorithms. Boston, MA:\nKluwer Academic Publishers.\nMiller, B. L. (1997, May). Noise, sampling, and efficient genetic algorithms. Doctoral dissertation,\nUniversity of Illinois at Urbana-Champaign, General Engineering Department, Urbana, IL.\n(Also IlliGAL Report No. 97001).\nMiller, B. L., & Goldberg, D. E. (1995). Genetic algorithms, tournament selection, and the effects\nof noise. Complex Systems, 9 (3), 193\u2013212. (Also IlliGAL Report No. 95006).\nM\u00fchlenbein, H., & Schlierkamp-Voosen, D. (1993). Predictive models for the breeder genetic\nalgorithm: I. continous parameter optimization. Evolutionary Computation, 1 (1), 25\u201349.\nPelikan, M. (2002). Bayesian optimization algorithm: From single level to hierarchy. Doctoral\ndissertation, University of Illinois at Urbana-Champaign, Urbana, IL. (Also IlliGAL Report\nNo. 2002023).\nPelikan, M., & Goldberg, D. E. (2001). Escaping hierarchical traps with competent genetic\nalgorithms. Proceedings of the Genetic and Evolutionary Computation Conference, 511\u2013518.\n(Also IlliGAL Report No. 2000020).\nPelikan, M., Goldberg, D. E., & Cant\u00fa-Paz, E. (2000a). Bayesian optimization algorithm, population sizing, and time to convergence. Proceedings of the Genetic and Evolutionary Computation Conference, 275\u2013282. (Also IlliGAL Report No. 2000001).\nPelikan, M., Goldberg, D. E., & Cant\u00fa-Paz, E. (2000b). Linkage learning, estimation distribution,\nand Bayesian networks. Evolutionary Computation, 8 (3), 314\u2013341. (Also IlliGAL Report No.\n98013).\nPelikan, M., Goldberg, D. E., & Sastry, K. (2001). Bayesian optimization algorithm, decision\ngraphs, and Occam's razor. Proceedings of the Genetic and Evolutionary Computation Conference, 519\u2013526. (Also IlliGAL Report No. 2000020).\nPelikan, M., Lobo, F., & Goldberg, D. E. (2002). A survey of optimization by building and using\nprobabilistic models. Computational Optimization and Applications, 21 , 5\u201320. (Also IlliGAL\nReport No. 99018).\nPelikan, M., & Sastry, K. (2004, January). Fitness inheritance in the bayesian optimization algorithm (IlliGAL Report No. 2004009). Urbana, IL: University of Illinois at Urbana-Champaign.\nPelikan, M., Sastry, K., & Goldberg, D. E. (2003). Scalability of the Bayesian optimization\nalgorithm. International Journal of Approximate Reasoning, 31 (3), 221\u2013258. (Also IlliGAL\nReport No. 2001029).\nSastry, K. (2001). Evaluation-relaxation schemes for genetic and evolutionary algorithms. Master's thesis, University of Illinois at Urbana-Champaign, General Engineering Department,\nUrbana, IL. (Also IlliGAL Report No. 2002004).\n15\n\n\fSastry, K., & Goldberg, D. E. (2000). On extended compact genetic algorithm. Late-Breaking\nPaper at the Genetic and Evolutionary Computation Conference, 352\u2013359. (Also IlliGAL\nReport No. 2000026).\nSastry, K., & Goldberg, D. E. (2002). Genetic algorithms, efficiency enhancement, and deciding well between fitness function with differing variances. Proceedings of the Genetic and\nEvolutionary Computation Conference, 528\u2013535. (Also IlliGAL Report No. 2002002).\nSastry, K., Goldberg, D. E., & Pelikan, M. (2001). Don't evaluate, inherit. Proceedings of\nthe Genetic and Evolutionary Computation Conference, 551\u2013558. (Also IlliGAL Report No.\n2001013).\nSmith, R., Dike, B., & Stegmann, S. (1995). Fitness inheritance in genetic algorithms. In Proceedings of the ACM Symposium on Applied Computing (pp. 345\u2013350). New York, NY, USA:\nACM.\nTakagi, H. (2001). Interactive evolutionary computation: Fusion of the capabilities of EC optimization and human evaluation. Proceedings of the IEEE , 89 (9), 1275\u20131296.\nThierens, D., & Goldberg, D. E. (1994). Convergence models of genetic algorithm selection\nschemes. Parallel Problem Solving from Nature, 3 , 116\u2013121.\nZheng, X., Julstrom, B., & Cheng, W. (1997). Design of vector quantization codebooks using a\ngenetic algorithm. Proceedings of the IEEE Conference on Evolutionary Computation, ICEC ,\n525\u2013529.\n\n16\n\n\f8\n\n6\n\n4\n\n2\n\n0\n5\n0\nx\n\u20135\n\n4\n\n2\n\n0\ny\n\n\u20132\n\n\u20134\n\n\f"}