{"id": "http://arxiv.org/abs/math/0511702v1", "guidislink": true, "updated": "2005-11-29T12:59:36Z", "updated_parsed": [2005, 11, 29, 12, 59, 36, 1, 333, 0], "published": "2005-11-29T12:59:36Z", "published_parsed": [2005, 11, 29, 12, 59, 36, 1, 333, 0], "title": "Fragmentation associated to Levy processes using snake", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0401361%2Cmath%2F0401435%2Cmath%2F0401150%2Cmath%2F0511321%2Cmath%2F0511169%2Cmath%2F0511414%2Cmath%2F0511574%2Cmath%2F0511241%2Cmath%2F0511641%2Cmath%2F0511399%2Cmath%2F0511591%2Cmath%2F0511411%2Cmath%2F0511104%2Cmath%2F0511487%2Cmath%2F0511114%2Cmath%2F0511017%2Cmath%2F0511128%2Cmath%2F0511284%2Cmath%2F0511692%2Cmath%2F0511709%2Cmath%2F0511422%2Cmath%2F0511051%2Cmath%2F0511612%2Cmath%2F0511490%2Cmath%2F0511048%2Cmath%2F0511363%2Cmath%2F0511071%2Cmath%2F0511660%2Cmath%2F0511645%2Cmath%2F0511195%2Cmath%2F0511319%2Cmath%2F0511708%2Cmath%2F0511505%2Cmath%2F0511106%2Cmath%2F0511408%2Cmath%2F0511112%2Cmath%2F0511210%2Cmath%2F0511264%2Cmath%2F0511603%2Cmath%2F0511607%2Cmath%2F0511168%2Cmath%2F0511066%2Cmath%2F0511601%2Cmath%2F0511478%2Cmath%2F0511047%2Cmath%2F0511090%2Cmath%2F0511515%2Cmath%2F0511003%2Cmath%2F0511742%2Cmath%2F0511485%2Cmath%2F0511238%2Cmath%2F0511232%2Cmath%2F0511711%2Cmath%2F0511248%2Cmath%2F0511009%2Cmath%2F0511618%2Cmath%2F0511397%2Cmath%2F0511297%2Cmath%2F0511352%2Cmath%2F0511310%2Cmath%2F0511004%2Cmath%2F0511097%2Cmath%2F0511526%2Cmath%2F0511494%2Cmath%2F0511346%2Cmath%2F0511382%2Cmath%2F0511648%2Cmath%2F0511277%2Cmath%2F0511421%2Cmath%2F0511161%2Cmath%2F0511428%2Cmath%2F0511117%2Cmath%2F0511389%2Cmath%2F0511518%2Cmath%2F0511502%2Cmath%2F0511347%2Cmath%2F0511737%2Cmath%2F0511155%2Cmath%2F0511255%2Cmath%2F0511172%2Cmath%2F0511030%2Cmath%2F0511285%2Cmath%2F0511740%2Cmath%2F0511176%2Cmath%2F0511644%2Cmath%2F0511702%2Cmath%2F0511543%2Cmath%2F0511280%2Cmath%2F0511259%2Cmath%2F0511022%2Cmath%2F0511390%2Cmath%2F0511452%2Cmath%2F0511716%2Cmath%2F0511166%2Cmath%2F0511219%2Cmath%2F0511089%2Cmath%2F0511317%2Cmath%2F0511202%2Cmath%2F0511420%2Cmath%2F0511159%2Cmath%2F0511514&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Fragmentation associated to Levy processes using snake"}, "summary": "We consider the height process of a Levy process with no negative jumps, and\nits associated continuous tree representation. Using Levy snake tools developed\nby Duquesne and Le Gall, with an underlying Poisson process, we construct a\nfragmentation process, which in the stable case corresponds to the self-similar\nfragmentation described by Miermont. For the general fragmentation process we\ncompute a family of dislocation measures as well as the law of the size of a\ntagged fragment. We also give a special Markov property for the snake which is\ninteresting in itself.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0401361%2Cmath%2F0401435%2Cmath%2F0401150%2Cmath%2F0511321%2Cmath%2F0511169%2Cmath%2F0511414%2Cmath%2F0511574%2Cmath%2F0511241%2Cmath%2F0511641%2Cmath%2F0511399%2Cmath%2F0511591%2Cmath%2F0511411%2Cmath%2F0511104%2Cmath%2F0511487%2Cmath%2F0511114%2Cmath%2F0511017%2Cmath%2F0511128%2Cmath%2F0511284%2Cmath%2F0511692%2Cmath%2F0511709%2Cmath%2F0511422%2Cmath%2F0511051%2Cmath%2F0511612%2Cmath%2F0511490%2Cmath%2F0511048%2Cmath%2F0511363%2Cmath%2F0511071%2Cmath%2F0511660%2Cmath%2F0511645%2Cmath%2F0511195%2Cmath%2F0511319%2Cmath%2F0511708%2Cmath%2F0511505%2Cmath%2F0511106%2Cmath%2F0511408%2Cmath%2F0511112%2Cmath%2F0511210%2Cmath%2F0511264%2Cmath%2F0511603%2Cmath%2F0511607%2Cmath%2F0511168%2Cmath%2F0511066%2Cmath%2F0511601%2Cmath%2F0511478%2Cmath%2F0511047%2Cmath%2F0511090%2Cmath%2F0511515%2Cmath%2F0511003%2Cmath%2F0511742%2Cmath%2F0511485%2Cmath%2F0511238%2Cmath%2F0511232%2Cmath%2F0511711%2Cmath%2F0511248%2Cmath%2F0511009%2Cmath%2F0511618%2Cmath%2F0511397%2Cmath%2F0511297%2Cmath%2F0511352%2Cmath%2F0511310%2Cmath%2F0511004%2Cmath%2F0511097%2Cmath%2F0511526%2Cmath%2F0511494%2Cmath%2F0511346%2Cmath%2F0511382%2Cmath%2F0511648%2Cmath%2F0511277%2Cmath%2F0511421%2Cmath%2F0511161%2Cmath%2F0511428%2Cmath%2F0511117%2Cmath%2F0511389%2Cmath%2F0511518%2Cmath%2F0511502%2Cmath%2F0511347%2Cmath%2F0511737%2Cmath%2F0511155%2Cmath%2F0511255%2Cmath%2F0511172%2Cmath%2F0511030%2Cmath%2F0511285%2Cmath%2F0511740%2Cmath%2F0511176%2Cmath%2F0511644%2Cmath%2F0511702%2Cmath%2F0511543%2Cmath%2F0511280%2Cmath%2F0511259%2Cmath%2F0511022%2Cmath%2F0511390%2Cmath%2F0511452%2Cmath%2F0511716%2Cmath%2F0511166%2Cmath%2F0511219%2Cmath%2F0511089%2Cmath%2F0511317%2Cmath%2F0511202%2Cmath%2F0511420%2Cmath%2F0511159%2Cmath%2F0511514&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider the height process of a Levy process with no negative jumps, and\nits associated continuous tree representation. Using Levy snake tools developed\nby Duquesne and Le Gall, with an underlying Poisson process, we construct a\nfragmentation process, which in the stable case corresponds to the self-similar\nfragmentation described by Miermont. For the general fragmentation process we\ncompute a family of dislocation measures as well as the law of the size of a\ntagged fragment. We also give a special Markov property for the snake which is\ninteresting in itself."}, "authors": ["Romain Abraham", "Jean-Francois Delmas"], "author_detail": {"name": "Jean-Francois Delmas"}, "author": "Jean-Francois Delmas", "links": [{"href": "http://arxiv.org/abs/math/0511702v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0511702v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0511702v1", "affiliation": "CERMICS", "arxiv_url": "http://arxiv.org/abs/math/0511702v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0511702v1 [math.PR] 29 Nov 2005\n\nFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES USING\nSNAKE\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\nAbstract. We consider the height process of a L\u00e9vy process with no negative jumps, and\nits associated continuous tree representation. Using L\u00e9vy snake tools developed by Duquesne\nand Le Gall, with an underlying Poisson process, we construct a fragmentation process, which\nin the stable case corresponds to the self-similar fragmentation described by Miermont. For\nthe general fragmentation process we compute a family of dislocation measures as well as\nthe law of the size of a tagged fragment. We also give a special Markov property for the\nsnake which is interesting in itself.\n\n1. Introduction\nWe present a fragmentation process associated to general critical or sub-critical continuous\nrandom trees (CRT) which were introduced by Le Gall and Le Jan [15] and developed later\nby Duquesne and Le Gall [10]. This extends previous work from Miermont [18] on stable\nCRT. Although the underlying ideas are the same in both constructions, the arguments in\nthe proofs are very different. Following Abraham and Serlet [1] who deal with the particular\ncase of Brownian CRT, our arguments rely on L\u00e9vy Poisson Snake processes. Those path\nprocesses are L\u00e9vy Snake, see [10], with underlying Poisson process. To prove the fragmentation property, we need some results on L\u00e9vy Snake which are interesting by themselves.\nEventually we give the dislocation measure of the fragmentation process. We think this construction provides non trivial examples of non self-similar fragmentations, and that the tools\ndeveloped here could give further results on the fragmentation associated to CRT.\nThe next three subsections give a brief presentation of the mathematical objects and state\nthe mains results. The last one describes the organization of the paper.\n1.1. Exploration process. The coding of a tree by its height process is now well-known.\nFor instance, the height process of Aldous' CRT [2] is a normalized Brownian excursion. In\n[15], Le Gall and Le Jan associated to a L\u00e9vy process with no negative jumps that does not\ndrift to infinity, X = (Xt , t \u2265 0), a continuous state branching process (CSBP) and a L\u00e9vy\nCRT which keeps track of the genealogy of the CSBP. Let \u03c8 denote the Laplace exponent of\nX. We shall assume there is no Brownian part, so that\nZ\nh\ni\n\u03c0(dl) e\u2212\u03bbl \u22121 + \u03bbl ,\n\u03c8(\u03bb) = \u03b10 \u03bb +\n(0,+\u221e)\n\nwith\n\u03b10 \u2265 0 and the L\u00e9vy measure \u03c0 is a positive \u03c3-finite measure on (0, +\u221e) such that\nR\n2\n(0,+\u221e) (l \u2227 l )\u03c0(dl) < \u221e. Following [10], we shall also assume that X is of infinite variation\n\nDate: September 5, 2018.\n2000 Mathematics Subject Classification. 60J25, 60G57.\nKey words and phrases. Fragmentation, L\u00e9vy snake, dislocation measure, stable processes, special Markov\nproperty.\n1\n\n\f2\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nR\na.s. which implies that (0,1) l\u03c0(dl) = \u221e. Notice those hypothesis are fulfilled in the stable\ncase: \u03c8(\u03bb) = \u03bb\u03b1 , \u03b1 \u2208 (1, 2).\nInformally for the height process, H = (Ht , t \u2265 0), Ht gives the distance (which can be\nunderstood as the number of generations) between the individual labeled t and the root, 0,\nof the CRT. This process is a key tool in this construction but it is not a Markov process.\nThe so-called exploration process \u03c1 = (\u03c1t , t \u2265 0) is a c\u00e0d-l\u00e0g Markov process taking values in\nMf (R+ ), the set of finite measure on R+ , endowed with the topology of weak convergence.\nThe height process can easily be recovered from the exploration process as Ht = H(\u03c1t ), where\nH(\u03bc) denotes the supremum of the closed support of the measure \u03bc (with the convention that\nH(0)=0). In some sense \u03c1t (dv) records the \"number\" of brothers, with labels larger than t,\nof the ancestor of t at generation v. Furthermore the jumps of \u03c1 are given by\n\u03c1t \u2212 \u03c1t\u2212 = \u2206t \u03b4Ht ,\nwhere \u2206t is the jump of the L\u00e9vy process X at time t and \u03b4x is the Dirac mass at\n\b x.\nIntuitively \u2206t represents the \"size\" of the progeny of such individual t. And the set s \u2265\nt; min{Hu , u \u2208 [t, s]} \u2265 Ht represents the \"size\" of the total descendants of the individual t.\nSuch individual t corresponds to a node in the CRT. To each jump of X corresponds a node\nin the CRT and vice-versa. Definition and properties of the height process and exploration\nprocess are recalled in Section 2.\n1.2. Fragmentation. A fragmentation process is a Markov process which describes how an\nobject with given total mass evolves as it breaks into several fragments randomly as time\npasses. Notice there may be loss of mass but no creation. This kind of processes has been\nwidely studied in the recent years, see Bertoin [7] and references therein. To be more precise,\nthe state space of a fragmentation process is the set of the non-increasing sequences of masses\nwith finite total mass\n)\n(\n+\u221e\nX\n\u2193\nsk < +\u221e .\nS = s = (s1 , s2 , . . .); s1 \u2265 s2 \u2265 * * * \u2265 0 and \u03a3(s) =\nk=1\n\nS \u2193 -valued\n\n(\u039b\u03b8 , \u03b8\n\nIf we denote by Ps the law of a\nprocess \u039b =\n\u2265 0) starting at s = (s1 , s2 , . . .) \u2208\nS \u2193 , we say that \u039b is a fragmentation process if it is a Markov process such that \u03b8 7\u2192 \u03a3(\u039b\u03b8 )\nis non-increasing and if it fulfills the fragmentation property: the law of (\u039b\u03b8 , \u03b8 \u2265 0) under Ps\nis the non-increasing reordering of the fragments of independent processes of respective laws\nP(s1 ,0,...) ,P(s2 ,0,...) , . . . In other words, each fragment after dislocation behaves independently\nof the others, and its evolution depends only on its initial mass. As a consequence, to describe\nthe law of the fragmentation process with any initial condition, it suffices to study the laws\nPr := P(r,0,...) for any r \u2208 (0, +\u221e), i.e. the law of the fragmentation process starting with a\nsingle mass r.\nA fragmentation process is said to be self-similar of index \u03b1 if, for any r > 0, the law of\n\u03b1\nthe process (\u039b\u03b8 , \u03b8 \u2265 0) under Pr is the law of the process (r\u039br \u03b8 , \u03b8 \u2265 0) under P1 . Bertoin [6]\nproved that the law of a self-similar fragmentation is characterized by: the index of selfsimilarity \u03b1, an erosion coefficient which corresponds to a deterministic rate of mass loss, and\na dislocation measure \u03bd on S \u2193 which describes sudden dislocations of a fragment of mass 1.\nConnections between fragmentation processes and random trees or Brownian excursion\nhave been pointed out by several authors. Let us mention the work of Bertoin [5] who\nconstructed a fragmentation process by looking at the lengths of the excursions above level t\nof a Brownian excursion. Aldous and Pitman [3] constructed another fragmentation process,\nwhich is related to the additive coalescent process, by cutting Aldous' Brownian CRT. Their\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n3\n\nproofs rely on projective limits on trees. Those results have been generalized, by Miermont\n[17, 18] to CRT associated to stable L\u00e9vy processes, using path transformations of the L\u00e9vy\nprocess. Concerning the Aldous-Pitman's fragmentation process, Abraham and Serlet [1]\ngive an alternative construction using Poisson snakes. Our presentation follow their ideas.\nHowever, we give next a more intuitive presentation which is in fact equivalent (see Section\n9.1).\nWe consider an excursion of the L\u00e9vy process X out of 0, which correspond also to an\nexcursion of the exploration process (and the height process) out of 0. Let \u03c3 denote the\ncommon length of those excursions. Intuitively, \u03c3 represents the \"size\" of the total progeny\nof the root 0. Let J = {t \u2208 [0, \u03c3]; Xt 6= Xt\u2212 } the set of jumping times of X or nodes of the\nCRT, and consider (Tt ; t \u2208 J ) a countable family of independent random variable such that\nTt is distributed according to an exponential law with parameter \u2206t . At time Tt , the node\ncorresponding to the jump \u2206t is cut from the CRT. Two individuals, say u \u2264 v, belongs to\nthe same fragment at time \u03b8 if no node has been cut before \btime \u03b8 between them and their\nmost recent common ancestor which is defined as u f v = inf t \u2208 [0, u]; min{Hr , r \u2208 [u, v]} =\nmin{Hr , r \u2208 [t, u]} . Let \u039b\u03b8 denote the family of decreasing positive Lebesgue measure of\nthe fragments completed by zeros if necessary so that \u039b\u03b8 \u2208 S \u2193 . See Section 9.1 for a precise\nconstruction.\nCutting nodes at time \u03b8 > 0 may be viewed as adding horizontal lines under the epigraph\nof H (see figure 1).\nHs\n\n0\n\nt\n\nu\n\nv\n\n\u03c3\n\ns\n\nFigure 1. Cutting at nodes: a modifier\nWe then consider the excursions obtained after cutting the initial excursion along the\nhorizontal lines and gluing together the corresponding pieces of paths (for instance, the bold\npiece of the path of H in Figure 1 corresponds to the bold excursion in Figure 2). The\nlengths of these excursions, ranked in decreasing order, form the fragmentation process as\n\u03b8 increases. Of course, the figure are caricatures as the process H is very irregular and the\nnumber of fragments is infinite.\nTheorem 8.3 asserts that the process (\u039b\u03b8 , \u03b8 \u2265 0) is a fragmentation process. There is no\nloss of mass thanks to Proposition 8.8.\n\n\f4\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nFigure 2. Fragmentation of the excursion\nIn the stable case, \u03c8(\u03bb) = \u03bb\u03b1 with \u03b1 \u2208 (1, 2), using scaling properties, we get the fragmentation is self-similar with index 1/\u03b1 and we recover the results of Miermont [18], see Corollary\n9.3. In particular the dislocation measure is given by: for any measurable non-negative function F on S \u2193 ,\n\u0001\nZ\n\u03b1(\u03b1 \u2212 1)\u0393 [\u03b1 \u2212 1]/\u03b1\nF (x)\u03bd(dx) =\nE [S1 F (\u2206St /S1 , t \u2264 1)] ,\n\u0393(2 \u2212 \u03b1)\n\nwhere (St , t \u2265 0) is a stable subordinator with Laplace exponent \u03c8 \u22121 (\u03bb) = \u03bb1/\u03b1 , and\nF (\u2206St /S1 , t \u2264 1) has to be understood as F applied to the decreasing reordering of the\nsequence (\u2206St /S1 , t \u2264 1).\nIn the general case, the fragmentation is not self-similar. However, if T = {\u03b8 \u2265 0; \u039b\u03b8 6=\n\u03b8\u2212\n\u039b } denotes the jumping times of the process \u039b, we get as a direct consequence of Section\n9.3 that\nX\n\u03b4\u03b8,\u039b\u03b8\n\u03b8\u2208T\n\nis a point process with intensity d\u03b8\u03bd\u0303\u039b\u03b8\u2212 (ds), where (\u03bd\u0303x , x \u2208 S \u2193 ) is a family of \u03c3-finite measures\non S \u2193 . There exists a family (\u03bdr , r > 0) of \u03c3-finite measure on S \u2193 , which we call dislocation\nmeasures of the fragmentation \u039b, such that for any x = (x1 , x2 , . . .) \u2208 S \u2193 and any nonnegative measurable function, F , defined on S \u2193 ,\nZ\nX Z\nF (s)\u03bd\u0303x (ds) =\nF (xi,s )\u03bdxi (ds),\ni\u2208N\u2217 ;xi >0\n\nwhere xi,s is the decreasing reordering of the merging of the sequences s \u2208 S \u2193 and x, where\nxi has been removed of the sequence x. This means that only one element of x fragments and\nthe fragmentation depends only on the size of this very fragment.\nThe dislocation measures\nP\ncan be computed, see Theorem 9.1. In particular \u03bdr (dx)-a.e.\n\u2217\ni\u2208N xi = r assures there is no\nloss of mass at the dislocation. The definition of the dislocation measures is more involved\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n5\n\nthan in the stable case. However, it can still be written using the law of the jumps of a\nsubordinator with Laplace exponent \u03c8 \u22121 .\n1.3. The pruned exploration process. In fact the dislocation measure is computed by\nstudying the evolution of a tagged fragment, for example the one that contains the root of\nthe CRT. Therefore, it is natural to consider first the exploration process of the fragment\ncontaining the root at time \u03b8. The pruned exploration process, \u03c1\u0303 = (\u03c1\u0303t , t \u2265 0), is defined by\n\u03c1\u0303t = \u03c1Ct , where Ct = inf{r > 0; Ar \u2265 t} is the right continuous inverse of At , the Lebesgue\nmeasure of the set of individuals prior to t who belongs to the tagged fragment at time \u03b8\n(Section 4). The pruned process \u03c1\u0303 corresponds to the exploration process associated to the\ndashed height process of Figures 1 and 2. To get the law of the pruned exploration process\n(Section 6), we use a Poisson L\u00e9vy snake approach (Section 3) and we prove a special Markov\nproperty, Theorem 5.2 in Section 5, which is of independent interest. Notice this theorem\ndiffers from Proposition 4.2.3 in [10], or Proposition 7 in [8], where in both cases the exit\nmeasure is singular, whereas here it is absolutely continuous w.r.t. to the Lebesgue measure.\nEventually, using martingales, we get Theorem 6.1: the pruned exploration process \u03c1\u0303 is the\nexploration process associated to a L\u00e9vy process, X (\u03b8) , with Laplace exponent \u03c8 (\u03b8) defined\nby: for \u03bb \u2208 R+ ,\n\u03c8 (\u03b8) (\u03bb) = \u03c8(\u03bb + \u03b8) \u2212 \u03c8(\u03b8).\n\nThere exists other pruning procedure for Galton-Watson trees, see for example [11] and\nreferences therein.\nNotice that conditionally on the length of the excursion, the excursions of X and X (\u03b8) out\nof 0 are equally distributed (see Lemma 7.1). This property, as well as the special Markov\nproperty are essential to prove the fragmentation property. We also compute, see Proposition\n7.3 the joint law of \u03c3, the initial mass of the fragment, and \u03c3\u0303 the mass of the tagged fragment\nat time \u03b8, under the excursion measure.\n1.4. Organization of the paper. In Section 2, we recall the construction of the L\u00e9vy CRT\nand give the properties we shall use in this paper. Section 3 is devoted to the definition and\nsome properties of the L\u00e9vy Poisson snake. From this L\u00e9vy Poisson snake, we define in Section\n4 the pruned exploration process which corresponds to the tagged fragment that contains 0.\nThen, we introduce in Section 5 a special Markov property for the L\u00e9vy Poisson snake:\nTheorem 5.2 and Corollary 5.3. We compute in Section 6 the law of the pruned exploration\nprocess, see Theorem 6.1. Section 7 is then devoted to the study of some properties of\nthe pruned exploration process under the excursion measure. Eventually, we construct in\nSection 8, the fragmentation process associated to our L\u00e9vy Poisson snake and prove the\nfragmentation property, Theorem 8.3, and check there is no loss of mass, Proposition 8.8.\nIn Section 9, we identify completely the law of the fragmentation process by computing the\ndislocation measures, Theorem 9.1, and we recover the result of Miermont [18] for the stable\ncase in Corollary 9.3.\n2. L\u00e9vy snake: notations and properties\nWe recall here the construction of the L\u00e9vy continuous random tree (CRT) introduced\nin [15, 14] and developed later in [10]. We will emphasize on the height process and the\nexploration process which are the key tools to handle this tree. The results of this section\nare mainly extract from [10].\n\n\f6\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\n2.1. The underlying L\u00e9vy process. We consider a R-valued L\u00e9vy process (Xt , t \u2265 0) with\nno negative jumps, starting from 0. Its law is characterized by its Laplace transform: for\n\u03bb\u22650\ni\nh\nE e\u2212\u03bbXt = et\u03c8(\u03bb) ,\n\nwhere its Laplace exponent, \u03c8, is given by\nZ\n\u03c8(\u03bb) = \u03b10 \u03bb +\n\n(0,+\u221e)\n\nh\ni\n\u03c0(dl) e\u2212\u03bbl \u22121 + \u03bbl ,\n\nwith \u03b10 \u2265 0 and the L\u00e9vy measure \u03c0 is a positive \u03c3-finite measure on (0, +\u221e) such that\nZ\nZ\nl\u03c0(dl) = \u221e.\n(l \u2227 l2 )\u03c0(dl) < \u221e and\n(1)\n(0,1)\n\n(0,+\u221e)\n\nThe first assumption (with the condition \u03b10 \u2265 0) implies the process X does not drift to\ninfinity, while the second implies X is of infinite variation a.s.\nForR \u03bb \u2265 1/\u03b5 > 0, we have e\u2212\u03bbl \u22121 + \u03bbl \u2265 21 \u03bbl1{l\u22652\u03b5} , which implies that \u03bb\u22121 \u03c8(\u03bb) \u2265\n\u03b10 + (2\u03b5,\u221e) l \u03c0(dl). We deduce that\n\u03bb\n= 0.\n\u03bb\u2192\u221e \u03c8(\u03bb)\n\n(2)\n\nlim\n\nWe introduce some processes related to X. Let J = {s \u2265 0; Xs 6= Xs\u2212 }, the set of jumping\ntimes of X. For s \u2208 J , we denote by\n\u2206s = Xs \u2212 Xs\u2212\nP\nthe jump of X at time s and \u2206s = 0 otherwise. The random measure X = s\u2208J \u03b4s,\u2206s is a\nPoisson point process with intensity \u03c0(dl). Let I = (It , t \u2265 0) be the infimum process of X,\nIt = inf 0\u2264s\u2264t Xs , and let S = (St , t \u2265 0) be the supremum process, St = sup0\u2264s\u2264t Xs . We\nwill also consider for every 0 \u2264 s \u2264 t the infimum of X over [s, t]:\nIts = inf Xr .\ns\u2264r\u2264t\n\nThe point 0 is regular for the Markov process X \u2212 I, and \u2212I is the local time of X \u2212 I at\n0 (see [4], chap. VII). Let N be the associated excursion measure of the process X \u2212 I out\nof 0, and \u03c3 = inf{t > 0; Xt \u2212 It = 0} the length of the excursion of X \u2212 I under N. We will\nassume that under N, X0 = I0 = 0.\nSince X is of infinite variation, 0 is also regular for the Markov process S \u2212 X. The local\ntime, L = (Lt , t \u2265 0), of S \u2212 X at 0 will be normalized so that\n\u2212\u03b2SL\u22121\n\nE[e\n\nt\n\n] = e\u2212t\u03c8(\u03b2)/\u03b2 ,\n\nwhere L\u22121\nt = inf{s \u2265 0; Ls \u2265 t} (see also [4] Theorem VII.4 (ii)).\n2.2. The height process and the L\u00e9vy CRT. For each t \u2265 0, we consider the reversed\n(t)\nprocess at time t, X\u0302 (t) = (X\u0302s , 0 \u2264 s \u2264 t) by:\nX\u0302s(t) = Xt \u2212 X(t\u2212s)\u2212\n\n(t)\n\n(t)\n\nif\n\n0 \u2264 s < t,\n\nand X\u0302t = Xt . The two processes (X\u0302s , 0 \u2264 s \u2264 t) and (Xs , 0 \u2264 s \u2264 t) have the same law.\nLet \u015c (t) be the supremum process of X\u0302 (t) and L\u0302(t) be the local time at 0 of \u015c (t) \u2212 X\u0302 (t) with\nthe same normalization as L.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n7\n\nDefinition 2.1. There exists a process H = (Ht , t \u2265 0), called the height process, such that\n(t)\nfor all t \u2265 0, a.s. Ht = L\u0302t , and H0 = 0. Furthermore H is lower semi-continuous a.s. and\na.s. for all t\u2032 > t \u2265 0, the process H takes all the values between Ht and Ht\u2032 on the time\ninterval [t, t\u2032 ].\nThe height process (Ht , t \u2208 [0, \u03c3]) under N codes a continuous genealogical structure, the\nL\u00e9vy CRT, via the following procedure.\n(i) To each t \u2208 [0, \u03c3] corresponds a vertex at generation Ht .\n(ii) Vertex t is an ancestor of vertex t\u2032 if Ht = Ht,t\u2032 , where\n(3)\n\nHt,t\u2032 = inf{Hu , u \u2208 [t \u2227 t\u2032 , t \u2228 t\u2032 ]}.\n\nIn general Ht,t\u2032 is the generation of the last common ancestor to t and t\u2032 .\n(iii) We put d(t, t\u2032 ) = Ht + Ht\u2032 \u2212 2Ht,t\u2032 and identify t and t\u2032 (t \u223c t\u2032 ) if d(t, t\u2032 ) = 0.\nThe L\u00e9vy CRT coded by H is then the quotient set [0, \u03c3]/ \u223c, equipped with the distance\nd and the genealogical relation specified in (ii).\n2.3. The exploration process. The height process is in general not Markov. But it is a\nvery simple function of a measure-valued Markov process, the so-called exploration process.\nIf E is a polish space, let B(E) (resp. B+ (E)) be the set of real-valued measurable (resp.\nand non-negative) functions defined on E endowed with its Borel \u03c3-field, and let M(E) (resp.\nMf (E)) be the set of \u03c3-finite (resp. finite) measures on E, endowed with the topology of\nvague (resp. weak) convergence. For any measure \u03bc \u2208 M(E) and f \u2208 B+ (E), we write\nZ\nh\u03bc, f i = f (x) \u03bc(dx).\n\nThe exploration process \u03c1 = (\u03c1t , t \u2265 0) is a Mf (R+ )-valued process defined as follows: for\nevery f \u2208 B+ (R+ ),\nZ\nds Its f (Hs ),\nh\u03c1t , f i =\n[0,t]\n\nor equivalently\n(4)\n\n\u03c1t (dr) =\n\nX\n\n0<s\u2264t\n\n(Its \u2212 Xs\u2212 )\u03b4Hs (dr).\n\nXs\u2212 <Its\n\nIn particular, the total mass of \u03c1t is h\u03c1t , 1i = Xt \u2212 It .\nFor \u03bc \u2208 M(R+ ), we set\n(5)\n\nH(\u03bc) = sup Supp \u03bc,\n\nwhere Supp \u03bc is the closed support of \u03bc, with the convention H(0) = 0. We have\nProposition 2.2. Almost surely, for every t > 0,\n\u2022 H(\u03c1t ) = Ht ,\n\u2022 \u03c1t = 0 if and only if Ht = 0,\n\u2022 if \u03c1t 6= 0, then Supp \u03c1t = [0, Ht ].\n\u2022 \u03c1t = \u03c1t\u2212 + \u2206t \u03b4Ht , where \u2206t = 0 if t 6\u2208 J .\nIn the definition of the exploration process, as X starts from 0, we have \u03c10 = 0 a.s. To\nget the Markov property of \u03c1, we must define the process \u03c1 started at any initial measure\n\u03bc \u2208 Mf (R+ ).\n\n\f8\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nFor a \u2208 [0, h\u03bc, 1i], we define the erased measure ka \u03bc by\nka \u03bc([0, r]) = \u03bc([0, r]) \u2227 (h\u03bc, 1i \u2212 a),\n\nfor r \u2265 0.\n\nIf a > h\u03bc, 1i, we set ka \u03bc = 0. In other words, the measure ka \u03bc is the measure \u03bc erased by a\nmass a backward from H(\u03bc).\nFor \u03bd, \u03bc \u2208 Mf (R+ ), and \u03bc with compact support, we define the concatenation [\u03bc, \u03bd] \u2208\nMf (R+ ) of the two measures by:\n[\u03bc, \u03bd], f = \u03bc, f + \u03bd, f (H(\u03bc) + *) ,\n\nf \u2208 B+ (R+ ).\n\u0002\nEventually, we set for every \u03bc \u2208 Mf (R+ ) and every t > 0 \u03c1\u03bct = k\u2212It \u03bc, \u03c1t ]. We say that\n(\u03c1\u03bct , t \u2265 0) is the process \u03c1 started at \u03c1\u03bc0 = \u03bc, and write P\u03bc for its law. Unless there is an\nambiguity, we shall write \u03c1t for \u03c1\u03bct .\nProposition 2.3. The process (\u03c1t , t \u2265 0) is a c\u00e0d-l\u00e0g strong Markov process in Mf (R+ ).\nRemark 2.4. From the construction of \u03c1, we get that a.s. \u03c1t = 0 if and only if \u2212It \u2265 h\u03c10 , 1i\nand Xt \u2212 It = 0. This implies that 0 is also a regular point for \u03c1. Let (\u03c4s , s \u2265 0) be the\nright continuous inverse of \u2212I: \u03c4s = inf{t > 0; \u2212It > s}. We get the local time at 0 of \u03c1\u03bc ,\n(L0t , t \u2265 0), is given for t \u2265 0, by\nL0t = \u2212It + It\u2227\u03c4h\u03bc,1i .\n\nNotice that N is also the excursion measure of the process \u03c1 out of 0, and that \u03c3, the length\nof the excursion, is N-a.e. equal to inf{t > 0; \u03c1t = 0}.\nRemark 2.5. Recall (\u2206s , s \u2265 0) are the jumps of the process X. The process \u03c1 is adapted\nto the filtration generated by the process X, that is by the Poisson point process X , and\n\u03c10 , completed the usual way. From the construction of \u03c1, we get there exists a measurable\nfunction, \u0393, defined on M(R2+ ) \u00d7 Mf (R+ ) (endowed with its Borel \u03c3-field) taking values in\nMf (R+ ) (endowed with its Borel \u03c3-field), such that\n\u03c1t = \u0393(X 1[0,t]\u00d7R+ , \u03c10 ).\nOn the other hand, notice that a.s. the jumping times of \u03c1 are also the jumping times of X,\nand for s \u2208 J , we have \u03c1s ({Hs }) = \u2206s . We deduce that (\u2206u , u \u2208 (s, t]) is measurable w.r.t.\nthe \u03c3-field \u03c3(\u03c1u , u \u2208 [s, t]).\n2.4. The dual process and representation formula. We shall need the Mf (R+ )-valued\nprocess \u03b7 = (\u03b7t , t \u2265 0) defined by\nX\n\u03b7t (dr) =\n(Xs \u2212 Its )\u03b4Hs (dr).\n0<s\u2264t\n\nXs\u2212 <Its\n\nThe process \u03b7 is the dual process of \u03c1 under N (see Corollary 3.1.6 in [10]). We write (recall\n\u2206s = Xs \u2212 Xs\u2212 )\nX\n(6)\n\u03bat (dr) = \u03c1t (dr) + \u03b7t (dr) =\n\u2206s \u03b4Hs (dr).\n0<s\u2264t\n\nXs\u2212 <Ist\n\nWe recall the Poisson representation of (\u03c1, \u03b7) under N. Let N (dx dl du) be a Poisson point\nmeasure on [0, +\u221e)3 with intensity\ndx l\u03c0(dl)1[0,1] (u)du.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n9\n\nFor every a > 0, let us denote by Ma the law of the pair (\u03bca , \u03bda ) of finite measures on R+\ndefined by: for f \u2208 B+ (R+ )\nZ\n(7)\nh\u03bca , f i = N (dx dl du)1[0,a] (x)ulf (x),\nZ\n(8)\nh\u03bda , f i = N (dx dl du)1[0,a] (x)l(1 \u2212 u)f (x).\nWe eventually set M =\n\nR +\u221e\n0\n\nda e\u2212\u03b10 a Ma .\n\nProposition 2.6. For every non-negative measurable function F on Mf (R+ )2 ,\n\u0015 Z\n\u0014Z \u03c3\nF (\u03c1t , \u03b7t ) dt = M(d\u03bc d\u03bd)F (\u03bc, \u03bd),\nN\n0\n\nwhere \u03c3 = inf{s > 0; \u03c1s = 0} denotes the length of the excursion.\nWe recall Lemma 3.2.2 from [10], we shall use later.\nProposition 2.7. Let \u03c4 be an exponential variable of parameter \u03bb > 0 independent of X\ndefined under the measure N. Then, for every F \u2208 B+ (Mf (R+ )), we have\nZ\n\u22121\nN (F (\u03c1\u03c4 )1\u03c4 \u2264\u03c3 ) = \u03bb M(d\u03bc d\u03bd)F (\u03bc) e\u2212\u03c8 (\u03bb)h\u03bd,1i .\nIt is easy to deduce from this (see also the beginning of Section 3.2.2. [10]) that for \u03bb > 0\ni\nh\n(9)\nN 1 \u2212 e\u2212\u03bb\u03c3 = \u03c8 \u22121 (\u03bb).\n3. The L\u00e9vy Poisson snake\nAs in [1], we want to construct a Poisson snake in order to cut the L\u00e9vy CRT at its nodes.\nFor this, we will construct a consistent family (m\u03b8 = (m\u03b8t , t \u2265 0), \u03b8 \u2265 0) of measure-valued\nprocesses. For fixed \u03b8 and t, m\u03b8 will be a point-measure whose atoms mark the atoms of\n\u2032\nthe measure \u03c1t and such that the set of atoms of m\u03b8+\u03b8 contains those of m\u03b8 . To achieve\nthis, we attach to each jump of X a Poisson process indexed by \u03b8, with intensity equal to\nthis jump. In fact only the first jump of the Poisson processes will be necessary to build the\nfragmentation process.\nP\n3.1.\nP Definition and properties. Conditionally on X = s>0 \u03b4s,\u2206s , we consider a family\n( u>0 \u03b4Vs,u , s \u2208 J ) of independent Poisson point measures on R+ with respective intensity\n\u2206s 1{u>0} du. We define the M(R2+ )-valued process M = (Mt , t \u2265 0) by\nX\nX\n(10)\nMt (dr, dv) =\n(Its \u2212 Xs\u2212 )(\n\u03b4Vs,u (dv)) \u03b4Hs (dr).\n0<s\u2264t\n\nXs\u2212 <Its\n\nu>0\n\nRemark 3.1. The additional coefficient Its \u2212 Xs\u2212 is not very important and is only needed\nfor the process M to be right-continuous.\nLet \u03b8 > 0. For t \u2265 0, notice that\nMt (R+ \u00d7 [0, \u03b8]) \u2264\n\nX\n\n0<s\u2264t\n\n\u2206s \u03bes ,\n\n\f10\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nwith \u03bes = Card {u > 0; Vs,u \u2264 \u03b8}. In particular, we have for T > 0,\nX\n(11)\nsup Mt (R+ \u00d7 [0, \u03b8]) \u2264\n\u2206s \u03bes .\nt\u2208[0,T ]\n\n0<s\u2264T\n\nNotice the variable \u03bes are, conditionally on XP\n, independent and distributed\nas Poisson\nR random\nP\nvariables with parameter \u03b8\u2206s. We have E[ 0<s\u2264T \u2206s \u03bes |X ] = \u03b8 0<s\u2264T \u22062s . As (0,\u221e) (l2 \u2227\nP\nl)\u03c0(dl) is finite, this implies the quantity 0<s\u2264T \u22062s is finite a.s. In particular we have a.s.\nsup Mt (R+ \u00d7 [0, \u03b8]) < \u221e,\n\nt\u2208[0,T ]\n\nand Mt is a \u03c3-finite measure on R2+ . Notice that a.s.\n(12)\n\nMt (dr, dv) = \u03c1t (dr)Mt,r (dv),\n\nwhere Mt,r is a \u03c3-finite counting measure on R+ .\nWe call the process S = ((\u03c1t , Mt ), t \u2265 0) the L\u00e9vy Poisson snake started at \u03c10 = 0, M0 = 0.\nTo get the Markov property of the L\u00e9vy Poisson snake, we must define the process S started\nat any initial value (\u03bc, \u03a0) \u2208 S, where S is the set of pair (\u03bc, \u03a0) such that \u03bc \u2208 Mf (R+ ) and\n\u03a0(dr, dv) = \u03bc(dr)\u03a0r (dv), \u03a0r being \u03c3-finite measures on R+ , such that \u03a0(R+ \u00d7 [0, \u03b8]) < \u221e\nfor all \u03b8 \u2265 0. We set Ht\u03bc = H(k\u2212It \u03bc). Then, we define the process M \u03bc,\u03a0 = (Mt\u03bc,\u03a0 , t \u2265 0) by:\nfor \u03c6 \u2208 B+ (R2+ ),\nZ\nZ\n\u03bc,\u03a0\n\u03c6(r + Ht\u03bc , v)Mt (dr, dv).\n\u03c6(r, v)k\u2212It \u03bc(dr)\u03a0r (dv) +\nhMt , \u03c6i =\n(0,\u221e)\n\n(0,\u221e)\n\nWe shall write M for M \u03bc,\u03a0 . By construction and since \u03c1 is an homogeneous Markov process,\nthe L\u00e9vy Poisson snake S = (\u03c1, M ) is an homogeneous Markov process.\nWe now denote by P\u03bc,\u03a0 the law of the L\u00e9vy Poisson snake starting at 0 from (\u03bc, \u03a0), and\nby P\u2217\u03bc,\u03a0 the law of the L\u00e9vy Poisson snake killed when \u03c1 reaches 0. We deduce from (11),\nthat a.s.\n#\n\"\nX\n\u22062s + \u03a0(R+ \u00d7 [0, \u03b8]) < \u221e.\n(13)\nE\u03bc,\u03a0 sup Mt (R+ \u00d7 [0, \u03b8]) X \u2264 \u03b8\nt\u2208[0,T ]\n\n0<s\u2264T\n\nLet F = (Ft , t \u2265 0) be the filtration generated by S completed the\nP usual way.\nP Notice this\nfiltration is also generated by the processes (X ([0, t], *), t \u2265 0) and ( s\u2208J , s\u2264t u\u22650 \u03b4Vs,u , t \u2265\n0). In particular the filtration F is right continuous. And by construction, we have that \u03c1 is\nMarkovian with respect to F.\nProposition 3.2. The L\u00e9vy Poisson snake, S, is a c\u00e0d-l\u00e0g strong Markov process in S \u2282\nMf (R+ ) \u00d7 M(R2+ ).\nProof. We first check the process M is right continuous. Recall (12). We have by construction\na.s. for all t\u2032 > t,\nMt\u2032 (dr, dv) = k\u2212I t\u2032 \u03c1t (dr)Mt,r (dv) + \u03c1t\u2032 (dr)1{r>Ht,t\u2032 } Mt\u2032 ,r (dv),\nt\n\nwhere Ht,t\u2032 is defined by (3). Thanks to (11), we have, for \u03b8 > 0,\nZ\nX\n\u03c1t\u2032 (dr)1{r>Ht,t\u2032 } Mt\u2032 ,r ([0, \u03b8]) \u2264\n\u2206s \u03bes .\nR+\n\nt<s\u2264t\u2032\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n11\n\nIn particular this quantity decreases to 0 as t\u2032 \u2193 t a.s. By the properties of the exploration\nprocess, we recall that a.s. k\u2212I t\u2032 \u03c1t = \u03c1t\" , where t\" = inf{s \u2208 [t, t\u2032 ]; Ist = Itt\u2032 }. From the right\nt\ncontinuity of \u03c1, we deduce that a.s. for the vague convergence\nlim\nMt\u2032 = Mt .\n\u2032\nt \u2193t\n\nThis implies the right continuity of the process M for the vague topology on M(R2+ ).\nNow, we check the process M has left limits. Let t < t\u2032 . For r \u2208 [0, Ht,t\u2032 ], we have\nk\u2212I t\u2032 \u03c1t (dr)Mt,r = 1{r\u2264Ht,t\u2032 } \u03c1t\u2032 (dr)Mt\u2032 ,r , as well as\nt\n\nMt (dr, dv) = 1{r\u2264Ht,t\u2032 } \u03c1t\u2032 (dr)Mt\u2032 ,r (dv) + [\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)]Mt,r (dv).\nt\n\nIf \u03c1 is continuous at t\u2032 , then either \u03c1t\u2032 ({Ht\u2032 }) = 0 or Ht,t\u2032 = Ht\u2032 for t close enough to t\u2032 .\nIn particular, since limt\u2192t\u2032 Ht,t\u2032 = Ht\u2032 , we have limt\u2191t\u2032 1{r\u2264Ht,t\u2032 } \u03c1t\u2032 (dr) = \u03c1t\u2032 (dr). If \u03c1 is not\ncontinuous at t\u2032 , this implies that \u03c1t\u2032 (dr) = \u03c1t\u2032 \u2212 (dr) + \u2206t\u2032 \u03b4Ht\u2032 (dr) and for t close enough to\nt\u2032 , Ht,t\u2032 < Ht\u2032 . Then, we get limt\u2191t\u2032 1{r\u2264Ht,t\u2032 } \u03c1t\u2032 (dr) = \u03c1t\u2032 \u2212 (dr). In any case, we have a.s. for\nthe vague convergence\nlim\u2032 1{r\u2264Ht,t\u2032 } \u03c1t\u2032 (dr)Mt\u2032 ,r (dv) = \u03c1t\u2032 \u2212 (dr)Mt\u2032 ,r (dv).\nt\u2191t\n\nNow, we check that for the vague topology\nlim\u2032 [\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)]Mt,r (dv) = 0.\nt\u2191t\n\nt\n\nFor this purpose, we remark that\n\u0015\n\u0014Z\nZ\nE\u03bc,\u03a0\n[\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)](\u03c1t ({r}) + \u03b7t ({r}))\n[\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)]Mt,r ([0, \u03b8])|X = \u03b8\nt\nt\nR+\nR+\nZ\n[\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)]\n\u2264 \u03b8(h\u03c1t + \u03b7t , 1i)\n= \u03b8(h\u03c1t +\n\nR+\n\u03b7t , 1i)(\u2212Itt\u2032 ).\n\nt\n\nAs \u03c1 and \u03b7 are respectively c\u00e0d-l\u00e0g and c\u00e0g-l\u00e0d process, they are bounded over any finite\ninterval a.s. Since limt\u2191t\u2032 Itt\u2032 = 0, we deduce that\n\u0015\n\u0014Z\nlim\u2032 E\u03bc,\u03a0\n[\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)]Mt,r ([0, \u03b8])|X = 0.\nt\u2191t\n\nt\n\nR+\n\nThanks to (13) and Fatou's Lemma, we deduce that\nZ\nlim\u2032\n[\u03c1t (dr) \u2212 k\u2212I t\u2032 \u03c1t (dr)]Mt,r ([0, \u03b8]) = 0.\nt\u2191t\n\nt\n\nR+\n\nTherefore, we conclude that for vague topology,\nlim\u2032 Mt = Mt\u2032 \u2212 .\nt\u2191t\n\nWe deduce that for the vague topology on M(R2+ ), the process M is a.s. c\u00e0d-l\u00e0g. This\nimplies the process S is a.s. c\u00e0d-l\u00e0g.\nWe check the strong Markov property of S. Mimicking the proof of Proposition 1.2.3 in\n[10], and using properties of Poisson point measure, one gets that, for any F-stopping time\n\n\f12\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nT , we have a.s. for every t > 0,\ni\nh\n(T )\n\u03c1T +t = k\u2212I (T ) \u03c1T , \u03c1t\nt\n\n(T )\n\n(T )\n\nMT +t (dr, dv) = k\u2212I (T ) \u03c1t (dr)MT,r (dv) + Mt\nt\n\nI (T ) ,\n\n\u03c1(T )\n\n(dr + H(k\u2212I (T ) \u03c1T ), dv)\nt\n\nM (T )\n\nwhere\nand\nare the analogues of I, \u03c1 and M with X replaced by the shifted\nprocess X (T ) = (XT +t \u2212 XT , t \u2265 0). This implies the strong Markov property.\n\u0003\n3.2. Poisson representation of the snake. Notice that a.s. (\u03c1t , Mt ) = (0, 0) if and only\nif \u03c1t = 0. In particular, (0, 0) is a regular point for the L\u00e9vy Poisson snake, with associated\nlocal time (L0s , s \u2265 0). We still write N for the excursion measure of the L\u00e9vy Poisson snake\nout of (0, 0), with the same normalization as in Section 2.4.\nWe decompose the path of S under P\u2217\u03bc,\u03a0 according to excursions of the total mass of\n\u03c1 above its minimum, see Section 4.2.3 in [10]. More precisely let (\u03b1i , \u03b2i ), i \u2208 I be the\nexcursion intervals of the process h\u03c1, 1i above its minimum under P\u2217\u03bc,\u03a0 . For every i \u2208 I, we\ndefine hi = H\u03b1i and S i = (\u03c1i , M i ) by the formulas\nZ\ni\nf (x \u2212 hi )\u03c1(\u03b1i +t)\u2227\u03b2i (dx)\nh\u03c1t , f i =\n(hi ,+\u221e)\nZ\n\u03c6(x \u2212 hi , v)M(\u03b1i +t)\u2227\u03b2i (dx, dv).\nhMti , \u03c6i =\n(hi ,+\u221e)\u00d7[0,+\u221e)\n\nIt is easy to adapt Lemma 4.2.4. of [10] to get the following Lemma.\nX\nLemma 3.3. Let (\u03bc, \u03a0) \u2208 Mf (R+ ) \u00d7 M(R2+ ). The point measure\n\u03b4(hi ,S i ) is under P\u2217\u03bc,\u03a0\ni\u2208I\n\na Poisson point measure with intensity \u03bc(dr)N[dS].\n\n(\u03b8)\n\n3.3. The process m(\u03b8) . For \u03b8 \u2265 0, we define the M(R+ )-valued process m(\u03b8) = (mt , t \u2265 0)\nby\n(\u03b8)\n\nmt (dr) = Mt (dr, (0, \u03b8]).\n\n(14)\n\nWe make two remarks. We have for s > 0,\n\u2212\u03b8\n\nP\n\n\u2206s\n\n= e\u2212\u03b8h\u03bas ,1i .\nP\nNotice that for s \u2208 J , i.e. \u2206s > 0, we have Ms ({Hs }, dv) = \u2206s u\u22650 \u03b4Vs,u (dv), where\nP\nconditionally on X ,\nu\u22650 \u03b4Vs,u (dv) is a Poisson point measure with intensity \u2206s du. In\nparticular, we have\n(15)\n\nP0,0 (ms(\u03b8) = 0|X ) = e\n\n0<r\u2264s, Xs\u2212 <Its\n\n\u2212\u03b8\u2206s\n.\nP\u03bc,\u03a0 (m(\u03b8)\ns ({Hs }) > 0|X ) = P(Ms ({Hs } \u00d7 (0, \u03b8]) > 0|X ) = 1 \u2212 e\n\nFrom Poisson point measure properties, we get the following Lemma.\nX\nLemma 3.4. The pruned random measure X \u03b8 =\n1{m(\u03b8) ({H })>0} \u03b4s,\u2206s is a Poisson point\ns\u22650\n\ns\n\ns\n\nprocess with intensity\n(16)\n\nn\u03b8 (dl) = (1 \u2212 e\u2212\u03b8l )\u03c0(dl).\n\nWe shall use later the following property, which is a consequence of Poisson point measure\nproperties.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n13\n\nProposition 3.5. Let M \u03b8 = (Mt\u03b8 , t \u2265 0) be the measure-valued process defined by\nMt\u03b8 (dr, [0, a]) = Mt (dr, (\u03b8, \u03b8 + a]),\n\nfor all a \u2265 0.\n\nThen, given \u03c1, M \u03b8 is independent of M 1R+ \u00d7[0,\u03b8] and is distributed as M .\nEventually, the next Lemma on time reversibility can easily be deduced from Corollary\n3.1.6 of [10] and the construction of M .\nLemma 3.6. Under N, the processes ((\u03c1s , \u03b7s , 1{m(\u03b8) =0} ), s \u2208 [0, \u03c3]) and ((\u03b7(\u03c3\u2212s)\u2212 , \u03c1(\u03c3\u2212s)\u2212 ,\ns\n1{m(\u03b8)\n), s \u2208 [0, \u03c3]) have the same distribution.\n=0}\n(\u03c3\u2212s)\u2212\n\n4. The pruned exploration process\nLet us fix \u03b8 > 0. We shall write m for the process m(\u03b8) defined in the previous Section. We\ndefine the following continuous additive functional of the process ((\u03c1t , mt ), t \u2265 0): for t \u2265 0\nZ t\n1{ms =0} ds,\nAt =\n0\n\nand Ct = inf{r > 0; Ar > t} its right continuous inverse, with the convention that inf \u2205 = \u221e.\nNotice Ct is a F-stopping time for any t \u2265 0 and is finite a.s. from Corollary 4.2 below.\nWe define the pruned exploration process \u03c1\u0303 = (\u03c1\u0303t = \u03c1Ct , t \u2265 0) and the pruned L\u00e9vy\nPoisson snake S\u0303 = (\u03c1\u0303, M\u0303 ), where M\u0303 = (MCt , t \u2265 0). In particular the law of M\u0303 knowing \u03c1\u0303\nis the law of M knowing \u03c1 = \u03c1\u0303. Notice the process \u03c1\u0303, and thus the process S\u0303, is c\u00e0d-l\u00e0g. We\nalso set H\u0303t = HCt . Let F\u0303 = (F\u0303t , t \u2265 0) be the filtration generated by the pruned exploration\nprocess S\u0303 completed the usual way. In particular F\u0303t \u2282 FCt , where if \u03c4 is an F-stopping time,\nthen F\u03c4 is the \u03c3-field associated to \u03c4 .\nWe introduce the following Laplace exponent \u03c8 (\u03b8) defined for \u03bb \u2265 0 by\n(17)\n\n\u03c8 (\u03b8) (\u03bb) = \u03c8(\u03bb + \u03b8) \u2212 \u03c8(\u03b8).\n\nLemma 4.1. We have the following properties.\n\u22121\n\n(i) For \u03bb > 0, N[1 \u2212 e\u2212\u03bbA\u03c3 ] = \u03c8 (\u03b8) (\u03bb).\n(ii) N-a.e. 0 and \u03c3 are points of increase for A. More precisely, N-a.e. for all \u03b5 > 0, we\nhave A\u03b5 > 0 and A\u03c3 \u2212 A(\u03c3\u2212\u03b5)\u22280 > 0.\n(iii) N-a.e. the set {s; ms 6= 0} is dense in [0, \u03c3].\nBefore going into the proof of this Lemma, let us state two direct consequences. From\nexcursion decomposition, see Lemma 3.3, the second part of Lemma 4.1 implies the following\ncorollary.\nCorollary 4.2. For any initial measures \u03bc, \u03a0, P\u03bc,\u03a0 -a.s. the process (Ct , t \u2265 0) is finite and\nstarts at 0 if m0 = 0.\nWe define \u03c3\u0303 = inf{t > 0; \u03c1\u0303t = 0}. From the second part of Lemma 4.1, we get that\n\u03c3 = inf{t > 0; \u03c1t = 0} is a left increasing point of A (N-a.e. or P(\u03bc,\u03a0) -a.s., \u03bc 6= 0). Therefore,\nwe have limr\u2191A\u03c3 Cr = \u03c3. As \u03c1 is left continuous at \u03c3, we get that limr\u2191A\u03c3 \u03c1\u0303r = 0 which implies\nthat \u03c3\u0303 \u2264 A\u03c3 . Since \u03c3\u0303 \u2265 A\u03c3 , we get that N-a.e.\n(18)\n\n\u03c3\u0303 = A\u03c3 .\n\nThis equality holds also P(\u03bc,\u03a0) -a.s., for \u03bc 6= 0.\n\n\f14\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nProof of Lemma 4.1. We first prove (i). Let \u03bb > 0. Before computing v = N[1 \u2212 exp \u2212\u03bbA\u03c3 ],\nnotice that A\u03c3 \u2264 \u03c3 implies, thanks to (9), that v \u2264 N[1 \u2212 exp \u2212\u03bb\u03c3] = \u03c8 \u22121 (\u03bb) < +\u221e. We\nhave\n\u0015\n\u0015\n\u0014Z \u03c3\n\u0014Z \u03c3\nR\u03c3\ndAt E\u2217\u03c1t ,0 [e\u2212\u03bbA\u03c3 ] ,\ndAt e\u2212\u03bb t dAu = \u03bbN\nv = \u03bbN\n\u2212\u03bb\n\nR\u03c3\n\n0\nE\u2217\u03c1t ,0 [e\u2212\u03bbA\u03c3 ],\n\n0\ndAu\n\nits optional projection. In\nin the last equality by\nwhere we replaced e\norder to compute this last expression, we use the decomposition of S under P\u2217\u03bc,\u03a0 according\nto excursions of the total mass of \u03c1 above its minimum, see Lemma 3.3.\nP Using the same\nnotations as in this Lemma, notice that under P\u2217\u03bc,0 , we have A\u03c3 = A\u221e = i\u2208I Ai\u221e , with\nZ T\n1{Mti (R+ \u00d7[0,\u03b8])=0} dt.\n(19)\nAiT =\nt\n\n0\n\nBy Lemma 3.3, we get\n\nE\u2217\u03bc,0 [e\u2212\u03bbA\u03c3 ] = e\u2212h\u03bc,1iN[1\u2212exp \u2212\u03bbA\u03c3 ] = e\u2212vh\u03bc,1i .\nNow, for fixed t, recall (15). By conditioning with respect to X or to \u03c1 thanks to Remark\n2.5, we have\nhZ \u03c3\ni\nhZ \u03c3\ni\nhZ \u03c3\ni\n\u2212vh\u03c1t ,1i\n\u2212vh\u03c1t ,1i\nv = \u03bbN\n= \u03bbN\n= \u03bbN\ndAt e\ndt 1{mt =0} e\ndt e\u2212(v+\u03b8)h\u03c1t ,1i\u2212\u03b8h\u03b7t ,1i .\n0\n\n0\n\n0\n\nNow we use Proposition 2.6 to get\nZ +\u221e\nda e\u2212\u03b10 a Ma [e\u2212(v+\u03b8)h\u03bc,1i\u2212\u03b8h\u03bd,1i ]\nv=\u03bb\n0\nZ +\u221e\nn Z a Z 1 Z\n\u2212\u03b10 a\ndu\ndx\nda e\nexp \u2212\n=\u03bb\n(20)\n(21)\n\n=\u03bb\n\n+\u221e\n\nda exp\n0\n\n0\n\n0\n\n0\n\nZ\n\nn\n\n\u2212a\n\nv\n.\n=\u03bb\n\u03c8(\u03b8 + v) \u2212 \u03c8(\u03b8)\n\nZ\n\n1\n\n0\n\n(0,\u221e)\n\nio\nh\nl\u03c0(dl) 1 \u2212 e\u2212(v+\u03b8)ul\u2212\u03b8(1\u2212u)l\n\no\ndu \u03c8 \u2032 (\u03b8 + vu)\n\nwhere, for the third equality, we used\n(22)\n\n\u03c8 \u2032 (\u03bb) = \u03b10 +\n\nZ\n\n(0,\u221e)\n\n\u03c0(dl) l(1 \u2212 e\u2212\u03bbl ).\n\nNotice that if v = 0, then (20) implies v = \u03bb/\u03c8 \u2032 (\u03b8), which is absurd. Therefore we have\nv \u2208 (0, \u221e), and we can divide (21) by v to get \u03c8 (\u03b8) (v) = \u03bb. This proves (i).\nNow, we prove (ii). If we let \u03bb \u2192 \u221e in (i) and use that limr\u2192\u221e \u03c8 (\u03b8) (r) = +\u221e,Pthen we\nget that N[A\u03c3 > 0] = +\u221e. Notice that for (\u03bc, \u03a0) \u2208 S, we have under P\u2217\u03bc,\u03a0 , A\u221e = i\u2208I Ai\u221e ,\nwith Ai defined by (19). Thus Lemma 3.3 imply that if \u03bc 6= 0, then P\u2217\u03bc,\u03a0 -a.s. I is infinite\nand A\u221e > 0. Using the Markov property at time t of the snake under N, we get that for any\nt > 0, N-a.e. on {\u03c3 > t}, we have A\u03c3 \u2212 At > 0. This implies that \u03c3 is a point of increase of\nA N-a.e. By time reversibility, see Lemma 3.6, we also get that 0 is a point of increase of A\nN-a.e.\nR\nTo prove (iii), recall that (0,1) l\u03c0(dl) = +\u221e implies that J = {s \u2265 0; \u2206s > 0} is dense in\nR+ a.s. Moreover, for every t > r \u2265 0,\nX\n\u2206s = +\u221e a.s.\nr\u2264s\u2264t\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n15\n\nNow, by the properties of Poisson point measures, we have\ni\nh P\nP(\u2200s \u2208 [r, t], ms = 0) = E e\u2212 r\u2264s\u2264t \u2206s = 0\nwhich proves (iii).\n\n\u0003\n5. A special Markov property\nLet us fix \u03b8 > 0 and use the notations of the previous Section.\nIn order to define the excursion of the L\u00e9vy Poisson snake out of {s \u2265 0; ms = 0}, we\ndefine O as the interior of {s \u2265 0, ms 6= 0}.\nLemma 5.1. N-a.e. the open set O is non empty.\nProof. Thanks to Lemma 4.1, (iii), {s \u2265 0, ms 6= 0} is non empty. For any element, s, of\nthis set, there exists u \u2264 Hs such that ms ([0, u]) 6= 0 and \u03c1s ({u}) > 0. Then we consider\n\u03c4s = inf{t > s, \u03c1t ({u}) = 0}. By the right continuity of \u03c1, \u03c4s > s and clearly (s, \u03c4s ) \u2282 O\nN-a.e. Therefore O in non empty.\n\u0003\nS\nWe write O = i\u2208I (\u03b1i , \u03b2i ) and say that (\u03b1i , \u03b2i )i\u2208I are the excursions intervals of the L\u00e9vy\nPoisson snake S = (\u03c1, M ) out of {s \u2265 0, ms = 0}.\nNext we prove a special Markov property out of {s \u2265 0, ms = 0} under the excursion\nmeasure N. Using the right continuity of \u03c1 and the definition of M , we get that for i \u2208 I,\n\u03b1i > 0, \u03b1i \u2208 J , that is \u03c1\u03b1i ({H\u03b1i }) = \u2206\u03b1i , and M\u03b1i ([0, H\u03b1i ), [0, \u03b8]) = 0. For every i \u2208 I, let\nus define the measure-valued process S i = (\u03c1i , M i ) by: for every f \u2208 B+ (R+ ), \u03c6 \u2208 B+ (R2+ ),\nt \u2265 0,\nZ\ni\nf (x \u2212 H\u03b1i )\u03c1(\u03b1i +t)\u2227\u03b2i (dx)\nh\u03c1t , f i =\n[H\u03b1i ,+\u221e)\n\nhMti , \u03c6i =\n\nZ\n\n(H\u03b1i ,+\u221e)\u00d7[0,+\u221e)\n\n\u03c6(x \u2212 H\u03b1i , v)M(\u03b1i +t)\u2227\u03b2i (dx, dv).\n\nSince \u03c1i0 = \u03b4\u2206\u03b1i , with \u2206\u03b1i > 0, then for every t < \u03b2i \u2212 \u03b1i , the measure \u03c1it charges 0. As\nM0i = 0 we have for every t < \u03b2i \u2212 \u03b1i , Mti ({0} \u00d7 R+ ) = 0. We call \u2206\u03b1i the starting mass of\nS i.\nRecall F\u0303\u221e is the \u03c3-field generated by S\u0303 = ((\u03c1Ct , MCt ), t \u2265 0) and P\u2217\u03bc,\u03a0 (dS) denotes the\nlaw of the snake S started at (\u03bc, \u03a0) and stopped when \u03c1 reaches 0. For l \u2208 [0, +\u221e), we will\nwrite P\u2217l for P\u2217\u03b4l ,0 . Recall (16) and define the measure N by\nZ\nZ\n\u0011\n\u0010\n\u2217\n\u2212\u03b8l\nn(\u03b8) (dl)P\u2217l (dS).\nPl (dS) =\n\u03c0(dl) 1 \u2212 e\n(23)\nN(dS) =\n(0,\u221e)\n\n(0,+\u221e)\n\nIf Q is a measure on S and \u03c6 is a non-negative measurable function defined on a measurable\nspace R+ \u00d7 \u03a9 \u00d7 S, we denote by\nZ\nQ[\u03c6(u, \u03c9, *)] = \u03c6(u, \u03c9, S)Q(dS).\nS\n\nIn other words, the integration concerns only the third component of the function \u03c6.\nRecall the definition of \u03c3\u0303 given after Corollary 4.2.\n\n\f16\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nTheorem 5.2. (Special Markov property) Let \u03c6 be a non-negative measurable function defined\non R+ \u00d7 \u03a9 \u00d7 S such that t 7\u2192 \u03c6(t, \u03c9, S) is progressively F\u0303-measurable for any S \u2208 S. Then,\nwe have N-a.e.\n\"\n!\n#\n\u0012 Z \u03c3\u0303\ni\u0013\nh\nX\ni\n\u2212\u03c6(u,\u03c9,*)\n(24)\nN exp \u2212\n\u03c6(A\u03b1i , \u03c9, S )\ndu N 1 \u2212 e\n.\nF\u0303\u221e = exp \u2212\n0\n\ni\u2208I\n\nIn particular, the law of the excursion process\n\nX\ni\u2208I\n\n\u03b4(A\u03b1i ,S i ) , given F\u0303\u221e under N, is the law of\n\na Poisson point measure of intensity 1[0,\u03c3\u0303] (u) du N(dS).\nBefore going into the proof of this Theorem, we give a corollary we shall use later.\nX\nCorollary 5.3. The law of the excursion process\n\u03b4(A\u03b1i ,\u03c1\u03b1 \u2212 ,S i ) , given F\u0303\u221e , is the law of a\ni\n\ni\u2208I\n\nPoisson point measure of intensity 1[0,\u03c3\u0303] (u)du \u03b4\u03c1\u0303u (d\u03bc) N(dS).\n\nProof. This is a direct consequence of Theorem 5.2 and Lemma 5.5.\n\n\u0003\n\nThe rest of this Section is devoted to the proof of the special Markov property.\n5.1. A remark and notations. To begin with, let us remark that to prove Theorem 5.2,\nwe may only consider function \u03c6 satisfying the hypothesis of Theorem 5.2 and those two\nconditions:\n(h1 ) \u03c6(s, \u03c9, S) = 0 if the starting mass of S is less than \u03b7, that is h\u03c10 , 1i \u2264 \u03b7, for a fixed\npositive real number \u03b7.\n(h2 ) t 7\u2192 \u03c6(t, \u03c9, S) is continuous for all S \u2208 S a.s.\n\nIndeed if (24) holds for such functions then by monotone class Theorem and monotonicity it\nholds also for every function satisfying the hypothesis of Theorem 5.2. From now on, but for\nLemma 5.5, we fix \u03b7 > 0, and we assume the function \u03c6 satisfies the hypothesis of Theorem\n5.2 and (h1 ). We will assume (h2 ) only for Sections 5.6 and 5.7.\nLet \u03b5 < \u03b7 and let us define by induction (under the measure N) the following stopping\ntimes: T0\u03b5 = 0 and, for every integer k \u2265 0,\n\u03b5\nSk+1\n= inf {s > Tk\u03b5 , ms ({Hs }) > 0, \u03c1s ({Hs }) > \u03b5}\n\b\n\u03b5\n\u03b5\nTk+1\n= inf s > Sk+1\n, ms = 0\n\nwith the convention inf \u2205 = \u03c3. Let us then denote\n\nN\u03b5 = sup{k \u2208 N, Sk\u03b5 6= \u03c3}.\n\n(25)\n\nNotice N\u03b5 is finite N-a.e. as there is a finite number of jumps \u2206t > \u03b5.\nFor every k \u2264 N\u03b5 , we define the measure-valued process S k,\u03b5 = (\u03c1k,\u03b5 , M k,\u03b5 ) in the same\nway as the processes \u03c1i and M i : for every non-negative continuous functions f and \u03c6, and\nt \u2265 0,\nZ\nk,\u03b5\nf (x \u2212 HSk\u03b5 )\u03c1(Sk\u03b5 +t)\u2227Tk\u03b5 (dx)\nh\u03c1t , f i =\n[HS \u03b5 ,+\u221e)\nk\n\nhMtk,\u03b5 , \u03c6i\n\n=\n\nZ\n\n(HS \u03b5 ,+\u221e)\u00d7[0,+\u221e)\nk\n\n\u03c6(x \u2212 HSk\u03b5 , v)M(Sk\u03b5 +t)\u2227Tk\u03b5 (dx, dv).\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n17\n\n= \u03b4\u2206S \u03b5 and \u2206Sk\u03b5 \u2265 \u03b5 for k \u2208\nWe call \u2206Sk\u03b5 the starting mass of S k,\u03b5 . Notice that \u03c1k,\u03b5\n0\nk\n{1, . . . , N\u03b5 }. Notice also that N-a.e,\n[\n[\n(26)\nlim\n(Sk\u03b5 , Tk\u03b5 ) = (\u03b1i , \u03b2i ).\n\u03b5\u21920\n\ni\u2208I\n\nk\u2208N\n\n5.2. Approximation of the excursion process.\n\nLemma 5.4. N-a.e., we have for \u03b5 > 0 small enough\nX\n\n(27)\n\ni\u2208I\n\ni\n\n\u03c6(A\u03b1i , \u03c9, S ) =\n\nN\u03b5\nX\nk=2\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ).\n\nProof. Let I\u03b7 be the set of indexes i \u2208 I, such that the starting mass of S i is larger than \u03b7.\nBecause of (h1 ), we have\nX\nX\n\u03c6(A\u03b1i , \u03c9, S i ).\n\u03c6(A\u03b1i , \u03c9, S i ) =\ni\u2208I\n\ni\u2208I\u03b7\n\nLet \u03b5 < \u03b7. Then, for any i \u2208 I\u03b7 , there exists k \u2208 N\u2217 , such that S k,\u03b5 = S i .\nFurthermore, all the others excursions S k,\u03b5 which don't belong to {S i , i \u2208 I\u03b7 } either have a\nstarting mass less that \u03b7 (and thus \u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ) = 0), or have a starting mass greater that\n\u03b7 but mSk\u03b5 ([0, HSk\u03b5 )) > 0. But, as the set {s \u2265 0, \u2206s > \u03b7} is finite, there exists only a finite\nnumber of excursions S i which straddle a time s such that \u2206s > \u03b7. Therefore, the minimum\nover those excursions of their starting mass, say \u03b7 \u2032 , is positive a.s. and, if we choose \u03b5 < \u03b7 \u2032 ,\nthere are no excursions S k,\u03b5 with initial mass greater than \u03b7 which do not correspond to a\nS i.\nConsequently, if we choose \u03b5 < \u03b7 \u2227 \u03b7 \u2032 , we have\nX\ni\u2208I\n\n\u03c6(A\u03b1i , \u03c9, S i ) =\n\nN\u03b5\nX\nk=1\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ).\n\nNotice also, that because of Lemma 4.1 (iii), for \u03b5 > 0 small enough, the starting mass of\nS 1,\u03b5 is less than \u03b7. Therefore, we deduce that (27) holds N-a.e. for \u03b5 > 0 small enough.\n\u0003\nWe can now prove the next Lemma which gives Corollary 5.3.\nLemma 5.5. Let \u03c8 be a bounded non-negative measurable function defined on R+ \u00d7Mf (R+ )\u00d7\nS. N-a.e., we have\nX\nX\n\u03c8(A\u03b1i , \u03c1\u03b1i \u2212 , S i ) =\n\u03c6(A\u03b1i , \u03c9, S i ),\ni\u2208I\n\ni\u2208I\n\nwhere \u03c6(t, \u03c9, S) = \u03c8(t, \u03c1\u0303t (\u03c9), S).\n\nProof. First we assume that \u03c8(t, \u03bc, S) = 0 if the starting mass of S is less than \u03b7. The same\narguments as those used to prove Lemma 5.4 yields that N-a.e. for \u03b5 > 0 small enough, we\nhave\nN\u03b5\nX\nX\ni\n\u03c8(A\u03b1i , \u03c1\u03b1i \u2212 , S ) =\n\u03c8(ASk\u03b5 , \u03c1Sk\u03b5 \u2212 , S k,\u03b5 ).\ni\u2208I\n\nk=2\n\nNotice that by construction, \u03c1Sk\u03b5 \u2212 = \u03c1Tk\u03b5 and that mTk\u03b5 = 0. Using the strong Markov property\nat time Tk\u03b5 and the second part of Corollary 4.2, we deduce that N-a.e. for all k \u2208 N\u2217 ,\n\n(28)\n\nCAT \u03b5 = Tk\u03b5 .\nk\n\n\f18\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nTherefore, as ASk\u03b5 = ATk\u03b5 , we have N-a.e.\n\u03c1\u0303AS \u03b5 = \u03c1\u0303AT \u03b5 = \u03c1Tk\u03b5 = \u03c1Sk\u03b5 \u2212 .\nk\n\nk\n\nHence, we have that N-a.e. for \u03b5 > 0 small enough,\nX\ni\u2208I\n\ni\n\n\u03c8(A\u03b1i , \u03c1\u03b1i \u2212 , S ) =\n\nN\u03b5\nX\nk=2\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ),\n\nwith \u03c6(t, \u03c9, S) = \u03c8(t, \u03c1\u0303t (\u03c9), S). Now, we complete the proof using Lemma 5.4 and letting\n\u03b7 \u2193 0.\n\u0003\n5.3. A measurability result. We shall use later the next additive functional defined for\ns \u2265 0 by\nN\u03b5 Z s\nX\n\u03b5\n\u03b5\n(29)\nAs =\n1[Tk\u03b5 ,Sk+1\n] (u) du.\nk=0 0\n\nFor k \u2265 1, we consider the \u03c3-field F (\u03b5),k generated by the family of processes\n\u0011\n\u0010\n\u03b5 \u2212, s > 0\nS(Tl\u03b5 +s)\u2227Sl+1\n.\nl\u2208{0,...,k\u22121}\n\nNotice that for k \u2208\n(30)\n\nN\u2217\n\nF (\u03b5),k \u2282 FSk\u03b5 .\n\nLemma 5.6. For any \u03b5 > 0, k \u2208 N\u2217 , the function \u03c6(ASk\u03b5 , \u03c9, *) is F (\u03b5),k -measurable.\nProof. We set Cs\u03b5 the right continuous inverse of A\u03b5s and we define the filtration F\u0303 (\u03b5) =\n(\u03b5)\n(F\u0303t , t \u2265 0) generated by the process (SCs\u03b5 , s \u2265 0).\n\u03b5\n> A\u03b5t }.\nWe consider the counting process (Rt , t \u2265 0) defined by Rt = inf{k \u2265 0; Sk+1\n(\u03b5)\n(\u03b5)\n(\u03b5)\nConsider the filtration F (\u03b5) = (Ft , t \u2265 0), where Ft = F\u0303t \u2228 \u03c3(Rs , s \u2264 t). In particular\n(\u03b5)\nfor k \u2265 1, A\u03b5S \u03b5 = inf{t \u2265 0; Rt = k} is a F (\u03b5) -stopping time. Notice then that F (\u03b5),k = FA\u03b5 \u03b5 .\nk\n\nS\n\nk\n\nBy the monotone class Theorem, to prove the Lemma, it is enough to consider simple\nprocesses, \u03c6, defined by \u03c6(t, \u03c9, S) = g(S)Z1{r\u2264t} , where r \u2265 0, Z \u2208 F\u0303r , and g is a real\nmeasurable function defined on S. For k \u2208 N\u2217 , we have \u03c6(ASk\u03b5 , \u03c9, *) = gZ1{r\u2264AS \u03b5 } . Notice\nk\nthat\nA\u03b5Cr = inf{u > 0; Cu\u03b5 > Cr }\nZ Cu\u03b5\n1{ms =0} ds > r}\n= inf{u > 0;\n0\n\n= inf{u > 0;\n= inf{u > 0;\n\nCu\u03b5\n\nZ\n\nZ0 u\n0\n\n1{ms =0} dA\u03b5s > r}\n\n1{mC \u03b5 =0} dt > r},\nt\n\nwhere we used that A\u03b5 is the right continuous inverse of CS\u03b5 for the first equality, C is the\n\u03b5 ] for the third, and\nright continuous inverse of A for the second, {s; ms = 0} \u2282 k\u22650 [Tk\u03b5 , Sk+1\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n19\n\nthe change of variable t = A\u03b5s for the last. This gives that A\u03b5Cr is a F (\u03b5) -stopping time. By\n(\u03b5)\n\ncomposition of random change time, we also have F\u0303r \u2282 FA\u03b5 . Eventually, we have\nCr\n\n{r \u2264 ASk\u03b5 } = {r \u2264 ATk\u03b5 } = {Cr \u2264 Tk\u03b5 } = {A\u03b5Cr \u2264 A\u03b5T \u03b5 } = {A\u03b5Cr \u2264 A\u03b5S \u03b5 },\nk\n\nk\n\nwhere we used ASk\u03b5 = ATk\u03b5 for the first equality, (28) and the definition of C for the second,\nand similar properties for A\u03b5 for the two last ones. We deduce then that Z1{r\u2264AS \u03b5 } =\nZ1{A\u03b5C\n\n\u2264A\u03b5S \u03b5 }\nr\nk\n\nk\n\n(\u03b5)\n\nis measurable with respect to FA\u03b5 \u03b5 = F (\u03b5),k . This ends the proof of the Lemma.\nS\n\nk\n\n\u0003\n\n5.4. Computation of the conditional expectation of the approximation.\nLemma 5.7. For every F\u0303\u221e -measurable non-negative random variable Z, we have\n\"\n\nN Z exp \u2212\n\nN\u03b5\nX\nk=2\n\n!#\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 )\n\n\"\n\n=N Z\n\nN\u03b5\nY\n\nh\n\n\u2212\u03c6(AS \u03b5 ,\u03c9,*)\n\nN e\n\nk=2\n\nk\n\n#\ni\n\u03c10 > \u03b5 .\n\nProof. For every integer p \u2265 2, we consider a non-negative random variable Z of the form\n\u03b5\nZ = Z0 Z1 , where Z0 \u2208 F (\u03b5),p and Z1 \u2208 \u03c3(S(Tk\u03b5 +s)\u2227Sk+1\n\u2212 , s \u2265 0, k \u2265 p) are bounded\nnon-negative and\"such that N[Z0 ] < \u221e.\n!#\np\nX\nTo compute N Z exp \u2212\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ) , we first apply the strong Markov property\nk=2\n\nat time Tp\u03b5 . We obtain\n\"\n\nN Z exp \u2212\n\np\nX\nk=2\n\n\u03c6(ASk\u03b5 , \u03c9, S\n\nk,\u03b5\n\n!#\n\n)\n\n\"\n\n= N Z0 exp \u2212\n\np\nX\nk=2\n\n\u03c6(ASk\u03b5 , \u03c9, S\n\nk,\u03b5\n\n!\n\n)\n\nE\u2217\u03c1T \u03b5 ,0\np\n\n\u0002\n\n#\n\nZ1 ] .\n\nNotice that \u03c1Tp\u03b5 = \u03c1Sp\u03b5 \u2212 , and consequently \u03c1Tp\u03b5 is measurable with respect to FSp\u03b5 . So, when\nwe use the strong Markov property at time Sp\u03b5 , we get thanks to Lemma 5.6 and (30),\n\"\n\nN Z exp \u2212\n\np\nX\nk=2\n\n!#\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 )\n\"\n\n= N Z0 exp \u2212\n\np\u22121\nX\nk=2\n\n!\n\nh\n\n\u2212\u03c6(ASp\u03b5 ,\u03c9,*)\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ) E\u2217\u03c1p,\u03b5 ,0 e\n0\n\ni\n\n#\n\nE\u2217\u03c1T \u03b5 ,0 [Z1 ] .\np\n\n\u03b5\n, on N\u03b5 \u2265 p, the measure \u03c1p,\u03b5\nRecall p \u2265 2. Conditionally on FTp\u22121\n0 is a Dirac mass and,\nby the Poisson representation of Lemma 3.4, this mass is the first atom of the Poisson point\nmeasure X \u03b8 that lies in (\u03b5, +\u221e). Consequently, the mass of \u03c1p,\u03b5\n0 is distributed according\n\u03b8\nto the law n (dl | l > \u03b5). From Poisson point measure properties, notice that \u03c1p,\u03b5\n0 is also\nindependent of \u03c3(St , t < Sp\u03b5 ) and thus of F (\u03b5),p .\n\n\f20\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nTherefore, conditionally on N\u03b5 \u2265 p, \u03c1p,\u03b5\n0 is independent of Z0 , \u03c1Tp\u03b5 = \u03c1Sp\u03b5 \u2212 and, thanks to\nLemma 5.6 of \u03c6(ASp\u03b5 , \u03c9, *). So, by conditioning with respect to F (\u03b5),p , we get\n\"\n!#\np\nX\n(31) N Z exp \u2212\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 )\nk=2\n\n\"\n\n= N Z0 exp \u2212\n\np\u22121\nX\nk=2\n\n!\n\nh\n\n\u2212\u03c6(ASp\u03b5 ,\u03c9,*)\n\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 ) N e\n\n#\ni\n\u03c10 > \u03b5 E\u2217\u03c1T \u03b5 ,0 [Z1 ] .\np\n\n\u03b5\nRemark 5.8. From point Poisson measure property, notice that, conditionally on FTp\u22121\nand\n\u03b5\n\u03b5\n\u03b5\nN\u03b5 \u2265 p \u2265 2, ep = Sp \u2212 Tp\u22121 is an exponential random variable with parameter\nZ\n\u0010\n\u0011\n\u03b8\n\u03c0(dl) 1 \u2212 e\u2212\u03b8l .\n(32)\nn\u03b5 = n (l > \u03b5) =\n\n(\u03b5,+\u221e)\n\nAnd, conditionally on N\u03b5 and N\u03b5 \u2265 2, the random variables (e\u03b5k , k \u2208 {2, . . . , N\u03b5 }) are independent exponential random variables with parameter n\u03b5 .\nNow, using one more time the strong Markov property at time Tp\u03b5 , we get from (31)\n\"\n!#\np\nX\nN Z exp \u2212\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 )\nk=2\n\n!#\np\u22121\nh\ni\nX\n\u2212\u03c6(ASp\u03b5 ,\u03c9,*)\n= N ZN e\n\u03c10 > \u03b5 exp \u2212\n.\n\u03c6(ASk\u03b5 , \u03c9, S k,\u03b5 )\n\"\n\nk=2\n\nFrom monotone class Theorem, this equality holds also for any Z \u2208 F (\u03b5),\u221e non-negative.\n\u2212\u03c6(ASp\u03b5 ,\u03c9,*)\nThanks to Lemma 5.6, the non-negative random variable Z \u2032 = ZN[e\n|\u03c10 > \u03b5] is\n(\u03b5),\u221e\nmeasurable w.r.t. F\n. So, we may iterate the previous argument and eventually get that\nfor any non-negative random variable Z \u2208 F (\u03b5),\u221e , we have\n\"\n!#\n\" p\n#\np\ni\nX\nY h \u2212\u03c6(A \u03b5 ,\u03c9,*)\nk,\u03b5\nS\nk\nN Z exp \u2212\n=N Z\n\u03c6(ASk\u03b5 , \u03c9, S )\nN e\n\u03c10 > \u03b5 .\nk=2\n\nk=2\n\nLet p \u2192 +\u221e and notice that F\u0303\u221e \u2282\n\nF (\u03b5),\u221e\n\nto end the proof.\n\n\u0003\n\n5.5. An ancillary result. Recall (25) and (32) We prove the next result.\nLemma 5.9. There exists a positive sequence (\u03b5j , j \u2208 N\u2217 ) decreasing to 0, such that N-a.e.:\nN\u03b5 j\n= A\u03c3 .\n(i) lim\nj\u2192\u221e n\u03b5j\n(ii) For any g \u2208 B+ (R+ ) bounded continuous, we have\nN\n\n\u03b5j\nZ \u03c3\u0303\n1 X\nlim\ng(u) du.\ng(AS \u03b5j ) =\nj\u2192\u221e n\u03b5j\nk\n0\n\nk=2\n\nProof. Notice that {s; ms 6= 0} \u2282 O \u222a{s; \u2206s 6= 0} (see proof of Lemma 5.1). As {s; \u2206s 6= 0} is\ndiscrete, we have thanks to (26), that N-a.e. for all s \u2265 0, lim\u03b5\u21920 A\u03b5s = As where A\u03b5 is defined\nby (29). From Dini Theorem this convergence is uniform on [0, \u03c3] N-a.e. In particular, (ii)\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n21\n\nwill be proved once we proved (i) and that N-a.e. for any g \u2208 B+ (R+ ) bounded continuous,\nwe have\nN\u03b5j\nZ \u03c3\u0303\n1 X\n\u03b5\ng(u) du.\ng(A j\u03b5j ) =\n(33)\nlim\nSk\nj\u2192\u221e n\u03b5j\n0\nk=2\n\nFrom Remark 5.8, we see there exists a sequence of random variables (e\u03b5k , k \u2265 2), such that\nconditionally on N\u03b5 , they are independent exponential variables of parameter n\u03b5 (see (32))\nand\nN\u03b5\nX\n\u03b5\ne\u03b5k + (SN\n\u2212 TN\u03b5 \u03b5 ).\nA\u03b5\u03c3 = (S1\u03b5 \u2212 T0\u03b5 ) +\n\u03b5 +1\nk=2\nT0\u03b5 , so\n\nthat we have the compact notation A\u03b5\u03c3 =\n\u2212\n=\n\u2264 N\u03b5 .\nBecause of Lemma 4.1 (ii) and (iii) we have that N-a.e. lim\u03b5\u21930 e\u03b50 = lim\u03b5\u21930 e\u03b51 = 0. We\ndeduce that N-a.e.\nN\u03b5\nX\nlim\ne\u03b5k = lim A\u03b5\u03c3 = A\u03c3 .\n\nWe set e\u03b50 =\nP N\u03b5 \u03b5\nk=0 ek and\n\nS1\u03b5\n\n\u03b5\nSN\n\u2212 TN\u03b5 \u03b5 and e\u03b51\n\u03b5 +1\nP\nA\u03b5S \u03b5 = kl=1 e\u03b5l for k\nk\n\n\u03b5\u21930\n\n\u03b5\u21930\n\nk=2\n\nConditionally on N\u03b5 , the random variables (n\u03b5 e\u03b5k , k \u2265 2) are independent exponential\nvariables of parameter 1. The previous equality and the law of large numbers implies that\nN-a.e. for anypositive deterministic sequence (\u03b5j , j \u2208 N) that decreases to 0, and we obtain\n(i).\nTo get (33), we choose the sequence (\u03b5j , j \u2208 N) so that for some \u03b4 \u2208 (0, 1/3), we have\n+\u221e\nX\n\nn\u2212(1\u22123\u03b4)/2\n< +\u221e.\n\u03b5j\n\nj=1\n\nAs a consequence of (i), there exists a (random) integer J such that, if j \u2265 J,\nN\u03b5j \u2264 n1+\u03b4\n\u03b5j .\n\nNotice that to prove (33), it is enough to consider g bounded and Lipschitz. We have for\nj \u2265 J,\nN\n\nN\n\nN\n\nk=2\n\nk=2\n\nk=2 l=2\n\n\u03b5j\n\u03b5j\n\u03b5j\n\u0013\n\u0012\nk\nN\u03b5 \u03b5\n1 X X \u03b5j k \u2212 1\n1\n1 X\nk\n1 X\n\u03b5j\n\u2264 Cg\n+ Cg j (e1j +\n)\ng(A \u03b5j ) \u2212\ng\nel \u2212\nSk\nn\u03b5j\nn\u03b5j\nn\u03b5j\nn\u03b5j\nn\u03b5j\nn\u03b5j\nn\u03b5j\n\n\u2264 Cg Z(\u03b5j ) + Cg\n\nN\u03b5 j \u03b5 j\n1\n(e1 +\n)\nn\u03b5j\nn\u03b5j\n\nwhere Cg is the Lipschitz constant of g and\n1+\u03b4\n\nn\u03b5\nk\nX\n1 X\n(k \u2212 1)\nZ(\u03b5) =\n.\ne\u03b5l \u2212\nn\u03b5\nn\u03b5\nk=2\n\nl=2\n\nIn order to prove that limj\u2192\u221e Z(\u03b5j ) = 0, we compute the expectation of Z(\u03b5):\n#\n#\n\" k\n\" k\n1+\u03b4\nnX\nn1+\u03b4\n\u03b5\n\u03b5\nX\nX\n\u0002\n\u0003\n1 X\nk\n\u2212\n1\n1\nE Z(\u03b5) =\nn\u03b5 e\u03b5l \u2212 (k \u2212 1) .\ne\u03b5l \u2212\n= 2\nE\nE\nn\u03b5\nn\u03b5\nn\u03b5\nk=2\n\nl=1\n\nk=2\n\nl=2\n\n\f22\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nBut, as the law n\u03b5 e\u03b5l is the exponential law with parameter 1, we have\n\uf8ee\n!4 \uf8f9\nk\nX\nE\uf8f0\nn\u03b5 e\u03b5l \u2212 (k \u2212 1) \uf8fb = 6k(k \u2212 1).\nl=2\n\n\u0002\n\n\u0003\nThus, the quantity E Z(\u03b5) is bounded from above by\n\uf8ee\n!4 \uf8f91/4\n1+\u03b4\nnX\nn1+\u03b4\nk\n\u03b5\n\u03b5\nX\n\u221a\n1 X\n1\n\u03b5\n\uf8f0\n\uf8fb\nk \u2264 2n3(1+\u03b4)/2\u22122\n\u2264 2n\u2212(1\u22123\u03b4)/2\n.\n\u2212\n(k\n\u2212\n1)\nE\nn\ne\n\u2264\n2\n\u03b5\n\u03b5\n\u03b5\nl\nn2\u03b5\nn2\u03b5\nk=2\nl=2\nk=2\nP\nIn particular, the series j\u22651 E[Z(\u03b5j )] converges and as Z(\u03b5) is non-negative, this implies\nP\nthe series j\u22651 Z(\u03b5j ) converges a.s. and thus N-a.e. we have\nlim Z(\u03b5j ) = 0.\n\nj\u2192+\u221e\n\nThe convergence of the Riemann's sums gives that N-a.e.\nN\u03b5j \u0012\nN\u03b5j \u0012\n\u0013\n\u0013\nZ A\u03c3\nZ 1\nN\u03b5 j k\nN\u03b5 j 1 X\n1 X\nk\ng(u) du.\ng(uA\u03c3 ) du =\ng\ng\n=\n\u2212\u2192 A\u03c3\nn\u03b5j\nn\u03b5j\nn\u03b5j N\u03b5j\nn\u03b5j N\u03b5j j\u2192+\u221e\n0\n0\nk=2\n\nk=2\n\nThen we deduce (33) from (18), and this finishes the proof.\n\n\u0003\n\n5.6. Computation of the limit.\nLemma 5.10. We assume (h2 ), that is t 7\u2192 \u03c6(t, \u03c9, S) is continuous for all S \u2208 S. We have,\nfor the sequence (\u03b5j , j \u2208 N\u2217 ) from Lemma 5.9, that N-a.e.\nN\u03b5j\n\nlim\n\nj\u2192\u221e\n\nY\n\nk=2\n\n\u0014\n\n\u2212\u03c6(A\n\nN e\n\nS\n\n\u03b5j\nk\n\n,\u03c9,*)\n\n\u03c10 > \u03b5j\n\n\u0015\n\n\u0012 Z\n= exp \u2212\n\n0\n\n\u03c3\u0303\n\nh\n\n\u2212\u03c6(u,\u03c9,*)\n\ndu N 1 \u2212 e\n\ni\u0013\n\n.\n\nProof. For any sequence (\u03c6k , k \u2208 N) of non-negative measurable function on S, such that\n\u03c6k (S) = 0 if h\u03c10 , 1i \u2264 \u03b7, we have for \u03b5 \u2208 (0, \u03b7),\n\u0013\nN\u03b5 \u0012\nN\u03b5\nh\ni Y\nY\nN [1 \u2212 e\u2212\u03c6k ]\n\u2212\u03c6k\n.\n1\u2212\n\u03c10 > \u03b5 =\nN e\nN[\u03c10 > \u03b5]\nk=2\n\nk=2\n\nRecall (32), and notice that N [1 \u2212 e\u2212\u03c6k ] \u2264 N[\u03c10 \u2265 \u03b7] \u2264 N[\u03c10 > \u03b5] = n\u03b5 and lim\u03b5\u21930 n\u03b5 = +\u221e.\nSince log(1 \u2212 x) = \u2212x + h(x), with |h(x)| \u2264 x2 for x \u2208 [0, 1/2], we have for \u03b5 small enough\nsuch that N[\u03c10 > \u03b7]/n\u03b5 \u2264 1/2,\n\u0012\n\u0013\n\u0013!\nN\u03b5\nN\u03b5 \u0012\nX\nY\nN [1 \u2212 e\u2212\u03c6k ]\nN [1 \u2212 e\u2212\u03c6k ]\nln 1 \u2212\n= exp\n1\u2212\nn\u03b5\nn\u03b5\nk=2\nk=2\n!\n!\nN\u03b5\nN\u03b5\nX\n\u0003\n\u0002\n1 X\n= exp \u2212\nh(N[1 \u2212 e\u2212\u03c6k ]/n\u03b5 ) ,\nN 1 \u2212 e\u2212\u03c6k exp\nn\u03b5\nk=2\nk=2\nP N\u03b5\n2\n2\n\u2212\u03c6\nand k=2 h(N [1 \u2212 e k ] /n\u03b5 ) \u2264 N[\u03c10 > \u03b7] N\u03b5 /n\u03b5 . From the hypothesis on \u03c6, we can take\n\u03c6k = \u03c6(AS \u03b5j , \u03c9, *). Then, we deduce from Lemma 5.9 (i), that N-a.e.\nk\n\nN\u03b5j\n\u0011\n\u0010 h\nX\n\u2212\u03c6(A \u03b5j ,\u03c9,*) i\nS\nk\n/n\u03b5j = 0.\nh N 1\u2212e\nlim\n\nj\u2192\u221e\n\nk=2\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n23\n\n\u0002\n\u0003\nSince (h2 ) is satisfied, we deduce that t 7\u2192 N 1 \u2212 e\u2212\u03c6(t,\u03c9,*) is continuous. We get from\nLemma 5.9 (ii), that N-a.e.\nN\n\n\u03b5j\n\u0014\n\u0015 Z \u03c3\u0303 h\ni\n\u2212\u03c6(A \u03b5j ,\u03c9,*)\n1 X\nS\nk\nN 1\u2212e\nN 1 \u2212 e\u2212\u03c6(u,\u03c9,*) du.\n=\nlim\nj\u2192\u221e n\u03b5j\n0\n\nk=2\n\nThis finishes the proof of the Lemma.\n\n\u0003\n\n5.7. Proof of Theorem 5.2. Let Z \u2208 F\u0303\u221e non-negative such that N[Z] < \u221e. Let \u03c6\nsatisfying hypothesis of Theorem 5.2, (h1 ) and (h2 ). We have\n\uf8ee\n\uf8eb N\n\uf8f6\uf8f9\n\"\n!#\n\u03b5j\nX\nX\nN Z exp \u2212\n\u03c6(A\u03b1i , \u03c9, S i )\n= lim N \uf8f0Z exp \uf8ed\u2212\n\u03c6(AS \u03b5j , \u03c9, S k,\u03b5j )\uf8f8\uf8fb\ni\u2208I\n\nj\u2192\u221e\n\n\uf8ee\n\n= lim N \uf8f0Z\nj\u2192\u221e\n\n\u0014\n\nk\n\nk=2\n\nN\u03b5j\n\nY\n\n\u0014\n\n\u2212\u03c6(A\n\nN e\n\nk=2\n\n\u0012 Z\n= N Z exp \u2212\n\n0\n\n\u03c3\u0303\n\nh\n\n\u03b5j\nS\nk\n\n,\u03c9,*)\n\n\uf8f9\n\n\u03c10 > \u03b5j \uf8fb\n\n\u2212\u03c6(u,\u03c9,*)\n\nN 1\u2212e\n\n\u0015\n\ni\n\ndu\n\n\u0013\u0015\n\n,\n\nwhere we used Lemma 5.4 and dominated convergence for the first equality, Lemma 5.7 for the\nsecond equality, Lemma 5.10 and dominated convergence for the last equality. By monotone\nclass Theorem (resp. monotonicity), we \u0010can remove hypothesis (h2\u0011) (resp. (h1 )). To ends\nR \u03c3\u0303 \u0002\n\u0003\nthe proof, it suffices to remark that exp \u2212 0 N 1 \u2212 e\u2212\u03c6(u,\u03c9,*) du is F\u0303\u221e -measurable and\nso this is N-a.e. equal to the conditional expectation (i.e. the left hand side term of (24)).\n6. Law of the pruned exploration process\nRecall notations of Section 3 and definition (14). We still fix \u03b8 > 0 and write m for m(\u03b8) .\nNotice that \u03c8 (\u03b8) = \u03c8(\u03b8 + *) \u2212 \u03c8(\u03b8), defined by (17) is the Laplace exponent of a L\u00e9vy process,\nwith L\u00e9vy measure satisfying (1). The exploration process, \u03c1(\u03b8) , of this L\u00e9vy process is thus\nwell defined.\nThe aim of this section is to prove the following Theorem.\nTheorem 6.1. For every finite measure \u03bc, the law of the pruned process \u03c1\u0303 under P\u03bc,0 is the\nlaw of the exploration process \u03c1(\u03b8) associated to a L\u00e9vy process with Laplace exponent \u03c8 (\u03b8)\nunder P\u03bc .\nThe next Corollary is a direct consequence of this Theorem.\nCorollary 6.2. The excursion measure of \u03c1\u0303 outside 0 is equal to the excursion measure of\n\u03c1(\u03b8) outside 0.\n6.1. A martingale problem for \u03c1\u0303. In this section, we shall compute the law of the total\nmass process (h\u03c1\u0303t\u2227\u03c3\u0303 , 1i, t \u2265 0) under P\u03bc = P\u03bc,0 , using martingale problem characterization.\nWe will first show how a martingale problem for \u03c1 can be translated into a martingale\nproblem for \u03c1\u0303. (In a forthcoming paper, we shall compute the infinitesimal generator of \u03c1\nfor exponential functionals.) Unfortunately, we were not able to use standard techniques of\nrandom time change,\n\u0002 as developed in Chapter\n\u0003 6 of [12] and used for Poisson snake in [1],\nmainly because t\u22121 E\u03bc [f (\u03c1t )1{mt =0} ] \u2212 f (\u03bc) does not have a limit as t goes down to 0, even\nfor exponential functionals.\n\n\f24\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\n\u0014Z\n\n\u03c3\n\n\u0015\n\nLet F, K \u2208 B(Mf (R+ )) bounded such that, for any \u03bc \u2208 Mf (R+ ), E\u03bc\n|K(\u03c1s )| ds <\n0\nR t\u2227\u03c3\n\u221e and M\n\u0002 t = F (\u03c1t\u2227\u03c3\u0003) \u2212 0 K(\u03c1s ), for t \u2265 0, define an F-martingale. In particular, notice\nthat E\u03bc supt\u22650 |Mt | < \u221e. Thus, we can define for t \u2265 0,\nNt = E\u2217\u03bc [MCt |F\u0303t ].\n\nProposition 6.3. The process N = (Nt , t \u2265 0) is an F\u0303-martingale. And we have for all\n\u03bc \u2208 Mf (R+ ), P\u03bc -a.s.\nZ \u03c3\u0303 Z\n\u0011\n\u0010\n1 \u2212 e\u2212\u03b8l \u03c0(dl) |F ([\u03c1\u0303u , l\u03b40 ]) \u2212 F (\u03c1\u0303u )| < \u221e,\ndu\n(0,\u221e)\n\n0\n\nand the representation formula for Nt :\nZ\nZ t\u2227\u03c3\u0303\ndu K(\u03c1\u0303u ) +\n(34) Nt = F (\u03c1\u0303t\u2227\u03c3\u0303 ) \u2212\n\n(0,\u221e)\n\n0\n\n!\n\u0011\n\u0010\n\u0011\n\u0010\n\u2212\u03b8l\n\u03c0(dl) F ([\u03c1\u0303u , l\u03b40 ]) \u2212 F (\u03c1\u0303u )\n1\u2212e\n.\n\nProof. Notice that N = (Nt , t \u2265 0) is an F\u0303-martingale. Indeed, we have for t, s \u2265 0,\nE\u03bc [Nt+s |F\u0303t ] = E\u03bc [E\u03bc [MCt+s |F\u0303t+s ]|F\u0303t ]\n= E\u03bc [MCt+s |F\u0303t ]\n\n= E\u03bc [E\u03bc [MCt+s |FCt ]|F\u0303t ]\n\n= E\u03bc [MCt |F\u0303t ],\n\nwhere we used the stopping time Theorem for the last equality. To compute E\u03bc [MCt |F\u0303t ], we\nwrite MCt = Nt\u2032 \u2212 MC\u2032 t , where for u \u2265 0,\nZ u\u2227\u03c3\n\u2032\nK(\u03c1s )1{ms 6=0} ds.\nMu =\n0\n\nRecall that C0 = 0 P\u03bc -a.s. by Corollary 4.2. In particular, we get\nZ Ct \u2227\u03c3\nK(\u03c1s )1{ms =0} ds\nNt\u2032 = F (\u03c1Ct \u2227\u03c3 ) \u2212\n= F (\u03c1\u0303t\u2227\u03c3\u0303 ) \u2212\n= F (\u03c1\u0303t\u2227\u03c3\u0303 ) \u2212\n\nZ\n\n0\nCt \u2227\u03c3\n\nK(\u03c1s ) dAs\n\n0\n\nZ\n\nt\u2227\u03c3\u0303\n\nK(\u03c1\u0303u ) du,\n\n0\n\nwhere we used the time change u = As for the last equality. In particular, as \u03c3\u0303 is an F\u0303 stopping time, we get that the process (Nt\u2032 , t \u2265 0) is F\u0303 -adapted. Since Nt = Nt\u2032 \u2212 E\u03bc[MC\u2032 t |F\u0303t ],\nwe are left with the computation of E\u03bc [MC\u2032 t |F\u0303t ].\nIn Section 5, the arguments are given under the excursion measure, but they can readily\nbe extended under P\u03bc or P\u2217\u03bc,0 . In particular, the result of Corollary 5.3 holds also under P\u03bc\nor P\u2217\u03bc,0 . We keep the notations of Section 5. We consider (\u03c1i , mi ), i \u2208 I the excursions of\nthe process (\u03c1, m) outside {s, ms = 0} before \u03c3 and let (\u03b1i , \u03b2i ), i \u2208 I be the corresponding\ninterval excursions. In particular we can write\nZ Ct \u2227\u03c3\nX\n|K(\u03c1s )| 1{ms 6=0} ds =\n\u03a6(A\u03b1i , \u03c1\u03b1i \u2212 , \u03c1i ),\n0\n\ni\u2208I\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\nwith\n\u03a6(u, \u03bc, \u03c1) = 1{u<t}\n\nZ\n\n25\n\n\u03c3(\u03c1)\n\n|K([\u03bc, \u03c1s ])| ds,\n\n0\n\nwhere \u03c3(\u03c1) = inf{v > 0; \u03c1v = 0}. We deduce from Corollary 5.3, that P\u03bc -a.s.\n\u0014Z Ct \u2227\u03c3\n\u0015 Z \u03c3\u0303\n(35)\nE\u03bc\n|K(\u03c1s )| 1{ms 6=0} ds|F\u0303\u221e =\n1{u<t} K\u0302(\u03c1\u0303u ) du,\n0\n\n0\n\nwith, K\u0302 defined for \u03bd \u2208 Mf (R+ ) by\n\u0014Z\nZ\n\u0011\n\u0010\n\u2212\u03b8l\n\u03c0(dl) El\n1\u2212e\nK\u0302(\u03bd) =\n\n\u03c3\n\n0\n\n(0,\u221e)\n\n\u0015\n\n|K([\u03bd, \u03c1s ])| ds .\n\n\u0002R \u03c3\n\u0003\nSince E\u03bc 0 |K(\u03c1s )| ds is finite, we deduce that P\u03bc -a.s. du-a.e. 1{u<\u03c3\u0303} K\u0302(\u03c1\u0303u ) is finite.\nWe define K\u0303 \u2208 B(Mf (R+ )) for \u03bd \u2208 Mf (R+ ) by\n\u0015\n\u0014Z \u03c3\nZ\n\u0011\n\u0010\n\u2212\u03b8l\nK([\u03bd, \u03c1s ]) ds ,\n\u03c0(dl) El\n1\u2212e\n(36)\nK\u0303(\u03bd) =\n0\n\n(0,\u221e)\n\nif K\u0302(\u03bd) < \u221e, or by K\u0303(\u03bd) = 0 if K\u0302(\u03bd) = +\u221e. In particular, we have |K\u0303(\u03bd)| \u2264 K\u0302(\u03bd) and\nR \u03c3\u0303\nP\u03bc -a.s. 0 |K\u0303(\u03c1\u0303u )| du is finite. Using Corollary 5.3 once again (see (35)), we get that P\u03bc -a.s.,\n(37)\n\nh\n\nE\u03bc MC\u2032 t |F\u0303\u221e\n\ni\n\n= E\u03bc\n\n\u0014Z\n\nCt \u2227\u03c3\n\n\u0015\n\nK(\u03c1s )1{ms 6=0} ds|F\u0303\u221e =\n\n0\n\nZ\n\nt\u2227\u03c3\u0303\n\nK\u0303(\u03c1\u0303u ) du.\n\n0\n\n\u0014Z\n\n\u03c3\n\n\u0015\n\nK([\u03bd, \u03c1s ]) ds is equal\nTo rewrite K\u0303, we notice that, for \u03bd with compact support, El\n0\n\u0003\n\u0002R \u03c4l\nto E[\u03bd,l\u03b40 ] 0 K(\u03c1s ) ds , where \u03c4l = inf{s; \u2212Is \u2265 l} is an F-stopping time. Notice that\nP[\u03bd,l\u03b40 ] -a.s. \u03c4l \u2264 \u03c3 and \u03c1\u03c4l = \u03bd. We deduce from the stopping time Theorem that\n\u0015\n\u0014Z \u03c4l\n(38)\nE[\u03bd,l\u03b40 ]\nK(\u03c1s ) ds = E[\u03bd,l\u03b40] [\u2212M\u03c4l + F (\u03c1\u03c4l )] = \u2212F ([\u03bd, l\u03b40 ]) + F (\u03bd).\n0\n\nTherefore, we get from (36) and (37)\nZ t\u2227\u03c3\u0303 Z\ni\nh\n\u2032\nE\u03bc MCt |F\u0303\u221e = \u2212\n0\n\n(0,\u221e)\n\n\u0010\n\u0011\n\u0010\n\u0011\n1 \u2212 e\u2212\u03b8l \u03c0(dl) F ([\u03c1\u0303u , l\u03b40 ]) \u2212 F (\u03c1\u0303u ) du.\n\ni\nEventually, as Nt = Nt\u2032 \u2212 E\u03bc MC\u2032 t |F\u0303\u221e , this gives (34).\nh\n\nTo conclude, notice that from (38), the definition of K\u0302 and (35), we have\nZ \u03c3\u0303 Z\n\u0011\n\u0010\n1 \u2212 e\u2212\u03b8l \u03c0(dl) |F ([\u03c1\u0303u , l\u03b40 ]) \u2212 F (\u03c1\u0303u )| du\n0\n\n(0,\u221e)\n\n\u2264\n\nZ\n\nZ\n\n\u03c3\u0303\n\n0\n\u03c3\u0303\n\nZ\n\n(0,\u221e)\n\n\u0010\n\n\u2212\u03b8l\n\n1\u2212e\n\n\u0011\n\n\u03c0(dl)E[\u03c1\u0303u ,l\u03b40 ]\n\nK\u0302(\u03c1\u0303u ) du\n\u0014Z \u03c3\n\u0015\n= E\u03bc\n|K(\u03c1s )| 1{ms 6=0} ds|F\u0303\u221e ,\n=\n\n0\n\n0\n\n\u0014Z\n\n0\n\n\u03c4l\n\n\u0015\n\n|K(\u03c1s )| ds du\n\n\f26\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nwhich is finite P\u03bc -a.s. since E\u03bc\n\n\u0014Z\n\n\u03c3\n0\n\n\u0015\n\n|K(\u03c1s )| ds < \u221e.\n\n\u0003\n\nCorollary 6.4. Let \u03bc \u2208 Mf (R+ ). The law of the total mass process (h\u03c1\u0303t , 1i, t \u2265 0) under\nP\u2217\u03bc,0 is the law of the total mass process of \u03c1(\u03b8) under P\u2217\u03bc .\nProof. Let X = (Xt , t \u2265 0) be under P\u2217x , a L\u00e9vy process with Laplace transform \u03c8 started\nat x > 0 and stopped when it reached 0. Under P\u03bc , the total mass process (h\u03c1t\u2227\u03c3 , 1i, t \u2265 0)\nis distributed as X under P\u2217h\u03bc,1i . Let c > 0. From L\u00e9vy processes theory, we know that the\nRt\nprocess e\u2212cXt \u2212\u03c8(c) 0 e\u2212cXs ds, for t \u2265 0 is a martingale. We deduce from the stopping\ntime Theorem that M = (Mt , t \u2265 0) is an F-martingale under P\u03bc , where Mt = F (\u03c1t\u2227\u03c3 ) \u2212\nR t\u2227\u03c3\nK(\u03c1s ) ds, with F, K \u2208 B(Mf (R+ )) defined by F (\u03bd) = e\u2212ch\u03bd,1i for \u03bd \u2208 Mf (R+ ) and\n0\nK = \u03c8(c)F . Notice K \u2265 0. We have by dominated convergence and monotone convergence.\n\u0015\n\u0014Z \u03c3\n\u2212ch\u03bc,1i\n\u2212ch\u03c1\u03c3 ,1i\n\u2212ch\u03c1s ,1i\ne\n= lim E\u03bc [Mt ] = E\u03bc [e\n] \u2212 \u03c8(c)E\u03bc\ne\nds .\nt\u2192\u221e\n\n0\n\nThis implies that, for any \u03bc \u2208 Mf (R+ ), E\u03bc\n\n\u0014Z\n\ncompact support, we have\nZ\n\u0011\n\u0010\n1 \u2212 e\u2212\u03b8l \u03c0(dl) |F ([\u03bd, l\u03b40 ]) \u2212 F (\u03bd)|\n(0,\u221e)\nZ\n=\n\n\u03c3\n\n0\n\n\u0015\n\n|K(\u03c1s )| ds is finite. For \u03bd \u2208 Mf (R+ ) with\n\n\u0011\n\u0011\n\u0010\n1 \u2212 e\u2212\u03b8l \u03c0(dl) e\u2212ch\u03bd,1i \u2212 e\u2212ch\u03bd,1i\u2212cl\n(0,\u221e)\nZ\n\u0011\n\u0011\u0010\n\u0010\n\u2212ch\u03bd,1i\n1 \u2212 e\u2212\u03b8l 1 \u2212 e\u2212cl \u03c0(dl)\n=e\n\u0010\n\n(0,\u221e)\n\n\u0010\n\n\u0011\n= e\u2212ch\u03bd,1i \u03c8(c) \u2212 \u03c8 (\u03b8) (c) .\n\nIn particular, we have\nZ\n\u0010\n\u0011\n\u0011\nh\ni\n\u0010\n1 \u2212 e\u2212\u03b8l \u03c0(dl) F ([\u03c1\u0303u , l\u03b40 ]) \u2212 F (\u03c1\u0303u ) = e\u2212ch\u03c1\u0303u ,1i \u03c8 (\u03b8) (c) \u2212 \u03c8(c) .\n(0,\u221e)\n\nFrom Proposition 6.3, we get that N = (Nt , t \u2265 0), with for t \u2265 0,\nZ t\u2227\u03c3\u0303\n\u2212ch\u03c1\u0303t\u2227\u03c3\u0303 ,1i\n(\u03b8)\ne\u2212ch\u03c1\u0303s ,1i ds,\nNt = e\n\u2212\u03c8 (c)\n0\n\nis under P\u03bc an F\u0303 -martingale.\n(\u03b8)\nNotice that \u03c3\u0303 = inf{s \u2265 0; h\u03c1\u0303s , 1i = 0}. Let X (\u03b8) = (Xt , t \u2265 0) be under P\u2217x , a L\u00e9vy\nprocess with Laplace transform \u03c8 (\u03b8) started at x > 0 and stopped when it reached 0. The\ntwo non-negative c\u00e0d-l\u00e0g processes (h\u03c1\u0303t\u2227\u03c3\u0303 , 1i, t \u2265 0) and X (\u03b8) solves the martingale problem:\nfor any c \u2265 0, the process defined for t \u2265 0 by\nZ t\u2227\u03c3\u2032\n\u2212cYt\u2227\u03c3 \u2032\n(\u03b8)\ne\u2212cYs ds,\ne\n\u2212\u03c8 (c)\n0\n\nwhere \u03c3 \u2032 = inf{s \u2265 0; Ys \u2264 0}, is a martingale. From Corollary 4.4.4 in [12], we deduce that\nthose two processes have the same distribution. To finish the proof, notice that the total\n\u0003\nmass process of \u03c1(\u03b8) under P\u2217\u03bc is distributed as X (\u03b8) under P\u2217h\u03bc,1i .\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n27\n\n6.2. Identification of the law of \u03c1\u0303. To begin with, let us mention some useful properties\nof the process \u03c1\u0303.\nLemma 6.5. We have the following properties for the process \u03c1\u0303.\n(i) \u03c1\u0303 is a c\u00e0d-l\u00e0g Markov process.\n(ii) The sojourn time at 0 of \u03c1\u0303 is 0.\n(iii) 0 is recurrent for \u03c1\u0303.\nProof. (i) This is a direct consequence of the strong Markov property of the process (\u03c1, m).\n(ii) We have for r > 0, with the change of variable t = As , a.s.\nZ Cr\nZ Cr\nZ r\nZ r\n1{\u03c1s =0} ds = 0,\n1{\u03c1s =0} dAs =\n1{\u03c1Ct =0} dt =\n1{\u03c1\u0303t =0} dt =\n0\n\n0\n\n0\n\n0\n\nas the sojourn time of \u03c1 at 0 is 0 a.s.\n(iii) Since \u03c3\u0303 = A\u03c3 and \u03c3 < +\u221e a.s., we deduce that 0 is recurrent for \u03c1\u0303 a.s.\n\n\u0003\n\nSince the processes \u03c1\u0303 and \u03c1(\u03b8) are both Markov processes, to show that they have the same\nlaw, it is enough to show that they have the same one-dimensional marginals. We first prove\nthat result under the excursion measure.\nProposition 6.6. For every \u03bb > 0 and every non-negative bounded measurable function f ,\n\"Z (\u03b8)\n#\n\u0015\n\u0014Z \u03c3\u0303\n\u03c3\n(\u03b8)\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\n\u2212\u03bbt\u2212h\u03c1t ,f i\ne\ndt = N\nN\ne\ndt .\n0\n\n0\n\nProof. On one hand, we compute, using the definition of the pruned process \u03c1\u0303,\n\u0015\n\u0015\n\u0014Z A\u03c3\n\u0014Z \u03c3\u0303\n\u2212\u03bbt\u2212h\u03c1Ct ,f i\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\ne\ndt .\ne\ndt = N\nN\n0\n\n0\n\nWe now make the change of variable t = Au to get\n\u0015\n\u0014Z \u03c3\n\u0014Z \u03c3\u0303\n\u0015\ne\u2212\u03bbAu e\u2212h\u03c1u ,f i dAu\ne\u2212\u03bbt\u2212h\u03c1\u0303t ,f i dt = N\nN\n0\n\u0015\n\u0014Z 0 \u03c3\n\u2212\u03bbAu \u2212h\u03c1u ,f i\ne\ne\n1{mu =0} du .\n=N\n0\n\nBy a time reversibility argument, see Lemma 3.6, we obtain\n\u0015\n\u0015\n\u0014Z \u03c3\n\u0014Z \u03c3\u0303\n\u2212h\u03b7u ,f i \u2212\u03bb(A\u03c3 \u2212Au )\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\n1{mu =0} e\ne\ndu\ne\ndt = N\nN\n0\n\u0014Z0 \u03c3\ni \u0015\nh\n\u2212\u03bbA\u03c3\n\u2212h\u03b7u ,f i \u2217\ndu\n1{mu =0} e\nE\u03c1u ,0 e\n=N\n0\n\u0015\n\u0014Z \u03c3\n\u22121\n\u2212h\u03b7u ,f i \u2212h\u03c1u ,1i\u03c8(\u03b8) (\u03bb)\n1{mu =0} e\ne\ndu\n=N\n0\n\nwhere we applied Lemma 4.1 (i) for the last equality. Now, by definition of m, we have by\nconditioning,\n\u0015\n\u0015\n\u0014Z \u03c3\n\u0014Z \u03c3\u0303\n\u22121\n\u2212\u03b8h\u03bau ,1i \u2212h\u03b7u ,f i \u2212h\u03c1u ,1i\u03c8(\u03b8) (\u03bb)\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\ne\ne\ne\ndu .\ne\ndt = N\nN\n0\n\n0\n\n\f28\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nNow, the Poisson decomposition of Proposition 2.6 and standard computations lead to\n\u0015\n\u0014Z \u03c3\u0303\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\ne\ndt\nN\n0\n)\n( Z\nZ 1 Z\nZ +\u221e\ni\nh\na\n\u22121\n(\u03b8)\n(\u03bb))\nl\u03c0(dl) 1 \u2212 e\u2212l(\u03b8+(1\u2212u)f (x)+u\u03c8\ndu\ndx\nda e\u2212\u03b10 a exp \u2212\n=\n(0,+\u221e)\n\n0\n\n0\n\n0\n\n\u001a Z a Z 1\n\u001b\n+\u221e\n\u0001\n\u22121\n=\nda exp \u2212\ndx\ndu \u03c8 \u2032 \u03b8 + (1 \u2212 u)f (x) + u\u03c8 (\u03b8) (\u03bb)\n0\n0\n( Z0\n\u0001 )\nZ +\u221e\na\n\u03bb \u2212 \u03c8 (\u03b8) f (x)\ndx\nda exp \u2212\n=\n.\n\u22121\n0\n0\n\u03c8 (\u03b8) (\u03bb) \u2212 f (x)\nZ\n\nOn the other hand, the formula of Proposition 2.7, the Poisson representation of Proposition 2.6 and the same computations as before yields\n\"Z (\u03b8)\n#\n\u03c3\n\n(\u03b8)\n\ne\u2212\u03bbt\u2212h\u03c1t\n\nN\n\n,f i\n\ndt\n\n0\n\nZ\n\n(\u03b8) \u22121 (\u03bb)h\u03bd,1i\n\nM(d\u03bc d\u03bd) e\u2212h\u03bc,f i e\u2212\u03c8\n( Z\nZ +\u221e\n\u2212\u03b10 a\n=\nda e\nexp \u2212\n=\n\n0\n\n=\n\nZ\n\na\n\ndx\n\n0\n\n+\u221e\n0\n\n( Z\nda exp \u2212\n\na\n\ndx\n\n0\n\nZ\n\ndu\n1\n\nZ\n\nl\u03c0\n(0,+\u221e)\n\n\u0001 )\n\u03bb \u2212 \u03c8 (\u03b8) f (x)\n\n\u03c8 (\u03b8)\n\n\u22121\n\n(\u03b8)\n\n(\u03bb) \u2212 f (x)\n\nh\n\n\u2212l(uf (x)+\u03c8(\u03b8)\n\n(dl) 1 \u2212 e\n\n\u22121\n\n(\u03bb)(1\u2212u))\n\ni\n\n)\n\n.\n\nAs the two quantities are equal, the proof is over.\n\n\u0003\n\nNow, we prove the same result under P\u2217\u03bc,0 , that is:\nProposition 6.7. For every \u03bb > 0, f \u2208 B+ (R+ ) bounded and every finite measure \u03bc,\n\"Z (\u03b8)\n#\n\u0015\n\u0014Z\nE\u2217\u03bc,0\n\n\u03c3\u0303\n\n0\n\ne\u2212\u03bbt\u2212h\u03c1\u0303t ,f i dt = E\u2217\u03bc\n\n\u03c3\n\n(\u03b8)\n\ne\u2212\u03bbt\u2212h\u03c1t\n\n,f i\n\ndt .\n\n0\n\nProof. From the Poisson representation, see Lemma 3.3, and using notations of this Lemma\nand of (19) we have\nE\u2217\u03bc,0\n\n\u0014Z\n\n0\n\n\u03c3\u0303\n\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\n\ne\n\n\u0015\n\ndt =\n=\n\nE\u2217\u03bc,0\nE\u2217\u03bc,0\n\n\u0014Z\n\n\u03c3\n\n\u2212\u03bbAu \u2212h\u03c1u ,f i\n\ne\n\ndAu\n\n0\n\n\"\nX\n\n\u2212\u03bbA\u03b1i \u2212hk\u2212I\u03b1 ,f i\n\ne\n\ni\n\ni\u2208J\n\n(\u03bc)\n\n\u0015\n\nZ\n\n\u03c3i\n\n\u2212h\u03c1is ,f\u2212I\u03b1 i\u2212\u03bbAis\n\ne\n0\n\n(\u03bc)\n\ni\n\ndAis\n\n#\n\nwhere the function fr is defined by fr (x) = f (Hr + x) and Hr = H(kr \u03bc) is the maximal\nelement of the closed support of kr \u03bc (see (5)). We recall that \u2212I is the local time at 0 of the\nreflected process X \u2212 I, and that \u03c4r = inf{s; \u2212Is > r} is the right continuous inverse of \u2212I.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n29\n\nFrom excursion formula, and using the time change \u2212Is = r (or equivalently \u03c4r = s), we get\n\u0015\n\u0015\n\u0014Z \u03c3\u0303\n\u0014Z \u03c4h\u03bc,1i\n\u2217\n\u2212hk\u2212Is \u03bc,f i\u2212\u03bbAs\n\u2212\u03bbt\u2212h\u03c1\u0303t ,f i\n\u2217\nE\u03bc,0\nd(\u2212Is ) e\nG(\u2212Is )\ne\ndt = E\u03bc,0\n0\n0\n\"Z\n#\nh\u03bc,1i\n\n= E\u2217\u03bc,0\n\n(39)\n\ndr e\u2212hkr \u03bc,f i\u2212\u03bbA\u03c4r G(r)\n\n0\n\nwhere the function G(r) is given by\n\u0014Z \u03c3\n\u0015\n\u0014Z\n\u2212h\u03c1s ,fr i\u2212\u03bbAs\ndAs = N\ne\nG(r) = N\n0\n\n\u03c3\u0303\n\n\u2212\u03bbt\u2212h\u03c1\u0303t ,fr i\n\ne\n\n\u0015\n\ndt .\n\n0\n\nThe same kind of computation gives\n\"Z (\u03b8)\n#\n\"Z\n\u03c3\n(\u03b8)\n\u2212\u03bbt\u2212h\u03c1t ,f i\n\u2217\ne\ndt = E\n(40)\nE\u03bc\n0\n\nh\u03bc,1i\n\n(\u03b8)\n\n\u2212hkr \u03bc,f i\u2212\u03bb\u03c4r\n\ndr e\n\n(\u03b8)\n\nG\n\n0\n\n#\n\n(r)\n\nwhere the function G(\u03b8) is defined by\nG(\u03b8) (r) = N\n\n\"Z\n\n\u03c3(\u03b8)\n\n(\u03b8)\n\u2212\u03bbs\u2212h\u03c1s ,fr i\n\ne\n0\n\nds\n\n#\n\nand \u03c4 (\u03b8) is the right-continuous inverse of the infimum process \u2212I (\u03b8) of the L\u00e9vy process with\nLaplace exponent \u03c8 (\u03b8) .\nProposition 6.6 says that the functions G and G(\u03b8) are equal. Moreover, as the total mass\nprocesses have the same law (see Corollary 6.4), we know that the proposition is true for f\nconstant. And, for f constant, the functions G and G(\u03b8) are also constant. Therefore, we\nhave for f constant equal to c \u2265 0,\n#\n#\n\"Z\n\"Z\nh\u03bc,1i\nh\u03bc,1i\n(\u03b8)\n\u2212c(h\u03bc,1i\u2212r) \u2212\u03bb\u03c4r\n\u2212c(h\u03bc,1i\u2212r) \u2212\u03bbA\u03c4r\n\u2217\n.\n=E\ndr e\ne\ndr e\ne\nE\u03bc,0\n0\n\n0\n\nAs this is true for any c \u2265 0, uniqueness of the Laplace transform gives the equality\ni\ni\nh\nh\n(\u03b8)\ndr \u2212 a.e.\nE\u2217\u03bc,0 e\u2212\u03bbA\u03c4r = E e\u2212\u03bb\u03c4r\n\nIn fact this equality holds for every r by right-continuity.\nEventually as G = G(\u03b8) , we have thanks to (39) and (40), that, for every bounded nonnegative measurable function f ,\nZ h\u03bc,1i\nZ h\u03bc,1i\nh\ni\nh\ni\n(\u03b8)\ndr e\u2212hkr \u03bc,f i E e\u2212\u03bb\u03c4r G(\u03b8) (r)\ndr e\u2212hkr \u03bc,f i E\u2217\u03bc,0 e\u2212\u03bbA\u03c4r G(r) =\n0\n\n0\n\nwhich ends the proof.\n\n\u0003\n\nCorollary 6.8. The process \u03c1\u0303 under P\u2217\u03bc,0 is distributed as \u03c1(\u03b8) under P\u2217\u03bc .\nProof. Let f \u2208 B+ (R+ ) bounded. Proposition 6.7 can be re-written as\nZ +\u221e\nZ +\u221e\nh\ni\ni\nh\n(\u03b8)\n\u2212h\u03c1\u0303t ,f i\n\u2212\u03bbt \u2217\ne\u2212\u03bbt E\u2217\u03bc e\u2212h\u03c1t ,f i 1{t\u2264\u03c3(\u03b8) } dt.\n1{t\u2264\u03c3\u0303} dt =\ne\nE\u03bc,0 e\n0\n\n0\n\nBy uniqueness of the Laplace transform, we deduce that, for almost every t > 0,\nh\ni\ni\nh\n(\u03b8)\nE\u2217\u03bc,0 e\u2212h\u03c1\u0303t ,f i 1{t\u2264\u03c3\u0303} = E\u2217\u03bc e\u2212h\u03c1t ,f i 1{t\u2264\u03c3(\u03b8) } .\n\n\f30\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nIn fact this equality holds for every r by right-continuity. As the Laplace functionals characterize the law of a random measure, we deduce that, for fixed t > 0, the law of \u03c1\u0303t under P\u2217\u03bc,0\n(\u03b8)\n\nis the same as the law of \u03c1t under P\u2217\u03bc .\nThe Markov property then give the equality in law for the c\u00e0d-l\u00e0g processes \u03c1\u0303 and \u03c1(\u03b8) . \u0003\nProof of Theorem 6.1. 0 is recurrent for the Markov c\u00e0d-l\u00e0g processes \u03c1\u0303 and \u03c1(\u03b8) . This two\nprocesses have no sojourn at 0, and when killed on the first hitting time of 0, they have the\nsame law, thanks to Lemma 6.8. From Theorem 4.2 of [9], Section 5, we deduce that \u03c1\u0303 under\nP\u03bc,0 is distributed as \u03c1(\u03b8) under P\u03bc .\n\u0003\n7. Property of the excursion of the pruned exploration process\nWe know, (cf [4], Section VII) that the right continuous inverse, (\u03c4r , r \u2265 0), of \u2212I is\na subordinator with Laplace exponent \u03c8 \u22121 . This subordinator has no drift as (2) implies\nlim\u03bb\u2192\u221e \u03bb\u22121 \u03c8 \u22121 (\u03bb) = 0. We denote by \u03c0\u2217 its L\u00e9vy measure: for \u03bb \u2265 0\nZ\n\u22121\n\u03c0\u2217 (dl)(1 \u2212 e\u2212\u03bbl ).\n\u03c8 (\u03bb) =\n(0,\u221e)\n\nRecall N is the excursion measure of the exploration process above 0. If \u03c3 denotes the duration\nof the excursion, we have N[1 \u2212 e\u2212\u03bb\u03c3 ] = \u03c8 \u22121 (\u03bb). Hence, under N, \u03c3 is distributed according\nto the measure\n\u03c0\u2217 . By decomposing the measure N w.r.t. the distribution of \u03c3, we get that\nR\nN[dE] = (0,\u221e) \u03c0\u2217 (dr)Nr [dE], where (Nr , r \u2208 (0, \u221e)) is a measurable family of probability\nmeasures on the set of excursions such that Nr [\u03c3 = r] = 1 for \u03c0 \u2217 -a.e. r > 0.\nLemma 7.1. Conditionally on the length of the excursion, the law of the excursion of the\npruned exploration process is the law of the excursion of the exploration process.\n\nProof. From the previous Section, we get that the pruned exploration process (\u03c1\u0303t , t \u2265 0) is\ndistributed according to the law of the exploration process, \u03c1(\u03b8) , of a L\u00e9vy process, X (\u03b8) , with\nLaplace exponent \u03c8 (\u03b8) = \u03c8(\u03b8 + *) \u2212 \u03c8(\u03b8). In particular the law of the pruned exploration\nprocess under the excursion measure is the law of the exploration process \u03c1(\u03b8) under the\nexcursion measure.\nLet \u03c3 (\u03b8) denote the length of the excursion of the exploration process \u03c1(\u03b8) under the excursion measure. The following result is known, but since we couldn't give a reference, we shall\ngive a proof at the end of this Section.\nLemma 7.2. For any non-negative measurable function, G, on the space of excursions, we\nhave\ni\ni\nh\nh\n(\u03b8)\n(\u03b8)\nN e\u03c8(\u03b8)\u03c3 [1 \u2212 e\u2212G(\u03c1 ) ] = N 1 \u2212 e\u2212G(\u03c1) .\n\nIn particular the distribution of \u03c1(\u03b8) under the excursion measure is absolutely continuous\nw.r.t. to distribution of \u03c1 under the excursion measure, with density given by e\u2212\u03c3\u03c8(\u03b8) . We\n(\u03b8)\n(\u03b8)\ndeduce that \u03c0\u2217 (dr) = e\u2212r\u03c8(\u03b8) \u03c0\u2217 (dr), where \u03c0\u2217 is the L\u00e9vy measure corresponding to the\nLaplace exponent (\u03c8 (\u03b8) )\u22121 . And we have \u03c0\u2217 (dr)-a.e., conditionally on the length of the\nexcursion being equal to r, the law of the excursion of the pruned exploration process is the\nlaw of the excursion of the exploration process.\n\u0003\nR\u03c3\nRecall \u03c3\u0303 = 0 1{m(\u03b8) =0} ds denotes the length of the excursion of the pruned exploration\ns\nprocess. We can compute the joint law of (\u03c3\u0303, \u03c3). This will determine uniquely the law of \u03c3\u0303\nconditionally on \u03c3 = r.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n31\n\ni\nh\nProposition 7.3. For all non-negative \u03b3, \u03ba, \u03b8, the value v defined by v = N 1 \u2212 e\u2212\u03c8(\u03b3)\u03c3\u2212\u03ba\u03c3\u0303\nis the unique non-negative solution of the equation\n\u03c8(v + \u03b8) = \u03ba + \u03c8(\u03b3 + \u03b8).\nProof. Using the special Markov property, Theorem 5.2, with \u03c6(S) = \u03c8(\u03b3)\u03c3, we have\ni\ni\nh\nh\nR\u03c3\nv = N 1 \u2212 e\u2212\u03ba\u03c3\u0303\u2212\u03c8(\u03b3)\u03c3 = N 1 \u2212 e\u2212(\u03ba+\u03c8(\u03b3))\u03c3\u0303\u2212\u03c8(\u03b3) 0 1{ms 6=0} ds\ni\nh\nR\n\u2212(\u03ba+\u03c8(\u03b3))\u03c3\u0303\u2212\u03c3\u0303 (0,+\u221e) \u03c0(dl)(1\u2212e\u2212\u03b8l )E\u2217l [1\u2212exp (\u2212\u03c8(\u03b3)\u03c3)]\n.\n=N 1\u2212e\n\nNotice that \u03c3 under P\u2217l is distributed as \u03c4l , the first time for which the infimum of X, started\nat 0, reaches \u2212l. Since \u03c4l is distributed as a subordinator with Laplace exponent \u03c8 \u22121 at time\nl, we have\nh\ni\nE\u2217l [1 \u2212 e\u2212\u03c8(\u03b3)\u03c3 ] = E 1 \u2212 e\u2212\u03c8(\u03b3)\u03c4l = 1 \u2212 e\u2212l\u03b3 .\n\nand\nZ\n\n(0,+\u221e)\n\n\u2212\u03b8l\n\n\u03c0(dl)(1 \u2212 e\n\n)E\u2217l [1\n\n\u2212\u03c8(\u03b3)\u03c3\n\n\u2212e\n\n]=\n\nZ\n\n(0,+\u221e)\n\n\u03c0(dl)(1 \u2212 e\u2212\u03b8l )(1 \u2212 e\u2212\u03b3l ) = \u03c8 (\u03b8) (\u03b3) \u2212 \u03c8(\u03b3).\n\nWe get\ni\nh\n\u22121\n(\u03b8)\nv = N 1 \u2212 e\u2212\u03c3\u0303(\u03ba+\u03c8 (\u03b3)) = \u03c8 (\u03b8) (\u03ba + \u03c8 (\u03b8) (\u03b3)).\n\nUsing Corollary 6.2 and definition (17) of \u03c8 (\u03b8) , we have \u03c8(v + \u03b8) = \u03ba + \u03c8(\u03b3 + \u03b8). Since \u03c8 is\nincreasing and continuous, this equation has only one solution.\n\u0003\nProof of Lemma 7.2. Since an excursion of the exploration process above 0 can be recovered\nfrom an excursion of the process X above its minimum. We shall prove the Lemma in the\nlatter case.\n(\u03b8)\nLet \u03b8 > 0. We set X (\u03b8) = (Xt , t \u2265 0) the L\u00e9vy process with Laplace exponent \u03c8 (\u03b8) .\nNotice that (e\u2212\u03b8Xt \u2212t\u03c8(\u03b8) , t \u2265 0) is a martingale w.r.t. the natural filtration generated by X,\n(Ht , t \u2265 0). We define a new probability by\n(\u03b8)\n\ndP|Ht = e\u2212\u03b8Xt \u2212t\u03c8(\u03b8) dP|Ht .\n(\u03b8)\n\nThe law of (Xu , u \u2208 [0, t]) under P(\u03b8) is the law of (Xu , u \u2208 [0, t]). Therefore, we have for\nany non-negative measurable function on the path space\nh\ni\n(\u03b8)\n(\u03b8)\n(41)\nE F (X\u2264t ) e\u03b8Xt +t\u03c8(\u03b8) = E[F (X\u2264t )].\n(\u03b8)\n\nWe define \u2212It\n\n(\u03b8)\n\n= \u2212 inf u\u2208[0,t] Xu , and \u03c4 (\u03b8) its right-continuous inverse. In particular, it is a\n\u22121\n\n\u22121\n\nsubordinator of Laplace exponent \u03c8 (\u03b8) . Since \u03c8 (\u03b8) (\u03bb) = \u03c8 \u22121 (\u03bb + \u03c8(\u03b8)) \u2212 \u03b8, we have\ni\nh\n(\u03b8)\n\u22121\nE e\u2212\u03bb\u03c4r = e\u2212r[\u03c8 (\u03bb+\u03c8(\u03b8))\u2212\u03b8] .\ni\nh\n(\u03b8)\nFurthermore, this equality holds for \u03bb \u2265 \u2212\u03c8(\u03b8). With \u03bb = \u2212\u03c8(\u03b8), we get E e\u03c8(\u03b8)\u03c4r = e\u03b8r .\n(\u03b8)\n\nFrom (41), we get that the process (Qt , t \u2265 0), where Qt = e\u03b8Xt\n(\u03b8)\n\u2212\u03b8r+\u03c8(\u03b8)\u03c4r\n\nSince M\u03c4 (\u03b8) = e\nr\n\n(42)\n\n+t\u03c8(\u03b8)\n\nis a martingale.\n\nis integrable and E[M\u03c4 (\u03b8) ] = 1, we deduce from (41) that\nr\nh\ni\n(\u03b8)\n(\u03b8)\nE F (X (\u03b8) ) e\u2212\u03b8r+\u03c8(\u03b8)\u03c4r = E[F (X\u2264\u03c4r )].\n\u2264\u03c4r\n\n\f32\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nLet Ei = (Xt+\u03b1i \u2212 I\u03b1i , t \u2208 [\u03b1i , \u03b1i + \u03c3i ]), i \u2208 I,Pbe the excursions of X above its minimum, up\nto time \u03c4r . With F such that F (X\u2264\u03c4r ) = e\u2212 i\u2208I G(Ei ) , we get\n\u2212G(E)\u2212\u03bb\u03c3 ]\n\nE[F (X\u2264\u03c4r ) e\u2212\u03bb\u03c4r ] = e\u2212rN[1\u2212e\n\n.\n\nWe deduce from (42) that\n\u2212G(E (\u03b8) )+\u03c8(\u03b8)\u03c3 (\u03b8) ]\n\ne\u2212\u03b8r e\u2212rN[1\u2212e\n\n\u2212G(E) ]\n\n= e\u2212rN[1\u2212e\n\n,\n\nwhere E (\u03b8) is an excursion of X (\u03b8) above its minimum, that is\nN[1 \u2212 e\u2212G(E\n\nSubtracting N[1 \u2212 e\u03c8(\u03b8)\u03c3\n\n(\u03b8) )+\u03c8(\u03b8)\u03c3 (\u03b8)\n\n(\u03b8)\n\n] = N[1 \u2212 e\u2212G(E) ] \u2212 \u03b8.\n\n] = \u2212\u03b8, in the above equality, we get\ni\nh\ni\nh\n(\u03b8)\n(\u03b8)\nN e\u03c8(\u03b8)\u03c3 [1 \u2212 e\u2212G(E ) ] = N 1 \u2212 e\u2212G(E) .\n\n\u0003\n\n8. Link between L\u00e9vy snake and fragmentation processes at nodes\nWe define the fragmentation process. Let S = (\u03c1, M ) be a L\u00e9vy Poisson snake. Recall\ndefinition of m(\u03b8) at the end of Section 3. For fixed \u03b8 > 0, let us consider the following\nequivalence relation R\u03b8 on [0, \u03c3], defined under N or N\u03c3 (see definition in Section 7) by:\n\u0001\n\u0001\n(\u03b8)\n(43)\nsR\u03b8 t \u21d0\u21d2 ms(\u03b8) [Hs,t , Hs ] = mt [Hs,t , Ht ] = 0,\n\nwhere Hs,t = inf Hu (recall definition (3)). Intuitively, two points s and t belongs to the\nu\u2208[s,t]\n\nsame class of equivalence (i.e. the same fragment) at time \u03b8, if there is no cut on their lineage\n(\u03b8)\n(\u03b8)\ndown to their most recent common ancestor (that is ms put no mass on [Hs,t, Hs ] nor mt\non [Hs,t, Ht ]). Notice cutting occurs on branching points, that is at node of the CRT. Each\nnode of the CRT correspond to a jump of the underlying L\u00e9vy process X. The cutting times\nare, conditionally on the CRT, independent exponential random times, with parameter equal\nto the jump of the corresponding node.\nLet us index the different equivalent classes in the following way: For any s \u2264 \u03c3, let us\ndefine Hs0 = 0 and recursively for k \u2208 N,\nn\no\n\u0001\nk+1\n\u03b8\nk\nHs = inf u \u2265 0 ms (Hs , u] > 0 ,\n\nwith the usual convention inf \u2205 = +\u221e. We set\n\nKs = sup{j \u2208 N, Hsj < +\u221e}.\n\nRemark 8.1. Notice that we have Ks = \u221e if Ms (*, [0, \u03b8]) has infinitely many atoms. By\nconstruction of M using Poisson point measures, this happens N[dS] ds-a.e., if and only if\nthe intensity measure \u03c1s + \u03b7s is infinite. Since N[dS]-a.e., \u03c1 and \u03b7 are finite measure valued\nprocess, we get that N[dS]-a.e., Ks < \u221e.\nLet us remark that sR\u03b8 t implies Ks = Kt . We denote, for any j \u2208 N, (Rj,k , k \u2208 Jj ) the\nfamily of equivalent classes with positive Lebesgue measure such that Ks = j. For j \u2208 N,\nk \u2208 Jj we set\nZ t\nj,k\nAt =\n1{s\u2208Rj,k } ds and Ctj,k = inf{u \u2265 0, Aj,k\nu > t},\n0\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n33\n\nwith the convention inf \u2205 = \u03c3. And we define the corresponding L\u00e9vy snake, S\u0303 j,k =\n(\u03c1\u0303j,k , M\u0303 j,k ) by: for every f \u2208 B+ (R+ ), \u03c6 \u2208 B+ (R+ \u00d7 R+ ), t \u2265 0,\nZ\nj,k\nf (x \u2212 HC j,k )\u03c1C j,k (dx)\n\u03c1\u0303t , f =\n(H\n\nM\u0303tj,k , \u03c6\n\n=\n\nZ\n\n(H\n\nC\n\nj,k ,+\u221e)\n0\n\nC\n\nj,k ,+\u221e)\u00d7(\u03b8,+\u221e)\n0\n\n0\n\nt\n\n\u03c6(x \u2212 HC j,k , v \u2212 \u03b8)MC j,k (dx, dv).\n0\n\nt\n\nj,k\nLet \u03c3\u0303 j,k = Aj,k\n\u221e be the length of the excursion S\u0303 . Since Ks < \u221e N[dS]ds-a.e. (Remark\n8.1), the family (\u03c3\u0303 j,k j \u2208 N, k \u2208 Jj ) gives all the equivalent classes with positive Lebesgue\nmeasure.\n\nRemark 8.2. In view of the next Section we introduce the set L(\u03b8) = (\u03c1\u0303(j,k) , j \u2208 N, k \u2208 Jj ) of\nfragments of L\u00e9vy snake as well as the the set L(\u03b8\u2212) defined similarly but for the equivalence\nrelation where R\u03b8 in (43) is replaced by R\u03b8\u2212 defined as\n\u0001\n\u0001\n(44)\nsR\u03b8\u2212 t \u21d0\u21d2 Ms [Hs,t , Hs ] \u00d7 (0, \u03b8) = Ms [Hs,t , Ht ] \u00d7 (0, \u03b8) = 0.\n\u0001\n(\u03b8)\nNotice that ms (*) = Ms *, (0, \u03b8] . So the two equivalence relations are equal N-a.e. for fixed\n\u03b8, but may differ if M has an atom in {\u03b8} \u00d7 R+ .\n\nLet us denote by \u039b\u03b8 = (\u039b\u03b81 , \u039b\u03b82 , . . .) the sequence of positive Lebesgue measures of the\nequivalent classes of R\u03b8 , (\u03c3\u0303 j,k , j \u2208 N, k \u2208 Jj ), ranked in decreasing order. Notice this sequence\nis at most countable. If it is finite, we complete the sequence with zeros, so that N-a.s. and\nN\u03c3 -a.s.\nX\n\b\n\u039b\u03b8 \u2208 S \u2193 = (x1 , x2 , . . .), x1 \u2265 x2 \u2265 * * * \u2265 0,\nxi \u2264 \u221e .\n\nFor \u03c0 \u2217 (d\u03c3)-a.e. \u03c3 > 0, let P\u03c3 denote the law of (\u039b\u03b8 , \u03b8 \u2265 0) under N\u03c3 . (The law, Nr , of\nS conditionally on the length of the excursion, \u03c3, being equal to r has been defined in the\nprevious Section.) By convention P0 is the Dirac mass at (0, 0, . . .) \u2208 S \u2193 .\n\nTheorem 8.3. For \u03c0\u2217 (dr)-almost any r, under Pr , the process \u039b = (\u039b\u03b8 , \u03b8 \u2265 0) is a S \u2193 \u2032\nvalued fragmentation process. More precisely, the law under Pr of the process (\u039b\u03b8+\u03b8 , \u03b8 \u2032 \u2265 0)\nconditionally on \u039b\u03b8 = (\u039b1 , \u039b2 , . . .) is given by the decreasing reordering of independents\nprocesses of respective law P\u039b1 , P\u039b2 , . . ..\n\nRemark 8.4. We get a self-similar fragmentation when \u03c8(\u03bb) = \u03bb\u03b1 , see Corollary 9.3. This\nparticular case was already studied in [18].\nRemark 8.5. We may get rid of the \"\u03c0\u2217 (dr)-almost any r\" and have the theorem for any\npositive r if we have a regular version of the family of conditional probability laws (Nr , r > 0).\nThis is for instance the case when the L\u00e9vy process is stable (for which it is possible to\nconstruct the measure Nr from N1 by a scaling property) or when we may construct this\nfamily via a Vervaat's transform of the L\u00e9vy bridge (see [16]).\nR The proof of the Proposition is a consequence of Lemma 8.6, and the fact that N(*) =\n(0,+\u221e) \u03c0\u2217 (dr)Nr (*) which implies that the result of Lemma 8.6 holds Nr -a.s. for \u03c0\u2217 (dr)\nalmost every r.\n\nLemma 8.6. Under N, the law of the family (S \u0303j,k , j \u2208 N, k \u2208 Jj ), conditionally on (\u03c3\u0303 j,k , j \u2208\nN, k \u2208 Jj ), is the law of independent L\u00e9vy Poisson snakes, and the conditional law of S\u0303 j,k is\nN\u03c3\u0303j,k .\n\n\f34\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nProof. For j = 0, notice that J0 has only one element, say 0. And S\u0303 0,0 is just the L\u00e9vy snake,\nS\u0303, defined in Section 5. Of course, we have \u03c3\u0303 0,0 = \u03c3\u0303. From the special Markov property\n(Theorem 5.2) and Proposition 3.5, we deduce that conditionally on \u03c3\u0303 0,0 , S\u0303 0,0 and the family\n(S i , i \u2208 I) of excursions of S out of {s \u2265 0; m\u03b8s = 0} (as defined in Section 5) are independent.\nFrom Corollary 6.2 and Lemma 7.1 for the exploration process and Proposition 3.5 for\nthe underlying Poisson process, we deduce that, conditionally on \u03c3\u0303 0,0 , S\u0303 0,0 is distributed\naccording to N\u03c3\u03030,0 .\nFurthermore, from the special Markov property (Theorem 5.2), the conditional law of S i\nis given by N, defined in (23). Now we give a Poisson decomposition of the measure N.\nFor S \u2032 = (\u03c1\u2032 , M \u2032 ) distributed according to N, we consider (\u03b1\u2032l , \u03b2l )l\u2208I \u2032 the excursion intervals\nof the L\u00e9vy Poisson snake, S \u2032 , out of {Hs\u2032 = 0}. For l \u2208 I \u2032 , we set S \u2032 l = (\u03c1\u2032 l , M \u2032 l ) where for\ns \u2265 0,\nl\n\n\u03c1\u2032 s (dr) = \u03c1\u2032(s+\u03b1\u2032 )\u2227\u03b2 \u2032 (dr)1(0,+\u221e) (r),\nl\n\nl\nM \u2032 s (dr, dv)\n\n=\n\nl\n\n\u2032\nM(s+\u03b1\n\u2032 )\u2227\u03b2 \u2032 (dr, dv)1(0,+\u221e) (r).\nl\nl\n\nLet us remark that in the above definition \u03c1\u2032 l and M \u2032 l don't have mass at {0} and {0} \u00d7 R+ .\nAs a direct consequence of the Poisson decomposition of P\u2217l (see Lemma 3.3), we get the\nfollowing Lemma.\nX\nLemma 8.7. Under N, the point measure\n\u03b4S \u2032 i\u2032 is a Poisson point measure with intensity\ni\u2032 \u2208I \u2032\n\nC\u03b8 N(dS) where C\u03b8 =\n\nR\n\n\u2212\u03b8l )l\u03c0(dl) = \u03c8 \u2032 (\u03b8) \u2212 \u03c8 \u2032 (0).\n(0,\u221e) (1 \u2212 e\n\nBy this Poisson representation, each process S i is composed of i.i.d. excursions of law N.\nThus we get, conditionally on \u03c3\u0303 0,0 , a family (S 1,k , k \u2208 J1 ) of i.i.d. excursions distributed as\nthe atoms of a Poisson point measure with intensity \u03c3\u0303 0,0 C\u03b8 N. Now, we can repeat the above\narguments for each excursion S 1,k , k \u2208 J1 : so that conditionally on \u03c3\u0303 0,0 , we can\n\n\u2022 check that S\u0303 1,k is built from S 1,k as S\u0303 from S in Section 5,\n\u2032\n\u2022 get a family (S 2,k ,k , k\u2032 \u2208 J2k ), which are, conditionally on \u03c3\u0303 1,k , distributed as the\natoms of a Poisson point measure with intensity \u03c3\u0303 1,k C\u03b8 N. and are independent of\nS\u0303 1,k .\n\nIf we set J2 = \u222ak\u2208J1 J2k \u00d7 {k}, we get that conditionally on \u03c3\u0303 0,0 , and (\u03c3\u0303 1,k , k \u2208 J1 ),\n\n\u2022 the excursions S\u0303 0,0 and (S\u0303 1,k , k \u2208 J1 ), are independent,\n\u2022 S\u0303 i,k is distributed as N\u03c3\u0303j,k , for j \u2208 {0, 1}, k \u2208 Jj ,\n\u2032\n\u2022 (S 2,k , k\u2032 \u2208 J2 ), are distributed as the atoms of a Poisson point measure with intensity\nP\n1,k C N, and are independent of S\u0303 0,0 and (S\u0303 1,k , k \u2208 J ).\n1\n\u03b8\nk\u2208J1 \u03c3\u0303\n\nEventually, the result follows by induction.\n\n\u0003\nNow we check there is no loss of mass during the fragmentation.\nProposition 8.8. For \u03c0\u2217 (dr) almost every r, Pr -a.s., for every \u03b8 \u2265 0,\n\n+\u221e\nX\ni=1\n\n\u039b\u03b8i = r.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n35\n\nProof. Let \u03b8 > 0. We use the notations of the proof of Theorem 8.3 and of Lemma 8.6. For\nn \u2208 N, we have N-a.e.\nZ \u03c3\nn X\nX\nj,k\n1{Ks \u2265n+1} ds.\n\u03c3\u0303 +\n\u03c3=\n0\n\nk=0 j\u2208Jk\n\nBy monotone convergence, we deduce from Remark 8.1, that we get as n \u2192 +\u221e that N-a.e.\n\u03c3=\n\n\u221e X\nX\n\n\u03c3\u0303 j,k .\n\nk=0 j\u2208Jk\n\nAs the decreasing reordering of\n\n(\u03c3\u0303 j,k , j\n\n\u2208 N, k \u2208 Jj ) is\n\n\u039b\u03b8 ,\n\nwe get that N-a.e.\n\n+\u221e\nX\n\n\u039b\u03b8i = \u03c3. As\n\ni=1\nP\n\u03b8 , \u03b8 \u2265 0) is non increasing, we deduce that the previous equality holds\nthe sequence ( \u221e\n\u039b\ni=1 i\nfor any \u03b8 > 0, N-a.e.\nHere again the result for Pr is deduced from the one under N.\n\u0003\n\n9. Dislocation measures\nLet \u03bb(\u03b8) be the mass of a tagged fragment at time \u03b8 of the fragmentation process \u039b\ndefined in Theorem 8.3 (typically the fragment or the equivalent class which contains 0). A\ndislocation of this fragment occurs when \u03bb(\u03b8) has a jump. Let T0 be the set of time jumps\nfor \u03bb. Recall S \u2193 denote the set of non-negative non-increasing sequence (xi , i \u2208 N\u2217 ) such that\nP\n\u2032\n\u2032\n\u2032\n\u2217\n\u2193\ni\u22651 xi < \u221e. For \u03b8 \u2208 T0 , let x(\u03b8 ) = (xi (\u03b8 ), i \u2208 N ) \u2208 S , the masses of the fragments\nresulting of the dislocation at time \u03b8 \u2032 . Following the Remark after Theorem 3 in [6], we call\nthe random point measure\nX\n\u03b4(d\u03b8, dx) =\n\u03b4\u03b8\u2032 ,x(\u03b8\u2032 ) (d\u03b8, dx)\n\u03b8 \u2032 \u2208T0\n\nthe dislocation process of the fragmentation (or dislocation process of the \u03c8-CRT fragmentation at nodes). Of course,\nP since there is no erosion, that is the total length is constant cf.\nProposition 8.8, \u03bb(\u03b8 \u2032 \u2212) = i\u22651 xi (\u03b8 \u2032 ).\nFor self-similar fragmentation with with index \u03b3 and no erosion, there exists a measure \u03bd1 on\nP\n\u2193\nS1 = {x \u2208 S \u2193 ; i\u22651 xi = 1}, called the dislocation measure, such that the dislocation process\nis a point process with intensity 1{\u03bb(\u03b8\u2212)>0} \u03bd\u03bb(\u03b8\u2212) (dx)d\u03b8, where the measures (\u03bdr , r > 0) are\ndefined by\nZ\nZ\n\u03b3\nF (rx)\u03bd1 (dx),\nF (x)\u03bdr (dx) = r\n(45)\nSr\u2193\n\nS1\u2193\n\nand the equality hold for any non-negative measurable function on S \u2193 . We refer to [6] for\nthe proof of this result and to [13] for the definition of intensity of a random point measure.\nIn order to give the corresponding dislocation measures for the \u03c8-CRT fragmentation at\nnodes, we need to consider (\u2206St , t \u2265 0) the jumps of a subordinator S with Laplace exponent\n\u03c8 \u22121 . Let \u03bc the measure on R+ \u00d7 S \u2193 such that for any non-negative measurable function, F ,\non R+ \u00d7 S \u2193 ,\nZ\nZ\nF (r, x)\u03bc(dr, dx) = \u03c0(dv)E[F (Sv , (\u2206St , t \u2264 v))],\n(46)\nR+ \u00d7S \u2193\n\n\f36\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nwhere (\u2206St , t \u2264 v) has to be understood as the family of jumps of the subordinator up to\ntime v ranked in decreasing size.\nIntuitively, \u03bc is the law of ST and the jumps of S up to time T , where T and S are\nindependent, and T is distributed according to the infinite measure \u03c0. Recall \u03c0\u2217 is the \"law\"\nof \u03c3 under N (this is the L\u00e9vy measure associated to the Laplace exponent \u03c8 \u22121 ).\nTheorem 9.1. The dislocation process of the \u03c8-CRT fragmentation P\nat nodes, is under N a\npoint process with intensity 1{\u03bb(\u03b8\u2212)>0} \u03bd\u03bb(\u03b8\u2212) (dx)d\u03b8, where \u03bb(\u03b8\u2212) = i\u22651 xi (\u03b8) is the mass\nof the fragment just before \u03b8. And the family of dislocation measure (\u03bdr , r > 0) on S \u2193 is the\nresult of the disintegration of r\u03bc(dr, dx) w.r.t. \u03c0\u2217 (dr):\nr\u03bc(dr, dx) = \u03bdr (dx)\u03c0\u2217 (dr).\nP\n\u2217\nNotice that (46) implies that \u03c0 \u2217 (dr)-a.e. \u03bdr (dx)-a.e.\ni\u2208N\u2217 xi = r, where x = (xi , i \u2208 N ).\nThe dislocation measure \u03bdr describe the dislocation of a fragment of size r.\nRemark 9.2. Either from Lemma 7.1 or directly, it is easy to check that the dislocation\n(\u03b8)\nmeasure of the fragmentation at nodes associated to \u03c8 (\u03b8) (see (17)), (\u03bdr , r > 0), is equal to\n(\u03bdr , r > 0), \u03c0\u2217 (dr)-a.e.\nThe next Sections are devoted to the proof of the Theorem. In Section 9.1, we give an\nother representation of the fragmentation following ideas in [1, 3] developed for \u03c8(\u03bb) = \u03bb2 .\nIn Section 9.2, we explain how to compute the intensity of the dislocation process. And we\nperform the computation in Section 9.3. This will end the proof of the Theorem.\nFor the \u03bb\u03b1 -CRT (with \u03b1 \u2208 (1, 2)), thanks to scaling properties, the corresponding fragmentation is self similar with index 1/\u03b1, and we can recover the result of [18].\nCorollary 9.3. For the \u03bb\u03b1 -CRT fragmentation at nodes, the fragmentation is self-similar,\nwith index 1/\u03b1, that is (45) holds with \u03b3 = 1/\u03b1. And the dislocation measure \u03bd1 on S1\u2193 is s.t.\nZ\n\u03b1(\u03b1 \u2212 1)\u0393([\u03b1 \u2212 1]/\u03b1)\nE[S1 F ((\u2206St /S1 , t \u2264 1))],\nF (x)\u03bd1 (dx) =\n\u0393(2 \u2212 \u03b1)\n\nholds for any non-negative measurable function, F , on S1\u2193 , where (\u2206St , t \u2265 0) are the jumps of\na stable subordinator S = (St , t \u2265 0) of Laplace exponent \u03c8 \u22121 (\u03bb) = \u03bb1/\u03b1 , ranked by decreasing\nsize.\n\nProof. For \u03c8(\u03bb) = \u03bb\u03b1 , we get \u03c0(dr) = \u03b1(\u03b1 \u2212 1)\u0393(2 \u2212 \u03b1)\u22121 r \u22121\u2212\u03b1 dr as well as \u03c0\u2217 (dr) =\n[\u03b1\u0393([\u03b1 \u2212 1]/\u03b1)]\u22121 r \u2212(1+\u03b1)/\u03b1 dr. In particular, we have for a non-negative measurable function,\nF , defined on R+ \u00d7 S1\u2193 ,\n\u0014Z\n\u0015\nZ\nF (r, x) r\u03bc(dr, dx) = E\n\u03c0(dv) Sv F (Sv , (\u2206St , t \u2264 v))\n\u0014Z\n\u0015\n\u03b1(\u03b1 \u2212 1)\ndv\n=\nE\nSv F (Sv , (\u2206St , t \u2264 v))\n\u0393(2 \u2212 \u03b1)\nv 1+\u03b1\n\u0014Z\n\u0015\ndv\n\u03b1(\u03b1 \u2212 1)\n\u03b1\n\u03b1\nE\nS1 F (v S1 , v S1 (\u2206St /S1 , t \u2264 1))\n=\n\u0393(2 \u2212 \u03b1)\nv\nZ\n\u03b1\u22121\ndy\n=\nE[S1 F (y, y(\u2206St /S1 , t \u2264 1))] ,\n\u0393(2 \u2212 \u03b1)\ny\nwhere we used the scaling property of S, that is (\u2206St , t \u2264 r) is distributed as (r \u03b1 \u2206St , t \u2264 1),\nfor the third equality, and the change of variable y = v \u03b1 S1 for the fourth equality. From\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n37\n\nTheorem 9.1, we have that\nZ\nZ\ndr\ndy\n1\n\u03b1\u22121\nE[S1 F (y, (y\u2206St , t \u2264 1))] .\n\u03bdr (dx) F (r, x) =\n(1+\u03b1)/\u03b1\n\u03b1\u0393([\u03b1 \u2212 1]/\u03b1) r\n\u0393(2 \u2212 \u03b1)\ny\nThis implies that for a.a. r > 0,\nZ\n\u03b1(\u03b1 \u2212 1)\u0393([\u03b1 \u2212 1]/\u03b1) 1/\u03b1\n\u03bdr (dx) F (x) =\nr E[S1 F (r(\u2206St /S1 , t \u2264 1))],\n\u0393(2 \u2212 \u03b1)\nZ\nZ\n1/\u03b1\nand thus \u03bdr (dx) F (x) = r\n\u03bd1 (dx) F (rx), with\nZ\n\n\u03bd1 (dx) F (x) =\n\n\u03b1(\u03b1 \u2212 1)\u0393([\u03b1 \u2212 1]/\u03b1)\nE[S1 F ((\u2206St /S1 , t \u2264 1))].\n\u0393(2 \u2212 \u03b1)\n\n\u0003\n9.1. An other representation of the fragmentation. Following the ideas in [1, 3], we\ngive an other representation of the fragmentation process described in Section 8, using a\nPoisson point measure under the epigraph of the height process.\nWe consider a fragmentation process, as time \u03b8 increases, of the CRT, by cutting at nodes\n(set of points (s, a) such that \u03bas ({a}) > 0, where \u03ba is defined in (6)). More precisely, we\nconsider, conditionally on the CRT or equivalently on the exploration process \u03c1, a Poisson\npoint process, Q(d\u03b8, ds, da) under the epigraph of H, with intensity d\u03b8 q\u03c1 (ds, da), where\n(47)\n\nq\u03c1 (ds, da) =\n\nds \u03bas (da)\n,\nds,a \u2212 gs,a\n\nwith ds,a = sup{u \u2265 s, min{Hv , v \u2208 [s, u]} \u2265 a} and gs,a = inf{u \u2264 s, min{Hv , v \u2208 [u, s]} \u2265\na}. (The set [gs,a , ds,a ] \u2282 [0, \u03c3] represent the individuals who have a common ancestor with\nthe individual s after or at generation a.)\nNotice that from this representation, the cutting times of the nodes are, conditionally on\nthe CRT, independent exponential random time, and their parameter is equal to the mass of\nthe node (defined as the mass of \u03ba or equivalently as the value of the jump of X corresponding\nto the given node).\nWe say two points s, s\u2032 \u2208 [0, \u03c3] belongs to the same fragment at time \u03b8, if there is no cut on\ntheir lineage down to their most recent common ancestor Hs,s\u2032 : that is for v = s and v = s\u2032 ,\nZ\n1[Hs,s\u2032 ,Hv ] (a)1[gv,a ,dv,a ] (u)Q([0, \u03b8], du, da) = 0.\n\nThis define an equivalence relation, and we call fragment an equivalent class. Let \u039b\u03b8 be the\nsequences of Lebesgue measures of the corresponding equivalent classes ranked in decreasing\norder.\nIt is clear that conditionally on the CRT, the process (\u039b\u03b8 , \u03b8 \u2265 0) as the same distribution\nas the fragmentation process defined in Section 8. Roughly speaking, in Section 3 (which\nleads to the fragmentation of Section 8) we mark the node as they appear: that is, for a given\nlevel a, the node {s; \u03bas ({a}) > 0} is marked at gs,a . Whereas in this Section the same node is\nmarked uniformly on [gs,a , ds,a ]. In both case, the cutting times of the nodes are, conditionally\non the CRT, independent exponential random time, and their parameter is equal to the mass\nof the node (defined as the common value of \u03bau ({a}) for u \u2208 {s; \u03bas ({a}) > 0}, or equivalently\nas the value of the jump of X corresponding to the given node).\n\n\f38\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nNow, we define the fragments of the L\u00e9vy snake corresponding to the cutting of \u03c1 according\nto the measure q\u03c1 . For (s, a) chosen according to the measure q\u03c1 (ds, da), we can define the\n \u0303 of \u03c1 by considering\nfollowing L\u00e9vy snake fragments (\u03c1i , i \u2208 I)\n\u2022 the open intervals of excursion after s of H above level a: ((\u03b1i , \u03b2i ), i \u2208 I \u0303+ ), which are\nsuch that \u03b1i > s, H\u03b1i = H\u03b2i = a, and for s\u2032 \u2208 (\u03b1i , \u03b2i ) we have Hs\u2032 > a and Hs\u2032 ,s = a\n(recall definition (3));\n\u2022 the open intervals of excursion before s of H above level a: ((\u03b1i , \u03b2i ), i \u2208 I \u0303\u2212 ), which\nare such that \u03b2i < s, H\u03b1i = H\u03b2i = a, and for s\u2032 \u2208 (\u03b1i , \u03b2i ) we have Hs\u2032 > a and\nHs\u2032 ,s = a;\n\u2022 the excursion, is , of H above level a that straddle s: (\u03b1is , \u03b2is ), which is such that\n\u03b1is < s < \u03b2is , H\u03b1is = H\u03b2is = a, and for s\u2032 \u2208 (\u03b1is , \u03b2is ) we have Hs\u2032 > a and Hs\u2032 ,s = a;\n\u2022 the excursion, i0 , of H under level a: {s \u2208 [0, \u03c3]; Hs\u2032 ,s < a} = [0, \u03b1i0 ) \u222a (\u03b2i0 , \u03c3].\nFor i \u2208 I \u0303+ \u222a I \u0303\u2212 \u222a {is }, we set \u03c1i = (\u03c1is , s \u2265 0) where\nZ\nZ\nf (r)\u03c1is (dr) = f (r \u2212 a)1{r>a} \u03c1(\u03b1i +s)\u2227\u03b2i (dr)\n\nfor f \u2208 B+ (R). For i0 , we set \u03c1i0 = (\u03c1is0 , s \u2265 0) where \u03c1is0 = \u03c1s if s < \u03b1i0 and \u03c1is0 = \u03c1s\u2212\u03b2i0 +\u03b1i0\n \u0303 correspond to the\nif s > \u03b2i0 . Eventually, we set I \u0303 = I \u0303+ \u222a I \u0303\u2212 \u222a {is , i0 }. And (\u03c1i , i \u2208 I)\nfragments of the L\u00e9vy snake corresponding to the cutting of \u03c1 according to one point chosen\n \u0303 under N.\nwith the measure q\u03c1 . We shall denote \u03bd\u0303\u03c1 the distribution of (\u03c1i , i \u2208 I)\nIn Section 9.3, we shall use \u03c3 i , the length of fragment \u03c1i . For i \u2208 I \u0303\u2212 \u222a I \u0303+ , we have\ni0\ni0\nis\nis\nis\ni\n= s \u2212 \u03b1is (resp.\n(resp. \u03c3 i0 = \u03c3\u2212\n+ \u03c3+\n), where \u03c3\u2212\n+ \u03c3+\n\u03c3 = \u03b2i \u2212 \u03b1i . We also have \u03c3 is = \u03c3\u2212\ni0\ni0\nis\n\u03c3\u2212 = \u03b1i0 ) is the length of the fragment before s and \u03c3+ = \u03b2is \u2212 s (resp. \u03c3+\n= \u03c3 \u2212 \u03b2i0 ) is\nP\nthe length of the fragment after s. Notice that N-a.e. \u03c3 = i\u2208I \u0303 \u03c3 i .\n\n9.2. The dislocation process is a point process. Let T the set of time jumps of the\nPoisson process Q. For \u03b8 \u2208 T , consider L(\u03b8\u2212) = (\u03c1i , i \u2208 I (\u03b8\u2212) ) and L(\u03b8) = (\u03c1i , i \u2208 I (\u03b8) ) the\nfamilies of L\u00e9vy snakes defined in Remark 8.2. The length, ranked in decreasing order, of\nthose families of L\u00e9vy snakes correspond respectively to the fragmentation process just before\ntime \u03b8 and at time \u03b8. Notice that for \u03b8 \u2208 T the families L(\u03b8\u2212) and L(\u03b8) agree but for only\none snake \u03c1i\u03b8 \u2208 L(\u03b8\u2212) which fragments in a family (\u03c1i , i \u2208 I \u0303(\u03b8) ) \u2282 L(\u03b8) . Thus we have that\n\u0010\n\u0011[\nL(\u03b8) = L(\u03b8\u2212) \\{\u03c1i\u03b8 }\n(\u03c1i , i \u2208 I \u0303(\u03b8) ).\n\nFrom the representation of the previous Section, this fragmentation is given by cutting the\nL\u00e9vy snake according to the measure q\u03c1 : that is the measure \u03bd\u0303\u03c1 defined at the end of Section\n9.1. From Lemma 8.6 and the construction of the L\u00e9vy Poisson Snake, we deduce that\nX\n\u03b4\u03b8,L(\u03b8\u2212) ,(\u03c1i ,i\u2208I \u0303(\u03b8) )\n\u03b8\u2208T\n\nP\nis a point process with intensity d\u03b8 \u03b4L(\u03b8\u2212) \u03c1\u2208L(\u03b8\u2212) \u03bd\u0303\u03c1 .\nNotice the evolution of a tagged fragment of the L\u00e9vy snake has the same distribution as\nthe evolution of the fragment of the L\u00e9vy snake which contains 0, say \u03c10,(\u03b8) \u2208 L(\u03b8) . (This is\nknown as the re-rooting property of the CRT.) Then, we get that\nX\nX\n\u03b4\u03b8,(\u03c1i ,i\u2208I \u0303(\u03b8) ) =\n\u03b4\u03b8,(\u03c1i ,i\u2208I \u0303(\u03b8) ) 1{0 belongs to (\u03c1i ,i\u2208I \u0303(\u03b8) )} ,\n\u03b8\u2208T0\n\n\u03b8\u2208T\n\nwhere T0 is the set of time fragmentation of the fragment which contains 0, is a point process\nwith intensity d\u03b8 \u03bd\u0303\u03c10,(\u03b8\u2212) .\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n39\n\nP\nNow, in the dislocation process of the fragmentation, \u03b4(d\u03b8, dx) = \u03b8\u2032 \u2208T0 \u03b4\u03b8\u2032 ,x(\u03b8\u2032 ) (d\u03b8, dx),\nthe sequences x(\u03b8 \u2032 ) are the length ranked in decreasing order, (\u03c3 i , i \u2208 I \u0303(\u03b8) ), of the L\u00e9vy snakes\n(\u03c1i , i \u2208 I \u0303(\u03b8) ). Using a projection argument, one can check that the dislocation process is a\npoint process with intensity d\u03b8 \u03bd\u03c30,(\u03b8\u2212) , where \u03c3 0,(\u03b8\u2212) is the length of \u03c10,(\u03b8\u2212) and \u03bd\u03c30,(\u03b8\u2212) is\nthe distribution of the decreasing lengths of L\u00e9vy snakes under \u03bd\u0303\u03c10,(\u03b8\u2212) , integrated w.r.t. to\nthe law of \u03c10,(\u03b8\u2212) conditionally on \u03c3 0,(\u03b8\u2212) . More precisely we have \u03c0\u2217 (dr)-a.e.\n\u0014Z\n\u0015\nZ\ni\ni\n \u0303 \u03c1 (d(\u03c1 , i \u2208 I))\n \u0303 ,\nF ((\u03c3 , i \u2208 I))\u03bd\u0303\nF (x)\u03bdr (dx) = Nr\nS\u2193\n\n \u0303 as to be underfor any non-negative measurable function F defined on S \u2193 , where (\u03c3 i , i \u2208 I)\ni\n \u0303\nstood as the family of length, of the fragments (\u03c1 , i \u2208 I), ranked in decreasing size.\nThis prove that the dislocation process is a point process. And we will now explicit the\nfamily of dislocation measures (\u03bdr , r > 0).\nAs computations are more tractable under N than under Nr , we shall compute for \u03bb \u2265 0,\nand any non-negative measurable function, F , defined on S \u2193\nZ\ne\u2212\u03bbr F (x)\u03c0\u2217 (dr)\u03bdr (dx).\nR+ \u00d7S \u2193\n\nFrom the definition of \u03bd\u0303\u03c1 , and using the notation at the end of Section 9.1, we get that this\nlast quantity is equal to\n\u0014\n\u0015\nZ\n\u2212\u03bb\u03c3\ni\n \u0303\n(48)\nN e\nq\u03c1 (ds, da)F ((\u03c3 , i \u2208 I)) ,\n \u0303 as to be understood as the family of length ranked in decreasing size.\nwhere (\u03c3 i , i \u2208 I)\n9.3. Computation of dislocation measures. In order to compute quantities like (48), we\nshall consider for p > 0, p\u2032 > 0 and h \u2208 B+ (M((0, +\u221e)))\n\uf8ee\n\uf8f9\nZ\nX\nX\n\u0001\ni0\n\u2032 is\nA = N \uf8f0e\u2212\u03bb\u03c3 q\u03c1 (ds, da)(\u03c3 is +\n\u03c3 i ) e\u2212p\u03c3 \u2212p \u03c3 h\n\u03b4\u03c3i \uf8fb .\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\nP\n\u03bas (da)\nand since ds,a \u2212 gs,a = \u03c3 is + i\u2208I \u0303\u2212 \u222aI \u0303+ \u03c3 i , we get\nds,a \u2212 gs,a\n\uf8f9\n\uf8ee\nZ \u03c3 Z\nP\nX\ni\n\u0001\n\u2032\ni\ni\n\u2212\u03bb\n\u03c3\ns\n0\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\uf8fb.\n\u03b4\u03c3i e\nds \u03bas (da) e\u2212(p+\u03bb)\u03c3 \u2212(p +\u03bb)\u03c3 h\nA = N\uf8f0\n\nAs q\u03c1 (ds, da) =\n\n0\n\nWe set h(\u03bb)\n\nX\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\n\u0001\n\u03b4\u03c3i = h\n\nB = e\u2212(p+\u03bb)\u03c3\n\nX\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\ni0 \u2212(p\u2032 +\u03bb)\u03c3 is\n\n\u0001 \u2212\u03bb P i\u2208I \u0303 \u222aI \u0303 \u03c3i\n\u2212 +\n\u03b4\u03c3i e\n. Now, we can replace\nh(\u03bb)\n\nX\n\n\u03b4\u03c3i\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\ni0\n\n\u2032\n\nis\n\ni0\n\n\u2032\n\n\u0001\n\nis\n\n= e\u2212(p+\u03bb)\u03c3\u2212 \u2212(p +\u03bb)\u03c3\u2212 \u2212(p+\u03bb)\u03c3+ \u2212(p +\u03bb)\u03c3+ h(\u03bb)\n\nX\n\ni\u2208I \u0303\u2212\n\n\u03b4\u03c3i +\n\nX\n\ni\u2208I \u0303+\n\n\u03b4\u03c3i\n\n\u0001\n\n\f40\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nby its optional projection B \u2032 :\ni0\n\nis\n\n\u2032\n\nB \u2032 = e\u2212(p+\u03bb)\u03c3\u2212 \u2212(p +\u03bb)\u03c3\u2212\nR\nR\nh\nX\n\u0001i\n\u2212(p+\u03bb) 0\u03c3 1{H0,u <a} du\u2212(p\u2032 +\u03bb) 0\u03c3 1{H0,u >a} du\nh(\u03bb) \u03bc\u2032 +\nE\u2217\u03c1s e\n\u03b4\u03c3j\nj\u2208I \u0303+\n\n\u03bc\u2032 =\n\nP\n\n\u03bc\u2032 =\n\nP\n\n.\ni\u2208I \u0303\u2212\n\n\u03b4\u03c3 i\n\ni\u2208I \u0303\u2212\n\n\u03b4\u03c3 i\n\nUsing notations introduced above Lemma 3.3, we have\ni0\n\nis\n\n\u2032\n\nB \u2032 = e\u2212(p+\u03bb)\u03c3\u2212 \u2212(p +\u03bb)\u03c3\u2212\nh\nP\nP\n\u2032\nE\u2217\u03c1s e\u2212(p+\u03bb) k\u2208I \u03c3k 1{hk <a} \u2212(p +\u03bb) k\u2208I \u03c3k 1{hk >a} h(\u03bb) \u03bc\u2032 +\n\nX\n\n\u03b4\u03c3k\n\nk\u2208I;hk =a\n\n\u0001i\n\n.\n\nThen we deduce from Lemma 3.3, that\ni0\n\nis\n\n\u2032\n\nB \u2032 = e\u2212(p+\u03bb)\u03c3\u2212 \u2212(p +\u03bb)\u03c3\u2212\n\n\u2212(p+\u03bb)\u03c3 ]\u2212\u03c1 ((a,+\u221e))N[1\u2212e\u2212(p\u2032 +\u03bb)\u03c3 ]\ns\n\ne\u2212\u03c1s ([0,a))N[1\u2212e\ni0\n\nis\n\n\u2032\n\n= e\u2212(p+\u03bb)\u03c3\u2212 \u2212(p +\u03bb)\u03c3\u2212 e\u2212\u03c1s ([0,a))\u03c8\n\nE[h(\u03bb) (\u03bc\u2032 + P)]\n\n\u22121 (p+\u03bb)\u2212\u03c1 ((a,+\u221e))\u03c8 \u22121 (p\u2032 +\u03bb)\ns\n\n\u03bc\u2032 =\n\nP\n\ni\u2208I \u0303\u2212\n\nE[h(\u03bb) (\u03bc\u2032 + P)]\n\n\u03b4\u03c3 i\n\n\u03bc\u2032 =\n\nP\n\n,\ni\u2208I \u0303\u2212\n\n\u03b4\u03c3 i\n\nwhere P is under P a Poisson point measure with intensity \u03c1s ({a})N[d\u03c3] = \u03c1s ({a})\u03c0\u2217 (dr).\nBy time reversibility (see Corollary 3.1.6 in [10]), we get\nA=N\n\n\"Z\n\n\u03c3\n\nds\n0\n\nZ\n\ni0\n\n\u2032\n\nis\n\n\u03bas (da) e\u2212(p+\u03bb)\u03c3\u2212 \u2212(p +\u03bb)\u03c3\u2212\n\n\u2212\u03c1s ([0,a))\u03c8\u22121 (p+\u03bb)\u2212\u03c1s ((a,+\u221e))\u03c8\u22121 (p\u2032 +\u03bb)\n\ne\n\n=N\n\n\"Z\n\n\u03c3\n\nds\n0\n\nZ\n\ni0\n\n\u2032\n\nE[h(\u03bb) (\u03bc\u2032 + P)]\n\n\u03bc\u2032 =\n\nP\n\ni\u2208I \u0303\u2212\n\n\u03b4\u03c3 i\n\n#\n\nis\n\n\u03bas (da) e\u2212(p+\u03bb)\u03c3+ \u2212(p +\u03bb)\u03c3+\n\n\u2212\u03b7s ([0,a))\u03c8\u22121 (p+\u03bb)\u2212\u03b7s ((a,+\u221e))\u03c8\u22121 (p\u2032 +\u03bb)\n\ne\n\nE[h(\u03bb) (\u03bc\u2032 + P \u2032 )]\n\n\u03bc\u2032 =\n\nP\n\n#\n\n,\n\ni\u2208I \u0303+\n\n\u03b4\u03c3 i\n\nwhere P \u2032 is under P a Poisson point measure with intensity \u03b7s ({a})\u03c0\u2217 (d\u03c3). Using the same\ncomputation as above, we eventually get\nA=N\n\n\u0014Z\n\n0\n\n\u03c3\n\nds\n\nZ\n\n\u2212\u03bas ([0,a))\u03c8\u22121 (p+\u03bb)\u2212\u03bas ((a,+\u221e))\u03c8\u22121 (p+\u03bb)\n\n\u03bas (da) e\n\n\u0015\nE[h(\u03bb) (P )] ,\n\u2032\u2032\n\nwhere P \u2032\u2032 is under P a Poisson point measure with intensity \u03bas ({a})\u03c0\u2217 (d\u03c3). We write\ng\u03bb (\u03bas ({a})) for E[h(\u03bb) (P \u2032\u2032 )]. Thanks to the Poisson representation of Proposition 2.6, we\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n41\n\nget\n\uf8ee\nZ\n\uf8f0\nA=E\n=\n\nZ\n\n\u221e\n\nX\n\n\u2212\n\nli e\n\nxi \u2264a\n\n\uf8ee\n\n\u221e\n\nZ\n\n\u221e\n\nda E \uf8f0\n\n\uf8ee\n\nda\nR\n\nZ\n\nX\n\nli e\u2212xi\n\nxi \u2264a\n\u2032\n\nX\n\nP\n\nli e\u2212xi \u03c8 (\u03c8\n\nxj <xi lj \u03c8\n\nR\n\n\u22121 (p+\u03bb)\u2212\n\nP\n\na\u2265xj >xi lj \u03c8\n\n\u2212l\u03c8 \u22121 (p+\u03bb)\n\nl\u03c0(dl) [1\u2212e\n\n\u22121 (p+\u03bb))\u2212(a\u2212x\n\ni )\u03c8\n\n\u2032 (\u03c8 \u22121 (p\u2032 +\u03bb))\n\nl\u03c0(dl)\n\nZ\n\n\u2032\n\ndt 1[0,a] (t) l e\u2212t\u03c8 (\u03c8\n\n\u03bb))\n\n\u22121 (p\u2032 +\u03bb)\n\nR\n\n]\u2212(a\u2212xi )\n\nxi \u2264a\n\n(0,\u221e)\n2\n(0,\u221e) l g\u03bb (l) \u03c0(dl)\n\u03c8 \u2032 (\u03c8 \u22121 (p + \u03bb))\u03c8 \u2032 (\u03c8 \u22121 (p\u2032 +\n0\n\n=\n\n0\n\nZ\n\n0\n\n=\n\nda e\u2212\u03b10 a\n\nda e\u2212\u03b10 a E \uf8f0\n\n0\n\n=\n\n\u221e\n\n\uf8f9\n\ng\u03bb (li )\uf8fb\n\n\u2212l\u03c8 \u22121 (p\u2032 +\u03bb)\n\nl\u03c0(dl) [1\u2212e\n\n\uf8f9\n\ng\u03bb (li )\uf8fb\n\n\u22121 (p+\u03bb))\u2212(a\u2212t)\u03c8 \u2032 (\u03c8 \u22121 (p\u2032 +\u03bb))\n\n]\n\n\uf8f9\n\ng\u03bb (li )\uf8fb\n\ng\u03bb (l)\n\n,\n\nwhere we used (22) for the fourth equality.\nOn the other side, let (\u2206St , t \u2265 0) be the jumps of a subordinator S = (St , t \u2265 0) with\nLaplace exponent \u03c8 \u22121 and L\u00e9vy measure \u03c0\u2217 . Standard computations yield for r > 0,\n\uf8ee\n\uf8f9\nX\nX\n\u0001\n\u2032\nG(r) = E \uf8f0e\u2212\u03bbSr\n\u03b4\u2206Su \uf8fb\n\u2206St \u2206Ss e\u2212p\u2206St \u2212p \u2206Ss h\nt\u2264r,s\u2264r, t6=s\n\n\uf8ee\n\n= E\uf8f0\n= r2\n\nX\n\nu\u2264r,u6\u2208{s,t}\n\n\u2206St \u2206Ss e\u2212(p+\u03bb)\u2206St\n\n\u2212(p\u2032 +\u03bb)\u2206S\n\ns\n\nh(\u03bb)\n\nt\u2264r,s\u2264r, t6=s\n\n\u0014Z\n\n=r \u03c8\n\nu\u2264r,u6\u2208{s,t}\n\n\u03c0\u2217 (dl) l e\u2212(p+\u03bb)l\n\n2 \u22121 \u2032\n\nX\n\n(p + \u03bb)\u03c8\n\n\u22121 \u2032\n\n\u0015 \u0014Z\n\n\u2212(p\u2032 +\u03bb)l\n\n\u03c0\u2217 (dl) l e\n\n\u0015\n\n(p\u2032 + \u03bb)g\u03bb (r),\n\n\uf8ee\n\nE \uf8f0h(\u03bb)\n\nX\nu\u2264r\n\n\uf8f9\n\u0001\n\u03b4\u2206Su \uf8fb\n\u0001\n\n\uf8f9\n\n\u03b4\u2206Su \uf8fb\n\nP\n\u2032\nas u\u2264r \u03b4\u2206Su is a Poisson measure with intensity r\u03c0\u2217 (dv). Notice that \u03c8 \u22121 = 1/\u03c8 \u2032 \u25e6 \u03c8 \u22121 to\nconclude that\nR\nZ\n2\n(0,\u221e) r g\u03bb (r) \u03c0(dr)\n.\n\u03c0(dr)G(r) = \u2032 \u22121\n\u03c8 (\u03c8 (p + \u03bb))\u03c8 \u2032 (\u03c8 \u22121 (p\u2032 + \u03bb))\nTherefore, we deduce that for any p > 0, p\u2032 > 0 and h \u2208 B+ (M((0, +\u221e))), we have\n\uf8ee\n\nN \uf8f0e\u2212\u03bb\u03c3\n\nZ\n\nX\n\nq\u03c1 (ds, da)(\u03c3 is +\n\n\u03c3 i ) e\u2212p\u03c3\n\ni0 \u2212p\u2032 \u03c3 is\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\n=\n\nZ\n\n\uf8ee\n\n\u03c0(dr)E \uf8f0e\u2212\u03bbSr\n\nX\n\nt\u2264r,s\u2264r, t6=s\n\nX\n\n\uf8f9\n\ni\u2208I \u0303\u2212 \u222aI \u0303+\n\n\u0001\n\u03b4\u03c3i \uf8fb\n\n\u2206St \u2206Ss e\u2212p\u2206St\n\n\u2212p\u2032 \u2206S\n\nh\n\ns\n\nh\n\nX\n\nu\u2264r,u6\u2208{s,t}\n\n\u0001\n\n\uf8f9\n\n\u03b4\u2206Su \uf8fb .\n\n\f42\n\nROMAIN ABRAHAM AND JEAN-FRAN\u00c7OIS DELMAS\n\nRecall I \u0303 = I \u0303\u2212 \u222a I \u0303+ \u222a {i0 , is }. From monotone class Theorem, we deduce that for any h \u2208\nB+ (R+ \u00d7 R+ \u00d7 M((0, +\u221e))),\n\uf8ee\n\uf8f9\nZ\nZ\nX\n\u0001\n\u03c0\u2217 (dr) e\u2212\u03bbr Nr \uf8f0 q(ds, da)h \u03c3 i0 , \u03c3 is ,\n\u03b4\u03c3i \uf8fb\n \u0303 I \u0303+\ni\u2208I\u2212\u222a\n\n=\n\nZ\n\n\uf8ee\n\n\u03c0(dr)E \uf8f0Sr e\u2212\u03bbSr\n\nX\n\nt\u2264r,s\u2264r, t6=s\n\n\u2206St \u2206Ss\nh \u2206St , \u2206Ss ,\nSr Sr \u2212 \u2206St\n\nX\n\nu\u2264r,u6\u2208{s,t}\n\n\u0001\n\n\uf8f9\n\n\u03b4\u2206Su \uf8fb .\n\nFor a measurable non-negative function F defined on S \u2193 , we deduce that\n\u0014Z\n\u0015 Z\nZ\nh\n\u0001\n\u0001i\ni\n\u2212\u03bbr\n \u0303\nq(ds, da)F (\u03c3 , i \u2208 I) = \u03c0(dr)E Sr e\u2212\u03bbSr F (\u2206Su , u \u2264 r) ,\n\u03c0\u2217 (dr) e\nNr\n\n \u0303 and (\u2206Su , u \u2264 r) are to be understood as the family of length or jumps\nwhere (\u03c3 i , i \u2208 I)\nranked in decreasing size. From the end of Section 9.2, we deduce that\nZ\nZ\nh\n\u0001i\ne\u2212\u03bbr F (x)\u03c0\u2217 (dr)\u03bdr (dx) = \u03c0(dv)E Sv e\u2212\u03bbSv F (\u2206Su , u \u2264 v) .\nR+ \u00d7S \u2193\n\nFrom definition (46) of \u03bc, we deduce that\nZ\nZ\n\u2212\u03bbr\ne\nF (x)\u03c0\u2217 (dr)\u03bdr (dx) = e\u2212\u03bbr F (x) r\u03bc(dr, dx).\nR+ \u00d7S \u2193\n\nThis ends the proof of theorem 9.1.\n\nReferences\n[1]\n[2]\n[3]\n[4]\n[5]\n[6]\n[7]\n[8]\n[9]\n[10]\n[11]\n[12]\n[13]\n[14]\n[15]\n[16]\n[17]\n[18]\n\nR. ABRAHAM and L. SERLET. Poisson snake and fragmentation. Elect. J. of Probab., 7, 2002.\nD. ALDOUS. The continuum random tree III. Ann. Probab., 21(1):248\u2013289, 1993.\nD. ALDOUS and J. PITMAN. The standard additive coalescent. Ann. Probab., 26(4):1703\u20131726, 1998.\nJ. BERTOIN. L\u00e9vy processes. Cambridge University Press, Cambridge, 1996.\nJ. BERTOIN. A fragmentation process connected to Brownian motion. Probab. Th. Rel. Fields, 117:289\u2013\n301, 2000.\nJ. BERTOIN. Self-similar fragmentations. Ann. Inst. Henri Poincar\u00e9, 38(3):319\u2013340, 2000.\nJ. BERTOIN. Random fragmentation and coagulation processes. To appear, 2006.\nJ. BERTOIN, J.-F. LE GALL, and Y. LE JAN. Spatial branching processes and subordination. Canad.\nJ. of Math., 49(1):24\u201354, 1997.\nR. BLUMENTHAL. Excursions of Markov processes. Birkh\u00e4user, Boston, 1992.\nT. DUQUESNE and J.-F. LE GALL. Random trees, L\u00e9vy processes and spatial branching processes,\nvolume 281. Ast\u00e9risque, 2002.\nT. DUQUESNE and M. WINKEL. Growth of L\u00e9vy trees. To appear\nS. N. ETHIER and T. G. KURTZ. Markov processes. Wiley, 1986.\nJ. JACOD. Calcul stochastique et probl\u00e8mes de martingales, volume 714 of Lecture Notes in Mathematics.\nSpringer, 1979.\nJ.-F. LE GALL and Y. LE JAN. Branching processes in L\u00e9vy processes: Laplace functionals of snake\nand superprocesses. Ann. Probab., 26:1407\u20131432, 1998.\nJ.-F. LE GALL and Y. LE JAN. Branching processes in L\u00e9vy processes: The exploration process. Ann.\nProbab., 26:213\u2013252, 1998.\nG. MIERMONT. Ordered additive coalescent and fragmentations and stable subordinators. Elect. J. of\nProbab., 6, 2001.\nG. MIERMONT. Self-similar fragmentations derived from the stable tree i: splitting at heights. Probab.\nTh. Rel. Fields, 127(3):423\u2013454, 2003.\nG. MIERMONT. Self-similar fragmentations derived from the stable tree ii: splitting at nodes. Probab.\nTh. Rel. Fields, (to appear), 2004.\n\n\fFRAGMENTATION ASSOCIATED TO L\u00c9VY PROCESSES\n\n43\n\nMAPMO, Universit\u00e9 d'Orl\u00e9ans, B.P. 6759, 45067 Orl\u00e9ans cedex 2 FRANCE\nE-mail address: romain.abraham@univ-orleans.fr\nENPC-CERMICS, 6-8 av. Blaise Pascal, Champs-sur-Marne, 77455 Marne La Vall\u00e9e, France.\nE-mail address: delmas@cermics.enpc.fr\n\n\f"}