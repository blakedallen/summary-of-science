{"id": "http://arxiv.org/abs/1102.4971v2", "guidislink": true, "updated": "2011-06-10T14:32:34Z", "updated_parsed": [2011, 6, 10, 14, 32, 34, 4, 161, 0], "published": "2011-02-24T12:28:36Z", "published_parsed": [2011, 2, 24, 12, 28, 36, 3, 55, 0], "title": "Elementary affine $lambda$-calculus with multithreading and side effects", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.0675%2C1102.5214%2C1102.2556%2C1102.5494%2C1102.5439%2C1102.4562%2C1102.4762%2C1102.1022%2C1102.1903%2C1102.1165%2C1102.1350%2C1102.1331%2C1102.4111%2C1102.1434%2C1102.5167%2C1102.4246%2C1102.0660%2C1102.4308%2C1102.3771%2C1102.5169%2C1102.0691%2C1102.1173%2C1102.4533%2C1102.3532%2C1102.3444%2C1102.5531%2C1102.1651%2C1102.1637%2C1102.2597%2C1102.0125%2C1102.1398%2C1102.1939%2C1102.1634%2C1102.0409%2C1102.3591%2C1102.3714%2C1102.4600%2C1102.3051%2C1102.2766%2C1102.4682%2C1102.4103%2C1102.2039%2C1102.0966%2C1102.3098%2C1102.5108%2C1102.0806%2C1102.2189%2C1102.5638%2C1102.0871%2C1102.3927%2C1102.4695%2C1102.3818%2C1102.4572%2C1102.2563%2C1102.0276%2C1102.0309%2C1102.1804%2C1102.5738%2C1102.5205%2C1102.2861%2C1102.5645%2C1102.5682%2C1102.2399%2C1102.1164%2C1102.3950%2C1102.0946%2C1102.5406%2C1102.1638%2C1102.3733%2C1102.4895%2C1102.3501%2C1102.5285%2C1102.1833%2C1102.5282%2C1102.1017%2C1102.2636%2C1102.5728%2C1102.2022%2C1102.4971%2C1102.4702%2C1102.1341%2C1102.4396%2C1102.1407%2C1102.0870%2C1102.5183%2C1102.4945%2C1102.1050%2C1102.3869%2C1102.3150%2C1102.4205%2C1102.4672%2C1102.2845%2C1102.3172%2C1102.2875%2C1102.1635%2C1102.0273%2C1102.3819%2C1102.4279%2C1102.3933%2C1102.1312%2C1102.1934&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Elementary affine $lambda$-calculus with multithreading and side effects"}, "summary": "Linear logic provides a framework to control the complexity of higher-order\nfunctional programs. We present an extension of this framework to programs with\nmultithreading and side effects focusing on the case of elementary time. Our\nmain contributions are as follows. First, we provide a new combinatorial proof\nof termination in elementary time for the functional case. Second, we develop\nan extension of the approach to a call-by-value $lambda$-calculus with\nmultithreading and side effects. Third, we introduce an elementary affine type\nsystem that guarantees the standard subject reduction and progress properties.\nFinally, we illustrate the programming of iterative functions with side effects\nin the presented formalism.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.0675%2C1102.5214%2C1102.2556%2C1102.5494%2C1102.5439%2C1102.4562%2C1102.4762%2C1102.1022%2C1102.1903%2C1102.1165%2C1102.1350%2C1102.1331%2C1102.4111%2C1102.1434%2C1102.5167%2C1102.4246%2C1102.0660%2C1102.4308%2C1102.3771%2C1102.5169%2C1102.0691%2C1102.1173%2C1102.4533%2C1102.3532%2C1102.3444%2C1102.5531%2C1102.1651%2C1102.1637%2C1102.2597%2C1102.0125%2C1102.1398%2C1102.1939%2C1102.1634%2C1102.0409%2C1102.3591%2C1102.3714%2C1102.4600%2C1102.3051%2C1102.2766%2C1102.4682%2C1102.4103%2C1102.2039%2C1102.0966%2C1102.3098%2C1102.5108%2C1102.0806%2C1102.2189%2C1102.5638%2C1102.0871%2C1102.3927%2C1102.4695%2C1102.3818%2C1102.4572%2C1102.2563%2C1102.0276%2C1102.0309%2C1102.1804%2C1102.5738%2C1102.5205%2C1102.2861%2C1102.5645%2C1102.5682%2C1102.2399%2C1102.1164%2C1102.3950%2C1102.0946%2C1102.5406%2C1102.1638%2C1102.3733%2C1102.4895%2C1102.3501%2C1102.5285%2C1102.1833%2C1102.5282%2C1102.1017%2C1102.2636%2C1102.5728%2C1102.2022%2C1102.4971%2C1102.4702%2C1102.1341%2C1102.4396%2C1102.1407%2C1102.0870%2C1102.5183%2C1102.4945%2C1102.1050%2C1102.3869%2C1102.3150%2C1102.4205%2C1102.4672%2C1102.2845%2C1102.3172%2C1102.2875%2C1102.1635%2C1102.0273%2C1102.3819%2C1102.4279%2C1102.3933%2C1102.1312%2C1102.1934&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Linear logic provides a framework to control the complexity of higher-order\nfunctional programs. We present an extension of this framework to programs with\nmultithreading and side effects focusing on the case of elementary time. Our\nmain contributions are as follows. First, we provide a new combinatorial proof\nof termination in elementary time for the functional case. Second, we develop\nan extension of the approach to a call-by-value $lambda$-calculus with\nmultithreading and side effects. Third, we introduce an elementary affine type\nsystem that guarantees the standard subject reduction and progress properties.\nFinally, we illustrate the programming of iterative functions with side effects\nin the presented formalism."}, "authors": ["Antoine Madet", "Roberto M. Amadio"], "author_detail": {"name": "Roberto M. Amadio"}, "author": "Roberto M. Amadio", "links": [{"href": "http://arxiv.org/abs/1102.4971v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1102.4971v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.PL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1102.4971v2", "affiliation": "PPS", "arxiv_url": "http://arxiv.org/abs/1102.4971v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:1102.4971v2 [cs.PL] 10 Jun 2011\n\nAn Elementary Affine \u03bb-calculus\nwith Multithreading and Side Effects\u2217\nAntoine Madet\n\nRoberto M. Amadio\n\nLaboratoire PPS, Universit\u00e9 Paris Diderot\n{madet,amadio}@pps.jussieu.fr\n\nAbstract\nLinear logic provides a framework to control the complexity of higherorder functional programs. We present an extension of this framework\nto programs with multithreading and side effects focusing on the case of\nelementary time. Our main contributions are as follows. First, we provide\na new combinatorial proof of termination in elementary time for the functional case. Second, we develop an extension of the approach to a call-byvalue \u03bb-calculus with multithreading and side effects. Third, we introduce\nan elementary affine type system that guarantees the standard subject reduction and progress properties. Finally, we illustrate the programming\nof iterative functions with side effects in the presented formalism.\n\u2217 Work partially supported by project ANR-08-BLANC-0211-01 \"COMPLICE\" and the\nFuture and Emerging Technologies (FET) programme within the Seventh Framework Programme for Research of the European Commission, under FET-Open grant number: 243881\n(project CerCo).\n\n1\n\n\fContents\n1 Introduction\n\n3\n\n2 Elementary Time in a Modal \u03bb-calculus\n2.1 A Modal \u03bb-calculus . . . . . . . . . . . .\n2.1.1 Syntax . . . . . . . . . . . . . . .\n2.1.2 Operational Semantics . . . . . .\n2.2 Depth System . . . . . . . . . . . . . . .\n2.3 Elementary Bound . . . . . . . . . . . .\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n4\n4\n4\n5\n5\n7\n\n3 Elementary Time in a Modal \u03bb-calculus with Side Effects\n3.1 A Modal \u03bb-calculus with Multithreading and Regions . . . .\n3.1.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3.1.2 Operational Semantics . . . . . . . . . . . . . . . . . .\n3.2 Extended Depth System . . . . . . . . . . . . . . . . . . . . .\n3.3 Elementary Bound . . . . . . . . . . . . . . . . . . . . . . . .\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n10\n10\n10\n11\n12\n14\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n4 An Elementary Affine Type System\n\n16\n\n5 Expressivity\n19\n5.1 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n5.2 Iteration with Side Effects . . . . . . . . . . . . . . . . . . . . . . 19\n6 Conclusion\nA Proofs\nA.1 Proof\nA.2 Proof\nA.3 Proof\nA.4 Proof\nA.5 Proof\nA.6 Proof\nA.6.1\nA.6.2\nA.6.3\nA.7 Proof\nA.7.1\nA.7.2\nA.7.3\nA.7.4\nA.7.5\nA.7.6\n\n21\n\nof theorem 3.5 . . . . . . . . . . . . . .\nof proposition 3.6 . . . . . . . . . . . .\nof lemma 2.8 . . . . . . . . . . . . . . .\nof theorem 3.7 . . . . . . . . . . . . . .\nof proposition 4.1 . . . . . . . . . . . .\nof theorem 4.4 . . . . . . . . . . . . . .\nSubstitution . . . . . . . . . . . . . . .\nSubject Reduction . . . . . . . . . . .\nProgress . . . . . . . . . . . . . . . . .\nof theorem 5.3 . . . . . . . . . . . . . .\nSuccessor, addition and multiplication\nIteration schemes . . . . . . . . . . . .\nCoercion . . . . . . . . . . . . . . . . .\nPredecessor and subtraction . . . . . .\nComposition . . . . . . . . . . . . . .\nBounded sums and products . . . . .\n\n2\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n23\n23\n27\n28\n29\n31\n32\n32\n33\n34\n36\n37\n38\n39\n39\n40\n41\n\n\f1\n\nIntroduction\n\nThere is a well explored framework based on Linear Logic to control the complexity of higher-order functional programs. In particular, light logics [11, 10, 3]\nhave led to a polynomial light affine \u03bb-calculus [13] and to various type systems for the standard \u03bb-calculus guaranteeing that a well-typed term has a\nbounded complexity [9, 8, 5]. Recently, this framework has been extended to a\nhigher-order process calculus [12] and a functional language with recursive definitions [4]. In another direction, the notion of stratified region [7, 1] has been\nused to prove the termination of higher-order multithreaded programs with side\neffects.\nOur general goal is to extend the framework of light logics to a higher-order\nfunctional language with multithreading and side effects by focusing on the\ncase of elementary time [10]. The key point is that termination does not rely\nanymore on stratification but on the notion of depth which is standard in light\nlogics. Indeed, light logics suggest that complexity can be tamed through a fine\nanalysis of the way the depth of the occurrences of a \u03bb-term can vary during\nreduction.\nOur core functional calculus is a \u03bb-calculus extended with a constructor '!'\n(the modal operator of linear logic) marking duplicable terms and a related let !\ndestructor. The depth of an occurrence in a \u03bb-term is the number of !\u2032 s that\nmust be crossed to reach the occurrence. Our contribution can be described as\nfollows.\n1. In Section 2 we propose a formal system called depth system that controls the depth of the occurrences and which is a variant of a system\nproposed in [13]. We show that terms well-formed in the depth system are\nguaranteed to terminate in elementary time under an arbitrary reduction\nstrategy. The proof is based on an original combinatorial analysis of the\ndepth system ([10] assumes a specific reduction strategy while [13] relies\non a standardization theorem).\n2. In Section 3, following previous work on an affine-intuitionistic system [2],\nwe extend the functional core with parallel composition and operations\nproducing side effects on an 'abstract' notion of state. We analyse the impact of side-effects operations on the depth of the occurrences and deduce\nan extended depth system. We show that it still guarantees termination\nof programs in elementary time under a natural call-by-value evaluation\nstrategy.\n3. In Section 4, we refine the depth system with a second order (polymorphic)\nelementary affine type system and show that the resulting system enjoys\nsubject reduction and progress (besides termination in elementary time).\n4. Finally, in Section 5, we discuss the expressivity of the resulting type\nsystem. On the one hand we check that the usual encoding of elementary\nfunctions goes through. On the other hand, and more interestingly, we\nprovide examples of iterative (multithreaded) programs with side effects.\n3\n\n\fThe \u03bb-calculi introduced are summarized in Table 1.1. For each concurrent language there is a corresponding functional fragment and each language\n(functional or concurrent) refines the one on its left hand side. The elementary\ncomplexity bounds are obtained for the \u03bb!\u03b4 and \u03bb!R\n\u03b4 calculi while the progress\nproperty and the expressivity results refer to their typed refinements \u03bb!EA and\n\u03bb!R\nEA , respectively. Proofs are available in Appendix A.\nFunctional \u03bb!\n\u2229\nConcurrent \u03bb!R\n\n\u2283 \u03bb!\u03b4\n\n\u2283 \u03bb!EA\n\n\u2283 \u03bb!R\n\u03b4\n\n\u2283 \u03bb!R\nEA\n\nTable 1.1: Overview of the \u03bb-calculi considered\n\n2\n\nElementary Time in a Modal \u03bb-calculus\n\nIn this section, we present our core functional calculus, a related depth system,\nand show that every term which is well-formed in the depth system terminates\nin elementary time under an arbitrary reduction strategy.\n\n2.1\n\nA Modal \u03bb-calculus\n\nWe introduce a modal \u03bb-calculus called \u03bb! . It is very close to the light affine\n\u03bb-calculus of Terui [13] where the paragraph modality '\u00a7' used for polynomial\ntime is dropped and where the '!' modality is relaxed as in elementary linear\nlogic [10].\n2.1.1\n\nSyntax\n\nTerms are described by the grammar in Table 2.1: We find the usual set of\nM, N ::= x, y, z . . . | \u03bbx.M | M N | !M | let !x = N in M\nTable 2.1: Syntax of \u03bb!\nvariables, \u03bb-abstraction and application, plus a modal operator '!' (read bang)\nand a let ! operator. We define !0 M = M and !n+1 M = !(!n M ). In the terms\n\u03bbx.M and let !x = N in M the occurrences of x in M are bound. The set of\nfree variables of M is denoted by FV(M ). The number of free occurrences of x\nin M is denoted by FO(x, M ). M [N/x] denotes the term M in which each free\noccurrence of x has been substituted by the term N .\nEach term has an abstract syntax tree as exemplified in Figure 2.1(a). A\npath starting from the root to a node of the tree denotes an occurrence of the\nprogram that is denoted by a word w \u2208 {0, 1}\u2217 (see Figure 2.1(b)).\nWe define the notion of depth:\n4\n\n\f\u03bbx\n\n\u01eb\n\n0\n\nlet !y\n\n0\n\n0\n\nx\n\n00\n\n!\n\n01\n\n0\n\n010\n\n@\ny\n\n0\n\ny\n\n(a)\n\n0100\n\n1\n0101\n\n1\n\n(b)\n\n1\n\n(c)\n\nFigure 2.1: Syntax tree of the term \u03bbx.let !y = x in !(yy), addresses and depths\nDefinition 2.1 (depth). The depth d(w) of an occurrence w is the number of\n!'s that the path leading to w crosses. The depth d(M ) of a term M is the\nmaximum depth of its occurrences.\nIn Figure 2.1(c), each occurrence is labelled with its depth. Thus d(\u03bbx.let !y =\nx in !(yy)) = 1. In particular, the occurrence 01 is at depth 0; what matters in\ncomputing the depth of an occurrence is the number of ! that precedes strictly\nthe occurrence.\n2.1.2\n\nOperational Semantics\n\nWe consider an arbitrary reduction strategy. Hence, an evaluation context E\ncan be any term with exactly one occurrence of a special variable [ ], the 'hole'.\nE[M ] denotes E where the hole has been substituted by M . The reduction rules\nare given in Table 2.2. The let ! is 'filtering' modal terms and 'destructs' the\nE[(\u03bbx.M )N ] \u2192 E[M [N/x]]\nE[let !x = !N in M ] \u2192 E[M [N/x]]\nTable 2.2: Operational semantics of \u03bb!\n\u2217\n\nbang of the term !N after substitution. In the sequel, \u2192 denotes the reflexive\nand transitive closure of \u2192.\n\n2.2\n\nDepth System\n\nBy considering that deeper occurrences have less weight than shallow ones, the\nproof of termination in elementary time [10] relies on the observation that when\nreducing a redex at depth i the following holds:\n(1) the depth of the term does not increase,\n(2) the number of occurrences at depth j < i does not increase,\n\n5\n\n\f(3) the number of occurrences at depth i strictly decreases,\n(4) the number of occurrences at depth j > i may be increased by a multiplicative factor k bounded by the number of occurrences at depth i + 1.\nTheses properties can be guaranteed by the following requirements:\n(i) in \u03bbx.M , x may occur at most once in M and at depth 0,\n(ii) in let !x = M in N , x may occur arbitrarily many times in N and at depth\n1.\nHence, the rest of this section is devoted to the introduction of a set of\ninferences rules called depth system. Every term which is valid in the depth\nsystem will terminate in elementary time. First, we introduce the judgement:\n\u0393 \u22a2\u03b4 M\nwhere \u03b4 is a natural number and the context \u0393 is of the form x1 : \u03b41 , . . . , xn : \u03b4n .\nWe write dom(\u0393) for the set {x1 , . . . , xn }. It should be interpreted as follows:\nThe free variables of !\u03b4 M may only occur at the depth specified\nby the context \u0393.\nThe inference rules of the depth system are presented in Table 2.3.\n\u0393, x : \u03b4 \u22a2\u03b4 x\n\u0393, x : \u03b4 \u22a2\u03b4 M\n\nFO(x, M ) \u2264 1\n\u03b4\n\n\u0393 \u22a2 \u03bbx.M\n\u0393 \u22a2\u03b4 N\n\n\u0393, x : (\u03b4 + 1) \u22a2\u03b4 M\n\u03b4\n\n\u0393 \u22a2 let !x = N in M\n\n\u0393 \u22a2\u03b4 M\n\u0393 \u22a2\u03b4 N\n\u03b4\n\u0393 \u22a2 MN\n\u0393 \u22a2\u03b4+1 M\n\u0393 \u22a2\u03b4 !M\n\nTable 2.3: Depth system: \u03bb!\u03b4\nWe comment on the rules. The variable rule says that the current depth of a\nfree variable is specified by the context. The \u03bb-abstraction rule requires that the\noccurrence of x in M is at the same depth as the formal parameter; moreover\nit occurs at most once so that no duplication is possible at the current depth\n(Property (3)). The application rule says that we may only apply two terms if\nthey are at the same depth. The let ! rule requires that the bound occurrences of\nx are one level deeper than the current depth; note that there is no restriction\non the number of occurrences of x since duplication would happen one level\ndeeper than the current depth. Finally, the bang rule is better explained in\na bottom-up way: crossing a modal occurrence increases the current depth by\none.\n\n6\n\n\fDefinition 2.2 (well-formedness). A term M is well-formed if for some \u0393 and\n\u03b4 a judgement \u0393 \u22a2\u03b4 M can be derived.\nExample 2.3. The term of Figure 1(a) is well-formed according to our depth\nsystem:\n\nx : \u03b4 \u22a2\u03b4 x\n\nx : \u03b4, y : \u03b4 + 1 \u22a2\u03b4+1 y\nx : \u03b4, y : \u03b4 + 1 \u22a2\u03b4+1 y\nx : \u03b4, y : \u03b4 + 1 \u22a2\u03b4+1 yy\nx : \u03b4, y : \u03b4 + 1 \u22a2\u03b4 !(yy)\nx : \u03b4 \u22a2\u03b4 let !y = x in !(yy)\n\u22a2\u03b4 \u03bbx.let !y = x in !(yy)\n\nOn the other hand, the followings term is not valid:\nP = \u03bbx.let !y = x in !(y!(yz))\nIndeed, the second occurrence of y in !(y!(yz)) is too deep of one level, hence\nreduction may increase the depth by one. For example, P !!N of depth 2 reduces\nto !(!N !(!N )z) of depth 3.\nProposition 2.4 (properties on the depth system). The depth system satisfies\nthe following properties:\n1. If \u0393 \u22a2\u03b4 M and x occurs free in M then x : \u03b4 \u2032 belongs to \u0393 and all occurrences of x in !\u03b4 M are at depth \u03b4 \u2032 .\n2. If \u0393 \u22a2\u03b4 M then \u0393, \u0393\u2032 \u22a2\u03b4 M .\n\u2032\n\n\u2032\n\n3. If \u0393, x : \u03b4 \u2032 \u22a2\u03b4 M and \u0393 \u22a2\u03b4 N then d(!\u03b4 M [N/x]) \u2264 max (d(!\u03b4 M ), d(!\u03b4 N ))\nand \u0393 \u22a2\u03b4 M [N/x].\n4. If \u0393 \u22a20 M and M \u2192 N then \u0393 \u22a20 N and d(M ) \u2265 d(N ).\n\n2.3\n\nElementary Bound\n\nIn this section, we prove that well-formed terms terminate in elementary time\nunder an arbitrary reduction strategy. To this end, we define a measure on\nterms based on the number of occurrences at each depth.\nDefinition 2.5 (measure). Given a term M and 0 \u2264 i \u2264 d(M ), let \u03c9i (M ) be\nthe number of occurrences in M of depth i increased by 2 (so \u03c9i (M ) \u2265 2). We\ndefine \u03bcin (M ) for n \u2265 i \u2265 0 as follows:\n\u03bcin (M ) = (\u03c9n (M ), . . . , \u03c9i+1 (M ), \u03c9i (M ))\nWe write \u03bcn (M ) for \u03bc0n (M ). We order the vectors of n + 1 natural number with\nthe (well-founded) lexicographic order > from right to left.\nWe derive a termination property by observing that the measure strictly\ndecreases during reduction.\n7\n\n\fProposition 2.6 (termination). If M is well-formed, M \u2192 M \u2032 and n \u2265 d(M )\nthen \u03bcn (M ) > \u03bcn (M \u2032 ).\nProof. We do this by case analysis on the reduction rules:\n\u2022 M = E[(\u03bbx.M1 )M2 ] \u2192 M \u2032 = E[M1 [M2 /x]]\nLet the occurrence of the redex (\u03bbx.M1 )M2 be at depth i. The restrictions\non the formation of terms require that x occurs at most once in M1 at\ndepth 0. Then \u03c9i (M ) \u2212 3 \u2265 \u03c9i (M \u2032 ) because we remove the nodes for\napplication and \u03bb-abstraction and either M2 disappears or the occurrence\nof the variable x in M1 disappears (both being at the same depth as the\nredex). Clearly \u03c9j (M ) = \u03c9j (M \u2032 ) if j 6= i, hence\n\u03bcn (M \u2032 ) \u2264 (\u03c9n (M ), . . . , \u03c9i+1 (M ), \u03c9i (M ) \u2212 3, \u03bci\u22121 (M ))\n\n(2.1)\n\nand \u03bcn (M ) > \u03bcn (M \u2032 ).\n\u2022 M = E[let !x =!M2 in M1 ] \u2192 M \u2032 = E[M1 [M2 /x]]\nLet the occurrence of the redex let !x =!M2 in M1 be at depth i. The\nrestrictions on the formation of terms require that x may only occur in M1\nat depth 1 and hence in M at depth i+1. We have that \u03c9i (M ) = \u03c9i (P )\u22122\nbecause the let ! node disappear. Clearly, \u03c9j (M ) = \u03c9j (M \u2032 ) if j < i. The\nnumber of occurrences of x in M1 is bounded by k = \u03c9i+1 (M ) \u2265 2. Thus\nif j > i then \u03c9j (M \u2032 ) \u2264 k * \u03c9j (M ). Let's write, for 0 \u2264 i \u2264 n:\n\u03bcin (M ) * k = (\u03c9n (M ) * k, \u03c9n\u22121 (M ) * k, . . . , \u03c9i (M ) * k)\nThen we have\n\u03bcn (M \u2032 ) \u2264 (\u03bci+1\nn (M ) * k, \u03c9i (M ) \u2212 2, \u03bci\u22121 (M ))\n\n(2.2)\n\nand finally \u03bcn (M ) > \u03bcn (M \u2032 ).\n\nWe now want to show that termination is actually in elementary time. We\nrecall that a function f on integers is elementary if there exists a k such that\nfor any n, f (n) can be computed in time O(t(n, k)) where:\nt(n, 0) = 2n ,\n\nt(n, k + 1) = 2t(n,k) .\n\nDefinition 2.7 (tower functions). We define a family of tower functions\nt\u03b1 (x1 , . . . , xn ) by induction on n where we assume \u03b1 \u2265 1 and xi \u2265 2:\nt\u03b1 () =\nt\u03b1 (x1 , x2 , . . . , xn ) =\n\n0\nt\u03b1 (x2 ,...,xn )\n(\u03b1 * x1 )2\n\nThen we need to prove the following crucial lemma.\n\n8\n\nn\u22651\n\n\fLemma 2.8 (shift). Assuming \u03b1 \u2265 1 and \u03b2 \u2265 2, the following property holds\nfor the tower functions with x, x ranging over numbers greater or equal to 2:\nt\u03b1 (\u03b2 * x, x\u2032 , x) \u2264 t\u03b1 (x, \u03b2 * x\u2032 , x)\nNow, by a closer look at the shape of the lexicographic ordering during\nreduction, we are able to compose the decreasing measure with a tower function.\nTheorem 2.9 (elementary bound). Let M be a well-formed term with \u03b1 =\nd(M ) and let t\u03b1 denote the tower function with \u03b1 + 1 arguments. If M \u2192 M \u2032\nthen t\u03b1 (\u03bc\u03b1 (M )) > t\u03b1 (\u03bc\u03b1 (M \u2032 )).\nProof. We illustrate the proof for \u03b1 = 2 and the crucial case where\nM = let !x = !M1 in M2 \u2192 M \u2032 = M1 [M2 /x]\nLet \u03bc2 (M ) = (x, y, z) such that x = \u03c92 (M ), y = \u03c91 (M ) and z = \u03c90 (M ). We\nwant to show that:\nt2 (\u03bc2 (M \u2032 )) < t2 (\u03bc2 (M ))\nWe have:\nt2 (\u03bc2 (M \u2032 ))\n\n\u2264 t2 (x * y, y * y, z \u2212 2) by inequality (2.2)\n\u2264 t2 (x, y 3 , z \u2212 2)\nby Lemma 2.8\n\nHence we are left to show that:\nt2 (y 3 , z \u2212 2) < t2 (y, z) i.e.\n\n2(z\u22122)\n\n(2y 3 )2\n\n2z\n\n< (2y)2\n\nWe have:\n2(z\u22122)\n\n(2y 3 )2\n\n2(z\u22122)\n\n\u2264 (2y)3*2\n\nThus we need to show:\n3 * 22(z\u22122) < 22z\nDividing by 22z we get:\n3 * 2\u22124 < 1\nwhich is obviously true. Hence t2 (\u03bc2 (M \u2032 )) < t2 (\u03bc2 (M )).\nThis shows that the number of reduction steps of a term M is bound by an\nelementary function where the height of the tower depends on d(M ). We also\n\u2217\nnote that if M \u2192 M \u2032 then t\u03b1 (\u03bc\u03b1 (M )) bounds the size of M \u2032 . Thus we can\nconclude with the following corollary.\nCorollary 2.10 (elementary time normalisation). The normalisation of terms\nof bounded depth can be performed in time elementary in the size of the terms.\n\n9\n\n\f3\n\nElementary Time in a Modal \u03bb-calculus with\nSide Effects\n\nIn this section, we extend our functional language with side effects operations.\nBy analysing the way side effects act on the depth of occurrences, we extend our\ndepth system to the obtained language. We can then lift the proof of termination\nin elementary time to programs with side effects that run with a call-by-value\nreduction strategy.\n\n3.1\n\nA Modal \u03bb-calculus with Multithreading and Regions\n\nWe introduce a call-by-value modal \u03bb-calculus endowed with parallel composition and operations to read and write regions. We call it \u03bb!R . A region\nis an abstraction of a set of dynamically generated values such as imperative\nreferences or communication channels. We regard \u03bb!R as an abstract, highly\nnon-deterministic language which entails complexity bounds for more concrete\nlanguages featuring references or channels (we will give an example of such a\nlanguage in Section 5). To this end, it is enough to map the dynamically generated values to their respective regions and observe that the reductions in the\nconcrete languages are simulated in \u03bb!R (see, e.g., [2]).\n3.1.1\n\nSyntax\n\nThe syntax of the language is described in Table 3.1. We describe the new\nx, y, . . .\nr, r\u2032 , . . .\nV ::= \u2217 | r | x | \u03bbx.M | !V\nM ::= V | M M | !M | let !x = M in M\nset(r, V ) | get(r) | (M | M )\nS ::= (r \u2190 V ) | (S | S)\nP ::= M | S | (P | P )\nE ::= [ ] | EM | V E | !E | let !x = E in M\nC ::= [ ] | (C | P ) | (P | C)\n\n(Variables)\n(Regions)\n(Values)\n(Terms)\n(Stores)\n(Programs)\n(Evaluation Contexts)\n(Static Contexts)\n\nTable 3.1: Syntax of programs: \u03bb!R\noperators. We have the usual set of variable x, y, . . . and a set of regions r, r\u2032 , . . ..\nThe set of values V contains the unit constant \u2217, variables, regions, \u03bb-abstraction\nand modal values !V which are marked with the bang operator '!'. The set of\nterms M contains values, application, modal terms !M , a let ! operator, set(r, V )\nto write the value V at region r, get(r) to fetch a value from region r and\n(M | N ) to evaluate M and N in parallel. A store S is the composition of\nseveral stores (r \u2190 V ) in parallel. A program P is a combination of terms and\n\n10\n\n\fstores. Evaluation contexts follow a call-by-value discipline. Static contexts\nC are composed of parallel compositions. Note that stores can only appear\nin a static context, thus M (M \u2032 | (r \u2190 V )) is not a legal term. We define\n!n (P | P ) = (!n P | !n P ), and !n (r \u2190 V ) = (r \u2190 V ). As usual, we abbreviate\n(\u03bbz.N )M with M ; N , where z is not free in N .\nEach program has an abstract syntax tree as exemplified in Figure 3.1(a).\n\u01eb\n\n|\nlet !x\n\nr\u2190\n\nget(r) set(r)\n\n!\n\n1\n\n0\n00\n\n01\n\n10\n\n!\n\n\u03bbx\n\n010\n\n100\n\nx\n\n@\n\n0100\n\n1000\n\nx\n\n\u2217\n\n10000\n\n(a)\n\n10001\n\n(b)\n\nFigure 3.1: Syntax tree and addresses of P = let !x = get(r) in set(r, !x) | (r \u2190\n!(\u03bbx.x\u2217))\n\n3.1.2\n\nOperational Semantics\n\nThe operational semantics of the language is described in Table 3.2. Programs\nP | P\u2032\n(P | P \u2032 ) | P \u2032\u2032\n\n\u2261\n\u2261\n\nP\u2032 | P\n(Commutativity)\nP | (P \u2032 | P \u2032\u2032 )\n(Associativity)\n\nE[(\u03bbx.M )V ]\nE[let !x = !V in M ]\nE[set(r, V )]\nE[get(r)]\n| (r \u2190 V )\nE[let !x = get(r) in M ] | (r \u2190 !V )\n\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\n\nE[M [V /x]]\nE[M [V /x]]\nE[\u2217]\nE[V ]\nE[M [V /x]]\n\n| (r \u2190 V )\n| (r \u2190 !V )\n\nTable 3.2: Semantics of \u03bb!R programs\nare considered up to a structural equivalence \u2261 which is the least equivalence\nrelation preserved by static contexts, and which contains the equations for \u03b1renaming and for the commutativity and associativity of parallel composition.\nThe reduction rules apply modulo structural equivalence and in a static context\nC.\nWhen writing to a region, values are accumulated rather than overwritten\n(remember that \u03bb!R is an abstract language that can simulate more concrete ones\nwhere values relating to the same region are associated with distinct addresses).\n11\n\n\fOn the other hand, reading a region amounts to select non-deterministically\none of the values associated with the region. We distinguish two rules to read\na region. The first consumes the value from the store, like when reading a\ncommunication channel. The second copies the value from the store, like when\nreading a reference. Note that in this case the value read must be duplicable\n(of the shape !V ).\nExample 3.1. Program P of Figure 3.1 reduces as follows:\nlet !x = get(r) in set(r, !x) | (r \u2190 !(\u03bbx.x\u2217))\n\u2192 set(r, !(\u03bbx.x\u2217)) | (r \u2190 !(\u03bbx.x\u2217))\n\u2192 \u2217 | (r \u2190 !(\u03bbx.x\u2217)) | (r \u2190 !(\u03bbx.x\u2217))\n\n3.2\n\nExtended Depth System\n\nWe start by analysing the interaction between the depth of the occurrences and\nside effects. We observe that side effects may increase the depth or generate\noccurrences at lower depth than the current redex, which violates Property (1)\nand (2) (see Section 2.2) respectively. Then to find a suitable notion of depth, it\nis instructive to consider the following program examples where Mr = let !z =\nget(r) in !(z\u2217).\n(A) E[set(r, !V )]\n(B) \u03bbx.set(r, x); !get(r)\n(C) !(Mr ) | (r \u2190 !(\u03bby.Mr\u2032 )) | (r\u2032 \u2190 !(\u03bby.\u2217))\n(D) !(Mr ) | (r \u2190 !(\u03bby.Mr ))\n(A) Suppose the occurrence set(r, !V ) is at depth \u03b4 > 0 in E. Then when\nevaluating such a term we always end up in a program of the shape E[\u2217] |\n(r \u2190 !V ) where the occurrence !V , previously at depth \u03b4, now appears at\ndepth 0. This contradicts Property (2).\n(B) If we apply this program to !V we obtain !!V , hence Property (1) is violated\nbecause from a program of depth 1, we reduce to a program of depth 2. We\nremark that this is because the read and write operations do not execute\nat the same depth.\n(C) According to our definition, this program has depth 2, however when we\nreduce it we obtain a term !3 \u2217 which has depth 3, hence Property (1) is\nviolated. This is because the occurrence \u03bby.Mr\u2032 originally at depth 1 in\nthe store, ends up at depth 2 in the place of z applied to \u2217.\n(D) If we accept circular stores, we can even write diverging programs whose\ndepth is increased by 1 every two reduction steps.\nGiven these remarks, the rest of this section is devoted to a revised notion\nof depth and to depth system extended with side effects. First, we introduce\nthe following contexts:\n\u0393 = x1 : \u03b41 , . . . , xn : \u03b4n\n\nR = r1 : \u03b41 , . . . , rn : \u03b4n\n12\n\n\fwhere \u03b4i is a natural number. We write dom(R) for the set {r1 , . . . , rn }. We\nwrite R(ri ) for the depth \u03b4i associated with ri in the context R.\nIn the sequel, we shall call the notion of depth introduced in Definition 2.1\nnaive depth. We revisit the notion of naive depth as follows.\nDefinition 3.2 (revised depth). Let P be a program, R a region context where\ndom(R) contains all the regions of P and dn (w) the naive depth of an occurrence\nw of P . If w does not appear under an occurrence r \u2190 (a store), then the revised\ndepth dr (w) of w is dn (w). Otherwise, dr (w) is R(r)+dn (w). The revised depth\ndr (P ) of the program is the maximum revised depth of its occurrences.\nNote that the revised depth is relative to a fixed region context. In the sequel\nwe write d( ) for dr ( ). On functional terms, this notion of depth is equivalent\nto the one given in Definition 2.1. However, if we consider the program of\nFigure 3.1, we now have d(10) = R(r) and d(100) = d(1000) = d(10000) =\nd(10001) = R(r) + 1.\nA judgement in the depth system has the shape\nR; \u0393 \u22a2\u03b4 P\nand it should be interpreted as follows:\nThe free variables of !\u03b4 P may only occur at the depth specified\nby the context \u0393, where depths are computed according to R.\nThe inference rules of the extended depth system are presented in Table 3.3.\nWe comment on the new rules. A region and the constant \u2217 may appear at\nR; \u0393, x : \u03b4 \u22a2\u03b4 x\n\nR; \u0393 \u22a2\u03b4 r\n\nR; \u0393, x : \u03b4 \u22a2\u03b4 M\n\nFO(x, M ) \u2264 1\n\nR; \u0393 \u22a2\u03b4 Mi\ni = 1, 2\nR; \u0393 \u22a2\u03b4 M1 M2\n\n\u03b4\n\nR; \u0393 \u22a2 \u03bbx.M\nR; \u0393 \u22a2\u03b4+1 M\nR; \u0393 \u22a2\u03b4 !M\n\nR; \u0393 \u22a2\u03b4 \u2217\n\nR; \u0393 \u22a2\u03b4 M1\n\nR; \u0393, x : (\u03b4 + 1) \u22a2\u03b4 M2\n\nR; \u0393 \u22a2\u03b4 let !x = M1 in M2\nR, r : \u03b4; \u0393 \u22a2\u03b4 V\nR, r : \u03b4; \u0393 \u22a2\u03b4 set(r, V )\n\nR, r : \u03b4; \u0393 \u22a2\u03b4 get(r)\nR, r : \u03b4; \u0393 \u22a2\u03b4 V\nR, r : \u03b4; \u0393 \u22a20 (r \u2190 V )\n\nR; \u0393 \u22a2\u03b4 Pi\ni = 1, 2\nR; \u0393 \u22a2\u03b4 (P1 | P2 )\n\nTable 3.3: Depth system for programs: \u03bb!R\n\u03b4\nany depth. The key cases are those of read and write: the depth of these two\noperations is specified by the region context. The current depth of a store is\n13\n\n\falways 0, however, the depth of the value in the store is specified by R (note\nthat it corresponds to the revised definition of depth). We remark that R is\nconstant in a judgement derivation.\nDefinition 3.3 (well-formedness). A program P is well-formed if for some R,\n\u0393, \u03b4 a judgement R; \u0393 \u22a2\u03b4 P can be derived.\nExample 3.4. The program of Figure 3.1 is well-formed with the following\nderivation where R(r) = 0:\n\nR; \u0393 \u22a20 get(r)\n\nR; \u0393, x : 1 \u22a21 x\nR; \u0393, x : 1 \u22a20 !x\nR; \u0393, x : 1 \u22a20 set(r, !x)\n\nR; \u0393 \u22a20 let !x = get(r) in set(r, !x)\n\n..\n.\nR; \u0393 \u22a20 (r \u2190 !(\u03bbx.x\u2217))\n\nR; \u0393 \u22a20 let !x = get(r) in set(r, !x) | (r \u2190 !(\u03bbx.x\u2217))\nWe reconsider the troublesome programs with side effects. Program (A) is\nwell-formed with judgement (i):\nR; \u0393 \u22a20 E[set(r, !V )]\nR; \u0393 \u22a20 !Mr | (r \u2190 !(\u03bby.Mr\u2032 )) | (r\u2032 \u2190 !(\u03bby.\u2217))\n\nwith R = r : \u03b4\nwith R = r : 1, r\u2032 : 2\n\n(i)\n(ii)\n\nIndeed, the occurrence !V is now preserved at depth \u03b4 in the store. Program (B)\nis not well-formed since the read operation requires R(r) = 1 and the write\noperations require R(r) = 0. Program (C) is well-formed with judgement (ii);\nindeed its depth does not increase anymore because !Mr has depth 2 but since\nR(r) = 1 and R(r\u2032 ) = 2, (r \u2190 !(\u03bby.Mr\u2032 )) has depth 3 and (r\u2032 \u2190 !(\u03bby.\u2217)) has\ndepth 2. Hence program (C) has already depth 3. Finally, it is worth noticing\nthat the diverging program (D) is not well-formed since get(r) appears at depth\n1 in !Mr and at depth 2 in the store.\nTheorem 3.5 (properties on the extended depth system). The following properties hold:\n1. If R; \u0393 \u22a2\u03b4 M and x occurs free in M then x : \u03b4 \u2032 belongs to \u0393 and all\noccurrences of x in !\u03b4 M are at depth \u03b4 \u2032 .\n2. If R; \u0393 \u22a2\u03b4 P then R; \u0393, \u0393\u2032 \u22a2\u03b4 P .\n\u2032\n\n3. If R; \u0393, x : \u03b4 \u2032 \u22a2\u03b4 M and R; \u0393 \u22a2\u03b4 V then R; \u0393 \u22a2\u03b4 M [V /x] and\n\u2032\nd(!\u03b4 M [V /x]) \u2264 max (d(!\u03b4 M ), d(!\u03b4 V )).\n4. If R; \u0393 \u22a20 P and P \u2192 P \u2032 then R; \u0393 \u22a20 P \u2032 and d(P ) \u2265 d(P \u2032 ).\n\n3.3\n\nElementary Bound\n\nIn this section, we prove that well-formed programs terminate in elementary\ntime. The measure of Definition 2.5 extends trivially to programs except that\n14\n\n\fto simplify the proofs of the following properties, we assume the occurrences labelled with | and r \u2190 do not count in the measure and that set(r) counts for two\noccurrences such that the measure strictly decreases on the rule E[set(r, V )] \u2192\nE[\u2217] | (r \u2190 V ).\nWe derive a similar termination property:\nProposition 3.6 (termination). If P is well-formed, P \u2192 P \u2032 and n \u2265 d(P )\nthen \u03bcn (P ) > \u03bcn (P \u2032 ).\nProof. By a case analysis on the new reduction rules.\n\u2022 P \u2261 E[set(r, V )] \u2192 P \u2032 \u2261 E[\u2217] | (r \u2190 V )\nIf R; \u0393 \u22a2\u03b4 set(r, V ) then by 3.5(4) we have R; \u0393 \u22a20 (r \u2190 V ) with R(r) = \u03b4.\nHence, by definition of the depth, the occurrences in V stay at depth \u03b4 in\n(r \u2190 V ). However, the node set(r, V ) disappears, and both \u2217 and (r \u2190 V )\nare null occurrences, thus \u03c9\u03b4 (P \u2032 ) = \u03c9\u03b4 (P ) \u2212 1. The number of occurrences\nat other depths stay unchanged, hence \u03bcn (P ) > \u03bcn (P \u2032 ).\n\u2022 P \u2261 E[get(r)] | (r \u2190 V ) \u2192 P \u2032 \u2261 E[V ]\nIf R; \u0393 \u22a20 (r \u2190 V ) with R(r) = \u03b4, then get(r) must be at depth \u03b4 in\nE[ ]. Hence, by definition of the depth, the occurrences in V stay at\ndepth \u03b4, while the node get(r) and | disappear. Thus \u03c9\u03b4 (P \u2032 ) = \u03c9\u03b4 (P ) \u2212 1\nand the number of occurrences at other depths stay unchanged, hence\n\u03bcn (P ) > \u03bcn (P \u2032 ).\n\u2022 P \u2261 E[let !x = get(r) in M ] | (r \u2190 !V ) \u2192 P \u2032 \u2261 E[M [V /x]] | (r \u2190 !V )\nThis case is the only source of duplication with the reduction rule on let !.\nSuppose R; \u0393 \u22a2\u03b4 let !x = get(r) in M . Then we must have R; \u0393 \u22a2\u03b4+1 V .\nThe restrictions on the formation of terms require that x may only occur\nin M at depth 1 and hence in P at depth \u03b4 +1. Hence the occurrences in V\nstay at the same depth in M [V /x], while the let, get(r) and some x nodes\ndisappear, hence \u03c9\u03b4 (P ) \u2264 \u03c9\u03b4 (P \u2032 ) \u2212 2. The number of occurrences of x in\nM is bound by k = \u03c9\u03b4+1 (P ) \u2265 2. Thus if j > \u03b4 then \u03c9j (P \u2032 ) \u2264 k * \u03c9j (P ).\nClearly, \u03c9j (M ) = \u03c9j (M \u2032 ) if j < i. Hence, we have\n\u03bcn (P \u2032 ) \u2264 (\u03bci+1\nn (P ) * k, \u03c9i (P ) \u2212 2, \u03bci\u22121 (P ))\n\n(3.1)\n\nand \u03bcn (P ) > \u03bcn (P \u2032 ).\n\nThen we have the following theorem.\nTheorem 3.7 (elementary bound). Let P be a well-formed program with \u03b1 =\nd(P ) and let t\u03b1 denote the tower function with \u03b1+1 arguments. Then if P \u2192 P \u2032\nthen t\u03b1 (\u03bc\u03b1 (P )) > t\u03b1 (\u03bc\u03b1 (P \u2032 )).\n\n15\n\n\fProof. From the proof of termination, we remark that the only new rule that\nduplicates occurrences is the one that copies from the store. Moreover, the\nderived inequality (3.1) is exactly the same as the inequality (2.2). Hence the\narithmetic of the proof is exactly the same as in the proof of elementary bound\nfor the functional case.\nCorollary 3.8. The normalisation of programs of bounded depth can be performed in time elementary in the size of the terms.\n\n4\n\nAn Elementary Affine Type System\n\nThe depth system entails termination in elementary time but does not guarantee\nthat programs 'do not go wrong'. In particular, the introduction and elimination\nof bangs during evaluation may generate programs that deadlock, e.g.,\nlet !y = (\u03bbx.x) in !(yy)\n\n(4.1)\n\nis well-formed but the evaluation is stuck. In this section we introduce an elementary affine type system (\u03bb!R\nEA ) that guarantees that programs cannot deadlock (except when trying to read an empty store).\nThe upper part of Table 4.1 introduces the syntax of types and contexts.\nTypes are denoted with \u03b1, \u03b1\u2032 , . . .. Note that we distinguish a special behaviour\nt, t\u2032 , . . .\n\u03b1 ::=\nA ::=\n\u0393 ::=\nR ::=\n\n(Type variables)\n(Types)\n(Value-types)\n(Variable contexts)\n(Region contexts)\n\nB|A\nt | 1 | A \u22b8 \u03b1 | !A | \u2200t.A | Regr A\nx1 : (\u03b41 , A1 ), . . . , xn : (\u03b4n , An )\nr1 : (\u03b41 , A1 ), . . . , rn : (\u03b4n , An )\n\nR\u2193t\n\nR\u21931\n\nR\u2193A\nR \u2193 !A\n\nr : (\u03b4, A) \u2208 R\nR \u2193 Regr A\n\n\u2200r : (\u03b4, A) \u2208 R\nR\u22a2\n\nR\u2193A\nR\u2193\u03b1\nR \u2193 (A \u22b8 \u03b1)\n\nR\u2193B\n\nR\u2193A\n\n\u2200x : (\u03b4, A) \u2208 \u0393\nR\u22a2\u0393\n\nR\u2193A\nt\u2208\n/R\nR \u2193 \u2200t.A\nR\u22a2\nR\u2193\u03b1\nR\u22a2\u03b1\nR\u22a2A\n\nTable 4.1: Types and contexts\ntype B which is given to the entities of the language which are not supposed\n16\n\n\fto return a value (such as a store or several terms in parallel) while types of\nentities that may return a value are denoted with A. Among the types A, we\ndistinguish type variables t, t\u2032 , . . ., a terminal type 1, an affine functional type\nA \u22b8 \u03b1, the type !A of terms of type A that can be duplicated, the type \u2200t.A\nof polymorphic terms and the type Regr A of the region r containing values of\ntype A. Hereby types may depend on regions.\nIn contexts, natural numbers \u03b4i play the same role as in the depth system.\nWriting x : (\u03b4, A) means that the variable x ranges on values of type A and\nmay occur at depth \u03b4. Writing r : (\u03b4, A) means that addresses related to region\nr contain values of type A and that read and writes on r may only happen at\ndepth \u03b4. The typing system will additionally guarantee that whenever we use a\ntype Regr A the region context contains an hypothesis r : (\u03b4, A).\nBecause types depend on regions, we have to be careful in stating in Table 4.1\nwhen a region-context and a type are compatible (R \u2193 \u03b1), when a region context\nis well-formed (R \u22a2), when a type is well-formed in a region context (R \u22a2 \u03b1)\nand when a context is well-formed in a region context (R \u22a2 \u0393). A more informal\nway to express the condition is to say that a judgement r1 : (\u03b41 , A1 ), . . . , rn :\n(\u03b4n , An ) \u22a2 \u03b1 is well formed provided that: (1) all the region names occurring in\nthe types A1 , . . . , An , \u03b1 belong to the set {r1 , . . . , rn }, (2) all types of the shape\nRegri B with i \u2208 {1, . . . , n} and occurring in the types A1 , . . . , An , \u03b1 are such\nthat B = Ai . We notice the following substitution property on types.\nProposition 4.1. If R \u22a2 \u2200t.A and R \u22a2 B then R \u22a2 A[B/t].\nExample 4.2. One may verify that r : (\u03b4, 1 \u22b8 1) \u22a2 Regr (1 \u22b8 1) can be\nderived while the following judgements cannot: r : (\u03b4, 1) \u22a2 Regr (1 \u22b8 1), r :\n(\u03b4, Regr 1) \u22a2 1.\nA typing judgement takes the form:\nR; \u0393 \u22a2\u03b4 P : \u03b1\nIt attributes a type \u03b1 to the program P at depth \u03b4, in the region context R\nand the context \u0393. Table 4.2 introduces an elementary affine type system with\nregions. One can see that the \u03b4's are treated as in the depth system. Note that\na region r may occur at any depth. In the let ! rule, M should be of type !A\nsince x of type A appears one level deeper. A program in parallel with a store\nshould have the type of the program since we might be interested in the value\nthe program reduces to; however, two programs in parallel cannot reduce to a\nsingle value, hence we give them a behaviour type. The polymorphic rules are\nstraightforward where t \u2208\n/ (R; \u0393) means t does not occur free in a type of R or\n\u0393.\nExample 4.3. The well-formed program (C) can be given the following typing\njudgement: R; \u22a20 !(Mr ) | (r \u2190 !(\u03bby.Mr\u2032 )) | (r\u2032 \u2190 !(\u03bby.\u2217)) : !!1 where:\nR = r : (1, !(1 \u22b8 1)), r\u2032 : (2, !(1 \u22b8 1)). Also, we remark that the deadlocking\nprogram (4.1) admits no typing derivation.\n\n17\n\n\fR\u22a2\u0393\nx : (\u03b4, A) \u2208 \u0393\n\nR\u22a2\u0393\nR; \u0393 \u22a2\u03b4 \u2217 : 1\n\nR; \u0393 \u22a2\u03b4 x : A\nFO(x, M ) \u2264 1\nR; \u0393, x : (\u03b4, A) \u22a2\u03b4 M : \u03b1\n\u03b4\n\nR; \u0393 \u22a2 \u03bbx.M : A \u22b8 \u03b1\nR; \u0393 \u22a2\u03b4+1 M : A\nR; \u0393 \u22a2\u03b4 !M : !A\nR; \u0393 \u22a2\u03b4 M : A\n\nR; \u0393 \u22a2\u03b4 r : Regr A\n\nR; \u0393 \u22a2\u03b4 M : A \u22b8 \u03b1\nR; \u0393 \u22a2\u03b4 N : A\n\u03b4\nR; \u0393 \u22a2 M N : \u03b1\n\nR; \u0393 \u22a2\u03b4 M : !A\n\nR; \u0393, x : (\u03b4 + 1, A) \u22a2\u03b4 N : B\n\nR; \u0393 \u22a2\u03b4 let !x = M in N : B\nR; \u0393 \u22a2\u03b4 M : \u2200t.A\nR\u22a2B\n\u03b4\nR; \u0393 \u22a2 M : A[B/t]\n\nt\u2208\n/ (R; \u0393)\n\nR; \u0393 \u22a2\u03b4 M : \u2200t.A\nr : (\u03b4, A) \u2208 R\nR\u22a2\u0393\nR; \u0393 \u22a2\u03b4 get(r) : A\n\nR\u22a2\u0393\nr : (\u03b4 \u2032 , A) \u2208 R\n\nr : (\u03b4, A) \u2208 R\nR; \u0393 \u22a2\u03b4 V : A\nR; \u0393 \u22a2\u03b4 set(r, V ) : 1\n\nR; \u0393 \u22a2\u03b4 P : \u03b1\nR; \u0393 \u22a2\u03b4 S : B\nR; \u0393 \u22a2\u03b4 (P | S) : \u03b1\n\nr : (\u03b4, A) \u2208 R\nR; \u0393 \u22a2\u03b4 V : A\nR; \u0393 \u22a20 (r \u2190 V ) : B\n\nPi not a store i = 1, 2\nR; \u0393 \u22a2\u03b4 Pi : \u03b1i\nR; \u0393 \u22a2\u03b4 (P1 | P2 ) : B\n\nTable 4.2: An elementary affine type system: \u03bb!R\nEA\nTheorem 4.4 (subject reduction and progress). The following properties hold.\n1. (Well-formedness) Well-typed programs are well-formed.\n2. (Weakening) If R; \u0393 \u22a2\u03b4 P : \u03b1 and R \u22a2 \u0393, \u0393\u2032 then R; \u0393, \u0393\u2032 \u22a2\u03b4 P : \u03b1.\n\u2032\n\n3. (Substitution) If R; \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 M : \u03b1 and R; \u0393\u2032 \u22a2\u03b4 V : A and\nR \u22a2 \u0393, \u0393\u2032 then R; \u0393, \u0393\u2032 \u22a2\u03b4 M [V /x] : \u03b1.\n4. (Subject Reduction) If R; \u0393 \u22a2\u03b4 P : \u03b1 and P \u2192 P \u2032 then R; \u0393 \u22a2\u03b4 P \u2032 : \u03b1.\n5. (Progress) Suppose P is a closed typable program which cannot reduce.\nThen P is structurally equivalent to a program\nM 1 | * * * | M m | S1 | * * * | Sn\n\nm, n \u2265 0\n\nwhere Mi is either a value or can be decomposed as a term E[get(r)] such\nthat no value is associated with the region r in the stores S1 , . . . , Sn .\n\n18\n\n\f5\n\nExpressivity\n\nIn this section, we consider two results that illustrate the expressivity of the\nelementary affine type system. First we show that all elementary functions can\nbe represented and second we develop an example of iterative program with side\neffects.\n\n5.1\n\nCompleteness\n\nThe representation result just relies on the functional core of the language \u03bb!EA .\nBuilding on the standard concept of Church numeral, Table 5.1 provides a representation for natural numbers and the multiplication function. We denote with\nN\n\n= \u2200t.!(t \u22b8 t) \u22b8 !(t \u22b8 t)\n\n(type of numerals)\n\nn\nn\n\n: N\n= \u03bbf.let !f = f in !(\u03bbx.f (* * * (f x) * * * ))\n\n(numerals)\n\n: N \u22b8 (N \u22b8 N)\n= \u03bbn.\u03bbm.\u03bbf.let !f = f in n(m!f )\n\n(multiplication)\n\nmult\nmult\n\nTable 5.1: Representation of natural numbers and the multiplication function\nN the set of natural numbers. The precise notion of representation is spelled out\nin the following definitions where by strong \u03b2-reduction we mean that reduction\nunder \u03bb's is allowed.\nDefinition 5.1 (number representation). Let \u2205 \u22a2\u03b4 M : N. We say M represents\n\u2217\nn \u2208 N, written M n, if, by using a strong \u03b2-reduction relation, M \u2192 n.\nDefinition 5.2 (function representation). Let \u2205 \u22a2\u03b4 F : (N1 \u22b8 . . . \u22b8 Nk ) \u22b8\n!p N where p \u2265 0 and f : Nk \u2192 N. We say F represents f , written F\nf , if\nfor all Mi and ni \u2208 N where 1 \u2264 i \u2264 k such that \u2205 \u22a2\u03b4 Mi : N and Mi\nni ,\nF M1 . . . Mk f (n1 , . . . , nk ).\nElementary functions are also characterized as the smallest class of functions\ncontaining zero, successor, projection, subtraction and which is closed by composition and bounded summation/product. These functions can be represented\nin the sense of Definition 5.2 by adapting the proofs from Danos and Joinet [10].\nTheorem 5.3 (completeness). Every elementary function is representable in\n\u03bb!EA .\n\n5.2\n\nIteration with Side Effects\n\nWe rely on a slightly modified language where reads, writes and stores relate to\nconcrete addresses rather than to abstract regions. In particular, we introduce\n19\n\n\fterms of the form \u03bdx M to generate a fresh address name x whose scope is M .\nOne can then write the following program:\n\u2217\n\n\u03bdx ((\u03bby.set(y, V ))x) \u2192 \u03bdx \u2217 | (x \u2190 V )\nwhere x and y relate to a region r, i.e. they are of type Regr A. Our type system\ncan be easily adapted by associating region types with the address names. Next\nwe show that it is possible to program the iteration of operations producing a\nside effect on an inductive data structure. Specifically, in the following we show\nhow to iterate, possibly in parallel, an update operation on a list of addresses of\nthe store. The examples have been tested on a running implementation of the\nlanguage.\nFollowing Church encodings, we define the representation of lists and the\nassociated iterator in Table 5.2. Here is the function multiplying the numeral\nList A =\n[u1 , . . . , un ] :\n[u1 , . . . , un ] =\nlist it\nlist it\n\n:\n=\n\n\u2200t.!(A \u22b8 t \u22b8 t) \u22b8 !(t \u22b8 t)\n\n(type of lists)\n\nList A\n\u03bbf.let !f = f in !(\u03bbx.f u1 (f u2 . . . (f un x))\n\n(list represent.)\n\n\u2200u.\u2200t.!(u \u22b8 t \u22b8 t) \u22b8 List u \u22b8 !t \u22b8 !t\n\u03bbf.\u03bbl.\u03bbz.let !z = z in let !y = lf in !(yz)\n\n(iterator)\n\nTable 5.2: Representation of lists\npointed by an address at region r:\nupdate\nupdate\n\n: !Regr N \u22b8 !1 \u22b8 !1\n= \u03bbx.let !x = x in \u03bbz.!((\u03bby.set(x, y))(mult 2 get(x))\n\nConsider the following list of addresses and stores:\n[!x, !y, !z] | (x \u2190 m) | (y \u2190 n) | (z \u2190 p)\nNote that the bang constructors are needed to match the type !Regr N of the\nargument of update. Then we define the iteration as:\nrun : !!1\n\nrun = list it !update [!x, !y, !z] !!\u2217\n\nNotice that it is well-typed with R = r : (2, N) since both the read and the\nwrite appear at depth 2. Finally, the program reduces by updating the store as\nexpected:\nrun | (x \u2190 m) | (y \u2190 n) | (z \u2190 p)\n\u2217\n\u2192 !!1 | (x \u2190 2m) | (y \u2190 2n) | (z \u2190 2p)\nBuilding on this example, suppose we want to write a program with three concurrent threads where each thread multiplies by 2 the memory cells pointed by\n20\n\n\fa list. Here is a function waiting to apply a functional f to a value x in three\nconcurrent threads:\ngen threads\ngen threads\n\n:\n=\n\n\u2200t.\u2200t\u2032 .!(t \u22b8 t\u2032 ) \u22b8 !t \u22b8 B\n\u03bbf.let !f = f in \u03bbx.let !x = x in !(f x) | !(f x) | !(f x)\n\nWe define the functional F as run but parametric in the list:\nF : List !Regr N \u22b8 !!1\n\nF = \u03bbl.list it !update l !!\u2217\n\nAnd the final term is simply:\nrun threads : B\n\nrun threads = gen threads !F ![!x, !y, !z]\n\nwhere R = r : (3, !N). Our program then reduces as follows:\nrun threads\n\u2217\n\u2192 !!!1 | !!!1 | !!!1\n\n| (x \u2190 m)\n| (x \u2190 8m)\n\n| (y \u2190 n)\n| (y \u2190 8n)\n\n| (z \u2190 p)\n| (z \u2190 8p)\n\nNote that different thread interleavings are possible but in this particular case\nthe reduction is confluent.\n\n6\n\nConclusion\n\nWe have introduced a type system for a higher-order functional language with\nmultithreading and side effects that guarantees termination in elementary time\nthus providing a significant extension of previous work that had focused on\npurely functional programs. In the proposed approach, the depth system plays\na key role and allows for a relatively simple presentation. In particular we notice\nthat we can dispense both with the notion of stratified region that arises in recent\nwork on the termination of higher-order programs with side effects [1, 7] and\nwith the distinction between affine and intuitionistic hypotheses [6, 2].\nAs a future work, we would like to adapt our approach to polynomial time.\nIn another direction, one could ask if it is possible to program in a simplified\nlanguage without bangs and then try to infer types or depths.\nAcknowledgements We would like to thank Patrick Baillot for numerous\nhelpful discussions and a careful reading on a draft version of this report.\n\nReferences\n[1] R. M. Amadio. On stratified regions. In APLAS'09, volume 5904 of LNCS,\npages 210\u2013225. Springer, 2009.\n[2] R. M. Amadio, P. Baillot, and A. Madet. An affine-intuitionistic system of\ntypes and effects: confluence and termination. Technical report, Laboratoire PPS, 2009. http://hal.archives-ouvertes.fr/hal-00438101/.\n21\n\n\f[3] A. Asperti and L. Roversi. Intuitionistic light affine logic. ACM Trans.\nComput. Log., 3(1):137\u2013175, 2002.\n[4] P. Baillot, M. Gaboardi, and V. Mogbil. A polytime functional language\nfrom light linear logic. In ESOP'10, volume 6012 of LNCS, pages 104\u2013124.\nSpringer, 2010.\n[5] P. Baillot and K. Terui. A feasible algorithm for typing in elementary affine\nlogic. In TLCA'05, volume 3461 of LNCS, pages 55\u201370. Springer, 2005.\n[6] A. Barber. Dual intuitionistic linear logic. Technical Report ECS-LFCS96-347, The Laboratory for Foundations of Computer Science, University\nof Edinburgh, 1996.\n[7] G. Boudol. Typing termination in a higher-order concurrent imperative\nlanguage. Inf. Comput., 208(6):716\u2013736, 2010.\n[8] P. Coppola, U. Dal Lago, and S. Ronchi Della Rocca. Light logics and the\ncall-by-value lambda calculus. Logical Methods in Computer Science, 4(4),\n2008.\n[9] P. Coppola and S. Martini. Optimizing optimal reduction: A type inference\nalgorithm for elementary affine logic. ACM Trans. Comput. Log., 7:219\u2013\n260, 2006.\n[10] V. Danos and J.-B. Joinet. Linear logic and elementary time. Inf. Comput.,\n183(1):123 \u2013 137, 2003.\n[11] J.-Y. Girard. Light linear logic. Inf. Comput., 143(2):175\u2013204, 1998.\n[12] U. D. Lago, S. Martini, and D. Sangiorgi. Light logics and higher-order\nprocesses. In EXPRESS'10, volume 41 of EPTCS, pages 46\u201360, 2010.\n[13] K. Terui. Light affine lambda calculus and polynomial time strong normalization. Archive for Mathematical Logic, 46(3-4):253\u2013280, 2007.\n\n22\n\n\fA\nA.1\n\nProofs\nProof of theorem 3.5\n\n1. We consider the last rule applied in the typing of M .\n\u2022 \u0393, x : \u03b4 \u22a2\u03b4 x. The only free variable is x and indeed it is at depth \u03b4\nin !\u03b4 x.\n\u2022 \u0393 \u22a2\u03b4 \u03bby.M is derived from \u0393, y : \u03b4 \u22a2\u03b4 M . If x is free in \u03bby.M then\nx 6= y and x is free in M . By inductive hypothesis, x : \u03b4 \u2032 \u2208 \u0393, y : \u03b4\nand all occurrences of x in !\u03b4 M are at depth \u03b4 \u2032 . By definition of\ndepth, the same is true for !\u03b4 (\u03bby.M ).\n\u2022 \u0393 \u22a2\u03b4 (M1 M2 ) is derived from \u0393 \u22a2\u03b4 Mi for i = 1, 2. By inductive\nhypothesis, x : \u03b4 \u2032 \u2208 \u0393 and all occurrences of x in !\u03b4 Mi , i = 1, 2 are at\ndepth \u03b4 \u2032 . By definition of depth, the same is true for !\u03b4 (M1 M2 ).\n\u2022 \u0393 \u22a2\u03b4 !M is derived from \u0393 \u22a2\u03b4+1 M . By inductive hypothesis, x : \u03b4 \u2032 \u2208\n\u0393 and all occurrences of x in !\u03b4+1 M are at depth \u03b4 \u2032 and notice that\n!\u03b4+1 M = !\u03b4 (!M ).\n\u2022 \u0393 \u22a2\u03b4 let !y = M1 in M2 is derived from \u0393 \u22a2\u03b4 M1 and \u0393, y : (\u03b4 +\n1) \u22a2\u03b4 M2 . Without loss of generality, assume x 6= y. By inductive\nhypothesis, x : \u03b4 \u2032 \u2208 \u0393 and all occurrences of x in !\u03b4 Mi , i = 1, 2 are\nat depth \u03b4 \u2032 . By definition of depth, the same is true for !\u03b4 (let !y =\nM1 in M2 ).\n\u2022 M \u2261 \u2217 or M \u2261 r or M \u2261 get(r). There is no free variable in these\nterms.\n\u2022 M \u2261 let !y = get(r) in N . We have\nR, r : \u03b4; \u0393, y : (\u03b4 + 1) \u22a2\u03b4 N\nR, r : \u03b4; \u0393 \u22a2\u03b4 let !y = get(r) in N\nIf x occurs free in M then x occurs free in N . By induction hypothesis, x : \u03b4 \u2032 \u2208 \u0393 and all occurrences of x in !\u03b4 N are at depth \u03b4 \u2032 . By\ndefinition of the depth, this is also true for !\u03b4 (let !y = get(r) in N ).\n\u2022 M \u2261 set(r, V ). We have\nR, r : \u03b4; \u0393 \u22a2\u03b4 V\nR, r : \u03b4; \u0393 \u22a2\u03b4 set(r, V )\nIf x occurs free in set(r, V ) then x occurs free in V . By induction\nhypothesis, x : \u03b4 \u2032 \u2208 \u0393 and all occurrences of x in !\u03b4 V are at depth \u03b4 \u2032 .\nBy definition of the depth, this is also true for !\u03b4 (set(r, V )).\n\u2022 M \u2261 (M1 | M2 ). We have\nR; \u0393 \u22a2\u03b4 Mi\ni = 1, 2\nR; \u0393 \u22a2\u03b4 (M1 | M2 )\n23\n\n\fIf x occurs free in M then x occurs free in Mi , i = 1, 2. By induction\nhypothesis, x : \u03b4 \u2032 \u2208 \u0393 and all occurrences of x in !\u03b4 Mi , i = 1, 2, are\nat depth \u03b4 \u2032 . By definition of depth, the same is true of !\u03b4 (M1 | M2 ).\n2. All the rules can be weakened by adding a context \u0393\u2032 .\n3. If x is not free in M , we just have to check that any proof of \u0393, x : \u03b4 \u2032 \u22a2\u03b4 M\ncan be transformed into a proof of \u0393 \u22a2\u03b4 M .\nSo let us assume x is free in M .\nWe consider first the bound on the depth. By (1), we know that all\noccurrences of x in !\u03b4 M are at depth \u03b4 \u2032 . By definition of depth, it follows\nthat \u03b4 \u2032 \u2265 \u03b4 and the occurrences of x in M are at depth (\u03b4 \u2032 \u2212 \u03b4). An\n\u2032\noccurrence in !\u03b4 V at depth \u03b4 \u2032 +\u03b4 \u2032\u2032 will generate an occurrence in !\u03b4 M [V /x]\nat the same depth \u03b4 + (\u03b4 \u2032 \u2212 \u03b4) + \u03b4 \u2032\u2032 .\nNext, we proceed by induction on the derivation of \u0393, x : \u03b4 \u2032 \u22a2\u03b4 M .\n\u2032\n\n\u2022 \u0393, x : \u03b4 \u22a2\u03b4 x. Then \u03b4 = \u03b4 \u2032 , x[V /x] = V , and by hypothesis \u0393 \u22a2\u03b4 V .\n\u2022 \u0393, x : \u03b4 \u2032 \u22a2\u03b4 \u03bby.M is derived from \u0393, x : \u03b4 \u2032 , y : \u03b4 \u22a2\u03b4 M , with x 6= y and\n\u2032\ny not occurring in N . By (2), \u0393, y : \u03b4 \u22a2\u03b4 V . By inductive hypothesis,\n\u03b4\n\u0393, y : \u03b4 \u22a2 M [V /x], and then we conclude \u0393 \u22a2\u03b4 (\u03bby.M )[V /x].\n\u2022 \u0393, x : \u03b4 \u2032 \u22a2\u03b4 (M1 M2 ) is derived from \u0393, x : \u03b4 \u2032 \u22a2\u03b4 Mi , for i = 1, 2. By\ninductive hypothesis, \u0393 \u22a2\u03b4 Mi [V /x], for i = 1, 2 and then we conclude\n\u0393 \u22a2\u03b4 (M1 M2 )[V /x].\n\u2022 \u0393, x : \u03b4 \u2032 \u22a2\u03b4 !M is derived from \u0393, x : \u03b4 \u2032 \u22a2\u03b4+1 M . By inductive\nhypothesis, \u0393 \u22a2\u03b4+1 M [V /x], and then we conclude \u0393 \u22a2\u03b4 !M [V /x].\n\u2022 \u0393, x : \u03b4 \u2032 \u22a2\u03b4 let !y = M1 in M2 , with x 6= y and y not free in V is\nderived from \u0393, x : \u03b4 \u2032 \u22a2\u03b4 M1 and \u0393, x : \u03b4 \u2032 , y : (\u03b4 + 1) \u22a2\u03b4 M2 . By\ninductive hypothesis, \u0393 \u22a2\u03b4 M1 [V /x] \u0393, y : (\u03b4 + 1) \u22a2\u03b4 M2 [V /x], and\nthen we conclude \u0393 \u22a2\u03b4 (let !y = M1 in M2 )[V /x].\n\u2022 M \u2261 let !y = get(r) in M1 . We have\nR, r : \u03b4; \u0393, x : \u03b4 \u2032 , y : (\u03b4 + 1) \u22a2\u03b4 M1\nR, r : \u03b4; \u0393, x : \u03b4 \u2032 \u22a2\u03b4 let !y = get(r) in M1\nBy induction hypothesis we get\nR, r : \u03b4; \u0393, y : (\u03b4 + 1) \u22a2\u03b4 M1 [V /x]\nand hence we derive\nR, r : \u03b4; \u0393 \u22a2\u03b4 (let !y = get(r) in M1 )[V /x]\n\u2022 M \u2261 set(r, V \u2032 ). We have\nR, r : \u03b4; \u0393, x : \u03b4 \u2032 \u22a2\u03b4 V \u2032\nR, r : \u03b4; \u0393, x : \u03b4 \u2032 \u22a2\u03b4 set(r, V \u2032 )\n24\n\n\fBy induction hypothesis we get\nR, r : \u03b4; \u0393 \u22a2\u03b4 V \u2032 [V /x]\nand hence we derive\nR, r : \u03b4; \u0393 \u22a2\u03b4 (set(r, V \u2032 ))[V /x]\n\u2022 M \u2261 (M1 | M2 ). We have\nR; \u0393, x : \u03b4 \u2032 \u22a2\u03b4 Mi\ni = 1, 2\n\u2032 \u03b4\nR; \u0393, x : \u03b4 \u22a2 (M1 | M2 )\nBy induction hypothesis we derive\nR; \u0393 \u22a2\u03b4 Mi [V /x]\nand hence we derive\nR; \u0393 \u22a2\u03b4 (M1 | M2 )[V /x]\n4. We proceed by case analysis on the reduction rules.\n\u2022 Suppose \u0393 \u22a20 E[(\u03bbx.M )V ]. Then for some \u0393\u2032 extending \u0393 and \u03b4 \u2265 0\nwe must have \u0393\u2032 \u22a2\u03b4 (\u03bbx.M )V . This must be derived from \u0393\u2032 , x : \u03b4 \u22a2\u03b4\nM and \u0393\u2032 \u22a2\u03b4 V . By (3), with \u03b4 = \u03b4 \u2032 , it follows that \u0393\u2032 \u22a2\u03b4 M [V /x]\nand that the depth of an occurrence in E[M [V /x]] is bounded by the\ndepth of an occurrence which is already in E[(\u03bbx.M )V ]. Moreover,\nwe can derive \u0393 \u22a20 E[M [V /x]].\n\u2022 Suppose \u0393 \u22a20 E[let !x = !V in M ]. Then for some \u0393\u2032 extending \u0393 and\n\u03b4 \u2265 0 we must have \u0393\u2032 \u22a2\u03b4 let !x = !V in M . This must be derived\nfrom \u0393\u2032 , x : (\u03b4 + 1) \u22a2\u03b4 M and \u0393\u2032 \u22a2(\u03b4+1) V . By (3), with (\u03b4 + 1) = \u03b4 \u2032 ,\nit follows that \u0393\u2032 \u22a2\u03b4 M [V /x] and that the depth of an occurrence in\nE[M [V /x]] is bounded by the depth of an occurrence which is already\nin E[let !x = !V in M ]. Moreover, we can derive \u0393 \u22a20 E[M [V /x]].\n\u2022 E[set(r, V )] \u2192 E[\u2217] | (r \u2190 V )\nWe have R; \u0393 \u22a20 E[set(r, V )] from which we derive\nR; \u0393 \u22a2\u03b4 V\nR; \u0393 \u22a2\u03b4 set(r, V )\nfor some \u03b4 \u2265 0, with r : \u03b4 \u2208 R. Hence we can derive\nR; \u0393 \u22a2\u03b4 V\nR; \u0393 \u22a20 (r \u2190 V )\nMoreover, we have as an axiom R; \u0393 \u22a2\u03b4 \u2217 thus we can derive R; \u0393 \u22a20\nE[\u2217]. Applying the parallel rule we finally get\nR; \u0393 \u22a20 E[\u2217] | (r \u2190 V )\nConcerning the depth bound, clearly we have d(E[\u2217] | (r \u2190 V )) =\nd(E[set(r, V )]).\n25\n\n\f\u2022 E[get(r)] | (r \u2190 V ) \u2192 E[M [V /x]]\nWe have R; \u0393 \u22a20 E[get(r)] | (r \u2190 V ) from which we derive\nR; \u0393 \u22a2\u03b4 get(r)\nand\nR; \u0393, x : \u03b4 \u22a2\u03b4 M\nfor some \u03b4 \u2265 0, with r : \u03b4 \u2208 R, and\nR; \u0393 \u22a2\u03b4 V\nR; \u0393 \u22a20 (r \u2190 V )\nHence we can derive\nR; \u0393 \u22a20 E[V ]\nConcerning the depth bound, clearly we have d(E[V ]) = d(E[get(r)] |\n(r \u2190 V )).\n\u2022 E[let !x = get(r) in M ] | (r \u2190 !V ) \u2192 E[M [V /x]] | (r \u2190 !V )\nWe have R; \u0393 \u22a20 E[let !x = get(r) in M ] | r!V from which we derive\nR; \u0393\u2032 , x : (\u03b4 + 1) \u22a2\u03b4 M\nR; \u0393\u2032 \u22a2\u03b4 let !x = get(r) in M\nfor some \u03b4 \u2265 0 with r : \u03b4 \u2208 R, and some \u0393\u2032 extending \u0393. We also\nderive\nR; \u0393 \u22a2\u03b4+1 V\nR; \u0393 \u22a2\u03b4 !V\nR; \u0393 \u22a20 (r \u2190 !V )\nBy (2) we get R; \u0393\u2032 \u22a2\u03b4+1 V . By (3) we derive\nR; \u0393\u2032 \u22a2\u03b4 M [V /x]\nhence\nR; \u0393 \u22a20 E[M [V /x]]\nand finally\nR; \u0393 \u22a20 E[M [V /x]] | (r \u2190 !V )\nConcerning the depth bound, by (3), the depth of an occurrence\nin E[M [V /x]] | (r \u2190 !V ) is bounded by the depth of an occurrence which is already in E[let !x = get(r) in M ] | (r \u2190 !V ), hence\nd(E[M [V /x]] | (r \u2190 !V )) \u2264 d(E[let !x = get(r) in M ] | (r \u2190 !V )).\n\n26\n\n\fA.2\n\nProof of proposition 3.6\n\nWe do this by case analysis on the reduction rules.\n\u2022 P = E[(\u03bbx.M )V ] \u2192 P \u2032 = E[M [V /x]]\nLet the occurrence of the redex (\u03bbx.M )V be at depth i. The restrictions\non the formation of terms require that x occurs at most once in M at\ndepth 0. Then \u03c9i (P ) \u2212 3 \u2265 \u03c9i (P \u2032 ) because we remove the nodes for\napplication and \u03bb-abstraction and either V disappears or the occurrence\nof the variable x in M disappears (both being at the same depth as the\nredex). Clearly \u03c9j (P ) = \u03c9j (P \u2032 ) if j 6= i, hence\n\u03bcn (P \u2032 ) \u2264 (\u03c9n (P ), . . . , \u03c9i+1 (P ), \u03c9i (P ) \u2212 3, \u03bci\u22121 (P ))\n\n(A.1)\n\nand \u03bcn (P ) > \u03bcn (P \u2032 ).\n\u2022 P = E[let !x =!V in M ] \u2192 P \u2032 = E[M [V /x]]\nLet the occurrence of the redex let !x =!V in M be at depth i. The\nrestrictions on the formation of terms require that x may only occur in M\nat depth 1 and hence in P at depth i + 1. We have that \u03c9i (P \u2032 ) = \u03c9i (P )\u2212 2\nbecause the let ! node disappear. Clearly, \u03c9j (P ) = \u03c9j (P \u2032 ) if j < i. The\nnumber of occurrences of x in M is bounded by k = \u03c9i+1 (P ) \u2265 2. Thus\nif j > i then \u03c9j (P \u2032 ) \u2264 k * \u03c9j (P ). Let's write, for 0 \u2264 i \u2264 n:\n\u03bcin (P ) * k = (\u03c9n (P ) * k, \u03c9n\u22121 (P ) * k, . . . , \u03c9i (P ) * k)\nThen we have\n\u03bcn (P \u2032 ) \u2264 (\u03bci+1\nn (P ) * k, \u03c9i (P ) \u2212 2, \u03bci\u22121 (P ))\n\n(A.2)\n\nand finally \u03bcn (P ) > \u03bcn (P \u2032 ).\n\u2022 P \u2261 E[set(r, V )] \u2192 P \u2032 \u2261 E[\u2217] | (r \u2190 V )\nIf R; \u0393 \u22a2\u03b4 set(r, V ) then by 3.5(4) we have R; \u0393 \u22a20 (r \u2190 V ) with R(r) = \u03b4.\nHence, by definition of the depth, the occurrences in V stay at depth \u03b4\nin (r \u2190 V ). Moreover, the node set(r, V ) disappears and the nodes \u2217, |,\nand r \u2190 appear. Recall that we assume the occurrences | and r \u2190 do not\ncount in the measure and that set(r) counts for two occurrences. Thus\n\u03c9\u03b4 (P \u2032 ) = \u03c9\u03b4 (P )\u2212 2 + 1 + 0 + 0. The number of occurrences at other depths\nstay unchanged, hence \u03bcn (P ) > \u03bcn (P \u2032 ).\n\u2022 P \u2261 E[get(r)] | (r \u2190 V ) \u2192 P \u2032 \u2261 E[V ]\nIf R; \u0393 \u22a20 (r \u2190 V ) with R(r) = \u03b4, then get(r) must be at depth \u03b4 in\nE[ ]. Hence, by definition of the depth, the occurrences in V stay at\ndepth \u03b4, while the node get(r) and | disappear. Thus \u03c9\u03b4 (P \u2032 ) = \u03c9\u03b4 (P ) \u2212 1\nand the number of occurrences at other depths stay unchanged, hence\n\u03bcn (P ) > \u03bcn (P \u2032 ).\n\n27\n\n\f\u2022 P \u2261 E[let !x = get(r) in M ] | (r \u2190 !V ) \u2192 P \u2032 \u2261 E[M [V /x]] | (r \u2190 !V )\nThis case is the only source of duplication with the reduction rule on let !.\nSuppose R; \u0393 \u22a2\u03b4 let !x = get(r) in M . Then we must have R; \u0393 \u22a2\u03b4+1 V .\nThe restrictions on the formation of terms require that x may only occur\nin M at depth 1 and hence in P at depth \u03b4 +1. Hence the occurrences in V\nstay at the same depth in M [V /x], while the let, get(r) and some x nodes\ndisappear, hence \u03c9\u03b4 (P ) \u2264 \u03c9\u03b4 (P \u2032 ) \u2212 2. The number of occurrences of x in\nM is bounded by k = \u03c9\u03b4+1 (P ) \u2265 2. Thus if j > \u03b4 then \u03c9j (P \u2032 ) \u2264 k * \u03c9j (P ).\nClearly, \u03c9j (M ) = \u03c9j (M \u2032 ) if j < i. Hence, we have\n\u03bcn (P \u2032 ) \u2264 (\u03bci+1\nn (P ) * k, \u03c9i (P ) \u2212 2, \u03bci\u22121 (P ))\n\n(A.3)\n\nand \u03bcn (P ) > \u03bcn (P \u2032 ).\n\nA.3\n\nProof of lemma 2.8\n\nWe start by remarking some basic inequalities.\nLemma A.1 (some inequalities). The following properties hold on natural numbers.\n1. \u2200 x \u2265 2, y \u2265 0 (y + 1) \u2264 xy\n2. \u2200 x \u2265 2, y \u2265 0 (x * y) \u2264 xy\n3. \u2200 x \u2265 2, y, z \u2265 0 (x * y)z \u2264 x(y*z)\n4. \u2200 x \u2265 2, y \u2265 0, z \u2265 1 xz * y \u2264 x(y*z)\n5. If x \u2265 y \u2265 0 then (x \u2212 y)k \u2264 (xk \u2212 y k )\nProof.\n1. By induction on y. The case for y = 0 is clear. For the inductive\ncase, we notice:\n(y + 1) + 1 \u2264 2y + 2y = 2y+1 \u2264 xy+1 .\n2. By induction on y. The case y = 0 is clear. For the inductive case, we\nnotice:\nx * (y + 1) \u2264 x * (xy ) (by (1))\n= x(y+1)\n3. By induction on z. The case z = 0 is clear. For the inductive case, we\nnotice:\n(x * y)z+1\n\n=\n\u2264\n\u2264\n=\n\n(x * y)z (x * y)\nxy*z (x * y)\n(by inductive hypothesis)\nxy*z (xy )\n(by (2))\nxy*(z+1)\n\n28\n\n\f4. From z \u2265 1 we derive y \u2264 y z . Then:\nxz * y\n\n\u2264 xz * y z\n= (x * y)z\n\u2264 xy*z\n\n(by (3))\n\n5. By the binomial law, we have xk = ((x \u2212 y) + y)k = (x \u2212 y)k + y k + p with\np \u2265 0. Thus (x \u2212 y)k = xk \u2212 y k \u2212 p which implies (x \u2212 y)k \u2264 xk \u2212 y k .\nWe also need the following property.\nLemma A.2 (pre-shift). Assuming \u03b1 \u2265 1 and \u03b2 \u2265 2, the following property\nholds for the tower functions with x, x ranging over numbers greater or equal\nthan 2:\n\u03b2 * t\u03b1 (x, x) \u2264 t\u03b1 (\u03b2 * x, x)\nProof. This follows from:\nt\u03b1 (x)\n\n\u03b2 \u2264 \u03b22\n\nThen we can derive the proof of the shift lemma as follows.\nLet k = t\u03b1 (x\u2032 , x) \u2265 2. Then\nk\n\nt\u03b1 (\u03b2 * x, x\u2032 , x) = \u03b2 * (\u03b1 * x)2\n\nk\n\n\u2264 (\u03b1 * x)\u03b2*2\nk\n\u2264 (\u03b1 * x)(\u03b2*2)\n(\u03b2*k)\n\u2264 (\u03b1 * x)2\n\n(by lemma A.1(3))\n(by lemma A.1(3))\n\nand by lemma A.2 \u03b2 * t\u03b1 (x\u2032 , x) \u2264 t\u03b1 (\u03b2 * x\u2032 , x).\nHence\n(\u03b2*k)\nt\u03b1 (\u03b2*x\u2032 ,x)\n(\u03b1 * x)2\n\u2264 (\u03b1 * x)2\n= t\u03b1 (x, \u03b2 * x\u2032 , x)\n\nA.4\n\nProof of theorem 3.7\n\nSuppose \u03bc\u03b1 (P ) = (x0 , . . . , x\u03b1 ) so that xi corresponds to the occurrences at\ndepth (\u03b1 \u2212 i) for 0 \u2264 i \u2264 \u03b1. Also assume the reduction is at depth (\u03b1 \u2212 i).\nBy looking at equations (A.1) and (A.2) in the proof of termination (Proposition 3.6), we see that the components i + 1, . . . , \u03b1 of \u03bc\u03b1 (P ) and \u03bc\u03b1 (P \u2032 ) coincide.\nHence, let k = 2t\u03b1 (xi+1 ,...,x\u03b1 ) . By definition of the tower function, k \u2265 1.\nWe proceed by case analysis on the reduction rules.\n\u2022 P \u2261 let !x = !V in M \u2192 P \u2032 \u2261 M [V /x]\nBy inequality (A.2) we know that:\nt\u03b1 (\u03bc\u03b1 (P \u2032 ))\n\n\u2264 t\u03b1 (x0 * xi\u22121 , . . . , xi\u22121 * xi\u22121 , xi \u2212 2, xi+1 , . . . , x\u03b1 )\n= t\u03b1 (x0 * xi\u22121 , . . . , xi\u22121 * xi\u22121 , xi \u2212 2)k\n\n29\n\n\fBy iterating lemma 2.8, we derive:\n\u2264\n\u2264\n\u2264\n\nt\u03b1 (x0 * xi\u22121 , x1 * xi\u22121 , . . . , xi\u22121 * xi\u22121 , xi \u2212 2)\nt\u03b1 (x0 , x1 * x2i\u22121 , . . . , xi\u22121 * xi\u22121 , xi \u2212 2)\n...\nt\u03b1 (x0 , x1 , . . . , xii\u22121 , xi \u2212 2)\n\nRenaming xi\u22121 with x and xi with y, we are left to show that:\n(\u03b1*(y\u22122))k\n\n(\u03b1xi )2\n\n(\u03b1*y)k\n\n< (\u03b1x)2\n\nSince i \u2264 \u03b1 the first quantity is bounded by:\n(\u03b1*(y\u22122))k\n\n(\u03b1x)\u03b1*2\nWe notice:\nk\n\n\u03b1 * 2(\u03b1*(y\u22122))\nk\n\u03b1 * 2(\u03b1*y\u2212\u03b1*2)\nk\nk\n\u03b1 * 2(\u03b1*y) \u2212(\u03b1*2)\n\n=\n\u2264\n\n(by lemma A.1(5))\n\nSo we are left to show that:\n\u03b12(\u03b1*y)\n\nk\n\n\u2212(\u03b1*2)k )\n\n\u2264 2(\u03b1*y)\n\nk\n\nk\n\nDividing by 2(\u03b1*y) and recalling that k \u2265 1, it remains to check:\nk\n\n\u03b1 * 2\u2212(\u03b1*2) \u2264 \u03b1 * 2\u2212(\u03b1*2) < 1\nwhich is obviously true for \u03b1 \u2265 1.\n\u2022 P \u2261 (\u03bbx.M )V \u2192 P \u2032 \u2261 M [V /x]\nBy equation (A.1), we have that:\nt\u03b1 (\u03bc\u03b1 (P \u2032 )) \u2264 t\u03b1 (x0 , . . . , xi\u22121 , xi \u2212 2, xi+1 , . . . , x\u03b1 )\nand one can check that this quantity is strictly less than:\nt\u03b1 (\u03bc\u03b1 (P )) = t\u03b1 (x0 , . . . , xi\u22121 , xi , xi+1 , . . . , x\u03b1 )\n\u2022 P \u2261 let !x = get(r) in M | (r \u2190 !V ) \u2192 P \u2032 \u2261 M [V /x] | (r \u2190 !V )\nLet k = 2t\u03b1 (xi+1 ,...,x\u03b1 ) . By definition of the tower function, k \u2265 1. By\nequation (A.3) we have\nt\u03b1 (\u03bc\u03b1 (P \u2032 ))\n\n\u2264 t\u03b1 (x0 * xi\u22121 , . . . , xi\u22121 * xi\u22121 , xi \u2212 2, xi+1 , . . . , x\u03b1 )\n= t\u03b1 (x0 * xi\u22121 , . . . , xi\u22121 * xi\u22121 , xi \u2212 2)k\n\nAnd we end up in the case of the rule for let !.\n30\n\n\f\u2022 For the read that consume a value from the store, by looking at the proof of\ntermination, we see that exactly one element of the vector \u03bc\u03b1 (P ) is strictly\ndecreasing during the reduction, hence one can check that t\u03b1 (\u03bc\u03b1 (P )) >\nt\u03b1 (\u03bc\u03b1 (P \u2032 )).\n\u2022 The case for the write is similar to the read.\nWe conclude with the following remark that shows that the size of a program\nis proportional to its number of occurrences.\nRemark A.3. The size of P\na program |P | of depth d is at most twice the sum of\nits occurrences: |P | \u2264 2 * 0\u2264i\u2264d \u03c9i (P ).\nHence the size of a program P is bounded by td (\u03bcd (P )).\n\nA.5\n\nProof of proposition 4.1\n\nBy induction on A.\n\u2022 A \u2261 t\u2032\nWe have\n\nR \u22a2 t\u2032\nt\u2208\n/R\nR \u22a2 \u2200t.t\u2032\nIf t 6= t\u2032 we have t\u2032 [B/t] \u2261 t\u2032 hence R \u22a2 [B/t]t\u2032 . If t \u2261 t\u2032 then we have\nt\u2032 [B/t] \u2261 B hence R \u22a2 t\u2032 [B/t].\n\n\u2022 A\u22611\nWe have\n\nR\u22a21 t\u2208\n/R\nR \u22a2 \u2200t.1\nfrom which we deduce R \u22a2 1[B/t].\n\n\u2022 A \u2261 (C \u22b8 D)\nBy induction hypothesis we have R \u22a2 C[B/t] and R \u22a2 D[B/t]. We then\nderive\nR \u22a2 C[B/t]\nR \u22a2 D[B/t]\nR \u22a2 (C \u22b8 D)[B/t]\n\u2022 A \u2261 !C\nBy induction hypothesis we have R \u22a2 C[B/t], from which we deduce\nR \u22a2 C[B/t]\nR \u22a2 !C[B/t]\n\u2022 A \u2261 Regr C\nWe have\n\nR\u22a2 r:C\u2208R\nR \u22a2 Regr C\nR \u22a2 \u2200t.Regr C\n\n31\n\nt\u2208\n/R\n\n\fAs t \u2208\n/ R and r : (\u03b4, C) \u2208 R, we have r : (\u03b4, C[B/t]) \u2208 R, from which we\ndeduce\nR \u22a2 r : (\u03b4, C[B/t] \u2208 R\nR \u22a2 Regr C [B/t]\n\u2022 A \u2261 \u2200t\u2032 .C\nIf t 6= t\u2032 : From R \u22a2 \u2200t.(\u2200t\u2032 .C) we have t\u2032 \u2208\n/ R and by induction hypothesis\nwe have R \u22a2 C[B/t], from which we deduce\nR \u22a2 C[B/t]\nt\u2032 \u2208\n/R\n\u2032\nR \u22a2 (\u2200t .C)[B/t]\nIf t \u2261 t\u2032 we have (\u2200t\u2032 .C)[B/t] \u2261 \u2200t\u2032 .C. Since we have\nR \u22a2 \u2200t\u2032 .C\nt\u2208\n/R\n\u2032\nR \u22a2 \u2200t.(\u2200t .C)\nwe conclude R \u22a2 (\u2200t\u2032 .C)[B/t].\n\nA.6\n\nProof of theorem 4.4\n\nProperties 1 and 2 are easily checked.\nA.6.1\n\nSubstitution\n\nIf x is not free in M , we just have to check that any proof of \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 M\ncan be transformed into a proof of \u0393 \u22a2\u03b4 M .\nSo let us assume x is free in M . Next, we proceed by induction on the\nderivation of \u0393, x : \u03b4 \u2032 \u22a2\u03b4 M .\n\u2022 \u0393, x : (\u03b4, A) \u22a2\u03b4 x : A. Then \u03b4 = \u03b4 \u2032 , x[V /x] = V , and by hypothesis\n\u0393 \u22a2\u03b4 V : A.\n\u2022 \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 \u03bby.M : B \u22b8 C is derived from \u0393, x : (\u03b4 \u2032 , A), y : (\u03b4, B) \u22a2\u03b4\n\u2032\nM : C, with x 6= y and y not occurring in V . By (2), \u0393, y : (\u03b4, B) \u22a2\u03b4 V : A.\nBy inductive hypothesis, \u0393, (y : \u03b4, B) \u22a2\u03b4 M [V /x] : C, and then we conclude\n\u0393 \u22a2\u03b4 (\u03bby.M )[V /x] : B \u22b8 C.\n\u2022 \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 (M1 M2 ) : C is derived from \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 M1 : B \u22b8\nC and \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 M1 : B \u22b8 C. By inductive hypothesis, \u0393 \u22a2\u03b4\nM1 [V /x] : B \u22b8 C and \u0393 \u22a2\u03b4 M2 [V /x] : C, and then we conclude \u0393 \u22a2\u03b4\n(M1 M2 )[V /x] : C.\n\u2022 \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 !M : !B is derived from \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4+1 M : B. By\ninductive hypothesis, \u0393 \u22a2\u03b4+1 M [V /x] : B, and then we conclude \u0393 \u22a2\u03b4\n!M [V /x] : !B.\n\u2022 \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 let !y = M1 in M2 : B, with x 6= y and y not free in V\nis derived from \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 M1 : C and \u0393, x : (\u03b4 \u2032 , A), y : (\u03b4 + 1, C) \u22a2\u03b4\nM2 : B. By inductive hypothesis, \u0393 \u22a2\u03b4 M1 [V /x] : C \u0393, y : (\u03b4 + 1, C) \u22a2\u03b4\nM2 [V /x] : B, and then we conclude \u0393 \u22a2\u03b4 (let !y = M1 in M2 )[V /x] : B.\n32\n\n\f\u2022 M \u2261 get(r). We have R, r : (\u03b4, B); \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 get(r) : B. Since\nget(r)[V /x] = get(r) and x \u2208\n/ FV(get(r)) then R, r : (\u03b4, B); \u0393 \u22a2\u03b4 get(r)[V /x] :\nB.\n\u2022 M \u2261 set(r, V \u2032 ). We have\nR, r : (\u03b4, C); \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 V \u2032 : C\nR, r : (\u03b4, C); \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 set(r, V \u2032 ) : 1\nBy induction hypothesis we get\nR, r : (\u03b4, C); \u0393 \u22a2\u03b4 V \u2032 [V /x] : C\nand hence we derive\nR, r : (\u03b4, C); \u0393 \u22a2\u03b4 (set(r, V \u2032 ))[V /x] : 1\n\u2022 M \u2261 (M1 | M2 ). We have\nR; \u0393, x : (\u03b4 \u2032 , A) \u22a2\u03b4 Mi : Ci\n\ni = 1, 2\n\n\u03b4\n\n\u2032\n\nR; \u0393, x : (\u03b4 , A) \u22a2 (M1 | M2 ) : B\nBy induction hypothesis we derive\nR; \u0393 \u22a2\u03b4 Mi [V /x] : Ci\nand hence we derive\nR; \u0393 \u22a2\u03b4 (M1 | M2 )[V /x] : B\nA.6.2\n\nSubject Reduction\n\nWe first state and sketch the proof of 4 lemmas.\nLemma A.4 (structural equivalence preserves typing). If R; \u0393 \u22a2\u03b4 P : \u03b1 and\nP \u2261 P \u2032 then R; \u0393 \u22a2\u03b4 P \u2032 : \u03b1.\nProof. Recall that structural equivalence is the least equivalence relation induced by the equations stated in Table 3.2 and closed under static contexts.\nThen we proceed by induction on the proof of structural equivalence. This is is\nmainly a matter of reordering the pieces of the typing proof of P so as to obtain\na typing proof of P \u2032 .\nLemma A.5 (evaluation contexts and typing). Suppose that in the proof of\n\u2032\nR; \u0393 \u22a2\u03b4 E[M ] : \u03b1 we prove R; \u0393\u2032 \u22a2\u03b4 M : \u03b1\u2032 . Then replacing M with a M \u2032 such\n\u2032 \u03b4\u2032\n\u2032\n\u2032\nthat R; \u0393 \u22a2 M : \u03b1 , we can still derive R; \u0393 \u22a2\u03b4 E[M \u2032 ] : \u03b1.\nProof. By induction on the structure of E.\n\n33\n\n\fLemma A.6 (functional redexes). If R; \u0393 \u22a2\u03b4 E[\u2206] : \u03b1 where \u2206 has the shape\n(\u03bbx.M )V or let !x = !V in M then R; \u0393 \u22a2\u03b4 E[M [V /x]] : \u03b1.\nProof. We appeal to the substitution lemma 3. This settles the case where the\nevaluation context E is trivial. If it is complex then we also need lemma A.5.\nLemma A.7 (side effects redexes). If R; \u0393 \u22a2\u03b4 \u2206 : \u03b1 where \u2206 is one of the\nprograms on the left-hand side then R; \u0393 \u22a2\u03b4 \u2206\u2032 : \u03b1 where \u2206\u2032 is the corresponding\nprogram on the right-hand side:\n(1)\n(2)\n(3)\n\nE[set(r, V )]\nE[get(r)] | (r \u2190 V )\nE[let !x = get(r) in M ] | (r \u2190 !V )\n\nE[\u2217] | (r \u2190 V )\nE[V ]\nE[M [V /x]] | (r \u2190 !V )\n\nProof. We proceed by case analysis.\n\u2032\n\n1. Suppose we derive R; \u0393 \u22a2\u03b4 E[set(r, V )] : \u03b1 from R; \u0393\u2032 \u22a2\u03b4 set(r, V ) : 1. We\n\u2032\ncan derive R; \u0393\u2032 \u22a2\u03b4 \u2217 : 1 and by Lemma A.5 we derive R; \u0393 \u22a2\u03b4 E[\u2217] : \u03b1\nand finally R; \u0393 \u22a2\u03b4 E[set(r, V )] | (r \u2190 V ) : \u03b1.\n\u2032\n\n2. Suppose R; \u0393 \u22a2\u03b4 E[get(r)] : \u03b1 is derived from R; \u0393 \u22a2\u03b4 get(r) : A, where\n\u2032\nr : (\u03b4 \u2032 , A) \u2208 R. Hence R; \u0393 \u22a20 (r \u2190 V ) : B is derived from R; \u0393 \u22a2\u03b4 V : A.\nFinally, by Lemma A.5 we derive R; \u0393 \u22a2\u03b4 E[V ] : \u03b1.\n3. Suppose R; \u0393 \u22a2\u03b4 E[let !x = get(r) in M ] : \u03b1 is derived from\n\u2032\n\nR; \u0393\u2032 \u22a2\u03b4 get(r) : !A\n\n\u2032\n\nR; \u0393\u2032 , x : (\u03b4 \u2032 + 1, A) \u22a2\u03b4 M : \u03b1\u2032\n\n\u2032\n\nR; \u0393\u2032 \u22a2\u03b4 let !x = get(r) in M : \u03b1\u2032\nwhere r : (\u03b4 \u2032 , !A) \u2208 R. Hence R; \u0393 \u22a20 (r \u2190 !V ) : B is derived from\n\u2032\n\u2032\nR; \u0393 \u22a2\u03b4 +1 V : A. By Lemma 3 we can derive R; \u0393\u2032 \u22a2\u03b4 M [V /x] : \u03b1\u2032 . Then\nby Lemma A.5 we derive R; \u0393 \u22a2\u03b4 E[M [V /x]] : \u03b1.\n\nWe are then ready to prove subject reduction. We recall that P \u2192 P \u2032 means\nthat P is structurally equivalent to a program C[\u2206] where C is a static context,\n\u2206 is one of the programs on the left-hand side of the rewriting rules specified\nin Table 3.2, \u2206\u2032 is the respective program on the right-hand side, and P \u2032 is\nsyntactically equal to C[\u2206\u2032 ].\n\u2032\nBy lemma A.4, we know that R; \u0393 \u22a2\u03b4 C[\u2206] : \u03b1. This entails that R\u2032 ; \u0393\u2032 \u22a2\u03b4\n\u2032\n\u2206 : \u03b1\u2032 for suitable R\u2032 , \u0393\u2032 , \u03b1\u2032 , \u03b4 \u2032 . By lemmas A.6 and A.7, we derive that R\u2032 ; \u0393\u2032 \u22a2\u03b4\n\u2206\u2032 : \u03b1\u2032 . Then by induction on the structure of C we argue that R; \u0393 \u22a2\u03b4 C[\u2206\u2032 ] : \u03b1.\nA.6.3\n\nProgress\n\nTo derive the progress property we first determine for each closed type A where\nA = A1 \u22b8 A2 or A = !A1 the shape of a closed value of type A with the\nfollowing classification lemma.\n34\n\n\fLemma A.8 (classification). Assume R; \u2212 \u22a2\u03b4 V : A. Then:\n\u2022 if A = A1 \u22b8 A2 then V = \u03bbx.M ,\n\u2022 if A = !A1 then V = !V1\nProof. By case analysis on the typing rules.\n\u2022 if A = A1 \u22b8 A2 , the only typing rule that can be applied is\nR; x : (\u03b4, A1 ) \u22a2\u03b4 M : A2\nR; \u2212 \u22a2\u03b4 \u03bbx.M : A1 \u22b8 A2\nhence V = \u03bbx.M .\n\u2022 if A = !A1 , the only typing rule that can be applied is\nR; \u2212 \u22a2\u03b4+1 V1 : A1\nR; \u2212 \u22a2\u03b4 !V1 : !A1\nhence V = !V1 .\n\nThen we proceed by induction on the structure of the threads Mi to show that\neach one of them is either a value or a stuck get of the form E[\u2206] where \u2206 can\nbe (\u03bbx.M )get(r) or let !x = get(r) in M .\n\u2022 Mi = x\nthe case of variables is void since they are not closed terms.\n\u2022 Mi = \u2217 or Mi = r or Mi = \u03bbx.M\nthese cases are trivial since \u2217, r and \u03bbx.M are already values.\n\u2022 Mi = P Q\nWe know that P Q cannot reduce, which by looking at the evaluation\ncontexts means that P cannot reduce. Then by induction hypothesis we\nhave two cases: either P is a value or P is a stuck get.\n\u2013 assume P is a value. We have\nR; \u2212 \u22a2\u03b4 P : A \u22b8 B\nR; \u2212 \u22a2\u03b4 Q : A\nR; \u2212 \u22a2\u03b4 P Q : B\nBy Lemma A.8 we have P = \u03bbx.M . Since P Q cannot reduce and\nP = \u03bbx.M , by looking at the evaluation contexts we have that Q\ncannot reduce. Moreover Q cannot be a value, otherwise P Q is a\nredex. Hence by induction hypothesis Q is a stuck get of the form\nE1 [\u2206]. Hence P Q is of the form E[\u2206] where E = P E1 .\n\n35\n\n\f\u2013 assume P is a stuck get of the form E1 [\u2206]. Then P Q is of the form\nE[\u2206] where E = E1 Q.\n\u2022 Mi = let !x = P in Q\nWe know that let !x = P in Q cannot reduce, which by looking at the\nevaluation contexts means that P cannot reduce. Then by induction hypothesis we have two cases: either P is a value or P is a stuck get.\n\u2013 assume P is a value. We have\nR; \u2212 \u22a2\u03b4 P : !A\n\nR; x : (\u03b4 + 1, A) \u22a2\u03b4 Q : B\n\nR; \u2212 \u22a2\u03b4 let !x = P in Q : B\nBy Lemma A.8 we have P = !V hence let !x = !V in Q is a redex and\nthis contradicts the hypothesis that let !x = P in Q cannot reduce.\nThus P cannot be a value.\n\u2013 assume P is a stuck get of the form E1 [\u2206]. Then let !x = P in Q is\nof the form E[\u2206] where E = let !x = E1 in Q.\n\u2022 Mi = !P\nWe know that !P cannot reduce, which by looking at the evaluation contexts means that P cannot reduce. Then by induction hypothesis we have\ntwo cases: either P is a value or P is a stuck get.\n\u2013 assume P is a value. Then !P is also a value and we are done.\n\u2013 assume P is of the form E1 [\u2206]. Then !P is of the shape E[\u2206] where\nE = !E1 .\n\u2022 Mi = get(r\u2032 )\nWe know that get(r\u2032 ) cannot reduce which means that Mi is of the form\nE[\u2206] where r\u2032 = r and E = [] and that no value is associated with r in\nthe store.\n\u2022 Mi = set(r, V )\nThis case is void since set(r, V ) can reduce is any case.\n\nA.7\n\nProof of theorem 5.3\n\nElementary functions are characterized as the smallest class of functions containing zero, successor, projection, subtraction and which is closed by composition\nand bounded summation/product. We will need the arithmetic functions defined in Table A.1. We will abbreviate \u03bb! x.M for \u03bbx.let !x = x in M . Moreover,\nin order to represent some functions, we need to manipulate pairs in the language. We define the representation of pairs in Table A.2. In the following, we\nshow that the required functions can be represented in the sense of Definition 5.2\nby adapting the proofs from Danos and Joinet [10].\n\n36\n\n\f= \u2200t.!(t \u22b8 t) \u22b8 !(t \u22b8 t)\n\n(type of numerals)\n\nzero\nzero\n\n: N\n= \u03bbf.!(\u03bbx.x)\n\n(zero)\n\nsucc\nsucc\n\n: N\u22b8N\n= \u03bbn.\u03bbf.let !f = f in\nlet !y = n!f in!(\u03bbx.f (yx))\n\n(successor)\n\n: N\n= \u03bbf.let !f = f in !(\u03bbx.f (* * * (f x) * * * ))\n\n(numerals)\n\n: N \u22b8 (N \u22b8 N)\n= \u03bbn.\u03bbm.\u03bbf.let !f = f in\nlet !y = n!f in\nlet !y \u2032 = m!f in !(\u03bbx.y(y \u2032 x))\n\n(addition)\n\nmult\nmult\n\n: N \u22b8 (N \u22b8 N)\n= \u03bbn.\u03bbm.\u03bbf.let !f = f in\nn(m!f )\n\n(multiplication)\n\nint it\nint it\n\n: N \u22b8 \u2200t.!(t \u22b8 t) \u22b8 !t \u22b8 !t\n= \u03bbn.\u03bbg.\u03bbx.let !y = ng in\nlet !y \u2032 = x in !(yy \u2032 )\n\n(iteration)\n\nN\n\nn\nn\nadd\nadd\n\nint git\nint git\n\n: \u2200t.\u2200t\u2032 .!(t \u22b8 t) \u22b8 (!(t \u22b8 t) \u22b8 t\u2032 ) \u22b8 N \u22b8 t\u2032\n= \u03bbs.\u03bbe.\u03bbn.e(nts)\n\nTable A.1: Representation of some arithmetic functions\nA.7.1\n\nSuccessor, addition and multiplication\n\nWe check that succ represents the successor function s:\ns : N 7\u2192 N\ns(x) = x + 1\nProposition A.9. succ\n\ns.\n\nProof. Take \u2205 \u22a2\u03b4 M : N and M n. We have \u2205 \u22a2\u03b4 succ : N \u22b8 N. We can show\n\u2217\nthat succ M \u2192 s(n), hence succ M s(n). Thus succ s.\nWe check that add represents the addition function a:\na : N2 7\u2192 N\na(x, y) = x + y\n37\n\n\fA\u00d7B\n\n= \u2200t.(A \u22b8 B \u22b8 t) \u22b8 t\n\nhM, N i : A \u00d7 B\nhM, N i = \u03bbx.xM N\n\n(type of pairs)\n(pair representation)\n\nfst\nfst\n\n: \u2200t, t\u2032 .t \u00d7 t\u2032 \u22b8 t\n= \u03bbp.p(\u03bbx.\u03bby.x)\n\n(left destructor)\n\nsnd\nsnd\n\n: \u2200t, t\u2032 .t \u00d7 t\u2032 \u22b8 t\u2032\n= \u03bbp.p(\u03bbx.\u03bby.y)\n\n(right destructor)\n\nTable A.2: Representation of pairs\na.\n\nProposition A.10. add\n\nProof. For i = 1, 2 take \u2205 \u22a2\u03b4 Mi : N and Mi\nni . We have \u2205 \u22a2\u03b4 add : N \u22b8\n\u2217\nN \u22b8 N. We can show that addM1 M2 \u2192 a(n1 , n2 ), hence addM1 M2 a(n1 , n2 ).\nThus A a.\nWe check that mult represents the multiplication function m:\nm : N2 7\u2192 N\nm(x, y) = x \u2217 y\nProposition A.11. mult\n\nm.\n\nProof. For i = 1, 2 take \u2205 \u22a2\u03b4 Mi : N and Mi ni . We have \u2205 \u22a2\u03b4 mult : N \u22b8\n\u2217\nN \u22b8 N. We can show that mult M1 M2 \u2192 m(n1 , n2 ), hence mult M1 M2\nm(n1 , n2 ). Thus mult m.\nA.7.2\n\nIteration schemes\n\nWe check that int it represents the following iteration function it:\nit : (N 7\u2192 N) 7\u2192 N 7\u2192 N 7\u2192 N\nit(f, n, x) = f n (x)\nProposition A.12. int it\n\nit.\n\nProof. We have \u2205 \u22a2\u03b4 int it : N \u22b8 \u2200t.!(t \u22b8 t) \u22b8 !t \u22b8 !t. Given \u2205 \u22a2\u03b4 M : N\nwith M\nn, \u2205 \u22a2\u03b4 F : N \u22b8 N with F\nf and \u2205 \u22a2\u03b4 X : N with X\nx,\n\u2217\nn\nf and X\nx, we get\nwe observe that int it M (!F )(!X) \u2192 F X. Since F\n\u2217\nF n X \u2192 it(f, n, x). Hence int it it.\nThe function it is an instance of the more general iteration scheme git:\ngit : (N 7\u2192 N) 7\u2192 ((N 7\u2192 N) 7\u2192 N) 7\u2192 N 7\u2192 N\ngit(step, exit, n) = exit(\u03bbx.stepn (x))\n38\n\n\fIndeed, we have:\ngit(f, \u03bbf.f x, n) = (\u03bbf.f x)(\u03bbx.f n (x)) = it(f, n, x)\nProposition A.13. int git\n\ngit.\n\nProof. Take \u2205 \u22a2\u03b4 M : N with M n, \u2205 \u22a2\u03b4 E : ((N \u22b8 N) \u22b8 N) \u22b8 N with E\n\u2217\nexit, \u2205 \u22a2\u03b4 S : N \u22b8 N with S step. Then we have int git S E M \u2192 E(\u03bbx.S n x).\n\u2217\nSince S\nstep and E\nexit we have E(\u03bbx.S n x) \u2192 exit(\u03bbx.stepn (x). Hence\nint git git.\nA.7.3\n\nCoercion\n\nLet S = \u03bbnN .S \u2032 . For 0 \u2265 i, we define Si\u2032 inductively:\nS0\u2032 = S \u2032\n\u2032\nSi\u2032 = let !n = n in !Si\u22121\nLet Si = \u03bbn.Si\u2032 . We can derive \u2205 \u22a2\u03b4 Si : !i N \u22b8 !i N. For i \u2265 0, we define Ci\ninductively:\nC0 = \u03bbx.x\nCi+1 = \u03bbn.int it(!Si )(!i+1 0)n\n\u2205 \u22a2\u03b4 Ci : N \u22b8 !i N\nLemma A.14 (integer representation is preserved by coercion). Let \u2205 \u22a2\u03b4 M : N\nand M n. We can derive \u2205 \u22a2\u03b4 Ci M : !i N. Moreover Ci M n.\nProof. By induction on i.\nLemma A.15 (function representation is preserved by coercion). Let\n\u2205 \u22a2\u03b4 F : !i1 N1 \u22b8 . . . \u22b8 !ik Nk \u22b8 !p N\n\u2217\n\nand \u2205 \u22a2\u03b4 Mj : N with Mj nj for 1 \u2264 j \u2264 k such that F (!i1 M1 . . . (!ik Mk )) \u2192\nf (n1 , . . . , nk ). Then we can find a term C(F ) = \u03bb~xN .F ((Ci1 x1 ) . . . (Cik xk )) such\nthat\n\u2205 \u22a2\u03b4 C(F ) : N \u22b8 N \u22b8 . . . \u22b8 N \u22b8 !p N\nand C(F )\nA.7.4\n\nf.\n\nPredecessor and subtraction\n\nWe first want to represent predecessor :\np : N 7\u2192 N\np(0) = 0\np(x) = x \u2212 1\n\n39\n\n\fWe define the following terms:\nST = !(\u03bbz.hsnd z, f (snd z)i)\nf : (\u03b4 + 1, t \u22b8 t) \u22a2\u03b4 ST : !(t \u00d7 t \u22b8 t \u00d7 t)\nEX = \u03bbg.let !g = g in !(\u03bbx.fst ghx, xi)\n\u2205 \u22a2\u03b4 EX : !(t \u00d7 t \u22b8 t \u00d7 t) \u22b8 !(t \u22b8 t)\nP = \u03bbn.\u03bbf.let !f = f in int git ST EX n\n\u2205 \u22a2\u03b4 P : N \u22b8 N\nProposition A.16 (predecessor is representable). P\nProof. Take \u2205 \u22a2\u03b4 M : N and M\nP M p(n). Thus P p.\n\np.\n\u2217\n\nn. We can show that (P M )\u2212 \u2192 p(n), hence\n\nNow we want to represent (positive) subtraction s:\ns : N2 7\u2192 N\n\u001a\n\ns(x, y) =\nTake\n\nx\u2212y\n0\n\nif x \u2265 y\nif y \u2265 x\n\nSU B = \u03bbm.let !m = m in \u03bbn.int it !P !m n : !N \u22b8 N \u22b8 !N\n\u2205 \u22a2\u03b4 SU B : !N \u22b8 N \u22b8 !N\n\nProposition A.17 (subtraction is representable). C(SU B)\n\ns.\n\nProof. For i = 1, 2 take \u2205 \u22a2\u03b4 Mi : N and Mi\nni . We can show that\n\u2217\n(SU B(!M1 )M2 )\u2212 \u2192 s(n1 , n2 ). Hence by Lemma A.15, C(SU B) s.\nA.7.5\n\nComposition\n\nLet g be a m-ary function and G\nNm \u22b8 !p N (where p \u2265 0) and G\nand Fi a term such that \u2205 \u22a2\u03b4 Fi\nFi fi . We want to represent the\n\nbe a term such that \u2205 \u22a2\u03b4 G : N1 \u22b8 . . . \u22b8\ng. For 1 \u2264 i \u2264 m, let fi be a k-ary function\n: N1 \u22b8 . . . \u22b8 Nk !qi N (where qi \u2265 0) and\ncomposition function h such that:\n\nh : Nk 7\u2192 N\nh(x1 , . . . , xk ) = g(f1 (x1 , . . . , xk ), . . . , fm (x1 , . . . , xk ))\nFor i \u2265 0 and a term T , we define T i inductively as:\nT0 = T\ni\nT i = \u03bb~x! N .let !~x = ~x in !(T i\u22121 ~x)\nLet q = max(qi ). We can derive\n\u2205 \u22a2\u03b4 Gq+1 : !q+1 N1 \u22b8 . . . \u22b8 !q+1 Nm \u22b8 !p+q+1 N\n40\n\n\fWe can also derive\n\u2205 \u22a2\u03b4 Fiq\u2212qi : !q\u2212qi N1 \u22b8 . . . \u22b8 !q\u2212qi Nk \u22b8 !q N\nThen, applying coercion we get\n\u2205 \u22a2\u03b4 C(Fiq\u2212qi ) : N1 \u22b8 . . . Nk \u22b8 !q N\nand we derive\nx1 : (\u03b4 + 1, N), . . . , xk : (\u03b4 + 1, N) \u22a2\u03b4 !(C(Fiq\u2212qi )x1 . . . xk ) : !q+1 N\nLet Fi\u2032 \u2261 !(C(Fiq\u2212qi )x1 . . . xk ). By application we get\n\u2032\n: !p+q+1 N\nx1 : (\u03b4 + 1, N), . . . , xk : (\u03b4 + 1, N) \u22a2\u03b4 Gq+1 F1\u2032 . . . Fm\n\nWe derive\n\u2032\n\u2205 \u22a2\u03b4 \u03bb~x.let !~x = ~x in Gq+1 F1\u2032 . . . Fm\n: !N1 \u22b8 . . . \u22b8 !Nm \u22b8 !p+q+1 N\n\nApplying coercion we get\n\u2032\n) : N1 \u22b8 . . . \u22b8 Nm \u22b8 !p+q+1 N\n\u2205 \u22a2\u03b4 C(\u03bb~x!N .let !~x = ~x in Gq+1 F1\u2032 . . . Fm\n\nTake\n\u2032\nH = C(\u03bb~x!N .let !~x = ~x in Gq+1 F1\u2032 . . . Fm\n)\n\nProposition A.18 (composition is representable). H\n\nh.\n\nProof. We now have to show that for all Mi and ni where 1 \u2264 i \u2264 k such that\nMi ni and \u2205 \u22a2\u03b4 Mi : N, we have HM1 . . . Mk h(n1 , . . . , nk ). Since Fi fi ,\nwe have Fi M1 . . . Mk fi (n1 , . . . , nk ). Moreover G g, hence\nG(F1 M1 . . . Mk ) . . . (Fm M1 . . . Mk )\n\ng(f1 (n1 , . . . , nk ), . . . , fm (n1 , . . . , nk ))\n\n\u2217\n\nWe can show that HM1 . . . Mk \u2192 G(F1 M1 . . . Mk ) . . . (Fm M1 . . . Mk ), hence\nHM1 . . . Mk\nThus H\nA.7.6\n\ng(f1 (n1 , . . . , nk ), . . . , fm (n1 , . . . , nk ))\n\nh.\nBounded sums and products\n\nLet f be a k + 1-ary function f : Nk+1 \u2192 N, where\n\u2205 \u22a2 F : N i \u22b8 N 1 \u22b8 . . . \u22b8 N k \u22b8 !p N\nwith p \u2265 0 and F\n\nf . We want to represent\nP\n\u2022 bounded sum:\n1\u2264i\u2264n f (i, x1 , . . . , xk )\nQ\n\u2022 bounded product: 1\u2264i\u2264n f (i, x1 , . . . , xk )\n41\n\n\fFor this we are going to represent h : Nk+1 \u2192 N:\nh(0, x1 , . . . , xk ) = f (0, x1 , . . . , xk )\nh(n + 1, x1 , . . . , xk ) = g(f (n + 1, x1 , . . . , xk ), h(n, x1 , . . . , xk ))\nwhere g is a binary function standing for addition or multiplication, thus representable. More precisely we have g : N2 \u2192 N such that \u2205 \u22a2\u03b4 G : N \u22b8 N \u22b8 N\nand G g.\nFor i \u2265 0 and a term T we define T i inductively:\nT 0 = T x1 . . . xk\nT i = let !x1 = x1 in . . . let !xk = xk in !T i\u22121\nWe define the following terms:\nST = \u03bbz.hS(fst z), Gp (F x1 . . . xk (S(fst z)))(snd z)i\n\u2205; x1 : (\u03b4, N), . . . , xk : (\u03b4, N) \u22a2\u03b4 ST : N \u00d7 !p N \u22b8 N \u00d7 !p N\nEX = \u03bbh.let !h = h in !snd hh0, F x1 . . . xk 0i\n\u2205; x1 : (\u03b4 + 1, N), . . . , xk : (\u03b4 + 1, N) \u22a2\u03b4 EX : !(N \u00d7 !p N \u22b8 N \u00d7 !p N) \u22b8 !p+1 N\nWe derive\nn : ( N), ~x : (\u03b4, N) \u22a2\u03b4 let !~x = ~x in let !n = n in int git !ST EX n : !p+1 N\nLet R = let !~x = ~x in let !n = n in int git !ST EX n. By coercion and\nabstractions we get\n\u2205 \u22a2\u03b4 C(\u03bbn.\u03bb~x.R) : Ni \u22b8 N1 \u22b8 . . . \u22b8 Nk \u22b8 !p+1 N\nTake H = C(\u03bbn.\u03bb~x.R).\nProposition A.19 (bounded sum/product is representable). H\nProof. Given Mi\nwe remark that\n\ni and Mj\n\nh.\n\nnj with 1 \u2264 j \u2264 k and taking G for addition,\n\n\u2217\n\nHMi M1 . . . Mk \u2192 f (i, n1 , . . . , nk ) + . . . + f (1, n1 , . . . , nk ) + f (0, n1 , . . . , nk )\nHence H\n\nh.\n\n42\n\n\f"}