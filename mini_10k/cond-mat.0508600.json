{"id": "http://arxiv.org/abs/cond-mat/0508600v1", "guidislink": true, "updated": "2005-08-25T06:31:18Z", "updated_parsed": [2005, 8, 25, 6, 31, 18, 3, 237, 0], "published": "2005-08-25T06:31:18Z", "published_parsed": [2005, 8, 25, 6, 31, 18, 3, 237, 0], "title": "Proof of the local REM conjecture for number partitioning II: growing\n  energy scales", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0508338%2Ccond-mat%2F0508675%2Ccond-mat%2F0508706%2Ccond-mat%2F0508652%2Ccond-mat%2F0508431%2Ccond-mat%2F0508600%2Ccond-mat%2F0508240%2Ccond-mat%2F0508399%2Ccond-mat%2F0508407%2Ccond-mat%2F0508693%2Ccond-mat%2F0508194%2Ccond-mat%2F0508372%2Ccond-mat%2F0508185%2Ccond-mat%2F0508524%2Ccond-mat%2F0508576%2Ccond-mat%2F0508687%2Ccond-mat%2F0508559%2Ccond-mat%2F0508228%2Ccond-mat%2F0508608%2Ccond-mat%2F0508619%2Ccond-mat%2F0508316%2Ccond-mat%2F0508737%2Ccond-mat%2F0508772%2Ccond-mat%2F0508135%2Ccond-mat%2F0508160%2Ccond-mat%2F0508667%2Ccond-mat%2F0508009%2Ccond-mat%2F0508287%2Ccond-mat%2F0508587%2Ccond-mat%2F0508181%2Ccond-mat%2F0508314%2Ccond-mat%2F0508683%2Ccond-mat%2F0508765%2Ccond-mat%2F0508495%2Ccond-mat%2F0508707%2Ccond-mat%2F0508396%2Ccond-mat%2F0508201%2Ccond-mat%2F0508369%2Ccond-mat%2F0508091%2Ccond-mat%2F0508178%2Ccond-mat%2F0508405%2Ccond-mat%2F0508555%2Ccond-mat%2F0508357%2Ccond-mat%2F0508419%2Ccond-mat%2F0508214%2Ccond-mat%2F0508352%2Ccond-mat%2F0508618%2Ccond-mat%2F0508689%2Ccond-mat%2F0508666%2Ccond-mat%2F0508680%2Ccond-mat%2F0508144%2Ccond-mat%2F0508154%2Ccond-mat%2F0508621%2Ccond-mat%2F0508279%2Ccond-mat%2F0508599%2Ccond-mat%2F0508235%2Ccond-mat%2F0508098%2Ccond-mat%2F0508242%2Ccond-mat%2F0508702%2Ccond-mat%2F0508444%2Ccond-mat%2F0508207%2Ccond-mat%2F0508622%2Ccond-mat%2F0508663%2Ccond-mat%2F0508665%2Ccond-mat%2F0508271%2Ccond-mat%2F0508640%2Ccond-mat%2F0508489%2Ccond-mat%2F0508327%2Ccond-mat%2F0508452%2Ccond-mat%2F0508153%2Ccond-mat%2F0508501%2Ccond-mat%2F0508548%2Ccond-mat%2F0508292%2Ccond-mat%2F0508345%2Ccond-mat%2F0508657%2Ccond-mat%2F0508005%2Ccond-mat%2F0508724%2Ccond-mat%2F0508522%2Ccond-mat%2F0508095%2Ccond-mat%2F0508244%2Ccond-mat%2F0508425%2Ccond-mat%2F0508468%2Ccond-mat%2F0508597%2Ccond-mat%2F0508114%2Ccond-mat%2F0508430%2Ccond-mat%2F0508474%2Ccond-mat%2F0508709%2Ccond-mat%2F0508564%2Ccond-mat%2F0508454%2Ccond-mat%2F0508003%2Ccond-mat%2F0508351%2Ccond-mat%2F0508582%2Ccond-mat%2F0508566%2Ccond-mat%2F0508036%2Ccond-mat%2F0508313%2Ccond-mat%2F0508491%2Ccond-mat%2F0508220%2Ccond-mat%2F0508047%2Ccond-mat%2F0508753%2Ccond-mat%2F0508612%2Ccond-mat%2F0508033&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Proof of the local REM conjecture for number partitioning II: growing\n  energy scales"}, "summary": "We continue our analysis of the number partitioning problem with $n$ weights\nchosen i.i.d. from some fixed probability distribution with density $\\rho$. In\nPart I of this work, we established the so-called local REM conjecture of\nBauke, Franz and Mertens. Namely, we showed that, as $n \\to \\infty$, the\nsuitably rescaled energy spectrum above some {\\it fixed} scale $\\alpha$ tends\nto a Poisson process with density one, and the partitions corresponding to\nthese energies become asymptotically uncorrelated. In this part, we analyze the\nnumber partitioning problem for energy scales $\\alpha_n$ that grow with $n$,\nand show that the local REM conjecture holds as long as $n^{-1/4}\\alpha_n \\to\n0$, and fails if $\\alpha_n$ grows like $\\kappa n^{1/4}$ with $\\kappa>0$.\n  We also consider the SK-spin glass model, and show that it has an analogous\nthreshold: the local REM conjecture holds for energies of order $o(n)$, and\nfails if the energies grow like $\\kappa n$ with $\\kappa >0$.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0508338%2Ccond-mat%2F0508675%2Ccond-mat%2F0508706%2Ccond-mat%2F0508652%2Ccond-mat%2F0508431%2Ccond-mat%2F0508600%2Ccond-mat%2F0508240%2Ccond-mat%2F0508399%2Ccond-mat%2F0508407%2Ccond-mat%2F0508693%2Ccond-mat%2F0508194%2Ccond-mat%2F0508372%2Ccond-mat%2F0508185%2Ccond-mat%2F0508524%2Ccond-mat%2F0508576%2Ccond-mat%2F0508687%2Ccond-mat%2F0508559%2Ccond-mat%2F0508228%2Ccond-mat%2F0508608%2Ccond-mat%2F0508619%2Ccond-mat%2F0508316%2Ccond-mat%2F0508737%2Ccond-mat%2F0508772%2Ccond-mat%2F0508135%2Ccond-mat%2F0508160%2Ccond-mat%2F0508667%2Ccond-mat%2F0508009%2Ccond-mat%2F0508287%2Ccond-mat%2F0508587%2Ccond-mat%2F0508181%2Ccond-mat%2F0508314%2Ccond-mat%2F0508683%2Ccond-mat%2F0508765%2Ccond-mat%2F0508495%2Ccond-mat%2F0508707%2Ccond-mat%2F0508396%2Ccond-mat%2F0508201%2Ccond-mat%2F0508369%2Ccond-mat%2F0508091%2Ccond-mat%2F0508178%2Ccond-mat%2F0508405%2Ccond-mat%2F0508555%2Ccond-mat%2F0508357%2Ccond-mat%2F0508419%2Ccond-mat%2F0508214%2Ccond-mat%2F0508352%2Ccond-mat%2F0508618%2Ccond-mat%2F0508689%2Ccond-mat%2F0508666%2Ccond-mat%2F0508680%2Ccond-mat%2F0508144%2Ccond-mat%2F0508154%2Ccond-mat%2F0508621%2Ccond-mat%2F0508279%2Ccond-mat%2F0508599%2Ccond-mat%2F0508235%2Ccond-mat%2F0508098%2Ccond-mat%2F0508242%2Ccond-mat%2F0508702%2Ccond-mat%2F0508444%2Ccond-mat%2F0508207%2Ccond-mat%2F0508622%2Ccond-mat%2F0508663%2Ccond-mat%2F0508665%2Ccond-mat%2F0508271%2Ccond-mat%2F0508640%2Ccond-mat%2F0508489%2Ccond-mat%2F0508327%2Ccond-mat%2F0508452%2Ccond-mat%2F0508153%2Ccond-mat%2F0508501%2Ccond-mat%2F0508548%2Ccond-mat%2F0508292%2Ccond-mat%2F0508345%2Ccond-mat%2F0508657%2Ccond-mat%2F0508005%2Ccond-mat%2F0508724%2Ccond-mat%2F0508522%2Ccond-mat%2F0508095%2Ccond-mat%2F0508244%2Ccond-mat%2F0508425%2Ccond-mat%2F0508468%2Ccond-mat%2F0508597%2Ccond-mat%2F0508114%2Ccond-mat%2F0508430%2Ccond-mat%2F0508474%2Ccond-mat%2F0508709%2Ccond-mat%2F0508564%2Ccond-mat%2F0508454%2Ccond-mat%2F0508003%2Ccond-mat%2F0508351%2Ccond-mat%2F0508582%2Ccond-mat%2F0508566%2Ccond-mat%2F0508036%2Ccond-mat%2F0508313%2Ccond-mat%2F0508491%2Ccond-mat%2F0508220%2Ccond-mat%2F0508047%2Ccond-mat%2F0508753%2Ccond-mat%2F0508612%2Ccond-mat%2F0508033&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We continue our analysis of the number partitioning problem with $n$ weights\nchosen i.i.d. from some fixed probability distribution with density $\\rho$. In\nPart I of this work, we established the so-called local REM conjecture of\nBauke, Franz and Mertens. Namely, we showed that, as $n \\to \\infty$, the\nsuitably rescaled energy spectrum above some {\\it fixed} scale $\\alpha$ tends\nto a Poisson process with density one, and the partitions corresponding to\nthese energies become asymptotically uncorrelated. In this part, we analyze the\nnumber partitioning problem for energy scales $\\alpha_n$ that grow with $n$,\nand show that the local REM conjecture holds as long as $n^{-1/4}\\alpha_n \\to\n0$, and fails if $\\alpha_n$ grows like $\\kappa n^{1/4}$ with $\\kappa>0$.\n  We also consider the SK-spin glass model, and show that it has an analogous\nthreshold: the local REM conjecture holds for energies of order $o(n)$, and\nfails if the energies grow like $\\kappa n$ with $\\kappa >0$."}, "authors": ["Christian Borgs", "Jennifer Chayes", "Stephan Mertens", "Chandra Nair"], "author_detail": {"name": "Chandra Nair"}, "author": "Chandra Nair", "arxiv_comment": "42 pages", "links": [{"href": "http://arxiv.org/abs/cond-mat/0508600v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0508600v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0508600v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0508600v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:cond-mat/0508600v1 [cond-mat.dis-nn] 25 Aug 2005\n\nPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER\nPARTITIONING II: GROWING ENERGY SCALES\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\nAbstract. We continue our analysis of the number partitioning problem with\nn weights chosen i.i.d. from some fixed probability distribution with density\n\u03c1. In Part I of this work, we established the so-called local REM conjecture of\nBauke, Franz and Mertens. Namely, we showed that, as n \u2192 \u221e, the suitably\nrescaled energy spectrum above some fixed scale \u03b1 tends to a Poisson process\nwith density one, and the partitions corresponding to these energies become\nasymptotically uncorrelated. In this part, we analyze the number partitioning\nproblem for energy scales \u03b1n that grow with n, and show that the local REM\nconjecture holds as long as n\u22121/4 \u03b1n \u2192 0, and fails if \u03b1n grows like \u03ban1/4 with\n\u03ba > 0.\nWe also consider the SK-spin glass model, and show that it has an analogous\nthreshold: the local REM conjecture holds for energies of order o(n), and fails\nif the energies grow like \u03ban with \u03ba > 0.\n\n1. Introduction\n1.1. Number Partitioning. In this paper we continue the study of the energy\nspectrum of the number partition problem (Npp) with randomly chosen weights.\nWe refer the reader to [BCMN05] for a detailed motivation of this study, but for\ncompleteness, we repeat the main definitions.\nWe consider random instances of the Npp with weights X1 , . . . , Xn \u2208 R taken to\nbe independently and identically distributed according to some density \u03c1(X) with\nfinite second moment (for simplicity of notation, we will choose the second moment\nto be one). Given these weights, one seeks a partition of these numbers into two\nsubsets such that the sum of numbers in one subset is as close as possible to the\nsum of numbers in the other subset. Each of the 2n partitions can be encoded as\n\u03c3 \u2208 {\u22121, +1}n, where \u03c3i = 1 if Xi is put in one subset and \u03c3i = \u22121 if Xi is put in\nthe other subset; in the physics literature, such partitions \u03c3 are identified with Ising\nspin configurations. The cost function to be minimized over all spin configurations\n\u03c3 is the energy\nn\n1 X\n\u03c3i Xi ,\n(1.1)\nE(\u03c3) = \u221a\nn i=1\n\u221a\nwhere, as in [BCMN05], we have inserted a factor 1/ n to simplify the equations\nin the rest of the paper.\nNote that this scaling implies\n\u221a that the typical energies are of order one, and the\nmaximal energies are of order n. Indeed, if \u03c3 is chosen uniformly at random\nP and\nX1 , . . . , Xn are i.i.d. with second moment one, the random variable n\u22121/2 i \u03c3i Xi\nconverges to a standard normal as n \u2192 \u221e, implying in particular that for a typical\nDate: August 23, 2005.\n1\n\n\f2\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nconfiguration, P\nE(\u03c3) is of order one. The maximal energy, on the other hand, is\nequal to n\u22121/2 i |Xi |. By the law\u221aof large numbers, this implies that the maximal\nenergy is asymptotically equal to n times the expectation of |X|.\nAs usual, the correlation between two different partitions \u03c3 and \u03c3\u0303 is measured\nby the overlap between \u03c3 and \u03c3\u0303, defined as\nn\n\nq(\u03c3, \u03c3\u0303) =\n\n1X\n\u03c3k \u03c3\u0303k .\nn\n\n(1.2)\n\nk=1\n\nNote that the spin configurations \u03c3 and \u2212\u03c3 correspond to the same partition\nand therefore of course have the same energy. Thus there are N = 2n\u22121 distinct\npartitions and (with probability one) also N distinct energies. The energy spectrum\nis the sorted increasing sequence E1 , ..., EN of the energy values corresponding to\nthese N distinct partitions. Taking into account that, for each i, there are two\nconfigurations with energy Ei , we define \u03c3 (i) to be the random variable which is\nequal to one of these two configurations with probability 1/2, and equal to the other\nwith probability 1/2. Then the overlap between the configurations corresponding\nto ith and j th energies is the random variable q(\u03c3 (i) , \u03c3 (j) ).\nAs noted in [BCMN05], neither the distribution of the energies, nor the distribution of the overlaps changes if one replaces the density \u03c1(X) by the symmetrized\ndensity 21 (\u03c1(X) + \u03c1(\u2212X)). We may therefore assume without loss of generality that\n\u03c1(X) = \u03c1(\u2212X). Under this assumption, it is easy to see that the energies E(\u03c3) for\nthe different configurations \u03c3 are identically distributed. Let us stress, however,\nthat these energies are not independently distributed; the energies between different configurations are correlated random variables. Indeed, there are N = 2n\u22121\nenergies, E1 , . . . En , constructed from only n independent variables X1 , . . . Xn .\nConsider now a very simple model, the so-called random energy model (REM)\nfirst introduced by Derrida [Der81] in a different context. The defining property\nof the REM is that N energies E(\u03c3) are taken to be independent, identically distributed random variables. In the REM, the asymptotic energy spectrum for large\nN can be easily determined with the help of large order statistics: if the energies\nare ordered in increasing order and \u03b1 \u2265 0 is any fixed energy scale, the suitably\nrescaled energy spectrum above \u03b1 converges to a Poisson process. More precisely,\nif the distribution of E(\u03c3) has a non-vanishing, continuous density g(\u03b1) at \u03b1 and\nEr+1 is the first energy above \u03b1, then the rescaled energies (Er+1 \u2212 \u03b1)N g(\u03b1),\n(Er+2 \u2212 \u03b1)N g(\u03b1), . . . converge to a Poisson process with density one.\nIn spite of the correlations between the energies E(\u03c3) in the Npp, it had been\nconjectured [Mer00, BFM04] that as n \u2192 \u221e, the energy spectrum above any fixed\nenergy \u03b1 behaves asymptotically like the energy spectrum of the REM, in the sense\nthat the suitably rescaled spectrum above \u03b1 again becomes a Poisson process.\nIn [BFM04] it was also conjectured that the overlaps corresponding to adjacent\nenergies are asymptotically uncorrelated, so that the suitably normalized overlaps\nconverges to a standard normal. These two, at first sight highly speculative, claims\nwere collectively called the local REM conjecture. This conjecture was supported\nby detailed simulations.\nIn Part I of this paper [BCMN05], we proved the local REM conjecture for the\nNpp with a distribution \u03c1 that has finite second moment and lies in L1+\u01eb for some\n\u01eb > 0. More precisely, under these conditions, we proved that for all i 6= j, the\nsuitably normalized overlap between the configurations corresponding to the ith and\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n3\n\nj th energy above \u03b1 becomes asymptotically normal, and that the rescaled energies\n(Er+1 \u2212 \u03b1)\u03ben\u22121 , (Er+2 \u2212 \u03b1)\u03ben\u22121 , . . . with rescaling factor\nr\n\u03c0 \u2212(n\u22121) \u03b12\n(1.3)\n2\ne2\n\u03ben =\n2\nconverge to a Poisson process with density one. Recalling that the normalization\nin (1.1) corresponds to typical energies of order one, this this establishes the local\nREM conjecture for typical energies.\nIn [BFM04], the authors expressed the belief that the weak convergence of the\nrescaled energies to a Poisson process should extend to values of \u03b1 that grow slowly\nenough with n, although computational limitations prevented them from supporting\nthis stronger claim by simulations.\n\u221a At first, one might think that the local REM\nconjecture\ncould\nhold\nfor\n\u03b1\n=\no(\nn). Indeed, since \u221a\nthe maximal energy is of order\n\u221a\nn, it is clear that the conjecture is false for \u03b1 = c n with large enough c. But if\nthis were the\u221a\nonly obstruction, then one might hope that the conjecture could hold\nup to \u03b1 = o( n). As we will see in this paper, this is not the case; the conjecture\nwill only hold for \u03b1 = o(n1/4 ).\nBefore stating this precisely, let us be a little more careful with the scaling of the\nenergy spectrum. Note that the scaling factor (1.3)\nto [N g(\u03b1)]\u22121 , where\np is equal\nn\u22121\n\u2212\u03b12 /2\nN =2\nis the number of energies, and g(\u03b1) = 2/\u03c0e\nis the density of the\nabsolute value of a standard normal, in accordance with the expected asymptotic\ndensity of E(\u03c3) according to the local limit theorem. But it is well know that, in\ngeneral, the local limit theorem does not hold in the tails of the distribution. For\ngrowing \u03b1n , the REM conjecture should therefore be stated with a scaling factor\nthat is equal to the inverse of 2n\u22121 multiplied by the density of the energy E(\u03c3) at\n\u03b1. We call the REM conjecture with this scaling the modified REM conjecture.\u221aIt is\nthis modified REM conjecture that one might naively expect to hold for \u03b1 = o( n).\nIt turns out, however, that at least for the Npp, this distinction does not make\nmuch of a difference. For \u03b1 = o(n1/4 ), the original and the modified conjectures\nare equivalent, and the original REM conjecture holds, while for \u03b1 growing like a\nconstant times n1/4 , both the original and the modified REM conjectures fail. \u221aSo\nfor the Npp, the threshold for the validity of the REM conjecture is n1/4 , not n\nas one might have naively guessed.\n1.2. The SK Spin Glass. In a follow-up paper to [BFM04], Bauke and Mertens\ngeneralized the local REM conjecture for the Npp to a large class of disordered\nsystems, including many other models of combinatorial optimization as well as\nseveral spin glass models [BM04]. Motivated by this conjecture, Bovier and Kurkova\ndeveloped an axiomatic approach to Poisson convergence, covering, in particular\nmany types of spin glasses like the Edwards-Anderson model and the SherringtonKirkpatrick model.\nThe Sherrington-Kirkpatrick model (SK model) is defined by the energy function\nn\n1 X\nE(\u03c3) = \u221a\nXij \u03c3i \u03c3j .\nn i,j=1\n\n(1.4)\n\nAs before, \u03c3 is a spin configuration in {\u22121, +1}n, but now the random input is\ngiven in terms of n2 random variables Xij with i, j \u2208 {1, . . . , n}, usually taken to\nbe i.i.d. standard normals. Again E(\u03c3) = E(\u2212\u03c3), leading to N = 2n\u22121 a priori\n\n\f4\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\ndifferent energies E1 \u2264 E2 \u2264 * * * \u2264 EN . Note,\u221ahowever, that the normalization in\n(1.4) corresponds to typical energies of order n and maximal energies of order n,\nin accordance with the standard physics notation.\nConsider an energy scale \u03b1n \u2265 0, and let Er+1 be the first energy above \u03b1n .\nTo obtain the REM approximation for the SK model, we observe that the random\nvariable E(\u03c3) is a Gaussian with density\n2\n1\ne\u2212x /2n .\ng\u0303(x) = \u221a\n2\u03c0n\n\n(1.5)\n\nThe REM approximation for the SK model therefore suggests that the rescaled\nenergy spectrum (Er+1 \u2212 \u03b1n )\u03be \u0303n\u22121 , (Er+2 \u2212 \u03b1n )\u03be \u0303n\u22121 , . . . with rescaling factor\n\u03be \u0303n =\n\n\u221a\n\n\u03b12\nn\n\n2\u03c0n 2\u2212(n\u22121) e 2n\n\n(1.6)\n\nconverges to \u221a\na Poisson process with density one. Recalling that typical energies are\nnow of order n, the local\n\u221a REM conjecture for typical energies in the SK model thus\nclaims that for \u03b1n = O( n), the rescaled energy spectrum converges to a Poisson\nprocess with density one, with overlaps which again tend to zero as n \u2192 \u221e.\nThis conjecture was proved in a very nice paper by Bovier and Kurkova [BK05a].\nIn fact, they proved that the conjecture remains valid as long as \u03b1n = O(n\u03b7 )\nwith \u03b7 < 1. To get some insight into still faster growing \u03b1n , Bovier and Kurkova\nthen considered the generalized random energy model (GREM) of Derrida [Der85].\nFor this model, they proved [BK05b] that the local REM conjecture holds up to\n\u03b1n = \u03b20 n, where \u03b20 is the inverse transition temperature of the GREM, and fails\nonce \u03b1n exceeds this threshold. Based on these results for the GREM, Bovier\nand Kurkova then suggested [BK05c] that the \u03b20 might be the threshold for other\ndisordered spin systems as will.\nAs we will show in this paper, this is not the case, at least not for the SK model,\nfor which we prove that the REM conjecture holds up to the threshold \u03b1n = o(n),\nand becomes invalid as soon as lim sup \u03b1n /n > 0, see Theorem 2.2 below for the\nprecise statement. Thus even the scaling with n of the threshold does not obey the\nnaive expectation derived from the GREM. Note that for the SK model there is no\ndifference between the original REM conjecture and the modified REM conjecture,\nsince the density of E(\u03c3) is Gaussian for all energy scales.\n1.3. Organization of the Paper. This paper is organized as follows. In the next\nsection, we precisely state the assumptions on our model and formulate our main\nresults, see Theorems 2.1 and 2.2. In Section 3, we then describe our main proof\nstrategy for the Npp. Since the proof strategy for the SK model only requires\nminor modifications (the proof is, in fact, much easier), we defer the discussion\nof this model to the last subsection, Section 3.7. The next four sections contain\nthe details of the proof: As a warmup, we start with the Npp with Gaussian\nnoise, where our strategy is most straightforward. Next, in Section 5, we move\nto the Npp with a general distribution. This section contains the meat of our\nproof: the establishment of a large deviations estimate for the probability density\nof several (weakly dependent) random variables. In Section 6 we give the proof of\nTheorem 2.2, and in Section 7 we establish several auxiliary results needed in the\nrest of the paper. We conclude the paper with a section summarizing our results\nand discussing possible extensions, Section 8.\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n5\n\n2. Statement of Results\n2.1. Number Partitioning. Let X1 , ..., Xn be independent random variables distributed according to the common density function \u03c1(x). We assume that \u03c1 has\nsecond moment one and satisfies the bound\nZ \u221e\n|\u03c1(x)|1+\u01eb dx < \u221e\n(2.1)\n\u2212\u221e\n\nfor some \u01eb > 0. Since neither the distribution of the overlaps nor the energy\nspectrum changes if we replace \u03c1(x) by 12 (\u03c1(x)+\u03c1(\u2212x)), we will assume that \u03c1(x) =\n\u03c1(\u2212x). We use the symbol Pn (*) to denote the probability with respect to the joint\nprobability distribution of X1 , ..., Xn , and the symbol En (*) to denote expectations\nwith respect to Pn (*).\nAs in the introduction, we represent the 2n partitions of the integers {1, .., n} as\nspin configurations \u03c3 \u2208 {\u22121, +1}n and define the energy of \u03c3 as in (1.1). Recalling\nthat the distribution of E(\u03c3) does not depend on \u03c3, let gn (*) be the density of\nE(\u03c3), and let \u03ben be the modified scaling factor\n\u03ben =\n\n1\n2n\u22121 g\n\nn (\u03b1n )\n\n.\n\n(2.2)\n\nWe now introduce a continuous time process {Nn (t) : t \u2265 0} where Nn (t) is defined\nas the number of points in the energy spectrum that lie between \u03b1n and \u03b1n + t\u03ben .\nLet E1 , . . . , EN be the increasing spectrum of the energy values corresponding\nto the N = 2n\u22121 distinct partitions. Given \u03b1n \u2265 0, let rn be the random variable\ndefined by Ern < \u03b1n \u2264 Ern +1 . For j > i > 0, we then define the rescaled overlap\nQij as the random variable\n1 X 1/2\nn q(\u03c3, \u03c3\u0303)\n(2.3)\nQij =\n4\n\u03c3,\u03c3\u0303\n\nwhere the sum goes over the four pairs of configurations with E(\u03c3) = Ern +i and\nE(\u03c3\u0303) = Ern +j . Instead of the overlap Qij , we will sometimes consider the following\nvariant: consider two distinct configurations \u03c3 and \u03c3\u0303 chosen uniformly at random\nfrom all pairs of distinct configurations. We then define Qn,t as the rescaled overlap\nn1/2 q(\u03c3, \u03c3\u0303) conditioned on the event that E(\u03c3) and E(\u03c3\u0303) fall into the energy\ninterval [\u03b1n , \u03b1n + t\u03ben ]. We will refer to Qn,t as the overlap between two typical\nconfigurations contributing to Nn (t).\nThe main results of this paper are statements ii) and iii) of the following theorem.\nThe first statement is a corollary of the proof of ii) and iii) and implies that for\n\u03b1n = o(n1/4 ), the original and the modified REM conjecture are equivalent.\nTheorem 2.1. Let X1 , ..., Xn \u2208 R be i.i.d. random variables drawn from a probability distribution with second moment one and even density \u03c1. If \u03c1 obeys the\nassumption (2.1) for some \u01eb > 0 and has a Fourier transform that is analytic in a\nneighborhood of zero, then the following holds:\np\n2\ni) Let gn (*) be the density of E(\u03c3), and let g(\u03b1) = 2/\u03c0e\u2212\u03b1 /2 . If \u03b1n = o(n1/4 ),\nthen gn (\u03b1n ) = g(\u03b1n )(1 + o(1)).\nii) Let \u03b1n = o(n1/4 ), and let j > i > 0 be arbitrary integers not depending on n.\nAs n \u2192 \u221e, the process Nn (t) converges weakly to a Poisson process with density\none, and both Qij and Qn,t converge in distribution to standard normals.\n\n\f6\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\niii) Let \u03b1n = \u03ban1/4 for some finite \u03ba > 0. Then En [Nn (t)] = t + o(1), but the\nprocess Nn (t) does not converge to a Poisson process, and Qn,t does not converge\nto a standard normal.\nIn order to prove the above theorem, we will analyze the factorial moments of\nthe process Zn (t). We will show that for \u03b1n = o(n1/4 ), they converge to those\nof a Poisson process, and for \u03b1n = \u03ban1/4 with \u03ba > 0, they do not converge to\nthe moments of a Poisson process. Together with suitable upper bounds on the\nmoments of Zn (t), this allows us to establish non-convergence to Poisson for \u03ba > 0,\nbut, unfortunately, it does not allow us to establish convergence to some other\ndistribution.\nThe situation is slightly more \"constructive\" for the overlap distribution: here\nwe are able to determine the limiting distribution of Qn,t for \u03b1n = \u03ban1/4 with\n\u03ba > 0. In this regime, the distribution of Qn,t converges to a convex combination of\ntwo shifted Gaussians: with probability 1/2 a Gaussian with mean \u03ba2 and variance\none, and with probability 1/2 a Gaussian with mean \u2212\u03ba2 and variance one, so\nin particular Qn,t is not asymptotically normal. As we will see, this is closely\nconnected to the failure of Poisson convergence; see Remark 4.2 in Section 4 and\nRemark 5.8 in Section 5 below.\n2.2. SK Spin Glass. We consider the SK model with energies given by (1.4) and\nrandom coupling Xij which are i.i.d. standard normals. Let N = 2n\u22121 , and let\nE1 , . . . , EN and \u03c3 (1) , . . . , \u03c3 (N ) be as defined in the introduction.\nGiven an energy scale \u03b1n \u2265 0 and two integers j > i > 0, we again introduce\nQij as the random variable defined in (2.3), with rn given by the condition that\nErn < \u03b1n \u2264 Ern +1 . Finally, we define Nn (t) to be the number of points in the\nenergy spectrum of (1.4) that lie between \u03b1n and \u03b1n + t\u03be \u0303n , with \u03be \u0303n given by (1.6).\nWe say that the local REM conjecture holds if Nn (t) converges weakly to a Poisson\nprocess with density one, and Qij converges in distribution to a standard normal\nfor all j > i > 0.\nOur proofs for the Npp can then be easily generalized to give the following\ntheorem.\nTheorem 2.2. There exists a constant \u01eb0 > 0 such the following statements hold\nfor all sequences of positive real numbers \u03b1n with \u03b1n \u2264 \u01eb0 n:\n(i) E(Nn (t)) \u2192 t as n \u2192 \u221e.\n(ii) The local REM conjecture for the SK model holds if and only if \u03b1n = o(n).\n3. Proof Strategy\nIn this section we describe our proof strategy for Theorems 2.1 and 2.2. We\nexplain our ideas using the example of the Npp, referring to the SK model only in\nthe last subsection, Section 3.7.\n3.1. Factorial moments. Consider a finite family of non-overlapping intervals\n[c1 , d1 ], . . . , [cm , dm ] with dl > cl \u2265 0, and let \u03b3l = dl \u2212 cl . Weak convergence\nof the process {Nn (t) : t \u2265 0} to a Poisson process of density one is equivalent\nto the statement that for each such family, the increments Nn (d1 ) \u2212 Nn (c1 ), . . . ,\nNn (dm ) \u2212 Nn (cm ) converge to independent Poisson random variables with rates\n\u03b31 , . . . , \u03b3m .\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n7\n\nLet Zn (a, b) be the number of point in the energy spectrum that fall into the\ninterval [a, b]. We then rewrite Nn (dl ) \u2212 Nn (cl ) as Zn (aln , bln ), where aln = \u03b1 + cl \u03ben\nand bln = \u03b1 + dl \u03ben , with \u03ben defined in equation (2.2). We prove convergence of\nthe increments to independent Poisson random variables by proving convergence of\nthe multidimensional factorial moments, i.e., by proving the following theorem. To\nsimplify our notation, we will henceforth drop the index n on both the symbol En\nand Pn .\nTheorem 3.1. Let \u03c1 be as in Theorem 2.1, let \u03b1n = o(n1/4 ) be a sequence of\npositive real numbers, let m be a positive integer, let [c1 , d1 ], . . . , [cm , dm ] be a\nfamily of non-overlapping, non-empty intervals, and let (k1 , .., km ) be an arbitrary\nm-tuple of positive integers. For l = 1, . . . , m, set aln = \u03b1n + cl \u03ben , bln = \u03b1n + dl \u03ben ,\nand \u03b3l = dl \u2212 cl . Under these conditions, we have\nm\nm\nY\nY\nlim E[ (Zn (aln , bln ))kl ] =\n\u03b3lkl ,\n(3.1)\nn\u2192\u221e\n\nl=1\n\nl=1\n\nwhere, as usual, (Z)k = Z(Z \u2212 1) . . . (Z \u2212 k + 1).\n\nTheorem 3.1 establishes that {Nn (t) : t \u2265 0} converges to a Poisson process with\ndensity one if \u03b1n = o(n1/4 ). The convergence of the overlaps is an easy corollary to\nthe proof of this theorem. The details are exactly the same as in [BCMN05], and\nwill not be repeated here.\nThe failure of Poisson convergence for faster growing \u03b1n is easiest to explain for\nthe case in which X1 , . . . , Xn are standard normals, since this does not require us\nto distinguish between the original and the modified REM conjectures. Our proof\nis again based on the analysis of the factorial moments of Nn (t).\nMore precisely, we will show that E[Nn (t)] converges to t, while the second\nfactorial moment, E[(Nn (t))2 ] does not converge to t2 . Note that this fact by itself\nis not enough to exclude convergence to a Poisson process since convergence of the\nfactorial moments is, in general, only a sufficient condition for weak convergence to\na Poisson process. But combined with suitable estimates on the growth of the third\nmoment, the fact that E[(Nn (t))2 ] does not converge to t2 is enough. This follows\nfrom the following lemma, which is an easy consequence of a standard theorem on\nuniformly integrable sequences of random variables (see, e.g., Theorem 25.12 and\nits corollary in [Bi94]).\nLemma 3.2. Let Zn \u2265 0 be a sequence of random variables such that E[Znr ] is\nbounded uniformly in n for some r < \u221e. If Zn converges weakly to a Poisson\nrandom variable with rate \u03b3 > 0, then limn\u2192\u221e E[(Zn )k ] = \u03b3 k for all k < r.\nCombined with this lemma, the next theorem establishes the third statement of\nTheorem 2.1 if the weights X1 , . . . , Xn are Gaussian. The proof for non-Gaussian\nweights will be given in Section 5.4.\nTheorem 3.3. Let X\n\u221a1 , ..., Xn \u2208 R be i.i.d. random variables with normal distribution, and let \u03b1n = o( n).\n(i) E[Nn (t)] = t + o(1) for all fixed t > 0.\nPm\n(ii) Let m, aln , bln , \u03b3l , and k1 , .., km be as in Theorem 3.1. For k = l=1 kl \u2265 2,\nwe then have\nm\nm\n\u0010Y\n\u0011 k(k\u22121) 4\nY\n6 \u22122\n(3.2)\nE[ (Zn (aln , bln ))kl ] =\n\u03b3lkl e 4n \u03b1n eO(\u03b1n n )+o(1) .\nl=1\n\nl=1\n\n\f8\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nTheorem 3.3 will be proved in Section 4, and Theorem 3.1 will be proved in\nSection 5. In the remainder of this section, we will map out the general proof\nstrategy, and in the process, establish several properties which will be used in the\nproofs of Theorems 3.1 and 3.3.\n3.2. Analysis of first moment. In order to analyze the first moment we rewrite\nZn (aln , bln ) as\nX\nZn (aln , bln ) =\nI (l) (\u03c3)\n(3.3)\n\u03c3\n\n(l)\n\nwhere I (\u03c3) is 1/2 times an indicator function of the event that the energy E(\u03c3)\nfalls into the interval [aln , bln ] (the factor 1/2 compensates for the fact that the sum\nin (3.3) goes over all configurations \u03c3 \u2208 {\u22121, +1}n, and therefore counts every\ndistinct partition twice). Taking expectations of both sides we see that\n\u0011\n1X \u0010\nP E(\u03c3) \u2208 [aln , bln ] .\n(3.4)\nE[Zn (aln , bln )] =\n2 \u03c3\n\nSince we have taken \u03c1(x) = \u03c1(\u2212x), the distribution of E(\u03c3) is identical for all \u03c3, so\nthat the probability on the right hand side is independent of \u03c3. In order to prove\nthat E[Zn (aln , bln )] = \u03b3l (1 + o(1)), we will therefore want to prove that\n\u0010\n\u0011\nP E(\u03c3) \u2208 [aln , bln ] = 2\u2212(n\u22121) \u03b3l (1 + o(1)).\n(3.5)\nRewriting the left hand side as\n\n\u0011 Z\n\u0010\nP E(\u03c3) \u2208 [aln , bln ] =\n\nbln\n\ngn (y)dy,\n\n(3.6)\n\naln\n\nwhere gn (*) is the density of E(\u03c3) with respect to the Lesbesgue measure on R+ =\n{x \u2208 R : x \u2265 0}, and recalling the definition \u03ben = [2n\u22121 gn (\u03b1n )]\u22121 , we see that the\nbound (3.5) is equivalent to the statement that gn (y) = gn (\u03b1n )(1 + o(1)) whenever\ny = \u03b1n + O(\u03ben ).\nThis\u221abound is easily established\nin the Gaussian case, where it holds as long as\n\u221a\n\u03b1n \u2264 c n for some c < 2 log 2. Indeed, let us write E(\u03c3) as |H(\u03c3)|, where\nn\n\n1 X\n\u03c3i Xi .\nH(\u03c3) = \u221a\nn i=1\n\n(3.7)\n\nIf the random variables X1 , . . . , Xn are standard Gaussians, the random variables\nH(\u03c3) are standard Gaussians as well, implying that E(\u03c3) has density\nr\n2 \u2212y2 /2\ne\n(3.8)\ng(y) =\n\u03c0\n\u221a\nwith respect to\non R+ = {x \u2208 R : x \u2265 0}. If \u03b1n \u2264 c n\n\u221a the Lesbesgue measure\nfor some c < 2 log 2, then \u03ben = o(e\u2212\u01ebn\u221a) for some \u01eb > 0, implying that for y =\n\u03b1n + O(\u03ben ), we have g(y) = g(\u03b1n )(1 + O( n\u03ben )) = g(\u03b1n )(1 + o(1)), as desired. This\n\u221a\nl\nl\nproves (3.5) and\n\u221a hence the bound E[Zn (an , bn )] = \u03b3l (1 + o(1)) provided \u03b1n \u2264 c n\nfor some c < 2 log 2. Note that this already establishes the first moment bound\nstated in Theorem 3.3.\nFor more general distributions, the proof is more complicated since gn (\u03b1n ) is no\nlonger given by a simple formula like (3.8). But given our assumptions on \u03c1, we\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n9\n\n\u221a\nwill be able to show that under the assumption that \u03b1n = o( n), it can be written\nin the form\nr\n2 \u2212nG(\u03b1n n\u22121/2 )\ne\n(1 + o(1))\n(3.9)\ngn (\u03b1n ) =\n\u03c0\nwhere G is an even function which is analytic in a neighborhood of zero and satisfies\nthe bound\nx2\nG(x) =\n+ O(x4 ).\n(3.10)\n2\nThe proof of the representation (3.9) involves an integral representation for gn\ncombined with a steepest descent analysis and will be given in Section 5.2.\nThe bounds (3.9) and (3.10) have several immediate consequences. First, they\nclearly imply that gn (\u03b1n ) = g(\u03b1n )(1 + o(1)) if \u03b1n = o(n1/4 ), proving the first\nstatement \u221a\nof Theorem 2.1. Second, they imply that \u03ben decays exponentially in n\nif \u03b1n = o( n). Using the bounds (3.9) and (3.10) once more, we conclude that\ngn (y) = gn (\u03b1\n\u221an )(1 + o(1) + O(\u03b1n \u03ben )) = gn (\u03b1n )(1 + o(1)) whenever y = \u03b1n + O(\u03ben ).\nFor \u03b1n = o( n), we therefore get convergence of the first moment, E[Zn (aln , bln )] =\n\u03b3l (1 + o(1)), implying in particular that E[Zn (t)] = t + o(1) as claimed in the last\nstatement of Theorem 2.1.\n3.3. Factorial moments as sums over pairwise distinct configurations.\nNext we turn to higher factorial moments. Before\nQm studying these factorial moments, let us consider the standard moments E[ l=1 (Zn (aln , bln ))kl ]. In view of\n(3.3), these P\nmoments can be written as a sum over k configurations \u03c3 (1) , . . . , \u03c3 (k) ,\nm\nwhere k = l=1 kl . As already observed in [BCP01], the factorial moments can\nbe expressed in a similar way, the only difference being that the sum over configurations is now a sum over pairwise distinct configurations, i.e., configurations\n\u03c3 (1) , . . . , \u03c3 (k) \u2208 {\u22121, +1}n such that \u03c3 (i) 6= \u00b1\u03c3(j) for all i 6= j. Explicitly,\nm\ni\nhY\nE\n(Zn (aln , bln ))kl =\nl=1\n\n=\n\n1\n2k\n\nX\n\n\u03c3 (1) ,...,\u03c3 (k) :\n\u03c3 (i) 6=\u00b1\u03c3 (j)\n\nX\n\n\u03c3 (1) ,...,\u03c3 (k) :\n\u03c3 (i) 6=\u00b1\u03c3 (j)\n\nk\ni\nhY\nI (l(j)) (\u03c3 (j) )\nE\nj=1\n\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k ,\n\n(3.11)\n\nwhere the sums run over pairwise distinct configurations and l(j) = 1 if j =\n1, . . . , k1 , l(j) = 2 if j = k1 + 1, . . . , k1 + k2 , and so on. See [BCMN05] for the\n(straightforward) derivation of (3.11).\nIn order to prove convergence of the higher factorial moments, we therefore would\nlike to show that the probability\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j\nQ\nl(j) l(j)\nasymptotically factors into the product j P(E(\u03c3 (j) ) \u2208 [an , bn ]). Unfortunately, this asymptotic factorization does not hold for arbitrary families of distinct\nconfigurations \u03c3 (1) . . . \u03c3 (k) . This problem is already present for \u03b1n that are bounded\nas n \u2192 \u221e (see [BCMN05]), and \u2013 in a milder form \u2013 it is even present for the special\ncase of \u03b1n = 0 treated in [BCP01].\n\n\f10\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\n3.4. Typical and atypical configurations. As in [BCMN05] and [BCP01], it\nis useful to distinguish between \"typical\" and \"atypical\" sets of configurations\n\u03c3 (1) , ..., \u03c3 (k) when analyzing the right hand side of (3.11). To this end, we consider the matrix M formed by the row vectors \u03c3 (1) , . . . , \u03c3 (k) . Given a vector\n\u03b4 \u2208 {\u22121, 1}k , we then define n\u03b4 (\u03c3 (1) , ..., \u03c3 (k) ) as the number of times the column\nvector \u03b4 appears in the matrix M ,\n(1)\n\n(k)\n\nn\u03b4 = n\u03b4 (\u03c3 (1) , ..., \u03c3 (k) ) = |{j \u2264 n : (\u03c3j , ..., \u03c3j ) = \u03b4}|.\n\n(3.12)\n\nIf \u03c3 (1) , . . . , \u03c3 (k) \u2208 {\u22121, +1}n are chosen independently and uniformly at random,\nthen the expectation of n\u03b4 is equal to n2\u2212k for all \u03b4 \u2208 {\u22121, +1}k . By a standard\nmartingale argument, for most configurations,\nthe difference between n\u03b4 and n2\u2212k\n\u221a\nis therefore not much larger than n. More precisely, for any \u03bbn \u2192 \u221e as n \u2192 \u221e,\nall but a vanishing fraction of the configurations \u03c3 (1) , . . . , \u03c3 (k) obey the condition\n\u221a\nn\nmax |n\u03b4 (\u03c3 (1) , ..., \u03c3 (k) ) \u2212 k | \u2264 n \u03bbn n,\n(3.13)\n\u03b4\n2\nsee Lemma 3.9 in [BCMN05] for a proof.\nThe proof of Theorems 3.1 and 3.3 now proceeds in two steps. First, we show that\nthe contribution of the configurations that violate (3.13) is negligible as n \u2192 \u221e, and\nsecond we analyze the configurations satisfying (3.13). It turns out that first part is\nquite complicated and requires distinguishing several sub-classes of configurations,\nbut this analysis has already been carried out in [BCMN05], resulting in bounds\nthat are sharp enough for growing \u03b1n as well. So the only additional work needed\nis a sharp analysis of the typical configurations.\nThe next lemma summarizes the main results from [BCMN05] needed in this\npaper. To state it, we define Rn,k (\u03bbn ) as\n\u0010\n\u0011\nX\u2032\n1\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k , (3.14)\nRn,k (\u03bbn ) = k\n2 (1)\n(k)\n\u03c3\n\n,*** ,\u03c3\n\nwhere the sum runs over pairwise distinct configurations \u03c3 (1) , . . . , \u03c3 (k) that are\neither linearly dependent or violate the bound (3.13). We also use the notation\nqmax = max |q(\u03c3 (i) , \u03c3 (j) )|\ni6=j\n\n(3.15)\n\nfor the maximal off-diagonal overlap of \u03c3 (1) , . . . , \u03c3 (k) .\nLemma 3.4. Let \u03bbn be a sequence of positive numbers.\n(1) Then the number of configurations \u03c3 (1) , ..., \u03c3 (k) that violate the condition\n1 2\n(3.13) is bounded by 2nk 2k+1 e\u2212 2 \u03bbn .\n\u221a\n(2) Assume that both \u03b1n and \u03bbn are of order o( n). Then there are constants\nc, C < \u221e depending only on k, \u03b31 , . . . , \u03b3k , and the sequence \u03bbn , such that\nfor n sufficiently large we have\n\u0001\n2\n2\n1\n(3.16)\nRn,k (\u03bbn ) \u2264 Cnc e 2 k\u03b1n (1+o(1)) \u03ben1/n0 + e\u2212\u03bbn /2 .\nHere n0 = (1 + \u01eb)/\u01eb with \u01eb as in (2.1).\n(3) Let \u03c3 (1) , ..., \u03c3 (k) be an arbitrary set of row vectors satisfying (3.13). Then\n\u03bbn\nqmax \u2264 2k \u221a ,\nn\n\n(3.17)\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n11\n\n\u221a\nand hence for \u03bbn = o( n) and n sufficiently large, we have that \u03c3 (1) , ..., \u03c3 (k)\nare linearly independent.\nProof. Statements (1) and (3) are copied from Lemma 3.8 in [BCMN05], while\nstatement (2) is a consequence of the bounds (3.65) and (3.67) in [BCMN05] and\n1 2\nthe fact that 2n \u03ben = e 2 \u03b1n (1+o(1)) eO(1) , a bound which follows immediately from\n(3.9), (3.10), and the definition (2.2) of \u03ben .\n\u0003\n3.5. Factorization for typical configurations. In view of Lemma 3.4, it will\nbe enough to analyze the expectations on the right hand side of (3.11) for configurations \u03c3 (1) , ..., \u03c3 (k) that satisfy (3.13) and are linearly independent, provided we\n\u221a\n2\nchoose \u03bbn in such a way that \u03b1n = o(\u03bbn ), \u03bbn = o( n) and e\u2212\u03bbn /2 decays faster\nthan any power of n.\nConsider therefore a family of linearly independent configurations satisfying the\ncondition (3.13). The main technical result of this paper is that the following\napproximate factorization statement\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k\n=\n\nk\n\u0010\n\u0011\nY\n2\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] eO(\u03b1n qmax )+o(1)\n\n(3.18)\n\nj=1\n\nis valid whenever n is large enough and \u03c3 (1) , ..., \u03c3 (k) obey the condition (3.13). (For\nthe non-Gaussian\ncase, we will also need that \u03b1n = o(n1/4 ), while the assumption\n\u221a\n\u03b1n = o( n) stated at the beginning of this subsection is enough in the Gaussian\ncase.)\nIf X1 , . . . , Xn are standard normals, the bound (3.18) is quite intuitive and not\nhard to prove. Indeed, let H(\u03c3) be the random variable defined in (3.7), and let\n\u03ba(k) (*) be the joint density of H(\u03c3 (1) ), . . . , H(\u03c3 (k) ). Using the notation x and y\nfor vectors with components x1 , . . . , xk and y1 , . . . , yk , respectively, we then express\nthe joint density of E(\u03c3 (1) ), . . . , E(\u03c3 (k) ) with respect to the Lebesque measure on\nRk+ as\nX\ng (k) (y) =\n\u03ba(k) (x).\n(3.19)\nx1 ,...xk :\nyi =\u00b1xi\n\nIf X1 , . . . , Xn are standard Gaussians, the joint distribution of H(\u03c3 (1) ), . . . , H(\u03c3 (k) )\nis Gaussian as well, with mean zero and covariance matrix\nCij = E[H(\u03c3 (i) )H(\u03c3 (j) )] = q(\u03c3 (i) , \u03c3 (j) ),\nleading to the representation\n\n(3.20)\n\n\u0010 1\n\u0011\n1\n1\n\u22121\n\u221a\nexp\n\u2212\n(x,\nC\nx)\n,\n(3.21)\n2\n(2\u03c0)k/2 det C\nwhenever C P\nis invertible. As usual, C \u22121 denotes the matrix inverse of C, and\n\u22121\n\u22121\n\u22121\n(x, C x) = i,j xi Cij\nxj . Observing that Cij\n= \u03b4ij + O(qmax ), this immediately\nleads to the bound (3.18); see Section 4 for details.\nIn the non-Gaussian case, we do not have an explicit formula for the joint density\nof E(\u03c3 (1) ), . . . , E(\u03c3 (k) ), thus making the proof of the approximate factorization\nformula (3.18) much more difficult. Basically, the proof requires a multi-dimensional\nlocal limit theorem for a case in which the arguments of the probability density\nunder investigation grow with n. In order to prove this local limit theorem, we will\n\u03ba(k) (x) =\n\n\f12\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nuse an integral representation for the probabilities on the left hand side of (3.18)\nand then use a saddle point analysis to prove (3.18). In contrast to [BCMN05] and\n[BCP01], where it was sufficient to analyze the saddle point of the integral in the\noriginal domain of integration, the case with growing \u03b1n considered here requires\na more sophisticated analysis, involving the shift to a complex saddle point in a\ncomplex space of dimension k; see Section 5 for the details.\nLet us close this section by showing how to complete the proof of Theorem 3.1\nonce the bound (3.18) is established. To this end, let us first consider the case\nwhere \u03b1n grows somewhat more slowly than o(n1/4 ), in particular assume that \u03b1n =\no(n1/6 ). Choosing \u03bbn = n1/6 , we then invoke the bound (3.17) from Lemma 3.4\n(3) to conclude that qmax = O(n\u22121/3 ) and \u03b12n qmax = o(1) whenever \u03c3 (1) , ..., \u03c3 (k)\nsatisfy the bound (3.13). For a family of configurations satisfying (3.13), the the\nmultiplicative error term in the joint probability on the right hand side of (3.18) is\ntherefore equal to 1 + o(1), leading to asymptotic factorization of the probabilities\non the right hand side of (3.11). Using Lemma 3.4 (2) to bound the sum over\nfamilies of configurations not satisfying (3.13), and Lemma 3.4 (1) to show that the\nnumber of families of configurations satisfying (3.13) is equal to 2nk (1 + o(1)), this\ngives the bound (3.1) from Theorem 3.1.\nFor still more quickly growing \u03b1n , it is not enough to use the worst case bound\n(3.17). Instead, we would like to use that a typical family of configurations has\nmaximal off-diagonal overlap of order n\u22121/2 . For a typical family of configurations, we therefore get asymptotic factorization as long as \u03b1n = o(n1/4 ). The next\nlemma, to be proved in Section 7, implies that the error term coming from atypical\nconfigurations does not destroy the asymptotic factorization.\nLemma 3.5. Let c > 0, let k be a positive integer, and let \u03b1n be a sequence of\npositive numbers such that \u03b1n n\u22121/4 \u2192 0 as n \u2192 \u221e. If f is a function from the\nset of all families of configurations \u03c3 (1) , . . . , \u03c3 (k) \u2208 {\u22121, +1}n into R such that\n|f (\u03c3 (1) , . . . , \u03c3 (k) )| \u2264 c\u03b12n qmax , then\nX\n(1)\n(k)\n2\u2212nk\nef (\u03c3 ,...,\u03c3 ) = 1 + o(1)\n(3.22)\n\u03c3 (1) ,...,\u03c3 (k)\n\nas n \u2192 \u221e.\n\nWe will now show that Lemmas 3.4 and 3.5 combined with (3.18) and (3.5)\nimmediately imply Theorem 3.1. Indeed, let us choose \u03bbn in such a way that\n\u221a\n2\n\u03b1n = o(\u03bbn ), \u03bbn = o( n) and e\u2212\u03bbn /2 decays faster than any power of n. Invoking\n(3.11) and using Lemma 3.4 (2) to bound the sum over configurations which do not\nsatisfy (3.13) and the bounds (3.18) and (3.5) to approximate the remaining terms\non the right hand side of (3.11), we get the estimate\nm\nk\n\u0011\nhY\ni\n\u0010Y\nX \u2032\u2032\n2\n\u03b3l(i) 2\u2212nk\neO(\u03b1n qmax )+o(1)\n(Zn (aln , bln ))kl = (1 + o(1))\nE\nl=1\n\ni=1\n\n\u03c3 (1) ,...,\u03c3 (k)\n\n(3.23)\nP \u2032\u2032\nwhere the sum\nruns over families of linearly independent configurations \u03c3 (1) ,\n. . . , \u03c3 (k) that satisfy (3.13). Using Lemma 3.4 (1) to extend the sum to a sum\nover all families of configurations \u03c3 (1) , . . . , \u03c3 (k) \u2208 {\u22121, +1}n, we then refer to the\nstatement of Lemma 3.5 to complete the proof of Theorem 3.1.\nThe above considerations also indicate why the asymptotic factorization of the\nfactorial moments fails if \u03b1n grows faster than o(n1/4 ). Indeed, expressing the\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n13\n\n(i)\n(j)\nmatrix elements of C as\n) if i 6= j and q\u0303ij = 0\nij + q\u0303ij where q\u0303ij = q(\u03c3 , \u03c3\nPCij2 = \u03b4P\n\u22121\n2\n2\nif i = j, (x, C x) = j xj \u2212 i6=j xi q\u0303ij xj + O(qmax kxk2 ), where, as usual, kxk2\ndenotes the l2 norm of x. This in turn leads to the more precise estimate\nm\nhY\ni\nE\n(Zn (aln , bln ))kl\nl=1\n\n=\n\nk\n\u0010Y\n\ni=1\n\n\u0011\n\u03b3l(i) 2\u2212nk\n\nX\n\n\u03c3 (1) ,...,\u03c3(k)\n\ne\n\n\u03b12\nn\n2\n\nP\n\n(3.24)\ni6=j\n\n2\nqij +O(\u03b12n qmax\n)+o(1)\n\n+ o(1)\n\n\u03b12 P\nfor the case where X1 , . . . , Xn are standard normals. While the term 2n i6=j qij\nis negligible if \u03b1n = o(n1/4 ), it becomes important as soon as \u03b1n grows like n1/4 or\nfaster, leading to the failure of asymptotic factorization for the factorial moments.\nThe details are straightforward but a little tedious and are given in Section 4 for\nthe Gaussian case, and in Section 5.4 for the non-Gaussian case.\n\n3.6. Integral representation. As discussed in the preceding subsections, the convergence of the factorial moments of Zn reduces to the proof of the approximate\nfactorization formula (3.18). Following a strategy that was already used in [BCP01]\nand [BCMN05], our proof for the case where X1 , . . . , Xn are not normally distributed uses an integral representation for the probabilities on the left hand side\nof (3.18).\nTo derive this integral representation we first express the indicator function\nI (l) (\u03c3) in terms of the function rect(x) defined to be 1 if |x| \u2264 1/2 and 0 otherwise. Using Fourier inversion and the fact that the Fourier transform of the\nfunction rect(x) is equal to sinc(f ) = sin\u03c0f\u03c0f this leads to the representation\nI\n\n(l)\n\n(\u03c3) = qn,l\n\nZ\n\n\u221e\n\n\u2212\u221e\n\nPn\n\u221a\nsinc(f qn,l ) cos(2\u03c0f tln n)e2\u03c0if s=1 \u03c3s Xs df,\n\n(3.25)\n\nl\nl\nl\nl\nl\nwhere\n\u221a tn = (an + bn )/2 denotes the center of the interval [an , bn ], and qn,l =\n\u03b3l \u03ben n. Taking the expectation of both sides of (3.25) and exchanging the expectation and the integral on the right hand side (the justification of this exchange is\ngiven by Lemma 3.2 in [BCMN05]), we get the representation\n\n\u0010\n\u0011\nP E(\u03c3) \u2208 [aln , bln ] = 2E[I (l) (\u03c3)]\nZ \u221e\n\u221a\n= 2qn,l\nsinc(f qn,l ) cos(2\u03c0f tln n)\u03c1\u0302n (f )df\n\n(3.26)\n\n\u2212\u221e\n\nwhere \u03c1\u0302(f ) = E[e2\u03c0if X ] is the Fourier transform of \u03c1.\nWhen deriving an integral representation for the terms on the right hand side\nof (3.11), we will have to take the expectation of a product of integrals of the\nform (3.25). Neglecting, for the moment, problems associated with the exchange of\nintegrations and expectations, this is not difficult. Indeed, rewriting the product of\n\n\f14\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nintegrals as\nk Z\nY\nj=1\n\n\u221e\n\n\u2212\u221e\n\n=\n\nPn\n\u221a\nsinc(fj qn,l(j) ) cos(2\u03c0fj tnl(j) n)e2\u03c0ifj s=1 \u03c3s Xs dfj\n\nZZZ\n\n\u221e\n\nn\nY\n\ne2\u03c0ivs Xs\n\n\u2212\u221e s=1\n\nk\nY\n\n(3.27)\n\n\u221a\nsinc(fj qn,l(j) ) cos(2\u03c0fj tnl(j) n)dfj\n\nj=1\n\nwhere\nvs =\n\nk\nX\n\n\u03c3s(j) fj ,\n\n(3.28)\n\nj=1\n\nand taking expectations of both sides, we easily arrive at the representation\nm\n\u0010\n\u0011 Y\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k =\n(2qn,l )kl\nl=1\n\n\u00d7\n\nZZZ\n\n\u221e\n\nn\nY\n\n\u03c1\u0302(vs )\n\n\u2212\u221e s=1\n\nk\nY\n\nsinc(fj qn,l(j) ) cos(2\u03c0fj tnl(j)\n\n\u221a\nn)dfj .\n\n(3.29)\n\nj=1\n\nBut here a little bit more care is needed to justify the exchange of expectation and\nintegrals. Indeed, this exchange can only be justified if \u03c3 (1) , . . . , \u03c3 (k) are linearly\nindependent (see Lemma 3.5 in [BCMN05]), but luckily, this will be all we need.\n3.7. The SK Model. As in the proof for the Npp, we define Zn (a, b) to be the\nnumber of points in the energy spectrum that fall into the interval [a, b], where the\nenergy of a configuration \u03c3 is now given by (1.4). Given a family of non-overlapping\nintervals [c1 , d1 ], . . . , [cm , dm ] with cl \u2265 0, and dl = cl + \u03b3l > cl for l = 1, . . . , m,\nwe now consider the intervals [aln , bln ] with aln = \u03b1 + cl \u03be\u0303n and bln = \u03b1 + dl \u03be \u0303n , where\n\u03be \u0303n is defined in (1.6). Theorem 2.2 now follows immediately from the following two\ntheorems.\nTheorem 3.6. Let \u03b1n = o(n) be a sequence of positive real numbers, let m be a\npositive integer, and for l = 1, . . . , m, let aln and bln be as above. For an arbitrary\nm-tuple of positive integers (k1 , .., km ) we then have\nlim E[\n\nn\u2192\u221e\n\nm\nY\n\n(Zn (aln , bln ))kl ] =\n\nl=1\n\nm\nY\n\n\u03b3lkl .\n\n(3.30)\n\nl=1\n\nTheorem 3.7. There exists a constant \u01eb0 > 0 such the following statements hold\nfor all c \u2265 0 and \u03b3 > 0, all sequences of positive real numbers \u03b1n with \u03b1n \u2264 \u01eb0 n,\nand an , bn of the form an = \u03b1n + c\u03be \u0303n , bn = \u03b1n + (c + \u03b3)\u03be \u0303n .\n(i) limn\u2192\u221e E[Zn (an , bn )] = \u03b3.\n(ii) E[(Zn (an , bn ))3 ] is bounded uniformly in n.\n(iii) If lim sup \u03b1nn > 0, then lim supn\u2192\u221e E[(Zn (a, b))2 ] > \u03b3 2 .\nBy now, the proof strategy for these theorems is straightforward: As before, the\nfirst moment is given as an integral over the energy density. For the SK model, this\ndensity is given by(1.5), leading to E[Zn (aln , bln )] = \u03b3l (1+o(1)) as long as \u03be\u0303n = o(1).\nTo analyze the higher factorial moments, we again use a representation of the form\n(3.11). Neglecting for the moment the issue of bounding the sum over atypical\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n15\n\nconfigurations, we will again study the factorization properties of probabilities of\nthe form\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k .\n(3.31)\n\nFor the SK model, this is even easier than for the Npp with Gaussian noise, since\nE(\u03c3) is now itself a Gaussian random variable, rather than the absolute value of a\nGaussian. The joint distribution of E(\u03c3 (1) ), . . . , E(\u03c3 (k) ) therefore has density\n\u0011\n\u0010 1\n1\n1\n\u22121\n\u221a\ng\u0303 (k) (x) =\n(x,\nC\nx)\n,\n(3.32)\nexp\n\u2212\n2\n(2\u03c0)k/2 det C\nwhere C is the covariance matrix\n\nCij = E[E(\u03c3 (i) )E(\u03c3 (j) )] = n(q(\u03c3 (i) , \u03c3 (j) ))2 .\n\u22121\nCij\n\n\u22121\nCij\n\n1\nn (\u03b4ij\n\n(3.33)\n\n2\nO(qmax\n)),\n\n+\nwe then get the following analogue of\nExpanding\nas\n=\nthe factorization formula (3.18):\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k\n=\n\nk\n\u0010\n\u0011\nY\n2 \u22121 2\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] eO(\u03b1n n qmax )+o(1) .\n\n(3.34)\n\ni=1\n\nIn the exponent of the above expression, note that the additional factor of n\u22121\nrelative to the analogous expression for the Npp is simply a consequence of the\ndifferent normalizations of the energies. The more significant difference is the factor\n2\nof qmax\nrather than qmax , a consequence of the difference between the covariance\nmatrices for the two problems. For typical configurations with overlap qmax =\nO(n\u22121/2 ), equation (3.34) suggests that there will be asymptotic factorization if\nand only if \u03b1n = o(n). That this is indeed the case is established in Section 6.\n4. The Npp with Gaussian densities\nIn this section we analyze the factorization properties of the probabilities\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for j = 1, . . . , k\n(4.1)\n\nfor the case where X1 , . . \u221a\n. , Xn are standard normals. Throughout this section, we\nwill assume that \u03b1n = o( n).\nIn a preliminary step, we show that it is possible to approximate the joint density\ng (k) (y) of E(\u03c3 (1) ), . . . , E(\u03c3 (k) ) by its value at yi = \u03b1n . To this end we combine\nthe representations (3.19) and (3.21) with the fact that C \u22121 is bounded uniformly\nl(i) l(i)\nin n if qmax = o(1). For yi \u2208 [an , bn ], we then have\ng (k) (y) = g (k) (\u03b1n )(1 + O(\u03b1n \u03ben ) + O(\u03ben2 )) = g (k) (\u03b1n )(1 + o(1)),\n\n(4.2)\n\nimplying that\nm\n\u0010\n\u0011 \u0010Y\n\u0011\n(\u03ben \u03b3l )kl g (k) (\u03b1n )(1 + o(1)).\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for j = 1, . . . , k =\nl=1\n\n(4.3)\nHaving established this approximation, we now proceed to prove the factorization\nformula (3.18).\n\n\f16\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\n4.1. Proof of the factorization formula (3.18). Let us express the right hand\nside of (4.3) as a sum over vectors x \u2208 Rk with |xi | = \u03b1n , see (3.19). Recalling the\nrepresentation (3.21), we expand (x, C \u22121 x) as (x, C \u22121 x) = kxk22 (1 + O(qmax )) =\nk\u03b12n +O(qmax \u03b12n ), where, as before, kxk2 denotes the l2 -norm of x. For qmax = o(1),\nwe further have det C = 1 + o(1), implying that\n\u0010 2 \u0011k/2 k 2\n2\n2\n(4.4)\ng (k) (\u03b1n ) =\ne\u2212 2 \u03b1n +O(qmax \u03b1n )+o(1) = (g(\u03b1n ))k eO(qmax \u03b1n )+o(1) .\n\u03c0\n\u0010\n\u0011\nRecalling the approximation P E(\u03c3) \u2208 [aln , bln ] = g(\u03b1n )\u03b3l \u03ben (1 + o(1)) established\nin Section 3.2, the bounds (4.3) and (4.4) imply the approximate factorization\nformula (3.18). Note\n\u221a that the only conditions needed in this derivation were the\nconditions \u03b1n = o( n) and qmax = o(1). Taking into account Lemma 3.4 (iii), we\n\u221a\n(1)\n(k)\ntherefore have established that (3.18) holds whenever\n\u221a \u03b1n = o( n) and \u03c3 , ..., \u03c3\nobey the condition (3.13) for some \u03bbn of order o( n).\nAs shown in Section 3.5, the approximate factorization formula (3.18) immediately leads to Poisson convergence if \u03b1n = o(n1/4 ). To establish that this convergence fails for faster growing \u03b1n , requires a little bit more work. This is done in\nthe next subsection.\n4.2. Proof of Theorem 3.3. We start again from (4.3), but this time we expand\nthe inverse of C a little further. Explicitly, expressing the matrix elements of C as\nCij = \u03b4ij + q\u0303ij where q\u0303ij = q(\u03c3 (i) , \u03c3 (j) ) if i 6= j and q\u0303ij = 0 if i = j, we clearly have\nX\nX\n2\nx2j \u2212\nxi q\u0303ij xj + O(qmax\nkxk22 )\n(x, C \u22121 x) =\nj\n\n=\n\ni6=j\n\nk\u03b12n\n\n\u2212\n\nX\n\n2\nxi q\u0303ij xj + O(qmax\n\u03b12n )\n\n(4.5)\n\ni6=j\n\nwhenever qmax = o(1) and |xi | = \u03b1n for all i. With the help of (4.3), (1.3), (3.19)\nand (3.21), this implies that\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for j = 1, . . . , k\n=\n\nm\n\u0010Y\n\nl=1\n\n\u0011\n\u03b3lkl 2\u2212nk\n\n\u0011\n\u00101 X\n2\nxi q\u0303ij xj + O(qmax\n\u03b12n ) + o(1) .\nexp\n2\nx1 ,...xk :\nX\n\n(4.6)\n\ni6=j\n\nxi =\u00b1\u03b1n\n\n\u221a\n2\nLet us now choose \u03bbn in such a way that \u03b1n = o(\u03bbn ), \u03bbn = o( n) and e\u2212\u03bbn /2\ndecays faster than any power of n. Combining (4.6) with the representation (3.11)\nand Lemma 3.4 (2), we then have\nk\nm\n\u0011\ni \u0010Y\nhY\n\u03b3l(i) 2\u2212nk\n(Zn (aln , bln ))kl =\nE\ni=1\n\nl=1\n\nX \u2032\u2032\n\n\u03c3(1) ,...,\u03c3(k)\n\n2\u2212k\n\n\u0011\n\u00101 X\n2\nxi q\u0303ij xj + O(qmax\n\u03b12n ) + o(1) + o(1)\nexp\n\u00d7\n2\nx1 ,...xk :\nX\n\nxi =\u00b1\u03b1n\n\n(4.7)\n\ni6=j\n\nP \u2032\u2032\nwhere the sum\nruns over families of linearly independent configurations \u03c3 (1) ,\n(k)\n. . . , \u03c3 that satisfy (3.13). Next we claim that we can extend this sum to a sum\nover all families of configurations \u03c3 (1) , . . . , \u03c3 (k) at the cost of an additional additive error o(1). Indeed, by Lemma 3.4 (1) and (3), the number of configurations\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n17\n\n\u03c3 (1) , . . . , \u03c3 (k) that are linearly dependent or violate the bound (3.13) is bounded\n2\nby a constant times 2nk e\u2212\u03bbn /2 . Since the terms in the above sum are all bounded\nP \u2032\u2032\n2\n2\nby eO(\u03b1n ) = eo(\u03bbn ) , the extension from the sum\nto a sum over all families of\nconfigurations \u03c3 (1) , . . . , \u03c3 (k) indeed\nonly\nintroduces\nan additive error o(1). ObP\nserving finally that the exponent i6=j xi q\u0303ij xj is invariant under the transformation\nxi \u2192 |xi | = \u03b1n and \u03c3 (i) \u2192 sign(xi )\u03c3 (i) , we obtain the approximation (3.24), which\nwe restate here as\nm\ni\nhY\nE\n(Zn (aln , bln ))kl\nl=1\n\n=\n\nk\n\u0010Y\n\ni=1\n\n\u0011\n\u03b3l(i) 2\u2212nk\n\nX\n\n\u03c3 (1) ,...,\u03c3\n\n\u0011\n\u0010 \u03b12 X\n2\nq\u0303ij + O(qmax\n\u03b12n ) + o(1) + o(1).\nexp n\n2\n(k)\ni6=j\n\n(4.8)\nWith the approximation (4.8) in hand, the second statement of Theorem 3.3 now\nfollows immediately from the following lemma.\nLemma 4.1. Let C < \u221e, let \u03b2n = o(n), let Ek denote expectation with respect to\nthe uniform measure on all families of configurations \u03c3 (1) , . . . , \u03c3(k) , and let R de2\nnote a function on families of configurations such that |R(\u03c3 (1) , . . . , \u03c3 (k) )| \u2264 Cqmax\n.\nThen\nh\n\u0010 \u0010X\n\u0011\u0011i\n\u0010 k(k \u2212 1)\n\u0011\nq\u0303ij + R\n= exp\nEk exp \u03b2n\n\u03b2n2 + O(\u03b2n3 n\u22122 ) + o(1) .\nn\n\n(4.9)\n\ni6=j\n\nProof. The complete proof of the lemma will be given in Section 7.2. Here we only\nshow that the leading term behaves as claimed, namely\n\u0010 k(k \u2212 1)\nh\n\u0010 X \u0011i\n\u0011\nq\u0303ij = exp\nEk exp \u03b2n\n\u03b2n2 + O(\u03b2n3 n\u22122 ) .\n(4.10)\nn\ni6=j\n\nTo this end, we observe that\nX\ni6=j\n\nq\u0303ij =\n\nX\ni,j\n\n1 X\u0010X (i) \u00112\n\u03c3\n\u2212 k.\nn s=1 i=1 s\nn\n\nq(\u03c3 (i) , \u03c3 (j) ) \u2212 k =\n\nk\n\nAs a consequence, we have\nk\nn\n\u00112 \u0011i\nhY\n\u0010 \u03b2 \u0010X\ni\nh\nP\nn\n\u03c3s(i)\nexp\nEk e\u03b2n i6=j q\u0303ij = e\u2212k\u03b2n Ek\nn i=1\ns=1\nk\nh\n\u0010 \u03b2 \u0010X\n\u00112 \u0011in\nn\n= e\u2212k\u03b2n \u1ebck exp\n,\n\u03b4i\nn i=1\n\n(4.11)\n\n(4.12)\n\nwhere \u1ebck denotes expectation with respect to the uniform measure on all configurations \u03b4 = (\u03b41 , . . . , \u03b4k ) \u2208 {\u22121, +1}k . Next we expand the expectation on the right\nhand side into a power series\nP Using\nP in \u03b2n /n (recall that we assumed \u03b2n = o(n)).\nthat the expectation of ( i \u03b4i )2 is equal to k, while the expectation of ( i \u03b4i )4 is\nequal to 3k 2 \u2212 2k, this gives\nk\nh\n\u0010 \u03b2 \u0010X\n\u0011\n\u00112 \u0011i\n\u0010\u03b2\n\u03b22\nn\nn\n\u1ebck exp\n\u03b4i\nk + n2 k(k \u2212 1) + O(\u03b2n3 n\u22123 )\n(4.13)\n= exp\nn i=1\nn\nn\n\n\f18\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nand hence\n\u0011\ni\n\u0010 k(k \u2212 1)\nh\nP\n\u03b2n2 + O(\u03b2n3 n\u22122 ) .\nEk e\u03b2n i6=j q\u0303ij = exp\nn\n\n(4.14)\n\u0003\n\nRemark 4.2. For the special case where \u03b1n grows like n1/4 , Theorem 3.3 implies that\nthe density of the process Nn (t) converges to one, while the process itself does not\nconverge to Poisson. Another interesting consequence of our proof is the following:\nConsider the rescaled overlap Qn,t of two typical configurations contributing to\nNn (t) (see Section 2.1 for the precise definition of Qn,t ). Then Qn,t converges in\ndistribution to the superposition of two Gaussians with mean \u00b1\u03ba2 , where \u03ba =\nlimn\u2192\u221e \u03b1n n\u22121/4 ,\n2 2\n1\nZ \u221e \u2212 1 (x\u2212\u03ba2 )2\n1 1\n+ e\u2212 2 (x+\u03ba )\ne 2\nlim P(Qn,t \u2265 y) = \u221a\ndx.\n(4.15)\nn\u2192\u221e\n2 2\u03c0 y\n2\nThis follows again from (4.6); in fact, now we only need this formula for k = 2,\nwhere the sum over x just gives a factor cosh(\u03b12n q(\u03c3, \u03c3\u0303)). This factor is responsible\nfor the shift of \u00b1\u03ba2 in the limiting distribution of Qn,t = n1/2 q(\u03c3, \u03c3\u0303).\n5. The Npp with general distribution\nIn this section we prove the first moment estimate (3.5) and the factorization\nformula (3.18) for arbitrary distributions \u03c1 obeying the assumptions of Theorem 2.1,\nsee Propositions 5.2 and 5.6 below. As discussed in Section 3, this immediately gives\nTheorem 3.1. We also show in Section 5.4 how the proof of non-convergence can\nbe generalized from the Gaussian case to the general distributions considered in\nTheorem 2.1.\n5.1. Properties of the Fourier transform. Throughout this section, we will\nuse several properties of the Fourier transform in \u03c1\u0302 which we summarize in this\nsubsection.\n1\n+ n1o = 1 with \u01eb as in (2.1),\n(i) For any n \u2265 no , where n0 is the solution of 1+\u01eb\nwe have\nZ \u221e\nZ \u221e\nn\n(5.1)\n|\u03c1\u0302(f )| \u2264\n|\u03c1\u0302(f )|n0 = C0 < \u221e.\n\u2212\u221e\n\n\u2212\u221e\n\n(ii) There exists \u03bc0 > 0 such that \u03c1\u0302(f ) is analytic in the region |Imf | < \u03bc0 .\n(iii) For any \u03bc1 > 0 there exists c1 > 0 and \u03bc2 > 0 and such that\n|\u03c1\u0302(f )| \u2264 e\u2212c1\nwhenever |Imf | \u2264 \u03bc2 and |Ref | \u2265 \u03bc1 .\n\n(5.2)\n\nThese properties easily follow from our assumptions on the density \u03c1. The bound\n(5.1) is a direct consequence of (2.1). Analyticity of \u03c1\u0302 in a neighborhood of the\norigin implies existence of exponential moments and this in turn implies analyticity\nin a strip about the real line. To see that the bound (5.2) is true, we first observe\nthat it obviously holds when f is real. From the fact that d\u03c1\u0302(z)/dz is bounded\nuniformly in z as long as the imaginary part of z is small enough, we can choose\n\u03bc2 in such a way that the bound (5.2) extends to |Imf | \u2264 \u03bc2 (with c1 replaced by\na slightly smaller constant, which we again call c1 ).\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n19\n\n5.2. First Moment. In this section we establish the representation (3.9) for the\ndensity gn (*), see Proposition 5.2 below. As explained in Section 3.2,\u221athis representation immediately give the first moment estimate (3.5) for \u03b1n = o( n).\nWe will start from the integral representation\nZ \u221e\n\u221a\n\u221a\ngn (\u03b1) = 2 n\ncos(2\u03c0f \u03b1 n)\u03c1\u0302n (f )df,\n(5.3)\n\u2212\u221e\n\nThis formula can easily be derived by first expressing the density of H(\u03c3) in terms\nof the n-fold convolution of \u03c1 with itself, using Fourier inversion to express this\ndensity as an integral over \u03c1\u0302n , and then summing over the two possible choices for\nthe sign of H(\u03c3) given E(\u03c3) (alternatively, the formula can be derived from (3.26)\nby sending \u03b3l to 0).\nIn order to determine the asymptotic behavior of gn (\u03b1), one might want to\nexpand \u03c1\u0302n (f ) about its maximum, i.e. about f = 0. While this strategy works well\nfor bounded \u03b1n , it needs to be modified in the case of growing \u03b1n . Here we will\nuse the method of steepest descent, a method which was first introduced into the\nanalysis of density functions by a paper of Daniels [Dan54], though of course the\nideas go back to Laplace.\nBefore explaining this further, let us first note that, asymptotically, the integral\nin (5.3) can be restricted to a bounded interval about zero. Indeed, let \u03bc1 > 0 be\nan arbitrary constant, let \u03bc2 be as in (5.2), and let n0 be as in (5.1). For n \u2265 n0\nand |f | \u2265 \u03bc1 , we then have |\u03c1\u0302n (f )| \u2264 |\u03c1\u0302n0 (f )|e\u2212c1 (n\u2212n0 ) . As a consequence, the\ncontribution\nto the integral (5.3) from the region |f | \u2265 \u03bc1 is bounded by a constant\n\u221a\ntimes ne\u2212c1 n , giving the estimate\nZ \u03bc1\n\u221a\n\u221a\n\u221a\ncos(2\u03c0f \u03b1 n)\u03c1\u0302n (f )df + O( ne\u2212c1 n ).\ngn (\u03b1) = 2 n\n(5.4)\n\u2212\u03bc1\n\nNext we observe that both the range of integration and the function f 7\u2192 \u03c1\u0302(f ) are\ninvariant under the change f \u2192 \u2212f , implying that we can rewrite the integral as\nZ \u03bc1\nZ \u03bc1\n\u221a\n\u03b1n\n\u221a\n\u221a\n\u2212n(F (f )\u22122\u03c0i \u221a\nf)\nn\ne2\u03c0if \u03b1n n \u03c1\u0302n (f )df = 2 n\ne\ndf\n(5.5)\n2 n\n\u2212\u03bc1\n\n\u2212\u03bc1\n\nwhere F (f ) is defined by\n\n\u03c1\u0302(f ) = e\u2212F (f ) .\n(5.6)\nAs defined earlier, let \u03bc0 be such that \u03c1\u0302(f ) is analytic in the region |Imf | < \u03bc0 .\nFurther let 0 < \u03b7 \u2264 \u03bc0 , and let C be the path in the complex plane obtained\nby concatenating the three line segments that join the point \u2212\u03bc1 to the point\n\u2212\u03bc1 + i\u03b7, the point \u2212\u03bc1 + i\u03b7 to the point \u03bc1 + i\u03b7, and the point \u03bc1 + i\u03b7 to the\npoint \u03bc1 , respectively. Let G be the region bounded by C and the line segment\nfrom \u2212\u03bc1 to \u03bc1 . Then the function f 7\u2192 \u03c1\u0302(f ) and hence the integrand in (5.5) is\nanalytic in G, implying that the integral on the right hand side of (5.5) is equal to\nthe integral over C. Our next lemma states that the contribution of the first and\nthird line segment to this integral is negligible, effectively allowing us to \"shift the\npath of integration\" into a parallel line segment in the complex plane.\nLemma 5.1. Given \u03bc1 > 0, there are constants c1 > 0 and \u03bc2 > 0 such that\nZ \u03bc1 +i\u03b7\n\u03b1n\n\u221a\n\u221a\nf)\n\u2212n(F (f )\u22122\u03c0i \u221a\nn\ngn (\u03b1n ) = 2 n\ndf + O( ne\u2212c1 n )\ne\n(5.7)\n\u2212\u03bc1 +i\u03b7\n\nprovided \u03b1n \u2265 0 and 0 \u2264 \u03b7 \u2264 \u03bc2 .\n\n\f20\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nProof. Taking into account (5.4), we need to analyze the integral on the right of\n(5.5) which in turn is equal to the integral over the path C defined above, provided\nwe choose \u03bc2 \u2264 \u03bc0 .\nConsider the integral\nZ \u2212\u03bc1 +i\u03b7\n\u03b1n\nf)\n\u2212n(F (f )\u22122\u03c0i \u221a\nn\ndf.\n(5.8)\ne\n\u2212\u03bc1\n\nFor f in the line segment joining \u2212\u03bc1 to \u2212\u03bc1 + i\u03b7, the imaginary part of f is\n\u03b1n\n2\u03c0in \u221a\nf\nn | \u2264 1. Due to property (5.2) of the Fourier\nnon-negative, implying that |e\ntransform \u03c1\u0302, we furthermore have that |\u03c1\u0302(f )| = |e\u2212F (f ) | \u2264 e\u2212c1 on this line segment.\nAs a consequence, the above integral is bounded by \u03b7e\u2212c1 n = O(e\u2212c1 n ). In a similar\nway, the integral over the third line \u221a\nsegment is bounded by O(e\u2212c1 n ). Taking into\naccount the multiplicative\n\u221a factor of n in (5.4) and the fact that the error term in\n(5.4) is bounded by O( ne\u2212c1 n ), this proves (5.7).\n\u0003\nNote that the above lemma holds for arbitrary \u03b7 \u2265 0. As usual when applying\nthe method of steepest descent, the value of \u03b7 will be chosen in such a way that\nthe asymptotic analysis of the integral on the right becomes as simple as possible.\nHere this amounts to requiring that at f = i\u03b7, the first derivative of the integrand\nis zero. In other words, we will choose \u03b7 as the solution of the equation\n\u03b1n\nF \u2032 (i\u03b7) = 2\u03c0i \u221a ,\n(5.9)\nn\nwhere F \u2032 (z) = dFdz(z) denotes the complex derivative of F . This leads to the following proposition.\nProposition 5.2. There is an even function G(x) which is real analytic in a neighborhood of zero such that\nr\n2 \u2212nG(\u03b1n n\u22121/2 )\ngn (\u03b1n ) =\ne\n(1 + o(1))\n(5.10)\n\u03c0\n\u221a\nwhenever \u03b1n = o( n). In a neighborhood of zero, G(x) can be expanded as\nx2\n+ O(x4 ).\n2\n\u221a\nFor \u03b1n = o( n) and aln , bln and \u03b3l as in Theorem 3.1 we therefore have\n\u0010\n\u0011\nP E(\u03c3) \u2208 [aln , bln ] = 2\u2212(n\u22121) \u03b3l (1 + o(1)).\nG(x) =\n\n(5.11)\n\n(5.12)\n\nProof. We first argue that the equation (5.9)\u221ahas a unique solution which can be\nexpressed as an analytic function of x = \u03b1n / n. Consider thus the equation\nF \u2032 (i\u03b7) = 2\u03c0ix.\n\n(5.13)\n\nSince \u03c1\u0302 is an even function which is analytic in a neighborhood of zero with \u03c1\u0302(0) = 1,\nthe function F is even and analytic in a neighborhood of zero as well. Taking into\naccount that the second moment of \u03c1 is one, we now expand F (f ) as\n1\n(2\u03c0f )2 + O(f 4 )\n2\n\n(5.14)\n\nF \u2032 (f ) = (2\u03c0)2 f + O(f 3 ).\n\n(5.15)\n\nF (f ) =\nand F \u2032 (f ) as\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n21\n\nBy the implicit function theorem, the equation (5.13) has a unique solution \u03b7(x) in\na neighborhood of zero, and \u03b7(x) is an analytic function of x. Taking into account\nthat F \u2032 is odd, we furthermore have that \u03b7(x) is an odd function which is real\n1\nx + O(x3 ) we\nanalytic in a neighborhood of zero, and expanding \u03b7(x) as \u03b7(x) = 2\u03c0\nsee that \u03b7(x) \u2265 0 if x \u2265 0 is sufficiently small.\nHaving established the existence and uniqueness of \u03b7(x) for small enough\nx, we\n\u221a\nare now ready to analyze the integral in (5.7) for \u03b7 = \u03b7(x) and x = \u03b1n / n = o(1).\nTo this end, we rewrite the integral as\nZ \u03bc1\nZ \u03bc1\n\u0001\ne\u2212nF\u0303 (f ) df\ne\u2212n F (i\u03b7(x)+f )+2\u03c0x(\u03b7(x)\u2212if ) df = e\u2212nG(x)\n(5.16)\nwhere\n\n\u2212\u03bc1\n\n\u2212\u03bc1\n\nG(x) = F (i\u03b7(x)) + 2\u03c0x\u03b7(x),\n\n(5.17)\n\nand\nF\u0303 (f ) = F (i\u03b7(x) + f ) \u2212 F (i\u03b7(x)) \u2212 2\u03c0ixf.\n(5.18)\nNext we would like to show that the integral on the right hand side of (5.16) can\n\u221a\nbe restricted to |f | \u2264 log n/ n. To this end, we expand F\u0303 (f ) about f = 0. Taking\ninto account the fact that the first derivative at f = 0 vanishes by the definition of\n\u03b7(x), we get\n1\n1\n(5.19)\nF\u0303 (f ) = F (2) (i\u03b7(x))f 2 + F (3) (i\u03b7(x))f 3 + O(f 4 ).\n2\n6\nUsing again that F is an even function of its argument, we conclude that F (2) (i\u03b7(x))\nis real, while F (3) (i\u03b7(x)) is purely imaginary, so that\n1\n(5.20)\nRe F\u0303 (f ) = F (2) (i\u03b7(x))f 2 + O(f 4 ).\n2\nSince \u03b7(x) = O(x) = o(1) and F (2) (i\u03b7(x)) = 4\u03c0 2 + O(\u03b7(x)2 ), we have that\nRe F\u0303 (f ) \u2265 f 2 provided \u03bc1 is sufficiently small and n is sufficiently large. As a\nconsequence, we get that\nZ n\u22121/2 log n\nZ \u03bc1\n\u0011\n\u0010 1\n2\n\u2212nF\u0303 (f )\n(5.21)\ne\ndf =\ne\u2212nF\u0303 (f ) df + O \u221a e\u2212 log n .\nn\n\u2212n\u22121/2 log n\n\u2212\u03bc1\n\u221a\nFor |f | \u2264 log n/ n, we now expand\n\u0011\n\u0010 n\ne\u2212nF\u0303 (f ) = exp \u2212 F (2) (i\u03b7(x))f 2 + O(nf 3 )\n2\n\u0011\u0010\n\u0011\n(5.22)\n\u0010 n\n= exp \u2212 F (2) (i\u03b7(x))f 2 1 + O(nf 3 ) ,\n2\nleading to the approximation\ns\nZ n\u22121/2 log n\n\u0001\n\u0001\n1\n2\u03c0\n\u2212nF\u0303 (f )\n1 + O(n\u22121/2 ) = \u221a\ne\ndf =\n1 + o(1) .\n(2)\nnF (i\u03b7(x))\n2\u03c0n\n\u2212n\u22121/2 log n\n(5.23)\nCombined with (5.7), (5.16) and (5.21) this proves (5.10).\nNext, we show that G(x) is an even function which is real analytic in a neighborhood of zero and obeys the bound (5.11). But this is almost obvious by now.\nIndeed, combining the fact that F is an even function which is real analytic in\na neighborhood of zero with the fact that \u03b7(x) is an odd function which is real\nanalytic in a neighborhood of zero, we see that G(x) is an even function which is\n\n\f22\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nreal analytic in a neighborhood of zero. With the help of (5.14), the bound (5.11)\n1\nx + O(x3 ) into the definition\nfinally follows by inserting the expansion \u03b7(x) = 2\u03c0\n(5.17) of G.\nAs we already argued in Section 3.2, the bound (5.12) finally follows immediately\nfrom the remaining statements of the proposition.\n\u0003\n5.3. Higher Moments. In order to establish convergence of the higher factorial\nmoments, we start from the integral representation (3.29). Recalling the definition\n(3.12), let\nnmin = nmin (\u03c3 (1) , ..., \u03c3 (u) ) = min{n\u03b4 : \u03b4 \u2208 {\u22121, +1}u}.\n\n(5.24)\n\nIn a first step, we show that under the condition that nmin \u2265 n0 where n0 is the\n1\nsolution of 1+\u01eb\n+ n1o = 1 with \u01eb as in (2.1), the integral in (3.29) is well approximated\nby an integral over a bounded domain, with the product of the sinc factors replaced\nby one and the various midpoints tln replaced by \u03b1n .\n\u221a\nLemma 5.3. Given \u03bc1 > 0 there exists a constant c1 > 0 such that for \u03b1n = o( n)\nand nmin = nmin (\u03c3 (1) , .., \u03c3 (k) ) \u2265 n0 we have\nm\n\u0010\n\u0011 Y\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for j = 1, . . . , k =\n(2qn,l )kl\n\n\u00d7\n\n\u0012 ZZZ\n\nl=1\n\n\u03bc1\n\n\u2212\u03bc1\n\nY\n\u03b4\n\n\u03c1\u0302(f * \u03b4)n\u03b4\n\nk\nY\n\nj=1\n\n\u0013\n\u221a\n\u221a\ncos(2\u03c0fj \u03b1n n)dfj + O(e\u2212c1 nmin ) + O( n\u03ben ) .\n\n(5.25)\nHere theP\nproduct over \u03b4 runs over all \u03b4 \u2208 {\u22121, +1}k and f * \u03b4 stands for the scalar\nproduct j fj \u03b4j .\n\nProof. Consider the integral on the right hand side of (3.29). In a first step, we will\nconsider the contribution of the region where |fj | > \u03bc1 for at least one j and show\nthat it is negligible. To this end, it is clearly enough to bound the contribution of the\nPk\nPk\nregion where j=1 |fj | > \u03bc1 . But if j=1 |fj | > \u03bc1 , then there is a \u03b4 \u2208 {\u22121, +1}\nPk\nsuch that | j=1 \u03b4j fj | > \u03bc1 . Since n\u03b4 \u2265 1 for all \u03b4 \u2208 {\u22121, +1}k , we conclude that\nthere exists an s \u2208 {1, . . . , n} such that |vs | > \u03bc1 .\nThus consider the event that one of the |vs |'s, say |vt1 |, is larger than \u03bc1 . Let\n(k)\n(1)\n\u03b4 1 = {\u03c3t1 , .., \u03c3t1 }, and let \u03b4 2 , ..., \u03b4 k be vectors such that the rank of the matrix\n\u2206 formed by \u03b4 1 , .., \u03b4 k is k. Let {vt2 , ..., vtk } be defined by\nvti =\n\nk\nX\n\n\u03b4ij fj .\n\n(5.26)\n\nj=1\n\nSince \u2206 has rank k, we can change the variables of integration from fj to vtj . Let\nthe Jacobian of this transformation be Jk , i.e., let Jk = | det \u2206|\u22121 where det \u2206 is\nthe determinant of \u2206. Since \u2206 has entries \u00b11 and is non-singular, we conclude that\n| det \u2206| \u2265 1, implying that |Jk | \u2264 1. We therefore may bound the integral over the\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n23\n\nregion where where |vt1 | > \u03bc1 by\nZZZ\n\n\u221e\n\n\u2212\u221e\n\n\u2264\n\nZZZ\n\nZ\n\n|vt1 |>\u03bc1\n\nk\n\u221e Y\n\n\u2212\u221e j=2\n\n\u2264 (C0 )k\u22121\n\nn\nY\n\nJk\n\n|\u03c1\u0302(vtj )|\n\nZ\n\n|vt1 |>\u03bc1\n\n\u03c1\u0302(vs )\n\nk\nY\n\ns=1\n\nj=1\n\nn\u03b4 j\n\nZ\n\ndvtj \u00d7\n\n\u221a\nsinc(fj qn,l(j) ) cos(2\u03c0fj tnl(j) n)dvtj\n\n|vt1 |>\u03bc1\n\n(5.27)\n\n|\u03c1\u0302(vt1 )|n\u03b41 dvt1\n\n|\u03c1\u0302(vt1 )|n\u03b4 1 dvt1 \u2264 C0k e\u2212c1 (nmin \u2212n0 ) ,\n\nwhere C0 and c1 are as in (5.1) and (5.2). Since the number of choices for \u03b4 t1 is\nbounded by 2k , the bound (5.27) implies that the contribution of the region where\nat least one of the |fj |'s is larger than \u03bc1 is bounded by O(e\u2212c1 nmin ), with the\nconstant implicit in the O-symbol\ndepending on k.\n\u221a\nNoting that qn,l(j) = O( n\u03ben ), we finally observe that in the region where\n\u221a\n\u221a\n|fj | \u2264 \u03bc1 for all j, we may expand sinc(qn,l(j) fj ) as 1+O( n\u03ben ) and cos(2\u03c0fj tn n)\nQ\n\u221a\n\u221a\nas cos(2\u03c0fj \u03b1n n) + O( n\u03ben ). Rewriting the product s \u03c1\u0302(vs ) as\nn\nY\n\nY\n\n\u03c1\u0302(vs ) =\n\ns=1\n\n\u03b4\u2208{\u22121,+1}k\n\n\u03c1\u0302(f * \u03b4)n\u03b4 ,\n\n(5.28)\n\nthis gives (5.25).\n\n\u0003\n\nNext we rewrite the integral in (5.25) as the average\nZ Z Z \u03bc1 Y\nk\nY\n\u221a\nn\u03b4\ncos(2\u03c0fj \u03b1n n)dfj\n\u03c1\u0302(f * \u03b4)\n\u2212\u03bc1\n\nj=1\n\n\u03b4\n\n=2\n\n\u2212k\n\nX\n\n\u03b1n \u03b1n k\nx\u2208{\u2212 \u221a\n, \u221an }\nn\n\nZZZ\n\n\u03bc1\n\ne\n\n2\u03c0inf *x\n\n\u2212\u03bc1\n\nY\n\u03b4\n\nn\u03b4\n\n\u03c1\u0302(f * \u03b4)\n\nk\nY\n\n(5.29)\ndfj\n\nj=1\n\n\u03b1n \u221a\nwhere the sum goes over all sequences x = (x1 , . . . , xk ) \u2208 {\u2212 \u221a\n, \u03b1nn }k and f * x\nn\nP\nstands again for the scalar product, f *x = j fj xj . In order to analyze the integrals\non the right hand side, we will again use the method of steepest decent. To this\nend, we first prove the following analog of Lemma 5.1. As before, \u03bc0 is a constant\nsuch that \u03c1\u0302(f ) is analytic in the strip |Imf | < \u03bc0 .\n\nLemma 5.4. Given \u03bc1 > 0 there are constants c1 > 0 and \u03bc2 \u2208 (0, \u03bc0 ) such that\nthe following boundPholds whenever nmin \u2265 2\u2212(k+1) n and \u03b71 , . . . , \u03b7k is sequence of\nreal numbers with j |\u03b7j | \u2264 \u03bc2 and \u03b7j xj \u2265 0 for all j:\nZ Z Z \u03bc1 Y\nk\nY\ne2\u03c0inxj fj dfj\n\u03c1\u0302(f * \u03b4)n\u03b4\n\u2212\u03bc1\n\n=\n\n\u03b4\n\nZZZ\n\n\u03bc1\n\n\u2212\u03bc1\n\nj=1\n\ne2\u03c0n(ix*f \u2212x*\u03b7)\n\nY\n\u03b4\n\n\u03c1\u0302(f * \u03b4 + i\u03b7 * \u03b4)n\u03b4\n\nk\nY\n\n(5.30)\n\ndfj + O(e\n\n\u2212 21 c1 nmin\n\n).\n\nj=1\n\nProof. For j = 1, . . . , k, let Cj be the path consisting of the three line segments\nwhich join the point \u2212\u03bc1 to the point \u2212\u03bc1 + i\u03b7j , the point \u2212\u03bc1 + i\u03b7j to the point\n\u03bc1 + i\u03b7j , and the point \u03bc1 + i\u03b7j to the point \u03bc1 , respectively. For j = 1, . . . , k, we\n\n\f24\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nreplace, one by one, the integrals over the variables fj by integrals over the paths Cj\nand then bound the contribution over the part coming from the two line segments\njoining \u2212\u03bc1 to \u2212\u03bc1 + i\u03b7j and \u03bc1 + i\u03b7j to \u03bc1 , respectively. In each of step, we then\nhave to bound integrals of the form\nZZZ Y\nk\nY\n\u03c1\u0302(f * \u03b4)n\u03b4\ne2\u03c0inxj\u2032 fj\u2032 dfj \u2032\n(5.31)\nj \u2032 =1\n\n\u03b4\n\nwhere f1 , . . . , fj\u22121 run over the line segments from \u2212\u03bc1 + i\u03b7j to \u03bc1 + i\u03b7j , fj runs\neither over the the line segment from \u2212\u03bc1 to \u2212\u03bc1 + i\u03b7j or the line segment from\n\u03bc1 + i\u03b7j to \u03bc1 , and fj+1 , . . . , fk run over the interval [\u2212\u03bc1 , \u03bc1 ]. To bound these\nintegrals, we note that in this domain of integration the real part of fj has absolute\nvalue \u03bc1 , implying in particular that\nX\n|Refi | \u2264 k\u03bc1 .\n(5.32)\n\u03bc1 \u2264\ni\n\nAs a consequence, |Ref * \u03b4| \u2264 k\u03bc1 for all \u03b4, and further there exists at least one \u03b4\nfor which |Ref * \u03b4| \u2265 \u03bc1 . (In fact it is easyPto see that there are at least 2k\u22121 such\n\u03b4's.) On the other hand, the assumption j |\u03b7j | \u2264 \u03bc2 implies that |Imf * \u03b4| \u2264 \u03bc2\nfor all \u03b4.\nConsider first a vector \u03b4 for which \u03bc1 \u2264 |Ref * \u03b4| \u2264 k\u03bc1 , and assume that\n\u03bc2 \u2264 \u03bc0 is chosen in such a way that (5.2) holds. Under this assumption, we have\n|\u03c1\u0302(f * \u03b4)| \u2264 e\u2212c1 , implying that the term \u03c1\u0302(f * \u03b4)n\u03b4 contributes a factor that is at\nmost e\u2212nmin c1 .\nTo bound |\u03c1\u0302(z)| when we only know that |Rez| \u2264 k\u03bc1 , we use continuity in\nconjunction with the fact that |\u03c1\u0302(z)| \u2264 1 for all real z. Decreasing \u03bc2 , if necessary,\n\u2212k\u22122\nwe conclude that |\u03c1\u0302(z)| \u2264 ec1 2\nwhenever |Rez| \u2264 k\u03bc1 and |Imz| \u2264 \u03bc2 . As a\nconsequence, the first product in (5.31) can be bounded by\nY\n\u2212k\u22122\n1\nn\n(5.33)\n\u2264 e\u2212 2 nmin c1 .\n\u03c1\u0302(f * \u03b4)n\u03b4 \u2264 e\u2212nmin c1 ec1 2\n\u03b4\n\nSince the second product is bounded by one as before, and the integral only contributes a constant, this proves the lemma.\n\u0003\n\nNext we have to determine the values of the shifts \u03b71 , . . . , \u03b7k . According to the\nmethod of steepest decent, we again choose a saddle point of the integrand. Since\nthe integrand is now a function of k variables, this now gives a system of k equations\nfor \u03b7 = (\u03b71 , . . . , \u03b7k ):\nX n\u03b4\n\u03b4j F \u2032 (i\u03b4 * \u03b7) = 2\u03c0ixj .\n(5.34)\nn\n\u03b4\n\nAssume for a moment that this equation has a unique solution \u03b7 = \u03b7(x). We then\ndefine a function\nX n\u03b4\nGn,k (x) =\nF (i\u03b4 * \u03b7(x)) + 2\u03c0\u03b7(x) * x.\n(5.35)\nn\n\u03b4\n\u221a\nk\nLemma 5.5.\n\u221a Let 0 \u2264 \u03b1n = o( n), let qmax = o(1), and let x \u2208 R be such that\n|xi | = \u03b1n / n. Then the equation (5.34) has a unique solution \u03b7 = \u03b7(x),\n\u03b7i (x) =\n\nk\n\u0011\u0010\n\u0010 1 X\n\u03b12 \u0001\u0011\n\u22121\nCij\nxj 1 + O n\n2\u03c0 j=1\nn\n\n(5.36)\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n25\n\nand \u03b7j (x)xj \u2265 0 for all j \u2208 {1, . . . , k}. In addition, for sufficiently small \u03bc1 ,\nZ Z Z \u03bc1\nk\nY\nY\ndfj\ne2\u03c0n(ix*f \u2212x*\u03b7)\n\u03c1\u0302(f * \u03b4 + i\u03b7 * \u03b4)n\u03b4\n\n(5.37)\n\n\u2212\u03bc1\n\nj=1\n\n\u03b4\n\n= e\u2212nGn,k (x)\n\n\u0012\n\n\u0013k/2 \u0010\n\u0011\n1\n1 + O(n\u22121/2 ) + O(\u03b12n /n) + O(qmax ) .\n2\u03c0n\n\nProof. For x = 0, the equation (5.34) is obviously solved by \u03b7 = 0. To obtain\nexistence and uniqueness of a solution in the neighborhood of zero, we consider the\nderivative matrix of the function on the left hand side,\nX n\u03b4\nAij (\u03b7) = i\n\u03b4i \u03b4j F \u2032\u2032 (i\u03b4 * \u03b7).\n(5.38)\nn\n\u03b4\n\n\u2032\u2032\n\n2\n\nUsing the fact that F (f ) = (2\u03c0) + O(f 2 ) we may expand Aij (\u03b7) as\nAij (\u03b7) = Aij (0) + O(k\u03b7k22 ),\nand for \u03b7 = 0 we have\nAij (0) = (2\u03c0)2 i\n\nX n\u03b4\n\u03b4\n\nn\n\n(5.39)\n\n\u03b4i \u03b4j = (2\u03c0)2 iCij ,\n\n(5.40)\n\nwhere Cij is the overlap matrix Cij = q(\u03c3 (i) , \u03c3 (j) ). If the maximal off-diagonal\noverlap qmax is o(1), the matrix C is invertible, implying in particular that Aij (\u03b7)\nis non-singular in a neighborhood of zero. By the implicit function theorem, we\nconclude that for x sufficiently small, the equation (5.34) had a unique solution\n\u03b7(x), and by (5.39), we may expand \u03b7(x) as\n\u03b7i (x) = 2\u03c0i\n\nk\nX\n\n3\nA\u22121\nij (0)xj + O(kxk2 )\n\nj=1\n\n(5.41)\n\nk\n1 X \u22121\n=\nC xj + O(kxk32 ).\n2\u03c0 j=1 ij\n\n\u22121\nFor qmax = o(1), the matrix C \u22121 can be approximated as Cij\n= \u03b4ij + o(qmax ),\n\u221a\nimplying in particular\n\u221a that for |xj | = \u03b1n / n, the leading term on the right hand\nside is of order \u03b1n / n. As a consequence, we can convert the additive error into a\nmultiplicative error 1 + O(\u03b12n /n), giving the desired bound (5.36). Using once more\n\u22121\nthat Cij\n= \u03b4ij + o(qmax ), the fact that xj \u03b7j (x) \u2265 0 is an immediate corollary of\n(5.36).\nWe are left with the proof of (5.37). To this end, we rewrite the left hand side\nas\nZ Z Z \u03bc1\nk\nY\nP\ndfj\ne2\u03c0n(ix*f \u2212x*\u03b7) e\u2212 \u03b4 n\u03b4 F (f *\u03b4+i\u03b7*\u03b4)\n\u2212\u03bc1\n\nj=1\n\n=e\n\n\u2212nGk (x)\n\nZZZ\n\n\u03bc1\n\n\u2212\u03bc1\n\nwith\nG\u0303n,k (f ) =\n\nX n\u03b4\n\u03b4\n\nn\n\ne\n\n\u2212nG\u0303n,k (f )\n\nk\nY\n\n(5.42)\n\ndfj\n\nj=1\n\n\u0001\nF (f * \u03b4 + i\u03b7 * \u03b4) \u2212 F (i\u03b7 * \u03b4) \u2212 2\u03c0ix * f .\n\n(5.43)\n\n\f26\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nObserving that the derivatives of G\u0303n,k (f ) at f = 0 vanish by the definition of \u03b7(x),\nwe now expand G\u0303n,k (f ) as\nX n\u03b4 \u0010 1\n\nG\u0303n,k (f ) =\n\n\u03b4\n\nn\n\n2\n\n(f * \u03b4)2 F \u2032\u2032 (i\u03b7 * \u03b4) +\n\n\u0011\n1\n(f * \u03b4)3 F (3) (i\u03b7 * \u03b4) + O((f * \u03b4)4 ) . (5.44)\n3!\n\nArguing as in the proof of Proposition 5.2 we now have that\nX n\u03b4\nX\nReG\u0303n,k (f ) \u2265\nfi Cij fj\n(f * \u03b4)2 =\nn\ni,j\n\n(5.45)\n\n\u03b4\n\nprovided \u03bc1 is sufficiently small and n is sufficiently large. Since the maximal\noff-diagonal overlap qmax is of order o(1), we conclude that ReG\u0303n,k (f ) \u2265 12 kf k22\nprovided \u03bc1 is sufficiently small and n is sufficiently large. As a consequence, the\nintegral\n\u221a in (5.42) is dominated by configurations for which kf k2 is smaller than, say,\nlog n/ n. More quantitatively, we have\nZZZ\n\n\u03bc1\n\ne\u2212nG\u0303n,k (f )\n\n\u2212\u03bc1\n\n=\n\n=\n\nk\nY\n\ndfj\n\nj=1\n\nZZZ\n\n\u221a\nkf k2 \u2264log n/ n\n\nZZZ\n\n\u221a\n\ne\u2212nG\u0303n,k (f )\n\nk\nY\n\nj=1\n\ne\u2212nG\u0303n,k (f )\n\nkf k2 \u2264log n/ n\n\nk\nY\n\nj=1\n\ndfj + O\n\n\u0010Z Z Z\n\n\u221a\nkf k2 \u2265log n/ n\n\n\u0010\n\n1\n\ndfj + O e\u2212 2 log\n\n2\n\nn\n\n\u0011\n\ne\u2212nkf k\n\n2\n\n/2\n\nk\nY\n\nj=1\n\ndfj\n\n\u0011\n\n.\n\n\u221a\nFor kf k2 \u2264 log n/ n we expand e\u2212nG\u0303n,k (x) as\n\u0010 1Xn\n\u0011\n\u03b4\nG\u0303n,k (f ) = exp \u2212\n(f * \u03b4)2 F \u2032\u2032 (i\u03b7 * \u03b4) + O(nkf k3 )\n2\nn\n\u03b4\n\u0010\n\u0011\nP\n1\n= e\u2212 2 ij fi Mij fj 1 + O(nkf k3 )\n\nwhere M is the matrix with matrix elements\nX n\u03b4\n\u03b4i \u03b4j F \u2032\u2032 (i\u03b7 * \u03b4) = (2\u03c0)2 Cij + O(k\u03b7k2 )\nMij =\nn\n\u03b4\n\n(5.46)\n\n(5.47)\n\n(5.48)\n\n= (2\u03c0)2 \u03b4ij + O(\u03b12n /n) + O(qmax ).\n\nAs a consequence,\nZZZ\n\n\u221a\nkf k2 \u2264log n/ n\n\ne\u2212nG\u0303n,k (f )\n\nk\nY\n\nj=1\n\ndfj =\n\n\u0010 1 \u0011 k2 \u0010\n\u0011\n1+O(n\u22121/2 )+O(\u03b12n /n)+O(qmax ) .\n2\u03c0n\n\nCombined with (5.42) and (5.46), this implies the desired bound (5.37).\n\n(5.49)\n\u0003\n\nLemma 5.3, Lemma 5.4, the relation (5.29), Lemma 5.4 and Lemma 5.5 we now\neasily prove the following proposition.\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n27\n\n\u221a\n\u221a\nProposition 5.6. Let 0 \u2264 \u03b1n = o( n) and let 0 \u2264 \u03bbn = o( n). If n is sufficiently\nlarge and \u03c3 (1) . . . , \u03c3 (k) obey the condition (3.13), then\nm\n\u0010\n\u0011 \u0010Y\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for j = 1, . . . , k =\n\u03b3lkl\n\n\u00d7\n\n\u0012\n\n\u03ben\n\u221a\n2\u03c0\n\n\u0013k\n\nl=1\n\nX\n\n\u03b1n \u03b1n k\nx\u2208{\u2212 \u221a\n, \u221an }\nn\n\n\u0010\n\n\u0011\ne\u2212nGn,k (x) 1 + o(1) .\n\n\u221a\nIf we strengthen the condition \u03b1n = o( n) to \u03b1n = o(n1/4 ), we have\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k\n=\n\nk\n\u0010\n\u0011\nY\n2\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] eO(\u03b1n qmax )+o(1) .\n\n(5.50)\n\n(5.51)\n\ni=1\n\nProof. Observe that under the condition (3.13), we have that nmin = n2\u2212k + o(n)\nand qmax = o(1). We may therefore use Lemma 5.3, Lemma 5.4, the relation\n(5.29), Lemma 5.4 and Lemma 5.5 to conclude that under the conditions of the\nproposition, there is a constant c > 0 such that\nm\n\u0011 Y\n\u0010\n(2qn,l )kl\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for j = 1, . . . , k =\nl=1\n\n\u00d7 2\u2212k\n\nX\n\n\u03b1n \u03b1n\nx\u2208{\u2212 \u221a\n, \u221an }\nn\n\n\u0013k/2 \u0010\n\u0012\n\u0012\n\u0013\n\u0011\n\u221a\n1\n1 + o(1) + O(e\u2212cn ) + O( n\u03ben ) .\ne\u2212nGn,k (x)\n2\u03c0n\nk\n\n(5.52)\nNext we expand Gn,k (x) with the help of the bounds (5.14) and (5.36), yielding\nthe approximation\n1 X n\u03b4\n(2\u03c0\u03b4 * \u03b7)2 + 2\u03c0\u03b7 * x + O(kxk42 )\nGn,k (x) = \u2212\n2\nn\n\u03b4\n\n(2\u03c0)2\n=\u2212\n(\u03b7, C\u03b7) + 2\u03c0\u03b7 * x + O(kxk42 )\n2\n\u0010 \u03b14 \u0011\n1\n= (x, C \u22121 x) + O n2 .\n2\nn\n\n(5.53)\n\nNote that this implies in particular that nGn,k (x) = O(\u03b12n ) + O(\u03b14n /n) = o(n).\nThe leading term on the right hand side of (5.52) is therefore much larger than\nthe additive error terms, which both decay exponentially in n. These additive\nerror terms can therefore be converted\ninto a multiplicative error\nP term (1 + o(1)).\n\u221a\nInserting the value of qn,l (= \u03b3l \u03ben n) and using the fact that l kl = k, this yields\nthe approximation (5.50).\nTo infer the bound (5.51), we use the assumption \u03b1n = o(n1/4 ) to expand the\n\u221a\n2\nfactor (\u03ben / 2\u03c0)k as 2\u2212nk ek\u03b1n /2 (1 + o(1)), and the factor e\u2212nGn,k (x) as\n\u0011\n\u22121\n4\n2\n2\nn\nn\ne\u2212 2 (x,C x)+O(\u03b1n /n) = e\u2212 2 kxk2 +O(nkxk2 qmax ) 1 + O(\u03b14n /n)\n\u0011\n(5.54)\n2\nk 2\n= e\u2212 2 \u03b1n +O(\u03b1n qmax ) 1 + o(1) .\n\n\fCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\n28\n\nInserting these estimates into (5.50) and taking into account the bound (5.12), this\ngives (5.51).\n\u0003\n5.4. Failure of Poisson convergence for faster growing \u03b1n . In this section,\nwe prove the last statement of Theorem 2.1 for general distributions.\nThroughout\n\u221a\nthis section, we will assume that \u03b1n = O(n1/4 ) and \u03bbn = o( n). Near the end of\nthe section, we will specialize to \u03b1n = \u0398(n1/4 ), for which we will prove absence of\nPoisson convergence.\nWe start from (5.50), but instead of (5.53) we use a more accurate approximation\nfor Gn,k (x). To this end, we use the fact that \u03c1\u0302(f ) = \u03c1\u0302(\u2212f ) is analytic in a\nneighborhood of zero to infer the existence of a constant c4 such that\nF (z) =\n\n(2\u03c0)2 2\nz + c4 (2\u03c0)4 z 4 + O(|z|6 )\n2\n\nand\nF \u2032 (z) = (2\u03c0)2 z + 4c4 (2\u03c0)4 z 3 + O(|z|5 ).\n\u02c6)\nRemark 5.7. Using the fact that E(X 4 ) \u2265 E(X 2 )2 = 1 and expanding the log \u03c1(f\n1\n2\none can see that c4 \u2264 12 , with equality holding if and only if X = 1 with probability\none. Thus for all random variables whose density satisfies assumption (2.1) we have\nc4 < 1/12.\n\u22121\nUsing these expressions and the fact that Cij\n= \u03b4ij +O(qmax ) = \u03b4ij +O(\u03bbn n\u22121/2 )\n(1)\n(k)\nwhen \u03c3 . . . , \u03c3 obey the condition (3.13), we then expand the solution of (5.34)\nas\n\n4c4 X n\u03b4 \u22121\n1\n(C \u22121 x)i +\n(C \u03b4)i (\u03b4, C \u22121 x)3 + O(kxk5 )\n2\u03c0\n2\u03c0\nn\n\u03b4\nX\n1\n4c\nn\u03b4\n4\n=\n(C \u22121 x)i +\n\u03b4i (\u03b4 * x)3 + O(kxk5 ) + O(kxk3 \u03bbn n\u22121/2 ).\n2\u03c0\n2\u03c0\nn\n\n\u03b7i =\n\n(5.55)\n\n\u03b4\n\nIn order to analyze the sum over \u03b4, we use the condition (3.13) to estimate\nX n\u03b4\n\u03b4\n\nn\n\n\u03b4i \u03b4j \u03b4k \u03b4l = 2\u2212k\n\nX\n\n\u03b4i \u03b4j \u03b4k \u03b4l + O(\u03bbn n\u22121/2 ).\n\n\u03b4\n\nThe first term is zero unless i, j, k, l are such that either all of them are equal or\nare pairwise equal for some pairing of i, j, k, l. Observing that there are 3 possible\nways to pair four numbers into two pairs of two, this leads to the estimate\n\u03b7i =\n\nX \u0001\u0011\n4c4\n1\n(C \u22121 x)i +\nxi x2i + 3\nx2k + O(kxk3 \u03bbn n\u22121/2 ) + O(kxk5 )\n2\u03c0\n2\u03c0\nk6=i\n\n(5.56)\n1\n4c4 \u03b12n\n\u22121\n3\n\u22121/2\n5\n=\n(C x)i + (1 + 3(k \u2212 1))\nxi + O(kxk \u03bbn n\n) + O(kxk )\n2\u03c0\n2\u03c0n\n\u221a\nwhere we used the fact that |xi | = |xj | = \u03b1n / n in the last step. Inserting this\nexpression into the definition (5.35) and expanding the result in a similar way as\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n29\n\nwe expanded \u03b7 above, this leads to the approximation\nX\n(2\u03c0)2 X n\u03b4\n(\u03b4 * \u03b7)2 + c4 2\u2212k\n(\u03b4 * x)4 + 2\u03c0\u03b7 * x\nGn,k (x) = \u2212\n2\nn\n\u03b4\n\n\u03b4\n\n+ O(kxk6 ) + O(kxk4 \u03bbn n\u22121/2 )\n\n=\u2212\n\n\u03b14\n(2\u03c0)2\n(\u03b7, C\u03b7) + c4 k(1 + 3(k \u2212 1)) n2 + 2\u03c0\u03b7 * x\n2\nn\n+ O(kxk6 ) + O(kxk4 \u03bbn n\u22121/2 )\n\n1\n\u03b14\n4c4 \u03b14\n= \u2212 (x, C \u22121 x) \u2212 k(1 + 3(k \u2212 1)) 2 n + c4 k(1 + 3(k \u2212 1)) n2\n2\nn\nn\n4c4 \u03b14n\n6\n\u22121\n+ (x, C x) + k(1 + 3(k \u2212 1)) 2 + O(kxk )\nn\n+ O(kxk4 \u03bbn n\u22121/2 )\n\u0010 \u03b16 \u0011\n\u03b14\n\u03b14\n1\n= (x, C \u22121 x) + c4 k(1 + 3(k \u2212 1)) n2 + O n3 + O( n2 \u03bbn n\u22121/2 ).\n2\nn\nn\nn\n\u221a\n1/4\nUsing that \u03b1n = O(n ) and \u03bbn = o( n), this gives\n\u03b14\nn\n(x, C \u22121 x) + c4 k(1 + 3(k \u2212 1)) n + o(1).\n2\nn\nAs a consequence, we have that\nm\n\u0010\n\u0011 \u0010Y\n\u0011\n(j)\nl(j) l(j)\nP E(\u03c3 ) \u2208 [an , bn ] for j = 1, . . . , k =\n\u03b3lkl\n\n(5.57)\n\nnGn,k (x) =\n\n\u00d7\n\n\u0012\n\n\u03ben\n\u221a\n2\u03c0\n\n\u0013k\n\nl=1\n\nX\n\n\u03b1n \u03b1n k\nx\u2208{\u2212 \u221a\n, \u221an }\nn\n\ne\n\n\u22121\nx)\n\u2212n\n2 (x,C\n\ne\u2212c4 k(1+3(k\u22121))\n\n\u03b14\nn\nn\n\n\u0010\n\u0011\n1 + o(1)\n\n(5.58)\n\nwhenever \u03c3 (1) . . . , \u03c3 (k) obey the condition (3.13).\nNext we expand \u03ben , using that \u03ben = (2(n\u22121) gn (\u03b1n ))\u22121 with gn (\u03b1n ) given by\nx\n(5.10). To this end, we approximate \u03b7(x) as \u03b7(x) = 2\u03c0\n(1 + 4c4 x2 ) + O(x5 ) and\nG(x) as\n1\nx2\nG(x) = \u2212 (2\u03c0\u03b7(x))2 + c4 (2\u03c0\u03b7(x))4 + 2\u03c0x\u03b7(x) + O(x6 ) =\n+ c4 x4 + O(x6 ),\n2\n2\ngiving the expansion\nr\n\u00101\n\u0001\n\u03b14 \u0011\n\u03c0 \u2212(n\u22121)\n(5.59)\n2\nexp \u03b12n + c4 n 1 + o(1) .\n\u03ben =\n2\n2\nn\n\nInserting this expansion into (5.58) we then continue as in the proof of Theorem 3.3\nto get that\nm\nm\n\u0010Y\n\u0011\n\u0010 \u03b14 \u0010 k(k \u2212 1)\n\u0011\u0011\u0010\n\u0011\nY\nE[ (Zn (aln , bln ))kl ] =\n\u03b3lkl exp n\n\u2212 3c4 k(k \u2212 1)\n1 + o(1) .\nn\n4\nl=1\nl=1\n(5.60)\nSpecializing now to \u03b1n = \u03ban1/4 , this implies in particular that all moments of Zn (t)\nare bounded, and\n\u0011\u0011\n\u0010\n\u0010\n(5.61)\nlim E[(Zn (t))k ] = tk exp \u03ba4 (k \u2212 1)k 1/4 \u2212 3c4 .\nn\u2192\u221e\n\n\f30\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nIn view of Lemma 3.2 and the fact that c4 < 1/12 by Remark 5.7, this is incompatible with weak convergence to a Poisson random variable. This establishes the\n\u22121/4\nfailure of the modified REM conjecture for limn\u2192\u221e \u03b1n\n= \u03ba > 0.\nNote that the original REM conjecture also fails if limn\u2192\u221e \u03b1n n\u22121/4 = \u03ba > 0.\nIndeed, in this range, the original scaling (1.3) and the modified scaling differ by\n4\nthe asymptotically constant factor e\u2212c4 \u03ba (1 + o(1)). This makes things worse, since\nnow even the first moment does not converge to the desired value unless c4 = 0,\nin which case the original and the modified REM conjecture remain equivalent for\n\u03b1n = O(n1/4 ). This completes the proof of the last statement of Theorem 2.1.\nRemark 5.8. It is not hard to see that for \u03b1n = \u03ban1/4 the distribution of the overlap\nQn,t converges again to a superposition of two shifted Gaussians, see Remark 4.2,\nwhere this was discussed for the case where X1 , . . . , Xn where standard normals.\nIndeed, the only difference with the situation discussed in that remark is the extra\n4\nfactor of e\u2212c4 (k\u22121)(1+3k)\u03ba . But this factor does not depend on the overlap, and\nhence does not influence the overlap distribution.\n6. Analysis of the SK model\nFor \u03b1n = O(n\u03b7 ) and \u03b7 < 1, the local REM conjecture for the SK model has been\nproved in [BK05a]. To extend the proof up to the threshold \u03b1n = o(1), a little bit\nmore care is needed, but given the analysis of the Npp with Gaussian noise from\nthe Section 4, this is still relatively straightforward, even though the details vary\nat several places. But for \u03b1n of order n we have to be quite careful, since now\nseveral error terms which went to zero before are not vanishing anymore. It turns\nout, however, that for \u03b1n /n \u2264 \u01eb0 and \u01eb0 sufficiently small, we can at least control\nthe first three moments, which is enough to prove absence of Poisson convergence\nif lim sup \u03b1n /n > 0.\nWe start with the analysis of the first moment.\n6.1. First moment. For the SK model, the energy E(\u03c3) is a Gaussian random\nvariable with density given by (1.5). For \u03b1n = O(n) and \u03be \u0303n = o(1), the first moment\ncan therefore be approximated as\nZ bln\n2\n1\n2n\u22121\nE[Zn (aln , bln )] = \u221a\ne\u2212 2n x dx\n2\u03c0n aln\n\u0010 \u03b1 \u03be \u0303 \u0011\n\u0010 \u03be\u0303 2 \u0011\u0011\n(6.1)\n\u03b3l \u03be\u0303n 2n\u22121 \u2212 1 \u03b12n \u0010\nn n\n1+O\ne 2n\n+O n\n= \u221a\nn\nn\n2\u03c0n\n= \u03b3l (1 + o(1)).\n\u221a\nThis proves the convergence of the first moment for \u03b1n \u2264 cn and c < 2 log 2.\n6.2. Families of linearly independent configurations. When analyzing the\nfactorization properties of the joint distribution of E(\u03c3 (1) ), . . . , E(\u03c3 (k) ), we will\nwant to use the representation (3.32), which at a minimum, requires that the covariance matrix C defined in (3.33) is invertible. The following Lemma 6.1 shows\nthat a family of linearly independent configurations leads to an invertible covariance matrix, and gives a bound on the contribution of the families which are not\nlinearly independent. It serves the same purpose as Lemma 3.4 (2) served for the\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n31\n\nNpp. Note that statements similar to those in Lemma 6.1 were proved in [BK05a]\nunder the more restrictive condition that \u03b1n = O(n\u2212\u03b7 ) with \u03b7 < 1.\nTo state the lemma, we define R\u0303n,k as\n\u0010\n\u0011\nX\u2032\n1\nR\u0303n,k = k\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k ,\n(6.2)\n2 (1)\n(k)\n\u03c3\n\n,*** ,\u03c3\n\nwhere the sum runs over pairwise distinct configurations \u03c3 (1) , . . . , \u03c3 (k) which are\nlinearly dependent.\nLemma 6.1. Let k < \u221e. Then there exists a constant \u01ebk > 0 such that the\nfollowing statements are true.\n(1) If \u03c3 (1) , . . . , \u03c3 (k) are linearly independent, the matrix C defined in (3.33) is\ninvertible, and\n\u0010 n \u0011k/2 1\n\u22121\n(6.3)\ng\u0303 (k) (x) \u2264\ne\u2212 2 (x,C x) .\n2\u03c0\n(2) If \u03b1n \u2264 n\u01ebk , then\nR\u0303n,k \u2192 0\n\nas\n\nn \u2192 \u221e.\n\n(6.4)\n\nProof. (1) This statement is quite easy and must be known to most experts in the\nfield. First, we rewrite the matrix elements of C as Cij = nq(\u03b7 (i) , \u03b7 (j) ), where\n2\n(i)\n(i) (i)\n\u03b7(1) , . . . , \u03b7 (k) are vectors in {\u22121, +1}n . Indeed, setting \u03b7r,s = \u03c3s \u03c3r , where\n\u00012\nr, s = 1, . . . n and i = 1, . . . k, we see that q(\u03b7 (i) , \u03b7 (j) ) = q(\u03c3 (i) , \u03c3 (j) ) , implying\nthe above representation for C. Next we observe that that the linear independence\nof \u03c3 (1) , . . . , \u03c3 (k) implies linear independence of \u03b7 (1) , . . . , \u03b7 (k) , which in turn can\neasily be seen to imply linear independence of the row vectors of the matrix with\nmatrix elements q(\u03b7 (i) , \u03b7 (j) ). This gives that C is non-degenerate. But C is a\nk \u00d7 k matrix with entries which are multiples of n\u22121 , so if det C 6= 0, we must have\n| det C| \u2265 n\u2212k . This implies the bound (6.3).\n(2) To prove (2), we decompose the sum in (6.2) according to the rank of the\nmatrix M formed by the vectors \u03c3 (1) , . . . , \u03c3 (k) . Assume that the rank of M is equal\nto u < k. Reordering the vectors \u03c3 (1) , . . . , \u03c3 (k) , if necessary, let us further assume\nthat \u03c3 (1) , . . . , \u03c3 (u) are linearly independent. With the help of (1), we then bound\nthe probability on the right hand side of (6.2) by\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k\n\u0010\n\u0011\n\u2264 P E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , u\n(6.5)\nu\n\u0010 n \u0011u/2 Y\n\u221a\n(\u03be \u0303n \u03b3l(j) ) = O(( n\u03be \u0303n )u )\n\u2264\n2\u03c0\nj=1\nTo continue, we use the following two facts, proven, e.g., in [BCP01] (see also\nLemma 3.9 in [BCMN05]:\n(1) If \u03c3 (1) , . . . , \u03c3 (k) are pairwise distinct, the rank of M is u < k and \u03c3 (1) , . . . ,\n\u03c3 (u) are linearly independent, then n\u03b4 (\u03c3 (1) , . . . , \u03c3 (u) ) = 0 for at least one\n\u03b4 \u2208 {\u22121, +1}u.\n(2) Given u < k linearly independent vectors \u03c3 (1) , . . . , \u03c3 (u) , there are at most\n2u(k\u2212u) ways to choose \u03c3 (1) , . . . , \u03c3 (k) in such a way that the rank of M is\nu.\n\n\f32\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nAs a consequence, of (1), we have\n| max |n\u03b4 (\u03c3 (1) , . . . , \u03c3 (u) ) \u2212 2\u2212u n| \u2265 2\u2212u n.\n\u03b4\n\nCombined with Lemma 3.4 (1) and the property (2) above, we conclude that there\n\u2212(2u+1)\n\u2212(2k\u22121)\nn\nn\nare at most O(2nu e\u22122\n) = O(2nu e\u22122\n) ways to choose k pairwise dis(1)\n(k)\ntinct configurations \u03c3 , . . . , \u03c3\nsuch that the rank of M is u. Using the fact\n\u221a\n2\nu\nthat ( n\u03be\u0303n )u = O(nu e 2n \u03b1n 2\u2212nu ), we immediately see that for \u03b1n \u2264 \u01ebk n and \u01ebk\nsufficiently small, the contribution of all configurations \u03c3 (1) , . . . , \u03c3 (k) such that the\nrank of M is smaller than k decays exponentially in n, so in particular it is o(1). \u0003\nConsider now a family of linearly independent configurations\n\u03c3 (1) , . . . , \u03c3 (k) . We\n\u221a\nclaim that for such a family and \u03b1n \u2264 cn with c < 2 log 2, we have\n\u0010\n\u0011\nP E(\u03c3 (j) ) \u2208 [anl(j) , bnl(j) ] for all j = 1, . . . , k\n=\n\nm\nY\n\n(\u03be \u0303n \u03b3l )kl\n\nl=1\n\n\u22121\n1\n1\n1\ne\u2212 2 (\u03b1,C \u03b1) (1 + o(1)),\n(2\u03c0)k/2 (det C)1/2\n\n(6.6)\n\nwhere \u03b1 is the vector (\u03b1n , . . . , \u03b1n ) \u2208 Rk and C is the covariance matrix defined in (3.33). To prove this approximation, we have to show that (x, C \u22121 x) =\n(\u03b1, C \u22121 \u03b1) = o(1) whenever x is a vector with xi = \u03b1n + O(\u03be \u0303n ). This in turn\nrequires an upper bound on the inverse of C. To prove such a bound we use that\nthe matrix elements of C are bounded by n, while det C is bounded from below by\nn\u2212k . Using Cramer's rule, we conclude that the norm of C \u22121 is O(n2k\u22121 ), which\n\u22121\n\u22121\n2k\u22121\nin turn implies that\n\u03b1n \u03be \u0303n ) + O(n2k\u22121 \u03be\u0303n2 ). For\n\u221a (x, C x) = (\u03b1, C \u03b1) + O(n\n\u03b1n \u2264 cn with c < 2 log 2, the error term\n\u221a is o(1), as desired.\nAssume that \u03b1n \u2264 cn with c < min{ 2 log 2, \u01ebk }. Using first the representation\n(3.11), then Lemma 6.1 and the bound (6.6), and finally the explicit formula (1.6)\nfor \u03be\u0303n , we now approximate the k th factorial moment as\nm\nm\ni \u0010Y\nhY\n\u0011\nE\n\u03b3lkl\n(Zn (aln , bln ))kl =\nl=1\n\n\u00d72\n\n\u2212nk\n\nX \u2032\u2032\n\n\u03c3 (1) ,...,\u03c3 (k)\n\nl=1\nk/2\n\n\u0010\n\u0011\n2\n\u22121\n1\n1\nn\n\u03b1)\n2n k\u03b1k2 e\u2212 2 (\u03b1,C\ne\n1\n+\no(1)\n+ o(1)\n(det C)1/2\n\n(6.7)\n\nwhere the sum goes over families of linearly independent configurations \u03c3 (1) , . . . ,\n\u03c3 (k) .\n6.3. Poisson convergence for \u03b1n = o(n). In this section, we\n\u221a prove Theorem\n\u221a 3.6.\nTo this end, we again choose \u03bbn in such a way that \u03b1n = o(\u03bbn n), \u03bbn = o( n) and\n2\ne\u2212\u03bbn /2 decays faster than any power of n. Recalling Lemmas 3.4 (1) and (3), we\u221a\nmay\nthen restrict the sum in (6.7) to a sum over configurations with qmax = O(\u03bbn / n).\n\u22121\n2\n)), we then approximate det C\nExpanding the inverse of C as Cij\n= n1 (\u03b4ij + O(qmax\nk\n\u22121\n\u22121\n2\nas det C = n (1 + o(1)), and (\u03b1, C \u03b1) as (\u03b1, C \u03b1) = k\u03b1k22 + O(n\u22121 \u03b12n qmax\n).\nUsing Lemma 3.4 and Lemma 6.1 a second time to extend the sum over families of\nconfigurations back to a sum over all families of configurations in {\u22121, +1}n, the\nproof of Theorem 3.6 is therefore reduced to the proof of the bound\nX\n1 2 2\n2\u2212nk\neO( n \u03b1n qmax ) = 1 + o(1).\n(6.8)\n\u03c3 (1) ,...,\u03c3 (k)\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n33\n\nSince typical configurations lead to a maximal off-diagonal overlap qmax of order\nO(n\u22121/2 ), we expect that such a bound holds as long as \u03b1n = o(n). Lemma 7.1 in\nSection 7.2 implies that this is indeed the case.\n6.4. Absence of Poisson convergence for faster growing \u03b1n . In this section,\nwe prove Theorem 3.7. We start by proving the following lemma.\nLemma 6.2. Given a positive integer k, there are constants \u01eb\u0303k > 0 and Ck < \u221e\nsuch that\nm\nm\ni\nhY\nY\nE\n\u03b3lkl + o(1)\n(6.9)\n(Zn (aln , bln ))kl \u2264 Ck\nl=1\n\nl=1\n\nwhenever \u03b1n \u2264 \u01eb\u0303k n, k =\n\nP\n\nl\n\nkl and n is large enough.\n\nProof. Starting from the approximation (6.7), we will again restrict ourselves to\nconfigurations\nn of the\n\u221a obeying the condition (3.13), but this time we will choose \u03bb\u221a\nform \u03bbn = 2kn\u01eb\u0303k where \u01eb\u0303k > 0 will be chosen in such a way that \u01eb\u0303k < 2 log 2\nand \u01eb\u0303k \u2264 \u01ebk . Note that our choice of \u03bbn guarantees that for \u03b1n \u2264 n\u01eb\u0303n , the sum\nover families of configurations violating the condition (3.13)\n\u221a decays exponentially\nwith n. Note further that the condition (3.13) with \u03bbn = 2kn\u01eb\u0303k guarantees that\n2\n2\nqmax\n\u2264 22k+1 k\u01eb\u03032k . Expanding det C as det C = nk (1 + O(qmax\n)), we therefore have\n1 k\nthat det C \u2265 2 n provided \u01eb\u0303k is chosen small enough.\nLet us finally write the matrix C as C = n1 (Ik + A), where Ik is the identity\nmatrix of size k, and A is the matrix with zero diagonal and off-diagonal entries\nA2\n), we see that\nq 2 (\u03c3 (i) , \u03c3 (j) ). Expanding C \u22121 as C \u22121 = n1 (Ik \u2212 A + 1+A\n\u0011\n\u0011\n1\u0010\n1\u0010\n2\n(6.10)\nk\u03b1k22 \u2212 (\u03b1, A\u03b1) \u2265\nk\u03b1k22 \u2212 k 2 qmax\n\u03b12n .\n(\u03b1, C \u22121 \u03b1) \u2265\nn\nn\nTogether with our lower bound on det C, we see that the proof of the lemma now\nreduces to the bound\nX\n\u221a 1 (k\u03b1 q )2\n2\u2212nk\n2e 2n n max \u2264 Ck .\n(6.11)\n\u03c3 (1) ,...,\u03c3(k)\n\nFor \u01eb\u0303k small enough, this bound again follows from Lemma 7.1 in Section 7.2.\n\n\u0003\n\nNote that Lemma 6.2 implies statement (ii) of Theorem 3.7, while the bound\n(6.1) implies statement (i). We are therefore left with the proof of (iii), i.e., the\nstatement that lim supn\u2192\u221e E[(Zn (a, b))2 ] > \u03b3 2 when lim sup \u03b1n /n > 0. Recalling\nthe representation, this in turn requires us to prove that\nX \u2032\u2032\n2\n\u22121\n1\n1\nn\n(6.12)\nlim sup 2\u22122n\ne 2n k\u03b1k2 e\u2212 2 (\u03b1,C \u03b1) > 1.\n1/2\n(det\nC)\nn\u2192\u221e\n(1)\n(2)\n\u03c3\n\n,\u03c3\n\nLet q = q(\u03c3 (1) , \u03c3 (2) ) be the off-diagonal overlap of the two configurations \u03c3 (1) and\n\u03c3 (2) . Since C is now just a 2 \u00d7 2 matrix, both its inverse and its determinant can\nbe easily calculated, giving det C = n2 (1 \u2212 q 4 ), and, using that k\u03b1k22 = k\u03b12n = 2\u03b12n ,\n(\u03b1, C \u22121 \u03b1) =\n\n1\n2\u03b12n\n2\u03b12n\nq2\n2\n2 2\n).\n(2\u03b1\n\u2212\n2q\n\u03b1\n)\n=\n=\n(1\n\u2212\nn\nn\nn(1 \u2212 q 4 )\nn(1 + q 2 )\nn\n1 + q2\n\n(6.13)\n\n\f34\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nAs a consequence, we will have to prove a lower bound on the expression\n2\n\u03b12\nX \u2032\u2032\nn q\n1\np\ne n 1+q2 .\n2\u22122n\n1 \u2212 q4\n\u03c3 (1) ,\u03c3 (2)\n\n(6.14)\n\nTaking subsequence,\nn /n converges to some \u03ba, with\n\u221a if necessary, let us assume that \u03b1P\n\u2032\u2032\n0 < \u03ba < min{\u01eb2 , 2 log 2}. We then bound the sum\nfrom below by restricting\nit to all configurations for which |q| \u2264 2\u03ba. Under this restriction, the summand is\n2\n1\ne\u03b2n q , with \u03b2n = \u03b12n /(n(1 + 4\u03ba2 )). Observing that\nbounded from below by \u221a1\u221216\u03ba\n4\nq 2 \u2264 1 we may then use Lemma 3.4 (1) and (3) to extend the sum back to a sum\nwhich runs over all configurations \u03c3 (1) and \u03c3 (2) , leading to the lower bound\n2\n\u03b12\nX \u2032\u2032\nX\nn q\n2\n1\n2\u22122n\np\n2\u22122n\ne n 1+q2 \u2265 \u221a\ne\u03b2n q + o(1).\n(6.15)\n4\n1 \u2212 16\u03ba \u03c3(1) ,\u03c3(2)\n1 \u2212 q4\n\u03c3 (1) ,\u03c3(2)\n\nLet E2 denote expectations with respect to the uniform measure over families of\nconfigurations \u03c3 (1) , \u03c3 (2) \u2208 {\u22121, +1}n. Using H\u00f6lder and the fact that E2 [q 2 ] = n1 ,\nwe then lower bound the right hand side by\nX\n2\n2\u22122n\n\u221a\ne\u03b2n q + o(1)\n4\n1 \u2212 16\u03ba \u03c3(1) ,\u03c3(2)\n(6.16)\n\u0010 \u03ba2 \u0011\n1\ne\u03b2n /n\n+ o(1).\n+ o(1) = \u221a\nexp\n\u2265 \u221a\n1 + 4\u03ba2\n1 \u2212 16\u03ba4\n1 \u2212 16\u03ba4\nFor \u03ba sufficiently small, the right hand side is asymptotically larger than 1, proving\nthe desired lower bound (6.12), which completes the proof of Theorem 3.7.\n7. Auxiliary results\n7.1. Proof of Lemma 3.5.\nProof of Lemma 3.5. We will have to prove that\nX\n(1)\n(k)\n2\u2212nk\nef (\u03c3 ,...,\u03c3 ) = 1 + o(1).\n\n(7.1)\n\n\u03c3 (1) ,...,\u03c3 (k)\n\nRecalling the assumption |f (\u03c3 (1) , . . . , \u03c3 (k) )| \u2264 c\u03b12n qmax , let \u03b8n = \u221a\no(n) be a sequence\nof positive integers such that \u03b8n \u2192 \u221e as n \u2192 \u221e and \u03b12n \u03b8n = o( n).\nWe now split the sum on the left hand side of (7.1) into two parts: the sum\nover all families of configurations \u03c3 (1) , . . . , \u03c3 (k) that satisfy (3.13) with \u03b8n taking\nthe place of \u03bbn and the sum over the configurations that violate the bound (3.13),\nagain with \u03b8n replacing \u03bbn .\nConsider the first sum. By Lemma 3.4, the number of terms in this sum is\n2\n\u03b8n\n\nbounded between 2nk (1 \u2212 2k+1 e\u2212 2 ) and 2nk . For all these configurations we know\n\u03b8n\n\u03b8n\nfrom Lemma 3.4 that qmax \u2264 2k \u221a\nand hence |f (\u03c3 (1) , . . . , \u03c3 (k) )| \u2264 c2k \u03b12n \u221a\n=\nn\nn\no(1) as n \u2192 \u221e. Using the fact that \u03b8n \u2192 \u221e as n \u2192 \u221e we obtain that the\ncontribution from the first summation is 1 + o(1) as n \u2192 \u221e.\nThus, to establish Lemma 3.5 it suffices to show that the contribution from the\nsecond sum is o(1) as n \u2192 \u221e. To this end we partition the interval [\u03b8n , n] into\nsubintervals [\u03bai , \u03bai+1 ] of length one. Now consider the families of configurations\n\u03c3 (1) , . . . , \u03c3 (k) that satisfy (3.13) when \u03bbn is replaced by \u03bai+1 but violate it if \u03bbn\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n35\n\nis replaced by \u03bai . It is easy to see that for n large enough, the contribution from\nthese terms is bounded by\n2\n\n2k+1 e\u2212\u03bai /2 e\n\nc\u03b12n 2k\n\n\u03bai+1\n\u221a\nn\n\n2\n\n2\n\n= 2k+1 e\u2212\u03bai /2 eo(\u03bai ) \u2264 e\u2212\u03bai /4 .\n\n2\n\nAdding up these error terms, we obtain that the second sum is of order O(e\u2212\u03b8n /4 ) =\no(1). This completes the proof of Lemma 3.5.\n\u0003\n7.2. Proof of Lemma 4.1. The proof of Lemma 4.1 will be based on the following\nlemma.\nLemma 7.1. Let k be a positive integer, and let \u03b2 <\n(1)\n\n(k)\n\n2\n\u03b2qmax\n\nIf |g(\u03c3 , . . . , \u03c3 )| \u2264\n\u0010\nk(k \u2212 1) \u03b2 \u0011\n1\u2212\n\u2264 2\u2212nk\n2\nn\n\n\u03c3\n\nn\nk(k\u22121)\n\nbe a non-negative real.\n\nfor all families of configurations \u03c3 (1) , . . . , \u03c3 (k) , then\n\u0010\nX\n(1)\n(k)\n\u03b2 \u0011\u22121/2\neg(\u03c3 ,...,\u03c3 ) \u2264 1 \u2212 k(k \u2212 1)\n(7.2)\nn\n(1)\n(k)\n,...,\u03c3\n\nProof. Let Ek [*] denote expectations with respect to the uniform measure over all\nfamilies of configurations \u03c3 (1) , . . . , \u03c3 (k) \u2208 {\u22121, +1}n. With the help of Jensen's\ninequality, we then immediately obtain the lower bound\n\u0011\n\u0010\nX\n2\n2\n]\nEk [qij\nEk [eg ] \u2265 exp(\u2212\u03b2Ek [qmax\n]) \u2265 exp \u2212\u03b2\n\ni<j\n(7.3)\n\u0010\nk(k \u2212 1) 1\nk(k \u2212 1) 1 \u0011\n\u22651\u2212\u03b2\n.\n= exp \u2212\u03b2\n2\nn\n2\nn\nTo obtain an upper bound, we first use H\u00f6lder's inequality to obtain the estimate\nY\nP\n2\n2\n2\nEk [eK\u03b2qij ]1/K \u2264 max Ek [eK\u03b2qij ]\n(7.4)\nEk [eg ] \u2264 Ek [e i<j qij ] \u2264\ni<j\n\ni<j\n\nwith K = k(k \u2212 1)/2. Next we rewrite the expectation on the right hand side as\nZ \u221e\n\u221a\n2\n1\nx2\nEk [eK\u03b2qij ] = \u221a\n(7.5)\ne\u2212 2 Ek [e 2K\u03b2qij x ]dx.\n2\u03c0 \u2212\u221e\nBut now we can calculate the expectation exactly. Together with the inequality\ncosh(y) \u2264 exp(y 2 /2), this leads to the estimate\n\u0010\n\u0011n\n\u0011\n\u0010\n\u221a\np\nEk [e 2K\u03b2qij x ] = cosh( 2K\u03b2xn\u22121 ) \u2264 exp K\u03b2x2 n\u22121 .\nInserting this into (7.5) and (7.4), we have\nZ \u221e\n\u22121 x2\n1\n1\n1\n= p\ne\u2212(1\u22122K\u03b2n ) 2 dx = p\n,\nEk [eg ] \u2264 \u221a\n\u22121\n2\u03c0 \u2212\u221e\n1 \u2212 k(k \u2212 1)\u03b2n\u22121\n1 \u2212 2K\u03b2n\n\nthe desired upper bound.\n\n\u0003\n\nHaving established the above lemma, we are now ready to prove Lemma 4.1.\nP\nProof of Lemma 4.1. Let f1 (\u03c3 (1) , . . . , \u03c3 (k) ) = i6=j q\u0303ij and f = f1 + R, and define\nF (\u03b2) = Ek [e\u03b2f ], F1 (\u03b2) = Ek [e\u03b2f1 ], and F2 (\u03b2) = Ek [e\u03b2R ].\n\nSince (by (4.10))\n\u0010 k(k \u2212 1)\n\u0011\nF1 (\u03b2n ) = exp\n\u03b2n2 + O(\u03b2n3 n\u22122 ) ,\nn\n3\n\n\u22122\n\nwe only have to prove that F (\u03b2n ) = F1 (\u03b2n )eO(\u03b2n n\n\n)+o(1)\n\n(7.6)\n\nwhenever \u03b2n = o(n).\n\n\f36\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nLet \u01ebn = 2k(k \u2212 1)C \u03b2nn where C is the constant from Lemma 4.1. Applying\nH\u00f6lder's inequality to Ek [ef ] we obtain\n\u01ebn\n1\n1 + \u01ebn 1+\u01eb\n) n\nF (\u03b2n ) \u2264 F1 (\u03b2n (1 + \u01ebn )) 1+\u01ebn F2 (\u03b2n\n\u01ebn\nand hence\n1\n\u01ebn\nF (\u03b2n )\n1 + \u01eb 1+\u01eb\nF1 (\u03b2n (1 + \u01ebn )) 1+\u01ebn\n\u2264\nF2 (\u03b2n\n) n.\nF1 (\u03b2n )\nF1 (\u03b2n )\n\u01eb\nUsing equation (7.6) one obtains\n1\n\nF1 (\u03b2n (1 + \u01ebn )) 1+\u01ebn\n= exp(\u03b2n2 \u01ebn n\u22121 + O(\u03b2n3 /n2 )) = exp(O(\u03b2n3 /n2 )).\nF1 (\u03b2n )\n2\nRecalling that |R| \u2264 Cqmax\n, we would like to use Lemma 7.1 to bound the second\n\u03b2n\nn\nfactor. To this end, we need to guarantee that k(k \u2212 1) 1+\u01eb\n\u01ebn C n < 1. By our choice\nof \u01ebn this will be the case as soon as n is large enough to ensure that \u01ebn < 1. For\nn large enough, we therefore have\n\u01ebn\n\u0010\n\u01eb\n1 + \u01eb 1+\u01eb\n1 + \u01ebn \u03b2n \u0011\u2212 2(1+\u01eb\nn)\nF2 (\u03b2n\nC\n)\n\u2264 1 \u2212 k(k \u2212 1)\n= exp(O(\u03b2n /n)).\n\u01eb\n\u01ebn\nn\nPutting everything together, we get\n\u0010\n\u0011\n\u0010\n\u0011\nF (\u03b2n )\n\u2264 exp O(\u03b2n3 /n2 ) + O(\u03b2n n\u22121 ) = exp O(\u03b2n3 /n2 ) + o(1) .\nF1 (\u03b2n )\n\u22121\n\nApplying H\u00f6lder's inequality to Ek [e(1+\u01ebn ) \u03b2n (f \u2212R) ] we obtain that\n\u0010 \u03b2 \u0011\u01ebn\n\u0010 \u03b2 \u00111+\u01ebn\nn\nn\n\u2264 F (\u03b2n )F2 \u2212\n.\nF1\n1 + \u01ebn\n\u01ebn\nThis implies that\n1\nF1 ((1 + \u01ebn )\u22121 \u03b2n )1+\u01ebn\nF (\u03b2n )\n\u2265\n.\nF1 (\u03b2n )\nF1 (\u03b2n )\nF2 (\u2212\u03b2n \u01eb1n )\u01ebn\n\nProceeding along similar lines as for the upper bound, we obtain that\n\u0010\n\u0011\nF (\u03b2n )\n\u2265 exp O(\u03b2n3 /n2 ) + o(1) .\nF1 (\u03b2n )\nCombining the two applications of H\u00f6lder's inequality we finally obtain that\n\u0010\n\u0011\nF (\u03b2n )\n= exp O(\u03b2n3 /n2 ) + o(1) .\nF1 (\u03b2n )\nThis completes the proof of the lemma.\n\u0003\n8. Summary and Outlook\n8.1. Summary of Results. In this paper, we considered the local REM conjecture\nof Bauke, Franz and Mertens, for both the Npp and the SK spin glass model. For\nthe Npp we showed that the local REM conjecture holds for energy scales \u03b1n of\norder o(n1/4 ), and fails if \u03b1n grows like \u03ban1/4 with \u03ba > 0. For the SK model we\nestablished a similar threshold, showing that the local REM conjecture holds for\nenergies of order o(n), and fails if the energies grow like \u03ban with \u03ba > 0 sufficiently\nsmall.\nAlthough we believe that the local REM conjecture also fails for still faster\ngrowing energy scales, our analysis did not allow us to make this rigorous since\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n37\n\nwe could not exclude that the moments of the energy spectrum diverge, while the\nspectrum itself undergoes a re-entrance transition and converges again to Poisson\nfor faster growing energy scales.\n8.2. Proof Strategy. Before discussing possible extensions, let us recall our proof\nstrategy. Both the proof of Poisson convergence, and the proof that Poisson convergence fails after a certain point, relied on a precise asymptotic analysis of the\nfactorial moments.\nFor the purposes of this discussion, let us restrict to the one-dimensional factorial\nmoments E[(Zn (an , bn ))k ] of the number of points in the energy spectrum between\nsome an and bn in the vicinity of \u03b1n . We expressed these factorial moments in\nterms of the probability that the energies E(\u03c3 (1) ), . . . , E(\u03c3 (k) ) of k pairwise distinct\nconfigurations \u03c3 (1) , . . . , \u03c3 (k) all lie in the interval [an , bn ], see (3.11).\nThe technical meat of our proof then consisted of two steps: a bound on the\nsum over \"atypical configurations\" (see Lemmas 3.4 and 6.1), and a proof that\nfor typical configurations, the probability that the energies of \u03c3 (1) , . . . , \u03c3 (k) all\nlie in the interval [a, b] is asymptotically equal to the product of the probabilities\nP(E(\u03c3 (i) \u2208 [an , bn ])).\nFor both the Npp and the SK model, the value of the threshold can already be\nunderstood by considering the factorization properties of typical configurations, see\n(3.24). Taking, e.g., the case k = 2, our results say that for typical configurations\nin the Npp with Gaussian noise, we have factorization up to a factor\n2\n\ne\u03b1n (q+O(q\n\n2\n\n))\n\n(1 + o(1)),\n\n(8.1)\n\nwhere q is the overlap between the two configurations. Since the overlap between\ntypical configurations is of order n\u22121/2 , we obtain factorization if and only if \u03b1n =\no(n1/4 ). To obtain the same result for the Npp with general distribution was much\nmore work, since it required establishing a large deviation density estimate for k a\npriori highly dependent variables, but the heuristic for the threshold of n1/4 is still\nthe same.\nBy contrast, the threshold for the SK model is easier to establish than that for\nthe Npp. The main reason is the restriction to Gaussian noise, which made the\nproof of a large deviation density estimate unnecessary, in addition to simplifying\nthe proof of the bound on atypical configurations. But on a heuristic level, there is\nnot much of a difference: now we obtain factorization up to multiplicative factor of\n\u03b12\nn\n\n2\n\n4\n\ne n (q +O(q )) (1 + o(1)),\ngiving the threshold of \u03b1n = o(n) for Poisson convergence.\n\n(8.2)\n\n8.3. p-Spin models. In the physics literature, one often considers a generalization\nof the SK model which involves interactions between p different spins, instead of\nthe two-body interaction of the standard SK model. For our purpose, these p-spin\nSK models are best defined as Gaussian fields indexed by the spin configurations\n\u03c3 \u2208 {\u22121, +1}n. Recalling that a Gaussian field is uniquely defined by its mean\nand covariance matrix, we then define the p-spin SK-Hamiltonian H (p) (\u03c3) as the\nGaussian field with mean 0 and covariance matrix E[H (p) (\u03c3)H (p) (\u03c3\u0303)] = nq(\u03c3, \u03c3\u0303)p\nwhere p = 1, 2, . . . , and q(*, *) is the overlap defined in (1.2). Note that the energy\nof the Npp with Gaussian\n\u221a noise is nothing but the\u221aabsolute value of the p = 1 SK\nHamiltonian divided by n. Up to a rescaling by n, the energy spectrum of the\n\n\f38\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\nNpp with Gaussian noise is therefore identical to the positive energy spectrum of\nthe p = 1 SK model.\nIt was shown in [BK05a] that the local REM conjecture holds for p = 1 if\n\u03b1n = O(n3/4\u2212\u01eb ) for some \u01eb > 0, and for p \u2265 2 if \u03b1n = O(n1\u2212\u01eb ). For p = 1, 2 our\nresults establish a little bit more, namely the validity of the REM conjecture for\n\u03b1n = o(n3/4 ) if p = 1, and for \u03b1n = o(n) if p = 2. More importantly, our results\nprove that these are actually the thresholds for the validity of the REM conjecture.\nThis raises the question about the true threshold for p \u2265 3. Starting with the\nfactorization properties for typical configurations, one easily sees that the joint\ndensity of H(\u03c3 (1) ), . . . , H(\u03c3 (k) ) is again given by a formula of the form (3.32),\nwhere C is now the matrix with matrix element Cij = n(q(\u03c3 (i) , \u03c3 (j) ))p . This then\nleads to factorization up to a multiplicative error term\ne\n\n\u03b12\nn\nn\n\np\nO(qmax\n)\n\n(1 + o(1)),\n\n(8.3)\n\nwhere qmax is the maximal off-diagonal overlap of \u03c3 (1) , . . . , \u03c3 (k) . If \u03b1n = O(n), this\ngives factorization for typical configurations as long as p > 2. But unfortunately,\nour control over atypical configurations is not good enough to allow a proof of the\nREM conjecture for energies that grow that fast. Indeed, it is easy to see that\nLemma 6.1 can be generalized to p > 2; but an application of the lemma to control\nthe error for the k th factorial moment requires the condition \u03b1n \u2264 n\u01ebk where \u01ebk is\na positive constant that goes to zero as k \u2192 \u221e.\nWe therefore see that our methods can easily be used to prove the local REM\nconjecture for \u03b1n = o(n3/4 ) and p = 1 as well as \u03b1n = o(n) and all p \u2265 2, but they\nare not strong enough to answer the question whether this is the actual threshold\nfor p \u2265 3, or whether the REM conjecture remains valid if p \u2265 3 and \u03b1n grows like\nn\u03ba for some small \u03ba > 0.\nAn even more challenging question is the question of what happens after the\nlocal REM conjecture fails. This question seems quite hard, and so far it has only\nbeen answered for the hierarchical GREM-model. For this model it has been shown\n[BK05b, BK05c] that the suitably rescaled energy spectrum converges to a mixed\nPoisson process with density given in terms of a Poisson cascades on Rl , where\nthe dimension l becomes larger and larger as \u03ba passes through an infinite series of\nthresholds, the first threshold being the value where the local REM conjecture fails\nfor the GREM.\n8.4. A Simple Heuristic. Returning now to the Npp, we note that the rigorous\nmoment analysis of the threshold is somewhat unintuitive and rather involved.\nAlternatively, let us present a simple heuristic to explain the threshold scale n1/4 .\nTo this end it is useful to introduce the gauge invariant magnetization\n1X\n\u03c3i sgnXi ,\nM (\u03c3) =\nn\nf(\u03c3) = \u221anM (\u03c3) and the \"signed\" energy\nand consider the joint distribution of M\nH(\u03c3) introduced in (3.7) with, as usual, X1 , . . . , Xn chosen i.i.d. with density \u03c1,\nand \u03c3 chosen uniformly at random.\nf(\u03c3) and H(\u03c3) is easily calculated to be\nThe covariance matrix C of M\n\u0014\n\u0015\n1 \u03bc\nC=\n\u03bc 1\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n39\n\nwhere \u03bc = E[|X1 |] < 1, and its inverse C \u22121 is given by\nC \u22121 =\n\n\u0014\n\u0015\n1\n1 \u2212\u03bc\n.\n1 \u2212 \u03bc2 \u2212\u03bc 1\n\nf(\u03c3) and H(\u03c3) obeys a local\nAssuming, for the moment, that the joint density of M\nlimit theorem, we now approximate this density by the Gaussian density\n2 \u22121 f 2 \u22121\n1\n1\nf\n\u221a\ne\u2212 2 (H C11 +M C22 +2H M C12 )\n2\u03c0 det C\n1\nf 2 \u2212\u03bcH M\nf)\n1\n(H 2 +M\n\u2212\n\u221a\n=\ne 2(1\u2212\u03bc2 )\n2\u03c0 det C\n1\nf \u2212\u03bcH)2\n2 \u2212\n1\n1\n(M\n\u221a\n.\n=\ne\u2212 2 H e 2(1\u2212\u03bc2 )\n2\u03c0 det C\n\nf) =\ng(H, M\n\n(8.4)\n\nf conditioned on H = \u03b1 is therefore\nIn this approximation, the distribution of M\nGaussian with mean \u03b1\u03bc and covariance\n1 \u2212 \u03bc2 , implying in particular that the\n\u221a\nexpectation of M is equal to \u03b1\u03bc/ n.\nConsider now two configurations \u03c3, \u03c3 \u2032 , both chosen uniformly at random among\nall configurations with magnetization M . Then the expected overlap between \u03c3\nand \u03c3 \u2032 is M 2 (1 + o(1)).\nFinally, consider two configurations \u03c3, \u03c3 \u2032 both chosen uniformly at random\namong all configurations with signed energies in the range H \u2208 [\u03b1, \u03b1 + d\u03b1], for\nsome small d\u03b1. Since the energies of \u03c3 and \u03c3 \u2032 are correlated, it follows that\ntheir magnetizations are also correlated. Under the assumptions that (1) the\nf) obeys a local limit theorem, as in (8.4), and (2) the\njoint distribution g(H, M\nonly correlation between these configurations is due to the correlation in their\nmagnetizations, it would follow that the expected overlap E[q(\u03c3, \u03c3 \u2032 )] is given by\nM 2 (1 + o(1)) = \u03b12 \u03bc2 /n(1 + o(1)).\nNote that the above heuristic focuses on the \"signed energy\" H(\u03c3) rather than\nthe true energy E(\u03c3) = |H(\u03c3)|. Conditioning instead on E(\u03c3), E(\u03c3 \u2032 ) \u2208 [\u03b1, \u03b1+d\u03b1],\nthe above heuristic therefore suggests a bimodal distribution of q(\u03c3, \u03c3 \u2032 ) with peaks\nat \u00b1\u03b12 \u03bc2 /n(1 + o(1)).\nby\n\u221a\n\u221a Now recall that the local REM conjecture says that the overlap, rescaled\nn, is asymptotically normal. However, our above heuristic says that nq(\u03c3, \u03c3 \u2032 )\ncannot be asymptotically normal for \u03b1 growing like n1/4 or faster, in agreement\nwith our rigorous results. Thus this heuristic correctly predicts the scale at which\nthe REM conjecture breaks down, and suggests that the breakdown could be due\nto correlations in the magnetization of configurations with similar energies of scale\nn1/4 or greater.\nA detailed calculation, however, suggests that we exercise some caution in the\napplication of this heuristic. Although the heuristic correctly predicts the scale of\nthe threshold, and the double peak structure of the overlap at the threshold, it\ndoes not predict the correct position of the peaks when \u03b1 = \u03ban1/4 . Indeed, for this\nscaling, we rigorously showed that the rescaled overlap distribution converges to a\nconvex combination of two Gaussians centered at \u00b1\u03ba2 , in contrast to the heuristic\nprediction of \u00b1\u03ba2 \u03bc2 . This, in turn, suggests that there are additional correlations\nbesides those induced by the magnetization.\n\n\f40\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\n8.5. Algorithmic Consequences. Over twenty years ago, Karmarkar and Karp\n[KK82] gave a linear time algorithm for a suboptimal solution of the number partitioning problem. For i.i.d. weights with densities of the form studied in the\ncurrent paper, the typical energy EKK of the KK solution is of order n\u2212\u03b8(log n) ,\n[KK82, Yak96], while the minimal energy is known to be much smaller [KKLO86,\nLue98, BCP01], namely of order 2\u2212\u03b8(n) .\nThis raises the question of whether one can do better than the KK solution \u2013 a\nquestion which has received much study due to the numerous applications of the\nnumber partitioning problem. This work has led to many different heuristics, but to\nour knowledge no algorithm with guaranteed performance significantly better than\nKK has emerged. In the absence of a good global alternative to KK, one might try\nto base an improved solution of the problem on a local search algorithm starting\nfrom the KK solution. But such an approach is unlikely to produce better results,\nas the following argument shows.\nConsider the random Npp as defined in this paper, and let \u03c3 be a partition with\nenergy E(\u03c3) of the order of EKK , i.e., E(\u03c3) = n\u2212\u03b8(log n) . Let \u03c3\u0303 be a local perturbation of \u03c3, i.e., let \u03c3\u0303 be a configuration such that \u03c3 and \u03c3\u0303 differ on a small subset\nK \u2282 {1, . . . , n}, with k = |K| bounded uniformly in n. The signed energies H(\u03c3)\nand H(\u03c3\u0303) then differ by n\u22121/2 \u2206K (\u03c3 K ), where \u2206K (\u03c3 K ) is the random variable\nX\n\u2206K (\u03c3 K ) = 2\n\u03c3i Xi\ni\u2208K\n\nand \u03c3 K is the restriction of \u03c3 to K. Under mild assumptions on the probability\ndensity \u03c1 of the weights X1 , . . . , Xn , the density of \u2206K (\u03c3 K ) is a continuous function\nnear zero, and the probability that |\u2206K | \u2264 \u01eb for some small \u01eb is of order \u03b8(\u01eb) with\nthe constants implicit in the \u03b8 symbol depending only on k.\nObviously, any local improvement algorithm that changes exactly k bits will lead\nto a change in the unsigned energies that is bounded from below by\n(\u2212)\n\n\u03b4k\n\n= n\u22121/2 min min |\u2206K (\u03c3 K )|.\nK:|K|=k \u03c3 K\n\n\u0001\nTaking into account that there are only nk \u2264 nk possible choices for K, we see that\n(\u2212)\nthe probability that \u03b4k \u2264 \u01eb is bounded by O(\u01ebnk+1/2 ). We conclude that with high\n(\u2212)\nprobability, \u03b4k is at least \u03b8(n\u22121/2\u2212k ), much larger than the energy n\u2212\u03b8(log n) of\nour starting configuration \u03c3. Thus any local improvement algorithm that changes\nk bits moves us with high probability far away from the starting configuration with\nenergy of order n\u2212\u03b8(log n) .\nNote that this simple argument does not use very much; in particular, it is not\nrelated to REM conjecture, which suggests a much deeper reason for the apparent\ndifficulty of the Npp. Indeed, applying our local REM Theorem to \u03b1 = EKK , it\nsays that in the vicinity of EKK , the energy behaves like a random cost function of\n2n\u22121 independent random variables. If the energy of the Npp were truly a random\ncost function of 2n\u22121 independent random variables, this would imply that there\nis no algorithm faster than exhaustive search, implying a running time exponential\nin n. But of course, we have not come near to proving anything as strong as this.\nIn fact, even on a non-rigorous level some caution is required when applying\nthe above heuristic. Indeed, only n linear independent configurations \u03c3 (1) , . . . ,\n\u03c3 (n) are needed to completely determine the random variables X1 , . . . , Xn from the\nenergies E(\u03c3 (1) ), . . . , E(\u03c3 (n) ), implying that the energy spectrum lies in a subspace\n\n\fPROOF OF THE LOCAL REM CONJECTURE FOR NUMBER PARTITIONING II\n\n41\n\nof dimension n, not 2n . Still, our REM Theorem proves that the energy spectrum\nbehaves locally like that of a random cost function, suggesting several possible\nconjectures.\nThe first conjecture is best described in an oracle setting, where the oracle, O,\nkeeps the n weights X1 , . . . , Xn secret from the algorithm A. The algorithm is\ngiven the KK-solution \u03c3 (KK) and its energy EKK , and successively asks the oracle\nfor the energy of some configurations \u03c3 (1) , . . . , \u03c3 (m) , where m is bounded. Given\nthis information, the algorithm then calculates a new approximation \u03c3\u0303 6= \u00b1\u03c3 (KK) .\nGiven our REM Theorem, we conjecture that with high probability (tending to one\nas n \u2192 \u221e), the energy of the new configuration \u03c3\u0303 is much larger than EKK ; in\nfact, we conjecture that with high probability E(\u03c3\u0303)/EKK \u2192 \u221e as n \u2192 \u221e.\nThe second conjecture gives the algorithm much more input, namely the l first\nenergies above a threshold \u03b1 and the configurations corresponding to these energies.\nThe task of the algorithm is now to find a new partition \u03c3\u0303 whose energy is as near\npossible to \u03b1, which we assume to grow only slowly with n (say like o(n\u22121/4 ), to stay\nin the realm of our Theorem 2.1). Again, the algorithm has no access to the original\nweights, but may ask the oracle O for the energies of m additional configurations\n\u03c3 (1) , . . . , \u03c3 (m) , adapting the next question to the answer of the preceding ones. For\nm and l bounded uniformly in n, we then conjecture that with high probability the\nalgorithm produces a configuration \u03c3\u0303 with (E(\u03c3\u0303) \u2212 \u03b1)\u03ben\u22121 \u2192 \u221e, while the actual\nvalue of the next configuration above \u03b1 is with high probability equal to \u03b1 + O(\u03ben )\nby our Theorem 2.1.\nOne finally might want to consider the above conjectures in a setting where the\noracle only reveals the relative order of the energies E(\u03c3 (1) ), . . . , E(\u03c3 (m) ), but keeps\nthe numerical values of E(\u03c3 (1) ), . . . , E(\u03c3 (m) ) secret. In such a setting, there is no\na priori reason to assume that m < n. Instead, it seems reasonable to conjecture\ninapproximability results for values of m and l that are polynomial in n.\nAcknowledgement: We thank Keith Ball, Amir Dembo, Laci Lovasz, Yuval Perez,\nDavid Wilson and Avi Widgerson for useful discussions. S.M. was supported in part\nby the German Science Council (grant ME2044/1-1).\nReferences\n[BCP01]\n\nC. Borgs, J.T Chayes, and B. Pittel, Phase transition and finite-size scaling for the\ninteger partitioning problem, Rand. Struct. Alg. 19 (2001), no. 3\u20134, 247\u2013288.\n[BCMN05] C. Borgs, J.T. Chayes, S. Mertens and C. Nair, Proof of the local REM conjecture for\nnumber partitioning I: constant energy scales, arXiv.org/cond-mat/0501760.\n[BFM04] H. Bauke, S. Franz, and S. Mertens, Number partitioning as random energy model, J.\nStat. Mech.: Theor. Exp. (2004), P04003.\n[BM04]\nH. Bauke and S. Mertens, Universality in the level statistics of disordered systems,\nPhys. Rev. E 70 (2004), 025102(R).\n[Bi94]\nP. Billingsley, Probability and Measure, 3rd ed., Wiley series in Probability and Mathematical Statistics, 1994.\n[BK05a]\nA. Bovier and I. Kurkova, Local energy statistics in disorderd systems: a proof of the\nlocal REM conjecture, Preprint, 2005.\n[BK05b] A. Bovier and I. Kurkova, A tomography of the GREM: beyond the REM conjecture,\nPreprint, 2005.\n[BK05c]\nA. Bovier and I. Kurkova, Energy statistics in disordered systems: beyond the REM\nconjecture, In: \"Applications of random matrices in economics and other complex\nsystems\", Krakow, 2005, to appear.\n[Der81]\nB. Derrida, Random-energy model: An exactly solvable model of disordered systems,\nPhys. Rev. B 24 (1981), no. 5, 2613\u20132626.\n\n\f42\n\nCHRISTIAN BORGS1 , JENNIFER CHAYES1 , STEPHAN MERTENS2 , CHANDRA NAIR1\n\n[Der85]\n\nB. Derrida, A generalization of the random-energy model that includes correlations\nbetween energies, J. Rev. Lett. 46 (1985), 401\u2013407.\n[Dan54]\nH.E. Daniels, Saddlepoint approximations in statistics, Ann. Math. Statist. 25 (1954)\n631\u2013650.\n[Mer00]\nS. Mertens, Random costs in combinatorial optimization, Phys. Rev. Lett. 84 (2000),\nno. 7, 1347\u20131350.\n[KK82]\nN. Karmarkar, R.M. Karp, The differencing method of set partitioning Technical Report UCB/CSD 82/113, Computer Science Division (EECS), University of California,\nBerkeley (1982)\n[KKLO86] N. Karmarkar, R.M. Karp, G.S. Lueker and A.M. Odlyzko, Probabilistic anaysis of\noptimum partitioning, J. Appl. Prob. 23 (1986) 626\u2013645.\n[Lue98]\nG.S. Lueker, Exponentially small bounds on the expected optimum of the partition and\nsubset sum problem, Rand. Struc. Alg. 12 (1998) 51\u201362.\n[Yak96]\nB. Yakir, The differencing algorithm LDM for partitioning: a proof of a conjecture of\nKarmakar and karp, Math. of Operations Res., 21 (1996) 85\u201399\n1 Microsoft\n2 Inst.\n\nGermany\n\nResearch, One Microsoft Way, Redmond, WA 98052\n\nf. Theor. Physik, Otto-von-Guericke Universit\u00e4t, PF 4120, 39016 Magdeburg,\n\n\f"}