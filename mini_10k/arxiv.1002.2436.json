{"id": "http://arxiv.org/abs/1002.2436v1", "guidislink": true, "updated": "2010-02-12T14:33:37Z", "updated_parsed": [2010, 2, 12, 14, 33, 37, 4, 43, 0], "published": "2010-02-12T14:33:37Z", "published_parsed": [2010, 2, 12, 14, 33, 37, 4, 43, 0], "title": "Leftover Hashing Against Quantum Side Information", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1002.2383%2C1002.4348%2C1002.2571%2C1002.4814%2C1002.2691%2C1002.1069%2C1002.0384%2C1002.1504%2C1002.4934%2C1002.0736%2C1002.2459%2C1002.4352%2C1002.3926%2C1002.4119%2C1002.3830%2C1002.0540%2C1002.1154%2C1002.2918%2C1002.1917%2C1002.4470%2C1002.1092%2C1002.1343%2C1002.2415%2C1002.2890%2C1002.2160%2C1002.3741%2C1002.1921%2C1002.1401%2C1002.4778%2C1002.1957%2C1002.3012%2C1002.4985%2C1002.3353%2C1002.3290%2C1002.2049%2C1002.2359%2C1002.0163%2C1002.3232%2C1002.2562%2C1002.2328%2C1002.4512%2C1002.2064%2C1002.2117%2C1002.0904%2C1002.2028%2C1002.3977%2C1002.4827%2C1002.2257%2C1002.0391%2C1002.0992%2C1002.4128%2C1002.4507%2C1002.0396%2C1002.1486%2C1002.3018%2C1002.0787%2C1002.2060%2C1002.0072%2C1002.1903%2C1002.3563%2C1002.2187%2C1002.4435%2C1002.1072%2C1002.3105%2C1002.3037%2C1002.4674%2C1002.1560%2C1002.3557%2C1002.3013%2C1002.2436%2C1002.0893%2C1002.5035%2C1002.0760%2C1002.3647%2C1002.4788%2C1002.3415%2C1002.2077%2C1002.0575%2C1002.4497%2C1002.2073%2C1002.5045%2C1002.0054%2C1002.0307%2C1002.3595%2C1002.3324%2C1002.4881%2C1002.3213%2C1002.4307%2C1002.3065%2C1002.2289%2C1002.0907%2C1002.0983%2C1002.0670%2C1002.4042%2C1002.4803%2C1002.3795%2C1002.0158%2C1002.1117%2C1002.1909%2C1002.0148%2C1002.3410&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Leftover Hashing Against Quantum Side Information"}, "summary": "The Leftover Hash Lemma states that the output of a two-universal hash\nfunction applied to an input with sufficiently high entropy is almost uniformly\nrandom. In its standard formulation, the lemma refers to a notion of randomness\nthat is (usually implicitly) defined with respect to classical side\ninformation. Here, we prove a (strictly) more general version of the Leftover\nHash Lemma that is valid even if side information is represented by the state\nof a quantum system. Furthermore, our result applies to arbitrary delta-almost\ntwo-universal families of hash functions. The generalized Leftover Hash Lemma\nhas applications in cryptography, e.g., for key agreement in the presence of an\nadversary who is not restricted to classical information processing.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1002.2383%2C1002.4348%2C1002.2571%2C1002.4814%2C1002.2691%2C1002.1069%2C1002.0384%2C1002.1504%2C1002.4934%2C1002.0736%2C1002.2459%2C1002.4352%2C1002.3926%2C1002.4119%2C1002.3830%2C1002.0540%2C1002.1154%2C1002.2918%2C1002.1917%2C1002.4470%2C1002.1092%2C1002.1343%2C1002.2415%2C1002.2890%2C1002.2160%2C1002.3741%2C1002.1921%2C1002.1401%2C1002.4778%2C1002.1957%2C1002.3012%2C1002.4985%2C1002.3353%2C1002.3290%2C1002.2049%2C1002.2359%2C1002.0163%2C1002.3232%2C1002.2562%2C1002.2328%2C1002.4512%2C1002.2064%2C1002.2117%2C1002.0904%2C1002.2028%2C1002.3977%2C1002.4827%2C1002.2257%2C1002.0391%2C1002.0992%2C1002.4128%2C1002.4507%2C1002.0396%2C1002.1486%2C1002.3018%2C1002.0787%2C1002.2060%2C1002.0072%2C1002.1903%2C1002.3563%2C1002.2187%2C1002.4435%2C1002.1072%2C1002.3105%2C1002.3037%2C1002.4674%2C1002.1560%2C1002.3557%2C1002.3013%2C1002.2436%2C1002.0893%2C1002.5035%2C1002.0760%2C1002.3647%2C1002.4788%2C1002.3415%2C1002.2077%2C1002.0575%2C1002.4497%2C1002.2073%2C1002.5045%2C1002.0054%2C1002.0307%2C1002.3595%2C1002.3324%2C1002.4881%2C1002.3213%2C1002.4307%2C1002.3065%2C1002.2289%2C1002.0907%2C1002.0983%2C1002.0670%2C1002.4042%2C1002.4803%2C1002.3795%2C1002.0158%2C1002.1117%2C1002.1909%2C1002.0148%2C1002.3410&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The Leftover Hash Lemma states that the output of a two-universal hash\nfunction applied to an input with sufficiently high entropy is almost uniformly\nrandom. In its standard formulation, the lemma refers to a notion of randomness\nthat is (usually implicitly) defined with respect to classical side\ninformation. Here, we prove a (strictly) more general version of the Leftover\nHash Lemma that is valid even if side information is represented by the state\nof a quantum system. Furthermore, our result applies to arbitrary delta-almost\ntwo-universal families of hash functions. The generalized Leftover Hash Lemma\nhas applications in cryptography, e.g., for key agreement in the presence of an\nadversary who is not restricted to classical information processing."}, "authors": ["Marco Tomamichel", "Christian Schaffner", "Adam Smith", "Renato Renner"], "author_detail": {"name": "Renato Renner"}, "author": "Renato Renner", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/TIT.2011.2158473", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1002.2436v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.2436v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.2436v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.2436v1", "arxiv_comment": null, "journal_reference": "IEEE Trans. Inf. Theory, 57 (8), 2011", "doi": "10.1109/TIT.2011.2158473", "fulltext": "Leftover Hashing Against Quantum Side Information\nMarco Tomamichel,1, \u2217 Christian Schaffner,2, \u2020 Adam Smith,3, \u2021 and Renato Renner1, \u00a7\n1\n\narXiv:1002.2436v1 [quant-ph] 12 Feb 2010\n\n2\n\nInstitute for Theoretical Physics, ETH Zurich, 8093 Zurich, Switzerland.\nCentrum Wiskunde & Informatica (CWI), Amsterdam, The Netherlands.\n3\nPennsylvania State University, University Park, PA 16802, USA.\n(Dated: October 29, 2018)\n\nThe Leftover Hash Lemma states that the output of a two-universal hash function applied to an\ninput with sufficiently high entropy is almost uniformly random. In its standard formulation, the\nlemma refers to a notion of randomness that is (usually implicitly) defined with respect to classical\nside information. Here, we prove a (strictly) more general version of the Leftover Hash Lemma that\nis valid even if side information is represented by the state of a quantum system. Furthermore,\nour result applies to arbitrary \u03b4-almost two-universal families of hash functions. The generalized\nLeftover Hash Lemma has applications in cryptography, e.g., for key agreement in the presence of\nan adversary who is not restricted to classical information processing.\n\nI.\n\nINTRODUCTION\n\nWe will first consider the task of extracting uniform\nrandomness from a random variable and introduce the\nLeftover Hash Lemma. Following its discussion, we extend the scenario to include side information that is potentially stored in a quantum state.\n\nA.\n\nRandomness Extraction\n\nConsider a random variable X that is partially known\nto an agent, i.e., the agent possesses side information E\ncorrelated to X. One may ask whether it is possible to\nextract from X a part Z that is completely unknown to\nthe agent, i.e., uniform conditioned on E. If yes, what is\nthe maximum size of Z? And how is Z computed?\nThe Leftover Hash Lemma answers these questions. It\nstates that extraction of uniform randomness Z is possible whenever the agent's uncertainty about X is sufficiently large. More precisely, the number l of extractable\nbits is approximately equal to the min-entropy of X conditioned on E, denoted Hmin (X|E) (see Section I B for a\ndefinition and properties). Furthermore, Z can be computed as the output of a function f selected at random\nfrom a suitably chosen family of functions F , called twouniversal family of hash functions (see Section I C for\na definition). Remarkably, the family F can be chosen\nwithout knowing the actual probability distribution of\nX and only depends on the alphabet X of X and the\nnumber of bits l to be extracted.\nLemma 1 (Classical Leftover Hash Lemma). Let X and\nE be random variables and let F be a two-universal family of hash functions with domain X and range {0, 1}l.\n\n\u2217 marcoto@phys.ethz.ch\n\nThen, on average over the choices of f from F , the distribution of the output Z := f (X) is \u2206-close from uniform\nconditioned on E 1 , where\n\u2206=\n\nThe lemma immediately implies that for a fixed joint\ndistribution of X and E, there is a fixed function f that\nextracts almost uniform randomness. More precisely,\ngiven any \u2206 > 0, there exists a function f that produces\nj\n1 k\nl = Hmin (X|E) \u2212 2 log\n2\u2206\n\n(1)\n\nbits that are \u2206-close to uniform and independent of E.2\nThe Leftover Hash Lemma plays an important role in a\nvariety of applications in computer science and cryptography (see, e.g., [1] for an overview). A prominent example is privacy amplification, i.e., the task of transforming\na weakly secret key (over which an adversary may have\npartial knowledge E), into a highly secret key (that is\nuniform and independent of the adversary's information\nE). It was in this context that the use of two-universal\nhashing for randomness distillation has first been proposed [2]. Originally, the analysis was however restricted\nto situations where X is uniform and E is bounded in\nsize. Later, versions of the Leftover Hash Lemma similar to Lemma 1 above have been proved independently\nin [3] and [4]. The term leftover hashing was coined in [5],\nwhere its use for recycling the randomness in randomized\nalgorithms and for the construction of pseudo-random\nnumber generators is discussed (see also [3, 6]).\n\n1\n\n\u2020 c.schaffner@cwi.nl\n\u2021 asmith@cse.psu.edu\n\u00a7 renner@phys.ethz.ch\n\n1 p l\u2212Hmin (X|E)\n.\n2\n2\n\n2\n\nThe distance from uniform \u2206 measures the statistical distance\nof the probability distribution of X given E to a uniform distribution. See Section III for a formal definition.\nWe use log to denote the binary logarithm.\n\n\f2\nB.\n\nQuantum Side Information\n\nA majority of the original work on universal hashing is\nbased entirely on probability theory and side information\nis therefore (often implicitly) assumed to be represented\nby a classical system E (modeled as a random variable).3\nIn fact, since hashing is an entirely \"classical\" process (a\nsimple mapping from a random variable X to another\nrandom variable Z), one may expect that the physical\nnature of the side information is irrelevant and that a\npurely classical treatment is sufficient. This is, however,\nnot necessarily the case. It has been shown, for instance,\nthat the output of certain extractor functions may be\npartially known if side information about their input is\nstored in a quantum device of a certain size, while the\nsame output is almost uniform conditioned on any side\ninformation stored in a classical system of the same size\n(see [7] for a concrete example and [8] for a more general\ndiscussion).4\nHere, we follow a line of research started in [9\u201311] and\nstudy randomness extraction in the presence of quantum\nside information E (which, of course, includes situations\nwhere E is partially or fully classical.) More specifically,\nour goal is to establish a generalized version of Lemma 1\nwhich holds if the system E is quantum-mechanical. For\nthis, we first need to quickly review the notion of minentropy as well as of the notion of uniformity, which need\nto be extended accordingly.\nThe definition of uniformity in the context of quantum\nside information E is rather straightforward. Let Z be\na classical random variable which takes any value z \u2208 Z\nwith probability pz and let E be a quantum system whose\nstate conditioned on Z = z is given by a density operator\n[z]\n\u03c1E on HE . This situation is compactly described by the\nclassical-quantum (CQ) state\nX\n[z]\n\u03c1ZE :=\n(2)\npz |zihz|Z \u2297 \u03c1E ,\nz\u2208Z\n\ndefined on the product space HZ \u2297 HE , where HZ is a\nHilbert space with orthonormal basis {|ziZ }z\u2208Z . We say\nthat Z is uniform conditioned on E if \u03c1ZE has product\nform \u03c9Z \u2297\u03c1E , where \u03c9Z := 1Z /|Z| is the maximally mixed\nstate on HZ . More generally, we say that Z is \u2206-close to\nuniform conditioned on E if there exists a state \u03c3E on E\nfor which the trace distance between \u03c1ZE and \u03c9Z \u2297 \u03c3E is\n\n3\n\n4\n\nIf the side information E is classical, the Leftover Hash Lemma\ncan be formulated without the need to introduce E explicitly\n(see, e.g., [3]). Instead, one may simply interpret all probability\ndistributions as being conditioned on a fixed value of the side\ninformation.\nNote that there is no sensible notion of a conditional probability\ndistribution where the conditioning is on the state of a quantum\n(as opposed to a classical ) system. An implicit treatment of side\ninformation E, where one considers all probability distributions\nto be conditioned on a specific value of E, as explained in the\nprevious footnote, is therefore not possible in the general case.\n\nat most \u2206 (see Section III for a formal definition). The\ntrace distance is a natural choice of metric because it corresponds to the distinguishing advantage.5 Furthermore,\nin the purely classical case, the trace distance reduces to\nthe statistical distance.\nNext, we generalize the notion of min-entropy to situations involving quantum side information. Before we do\nthis, note that the classical min-entropy Hmin (X|E) has\nan operational interpretation as the guessing probability\nof X given E, namely\nHmin (X|E) = \u2212 log pguess (X|E) .\n\n(3)\n\nHere, pguess (X|E) denotes the probability of correctly\nguessing the value of X using the optimal strategy with\naccess to E. The optimal strategy in the classical case is\nto guess, for each value of e of E, the X with the highest\nconditional probability PX|E=e . The guessing probability is thus\nX\npguess (X|E) =\nPE (e) max PX|E=e (x) .\ne\n\nx\n\nA generalization of the min-entropy to situations where E\nmay be a quantum system has first been proposed in [10]\n(see Section II for a formal definition). As shown in [13],\nthe operational interpretation (3) naturally extends to\nthis more general case. In other words, the min-entropy,\nHmin (X|E), is a measure for the probability of guessing\nX using an optimal strategy with access to the quantum\nsystem E.\nHowever, the actual requirement on the entropy measure used in Lemma 1 is that it accurately characterizes\nthe total amount of randomness contained in X, i.e. the\nnumber of uniformly random bits that can be extracted\nusing an optimal extraction strategy. As we will show\nbelow, Hmin (X|E) (or, more precisely, a smooth version\nof it) meets this requirement.\nFor this purpose, let \u03c1XE be fixed and assume that\nf is a function that maps X to a string Z = f (X) \u2208\n{0, 1}l of length l that is uniform conditioned on the\nside information E. Then, obviously, the probability of\nguessing Z correctly given E is equal to 2\u2212l and, by\nvirtue of (3), we find that\nHmin (Z|E) = l .\n\n(4)\n\nFurthermore, the probability of guessing Z = f (X) correctly cannot be smaller than the probability of guessing\nX, correctly. This fact can again be expressed in terms\nof min-entropies,\nHmin (Z|E) \u2264 Hmin (X|E) ,\n\n5\n\n(5)\n\nLet psucc be the maximum probability that a distinguisher, presented with a random choice of either the state \u03c1 or the state\n\u03c3, can correctly guess which of the two he has seen. The distinguishing advantage is then defined as the advantage compared\nto a random guess, which is given by psucc \u2212 12 = 14 k\u03c1 \u2212 \u03c3k1 (see\ne.g. [12])\n\n\f3\ni.e., the min-entropy can only decrease under the action\nof a function. Combining (4) and (5) immediately yields\nl \u2264 Hmin (X|E) .\n\n(6)\n\nWe conclude that the number l of uniform bits (relative to E) that can be extracted from data X is upper\nbounded by the min-entropy of X conditioned on E. This\nresult may be seen as a converse of (1).\nSo far, the claim (6) is restricted to the extraction\nof perfectly uniform randomness. In order to extend\nthis concept to the more general case of approximately\nuniform randomness, we need to introduce the notion\nof smooth min-entropy. Roughly speaking, for any\n\u03b5 \u2265 0, the \u03b5-smooth min-entropy of X given E, de\u03b5\nnoted Hmin\n(X|E), is defined as the maximum value of\nHmin (X|E) evaluated for all density operators \u03c1\u0303 that are\n\u03b5-close to \u03c1 (see Section II for a formal definition).\nThe above argument leading to (6) can be generalized\nin a straightforward manner to smooth min-entropy, and\nresults in the bound\nl\u2264\n\n\u221a\n2 \u2206\nHmin\n(X|E)\n\nfor the maximum number l of extractable bits that are\n\u2206-close to uniform conditioned on E. Crucially, our extended version of the Leftover Hash Lemma implies that\nthis bound can be reached, up to additive terms of order log(1/\u2206) (see Theorem 6 and Theorem 7). We thus\nconclude that the min-entropy of X conditioned on E,\nin particular its \"smoothed\" version, is an accurate measure for the amount of uniform randomness (conditioned\non E) that can be extracted from X.\nC.\n\nAlmost Two-Universal Hashing\n\nThe notion of two-universal hashing has been introduced by Carter and Wegman [14]. A family F of functions from X to Z is said to be two-universal if, for any\npair of distinct inputs x and x\u2032 , and for f chosen at random from F , the probability of a collision f (x) = f (x\u2032 )\nis not larger than \u03b4 := 1/|Z|. Note that this value for\nthe collision probability corresponds to the one obtained\nby choosing F as the family of all functions with domain\nX and range Z.\nLater, the concept of two-universal hashing has been\ngeneralized to arbitrary collision probabilities \u03b4 [15].\nNamely, a family of functions F from X to Z is called\n\u03b4-almost two-universal if\nPr [f (x) = f (x\u2032 )] \u2264 \u03b4\n\nf \u2208F\n\n(7)\n\nfor any x 6= x\u2032 . A two-universal family as above simply\ncorresponds to the special case \u03b4 = 1/|Z|.\nThe classical Leftover Hash Lemma (Lemma 1) can be\ngeneralized to \u03b4-almost two-universal hash functions [1].\nMore precisely, when extracting an l-bit string from\ndata X, its distance\np from uniform conditioned on E is\nbounded by \u2206 = 12 (2l \u03b4 \u2212 1) + 2l\u2212Hmin (X|E) .\n\nD.\n\nMain result\n\nOur main result is a generalization of the Leftover\nHash Lemma for \u03b4-almost two-universal families of hash\nfunctions which is valid in the presence of quantum side\ninformation. While the statement is new for general\n\u03b4-almost two-universal hash functions, the special case\nwhere \u03b4 = 2\u2212l has been proved previously by one of\nus [10].\nLemma 2 (General Leftover Hash Lemma). Let X be\na random variable, let E be a quantum system, and let\nF be a \u03b4-almost two-universal family of hash functions\nfrom X to {0, 1}l. Then, on average over the choices of\nf from F , the output Z := f (X) is \u2206-close to uniform\nconditioned on E, where\nq\n1\n2\n\u2206 = inf\n(2l \u03b4 \u2212 1) + 2l\u2212Hmin (X|E)+log(2/\u03b5 +1) + \u03b5 .\n\u03b5>0 2\nFurthermore, if \u03b4 \u2264 2\u2212l , i.e., if F is two-universal, then\n\u2206=\n\n1 p l\u2212H (X|E)\nmin\n2\n.\n2\n\n(8)\n\nNote that inserting \u03b4 = 2\u2212l into the first expression for\n\u2206 yields a formula which is less tight than (8). The latter,\ntherefore, requires a separate proof. In the technical part\nbelow, the two claims are formulated more generally for\nthe smooth min-entropy (Theorem 6 and Theorem 7).\n\nE.\n\nApplications and Related Work\n\nQuantum versions of the Leftover Hash Lemma [10]\nfor two-universal families of hash functions have been\nused in the context of privacy amplification against a\nquantum adversary [8, 11]. This application has gained\nprominence with the rise of quantum cryptography and\nquantum key distribution in particular. There, the side\ninformation E is gathered during a key agreement process\nbetween two parties by an eavesdropper who is not necessarily limited to classical information processing. The\nquantum generalization of the Leftover Hash Lemma is\nthen used to bound the amount of secret key that can be\ndistilled by the two parties.\nThe restriction to two-universal families of hash functions leads to the need for a random seed of length \u0398(n),\nwhere n is the length in bits of the original partially secret\nstring. This seed is used to choose f from a two-universal\nfamily F . The main result of this paper, Lemma 2, and a\nsuitable construction of a \u03b4-almost two-universal family\nof hash functions (see Section IV) allow for a shorter seed\n1\n. The length\nof length proportional to l, log nl and log \u2206\nof secret key that can be extracted with this method is\n1\nonly reduced by a term proportional to log \u2206\ncompared\nto the extractor using two-universal hashing. Furthermore, the generalized Leftover Hashing Lemma allows\nfor an extension of existing cryptographic security proofs\n\n\f4\nto \u03b4-almost two-universal families of hash functions and\nmay lead to a speed-up in practical implementations.6\nRecently, the problem of randomness extraction with\nquantum side information has generated renewed interest. It has been shown that the classical technique [18]\nof XORing a classical source about which an adversary\nholds quantum information with a \u03b4-biased mask results\nin a uniformly distributed string [19]7 .\nHowever, to achieve even shorter seed lengths, more\nadvanced techniques such as Trevisan's [21] extractor\nhave been studied in [22\u201324]. In [23], it is shown that\na seed of length O(polylog n) is sufficient to generate a\nkey of length l \u2248 Hmin (X) \u2212 log dim HE , where dim HE is\na measure of the size of the adversary's quantum memory. In [24], the result was extended to the formalism\nof conditional min-entropies. They attain a key length\n\u03b5\nof l \u2248 Hmin\n(X|E), which can be arbitrarily larger than\nHmin (X) \u2212 log dim HE . Furthermore, as we show in (6),\nthis key length is almost optimal. Our result may be useful to further improve the performance of these extractors\n(see discussion in [24]).\nFurthermore, our result should be used instead of the\nclassical Leftover Hashing Lemma whenever randomness\nis extracted in a context governed by the laws of quantum\nphysics. For example, consider a device that needs a seed\nthat is random conditioned on its internal state. In this\ncase the use of the classical Leftover Hashing Lemma\ninstead of its quantum version, Lemma 2, corresponds to\nthe implicit and potentially unjustified assumption that\nthe device does not make use of quantum mechanics.\n\nII.\n\nSMOOTH ENTROPIES\n\nLet H be a finite-dimensional Hilbert space. We use\nL(H), L\u2020 (H) and P(H) to denote the set of linear, Hermitian and positive semi-definite operators on H, respectively. We define the set of normalized quantum states\nby S= (H) := {\u03c1 \u2208 P(H) : tr \u03c1 = 1} and the set of subnormalized states by S\u2264 (H) := {\u03c1 \u2208 P(H) : 0 < tr \u03c1 \u2264\n1}. Given a pure state |\u03c6i \u2208 H, we use \u03c6 = |\u03c6ih\u03c6| to denote the corresponding projector in P(H). The inverse\nof a Hermitian operator is meant to be taken on its support only (generalized inverse). Given a bipartite Hilbert\nspace HAB := HA \u2297 HB and a state \u03c1AB \u2208 S\u2264 (HAB ),\nwe denote by \u03c1A and \u03c1B its marginals \u03c1A = trB \u03c1AB and\n\u03c1B = trA \u03c1AB .\nThe trace distance between states \u03c1 and \u03c4 is given by\n1\n||\u03c1\n\u2212 \u03c4 ||1 = 21 tr |\u03c1 \u2212 \u03c4 |. We also employ the purified\n2\ndistance P as a metric on S\u2264 (H) [26]. It is an upper\nbound on the trace distance and defined in terms of the\ngeneralized fidelity F\u0304 as\nq\nP (\u03c1, \u03c4 ) := 1 \u2212 F\u0304 (\u03c1, \u03c4 )2 , where\np\n\u221a \u221a\nF\u0304 (\u03c1, \u03c4 ) := tr| \u03c1 \u03c4 | + (1 \u2212 tr \u03c1)(1 \u2212 tr \u03c4 ) .\nWe will need that the purified distance is a monotone under trace non-increasing completely positive maps\n(CPMs). Let E be a trace non-increasing CPM, then [26]\nP (\u03c1, \u03c4 ) \u2265 P (E(\u03c1), E(\u03c4 )) .\n\n(9)\n\nNote that the projections \u03c1 7\u2192 \u03a0\u03c1\u03a0 for any projector \u03a0\nis a trace non-increasing CPM. We define the \u03b5-ball of\nstates close to \u03c1 \u2208 S\u2264 (H) as\nF.\n\nOrganization of the paper\n\nIn Section II, we discuss various aspects of the smooth\nentropy framework, which will be needed for our proof.\nWe then give the proof of our generalized Leftover Hash\nLemma (Lemma 2) in Section III. More precisely, we provide statements of the Leftover Hashing Lemma for twouniversal and \u03b4-almost two-universal hashing in terms\nof the smooth min-entropy (Theorems 9 and 10). Finally, in Section IV, we combine known constructions of\n\u03b4-almost two-universal hash functions and discuss their\nuse for randomness extraction with shorter random seeds.\nAppendix B may be of independent interest because it establishes a relation between the smooth min- and maxentropies (as defined above and used in [13, 25, 26]) and\ncertain related entropic quantities used in earlier work\n(e.g., in [10])\n\n6\n7\n\nSee, e.g. [16] and [17], where a practical implementation of privacy amplification is discussed in Section V.\nSee also [20] for a generalization of this work to the fully quantum\nsetting.\n\nB \u03b5 (\u03c1) := {\u03c1\u0303 \u2208 S\u2264 (H) : P (\u03c1, \u03c1\u0303) \u2264 \u03b5} .\nWe will now define the smooth min-entropy [10].\nDefinition 1. Let \u03b5 \u2265 0 and \u03c1AB \u2208 S\u2264 (HAB ). The minentropy of A conditioned on B is given by\nHmin (A|B)\u03c1 :=\n\nmax sup {\u03bb \u2208 R : \u03c1AB \u2264 2\u2212\u03bb 1A \u2297 \u03c3B } .\n\n\u03c3B \u2208S= (HB )\n\nFurthermore, the smooth min-entropy of A conditioned\non B is defined as\n\u03b5\nHmin\n(A|B)\u03c1 :=\n\nmax\n\n\u03c1\u0303AB \u2208B\u03b5 (\u03c1AB )\n\nHmin (A|B)\u03c1\u0303 .\n\nThe conditional min-entropy is a measure of the uncertainty about the state of a system A given quantum side\ninformation B. In particular, if the system A describes a\nclassical random variable (i.e. if the state is CQ), the minentropy can be interpreted as a guessing probability.8 For\n\n8\n\nSee discussion in Section I and [13] for details.\n\n\f5\ngeneral quantum states, the smooth min-entropy satisfies data-processing inequalities. For example, if a CPM\nis applied to the B system or if a measurement is conducted on the A system, the smooth min-entropy of A\ngiven B is guaranteed not to decrease.9\nFinally, we will need a fully quantum generalization of\nthe collision entropy (R\u00e9nyi-entropy of order 2).\nDefinition 2. Let \u03c1AB \u2208 S\u2264 (HAB ) and \u03c3B \u2208 P(HB ),\nthen the collision entropy of A conditioned on B of a\nstate \u03c1AB given \u03c3B is \u2212 log \u0393C (\u03c1AB |\u03c3B ), where\n\u22121/2 \u00012\n\u0393C (\u03c1AB |\u03c3B ) := tr \u03c1AB (1A \u2297 \u03c3B ) .\nWe will use the fact that the collision entropy provides\nan upper bound on the min-entropy. The proof of the\nfollowing statement can be found in Appendix C and\nconstitutes one of the main technical contributions of this\nwork.\nLemma 3. Let \u03c1XB \u2208 S\u2264 (HXB ) be a CQ-state and \u03b5\u0304 > 0.\nThen, there exists a state \u03c3B \u2208 S= (HB ) such that\n\u0393C (\u03c1XB |\u03c3B ) \u2264 2\u2212Hmin (X|B)\u03c1 .\n\n(10)\n\nMoreover, there exists a normalized CQ-state \u03c1\u0304XB \u2208\nB \u03b5\u0304 (\u03c1XB ) such that\n2\n\n\u0393C (\u03c1\u0304XB |\u03c1\u0304B ) \u2264 2\u2212Hmin (X|B)\u03c1 +log( \u03b5\u03042 +1) .\nIII.\n\n(11)\n\nPROOF OF THE LEFTOVER HASH\nLEMMA\n\nIn this section we give bounds on the distance from\nuniform of the quantum state after privacy amplification\nwith two-universal and \u03b4-almost two-universal hashing\n(Theorems 6 and 7). The proof of Lemma 2 then follows.\nFirst, we extend the definition of the distance from\nuniform to sub-normalized states for technical reasons.10\nDefinition 3. Let \u03c1AB \u2208 S\u2264 (HAE ), then we define the\ndistance from uniform of A conditioned on B as\n1\n\u2206(A|B)\u03c1 := min ||\u03c1AB \u2212 \u03c9A \u2297 \u03c3B ||1 ,\n\u03c3B 2\n\n(12)\n\nAs a first step, we bound the distance from uniform in\nterms of the collision entropy.\nLemma 4. Let \u03c1AB \u2208 S\u2264 (HAB ) and \u03c4B \u2208 S\u2264 (HB ) with\nsupp {\u03c4B } \u2287 supp {\u03c1B }, then\nq\n1\n\u22121/2 \u0001\n\u22121/2\n.\ndA \u0393C (\u03c1AB |\u03c4B ) \u2212 tr \u03c1B \u03c4B \u03c1B \u03c4B\n\u2206(A|B)\u03c1 \u2264\n2\n\n9\n\n2 \u2206(A|B)\u03c1 \u2264 ||\u03c1AB \u2212 \u03c9A \u2297 \u03c1B ||1\n\n1/4\n\nSee [26] for precise statements and proofs.\nNote that sub-normalized states have to be considered due to\nour definition of the smoothing of the min-entropy.\n\n1/4\n\n1/2\n\n= ||ABC||1 \u2264 ||A4 ||1 ||B 2 ||1 ||C 4 ||1\nq\n\u22121/2 \u00012\n\u2264 dA tr (\u03c1AB \u2212 \u03c9A \u2297 \u03c1B )(1A \u2297 \u03c4B ) .\n\nWe simplify the expression on the r.h.s. further using\n\u22121/2 \u00012\ntr (\u03c1AB \u2212 \u03c9A \u2297 \u03c1B )(1A \u2297 \u03c4B )\n\u22121/2 \u00012\n\u22121/2 \u00012\n= tr \u03c1AB (1A \u2297 \u03c4B ) + tr (\u03c9A \u2297 \u03c1B )(1A \u2297 \u03c4B )\n\u22121/2 \u0001\n\u22121/2\n\u2212 2tr \u03c1AB (1A \u2297 \u03c4E )(\u03c9A \u2297 \u03c1B )(1A \u2297 \u03c4E )\n1\n\u22121/2 \u0001\n\u22121/2\n= \u0393C (\u03c1AB |\u03c4B ) \u2212\n,\ntr \u03c1B \u03c4B \u03c1B \u03c4B\ndA\nwhich concludes the proof.\nThe above bound can be simplified by setting \u03c4B = \u03c1B :\n\u2206(A|B)\u03c1 \u2264\n\n1p\ndA \u0393C (\u03c1AB |\u03c1B ) \u2212 tr \u03c1B .\n2\n\n(13)\n\nWe now consider a scenario where X is picked from\na set X and E is a quantum system whose state may\ndepend on X. The situation is described by a CQ-state\nof the form\nX\n[x]\n\u03c1XE =\n(14)\n|xihx|X \u2297 \u03c1E ,\nx\n\nwhere the probability of x occurring is the trace of the\nP [x]\n[x]\nsub-normalized state \u03c1E and \u03c1E = x \u03c1E . After applying a function f : X \u2192 {0, 1}\u00d7l chosen at random from\na family of hash functions F , the resulting CQ-state is\ngiven by\nXX\n[f,z]\n\u03c1FZE =\n(15)\npf |f ihf |F \u2297 |zihz|Z \u2297 \u03c1E ,\nf\n\nwhere \u03c9A := 1A / dim HA and the minimum is taken over\nall \u03c3B \u2208 P(HB ) satisfying tr \u03c3B = tr \u03c1B .\n\n10\n\nProof. We apply the H\u00f6lder inequality (Lemma 18 in Appendix A) with parameters r = t = 4, s = 2, A = C =\n1/4\n\u22121/4\n\u22121/4\n1A \u2297\u03c4B and B = (1A \u2297\u03c4B )(\u03c1AB \u2212\u03c9A \u2297\u03c1B )(1A \u2297\u03c4B ).\nThis leads to\n\nz\n\nwhere z \u2208 {0, 1}\u00d7l, pf = 1/|F | and\nX\n[x]\n[f,z]\n\u03c1E .\n\u03c1E :=\n\n(16)\n\nx,f (x)=z\n\nFormally, randomness extraction can be modelled as a\ntrace-preserving CPM, A, from HFX \u2192 HFZ that maps\n\u03c1F \u2297 \u03c1XE 7\u2192 (A \u2297 IE )(\u03c1F \u2297 \u03c1XE ) = \u03c1FZE .\nThe followoing lemma yields a bound on the collision\nentropy of the output of the hash function in terms of\nthe collision entropy of the input.\nLemma 5. Let F be \u03b4-almost two-universal, let \u03c1XE and\n\u03c1FZE be defined as in (14) and (15), respectively, and let\n\u03c4E \u2208 S= (HE ). Then,\n\u22121/2\n\n\u0393C (\u03c1FZE |\u03c1F \u2297 \u03c4E ) \u2264 \u0393C (\u03c1XE |\u03c4E ) + \u03b4 tr (\u03c1E \u03c4E\n\n\u22121/2\n\n\u03c1E \u03c4E\n\n).\n\n\f6\nProof. The collision entropy on the l.h.s. can be rewritten\nas an expectation value over F , that is\n\u0393C (\u03c1FZE |\u03c1F \u2297 \u03c4E )\n\u0010\n\u0011\n1\n1\n= tr \u03c1FZE (pf 1FZ \u2297 \u03c4E )\u2212 /2 \u03c1ZEF (pf 1FZ \u2297 \u03c4E )\u2212 /2\nX\nX\n[f,z] \u22121/2 [f,z] \u22121/2 \u0001\n=\npf\ntr |f ihf |F \u2297|zihz|Z \u2297 \u03c1E \u03c4E \u03c1E \u03c4E\nf\n\n=\n=\n\nE\n\nF \u2208F\n\nX\nx,x\u2032\n\nz\n\nhX\nz\n\nE\n\nF \u2208F\n\ni\n[F,z] \u22121/2 [F,z] \u22121/2\ntr (\u03c1E \u03c4E \u03c1E \u03c4E )\n\nhX\nz\n\ni\n[x] \u22121/2 [x\u2032 ] \u22121/2\n\u03b4F (x)=z \u03b4F (x\u2032 )=z tr (\u03c1E \u03c4E \u03c1E \u03c4E ) .\n[F,z]\n\nin the last step.\nWe have used (16) to substitute for \u03c1E\nThe expectation value can be evaluated using the defining\nproperty (7) of \u03b4-almost two-universal families. We get\ni\nhX\n\u03b4F (x)=z \u03b4F (x\u2032 )=z \u2264 \u03b4\nE\nF \u2208F\n\nz\n\nif x 6= x\u2032 and 1 otherwise. We use this relation and the\nfact that the trace terms are positive to bound\n\u0393C (\u03c1FZE |\u03c1F \u2297 \u03c4E )\nX\nX\n[x] \u22121/2 [x\u2032 ] \u22121/2\n[x] \u22121/2 [x] \u22121/2\n\u2264\ntr(\u03c1E \u03c4E \u03c1E \u03c4E ) .\ntr(\u03c1E \u03c4E \u03c1E \u03c4E ) + \u03b4\nx\n\nx6=x\u2032\n\nWe now complete the second sum with the terms where\nx = x\u2032 to get the statement of the lemma.\nIf we set \u03c4E = \u03c1E , the result can be simplified further:\n\u0393C (\u03c1FZE |\u03c1F \u2297 \u03c1E ) \u2264 \u0393C (\u03c1XE |\u03c1E ) + \u03b4 tr \u03c1E .\n\n(17)\n\nWe are now ready to give a bound on the distance\nfrom uniform \u2206(Z|F E) after privacy amplification with\ntwo-universal and \u03b4-almost two-universal families of hash\nfunctions. Note that we consider the distance from uniform conditioned on F as well as E. This describes the\nsituation where the chosen hash function (the value f ) is\npublished after its use (strong extractor regime).\nThe distance from uniform conditioned on E averaged\nover the choice of f is given by\nX\nX\n[f ]\n[f,z]\npf \u2206(Z|E)\u03c1[f ] , where \u03c1ZE :=\n|zihz|Z \u2297 \u03c1E\n\nTheorem 6. Let F be two-universal and let \u03c1XE and\n\u03c1ZEF be defined as in (14) and (15), respectively. Then,\nfor any \u03b5 \u2265 0,\n\u2206(Z|F E)\u03c1 \u2264 \u03b5 +\n\nProof. We use Lemma 4 to bound \u2206(Z|F E)\u03c1 . In particular, we set \u03c4FE := \u03c1F \u2297 \u03c4E to get\nq\n\u22121/2\n\u22121/2\n2\u2206(Z|F E)\u03c1 \u2264 2l \u0393C (\u03c1ZFE |\u03c4FE ) \u2212 tr (\u03c1E \u03c4E \u03c1E \u03c4E )\nq\n\u2264 2l \u0393C (\u03c1XE |\u03c4E ) ,\nwhere we have used Lemma 5 and that F is two-universal\n(\u03b4 \u2264 2\u2212l ) in the last step. The r.h.s. can be expressed in\nterms of a min-entropy using (10). With an appropriate\nchoice of \u03c4E , we have\np\n2\u2206(Z|F E)\u03c1 \u2264 2l\u2212Hmin (X|E)\u03c1 .\n(19)\nWe have now shown the statement of the theorem for the\ncase \u03b5 = 0.\nFinally, the bound can be expressed in terms of a\nsmooth min-entropy. Let \u03c1\u0303XE \u2208 B \u03b5 (\u03c1XE ) be the CQstate (cf. Lemma 19) that optimizes the smooth min\u03b5\nentropy Hmin\n(X|E)\u03c1 = Hmin (X|E)\u03c1\u0303 . We define \u03c1\u0303FZE :=\n(A \u2297 IE )(\u03c1F \u2297 \u03c1\u0303XE ) and note that privacy amplification\ncan only decrease the purified distance (9), i.e.\n1\n||\u03c1FZE \u2212 \u03c1\u0303FZE ||1 \u2264 P (\u03c1FZE , \u03c1\u0303FZE ) \u2264 P (\u03c1XE , \u03c1\u0303XE ) \u2264 \u03b5 .\n2\nMoreover, let \u03c3\u0303FE be the state that minimizes the distance from uniform du (Z|F E)\u03c1\u0303 . Then,\n2\u2206(Z|F E)\u03c1 \u2264 ||\u03c1FZE \u2212 \u03c9Z \u2297 \u03c3\u0303FE ||1\n\u2264 ||\u03c1FZE \u2212 \u03c1\u0303FZE ||1 + ||\u03c1\u0303FZE \u2212 \u03c9Z \u2297 \u03c3\u0303FE ||1\n\u2264 2\u03b5 + 2\u2206(Z|F E)\u03c1\u0303 .\nWe now apply (19) for \u03c1\u0303FZE (instead of \u03c1FZE ) to get\n1 p l\u2212H (X|E)\u03c1\u0303\nmin\n2\n2\n1 p l\u2212H \u03b5 (X|E)\u03c1\nmin\n=\u03b5+\n,\n2\n2\n\n\u2206(Z|F E)\u03c1 \u2264 \u03b5 +\n\nz\n\nf\n\nand it can be bounded in terms of \u2206(Z|F E) as\nX\nf\n\npf \u2206(Z|E)\u03c1[f ] \u2264\n\n1X\n2\n\nf\n\nwhich concludes the proof.\n\n[f ]\n\npf \u03c1ZE \u2212 \u03c9Z \u2297 \u03c3E\n\n= \u2206(Z|EF )\u03c1 ,\n\n1 p l\u2212H \u03b5 (X|E)\u03c1\nmin\n.\n2\n2\n\nNext, we consider the case of \u03b4-almost two-universal\nhashing.\n\n1\n\n(18)\n\nwhere \u03c3E optimizes (12) for \u2206(Z|EF )\u03c1 . Hence, an upper bound on \u2206(Z|F E) implies an upper bound on the\naverage distance to uniform conditioned on E as well.\nFor two-universal hashing, we get the following bound\n(see also [10]).\n\nTheorem 7. Let F be \u03b4-almost two-universal and let\n\u03c1XE and \u03c1ZEF be defined as in (14) and (15), respectively.\nThen, for any \u03b5 \u2265 0 and \u03b5\u0304 > 0,\n\u2206(Z|F E)\u03c1 \u2264 \u03b5+ \u03b5\u0304+\n\n1\n2\n\nq\n2\n\u03b5\n(2l \u03b4\u22121)+2l\u2212Hmin(X|B)\u03c1 +log( \u03b5\u03042 +1) .\n\n\f7\nProof. We use Lemma 4 as in (13) to bound \u2206(Z|F E)\u03c1 .\nFor normalized \u03c1ZFE , we find\nq\n2\u2206(Z|F E)\u03c1 \u2264 2l \u0393C (\u03c1FZE |\u03c1F \u2297 \u03c1E ) \u2212 1\nq\n\u2264 2l \u0393C (\u03c1XE |\u03c1E ) + (2l \u03b4 \u2212 1) ,\nwhere we used Lemma 5 as stated in (17).\nThe smoothing of the above equation is achieved using\nthe same arguments as in the proof of Theorem 9. However, this time we need to include an additional smoothing parameter \u03b5\u0304 > 0 in order to be able to apply (11).\nLet \u03c1\u0303XE \u2208 B \u03b5 (\u03c1XE ) be the CQ-state (cf. Lemma 19)\n\u03b5\nthat optimizes the smooth min-entropy Hmin\n(X|E)\u03c1 =\nHmin (X|E)\u03c1\u0303 and let \u03c1\u0304XE \u2208 B \u03b5\u0304 (\u03c1\u0303XE ) be the CQ-state\n(cf. Lemma 3) that satisfies\n2\n\n\u0393C (\u03c1\u0304XE |\u03c1\u0304E ) \u2264 2\u2212Hmin (X|E)\u03c1\u0303 +log( \u03b5\u03042 +1)\n=2\n\n\u03b5\n\u2212Hmin\n(X|E)\u03c1 +log( \u03b5\u030422\n\n+1)\n\n.\n\n(20)\n\nThen, \u03c1\u0304XE \u2208 B \u03b5+\u03b5\u0304 (\u03c1XE ) holds due to the triangle inequality of the purified distance. Moreover, we define the state\nafter randomness extraction, \u03c1\u0304FZE := (A \u2297 IE )(\u03c1F \u2297 \u03c1\u0304XE ).\nFollowing the arguments laid out in the proof of Theorem 6, we have\n\u2206(Z|F E)\u03c1 \u2264 \u03b5 + \u03b5\u0304 + \u2206(Z|F E)\u03c1\u0304\nq\n1\n2l \u0393C (\u03c1\u0304XE |\u03c1\u0304E ) + (2l \u03b4 \u2212 1) .\n\u2264 \u03b5 + \u03b5\u0304 +\n2\nThis can be bounded using (20), which concludes the\nproof.\nThe proof of the Leftover Hash Lemma stated in the\nintroduction (Lemma 2) follows when we set \u03b5 = 0 in\nTheorem 9 and Theorem 10. To see this, note that the\nstatements of two theorems can be expressed in terms of\nthe distance from uniform averaged over the choice of f\nusing (18).\n\nIV.\n\nEXPLICIT CONSTRUCTIONS WITH\nSHORTER SEEDS\n\nHere, we combine known constructions of twouniversal and \u03b4-almost two-universal hash functions and\ndiscuss their use for randomness extraction with shorter\nrandom seeds. We consider a scenario where X is an nbit string x \u2208 {0, 1}\u00d7n and E is a quantum system. The\nchallenge is typically to optimize the following parameters:\na) the error described by the distance from uniform,\ne := \u2206(Z|F E), which should be small,\nb) the length of the extracted key, l, which one wants\n\u03b5\nto make as large as possible (close to Hmin\n(X|E))\nand\n\nc) the length of the random seed, s := log |F |, needed\nto choose f , which one wants to keep small.\nThe latter point is important in practical implementations of privacy amplification, for example in quantum\nkey distribution (QKD), where the choice of f has to be\ncommunicated between two parties.\nWe will first review the explicit constructions of (\u03b4almost) two-universal hash functions used in this section.\nIn [14], Carter and Wegman proposed several constructions of two-universal function families, trying to minimize the size of F . An example of a two-universal set of\nhash functions with |F | = 2n is the set F = {f\u03b1 }\u03b1\u2208{0,1}n\nconsisting of elements\nf\u03b1 : {0, 1}n \u2212\u2192\n{0, 1}l\nx\n7\u2212\u2192 x * \u03b1 mod 2l\n\n(21)\n\nwhere x*\u03b1 denotes the multiplication in the field GF(2n ).\nThe fact that F is two-universal can be readily verified\nby considering the difference f\u03b1 (x) \u2212 f\u03b1 (x\u2032 ) = (x \u2212 x\u2032 ) * \u03b1\nmod 2l and noting that the mapping \u03b1 7\u2192 (x \u2212 x\u2032 ) * \u03b1 is\na bijection if x \u2212 x\u2032 6= 0.\nWith \u03b4-almost two-universal families, a larger value of\n\u03b4 typically allows for a smaller set F . This is nicely illustrated by the following well-known construction based\non polynomials. Let F be an arbitrary field and let r be\na positive integer. We define the family F = {f\u03b1 }\u03b1\u2208F of\nfunctions\nf\u03b1 :\n\nFr\n\u2212\u2192 P\nF\nr\nr\u2212i\n(x1 , . . . , xr ) 7\u2212\u2192\nx\n.\ni=1 i \u03b1\n\n(22)\n\nUsing the fact that a polynomial of degree r \u2212 1 can only\nhave r \u2212 1 zeros, it is easy to verify that F is \u03b4-almost\ntwo-universal, for \u03b4 = (r \u2212 1)/|F|.\nAnother method to construct \u03b4-almost two-universal\nfamilies of hash functions is to concatenate two such families. We will use the following lemma by Stinson (see\nTheorem 5.4 in [15]).\nLemma 8. Let F1 be \u03b41 -almost two-universal from\n{0, 1}\u00d7n to {0, 1}\u00d7k and let F2 be \u03b42 -almost twouniversal from {0, 1}\u00d7k to {0, 1}\u00d7l. Then, the family\nG := {f2 \u25e6 f1 : f1 \u2208 F1 , f2 \u2208 F2 } consisting of all concatenated hash functions is (\u03b41 +\u03b42 )-almost two-universal.\nCombining the general results on \u03b4-almost twouniversal hashing of Section III with the explicit constructions described above, we obtain the following statements.\nIf we do not care about s, we may choose a twouniversal family of hash functions and recover a result\nby Renner [10]:\nTheorem 9. There exists a family of hash functions\nfrom {0, 1}\u00d7n to {0, 1}\u00d7l satisfying\ns = n and e \u2264 \u03b5 +\n\n1 p l\u2212H \u03b5 (X|E)\u03c1\nmin\n2\n2\n\nfor any \u03b5 \u2265 0.\n\n\f8\nProof. We apply Theorem 6 using the two-universal family constructed in (21), which yields s = log |F | = n.\nWe now show that we can choose a family of hash\nfunctions such that s is proportional to the key length l\ninstead of the input string length n.\nTheorem 10. There exists a family of hash functions\nfrom {0, 1}\u00d7n to {0, 1}\u00d7l satisfying\n2\n\ns = 2\u230al + log(n/l) + log(1/\u03b5 ) \u2212 1\u230b and\nq\n2\n\u03b5\n1\ne \u2264 3\u03b5 +\n2l\u2212Hmin (X|E)\u03c1 +log( \u03b52 +1) for any \u03b5 > 0.\n2\nProof. We use the standard classical way of concatenating two hash functions to obtain the required parameters [27]. For the first function, we set k = \u230al +\nlog(n/l) + log(1/\u03b52 )\u230b and use the field F = GF(2k ) in\nthe polynomial-based hash construction from (22). Interpreting the n-bit strings as r = \u2308n/k\u2309 blocks of k bits,\nthe first hash function maps from {0, 1}\u00d7n to {0, 1}\u00d7k\nand requires a k-bit seed. Then, regular two-universal\nhashing from (21) with a seed length of again k bits is\nused to map from {0, 1}\u00d7k to {0, 1}\u00d7l. The two seed\nlengths add up to s = 2k = 2\u230al + log(n/l) + log(1/\u03b52 )\u230b.\nPolynomial-based hashing achieves a \u03b41 of at most\nr\u22121\nn\n4 l \u03b52\n4\u03b52\n\u2264\n\u2264\n\u2264 l\nk\nk\nl\n2\nk2\nk2\n2\nby the choice of r and the fact that k \u2265 l + log(n/l) +\nlog(1/\u03b52 ) \u2212 2. Together with the \u03b42 \u2264 2\u2212l from the twouniversal hashing, we get from Lemma 8 that this con2\n-almost two-universal\nstruction yields a \u03b41 + \u03b42 \u2264 1+4\u03b5\n2l\nfamily of hash functions. Inserting this expression for \u03b4\ninto Theorem 7 and setting \u03b5\u0304 = \u03b5 yields\nq\n2\n\u03b5\n1\n2l\u2212Hmin (X|E)\u03c1 +log( \u03b52 +1) + 4\u03b52 .\ne \u2264 2\u03b5 +\n2\nThe theorem then follows as an upper bound to this expression.\nAcknowledgment\n\nWe thank Roger Colbeck and Johan \u00c5berg for useful discussions and comments. MT and RR acknowledge support from the Swiss National Science Foundation (grant No. 200021-119868). CS is supported by a\nNWO VICI project.\nAppendix A: Technical Results\n\nThe first lemma is an application of Uhlmann's theorem [28] to the purified distance11 (see [26] for a proof).\n\n11\n\nThe main advantage of the purified distance over the trace distance is that we can always find extensions and purifications\n\nLemma 11. Let \u03c1, \u03c4 \u2208 S\u2264 (H), H\u2032 \u223c\n= H and \u03c6 \u2208 H \u2297 H\u2032\nbe a purification of \u03c1. Then, there exists a purification\n\u03b8 \u2208 H \u2297 H\u2032 of \u03c4 with P (\u03c1, \u03c4 ) = P (\u03c6, \u03b8).\nCorollary 12. Let \u03c1, \u03c4 \u2208 S\u2264 (H) and \u03c1\u0304 \u2208 S\u2264 (H \u2297 H\u2032 )\nbe an extension of \u03c1. Then, there exists an extension\n\u03c4\u0304 \u2208 S\u2264 (H \u2297 H\u2032 ) of \u03c4 with P (\u03c1, \u03c4 ) = P (\u03c1\u0304, \u03c4\u0304 ).\nIn the following, we apply this result to an \u03b5-ball of\npure states, Bp\u03b5 (\u03c1) := {\u03c1\u0303 \u2208 B \u03b5 (\u03c1) : rank \u03c1\u0303 = 1}.\nCorollary 13. Let \u03c1 \u2208 S\u2264 (H) and \u03c6 \u2208 H \u2297 H\u2032 be a\npurification of \u03c1. Then,\nB \u03b5 (\u03c1) \u2287 {\u03c1\u0303 \u2208 S\u2264 (H) : \u2203 \u03c6\u0303 \u2208 Bp\u03b5 (\u03c6) s.t. \u03c1\u0303 = trH' \u03c6\u0303}\nand equality holds if the Hilbert space dimensions satisfy\ndim H\u2032 \u2265 dim H.\nThe following lemma establishes a fundamental property of pure bipartite states, namely that every linear operator applied to one subsystem has a dual on the other\nsubsystem, such that the resulting pure state is the same.\nLemma 14. Let \u03c6AB \u2208 P(HAB ) be pure, \u03c1A = trB \u03c6AB ,\n\u03c1B = trA \u03c6AB and let X \u2208 L(HA ) be an operator with\nsupport and image in supp {\u03c1A }. Then,\n\u0001\n1/2\n\u22121/2 \u0001\nX \u2297 1B |\u03c6iAB = 1A \u2297 (\u03c1B X T \u03c1B ) |\u03c6iAB ,\n\nwhere the transpose is taken with regard to the Schmidt\nbasis of \u03c6AB .\nProof. We introduce the Schmidt decomposition |\u03c6iAB =\nP \u221a\nP\n\u22121/2 \u0001\n|\u03c6iAB = i |iiA \u2297\n\u03bbi |iiA \u2297|iiB . Clearly, 1A \u2297\u03c1B\ni\n|iiB =: |\u03b3iAB is the (unnormalized) fully entangled state\non the support of \u03c1A and \u03c1B . It is easy to verify that\nT\n(X \u2297 1B )|\u03b3iAB = (1A \u2297 XP\n)|\u03b3iAB , where the transposed\nT\nmatrix is given by X = i,j hi|X|jiA |jihi|B .\nCorollary 15. Let \u03c6AB \u2208 P(HAB ) be pure, \u03c1A = trB \u03c6AB ,\n\u03c1B = trA \u03c6AB and f : R+ \u2192 R a real-valued function, then\n\u0001\n\u0001\nf (\u03c1A ) \u2297 1B |\u03c6iAB = 1A \u2297 f (\u03c1B ) |\u03c6iAB .\nWe define the notion of a dual projector with regard\nto a pure state using the following corollary:\nCorollary 16. Let |\u03c6iAB \u2208 HAB be pure, \u03c1A = trB \u03c6AB ,\n\u03c1B = trA \u03c6AB and let \u03a0A \u2208 P(HA ) be a projector in\nsupp {\u03c1A }. Then, there exists a dual projector \u03a0B on\nHB such that\n\u22121/2 \u0001\n\n\u03a0A \u2297 \u03c1B\n\n\u22121/2\n\n|\u03c6iAB = \u03c1A\n\n\u0001\n\u2297 \u03a0B |\u03c6iAB .\n\nThe next Lemma gives a bound on the purified distance\nof a state \u03c1 and a projected state \u03a0\u03c1\u03a0.\n\nwithout increasing the distance.\n\n\f9\nLemma 17. Let \u03c1 \u2208 S\u2264 (H) and \u03a0 a projector on H,\nthen\n\u0001 q\nP \u03c1, \u03a0\u03c1\u03a0 \u2264 2 tr(\u03a0\u22a5 \u03c1) \u2212 tr(\u03a0\u22a5 \u03c1)2 ,\n\nF\u0304 (\u03c1, \u03a0\u03c1\u03a0) \u2265 tr(\u03a0\u03c1) + 1 \u2212 tr \u03c1 = 1 \u2212 tr(\u03a0\u22a5 \u03c1) .\n\nwhere we used Klein's inequality [12, 30] in the last step.\nThe relative entropy is defined as D(\u03c1 k \u03c4 ) := tr(\u03c1(log \u03c1\u2212\nlog \u03c4 )) and H(\u03c1) := \u2212tr(\u03c1 log \u03c1).\nWe will now define the smooth min-entropy and an\nalternative to the smooth entropy as first introduced\nin [10]. The definition of two versions of the min-entropy\nis parallel to the case of the von Neumann entropy above;\nhowever, the two identities (B1) and (B2) now lead to\ndifferent definitions. We follow [31] and first introduce\nthe max relative entropy. For two positive operators\n\u03c1 \u2208 S\u2264 (H) and \u03c4 \u2208 P(H) we define\n\nThe desired bound on the purified distance follows from\nits definition.\n\nDmax (\u03c1 k \u03c4 ) := inf{\u03bb \u2208 R : \u03c1 \u2264 2\u03bb \u03c4 } .\n\nwhere \u03a0\u22a5 = 1 \u2212 \u03a0 is the complement of \u03a0 on H.\nProof. The generalized fidelity between the two states\ncan be bounded using tr(\u03a0\u03c1) \u2264 tr(\u03c1). We have\n\nWe also need a H\u00f6lder inequality for linear operators\nand unitarily invariant norms (see [29] for a proof). Here,\nwe state a version for three operators and the trace norm:\nLemma 18. Let A, B and C be linear operators and\nr, s, t > 0 such that r1 + 1s + 1t = 1, then\n1\n\n1\n\n1\n\n||ABC||1 \u2264 |||A|r ||1 r |||B|s ||1 s |||C|t ||1 t .\nThe following lemma makes clear that the min-entropy\nsmoothing of a state will not destroy its CQ structure.\nLemma 19. Let \u03c1XB be a CQ-state of the form \u03c1XB =\nP\n[x]\n\u03b5\nx |xihx| \u2297 \u03c1B . Then, the state \u03c1\u0303XB \u2208 B (\u03c1XB ) that op\u03b5\ntimizes Hmin (X|B)\u03c1 = Hmin (X|B)\u03c1\u0303 is of the same form.\nProof. Let \u03c1\u0303AB be any state in B \u03b5 (\u03c1XB ). We can establish a CQ-state \u03c1\u0303XB by measuring A in the basis determined by X. This operation will not increase the distance P (\u03c1\u0303AB , \u03c1XB ) (cf. [26], Lemma 7) and not decrease\nthe min-entropy (cf. [26], Theorem 19). Thus, we can\nconclude that the optimal state is CQ.\n\nAppendix B: Alternative Entropic Quantities\n\nHere, we discuss two alternative entropic quantities,\n\u03b5\nb \u03b5 (A|B) and H\nb max\nH\n(A|B) and show that they are equivmin\nalent (up to terms in log \u03b5) to the smooth min-entropy\nand smooth max-entropy, respectively. Some of the technical results of this appendix will be used to give a bound\non the collision entropy in terms of the smooth minentropy (cf. Appendix C and Lemma 3).\nFirst, note that conditional entropies can be defined\nin terms of relative entropies, as is well-known for the\ncase of the von Neumann entropy. Let \u03c1AB be a bipartite quantum state. Then, the condtional von Neumann\nentropy of A given B is defined as\nH (A|B)\u03c1 : = H(\u03c1AB ) \u2212 H(\u03c1B )\n= \u2212D(\u03c1AB k 1A \u2297 \u03c1B )\n=\u2212\nmin\nD(\u03c1AB k 1A \u2297 \u03c3B ) ,\n\u03c3B \u2208S= (HB )\n\n(B1)\n(B2)\n\nDefinition 4. Let \u03b5 \u2265 0 and \u03c1AB \u2208 S\u2264 (HAB ). The minentropy and the alternative min-entropy of A conditioned\non B are given by\nHmin (A|B)\u03c1 =\n\nmax\n\n\u2212Dmax (\u03c1AB k 1A \u2297 \u03c3B )\n\n\u03c3B \u2208S= (HB )\n\nand\n\nb min (A|B)\u03c1 := \u2212Dmax (\u03c1AB k 1A \u2297 \u03c1B ) ,\nH\n\nrespectively. Furthermore, the smooth min-entropy and\nthe alternative smooth min-entropy of A conditioned on\nB are defined as\n\u03b5\nHmin\n(A|B)\u03c1 =\n\nb \u03b5 (A|B)\u03c1 :=\nH\nmin\n\nmax\n\nHmin (A|B)\u03c1\u0303\n\nmax\n\nb (A|B)\u03c1\u0303 .\nH\nmin\n\n\u03c1\u0303AB \u2208B\u03b5 (\u03c1AB )\n\n\u03c1\u0303AB \u2208B\u03b5 (\u03c1AB )\n\nand\n\nThe smooth max-entropies can be defined as duals of\nthe smooth min-entropies.\nDefinition 5. Let \u03b5 \u2265 0 and \u03c1AB \u2208 S\u2264 (HAB ), then\nwe define the smooth max-entropy and the alternative\nsmooth max-entropy of A conditioned on B as\n\u03b5\n\u03b5\nHmax\n(A|B)\u03c1 := \u2212Hmin\n(A|C)\u03c1 and\n\u03b5\n\u03b5\nb\nb\nHmax (A|B)\u03c1 := \u2212Hmin (A|C)\u03c1 ,\n\nwhere \u03c1ABC \u2208 S\u2264 (HABC ) is any purification of \u03c1AB .\nThe max-entropies are well-defined since the minentropies are invariant under local isometries on the C\nsystem (cf. [26] and Lemma 24) and, thus, independent of\nthe chosen purification. The non-smooth max-entropies\nb max (A|B)\u03c1 are defined as the limit\nHmax (A|B)\u03c1 and H\n\u03b5 \u2192 0 of the corresponding smooth quantities. The alternative max-entropy is discussed in Appendix D, where\nit is shown that (cf. also [32])\nb\nH\nmax (A|B)\u03c1 =\n\nmax\n\nlog tr (\u03a0\u03c1AB (1A \u2297 \u03c3B )) , (B3)\n\n\u03c3B \u2208S= (HB )\n\nwhere \u03a0\u03c1AB is the projector onto the support of \u03c1AB .\nFurthermore, we find that\n\u03b5\nb max\nH\n(A|B)\u03c1 = inf\n\nmin\n\nHB' \u2287HB \u03c1\u0303AB' \u2208B\u03b5 (\u03c1AB' )\n\nb max (A|B')\u03c1\u0303 , (B4)\nH\n\n\f10\nwhere the infimum is taken over all embeddings \u03c1AB' of\n\u03c1AB into HA \u2297 HB' . In fact, it is sufficient to consider\nan embedding into a space of size dim HB' = rank {\u03c1AB } *\ndim HA .\nThe first definition of the smooth max-entropy,\n\u03b5\nHmax\n(A|B), is used in [13, 25] and is found to have many\ninteresting properties, e.g. it satisfies a data-processing\nb \u03b5 (A|B),\ninequality [26]. The alternative definition, H\nmax\nwas first introduced in [10] and is used to quantitatively characterize various information theoretic tasks (cf.\ne.g. [31, 33, 34]). Here, we find that the two smooth minentropies and the two smooth max-entropies are pairwise\nequivalent up to terms in log \u03b5. Namely, the following\nlemma holds:\n\nwith regard to \u03c1ABC and the fact that \u03c1AB \u2264 \u03bb1A \u2297 \u03c3B by\ndefinition of \u03bb and \u03c3B :\n\u22121/2 \u0001\n\u22121/2\nrhs. = trC (\u03a0AC \u2297 \u03c1B ) \u03c1ABC (\u03a0AC \u2297 \u03c1B ) \u221e\n\nLemma 20. Let \u03b5 > 0, \u03b5\u2032 \u2265 0 and \u03c1AB \u2208 S= (HAB ), then\n\nWe use Lemma 17 to bound the distance between \u03c1ABC\nand \u03c1\u0303ABC , namely\nq\nq\n\u03c1\n)\n=\n2 tr(\u03a0\u22a5\n\u03c1 ),\nP (\u03c1ABC , \u03c1\u0303ABC ) \u2264 2 tr(\u03a0\u22a5\nAC ABC\nB B\n\n\u03b5\u2032\nb \u03b5+\u03b5\u2032 (A|B)\u03c1 \u2264 H \u03b5+\u03b5\u2032 (A|B)\u03c1 ,\nHmin\n(A|B)\u03c1 \u2212 log c \u2264 H\nmin\nmin\n\nwhere c = 2/\u03b52 + 1/(1 \u2212 \u03b5\u2032 ).\n\nThe equivalence of the max-entropies follows by their\ndefinition as duals, i.e. we have\n\u03b5\u2032\n\u03b5+\u03b5\u2032\n\u03b5+\u03b5\u2032\nb max\nHmax\n(A|B)\u03c1 + log c \u2265 H\n(A|B)\u03c1 \u2265 Hmax\n(A|B)\u03c1 .\n\nFor convenience of exposition, we introduce the generalized conditional min-entropy\nhmin (A|B)\u03c1|\u03c3 := \u2212Dmax(\u03c1AB k 1A \u2297 \u03c3B ) .\nThe proof of Lemma 20 is based on the following result.\nLemma 21. Let \u03b5 > 0 and \u03c1ABC \u2208 S\u2264 (HABC ) be pure.\nThen, there exists a projector \u03a0AC on HAC and a state\n\u03c1\u0303ABC = \u03a0AC \u03c1ABC \u03a0AC such that \u03c1\u0303ABC \u2208 Bp\u03b5 (\u03c1ABC ) and\nhmin (A|B)\u03c1\u0303|\u03c1 \u2265 Hmin (A|B)\u03c1 \u2212 log\n\n2\n.\n\u03b52\n\nFurthermore, there exists a state \u03c1\u0304AB \u2208 S\u2264 (HAB ) that\nsatisfies \u03c1\u0304AB \u2208 B \u03b5 (\u03c1AB ) and\n\u0011\n\u0010\nb (A|B)\u03c1\u0304 \u2265 H (A|B)\u03c1 \u2212 log 2 + 1\n.\nH\nmin\nmin\n\u03b52\ntr \u03c1AB\nProof. The proof is structured as follows: First, we give\na lower bound on the entropy hmin (A|B)\u03c1\u0303|\u03c1 in terms of\nHmin (A|B)\u03c1 and a projector \u03a0B that is the dual projector\n(cf. Corollay 16) of \u03a0AC with regard to \u03c1ABC . We then\nfind a lower bound on the purified distance between \u03c1ABC\nand \u03c1\u0303ABC in terms of \u03a0B and define \u03a0B (and, thus, \u03a0AC )\nsuch that this distance does not exceed \u03b5.\nLet \u03bb and \u03c3B be the pair that optimizes the minentropy Hmin (A|B)\u03c1 , i.e. Hmin (A|B)\u03c1 = hmin (A|B)\u03c1|\u03c3 =\n\u2212 log \u03bb. We have \u03c1\u0303B \u2264 \u03c1B by definition of \u03c1\u0303ABC . Hence,\nhmin (A|B)\u03c1\u0303|\u03c1 is finite and can be written as\n\u22121/2\n\n2\u2212hmin (A|B)\u03c1\u0303|\u03c1 = \u03c1B\n\n\u22121/2\n\n\u03c1\u0303AB \u03c1B\n\n\u221e\n\n,\n\nwhere ||X||\u221e denotes the maximum eigenvalue of X. We\nbound this expression using the dual projector \u03a0B of \u03a0AC\n\n\u22121/2\n\n= \u03a0B \u03c1B\n\n\u22121/2\n\n\u03c1AB \u03c1B\n\n\u22121/2\n\n\u2264 \u03bb 1A \u2297 \u03a0B \u03c1B\n\n\u03a0B\n\n\u221e\n\u22121/2\n\n\u03c3B \u03c1B\n\n\u03a0B\n\n= \u03bb ||\u03a0B \u0393B \u03a0B ||\u221e ,\n\n\u221e\n\nwhere, in the last step, we introduced the Hermitian op\u22121/2\n\u22121/2\nerator \u0393B := \u03c1B \u03c3B \u03c1B . Taking the logarithm on both\nsides leads to\nhmin (A|B)\u03c1\u0303|\u03c1 \u2265 Hmin (A|B)\u03c1 \u2212 log ||\u03a0B \u0393B \u03a0B ||\u221e .\n\n(B5)\n\nwhere the last equality can be verified using Corollary 16.\nClearly, the optimal choice of \u03a0B will cut off the largest\neigenvalues of \u0393B in (B5) while keeping the states \u03c1ABC\nand \u03c1\u0303ABC close. We thus define PB to be the minimum\nrank projector onto the smallest eigenvalues of \u0393B such\nthat tr(\u03a0B \u03c1B ) \u2265 tr \u03c1B \u2212\u03b52 /2 or, equivalently, tr(\u03a0\u22a5\nB \u03c1B ) \u2264\n\u03b52 /2. This definition immediately implies that \u03c1ABC and\n\u03c1\u0303ABC are \u03b5-close and it remains to find an upper bound\non ||\u03a0B \u0393B \u03a0B ||\u221e .\nLet \u03a0\u2032B be the projector onto the largest remaining\neigenvalue in \u03a0B \u0393B \u03a0B and note that \u03a0\u2032B and \u03a0\u22a5\ncommute\nB\nwith \u0393B . Then,\n||\u03a0B \u0393B \u03a0B ||\u221e = tr(\u03a0\u2032B \u0393B ) = min\n\u03bcB\n\ntr(\u03bcB (\u03a0\u22a5\nB + \u03a0B )\u0393B )\n,\ntr(\u03bcB )\n\nwhere \u03bcB is minimized over all positive operators in\n\u2032\nthe support of \u03a0\u22a5\nFixing instead \u03bcB = (\u03a0\u22a5\nB + \u03a0B .\nB +\n\u2032\n\u22a5\n\u2032\n\u03a0B )\u03c1B (\u03a0B + \u03a0B ), we find\n1/2\n\n1/2\n\n||\u03a0B \u0393B \u03a0B ||\u221e \u2264\n\n+ \u03a0\u2032B ))\ntr(\u0393B \u03c1B \u0393B (\u03a0\u22a5\nB\n\u22a5\n\u2032\ntr((\u03a0B + \u03a0B )\u03c1B )\n\n\u2264\n\ntr(\u0393B \u03c1B \u0393B )\n2\n\u2264 2.\n\u22a5\n\u2032\ntr((\u03a0B + \u03a0B )\u03c1B )\n\u03b5\n\n1/2\n\n1/2\n\n1/2\n\n1/2\n\nIn the last step we used that tr(\u03c1B \u0393B \u03c1B ) = tr(\u03c3B ) = 1\n2\n. We\nand that tr((\u03a0\u22a5\n+ \u03a0\u2032B )\u03c1B ) \u2265 \u03b52 by definition of \u03a0\u22a5\nB\nB\nhave now established the first statement.\nTo prove the second statement, we introduce an operator \u2206B := \u03c1B \u2212\u03c1\u0303B \u2265 0. The state \u03c1\u0304AB = \u03c1\u0303AB +1A /dA \u2297\u2206B ,\nwhere dA = dim HA , satisfies \u03c1\u0304B = \u03c1B . We now show that\nthe state\u221a\u03c1\u0304AB is \u03b5-close to \u221a\n\u03c1AB . The inequality \u03c1\u0303AB \u2264 \u03c1\u0304AB\n\u221a\n\u221a\nimplies || \u03c1\u0303AB \u03c1AB ||1 \u2264 || \u03c1\u0304AB \u03c1AB ||1 and, thus,\nF\u0304 (\u03c1AB , \u03c1\u0304AB ) \u2265 F (\u03c1\u0303AB , \u03c1AB ) + 1 \u2212 tr \u03c1AB\n\u2265 F (\u03c1\u0303ABC , \u03c1ABC ) + 1 \u2212 tr \u03c1AB\n\n= 1 \u2212 tr(\u03a0\u22a5\n\u03c1 ) \u2265 1 \u2212 \u03b52 /2 ,\nAC AC\n\n\f11\nwhere\nwe used the monotonicity of the fidelity F (\u03c1, \u03c4 ) :=\n\u221a \u221a\n|| \u03c1 \u03c4 ||1 under the partial trace. Thus, P (\u03c1\u0304AB , \u03c1AB ) \u2264 \u03b5.\nWe use that \u03c1\u0304B = \u03c1B and \u03c1\u0304AB \u2264 \u03c1\u0303AB + 1A /dA \u2297 \u03c1B to\nb (A|B)\u03c1\u0304 = h (A|B)\u03c1\u0304|\u03c1 :\nfind a lower bound on H\nmin\nmin\nb\n\n\u03c1\u0304AB \u03c1B\n\n\u22121/2\n\n\u03c1\u0303AB \u03c1B\n\n\u2264 \u03c1B\n\u2264\u03bb\n\n\u22121/2\n\n\u22121/2\n\n2\u2212Hmin (A|B)\u03c1\u0304 = \u03c1B\n\n\u22121/2\n\n\u221e\n\n+\n\n1\n1AB\ndA\n\n2\n1\n+\n.\n\u03b52\ndA\n\n\u22121/2\n\n)\u03c1AB (1A \u2297 \u03c3B\n\n) \u2264 2Dmax (\u03c1AB k1A \u2297\u03c3B ) 1AB .\n\nWe use this and the fact that tr(\u03c1AB X) \u2264 tr(\u03c1AB Y ) if\nX \u2264 Y to get\n\u0393C (A|B)\u03c1|\u03c3 \u2264 2Dmax (\u03c1AB k 1A \u2297\u03c3B ) tr \u03c1AB ,\nwhich concludes the proof.\n\n\u00102\n1 \u0011\n.\n+\n\u03b52\ntr \u03c1AB\n\nThis concludes the proof of the second statement.\nFurthermore, the alternative smooth min-entropy is a\nlower bound on the smooth min-entropy by definition.\nLemma 22. Let \u03c1AB \u2208 S\u2264 (HAB ), then\nb (A|B)\u03c1 \u2264 H (A|B)\u03c1 \u2212 log 1 .\nH\nmin\nmin\ntr \u03c1AB\nWe are now ready to prove Lemma 20. Namely, we\nshow that, for \u03b5 > 0, \u03b5\u2032 \u2265 0 and \u03c1AB \u2208 S\u2264 (HAB ), it holds\nthat\n\u2032\n\n\u22121/2\n\n(1A \u2297 \u03c3B\n\n\u221e\n\nWe have \u03bb \u2265 tr \u03c1AB /dA (Lemma 20 in [26]) and, thus,\nb (A|B)\u03c1\u0304 \u2265 H (A|B)\u03c1 \u2212 log\nH\nmin\nmin\n\nProof. By definition of the max relative entropy, we have\n\u03c1AB \u2264 2Dmax (\u03c1AB k1A \u2297\u03c3B ) 1A \u2297 \u03c3B and, thus,\n\n\u2032\n\nUsing the above result and Lemma 21 of Appendix B,\nwe are ready to prove Lemma 3 of Section II.\nProof of Lemma 3. To prove the first statement, we apply Lemma 23 to the state \u03c1XB . The inequality holds\nin particular for the state \u03c3B that optimizes Hmin (X|B)\u03c1\n(cf. Definition 4), establishing (10).\nNext, we use Lemma 21 to define \u03c1\u0304XB \u2208 B \u03b5\u0304 (\u03c1XB ). Thus,\nb min (X|B)\u03c1\u0304 \u2265 Hmin (X|B)\u03c1 \u2212 log\nH\n\nIn particular, we can choose \u03c1\u0304XB normalized and CQ.12\nWe apply Lemma 23 to this state to get\nb\n\nwhich concludes the proof of (11).\n\n\u2032\n\n\u03b5\u2032\n\nProof of Lemma 20. Let \u03c1\u0303AB \u2208 B (\u03c1AB ) be the state that\n\u03b5\u2032\nmaximizes Hmin\n(A|B)\u03c1 . Clearly, tr \u03c1\u0303AB \u2265 tr \u03c1AB \u2212 \u03b5\u2032 .\nMoreover, Lemma 21 and the triangle inequality of the\npurified\ndistance imply that there exists a state \u03c1\u0304AB \u2208\n\u2032\nB \u03b5+\u03b5 (\u03c1AB ) that satisfies\nb \u03b5+\u03b5\u2032 (A|B)\u03c1 \u2265 H\nb (A|B)\u03c1\u0304 \u2265 H \u03b5\u2032 (A|B)\u03c1 \u2212 log c ,\nH\nmin\nmin\nmin\n\nwhich concludes the proof of the first inequality. The\nsecond inequality follows by applying Lemma 22 to the\nb \u03b5+\u03b5\u2032 (A|B)\u03c1 .\nstate that maximizes H\nmin\nAppendix C: Collision Entropy\n\nAppendix D: Duality Relation for Alternative\nSmooth Entropies\n\nHere, we find that the alternative smooth min-entropy\nof A conditioned on B is invariant under local isometries\non the B system. Since all purifications are equivalent\nup to isometries on the purifying system, this allows the\ndefinition of the alternative max-entropy as its dual (see\nDefinition 5). Furthermore, the max-entropy of A conditioned on B is invariant under local isometries on the B\nsystem as a direct consequence. Note that the alternative\nsmooth min- and max-entropies are in general not invariant under isometries on the A system, i.e. they depend\non the dimension of the Hilbert space HA .\nLemma 24. Let \u03b5 \u2265 0 and \u03c1AB \u2208 S\u2264 (HAB ). Moreover,\nlet U : HB \u2192 HD be an isometry with \u03c4AD := (1A \u2297\nU )\u03c1AB (1A \u2297 U \u2020 ). Then,\n\u03b5\n\u03b5\nb min\nb min\nH\n(A|B)\u03c1 = H\n(A|D)\u03c4 and\nb \u03b5 (A|B)\u03c1 = H\nb \u03b5 (A|D)\u03c4 .\nH\nmax\nmax\n\nIn this section, we prove Lemma 3, which gives a relation between the collision entropy and the min-entropy.\nFirst, we provide an inequality in terms of relative entropies.\nLemma 23. Let \u03c1AB \u2208 S\u2264 (HAB ) and \u03c3B \u2208 S= (HB ), then\nDmax (\u03c1AB k 1A \u2297 \u03c3B ) \u2265 log \u0393C (\u03c1AB |\u03c3B ) \u2212 log tr \u03c1AB .\n\n2\n\n\u0393C (\u03c1\u0304XB |\u03c1\u0304B ) \u2264 2\u2212Hmin (X|B)\u03c1\u0304 \u2264 2\u2212Hmin (X|B)\u03c1 +log( \u03b5\u03042 +1) ,\n\n\u03b5\nb \u03b5+\u03b5 (A|B)\u03c1 \u2264 H \u03b5+\u03b5 (A|B)\u03c1 ,\nHmin\n(A|B)\u03c1 \u2212 log c \u2264 H\nmin\nmin\n\nwhere c = 2/\u03b52 + 1/(tr \u03c1AB \u2212 \u03b5\u2032 ).\n\n\u00102\n1 \u0011\n.\n+\n\u03b5\u03042\ntr \u03c1XB\n\n12\n\nTo see this, first note that the alternative min-entropy,\nb\nH\nmin (X|B)\u03c1\u0304 , is independent of tr \u03c1\u0304XB . Moreover, measuring \u03c1\u0304XB\non the X system will increase the alternative min-entropy while\nthe distance to \u03c1XB can only decrease.\n\n\f12\nProof. Let \u03c1\u0303AB \u2208 B \u03b5 (\u03c1AB ) be the state that maximizes\nthe alternative min-entropy of A conditioned on B and\nb \u03b5 (A|B)\u03c1 = \u2212 log \u03bb. Then \u03c1\u0303AB \u2264\nlet \u03bb be defined with H\nmin\n\u03bb1A \u2297 \u03c1\u0303B , which implies\n(1A \u2297 U )\u03c1\u0303AB (1A \u2297 U \u2020 ) \u2264 \u03bb1A \u2297 (U \u03c1\u0303B U \u2020 ) .\n|\n{z\n}\n=: \u03c4\u0303AD\n\nHence, \u03c4\u0303AD \u2264 \u03bb1A \u2297 \u03c4\u0303D . Moreover, \u03c4\u0303AD \u2208 B \u03b5 (\u03c4AD )\nb \u03b5 (A|D)\u03c1 \u2265 H\nb \u03b5 (A|B)\u03c1 .\ndue to (9), which implies H\nmin\nmin\nThe same argument in reverse can be applied to get\nb \u03b5 (A|B)\u03c1 \u2265 H\nb \u03b5 (A|D)\u03c4 .\nH\nmin\nmin\nThe invariance under isometry of the dual quantity\nfollows by definition. Namely, let \u03c1ABE be any purification\nof \u03c1AB , then\nb \u03b5 (A|B)\u03c1 = \u2212H\nb \u03b5 (A|E)\u03c1\nH\nmax\nmin\nb \u03b5 (A|E)\u03c4 = H\nb \u03b5 (A|D)\u03c4 ,\n= \u2212H\nmin\nmax\n\nwhere \u03c4ADE := (1A \u2297 U \u2297 1E )\u03c1ABE (1A \u2297 U \u2020 \u2297 1E ) is a\npurification of \u03c4AD .\nNext, we derive expression (B3) for the alternative\nnon-smooth and smooth max-entropies. The result for\nthe non-smooth entropy was first shown in [32] and an\nalternative proof is provided here for completeness.\nLemma 25. Let \u03c1AB \u2208 S\u2264 (HAB ), then\nb max (A|B)\u03c1 =\nH\n\nmax\n\n\u03c3B \u2208S= (HB )\n\nlog tr (\u03a0\u03c1AB (1A \u2297 \u03c3B ))\n\nProof. Let \u03c1ABC be a purification of \u03c1AB . Then, \u03c4ABC :=\n\u22121/2 \u0001\n\u22121/2 \u0001\nhas marginal \u03c4AB = \u03a0\u03c1AB\n\u03c1ABC 1AB \u2297 \u03c1C\n1AB \u2297 \u03c1C\ndue to Lemma 14. This allows us to write\nb\n\nb\n\n2Hmax (A|B)\u03c1 = 2\u2212Hmin (A|C)\u03c1 = ||\u03c4AC ||\u221e = ||\u03c4B ||\u221e\n= max tr(\u03c3B \u03c4B ) = max tr (\u03a0\u03c1AB (1A \u2297 \u03c3B )) ,\n\u03c3B\n\n\u03c3B\n\nwhere the maximization is over all \u03c3B \u2208 S= (HB ).\nThe alternative smooth max-entropy can be seen as an\noptimization of the non-smooth quantity over an \u03b5-ball of\nstates, where the ball is embedded in a sufficiently large\nHilbert space. We show that (B4) holds.\n\n[1] D. R. Stinson, \"Universal Hash Families and the Leftover Hash Lemma, and Applications to Cryptography\nand Computing,\" Journal of Combinatorial Mathematics\nand Combinatorial Computing, vol. 42, pp. 3\u201331, 2002.\n[2] C. H. Bennett, G. Brassard, and J.-M. Robert, \"Privacy\nAmplification by Public Discussion,\" SIAM J. Comput.,\nvol. 17, no. 2, p. 210, 1988.\n[3] R. Impagliazzo, L. A. Levin, and M. Luby, \"PseudoRandom Generation from one-way Functions,\" in Proc.\n21st Annual ACM Symposium on Theory of Computing,\n\nLemma 26. Let \u03b5 \u2265 0 and \u03c1AB \u2208 S\u2264 (HAB ), then\nb \u03b5 (A|B)\u03c1 = inf\nH\nmax\n\nmin\n\nHB' \u2287HB \u03c1\u0303AB' \u2208B\u03b5 (\u03c1AB' )\n\nb\nH\nmax (A|B')\u03c1\u0303 ,\n\nwhere \u03c1AB' is the embedding of \u03c1AB into HAB' . Furthermore, the infimum is attained for embeddings with\ndim HB' \u2265 dim supp {\u03c1AB } * dim HA .\nProof. Let \u03c1ABC be a purification of \u03c1AB on a Hilbert space\nHC with dim HC = rank {\u03c1AB }. Furthermore, for any\nHB' \u2287 HB , let \u03c1AB'C' be the embedding of \u03c1ABC into HAB'C'\nwith dim HC' = dim HAB' . We use Corollary 13 twice to\nupper bound\n\u03b5\n\u03b5\nb max\nb min\nH\n(A|B)\u03c1 = \u2212H\n(A|C')\u03c1\n\n=\n\n\u2264\n=\n\nmin\n\n\u03c1\u0303AC' \u2208B\u03b5 (\u03c1AC' )\n\nb (A|C')\u03c1\u0303\n\u2212H\nmin\n\nmin\n\n\u03b5 (\u03c1\n\u03c1\u0303AB'C' \u2208Bp\nAB'C' )\n\nmin\n\n\u03c1\u0303AB' \u2208B\u03b5 (\u03c1AB' )\n\nb max (A|B')\u03c1\u0303\nH\n\nb\nH\nmax (A|B')\u03c1\u0303 .\n\nb \u03b5 (A|B)\u03c1 follows when we require\nA lower bound on H\nmax\nthat dim HB' \u2265 rank {\u03c1AB } * dim HA = dim HAC . Then,\nHB' is large enough to accomodate all purifications of\nstates in HAC . Using Corollay 13 twice, we find\n\u03b5\nb max\nH\n(A|B)\u03c1 =\n\n=\n\u2265\n\nmin\n\n\u03c1\u0303AC \u2208B\u03b5 (\u03b5)\u03c1AC\n\nmin\n\nb min (A|C)\u03c1\u0303\n\u2212H\n\n\u03b5 (\u03c1\n\u03c1\u0303AB'C \u2208Bp\nAB'C )\n\nmin\n\n\u03c1\u0303AB' \u2208B\u03b5 (\u03c1AB' )\n\nb\nH\nmax (A|B')\u03c1\u0303\n\nb max (A|B')\u03c1\u0303 .\nH\n\nThe infimum is therefore attained and it is sufficient to\nconsider embeddings with dim HB' = dim supp {\u03c1AB } *\ndim HA .\n\n1989, pp. 12\u201324.\n[4] C. H. Bennett, G. Brassard, C. Crepeau, and U. M. Maurer, \"Generalized Privacy Amplification,\" IEEE Trans.\non Inf. Theory, vol. 41, no. 6, pp. 1915\u20131923, 1995.\n[5] R. Impagliazzo and D. Zuckerman, \"How to Recycle Random Bits,\" in Proc. 30th Annual IEEE Symposium on\nFoundations of Computer Science, 1989, pp. 248\u2013253.\n[6] J. H\u00e5 stad, R. Impagliazzo, L. A. Levin, and M. Luby, \"A\nPseudorandom Generator from any one-way Function,\"\nSIAM J. Comput., vol. 28, no. 4, pp. 1364\u20131396, 1999.\n\n\f13\n[7] D. Gavinsky, J. Kempe, W. J. Kempe, I. Kerenidis,\nC. W. I. Amsterdam, R. Raz, R. de Wolf, and O. R. Raz,\n\"Exponential Separation for one-way Quantum Communication Complexity, with Applications to Cryptography,\" in Proc. 39th Annual ACM Symposium on Theory\nof Computing. San Diego: ACM, 2007, pp. 516\u2013525.\n[8] R. K\u00f6nig and R. Renner, \"Sampling of min-entropy\nRelative to Quantum Knowledge,\" p. 48, December 2007.\n[Online]. Available: http://arxiv.org/abs/0712.4291\n[9] R. K\u00f6nig, U. M. Maurer, and R. Renner, \"On the Power\nof Quantum Memory,\" IEEE Trans. on Inf. Theory,\nvol. 51, no. 7, pp. 2391\u20132401, 2005.\n[10] R. Renner, \"Security of Quantum Key Distribution,\"\nPhD Thesis, ETH Z\u00fcrich, 2005. [Online]. Available:\nhttp://arxiv.org/abs/quant-ph/0512258\n[11] R. Renner and R. K\u00f6nig, \"Universally Composable Privacy Amplification Against Quantum Adversaries,\" in\nSecond Theory of Cryptography Conference, TCC 2005,\nser. LNCS, vol. 3378. Springer, 2005, pp. 407\u2013425.\n[12] M. A. Nielsen, I. Chuang, and L. Grover, Quantum Computation and Quantum Information. Cambridge University Press, 2000.\n[13] R. K\u00f6nig, R. Renner, and C. Schaffner, \"The Operational\nMeaning of min- and max-Entropy,\" IEEE Trans. on\nInf. Theory, vol. 55, no. 9, pp. 4337\u20134347, 2009. [Online].\nAvailable: http://arxiv.org/abs/0807.1338\n[14] J. L. Carter and M. N. Wegman, \"Universal Classes of\nHash Functions,\" Journal of Computer and System Sciences, vol. 18, no. 2, pp. 143\u2013154, 1979.\n[15] D. R. Stinson, \"Universal Hashing and Authentication\nCodes,\" Designs, Codes and Cryptography, vol. 4, no. 3,\npp. 369\u2013380, July 1994.\n[16] G. Van Assche, Quantum Cryptography and Secret-Key\nDistillation. Cambridge University Press, 2006.\n[17] J. Lodewyck, M. Bloch, R. Garc\u0131\u0301a-Patr\u00f3n, S. Fossier,\nE. Karpov, E. Diamanti, T. Debuisschert, N. Cerf,\nR. Tualle-Brouri, S. McLaughlin, and P. Grangier,\n\"Quantum Key Distribution over 25km with an All-Fiber\nContinuous-Variable System,\" Phys. Rev. A, vol. 76,\nno. 4, 2007.\n[18] Y. Dodis and A. Smith, \"Correcting Errors without Leaking Partial Information,\" in 37th Annual ACM Symposium on Theory of Computing (STOC), 2005, pp. 654\u2013\n663.\n[19] S. Fehr and C. Schaffner, \"Randomness Extraction Via\nDelta-Biased Masking in the Presence of a Quantum\nAttacker,\" in Theory of Cryptography Conference '08.\n\nSpringer, 2008, pp. 465\u2013481.\n[20] S. P. Desrosiers and F. Dupuis, \"Quantum entropic\nsecurity and approximate quantum encryption,\" 2007.\n[Online]. Available: http://arxiv.org/abs/0707.0691\n[21] L. Trevisan, \"Extractors and Pseudorandom Generators,\" Journal of the ACM, vol. 48, no. 4, pp. 860\u2013879,\nJuly 2001.\n[22] A. Ta-Shma,\n\"Short Seed Extractors Against\nQuantum Storage,\"\n2008.\n[Online]. Available:\nhttp://arxiv.org/abs/0808.1994\n[23] A. De and T. Vidick, \"Near-Optimal Extractors Against\nQuantum Storage,\" November 2009. [Online]. Available:\nhttp://arxiv.org/abs/0911.4680\n[24] A. De, C. Portmann, T. Vidick, and R. Renner,\n\"Trevisan's Extractor in the Presence of Quantum\nSide Information,\" December 2009. [Online]. Available:\nhttp://arxiv.org/abs/0912.5514\n[25] M. Tomamichel, R. Colbeck, and R. Renner, \"A Fully\nQuantum Asymptotic Equipartition Property,\" IEEE\nTrans. on Inf. Theory, vol. 55, no. 12, pp. 5840\u20135847,\n2009.\n[26] M. Tomamichel, R. Colbeck, and R. Renner, \"Duality\nBetween Smooth Min- and Max-Entropies,\" 2009.\n[Online]. Available: http://arxiv.org/abs/0907.5238v1\n[27] A. Srinivasan and D. Zuckerman, \"Computing with Very\nWeak Random Sources,\" SIAM J. Comput., vol. 28,\nno. 4, pp. 1433\u20131459, 1999.\n[28] A. Uhlmann, \"The Transition Probability for States of\nStar-Algebras,\" Annalen der Physik, vol. 497, no. 4, pp.\n524\u2013532, 1985.\n[29] R. Bhatia, Matrix Analysis, ser. Graduate Texts in Mathematics. Springer, 1997.\n[30] O. Klein, \"Zur quantenmechanischen Begr\u00fcndung des\nzweiten Hauptsatzes der W\u00e4rmelehre,\" Z. Phys, vol. 72,\nno. 11-12, pp. 767\u2013775, November 1931.\n[31] N. Datta, \"Min- and Max- Relative Entropies and a New\nEntanglement Monotone,\" IEEE Trans. on Inf. Theory,\nvol. 55, no. 6, pp. 2816\u20132826, 2009.\n[32] M. Berta, \"Single-Shot Quantum State Merging,\" Master's Thesis, ETH Z\u00fcrich, 2008.\n[33] M. Mosony and N. Datta, \"Generalized Relative Entropies and the Capacity of Classical-Quantum Channels,\" J. Math. Phys., vol. 50, no. 7, 2009.\n[34] F. Buscemi and N. Datta, \"The Quantum Capacity\nof Channels with Arbitrarily Correlated Noise,\" 2009.\n[Online]. Available: http://arxiv.org/abs/0902.0158v5\n\n\f"}