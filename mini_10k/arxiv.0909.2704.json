{"id": "http://arxiv.org/abs/0909.2704v1", "guidislink": true, "updated": "2009-09-15T19:45:22Z", "updated_parsed": [2009, 9, 15, 19, 45, 22, 1, 258, 0], "published": "2009-09-15T19:45:22Z", "published_parsed": [2009, 9, 15, 19, 45, 22, 1, 258, 0], "title": "Memory Consistency Conditions for Self-Assembly Programming", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.2828%2C0909.4453%2C0909.1230%2C0909.2685%2C0909.1856%2C0909.1995%2C0909.2919%2C0909.0290%2C0909.2733%2C0909.1089%2C0909.3265%2C0909.3851%2C0909.3821%2C0909.2109%2C0909.1396%2C0909.1186%2C0909.2328%2C0909.2519%2C0909.3141%2C0909.3620%2C0909.2383%2C0909.3939%2C0909.2704%2C0909.1771%2C0909.3920%2C0909.3611%2C0909.5184%2C0909.4354%2C0909.1390%2C0909.5660%2C0909.1744%2C0909.2514%2C0909.0378%2C0909.0108%2C0909.3092%2C0909.1778%2C0909.3152%2C0909.2303%2C0909.4521%2C0909.4656%2C0909.1083%2C0909.3824%2C0909.0006%2C0909.2881%2C0909.5330%2C0909.1905%2C0909.2127%2C0909.3445%2C0909.1400%2C0909.3057%2C0909.4343%2C0909.2725%2C0909.0528%2C0909.3971%2C0909.1293%2C0909.0356%2C0909.1664%2C0909.2079%2C0909.4254%2C0909.4947%2C0909.5365%2C0909.1781%2C0909.4037%2C0909.3781%2C0909.2797%2C0909.0533%2C0909.1269%2C0909.4897%2C0909.3827%2C0909.3640%2C0909.0150%2C0909.0382%2C0909.2993%2C0909.3880%2C0909.1137%2C0909.4591%2C0909.1113%2C0909.1968%2C0909.2835%2C0909.4794%2C0909.1752%2C0909.1321%2C0909.5406%2C0909.2063%2C0909.2911%2C0909.3362%2C0909.1333%2C0909.3941%2C0909.0284%2C0909.3716%2C0909.4951%2C0909.0281%2C0909.0330%2C0909.4071%2C0909.1538%2C0909.2982%2C0909.3170%2C0909.4539%2C0909.4925%2C0909.4123%2C0909.5502&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Memory Consistency Conditions for Self-Assembly Programming"}, "summary": "Perhaps the two most significant theoretical questions about the programming\nof self-assembling agents are: (1) necessary and sufficient conditions to\nproduce a unique terminal assembly, and (2) error correction. We address both\nquestions, by reducing two well-studied models of tile assembly to models of\ndistributed shared memory (DSM), in order to obtain results from the memory\nconsistency systems induced by tile assembly systems when simulated in the DSM\nsetting. The Abstract Tile Assembly Model (aTAM) can be simulated by a DSM\nsystem that obeys causal consistency, and the locally deterministic tile\nassembly systems in the aTAM correspond exactly to the concurrent-write free\nprograms that simulate tile assembly in such a model. Thus, the detection of\nthe failure of local determinism (which had formerly been an open problem)\nreduces to the detection of data races in simulating programs. Further, the\nKinetic Tile Assembly Model can be simulated by a DSM system that obeys GWO, a\nmemory consistency condition defined by Steinke and Nutt. (To our knowledge,\nthis is the first natural example of a DSM system that obeys GWO, but no\nstronger consistency condition.) We combine these results with the observation\nthat self-assembly algorithms are local algorithms, and there exists a fast\nconversion of deterministic local algorithms into deterministic\nself-stabilizing algorithms. This provides an \"immediate\" generalization of a\ntheorem by Soloveichik et al. about the existence of tile assembly systems that\nsimultaneously perform two forms of self-stabilization: proofreading and\nself-healing. Our reductions and proof techniques can be extended to the\nprogramming of self-assembling agents in a variety of media, not just DNA\ntiles, and not just two-dimensional surfaces.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.2828%2C0909.4453%2C0909.1230%2C0909.2685%2C0909.1856%2C0909.1995%2C0909.2919%2C0909.0290%2C0909.2733%2C0909.1089%2C0909.3265%2C0909.3851%2C0909.3821%2C0909.2109%2C0909.1396%2C0909.1186%2C0909.2328%2C0909.2519%2C0909.3141%2C0909.3620%2C0909.2383%2C0909.3939%2C0909.2704%2C0909.1771%2C0909.3920%2C0909.3611%2C0909.5184%2C0909.4354%2C0909.1390%2C0909.5660%2C0909.1744%2C0909.2514%2C0909.0378%2C0909.0108%2C0909.3092%2C0909.1778%2C0909.3152%2C0909.2303%2C0909.4521%2C0909.4656%2C0909.1083%2C0909.3824%2C0909.0006%2C0909.2881%2C0909.5330%2C0909.1905%2C0909.2127%2C0909.3445%2C0909.1400%2C0909.3057%2C0909.4343%2C0909.2725%2C0909.0528%2C0909.3971%2C0909.1293%2C0909.0356%2C0909.1664%2C0909.2079%2C0909.4254%2C0909.4947%2C0909.5365%2C0909.1781%2C0909.4037%2C0909.3781%2C0909.2797%2C0909.0533%2C0909.1269%2C0909.4897%2C0909.3827%2C0909.3640%2C0909.0150%2C0909.0382%2C0909.2993%2C0909.3880%2C0909.1137%2C0909.4591%2C0909.1113%2C0909.1968%2C0909.2835%2C0909.4794%2C0909.1752%2C0909.1321%2C0909.5406%2C0909.2063%2C0909.2911%2C0909.3362%2C0909.1333%2C0909.3941%2C0909.0284%2C0909.3716%2C0909.4951%2C0909.0281%2C0909.0330%2C0909.4071%2C0909.1538%2C0909.2982%2C0909.3170%2C0909.4539%2C0909.4925%2C0909.4123%2C0909.5502&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Perhaps the two most significant theoretical questions about the programming\nof self-assembling agents are: (1) necessary and sufficient conditions to\nproduce a unique terminal assembly, and (2) error correction. We address both\nquestions, by reducing two well-studied models of tile assembly to models of\ndistributed shared memory (DSM), in order to obtain results from the memory\nconsistency systems induced by tile assembly systems when simulated in the DSM\nsetting. The Abstract Tile Assembly Model (aTAM) can be simulated by a DSM\nsystem that obeys causal consistency, and the locally deterministic tile\nassembly systems in the aTAM correspond exactly to the concurrent-write free\nprograms that simulate tile assembly in such a model. Thus, the detection of\nthe failure of local determinism (which had formerly been an open problem)\nreduces to the detection of data races in simulating programs. Further, the\nKinetic Tile Assembly Model can be simulated by a DSM system that obeys GWO, a\nmemory consistency condition defined by Steinke and Nutt. (To our knowledge,\nthis is the first natural example of a DSM system that obeys GWO, but no\nstronger consistency condition.) We combine these results with the observation\nthat self-assembly algorithms are local algorithms, and there exists a fast\nconversion of deterministic local algorithms into deterministic\nself-stabilizing algorithms. This provides an \"immediate\" generalization of a\ntheorem by Soloveichik et al. about the existence of tile assembly systems that\nsimultaneously perform two forms of self-stabilization: proofreading and\nself-healing. Our reductions and proof techniques can be extended to the\nprogramming of self-assembling agents in a variety of media, not just DNA\ntiles, and not just two-dimensional surfaces."}, "authors": ["Aaron Sterling"], "author_detail": {"name": "Aaron Sterling"}, "author": "Aaron Sterling", "links": [{"href": "http://arxiv.org/abs/0909.2704v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0909.2704v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0909.2704v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0909.2704v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Memory Consistency Conditions for Self-Assembly Programming\nAaron Sterling?\nLaboratory for Nanoscale Self-Assembly\nDepartment of Computer Science\nIowa State University\nAmes, Iowa, USA\nsterling@cs.iastate.edu\n\narXiv:0909.2704v1 [cs.DS] 15 Sep 2009\n\nAbstract. Perhaps the two most significant theoretical questions about the programming of selfassembling agents are: (1) necessary and sufficient conditions to produce a unique terminal assembly,\nand (2) error correction. We address both questions, by reducing two well-studied models of tile assembly\nto models of distributed shared memory (DSM), in order to obtain results from the memory consistency\nsystems induced by tile assembly systems when simulated in the DSM setting. The Abstract Tile\nAssembly Model (aTAM) can be simulated by a DSM system that obeys causal consistency, and the\nlocally deterministic tile assembly systems in the aTAM correspond exactly to the concurrent-write\nfree programs that simulate tile assembly in such a model. Thus, the detection of the failure of local\ndeterminism (which had formerly been an open problem) reduces to the detection of data races in\nsimulating programs. Further, the Kinetic Tile Assembly Model can be simulated by a DSM system that\nobeys GWO, a memory consistency condition defined by Steinke and Nutt. (To our knowledge, this is\nthe first natural example of a DSM system that obeys GWO, but no stronger consistency condition.) We\ncombine these results with the observation that self-assembly algorithms are local algorithms, and there\nexists a fast conversion of deterministic local algorithms into deterministic self-stabilizing algorithms.\nThis provides an \"immediate\" generalization of a theorem by Soloveichik et al. about the existence of\ntile assembly systems that simultaneously perform two forms of self-stabilization: proofreading and selfhealing. Our reductions and proof techniques can be extended to the programming of self-assembling\nagents in a variety of media, not just DNA tiles, and not just two-dimensional surfaces.\n\n?\n\nThis research was supported in part by National Science Foundation Grants 0652569 and 0728806.\n\n\f1\n\nIntroduction\n\nIn August 2009, IBM and the DNA and Natural Algorithms Group at Caltech announced a joint project\nto use \"DNA origami\" as a scaffolding in order to place microchip components 6 nm apart, breaking the\n22 nm barrier that is the current state of the art in chip manufacturing [1]. In contrast to some other\nemerging models of computation, such as quantum computing or membrane computing, about which there\nare extensive theoretical results but as yet little experimental success, the experimental results of algorithmic\nDNA self-assembly are significantly ahead of the theory. (A recent survey of nanofabrication by DNA selfassembly, including a high-level explanation of DNA origami, appears in [2].) Indeed, there are only a handful\nof results about perhaps the two most significant theoretical questions about self-assembly programming:\n(1) necessary and sufficient conditions to produce a unique terminal assembly, and (2) error correction.\nThe goal of this paper is to recast those two questions as programming questions of memory consistency\nconditions and self-stabilizing algorithms, thus making techniques from the study of concurrent architectures\nand programming languages, and self-stabilization, available to this emerging area of research.\nWhen a global structure (or organism) forms because of the connections formed by strictly simpler\nstructures to one another, following only local rules, we say the global structure self-assembles. The goal of\nalgorithmic self-assembly is to direct (or to program) the self-assembly of desired structures, by constructing\nself-assembling agents, and their environment, so they combine to form a desired result. We will focus on\nalgorithmic DNA self-assembly in this paper, a field merging computer science and nanotechnology that began\nin the 1990s, spurred especially by the work of Adleman, Rothemund, and Winfree [3]. The formalisms to\nmodel self-assembling systems contain the following: a finite set of distinct types of self-assembling agents, a\nset of local binding rules that completely determines the behavior of the agents, and an initial configuration\nof the system. A particular self-assembly \"run\" starts with an operator placing a finite seed assembly on the\nsurface, and then allowing a \"solution\" containing infintely many of each agent type to mix on the surface.\nAgents bind to the seed assembly, and to the growing configuration, consistent with the local rules, and\nin a random, asynchronous manner. In the tile assembly models we consider in this paper, each agent is a\nfour-sided tile, and the assembly surface is the two-dimensional integer plane.\nIn [4], we proved a time lower bound for certain computational problems in self-assembly on a surface,\nby reducing a class of self-assembly models to message-passing models of distributed computing, and then\napplying a known impossibility result about local algorithms. We follow a similar strategy in this paper: we\nreduce well-studied tile assembly models to models of distributed shared memory and then explore some of\nthe consequences of those reductions. In particular, we consider the Abstract Tile Assembly Model (aTAM),\ndue to Winfree [5] and Rothemund [6], and the Kinetic Tile Assembly Model (kTAM) due to Winfree [5]. In\nthe aTAM, binding between self-assembling agents is error-free and irreversible; while in the kTAM, binding\nerrors are possible, and agents can bind but later dissociate with some positive probability. We show that tile\nassembly systems defined in the aTAM can be simulated by systems of distributed shared memory (DSM)\nthat obey causal consistency [7], a memory consistency condition weaker than the better-known sequential\nconsistency. In a sense, this level of memory consistency is \"tight\" for any DSM model that simulates the\naTAM.\nNext, we translate one of the fundamental theorems about the aTAM-that \"locally deterministic\" tile\nassembly systems produce a unique terminal assembly [8]-into the language of memory consistency. We show\nthat locally deterministic tile assembly systems correspond exactly to the concurrent-write free programs\nthat simulate tile assembly in our DSM model. Hence, the programming techniques to produce data-race\nfree and concurrent-write free programs-and to detect data races-can be applied to the programming of\nself-assembling agents.\nRegarding the kTAM, we show it reduces to a model of DSM obeying memory consistency condition\nGWO, which is strictly weaker than causal consistency. Again, there is a sense in which this level of memory\nconsistency is tight. GWO was defined by Steinke and Nutt, to fill out a lattice with which they compared\nall known memory consistency conditions [9]. To our knowledge, the only DSM system in the literature that\nprecisely obeys GWO is the one Steinke and Nutt built to show that some such model exists. The DSM\nsimulation of the kTAM, then, is the first natural example of a model that lies within GWO but no stronger\nlevel of memory consistency.\n1\n\n\fFinally, we combine these results with the observation that self-assembly algorithms are local algorithms,\nand there exists a fast conversion of deterministic local algorithms into deterministic self-stabilizing algorithms. This provides an \"immediate\" generalization of a theorem by Soloveichik et al. about the existence\nof tile assembly systems that simultaneously perform two forms of self-stabilization: proofreading and selfhealing. Our general reduction and proof techniques can be extended to the programming of self-assembling\nagents in a variety of media, not just DNA tiles, and not just two-dimensional surfaces.\nSeveral researchers have voiced intuitions about a connection between self-assembly and distributed\ncomputing, for example Klavins [10], or an Arora et al. 2007 NSF Report [11]. However, the first rigorous\napplication of the theory of distributed computing to questions in self-assembly appeared in [4]. Subsequent\nto [4] (and its extended version [12]), we used the wait-free consensus hierarchy to separate models of\nself-assembly based on their synchronization power [13]; and we showed that graph assembly systems (a\ngraph grammar self-assembly formalism due to Klavins) are distributed systems in a strong sense [14]. To\nthe best of our knowledge, the current paper is the first to consider self-assembly within the context of\nmemory consistency models, and the first to apply multiprocessor programming techniques to biomolecular\ncomputation\nThe rest of the paper is structured as follows. Section 2 provides background on tile assembly models\nand memory consistency models. In Section 3.1 we reduce the Abstract Tile Assembly Model to a DSM\nsystem that obeys causal consistency. In Section 3.2 we reduce the Kinetic Tile Assembly Model to a DSM\nsystem that obeys GWO. In Section 4 we show how to generalize an existence theorem about proofreading\nand self-healing tilesets by using techniques from self-stabilizing algorithms. Section 5 concludes the paper\nand suggests directions for future research.\n\n2\n2.1\n\nBackground\nTile assembly background\n\nWe now give the formal definitions of the tile assembly models we will work with.\nAbstract Tile Assembly Model Winfree's objective in defining the Abstract Tile Assembly Model was\nto provide a useful mathematical abstraction of DNA tiles combining in solution in a nondeterministic,\nasynchronous manner [5]. Rothemund [6], and Rothemund and Winfree [15], extended the original definition\nof the model. For a comprehensive introduction to tile assembly, we refer the reader to [6]. Intuitively, we\ndesire a formalism that models the placement of square tiles on the integer plane, one at a time, such that\neach new tile placed binds to the tiles already there, according to specific rules. Tiles have four sides (often\nreferred to as north, south, east and west) and exactly one orientation, i.e., they cannot be rotated.\nA tile assembly system T is a 5-tuple (T, \u03c3, \u03a3, \u03c4, R), where T is a finite set of tile types; \u03c3 is the seed tile\nor seed assembly, the \"starting configuration\" for assemblies of T ; \u03c4 : T \u00d7 {N, S, E, W } \u2192 \u03a3 \u00d7 {0, 1, 2} is an\nassignment of symbols (\"glue names\") and a \"glue strength\" (0, 1, or 2) to the north, south, east and west\nsides of each tile; and a symmetric relation R \u2286 \u03a3 \u00d7 \u03a3 that specifies which glues can bind with nonzero\nstrength. In this model, there are no negative glue strengths, i.e., two tiles cannot repel each other.\nA configuration of T is a set of tiles, all of which are tile types from T , that have been placed in the plane,\nand the configuration is stable if the binding strength (from \u03c4 and R in T ) at every possible cut is at least\n2. An assembly sequence is a sequence of single-tile additions to the frontier of the assembly constructed at\nthe previous stage. Assembly sequences can be finite or infinite in length. The result of assembly sequence\n\u2192\n\u2212\n\u2212\n\u03b1 is the union of the tile configurations obtained at every finite stage of \u2192\n\u03b1 . The assemblies produced by T is\nthe set of all stable assemblies that can be built by starting from the seed assembly of T and legally adding\ntiles. If \u03b1 and \u03b2 are configurations of T , we write \u03b1 \u2212\u2192 \u03b2 if there is an assembly sequence that starts at \u03b1\nand produces \u03b2. An assembly of T is terminal if no tiles can be stably added to it.\nWe are, of course, interested in being able to prove that a certain tile assembly system always achieves a\ncertain output. In [8], Soloveichik and Winfree presented a strong technique for this: local determinism. An\n\u2212\n\u2212\nassembly sequence \u2192\n\u03b1 is locally deterministic if (1) each tile added in \u2192\n\u03b1 binds with the minimum strength\n2\n\n\frequired for binding; (2) if there is a tile of type t0 at location l in the result of \u03b1, and t0 and the immediate\n\u2212\n\"OUT-neighbors\" of t0 are deleted from the result of \u2192\n\u03b1 , then no other tile type in T can legally bind at l;\n\u2192\n\u2212\nthe result of \u03b1 is terminal. Local determinism is important because of the following result.\nTheorem 1 (Soloveichik and Winfree [8]). If T is locally deterministic, then T has a unique terminal\nassembly.\nKinetic Tile Assembly Model The Kinetic Tile Assembly Model (kTAM) was defined by Winfree [5],\nto provide a mathematical model for self-assembly (and disassembly) in solution, based on the kinetics of\nchemical reactions. Slightly different versions of the kTAM appear in different papers on the subject. We\nwill follow the treatment in [16], because we will use techniques from distributed computing to address an\nopen question in [16].\nWhereas the aTAM is an error-free, irreversible, nondeterministic model, the kTAM is a probabilistic\nmodel in which tiles bind with some probability of error, and bound tiles can dissociate with some probability.\nThese probabilities are derived from the equations of chemical reaction kinetics. There is a forward rate f ,\nwhich we assume is the same for any tile type at any position of the perimeter in the growing assembly,\ndefined as f = kf e\u2212Gmc , where kf is a constant that sets the time scale, and Gmc is the logarithm of\nthe concentration of each tile type in solution. We assume that tiles can only fall off of the perimeter of\nthe assembly; this assumption matches experimental observation. The rate of dissociation (reverse rate rb )\ndepends exponentially on the number of bonds that must be broken: rb = kf e\u2212bGse , where b is the total\ninteraction strength with which the tile is attached to the assembly, and Gse is the unit bond free energy,\nwhich may depend on the overall temperature of the system.\nAs with our treatment of the aTAM, we assume that \"strength 2\" bonds are sufficient for tiles in the\nkTAM to bind stably. Hence we let f = r2 , which ensures that the forward growth of the kTAM mirrors\n(with high probability) the binding rules of the aTAM, and incorrectly bound tiles (with high probability)\nquickly dissociate. We assume that kf is a physical constant that cannot be experimentally controlled, but\nby changing concentrations or temperature we could change Gmc and/or Gse .\nOne objective of this paper is to develop proof techniques that would be applicable to models of selfassembly other than the aTAM and kTAM. To this end, we will not use all the information available about\nthe kTAM when we simulate it, but rather will use a more general construction, with the understanding that\nspecific values for probabilities could be plugged in as required, based on the rate equations of the kTAM.\nIn particular, we will limit ourselves to the existence of a forward rate f which is the same for each bond, a\nreverse rate rb which is much higher for erroneous bonds than for correct ones, and an error probability \u03c0e\nthat a tile will bind incorrectly to the frontier of the assembly.\n2.2\n\nDistributed shared memory background\n\nA distributed shared memory model (or system) is a model of distributed processors and (possibly shared)\nread/write registers. A processor p can perform a read or a write on register r, if p has permission to perform\nthat operation on r. The only operations a processor can perform on a register are reads and writes. The\nread operation begins with an invocation and terminates when p receives a value. The write operation begins\nwith an invocation that includes a value, and ends when p receives an ack. A processor can only perform\none operation at a time. We do not assume atomicity of reads and writes to a given register r.\nA memory consistency model specifies the allowable behavior of memory. Study of memory consistency\nmodels arose from a conflict between the goals of hardware and compiler designers, to permit aggressive\noptimization (which requires \"weak\" memory consistency), and the desire of programmers to have concurrent\ncode execute in a predictable fashion (which requires \"strong\" memory consistency). We refer the reader\nto [17] for a survey and tutorial on these issues. In 2004, Steinke and Nutt presented a theory that unified the\nvarious memory consistency models that had been proposed in the literature [9]. They showed the existence\nof a lattice of 13 memory consistency models; this lattice contained all known models, and showed the logical\ninterrelation between each. We now describe the memory consistency conditions that will be most important\nfor this paper.\n3\n\n\fA system of distributed processors is sequentially consistent [18] if the result of any execution is the same\nas if the operations of all the processors were executed in some sequential order, and the operations of each\nindividual processor appear in this sequence in the order specified by its program. A system of distributed\nprocessors is causally consistent [7] if for each processor the operations of that processor plus all writes known\nto that processor appear to that processor to appear in a total order that respects potential causality. A\nsystem of distributed processors is PRAM consistent [19] if writes performed by a single processor are seen\nby all other processors in the order in which they were issued, but writes from different processors may be\nseen in different orders by different processors. These three consistency conditions are in descending order of\nstrength: a sequentially consistent system is causally consistent, and a causally consistent system is PRAM\nconsistent, but the converses do not always hold.\nTo compare consistency conditions, Steinke and Nutt defined logical properties about processor views of\na DSM system. A processor view is a total order on a subset of operations that occurred during an execution\nof a DSM system, the subset being those operations an individual processor performed or could deduce\noccurred. The property GPO (\"global process order\") is the condition that there is global agreement on the\norder of operations from each process. The property GWO (\"global write-read-write order\") is the condition\nthat there is global agreement on the order of any two writes when a process can prove it has read one before\nthe other. A DSM system satisfies GPO exactly when it is PRAM consistent, and it satisfies both GPO and\nGWO exactly when it is causally consistent.\nA relation \u227a is a causality order of operations if o1 \u227a o2 means that one of the following holds for any\noperations o1 and o2 :\n1. o1 and o2 were performed by the same processor p, and p executed o1 before o2 .\n2. o2 reads the value written to a shared register by o1 .\n3. There is some other operation o0 such that o1 \u227a o0 \u227a o2 .\nWe will say that program P is concurrent-write free in DSM model M if every processor in M runs P , and\nthere is no legal execution history H of P such that the causality order induced by H contains two writes\nw1 and w2 such that w1 \u2280 w2 and w2 \u2280 w1 (i.e., there are no writes that are causally concurrent under\nany possible execution). In other words, P is concurrent-write free if a single program Q that simulates each\nprocessor in the system executing P is concurrent-write free under the standard definition that no execution\nof Q contains conflicting writes.\n\n3\n3.1\n\nReduction of tile assembly models to distributed shared memory models\nThe aTAM reduces to causally consistent models of DSM\n\nThe objective of this section is to show that the aTAM can be simulated by a causally consistent DSM system,\nand, under a reasonable definition of \"simulation,\" no DSM system that fails to obey causal consistency can\nsimulate the aTAM. First, we define formally what it means for a DSM system to simulate a tile assembly\nsystem. For simplicity, we limit consideration to tile assembly systems that self-assemble on the first quadrant\nof Z2 ; our definitions could be extended to the entire integer plane.\nDefinition 1. Let T = hT, \u03c3, \u03a3, \u03c4, Ri be a tile assembly system in the aTAM, and M be a model of distributed\nprocessors. We say M simulates T on the k \u00d7 k surface if the following holds.\n1. The network topology of M is that of a k \u00d7 k square.\n2. Each processor pij (0 \u2264 i, j < k) in M has a write-once output register \u03c1ij that is initialized to value\nEMPTY, and can take on |T | distinct values other than EMPTY.\n3. There is a bijection \u03c8 from tile types in T to possible values of \u03c1 (not including EMPTY).\n\u2212\n4. For each legal tile assembly sequence \u2192\n\u03b1 of T , there is a legal execution E of M such that, if tile type t\n\u2192\n\u2212\nis placed on coordinate (i, j) in \u03b1 , then processor pij writes \u03c8(t) to \u03c1ij in E. Moreover, processors write\n\u2212\nto their respective \u03c1 in E in the same order that tiles get placed on the surface in \u2192\n\u03b1 . (The placement of\nthe seed assembly \u03c3 is simulated by writing the value \u03c8(t) to \u03c1ij if \u03c3(i, j) = t.)\n4\n\n\f\u2212\n5. For each legal execution E of M , there is a corresponding legal assembly sequence \u2192\n\u03b1 , such that if pij\n\u2192\n\u2212\nwrites \u03c8(t) to \u03c1ij , then tile type t is placed on location (i, j) in \u03b1 . Moreover, the order of writing values\n\u2212\nin E is preserved by the order of placing tiles in \u2192\n\u03b1.\nIntuitively, M simulates T on a finite surface if each process in M behaves like a location on the surface, with\neach processor executing a local algorithm that mimics the binding rules required by R. We now generalize\nthe above definition to arbitrary tile assembly systems.\nDefinition 2. Let T be a tile assembly system in the aTAM. We say a class M = {M0 , M1 , . . .} of DSM\nmodels simulates T if, for each k \u2208 N, Mk simulates T on a k \u00d7 k surface. Let \u03c6 be a mapping from tile\nassembly systems to algorithms. Then we say that (M, \u03c6) simulates the aTAM if, for any tile assembly system\nT , M simulates T when the processors in the models in M run \u03c6(T ) as their local algorithm, beginning at\nan initial state determined by the seed assembly \u03c3 as above.\nWe now prove that there exists a class of causally consistent DSM models that simulates the aTAM.\nTheorem 2. There exists a class of DSM models M that simulates the aTAM. Each M \u2208 M is causally\nconsistent. Further, the models in M do not obey a memory consistency condition in Steinke and Nutt's\nlattice that is stronger than causal consistency.\nProof. Fix k \u2208 N. We define a DSM model Mk as follows. M contains k 2 processors, with network graph of\na k \u00d7 k grid. We will refer to the processors as pij (i, j < k), to denote the processor at location (i, j) in the\nnetwork grid. Note this is a convenience for the proof; the processors do not have unique ID's, and do not\nknow whether they are on the edge, the corner, or the interior of the grid. We assume that all tile assembly\nsystems have temperature 2, as that is sufficient for Turing universality. Each processor can read from two\n1\n2\nregisters, rij\nand rij\n. Each processor can write to twelve registers, r1 , r2 and Index of each of its neighbors\nto the north, south, east and west on the grid. (For processors on the edge of the grid, these registers exist,\nand ack when written to, but no processor ever reads from them if they \"belong\" to nonexistent processors.\nThis way, a processor cannot deduce that it is on the edge of the grid.) To simulate \u03c4 > 2, we could use\nregisters r1 , . . . , r\u03c4 instead of just two such registers per processor.\nThe register Indexij is initialized to the value 1, and can take 3 possible values: 1, 2, and \"1 and 2.\" The\nalgorithm each processor runs will look first at the value in Index to determine whether to write to r1 , r2\nor both.\nEach processor pij has a write-once register \u03c1ij initialized to the value EMPTY. Only pij can write to\n\u03c1ij , and it can write one of |T | distinct values. Fix a bijection \u03c8 between tile types of T and possible values\nthat can be written to each \u03c1. The processors of Mk all run a common nondeterministic, distributed, local,\nalgorithm as follows. Before starting execution, Mk is configured to simulate the seed assembly of T : for\ni, j < k, if \u03c3(i, j) 6= \u2205 then pij writes \u03c8(\u03c3(i, j)) to \u03c1ij .\nOnce placement of the seed assembly is simulated, execution of the algorithm proceeds in synchronized\nstages (rounds), beginning at stage s = 0. At the start of time stage s, if at stage s \u2212 1, pij wrote a value\n\u03c8(t) (for t \u2208 T ) to \u03c1ij , then pij writes to each of its neighbors in a way that communicates the glues and glue\nstrengths of the tile pij is simulating, as follows. (We limit discussion to communication with the neighbor\nto the north; communication to the other neighbors is similar.)\nFirst, pij reads Indexij+1 . If pij wants to communicate a bond with strength 2 to its northern neighbor,\n1\n2\nthen it writes its message in both rij+1\nand rij+1\n. If it wants to communicate a bond with strength 1, then\n1\n2\npij writes hS, gi to rij+1 , to rij+1 , or to both registers, based on the value it read from Indexij+1 ; here g is\na message that corresponds to the glue type on the north side of t. This indicates to the northern neighbor\nof pij that glue type g is present immediately to the south. More generally, each message written to r1 or r2\nof a given processor will be of form hd, gi where d \u2208 {N, S, E, W} is a direction, and g is a glue type.\nAfter processors write, the second phase of stage s takes place as follows. The algorithm of exactly one\nprocessor pij (chosen nondeterministically from the set of processors that could legally write a value to their\nrespective \u03c1 using the protocol explained below) with pij still set to EMPTY chooses (again nondeterminis1\n2\n1\ntically) which message it will \"hear\" in each of rij\nand rij\n, of all the messages that have been written to rij\n2\nand rij since the start of execution of the algorithm. Processor pij then writes a value to \u03c1ij , by applying \u03c8\n5\n\n\fand \u03c8 \u22121 to the binding rules induced by the relation R of T , so pij writes \u03c8(t) for some t such that t can\n1\n2\nlegally bind given neighbors with glue types as indicated by the values of rij\nand rij\n. If more that one tile\ntype can legally bind given the same set of neighbors, the value \u03c8(t) is again chosen nondeterministically\nfrom the set of legal values.\nFinally, pij \"increments\" the value of Index of each of its neighbors that it wrote to. Continuing with\nour example of writing to the northern neighbor, if the value is 1, it writes the value 2 to Indexij+1 . If the\nvalue is 2, it writes \"1 and 2\" to Indexij+1 . This concludes stage s of the algorithm.\nMk simulates T on a k \u00d7 k surface in the \"natural\" way. For each nondeterministic run of T , i.e., each\n\u2212\ntile assembly sequence \u2192\n\u03b1 , there is a nondeterministic execution of Mk such that the behavior of each pij\n\u2212\nmimics the behavior of the location (i, j) in \u2192\n\u03b1 . Similarly, for each nondeterministic execution E of Mk , there\nis a legal tile assembly sequence that makes the same nondeterministic choices, since the choices of E are\nconstrained by the binding rules that determine the legal behavior of any assembly sequence of T .\nSince our choice of k was arbitrary, we can define M = {Mk | k \u2208 N}. Such an M simulates T . Further,\nour definition of each Mk was uniform with respect to any set of binding rules determined by a given R. So\nwe can define a class of models M0 such that each Mk0 runs an algorithm that simulates \u03c3 and R for any tile\nassembly system. Hence there is a class of models M0 that simulates the aTAM.\nWe turn now to the memory consistency conditions obeyed by the Mk0 . First, each Mk0 must be causally\nconsistent, because each processor writes only once to any memory location, and writes deterministically\nbased on values read from other writes (values written either to r1 and r2 ), or at stage 0 to simulate the\nseed assembly, which is a finite, completely determined set of decisions. Therefore, for any process pij , the\noperations of that process, and any writes known to that process, occur in a total order that respects potential\ncausality, even though the values of those writes were nondeterministically chosen.\nCausal consistency is an upper bound for the memory consistency of the Mk0 as well. This is because\nthe only memory consistency conditions that are stronger than causal consistency in the lattice by Steinke\nand Nutt are conditions that include the property GDO (Global Data Order, which is equivalent to cache\nconsistency). But Mk0 makes no guarantee that all writes to the same memory location are performed in\nsome sequential order: a write to r1 or r2 that occurs at an earlier stage than another write may still be\nnondeterministically chosen as the value of that register in a legal execution. So causal consistency exactly\ncaptures the memory consistency of this simulation of the aTAM.\nIt is worth noting that if a DSM model is going to simulate the behavior of a tile assembly system in the\naTAM, then causal consistency is the weakest memory consistency model it can follow. This is so because\ncausal consistency is the combination of properties GPO and GWO. If a DSM model does not satisfy GPO\n(i.e., does not satisfy PRAM consistency), then consider processor pij that writes multiple times to a neighbor\nq, yet q does not see these writes in the order in which they were issued. There is no legal tile assembly\nsequence that corresponds to such an execution, as tiles in the aTAM are placed one at a time, error-free,\nbased on information transmitted to neighboring locations by already-placed tiles. Similarly, if a DSM model\ndoes not satisfy GWO, there exists some execution where q1 and q2 disagree on the ordering of writes, even\nthough q1 can prove that a particular write happened first. As before, no legal tile assembly sequence captures\nthis behavior, as a tile assembly sequence induces a total order on the system, such that at each stage of\nassembly, a newly placed tile communicates its glue types to all neighboring locations. So with respect to\nthe lattice defined by Steinke and Nutt, causal consistency is \"tight\" for simulations of the aTAM.\nWe now show that, under our reduction, locally deterministic tile assembly systems correspond to an\nimportant class of simulating programs. Let P be a program that simulates a tile assembly system; we will\ncall P binding-rule determined if for each set of messages that simulates strength 2 bonds, there is at most\none value P writes to \u03c1 to simulate a tile type. It is easy to check whether P is binding-rule determined, but\nharder to check whether a tile assembly system is locally deterministic, as we discuss below.\nTheorem 3. Let M be the class of DSM systems in Theorem 2. Then if T is a locally determinstic assembly\nsystem, the program P for which hM, P i simulates T is concurrent-write free. Conversely, if M running\nconcurrent-write free, binding-rule determined, program P , simulates tile assembly system T , then T is locally\ndeterministic.\n6\n\n\f\u2212\nProof. Let T be a locally deterministic tile assembly system, let \u2192\n\u03b1 be a legal assembly sequence of T ,\n\u2192\n\u2212\nand let (x, y) be a location in the result of \u03b1 . As before, we assume we are operating within the aTAM\n\u2212\nat temperature 2. Either (x, y) is part of the seed assembly, or, in the sequence \u2192\n\u03b1 , prior to a tile being\nplaced at (x, y), either one neighbor of (x, y) has a tile placed with a strength 2 bond incident to (x, y),\n\u2212\nor two neighbors have tiles placed with strength 1 bonds incident to (x, y). The simulation of \u2192\n\u03b1 in M via\n1\nthe reduction of Theorem 2 produces a concurrent-write free program, as for processor pxy , each of rxy\nand\n2\nrxy is written to at most once; and, if two neighbors of pxy write to Indexxy with writes w1 and w2 , in all\nlegal execution histories, there will be an operation of one processor reading the value written by the other\nprocessor to Index in between w1 and w2 , so either w1 \u227a w2 or w2 \u227a w1 , because of the definition of causal\nordering.\nConversely, suppose hM, P i simulates a tile assembly system T , and P is concurrent-write free. Then\n1\n2\nthere is no execution history for hM, P i that contains concurrent writes on rij\nand rij\nfor any pij . But this\nmeans that at most two neighbors could have written to the registers of pjk , as otherwise two neighbors q1\n1\nand q2 would have written to rij\n, and causal consistency permits histories in which those writes could happen\nin either order. So the writes are concurrent after all, contrary to assumption. So at most two neighbors\nwrite to any location before that location decides which tile type to simulate. Further, suppose one of the\nneighbors of pij that writes to the registers of pij before pij decides, writes to pij with a strength 2 bond.\n1\n2\nThen that neighbor writes to both rij\nand rij\n, so no other neighbor can write to the registers of pij before pij\ndecides, or there will be concurrent writes, by the above argument. Hence the neighbors writing to pij write\nmessages that simulate exactly a strength 2 bond. Finally, since P is binding-rule determined, the conditions\nof local determinism are satisfied, and T must be locally deterministic.\n\"T is locally deterministic\" is an undecidable property, as the standard tile assembly Turing machine simulation is locally deterministic, and it could be modified to do something not locally deterministic iff a machine\nachieves a halting state. Nevertheless, it would be useful to test for that property when programming-and\ndebugging-a tile assembly system, hence self-assembly simulation and programming tools have attempted\nto include that functionality [20] [21]. Theorem 3 classifies this problem precisely, and indicates that programming techniques to ensure [22], and detect [23], data-race freedom and concurrent-write freedom in\nparallel systems can be used productively to program self-assembling agents.\n3.2\n\nThe kTAM reduces to GWO-consistent models of DSM\n\nWhereas the aTAM was a nondeterministic model, the kTAM is a stochastic model. In order to apply a\nresult about self-stabilizing algorithms to the kTAM, we will construct a DSM simulation whose processors\nrun deterministic algorithms and whose registers return values probabilistically, for example by providing\nerroneous information with some nonzero probability. We use the same definition as above for what it means\nfor a DSM system to simulate a tile assembly system, except substituting \"kTAM\" for \"aTAM\" when it\nappears, and the \u03c1ij can be written to multiple times, not just once, since the kTAM is a reversible model\nin which binding errors can occur. It turns out that the probabilistic behavior of the registers is captured by\nthe memory consistency condition GWO.\nTheorem 4. There exists a class of DSM models M that simulates the kTAM. Each Mk \u2208 M obeys GWO.\nFurther, the models in M do not obey a memory consistency condition in Steinke and Nutt's lattuce that is\nstronger than GWO.\nProof. We use a DSM system that is largely the same as the one used in Theorem 2: each processor has an\nIndex register, registers r1 , r2 , and \u03c1. Index and \u03c1 when read always returns the most recent value written\nto them, but r1 and r2 only satisfy a weaker consistency condition, as follows.\nLet V = {EMPTY, v1 , v2 , . . . , vi } be the set of values that has been written to r1 (the behavior of r2\nwill follow this same condition also). Let \u03c0e be the probability of a tile binding error in the kTAM. Then,\nwhen r1 is read, with probability \u03c0e it returns a value that simulates a glue in the tile assembly system, but\nis not a value that had been previously written to r1 . With probability 1 \u2212 \u03c0e , r1 returns one of the values\npreviously written to it. This value is determined by selecting at random from the sample space V , with\n7\n\n\feach of the vi weighted by f . Lastly, if in a previous stage, r1 returned an erroneous value, at subsequent\nstages, with probability rb , r1 when read will return the value EMPTY; this simulates the dissociation of a\nbond. After returning the value EMPTY, r1 no longer returns EMPTY with probability rb , unless at some\nfuture stage it returns an erroneous value again.\nExecution of the algorithm proceeds in synchronous rounds, much as before. This time, though, instead\nof one processor nondeterministically choosing to be the location to act this round, all processors on the\nperimeter of the simulated assembly act if they can. (Recall that the kTAM assumes, consistent with experimental observation, that addition and dissociation of tiles only occurs on the perimeter; we mimic that\nassumption here.) The specific algorithm is as follows.\nAt stage 0, each pij that is part of the seed assembly writes the appropriate value to \u03c1ij . All other \u03c1, and\nall r1 and r2 are initialized to EMPTY. All values of Index are set to 1.\nAt stage s \u2265 1, all pij with non-EMPTY value in \u03c1ij write glues to their neighbors following the same\nmethod as in the aTAM simulation (i.e., reading from Index and using that value to determine which subset\nof {r1 , r2 } to write to). Then, each processor on the perimeter of the assembly reads the contents of its r1\nand r2 ; those registers return values probabilistically, as explained above. Each processor on the perimeter\nthen writes to \u03c1, if appropriate (based on the binding rules of T ), perhaps to EMPTY. To conclude the\nround, processors that sent messages at the beginning of the round increment the value of the appropriate\nIndex registers, similar to the aTAM simulation.\nThe behavior of each pij mirrors the behavior of the locations of the surface on which T is assembling.\nSo for any legal execution of M, there is a legal tile assembly sequence in which the tiles were placed in the\nsame order. Note that there is a significant change from the previous simulation: multiple processors may\nact in a round, instead of just one at a time, as in the aTAM simulation, so multiple locations may write to\nthe same r1 . That is consistent with our definition of \"simulation,\" because for every tile assembly sequence\nof T , there will be an execution of M that writes to each \u03c1 in the same order that locations add or remove\ntiles. The order is what matters, not the exact time step at which a change takes place. So M simulates the\nkTAM.\nWe now show that M obeys GWO, but no stronger consistency model in the lattice of Steinke and\nNutt. Recall that GWO means that there is global agreement on the order of potentially causally-related\nwrites. The writes of processor p are causally related in history H to the writes of processor q only if one\nprocessor simulates a tile that binds or dissociates, and there is a sequence of processors (WLOG from p\nto q) S = hp, p1 , p2 , . . . , qi, such that each processor is a neighbor of its successor, and each processor chose\nto simulate its particular tile type because of information written to it by its predecessor. There is global\nagreement on the ordering of writes, because any processor q 0 that could view a write w by p0 , or view a\nwrite causally related to w, is a member of a sequence S 0 from p0 to q 0 as above. So M satisfies GWO.\nOn the other hand, M does not satisfy either of the consistency conditions immediately stronger than\nGWO in Steinke and Nutt's lattice. These two stronger conditions are causal consistency (GPO+GWO),\nand GDO+GWO, where GDO is equivalent to cache consistency. M does not satisfy GDO for the same\nreason as in the aTAM simulation: there is no guarantee that writes performed to a given memory location\nwill return the most recent value as a read. GPO, which is equivalent to PRAM consistency, was satisfied by\nthe DSM models simulating the aTAM, but is not satisfied under this model because of the possibility that\na register will return a value that has never been written to it. This is in fact a violation of slow consistency,\nwhich requires that a read return a value that has previously been written to it. Slow consistency is strictly\nweaker than PRAM consistency, hence PRAM consistency cannot be satisfied. So GWO is the strongest\nconsistency condition in the lattice obeyed by M.\nAs in the previous section, there is a sense in which GWO is the \"tight\" memory consistency condition\nfor kTAM simulation. The only consistency condition in Steinke and Nutt's lattice weaker than GWO is\nlocal consistency, which requires that each process's local operations appear to occur in the order specified\nby its program. Without such a requirement, processors in a simulation could potentially change the value\nof \u03c1 before receiving the values written to them by their neighbors, which would be inconsistent with our\nintuition of simulating tiles binding to other tiles. However, the lack of consistency conditions between local\nconsistency and GWO is due only to the fact that no one has defined and studied such conditions, not because\n8\n\n\fit is logically impossible to do so. More precise consistency conditions for simulation of error-permitting selfassembly may be an area of future investigation.\n\n4\n\nSelf-stabilization applied to tile self-assembly\n\nNow that we have reduced the kTAM to models of DSM that run deterministic algorithms with sometimesfaulty registers, we can apply the theory of self-stabilization to prove the existence of certain error-correcting\ntile assembly systems. Recall that a distributed system is self-stabilizing if, starting from any initial state, the\nsystem is guaranteed to converge to, and stay in thereafter, one of a set of \"legitimate\" states; this research\ntopic was begun by Dijkstra [24]. In the case of tile assembly, the legitimate states are the assemblies\nachievable from error-free assembly sequences.\nWhile not in wide use in the distributed computing literature, there is a simple, polynomial-time conversion that, given a constant-time local algorithm, yields a constant-time self-stabilizing algorithm [25] [26].\n(See [27] for a recent exposition of this conversion, with additional motivation and examples.) Molecular selfassembly algorithms are inherently local, and the self-assembly literature has considered two main classes\nof self-stabilizing algorithms: proofreading tilesets [28], which correct initial binding errors; and self-healing\ntilesets [29], which rebuild completed assemblies that have been damaged. Soloveichik et. al. recently demonstrated a \"proof of concept,\" by constructing a tile assembly system that combined both proofreading and\nself-healing properties within a restricted version of the kTAM [16]. Their construction worked for tile assembly systems that only built north and east. We can use tools from self-stabilization to generalize their\nresult to the full kTAM, and to locally deterministic models that grow in any direction.\nIf T is a tile assembly system, the c-scaled result of T is the colored shape on the integer plane obtained\nby \"blowing up\" each location in the result of T to a c \u00d7 c block of tiles, such that each tile in the block is\ncolored the same as the tile on the source location in the result of T .\nTheorem 5. There is a polynomial-time algorithm that does the following: upon input of a locally deterministic tile assembly system T for the kTAM, it outputs a self-healing, proofreading, tile assembly system\n\u00012\nT 0 such that T 0 builds the c-scaled result of T , for some constant c. Further, |T 0 | \u2264 43 c2 |T |2 .\nProof. Let T be a locally deterministic tile assembly system, and let hM, P i be the DSM model that simulates\nit, as produced by the reduction in Theorem 4. Then let P \u2217 be the self-stabilizing algorithm obtained by\napplying the conversion of [25] [26] to P . (Briefly, P is a constant-time algorithm. To convert P to a selfstabilizing algorithm, \"unroll\" all possible executions of P , over all possible inputs, as a circuit. The program\nP \u2217 simulates that circuit, and assumes the inputs to the circuit are correct. Then it repeats that same step k\ntimes, where k is large enough such that, with high probability, all the inputs at round k really are correct.)\nP \u2217 is also a constant-time algorithm, whose running time depends on the size of the P -simulating circuit\nand the value of k we choose.\nAs tile assembly is Turing universal, we can of course convert P \u2217 into tiles. More importantly, there\nis some constant c such that we need lay out only c-many tiles in order to simulate the behavior P \u2217 on\nany of its legal inputs. WLOG we assume that c is large enough, and our tile simulation is \"padded\" if\nnecessary, so that the simulation of P \u2217 , on input of tile type t, takes up a c \u00d7 c square, for any t. Further,\nwe dedicate a set of tile types to each input t, so the color of each tile in this c \u00d7 c square is the same color\nas the input tile t. Finally, in order to ensure that self-healing does not generate nondeterministic behavior,\nwe have to differentiate each tile that could potentially add tiles in more than one direction. (This is why\nthe construction in [16] assumed that tiles could only grow north and east.) In other words, if a \"hole gets\npunched\" in a completed assembly, self-healing tiles can rebuild the empty area, by building in the reverse\ndirection from the original assembly sequence. So for each tile type in T , we need T 0 to include a unique tile\ntype that encodes \"Tile type t attached to the assembly using input sides S.\" It takes at least one side to\nattach, so at most three sides of t remain as output sides, which is where we need to encode the information\nto reverse the process of binding t at that location.\nSo the number of tiles we need to place into T 0 to simulate\n\u0001\n4\na given tile t of T is upper-bounded by 3 . Further, we need sufficient new tile types that encode \"I have\n9\n\n\f4\n3\n\n\u0001\n\n|T | of those. Since for each tile type in\n\u00012\nT there are at most c tile types that simulate P on t, we get the overall upper-bound |T 0 | \u2264 43 c2 |T |2 .\nreceived information from tile type t.\" There are at most another\n2\n\n\u2217\n\nA discussion of theoretical and practical reasons to choose particular values of k (i.e., the optimal number\nof iterations to minimize the possibility of error) for DNA self-assembly appears in [16]. For our purposes,\nit suffices to use the conversion from constant-time algorithm to self-stabilizing algorithm as a black box,\nwithout considering the specific types of error that are most likely to occur in the kTAM. Therefore, Theorem 5 gives much weaker tile complexity bounds than the dedicated construction that appears in [16], but\nit provides a general method that can be extended to a variety of self-assembly models, not just DNA tiling,\nand not just two-dimensional surfaces.\nTheorem 5 may be a \"proof of applicability\" of self-stabilization techniques to self-assembly, but more is\nneeded than \"just\" self-stabilization. Perhaps the most troublesome form of error in nanoscale self-assembly\nexperiments occurs when a tile binds incorrectly, and then other tiles bind around it, preventing it from\ndissociating. To address this in the language of self-stabilization, one needs a fault-containing self-stabilizing\nalgorithm with minimal fault gap [30], that is to say, a self-stabilizing algorithm in which the effects of a\nprocessor's failure are contained within that processor's local neighborhood, and, after recovering from a\ngiven fault, there is only a small time gap until the system can recover from a new fault. Fujibiyashi et al.\nhave suggested extending the kTAM with special tile mechanisms that would achieve a one-time-step fault\ngap with high probability [31], though they did not phrase their results in the language of self-stabilization.\nThere is some evidence that handling fault-containment probabilistically instead of deterministically will\nreduce an algorithm's fault-gap [32], but little is known about such tradeoffs, either in self-assembly or in\ngeneral distributed systems.\n\n5\n\nConclusion\n\nIn this paper, we reduced the Abstract Tile Assembly Model and the Kinetic Tile Assembly Model to systems\nof distributed shared memory with particular memory consistency conditions. We then applied the reductions\nto show that (1) local determinism is closely related to concurrent-write freedom in parallel programming,\nand (2) the theory of self-stabilization can be usefully applied to questions of error correction in self-assembly.\nWe focused on the aTAM and the kTAM because they have been the most theoretically studied selfassembly models. However, both models are limited to the binding of DNA tiles to other DNA tiles, and as\nthe recent nanofabrication survey [2] points out, the \"greatest promise\" of algorithmic DNA self-assembly\n\"may lie in applications where DNA nanostructure templates have been used to assemble other inorganic\ncomponents and functional groups.\" The IBM/Caltech microchip project is an example of this research\ndirection. Therefore, we believe it is critical to develop a programming theory for \"mixed-media\" models of\nself-assembly (such models by-and-large do not yet exist), and that programming theory may be advanced\nby continuing the investigation begun in this paper.\nFrom the perspective of \"pure theory,\" there has been initial work to classify shared read/write variables [33], much as Steinke and Nutt classified known memory consistency systems. It would be useful\nto explore further the weak consistency, like GWO, offered by registers that simulate the binding of selfassembling agents, whether in DNA or another medium. It would also be useful to explore what \"more\nrobust\" registers (like the consensus objects in [13]) could be built, to know how agents might cooperate to\nform more fault-tolerant structures. Lastly, we believe it would be productive to explore further the relationship between self-assembling structures and the placing of geometric constraints on local and self-stabilizing\nalgorithms.\n\nAcknowledgments\nI am grateful to Soma Chaudhuri, Christoph Lentzen, Jack Lutz, Paul Rothemund, David Soloveichik, Jukka\nSuomela and Erik Winfree for helpful discussions.\n10\n\n\fReferences\n1. Kershner, R.J., Bozano, L.D., Micheel, C.M., Hung, A.M., Fornof, A.R., Cha, J.N., Rettner, C.T., Bersani, M.,\nFrommer, J., Rothemund, P.W.K., Wallraff, G.M.: Placement and orientation of individual DNA shapes on\nlithographically patterned surfaces. Nature Nanotechnology (August 11, 2009)\n2. Li, H., Carter, J.D., LaBean, T.H.: Nanofabrication by DNA self-assembly. Materials Today 12(5) (May 2009)\n24\u201332\n3. Roweis, S.T., Winfree, E., Burgoyne, R., Chelyapov, N.V., Goodman, M.F., Rothemund, P.W.K., Adleman, L.M.:\nA sticker-based model for DNA computation. Journal of Computational Biology 5(4) (1998) 615\u2013630\n4. Sterling, A.: A limit to the power of multiple nucleation in self-assembly. In Taubenfeld, G., ed.: DISC. Volume\n5218 of Lecture Notes in Computer Science., Springer (2008) 451\u2013465\n5. Winfree, E.: Algorithmic Self-Assembly of DNA. PhD thesis, California Institute of Technology (1998)\n6. Rothemund, P.W.K.: Theory and Experiments in Algorithmic Self-Assembly. PhD thesis, University of Southern\nCalifornia (2001)\n7. Ahamad, M., Neiger, G., Burns, J.E., Kohli, P., Hutto, P.: Causal memory: Definitions, implementation and\nprogramming. Distributed Computing 9(1) (1995) 37\u201349\n8. Soloveichik, D., Winfree, E.: Complexity of self-assembled shapes. SIAM J. Comput. 36(6) (2007) 1544\u20131569\n9. Steinke, R.C., Nutt, G.J.: A unified theory of shared memory consistency. J. ACM 51(5) (2004) 800\u2013849\n10. Klavins, E.: Programmable self-assembly. Control Systems Magazine 24(4) (August 2007) 43\u201356\n11. Arora, S., Blum, A., Schulman, L., Sinclair, A., Vazirani, V.: The computational worldview and the sciences: a\nreport on two workshops. NSF Report (October 2007)\n12. Sterling, A.: A time lower bound for multiple nucleation on a surface. CoRR abs/0902.2422 (2009)\n13. Sterling, A.: Distributed agreement in tile self-assembly. In: DNA 15. (June 2009) To appear.\n14. Sterling, A.: Self-assembling systems are distributed systems. CoRR abs/0907.1072 (2009)\n15. Rothemund, P.W.K., Winfree, E.: The program-size complexity of self-assembled squares (extended abstract).\nIn: STOC. (2000) 459\u2013468\n16. Soloveichik, D., Cook, M., Winfree, E.: Combining self-healing and proofreading in self-assembly. Natural\nComputing 7(2) (2008) 203\u2013218\n17. Adve, S.V., Gharachorloo, K.: Shared memory consistency models: A tutorial. IEEE Computer 29(12) (1996)\n66\u201376\n18. Lamport, L.: How to make a multiprocessor computer that correctly executes multiprocess programs. IEEE\nTrans. Computers 28(9) (1979) 690\u2013691\n19. Lipton, R.J., Sandberg, J.S.: PRAM: A scalable shared memory. Technical Report CS-TR-180-88, Princeton\nUniversity (September 1988)\n20. Patitz, M.J.: Simulation of self-assembly in the abstract tile assembly model with ISU TAS. In: FNANO. (2009)\n21. Doty, D., Patitz, M.J.: A domain-specific language for programming in the tile assembly model. In: DNA. (2009)\n22. Boyapati, C., Rinard, M.C.: A parameterized type system for race-free java programs. In: OOPSLA. (2001)\n56\u201369\n23. O'Callahan, R., Choi, J.D.: Hybrid dynamic data race detection. SIGPLAN Not. 38(10) (2003) 167\u2013178\n24. Dijkstra, E.W.: Self-stabilizing systems in spite of distributed control. Commun. ACM 17(11) (1974) 643\u2013644\n25. Awerbuch, B., Sipser, M.: Dynamic networks are as fast as static networks (preliminary version). In: FOCS,\nIEEE (1988) 206\u2013220\n26. Awerbuch, B., Varghese, G.: Distributed program checking: a paradigm for building self-stabilizing distributed\nprotocols (extended abstract). In: FOCS, IEEE (1991) 258\u2013267\n27. Lenzen, C., Suomela, J., Wattenhofer, R.: Local Algorithms: Self-Stabilization on Speed. In: 11th International\nSymposium on Stabilization, Safety, and Security of Distributed Systems (SSS), Lyon, France. (November 2009)\n28. Winfree, E., Bekbolatov, R.: Proofreading tile sets: error-correction for algorithmic self-assembly. In: DNA\nComputing 9. (2004) 126\u2013144\n29. Winfree, E.: Self-healing tile sets. In Chen, J., Jonoska, N., Rozenberg, G., eds.: Nanotechnology: Science and\nComputation. Natural Computing Series, Springer (2006) 55\u201378\n30. Ghosh, S., Gupta, A., Herman, T., Pemmaraju, S.V.: Fault-containing self-stabilizing distributed protocols.\nDistributed Computing 20(1) (2007) 53\u201373\n31. Fujibiyashi, K., Zhang, D.Y., Winfree, E., Murata, S.: Error suppression mechanisms for DNA tile self-assembly\nand their simulation. Natural Computing (July 9, 2008)\n32. Dasgupta, A., Ghosh, S., Xiao, X.: Probabilistic fault-containment. In Masuzawa, T., Tixeuil, S., eds.: SSS.\nVolume 4838 of Lecture Notes in Computer Science., Springer (2007) 189\u2013203\n33. Haldar, S., Vidyasankar, K.: On specification of read/write shared variables. J. ACM 54(6) (2007) 31\n\n11\n\n\f"}