{"id": "http://arxiv.org/abs/1107.2353v1", "guidislink": true, "updated": "2011-07-12T17:17:52Z", "updated_parsed": [2011, 7, 12, 17, 17, 52, 1, 193, 0], "published": "2011-07-12T17:17:52Z", "published_parsed": [2011, 7, 12, 17, 17, 52, 1, 193, 0], "title": "Blending Bayesian and frequentist methods according to the precision of\n  prior information with an application to hypothesis testing", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1107.5758%2C1107.1455%2C1107.3248%2C1107.0429%2C1107.3895%2C1107.4856%2C1107.0333%2C1107.1522%2C1107.2154%2C1107.3497%2C1107.4847%2C1107.1918%2C1107.4048%2C1107.2676%2C1107.1184%2C1107.2970%2C1107.5942%2C1107.3972%2C1107.1082%2C1107.2656%2C1107.2353%2C1107.3916%2C1107.0048%2C1107.0155%2C1107.1433%2C1107.3897%2C1107.3908%2C1107.5937%2C1107.4303%2C1107.0123%2C1107.5645%2C1107.1497%2C1107.3375%2C1107.2687%2C1107.0092%2C1107.3728%2C1107.1701%2C1107.2418%2C1107.1732%2C1107.0249%2C1107.2142%2C1107.5232%2C1107.2228%2C1107.3482%2C1107.0223%2C1107.6027%2C1107.0639%2C1107.4066%2C1107.0020%2C1107.2825%2C1107.3637%2C1107.0038%2C1107.5342%2C1107.2350%2C1107.2201%2C1107.3088%2C1107.5271%2C1107.1502%2C1107.5300%2C1107.5251%2C1107.5563%2C1107.3287%2C1107.1990%2C1107.3387%2C1107.4005%2C1107.0232%2C1107.2620%2C1107.4181%2C1107.5485%2C1107.2175%2C1107.3682%2C1107.1826%2C1107.3636%2C1107.4833%2C1107.3343%2C1107.3379%2C1107.1062%2C1107.0705%2C1107.1072%2C1107.0397%2C1107.3501%2C1107.0145%2C1107.0899%2C1107.1468%2C1107.4389%2C1107.0203%2C1107.5979%2C1107.3901%2C1107.1413%2C1107.5558%2C1107.3744%2C1107.4893%2C1107.3125%2C1107.0823%2C1107.4648%2C1107.1228%2C1107.2550%2C1107.4513%2C1107.3683%2C1107.0207%2C1107.0381&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Blending Bayesian and frequentist methods according to the precision of\n  prior information with an application to hypothesis testing"}, "summary": "The following zero-sum game between nature and a statistician blends Bayesian\nmethods with frequentist methods such as p-values and confidence intervals.\nNature chooses a posterior distribution consistent with a set of possible\npriors. At the same time, the statistician selects a parameter distribution for\ninference with the goal of maximizing the minimum Kullback-Leibler information\ngained over a confidence distribution or other benchmark distribution. An\napplication to testing a simple null hypothesis leads the statistician to\nreport a posterior probability of the hypothesis that is informed by both\nBayesian and frequentist methodology, each weighted according how well the\nprior is known.\n  Since neither the Bayesian approach nor the frequentist approach is entirely\nsatisfactory in situations involving partial knowledge of the prior\ndistribution, the proposed procedure reduces to a Bayesian method given\ncomplete knowledge of the prior, to a frequentist method given complete\nignorance about the prior, and to a blend between the two methods given partial\nknowledge of the prior. The blended approach resembles the Bayesian method\nrather than the frequentist method to the precise extent that the prior is\nknown.\n  The problem of testing a point null hypothesis illustrates the proposed\nframework. The blended probability that the null hypothesis is true is equal to\nthe p-value or a lower bound of an unknown Bayesian posterior probability,\nwhichever is greater. Thus, given total ignorance represented by a lower bound\nof 0, the p-value is used instead of any Bayesian posterior probability. At the\nopposite extreme of a known prior, the p-value is ignored. In the intermediate\ncase, the possible Bayesian posterior probability that is closest to the\np-value is used for inference. Thus, both the Bayesian method and the\nfrequentist method influence the inferences made.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1107.5758%2C1107.1455%2C1107.3248%2C1107.0429%2C1107.3895%2C1107.4856%2C1107.0333%2C1107.1522%2C1107.2154%2C1107.3497%2C1107.4847%2C1107.1918%2C1107.4048%2C1107.2676%2C1107.1184%2C1107.2970%2C1107.5942%2C1107.3972%2C1107.1082%2C1107.2656%2C1107.2353%2C1107.3916%2C1107.0048%2C1107.0155%2C1107.1433%2C1107.3897%2C1107.3908%2C1107.5937%2C1107.4303%2C1107.0123%2C1107.5645%2C1107.1497%2C1107.3375%2C1107.2687%2C1107.0092%2C1107.3728%2C1107.1701%2C1107.2418%2C1107.1732%2C1107.0249%2C1107.2142%2C1107.5232%2C1107.2228%2C1107.3482%2C1107.0223%2C1107.6027%2C1107.0639%2C1107.4066%2C1107.0020%2C1107.2825%2C1107.3637%2C1107.0038%2C1107.5342%2C1107.2350%2C1107.2201%2C1107.3088%2C1107.5271%2C1107.1502%2C1107.5300%2C1107.5251%2C1107.5563%2C1107.3287%2C1107.1990%2C1107.3387%2C1107.4005%2C1107.0232%2C1107.2620%2C1107.4181%2C1107.5485%2C1107.2175%2C1107.3682%2C1107.1826%2C1107.3636%2C1107.4833%2C1107.3343%2C1107.3379%2C1107.1062%2C1107.0705%2C1107.1072%2C1107.0397%2C1107.3501%2C1107.0145%2C1107.0899%2C1107.1468%2C1107.4389%2C1107.0203%2C1107.5979%2C1107.3901%2C1107.1413%2C1107.5558%2C1107.3744%2C1107.4893%2C1107.3125%2C1107.0823%2C1107.4648%2C1107.1228%2C1107.2550%2C1107.4513%2C1107.3683%2C1107.0207%2C1107.0381&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The following zero-sum game between nature and a statistician blends Bayesian\nmethods with frequentist methods such as p-values and confidence intervals.\nNature chooses a posterior distribution consistent with a set of possible\npriors. At the same time, the statistician selects a parameter distribution for\ninference with the goal of maximizing the minimum Kullback-Leibler information\ngained over a confidence distribution or other benchmark distribution. An\napplication to testing a simple null hypothesis leads the statistician to\nreport a posterior probability of the hypothesis that is informed by both\nBayesian and frequentist methodology, each weighted according how well the\nprior is known.\n  Since neither the Bayesian approach nor the frequentist approach is entirely\nsatisfactory in situations involving partial knowledge of the prior\ndistribution, the proposed procedure reduces to a Bayesian method given\ncomplete knowledge of the prior, to a frequentist method given complete\nignorance about the prior, and to a blend between the two methods given partial\nknowledge of the prior. The blended approach resembles the Bayesian method\nrather than the frequentist method to the precise extent that the prior is\nknown.\n  The problem of testing a point null hypothesis illustrates the proposed\nframework. The blended probability that the null hypothesis is true is equal to\nthe p-value or a lower bound of an unknown Bayesian posterior probability,\nwhichever is greater. Thus, given total ignorance represented by a lower bound\nof 0, the p-value is used instead of any Bayesian posterior probability. At the\nopposite extreme of a known prior, the p-value is ignored. In the intermediate\ncase, the possible Bayesian posterior probability that is closest to the\np-value is used for inference. Thus, both the Bayesian method and the\nfrequentist method influence the inferences made."}, "authors": ["David R. Bickel"], "author_detail": {"name": "David R. Bickel"}, "author": "David R. Bickel", "links": [{"href": "http://arxiv.org/abs/1107.2353v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1107.2353v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1107.2353v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1107.2353v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:1107.2353v1 [stat.ME] 12 Jul 2011\n\nBlending Bayesian and frequentist methods\naccording to the precision of prior information with\nan application to hypothesis testing\n\nOctober 31, 2018\n\nDavid R. Bickel\nOttawa Institute of Systems Biology\nDepartment of Biochemistry, Microbiology, and Immunology\nUniversity of Ottawa; 451 Smyth Road; Ottawa, Ontario, K1H 8M5\n\nAbstract\nThe following zero-sum game between nature and a statistician blends Bayesian\nmethods with frequentist methods such as p-values and confidence intervals.\nNature chooses a posterior distribution consistent with a set of possible priors.\nAt the same time, the statistician selects a parameter distribution for inference\nwith the goal of maximizing the minimum Kullback-Leibler information gained\n\n1\n\n\fover a confidence distribution or other benchmark distribution. An application\nto testing a simple null hypothesis leads the statistician to report a posterior\nprobability of the hypothesis that is informed by both Bayesian and frequentist\nmethodology, each weighted according how well the prior is known.\nAs is generally acknowledged, the Bayesian approach is ideal given knowledge of a prior distribution that can be interpreted in terms of relative frequencies. On the other hand, frequentist methods such as confidence intervals\nand p-values have the advantage that they perform well without knowledge of\nsuch a distribution of the parameters. Since neither the Bayesian approach\nnor the frequentist approach is entirely satisfactory in situations involving partial knowledge of the prior distribution, the proposed procedure reduces to a\nBayesian method given complete knowledge of the prior, to a frequentist method\ngiven complete ignorance about the prior, and to a blend between the two methods given partial knowledge of the prior. The blended approach resembles the\nBayesian method rather than the frequentist method to the precise extent that\nthe prior is known.\nThe problem of testing a point null hypothesis illustrates the proposed framework. The blended probability that the null hypothesis is true is equal to the pvalue or a lower bound of an unknown Bayesian posterior probability, whichever\nis greater. Thus, given total ignorance represented by a lower bound of 0, the\np-value is used instead of any Bayesian posterior probability. At the opposite\nextreme of a known prior, the p-value is ignored. In the intermediate case,\nthe possible Bayesian posterior probability that is closest to the p-value is used\nfor inference. Thus, both the Bayesian method and the frequentist method\ninfluence the inferences made.\n\nKeywords: blended inference; confidence distribution; confidence posterior; hybrid\ninference; maximum entropy; maxmin expected utility; minimum cross entropy; minimum divergence; minimum information for discrimination; minimum relative entropy;\n\n2\n\n\fobserved confidence level; robust Bayesian analysis\n\n1\n\nIntroduction\n\n1.1\n\nMotivation\n\nVarious compromises between Bayesian and frequentist approaches to statistical inference represent first attempts to combining attractive aspects of each approach (Good,\n1983). While the more recent the hybrid inference approach of Yuan (2009) succeeded\nin leveraging Bayesian point estimators with maximum likelihood estimates, reducing\nto the former or the latter in the presence or absence of a reliably estimated prior on\nall parameters, how to extend the theory beyond point estimation is not yet clear.\nFurther, hybrid inference in its current form does not cover the case of a parameter\nof interest that has a partially known prior. Since such partial knowledge of a prior\noccurs in many scientific inference situations, it calls for a theoretical framework for\nmethod development that appropriately blends Bayesian and frequentist methods.\nIdeally, blended inference would meet these criteria:\n1. Complete knowledge of the prior. If the prior is known, the corresponding\nposterior is used for inference. Among statisticians, this principle is almost\nuniversally acknowledged. However, it is rarely the case of the prior is known\nfor all practical purposes.\n2. Negligible knowledge of the prior. If there is no reliable knowledge of a\nprior, inference is based on methods that do not require such knowledge. This\nprinciple motivates not only the development of confidence intervals and pvalues but also Bayesian posteriors derived from improper and data-dependent\npriors. Accordingly, blended inference must allow the use of such methods when\napplicable.\n3\n\n\f3. Continuum between extremes. Inference relies on the prior to the extent\nthat it is known while relying on the other methods to the extent that it is\nnot known. Thus, there is a gradation of methodology between the above two\nextremes. The premise of this paper is that this intermediate scenario calls\nfor a careful balance between pure Bayesian methods on one hand and impure\nBayesian or non-Bayesian methods on the other hand.\nInstead of framing the knowledge of a prior in terms of confidence intervals, as in\npure empirical Bayes approaches, it will be framed more generally herein in terms of\na set of plausible priors, as in interval probability (Weichselberger, 2000; Augustin,\n2002, 2004) and robust Bayesian (Berger, 1984) approaches. Whereas the concept\nof an unknown prior cannot arise in strict Bayesian statistics, it does arise in robust\nBayesian statistics when the levels of belief of an intelligent agent have not been fully\nassessed (Berger, 1984). Unknown priors also occur in many more objective contexts\ninvolving purely frequentist interpretations of probability in terms of variability in the\nobservable world rather than the uncertainty in the mind of an agent. For example,\nfrequency-based priors are routinely estimated under random effects and empirical\nBayes models; see, e.g., Efron (2010). (Remark 1 comments further on interpretations\nof probability and relaxes the convenient assumption of a true prior.)\nWith respect to the problem at hand, the most relevant robust Bayesian approaches are the minimax Bayes risk (\"\u0393-minimax\") practice of minimizing the maximum Bayes risk (Robbins, 1951; Berger, 1985; Vidakovic, 2000) and the maxmin\nexpected utility (\"conditional \u0393-minimax\") practice of maximizing the minimum posterior expected payoff or, equivalently, minimizing the maximum posterior expected\nloss (Gilboa and Schmeidler, 1989; DasGupta and Studden, 1989; Vidakovic, 2000;\nAugustin, 2002, 2004). Augustin (2004) reviews both methods in terms of interval probabilities that need not be subjective. With typical loss functions, the former method meets the above criteria for classical minimax alternatives to Bayesian\n4\n\n\fmethods but does not apply to other attractive alternatives. For example, several\nconfidence intervals, p-values, and objective-Bayes posteriors routinely used in biostatistics are not minimax optimal. (Fraser and Reid (1990) and Fraser (2004) argued\nthat requiring the optimality of frequentist procedures can lead to trade-offs between\nhypothetical samples that potentially mislead scientists or yield pathological procedures.) Optimality in the classical sense is not required of the alternative procedures\nunder the framework outlined below, which can be understood in terms of maxmin\nexpected utility with a payoff function that incorporates the alternative procedures\nto be used as a benchmark for the Bayesian posteriors.\n\n1.2\n\nHeuristic overview\n\nTo define a general theory of blended inference that meets a formal statement of the\nthree criteria, Section 2 introduces a variation of a zero-sum game of Tops\u00f8e (1979),\nHarremo\u00ebs and Tops\u00f8e (2001), and Tops\u00f8e (2007). (The discrete version of the game\nalso appeared in Pfaffelhuber (1977), and Gr\u00fcnwald and Philip Dawid (2004) interpreted it as a special case of the maxmin expected utility problem.) The \"nature\"\nopponent selects a prior consistent with the available knowledge as the \"statistician\"\nplayer selects a posterior distribution with the aim of maximizing the minimum information gained relative to one or more alternative methods. Such benchmark methods\nmay be confidence interval procedures, frequentist hypothesis tests, or other techniques that are not necessarily Bayesian.\nFrom that theory, Section 3 derives a widely applicable framework for testing\nhypotheses. For concreteness, the motivating results are heuristically summarized\nhere. Consider the problem of testing H0 : \u03b8\u2217 = 0, the hypothesis that a real-valued\nparameter \u03b8\u2217 of interest is equal to the point 0 on the real line R. The observed data\nvector x is modeled as a realization of a random variable denoted by X. Let p (x)\ndenote the p-value resulting from a statistical test.\n5\n\n\fIt has long been recognized that the p-value for a simple (point) null hypothesis is\noften smaller than Bayesian posterior probabilities of the hypothesis (Lindley, 1957;\nBerger and Sellke, 1987). Suppose \u03b8\u2217 has an unknown prior distribution according to\nwhich the prior probability of H0 is \u03c00 . While \u03c00 is unknown, it is assumed to be no\nless than some known lower bound denoted by \u03c0 0 .\nFollowing the methodology of Berger et al. (1994), Sellke et al. (2001) found a\ngenerally applicable lower bound on the Bayes factor. As Section 3.1 will explain,\nthat bound immediately leads to\n\u0012\n\u0012\nPr (H0 |p (X) = p (x)) = 1 \u2212\n\n1 \u2212 \u03c00\n\u03c0 0 ep (x) log p (x)\n\n\u0013\u0013\u22121\n(1)\n\nas a lower bound on the unknown posterior probability of the null hypothesis for\np (x) < 1/e and to \u03c0 0 as a lower bound on the probability if p (x) \u2265 1/e.\nIn addition to Pr (H0 |p (X) = p (x)) , the unknown Bayesian posterior probability\nof H0 , there is a frequentist posterior probability of H0 that will guide selection of a\nposterior probability for inference based on \u03c00 \u2265 \u03c0 0 and other constraints summarized\nby Pr (H0 |p (X) = p (x)) \u2265 Pr (H0 |p (X) = p (x)). While it is incorrect to interpret\nthe p-value p (x) as a Bayesian probability, it will be seen in Section 3.2 that p (x) is\na confidence posterior probability that H0 is true.\nWith the confidence posterior as the benchmark, the solution to the optimization\nproblem described above gives the blended posterior probability that the null hypothesis is true. It is simply the maximum of the p-value and the lower bound on the\nBayesian posterior probability:\n\nPr (H0 ; p (x)) = p (x) \u2228 Pr (H0 |p (X) = p (x)) .\n\n(2)\n\nBy plotting Pr (H0 ; p (x)) as a function of p (x) and \u03c0 0 , Figures 1 and 2 illustrate each\nof the above criteria for blended inference:\n6\n\n\f1. Complete knowledge of the prior. In this example, the prior is only known\nwhen \u03c0 0 = 1, in which case\n\nPr (H0 ; p (x)) = Pr (H0 |p (X) = p (x)) = 1\n\nfor all p (x). Thus, the p-value is ignored in the presence of a known prior.\n2. Negligible knowledge of the prior. There is no knowledge of the prior when\n\u03c0 0 = 0 and negligible knowledge when \u03c0 0 is so low that Pr (H0 |p (X) = p (x)) \u2264\np (x). In such cases, Pr (H0 ; p (x)) = p (x), and the Bayesian posteriors are\nignored.\n3. Continuum between extremes. When \u03c0 0 is of intermediate value in the\nsense that Pr (H0 |p (X) = p (x)) is exclusively between p (x) and 1,\n\nPr (H0 ; p (x)) = Pr (H0 |p (X) = p (x)) < 1.\n\nConsequently, Pr (H0 ; p (x)) increases gradually from p (x) to 1 as \u03c0 0 increases\n(Figures 1 and 2). In this case, the blended posterior lies in the set of allowed\nBayesian posteriors but is on the boundary of that set that is the closest to\nthe p-value. Thus, both the p-value and the Bayesian posteriors influence the\nblended posterior and thus the inferences made on its basis.\nThe plotted parameter distribution will be presented in Section 3.3 as a widely applicable blended posterior.\nFinally, Section 4 offers additional details and generalizations in a series of remarks.\n\n7\n\n\fFigure 1: Blended posterior probability that the null hypothesis is true versus the\np-value. The curves correspond to lower bounds of prior probabilities ranging in 5%\nincrements from 0% on the bottom to 100% on the top.\n\n8\n\n\fFigure 2: Blended posterior probability that the null hypothesis is true versus the\np-value and the lower bound of the prior probability that the null hypothesis is true.\nThe top plot displays the full domain, half of which is shown in the bottom plot.\n\n9\n\n\f2\n\nGeneral theory\n\n2.1\n\nPreliminary notation and definitions\n\nDenote the observed data set, typically a vector or matrix of observations, by x, a\nmember of a set X that is endowed with a \u03c3-algebra X. The value of x determines\ntwo sets of posterior distributions that can be blended for inference about the value\nof a target parameter. Much of the following notation is needed to transform general\nBayesian posteriors and confidence posteriors or other benchmark posteriors such\nthat they are defined on the same measurable space, that of the target parameter.\n(A confidence posterior, to be defined in Section 3.2.1, is a parameter distribution\nfrom which confidence intervals and p-values may be extracted. As such, it facilitates\nblending typical frequentist procedures with Bayesian procedures.)\n\n2.1.1\n\nBayesian posteriors\n\u0010\n\n\u0011\n\nWith some measurable space \u0398\u0307\u2217 , \u0226\u2217 for parameter values in \u0398\u0307\u2217 , let P\u2217prior denote\n\u0010\n\u0011\na set of probability distributions on X \u00d7 \u0398\u0307\u2217 , X \u2297 \u0226\u2217 . Any distribution in P\u2217prior is\ncalled a prior (distribution), understood in the broad sense of a model that includes\nthe possible likelihood functions as well as the parameter distribution. It encodes the\nconstraints and other information available about the parameter before observing x.\nOn the other hand, any distribution of a parameter is called a posterior (distribution) if it depends on x. For some P\u2217prior \u2208 P\u2217prior , an example of a posterior distribu\u0010\n\u0011\ntion on \u0398\u0307\u2217 , \u0226\u2217 is \u1e56\u2217 = P\u2217prior (\u2022|X = x), where X is a random variable of a distribution on (X , X) that is determined by P\u2217prior . \u1e56\u2217 is called a Bayesian posterior (distribution) since it is equal to a conditional distribution of the parameter given X = x.\n\b\nAdapting an apt term from Tops\u00f8e (2007), the set \u1e56\u2217 = P\u2217prior (\u2022|X = x) : P\u2217prior \u2208 P\u2217prior\n\u0010\n\u0011\nof Bayesian posteriors on \u0398\u0307\u2217 , \u0226\u2217 may be considered the \"knowledge base.\" For a\nset \u0398\u0307, if \u03c4\u0307 : \u0398\u0307\u2217 \u2192 \u0398 is an \u0226\u2217 -measurable map and if \u03b8\u0307\u2217 has distribution \u1e56\u2217 \u2208 \u1e56\u2217 ,\n\n10\n\n\f\u0010 \u0011\nthen \u03b8\u0307 = \u03c4\u0307 \u03b8\u0307\u2217 , referred to as an inferential target of \u1e56\u2217 , has induced probability\n\u0010\n\u0011\nspace \u0398, A, \u1e56 . The set\nn\n\u0010 \u0011\no\n\u1e56 = \u1e56 : \u03c4\u0307 \u03b8\u0307\u2217 \u223c \u1e56 , \u03b8\u0307\u2217 \u223c \u1e56\u2217 \u2208 \u1e56\u2217\n\nof all distributions thereby induced and the set P of all probability distributions on\n(\u0398, A) are related by \u1e56 \u2286 P.\nExample 1. In the hypothesis test of Section 1.2, \u03b8\u0307 = 0 if the null hypothesis that\n\u03b8\u0307\u2217 = 0 is true and \u03b8\u0307 = 1 if the alternative hypothesis that \u03b8\u0307\u2217 6= 0 is true, where\n\u03b8\u0307\u2217 and \u03b8\u0307 are random variables with distributions respectively defined on the Borel\n\u0001\nspace (R, B (R)) and the discrete space {0, 1} , 2{0,1} , where 2{0,1} is the power set\nof {0, 1}. Thus, in this case, \u03c4\u0307 is the indicator function 1(\u2212\u221e,0)\u222a(0,\u221e) : R \u2192 {0, 1},\n\u0010 \u0011\nyielding \u03b8\u0307 = 1(\u2212\u221e,0)\u222a(0,\u221e) \u03b8\u0307\u2217 . Section 3 considers this example in more detail.\nA function that transforms a set of parameter distributions to a single parameter\ndistribution on the same measurable space is called an inference process (Paris, 1994;\nParis and Vencovsk\u00e1, 1997). The resulting distribution is known as a \"representation\"\n(Augustin, 2002) or \"reduction\" (Bickel, 2011a) of the set. Perhaps the best known\ninference process for a discrete parameter set \u0398 is that of the maximum entropy\nprinciple, which would select a member of \u1e56 such that it has higher entropy than\nany other member of the set (see Remark 2). This paper will propose a wide class of\ninference processes such that each transforms \u1e56 to a member of P on the basis the\nfollowing concept of a benchmark distribution on (\u0398, A).\n\n2.1.2\n\nBenchmark posteriors\n\nFor the convenience of the reader, the same Latin and Greek letters will be used for the\nset of posteriors that will represent a gold standard or benchmark method of inference\nas for the Bayesian posteriors of Section 2.1.1, with the double-dot \u2022 \u0308 replacing the\n11\n\n\f \u0307 Let P\u0308\u2217 represent a set of posterior distributions on some measurable\nsingle-dot \u2022.\n\u0010\n\u0011\nspace \u0398\u0308\u2217 , \u00c4\u2217 , and let P\u0308\u2217 represent a set of such sets. For instance, considering any\nP\u0308\u2217 in P\u0308\u2217 , P\u0308\u2217 may be a confidence posterior (a fiducial-like distribution to be defined\nprecisely in Section 3.2), a generalized fiducial posterior of Hannig (2009), or even a\nBayesian posterior based on an improper prior. (In the first case, nested confidence\nintervals with inexact coverage rates generate a set P\u0308\u2217 of multiple confidence posteriors\nrather than the single confidence posterior that is generated by exact confidence\nintervals (Bickel, 2011a).) Suppose there exists a function \u03c4\u0308 : P\u0308\u2217 \u2192 \u0398 such that P\u0308 ,\n\u0010 \u0011\nthe probability distribution of \u03c4\u0308 P\u0308\u2217 , is defined on (\u0398, A). P\u0308 is called the benchmark\n\u0010 \u0011\nposterior (distribution), and \u03b8\u0308 = \u03c4\u0308 P\u0308\u2217 is the inferential target of P\u0308\u2217 . It follows that\nP\u0308 is in P but not necessarily in \u1e56.\nExample 2. Consider a model in which the full parameter \u03b8\u0307\u2217 \u2208 \u0398\u0307\u2217 consists of an\ninterest parameter \u03b8\u0307 and a nuisance parameter \u03bb\u0307. The measurable space of \u03b8\u0307\u2217 =\nD E\n\u0010\n\u0011\n\u03b8\u0307, \u03bb\u0307 is denoted by \u0398\u0307\u2217 , \u0226\u2217 , and that of \u03b8\u0307 by (\u0398, A). Suppose that a set of\nBayesian posteriors is available for \u03b8\u0307\u2217 but that nested confidence intervals are only\navailable for an unknown parameter \u03b8 \u2208 \u0398. It follows that a confidence posterior\n\u0010\n\u0011\nP\u0308 is available on (\u0398, A) but not on \u0398\u0307\u2217 , \u0226\u2217 . Then the framework of this section\n\u0010 \u0011\ncan be applied by using the function \u03c4\u0307 such that \u03b8 = \u03c4\u0307 \u03b8\u0307\u2217 in order to project the\nBayesian posteriors onto (\u0398, A), the measurable space on which P\u0308 is defined. In this\ncase, since there is only one possible benchmark posterior, the function \u03c4\u0308 need not\nbe explicitly constructed.\nThe function \u03c4\u0308 allows consideration of a set of possible benchmark posteriors by\ntransforming it to a single benchmark posterior defined on (\u0398, A), the same measurable space as the above Bayesian posteriors of \u03b8\u0307. Since that function is unusual, two\nways to compose it will now be explained.\nExample 3. Consider the inference process \u03a0\u0308 : P\u0308\u2217 \u2192 P\u2217 , where P\u2217 is the set of\n\u0010\n\u0011\nall probability distributions on \u0398\u0308\u2217 , \u00c4\u2217 . Define the random variable \u03b8\u0308\u2217 to have\n12\n\n\f\u0010 \u0011\n\u0010 \u0011\ndistribution \u03a0\u0308 P\u0308\u2217 (\u2022) = \u03a0\u0308 P\u0308\u2217 . If \u03c4\u0308 : \u0398\u0308\u2217 \u2192 \u0398 is an \u00c4\u2217 -measurable function, then\n\u0010 \u0011\n\u03b8\u0308 = \u03c4\u0308 \u03b8\u0308\u2217 is the inferential target of P\u0308\u2217 . Further, the distribution P\u0308 of \u03b8\u0308 is the\nbenchmark posterior.\n\nExample 4. Whereas Example 3 applied an inference process before a parameter\ntransformation, this example reverses the order by first applying \u03c4\u0308 . Let P\u0308 denote the\nsubset of P consisting of all distributions of the parameters transformed by \u03c4\u0308 :\nn\n\u0010 \u0011\no\nP\u0308 = P : \u03c4\u0308 \u03b8\u0308\u2217 \u223c P, \u03b8\u0308\u2217 \u223c P\u0308\u2217 \u2208 P\u0308\u2217 .\n\nThen an inference process transforms P\u0308 to the benchmark posterior P\u0308 , which in turn\nis the distribution of \u03b8\u0308, the inferential target of P\u0308\u2217 .\n\n2.2\n\nBlended inference\n\nIn terms of Radon-Nikodym differentiation, the information divergence of P with\nrespect to Q on (\u0398, A) is\n\u0012\n\nZ\nI (P ||Q) =\n\ndP log\n\ndP\ndQ\n\n\u0013\n(3)\n\nif P \u001c Q and I (P ||Q) = \u221e otherwise. I (P ||Q) is also known as cross/relative entropy, I-divergence, information for discrimination, and Kullback-Leibler divergence.\nOther measures of information may also be used (Remark 3). For any posteriors\n\u0011\n\u0010\n\u1e56 \u2208 \u1e56 and Q \u2208 P, the inferential gain I \u1e56 ||P\u0308\nQ of Q relative to P\u0308 given \u1e56 is\nthe amount of information gained by making inferences on the basis of Q instead of\n\n13\n\n\fthe benchmark posterior P\u0308 :\n\u0010\nI \u1e56 ||P\u0308\n\n\u0011\n\u0010\n\u0011\n\u0010\n\u0011\nQ = I \u1e56 ||P\u0308 \u2212 I \u1e56 ||Q .\n\n\u0010 \u0011\nLet \u1e56 P\u0308 denote the largest subset of \u1e56 such that the information divergence of\nany of its members with respect to P\u0308 is finite. That is,\n\u0010 \u0011 n\n\u0010\n\u0011\no\n\u1e56 P\u0308 = \u1e56 \u2208 \u1e56 : I \u1e56 ||P\u0308 < \u221e ,\n\n(4)\n\nwhich is nonempty by assumption. (The assumption is not necessary under the\ngeneralization described in Remark 4.)\nThe blended posterior (distribution) P\u0302 is the probability distribution on (\u0398, A)\nthat maximizes the inferential gain relative to the benchmark posterior given the\n\u0010 \u0011\nworst-case posterior restricted by the constraints that defined \u1e56 and \u1e56 P\u0308 :\n\u0010\ninf I \u1e56 ||P\u0308\n\u1e56 \u2208\u1e56 (P\u0308 )\n\nP\u0302\n\n\u0011\n\n\u0010\ninf I \u1e56 ||P\u0308\nQ\u2208P \u1e56 \u2208\u1e56 (P\u0308 )\n\n= sup\n\n\u0011\nQ ,\n\n(5)\n\nwhere the supremum and infinum over any set including an indeterminate number\nare \u221e and \u2212\u221e, respectively (Tops\u00f8e, 2007). Inferences based on P\u0302 are blended in\nthe sense that they depend on both \u1e56 and P\u0308 in the ways to be specified in Section\n2.3.\nThe main result of Theorem 2 of Tops\u00f8e (2007) gives a simply stated solution of\nthe optimality problem of equation (5) under broad conditions.\n\u0010\n\u0011\n\u0010 \u0011\nProposition 1. If I \u1e56 ||P\u0308 < \u221e for some \u1e56 \u2208 \u1e56 and if \u1e56 P\u0308 is convex, then the\nblended posterior P\u0302 is the probability distribution in \u1e56 that minimizes the information\ndivergence with respect to the benchmark posterior:\n\u0010\n\u0011\nI P\u0302 ||P\u0308 =\n\n\u0010\n\u0011\ninf I \u1e56 ||P\u0308 .\n\u1e56 \u2208\u1e56 (P\u0308 )\n14\n\n(6)\n\n\fProof. Tops\u00f8e (2007) proved the result from inequalities of information theory given\n\u0010\n\u0011\nthe additional stated condition of his Theorem 2 that I \u1e56 ||P\u0308 < \u221e for all \u1e56 \u2208\n\u0010 \u0011\n\u0010\n\u0011\n\u1e56 P\u0308 . (See Remark 4.) The condition that I \u1e56 ||P\u0308 < \u221e for some \u1e56 \u2208 \u1e56 and the\n\u0010 \u0011\nabove definition of \u1e56 P\u0308 ensure that the condition is met.\nAlternatively, the minimization of information divergence may define P\u0302 rather\nthan result from its definition in terms of the game (Remark 5).\n\n2.3\n\nProperties of blended inference\n\nThe desiderata of Section 1 for blended inference can now be formalized. A posterior\n\u0010\n\u0011\ndistribution P\u0303 \u2022; \u1e56, P\u0308 on (\u0398, A) is said to blend the set \u1e56 of Bayesian posteriors\nwith the benchmark posterior P\u0308 for inference about the parameter in \u0398 provided that\n\u0010\n\u0011\nP\u0303 \u2022; \u1e56, P\u0308 satisfies the following criteria under the conditions of Proposition 1:\n1. Complete knowledge of the prior. If \u1e56 has a single member \u1e56 , then\n\u0010\n\u0011\nP\u0303 \u2022; \u1e56, P\u0308 = \u1e56 .\n2. Negligible knowledge of the prior. If P\u0308 \u2208 \u1e56 and if \u1e56 has at least two\n\u0010\n\u0011\nmembers, then P\u0303 \u2022; \u1e56, P\u0308 = P\u0308 .\n3. Continuum between extremes. For any D \u2265 0 and any P ? \u2286 P such that\n\u0010\n\u0011\n\u0010\n\u0011\nI P ||P\u0308 \u2212 I \u1e56 ||P\u0308 \u2264 D\n\nsup\nP \u2208P ? ,\u1e56 \u2208\u1e56\n\n(7)\n\n(P\u0308 )\n\n\u0010 \u0011\nand such that \u1e56 P\u0308 \u222a P ? is convex,\n\u0010 \u0010\n\u0011 \u0011\n\u0010 \u0010\n\u0011 \u0011\nI P\u0303 \u2022; \u1e56 \u222a P ? , P\u0308 ||P\u0308 \u2212 I P\u0303 \u2022; \u1e56, P\u0308 ||P\u0308 \u2264 D.\n\n(8)\n\nTheorem 1. The blended posterior P\u0302 blends the set \u1e56 of Bayesian posteriors with\nthe benchmark posterior P\u0308 for inference about the parameter in \u0398.\n15\n\n\fProof. Since the criteria are only required under the conditions of Proposition 1, it will\nsuffice to prove that the criteria follow from equation (6). If \u1e56 has a single member\n\u1e56 , then equation (6) implies that P\u0302 = \u1e56 , thereby ensuring Criterion 1. Similarly,\nif P\u0308 \u2208 \u1e56, then equation (6) implies that P\u0302 = P\u0308 , thus proving that Criterion 2 is\nmet. Assume, contrary to Criterion 3, that there exist a D \u2265 0 and a P ? \u2286 P\n\u0010 \u0011\nsuch that \u1e56 P\u0308 \u222a P ? is convex, equation (7) is true, and equation (8) is false with\n\u0010\n\u0011\n\u0010\n\u0011\nP\u0303 \u2022; \u1e56 \u222a P ? , P\u0308 and P\u0303 \u2022; \u1e56, P\u0308 equal to the blended posteriors respectively using\n\u1e56 \u222a P ? and \u1e56 as the sets of Bayesian posteriors. Then equation (6) can be written as\n\u0010 \u0010\n\u0011 \u0011\nI P\u0303 \u2022; \u1e56 \u222a P ? , P\u0308 ||P\u0308 =\n\n\u0010 \u0010\n\u0011 \u0011\nI P\u0303 \u2022; \u1e56, P\u0308 ||P\u0308 =\n\n\u0010\n\u0011\ninf\nI \u1e56 ||P\u0308 ;\n\u1e56 \u2208\u1e56 (P\u0308 )\u222aP ?\ninf\n\n\u0010\n\n\u0011\n\nI \u1e56 ||P\u0308 .\n\n\u1e56 \u2208\u1e56 (P\u0308 )\n\nHence, with a \u2227 b signifying the minimum of a and b,\n\u0010 \u0010\n\u0011 \u0011\n\u0010 \u0010\n\u0011 \u0011\nI P\u0303 \u2022; \u1e56 \u222a P ? , P\u0308 ||P\u0308 \u2212 I P\u0303 \u2022; \u1e56, P\u0308 ||P\u0308 =\n\u0010\n\u0011\n\u0010\n\u0011\n\u0010\n\u0011\ninf I \u1e56 ||P\u0308 \u2212 inf I \u1e56 ||P\u0308 \u2227 inf ? I P ||P\u0308 ,\nP \u2208P\n\u1e56 \u2208\u1e56 (P\u0308 )\n\u1e56 \u2208\u1e56 (P\u0308 )\n\u0010\n\u0011\n\u0010\n\u0011\nwhich cannot exceed inf \u1e56 \u2208\u1e56 (P\u0308 ) I \u1e56 ||P\u0308 \u2212 inf P \u2208P ? I P ||P\u0308 and thus, according to\nequation (7), cannot exceed D. Therefore, the above assumption that equation (8) is\nfalse is contradicted, thereby establishing satisfaction of Criterion 3.\nExample 5. Suppose the set of possible priors consists of a single frequency-matching\nprior, i.e., a prior that leads to 95% posterior credible intervals that are equal to 95%\nconfidence intervals, etc. If the benchmark posterior is the confidence posterior that\nyields the same confidence intervals, then it is the Bayesian posterior distribution\ncorresponding to the prior. In that case, the blended distribution is equal to that\nBayesian/confidence posterior. Thus, the first condition of blended inference applies.\n\n16\n\n\fThe second condition would instead apply if the set of possible priors contained at\nleast one other prior in addition to the frequency-matching prior.\nCriterion 3 is much stronger than the heuristic idea of continuity introduced in Section 1.1. Its use of information divergence can be generalized to other measures of\ndivergence (Remark 3).\n\n3\n\nBlended hypothesis testing\n\nA fertile field of application for the theory of Section 2 is that of testing hypotheses,\nas outlined in Section 1.2. Building on Example 1, this section provides methodology\nfor a wide class of models used in hypothesis testing.\n\n3.1\n\nA bound on the Bayesian posterior\n\nDefining that class in terms of the concepts of Section 2.1.1 requires additional notation. For a continuous sample space X and a function p : X \u2192 [0, 1] such that\np (X) \u223c U (0, 1) under a null hypothesis, each p (x) for any x \u2208 X will be called a pvalue. Using some dominating measure, let f0 and f1 denote probability density func\u0010\n\u0011\ntions of p (X) under the null hypothesis \u03b8\u0307 = 0 and under the alternative hypothesis\n\u0010\n\u0011\n\u03b8\u0307 = 1 , respectively. For the observed x, the likelihood ratio f0 (p (x)) /f1 (p (x)) is\ncalled the Bayes factor since, for a prior distribution P\u2217prior , Bayes's theorem gives\n\u0010\n\u0011\n\u03b8\u0307 = 0 f (p (x))\n\u03c6 (p (x))\n\u0010\n\u0011 0\n=\n,\n1 \u2212 \u03c6 (p (x))\nP\u2217prior \u03b8\u0307 = 1 f1 (p (x))\nP\u2217prior\n\nwhere \u03c6 (p (x)) =\n\nP\u2217prior\n\n\u0010\n\n(9)\n\n\u0011\n\u03b8\u0307 = 0|p (X) = p (x) . Here, as \u03c6 (p (x)) is a local false dis-\n\ncovery rate (LFDR), the letter \u03c6 abbreviates \"false\" (Efron, 2010; Bickel, 2011c).\nIn a parametric setting, f1 (p (x)) would be the likelihood integrated over the prior\ndistribution conditional on the alternative hypothesis.\n17\n\n\fLet \u03ba : X \u2192 R denote the function defined by the transformation \u03ba (x) =\n\u2212 log p (x) for all x \u2208 X . Then a probability density of \u03ba (X) under the null hypothesis is the standard exponential density g0 (\u03ba (x)) = e\u2212\u03ba(x) . Assume that, un\u0010\n\u0011\nder the alternative hypothesis \u03b8\u0307 = 1 , \u03ba (X) admits a density function g1 with respect to the same dominating measure as g0 . It follows that g0 (\u03ba (x)) /g1 (\u03ba (x)) =\nf0 (p (x)) /f1 (p (x)). The hazard rate h1 (\u03ba (x)) under the alternative is defined by\nR\u221e\nh1 (\u03ba (x)) = g1 (\u03ba (x)) / \u03ba(x) g1 (k) dk for all x \u2208 X , and h1 : (0, \u221e) \u2192 [0, \u221e) is called\nthe hazard rate function.\nSellke et al. (2001) obtained the following lower bound b (p (x)) of the Bayes factor\nb (x).\nLemma 1. If h1 is nonincreasing, then, for all x \u2208 X ,\n\nb (p (x)) =\n\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2\u2212ep (x) log p (x) if p (x) < 1/e;\n\nf0 (p (x))\n\u2265 b (p (x)) =\n\uf8f4\nf1 (p (x))\n\uf8f4\n\uf8f31\n\n(10)\n\nif p (x) \u2265 1/e.\n\nThe condition on the hazard rate defines a wide class of models that is useful for\ntesting simple null hypotheses. A broad subclass will now be defined by imposing\n\u0010\n\u0011\nconstraints on \u03c00 = P\u2217prior \u03b8\u0307 = 0 , the prior probability that the null hypothesis\nis true, in addition to the hazard rate condition. Specifically, \u03c00 is known to have\n\u03c0 0 \u2208 [0, 1] as a lower bound. Thus, rearranging equation (9) as\n\u0012\n\u0012\n\u03c6 (p (x)) = 1 +\n\n1 \u2212 \u03c00\n\u03c00 b0 (p (x))\n\n\u0013\u0013\u22121\n,\n\na lower bound on \u03c6 (p (x)) is\n\u0012\n\u0012\n\u0013\u0013\u22121\n1 \u2212 \u03c00\nPr (H0 |p (X) = p (x)) = \u03c6 (p (x)) = 1 +\n,\n\u03c0 0 b (p (x))\nleading to equation (1).\n18\n\n\f\u0001\nLet P consist of all probability distributions on (\u0398, A) = {0, 1} , 2{0,1} . The\n\u0010\n\u0011\nsubset \u1e56 consists of all \u1e56 \u2208 P such that \u1e56 \u03b8\u0307 = 0 \u2265 \u03c6 (p (x)).\n\n3.2\n3.2.1\n\nA confidence benchmark posterior\nConfidence posterior theory\n\nThe following parametric framework facilitates the application of Section 2.1.2 to\nhypothesis testing. The observation x is an outcome of the random variable \u1e8c of\nprobability space (X , X, P\u03b8\u2217 ,\u03bb\u2217 ), where the interest parameter \u03b8\u2217 \u2208 \u0398\u0308\u2217 and a nuisance\nparameter \u03bb\u2217 (in some set \u039b\u0308\u2217 ) are unknown. Let S : \u0398\u0308\u2217 \u00d7X \u2192 [0, 1] and t : X \u00d7 \u0398\u0308\u2217 \u2192\nR denote functions such that S (\u2022; x) is a distribution function, S (\u03b8\u2217 ; X) \u223c U (0, 1),\nand\n\u0011\n\u0011\n\u0010 \u0010\nS (\u03b8\u2217 ; x) = P\u03b8\u2217 ,\u03bb\u2217 t \u1e8c; \u03b8\u2217 \u2265 t (x; \u03b8\u2217 )\nfor all x \u2208 X , \u03b8\u2217 \u2208 \u0398\u0308\u2217 , and \u03bb\u2217 \u2208 \u039b\u0308\u2217 . S is known as a significance function, and t as\na pivot or test statistic. It follows that p (x) = S (0; x) is a p-value for testing the\nhypothesis that \u03b8\u2217 = 0 and that [S \u22121 (\u03b1; X) , S \u22121 (\u03b2; X)] is a (\u03b2 \u2212 \u03b1) 100% confidence\ninterval for \u03b8\u2217 given any \u03b1 \u2208 [0, 1] and \u03b2 \u2208 [\u03b1, 1]. Thus, whether a significance\nfunction is found from p-values over a set of simple null hypotheses or instead from a\nset of nested confidence intervals, it contains the information needed to derive either\n(Schweder and Hjort, 2002; Singh et al., 2007; Bickel, 2011a,b).\nLet \u03b8\u0308\u2217 denote the random variable of the probability measure P\u0308\u2217 that has S (\u2022; x) as\n\u0010\n\u0011\nits distribution function. In other words, P\u0308\u2217 \u03b8\u0308\u2217 \u2264 \u03b8\u2217 = S (\u03b8\u2217 ; x) for all \u03b8\u2217 \u2208 \u0398\u0308\u2217 . P\u0308\u2217\nis called a confidence posterior (distribution) since it equates the frequentist coverage\nrate of a confidence interval with the probability that the parameter lies in the fixed,\n\n19\n\n\fobserved confidence interval:\n\n\u0002\n\u0003\u0001\n\u03b2 \u2212 \u03b1 = P\u03b8\u2217 ,\u03bb\u2217 \u03b8\u2217 \u2208 S \u22121 (\u03b1; X) , S \u22121 (\u03b2; X)\n\u0010\n\u0002\n\u0003\u0011\n= P\u0308\u2217 \u03b8\u0308\u2217 \u2208 S \u22121 (\u03b1; x) , S \u22121 (\u03b2; x)\n\nfor all x \u2208 X , \u03b8\u2217 \u2208 \u0398\u0308\u2217 , and \u03bb\u2217 \u2208 \u039b\u0308\u2217 . The term \"confidence posterior\" (Bickel,\n2011a,b) is preferred here over the usual term \"confidence distribution\" (Schweder and\nHjort, 2002) to emphasize its use as an alternative to Bayesian posterior distributions.\nPolansky (2007), Singh et al. (2007), and Bickel (2011a) provide generalizations to\nvector parameters of interest. Extensions based on multiple comparison procedures\nare sketched in Remark 6.\n\n3.2.2\n\nA confidence posterior for testing\n\nFor the application to two-sided testing of a simple null hypothesis, let \u03b8\u2217 = |\u03b8\u2217\u2217 |,\nthe absolute value of a real parameter \u03b8\u2217\u2217 of interest, leading to \u0398\u0308\u2217 = [0, \u221e). Then\np (x) = S (0; x) is equivalent to a two-tailed p-value for testing the hypothesis that\n\u0010\n\u0011\n\u0010\n\u0011\n\u0010\n\u0011\n\u03b8\u2217\u2217 = 0. Since P\u0308\u2217 \u03b8\u0308\u2217 \u2264 0 = S (0; x) and since P\u0308\u2217 \u03b8\u0308\u2217 \u2264 0 = P\u0308\u2217 \u03b8\u0308\u2217 = 0 , it follows\n\u0010\n\u0011\nthat p (x) = P\u0308\u2217 \u03b8\u0308\u2217 = 0 , i.e., the p-value is equal to the probability that the mull\nhypothesis is true.\nn o\nIf P\u0308\u2217 is the only confidence posterior under consideration, then P\u0308\u2217 = P\u0308\u2217 , and\nthere is no need for an inference process. Following the terminology of Example 3,\n\u0010 \u0011\n\u0010 \u0011\n\u03c4\u0308 : \u0398\u0308\u2217 \u2192 \u0398 is defined by \u03c4\u0308 \u03b8\u0308\u2217 = 1(0,\u221e) \u03b8\u0308\u2217 . By implication, \u03b8\u0308 = 0 if \u03b8\u0308\u2217 = 0 and\n\u0010\n\u0011\n\u0010\n\u0011\n\u03b8\u0308 = 1 if \u03b8\u0308\u2217 > 0. Thus, p (x) = P\u0308\u2217 \u03b8\u0308\u2217 = 0 ensures that P\u0308 \u03b8\u0308 = 0 = p (x), which in\n\u0010\n\u0011\nturn implies P\u0308 \u03b8\u0308 = 1 = 1 \u2212 p (x).\nExample 6. In the various t-tests, \u03b8\u2217 is the mean of X or a difference in means, and\nthe statistic t (X; 0) is the absolute value of a statistic with a Student t distribution\nof known degrees of freedom. The above formalism then gives the usual two-sided\n20\n\n\f\u0010\n\u0011\np-value from a t-test as P\u0308 \u03b8\u0308 = 0 and p (x). Specials cases of this P\u0308 have been\npresented as fiducial distributions (van Berkum et al. (1996);Bickel, 2011d).\n\n3.3\n\nA blended posterior for testing\n\nThis subsection blends the above set \u1e56 of Bayesian posteriors with the above confidence posterior P\u0308 as prescribed by Section 2.2. Gathering the results of Sections 3.1\nand 3.2,\no\nn\n\u0010\n\u0011\n\u1e56 = \u1e56 \u2208 P : \u1e56 \u03b8\u0307 = 0 \u2265 \u03c6 (p (x)) ;\n\u0010\n\u0011\n\u0010\n\u0011\nP\u0308 \u03b8\u0308 = 0 = p (x) = 1 \u2212 P\u0308 \u03b8\u0308 = 1 .\nEquation (4) then implies that\n\u0010 \u0011 n\n\u0010\n\u0011\no\n\u1e56 P\u0308 = \u1e56 \u2208 P : \u03c6 (p (x)) \u2264 \u1e56 \u03b8\u0307 = 0 < 1 ,\n\nin which the first inequality is strict if and only if \u03c6 (p (x)) = 0 and the second\n\u0010 \u0011\ninequality is strict unless p (x) = 1. Since \u1e56 P\u0308 is convex, Proposition 1 yields\n\nP\u0302 (\u03b8 = 0) =\n\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2\u03c6 (p (x)) if p (x) < \u03c6 (p (x))\n\uf8f4\n\uf8f4\n\uf8f3p (x)\n\n,\n\n(11)\n\nif p (x) \u2265 \u03c6 (p (x))\n\nwhere \u03b8 is the random variable of distribution P\u0302 . With the identities \u03c6 (p (x)) =\nPr (H0 |p (X) = p (x)) and P\u0302 (\u03b8 = 0) = Pr (H0 ; p (x)) and with the establishment of\nequation (1) by Section 3.1, equation (11) verifies the claim of equation (2) made in\nSection 1.2.\n\n21\n\n\f4\n\nRemarks\n\nRemark 1. As mentioned in Section 1.1, the use of Bayes's theorem with proper\npriors need not involve subjective interpretations of probability. The set of posteriors\nmay be determined by interval constraints on the corresponding priors without any\nrequirement that they model levels of belief (Weichselberger, 2000; Augustin, 2002,\n2004). However, subjective applications of blended inference are also possible. While\nthe framework was developed with an unknown prior in mind, the concept of imprecise\nor indeterminate probability (Walley, 1991) could take the place of the set in which\nan unknown prior lies. By allowing the partial order of agent preferences, imprecise\nprobability theories need not assume the existence of any true prior (Walley, 1991;\nColetti and Scozzafava, 2002). As often happens, the same mathematical framework\nis subject to very different philosophical interpretations.\n\nRemark 2. Technically, the principle of maximum entropy (Paris, 1994; Paris and\nVencovsk\u00e1, 1997) mentioned in Section 2.1.1 could be used if \u0398 is finite or countable\ninfinite. However, unlike the proposed methodology, that practice is equivalent to\nmaking the benchmark posterior P\u0308 depend on the function \u03c4\u0307 that maps a parameter\nspace to \u0398 rather than on a method of data analysis that is coherent in the sense\nthat its posterior depends on the data rather than on the hypothesis. If blending\nwith such a method is not desired, one may average the Bayesian posteriors with\nrespect to some measure that is not a function of \u0398. For example, averaging with\nrespect to the Lebesgue measure, as Bickel (2011a) did with confidence posteriors,\n\u0001\nleads to 1 + \u03c6 (p (x)) /2 as the posterior probability of the null hypothesis under\nthe assumptions of Section 3.1. Remark 5 discusses a more tenable version of the\nmaximum entropy principle for blended inference.\n\n22\n\n\fRemark 3. Using definitions of divergence that include information divergence (3)\nas a special case, Gr\u00fcnwald and Philip Dawid (2004) and Tops\u00f8e (2004) generalized\nvariations of Proposition 1. The theory of blended inference extends accordingly.\n\nRemark 4. A generalization of Section 2 in a different direction from that of Remark\n3 replaces each \"inf \u1e56 \u2208\u1e56 (P\u0308 ) \" of equation (5) with \"inf \u1e56 \u2208\u1e56 .\" For that optimization\n\u0010\n\u0011\nproblem, Theorem 2 of Tops\u00f8e (2007) has the condition that \u1e56 \u2208 \u1e56 =\u21d2 I \u1e56 ||P\u0308 <\n\u221e in addition to the convexity of \u1e56 that Proposition 1 of the present paper requires.\nThus, in that formulation, the blended posterior P\u0302 need not satisfy equation (6) even\nif \u1e56 is convex.\n\nRemark 5. A posterior distribution P\u0302 that is defined by\n\u0010\n\u0011\n\u0010\n\u0011\nI P\u0302 ||P\u0308 = inf I \u1e56 ||P\u0308\n\n(12)\n\n\u1e56 \u2208\u1e56\n\nsatisfies the desiderata of Section 2.3 whether or not the conditions of Proposition\n1 hold. While certain axiomatic systems (e.g., Csisz\u00e1r, 1991) lead to this generalization of the principle of maximum entropy (Remark 2), the optimization problem\nof equation (5) seems more compelling in this context and defines P\u0302 even when no\ndistribution satisfying equation (12) exists.\n\nRemark 6. In the presence of multiple comparisons, the confidence posteriors of Section 3.2.1 may be adjusted to control a family-wise error rate or false coverage rate\n(Benjamini and Yekutieli, 2005), if desired. Either error rate would then take the\nplace of the conventional confidence level as the confidence posterior probability.\n\n23\n\n\fAcknowledgments\nThis research was partially supported by the Canada Foundation for Innovation, by\nthe Ministry of Research and Innovation of Ontario, and by the Faculty of Medicine\nof the University of Ottawa.\n\nReferences\nAugustin, T., 2002. Expected utility within a generalized concept of probability - a\ncomprehensive framework for decision making under ambiguity. Statistical Papers\n43 (1), 5\u201322.\nAugustin, T., 2004. Optimal decisions under complex uncertainty - basic notions\nand a general algorithm for data-based decision making with partial prior\nknowledge described by interval probability. Zeitschrift fur Angewandte\nMathematik und Mechanik 84 (10-11), 678\u2013687.\nBenjamini, Y., Yekutieli, D., 2005. False discovery rate-adjusted multiple confidence\nintervals for selected parameters. Journal of the American Statistical Association\n100 (469), 71\u201381.\nBerger, J., Brown, L., Wolpert, R., 1994. A unified conditional frequentist and\nBayesian test for fixed and sequential simple hypothesis-testing. Annals of\nStatistics 22 (4), 1787\u20131807.\nBerger, J. O., 1984. Robustness of Bayesian analyses. Studies in Bayesian\neconometrics. North-Holland.\nBerger, J. O., 1985. Statistical Decision Theory and Bayesian Analysis. Springer,\nNew York.\n\n24\n\n\fBerger, J. O., Sellke, T., 1987. Testing a point null hypothesis: The irreconcilability\nof p values and evidence. Journal of the American Statistical Association\n82 (397), 112\u2013122.\nBickel, D. R., 2011a. Coherent frequentism: A decision theory based on confidence\nsets. To appear in Communications in Statistics - Theory and Methods (accepted\n22 November 2010); 2009 preprint available from arXiv:0907.0139.\nBickel, D. R., 2011b. Estimating the null distribution to adjust observed confidence\nlevels for genome-scale screening. Biometrics 67, 363\u2013370.\nBickel, D. R., 2011c. Simple estimators of false discovery rates given as few as one or\ntwo p-values without strong parametric assumptions. Technical Report, Ottawa\nInstitute of Systems Biology, arXiv:1106.4490.\nBickel, D. R., 2011d. Small-scale inference: Empirical Bayes and confidence methods\nfor as few as a single comparison. Technical Report, Ottawa Institute of Systems\nBiology, arXiv:1104.0341.\nColetti, C., Scozzafava, R., 2002. Probabilistic Logic in a Coherent Setting. Kluwer,\nAmsterdam.\nCsisz\u00e1r, I., 1991. Why least squares and maximum entropy? an axiomatic approach\nto inference for linear inverse problems. Ann. Stat. 19 (4), 2032\u20132066.\nDasGupta, A., Studden, W., 1989. Frequentist behavior of robust Bayes estimates of\nnormal means. Statist. Dec. 7, 333\u2013361.\nEfron, B., 2010. Large-Scale Inference: Empirical Bayes Methods for Estimation,\nTesting, and Prediction. Cambridge University Press.\nFraser, D. A. S., 2004. Ancillaries and conditional inference. Statistical Science\n19 (2), 333\u2013351.\n25\n\n\fFraser, D. A. S., Reid, N., 1990. Discussion: An ancillarity paradox which appears\nin multiple linear regression. The Annals of Statistics 18 (2), 503\u2013507.\nGilboa, I., Schmeidler, D., 1989. Maxmin expected utility with non-unique prior.\nJournal of Mathematical Economics 18 (2), 141\u2013153.\nGood, I., 1983. Good Thinking: the Foundations of Probability and Its\nApplications. G - Reference, Information and Interdisciplinary Subjects Series.\nUniversity of Minnesota Press.\nGr\u00fcnwald, P., Philip Dawid, A., 2004. Game theory, maximum entropy, minimum\ndiscrepancy and robust Bayesian decision theory. Annals of Statistics 32 (4),\n1367\u20131433.\nHannig, J., 2009. On generalized fiducial inference. Statistica Sinica 19, 491\u2013544.\nHarremo\u00ebs, P., Tops\u00f8e, F., 2001. Maximum entropy fundamentals. Entropy 3 (3),\n191\u2013226.\nLindley, D. V., 1957. A statistical paradox. Biometrika 44 (1/2), pp. 187\u2013192.\nParis, J., Vencovsk\u00e1, A., 1997. In defense of the maximum entropy inference process.\nInternational Journal of Approximate Reasoning 17 (1), 77 \u2013 103.\nParis, J. B., 1994. The Uncertain Reasoner's Companion: A Mathematical\nPerspective. Cambridge University Press, New York.\nPfaffelhuber, E., 1977. Minimax Information Gain and Minimum Discrimination\nPrinciple. In: Csisz\u00e1r, I., Elias, P. (Eds.), Topics in Information Theory. Vol. 16 of\nColloquia Mathematica Societatis J\u00e1nos Bolyai. J\u00e1nos Bolyai Mathematical\nSociety and North-Holland, pp. 493\u2013519.\nPolansky, A. M., 2007. Observed Confidence Levels: Theory and Application.\nChapman and Hall, New York.\n26\n\n\fRobbins, H., 1951. Asymptotically subminimax solutions of compound statistical\ndecision problems. Proc. Second Berkeley Symp. Math. Statist. Probab. 1,\n131\u2013148.\nSchweder, T., Hjort, N. L., 2002. Confidence and likelihood. Scandinavian Journal\nof Statistics 29 (2), 309\u2013332.\nSellke, T., Bayarri, M. J., Berger, J. O., 2001. Calibration of p values for testing\nprecise null hypotheses. American Statistician 55 (1), 62\u201371.\nSingh, K., Xie, M., Strawderman, W. E., 2007. Confidence distribution (CD) \u2013\ndistribution estimator of a parameter. IMS Lecture Notes Monograph Series 2007\n54, 132\u2013150.\nTops\u00f8e, F., 1979. INFORMATION THEORETICAL OPTIMIZATION\nTECHNIQUES. KYBERNETIKA 15 (1), 8\u201327.\nTops\u00f8e, F., 2004. Entropy and equilibrium via games of complexity. PHYSICA\nA-STATISTICAL MECHANICS AND ITS APPLICATIONS 340 (1-3), 11\u201331.\nTops\u00f8e, F., 2007. Information theory at the service of science. In: T\u00f3th, G. F.,\nKatona, G. O. H., Lov\u00e1sz, L., P\u00e1lfy, P. P., Recski, A., Stipsicz, A., Sz\u00e1sz, D.,\nMikl\u00f3s, D., Csisz\u00e1r, I., Katona, G. O. H., Tardos, G., Wiener, G. (Eds.), Entropy,\nSearch, Complexity. Vol. 16 of Bolyai Society Mathematical Studies. Springer\nBerlin Heidelberg, pp. 179\u2013207.\nvan Berkum, E., Linssen, H., Overdijk, D., 1996. Inference rules and inferential\ndistributions. Journal of Statistical Planning and Inference 49 (3), 305\u2013317.\nVidakovic, B., 2000. Gamma-minimax: A paradigm for conservative robust\nBayesians. Robust Bayesian Analysis. Springer, New York, pp. 241\u2013260.\n\n27\n\n\fWalley, P., 1991. Statistical Reasoning with Imprecise Probabilities. Chapman and\nHall, London.\nWeichselberger, K., 2000. The theory of interval-probability as a unifying concept for\nuncertainty. International Journal of Approximate Reasoning 24 (2-3), 149\u2013170.\nYuan, B., 2009. Bayesian frequentist hybrid inference. Annals of Statistics 37,\n2458\u20132501.\n\n28\n\n\f"}