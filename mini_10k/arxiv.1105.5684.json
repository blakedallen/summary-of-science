{"id": "http://arxiv.org/abs/1105.5684v1", "guidislink": true, "updated": "2011-05-28T06:23:13Z", "updated_parsed": [2011, 5, 28, 6, 23, 13, 5, 148, 0], "published": "2011-05-28T06:23:13Z", "published_parsed": [2011, 5, 28, 6, 23, 13, 5, 148, 0], "title": "Towards High-Performance Network Application Identification With\n  Aggregate-Flow Cache", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1105.4129%2C1105.4309%2C1105.3980%2C1105.4756%2C1105.6124%2C1105.1139%2C1105.5065%2C1105.1552%2C1105.5419%2C1105.0003%2C1105.3991%2C1105.5157%2C1105.3394%2C1105.2111%2C1105.2920%2C1105.4688%2C1105.1811%2C1105.1941%2C1105.4634%2C1105.5450%2C1105.1356%2C1105.1477%2C1105.0455%2C1105.1774%2C1105.0774%2C1105.3751%2C1105.0026%2C1105.5546%2C1105.2353%2C1105.0707%2C1105.5598%2C1105.2887%2C1105.2540%2C1105.0265%2C1105.4288%2C1105.1367%2C1105.5814%2C1105.1790%2C1105.6227%2C1105.2204%2C1105.1677%2C1105.5128%2C1105.5684%2C1105.3787%2C1105.5833%2C1105.2480%2C1105.0549%2C1105.0896%2C1105.4179%2C1105.1247%2C1105.6034%2C1105.0479%2C1105.2460%2C1105.0978%2C1105.4076%2C1105.5540%2C1105.3997%2C1105.2950%2C1105.1221%2C1105.4148%2C1105.3521%2C1105.5493%2C1105.0791%2C1105.0701%2C1105.4952%2C1105.4566%2C1105.3202%2C1105.3973%2C1105.3211%2C1105.3204%2C1105.0806%2C1105.0244%2C1105.1727%2C1105.6047%2C1105.0290%2C1105.0048%2C1105.0619%2C1105.3282%2C1105.2271%2C1105.3944%2C1105.4407%2C1105.2072%2C1105.1807%2C1105.2226%2C1105.3195%2C1105.1755%2C1105.5696%2C1105.0136%2C1105.2316%2C1105.1383%2C1105.3882%2C1105.1415%2C1105.0372%2C1105.3825%2C1105.3723%2C1105.0739%2C1105.4515%2C1105.6138%2C1105.6235%2C1105.1017%2C1105.1250&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Towards High-Performance Network Application Identification With\n  Aggregate-Flow Cache"}, "summary": "Classifying network traffic according to their application-layer protocols is\nan important task in modern networks for traffic management and network\nsecurity. Existing payload-based or statistical methods of application\nidentification cannot meet the demand of both high performance and accurate\nidentification at the same time. We propose an application identification\nframework that classifies traffic at aggregate-flow level leveraging\naggregate-flow cache. A detailed traffic classifier designed based on this\nframework is illustrated to improve the throughput of payload-based\nidentification methods. We further optimize the classifier by proposing an\nefficient design of aggregate-flow cache. The cache design employs a\nfrequency-based, recency-aware replacement algorithm based on the analysis of\ntemporal locality of aggregate-flow cache. Experiments on real-world traces\nshow that our traffic classifier with aggregate-flow cache can reduce up to 95%\nworkload of backend identification engine. The proposed cache replacement\nalgorithm outperforms well-known replacement algorithms, and achieves 90% of\nthe optimal performance using only 15% of memory. The throughput of a\npayload-based identification system, L7-filter [1], is increased by up to 5.1\ntimes by using our traffic classifier design.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1105.4129%2C1105.4309%2C1105.3980%2C1105.4756%2C1105.6124%2C1105.1139%2C1105.5065%2C1105.1552%2C1105.5419%2C1105.0003%2C1105.3991%2C1105.5157%2C1105.3394%2C1105.2111%2C1105.2920%2C1105.4688%2C1105.1811%2C1105.1941%2C1105.4634%2C1105.5450%2C1105.1356%2C1105.1477%2C1105.0455%2C1105.1774%2C1105.0774%2C1105.3751%2C1105.0026%2C1105.5546%2C1105.2353%2C1105.0707%2C1105.5598%2C1105.2887%2C1105.2540%2C1105.0265%2C1105.4288%2C1105.1367%2C1105.5814%2C1105.1790%2C1105.6227%2C1105.2204%2C1105.1677%2C1105.5128%2C1105.5684%2C1105.3787%2C1105.5833%2C1105.2480%2C1105.0549%2C1105.0896%2C1105.4179%2C1105.1247%2C1105.6034%2C1105.0479%2C1105.2460%2C1105.0978%2C1105.4076%2C1105.5540%2C1105.3997%2C1105.2950%2C1105.1221%2C1105.4148%2C1105.3521%2C1105.5493%2C1105.0791%2C1105.0701%2C1105.4952%2C1105.4566%2C1105.3202%2C1105.3973%2C1105.3211%2C1105.3204%2C1105.0806%2C1105.0244%2C1105.1727%2C1105.6047%2C1105.0290%2C1105.0048%2C1105.0619%2C1105.3282%2C1105.2271%2C1105.3944%2C1105.4407%2C1105.2072%2C1105.1807%2C1105.2226%2C1105.3195%2C1105.1755%2C1105.5696%2C1105.0136%2C1105.2316%2C1105.1383%2C1105.3882%2C1105.1415%2C1105.0372%2C1105.3825%2C1105.3723%2C1105.0739%2C1105.4515%2C1105.6138%2C1105.6235%2C1105.1017%2C1105.1250&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Classifying network traffic according to their application-layer protocols is\nan important task in modern networks for traffic management and network\nsecurity. Existing payload-based or statistical methods of application\nidentification cannot meet the demand of both high performance and accurate\nidentification at the same time. We propose an application identification\nframework that classifies traffic at aggregate-flow level leveraging\naggregate-flow cache. A detailed traffic classifier designed based on this\nframework is illustrated to improve the throughput of payload-based\nidentification methods. We further optimize the classifier by proposing an\nefficient design of aggregate-flow cache. The cache design employs a\nfrequency-based, recency-aware replacement algorithm based on the analysis of\ntemporal locality of aggregate-flow cache. Experiments on real-world traces\nshow that our traffic classifier with aggregate-flow cache can reduce up to 95%\nworkload of backend identification engine. The proposed cache replacement\nalgorithm outperforms well-known replacement algorithms, and achieves 90% of\nthe optimal performance using only 15% of memory. The throughput of a\npayload-based identification system, L7-filter [1], is increased by up to 5.1\ntimes by using our traffic classifier design."}, "authors": ["Fei He", "Fan Xiang", "Yibo Xue", "Jun Li"], "author_detail": {"name": "Jun Li"}, "author": "Jun Li", "links": [{"href": "http://arxiv.org/abs/1105.5684v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1105.5684v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1105.5684v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1105.5684v1", "arxiv_comment": null, "journal_reference": "International Journal of Computer Networks & Communications, 2011", "doi": null, "fulltext": "TOWARDS HIGH-PERFORMANCE NETWORK\nAPPLICATION IDENTIFICATION WITH\nAGGREGATE-FLOW CACHE\nFei He1, 2, Fan Xiang1, Yibo Xue2,3 and Jun Li2,3\n1\n\nDepartment of Automation, Tsinghua University, Beijing, China\n{hefei06,xiangf07}@mails.tsinghua.edu.cn\n\n2\n\nResearch Institute of Information Technology, Tsinghua University, Beijing, China\n3\nTsinghua National Lab for Information Science and Technology, Beijing, China\n{yiboxue,junl}@tinghua.edu.cn\n\nA B ST R ACT\nClassifying network traffic according to their application-layer protocols is an important task in modern\nnetworks for traffic management and network security. Existing payload-based or statistical methods of\napplication identification cannot meet the demand of both high performance and accurate identification\nat the same time. We propose an application identification framework that classifies traffic at aggregateflow level leveraging aggregate-flow cache. A detailed traffic classifier designed based on this framework\nis illustrated to improve the throughput of payload-based identification methods. We further optimize the\nclassifier by proposing an efficient design of aggregate-flow cache. The cache design employs a\nfrequency-based, recency-aware replacement algorithm based on the analysis of temporal locality of\naggregate-flow cache. Experiments on real-world traces show that our traffic classifier with aggregateflow cache can reduce up to 95% workload of backend identification engine. The proposed cache\nreplacement algorithm outperforms well-known replacement algorithms, and achieves 90% of the\noptimal performance using only 15% of memory. The throughput of a payload-based identification\nsystem, L7-filter [1], is increased by up to 5.1 times by using our traffic classifier design.\n\nK E YWOR DS\nApplication Identification, Aggregate-flow, Traffic Classification, Cache Replacement\n\n1. I NT R ODUC T I ON\nModern datacenter and enterprise networks require granular control of traffic to either improve\nthe performance of data transfer or ensure network security. Classifying network traffic\naccording to their application-layer protocols is an essential task for network devices such as\nnext-generation firewall [2], intrusion prevention system, and traffic management system.\nThese devices either perform application specific authentication or quality-of-service assurance\nbased on the application-layer protocol of the traffic.\nIn early days of the Internet, application identification practices rely to a large extent on the use\nof transport-layer port numbers. Port-based methods were effective for applications use IANA\nregistered port numbers (for example, HTTP traffic uses port 80 and DNS traffic uses port 25).\nHowever, emerging applications such as streaming audio and video, file sharing, and social\nnetworks are capable of using non-standard or dynamic ports, encapsulating inside commonly\nused protocols as a means of evading port-based identification. Therefore, port-based methods\ncan no longer provide sufficient information for network application identification.\nPrevious works have proposed a number of methods to identify the application associated with a\nconnection. Most of them can be categorized into payload-based methods [3] and statistical\nmethods [4-6]. Payload-based methods are accurate and reliable in most cases, and they are\n\n\fsimilar with other deep inspection (DI) systems, such as intrusion prevention systems, which\ninspect the payload of packets searching against a set of signatures. However, these methods\nrequire much resources (both computational and memory) since every bytes of packet payloads\nneed to be inspected. Statistical methods usually use machine learning techniques to classify the\ntraffic based on connection properties such as connection duration, packet size distribution per\nconnection, mean packet inter-arrival time and so on [7]. Statistical methods are currently not\nable to provide fine-grained application identification, and the accuracy of statistical methods is\nusually not acceptable for in-line network devices. For these reasons, most of production AppID systems, such as Palo Alto [8], and open source system L7-filter [1], are based on payloadbased methods which provide fine-grained and accurate results.\nExisting methods cannot meet the requirements of in-line network devices in terms of both\nthroughput and identification accuracy. Payload-based methods are accurate, but they consume\na lot of computation power and become bottleneck when hardware resources are limited. Guo et\nal. [9] presents that the throughput of original L7-filter is around 200Mbps on an latest Intel\nXeon platform. Although the throughput of 8-thread parallel version reaches 1.2Gbps, it is far\nbelow the wire-speed of modern access networks (e.g. 10Gbps and beyond). Even the\nthroughput of statistical methods is not as good as the common belief. Cascarano et al. [10]\ndemonstrates that a statistical classifier based on Support Vector Machines have comparable\ncomputational complexity with a payload-based classifier.\nTo address the challenges of network application identification, we propose an application\nidentification framework that classifies traffic at aggregate-flow level (defined in Section 3) in\nthis paper. The proposed framework can be used with almost all of the existing methods to\nimprove the overall performance of application identification.\nThe main contribution of this paper includes:\na) We propose an application identification framework that classifies traffic at aggregate-flow\nlevel. Traffic classifier designer can leverage aggregate-flow heuristics provided by the\naggregate-flow cache to achieve better identification accuracy or higher throughput.\nb) Considering the throughput of traffic classifier as the target, a detailed traffic classifier is\ndesigned based on this framework. The traffic classifier caches previous identification results\nin the aggregate-flow cache to reduce the workload of the backend identification engine.\nThus the throughput of the classifier is improved significantly while the identification\naccuracy is not affected.\nc) In order to further optimize the traffic classifier, an effective design of aggregate-flow cache\nis proposed. We characterize the temporal locality of aggregate-flow cache and propose a\nfrequency based, recency-aware cache replacement algorithm based on the locality analysis.\nThe rest of the paper is organized as follows. Related work is presented is in Section 2. We\ndescribe our aggregate-flow level application identification framework in Section 3. A detailed\ntraffic classifier design for throughput optimization is presented in Section 4. Section 5\ndemonstrates the design of data structure and replacement algorithm of aggregate-flow cache.\nSection 6 evaluates the performance of our method. We conclude the paper in Section 6.\n\n2. R E L A T E D W OR K\nAnalysis of the application-layer protocol of traffic has always been one of the major interests\nfor network operators. To address the inefficiency of port-based classification, several\napplication identification techniques have been proposed. Generally, they are categorized into\npayload-based and statistical methods. Payload-based application identification is one of the\nmost used techniques. Sen et al. [3] have proposed a method that use fixed strings and regular\nexpressions to identify P2P applications. Many other studies focus on increase the throughput of\npayload-based methods. For example, a rich set of research focuses on accelerating regular\nexpression matching [11-13], which is the component consuming most resources in payload-\n\n\fbased methods. Guo et al. [9] exploit flow-level parallelism of application identification and\nutilize multi-core architecture to increase the throughput of application identification system.\nThere are also many identification algorithms based on statistical methods, e.g. machine\nlearning and clustering algorithms. Moore et al. [6] use Bayesian Classifier to perform traffic\nclassification based on per-connection statistics. Li et al. [14] study the method of traffic\nclassification using the SVM. However, all these methods classify traffic on per-connection\nbasis, i.e. only heuristics in each connection are used to perform application identification.\nKaragiannis et al. [15] propose an interesting approach that classifies traffic based on the\nbehavior of the hosts generating it. The identification algorithm, called BLINC, analyzes\ntransport-layer information of connections generated by specific hosts, and classifies traffic\nbased on the services the hosts provide or use. This work enlightens us that application\nidentification can be performed beyond connection level. The problem of BLINC is that it\ncannot classify a single connection, and it cannot perform online classification. The framework\nproposed in this paper that classifies traffic at aggregate-flow level overcomes these problems.\nSeveral other papers [4, 16, 17] propose running statistical methods and payload-based methods\nin parallel to improve the accuracy of application identification. In their methods, two or more\nidentification algorithms are run in parallel, and the identification result is combined from the\nresults of each algorithm. Their methods improve the accuracy at the cost of increasing the\nworkload of the identification engine, thus reduce the throughput of the system. This kind of\nmethods can be combined with our aggregate-flow level classification framework to achieve\nbetter accuracy without reducing the throughput.\nIn the next section, we present the proposed application identification framework at aggregateflow level.\n\n3. F R A M E W OR K\nL EVEL\n\nOF\n\nA PPL I C A T I ON I DE NT I F I C A T I ON A T A G G R E G A T E -F L OW\n\nMost of existing methods only utilize connection-level heuristics. For example, Payload-based\nmethods matches the payload of packets in each connection against a set of pre-defined\napplication signatures. Statistical methods also collects per-connection statistics only, such as\npacket size distribution per connection, mean packet inter-arrival time, etc. We argue that\napplication identification should be performed above connection-level.\nA connection transmitting data between hosts has two endpoints: client endpoint and server\nIncoming packets\n\nConnection Table\n\nConnection lookup\n\nExisting Connection\nCache lookup\n\nAggregate-Flow Cache\nCache replacement\n\nPacket + AggregateFlow Heuristics\nIdentification engine\n\nAggregate-Flow\nAdapter\n\nApplication label\n\nFigure 1. Framework of application identification at aggregate-flow level.\n\n\fendpoint, each of which can be represented by the triple of IP address, transport-layer protocol,\nand transport-layer port. We define the aggregate-flow as the set of connections with a common\nserver-endpoint. Connections belong to one aggregate-flow are usually generated by the same\napplication at most of times for the following reasons:\n\n\uf0a7 A server endpoint is generally multiplexed between a variety of different connections, which\nmeans only one connection needs to be classified and all the other can share the result.\n\n\uf0a7 For most applications, the server endpoint is listened to by the server-side of an application,\nand the application binding to a specific server endpoint will not change frequently.\n\n\uf0a7 The popularity of various server endpoints could be highly uneven due to the existing of\nwell-known services, e.g. popular websites, mail servers, etc.\nSince connections in each aggregate-flow are generated by the same application, a traffic\nclassifier framework leveraging aggregate-flow level heuristics is proposed in order to achieve\nbetter performance than existing methods that identifies at connection-level. As illustrated in\nFigure 1, the proposed framework consists of a connection table as ordinary traffic classifier.\nAfter the application-layer protocol of a connection is identified by the identification engine, it\nis added to the connection table. The following packets of that connection are not processed by\nthe identification engine. The proposed classifier framework uses a data structure called\naggregate-flow cache to capture and store aggregate-flow level information. In more detail, each\nentry in the aggregate-flow cache consists of a triple (server IP, server port, transport-layer\nprotocol) as the key, an application label field stores previous identification result, and any other\naggregate-flow level heuristics needed by the classifier. If a packet finds the corresponding\naggregate-flow entry in the cache, the packet along with the aggregate-flow heuristics is sent to\nthe aggregate-flow adapter. The aggregate-flow adapter can be designed to achieve different\noptimization targets. It determines which packet with what kind of heuristic is sent to the\nidentification engine, and also what kind of identification result should be captured and stored\nin the cache. For example, if a statistical method is used as the identification engine, the adapter\ncan be designed to collect and store aggregate-flow level statistics in the cache. Both aggregateflow level statistics and connection level statistics are sent into the identification engine to\nachieve better identification accuracy. The target of this paper is to improve the throughput of\nidentification engine, a traffic classifier under this framework is presented in the next section to\nachieve this goal.\n\nPacket + AggregateFlow Heuristics\n\nNo\n\nHas valid\napplication\nlabel\nYes\n\nAggregate-Flow\nCache\n\nIdentification\nengine\nSampled\n\nSample with\nprobability p\n\nOutput filter\n\nApplication label\n\nFigure 2. Design of Aggregate-Flow Adapter.\n\n\f4. D E SI G N OF T R AF F I C C L A SSI F I E R B A SE D ON A G G R E G A T E -F L OW C A C H E\nSince the accuracy and reliability of payload-based methods are acceptable for in-line network\ndevices, it is more urgent to increase the throughput of application identification system. In this\nsection, we demonstrate a traffic classifier designed under the proposed framework to achieve\nthe goal of throughput improvement.\nThis classifier use a payload-based method as the identification engine. The goal of this design\nis to reach much better throughput than existing payload-based methods by leveraging the\naggregate-flow cache. Figure 2 shows the structure of the aggregate-flow adapter used in this\ntraffic classifier. In this case, the aggregate-flow heuristic is application label of the aggregateflow the packet belongs to. If a connection of the aggregate-flow has been identified before, the\napplication lable is a valid value. The packets can be marked as the same application label. Only\nwhen the packet does not find a match in aggregate-flow cache or the application lable is invalid,\nthe packet is sent to the identification engine for application identification based on its payload.\nActually, this traffic classifier perform classification on a per-aggregate-flow basis instead of\nper-connection basis, which can reduce the workload of the identification engine dramatically.\nAlthough the application of an aggregate-flow generally does not change in the short term, the\ncorresponding cache entry needs to be updated when it changes. To deal with the validation of\naggregate-flow entries, the adapter samples each connection that matches a cache entry with a\nprobability. If a connection is sampled, its packets are still sent to the identification engine. The\nidentification result is sent to the output filter module to update existing entries.\nThe output filter in the adapter also determines whether the identification result of a connection\nshould be cached. There are some special cases that should not be cached: (a) The data\nconnection of applications using dynamic port-negotiation mechanism, e.g. FTP, and SIP,\nshould not be cached, since the server endpoint of this kind of connection is randomly generated\nand may be used only once. (b) Incoming connections to a proxy server is another category that\nshould not be cached. A proxy server listens at a port that accepting multiple applications.\nTherefore, connections belongs to the corresponding aggregate-flow may not be generated by\nthe same application.\nStoring previous identification result in the aggregate-flow cache can significantly reduce the\nload of the identification engine. However, when deploying this classifier on network devices,\nthe memory usage of the aggregate-flow cache is an important thing to consider. We propose an\nefficient aggregate-flow cache design in the next section.\n\n5. E F F I C I E NT A G G R E G A T E -F L OW C A C H E D E SI G N\nTo design an efficient aggregate-flow cache, we need to a data structure optimized for both\ncache lookup and cache replacement operations. In addition, an efficient cache replacement\nalgorithm is very important to get high cache hit ratio using limited memory space. We\ndemonstrate data structure and cache replacement algorithm design in the following subsections.\nThe maintenance of aggregate-flow cache is different from that of connection table. Concurrent\nnumber of connections of a given link is usually within a certain range, since a majority of\nconnections time out quickly. However, it takes much longer time for an aggregate-flow to time\nout, if defining the timeout of an aggregate-flow as the status that all the connections belong to\nthis aggregate-flow time out. Actually, an aggregate-flow times out only when the server\nendpoint is closed or changed. The time when a server endpoint is not used is usually not\npredictable on a network device. Therefore, we use a fixed size memory for the aggregate-flow\ncache, and do not maintain timeout status for every each aggregate-flow entry. Instead, an\naggregate-flow entry is removed only when the cache is full. An efficient cache replacement\n\n\fTable 1. Value of \u03b1 for each trace.\nTr ace\n\u03b1\n\nTHU1 THU2 LBL1 LBL2 CAIDA1 CAIDA2\n0.90\n\n0.98\n\n1.26\n\n1.19\n\n0.69\n\n0.73\n\n10000\n\nNumber of Accesses (log)\n\nTHU1\n1000\n\n100\n\n10\n\n1\n1\n\n10\n100\n1000\n10000\nRanking of aggregate flow entry (log)\n\nFigure 3. Frequency of aggregate flow accesses versus ranking.\nalgorithm is needed for this design to store aggregate-flow entries with high probability of being\nreferenced in the future in the cache. We characterize the temporal locality of aggregate-flow\nusing traffic traces from different networks (detailed information of these traces are shown in\nSection 6), and derive an algorithm to capture the temporal locality.\n\n5.1 Analysis of temporal locality\nTemporal locality means that an entry just referenced has a high probability of being referenced\nagain in the near future. Increased temporal locality generally improves cache performance.\nTemporal locality of reference in aggregate-flow cache emerges from two distinct phenomena:\nthe long-term popularity of aggregate-flows and the short-term temporal correlations of\nreferences. We study the long-term popularity and the short-term temporal correlations\nseparately in order to guide the design of replacement algorithm.\nIntuitively, aggregate-flows associated with endpoints of well-known services may contain a\nlarger portion of connections than other aggregate-flows. The log-log scale plot in Figure 3\nshows that the popularity of various aggregate-flows is highly uneven. Actually, Zipf's law [4]\nis applicable to characterize the popularity of aggregate-flows. Zipf's Law states that the\npopularity of the nth most popular object is proportional to 1/n. We use the value \u03b1 in \"Zipf-like\"\ndistributions as a metric for popularity skewness. In such a distribution:\nP (On ) \u221d n \u2212\u03b1\n\nin which P(On) is the probability of a reference to the nth most popular object. Table 1 presents\na least-square fit of the alpha value of different traffic traces. The experiment shows that long\nterm popularity follows Zipf-like distribution and exhibits different \u03b1. Larger \u03b1 values are\nobserved in edge networks, and the \u03b1 values of backbone-network traces are smaller.\nAfter identifying an appropriate metric for capturing popularity, it remains to study the\ncorrelation component of temporal locality. The stack distance model [Evaluating techniques\nand storage hierarchies] is a widely used approach to capture and characterize temporal locality.\nFor any given reference to entry i, the corresponding stack distance is the number of unique\n\n\fLBL1\n\nLBL2\n1\n\n1\n\nOriginal\n\nOriginal\n\nRandom\n\nProbability of reference s\n\nProbability of reference s\n\nRandom\n\n0.1\n\n0.01\n\n0.001\n\n0.1\n\n0.01\n\n0.001\n\n0.0001\n\n0.0001\n1\n\n10\n\n100\n\n1000\n\n10\n\n1\n\n10000\n\n100\n\n1000\n\nDistance from the last reference\n\nDistance from the last reference\n\nFigure 4. Probability distribution of inter-reference distance of the two traces.\nTable 2. Slopes of the curves of the probability distribution of inter-reference distance.\nTr ace\n\nTHU1 THU2 LBL1 LBL2 CAIDA1 CAIDA2\n\nOr iginal\n\n0.97\n\n0.88\n\n0.65\n\n1.11\n\n0.50\n\n0.54\n\nScr ambled\n\n1.01\n\n0.91\n\n0.91\n\n0.88\n\n0.41\n\n0.59\n\nreferences since the last reference to i. However, stack distance cannot distinguish the causes of\ntemporal locality directly.\nIn order to measure short term popularity separately, we measure the stack distance when the\npacket streams are subjected to a random permutation. The temporal correlations can be\neliminated by applying a random permutation to the packet streams while preserving the\npopularity distribution. Figure 4 presents the probability distribution of inter-reference distance\nof two different traces. For trace LBL1, there is no significant change in the distribution\nbetween the original trace and the randomized trace, which means the temporal locality in this\ntrace is predominantly determined by the popularity distribution. However, the result of trace\nLBL2 presented in the right plot of Figure 4, reveals some difference between the original trace\nand the randomized trace. Table 2 shows the slopes of the curves for different traces using a\nleast-square fit. We can see that temporal correlation only exists in some traces and the intensity\nof this effect is not clear.\nOur characterization of temporal locality indicated that long-term popularity is the predominant\nand reliable contributor to temporal locality, but that temporal correlation exists in some traces.\nIt advocates us to design an aggregate-flow cache that mainly considers the skewed popularity,\nbut also consider the effect of temporal correlation.\n\n5.2 Data structure and replacement algorithm\nThe basic cache replacement policy that leverages the skewed popularity is Least-FrequentlyUsed (LFU). LFU infers object popularity directly from the reference history, and replace the\nentry with the least access frequency when a new entry is added to the full cache. It should be\nnoted that LFU can be implemented in two different forms: perfect LFU and in-cache LFU.\nPerfect LFU keeps the frequency information of all the objects, including both cached and\nevicted objects. On the other hand, in-cache LFU only maintains the frequency of cached\nobjects. Perfect LFU is obviously unrealistic due to the large scale of server endpoints, while\nthe performance of in-cache LFU is not good enough since it does not represent all requests in\n\n\fAggregate-flow cache\nMultistage Filter\n\nh1(F)\n\nHash table\n(all entryies)\n\nAggregate-flow\nentry with ID F\n\nh2(F)\n\nAll reach\nthreshold?\n\nh3(F)\nPriority Queue\n(Least frequently\nentries)\n\nFigure 5. Design of aggregate-flow cache.\nthe past.\nIn order to capture the most frequently accessed aggregate-flow entries in the cache, and use\nlittle extra memory, we employ a data structure called multistage filters [18] to identify\nfrequently accessed aggregate-flows. An aggregate-flow is added to the cache, only if its\nfrequency exceeds a pre-defined threshold T.\nThe basic structure of a multistage filter is shown in the left-side of Figure 5. The building\nblocks are several hash stages operate in parallel. Each hash stage is a table of counters indexed\nby a hash function computed on an aggregate-flow ID. All the counters are initialized to 0.\nBefore an aggregate-flow entry is added to the cache, a hash value on its aggregate-flow ID is\ncomputed and the corresponding counter is added by one. If the aggregate-flow appears more\nthan threshold T, its counter will exceed the threshold. However, since the memory for counters\nis limited, many aggregate-flows will map to the same counter. This will cause false positives,\nsince several aggregate-flows hashed to the same counter can add up to a number larger than the\nthreshold. To reduce the number of false positives, multiple stages with independent hash\nfunctions are used. An aggregate-flow entry is passed to the aggregate-flow cache, only if\nhashed counters in all stages exceed the threshold. Following the analysis in [18], we use d to\ndenote the number of stages, k for the stage strength which is the ratio of the threshold and the\naverage size of a counter. The probability of an aggregate-flow of frequency f \u2264 T (1 \u2212 1 / k )\n1 T d\npassing a d-stage filter is at most Pf \u2264 (\n) . The multiple stages reduce the probability\nkT\u2212f\nof false positives exponentially in the number of stages, which make it possible for us to capture\nthe most frequently accessed aggregate-flows using little extra memory.\nAggregate-flows pass the multistage filter is added to the cache. If the cache is full, the\nreplacement always happens among entries with the lowest frequency. Usually, an\nimplementation of such a policy would store all the entries in a priority queue with access\nfrequency as the key. This results in an expensive O(nlogn) time complexity for cache lookup.\nFortunately, there are a large number of entries that equal to the lowest frequency, and almost\nall the replacements happen among these entries. Our implementation uses a hash table to store\nall the cache entries, and a priority queue to store the entries with the lowest frequency. The\npriority queue uses the last access time of aggregate-flow as the key. Our implementation\nselects the oldest one from entries that are least frequently accessed as a candidate for eviction.\nThe implementation needs only O(1) time for each cache lookup, and O(mlogm) (m is the\naverage number of entries with the lowest frequency) time for each replacement. Experiments in\nthe next section will show that this algorithm outperforms LRU and LFU in almost all the\ncircumstances.\n\n\fTable 3. General information of our traces.\nSet\n\nDate\n\nTHU1\nTHU2\nLBL1\nLBL2\nCAIDA1\nCAIDA2\n\n2005-10-15\n2005-10-15\n2004-12-15\n2004-12-15\n2009-09-17\n2010-03-25\n\nLink\nbandwidth\n1Gbps\n1Gbps\nN/A\nN/A\n10Gbps\n10Gbps\n\nIP\naddress\n19K\n8.6K\n1.0K\n3.0K\n1194K\n1334K\n\nPackets\n\nConnections\n\n2628K\n2455K\n8439K\n9257K\n38485K\n41083K\n\n36K\n18K\n9K\n32K\n2571K\n2576K\n\nAggregateflows\n3897\n3484\n412\n1597\n487K\n525K\n\n6. P E R F OR M A NC E E V A L UA T I ON\nIn this section, we demonstrate the effectiveness of our approach when applied to real world\ntraffic traces. After describe the datasets used and the experiment environment, a proof of\nconcept is given. Then we present the performance of our cache replacement algorithm\ncomparing to several well-known algorithms. Finally, the throughput and memory usage of the\nproposed traffic classifier is evaluated.\n\n6.1 Experiment Setup\nWe use three sets of traffic traces from academic, enterprise and backbone networks. The first\nset (THU1, THU2) are traffic traces with packet payload collected on the Internet link of a\ncampus network with about 1000 computers at Tsinghua University. The second set (LBL1,\nLBL2) are packet header traces of enterprise network, provided by LBNL/ICSI Enterprise\nTracing Project [19]. The third set (CAIDA1, CAIDA2) contains packet header traces from\nCAIDA's monitors on OC192 Internet backbone links [20]. Table 3 lists general information of\nour data sets.\nWe implement a trace-driven traffic classifier based on Libnids [21] to test the performance of\nour design when processing real-world traffic. The backend application identification engine\nused in the classifier is a widely-deployed payload-based engine, L7-filter [1]. All the\nexperiments were obtained on a Server with a Xeon E5504 CPU (4 cores at 2.0 GHz) and 4 GB\nDDR3 memory.\n\n6.2 Evaluation Results\nWe first give a proof concept of our method by comparing the number of aggregate-flows with\nthe number of connections. Figure 6 shows that the numbers of aggregate-flows are among\n4.7% to 20.4% of the numbers of connections for different network environments. Therefore,\nthe number of connections needs to perform payload-based application identification can be\n\n#aggregate flows /\n#connections\n\n25%\n20%\n15%\n10%\n5%\n0%\nTHU1\n\nTHU2\n\nLBL1\n\nLBL2 CAIDA1 CAIDA2\n\nFigure 6. Number of aggregate-flows divided by number of connections.\n\n\fTHU2\n100%\n\n90%\n\n90%\n\n80%\n\n80%\n\n70%\n\n70%\n\n60%\n50%\n\nOptimal-LFU\n\n40%\n\nLRU\n\n30%\n\nCache hit ratio\n\nCache hit ratio\n\nTHU1\n100%\n\n60%\n50%\n\nOptimal-LFU\n\n40%\n\nLRU\n\n30%\n\n20%\n\nMS-Hybrid\n\n20%\n\nMS-Hybrid\n\n10%\n\nLFU-incache\n\n10%\n\nLFU-incache\n\n0%\n\n0%\n0%\n\n0%\n\n20%\n40%\n60%\n80%\n100%\nCache size (% of total aggregate-flows)\n\nLBL2\n\n100%\n\n100%\n\n90%\n\n90%\n\n80%\n\n80%\n\n70%\n\n70%\n\n60%\n50%\n\nOptimal-LFU\n\n40%\n\nLRU\n\n30%\n\nCache hit ratio\n\nCache hit ratio\n\nLBL1\n\n60%\n50%\n\nOptimal-LFU\n\n40%\n\nLRU\n\n30%\n\n20%\n\nMS-Hybrid\n\n20%\n\nMS-Hybrid\n\n10%\n\nLFU-incache\n\n10%\n\nLFU-incache\n\n0%\n\n0%\n0%\n\n20%\n40%\n60%\n80%\n100%\nCache size (% of total aggregate-flows)\n\n0%\n\nCAIDA1\n100%\n\n90%\n\n90%\n\n80%\n\n80%\n\n70%\n\n70%\n\n60%\n50%\n\nOptimal-LFU\n\n40%\n\nLRU\n\n30%\n\n20%\n40%\n60%\n80%\n100%\nCache size (% of total aggregate-flows)\nCAIDA2\n\n100%\n\nCache hit ratio\n\nCache hit ratio\n\n60%\n80%\n100%\n20%\n40%\nCache size (% of total aggregate-flows)\n\n60%\n50%\n\nOptimal-LFU\n\n40%\n\nLRU\n\n30%\n\n20%\n\nMS-Hybrid\n\n20%\n\nMS-Hybrid\n\n10%\n\nLFU-incache\n\n10%\n\nLFU-incache\n\n0%\n\n0%\n0%\n\n20%\n40%\n60%\n80%\n100%\nCache size (% of total aggregate-flows)\n\n0%\n\n20%\n40%\n60%\n80%\n100%\nCache size (% of total aggregate-flows)\n\nFigure 7. Cache hit ratio of different replacement algoritms\nreduced by up to 95%, which increases the performance of the traffic classifier significantly.\nActually, the ratio of number of aggregate-flows and number of connections is mainly\ndetermined by the applications in network. Since most applications in general networks uses\npersistent server endpoints, the proposed framework of classifying traffic at aggregate-flow\nlevel should be effective.\nFigure 7 presents the result of our cache replacement algorithm (Multistage-Hybrid, MS-Hybrid)\ncomparing with two well-known replacement algorithm Least Recent Used (LRU) and in-cache\nLFU. The cache hit ratio of Optimal-LFU is calculated assuming the popularity of every\naggregate-flow is known in advance, which is unrealistic. It is the optimal result frequencybased replacement algorithm can reach, and is used as a benchmark for comparison. Our\nreplacement algorithms outperform LRU and in-cache LFU on almost all the traces, especially\nwhen the cache size is small. In additional, the cache hit ratio of MS-Hybrid is very close to that\nof the Optimal-LFU. The result of LRU on trace LBL2 is a little bit better than MS-Hybrid as\n\n\f6\n\nThroughput (normalized)\n\n5\n4\n3\nTHU1\n\n2\n1\n\nTHU2\n\n0\n0%\n\n20%\n\n40%\n60%\nCache size\n\n80%\n\n100%\n\nFigure 8. Throughput of proposed traffic classifier comparing to L7-filter.\nthe analysis in section 5.1 shows that the temporal correlation in LBL2 is intensive. Still, the\ntime complexity of MS-Hybrid is only O(1), smaller than O(nlogn) of LRU and LFU.\nWhen using our replacement algorithm, the cache hit ratio reaches almost its maximum when\nthe cache size is 40% of total number of aggregate-flows. For most traces, the performance\ndegradation is only around 10% if the cache size is reduced to 15% of total number of entries.\nTherefore, the performance of the traffic classifier can be guaranteed when the memory-usage\nof aggregate-flow cache is limited.\nIn Figure 8, the throughput of the proposed traffic classifier, normalized to that of L7-filter on\nthe same traces, is illustrated. Only results on trace THU1 and THU2 are tested since these two\ntraces are with packet payload, and the other traces are packet-header-only. The throughput of\nthe traffic classifier increases up to 5.1 times over original L7-filter on trace THU1, up to 4.5\ntimes on trace THU2. The increase is 4.5 times and 4.1 times respectively when the cache size\nis limited to 15% of total number of aggregate-flows.\n\n6. C ONC L USI ONS\nIn this paper, we study network application identification problem from a different perspective.\nWe propose an application identification framework that classifies traffic at aggregate-flow\nlevel. Traffic classifier designer can leverage aggregate-flow heuristics provided by the\naggregate-flow cache to achieve different design goal. A detailed traffic classifier designed\nbased on the framework is demonstrated to improve the throughput of payload-based\nidentification methods. Experiments on real-world traces show that our traffic classifier with\ncan reduce up to 95% workload of backend identification engine. In additional, we optimize the\nclassifier by proposing an effective design of aggregate-flow cache. We first characterize the\ntemporal locality of aggregate-flow cache and propose a frequency based, recency-aware cache\nreplacement algorithm based on the locality analysis. The proposed cache replacement\nalgorithm outperforms well-known replacement algorithms, and achieves 90% of the optimal\nperformance using only 15% of memory. Tests on an implementation of our classifier shows\nthat the throughput of L7-filter is increased by up to 5.1 times by using our traffic classifier\ndesign.\n\nR E F E R E NC E S\n[1]\n[2]\n[3]\n[4]\n\nApplication layer packet classifier for linux (l7-filter). Available: http://l7-filter.sourceforge.net\nJ. Pescatore and G. Young, \"Defining the Next-Generation Firewall,\" 2009.\nS. Sen, et al., \"Accurate, scalable in-network identification of p2p traffic using application\nsignatures,\" Proceedings of the 13th international conference on World Wide Web, May 1 2004.\nA. Callado, et al., \"Better network traffic identification through the independent combination of\n\n\f[5]\n[6]\n[7]\n[8]\n[9]\n\n[10]\n[11]\n\n[12]\n[13]\n[14]\n[15]\n[16]\n[17]\n\n[18]\n\n[19]\n[20]\n[21]\n\ntechniques,\" Journal of Network and Computer Applications, pp. 1-14, Feb 22 2010.\nA. McGregor, et al., \"Flow clustering using machine learning techniques,\" Passive and Active\nNetwork Measurement, Jan 1 2004.\nA. Moore and D. Zuev, \"Internet traffic classification using bayesian analysis techniques,\"\nProceedings of the 2005 ACM SIGMETRICS conference, Jun 1 2005.\nL. Bernaille, et al., \"Traffic classification on the fly,\" ACM SIGCOMM Computer\nCommunication Review, Jan 1 2006.\nPalo\nAlto\nNetworks\nEnterprise\nFirewall.\nAvailable: http://www.paloaltonetworks.com/products/pa4000.html\nD. Guo, et al., \"A scalable multithreaded L7-filter design for multi-core servers,\" Proceedings of\nthe 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems,\nNov 1 2008.\nN. Cascarano, et al., \"An experimental evaluation of the computational cost of a DPI traffic\nclassifier,\" Proceedings of the 28th IEEE conference on Global telecommunications, Nov 1 2009.\nM. Becchi and P. Crowley, \"An improved algorithm to accelerate regular expression\nevaluation,\" Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and\ncommunications systems, Dec 1 2007.\nS. Kumar, et al., \"Algorithms to accelerate multiple regular expressions matching for deep\npacket inspection,\" Proceedings of the 2006 ACM SIGCOMM conference, Aug 1 2006.\nR. Smith, et al., \"Deflating the big bang: fast and scalable deep packet inspection with extended\nfinite automata,\" Proceedings of the 2008 ACM SIGCOMM conference, Aug 1 2008.\nZ. Li, et al., \"Accurate Classification of the Internet Traffic Based on the SVM Method,\" in\nProceedings of IEEE International Conference on Communications, 2007, pp. 1373 -1378.\nT. Karagiannis, et al., \"BLINC: multilevel traffic classification in the dark,\" Proceedings of the\n2005 ACM SIGCOMM conference, Aug 1 2005.\nG. Szabo, et al., \"Accurate Traffic Classification,\" Proceedings of IEEE International\nSymposium on World of Wireless, Mobile and Multimedia Networks, pp. 1-8, 2007.\nG. Zhang, et al., \"Accurate Online Traffic Classification with Multi-Phases Identification\nMethodology,\" Proceedings of IEEE Consumer Communications and Networking Conference,\npp. 141-146, 2008.\nC. Estan and G. Varghese, \"New directions in traffic measurement and accounting: Focusing on\nthe elephants, ignoring the mice,\" ACM Transactions on Computer Systems, vol. 21, pp. 270-313,\n2003.\nLBNL/ICSI enterprise tracing project. Available: http://www.icir.org/enterprise-tracing/\nk. claffy, et al. The CAIDA anonymized 2009, 2010 Internet traces.\nAvailable: http://www.caida.org/data/passive/\nLibnids. Available: http://libnids.sourceforge.net\n\n\f"}