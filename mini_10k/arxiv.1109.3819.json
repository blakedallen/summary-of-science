{"id": "http://arxiv.org/abs/1109.3819v3", "guidislink": true, "updated": "2012-06-17T11:20:44Z", "updated_parsed": [2012, 6, 17, 11, 20, 44, 6, 169, 0], "published": "2011-09-17T23:22:55Z", "published_parsed": [2011, 9, 17, 23, 22, 55, 5, 260, 0], "title": "Speeding up of microstructure reconstruction: I. Application to\n  labyrinth patterns", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1109.4747%2C1109.2290%2C1109.4499%2C1109.4821%2C1109.6678%2C1109.5699%2C1109.2710%2C1109.3035%2C1109.4762%2C1109.2084%2C1109.2782%2C1109.0338%2C1109.2591%2C1109.1649%2C1109.4169%2C1109.3293%2C1109.0037%2C1109.2370%2C1109.4872%2C1109.5673%2C1109.6308%2C1109.4208%2C1109.2297%2C1109.6242%2C1109.6853%2C1109.1091%2C1109.1051%2C1109.3134%2C1109.1330%2C1109.5399%2C1109.2967%2C1109.3971%2C1109.5620%2C1109.4862%2C1109.3751%2C1109.3905%2C1109.1184%2C1109.1737%2C1109.2003%2C1109.1696%2C1109.1134%2C1109.4195%2C1109.1139%2C1109.4662%2C1109.3898%2C1109.0635%2C1109.5936%2C1109.0096%2C1109.3819%2C1109.6373%2C1109.1905%2C1109.6360%2C1109.3702%2C1109.6318%2C1109.6080%2C1109.2092%2C1109.1468%2C1109.1236%2C1109.2641%2C1109.2200%2C1109.1819%2C1109.0312%2C1109.2695%2C1109.6828%2C1109.3489%2C1109.4090%2C1109.3242%2C1109.6510%2C1109.5012%2C1109.2460%2C1109.2323%2C1109.1238%2C1109.5530%2C1109.4401%2C1109.2678%2C1109.3962%2C1109.5546%2C1109.5472%2C1109.0756%2C1109.1361%2C1109.5515%2C1109.3852%2C1109.3387%2C1109.4909%2C1109.1502%2C1109.0215%2C1109.3979%2C1109.5410%2C1109.2648%2C1109.4767%2C1109.1074%2C1109.2643%2C1109.5829%2C1109.3909%2C1109.3776%2C1109.3248%2C1109.3612%2C1109.0321%2C1109.5439%2C1109.0801%2C1109.4489&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Speeding up of microstructure reconstruction: I. Application to\n  labyrinth patterns"}, "summary": "Recently, entropic descriptors based the Monte Carlo hybrid reconstruction of\nthe microstructure of a binary/greyscale pattern has been proposed (Piasecki\n2011 Proc. R. Soc. A 467 806). We try to speed up this method applied in this\ninstance to the reconstruction of a binary labyrinth target. Instead of a\nrandom configuration, we propose to start with a suitable synthetic pattern\ncreated by cellular automaton. The occurrence of the characteristic attributes\nof the target is the key factor for reducing the computational cost that can be\nmeasured by the total number of MC steps required. For the same set of basic\nparameters, we investigated the following simulation scenarios: the\nbiased/random alternately mixed #2m approach, the strictly biased #2b and the\nrandom/partially biased #2rp one. The series of 25 runs were performed for each\nscenario. To maintain comparable accuracy of the reconstructions, during the\nfinal stages the only selection procedure we used was the biased one. This\nallowed us to make the consistent comparison of the first three scenarios. The\npurely random #2r approach of low efficiency was included only for completeness\nof the approaches. Finally, for the conditions established, the best single\nreconstruction and the best average tolerance value among all the scenarios\nwere given by the mixed #2m method, which was also the fastest one. The\nslightly slower the alternative #2b and #2rp variants provided comparable but\nless satisfactory results.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1109.4747%2C1109.2290%2C1109.4499%2C1109.4821%2C1109.6678%2C1109.5699%2C1109.2710%2C1109.3035%2C1109.4762%2C1109.2084%2C1109.2782%2C1109.0338%2C1109.2591%2C1109.1649%2C1109.4169%2C1109.3293%2C1109.0037%2C1109.2370%2C1109.4872%2C1109.5673%2C1109.6308%2C1109.4208%2C1109.2297%2C1109.6242%2C1109.6853%2C1109.1091%2C1109.1051%2C1109.3134%2C1109.1330%2C1109.5399%2C1109.2967%2C1109.3971%2C1109.5620%2C1109.4862%2C1109.3751%2C1109.3905%2C1109.1184%2C1109.1737%2C1109.2003%2C1109.1696%2C1109.1134%2C1109.4195%2C1109.1139%2C1109.4662%2C1109.3898%2C1109.0635%2C1109.5936%2C1109.0096%2C1109.3819%2C1109.6373%2C1109.1905%2C1109.6360%2C1109.3702%2C1109.6318%2C1109.6080%2C1109.2092%2C1109.1468%2C1109.1236%2C1109.2641%2C1109.2200%2C1109.1819%2C1109.0312%2C1109.2695%2C1109.6828%2C1109.3489%2C1109.4090%2C1109.3242%2C1109.6510%2C1109.5012%2C1109.2460%2C1109.2323%2C1109.1238%2C1109.5530%2C1109.4401%2C1109.2678%2C1109.3962%2C1109.5546%2C1109.5472%2C1109.0756%2C1109.1361%2C1109.5515%2C1109.3852%2C1109.3387%2C1109.4909%2C1109.1502%2C1109.0215%2C1109.3979%2C1109.5410%2C1109.2648%2C1109.4767%2C1109.1074%2C1109.2643%2C1109.5829%2C1109.3909%2C1109.3776%2C1109.3248%2C1109.3612%2C1109.0321%2C1109.5439%2C1109.0801%2C1109.4489&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Recently, entropic descriptors based the Monte Carlo hybrid reconstruction of\nthe microstructure of a binary/greyscale pattern has been proposed (Piasecki\n2011 Proc. R. Soc. A 467 806). We try to speed up this method applied in this\ninstance to the reconstruction of a binary labyrinth target. Instead of a\nrandom configuration, we propose to start with a suitable synthetic pattern\ncreated by cellular automaton. The occurrence of the characteristic attributes\nof the target is the key factor for reducing the computational cost that can be\nmeasured by the total number of MC steps required. For the same set of basic\nparameters, we investigated the following simulation scenarios: the\nbiased/random alternately mixed #2m approach, the strictly biased #2b and the\nrandom/partially biased #2rp one. The series of 25 runs were performed for each\nscenario. To maintain comparable accuracy of the reconstructions, during the\nfinal stages the only selection procedure we used was the biased one. This\nallowed us to make the consistent comparison of the first three scenarios. The\npurely random #2r approach of low efficiency was included only for completeness\nof the approaches. Finally, for the conditions established, the best single\nreconstruction and the best average tolerance value among all the scenarios\nwere given by the mixed #2m method, which was also the fastest one. The\nslightly slower the alternative #2b and #2rp variants provided comparable but\nless satisfactory results."}, "authors": ["R. Piasecki", "W. Olchawa"], "author_detail": {"name": "W. Olchawa"}, "author": "W. Olchawa", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/0965-0393/20/5/055003", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1109.3819v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1109.3819v3", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "11 pages, 3 figures, 2 tables, published version", "arxiv_primary_category": {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.mtrl-sci", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "physics.comp-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1109.3819v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1109.3819v3", "journal_reference": "Modelling Simul. Mater. Sci. Eng. 20 (2012) 055003", "doi": "10.1088/0965-0393/20/5/055003", "fulltext": "Speeding up of microstructure reconstruction:\nI. Application to labyrinth patterns\n\nR Piasecki and W Olchawa\nInstitute of Physics, University of Opole, Oleska 48, 45-052 Opole, Poland\nE-mail: piaser@uni.opole.pl\n\nAbstract\nRecently, entropic descriptors based the Monte Carlo hybrid reconstruction of the\nmicrostructure of a binary/greyscale pattern has been proposed (Piasecki 2011 Proc.\nR. Soc. A 467 806). We try to speed up this method applied in this instance to the\nreconstruction of a binary labyrinth target. Instead of a random configuration, we\npropose to start with a suitable synthetic pattern created by cellular automaton. The\noccurrence of the characteristic attributes of the target is the key factor for reducing\nthe computational cost that can be measured by the total number of MC steps required.\nFor the same set of basic parameters, we investigated the following simulation\nscenarios: the biased/random alternately mixed #2m approach, the strictly biased #2b\nand the random/partially biased #2rp one. The series of 25 runs were performed for\neach scenario. To maintain comparable accuracy of the reconstructions, during the\nfinal stages the only selection procedure we used was the biased one. This allowed us\nto make the consistent comparison of the first three scenarios. The purely random #2r\napproach of low efficiency was included only for completeness of the approaches.\nFinally, for the conditions established, the best single reconstruction and the best\naverage tolerance value among all the scenarios were given by the mixed #2m method,\nwhich was also the fastest one. The slightly slower the alternative #2b and #2rp\nvariants provided comparable but less satisfactory results.\n(Some figures may appear in colour only in the online journal)\n\nPACS: 05.90.+m; 47.54.Jk; 89.75.Kd\nKeywords: Microstructure reconstruction; entropic descriptors; computer modelling\n\n1. Introduction\nFor efficient Monte Carlo (MC) modelling, a reduction in the reconstruction time is highly\ndesirable. Can we reduce it considerably in a simple way, at least for a certain class of\npatterns? Let us focus on the microstructure reconstruction of a binary labyrinth pattern\nmaking use of the simulated annealing (SA) technique within the MC method. There are\nmany factors that influence the computational cost\u2013\u2013measured roughly by the total number of\n\n\f2\n\nR. Piasecki, W. Olchawa\n\nMC steps (MCSs)\u2013\u2013in particular, when a personal computer is in use. In this context, a few\nessential factors are addressed in this paper. Frequently, a random initial configuration of\nobjects is applied instead of a suitable synthetic pattern that includes some of the most\ncharacteristic attributes of a target. To minimize an objective function, the assumed level of\nthe tolerance value should not be too restrictive. We mean such a situation when it nearly\ndoubles the number of MCSs while the final pattern is practically of the same quality. In\naddition, the optimization of a used program and the choice of a kind of simulation scenario\nbelong to the essential factors. Each of these points is taken into account in this paper, with\na particular care regarding the first and last ones.\nAmong the numerous models of pattern formation, the cellular automata (CA) approach\nis particularly simple in usage. To this group belongs spatially discrete model of vertebrate\nskin pattern growth proposed by Young [1]. The mechanism of pattern formation is based on\nshort-range activation and long-range inhibition. The model allows the reproduction of the\nbasic features of vertebrate skin patterns: spots, stripes and mixed forms. Its extended version\n(given in the next section) can be applied to produce a synthetic initial pattern with the\ntarget's characteristic attributes. In this way, the microstructure reconstruction becomes more\nefficient. It should also be noted that our aim is not the exact duplication of the parent\nmicrostructure. The inverse reconstruction process is meant rather to create statistically\nsimilar microstructures instead [2, 3]. Such microstructures can be used for testing of various\nmodels or to optimise the design of heterogeneous materials in material science [4, 5].\nUnlike the traditionally used correlation functions [6\u20139], objective functions employing\nthe so-called entropic descriptors (EDs) have been recently proposed [10]. A different fresh\napproach that describes microstructure variance as a stochastic process was developed in [11].\nIn this paper, we focus on the ED method that makes multi-scale information known partly\ndissimilar to that given by correlation functions at almost all length scales. In the simplest\ncase, the EDs can be used for quantitative characterization of the spatial inhomogeneity of\na binary microstructure (for greyscale images other applications are also available [10]). Here\nwe show, how the ED based MC hybrid reconstruction of labyrinth binary microstructure can\nbe made much faster in a simple way.\n\n2. The extended Young's model\nAccording to specific rules of Young's model [1], an initially random arrangement of ninit\ndifferentiated cells (DC as black pixels) in a matrix of undifferentiated cells (UC as white\n\n\fSpeeding up microstructure reconstruction\n\n3\n\npixels) can evolve into a 'skin' pattern. A square grid L L with periodic boundary conditions\nin both directions is used for simulation of the evolution. Each DC produces two diffusible\nmorphogens at a constant rate: i) an inhibitor having the longer range and stimulating the\ndedifferentiation of DC, ii) an activator stimulating the differentiation of the nearby UC. On\nthe other hand, the UCs are passive and produce no active substances. The sum of\nmorphogens influences each (x, y)-cell from all neighbouring DCs and this determines the fate\nof the cell. Therefore, in this process the mechanism of pattern formation includes local\nactivation and long-range inhibition:\n\nw( ri )\n\nw1\n\n0\n\nfor\n\nri\n\nR1\n\n(I\n\nregion ) ,\n\nw2\n\n0\n\nfor R1\n\nri\n\nR2\n\n( II\n\nregion ) .\n\n(2.1)\n\nHere, ri is the radial distance of the ith DC from the (x, y)-cell. For the model parameters w1,\nw2, R1 and R2, the rule of time-evolution of every cell, see (2.3), depends on the summary\nactivation-inhibition field at time t\nW ( x, y; t )\n\nw1\nri\n\nI\n\nw2\n\n(2.2)\n\nri II\n\nWithin a simple extension of the above model, the process of evolution affected by chemical\nor physical properties of an 'environment' can be easily taken into account. Making use of the\nauxiliary parameter\n\nthat is involved in on\u2013off switching of cell differentiations, favourable\n\n( < 0), neutral ( = 0) or hostile ( > 0) environmental conditions can be considered. Thus,\nfor each (x, y; t)-cell the following situations can appear at the time t + 1:\n(a)\n\nIf W ( x, y; t )\n\nthen DC (UC) becomes (remains) a UC cell at time t 1\n\n(b)\n\nIf W ( x, y; t )\n\nthen the cell does not changes state at time t 1\n\n(c)\n\nIf W ( x, y; t )\n\nthen UC (DC) becomes (remains) a DC cell at time t 1\n\nIf\n\n(2.3)\n\n> 0 then we observe the lowering of nfinal in comparison with the original model that is\n\nrecovered for = 0. The opposite situation appears for < 0.\nOnce the results of changing states for each grid cell are saved as a separate successive\npattern, we consider this moment as the first iteration step j = 1 (temporal evolution step).\nThen, the resulting black\u2013white pattern with a current population size n(j) becomes the new\nstarting configuration. Let us denote the number of 'positive' UC\nDC\n\nDC and 'negative'\n\nUC changes in the jth iteration step by n+(j) and n (j), respectively. The iteration is\n\nrepeated until the resulting synthethic pattern no longer changes, i.e. n+(j) = n (j) = 0 [1].\n\n\f4\n\nR. Piasecki, W. Olchawa\n\n3. Hybrid approach to microstructure reconstruction\nThe question of modelling heterogeneous materials\u2013\u2013'to what extent can the structure of\na disordered heterogeneous material be reconstructed using limited but essentially exact\nstructural information about the original system?'\u2013\u2013remains a present-day problem [12]. Here\nwe apply one of the particularly useful approaches of modelling in material science, the SA\ntechnique within Monte Carlo method; see for instance the monograph [13]. In this paper,\na 100 100 sub-domain of a larger binarized image of magnetic stripes in perpendicular\nCo/Pt-based multilayers, see figure 2 in [14], was adapted as the target pattern. This magnetic\nforce microscopy image corresponds to a quite complex labyrinth microstructure with the\nblack phase volume fraction \u03c6 = 0.591. In order to perform its statistical reconstruction we\nconsider the multi-scale function\n\nfully described in [10]. This objective function is the\n\nweighted sum of squared differences between EDs computed for trial configurations and\ntargets ones marked with superscript '0'\n\nE\n\n1\n4\n\nL\n\n[( S\n\nS 0 )2\n\n(C\n\n,S\n\nC 0, S ) 2\n\n(G\n\nG 0 )2\n\n(C\n\n,G\n\nC 0, G ) 2 ] .\n\n(3.1)\n\nk 1\n\nThe basic definition of the EDs is given below in (3.2) and (3.3). In particular, the ED\nS (C\nG (C\n\n, S)\n, G)\n\nquantifies the spatial inhomogeneity (statistical complexity) [15, 16], while\ndescribes the compositional inhomogeneity (statistical complexity), respectively\n\n[16, 17]. We recall that a binary pattern can be encoded in two ways: (a) standard one\n(0 =black, 1 =white) and (b) greyscale fashion (0 =black, 255 =white). Therefore, to increase\nthe statistical sensitivity of the reconstruction, in (3.1) we employ ED pairs: {S , C\n{G , C\n\n, G}.\n\n, S}\n\nEach of the EDs makes use of the microcanonical entropy Entr(X) = kB ln\n\nwhere Boltzmann's constant is equal to unity,\n\nand\n(X),\n\ndenotes the number of microstates realizing\n\na macrostate properly defined and X = {S for the standard binary case; G for the greyscale\ncase}.\nIn our approach, black pixels are treated as finite-sized 1 1-objects. A configurational\n(binary) macrostate is given by a set of numbers {ni (k)}, i = 1, 2,..., (k), of black pixels\ninside the cell of size k k sliding by a discrete unit distance. The side length of the cell\ndefines the length scale k. For a one-dimensional pattern, 1 L, the number of allowed\npositions of the sliding cell 1 k is equal to (k) = [L\n\nk + 1] while in a two-dimensional\n\n\fSpeeding up microstructure reconstruction\n\ncase, L L, we have the sliding cell k k and (k) = [L\ninstead of letters\n\nand\n\n5\n\nk + 1]2 possible locations. Note that\n\npreviously used in [10, 15], now we make use of\n\nexclusively.\n\nIn turn, a set of cell sums {gi (k)}, i = 1, 2,..., (k), of grey level values determines\na compositional (greyscale) macrostate. The more detailed description and formulae used for\nthe numbers of realizations\n\nof appropriate macrostates can be found in the appendix\n\nof [10].\nFor inhomogeneity, the general form of EDs S and G is as follows:\n\nX (k )\n\n1 [ Entr ( X )\nmax\n\nEntr( X )] .\n\n(3.2)\n\nThe highest possible value of entropy, Entrmax (X; k) = ln\n\nmax (X; k),\n\nis related to the most\n\nspatially (or compositionally) uniform object configuration at a given length scale. Such\nan arrangement of black pixels (or distribution of grey levels) corresponds to the reference\nmacrostate RMmax(X). To evaluate, for each length scale k, the deviation of the current\narrangement that represents the actual macrostate AM from the appropriate RMmax it is natural\nto consider the difference Entrmax(k) \u2013 Entr(k) averaged over the number of cells\n\n.\n\nThe averaging allows for a comparison of ED values at different length scales k.\nOn the other hand, for statistical complexity C\n\nC\n\n,X\n\n(k )\n\n,S\n\nand C\n\n,G\n\nhave a more extended form\n\n1 [ Entrmax( X ) Entr( X )][ Entr( X ) Entrmin( X )] .\n[ Entrmax( X ) Entrmin ( X )]\n\nHere, the lowest possible value of entropy, Entrmin (X; k) = ln\n\n(3.3)\n\nmin (X; k),\n\nis related to the most\n\nspatially (or compositionally) non-uniform object configuration at a given length scale. For\nlimiting macrostates characterised by Entrmax(k) and Entrmin(k), the statistical complexity\nshould be minimal and it is, see (3.3). The most 'complex' arrangement at a given length\nscale emerges when the average departures of the actual entropy from the highest one and\nfrom the lowest reference entropy are similar to each other, a kind of compromise between\ntwo opposite limiting configurations: the most homogeneous and the most inhomogeneous.\nAccording to (3.2) for any length scale 1 \u2264 k \u2264 L, the binary S component (the grey level\ncounterpart G ) of the ED pairs takes into account the statistical dissimilarity of the actual\nmacrostate AM(S) [AM(G)] and the reference theoretical one RMmax(S) [RMmax(G)] that\nmaximizes the appropriate entropy. Consecutively, in (3.3) the binary C\n\n,S\n\ncomponent of the\n\nED pairs takes into consideration the statistical dissimilarity of macrostates in the pairs:\n\n\f6\n\nR. Piasecki, W. Olchawa\n\nAM(S) and RMmax(S), AM(S) and RMmin(S), RMmax(S) and RMmin(S), where the reference\ntheoretical one RMmin(S) [RMmin(G)] minimizes the appropriate entropy. A similar\ninterpretation applies to the grey level counterpart C\n\n, G.\n\nThis type of ED is able to distinguish\n\nstructurally distinct configurational [compositional] macrostates with identical or nearly the\nsame degree of spatial [compositional] disorder [16]. In particular, we are interested in those\nstructural features that depend on the length scale k.\nTo minimize the objective function\n\n, see (3.1), we repeat the following steps. For\n\na current pattern, two randomly selected pixels of different phases are interchanged giving the\nnew trial configuration. The new 'state' is then accepted with probability p(\n\n) given by the\n\nMetropolis\u2013MC acceptance rule [13]\n\np( E )\n\nwhere\n\n1\nexp(\n\n= Enew\n\nE T ),\nold\n\nE\n\n0,\n\nE\n\n0,\n\n(3.4)\n\nis the change in the 'energy' between the two successive states. Upon\n\nacceptance, the trial pattern becomes a current one, and the evolving procedure is repeated.\nThe variation of a fictitious temperature T as a function of time is called the cooling schedule\nassociated with the annealing process. We use the popular cooling schedule T(l) \u2044 T(0) =\n\nl\n\nwith a fixed parameter = 0.8, where l stands for the number of temperature loops. For each l,\nthe value of the number na(l) of MCS accepted during the lth temperature loop allows for\ntracing a fraction na(l) \u2044 N(l)\n\n(l), where N(l) means the entire length of the lth loop. In turn,\n\nthe chosen value of initial temperature, T(0) = 4 10\u20133, ensures the initial effectiveness\n0.3 < (1) < 0.65 for the synthetic starting pattern '2' that possesses characteristic attributes of\nthe target's pattern T; see the corresponding insets in figure 1. When a fraction of less than\n1% ( < 0.01) of the proposed MCS is accepted, we put in motion the specified biased\nprocedure of exchange of positions of two pixels of different phases. Such a pair is randomly\nselected among the black pixels belonging to a black cluster's border and white pixels\nneighbouring the border.\nIt should be stressed that the biased procedure consists of the conditional acceptation of\nthe pixels exchange. It is carried out, when the number of nearest neighbour (nn) black pixels\nfor a white centre is greater than or equal to number two and simultaneously, the number of\nnn black pixels for a black centre is less than or equal to number two. As a result, the number\nof very small white clusters (inside the black 'sea') and black clusters (inside the white 'sea')\nreduces considerably. Two pixels aligned along the diagonal form two clusters each of size\n\n\fSpeeding up microstructure reconstruction\n\n7\n\none while their side contact forms one cluster of size two. Additionally, some of the biased\nexchanges on a cluster's surface modify their shapes. This is in contrast to the strictly\nunbiased multi-scale reconstruction used previously [10], where the target microstructure was\nnaturally composed of many inner clusters of sizes in a wide range. Here, we deal with\na specific labyrinth pattern. There, in addition to one compact large cluster of size 5789 in\npixels, only a few much smaller clusters appear. Their occurrence is caused mainly by the\nprocedure of cutting out a 100 100 target sub-domain from the larger pattern adapted from\n[14]. This is an additional reason for the application of a biased procedure.\n\n4. Four simulation scenarios\nThe Monte Carlo reconstructions typically use a random configuration as the initial one. This\ncontributes to an increase in the computational cost. At least for a certain class of patterns,\ni.e. labyrinth patterns, this point can be easily overcome. To reduce the computational cost of\nthe statistical reconstruction process, we propose to replace a random initial configuration '1'\n(not shown) by the synthetic pattern '2'; see the inset of figure 1. The latter pattern can be\neasily created with the CA program already discussed in section 2. For a given seed, it is\nenough to take into account just two main indicators, the position of the first peak of S placed\nat length scale k = 5 and the number nfinal = 5789 of black pixels corresponding to its volume\nfraction \u03c6 = 0.591. Having some experience with the CA program, several trials led to the\nfollowing model parameters: R1 = 1.8, R2 = 6.2, w1 = 1, w2 = \u2013 0.068,\n\n= \u2013 0.127. Also the\n\ninitial number of black pixels, ninit = 493, can be finally fitted. In figure 1, the S lines, dashed\nand solid (red online), show how close the microstructure of pattern '2' is to the target one T.\nUsually, the evolving procedure ends when the energy\n\nbecomes smaller than the\n\nassumed tolerance -value. We think that a better insight into the efficiency of different\nsimulation strategies can be gained by the comparison of results for a series of simulations\nunder clearly established conditions. Here, we ask how far from the chosen value\n\n= 3 10\u20133\n\nare the average results for each of the proposed scenarios with the limited number of loops,\nlmax = 32, but with increasing length of successive lth loop. The length N(l) of each of the\nloops is an integer part of the suggested function f (l) given by\nl 1\n\nf (l )\n\na + (l\n\n1) b + ( c l\n\n*\n\n1) ,\n\n(4.1)\n\n\f8\n\nR. Piasecki, W. Olchawa\n\nwhere l = 1, 2, ..., lmax is the consecutive number of a temperature loop. For higher l numbers\nthan the chosen one, l* = 20 in (4.1), the length increase becomes more and more non-linear;\nsee the inset of figure 2. The other coefficients are a = 100, b = 25, c = 750 and correspond to\nthe length of initial loop, the linear part of the increase in loop length and the base of power\nfunction, respectively. In this way, for different scenarios comparable loop parameters are\nensured.\nIt should be also mentioned that the present program is significantly optimized. Namely,\nfor calculation of the factorial function, particularly at large arguments, we apply the code\ntaken from [18], which is based on the excellent approximation for the gamma function\nderived by Lanczos [19]. Compared with the version used previously this code works very\nfast and produces highly accurate results.\nNow, using the synthetic initial pattern '2', we investigate three main simulation\nscenarios: the mixed one #2m with alternately applied biased/random selection in the\nsucceeding temperature loops, the strictly biased #2b and the random/partially biased (more\nprecisely, biased only at the final stage) #2rp. Additionally, for comparison purposes only, the\npurely random #2r approach with no use of the biased procedure is also considered. We\nwould like to point out that a random initial configuration '1' is not taken into account, since\nsuch an approach is highly inefficient. It needed about 20 000 acceptable MCS during a single\nlong run of the previous version of our program.\nAmong the tested variants, the mixed one #2m provides the best results. In this approach,\nthe length of those temperature loops, which were involved in a random selection procedure,\nwas shortened to about 1/5 of the lth length described by (4.1). The best #2m single\nreconstruction among the 25 runs is also the best one in comparison with the other scenarios\nperformed for the same conditions. It shows the tolerance value\n\n= 2.5 10\u20133 obtained after\n\nNa = 1266 accepted and Ntot = 113 320 total MCS; see (red) circles and the upper right inset\nof figure 1. In this figure, the S thick solid line corresponds to the labyrinth target T-pattern,\nshort dashed (red) line relates to the synthetic '2' initial configuration created suitably by\ncellular automaton described in section 2. In turn, the long-dashed (blue) line refers to S\ncalculated for a random initial configuration '1' (not used further in fact). The appearance of\nequal quality fitting was also found for the other three EDs (not shown here for clarity of the\nfigure). The adequate statistical features of the best #2m reconstruction are also confirmed by\nthe cluster size distribution shown in table 1. In addition, one can see therein that the smallest\naverage tolerance value < > = 3.46 10\u20133 \u00b1 0.000 36 belongs to #2m scenario.\n\n\fSpeeding up microstructure reconstruction\n\n9\n\nTable 1. Numbers n(s) of cluster sizes s (in pixels) for target pattern T and its the best representative\nreconstructions #2m, #2b, #2rp and #2r, compared for the same conditions. Below, the corresponding\npatterns are depicted. The quality of reconstructions can be measured by the tolerance -value. For\nscenarios investigated, the average < > of 25 runs of our main program is given. In addition, the number\nNa of acceptances and the number Ntot of MCS during 32 loops of a single run is shown. The last right\npattern and shadowed data relate to the extra-reconstruction of type #2m, when only\n0.85 was changed.\nT\ns\n5\n8\n10\n22\n36\n40\n5789\n\nn\n1\n1\n1\n1\n1\n1\n1\n\n#2m\ns\n1\n2\n37\n62\n92\n5711\n\nn\n6\n1\n1\n1\n1\n1\n\n#2b\ns\n1\n3\n55\n5851\n\nn\n1\n1\n1\n1\n\n#2rp\ns\nn\n1\n15\n29\n1\n35\n1\n50\n1\n56\n1\n125\n1\n5600\n1\n\n#2r\ns\n1\n2\n3\n5\n9\n18\n34\n44\n48\n51\n57\n\nn\n57\n5\n2\n1\n1\n1\n1\n1\n1\n3\n1\n\ncontinuation\n69\n1\n77\n1\n84\n1\n108\n1\n129\n1\n348\n1\n539\n1\n602\n1\n805\n1\n2708\n1\n\n#2m for\n0.85\nwith smax = 5815\n= 0.00250\n< > = 0.00346\n\u00b1 0.00036\nNa 1266\n<Na> 1324\nNtot = 113320\n\n0.00342\n0.00409\n\u00b1 0.00041\n1562\n1612\n117054\n\n0.00306\n0.00435\n\u00b1 0.00054\n1375\n1341\n117054\n\n0.03002\n0.03419\n\u00b1 0.00435\n1061\n1047\n117054\n\n0.00201\n\n2331\n106340\n\nIn the same table, the data corresponding to the best representatives of other scenarios are\nalso summarized. For instance, the size of the biggest cluster s(#2m) = 5711 is quite close to\nthe target one s(T) = 5789 similarly to the strictly biased approach, s(#2b) = 5851. However,\nthe latter one does not guarantee a suitable distribution of the cluster's sizes. Similar to the\n#2b case behaviour for a distribution of the cluster's sizes appears for the #2rp scenario; see\ntable 1. In the latter case the random selection ends in the lth loop if\n\n(l) < 1 and the biased\n\nselection begins in the (l + 1)th loop until l = lmax = 32. Despite such disadvantages, only\nslightly worse average tolerance values, < (#2b) > = 4.09 10\u20133 \u00b1 0.000 41, and < (#2rp) > =\n4.35 10\u20133 \u00b1 0.000 54, are shown by these scenarios. The best reconstruction of 25 runs for\nthe former approach, needed Na(#2b) = 1562 accepted and Ntot = 117 054 of MCS while the\nlatter one, only Na(#2rp) = 1375. Therefore, both #2b and #2rp scenarios show moderate\nadvantages as well as weaknesses. In this comparison, the fastest #2m scenario, with its\naverage (over 25 runs) total number <Ntot> 111 501 of MCS is our preferred approach.\n\n\f10\n\nR. Piasecki, W. Olchawa\nTable 2. Numbers na(l) and fractions (l) of accepted trials in each loop for the best representative\nreconstructions #2m, #2b, #2rp and #2r obtained for the same conditions. In the last two sub-columns,\nthe similar data are shown for the extra reconstruction of type #2m, when only\n0.85 was changed.\nThe numbers of acceptances for non-biased trials are marked in bold.\n\nl\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n#2m\n#2b\n#2rp\n#2r\n#2m for\nna(l)\n(l) na(l)\n(l) na(l)\n(l) na(l)\n(l) na(l)\n57\n10\n72\n7\n83\n4\n85\n8\n83\n8\n80\n4\n79\n6\n64\n4\n78\n5\n84\n1\n68\n62\n59\n25\n37\n28\n35\n19\n33\n27\n28\n23\n\n57\n47.62\n47.68\n24.14\n40.89\n10.53\n33.20\n17.02\n26.52\n14.04\n21.28\n5.80\n17.48\n6\n11.59\n3.25\n11.16\n3.13\n8.97\n0.45\n5.04\n3.72\n2.81\n0.93\n1.05\n0.60\n0.56\n0.23\n0.29\n0.17\n0.13\n0.08\n\n63\n64\n74\n76\n70\n79\n91\n72\n75\n74\n73\n71\n62\n68\n55\n42\n46\n47\n44\n35\n26\n38\n22\n33\n31\n19\n20\n24\n19\n17\n22\n10\n\n63\n51.2\n49.01\n42.94\n34.48\n34.5\n35.55\n25.35\n23.96\n21.51\n19.41\n17.23\n13.72\n13.65\n9.96\n6.81\n6.58\n5.86\n4.70\n3.14\n1.92\n2.28\n1.05\n1.22\n0.88\n0.41\n0.32\n0.29\n0.17\n0.11\n0.10\n0.03\n\n32\n23\n18\n23\n18\n19\n22\n25\n19\n16\n17\n9\n21\n21\n21\n25\n26\n18\n29\n29\n38\n38\n39\n39\n68\n66\n50\n361\n108\n43\n38\n56\n\n32\n18.4\n11.92\n12.99\n8.87\n8.3\n8.59\n8.80\n6.07\n4.65\n4.52\n2.18\n4.65\n4.22\n3.80\n4.05\n3.72\n2.24\n3.1\n2.61\n2.82\n2.28\n1.85\n1.45\n1.93\n1.42\n0.80\n4.31\n0.95\n0.28\n0.18\n0.19\n\n35\n26\n26\n29\n26\n17\n12\n14\n17\n20\n20\n18\n10\n25\n13\n21\n23\n19\n29\n38\n28\n22\n44\n36\n55\n52\n49\n52\n61\n85\n62\n77\n\n35\n20.8\n17.22\n16.38\n12.81\n7.42\n4.69\n4.93\n5.43\n5.81\n5.32\n4.37\n2.21\n5.02\n2.36\n3.40\n3.29\n2.37\n3.1\n3.41\n2.08\n1.32\n2.09\n1.34\n1.56\n1.12\n0.79\n0.62\n0.54\n0.55\n0.29\n0.26\n\n59\n8\n78\n14\n108\n7\n116\n9\n111\n6\n99\n13\n115\n10\n109\n9\n127\n6\n130\n6\n108\n5\n115\n8\n143\n4\n168\n121\n170\n124\n102\n123\n\n0.85\n(l)\n59\n38.1\n51.66\n48.28\n53.20\n18.42\n45.31\n19.15\n35.46\n10.53\n26.33\n18.84\n25.44\n10\n19.75\n7.317\n18.17\n3.75\n13.89\n2.69\n8.01\n1.5\n5.47\n1.48\n4.06\n0.34\n2.70\n1.44\n1.49\n0.8\n0.48\n0.42\n\nAs concerns the entirely random scenario #2r, it was included here only for completeness\nof investigation. Note that in this case the average tolerance value, < (#2r) > = 3.42 10\u20132 \u00b1\n0.004 35, is relatively worse than the values earlier discussed by about one order. This weak\nresult is expected since the purely random selection procedure from a definition is not well\nsuited to optimize the cost MC function for a highly correlated initial synthethic pattern\ncomposed of compact clusters. We refer the reader to tables 1 and 2, where various details of\ndifferent scenarios are summarized.\n\n\fSpeeding up microstructure reconstruction\n\n11\n\nIn order to obtain a better insight into the speeding up of ED-based microstructure\nreconstruction, in table 2 the numbers na (l) and fractions\n\n(l) of accepted trials in each\n\ntemperature loop for the best representative reconstructions #2m, #2b, #2rp and #2r are\nsummarized. It is interesting that in the sub-column related to the #2rp method, the jump of\nna (l) appears for l =28, since the random selection was stopped earlier and the biased\nexchange procedure is switched on. Such a switching at the final stage is forbidden for purely\nrandom #2r scenario, hence, the worse results appear.\nOne point deserves a comment; in both tables, quite surprising data are presented for\na single run of extra-reconstruction of type #2m but with only one parameter changed,\ni.e.\n\n0.85. The less aggressive cooling schedule results in the best tolerance value\n\n=\n\n2.01 10\u20133 that was obtained after Na, extra = 2331 of accepted MCS; see the shadowed data and\nthe corresponding final pattern in table 1. Moreover, instead of temperature T(l=32) =\n3.96 10\u20136 now the program ends with nearly 7 times higher temperature, Textra(l=32) =\n2.59 10\u20135. This also forces the appearance of higher acceptance numbers na (l) during each\ntemperature loop and their more regular distributions; see the last two sub-columns in table 2.\nFinally, this single run turns needed only Ntot, extra = 106 340 of MCS. All these indicate that\nthere is still much room for searching optimal scenarios, at least for the reconstruction of\nbinary labyrinth patterns.\nFigure 2 illustrates the convergence of the cost function E for different scenarios we have\nfocused on. The arrows indicate the ED-based reconstructions: #2m (red line), #2b (green\nline), #2rp (blue line) and #2r (grey line) performed under the same conditions. In addition,\nthe convergence for extra-reconstruction of type #2m is shown, when only\n\n0.85 is\n\nchanged (rose line). One can also observe the changes of the number Na of accepted MCS for\neach of the investigated scenarios. It is obvious now that the smallest acceptance number\ncannot be linked directly with the best quality reconstruction, see for instance, the grey line\ncorresponding to the best representative reconstruction of #2r type.\nNow, we would like to point out that an interesting alternative [20] for reconstructing\nrandom microstructures is the hybrid approach making use of a pair {S2(r); C2(r)}, where\ntwo-point cluster function C2(r) gives the probability of finding two points separated by\na distance r in the same cluster of the phase of interest. Figure 3 displays the restricted twopoint correlation function S2 of the black phase computed by orthogonal-sampling algorithm\nwith the hard-wall conditions for the target T-pattern (black line) and for the best\nreconstructions #2m (red circles), #2b (green triangles), #2rp (blue squares). Those\n\n\f12\n\nR. Piasecki, W. Olchawa\n\nreconstructions are of comparable fitting quality because of the similar\n\nexcept the next one,\n\n#2r (grey line). One can observe that even such a simplified variant of two-point correlation\nfunction reveals relatively dissimilar structural information from that given by EDs for all\nreconstructed patterns. For instance, see the lower amplitudes at important length scale k = 5\nand stronger fluctuations at larger scales, say for k 15. Therefore, the combination of our\nmethod with the standard two-point correlation function S2 may be interesting in this context.\n\n4. Summary\nWe have developed a simple approach that allowed for speeding up of microstructure\nreconstruction of binary (two phases) labyrinth patterns. The effectiveness of the replacing of\na random initial configuration with a synthetic pattern carefully prepared by cellular\nautomaton has been confirmed by a series of tests. The hybrid reconstruction based on novel\nentropic descriptors seems to be a quite prospective method. It provides a responsible\nstatistical reconstruction of a microstructure with a given tolerance value. The number of\naccepted and total MCS reduces significantly also as result of the use of an improved version\nof our program. It employs only 32 temperature loops of given different lengths. For the\nestablished conditions, the most cost-effective scenario leading simultaneously to the best\nquality of the reconstruction is the biased/random alternately mixed #2m approach. From the\nphysical point of view, such an outcome agrees well with our expectations.\n\n\fSpeeding up microstructure reconstruction\n\n13\n\nReferences\n[1]\n[2]\n[3]\n[4]\n[5]\n[6]\n[7]\n[8]\n[9]\n[10]\n[11]\n[12]\n[13]\n[14]\n[15]\n[16]\n[17]\n[18]\n[19]\n[20]\n\nYoung D A 1984 Math. Biosci. 72 51\nKumar H, Briant C L and Curtin W A 2006 Mech. Mater. 38 818\nTorquato S 2009 Soft Matter 5 1157\nFullwood D T, Niezgoda S R, Adams B L and Kalidindi S R 2010 Prog. Mater. Sci. 55 477\nTorquato S 2010 Annu. Rev. Mater. Res. 40 101\nYeong C L Y and Torquato S 1998 Phys Rev E 57 495\nZeman J and \u0160ejnoha M 2007 Modelling Simul. Mater. Sci. Eng. 15 S325\nFullwood D T, Niezgoda S R and Kalidindi S R 2008 Acta Mater 56 942\nJiao Y, Stillinger F H and Torquato S 2008 Phys. Rev. E 77 031135\nPiasecki R 2011 Proc. R. Soc. A 467 806\nNiezgoda S R, Yabansu Y C and Kalidindi S R 2011 Acta Materialia 59 6387\nRintoul M D and Torquato S 1997 J. Colloid Surface Sci. 186 467\nTorquato S 2002 Random Heterogeneous Materials: Microstructure and Macroscopic Properties\n(Berlin: Springer)\nHellwig O, Denbeaux G P, Kortright J B and Fullerton E E 2003 Physica B 336 136\nPiasecki R 2000 Physica A 277 157\nPiasecki R 2000 Surf. Sci. 454-456 1058\nPiasecki R and Plastino A 2010 Physica A 389 397\nPiasecki R 2009 Physica A 388 2403\nPiasecki R 2009 Physica A 388 4229\nPress W H, Teukolsky S A, Vetterling W T and Flannery B P 2007 Numerical Recipes\n(Cambridge: University Press) p 256\nLanczos C 1964 SIAM Journal on Numerical Analysis, ser. B, 1 86\nJiao Y, Stillinger F H and Torquato S 2009 PNAS 106 17634\n\nFigure captions\nFigure 1. Hybrid reconstruction making use of two pairs of EDs, {S ; C , S} and {G ; C , G}, for a 100 100 part\nof the binarized image of magnetic stripe domains in perpendicular Co/Pt-based multilayers adapted from\nfigure 2 in [10]. The S thick solid line corresponds to target labyrinth T-pattern while fitting by red circles refers\nto the mixed-type #2m reconstruction; the short dashed red line relates to the synthetic '2' initial configuration\ncreated suitably by a cellular automaton while the long dashed blue line indicates the S calculated for a random\ninitial configuration. Equal quality fitting appears also for the other three EDs.\nFigure 2. Convergence of different preferred scenarios for EDs based hybrid reconstructions: #2m (red line),\n#2b (green line), #2rp (blue line) and #2r (grey line) performed for the same conditions. In addition, the\nconvergence for extra reconstruction of type #2m is shown, when only\n0.85 is changed (rose line). In the\ninset, the increase in loop length as a function of loop number l is depicted.\nFigure 3. Restricted two-point correlation function S2 of black phase computed by the orthogonal-sampling\nalgorithm with the hard-wall conditions for target T-pattern (black line) and for its reconstructions: #2m (red\ncircles), #2b (green triangles), #2rp (blue squares) and #2r (grey line). The easily seen differences between the\ntarget and its reconstructions (via EDs) show that they provide relatively dissimilar structural information\ncompared with S2.\n\n\f14\n\nR. Piasecki, W. Olchawa\n\nS\n\n3.5\n3.0\n#2m\n\n2.5\n\nT\n\n2.0\n1.5\n'2'\n\n1.0\n0.5\n0.0\n\n0\n\n20\n\n40\n\n60\n\n80\n\nk\n\n100\n\nFigure 1. Hybrid reconstruction making use of two pairs of EDs, {S ; C , S} and {G ; C , G}, for a 100 100 part\nof the binarized image of magnetic stripe domains in perpendicular Co/Pt-based multilayers adapted from\nfigure 2 in [10]. The S thick solid line corresponds to target labyrinth T-pattern while fitting by red circles refers\nto the mixed-type #2m reconstruction; the short dashed red line relates to the synthetic '2' initial configuration\ncreated suitably by a cellular automaton while the long dashed blue line indicates the S calculated for a random\ninitial configuration. Equal quality fitting appears also for the other three EDs.\n\nFig. 1\n\n\fSpeeding up microstructure reconstruction\n\n1.6\n\n15\n\n30000\n\nN\n\nE\n\n25000\n\n#2rp\n20000\n\n1.2\n\n#2r\n\n15000\n10000\n\n0.8\n\n5000\n0\n\n0.4\n\n0\n\n4\n\n8\n\n12 16 20 24 28 32\n\nl\n\n#2b\n#2m for = 0.85\n\n0.0\n\n#2m\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\nMCS accepted\n\nFigure 2. Convergence of different preferred scenarios for EDs based hybrid reconstructions: #2m (red line),\n#2b (green line), #2rp (blue line) and #2r (grey line) performed for the same conditions. In addition, the\nconvergence for extra reconstruction of type #2m is shown, when only\n0.85 is changed (rose line). In the\ninset, the increase in loop length as a function of loop number l is depicted.\n\nFig. 2\n\n\f16\n\nR. Piasecki, W. Olchawa\n\n0.38\n\nS2\n\n#2m\n\n0.36\n\n0.34\n\n0.32\n\n0.30\nT\n\n0\n\n10\n\n20\n\n30\n\n40\n\nk\n\n50\n\nFigure 3. Restricted two-point correlation function S2 of black phase computed by the orthogonal-sampling\nalgorithm with the hard-wall conditions for target T-pattern (black line) and for its reconstructions: #2m (red\ncircles), #2b (green triangles), #2rp (blue squares) and #2r (grey line). The easily seen differences between the\ntarget and its reconstructions (via EDs) show that they provide relatively dissimilar structural information\ncompared with S2.\n\nFig. 3\n\n\f"}