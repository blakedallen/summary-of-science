{"id": "http://arxiv.org/abs/0706.4375v1", "guidislink": true, "updated": "2007-06-29T08:58:02Z", "updated_parsed": [2007, 6, 29, 8, 58, 2, 4, 180, 0], "published": "2007-06-29T08:58:02Z", "published_parsed": [2007, 6, 29, 8, 58, 2, 4, 180, 0], "title": "A Robust Linguistic Platform for Efficient and Domain specific Web\n  Content Analysis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0706.2180%2C0706.3155%2C0706.0105%2C0706.0035%2C0706.4471%2C0706.0922%2C0706.2607%2C0706.3207%2C0706.1016%2C0706.0597%2C0706.3092%2C0706.2369%2C0706.1228%2C0706.3737%2C0706.1482%2C0706.1679%2C0706.3124%2C0706.0524%2C0706.4154%2C0706.0890%2C0706.3134%2C0706.1210%2C0706.3515%2C0706.4427%2C0706.1102%2C0706.4165%2C0706.4147%2C0706.2344%2C0706.3855%2C0706.0693%2C0706.0448%2C0706.1124%2C0706.2692%2C0706.1682%2C0706.1324%2C0706.1197%2C0706.4105%2C0706.3000%2C0706.2728%2C0706.3731%2C0706.3819%2C0706.4375%2C0706.3789%2C0706.2588%2C0706.2621%2C0706.0258%2C0706.3596%2C0706.0677%2C0706.1492%2C0706.1535%2C0706.1859%2C0706.1971%2C0706.0233%2C0706.4401%2C0706.3909%2C0706.2322%2C0706.1355%2C0706.2649%2C0706.1100%2C0706.0895%2C0706.1267%2C0706.3841%2C0706.1510%2C0706.2523%2C0706.2952%2C0706.3187%2C0706.3840%2C0706.3339%2C0706.0517%2C0706.2063%2C0706.3999%2C0706.1048%2C0706.0348%2C0706.4149%2C0706.2259%2C0706.0311%2C0706.2023%2C0706.1777%2C0706.3986%2C0706.2562%2C0706.4321%2C0706.0605%2C0706.2092%2C0706.2826%2C0706.3645%2C0706.1578%2C0706.2604%2C0706.0678%2C0706.2798%2C0706.1566%2C0706.2373%2C0706.1363%2C0706.1046%2C0706.2219%2C0706.4482%2C0706.3027%2C0706.2007%2C0706.1158%2C0706.1512%2C0706.1183%2C0706.1062&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Robust Linguistic Platform for Efficient and Domain specific Web\n  Content Analysis"}, "summary": "Web semantic access in specific domains calls for specialized search engines\nwith enhanced semantic querying and indexing capacities, which pertain both to\ninformation retrieval (IR) and to information extraction (IE). A rich\nlinguistic analysis is required either to identify the relevant semantic units\nto index and weight them according to linguistic specific statistical\ndistribution, or as the basis of an information extraction process. Recent\ndevelopments make Natural Language Processing (NLP) techniques reliable enough\nto process large collections of documents and to enrich them with semantic\nannotations. This paper focuses on the design and the development of a text\nprocessing platform, Ogmios, which has been developed in the ALVIS project. The\nOgmios platform exploits existing NLP modules and resources, which may be tuned\nto specific domains and produces linguistically annotated documents. We show\nhow the three constraints of genericity, domain semantic awareness and\nperformance can be handled all together.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0706.2180%2C0706.3155%2C0706.0105%2C0706.0035%2C0706.4471%2C0706.0922%2C0706.2607%2C0706.3207%2C0706.1016%2C0706.0597%2C0706.3092%2C0706.2369%2C0706.1228%2C0706.3737%2C0706.1482%2C0706.1679%2C0706.3124%2C0706.0524%2C0706.4154%2C0706.0890%2C0706.3134%2C0706.1210%2C0706.3515%2C0706.4427%2C0706.1102%2C0706.4165%2C0706.4147%2C0706.2344%2C0706.3855%2C0706.0693%2C0706.0448%2C0706.1124%2C0706.2692%2C0706.1682%2C0706.1324%2C0706.1197%2C0706.4105%2C0706.3000%2C0706.2728%2C0706.3731%2C0706.3819%2C0706.4375%2C0706.3789%2C0706.2588%2C0706.2621%2C0706.0258%2C0706.3596%2C0706.0677%2C0706.1492%2C0706.1535%2C0706.1859%2C0706.1971%2C0706.0233%2C0706.4401%2C0706.3909%2C0706.2322%2C0706.1355%2C0706.2649%2C0706.1100%2C0706.0895%2C0706.1267%2C0706.3841%2C0706.1510%2C0706.2523%2C0706.2952%2C0706.3187%2C0706.3840%2C0706.3339%2C0706.0517%2C0706.2063%2C0706.3999%2C0706.1048%2C0706.0348%2C0706.4149%2C0706.2259%2C0706.0311%2C0706.2023%2C0706.1777%2C0706.3986%2C0706.2562%2C0706.4321%2C0706.0605%2C0706.2092%2C0706.2826%2C0706.3645%2C0706.1578%2C0706.2604%2C0706.0678%2C0706.2798%2C0706.1566%2C0706.2373%2C0706.1363%2C0706.1046%2C0706.2219%2C0706.4482%2C0706.3027%2C0706.2007%2C0706.1158%2C0706.1512%2C0706.1183%2C0706.1062&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Web semantic access in specific domains calls for specialized search engines\nwith enhanced semantic querying and indexing capacities, which pertain both to\ninformation retrieval (IR) and to information extraction (IE). A rich\nlinguistic analysis is required either to identify the relevant semantic units\nto index and weight them according to linguistic specific statistical\ndistribution, or as the basis of an information extraction process. Recent\ndevelopments make Natural Language Processing (NLP) techniques reliable enough\nto process large collections of documents and to enrich them with semantic\nannotations. This paper focuses on the design and the development of a text\nprocessing platform, Ogmios, which has been developed in the ALVIS project. The\nOgmios platform exploits existing NLP modules and resources, which may be tuned\nto specific domains and produces linguistically annotated documents. We show\nhow the three constraints of genericity, domain semantic awareness and\nperformance can be handled all together."}, "authors": ["Thierry Hamon", "Adeline Nazarenko", "Thierry Poibeau", "Sophie Aubin", "Julien Derivi\u00e8re"], "author_detail": {"name": "Julien Derivi\u00e8re"}, "author": "Julien Derivi\u00e8re", "links": [{"href": "http://arxiv.org/abs/0706.4375v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0706.4375v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0706.4375v1", "affiliation": "LIPN", "arxiv_url": "http://arxiv.org/abs/0706.4375v1", "arxiv_comment": null, "journal_reference": "Proceedings of RIAO 2007 (30/05/2007)", "doi": null, "fulltext": "A Robust Linguistic Platform for\nEfficient and Domain specific Web Content Analysis\nThierry Hamon, Adeline Nazarenko, Thierry Poibeau, Sophie Aubin, Julien Derivi\u00e8re,\nLIPN \u2013 UMR CNRS 7030\n99, avenue J.B. Cl\u00e9ment\nF-93430 Villetaneuse, France\n\nfirstname.name@lipn.univ-paris13.fr\n\nAbstract\nWeb semantic access in specific domains calls for specialized search engines with enhanced semantic querying\nand indexing capacities, which pertain both to information retrieval (IR) and to information extraction (IE). A\nrich linguistic analysis is required either to identify the relevant semantic units to index and weight them\naccording to linguistic specific statistical distribution, or as the basis of an information extraction process. Recent\ndevelopments make Natural Language Processing (NLP) techniques reliable enough to process large collections\nof documents and to enrich them with semantic annotations. This paper focuses on the design and the\ndevelopment of a text processing platform, Ogmios, which has been developed in the ALVIS project. The\nOgmios platform exploits existing NLP modules and resources, which may be tuned to specific domains and\nproduces linguistically annotated documents. We show how the three constraints of genericity, domain semantic\nawareness and performance can be handled all together.\n\n1. Introduction\nSearch engines like Google or Yahoo offer access to billions of textual web pages. These\ntools are very popular and seem to be sufficient for a large number of general user queries on\nthe Internet. However, some other queries are more complex, requiring specific knowledge or\nprocessing strategies: no really satisfactory solution exists for these requests. There is thus a\nneed for more specific search engines dedicated to specialized domain or users.\nLet us consider the case of text mining in Microbiology for example. Given the specificity\nand the reliability of the information that is sought by scientists, it is clear than one needs\nmore than existing search engines. Even if recent developments in biology and biomedicine\nare reported in large bibliographical databases (e.g. Flybase, specialized on Drosophilia\nMenogaster or Medline), such databases and the associated searching functionalities are not\nsufficient to satisfy biologists' specific information needs, such as finding information on\ngene interactions in order to progressively figure out a whole interaction network. We\npreviously argued that looking for this kind of relational information requires a\ndomain-specific linguistic analysis and parsing of the documents (Alphonse et al., 2004).\nThe ALVIS project aims at developing an open source search engine, with extended semantic\nsearch facilities. Compared to state of the art search engines (like Google, the most popular\none), the ALVIS search engine is domain specific. It relies on a specialized crawler, which\nselects the web pages on terminological grounds. Indexing exploits various types of linguistic\nand domain specific annotation. Through a dedicated user interface, the ALVIS search engine\nprocesses the query more accurately, taking into account the topic and the context of search to\nrefine both the query and the document analysis.\n\n\fFigure 1: Role of NLP in the ALVIS semantic search engine\nThis paper focuses on the design and the development of the text processing platform,\nOgmios, which has been developed in the ALVIS project. The challenges were\n\u2022 to handle rather large domain specific collections of documents (typical specialized\ncollections gather hundreds of thousands of documents, rather than hundreds of\nmillions of documents),\n\u2022 to analyze documents from the web using a single platform, how heterogeneous they\nmay be,\n\u2022 to enrich documents with domain-specific semantic information to allow semantic\nquerying.\nThe present paper shows how the three constraints of genericity, domain semantic awareness\nand performance can be handled all together.\nThe Ogmios platform is a generic one. It is instantiated using existing NLP modules and\nresources, which can be tuned to specific domains. The figure 1 shows the role of the NLP\nannotation and resource acquisition in the whole IR process. For processing texts in the\nbiological domain, we exploited a specific named entity dictionaries and terminologies and\nwe adapted a generic syntactic analyzer. In this paper, we focus on parsing which is the most\nchallenging NLP step when one wants to annotate a large document collection.\nSection 2 gives an overview of the existing platforms designed for document annotation.\nSections 3 and 4 describe the global architecture of the platform and its various NLP modules.\nSection 5 describes the performance of our system on a collection of crawled documents\nrelative to Microbiology. The last section presents our NLP adaptation strategy, showing as\nan example how a specialized parser can be derived from a generic one.\n2. Background\nSeveral text engineering architectures have been proposed to manage text processing over the\nlast decade (Cunningham et al., 2000). GATE (General Architecture for Text Engineering)\n(Bontcheva et al., 2004) has been essentially designed for information extraction tasks. It aims\nat reusing NLP tools in built-in components. The interchange annotation format (CPSL \u2013\n\n\fCommon Pattern Specific Language) is based on the TIPSTER annotation format\n(Grishman, 1997).\nBased on an external linguistic annotation platform, namely GATE, the KIM platform (Popov\net al., 2004) can be considered as a \"meta-platform\". It is designed for ontology population,\nsemantic indexing and information retrieval. KIM has been integrated in massive semantic\nannotation projects such as the SWAN clusters1 and SEKT.2 The authors identify scalability\nas a critical parameter for two reasons: (1) it has to be able to process large amounts of data,\nin order to build and train statistical models for Information Extraction; (2) it has to support\nits own use as an online public service.\nUIMA (Furrucci & Lally, 2004), a new implementation architecture of TEXTRACT (Neff et\nal., 2004), is similar to GATE. It mainly differs from GATE in the data representation model.\nUIMA is a framework for the development of analysis engines. It offers components for the\nanalysis of unstructured information streams as HTML web pages. These components are\nsupposed to range from lightweight to highly scalable implementations. The UIMA SDK is a\ncollection of Java classes. The UIMA annotation format is called CAS (Common Analysis\nStructure). It is mainly based on the TIPSTER format (Grishman, 1997). CAS annotations are\nstand-off for the sake of flexibility. Documents can be processed either at a single document\nlevel or at a collection level. Collections are handled in UIMA by the Collection Processing\nEngine, which has some interesting features such as filtering, performance monitoring and\nparallelization.\nThe Textpresso system (Muller et al., 2004) has been specifically developed to mine\nbiological documents, abstracts as well as articles. For instance, it has been used to process\n16,000 abstracts and 3,000 full text articles related to Caenorhabditis elegans. It is designed\nas a curation system extracting gene-gene interaction that is also used as a search engine. It\nintegrates the following NLP modules: tokenizer, sentence segmentation, Part-Of-Speech\n(POS) tagging, and an semantic tagging based on Gene Ontology (GOConsortium, 2001).\nWhile Textpresso is specifically designed for biomedical texts, our platform is more similar to\nGATE in its aim: proposing a generic platform to process large document collections.\nGenerally, very little information is given to evaluate the behavior of the systems on a\ncollection of documents whereas from our point of view, this aspect is crucial for such a\nsystem. Our first test shows that GATE is not suited to process large collections of documents.\nGATE has been designed as a powerful environment for conception and development of NLP\napplications in information extraction. Scalability is not central in its design, and information\nextraction deals with small sets of documents. However, we have observed that problems\nappear on small sets of documents. We choose to propose a platform able to analyze large\namounts of documents, and focus on the efficiency of the processing.\n3. A modular and tunable platform\nIn the development of Ogmios, we focused on tool integration. Our initial goal was to exploit\nexisting NLP tools rather than developing new ones3 but integrating heterogeneous tools and\nnevertheless achieve good performance in document annotation was challenging. Ogmios\nplatform was designed to test various combinations of annotations in order to identify which\n1\n\nhttp://deri.ie/projects/swan\nhttp://sekt.semanticweb.org\n3\nWe developed NLP systems only when no other solution was available. We preferably chose GPL or free licence software\nwhen possible.\n2\n\n\fones have a significant impact on information retrieval, information extraction or even\nextraction rule learning. In that respect, the platform can be viewed as a modular software\narchitecture that can be configured to achieve various tasks.\n3.1. Specific constraints\nThe reuse of NLP tools imposes specific constraints regarding software engineering and\nprocessing domain-specific documents requires tuning resources to better fit the data.\nFrom the software engineering point of view, the constraints mainly concern the input/output\nformats of the integrated NLP tools. Each tool has its own input and output format. Linking\ntogether several tools requires defining an interchange format. This engineering point of view\nis important for testing various combinations of annotations. The second type of constraints is\nthe cost linguistic analysis in terms of processing time. The main pitfall is the deep syntactic\ndependency parsing which is time consuming) and which lead us to design a distributed\narchitecture.\nA domain specific annotation platform also requires lexical and ontological resources or the\ntuning of NLP tools such as the Part-of-Speech tagger or parser. For instance, we have argued\nin (Alphonse et al., 2004) that identification of gene interaction requires gene name tagging,\nwhich relates to traditional named entity recognition, term recognition and a reliable syntactic\nanalysis.\n3.2. General architecture\nThe different processing steps are traditionally separated in modules (Bontcheva et al., 2004).\nEach module carries out a specific processing step: named entity recognition, word\nsegmentation, POS tagging, parsing, semantic tagging or anaphora resolution. It wraps an\nNLP tool to ensure the conformity of the input/output format with the DTD. Annotations are\nrecorded in an XML stand-off format to deal with the heterogeneity of NLP tools input/output\n(the DTD is fully described in (Nazarenko et al., 2006)). The modularity of the architecture\nsimplifies the substitution of a tool by another.\nTuning to a specific field is insured by the exploitation of specialized resources by each\nmodule. For instance, a targeted species or gene list can be added to the biology-specific\nnamed entity recognizer to process Medline abstracts. In the ALVIS project, the problem of\nacquiring automatically these specialized resources from a training corpus is also addressed\n(see Figure 1 and (Alphonse et al., 2004)) but this question falls out of the scope of the\npresent paper.\nFigure 2 gives an overview of the architecture. The various modules composing the NLP line\nare represented as boxes. The description of these modules is given in section 4. The arrows\nrepresent the data processing flow. Intermediary levels of annotations can be produced if the\ncomplete NLP line is not used. For instance, anaphora resolution is seldom activated.\n\n\fFigure 2: Ogmios architecture\nWe assume that input web documents are already downloaded, cleaned, encoded into the\nUTF-8 character set, and formatted in XML (Nazarenko et al., 2006). Documents are first\ntokenized to define offsets to ensure the homogeneity of the various annotations. Then,\ndocuments are processed through several modules: named entity recognition, word and\nsentence segmentation, lemmatization, part-of-speech tagging, term tagging, parsing,\nsemantic tagging and anaphora resolution.\nAlthough this architecture is quite traditional, few points should be highlighted:\n\u2022 Tokenization computes a first basic non-linguistic segmentation of the document,\nwhich is used for further reference. The tokens are the basic textual units in the text\nprocessing line. Tokenization serves no other purpose but to provide a starting point\nfor segmentation. This level of annotation follows the recommendations of the\nTC37SC4/TEI workgroup, even if we refer to the character offset rather than pointer\nmark-up (TEI element ptr) in the textual signal to mark the token boundaries. To\nsimplify further processing, we distinguish different types of tokens: alphabetical\ntokens, numerical tokens, separating tokens and symbolic tokens.\n\n\f\u2022 Named Entity tagging takes place very early in the NLP line because unrecognized\nnamed entities hinder most NLP steps, in many sublanguages;\n\u2022 Terminological tagging is used as such but is also considered as an aid for syntactic\nparsing. As this latter step is time consuming, we exploit the fact that terminological\nanalysis simplifies the parsing cost.\nFor each document, the NLP modules are called sequentially. The outputs of the modules are\nstored in memory until the end of the processing. XML output is recorded at the end of the\ndocument processing.\n4. Description of the NLP modules\nThis section describes the different NLP modules. Il also explains what is the expected impact\nof each linguistic annotation step on IR or IE performance.\nNamed Entity tagging\nThe Named Entity tagging module aims at annotating semantic units, with syntactic and\nsemantic types. Each text sequence corresponding to a named entity is tagged with a unique\ntag corresponding to its semantic value (for example a \"gene\" type for gene names, \"species\"\ntype for species names, etc.). We use the TagEN Named Entity tagger (Berroyer, 2004),\nwhich is based on a set of linguistic resources and grammars. Named entity tagging has a\ndirect impact on search performance when the query contains one or two named entities, as\nthose semantic units are have a high discriminative power.\nWord and sentence Segmentation\nThis module identifies sentence and word boundaries. We use simple regular expressions,\nbased on the algorithm proposed in (Grefenstette & Tapanainen, 1994). Part of the\nsegmentation has been implicitly performed during the Named Entity tagging to solve some\nambiguities such as the abbreviation dot in the sequence \"B. subtilis\", which could be\nunderstood as a full stop if it were not analyzed beforehand.\nMorpho-syntactic tagging\nThis module aims at associating a part of speech (POS) tag to each word. It assumes that the\nword and sentence segmentation has been performed. We are using a probabilistic\nPart-Of-Speech tagger: TreeTagger (Schmid, 1997). The POS tags are not used as such for IR\nbut POS tagging facilitates the rest of the linguistic processing.\nLemmatization\nThis module associates its lemma, i.e. its canonical form, to each word. The experiments\npresented in (Moreau, 2006) show that this morphological normalization increases the\nperformance of search engines. If the word cannot be lemmatized (for instance a number or a\nforeign word), the information is omitted. This module assumes that word segmentation and\nmorpho-syntactic information are provided. Even if it is a distinct module, we currently\nexploit the TreeTagger output which provides lemma as well as POS tags.\nTerminology tagging\nThis module aims at recognizing the domain specific phrases in a document, like gene\nexpression or spore coat cell. These phrases considered as the most relevant terminological\nitems. They can be provided through terminological resources such as the Gene Ontology\n(GOConsortium, 2001), the MeSH (MeSH) or more widely UMLS (UMLS). They can also be\nacquired through corpus analysis (see Figure 1). Providing a given terminology tunes the term\n\n\ftagging to the corresponding domain. Previous annotation levels as lemmatization and word\nsegmentation but also named entities are required. The goal in identifying domain specific\nphrases in the documents is the same as for the named entitiy recognition, i.e. to identify the\nrelevant semantic units. Even if previous experiments (see (Lewis, 1992) among others) have\nshown a little impact of the phrases on IR performance, we argue that terminology should\nhave a more significant impact on specialized search engines, as a terminology is relevant for\na specific domain. In addition to that, a normalization procedure can associate a canonical\nform to any phrase occurrence (e.g. gene expression, expression of gene, gene expressed...).\nThis normalization step is similar to the lemmatization one for words. Gathering associated\nvariants under a single form modifies the phrase frequencies and thus affects IR.\nParsing\nThe parsing module aims at exhibiting the graph of the syntactic dependency relations\nbetween the words of the sentence. Parsing is a time and resource-consuming NLP, especially\nwhen compared to other NLP tasks like named entity recognition or part-of-speech tagging.\nAs mentioned above, the syntactic analysis is especially important for the tasks that involve\nrelations between entities (either information extraction or relational queries such as X's\nspeeches as opposed to speeches on or relative to X). However, this technology is not yet fully\ncompatible with Information Retrieval or Extraction.\nEven if processing time is a critical point for syntactic parsing, we argue that it may enhance\nthe semantic access to web documents. On the one hand, it is usually not necessary to parse\nthe entire documents. A good filtering procedure may select the more relevant sections to\nparse. We still have to develop a method for pre-filtering the textual segments that are worth\nparsing as proposed in (N\u00e9dellec et al., 2001). On the other hand, as we will show in Section\n5, a good recognition of the terms can reduce significantly the number of possible parses and\nconsequently the parsing processing time.\nIn Ogmios, the word level of annotation is required in the parser input. Depending on the\nchoice of the parser, the morpho-syntactic level may be needed. The Link Grammar Parser\n(Sleator & Temperley, 1993) is integrated.\nSemantic type tagging and anaphora resolution\nThe last modules are currently under test and should be integrated in the next release of the\nplatform. The semantic type tagging associates to the previously identified semantic units tags\nreferring to ontological concepts. This allows a semantic querying of the document base.\nThe anaphora resolution module establishes coreference links between the anaphoric pronoun\noccurrences and the antecedents they refer to. Even if solving anaphora has a small impact on\nthe frequency counts and therefore on IE, it increases IE recall: for instance it inhibits Y may\nstand for X inhibits Y and must be interpreted as such in a extraction engine dealing with gene\ninteractions.\n5. Performance analysis\nWe carried out an experiment on a collection of 55,329 web documents from the biological\ndomain. All the documents went through all NLP modules, up to the term tagging (as\nmentioned before, the goal is not to parse the whole documents but only some filtered part of\nthem). A 400,000 named entity list, including species and gene names, and a 375,000 term list,\nissued from the MeSH and Gene Ontology have been used.\n\n\fFigure 3 shows the distribution of the input document size (both axes are on a log scale). Most\ndocuments have an XML size between 1KB and 100KB. The size of the biggest document is\nabout 5.7 MB.\n\nFigure 3. Distribution of document size\nWe used 20 machines to annotate these documents. Most of these machines were standard\nPersonal Computers with 1GB of RAM and 2.9 or 3.1 GHz processor. We also used a\ncomputer with 8GB of RAM and two 2.8GHz Xeon (dual-core) processors. Their operating\nsystem were either Debian Linux or Mandrake Linux. The server and three NLP clients were\nrunning on the 8GB/biprocessor. Only one NLP client was running on each standard Personal\nComputer.\nEven if a real benchmark requires several tests to evaluate the performance, we consider this\nperformance as an interesting indication of the platform processing time. Timers are run\nbetween each function call in order to measure how long each step is (user-time-wise). We\nused the functions provided in the Time::Hires Perl package. All the time results are\nrecorded in the annotated XML documents.\n\nTokens\nNamed entities\nWords\nSentences\nPart-of-speech tags and lemma\nTerms\n\nAverage number of units\nby document\n5,021.9\n81.88\n1,912.65\n85.41\n1883.5\n250.76\n\nTotal number of units in the\ndocument collection\n277,846,470\n4,530,368\n105,821,243\n4,726,003\n104,208,536\n13,874,089\n\nTable 3: Average and total numbers of linguistic units.\nThe annotation of the documents was completed in 35 hours. Table 3 shows the total number\nof entities found in the document collection. 106 million words and 4.72 million sentences\n\n\fwere processed; 4.53 million named entities and 13.9 million domain specific phrases were\nidentified. Each document contains, on average, 1,913 words, 85 sentences, 82 named entities\nand 251 domain specific phrases. 147 documents contained no words at all; they therefore\nunderwent the tokenization step only. One of our NLP clients processed a 414,995 word\ndocument.\nTable 4 shows the average processing time for each document. Each document has been\nprocessed in 37 seconds. Due to the exploited resource, the most time-consuming steps are the\nterm tagging (56% of the overall processing time) and the named entity recognition (16% of\nthe overall processing time).\n\nloading XML input doc.\ntokenization\nnamed entity recognition\nword segmentation\nsentence segmentation\npart-of-speech tagging and lemmatization\nterm tagging\nrendering XML output doc.\nTotal\n\nAverage time processing\n0.38\n0.7\n6.12\n5.19\n0.18\n1.84\n20.83\n2.03\n37,27\n\nPercentage\n1.02\n1.88\n16.42\n13.92\n0.48\n4.94\n55.89\n5.45\n100\n\nTable 4: Average time for one document processing (in seconds).\nThe whole document collection, except two documents, has been analysed. Thanks to the\ndistribution of the processing, the problems occuring on a specific document had no\nconsequence on the whole process. Clients in charge of the analysis of these documents have\nbeen simply restarted.\nThe performance we get on this collection show the robustness of the NLP platform, and its\nability to analyse large and heterogeneous collection of documents in a reasonable time. We\nhave proven the efficiency of the overall process for semantic crawlers and its accuracy for a\nprecise indexing of web documents.\n6. Tuning a syntactic analyzer to the biological domain\nThis section presents our strategy to tune NLP tools to a given specialized domain. We take\nthe parser as an example as its adaptation is the richest and the most complex one.\nIn order to extract structured pieces of information from texts, one needs to link isolated\nchunks of texts together. Most of the time, chunks of texts correspond to named entities and\nrelations are expressed through verbs or predicative nouns. We thus need a reliable and\nprecise analysis of syntactic relations between phrases. For those reasons, we chose to\nintegrate a symbolic dependency-based parser seemed (in contrast with a constituent-based\nparser).\nInstead of redeveloping new parsers for each sublanguage, we try to define a method for\nadapting a general parser to a specific sublanguage. This section presents a strategy to adapt\nthe Link Parser (LP) (Sleator & Temerley, 1993) to parse Medline abstracts dealing with\ngenomics. More details are given in (Aubin et al., 2005).\n\n\f6.1. The initial parser choice\nLP presents several advantages among which the robustness, the good quality of the parsing,\nthe underlying dependency formalism and the declarative format of its lexicon.\nIn order to test various parsers, a corpus has been built from Medline4 abstracts (in English)\ndealing with transcription in Bacillus subtilis (Aubin et al., 2005), named henceforth\nMED-TEST corpus. Our test corpus contains 212 randomly selected sentences (5,992 words),\nwhich contain an average of 25.4 words (from 8 to 59). Despite its relatively small size, this\ncorpus is a good sample of the sublanguage of genomics. Medline abstracts present the\nfollowing characteristics: they are made of long and syntactically complex sentences,\nspecialized vocabulary, scientific notations and numerous non grammatical constructions.\nFrom the results of the evaluation that we did on different parsers, it turned out that\ndependency-based parsers have better results on long and complex sentences, particularly\nwith coordination. For example, LP seems to offer better performance than a\nconstituent-based parser applied on Medline abstracts (see (Grover, 2004) for an experiment\nusing a GPSG parser). This conclusion is shared by (Ding, 2003) who also worked on the\nsame kind of corpus. Other experiments have also shown that the parser performance varies\nfrom one corpus to another. In the context of the ExtrAns project, (Molla et al., 2000) showed\nthat 76% of 2,781 sentences from a Unix manpage corpus were completely parsed by LP\nindependently to the parsing quality, while we reach only 54% on the biological corpus.\nWhen looking at the quality of the parses, we noticed different kinds of errors depending\neither on the biological domain or on more general linguistic difficulties like ambiguous\nconstructions. We propose three solutions to address these issues: text normalization,\nterminology analysis and lexicon/grammar adaptation.\n6.2. Diagnosis and adaptation\nOur analysis of the performance of the Link grammar on the biological corpus confirms\nprevious works. The main problems can be classified along the following axes.\nTextual noise\nScientific texts present particularities that we chose to handle in a normalization step prior to\nthe parsing. First, the segmentation in sentences and words was taken off from the parser and\nenriched with named entities recognition and rules specific to the biological domain. We also\ndelete some extra-textual information that alters parsing quality (such as citations, for\ninstance).\nUnknown words\nIn a corpus made of full Medline abstracts, we identified 6,005 out-of-lexicon forms (45,804\noccurrences) among 12,584 distinct words, i.e. 47.72%. They are mostly latin words, numbers,\nDNA sequences, gene names, misspellings and technical lexicon.\nHowever, LP includes a module that can assign a syntactic category to an unknown word. It is\nbased on the word suffix. Modifying the morpho-guessing (MG) module seemed a better\nstrategy than extending the dictionary since biological objects differ from an organism to\nanother (Grover (2004) also reports a similar process). We then created 19 new MG classes\nfor nouns (\u2013ase, -ity, etc.) and adjectives (\u2013al, -ous, etc.) along with their rule. At the same\n\n4\n\nhttp://www.ncbi.nlm.nih.gov/entrez/query.fcgi.\n\n\ftime, we added about 500 words of the biological domain to the LP lexicon in different\nclasses, mainly nouns, adjectives and verbs.\nSpecific constructions\nSome words already defined in the LP lexicon present a specific usage in biological texts,\nwhich implied some modifications including moving words from one class to another and\nadapting or creating rules.\nThe main motivation for moving words from one class to another is that the abstracts are\nwritten by non-native English speakers. This point was also raised by (Pyysalo et al., 2004).\nOne way to allow the parsing of such ungrammatical sentences is to relax constraints by\nmoving some words from the countable to the mass-countable class for instance. Some very\nfrequent words present idiosyncratic uses (particular valency of verbs for instance), which\ninduced the modification or creation of rules. Numbers and measure units are omnipresent in\nthe corpus and were not necessarily well described or even present in the lexicon/grammar.\nStructural ambiguity\nWe identified two cases of ambiguity that can be partially resolved by exploiting\nterminological information.\nPrepositional attachment is a tricky point that is often fixed using statistical information from\nthe text itself (Hindle & Rooth, 1993), a larger corpus (Bourigault & Fr\u00e9rot, 2004), the web\n(Volk, 2002) or external resources such as WordNet (Stetina & Nagao, 1997).\nThe second major ambiguity factor is the attachment of series of more than two nouns. like in\ntwo-component signal transduction systems. We noticed that such cases often appear inside\nlarger nominal phrases often corresponding to domain specific terms. For this reason, we\ndecided to identify terms in a pre-processing step and to reduce them to their syntactic head. If\nneeded, the internal analysis of terms is added to the parsing result for the simplified sentence.\nThe strategy proposed by (Sutcliffe et al., 1995) that consists in the linkage of the words\ncontained in a compound (for instance sporulation_process) was excluded, as it increases the\nlexicon size augment without reducing the parsing complexity.\nBefore practically integrating the use of terminology in our processing suite, we made a\nsimulation of this simplification of terms.\n6.3. Evaluation\nWe performed a two-stage evaluation of the modifications in order to measure the respective\ncontribution of the LP adaptation on the one hand and of the term simplification on the other\nhand.\nCorpus and criteria\nWe used a subset (10 files5) of the MED-TEST corpus but, contrary to the first evaluation\ndesigned for choosing a parser, we wanted to measure the quality of the whole parse and not\nonly of specific relations.\nTable 1 (for the MED-TEST subset) shows the way that out-of-lexicon words (OoL), i.e.\nunknown (UW) and guessed (GW) words, are handled by giving the percentage of incorrect\n5\n\n141 sentences, 2,630 words.\n\n\fmorpho-syntactic category assignments with the original resources (lp), those adapted to\nbiology (lp-bio) and finally the latter associated with the simplification of terms (lp-bio-t).\n\nUW\nGW\nOoL\n\na\n244\n24\n268\n\nlp\n\nb\n41.1%\n4.2%\n38%\n\na\n53\n72\n125\n\nLp-bio\n\nB\n52.8%\n0%\n22.4%\n\na\n26\n31\n57\n\nlp-bio-t\n\nb\n19.2%\n0%\n8.8%\n\nTable 1: Incorrect MS category assignments\n(a : total MS assignments ; b% : incorrect assignments).\nIn Table 2, five criteria inform on the parsing time and quality for each sentence : the number\nof linkages (NbL), the parsing time (PT) in seconds, the fact that a complete linkage is found\nor not (CLF), the number of erroneous links (EL) and the quality of the constituency parse\n(CQ). NbW is the average number of words in a sentence which varies with term\nsimplification. The results are given for each one of the three versions of the parser.\nCrit.\nNbW\nNbL\nPT\nCLF\nEL\nCQ\n\nlp\nAvg\n24.05\n190,306\n37.83\n0.54\n2.87\n0.54\n\nLp-bio\nAvg\n%/lp\n24.05\n100%\n232,622\n122,2%\n29.4\n77.7%\n0.72\n133%\n1.91\n66.5%\n0.7\n129.6%\n\nAvg\n18.9\n1,431\n0.53\n0.77\n1.15\n0.8\n\nlp-bio-t\n\n%/lp\n78.6%\n0.75%\n1.4%\n142.6%\n40.1%\n148.1%\n\nTable 2: Parsing time and quality.\nUW, GW, NbL, PT and CLF are objective data while EL and CQ necessitate linguistic\nexpertise. The CQ evaluation consisted in the assignment of a general quality score to the\nsentence.\nResults and comments\nThe extension of the MG module reduced the number of erroneous morpho-syntactic category\nassignments (see Table 1) from 38% to 22.4%. 61% of the sentences where one or more\nassignment error was corrected by the MG module actually have better parsing results (15%\nhave been degraded). More generally, guessing more forms makes category assignment more\nreliable.\nThe extension of the lexicon discharged the two modules from 143 assignments out of 268\n(50 of which were wrong). 64% of the sentences where one or more assignment error was\ncorrected by the extension of lexicon have better parsing results (18% of the sentences were\ndegraded).\nThe effect of rule modification and creation is difficult to evaluate precisely though it actually\nimproves the parsing, especially by relaxing the constraints on determiners and inserts.\nThe most obvious contribution to the better parsing quality is the one of term simplification.\nThe drastic reduction in parsing time and number of linkages gives an idea of the reduction of\ncomplexity. It is not only due to the smaller number of words since the number of erroneous\nlinks is reduced by 60% while the number of words is reduced by only 21.4%. This confirms\n\n\fprevious similar studies that showed a reduction of 40% of the error rate on the main syntactic\nrelations with a French corpus.\nThe remaining errors are due to four different phenomena. First, the normalization step, prior\nto parsing, needs to be enhanced. Concerning LP, there are still lexicon gaps, wrong class\nassignments and a still unsatisfactory handling of numerical expressions. In addition, and like\n(Sutcliffe et al., 1995), we identified a weakness of LP regarding coordination. A specific\nstudy of the coordination system in LP and in the biological texts may be necessary. Finally,\nsome ambiguous nominal and prepositional attachments still remain in spite of term\nsimplification. These may be resolved in a post-processing step like in ExtrAns that uses a\ncorpus based approach to retrieve the correct attachment from the different linkages given by\nLP for a sentence.\nThus, the parser adaptation relies on three methods: the exploitation of a small base of\nmorphological rules, the modification of the grammar, and an adequate integration that relieve\nthe parser from all what do not directly deal with structural ambiguity (POS and term tagging,\nespecially).\n7. Conclusion\nWe have presented in this paper a platform that has been designed to enrich specialized\ndomain documents with linguistic annotations. While developments and experiments have\nbeen performed on biomedical texts, we assume that this architecture is generic enough to\nprocess other specialized documents. The platform is designed as a framework using existing\nNLP tools which can be substituted by others if necessary. Several NLP modules have been\nintegrated: named entity tagging, word and sentence segmentation, POS tagging,\nlemmatization, term tagging, and syntactic parsing. Semantic type tagging and anaphora\nresolution are currently being under stress.\nWe also focused on the system performance, since this point is crucial for most Internet\napplications. We have experimented a distributed design of the platform, by splitting the\ncorpus in equal parts: this strategy dramatically increased the overall performance (see\n(Ravichandran et al., 2004). We have also shown that Ogmios is a robust NLP platform with\nrespect to the high heterogeneity of the document sizes and types.\nThese first experiments show that a deep analysis of web documents is possible. Besides the\nnecessary improvement the Ogmios platform, our next goal is to assess the impact of NLP on\nIR performance. Our hypothesis is that this impact should be higher in the case of a\nspecialized search engines than for a generic IR framework, on which the IR-NLP\ncooperation has mainly been tested until now. Specific experiments are currently carried out\nin the ALVIS project to test the potential resulting enhanced functionalities on a\nmicrobiological search engine.\nAcknowledgements\nThis work is supported by the EU 6th Framework Program in the IST Priority under the\nALVIS project. The material benefits from interactions with the ALVIS partners, especially\nwith INRA-MIG.\nReferences\nAlphonse, E., Aubin, S., Bessieres, P., Bisson, G., Hamon, T., Laguarrigue, S., Manine, A.P.,\nNazarenko, A., Nedellec, C., Vetah, M.O.A., Poibeau, T., Weissenbacher, D.: Event-based\n\n\finformation extraction for the biomedical domain: the CADERIGE project. In: Workshop\nBioNLP (Biology and Natural language Processing), Conference Computational Linguistics\n(Coling 2004), Geneva (2004)\nAubin, S., Nazarenko, A., N\u00e9dellec, C.: Adapting a General Parser to a Sublanguage. In:\nProceedings of the International Conference on Recent Advances in Natural Language\nProcessing (RANLP'05), Borovets, Bulgaria (2005) 89\u201393\nBerroyer, J.F., Poibeau, T.: TagEN, un analyseur d'entit\u00e9es nomm\u00e9es. LIPN Internal Report,\nUniversit\u00e9 Paris-Nord (2004)\nBontcheva, K., Tablan, V., Maynard, D., Cunningham, H.: Evolving GATE to meet new\nchallenges in language engineering. Natural Language Engineering 10 (2004) 349\u2013374\nBourigault, D., Fr \u0301erot, C.: Ambigu\u00eft\u00e9 de rattachement pr\u00e9positionnel : introduction de\nressources exog\u00e8nes de sous-cat\u00e9gorisation dans un analyseur syntaxique de corpus\nendog\u00e8ne. In: Actes des 11mes journ\u00e9es sur le Traitement Automatique des Langues\nNaturelles, F`es, Maroc. (2004)\nConsortium, T.G.O.: Creating the Gene Ontology Resource: Design and Implementation.\nGenome Res. 11 (2001) 1425\u20131433\nCunningham, H., Bontcheva, K., Tablan, V., Wilks, Y.: Software infrastructure for language\nresources: a taxonomy of previous work and a requirements analysis. In: Proceedings of the\n2nd International Conference on Language Resources and Evaluation (LREC-2), Athens\n(2000)\nDing, J., Berleant, D., Xu, J., Fulmer, A.W.: Extracting Biochemical Interactions from\nMEDLINE Using a Link Grammar Parser. In: 15th IEEE International Conference on Tools\nwith Artificial Intelligence (ICTAI'03). (2003) 467\u2013471\nFerrucci, D., Lally, A.: UIMA: an architecture approach to unstructured information\nprocessing in a corporate research environment. Natural Language Engineering 10 (2004)\n327\u2013348\nGrefenstette, G., Tapanainen P.: What is a word, what is a sentence? Problems of tokenization.\nIn: Proceedings of the 3rd International Conference on Computational Lexicography.\n(1994) 79\u201387\nGrishman, R.: Tipster architecture design document version 2.3. Technical report, DARPA\n(1997)\nGrover, C., Lapata, M., Lascarides, A.: A Comparison of Parsing Technologies for the\nBiomedical Domain. Journal of Natural Language Engineering (2004)\nHindle, D., Rooth, M.: Structural Ambiguity and Lexical Relations. In: Meeting of the\nAssociation for Computational Linguistics. (1993) 229\u2013236\nLewis D.D.: An Evaluation of Phrasal and Clustered\nRepresentations on a Text\nCategorization Task. In proceedings of the 13th Annual International ACM SIGIR\nConference on Research and Development in Information Retrieval, Copenhaguen,\nDenmark, 1992.\nMeSH: Medical subject headings. WWW page http://www.nlm.nih.gov/mesh/\nmeshhome.html, Library of Medicine, Bethesda, Maryland (1998)\nMolla, D., Schneider, G., Schwitter, R., Hess, M.: Answer Extraction Using a Dependency\nGrammar in ExtrAns. Traitement Automatique de Langues, Special Issue on Dependency\nGrammars (2000) 145\u2013178\nMoreau F. Revisiter le couplage traitement automatique des langues et recherch\u00e9\nd'information. Th\u00e8se d'informatique de l'Universit\u00e9 de Rennes 1, d\u00e9c. 2006.\nMuller, H.M., Kenny, E.E., Sternberg, P.W.: Textpresso: an ontology-based information\nretrieval and extraction system for biological literature. PLoS Biology 2 (2004) 1984\u20131998\nNational Library of Medicine, ed.: UMLS Knowledge Source. 13 th edn. (2003)\nNazarenko A., Alphonse E., Derivi\u00e8re J., Hamon T., Vauvert G., Weissenbacher D.: The\nALVIS Format for Linguistically Annotated Documents. Proceedings of the Language and\nRessources Evaluation Conference (LREC 2006), pp.1782-1786, Genoa, Italy, 24-25-26\nMay 2006.\nN\u00e9dellec C., Mould Abdel Vetah M., Bessi\u00e8res P. (2001): Sentence Filtering for Information\nExtraction in Genomics: A Classification Problem. In Proceedings of the International\nConference on Practical Knowledge Discovery in Databases (PKDD'2001), pp. 326\u2013338.\nSpringer Verlag, LNAI 2167, Freiburg.\nNeff, M.S., Byrd, R.J., Boguraev, B.K.: The talent system: Textract architecture and data\nmodel. Natural Language Engineering 10 (2004) 307\u2013326\nPopov, B., Kiryakov, A., Ognyanoff, D., Manov, D., Kirilov, A.: Kim \u2013 a semantic platform\nfor information extraction and retrieval. Natural Language Engineering 10 (2004) 375\u2013392\nPyysalo, S., Ginter, F., Pahikkala, T., Boberg, J., Jarvinen, J., Salakoski, T., Koivula, J.:\nAnalysis of link grammar on biomedical dependency corpus targeted at protein-protein\n\n\finteractions. In: Proceedings of the international Workshop on Natural Language\nProcessing in Biomedicine and its Applications (JNLPBA). (2004) 15\u201321\nSchmid, H.: Probabilistic part-of-speech tagging using decision trees. In Jones, D., Somers, H.,\neds.: New Methods in Language Processing Studies in Computational Linguistics. (1997)\nSleator, D., Temperley, D.: Parsing English with a Link Grammar. In: Third International\nWorkshop on Parsing Technologies. (1993)\nStetina, J., Nagao, M.: Corpus Based PP Attachment Ambiguity Resolution with a Semantic\nDictionary. In Zhou, J., Church, K.W., eds.: Proceedings of the Fifth Workshop on Very\nlarge Corpora, Beijing, China (1997) 66\u201380\nSutcliffe, R.F.E., Brehony, T., McElligott, A.: The Grammatical Analysis of Technical Texts\nusing a Link Parser. In: Second Conference of the Pacific Association for Computational\nLinguistics, PACLING'95. (19-22 April 1995)\nVolk, M.: Using the Web as Corpus for Linguistic Research. In Pajusalu, R., Hennoste, T.,\neds.: T\u00e4hendusep\u00fc\u00fcdja. Catcher of the Meaning. A Festschrift for Professor Haldur \u00d5im.\nPublications of the Department of General Linguistics 3. University of Tartu, Estonia (2002)\n\n\f"}