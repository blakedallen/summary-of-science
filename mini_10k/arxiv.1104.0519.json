{"id": "http://arxiv.org/abs/1104.0519v2", "guidislink": true, "updated": "2014-01-14T12:38:39Z", "updated_parsed": [2014, 1, 14, 12, 38, 39, 1, 14, 0], "published": "2011-04-04T10:17:40Z", "published_parsed": [2011, 4, 4, 10, 17, 40, 0, 94, 0], "title": "Explicit rates of approximation in the CLT for quadratic forms", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1104.4704%2C1104.4602%2C1104.1258%2C1104.1210%2C1104.1434%2C1104.2107%2C1104.3106%2C1104.1672%2C1104.4982%2C1104.0701%2C1104.3067%2C1104.0265%2C1104.0671%2C1104.0751%2C1104.2673%2C1104.4380%2C1104.2127%2C1104.1297%2C1104.0360%2C1104.1477%2C1104.0655%2C1104.1354%2C1104.5640%2C1104.1475%2C1104.2636%2C1104.3756%2C1104.1194%2C1104.0364%2C1104.5338%2C1104.1005%2C1104.4948%2C1104.0002%2C1104.3592%2C1104.3225%2C1104.1848%2C1104.0923%2C1104.0940%2C1104.2661%2C1104.3697%2C1104.0239%2C1104.2293%2C1104.0285%2C1104.0764%2C1104.1936%2C1104.4376%2C1104.0384%2C1104.4848%2C1104.4621%2C1104.2420%2C1104.5643%2C1104.3538%2C1104.4128%2C1104.4813%2C1104.1633%2C1104.1346%2C1104.0492%2C1104.2070%2C1104.3650%2C1104.3884%2C1104.3316%2C1104.1104%2C1104.3253%2C1104.2274%2C1104.1021%2C1104.3368%2C1104.4459%2C1104.5443%2C1104.1833%2C1104.5410%2C1104.4998%2C1104.4130%2C1104.2708%2C1104.2671%2C1104.2237%2C1104.1767%2C1104.4203%2C1104.1030%2C1104.1011%2C1104.3735%2C1104.3103%2C1104.4176%2C1104.1948%2C1104.3662%2C1104.2128%2C1104.2427%2C1104.1584%2C1104.0324%2C1104.0856%2C1104.3736%2C1104.5142%2C1104.3957%2C1104.5287%2C1104.3324%2C1104.0505%2C1104.1785%2C1104.3492%2C1104.3263%2C1104.5047%2C1104.1909%2C1104.0519%2C1104.3888&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Explicit rates of approximation in the CLT for quadratic forms"}, "summary": "Let $X,X_1,X_2,\\ldots$ be i.i.d. ${\\mathbb{R}}^d$-valued real random vectors.\nAssume that ${\\mathbf{E}X=0}$, $\\operatorname {cov}X=\\mathbb{C}$,\n$\\mathbf{E}\\Vert X\\Vert^2=\\sigma ^2$ and that $X$ is not concentrated in a\nproper subspace of $\\mathbb{R}^d$. Let $G$ be a mean zero Gaussian random\nvector with the same covariance operator as that of $X$. We study the\ndistributions of nondegenerate quadratic forms $\\mathbb{Q}[S_N]$ of the\nnormalized sums ${S_N=N^{-1/2}(X_1+\\cdots+X_N)}$ and show that, without any\nadditional conditions, \\[\\Delta_N\\stackrel{\\mathrm{def}}{=}\\sup_x\\bigl\n|\\mathbf{P}\\bigl\\{\\mathbb{Q}[S_N]\\leq\nx\\bigr\\}-\\mathbf{P}\\bigl\\{\\mathbb{Q}[G]\\leq\nx\\bigr\\}\\bigr|={\\mathcal{O}}\\bigl(N^{-1}\\bigr),\\] provided that $d\\geq5$ and\nthe fourth moment of $X$ exists. Furthermore, we provide explicit bounds of\norder ${\\mathcal{O}}(N^{-1})$ for $\\Delta_N$ for the rate of approximation by\nshort asymptotic expansions and for the concentration functions of the random\nvariables $\\mathbb{Q}[S_N+a]$, $a\\in{\\mathbb{R}}^d$. The order of the bound is\noptimal. It extends previous results of Bentkus and G\\\"{o}tze [Probab. Theory\nRelated Fields 109 (1997a) 367-416] (for ${d\\ge9}$) to the case $d\\ge5$, which\nis the smallest possible dimension for such a bound. Moreover, we show that, in\nthe finite dimensional case and for isometric $\\mathbb{Q}$, the implied\nconstant in ${\\mathcal{O}}(N^{-1})$ has the form $c_d\\sigma\n^d(\\det\\mathbb{C})^{-1/2}\\mathbf {E}\\|\\mathbb{C}^{-1/2}X\\|^4$ with some $c_d$\ndepending on $d$ only. This answers a long standing question about optimal\nrates in the central limit theorem for quadratic forms starting with a seminal\npaper by Ess\\'{e}en [Acta Math. 77 (1945) 1-125].", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1104.4704%2C1104.4602%2C1104.1258%2C1104.1210%2C1104.1434%2C1104.2107%2C1104.3106%2C1104.1672%2C1104.4982%2C1104.0701%2C1104.3067%2C1104.0265%2C1104.0671%2C1104.0751%2C1104.2673%2C1104.4380%2C1104.2127%2C1104.1297%2C1104.0360%2C1104.1477%2C1104.0655%2C1104.1354%2C1104.5640%2C1104.1475%2C1104.2636%2C1104.3756%2C1104.1194%2C1104.0364%2C1104.5338%2C1104.1005%2C1104.4948%2C1104.0002%2C1104.3592%2C1104.3225%2C1104.1848%2C1104.0923%2C1104.0940%2C1104.2661%2C1104.3697%2C1104.0239%2C1104.2293%2C1104.0285%2C1104.0764%2C1104.1936%2C1104.4376%2C1104.0384%2C1104.4848%2C1104.4621%2C1104.2420%2C1104.5643%2C1104.3538%2C1104.4128%2C1104.4813%2C1104.1633%2C1104.1346%2C1104.0492%2C1104.2070%2C1104.3650%2C1104.3884%2C1104.3316%2C1104.1104%2C1104.3253%2C1104.2274%2C1104.1021%2C1104.3368%2C1104.4459%2C1104.5443%2C1104.1833%2C1104.5410%2C1104.4998%2C1104.4130%2C1104.2708%2C1104.2671%2C1104.2237%2C1104.1767%2C1104.4203%2C1104.1030%2C1104.1011%2C1104.3735%2C1104.3103%2C1104.4176%2C1104.1948%2C1104.3662%2C1104.2128%2C1104.2427%2C1104.1584%2C1104.0324%2C1104.0856%2C1104.3736%2C1104.5142%2C1104.3957%2C1104.5287%2C1104.3324%2C1104.0505%2C1104.1785%2C1104.3492%2C1104.3263%2C1104.5047%2C1104.1909%2C1104.0519%2C1104.3888&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Let $X,X_1,X_2,\\ldots$ be i.i.d. ${\\mathbb{R}}^d$-valued real random vectors.\nAssume that ${\\mathbf{E}X=0}$, $\\operatorname {cov}X=\\mathbb{C}$,\n$\\mathbf{E}\\Vert X\\Vert^2=\\sigma ^2$ and that $X$ is not concentrated in a\nproper subspace of $\\mathbb{R}^d$. Let $G$ be a mean zero Gaussian random\nvector with the same covariance operator as that of $X$. We study the\ndistributions of nondegenerate quadratic forms $\\mathbb{Q}[S_N]$ of the\nnormalized sums ${S_N=N^{-1/2}(X_1+\\cdots+X_N)}$ and show that, without any\nadditional conditions, \\[\\Delta_N\\stackrel{\\mathrm{def}}{=}\\sup_x\\bigl\n|\\mathbf{P}\\bigl\\{\\mathbb{Q}[S_N]\\leq\nx\\bigr\\}-\\mathbf{P}\\bigl\\{\\mathbb{Q}[G]\\leq\nx\\bigr\\}\\bigr|={\\mathcal{O}}\\bigl(N^{-1}\\bigr),\\] provided that $d\\geq5$ and\nthe fourth moment of $X$ exists. Furthermore, we provide explicit bounds of\norder ${\\mathcal{O}}(N^{-1})$ for $\\Delta_N$ for the rate of approximation by\nshort asymptotic expansions and for the concentration functions of the random\nvariables $\\mathbb{Q}[S_N+a]$, $a\\in{\\mathbb{R}}^d$. The order of the bound is\noptimal. It extends previous results of Bentkus and G\\\"{o}tze [Probab. Theory\nRelated Fields 109 (1997a) 367-416] (for ${d\\ge9}$) to the case $d\\ge5$, which\nis the smallest possible dimension for such a bound. Moreover, we show that, in\nthe finite dimensional case and for isometric $\\mathbb{Q}$, the implied\nconstant in ${\\mathcal{O}}(N^{-1})$ has the form $c_d\\sigma\n^d(\\det\\mathbb{C})^{-1/2}\\mathbf {E}\\|\\mathbb{C}^{-1/2}X\\|^4$ with some $c_d$\ndepending on $d$ only. This answers a long standing question about optimal\nrates in the central limit theorem for quadratic forms starting with a seminal\npaper by Ess\\'{e}en [Acta Math. 77 (1945) 1-125]."}, "authors": ["Friedrich G\u00f6tze", "Andrei Yu. Zaitsev"], "author_detail": {"name": "Andrei Yu. Zaitsev"}, "author": "Andrei Yu. Zaitsev", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/13-AOP839", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1104.0519v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1104.0519v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in at http://dx.doi.org/10.1214/13-AOP839 the Annals of\n  Probability (http://www.imstat.org/aop/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.NT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1104.0519v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1104.0519v2", "journal_reference": "Annals of Probability 2014, Vol. 42, No. 1, 354-397", "doi": "10.1214/13-AOP839", "fulltext": "arXiv:1104.0519v2 [math.PR] 14 Jan 2014\n\nThe Annals of Probability\n2014, Vol. 42, No. 1, 354\u2013397\nDOI: 10.1214/13-AOP839\nc Institute of Mathematical Statistics, 2014\n\nEXPLICIT RATES OF APPROXIMATION IN THE CLT FOR\nQUADRATIC FORMS\nBy Friedrich G\u00f6tze1 and Andrei Yu. Zaitsev1,2\nUniversit\u00e4t Bielefeld and St. Petersburg Department of Steklov\nMathematical Institute\nLet X, X1 , X2 , . . . be i.i.d. Rd -valued real random vectors. Assume\nthat EX = 0, cov X = C, EkXk2 = \u03c3 2 and that X is not concentrated\nin a proper subspace of Rd . Let G be a mean zero Gaussian random\nvector with the same covariance operator as that of X. We study the\ndistributions of nondegenerate quadratic forms Q[SN ] of the normalized sums SN = N \u22121/2 (X1 + * * * + XN ) and show that, without any\nadditional conditions,\ndef\n\n\u2206N = sup|P{Q[SN ] \u2264 x} \u2212 P{Q[G] \u2264 x}| = O(N \u22121 ),\nx\n\nprovided that d \u2265 5 and the fourth moment of X exists. Furthermore,\nwe provide explicit bounds of order O(N \u22121 ) for \u2206N for the rate of\napproximation by short asymptotic expansions and for the concentration functions of the random variables Q[SN + a], a \u2208 Rd . The\norder of the bound is optimal. It extends previous results of Bentkus\nand G\u00f6tze [Probab. Theory Related Fields 109 (1997a) 367\u2013416] (for\nd \u2265 9) to the case d \u2265 5, which is the smallest possible dimension for\nsuch a bound. Moreover, we show that, in the finite dimensional case\nand for isometric Q, the implied constant in O(N \u22121 ) has the form\ncd \u03c3 d (det C)\u22121/2 EkC\u22121/2 Xk4 with some cd depending on d only. This\nanswers a long standing question about optimal rates in the central\nlimit theorem for quadratic forms starting with a seminal paper by\nEss\u00e9en [Acta Math. 77 (1945) 1\u2013125].\nReceived December 2011; revised February 2013.\nSupported by the SFB 701 in Bielefeld and by Grant RFBR-DFG 09-01-91331.\n2\nSupported by Grants NSh-1216.2012.01, RFBR 09-01-12180, 10-01-00242 and 11-0112104, by the Alexander von Humboldt Foundation and by a program of fundamental\nresearches of Russian Academy of Sciences \"Modern problems of fundamental mathematics.\"\nAMS 2000 subject classifications. Primary 60F05; secondary 62E20.\nKey words and phrases. Central Limit theorem, concentration functions, convergence\nrates, multidimensional spaces, quadratic forms, ellipsoids, hyperboloids, lattice point\nproblem, theta-series.\n1\n\nThis is an electronic reprint of the original article published by the\nInstitute of Mathematical Statistics in The Annals of Probability,\n2014, Vol. 42, No. 1, 354\u2013397. This reprint differs from the original in pagination\nand typographic detail.\n1\n\n\f2\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\n1. Introduction. Let Rd be the d-dimensional space of real vectors x =\n(x1 , . . . , xd ) with scalar product hx, yi = x1 y1 + * * * + xd yd and norm kxk =\nhx, xi1/2 . We also denote by R\u221e a separable Hilbert space consisting of all\nreal sequences x = (x1 , x2 , . . .) such that kxk2 = x21 + x22 + * * * < \u221e.\nLet X, X1 , X2 , . . . be a sequence of i.i.d. Rd -valued random vectors. Asdef\nsume that EX = 0 and \u03c3 2 = EkXk2 < \u221e. Let G be a mean zero Gaussian\nrandom vector such that its covariance operator C = cov G : Rd \u2192 Rd is equal\nto cov X. It is well known that the distributions L(SN ) of sums\ndef\n\nSN = N \u22121/2 (X1 + * * * + XN )\n\n(1.1)\n\nconverge weakly to L(G).\nLet Q : Rd \u2192 Rd be a linear symmetric bounded operator, and let Q[x] =\nhQx, xi be the corresponding quadratic form. We say that Q is nondegenerate if ker Q = {0}.\nDenote, for q > 0,\ndef\n\n\u03b2q = EkXkq ,\n\ndef\n\n\u03b2 = \u03b24 .\n\nIntroduce the distribution functions\n(1.2)\n\ndef\n\nF (x) = P{Q[SN ] \u2264 x},\n\ndef\n\nH(x) = P{Q[G] \u2264 x}.\n\nWrite\n(1.3)\n\ndef\n\n\u2206N = sup|F (x) \u2212 H(x)|.\nx\u2208R\n\nTheorem 1.1.\nor d = \u221e. Then\n\nAssume that Q and C are nondegenerate and that d \u2265 5\n\u2206N \u2264 c(Q, C)\u03b2/N.\n\nThe constant c(Q, C) in this bound depends on Q and C only.\nTheorem 1.2. Let the conditions of Theorem 1.1 be satisfied, and let\n5 \u2264 d < \u221e. Assume that the operator Q is isometric. Then\n\u2206N \u2264 cd \u03c3 d (det C)\u22121/2 EkC\u22121/2 Xk4 /N.\n\nThe constant cd in this bound depends on d only.\nTheorems 1.1 and 1.2 are simple consequences of the main result of this\npaper, Theorem 2.2; see also Theorem 2.1. Theorem 1.1 was proved in G\u00f6tze\nand Zaitsev (2008). It confirms a conjecture of Bentkus and G\u00f6tze (1997a)\n[below BG (1997a)]. It generalizes to the case d \u2265 5 the corresponding result\nof BG (1997a). In their Theorem 1.1, it was assumed that d \u2265 9, while our\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n3\n\nTheorem 1.1 is proved for d \u2265 5. Theorem 1.2 yields an explicit bound in\nterms of the distribution L(X).\nThe distribution function of kSN k2 (for bounded X with values in Rd )\nmay have jumps of order O(N \u22121 ), for all 1 \u2264 d \u2264 \u221e; see, for example, BG\n[(1997a), page 468]. Therefore, the bounds of Theorems 1.1 and 1.2 are\noptimal with respect to the order in N .\nTheorems 1.1, 1.2 and the method of their proof are closely related to\nthe lattice point problem in number theory. Suppose that d < \u221e and that\nhQx, xi > 0, for x 6= 0. Let volEr be the volume of the ellipsoid\nEr = {x \u2208 Rd : Q[x] \u2264 r 2 }\n\nfor r \u2265 0.\n\nWrite volZ Er for the number of points in Er \u2229 Zd , where Zd \u2282 Rd is the\nstandard lattice of points with integer coordinates.\nThe following result due to G\u00f6tze (2004) is related to Theorems 1.1 and\n1.2; see also BG (1995a, 1997b).\nTheorem 1.3.\nsup\na\u2208Rd\n\nFor all dimensions d \u2265 5,\n\nvolZ (Er + a) \u2212 volEr\n= O(r \u22122 )\nvolEr\n\nfor r \u2265 1,\n\nwhere the constant in O(r \u22122 ) depends on the dimension d and on the lengths\nof axes of the ellipsoid E1 only.\nTheorem 1.3 solves the lattice point problem for d \u2265 5. It improves the\nclassical estimate O(r \u22122d/(d+1) ) due to Landau (1915), just as Theorem 1.1\nimproves the bound O(N \u2212d/(d+1) ) by Ess\u00e9en (1945) in the CLT for ellipsoids\nwith axes parallel to coordinate axes. A related result for indefinite forms\nmay be found in G\u00f6tze and Margulis (2010).\nWork on the estimation of the rate of approximation under the conditions of Theorem 1.1 for Hilbert spaces started in the second half of the\nlast century. See Zalesski\u0131\u0306, Sazonov and Ulyanov (1988) and Nagaev (1989)\nfor optimal bounds of order O(N \u22121/2 ) (with respect to eigenvalues of C)\nassuming finiteness of the third moment. For a more detailed discussion see\nYurinskii (1982), Zalesski\u0131\u0306, Sazonov and Ulyanov (1991), Bentkus, G\u00f6tze,\nPaulauskas and Ra\u010dkauskas (1991), BG (1995b, 1996, 1997a) and Senatov\n(1997, 1998).\nUnder some more restrictive moment and dimension conditions the estimate of order O(N \u22121+\u03b5 ), with \u03b5 \u2193 0 as d \u2191 \u221e, was obtained by G\u00f6tze (1979).\nThe proof in G\u00f6tze (1979) was based on a new symmetrization inequality\nfor characteristic functions of quadratic forms. This inequality is related to\nWeyl's (1916) inequality for trigonometric sums. This inequality and its extensions (see Lemma 6.1) play a crucial role in the proofs of bounds in the\n\n\f4\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nCLT for ellipsoids and hyperboloids in finite and infinite dimensional cases.\nUnder some additional smoothness assumptions, error bounds O(N \u22121 ) (and,\nmoreover, Edgeworth type expansions) were obtained in G\u00f6tze (1979), Bentkus (1984), Bentkus, G\u00f6tze and Zitikis (1993). BG (1995b, 1996, 1997a) established the bound of order O(N \u22121 ) without smoothness-type conditions.\nSimilar bounds for the rate of infinitely divisible approximations were obtained by Bentkus, G\u00f6tze and Zaitsev (1997). Among recent publications, we\nshould mention the papers of Nagaev and Chebotarev (1999, 2005) (d \u2265 13,\nproviding a more precise dependence of constants on the eigenvalues of C)\nand Bogatyrev, G\u00f6tze and Ulyanov (2006) (nonuniform bounds for d \u2265 12);\nsee also G\u00f6tze and Ulyanov (2000). The proofs of bounds of order O(N \u22121 )\nare based on discretization (i.e., a reduction to lattice valued random vectors) and the symmetrization techniques mentioned above.\nAssuming the matrices Q and C to be diagonal, and the independence of\nthe first five coordinates of X, BG (1996) have already reduced the dimension requirement for the bound O(N \u22121 ) to d \u2265 5. The independence assumption in BG (1996) allowed to apply an adaption of the Hardy\u2013Littlewood\ncircle method. For the general case considered in Theorem 1.1, one needs\nto develop new techniques. Some yet unpublished results of G\u00f6tze (1994)\nprovide the rate O(N \u22121 ) for sums of two independent arbitrary quadratic\nforms (each of rank d \u2265 3). G\u00f6tze and Ulyanov (2003) obtained bounds of\norder O(N \u22121 ) for some ellipsoids in Rd with d \u2265 5 in the case of lattice\ndistributions of X.\nThe optimal possible dimension condition for this rate is just d \u2265 5, due\nto the lower bounds of order O(N \u22121 log N ) for dimension d = 4 in the corresponding lattice point problem. The question about precise convergence\nrates in dimensions 2 \u2264 d \u2264 4 still remains completely open (even in the simplest case where Q is the identity operator Id , and for random vectors with\nindependent Rademacher coordinates). It should be mentioned that, in the\ncase d = 2, a precise convergence rate would imply a solution of the famous\ncircle problem. Known lower bounds in the circle problem correspond to the\nbound of order O(N \u22123/4 log\u03b4 N ), \u03b4 > 0, for \u2206N . Hardy (1916) conjectured\nthat up to logarithmic factors this is the optimal order.\nNow we describe the most important elements of the proof. We have to\nmention that a big part of the proof repeats the arguments of BG (1997a);\nsee BG (1997a) for the description and application of symmetrization inequality and discretization procedure. In our proof we do not use the multiplicative inequalities of BG (1997a). Here we replace those techniques by\narguments from the geometry of numbers, developed in G\u00f6tze (2004), combined with effective equidistribution results by G\u00f6tze and Margulis (2010)\nfor suitable actions of unipotent subgroups of SL(2, R); see Lemma 8.2. These\nnew techniques (compared to previous results) are mainly concentrated in\nSections 5\u20138.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n5\n\nUsing the Fourier inversion formula [see (4.2) and (4.3)], we have to estimate some integrals of the absolute values of differences of characteristic\nfunctions of quadratic forms. In Section 6, we reduce the estimation of characteristic functions to the estimation of a theta-series; see Lemma 6.5 and\ninequality (6.28). To this end, we write the expectation with respect to\nRademacher random variables as a sum with binomial weights p(m) and\np(m). Then we estimate p(m) and p(m) from above by discrete Gaussian\nexponential weights cs q(m) and cs q(m); see (6.16), (6.19), (6.21) and (6.22).\nTogether with the nonnegativity of some characteristic functions [see (6.20)\nand (6.24)], this allows us to apply then the Poisson summation formula from\nLemma 6.4. This formula reduces the problem to an estimation of integrals\nof theta-series. Section 7 is devoted to some facts from number theory. We\nconsider the lattices, their \u03b1-characteristics [which are defined in (7.5) and\n(7.6)] and Minkowski's successive minima. In Section 8, we reduce the estimation of integrals of theta-series to some integrals of \u03b1-characteristics. An\napplication of the crucial Lemma 8.2, mentioned above, ends the proof.\n2. Results. To formulate the results we need more notation repeating\nmost part of the notation used in BG (1997a). Let \u03c312 \u2265 \u03c322 \u2265 * * * be the\neigenvalues of C, counting their multiplicities. We have \u03c3 2 = \u03c312 + \u03c322 + * * *.\nWe identify the linear operators and corresponding matrices. By Id : Rd \u2192\nd\nR we denote the identity operator and, simultaneously, the diagonal matrix\nwith entries 1 on the diagonal. By Od we denote the (d \u00d7 d) matrix with\nzero entries.\nThroughout S = {e1 , . . . , es } \u2282 Rd denotes a finite set of cardinality s. We\nwrite So instead of S if the system {e1 , . . . , es } is orthonormal. Let p > 0\nand \u03b4 \u2265 0. Denote\n(2.1)\n\nP (\u03b4, S, Y ) = min P{kY \u2212 ek \u2264 \u03b4}.\ne\u2208S\n\nSimilarly to BG (1997a), we use the following nondegeneracy condition for\nthe distribution of a d-dimensional vector Y :\n(2.2)\n\ndef\n\nPQ (\u03b4, S, Y ) = min{P (\u03b4, S, Y ), P (\u03b4, QS, Y )} \u2265 p,\n\nwhere p > 0 is a parameter involved in the condition. Note that\n(2.3)\n\nP (\u03b4, S, Y ) = PId (\u03b4, S, Y ).\n\nIntroduce truncated random vectors\n\u221a\n\u221a\n(2.4) X \u22c4 = XI{kXk \u2264 \u03c3 N },\nX\u22c4 = XI{kXk > \u03c3 N },\n\u221a\n\u221a\n(2.5) X \u0003 = XI{kC\u22121/2 Xk \u2264 dN },\nX\u0003 = XI{kC\u22121/2 Xk > dN },\n\n\f6\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nand their moments (for q > 0)\n(2.6)\n\n\u039b\u22c44 =\n\n(2.7)\n\n\u039b\u00034 =\n\n1\n\u03c34 N\n1\nd2 N\n\nEkX \u22c4 k4 ,\n\n\u03a0\u22c4q =\n\nEkC\u22121/2 X \u0003 k4 ,\n\nN\n\u221a\nEkX\u22c4 kq ,\nq\n(\u03c3 N )\nN\n\u03a0\u0003q = \u221a\nEkC\u22121/2 X\u0003 kq .\nq\n( dN )\n\nHere and below I{A} denotes the indicator of an event A. Of course, definitions (2.5) and (2.7) have sense if d < \u221e and the covariance operator C is\nnondegenerate.\nClearly, we have\n(2.8)\n\nX \u22c4 + X\u22c4 = X \u0003 + X\u0003 = X,\n\nkX \u22c4 kkX\u22c4 k = kX \u0003 kkX\u0003 k = 0.\n\nGenerally speaking, X \u0003 and X \u22c4 are different truncated vectors. In BG\n(1997a) the i.i.d. copies of the vectors X \u22c4 and X\u22c4 only were involved. Truncation (2.5) was there applied to the vector X \u22c4 . The use of X \u0003 is more\nnatural for the estimation of constants in the case d < \u221e. It is easy to see\nthat\n(2.9)\n\n(C\u22121/2 X)\u22c4 = (C\u22121/2 X)\u0003 = C\u22121/2 X \u0003\n\nand\n(2.10)\n\n(C\u22121/2 X)\u22c4 = (C\u22121/2 X)\u0003 = C\u22121/2 X\u0003 .\n\nEqualities (2.9) and (2.10) provide a possibility to apply auxiliary results\nobtained in BG (1997a) for truncated vectors X \u22c4 and X\u22c4 to truncated vectors C\u22121/2 X \u0003 and C\u22121/2 X\u0003 . However, one should take into account that \u03c3 2 ,\n\u039b\u22c44 , \u03a0\u22c4q , G, . . . have to be replaced by corresponding objects related to the\nvector C\u22121/2 X (i.e., by d, \u039b4\u0003 , \u03a0q\u0003 , C\u22121/2 G, . . .).\nBy c, c1 , c2 , . . . we denote absolute positive constants. If a constant depends on, say, s, then we point out the dependence writing cs or c(s). We\ndenote by c universal constants which might be different in different places of\nthe text. Furthermore, in the conditions of theorems and lemmas (see, e.g.,\nTheorem 2.1 and the proofs of Theorems 2.2, 2.4 and 2.5) we write c0 for\nan arbitrary positive absolute constant; for example, one may choose c0 = 1.\nWe write A \u226a B if there exists an absolute constant c such that A \u2264 cB.\nSimilarly, A \u226as B if A \u2264 c(s)B. We also write A \u224ds B if A \u226as B \u226as A. By\n\u230a\u03b1\u230b we denote the largest integer not greater than \u03b1.\nThroughout we assume that all random vectors and variables are independent in aggregate if the contrary is not clear from the context. By\nX1 , X2 , . . . we shall denote independent copies of a random vector X. Similarly, G1 , G2 , . . . are independent copies of G and so on. By L(X) we denote\ne of a random vector X\nthe distribution of X. Define the symmetrization X\ne\nas a random vector with distribution L(X) = L(X1 \u2212 X2 ).\n\n\f7\n\nEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\nInstead of normalized sums SN , it is sometimes more convenient to con(\u22c4)\nsider the sums ZN = X1 + * * * + XN . Then SN = N \u22121/2 ZN . Similarly, by ZN\n(\u0003)\n(resp., ZN ) we shall denote sums of N independent copies of X \u22c4 (resp., X \u0003 ).\n(\u0003)\n\u0003\n.\nFor example, ZN = X1\u0003 + * * * + XN\nThe expectation EY with respect to a random vector Y we define as the\nconditional expectation\nEY f (X, Y, Z, . . .) = E(f (X, Y, Z . . .)|X, Z, . . .)\ngiven all random vectors but Y .\ndef\nThroughout we write e{x} = exp{ix}. By\nZ \u221e\nb\ne{tx} dF (x),\n(2.11)\nF (t) =\n\u2212\u221e\n\nwe denote the Fourier\u2013Stieltjes transform of a function F of bounded variation or, in other words, the Fourier transform of the measure which has the\ndistribution function F .\nIntroduce the distribution functions\ndef\n\n(2.12)\n\nFa (x) = P{Q[SN \u2212 a] \u2264 x},\n\ndef\n\nHa (x) = P{Q[G \u2212 a] \u2264 x},\na \u2208 Rd , x \u2208 R.\n\nFurthermore, define, for d = \u221e and a \u2208 Rd , the Edgeworth correction\nEa (x) = Ea (x; Q, X)\n\nas a function of bounded variation such that Ea (\u2212\u221e) = 0 and its Fourier\u2013\nStieltjes transform is given by\n\n(2.13)\n\n2\nba (t) = 2(it)\n\u221a E e{tQ[Y ]}(3hQX, Y ihQX, Xi + 2ithQX, Y i3 ),\nE\n3 N\n\nY = G \u2212 a.\n\nIn finite dimensional spaces (for 1 \u2264 d < \u221e) we define the Edgeworth\ncorrection as follows; see Bhattacharya and Rao (1986). \u221aLet \u03c6 denote the\nstandard normal density in Rd . Then\u221ap(y) = \u03c6(C\u22121/2 y)/ det C, y \u2208 Rd , is\nthe density of G, and, for a \u2208 Rd , b = N a, we have\n1\ndef\ndef\nEa (x) = \u0398b (N x) = \u221a \u03c7(Ax ),\n6 N\n\n(2.14)\n\nAx = {u \u2208 Rd : Q[u \u2212 a] \u2264 x},\n\nwith the signed measure\nZ\ndef\n(2.15)\nEp\u2032\u2032\u2032 (y)X 3 dy\n\u03c7(A) =\nA\n\nfor the Borel sets A \u2282 Rd ,\n\n\f8\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nand where\n(2.16)\n\np\u2032\u2032\u2032 (y)u3 = p(y)(3hC\u22121 u, uihC\u22121 y, ui \u2212 hC\u22121 y, ui3 )\n\ndenotes the third Frechet derivative of p in direction u.\nNotice that Ea = 0 if a = 0 or if EhX, yi3 = 0, for all y \u2208 Rd . In particular,\nEa = 0 if X is symmetric [i.e., L(X) = L(\u2212X)].\nWe can write similar representations for Ea\u0003 (x) = \u0398b\u0003 (N x) and Ea\u22c4 (x) =\n\u22c4\n\u0398b (N x) just replacing X by X \u0003 and X \u22c4 in (2.13) or (2.15) with Y = G \u2212 a.\nFor b \u2208 Rd , introduce the distribution functions\ndef\n\n(2.17)\n\n\u03a8b (x) = P{Q[ZN \u2212 b] \u2264 x} = Fa (x/N )\n\nand\n\n\u221a\ndef\n\u03a6b (x) = P{Q[ N G \u2212 b] \u2264 x} = Ha (x/N ).\n\u221a\nDefine, for a \u2208 Rd , b = N a,\n(2.18)\n\n(2.19)\n\n(a) def\n\n\u2206N = sup|Fa (x) \u2212 Ha (x) \u2212 Ea (x)| = sup|\u03a8b (x) \u2212 \u03a6b (x) \u2212 \u0398b (x)|;\nx\u2208R\n\nx\u2208R\n\nsee (2.12), (2.14), (2.17) and (2.18) to justify the last equality in (2.19). We\n(a)\n(a)\nwrite \u2206N,\u0003 and \u2206N,\u22c4 replacing Ea by Ea\u0003 and Ea\u22c4 in (2.19).\n(a)\n\nThe aim of this paper is to derive for \u2206N explicit bounds of order O(N \u22121 )\nwithout any additional smoothness type assumptions. Theorem 2.1 [which\nwas proved in BG (1997a)] solved this problem in the case 13 \u2264 d \u2264 \u221e.\nIn Theorems 2.1\u20132.5 we assume that the symmetric operator Q is isometric, that is, that Q2 is the identity operator Id . This does not restrict\ngenerality; see Remark 1.7 in BG (1997a). Indeed, any symmetric operator Q\nmay be decomposed as Q = Q1 Q0 Q1 , where Q0 is symmetric and isometric\nand Q1 is symmetric bounded and nonnegative, that is, hQ1 x, xi \u2265 0, for all\nx \u2208 Rd . Thus, for any symmetric Q, we can apply all our bounds replacing\nthe random vector X by Q1 X, the Gaussian random vector G by Q1 G, the\nshift a by Q1 a, etc. In the case of concentration functions (see Theorems\n2.4 and 2.5), we have Q(X; \u03bb; Q) = Q(Q1 X; \u03bb; Q0 ), and we may apply the\nresults provided Q1 X (instead of X) satisfies the conditions.\nTheorem 2.1 [BG (1997a), Theorem 1.3]. Assume that \u03b4 = 1/300, Q2 =\nId , s = 13 and 13 \u2264 d \u2264 \u221e. Let PQ (\u03b4, So , c0 G/\u03c3) \u2265 p > 0, where c0 is an\narbitrary positive absolute constant. Then\n(2.20)\nand\n(2.21)\n\n(a)\n\n\u2206N \u2264 C(\u03a0\u22c43 + \u039b\u22c44 )(1 + ka/\u03c3k6 )\n(a)\n\n\u2206N,\u22c4 \u2264 C(\u03a0\u22c42 + \u039b\u22c44 )(1 + ka/\u03c3k6 )\n\nwith C = cp\u22126 + c(\u03c3/\u03b88 )8 , where \u03b814 \u2265 \u03b824 \u2265 * * * are the eigenvalues of (CQ)2 .\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n9\n\nUnfortunately, we cannot apply Theorem 2.1 for d = 5, 6, . . . , 12. Moreover, the quantity C depends on p which is exponentially small with respect\nto eigenvalues of C.\nThe main result of the paper is Theorem 2.2. It is valid for 5 \u2264 d < \u221e\nin finite-dimensional spaces Rd only. However, the bounds of Theorem 2.2\ndepend on the smallest \u03c3j 's. This makes them unstable if one or more of\ncoordinates of X degenerates. In our finite dimensional results, Theorems\n2.2, 2.4, 2.5 and Corollary 2.3, we always assume that the covariance operator\nC is nondegenerate.\nTheorem 2.2.\n\nLet Q2 = Id , 5 \u2264 d < \u221e. Then\n(a)\n\n\u2206N \u2264 C(\u03a03\u0003 + \u039b4\u0003 )(1 + ka/\u03c3k3 )\n\n(2.22)\nand\n\n(a)\n\n\u2206N,\u0003 \u2264 C(\u03a02\u0003 + \u039b4\u0003 )(1 + ka/\u03c3k3 ),\n\n(2.23)\n\nwith C = cd \u03c3 d (det C)\u22121/2 .\nIn G\u00f6tze and Zaitsev (2010) [see also a preprint of G\u00f6tze and Zaitsev\n(2009) which is available in Internet], an analogue of Theorem 2.2 was proved\nin the case s = 5 and 5 \u2264 d < \u221e with bounds for constants which are not\noptimal. It extends to the case d \u2265 5 Theorem 1.5 of BG (1997a) which contains the corresponding bounds for d \u2265 9. Unfortunately, in both papers, the\nquantity C depends on p which is exponentially small with respect to \u03c39 /\u03c3 2\n[in BG (1997a)] and to \u03c35 /\u03c3 2 [in G\u00f6tze and Zaitsev (2010)]. Under some\nadditional conditions, C may be estimated from above by cd exp(c\u03c3 2 \u03c39\u22122 )\nand by cd exp(c\u03c3 2 \u03c35\u22122 ), respectively. The case a = 0 was considered earlier\nin G\u00f6tze and Zaitsev (2008). As a consequence, we have proved Theorem 1.1.\nIt is easy to see that, according to (2.5) and (2.7),\n(2.24) \u03a03\u0003 + \u039b4\u0003 \u2264 EkC\u22121/2 Xk3+\u03b4 /(d(3+\u03b4)/2 N (1+\u03b4)/2 )\n\nfor 0 \u2264 \u03b4 \u2264 1\n\nand\n(2.25) \u03a02\u0003 + \u039b4\u0003 \u2264 EkC\u22121/2 Xk2+\u03b4 /(d(2+\u03b4)/2 N \u03b4/2 )\n\nfor 0 \u2264 \u03b4 \u2264 2.\n\nTherefore, Theorem 2.2 implies the following Corollary 2.3.\nCorollary 2.3.\n(a)\n\nLet Q2 = Id , 5 \u2264 d < \u221e. Then\n\n(2.26) \u2206N \u226ad C(1 + ka/\u03c3k3 )EkC\u22121/2 Xk3+\u03b4 /N (1+\u03b4)/2\n\nfor 0 \u2264 \u03b4 \u2264 1\n\nand\n(2.27)\n\n(a)\n\n\u2206N,\u0003 \u226ad C(1 + ka/\u03c3k3 )EkC\u22121/2 Xk2+\u03b4 /N \u03b4/2\n\nfor 0 \u2264 \u03b4 \u2264 2,\n\n\f10\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nwith C = \u03c3 d (det C)\u22121/2 . In particular,\n(2.28)\n\n(a)\n\n(a)\n\nmax{\u2206N , \u2206N,\u0003 } \u226ad C(1 + ka/\u03c3k3 )EkC\u22121/2 Xk4 /N.\n\nTheorem 2.1 and Corollary 2.3 yield Theorems 1.1 and 1.2, using that\nE0 (x) \u2261 0, EkC\u22121/2 Xk4 \u2264 \u03b2/\u03c3d4 , and \u03a0\u22c42 + \u039b\u22c44 \u2264 \u03a0\u22c43 + \u039b\u22c44 \u2264 \u03b2/(\u03c3 4 N ).\nComparing Theorem 2.2 and Corollary 2.3 with the main results of BG\n(1997a) and G\u00f6tze and Zaitsev (2010), we see that the constants in Theorem\n2.2 and Corollary 2.3 are written explicitly in terms of moment characteristics of L(X). In the case of nonpositive definite quadratic forms Q such\nkind of estimates were unknown.\nIf, in the conditions of Theorem 2.2, the distribution of X is symmetric\nor a = 0, then the Edgeworth corrections Ea (x) and Ea\u0003 (x) vanish and\n(2.29)\n\n(a)\n\n(a)\n\n\u2206N = \u2206N,\u0003 \u2264 C(\u03a02\u0003 + \u039b4\u0003 )(1 + ka/\u03c3k3 ),\n\nC = cd \u03c3 d (det C)\u22121/2 .\n\nThe corresponding inequality from Theorem 1.4 of BG (1997a) yields in the\ncase s = 9 and 9 \u2264 d \u2264 \u221e under the condition PQ (\u03b4, So , c0 G/\u03c3) \u2265 p > 0 with\n\u03b4 = 1/300 the bound\n(2.30)\n\n(a)\n\n\u2206N \u2264 C(\u03a0\u22c42 + \u039b\u22c44 )(1 + ka/\u03c3k4 ),\n\nC = cp\u22124 .\n\nIt is clear that sometimes the bound (2.30) may be sharper than (2.29) but,\nunfortunately, it depends on p which is usually exponentially small with\nrespect to \u03c39 /\u03c3 2 .\nSeveral authors have obtained more precise estimates of constants in the\ncase of d-dimensional balls with d \u2265 12, including the case d = \u221e. For\nballs, Q = Id . In the papers mentioned above, the authors have used the\naproach of BG (1997a) and obtained bounds with constants depending on\ns \u2264 d largest eigenvalues \u03c312 \u2265 \u03c322 \u2265 * * * \u2265 \u03c3s2 of the covariance operator C;\nsee Nagaev and Chebotarev (1999, 2005), with d \u2265 s = 13, and G\u00f6tze and\nUlyanov (2000), and Bogatyrev, G\u00f6tze and Ulyanov (2006), with d \u2265 s = 12.\nIt should be mentioned, that, in a particular case, where Q = Id and d \u2265 12,\nthese results may be sharper than (2.22), for some covariance operators C.\n(a)\nThe lower bounds for \u2206N under different conditions on a and L(X) are\n(a)\ngiven in G\u00f6tze and Ulyanov (2000). See the upper bounds for \u2206N with\ns = 12 and d = \u221e in Ulyanov and G\u00f6tze (2011), where the dependence on\nthe eigenvalues of C is given in the upper bound in an explicit form which\ncoincides with that in the lower bound. See also the review of recent results\nfor \"almost\" quadratic forms in Prokhorov and Ulyanov (2013).\nThus we see that the statement of Theorem 2.2 is especially interesting for\nd = 5, . . . , 11. It is new even in the case of d-dimensional balls. It is plausible\nthat the bounds for constants in Theorem 2.2 could be also improved for balls\nwith d \u2265 5, especially in the case where d is large. It seems, however, that this\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n11\n\nis impossible in the case of general Q even if Q2 = Id . For example, consider\nthe operator Q such that Qej = ed\u2212j+1 , where Cej = \u03c3j2 ej , j = 1, 2, . . . , d,\nare eigenvectors of C. Following the proof of Theorem 2.2, we see that the\nb b (t)| = |E e{tQ[ZN \u2212\nbounds for the modulus of the characteristic function |\u03a8\nb]}| behave as the bounds for the modulus of the characteristic function\n|E e{tId [ZN \u2212 b]}|, but with eigenvalues of the covariance operator \u03c31 \u03c3d ,\n\u03c32 \u03c3d\u22121 , \u03c33 \u03c3d\u22122 , . . . which may be essentially smaller than \u03c312 \u2265 \u03c322 \u2265 \u03c332 \u2265 * * *.\nTherefore, it is natural that the bounds for constants in Theorem 2.2 depends\non the smallest eigenvalues of the covariance operator C.\nNote that, in the proof of Theorem 2.1 in BG (1997a), inequalities (2.20)\nand (2.21) were derived for the Edgeworth correction Ea (x) defined by\n(2.13). However, from Theorems 2.1 and 2.2 it follows that, at least for\n13 \u2264 d < \u221e, definitions (2.13) and (2.14) determine the same function Ea (x).\nIndeed, both functions may be represented as N \u22121/2 Kj (x), where Kj (x) are\nsome functions of bounded variation which are independent of N . Furthermore, inequalities (2.20) and (2.22) provide both bounds of order O(N \u22121 ).\nThis is possible only if the Edgeworth corrections Ea (x) are the same in\nthese inequalities.\nOn the other hand, it is proved (for d \u2265 9) that definition (2.13) determines a function of bounded variation [see BG (1997a, Lemma 5.7)], while\ndefinition (2.14) has no sense for d = \u221e.\nIntroduce the concentration function\nQ(X; \u03bb) = Q(X; \u03bb; Q)\n(2.31)\n=\n\nsup\na\u2208Rd ,x\u2208R\n\nP{x \u2264 Q[X \u2212 a] \u2264 x + \u03bb}\n\nfor \u03bb \u2265 0.\n\nNote that, evidently, Q(X + Y ; \u03bb) \u2264 Q(X; \u03bb), for any Y which is independent\nof X.\nWe say that a random vector Y is concentrated in L \u2282 Rd if P{Y \u2208 L} = 1.\ne is not\nIn BG [(1997a), item (iii) of Theorem 1.6] it was shown that if X\nd\nconcentrated in a proper closed linear subspace of R , 1 \u2264 d \u2264 \u221e, then for\nany \u03b4 > 0 and S, there exists a natural number m such that the condition\nPQ (\u03b4, S, m\u22121/2 Zem ) \u2265 p holds with some p > 0.\nIn this paper, we shall prove the following Theorems 2.4 and 2.5.\nTheorem 2.4.\n\nLet Q2 = Id , 5 \u2264 s = d < \u221e and 0 \u2264 \u03b4 \u2264 1/(5s). Then:\n\n(i)\n(2.32)\n\nQ(ZN ; \u03bb) \u226ad (pN )\u22121 max{1; \u03bb\u03c3 \u22122 }\u03c3 d (det C)\u22121/2\n\ne \u2265 p for some So and p > 0.\nif P (\u03b4, So , C\u22121/2 X)\n\nfor all \u03bb \u2265 0,\n\n\f12\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\n(ii)\n(2.33) Q(ZN ; \u03bb) \u226ad (pN )\u22121 max{m; \u03bb\u03c3 \u22122 }\u03c3 d (det C)\u22121/2\n\nfor all \u03bb \u2265 0,\n\nem ) \u2265 p > 0.\nif, for some So and positive integer m, P (\u03b4, So , m\u22121/2 C\u22121/2 Z\nTheorem 2.5.\n\n(2.34)\n\nAssume that 5 \u2264 d < \u221e and that Q2 = Id . Then\n\nQ(ZN ; \u03bb) \u226ad max{\u03a0\u00032 + \u039b\u00034 ; \u03bb\u03c3 \u22122 N \u22121 }\u03c3 d (det C)\u22121/2\n\nIn particular, Q(ZN ; \u03bb) \u226ad\n\nfor all \u03bb \u2265 0.\n\nN \u22121 max{EkC\u22121/2 Xk4 ; \u03bb\u03c3 \u22122 }\u03c3 d (det C)\u22121/2 .\n\nTheorems 2.4 and 2.5 yield more explicit versions of Theorems 1.5 and\n2.1 from G\u00f6tze and Zaitsev (2010) [which extend to the case 5 \u2264 d \u2264 \u221e\nTheorems 1.6 and 2.1 of BG (1997a) which were proved for 9 \u2264 d \u2264 \u221e].\nWe should mention that the results of G\u00f6tze and Zaitsev (2010) do not\nfollow from Theorems 2.2, 2.4 and 2.5. For example, they may be sharper\nthan Theorems 2.2, 2.4 and 2.5, in a particular case, where Q = Id and\n\u03c35 \u224dd \u03c3. Under some additional conditions, \u03c3 d (det C)\u22121/2 is replaced by\nexp(c\u03c3 2 \u03c35\u22122 ) \u224dd 1. On the other hand, \u03c3 d (det C)\u22121/2 provides a power-type\ndependence on eigenvalues of C and the results are valid for Q which might\nbe not positive definite.\nIn Theorems 2.2 and 2.5, we do not assume conditions P (*) \u2265 p > 0 or\nPQ (*) \u2265 p > 0. In the proofs, we use, however, that, for any fixed absolute\npositive constant c0 and any positive quantity cd depending on d only, condition P (\u03b4, So , c0 C\u22121/2 G) \u2265 p is fulfilled with s = d, \u03b4 = cd and p \u224dd 1, for\nany orthonormal system So .\nSimilarly to BG (1997a), in Section 3, we prove bounds for concentration\nfunctions. The proof is technically simpler as that of Theorem 2.2, but it\nshows how to apply the principal ideas. This proof repeats almost literally\nthe corresponding proof of BG (1997a). The only difference consists in the\nuse of new Lemma 8.3 which allows us to estimate characteristic functions of\nquadratic forms for relatively large values of argument t. In Sections 4 and\n5, Theorem 2.2 is proved. We replace Lemma 9.4 of BG (1997a) by its improvement, Lemma 5.1. Another difference is in another choice of k in (5.31)\nand (5.32) in comparison with that in BG (1997a). In Sections 6\u20138 we prove\nestimates for characteristic functions which were discussed in Section 1.\n3. Proofs of bounds for concentration functions.\nProof of Theorems 2.4 and 2.5. Below we prove assertions (2.32); (2.32) =\u21d2\n(2.33) and (2.33) =\u21d2 (2.34). The proof repeats almost literally the corresponding proof of BG (1997a). It is given here for the sake of completeness.\nThe only essential difference is in the use of Lemma 8.3 in the proof of\nLemma 3.1. We have also to replace everywhere 9 by 5 and \u22c4 by \u0003.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\nFor 0 \u2264 t0 \u2264 T and b \u2208 Rd , define the integrals\nZ\nZ T\nb\n|\u03a8b (t)| dt,\nI1 =\nI0 =\n\nt0 \u2264|t|\u2264T\n\n\u2212T\n\nwhere\n\nb b (t)|\n|\u03a8\n\n13\n\ndt\n,\n|t|\n\nb b (t) = E e{tQ[ZN \u2212 b]}\n\u03a8\n\n(3.1)\n\ndenotes the Fourier\u2013Stieltjes transform of the distribution function \u03a8b of\nb b (\u2212t)| = |\u03a8\nb b (t)|.\nQ[ZN \u2212 b]. Note that |\u03a8\n\ne \u2265 p > 0 with some 0 \u2264 \u03b4 \u2264\nLemma 3.1. Assume that P (\u03b4, So , C\u22121/2 X)\n2\n1/(5s) and 5 \u2264 s = d < \u221e. Let \u03c3 = 1 and\n(3.2)\n\nt0 = c1 (s)\u03c31\u22122 (pN )\u22121+2/s ,\n\nc2 (s)\u03c31\u22122 \u2264 T \u2264 c3 (s)\u03c31\u22122\n\nwith some positive constants cj (s), 1 \u2264 j \u2264 3. Then\n(3.3)\n\nI0 \u226as (det C)\u22121/2 (pN )\u22121 ,\n\nI1 \u226as (det C)\u22121/2 (pN )\u22121 .\n\nProof. Note that the condition \u03c3 2 = 1 implies that\n(3.4)\n\nT \u224ds \u03c312 \u224ds \u03c3 2 = 1 and\n\ndet C \u2264 1.\n\nDenote k = pN . Without loss of generality we assume that k \u2265 cs , for a\nsufficiently large quantity cs depending on s only. Indeed, if k \u2264 cs , then one\nb b | \u2264 1. Choosing cs to be large enough, we\ncan prove (3.3) using (3.4) and |\u03a8\nensure that k \u2265 cs implies 1/k \u2264 t0 \u2264 T .\nLemma 8.3 and (3.4) imply now that\nZ T\n\u22121/2\nb b (t)| dt \u226as (det C)\n|\u03a8\n(3.5)\nt\nk\nc4 (s)k \u22121+2/s\nfor any c4 (s) depending on s only. Inequalities (3.4) and (3.5) imply (3.3)\nfor I1 .\nLet us prove inequality (3.2) for I0 . By (3.4) and by Lemma 8.1, for\nany \u03b3 > 0 and any fixed t \u2208 R satisfying k1/2 |t| \u2264 c5 (s), where c5 (s) is an\narbitrary quantity depending on s only, we have (taking into account that\nb b | \u2264 1)\n|\u03a8\n\n(3.6)\n\nb b (t)| \u226a\u03b3,s min{1; k\u2212\u03b3 + k\u2212s/2 |t|\u2212s/2 (det C)\u22121/2 },\n|\u03a8\n\nk = pN.\n\nFurthermore, choosing an appropriate \u03b3 and using (3.4)\u2013(3.6), we obtain\nZ \u221e\nZ 1/k\n1\ndt\n1\n1/2\n\u226as ,\n(det C) I0 \u226as\n(3.7)\ndt + +\ns/2\nk\nk\n1/k (tk)\n0\nproving (3.2) for I0 . \u0003\n\n\f14\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nProof of (2.32). Let \u03c3 2 = 1. Using a well-known inequality for concentration functions [see, e.g., Petrov (1975), Lemma 3 of Chapter 3], we\nhave\nZ 1\nb b (t)| dt.\n(3.8)\n|\u03a8\nQ(ZN ; \u03bb) \u2264 4 sup max{\u03bb; 1}\nb\u2208Rd\n\n0\n\nTo estimate the integral in (3.8) we apply Lemma 3.1 which implies that\nQ(ZN ; \u03bb) \u226ad max{\u03bb; 1}(pN )\u22121 (det C)\u22121/2 ,\n\n(3.9)\n\nproving (2.32) in the case \u03c3 2 = 1. If \u03c3 2 6= 1, we obtain (2.32) applying (3.9)\nto ZN /\u03c3. \u0003\nProof of (2.32) =\u21d2 (2.33). Without loss of generality we can assume\nthat N/m \u2265 2. Let Y1 , Y2 , . . . be independent\ncopies of m\u22121/2 Zm . Denote\n\u221a\nWk = Y1 + * * * + Yk . Then L(ZN ) = L( mWk + y), where k = \u230aN/m\u230b is the\nlargest integer not greater than N/m and y is independent of Wk . Therefore,\nQ(ZN ; \u03bb) \u2264 Q(Wk ; \u03bb/m). In order to estimate Q(Wk ; \u03bb/m) we apply (2.32)\nreplacing ZN by Wk . We have\n(3.10)\n\nQ(Wk ; \u03bb/m) \u226as (pk)\u22121 max{1; \u03bb\u03c3 \u22122 /m}\u03c3 d (det C)\u22121/2\n\u226a (pN )\u22121 max{m; \u03bb\u03c3 \u22122 }\u03c3 d (det C)\u22121/2 .\n\n\u0003\n\nRecall that truncated random vectors and their moments are defined by\n(2.4)\u2013(2.7) and that C = cov X = cov G.\nLemma 3.2.\n\nThe random vectors X \u0003 , X\u0003 satisfy\n\nhCx, xi = hcov X \u0003 x, xi + EhX\u0003 , xi2 + hEX \u0003 , xi2 .\nThere exist independent centered Gaussian vectors G\u2217 and W such that\nL(G) = L(G\u2217 + W )\nand\ne \u0003,\n2 cov G\u2217 = 2 cov X \u0003 = cov X\n\nhcov W x, xi = EhX\u0003 , xi2 + hEX \u0003 , xi2 .\n\nFurthermore,\n\nEkC\u22121/2 Gk2 = d = EkC\u22121/2 G\u2217 k2 + EkC\u22121/2 W k2\n\nand EkC\u22121/2 W k2 \u2264 2d\u03a02\u0003 .\n\nWe omit the simple proof of this lemma; see BG [(1997a), Lemma 2.4] for\nthe same statement with \u22c4 instead of \u0003.\n(\u22c4)\n(\u0003)\nRecall that ZN and ZN denote sums of N independent copies of X \u0003\nand X \u22c4 , respectively.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n15\n\nLemma 3.3. Let \u03b5 > 0. There exist absolute positive constants c and c1\nsuch that the condition \u03a02\u0003 \u2264 c1 p\u03b42 /(d\u03b52 ) implies that\nP (\u03b4, S, \u03b5C\u22121/2 G) \u2265 p\n\n(\u0003)\nP (4\u03b4, S, \u03b5(2m)\u22121/2 C\u22121/2 Zem\n) \u2265 p/4\n\n=\u21d2\n\nfor m \u2265 c\u03b54 d2 N \u039b4\u0003 /(p\u03b44 ).\n\nLemmas 3.2 and 3.3 are in fact the statements of Lemmas 2.4 and 2.5\nfrom BG (1997a) applied to the vectors C\u22121/2 X instead of the vectors X.\nWe use in this connection equalities (2.3), (2.9) and (2.10) replacing in the\n(\u0003)\n(\u22c4)\nformulation \u03c3 2 , \u039b\u22c44 , \u03a0\u22c4q , G, Zm , . . . by d, \u039b4\u0003 , \u03a0q\u0003 , C\u22121/2 G, Zm , . . . , respectively.\nProof of (2.33) =\u21d2 (2.34).\nhave\n(3.11)\n\nBy a standard truncation argument, we\n\n(\u0003)\n\n|P{ZN \u2208 A} \u2212 P{ZN \u2208 A}| \u2264 N P{kC\u22121/2 Xk >\n\nfor any Borel set A, and\n\n\u221a\n\ndN } \u2264 \u03a02\u0003\n\n(\u0003)\n\nQ(ZN , \u03bb) \u2264 \u03a02\u0003 + Q(ZN , \u03bb).\n\n(3.12)\n\nRecall that we are proving (2.34) assuming that 5 \u2264 d < \u221e. It is easy to see\nthat, for any absolute positive constant c0 and for any orthonormal system\nSo = {e1 , . . . , es } \u2282 Rd , condition\n(3.13)\n\nP (\u03b4, So , c0 C\u22121/2 G) \u2265 p\n\nwith p \u224dd 1, 5 \u2264 s = d < \u221e, \u03b4 = 1/(20s)\n\nis in fact fulfilled automatically since the vector C\u22121/2 G has standard Gaussian distribution in Rd and, therefore,\n\u22121\nP{kc0 C\u22121/2 G \u2212 ek \u2264 \u03b4} = P{kC\u22121/2 G \u2212 c\u22121\n0 ek \u2264 c0 \u03b4} = c(d, c0 )\n\nfor any vector e \u2208 Rd with kek = 1. For any fixed c0 , the c(d, c0 ) may be\nconsidered\n\u221a as a quantity depending on d only. Clearly, 4\u03b4 = 1/(5s). Write\nK = \u03b5/ 2 with \u03b5 = c0 . Then, by (3.13) and Lemma 3.3, we have\n(3.14)\n\nP (\u03b4, So , \u03b5C\u22121/2 G) \u2265 p\n\n=\u21d2\n\nprovided that\n\n\u03a02\u0003 \u2264 c1 (d),\n\n(3.15)\n\n(\u0003 )\nP (4\u03b4, So , m\u22121/2 KC\u22121/2 Zem\n) \u2265 p/4,\n\nm \u2265 c2 (d)N \u039b4\u0003 .\n\nWithout loss of generality we may assume that \u03a02\u0003 \u2264 c1 (d), since otherwise\nthe result follows easily from the trivial inequality Q(ZN ; \u03bb) \u2264 1.\n(\u0003)\nThe nondegeneracy condition (3.14) for K Zem allows us to apply inequality (2.33) of Theorem 2.4, and, using (3.13), we obtain\n(\u0003)\n\n(3.16)\n\n(\u0003)\n\nQ(ZN , \u03bb) = Q(KZN , K 2 \u03bb)\n\n\u226ad N \u22121 max{m; K 2 \u03bb/K 2 \u03c3 2 }\u03c3 d (det C)\u22121/2\n\n\f16\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nfor any m such that (3.15) is fulfilled. Choosing the minimal m in (3.15),\nwe obtain\n(3.17)\n\n(\u0003)\n\nQ(ZN , \u03bb) \u226ad max{\u039b4\u0003 ; \u03bb/(\u03c3 2 N )}\u03c3 d (det C)\u22121/2 .\n\nCombining the estimates (3.12) and (3.17), we complete the proof. \u0003\n4. Auxiliary lemmas. In Sections 4 and 5 we prove Theorem 2.2. Therefore, we assume that its conditions are satisfied. We consider the case d < \u221e\nassuming that the following conditions are satisfied:\n\u221a\nQ2 = Id ,\n\u03c3 2 = 1,\nd \u2265 5,\nb = N a.\n(4.1)\n\nNotice that the assumption \u03c3 2 = 1 does not restrict generality since from\nTheorem 2.2 with \u03c3 2 = 1, we can derive the general result replacing X, G\nby X/\u03c3, G/\u03c3, etc. Other assumptions in (4.1) are included as conditions\nin Theorem 2.2. Section 4 is devoted to some auxiliary lemmas which are\nsimilar to corresponding lemmas of BG (1997a).\nIn several places, the proof of Theorem 2.2 repeats almost literally the\nproof of Theorem 1.5 in BG (1997a). Note, however, that we use truncated\nvectors Xj\u0003 , while in BG (1997a) the vectors Xj\u22c4 were involved. We start\nwith an application\nof the Fourier transform to the functions \u03a8b and \u03a6b ,\n\u221a\nwhere b = N a. We estimate integrals over the Fourier transforms using\nresults of Sections 3, 6\u20138 and some technical lemmas of BG (1997a). We\nalso apply some methods of estimation of the rate of approximation in the\nCLT in multidimensional spaces; cf., for example, Bhattacharya and Rao\n(1986).\nBelow we use the following formula for the Fourier inversion; see, for\nexample, BG (1997a). A smoothing inequality of Prawitz (1972) implies [see\nBG (1996), Section 4] that\nZ\ndt\ni\n1\ne{\u2212xt}Fb(t) + R\n(4.2)\nV.P.\nF (x) = +\n2 2\u03c0\nt\n|t|\u2264K\nfor any K > 0 and any distribution function F with characteristic function Fb\n[see (2.11)], where\nZ\n1\n|R| \u2264\n(4.3)\n|Fb(t)| dt.\nK |t|\u2264K\nR\nR\nHere V.P. f (t) dt = lim\u03b5\u21920 |t|>\u03b5 f (t) dt denotes the principal value of the\nintegral.\nIn Sections 4 and 5, we denote\n(4.4)\n\nX \u2032 = X \u0003 \u2212 EX \u0003 + W,\n\nwhere W is a centered Gaussian random vector which is independent of all\nother random vectors and variables and is chosen so that cov X \u2032 = cov G.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n17\n\nSuch a vector W exists by Lemma 3.2. We define Ea\u2032 (x) = \u0398\u2032b (N x) replacing\nX by X \u2032 in (2.13) or (2.15) with Y = G \u2212 a.\n(\u0003)\nRecall that the random vector X \u0003 is defined in (2.5) and ZN is a sum\n\u2032\n\u2032\n\u2032\nof its N independent copies. Similarly, ZN = X1 + * * * + XN . Write \u03a8b\u0003 and\n(\u0003)\n\u2032 \u2212 b], respectively.\n\u03a8\u2032b for the distribution function of Q[ZN \u2212 b] and Q[ZN\nFor 0 \u2264 k \u2264 N introduce the distribution function\n(4.5)\n\n(k)\n\n\u2032\n\u2032\n\u03a8b (x) = P{Q[G1 + * * * + Gk + Xk+1\n+ * * * + XN\n\u2212 b] \u2264 x}.\n(N )\n\n(0)\n\nNotice that \u03a8b = \u03a8\u2032b , \u03a8b = \u03a6b .\nThe proof of the following lemma repeats the proof of Lemma 3.1 of BG\n(1997a). The difference is that here we use the truncated vectors Xj\u0003 instead\nof Xj\u22c4 .\nLemma 4.1. Let cd be a quantity depending on d only. There exist positive quantities c1 (d) and c2 (d) depending on d only such that the following\nstatement is valid. Let \u03a02\u0003 \u2264 c1 (d)p and let an integer 1 \u2264 m \u2264 N satisfy\nm \u2265 c2 (d)N \u039b4\u0003 /p. Write\nK = c20 /(2m),\n\nt1 = cd (pN/m)\u22121+2/d .\n(k)\n\nLet F denote any of the functions \u03a8b\u0003 , \u03a8\u2032b , \u03a8b or \u03a6b . Then we have\nZ\ndt\ni\n1\ne{\u2212xtK}Fb(tK) + R1 ,\n(4.6)\nV.P.\nF (x) = +\n2 2\u03c0\nt\n|t|\u2264t1\nwith |R1 | \u226ad (pN )\u22121 m(det C)\u22121/2 .\n\nProof. We assume that (pN )\u22121 m \u2264 c3 (d) with sufficiently small c3 (d)\nsince otherwise the statement of Lemma 4.1 is trivial; see (3.4), (4.2) and\n(4.3). Let us prove (4.6). We combine (4.2) and Lemma 3.1. Changing the\nvariable t = \u03c4 K in formula (4.2), we obtain\nZ\ndt\ni\n1\ne{\u2212xtK}Fb(tK) + R,\n(4.7)\nV.P.\nF (x) = +\n2 2\u03c0\nt\n|t|\u22641\nwhere\n\n(4.8)\n\n|R| \u2264\n(k)\n\u03a8\u2032b , \u03a8b\n\nZ\n\n|t|\u22641\n\n|Fb(tK)| dt.\n\nand \u03a6b are distribution functions of random variNotice that \u03a8b\u0003 ,\nables which may be written in the following form:\nQ[V + T ],\n\ndef\n\n\u0003\n\u0003\nV = G1 + * * * + Gk + Xk+1\n+ * * * + XN\n,\n\nwith some k, 0 \u2264 k \u2264 N , and some random vector T which is independent of\nXj\u0003 and Gj , for all j. Let us consider separately two possible cases, k \u2265 N/2\nand k < N/2.\n\n\f18\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nThe case k < N/2. Let Y denote a sum of m independent copies of\nK 1/2 X \u0003 . Let Y1 , Y2 , . . . be independent copies of Y . Then we have\nL(K 1/2 V ) = L(Y1 + * * * + Yl + T1 )\n\n(4.9)\n\nwith l = \u230aN/(2m)\u230b and some random T1 independent of Y1 , . . . , Yl . By (3.13)\nand by Lemma 3.3, we have\n(4.10)\nP (\u03b4, S, c0 C\u22121/2 G) \u2265 p =\u21d2 P (4\u03b4, S, C\u22121/2 Ye ) \u2265 p/4\nprovided that\n\n\u03a02\u0003 \u226a p/d3\n\n(4.11)\n\nand m \u226b d6 N \u039b4\u0003 /p.\n\nThe inequalities in (4.11) follow from conditions of Lemma 4.1 if we choose\nsome sufficiently small (resp., large) c1 (d) [resp. c2 (d)]. Due to (3.13), (4.1),\n(4.9) and (4.10), we can apply Lemma 3.1 in order to estimate the integrals\nin (4.7) and (4.8). Replacing in Lemma 3.1 X by Y and N by l, we obtain\n(4.6) in the case k < N/2.\nThe case k \u2265 N/2. We can argue as in the previous case defining now Y as\na sum of m independent copies of K 1/2 G. Condition P (4\u03b4, S, C\u22121/2 Ye ) \u2265 p/4\nis satisfied by (3.13), since now L(Ye ) = L(c0 G).\nFollowing BG (1997a), introduce the upper bound \u03ba(t; N, X) for the characteristic function of quadratic forms; cf. Bentkus (1984) and Bentkus,\nG\u00f6tze and Zitikis (1993). We define \u03ba(t; N, X) = \u03ba \u2217 (t; N, X) + \u03ba \u2217 (t; N, G),\nwhere\n(4.12)\n\n\u03ba \u2217 (t; N, X) = sup |E e{tQ[Zj ] + hx, Zj i}|,\nx\u2208Rd\n\nZj = X1 + * * * + Xj ,\n\nwith j = \u230a(N \u2212 2)/14\u230b. Note that |E e{tQ[Zj ] + hx, Zj i}| = |E e{tQ[Zj \u2212 y]}|\nwith y = \u2212Qx/(2t). In the sequel, we use that\n\u03ba(t; N, X \u2032 ) \u2264 \u03ba(t; N, X \u0003 ).\n\n(4.13)\n\nFor the proof, it suffices to note that X \u2032 = X \u0003 \u2212 EX \u0003 + W and W is independent of X \u0003 .\nLemma 4.2.\nZ\n\n(4.14)\n\nLet the conditions of Lemma 4.1 be satisfied. Then\n(|t|K)\u03b1 \u03ba(tK; N, X \u0003 )\n\n|t|\u2264t1\n\ndt\n|t|\n\n\uf8f1\n(N p)\u2212\u03b1 ,\nfor 0 \u2264 \u03b1 < d/2,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4 (N p)\u2212\u03b1 (1 + |log(N p/m)|),\n\uf8f4\n\uf8f2\n\u226a\u03b1,d (det C)\u22121/2\nfor \u03b1 = d/2,\n\uf8f4\n\uf8f4\n\u2212\u03b1\n\uf8f4\n(N p) (1 + (N p/m)(2\u03b1\u2212d)/d ),\n\uf8f4\n\uf8f4\n\uf8f3\nfor \u03b1 > d/2.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n19\n\nLemma 4.2 is a generalization of Lemma 3.2 from BG (1997a) which\ncontains the same bound for 0 \u2264 \u03b1 < d/2. In this paper, we have to estimate\nthe left-hand side of (4.14) in the case d/2 \u2264 \u03b1 too.\nProof. We assume again that (pN )\u22121 m \u2264 c3 (d) with sufficiently small\nc3 (d) since otherwise (4.14) is an easy consequence of |\u03ba| \u2264 1.\n(\u0003)\nBy (3.13) and (4.10), the condition P (4\u03b4, So , K 1/2 C\u22121/2 Zem ) \u2265 p/4 is ful1/2\n\u0003\nfilled. Therefore, collecting independent copies of K X in groups as in\n(4.9), we can apply inequality (8.34) of Lemma 8.1. By (3.4), (3.13) and\n(8.34), for any \u03b3 > 0 and |t| \u2264 t1 ,\n\u03ba \u2217 (tK; N, X \u0003 ) \u226a\u03b3,d (pN/m)\u2212\u03b3 + min{1; (N p/m)\u2212d/2 |t|\u2212d/2 (det C)\u22121/2 }.\n\nWe have used that \u03c3 2 = 1 implies \u03c312 \u224dd 1. A similar upper bound is valid\nfor the quantity \u03ba \u2217 (tK; N, G); cf. the proof of (4.6) for k > N/2. Thus we\nget for any \u03b3 > 0 and |t| \u2264 t1 ,\n\u03ba(tK; N, X \u0003 ) \u226a\u03b3,d (pN/m)\u2212\u03b3 + min{1; (det C)\u22121/2 (m/(|t|pN ))d/2 }.\n\nIntegrating this bound (cf. the estimation of I1 in Lemma 3.1), we obtain\n(4.14). \u0003\n5. Proof of Theorem 2.2. To simplify notation, in Section 5 we write\n\u03a0 = \u03a02\u0003 and \u039b = \u039b4\u0003 . The assumption \u03c3 2 = 1 and equalities EkC\u22121/2 Xk2 = d,\n(2.5) and (2.7) imply\n(5.1)\n\n\u03a0 + \u039bN \u226b 1,\n\n\u03a0 + \u039b \u2264 1,\n\n(a)\n\n\u03c3j2 \u2264 1,\n\ndet C \u2264 1.\n\nRecall that \u2206N and functions \u03a8b , \u03a6b and \u0398b are defined in (2.14) and\n(2.17)\u2013(2.19). Note now that \u0398b\u0003 (x) = Ea\u0003 (x/N ) and, according to (2.19),\n\u221a\nwhere b = N a and\n(5.3)\n\n(a)\n\n(a)\n\n(5.2)\n\n\u2206N \u2264 \u2206N,\u0003 + sup|\u0398b (x) \u2212 \u0398b\u0003 (x)|,\nx\u2208R\n\n(a)\n\n\u2206N,\u0003 = sup|\u03a8b (x) \u2212 \u03a6b (x) \u2212 \u0398b\u0003 (x)|.\nx\u2208R\n\nLet us verify that\nsup|\u0398b (x) \u2212 \u0398b\u0003 (x)| \u226ad \u03a03\u0003 .\n\n(5.4)\n\nx\u2208R\n\nTo this end we apply representation (2.14)\u2013(2.15) of the Edgeworth correction as a signed measure and estimate the variation of that measure. Indeed,\nusing (2.14)\u2013(2.15), we have\n(5.5)\n\nsup|\u0398b (x) \u2212 \u0398\u0003b (x)| \u226a N \u22121/2 I,\nx\u2208R\n\ndef\n\nI =\n\nZ\n\nRd\n\n3\n\n|Ep\u2032\u2032\u2032 (x)X 3 \u2212 Ep\u2032\u2032\u2032 (x)X \u0003 | dx.\n\n\f20\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nBy the explicit formula (2.16), the function u 7\u2192 p\u2032\u2032\u2032 (x)u3 is a 3-linear form\nin the variable u. Therefore, using X = X \u0003 + X\u0003 and kX \u0003 kkX\u0003 k = 0, we\nhave p\u2032\u2032\u2032 (x)X 3 \u2212 p\u2032\u2032\u2032 (x)X \u0003 3 = p\u2032\u2032\u2032 (x)X\u00033 , and\nZ\n\u22121/2\n3/2 \u0003\n(5.6) N\n(kC\u22121/2 xk + kC\u22121/2 xk3 )p(x) dx = cd \u03a03\u0003 .\nI \u2264 3d \u03a03\nRd\n\nInequalities (5.5) and (5.6) imply now (5.4).\nTo prove the statement of Theorem 2.2, we have to derive that\n(a)\n\n\u2206N,\u0003 \u226ad (\u03a0 + \u039b)(1 + kak)3 (det C)\u22121/2 .\n\n(5.7)\n\nWhile proving (5.7) we assume that\n(5.8)\n\n\u03a0 \u2264 cd\n\nand \u039b \u2264 cd ,\n\nwith a sufficiently small positive constant cd depending on d only. These\nassumptions do not restrict generality. Indeed, we have |\u03a8b (x) \u2212 \u03a6b (x)| \u2264 1.\nIf conditions (5.8) do not hold, then the estimate\n(5.9)\n\nsup|\u0398b\u0003 (x)| \u226ad N \u22121/2 EkC\u22121/2 X \u0003 k3 \u226ad \u039b1/2\nx\u2208R\n\nimmediately implies (5.7). In order to prove (5.9) we can use (2.7) and\nrepresentation (2.14)\u2013(2.15) of the Edgeworth correction. Estimating the\nvariation of that measure and using\n(5.10)\n(5.11)\n\nEkC\u22121/2 X \u0003 k2 \u2264 EkC\u22121/2 Xk2 = d,\n\n(EkC\u22121/2 X \u0003 k3 )2 \u2264 EkC\u22121/2 X \u0003 k2 EkC\u22121/2 X \u0003 k4 ,\n\nwe obtain (5.9).\nIt is clear that\n\n(a)\n\n(5.12)\n\n\u2206N,\u0003 \u2264 sup(|\u03a8b (x) \u2212 \u03a8\u2032b (x)| + |\u0398\u0003b (x) \u2212 \u0398\u2032b (x)|\nx\u2208R\n\nSimilarly to (5.5), we have\n\n+ |\u03a8\u2032b (x) \u2212 \u03a6b (x) \u2212 \u0398\u2032b (x)|).\n\nsup|\u0398\u0003b (x) \u2212 \u0398\u2032b (x)| \u226a N \u22121/2 J,\nx\u2208R\n\n(5.13)\n\ndef\n\nJ =\n\nZ\n\n3\n\nRd\n\n3\n\n|Ep\u2032\u2032\u2032 (x)X \u0003 \u2212 Ep\u2032\u2032\u2032 (x)X \u2032 | dx.\n\nRecall that vector X \u2032 is defined in (4.4). By Lemma 3.2, we have\nEkC\u22121/2 W k2 \u2264 2d\u03a0 (hence, EkC\u22121/2 W kq \u226ad \u03a0q/2 , for 0 \u2264 q \u2264 2). Using\nthe well-known equivalence of moments of Gaussian random vectors, we\nconclude that\n(5.14)\n\nEkC\u22121/2 W kq \u226aq (EkC\u22121/2 W k2 )q/2 \u226aq,d \u03a0q/2 ,\n\nq \u2265 0.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n21\n\nFurthermore, according to (2.5), (2.7) and (5.8),\nEkC\u22121/2 X\u0003 k \u226ad \u03a0N \u22121/2 \u226ad \u03a01/2 N \u22121/2 .\n\n(5.15)\n\nHence, by (2.7), (4.4), (5.1), (5.14) and (5.15),\ndef\n\nEkX \u2032 k4 \u226a \u03b2 = EkC\u22121/2 X \u2032 k4 \u226ad N \u039b + \u03a02 .\n\n(5.16)\n\nUsing (2.16), (5.1), (5.8), (5.10) and (5.13)\u2013(5.15), we get\nZ\n(kC\u22121/2 xk + kC\u22121/2 xk3 )p(x) dx\nN \u22121/2 J \u226ad \u03a01/2 (N \u22121/2 \u03a0 + \u039b1/2 )\nRd\n\n(5.17)\n\n\u226ad \u03a0 + \u039b.\nThus, according to (5.13) and (5.17),\nsup|\u0398b\u0003 (x) \u2212 \u0398\u2032b (x)| \u226ad \u03a0 + \u039b.\n\n(5.18)\n\nx\u2208R\n\nThe same approach is applicable for the estimation of |\u0398\u2032b |. Using (2.14)\u2013\n(2.16), (4.4), (5.1), (5.10), (5.11), (5.14) and (5.15), we get\nZ\n3\nsup|\u0398\u2032b (x)| \u226a N \u22121/2\n|Ep\u2032\u2032\u2032 (x)X \u2032 | dx\nRd\n\nx\u2208R\n\n(5.19)\n\n\u226ad \u039b1/2 + N \u22121/2 \u03a03/2 .\n\nLet us prove that\n(5.20)\n\nsup|\u03a8b (x) \u2212 \u03a8\u2032b (x)| \u226a (det C)\u22121/2 p\u22122 (\u03a0 + \u039b)(1 + kak2 ).\nx\u2208R\n\nUsing truncation [see (3.11)], we have |\u03a8b \u2212 \u03a8b\u0003 | \u2264 \u03a0, and\n\nsup|\u03a8b (x) \u2212 \u03a8\u2032b (x)| \u2264 \u03a0 + sup|\u03a8b\u0003 (x) \u2212 \u03a8\u2032b (x)|.\n\n(5.21)\n\nx\u2208R\n\nx\u2208R\n\n|\u03a8b \u2212 \u03a8\u2032b |,\n\u0003\n\nIn order to estimate\nwe apply Lemmas 4.1 and 4.2. The number\nm in these Lemmas exists and N \u039b/p \u226bd 1, as it follows from (5.1) and (5.8).\nLet us choose the minimal m, that is, m \u224dd N \u039b/p. Then (pN )\u22121 m \u226ad \u039b/p2\nand m/N \u226ad \u039b/p. Therefore, using Lemma 4.1, we have\n(5.22)\n\nsup|\u03a8\u0003b (x) \u2212 \u03a8\u2032b (x)|\nx\n\n\u226ad p\n\n\u22122\n\n\u039b(det C)\n\nWe shall prove that\n(5.23)\n\n\u22121/2\n\n+\n\nZ\n\nb \u2032 (\u03c4 )| dt ,\nb \u0003 (\u03c4 ) \u2212 \u03a8\n|\u03a8\nb\nb\n|t|\n|t|\u2264t1\n\nb \u2032 (\u03c4 )| \u226ad \u03ba\u03a0|\u03c4 |N (1 + |\u03c4 |N )(1 + kak2 )\nb \u0003 (\u03c4 ) \u2212 \u03a8\n|\u03a8\nb\nb\n\n\u03c4 = tK.\n\n\f22\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nwith \u03ba = \u03ba(\u03c4 ; N, X \u0003 ). Combining (5.21)\u2013(5.23), using \u03c4 = tK and integrating inequality (5.23) with the help of Lemma 4.2, we derive (5.20).\n(\u0003)\n(\u0003 )\nLet us prove (5.23). Writing D = ZN \u2212 EZN \u2212 b, we have\n\u221a\n(\u0003)\n(\u0003)\n\u2032\nL(ZN\n\u2212 b) = L(D + N W )\nZN \u2212 b = D + EZN ,\nand\nb \u2032 (\u03c4 )| \u2264 |f1 (\u03c4 )| + |f2 (\u03c4 )|\nb \u0003 (\u03c4 ) \u2212 \u03a8\n|\u03a8\nb\nb\n\n(5.24)\nwith\n(5.25)\n\nf1 (\u03c4 ) = E e{\u03c4 Q[D +\n\n\u221a\n\nN W ]} \u2212 E e{\u03c4 Q[D]},\n(\u0003)\n\nf2 (\u03c4 ) = E e{\u03c4 Q[D + EZN ]} \u2212 E e{\u03c4 Q[D]}.\nNow we have to prove that both |f1 (\u03c4 )| and |f2 (\u03c4 )| may be estimated by\nthe right-hand side of (5.23).\n\u221a\nLet\u221aus consider f1 . We can write Q[D + N W ] = Q[D] + A + B with\nA = 2 N hQD, W i and B = N Q[W ]. Taylor's expansions of the exponent\nin (5.25) in powers of i\u03c4 B and i\u03c4 A with remainders O(\u03c4 B) and O(\u03c4 2 A2 ),\nrespectively, imply (recall that EW = 0 and Q2 = Id )\n(5.26)\n\n|f1 (\u03c4 )| \u226a \u03ba|\u03c4 |N EkW k2 + \u03ba\u03c4 2 N EkW k2 EkDk2 ,\n\nwhere \u03ba = \u03ba(\u03c4 ; N, X \u0003 ). The estimation of the remainders of these expansions is based on the splitting and conditioning techniques described in Section 9 of BG (1997a); see also Bentkus, G\u00f6tze and Zaitsev (1997). Using the\nrelations EkW k2 \u226a EkC\u22121/2 W k2 \u226ad \u03a0, \u03c3 2 = 1 and EkDk2 \u226a N (1 + kak2 ),\nwe derive from (5.26) that\n(5.27)\n\n|f1 (\u03c4 )| \u226ad \u03ba\u03a0|\u03c4 |N (1 + |\u03c4 |N )(1 + kak2 ).\n\n(\u0003)\nNote that EZN = N EX \u0003 = \u2212N EX\u0003 . Expanding the exponent e{\u03c4 Q[D +\n(\u0003)\nEZN ]}, using (5.15) and proceeding similarly to the proof of (5.27), we\nobtain\n\n(5.28)\n\n|f2 (\u03c4 )| \u226ad \u03ba\u03a0|\u03c4 |N (1 + kak).\n\nInequalities (5.24), (5.27) and (5.28) imply now (5.23).\nIt remains to estimate |\u03a8\u2032b \u2212 \u03a6b \u2212 \u0398\u2032b |. Recall that the distribution func(l)\ntions \u03a8b (x), for 0 \u2264 l \u2264 N , are defined in (4.5).\nFix an integer k, 1 \u2264 k \u2264 N . Clearly, we have\n(5.29)\n\nsup|\u03a8\u2032b (x) \u2212 \u03a6b (x) \u2212 \u0398\u2032b (x)| \u2264 I1 + I2 + I3 ,\nx\u2208R\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n23\n\nwhere\n(k)\n\nI1 = sup|\u03a8b (x) \u2212 \u03a6b (x) \u2212 (N \u2212 k)\u0398\u2032b (x)/N |,\n\n(5.30)\n\nx\u2208R\n\n(k)\n\nI2 = sup|\u03a8\u2032b (x) \u2212 \u03a8b (x)|\n\n(5.31)\n\nx\u2208R\n\nand\nI3 = sup kN \u22121 |\u0398\u2032b (x)|.\n\n(5.32)\n\nx\u2208R\n\nLet estimate I1 . Define the distributions\n)\n(\nN\nX\n\u221a\nXj\u2032 \u2208 N A ,\n\u03bc(A) = P Uk +\nj=k+1\n\n(5.33)\n\n\u221a\n\u03bc0 (A) = P{UN \u2208 N A} = P{G \u2208 A},\n\nwhere Ul = G1 + * * * + Gl . Introduce the measure \u03c7\u2032 replacing X by X \u2032 in\n(2.15). For the Borel sets A \u2282 Rd define the Edgeworth correction (to the\ndistribution \u03bc) as\n(k)\n\n\u03bc1 (A) = (N \u2212 k)N \u22123/2 \u03c7\u2032 (A)/6.\n\n(5.34)\n\nIntroduce the signed measure\n(k)\n\n(5.35)\n\n\u03bd = \u03bc \u2212 \u03bc0 \u2212 \u03bc1 .\n\nIt is easy to see that a re-normalization of random vectors implies [see\nrelations (2.14), (2.17)\u2013(2.19), (4.5) and (5.33)\u2013(5.35)]\n(k)\n\n(5.36)\n\n|\u03a8b (x) \u2212 \u03a6b (x) \u2212 (N \u2212 k)\u0398\u2032b (x)/N | = \u03bd({u \u2208 Rd : Q[u \u2212 a] \u2264 x/N })\ndef\n\n\u2264 \u03b4N = sup |\u03bd(A)|.\nA\u2282Rd\n\nLemma 5.1. Assume that d < \u221e and 1 \u2264 k \u2264 N . Then there exists a\nc(d) depending on d only and such that \u03b4N defined in (5.36) satisfies the\ninequality\n(5.37)\n\n\u03b4N \u226ad\n\nN d/2\n\u03b2\n+ d/2 exp{\u2212c(d)k/\u03b2}\nN\nk\n\nwith \u03b2 = EkC\u22121/2 X \u2032 k4 .\nAn outline of the proof. We repeat and slightly improve the proof of\nLemma 9.4 in BG (1997a); cf. the proof of Lemma 2.5 in BG (1997a). We\nshall prove (5.37) assuming that cov X = cov X \u2032 = cov G = Id . Applying it\nto C\u22121/2 X \u2032 and C\u22121/2 G, we obtain (5.37) in general case.\n\n\f24\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nWhile proving (5.37) we assume that \u03b2/N \u2264 cd and N \u2265 1/cd with a\nsufficiently small positive constant cd . Otherwise (5.37) follows from the\nobvious bounds \u03b2 \u2265 \u03c3 4 = d2 and\nZ\n1/2\nkxk3 p(x) dx \u226ad 1 + (\u03b2/N )1/2 .\n\u03b4N \u226ad 1 + (\u03b2/N )\nRd\n\nSet n = N \u2212 k. Denoting by Zj\u2032 and Uj\u2032 sums of j independent copies of X \u2032\nand G\u2032 , respectively, introduce the multidimensional characteristic functions\n\n(5.38)\n\ng(t) = E e{hN \u22121/2 t, Gi},\n\n(5.39)\n\nf (t) = E e{hN \u22121/2 t, Zn\u2032 i} = hn (t),\n\n(5.40)\n(5.41)\n\nh(t) = E e{hN \u22121/2 t, X \u2032 i},\n\nf0 (t) = E e{hN \u22121/2 t, Un\u2032 i} = gn (t),\nf1 (t) = nm(t)f0 (t)\n\nwhere m(t) =\n\n\u03bdb(t) = (f (t) \u2212 f0 (t) \u2212 f1 (t))g(\u03c1t),\n\nIt is easy to see that\n(5.42)\n\n\u03bdb(t) =\n\nZ\n\n1\nEhit, X \u2032 i3 ,\n6N 3/2\n\u03c12 = k.\n\ne{ht, xi}\u03bd(dx).\nRd\n\nUsing a truncation, we obtain\n\u221a\n(5.43)\nEkZl\u2032 / N k\u03b3 \u226a\u03b3,d 1,\n\n\u03b3 > 0, 1 \u2264 l \u2264 N.\n\nBy an extension of the proof of Lemma 11.6 in Bhattacharya and Rao\n(1986) [see also the proof of Lemma 2.5 in BG (1996)], we obtain\nZ\n(5.44)\n|\u2202 \u03b1 \u03bdb(t)| dt.\n\u03b4N \u226ad max\n|\u03b1|\u22642d Rd\n\nHere |\u03b1| = |\u03b11 | + * * * + |\u03b1d |, \u03b1 = (\u03b11 , . . . , \u03b1d ), \u03b1j \u2208 Z, \u03b1j \u2265 0. In order to\nderive (5.37) from (5.44), it suffices to prove that, for |\u03b1| \u2264 2d,\n(5.45) |\u2202 \u03b1 \u03bdb(t)| \u226ad g(c1 \u03c1t),\n\n(5.46) |\u2202 \u03b1 \u03bdb(t)| \u226ad \u03b2N \u22121 (1 + ktk6 ) exp{\u2212c2 ktk2 }\nfor ktk2 \u2264 c3 (d)N/\u03b2.\nq\nIndeed, using (5.45) and denoting T = c3 (d)N/\u03b2, we obtain\nZ\nZ\n\u03b1\ng(c1 \u03c1t) dt\n|\u2202 \u03bdb(t)| dt \u226ad\n(5.47)\n\nktk\u2265T\n\nktk\u2265T\n\n\u001a 2 2 2\u001bZ\nc \u03c1 T\nN d/2\nexp{\u2212c21 ktk2 /8} dt,\n\u226ad d exp \u2212 1\n\u03c1\n8N\nd\nR\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n25\n\nand it is easy to see that the right-hand side of (5.47) is bounded from above\nby the second summand on the right-hand side of (5.37). Similarly, using\n(5.46), we can integrate |\u2202 \u03b1 \u03bdb(t)| over ktk \u2264 T , and the integral is bounded\nfrom above by cd \u03b2/N .\nIn the proof of (5.45)\u2013(5.47) we applied standard methods of estimation\nwhich are provided in Bhattacharya and Rao (1986). In particular, we used\na Bergstr\u00f6m type identity\n(5.48) f \u2212 f0 \u2212 f1 =\n\nn\u22121\nX\nj=0\n\n(h \u2212 g \u2212 m)hj g n\u2212j\u22121 +\n\nn\u22121\nX\nj=0\n\nm\n\nj\u22121\nX\nl=0\n\n(h \u2212 g)hl gn\u2212l\u22121 ,\n\nrelations (5.38)\u2013(5.43), 1 \u2264 k \u2264 N , |\u2202 \u03b1 exp{\u2212c4 ktk2 }| \u226a\u03b1 exp{\u2212c5 ktk2 },\n\u221a\n1/2\nN /\u03b2 \u226bd 1 and y cd exp{\u2212y} \u226ad 1, for y > 0.\nApplying (5.30), (5.36) and Lemma 5.1, we get\n(5.49)\n\nI1 \u226ad\n\nN d/2\n\u03b2\n+ d/2 exp{\u2212c(d)k/\u03b2}.\nN\nk\n\nFor the estimation of I2 we shall use Lemma 5.2 which is an easy consequence of BG [(1997a), Lemma 9.3], (4.13) and (5.16).\nLemma 5.2.\n\nWe have\n\nb (l) (t)| \u226a \u03bat2 l(\u03b2 + |t|N \u03b2 + |t|N\nb \u2032 (t) \u2212 \u03a8\n|\u03a8\nb\nb\n\nwhere \u03ba = \u03ba(t; N, X \u0003 ); cf. (4.12).\n\nq\n\nN \u03b2)(1 + kak3 )\n\nfor 0 \u2264 l \u2264 N,\n\nAs in the proof of (5.22), applying Lemma 4.1 [choosing m \u224dd N (\u039b+\u03a0)/p]\nand using (3.13), we obtain\nZ\n\u22121/2\nb (k) (\u03c4 )| dt/|t|,\nb \u2032 (\u03c4 ) \u2212 \u03a8\n\u03c4 = tK.\n|\u03a8\nI2 \u226ad (\u039b + \u03a0)(det C)\n+\nb\nb\n|t|\u2264t1\n\nThe existence of such an m is ensured by (3.13), (5.1) and (5.8). Applying\nLemma 5.2 and replacing in that lemma t by \u03c4 , we have\nq\n(k)\n\u2032\n2\nb\nb\n(5.50) |\u03a8b (\u03c4 ) \u2212 \u03a8b (\u03c4 )| \u226a \u03ba\u03c4 k(\u03b2 + |\u03c4 |N \u03b2 + |\u03c4 |N N \u03b2)(1 + kak3 ).\n\nIntegrating with the help of Lemma 4.2 and using (3.13), we obtain\nq\n\u22121/2\n\u22122\nI2 \u226ad (det C)\n(\u03a0 + \u039b + kN (\u03b2 + N \u03b2)\n(5.51)\n\u00d7 (1 + (\u03a0 + \u039b)\u22121/d )(1 + kak3 )).\n\n\f26\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n3/4\n\nLet us choose k \u224dd N 1/4 \u03b2 . Such k \u2264 N exists by \u03b2 \u226bd \u03c3 4 = 1, by (5.16)\nand by assumption (5.8). Then (5.49) and (5.51) turn into\n\u001a\n\u0012 \u00131/4 \u001b\n\u0012 \u00133d/8\nN\nN\n\u03b2\n\u03b2\nI1 \u226ad\nexp \u2212cd\n\u226ad\n(5.52)\n+\nN\nN\n\u03b2\n\u03b2\nand\n\n\u22121/2\n\n(5.53)\n\nI2 \u226ad (det C)\n\n\u0012\n\n\u03a0+\u039b+\n\n\u0012\u0012\n\n\u03b2\nN\n\n\u00135/4\n\n+\n\n\u0013\n\u00d7 (1 + (\u03a0 + \u039b)\u22121/d )(1 + kak3 ) .\n\n\u0012\n\n\u03b2\nN\n\n\u00137/4 \u0013\n\nUsing (3.13), (5.8), (5.16) and (5.53), we get\n\u0013\n\u0012\n\u03b2\n3\n\u22121/2\n(5.54)\nI2 \u226ad (det C)\n\u03a0 + \u039b + (1 + kak ) .\nN\n\nFinally, by (5.8), (5.16), (5.20) and (5.32),\nk\nI3 \u226ad (\u039b1/2 + N \u22121/2 \u03a03/2 ) \u226a \u039b + \u03a0.\n(5.55)\nN\nInequalities (5.8), (5.12), (5.16), (5.18), (5.20), (5.29), (5.52), (5.54) and\n(5.55) imply now (5.7) [and, hence, (2.23)] by an application of \u03a0 + \u039b \u2264\n1. Note that, by (2.7), we have \u03a0 \u2264 \u03a03\u0003 . Together with (5.2) and (5.4),\ninequality (5.7) yields (2.22). The statement of Theorem 2.2 is proved. \u0003\n6. From probability to number theory. In Section 6 we reduce the estib b (t) to\nmation of the integrals of the modulus of characteristic functions \u03a8\nthe estimation the integrals of some theta-series. We shall use the following\nlemmas.\nLemma 6.1 [BG (1997a), Lemma 5.1]. Let L, C \u2208 Rd and let Q : Rd \u2192\nbe a symmetric linear operator. Let Z, U, V and W denote independent\nrandom vectors taking values in Rd . Denote by\nRd\n\nP (x) = hQx, xi + hL, xi + C,\n\nx \u2208 Rd ,\n\na real-valued polynomial of second order. Then\ne Ui}\ne + E e{2thQZ,\ne Ve i}.\n2|E e{tP (Z + U + V + W )}|2 \u2264 E e{2thQZ,\n\nLet \u03b4 > 0, S = {e1 , . . . , es } \u2282 Rd and let D : Rd \u2192 Rd be a linear operator.\nUsually, we take D = C\u22121/2 . Denote\n(6.1) \u0393(\u03b4; D, S) = {(z1 , . . . , zs ) : zj \u2208 Rd , kDzj \u2212 ej k \u2264 \u03b4, for all 1 \u2264 j \u2264 s}.\n\nRecall that So = {e1 , . . . , es } \u2282 Rd denotes an orthonormal system.\nLet {\u03b5jk , j = 1, 2 . . . , s; k = 1, 2 . . .}\u222a{\u03b5\u2032jk , j = 1, 2 . . . , s; k = 1, 2 . . .} be i.i.d.\nsymmetric Rademacher random variables.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n27\n\ne \u2265\nLemma 6.2. Assume that Q2 = Id and that the condition P (\u03b4, S, DX)\np holds with some p > 0 and \u03b4 > 0. Write m = \u230apN /(5s)\u230b. Then, for any\n0 < A \u2264 B, b \u2208 Rd and \u03b3 > 0, we have\nZ B\nb b (t)| dt \u2264 I + c\u03b3 (s)(pN )\u2212\u03b3 log B ,\n|\u03a8\n(6.2)\n|t|\nA\nA\nwith\n\n(6.3)\n\nI = sup sup\n\u0393 b\u2208Rd\n\nPm\n\nZ\n\nB\n\nA\n\np\n\n\u03c6b (t/4)\n\ndt\n,\n|t|\n\ndef\n\n\u03c6b (t) = |E e{tQ[Y + b]}|2 ,\n\nwhere Y = k=1 Uk denote a sum of independent (non i.i.d.) vectors Uk =\nP\ns\nj=1 \u03b5jk zjk , and sup\u0393 is taken over all {(z1k , . . . , zsk ) \u2208 \u0393(\u03b4; D, S), k =\n1, . . . , m}.\nLemma 6.2 is an analogue of Corollary 6.3 from BG (1997a). Its proof is\neven simpler than that in BG (1997a). Therefore it is omitted.\ne \u2265\nLemma 6.3. Assume that Q2 = Id and that the condition P (\u03b4, S, DX)\np holds with some p > 0 and \u03b4 > 0. Let\ndef\n\n(6.4)\n\nn = \u230apN/(16s)\u230b \u2265 1.\n\nThen, for any 0 < A \u2264 B, b \u2208 Rd and \u03b3 > 0,\nZ Bq\nZ B\nb b (t)| dt \u2264 c\u03b3 (s)(pN )\u2212\u03b3 log B + sup\nf, W\nf \u2032 i/2} dt ,\n(6.5)\n|\u03a8\nE e{thQW\n|t|\nA\n|t|\n\u0393\nA\nA\nand for any fixed t \u2208 R,\n(6.6)\n\nb b (t)| \u2264 c\u03b3 (s)(pN )\u2212\u03b3 + sup\n|\u03a8\n\u0393\n\nq\n\nf, W\nf \u2032 i/2},\nE e{thQW\n\nwhere W = V1 + * * * + Vn and W \u2032 = V1\u2032 + * P\n* * + Vn\u2032 are independent\nP sums of\nindependent copies of random vectors V = sj=1 \u03b5j1 zj and V \u2032 = sj=1 \u03b5\u2032j1 zj\u2032 ,\nand sup\u0393 is taken over all (z1 , . . . , zs ), (z1\u2032 , . . . , zs\u2032 ) \u2208 \u0393(\u03b4; D, S).\nNote that this lemma will be proved for general S, but in this paper we\nneed S = So only. Moreover, a more careful estimation of binomial probabilities could allow us to replace c\u03b3 (s)(pN )\u2212\u03b3 in (6.2), (6.5) and (6.6) by\nc(s) exp{\u2212cpN }; see, for example, Nagaev and Chebotarev (2005). However,\nwe do not need to use this improvement.\nProof of Lemma 6.3. Inequality (6.6) is an analogue of the statement\nof Lemma 7.3 from BG (1997a). Its proof is even simpler than that in BG\n(1997a). Therefore it is omitted.\n\n\f28\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nLet us show that\nZ Bq\nZ B\nB\ndt\n\u2212\u03b3\nb\nf, W\nf \u2032 i/2} dt ,\nE e{thQW\n(6.7)\n|\u03a8b (t)| \u2264 c\u03b3 (s)(pN ) log + sup\n|t|\nA\n|t|\n\u0393\nA\nA\n\n+ * * * + Vn\u2032 are independent\nwhere W = V1 + * * * + Vn and W \u2032 = V1\u2032 P\nP sums \u2032 of\n,\nindependent (non i.i.d.) vectors Vk = sj=1 \u03b5jk zjk , and Vk\u2032 = sj=1 \u03b5\u2032jk zjk\n\u2032\n\u2032\nrespectively, while sup\u0393 is taken over all {(z1k , . . . , zsk ), (z1k , . . . , zsk ) \u2208 \u0393(\u03b4;\nD, S), k = 1, . . . , n}.\nComparing (6.5) and (6.7), we see that inequality (6.7) is related to sums\nof non i.i.d. vectors {Vj } and {Vj\u2032 } while inequality (6.5) deals with i.i.d.\nvectors. Nevertheless, we derive (6.5) from (6.7).\nWhile proving (6.7) we can assume that pN \u2265 cs with a sufficiently large\nconstant cs , since otherwise (6.7) is obviously\nP valid.\nLet \u03c6b (t) be defined inP\n(6.3), where Y = m\nk=1 Uk is a sum of independent\n(non i.i.d.) vectors Uk = sj=1 \u03b5jk zjk , where {(z1k , . . . , zsk ) \u2282 \u0393(\u03b4; D, S), k =\n1, . . . , m}, m = \u230apN /(5s)\u230b.\nWe shall apply the symmetrization Lemma 6.1. Split Y = T + T1 + T2\ninto sums of independent sums of independent summands so that each of\nthe sums T , T1 and T2 contains n = \u230apN/(16s)\u230b independent summands\nUj . Such an n exists since pN \u2265 cs with a sufficiently large cs . Lemma 6.1\nimplies that\n(6.8)\n2\u03c6b (t) \u2264 E e{2thQTe, Te1 i} + E e{2thQTe, Te2 i}.\nInequality (6.7) follows now from (6.8) and Lemma 6.2.\n\u2032\n\u2032\n\u2032\nLet now W = V1 + * * * + VP\nn and W = V1 + * * * + VP\nn be independent sums of\ns\n\u2032\n\u2032 , respectively,\nindependent vectors Vk = j=1 \u03b5jk zjk , and Vk = sj=1 \u03b5\u2032jk zjk\n\u2032 , . . . , z \u2032 ) \u2208 \u0393(\u03b4; D, S), k = 1, . . . , n}.\nwith {(z1k , . . . , zsk ), (z1k\nsk\nUsing that all random vectors Vek are symmetrized and have nonnegative characteristic functions and applying H\u00f6lder's inequality, we obtain, for\neach t,\n!\nn\nY\nf, W\nf \u2032 i} = E f \u2032\nf \u2032 i}\nE e{thQW\n(6.9)\nE e e{thQVek , W\nVk\n\nW\n\nk=1\n\n(6.10)\n\n(6.11)\n\n\u2264\n=\n\nn\nY\n\nk=1\nn\nY\n\nk=1\n\n(6.12)\n\n=\n\nn\nY\n\nk=1\n\nf\u2032\n\ne\nEW\nf \u2032 (EVek e{thQVk , W i})\nf\u2032\n\nn\n\n!1/n\n\ne\nEW\nf \u2032 (ETek e{thQTk , W i})\nf\u2032\n\n!1/n\n\nE e{thQTek , W i}\n\n,\n\n!1/n\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n29\n\ndef P\nwhere Tek = nl=1 Vekl denotes a sum of i.i.d. copies Vekl of Vek which are\nindependent of all other random vectors and variables.\nf \u2032 i} instead\nRepeating the steps (6.9)\u2013(6.12) for each factor E e{thQTek , W\nf, W\nf \u2032 i} on the right-hand side separately, we get\nof the expectation E e{thQW\nP\ndef\n(with Tei\u2032 = nl=1 Veil\u2032 , where Veil\u2032 are i.i.d. copies of Vei\u2032 independent of all other\nrandom vectors)\n!1/n2\nn\nn Y\nY\nf, W\nf \u2032 i} \u2264\n(6.13)\n.\nE e{thQTek , Te\u2032 i}\nE e{thQW\ni\n\nk=1 i=1\n\nThus, using (6.13) and the arithmetic-geometric mean inequality, we have\nZ Bq\nf, W\nf \u2032 i/2} dt\nE e{thQW\n|t|\nA\n!1/2n2\nZ B Y\nn Y\nn\ndt\nE e{thQTek , Tei\u2032 i/2}\n\u2264\n|t|\nA\nk=1 i=1\n(6.14)\nn\nn Z\n1 XX B\ndt\n\u2264 2\n(E e{thQTek , Tei\u2032 i/2})1/2\nn\n|t|\nk=1 i=1 A\nZ Bq\ndt\nE e{thQTe, Te\u2032 i/2} ,\n\u2264 sup\n|t|\n\u0393\nA\n\n* + Un\u2032 are independent\nwhere T = U1 + * * * + Un and T \u2032 = U1\u2032 + * *P\nP sums of\nindependent copies of random vectors U = sj=1 \u03b5j1 z1 and U \u2032 = sj=1 \u03b5\u2032j1 z1\u2032 ,\nand sup\u0393 is taken over all (z1 , . . . , zs ), (z1\u2032 , . . . , zs\u2032 ) \u2208 \u0393(\u03b4; D, S). Inequalities\n(6.7) and (6.14) imply now the statement of the lemma. \u0003\nThe following Lemma 6.4 provides a Poisson summation formula.\nLemma 6.4. Let Re z > 0, a, b \u2208 Rs and S : Rs \u2192 Rs be a positive definite\nsymmetric nondegenerate linear operator. Then\nX\nexp{\u2212zS[m + a] + 2\u03c0ihm, bi}\nm\u2208Zs\n\n= (det(S/\u03c0))\u22121/2 z \u2212s/2 exp{\u22122\u03c0iha, bi}\n\u001b\n\u001a 2\nX\n\u03c0 \u22121\n\u00d7\nexp \u2212 S [l + b] \u2212 2\u03c0iha, li ,\nz\ns\nl\u2208Z\n\nwhere\n\nS\u22121 : Rs\n\n\u2192 Rs\n\ndenotes the inverse positive definite operator for S.\n\nProof. See, for example, Fricker (1982), page 116, or Mumford (1983),\npage 189, formula (5.1); and page 197, formula (5.9). \u0003\n\n\f30\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nLet the conditions of Lemma 6.3 be satisfied. Introduce one-dimensional\nlattice probability distributions Hn = L(\u03ben ) with integer valued \u03ben setting\nP{\u03ben = k} = An n\u22121/2 exp{\u2212k2 /2n}\n\nfor k \u2208 Z.\n\nIt is easy to see that An \u224d 1. Moreover, by Lemma 6.4,\nb n (t) \u2265 0\nH\n\n(6.15)\n\nfor all t \u2208 R.\n\nIntroduce the s-dimensional random vector \u03b6n having as coordinates independent copies of \u03ben . Then, for m = (m1 , . . . , ms ) \u2208 Zs , we have\n(6.16)\n\ndef\n\nq(m) = P{\u03b6n = m} = Asn n\u2212s/2 exp{\u2212kmk2 /2n}.\n\nLemma 6.5. Let W = V1 + * * * + Vn and W \u2032 = V1\u2032 + * * * + Vn\u2032 denote independent sums of independent copies of random vectors V and V \u2032 such\nthat\nV = \u03b511 z1 + * * * + \u03b5s1 zs ,\n\nV \u2032 = \u03b5\u203211 z1\u2032 + * * * + \u03b5\u2032s1 zs\u2032 ,\n\nwith some zj , zj\u2032 \u2208 Rd . Introduce the matrix Bt = {bij (t) : 1 \u2264 i, j \u2264 s} with\nbij (t) = thQzi , zj\u2032 i. Then\nf, W\nf \u2032 i/4} \u226as E e{hBt \u03b6n , \u03b6n\u2032 i} + exp{\u2212cn}\nE e{thQW\n\nfor all t \u2208 R,\n\nwhere \u03b6n\u2032 are independent copies of \u03b6n and c is a positive absolute constant.\nProof. Without loss of generality, we assume that n \u2265 c1 , with a sufficiently large absolute constant c1 . Consider the random vector Y = (e\n\u03b51 , . . . ,\n\u03b5es ) \u2208 Rs with coordinates which are symmetrizations of i.i.d. Rademacher\nrandom variables. Let R = (R1 , . . . , Rs ) and T denote independent sums of\nn independent copies of Y /2. Then we can write\n(6.17)\n\nf, W\nf \u2032 i/4} = E e{hBt R, T i}\nE e{thQW\n\nfor all t \u2208 R.\n\nNote that the scalar product h*, *i in E e{hBt R, T i} means the scalar product\nof vectors in Rs . In order to estimate this expectation, we write it in the\nform\n\n(6.18)\n\nE e{hBt R, T i} = EER e{hBt R, T i}\nX\nX\n=\np(m)\np(m) e{hBt m, mi},\nm\u2208Zs\n\nm\u2208Zs\n\nwith summing over m = (m1 , . . . , ms ) \u2208 Zs , m = (m1 , . . . , ms ) \u2208 Zs and\n\u0012\n\u0013\ns\ns\nY\nY\n2n\n\u22122n\n2\nP{Rj = mj } =\n(6.19) p(m) = P{R = m} =\n,\nmj + n\nj=1\n\nj=1\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n31\n\nif max1\u2264j\u2264s |mj | \u2264 n and p(m) = 0 otherwise. Clearly, for fixed T = m,\nX\n(6.20)\nER e{hBt R, T i} =\np(m) e{hBt m, mi} \u2265 0\nm\u2208Zs\n\nis a value of the characteristic function of symmetrized random vector Bt R.\nUsing Stirling's formula, it is easy to show that there exist positive absolute\nconstants c2 and c3 such that\n(6.21)\n\nP{Rj = mj } \u226a n\u22121/2 exp{\u2212m2j /2n}\n\nfor |mj | \u2264 c2 n\n\nand\n(6.22)\n\nP{|Rj | \u2265 c2 n} \u226a exp{\u2212c3 n}.\n\nUsing (6.18)\u2013(6.22), we obtain\nX\nX\np(m) e{hBt m, mi} + exp{\u2212c3 n}\nq(m)\nE e{hBt R, T i} \u226as\nm\u2208Zs\n\nm\u2208Zs\n\n=\n(6.23)\n\nX\n\nm\u2208Zs\n\nX\n\np(m)\n\nq(m) e{hBt m, mi} + exp{\u2212c3 n}\n\nm\u2208Zs\n\n= EE\u03b6n e{hBt R, \u03b6n i} + exp{\u2212c3 n}\n\n= E e{hBt R, \u03b6n i} + exp{\u2212c3 n}.\n\nNow we repeat our previous arguments, noting that\nX\n(6.24)\nq(m) e{hBt R, mi} \u2265 0\nE\u03b6n e{hBt R, \u03b6n i} =\nm\u2208Zs\n\nis a value of the nonnegative characteristic function of the random vector\n\u03b6n ; see (6.15). Using again (6.21) and (6.22), we obtain\n(6.25)\n\nE e{hBt R, \u03b6n i} \u226as E e{hBt \u03b6n , \u03b6n\u2032 i} + exp{\u2212c3 n}.\n\nRelations (6.17), (6.23) and (6.25) imply the statement of the lemma. \u0003\nLet us estimate the expectation E e{hBt \u03b6n , \u03b6n\u2032 i} under the conditions of\nLemmas 6.3 and 6.5, assuming that s = d, D = C\u22121/2 , \u03b4 \u2264 1/(5s), n \u2265 c4 ,\nwhere c4 is a sufficiently large absolute constant, and (z1 , . . . , zs ), (z1\u2032 , . . . , zs\u2032 ) \u2208\n\u0393(\u03b4; D, S), that is,\n(6.26) kC\u22121/2 zj \u2212 ej k \u2264 \u03b4,\n\nkC\u22121/2 zj\u2032 \u2212 ej k \u2264 \u03b4\n\nfor 1 \u2264 j \u2264 s,\n\nwith an orthonormal system S = So = {e1 , . . . , es } involved in the conditions\nof Lemma 6.3. We can rewrite E e{hBt \u03b6n , \u03b6n\u2032 i} as\nX\nX\nE e{hBt \u03b6n , \u03b6n\u2032 i} =\nq(m)\nq(m) e{hBt m, mi}.\nm\u2208Zs\n\nm\u2208Zs\n\n\f32\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nThus, by (6.16),\n\u2212s\nE e{hBt \u03b6n , \u03b6n\u2032 i} = A2s\nn n\n\nX X\n\nm\u2208Zs m\u2208Zs\n\nDenote\n(6.27)\n\nr=\n\nexp{ihBt m, mi \u2212 kmk2 /2n \u2212 kmk2 /2n}.\n\u221a\n\n2\u03c0 2 n.\n\nApplying Lemma 6.4 with S = Is , z = 1/2n, a = 0, b = (2\u03c0)\u22121 Bt m and using\nthat An \u224d 1, we obtain\nE e{hBt \u03b6n , \u03b6n\u2032 i}\n\n(6.28)\n\n\u226as n\u2212s/2\n\u226as r \u2212s\n\nX\n\nl,m\u2208Zs\n\nX\n\nm,m\u2208Zs\n\nexp{\u22122\u03c0 2 nkl + (2\u03c0)\u22121 Bt mk2 \u2212 kmk2 /2n}\n\nexp{\u2212r 2 km \u2212 tVmk2 \u2212 kmk2 /r 2 },\n\nwhere V : Rs \u2192 Rs is the operator with matrix\n(6.29)\n\nV = (2\u03c0)\u22121 B1 .\n\nNote that the right-hand side of (6.28) may be considered as a theta-series.\nDenote yk = C\u22121/2 zk , 1 \u2264 k \u2264 s. Let Y be the (s \u00d7 s)-matrix with entries\nhej , yk i, where index j is the number of the row, while k is the number of\ndef\n\nthe column. Then the matrix F = Y\u2217 Y has entries hyj , yk i. Here Y\u2217 is the\ntransposed matrix for Y. According to (6.26), we have\n\n(6.30)\n\nkyj \u2212 ej k \u2264 \u03b4\n\nfor 1 \u2264 j \u2264 s.\n\nLet us show that [cf. BG (1997a), proof of Lemma 7.4]\n(6.31)\n\nkYk \u2264 3/2\n\nand\n\nkY\u22121 k \u2264 2.\n\nSince So = {e1 , e2 , . . . , es } is an orthonormal system, inequalities (6.30) imply\nthat Y = Is + A with some matrix A = {aij } such that |aij | \u2264 \u03b4. Thus, we\nhave kAk \u2264 kAk2 \u2264 s\u03b4, where kAk2 denotes the Hilbert\u2013Schmidt norm of\nthe matrix A. Therefore, the condition \u03b4 \u2264 1/(5s) implies kAk \u2264 1/2 and\ninequalities (6.31).\nThe matrix F is symmetric and positive definite. Its determinant is the\nproduct of eigenvalues which [by (6.31)] are bounded from above and from\nbelow by some absolute positive constants. Moreover,\n(6.32)\n\n(det Y)2 = (det Y\u2217 )2 = det F \u224ds 1 \u224d kFk \u224d kYk.\n\nDefine the matrices Y and F, replacing zj by zj\u2032 in the definition of Y and\nF. Similarly to (6.32), one can show that\n(6.33)\n\n\u2217\n\n(det Y)2 = (det Y )2 = det F \u224ds 1 \u224d kFk \u224d kYk.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n33\n\nLet G and G be the (s \u00d7 s)-matrices with entries hej , Qzk i and hej , zk\u2032 i,\nrespectively. Then, clearly, G = QC1/2 Y and G = C1/2 Y. Therefore,\n(6.34)\n\nB1 = G\u2217 G = Y\u2217 C1/2 QC1/2 Y.\n\nMoreover, Q2 = Id implies that | det Q| = 1 and kQk = 1. Using relations\n(6.29) and (6.32)\u2013(6.34), we obtain\n(6.35)\n\n| det V| \u224ds | det B1 | \u224ds det C\n\nand\n(6.36)\n\nkVk \u226a kB1 k \u226a kCk \u226a \u03c312 .\n\n7. Some facts from number theory. In Section 7, we consider some facts\nof the geometry of numbers; see Davenport (1958) or Cassels (1959). They\nwill help us to estimate the integrals of the right-hand side of inequality (6.28). See G\u00f6tze and Margulis (2010) or G\u00f6tze and Zaitsev (2010) for a\nmore detailed version of this section.\nLet e1 , e2 , . . . , ed be linearly independent vectors in Rd . The set\n)\n( d\nX\n(7.1)\nnj ej : nj \u2208 Z, j = 1, 2, . . . , d\n\u039b=\nj=1\n\nis called the lattice with basis e1 , e2 , . . . , ed . The determinant det(\u039b) of a\nlattice \u039b is the modulus of the determinant of the matrix formed from the\nvectors e1 , e2 , . . . , ed . If \u039b = AZd , where A is a nondegenerate linear operator,\nthen det(\u039b) = | det A|.\nLet F : Rd \u2192 [0, \u221e) denote a norm on Rd . The successive minima M1 \u2264\n* * * \u2264 Md of F with respect to a lattice \u039b \u2282 Rd are defined as follows: Mj is\nthe infimum of \u03bb > 0 such that the set {m \u2208 \u039b : F (m) < \u03bb} contains j linearly independent vectors. The following Lemma 7.1 is proved by Davenport\n[(1958), Lemma 1] for \u039b = Zd ; see also G\u00f6tze and Margulis (2010).\nLemma 7.1. Let M1 \u2264 * * * \u2264 Md be the successive minima of a norm F\nwith respect to a lattice \u039b \u2282 Rd . Denote Md+1 = \u221e. Suppose that 1 \u2264 j \u2264 d\nand Mj \u2264 b \u2264 Mj+1 , for some b > 0. Then\n(7.2) #{m = (m1 , . . . , md ) \u2208 Zd : F (m) < b} \u224dd bj (M1 * M2 * * * Mj )\u22121 .\nRepresenting \u039b = AZd , we see that the lattice \u039b = Zd may be replaced in\nLemma 7.1 by any lattice \u039b \u2282 Rd .\nLemma 7.2. Let Fj (m), j = 1, 2, be some norms in Rd and M1 \u2264 * * * \u2264\nMd and N1 \u2264 * * * \u2264 Nd be the successive minima of F1 with respect to a lattice\n\n\f34\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\n\u039b1 and of F2 with respect to a lattice \u039b2 , respectively. Let C > 0. Assume\nthat Mk \u226bd CF2 (nk ), k = 1, 2, . . . , d, for some linearly independent vectors\nn1 , n2 , . . . , nd \u2208 \u039b2 . Then\n(7.3)\n\nMk \u226bd CNk ,\n\nk = 1, . . . , d.\n\nLemma 7.3. Let \u039b be a lattice in Rd and let cj (d), j = 1, 2, 3, be positive\nquantities depending on d only. Let F (*) be a norm in Rd such that F (*) \u224dd\nk * k. Then\nX\nX\nexp{\u2212c1 (d)kvk2 } \u224dd\nexp{\u2212c2 (d)(F (v))2 }\n\n(7.4)\n\nv\u2208\u039b\n\nv\u2208\u039b\n\n\u224dd #{v \u2208 \u039b : F (v) < c3 (d)}.\n\nFor a lattice \u039b \u2282 Rd and 1 \u2264 l \u2264 d, we define its \u03b1l -characteristics by\ndef\n\n(7.5) \u03b1l (\u039b) = sup{|det(\u039b\u2032 )|\u22121 : \u039b\u2032 is a l-dimensional sublattice of \u039b}.\nDenote\ndef\n\n(7.6)\n\n\u03b1(\u039b) = max \u03b1l (\u039b).\n1\u2264l\u2264d\n\nLemma 7.4. Let F (*) be a norm in Rd such that F (*) \u224dd k * k. Let c(d) be\na positive quantity depending on d only. Let M1 \u2264 * * * \u2264 Md be the successive\nminima of F with respect to a lattice \u039b \u2282 Rd . Then\n(7.7)\n\nMoreover,\n(7.8)\n\n\u03b1l (\u039b) \u224dd (M1 * M2 * * * Ml )\u22121 ,\n\nl = 1, . . . , d.\n\n\u03b1(\u039b) \u224dd #{v \u2208 \u039b : kvk < c(d)},\n\nprovided that M1 \u226ad 1.\n\nLemma 7.4 is an easy consequence of the following lemma formulated\nin proposition (page 517) and remark (page 518) in Lenstra, Lenstra and\nLov\u00e1sz (1982).\nLemma 7.5. Let M1 \u2264 * * * \u2264 Md be the successive minima of the standard\nEuclidean norm with respect to a lattice \u039b \u2282 Rd . Then there exists a basis\ne1 , e2 , . . . , ed of \u039b such that\n(7.9)\nMoreover,\n(7.10)\n\nMl \u224dd kel k,\n\ndet(\u039b) \u224dd\n\nl = 1, . . . , d.\nd\nY\nl=1\n\nkel k.\n\n\f35\n\nEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n8. From number theory to probability. In Section 8, we use numbertheoretical results of Section 7 to estimate integrals of the right-hand side\nof (6.28). Recall that we have assumed the conditions of Lemmas 6.3 and 6.5,\ns = d, D = C\u22121/2 , \u03b4 \u2264 1/(5s), n \u2265 c4 and (6.15), for an orthonormal system\nS = So . The notation SL(d, R) is used below for the set of all (d \u00d7 d)-matrices\nwith real entries and determinant 1.\nIntroduce the matrices\n\u0012\n\u0013\nrIs\nOs\ndef\nDr =\n(8.1)\n\u2208 SL(2s, R),\nr > 0,\nOs r \u22121 Is\n\u0012\n\u0013\nIs \u2212tIs\ndef\nKt =\n(8.2)\n,\nt \u2208 R,\ntIs\nIs\n\u0012\n\u0013\nIs \u2212tIs\ndef\nUt =\n(8.3)\n\u2208 SL(2s, R),\nt \u2208 R,\nOs\nIs\nand the lattices\n(8.4)\n(8.5)\n\n\u0012\n\n\u0013\n\nZ2s ,\n\n\u039bj = Dj Uj \u22121 \u039b =\n\njIs\nOs\n\ndef\n\n\u039b=\n\nIs\nOs\n\nOs\nV0\n\n\u0012\n\n\u2212V0\nj \u22121 V0\n\n\u0013\n\nZ2s ,\n\nj = 1, 2, . . . ,\n\nwhere\nV0 = \u03c31\u22122 V\n\n(8.6)\n\nand the matrix V is defined in (6.29). Below we use the following simplest\nproperties of these matrices:\n(8.7)\n\nDa Db = Dab ,\n\nUa Ub = Ua+b\n\nand Da Ub = Ua2 b Da\nfor a, b > 0.\n\nLet kxk\u221e = max1\u2264j\u2264d |xj |, for x = (x1 , . . . , xd ) \u2208 Rd . Let Mj,t , j = 1, 2, . . . ,\n2s, be the successive minima of the norm k * k\u221e with respect to the lattice\n\u0012\n\u0013\nrIs \u2212rtV\ndef\n\u039et =\n(8.8)\nZ2s .\nOs r \u22121 Is\n\nMoreover, simultaneously, Mj,t are the successive minima of the norm F \u2217 (*)\ndefined for (m, m) \u2208 R2s , m, m \u2208 Rs , by\n(8.9)\n\ndef\n\nF \u2217 ((m, m)) = max{kmk\u221e , \u03c312 kV\u22121 mk\u221e }\n\nwith respect to the lattice\n\u0012\n\u0013\nrIs\n\u2212rtV\ndef\n(8.10) \u03a9t =\nZ2s = Dr Uu \u039b\nOs \u03c31\u22122 r \u22121 V\n\ndef\n\nwhere u = \u03c312 t.\n\n\f36\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nUsing Lemmas 7.2 and 7.5 and the equality det(\u039et ) = 1, it is easy to show\nthat\n(8.11)\n\nM1,t \u226as 1.\n\n\u2217 be the successive minima of the Euclidean norm with respect to\nLet Mj,t\nthe lattice \u03a9t . Note that, according to (6.36) and (8.9),\n\nk * k \u226as F \u2217 (*).\n\n(8.12)\n\nUsing (8.12) and Lemma 7.2, we obtain\n(8.13)\n\n\u2217\nMj,t\n\u226as Mj,t ,\n\nj = 1, . . . , 2s.\n\nAccording to Lemma 7.4,\n(8.14)\n\n\u03b1(\u039et ) \u226as \u03b1(\u03a9t ).\n\nLet us estimate \u03b1(\u03a9t ) assuming that r \u2265 1 and (for a moment) t = \u03c31\u22122 r \u22121 .\nIn this case\n\u0012\n\u0013\nrIs \u2212V0\n\u03a9t =\n(8.15)\nZ2s .\nOs r \u22121 V0\nBy relation (7.8) of Lemma 7.4, we have\n(8.16)\n\n\u03b1(\u03a9t ) \u224ds #{v \u2208 \u03a9t : kvk < 1/2} = #K,\n\nwhere\n(8.17)\n\nK = {v = (m, m) \u2208 Z2s : m, m \u2208 Zs ,\nkrm \u2212 V0 mk2 + kr \u22121 V0 mk2 < 1/4}.\n\nLet us estimate from above the right-hand side of (8.16). If v = (m, m) \u2208 K,\nthen\n1 r\nrkmk \u2264 krm \u2212 V0 mk + kV0 mk < + \u2264 r.\n(8.18)\n2 2\nHence m = 0 and kV0 mk \u2264 1/2. It remains to estimate the quantity\n(8.19)\n\ndef\n\nR = #{m \u2208 Zs : kV0 mk < 1} \u2265 #K.\n\nLet N1 \u2264 * * * \u2264 Ns be the successive minima of the Euclidean norm with\nrespect to the lattice V0 Zs . Let e1 , e2 , . . . , es be the standard orthonormal\nbasis of Zs . By (6.36) and (8.6), we have kV0 ej k \u2264 1, j = 1, 2, . . . , s. Therefore, using Lemma 7.2, we see that N1 \u2264 * * * \u2264 Ns \u2264 1. By (6.35), (8.6), (8.19)\nand by Lemmas 7.1, 7.2 and 7.5,\n(8.20)\n\nR \u224ds (N1 * N2 * * * Ns )\u22121 \u224ds (det V0 )\u22121 \u224ds \u03c312s (det C)\u22121 .\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n37\n\nHence, using (8.16), (8.19) and (8.20), we conclude that\n(8.21)\n\n\u03b1(\u03a9t ) \u226as \u03c312s (det C)\u22121\n\nfor r \u2265 1 and t = \u03c31\u22122 r \u22121 .\n\nLet now t \u2208 R be arbitrary. By (8.8), (8.11), (8.14) and by Lemmas 7.1,\n7.3 and 7.4,\nX\nX\nexp{\u2212kvk2 }\nexp{\u2212r 2 km \u2212 tVmk2 \u2212 kmk2 /r 2 } =\nm,m\u2208Zs\n\n(8.22)\n\nv\u2208\u039et\n\ndef\n\n\u226as Rt = #{v \u2208 \u039et : kvk < 1}\n\u226as \u03b1(\u039et ) \u226as \u03b1(\u03a9t ).\n\nNow, by (6.28), (8.10) and (8.22), we have\n(8.23) E e{hBt \u03b6n , \u03b6n\u2032 i} \u226as r \u2212s \u03b1(\u03a9t ) = r \u2212s \u03b1(Dr Uu \u039b)\n\nwhere u = \u03c312 t.\n\nLet us estimate the quantity Rt , t \u2208 R, defined in (8.22) assuming that\nr \u2265 1 and |rt| \u2264 c\u2217s \u03c31\u22122 , where c\u2217s \u2265 1 is an arbitrary quantity depending on\ns only. By Lemma 7.3, we have\n(8.24)\n\nRt \u224ds #K0 ,\n\nwhere\ndef\n\n(8.25)\n\nK0 = {v = (m, m) \u2208 Z2s : m, m \u2208 Zs ,\nkrm \u2212 rtVmk2 + kr \u22121 mk2 < (2c\u2217s )\u22122 }.\n\nIf v = (m, m) \u2208 K0 , r \u2265 1 and |rt| \u2264 c\u2217s \u03c31\u22122 , then, by (6.36) and (8.25),\n(8.26)\n\nrkmk \u2264 krm \u2212 rtVmk + |rt|kVmk <\n\n1 r\n+ \u2264 r.\n2 2\n\nHence m = 0 and |rt|kVmk \u2264 (2c\u2217s )\u22121 < 1. It remains to estimate the quantity\n(8.27)\n\ndef\n\nS = #{m \u2208 Zs : |rt|kVmk < 1} \u2265 #K0 .\n\nLet P1 \u2264 * * * \u2264 Ps be the successive minima of the Euclidean norm with\nrespect to the lattice |rt|VZs . Let e1 , e2 , . . . , es be the standard orthonormal\nbasis of Zs . By (6.36), we have k|rt|Vej k \u226as 1, j = 1, 2, . . . , s. Therefore,\nusing Lemma 7.2, we see that P1 \u2264 * * * \u2264 Ps \u226as 1. By (6.35), (8.27) and\nLemmas 7.1 and 7.5,\n(8.28)\n\nS \u224ds (P1 * P2 * * * Ps )\u22121 \u224ds (det(|rt|V))\u22121 \u224ds |rt|\u2212s (det C)\u22121 .\n\nHence, using (8.24), (8.27) and (8.28), we conclude that\n(8.29)\n\nRt \u226as |rt|\u2212s (det C)\u22121\n\nfor r \u2265 1 and |rt| \u2264 c\u2217s \u03c31\u22122 .\n\n\f38\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nNow, by (6.28), (8.22) and (8.29), we have\n(8.30)\n\nE e{hBt \u03b6n , \u03b6n\u2032 i} \u226as r \u2212s Rt\n\u226as r \u22122s |t|\u2212s (det C)\u22121\n\nfor r \u2265 1 and |rt| \u2264 c\u2217s \u03c31\u22122 .\n\nIt is easy to verify that\nZ \u03c3\u22122 r\u22121\np\n1\ndt\nr \u22122s |t|\u2212s (det C)\u22121 \u226as r \u22122 \u03c31s (det C)\u22121/2\n(8.31)\n\u22122 \u22122+4/s\nt\ncs \u03c31 r\n\nfor any cs depending on s only. Note that \u03c31s (det C)\u22121/2 \u2265 1. Using (8.23),\n(8.31) and Lemmas 6.3 and 6.5, we derive the following lemma.\nLemma 8.1. Let the conditions of Lemma 6.3 be satisfied with s = d, D =\nC\u22121/2 , \u03b4 \u2264 1/(5s) and with an orthonormal system S = So = {e1 , . . . , es } \u2282\nRd . Let cs be an arbitrary quantity depending on s only. Then, for any b \u2208 Rd\nand r \u2265 1,\nZ \u03c3\u22122\n1\nb b (t/2)| dt\n|\u03a8\nt\ncs \u03c31\u22122 r \u22122+4/s\n(8.32)\nZ 1\ndu\n\u22121 s\n\u22121/2\n\u2212s/2\n\u226as (pN ) \u03c31 (det C)\n+r\nsup\n(\u03b1(Dr Uu \u039b))1/2 ,\nu\n\u0393\nr \u22121\n\nwhere r, \u03b1(*), Dr Ut and the lattice \u039b are defined in relations (6.4), (6.27),\n(6.29), (7.5), (7.6), (8.1), (8.3) and (8.4) and in Lemma 6.5. The sup\u0393\nmeans here the supremum over all possible values of zj , zj\u2032 \u2208 Rd (involved in\nthe definition of matrices Bt and V) such that\n(8.33) kC\u22121/2 zj \u2212 ej k \u2264 \u03b4,\n\nkC\u22121/2 zj\u2032 \u2212 ej k \u2264 \u03b4\n\nfor 1 \u2264 j \u2264 s.\n\nMoreover, for any b \u2208 Rd , r \u2265 1 and \u03b3 > 0 and any fixed t \u2208 R satisfying\n|rt| \u2264 c\u2217s \u03c31\u22122 , where c\u2217s \u2265 1 is an arbitrary quantity depending on s only, we\nhave\nb b (t)| \u226a\u03b3,s (pN )\u2212\u03b3 + r \u2212s |t|\u2212s/2 (det C)\u22121/2 .\n(8.34)\n|\u03a8\nLet v = (m, m) \u2208 R2s , m, m \u2208 Rs and t \u2208 R. Then\n\n(8.35)\n\nm + tm = (1 + t2 )m + t(m \u2212 tm).\n\nEquality (8.35) implies that\n(8.36)\nHence,\n(8.37)\n\nkm + tmk \u226as kmk + km \u2212 tmk\n\nfor |t| \u226as 1.\n\nrkm \u2212 tmk + r \u22121 km + tmk \u226as rkm \u2212 tmk + r \u22121 kmk\nfor r \u226b 1, |t| \u226as 1.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n39\n\nAccording to (8.1)\u2013(8.3), we have\nDr Ut v = (r(m \u2212 tm), r \u22121 m)\n\n(8.38)\n\nand\n\nDr Kt v = (r(m \u2212 tm), r \u22121 (m + tm)).\n\nIt is clear that the operators Dr Ut and Dr Kt are invertible. Therefore, using\n(8.37) and (8.38) and applying Lemmas 7.2 and 7.4, we derive the inequality\n(8.39)\n\n\u03b1(Dr Ut \u03a9) \u226as \u03b1(Dr Kt \u03a9)\n\nfor r \u226b 1, |t| \u226as 1,\n\nwhich is valid for any lattice \u03a9 \u2282 R2s .\nLet T be the permutation (2s \u00d7 2s)-matrix which permutes the rows of a\n(2s \u00d7 2s)-matrix A so that the new order (corresponding to the matrix TA)\nis\n1, s + 1, 2, s + 2, . . . , s, 2s.\nNote that the operator T is isometric and A 7\u2192 AT\u22121 rearranges the columns\nof A in the order mentioned above. It is easy to see that\n(8.40)\n\n\u03b1j (T\u03a9) = \u03b1j (\u03a9),\n\nj = 1, . . . 2s and \u03b1(T\u03a9) = \u03b1(\u03a9)\n\nfor any lattice \u03a9 \u2282 R2s .\nNote now that\nTDr Kt \u039bj = TDr Kt T\u22121 T\u039bj = Wt \u2206j ,\n\n(8.41)\n\nwhere \u2206j is a lattice defined by\n(8.42)\n\n\u2206j = T\u039bj\n\nand where Wt is (2s \u00d7 2s)-matrix\n\uf8eb\n\uf8ec Gr,t\n\uf8ec\n\uf8ec\n(8.43)\nWt = \uf8ec O 2\n\uf8ec ***\n\uf8ed\nO2\n\nO2\nGr,t\n***\nO2\n\n\uf8f6\n..\n.\nO2 \uf8f7\n\uf8f7\n..\n.\nO2 \uf8f7\n\uf8f7\n*** *** \uf8f7\n\uf8f8\n..\n. Gr,t\n\nconstructed of (2 \u00d7 2)-matrices O2 (with zero entries) and\n\u0012\n\u0013\nr\n\u2212rt\ndef\nGr,t =\n(8.44)\n.\nr \u22121 t r \u22121\nLet |t| \u2264 2 and\n(8.45)\n\n\u03b8 = arcsin(t(1 + t2 )\u22121/2 )\n\nor, equivalently t = tan \u03b8.\n\n\f40\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nThen we have\n(8.46)\n\n\u221a\ndef\n|\u03b8| \u2264 c\u2217 = arcsin(2/ 5),\n\ncos \u03b8 = (1 + t2 )\u22121/2 ,\n\nsin \u03b8 = t(1 + t2 )\u22121/2 .\n\nIt is easy to see that\nGr,t = (1 + t2 )1/2 Dr K\u03b8\n\n(8.47)\nand\n\ne rK\ne \u03b8,\nWt = (1 + t2 )1/2 D\n\n(8.48)\nwhere\n\n\uf8eb\n\nDr\n\n\uf8ec\n\uf8ec\nO2\ne\n(8.49) Dr = \uf8ec\n\uf8ec\n\uf8ed ***\n\nO2\n\nO2\nDr\n***\n\nO2\n\n..\n.\n..\n.\n\nO2\n\n\uf8f6\n\n\uf8f7\n\uf8f7\nO2 \uf8f7\n\uf8f7\n*** *** \uf8f8\n..\n. D\n\nK\u03b8\n\n\uf8ec\n\uf8ec\nO2\ne\nK\u03b8 = \uf8ec\n\uf8ec\n\uf8ed ***\n\nand\n\nO2\n\nr\n\nare (2s \u00d7 2s)-matrices with\n\u0013\n\u0012\nr\n0\ndef\nand\n(8.50) Dr =\n0 r \u22121\n\n\uf8eb\n\ndef\n\nK\u03b8 =\n\n\u0012\n\ncos \u03b8\nsin \u03b8\n\n\u2212 sin \u03b8\ncos \u03b8\n\nO2\nK\u03b8\n***\n\nO2\n\n\u0013\n\n..\n.\n..\n.\n\nO2\n\n\uf8f6\n\n\uf8f7\n\uf8f7\nO2 \uf8f7\n\uf8f7\n*** *** \uf8f8\n..\n. K\n\u03b8\n\n\u2208 SL(2, R).\n\nSubstituting (8.48) into equality (8.41), we obtain\ne rK\ne \u03b8 \u2206j .\nTDr Kt \u039bj = (1 + t2 )1/2 D\n\n(8.51)\n\nBelow we also use the following crucial lemma of G\u00f6tze and Margulis\n(2010).\nLemma 8.2.\n\n(8.52)\n\ne \u03b8 and\nLet K\n\uf8eb\n\nH\n\n\uf8ec\n\uf8ec\ne = \uf8ec O2\nH\n\uf8ec\n\uf8ed ***\nO2\n\nO2\nH\n***\n\nO2\n\n..\n.\n..\n.\n***\n..\n.\n\nO2\n\n\uf8f6\n\n\uf8f7\n\uf8f7\nO2 \uf8f7\n\uf8f7\n*** \uf8f8\nH\n\ne \u03b8 is defined in (8.49)\nbe (2d \u00d7 2d)-matrices such that H \u2208 G = SL(2, R) and K\nand (8.50). Let \u03b2 be a positive number such that \u03b2d > 2. Then, for any\nH \u2208 G and any lattice \u2206 \u2282 R2d ,\nZ 2\u03c0\neK\ne \u03b8 \u2206))\u03b2 d\u03b8 \u226a\u03b2,d (\u03b1(\u2206))\u03b2 kHk\u03b2d\u22122 .\n(\u03b1(H\n(8.53)\n0\n\nHere kHk is the standard norm of the linear operator H : R2 \u2192 R2 .\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n41\n\nConsider, under the conditions of Lemma 8.1,\nZ \u03c3\u22122\nZ \u03c3\u22122 /2\n1\n1\ndt\ndef\nb b (t/2)| dt .\nb b (t)| =\n|\u03a8\n(8.54)\n|\u03a8\nI0 =\nt\nt\ncs \u03c31\u22122 r \u22122+4/s\ncs \u03c31\u22122 r \u22122+4/s /2\nBy Lemma 8.1, we have\n\nI0 \u226as (pN )\u22121 \u03c31s (det C)\u22121/2 + r \u2212s/2 sup J,\n\n(8.55)\n\n\u0393\n\nwhere\nJ=\n\n(8.56)\n\nZ\n\n1\n\nr \u22121\n\n\u03c1\n\n(\u03b1(Dr Ut \u039b))1/2\n\ndt X\nIj ,\n\u2264\nt\nj=2\n\nwith\ndef\n\n(8.57) Ij =\n\nZ\n\n(j\u22121)\u22121\n\nj \u22121\n\n(\u03b1(Dr Ut \u039b))1/2\n\ndt\n,\nt\n\ndef\n\nj = 2, 3, . . . , \u03c1 = \u230ar\u230b + 1.\n\nChanging variable t = vj \u22122 and v = w + j in Ij and using the properties\nof matrices Dr and Ut , we have\nZ j 2 (j\u22121)\u22121\ndv\nIj =\n(\u03b1(Dr Uvj \u22122 \u039b))1/2\nv\nj\nZ j+2\ndv\n(8.58)\n(\u03b1(Dr Uvj \u22122 \u039b))1/2\n\u2264\nv\nj\nZ 2\ndw\n.\n(\u03b1(Dr Uwj \u22122 Uj \u22121 \u039b))1/2\n=\nw\n+j\n0\nBy (8.7),\n(8.59)\n\nDr Uwj \u22122 = Drj \u22121 Dj Uwj \u22122 = Drj \u22121 Uw Dj .\n\nAccording to (8.58) and (8.59),\nZ\n1 2\n(8.60)\n(\u03b1(Drj \u22121 Ut \u039bj ))1/2 dt,\nIj \u226a\nj 0\nwhere the lattices \u039bj are defined in (8.5); see also (8.1), (8.3) and (8.4).\nUsing (8.5), (8.15) and (8.21), we see that\n(8.61)\n\n\u03b1(\u039bj ) \u226as \u03c312s (det C)\u22121 .\n\nBy (8.39), (8.40) and (8.51), we have\n(8.62)\n\n\u03b1(Drj \u22121 Ut \u039bj ) \u226as \u03b1(Drj \u22121 Kt \u039bj ) = \u03b1(TDrj \u22121 Kt \u039bj )\ne rj \u22121 K\ne \u03b8 \u2206j )\n\u226as \u03b1(D\n\n\f42\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nfor |t| \u226as 1, r \u2265 1, j = 2, 3, . . . , \u03c1, where \u2206j and \u03b8 are defined in (8.42)\nand (8.45), respectively. Using (8.45), (8.46), (8.49), (8.62) and Lemma 8.2\n(with d = s), we obtain\nZ 2\nZ c\u2217\n1/2\ne rj \u22121 K\ne \u03b8 \u2206j ))1/2 d\u03b8\n(\u03b1(Drj \u22121 Ut \u039bj )) dt \u226as\n(\u03b1(D\ncos2 \u03b8\n0\n0\nZ 2\u03c0\ne rj \u22121 K\ne \u03b8 \u2206j ))1/2 d\u03b8\n(8.63)\n(\u03b1(D\n\u226a\n0\n\n\u226as kDrj \u22121 ks/2\u22122 (\u03b1(\u2206j ))1/2 ,\n\nif s \u2265 5. It is clear that kDrj \u22121 k = rj \u22121 . Therefore, according to (8.40),\n(8.42), (8.60) and (8.63),\n1\n(8.64)\nIj \u226as (rj \u22121 )s/2\u22122 (\u03b1(\u039bj ))1/2 .\nj\nBy (8.56), (8.61) and (8.64), we obtain, for s \u2265 5,\n(8.65) J\n\n\u226as \u03c31s (det C)\u22121/2\n\n\u03c1\nX\n1\nj=2\n\nj\n\n(rj \u22121 )s/2\u22122 \u226as r s/2\u22122 \u03c31s (det C)\u22121/2 .\n\nBy (6.4), (6.27), (8.55) and (8.65), we have r \u224ds (N p)1/2 and\n(8.66)\n\nI0 \u226as r \u22122 \u03c31s (det C)\u22121/2 \u226as (N p)\u22121 \u03c31s (det C)\u22121/2 .\n\nIt is clear that in a similar way we can establish that\nZ c(s)\u03c3\u22122\n1\nb b (t/2)| dt \u226as r \u22122 \u03c31s (det C)\u22121/2 \u226as (N p)\u22121 \u03c31s (det C)\u22121/2\n|\u03a8\n(8.67)\nt\n\u03c31\u22122\n\nfor any quantity c(s) depending on s only. The proof will be easier due to\nthe fact that t cannot be small in this integral.\nThus, we have proved the following lemma.\nLemma 8.3. Let the conditions of Lemma 6.3 be satisfied with s =\nd \u2265 5, D = C\u22121/2 , \u03b4 \u2264 1/(5s) and with an orthonormal system S = So =\n{e1 , . . . , es } \u2282 Rd . Let c1 (s) and c2 (s) be some quantities depending on s\nonly. Then there exists a cs such that\nZ c2 (s)\u03c3\u22122\n1\nb b (t)| dt \u226as (N p)\u22121 \u03c31s (det C)\u22121/2 ,\n|\u03a8\n(8.68)\n\u22122 \u22122+4/s\nt\nc1 (s)\u03c31 r\nif N p \u226bs cs , where r is defined in (6.4) and (6.27).\n\nAcknowledgments. We would like to thank V.V. Ulyanov for helpful discussions, and two anonymous referees for useful suggestions which allowed\nus to improve the presentation.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\n\n43\n\nREFERENCES\nBentkus, V. Y. (1984). Asymptotic expansions for distributions of sums of independent\nrandom elements in a Hilbert space. Lithuanian Math. J. 24 305\u2013319.\nBentkus, V. and G\u00f6tze, F. (1995a). On the number of lattice points in a large ellipsoid.\nRussian Acad. Sc. Doklady 343 439\u2013440.\nBentkus, V. and G\u00f6tze, F. (1995b). Optimal rates of convergence in functional limit\ntheorems for quadratic forms. Preprint 95-091 SFB 343, Univ. Bielefeld.\nBentkus, V. and G\u00f6tze, F. (1996). Optimal rates of convergence in the CLT for\nquadratic forms. Ann. Probab. 24 466\u2013490. MR1387646\nBentkus, V. and G\u00f6tze, F. (1997a). Uniform rates of convergence in the CLT for\nquadratic forms in multidimensional spaces. Probab. Theory Related Fields 109 367\u2013\n416. MR1481126\nBentkus, V. and G\u00f6tze, F. (1997b). On the lattice point problem for ellipsoids. Acta\nArith. 80 101\u2013125. MR1450919\nBentkus, V., G\u00f6tze, F., Paulauskas, V. and Ra\u010dkauskas, A. (1991). The accuracy of\nGaussian approximation in Banach spaces. In Probability Theory, 6 (Russian) 39\u2013139.\nAkad. Nauk SSSR Vsesoyuz. Inst. Nauchn. i Tekhn. Inform., Moscow. MR1157207\nBentkus, V., G\u00f6tze, F. and Zaitsev, A. Y. (1997). Approximation of quadratic forms\nof independent random vectors by accompanying laws. Theory Probab. Appl. 42 189\u2013\n212.\nBentkus, V., G\u00f6tze, F. and Zitikis, R. (1993). Asymptotic expansions in the integral\nand local limit theorems in Banach spaces with applications to \u03c9-statistics. J. Theoret.\nProbab. 6 727\u2013780. MR1245394\nBhattacharya, R. N. and Ranga Rao, R. (1986). Normal Approximation and Asymptotic Expansions. Wiley, New York.\nBogatyrev, S. A., G\u00f6tze, F. and Ulyanov, V. V. (2006). Non-uniform bounds for\nshort asymptotic expansions in the CLT for balls in a Hilbert space. J. Multivariate\nAnal. 97 2041\u20132056. MR2301275\nCassels, J. W. S. (1959). An Introduction to the Geometry of Numbers. Springer, Berlin.\nMR0157947\nDavenport, H. (1958). Indefinite quadratic forms in many variables. II. Proc. Lond.\nMath. Soc. (3) 8 109\u2013126. MR0092808\nEsseen, C.-G. (1945). Fourier analysis of distribution functions. A mathematical study\nof the Laplace\u2013Gaussian law. Acta Math. 77 1\u2013125. MR0014626\nFricker, F. (1982). Einf\u00fchrung in die Gitterpunktlehre. Lehrb\u00fccher und Monographien aus dem Gebiete der Exakten Wissenschaften (LMW). Mathematische Reihe 73.\nBirkh\u00e4user, Basel. MR0673938\nG\u00f6tze, F. (1979). Asymptotic expansions for bivariate von Mises functionals. Z. Wahrsch.\nVerw. Gebiete 50 333\u2013355. MR0554550\nG\u00f6tze, F. (1994). Unpublished manuscript.\nG\u00f6tze, F. (2004). Lattice point problems and values of quadratic forms. Invent. Math.\n157 195\u2013226. MR2135188\nG\u00f6tze, F. and Margulis, G. A. (2010). Distribution of values of quadratic forms at\nintegral points. Preprint. Available at arXiv:1004.5123.\nG\u00f6tze, F. and Ulyanov, V. (2000). Uniform approximations in the CLT for balls in\nEuclidian spaces. Preprint 00-034 SFB 343. Bielefeld Univ., Bielefeld.\nG\u00f6tze, F. and Ulyanov, V. (2003). Asymptotic disrtribution of \u03c72 -type statistics.\nPreprint 03-033 Research group \"Spectral analysis, asymptotic distributions and\nstochastic dynamics,\" Bielefeld Univ., Bielefeld.\n\n\f44\n\nF. G\u00d6TZE AND A. YU. ZAITSEV\n\nG\u00f6tze, F. and Zaitsev, A. Y. (2008). Uniform rates of convergence in the CLT for\nquadratic forms. Preprint 08-119 SFB 701. Bielefeld Univ., Bielefeld.\nG\u00f6tze, F. and Zaitsev, A. Y. (2009). Uniform rates of approximation by short asymptotic expansions in the CLT for quadratic forms of sums of i.i.d. random vectors.\nPreprint 09-073 SFB 701. Bielefeld Univ., Bielefeld.\nG\u00f6tze, F. and Zaitsev, A. Y. (2010). Uniform rates of approximation by short asymptotic expansions in the CLT for quadratic forms. Zapiski Nauchnykh Seminarov POMI\n384 105\u2013153.\nHardy, G. H. (1916). The average order of the arithmetical functions P (x) and \u03b4(x).\nProc. Lond. Math. Soc. (2) 15 192\u2013213. MR1576556\nLandau, E. (1915). Zur analytischen Zahlentheorie der definiten quadratischen Formen.\nSitzber. Preuss. Akad. Wiss. 31 458\u2013476.\nLenstra, A. K., Lenstra, H. W. Jr. and Lov\u00e1sz, L. (1982). Factoring polynomials\nwith rational coefficients. Math. Ann. 261 515\u2013534. MR0682664\nMumford, D. (1983). Tata Lectures on Theta. I. Progress in Mathematics 28. Birkh\u00e4user,\nBoston, MA. MR0688651\nNagaev, S. V. (1989). On a new approach to the study of the distribution of the norm\nof random element in Hilbert space. In Abstracts of the Fifth Intern. Vilnius Conf. in\nProbab. Theory and Math. Stat., 4 77\u201378. Mokslas, VSP, Vilnius.\nNagaev, S. V. and Chebotarev, V. I. (1999). On the accuracy of Gaussian approximation in Hilbert space. Acta Appl. Math. 58 189\u2013215. MR1734750\nNagaev, S. V. and Chebotarev, V. I. (2005). On the accuracy of Gaussian approximation in Hilbert space. Siberian Adv. Math. 15 11\u201373. MR2141789\nPetrov, V. V. (1975). Sums of Independent Random Variables. Springer, New York.\nMR0388499\nPrawitz, H. (1972). Limits for a distribution, if the characteristic function is given in a\nfinite domain. Skand. Aktuarietidskr. 1972 138\u2013154. MR0375429\nProkhorov, Y. V. and Ulyanov, V. V. (2013). Some approximation problems in statistics and probability. In Limit Theorems in Probability, Statistics and Theory, Series:\nSpringer Proceedings in Mathematics and Statistics, 42. Springer, Berlin.\nSenatov, V. V. (1997). Qualitative effects in estimates for the rate of convergence in\nthe central limit theorem in multidimensional spaces. Tr. Mat. Inst. Steklova 215 239.\nMR1632100\nSenatov, V. V. (1998). Normal Approximation: New Results, Methods and Problems.\nVSP, Utrecht. MR1686374\nUlyanov, V. V. and G \u00f6tze, F. (2011). Short asymptotic expansions in the CLT in Euclidean spaces: A sharp estimate for its accuracy. In Proceedings 2011 World Congress\non Engineering and Technology. Oct. 28\u2013Nov. 2, 2011. Shanghai, China, 1 260\u2013262.\nIEEE Press, New York.\nWeyl, H. (1916). \u00dcber die Gleichverteilung der Zahlen mod-Eins. Math. Ann. 77 313\u2013352.\nYurinski\u0131\u0306, V. V. (1982). On the accuracy of normal approximation of the probability of\nhitting a ball. Theory Probab. Appl. 27 270\u2013278.\nZalesski\u0131\u0306, B. A., Sazonov, V. V. and Ul'yanov, V. V. (1988). A sharp estimate for\nthe accuracy of the normal approximation in a Hilbert space. Theory Probab. Appl. 33\n700\u2013701.\nZalesski\u0131\u0306, B. A., Sazonov, V. V. and Ul'yanov, V. V. (1991). A precise estimate for\nthe rate of convergence in the central limit theorem in a Hilbert space. Math. USSR\nSbornik 68 453\u2013482.\n\n\fEXPLICIT RATES OF APPROXIMATION IN THE CLT\nFakult\u00e4t f\u00fcr Mathematik\nUniversit\u00e4t Bielefeld\nPostfach 100131, D-33501\nBielefeld\nGermany\nE-mail: goetze@math.uni-bielefeld.de\n\n45\n\nSt. Petersburg Department\nof V. A. Steklov Mathematical Institute\nFontanka 27\nSt. Petersburg 191023\nRussia\nE-mail: zaitsev@pdmi.ras.ru\n\n\f"}