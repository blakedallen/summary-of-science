{"id": "http://arxiv.org/abs/cond-mat/0206569v1", "guidislink": true, "updated": "2002-06-28T10:19:25Z", "updated_parsed": [2002, 6, 28, 10, 19, 25, 4, 179, 0], "published": "2002-06-28T10:19:25Z", "published_parsed": [2002, 6, 28, 10, 19, 25, 4, 179, 0], "title": "Parallel dynamics of the fully connected Blume-Emery-Griffiths neural\n  network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0206449%2Ccond-mat%2F0206088%2Ccond-mat%2F0206407%2Ccond-mat%2F0206197%2Ccond-mat%2F0206006%2Ccond-mat%2F0206424%2Ccond-mat%2F0206377%2Ccond-mat%2F0206109%2Ccond-mat%2F0206093%2Ccond-mat%2F0206020%2Ccond-mat%2F0206089%2Ccond-mat%2F0206022%2Ccond-mat%2F0206307%2Ccond-mat%2F0206552%2Ccond-mat%2F0206010%2Ccond-mat%2F0206572%2Ccond-mat%2F0206473%2Ccond-mat%2F0206334%2Ccond-mat%2F0206319%2Ccond-mat%2F0206318%2Ccond-mat%2F0206114%2Ccond-mat%2F0206468%2Ccond-mat%2F0206389%2Ccond-mat%2F0206166%2Ccond-mat%2F0206532%2Ccond-mat%2F0206303%2Ccond-mat%2F0206579%2Ccond-mat%2F0206237%2Ccond-mat%2F0206444%2Ccond-mat%2F0206576%2Ccond-mat%2F0206324%2Ccond-mat%2F0206497%2Ccond-mat%2F0206193%2Ccond-mat%2F0206129%2Ccond-mat%2F0206229%2Ccond-mat%2F0206513%2Ccond-mat%2F0206050%2Ccond-mat%2F0206085%2Ccond-mat%2F0206087%2Ccond-mat%2F0206343%2Ccond-mat%2F0206484%2Ccond-mat%2F0206384%2Ccond-mat%2F0206294%2Ccond-mat%2F0206440%2Ccond-mat%2F0206430%2Ccond-mat%2F0206047%2Ccond-mat%2F0206188%2Ccond-mat%2F0206541%2Ccond-mat%2F0206391%2Ccond-mat%2F0206272%2Ccond-mat%2F0206485%2Ccond-mat%2F0206103%2Ccond-mat%2F0206286%2Ccond-mat%2F0206305%2Ccond-mat%2F0206437%2Ccond-mat%2F0206168%2Ccond-mat%2F0206158%2Ccond-mat%2F0206480%2Ccond-mat%2F0206522%2Ccond-mat%2F0206226%2Ccond-mat%2F0206107%2Ccond-mat%2F0206416%2Ccond-mat%2F0206445%2Ccond-mat%2F0206442%2Ccond-mat%2F0206104%2Ccond-mat%2F0206195%2Ccond-mat%2F0206248%2Ccond-mat%2F0206172%2Ccond-mat%2F0206504%2Ccond-mat%2F0206271%2Ccond-mat%2F0206283%2Ccond-mat%2F0206171%2Ccond-mat%2F0206227%2Ccond-mat%2F0206180%2Ccond-mat%2F0206548%2Ccond-mat%2F0206529%2Ccond-mat%2F0206580%2Ccond-mat%2F0206560%2Ccond-mat%2F0206492%2Ccond-mat%2F0206276%2Ccond-mat%2F0206333%2Ccond-mat%2F0206464%2Ccond-mat%2F0206262%2Ccond-mat%2F0206467%2Ccond-mat%2F0206144%2Ccond-mat%2F0206308%2Ccond-mat%2F0206143%2Ccond-mat%2F0206295%2Ccond-mat%2F0206405%2Ccond-mat%2F0206116%2Ccond-mat%2F0206564%2Ccond-mat%2F0206401%2Ccond-mat%2F0206266%2Ccond-mat%2F0206483%2Ccond-mat%2F0206330%2Ccond-mat%2F0206569%2Ccond-mat%2F0206432%2Ccond-mat%2F0206138%2Ccond-mat%2F0206281%2Ccond-mat%2F0206520%2Ccond-mat%2F0206392&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Parallel dynamics of the fully connected Blume-Emery-Griffiths neural\n  network"}, "summary": "The parallel dynamics of the fully connected Blume-Emery-Griffiths neural\nnetwork model is studied at zero temperature for arbitrary using a\nprobabilistic approach. A recursive scheme is found determining the complete\ntime evolution of the order parameters, taking into account all feedback\ncorrelations. It is based upon the evolution of the distribution of the local\nfield, the structure of which is determined in detail. As an illustrative\nexample, explicit analytic formula are given for the first few time steps of\nthe dynamics. Furthermore, equilibrium fixed-point equations are derived and\ncompared with the thermodynamic approach. The analytic results find excellent\nconfirmation in extensive numerical simulations.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0206449%2Ccond-mat%2F0206088%2Ccond-mat%2F0206407%2Ccond-mat%2F0206197%2Ccond-mat%2F0206006%2Ccond-mat%2F0206424%2Ccond-mat%2F0206377%2Ccond-mat%2F0206109%2Ccond-mat%2F0206093%2Ccond-mat%2F0206020%2Ccond-mat%2F0206089%2Ccond-mat%2F0206022%2Ccond-mat%2F0206307%2Ccond-mat%2F0206552%2Ccond-mat%2F0206010%2Ccond-mat%2F0206572%2Ccond-mat%2F0206473%2Ccond-mat%2F0206334%2Ccond-mat%2F0206319%2Ccond-mat%2F0206318%2Ccond-mat%2F0206114%2Ccond-mat%2F0206468%2Ccond-mat%2F0206389%2Ccond-mat%2F0206166%2Ccond-mat%2F0206532%2Ccond-mat%2F0206303%2Ccond-mat%2F0206579%2Ccond-mat%2F0206237%2Ccond-mat%2F0206444%2Ccond-mat%2F0206576%2Ccond-mat%2F0206324%2Ccond-mat%2F0206497%2Ccond-mat%2F0206193%2Ccond-mat%2F0206129%2Ccond-mat%2F0206229%2Ccond-mat%2F0206513%2Ccond-mat%2F0206050%2Ccond-mat%2F0206085%2Ccond-mat%2F0206087%2Ccond-mat%2F0206343%2Ccond-mat%2F0206484%2Ccond-mat%2F0206384%2Ccond-mat%2F0206294%2Ccond-mat%2F0206440%2Ccond-mat%2F0206430%2Ccond-mat%2F0206047%2Ccond-mat%2F0206188%2Ccond-mat%2F0206541%2Ccond-mat%2F0206391%2Ccond-mat%2F0206272%2Ccond-mat%2F0206485%2Ccond-mat%2F0206103%2Ccond-mat%2F0206286%2Ccond-mat%2F0206305%2Ccond-mat%2F0206437%2Ccond-mat%2F0206168%2Ccond-mat%2F0206158%2Ccond-mat%2F0206480%2Ccond-mat%2F0206522%2Ccond-mat%2F0206226%2Ccond-mat%2F0206107%2Ccond-mat%2F0206416%2Ccond-mat%2F0206445%2Ccond-mat%2F0206442%2Ccond-mat%2F0206104%2Ccond-mat%2F0206195%2Ccond-mat%2F0206248%2Ccond-mat%2F0206172%2Ccond-mat%2F0206504%2Ccond-mat%2F0206271%2Ccond-mat%2F0206283%2Ccond-mat%2F0206171%2Ccond-mat%2F0206227%2Ccond-mat%2F0206180%2Ccond-mat%2F0206548%2Ccond-mat%2F0206529%2Ccond-mat%2F0206580%2Ccond-mat%2F0206560%2Ccond-mat%2F0206492%2Ccond-mat%2F0206276%2Ccond-mat%2F0206333%2Ccond-mat%2F0206464%2Ccond-mat%2F0206262%2Ccond-mat%2F0206467%2Ccond-mat%2F0206144%2Ccond-mat%2F0206308%2Ccond-mat%2F0206143%2Ccond-mat%2F0206295%2Ccond-mat%2F0206405%2Ccond-mat%2F0206116%2Ccond-mat%2F0206564%2Ccond-mat%2F0206401%2Ccond-mat%2F0206266%2Ccond-mat%2F0206483%2Ccond-mat%2F0206330%2Ccond-mat%2F0206569%2Ccond-mat%2F0206432%2Ccond-mat%2F0206138%2Ccond-mat%2F0206281%2Ccond-mat%2F0206520%2Ccond-mat%2F0206392&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The parallel dynamics of the fully connected Blume-Emery-Griffiths neural\nnetwork model is studied at zero temperature for arbitrary using a\nprobabilistic approach. A recursive scheme is found determining the complete\ntime evolution of the order parameters, taking into account all feedback\ncorrelations. It is based upon the evolution of the distribution of the local\nfield, the structure of which is determined in detail. As an illustrative\nexample, explicit analytic formula are given for the first few time steps of\nthe dynamics. Furthermore, equilibrium fixed-point equations are derived and\ncompared with the thermodynamic approach. The analytic results find excellent\nconfirmation in extensive numerical simulations."}, "authors": ["D. Bolle", "J. Busquets Blanco", "G. M. Shim"], "author_detail": {"name": "G. M. Shim"}, "author": "G. M. Shim", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/S0378-4371(02)01528-5", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0206569v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0206569v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "22 pages, 12 figures", "arxiv_primary_category": {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0206569v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0206569v1", "journal_reference": null, "doi": "10.1016/S0378-4371(02)01528-5", "fulltext": "Parallel dynamics of the fully connected\nBlume-Emery-Griffiths neural network\n\narXiv:cond-mat/0206569v1 [cond-mat.dis-nn] 28 Jun 2002\n\nD. Boll\u00e9\n\n1\n\n, J. Busquets Blanco\n\n2\n\nInstituut voor Theoretische Fysica, Katholieke Universiteit Leuven,\nCelestijnenlaan 200 D, B-3001 Leuven, Belgium\n\nG.M.Shim\n\n3\n\nDepartment of Physics, Chungnam National University ,Yuseong, Daejeon\n305-764, R.O. Korea\n\nAbstract\nThe parallel dynamics of the fully connected Blume-Emery-Griffiths neural network\nmodel is studied at zero temperature using a probabilistic approach. A recursive\nscheme is found determining the complete time evolution of the order parameters,\ntaking into account all feedback correlations. It is based upon the evolution of the\ndistribution of the local field, the structure of which is determined in detail. As an\nillustrative example explicit analytic formula are given for the first few time steps\nof the dynamics. Furthermore, equilibrium fixed-point equations are derived and\ncompared with the thermodynamic approach. The analytic results find excellent\nconfirmation in extensive numerical simulations.\nPACS : 87.10.+e, 02.50.+s, 64.60.Cn\nKey words: parallel dynamics; fully connected networks; probabilistic approach\n\n1\n\nIntroduction\n\nRecently, an optimal Hamiltonian has been derived in the statistical mechanics approach to Qstate neural networks starting from the concept of mutual information [1],[2]. Optimal means\nthat the best retrieval properties are guaranteed including, e.g., the largest retrieval overlap,\nloading capacity, basin of attraction, convergence time. For Q = 3 this Hamiltonian resembles\nthe classical Blume-Emery-Griffiths (BEG) Hamiltonian in the sense that it contains both a\nbilinear and biquadratic term in the spins [3]. For a fully connected architecture it has been\nshown, using a thermodynamic replica approach that the maximal loading capacity for the\nBEG network is indeed bigger than the one for other three-state networks existing in the\nliterature (Ising, Potts...) [2].\n1\n2\n3\n\ndesire.bolle@fys.kuleuven.ac.be\njordi.busquets@fys.kuleuven.ac.be\ngmshim@cnu.ac.kr\n\nPreprint submitted to Elsevier Science\n\n6 November 2018\n\n\fThe dynamics of these new type of neural network models is under investigation. In the case\nof an asymmetric extremely diluted architecture where one knows that there are no feedback\nloops complicating the time evolution, this dynamics has been solved in closed form [1] showing\na better retrieval quality than other diluted models for certain parameters of the system. For\nsymmetric architectures \u2013 fully connected but also extremely diluted \u2013 however, the situation\nis much more complicated. From former experience with, e.g., Q-Ising models (see [4] and\nreferences therein) one knows that the dynamics is very non-trivial due to the feedback in\nthe system [5]. This feedback causes the appearance of discrete noise, besides Gaussian noise,\ninvolving the neurons at all previous time steps and prevents a closed-form solution.\nIn this work we generalize the probabilistic approach that has been developed for the Hopfield\nmodel [6], [7] and Q-Ising model [8] in order to solve the dynamics for the fully connected BEG\nmodel at zero temperature. Thereby, we start from the time evolution of the distribution of\nthe local field, instead of working directly with the order parameters. We study the structure\nof this distribution in detail and, using this knowledge, we develop a recursive scheme in order\nto calculate the relevant order parameters of the system, i.e., the main overlap, the neural\nactivity, the activity overlap and the variance of the residual overlap at any time step. As an\nillustration we write out these expressions in detail for the first few time steps of the dynamics.\nFurthermore, by requiring the local field to be time-independent, implying that some correlations between its Gaussian and discrete noise parts are neglected, we derive fixed-point\nequations for the order parameters. They coincide with those derived via thermodynamical\nmethods [2].\nFinally we perform numerical simulations of a BEG network with N = 6000 neurons. They\nconfirm the analytical results we have derived.\nThe rest of this paper is organized as follows. In Section 2 we introduce the model, its dynamics\nand the relevant order parameters. In Section 3 we use the probabilistic approach in order\nto derive a recursive scheme for the evolution of the distribution of the local field, leading\nto recursion relations for the order parameters. Using this scheme, we explicitly calculate in\nAppendix A the order parameters and in Appendix B the local field for the first few time steps\nof the dynamics. In Section 4 we show the existence of a Lyapunov function at zero temperature\nand we discuss the evolution of the system to fixed-point attractors. Section 5 details the\nstructure of the local field distribution, especially the appearance of gaps. The analytic results\nare compared with numerical simulations in Section 6. Some concluding remarks are given in\nSection 7.\n\n2\n\nThe model\n\nConsider a neural network consisting of N neurons which can take values \u03c3i , i = 1, . . . , N\nfrom the discrete set S \u2261 {\u22121, 0, +1}. The p = \u03b1N patterns to be stored in this network\nare supposed to be a collection of independent and identically distributed random variables\n(i.i.d.r.v.), {\u03bei\u03bc }, \u03bc = 1, . . . , p with a probability distribution\na\na\np(\u03bei\u03bc ) = \u03b4(\u03bei\u03bc \u2212 1) + \u03b4(\u03bei\u03bc + 1) + (1 \u2212 a)\u03b4(\u03bei\u03bc )\n2\n2\n2\n\n(1)\n\n\fwith a the activity of the patterns so that\n1 X \u03bc 2\n(\u03bei ) = a.\nN \u2192\u221e N\ni\n\n(2)\n\nlim\n\nGiven the network configuration at time t, \u03c3 N (t) \u2261 {\u03c3j (t)}, j = 1, . . . , N, the following\ndynamics is considered. The configuration \u03c3 N (0) is chosen as input. At zero temperature all\nneurons are updated in parallel according to the rule\n\u03c3i (t) \u2192 \u03c3i (t + 1) = s\u2032 : min \u01ebi [s|\u03c3N (t)] = \u01ebi [s\u2032 |\u03c3 N (t)]\ns\u2208S\n\n(3)\n\nwith s\u2032 \u2208 S. We remark that this rule is the zero temperature limit of the stochastic parallel\nspin-flip dynamics defined by the transition probabilities\nPr (\u03c3i (t + 1) = s\u2032 \u2208 S|\u03c3 N (t)) = P\n\nexp[\u2212\u03b2\u01ebi (s\u2032 |\u03c3 N (t))]\n.\ns\u2208S exp[\u2212\u03b2\u01ebi (s|\u03c3 N (t))]\n\n(4)\n\nHere the energy potential \u01ebi [s|\u03c3 N (t)] is defined by\n\n\u01ebi (s|\u03c3N (t)) = \u2212shi (\u03c3 N (t)) \u2212 s2 \u03b8i (\u03c3 N (t)) ,\n\n(5)\n\nwhere the following local fields in neuron i carry all the information\nhN,i (t) =\n\nX\n\nJij \u03c3j (t),\n\n\u03b8N,i (t) =\n\nj6=i\n\nX\n\nKij \u03c3j2 (t)\n\n(6)\n\nj6=i\n\nwith the obvious shorthand notation for the local fields. The synaptic couplings Jij and Kij\nare of the Hebb-type\nJij =\n\np\n1 X\n\u03be \u03bc\u03be \u03bc,\na2 N \u03bc=1 i j\n\nKij =\n\np\n1 X\n\u03b7\u03bc\u03b7\u03bc\nN \u03bc=1 i j\n\n(7)\n\nwith\n\u03b7i\u03bc =\n\n1\n((\u03be \u03bc )2 \u2212 a).\na(1 \u2212 a) i\n\n(8)\n\nThese are the local fields entering in the BEG model [1]. The updating rule (3) is equivalent\nto using a gain function\n\u03c3i (t + 1) = g(hN,i (t), \u03b8N,i (t)) = sign(hN,i (t))\u0398(|hN,i (t)| + \u03b8N,i (t))\n\n(9)\n\nwith \u0398 the Heaviside function.\nThe order parameters of this system have been obtained starting form the mutual information\nas a measure for the retrieval quality of the system [1], [2]. They are the retrieval overlap, the\nactivity overlap, and the neural activity\nm\u03bcN (t) =\n\n1 X \u03bc\n\u03be \u03c3i (t),\naN i i\n\nn\u03bcN (t) =\n\n1 X \u03bc 2\n(\u03be ) (\u03c3i (t))2 ,\naN i i\n3\n\nqN (t) =\n\n1 X\n(\u03c3i (t))2 .\nN i\n\n(10)\n\n\fInstead of using the activity overlap nN (t) itself it is more convenient to employ the modified\nactivity overlap\n\u03bc\nlN\n(t) =\n\n3\n\n1 X \u03bc\n1\n(\u03b7 )(\u03c3i (t))2 .\n(n\u03bcN (t) \u2212 qN (t)) =\n1\u2212a\nN i i\n\n(11)\n\nRecursive dynamical scheme\n\nIn networks with symmetric couplings it is known that non-trivial correlations occur, even at\nzero temperature, which become increasingly tedious to evaluate [5].\nOn the basis of the probabilistic approach (see, e.g., [6], [7], [8]) used successfully before ([4]\nand references therein) we develop in this section a recursive dynamical scheme in order to\nstudy the time evolution of the distribution of the local fields hi (t) and \u03b8i (t). This allows us\nto write down recursion relations determining the full time evolution of the order parameters\n(10)-(11) of the BEG network model.\nSuppose that the initial configuration of the network {\u03c3i (0)} is a collection of i.i.d.r.v. with\nmean E[\u03c3i (0)] = 0 and variance Var[\u03c3i (0)] = q0 and correlated with only one pattern which\nwe choose, without loss of generality, to be the first one\nE[\u03bei\u03bc \u03c3j (0)] = \u03b4i,j \u03b4\u03bc,1 m10 a,\n\nm10 > 0,\n\nE[\u03b7j\u03bc \u03c3i2 (0)] = \u03b4i,j \u03b4\u03bc,1 l01 .\n\n(12)\n\nBy the law of large numbers (LLN) eqs. (10)-(11) and (12) determine the order parameters\n1\nm1N (0), qN (0) and lN\n(0) at t = 0 in the limit N \u2192 \u221e.\nNext, we want to apply standard signal-to-noise techniques (see, e.g, [6], [8]) to both the local\nfields hN,i (0) and \u03b8N,i (0) at t = 0. Starting from their definitions we find\n\nhi (0) = lim\n\nN \u2192\u221e\n\n\u0012\n\n\u0013\n1 1 1\n1\n1 XX \u03bc \u03bc\n\u03bei mN (0) \u2212 2 (\u03bei1 )2 \u03c3i (0) + 2\n\u03bei \u03bej \u03c3j (0)\na\naN\na N \u03bc>1 j6=i\n\n\u0010 \u03b1q(0) \u0011\nD 1\n= \u03bei1 m1 (0) + N 0, 2\na\na\n\u0012\n\u0013\n1\n1 XX \u03bc \u03bc 2\n1\n(0) \u2212 (\u03b7i1 )2 \u03c3i2 (0) +\n\u03b8i (0) = lim \u03b7i1 lN\n\u03b7i \u03b7j \u03c3j (0)\nN \u2192\u221e\nN\nN \u03bc>1 j6=i\nD\n\n\u0010\n\n= \u03b7i1 l1 (0) + N 0,\n\n\u03b1q(0) \u0011\n,\na2 (1 \u2212 a)2\n\n(13)\n\n(14)\n\nwhere the convergence is in distribution [9]. The quantity N (0, d) represents a Gaussian random variable with mean 0 and variance d.\nThe key question is then how these quantities evolve in time under the parallel dynamics\nspecified before. For a general time step we find from eq. (9) and the LLN in the limit N \u2192 \u221e\nfor the order parameters (eqs.(10)-(11))\n4\n\n\f1\n\u03bei1 g hi (t), \u03b8i (t)\na\n\u0010\n\u0011EE\nDD\nPr\nq(t + 1) = \u03bei1 g 2 hi (t), \u03b8i (t)\nPr\n\nm1 (t + 1) =\n\nPr\n\nl1 (t + 1) =\n\nDD\n\n\u0010\n\n\u03b7i1 g 2 hi (t), \u03b8i (t)\n\n\u0011EE\n\n(15)\n(16)\n,\n\n(17)\n\nwhere hi (t) = limN \u2192\u221e hN,i (t) (with an analogous formula for \u03b8i (t)), and where the convergence\nis in probability. In the above hh*ii denotes the average both over the distribution of the {\u03bei\u03bc }\n(and hence {\u03b7i\u03bc }) and the {\u03c3i (0)}. Note that the average over the latter is hidden in an\naverage over the local field through the updating rule (9). From the work on symmetric QIsing networks [4], [10] we know that due to the correlations we have to study carefully the\ninfluence of non-condensed (\u03bc > 1) patterns in the time evolution of the system, expressed by\nthe variance of the residual overlaps, in our case in both the local fields. The latter are defined\nas\n\u03bc\n(t) = lim\nr \u03bc (t) \u2261 lim rN\nN \u2192\u221e\n\nN \u2192\u221e a2\n\n1\n\u221a\n\nN\n\nX\n\n\u03bej\u03bc \u03c3j (t),\n\n\u03bc>1\n\n(18)\n\nj\n\n1 X \u03bc 2\ns\u03bc (t) \u2261 lim s\u03bcN (t) = lim \u221a\n\u03b7j \u03c3j (t),\nN \u2192\u221e\nN \u2192\u221e\nN j\n\n\u03bc>1\n\n(19)\n\n\u03bc\nwhere the limit N \u2192 \u221e of rN\n(0) and s\u03bcN (0) is given by the Gaussian random variable in eqs.\n(13) and (14). At this point we want to remark that the choice of the initial configurations\nassures the independence of r \u03bc (0) and s\u03bc (0) as can be seen by calculating the characteristic\n\u03bc\nfunction E[exp(ixrN\n(0) + iys\u03bcN (0))].\n\nThe further aim of this section is then to calculate the distribution of the local fields and the\norder parameters as a function of time.\nWe start by rewriting the local fields (6) at time t in the following way\n1\n\u03b1\n1 XX \u03bc \u03bc\nhN,i (t) = \u03bei1m1N (t) + 2\n\u03bei \u03bej \u03c3j (t) \u2212 \u03c3i (t)\na\na N \u03bc>1 j\na\n\n1\n\u03b1\n1 X \u03bc \u03bc\n\u03bei rN (t)\n= \u03bei1m1N (t) \u2212 \u03c3i (t) + \u221a\na\na\nN \u03bc>1\n1 XX \u03bc \u03bc 2\n\u03b1\n1\n\u03b8N,i (t) = \u03b7i1 lN\n(t) +\n\u03b7i \u03b7j \u03c3j (t) \u2212\n\u03c3 2 (t)\nN \u03bc>1 j\na(1 \u2212 a) i\n\u03b1\n1 X \u03bc \u03bc\n1\n\u03b7i sN (t) .\n= \u03b7i1 lN\n(t) \u2212\n\u03c3i2 (t) + \u221a\na(1 \u2212 a)\nN \u03bc>1\n\n(20)\n\n(21)\n\nFrom a technical point of view the explicit addition and subtraction of the \u03c3i (t) (\u03c3i2 (t)) term is\nconvenient in order to treat all indices in the sum over j on equal footing, which is important\nto take into account all possible feedback loops.\nAt this point several remarks are in order. Since the neuronal states {\u03c3j (t)}, for t > 0, are\nnot i.i.d.r.v., the central limit theorem (CLT) can not be applied directly to the residual\n\u03bc\n\u03bc\noverlap rN\n(t) and s\u03bcN (t). Furthermore, the set of \u03b1N variables {\u03bei\u03bc rN\n(t)}\u03bc and {\u03b7i\u03bc s\u03bcN (t)}\u03bc\n\u03bd\nare not independent because the rN\n(t) respectively s\u03bdN (t), \u03bd 6= \u03bc are weakly dependent on\n\u03bc\n\u03bc\nthe \u03bei respectively \u03b7i . Indeed, after applying the dynamics, the \u03c3i (t) (\u03c3i2 (t)) and the \u03bei\u03bc (\u03b7i\u03bc )\n5\n\n\fbecome dependent, leading to a weak depence of rN (t) (sN (t)) and \u03bei (\u03b7i ). This microscopic\ndependence gives rise to a macroscopic contribution after summing and taking the limit N \u2192\n\u221e. Therefore, we follow a procedure similar to the one used in the Q-Ising model [4], [10] by\nisolating in the local fields precisely the contributions arising from these dependences.\nIn order to do so we rewrite the residual overlaps as\n\u0010\n\u0011\n1\n1\n\u03bc\n\u03bc\n\u03bei\u03bc g h\u0303\u03bcN,i (t) + \u221a \u03bei\u03bc rN\n(t), \u03b8\u0303N,i\n(t) + \u221a \u03b7i\u03bc s\u03bcN (t)\na2 N i\nN\nN\n\u0010\n\u0011\n1 X \u03bc 2 \u03bc\n1\n1\n\u03bc\n\u03bc\ns\u03bcN (t + 1) = \u221a\n\u03b7i g h\u0303N,i (t) + \u221a \u03bei\u03bc rN\n(t) + \u221a \u03b7i\u03bc s\u03bcN (t)\n(t), \u03b8\u0303N,i\nN i\nN\nN\n\u03bc\nrN\n(t + 1) =\n\n1\n\u221a\n\nX\n\n(22)\n(23)\n\nwith obvious notation. In these expressions we have extracted the contribution of the \u03bc term\n\u03bc\nout of the local fields such that the modified local fields h\u0303\u03bcN,i (t) and \u03b8\u0303N,i\n(t) are only weakly\n\u03bc\n\u03bc\n\u03bc\n\u03bc\ndependent on \u03bei and \u03b7i respectively, whereas hN,i (t) and \u03b8N,i (t) depend strongly on them.\nNext, we want to find the most important terms in (22) and (23) in the limit N \u2192 \u221e.\n\u03bc\n(t + 1) + iys\u03bcN (t + 1))] using (22)\nTherefore, we consider the characteristic function E[exp(ixrN\nand (23), up to order O(N \u22123/2 ). We then expand the gain function around the modified local\nfields. After some calculation we obtain in the limit N \u2192 \u221e\n\u03bc\nlim E[exp(ixrN\n(t + 1) + iys\u03bcN (t + 1))]\n\nN \u2192\u221e\n\n\"\n\n2 q(t\n\n\u03bc\n\n+ 1)\nq(t + 1)\n+ iy\u03c7\u03b8 (t)s\u03bc (t) \u2212 y 2\n3\n2a\n2a(1 \u2212 a)\n\n= exp ix\u03c7h (t)r (t) \u2212 x\n\n#\n\n(24)\n\nwith \u03c7h (t) and \u03c7\u03b8 (t) the \"susceptibilities\" corresponding to the fields hi (t) and \u03b8i (t) and given\nby\n\n\u03c7h (t) =\n\n\u03c7\u03b8 (t) =\n\n**\n\n**\n\n\u2202g\n\u2202h\n\n\u2202g 2\n\u2202\u03b8\n\nh\u0303,\u03b8\u0303\n\nh\u0303,\u03b8\u0303\n\n++\n\n++\n\n=\n\n**\n\n=\n\n2\na\n\n1\na\n\nZ\n\n\u001c\u001cZ\n\n\u2202g\nd\u0125\nd\u03b8\u0302\u03c1h\u0303(t) (\u0125)\u03c1\u03b8\u0303(t) (\u03b8\u0302)\n\u2202h\n\u2212\u221e\n\u2212\u221e\n\u221e\n\n\u221e\n\n0\n\n1\n=\na(1 \u2212 a)\n\nZ\n\n\u221e\n\n\u0012\n\nd\u03b8\u0302\u03c1h\u0303(t) (0)\u03c1\u03b8\u0303(t) (\u03b8\u0302)\n\u001c\u001cZ\n\n0\n\n\u2212\u221e\n\n\u001d\u001d\n\n\u0125,\u03b8\u0302\n\n\u0013++\n\n+ (1 \u2212 a)\u03c7\u03b8 (t)\n\nd\u03b8\u0302\u03c1\u03b8\u0303(t) (\u03b8\u0302)(\u03c1h\u0303(t) (\u03b8\u0302) + \u03c1h\u0303(t) (\u2212\u03b8\u0302))\n\n(25)\n\u001d\u001d\n\n.\n\n(26)\n\nIn these expressions, \u03c1h\u0303(t) (h) and \u03c1\u03b8\u0303(t) (\u03b8) are the probability densities of the modified local\nfields, h\u0303 and \u03b8\u0303. They areR the integrations of the joint distribution \u03c1h\u0303(t),\u03b8\u0303(t) (h, \u03b8) over the h and\n\u03b8 values, e.g. \u03c1h\u0303(t) (h) = d\u03b8\u03c1h\u0303(t),\u03b8\u0303(t) (h, \u03b8). (See Section 5 for more details). From the expansion\n(24) we see that the local fields hN,i (t) and \u03b8N,i (t) are independent up to the order O(N \u22123/2 )\n\u03bc\nsince rN\n(t) and s\u03bcN (t) are as well.\nIdentifying terms we then get\nr \u03bc (t + 1) = r\u0303 \u03bc (t) + \u03c7h (t)r \u03bc (t)\ns\u03bc (t + 1) = s\u0303\u03bc (t) + \u03c7\u03b8 (t)s\u03bc (t) ,\n\n(27)\n(28)\n\nwhere\n6\n\n\f1\nq(t + 1) ,\na3\nN i\n\u0011\n\u0011\n\u0010\n1 X \u03bc 2\u0010\n1\nD\ns\u0303\u03bc (t) = lim \u221a\n\u03b7i g h\u0303N,i (t), \u03b8\u0303N,i (t) = N 0,\nq(t + 1) .\nN \u2192\u221e\na(1 \u2212 a)\nN i\n\nr\u0303 \u03bc (t) = lim\n\nN \u2192\u221e a2\n\n1\n\u221a\n\nD\n\n\u03bei\u03bc g h\u0303N,i (t), \u03b8\u0303N,i (t) = N 0,\n\n(29)\n(30)\n\nWe remark that this calculation also shows us that r \u03bc (t) and s\u03bc (t) are independent for all\ntimes.\nIn this way we obtain in the limit N \u2192 \u221e from eqs.(20) and (21)\n1\n\u03b1\n1\nhi (t + 1) = \u03bei1 m1 (t + 1) + \u03c7h (t) hi (t) \u2212 \u03bei1 m1 (t) + \u03c3i (t)\na \u0012\na\na\n\u0013\n\u03b1\n+N 0, 2 q(t + 1)\na\n\u001b\n\u001a\n\u03b1\n2\n1 1\n1 1\n\u03c3 (t)\n\u03b8i (t + 1) = \u03b7i l (t + 1) + \u03c7\u03b8 (t) \u03b8i (t) \u2212 \u03b7i l (t) +\na(1 \u2212 a) i\n\u0012\n\u0013\n\u03b1\n+N 0, 2\nq(t + 1) .\na (1 \u2212 a)2\n\u001a\n\n\u001b\n\n(31)\n\n(32)\n\nFrom this it is clear that the local fields at time t + 1 consist out of a discrete part and a\nnormally distributed part, viz.\n\u0010\n\nhi (t + 1) = Mi (t + 1) + N 0, V (t + 1)\n\u0010\n\n\u0011\n\n(33)\n\n\u0011\n\n\u03b8i (t + 1) = Li (t + 1) + N 0, W (t + 1) ,\nwhere\n\n(34)\n\n\u03b1\n\u03bei1 1\n\u03bei1 1\nMi (t + 1) = \u03c7h (t) Mi (t) \u2212 m (t) + \u03c3i (t) + m (t + 1)\na\na\na\u0015\n\u0014\n\u03b1\n1 1\n2\nLi (t + 1) = \u03c7\u03b8 (t) Li (t) \u2212 \u03b7i l (t) +\n\u03c3i (t) + \u03b7i1 l1 (t + 1)\na(1 \u2212 a)\n\u0015\n\n\u0014\n\n(35)\n(36)\n\nand\nV (t + 1) = \u03b1aD(t + 1),\n\nW (t + 1) =\n\n\u03b1\nE(t + 1)\na(1 \u2212 a)\n\n(37)\n\nwith D(t + 1) and E(t + 1) the variances of the residual overlaps, r \u03bc (t + 1) and s\u03bc (t + 1),\nsatisfying the recursion relations\nq(t + 1)\n+ \u03c72h (t)D(t) + 2\u03c7h (t)Cov[r\u0303 \u03bc (t), r \u03bc (t)]\na3\nq(t + 1)\n+ \u03c72\u03b8 (t)E(t) + 2\u03c7\u03b8 (t)Cov[s\u0303\u03bc (t), s\u03bc (t)] .\nE(t + 1) =\na(1 \u2212 a)\n\nD(t + 1) =\n\n(38)\n(39)\n\nWe still have to determine \u03c1h\u0303(t) (h) and \u03c1\u03b8\u0303(t) (\u03b8) in (25) and (26). We know that the quantities\nMi (t) and Li (t) consist out of a signal term and a discrete noise term, viz.\n7\n\n\fMi (t) =\n\nX \u03b1 Y\n\u03bei1 1\n\u03c7h (s) \u03c3i (t\u2032 )\nm (t) +\na\na s=t\u2032\nt\u2032 =0\n\nLi (t) = \u03b7i1 l1 (t)\n\n(40)\n\n\u0014 t\u22121\n\u0015\nY\n\u03b1\n\u03c7\u03b8 (s) \u03c3i2 (t\u2032 ).\n+\na(1\n\u2212\na)\n\u2032\n\u2032\ns=t\nt =0\nt\u22121\nX\n\n(41)\n\nThe evolution equation tells that the \u03c3i (t\u2032 ) and \u03c3i2 (t\u2032 ) can be written in terms of the hi (t\u2032 \u2212 1)\nand \u03b8i (t\u2032 \u2212 1) such that the second terms in the expressions above are the sum of correlated\nvariables. Furthermore, these are also correlated through the dynamics with the normally\ndistributed part of the local fields. So the local fields can be considered as a transformation\nof a set of correlated variables x = {xs }, y = {ys }, s = 1, 2, . . . , t \u2212 2, t which we choose to\nnormalise. Then we arrive at the following expression for the probability densities of the local\nfields\n\nlim \u03c1\n\nN \u2192\u221e\n\nh\u0303\u03bc\ni (t)\n\n(h) = \u03c1hi (t) (h) =\n\nlim \u03c1\u03b8\u0303\u03bc (t) (\u03b8) = \u03c1\u03b8i (t) (\u03b8) =\n\nN \u2192\u221e\n\ni\n\nZ \u0010 t\u22122\nY\n\n\u0011\n1\n1\nq\ndxs dys dxt dyt q\ndet(2\u03c0Ch ) det(2\u03c0C\u03b8 )\ns=0\nq\n\u0010\n\u0011 \u0010\n\u0011\n1\n1\nexp \u2212 xCh\u22121 xT \u2212 yC\u03b8\u22121 yT \u03b4 h \u2212 Mi (t) \u2212 V (t)xt\n2\n2\n\n(42)\n\nZ \u0010 t\u22122\nY\n\n\u0011\n1\n1\nq\ndxs dys dxt dyt q\ndet(2\u03c0Ch ) det(2\u03c0C\u03b8 )\ns=0\nq\n\u0011\n\u0010\n1 \u22121 T 1 \u22121 T \u0011 \u0010\nexp \u2212 xCh x \u2212 yC\u03b8 y \u03b4 \u03b8 \u2212 Li (t) \u2212 W (t)yt ,\n2\n2\n\n(43)\n\nwhere the correlations matrices Ch and C\u03b8 are given by\n\u0010\n\nCh\n\n\u0011\n\ntt\u2032\n\n\u0010\n\n= \u03c1(xt , xt\u2032 ) = E[xt xt\u2032 ],\n\nC\u03b8\n\n\u0011\n\ntt\u2032\n\n= \u03c1(yt , yt\u2032 ) = E[yt yt\u2032 ] .\n\n(44)\n\nTogether with eqs. (15)-(17) the equations (27)-(28),(35)-(39),(42)-(44) form an exact recursive\nscheme in order to obtain the order parameters of the system. The practical difficulty that\nremains is the explicit correlations in the network at different time steps. As an illustration\nwe calculate the first three time steps in Appendix A.\n\n4\n\nFixed-point equations\n\nA second type of results can be obtained by requiring through the recursion relations (35)-(39)\nthat the local fields become time-independent. This means that most of the discrete noise part\nis neglected. We show that this procedure leads to the same fixed-point equations as those\nrecently found from a replica symmetric thermodynamic approach [2].\nFirst, for the BEG-model one can show that\nH(t) = \u2212\n\nN \u0012\nX\n\n\u0013\n\nhi (t)\u03c3\u0303i (t) + \u03b8i (t)\u03c3\u0303i2 (t) ,\n\ni=1\n\n8\n\n(45)\n\n\fwhere the set {\u03c3i (t)} is the network configuration at time t and the {\u03c3\u0303i (t)} are chosen such\nthat\n\u01ebi [\u03c3\u0303i (t)|\u03c3(t)] = min \u01ebi [s|\u03c3(t)]\n\n(46)\n\ns\u2208S\n\nis a Lyapunov function for zero temperature. The proof is completely analogous to the argumentation used in [11] and [12]. The choice of {\u03c3\u0303i (t)} implies through the updating rule (3) that\n\u03c3i (t + 1) = \u03c3\u0303i (t). For finite N, H(t) is bounded from below implying that H(t + 1) \u2212 H(t) = 0\nafter finitely many time steps. This can be realized for \u03c3i (t + 2) = \u03c3i (t) for all i and, hence,\nboth two-cycles and fixed-points satisfy this condition. We only study fixed-points.\nNext, we start by eliminating the time dependence in the evolution equations for the local\nfields (31)-(32). This leads to\n\n1\n\u03b1\n\u03b1\n1\nN 0, 2 q + \u03b7h \u03c3i\nhi = \u03bei m +\na\n1 \u2212 \u03c7h\na\na\n\u0012\n\u0013\n\u03b1\n\u03b1\n1\nN 0, 2\nq +\n\u03b7\u03b8 \u03c3i2 ,\n\u03b8i = \u03b7i l +\n2\n1 \u2212 \u03c7\u03b8\na (1 \u2212 a)\na(1 \u2212 a)\n\u0012\n\n\u0013\n\n(47)\n(48)\n\nwhere from now on we forget about the pattern index 1 and where we have defined\n\u03b7x =\n\n\u03c7x\n,\n1 \u2212 \u03c7x\n\nx = h, \u03b8 .\n\n(49)\n\nThis means that out of the discrete part of the local field distributions, i.e., Mi (t) (Li (t)), only\nthe \u03c3i (t \u2212 1) (\u03c3i2 (t \u2212 1)) term is kept besides, of course, the signal\nterms. These expressions\n\u0013\n\u0012\n\nconsist out of two parts: A normally distributed part, h\u0303i = N \u03bei m/a, \u03b1q/a2 (1 \u2212 \u03c7h )2\n\nand\n\nthe analogous formula for \u03b8\u0303i , and some discrete noise part. Employing these expressions in the\nupdating rule one finds\n\u03b1\n\u03b1\n\u03c3i = g h\u0303i + \u03b7h \u03c3i , \u03b8\u0303i +\n\u03b7\u03b8 \u03c3i2 .\na\na(1 \u2212 a)\n\u0013\n\n\u0012\n\n(50)\n\nThis is a self-consistent equation in \u03c3i which, in general, admits more than one solution. This\ntype of equation has been solved in the case of analog neural networks with continuous time\ndynamics [13] and in the case of Q-Ising neural networks [4], [10] using a Maxwell construction.\nHere we follow the same line of reasoning for the joint probability distribution of the local\nfields in the (h, \u03b8)-plane (see fig. 1) leading to a unique solution\n\u0012\n\n\u0013\n\n\u0012\n\n\u0013\n\n\u03c3i \u2261 g\u0303 h\u0303i , \u03b8\u0303i = sign(h\u0303i )\u0398 |h\u0303i | + \u03b8\u0303i + \u2206 ,\n\n(51)\n\nwhere\n\u2206=\n\n\u03b1\n\u03b1\n\u03b7h +\n\u03b7\u03b8 .\n2a\n2a(1 \u2212 a)\n\n(52)\n\nUsing the definition of the order parameters (see (10), (11)) in the limit N \u2192 \u221e one finds in\nthe fixed point, dropping the index i\n9\n\n\f\u0011\n\u03b1q\n\u03b1q\nz, \u03b7l +\ny\na\na(1 \u2212 \u03c7h )\na(1 \u2212 a)(1 \u2212 \u03c7\u03b8 )\n++\n**Z\n\u221a\n\u221a\nZ\n\u0011\n\u00101\n\u03b1q\n\u03b1q\nz, \u03b7l +\ny\nDz Dy g\u0303 2 \u03bem +\nq=\na\na(1 \u2212 \u03c7h )\na(1 \u2212 a)(1 \u2212 \u03c7\u03b8 )\n** Z\n++\n\u221a\n\u221a\nZ\n\u0010\n\u0011\n\u03b1q\n\u03b1q\n2 1\nl = \u03b7 Dz Dy g\u0303\n\u03bem +\nz, \u03b7l +\ny\n.\na\na(1 \u2212 \u03c7h )\na(1 \u2212 a)(1 \u2212 \u03c7\u03b8 )\n\nm=\n\n1\na\n\n\u03be\n\nDz\n\nDy g\u0303\n\n\u00101\n\n\u03bem +\n\n(53)\n(54)\n(55)\n\nFrom (27)-(28), (38)-(39) and (25)-(26) it is clear that\nD=\n\na3 (1\n\nq\n,\n\u2212 \u03c7h )2\n\nE=\n\nq\na(1 \u2212 a)(1 \u2212 \u03c7\u03b8 )2\n\n(56)\n\nwith\n++\n**Z\n\u221a\n\u221a\nZ\n\u0011\n\u00101\n\u03b1q\n\u03b1q\n1\nz, \u03b7l +\ny\n(57)\nDz Dy z g\u0303 \u03bem +\n\u03c7h = \u221a\na\na(1 \u2212 \u03c7h )\na(1 \u2212 a)(1 \u2212 \u03c7\u03b8 )\n\u03b1a3 D\n++\n**Z\n\u221a\n\u221a\nZ\n\u0011\n\u0010\n\u03b1q\n\u03b1q\n1\n2 1\n\u03c7\u03b8 = q\n\u03bem +\nz, \u03b7l +\ny\n.\nDz Dy y g\u0303\na\na(1 \u2212 \u03c7h )\na(1 \u2212 a)(1 \u2212 \u03c7\u03b8 )\na(1 \u2212 a)\u03b1E\n\n(58)\n\nThese equations are the same as the fixed-point equations derived from a replica-symmetric\nmean-field theory treatment [2].\n\u03b8\n\nh\nP\n\nFig. 1. The Maxwell construction. To the right of the short-dashed line the solution \u03c3 = 1 exists, to\nthe left of the long-dashed line, \u03c3 = \u22121 is a solution, and under the dotted line, \u03c3 = 0 exists. The\nthick full line shows\nthe\n\u0010\n\u0011 unique solution, dividing the local fields space in three parts. The point P is\ngiven by P = 0, \u2212\u2206 .\n\n5\n\nLocal field distribution\n\nIt is interesting to study the distribution of the local fields, the main ingredients in our dynamical scheme. First, we look at the stationary distribution. Since the Maxwell construction\nwe used is discussed in the plane (h, \u03b8), we want to find the joint-distribution for the local\nfields, \u03c1\u221e (h, \u03b8) \u2261 \u03c1h(\u221e),\u03b8(\u221e) (h, \u03b8) defined by\n10\n\n\f\u03c1\u221e (h, \u03b8) =\n\n\u03b1q\n\u03b1\n1\n1\nz\nDzDy\u03b4 h \u2212 \u03bem \u2212 \u03b7h \u03c3 \u2212\na\na\n1 \u2212 \u03c7h a2\n\u03c3\ns\n\u0013\n\u0012\n1\n\u03b1\n\u03b1q\n2\n\u03b7\u03b8 \u03c3 \u2212\ny\n\u03a6(\u03c3) ,\n\u00d7\u03b4 \u03b8 \u2212 \u03b7l \u2212\na(1 \u2212 a)\n1 \u2212 \u03c7\u03b8 a2 (1 \u2212 a)2\n\n(59)\n\nwhere \u03a6(\u03c3) is obtained from the updating rule after the Maxwell construction (see eq. (51))\n\u03b1\u03b7h\n\u03b1\u03b7\u03b8\n\u03a6(\u03c3) = \u0398 \u2212 |h| \u2212 \u03b8 \u2212\n\u03b4\u03c3,0\n\u2212\n2a\n2a(1 \u2212 a)\n\u0012 \u0013 \u0012\n\u0013\n\u03b1\u03b7h\n\u03b1\u03b7\u03b8\n+\u0398 h \u0398 h + \u03b8 +\n\u03b4\u03c3,1\n+\n2a\n2a(1 \u2212 a)\n\u0012\n\u0013 \u0012\n\u0013\n\u03b1\u03b7h\n\u03b1\u03b7\u03b8\n+\u0398 \u2212 h \u0398 \u2212 h + \u03b8 +\n\u03b4\u03c3,\u22121 .\n+\n2a\n2a(1 \u2212 a)\n\u0012\n\n\u0013\n\n(60)\n\nThis leads to\n\u03b1\n\u03b1\n\u03b7h )\u0398(h + \u03b8 \u2212 \u2206) + \u03c1\u22121 (h, \u03b8)\u0398(\u2212h \u2212 \u03b7h )\u0398(\u2212h + \u03b8 \u2212 \u2206)\na\na\n+ \u03c10 (h, \u03b8)\u0398(\u2212|h| \u2212 \u03b8 \u2212 \u2206) ,\n(61)\n\n\u03c1\u221e (h, \u03b8) = \u03c1+1 (h, \u03b8)\u0398(h \u2212\nwhere\n\n\u03c1\u03c3 =\n\n(1 \u2212 \u03c7h )(1 \u2212 \u03c7\u03b8 )(1 \u2212 a)a2\nexp\n2\u03c0q\u03b1\n\n\u0012\n\n\u2212\n\n\u00d7 exp\n\n1 (h \u2212 a\u03be m \u2212 \u03b1a \u03b7h \u03c3)2\n\u03b1q\n1\n2\n(1\u2212\u03c7h )2 a2\n\u0012\n\n\u0013\n\n\u03b1\n2 2\u0013\n1 (\u03b8 \u2212 \u03b7l \u2212 a(1\u2212a) \u03b7\u03b8 \u03c3 )\n.\n\u2212\n\u03b1q\n1\n2\n(1\u2212\u03c7\u03b8 )2 a2 (1\u2212a)2\n\n(62)\n\nAnalyzing these expressions we see that the distribution \u03c1\u221e (h, \u03b8) shows a gap. In fig. 2 we show\nthis gap structure which depends, of course, on the specific values of the physical parameters\n\u03b1, a, \u03c7h , \u03c7\u03b8 of the system. The important points bordering these gaps are given by P+1 =\n( \u03b1a \u03b7h , \u2206 \u2212 \u03b1a \u03b7h ), P\u22121 = (\u2212 \u03b1a \u03b7h , \u2206 \u2212 \u03b1a \u03b7h ), P0 = (0, \u2212\u2206).\n\u03b8\n\nGAP\n\n\u03c1\n\n\u03c1\n\n\u22121\n\n+1\n\nh\nP\u22121\n\nP+1\nP0\n\nG\n\nG\n\nAP\n\nAP\n\u03c10\n\nFig. 2. The gap structure of \u03c1\u221e (h, \u03b8). The coordinates of the points P+1 , P\u22121 , P0 are given in the\ntext. The integral \u03c1\u00b11 in (61) is only different from zero in the region to the right (left) of the line\non which P\u00b11 lies; \u03c10 exists only below the line on which P0 lies.\n\n11\n\n\fDividing this joint probability by their integrations with respect to h (or \u03b8) we can obtain\nprojections on the \u03b8 (or h) axis\n\u03c1\u221e (h, \u03b80 )\n\u2212\u221e \u03c1\u221e (h, \u03b80 )dh\n\u03c1\u221e (h0 , \u03b8)\n\u03c1t=\u221e (\u03b8|h0 ) = R \u221e\n.\n\u2212\u221e \u03c1\u221e (h0 , \u03b8)d\u03b8\n\n(63)\n\n\u03c1t=\u221e (h|\u03b80 ) = R \u221e\n\n(64)\n\nFinally, starting from (42)-(43) one can write down expressions for \u03c1h(t) (h), \u03c1\u03b8(t) (\u03b8) for the\nfirst time steps and calculate both the joint probability and its projections from it. This is\nillustrated in Appendix B. All these projections will be compared with numerical simulations\nin the next Section.\n\n6\n\nNumerical results and simulations\n\nThe equations derived in Sections 3-5 and Appendices A and B have been studied numerically\nand have been compared with simulations for systems up to N = 6000 neurons averaged over\n500 runs.\nWe start with the remark that the initial conditions are not independent because positivity of\nthe relevant probabilities implies\n\nq0 > am10 ,\n\nm10 \u2212 q0\n\u2265 l01 ,\n1\u2212a\n\nand for a \u2265 q0 :\nfor a \u2264 q0 :\n\nq0\na\n1\n\u2212 q0\nl01 \u2264\n.\n1\u2212a\n\nl01 \u2264\n\n(65)\n\nThe phase diagram of the fully connected BEG neural network has been discussed in [2] using\na replica-symmetric mean-field theory. From that work we see that for uniformly distributed\npatterns the critical capacity at zero temperature is 0.091.\nThe first point we would like to examine is whether the recursive dynamical scheme we have\nderived is confirmed by simulations. This is illustrated by some typical results in fig. 3 showing\nthe order parameters as a function of \u03b1 for uniform patterns and m0 = 0.6, l0 = 0.6, q0 = 0.5.\nWe see that the theoretical results, given by the explicit formula in Appendix A, and the\nsimulations agree very well over the whole range of \u03b1's. Furthermore, we learn that in the\nretrieval regime the first time steps of the dynamics give us already a reasonable estimate for\nthe critical capacity especially through the order parameter l. This is also the case for the\nother values of a, a = 0.02, 0.05, 0.08, we have considered.\nThese findings are confirmed by some typical (m(t), l(t)) flow diagrams. In figs. 4 and 5 we show\nthe results for uniform patterns and two values of \u03b1 in the retrieval region, \u03b1 = 0.015, 0.08,\ngiving us a good idea of the basin of attraction. Remark that to the right of the dotted line\nwe cannot start initially because of the condition (65). At later times we can enter this region\nbecause q(t) changes from its initial value q(0) = a = 2/3. The dashed line in the figures 4a\n12\n\n\f0.95\n\n0.9\n\nm(t)\n\n0.85\n\n0.8\n\n0.75\n\n0.7\n\n0\n\n0.05\n\n0.1\n\n\u03b1\n\n0.15\n\n0.2\n\n1\n0.95\n0.9\n0.85\n0.8\n\nl(t)\n\n0.75\n0.7\n0.65\n0.6\n0.55\n0.5\n0.45\n\n0\n\n0.05\n\n0.1\n\n\u03b1\n\n0.15\n\n0.2\n\n0\n\n0.05\n\n0.1\n\n\u03b1\n\n0.15\n\n0.2\n\n0.74\n\n0.72\n\n0.7\n\n0.68\n\nq(t)\n0.66\n\n0.64\n\n0.62\n\n0.6\n\nFig. 3. Order parameters m(t), l(t) and q(t) as a function of the capacity \u03b1 for the first three time\nsteps and a = 2/3,m0 = 0.6, l0 = 0.6, q0 = 0.5. Theoretical results (solid lines) versus simulations\nwith N = 6000 (time 1, 2 and 3 given by the plus symbol, times symbol respectively circles) are\nshown.\n\nand 5a indicates the border of the basin of attraction. To have an idea about the accuracy\nof this basin boundary we also show in figs 4b and 5b the percentage of runs going to the\nattractor on the line m0 = l0 , starting from the (0,0)-point. The basin boundary is drawn\njoining the starting points of the flow lines reaching the attractor with a percentage lying\nbetween 45% and 55%, as visualized by the two parallel dashed lines. As expected, the basin\nof attraction shrinks for increasing \u03b1, due to the appearance of other thermodynamically stable\nstates (spin-glass states), and the error for defining the basin boundary becomes bigger. For\ncomparable values of the relevant system parameters for the Q-Ising model one can verify (see\n[10]) that the basin of attraction of the latter is smaller.\n\n13\n\n\f(b)\n\n(a)\n1\n\n100\n\n0.9\n\n90\n\n0.8\n\n80\n\n0.7\n\n70\n\n0.6\n\nl(t)\n\n60\n\n%\n\n0.5\n\n50\n\n0.4\n\n40\n\n0.3\n\n30\n\n0.2\n\n20\n\n0.1\n\n10\n\n0\n\n0\n\n0.2\n\n0.4\n\nm(t)\n\n0.6\n\n0.8\n\n0\n\n1\n\n0\n\n0.04\n\n0.08\n\n0.12\n\nm(0)=l(0)\n\nFig. 4. Flow diagram for uniform patterns a = 2/3 and capacity \u03b1 = 0.015. In figure 4a, the\nlong-dashed line shows the basin boundary. The parallel dashed lines in figure 4b indicate the error\nbounds.\n(b)\n\n(a)\n1\n\n100\n\n0.9\n\n90\n\n0.8\n\n80\n\n0.7\n\n70\n\n0.6\n\nl(t)\n\n60\n\n%\n\n0.5\n\n50\n\n0.4\n\n40\n\n0.3\n\n30\n\n0.2\n\n20\n\n0.1\n\n10\n\n0\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n0\n0.2\n\nm(t)\n\n0.4\n\n0.6\n\nm(0)=l(0)\n\n0.8\n\nFig. 5. As in fig. 4 for \u03b1 = 0.08.\n\nThe next point we look at is the appearance of a so-called quadrupolar state (m = 0, l 6= 0).\nExtended simulations did not show any such stable state at zero temperature in the fully\nconnected model. This is different from the findings in the diluted model where a quadrupolar\nstate is predicted [1]. However, recent discussions indicate that also for this diluted model the\nquadrupolar state is not stable at temperature zero [14].\nFinally, we consider the distributions of the local field, an important ingredient in our dynamical scheme. We have investigated them numerically using the fixed-point equations mentioned\nbefore and compared them with numerical simulations. Some typical results are shown in\nfigs. 6 for uniform patterns. In fig. 6a we show the joint distribution of the local fields, for\n\u03be = 0, projected on the h-axis, fixing \u03b8 = \u22120.6, in the retrieval region, \u03b1 = 0.064, for\nm0 = l0 = 0.5, q0 = 0.5, while fig.6b represents this distribution in the non-retrieval region,\n\u03b1 = 0.13, for m0 = l0 = 0.2, q0 = 0.5. The first time steps, given by the explicit formula in\nAppendix B, are in complete agreement with the numerical simulations.\nConcerning the gap structure we see that for the retrieval state there are, typically, small gaps\nin the equilibrium distribution. For small \u03b1 the gaps are very narrow (see insets of fig. 6a). In\nthe simulations these gaps show up very quickly. In order not to overload the figures we have\nplotted one intermediate result for the time step t = 100. For the non-retrieval state the gaps\n14\n\n\fare typically much bigger. Again in simulations the gaps show up rather quickly. In fig. 7 we\nplot a 3-d picture of the equilibrium distribution for \u03be = 0 in the spin-glass region, \u03b1 = 0.013,\nfor uniform patterns. The gaps are clearly visible. We recall that the theoretical equilibrium\nresults coincide with the thermodynamic replica-symmetric solution and that it is expected\nthat the gaps are reduced to one point for the exact solution. It is extremely difficult to find\npoints touching the axis in the simulations because of the final size effects. Analogous results\nhave been found for the Hopfield model, the Q-Ising model [15], [16], [17] and, first, in the\ninfinite range spin-glass [18].\n\n(a)\n\n(b)\n0.5\n0.2\n\n1.4\n\n0.2\n\n1.6\n\n0.1\n0\n\n0\n\u22120.65\n\n\u22120.6\n\n\u22120.55\n\n0.55\n\n0.6\n\n0.65\n\nP(h|\u03b8=\u22120.6)\n\nP(h|\u03b8=\u22120.6)\n\n1\n\n0.1\n\n0.4\n1.2\n\n0.8\n\n0.6\n\n0.3\n\n0.2\n\n0.4\n0.1\n0.2\n\n0\n\u22121.5\n\n\u22121\n\n\u22120.5\n\n0\n\nh\n\n0.5\n\n1\n\n1.5\n\n0\n\n\u22124\n\n\u22123\n\n\u22122\n\n\u22121\n\n0\n\nh\n\n1\n\n2\n\n3\n\n4\n\nFig. 6. Projections of the joint probability distribution of the local fields in the retrieval (\u03b1 = 0.064,\nfig. 6a) and the spin-glass phase (\u03b1 = 0.13, fig. 6b). Simulations for time steps 0 (circles), 1 (squares)\nand 100 (plus symbol) are shown. For clarity we have not included time 0 results in fig. 6b. Dotted,\nsolid and dashed lines show the theoretical results for times 0, 1 and \u221e.\n\n7\n\nConclusions\n\nAn evolution equation is derived for the distribution of the local field governing the parallel\ndynamics at zero temperature of BEG networks. All feedback correlations are taken into\naccount. This distribution contains both a normally distributed part and a discrete part.\nEmploying this evolution equation a general recursive scheme is developed allowing one to\ncalculate the relevant order parameters of the system, i.e., the retrieval overlap, the activity\noverlap and the neural activity for any time step. This scheme has been worked out explicitly\nfor the first three time steps of the dynamics.\nUnder the condition that the local field becomes time-independent, meaning that some of the\ndiscrete noise is neglected, fixed-point equations are obtained for the order parameters. They\nagree with those obtained from a mean-field replica symmetric thermodynamic approach. The\ngap structure of the equilibrium local field distribution is examined. The gaps in the retrieval\nregime are much smaller than those in the non-retrieval regime.\nExtensive numerical simulations are performed for a system of 6000 neurons. They confirm the\nresults obtained from the dynamical scheme both for the local fields and the order parameters.\nFurthermore, they illustrate that the first few time steps do give a reasonable estimate of the\n15\n\n\fFig. 7. A 3-d plot of the joint probability for the local field distribution for \u03be = 0 in the spin glass\nphase, \u03b1 = 0.013, and uniform patterns, a = 2/3, at t \u2192 \u221e.\n\ncritical capacity, especially through the activity overlap order parameter. Finally, flow diagrams\nindicate the size of the basin of attraction of the retrieval state as a function of the loading.\n\nAcknowledgements\nThis work has been supported in part by the Fund of Scientific Research, Flanders-Belgium.\nThe authors are indebted to D. Dominguez, R. Erichsen jr, I. P\u00e9rez Castillo, W.K. Theumann\nand T. Verbeiren for constructive discussions.\n\nAppendix A\nFollowing the general recursive scheme developed in Section 3, evolution equations are derived\nfor the first three time steps of the BEG fully connected network, taking into account all\ncorrelations. Our starting point is the set of equations for the order parameters (15)-(17) with\nthe following initial conditions\nm1 (0) = m0 , l1 (0) = l0 , q(0) = q0\n1\n\u03b1q0\n\u03b1q0\nhi (0) = \u03bei1 m0 + N (0, 2 ), \u03b8i (0) = \u03b7i1 l0 + N (0, 2\n)\na\na\na (1 \u2212 a)2\nq0\n\u03b1E(0)\nq0\n, V (0) = \u03b1aD(0), W (0) =\n.\nD(0) = 3 , E(0) =\na\na(1 \u2212 a)\na(1 \u2212 a)\n16\n\n(66)\n(67)\n(68)\n\n\fFrom now on we forget about the superscript 1 to indicate the condensed pattern.\n\nFirst time step\n\nWe immediately get from (15)-(17)\n1\n\u03be\nm(1) =\na\n\u001c\u001cZ\n\n\u001c\u001c Z\n\nDz\n\nq(1) =\n\nl(1) =\n\nDz\n\n\u001c\u001c Z\n\n\u03b7\n\nZ\n\nDz\n\nZ\n\nDy g\n\u0010\n\n\u0010\n\nh\u20320 (z), \u03b80\u2032 (y)\n\nDy g 2 h\u20320 (z), \u03b80\u2032 (y)\nZ\n\n\u0010\n\n\u0011\u001d\u001d\n\n(69)\n\n\u0011\u001d\u001d\n\nDy g 2 h\u20320 (z), \u03b80\u2032 (y)\n\n(70)\n\n\u0011\u001d\u001d\n\n,\n\n(71)\n\n\u221a\nwhere Dx = dx exp(\u2212x2 /2)/ 2\u03c0 denotes the Gaussian measure and\nq\n1\nh\u20320 (z) = \u03bem0 + V (0) z,\na\n\n\u03b80\u2032 (y) = \u03b7l0 +\n\nq\n\nW (0) y .\n\n(72)\n\n\u03bc\nFrom the definition of h\u0303\u03bcN,i (t) and \u03b8\u0303N,i\n(t), we know that, when N \u2192 \u221e, the elements in the\n\u03bc\n\u03bc\n\u03bc\n\u03bc\npairs {\u03bei , g(h\u0303i (0), \u03b8\u0303i (0))}, {\u03bei , \u03c3i (0)}, {\u03b7i\u03bc , g 2(h\u0303\u03bci (0), \u03b8\u0303i\u03bc (0))} and {\u03b7i\u03bc , \u03c3i2 (0)} are uncorrelated\nfor \u03bc 6= 1. Therefore, using the recursion relations (38) (39) we get\n\nq(1)\n+ \u03c72h (0)D(0) + 2\u03c7h (0)R(1, 0)\n3\na\nq(1)\n+ \u03c72\u03b8 (0)E(0) + 2\u03c7\u03b8 (0)S(1, 0) ,\nE(1) =\na(1 \u2212 a)\n\n(73)\n\nD(1) =\n\n(74)\n\nwhere, in general, the correlation parameters are defined as\ni\n1 h\n\u2032\n\u2032\nE\ng(\nh\u0303(t\n\u2212\n1),\n\u03b8\u0303(t\n\u2212\n1))g(\nh\u0303(t\n\u2212\n1),\n\u03b8\u0303(t\n\u2212\n1))\na3\ni\n1 h\nR(t, 0) = 3 E \u03c3(0)g(h\u0303(t \u2212 1), \u03b8\u0303(t \u2212 1))\na\nh\ni\n1\nS(t, t\u2032 ) =\nE g 2 (h\u0303(t \u2212 1), \u03b8\u0303(t \u2212 1))g 2 (h\u0303(t\u2032 \u2212 1), \u03b8\u0303(t\u2032 \u2212 1))\na(1 \u2212 a)\nh\ni\n1\nE \u03c3 2 (0)g 2 (h\u0303(t \u2212 1), \u03b8\u0303(t \u2212 1))\nS(t, 0) =\na(1 \u2212 a)\n\nR(t, t\u2032 ) =\n\n(75)\n(76)\n(77)\n(78)\n\nleading, in the limit N \u2192 \u221e, to the following formula for the first time step\n1\nR(1, 0) = 3\na\nS(1, 0) =\n\n\u001c\u001c\n\n\u03c3(0)\n\n1\na(1 \u2212 a)\n\nZ\n\n\u001c\u001c\n\nDz\n\nZ\n\n\u03c3 2 (0)\n\nDy g\nZ\n\nDz\n\n\u0010\n\nZ\n\nh\u20320 (z), \u03b80\u2032 (y)\n\u0010\n\n\u0011\u001d\u001d\n\nDy g 2 h\u20320 (z), \u03b80\u2032 (y)\n\nSince at time zero there are no correlations yet\n17\n\n(79)\n\u0011\u001d\u001d\n\n.\n\n(80)\n\n\f1\nDz Dy z g h\u20320 (z), \u03b80\u2032 (y)\n\u03c7h (0) = q\na V (0)\n\u001c\u001cZ\nZ\n\u0010\n\u0011\u001d\u001d\n1\n\u2032\n\u2032\n2\nq\n.\nDz Dy y g h0 (z), \u03b80 (y)\n\u03c7\u03b8 (0) =\na(1 \u2212 a) W (0)\n\n(81)\n(82)\n\nSecond time step\nFirst, we need the distribution of the local fiels at time t = 1. This follows immediately from\n(35)-(36) and (37)\n\u03bei\n\u03b1\nm(1) + \u03c7h (0)\u03c3i (0) + N (0, V (1))\na\na\n\u03b1\n\u03c7\u03b8 (0)\u03c3i2 (0) + N (0, W (1)) .\n\u03b8i (1) = \u03b7i l(1) +\na(1 \u2212 a)\n\nhi (1) =\n\n(83)\n(84)\n\nThese results allow us to write down the order parameters at time step 2:\n1\nm(2) =\n\u03be\na\n\u001c\u001cZ\n\n\u001c\u001c Z\n\nDz\n\nq(2) =\n\nl(2) =\n\n\u001c\u001c Z\n\n\u03b7\n\nDz\nZ\n\nDz\n\nZ\n\nDy g\n\u0010\n\n\u0010\n\nh\u20321 (z), \u03b81\u2032 (y)\n\nDy g 2 h\u20321 (z), \u03b81\u2032 (y)\nZ\n\n\u0010\n\n\u0011\u001d\u001d\n\n(85)\n\n\u0011\u001d\u001d\n\nDy g 2 h\u20321 (z), \u03b81\u2032 (y)\n\n(86)\n\n\u0011\u001d\u001d\n\n,\n\n(87)\n\nwhere\nq\n1\n\u03b1\nh\u20321 (z) = \u03bem(1) + \u03c7h (0)\u03c3i (0) + V (1) z\na\na\nq\n\u03b1\n\u2032\n\u03b81 (y) = \u03b7l(1) +\n\u03c7\u03b8 (0)\u03c3i2 (0) + W (1) y\na(1 \u2212 a)\n\n(88)\n(89)\n\nand\n\u03c7h (1) =\n\u03c7\u03b8 (1) =\n\n1\nq\n\na V (1)\n1\n\n\u001c\u001cZ\n\nq\n\nDz\n\na(1 \u2212 a) W (1)\n\nZ\n\nDy z g\n\n\u001c\u001cZ\n\nDz\n\nZ\n\n\u0010\n\nh\u20321 (z), \u03b81\u2032 (y)\n\nDy y g\n\n2\n\n\u0010\n\n\u0011\u001d\u001d\n\nh\u20321 (z), \u03b81\u2032 (y)\n\n(90)\n\u0011\u001d\u001d\n\n.\n\n(91)\n\nThe calculation of the variance of the residual overlap needs some more work. From the\nrecursion relations (38)-(39) one finds\n\u0010\n\u0011\nq(2)\n2\n+\n\u03c7\n(1)D(1)\n+\n2\u03c7\n(1)\nR(2,\n1)\n+\n\u03c7\n(0)R(2,\n0)\nh\nh\nh\na3\n\u0010\n\u0011\nq(2)\nE(2) =\n+ \u03c72\u03b8 (1)E(1) + 2\u03c7\u03b8 (1) S(2, 1) + \u03c7\u03b8 (0)S(2, 0) ,\na(1 \u2212 a)\n\nD(2) =\n\n18\n\n(92)\n(93)\n\n\fwhere R(2, 0) and S(2, 0) can be written down immediately\n1\nR(2, 0) = 3\na\nS(2, 0) =\n\n\u001c\u001c\n\n\u03c3(0)\n\n1\na(1 \u2212 a)\n\nZ\n\nDz\n\n\u001c\u001c\n\nZ\n\n\u03c3 2 (0)\n\nDy g\nZ\n\nDz\n\n\u0010\n\nZ\n\nh\u20321 (z), \u03b81\u2032 (y)\n\u0010\n\n\u0011\u001d\u001d\n\n(94)\n\nDy g 2 h\u20321 (z), \u03b81\u2032 (y)\n\n\u0011\u001d\u001d\n\n.\n\n(95)\n\nTo obtain R(2, 1) and S(2, 1) we remark that the local fields at time steps 0 and 1 are correlated. The correlation coefficients of their normally distributed part, viz.\n\n\u03c1h (t, t\u2032 ) =\n\nE[(h(t) \u2212 M(t))(h(t\u2032 ) \u2212 M(t\u2032 ))]\n\n(96)\n\n\u03c1\u03b8 (t, t\u2032 ) =\n\nE[(\u03b8(t) \u2212 L(t))(h\u03b8(t\u2032 ) \u2212 L(t\u2032 ))]\n\n(97)\n\nq\n\nq\n\nV (t) V (t\u2032 )\n\nq\n\nq\n\nW (t) W (t\u2032 )\n\nis found using the recursion formula (83)-(84)\n\u03c1h (1, 0) =\n\nR(1, 0) + D(0)\u03c7h (0)\n\n\u03c1\u03b8 (1, 0) =\n\nq\n\nD(0)D(1)\n\nS(1, 0) + E(0)\u03c7\u03b8 (0)\nq\n\nE(0)E(1)\n\n.\n\n(98)\n\nEmploying all this in eqs. (75) and (77) we arrive at\n1\nR(2, 1) = 3\na\nS(2, 1) =\n\n\u001c\u001cZ\n\nD\u03c9h1,0 (z, s)\n\n1\na(1 \u2212 a)\n\n\u001c\u001cZ\n\nZ\n\nD\u03c9\u03b81,0(y, t)\n\nD\u03c9h1,0 (z, s)\n\nZ\n\ng\n\n\u0010\n\nh\u20321 (z), \u03b81\u2032 (y)\n\u0010\n\n\u0011\n\ng\n\n\u0010\n\nh\u20320 (s), \u03b80\u2032 (t)\n\u0011\n\n\u0010\n\n\u0011\u001d\u001d\n\nD\u03c9\u03b81,0 (y, t) g 2 h\u20321 (z), \u03b81\u2032 (y) g 2 h\u20320 (s), \u03b80\u2032 (t)\n\n(99)\n\u0011\u001d\u001d\n\n,(100)\n\nwhere the joint distribution D\u03c9xa,b (z, y) equals\nD\u03c9xa,b(z, y)\n\nz 2 \u2212 2zy\u03c1x (a, b) + y 2\n= q\nexp \u2212\n2(1 \u2212 \u03c12x (a, b))\n2\u03c0 1 \u2212 \u03c12x (a, b)\ndzdy\n\n!\n\n.\n\n(101)\n\nThird time step\nWe start by writing down the distribution of the local fiels at t = 2\n\u03bei\n\u03b1\nhi (2) = m(2) + \u03c7h (2) \u03c3i (1) + \u03c7h (0)\u03c3i (0) + N (0, V (2))\na\na\n\u0015\n\u0014\n\u03b1\n2\n2\n\u03c7\u03b8 (1) \u03c3i (1) + \u03c7\u03b8 (0)\u03c3i + N (0, W (2)) .\n\u03b8i (2) = \u03b7i l(2) +\na(1 \u2212 a)\n\u0014\n\n\u0015\n\n(102)\n(103)\n\nIn order to write down the expressions for the order parameters starting from (15)-(17) the\naverage has to be taken over the Gaussian noise, \u03c3i (0) and \u03c3i (1). The average over \u03c3i (0)\ncauses no difficulties because this initial configuration is chosen randomly. The average over\nthe Gaussian random noise variable appearing in hi (2), \u03b8i (2), and \u03c3i (1) is more tricky because,\ne.g., hi (2) and \u03c3i (1) are correlated by the dynamics. However, the evolution equation tells us\n19\n\n\fthat \u03c3i (1) can be replaced by g(hi (0), \u03b8i (0)) and, hence, its average taken over hi (0),\u03b8i (0)\ninstead of \u03c3i (1). From the recursion relation (31)-(32) one finds for the relevant correlation\ncoefficients\n\nR(2, 0) + R(1, 0)\u03c7h (1) + D(0)\u03c7h (1)\u03c7h (0)\n\n\u03c1h (2, 0) =\n\n(104)\n\nq\n\nD(0)D(2)\n\nS(2, 0) + S(1, 0)\u03c7\u03b8 (1) + E(0)\u03c7\u03b8 (1)\u03c7\u03b8 (0)\n\n\u03c1\u03b8 (2, 0) =\n\nq\n\nE(0)E(2)\n\n.\n\n(105)\n\nUsing this we get\n\nm(3) =\nq(3) =\nl(3) =\n\n1\n\u03be\na\n\u001c\u001cZ\n\n\u001c\u001c Z\n\nD\u03c9h2,0(z, s)\n\nD\u03c9h2,0(z, s)\n\n\u001c\u001c Z\n\n\u03b7\n\nZ\n\nZ\n\n\u001d\u001d\n\nD\u03c9\u03b82,0 (y, t)g (h\u20322 (z, s, t), \u03b82\u2032 (y, s, t))\n\n(106)\n\n\u001d\u001d\n\n(107)\n\nD\u03c9\u03b82,0(y, t)g 2 (h\u20322 (z, s, t), \u03b82\u2032 (y, s, t))\n\nD\u03c9h2,0(z, s)\n\nZ\n\n\u001d\u001d\n\nD\u03c9\u03b82,0(y, t)g 2 (h\u20322 (z, s, t), \u03b82\u2032 (y, s, t))\n\n(108)\n\nwith the joint distributions as defined before (see, (101)) and\n\nq\n\u03b1\n1\nh\u20322 (z, s, t) = \u03bem(2) + \u03c7h (1)[g(h\u20320 (s), \u03b80\u2032 (t)) + \u03c7h (0)\u03c3(0)] + V (2) z\na\na\nq\n\u03b1\n\u03c7\u03b8 (1)[g 2(h\u20320 (s), \u03b80\u2032 (t)) + \u03c7\u03b8 (0)\u03c3 2 (0)] + W (2) y .\n\u03b82\u2032 (y, s, t) = \u03b7l(2) +\na(1 \u2212 a)\n\n(109)\n(110)\n\nIn the same way further time steps can be calculated at the price of more complicated algebraic\nexpressions.\n\nAppendix B\n\nWe calculate explicitly the projected joint distributions for the local fields for the first time\nsteps. Starting from (42)-(43) we obtain\n\n\u2212(h \u2212 a\u03be m0 )2\n\u03c1h(0) (h) = q\nexp\n2V (0)\n2\u03c0V (0)\n1\n\n\u03c1\u03b8(0) (\u03b8) =\n\n\u001a\n\n\u2212(\u03b8 \u2212 \u03b7l0 )2\nexp\n2W (0)\n2\u03c0W (0)\n1\n\nq\n\n\u001a\n\n\u001b\n\n(111)\n\n\u001b\n\n(112)\n\nand\n20\n\n\f\u2212(h \u2212 a m(1) \u2212 a \u03c7h (0)\u03c3(0))2\n1\n\u03c1h(1) (h) = q\nexp\n2V (1)\n2\u03c0V (1)\n1\n\nexp\n\u03c1\u03b8(1) (\u03b8) = q\n2\u03c0W (1)\n\n\u001a \u2212(\u03b8\n\n\u2212 \u03b7l(1) \u2212\n\n\u03b1\n\u03c7 (0)\u03c3 2 (0))2 \u001b\na(1\u2212a) \u03b8\n\n2W (1)\n\n(113)\n.\n\n(114)\n\nTo construct the joint probability for t = 0 we just have to take the product of (111) and\n(112). In order to find the joint probability for t = 1 we have to average the product of (113)\nand (114)over \u03c3(0). This leads to\n\n\u03c1t=1 (h, \u03b8) =\n\n1\nq\n\n2\u03c0 V (1)W (1)\n\u03b1\n2\u001b\n\u001a\n\u2212(h \u2212 a\u03be m(1) \u2212 \u03b1a \u03c7h (0))2 \u2212(\u03b8 \u2212 \u03b7l(1) \u2212 a(1\u2212a) \u03c7\u03b8 (0))\nq0\nexp\n\u2212\n\u00d7\n2\n2V (1)\n2W (1)\n\u03b1\n2\u001b\n\u001a\n\u2212(h \u2212 a\u03be m(1) + \u03b1a \u03c7h (0))2 \u2212(\u03b8 \u2212 \u03b7l(1) \u2212 a(1\u2212a) \u03c7\u03b8 (0))\nq0\n+ exp\n\u2212\n2\n2V (1)\n2W (1)\n\u001b\u0015\n\u001a\n\u03be\n2\n\u2212(h \u2212 a m(1))\n\u2212(\u03b8 \u2212 \u03b7l(1))2\n.\n\u2212\n+(1 \u2212 q0 ) exp\n2V (1)\n2W (1)\n\n\u0014\n\n(115)\n\nThe projected distributions are then obtained analogously to eqs. (63) and (64). For t = 0 we\nfind back (111) and (112) confirming again that the local fields at time zero are independent\nbecause no correlations are present yet. For the first time step we obtain\n\n\u0014\n\u001a \u2212(\u03b8 \u2212 \u03b7l(1) \u2212 \u03b1 \u03c7 (0))2 \u001b\n0\n1\nq0\na(1\u2212a) \u03b8\n\u03c1t=1 (h|\u03b80 ) = q\nexp\n2W (1)\n2\u03c0V (1) 2\n\n\u2212(h \u2212 a\u03be m(1) + \u03b1a \u03c7h (0))2\n\u2212(h \u2212 a\u03be m(1) \u2212 \u03b1a \u03c7h (0))2\n+ exp\n\u00d7\n2V (1)\n2V (1)\n\u001a\n\u001b\n\u001a\n\u001b\u0015\n\u2212(h \u2212 a\u03be m(1))2\n\u2212(\u03b80 \u2212 \u03b7l(1))2\n+(1 \u2212 q0 ) exp\nexp\n2V (1)\n2W (1)\n\u001a\n\u001b\u0015\n\u0014\n\u001a \u2212(\u03b8 \u2212 \u03b7l(1) \u2212 \u03b1 \u03c7 (0))2 \u001b\n0\n\u2212(\u03b80 \u2212 \u03b7l(1))2 \u22121\na(1\u2212a) \u03b8\n+ (1 \u2212 q0 ) exp\n\u00d7 q0 exp\n2W (1)\n2W (1)\n\u0012\n\n\u00d7 exp\n\n\u001a\n\n\u001b\n\n\u001a\n\n\u001b\u0013\n\n(116)\n\nand finally\n21\n\n\f\u2212(\u03b8 \u2212 \u03b7l(1) \u2212 a(1\u2212a) \u03c7\u03b8 (0))\nq0\n1\nexp\n\u03c1t=1 (\u03b8|h0 ) = q\n2W (1)\n2\u03c0W (1) 2\n\n\u2212(h0 \u2212 a\u03be m(1) \u2212 \u03b1a \u03c7h (0))2\n\u2212(h0 \u2212 a\u03be m(1) + \u03b1a \u03c7h (0))2\n\u00d7 exp\n+ exp\n2V (1)\n2V (1)\n\u001a\n\u001a\n\u001b\u0015\n\u03be\n2\u001b\n2\n\u2212(h0 \u2212 a m(1))\n\u2212(\u03b8 \u2212 \u03b7l(1))\n+(1 \u2212 q0 ) exp\nexp\n2V (1)\n2W (1)\n\u001b\n\u001a\n\u001a\n\u0014\n\u03be\n\u03b1\n2\u001b\n\u2212(h0 \u2212 a m(1) \u2212 a \u03c7h (0))\n\u2212(h0 \u2212 a\u03be m(1) + \u03b1a \u03c7h (0))2\nq0\nq0\n+ exp\nexp\n\u00d7\n2\n2V (1)\n2\n2V (1)\n\u001a\n\u03be\n2 \u001b\u0015\u22121\n\u2212(h0 \u2212 a m(1))\n+(1 \u2212 q0 ) exp\n.\n(117)\n2V (1)\n\u0012\n\n\u001a\n\n\u001b\n\n\u001a\n\n\u001b\u0013\n\nReferences\n[1] D.R.C. Dominguez and E. Korutcheva, Phys. Rev. E, 62, 2620 (2000)\n[2] D. Boll\u00e9 and T. Verbeiren, Phys. Lett. A, 297, 3-4, 156-161\n[3] M. Blume, V.J. Emery and R.B. Griffiths, Phys. Rev. A, 4, 1071 (1971); M. Blume, Phys. Rev.,\n141, 517 (1966); H.W. Capel, Physica 32, 966 (1966).\n[4] D. Boll\u00e9, G. Jongen and G.M. Shim, J. Stat. Phys. 96, 861 (1999).\n[5] E. Barkai, I. Kanter and H. Sompolinsky, Phys. Rev. A, 41, 590 (1990).\n[6] A.E. Patrick and V.A. Zagrebnov, J. Phys. A: Math. and Gen. 24, 3413 (1991).\n[7] A.E. Patrick and V.A. Zagrebnov, J. Stat. Phys. 63, 59 (1991).\n[8] D. Boll\u00e9, B. Vinck and V.A. Zagrebnov,J. Stat. Phys. 70, 1099 (1993).\n[9] A.N. Shiryayev, Probability (Springer, NY, 1984)\n[10] D. Boll\u00e9, G. Jongen and G.M. Shim, J. Stat. Phys. 91, 125 (1998).\n[11] P. Peretto, Biol. Cybern. 50, 51 (1984)\n[12] J.L. van Hemmen and R. K\u00fchn, in Models of Neural Networks, eds. E. Domany, J.L. van Hemmen\nand K.Schulten (Springer, 1991), p.1\n[13] M. Shiino and T. Fukai, Phys. Rev. 48, 867 (1993)\n[14] D.R.C. Dominguez, E. Korutcheva, W.K. Theumann and R. Erichsen jr., Flow diagrams of the\nquadratic neural network, submitted to the ICANN 2002 conference.\n[15] V.A. Zagrebnov and A.S. Chvyrov, Sov.Phys.JETP, 68, 153 (1989).\n[16] A.C.C. Coolen and D. Sherrington, Phys. Rev. E 49, 1921 (1994).\n[17] D. Boll\u00e9 and G.M. Shim, cond-mat/0106242, to appear in Phys. Rev. E\n[18] L.J. Schowalter and M.W. Klein, J.Phys.C: Solid State Physics, 12, L935 (1979).\n\n22\n\n\f"}