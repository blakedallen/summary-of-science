{"id": "http://arxiv.org/abs/0810.4185v1", "guidislink": true, "updated": "2008-10-23T00:02:33Z", "updated_parsed": [2008, 10, 23, 0, 2, 33, 3, 297, 0], "published": "2008-10-23T00:02:33Z", "published_parsed": [2008, 10, 23, 0, 2, 33, 3, 297, 0], "title": "On the discrepancy principle for some Newton type methods for solving\n  nonlinear inverse problems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.1577%2C0810.2122%2C0810.3974%2C0810.3259%2C0810.3708%2C0810.4344%2C0810.3685%2C0810.3243%2C0810.5179%2C0810.5567%2C0810.1608%2C0810.0522%2C0810.4699%2C0810.0510%2C0810.3134%2C0810.4057%2C0810.1194%2C0810.4315%2C0810.4353%2C0810.4091%2C0810.1999%2C0810.3712%2C0810.2000%2C0810.2196%2C0810.1012%2C0810.1676%2C0810.2089%2C0810.1721%2C0810.4938%2C0810.2094%2C0810.2915%2C0810.1895%2C0810.2740%2C0810.4576%2C0810.2252%2C0810.1408%2C0810.3476%2C0810.4209%2C0810.4046%2C0810.5601%2C0810.1880%2C0810.1479%2C0810.5754%2C0810.3508%2C0810.4586%2C0810.4214%2C0810.4343%2C0810.3690%2C0810.3469%2C0810.3730%2C0810.4727%2C0810.0097%2C0810.0117%2C0810.1792%2C0810.3548%2C0810.1673%2C0810.1261%2C0810.3507%2C0810.1200%2C0810.3738%2C0810.3415%2C0810.4013%2C0810.5070%2C0810.2818%2C0810.5061%2C0810.1763%2C0810.1996%2C0810.4325%2C0810.3466%2C0810.2831%2C0810.4498%2C0810.3782%2C0810.4076%2C0810.1964%2C0810.4579%2C0810.4019%2C0810.2869%2C0810.2249%2C0810.4185%2C0810.2675%2C0810.1076%2C0810.2719%2C0810.0765%2C0810.5124%2C0810.3601%2C0810.4902%2C0810.0871%2C0810.2140%2C0810.5606%2C0810.4083%2C0810.3041%2C0810.1472%2C0810.4109%2C0810.1005%2C0810.4989%2C0810.1806%2C0810.0013%2C0810.1061%2C0810.4329%2C0810.1592%2C0810.2917&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On the discrepancy principle for some Newton type methods for solving\n  nonlinear inverse problems"}, "summary": "We consider the computation of stable approximations to the exact solution\n$x^\\dag$ of nonlinear ill-posed inverse problems $F(x)=y$ with nonlinear\noperators $F:X\\to Y$ between two Hilbert spaces $X$ and $Y$ by the Newton type\nmethods $$ x_{k+1}^\\delta=x_0-g_{\\alpha_k} (F'(x_k^\\delta)^*F'(x_k^\\delta))\nF'(x_k^\\delta)^* (F(x_k^\\delta)-y^\\delta-F'(x_k^\\delta)(x_k^\\delta-x_0)) $$ in\nthe case that only available data is a noise $y^\\delta$ of $y$ satisfying\n$\\|y^\\delta-y\\|\\le \\delta$ with a given small noise level $\\delta>0$. We\nterminate the iteration by the discrepancy principle in which the stopping\nindex $k_\\delta$ is determined as the first integer such that $$\n\\|F(x_{k_\\delta}^\\delta)-y^\\delta\\|\\le \\tau \\delta <\\|F(x_k^\\delta)-y^\\delta\\|,\n\\qquad 0\\le k<k_\\delta $$ with a given number $\\tau>1$. Under certain\nconditions on $\\{\\alpha_k\\}$, $\\{g_\\alpha\\}$ and $F$, we prove that\n$x_{k_\\delta}^\\delta$ converges to $x^\\dag$ as $\\delta\\to 0$ and establish\nvarious order optimal convergence rate results. It is remarkable that we even\ncan show the order optimality under merely the Lipschitz condition on the\nFr\\'{e}chet derivative $F'$ of $F$ if $x_0-x^\\dag$ is smooth enough.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.1577%2C0810.2122%2C0810.3974%2C0810.3259%2C0810.3708%2C0810.4344%2C0810.3685%2C0810.3243%2C0810.5179%2C0810.5567%2C0810.1608%2C0810.0522%2C0810.4699%2C0810.0510%2C0810.3134%2C0810.4057%2C0810.1194%2C0810.4315%2C0810.4353%2C0810.4091%2C0810.1999%2C0810.3712%2C0810.2000%2C0810.2196%2C0810.1012%2C0810.1676%2C0810.2089%2C0810.1721%2C0810.4938%2C0810.2094%2C0810.2915%2C0810.1895%2C0810.2740%2C0810.4576%2C0810.2252%2C0810.1408%2C0810.3476%2C0810.4209%2C0810.4046%2C0810.5601%2C0810.1880%2C0810.1479%2C0810.5754%2C0810.3508%2C0810.4586%2C0810.4214%2C0810.4343%2C0810.3690%2C0810.3469%2C0810.3730%2C0810.4727%2C0810.0097%2C0810.0117%2C0810.1792%2C0810.3548%2C0810.1673%2C0810.1261%2C0810.3507%2C0810.1200%2C0810.3738%2C0810.3415%2C0810.4013%2C0810.5070%2C0810.2818%2C0810.5061%2C0810.1763%2C0810.1996%2C0810.4325%2C0810.3466%2C0810.2831%2C0810.4498%2C0810.3782%2C0810.4076%2C0810.1964%2C0810.4579%2C0810.4019%2C0810.2869%2C0810.2249%2C0810.4185%2C0810.2675%2C0810.1076%2C0810.2719%2C0810.0765%2C0810.5124%2C0810.3601%2C0810.4902%2C0810.0871%2C0810.2140%2C0810.5606%2C0810.4083%2C0810.3041%2C0810.1472%2C0810.4109%2C0810.1005%2C0810.4989%2C0810.1806%2C0810.0013%2C0810.1061%2C0810.4329%2C0810.1592%2C0810.2917&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider the computation of stable approximations to the exact solution\n$x^\\dag$ of nonlinear ill-posed inverse problems $F(x)=y$ with nonlinear\noperators $F:X\\to Y$ between two Hilbert spaces $X$ and $Y$ by the Newton type\nmethods $$ x_{k+1}^\\delta=x_0-g_{\\alpha_k} (F'(x_k^\\delta)^*F'(x_k^\\delta))\nF'(x_k^\\delta)^* (F(x_k^\\delta)-y^\\delta-F'(x_k^\\delta)(x_k^\\delta-x_0)) $$ in\nthe case that only available data is a noise $y^\\delta$ of $y$ satisfying\n$\\|y^\\delta-y\\|\\le \\delta$ with a given small noise level $\\delta>0$. We\nterminate the iteration by the discrepancy principle in which the stopping\nindex $k_\\delta$ is determined as the first integer such that $$\n\\|F(x_{k_\\delta}^\\delta)-y^\\delta\\|\\le \\tau \\delta <\\|F(x_k^\\delta)-y^\\delta\\|,\n\\qquad 0\\le k<k_\\delta $$ with a given number $\\tau>1$. Under certain\nconditions on $\\{\\alpha_k\\}$, $\\{g_\\alpha\\}$ and $F$, we prove that\n$x_{k_\\delta}^\\delta$ converges to $x^\\dag$ as $\\delta\\to 0$ and establish\nvarious order optimal convergence rate results. It is remarkable that we even\ncan show the order optimality under merely the Lipschitz condition on the\nFr\\'{e}chet derivative $F'$ of $F$ if $x_0-x^\\dag$ is smooth enough."}, "authors": ["Qinian Jin", "Ulrich Tautenhahn"], "author_detail": {"name": "Ulrich Tautenhahn"}, "author": "Ulrich Tautenhahn", "arxiv_comment": "To appear in Numerische Mathematik", "links": [{"href": "http://arxiv.org/abs/0810.4185v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0810.4185v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.NA", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.NA", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "65J15; 65J20; 47H17", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0810.4185v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0810.4185v1", "journal_reference": null, "doi": null, "fulltext": "Noname manuscript No.\n(will be inserted by the editor)\n\narXiv:0810.4185v1 [math.NA] 23 Oct 2008\n\nOn the discrepancy principle for some Newton type methods\nfor solving nonlinear inverse problems\nQinian Jin * Ulrich Tautenhahn\n\nthe date of receipt and acceptance should be inserted later\n\nAbstract We consider the computation of stable approximations to the exact solution x\u2020 of\nnonlinear ill-posed inverse problems F(x) = y with nonlinear operators F : X \u2192 Y between two\nHilbert spaces X and Y by the Newton type methods\n\u0010\n\u0010\n\u0011\n\u0011\nx\u03b4k+1 = x0 \u2212 g\u03b1k F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )(x\u03b4k \u2212 x0)\n\nin the case that only available data is a noise y\u03b4 of y satisfying ky\u03b4 \u2212 yk \u2264 \u03b4 with a given small\nnoise level \u03b4 > 0. We terminate the iteration by the discrepancy principle in which the stopping\nindex k\u03b4 is determined as the first integer such that\nkF(x\u03b4k\u03b4 ) \u2212 y\u03b4 k \u2264 \u03c4\u03b4 < kF(x\u03b4k ) \u2212 y\u03b4 k,\n\n0 \u2264 k < k\u03b4\n\nwith a given number \u03c4 > 1. Under certain conditions on {\u03b1k }, {g\u03b1 } and F, we prove that x\u03b4k\n\u03b4\nconverges to x\u2020 as \u03b4 \u2192 0 and establish various order optimal convergence rate results. It is\nremarkable that we even can show the order optimality under merely the Lipschitz condition on\nthe Fr\u00e9chet derivative F \u2032 of F if x0 \u2212 x\u2020 is smooth enough.\nKeywords Nonlinear inverse problems * Newton type methods * the discrepancy principle *\norder optimal convergence rates\nMathematics Subject Classification (2000) 65J15 * 65J20 * 47H17\n1 Introduction\nIn this paper we will consider the nonlinear inverse problems which can be formulated as the\noperator equations\nF(x) = y,\n(1.1)\nwhere F : D(F) \u2282 X \u2192 Y is a nonlinear operator between the Hilbert spaces X and Y with\ndomain D(F). We will assume that problem (1.1) is ill-posed in the sense that its solution does\nnot depend continuously on the right hand side y, which is the characteristic property for most of\nQinian Jin\nDepartment of Mathematics, The University of Texas at Austin, Austin, Texas 78712, USA\nE-mail: qjin@math.utexas.edu\nUlrich Tautenhahn\nDepartment of Mathematics, University of Applied Sciences Zittau/G\u00f6rlitz, PO Box 1454, 02754 Zittau, Germany\nE-mail: u.tautenhahn@hs-zigr.de\n\n\f2\n\nthe inverse problems. Such problems arise naturally from the parameter identification in partial\ndifferential equations.\nThroughout this paper k * k and (*, *) denote respectively the norms and inner products for\nboth the spaces X and Y since there is no confusion. The nonlinear operator F is always assumed\nto be Fr\u00e9chet differentiable, the Fr\u00e9chet derivative of F at x \u2208 D(F) is denoted as F \u2032 (x) and\nF \u2032 (x)\u2217 is used to denote the adjoint of F \u2032 (x). We assume that y is attainable, i.e. problem (1.1)\nhas a solution x\u2020 \u2208 D(F) such that\nF(x\u2020 ) = y.\nSince the right hand side is usually obtained by measurement, thus, instead of y itself, the available data is an approximation y\u03b4 satisfying\nky\u03b4 \u2212 yk \u2264 \u03b4\n\n(1.2)\n\nwith a given small noise level \u03b4 > 0. Due to the ill-posedness, the computation of a stable solution\nof (1.1) from y\u03b4 becomes an important issue, and the regularization techniques have to be taken\ninto account.\nMany regularization methods have been considered to solve (1.1) in the last two decades.\nTikhonov regularization is one of the well-known methods that has been studied extensively\n(see [17,11,19] and the references therein). Due to the straightforward implementation, iterative\nmethods are also attractive for solving nonlinear inverse problems. In this paper we will consider\nsome Newton type methods in which the iterated solutions {x\u03b4k } are defined successively by\n\u0010\n\u0010\n\u0011\n\u0011\n(1.3)\nx\u03b4k+1 = x0 \u2212 g\u03b1k F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )(x\u03b4k \u2212 x0 ) ,\nwhere x\u03b40 := x0 is an initial guess of x\u2020 , {\u03b1k } is a given sequence of numbers such that\n\n\u03b1k > 0,\n\n1\u2264\n\n\u03b1k\n\u2264r\n\u03b1k+1\n\nand\n\nlim \u03b1k = 0\n\nk\u2192\u221e\n\n(1.4)\n\nfor some constant r > 1, and g\u03b1 : [0, \u221e) \u2192 (\u2212\u221e, \u221e) is a family of piecewise continuous functions\nsatisfying suitable structure conditions. The method (1.3) can be derived as follows. Suppose x\u03b4k\nis a current iterate, then we may approximate F(x) by its linearization around x\u03b4k , i.e. F(x) \u2248\nF(x\u03b4k ) + F \u2032 (x\u03b4k )(x \u2212 x\u03b4k ). Thus, instead of (1.1), we have the approximate equation\nF \u2032 (x\u03b4k )(x \u2212 x\u03b4k ) = y\u03b4 \u2212 F(x\u03b4k ).\n\n(1.5)\n\nIf F \u2032 (x\u03b4k ) has bounded inverse, the usual Newton method defines the next iterate by solving (1.5)\nfor x. For nonlinear ill-posed inverse problems, however, F \u2032 (x\u03b4k ) in general is not invertible.\nTherefore, we must use linear regularization methods to solve (1.5). There are several ways to\ndo this step. One way is to rewrite (1.5) as\nF \u2032 (x\u03b4k )h = y\u03b4 \u2212 F(x\u03b4k ) + F \u2032 (x\u03b4k )(x\u03b4k \u2212 x0 ),\n\n(1.6)\n\nwhere h = x \u2212 x0 . Applying the linear regularization method defined by {g\u03b1 } we may produce\nthe regularized solution h\u03b4k by\n\u0010\n\u0011\n\u0011\n\u0010\nh\u03b4k = g\u03b1k F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) F \u2032 (x\u03b4k )\u2217 y\u03b4 \u2212 F(x\u03b4k ) + F \u2032 (x\u03b4k )(x\u03b4k \u2212 x0) .\n\nThe next iterate is then defined to be x\u03b4k+1 := x0 + h\u03b4k which is exactly the form (1.3).\nIn order to use x\u03b4k to approximate x\u2020 , we must choose the stopping index of iteration properly.\nSome Newton type methods that can be casted into the form (1.3) have been analyzed in [3,12,\n14] under a priori stopping rules, which, however, depend on the knowledge of the smoothness\nof x0 \u2212 x\u2020 that is difficult to check in practice. Thus a wrong guess of the smoothness will lead\nto a bad choice of the stopping index, and consequently to a bad approximation to x\u2020 . Therefore,\n\n\f3\n\na posteriori rules, which use only quantities that arise during calculations, should be considered\nto choose the stopping index of iteration. One can consult [3,8,4,9,2,14] for several such rules.\nOne widely used a posteriori stopping rule in the literature of regularization theory for illposed problems is the discrepancy principle which, in the context of the Newton method (1.3),\ndefines the stopping index k\u03b4 to be the first integer such that\nkF(x\u03b4k\u03b4 ) \u2212 y\u03b4 k \u2264 \u03c4\u03b4 < kF(x\u03b4k ) \u2212 y\u03b4 k,\n\n0 \u2264 k < k\u03b4 ,\n\n(1.7)\n\nwhere \u03c4 > 1 is a given number. The method (1.3) with g\u03b1 (\u03bb ) = (\u03b1 + \u03bb )\u22121 together with (1.7)\nhas been considered in [3,8]. Note that when g\u03b1 (\u03bb ) = (\u03b1 + \u03bb )\u22121 , the method (1.3) is equivalent\nto the iteratively regularized Gauss-Newton method [1]\n\u0010\n\u0011\u22121 \u0010\n\u0011\nx\u03b4k+1 = x\u03b4k \u2212 \u03b1k I + F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k )\nF \u2032 (x\u03b4k )\u2217 (F(x\u03b4k ) \u2212 y\u03b4 ) + \u03b1k (x\u03b4k \u2212 x0) .\n(1.8)\nWhen F satisfies the condition like\n\nF \u2032 (x) = R(x, z)F \u2032 (z) + Q(x, z),\nkI \u2212 R(x, z)k \u2264 CR kx \u2212 zk,\n\u2032\n\nkQ(x, z)k \u2264 CQ kF (z)(x \u2212 z)k,\n\nx, z \u2208 B\u03c1 (x\u2020 ),\n\n(1.9)\n\nwhere CR and CQ are two positive constants, for the method defined by (1.8) and (1.7) with \u03c4\nbeing sufficiently large, it has been shown in [3,8] that if x0 \u2212 x\u2020 satisfies the H\u00f6lder source\ncondition\n(1.10)\nx0 \u2212 x\u2020 = (F \u2032 (x\u2020 )\u2217 F \u2032 (x\u2020 ))\u03bd \u03c9\nfor some \u03c9 \u2208 X and 0 \u2264 \u03bd \u2264 1/2, then\n\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 o(\u03b4 2\u03bd /(1+2\u03bd ));\nwhile if x0 \u2212 x\u2020 satisfies the logarithmic source condition\n\n\u0001\u2212\u03bc\n\u03c9\nx0 \u2212 x\u2020 = \u2212 log(F \u2032 (x\u2020 )\u2217 F \u2032 (x\u2020 ))\n\nfor some \u03c9 \u2208 X and \u03bc > 0, then\n\n(1.11)\n\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 O((\u2212 ln \u03b4 )\u2212\u03bc ).\n\nUnfortunately, except the above results, there is no more result available in the literature on the\ngeneral method defined by (1.3) and (1.7).\nDuring the attempt of proving regularization property of the general method defined by (1.3)\nand (1.7), Kaltenbacher realized that the arguments in [3,8] depend heavily on the special properties of the function g\u03b1 (\u03bb ) = (\u03b1 + \u03bb )\u22121 , and thus the technique therein is not applicable. Instead\nof the discrepancy principle (1.7), she proposed in [13] a new a posteriori stopping rule to terminate the iteration as long as\nn\no\nmax kF(x\u03b4m\u03b4 \u22121 ) \u2212 y\u03b4 k, kF(x\u03b4m\u03b4 \u22121 ) + F \u2032 (x\u03b4m\u03b4 \u22121 )(x\u03b4m\u03b4 \u2212 x\u03b4m\u03b4 \u22121 ) \u2212 y\u03b4 k \u2264 \u03c4\u03b4\n(1.12)\nis satisfied for the first time, where \u03c4 > 1 is a given number. Under the condition like (1.9), it\nhas been shown that if x0 \u2212 x\u2020 satisfies the H\u00f6lder source condition (1.10) for some \u03c9 \u2208 X and\n0 \u2264 \u03bd \u2264 1/2, then there hold the order optimal convergence rates\nkx\u03b4m\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\nif {g\u03b1 } satisfies some suitable structure conditions, \u03c4 is sufficiently large and k\u03c9 k is sufficiently\nsmall. Note that any result on (1.12) does not imply that the corresponding result holds for (1.7).\nNote also that k\u03b4 \u2264 m\u03b4 \u2212 1 which means that (1.12) requires more iterations to be performed.\n\n\f4\n\nMoreover, the discrepancy principle (1.7) is simpler than the stopping rule (1.12). Considering\nthe fact that it is widely used in practice, it is important to give further investigations on (1.7).\nIn this paper, we will resume the study of the method defined by (1.3) and (1.7) with completely different arguments. With the help of the ideas developed in [9,19,10], we will show\nthat, under certain conditions on {g\u03b1 }, {\u03b1k } and F, the method given by (1.3) and (1.7) indeed\ndefines a regularization method for solving (1.1) and is order optimal for each 0 < \u03bd \u2264 \u03bd\u0304 \u2212 1/2,\nwhere \u03bd\u0304 \u2265 1 denotes the qualification of the linear regularization method defined by {g\u03b1 }. In\nparticular, when x0 \u2212 x\u2020 satisfies (1.10) for 1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212 1/2, we will show that the order optimality of (1.3) and (1.7) even holds under merely the Lipschitz condition on F \u2032 . This is the\nmain contribution of the present paper. We point out that our results are valid for any \u03c4 > 1. This\nless restrictive requirement on \u03c4 is important in numerical computations since the absolute error\ncould increase with respect to \u03c4 .\nThis paper is organized as follows. In Section 2 we will state various conditions on {g\u03b1 },\n{\u03b1k } and F, and then present several convergence results on the methods defined by (1.3) and\n(1.7). We then complete the proofs of these main results in Sections 3, 4, and 5. In Section 6, in\norder to indicate the applicability of our main results, we verify those conditions in Section 2 for\nseveral examples of {g\u03b1 } arising from Tikhonov regularization, the iterated Tikhonov regularization, the Landweber iteration, the Lardy's method, and the asymptotic regularization.\n\n2 Assumptions and main results\nIn this section we will state the main results for the method defined by (1.3) and the discrepancy\nprinciple (1.7). Since the definition of {x\u03b4k } involves F, g\u03b1 and {\u03b1k }, we need to impose various\nconditions on them.\nWe start with the assumptions on g\u03b1 which is always assumed to be continuous on [0, 1/2]\nfor each \u03b1 > 0. We will set\nr\u03b1 (\u03bb ) := 1 \u2212 \u03bb g\u03b1 (\u03bb ),\nwhich is called the residual function associated with g\u03b1 .\nAssumption 1\n\n1\n\n(a) There are positive constants c0 and c1 such that\n0 < r\u03b1 (\u03bb ) \u2264 1,\n\nr\u03b1 (\u03bb )\u03bb \u2264 c0 \u03b1\n\nand 0 \u2264 g\u03b1 (\u03bb ) \u2264 c1 \u03b1 \u22121\n\nfor all \u03b1 > 0 and \u03bb \u2208 [0, 1/2];\n(b) r\u03b1 (\u03bb ) \u2264 r\u03b2 (\u03bb ) for any 0 < \u03b1 \u2264 \u03b2 and \u03bb \u2208 [0, 1/2];\n(c) There exists a constant c2 > 0 such that\nr\n\u03bb\nr (\u03bb )\nr\u03b2 (\u03bb ) \u2212 r\u03b1 (\u03bb ) \u2264 c2\n\u03b1 \u03b2\nfor any 0 < \u03b1 \u2264 \u03b2 and \u03bb \u2208 [0, 1/2].\nThe conditions (a) and (b) in Assumption 1 are standard in the analysis of linear regularization methods. Assumption 1(a) clearly implies\n0 \u2264 r\u03b1 (\u03bb )\u03bb 1/2 \u2264 c3 \u03b1 1/2\n1/2\n\nand 0 \u2264 g\u03b1 (\u03bb )\u03bb 1/2 \u2264 c4 \u03b1 \u22121/2\n\n1/2\n\n(2.1)\n\nwith c3 \u2264 c0 and c4 \u2264 c1 . We emphasize that direct estimates on r\u03b1 (\u03bb )\u03bb 1/2 and g\u03b1 (\u03bb )\u03bb 1/2\ncould give smaller c3 and c4 . From Assumption 1(a) it also follows for each 0 \u2264 \u03bd \u2264 1 that\nr\u03b1 (\u03bb )\u03bb \u03bd \u2264 c\u03bd0 \u03b1 \u03bd for all \u03b1 > 0 and \u03bb \u2208 [0, 1/2]. Thus the linear regularization method defined\nby {g\u03b1 } has qualification \u03bd\u0304 \u2265 1, where, according to [20], the qualification is defined to be the\n1\n\nRecently we realized that (c) can be derived from (a) and (b).\n\n\f5\n\nlargest number \u03bd\u0304 with the property that for each 0 \u2264 \u03bd \u2264 \u03bd\u0304 there is a positive constant d\u03bd such\nthat\n(2.2)\nr\u03b1 (\u03bb )\u03bb \u03bd \u2264 d\u03bd \u03b1 \u03bd for all \u03b1 > 0 and \u03bb \u2208 [0, 1/2].\n\nMoreover, Assumption 1(a) implies for every \u03bc > 0 that\n\b\nr\u03b1 (\u03bb )(\u2212 ln \u03bb )\u2212\u03bc \u2264 min (\u2212 ln \u03bb )\u2212\u03bc , c0 \u03b1\u03bb \u22121 (\u2212 ln \u03bb )\u2212\u03bc\n\nfor all 0 < \u03b1 \u2264 \u03b10 and \u03bb \u2208 [0, 1/2]. It is clear that (\u2212 ln \u03bb )\u2212\u03bc \u2264 (\u2212 ln(\u03b1 /(2\u03b10 )))\u2212\u03bc for 0 \u2264\n\u03bb \u2264 \u03b1 /(2\u03b10 ). By using the fact that the function \u03bb \u2192 c0 \u03b1\u03bb \u22121 (\u2212 ln \u03bb )\u2212\u03bc is decreasing on the\ninterval (0, e\u2212\u03bc ] and is increasing on the interval [e\u2212\u03bc , 1), it is easy to show that there is a positive constant a\u03bc such that c0 \u03b1\u03bb \u22121 (\u2212 ln \u03bb )\u2212\u03bc \u2264 a\u03bc (\u2212 ln(\u03b1 /(2\u03b10 )))\u2212\u03bc for \u03b1 /(2\u03b10 ) \u2264 \u03bb \u2264 1/2.\nTherefore for every \u03bc > 0 there is a positive constant b\u03bc such that\nr\u03b1 (\u03bb )(\u2212 ln \u03bb )\u2212\u03bc \u2264 b\u03bc (\u2212 ln(\u03b1 /(2\u03b10 )))\u2212\u03bc\n\n(2.3)\n\nfor all 0 < \u03b1 \u2264 \u03b10 and \u03bb \u2208 [0, 1/2]. This inequality will be used to derive the convergence rate\nwhen x0 \u2212 x\u2020 satisfies the logarithmic source condition (1.11)\nThe condition (c) in Assumption 1 seems to appear here for the first time. It is interesting\nto note that one can verify it for many well-known linear regularization methods. Moreover, the\nconditions (b) and (c) have the following important consequence.\nLemma 1 Under the conditions (b) and (c) in Assumption 1, there holds\nc2\nk[r\u03b2 (A\u2217 A) \u2212 r\u03b1 (A\u2217 A)]xk \u2264 kx\u0304 \u2212 r\u03b2 (A\u2217 A)xk + \u221a kAx\u0304k\n\u03b1\n\n(2.4)\n\nfor\u221aall x, x\u0304 \u2208 X, any 0 < \u03b1 \u2264 \u03b2 and any bounded linear operator A : X \u2192 Y satisfying kAk \u2264\n1/ 2.\nProof For any 0 < \u03b1 \u2264 \u03b2 we set\n\nr\u03b2 (\u03bb ) \u2212 r\u03b1 (\u03bb )\n,\nr\u03b2 (\u03bb )\n\np\u03b2 ,\u03b1 (\u03bb ) :=\n\n\u03bb \u2208 [0, 1/2].\n\nIt follows from the conditions (a) and (b) in Assumption 1 that\n(\nr )\n\u03bb\n.\n0 \u2264 p\u03b2 ,\u03b1 (\u03bb ) \u2264 min 1, c2\n\u03b1\n\n(2.5)\n\nTherefore, for any x, x\u0304 \u2208 X,\nk[r\u03b2 (A\u2217 A) \u2212 r\u03b1 (A\u2217 A)]xk = kp\u03b2 ,\u03b1 (A\u2217 A)r\u03b2 (A\u2217 A)xk\n\n\u2264 kp\u03b2 ,\u03b1 (A\u2217 A)[r\u03b2 (A\u2217 A)x \u2212 x\u0304]k + kp\u03b2 ,\u03b1 (A\u2217 A)x\u0304k\n\u2264 kr\u03b2 (A\u2217 A)x \u2212 x\u0304k + kp\u03b2 ,\u03b1 (A\u2217 A)x\u0304k.\n\n(2.6)\n\nLet {E\u03bb } be the spectral family generated by A\u2217 A. Then it follows from (2.5) that\nkp\u03b2 ,\u03b1 (A\u2217 A)x\u0304k2 =\n\nZ 1/2 \u0002\n0\n\n\u2264 c22\n\n\u00032\np\u03b2 ,\u03b1 (\u03bb ) dkE\u03bb x\u0304k2\n\nZ 1/2\n\u03bb\n\n\u03b1\n0\nc22\n= kAx\u0304k2 .\n\u03b1\n\ndkE\u03bb x\u0304k2 =\n\nCombining this with (2.6) gives the desired assertion.\n\nc22\nk(A\u2217 A)1/2 x\u0304k2\n\u03b1\n\n\u2737\n\n\f6\n\nFor the sequence of positive numbers {\u03b1k }, we will always assume that it satisfies (1.4).\nMoreover, we need also the following condition on {\u03b1k } interplaying with r\u03b1 .\nAssumption 2 There is a constant c5 > 1 such that\nr\u03b1k (\u03bb ) \u2264 c5 r\u03b1k+1 (\u03bb )\nfor all k and \u03bb \u2208 [0, 1/2].\nWe remark that for some {g\u03b1 } Assumption 2 is an immediate consequence of (1.4). However, this is not always the case; in some situations, Assumption 2 indeed imposes further conditions on {\u03b1k }. As a rough interpretation, Assumption 2 requires for any two successive iterated\nsolutions the errors do not decrease dramatically. This may be good for the stable numerical\nimplementations of ill-posed problems although it may require more iterations to be performed.\nNote that Assumption 2 implies\nkr\u03b1k (A\u2217 A)xk \u2264 c5 kr\u03b1k+1 (A\u2217 A)xk\n\n(2.7)\n\nfor some \u03c1 > 0\n\n(2.8)\n\n\u221a\nfor any x \u2208 X and any bounded linear operator A : X \u2192 Y satisfying kAk \u2264 1/ 2.\nThroughout this paper, we will always assume that the nonlinear operator F : D(F) \u2282 X \u2192 Y\nis Fr\u00e9chet differentiable such that\nB\u03c1 (x\u2020 ) \u2282 D(F)\nand\nn\no\n1/2\n1/2\n,\nkF \u2032 (x)k \u2264 min c3 \u03b10 , \u03b20\n\nx \u2208 B\u03c1 (x\u2020 ),\n\n(2.9)\n\nwhere 0 < \u03b20 \u2264 1/2 is a number such that r\u03b10 (\u03bb ) \u2265 3/4 for all \u03bb \u2208 [0, \u03b20 ]. Since r\u03b10 (0) = 1,\nsuch \u03b20 always exists. The scaling condition (2.9) can always be fulfilled by rescaling the norm\nin Y .\nThe convergence analysis on the method defined by (1.3) and (1.7) will be divided into two\ncases:\n(i) x0 \u2212 x\u2020 satisfies (1.10) for some \u03bd \u2265 1/2;\n(ii) x0 \u2212 x\u2020 satisfies (1.10) with 0 \u2264 \u03bd < 1/2 or (1.11) with \u03bc > 0.\nThus different structure conditions on F will be assumed in order to carry out the arguments. It\nis remarkable to see that for case (i) the following Lipschitz condition on F \u2032 is enough for our\npurpose.\nAssumption 3 There exists a constant L such that\nkF \u2032 (x) \u2212 F \u2032 (z)k \u2264 Lkx \u2212 zk\n\n(2.10)\n\nfor all x, z \u2208 B\u03c1 (x\u2020 ).\nAs the immediate consequence of Assumption 3, we have\n1\nkF(x) \u2212 F(z) \u2212 F \u2032 (z)(x \u2212 z)k \u2264 Lkx \u2212 zk2\n2\nfor all x, z \u2208 B\u03c1 (x\u2020 ). We will use this consequence frequently in this paper.\nDuring the convergence analysis of (1.3), we will meet some terms involving operators such\nas r\u03b1k (F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k )). In order to make use of the source conditions (1.10) for x0 \u2212 x\u2020 , we\nneed to switch these operators with r\u03b1k (F \u2032 (x\u2020 )\u2217 F \u2032 (x\u2020 )). Thus we need the following commutator\nestimates involving r\u03b1 and g\u03b1 .\n\n\f7\n\nAssumption 4 There is a constant c6 > 0 such that\nkr\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B)k \u2264 c6 \u03b1 \u22121/2 kA \u2212 Bk,\n\n(2.11)\n\nk [r\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B)] B\u2217 k \u2264 c6 kA \u2212 Bk,\n\n(2.12)\n\nkA [r\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B)] B\u2217 k \u2264 c6 \u03b1 1/2 kA \u2212 Bk,\nand\n\n(2.13)\n\nk [g\u03b1 (A\u2217 A) \u2212 g\u03b1 (B\u2217 B)] B\u2217 k \u2264 c6 \u03b1 \u22121 kA \u2212 Bk\n\n(2.14)\n\u221a\nfor any \u03b1 > 0 and any bounded linear operators A, B : X \u2192 Y satisfying kAk, kBk \u2264 1/ 2.\nThis assumption looks restrictive. However, it is interesting to note that for several important\nexamples we indeed can verify it easily, see Section 6 for details. Moreover, in our applications,\nwe only need Assumption 4 with A = F \u2032 (x) and B = F \u2032 (z) for x, z \u2208 B\u03c1 (x\u2020 ), which is trivially\nsatisfied when F is linear.\nNow we are ready to state the first main result of this paper.\nTheorem 1 Let {g\u03b1 } and {\u03b1k } satisfy Assumption 1, (1.4), Assumption 2, and Assumption 4,\nlet \u03bd\u0304 \u2265 1 be the qualification of the linear regularization method defined by {g\u03b1 }, and let F\nsatisfy (2.8), (2.9) and Assumption 3 with \u03c1 > 4kx0 \u2212 x\u2020 k. Let {x\u03b4k } be defined by (1.3) and let\nk\u03b4 be the first integer satisfying (1.7) with \u03c4 > 1. Let x0 \u2212 x\u2020 satisfy (1.10) for some \u03c9 \u2208 X and\n1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212 1/2. Then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\nif Lkuk \u2264 \u03b70 , where u \u2208 N (F \u2032 (x\u2020 )\u2217 )\u22a5 \u2282 Y is the unique element such that x0 \u2212 x\u2020 = F \u2032 (x\u2020 )\u2217 u,\n\u03b70 > 0 is a constant depending only on r, \u03c4 and ci , and C\u03bd is a positive constant depending only\non r, \u03c4 , \u03bd and ci , i = 0, * * * , 6.\nTheorem 1 tells us that, under merely the Lipschitz condition on F \u2032 , the method (1.3) together\nwith (1.7) indeed defines an order optimal regularization method for each 1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212 1/2; in\ncase the regularization method defined by {g\u03b1 } has infinite qualification the discrepancy principle (1.7) provides order optimal convergence rates for the full range \u03bd \u2208 [1/2, \u221e). This is one of\nthe main contribution of the present paper.\nWe remark that under merely the Lipschitz condition on F \u2032 we are not able to prove the\nsimilar result as in Theorem 1 if x0 \u2212 x\u2020 satisfies weaker source conditions, say (1.10) for some\n\u03bd < 1/2. Indeed this is still an open problem in the convergence analysis of regularization methods for nonlinear ill-posed problems. In order to pursue the convergence analysis under weaker\nsource conditions, we need stronger conditions on F than Assumption 3. The condition (1.9) has\nbeen used in [3,8] to establish the regularization property of the method defined by (1.8) and\n(1.7), where the special properties of g\u03b1 (\u03bb ) = (\u03bb + \u03b1 )\u22121 play the crucial roles. In order to study\nthe general method (1.3) under weaker source conditions, we need the following two conditions\non F.\nAssumption 5 There exists a positive constant K0 such that\nF \u2032 (x) = F \u2032 (z)R(x, z),\nkI \u2212 R(x, z)k \u2264 K0 kx \u2212 zk\nfor any x, z \u2208 B\u03c1 (x\u2020 ).\nAssumption 6 There exist positive constants K1 and K2 such that\nk[F \u2032 (x) \u2212 F \u2032 (z)]wk \u2264 K1 kx \u2212 zkkF \u2032 (z)wk + K2 kF \u2032 (z)(x \u2212 z)kkwk\nfor any x, z \u2208 B\u03c1 (x\u2020 ) and w \u2208 X.\n\n\f8\n\nAssumption 5 has been used widely in the literature of nonlinear ill-posed problems (see\n[17,11,9,19]); it can be verified for many important inverse problems. Another frequently used\nassumption on F is (1.9) which is indeed quite restrictive. It is clear that Assumption 6 is a direct\nconsequence of (1.9). In order to illustrate that Assumption 6 could be weaker than (1.9), we\nconsider the identification of the parameter c in the boundary value problem\n\u001a\nin \u03a9\n\u2212\u2206 u + cu = f\n(2.15)\nu=g\non \u2202 \u03a9\nfrom the measurement of the state u, where \u03a9 \u2282 Rn , n \u2264 3, is a bounded domain with smooth\nboundary \u2202 \u03a9 , f \u2208 L2 (\u03a9 ) and g \u2208 H 3/2 (\u2202 \u03a9 ). We assume c\u2020 \u2208 L2 (\u03a9 ) is the sought solution. This\nproblem reduces to solving an equation of the form (1.1) if we define the nonlinear operator F to\nbe the parameter-to-solution mapping F : L2 (\u03a9 ) \u2192 L2 (\u03a9 ), F(c) := u(c) with u(c) \u2208 H 2 (\u03a9 ) \u2282\nL2 (\u03a9 ) being the unique solution of (2.15). Such F is well-defined on\n\b\nD(F) := c \u2208 L2 (\u03a9 ) : kc \u2212 \u0109kL2 \u2264 \u03b3 for some \u0109 \u2265 0 a.e.\nfor some positive constant \u03b3 > 0. It is well-known that F has Fr\u00e9chet derivative\nF \u2032 (c)h = \u2212A(c)\u22121 (hF(c)),\n\nh \u2208 L2 (\u03a9 ),\n\n(2.16)\n\nwhere A(c) : H 2 \u2229 H01 \u2192 L2 is defined by A(c)u := \u2212\u2206 u + cu which is an isomorphism uniformly\nin a ball B\u03c1 (c\u2020 ) R\u2282 D(F) around c\u2020 . Let V be the dual space of H 2 \u2229H01 with respect to the bilinear\nform h\u03c6 , \u03c8 i = \u03a9 \u03c6 (x)\u03c8 (x)dx. Then A(c) extends to an isomorphism from L2 (\u03a9 ) to V . Since\n(2.16) implies for any c, d \u2208 B\u03c1 (c\u2020 ) and h \u2208 L2 (\u03a9 )\n\u0001\n\u0001\nF \u2032 (c) \u2212 F \u2032 (d) h = \u2212A(c)\u22121 (c \u2212 d)F \u2032 (d)h \u2212 A(c)\u22121 (h(F(c) \u2212 F(d))) ,\n\nand since L1 (\u03a9 ) embeds into V due to the restriction n \u2264 3, we have\n\u0001\nk(F \u2032 (c) \u2212 F \u2032 (d))hkL2 \u2264 kA(c)\u22121 (c \u2212 d)F \u2032 (d)h kL2 + kA(c)\u22121 (h(F(c) \u2212 F(d))) kL2\n\u2264 Ck(c \u2212 d)F \u2032 (d)hkV + Ckh(F(c) \u2212 F(d))kV\n\u2264 Ck(c \u2212 d)F \u2032 (d)hkL1 + Ckh(F(c) \u2212 F(d))kL1\n\u2264 Ckc \u2212 dkL2 kF \u2032 (d)hkL2 + CkF(c) \u2212 F(d)kL2 khkL2 .\n\n(2.17)\n\nOn the other hand, note that F(c) \u2212 F(d) = \u2212A(d)\u22121 ((c \u2212 d)F(c)), by using (2.16) we obtain\nF(c) \u2212 F(d) \u2212 F \u2032 (d)(c \u2212 d) = \u2212A(d)\u22121 ((c \u2212 d) (F(c) \u2212 F(d))) .\nThus, by a similar argument as above,\nkF(c) \u2212 F(d) \u2212 F \u2032 (d)(c \u2212 d)kL2 \u2264 Ckc \u2212 dkL2 kF(c) \u2212 F(d)kL2 .\nTherefore, if \u03c1 > 0 is small enough, we have kF(c) \u2212 F(d)kL2 \u2264 CkF \u2032 (d)(c \u2212 d)kL2 , which\ntogether with (2.17) verifies Assumption 6. The validity of (1.9), however, requires u(c) \u2265 \u03ba > 0\nfor all c \u2208 B\u03c1 (c\u2020 ), see [7].\nIn our next main result, Assumption 5 and Assumption 6 will be used to derive estimates\nrelated to x\u03b4k \u2212 x\u2020 and F \u2032 (x\u2020 )(x\u03b4k \u2212 x\u2020 ) respectively. Although Assumption 6 does not explore the\nfull strength of (1.9), the plus of Assumption 5 could make our conditions stronger than (1.9)\nin some situations. One advantage of the use of Assumption 5 and Assumption 6, however, is\nthat we can carry out the analysis on the discrepancy principle (1.7) for any \u03c4 > 1, in contrast to\nthose results in [3,8] where \u03c4 is required to be sufficiently large. It is not yet clear if only one of\nthe above two assumptions is enough for our purpose. From Assumption 6 it is easy to see that\n1\nkF(x) \u2212 F(z) \u2212 F \u2032 (z)(x \u2212 z)k \u2264 (K1 + K2 )kx \u2212 zkkF \u2032 (z)(x \u2212 z)k\n2\n\n(2.18)\n\n\f9\n\nand\n3\nkF(x) \u2212 F(z) \u2212 F \u2032 (z)(x \u2212 z)k \u2264 (K1 + K2 )kx \u2212 zkkF \u2032 (x)(x \u2212 z)k.\n2\n\n(2.19)\n\nfor any x, z \u2208 B\u03c1 (x\u2020 ).\nWe still need to deal with some commutators involving r\u03b1 . The structure information on F\nwill be incorporated into such estimates. Thus, instead of Assumption 4, we need the following\nstrengthened version.\nAssumption 7 (a) Under Assumption 5, there exists a positive constant c7 such that\n\u0001\n\u0001\nr\u03b1 F \u2032 (x)\u2217 F \u2032 (x) \u2212 r\u03b1 F \u2032 (z)\u2217 F \u2032 (z) \u2264 c7 K0 kx \u2212 zk\n\n(2.20)\n\nfor all x, z \u2208 B\u03c1 (x\u2020 ) and all \u03b1 > 0.\n(b) Under Assumption 5 and Assumption 6, there exists a positive constant c8 such that\n\u0001\n\u0001\u0003\n\u0002\nkF \u2032 (x) r\u03b1 F \u2032 (x)\u2217 F \u2032 (x) \u2212 r\u03b1 F \u2032 (z)\u2217 F \u2032 (z) k\n\n\u2264 c8 (K0 + K1 )\u03b1 1/2 kx \u2212 zk + c8K2 kF \u2032 (x)(x \u2212 z)k + kF \u2032 (z)(x \u2212 z)k\n\nfor all x, z \u2208 B\u03c1 (x\u2020 ) and all \u03b1 > 0.\n\n\u0001\n\n(2.21)\n\nNow we are ready to state the second main result in this paper which in particular says that the\nmethod (1.3) together with the discrepancy principle (1.7) defines an order optimal regularization\nmethod for each 0 < \u03bd \u2264 \u03bd\u0304 \u2212 1/2 under stronger conditions on F. We will fix a constant \u03b31 >\nc3 r1/2 /(\u03c4 \u2212 1).\nTheorem 2 Let {g\u03b1 } and {\u03b1k } satisfy Assumption 1, (1.4), Assumption 2 and Assumption 7, let\n\u03bd\u0304 \u2265 1 be the qualification of the linear regularization method defined by {g\u03b1 }, and let F satisfy\n(2.8), (2.9), Assumption 5 and Assumption 6 with \u03c1 > 2(1 + c4 \u03b31 )kx0 \u2212 x\u2020 k. Let {x\u03b4k } be defined\nby (1.3) and let k\u03b4 be the first integer satisfying (1.7) with \u03c4 > 1. Then there exists a constant\n\u03b71 > 0 depending only on r, \u03c4 and ci , i = 0, * * * , 8, such that if (K0 + K1 + K2 )kx0 \u2212 x\u2020 k \u2264 \u03b71\nthen\n(i) If x0 \u2212 x\u2020 satisfies the H\u00f6lder source condition (1.10) for some \u03c9 \u2208 X and 0 < \u03bd \u2264 \u03bd\u0304 \u2212 1/2,\nthen\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd ) ,\n\n(2.22)\n\nwhere C\u03bd is a constant depending only on r, \u03c4 , \u03bd and ci , i = 0, * * * , 8.\n(ii) If x0 \u2212 x\u2020 satisfies the logarithmic source condition (1.11) for some \u03c9 \u2208 X and \u03bc > 0,\nthen\n\u0013\u2212\u03bc\n\u0012\n\u03b4\n\u03b4\n\u2020\nkxk\u03b4 \u2212 x k \u2264 C\u03bc k\u03c9 k 1 + ln\n,\n(2.23)\nk\u03c9 k\nwhere C\u03bc is a constant depending only on r, \u03c4 , \u03bc , and ci , i = 0, * * * , 8.\n\nIn the statements of Theorem 1 and Theorem 2, the smallness of Lkuk and (K0 + K1 +\nK2 )kx0 \u2212 x\u2020 k are not specified. However, during the proof of Theorem 1, we indeed will spell\nout all the necessary smallness conditions on Lkuk. For simplicity of presentation, we will not\nspell out the smallness conditions on (K0 + K1 + K2 )kx0 \u2212 x\u2020 k any more; the readers should be\nable to figure out such conditions without any difficulty.\nNote that, without any source condition on x0 \u2212 x\u2020 , the above two theorems do not give\nthe convergence of x\u03b4k to x\u2020 . The following theorem says that x\u03b4k \u2192 x\u2020 as \u03b4 \u2192 0 provided\n\u03b4\n\n\u03b4\n\nx0 \u2212 x\u2020 \u2208 N (F \u2032 (x\u2020 ))\u22a5 . In fact, it tells more, it says that the convergence rates can even be\nimproved to o(\u03b4 2\u03bd /(1+2\u03bd ) ) if x0 \u2212 x\u2020 satisfies (1.10) for 0 \u2264 \u03bd < \u03bd\u0304 \u2212 1/2.\n\n\f10\n\nTheorem 3 (i) Let all the conditions in Theorem 1 be fulfilled. If \u03bd\u0304 > 1 and x\u2020 \u2212 x0 satisfies the\nH\u00f6lder source condition (1.10) for some \u03c9 \u2208 N (F \u2032 (x\u2020 ))\u22a5 and 1/2 \u2264 \u03bd < \u03bd\u0304 \u2212 1/2, then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 o(\u03b4 2\u03bd /(1+2\u03bd ) )\n\nas \u03b4 \u2192 0.\n(ii) Let all the conditions in Theorem 2 be fulfilled. If x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208\nN (F \u2032 (x\u2020 ))\u22a5 and 0 \u2264 \u03bd < \u03bd\u0304 \u2212 1/2, then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 o(\u03b4 2\u03bd /(1+2\u03bd ) )\n\nas \u03b4 \u2192 0.\nTheorem 1, Theorem 2 and Theorem 3 will be proved in Sections 3, 4 and 5 respectively. In\nthe following we will give some remarks.\nRemark 1 A comprehensive overview on iterative regularization methods for nonlinear ill-posed\nproblems may be found in the recent book [14]. In particular, convergence and convergence rates\nfor the general method (1.3) are obtained in [14, Theorem 4.16] in case of a priori stopping rules\nunder suitable nonlinearity assumptions on F.\nRemark 2 In [18] Tautenhahn introduced a general regularization scheme for (1.1) by defining\nthe regularized solutions x\u03b1\u03b4 as a fixed point of the nonlinear equation\n\u0011\n\u0010\n\u0001\n(2.24)\nx = x0 \u2212 g\u03b1 F \u2032 (x)\u2217 F \u2032 (x) F \u2032 (x)\u2217 F(x) \u2212 y\u03b4 \u2212 F \u2032 (x)(x \u2212 x0 ) ,\n\nwhere \u03b1 > 0 is the regularization parameter. When \u03b1 is determined by a Morozov's type discrepancy principle, it was shown in [18] that the method is order optimal for each 0 < \u03bd \u2264 \u03bd\u0304 /2\nunder certain conditions on F. We point out that the technique developed in the present paper\ncan be used to analyze such method; indeed we can even show that, under merely the Lipschitz\ncondition on F \u2032 , the method in [18] is order optimal for each 1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212 1/2, which improves\nthe corresponding result.\nRemark 3 Alternative to (1.3), one may consider the inexact Newton type methods\n\u0010\n\u0011\n\u0011\n\u0010\nx\u03b4k+1 = x\u03b4k \u2212 g\u03b1k F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4\n\n(2.25)\n\nwhich can be derived by applying the regularization method defined by {g\u03b1 } to (1.5) with the\ncurrent iterate x\u03b4k as an initial guess. Such methods have first been studied by Hanke in [5,6]\nwhere the regularization properties of the Levenberg-Marquardt algorithm and the Newton-CG\nalgorithm have been established without giving convergence rates when the sequence {\u03b1k } is\nchosen adaptively during computation and the discrepancy principle is used as a stopping rule.\nThe general methods (2.25) have been considered later by Rieder in [15,16], where {\u03b1k } is\ndetermined by a somewhat different adaptive strategy; certain sub-optimal convergence rates\nhave been derived when x0 \u2212 x\u2020 satisfies (1.10) with \u03b7 < \u03bd \u2264 1/2 for some problem-dependent\nnumber 0 < \u03b7 < 1/2, while it is not yet clear if the convergence can be established under weaker\nsource conditions. The convergence analysis of (2.25) is indeed far from complete. The technique\nin the present paper does not work for such methods.\nThroughout this paper we will use {xk } to denote the iterated solutions defined by (1.3)\ncorresponding to the noise free case. i.e.\n\u0001\n\u0001\nxk+1 = x0 \u2212 g\u03b1k F \u2032 (xk )\u2217 F \u2032 (xk ) F \u2032 (xk )\u2217 F(xk ) \u2212 y \u2212 F \u2032 (xk )(xk \u2212 x0 ) .\n(2.26)\n\nWe will also use the notations\n\nAk := F \u2032 (xk )\u2217 F \u2032 (xk ),\n\nAk\u03b4 := F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ),\n\nB := F \u2032 (x\u2020 )F \u2032 (x\u2020 )\u2217 , Bk := F \u2032 (xk )F \u2032 (xk )\u2217 ,\n\nBk\u03b4 := F \u2032 (x\u03b4k )F \u2032 (x\u03b4k )\u2217 ,\n\nA := F \u2032 (x\u2020 )\u2217 F \u2032 (x\u2020 ),\n\n\f11\n\nand\nek := xk \u2212 x\u2020 ,\n\ne\u03b4k := x\u03b4k \u2212 x\u2020 .\n\nFor ease of exposition, we will use C to denote a generic constant depending only on r. \u03c4 and\nci , i = 0, * * * , 8, we will also use the convention \u03a6 . \u03a8 to mean that \u03a6 \u2264 C\u03a8 for some generic\nconstant C. Moreover, when we say Lkuk (or (K0 + K1 + K2 )ke0 k) is sufficiently small we will\nmean that Lkuk \u2264 \u03b7 (or (K0 + K1 + K2 )ke0 k \u2264 \u03b7 ) for some small positive constant \u03b7 depending\nonly on r, \u03c4 and ci , i = 0, * * * , 8.\n3 Proof of Theorem 1\nIn this section we will give the proof of Theorem 1. The main idea behind the proof consists of\nthe following steps:\n\u2022 Show the method defined by (1.3) and (1.7) is well-defined.\n\u221a\n\u2022 Establish the stability estimate kx\u03b4k \u2212 xk k . \u03b4 / \u03b1k . This enables us to write ke\u03b4k k .\n\u03b4\n\u221a\nkek\u03b4 k + \u03b4 / \u03b1k\u03b4 .\n\u2022 Establish \u03b1k\u03b4 \u2265 C\u03bd (\u03b4 /k\u03c9 k)2/(1+2\u03bd ) under the source condition (1.10) for 1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212\n1/2. This is an easy step although it requires nontrivial arguments.\n\u2022 Show kek\u03b4 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd ) , which is the hard part in the whole proof. In order\nto achieve this, we pick an integer k\u0304\u03b4 such that k\u03b4 \u2264 k\u0304\u03b4 and \u03b1k\u0304\u03b4 \u223c (\u03b4 /k\u03c9 k)2/(1+2\u03bd ). Such k\u0304\u03b4 will\nbe proved to exist. Then we connect kek\u03b4 k and kek\u0304\u03b4 k by establishing the inequality\n\u0001\n1\nkek\u03b4 k . kek\u0304\u03b4 k + p\nkF(xk\u03b4 ) \u2212 yk + \u03b4 .\n\u03b1k\u0304\u03b4\n\n(3.1)\n\nThe right hand side can be easily estimated by the desired bound.\n\u2022 In order to establish (3.1), we need to establish the preliminary convergence rate estimate\nke\u03b4k k . kuk1/2\u03b4 1/2 when x0 \u2212 x\u2020 = F \u2032 (x\u2020 )\u2217 u for some u \u2208 N (F \u2032 (x\u2020 )\u2217 )\u22a5 \u2282 Y .\n\u03b4\n\nTherefore, in order to complete the proof of Theorem 1, we need to establish various estimates.\n\n3.1 A first result on convergence rates\nIn this subsection we will derive the convergence rate ke\u03b4k k . kuk1/2\u03b4 1/2 under the source\n\u03b4\ncondition\nx0 \u2212 x\u2020 = F \u2032 (x\u2020 )\u2217 u, u \u2208 N (F \u2032 (x\u2020 )\u2217 )\u22a5 .\n(3.2)\nTo this end, we introduce k\u0303\u03b4 to be the first integer such that\n\n\u03b1k\u0303\u03b4 \u2264\n\n\u03b4\n< \u03b1k ,\n\u03b30 kuk\n\n0 \u2264 k < k\u0303\u03b4 ,\n\n(3.3)\n\nwhere \u03b30 is a number satisfying \u03b30 > c0 r/(\u03c4 \u2212 1), and c0 is the constant from Assumption 1 (a).\nBecause of (1.4), such k\u0303\u03b4 is well-defined.\nTheorem 4 Let {g\u03b1 } and {\u03b1k } satisfy Assumption 1(a), Assumption 2, (2.12) and (1.4), and let\nF satisfy (2.8), (2.9) and Assumption 3 with \u03c1 > 4kx0 \u2212 x\u2020 k. Let {x\u03b4k } be defined by (1.3) and let\nk\u03b4 be determined by the discrepancy principle (1.7) with \u03c4 > 1. If x0 \u2212 x\u2020 satisfies (3.2) and if\nLkuk is sufficiently small, then\n\n\f12\n\n(i) For all 0 \u2264 k \u2264 k\u0303\u03b4 there hold\nx\u03b4k \u2208 B\u03c1 (x\u2020 )\n\nke\u03b4k k \u2264 2(c3 + c4\u03b30 )r1/2 \u03b1k kuk.\n1/2\n\nand\n\n(3.4)\n\n(ii) k\u03b4 \u2264 k\u0303\u03b4 , i.e. the discrepancy principle (1.7) is well-defined.\n(iii) There exists a generic constant C > 0 such that\nke\u03b4k\u03b4 k \u2264 Ckuk1/2\u03b4 1/2 .\n\nProof We first prove (i). Note that \u03c1 > 4kx0 \u2212 x\u2020 k, it follows from (3.2) and (2.9) that (3.4)\nis trivial for k = 0. Now for any fixed integer 0 < l \u2264 k\u0303\u03b4 , we assume that (3.4) is true for all\n0 \u2264 k < l. It follows from the definition (1.3) of {x\u03b4k } that\n\u0011\n\u0010\ne\u03b4k+1 = r\u03b1k (Ak\u03b4 )e0 \u2212 g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )e\u03b4k .\n(3.5)\nUsing (3.2), Assumption 3, Assumption 1(a), (2.1) and (1.2) we obtain\n\nke\u03b4k+1 k \u2264 kr\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 uk + kr\u03b1k (Ak\u03b4 )[F \u2032 (x\u2020 )\u2217 \u2212 F \u2032 (x\u03b4k )\u2217 ]uk\n\nkF(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )e\u03b4k k\n1\n1/2\n\u22121/2\n\u22121/2\n\u2264 c3 \u03b1k kuk + Lkukke\u03b4k k + c4 Lke\u03b4k k2 \u03b1k\n+ c4 \u03b4 \u03b1k\n.\n2\n\u22121/2\n\n+ c4\u03b1k\n\nNote that \u03b4 \u03b1k\u22121 \u2264 \u03b30 kuk for 0 \u2264 k < k\u0303\u03b4 . Note also that \u03b1k \u2264 r\u03b1k+1 by (1.4). Therefore, by using\n(3.4) with k = l \u2212 1, we obtain\n\uf8ee\n! \uf8f9\n\u03b4 k\n\u03b4 k 2\nke\nke\n1\n1/2\n\uf8fb\nke\u03b4l k \u2264 r1/2 \u03b1l \uf8f0(c3 + c4 \u03b30 )kuk + Lkuk \u221a l\u22121 + c4 L \u221a l\u22121\n\u03b1l\u22121 2\n\u03b1l\u22121\n1/2\n\n\u2264 2(c3 + c4 \u03b30 )r1/2 \u03b1l\n\nkuk\n\nif Lkuk is so small that\n\u0010\n\u0011\n2 r1/2 + (c3 + c4 \u03b30 )c4 r Lkuk \u2264 1.\n\n(3.6)\n\nBy using (3.5), (2.1), Assumption 3, (1.2), Assumption 1(a), (3.4) with k = l \u2212 1 and (3.6), we\nalso obtain\n1\n\u22121/2\n\u22121/2\n\u03b4\nke\u03b4l k \u2264 kr\u03b1l\u22121 (Al\u22121\n)e0 k + c4\u03b4 \u03b1l\u22121 + c4 Lke\u03b4l\u22121 k2 \u03b1l\u22121\n2\n1/2\n\u2264 ke0 k + c4\u03b30 kuk1/2\u03b4 1/2 + (c3 + c4 \u03b30 )c4 r1/2 Lkukke\u03b4l\u22121k\n1\n1/2\n\u2264 ke0 k + c4\u03b30 kuk1/2\u03b4 1/2 + \u03c1\n2\nTherefore, by using \u03c1 > 4ke0k, we have\n3\n1/2\nke\u03b4k k \u2264 \u03c1 + c4 \u03b30 kuk1/2\u03b4 1/2 < \u03c1\n4\n\nif \u03b4 > 0 is small enough. Thus (3.4) is also true for all k = l. As l \u2264 k\u0303\u03b4 has been arbitrary, we\nhave completed the proof of (i).\nNext we prove (ii) by showing that k\u03b4 \u2264 k\u0303\u03b4 . From (3.5) and (3.2) we have for 0 \u2264 k < k\u0303\u03b4 that\n\u0011i\nh\n\u0010\nF \u2032 (x\u2020 )e\u03b4k+1 \u2212 y\u03b4 + y = F \u2032 (x\u03b4k )r\u03b1k (Ak\u03b4 ) F \u2032 (x\u03b4k )\u2217 + F \u2032 (x\u2020 )\u2217 \u2212 F \u2032 (x\u03b4k )\u2217 u\n\u0011i\ni\nh\n\u0010\nh\n+ F \u2032 (x\u2020 ) \u2212 F \u2032 (x\u03b4k ) r\u03b1k (Ak\u03b4 ) F \u2032 (x\u03b4k )\u2217 + F \u2032 (x\u2020 )\u2217 \u2212 F \u2032 (x\u03b4k )\u2217 u\nh\ni\nh\ni\n\u2212 F \u2032 (x\u2020 ) \u2212 F \u2032 (x\u03b4k ) g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )e\u03b4k\nh\ni\n\u2212 g\u03b1k (Bk\u03b4 )Bk\u03b4 F(x\u03b4k ) \u2212 y \u2212 F \u2032 (x\u03b4k )e\u03b4k\n\u2212 r\u03b1k (Bk\u03b4 )(y\u03b4 \u2212 y).\n\n\f13\n\nBy using Assumption 3, Assumption 1(a), (2.1), (1.2) and (3.4), and noting that \u03b4 /\u03b1k \u2264 \u03b30 kuk,\nwe obtain\nkF \u2032 (x\u2020 )e\u03b4k+1 \u2212 y\u03b4 + yk \u2264 \u03b4 + c0 \u03b1k kuk + 2c3Lkuk\u03b1k ke\u03b4k k + L2 kukke\u03b4k k2\n1\n1\n\u22121/2\n\u22121/2 \u03b4 3\n+ c4Lke\u03b4k k\u03b4 \u03b1k\n+ c4 L2 \u03b1k\nkek k + Lke\u03b4k k2\n2\n2\n\u2264 \u03b4 + (c0 + \u03b51 ) \u03b1k kuk,\n1/2\n\nwhere\nh\ni\n\u03b51 = 2r1/2 (c3 + c4 \u03b30 )(2c3 + c4 \u03b30 ) + 2(c3 + c4\u03b30 )2 r Lkuk\nh\ni\n+ 4 (c3 + c4 \u03b30 )2 r + (c3 + c4 \u03b30 )3 c4 r3/2 L2 kuk2.\n\nFrom (1.2), (3.2) and (2.9) we have kF \u2032 (x\u2020 )e0 \u2212 y\u03b4 + yk \u2264 \u03b4 + kA uk \u2264 \u03b4 + c0 \u03b10 kuk. Thus, by\nusing (1.4),\nkF \u2032 (x\u2020 )e\u03b4k \u2212 y\u03b4 + yk \u2264 \u03b4 + r (c0 + \u03b51 ) \u03b1k kuk, 0 \u2264 k \u2264 k\u0303\u03b4 .\nConsequently\nkF(xk\u0303\u03b4 ) \u2212 y\u03b4 k \u2264 kF \u2032 (x\u2020 )ek\u0303\u03b4 \u2212 y\u03b4 + yk + kF(xk\u0303\u03b4 ) \u2212 y \u2212 F \u2032 (x\u2020 )e\u03b4k\u0303 k\n\u03b4\n\n\u03b4\n\n\u03b4\n\n\u03b4\n\n1\n\u2264 \u03b4 + r (c0 + \u03b51 ) \u03b1k\u0303\u03b4 kuk + Lkek\u0303\u03b4 k2\n\u03b4\n2\n\u0001\n\u2264 \u03b4 + r c0 + \u03b51 + 2(c3 + c4 \u03b30 )2 rLkuk \u03b1k\u0303\u03b4 kuk\n\u0001\n\u2264 \u03b4 + r c0 + \u03b51 + 2(c3 + c4 \u03b30 )2 rLkuk \u03b30\u22121 \u03b4\n\u2264 \u03c4\u03b4\nif Lkuk is so small that\n\n\u03b51 + 2(c3 + c4 \u03b30 )2 rLkuk \u2264\n\n(\u03c4 \u2212 1)\u03b30 \u2212 c0 r\n.\nr\n\nBy the definition of k\u03b4 , it follows that k\u03b4 \u2264 k\u0303\u03b4 .\nFinally we are in a position to derive the convergence rate in (iii). If k\u03b4 = 0, then, by the\ndefinition of k\u03b4 , we have kF(x0 ) \u2212 y\u03b4 k \u2264 \u03c4\u03b4 . This together with Assumption 3 and (1.2) gives\n1\nkF \u2032 (x\u2020 )e0 k \u2264 kF(x0 ) \u2212 y \u2212 F \u2032 (x\u2020 )e0 k + kF(x0 ) \u2212 yk \u2264 Lke0 k2 + (\u03c4 + 1)\u03b4 .\n2\nThus, by using (3.2), we have\nke0 k = (e0 , F \u2032 (x\u2020 )\u2217 u)1/2 = (F \u2032 (x\u2020 )e0 , u)1/2 \u2264 kF \u2032 (x\u2020 )e0 k1/2kuk1/2\nr\n\u221a\n1\n\u2264\nLkukke0 k + \u03c4 + 1kuk1/2\u03b4 1/2 .\n2\nBy assuming that Lkuk \u2264 1, we obtain ke\u03b4k k = ke0 k . kuk1/2\u03b4 1/2 .\n\u03b4\nTherefore we will assume k\u03b4 > 0 in the following argument. It follows from (3.5), (2.1),\nAssumption 3 and (3.4) that for 0 \u2264 k < k\u0303\u03b4\n1\n\u22121/2\n+ c4 Lke\u03b4k k2 \u03b1k\n2\n\u2264 kr\u03b1k (Ak\u03b4 )e0 k + c4(\u03b30 kuk\u03b4 )1/2 + (c3 + c4\u03b30 )c4 r1/2 Lkukke\u03b4k k.\n\nke\u03b4k+1 k \u2264 kr\u03b1k (Ak\u03b4 )e0 k + c4\u03b4 \u03b1k\n\n\u22121/2\n\n(3.7)\n\n\f14\n\nBy (3.2), (2.12) in Assumption 4, and Assumption 3 we have\nkr\u03b1k (Ak\u03b4 )e0 \u2212 r\u03b1k (A )e0 k = k[r\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (A )]F \u2032 (x\u2020 )\u2217 uk\n\u2264 c6 kukkF \u2032 (x\u03b4k ) \u2212 F \u2032 (x\u2020 )k\n\n\u2264 c6 Lkukke\u03b4k k.\n\n(3.8)\n\nThus\n\u0010\n\u0011\nke\u03b4k+1 k \u2264 kr\u03b1k (A )e0 k + c4(\u03b30 kuk\u03b4 )1/2 + c6 + (c3 + c4 \u03b30 )c4 r1/2 Lkukke\u03b4k k\n\u2264 kr\u03b1k (A )e0 k + c4(\u03b30 kuk\u03b4 )1/2 +\n\n1 \u03b4\nke k\n4c5 k\n\n(3.9)\n\nif we assume further that\n\u0011\n\u0010\n4c5 c6 + (c3 + c4 \u03b30 )c4 r1/2 Lkuk \u2264 1.\n\n(3.10)\n\nNote that (2.9) and the choice of \u03b20 imply kr\u03b10 (A )e0 k \u2265 43 ke0 k. Thus, with the help of (2.7), by\ninduction we can conclude from (3.9) that\n4\nke\u03b4k k \u2264 c5 kr\u03b1k (A )e0 k + Ckuk1/2\u03b4 1/2 ,\n3\n\n0 \u2264 k \u2264 k\u0303\u03b4 .\n\nThis together with (3.8) and (3.10) implies\nke\u03b4k k \u2264 2c5 kr\u03b1k (Ak\u03b4 )e0 k + Ckuk1/2\u03b4 1/2 ,\n\n0 \u2264 k \u2264 k\u0303\u03b4 .\n\n(3.11)\n\n0 \u2264 k < k\u0303\u03b4 .\n\n(3.12)\n\nThe combination of (3.7), (3.11) and (3.10) gives\n3\nke\u03b4k+1 k \u2264 kr\u03b1k (Ak\u03b4 )e0 k + Ckuk1/2\u03b4 1/2 ,\n2\n\nWe need to estimate kr\u03b1k (Ak\u03b4 )e0 k. By (3.2), Assumption 1(a) and Assumption 3 we have\n\u0010\n\u0011\nkr\u03b1k (Ak\u03b4 )e0 k2 = r\u03b1k (Ak\u03b4 )e0 , r\u03b1k (Ak\u03b4 )F \u2032 (x\u2020 )\u2217 u\n\u0011i \u0011\nh\n\u0010\n\u0010\n= r\u03b1k (Ak\u03b4 )e0 , r\u03b1k (Ak\u03b4 ) F \u2032 (x\u03b4k )\u2217 + F \u2032 (x\u2020 )\u2217 \u2212 F \u2032 (x\u03b4k )\u2217 u\n\u2264 kF \u2032 (x\u03b4k )r\u03b1k (Ak\u03b4 )e0 kkuk + Lkukke\u03b4k kkr\u03b1k (Ak\u03b4 )e0 k.\n\nThus\n\nkr\u03b1k (Ak\u03b4 )e0 k \u2264 kF \u2032 (x\u03b4k )r\u03b1k (Ak\u03b4 )e0 k1/2kuk1/2 + Lkukke\u03b4k k.\n\nWith the help of (3.5), (1.2), Assumption 1(a) and Assumption 3 we have\n\u0010\n\u0011\nkF \u2032 (x\u03b4k )r\u03b1k (Ak\u03b4 )e0 k \u2264 kF \u2032 (x\u03b4k )e\u03b4k+1 k + kg\u03b1k (Bk\u03b4 )Bk\u03b4 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )e\u03b4k k\n\u2264 kF(x\u03b4k+1 ) \u2212 y\u03b4 k + 2\u03b4 + kF(x\u03b4k+1 ) \u2212 y \u2212 F \u2032 (x\u03b4k+1 )e\u03b4k+1 k\n\n+ k[F \u2032 (x\u03b4k+1 ) \u2212 F \u2032 (x\u03b4k )]e\u03b4k+1 k + kF(x\u03b4k ) \u2212 y \u2212 F \u2032 (x\u03b4k )e\u03b4k k\n\n\u2264 kF(x\u03b4k+1 ) \u2212 y\u03b4 k + 2\u03b4 + Lke\u03b4k k2 + 2Lke\u03b4k+1 k2 .\nTherefore\n\np\n\u221a\nkr\u03b1k (Ak\u03b4 )e0 k \u2264 kuk1/2kF(x\u03b4k+1 ) \u2212 y\u03b4 k1/2 + 2kuk1/2\u03b4 1/2 + 2Lkukke\u03b4k+1 k\n\u0011\n\u0010\np\n+ Lkuk + Lkuk ke\u03b4k k.\n\n\f15\n\nCombining this with (3.11) and (3.12) yields\n\nThus, if\n\nkr\u03b1k (Ak\u03b4 )e0 k \u2264 kuk1/2kF(x\u03b4k+1 ) \u2212 y\u03b4 k1/2 + Ckuk1/2\u03b4 1/2\ni\n\u0011p\n1 h\u0010 \u221a\nLkuk + 4c5 Lkuk kr\u03b1k (Ak\u03b4 )e0 k.\n+\n3 2 + 4c5\n2\n\u0011p\n\u0010 \u221a\nLkuk + 4c5Lkuk \u2264 1,\n3 2 + 4c5\n\nwe then obtain\n\nkr\u03b1k (Ak\u03b4 )e0 k . kuk1/2kF(x\u03b4k+1 ) \u2212 y\u03b4 k1/2 + kuk1/2\u03b4 1/2 .\n\nThis together with (3.12) gives\nke\u03b4k k . kuk1/2kF(x\u03b4k ) \u2212 y\u03b4 k1/2 + kuk1/2\u03b4 1/2\nfor all 0 < k \u2264 k\u0303\u03b4 . Consequently, we may set k = k\u03b4 in the above inequality and use the definition\nof k\u03b4 to obtain ke\u03b4k k . kuk1/2\u03b4 1/2 .\n\u2737\n\u03b4\n\n3.2 Stability estimates\nIn this subsection we will consider the stability of the method (1.3) by deriving some useful\nestimates on kx\u03b4k \u2212 xk k, where {xk } is defined by (2.26). It is easy to see that\n\u0001\n(3.13)\nek+1 = r\u03b1k (Ak )e0 \u2212 g\u03b1k (Ak )F \u2032 (xk )\u2217 F(xk ) \u2212 y \u2212 F \u2032 (xk )ek .\n\nWe will prove some important estimates on {xk } in Lemma 3 in the next subsection. In particular,\nwe will show that, under the conditions in Theorem 4,\nxk \u2208 B\u03c1 (x\u2020 )\n\nand\n\n1/2\n\nkek k \u2264 2c3 r1/2 \u03b1k kuk\n\n(3.14)\n\nfor all k \u2265 0 provided Lkuk is sufficiently small.\nLemma 2 Let all the conditions in Theorem 4 and Assumption 4 hold. If Lkuk is sufficiently\nsmall, then for all 0 \u2264 k \u2264 k\u0303\u03b4 there hold\n\nand\n\n\u03b4\nkx\u03b4k \u2212 xk k \u2264 2c4 \u221a\n\u03b1k\n\n(3.15)\n\nkF(x\u03b4k ) \u2212 F(xk ) \u2212 y\u03b4 + yk \u2264 (1 + \u03b52)\u03b4 ,\n\n(3.16)\n\nwhere\n\u0010\n\u0011\n\u03b52 := 2c4 (c6 + rc4\u03b30 ) + (4c3 + 3c4\u03b30 )r1/2 + 4(c3 + c4 \u03b30 )r Lkuk\n\u0010\n\u0011\n+ 4c3c4 c6 r1/2 + (c4 + c6 )c3 r L2 kuk2 .\nProof For each 0 \u2264 k \u2264 k\u0303\u03b4 we set\nuk := F(xk ) \u2212 y \u2212 F \u2032 (xk )ek ,\n\nu\u03b4k := F(x\u03b4k ) \u2212 y \u2212 F \u2032 (x\u03b4k )e\u03b4k .\n\n(3.17)\n\nIt then follows from (3.5) and (3.13) that\nx\u03b4k+1 \u2212 xk+1 = I1 + I2 + I3 + I4,\n\n(3.18)\n\n\f16\n\nwhere\nh\ni\nI1 := r\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (Ak ) e0 ,\n\nI2 := g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 (y\u03b4 \u2212 y),\ni\nh\nI3 := g\u03b1k (Ak )F \u2032 (xk )\u2217 \u2212 g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 uk ,\n\nI4 := g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 (uk \u2212 u\u03b4k ).\n\nBy using (3.2), (2.11), (2.12), Assumption 3 and (3.14) we have\nkI1 k \u2264 kr\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (Ak )kkF \u2032 (x\u2020 )\u2217 \u2212 F \u2032 (xk )\u2217 kkuk\n+ k[r\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (Ak )]F \u2032 (xk )\u2217 uk\n\n+ c6 Lkukkx\u03b4k \u2212 xk k\n\u2264 c6 L2 kukkek kkx\u03b4k \u2212 xk k\u03b1k\n\u0011\n\u0010\n\u2264 c6 Lkuk + 2c3r1/2 L2 kuk2 kx\u03b4k \u2212 xk k.\n\u22121/2\n\nWith the help of (2.1) and (1.2) we have\n\n\u03b4\nkI2 k \u2264 c4 \u221a .\n\u03b1k\nBy applying Assumption 1(a), (2.14), Assumption 3 and (3.14) we can estimate I3 as\nkI3 k \u2264 kg\u03b1k (Ak )[F \u2032 (x\u03b4k )\u2217 \u2212 F \u2032 (xk )\u2217 ]uk k + k[g\u03b1k (Ak ) \u2212 g\u03b1k (Ak\u03b4 )]F \u2032 (x\u03b4k )\u2217 uk k\n1\n\u2264 (c1 + c6 )Lkuk kkx\u03b4k \u2212 xk k\u03b1k\u22121 \u2264 (c1 + c6 )L2 kek k2 kx\u03b4k \u2212 xk k\u03b1k\u22121\n2\n\u2264 2(c1 + c6 )c23 rL2 kuk2kx\u03b4k \u2212 xk k.\nFor the term I4 , we have from (2.1) that\nc4\nkI4 k \u2264 \u221a ku\u03b4k \u2212 uk k.\n\u03b1k\nBy using Assumption 3, (3.4) and (3.14) one can see\nkuk \u2212 u\u03b4k k \u2264 kF(x\u03b4k ) \u2212 F(xk ) \u2212 F \u2032 (xk )(x\u03b4k \u2212 xk )k + k[F \u2032 (x\u03b4k ) \u2212 F \u2032 (xk )]e\u03b4k k\n\u0011\n1\n1 \u0010\n\u2264 Lkx\u03b4k \u2212 xk k2 + Lke\u03b4k kkx\u03b4k \u2212 xk k \u2264 L 3ke\u03b4k k + kek k kx\u03b4k \u2212 xk k\n2\n2\n\u03b4\n1/2 1/2\n\u2264 (4c3 + 3c4\u03b30 ) r \u03b1k Lkukkxk \u2212 xk k.\nTherefore\n\n(3.19)\n\nkI4 k \u2264 (4c3 + 3c4\u03b30 ) c4 r1/2 Lkukkx\u03b4k \u2212 xk k.\n\nThus, if Lkuk is so small that\n\u0011\n\u0010\n\u0011\n\u0010\n1\nc6 + (4c3 + 3c4\u03b30 )c4 r1/2 Lkuk + 2 c3 c6 r1/2 + c23 (c1 + c6 )r L2 kuk2 \u2264 ,\n2\n\nthen the combination of the above estimates on I1 , I2 , I3 and I4 gives for 0 \u2264 k < k\u0303\u03b4 that\n\n\u03b4\n1\nkx\u03b4k+1 \u2212 xk+1 k \u2264 c4 \u221a + kx\u03b4k \u2212 xk k.\n\u03b1k 2\n\nThis implies (3.15) immediately.\nNext we prove (3.16). We have from (3.18) that\nF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1 ) \u2212 y\u03b4 + y = F \u2032 (x\u03b4k ) (I1 + I2 + I3 + I4 ) \u2212 y\u03b4 + y.\n\n(3.20)\n\n\f17\n\nFrom (3.2), (2.12), (2.13), Assumption 3, (3.14) and (3.15) it follows that\nkF \u2032 (x\u03b4k )I1 k \u2264 kF \u2032 (x\u03b4k )[r\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (Ak )][F \u2032 (x\u2020 )\u2217 \u2212 F \u2032 (xk )\u2217 ]uk\n+ kF \u2032 (x\u03b4k )[r\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (Ak )]F \u2032 (xk )\u2217 uk\n\n\u2264 c6 L2 kukkek kkx\u03b4k \u2212 xk k + c6Lkuk\u03b1k kx\u03b4k \u2212 xk k\n\u0011\n\u0010\n\u2264 2c4 c6 Lkuk + 4c3c4 c6 r1/2 L2 kuk2 \u03b4 .\n1/2\n\nBy using Assumption 1(a) and (1.2) it is easy to see\n\nkF \u2032 (x\u03b4k )I2 \u2212 y\u03b4 + yk = kr\u03b1k (Bk\u03b4 )(y\u03b4 \u2212 y)k \u2264 \u03b4 .\n\n(3.21)\n\nIn order to estimate F \u2032 (x\u03b4k )I3 , we note that\nh\ni\nh\ni\nF \u2032 (x\u03b4k )I3 = F \u2032 (x\u03b4k ) \u2212 F \u2032 (xk ) g\u03b1k (Ak )F \u2032 (xk )\u2217 uk + r\u03b1k (Bk\u03b4 ) \u2212 r\u03b1k (Bk ) uk .\n\nThus, it follows from (2.1), Assumption 3, (2.11), (3.14) and (3.15) that\nh\ni\nkF \u2032 (x\u03b4k )I3 k \u2264 k F \u2032 (x\u03b4k ) \u2212 F \u2032 (xk ) g\u03b1k (Ak )F \u2032 (xk )\u2217 uk k\nh\ni\n+ k r\u03b1k (Bk\u03b4 ) \u2212 r\u03b1k (Bk ) uk k\nLkx\u03b4k \u2212 xk kkuk k\n\u2264 (c4 + c6 )\u03b1k\n1\n\u22121/2 2\nL kek k2 kx\u03b4k \u2212 xk k\n\u2264 (c4 + c6)\u03b1k\n2\n\u2264 4(c4 + c6 )c23 c4 rL2 kuk2\u03b4 .\n\u22121/2\n\nFor the term F \u2032 (x\u03b4k )I4 we have from Assumption 1(a), (3.19) and (3.15) that\nkF \u2032 (x\u03b4k )I4 k \u2264 kuk \u2212 u\u03b4k k \u2264 2(4c3 + 3c4\u03b30 )c4 r1/2 Lkuk\u03b4 .\nCombining the above estimates, we therefore obtain\nkF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1 ) \u2212 y\u03b4 + yk \u2264 (1 + \u03b53)\u03b4 ,\n\n0 \u2264 k < k\u0303\u03b4 ,\n\nwhere\n\u0010\n\u0011\n\u0011\n\u0010\n\u03b53 :=2c4 c6 + (4c3 + 3c4 \u03b30 )r1/2 Lkuk + 4c3c4 c6 r1/2 + (c4 + c6 )c3 r L2 kuk2.\nThis together with Assumption 3, (3.4), (3.15) and (1.4) implies for 0 \u2264 k < k\u0303\u03b4 that\nkF \u2032 (x\u03b4k+1 )(x\u03b4k+1 \u2212 xk+1 ) \u2212 y\u03b4 + yk\n\n\u2264 kF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1 ) \u2212 y\u03b4 + yk + Lkx\u03b4k+1 \u2212 x\u03b4k kkx\u03b4k+1 \u2212 xk+1 k\n\n\u03b4\n\u2264 (1 + \u03b53)\u03b4 + 2c4L(ke\u03b4k+1 k + ke\u03b4k k) \u221a\n\u03b1k+1\n\n\u2264 (1 + \u03b54)\u03b4 ,\nwhere\n\n\u03b54 := \u03b53 + 8(c3 + c4 \u03b30 )c4 rLkuk.\nThus\nkF \u2032 (x\u03b4k )(x\u03b4k \u2212 xk ) \u2212 y\u03b4 + yk \u2264 (1 + \u03b54 )\u03b4 ,\n\n0 \u2264 k \u2264 k\u0303\u03b4 .\n\n(3.22)\n\n\f18\n\nTherefore, noting that \u03b4 /\u03b1k \u2264 r\u03b30 kuk for 0 \u2264 k \u2264 k\u0303\u03b4 , we have\nkF(x\u03b4k ) \u2212 F(xk ) \u2212 y\u03b4 + yk \u2264 kF(x\u03b4k ) \u2212 F(xk ) \u2212 F \u2032 (x\u03b4k )(x\u03b4k \u2212 xk )k\n+ kF \u2032 (x\u03b4k )(x\u03b4k \u2212 xk ) \u2212 y\u03b4 + yk\n1\n\u2264 Lkx\u03b4k \u2212 xk k2 + (1 + \u03b54)\u03b4\n2\n\u03b4\n\u2264 2c24 L \u03b4 + (1 + \u03b54)\u03b4\n\u03b1k\n\u2264 (1 + \u03b54 + 2rc24\u03b30 Lkuk)\u03b4 .\n\nThe proof of (3.16) is thus complete.\n\n\u2737\n\n3.3 Some estimates on noise-free iterations\nLemma 3 Let all the conditions in Theorem 4 be fulfilled. If Lkuk is sufficiently small, then for\nall k \u2265 0 we have\nxk \u2208 B\u03c1 (x\u2020 )\n\n1/2\n\nkek k \u2264 2c3 r1/2 \u03b1k kuk.\n\nand\n\n(3.23)\n\nIf, in addition, Assumption 1(b) is satisfied, then\n2\n4\nkr\u03b1 (A )e0 k \u2264 kek k \u2264 c5 kr\u03b1k (A )e0 k\n3 k\n3\n\n(3.24)\n\n1\nkek k \u2264 kek+1 k \u2264 2kek k.\n2c5\n\n(3.25)\n\nand\n\nProof By using (3.2), (2.1), (2.12) and Assumption 3, we have from (3.13) that\nc4\nkek+1 \u2212 r\u03b1k (A )e0 k \u2264 k[r\u03b1k (Ak ) \u2212 r\u03b1k (A )]F \u2032 (x\u2020 )\u2217 uk + \u221a kF(xk ) \u2212 y \u2212 F \u2032 (xk )ek k\n\u03b1k\nc4\n2\n(3.26)\n\u2264 c6 Lkukkek k + \u221a Lkek k .\n2 \u03b1k\n1/2\n\nSince (2.1) and (3.2) imply kr\u03b1k (A )e0 k \u2264 c3 \u03b1k kuk, we have\nc4\n1/2\nkek+1 k \u2264 c3 \u03b1k kuk + c6Lkukkek k + \u221a Lkek k2 .\n2 \u03b1k\n1/2\n\nNote that (3.2) and (2.9) imply ke0 k \u2264 c3 \u03b10 kuk. By induction one can conclude the assertion\n(3.23) if Lkuk is so small that 2(c6 r1/2 + c3 c4 r)Lkuk \u2264 1.\nIf we assume further that\n\u0011\n\u0010\n(3.27)\n5c5 c6 + c3 c4 r1/2 Lkuk \u2264 1,\nthe combination of (3.26) and (3.23) gives\n\n\u0011\n\u0010\n1\nkek+1 \u2212 r\u03b1k (A )e0 k \u2264 c6 + c3 c4 r1/2 Lkukkek k \u2264\nkek k.\n5c5\n\n(3.28)\n\nNote that Assumption 1(b) and \u03b1k \u2264 \u03b1k\u22121 imply kr\u03b1k (A )e0 k \u2264 kr\u03b1k\u22121 (A )e0 k. Note also that\nAssumption 1(a) and (2.9) imply (3.24) with k = 0. Thus, from (3.28) and (2.7) we can conclude\n(3.24) by an induction argument. (3.25) is an immediate consequence of (3.28) and (3.24). \u2737\n\n\f19\n\nLemma 4 Let all the conditions in Lemma 2 and Assumption 1(c) hold. If k\u03b4 > 0 and Lkuk is\nsufficiently small, then for all k \u2265 k\u03b4 we have\n\u0001\n1\nkF(xk\u03b4 ) \u2212 yk + \u03b4 .\nkek\u03b4 k . kek k + \u221a\n\u03b1k\n\n(3.29)\n\nProof It follows from (3.13) that\n\nxk\u03b4 \u2212 xk = [r\u03b1k \u22121 (A ) \u2212 r\u03b1k\u22121 (A )]e0 + [r\u03b1k \u22121 (Ak\u03b4 \u22121 ) \u2212 r\u03b1k \u22121 (A )]e0\n\u03b4\n\u03b4\n\u0002\u03b4\n\u0003\n\u2212 r\u03b1k\u22121 (Ak\u22121 ) \u2212 r\u03b1k\u22121 (A ) e0\n\u0002\n\u0003\n\u2212 g\u03b1k \u22121 (Ak\u03b4 \u22121 )F \u2032 (xk\u03b4 \u22121 )\u2217 F(xk\u03b4 \u22121 ) \u2212 y \u2212 F \u2032 (xk\u03b4 \u22121 )ek\u03b4 \u22121\n\u03b4\n\u0002\n\u0003\n+ g\u03b1k\u22121 (Ak\u22121 )F \u2032 (xk\u22121 )\u2217 F(xk\u22121 ) \u2212 y \u2212 F \u2032 (xk\u22121 )ek\u22121 .\n\n(3.30)\n\nThus, by using (3.2), (2.12), Assumption 3, (2.1), (3.23) and (3.27), we have\nkxk\u03b4 \u2212 xk k \u2264 k[r\u03b1k\n\n(A ) \u2212 r\u03b1k\u22121 (A )]e0 k + c6Lkuk kek\u22121 k + kek\u03b4 \u22121 k\nc4\nc4\nLkek\u03b4 \u22121 k2 + \u221a\nLkek\u22121 k2\n+ \u221a\n2 \u03b1k\u03b4 \u22121\n2 \u03b1k\u22121\n\u0001\n1\nkek\u22121 k + kek\u03b4 \u22121 k .\n\u2264 k[r\u03b1k \u22121 (A ) \u2212 r\u03b1k\u22121 (A )]e0 k +\n\u03b4\n5c5\n\u03b4 \u22121\n\n\u0001\n(3.31)\n\nSince k \u2265 k\u03b4 , we have \u03b1k\u22121 \u2264 \u03b1k\u03b4 \u22121 . Since Assumption 1(b) and (c) hold, we may apply Lemma\n1 with x = e0 , x\u0304 = ek\u03b4 , \u03b1 = \u03b1k\u22121 , \u03b2 = \u03b1k\u03b4 \u22121 and A = F \u2032 (x\u2020 ) to obtain\nk[r\u03b1k\n\n\u03b4 \u22121\n\n(A ) \u2212 r\u03b1k\u22121 (A )]e0 k \u2264 kr\u03b1k\n\n\u03b4 \u22121\n\n(A )e0 \u2212 ek\u03b4 k + \u221a\n\nc2\nkF \u2032 (x\u2020 )ek\u03b4 k.\n\u03b1k\u22121\n\nNote that (3.28) implies\nkek\u03b4 \u2212 r\u03b1k\n\n\u03b4 \u22121\n\n(A )e0 k \u2264\n\n1\nkek \u22121 k.\n5c5 \u03b4\n\nNote also that Assumption 3 implies\n1\nkF \u2032 (x\u2020 )ek\u03b4 k \u2264 kF(xk\u03b4 ) \u2212 yk + Lkek\u03b4 k2 .\n2\nThus\nk[r\u03b1k\n\n\u03b4 \u22121\n\n(A ) \u2212 r\u03b1k\u22121 (A )]e0 k \u2264\n\n\u0001\nC\n1\nkF(xk\u03b4 ) \u2212 yk + Lkek\u03b4 k2 .\nkek\u03b4 \u22121 k + \u221a\n5c5\n\u03b1k\n\nSince Lemma 2, Theorem 4 and the fact k\u03b4 \u2264 k\u0303\u03b4 imply\n\n\u03b4\n. kuk1/2\u03b4 1/2 ,\nkek\u03b4 k . ke\u03b4k\u03b4 k + \u221a\n\u03b1k\u03b4\nwe have\nk[r\u03b1k\n\n\u03b4 \u22121\n\n(A ) \u2212 r\u03b1k\u22121 (A )]e0 k \u2264\n\n\u0001\nC\n1\nkF(xk\u03b4 ) \u2212 yk + Lkuk\u03b4 .\nkek\u03b4 \u22121 k + \u221a\n5c5\n\u03b1k\n\nCombining this with (3.31) and using Lemma 3 gives\n\n\u0001\n4\nC\nkxk\u03b4 \u2212 xk k \u2264 kek\u03b4 k + Ckek k + \u221a\nkF(xk\u03b4 ) \u2212 yk + \u03b4 .\n5\n\u03b1k\n\nThis completes the proof.\n\n\u2737\n\n\f20\n\n3.4 Completion of proof of Theorem 1\nLemma 5 Assume that all the conditions in Lemma 3 are satisfied. Then\n1/2\n\nkF \u2032 (x\u2020 )ek k . kr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k\n\n(3.32)\n\nfor all k \u2265 0.\nProof We first use (3.13) to write\n\u0002\n\u0003\nF \u2032 (x\u2020 )ek+1 = F \u2032 (x\u2020 )r\u03b1k (A )e0 + F \u2032 (x\u2020 ) r\u03b1k (Ak ) \u2212 r\u03b1k (A ) e0\n\u0002\n\u0003\n\u2212 F \u2032 (x\u2020 )g\u03b1k (Ak )F \u2032 (xk )\u2217 F(xk ) \u2212 y \u2212 F \u2032 (xk )ek .\n\n(3.33)\n\nThus, it follows from (3.2), Assumption 3, Assumption 1(a), (2.12), (2.13), (3.23) and (3.24) that\nkF \u2032 (x\u2020 )ek+1 k . kF \u2032 (x\u2020 )r\u03b1k (A )e0 k + Lkek kk[r\u03b1k (Ak ) \u2212 r\u03b1k (A )]F \u2032 (x\u2020 )\u2217 uk\n\n\u22121/2\n\n+ kF \u2032 (xk )[r\u03b1k (Ak ) \u2212 r\u03b1k (A )]F \u2032 (x\u2020 )\u2217 uk + (1 + Lkekk\u03b1k\n1/2\n\n. kr\u03b1k (A )A 1/2 e0 k + L2 kukkek k2 + \u03b1k Lkukkek k + Lkek k2\n\n)Lkek k2\n\n1/2\n\n. kr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k.\n\nThis together with (2.7) and (1.4) implies (3.32).\n\n\u2737\n\nLemma 6 Under the conditions in Lemma 2 and Lemma 3, if \u03b52 \u2264 (\u03c4 \u2212 1)/2 then for the k\u03b4\ndetermined by (1.7) with \u03c4 > 1 we have\n1/2\n\n(\u03c4 \u2212 1)\u03b4 . kr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k\n\n(3.34)\n\nfor all 0 \u2264 k < k\u03b4 ,\nProof By using (3.16), Lemma 3 and Lemma 5, we have for 0 \u2264 k < k\u03b4 that\n\n\u03c4\u03b4 \u2264 kF(x\u03b4k ) \u2212 y\u03b4 k \u2264 kF(x\u03b4k ) \u2212 F(xk ) \u2212 y\u03b4 + yk + kF(xk ) \u2212 yk\n1\n\u2264 (1 + \u03b52 )\u03b4 + kF \u2032 (x\u2020 )ek k + Lkek k2\n2\n1/2\n\u2264 (1 + \u03b52 )\u03b4 + Ckr\u03b1k (A )A 1/2 e0 k + C\u03b1k kr\u03b1k (A )e0 k.\n\nSince \u03c4 > 1, by the smallness condition \u03b52 \u2264 (\u03c4 \u2212 1)/2 on Lkuk we obtain (3.34).\n\n\u2737\n\nProof of Theorem 1. If k\u03b4 = 0, then the definition of k\u03b4 implies kF(x0 ) \u2212 y\u03b4 k \u2264 \u03c4\u03b4 . From Theorem 4 we know that ke0 k . kuk1/2\u03b4 1/2 . Thus\nkF \u2032 (x\u2020 )e0 k \u2264 kF(x0 ) \u2212 y \u2212 F \u2032 (x\u2020 )e0 k + kF(x0 ) \u2212 y\u03b4 k + \u03b4\n1\n\u2264 Lke0 k2 + (1 + \u03c4 )\u03b4 . \u03b4 .\n2\n\nSince e0 = A \u03bd \u03c9 for some 1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212 1/2, we may use the interpolation inequality to obtain\nke\u03b4k\u03b4 k = ke0 k = kA \u03bd \u03c9 k \u2264 k\u03c9 k1/(1+2\u03bd )kA 1/2+\u03bd \u03c9 k2\u03bd /(1+2\u03bd )\n= k\u03c9 k1/(1+2\u03bd )kF \u2032 (x\u2020 )e0 k2\u03bd /(1+2\u03bd )\n. k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd ) ,\n\nwhich gives the desired estimate.\nTherefore, we may assume that k\u03b4 > 0 in the remaining argument. By using e0 = A \u03bd \u03c9 for\nsome 1/2 \u2264 \u03bd \u2264 \u03bd\u0304 \u2212 1/2 and Lemma 6 it follows that there exists a positive constant C\u03bd such\nthat\n\u03bd +1/2\nk\u03c9 k,\n(\u03c4 \u2212 1)\u03b4 < C\u03bd \u03b1k\n0 \u2264 k < k\u03b4 .\n\n\f21\n\nNow we define the integer k\u0304\u03b4 by\n\u0013\n\u0012\n(\u03c4 \u2212 1)\u03b4 2/(1+2\u03bd )\n< \u03b1k ,\n\u03b1k\u0304\u03b4 \u2264\nC\u03bd k\u03c9 k\n\n0 \u2264 k < k\u0304\u03b4 .\n\nThen k\u03b4 \u2264 k\u0304\u03b4 . Thus, by using Lemma 2 and Lemma 4, we have\n\nkF(xk\u03b4 ) \u2212 yk + \u03b4\n\u03b4\n\u03b4\n. kek\u0304\u03b4 k +\n+\u221a\n.\nke\u03b4k\u03b4 k . kek\u03b4 k + \u221a\np\n\u03b1k\u03b4\n\u03b1k\u0304\u03b4\n\u03b1k\u03b4\n\nNote that Lemma 2 and the definition of k\u03b4 imply\n\nkF(xk\u03b4 ) \u2212 yk \u2264 kF(x\u03b4k\u03b4 ) \u2212 y\u03b4 k + kF(x\u03b4k\u03b4 ) \u2212 F(xk\u03b4 ) \u2212 y\u03b4 + yk . \u03b4 .\nThis together with (3.24), k\u03b4 \u2264 k\u0304\u03b4 and kr\u03b1k (A )e0 k . \u03b1k\u03bd k\u03c9 k then gives\n\n\u03b4\n\u03b4\n\u03b4\n+p\n. \u03b1k\u0304\u03bd k\u03c9 k + p\n.\nke\u03b4k\u03b4 k . \u03b1k\u0304\u03bd k\u03c9 k + \u221a\n\u03b4\n\u03b4\n\u03b1k\u03b4\n\u03b1k\u0304\u03b4\n\u03b1k\u0304\u03b4\n\nUsing the definition of k\u0304\u03b4 and (1.4), we therefore complete the proof.\n\n(3.35)\n\u2737\n\n4 Proof of Theorem 2\nIn this section we will give the proof of Theorem 2. The essential idea is similar as in the proof of\nTheorem 1. Thus we need to establish similar results as those used in Section 3. However, since\nwe do not have source representation e0 = F \u2032 (x\u2020 )\u2217 u any longer and since F satisfies different\nconditions, we must modify the arguments carefully. We will indicate the essential steps without\nspelling out all the necessary smallness conditions on (K0 + K1 + K2 )ke0 k. We first introduce the\ninteger n\u03b4 by\n\u00132\n\u0012\n\u03b4\n0 \u2264 k < n\u03b4 .\n< \u03b1k ,\n\u03b1n\u03b4 \u2264\n(4.1)\n\u03b31 ke0 k\nRecall that \u03b31 is a constant satisfying \u03b31 > c3 r1/2 /(\u03c4 \u2212 1).\n\nProof of Theorem 2. In order to complete the proof of Theorem 2, we need to establish various\nestimates. We will divide the arguments into several steps.\nStep 1. We will show that for all 0 \u2264 k \u2264 n\u03b4\nx\u03b4k \u2208 B\u03c1 (x\u2020 ),\n\nke\u03b4k k . ke0 k,\n\nkF \u2032 (x\u2020 )e\u03b4k k . \u03b1k ke0 k\n1/2\n\n(4.2)\n(4.3)\n\nand that k\u03b4 \u2264 n\u03b4 for the integer k\u03b4 defined by the discrepancy principle (1.7) with \u03c4 > 1.\nTo see this, we note that, for any 0 \u2264 k < n\u03b4 with x\u03b4k \u2208 B\u03c1 (x\u2020 ), (3.5) and Assumption 5 imply\ne\u03b4k+1 = r\u03b1k (Ak\u03b4 )e0 \u2212\n\nZ 1\n0\n\n\u0010\n\u0011\ng\u03b1k (Ak\u03b4 )Ak\u03b4 R(x\u03b4k \u2212 te\u03b4k , x\u03b4k ) \u2212 I e\u03b4k dt\n\n+ g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 (y\u03b4 \u2212 y).\n\nTherefore, with the help of Assumption 1(a) and (2.1), we have\n1\n1\n\u22121/2\nke\u03b4k+1 k \u2264 ke0 k + K0 ke\u03b4k k2 + c4 \u03b4 \u03b1k\n\u2264 (1 + c4\u03b31 )ke0 k + K0 ke\u03b4k k2 .\n2\n2\nThus, if 2(1 + c4 \u03b31 )K0 ke0 k \u2264 1, then, by using \u03c1 > 2(1 + c4 \u03b31 )ke0 k and an induction argument,\nwe can conclude ke\u03b4k k \u2264 2(1 + c4\u03b31 )ke0 k < \u03c1 for all 0 \u2264 k \u2264 n\u03b4 . This establishes (4.2).\n\n\f22\n\nNext we show (4.3). It follows from (3.5), Assumption 1(a), (1.2), (2.19) and (4.1) that for\n0 \u2264 k < n\u03b4\nkF \u2032 (x\u03b4k )e\u03b4k+1 k . \u03b1k ke0 k + \u03b4 + kF(x\u03b4k ) \u2212 y \u2212 F \u2032 (x\u03b4k )e\u03b4k k\n1/2\n\n. \u03b1k ke0 k + (K1 + K2 )ke\u03b4k kkF \u2032 (x\u2020 )e\u03b4k k.\n1/2\n\nBy Assumption 6 we have\nk[F \u2032 (x\u2020 ) \u2212 F \u2032 (x\u03b4k )]e\u03b4k+1 k \u2264 K1 ke\u03b4k kkF \u2032 (x\u2020 )e\u03b4k+1 k + K2 ke\u03b4k+1 kkF \u2032 (x\u2020 )e\u03b4k k.\nThe above two inequalities and (4.2) then imply\nkF \u2032 (x\u2020 )e\u03b4k+1 k . \u03b1k ke0 k + K1ke0 kkF \u2032 (x\u2020 )e\u03b4k+1 k + (K1 + K2 )ke0 kkF \u2032 (x\u2020 )e\u03b4k k.\n1/2\n\nThus, if (K1 + K2 )ke0 k is sufficiently small, we can conclude (4.3) by an induction argument. As\ndirect consequences of (4.2), (4.3) and Assumption 6 we have\nkF \u2032 (x\u03b4k )e\u03b4k k . \u03b1k ke0 k,\n1/2\n\nand\n\n0 \u2264 k \u2264 n\u03b4\n\nkF \u2032 (x\u03b4k+1 )(x\u03b4k+1 \u2212 x\u03b4k )k . \u03b1k ke0 k,\n1/2\n\n0 \u2264 k < n\u03b4 .\n\n(4.4)\n(4.5)\n\nIn order to show k\u03b4 \u2264 n\u03b4 , we note that (3.5) gives\n\u0010\n\u0011\nF \u2032 (x\u2020 )e\u03b4k+1 \u2212 y\u03b4 + y = F \u2032 (x\u03b4k )r\u03b1k (Ak\u03b4 )e0 + F \u2032 (x\u2020 ) \u2212 F \u2032 (x\u03b4k ) r\u03b1k (Ak\u03b4 )e0\n\u0011\n\u0010\n\u0011\n\u0010\n\u2212 F \u2032 (x\u2020 ) \u2212 F \u2032 (x\u03b4k ) g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )e\u03b4k\n\u0010\n\u0011\n\u2212 g\u03b1k (Bk\u03b4 )Bk\u03b4 F(x\u03b4k ) \u2212 y \u2212 F \u2032 (x\u03b4k )e\u03b4k \u2212 r\u03b1k (Bk\u03b4 )(y\u03b4 \u2212 y).\n\nThus, by using (1.2), Assumption 1(a), (2.1), Assumption 6, (2.18), (4.2), (4.4) and (1.4) we have\nfor 0 \u2264 k < n\u03b4\nkF \u2032 (x\u2020 )e\u03b4k+1 \u2212 y\u03b4 + yk \u2264 \u03b4 + c3 \u03b1k ke0 k + c3K1 ke0 kke\u03b4k k\u03b1k + K2 ke0 kkF \u2032 (x\u03b4k )e\u03b4k k\n\u0012\n\u0013\n1\n+ K1 ke\u03b4k k \u03b4 + (K1 + K2 )ke\u03b4k kkF \u2032 (x\u03b4k )e\u03b4k k\n2\n\u0012\n\u0013\n1\n\u22121/2\n+ c4 K2 \u03b1k\nkF \u2032 (x\u03b4k )e\u03b4k k \u03b4 + (K1 + K2 )ke\u03b4k kkF \u2032 (x\u03b4k )e\u03b4k k\n2\n1\n+ (K1 + K2 )ke\u03b4k kkF \u2032 (x\u03b4k )e\u03b4k k\n2\n1/2\n\u2264 \u03b4 + (c3 + C(K1 + K2 )ke0 k) \u03b1k ke0 k\n1/2\n\n1/2\n\n1/2\n\n\u2264 \u03b4 + r1/2 (c3 + C(K1 + K2 )ke0 k) \u03b1k+1 ke0 k.\n\nRecall that \u03b31 > c3 r1/2 /(\u03c4 \u2212 1). Thus, with the help of (4.2), (4.3) and the definition of n\u03b4 , one\ncan see that, if (K1 + K2 )ke0 k is sufficiently small, then\nkF(x\u03b4n\u03b4 ) \u2212 y\u03b4 k \u2264 kF(x\u03b4n\u03b4 ) \u2212 y \u2212 F \u2032 (x\u2020 )e\u03b4n\u03b4 k + kF \u2032 (x\u2020 )e\u03b4n\u03b4 \u2212 y\u03b4 + yk\n1/2\n\n\u2264 \u03b4 + r1/2 (c3 + C(K1 + K2 )ke0 k) \u03b1n\u03b4 ke0 k\n1\n+ (K1 + K2 )ke\u03b4n\u03b4 kkF \u2032 (x\u2020 )e\u03b4n\u03b4 k\n2\n1/2\n\u2264 \u03b4 + r1/2 (c3 + C(K1 + K2 )ke0 k) \u03b1n\u03b4 ke0 k\n\u2264 \u03b4 + r1/2 (c3 + C(K1 + K2 )ke0 k) \u03b31\u22121 \u03b4\n\n\u2264 \u03c4\u03b4 .\n\n\f23\n\nThis implies k\u03b4 \u2264 n\u03b4 .\nStep 2. We will show, for the noise-free iterated solutions {xk }, that for all k \u2265 0\n\nand for all 0 \u2264 k \u2264 l\n\nkr\u03b1k (A )e0 k . kek k . kr\u03b1k (A )e0 k,\n\n(4.6)\n\nkek k . kek+1 k . kek k\n\n(4.7)\n\n1\nkek k . kel k + \u221a kF(xk ) \u2212 yk.\n\u03b1l\n\n(4.8)\n\nIn fact, from (3.13) and Assumption 5 it is easy to see that\n1\nkek+1 \u2212 r\u03b1k (Ak )e0 k \u2264 K0 kek k2 .\n2\n\n(4.9)\n\nIf 2K0 ke0 k \u2264 1, then by induction we can see that {xk } is well-defined and\nkek k \u2264 2ke0 k\n\nfor all k \u2265 0.\n\n(4.10)\n\nThis together with (4.9) and (2.20) gives\nkek+1 \u2212 r\u03b1k (A )e0 k . k[r\u03b1k (Ak ) \u2212 r\u03b1k (A )]e0 k + K0kek k2 . K0 ke0 kkek k.\n\n(4.11)\n\nThus, by Assumption 2 and the smallness of K0 ke0 k we obtain (4.6) by induction. (4.7) is an\nimmediate consequence of (4.11) and (4.6).\nIn order to show (4.8), we first consider the case k > 0. Note that xk \u2212 xl has a similar expression as in (3.30), so we may use (2.20), Assumption 5 and (4.10) to obtain\nkxk \u2212 xl k . kr\u03b1k\u22121 (A )e0 \u2212 r\u03b1l\u22121 (A )e0 k + K0ke0 k (kek\u22121 k + kel\u22121k)\n+ K0 kek\u22121 k2 + K0 kel\u22121 k2\n\n. k[r\u03b1k\u22121 (A ) \u2212 r\u03b1l\u22121 (A )]e0 k + K0 ke0 k (kek\u22121 k + kel\u22121k) .\n\n(4.12)\n\nBy Lemma 1 with x = e0 , x\u0304 = ek , \u03b1 = \u03b1l\u22121 , \u03b2 = \u03b1k\u22121 and A = F \u2032 (x\u2020 ), we have\n1\nk[r\u03b1k\u22121 (A ) \u2212 r\u03b1l\u22121 (A )]e0 k . kr\u03b1k\u22121 (A )e0 \u2212 ek k + \u221a\nkF \u2032 (x\u2020 )ek k.\n\u03b1l\u22121\nWith the help of (2.18), (4.10), and the smallness of (K1 + K2 )ke0 k, we have\n1\nkF \u2032 (x\u2020 )ek k \u2264 kF(xk ) \u2212 yk + kF \u2032 (x\u2020 )ek k.\n2\n\n(4.13)\n\nTherefore kF \u2032 (x\u2020 )ek k \u2264 2kF(xk ) \u2212 yk. This together with (4.11) and (4.7) then implies\n1\nk[r\u03b1k\u22121 (A ) \u2212 r\u03b1l\u22121 (A )]e0 k . K0 ke0 kkek k + \u221a kF(xk ) \u2212 yk.\n\u03b1l\nCombining this with (4.12) gives\n1\nkxk \u2212 xl k . K0 ke0 kkek k + kel k + \u221a kF(xk ) \u2212 yk\n\u03b1l\nwhich implies (4.8) if K0 ke0 k is sufficiently small.\nFor the case k = 0, we can assume l \u2265 1. Since (4.8) is valid for k = 1, we may use (4.7) to\nconclude that (4.8) is also true for k = 0.\nStep 3. We will show for all k \u2265 0 that\nkF \u2032 (x\u2020 )ek k . kr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k.\n1/2\n\n(4.14)\n\n\f24\n\nTo this end, first we may use the similar manner in deriving (4.3) to conclude\n1/2\n\nkF \u2032 (x\u2020 )ek k . \u03b1k ke0 k.\n\n(4.15)\n\nNote that Assumption 6 and (4.10) imply\nk[F \u2032 (x\u2020 ) \u2212 F \u2032 (xk )]ek k \u2264 (K1 + K2 )kek kkF \u2032 (x\u2020 )ek k\n\n. (K1 + K2 )ke0 kkF \u2032 (x\u2020 )ek k.\n\nTherefore\nkF \u2032 (xk )ek k . kF \u2032 (x\u2020 )ek k.\n\n(4.16)\n\nIn particular this implies\n1/2\n\nkF \u2032 (xk )ek k . \u03b1k ke0 k.\n\n(4.17)\n\nBy using (3.33), (2.21), Assumption 6, (2.18) and Assumption 1(a) we obtain\n1/2\n\nkF \u2032 (x\u2020 )ek+1 k . kr\u03b1k (A )A 1/2 e0 k + (K0 + K1 )ke0 kkek k\u03b1k\n\u0001\n+ K2 ke0 k kF \u2032 (x\u2020 )ek k + kF \u2032 (xk )ek k\n\n+ (K1 + K2 )kek kkF \u2032 (xk )ek k + K1 (K1 + K2 )kek k2 kF \u2032 (xk )ek k\n\u22121/2\n\n+ K2 (K1 + K2 )kek kkF \u2032 (xk )ek k2 \u03b1k\n\n.\n\nThus, with the help of (4.6), (4.15), (4.16), (4.17) and (4.10), we obtain\n1/2\n\nkF \u2032 (x\u2020 )ek+1 k . kr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k + K2ke0 kkF \u2032 (x\u2020 )ek k.\nThe estimates (4.14) thus follows by Assumption 2 and an induction argument if K2 ke0 k is\nsufficiently small.\nStep 4. Now we will establish some stability estimates. We will show for all 0 \u2264 k \u2264 n\u03b4 that\n\nand\n\n\u03b4\nkx\u03b4k \u2212 xk k . \u221a\n\u03b1k\n\n(4.18)\n\nkF(x\u03b4k ) \u2212 F(xk ) \u2212 y\u03b4 + yk \u2264 (1 + C(K0 + K1 + K2 )ke0 k) \u03b4 .\n\n(4.19)\n\nIn order to show (4.18), we use again the decomposition (3.18) for x\u03b4k+1 \u2212 xk+1 . We still have\n\u221a\nkI2 k \u2264 c4 \u03b4 / \u03b1k . By using (2.20) the term I1 can be estimated as\nkI1 k . K0 ke0 kkx\u03b4k \u2212 xk k.\nIn order to estimate I3 , we note that Assumption 5 implies\nI3 =\n+\n\nZ 1h\n0\n\nZ 1\n0\n\n=\n\nh\ni\ng\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) \u2212 F \u2032 (xk ) [R(xk \u2212 tek , xk ) \u2212 I]ek dt\n\nZ 1h\n0\n\n+\n\ni\ng\u03b1k (Ak )Ak \u2212 g\u03b1k (Ak\u03b4 )Ak\u03b4 [R(xk \u2212 tek , xk ) \u2212 I]ek dt\n\nZ 1\n0\n\ni\nr\u03b1k (Ak\u03b4 ) \u2212 r\u03b1k (Ak ) [R(xk \u2212 tek , xk ) \u2212 I]ek dt\n\nh\ni\ng\u03b1k (Ak\u03b4 )Ak\u03b4 I \u2212 R(xk , x\u03b4k ) [R(xk \u2212 tek , xk ) \u2212 I]ek dt.\n\nThus, by using (2.20) and (4.10), we obtain\n\nkI3 k . K02 kek k2 kx\u03b4k \u2212 xk k . K02 ke0 k2 kx\u03b4k \u2212 xk k.\n\n\f25\n\nIn order to estimate I4 , we again use Assumption 5 to write\nh\ni\nI4 = g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 F(xk ) \u2212 F(x\u03b4k ) \u2212 F \u2032 (x\u03b4k )(xk \u2212 x\u03b4k )\nh\ni\n+ g\u03b1k (Ak\u03b4 )F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) \u2212 F \u2032 (xk ) ek\nZ 1\nh\ni\ng\u03b1k (Ak\u03b4 )Ak\u03b4 R(x\u03b4k + t(xk \u2212 x\u03b4k ), x\u03b4k ) \u2212 I (xk \u2212 x\u03b4k )dt\n=\n0\nh\ni\n+ g\u03b1k (Ak\u03b4 )Ak\u03b4 I \u2212 R(xk , x\u03b4k ) ek .\nHence, we may use (4.2) and (4.10) to derive that\n\nkI4 k . K0 kx\u03b4k \u2212 xk k2 + K0 kek kkx\u03b4k \u2212 xk k . K0 ke0 kkx\u03b4k \u2212 xk k.\nCombining the above estimates we obtain for 0 \u2264 k < n\u03b4\n\n\u03b4\nkx\u03b4k+1 \u2212 xk+1 k . \u221a + K0 ke0 kkx\u03b4k \u2212 xk k.\n\u03b1k\n\nThus, if K0 ke0 k is sufficiently small, we can obtain (4.18) immediately.\nNext we show (4.19) by using (3.20). We still have (3.21). In order to estimate kF \u2032 (x\u03b4k )I1 k,\nkF \u2032 (x\u03b4k )I3 k and kF \u2032 (x\u03b4k )I4 k, we note that Assumption 6, (4.10), (4.15) and (4.18) imply\nk[F \u2032 (xk ) \u2212 F \u2032 (x\u2020 )](x\u03b4k \u2212 xk )k\n\n\u2264 K1 kek kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k + K2 kF \u2032 (x\u2020 )ek kkx\u03b4k \u2212 xk k\n\n. K1 ke0 kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k + K2ke0 k\u03b4 ,\nwhich in turn gives\nSimilarly, we have\n\nkF \u2032 (xk )(x\u03b4k \u2212 xk )k . kF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k + \u03b4 .\n\n(4.20)\n\nkF \u2032 (x\u03b4k )(x\u03b4k \u2212 xk )k . kF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k + \u03b4 .\n\n(4.21)\n\nThus, by using (2.21), (4.18), (4.20) and (4.21) we have\nkF \u2032 (x\u03b4k )I1 k . (K0 + K1 )ke0 k\u03b1k kx\u03b4k \u2212 xk k\n\u0011\n\u0010\n+ K2 ke0 k kF \u2032 (x\u03b4k )(x\u03b4k \u2212 xk )k + kF \u2032 (xk )(x\u03b4k \u2212 xk )k\n1/2\n\n. (K0 + K1 + K2 )ke0 k\u03b4 + K2 ke0 kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k.\n\nMoreover, by employing (3.22), (2.20), Assumption 6, (2.18), (4.10), (4.17), (4.18) and (4.20),\nkF \u2032 (x\u03b4k )I3 k can be estimated as\nkF \u2032 (x\u03b4k )I3 k . (K0 + K1 )kx\u03b4k \u2212 xk kkuk k + \u03b1k\n\n\u22121/2\n\n. (K0 + K1 + K2 )(K1 + K2 )ke0 k2 \u03b4\n\nK2 kF \u2032 (xk )(x\u03b4k \u2212 xk )kkuk k\n\n+ K2 (K1 + K2 )ke0 k2 kF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k.\n\nwhile, by using Assumption 6, (2.18), (4.2), (4.10), (4.4), (4.18), (4.20) and (4.21), kF \u2032 (x\u03b4k )I4 k\ncan be estimated as\nkF \u2032 (x\u03b4k )I4 k \u2264 kF(x\u03b4k ) \u2212 F(xk ) \u2212 F \u2032 (xk )(x\u03b4k \u2212 xk )k + k[F \u2032 (x\u03b4k ) \u2212 F \u2032 (xk )]e\u03b4k k\n. (K1 + K2 )kx\u03b4k \u2212 xk kkF \u2032 (xk )(x\u03b4k \u2212 xk )k\n\n+ K1 kx\u03b4k \u2212 xk kkF \u2032 (x\u03b4k )e\u03b4k k + K2 kF \u2032 (x\u03b4k )(x\u03b4k \u2212 xk )kke\u03b4k k\n\n. (K1 + K2 )ke0 k\u03b4 + (K1 + K2 )ke0 kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k.\n\n\f26\n\nCombining the above estimates we get\nkF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1) \u2212 y\u03b4 + yk\n\n\u2264 (1 + C(K0 + K1 + K2 )ke0 k)\u03b4 + C(K1 + K2 )ke0 kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k.\n\n(4.22)\n\nThis in particular implies\nkF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1 )k . \u03b4 + (K1 + K2 )ke0 kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k.\nOn the other hand, similar to the derivation of (4.20), by Assumption 6, (4.2), (4.4) and (4.18)\nwe have for 0 \u2264 k < n\u03b4 that\nkF \u2032 (x\u2020 )(x\u03b4k+1 \u2212 xk+1 )k . K2 ke0 k\u03b4 + kF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1 )k.\n\nTherefore\n\nkF \u2032 (x\u2020 )(x\u03b4k+1 \u2212 xk+1 )k . \u03b4 + (K1 + K2 )ke0 kkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k.\n\nThus, if (K1 + K2 )ke0 k is small enough, then we can conclude\nkF \u2032 (x\u2020 )(x\u03b4k \u2212 xk )k . \u03b4 ,\n\n0 \u2264 k \u2264 n\u03b4 .\n\n(4.23)\n\nCombining this with (4.22) gives for 0 \u2264 k < n\u03b4\n\nkF \u2032 (x\u03b4k )(x\u03b4k+1 \u2212 xk+1 ) \u2212 y\u03b4 + yk \u2264 (1 + C(K0 + K1 + K2 )ke0 k) \u03b4 .\n\n(4.24)\n\nHence, by using (4.24), Assumption 6, (4.2), (4.5), (4.18), (4.21) and (4.23), we obtain for 0 \u2264\nk \u2264 n\u03b4\nkF \u2032 (x\u03b4k )(x\u03b4k \u2212 xk ) \u2212 y\u03b4 + yk \u2264 (1 + C(K0 + K1 + K2 )ke0 k) \u03b4 .\nThis together with (2.18), (4.2) and (4.10) implies (4.19).\nStep 5. Now we are ready to complete the proof. By using the definition of k\u03b4 , (4.19), (2.18)\nand (4.14) we have for 0 \u2264 k < k\u03b4\n\n\u03c4\u03b4 \u2264 kF(x\u03b4k ) \u2212 y\u03b4 k \u2264 kF(x\u03b4k ) \u2212 F(xk ) \u2212 y\u03b4 + yk + kF(xk ) \u2212 yk\n\u2264 (1 + C(K0 + K1 + K2 )ke0 k)\u03b4 + CkF \u2032 (x\u2020 )ek k\n\n1/2\n\n\u2264 (1 + C(K0 + K1 + K2 )ke0 k) \u03b4 + Ckr\u03b1k (A )A 1/2 e0 k + C\u03b1k kr\u03b1k (A )e0 k.\n\nSince \u03c4 > 1, by assuming (K0 + K1 + K2 )ke0 k is small enough, we can conclude for 0 \u2264 k < k\u03b4\nthat\n1/2\n(4.25)\n(\u03c4 \u2212 1)\u03b4 . kr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k.\n\nWhen x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208 X and 0 < \u03bd \u2264 \u03bd\u0304 \u2212 1/2, by using (4.25), (4.8),\n(4.6), (4.18), (4.19) and the definition of k\u03b4 , we can employ the similar argument as in the last\npart of the proof of Theorem 1 to conclude (2.22).\nWhen x0 \u2212 x\u2020 satisfies (1.11) for some \u03c9 \u2208 X and \u03bc > 0, we have from Assumption 1(a) and\n(2.3) that\n\u0010\n\u0011\n1/2\n1/2\n1/2\nkr\u03b1k (A )A 1/2 e0 k + \u03b1k kr\u03b1k (A )e0 k \u2264 c0 b2\u03bc + b\u03bc \u03b1k (\u2212 ln(\u03b1k /(2\u03b10 )))\u2212\u03bc k\u03c9 k.\nThis and (4.25) imply that there exists a constant C\u03bc > 0 such that\n1/2\n\n(\u03c4 \u2212 1)\u03b4 < C\u03bc \u03b1k\n\n(\u2212 ln(\u03b1k /(2\u03b10 )))\u2212\u03bc k\u03c9 k,\n\n0 \u2264 k < k\u03b4 .\n\nIf we introduce the integer k\u0302\u03b4 by\n1/2\n\n\u03b1k\u0302\n\n\u03b4\n\n\u0011\u2212\u03bc (\u03c4 \u2212 1)\u03b4\n\u0010\n1/2\n\u2264\n< \u03b1k (\u2212 ln(\u03b1k /(2\u03b10 )))\u2212\u03bc ,\n\u2212 ln(\u03b1k\u0302 /(2\u03b10 ))\n\u03b4\nC\u03bc k\u03c9 k\n\n0 \u2264 k < k\u0302\u03b4 ,\n\n\f27\n\nthen k\u03b4 \u2264 k\u0302\u03b4 . Thus, by using (4.8), (4.18), (4.19), the definition of k\u03b4 and the fact kek k .\nkr\u03b1k (A )e0 k . (\u2212 ln(\u03b1k /(2\u03b10 )))\u2212\u03bc k\u03c9 k, we can use the similar manner in deriving (3.35) to\nget\n\u0011\u2212 \u03bc\n\u0010\n\u03b4\n\u03b4\nk\u03c9 k + p\n.p\n.\n(4.26)\nke\u03b4k\u03b4 k . \u2212 ln(\u03b1k\u0302 /(2\u03b10 ))\n\u03b4\n\u03b1k\u0302\n\u03b1k\u0302\n\u03b4\n\n\u03b4\n\nBy elementary argument we can show from (1.4) and the definition of k\u0302\u03b4 that there is a constant\nc\u03bc > 0 such that\n\u0012\n\u00132 \u0012\n\u00132\u03bc\n\u03b4\n\u03b4\n\u03b1k\u0302 \u2265 r\u22121 \u03b1k\u0302 \u22121 \u2265 c\u03bc\n.\n1 + ln\n\u03b4\n\u03b4\nk\u03c9 k\nk\u03c9 k\n\nThis together with (4.26) implies the estimate (2.23).\n\n\u2737\n\n5 Proof of Theorem 3\nIf x0 = x\u2020 , then k\u03b4 = 0 and the result is trivial. Therefore, we will assume x0 6= x\u2020 . We define k\u0302\u03b4\nto be the first integer such that\n1/2\n\nkr\u03b1k\u0302 (A )A 1/2 e0 k + \u03b1k\u0302 kr\u03b1k\u0302 (A )e0 k \u2264 c\u03b4 ,\n\u03b4\n\n\u03b4\n\n\u03b4\n\nwhere the constant c > 0 is chosen so that we may apply Lemma 6 or (4.25) to conclude k\u03b4 \u2264 k\u0302\u03b4 .\nBy (1.4), such k\u0302\u03b4 is clearly well-defined and is finite. Moreover, by a contradiction argument it\nis easy to show that\n(5.1)\nk\u0302\u03b4 \u2192 \u221e as \u03b4 \u2192 0.\nNow, under the conditions of Theorem 3 (i) we use Lemma 2, Lemma 4 and (3.24), while\nunder the conditions of Theorem 3 (ii) we use (4.18), (4.19), (4.6) and (4.8), then from the\ndefinition of k\u03b4 we have\n\n\u03b4\n\u03b4\nke\u03b4k\u03b4 k . kek\u03b4 k + \u221a\n. kek\u03b4 k + p\n\u03b1k\u03b4\n\u03b1k\u0302\n\n\u03b4\n\n1\n. kek\u0302 k + p\n\u03b4\n\u03b1k\u0302\n\n\u03b4\n\nkF(xk\u03b4 ) \u2212 yk + \u03b4\n\n\u03b4\n. kr\u03b1k\u0302 (A )e0 k + p\n\u03b4\n\u03b1k\u0302\n\n\u0001\n\n\u03b4\n\n\u03b4\n.p\n.\n\u03b1k\u0302\n\n(5.2)\n\n\u03b4\n\nWe therefore need to derive the lower bound of \u03b1k\u0302 under the conditions on e0 . We set for each\n\u03b4\n\u03b1 > 0 and 0 \u2264 \u03bc \u2264 \u03bd\u0304\nc\u03bc (\u03b1 ) :=\n\n\u0014Z\n\n0\n\n1/2\n\n\u03b1\n\n\u22122 \u03bc\n\n2 2\u03bc\n\nr\u03b1 (\u03bb ) \u03bb\n\n\u00151/2\nd(E\u03bb \u03c9 , \u03c9 )\n,\n\nwhere {E\u03bb } denotes the spectral family generated by A . It is easy to see for each 0 \u2264 \u03bc < \u03bd\u0304 that\n\u03b1 \u22122\u03bc r\u03b1 (\u03bb )2 \u03bb 2\u03bc is uniformly bounded for all \u03b1 > 0 and \u03bb \u2208 [0, 1/2] and \u03b1 \u22122\u03bc r\u03b1 (\u03bb )2 \u03bb 2\u03bc \u2192 0\nas \u03b1 \u2192 0 for all \u03bb \u2208 (0, 1/2]. Since \u03c9 \u2208 N (F \u2032 (x\u2020 ))\u22a5 , by the dominated convergence theorem\nwe have for each 0 \u2264 \u03bc < \u03bd\u0304\nc\u03bc (\u03b1 ) \u2192 0 as \u03b1 \u2192 0.\n(5.3)\n\n\f28\n\nBy the definition of k\u0302\u03b4 , (1.4), Assumption 2, and the condition e0 = A \u03bd \u03c9 we have\n\n\u03b4 . kr\u03b1k\u0302\n\n\u03b4 \u22121\n\n(A )A 1/2 e0 k + \u03b1k\u0302\n\n\u03b4 \u22121\n\n\u03b4 \u22121\n\n(A )e0 k\n\n. kr\u03b1k\u0302 (A )A 1/2 e0 k + \u03b1k\u0302 kr\u03b1k\u0302 (A )e0 k\n\u03b4\n\u03b4\n\u03b4\n\u0011\n\u0010\n\u03bd +1/2\n. \u03b1k\u0302\nc\u03bd (\u03b1k\u0302 ) + c\u03bd +1/2(\u03b1k\u0302 )\n\u03b4\n\n\u03b4\n\nThis implies\n\nkr\u03b1k\u0302\n\n\u03b4\n\nc\u03b4\nc\u03bd (\u03b1k\u0302 ) + c\u03bd +1/2(\u03b1k\u0302 )\n\n\u03b1k\u0302 \u2265\n\u03b4\n\n\u03b4\n\n\u03b4\n\n!2/(1+2\u03bd )\n\n.\n\n(5.4)\n\nCombining (5.2) and (5.4) gives\n\u0010\n\u00111/(1+2\u03bd )\nke\u03b4k\u03b4 k . c\u03bd (\u03b1k\u0302 ) + c\u03bd +1/2(\u03b1k\u0302 )\n\u03b4 2\u03bd /(1+2\u03bd )\n\u03b4\n\n\u03b4\n\nSince 0 \u2264 \u03bd < \u03bd\u0304 \u2212 1/2, this together with (5.1) and (5.3) gives the desired conclusion.\n6 Applications\nIn this section we will consider some specific methods defined by (1.3) by presenting several\nexamples of {g\u03b1 }. We will verify that those assumptions in Section 2 are satisfied for these\nexamples.\n\n6.1 Example 1\nWe first consider the function g\u03b1 given by\ng\u03b1 (\u03bb ) =\n\n(\u03b1 + \u03bb )m \u2212 \u03b1 m\n,\n\u03bb (\u03b1 + \u03bb )m\n\n(6.1)\n\nwhere m \u2265 1 is a fixed integer. This function arises from the iterated Tikhonov regularization of\norder m for linear ill-posed problems. Note that when m = 1, the corresponding method defined\nby (1.3) is exactly the iteratively regularized Gauss-Newton method (1.8). It is clear that the\nresidual function corresponding to (6.1) is\nr\u03b1 (\u03bb ) =\n\n\u03b1m\n.\n(\u03b1 + \u03bb )m\n\nBy elementary calculations it is easy to see that Assumption 1(a) and (b) are satisfied with c0 =\n(m \u2212 1)m\u22121 /mm and c1 = m. Moreover (2.1) is satisfied with\n\u0013\n\u0012\n\u0012\n\u0013 \u0013\n\u0012\nm+1 m \u221a\n2m \u2212 1 m\n1\n\u221a\nm.\nand c4 = 1 \u2212\nc3 =\n2m\nm+3\n2m \u2212 1\nBy using the elementary inequality\n1 \u2212 (1 \u2212 t)n \u2264\n\n\u221a\nnt,\n\n0\u2264t \u22641\n\nfor any integer n \u2265 0, we have for 0 < \u03b1 \u2264 \u03b2 and \u03bb \u2265 0 that\nr\n\u0012\n\u0013 \u0015\n\u03bb /\u03b1 \u2212 \u03bb /\u03b2 m\n\u03bb\n1/2\nr\u03b2 (\u03bb ) \u2212 r\u03b1 (\u03bb ) = r\u03b2 (\u03bb ) 1 \u2212 1 \u2212\n\u2264m\nr (\u03bb ).\n1 + \u03bb /\u03b1\n\u03b1 \u03b2\n\u0014\n\n(6.2)\n\n\f29\n\nThis verifies Assumption 1(c) with c2 = m1/2 . It is well-known that the qualification for g\u03b1 is\n\u03bd\u0304 = m and (2.2) is satisfied with d\u03bd = (\u03bd /m)\u03bd ((m \u2212 \u03bd )/m)m\u2212\u03bd \u2264 1 for each 0 \u2264 \u03bd \u2264 m. For the\nsequence {\u03b1k } satisfying (1.4), Assumption 2 is satisfied with c5 = rm .\nIn order to verify Assumption 4, we note that\nr\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B)\nm\n\n= \u03b1 m \u2211 (\u03b1 I + A\u2217 A)\u2212i [A\u2217 (B \u2212 A) + (B\u2217 \u2212 A\u2217)B](\u03b1 I + B\u2217 B)\u2212m\u22121+i .\n\n(6.3)\n\ni=1\n\nThus, by using the estimates\nk(\u03b1 I + A\u2217 A)\u2212i (A\u2217 A)\u03bc k \u2264 \u03b1 \u2212i+\u03bc\n\nfor i \u2265 1 and 0 \u2264 \u03bc \u2264 1,\n\nwe can verify (2.11), (2.12) and (2.13) easily.\n\u2212i\ni\nNote also that g\u03b1 (\u03bb ) = \u03b1 \u22121 \u2211m\ni=1 \u03b1 (\u03b1 + \u03bb ) . We have, by using (2.12),\nm\n\nk[g\u03b1 (A\u2217 A) \u2212 g\u03b1 (B\u2217 B)]B\u2217 k \u2264 \u03b1 \u22121 \u2211 k\u03b1 i [(\u03b1 I + A\u2217A)\u2212i \u2212 (\u03b1 I + B\u2217B)\u2212i ]B\u2217 k\ni=1\n\n. \u03b1 \u22121 kA \u2212 Bk,\nwhich verifies (2.14).\nFinally we verify Assumption 7 by assuming that F satisfies Assumption 5 and Assumption\n6. We will use the abbreviation Fx\u2032 := F \u2032 (x) for x \u2208 B\u03c1 (x\u2020 ). With the help of (6.3) with A = Fx\u2032\nand B = Fz\u2032 , we obtain from Assumption 5 that\nkr\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 )k\nm\n\n\u2264 \u03b1 m \u2211 k(\u03b1 I + Fx\u2032\u2217 Fx\u2032 )\u2212i Fx\u2032\u2217 Fx\u2032 [R(z, x) \u2212 I](\u03b1 I + Fz\u2032\u2217 Fz\u2032 )\u2212m\u22121+i k\ni=1\nm\n\n+ \u03b1 m \u2211 k(\u03b1 I + Fx\u2032\u2217 Fx\u2032 )\u2212i [I \u2212 R(x, z)]\u2217 Fz\u2032\u2217 Fz\u2032 (\u03b1 I + Fz\u2032\u2217 Fz\u2032 )\u2212m\u22121+i k\n\u2264\u03b1\n\ni=1\nm\nm\n\nm\n\n\u2211 \u03b1 \u2212i+1 kI \u2212 R(z, x)k\u03b1 \u2212m\u22121+i + \u03b1 m \u2211 \u03b1 \u2212i kI \u2212 R(x, z)k\u03b1 \u2212m+i\n\ni=1\n\ni=1\n\n. kI \u2212 R(z, x)k + kI \u2212 R(x, z)k\n. K0 kx \u2212 zk\nwhich verifies (2.20). In order to show (2.21), we note that, for any a \u2208 X and b \u2208 Y satisfying\nkak = kbk = 1, (6.3) implies\n(Fx\u2032 [r\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 )]a, b)\nm\n\n\u2264 \u03b1 m \u2211 \u03b1 \u2212i+1 k(Fz\u2032 \u2212 Fx\u2032 )(\u03b1 I + Fz\u2032\u2217 Fz\u2032 )\u2212m\u22121+i akkbk\ni=1\nm\n\n+ \u03b1 m \u2211 \u03b1 \u2212m\u22121/2+i k(Fz\u2032 \u2212 Fx\u2032 )(\u03b1 I + Fx\u2032\u2217 Fx\u2032 )\u2212i Fx\u2032\u2217 bkkak.\ni=1\n\n\f30\n\nThus, by using Assumption 6, we have\n(Fx\u2032 [r\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 )]a, b)\nm\n\n\u2264 \u03b1 m \u2211 \u03b1 \u2212i+1 K1 kx \u2212 zkkFz\u2032 (\u03b1 I + Fz\u2032\u2217 Fz\u2032 )\u2212m\u22121+i ak\ni=1\nm\n\n+ \u03b1 m \u2211 \u03b1 \u2212i+1 K2 kFz\u2032 (x \u2212 z)kk(\u03b1 I + Fz\u2032\u2217 Fz\u2032 )\u2212m\u22121+i ak\ni=1\nm\n\n+ \u03b1 m \u2211 \u03b1 \u2212m\u22121/2+i K1 kx \u2212 zkkFx\u2032 (\u03b1 I + Fx\u2032\u2217 Fx\u2032 )\u2212i Fx\u2032\u2217 bk\ni=1\nm\n\n+ \u03b1 m \u2211 \u03b1 \u2212m\u22121/2+i K2 kFx\u2032 (x \u2212 z)kk(\u03b1 I + Fx\u2032\u2217 Fx\u2032 )\u2212i Fx\u2032\u2217 bk\ni=1\n1/2\n\n. K1 \u03b1\n\n\u0001\nkx \u2212 zk + K2 kFx\u2032 (x \u2212 z)k + kFz\u2032 (x \u2212 z)k .\n\nThis verifies (2.21).\nThe above analysis shows that Theorem 1, Theorem 2 and Theorem 3 are applicable for the\nmethod defined by (1.3) and (1.7) with g\u03b1 given by (6.1). Thus we obtain the following result.\nCorollary 1 Let F satisfy (2.8) and (2.9), let {\u03b1k } be a sequence of numbers satisfying (1.4),\nand let {x\u03b4k } be defined by (1.3) with g\u03b1 given by (6.1) for some fixed integer m \u2265 1. Let k\u03b4 be\nthe first integer satisfying (1.7) with \u03c4 > 1.\n(i) If F satisfies Assumption 3 and if x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208 X and 1/2 \u2264 \u03bd \u2264\nm \u2212 1/2, then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\n\nprovided Lkuk \u2264 \u03b70 , where u \u2208 N (F \u2032 (x\u2020 )\u2217 )\u22a5 \u2282 Y is the unique element such that x0 \u2212 x\u2020 =\nF \u2032 (x\u2020 )\u2217 u, \u03b70 > 0 is a constant depending only on r, \u03c4 and m, and C\u03bd > 0 is a constant depending\nonly on r, \u03c4 , m and \u03bd .\n(ii) Let F satisfy Assumption 5 and Assumption 6, and let x0 \u2212 x\u2020 \u2208 N(F \u2032 (x\u2020 ))\u22a5 . Then there\nexists a constant \u03b71 > 0 depending only on r, \u03c4 and m such that if (K0 + K1 + K2 )kx0 \u2212 x\u2020 k \u2264 \u03b71\nthen\nlim x\u03b4k\u03b4 = x\u2020 ,\n\u03b4 \u21920\n\nmoreover, when x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208 X and 0 < \u03bd \u2264 m \u2212 1/2, then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\n\nfor some constant C\u03bd > 0 depending only on r, \u03c4 , m and \u03bd ; while when x0 \u2212 x\u2020 satisfies (1.11)\nfor some \u03c9 \u2208 X and \u03bc > 0, then\n\u0013\u2212\u03bc\n\u0012\n\u03b4\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bc k\u03c9 k 1 + ln\nk\u03c9 k\n\nfor some constant C\u03bc depending only on r, \u03c4 , m and \u03bc .\n\nCorollary 1 with m = 1 reproduces those convergence results in [3,8] for the iteratively regularized Gauss-Newton method (1.8) together with the discrepancy principle (1.7) under somewhat different conditions on F. Note that those results in [3,8] require \u03c4 be sufficiently large,\nwhile our result is valid for any \u03c4 > 1. This less restrictive requirement on \u03c4 is important in numerical computations since the absolute error could increase with respect to \u03c4 . Moreover, when\nx0 \u2212 x\u2020 satisfies (1.10) with \u03bd = 1/2, Corollary 1 with m = 1 improves the corresponding result\nin [3], since we only need the Lipschitz condition on F \u2032 here.\nCorollary 1 shows that the method defined by (1.3) and (1.7) with g\u03b1 given by (6.1) is order optimal for 0 < \u03bd \u2264 m \u2212 1/2. However, we can not expect better rate of convergence than\nO(\u03b4 (2m\u22121)/(2m) ) even if x0 \u2212 x\u2020 satisfies (1.10) with m \u2212 1/2 < \u03bd \u2264 m. An a posteriori stopping\nrule without such saturation has been studied in [9,10] for the iteratively regularized GaussNewton method (1.8).\n\n\f31\n\n6.2 Example 2\nWe consider the function g\u03b1 given by\ng\u03b1 (\u03bb ) =\n\n[1/\u03b1 ]\n\n\u2211 (1 \u2212 \u03bb )i\n\n(6.4)\n\ni=0\n\nwhich arises from the Landweber iteration applying to linear ill-posed problems. With such\nchoice of g\u03b1 , the method (1.3) becomes\nx\u03b4k+1 = x0 \u2212\n\n[1/\u03b1k ] \u0010\n\n\u2211\n\ni=0\n\n\u0010\n\u0011i\n\u0011\nI \u2212 F \u2032 (x\u03b4k )\u2217 F \u2032 (x\u03b4k ) F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 \u2212 F \u2032 (x\u03b4k )(x\u03b4k \u2212 x0 )\n\nwhich is equivalent to the form\nx\u03b4k,0 = x0 ,\n\u0010\n\u0011\nx\u03b4k,i+1 = x\u03b4k,i \u2212 F \u2032 (x\u03b4k )\u2217 F(x\u03b4k ) \u2212 y\u03b4 + F \u2032 (x\u03b4k )(x\u03b4k,i \u2212 x\u03b4k ) ,\n\n0 \u2264 i \u2264 [1/\u03b1k ],\n\nx\u03b4k+1 = x\u03b4k,[1/\u03b1k ]+1 .\n\nThis method has been considered in [12] and is called the Newton-Landweber iteration.\nNote that the corresponding residual function is\nr\u03b1 (\u03bb ) = (1 \u2212 \u03bb )[1/\u03b1 ]+1.\n\n(6.5)\n\nIt is easy to see that Assumption 1(a), (b) and (2.1) hold with\n\u221a\n\u221a\n2\n1\nc0 = , c1 = 2, c3 =\nand c4 = 2.\n2\n3\nMoreover, by (6.2) we have for any 0 < \u03b1 \u2264 \u03b2 that\n\u0010\n\n[1/\u03b1 ]\u2212[1/\u03b2 ]\n\n\u0011\n\nr\u03b2 (\u03bb ) \u2212 r\u03b1 (\u03bb ) = r\u03b2 (\u03bb ) 1 \u2212 (1 \u2212 \u03bb )\n\n\u2264\n\nr\n\n\u03bb\nr (\u03bb ).\n\u03b1 \u03b2\n\nThis verifies Assumption 1(c) with c2 = 1. It is well-known that the qualification of linear\nLandweber iteration is \u03bd\u0304 = \u221e and (2.2) is satisfied with d\u03bd = \u03bd \u03bd for each 0 \u2264 \u03bd < \u221e.\nIn order to verify Assumption 2, we restrict the sequence {\u03b1k } to be of the form \u03b1k := 1/nk ,\nwhere {nk } is a sequence of positive integers such that\n0 \u2264 nk+1 \u2212 nk \u2264 q and\n\nlim nk = \u221e\n\nk\u2192\u221e\n\n(6.6)\n\nfor some q \u2265 1. Then for \u03bb \u2208 [0, 1/2] we have\n\nr\u03b1k (\u03bb ) = (1 \u2212 \u03bb )nk \u2212nk+1 r\u03b1k+1 (\u03bb ) \u2264 2q r\u03b1k+1 (\u03bb ).\n\nThus Assumption 2 is also true.\nIn order to verify Assumption 4, we will use some techniques from [7,12] and the following\nwell-known estimates\nk(I \u2212 A\u2217 A) j (A\u2217 A)\u03bd k \u2264 \u03bd \u03bd ( j + \u03bd )\u2212\u03bd ,\n\nj \u2265 0, \u03bd \u2265 0\n\n(6.7)\n\nfor any bounded linear operator A satisfying kAk \u2264 1.\nFor any \u03b1 > 0, we set k := [1/\u03b1 ]. Let A and B be any two bounded linear operators satisfying\nkAk, kBk \u2264 1. Then it follows from (6.5) that\nr\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B) =\n\nk\n\n\u2211 (I \u2212 A\u2217A) j [A\u2217 (B \u2212 A) + (B\u2217 \u2212 A\u2217)B] (I \u2212 B\u2217B)k\u2212 j .\n\nj=0\n\n(6.8)\n\n\f32\n\nBy using (6.7) we have\n\u0011\nk \u0010\nkr\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B)k . \u2211 ( j + 1)\u22121/2 + (k + 1 \u2212 j)\u22121/2 kA \u2212 Bk\nj=0\n\n\u221a\n1\n. kkA \u2212 Bk . \u221a kA \u2212 Bk.\n\u03b1\n\nThis verifies (2.11).\nFrom (6.8) we also have A [r\u03b1 (A\u2217 A) \u2212 r\u03b1 (B\u2217 B)] B\u2217 = J1 + J2 , where\nk\n\nJ1 :=\n\n\u2211 (I \u2212 AA\u2217) j AA\u2217 (B \u2212 A)(I \u2212 B\u2217B)k\u2212 j B\u2217 ,\n\nj=0\nk\n\nJ2 :=\n\n\u2211 A(I \u2212 A\u2217A) j (B\u2217 \u2212 A\u2217)(I \u2212 BB\u2217)k\u2212 j BB\u2217.\n\nj=0\n\nIn order to verify (2.13), it suffices to show kJ1 k . (k + 1)\u22121/2 kA \u2212 Bk since the estimate on J2\n(1)\n(2)\nis exactly the same. We write J1 = J1 + J2 , where\n[k/2]\n\n(1)\n\n\u2211 (I \u2212 AA\u2217) j AA\u2217(B \u2212 A)(I \u2212 B\u2217B)k\u2212 j B\u2217 ,\n\nJ1 :=\n\nj=0\n\nk\n\n\u2211\n\n(2)\n\nJ1 :=\n\n(I \u2212 AA\u2217) j AA\u2217 (B \u2212 A)(I \u2212 B\u2217 B)k\u2212 j B\u2217 .\n\nj=[k/2]+1\n\n(2)\n\nWith the help of (6.7), we can estimate J1 as\nk\n\n\u2211\n\n(2)\n\nkJ1 k .\n\n( j + 1)\u22121(k + j \u2212 1)\u22121/2kA \u2212 Bk\n\nj=[k/2]+1\n\nk\n\n. (k + 1)\u22121 \u2211 (k + 1 \u2212 j)\u22121/2kA \u2212 Bk . (k + 1)\u22121/2kA \u2212 Bk.\nj=0\n\n(1)\n\nIn order to estimate J1 , we use AA\u2217 = I \u2212 (I \u2212 AA\u2217) to rewrite it as\n(1)\n\n[k/2]\n\nJ1 =\n\n\u2211 (I \u2212 AA\u2217) j (B \u2212 A)(I \u2212 B\u2217B)k\u2212 j B\u2217\n\nj=0\n\n[k/2]+1\n\n\u2212\n\n\u2211\n\nj=1\n\n(I \u2212 AA\u2217 ) j (B \u2212 A)(I \u2212 B\u2217 B)k+1\u2212 j B\u2217\n\n=(B \u2212 A)(I \u2212 B\u2217 B)k B\u2217 \u2212 (I \u2212 AA\u2217)[k/2]+1 (B \u2212 A)(I \u2212 B\u2217 B)k\u2212[k/2] B\u2217\n[k/2]\n\n+\n\n\u2211 (I \u2212 AA\u2217) j (B \u2212 A)(I \u2212 B\u2217B)k\u2212 j (B\u2217 B)B\u2217 .\n\nj=1\n\nThus, in view of (6.7), we obtain\n(1)\n\nkJ1 k .(k + 1)\u22121/2kA \u2212 Bk + (k \u2212 [k/2] + 1)\u22121/2kA \u2212 Bk\n[k/2]\n\n+\n\n\u2211 (k \u2212 j + 1)\u22123/2kA \u2212 Bk\n\nj=1\n\n.(k + 1)\u22121/2kA \u2212 Bk.\n\n\f33\n\nWe thus verify (2.13). The verification of (2.12) can be done similarly.\nApplying the estimate (2.12), we obtain\nk [g\u03b1 (A\u2217 A) \u2212 g\u03b1 (B\u2217 B)] B\u2217 k \u2264\n\nk\n\n\u2211k\n\nj=1\n\n\u0002\n\n\u0003\n(I \u2212 A\u2217 A) j \u2212 (I \u2212 B\u2217 B) j B\u2217 k\n\n. kkA \u2212 Bk .\n\n1\nkA \u2212 Bk,\n\u03b1\n\nwhich verifies (2.14).\nFinally we verify Assumption 7 by assuming that F satisfies Assumption 5 and Assumption\n6. From (6.8) and Assumption 5 it follows that\nr\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 ) =\n\nk\n\n\u2211 (I \u2212 Fx\u2032\u2217 Fx\u2032 ) j Fx\u2032\u2217 Fx\u2032 (R(z, x) \u2212 I)(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j\n\nj=0\nk\n\n+ \u2211 (I \u2212 Fx\u2032\u2217 Fx\u2032 ) j (I \u2212 R(x, z))\u2217 Fz\u2032\u2217 Fz\u2032 (I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j .\nj=0\n\nThus we may use the argument in the verification of (2.13) to conclude\nkr\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 )k . kI \u2212 R(x, z)k + kI \u2212 R(z, x)k . K0 kx \u2212 zk.\nThis verifies (2.20).\nBy using (6.8) and Assumption 5 we also have for any w \u2208 X\n\nFx\u2032 [r\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 )]w = Q1 + Q2 + Q3 + Q4,\n\nwhere\n[k/2]\n\nQ1 =\n\n\u2211 (I \u2212 Fx\u2032 Fx\u2032\u2217 ) j (Fx\u2032 Fx\u2032\u2217)(Fz\u2032 \u2212 Fx\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j w,\n\nj=0\n\nk\n\nQ2 =\n\n\u2211\n\n(I \u2212 Fx\u2032 Fx\u2032\u2217 ) j (Fx\u2032 Fx\u2032\u2217 )(Fz\u2032 \u2212 Fx\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j w,\n\nj=[k/2]+1\n[k/2]\n\nQ3 =\n\n\u2211 (I \u2212 Fx\u2032 Fx\u2032\u2217 ) j Fx\u2032 (I \u2212 R(x, z))\u2217 (Fz\u2032\u2217 Fz\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j w,\n\nj=0\n\nk\n\nQ4 =\n\n\u2211\n\n(I \u2212 Fx\u2032 Fx\u2032\u2217 ) j Fx\u2032 (I \u2212 R(x, z))\u2217 (Fz\u2032\u2217 Fz\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j w.\n\nj=[k/2]+1\n\nBy employing (6.7) it is easy to see that\n[k/2]\n\nkQ3 k .\n\n\u2211 ( j + 1)\u22121/2(k \u2212 j + 1)\u22121kI \u2212 R(x, z)kkwk . (k + 1)\u22121/2K0 kx \u2212 zkkwk.\n\nj=0\n\nWith the help of (6.7) and Assumption 6, we have\nk\n\nkQ2 k .\n\n\u2211\n\n( j + 1)\u22121k(Fz\u2032 \u2212 Fx\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j wk\n\nj=[k/2]+1\n\nk\n\n. K1 kx \u2212 zk\n\n\u2211\n\nj=[k/2]+1\n\n+ K2 kFz\u2032 (x \u2212 z)k\n\u22121/2\n\n. (k + 1)\n\n( j + 1)\u22121 (k \u2212 j + 1)\u22121/2kwk\n\nk\n\n\u2211\n\n( j + 1)\u22121 kwk\n\nj=[k/2]+1\n\nK1 kx \u2212 zkkwk + K2kFz\u2032 (x \u2212 z)kkwk.\n\n\f34\n\nBy using the argument in the verification of (2.13) and Assumption 6 we obtain\nkQ1 k . k(Fz\u2032 \u2212 Fx\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k wk + k(Fz\u2032 \u2212 Fx\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212[k/2] wk\n[k/2]\n\n+\n\n\u2211 k(Fz\u2032 \u2212 Fx\u2032 )(I \u2212 Fz\u2032\u2217 Fz\u2032 )k\u2212 j (Fz\u2032\u2217Fz\u2032 )wk\n\nj=1\n\n. (k + 1)\u22121/2K1 kx \u2212 zkkwk + K2kFz\u2032 (x \u2212 z)kkwk\n[k/2] \u0010\n\u0011\n+ \u2211 K1 kx \u2212 zk(k \u2212 j + 1)\u22123/2 + K2 kFz\u2032 (x \u2212 z)k(k \u2212 j + 1)\u22121 kwk\nj=1\n\n. (k + 1)\u22121/2K1 kx \u2212 zkkwk + K2kFz\u2032 (x \u2212 z)kkwk.\n\nUsing Assumption 5 and the the similar argument in the verification of (2.13) we also have\nkQ4 k . (k + 1)\u22121/2kI \u2212 R(x, z)kkwk . (k + 1)\u22121/2K0 kx \u2212 zkkwk.\nCombining the above estimates we thus obtain for any w \u2208 X\nkFx\u2032 [r\u03b1 (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 (Fz\u2032\u2217 Fz\u2032 )]wk\n\n. (K0 + K1 )\u03b1 1/2 kx \u2212 zkkwk + K2kFz\u2032 (x \u2212 z)kkwk\n\nwhich implies (2.21).\nTherefore, Theorem 1, Theorem 2 and Theorem 3 are applicable for the method defined by\n(1.3) and (1.7) with g\u03b1 given by (6.4).\nThe similar argument as above also applies to the situation where g\u03b1 is given by\ng\u03b1 (\u03bb ) :=\n\n[1/\u03b1 ]\n\n\u2211 (1 + \u03bb )\u2212i\n\ni=0\n\nwhich arise from the Lardy's method for solving linear ill-posed problems.\nIn summary, we obtain the following result.\nCorollary 2 Let F satisfy (2.8) and (2.9), and let {\u03b1k } be a sequence given by \u03b1k = 1/nk , where\n{nk } is a sequence of positive integers satisfying (6.6) for some q \u2265 1. Let {x\u03b4k } be defined by\n(1.3) with\ng\u03b1 (\u03bb ) =\n\n[1/\u03b1 ]\n\n\u2211 (1 \u2212 \u03bb )i\n\nor\n\ni=0\n\ng\u03b1 (\u03bb ) =\n\n[1/\u03b1 ]\n\n\u2211 (1 + \u03bb )\u2212i,\n\ni=0\n\nand let k\u03b4 be the first integer satisfying (1.7) with \u03c4 > 1.\n(i) If F satisfies Assumption 3, and if x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208 X and \u03bd \u2265 1/2,\nthen\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\nprovided Lkuk \u2264 \u03b70 , where u \u2208 N (F \u2032 (x\u2020 )\u2217 )\u22a5 \u2282 Y is the unique element such that x0 \u2212 x\u2020 =\nF \u2032 (x\u2020 )\u2217 u, \u03b70 > 0 is a constant depending only on \u03c4 and q, and C\u03bd is a constant depending only\non \u03c4 , q and \u03bd .\n(ii) Let F satisfy Assumption 5 and Assumption 6, and let x0 \u2212 x\u2020 \u2208 N(F \u2032 (x\u2020 ))\u22a5 . Then there\nexists a constant \u03b71 > 0 depending only on \u03c4 and q such that if (K0 + K1 + K2 )kx0 \u2212 x\u2020 k \u2264 \u03b71\nthen\nlim x\u03b4k\u03b4 = x\u2020 ,\n\u03b4 \u21920\n\nmoreover, when x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208 X and \u03bd > 0, then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\n\n\f35\n\nfor some constant C\u03bd > 0 depending only on \u03c4 , q and \u03bd ; while when x0 \u2212 x\u2020 satisfies (1.11) for\nsome \u03c9 \u2208 X and \u03bc > 0, then\n\u0012\n\u0013\u2212\u03bc\n\u03b4\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bc k\u03c9 k 1 + ln\nk\u03c9 k\nfor some constant C\u03bc depending only on \u03c4 , q and \u03bc .\n\n6.3 Example 3\nAs the last example we consider the method (1.3) with g\u03b1 given by\ng\u03b1 (\u03bb ) =\n\n\u0011\n1\u0010\n1 \u2212 e\u2212 \u03bb / \u03b1\n\u03bb\n\n(6.9)\n\nwhich arises from the asymptotic regularization for linear ill-posed problems. In this method, the\niterated sequence {x\u03b4k } is equivalently defined as x\u03b4k+1 := x\u03b4 (1/\u03b1k ), where x\u03b4 (t) is the solution\nof the initial value problem\n\u0010\n\u0011\nd \u03b4\nx (t) = F \u2032 (x\u03b4k )\u2217 y\u03b4 \u2212 F(x\u03b4k ) + F \u2032 (x\u03b4k )(x\u03b4k \u2212 x\u03b4 (t)) ,\ndt\nx\u03b4 (0) = x0 .\n\nt > 0,\n\nNote that the corresponding residual function is\nr\u03b1 (\u03bb ) = e\u2212\u03bb /\u03b1 .\nIt is easy to see that Assumption 1(a), (b) and (2.1) hold with\nc0 = e\n\n\u22121\n\n,\n\nc1 = 1,\n\n1\nc3 = \u221a\n2e\n\nand c4 =\n\nr\n\n2\n.\ne\n\n\u221a\nt for t \u2265 0 we have for 0 < \u03b1 \u2264 \u03b2 that\ns\nr\n\u0011\n\u0010\n\u03bb \u03bb\n\u03bb\n\u03bb /\u03b2 \u2212\u03bb /\u03b1\n\u2264\n\u2212 r\u03b2 (\u03bb ) \u2264\nr (\u03bb ).\nr\u03b2 (\u03bb ) \u2212 r\u03b1 (\u03bb ) = r\u03b2 (\u03bb ) 1 \u2212 e\n\u03b1 \u03b2\n\u03b1 \u03b2\n\nBy using the inequality 1 \u2212 e\u2212t \u2264\n\nThis verifies Assumption 1(c) with c2 = 1. It is well-known that the qualification of the linear\nasymptotic regularization is \u03bd\u0304 = \u221e and (2.2) is satisfied with d\u03bd = (\u03bd /e)\u03bd for each 0 \u2264 \u03bd < \u221e.\nIn order to verify Assumption 2, we assume that {\u03b1k } is a sequence of positive numbers\nsatisfying\n1\n1\n\u2212\n\u2264 \u03b80 and lim \u03b1k = 0\n0\u2264\n(6.10)\nk\u2192\u221e\n\u03b1k+1 \u03b1k\nfor some \u03b80 > 0. Then for all \u03bb \u2208 [0, 1] we have\nr\u03b1k (\u03bb ) = e(1/\u03b1k+1 \u22121/\u03b1k )\u03bb r\u03b1k+1 (\u03bb ) \u2264 e\u03b80 r\u03b1k+1 (\u03bb ).\nThus Assumption 2 is also true.\nIn order to verify Assumption 4 and Assumption 7, we set for every integer n \u2265 1\n\u0012\n\u0013\n\u0012\n\u0013 !\n1\n\u03bb \u2212n\n\u03bb \u2212n\nr\u03b1 ,n (\u03bb ) := 1 +\n1\u2212 1+\n.\n,\ng\u03b1 ,n (\u03bb ) :=\nn\u03b1\n\u03bb\nn\u03b1\n\n\f36\n\nNote that, for each fixed \u03b1 > 0, {r\u03b1 ,n } and {g\u03b1 ,n} are uniformly bounded over [0, 1], and\nr\u03b1 ,n (\u03bb ) \u2192 r\u03b1 (\u03bb ) and g\u03b1 ,n (\u03bb ) \u2192 g\u03b1 (\u03bb ) as n \u2192 \u221e. By the dominated convergence theorem, we\nhave for any bounded linear operator A with kAk \u2264 1 that\nlim k[r\u03b1 (A\u2217 A) \u2212 r\u03b1 ,n (A\u2217 A)]xk2\n\nn\u2192\u221e\n\n= lim\n\nZ kAk2\n\nn\u2192\u221e 0\n\n(r\u03b1 (\u03bb ) \u2212 r\u03b1 ,n (\u03bb ))2 d(E\u03bb x, x) = 0\n\nand\nlim k[g\u03b1 (A\u2217 A) \u2212 g\u03b1 ,n(A\u2217 A)]xk2\n\nn\u2192\u221e\n\n= lim\n\nZ kAk2\n\nn\u2192\u221e 0\n\n(g\u03b1 (\u03bb ) \u2212 g\u03b1 ,n(\u03bb ))2 d(E\u03bb x, x) = 0\n\nfor any x \u2208 X, where {E\u03bb } denotes the spectral family generated by A\u2217 A. Thus it suffices to\nverify Assumption 4 and Assumption 7 with g\u03b1 and r\u03b1 replaced by g\u03b1 ,n and r\u03b1 ,n with uniform\nconstants c6 , c7 and c8 independent of n. Let A and B be any two bounded linear operators\nsatisfying kAk, kBk \u2264 1. We need the following inequality which says for any integer n \u2265 1 there\nholds\nkr\u03b1 ,n (A\u2217 A)(A\u2217 A)\u03bd k \u2264 \u03bd \u03bd \u03b1 \u03bd ,\n0 \u2264 \u03bd \u2264 n.\n(6.11)\nBy noting that\nr\u03b1 ,n (A\u2217 A) \u2212 r\u03b1 ,n(B\u2217 B)\n=\n\n1\nn\u03b1\n\nn\n\n\u2211 r\u03b1 ,i (A\u2217 A) [A\u2217 (B \u2212 A) + (B\u2217 \u2212 A\u2217)B] r\u03b1 ,n+1\u2212i(B\u2217 B),\n\n(6.12)\n\ni=1\n\nwe thus obtain\n\nr\n\n2\nkA \u2212 Bk,\n\u03b1\n3\nk[r\u03b1 ,n (A\u2217 A) \u2212 r\u03b1 ,n(B\u2217 B)]B\u2217 k \u2264 kA \u2212 Bk\n2\n\u2217\n\n\u2217\n\nkr\u03b1 ,n (A A) \u2212 r\u03b1 ,n (B B)k \u2264\n\nand\nkA[r\u03b1 ,n (A\u2217 A) \u2212 r\u03b1 ,n (B\u2217 B)]B\u2217 k \u2264\n\nFurthermore, by noting that g\u03b1 ,n (\u03bb ) =\n\n1\nn\u03b1\n\n(6.13)\n\n\u221a\n2\u03b1 kA \u2212 Bk.\n\n\u2211ni=1 r\u03b1 ,i (\u03bb ), we may use (6.13) to conclude\n\nk[g\u03b1 ,n (A\u2217 A) \u2212 g\u03b1 ,n(B\u2217 B)]B\u2217 k \u2264\n\n1\nn\u03b1\n\nn\n\n\u2211 k[r\u03b1 ,i (A\u2217 A) \u2212 r\u03b1 ,i(B\u2217 B)]B\u2217k\n\ni=1\n\n3\nkA \u2212 Bk.\n\u2264\n2\u03b1\nAssumption 4 is therefore verified.\nIt remains to verify Assumption 7 with g\u03b1 and r\u03b1 replaced by g\u03b1 ,n and r\u03b1 ,n with uniform\nconstants c7 and c8 independent of n. By using (6.12), Assumption 5 and (6.11) we have\nkr\u03b1 ,n (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 ,n (Fz\u2032\u2217 Fz\u2032 )k\n\u2264\n\n1\nn\u03b1\n\n+\n\n1\nn\u03b1\n\nn\n\n\u2211 kr\u03b1 ,i (Fx\u2032\u2217 Fx\u2032 )(Fx\u2032\u2217Fx\u2032 )(R(z, x) \u2212 I)r\u03b1 ,n+1\u2212i(Fz\u2032\u2217 Fz\u2032 )k\n\ni=1\nn\n\n\u2211 kr\u03b1 ,i (Fx\u2032\u2217 Fx\u2032 )(I \u2212 R(x, z))\u2217 (Fz\u2032\u2217 Fz\u2032 )r\u03b1 ,n+1\u2212i(Fz\u2032\u2217 Fz\u2032 )k\n\ni=1\n\n\u2264 kI \u2212 R(z, x)k + kI \u2212 R(x, z)k\n\n\u2264 2K0 kx \u2212 zk.\n\n\f37\n\nThis implies (2.20).\nBy using (6.12), Assumption 6 and (6.11) we also have for any a \u2208 X and b \u2208 Y satisfying\nkak = kbk = 1 that\n(Fx\u2032 [r\u03b1 ,n (Fx\u2032\u2217 Fx\u2032 ) \u2212 r\u03b1 ,n (Fz\u2032\u2217 Fz\u2032 )]a, b)\n\u2264\n\n1\nn\u03b1\n\nn\n\n\u2211 |(r\u03b1 ,i (Fx\u2032 Fx\u2032\u2217 )(Fx\u2032 Fx\u2032\u2217 )(Fz\u2032 \u2212 Fx\u2032 )r\u03b1 ,n+1\u2212i (Fz\u2032\u2217Fz\u2032 )a, b)|\n\ni=1\n\n1 n\n+\n\u2211 |(a, r\u03b1 ,n+1\u2212i (Fz\u2032\u2217 Fz\u2032 )Fz\u2032\u2217 (Fz\u2032 \u2212 Fx\u2032 )Fx\u2032\u2217 r\u03b1 ,i (Fx\u2032 Fx\u2032\u2217)b)|\nn\u03b1 i=1\n\u221a\n1\n\u2264 2K1 \u03b1 1/2 kx \u2212 zk + K2kFz\u2032 (x \u2212 z)k + K2 kFx\u2032 (x \u2212 z)k.\n2\nThis implies (2.21).\nTherefore, we may apply Theorem 1, Theorem 2 and Theorem 3 to conclude the following\nresult.\nCorollary 3 Let F satisfy (2.8) and (2.9), and let {\u03b1k } be a sequence of positive numbers satisfying (6.10) for some \u03b80 > 0. Let {x\u03b4k } be defined by (1.3) with g\u03b1 given by (6.9) and let k\u03b4 be\nthe first integer satisfying (1.7) with \u03c4 > 1.\n(i) If F satisfies Assumption 3, and if x0 \u2212 x\u2020 satisfies (1.10) for some \u03c9 \u2208 X and \u03bd \u2265 1/2,\nthen\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\nprovided Lkuk \u2264 \u03b70 , where u \u2208 N (F \u2032 (x\u2020 )\u2217 )\u22a5 \u2282 Y is the unique element such that x0 \u2212 x\u2020 =\nF \u2032 (x\u2020 )\u2217 u, \u03b70 > 0 is a constant depending only on \u03c4 , \u03b80 and \u03b10 , and C\u03bd is a constant depending\nonly on \u03c4 , \u03b80 , \u03b10 and \u03bd .\n(ii) Let F satisfy Assumption 5 and Assumption 6, and let x0 \u2212 x\u2020 \u2208 N(F \u2032 (x\u2020 ))\u22a5 . Then there\nexists a constant \u03b71 > 0 depending only on \u03c4 , \u03b80 and \u03b10 such that if (K0 + K1 + K2 )kx0 \u2212 x\u2020 k \u2264 \u03b71\nthen\nlim x\u03b4k\u03b4 = x\u2020 ;\n\u03b4 \u21920\n\nmoreover, when x0\n\n\u2212 x\u2020\n\nsatisfies (1.10) for some \u03c9 \u2208 X and \u03bd > 0, then\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bd k\u03c9 k1/(1+2\u03bd )\u03b4 2\u03bd /(1+2\u03bd )\n\nfor some constant C\u03bd > 0 depending only on \u03c4 , \u03b80 , \u03b10 and \u03bd ; while when x0 \u2212 x\u2020 satisfies (1.11)\nfor some \u03c9 \u2208 X and \u03bc > 0, then\n\u0012\n\u0013\u2212\u03bc\n\u03b4\nkx\u03b4k\u03b4 \u2212 x\u2020 k \u2264 C\u03bc k\u03c9 k 1 + ln\nk\u03c9 k\nfor some constant C\u03bc depending only on \u03c4 , \u03b80 , \u03b10 and \u03bc .\n\nAcknowledgements The authors wish to thank the referee for careful reading of the manuscript and useful comments.\n\nReferences\n1. A. B. Bakushinskii, The problems of the convergence of the iteratively regularized Gauss-Newton method, Comput.\nMath. Math. Phys., 32(1992), 1353\u20131359.\n2. F. Bauer and T. Hohage, A Lepskij-type stopping rule for regularized Newton methods, Inverse Problems, 21(2005),\n1975\u20131991.\n3. B. Blaschke, A. Neubauer and O. Scherzer, On convergence rates for the iteratively regularized Gauss-Newton\nmethod, IMA J. Numer. Anal., 17(1997), 421\u2013436.\n4. P. Deuflhard, H. W. Engl and O. Scherzer, A convergence analysis of iterative methods for the solution of nonlinear\nill-posed problems under affinely invariant conditions, Inverse Problems, 14 (1998), no. 5, 1081\u20131106.\n\n\f38\n5. M. Hanke, A regularizing Levenberg-Marquardt scheme with applications to inverse groundwater filtration problems, Inverse Problems, 13(1997), 79\u201395.\n6. M. Hanke, Regularizing properties of a truncated Newton-CG algorithm for nonlinear inverse problems, Numer.\nFunct. Anal. Optim., 18(1997), 971\u2013993.\n7. M. Hanke, A. Neubauer and O. Scherzer, A convergence analysis of Landweber iteration of nonlinear ill-posed\nproblems, Numer. Math., 72(1995), 21\u201337.\n8. T. Hohage, Logarithmic convergence rates of the iteratively regularized Gauss-Newton method for an inverse\npotential and an inverse scattering problem, Inverse Problems, 13 (1997), no. 5, 1279\u20131299.\n9. Q. N. Jin, On the iteratively regularized Gauss-Newton method for solving nonlinear ill-posed problems, Math.\nComp., 69 (2000), no. 232, 1603\u20131623.\n10. Q. N. Jin, A convergence analysis of the iteratively regularized Gauss-Newton method under the Lipschitz condition, Inverse Problems, 24(2008), no. 4, to appear.\n11. Q. N. Jin and Z. Y. Hou, On an a posteriori parameter choice strategy for Tikhonov regularization of nonlinear\nill-posed problems, Numer. Math., 83(1999), no. 1, 139\u2013159.\n12. B. Kaltenbacher, Some Newton-type methods for the regularization of nonlinear illposed problems, Inverse Problems, 13(1997), 729\u2013753.\n13. B. Kaltenbacher, A posteriori choice strategies for some Newton type methods for the regularization of nonlinear\nill-posed problems, Numer. Math., 79 (1998), 501-528.\n14. B. Kaltenbacher, A. Neubauer and O. Scherzer, Iterative Regularization Methods for Nonlinear Ill-Posed Problems,\nBerlin, de Gruyter, 2008.\n15. A. Rieder, On the regularization of nonlinear ill-posed problems via inexact Newton iterations, Inverse Problems,\n15(1999), 309\u2013327.\n16. A. Rieder, On convergence rates of inexact Newton regularizations, Numer. Math., 88(2001), 347\u2013365.\n17. O. Scherzer, H. W. Engl and K. Kunisch, Optimal a posteriori parameter choice for Tikhonov regularization for\nsolving nonlinear ill-posed problems, SIAM J. Numer. Anal., 30(1993), 1796\u20131838.\n18. U. Tautenhahn, On a general regularization scheme for nonlinear ill-posed problems, Inverse Problems, 13 (1997),\nno. 5, 1427\u20131437.\n19. U. Tautenhahn and Q. N. Jin, Tikhonov regularization and a posteriori rules for solving nonlinear ill posed problems, Inverse Problems, 19 (2003), no. 1, 1\u201321.\n20. G. M. Vainikko and A. Y. Veretennikov, Iteration Procedures in Ill-Posed Problems, Moscow, Nauka, 1986 (In\nRussian).\n\n\f"}