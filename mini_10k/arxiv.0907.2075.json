{"id": "http://arxiv.org/abs/0907.2075v1", "guidislink": true, "updated": "2009-07-12T22:39:34Z", "updated_parsed": [2009, 7, 12, 22, 39, 34, 6, 193, 0], "published": "2009-07-12T22:39:34Z", "published_parsed": [2009, 7, 12, 22, 39, 34, 6, 193, 0], "title": "Multiresolution Elastic Medical Image Registration in Standard Intensity\n  Scale", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0907.3131%2C0907.4526%2C0907.0352%2C0907.1916%2C0907.2232%2C0907.3374%2C0907.4544%2C0907.4465%2C0907.1468%2C0907.4785%2C0907.0727%2C0907.4921%2C0907.2162%2C0907.2466%2C0907.3586%2C0907.2297%2C0907.3716%2C0907.4724%2C0907.4717%2C0907.2354%2C0907.3937%2C0907.3803%2C0907.5055%2C0907.4349%2C0907.3350%2C0907.3917%2C0907.0117%2C0907.3196%2C0907.2345%2C0907.2676%2C0907.2939%2C0907.5428%2C0907.1014%2C0907.1106%2C0907.0805%2C0907.1416%2C0907.1202%2C0907.3475%2C0907.2995%2C0907.0490%2C0907.2993%2C0907.3866%2C0907.4829%2C0907.2891%2C0907.3880%2C0907.2991%2C0907.0242%2C0907.4586%2C0907.1950%2C0907.5355%2C0907.2075%2C0907.3010%2C0907.1288%2C0907.4888%2C0907.3327%2C0907.5429%2C0907.1415%2C0907.0630%2C0907.3953%2C0907.0240%2C0907.1080%2C0907.2296%2C0907.2624%2C0907.3798%2C0907.4357%2C0907.1955%2C0907.2119%2C0907.4229%2C0907.3817%2C0907.1560%2C0907.3497%2C0907.0119%2C0907.0550%2C0907.4577%2C0907.2376%2C0907.1695%2C0907.2426%2C0907.3155%2C0907.1526%2C0907.0085%2C0907.0443%2C0907.1181%2C0907.0259%2C0907.1884%2C0907.2148%2C0907.0373%2C0907.1886%2C0907.0061%2C0907.2215%2C0907.5154%2C0907.4768%2C0907.1700%2C0907.2237%2C0907.1268%2C0907.3162%2C0907.1655%2C0907.1763%2C0907.4144%2C0907.4982%2C0907.2863%2C0907.1922&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Multiresolution Elastic Medical Image Registration in Standard Intensity\n  Scale"}, "summary": "Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0907.3131%2C0907.4526%2C0907.0352%2C0907.1916%2C0907.2232%2C0907.3374%2C0907.4544%2C0907.4465%2C0907.1468%2C0907.4785%2C0907.0727%2C0907.4921%2C0907.2162%2C0907.2466%2C0907.3586%2C0907.2297%2C0907.3716%2C0907.4724%2C0907.4717%2C0907.2354%2C0907.3937%2C0907.3803%2C0907.5055%2C0907.4349%2C0907.3350%2C0907.3917%2C0907.0117%2C0907.3196%2C0907.2345%2C0907.2676%2C0907.2939%2C0907.5428%2C0907.1014%2C0907.1106%2C0907.0805%2C0907.1416%2C0907.1202%2C0907.3475%2C0907.2995%2C0907.0490%2C0907.2993%2C0907.3866%2C0907.4829%2C0907.2891%2C0907.3880%2C0907.2991%2C0907.0242%2C0907.4586%2C0907.1950%2C0907.5355%2C0907.2075%2C0907.3010%2C0907.1288%2C0907.4888%2C0907.3327%2C0907.5429%2C0907.1415%2C0907.0630%2C0907.3953%2C0907.0240%2C0907.1080%2C0907.2296%2C0907.2624%2C0907.3798%2C0907.4357%2C0907.1955%2C0907.2119%2C0907.4229%2C0907.3817%2C0907.1560%2C0907.3497%2C0907.0119%2C0907.0550%2C0907.4577%2C0907.2376%2C0907.1695%2C0907.2426%2C0907.3155%2C0907.1526%2C0907.0085%2C0907.0443%2C0907.1181%2C0907.0259%2C0907.1884%2C0907.2148%2C0907.0373%2C0907.1886%2C0907.0061%2C0907.2215%2C0907.5154%2C0907.4768%2C0907.1700%2C0907.2237%2C0907.1268%2C0907.3162%2C0907.1655%2C0907.1763%2C0907.4144%2C0907.4982%2C0907.2863%2C0907.1922&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images."}, "authors": ["Ulas Bagci", "Li Bai"], "author_detail": {"name": "Li Bai"}, "author": "Li Bai", "arxiv_comment": "IEEE Sibgrapi 2007 submission", "links": [{"href": "http://arxiv.org/abs/0907.2075v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0907.2075v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0907.2075v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0907.2075v1", "journal_reference": "IEEE 20th Brazilian Symposium on Computer Graphics and Image\n  Processing (SIBGRAPI-07), Belo Horizonte-Minas Gerais, Brasil, October 7-10,\n  2007", "doi": null, "fulltext": "arXiv:0907.2075v1 [cs.CV] 12 Jul 2009\n\nMultiresolution Elastic Medical Image Registration in Standard Intensity Scale\nUla\u015f Ba\u011fc\u0131\nThe University of Nottingham\nCollaborative Medical Image Analysis Group\nJubilee Campus, NG8 1BB, UK\nuxb@cs.nott.ac.uk\n\nAbstract\nMedical image registration is a difficult problem. Not\nonly a registration algorithm needs to capture both large\nand small scale image deformations, it also has to deal with\nglobal and local image intensity variations. In this paper\nwe describe a new multiresolution elastic image registration\nmethod that challenges these difficulties in image registration. To capture large and small scale image deformations,\nwe use both global and local affine transformation algorithms. To address global and local image intensity variations, we apply an image intensity standardization algorithm to correct image intensity variations. This transforms\nimage intensities into a standard intensity scale, which allows highly accurate registration of medical images.\n\n1 Introduction\nImage registration is important in many imaging applications. For example, in diagnostic imaging, there is often\na need for comparing two images for disease diagnosis or\nlongitudinal studies. There is also a frequent need for registering two images of different imaging modalities, e.g., MR\nand PET images.\nImage registration involves the development of a reasonable transformation between a pair of images, the source\nand target, such that the similarity between the transformed\nsource image (registered source) and target image is optimum. The similarity measure should capture both large and\nsmall scale deformations (also known as displacements),\ntogether with global and local variations of image intensities. Based on the nature of the transformation, registration\nmethods can be categorized as rigid, affine and elastic. In\nrigid registration, the transformation includes global rotation and/or translation parameters. For Affine registration\nin particular, scaling parameters are also included. Registration is considered elastic(deformable) if the transformation\nis able to express both global and local deformations. For\n\nLi Bai\nThe University of Nottingham\nCollaborative Medical Image Analysis Group\nJubilee Campus, NG8 1BB, UK\nbai@cs.nott.ac.uk\n\nsurveys of image registration including nonlinear medical\nimage registration, see [20, 13, 12, 8, 18, 1, 14].\nAlthough rigid and affine transformations are able to\nalign images, they can only handle global deformations. In\nrigid registration, the recovered transformation itself has no\nclinical significance, however, in nonrigid registration the\nrecovered transformation may have clinical significance [8].\nSince motion and deformation characteristics are necessary\nfor quantification of changes between images, transformation should be found as accurate as possible. Except for\na few studies [15, 19, 16, 10], most of the elastic deformations based nonrigid registrations rely on the assumption that image intensities remain constant between images [2, 3, 12, 18], which is not always true and affects\nthe accuracy of motion and deformations obtained from the\ntransformation.\nTo address this problem, a locally affine but globally\nsmooth transformation model has been developed in the\npresence of intensity variations in [15]. In addition to 6\nand 12 affine parameters for 2D and 3D registrations respectively, two more affine parameters are used to capture intensity variations during registration. In order to remove inefficiency and inaccuracy arising from certain circumstances,\nsuch as low-resolution images, Bayesian based importance\nsampling technique with the same spatially varying parameters are used in [19]. In [16], voxel based similarity measures, such as normalized mutual information, are combined with B-spline based nonrigid transformation called\nfree-form deformation (FFD). Since the intensity and contrast between the pre- and post-contrast enchanced images\nvary, voxel based similarity measures are used because it\nis insensitive to intensity changes as a result of contrast\nenchancement. However, there is a trade-off between accuracy and computation time of FFD-based method. The\nlocal flexibility and computational complexity of the local\nmotion model is related to the resolution of B-spline control points. More control points may improve the registration accuracy, but the computation time will also increase\ndramatically [6]. In [10], a fast elastic multidimensional\n\n\fintensity-based image registration with a parametric model\nof deformation is presented. Although adding landmarks\ncontrols the smoothness of deformation field and using a\nmultiresolution approach for both the image and the deformation model makes registration algorithm robust and fast,\nglobal solution of the optimization function cannot be guaranteed due to manual identification of landmarks.\nIn this paper, we present a multiresolution elastic image\nregistration framework on images in the standard intensity\nscale. The standard intensity scale is obtained by a standardisation procedure which corrects image intensity variations [4]. In the standard scale, similar intensities will mean\nsimilar tissue properties.\nThe paper is organised as follows: a detailed description\nof elastic registration used in this study is given in Section 2.\nA brief explanation of intensity standardization method is\npresented in Section 3. Multiresolution framework is explained in Section 4. Experiments and promising results are\ngiven in Section 5 and concluding remarks in Section 6.\n\nwhere D denotes a small spatial neighborhood. From a Taylor expansion of Eq (3), we obtain linear quadratic error\nfunction to be minimized:\n\u00112\nX\u0010\nft \u2212 (f~T .[A \u2212 I]).~v\nE(A) \u2248\n~\nv \u2208D\n\nX\u0010\n\n\u2248\n\n~\nv \u2208D\n\nwhere I is 3x3 identity matrix, f~ = [fx\nfx = fx (~v , t)\n\nfy = fy (~v , t)\n\n\u0014\n\nF (~v , t)\n1\n\n\u0015\n\n= F (~v \u2217 , t \u2212 1) = F (A.~v , t \u2212 1)\n\nIn general notation of affine transformation, a7 and a8 controls the intensity variations between image pairs. In proposed registration algorithm since possible variations in intensities are captured by standardization method, Eq (1) is\nminimized by setting a7 = 1 and a8 = 0 respectively. A\nsimple way to estimate affine matrix parameters is to minimize quadratic error function E(A) which can be defined\nas:\nX\n\n~\nv \u2208D\n\nft ]T and\n\nft = ft (~v , t)\n\n(5)\n\nx,y\u2208D\n\n(6)\n\n(1)\nwhere t is the time, a7 and a8 are parameters describing\nintensity variations between source and target images and\nA is affine transform matrix defined as:\n\uf8ee\n\uf8f9\na1 a2 a3\nA = \uf8f0 a4 a5 a6 \uf8fb\n(2)\n0 0 1\n\nE(A) \u2248\n\nfy\n\n(4)\n\n+y.fy .a5 + fy .a6 \u2212 f T .~v )2\n\nFor 2D image registration, an affine transformation has\nsix parameters, which can be determined if the coordinates\nof at least three non-colinear corresponding points in the\nimages are known [5]. As ~v = [x y 1]T represents the\nhomogeneous spatial coordinates, let F (~v , t) and F (~v \u2217 , t \u2212\n1) be the source and target images respectively. General\naffine transformation between source and target image can\nbe modelled locally as:\n\na8 ] .\n\n\u00112\n\nare partial derivatives of image F on D. Open expression\nfor the gradient based constraint equation (4) can be expressed further as:\nX\nE(~a) =\n(x.fx .a1 + y.fx .a2 + fx .a3 + x.fy .a4\n\n2 Local Affine Transformation\n\n[a7\n\nft \u2212 f~T .A.~v + f~T .~v\n\n2\n\n[F (~v , t) \u2212 F (A.~v , t \u2212 1)]\n\n(3)\n\nwhere ~a = [a1 a2 a3 a4 a5 a6 ]T .\nMore\n~\ncompact form can be obtained by defining \u03a9 =\n[x.fx y.fx fx x.fy y.fy , fy ]T as in [15]:\nE(~a) =\n\nX\n\n~ T .~a \u2212 f T .~v ]2\n[\u03a9\n\n(7)\n\nx,y\u2208D\n\nQuadratic error function in Eq (7) can be minimized analytically by differentiating it with respect to the unknown\nparameters ~a\nh\ni\nX\n~ \u03a9\n~ T .~a \u2212 f T .~v\ndE(~a)/d~a =\n2\u03a9\n(8)\nx,y\u2208D\n\nSetting Eq (8) equal to zero and solving for ~a parameters\nyields:\n\uf8ee\n\n~a = \uf8f0\n\nX\n\nx,y\u2208D\n\n\uf8f9\u22121 \uf8ee\n\n~\u03a9\n~T\uf8fb\n\u03a9\n\n\uf8f0\n\nX\n\nx,y\u2208D\n\n\uf8f9\n\n~ T .~v \uf8fb\n\u03a9f\n\n(9)\n\nSince the velocity field at each image point has two components while the changes in image brightness at a point in the\nimage plane due to motion yields only one constraint, the\noptical flow cannot be computed at a point in the image independently of neighboring points without introducing additional constraints [9]. This additional constraint is based\non the smoothness of parameters over domain D such that\nneighboring points on the domain D have similar velocities\nand the velocity field of the brightness patterns in the image\nvaries smoothly almost everywhere. One way to express\n\n\fthis additional constraint is to minimize the magnitude of\nthe gradient of the optical flow velocity, which is:\n\"\u0012\n\u00132 \u0012\n\u00132 #\n6\nX\n\u2202ai\n\u2202ai\n\u03bbi\n(10)\n+\nEsmooth (~a) =\n\u2202x\n\u2202y\ni=1\n\nFigure 1. Location of the histogram specific landmarks, m1 =minimum gray value,\nm2 =maximum gray value\n\nwhere magnitude of \u03bbi reflects the influence of smoothness\nterm. Hence, the problem is to minimize the sum of the\nerrors in the equation (7) and (10). To obtain local affine\nparameters ~ai , we can differentiate Etotal (~a) = E(~a) +\nEsmooth (~a) and set the result to be zero [9]. Solution for\nthe ~a is [19]:\n\u0010\n\u0011\n\u0011\u22121 \u0010\n~ \u03a9\n~T +\u039b\n~ f~T .~v + \u039b.~anp\n~an+1 = \u03a9.\n(11)\n\u03a9.\n\nwhere \u039b is 6x6 diagonal matrix with elements \u03bbi , and ~anp is\nthe component-wise average of ~a over domain D. Starting\nwith the initial guess (~a0 ) 1 , at each step the next local\naffine paramters are computed and resultant system of linear\nequations are solved accordingly.\n\n3 Standardization of MR Image Intensity\nScale\nSince MR image intensities do not have a fixed tissue\nmeaning in image scale even within the same protocol, for\nthe same body region, for images obtained on the same\nscanner, for the same patient, there is a strong need to transform image scale into standard intensity scale in order so\nthat for the same MR protocol and body region, similar intensities will have similar tissue meaning [4].\nStandardization is based on mapping image intensity histograms into a standard histogram. The method consists of\ntwo steps called training and transformation. In the training\nstep, a set of images of the same body region are given as\ninput to \"learn\" histogram-specific parameters, called landmarks. In the transformation step, any given image is standardized with estimated histogram-specific landmarks obtained from the training step.\n\n3.1\n\nMethods\n\nBased on the study [11], image histograms of the same\nbody region are always of the same type. There are different types of histograms, unimodal, bimodal and generalization of both. Since most of the protocols studied in [11]\nproduce bimodal histograms, bimodal histogram distribution is used to extract histogram specific landmarks. In bimodal histograms, one of the histogram specific landmarks\nis mode(\u03bc) representing main foreground object in the image, as depicted in Figure 1.\n1~\na0\n\ncan be obtained through the same equation by putting \u039b =\nnull, [15]\n\n\u03bc\n\nm1 p1\n\np2\n\nm2\n\nBimodal\n\nOther histogram specific landmarks denoted by p1 and\np2 are extracted according to range of intensity of interest\n(IOI). Landmarks p1 and p2 are defined according to minimum and maximum percentile values, pc1 and pc2 , that are\nused to select IOI.\nIn the training step, for image j, the landmarks p1j ,\np2j and \u03bcj obtained from the histogram of each image are\nmapped to the standard scale by mapping intensities from\n[p1j , p2j ] to [s1 , s2 ] where s1 and s2 are minimum and maximum intensities on the standard scale respectively. The formula for mapping x \u2208 [p1j , p2j ] to x\u2032 is the following [11].\nx\u2032 = s1 +\n\nx \u2212 p1j\n(s2 \u2212 s1 )\np2j \u2212 p1j\n\n(12)\n\nFigure 2 shows two separate linear mappings, the first\nfrom [p1i , \u03bci ] to [s1 , \u03bcs ] and the second from [\u03bci , p2i ]\nto [\u03bcs , s2 ]. Overall mapping, \u03c4i (x), from [m1i , m2i ] to\n[s\u20321i , s\u20322i ] can be summarized as follows:\n\uf8f1\n\u0010\n\u0011\n\uf8f2 \u2308\u03bcs + (x \u2212 \u03bci ) s1 \u2212\u03bcs \u2309\n\u0010 p1i \u2212\u03bci \u0011\n\u03c4i (x) =\n\uf8f3 \u2308\u03bcs + (x \u2212 \u03bci ) s2 \u2212\u03bcs \u2309\np2i \u2212\u03bci\n\nif m1i \u2264 x \u2264 \u03bci\n\nif \u03bci \u2264 x \u2264 m2i\n(13)\nwhere \u2308.\u2309 converts any number y\u2208 R into closest integer\nY such that Y \u2265 y or \u2264 y. Further details can be found\nin [11].\n\n3.2\n\nChoosing the Standardization Parameters\n\nBased on the experiments in [11, 4], minimum and maximum percentile values are set to pc1 = 0 and pc2 = 99.8 respectively. On the standard scale, s1 and s2 are set to s1 = 1\n\n\fFigure 2. The intensity mapping function for\nthe transformation step\n\nFigure 3. Histograms before and after standardization\n9000\n\ns2'i\n\ntarget\nsource\n\n8000\n\ns2\n7000\n\nstandard\nscale\n\n6000\n5000\n\n\u03bcs\n\n4000\n3000\n\ns1\n\n2000\n1000\n\ns1'i\nm1i\n\np1i\n\n\u03bci\n\np2i m2i\n\n0\n\n0\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\nimage\nscale\n9000\nsource\ntarget\n\n8000\n\nand s2 = 4095. Figure 3 shows the histograms before intensity mapping and after intensity mapping respectively. It\nis easily seen that histograms are more similar in shape, location and distribution after standardization than before. It\nmeans that intensities have tissue-specific meaning after the\nstandardization.\nImages in the first row of Figure 4 shows a source and\ntarget images in image scale. In the second row on the same\nfigure, the same slices are displayed after standardization\nusing the parameters defined above.\n\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n5000\n\n6000\n\n4 Multiresolution\nImage registration can be highly nonlinear and therefore\nmany iterations may be required to reach a solution.\nAn important method to reduce the amount of computational cost and deal with nonlinearities is to use a\nmultilevel(multiresolution) image pyramid. Multilevel\ncontinuation is well established for optimization problems\nand systems of non-linear equations [7]. As common to\nmany other nonrigid registration algorithms, the registration method we use includes two steps. After global\nregistration has been done in the first step, locally affine\nglobally smooth elastic registration on standard scale is\nperformed. In order to achieve low computational cost and\naccelerate the registration process, coarse-to-fine strategy\nis used. Global affine registration is first performed at\nthe coarsest level where convergence is fast because there\nare few data. The initial condition at the coarsest scale is\narbitrary. Moreover, it is likely that the criterion to optimize\nhas a reduced number of local optima; this is due to a loss\nof image details and results in enhanced robustness [17].\n\nAs seen from Figure 5, registration in finer level is performed with the result of the previous level as initial condition. This process continues until the finest level is reached.\nSince the number of iterations performed at the finest level\nis more relevant than the other levels, for the computational\ncost of the whole optimization, it is very important that the\ninitial condition for this last level be the best possible in order to reduce the amount of refinement necessary to reach\nconvergence. To get optimal starting conditions, it is crucial that the coarse levels of the pyramid most represent the\nfinest level [17]. In addition to this, the use of interpolation\nmodels (except linear interpolation) will change the intensity histogram of image after each warping. Available interpolation methods vary in their computational complexity,\nspeed and accuracy. To ensure a more accurate solution, we\nperform standardization after each warping/interpolation.\nEither small or large, intensity changes caused by the interpolation are captured by standardization.\n\n\fFigure 4. images in non-standard(1st row)\nand standard scale(2nd row)\n\nFigure\n5.\nCoarsest-to-Finest\nRepresentation-Gaussian Pyramid\n\nImage\n\n111111111\n000000000\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\ninitialization\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\nCoarsest Level\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n0000000\n1111111\n000000000\n111111111\n0000000\n1111111\n000000000\n111111111\n0000000\n1111111\n000000000\n111111111\n000000000\n111111111\ninput to\n000000000\n111111111\n000000000\n111111111\nCoarse Level\n000000000\n111111111\ncoarse level\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\ninput to\n000000000\n111111111\n000000000\n111111111\nFine Level\n000000000\n111111111\nfine level\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\ninput to 111111111111111111111\n000000000000000000000\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\nfinest 111111111111111111111\n000000000000000000000\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\nlevel 111111111111111111111\n000000000000000000000\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n000000000000000000000\n111111111111111111111\n000000000\n111111111\n\n1111111111\n0000000000\n0000000000\n1111111111\n0000000000\n1111111111\n00000000000000000\n11111111111111111\n00000000000000000\n11111111111111111\n00000000000000000\n11111111111111111\n00000000000000000\n11111111111111111\n\nFinest Level\n\n5 Experiments and Results\nThe registration algorithm is tested in two different experiments. The first experiment is global affine registration\nand the second is elastic registration, both in the multiresolution framework. Accuracy of registration results is evaluated quantitatively and qualitatively. Quantitative evaluation includes mean square differences in intensity between\nthe pair of images 2 . For visual assesment of registration, a checkerboard image is created by picking alternating\nsquares from the image pair, the registered source and target. Spatial alignment can be investigated visually by looking at continuity of tissue boundaries in the two interleaved\nimages. The alignment is good if there is no discontinuity of contours and the tissues merge smoothly across the\ncheckerboard borders.\n\n5.1\n\nThe algorithm is performed both on image scale and on\nstandard intensity scale. Thirty deformed brain images are\ngenerated by applying random deformations to the original\ntarget images. Original source images are tried to be registered to each deformed target images on standard intensity\nscale and image scale. Random deformations are obtained\nby randomly choosing parameters for affine matrix A. The\nresulting deformation field is normalized so that r.m.s displacement is at most 12 pixels. An example for affinely\nwarped images is shown in Figure 6.\n\nFigure 6. Images are randomly deformed by\naffine transformations\n\nExperiment I\n\nIn the first experiment global deformations are captured\nwith affine transformations in the multiresolution framework. For both the source and target images, four level\ncoarsest to finest Gaussian pyramid is used. In each multiresolution level, an optimal solution is determined and\nused as the starting point for the next level as seen in\nFigure 5. In each level, a single global affine transform\nis estimated with domain D, which is defined to be entire image. Transformed images are interpolated with cubic splines. Since intensities of images are changed in\neach warping/interpolation pair, image intensities are restandardized into standard scale from image scale.\n2 Mean\n\nSquare Error\n\nIn Figure 7, three example registration results of randomly and affinely warped images are shown. The result-\n\n\fing images clearly show that registered source images are\nin good agreement with target images. Registration quality\nis measured over 30 randomly deformed images by mean of\nthe square of the differences in intensity (MSE). Experiment\nhas been done both in image scale and on standard scale to\nshow improvement in MSE sense. Table-1 shows the MSE,\nmaximum MSE and minimum MSE over 30 registration examples on image scale and on intensity scale respectively.\n\nFigure 7. Resulting registration of images\nwith random affine warps. Each row includes\nsource, target and registered source\nsource, target and registered source\n\nsource, target and registered source\n\nthe Gaussian image pyramid. Accumulating all the transformations on each Gaussian image pyramid level yields a\nsingle final transformation that is able to capture both large\nand small scale motions.\nAs in the previous experiment, the algorithm is performed both on image scale and on standard intensity\nscale. Thirty deformed brain images are generated by applying random nonlinear deformations to the target images.\nRandom nonlinear deformations are obtained according to\nequation given below:\nx\u2032 = n1 .x + (\u22121)n2 .en3 .sin(y/n4 )\ny \u2032 = n5 .x + (\u22121)n6 .en7 .cos(y/n8 )\n\n(14)\n\nwhere [x, y], [x\u2032 , y \u2032 ] are initial and transformed spatial coordinates of the images respectively, and, n1 , ..n8 are chosen\nrandomly such that r.m.s displacement is at most 12 pixels. An example for nonlinearly warped images is shown in\nFigure 8.\n\nFigure 8. Images are randomly deformed by\nnonlinear transformations\nsource, target and registered source\n\nTable 1. Affine registration evaluations\nScale/Error\nMSE\nMax MSE Min MSE\nOn Image Scale\n0.1211\n0.1703\n0.0993\nOn Standard Scale 0.1060\n0.1457\n0.0857\n\n5.2\n\nExperiment II\n\nIn the second experiment, in addition to global deformations, local deformations are captured with locally\naffine transformations in the multiresolution framework.\nThe experiment starts with global affine registration in\nwhich pre-alignment of the source and target images is\nobtained. Similar to the first experiment, standardization\nis performed to handle image intensity variations in every\nwarping/interpolation pair. The resulting global affine parameters are used in the coarsest level of the Gaussian image pyramid to estimate local affine parameters on domain\nD, where D is now 5x5 pixels. Estimated local affine parameters are used to transform source image in the next level of\n\nIn Figure 9, three example registration results of randomly and nonlinearly warped images are shown. Capturing signal intensity variations during registration process\nwith intensity standardization method leads to assesment\nof visual comparision of registered source and target images with warping grid. Evaluation of the registration results is summarized in Table-2. The table shows that large\nand small scale deformations are captured accurately on the\nstandard intensity scale. Resulting images have fixed intensity meanings even there is large intensity variations initially.\nThe resulting registered images and deformation fields\nshow that standardization of intensity scales improves the\naccuracy of registration.\n\n\fFigure 9. Resulting registration of images\nwith random nonlinear warps. Each row includes source, target, registered source and\nestimated warping grid\n\nFigure 10. First row includes the source and\ntarget images, second row shows registered\nsource with warped grid and checkerboard\nimage for visual assesment\n\nsource, target and registered source\n\nsource, target and registered source estimated warp\n\nsource, target and registered source estimated warp\n\nTable 2. Elastic registration evaluations\nScale/Error\nMSE\nMax MSE Min MSE\nOn Image Scale\n0.0204\n0.0356\n0.0155\nOn Standard Scale 0.0194\n0.0320\n0.0148\n\nAnother method to evaluate proposed registration\nmethod is visual examination of checkerboard images. Figure 10 shows an elastic registration example together with\ncheckerboard image illustrating how well the image pair is\nregistered. Checkerboard image includes white and black\nsquares corresponding to intensity values taken from the\nregistered source and the target image respectively. Our\noverall observation from experimental results is that multiresolution elastic registration on standard intensity scale\ncan capture both local and global deformations with high\naccuracy.\n\n6 Conclusion\nIn this paper, a multiresolution elastic medical image\nregistration is presented. The multiresolution framework\nleads to a robust and fast algorithm. Variations in image\nintensity histograms at each pyramid level is corrected by\nthe intensity standardization method in order to provide an\nefficient framework for registration. The standardization\nmethod enables similar image intensities mean similar tissue contents, which leads to less parameters in registration.\nQualitative and quantitative evaluation of experimental results indicate that small and large scale deformations are\n\ncaptured with high accuracy. The examples presented here\nuse 2D images but the proposed algorithm is valid in 3D as\nwell.\n\n7 Acknowledgements\nThis research is funded by the European Commission Fp6 Marie Curie Action Programme (MEST-CT-2005021170)\n\nReferences\n[1] L. G. Brown. A survey of image registration techniques.\nComputer Surveys, 24(4), 1992.\n[2] C. Davatzikos. Spatial transformation and registration of\nbrain images using elastically deformable models. Computer Vision and Image Understanding: CVIU, 66(2):207\u2013\n222, 1997.\n[3] C. Davatzikos. Hammer: Hierarchical attribute matching\nmechanism for elastic registration. IEEE Transactions on\nMedical Imaging, 21(11):1421\u20131438, November 2002.\n[4] Y. Ge, J. Udupa, L. Nyul, L. Wei, and R. Grossman. Numerical tissue characterization in ms via standardization of the\nmr image intensity scale. Journal of Magnetic Resonance\nImaging, 12(5):715\u2013721, November 200.\n[5] A. A. Goshtasby. 2-D and 3-D Image Registration: for Medical, Remote Sensing, and Industrial Applications. Wiley\nPress, 2005.\n\n\f[6] Y. Guo, R. Sivaramakrishna, C.-C. Lu, J. Suri, and S. Laxminarayan. Breast image registration techniques: a survey.\nMedical and Biological Engineering and Computing, 44(12):15\u201326, March 2006.\n[7] E. Haber and J. Modersitzki. A multilevel method for image registration. SIAM Journal on Scientific Computing,\n27(5):1594\u20131607, 2006.\n[8] J. Hajnal, D. Hill, and D. Hawkes. Medical Image Registration. CRC Press, Boca Raton, 2001.\n[9] B. Horn. Robot Vision. Cambridge, MA: MIT Press, 1986.\n[10] J. Kybic and M. Unser. Fast parametric elastic image\nregistration. IEEE Transactions on Image Processing,\n12(11):1427\u20131442, November 2003.\n[11] G. N. Laszlo and K. U. Jayaram. On standardizing the mr\nimage intensity scale. Magnetic Resonance in Medicine,\n42(6):1072 \u2013 1081, 1999.\n[12] H. Lester and S. Arridge. A survey of hierarchical non-linear\nmedical image registration. Pattern Recognition, (32):129\u2013\n149, 1999.\n[13] J. B. A. Maintz and M. A. Viergever. A survey of medical image registration. Medical Image Analysis, 2(1):1\u201337,\nOctober 1998.\n[14] J. Modersitzki. Numerical Methods for Image Registration.\nOxford Science Publications, 2004.\n[15] S. Periaswamy and H. Farid. Elastic registration in the presence of intensity variations. IEEE Transactions on Medical\nImaging, 22(7):865\u2013874, July 2003.\n[16] D. Rueckert, L. Sonoda, C. Hayes, D. Hill, M. Leach, and\nD. Hawkes. Non-rigid registration using free-form deformations: Application to breast mr images. IEEE Transactions\non Medical Imaging, 18(8):712 \u2013 721, 1999.\n[17] P. Th\u00e9venaz and M. Unser. An efficient mutual information\noptimizer for multiresolution image registration. In Proceedings of the IEEE International Conference on Image\nProcessing (ICIP'98), volume 1, Chicago IL, USA, October 4-7.\n[18] L. Zagorchev and A. Goshtasby. A comparative study of\ntransformation functions for nonrigid image registration.\nIEEE Transactions on Image Processing, 15(3):529\u2013538,\nMarch 2006.\n[19] H. Zhou, T. Liu, F. Lin, Y. Pang, J. Wu, and J. Wu. Towards\nefficient registration of medical images. Computerized Medical Imaging and Graphics, In Press, Corrected Proof.\n[20] B. Zitova and J. Flusser. Image registration methods: a survey. Image and Vision Computing, 21(11):977\u20131000, October 2003.\n\n\f"}