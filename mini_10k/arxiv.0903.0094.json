{"id": "http://arxiv.org/abs/0903.0094v2", "guidislink": true, "updated": "2009-12-08T23:58:27Z", "updated_parsed": [2009, 12, 8, 23, 58, 27, 1, 342, 0], "published": "2009-03-01T20:42:05Z", "published_parsed": [2009, 3, 1, 20, 42, 5, 6, 60, 0], "title": "Dynamic Conjectures in Random Access Networks Using Bio-inspired\n  Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0903.2634%2C0903.0865%2C0903.3216%2C0903.4997%2C0903.2222%2C0903.1846%2C0903.1942%2C0903.4212%2C0903.5065%2C0903.2513%2C0903.0061%2C0903.3014%2C0903.0470%2C0903.3295%2C0903.1026%2C0903.3038%2C0903.2416%2C0903.0026%2C0903.3862%2C0903.0851%2C0903.3712%2C0903.3891%2C0903.2065%2C0903.1791%2C0903.1369%2C0903.2470%2C0903.1113%2C0903.0766%2C0903.3768%2C0903.3767%2C0903.5166%2C0903.1379%2C0903.2990%2C0903.4193%2C0903.2875%2C0903.3401%2C0903.5096%2C0903.1551%2C0903.1368%2C0903.0841%2C0903.0566%2C0903.2211%2C0903.3222%2C0903.4661%2C0903.5118%2C0903.1084%2C0903.5494%2C0903.4819%2C0903.4643%2C0903.1495%2C0903.3395%2C0903.3059%2C0903.2383%2C0903.1477%2C0903.0730%2C0903.1237%2C0903.1525%2C0903.3774%2C0903.0675%2C0903.2305%2C0903.0408%2C0903.1378%2C0903.2763%2C0903.5439%2C0903.4779%2C0903.2345%2C0903.2255%2C0903.3137%2C0903.5510%2C0903.2391%2C0903.3028%2C0903.4462%2C0903.0647%2C0903.0894%2C0903.2421%2C0903.1021%2C0903.1742%2C0903.0516%2C0903.4433%2C0903.3064%2C0903.4866%2C0903.1603%2C0903.2261%2C0903.1085%2C0903.3055%2C0903.5167%2C0903.3630%2C0903.2786%2C0903.3771%2C0903.5232%2C0903.1017%2C0903.2444%2C0903.0094%2C0903.2738%2C0903.2198%2C0903.1559%2C0903.5026%2C0903.5133%2C0903.4318%2C0903.5001%2C0903.4984&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Dynamic Conjectures in Random Access Networks Using Bio-inspired\n  Learning"}, "summary": "This paper considers a conjecture-based distributed learning approach that\nenables autonomous nodes to independently optimize their transmission\nprobabilities in random access networks. We model the interaction among\nmultiple self-interested nodes as a game. It is well-known that the Nash\nequilibria in this game result in zero throughput for all the nodes if they\ntake myopic best-response, thereby leading to a network collapse. This paper\nenables nodes to behave as intelligent entities which can proactively gather\ninformation, form internal conjectures on how their competitors would react to\ntheir actions, and update their beliefs according to their local observations.\nIn this way, nodes are capable to autonomously \"learn\" the behavior of their\ncompetitors, optimize their own actions, and eventually cultivate reciprocity\nin the random access network. To characterize the steady-state outcome, the\nconjectural equilibrium is introduced. Inspired by the biological phenomena of\n\"derivative action\" and \"gradient dynamics\", two distributed conjecture-based\naction update mechanisms are proposed to stabilize the random access network.\nThe sufficient conditions that guarantee the proposed conjecture-based learning\nalgorithms to converge are derived. Moreover, it is shown that all the\nachievable operating points in the throughput region are essentially stable\nconjectural equilibria corresponding to different conjectures. We investigate\nhow the conjectural equilibrium can be selected in heterogeneous networks and\nhow the proposed methods can be extended to ad-hoc networks. Simulations verify\nthat the system performance significantly outperforms existing protocols, such\nas IEEE 802.11 DCF protocol and the PMAC protocol, in terms of throughput,\nfairness, convergence, and stability.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0903.2634%2C0903.0865%2C0903.3216%2C0903.4997%2C0903.2222%2C0903.1846%2C0903.1942%2C0903.4212%2C0903.5065%2C0903.2513%2C0903.0061%2C0903.3014%2C0903.0470%2C0903.3295%2C0903.1026%2C0903.3038%2C0903.2416%2C0903.0026%2C0903.3862%2C0903.0851%2C0903.3712%2C0903.3891%2C0903.2065%2C0903.1791%2C0903.1369%2C0903.2470%2C0903.1113%2C0903.0766%2C0903.3768%2C0903.3767%2C0903.5166%2C0903.1379%2C0903.2990%2C0903.4193%2C0903.2875%2C0903.3401%2C0903.5096%2C0903.1551%2C0903.1368%2C0903.0841%2C0903.0566%2C0903.2211%2C0903.3222%2C0903.4661%2C0903.5118%2C0903.1084%2C0903.5494%2C0903.4819%2C0903.4643%2C0903.1495%2C0903.3395%2C0903.3059%2C0903.2383%2C0903.1477%2C0903.0730%2C0903.1237%2C0903.1525%2C0903.3774%2C0903.0675%2C0903.2305%2C0903.0408%2C0903.1378%2C0903.2763%2C0903.5439%2C0903.4779%2C0903.2345%2C0903.2255%2C0903.3137%2C0903.5510%2C0903.2391%2C0903.3028%2C0903.4462%2C0903.0647%2C0903.0894%2C0903.2421%2C0903.1021%2C0903.1742%2C0903.0516%2C0903.4433%2C0903.3064%2C0903.4866%2C0903.1603%2C0903.2261%2C0903.1085%2C0903.3055%2C0903.5167%2C0903.3630%2C0903.2786%2C0903.3771%2C0903.5232%2C0903.1017%2C0903.2444%2C0903.0094%2C0903.2738%2C0903.2198%2C0903.1559%2C0903.5026%2C0903.5133%2C0903.4318%2C0903.5001%2C0903.4984&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper considers a conjecture-based distributed learning approach that\nenables autonomous nodes to independently optimize their transmission\nprobabilities in random access networks. We model the interaction among\nmultiple self-interested nodes as a game. It is well-known that the Nash\nequilibria in this game result in zero throughput for all the nodes if they\ntake myopic best-response, thereby leading to a network collapse. This paper\nenables nodes to behave as intelligent entities which can proactively gather\ninformation, form internal conjectures on how their competitors would react to\ntheir actions, and update their beliefs according to their local observations.\nIn this way, nodes are capable to autonomously \"learn\" the behavior of their\ncompetitors, optimize their own actions, and eventually cultivate reciprocity\nin the random access network. To characterize the steady-state outcome, the\nconjectural equilibrium is introduced. Inspired by the biological phenomena of\n\"derivative action\" and \"gradient dynamics\", two distributed conjecture-based\naction update mechanisms are proposed to stabilize the random access network.\nThe sufficient conditions that guarantee the proposed conjecture-based learning\nalgorithms to converge are derived. Moreover, it is shown that all the\nachievable operating points in the throughput region are essentially stable\nconjectural equilibria corresponding to different conjectures. We investigate\nhow the conjectural equilibrium can be selected in heterogeneous networks and\nhow the proposed methods can be extended to ad-hoc networks. Simulations verify\nthat the system performance significantly outperforms existing protocols, such\nas IEEE 802.11 DCF protocol and the PMAC protocol, in terms of throughput,\nfairness, convergence, and stability."}, "authors": ["Yi Su", "Mihaela van der Schaar"], "author_detail": {"name": "Mihaela van der Schaar"}, "author": "Mihaela van der Schaar", "arxiv_comment": "41 pages, 15 figures", "links": [{"href": "http://arxiv.org/abs/0903.0094v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0903.0094v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0903.0094v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0903.0094v2", "journal_reference": null, "doi": null, "fulltext": "1\n\nDynamic Conjectures in Random Access\nNetworks Using Bio-inspired Learning\nYi Su and Mihaela van der Schaar\n\narXiv:0903.0094v2 [cs.GT] 8 Dec 2009\n\nDepartment of Electrical Engineering, UCLA\n\nAbstract\nInspired by the biological entities' ability to achieve reciprocity in the course of evolution, this paper\nconsiders a conjecture-based distributed learning approach that enables autonomous nodes to independently optimize their transmission probabilities in random access networks. We model the interaction\namong multiple self-interested nodes as a game. It is well-known that the Nash equilibria in this game\nresult in zero throughput for all the nodes if they take myopic best-response, thereby leading to a\nnetwork collapse. This paper enables nodes to behave as intelligent entities which can proactively gather\ninformation, form internal conjectures on how their competitors would react to their actions, and update\ntheir beliefs according to their local observations. In this way, nodes are capable to autonomously \"learn\"\nthe behavior of their competitors, optimize their own actions, and eventually cultivate reciprocity in the\nrandom access network. To characterize the steady-state outcome of this \"evolution\", the conjectural\nequilibrium is introduced. Inspired by the biological phenomena of \"derivative action\" and \"gradient\ndynamics\", two distributed conjecture-based action update mechanisms are proposed to stabilize the\nrandom access network. The sufficient conditions that guarantee the proposed conjecture-based learning\nalgorithms to converge are derived. Moreover, it is analytically shown that all the achievable operating\npoints in the throughput region are essentially stable conjectural equilibria corresponding to different\nconjectures. We also investigate how the conjectural equilibrium can be selected in heterogeneous\nnetworks and how the proposed methods can be extended to ad-hoc networks. Numerical simulations\nverify that the system performance significantly outperforms existing protocols, such as IEEE 802.11\nDistributed Coordination Function (DCF) protocol and priority-based fair medium access control (PMAC) protocol, in terms of throughput, fairness, convergence, and stability.\n\nIndex Terms\nreciprocity, conjectural equilibrium, medium access control, distributed learning, bio-inspired design.\n\n\f2\n\nI. I NTRODUCTION\nMulti-user communication systems represent competitive environments, where networked devices compete for the limited available resources and wireless spectrum. Most of these devices are autonomous, and\nmust adapt to the surrounding environment in a totally distributed and unsupervised manner. Recently, a\nnumber of emerging approaches have been considered to better understand, analyze, and characterize the\ndynamics of multi-user interactions among communication devices using biologically-inspired methods\n[1]- [3]. The scientific rationale for this is that, as communication networks expand in size, the network\n\"entities\" grow in their diversity and ability to gather and process information, and hence, networks will\nincreasingly come to resemble the models of interaction and self-organization of biological systems.\nIt is well-known that many biological species exhibit various levels of learning abilities, which enables\nthem to survive and evolve in the process of natural selection [4]- [6]. In particular, game theory has been\nused for a long time as a descriptive tool for characterizing the interaction of biological agents learning\nto improve their utility, e.g. the chance of \"survival\" for the selfish genes or organisms [4] [5]. Various\nlearning models have been developed, largely in response to observations by biologists about animal and\nhuman behavior [4] [6]. Several particular dynamic adjustment processes have received specific attention\nin the theory of learning and evolution. For example, replicator dynamics models how the share of\nthe population using a certain survival strategy grows at a rate proportional to that strategy's current\npayoff. In the partial best response dynamics, a fixed portion of the population switches during each time\nperiod from their current action to a best response to the aggregate statistic of the population play in\nthe previous period. As a result, the cooperative or altruistic behavior may be favored and reciprocity is\ntherefore established in the course of evolution [7].\nSeveral learning models have been applied to solve multi-user interaction problems in both wireline\nand wireless network settings [1] [8]- [10]. For instance, appropriate learning solutions are studied in\ndistributed environments consisting of agents with very limited information about their opponents, such as\nthe Internet [8]. A class of no-regret learning algorithms is proposed in the stochastic game framework to\nenable cognitive radio devices to learn from the environment and efficiently utilize the spectrum resource\n[1]. A reinforcement learning algorithm is proposed in the repeated game setting to design power control\nin wireless ad-hoc networks [9], where it is shown that the learning dynamics eventually converge to\nNash equilibrium (NE) and achieve satisfactory performance. A novel learning approach is proposed for\nwireless users to dynamically and efficiently share spectrum resources by considering the time-varying\nproperties of their traffic and channel conditions [10].\n\n\f3\n\nThis paper is concerned with developing distributed learning mechanisms in random access communication networks from not only the biological, but also the game-theoretic perspective. It is well-known that\nmyopic selfish behavior is detrimental in random access communication networks [14]. To avoid a network\ncollapse and encourage cooperation, we adopt the conjecture-based model introduced by Wellman and\nothers [18] [19] and enable the cognitive communication devices to build belief models about how their\ncompetitors' reactions vary in response to their own action changes. The belief functions of the wireless\ndevices are inspired by the evolutionary biological concept of reciprocity, which refers to interaction\nmechanisms in which the emergence of cooperative behavior is favored by the probability of future mutual\ninteractions [5] [7]. Specifically, by deploying such a behavior model, devices will no longer adopt myopic,\nselfish, behaviors, but rather they will form beliefs about how their actions will influence the responses\nof their competitors and, based on these beliefs, they will try to maximize their own welfare. The steady\nstate of such a play among belief-forming devices can be characterized as a conjectural equilibria (CE).\nAt the equilibrium, devices compensate for their lack of information by forming an internal representation\nof the opponents' behavior and preferences, and using these \"conjectured responses\" in their personal\noptimization program [19]. More importantly, we show that the reciprocity among these self-interested\ndevices can be sustained.\nIn particular, the main contributions of this paper are as follows. First, to cultivate cooperation in random\naccess networks, we enable self-interested autonomous nodes to form independent linear beliefs about\nhow their rival actions vary as a function of their own actions. Inspired by two biological phenomena,\nnamely \"derivative action\" in biological motor control system [20] [21] and \"gradient dynamics\" in\nbiological mutation [22]- [24], we design two simple distributed learning algorithms in which all the\nnodes' beliefs and actions will be revised by observing the outcomes of past mutual interaction over\ntime. Both conjecture-based algorithms require little information exchange among different nodes and\nthe internal computation for each node is very simple. For both algorithms, we investigate the stability of\ndifferent operating points and derive sufficient conditions that guarantee their global convergence, thereby\nestablishing the connection between the dynamic belief update procedures and the steady-state CE. We\nprove that all the operating points in the throughput region are stable CE and reciprocity can be eventually\nsustained via the proposed bio-inspired evolution. We also provide an engineering interpretation of the\nproposed bio-inspired design to clarify the similarities and differences between the proposed algorithms\nand existing protocols, e.g. the IEEE 802.11 DCF.\nSecond, we investigate the relationship between the parameter initialization of beliefs and Paretoefficiency of the achieved CE. In the economic market context, it has been shown that adjustment processes\n\n\f4\n\nbased on conjectures and individual optimization may sometimes be driven to Pareto-optimality [25]. To\nthe best of our knowledge, this is the first attempt in investigating the Pareto efficiency of the conjecturebased approach in communication networks. Importantly, it is shown that, regardless of the number of\nnodes, there always exist certain belief configurations such that the proposed distributed bio-inspired\nlearning algorithms can operate arbitrarily close to the Pareto boundary of the throughput region while\napproximately maintaining the weighted fairness across the entire network. Our investigation provides\nuseful insights that help to define convergent dynamic adaptation schemes that are apt to drive distributed\nrandom access networks towards efficient, stable, and fair configurations.\nThe rest of this paper is organized as follows. Section II presents the system model of random access\nnetworks, reviews the existing game theoretic solutions, and introduces the concept of CE. Based on\nthe intuition gained from \"derivative action\" and \"gradient dynamics\", Section III develops two simple\ndistributed learning algorithms in which nodes form dynamic conjectures and optimize their actions\nbased on their conjectures. The stability of different CE and the condition of global convergence are\nestablished. This section also shows that nodes' conjectures can be configured to stably operate at any\npoint that is arbitrarily close to the Pareto frontier in throughput region. Section IV addresses the topics\nof equilibrium selection in heterogeneous networks and presents possible extension to ad-hoc networks.\nNumerical simulations are provided in Section V to compare the proposed algorithms with the IEEE\n802.11 DCF protocol and P-MAC protocol. Conclusions are drawn in Section VI.\nII. S YSTEM D ESCRIPTION\n\nAND\n\nC ONJECTURAL E QUILIBRIUM\n\nIn this section, we describe the system model of random access networks and define the investigated\nrandom access game. We also discuss the existing game-theoretic solutions and introduce the concept of\nconjectural equilibrium.\nA. System Model of Random Access Networks\nFollowing [12] [13], we model the interaction among multiple autonomous wireless nodes in random\naccess networks as a random access game.\nAs shown in Fig. 1, consider a set K = {1, 2, . . . , K} of wireless nodes and each node represents a\ntransmitter-receiver pair (link). We define T xk as the transmitter node of link k and Rxk as the receiver\nnode of link k. We first assume a single-cell wireless network, where every node can hear every other\nnode in the network, and we will address the ad-hoc network scenario in Section IV.B. The system\noperates in discrete time with evenly spaced time slots [30] [33]. We assume that all nodes always have\n\n\f5\n\na data packet to transmit at each time slot (i.e. we investigate the saturated traffic scenario1), and the\nnetwork is noise free and packet loss occurs only due to collision. The action of a node in this game is\nto select its transmission probability and a node k will independently attempt transmission of a packet\nwith transmit probability pk . The action set available to node k is Pk = [0, 1] for all k \u2208 K2 . Once the\nnodes decide their transmission probabilities based on which they transmit their packets, an action profile\nis determined. We denote the action profile in the random access game as a vector p = (p1 , . . . , pK ) in\nP = P1 \u00d7 * * * \u00d7 PK . Then the throughput of node k is given by3\nuk (p) = pk\n\nY\n\n(1 \u2212 pi ).\n\n(1)\n\ni\u2208K\\{k}\n\nTo capture the performance tradeoff in the network, the throughput (payoff) region is defined as T =\n{(u1 (p), . . . , uK (p))| \u2203 p \u2208 P }. The random access game can be formally defined by the tuple \u0393 =\nhK, (Pk ), (uk )i [26]. Denote the transmission probability for all nodes but k by p\u2212k = (p1 , . . . , pk\u22121 , pk+1 ,\n. . . , pK ). From (1), we can see that node k's throughput depends not only on its own transmission\n\nprobability pk , but also the other nodes' transmission probabilities p\u2212k .\nB. Existing Solutions\nThe throughput tradeoff and stability of random access networks have been extensively studied from the\ngame theoretic perspective [11]- [17]. This subsection briefly reviews these existing results and highlights\nthe advantage and disadvantage of different approaches.\nIn the random access game, one of the most investigated problems is whether or not a Nash equilibrium\nexists. The definition of Nash equilibrium is given as follows [26].\nDefinition 1: A profile p of actions constitutes a Nash equilibrium of \u0393 if uk (pk , p\u2212k ) \u2265 uk (p\u2032k , p\u2212k )\nfor all p\u2032k \u2208 Pk and k \u2208 K.\nThe NE of the investigated random access game has been addressed in the similar context of CSMA/CA\nnetworks where selfish nodes deliberately control their random deferment by altering their contention\n1\n\nThis paper focuses on the saturated system because we are interested in throughput maximization. The analysis can be\n\nextended to investigate the non-saturated networks where the incoming packets of the individual nodes' queues arrive at finite\nrates.\n2\n\nThe action set can be alternatively defined to be Pk = [Pkmin , Pkmax ] and the analysis in this paper still applies.\n\n3\n\nThis throughput model assumes that time is slotted and all packets are of equal length. We use this model for theoretic\n\nanalysis. The throughput of the scenarios in which packet lengths are not equal, e.g. the IEEE 802.11 DCF, will be addressed\nin Section V.\n\n\f6\n\nwindows [14]. Specifically, the transmission probability pk in our model can be related to the contention\nwindow CWk in the CSMA/CA protocol, where pk =\n\n2\n1+CWk .\n\nIt has been shown in [14] that at the\n\nNE, at least one selfish node will set CWk = 1 (i.e. always transmit). If more than one selfish node sets\nits contention window to 1, it will cause zero throughput for all the nodes in the system. This kind of\nresult is known as the tragedy of the commons. We can see that, myopic selfish behavior is detrimental in\nrandom access scenarios and novel mechanisms are required to encourage cooperative behavior among\nthe self-interested devices. In addition, the existence of and convergence to the NE in random access\ngames have been studied also in other scenarios, where individual nodes have utility functions that are\ndifferent from (1) [11] [12]. For example, the nodes in [11] adjust their transmission probabilities in\nan attempt to attain their desired throughputs. A local utility function is found for exponential backoffbased MAC protocols, based on which these protocols can be reverse-engineered in order to stabilize the\nnetwork [12]. However, due to the inadequate coordination or feedback mechanism in these protocols,\nPareto optimality of the throughput performance cannot be guaranteed.\nSeveral recent works also investigate how to design new distributed algorithms that provably converge to\nthe Pareto boundary of the network throughput region [14]- [16]. A distributed protocol is proposed in [14]\nto guide multiple selfish nodes to a Pareto-optimal NE by including penalties into their utility functions.\nHowever, the penalties must be carefully chosen. In [15], the utility maximization is solved using the\ndual decomposition technique by enabling nodes to cooperatively exchange coordination information\namong each other. Furthermore, it is shown in [16] that network utility maximization in random access\nnetworks can be achieved without real-time message passing among nodes. The key idea is to estimate\nthe other nodes' transmission probabilities from local observations, which in fact increases the internal\ncomputational overhead of individual nodes.\nAs discussed before, the goal of this paper is to design a simple distributed random access algorithm\nthat requires limited information exchanges among nodes and also stabilizes the entire network. More\nimportantly, this algorithm should be capable of achieving high efficiency and of differentiating among\nheterogeneous nodes carrying various traffic classes with different quality of service requirements. As we\nwill show later, the game-theoretic concept of conjectural equilibrium provides such an elegant solution.\nC. Conjectural Equilibrium\nIn game-theoretic analysis, conclusions about the reached equilibria are based on assumptions about\nwhat knowledge the players possess. For example, the standard NE strategy assumes that every player\nbelieves that the other players' actions will not change at NE. Therefore, it chooses to myopically\n\n\f7\n\nmaximize its immediate payoff [26]. Therefore, the players operating at equilibrium can be viewed as\ndecision makers behaving optimally with respect to their beliefs about the strategies of other players.\nTo rigorously define CE, we need to include two new elements S and s and, based on this, reformulate\n\u0010\n\u0011\nthe random access game \u0393\u2032 = K, (Pk ), (uk ), (Sk ), (sk ) [18]. S = \u00d7k\u2208K Sk is the state space, where Sk\n\nis the part of the state relevant to the node k. Specifically, the state in the random access game is defined\nas the contention probability that nodes experience. The utility function uk is a map from the nodes'\nstate space to real numbers, uk : Sk \u00d7 Pk \u2192 R. The state determination function s = \u00d7k\u2208K sk maps\njoint action to state with each component sk : P \u2192 Sk . Each node cannot directly observe the actions\n(transmission probabilities) chosen by the others, and each node has some belief about the state that\nwould result from performing its available actions. The belief function s\u0303k is defined to be s\u0303k : Pk \u2192 Sk\nsuch that s\u0303k (pk ) represents the state that node k believes it would result in if it selects action pk . Notice\nthat the beliefs are not expressed in terms of other nodes' actions and preferences, and the multi-user\ncoupling in these beliefs is captured directly by individual nodes forming conjectures of the effects of\ntheir own actions. Moreover, each node chooses the action pk \u2208 Pk if it believes that this action will\nmaximize its utility.\nDefinition 2: In the game \u0393\u2032 defined above, a configuration of belief functions (s\u0303\u22171 , . . . , s\u0303\u2217K ) and a joint\naction p\u2217 = (p\u22171 , . . . , p\u2217K ) constitute a conjectural equilibrium, if for each k \u2208 K,\ns\u0303\u2217k (p\u2217k ) = sk (p\u22171 , . . . , p\u2217K ) and p\u2217k = arg max uk (s\u0303\u2217k (pk ), pk ).\npk \u2208Pk\n\nFrom the above definition, we can see that, at CE, all nodes' expectations based on their beliefs are\nrealized and each node behaves optimally according to its expectation. In other words, nodes' beliefs are\nconsistent with the outcome of the play and they behave optimally with respect to their beliefs. The key\nchallenges are how to configure the belief functions such that reciprocal behavior is encouraged and how\nto design the evolution rules such that the network can dynamically converge to a CE having satisfactory\nperformance. Section III provides bio-inspired solutions for these problems in random access games.\nIII. D ISTRIBUTED B IO - INSPIRED L EARNING\nIn this section, to promote reciprocity, we design a prescribed rule for each node to configure its\nbelief about its expected contention of the wireless network as a linear function of its own transmission\nprobability. It is shown that all the achievable operating points in the throughput region T are CE by\ndeploying these belief functions. Furthermore, inspired by the biological mechanisms \"derivative action\"\nand \"gradient dynamics\", we propose two distributed learning algorithms for these nodes to dynamically\n\n\f8\n\nachieve the CE. We provide the sufficient conditions that guarantee the stability and convergence of\nthe CE. We also discuss the similarities and differences between these bio-inspired algorithms and the\nexisting well-known protocols. Finally, it is proven that any Pareto-inefficient operating point is a stable\nCE, i.e. we can approach arbitrarily close to the Pareto frontier of the throughput region T .\n\nA. Individual Behavior\nAs discussed before, both the state space and belief functions need to be defined in order to investigate\nQ\nthe existence of CE. In the random access game, we define the state sk = i\u2208K\\{k} (1 \u2212 pi ) to be the\n\ncontention measure signal representing the probability that all nodes except node k do not transmit. This\nis because besides its own transmission probability, its throughput only depends on the probability that\nthe remaining nodes do not transmit. We can see that state sk indicates the aggregate effects of the other\n\nnodes' joint actions on node k's payoff. In practice, it is hard for wireless nodes to compute the exact\ntransmission probabilities of their opponents [16]. Therefore, we assume that sk is the only information\nthat node k has about the contention level of the entire network, because it is a metric that node k can\neasily compute based on local observations. Specifically, from user k's viewpoint, the probabilities of\ndenote the number of time slots between\n= (1 \u2212 pk )sk . Let nidle\nexperiencing an idle time slot is pidle\nk\nk\nhas an independent identically distributed geometric distribution\nany two consecutive idle time slots. nidle\nk\nidle = 1/(1 + n\u0304idle ), where n\u0304idle is the mean value of nidle\nwith probability pidle\nk . Therefore, we have pk\nk\nk\nk\n\nand can be locally estimated by node k through its observation of the channel contention history. Since\nnode k knows its own transmission probability pk , it can estimate sk using sk = 1/(1 + n\u0304idle\nk )(1 \u2212 pk ).\nNotice that the action available to node k is to choose the transmission probability pk \u2208 Pk . By the\ndefinition of belief function, we need to express the expected contention measure s\u0303k as a function of its\nown transmission probability pk . The simplest approach is to deploy linear belief models, i.e. node k's\nbelief function takes the form\ns\u0303k (pk ) = s\u0304k \u2212 ak (pk \u2212 p\u0304k ),\n\n(2)\n\nfor k \u2208 K. The values of s\u0304k and p\u0304k are specific states and actions, called reference points [25] and ak\nis a positive scalar. In other words, node k assumes that other nodes will observe its deviation from\nits reference point p\u0304k and the aggregate contention probability deviates from the referent point s\u0304k by\na quantity proportional to the deviation of pk \u2212 p\u0304k . How to configure s\u0304k , p\u0304k , and ak will be addressed\nin the rest of this paper. The reasons why we focus on the linear beliefs represented in (2) are twofold. First, the linear form represents the simplest model based on which a user can model the impact\n\n\f9\n\nof its environment. As we will show later in Section III-E, building and optimizing over such simple\nbeliefs is sufficient for the network to achieve almost any operating point in the throughput region as a\nstable CE. Second, the conjecture functions deployed by the wireless users are based on the concept of\nreciprocity [5] [7], which was developed in evolutionary biology, and refers to interaction mechanisms in\nwhich the evolution of cooperative behavior is favored by the probability of future mutual interactions.\nSimilarly, in single-hop wireless networks, the devices repeatedly interact when accessing the channel. If\nthey disregard the fact that they have a high probability to interact in the future, they will act myopically,\nwhich will lead to a tragedy of commons (the zero-payoff Nash equilibrium). However, if they recognize\nthat their probability of interacting in the future is high, they will consider their impact on the network\nstate, which is captured in the belief function by the positive ak .\nThe goal of node k is to maximize its expected throughput pk *s\u0303k (pk ) taking into account the conjectures\nthat it has made about the other nodes. Therefore, the optimization a node needs to solve becomes:\nh\ni\n(3)\nmax pk s\u0304k \u2212 ak (pk \u2212 p\u0304k ) ,\npk \u2208Pk\n\nwhere the second term is the expected contention measure s\u0303k (pk ) if node k transmits with probability pk .\nThe product of pk and s\u0303k (pk ) gives the expected throughput for pk \u2208 Pk . For ak > 0, node k believes that\nincreasing its transmission probability will increase its experienced contention probability. The optimal\nsolution of (3) is given by\np\u2217k = min\n\nn s\u0304\np\u0304k o\nk\n+ ,1 .\n2ak\n2\n\n(4)\n\nIn the following, we first show that forming simple linear beliefs in (2) can cause all the operating\npoints in the achievable throughput region to be CE.\nTheorem 1: All the operating points in the throughput region T are conjectural equilibria.\nProof : For each operating point (\u03c41 , . . . , \u03c4K ) in the throughput region T , there exists at least a joint\naction profile (p\u22171 , . . . , p\u2217K ) \u2208 P such that \u03c4k = uk (p\u2217 ), \u2200k \u2208 K. We consider setting the parameters in\nthe belief functions to be:\na\u2217k\n\n=\n\nQ\n\ni\u2208K\\{k} (1\np\u2217k\n\nIt is easy to check that, if the reference points are s\u0304k =\n\n\u2212 p\u2217i )\n\nQ\n\n.\n\ni\u2208K\\{k} (1\n\n(5)\n\u2212 p\u2217i ), p\u0304k = p\u2217k , we have s\u0303k (p\u2217k ) =\n\nsk (p\u22171 , . . . , p\u2217K ) and p\u2217k = arg maxpk \u2208Pk uk (s\u0303k (pk ), pk ). Therefore, this configuration of the belief func-\n\ntions and the joint action p\u2217 = (p\u22171 , . . . , p\u2217K ) constitute the CE that results in the throughput (\u03c41 , . . . , \u03c4K ).4\n4\n\nBy the definition of CE, the configuration of the linear belief functions is a key part of CE. Since this paper focuses on the\n\nlinear belief functions defined in (2), we will simply state the joint action p\u2217 is a CE hereafter for the ease of presentation.\n\n\f10\n\n\u0004\n\nTheorem 1 establishes the existence of CE, i.e. for a particular p\u2217 \u2208 P , how to choose the parameters\n\u2217\n{s\u0304k , p\u0304k , ak }K\nk=1 such that p is a CE. However, it neither tells us how these CE can be achieved and\n\nsustained in the dynamic setting nor clarifies how different belief configurations can result in various CE.\nIn distributed learning scenarios, nodes learn when they modify their conjectures based on their new\nobservations. Specifically, we first allow the nodes to revise their reference points based on their past\nlocal observations. Let stk , ptk , s\u0303tk , s\u0304tk , p\u0304tk be user k's state, transmission probability, belief function, and\nQ\nreference points at stage t5 , in which stk = i\u2208K\\{k} (1 \u2212 pti ). We propose a simple rule for individual\n\nnodes to update their reference points. At stage t, node k set its s\u0304tk and p\u0304tk to be st\u22121\nand pt\u22121\nk\nk . In other\nwords, node k's conjectured utility function at stage t is\ni\nh Y\nt\u22121\n(1 \u2212 pt\u22121\n)\n\u2212\na\n(p\n\u2212\np\n)\n.\nutk (s\u0303tk (pk ), pk ) = pk\nk\nk\ni\nk\n\n(6)\n\ni\u2208K\\{k}\n\nThe remainder of this paper will investigate the dynamic properties of the resulting operating points and\nthe performance trade-off among multiple competing nodes. In particular, for fixed {ak }K\nk=1 , Sections\nIII-B and C will embed the above individual optimization scheme in two different distributed learning\nprocesses in which all the nodes update their transmission probabilities over time. Section III-E further\nallows individual nodes adaptively update their parameters {ak }K\nk=1 such that desired efficiency can be\n\u2217\nattained. For given {ak }K\nk=1 , Section IV-A will derive a quantitative description of the resulting CE p .\n\nB. A Best Response Learning Algorithm\nOur first algorithm in establishing reciprocity through a evolution process is inspired by the \"derivative\naction\", which is a key component of biological motor control system models, e.g. cerebellar control over\narm, hand, truncal, and leg movements [20] [21]. Specifically, during limb movements, high frequency\ndifferential (velocity-like) signals after filtering due to biological sensors are attributed to lateral cerebellum as part of the input for cerebellar control. The classical control interpretation of \"derivative action\" is\nthat the first-order derivative term serves as a short term prediction of the measured zero-order variable.\nFor example, in a swing leg control, the velocity-like signals enable a cerebrocerebellar channel to better\n5\n\nThis paper assumes the persistence mechanism for contention resolution except in Section III.D. In the persistence mechanism,\n\neach wireless node maintains a persistence probability and accesses the channel with this probability [37]. A stage contains\nmultiple time slots. The nodes estimate the contention level in the network and update their persistence probabilities in the\n\"stage-by-stage\" manner. The superscript t in this paper represents the numbering of the stages unless specified.\n\n\f11\n\nlocate the ankle (or foot) position in front of the hip position during the swing phase. The conjecturebased approach is very similar in spirit with the aforementioned biological motor control models and\nthe standard proportional integral derivative (PID) controllers in engineered systems [38]. In particular,\nthe derivative term is substituted by a node's internal belief of how its own action will impact the other\nnodes' behavior. Our first learning algorithm adopts the simplest update mechanism in which each node\nadjusts its transmission probability using the best response that maximizes its conjectured utility function\n(6). Therefore, at stage t, node k chooses a transmission probability\nQ\nt\u22121\nn pt\u22121\no\ni\u2208K\\{k} (1 \u2212 pi )\nt t\nt\nk\npk = arg max uk (s\u0303k (pk ), pk ) = min\n+\n,1 .\npk \u2208Pk\n2\n2ak\n\n(7)\n\nIn this regard, the use of \"derivative action\" by an agent can be interpreted as using the best response to\nthe forecasted effect of all the opponents' strategies.\nAlgorithm 1 : A Distributed Best Response Learning Algorithm for Random Access\n1: Initialize: t = 0, the transmission probability p0k \u2208 [0, 1], and the parameter ak > 0 in node k 's belief\nfunction, \u2200k \u2208 K.\n2:\n\nprocedure\n\n3:\n\nLocally at each node k, iterate through t:\n\n4:\n\nSet t \u2190 t + 1.\n\n5:\n\nfor all k \u2208 K do\n\n6:\n\nAt stage t, ptk \u2190 min{pt\u22121\nk /2 +\n\nQ\n\ni\u2208K\\{k} (1\n\n\u2212 pt\u22121\ni )/(2ak ), 1}.\n\n7:\n\nend for\n\n8:\n\nNode k decides if it will transmit data with a probability ptk (or equivalently, maintain a window\nsize of CWkt = 2/ptk \u2212 1) for all the time slots during stage t.\n\n9:\n\nend procedure\n\nThe detailed description of the entire distributed best response learning procedure is summarized in\nAlgorithm 1 and it is also pictorially illustrated in Fig. 2. Next, we are interested in deriving the limiting\nbehavior, e.g. stability and convergence, of this algorithm. For ease of illustration, the sufficient conditions\nK\nfor stability and convergence throughout this paper are expressed in terms of {pk }K\nk=1 and {ak }k=1 ,\nK\nK\nrespectively. The mapping from {pk }K\nk=1 to {ak }k=1 is given in (5) and the mapping from {ak }k=1 to\n\n{pk }K\nk=1 will be addressed in Section IV-A.\n\n1) Local Stability: Although Theorem 1 indicates that all the points in T are CE, they may not be\nnecessarily stable. An unstable equilibrium is not desirable, because any small perturbation might cause\n\n\f12\n\nthe sequence of iterates to move away from the initial equilibrium. The following theorem describes a\nsubset in P in which all the points are stable CE.\nTheorem 2: For any p\u2217 = (p\u22171 , . . . , p\u2217K ) \u2208 P , if\nK\nX\n\np\u2217k < 1,\n\nk=1\n\nX\n\nor\n\ni\u2208K\\{k}\n\np\u2217k\n< 1, \u2200k \u2208 K,\n1 \u2212 p\u2217i\n\n(8)\n\np\u2217 is a stable CE for Algorithm 1.\nProof : To analyze the stability of different CE, we consider the Jacobian matrix of the self-mapping\nfunction in (7). Let Jik denote the element at row i and column k of the Jacobian matrix J. If pt\u22121\nk /2 +\nQ\nt\u22121\nBR\nof (7) is defined as:\ni\u2208K\\{k} (1 \u2212 pi )/(2ak ) \u2264 1, the Jacobian matrix J\n\uf8f1\n1\n\uf8f2\nif i = k,\n\u2202pti\n2,\nBR\n= t\u22121\nJik\n(9)\n=\nQ\n\uf8f3 \u2212 1\n\u2202pk\n(1 \u2212 pt\u22121 ), if i 6= k.\n2ai\n\nj\u2208K\\{i,k}\n\nj\n\nAs proven in Theorem 1, for p\u2217 = (p\u22171 , . . . , p\u2217K ) \u2208 P to be a fixed point of the self-mapping function in\nQ\n(7), ak must be set to be a\u2217k = i\u2208K\\{k} (1 \u2212 p\u2217i )/p\u2217k . It follows that\n\uf8f1\n1\n\uf8f2\nif i = k,\n2,\nBR\n(10)\n|p=p\u2217 , a=a\u2217 =\nJik\n\u2217\n\uf8f3 \u2212 pi \u2217 , if i 6= k.\n2(1\u2212p )\nk\n\np\u2217\n\nis stable if and only if the eigenvalues\n\n{\u03bbk }K\nk=1\n\nof matrix JBR in (10) are all inside the unit circle of\n\nthe complex plane, i.e. |\u03bbk | < 1, \u2200k \u2208 K.\nBR\nare located in the region\nFrom Gersgorin circle theorem [27], all the eigenvalues {\u03bbk }K\nk=1 of J\nK n\n[\n\n|\u03bb \u2212\n\nBR\n|\nJkk\n\nk=1\n\n6\n\nX\n\ni\u2208K\\{k}\n\no\n\nBR\n|\n|Jik\n\nK n\n[\nBR\nand\n|6\n|\u03bb \u2212 Jkk\nk=1\n\nX\n\ni\u2208K\\{k}\n\no\nBR\n| .\n|Jki\n\nBR = 1/2, these regions can be further simplified as\nNote that Jkk\nK n\n[\n\nk=1\n\n1\n|\u03bb \u2212 | 6\n2\n\nX\n\ni\u2208K\\{k}\n\nK n\no\n[\n1\np\u2217i\n|\u03bb \u2212 | 6\nand\n\u2217\n2(1 \u2212 pk )\n2\nk=1\n\nX\n\ni\u2208K\\{k}\n\no\np\u2217k\n.\n2(1 \u2212 p\u2217i )\n\nIf either condition in (8) is satisfied, all the eigenvalues of JBR must fall into the region |\u03bb \u2212 21 | < 12 ,\nwhich is located within the unit circle |\u03bb| < 1. Therefore, p\u2217 is a stable CE. \u0004\nRemark 1: p\u2217k /(1\u2212p\u2217i ) can be interpreted as the worst case probability that node k occupies the channel\ngiven that node i does not transmit. This metric reflects from node k's perspective the impact that node i's\nevacuation has on the overall congestion of the channel. Therefore, the sufficient conditions in (8) means\nthat if the system is not overcrowded from all the nodes' perspectives, the corresponding CE is stable. We\ncan see from Theorem 2 that lowering the transmission probabilities helps to stabilize the random access\n\n\f13\n\nnetwork. The system can accommodate a certain degree of individual nodes' \"aggressiveness\" while\nmaintaining the network stability. For example, if a node sends its packets with a probability close to 1,\nas long as the other nodes are conservative and they set their transmission probability small enough, the\nentire network can still be stabilized. However, if too many \"aggressive\" nodes with large transmission\nprobabilities coexist, the system stability may collapse, leading to a tragedy of commons.\n2) Global Convergence: Note that Theorem 2 only investigates the stability for different fixed points,\ni.e. Algorithm 1 converges to these points when initial values are close enough to them. In addition to\nlocal stability, we are also interested in characterizing the global convergence of Algorithm 1 when using\nvarious ak to initialize the belief function s\u0303k .\nK\nTheorem 3: Regardless of any initial value chosen for {p0k }K\nk=1 , if the parameters {ak }k=1 in the belief\n\nfunctions {s\u0303k }K\nk=1 satisfy\nX\n\ni\u2208K\\{k}\n\n1\n< 1, \u2200k \u2208 K,\nai\n\n(11)\n\nAlgorithm 1 converges to a unique CE.\nProof : For ak > 1, the self-mapping function in (7) can be rewritten as\nQ\nt\u22121\npt\u22121\ni\u2208K\\{k} (1 \u2212 pi )\nt\nk\n+\n.\npk =\n2\n2ak\n\n(12)\n\nWe can prove for Algorithm 1 the uniqueness of and the convergence to CE by showing that function\n(12) is a contraction map if the condition in (11) is satisfied.\nLet d(*) be the induced distance function by certain vector norm in the Euclidean space. Consider two\nsequences of the transmission probability vectors {p0 , . . . , pt\u22121 , pt , . . .} and {p\u03020 , . . . , p\u0302t\u22121 , p\u0302t , . . .}. We\nhave\nd(pt , p\u0302t ) = kpt \u2212 p\u0302t k \u2264 kJBR k * kpt\u22121 \u2212 p\u0302t\u22121 k = kJBR k * d(pt\u22121 , p\u0302t\u22121 ).\n\n(13)\n\nThe matrix norm used here is induced by the same vector norm. Using k*k1 for the Jacobian matrix of\n(12) as given in (10), we have\nkJBR k1 = max\nk\u2208K\n\nK\nX\nX\n1 1\nBR\n| \u2264 + max\n|Jik\n2 2 k\u2208K\ni=1\n\ni\u2208K\\{k}\n\n1\n.\nai\n\n(14)\n\nTherefore, if the condition in (11) is satisfied, there exist a constant q \u2208 [0, 1) and a positive \u01eb, such that\nq = kJBR k1 = 1 \u2212 \u01eb < 1 and kpt \u2212 p\u0302t k1 \u2264 qkpt\u22121 \u2212 p\u0302t\u22121 k1 . From the contraction mapping theorem\n\n[28], the self-mapping function in (7) has a unique fixed point and the sequence {pt }+\u221e\nt=0 converges to\nthe unique fixed point. \u0004\n\n\f14\n\nRemark 2: We can also alternatively derive a sufficient condition using k*k\u221e for (13) to be a contraction\nmap. We have\nkJBR k\u221e = max\nk\u2208K\n\nK\nX\nK \u22121\n1 1\nBR\n.\n| \u2264 + max\n|Jki\n2 2 k\u2208K ak\n\n(15)\n\ni=1\n\nTherefore, if ak > K \u2212 1, \u2200k \u2208 K, Algorithm 1 also globally converges. However, it is easy to verify\nthat it is a special case of the sufficient condition given by (11). In addition, we can see from (11) that,\nif the accumulated \"aggressiveness\" of the nodes in the entire networks reaches a certain threshold, the\nglobal convergence property may not hold. However, if all the nodes back off adequately by choosing\ntheir algorithm parameters {ak }K\nk=1 such that condition (11) is satisfied, Algorithm 1 globally converges.\nRemark 3: Under the sufficient condition in (11), by substituting (5) into (11), the limiting points lie\nin the set\nn\np\u2217 = (p\u22171 , . . . , p\u2217K )\n\nX\n\ni\u2208K\\{k}\n\nQ\n\no\np\u2217i\n<\n1,\n\u2200k\n\u2208\nK\n.\n\u2217\nl\u2208K\\{i} (1 \u2212 pl )\n\nIt is easy to check that this is a subset of {p\u2217 = (p\u22171 , . . . , p\u2217K )|\n\nPK\n\n\u2217\nk=1 pk\n\n(16)\n\n< 1} for K > 2, which verifies\n\nthe intuition that the set that Algorithm 1 globally converges to should be a subset of the set of locally\nstable CE.\n\nC. A Gradient Play Learning Algorithm\nThe best-response based dynamics may lead to large fluctuations in the entire network, which may\nnot be desirable if we want to avoid temporary system-wide instability. Therefore, in this subsection, we\npropose an alternative learning algorithm inspired by the gradient type dynamics, which has been well\nstudied in the field of evolutionary biology [22] [23]. For example, in population genetics, the evolutionary\ndynamics resulting for a particular mutant's invasion fitness, i.e. its growth rate, are primarily governed\nby the fitness gradient. In other words, the population has a small probability of moving its phenotype [4]\nin the direction in which fitness is increasing, and this probability is proportional to the fitness gradient\nfor possible mutants. This model has also been used to model fluid flow under a pressure gradient or the\nmotion of organisms towards sites of higher nutrient concentration [24].\nMotivated by the gradient dynamics, we consider the gradient play learning algorithm. At each iteration,\neach node updates its action gradually in the ascent direction of its conjectured utility function in (6).\nSpecifically, at stage t, node k chooses its transmission probability according to\n\u0014\n\u00151\n\u2202utk (s\u0303tk (pk ), pk )\nt\u22121\nt\np k = p k + \u03b3k\n,\n\u2202pk\nt\u22121 0\npk =pk\n\n(17)\n\n\f15\n\nin which [x]ba means max{min{x, b}, a}. The engineering interpretation of this updating procedure is\nthat each node will \"mutate\", i.e. update its transmission probability, along the gradient direction of\nits conjectured utility function. As long as the stepsize \u03b3k is small enough, the entire network will\n\"evolve\" smoothly and temporary system-wide instability will not occur. This algorithm also resembles\nthe technique of exponential smoothing in statistics [39]. In the following, we assume that all nodes use\nthe same stepsize \u03b3k = \u03b3, \u2200k \u2208 K and 0 < pt\u22121\n< 1. If \u03b3 is sufficiently small, substituting the utility\nk\nfunction (6) into (17), we have\n+\u03b3\nptk = pt\u22121\nk\n\nn Y\n\no\nt\u22121\n.\n(1 \u2212 pt\u22121\n)\n\u2212\na\np\nk\ni\nk\n\n(18)\n\ni\u2208K\\{k}\n\nThe detailed description of the distributed gradient play learning mechanism is summarized in Algorithm\n2. As for Algorithm 1, we investigate the stability and convergence of this gradient play learning algorithm.\n\nAlgorithm 2 : A Distributed Gradient Play Learning Algorithm for Random Access\n1: Initialize: t = 0, stepsize \u03b3 , the transmission probability p0k \u2208 [0, 1], and the parameter ak > 0 in\nnode k's belief function, \u2200k \u2208 K.\n2:\n\nprocedure\n\n3:\n\nLocally at each node k, iterate through t:\n\n4:\n\nSet t \u2190 t + 1.\n\n5:\n\nfor all k \u2208 K do\n\n6:\n\nptk\n\nAt stage t,\n\n\u2190\n\n\u0014\n\npt\u22121\nk\n\n+\u03b3\n\nnQ\n\ni\u2208K\\{k} (1\n\n\u2212\n\npt\u22121\ni )\u2212\n\nak pt\u22121\nk\n\no\u00151\n\n.\n\n0\n\n7:\n\nend for\n\n8:\n\nNode k decides if it will transmit data with a probability ptk (or equivalently, maintain a window\nsize of CWkt = 2/ptk \u2212 1) for all the time slots during stage t.\n\n9:\n\nend procedure\n\n1) Local Stability: First of all, the following theorem describes a stable CE set in P for Algorithm 2.\nTheorem 4: For any p\u2217 = (p\u22171 , . . . , p\u2217K ) \u2208 P , if\nK\nX\nk=1\n\np\u2217k < 1,\n\nor\n\nX\n\ni\u2208K\\{k}\n\np\u2217k\n< 1, \u2200k \u2208 K,\n1 \u2212 p\u2217i\n\nand the stepsize \u03b3 is sufficiently small, p\u2217 is a stable CE for Algorithm 2.\n\n(19)\n\n\f16\nGP =\nProof : Consider the Jacobian matrix JGP of the self-mapping function in (18). We have Jik\n\u2217\n\u2217\n\u2217\n\u2202pti /\u2202pt\u22121\nk . As discussed above, for p = (p1 , . . . , pK ) \u2208 P to be a fixed point of the self-mapping\nQ\nfunction in (18), ak must be set to be a\u2217k = i\u2208K\\{k} (1 \u2212 p\u2217i )/p\u2217k . It follows that\n\uf8f1\n\u2217\n\uf8f2 1 \u2212 \u03b3/p\u2217 * Q\nl\u2208K\\{k} (1 \u2212 pl ), if i = k,\nk\nGP\n\u2217\n\u2217\nJik |p=p , a=a =\n(20)\nQ\n\uf8f3\n(1 \u2212 p\u2217 ),\nif i 6= k.\n\u2212\u03b3\nl\u2208K\\{i,k}\n\nl\n\nGP\nare all inside the unit circle of the\np\u2217 is stable if and only if the eigenvalues {\u03bbk }K\nk=1 of matrix J\n\ncomplex plane, i.e. |\u03bbk | < 1, \u2200k \u2208 K. Recall that the spectral radius \u03c1(J) of a matrix J is the maximal\nabsolute value of the eigenvalues [27]. Therefore, it is equivalent to prove that \u03c1(JGP ) < 1.\nTo a vector w = (w1 , * * * , wK ) \u2208 RK\n+ with positive entries, we associate a weighted l\u221e norm, defined\nas\nx kw\nkx\n\u221e = max\nk\u2208K\n\n|xk |\n.\nwk\n\n(21)\n\nThe vector norm k * kw\n\u221e induces a matrix norm, defined by\nkAkw\n\u221e = max\nk\u2208K\n\nAccording to Proposition A.20 in [31], \u03c1(J\n\nGP\n\n)\u2264\n\nK\n1 X\n|aki |wi .\nwk\n\n(22)\n\ni=1\n\nkJGP kw\n\u221e.\n\nConsider the vector w = (w1 , * * * , wK ) in\n\nwhich wk = p\u2217k (1 \u2212 p\u2217k ). We have\nK\n\u03b3\n1 X GP\n|Jki |wi = 1 \u2212\nwk\n\nQ\n\n\u03b3\n\nQ\n\ni=1\n\n=1\u2212\n\nTherefore, if\n\nP\n\nl\u2208K\\{k} (1\np\u2217k\nl\u2208K\\{k} (1\np\u2217k\n\n\u2212 p\u2217l )\n\n+\n\n\u03b3p\u2217i\n\nX\n\ni\u2208K\\{k}\n\n\u2212\n\np\u2217l ) h\n\n1\u2212\n\nX\n\ni\u2208K\\{k}\n\n\u2217\nl\u2208K\\{k} (1 \u2212 pl )\np\u2217k (1 \u2212 p\u2217k )\n\nQ\n\np\u2217i i\n.\n1 \u2212 p\u2217k\n\n(23)\n\n\u2217\nk\u2208K pk\n\n< 1, \u2200k \u2208 K, there exists some \u03b2 > 0 such that\nQ\n\u2217 h\nX\np\u2217i \u2217 i\nl\u2208K\\{k} (1 \u2212 pl )\n1\n\u2212\n\u2265 \u03b2, \u2200k \u2208 K.\np\u2217k\n1 \u2212 pk\n\n(24)\n\ni\u2208K\\{k}\n\nIf the stepsize \u03b3 satisfies 0 < \u03b3 < 1/\u03b2 , we have\nQ\n\u001a\n\u2217 h\nX\n\u03b3\nl\u2208K\\{k} (1 \u2212 pl )\nGP w\n1\n\u2212\nkJ k\u221e = max 1 \u2212\nk\u2208K\np\u2217k\n\ni\u2208K\\{k}\n\n\u001b\np\u2217i i\n\u2264 1 \u2212 \u03b3\u03b2 < 1.\n1 \u2212 p\u2217k\n\n(25)\n\nGP\nSince \u03c1(JGP ) \u2264 kJGP kw\nmust fall into the unit circle |\u03bb| < 1. Therefore,\n\u221e < 1, all the eigenvalues of J\n\np\u2217 is a stable CE. Similarly, by choosing w = [1, * * * , 1], we can show that, if\nX\n\ni\u2208K\\{k}\n\np\u2217k\n< 1, \u2200k \u2208 K,\n1 \u2212 p\u2217i\n\nand \u03b3 is sufficiently small, p\u2217 is also stable. \u0004\n\n(26)\n\n\f17\n\n2) Global Convergence: Similarly as in the previous subsection, we derive in the following theorem\na sufficient condition under which Algorithm 2 globally converges.\nK\nTheorem 5: Regardless of any initial value chosen for {p0k }K\nk=1 , if the parameters {ak }k=1 in the belief\n\nfunctions {s\u0303k }K\nk=1 satisfy\nX\n\ni\u2208K\\{k}\n\n1\n< 1, \u2200k \u2208 K,\nai\n\n(27)\n\nand the stepsize \u03b3 is sufficiently small, Algorithm 2 converges to a unique CE.\nProof : For the self-mapping function in (18), the elements of its Jacobian matrix JGP satisfy\n\uf8f1\n\uf8f2\n1 \u2212 \u03b3ak ,\nif i = k,\nGP\n=\nJik\nQ\n\uf8f3 \u2212\u03b3\n6 k.\nl\u2208K\\{i,k} (1 \u2212 pl ), if i =\n\n(28)\n\nConsider the induced distance by weighted l\u221e norm in the Euclidean space. We have\nGP w\nkpt \u2212 p\u0302t kw\nk\u221e * kpt\u22121 \u2212 p\u0302t\u22121 kw\n\u221e \u2264 kJ\n\u221e.\n\n(29)\n\nUsing w = (1/a1 , * * * , 1/aK ) for (29), we have\n\u001a\n\u001a\n\u0010\nX\nY \u03b3ak (1 \u2212 pl ) \u001b\nX\nGP w\nkJ k\u221e = max 1 \u2212 \u03b3ak +\n\u2264 max 1 \u2212 \u03b3ak 1 \u2212\nk\u2208K\nk\u2208K\nai\ni\u2208K\\{k} l\u2208K\\{i,k}\n\ni\u2208K\\{k}\n\n\u001b\n1\u0011\n. (30)\nai\n\nTherefore, if the condition in (27) is satisfied, there exists some \u03b2 > 0 such that\n\u0010\nX 1\u0011\n\u2265 \u03b2, \u2200k \u2208 K.\nak 1 \u2212\nai\n\n(31)\n\ni\u2208K\\{k}\n\nIf the stepsize \u03b3 satisfies 0 < \u03b3 < 1/\u03b2 , we have\n\u001a\n\u0010\nX\nGP w\nkJ k\u221e \u2264 max 1 \u2212 \u03b3ak 1 \u2212\nk\u2208K\n\ni\u2208K\\{k}\n\n\u001b\n1\u0011\n\u2264 1 \u2212 \u03b3\u03b2 < 1.\nai\n\n(32)\n\nTherefore, there exist a constant q \u2208 [0, 1) and a positive \u01eb, such that q = kJGP kw\n\u221e = 1 \u2212 \u01eb < 1 and\nt\u22121 \u2212 p\u0302t\u22121 kw . From the contraction mapping theorem [28], the self-mapping function\nkpt \u2212 p\u0302t kw\n\u221e \u2264 qkp\n\u221e\n\nin (18) has a unique fixed point and the sequence {pt }+\u221e\nt=0 converges to the unique fixed point. \u0004\nRemark 4: Compare Theorem 4 and 5 with Theorem 2 and 3. We can see that, given the same target\noperating point p or parameters {ak }K\nk=1 , Algorithm 2 exhibits similar properties in terms of local stability\nand global convergence, provided that its stepsize \u03b3 is sufficiently small. In other words, the limiting\nbehavior of these two distinct bio-inspired dynamic mechanisms are similar. However, we need to consider\nsome design trade-off for both algorithms and choose the desired learning algorithm based on the specific\nsystem requirements about the speed of convergence and the performance fluctuation. Generally speaking,\nthe best response learning algorithm converges fast, but it may cause temporary large fluctuations during\n\n\f18\n\nthe convergence process, which is not desirable for transporting constant-bit-rate applications. On the\nother hand, the gradient play learning algorithm with small stepsize will evolve smoothly at the cost of\nsacrificing its convergence rate.\n\nD. Alternative Interpretations of the Conjecture-based Learning Algorithms\nIn this section, we re-interpret the proposed algorithms using the the backoff mechanism model in which\nthe transmission probabilities change from time slot to time slot [37], which helps us to understand the\nkey difference between the proposed algorithms and 802.11 DCF. The superscript t in this subsection\nt as the events that node k transmits\nrepresents the numbering of the time slots. We define Tkt and T\u2212k\n\ndata at time slot t and any node in K\\{k} transmits data at time slot t, respectively. If ak > 1, the RHS\nof (7) equals to\n\npkt\u22121\n2\n\n+\n\nQ\n\nt\u22121\n)\ni\u2208K\\{k} (1\u2212pi\n\n2ak\n\n, and the best response update function in (7) can be rewritten as\n\n1\n1\n1\n1\nt\u22121\nt\u22121\nt\u22121\nt\u22121\nt\u22121\nt\u22121\n1{T\u2212k\n}+\nE{1{T\u2212k\n}+ (1+ )E{1{T\u2212k\n},\nptk = E{pt\u22121\n=1} |p\n=0} 1{Tkt\u22121 =0} |p\n=0} 1{Tkt\u22121 =1} |p\nk\n2\n2ak\n2\nak\n(33)\n\nwhere 1a is an indicator function of event a taking place, E{a|b} is the expected value of a given b,\nQ\nt\u22121\nt\u22121 } = 1 \u2212\nt\u22121\nE{1{Tkt\u22121 =1} |pt\u22121 } = pt\u22121\n=1} |p\ni\u2208K\\{k} (1 \u2212 pi ). According to (33), we\nk , and E{1{T\u2212k\ncan provide an alternative interpretation of the best-response update algorithm as follows. Consider the\n\nfollowing update algorithm. At each time slot, if node k observes that any other node attempts to transmit,\ni.e. it senses a busy channel, it reduces its transmission probability by a factor 1/2. If no transmission\nattempt is made by any node in the system, node k sets its transmission probability to be 1/2ak . Otherwise,\nif node k makes a successful transmission, it will transmit with probability 0.5(1 + 1/ak ) in the next\ntime slot. We can see that equation (33) characterizes the expected trajectory of this alternative update\nmechanism. Fig. 3 compares this new interpretation with the IEEE 802.11 DCF [12]. We can see that, node\nk behaves similarly in the best response algorithm and the IEEE 802.11 DCF if it made a transmission\n\nattempt in the previous time slot, and the fundamental difference between these two protocols is how\nnode k updates its action given that it did not transmit in the previous time slot. In DCF, ptk is kept the\nsame as pt\u22121\nk . However, as we can see from (33), the best response algorithm either performs back-off if\nthe channel is busy or sets ptk to be 1/2ak if the channel is free. This can also be intuitively interpreted\nfrom a biological perspective: if the channel is busy, meaning that other competitors are accessing the\nresource (transmission opportunity), the node can avoid a confrontation by becoming less aggressive (i.e.\nreducing its transmission probability); if on the other hand, the system is idle and the resource is wasted,\nthe node will consume the resource by increasing its transmission probability to 1/2ak .\n\n\f19\n\nRemark 5: Both Equation (5) and (33) intuitively explain the meaning of the algorithm parameters\nQ\n\u2217\n{ak }K\nk=1 . Note that the numerator of (5),\ni\u2208K\\{k} (1 \u2212 pi ), represents the probability that transmitter\nk experiences a contention-free environment at p\u2217 . The value of 1/ak , i.e. the ratio between node k's\n\ntransmission probability pk and its contention-free probability, indicates the \"aggressiveness\" of this\nparticular node at equilibrium. In addition, according to (33), the transmission probability 1/2ak also\nreflects node k's \"aggressiveness\" in selecting its transmission probability after it sensed a free channel.\nIt is straightforward to see the selection of {ak }K\nk=1 introduces some trade-off between the stability\nand throughput of the networks. First of all, large values of {ak }K\nk=1 refrain nodes from transmitting\nat a higher channel access probability, and hence, it stabilizes the system at the cost of reducing the\nthroughput. On the other hand, lowering {ak }K\nk=1 increases the nodes' transmission probability, which\nmay improve the throughput performance. However, it can cause the conditions in (8) and (19) to fail and\nthe system becomes unstable. Therefore, the problems which we will investigate in the next subsection\nare which part of the throughput region can be achieved with stable CE and how the nodes can adaptively\nupdate their {ak }K\nk=1 such that the system can attain efficient and stable operating points.\nBefore proceeding to the next subsection, similarly as for the best response algorithm, we present an\nreinterpretation of the gradient play. Equation (18) can be rewritten as\nt\u22121\nt\u22121\nt\u22121\nt\u22121\n} + [pt\u22121\n+ \u03b3(1 \u2212 ak pt\u22121\n}.\nptk = (1 \u2212 \u03b3ak )pt\u22121\n=1} |p\n=0} |p\nk E{1{T\u2212k\nk\nk )]E{1{T\u2212k\n\n(34)\n\nIf ak > 1, the interpretation of (34) is that at each time slot, if node k senses a busy channel, it reduces\nits transmission probability by a factor 1 \u2212 \u03b3ak , otherwise it increases its transmission probability by an\namount \u03b3(1 \u2212 ak pt\u22121\nk ). We can see that, this interpretation of the gradient play learning resembles the\nwell-known AIMD (Additive Increase Multiplicative Decrease) control algorithm, which has been widely\napplied in the context of congestion avoidance in computer networks due to its superior performance in\nterms of convergence and efficiency [29].\n\nE. Stability of the Throughput Region\nK\nThe results in the previous subsections describe the values of {pk }K\nk=1 and {ak }k=1 for which local\n\nstability and global convergence can be guaranteed in both Algorithm 1 and 2. This subsection directly\ninvestigates for both algorithms the stability of achievable operating points in the throughput region T .\nLemma 6: The Pareto boundary of the throughput region T is the set of all points \u03c4 = (\u03c41 , . . . , \u03c4K )\nQ\nP\nsuch that \u03c4k = pk i\u2208K\\{k} (1\u2212pi ) where p = (p1 , . . . , pK ) is a vector satisfying p > 0 and k\u2208K pk = 1;\n\nand each such \u03c4 is determined by a unique such p.\n\n\f20\n\nProof : See Theorem 1 in [30]. \u0004\nTheorem 7: Regardless of the number of nodes in the network, for any Pareto-inefficient operating point\n\u03c4 \u2217 in the throughput region T , there always exists a belief configuration {ak }K\nk=1 stabilizing Algorithm\n\n1 and 2, and achieve the throughput \u03c4 \u2217 . If K > 2, any Pareto-optimal operating point {p\u2217k }K\nk=1 in T\nthat satisfies p\u2217k > 0, \u2200k \u2208 K is a stable CE for Algorithm 1 and 2.\nP\nProof : From Theorem 2, we know that k\u2208K pk < 1 is sufficient to guarantee that the corresponding\nCE is stable. Therefore, it is equivalent to check that any Pareto-inefficient operating point \u03c4 \u2217 can be\nP\nachieved with a joint transmission probability p\u2217 \u2208 P satisfying k\u2208K p\u2217k < 1.\nDefine the throughput region\n\nT (t) = {(u1 (p), . . . , uK (p))| \u2203 p \u2208 P,\n\nX\n\npk \u2264 t},\n\n(35)\n\nk\u2208K\n\nin which an additional constraint\n\nP\n\nk\u2208K pk\n\n\u2264 t is imposed. We denote the Pareto boundary of T (t) as\n\n\u2202T (t) = {\u03c4\u03c4 | \u2204 \u03c4 \u2032 \u2208 T (t) such that \u03c4k\u2032 \u2265 \u03c4k , \u2200k \u2208 K and \u03c4k\u2032 > \u03c4k , \u2203k \u2208 K}.\n\n(36)\n\nFollowing the proof of Lemma 6, we can draw a similar conclusion: all the points on \u2202T (t) satisfy\nP\nk\u2208K pk = t. By Lemma 6, \u2202T (1) corresponds to the Pareto boundary of T . Note that \u2202T (0) = 0. In\n\nother words, varying t from 1 to 0 will cause \u2202T (t) to continuously shrink from the Pareto boundary\nof the throughput region T to the origin 0. Therefore, for any Pareto inefficient point \u03c4 \u2217 \u2208 T , there\nexists 0 \u2264 t\u2032 < 1 such that \u03c4 \u2217 lie on \u2202T (t\u2032 ), i.e. \u03c4 \u2217 can be achieved with an action profile p\u2217 satisfying\nP\n\u2217\nk\u2208K pk = t < 1.\n\nTo prove the Pareto boundary are stable CE when K > 2, we need to show that the eigenvalues\n\nBR\nand JGP are all inside the unit circle of the complex plane [28],\n{\u03benBR }N\nn=1 of the Jacobian matrices J\n\ni.e. |\u03ben | < 1, \u2200n \u2208 N . Take the best response dynamics for example. To determine the eigenvalues of\n\n\f21\n\nJBR , we have\n...\n\np2\n2(1\u2212p1 )\n\np1\n2(1\u2212p2 )\n\u03be \u2212 12\n\n..\n.\n\n...\n..\n.\n\npK\n2(1\u2212p1 )\n\npK\n2(1\u2212p2 )\n\n...\n\n\u03be\u2212\nBR\n\ndet(\u03beI \u2212 J\n\n)=\n\n1\n2\n\n..\n.\n\n\u03be\u2212\n=\n\n\u03be\u2212\n\n\u2212\n\npK\np1\n\n\u03be\u2212\n\n\u2212\n\n\u0001\np1\n2(1\u2212p1 )\n\n\u2212\n\npK\n2(1\u2212p1 )\n1\n2\n\n\u03be\u2212\n\n..\n.\n\n=\n\n..\n.\n\n\u03be\u2212\n\n1\n2\n\np2\np1\n\np2\n2(1\u2212p1 )\n\np1\n2(1\u2212pK )\np2\n2(1\u2212pK )\n\n1\n2\n\n\u0001\n\n1\n2\n\n\u03be\u2212\n\n1\n2\n\np1\n2(1\u2212p2 )\np2\n1\n2 \u2212 2(1\u2212p2 )\n\n\u0001\n\n...\n\np1\n2(1\u2212pK )\n\n..\n.\n\n...\n..\n.\n\n0\n..\n.\n\n0\n\n... \u03be \u2212\npk\n2(1\u2212pk )\npk\n1\n\u03be\u2212 2 \u2212 2(1\u2212p\nk)\n\n\u0002\nP\n* 1+ K\nk=1\n\np2\n2(1\u2212p1 )\n\n\u2212\n\npK\n2(1\u2212p1 )\n\n\u2212\n\np2\np1\n\n\u03be\u2212\n\n2\n\npK\np1\n\n\u03be\u2212\n\n1\n2\n\n..\n.\n\n\u0001\n1\n\n\u0003\n\n1\n2\n\n\u2212\n\npK\n2(1\u2212pK )\n\n0\n\u03be\u2212\n\n1\n2\n\n\u0001\n\np2\n\u2212 2(1\u2212p\n2)\n..\n.\n\n...\n\n0\n\n...\n..\n.\n\n0\n..\n.\n\n... \u03be \u2212\n\n0\n\n1\n2\n\n\u2212\n\n.\npK\n2(1\u2212pK )\n\nTherefore, we can see that, the eigenvalues of JBR are the roots of\n\u0002\n\nDenote f (\u03be) =\n\n1+\n\nPK\n\nk=1\n\nK\nX\nk=1\n\npk\nK\n\u0003 Y\n2(1\u2212pk )\n*\npk\n1\n2 \u2212 2(1\u2212pk )\nk=1\n\n\u03be\u2212\n\npk\n2(1\u2212pk )\npk\n\u03be\u2212 12 \u2212 2(1\u2212p\nk)\n\n\u03be\u2212\n\n\u0001\npk\n1\n\u2212\n= 0.\n2 2(1 \u2212 pk )\n\n(37)\n\n. First, we assume that pi 6= pj , \u2200i, j . Without loss of generality,\n\nconsider p1 < p2 < * * * < pK . In this case, the eigenvalues of JBR are the roots of f (\u03be) = \u22121. Note that\nf (\u03be) is a continuous function and it strictly decreases in (\u2212\u221e, 12 +\n* * * , ( 12 +\nlim\u03be\u2192( 1 +\n2\n\npK\u22121\n1\n2(1\u2212pK\u22121 ) , 2\npk\n)+\n2(1\u2212pk )\n\n+\n\npK\n2(1\u2212pK ) ),\n\n( 21 +\n\npK\nand ( 2(1\u2212p\n, +\u221e). We also have lim\u03be\u2192( 1 +\nK)\n2\n\np1\n1\n2(1\u2212p1 ) , 2\n\npk\n)\u2212\n2(1\u2212pk )\n\n+\n\np2\n2(1\u2212p2 ) ),\n\nf (\u03be) = \u2212\u221e,\n\nf (\u03be) = +\u221e, n = 1, 2, * * * , K , and lim\u03be\u2192\u2212\u221e f (\u03be) = lim\u03be\u2192+\u221e f (\u03be) = 0. Therefore,\n\nthe roots of f (\u03be) = \u22121 lie in (\u2212\u221e, 21 +\npK\n2(1\u2212pK ) )\n\np1\n2(1\u2212p1 ) ),\n\np1\n2(1\u2212p1 ) ),\n\n( 12 +\n\np1\n1\n2(1\u2212p1 ) , 2\n\n+\n\np2\n2(1\u2212p2 ) ),\n\n* * * , ( 21 +\n\npK\u22121\n1\n2(1\u2212pK\u22121 ) , 2\n\n+\n\nrespectively.\n\nFor the operating points on the Pareto boundary, we have\nf (0) = \u22121, i.e. \u03be1 = 0. Therefore,\n\nTo see \u03beK\n\nPK\n\nk=1 pk\n\n= 1. It is easy to verify that\n\npK\u22121\n1\npK\n1\n, +\n).\n\u03c1(JBR ) = max |\u03bek | = \u03beK \u2208 ( +\nk\n2 2(1 \u2212 pK\u22121 ) 2 2(1 \u2212 pK )\nP\n< 1 for 0 \u2264 p1 < p2 < * * * < pK and K\nk=1 pk = 1. We differentiate two cases:\n\n1) If pK \u2264 0.5, we have \u03beK <\n\n1\n2\n\n+\n\npK\n2(1\u2212pK )\n\n\u2264 1;\n\n(38)\n\n\f22\n\n2) If pK > 0.5, we have\n( 21 +\n\npK\u22121\n1\n2(1\u2212pK\u22121 ) , 2\n\n+\n\n1\n2\n\npK\n2(1\u2212pK ) ),\n\n+\n\npK\u22121\n2(1\u2212pK\u22121 )\n\n< 1 and\n\n1\n2\n\n+\n\npK\n2(1\u2212pK )\n\n> 1. Since f (\u03be) strictly decreases in\n\nwe have \u03c1(JBR ) < 1 if and only if f (1) < \u22121. In fact,\n\nK\nX\n\nK\u22121\nX\n\u0001\npk\n1\n1\nf (1) \u2212 (\u22121) =\n+1=\n\u2212\n< 0.\npk\nPK\u22121\n1 \u2212 2pk\n1 \u2212 2pk\n1 \u2212 2 m=1 pm\nk=1\nk=1\n\n1\n<\nThe inequality holds because 1\u22122p\nk\nPK\np2 < * * * < pK , and k=1 pk = 1.\n\n1\u22122\n\nP1K\u22121\nm=1\n\npm\n\n(39)\n\nfor k = 1, 2, . . . , K \u2212 1 when pK > 0.5, 0 \u2264 p1 <\n\nSecond, we consider the cases in which there exists pi = pj for certain i, j . Suppose that {pk }K\nk=1\n\ntake M discrete values \u03ba1 , * * * , \u03baM and the number of {pk }K\nk=1 that equal to \u03bam is nm . In this case,\nEquation (37) is reduced to\npk\n2(1\u2212pk )\npk\n1\n2 \u2212 2(1\u2212pk )\n\nM\n\u0003 Y\n\u0001nm\n1\n\u03bam\n*\n\u03be\u2212 \u2212\n= 0.\n2 2(1 \u2212 \u03bam )\n\u03be\n\u2212\nm=1\nk=1\nPM\nHence, equation f (\u03be) = \u22121 has K + M \u2212 k=1 nm roots in total, and \u03be = 12 +\nK\nX\n\u0002\n1+\n\n(40)\n\u03bam\n2(1\u2212\u03bam )\n\nis a root of\n\nmultiplicity nm \u2212 1, \u2200m. All these roots are the eigenvalues of matrix JBR . Similarly, the remaining roots\n\n\u03baM \u22121\n\u03ba1\n\u03ba1\n\u03ba2\n\u03baM\n), ( 21 + 2(1\u2212\u03ba\n, 1 + 2(1\u2212\u03ba\n), * * * , ( 21 + 2(1\u2212\u03ba\n, 1 + 2(1\u2212\u03ba\n).\nof f (\u03be) = \u22121 lie in (\u2212\u221e, 12 + 2(1\u2212\u03ba\n1)\n1) 2\n2)\nM \u22121 ) 2\nM)\nPK\nIf K > 2, k=1 pk = 1 is still sufficient to guarantee that f (1) < \u22121. Therefore, |\u03bekBR | < 1, \u2200k \u2208 K. \u0004\n\nFig. 4 compares the throughput performance among various game-theoretic solution concepts, including\n\nNash equilibria, Pareto frontier, locally stable conjectural equilibria, and globally convergent conjectural\nequilibria, in random access games. As proven in Theorem 7, Fig. 4 shows that, the entire space spanning\nbetween the Nash equilibria and Pareto frontier essentially consists of stable conjectural equilibria. In\naddition, as discussed in Remark 3, the set of globally convergent CE is a subset of the stable CE set.\nIn practice, it is more important to construct algorithmic mechanisms to attain the desirable CE that\noperate stably and closely to the Pareto boundary. To this end, we develop an iterative algorithm and\nsummarize it as Algorithm 3. Specifically, this algorithm has an inner loop and an outer loop. The inner\nloop adopts either Algorithm 1 or 2 to achieve convergence for fixed {ak }K\nk=1 . This algorithm initializes\nak > |K| such that it initially globally converges. After converging to a stable CE, the outer loop adaptively\nK\nadjusts {ak }K\nk=1 until desired efficiency is attained. The outer loop updates {ak }k=1 in the multiplicative\nPK\nt K\nmanner due to two reasons. First, reducing {ak }K\nk=1 pk and\nk=1 individually increases {pk }k=1 and\n\nhence, moves the operating point towards the Pareto boundary. Second, multiplying {ak }K\nk=1 by the same\n\ndiscount factor can maintain weighted fairness among different nodes. Both reasons will be analytically\nexplained in the Section IV. It is also worth mentioning that individual nodes can measure the Pareto\nefficiency in a fully distributed manner during the outer loop iteration. For example, individual nodes can\nestimate the other nodes' transmission probabilities {ptk }K\nk=1 based on its local observation and figure out\n\n\f23\n\nwhether the current operating point is close to the Pareto boundary by calculating\n\nP\n\nt\nk\u2208K pk\n\n[16]. When\n\nthe network size grows bigger, individually estimating different nodes' transmission probabilities becomes\nchallenging. An alternative solution is that individual nodes can instead monitor their common observation\nP\nof the aggregate throughput k\u2208K utk and terminate the update of {ak }K\nk=1 once the aggregate throughput\nstarts to decrease. Next, we discuss several implementation issues regarding Algorithm 3. First, it is not\n\nnecessary that all the nodes update their parameters {ak }K\nk=1 synchronously. However, these nodes need\nto maintain the same update frequency, e.g. each node will update its parameter after a certain number of\ntimeslots or seconds. As long as \u03b4 is small, the performance gap between the actual CE and the intended\none will not be large. Moreover, in order to guarantee fairness, the new incoming nodes need to know\nthe real-time parameters of the old nodes in the same traffic class. This initialization only needs to be\ndone once, when the new nodes enter the cell by tracking the evolution of the transmission probabilities\nof the nodes in the same traffic class.\nAlgorithm 3 : Adaptive Distributed Learning Algorithm for Random Access\n1: Initialize: stepsize \u03b3 and \u03b4 , the transmission probability p0k \u2208 [0, 1], and the parameter ak > |K| in\nnode k's belief function, \u2200k \u2208 K.\n2:\n3:\n\nprocedure\nouter loop: For each node k, ak \u2190 ak (1 \u2212 \u03b4).\n\n4:\n\ninner loop: Locally at each node k, use Algorithm 1 or 2 to update ptk .\n\n5:\n\nuntil it converges.\n\n6:\n7:\n\nt\nk\u2208K pk\n\n\u2248 1.\n\nH ETEROGENEOUS N ETWORKS\n\nAND\n\nuntil the aggregate throughput is maximized or\nend procedure\n\nIV. E XTENSIONS\n\nTO\n\nP\n\nA D - HOC N ETWORKS\n\nIn this section, we first investigate how users with different qualify-of-service requirements should\ninitialize their belief functions and interact in the heterogeneous network setting and show that the\nconjecture-based approaches approximately achieve the weighted fairness. Furthermore, we discuss how\nthe single-cell solution can be extended to the general ad-hoc network scenario, where only the devices\nwithin a certain neighborhood range will impact each other's throughput.\n\n\f24\n\nA. Equilibrium Selection for Heterogeneous Networks\nConsider a network with N > 1 different classes of nodes. Let \u03c6n denote the parameter that class-n\nnodes choose for their conjectured utility functions (i.e. the parameter ak if node k belongs to class-n)\nand Fn denote the set of nodes that set their algorithm parameters to be \u03c6n , 1 \u2264 n \u2264 N . At equilibrium,\nthe transmission probabilities of the same class of nodes are equal, denoted as p\u0303n . Before we proceed, we\nfirst define the weighted fairness for the random access game [32]. For each traffic class n, we associate\nwith a positive weight \u03c7n . Then the weighted fairness intended for the random access game satisfy\n\u2200i, j \u2208 {1, 2, * * * , N }, \u2200s \u2208 Fi , \u2200s\u2032 \u2208 Fj ,\n\nE{1{T\u2212s\u2032 =0} 1{Ts\u2032 =1} }\nE{1{T\u2212s =0} 1{Ts =1} }\n=\n,\n\u03c7i\n\u03c7j\n\n(41)\n\nwhich means that the probability of an successful transmission attempt for traffic class n is proportional\nto its weight \u03c7n . By simple manipulation, we have the equivalent form for equation (41) [32]:\n\u2200i, j \u2208 {1, 2, * * * , N },\n\nF\nF\npW\npW\nj\ni\n=\n.\nF )\u03c7\nF )\u03c7\n(1 \u2212 pW\n(1 \u2212 pW\ni\nj\ni\nj\n\n(42)\n\n\u2217 K\nRecall that Theorem 1 showed how to choose {ak }K\nk=1 given a desired operating point {pk }k=1 such\n\nthat it is a CE. The following theorem indicates the quantitative relationship between the chosen algorithm\nN\nparameters {\u03c6n }N\nn=1 , the sizes of different classes {Fn }n=1 , and the resulting steady-state transmission\n\nprobabilities {p\u0303n }N\nn=1 . More importantly, it also shows that if the network size is large, the conjecturebased algorithms approximately achieve weighted fairness.\nTheorem 8: Suppose that \u03c6n \u2265 2, \u22001 \u2264 n \u2264 N . The achieved steady-state transmission probabilities\n{p\u0303n }N\nn=1 are given by\n\nr\n\u0013\n\u0012\n1\n4\u033a\np\u0303n =\n,\n1\u2212 1\u2212\n2\n\u03c6n\n\n(43)\n\nwhere \u033a satisfies\nr\n\u0013 \u0015\nN \u0014\u0012\n4\u033a |Fn |\n1 Y\n.\n(44)\n1+ 1\u2212\n\u033a= K\n2\n\u03c6n\nn=1\nQ\nQ\nProof : As shown in Theorem 1, a\u2217k p\u2217k = i\u2208K\\{k} (1 \u2212 p\u2217i ). Denote \u033a = i\u2208K (1 \u2212 p\u0303i ). Therefore, we\n\nobtain\n\n\u03c6n p\u0303n (1 \u2212 p\u0303n ) = \u033a, \u2200 1 \u2264 n \u2264 N.\n\n(45)\n\nSince \u03c6n > 2, we have p\u0303n < 0.5. Such a root of the quadratic equation in (45) is given in (43). Note\nQ\nthat \u033a = i\u2208K (1 \u2212 p\u0303i ). Substituting (43) into this equality, we get (44).\nWe can verify that a unique \u033a satisfying the equality in (44) exists if \u03c6n \u2265 2, \u22001 \u2264 n \u2264 N . This is\n\nbecause the RHS of (44) is feasible for \u033a \u2264 min1\u2264n\u2264N {\u03c6n }/4 and it is a strictly decreasing function\n\n\f25\n\nin \u033a. Meanwhile, the LHS of (44) is strictly increasing on \u033a \u2208 [0, min1\u2264n\u2264N {\u03c6n }/4]. Note that when\n\u033a = min1\u2264n\u2264N {\u03c6n }/4,\n\nLHS of (44) = min\n\n1\u2264n\u2264N\n\n\u03c6n\n1\n\u2265 \u2265 RHS of (44).\n4\n2\n\n(46)\n\nif \u03c6n \u2265 2. Therefore, a unique \u033a \u2208 [0, min1\u2264n\u2264N {\u03c6n }/4] satisfies (44) exists. \u0004\nRemark 6: There are several intuitions and observations that we can obtain from Theorem 8. First,\nthe multiplicative decreasing update in Algorithm 3 aims to move the operating points towards Pareto\nboundary. A quantitative approximation between the steady-state transmission probability p\u0303n and the\nalgorithm parameter \u03c6n of each traffic class can be derived if a large number of nodes coexist. Since\n\u033a \u2192 0 when |Fn | is large, using the Taylor expansion, p\u0303n can be approximated as \u033a/\u03c6n , i.e. the steady-\n\nstate transmission probability p\u0303n decays as the inverse first power of parameter \u03c6n that indicates the\n\"aggressiveness\" of traffic class n. Finally, we also observe from (45) that, if |Fn | is large, p\u0303n \u2192 0 and\n1 \u2212 p\u0303n \u2248 1. Therefore,\n\u2200i, j \u2208 {1, 2, * * * , N }, \u03c6i p\u0303i (1 \u2212 p\u0303i ) = \u03c6j p\u0303j (1 \u2212 p\u0303j ) \u21d2\n\n\u03c6i p\u0303i\n\u03c6j p\u0303j\n\u2248\n.\n1 \u2212 p\u0303i\n1 \u2212 p\u0303j\n\n(47)\n\nEquation (47) indicates that Algorithm 1 and 2 approximately achieve weighted fairness given in (42)\nwith weight \u03c7n = 1/\u03c6n . Moreover, it is worth mentioning that the weighted fairness is purely an implicit\nby-product of the conjecture-based approach and it can be sustained with stability. Therefore, Algorithm\n3 chooses to multiply {ak }K\nk=1 by the same discount factor 1 \u2212 \u03b4 such that the weighted fairness can be\nmaintained.\nB. Extension to Ad-hoc Networks\nConsider a wireless ad-hoc network with a set K = {1, 2, . . . , K} of distinct node pairs in Fig. 5.\nEach link (node pair) consists of one dedicated transmitter and one dedicated receiver. We assume that\nthe transmission of a link is interfered from the transmission of another link, if the distance between the\nreceiver node of the former and the transmitter node of the latter is less than some threshold Dth [9]\n[15]. For any node i, we define Ii \u2286 K as the set of nodes whose transmitters cause interference to the\nreceiver of node i and Oi \u2286 K as the set of nodes whose receivers get interfered from the transmitter of\nnode i. For example, in Fig. 5, I1 = {K} and O1 = {2, K}. Then, the throughput of node i is\nuk (p) = pk\n\nY\n\n(1 \u2212 pi ).\n\n(48)\n\ni\u2208Ik\n\nIn this scenario, the state, namely, the contention measure signal, can be redefined according to sk =\nQ\ni\u2208Ik (1\u2212pi ). Applying the conjecture-based approach, we have the following conjectured utility function\n\n\f26\n\nfor node k:\nutk (s\u0303tk (pk ), pk ) = pk\n\nhY\n\ni\u2208Ik\n\ni\nt\u22121\n)\n.\n(1 \u2212 pt\u22121\n)\n\u2212\na\n(p\n\u2212\np\nk\nk\ni\nk\n\n(49)\n\nParallel to the theorems proven in Section III-B and C, we have the following theorems on the stability\nand convergence of conjecture-based bio-inspired learning algorithms in ad-hoc networks. These theorems\ncan be shown similarly as in Section III, and hence, the proofs are omitted.\n1) Stability and Convergence:\nTheorem 9: For any p\u2217 = (p\u22171 , . . . , p\u2217K ) \u2208 P , if\nX\n\np\u2217i < 1, \u2200k \u2208 K,\n\nor\n\ni\u2208Ik\n\ni\u2208Ok \u222a{k}\n\np\u2217\n\nX\n\np\u2217k\n< 1, \u2200k \u2208 K,\n1 \u2212 p\u2217i\n\n(50)\n\nis a stable CE for Algorithm 1 and Algorithm 2 with sufficiently small \u03b3 .\nK\nTheorem 10: Regardless of any initial value chosen for {p0k }K\nk=1 , if the parameters {ak }k=1 in the\n\nbelief functions {s\u0303k }K\nk=1 satisfy\nak > |Ok |, \u2200k \u2208 K,\n\nor\n\nX 1\n< 1, \u2200k \u2208 K,\nai\n\n(51)\n\ni\u2208Ik\n\nAlgorithm 1 and Algorithm 2 with sufficiently small \u03b3 converge to a unique CE.\nRemark 7: We observe that the sufficient conditions in Theorem 9 and 10 are more relaxed compared\nwith the theorems in Section III. As opposed to the single-cell case, the mutual interference is reduced\nin ad-hoc networks due to the large scale geographical distance, therefore, these nodes can potentially\nimprove their throughput by increasing their transmission probabilities while still maintaining the local\nstability as well as global convergence.\nRemark 8: In ad-hoc networks, the parameters {ak }K\nk=1 can be determined in a distributed fashion\nsuch that the sufficient conditions in Theorem 10 are satisfied. For example, consider the symmetric\ncase where transmitter i interferes with receiver j if and only if transmitter i can receive signals from\nreceiver j . Each transmitter can listen to the channel and estimate |Ok | by intercepting the ACK packets\nsent by the receivers of the nodes in set Ok . An alternative distributed solution is that each transmitter\nP\nbroadcasts its parameter ak , and receiver k calculates i\u2208Ik a1i and notifies the nodes in set Ik to adjust\ntheir parameters accordingly.\n\n2) Stability of the Throughput Region: We also extend the stability analysis of the throughput region\nfrom the single-cell scenario to the ad-hoc networks. The following lemma explicitly describes the Pareto\nfrontier of the throughput region.\n\n\f27\n\nLemma 11: The Pareto boundary of the throughput region T can be characterized as the set of points\n\u03c4 = (\u03c41 , . . . , \u03c4K ) optimizing the weighted proportional fairness objective [33]:\nmax\np\u2208P\n\nin which \u03c4k = pk\n\nQ\n\ni\u2208Ik (1 \u2212 pi )\n\nX\n\n\u03c9k log\u03c4k ,\n\n(52)\n\nk\u2208K\n\nfor all possible sets of positive link \"weights\" {\u03c9k }K\nk=1 . Specifically, for\n\n\u2032\na particular weight combination {\u03c9k }K\nk=1 , the optimal p is given by\n\np\u2032k =\n\n\u03c9k +\n\nProof : See [33] for details.\n\n\u03c9\nPk\n\ni\u2208Ok\n\n\u03c9i\n\n.\n\n(53)\n\nBased on Lemma 11, we derive in the following theorem the necessary and sufficient condition under\nwhich a particular Pareto-efficient operating point is a stable CE for Algorithm 1. Similar results can be\nderived for Algorithm 2 with sufficiently small \u03b3 .\nTheorem 12: Suppose p\u2217 = (p\u22171 , . . . , p\u2217K ) \u2208 P satisfies (53) and maximizes the problem in (52). The\nelements of the Jacobi matrix J at p\u2217 satisfy\n\uf8f1\n1\n\uf8f4\n\uf8f4\nif i = k,\n\uf8f4\n2,\n\uf8f2\n\u2217\npi\nJik =\nif k \u2208 Ii ,\n\u2212 2(1\u2212p\n\u2217 ,\n\uf8f4\nk)\n\uf8f4\n\uf8f4\n\uf8f3\n0,\notherwise.\n\n(54)\n\nIf \u03c1(J) < 1, p is a stable CE for Algorithm 1.\n\nRemark 9: Theorem 12 generalizes the result in Theorem 7 from the single-cell scenario to the ad-hoc\nnetworks. Consider the l1 norm for J at p. We have\nkJk1 = max\nk\u2208K\n\n\u03c9k +\n\n\u03c9\nPk\n\ni\u2208Ok \u03c9i\n\n+\n\nX\n\ni\u2208Ok\n\n\u03c9i +\n\n\u03c9\nPi\n\nj\u2208Oi\n\n\u03c9j\n\n.\n\n(55)\n\nIn the single-cell case, Ok = K\\{k}, \u2200k \u2208 K, and kJk1 equals to 1 for any Pareto-optimal operating point.\nTherefore, any Pareto inefficient operating point can be achieved with stability due to \u03c1(J) \u2264 kJk1 < 1.\nHowever, in ad-hoc networks, the form of the Jacobi matrix J depends on the actual network topology\nand it is difficult to bound the spectral radius for a generic setting using certain matrix forms, such as l1\nnorm or l\u221e norm. Alternatively, according to Theorem 12, we will numerically test the stability of the\nPareto-optimal operating points in the simulation section.\nV. N UMERICAL S IMULATIONS\nIn this section, we numerically compare the performance of the existing 802.11 DCF protocol, the\nP-MAC protocol [32] and the proposed algorithms in this paper.\n\n\f28\n\nWe first illustrate the evolution of transmission probabilities of Algorithm 1 and 2. We simulate a singlecell network of 5 nodes. For each node, the initial transmission probability p0k is uniformly distributed in\n[0, 1] and ak is uniformly distributed between 5 and 10. The stepsize in the gradient play is \u03b3 = 0.02. Fig.\n\n6 compares the trajectory of the transmission probability updates in both Algorithm 1 and 2 in a single\nQ\nrealization, under the assumption that node k can perfectly estimate the probability j\u2208K\\{k} (1 \u2212 pj ),\n\n\u2200k \u2208 K. The best response update converges in around 8 iterations and the gradient play experiences a\n\nmore smooth trajectory and the same equilibrium is attained after 35 iterations. In addition, to illustrate\nhow individual nodes can adaptively adjust their algorithm parameters and improve their throughput, we\nsimulate a scenario with two traffic classes. Each traffic class consists of 5 nodes and the initial algorithm\nparameters of class 1 and 2 are \u03c61 = 30 and \u03c62 = 60, respectively. The discount factor in Algorithm\n3 is \u03b4 = 0.05. The blue dotted curve in Fig. 7 indicates that the operating point moves towards the red\nPareto boundary until the outer loop detects that the desired efficiency is reached.\nIn practice, packet transmission over wireless links, e.g. IEEE 802.11 WLANs, involves extra protocol\noverheads, such as inter-frame space and packet header. Assuming these realistic communication scenarios, we compare various performance metrics, including throughput, fairness, convergence, and stability,\nbetween our proposed conjecture-based algorithms, the P-MAC protocol in [32], and the IEEE 802.11\nDCF. To evaluate these metrics, the physical layer parameters need to be specified. In the simulation, we\nassume that each wireless device operates at the IEEE 802.11a PHY mode-8, and the key parameters\nare summarized in Table I. We assume no transmission errors and the RTS/CTS mechanism is disabled.\nThe aggregate network throughput can be calculated using Bianchi's model [35]\nPs Ld\n,\n(56)\n(1 \u2212 Ptr )Tslot + Ps Ts + Ptr Tc \u2212 Ps Tc\nP\nQ\n|Fn |\u22121 *\n|Fn | is the probability that a transmission\nwhere Ps = N\nn=1 |Fn | * pn * (1 \u2212 pn )\nm6=n (1 \u2212 pm )\nQ\n|Fn | is the probability that at least one\noccurring on the channel is successful, Ptr = 1 \u2212 N\nn=1 (1 \u2212 pn )\nT =\n\ntransmission attempt happens, Ts is the average time of a successful transmission, and Tc is the average\nduration of a collision. The detailed derivation of Ts and Tc using the given network parameters in Table\nI can be found in [32] [35]. The parameters in P-MAC are set according to [32]. The contention window\nsizes in the IEEE 802.11 DCF are CWmin = 16 and CWmax = 1024. In Algorithm 3, individual nodes\nmonitor the aggregate throughput to determine whether to adjust the parameter ak . The numerical results\nare obtained using a MAC simulation program in [35]. Our comparison results are summarized as follows.\nFirst, the throughput of the three algorithms is compared. We vary the total number of nodes K from\n4 to 50, in which \u2308K/2\u2309 nodes carry class-1 traffic and the remaining nodes carry class-2 traffic. The\n\n\f29\n\npositive weights of class-1 and class-2 are \u03c71 = 1 and \u03c72 = 0.5. The initial parameters in Algorithm\n3 are chosen to be \u03c61 = 3K/\u03c71 and \u03c62 = 3K/\u03c72 . As shown in Fig. 8, both the conjecture-based\nalgorithm and P-MAC significantly outperform the IEEE 802.11 DCF. The IEEE 802.11 DCF achieves\nthe lowest throughput, because the lack of adaptation mechanism of the contention window size causes\nmore frequent packet collisions as the number of nodes increases. Surprisingly, the performance of the\nconjectural equilibrium attained by Algorithm 3 achieves the maximum achievable throughput. It also\noutperforms P-MAC, because P-MAC uses approximation to derive closed-form expressions for the\ntransmission probabilities of different traffic class.\nNext, we evaluate the short-term fairness of different protocols using the quantitative fairness index\nintroduced in [32]\nF=\n\n\u03bc(Tk /\u03c7n )\n, k \u2208 Fn\n\u03bc(Tk /\u03c7n ) + \u03c3(Tk /\u03c7n )\n\n(57)\n\nin which Tk denote the throughput of node k that belongs to traffic class n, and \u03bc and \u03c3 are, respectively,\nthe mean and the standard deviation of Tn /\u03c7n over all the active data traffic flows. We simulate a\ntransmission duration of 3 minutes. The stage duration in Algorithm 3 is set as 50 successful transmissions.\nAs shown in Fig. 9, we can see that Algorithm 3 and P-MAC are comparable in their fairness performance\nand the achieved fairness index is always above 0.95 regardless of the network configuration. On the\nother hand, the fairness performance of 802.11 DCF is much poorer than the previous two algorithms\nbecause the DCF protocol provides no fairness guarantee.\nLast, in order to compare the convergence and the stability of different protocols for time-varying\ntraffic, we simulate a network in which the number of active nodes fluctuates over time. In order to cope\nwith traffic fluctuation, we slightly modify the outer loop in Algorithm 3. Once some nodes join or leave\nQ\nthe network (this can be detected either by tracking the contention signal k\u2208K (1 \u2212 pk ) or estimating\nthe total number of nodes in the network [36]), the adaptation of ak is activated. Specifically, if more\nnodes join the network, ak \u2190 ak (1 + \u03b4), otherwise, ak \u2190 ak (1 \u2212 \u03b4). At the beginning, |F1 | = |F2 | = 25.\nAt stage 200, 15 class-1 and 15 class-2 nodes join the network. These nodes leave the network at the\n400th stage. The algorithm parameter ak is updated every 5 stages and the stepsize in the gradient\nplay is \u03b3 = 0.003. Fig. 10 and Fig. 11 show the variation of the transmission probabilities for both\ntraffic classes and the expected accumulative throughput over time. P-MAC does not converge due to the\nlack of feedback control, which agrees with the observation about the instability of P-MAC reported in\n[13]. In addition, the optimal transmission probabilities computed by P-MAC and the conjecture-based\nalgorithms are different under the same network parameters because of the approximation used in P-MAC.\n\n\f30\n\nAs shown in Fig. 10, nodes deploying P-MAC transmit with a higher probabilities than the conjecturebased algorithms, which creates a more congested environment. As a result, the accumulative throughput\nachieved by P-MAC is slightly lower than the optimal throughput. In contrast, the conjecture-based\nalgorithms enable the nodes adaptively tune their parameters ak to maximize the network throughput\nwhile maintaining the weighted fairness as well as the system stability. As shown in Fig. 10 and Fig.\n11, during stage [200,300] and [400,470], both the best response and the gradient play autonomously\nadapt their parameter ak until it converges to the optimal operating point. As discussed before, the best\nresponse learning converges faster than the gradient play learning. To give a quantitative measure of\nthe stability, the standard deviations of the expected accumulative throughput in Fig. 11 for different\nExpected\nalgorithms satisfy \u03c3(TPExpected\n) \u2248 7 and the actual achieved accumulative throughput\n\u2212M AC )/\u03c3(TBIO\nActual\nsatisfy \u03c3(TPActual\n\u2212M AC )/\u03c3(TBIO ) \u2248 2. We can see that, thanks to the inherent feedback control mechanism,\n\nboth bio-inspired learning algorithm exhibit superior stability performance than P-MAC.\nWe also simulate the evolution trajectory of the transmission probabilities of the proposed Algorithm 1\nand the algorithm in [16]. Both algorithms are essentially the best-response based algorithms. Specifically,\nwe consider a network with K = 6. The peak data rates for different nodes are r1 = 6, r2 = 36, r3 = 9,\nr4 = 12, r5 = 18, and r6 = 54, all in Mbps. We apply the algorithm in [16] to solve the following\n\nnetwork utility maximization problem:\nmax\np\u2208P\n\nX\n\nk\u2208K\n\n1 \u0002\nrk pk\n1\u2212\u03b1\n\nY\n\n\u00031\u2212\u03b1\n,\n(1 \u2212 pj )\n\n(58)\n\nj\u2208K\\{k}\n\nin which \u03b1 = 2. The optimal solution corresponds to the belief configuration a1 = 2.03, a2 = 3.93, a3 =\n2.32, a4 = 2.55, a5 = 2.97, and a6 = 4.74. The trajectory of both algorithms are shown in Fig. 12. We can\n\nsee that, both algorithms converge very fast and oscillate around the neighborhood to the optimal solution\nafter several iterations. However, as we discussed before, the algorithm in [16] requires individual nodes\nto decode all the received packet headers and estimate the transmission probabilities of the other nodes\nindividually, which introduces a great internal computational overhead when the network size grows large.\nIn contrast, nodes deploying Algorithm 1 only have to estimate the probability of having a free channel\nwithout the need of decoding all the packets, which substantially reduces their computational efforts.\nWe simulate the performance of the proposed algorithms in an ad-hoc network contained in a 100m \u00d7\n100m square area. Nodes in the square area are placed in the random manner. Two nodes can interfere\n\nwith each other if their distance is no more than 40m, i.e. Dth = 40m. We simulate three scenarios with\nthe node numbers K = {10, 20, 40}. The Pareto-efficient point that we select is the associated operating\npoint with the link weighted vector \u03c9k = 1, 1 \u2264 k \u2264 K/2, and 0.5, K/2 < k \u2264 K in (53). We can see\n\n\f31\n\nfrom Fig. 13 that, \u03c1(JBR ) \u2264 1 holds for all the simulated topologies. As shown in Fig. 13, in some\nrealizations, \u03c1(JBR ) = 1, and hence, the associate operating points are not asymptotically stable. This\nwill occur when two nodes interfere with each other and they do not interfere and are not interfered\nby the remaining nodes in the entire ad-hoc network. On the other hand, the stability improves as the\nnumber of nodes increases. As long as the density of nodes is sufficiently large, the stability of the\nconjecture-based algorithm on the Pareto-efficient operating point can be achieved. Fig. 14 and Fig. 15\nshow the evolution of transmission probabilities and accumulative throughput for the IEEE 802.11 DCF\nand Algorithm 1 in a 10-node ad-hoc network with a randomly generated topology. The trajectory of the\nIEEE 802.11 DCF is obtained using the model in [12]. The parameter ak in Algorithm 1 is chosen to be\n|Ok |. The intuition behind is that, if |Ok | = 0, node k can transmit at the maximal probability without\n\ninterfering with any node. On the other hand, if |Ok | is large, node k should backoff adequately such that\nthe reciprocity can be established. As shown in the figures, Algorithm 1 converges faster and achieves\nhigher throughput than DCF. Similar results have been observed in the other simulated topologies.\nVI. C ONCLUSION\nIn this paper, we propose distributed learning solutions that enable autonomous nodes to improve their\nthroughput performance in random access networks. It is well-known that whenever biological entities\nbehave selfishly and myopically, a tragedy of commons might take place, which has also been observed\nin the context of random access control. Hence, we investigate whether forming internal belief functions\nand learning the impact of various actions can alter the interaction outcome among these intelligent nodes.\nSpecifically, two bio-inspired learning mechanisms are proposed to dynamically update individual nodes'\ntransmission probabilities. It is analytically proven that the entire throughput region essentially consist\nof stable conjectural equilibria. In addition, we prove that the conjecture-based approach achieves the\nweighted fairness for heterogeneous traffic classes and extend the distributed learning solutions to ad-hoc\nnetworks. Simulation results have shown that the proposed algorithms achieve significant performance\nimprovement against existing protocols, including the IEEE 802.11 DCF and the P-MAC protocol, in\nterms of not only fairness and throughput but also convergence and stability. A potential future direction\nis to investigate how to detect and prevent misbehavior for these bio-inspired solutions.\nR EFERENCES\n[1] S. Haykin, \"Cognitive Radio: Brain-empowered wireless communications\", IEEE J. Selected Areas in Commu., vol. 23,\npp. 201-220, 2005.\n\n\f32\n\n[2] F. Dressler and I. Carreras, Advances in Biologically Inspired Information Systems - Models, Methods, and Tools, Studies\nin Computational Intelligence (SCI), vol. 69, Berlin, Heidelberg, New York, Springer, 2007.\n[3] T. Suda, T. Itao, and M Matsuo, \"The Bio-Networking Architecture: The Biologically Inspired Approach to the Design of\nScalable, Adaptive, and Survivable/Available Network Applications,\" in The Internet as a Large-Scale Complex System,\nthe Santafe Institute Book Series, Oxford University Press, 2005.\n[4] R. Dawkins, The Selfish Gene, 2nd ed., United Kingdom: Oxford University Press, 1989.\n[5] J. M. Smith, Evolution and the Theory of Games, Cambridge: Cambridge University Press, 1982.\n[6] D. Fudenberg and D. Levine, The Theory of Learning in Games, Cambridge, MA: MIT Press, 1999.\n[7] M. Nowak, \"Five Rules for the Evolution of Cooperation,\" Science, vol. 314, pp. 1560-1563, 2006.\n[8] E. Friedman and S. Shenker. \"Learning and Implementation on the Internet\", Manuscript. New Brunswick: Rutgers\nUniversity, Department of Economics, 1997. (available at http://citeseer.ist.psu.edu/eric98learning.html)\n[9] C. Long, Q. Zhang, B. Li, H. Yang, and X. Guan, \"Non-Cooperative Power Control for Wireless Ad Hoc Networks with\nRepeated Games\", IEEE J. Select. Areas Commun., vol. 25, pp. 1101-1112, Aug, 2007.\n[10] F. Fu and M. van der Schaar,\"Learning to Compete for Resources in Wireless Stochastic Games\", IEEE Trans. Veh. Tech.,\nto appear.\n[11] Y. Jin and G. Kesidis, \"Equilibria of a noncooperative game for heterogeneous users of an Aloha networks\", IEEE\nCommun. Lett., vol. 6, no. 7, pp. 282-284, July 2002.\n[12] J. Lee, A. Tang, J. Huang, M. Chiang, and A. R. Calderbank, \"Reverse-engineering MAC: A non-cooperative game\nmodel\", IEEE J. Select. Areas Commun., vol. 25, no. 6, pp. 1135-1147, Aug. 2007.\n[13] T. Cui, L. Chen, and S. H. Low, \"A Game-Theoretic Framework for Medium Access Control\", IEEE J. Select. Areas\nCommun., vol. 26, no. 7, pp. 1116-1127, Sep. 2008.\n[14] \u010cagalj, S. Ganeriwal, I. Aad, and J. P. Hubaux, \"On selfish behavior in CSMA/CA networks\", in Proc. IEEE Infocom,\npp. 2513-2524, Mar. 2005.\n[15] J. Lee, M. Chiang, and R. A. Calderbank, \"Utility-optimal random-access control\", IEEE Trans. Wireless Commun., vol.\n6, no. 7, pp. 2741-2751, July 2007.\n[16] A. Mohsenian-Rad, J. Huang, M. Chiang, and V. Wong, \"Utility-Optimal Random Access: Optimal Performance Without\nFrequent Explicit Message Passing\", IEEE Trans. on Wireless Commu., vol. 8, no. 2, 898-911, Feb. 2009.\n[17] R. T. B. Ma, V. Misra, and D. Rubenstein, \"An Analysis of Generalized Slotted-Aloha Protocols\", IEEE/ACM Trans.\nNetworking, accepted for future publication.\n[18] M. P. Wellman and J. Hu, \"Conjectural equilibrium in multiagent learning,\" Machine Learning, vol. 33, pp. 179-200,\n1998.\n[19] C. Figui\u00e8res, A. Jean-Marie, N. Qu\u00e9rou, and M. Tidball, Theory of Conjectural Variations, World Scientific Publishing,\n2004.\n[20] S. G. Massaquoi, \"Modeling the function of the cerebellum in scheduled linear servo control of simple horizontal planar\narm movements,\" Ph.D. dissertation, MIT, Cambridge, MA, 1999.\n[21] S. Jo, \"A neurobiological model of the recovery strategies from perturbed walking,\" BioSystems, vol. 90, no. 3, pp.\n750-768, 2007.\n[22] U. Dieckmann and R. Law, \"The dynamical theory of coevolution: a derivation from stochastic ecological processes\",\nJournal of Mathematical Biology, vol. 34, pp. 579-612, 1996.\n\n\f33\n\n[23] P. Taylor and T. Day, \"Evolutionary stability under the replicator and the gradient dynamics\", Evolutionary Ecology, vol.\n11, pp. 579-590, 1997.\n[24] L. Edelstein-Keshet, Mathematical Models in Biology, Random House, New York, 1988.\n[25] A. Jean-Marie and M. Tidball, \"Adapting behaviors through a learning process\", Journal of Economic Behavior and\nOrganization, vol. 60, pp. 399-422, 2006.\n[26] R. Myerson, Game Theory, Harvard University Press, 1991.\n[27] R. A. Horn and C. R. Johnson, Matrix Analysis, Cambridge, U.K. : Cambridge Univ. Press, 1991.\n[28] A. Granas and J. Dugundji, Fixed Point Theory, New York: Springer-Verlag, 2003.\n[29] D. Chiu and R. Jain, \"Analysis of the Increase/Decrease Algorithms for Congestion Avoidance in Computer Networks\",\nJournal of Computer Networks and ISDN, vol. 17, no. 1, pp. 1-14, June 1989.\n[30] J. Massey and P. Mathys, \"The collision channel without feedback\", IEEE Trans. Inform. Theory, vol. 31, no. 2, pp.\n192-204, 1985.\n[31] D. P. Bertsekas and J. N. Tsitsiklis, Parallel and Distributed Computation. Englewood Cliffs, New Jersey: Prentice Hall,\n1997.\n[32] D. Qiao and K. G. Shin, \"Achieving efficient channel utilization and weighted fairness for data communications in IEEE\n802.11 WLAN under the DCF\", Proc. IWQoS 2002, pp. 227-236, May 2002.\n[33] P. Gupta and A. L. Stolyar, \"Optimal Throughput Allocation in General Random-Access Networks\", Proc. CISS 2006,\npp. 1254-1259, Mar. 2006.\n[34] IEEE 802.11a, Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) specifications: Highspeed Physical Layer in the 5 GHz Band, Supplement to IEEE 802.11 Standard, Sep. 1999.\n[35] G. Bianchi, \"Performance Analysis of the IEEE 802.11 Distributed Coordination Function,\" IEEE J. Selected Areas in\nCommu., vol. 18, no. 3, pp. 535-547, Mar. 2000.\n[36] G. Bianchi and I. Tinnirello, \"Kalman Filter Estimation of the Number of Competing Terminals in an IEEE 802.11\nNetwork,\" Proc. of IEEE Infocom, 2003.\n[37] T. Nandagopal, T. E. Kim, X. Gao and V. Bharghhavan, \"Achieving MAC layer fairness in wireless packet networks,\"\nProc. ACM Mobicom, 2000.\n[38] K. J. Astrom and T. Hagglund, PID Controllers: Theory, design and tuning. Instrument society of America, 2nd edition,\n1995.\n[39] J. S. Simonoff, Smoothing Methods in Statistics, Springer Series in Statistics. Springer-Verlag New York, 1996.\n\n\f34\n\n2\n\n1\n\nK\n\nK\n\n1\n2\n\nFig. 1.\n\nSystem model of a single cell.\n\n\u0083\n\u0084\n\n\u0001 \u0002\u0003\u0004\u0005 \u0006\b\u0007\n\n{vu \u0080 mno pqr |w k}\u0081x i~y jl\nzt \u007f\u0082s\n\n\u0018\u0019\u001a\u001b\u001c\u001d\n\u001e\u001f !\"#\n$%&'()*\n\n\u0086\u0087\u0088\u0089\u008a\u008b\u008c\u008d\n+,-./0123456\n\n\u000e\u000f\u0010\u0011 \u0012\u0013\u0014\u0015\u0016\u0017\n\nBCDEFGHIJK LMNOPQRSTUV\nX ]>\n`Z ^ a ?@[A <W _ \\Y =\n\nfhd bge c\n789: ;\nFig. 2.\n\nAn illustration of the distributed learning process.\n\n\u008e\u008f\u0090 \u0091\u0092\u0093\u0094 \u0095 \u0096\u0097\u0098\u0099\u009a\u009b\u009c\u009d\u009e\n\u03bc\u00b6*\n\u009f\u00a1\n\u00a2\u00a3\u00a4\u00a5\u00a6\n\u00a7 \u0308\u00a9a\u00ab\n\u00ac-\u00ae \u0304\u00b0\u00b123 \u0301\n\nFig. 3.\n\no\u00bb1\u20444\n\n\u00c8AE\u00c4 \u00cd \u00c9\u00c7\u00c5 \u00cc\u00bf \u00c0\u00c1 \u00c2\u00ca\u00cb\u00c3\n\u0006\u0002\n\u0007\u0003 \u00fd \u00fe \u00ff \u0001\b\n\n\u00d7\u00d5\u00d3 \u00dc \u00d8\u00d6\u00d4 \u00db\u00ce \u00cf\u00d0 \u00d1\u00d9\u00da\u00d2\n\n\u00ea\u00e8\u00e7 \u00ee \u00dd\u00dess\u00e0\u00e1 \u00ef \u00e2\u00e3 \u00eb\u00e9 \u00e4 \u00e5\u00ec\u00edae\n\n\u00f8\u00f6\u00f5 \u00fc \u00f0\u00f1\u00f2\u00f9\u00f7 \u00f3\u00fa\u00fb\u00f4\n\n\u0004\n\n1\u204423\u20444\n\n \u03271\n\n\u0005\n\n0/. 5 1 )*+\n\n,234 -\n\n\u0010\n\u0011\u0019\n\u0014\u0012 \u001a \u0015\u0013\n\n\"\u001e ( #!\u001f '\u001b\n\n\u000e\u0016\u0017\u0018 \u000f\n\n\u001c$%& \u001d\n\nComparison between the best response learning and the IEEE 802.11 DCF (P max is specified in the DCF protocol).\n\n\f35\n\n9\n\n8\n:;<= >?@ABCDEFG\nHIJKLM NOPQRSTU\nVWXYZ[\\ ]^_`ab\ncdefghijklm nopqrstuvw\nxyz{|}~\u007f \u0080\u0081\u0082\u0083\u0084 \u0086\u0087\u0088\u0089\n\u008a\u008b\u008c\u008d\u008e\u008f\u0090\u0091\u0092\u0093\u0094 \u0095\u0096\u0097\u0098\u0099\u009a\u009b\u009c\u009d\u009e\n\n7\n6\n\nFig. 4.\n\nComparison among different solution concepts.\n\nTABLE I\nIEEE 802.11 A PHY MODE -8 PARAMETERS\n\nParameters\n\nValue\n\nDuration of an Idle Slot (Tslot )\n\n9 \u03bcs\n\nDuration of PHY Header (TP HY )\n\n20 \u03bcs\n\nSIFS Time (TSIF S )\n\n16 \u03bcs\n\nDIFS Time (TDIF S )\n\n34 \u03bcs\n\nPropagation Delay (Td )\n\n1 \u03bcs\n\nMAC Header (LM AC )\n\n28 octets\n\nPacket Payload Size (Ld )\n\n2304 octets\n\nACK Frame Size (LACK )\n\n14 octets\n\nData Rate (Rt )\n\n54 Mbps\n\n\f36\n\n\u00a5\u00a6\u00a7\n\u00ab\u00ac-\n\n\u009f \u00a1\n\n\u00b123\n\u00a2\u00a3\u00a4\n\u00ae \u0304\u00b0\n\n \u0308\u00a9a\n\nFig. 5.\n\nSystem model of ad hoc networks.\n0.8\nBest response, node 1\nBest response, node 2\nBest response, node 3\nBest response, node 4\nBest response, node 5\nGradient Play, node 1\nGradient Play, node 2\nGradient Play, node 3\nGradient Play, node 4\nGradient Play, node 5\n\n0.7\n\nTransmisson Probability\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n\nFig. 6.\n\n0\n\n5\n\nDynamics of Algorithms 1 and 2.\n\n10\n\n15\n\n20\nStage\n\n25\n\n30\n\n35\n\n40\n\n\f37\n\n0.07\nTrajectory of Algorithm 3\nPareto boundary\n0.06\n\nThroughput of Class 2\n\n0.05\n\n0.04\n\n0.03\n\n0.02\n\n\u03c61/\u03c62=1:2, \u03b4=0.05\n\n0.01\n\n0\n0.01\n\n0.02\n\n0.03\n\n0.04\n\n0.05\n\n0.06\n\n0.07\n\n0.08\n\n0.09\n\n45\n\n50\n\nThroughput of Class 1\n\nFig. 7.\n\nThe trajectory of Algorithm 3.\n\n36\n35\n34\nOptimal throughput\nConjectural\u2212based algorithms\nP\u2212MAC\nIEEE 802.11 DCF\n\nAccumulative throughput (Mbps)\n\n33\n32\n31\n30\n29\n28\n27\n26\n25\n\nFig. 8.\n\n5\n\n10\n\n15\n\n20\n\n25\n30\nNumber of nodes\n\n35\n\n40\n\nComparison of the accumulative throughput in the IEEE 802.11 DCF, P-MAC, and conjecture-based algorithms. Error\n\nbars correspond to the standard deviation of the mean of the 100 measurements sampled at each point. The error bars in the\nremaining figures are as in this figure.\n\n\f38\n\n1.1\n\n1.05\n\n1\n\nFairness index\n\n0.95\nUpper bound\nConjectural\u2212based algorithms\nP\u2212MAC\nIEEE 802.11 DCF\n\n0.9\n\n0.85\n\n0.8\n\n0.75\n\n0.7\n\n0.65\n\n0.6\n\nFig. 9.\n\n5\n\n10\n\n15\n\n20\n\n25\n30\nNumber of nodes\n\n35\n\n40\n\n45\n\n50\n\nComparison of the achieved fairness of the IEEE 802.11 DCF, P-MAC, and Algorithm 3.\n\n0.02\nP\u2212MAC, Class 1\n0.018\n\nP\u2212MAC, Class 2\nGradient play, Class 1\n\n0.016\nGradient play, Class 2\n\nTransmission Probability\n\n0.014\n\n0.012\n\n0.01\n\n0.008\n\n0.006\n\n0.004\n\n0.002\n\n0\n\nFig. 10.\n\n0\n\n100\n\n200\n\n300\nStage\n\n400\n\nThe dynamics of the transmission probabilities in P-MAC and Algorithm 3.\n\n500\n\n600\n\n\f39\n\n36\n\n35.5\n\nExpected accumulative throughput (Mbps)\n\n35\n\n34.5\n\n34\n\n33.5\nP\u2212MAC\n33\nGradient Play\n32.5\n\n32\n\n31.5\n\n31\n\nFig. 11.\n\n0\n\n100\n\n200\n\n300\nStage\n\n400\n\n500\n\n600\n\nThe dynamics of the accumulative throughput in P-MAC and Algorithm 3.\n\n0.25\n\np\n\n1\n\nTransmission Probabilities\n\np3\n0.2\np\n\n4\n\np\n\n5\n\n0.15\n\np\n\n2\n\n0.1\np\n\n6\n\n0.05\nAlgorithm in [16]\nAlgorithm 1\n0\n\nFig. 12.\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\nStage\n\nComparison between Algorithm 1 and the algorithm in [16].\n\n60\n\n70\n\n80\n\n90\n\n100\n\n\f40\n\n1\n\n0.9\n\n0.8\n\ncumulative probability\n\n0.7\n\n0.6\nK=40\n0.5\nK=20\n0.4\nK=10\n0.3\n\n0.2\n\n0.1\n\n0\n0.5\n\n0.55\n\n0.6\n\n0.65\n\n0.7\n\n0.75\n\n0.8\n\n0.85\n\n0.9\n\n0.95\n\n1\n\n40\n\n45\n\n50\n\n\u03c1(JBR)\n\nFig. 13.\n\nCumulative distribution function of \u03c1(JBR ) in ad-hoc networks.\n\n0.5\n\n0.45\nIEEE 802.11 DCF\n0.4\nAlgorithm 1\n\nTransmission Probabilities\n\n0.35\n\n0.3\n\n0.25\n\n0.2\n\n0.15\n\n0.1\n\n0.05\n\n0\n\nFig. 14.\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\nStage\n\n30\n\n35\n\nTransmission probabilities of Algorithm 1 and the IEEE 802.11 DCF in ad-hoc networks.\n\n\f41\n\n120\n\n110\n\nAccumulative throughput (Mbps)\n\n100\n\n90\nAlgorithm 1\nIEEE 802.11 DCF\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n20\n\nFig. 15.\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\nStage\n\n30\n\n35\n\n40\n\n45\n\nAccumulative throughput of Algorithm 1 and the IEEE 802.11 DCF in ad-hoc networks.\n\n50\n\n\f"}