{"id": "http://arxiv.org/abs/0710.0465v1", "guidislink": true, "updated": "2007-10-02T09:02:35Z", "updated_parsed": [2007, 10, 2, 9, 2, 35, 1, 275, 0], "published": "2007-10-02T09:02:35Z", "published_parsed": [2007, 10, 2, 9, 2, 35, 1, 275, 0], "title": "The Loudest Event Statistic: General Formulation, Properties and\n  Applications", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0710.1872%2C0710.5051%2C0710.1140%2C0710.5508%2C0710.3612%2C0710.1669%2C0710.3106%2C0710.3695%2C0710.5110%2C0710.4714%2C0710.2959%2C0710.5101%2C0710.0372%2C0710.1570%2C0710.0270%2C0710.4347%2C0710.5141%2C0710.1379%2C0710.4765%2C0710.0897%2C0710.3571%2C0710.0124%2C0710.2771%2C0710.5251%2C0710.0131%2C0710.1482%2C0710.2498%2C0710.0847%2C0710.0957%2C0710.2653%2C0710.1115%2C0710.5200%2C0710.5176%2C0710.0986%2C0710.3775%2C0710.4858%2C0710.2688%2C0710.0575%2C0710.0420%2C0710.0465%2C0710.2602%2C0710.0591%2C0710.3105%2C0710.4326%2C0710.0859%2C0710.3726%2C0710.4299%2C0710.4890%2C0710.1272%2C0710.3303%2C0710.0094%2C0710.0168%2C0710.3547%2C0710.0456%2C0710.3404%2C0710.3330%2C0710.4193%2C0710.4100%2C0710.5082%2C0710.1880%2C0710.4941%2C0710.1603%2C0710.1584%2C0710.0799%2C0710.5336%2C0710.2593%2C0710.0702%2C0710.2024%2C0710.0113%2C0710.5894%2C0710.0647%2C0710.3079%2C0710.2918%2C0710.5310%2C0710.1576%2C0710.3611%2C0710.5037%2C0710.1182%2C0710.4902%2C0710.2787%2C0710.4144%2C0710.1496%2C0710.0477%2C0710.5057%2C0710.1580%2C0710.2838%2C0710.4357%2C0710.2025%2C0710.4173%2C0710.1520%2C0710.4649%2C0710.5780%2C0710.4429%2C0710.2841%2C0710.3724%2C0710.0748%2C0710.4337%2C0710.4415%2C0710.2261%2C0710.4532%2C0710.5701&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The Loudest Event Statistic: General Formulation, Properties and\n  Applications"}, "summary": "The use of the loudest observed event to generate statistical statements\nabout rate and strength has become standard in searches for gravitational waves\nfrom compact binaries and pulsars. The Bayesian formulation of the method is\ngeneralized in this paper to allow for uncertainties both in the background\nestimate and in the properties of the population being constrained. The method\nis also extended to allow rate interval construction. Finally, it is shown how\nto combine the results from multiple experiments and a comparison is drawn\nbetween the upper limit obtained in a single search and the upper limit\nobtained by combining the results of two experiments each of half the original\nduration. To illustrate this, we look at an example case, motivated by the\nsearch for gravitational waves from binary inspiral.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0710.1872%2C0710.5051%2C0710.1140%2C0710.5508%2C0710.3612%2C0710.1669%2C0710.3106%2C0710.3695%2C0710.5110%2C0710.4714%2C0710.2959%2C0710.5101%2C0710.0372%2C0710.1570%2C0710.0270%2C0710.4347%2C0710.5141%2C0710.1379%2C0710.4765%2C0710.0897%2C0710.3571%2C0710.0124%2C0710.2771%2C0710.5251%2C0710.0131%2C0710.1482%2C0710.2498%2C0710.0847%2C0710.0957%2C0710.2653%2C0710.1115%2C0710.5200%2C0710.5176%2C0710.0986%2C0710.3775%2C0710.4858%2C0710.2688%2C0710.0575%2C0710.0420%2C0710.0465%2C0710.2602%2C0710.0591%2C0710.3105%2C0710.4326%2C0710.0859%2C0710.3726%2C0710.4299%2C0710.4890%2C0710.1272%2C0710.3303%2C0710.0094%2C0710.0168%2C0710.3547%2C0710.0456%2C0710.3404%2C0710.3330%2C0710.4193%2C0710.4100%2C0710.5082%2C0710.1880%2C0710.4941%2C0710.1603%2C0710.1584%2C0710.0799%2C0710.5336%2C0710.2593%2C0710.0702%2C0710.2024%2C0710.0113%2C0710.5894%2C0710.0647%2C0710.3079%2C0710.2918%2C0710.5310%2C0710.1576%2C0710.3611%2C0710.5037%2C0710.1182%2C0710.4902%2C0710.2787%2C0710.4144%2C0710.1496%2C0710.0477%2C0710.5057%2C0710.1580%2C0710.2838%2C0710.4357%2C0710.2025%2C0710.4173%2C0710.1520%2C0710.4649%2C0710.5780%2C0710.4429%2C0710.2841%2C0710.3724%2C0710.0748%2C0710.4337%2C0710.4415%2C0710.2261%2C0710.4532%2C0710.5701&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The use of the loudest observed event to generate statistical statements\nabout rate and strength has become standard in searches for gravitational waves\nfrom compact binaries and pulsars. The Bayesian formulation of the method is\ngeneralized in this paper to allow for uncertainties both in the background\nestimate and in the properties of the population being constrained. The method\nis also extended to allow rate interval construction. Finally, it is shown how\nto combine the results from multiple experiments and a comparison is drawn\nbetween the upper limit obtained in a single search and the upper limit\nobtained by combining the results of two experiments each of half the original\nduration. To illustrate this, we look at an example case, motivated by the\nsearch for gravitational waves from binary inspiral."}, "authors": ["Rahul Biswas", "Patrick R. Brady", "Jolien D. E. Creighton", "Stephen Fairhurst"], "author_detail": {"name": "Stephen Fairhurst"}, "author": "Stephen Fairhurst", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/0264-9381/26/17/175009", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0710.0465v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0710.0465v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "11 pages, 8 figures", "arxiv_primary_category": {"term": "gr-qc", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "gr-qc", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0710.0465v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0710.0465v1", "journal_reference": "Class.Quant.Grav.26:175009,2009", "doi": "10.1088/0264-9381/26/17/175009", "fulltext": "The Loudest Event Statistic: General Formulation, Properties and Applications\nRahul Biswas, Patrick R. Brady, and Jolien D. E. Creighton\nUniversity of Wisconsin-Milwaukee, Milwaukee, WI 53201, USA\n\nStephen Fairhurst\n\narXiv:0710.0465v1 [gr-qc] 2 Oct 2007\n\nUniversity of Wisconsin-Milwaukee, Milwaukee, WI 53201, USA\nSchool of Physics and Astronomy, Cardiff University, Cardiff, CF2 3YB, United Kingdom and\nLIGO - California Institute of Technology, Pasadena, CA 91125, USA\nThe use of the loudest observed event to generate statistical statements about rate and strength has become\nstandard in searches for gravitational waves from compact binaries and pulsars. The Bayesian formulation of\nthe method is generalized in this paper to allow for uncertainties both in the background estimate and in the\nproperties of the population being constrained. The method is also extended to allow rate interval construction.\nFinally, it is shown how to combine the results from multiple experiments and a comparison is drawn between the\nupper limit obtained in a single search and the upper limit obtained by combining the results of two experiments\neach of half the original duration. To illustrate this, we look at an example case, motivated by the search for\ngravitational waves from binary inspiral.\n\nI.\n\nINTRODUCTION\n\nIn daily life, we often estimate the birth rate, the rate of automobile fatalities, or the rate of hurricanes in the Gulf. In\nthese cases, it is reasonably easy to determine when one event\nhas occurred and so the best estimate is usually taken to be the\nnumber of events divided by the observation time. As physicists and astronomers, we know this is a good estimator of\nthe rate of an underlying Poisson process. In these cases, the\nability to identify events with high confidence is central to the\ncorrectness of the rate estimate.\nWe can carry this method over to more complicated observational situations by allowing for false positives in our identification of events. Experiments are usually designed so that\nthe rate of real (foreground) events is higher than the rate of\nfalse positive (background) events. Hence a good estimate of\nthe rate is obtained by counting the number of events per unit\ntime, and making a small correction to allow for the false positives. This is the typical experimental method of estimating\nthe rate.\nIn both physics and astronomy, it is common to search for\nvery rare events in large data sets and we rely heavily on statistical methods to interpret these searches. In this paper, we\ndiscuss the problem of estimating the rate of these rare events.\nWhen real events are very rare or very weak, it is important\nto revisit the reasoning that underlies the standard approaches\nto estimating rates (and indeed other parameters). Here, we\nexplore the effects of incorporating information about quality\nof observed events into the estimate of event rate. One measure of quality might be the signal to noise of the events; the\nlouder an event, the more likely it is to be signal. Of course,\nmore complicated measures are also possible. We simply require a rank ordering such that a larger quality implies the\nevent is less likely to be background.\nA popular method of incorporating quality information is\nto fix a threshold, prior to looking at the data. The threshold is often chosen to give an acceptable rate of background\nevents in some qualitative sense. Then, the upper limit is determined by counting the number of events per unit time above\n\nthe chosen threshold and making a correction which allows for\nthe background. Central to this method is the prescription by\nwhich the final list of events are identified.\nThere are many alternative criteria that might be used to\ndetermine the sample of events in an experiment. We consider using the loudest event to estimate the rate. This method\nwas first introduced in gravitational-wave searches during the\nanalysis of data from a prototype instrument [1]; the method\nwas used to determine an upper limit on the rate of binary neutron star mergers in the Galaxy. Since then, the\nmethod has been used in a number of searches for gravitational waves [2, 3, 4, 5, 6, 7]. More details of this method\nof determining an upper limit are available in [8]. Related\nmethods have been discussed in the context of particle physics\nexperiments by Cousins [9] and Yellin [10].\nIn Sec. II, we present a general formulation of the loudest\nevent statistic [1, 8]. We adopt the Bayesian approach which\ngives a posterior distribution over physical parameters based\non the loudest event observed in an experiment. To provide a\nconcrete example, in Sec. III we specialize to the case of a single unknown rate amplitude multiplying a known distribution\nof events. Confidence intervals based on the loudest event\nposterior are discussed in Sec. IV. The approach we take is\nsometimes called a highest posterior density interval [11]. It\nprovides a unified approach giving an upper limit for a loudest event that is due to noise with high probability and a confidence interval (bounded away from zero) when the loudest\nevent is foreground with high probability. In real experiments\nthere are many systematic uncertainties; we discuss marginalization over uncertainties in Sec. V. Finally, we explain how\nto combine the results from multiple experiments using the\nloudest event method and show that the resulting upper limit is\nindependent of the order of the experiments. This discussion\nalso leads naturally to an investigation of the effect on an upper limit if a single search is split into two parts. In Sec. VII,\nwe make some general comments on the results obtained in\nthis paper. In Appendix A, we consider the application of a\nFeldman-Cousins unified approach to obtaining a frequentist\nupper limit using the loudest observed events. A comparison between the loudest event method and an event counting\n\n\f2\nmethod of obtaining an upper limit is given in Appendix B for\na toy problem.\nNotation: We use the following notation throughout this\npaper. The loudest event statistic variable is denoted x. The\nexperimentally measured values of a quantity are denoted by\na circumflex accent; e.g., the experimentally measured value\nof the loudest event statistic is given by x\u0302. Probability distributions and other quantities related to an experimental background appear with a subscripted 0; e.g., P0 (x) is the background probability distribution for the loudest event statistic.\nThe symbol B is used to describe the collective information\nabout the experimental background in conditional probability distributions that are contingent on this information; thus\nP (x|B) is the distribution of the loudest event statistic in an\nexperiment that includes a background.\nII.\n\nHowever, if the experiment can produce background events,\nthen the probability that there are no events, either foreground\nor background, louder than x is\nP (x|B) = P0 (x)e\u2212\u03bd(x)\n\nwhere we have used B to indicate that the probability depends\non the background and the factor P0 (x) is the probability of\nobtaining zero background events louder than x.\nThe mean number of events expected during the course of\nthe experiment, \u03bd(x), depends on the duration of the experiment, the rate of events, and the ability of the experiment to\ndetect events that occur. The sensitivity of the search is encoded in the efficiency which is the probability that an event\nwill have a loudness value greater than or equal to x. The efficiency depends on x as well as a set of parameters, collectively\ndenoted by \u03b8, that determine the detectability of a source. For\nexample, \u03b8 may include such things as the sky position, orientation, distance, etc., of an astrophysical source. We write\nthe efficiency as \u03b5(x, t, \u03b8). (The sensitivity of the experiment\nmay change with time; hence the explicit dependence on t in\nthe efficiency.) The rate of events depends on the parameters\n\u03b8 that describe the source population as well as on physical\nparameters, collectively denoted by \u03bc, that we are interested\nin measuring or constraining by means of the experiment. We\nwrite the rate of events as R(\u03b8, \u03bc). With this factorization,\nthe mean number of events expected can be expressed as\n\nGENERAL FORMULATION OF LOUDEST EVENT\nSTATISTIC\n\nConsider a search of experimental data for a rare Poisson\nprocess. The output of this search is a set of candidate events\nwhich have survived all cuts applied during the analysis. At\nfirst, suppose that all the events are foreground events. Assume that these events can be ranked according to a single\nparameter x, such as a signal-to-noise ratio, in such a way that\nthe probability that the search will detect an event increases\nwith increasing x. For simplicity we will call this parameter\nthe loudness parameter and we will say that the event with the\nlargest value of x is the loudest event. If the mean number\nof events expected during the course of the experiment with\nthe ranking statistic value above x is given by \u03bd(x), then the\nprobability of observing no events above a given value of x is\nP (x) = e\u2212\u03bd(x) .\n\n(2)\n\n\u03bd(x, \u03bc) =\n\nZ\n\n0\n\nT\n\ndt\n\nZ\n\nd\u03b8 \u03b5(x, t, \u03b8)R(\u03b8, \u03bc) ,\n\n(3)\n\nwhere T is the total observation time.\nWe can substitute our expression for the rate (3) into Eq. (2)\nto obtain the probability that there are zero events in the data\nwith a loudness statistic value greater than x as\n\n(1)\n\n( Z\nP (x|\u03bc, B) = P0 (x) exp \u2212\n\n0\n\nT\n\ndt\n\nZ\n\n)\n\nd\u03b8 \u03b5(x, t, \u03b8)R(\u03b8, \u03bc) .\n\n(4)\n\nFurthermore, the probability of the loudest event occurring between x and x + dx is given by p(x|\u03bc, B) dx where\nd\nP (x|\u03bc, B)\ndx \"\n#\n\u0013Z T Z\n\u0012\nd\u03b5(x, t, \u03b8)\nP0 (x)\n= p0 (x) 1 \u2212\nR(\u03b8, \u03bc) e\u2212\u03bd(x,\u03bc)\ndt d\u03b8\np0 (x)\ndx\n0\n\np(x|\u03bc, B) =\n\nand p0 (x) = dP (x)/dx. Notice that the probability distribution contains two factors: an exponential decay that is determined by the (foreground) rate of events and a shape factor\ncomprising two terms.\nAfter performing an experiment, we are interested in obtaining a distribution for the model parameters that govern the\n\n(5)\n\nrate. To do this, we calculate a Bayesian posterior distribution\nfor these parameters, \u03bc, given the observations. This distribution is denoted p(\u03bc|x\u0302, B), where x\u0302 is the value of the observed\nloudest event, and it is derived using Bayes' law:\np(\u03bc|x\u0302, B) = R\n\np(\u03bc) p(x\u0302|\u03bc, B)\nd\u03bc p(\u03bc) p(x\u0302|\u03bc, B)\n\n(6)\n\n\f3\nwhere p(\u03bc) is the prior probability distribution on the model\nparameters. In many circumstances, the parameters \u03bc may be\nfurther divided into a set of particular interest \u03bcI and others\nof less interest \u03bcII . By integrating Eq. (6) over the unwanted\nparameters \u03bcII , one obtains the posterior distribution\nR\nd\u03bcII p(\u03bcI , \u03bcII ) p(x\u0302|\u03bcI , \u03bcII , B)\nR\n. (7)\np(\u03bcI |x\u0302, B) =\nd\u03bc p(\u03bc) p(x\u0302|\u03bc, B)\n\nIn Sec. V we consider this procedure of marginalization over\nunwanted, or nuisance, parameters in more detail.\nTo bound the parameters of interest at a given confidence\nlevel \u03b1, one integrates Eq. (7) over some region \u03a9(\u03bcI ) such\nthat\nZ\nd\u03bc p(\u03bcI |x\u0302, B).\n(8)\n\u03b1=\n\u03a9(\u03bcI )\n\nIn general, the difficult part is selecting the region \u03a9(\u03bcI ), especially in more than one dimension. There are several ways\nto do this: for example, one could marginalize over all but\none of the parameters thus reducing the problem to a onedimensional integral; or select the smallest volume \u03a9(\u03bcI ) that\ngives the required probability. This is sometimes called a\nhighest posterior density interval [11]. In Sec. IV, we investigate the properties of this type of rate interval based on the\nloudest event method.\nIII.\n\nUPPER LIMIT ON UNKNOWN RATE AMPLITUDE\n\nWe have obtained the general expression for the posterior\nprobability distribution of the parameters \u03bc governing an astrophysical model based on an observed loudest event. In\npractice, the details of obtaining either a rate upper limit or\na confidence interval on the model parameters will depend\nupon the details of the astrophysical model and its dependence\nupon the variables \u03bc. In this section, we simplify to the situation where the rate is dependent upon a single parameter \u03bc,\nan overall unknown Poisson mean number of events, so that\n\u03bcf (\u03b8)\nR(\u03b8, \u03bc) =\nT\n\n(9)\n\nwhere T is the observation time and f (\u03b8) is the distribution\nof events as a function of \u03b8.\nWe can use this form of the rate to simplify the general expression for the posterior. To begin, we introduce the quantity\nZ\nZ\n1 T\n\u01eb(x) =\ndt d\u03b8 \u03b5(x, t, \u03b8)f (\u03b8)\n(10)\nT 0\nwhich can be regarded as an averaged detection efficiency:\nthe probability that a foreground event will have a loudness\nparameter greater than x. Then, the mean number of events\nwith ranking statistic above x is \u03bd(x) = \u03bc\u01eb(x), and (at least\nin principle) \u01eb(x) is known. The posterior distribution is determined by substituting Eqs. (9) into (3) and using Eqs. (5),\n(6), and (10) to obtain\np(\u03bc|\u01eb\u0302, \u039b\u0302) = R\n\np(\u03bc) p0 (x\u0302) (1 + \u03bc\u01eb\u0302\u039b\u0302)e\u2212\u03bc\u01eb\u0302\nd\u03bc p(\u03bc) p0 (x\u0302) (1 + \u03bc\u01eb\u0302\u039b\u0302)e\u2212\u03bc\u01eb\u0302\n\n(11)\n\nwhere the function \u039b(x) is given by\n\u039b(x) =\n\n\u0012\n\n\u22121 d\u01eb(x)\n\u01eb(x) dx\n\n\u0013\u0012\n\np0 (x)\nP0 (x)\n\n\u0013\u22121\n\n(12)\n\nand a hat over a function indicates evaluation at x\u0302. The quantity \u039b(x) is a measure of the relative probability of detecting\na single event with loudness parameter x versus such an event\noccurring due to the experimental background; in particular\n\u039b\u0302 \u2192 0 in the limit that the loudest event is definitely from the\nbackground and \u039b\u0302 \u2192 \u221e in the limit that the loudest event is\ndefinitely from the foreground. Note that if the possibility that\nthe loudest event could be from a background is ignored, the\nposterior distribution, p(\u03bc|\u01eb\u0302) \u221d \u03bc \u01eb\u0302 e\u2212\u03bc\u01eb\u0302 is peaked away from\nzero and vanishes as \u03bc \u2192 0; that is, the posterior distribution\nwill be inconsistent with zero foreground events.\nFor the rest of the paper we take a uniform prior except in\nSection VI in which we consider using the posterior from a\nfirst experiment as a prior for a second experiment. It should\nbe noted that only power law priors on the rate, including the\nuniform prior, do not introduce a timescale into the problem.\nPower laws with powers greater than -1 are needed to avoid a\nrequired low-rate cutoff, which again would introduce a natural timescale.\nLet us evaluate the upper limit making use of a uniform\nprior,\np(\u03bc) = const.\n\n(13)\n\nWhile this distribution is not normalizable, we can introduce\na cutoff at large \u03bc (well above the expected number of events\nduring the given experiment) in order to render it normalizable. Physically, this is a reasonable choice of prior if there is\nno information available about the expected value of \u03bc. Furthermore, the posterior distribution is insensitive to the value\nof the cutoff provided it is sufficiently large. For the uniform\nprior, the posterior distribution in Eq. (11) evaluates to\np(\u03bc|\u01eb\u0302, \u039b\u0302) =\n\n\u01eb\u0302\n1 + \u039b\u0302\n\n(1 + \u03bc\u01eb\u0302\u039b\u0302)e\u2212\u03bc\u01eb\u0302 .\n\n(14)\n\nIt is straightforward to show that the distribution in Eq. (11)\nwill be peaked away from zero if and only if \u039b\u0302 > 1; the mode\nof the distribution is\n\u001a\n0\n\u039b\u0302 \u2264 1\n(15)\n\u03bcpeak =\n(\u039b\u0302 \u2212 1)/\u039b\u0302\u01eb\u0302\n\u039b\u0302 > 1.\nIf \u039b\u0302 > 1 then one might take this as an indication of a nonzero rate. The extent to which this is true is explored in\nSec. IV.\nWe integrate Eq. (14) to obtain an upper limit at confidence\nlevel \u03b1 by solving\nZ \u03bc\n\u03b1 =\nd\u03bc\u2032 p(\u03bc\u2032 |\u01eb\u0302, \u039b\u0302)\n0\n\"\n#\n\u03bc\u01eb\u0302\u039b\u0302\n= 1\u2212 1+\ne\u2212\u03bc\u01eb(x\u0302)\n(16)\n1 + \u039b\u0302\n\n\f4\n\nFIG. 1: The posterior probability density function p(\u03bc|\u01eb\u0302, \u039b\u0302) on the\nPoisson mean \u03bc, assuming a uniform prior, and a fixed value \u01eb\u0302 of the\nefficiency evaluated at the loudest event x\u0302. The three curves correspond to three different values of \u039b\u0302: a) \u039b\u0302 = 0 (solid line), the loudest\nevent is definitely background and the distribution is exponential; b)\n\u039b\u0302 = 1 (dashed line), the transitional case where the the distribution\npeaks at zero but the derivative vanishes there; c) \u039b\u0302 \u2192 \u221e (dotted\nline), the loudest event is definitely from the foreground, the distribution is peaked away from zero.\n\nFIG. 2: The graph shows the behavior of the lower and upper boundaries of the interval, \u03bc1 and \u03bc2 respectively, as a function of \u039b\u0302. They\nare plotted for three different values of the confidence level \u03b1 of 80%,\n90% and 95%. The peak \u03bcpeak (solid line) approaches zero as \u039b\u0302 approaches one. As \u039b\u0302 \u2192 0, \u03bc2 agrees with the no foreground upper\nlimit treated above.\n\nfor \u03bc. It has been shown in [8] that setting the background\nto zero yields a conservative rate limit. In the Bayesian analysis, however, this yields a posterior probability distribution\nfunction which is peaked away from zero, and goes to zero\nat zero rate. This is clearly seen in Fig. 1 which shows the\nposterior distribution for three values of \u039b\u0302 including \u039b\u0302 \u2192 \u221e.\nThis is not surprising as we have neglected the background,\nin which case the existence of a loudest event implies a nonzero rate. Although this does not invalidate the upper limit,\nit does mean that the posterior would not serve as a suitable\nprior for a future experiment, as it is inconsistent with a zero\nrate. Nevertheless, it is still possible to obtain the upper limit\nas\n\nIn Sec. III, we derived the upper limit on the Poisson mean\n\u03bc based on the loudest event. However, in the case where the\nvalue of \u039b\u0302 is large (likely to be foreground), one might prefer to obtain a rate interval rather than an upper limit. For\na uniform prior, the mode \u03bcpeak of the posterior distribution\nfor the Poisson mean, given in Eq. (15), is non-zero whenever \u039b\u0302 > 1. Furthermore, in this case, \u03bcpeak asymptotes to\n1/\u01eb\u0302 for large values of \u039b\u0302 as one might expect. How significant an indicator of a non-zero rate is having the peak of rate\ndistribution be non-zero? In order to examine this idea more\nprecisely, we describe a method of constructing a rate interval using the loudest event statistic which provides a unified\napproach similar to Feldman and Cousins [12].\nAt some confidence level \u03b1, an interval is given by [\u03bc1 , \u03bc2 ]\nsuch that\nZ \u03bc2\np(\u03bc|\u01eb\u0302, \u039b\u0302) d\u03bc = \u03b1.\n(20)\n\n3.890\n\u03bc90%\n=\n.\nT\nT \u01eb(x\u0302)\n\n(17)\n\nSimilarly, the no-foreground limit can be obtained by taking\n\u039b\u0302 = 0. In this case, the 90% confidence limit tends to\n2.303\n\u03bc90%\n=\n.\nT\nT \u01eb(x\u0302)\n\n(18)\n\nFinally, we can consider the transitional case \u039b\u0302 = 1:\n\u03bc90%\n3.272\n=\n.\nT\nT \u01eb(x\u0302)\n\n(19)\n\nThe posterior distribution for the Poisson mean \u03bc for these\nthree possibilities is shown in Fig. 1.\n\nIV. CONFIDENCE INTERVAL ON UNKNOWN RATE\nAMPLITUDE\n\n\u03bc1\n\nA supplementary condition is required to select a unique interval: we identify the interval which minimizes |\u03bc2 \u2212 \u03bc1 |\nand contains the mode of the distribution (or zero for \u039b\u0302 < 1).\nThis condition clearly results in \u03bc1 = 0 for small values of\n\u039b\u0302, i.e. when the loudest event was likely to have arisen from\nthe background, the rate interval on the process we wish to\nconstrain includes zero rate.\nFor the uniform prior, the dependence of \u03bc1 , \u03bc2 and \u03bcpeak\non \u039b\u0302 are shown in Fig. 2. For \u039b\u0302 < 1, \u03bcpeak = 0 and consequently \u03bc1 = 0, as expected. However, for a significant range\nof \u039b\u0302 > 1, even though the rate distribution is peaked away\n\n\f5\nfrom zero, \u03bc1 = 0 indicating that (at the given confidence)\nthe rate interval still includes zero.\nWe can determine the precise value of \u039b\u0302 at which \u03bc1 becomes non-zero. For fixed \u039b\u0302 and \u01eb\u0302, Eq. (20) gives \u03bc2 implicitly as a function of \u03bc1 . The minimal interval condition is then\njust\nd[\u03bc2 (\u03bc1 ) \u2212 \u03bc1 ]\n= 0.\nd\u03bc1\n\n(21)\n\nSubstituting \u03bc1 = 0 into Eqs. (20) and (21), we obtain two\nequations which depend on \u03bc2 and \u039b\u0302. As an example, consider a 90% confidence interval. In this case, \u03bc1 becomes\nnon-zero, and the interval is bounded away from the origin, at\nvalue of \u039b\u0302 \u2243 11.56. This corresponds to \u03bc2 \u2243 3.807/\u01eb(x\u0302).\nThis result is in good agreement with the values obtained numerically in Fig. 2.\nIt is interesting to note that the 90% confidence interval still\nincludes zero for a wide range of \u039b\u0302 that give posterior distributions peaked away from zero. Figure 3 provides a concrete\nexample of the posterior when \u039b\u0302 = 10; the 90% confidence\ninterval still includes zero.\nV.\n\nMARGINALIZATION OVER UNCERTAINTIES\n\nThe expected mean number of detected events, \u03bd(x, \u03bc) in\nEq. (3), is dependent upon the frequency of events and their\namplitude distribution as well as the sensitivity of the search\nwhich is performed. In many cases, neither of these quantities\nwill be precisely known. For example, the efficiency of an\nexperiment is often measured via Monte-Carlo methods and\ntherefore suffers from uncertainties due to the finite number\nof trials. If we expand our understanding of the parameters\n\u03bc to further parametrize the uncertainties that can arise in the\nunderlying models and in measurements of efficiency, it is natural to marginalize over these uncertainties before computing\nan upper limit or rate interval. Just as the marginalization over\nuninteresting physical parameters [given in Eq. (7)] requires a\nprior distribution to be specified, the same is true of the uncertainties. This prior distribution would typically reflect the\nsystematic and statistical errors estimate for the experiment.\n\np(\u03bc|k, \u01eb\u0302, \u039b\u0302) =\n\n\u01eb\u0302\n\n\"\n\nA. Marginalization over uncertainties in \u01eb\n\nAs a particular example, consider the problem of the unknown rate amplitude presented in Sec. III and assume there\nis some uncertainty associated with the value of \u01eb\u0302 = \u01eb(x\u0302).\nTypically, one might choose the prior to be a normal distribution of the variate \u01eb peaked around the estimate value of \u01eb\u0302. It\nis, however, unphysical for the rate to be zero, so the distribution would need to be truncated. A more natural choice is a\nlog-normal distribution, for which the logarithm of \u01eb would be\nnormally distributed, thereby guaranteeing that \u01eb is positive.\nHere, we choose to make use of the \u03b3-distribution, primarily because it can be analytically integrated. The \u03b3distribution is similar in shape (for small standard deviation)\nto both the Gaussian and log-normal distributions and in addition takes only non-negative values. The \u03b3-distribution is\ngiven by\np(\u01eb; k, \u03b8) =\n\nIn order to examine the effect of marginalization, in Fig. 3\nwe plot the unmarginalized posterior distribution for \u039b\u0302 = 10\nalong with three distributions obtained by marginalizing over\ndifferent size systematic errors or uncertainties. These distri-\n\n(22)\n\nwhere \u0393(k) is the Gamma function. The mean is \u01ed = k\u03b8 while\nthe standard deviation is \u03c3\u01eb = k 1/2 \u03b8. Therefore, the fractional\nstandard deviation, \u03c3\u01eb /\u01ed = k \u22121/2 tends to zero in the limit as\nk \u2192 \u221e, whereby we expect to recover the unmarginalized\nresults. Note that the \u03b3-distribution is a distribution over the\ndomain \u01eb \u2208 [0, \u221e) while the efficiency actually takes values\nonly between 0 and 1. If k is large then the \u03b3-distribution is\nsharply peaked about its mean value and we can ignore this\nissue.\nThe marginalized distribution is calculated by integrating\nover \u01eb,\n\u0014Z \u221e\n\u0015\np(\u03bc|k, \u01eb\u0302, \u039b\u0302) =\nd\u01eb p(\u01eb; k, \u03b8) p(\u03bc|\u01eb, \u039b\u0302)\n. (23)\n0\n\n\u03b8=\u01eb\u0302/k\n\nwhere we set the value of the parameter \u03b8 so that the mean of\nthe \u03b3-distribution equals the observed efficiency \u01eb\u0302, and where\nk is a measure of the fractional uncertainty in the value of \u01eb\u0302.\nMaking use of the distribution (11) for the Poisson mean parameter and the expression for the \u03b3-distribution given above,\nwe obtain the marginalized distribution for integer values of k\n\n1\n\n(1 + \u039b\u0302) (1 + \u03bc\u01eb\u0302/k)k+1\n\nIn the limit that k \u2192 \u221e, we recover the previous distribution\nfor \u03bc as expected.\n\n\u01eb(k\u22121) e\u2212\u01eb/\u03b8\n\u03b8k \u0393(k)\n\n#\n\u03bc\u01eb\u0302\u039b\u0302(1 + 1/k)\n.\n+\n(1 + \u03bc\u01eb\u0302/k)k+2\n\n(24)\n\nbutions are obtained from (24) with values of k = 100, 16 and\n4 corresponding to errors of 10%, 25% and 50% respectively.\nAs the systematic error increases, the posterior distribution\nfor the Poisson mean parameter gets broader; the value of the\nprobability density function increases for large values of the\nPoisson mean parameter. This causes an increase in the upper\nlimit. Without taking into account any uncertainties, the 90%\n\n\f6\n\nFIG. 3: The posterior probability density function on the Poisson\nmean parameter \u03bc for different sizes of systematic error, where \u01eb\u0302 is\nthe efficiency evaluated at the loudest event x\u0302. The curves were generated assuming a uniform prior and using \u039b\u0302 = 10. The solid line\ncorresponds to the unmarginalized probability density function. The\ndot-dashed line gives the distribution marginalized over a 10% systematic uncertainty (equivalently k = 100 for the \u03b3-distribution).\nWith this level of uncertainty, the marginalized distribution is barely\nchanged from the original. The dotted and dashed lines show the\nposterior for 25% (k = 16) and 50% (k = 4) systematic errors. As\nthe systematic error increases the distribution broadens and consequently the upper limit increases.\n\nconfidence upper limit is 3.796/\u01eb(x\u0302). For 10% systematic error, this increases only slightly to 3.850/\u01eb(x\u0302) while for 25%\nand 50% this increases further to 4.147/\u01eb(x\u0302) and 5.434/\u01eb(x\u0302)\nrespectively. In Figure 4 we plot the upper limit as a function of the systematic error for four different values of \u039b. The\nresults are qualitatively similar to what was seen before -\nmarginalizing over uncertainties will increase the upper limit\nand the larger the errors, the larger the effect.\n\nB. Marginalization over uncertainties in \u039b\n\nIn many cases, there will also be uncertainties in the precise\nvalue of \u039b\u0302 = \u039b(x\u0302). These can be marginalized over in the\nsame way as described above. Since the \u039b\u0302 dependence of the\ndistribution (11) is straightforward, this can be done explicitly.\nFor concreteness, let us take a uniform prior, in which case\nthe posterior distribution is given by Eq. (14). Then, given a\nprobability distribution p(\u039b), the marginalized distribution is\nZ\np(\u03bc|\u01eb\u0302) = d\u039b p(\u039b) p(\u03bc|\u01eb\u0302, \u039b)\n(25)\nIn this case, the above integral is straightforward. Specifically,\nlet us define\nZ\n\u039b\n\u03be = d\u039b p(\u039b)\n.\n(26)\n(1 + \u039b)\n\nFIG. 4: The 90% confidence upper limit versus the size of the systematic error which is marginalized over (equivalent to k\u22121/2 in the\n\u03b3-distribution discussed in the text). The limit is plotted for four different values of \u039b\u0302: 0, 0.1, 1, 10. In all cases, the upper limit increases\nwith larger systematic error.\n\nThen, the posterior distribution following marginalization\nover \u039b is given by\np(\u03bc|\u01eb\u0302) = \u01eb\u0302 [(1 \u2212 \u03be) + \u03bc\u01eb\u0302\u03be] e\u2212\u03bc\u01eb\u0302\n\n(27)\n\nwhere \u03be contains all of the dependence of the posterior on the\nmarginalized background.\nSuppose that \u039b is distributed with expectation value \u039b\u0302 and\n2\nvariance \u03c3\u039b\n. Then, to leading order,\n\u03be\u2248\n\n\u039b\u0302\n1 + \u039b\u0302\n\n\u2212\n\n2\n\u03c3\u039b\n\n(1 + \u039b\u0302)3\n\n.\n\n(28)\n\nFrom this, we notice two things. First, even if the fractional\nuncertainties in \u039b\u0302 are of order unity, when \u039b\u0302 \u226b 1 or \u039b\u0302 \u226a\n1, the second term is small compared to the first and can be\nignored. Second, marginalizing over \u039b only serves to decrease\nthe value of \u03be relative to the unmarginalized case. This is\nequivalent to reducing the likelihood that the loudest event\nis foreground and consequently will reduce the upper limit.\nTherefore, it is possible to neglect the marginalization of \u039b as\nthis is a conservative thing to do.\nVI. COMBINING RESULTS FROM MULTIPLE\nEXPERIMENTS\n\nWhen performing a series of experiments, there is a very\nnatural way to combine the results in a Bayesian manner. As\ndiscussed above, the calculation of a Bayesian upper limit requires the specification of a prior probability distribution for\nthe rate \u03bc. When a previous experiment has been performed,\nit is natural to use the posterior from the first experiment as\nthe prior for the second. It is straightforward to show that the\nresults are independent of the order of the experiments. (This\n\n\f7\ndoes not depend upon the loudest event, rather it is a general\nBayesian result.) Begin by recalling that\np(\u03bc|x\u03021 ) = R\n\np(\u03bc) p(x\u03021 |\u03bc)\n.\nd\u03bc p(\u03bc) p(x\u03021 |\u03bc)\n\n(29)\n\nA. Splitting a search\n\nFor the second search, simply use p(\u03bc|x\u03021 ) as the prior to obtain the posterior distribution on \u03bc given the observations in\nboth the first and second experiments:\np(\u03bc|x\u03021 , x\u03022 ) = R\n\np(\u03bc) p(x\u03021 |\u03bc) p(x\u03022 |\u03bc)\n.\nd\u03bc p(\u03bc) p(x\u03021 |\u03bc) p(x\u03022 |\u03bc)\n\n(30)\n\nThis is clearly symmetric in x\u03021 and x\u03022 . It is straightforward to\nsee that marginalization over nuisance parameters (see Sec. V)\npreserves this symmetry.\nLet us consider this in more detail. If the first search was\nperformed using a uniform prior, the posterior is given by\nEq. (11) with a loudest event value x\u03021 observed in the first\nsearch. Furthermore, in the event that the loudest event is\nmost likely background, one expects \u039b\u03021 \u226a 1. Then, we can\nconservatively rewrite the posterior as\npconservative (\u03bc|\u01eb\u03021 , \u039b\u03021 ) = \u01eb\u03021 \u039b\u03021 e\u2212\u03bc\u01eb\u03021 (1\u2212\u039b\u03021 )\n\n(31)\n\nwhere \u01eb\u03021 = \u01eb1 (x\u03021 ), \u039b\u03021 = \u039b1 (x\u03021 ), and we have made use of\nthe fact that\n1 + \u03bc\u01eb\u03021 \u039b\u03021 \u2264 e\u03bc\u01eb\u03021 \u039b\u03021 .\n\n(32)\n\nIt is straightforward to show that the rate limit at a given confidence level \u03b1 inferred using this posterior is necessarily larger\nthan that obtained using the original distribution. In this sense,\nthe alternative distribution is conservative and the distribution\nhas been cast as an exponential.\nTherefore, in the second search, it is natural to use an exponential prior,\np(\u03bc) = \u03bae\u2212\u03ba\u03bc .\n\n(33)\n\nTo obtain the posterior distribution obtained when the exponential prior is used, it is beneficial to re-define \u039b(x) as\n\u039b\u03ba (x) =\n\n\u0012\n\n\u22121 d\u01eb\u03ba (x)\n\u01eb\u03ba (x) dx\n\n\u0013\u0012\n\np0 (x)\nP0 (x)\n\nwith \u01eb\u0302\u03ba = \u01eb\u03ba (x\u0302) and \u039b\u0302\u03ba = \u039b\u03ba (x\u0302). As before, the posterior\ndistribution is peaked away from zero if \u039b\u0302\u03ba > 1. In addition,\nthe distribution is identical to that obtained using a uniform\nprior, only now the search efficiency is effectively \u01eb(x\u0302) + \u03ba.\n\n\u0013\u22121\n\n(34)\n\nwhere\n\u01eb\u03ba (x) = \u01eb(x) + \u03ba\n\n(35)\n\nincludes the exponential scale constant from the prior distribution. Then, the posterior distribution is given by\np(\u03bc|\u01eb\u0302\u03ba , \u039b\u0302\u03ba ) \u221d (1 + \u03bc\u01eb\u0302\u03ba \u039b\u0302\u03ba )e\u2212\u03bc\u01eb\u0302\u03ba\n\n(36)\n\nNext, let us consider the effect of taking a single search and\nsplitting it into two halves, which can be combined to produce\nan upper limit in the manner described above. Naively, it appears that splitting the search will give a lower rate limit, since\nwe will be using a quieter loudest event for half the search. If\nthis were the case, then it would seem that splitting the search\ninto ever shorter searches would lower the upper limit indefinitely. As we shall see, the result is not so clear cut, and it\ndepends critically upon the foreground and background distributions \u01eb(x) and P0 (x).\nConsider an experiment performed for some given time T ,\nand assume that both the foreground and background rates are\nconstant over time. We would then like to compare the (expected) upper limit from the full search to that obtained by\nsplitting the data in two parts of length T1 and T2 and calculating a combined upper limit from the two searches. Let\nus assume, without loss of generality, that the loudest event\noverall in the search occurs in the first half of the search with\na statistic value of x\u03021 , and the loudest event in the second half\nof the search has a statistic value x\u03022 . Then, we can calculate\nthe upper limit from the search (taking it as a single entity)\nand from the split search.\nThe posterior for the single search is given by\n\np(\u03bc) [1 + \u03bc\u01eb(x\u03021 )\u039b(x\u03021 )] exp{\u2212\u03bc\u01eb(x\u03021 )}\nd\u03bc p(\u03bc) [1 + \u03bc\u01eb(x\u03021 )\u039b(x\u03021 )] exp{\u2212\u03bc\u01eb(x\u03021 )}\n(37)\nwhile for the split search, the likelihood for each part is proportional to\np(\u03bc|x\u03021 , B) = R\n\ni\nh\np(x\u0302i |\u03bc, B) \u221d 1 + \u03bc\u03b7i \u01eb\u0302i \u039b\u0302i e\u2212\u03bc\u03b7i \u01eb\u0302i\n\n(38)\n\nwhere i = 1, 2 label the two parts of the search, \u01eb\u0302i = \u01ebi (x\u0302i ),\n\u039b\u0302i = \u039bi (x\u0302i ) and \u03b7i = Ti /T is the fraction of the total observation time that is contained in the each interval; \u03b71 + \u03b72 = 1.\nThen the combined posterior distribution for the split search\nis\n\n\f8\n\nh\nih\ni\np(\u03bc) 1 + \u03bc\u03b71 \u01eb\u03021 \u039b\u03021 1 + \u03bc\u03b72 \u01eb\u03022 \u039b\u03022 exp{\u2212\u03bc[\u03b71 \u01eb\u03021 + \u03b72 \u01eb\u03022 ]}\ni\nih\nh\n.\np(\u03bc|x\u03021 , x\u03022 , B) = R\nd\u03bc p(\u03bc) 1 + \u03bc\u03b71 \u01eb\u03021 \u039b\u03021 1 + \u03bc\u03b72 \u01eb\u03022 \u039b\u03022 exp{\u2212\u03bc[\u03b71 \u01eb\u03021 + \u03b72 \u01eb\u03022 ]}\n\n(39)\n\nso the rate limit from the split search can become bigger than\nthat obtained in the single search. While this makes intuitive\nsense, the result depends on the particular observed outcomes\nof the experiment.\nWhen \u039b\u03021 \u226a 1 and \u039b\u03022 \u226a 1, the posterior distribution for\nthe single search can be approximated conservatively as\np(\u03bc|x\u03021 , B) \u2243 \u01eb(x\u03021 )[1 \u2212 \u039b(x\u03021 )]e\u2212\u03bc\u01eb(x\u03021 )[1\u2212\u039b(x\u03021 )]\n\n(40)\n\nwhile the posterior for the split search becomes\np(\u03bc|x\u03021 , x\u03022 , B) \u2243 c(x\u03021 , x\u03022 )e\u2212\u03bcc(x\u03021 ,x\u03022 )\n\n(41)\n\nc(x1 , x2 ) = \u01eb\u03021 \u03b71 (1 \u2212 \u039b\u03021 ) + \u01eb\u03022 \u03b72 (1 \u2212 \u039b\u03022 ).\n\n(42)\n\nwhere\n\nFIG. 5: The ratio of \u03bcsingle to \u03bcsplit as a function of \u039b\u03022 for several values of \u01eb\u03022 /\u01eb\u03021 . The data presented uses a uniform prior on \u03bc,\n\u03b7i = 12 , \u01eb(x) = \u01ebi (x) and \u039b1 (x) = \u039b2 (x). The figure was generated for \u039b(x\u03021 ) = 0.5\u039b1 (x\u03021 ) = 1. In general, there is only a weak\ndependence on this value; the curves steepen a little for smaller value\nof \u039b(x\u03021 ), but look qualitatively similar. Note also that for most sensible choices of amplitude statistic x, one expects \u039b\u03022 \u2264 \u039b\u03021 . The plot\nis extended to \u039b\u03022 = 10 for completeness.\n\nIf we further assume that both the foreground and background\nare Poisson distributed over the entire search, then \u01ebi (x) =\n\u01eb(x) and \u03b7i \u039bi (x) = \u039b(x). Within the context of these assumptions, it is then easy to write down the upper limit for\neach distribution. In particular,\n\u03bcsingle =\n\n\u2212 ln(1 \u2212 \u03b1)\n\u01eb(x\u03021 )[1 \u2212 \u039b(x\u03021 )]\n\n(43)\n\nfor the single search; for the split search\nWe can now compare the posterior distributions for the single and split search. In general, the efficiencies \u01ebi (x) and\nthe likelihoods \u039bi (x) could be different for the two parts.\nNevertheless, it follows directly from Eq. (10) that \u01eb(x) =\n\u03b71 \u01eb1 (x) + \u03b72 \u01eb2 (x). Therefore, in the split search, the exponential decay term is at least as large as for the single search,\nwith equality only if x2 = x1 . This tends to make the upper\nlimit obtained in the split search smaller than that of the single\nsearch. In contrast, the polynomial prefactor is always more\nsignificant for the split search (i.e. it grows more steeply with\n\u03bc). This tends to make the upper limit larger. So splitting the\nsearch will lead to a larger limit when \u01eb\u03022 = \u01eb\u03021 and \u039b\u03022 = \u039b\u03021 .\nMeanwhile if \u01eb\u03022 \u226b \u01eb\u03021 and \u039b\u03022 \u226a \u039b\u03021 , the split search will give\na numerically smaller limit.\nAssuming a uniform prior on \u03bc, we compare the 90%confidence upper limits on the Poisson mean obtained from\na single search with the limit obtained from a split search with\n\u03b71 = \u03b72 = 1/2. The results are shown in Fig. 5 for several choices of \u01eb\u03022 /\u01eb\u03021 under the assumptions that \u01eb(x) = \u01ebi (x)\nand \u039b1 (x) = \u039b2 (x). While not the most general case, these\nassumptions are reasonable in the context of an experiment\nwith the same apparatus and background noise sources. In the\nlimit \u039b\u03022 \u2192 0, we find \u03bcsingle > \u03bcsplit as expected. As \u039b\u03022\nincreases, the second event is less likely to be background and\n\n\u03bcsplit =\n\n\u2212 ln(1 \u2212 \u03b1)\n.\nc(x\u03021 , x\u03022 )\n\n(44)\n\nHence, the single search will give a smaller upper limit if\n\u0015\n\u0014\n\u01eb(x\u03021 )\n.\n(45)\n\u039b2 (x\u03022 ) > 1 \u2212\n\u01eb(x\u03022 )\nOnce again, the comparison between the single and split\nsearch is sensitive to the precise nature of the foreground,\nbackground and observed results.\nVII. DISCUSSION\n\nThe loudest event statistic is just one method of taking\naccount of the quality of an event in the interpretation of a\nsearch. In this paper, we have presented further exploration of\nthe method including the discussion of marginalization over\nuncertainties in the input model. The Bayesian approach allows simple accounting of these uncertainties by integrating\nthem out.\nWe also showed how the method could be used to determine a rate interval. Once again, this is not the most powerful method of determining an interval (in the sense that using\n\n\f9\nmore than one event would lead to a more strongly peaked\ndistribution and, consequently, a narrower interval). Nevertheless, the approach shows that a rate interval arises when\nthe likelihood that the event is signal becomes large enough.\nFinally, we presented a discussion of combining the results\nfrom multiple searches to determine a single upper limit. It\nwas shown that the limit obtained by combining two searches\nof equal duration is, in general, different to the limit obtained\nby performing a single search of equivalent duration. What\nconclusion to draw from this is unclear since the notion of\nbetter depends on the true value of the rate being explored.\nEven though physicists have a deep appreciation for probabilistic phenomena in nature, it is often tempting to talk about\nbetter upper limits by using one method or another. This is, of\ncourse, a flawed approach. In fact, it is the experiment that one\nshould choose not the statistical method. Nevertheless, some\nexperiments may be more powerful than others. For example,\nit would be ill-conceived to use the loudest event method to\ndetermine a rate interval in an experiment which is likely (in\nthe sense of prior probability) to generate more than one loud\nevent that could be considered to arise from the phenomenon\nof interest. Indeed, these considerations lead back to an experiment more like the standard threshold approach.\n\nAcknowledgments\n\nWe would like to acknowledge many useful discussions\nwith members of the LIGO Scientific Collaboration inspiral\nanalysis group which were critical in the formulation of the\nmethods and results described in this paper. This work has\nbeen supported in part by NSF grants PHY-0200852 and PHY0701817; PRB is grateful to the Research Corporation for support by a Cottrell Scholar Award; SF was funded in part by the\nRoyal Society. LIGO was constructed by the California Institute of Technology and Massachusetts Institute of Technology\nwith funding from the National Science Foundation and operates under cooperative agreement PHY-0107417. This paper\nhas LIGO Document Number LIGO-P070076-00-Z.\n\nAPPENDIX A: FREQUENTIST APPROACH TO THE\nLOUDEST EVENT STATISTIC\n\nThis paper has explored the loudest event statistic from the\nBayesian point of view. In this appendix we consider an alternative approach: the construction of frequentist confidence\nintervals using the loudest event statistic. The construction\nof frequentist upper limits is almost trivial (see [8]). More\ninteresting is the application of the method of Feldman and\nCousins [12] for a unified approach to constructing confidence\nintervals. We restrict attention here to the case in which only\nthe unknown rate amplitude \u03bc is to be bounded.\nWe briefly summarize the Neyman approach to constructing confidence belts: For each fixed value of \u03bc, an interval\n[x1 , x2 ] is constructed such that the probability of observing\na loudest event x in this interval is equal to the desired confi-\n\nFIG. 6: The \u03b1 = 90% confidence belt constructed using the procedure of Feldman and Cousins for the example described in the text.\nFor each value of \u03bc, the probability of obtaining a loudest event value\nof x in the interval given by the solid line bounded by open circles\nis 90%. The solid diamond shows the point in this interval where\nR(x) is the greatest. For an observed loudest event value x\u0302, the interval on \u03bc is the intersection of the vertical line x = x\u0302 with this belt.\nNote that for small values of x\u0302 an upper limit on \u03bc is obtained while\nfor larger values of x\u0302 the interval on \u03bc is bounded away from zero.\nThe division between an upper limit and an inteval that excludes zero\noccurs at a value of x90% for which P0 (x90% ) = 90%.\n\ndence level \u03b1:\nP (x2 |\u03bc) \u2212 P (x1 |\u03bc) = \u03b1\n\n(A1)\n\nP (x|\u03bc) = P0 (x)e\u2212\u03bc\u01eb(x) .\n\n(A2)\n\nwhere\n\nThe collection of such intervals then defines a confidence belt;\nfor any observed value of the loudest event x\u0302, the belt covers\na range of values of \u03bc, [\u03bc1 , \u03bc2 ], which is the desired interval\non the rate amplitude parameter. In order to construct the confidence belt, a supplementary condition is needed in order to\nuniquely define the interval. For example, to obtain a confidence belt that always yields upper limits, choose x2 = \u221e.\nThen the belt is defined as the interval [x1 , \u221e) where x1 satisfies\n1 \u2212 P (x1 |\u03bc) = \u03b1\n\n(A3)\n\nfor each value of \u03bc. Then, given an observed loudest event\nvalue x\u0302, the rate amplitude interval is [0, \u03bc2 ] where\n1 \u2212 P (x\u0302|\u03bc2 ) = \u03b1\n\n(A4)\n\n\f10\nor\n\u03bc2 = \u2212\n\nln(1 \u2212 \u03b1) \u2212 ln P0 (x\u0302)\n.\n\u01eb(x\u0302)\n\n(A5)\n\nAs mentioned in [8], this procedure has the pathology that if\nP0 (x\u0302) < 1 \u2212 \u03b1 then the interval on \u03bc is empty.\nThe unified approach of Feldman and Cousins provides\na different supplementary condition for defining the interval [x1 , x2 ] for fixed \u03bc. In the Feldman and Cousins approach, the interval is constructed using a function R(x) so\nthat R(x) \u2265 Rmin for x \u2208 [x1 , x2 ] and R(x) < Rmin for x\noutside the interval where Rmin = min{R(x1 ), R(x2 )}. The\nfunction R(x) is chosen to be the likelihood ratio\np(x|\u03bc)\n(A6)\np(x|\u03bcpeak )\n\uf8f1\n\u2212\u03bc\u01eb(x)\n\u039b(x) \u2264 1\n\uf8f4\n\uf8f2 [1 + \u03bc\u01eb(x)\u039b(x)]e\n\u2212\u03bc\u01eb(x)\n=\n(A7)\n[1 + \u03bc\u01eb(x)\u039b(x)]e\n\uf8f4\n\uf8f3\n\u039b(x) > 1\n1/\u039b(x)\u22121\n\u039b(x)e\n\nR(x) =\n\nwhere\np(x|\u03bc) =\n\ndP (x|\u03bc)\n= p0 (x)[1 + \u03bc\u01eb(x)\u039b(x)]e\u2212\u03bc\u01eb(x) (A8)\ndx\n\nand \u03bcpeak is given by Eq. (15).\nAs an illustration, we compute the confidence belt according to the Feldman and Cousins procedure for the following example: We take \u01eb(x) = (xmin /x)3 and P0 (x) =\n1 \u2212 exp(xmin \u2212 x) with xmin = 5; only values x > xmin\nare realizable. The \u03b1 = 90% confidence belt is shown in\nFig. 6. Notice that there is a well-defined inteval on \u03bc for\nany observed loudest event value x\u0302 possible, that is, the Feldman and Cousins procedure produces confidence belts that are\nfree of the pathology described above when upper limit confidence belts are constructed. Furthermore, the interval on \u03bc\nis a upper limit for small loudest event values x\u0302 < x90% , but\nbecomes an interval which excludes zero for x\u0302 > x90% where\nP0 (x90% ) = 90%.\nIt is interesting to consider the behavior of the confidence\nintervals for large values of x. In this regime, \u039b(x) \u226b 1,\nP0 (x) \u2243 1 so R(x) \u2243 \u03bc\u01eb(x)e\u2212\u03bc\u01eb(x)+1 and P (x|\u03bc) \u2243\ne\u2212\u03bc\u01eb(x) . The confidence belt at fixed \u03bc is given by the interval [x1 , x2 ] that satisfies R(x1 ) = R(x2 ) and P (x2 |\u03bc) \u2212\nP (x1 |\u03bc) = \u03b1. Therefore, x1 and x2 satisfy the coupled\nequations \u03bc\u01eb(x1 )e\u2212\u03bc\u01eb(x1 ) = \u03bc\u01eb(x2 )e\u2212\u03bc\u01eb(x2 ) and e\u2212\u03bc\u01eb(x2 ) \u2212\ne\u2212\u03bc\u01eb(x1 ) = \u03b1. For \u03b1 = 90%, \u03bc\u01eb(x1 ) = 3.932 and\n\u03bc\u01eb(x2 ) = 0.08381. Consequently, the 90% confidence\nrate amplitude interval [\u03bc1 , \u03bc2 ] for large x\u0302 will be given by\n\u03bc1 = 0.08381/\u01eb(x\u0302) and \u03bc2 = 3.932/\u01eb(x\u0302). Notice the ratio\n\u03bc2 /\u03bc1 = 46.91 is fixed: the fractional uncertainty in the value\nof \u03bc does not improve as x\u0302 increases. This demonstrates that\nfor experiments in which events in the low-background region\nare expected, the loudest event statistic will not give strong\nconstraints on the event rate. As emphasized in the introduction, the loudest event statistic is best suited to problems in\nwhich the anticipated event rate is very low and foreground\nand background events are expected to have comparable amplitudes.\n\nFIG. 7: a) The upper limit as a function of the observed loudest\nevent. The solid line shows the value of the upper limit as a function of x\u0302. The dotted and dashed lines are given by 2.303/\u01eb(x\u0302) and\n3.890/\u01eb(x\u0302). We see that the upper limit transitions smoothly from\none to the other. At low values of x\u0302, the loudest event is very much\nconsistent with the background, \u039b\u0302 \u2248 0 and the upper limit is close to\nthe dotted line. For larger values of x\u0302 the loudest event is more consistent with foreground, \u039b\u0302 \u2192 \u221e, and the upper limit is more consistent with the dashed line. b) The probability distribution for the\nloudest event assuming that it is drawn from the background distribution, p0 (x). Multiplying the upper limit curve by this distribution\nand integrating over x gives the expected value of the upper limit if\nthe loudest event is from the background.\n\nAPPENDIX B: COMPARISON WITH FIXED THRESHOLDS\n\nLet us compare the loudest event statistic against a fixed\nthreshold approach. The loudest event prescription can be applied to any form of background, provided the required quantities in Eq. (12) can be measured or estimated. In many experiments, one might expect the background events above a\nstatistic value x to be Poisson distributed, with mean \u03bd0 (x)\nwhere \u03bd0 is a non-increasing function of x. Then, it follows\n\n\f11\n\nFIG. 8: Figure showing the expected upper limit as a function of\nthe fixed threshold. The dashed line shows the upper limit obtained\nwhen ignoring the background, while the dotted line includes the\nbackground contribution. For large values of the threshold where\nthe expected background is small, both limits approach 2.303/\u01eb(x\u2217 )\nas expected. For low values of x\u2217 , there is a good chance of many\nevents above threshold which leads to a worse upper limit. The balance occurs at around a threshold value of x\u2217 = 8.3. For reference,\nwe also plot a horizontal line showing the expected upper limit from\nthe loudest event. Interestingly, the loudest event will, on average,\noutperform the fixed threshold for any value of the threshold.\n\ndirectly that\nP0 (x) = e\u2212\u03bd0 (x)\nd\u03bd0 (x) \u2212\u03bd0 (x)\np0 (x) =\ne\ndx\nd\u03bd0 (x)\np0 (x)/P0 (x) =\n.\ndx\n\n(B1)\n\nWe work with an example where the mean \u03bd0 (x) =\n2\n2\ne(8 \u2212x )/2 and the foreground is distributed as \u01eb(x) = (8/x)3 .\nThese choices are natural in the context of a search for gravitational waves from coalescing binaries where the background\nis \u03c72 distributed with two degrees of freedom, while the foreground is uniformly distributed in volume, and the signal\n\n[1] B. Allen et al., Phys. Rev. Lett. 83, 1498 (1999).\n[2] B. Abbott et al. (LIGO Scientific Collaboration), Phys. Rev. D\n69, 122001 (2004), gr-qc/0308069.\n[3] B. Abbott et al. (LIGO Scientific Collaboration), Phys. Rev. D\n72, 082002 (2005), gr-qc/0505042.\n[4] B. Abbott et al. (LIGO Scientific Collaboration), Phys. Rev. D\n72, 082001 (2005), gr-qc/0505041.\n[5] B. Abbott et al. (LIGO Scientific Collaboration), Phys. Rev. D\n73, 062001 (2006), gr-qc/0509129.\n[6] B. Abbott et al. (LIGO Scientific), Phys. Rev. D69, 082004\n(2004), gr-qc/0308050.\n[7] X. Siemens et al., Phys. Rev. D73, 105001 (2006), gr-\n\nstrength (and hence statistic value x) are inversely proportional to the distance [13]. The normalizations of these functions are chosen for simplicity so that \u03bd0 (8) = \u01eb(8) = 1. The\nmain feature of these distributions, however, is simply that\nthey are both decreasing functions of x, and that the background decreases more rapidly than the foreground. The value\nof the upper limit as a function of the actual loudest event is\nshown in Fig. 7a. The upper limit transitions smoothly from\nthe zero foreground limit (at low values of x) to zero background limit (at large values of x). Figure 7b shows the distribution p0 (x). This corresponds to the expected distribution\nof for the loudest event if it is due to the background. Then,\nby multiplying the upper limit by the expected distribution for\nthe loudest event and integrating, we obtain the expected upper limit. In this example it is 2.64.\nFor comparison, the upper limit for a fixed threshold is presented in Figure 8. When calculating the upper limit for a\nfixed threshold, one simply counts the number of events n\u0302\nabove the chosen threshold x\u2217 and obtains a limit\n\u03bc90%\nF (n\u0302)\n=\nT\n\u01eb(x\u2217 )T\n\n(B2)\n\nwhere F (n) is a known function for each integer n (see, for\nexample, [14] for more details). In particular, when zero\nevents are observed above the threshold, F (0) = 2.303.\nWhen performing a fixed threshold search, it is possible to\ntake into account the expected background and, much as for\nthe loudest event, neglecting to do so will lead to a conservative result. In Fig. 8, we show the expected upper limit as a\nfunction of the threshold.\nClearly, in this example, the loudest event statistic is preferable to a fixed threshold, as it will provide a better expected\nupper limit value than the fixed threshold for any value of the\nthreshold (with or without the background). We note that this\nresult is specific to the details of the example under consideration; the key feature is that the background rate is a very steep\nfunction of x. Indeed, in [8], the same example was considered, but with an expected background of unity at x\u0302 = 4.5\nrather than x\u0302 = 8, leading to a small range of values where\nthe fixed threshold does beat the loudest event. However, as\nemphasized in that paper the attraction of the loudest event is\nthat it is unnecessary to fix a threshold ahead of performing\nthe search - the search itself determines the threshold.\n\nqc/0603115.\n[8] P. R. Brady, J. D. E. Creighton, and A. G. Wiseman, Class.\nQuant. Grav. 21, S1775 (2004).\n[9] R. Cousins, Nucl. Instrum. Meth. A337, 557 (1994).\n[10] S. Yellin, Phys. Rev. D66, 032005 (2002), physics/0203002.\n[11] W.-M. Yao et al., J. Phys. G: Nucl. Part. Phys. 33, 1 (2006).\n[12] G. J. Feldman and R. D. Cousins, Phys. Rev. D 57, 3873 (1998),\nphysics/9711021.\n[13] P. Brady and S. Fairhurst, gr-qc (2007), arXiv:0707.2410.\n[14] W. M. Yao et al. (Particle Data Group), J. Phys. G33, 1 (2006).\n\n\f"}