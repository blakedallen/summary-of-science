{"id": "http://arxiv.org/abs/cs/0501058v1", "guidislink": true, "updated": "2005-01-22T02:53:20Z", "updated_parsed": [2005, 1, 22, 2, 53, 20, 5, 22, 0], "published": "2005-01-22T02:53:20Z", "published_parsed": [2005, 1, 22, 2, 53, 20, 5, 22, 0], "title": "Estimation of the Number of Sources in Unbalanced Arrays via Information\n  Theoretic Criteria", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0212031%2Ccs%2F0212032%2Ccs%2F0212033%2Ccs%2F0212048%2Ccs%2F0212041%2Ccs%2F0212007%2Ccs%2F0212008%2Ccs%2F0212014%2Ccs%2F0212029%2Ccs%2F0212045%2Ccs%2F0212016%2Ccs%2F0212034%2Ccs%2F0212020%2Ccs%2F0212022%2Ccs%2F0212005%2Ccs%2F0212051%2Ccs%2F0212027%2Ccs%2F0212053%2Ccs%2F0212023%2Ccs%2F0212017%2Ccs%2F0212038%2Ccs%2F0212003%2Ccs%2F0212021%2Ccs%2F0212015%2Ccs%2F0212049%2Ccs%2F0212054%2Ccs%2F0212011%2Ccs%2F0212012%2Ccs%2F0212037%2Ccs%2F0212006%2Ccs%2F0212035%2Ccs%2F0212002%2Ccs%2F0212024%2Ccs%2F0212013%2Ccs%2F0212001%2Ccs%2F0212026%2Ccs%2F0212042%2Ccs%2F0212018%2Ccs%2F0212004%2Ccs%2F0212047%2Ccs%2F0212044%2Ccs%2F0212039%2Ccs%2F0212030%2Ccs%2F0212028%2Ccs%2F0212052%2Ccs%2F0212055%2Ccs%2F0212050%2Ccs%2F0212009%2Ccs%2F0107019%2Ccs%2F0107003%2Ccs%2F0107013%2Ccs%2F0107021%2Ccs%2F0107023%2Ccs%2F0107002%2Ccs%2F0107017%2Ccs%2F0107024%2Ccs%2F0107010%2Ccs%2F0107005%2Ccs%2F0107004%2Ccs%2F0107036%2Ccs%2F0107033%2Ccs%2F0107034%2Ccs%2F0107008%2Ccs%2F0107009%2Ccs%2F0107030%2Ccs%2F0107027%2Ccs%2F0107006%2Ccs%2F0107022%2Ccs%2F0107007%2Ccs%2F0107018%2Ccs%2F0107029%2Ccs%2F0107012%2Ccs%2F0107020%2Ccs%2F0107011%2Ccs%2F0107025%2Ccs%2F0107015%2Ccs%2F0107016%2Ccs%2F0107028%2Ccs%2F0107001%2Ccs%2F0107035%2Ccs%2F0107026%2Ccs%2F0107031%2Ccs%2F0107014%2Ccs%2F0501001%2Ccs%2F0501002%2Ccs%2F0501059%2Ccs%2F0501058%2Ccs%2F0501045%2Ccs%2F0501042%2Ccs%2F0501096%2Ccs%2F0501041%2Ccs%2F0501039%2Ccs%2F0501087%2Ccs%2F0501064%2Ccs%2F0501062%2Ccs%2F0501072%2Ccs%2F0501020%2Ccs%2F0501030%2Ccs%2F0501040%2Ccs%2F0501016%2Ccs%2F0501034&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Estimation of the Number of Sources in Unbalanced Arrays via Information\n  Theoretic Criteria"}, "summary": "Estimating the number of sources impinging on an array of sensors is a well\nknown and well investigated problem. A common approach for solving this problem\nis to use an information theoretic criterion, such as Minimum Description\nLength (MDL) or the Akaike Information Criterion (AIC). The MDL estimator is\nknown to be a consistent estimator, robust against deviations from the Gaussian\nassumption, and non-robust against deviations from the point source and/or\ntemporally or spatially white additive noise assumptions. Over the years\nseveral alternative estimation algorithms have been proposed and tested.\nUsually, these algorithms are shown, using computer simulations, to have\nimproved performance over the MDL estimator, and to be robust against\ndeviations from the assumed spatial model. Nevertheless, these robust\nalgorithms have high computational complexity, requiring several\nmulti-dimensional searches.\n  In this paper, motivated by real life problems, a systematic approach toward\nthe problem of robust estimation of the number of sources using information\ntheoretic criteria is taken. An MDL type estimator that is robust against\ndeviation from assumption of equal noise level across the array is studied. The\nconsistency of this estimator, even when deviations from the equal noise level\nassumption occur, is proven. A novel low-complexity implementation method\navoiding the need for multi-dimensional searches is presented as well, making\nthis estimator a favorable choice for practical applications.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0212031%2Ccs%2F0212032%2Ccs%2F0212033%2Ccs%2F0212048%2Ccs%2F0212041%2Ccs%2F0212007%2Ccs%2F0212008%2Ccs%2F0212014%2Ccs%2F0212029%2Ccs%2F0212045%2Ccs%2F0212016%2Ccs%2F0212034%2Ccs%2F0212020%2Ccs%2F0212022%2Ccs%2F0212005%2Ccs%2F0212051%2Ccs%2F0212027%2Ccs%2F0212053%2Ccs%2F0212023%2Ccs%2F0212017%2Ccs%2F0212038%2Ccs%2F0212003%2Ccs%2F0212021%2Ccs%2F0212015%2Ccs%2F0212049%2Ccs%2F0212054%2Ccs%2F0212011%2Ccs%2F0212012%2Ccs%2F0212037%2Ccs%2F0212006%2Ccs%2F0212035%2Ccs%2F0212002%2Ccs%2F0212024%2Ccs%2F0212013%2Ccs%2F0212001%2Ccs%2F0212026%2Ccs%2F0212042%2Ccs%2F0212018%2Ccs%2F0212004%2Ccs%2F0212047%2Ccs%2F0212044%2Ccs%2F0212039%2Ccs%2F0212030%2Ccs%2F0212028%2Ccs%2F0212052%2Ccs%2F0212055%2Ccs%2F0212050%2Ccs%2F0212009%2Ccs%2F0107019%2Ccs%2F0107003%2Ccs%2F0107013%2Ccs%2F0107021%2Ccs%2F0107023%2Ccs%2F0107002%2Ccs%2F0107017%2Ccs%2F0107024%2Ccs%2F0107010%2Ccs%2F0107005%2Ccs%2F0107004%2Ccs%2F0107036%2Ccs%2F0107033%2Ccs%2F0107034%2Ccs%2F0107008%2Ccs%2F0107009%2Ccs%2F0107030%2Ccs%2F0107027%2Ccs%2F0107006%2Ccs%2F0107022%2Ccs%2F0107007%2Ccs%2F0107018%2Ccs%2F0107029%2Ccs%2F0107012%2Ccs%2F0107020%2Ccs%2F0107011%2Ccs%2F0107025%2Ccs%2F0107015%2Ccs%2F0107016%2Ccs%2F0107028%2Ccs%2F0107001%2Ccs%2F0107035%2Ccs%2F0107026%2Ccs%2F0107031%2Ccs%2F0107014%2Ccs%2F0501001%2Ccs%2F0501002%2Ccs%2F0501059%2Ccs%2F0501058%2Ccs%2F0501045%2Ccs%2F0501042%2Ccs%2F0501096%2Ccs%2F0501041%2Ccs%2F0501039%2Ccs%2F0501087%2Ccs%2F0501064%2Ccs%2F0501062%2Ccs%2F0501072%2Ccs%2F0501020%2Ccs%2F0501030%2Ccs%2F0501040%2Ccs%2F0501016%2Ccs%2F0501034&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Estimating the number of sources impinging on an array of sensors is a well\nknown and well investigated problem. A common approach for solving this problem\nis to use an information theoretic criterion, such as Minimum Description\nLength (MDL) or the Akaike Information Criterion (AIC). The MDL estimator is\nknown to be a consistent estimator, robust against deviations from the Gaussian\nassumption, and non-robust against deviations from the point source and/or\ntemporally or spatially white additive noise assumptions. Over the years\nseveral alternative estimation algorithms have been proposed and tested.\nUsually, these algorithms are shown, using computer simulations, to have\nimproved performance over the MDL estimator, and to be robust against\ndeviations from the assumed spatial model. Nevertheless, these robust\nalgorithms have high computational complexity, requiring several\nmulti-dimensional searches.\n  In this paper, motivated by real life problems, a systematic approach toward\nthe problem of robust estimation of the number of sources using information\ntheoretic criteria is taken. An MDL type estimator that is robust against\ndeviation from assumption of equal noise level across the array is studied. The\nconsistency of this estimator, even when deviations from the equal noise level\nassumption occur, is proven. A novel low-complexity implementation method\navoiding the need for multi-dimensional searches is presented as well, making\nthis estimator a favorable choice for practical applications."}, "authors": ["Eran Fishler", "H. Vincent Poor"], "author_detail": {"name": "H. Vincent Poor"}, "author": "H. Vincent Poor", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/TSP.2005.853099", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cs/0501058v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0501058v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "To appear in the IEEE Transactions on Signal Processing", "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0501058v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0501058v1", "journal_reference": null, "doi": "10.1109/TSP.2005.853099", "fulltext": "1\n\nEstimation of the Number of Sources in Unbalanced\nArrays via Information Theoretic Criteria\nEran Fishler\u2021 and H. Vincent Poor\u2020\n\narXiv:cs/0501058v1 [cs.IT] 22 Jan 2005\n\nAbstract- Estimating the number of sources impinging on an\narray of sensors is a well known and well investigated problem.\nA common approach for solving this problem is to use an\ninformation theoretic criterion, such as Minimum Description\nLength (MDL) or the Akaike Information Criterion (AIC). The\nMDL estimator is known to be a consistent estimator, robust\nagainst deviations from the Gaussian assumption, and non-robust\nagainst deviations from the point source and/or temporally or\nspatially white additive noise assumptions. Over the years several\nalternative estimation algorithms have been proposed and tested.\nUsually, these algorithms are shown, using computer simulations,\nto have improved performance over the MDL estimator, and to\nbe robust against deviations from the assumed spatial model.\nNevertheless, these robust algorithms have high computational\ncomplexity, requiring several multi-dimensional searches.\nIn this paper, motivated by real life problems, a systematic\napproach toward the problem of robust estimation of the number\nof sources using information theoretic criteria is taken. An\nMDL type estimator that is robust against deviation from\nassumption of equal noise level across the array is studied. The\nconsistency of this estimator, even when deviations from the equal\nnoise level assumption occur, is proven. A novel low-complexity\nimplementation method avoiding the need for multi-dimensional\nsearches is presented as well, making this estimator a favorable\nchoice for practical applications.\n\nI. I NTRODUCTION\n\nA. Motivation\nThe problem of estimating the number of sources impinging\non a passive array of sensors has received a considerable\namount of attention during the last two decades. The first\nto address this problem were Wax and Kailath, [1]. In their\nseminal work [1] it is assumed that the additive noise process\nis a spatially and temporally white Gaussian random process.\nGiven this assumption the number of sources can be deduced\nfrom the multiplicity of the received signal correlation matrix's\nsmallest eigenvalue [2], [3]. In order to avoid the use of\nsubjective thresholds required by multiple hypothesis testing\ndetectors [4], Wax and Kailath suggested the use of the\nMinimum Description Length (MDL) criterion for estimating\nthe number of sources. The MDL estimator can be interpreted\nas a test for determining the multiplicity of the smallest\neigenvalue [3].\n\n\u2020 H. V. Poor is with the Department of Electrical Engineering, Princeton\nUniversity, Princeton, NJ 08544, USA, Tel: (201) 258-1816, Fax: (201) 2581468, e-mail: poor@princeton.edu\n\u2021 E. Fishler was with the Department of Electrical Engineering, Princeton\nUniversity, Princeton, NJ. He is now with the Stern School of Business, New\nYork University, NY, NY. e-mail: ef485@stern.nyu.edu.\n\u2217 This research was supported by the U.S. Office of Naval Research under\nGrant No. N00014-03-1-0102.\n\nFollowing [1], many other papers have addressed this problem (see, among others [5], [6], [7], [8], [9], [10]). These\npapers can be divided into two major groups: the first is\nconcerned with performance analysis of the MDL estimator\n[11], [2], [12], [13], while the second is concerned with\nimprovements on the MDL estimator.\nPapers detailing improvements of the MDL estimator can\nbe found quite extensively: [5], [14], [6], [15], [16], [9] is\nonly a partial list of such works. In many of these works\nthe MDL approach is taken, and by exploiting some type of\nprior knowledge, performance improvement is achieved [17],\n[6], [10]. One of the assumptions usually made is that the\nadditive noise process is a spatially white process, and the\nrobustness of the proposed methods against deviations from\nthis assumption is usually assessed via computer simulations\n[9]. In general it can be observed that methods which use\nsome kind of prior information are robust, while methods\nwhich are based on the multiplicity of the smallest eigenvalue\nare non-robust. The reason for these latter estimators' lack of\nrobustness is that, when a deviation from the assumed model\noccurs, the multiplicity of the smallest eigenvalue equals one\n[1]. Thus, one can not infer the number of sources from the\nmultiplicity of the received signal correlation matrix's smallest\neigenvalue. On the other hand, methods that are based on\nsome prior knowledge, e.g., the array steering vectors, usually\nhave high computational complexity, requiring several multidimensional numerical searches [18]. Moreover, these methods\nare not necessarily consistent when some deviations from the\nassumed model occur, although they exhibit good robustness\nproperties in simulations.\nEfficient and robust estimation of the number of sources is\nvery important in bio-medical applications (see, for example\n[19], and references therein). For example, in one such application it is of interest to estimate the number of neurons\nreacting to a short stimulus. This is done by placing a very\nlarge array of sensors over a patient's head, and recording\nthe brain activity as received by these sensors. In these biomedical problems no a priori knowledge (e.g., knowledge of\nsteering vectors) exists. Moreover, since different sensors are\nat slightly different distances from the patient's skin, the noise\nlevels at the outputs of the sensors vary considerably. Thus biomedical applications are an example of one important class of\nproblem in which the additive noise is not necessarily spatially\nhomogeneous.\nAlthough robust estimators for the number of sources exist,\nthese estimators require some a priori knowledge which is\noften not avilable, and their computational complexity is large,\nas noted above. Thus, computationally efficient and robust\n\n\f2\n\nestimators for the number of sources are of considerable\ninterest. These estimators should not require prior knowledge\nand should be consistent even when deviations from the\nassumed model occur. Such estimators for specific types of\ndeviations from the assumed model are developed in this paper.\nIn particular, we consider the situation in which the sensor\nnoise levels are spatially inhomogeneous. It will be shown\nthat while traditional methods for estimating the number of\nsources tend to over-estimate the number of sources under\nthese circumstances, our proposed estimator does not have this\ntendency.\n\nC. Information Theoretic Criteria and MDL Estimators\nAn Information Theoretic Criterion (ITC) is an estimation\ncriterion for choosing between several competing parametric\nmodels [3]. Given a parameterized family of probability densities, fX (X|\u03b8q ) , \u03b8q \u2208 \u0398q for X = [x1 , . . . , xN ] and for\nvarious q, an ITC estimator selects q\u0302 such that [3]:\no\nn\n\u0010 \u0011\n(2)\nq\u0302ITC = arg min ITC(q) = arg min \u2212L \u03b8\u0302q + penalty(q)\nq\n\nq\n\n\u25b3\n\nB. Problem Formulation\nConsider an array of p sensors and denote by x(t) the\nreceived, p-dimensional, signal vector at time instant t. Denote\nby q < p the number of signals impinging on the array. A\ncommon model for the received signal vector is [18], [11]:\nx(t) = As(t) + n(t)\n\n,\n\nt = 1, 2, . . . , N\n\n(1)\n\nwhere A = [a(\u03c81 ), a(\u03c82 ), * * * , a(\u03c8q )] is a p \u00d7 q matrix\ncomposed of q p-dimensional vectors, and a(\u03c8) lies on the\narray manifold {A = a(\u03c8)|\u03c8 \u2208 \u03a8}, where \u03a8 denotes\na set of parameters describing the array response. a(\u03c8) is\ncalled the array response vector or the steering vector and\nA is referred to as the steering matrix, and \u03c8i is a vector of unknown parameters associated with the ith source.\ns(t) = [s1 (t) * * * sq (t)]T is a white complex, stationary\nGaussian random processes, with zero means and positive\ndefinite correlation matrix, Rs ; n(t) is a temporally white\ncomplex Gaussian vector random process, independent of\nthe signals, with zero\u0001 mean and correlation matrix \u0001given by\ndiag [\u03c312 , \u03c322 , . . . , \u03c3p2 ] , where diag [\u03c312 , \u03c322 , . . . , \u03c3p2 ] denotes\na diagonal matrix with the vector [\u03c312 , \u03c322 , . . . , \u03c3p2 ] on its diagonal. This correlation matrix represents the scenario in which\neach sensor\nPp potentially faces a different noise level. Define\n\u03c3 2 = p1 i=1 \u03c3i2 , wi = \u03c3i2 \u2212 \u03c3 2 , and w = [w1 , w2 , . . . , wp ].\nThe additive noise correlation \b\nmatrix can be described with the\naid of \u03c3 2 and w as follows E n(t)nH (t) = \u03c3 2 I+ diag (w).\nThis alternate representation simplifies some of the proofs and\nderivations in the sequel. Note, that the vector w represents a\ndeviation from the assumption that the noise level is constant\nacross the array. Finally, all the elements of the steering matrix,\nA, are assumed to be unknown [1], with the only restriction\nbeing that A is of full rank. In the sequel the Gaussian\nassumption will be eased.\nWe denote by \u03b8q the set of unknown parameters assuming\n2\nq sources, that is \u03b8q = [Rs,q , Aq , \u03c3n,q\n, wq ], where Rs,q is the\ntransmitted signals' correlation matrix assuming q sources; Aq\n2\nis the steering matrix assuming q sources; \u03c3n,q\nis the white\nnoise level; and wq is the vector containing the parameters\nrepresenting the deviations from the spatially white noise\nassumption. The parameter space of the unknown parameters\ngiven q sources is denoted by \u0398q . The problem is to estimate\nq based on N independent snapshots of the array output,\nx1 = x(t1 ), . . . , xN = x(tN ) [1].\n\nwhere L (\u03b8q ) = log fX (X|\u03b8q ) is the log-likelihood of the\nmeasurements, \u03b8\u0302q = arg max\u03b8q \u2208\u0398q fX (X|\u03b8q ) is the maximum likelihood (ML) estimate of the unknown parameters\ngiven the qth family of distributions, and penalty(q) is some\ngeneral penalty function associated with the particular ITC\nused. The MDL and AIC estimators are given by penalty(q) =\n0.5|\u0398q | log (N ) and penalty(p) = |\u0398q | respectively, where\n|\u0398q | is the number of free parameters in \u0398q [20], [21], [1]. It\nis well known that, asymptotically and under certain regularity\nconditions, the MDL estimator minimizes the description\nlength (measured in bits) of both the measurements, X, and\nthe model, \u03b8\u0302q [22], while the AIC criterion minimizes the\nKullback-Liebler divergence between the various models and\nthe true one. In the rest of the paper we will consider only the\nMDL criterion, although other penalty functions can also be\ntreated similarly.\nAlthough in many problems associated with array processing, e.g., direction of arrival (DOA) estimation, one has some\nprior knowledge about the array structure, when estimating the\nnumber of sources this prior knowledge is usually ignored [1],\n[18]. The reason for this is that by ignoring the array structure\nand assuming Gaussian signals and noise, and w \u2261 0, the\nresulting MDL estimator (2), termed here the Gaussian-MDL\n(GMDL) estimator [11], has a simple closed form expression\ngiven by [1]\n\nq\u0302|GMDL = arg\n\nmin\n\nq=0,...,p\u22121\n\n\uf8ee\n\n\uf8ef\n\uf8f0\u2212N log \u0010\n+\n\nQp\n\ni=q+1 li\n\n1\np\u2212q\n\nPp\n\ni=q+1 li\n\n\u0011p\u2212q\n\n1\n(q(2p \u2212 q) + 1) log N\n2\n\n\u0015\n\n(3)\n\nwhere l1 \u2265 l2 \u2265 * * * \u2265 lp are the eigenvalues of the empirical\nb = 1 P xi xH . It is\nreceived signal's correlation matrix, R\ni\nN\nwell known that when w \u2261 0 the GMDL estimator is a\nconsistent estimator of the number of sources, while when\nw 6= 0, the GMDL estimator, (3), is not consistent and in fact,\nas the number of snapshots approaches infinity, the probability\nof error incurred by the GMDL estimator approaches one [11].\nDenote by Rq the set of all positive definite, rank q,\nHermitian, p \u00d7 p matrices, and by W the set of all zero mean\np-length vectors. Given the assumptions made in the problem\nformulation, the MDL estimator for estimating the number\nof sources, denoted hereafter as the Robust-MDL (RMDL)\n\n\fFISHLER AND POOR: ROBUST ESTIMATION OF THE NUMBER OF SOURCES\n\nestimator, is given by,\nq\u0302RMDL = arg min\nq=0,...,p\u22121\nn\n2\nN log \u00c2q R\u0302s,q \u00c2H\nq + \u03c3\u0302n,q I + diag (\u0175q )\n\u001a\u0010\n\u0011\u22121 \u001b\nH\n2\n+Tr\n\u00c2q R\u0302s,q \u00c2q + \u03c3\u0302n,q I + diag (\u0175q )\nR\u0302\n\u001b\n1\n+ (q(2p \u2212 q) + p) log N\n(4)\n2\n2\nwhere \u00c2q , R\u0302s,q , \u03c3\u0302n,q\n, \u0175q are the ML estimates of the unknown parameters assuming q sources, that is\n2\n\u00c2q , R\u0302s,q , \u03c3\u0302n,q\n, \u0175q = arg\nmax\n2\nAq Rs,q AH\nq \u2208Rq ,\u03c3n,q >0,wq \u2208W\n\u0002\nH\n2\n\u2212N log Aq Rs,q Aq + \u03c3n,q I + diag (wq )\nn\n\u0001\u22121 oi\n2\n+Tr Aq Rs,q AH\nR\u0302 . (5)\nq + \u03c3n,q I + diag (wq )\n\nNote that since Aq Rs,q AH\n\u2208 Rq , by Pusing eigenq\nq\nH\ndecomposition we can write Aq Rs,q AH\nq =\ni=1 \u03bbi vi vi ,\nwhere {vi } is an orthonormal set of vectors. Hence, the vector\nof unknown parameters assuming q sources is also given by\n\u03b8q = [\u03bb1 , . . . , \u03bbq , v1T , . . . , vqT , wT , \u03c3n2 ].\n\n(6)\n\nD. Organization of the Paper\nThe rest of this paper is organized as follows: In Section II\nwe discuss the indentifiabilty of the estimation problem and\nwe prove the consistency of the RMDL estimator. In Section\nIII we describe a low-complexity algorithm for approximating\nthe RMDL estimator, (4), and we discuss the properties of\nthis algorithm. In Section IV we present empirical results. In\nSection V some concluding remarks are provided.\nII. I DENTIFIABILITY\n\nAND C ONSISTENCY OF THE\nE STIMATOR\n\nRMDL\n\nA. Identifiability\nConsider a parameterized family of probability density\nfunctions (pdf's) fX (x|\u03b8), \u03b8 \u2208 \u0398. This family of densities is said to be identifiable if for every \u03b8 6= \u03b8 \u2032 , the\nKullback-Liebler divergence between fX (x|\u03b8) and fX (x|\u03b8 \u2032 )\nis greater than zero, that Ris D (fX (x|\u03b8) ||fX (x|\u03b8 \u2032 )) > 0,\nwhere D(f (x)||g(x)) = f log fg is the Kullback-Leibler\ndivergence between f (x) and g(x) [23]. This condition insures\nthat there is a one-to-one relationship between the parameter\nspace and the statistical properties of the measurements.\nThe problem discussed in Section I-B is a model order\nselection problem [22]. This problem is unidentifiable if it\nis possible to find for some k 6= l two points in the parameter\nspace, \u03b8k \u2208 \u0398k and \u03b8l \u2208 \u0398l such that f (*|\u03b8k ) = f (*|\u03b8l ).\nUnfortunately, we can, in fact, identify two such points leading\nto the conclusion that the estimation problem discussed in\nSection I-B is unidentifiable. The received signal's pdf is\nfully characterized by the received signal's correlation matrix.\nThus, in order to prove that the problem is unidentifiable, it\nsuffices to find two different parameter values under which the\ncorresponding received signal's correlation matrices are equal.\n\n3\n\nTake, for example, the following received signal correlation\nmatrix: diag ([11, 10.5, 9.5, 10]). This correlation matrix can\nresult from a noise-only scenario with \u03c3n2 = 10.25 and w =\n[0.75, 0.25, \u2212 0.75, \u2212 0.25], or from a one source scenario\nwhere \u03c3n2 = 10, w = [0, 0.5, \u2212 0.5, 0], a = [1, 0, 0, 0]T , and\nRs = 1. Thus we have found two scenarios, the first corresponding to a noise only scenario, and the other corresponding\nto a one source scenario, such that the distribution of the\nreceived signal vector is the same. Thus, this example shows\nthat the estimation problem formulated is unidentifiable.\nIn order to make the estimation problem identifiable, all the\npoints having the same received signal pdf must be removed\nfrom the parameter space except one. As is the custom in\nmodel order selection problems, among all the points having\nthe same received signal pdf, the one with the smallest number\nof sources, that is, the point with the lowest number of\nunknown parameters, is left in the parameter space, and the\nremaining ones are deleted. The main question that arises\nis whether most of the points in the parameter space are\nidentifiable or not. Fortunately, the answer to this question\nis yes; that is, most of the points in the parameter space\nare identifiable. The following lemma characterizes all the\nunidentifiable points in the parameter space.\nLemma 1: Suppose q < p. Then \u03b8q is an unidentifiable\npoint\nthe parameter space if and only if the matrix\nPq in H\ni=1 vi vi contains \u03b1ej = [0j\u22121 , 1, 0p\u2212j ] as its jth row\nfor some j \u2208 [1, . . . , p], where vi defined in (6).\nProof of Lemma 1: See Appendix I\nThe proof of Lemma 1 provides an interesting physical\ninterpretation of the unidentifiable points. In particular, it can\nbe seen from the proof of the lemma that all the unidentifiable\npoints are similar to the above example used to show that\nthe problem is unidentifiable. That is, an unidentifiable point\ncorresponds to a scenario where there are, say q sources, and\none of them is received at only one of the sensors. Since\nthis source can not be distinguished from a deviation, from\nsome nominal value, of the noise level in the corresponding\nelement, this scenario could be confused with a different\nscenario having one fewer source, and an increase in the noise\nlevel at the proper element. From a practical viewpoint, this\ntype of situation is a rarity.\nB. Consistency of the RMDL Estimator\nIn the previous subsection it was proved that the estimation\nproblem defined in Section I-B is unidentifiable. Nevertheless,\nit was also argued that only a small portion of the points in the\nparameter space are unidentifiable, meaning that by excluding\nthese points from the parameter space the problem becomes\nidentifiable. For the rest of this paper, we consider these points\nto be excluded from the parameter space. Once the estimation\nproblem has been shown to be identifiable, it is possible to\ninfer the number of sources from the measurements. However\nfor a specific estimator, the issue of consistency must be\nconsidered.\nIn model order selection, the common performance measure\nis the probability of error, that is Pe = P (q\u0302 6= q) [3]. In what\nfollows the RMDL estimator, (4), is proven to be a consistent\nestimator, that is limN \u2192\u221e Pe = 0.\n\n\f4\n\nLemma 2: The RMDL estimator, (4), is a consistent estimator of the number of sources.\nProof of Lemma 2: See Appendix II\nDeviations from the assumption of spatial homogeneity are\npart of our general model. Thus, even if the noise levels at\nvarious sensor are not equal, according to Lemma 2 the RMDL\nestimator, (4), is still consistent. That is, the probability of\nerror of the RMDL estimator still converges to zero even in\nthe presence of deviations from assumption of equal noise\nlevels.\nIt is well known that the GMDL estimator, (3), is a nonrobust estimator when the noise levels at the various sensor are\nnot equal, i.e., the probability of error of the GMDL estimator\napproaches one as N \u2192 \u221e. Nevertheless, it is known that\nthe GMDL estimator is robust against statistical mismodeling.\nUnder very weak regularity conditions, if the transmitted\nsignal and/or the additive noise are non-Gaussian, then the\nprobability of error of the GMDL estimator still converges to\nzero. Fortunately, it can be shown that the RMDL estimator,\n(4) is robust against statistical mismodeling as well. Being\nrobust against both statistical and spatial mismodeling is an\nadvantage of the RMDL estimator over the GMDL estimator.\nWe conclude this subsection by proving that the RMDL\nestimator, (4) is a consistent estimator even in the presence\nof statistical mismodeling. Denote by g(x) the actual pdf\nof the received signal at some time instant, and by f (x|\u03b8)\nthe assumed measurement pdf, i.e., the Gaussian\n\b distribution.\nNote that it is still assumed that Rx = E xxH has the\nH\n2\nfollowing form\nR Rx = As Rs A + \u03c3n I + diag (w). Let\nEg {h(x)} = h(x)g(x)dx. The following lemma establishes\nthe consistency of the RMDL estimator when the sources are\nnot Gaussian\no\nn\nf (x|\u03b8) \u2202 log f (x|\u03b8) T\nand\nLemma 3: Assume that Eg \u2202 log\u2202\u03b8\n\u2202\u03b8\nn 2\no\n\u2202 log f (x|\u03b8)\nEg\nexist and are finite. Then the probability of\n\u2202\u03b8(\u2202\u03b8)T\nerror of the RMDL estimator converges to zero as N \u2192 \u221e.\nProof of Lemma 3: See Appendix III.\nIII. A P RACTICAL E STIMATION A LGORITHM\nIn the previous section the asymptotic properties of the\nRMDL estimators were considered. It was proven that the\nRMDL estimator is both a consistent and robust estimator of\nthe number of sources. These two properties make the RMDL\nestimator very appealing for use in practical problems. However the computational complexity of the RMDL estimator\nis still very high compared to that of the GMDL estimator.\nRecall that in order to implement the RMDL estimator ML\nestimates of the unknown parameters must be found for every\npossible number of sources. Since no closed-form expression\nfor these ML estimates exists, multi-dimensional numerical\nsearches must be used in order to find them. Even for moderate\narray sizes, e.g., p = 6, the number of unknown parameters is\na few dozen, which makes the task of finding the ML estimates\nimpractical.\nIn order to overcome the computational burden of computing the ML estimates, we propose to replace the ML estimates by estimates obtained using a low-complexity estimation\nalgorithm. A reasonable criterion used in array processing\n\napplications is to choose as an estimate the parameter vector\nthat minimizes the Frobenius norm of the error matrix [24],\n[25]; that is\n\u03b8\u0302q,LS\n\n=\n=\n=\n\nb \u2212 Rx (\u03b8q ))||2\narg min ||(R\nF\n\u03b8q \u2208\u0398q\nn\no\nb \u2212 Rx (\u03b8q ))(R\nb \u2212 Rx (\u03b8q ))H\narg min Tr (R\n\u03b8q \u2208\u0398q\n\narg min\n\n\u03b8q \u2208\u0398q\n\np\np X\nX\ni=1 j=1\n\n2\n\nb \u2212 Rx (\u03b8q ))(R\nb \u2212 Rx (\u03b8q ))]ij(7)\n[(R\n\nand the corresponding estimate for the number of sources is\ngiven by,\n\u0015\n\u0014\n\u0011\n\u0010\nlog N\n. (8)\n\u2212L \u03b8\u0302q,LS + q(2p \u2212 q)\nq\u0302 = arg min\nq=0,...,p\u22121\n2\n\nReplacing the ML estimates with their LS counterparts\nraises two important questions. One is whether replacing the\nML estimates with the LS estimates results in performance\nloss; and the second is whether efficient algorithms for computing the LS estimates exist. Fortunately, it can be demonstrated that no performance loss is incurred (asymptotically)\nby replacing the ML estimates with the LS estimates, and\nan efficient algorithm for computing the LS estimates exists.\nIt was pointed out by one of the reviewers that for finite\nsample sizes since the ML estimates\n\u0011\n\u0011\n\u0010by the LS\n\u0010 are replaced\nestimates, it is not guaranteed that L \u03b8\u0302q,LS < L \u03b8\u0302q+1,LS .\nThis problem can be easily solved by noting that because\nthe problem is a nested hypotheses problem hat\u03b8q \u2208 \u0398q+1 .\nTherefore, if L(\u03b8\u0302q|LS ) < L(\u03b8\u0302q+1|LS ), we can use L(\u03b8\u0302q|LS )\ninstead of L(\u03b8\u0302q+1|LS ) in the MDL formula.\nOur problem is a model order selection problem, and our\nmain interest is in the probability of error of the proposed\nestimator. In [11], it is demonstrated that the MDL's asymp\u2217\ntotic probability of error depends on \u03b8q and \u03b8q\u22121\n\u2208 \u0398q\u22121 ,\n\u2217\nwhere \u03b8q\u22121 = arg min\u03b8q\u22121 D(f (x|\u03b8q )||f (x|\u03b8q\u22121 )). It is\n\u2217\nis the limit of the ML estimates under\neasily seen that \u03b8q\u22121\n\u2192\u221e\n\u2217\n\u02c6 |\u03b8q N\u2212\u2192\n\u03b8q\u22121\n.\nthe assumption of q \u2212 1 sources, i.e., \u03b8q\u22121\nAnalysis similar to that in [11] demonstrates that if a consistent\nestimator is used instead of the ML estimator in the MDL\nestimator, then the asymptotic probability of detection remains\nthe same. Since the LS estimator is a consistent estimator of\nthe unknown parameters, the asymptotic performance of the\nRMDL's simplified version, (8), is the same as the asymptotic\nperformance of the RMDL estimator, (4).\nSimilarly to the ML estimates, \u03b8\u0302q,LS is the solution of a\nnonlinear programming problem, requiring brute-force multidimensional search. Nevertheless, based on the concept of\nserial interference cancellation (SIC) [26], in what follows a\nnovel algorithm for finding \u03b8\u0302q,LS is suggested. In this algorithm the unknown parameters are divided into two groups,\nand given the estimate of one group of unknown parameters,\nan estimate of a second group of unknown parameters is\nconstructed. The estimates are constructed in such a way as\nto insure a decrease in the Frobenius norm of the error matrix\nafter each iteration. The estimation process iterates between\nthe two groups of unknown parameters, until the estimates\nconverge to a stationary point.\n\n\fFISHLER AND POOR: ROBUST ESTIMATION OF THE NUMBER OF SOURCES\n\nIn multiple access communications two (or more) users\ntransmit information over two non-orthogonal subspaces. The\nserial interference cancellation multiuser detection algorithm\nfor data detection in such situations works as follows. First,\nthe unknown parameters associated with the first user are\nestimated. Next, an error signal is constructed by subtracting\nfrom the received signal the estimated first user's transmitted\nsignal. In the next stage, the unknown parameters associated\nwith the second user are estimated from the error signal. In\nthe next iteration, the unknown parameters associated with\nthe first user are re-estimated based on the received signal\nafter subtraction of the estimated second user's transmitted\nsignal. This iterative process is continued until convergence is\nreached.\nThe principle behind the SIC multiuser detector can\nbe used for constructing a novel low-complexity estimation algorithm for estimating the unknown parameters\nin the present situation. In what follows such a lowcomplexity estimation algorithm is described and its properties are discussed. The unknown parameters in our estimation problem are [\u03bb1 , . . . , \u03bbq , v1T , . . . , vqT , wT , \u03c3n2 ], or\n2\nequivalently, Aq Rs,q AH\nq , \u03c3n,q , wq . These unknown parameters are divided into two groups. The first group contains\n[\u03bb1 , . . . , \u03bbq , v1T , . . . , vqT , \u03c3n2 ], or equivalently Aq Rs,q AH\nq and\n2\n, while the second contains wq . The first group corre\u03c3n,q\nsponds to the unknown parameters of the ideal point source\nplus spatially white additive noise model, while the second\ncorresponds to the unknown parameters representing the deviations from the ideal model. In a sense, wq can be regarded\nas the unknown parameters that robustify\nthe estimator. The\nb x = 1 PN x(ti )x(ti )H which\ninput to the algorithm is R\nt=1\nN\nis a sufficient statistic for estimating the unknown parameters,\nassuming Gaussian sources and \u0001noise.\nH\nj\nDenote by \u03c3n,q\n, Ajq Rjs,q Ajq , and wqj the estimates of\nthe unknown parameters after the jth iteration. The proposed\nalgorithm is implemented\nas follows: In the first iteration,\n\u0001H\n1\nb x . The best estiare estimated from R\n\u03c3n,q\n, A1q R1s,q A1q\nmates, in both the ML sense and the Least Squares (LS) sense\n(see appendix IV), are\nv\nu\np\nX\nu 1\n1\n\u03c3n,q\n=t\nli\n(9)\np \u2212 q i=q+1\nA1q R1s,q A1q\n\n\u0001H\n\n=\n\nq \u0010\nX\n\n1\nli \u2212 \u03c3n,q\n\ni=1\n\n\u00012 \u0011\n\nvi viH\n\n(10)\n\nwhere l1 > * * * > lp and v1 , . . . , vp are, respectively, the\nb x . In the next step an error\neigenvalues and eigenvectors of R\nbx\nmatrix, denoted by E, is constructed by subtracting from R\nthe estimate for the estimated part of the received signal's\ncorrelation matrix\ncorresponding\nto the ideal model, that is\n\u00012\n\u0001\n1\n1 H\n1 1\n+ \u03c3n,q I. Thus, the error matrix is given\nAq Rs,q Aq\nby\n\u0001\n\u0001\nb \u2212 A1 R1 A1 H \u2212 \u03c3 1 2 I.\n(11)\nE=R\nn,1\nq\nq s,q\n\nNext, wq1 is estimated from E, and the best estimate in both\nthe ML and LS sense is,\nwq1 = diag (E) .\n\n(12)\n\n5\n\nAt the jth iteration, we\nthat\n\u0001Happly the same procedure except\nj\nb \u2212 wj\u22121 , while\nare estimated from R\nand Ajq Rjs,q Ajq\n\u03c3n,q\nq\n\u0001\n\u00012\nj\nb \u2212 Ajq Rjs,q Ajq H \u2212 \u03c3n,q\nwqj is estimated from R\nI.\nSummarizing the above, our proposed estimation algorithm\nis given as follows:\nb\n1) Initialize E = R.\n2) Compute l1 \u2265 * * * lp , v1 , . . . , vp the eigenvalues and the\ncorresponding eigenvectors of E.\n3) Compute the following estimates,\nv\nu\np\nX\nu 1\nt\n\u03c3n,q =\nli\n(13)\np \u2212 q i=q+1\nAq Rs,q (Aq )\n\nH\n\n=\n\nq \u0010\nX\n\n2\n\nli \u2212 (\u03c3n,q )\n\n\u0011\n\nvi viH (14)\n\ni=1\n\u0010\n\u0011\nb \u2212 Aq Rs,q (Aq )H \u2212 (\u03c3n,q )2 I(15)\nwq = diag R\n\nb \u2212 wq .\n4) Compute E = R\n5) If the estimates have stabilized, stop; otherwise return\nto step 2.\nA major question that arises is whether this algorithm is\nguaranteed to converge and, if so, whether the stationary\npoint of the algorithm is optimal in some sense. Fortunately,\nthe answers to these questions are yes. In Appendix IV it\nis proven that in each step of the algorithm, the Frobenius\nb \u2212 R(\u03b8qn )||2 \u2265\nnorm of the error matrix decreases, that is ||R\nF\nb \u2212 R(\u03b8qn+1 )||2 , where \u03b8qn is the estimate of the unknown\n||R\nF\nparameters after the nth iteration. This also proves that the\nproposed algorithm converge to a local minimum of the LS\ncost function.\nConsider our proposed iterative algorithm. The most complex operation in our algorithm is the eigenvalue decomposition whose complexity is O(p3 ). Since the process is\nrepeated p times (one for each possible number of sources),\nthe complexity of our algorithm is O(p4 ) per iteration.\nSince no closed expression for the ML estimates exists,\nsome numerical maximization method must be used. Therefore, the complexity of the ML estimator depends on the\nnumber of iterations and the exact numerical maximization\nmethod used. However, we can still demonstrate that the complexity of the ML estimator is higher than that of our proposed\nalgorithm. Since efficient numerical maximization algorithms\nrequire the computation of the derivative of the likelihood\nfunction, we examine the complexity of computing this derivative. The\nin computing the derivative\n\b most complex operation\nnh\ni \u22121 o\nb\n\u2202Tr R\u22121\nx (\u03b8)R\n\u2202Rx (\u03b8)\nb \u22121\nis\n,\n= \u2212Tr R\u22121\nx (\u03b8)RRx (\u03b8)\n\u2202\u03b8i\n\u2202\u03b8i\n8\nwhich has a complexity of O(p ). This operation has to be\nrepeated p times, one for each possible number of sources.\nTherefore the complexity of computing the derivative of the\nlikelihood function per iteration is O(p9 ). It follows that for\np > 3, the complexity of the ML estimator is higher by several\norders of magnitude than our proposed iterative algorithm.\nIV. S IMULATIONS\nIn this subsection simulation results with synthetic data are\npresented. We consider a uniform linear array with 10 ele-\n\n\f6\n\nments, and assume three equal-power and independent sources\nhaving signal-to-noise ratio (SNR) per element of 0 dB.\nThe sources' directions of arrival (DOA's) are taken to be\n[0\u25e6 5.7\u25e6 11.4\u25e6 ]. We consider two cases: the first corresponds\n\u0001\nto complex Gaussian sources, i.e., s(t) \u223c CN 0, \u03c3 2 ; and\nthe second corresponds to sources that are distributed as\ncomplex Laplacian sources, i.e., R (s(t)) and I (s(t)) are\n|x|\nindependent random variables having pdf \u03b11 e\u2212 \u03b1 . The second\ncase corresponds to impulsive sources usually found in biomedical application.\nWe first consider the case in which w = 0; i.e., the noise\nis spatially white. Figure 1 depicts the probability of correct\ndecision in this case of both the GMDL estimator and the\nRMDL estimator when used with the estimates computed by\nthe iterative algorithm. Since no deviations from the spatial\nwhite noise model exist in this case, the GMDL estimator is\nboth consistent and robust, and indeed the empirical probability of error of the GMDL estimator converges to zero\nwhether the sources are Gaussian or Laplacian. The RMDL\nestimator is also both a consistent and a robust estimator, and\nagain the empirical probability of error of the RMDL estimator\nconverges to zero as well, independent of the source distribution. These empirical results demonstrate that the GMDL\nestimator is superior to the RMDL estimator in this situation,\nan additional 100 samples are required by the RMDL estimator\nin order to achieve the same probability of correct decision as\nthe GMDL estimator. In [27] it was proven that by exploiting\nmore prior information the performance of the MDL estimator\nimproves. This explains the superiority of the GMDL estimator\nover the RMDL estimator, since the GMDL estimator makes\nuse of the spatial whiteness of the additive noise process, while\nthe RMDL estimator ignores this information.\nIn practice, multi-channel receivers are used in DOA estimation systems. The noise level in each receiver is different\nand hence the system has to be calibrated. Due to finite\nintegration time, errors and different drifts in each channel,\nsmall differences in the noise levels at the different receiver\nchannels exist. In the next example this scenario is simulated. For simulating this scenario w is taken to be w =\n2\n\u03c3n\n10 [\u22129/10, \u22127/10, . . . , 9/30]. This w represents a scenario in\nwhich the noise level in each receiver is different from the\nnominal noise level by no more than \u221210 dB. Figure 2 depicts\nthe probability of correct decision of both the GMDL and the\nRMDL estimators as functions of the number of snapshots\ntaken for both Gaussian and Laplacian sources.\nThe multiplicity of the received signal correlation matrix's\nsmallest eigenvalue is equal to one, and hence the GMDL\nestimator is not consistent, that is P (q\u0302 6= 3) \u2192 1 [3]. From\nFig. 2 it is seen that the empirical probability of error of the\nGMDL estimator converges to one as the number of snapshots increases. Nevertheless, it can be seen that this happen\nonly when the number of snapshots is quite large (about\n10,000). This phenomenon can be explained by examining\nthe eigenvalues of the received signal's correlation matrix.\nThe eigenvalues of the received signal's correlation matrix\nare given by [20.1, 10.9, 1.93, 1.07, * * *, 0.92]. For the GMDL\nestimator, the simulated scenario corresponds to a scenario\n\nwhere p \u2212 1 sources exists, the noise level equals to 0.9, and\nthe SNR of the fourth strongest source at the array output is\n\u22127 dB. The GMDL requires about 10,000 snapshots in order\nfor the probability of detection of this weak \"virtual\" source\nto be noticeable. As the number of snapshots increases, the\nprobability of detection of this weak virtual source increases\nas well, causing the probability of correct decision to decrease\nto zero. On the other hand, it can be seen that the probability\nof error of the RMDL estimator converges to zero as the\nnumber of snapshots increases for both the Gaussian and the\nLaplacian sources. This demonstrate both the consistency and\nthe robustness of the RMDL estimator.\nIn Figure 3 we study the spatial separation between the\nsources required for reliable detection. We assume that the\nthree sources' directions of arrival are [0, \u03c1, 2\u03c1], 15,000 snapshots are taken by the receiver, and the SNR per element is\neither 0 dB or 5 dB. Figure 3 depicts the probability of correct\ndecision of both the GMDL and the RMDL estimators for both\nGaussian and Laplacian sources as a function of \u03c1.\nIn the figure we can see again that the RMDL estimator\noutperforms the GMDL estimator. Even if large separation\nbetween the sources exists, the probability of correct decision\nof the GMDL estimator does not approach one. The probability of correct decision of the RMDL estimator, on the\nother hand, approaches one with the increase in the separation\nbetween the sources. This difference can be explained with\nthe aid of the received signal correlation matrix's eigenvalue\nspectrum. The received signal correlation matrix eigenvalues\nequal [11.54, 11.05, 10.39, 1.07, ..., 0.9237]. The three highest eigenvalues correspond to the three sources. However,\ndue to the different noise level in each sensor, the rest of\nthe eigenvalues are not equal to the noise level. The large\nnumber of snapshots enables the GMDL estimator to detect\nthe differences in the weakest eigenvalues as valid sources,\nwhich results in an error event. However, if the number of\nsnapshots is reduced, the GMDL estimator will not detect\nthese differences. Nonetheless, if the number of snapshot is\nreduced, and a valid weak source exists, the GMDL estimator\nwill not detect this valid source.\nAs discussed in the beginning of this paper, in biological\napplications the noise level may vary considerably between\nthe different receiver channels. Thus, large deviations from the\nideal model are expected in such systems. For simulating this\n\u03c32\ntype of scenario we take w = 2n [\u22129/10, \u22127/10, . . . , 9/10],\nwhich represents deviations of up to \u22123 dB from the nominal\nnoise level. Figure 4 depicts the probabilities of correct decision of the GMDL and the RMDL estimators as functions of\nthe number of snapshots taken.\nIt can be seen that in this scenario the empirical error probability of the GMDL estimator approaches one\neven when the number of snapshots is small (about 750).\nAgain, this can be explained by examining the received\nsignal correlation matrix's eigenvalues, which are equal to\n[20.13, 10.93, 2, 1.36, . . ., 0.62]. The GMDL estimator interprets this scenario as a p \u2212 1 sources scenario with the noise\nlevel equal to 0.5, and the SNR of the fourth strongest source\nat the array output is 6 dB. Due to its high SNR, only a small\nnumber of snapshots are required for detecting this \"virtual\"\n\n\fFISHLER AND POOR: ROBUST ESTIMATION OF THE NUMBER OF SOURCES\n\nsource, and by detecting this virtual source an error event is\ncreated. As the number of snapshots increases, the probability\nof detection of this virtual source increases as well, causing the\nprobability of correct decision to decrease to zero. Again, it\ncan be seen that the probability of error of the RMDL estimator\nconverges to zero as the number of snapshots increases.\nIn the last figure, Figure 5, we study the spatial separation between the sources required for reliable detection\nwhen the deviation from the equal noise power assumption\nis large. We assume that three sources' directions of arrival\nare [0, \u03c1, 2\u03c1], 250 snapshots are taken by the receiver, and the\nSNR per element is either 0 dB or 5 dB. Figure 5 depicts the\nprobabilities of correct decision of both the GMDL and the\nRMDL estimators for the Gaussian and Laplacian sources as\na function of \u03c1. Again, we can see that the RMDL estimator\noutperforms the GMDL estimator. Even for large separation\nbetween the sources, the deviation from the equal noise level\nassumption results in a change in the eigenvalue structure. This\nchange is detected by the GMDL estimator as an additional\nsources, and hence an error event occurs.\nV. S UMMARY\n\nAND\n\nC ONCLUDING R EMARKS\n\nIn this paper the problem of robust estimation of the\nnumber of sources impinging on an array of sensors has\nbeen addressed. It has been demonstrated that by proper use\nof additional unknown parameters, the resulting estimator,\ndenoted as the RMDL estimator, is robust against both spatial\nand statistical mismodeling. This situation represents an improvement on the traditional MDL estimator which is robust\nonly against statistical mismodeling. In addition, a novel lowcomplexity algorithm for computing the estimates of the unknown parameters has been presented. It has been shown that\nthis algorithm converges to the LS estimates of the unknown\nparameters. On one hand, the computational complexity of\nthe proposed estimator is higher than the complexity of the\ntraditional MDL estimator; on the other hand the complexity\nis far less than the complexity of known robust estimators\nwhich require several multi-dimensional searches.\nThe proposed estimation algorithm can be used to robustify\nother estimation algorithms as well. Take for example the MUSIC algorithm for estimating DOAs [28]. It is well known that\nthe MUSIC algorithm is not robust against spatial mismodeling. Even slight spatial mismodeling can cause a large error in\nthe estimated signal subspace, leading to substantial estimation\nerrors. The use of our estimation technique to improve the\nrobustness of the MUSIC algorithm is an interesting topic for\nfurther study.\nR EFERENCES\n[1] M. Wax and T. Kailath, \"Detection of signals by information theoretic\ncriteria,\" IEEE Trans. on Acoustics, Speech and Signal Processing.,\nvol. ASSP-33, pp. 387\u2013392, Feb. 1985.\n[2] M. Kaveh, H. Wang, and H. Hung, \"On the theoretical performance\nof a class of estimators of the number of narrow-band sources,\" IEEE\nTrans. on Acustic Speech and Signal Processing, vol. ASSP-35, no. 11,\npp. 1350\u20131352, 1987.\n[3] L. C. Zhao, P. R. Krishnaiah, and Z. D. Bai, \"On detection of the number\nof signals in the presence of white noise,\" J. Multivariate Analysis,\nvol. 20, pp. 1\u201320, Jan. 1986.\n\n7\n\n[4] T. W. Anderson, \"Asymptotic theory for principal component analysis,\"\nAnn. Math. Stat., vol. 34, pp. 122\u2013148, 1963.\n[5] Y. I. Abramovich, N. K. Spencer, and A. Y. Gorkhov, \"Detectionestimation of more uncorrelated Gaussian sources than sensors in\nnonuniform linear antenna arrays I:. fully augmentable arrays,\" IEEE\nTransactions on Signal Processing, vol. SP-49, pp. 959\u2013971, May 2001.\n[6] C. M. Cho and P. M. Djuric, \"Detection and estimation of DOA's\nvia Bayesian predictive densities,\" IEEE Trans. on Signal Processing,\nvol. SP-42, pp. 3051\u20133060, Nov. 1994.\n[7] E. Fishler and H. Messer, \"On the use of order statistics for improved\ndetection of signals by the MDL criterion,\" IEEE Trans. on Signal\nProcessing, vol. SP-48, pp. 2242\u20132247, Aug. 2000.\n[8] K. M. Wong, Q.-T. Zhang, J. P. Reilly, and P. C. Yip, \"On information\ntheoretic criteria for determining the number of signals in high resolution array processing,\" IEEE Trans. on Signal Processing, vol. SP-38,\npp. 1959\u20131971, Nov. 1990.\n[9] H. T. Wu, J. F. Yang, and F. K. Chen, \"Source number estimation\nusing transformed Gerschgorin radii,\" IEEE Trans. on Signal Processing,\nvol. SP-43, pp. 1325\u20131333, Jun. 1995.\n[10] A. M. Zoubir, \"Bootstrap methods for model selection,\" AEUIinternational Journal of Electronics and Communications, vol. 53,\npp. 386\u2013392, 1999.\n[11] E. Fishler, M. Grossman, and H. Messer, \"Estimation the number\nof sources using information theoretic criteria: General performance\nanalysis,\" IEEE Trans. on Signal Processing, vol. 50, pp. 1026\u20131035,\nMay 2002.\n[12] W. Xu and M. Kaveh, \"Analysis of the performance and sensitivity of\neigendecomposition - based detectors,\" IEEE Trans. on Signal Processing, vol. SP-43, pp. 1413\u20131426, Jun. 1995.\n[13] Q.-T. Zhang, K. M. Wong, and P. C. Y. J. P. Reilly, \"Statistical analysis of\nthe performance of information theoretic criteria in the detection of the\nnumber of sources in array processing,\" IEEE Trans. on Acustic Speech\nand Signal Processing., vol. ASSP-37, pp. 1557\u20131566, Oct. 1989.\n[14] R. F. Brcich, A. M. Zoubir, and P. Pelin, \"Detection of sources using\nbootstrap techniques,\" IEEE Transaction on Signal Processing, vol. SP50, pp. 206\u2013215, February 2002.\n[15] B. M. Radich and K. M. Buckley, \"Proper prior marginalization of the\nconditional ML model for combined model selection/source localization,\" 1995 International Conference on Acoustics, Speech, and Signal\nProcessing, 1995. ICASSP-95., vol. 3, pp. 2084\u20132087, 1995.\n[16] H. Wang and M. Kaveh, \"Coherent signal subspace processing for the\ndetection and estimation of angles of arrival of multiple wide-band\nsources,\" IEEE Trans. on Acoustics Speech and SIgnal Processing,\nvol. ASSP-33, pp. 823\u2013831, April 1985.\n[17] Y. I. Abramovich, N. K. Spencer, and A. Y. Gorokhov, \"Detectionestimation of more uncorrelated Gaussian sources than sensors in\nnonuniform linear antenna arrays II: Partially augmentable arrays,\" IEEE\nTrans. on Signal Processing, vol. 51, pp. 1492\u20131507, June 2003.\n[18] M. Wax, \"Detection and localization of multiple sources via the\nstochastic signal model,\" IEEE Trans. on Signal Processing, vol. SP39, pp. 2450\u20132456, Oct. 1991.\n[19] S. Niijima and S. Ueno, \"MEG source estimation using the forth\norder MUSIC method,\" IEICE Transaction on Information and Systems,\nvol. E85D, pp. 167\u2013174, Janurary 2002.\n[20] H. Akaike, \"Information theory and an extension of the maximum\nlikelihood principle,\" in 2nd Int. Symp. Inform. Theory, suppl. Problem\nof control and Inform. Theory, pp. 267\u2013281, 1973.\n[21] J. Rissanen, \"Modeling by shortest data description,\" Automatica,\nvol. 14, pp. 465\u2013471, 1978.\n[22] J. Rissanen, \"Universal coding, information prediction, and estimation,\"\nIEEE Trans. on Information Theory, vol. IT-30, pp. 629\u2013636, July 1984.\n[23] T. M. Cover and J. A. Thomas, Elements of Information Theory. WileyInterscience, 1991.\n[24] J. F. Bohme and D. Kraus, \"On least squares methods for direction of\narrival estimation in the presence of unknown noise fields,\" in IEEE\nInternational Conference on Acoustics, Speech, and Signal Processing,\n1988, pp. 2833\u20132836, New York, NY, April 1988.\n[25] K. M. Wong, \"Estimation of the directions of arrival of signals in\nunknown correlated noise part I: The MAP approach and its implementation,\" IEEE Transaction on Signal Processing, vol. SP-40, pp. 2007\u2013\n2017, August 1992.\n[26] S. Buzzi and H. V. Poor, \"Channel estimation and multiuser detection\nin long-code DS/CDMA systems,\" IEEE Journal of Selected Areas in\nCommunications, vol. 19, pp. 1476\u20131487, Aug. 2001.\n[27] E. Fishler and H. Messer, \"On the effect of a-priori information on\nperformance of the MDL estimator,\" in IEEE International Conference\n\n\f8\n\non Acoustics, Speech, and Signal Processing, 2002, vol. 3, pp. 2981\u2013\n2984, Orlando, FL, May 2002.\n[28] P. Stoica and A. Nehorai, \"MUSIC, maximum likelihood, and the\nCramer-Rao lower bound,\" IEEE Trans. on Acustic Speech and Signal\nProcessing, vol. ASSP-37, pp. 720\u2013743, a 1989.\n[29] E. L. Lehmann, Testing Statistical Hypotheses. John Wiley & Sons,\nNew York, 1959.\n[30] J. T. Kent, \"Robust properties of likelihood ratio tests,\" Biometrika,\nvol. 69, pp. 19\u201327, 1982.\n\nA PPENDIX I\nP ROOF OF L EMMA 1\nIn this appendix Lemma 1 is proven by a way of\nPqinduction\nH\non the number of sources. We first\nnote\nthat\nsince\ni=1 vi vi\nPq\nH\nis an Hermitian matrix, then if i=1 vi vi contains ej as its\njth row it also contains eTj as its jth column.\nWe first assume q = 0; that is, the noise-only scenario. Since\nthe noise-only scenario is always identifiable, the lemma holds\nfor this case.\nNow assume that the lemma holds\nPqfor q sources, that is for\nevery identifiable point \u03b8q \u2208 \u0398q , i=1 vi viH does not have\nej as one of its rows for every j = 1, . . . , p.\nThe following two lemmas will be essential in what follows.\nLemma 4: Assume that, \u03b8q \u2208 \u0398q is an identifiable point,\n\u25b3 Pq\nand denote by R\u0303(\u03b8q ) = i=1 \u03bbi vi viH . Denote by l1 \u2265 * * * \u2265\nlq+1 > 0 = * * * = 0 and {ci } are the eigenvalues and\ntheir corresponding eigenvectors of the matrix R\u0303(\u03b8q ) + ej eH\n.\nPq+1 jH\n)\n=\nq\n+\n1,\nthen,\nc\nc\nAssume that rank(R\u0303(\u03b8q ) + ej eH\ni\ni\nj\ni=1\nhas ej as his jth row.\nProof of Lemma 4: Assume with out loss of P\ngenerality that\np\nH\nj = 1. Since {ci } is an ortho-normal basis,\ni=1 ci ci =\nPp\nPq+1\nH\nH\nc c = I. According to the lemma we\ni=q+2\ni=1 ci ci +\nPq+1i i H\nhave to prove that i=1 ci ci has the following form,\nq+1\nX\n\nci cH\ni =\n\ni=1\n\n\u0014\n\n1\n0T\n\n0\nM\n\n\u0015\n\n.\n\n(16)\n\nP\nThis will happen if and only if pi=q+2 ci cH\ni has the following\nform\n\u0014\n\u0015\np\nX\n0\n0\nH\nci ci =\n,\n(17)\n0T M \u2032\ni=q+2\n\nPp\nPq+1\nH\nwhere M+M\u2032 = I, (recall that i=1 ci cH\ni +\ni=q+2 ci ci =\nPp\nH\nI). It is easy to verify that i=q+2 ci ci will have the form\ngiven by (17) if and only if [cl ]1 = 0 for every l > q + 1, so\nproving the lemma is equivalent to proving that [cl ]1 = 0 for\nevery l > q + 1. Assume that l > q + 1. From the properties\nof eigen-decomposition it follows that\n(R\u0303(\u03b8q ) + e1 eH\n1 )cl =\nq\nX\ni=1\n\n\u03bbi vi viH + e1 eH\n1\n\n!\n\nq+1\nX\n\nli ci cH\ni cl = 0 =\n\ni=1\n\ncl =\n\nq\nX\n\n\u03bbi (viH cl )vi + e1 [cl ]1 (18)\n\ni=1\n\nwhere \u03bb1 \u2265 * * * \u2265 \u03bbp and v1 , . . . , vp are, respectively, the\neigenvalues and eigenvectors of R\u0303(\u03b8q ). Since {ci }q+1\ni=1 spans\n\nthe subspace spanned by {vi }qi=1 , then viH cl = 0 for every\ni \u2264 q. Thus, by using (18),\ne1 [cl ]1 = 0,\n\n(19)\n\nwhich is possible if and only if [cl ]1 = 0.\nLemma 5: rank(R\u0303(\u03b8q ) + ei eH\ni ) = q + 1.\nProof of Lemma 5: Without loss of generality (wlg) it is\nproven that rank(R\u0303(\u03b8q ) + e1 eH\n1 ) = q + 1. Assume that\nrank(R\u0303(\u03b8q ) + e1 eH\n1 ) = q. Thus the rank of both R\u0303(\u03b8q )\nand R\u0303(\u03b8q ) + e1 eH\n1 are equal. Hence, it is possible to find\nk constants, denoted by a1 , . . . , aq , not all of them equal to\nzero, such that\ne1 =\n\nq\nX\n\nai vi .\n\n(20)\n\ni=1\n\nFrom (20) it is easy to see that\nH\nR\u0303(\u03b8q ) + e1 eH\n1 = VAV\n\n(21)\n\nwhere V = [v1 , . . . , vq ], and A is some q \u00d7 q diagonal\nmatrix. Since \u03b8q is an identifiable point, according the induction assumption there exists l > q such that [vl ]1 6= 0\n(otherwise according to the previous lemma the point would\nhave been unidentifiable contredicting our assumption that \u03b8q\nis identifiable). As such,\n\u0010\n\u0011\nR\u0303(\u03b8q ) + e1 eH\nvl = VAVH vl = 0 = e1 [vl ]1\n(22)\n1\nwhich is possible if and only if [vl ]1 = 0, This is a\ncontradiction, and Lemma 5 follows.\nDefine g(\u03b8q ) to be a function taking as an argument an\nidentifiable point in \u0398q , and returning a subset of \u0398q+1 ,\nsuch that for every \u03b8q+1 \u2208 g(\u03b8q ), Rx (\u03b8q+1 ) = Rx (\u03b8q ),\nand for every \u03b8q+1 \u2208 g(\u03b8k ), Rx (\u03b8q+1 ) 6= Rx (\u03b8q ). It\nis easy to see from Lemma 5 that \u03b8q+1 \u2208 g(\u03b8q ) if and\nH\n2\nonly if, R\u0303(\u03b8q+1\nP) = R\u0303(\u03b8q ) + [w(\u03b8q )]i ei ei , \u03c3n (\u03b8q+1 ) =\n1\n2\n\u03c3n (\u03b8q ) + p\u22121 j6=i [w(\u03b8k )]j , and [w(\u03b8q+1 )]k = [w(\u03b8q )]k \u2212\nP\n1\nj6=i [w(\u03b8q )]j where k 6= i, and 1 \u2264 i \u2264 p. From Lemma\np\u22121\n5 it is easy to see that (R\u0303(\u03b8q+1 )) has rank q + 1, and from\nLemma 4 it is easy to see that the conditions stated in Lemma\n1 are necessary. Since every unidentifiable point belongs to\nsome g(\u03b8q ) then the lemma is proved.\nA PPENDIX II\nP ROOF OF L EMMA 2\nIn this appendix the consistency of the RMDL estimator is\nproved. Specifically it is shown that the probability of error\nof the RMDL estimator converges to zero as the number of\nsnapshots increases to infinity. An error event will occur if and\nonly if there exists k 6= q such that RMDL(q) \u2212 RMDL(k) >\n0. Thus in order to prove the lemma it suffice to prove that\nfor every k 6= q, P (RMDL(q) \u2212 RMDL(k) > 0) \u2192 0.\nAssume that k > q. Since the problem is a nested hypothesis\nproblem, log fX (X|\u03b8\u0302k ) < log fX (X|\u03b8\u0302p\u22121 ) [11]. Also, since\n\u03b8\u0302q maximizes the likelihood of the measurements under the assumption of q sources, log fX (X|\u03b8\u0302q ) > log fX (X|\u03b8q ), where\n\n\fFISHLER AND POOR: ROBUST ESTIMATION OF THE NUMBER OF SOURCES\n\n\u03b8q is the true parameter value. Thus RMDL(q) \u2212 RMDL(k)\ncan be bounded as follows,\nRMDL(q) \u2212 RMDL(k) =\n\u2212 log fX (X|\u03b8\u0302q ) + log fX (X|\u03b8\u0302k ) +\nlog N\n(q(2p \u2212 q) \u2212 k(2p \u2212 k))\n2\n\u2264 \u2212 log fX (X|\u03b8q ) + log fX (X|\u03b8\u0302p\u22121 )\nlog N\n.\n+(q(2p \u2212 q) \u2212 k(2p \u2212 k))\n2\nUsing the spectral representation theorem, the\nsigPreceived\np\nnal's correlation matrix is equal to Rx (\u03b8q ) = i=1 \u03bbi vi viH ,\nwhere \u03bb1 > * * * > \u03bbp and v1 , . . . , vq are, respectively, the\neigenvalues and their corresponding eigenvectors of Rx (\u03b8q ).\n\u2217\nThus there exists a point, denoted by \u03b8p\u22121\n\u2208 \u0398p\u22121 such\n\u2217\nthat Rx (\u03b8q ) = Rx (\u03b8p\u22121 ) (take A = [v1 , . . . , vp\u22121 ], Rs =\n\u2217\ndiag (\u03bb1 \u2212 \u03bbp , . . . , \u03bb2 \u2212 \u03bb1 ) , \u03c3n2 = \u03bb1 , w = 0). Since \u03b8p\u22121\nis an inner point of \u0398p\u22121 , one can use the theory of likelihood [29] to show that asymptotically, \u22122 log fX (X|\u03b8q ) +\n\u2217\n2 log fX (X|\u03b8\u0302p\u22121 ) = 2 log fX (X|\u03b8\u0302p\u22121 ) \u2212 2 log fX (X|\u03b8p\u22121\n)\nis distributed as a chi-square random variable with degrees\nof freedoms equal to the number of unknown parameters,\n(p2 \u2212 1). We next note that since q < k, (q(2p \u2212 q) \u2212\nk(2p \u2212 k)) log2 N \u2192 \u2212\u221e as N approaches to infinity. Thus, as\nthe number of measurements increases, the probability that\n\u2212 log fX (X|\u03b8q ) + log fX (X|\u03b8\u0302p\u22121 ) exceeds |(q(2p \u2212 q) \u2212\nk(2p \u2212 k)) log2 N | is given by the tail of the chi-square distribution, which approaches zero as N approaches to infinity.\nThus,\nP (RMDL(q) \u2212 RMDL(k) > 0) <\n\u0010\nPr \u2212 log fX (X|\u03b8q ) + log fX (X|\u03b8\u0302p\u22121 )\n\u0013\nlog N\nN \u2192\u221e\n+ (q(2p \u2212 q) \u2212 k(2p \u2212 k))\n>0\n\u2192 0,(23)\n2\nwhich complete the first part of the consistency proof.\nNow, assume k < q. It was previously shown that under\nvery weak conditions the probability of miss of every MDL\nestimator converges to zero as N \u2192 \u221e [11]. In particular the\nprobability of miss of the RMDL estimator, which satisfies\nthe condition stated in [11] is the MDL estimator, converges\nto zero as N \u2192 \u221e.\nA PPENDIX III\nP ROOF OF L EMMA 3\nThe proof of Lemma 3 is very similar to the proof of\nLemma 2, and thus only the necessary modifications for the\nproof of lemma 2 are detailed. Again, in order to prove that\nthe probability of error converges to zero we will prove that\nPr {RMDL(q) \u2212 RMDL(k) > 0} \u2192 0.\nAssume k > q. It is easy to see from the proof\nof Lemma 2 that Pr (RMDL(q) \u2212 RMDL(k) > 0) <\nPr(\u2212 log fX (X|\u03b8q ) + log fX (X|\u03b8\u0302p\u22121 ) + (q(2p \u2212 q) \u2212 k(2p \u2212\nk)) log2 N > 0). It is known that asymptotically, given\nthe conditions stated in the lemma, log fX (X|\u03b8p\u22121 ) \u2212\n\u2217\nlog fX (X|\u03b8\u0302p\u22121\n) is distributed as a weighted sum of chi-square\nrandom variables having one degree of freedom [30]. Thus by\n\n9\n\nimplying the same reasoning used in the proof of Lemma 2,\nit easily shown that P (RMDL(q) \u2212 RMDL(k) > 0) \u2192 0.\nAssume k < q. Again, this case is a special case of a more\ngeneral theorem presented in [11] and hence we omit a specific\nproof for this case.\n\nC ONVERGENCE\n\nA PPENDIX IV\nOF THE P ROPOSED\n\nE STIMATION\n\nA LGORITHM\n2\nH\nDenote by \u03b8\u0302qn = [\u0175q,n , \u03c3\u0302q,n\n, Aq,n Rd\ns,q,n Aq,n ] the estimate\nb\nof \u03b8q after the nth iteration, and by En the error between R\nn\nn\nb\nand Rx (\u03b8\u0302q ), that\n\b x(\u03b8\u0302q ). HIn this appendix it is\n\b is En = R \u2212 R\n. The following\nproven that Tr En EnH > Tr En+1 En+1\nlemma will be very helpful in the sequel.\nLemma 6: Let X be a p \u00d7 P\np Hermitian matrix, with\np\nH\neigenvalue representation X =\ni=1 \u03b1i vi vi . The closest\nb\n(in the Frobenius\npP\n\u00d7 p Hermitian matrix X,\nPqnorm sense)\np\nH\nH\nb\nsuch that X = i=1 li ci ci +P\nl i=q+1 ci ci is the matrix\np\nlj\nP\nP\nq\np\nj=q+1\nH\nb =\nvi viH\nX\ni=1 \u03b1i vi vi +\ni=q+1\np\u2212q\nProof of Lemma 6: For the sake of simplicity we prove the\nlemma for real vectors, and not complex ones. The extension\nto complex vector is straight forward and thus is omitted\nb such\nhere. We\n\u001a\u0010first note\u0011 \u0010that we \u0011have\n\u001b to find the matrix X\nT\nb\nb\nthat Tr\nX\u2212X X\u2212X\nis minimized. We note the\n\nfollowing identities,\n\nXXT =\n\b\n\np\np X\nX\n\ni=1 j=1\np\nX\nT\n\n=\n\nTr XX\nbX\nbT =\nX\n+\n\n\u03b1i \u03b1j vi viT vj vjT =\n\u03b12i\n\nli lj ci cTi cj cTj +\n\nbX\nbT\nTr X\n+\n\no\n\nq+1\np\nX\nX\n\np\nq+1 X\nX\n\nli lci cTi cj cTj\n\ni=1 j=q+1\n\ni=1 j=1\n\nllj ci cTi cj cTj +\n\np\nX\n\np\nX\n\nl2 ci cTi cj cTj\n\ni=q+1 j=q+1\n\ni=q+1 j=1\n\nn\n\n\u03b12i vi viH\n\ni=1\n\ni=1\nq+1\nq+1\nXX\n\nq+1\np\nX\nX\n\np\nX\n\n=\n\nq+1\nq+1 X\nX\n\nli lj cTi cj\n\ni=1 j=1\n\nllj cTi cj\n\n\u00012\n\n+\n\np\nX\n\n\u00012\n\n+\n\np\nq+1 X\nX\n\nli l cTi cj\n\ni=1 j=q+1\n\np\nX\n\nl2 cTi cj\n\n\u00012\n\n\u00012\n\ni=q+1 j=q+1\np\np\nX\nX\n\u03b1i lvi viT cj cTj\n\u03b1i lj vi viT cj cTj +\nXX =\ni=1 j=q+1\ni=1 j=1\np\np\nq\np X\nn\no X\nX\n\u00012\n\u00012 X\nT\nT\nb\n\u03b1i l viT cj\n\u03b1i lj vi cj +\nTr XX\n=\ni=1 j=q+1\ni=1 j=1\ni=q+1 j=1\nq\np X\nX\nbT\n\nBy using these identities, Tr\n\n\u001a\u0010\n\nb\nX\u2212X\n\n\u0011\u0010\n\n\u0011H \u001b\nb\nX\u2212X\ncan be\n\n.\n\n\f10\n\nexpressed as follows:\n\u001a\u0010\n\u0011\u0010\n\u0011T \u001b\n\u25b3\nb\nb\nR = Tr\nX\u2212X\nXX\nn\no\no\nn\n\b\nbX\nbT =\nb T + Tr X\n= Tr XXT \u2212 2Tr XX\np\nX\n\n\u03b12i \u2212 2\n\n\u03b1i lj viT cj\n\ni=1 j=1\n\ni=1\n\n+\n\nq\np X\nX\n\nq+1\nq+1 X\nX\n\n\u00012\ncTi cj\n\nli lj\n\n+\n\n\u00012\n\n\u22122\n\np\np\nX\nX\n\n\u03b1i l viT cj\n\ni=1 j=q+1\n\np\nq+1 X\nX\n\n\u00012\ncTi cj\n\nli l\n\nAt the second part of the (n + 1)th iteration, wq,n+1 is\nconstructed as follows,\n!\nq\nX\nb\u2212\n(li \u2212 \u03c3 2 )vi vH + \u03c3 2 I\nwq,n+1 = diag R\nn\n\ni\n\nn\n\ni=1\n\n\u00012\n\n\u0001\n\u2032\n= diag En+1\n+ wq,n .\n\n(26)\n\nb and the estimate is\nThe total error, between R\nb \u2212 diag (wq,n ) \u2212\nEn+1 = R\n\nq\nX\n(li \u2212 \u03c3n2 )vi viH\n\ni=1\n\u0001\n\u2032\n\u2032\n+\u03c3n2 I \u2212 diag (wq,n+1 ) = En+1\n\u2212 diag En+1\n. (27)\n\u00012\n\u00012\nT\n2\nT\n\b\nP\n(24)Hence Tr E\nl ci cj .\nllj ci cj +\n+\nH\n[E\n] [E\n]H =\n=\nn+1 En+1\nP i,j \u2032n+1 ij \u2032n+1Hij\nP\ni=q+1 j=q+1\ni=q+1 j=1\nH\n\u2032\n\u2032\n=\ni,j [En+1 ]ij [En+1 ]ij\ni6\b\n=j [En+1 ]ij [En+1 ]ij\n\b\u2264\n\u2032\n\u2032H\nThe derivatives of R with respect to the unknown parameters Tr En+1\n\u2264 Tr En EnH , which concludes the\nEn+1\nare given by the following:\nproof.\ni=1 j=1\n\nq+1\np\nX\nX\n\ni=1 j=q+1\np\nX\n\np\nX\n\np\nX\n\u00012\n\u00012 X\n\u00012\n\u2202R\nli cTi ck\n\u03b1i viT ck + 2lk cTk ck +\n= \u22122\n\u2202lk\ni=1\n\n1\n\ni6=k\n\nl cTk cj\n\nj=q+1\n\n\u00012\n\n+\n\np\nX\n\nl cTi ck\n\ni=q+1\n\n\u00012\n\n0.7\n\np\nq+1 X\np\np\nX\nX\n\u00012\n\u00012 X\n\u2202R\nli cTi cj\n\u03b1i viT cj +\n= \u22122\n\u2202l\ni=1 j=q+1\ni=1 j=q+1\n\n+\n\nq+1\np\nX\nX\n\nlj\n\ni=q+1 j=1\n\n\u00012\ncTi cj\n\n+2\n\np\nX\n\np\nX\n\n0.8\n\n, k = 1, . . . , q\n\nl\n\ni=q+1 j=q+1\n\n0.6\nPD\n\np\nX\n\n+\n\n+8\n\nli lk cTi ck\n\ni6=k\n\np\nX\n\n\u0001\n\nci , k = 1, . . . q\nq+1\nX\n\n0.3\n\n0.2\n\n0.1\n\n0\n\ncTk ck\n\nck + 4\n\ni=q+1,i6=k\n\nl\n\n2\n\ncTi ck\n\n\u0001\n\n100\n\n200\n\n300\n\n400\nN\n\n500\n\n600\n\n700\n\n800\n\n1\n\nci\n\nIt is now easy to verify that by substituting into the above\nequations the proposed solution and exploiting the fact\nthat {vi } is an orthonormal bases, all the derivatives are\nequal\nthe proposed solution minimizes\n\u001a\u0010 to zero,\u0011 \u0010and hence\n\u0011H \u001b\nb\nb\nTr\nX\u2212X\nX\u2212X\n.\n\nAccording to the algorithm, at the beginning\nPq of the2 (n+1)th\nH\niterationP\nthe following matrix\nis\ncreated,\ni=1 (li \u2212\u03c3n )vi vi +\nP\n\u03c3n2 I = qi=1 li vi viH + \u03c3n2 pi=q+1 vi viH , where l1 > * * * >\nlp and v1 , . . . , vp are, respectively, the eigenvalues and the\ncorresponding eigenvectors of the matrix\n\n2\nH\nb \u2212 diag (\u0175q,n ) = En + Aq,n Rd\nR\n(25)\ns,q,n Aq,n + \u03c3\u0302q,n I,\nP\np\n1\n\u2032\nand \u03c3n2 = p\u2212q\ni=q+1 li . Denote by En+1 the error between\nP\nq\n2\nH\n\u2032\nb\nR\u2212diag\n(\u0175q,n ) and i=1 (li \u2212\u03c3n )vi vi +\u03c3n2 I; that is En+1\n=\nP\nq\n2\nH\n2\nb\nR \u2212 diag (\u0175q,n ) \u2212\n\b \u2032 i=1 (l\u2032Hi \u2212 \u03c3n )vi v\bi \u2212 \u03c3Hn I. According to\nthe Lemma 6 Tr En+1\nEn+1 < Tr En En .\n\nGMDL Gauss source\nRMDL Gauss source\nGMDL Laplace source\nRMDL Laplace source\n\n0.9\n\n0.8\n\n0.7\n\n0.6\nPD\n\n+4l\n\n2\n\np\nX\n\n0\n\nFig. 1. Three-user scenario, no mismatch. Probability of correct decision as\na function of the number of snapshots.\n\n\u0001\n\u0001\n\u2202R\nli l cTi ck ci\n\u03b1i l viT ck ci + 4\n= \u22124\n\u2202ck\ni=1\ni=1\n\u0001\n\n0.5\n\n0.4\n\n\u00012\ncTi cj\n\np\nX\n\u0001\n\u0001\n\u2202R\n\u03b1i lk viT ck vk + 4lj2 cH\n= \u22124\nk ck ck\n\u2202ck\ni=1\nq+1\nX\n\nGMDL Gauss source\nRMDL Gauss source\nGMDL Laplace source\nRMDL Laplace source\n\n0.9\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n\n0\n\n0.5\n\n1\n\n1.5\nN\n\n2\n\n2.5\n\n3\n4\n\nx 10\n\nFig. 2. Three-user scenario, weak mismatch. Probability of correct decision\nas a function of the number of snapshots.\n\n\fFISHLER AND POOR: ROBUST ESTIMATION OF THE NUMBER OF SOURCES\n\n1\n\n0.9\n\n0.8\n\n0.7\n\nP\n\nD\n\n0.6\n\n0.5\n\n0.4\n\n0.3\nGMDL Gauss source 0dB\nRMDL Gauss source 0dB\nGMDL Laplace source 0dB\nRMDL Laplace source 0dB\nGMDL Gauss source 5dB\nRMDL Gauss source 5dB\nGMDL Laplace source 5dB\nRMDL Laplace source 5dB\n\n0.2\n\n0.1\n\n0\n\n0\n\n2\n\n4\n\n6\nrho\n\n8\n\n10\n\n12\n\nFig. 3. Three-user scenario, weak mismatch. Probability of correct decision\nas a function of the spatial separation between the sources.\n\n1\nGMDL Gauss source\nRMDL Gauss source\nGMDL Laplace source\nRMDL Laplace source\n\n0.9\n\n0.8\n\n0.7\n\nP\n\nD\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n\n0\n\n500\n\n1000\n\n1500\nN\n\n2000\n\n2500\n\n3000\n\nFig. 4. Three-user scenario, strong mismatch. Probability of correct decision\nas a function of the number of snapshots.\n\n1\n\n0.9\n\n0.8\n\n0.7\n\nP\n\nD\n\n0.6\n\n0.5\n\n0.4\n\n0.3\nGMDL Gauss source 0dB\nRMDL Gauss source 0dB\nGMDL Laplace source 0dB\nRMDL Laplace source 0dB\nGMDL Gauss source 5dB\nRMDL Gauss source 5dB\nGMDL Laplace source 5dB\nRMDL Laplace source 5dB\n\n0.2\n\n0.1\n\n0\n\n0\n\n2\n\n4\n\n6\nrho\n\n8\n\n10\n\n12\n\nFig. 5. Three-user scenario, strong mismatch. Probability of correct decision\nas a function of the spatial separation between the sources\n\n11\n\n\f"}