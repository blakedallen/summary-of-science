{"id": "http://arxiv.org/abs/math/0408128v1", "guidislink": true, "updated": "2004-08-10T09:59:19Z", "updated_parsed": [2004, 8, 10, 9, 59, 19, 1, 223, 0], "published": "2004-08-10T09:59:19Z", "published_parsed": [2004, 8, 10, 9, 59, 19, 1, 223, 0], "title": "Dual random fragmentation and coagulation and an application to the\n  genealogy of Yule processes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0408270%2Cmath%2F0408323%2Cmath%2F0408206%2Cmath%2F0408164%2Cmath%2F0408174%2Cmath%2F0408188%2Cmath%2F0408092%2Cmath%2F0408128%2Cmath%2F0408055%2Cmath%2F0408159%2Cmath%2F0408111%2Cmath%2F0408031%2Cmath%2F0408033%2Cmath%2F0408147%2Cmath%2F0408097%2Cmath%2F0408076%2Cmath%2F0408392%2Cmath%2F0408348%2Cmath%2F0408361%2Cmath%2F0408420%2Cmath%2F0408211%2Cmath%2F0408258%2Cmath%2F0408320%2Cmath%2F0408236%2Cmath%2F0408234%2Cmath%2F0408316%2Cmath%2F0408378%2Cmath%2F0408096%2Cmath%2F0408406%2Cmath%2F0408098%2Cmath%2F0408426%2Cmath%2F0408393%2Cmath%2F0408299%2Cmath%2F0408088%2Cmath%2F0408370%2Cmath%2F0408176%2Cmath%2F0408329%2Cmath%2F0408120%2Cmath%2F0408237%2Cmath%2F0408182%2Cmath%2F0408254%2Cmath%2F0408061%2Cmath%2F0408008%2Cmath%2F0408257%2Cmath%2F0408196%2Cmath%2F0408081%2Cmath%2F0408086%2Cmath%2F0408220%2Cmath%2F0408343%2Cmath%2F0408375%2Cmath%2F0408114%2Cmath%2F0408210%2Cmath%2F0408328%2Cmath%2F0408198%2Cmath%2F0408187%2Cmath%2F0408259%2Cmath%2F0408163%2Cmath%2F0408212%2Cmath%2F0408200%2Cmath%2F0408434%2Cmath%2F0408091%2Cmath%2F0408387%2Cmath%2F0408138%2Cmath%2F0408245%2Cmath%2F0408124%2Cmath%2F0408049%2Cmath%2F0408078%2Cmath%2F0408435%2Cmath%2F0408359%2Cmath%2F0408093%2Cmath%2F0408015%2Cmath%2F0408369%2Cmath%2F0408264%2Cmath%2F0408266%2Cmath%2F0408394%2Cmath%2F0408354%2Cmath%2F0408143%2Cmath%2F0408016%2Cmath%2F0408135%2Cmath%2F0408283%2Cmath%2F0408134%2Cmath%2F0408189%2Cmath%2F0408410%2Cmath%2F0408398%2Cmath%2F0408344%2Cmath%2F0408109%2Cmath%2F0408012%2Cmath%2F0408084%2Cmath%2F0408430%2Cmath%2F0408265%2Cmath%2F0408351%2Cmath%2F0408085%2Cmath%2F0408110%2Cmath%2F0408321%2Cmath%2F0408280%2Cmath%2F0408144%2Cmath%2F0408132%2Cmath%2F0408291%2Cmath%2F0408118%2Cmath%2F0408126%2Cmath%2F0408228&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Dual random fragmentation and coagulation and an application to the\n  genealogy of Yule processes"}, "summary": "The purpose of this work is to describe a duality between a fragmentation\nassociated to certain Dirichlet distributions and a natural random coagulation.\nThe dual fragmentation and coalescent chains arising in this setting appear in\nthe description of the genealogy of Yule processes.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0408270%2Cmath%2F0408323%2Cmath%2F0408206%2Cmath%2F0408164%2Cmath%2F0408174%2Cmath%2F0408188%2Cmath%2F0408092%2Cmath%2F0408128%2Cmath%2F0408055%2Cmath%2F0408159%2Cmath%2F0408111%2Cmath%2F0408031%2Cmath%2F0408033%2Cmath%2F0408147%2Cmath%2F0408097%2Cmath%2F0408076%2Cmath%2F0408392%2Cmath%2F0408348%2Cmath%2F0408361%2Cmath%2F0408420%2Cmath%2F0408211%2Cmath%2F0408258%2Cmath%2F0408320%2Cmath%2F0408236%2Cmath%2F0408234%2Cmath%2F0408316%2Cmath%2F0408378%2Cmath%2F0408096%2Cmath%2F0408406%2Cmath%2F0408098%2Cmath%2F0408426%2Cmath%2F0408393%2Cmath%2F0408299%2Cmath%2F0408088%2Cmath%2F0408370%2Cmath%2F0408176%2Cmath%2F0408329%2Cmath%2F0408120%2Cmath%2F0408237%2Cmath%2F0408182%2Cmath%2F0408254%2Cmath%2F0408061%2Cmath%2F0408008%2Cmath%2F0408257%2Cmath%2F0408196%2Cmath%2F0408081%2Cmath%2F0408086%2Cmath%2F0408220%2Cmath%2F0408343%2Cmath%2F0408375%2Cmath%2F0408114%2Cmath%2F0408210%2Cmath%2F0408328%2Cmath%2F0408198%2Cmath%2F0408187%2Cmath%2F0408259%2Cmath%2F0408163%2Cmath%2F0408212%2Cmath%2F0408200%2Cmath%2F0408434%2Cmath%2F0408091%2Cmath%2F0408387%2Cmath%2F0408138%2Cmath%2F0408245%2Cmath%2F0408124%2Cmath%2F0408049%2Cmath%2F0408078%2Cmath%2F0408435%2Cmath%2F0408359%2Cmath%2F0408093%2Cmath%2F0408015%2Cmath%2F0408369%2Cmath%2F0408264%2Cmath%2F0408266%2Cmath%2F0408394%2Cmath%2F0408354%2Cmath%2F0408143%2Cmath%2F0408016%2Cmath%2F0408135%2Cmath%2F0408283%2Cmath%2F0408134%2Cmath%2F0408189%2Cmath%2F0408410%2Cmath%2F0408398%2Cmath%2F0408344%2Cmath%2F0408109%2Cmath%2F0408012%2Cmath%2F0408084%2Cmath%2F0408430%2Cmath%2F0408265%2Cmath%2F0408351%2Cmath%2F0408085%2Cmath%2F0408110%2Cmath%2F0408321%2Cmath%2F0408280%2Cmath%2F0408144%2Cmath%2F0408132%2Cmath%2F0408291%2Cmath%2F0408118%2Cmath%2F0408126%2Cmath%2F0408228&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The purpose of this work is to describe a duality between a fragmentation\nassociated to certain Dirichlet distributions and a natural random coagulation.\nThe dual fragmentation and coalescent chains arising in this setting appear in\nthe description of the genealogy of Yule processes."}, "authors": ["Jean Bertoin", "Christina Goldschmidt"], "author_detail": {"name": "Christina Goldschmidt"}, "author": "Christina Goldschmidt", "arxiv_comment": "14 pages", "links": [{"href": "http://arxiv.org/abs/math/0408128v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0408128v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60J80, 60J05", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0408128v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0408128v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0408128v1 [math.PR] 10 Aug 2004\n\nDual random fragmentation and coagulation and an\napplication to the genealogy of Yule processes\nJean Bertoin\n\n\u2217\n\nand\n\nChristina Goldschmidt\n\n\u2020\n\nAugust 22, 2018\n\nAbstract\nThe purpose of this work is to describe a duality between a fragmentation associated to\ncertain Dirichlet distributions and a natural random coagulation. The dual fragmentation\nand coalescent chains arising in this setting appear in the description of the genealogy of\nYule processes.\n\n1\n\nIntroduction\n\nAt a naive level, fragmentation and coagulation are inverse phenomena, in that a simple\ntime-reversal changes one into the other. However, stochastic models for fragmentation\nand coalescence usually impose strong hypotheses on the dynamics of the processes, such\nas the branching property for fragmentation (distinct fragments evolve independently as\ntime passes), and these requirements do not tend to be compatible with time-reversal.\nThus, in general, the time-reversal of a coalescent process is not a fragmentation process.\nNonetheless, there are a few special cases in which time-reversal does transform a\ncoalescent process into a fragmentation process. Probably the most important example\nwas discovered by Pitman [17]; it is related to the so-called cascades of Ruelle and the\nBolthausen-Sznitman coalescent [7], and also has a natural interpretation in terms of the\ngenealogy of a remarkable branching process considered by Neveu, see [4] and [6].\nThe first purpose of this note is to point out other simple instances of such duality,\nwhich rely on certain Dirichlet and Poisson-Dirichlet distributions. Then, in the second\npart, we shall show that these examples are related to the genealogy of Yule processes.\n\u2217\n\nLaboratoire de Probabilit\u00e9s et Mod\u00e8les Al\u00e9atoires and Institut universitaire de France, Universit\u00e9 Pierre et\nMarie Curie, 175, rue du Chevaleret, F-75013 Paris, France.\n\u2020\nLaboratoire de Probabilit\u00e9s et Mod\u00e8les Al\u00e9atoires, Universit\u00e9 Pierre et Marie Curie, 175, rue du Chevaleret,\nF-75013 Paris, France.\n\n1\n\n\f2\n\nDual fragmentation and coagulation\n\n2.1\n\nSome notation\n\nFor every integer n \u2265 1, we consider the simplex\n(\n\u2206n :=\n\nx = (x1 , . . . , xn+1 ) : xi \u2265 0 for every i = 1, . . . , n + 1 and\n\nn+1\nX\ni=1\n\n)\n\nxi = 1\n\n.\n\nIt will also be convenient to agree that \u22060 := {1}. We shall often refer to the coordinates\nx1 , . . . , xn+1 of points x in \u2206n as masses.\nWe recall that the n-dimensional Dirichlet distribution with parameter (\u03b11 , . . . , \u03b1n+1 )\nis the probability measure on the simplex \u2206n with density\n\u0393(\u03b11 + * * * + \u03b1n+1 ) \u03b11 \u22121\n\u03b1n+1 \u22121\nx\n* * * xn+1\n.\n\u0393(\u03b11 ) * * * \u0393(\u03b1n+1 ) 1\nThe special case when \u03b11 = . . . = \u03b1n+1 := \u03b1 \u2208 ]0, \u221e[ will have an important role in this\nwork; it will be convenient to write Dirn (\u03b1) for this distribution. We recall the following\nwell-known construction: let \u03b31 , . . . , \u03b3n+1 be i.i.d. gamma variables with parameters (\u03b1, c).\nSet \u03b3\u0304 = \u03b31 + * * * + \u03b3n+1 , so that \u03b3\u0304 has a gamma distribution with parameters (\u03b1(n + 1), c).\nThen the (n + 1)-tuple\n(\u03b31 /\u03b3\u0304, . . . , \u03b3n+1 /\u03b3\u0304)\nhas the distribution Dirn (\u03b1) and is independent of \u03b3\u0304.\nWe also define the (ranked) infinite simplex\n(\n\u2206\u221e :=\n\nx = (x1 , . . .) : x1 \u2265 x2 \u2265 . . . \u2265 0 and\n\n\u221e\nX\ni=1\n\n)\n\nxi = 1\n\nand recall that the Poisson-Dirichlet distribution with parameter \u03b8 > 0, which will be\ndenoted by PD(\u03b8) in the sequel, is the law of the random sequence\n\u0013\n\u0012\na2\na1\n, P\u221e\n,... ,\n\u03be := P\u221e\ni=1 ai\ni=1 ai\n\nwhere a1 \u2265 a2 \u2265 . . . > 0 are the atoms of a Poisson random\nP measure on ]0, \u221e[ with intensity \u03b8y \u22121 e\u2212y dy. We also recall that \u03be is independent of \u221e\ni=1 ai , and that the latter has\nthe gamma distribution with parameters (\u03b8, 1). By the celebrated L\u00e9vy-It\u00f4 decomposition\nof subordinators, we may also rephrase this construction as follows: if \u03b3 = (\u03b3(t), t \u2265 0) is\na standard gamma process and, for each fixed \u03b8 > 0, \u03b41 \u2265 \u03b42 \u2265 . . . denotes the sequence\nof sizes of the jumps of \u03b3 on the time interval [0, \u03b8], then\n\u0013\n\u0012\n\u03b42\n\u03b41\n,\n,...\n\u03b3(\u03b8) \u03b3(\u03b8)\nhas the PD(\u03b8) distribution and is independent of \u03b3(\u03b8).\n\n2\n\n\f2.2\n\nTwo dual random transformations\n\nWe now define two random transformations:\nFragk : \u2206n \u2192 \u2206n+k\n\nand\n\nCoagk : \u2206n+k \u2192 \u2206n ,\n\nwhere k, n are integers.\nFirst, we fix x = (x1 , . . . , xn+1 ) \u2208 \u2206n and pick an index I \u2208 {1, . . . , n + 1} at random\naccording to the distribution\n\nP(I = i) = xi ,\n\ni = 1, . . . , n + 1 ,\n\nso that xI is a size-biased pick from the sequence x. Let \u03b7 = (\u03b71 , . . . , \u03b7k+1 ) be a random\nvariable with values in \u2206k which is distributed according to Dirk (1/k) and independent\nof I. Then we split the Ith mass of x according to \u03b7 and we obtain a random variable in\n\u2206n+k :\nFragk (x) := (x1 , . . . , xI\u22121 , xI \u03b71 , . . . , xI \u03b7k+1 , xI+1 , . . . , xn+1 ) .\nSecond, we fix x = (x1 , . . . , xn+k+1 ) \u2208 \u2206n+k and pick an index J \u2208 {1, . . . , n + 1}\nuniformly\nat random. We merge the k + 1 masses xJ , xJ+1 . . . , xJ+k to form a single mass\nPJ+k\ni=J xi and leave the other masses unchanged. We obtain a random variable in \u2206n :\n!\nJ+k\nX\nxi , xJ+k+1 , . . . , xn+k+1 .\nCoagk (x) = x1 , . . . , xJ\u22121 ,\ni=J\n\nRemark. Consider the following alternative random coagulation of x = (x1 , . . . , xn+k+1 ) \u2208\n\u2206n+k . Pick k + 1 indices i1 , . . . , ik+1 from {1, . . . , n + k + 1} uniformly at random without\nreplacement, merge the masses xi1 , . . . , xik+1 , leave the other masses unchanged and let\n] k (x) be the sequence obtained by ranking the resulting masses in decreasing order.\nCoag\nWrite also Coag\u2193k (x) for the sequence Coagk (x) re-arranged in decreasing order. Then if\n] k (\u03be)) have the same distribution.\n\u03be is exchangeable the pairs (\u03be, Coag\u2193k (\u03be)) and (\u03be, Coag\nThis remark applies in particular to the case when \u03be has the law Dirn+k (1/k), and can\nthus be combined with forthcoming Proposition 1.\nThe starting point of this work lies in the observation of a simple relation of duality\nwhich links these two random transformations via Dirichlet laws.\nProposition 1. Let k, n \u2265 1 be two integers, and \u03be, \u03be \u2032 two random variables with values\nin \u2206n and \u2206n+k , respectively. The following assertions are then equivalent:\n(i) \u03be has the law Dirn (1/k) and, conditionally on \u03be, \u03be \u2032 is distributed as Fragk (\u03be).\n(ii) \u03be \u2032 has the law Dirn+k (1/k) and, conditionally on \u03be \u2032 , \u03be is distributed as Coagk (\u03be \u2032 ).\nIt has been observed by Kingman [13] that for k = 1, if \u03be \u2032 is uniformly distributed on\nthe simplex \u2206n+1 (i.e. has the law Dirn+1 (1)), then Coag1 (\u03be \u2032 ) is uniformly distributed on\n\u2206n . Clearly, this agrees with our statement.\nProof: Let \u03b31 , \u03b32 , . . . , \u03b3n+1 be independent Gamma(1/k, 1) random variables and set\n\u03b3\u0304 =\n\nn+1\nX\n\n\u03b3i\n\nand\n\n\u03be =\n\ni=1\n\n\u0012\n\n\u03b3n+1\n\u03b31\n,...,\n\u03b3\u0304\n\u03b3\u0304\n\n\u0013\n\n,\n\nso that \u03be has law Dirn (1/k) and is independent of \u03b3\u0304. Suppose that \u03b7 is a Dirk (1/k)\nrandom variable which is independent of the \u03b3i 's, and let \u03a6 : Rn+k+1 \u2192 R be a bounded\n\n3\n\n\fmeasurable function. Let I be an index picked at random from {1, . . . , n + 1} according\nto the conditional distribution\n\nP(I = i | \u03b31 , . . . , \u03b3n+1 ) = \u03b3i /\u03b3\u0304 ,\n\ni = 1, . . . , n + 1 ,\n\nand denote by Fragk (\u03be) the random sequence obtained from \u03be after the fragmentation of\nits Ith mass according to \u03b7. We have\n\u0015\n\u0014\n\u03b3i\n\u03a6 ((\u03b3l /\u03b3\u0304)l<i , \u03b3i \u03b7/\u03b3\u0304, (\u03b3l /\u03b3\u0304)l>i ) .\nE (\u03a6(Fragk (\u03be)), I = i) = E\n\u03b3\u0304\nNow, using the independence of \u03b3\u0304 and \u03be and the fact that \u03b3\u0304 has the law Gamma((n +\n1)/k, 1), we see that the last expression is equal to\n\n=\n=\n\nk\nE [\u03b3i \u03a6 ((\u03b3l /\u03b3\u0304)l<i , \u03b3i \u03b7/\u03b3\u0304, (\u03b3l /\u03b3\u0304)l>i )]\nn+1\n!\nZ \u221e\nk\nx\u03b7\n(\u03b3l )l>i\n(\u03b3l )l<i\n1\nP\nP\nP\nx\u03a6\nE\n,\n,\nx1/k\u22121 e\u2212x dx\nn+1\nx + j6=i \u03b3j x + j6=i \u03b3j x + j6=i \u03b3j \u0393(1/k)\n0\n\"\n!#\n\u03b3\u2032\u03b7\n(\u03b3l )l>i\n(\u03b3l )l<i\n1\nP\nP\nE \u03a6 \u2032 P\n,\n,\nn+1\n\u03b3 + j6=i \u03b3j \u03b3 \u2032 + j6=i \u03b3j \u03b3 \u2032 + j6=i \u03b3j\n\nwhere \u03b3 \u2032 \u223c Gamma((k + 1)/k, 1), independently of \u03b7 and (\u03b3j )j6=i . But then \u03b3 \u2032 \u03b7 is a\ncollection of k + 1 independent Gamma(1/k, 1) random variables, so Fragk (\u03be) has the law\nDirn+k (1/k) and is independent of the random index I which is uniformly distributed on\n{1, . . . , n + 1}. Since we can recover \u03be from Fragk (\u03be) and I by an obvious coagulation,\nthis completes the proof.\n\u0003\nNext we turn our attention to the infinite ranked simplex and define two random\ntransformations, Frag\u221e : \u2206\u221e \u2192 \u2206\u221e and Coaga : \u2206\u221e \u2192 \u2206\u221e , where a \u2208 [0, 1] is\nsome parameter. The fragmentation transformation on the infinite simplex simply mimics that on the finite simplex; in this direction, recall that the Poisson-Dirichlet PD(1)\narises as the weak limit as k \u2192 \u221e of sequence of Dirk (1/k) variables after obvious\nre-ordering. More precisely, given x = (x1 , . . .) \u2208 \u2206\u221e , we pick a mass xI at random\nby size-biased sampling and split xI using an independent variable \u03b7 = (\u03b71 , . . .) with\nlaw PD(1). In other words, Frag\u221e (x) is the ranked sequence with unordered terms\nx1 , . . . , xI\u22121 , xI \u03b71 , xI \u03b72 , . . . , xI+1 , . . ..\nNext, consider a sequence U1 , U2 , . . . of i.i.d. uniform random variables and a \u2208 [0, 1].\nStarting again from some fixed x \u2208 \u2206\u221e , we merge the masses xi for which Ui \u2264 a into a\nsingle mass and leave the others unchanged. We denote by Coaga (x) the random sequence\nobtained by putting the resulting masses in decreasing order. We then have the following\nanalogue of Proposition 1, which is reminiscent of Corollary 13 of Pitman [17].\nProposition 2. Let \u03be, \u03be \u2032 be two random variables with values in \u2206\u221e . For every \u03b8 > 0,\nthe following assertions are equivalent:\n(i) \u03be has the law PD(\u03b8) and, conditionally on \u03be, \u03be \u2032 is distributed as Frag\u221e (\u03be).\n(ii) \u03be \u2032 has the law PD(\u03b8+1) and, conditionally on \u03be \u2032 , \u03be is distributed as Coag1/(\u03b8+1) (\u03be \u2032 ).\nProof: Let \u03b3 = (\u03b3(t), t \u2265 0) be a standard gamma process and set\nDt = \u03b3((\u03b8 + 1)t)/\u03b3(\u03b8 + 1),\n\n4\n\n\ffor 0 \u2264 t \u2264 1, so that (Dt , 0 \u2264 t \u2264 1) is a Dirichlet process of parameter \u03b8 + 1. (The\nvector of ordered jumps of this Dirichlet process has the PD(\u03b8 + 1) distribution.) Consider\nthe following alternative way of thinking of the random coagulation operator Coag1/(\u03b8+1) :\npick a point V uniformly in [0, 1] and define a new process (Dt\u2032 , 0 \u2264 t \u2264 1) by\n(\nD\u03b8t/(\u03b8+1)\nif t < V\nDt\u2032 =\nD(1+\u03b8t)/(\u03b8+1) if t \u2265 V .\nAs the times of the jumps of D are uniformly distributed on [0, 1], this picks a proportion\n1/(\u03b8 + 1) of them and coalesces them into a single jump (say \u03b2 \u2217 = D(1+\u03b8V )/(\u03b8+1) \u2212\nD\u03b8V /(\u03b8+1) ) at V . Let \u03b21 \u2265 \u03b22 \u2265 . . . > 0 be the sequence of other jumps of D \u2032 and\nof jumps\nU1 , U2 , . . . the corresponding jump times. Let \u03b21\u2032 \u2265 \u03b22\u2032 \u2265 . . . > 0 be the\nP\u221esequence\n\u2217\n\u2032\nof D in the interval [\u03b8V /(\u03b8 + 1), (1 + \u03b8V )/(\u03b8 + 1)], so that \u03b2 = i=1 \u03b2i . We wish to\nshow that D \u2032 is a Dirichlet process with parameter \u03b8, so that the vector (\u03b2 \u2217 , \u03b21 , \u03b22 , . . .) of\nits jumps (re-arranged in the decreasing order) has the PD(\u03b8) distribution. We will also\nshow that the mass \u03b2 \u2217 resulting from the coalescence constitutes a size-biased pick from\nthis vector.\nLet\n(\n\u03b3(t)\nif t < V \u03b8\n1\n\u03b3 (t) =\n\u03b3(t + 1) \u2212 (\u03b3(V \u03b8 + 1) \u2212 \u03b3(V \u03b8)) if V \u03b8 \u2264 t \u2264 \u03b8\n\u03b3 2 (t) = \u03b3(V \u03b8 + t) \u2212 \u03b3(V \u03b8)\n\nfor 0 \u2264 t \u2264 1.\nd\n\nd\n\nThen \u03b3 1 and \u03b3 2 are independent processes with \u03b3 1 = (\u03b3(t), 0 \u2264 t \u2264 \u03b8) and \u03b3 2 = (\u03b3(t), 0 \u2264\nt \u2264 1), independently of V . Write \u03b41 \u2265 \u03b42 \u2265 . . . for the ordered sequence of jumps of \u03b3 1\nand T1 , T2 , . . . for the corresponding times of these jumps. Write \u03b41\u2032 \u2265 \u03b42\u2032 \u2265 . . . for the\nordered sequence of jumps of \u03b3 2 . Then\n(i) U1 = T1 /\u03b8, U2 = T2 /\u03b8, . . . are i.i.d. U[0, 1],\n(ii) \u03b2 \u2217 = \u03b3 2 (1)/\u03b3(1 + \u03b8) and so has a Beta(\u03b8, 1) distribution,\n(iii)\n\n1\n\u2032\n\u2032\n\u03b2 \u2217 (\u03b21 , \u03b22 , . . .)\n\n(iv)\n\n1\n1\u2212\u03b2 \u2217 (\u03b21 , \u03b22 , . . .)\n\n=\n\n1\n\u2032\n\u2032\n\u03b3 2 (1) (\u03b41 , \u03b42 , . . .)\n\n=\n\nand so has the PD(1) distribution,\n\n1\n(\u03b4 , \u03b4 , . . .)\n\u03b3 1 (\u03b8) 1 2\n\nand so has the PD(\u03b8) distribution.\n\nFurthermore, the random variables in (i) to (iv) above are independent. The fact that \u03b2 \u2217\nis a size-biased pick from (\u03b2 \u2217 , \u03b21 , \u03b22 , . . .) and the PD(\u03b8) distribution of the latter follow\nfrom (i) and (iii) and the stick-breaking scheme (see, for instance, Definition 1 in Pitman\nand Yor [19]). That D \u2032 is a Dirichlet process of parameter \u03b8 then follows from (iv) and\nthe independence.\nThe coagulation operator used here can be re-phrased as follows: starting with x \u2208\n\u2206\u221e , take a sequence V, V1 , V2 , . . . of i.i.d. U[0, 1] random variables, merge the masses xi\nfor which Vi \u2208 [\u03b8V /(\u03b8 +1), (1+\u03b8V )/(\u03b8 +1)], leave the other masses unchanged and, finally,\n] 1/(\u03b8+1) . Then it\nrank the resulting sequence in decreasing order. Call this operator Coag\n\u2032\nis clear that whenever \u03be is a random exchangeable sequence in \u2206\u221e , (\u03be \u2032 , Coag1/(\u03b8+1) (\u03be \u2032 ))\n] 1/(\u03b8+1) (\u03be \u2032 )) have the same distribution. Our claim follows now readily from\nand (\u03be \u2032 , Coag\nthese results.\n\u0003\nRemark. It may be interesting to check Proposition 2 as follows. Consider Poisson\nrandom measure M on (0, \u221e) with intensity \u03b8x\u22121 e\u2212x dx. Let a1 , a2 , . . . be the atoms of\n\n5\n\n\fM in decreasing order, so that\na1\n\na2\n\nP\u221e\n\nj=1 aj\n\n, P\u221e\n\nj=1 aj\n\n,...\n\n!\n\nP\nhas distribution PD(\u03b8), independently of \u221e\nj=1 aj . Let \u03b7 \u223c PD(1), independently of M\nand suppose that \u03a6 : \u2206\u221e \u2192 R is any symmetric bounded measurable function. Then if\n\u03be \u223c PD(\u03b8), using independence we have that\n!#\n\"\u221e\nX\n(al )l6=i\n1\nai \u03b7\niE\nE [\u03a6(Frag\u221e (\u03be))] = hP\n, P\u221e\n.\nai \u03a6 P \u221e\n\u221e\nj=1 aj\nj=1 aj\nE\na\nj=1\n\nj\n\ni=1\n\nBy the Palm formula, this is equal to\n1\nE\n\u03b8\n\"\n\nZ\n\n\u221e\n0\n\n= E \u03a6\n\n(al )\u221e\nPl=1\nx\u03a6\n,\nx + j=1 aj x + \u221e\nj=1 aj\n!#\n(al )\u221e\na\u2032 \u03b7\nP\n, \u2032 Pl=1\na\u2032 + \u221e\na\na + \u221e\nj\nj=1\nj=1 aj\nx\u03b7\nP\u221e\n\n!\n\n\u03b8x\u22121 e\u2212x dx\n\nwhere a\u2032 \u223c Exp(1), independently of M and \u03b7. But then a\u2032 \u03b7 has the distribution of\nthe atoms of a Poisson random measure with intensity x\u22121 e\u2212x dx arranged in decreasing\norder and so we see that taking these atoms together with those of M , we obtain a Poisson\nrandom measure of intensity (\u03b8 + 1)x\u22121 e\u22121 dx. Hence, Frag\u221e (\u03be) has the law PD(\u03b8 + 1).\n\n2.3\n\nDual fragmentation and coagulation chains\n\nThe dual fragmentation and coagulation operators that were defined in the preceding\nsection incite us to introduce Markov fragmentation and coagulation chains in duality by\ntime-reversal. Specifically, we consider for each integer k \u2265 1 a chain\nX (k) (0), X (k) (1), X (k) (2), . . . ,\nwhere X (k) (n) is a random variable with values in \u2206nk (in particular X (k) (0) = 1), and\nthe conditional distribution of X (k) (n + 1) given X (k) (n) = x is the law of Fragk (x). We\ndeduce from Proposition 1 by induction that for each n, X (k) (n) has the distribution\nDirnk (1/k). The time-reversed coagulation chain\n. . . , X (k) (n + 1), X (k) (n), . . . , X (k) (1), X (k) (0)\nis also Markov; more precisely, the conditional distribution of X (k) (n) given X (k) (n + 1) =\nx is the law of Coagk (x). Note that for k = 1, this has the distribution of the jump chain\nof Kingman's coalescent [13].\nAnalogously, for k = \u221e, we can define a Markov fragmentation chain on \u2206\u221e ,\nX (\u221e) (0), X (\u221e) (1), X (\u221e) (2), . . . ,\nsuch that the conditional distribution of X (\u221e) (n + 1) given X (\u221e) (n) = x is the law\nof Frag\u221e (x). We deduce by induction from Proposition 2 that for every \u03b8 > 0, if the\n\n6\n\n\fdistribution of the initial state X (\u221e) (0) is PD(\u03b8) then, for every integer n, X (\u221e) (n) has\nthe distribution PD(\u03b8 + n). Moreover, in this case, the time-reversed coagulation chain\n. . . , X (\u221e) (n + 1), X (\u221e) (n), . . . , X (\u221e) (1), X (\u221e) (0)\nis also Markov; more precisely, the conditional distribution of X (\u221e) (n) given X (\u221e) (n+1) =\nx is the law of Coag1/(n+1+\u03b8) (x).\nRemarks. (a) Recall that the parameter \u03b8 can be recovered from a sample \u03be of a PD(\u03b8)\nrandom variable as follows:\n\u03b8 = lim\n\n\u03b5\u21920+\n\n1\nmax {n : \u03ben > \u03b5} .\nlog 1/\u03b5\n\nThis shows that the above description for the reversed coagulation chain is indeed Markovian.\n(b) There is simple representation for the k = \u221e fragmentation chain in terms of\ncompound bridges with exchangeable increments which is inspired by [5]. Let U0 , U1 , . . .\nbe a sequence of independent uniform variables on [0, 1]. For each n, we consider the\nelementary bridge bn : [0, 1] \u2192 [0, 1] defined by\nbn (t) =\n\nn\n1\nt+\n1\n,\nn+1\nn + 1 {t>Un }\n\nt \u2208 [0, 1] .\n\nThen is is easy to check that for every n \u2208 N, the sequence bn \u25e6 bn+1 \u25e6 * * * \u25e6 bn+i converges\npointwise almost surely as i \u2192 \u221e to a bridge with exchangeable increments Bn which has\nno drift and infinitely many jumps a.s. If we write \u03b2n \u2208 \u2206n for the sequence of the sizes\nof the jumps of Bn ranked the decreasing order, then the chain (\u03b2n , n \u2208 N) has the same\nlaw as X (\u221e) . We refer to [5] for the necessary technical background.\n\n3\n\nThe genealogy of Yule processes\n\nWe shall now show that the dual fragmentation and coagulation chains which we introduced in the preceding section are naturally connected to the genealogy of Yule processes.\n\n3.1\n\nDiscrete setting\n\n\u0011\n\u0010\n(k)\nFor every integer k \u2265 1, we write Y (k) = Yt , t \u2265 0 for the Yule process started from\n(k)\n\n(k)\n\nY0 = 1: Yt gives the number of individuals alive a time t in a branching process in\nwhich each individual lives for an exponential time of parameter 1 and gives birth at its\ndeath to k + 1 children, which then evolve independently of one another according to the\nsame rules as their parent. We agree to label each child of an individual by an integer\nin {1, . . . , k + 1}, which allows us to order individuals at any generation in a consistent\nway: given two distinct individuals, we may consider their most recent common ancestor.\nPlainly, two different children of this ancestor are ancestors of exactly one of these two\nindividuals, and the labelling of the children of the most recent common ancestor induces\nthe order of the individuals.\n\u0011\n\u0010\n(k)\nLemma 3. The process exp(\u2212kt)Yt , t \u2265 0 is a uniformly integrable martingale and\nits limit W (k) has the Gamma(1/k, 1/k) distribution.\n\n7\n\n\fProof: A similar limit result is stated in Athreya & Ney [1] on page 130; however, the\nlimiting distribution given there is incorrect and so we shall provide here a detailed proof.\nThe martingale property is classical, so we focus on the distribution of the limit W (k) .\nDefine\n\u0010 (k) \u0011\n.\n\u03a6t (s) := E sYt\n\nThe backward equation implies that\n\n\u2202\n\u03a6t (s) = \u03a6k+1\n(s) \u2212 \u03a6t (s) ,\nt\n\u2202t\n\n\u03a60 (s) = s .\n\nThis equation has solution\n\nHence, for \u03b8 < 0,\n\n\u0011 \u0011\u22121/k\n\u0010\n\u0010\n.\n\u03a6t (s) = se\u2212t 1 \u2212 1 \u2212 e\u2212kt sk\n\n\u0011\u0011\n\u0010\n\u0010\n(k)\nE exp \u03b8e\u2212ktYt\n\n=\n=\n\n\u0011\u0011\u22121/k\n\u0011\n\u0010\n\u0010\n\u0010\n\u0011\n\u0010\nexp \u03b8e\u2212kt e\u2212t 1 \u2212 1 \u2212 e\u2212kt exp \u03b8ke\u2212kt\n\u0011\ni\u22121/k\nh\n\u0010\nekt exp \u2212\u03b8ke\u2212kt \u2212 ekt + 1\n,\n\nand when t \u2192 \u221e, this quantity converges to\n\u22121/k\n\n(1 \u2212 k\u03b8)\n\n\u0012\n\n=\n\n1/k\n1/k \u2212 \u03b8\n\n\u00131/k\n\n,\n\nwhich is the moment generating function of a gamma random variable with parameters\n(1/k, 1/k).\n\u0003\nWe think of W (k) as the size of the terminal population. For every t \u2265 0, by application\nof the branching property at time t, we may decompose the terminal population into subpopulations having the same ancestor at time t. Specifically,\n(k)\n\nYt\n\nW (k) =\n\nX\n\n(k)\n\nWi (t) ,\n\ni=1\n\n(k)\n\nwhere Wi (t) is the size of the terminal sub-population descending from the ith individual\n(k)\n(k)\nin the population at time t. Observe that conditionally on Yt , the variables Wi (t) are\n\u2212kt\n(k)\nindependent and all have the same law as e W .\n\u0001\nFinally, we define the genealogical process G(k) = G(k) (t), t \u2265 0 associated to Y (k)\nby\n\u0012\n\u0013\nG(k) (t) =\n\n(k)\n\nW1 (t), . . . , W\n\n(k)\n\n(k)\n\nYt\n\n(t)\n\n.\n\nThe genealogical structure of the Yule process can be described in terms of the fragmentation chain X (k) of Section 2.3 as follows.\nTheorem 4. Let N = (Nt , t \u2265 0) be a standard Poisson process which is independent of\nthe chain X (k) . Then for each w > 0, the compound chain\n\u0010\n\u0011\nwX (k) (Nwt ), t \u2265 0\n\n8\n\n\fhas the same law as the time-changed process\n\u0012\n\u0012\n\u0013\n\u0013\n(k) 1\nG\nlog(1 + kt) , t \u2265 0\nk\nconditioned on W (k) = w.\n\u0010\n\u0011\n(1)\nRemark. Theorem I of Kendall [12] states that given W (1) , Ylog(1+t/W (1) ) , t \u2265 0 is a\nPoisson process with unit parameter. This is clearly an aspect of Theorem 4. Moreover,\non page 130 of Athreya & Ney [1], it is suggested that no generalization of Kendall's\nresult to a more general continuous-time Markov branching process is known; Theorem 4\nconstitutes a small such generalization.\nProof: Set \u03c4 (t) := k1 log(1+kt) and let T be the time of the first birth in the Yule process,\nwhich is also the time of the first dislocation of G(k) . The k + 1 fragments of G(k) (T )\ncan be written as e\u2212kT Z1 , . . . , e\u2212kT Zk+1 where, by the branching property, Z1 , . . . , Zk+1\nare i.i.d. Gamma(1/k, 1/k) random variables, independent of T which is Exp(1). Define\na change of variables by\nS = \u03c4 \u22121 (T ) = (ekT \u2212 1)/k\nU1 = e\u2212kT Z1 ,\n\n...,\n\nUk = e\u2212kT Zk ,\n\nW = e\u2212kT (Z1 + * * * + Zk+1 ).\n\nIt is straightforward to see that the joint density of (T, Z1 , . . . , Zk+1 ) is\nf (t, z1 , . . . , zk+1 )\n= e\u2212t \u0393(1/k)\u2212(k+1) (1/k)(k+1)/k (z1 z2 . . . zk+1 )\u2212(k\u22121)/k exp(\u2212(z1 + * * * + zk+1 )/k)\nand so the joint density of (S, U1 , . . . , Uk , W ) is\ng(s, u1 , . . . , uk , w) = we\u2212ws * (1/k)\u0393(1/k)\u2212k w\u22121/k (u1 u2 . . . uk (w \u2212 u1 \u2212 * * * \u2212 uk ))1/k\u22121\n* (1/k)1/k \u0393(1/k)\u22121 w\u2212(k\u22121)/k exp(\u2212w/k).\nHence, W \u223c Gamma(1/k, 1/k) (as we already knew) and, conditional on W = w, we\nhave S \u223c Exp(w) and (U1 , U2 , . . . , Uk , W \u2212 U1 \u2212 * * * \u2212 Uk ) \u223c wDirk (1/k) independently of\nS. Thus, the first dislocation has the correct dynamics. But by the branching property,\nsubsequent dislocations are independent for different sub-populations and the total rate\nof fragmentation is always w. Hence result.\n\u0003\nIn the terminology of [2], Theorem 4 states that the time-changed genealogical process\nis a self-similar fragmentation with index 1, dislocation law Dirk (1/k) and erosion\ncoefficient 0. It may be interesting to observe that in the special case k = 1, this result\ncan also be derived as follows.\nConsider a real Brownian motion B started from 1 and killed when it reaches 0 (at time\nT0 = inf{t \u2265 0 : Bt = 0}). For every u \u2208 [0, 1[, let Yeu denote the number of excursions of\n(1)\nB away from 1 which go below level u. Then (Y\u2212 log(1\u2212u) )0\u2264u<1 is a version of (Yeu )0\u2264u<1 .\nTo see this, let us consider the evolution of Ye . Firstly, Ye0 = 1, corresponding to the\nsingle excursion below 1 which reaches 0. Let D = sup{t < T0 : Bt = 1}, the starting\ntime of the final excursion which hits 0, let U = inf 0\u2264t\u2264D Bt be the level reached by the\ndeepest excursion below 1 before D and let TU be the time at which it is reached. Then,\nG(k) \u25e6 \u03c4\n\n9\n\n\fby Williams' path decomposition theorem (Theorem VII.4.9 of Revuz and Yor [20]), U is\ndistributed uniformly on [0, 1[ and, conditional on U , (Bt )0\u2264t<TU is a Brownian motion\nstarted at 1 and stopped when it first hits level U . By symmetry, (BD\u2212t )0\u2264t<D\u2212TU is\nanother independent Brownian motion started at 1 and stopped when it first hits level\nU . Thus, Yeu is equal to 1 on [0, U [, YeU = 2 and (YeU +v )0\u2264v<1\u2212U evolves as the sum\nof two independent processes which are the same as Ye except that the times until the\nfirst jumps are now uniform on [0, U [ rather than on [0, 1[. (This is Theorem 8 of Le\nGall [16], repeated here for completeness.) Time-changing Y (1) with u \u2192 \u2212 log(1 \u2212 u)\nmeans that its exponential inter-jump times become uniform and so we do, indeed, have\nd\n(1)\n(Y\u2212 log(1\u2212u) )0\u2264u<1 = (Yeu )0\u2264u<1 .\nA more elegant way of expressing the preceding argument is to say that the Brownian\npath encodes a continuous-state branching process with quadratic branching mechanism.\nThe local time at level 1, L1T0 , satisfies\nL1T0 = lim 2(1 \u2212 u)Yeu .\nu\u21921\u2212\n\nIn this context, 21 L1T0 corresponds to the size of the population at time 1 in the continuousstate branching process generated by a single ancestor conditioned to have descendents\nup to time 1. The so-called reduced tree associated with the population at time 1 is\ndescribed up to the deterministic time-change u \u2192 \u2212 log(1 \u2212 u) by the Yule process Y (1) .\nSee, for instance, Section 2.7 in Duquesne and Le Gall [8], and Fleischmann and SiegmundSchultze [9]. Note that the well-known fact that 21 L1T0 has an exponential distribution with\nmean 1 (Proposition VI.4.6 of Revuz and Yor [20]) gives another derivation of the limiting\ndistribution in Lemma 3, since\n(1)\n\nW (1) = lim e\u2212t Yt\nt\u2192\u221e\n\nd 1\n(1)\n= lim (1 \u2212 u)Y\u2212 log(1\u2212u) = L1T0 .\nu\u21921\u2212\n2\n\nIt is known from excursion theory that in the scale of the local time at level 1, the\nrate of excursions of B away from 1 which reach level u \u2208 ]0, 1[ but do not exceed u \u2212 du\n1\n1\nis (1 \u2212 u)\u22122 du. Note that the map s \u2192 1 \u2212 1+s\nfrom R+ to [0, 1[ has inverse u \u2192 1\u2212u\n\u22121\n\u22122\nand, thus, transforms Lebesgue measure on R+ into the measure (1 \u2212 u) du on [0, 1[.\nSuppose that we split the local time at level 1 according to the occurrence of excursions\nexceeding level u, so that we obtain the sequence\n\u0010\n\u0011\nf (u) = W\nf1 (u), . . . , W\nfe (u) ,\nW\nYu\n\nf (u) is the sequence of the increments of the local time at level 1 on the maximal\nwhere W\ntime intervals such that at the beginning and end of each interval B is at 1 and during\nthe interval\nremains\nabove\nlevel u. Then it follows easily that the time-changed process\n\u0011\n\u0011\n\u0010\n\u0010\n1\nf\nW 1 \u2212 1+s , s \u2265 0 is a fragmentation in which each mass, say x, splits at rate x\ninto xU and x(1 \u2212 U ) where U is uniform. In other words, conditionally on 12 L1T0 = w,\n\u0011\n\u0011\n\u0010 \u0010\nf 1 \u2212 1 , s \u2265 0 is distributed as the compound fragmentation chain\nthe process W\n\u0001 1+s\nwX (1) (Nws ), s \u2265 0 , where N is an independent standard Poisson process.\nFinally, the composition of the two time-changes which appear in this analysis yields\n\u0012\n\u0012\n\u0013\u0013\n1\n= log(1 + s) ,\ns \u2208 R+ ,\ns \u2192 \u2212 log 1 \u2212 1 \u2212\n1+s\n\n10\n\n\fand so we recover Theorem 4 in the special case k = 1. Unfortunately, it does not seem\nthat there are similar interpretations for k \u2265 2.\nCorollary 5. We have that\n\u0013\n\u0012\n\u0012\n\u0011\u0013\n\u0010\n1\n\u2212t\n(k)\n(k) 1\nlog\n1\n+\nke\n/W\n,\nt\n\u2208\nR\nG\nk\nW (k)\nis a time-homogeneous Markov coalescent process which is independent of W (k) . For any\nn \u2265 1, given that it is in state x \u2208 \u2206nk , it waits an exponential time of parameter n and\nthen jumps to a variable distributed as Coagk (x), independently of the exponential time.\nNote that the case k = 1 of this result gives a variation of Kingman's coalescent. The\njump-chains are identical, as we have already noted, but here the rate of coalescence of two\nblocks depends on the total number of blocks present, whereas in Kingman's coalescent\nit does not.\nProof: Firstly, we note that by Theorem 4,\n\u0012\n\u0012\n\u0013\n\u0013\n1\n(k) 1\n\u2212t\n(k)\nG\nlog(1 + ke /W ) , t \u2208 R\nk\nW (k)\nhas the same law as\n\n\u0010\n\u0011\nX (k) (Ne\u2212t ), t \u2208 R\n\nand so we will work with the latter process instead. The k = 1 case is essentially treated\nin [3] and the proof proceeds in the same way here. The jump chain clearly behaves in the\ncorrect manner and so it remains to check that the inter-jump times are as claimed. Let\n0 \u2264 T1 \u2264 T2 \u2264 . . . be the jump times of (Nt )t\u22650 . Then the first instant that X (k) (Ne\u2212t )\nhas exactly nk + 1 terms is\ninf {t \u2208 R : Ne\u2212t = n} = \u2212 log Tn+1 .\nThe sequence of inter-jump times is\n. . . , log Tn+1 \u2212 log Tn , log Tn \u2212 log Tn\u22121 , . . . , log T2 \u2212 log T1\nand it is easily shown that this is a sequence of independent exponential random variables\nwith parameters\n. . . , n, n \u2212 1, . . . , 1\nrespectively.\n\n3.2\n\n\u0003\n\nContinuous setting\n\nContinuous-state branching processes (or CSBP's) were introduced by Lamperti [14, 15] as\nlimits of rescaled branching processes. Typically, a CSBP is a time-homogeneous Markov\nprocess with values in R+ ,\nZ = (Z(t, a), t \u2265 0 and a \u2265 0) ,\n(where the parameter t refers to time and the parameter a to the starting point i.e.\nZ(0, a) = a a.s.) which fulfils the branching property: the path-valued process (Z(*, x), x \u2265\n\n11\n\n\fe y) is an independent\n0) has independent and stationary increments. In particular, if Z(*,\ne y) has the law of Z(*, x + y). There is a simple recopy of Z(*, y), then Z(*, x) + Z(*,\nlation connecting CSBP's and Bochner's subordination for subordinators which enables\nus to define their genealogy; we refer the interested reader to [4] for heuristics, detailed\narguments etc.\nWe call a continuous state Yule process a CSBP\nY = (Y (t, a), t \u2265 0 and a \u2265 0) ,\nwhich evolves as follows: for each a > 0, the process Y (*, a) waits an exponential time\nwith parameter a and then jumps to a + 1. It then evolves independently as if it had been\nstarted in state a+ 1. In terms of the genealogy, the sub-population of size 1 which is born\nat a jump time has a parent which is chosen uniformly at random from the population\npresent before the jump. Note that this genealogy is easy to describe in a consistent\nmanner for different values a of the starting population.\nIt is immediate that for an integer starting point a \u2208 N, the process (Y (t, a), t \u2265 0)\nis a Yule process Y (1) with 2 offspring, as considered in the preceding section. However,\nwe stress that its genealogy is not the same as that of Y (1) , as we are dealing with a\ncontinuous population in the first case and a discrete population in the second.\nWe have the following analogue of Lemma 3:\n\u0001\nLemma 6. For every a \u2265 0, the process e\u2212t Y (t, a), t \u2265 0 is a uniformly integrable\nmartingale. Its limit, say \u03b3(a), viewed as a process in the variable a, has the same finite\ndimensional laws as a standard gamma process.\nL\n\nProof: For a = 1, we\u0001see from Lemma 3 and the identity in distribution Y (*, 1) = Y (1) (*)\nthat e\u2212t Y (t, 1), t \u2265 0 is a uniformly integrable martingale and that its limit has the\nstandard exponential distribution. The proof is easily completed by an appeal to the\nbranching property.\n\u0003\nRemark. The limiting distribution in Lemma 6 is essentially a corollary of Theorem 3\nof Grey [10].\nJust as in the preceding section, we think of \u03b3(a) as the size of the terminal population\nwhen the initial population has size a. We can express \u03b3(a) as\nX\n\u03b3(a) =\n\u03b4b ,\nb\u2264a\n\nwhere \u03b4 := (\u03b4b , b \u2265 0) is the jump process of \u03b3, which corresponds to decomposing the\nterminal population into sub-populations having the same ancestor at the initial time.\nWe write G(0, a) for the sequence of the jumps of \u03b3 on [0, a], ranked in decreasing order,\nand we deduce from Lemma 6 that conditionally on \u03b3(a) = g, G(0, a)/g has distribution\nPD(a).\nMore generally, by the branching property, we can decompose the terminal population\ninto sub-populations having the same ancestor at any given time t. This gives\nX\n(t)\n\u03b3(a) =\ne\u2212t \u03b4b ,\nb\u2264Y (t,a)\n\n(t)\n\nwhere \u03b4(t) := (\u03b4b , b \u2265 0) is the jump process of a standard gamma process \u03b3 (t) which is\nindependent of the Yule process up to time t, (Y (s, c), s \u2208 [0, t] and c \u2265 0). This enables\n\n12\n\n\fus to define for each a > 0 the genealogical process associated to a Yule process Y (*, a),\nG(*, a) = (G(t, a), t \u2265 0) ,\nwhere et G(t, a) is the ranked sequence of the sizes of the jumps of the subordinator \u03b3 (t)\non the interval [0, Y (t, a)].\nAn easy variation of the arguments for the proof of Theorem 4 shows that the genealogical structure of the Yule process can be described in terms of the fragmentation\nchain X (\u221e) of Section 2.3 as follows.\nTheorem 7. Fix a, g > 0 and let the chain X (\u221e) have initial distribution PD(a). Introduce a standard Poisson process, N = (Nt , t \u2265 0), which is independent of the chain\nX (\u221e) . Then the compound chain\n\u0010\n\u0011\ngX (\u221e) (Ngt ), t \u2265 0\nhas the same law as the time-changed process\n\n(G (log(1 + t), a) , t \u2265 0)\nconditioned on \u03b3(a) = g.\nLikewise, the analogue of Corollary 5 is as follows.\nCorollary 8. Fix a > 0. Then\n\u0012\n\u0013\n\u0001\n1\n\u2212t\nG log(1 + e /\u03b3(a)), a , t \u2208 R\n\u03b3(a)\n\nis a time-homogeneous Markov coalescent process which is independent of \u03b3(a). Suppose\nthat it is in state x \u2208 \u2206\u221e and recall Remark (a) of Section 2.3. Then if\nlim\n\n\u01eb\u21920+\n\n1\nmax{i : xi > \u01eb} = n + a,\nlog 1/\u01eb\n\nthe process waits an exponential time of parameter n and then jumps to a variable distributed as Coag1/(n+a) (x), independently of the exponential time.\n\nReferences\n[1] Athreya, K.B. and Ney, P.E. (1972). Branching processes. Springer-Verlag, BerlinHeidelberg-New York\n[2] Bertoin, J. (2002). Self-similar fragmentations. Ann. Inst. Henri Poincar\u00e9 38, 319340\n[3] Bertoin, J. (2003). Random covering of an interval and a variation of Kingman's\ncoalescent. To appear in Random Structures Algorithms. Also available as Preprint\nPMA-794 at http://www.proba.jussieu.fr/mathdoc/preprints/index.html\n[4] Bertoin, J. and Le Gall, J.-F. (2000). The Bolthausen-Sznitman coalescent and the\ngenealogy of continuous-state branching processes. Probab. Theory Relat. Fields 117,\n249-266\n\n13\n\n\f[5] Bertoin, J. and Le Gall, J.-F. (2003). Stochastic flows associated to coalescent processes. Probab. Theory Relat. Fields 126, 261-288\n[6] Bertoin, J. and Pitman, J. (2000). Two coalescents derived from the ranges of stable\nsubordinators. Elect. J. Probab. 5, 1-17. Available via\nhttp://www.math.u-psud.fr/~ejpecp/ejp5contents.html\n[7] Bolthausen, E. and Sznitman, A.S. (1998). On Ruelle's probability cascades and an\nabstract cavity method. Comm. Math. Physics 197, 247-276\n[8] Duquesne, T. and Le Gall, J.-F. (2002). Random trees, L\u00e9vy processes and spatial\nbranching processes. Ast\u00e9risque 281\n[9] Fleischmann, K. and Siegmund-Schultze, R. (1977) The structure of reduced critical\nGalton-Watson processes. Math. Nachr. 79, 233-241\n[10] Grey, D. R. (1974). Asymptotic behaviour of continuous time, continuous state-space\nbranching processes. J. Appl. Probab. 11, 669-677\n[11] Kallenberg, O. (1973). Canonical representations and convergence criteria for processes with interchangeable increments. Z. Wahrsch. verw. Gebiete 27, 23-36\n[12] Kendall, D. G. (1966). Branching processes since 1873. J. London Math. Soc. 41,\n385-406\n[13] Kingman, J. F. C. (1982). The coalescent. Stochastic Process. Appl. 13, 235-248\n[14] Lamperti, J. (1967). The limit of a sequence of branching processes. Z. Wahrsch.\nverw. Gebiete 7, 271-288\n[15] Lamperti, J. (1967). Continuous-state branching processes. Bull. Amer. Math. Soc.\n73, 382-386\n[16] Le Gall, J.-F. (1989). Marches al\u00e9atoires, mouvement brownien et processus de\nbranchement. S\u00e9minaire de Probabilit\u00e9s XXIII, Lecture Notes in Math., 1372,\nSpringer, Berlin, 258-274\n[17] Pitman, J. (1999). Coalescents with multiple collisions. Ann. Probab. 27, 1870-1902\n[18] Pitman, J. (2002). Combinatorial Stochastic Processes. Lecture notes for the St Flour\nsummer school. To appear. Available at\nhttp://stat-www.berkeley.edu/users/pitman/621.ps.Z\n[19] Pitman, J. and Yor, M. (1997). The two-parameter Poisson-Dirichlet distribution\nderived from a stable subordinator. Ann. Probab. 25, 855-900\n[20] Revuz, D. and Yor, M. (1999). Continuous martingales and Brownian motion, Third\nedition. Springer-Verlag, Berlin\n\n14\n\n\f"}