{"id": "http://arxiv.org/abs/1003.1643v1", "guidislink": true, "updated": "2010-03-08T14:50:49Z", "updated_parsed": [2010, 3, 8, 14, 50, 49, 0, 67, 0], "published": "2010-03-08T14:50:49Z", "published_parsed": [2010, 3, 8, 14, 50, 49, 0, 67, 0], "title": "THE TOOLS AND MONTE CARLO WORKING GROUP Summary Report from the Les\n  Houches 2009 Workshop on TeV Colliders", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1003.1069%2C1003.0172%2C1003.5118%2C1003.3150%2C1003.1899%2C1003.2576%2C1003.2507%2C1003.3423%2C1003.5021%2C1003.3280%2C1003.5525%2C1003.5861%2C1003.5930%2C1003.4426%2C1003.4263%2C1003.5900%2C1003.2817%2C1003.5248%2C1003.3635%2C1003.4088%2C1003.2346%2C1003.3288%2C1003.2966%2C1003.2347%2C1003.2505%2C1003.4834%2C1003.2669%2C1003.6127%2C1003.1784%2C1003.0741%2C1003.4443%2C1003.0095%2C1003.5851%2C1003.0542%2C1003.2674%2C1003.5569%2C1003.4572%2C1003.2459%2C1003.3143%2C1003.2795%2C1003.0680%2C1003.2950%2C1003.1236%2C1003.5981%2C1003.1644%2C1003.1422%2C1003.2014%2C1003.3628%2C1003.0884%2C1003.6046%2C1003.0343%2C1003.0259%2C1003.1643%2C1003.5967%2C1003.0691%2C1003.2614%2C1003.0654%2C1003.4268%2C1003.5898%2C1003.1159%2C1003.2792%2C1003.1253%2C1003.1282%2C1003.2673%2C1003.2707%2C1003.6047%2C1003.2405%2C1003.4206%2C1003.4452%2C1003.5277%2C1003.5417%2C1003.4650%2C1003.4036%2C1003.1341%2C1003.1409%2C1003.1678%2C1003.2514%2C1003.0962%2C1003.2257%2C1003.2010%2C1003.5447%2C1003.3284%2C1003.4987%2C1003.5649%2C1003.5784%2C1003.2493%2C1003.2411%2C1003.3911%2C1003.2475%2C1003.5429%2C1003.4352%2C1003.4227%2C1003.3267%2C1003.0461%2C1003.0811%2C1003.1249%2C1003.5820%2C1003.3084%2C1003.4028%2C1003.1827%2C1003.1034&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "THE TOOLS AND MONTE CARLO WORKING GROUP Summary Report from the Les\n  Houches 2009 Workshop on TeV Colliders"}, "summary": "This is the summary and introduction to the proceedings contributions for the\nLes Houches 2009 \"Tools and Monte Carlo\" working group.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1003.1069%2C1003.0172%2C1003.5118%2C1003.3150%2C1003.1899%2C1003.2576%2C1003.2507%2C1003.3423%2C1003.5021%2C1003.3280%2C1003.5525%2C1003.5861%2C1003.5930%2C1003.4426%2C1003.4263%2C1003.5900%2C1003.2817%2C1003.5248%2C1003.3635%2C1003.4088%2C1003.2346%2C1003.3288%2C1003.2966%2C1003.2347%2C1003.2505%2C1003.4834%2C1003.2669%2C1003.6127%2C1003.1784%2C1003.0741%2C1003.4443%2C1003.0095%2C1003.5851%2C1003.0542%2C1003.2674%2C1003.5569%2C1003.4572%2C1003.2459%2C1003.3143%2C1003.2795%2C1003.0680%2C1003.2950%2C1003.1236%2C1003.5981%2C1003.1644%2C1003.1422%2C1003.2014%2C1003.3628%2C1003.0884%2C1003.6046%2C1003.0343%2C1003.0259%2C1003.1643%2C1003.5967%2C1003.0691%2C1003.2614%2C1003.0654%2C1003.4268%2C1003.5898%2C1003.1159%2C1003.2792%2C1003.1253%2C1003.1282%2C1003.2673%2C1003.2707%2C1003.6047%2C1003.2405%2C1003.4206%2C1003.4452%2C1003.5277%2C1003.5417%2C1003.4650%2C1003.4036%2C1003.1341%2C1003.1409%2C1003.1678%2C1003.2514%2C1003.0962%2C1003.2257%2C1003.2010%2C1003.5447%2C1003.3284%2C1003.4987%2C1003.5649%2C1003.5784%2C1003.2493%2C1003.2411%2C1003.3911%2C1003.2475%2C1003.5429%2C1003.4352%2C1003.4227%2C1003.3267%2C1003.0461%2C1003.0811%2C1003.1249%2C1003.5820%2C1003.3084%2C1003.4028%2C1003.1827%2C1003.1034&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This is the summary and introduction to the proceedings contributions for the\nLes Houches 2009 \"Tools and Monte Carlo\" working group."}, "authors": ["J. M. Butterworth", "F. Maltoni", "F. Moortgat", "P. Richardson", "S. Schumann", "P. Skands", "J. Alwall", "A. Arbey", "L. Basso", "S. Belov", "A. Bharucha", "F. Braam", "A. Buckley", "M. Campanelli", "R. Chierici", "A. Djouadi", "L. Dudko", "C. Duhr", "F. Febres Cordero", "P. Francavilla", "B. Fuks", "L. Garren", "T. Goto", "M. Grazzini", "T. Hahn", "U. Haisch", "K. Hamilton", "S. Heinemeyer", "G. Hesketh", "S. Hoeche", "H. Hoeth", "J. Huston", "J. Kalinowski", "D. Kekelidze", "S. Kraml", "H. Lacker", "P. Lenzi", "P. Loch", "L. Lonnblad", "F. Mahmoudi", "E. Maina", "D. Majumder", "M. Mangano", "K. Mazumdar", "A. Martin", "J. Monk", "M. Muhlleitner", "C. Oleari", "S. Ovyn", "R. Pittau", "S. Plaetzer", "G. Piacquadio", "L. Reina", "J. Reuter", "X. Rouby", "C. Robinson", "T. Roy", "M. D. Schwartz", "H. Schulz", "E. von Seggern", "A. Sherstnev", "F. Siegert", "T. Sjostrand", "P. Slavich", "M. Spira", "C. Taylor", "M. Vesterinen", "S. de Visscher", "D. Wackeroth", "S. Weinzierl", "J. Winter", "T. R. Wyatt"], "author_detail": {"name": "T. R. Wyatt"}, "author": "T. R. Wyatt", "arxiv_comment": "144 Pages. Workshop site\n  http://wwwlapp.in2p3.fr/conferences/LesHouches/Houches2009/ . Conveners were\n  Butterworth, Maltoni, Moortgat, Richardson, Schumann and Skands", "links": [{"href": "http://arxiv.org/abs/1003.1643v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1003.1643v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "hep-ex", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1003.1643v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1003.1643v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:1003.1643v1 [hep-ph] 8 Mar 2010\n\nTHE TOOLS AND MONTE CARLO WORKING GROUP\nSummary Report\n\nJ. Alwall1 , A. Arbey3 , L. Basso4,5 , S. Belov6 , A. Bharucha7 , F. Braam9 , A. Buckley8 , J. M. Butterworth10\u2217 ,\nM. Campanelli10 , R. Chierici12 , A. Djouadi15 , L. Dudko16 , C. Duhr7 , F. Febres Cordero17 ,\nP. Francavilla18 , B. Fuks19 , L. Garren11 , T. Goto20 , M. Grazzini21,22 T. Hahn23 , U. Haisch24 ,\nK. Hamilton25 , S. Heinemeyer26 , G. Hesketh2 , S. H\u00f6che27 , H. Hoeth7 , J. Huston28 , J. Kalinowski29 ,\nD. Kekelidze6 , S. Kraml30 , H. Lacker31 , P. Lenzi13 , P. Loch32 , L. L\u00f6nnblad33 , F. Mahmoudi34 ,\nE. Maina35,36 , D. Majumder37 , F. Maltoni38\u2217 , M. Mangano2 , K. Mazumdar37 , A. Martin11,39 , J. Monk10 ,\nF. Moortgat21\u2217 , M. Muhlleitner40 , C. Oleari41 , S. Ovyn38 , R. Pittau42 , S. Pl\u00e4tzer40 , G. Piacquadio2,9 ,\nL. Reina43 , J. Reuter9 , P. Richardson7\u2217 , X. Rouby38 , C. Robinson10 , T. Roy44 , M. D. Schwartz45 ,\nH. Schulz31 , S. Schumann46\u2217 , E. von Seggern31 , A. Sherstnev16,48 F. Siegert7,10 , T. Sj\u00f6strand 33 ,\nP. Skands2\u2217 , P. Slavich49 , M. Spira50 , C. Taylor10 , M. Vesterinen54 , S. de Visscher27 , D. Wackeroth51 ,\nS. Weinzierl52 , J. Winter53 , T. R. Wyatt54\n\u2217 Session converners.\n1 SLAC National Accelerator Laboratory, Theoretical Physics Group, Mail Stop 81, 2575 Sand Hill Road,\nMenlo Park, CA 94025, USA\n2 CERN, CH-1211 Geneva 23, Switzerland\n3 Universit\u00e9 de Lyon, France; Universit\u00e9 Lyon 1, F\u201369622; CRAL, Observatoire de Lyon, F\u201369561\nSaint-Genis-Laval; CNRS, UMR 5574; ENS de Lyon, France\n4 School of Physics & Astronomy, University of Southampton, Highfield, Southampton SO17 1BJ, UK\n5 Particle Physics Department, Rutherford Appleton Laboratory, Chilton, Didcot, Oxon OX11 0QX, UK\n6 Joint Institute for Nuclear Research, Dubna, Moscow region, Russia, 141980\n7 IPPP, Physics Department, Durham University, DH1 3LE, UK\n8 School of Physics and Astronomy, University of Edinburgh, EH9 3JZ, UK\n9 University of Freiburg, Institute of Physics, Hermann-Herder-Str. 3, 79104 Freiburg, Germany\n10 Department of Physics and Astronomy, University College London, WC1E 6BT, UK\n11 Fermi National Accelerator Laboratory, P.O Box 500, Batavia, IL 60510, USA\n12 Institut de Physique Nucleaire de Lyon, IN2P3-CNRS, Universit\u00e9 Claude Bernard Lyon 1, Villeurbanne,\nFrance\n13 Universit\u00e0 degli Studi di Firenze & INFN Firenze, via Sansone 1, 50019 Sesto F.no, Firenze, Italy\n14 Department of Physics and Astronomy, UCLA, Los Angeles, CA 90095-1547, USA\n15 Laboratoire de Physique Th\u00e9orique, Universit\u00e9 Paris XI, F\u201391405 Orsay Cedex, France\n16 Skobeltsyn Institute of Nuclear Physics, Lomonosov Moscow State University, Vorob'evy Gory,\nMoscow 119992, Russia\n17 Universidad Sim\u00f3n Bol\u0131\u0301var, Departamento de F\u0131\u0301sica, Apartado 89000, Caracas 1080A, Venezuela.\n18 INFN - Pisa, Universita' di Pisa, G. Galilei Graduate School, Pisa, Italy\n19 Institut Pluridisciplinaire Hubert Curien/D\u00e9partement Recherche Subatomique, Universit\u00e9 de\nStrasbourg/CNRS-IN2P3, 23 Rue du Loess, F-67037 Strasbourg, France\n20 KEK Theory Center, Institute of Particle and Nuclear Studies, KEK, Tsukuba, 305-0801 Japan\n21 Dept. of Physics, ETH Z\u00fcrich, Z\u00fcrich, Switzerland\n22 INFN, Sezione di Firenze, 50019 Firenze, Italy.\n23 Max-Planck-Institut f\u00fcr Physik, F\u00f6hringer Ring 6, D\u201380805 Munich, Germany\n24 Institut f\u00fcr Physik (WA THEP), Johannes Gutenberg-Universit\u00e4t, D\u201355099 Mainz, Germany\n25 INFN, Sezione di Milano-Bicocca, 20126 Milan, Italy.\n26 Instituto de F\u0131\u0301sica de Cantabria (CSIC-UC), Santander, Spain\n27 Universit\u00e4t Z\u00fcrich, CH-8057 Z\u00fcrich, Switzerland\n28 Dept. of Physics and Astronomy, Michigan State University, East Lansing (MI), USA\n1\n\n\f29\n\nInstytut Fizyki Teoretycznej UW, Hoza 69, PL-00681 Warsaw, Poland\nde Physique Subatomique et de Cosmologie (LPSC), UJF Grenoble 1, CNRS/IN2P3, 53\nAvenue des Martyrs, 38026 Grenoble, France\n31 Inst. f. Physik, Humboldt-Universit\u00e4t zu Berlin, Berlin, Germany\n32 Department of Physics, University of Arizona, Tucson, Arizona, USA\n33 Department of Theoretical Physics, Lund University, S\u00f6lvegatan14A, S-223 62, Sweden.\n34 Clermont Universit\u00e9, Universit\u00e9 Blaise Pascal, CNRS/IN2P3, LPC, BP 10448, 63000\nClermont-Ferrand, France\n35 Dipartimento di Fisica Teorica, Universita' di Torino, Via Giuria 1, 10125 Torino, Italy\n36 INFN, Sezione di Torino, Via Giuria 1, 10125 Torino, Italy.\n37 Tata Institute of Fundamental Research, Homi Bhabha Road, Mumbai 400 005, India.\n38 Centre for Particle Physics and Phenomenology (CP3), Universit\u00e9 Catholique de Louvain, Chemin du\nCyclotron 2, B\u20131348 Louvain-la-Neuve, Belgium\n39 Department of Physics, Sloane Laboratory, Yale University, New Haven, CT 06520 USA\n40 Institut f\u00fcr Theoretische Physik, KIT, 76128 Karlsruhe, Germany\n41 Universit\u00e0 di Milano-Bicocca, 20126 Milano, Italy.\n42 Departamento de F\u0131\u0301sica Te\u00f3rica y del Cosmos Campus Fuentenueva, Universidad de Granada E-18071\nGranada, Spain\n43 Florida State University\n44 Department of Physics and Institute of Theoretical Science, University of Oregon, Eugene, OR 97403\nUSA\n45 Department of Physics, Harvard University, Cambridge, MA, USA\n46 Institut f\u00fcr Theoretische Physik, Universit\u00e4t Heidelberg, Philosophenweg 16, D-69120 Heidelberg,\nGermany\n48 R. Peierls Centre for Theoretical Physics, University of Oxford, OX1 3NP, UK\n49 LPTHE, 4, Place Jussieu, 75252 Paris, France\n50 Paul Scherrer Institut, CH\u20135232 Villigen PSI, Switzerland.\n51 University at Buffalo, SUNY\n52 Institut f\u00fcr Physik, Universit\u00e4t Mainz, D - 55099 Mainz, Germany\n53 Theoretical Physics Department, Fermi National Accelerator Laboratory, Batavia, IL 60510, USA\n54 Particle Physics Group, School of Physics and Astronomy, University of Manchester, UK.\n30 Laboratoire\n\nAbstract\nThis is the summary and introduction to the proceedings contributions for the\nLes Houches 2009 \"Tools and Monte Carlo\" working group.\nContents\n1. FOREWORD\n\n4\n\nI\n\n5\n\nINTERFACES\n\n2. A STANDARD FORMAT FOR LES HOUCHES EVENT FILES, VERSION 2\n\n5\n\n3. A DRAFT RUNTIME INTERFACE TO COMBINE PARTON SHOWERS AND NEXTTO-LEADING ORDER QCD PROGRAMS\n13\n4. STATUS OF THE FLAVOUR LES HOUCHES ACCORD\n\n19\n\n\fII\n\nTUNING\n\n27\n\n5. STATUS OF RIVET AND PROFESSOR MC VALIDATION & TUNING TOOLS\n\n27\n\n6. QUANTITATIVE ERROR ESTIMATION IN MC TUNES\n\n31\n\n7. MATRIX ELEMENT CORRECTIONS AND PARTON SHOWER MATCHING IN INCLUSIVE Z PRODUCTION AT LHC\n38\n\nIII\n\nBEYOND FIXED ORDER\n\n44\n\n8. MULTIPLE PARTON INTERACTIONS AS A BACKGROUND TO TOP PAIR PRODUCTION\n44\n9. A MATCHING SCHEME FOR W \u03b3 NLO MATRIX ELEMENT GENERATOR AND Pythia 8\nPARTON SHOWER\n51\n10. THEORY TESTS OF PARTON SHOWERS\n\n55\n\n11. HIGGS BOSON PRODUCTION VIA GLUON FUSION AT THE LHC: A COMPARATIVE STUDY\n58\n12. W bb\u0304 IN THE HIGH-pT HW REGION\n\n68\n\nIV\n\n80\n\nOBSERVABLES AND DETECTORS\n\n13. DELPHES, A FRAMEWORK FOR FAST SIMULATION OF A GENERIC COLLIDER\nEXPERIMENT\n80\n14. EFFECT OF QED FSR ON MEASUREMENTS OF Z/\u03b3\u2217 AND W LEPTONIC FINAL\nSTATES AT HADRON COLLIDERS\n84\n\nV\n\nJETS AND JET SUBSTRUCTURE\n\n91\n\n15. STATUS OF JET SUBSTRUCTURE STUDIES\n\n91\n\n16. HEAVY PARTICLE DECAYS IN MONTE CARLO EVENT GENERATORS\n\n96\n\n17. SENSITIVITY OF QCD JET MASS AND JET SUBSTRUCTURE TO PILE-UP AT LHC 108\n18. A STUDY OF RADIATION BETWEEN JETS AT THE LHC\n\n114\n\nVI\n\n120\n\nBEYOND THE STANDARD MODEL\n\n19. AN UPDATE OF THE PROGRAM HDECAY\n\n3\n\n120\n\n\f20. IMPLEMENTATION AND VALIDATION OF MODELS BEYOND THE STANDARD MODEL\nWITH FEYNRULES\n122\n1.\n\nFOREWORD\n\nThe working group on \"Tools\" and Monte Carlos for TeV-scale physics held discussions throughout the\ntwo-week period of the Les Houches meetings. The topics covered herein span both sessions. Several of\nthe topics followed on from those discussed in the \"Standard Model Handles and Candles\" session of the\nprevious workshop [1]; there has been substantial progress and several new topics were introduced.\nThe contributions here in fact include substantial physics results derived from the programmes, interfaces and techniques discussed, as well as status reports on existing projects and proposals for new\nstandards and interfaces.\nIn Part I we have collected the more technical proposals for common standards and interfaces, mostly\nrequired because of the rapid progress in higher order calculations. Part II collects results on the tuning\nof MC simulations, a critical topic for understanding LHC data. Part III contains several contributions\ncomparing various all-order calculations with fixed-order results, with and without matching between\nthe two. Part IV reflects some key issues on the communicability of results between experiment and\ntheory. Part V discusses recent progress and ideas in using jets and jet substructure at the LHC to study\nQCD and search for new physics, and finally Part VI discusses progress in some key modeling tools for\nbeyond-the-standard-model physics.\nThe productivity and pleasure of this workshop is overshadowed by the dreadful loss of our friend and\ncolleague Thomas Binoth, and we dedicate these proceedings to him.\n\n4\n\n\fPart I\n\nINTERFACES\n2.\n\nA STANDARD FORMAT FOR LES HOUCHES EVENT FILES, VERSION 2\n\n1\n\n2.1\n\nINTRODUCTION\n\nThe Les Houches Accord (LHA) for user-defined processes [2] has been immensely successful. It is\nroutinely used to pass information from matrix-element-based generators (MEGs) to general-purpose\nones (here, somewhat unfairly referred to as parton shower generators - PSGs), in order to generate\ncomplete events for a multitude of processes. The original standard was in terms of two Fortran common\nblocks where information could be stored, while the actual usage has tended to be mainly in terms of files\nwith parton-level events. For this purpose a new accord - the Les Houches Event File (LHEF) accord [3]\n- was introduced in 2006, which standardized the way such event files should be structured.\nThe LHEF was constructed using XML tags in order to make it flexible and easy to extend (although\nsome additional structure is assumed inside some tags which is not formulated in XML). The format has\nbeen extremely useful, and has basically become the standard way to interface matrix element generators\nand parton shower programs.\nAs the matching and merging of tree-level matrix elements and parton showers are now becoming the\nstate-of-art, it is reasonable to let this be reflected in an updated file format to standardize how relevant\ninformation should be given by the matrix element generators in a usable fashion for the parton shower\nprograms. Furthermore, with the matching of next-to-leading order (NLO) calculations and parton showers\nbecoming increasingly widespread, it is worth considering how the LHEF can be augmented in order to\nfacilitate this.\nFor the CKKW-type merging algorithms [4, 5] it is convenient to allow the Sudakov-reweighting to be\ndone in the MEG, as this will automatically regularize soft- and collinear divergencies. Hence it would be\ndesirable if the LHEF could include information about this. This does not only mean that a weight needs\nto be added, but also information about which cuts has been imposed in the MEG as well as information\non how the generated event was clustered to obtain the relevant scales and Sudakov form factors.\nIn the case the events are produced by a NLO MEG, the situation is a bit more complicated. Here\na subtraction scheme is typically used to handle the cancellation between real and virtual corrections.\nThis means that, besides loop-level events, each tree-level real event with one extra parton will need to\nbe supplemented by counter events corresponding to the assumed projections of the tree-level event to\nborn-level events with one parton less. To allow for matching or merging with a PSG, these events need to\nbe considered together in a group of events, something that was not forseen in the original file format.\nIndependent of these ME-PS matching considerations, we also wish to introduce some further, minor,\nadditions to assist the determination of errors arising from the the parton density function (PDF) parameterizations used in the MEG. Normally these error estimates are given as a set of different PDFs where\nthe parameters have been varied around the best fit value. Hence, a given event may be associated with\nseveral weights corresponding to the different PDFs used.\nNote that the scope of the format suggested here is somewhat different from the HepML schema [6]\n(used by eg. the MCDB project [7]). The LHEF format is specialized in the interface between matrix\nelement generators and parton shower programs, while HepML is intended to give more general metainformation on how events have been produced by an event generator. However, there is nothing that\n1\n\nContributed by L. L\u00f6nnblad Email leif.lonnblad@thep.lu.se, J. Alwall, S. Belov, L. Dudko, L. Garren, K. Hamilton, J. Huston, D. Kekelidze, E. Maina, F. Maltoni, M. Mangano, R. Pittau, S. Pl\u00e4tzer, A. Sherstnev, T. Sj\u00f6strand, P. Skands.\n\n5\n\n\f<LesHouchesEvents version=\"1.0\">\n<!-# optional information in completely free format,\n# except for the reserved end tag (see next line)\n-->\n<header>\n<!-- individually designed XML tags, in fancy XML style -->\n</header>\n<init>\ncompulsory initialization information\n# optional initialization information\n</init>\n<event>\ncompulsory event information\n# optional event information\n</event>\n(further <event> ... </event> blocks, one for each event)\n</LesHouchesEvents>\n\nFig. 1: The original structure of a Les Houches event file.\nprevents the LHEF format to be included in the HepML structure in the future.\nThe outline of this article is as follows. In section 2.2 we review the structure of the original LHEF\naccord and of the Les Houches common block structure on which it is based. Then in section 2.3 we\npresent the additional XML tags which may be used to specify additional global, and per-event information.\nFinally we give a brief summary and outlook.\n2.2\n\nTHE ORIGINAL EVENT FILE FORMAT AND COMMON BLOCK STRUCTURE\n\nThe first version of the Les Houches event file format was a simple structure specifying how to write the\nLes Houches common blocks to a text file. A few XML tags were defined to simplify parsing but not\nmuch more than the information in the common blocks was formalized. The structure of a file is outlined\nin figure 1, where the tags are as follows.\n\u2022 LesHouchesEvents: which contains the whole file and which mandates a version attribute\nset to \"1.0\".\n\u2022 header: which may contain any number of unspecified XML tags describing how the events were\ngenerated.\n\u2022 init: This is the tag which specifies the information in the HEPRUP common block. The start tag\nmust be alone on a line and the following line must contain the information which is in common for\nall processes in the file. The lines following this must contain the per-process information from the\ncommon block, one process per line. If there are any other lines before the end tag, they must be\npreceded by a #-sign (c.f. figure 2).\n\u2022 event: The init tag may be followed by any number of event tags, one for each event\ngenerated. Also the event start tag must be alone on a line and the following line must contain the\ngeneral event information from the HEPEUP common block. The lines following this must contain\nthe per-particle information, one line per particle. Also here additional lines may be included before\nthe end tag if they are preceded by a #-sign. (c.f. figure 3).\n\u2022 Before the init tag one may, optionally, include arbitrary text enclosed in XML comment tags,\n<!-- ... -->, but no other text is allowed in the enclosing LesHouchesEvents tag.\nFor a more detailed description of the LHEF format we refer to [3].\n\n6\n\n\f<init>\nIDBMUP(1) IDBMUP(2) EBMUP(1) EBMUP(2) PDFGUP(1) PDFSUP(1) PDFSUP(2) IDWTUP NPRUP\nXSECUP(1) XERRUP(1) XMAXUP(1) LPRUP(1)\nXSECUP(2) XERRUP(2) XMAXUP(2) LPRUP(2)\n...\nXSECUP(NPRUP) XERRUP(NPRUP) XMAXUP(NPRUP) LPRUP(NPRUP)\n# Additional\n# information\n</init>\n\nFig. 2: The structure of the init tag in the original LHEF format. See [2] for the meaning of the different\ncommon block variables.\n<event>\nNUP IDPRUP XWGTUP SCALUP AQEDUP AQCDUP\nIDUP(1) ISTUP(1) MOTHUP(1,1) MOTHUP(2,1) ICOLUP(1,1) ICOLUP(2,1) PUP(1,1) PUP(2,1) PUP(3,1) PUP(4,1) PUP(5,1)\nIDUP(2) ISTUP(2) MOTHUP(1,2) MOTHUP(2,2) ICOLUP(1,2) ICOLUP(2,2) PUP(1,2) PUP(2,2) PUP(3,2) PUP(4,2) PUP(5,2)\n...\n# In total 1+NUP lines after the <event> tag\n# Additional\n# information\n</event>\n\nFig. 3: The structure of the event tag in the original LHEF format. See [2] for the meaning of the\ndifferent common block variables.\n2.3\n\nTHE NEW FILE FORMAT\n\nWe now describe our suggestion for an updated file format which includes the additional information\nmentioned in the introduction. All such information is encoded in XML tags with optional attributes given\nin the usual way:\n<tag attribute1=\"value\" attribute2=\"value\">content</tag>\nor, for a tag without content,\n<tag attribute1=\"value\" attribute2=\"value\" attribute3=\"value\" />\nThe new tags can either be given in the init block, should they refer to the whole file, or in the event\nblock, if they only refer to an individual event. In addition group tags can be inserted to group events\ntogether.\n2.31\n\nGLOBAL INFORMATION\n\nThe following tags may be included inside the init tag and contain additional global information about\nhow the events in the file were produced. They must be placed after the mandatory lines containing\nHEPRUP common block information (see figure 2), but otherwise the order is unimportant. Only tags\nwhich are not marked optional below need to be supplied.\nThe generator tag (optional) This is just added to give easy access to the name of the program which\nhas generated the file. The content of the tag is simply the name and the only allowed attribute is\n- version: a string describing the version of the generator used.\nThe xsecinfo tag (required) The information in the HEPRUP common block is in principle sufficient\nto determine the cross sections of the processes involved. Currently, the way in which this information\n7\n\n\fis specified is a bit complicated and sometimes confusing, since it was assumed to be used to pass\ninformation between the MEG and PSG in both directions. For the event file, the communication is per\ndefinition one-way, and the information can be made more easily accessible. The tag itself has no content,\nand the information is given in the following attributes.\n-\n\n-\n\nneve (R)2 : the number of events3 in the file.\ntotxsec (R): the total cross section (in units of pb) of all processes in the file.\nmaxweight (D=1)4 : the maximum weight of any event5 in the file (in an arbitrary unit).\nminweight (D=-maxweight): if the file contains negative weights, the minweight is the\nmost negative of the negative weights in the file. (Must obviously be the same unit as maxweight.)\nmeanweight (D=1): The average weight of the events in the file (same unit as maxweight).\nnegweights (D=no): If yes, then the file may contain negative weights.\nvarweights (D=no): If yes, then the file may contain varying event weights. If no, all events\nare weighted with maxweight (or, if negweights=yes, with minweight).\neventgroups (D=no): If yes, the events in the file may be grouped together with group tags,\nin which case the attributes above count an event group as one event rather than several separate\nones.\nmaxingroupweight (D=maxweight): If eventgroups=yes, this gives the maximum\nweight among the events inside groups.\nminingroupweight (D=-maxingroupweight): If eventgroups=yes, this gives the\nminimum weight among the events inside groups.\n\nNote that it is assumed that all processes in the file are weighted with respect to a common total\ncross section, such that summing the weights for the events of a given process and multiplying with\ntotxsec/maxweight/neve will give the cross section for that process. In this way, the per-process\ninformation in the HEPRUP common block can be safely ignored.\nThe cutsinfo tag (optional) This tag is used to supply information about which kinematical cuts were\nused to generate the events in the file. Several different cuts can be given with cut tags and it is possible\nto specify which particles should be affected by each cut using ptype tags.\nThe cut tag contains an actual cut made in the generation of the events. In general, all events in the file\nwill pass this cut. The cut is defined in terms of a kinematical variable and the particles which are affected.\nThe content of the tag is one or two numbers giving the allowed range of value of the kinematical variable\naccording to the attribute limit (see below).\nThe variable is defined according to the following attributes of the cut tag:\n- p1 (D=0): Lists the particle types for which this cut applies. This can be either a number,\ncorresponding to a given particle PDG [8] code, or a string corresponding to a group of particles\npreviously defined with a ptype tag (see below). The default is zero which means any particle\ntype.\n- p2, . . . , p9: Allows the specification of additional sets of particle types, by analogy to p1, in order\nto facilitate the application of different classes of cuts to different classes of particles.\n- type (R): This defines the variable which is cut. The following values are predefined, but also\nother variables may be specified. (Where relevant, the laboratory frame is assumed, and all energy\nunits are in GeV.)\n2\n\n(R) means the attribute is mandatory\nNote that if the file contains events inside group tags (see section 2.33 below), neve must refer to the number of event\ngroups (plus the events which are outside the groups).\n4\nFor attributes which are not mandatory, (D=. . . ) indicates which value is assumed it not present\n5\nNote that if the file contains events inside group tags (see section 2.33 below), maxweight, minweight and\nmeanweight must refer to the weights of the groups (and the weights of the events which are outside the groups).\n3\n\n8\n\n\f\u2013 m: the invariant mass of a particle of type p1. If additional particle types are specified the cut\napplies to the invariant mass of the corresponding number of particles, i.e. if p1, p2 and p3\nare specified the cut is on the invariant mass of any set of three matching particles.\n\u2013 pt: the transverse momentum of a particle matching p1.\n\u2013 eta: the pseudo-rapidity of a particle matching p1.\n\u2013 y: the true rapidity of a particle matching p1.\np\n\u2013 deltaR: the pseudo-rapidity\u2013azimuthal-angle difference ( \u2206\u03b7 2 + \u2206\u03c62 ) between two particles matching p1 and p2 respectively.\n\u2013 E: the energy of a particle matching p1.\n\u2013 ETmiss: the norm of the vectorial sum of the pt of final state particles matching p1 and not\nmatching p2 (Note that an empty p2 defaults to the empty set here and for HT below).\n\u2013 HT: the scalar sum of the transverse momentum of final state particles matching p1 and not\nmatching p2.\n- limit (D=min): If set to min (max) only one number should be marked by the tag and give the\nminimum (maximum) for the kinematical variable, while if it is set to minmax, there should be\ntwo numbers corresponding to the minimum and maximum (in that order).\nThe groups of particles to be considered in the p1 and p2 attributes of the cut tag are specified by\nptype tags, which simply contains the PDG codes of the particle types belonging to the group. The only\nallowed attribute in the ptype tag is\n- name (R): the name of this group of particle types.\nHere is a short example on how to specify a cut where a charged electron or muon is required to have a\ntransverse momentum of at least 20 GeV and a minimum of 25 GeV missing transverse energy is required:\n<cutsinfo>\n<ptype name=\"l+-\">11 -11 13 -13</ptype>\n<ptype name=\"nu\">12 -12 14 -14 16 -16</ptype>\n<cut type=\"pt\" p1=\"l+-\">20</cut>\n<cut type=\"ETmiss\" p1=\"0\" p2=\"nu\">25</cut>\n</cutsinfo>\nThe procinfo tag (optional) The procinfo tag is used to supply additional per-process information\nin addition to what is given in the HEPRUP common block part of the init tag. The content of the tag is\nsimply an arbitrary string describing the process. The attributes are the following:\n- iproc (D=0): The process number for which the information is given. This must correspond to the\nLPRUP code in the HEPRUP common block for the corresponding process. Also zero can be given,\nin which case it refers to all processes in the file (except those with a separate procinfo tag).\n- loops (D=0): The number of loops used in calculating this process.\n- qcdorder: The power of \u03b1S used in calculating this process.\n- eworder: The power of the electro-weak coupling used in calculating this process.\n- rscheme (D=MSbar): The renormalization scheme used in calculating this process.\n- fscheme (D=MSbar): The factorization scheme used in calculating this process.\n- scheme (D=tree): Information about the scheme used to calculate the matrix elements to NLO.\nIf absent, a pure tree-level calculation is assumed. Possible values could be CSdipole (NLO\ncalculation with Catani\u2013Seymour subtraction [9]), FKS [10,11], MC@NLO [12,13], POWHEG [14,15]\nand NLOexclusive (NLO calculation according to the exclusive cross section (see eg. [16])\nwithin the given cuts).\n\n9\n\n\fThe mergetype tag (optional) For some merging schemes (eg. for CKKW) it is possible to reweight\nthe the events with Sudakov form factors already in the MEG. If this has been done the content of the\nmergetype tag for the corresponding process should give a name corresponding to the scheme used.\nThe attributes are:\n- iproc: The process number for which the information is given. A zero means all processes except\nthose with a separate mergeinfo tag.\n- mergingscale (R): The value of the merging scale in GeV.\n- maxmult (D=no): If yes, the corresponding process is reweighted as if it is the maximum\nmultiplicity process, i.e. the Sudakov form factor associated with evolution between the smallest\nclustering scale and the merging scale is not included.\n2.32\n\nPER-EVENT INFORMATION\n\nInformation about a given event may be given with XML tags after the mandatory lines containing\nHEPEUP common block information (see figure 3).\nThe weight tag (optional) An event can be associated with a number of different weights given in\nweight tags. The content of these tags is simply a sequence of weights corresponding to the cross\nsection for the event using different PDFs, \u03b1S values, etc. which can be used to estimate the systematic\nerrors due to, e.g., PDF uncertainties. Each weight tag should be given a name for identification. Only\none weight tag per event can be without a name and should then only contain one weight, which is\nthe one for which the statistics in the xsecinfo tag is given. The attributes of the weight tag are as\nfollows\n- name: An arbitrary string describing this set of weights. If no name is given this is the main weight\nfor the event.\n- born (D=1): If this is not a normal tree-level event but reweighted in some way (eg. by Sudakov\nreweighting or using loop contributions), this should be set to the relative weight of the tree-level\ncross section.\n- sudakov (D=1): If this event has been reweighted by a Sudakov form factor, the size of this factor\nshould be given here.\nThe last two attributes will probably only be given for the main weight. If an event has only been\nreweighted by a Sudakov form factor then these attributes are related by born*sudakov=1. The total\nBorn cross section is obtained by summing the weights multiplied by born for each event of the given\nprocess, and multiplying with totxsec/maxweight/neve from the xsecinfo tag.\nThe clustering tag (optional) If an event has eg. been reweighted with Sudakov form factors, it is\npossible to specify how the current event has been clustered to find the scales involved. The contents\nof this this tag should be a series of clus tags. The clustering should be defined from the final state\nbackwards in terms inverse time-like splittings, in the end defining a \"bare\" ladder diagram. This is then\nfollowed by a sequence of space-like splittings.\nThe clustering tag contains a number of clus tags corresponding to each of the splittings. Each\nclus tag contains two or three integers. The first two numbers indicate which particles entries in the\nHEPEUP common block are clustered. If a third number is given it should correspond to an actual particle\nentry which corresponds to the combined object (if eg. a decayed resonance is explicitly present in the\nHEPEUP common block). If no third number is given, the clustered object is in the following referred to\nby the first number. The attributes of the clus tag are:\n- scale: The scale (in GeV) associated with the clustering.\n- alphas: If the event has been reweighted with an \u03b1S at the scale of this clustering, the value of\nthis \u03b1S should be supplied here.\n10\n\n\f<clustering>\n<clus>6 7 5</clus>\n<clus>3 8</clus>\n<clus>1 3</clus>\n<clus>1 5</clus>\n<clus>1 4</clus>\n</clustering>\n\nFig. 4: Example of how a Feynman diagram can be encoded using a clustering tag. The numbering in the\ndiagram corresponds to the particle entries in the HEPEUP common block\n\nWe also wish to draw attention to the fact that the clustering tag can equally be used to encode the\nFeynman diagram (or the most likely of the ones) used to produce the event. See figure 4 for an example.\nThe pdfinfo tag (optional) The pdfinfo tag contains the values of the PDFs used when generating\nthis event, given by two numbers, xf1 (x1 , Q2 ) and xf2 (x2 , Q2 ), for the two incoming partons. The\nattributes are:\n-\n\n2.33\n\np1: The PDG code of the first incoming parton.\np2: The PDG code of the second incoming parton.\nx1: The momentum fraction of the first incoming parton.\nx2: The momentum fraction of the second incoming parton.\nscale: (D=SCALUP) The scale in GeV used in the PDFs (the default is taken from the HEPEUP\ncommon block).\nGROUPING OF EVENTS\n\nIf we have a NLO calculation using eg. Catani\u2013Seymour subtraction of a process with N particles in\nthe Born level, each N + 1 tree-level event will come with a number of counter events with N particles.\nFor this reason there is a need to group events together. Such a group of events should be included in a\ngroup tag.\nThe group tag (optional) The content of this tag is a number of event tags which for should be\nconsidered together. If this is a N + 1 tree-level event with a number of N -particle counter events, the first\nevent must always be the N + 1-particle event even if this event fails the cuts. The rest of the events are\nthen the counter events. The group tag must also contain at least one main weight tag (without name\nattribute) which is the one for which the statistics in the xsecinfo tag is given. The individual weights\nof the events in the group should sum up to the weight of the whole group. The only allowed attribute is\n- n (R): The number of events in the group.\nNote that if event groups are present, the neve attribute in the xsecinfo tag should count an event\ngroup as a single event. Also, it is the weight of the event group which relates to the maxweight\nand meanweight attributes in the xsecinfo tag. To be compatible with the previous standard, where\nthe <event> and </event> tags are required to be alone on a single line, also the <group> and\n</group> tags are required to be alone on a single line.\n11\n\n\f2.4\n\nOUTLOOK\n\nEvent files which follows this new standard should have their version attribute in the LesHouchesEvents (see figure 1) tag set to 2.0. The web page http://home.thep.lu.se/\u223cleif/LHEF/\ncontains a number of C++ classes implementing the reading and writing of files according to the new\nstandard.\nWe have tried to make the new standard backward compatible with the previous one, and although all\nexisting parsers may not be able to read new files we propose to keep the old preferred .lhe file name\nextension.\nAs with the previous standard, the current proposal must not be viewed as the end of the road. There\nmay be further information exchange that ought to be standardized. It is allowed to use/promote a \"private\nstandard\" of tags in the header block or of additional event information, and experience with such could\npoint the way towards an extended standard at a later date.\nNote that a formal description of the proposed new standard can be found at the Les Houches 09 wiki\npages.6\n\n6\n\nhttp://www.lpthe.jussieu.fr/LesHouches09Wiki/images/6/60/Grammar.pdf\n\n12\n\n\f3.\n\nA DRAFT RUNTIME INTERFACE TO COMBINE PARTON SHOWERS AND NEXT-TOLEADING ORDER QCD PROGRAMS 7\n\n3.1\n\nINTRODUCTION\n\nParton shower simulation programs like Pythia 6 and Herwig 6 [17, 18] have been the workhorses for high\nenergy physics experiments for a long time. With the advent of the Large Hadron Collider (LHC) at CERN,\nthe FORTRAN generators have been completely rewritten and extended as Pythia 8 and Herwig++ [19\u201321]\nand the program Sherpa has been established [22, 23].\nMany new developments have been made in order to refine these simulations and to extend their\napplicability. Particularly, progress is now being made towards automation of schemes combining\nparton shower Monte Carlos and NLO QCD corrections consistently along the lines of now established\nschemes [12, 14]. Especially the POWHEG scheme exhibits close connections to methods correcting the\nhardest emission in parton shower simulations to the relevant exact real emission matrix element, [24].\nDedicated codes performing just the matching to NLO QCD are as well under development, [25].\nIn order to use existing and future tools for fixed-order calculations, especially in view of efforts towards\nautomation present for these problems as well, it is desirable to specify an interface to the generic building\nblocks of fixed-order, particularly NLO QCD calculations carried out within the subtraction formalism.\nThe approach of communicating simulation results between different programs taken so far by exchanging event files of a definite format [3] is not appropriate for the task being addressed here. Rather a\nruntime interface between two distinct codes is desirable. Here, one code links to another either statically\nor dynamically and makes use of the implemented functionality through an interface which is now a set of\ndefinite function calls.\nThe interface should however not limit the particular ways in which fixed-order calculations are carried\nout, neither how the matching is actually performed by the parton shower Monte Carlo or a dedicated\nmatching code. It should further not limit which programming language is actually being used and\nis therefore formulated in a language independent way. Any binding to a particular language is an\nimplementational detail.\n3.2\n\nPRELIMINARIES\n\n3.21\n\nOBJECTS HANDLED BY THE INTERFACE\n\nThe interface aims at having each individual building block of a leading- or next-to-leading order QCD\ncalculation at hand. In particular\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\nphase space generation\ntree-level matrix elements\nsubtraction terms\nfinite parts of one loop/Born interferences\nfinite remainder terms originating from collinear factorization\n\nare addressed as individual objects. These objects will be defined in detail in the following sections.\n3.22\n\nDIFFERENTIAL CROSS SECTIONS\n\nThe interface is formulated to handle all pieces inherent to a leading- or next-to-leading order differential\ncross section to be available in the following form, where \u03b1 denotes any contribution as listed in the\n7\n\nContributed by: S. Pl\u00e4tzer\n\n13\n\n\fprevious subsection:\n\u03b1\nd\u03c3ij\n= fi (xi , \u03bcF )fj (xj , \u03bcF ) \u00d7\n\u03b1\nF{i,j,k\n({pi , pj , p1 , ..., pn }, \u03bcR )\n1 ,...,kn }\n\n\u2202\u03c6({pi , pj , p1 , ..., pn }, xi , xj ) d\nd r . (1)\n\u2202~r\n\nHere {i, j, k1 , ..., kn } identifies a particular subprocess of which the term indexed by \u03b1 contributes\nto, {pi , pj , p1 , ..., pn } is the physical phase space point, and ~r is a set of d random numbers in the\nd-dimensional unit hypercube.\nIn the following the Jacobian determinant will be referred to as a phase space generator. The corresponding functionality will be addressed as an individual part of differential cross sections within the\ninterface. Note that this does not reference the precise way in which the Monte Carlo integration or the\ngeneration of unweighted events is performed by any client code8 .\nThe parton density functions (PDFs) f as well as the value of renormalization scale \u03bcR , factorization\nscale \u03bcF and the strong coupling will be provided by the client code, such that the part of the interface\nrepresenting the contribution \u03b1 is completely specified as a function evaluating F \u03b1 . Additionally, few\nbookkeeping specifications will be introduced.\nFor tree-level matrix elements (including the real-emission part of a NLO calculation, F just represents\nthe corresponding tree-level matrix element squared times the appropriate flux and symmetry factors.\n3.23\n\nNLO DIFFERENTIAL CROSS SECTIONS AND SUBTRACTION\n\nThe interface focuses on NLO QCD corrections being carried out within the subtraction formalism to\nobtain finite contributions from both virtual and real-emission corrections to any infrared safe observable.\nExamples of schemes widely in use are [9, 10, 26], the interface to be specified in detail in the next\nsection should however not limit any implementation to a particular scheme.\nFew universal properties are however assumed to be common to any subtraction scheme at next-toleading order. In particular it will be assumed that the auxiliary cross section introduced to subtract the\ndivergent behaviour of the real emission contribution to NLO corrections for a 2 \u2192 n process is of the\nform\nk\nX\n\u03b1\nd\u03c3sub\n(pn+1 , in+1 )O(p\u03b1n (pn+1 ), i\u03b1n ) .\n(2)\n\u03b1=1\n\nHere, O denotes an infrared safe observable (sometimes also referred to as a jet defining function) and\np\u03b1n (pn+1 ) is a unique and invertible momentum mapping from a real emission to an underlying Born\nconfiguration, which is identified by a flavour mapping in+1 \u2192 i\u03b1n .\n\nThe number of individual subtraction terms k is not assumed to be fixed. Besides the unique association\nof a subtraction term to an underlying Born configuration each subtraction term is expected to subtract\nof a particular set of one or more collinear divergences, which at NLO are identified by just labelling\nthe pair of partons becoming collinear. This information is crucial for a parton shower simulation to\nassign an additional parton to a unique emitter in a meaningful way thereby fixing the initial conditions\nfor subsequent showering.\n3.24\n\n'COLLINEAR REMAINDERS'\n\nAfter analytical integration of the subtraction terms, the encountered divergences cancel these present in\nthe virtual correction and counter terms needed to renormalize the parton distribution functions. The finite\nremainder left from cancelling the latter divergences will then additionally depend on the factorization\nscale, the momentum fractions x1,2 and convolutions in one or two variables z \u2208 [0, 1] are in general\n8\n\nThroughout this work the NLO code itself is considered to be 'client' code of the interface.\n\n14\n\n\fpresent. Further, these convolutions are assumed to be casted in a form which is suitable to be done by\nMonte Carlo methods as well. The interface therefore assumes a modified version of the contribution F\nassociated to these finite remainders,\ncoll\ncoll\nF{i,j,k\n= F{i,j,k\n({pi , pj , p1 , ..., pn }, \u03bcR , \u03bcF , x1 , x2 , z1 , z2 ) ,\n1 ,...,kn }\n1 ,...,kn }\n\n(3)\n\nwhere two additional random numbers z1,2 on the unit interval are provided such that the convolution is\nperformed on averaging over all events.\n3.25\n\nCOLOUR DECOMPOSITION\n\nIn order to determine parton shower initial conditions but as well for the purpose of implementing\nindependent subtraction schemes, the knowledge of partial amplitudes for the Born and real emission\ncontribution is crucial.\nThe basis being used in this colour decomposition is however not unique. To the extent that parton\nshower initial conditions are usually determined by colour flows in the large-N limit, it would be desirable\nto have this decomposition in the fundamental representation of SU (N = 3) available. Here, the basis\ntensors are just strings of Kronecker \u03b4's,\n\u03b4ji11 * * * \u03b4jinn ,\n(4)\nwhere an upstairs index transforms according to the anti-fundamental, a downstairs index according to the\nfundamental representation, indicating outgoing colour (incoming anticolour) and outgoing anticolour\n(incoming colour), respectively. Note that this representation is not limited to, but well suited, for the\nlarge-N limit. The interface assumes this representation being available, but may be extended to other\nrepresentations leaving it up to the client code to change basis from one to another decomposition.\n3.26\n\nNOTATION\n\nThe interface is formulated as a set of functions, taking any number of arguments and returning a result.\nThe result may be a composite object of several types, which, depending on the language binding, may\nindividually be passed as references to the function call.\nA function of name F taking arguments of type A1, A2,..., returning a result of type T is denoted by T\nF (A1,A2,...), where each argument may be followed by a name identifying the meaning of the argument.\nThe required types are defined in the following section, except for obvious simple types. Semantic\ndefinitions of each interface part are accompanied by pre- and postconditions where needed. Examples of\nlanguage bindings are given to explain the relation between the abstract notation and implementational\ndetails.\n3.27\n\nTYPES USED\n\nThe purpose of this section is to introduce the more complex types used to specify the interface components.\nFew basic types with obvious semantics are used without further documentation.\nvector \u2013 A list of objects of the same type. Elements in the list can be accessed randomly by an\ninteger index. The type of objects stored is indicated in angle brackets, e.g. vector<double> is a vector\nstoring doubles. The size of the vector is to be asserted in the context of a particular piece of the interface.\nExamples are INTEGER V(4) or std::vector<int> v(4); for FORTRAN and C++, respectively.\npair \u2013 A pair stores to values of potentially different type. This is an auxiliary concept which does not\nhave to be supported by a particular language. A pair storing values of type T1 and T2, respectively, is\ndenoted pair<T1,T2>.\nunion \u2013 A union generalizes pair to more than two entries.\nprocessid \u2013 Defined to be vector<int>. Identifies a subprocess giving PDG ids for incoming partons\nin the first two entries, and PDG ids for outgoing partons in the following entries. The size of the vector is\n15\n\n\f \u0304 for example, would be identified by\nguaranteed to be greater or equal to three. The subprocess gg \u2192 ddg,\nthe entries {21, 21, 1, \u22121, 21}.\n\nmomentum \u2013 Defined to be vector<double> of length five. The first four entries contain the fourmomentum components px , py , pz , E in units of GeV. The fifth component is optional containing the\ninvariant mass squared in units of GeV squared. The metric is agreed to be mostly-minus, p * q =\nEp Eq \u2212 p~ * ~q.\npspoint \u2013 Defined to be union<double,pair<double,double>,vector<momentum> >. Represents\na phase space point as the phase space weight (Jacobian from unit-hypercube random numbers to phase\nspace measure), momentum fractions of incoming partons and a set of momenta. The first two momentum\nentries specify the momenta of incoming partons, subsequent these of outgoing partons. The size of the\nmomentum vector is greater or equal to three. The weight is given in units of the proper power of GeV to\nobtain a dimensionless quantity.\n\ncolourflow \u2013 Defined to be vector<pair<int,int> >. Represents a colour flow assigned to a particular\nsubprocess in the following convention: in association to a processid, the first and second members of an\nentry of a colourflow at position i contain an integer id for the colour and anticolour line, the corresponding\nparton at position i in the process id is connected to. By convention, a triplet always has its second\ncolour index set to zero, an antitriplet its first index. A singlet uses the pair {0, 0}. Note that this notation\nis not limited to large-N flows, but may represent any basis tensor in the fundamental representation\nby the following identification: Each non-zero entry in the first entry of a pair in a colour flow vector\nidentifies an index transforming according to the anti-fundamental, each entry at the second position an\nindex transforming according to the fundamental representation of SU (N ) and entries of the same id are\nattached to a Kronecker-\u03b4. Thus, the 1/N suppressed singlet contribution to a gluon (cf. the Fierz identity\nfor the fundamental representation generators) carries the pair {k, k}, where k is not zero. Example:\n \u0304 which would be identified by the processid {\u221211, 11, 1, \u22121, 21}.\nConsider the process e+ e\u2212 \u2192 ddg,\ni\ni\nHere two colour flows are possible, the leading part \u03b4jidg \u03b4jg \u0304, and the 1/N suppressed \u03b4jid \u0304\u03b4jgg contribution.\nd\nd\nThe first one would be identified by the colourflow {{0, 0}, {0, 0}, {k1 , 0}, {0, k2 }, {k2 , k1 }}, the latter\nby {{0, 0}, {0, 0}, {k1 , 0}, {0, k1 }, {k2 , k2 }}, where k1 6= k2 are non-zero, positive integers.\n3.3\n\nSPECIFICATION OF THE INTERFACE\n\nInitialization and Bookkeeping\nbool initialize () \u2013 The fixed-order code performs initialization and reads any relevant parameters from\nits preferred input mechanism. It returns true on success and false on failure.\npair<int,string> alphasinfo () \u2013 Return information on the running of the strong coupling to be used\nas a combination of the number of loops contributing to the QCD \u03b2-function, and a string identifying the\nrenormalization scheme used. Values for the latter have to be agreed on.\nbool haveleadingorder (processid) \u2013 Return true, if the process identified by the given processid can\nbe calculated at leading order.\nvector<colourflow> colourflows (processid) \u2013 Return the possible colourflows which could be\nselected for the given processid.\nvector<colourflow> largencolourflows (processid) \u2013 Return the possible colourflows in the large-N\nlimit which could be selected for the given processid.\nbool haveoneloop (processid) \u2013 Return true, if one loop QCD corrections to the given process can be\ncalculated.\nstring havesubtraction (processid) \u2013 Return a non-empty string identifying a subtraction scheme,\nif real emission subtraction terms are available for the given process. This does not require that the real\nemission process itself can be calculated. Return an empty string, if subtraction terms are not present.\n16\n\n\fOther return values have to be agreed on.\nvector<processid> realemissions (processid) \u2013 Assuming the given processid identifies a Born\nprocess, return the real emission processes to be considered for a NLO QCD correction.\nvector<int> subtractions (processid) \u2013 Assuming the given processid identifies a real emission\nprocess, return a list of ids for the subtraction terms to be considered. The ids need to be unique to the\nfixed-order code and are not used except for identifying a subtraction term. For dynamically allocated\nvectors, the function may return an empty vector to indicate that the process considered is non-singular,\nfor fixed-size vectors it should indicate this by filling the vector with zeroes.\nprocessid underlyingborn (processid, int) \u2013 Given a real emission process id and subtraction term\nid through the first and second arguments, respectively, return the underlying Born process the subtraction\nterm maps to.\nvector<pair<int,int> > collinearlimits (processid, int) \u2013 Given a real emission process id and\nsubtraction term id through the first and second arguments, respectively, return the positions of the partons\nin the processid given, for which the identified subtraction term subtracts collinear singularities. The\nordering of the returned value entries is irrelevant and by convention fixed such that the first entry is less\nthan the second.\n\nKinematics and Phase Space\nint ndim (processid) \u2013 Return the number of random numbers needed to generate a phase space point\nfor the given process.\npspoint phasespace (pair<momentum,momentum>, vector<double>, processid) \u2013 Generate a\nphase space point given incoming particle's momenta, a list of random numbers \u2208]0, 1[ and a process id.\n\nDynamics\nEach function call defined here represents the associated contribution F \u03b1 to differential cross section as\ndefined in eq. 1. Results are assumed to be scaled by the appropriate power of GeV such as to return a\ndimensionless quantity.\ndouble me2 (processid, pspoint, double) \u2013 Return the helicity and colour summed matrix element\nsquared for the given process, phase space point and value of the renormalization scale in GeV.\ndouble partialme2 (processid, pspoint, double, colourflow) \u2013 Return the helicity summed partial\namplitude squared, identified by the given colour flow, evaluated for the given process, phase space point\nand value of the renormalization scale in GeV.\ndouble bornvirt (processid, pspoint, double) \u2013 Return the helicity and colour summed Bornvirtual interference plus the integrated subtraction terms (i.e. the finite part remaining after carrying out\nsubtraction), consistent with the subtraction scheme chosen for the real emissions. Arguments in order are\nthe process to be considered, the phase space point and the renormalization scale in GeV.\ndouble collinear (processid, pspoint, double, double, pair<double,double>) \u2013 Return the finite\ncollinear remainder contribution consistent with the subtraction scheme chosen for the process identified\nby the given processid and phase space point. Further arguments in order are renormalization and\nfactorization scales in units of GeV, and two further random variables on the unit interval to perform\nMonte Carlo integration over convolutions present.\ndouble subtraction (processid, int, pspoint, double) \u2013 Return the subtraction term identified by real\nemission process and subtraction term id, given a phase space point and renormalization scale in units of\nGeV.\n\n17\n\n\fCONCLUSIONS\nA general runtime interface has been outlined to access the individual building blocks of a next-to-leading\norder (NLO) QCD calculation carried out within the subtraction formalism.\nSuch an interface is an indispensable tool for 'client' programs dedicated to the matching of parton\nshowers and higher order corrections. A subset of the interface may as well be used to implement so-called\nmatrix element corrections within parton shower Monte Carlos, correcting the hardest shower emission to\nthe exact real emission matrix element squared.\nACKNOWLEDGEMENTS\nI would like to thank Stephen Mrenna, Peter Skands, Leif L\u00f6nnblad and Nicolas Greiner for many fruitful\ndiscussions and encouraging comments.\n\n18\n\n\fSTATUS OF THE FLAVOUR LES HOUCHES ACCORD9\n\n4.\n4.1\n\nINTRODUCTION\n\nIn addition to the increasing number of refined approaches in the literature for calculating flavour-related\nobservables, advanced programs dedicated to the calculation of such quantities, e.g. Wilson coefficients,\nbranching ratios, mixing amplitudes, renormalisation group equation (RGE) running including flavour\neffects have recently been developed [27\u201331]. Flavour-related observables are also implemented by many\nother non-dedicated public codes to provide additional checks for the models under investigation [32\u201338].\nThe results are often subsequently used by other codes, e.g. as constraints on the parameter space of the\nmodel under consideration [39\u201342].\nAt present, a small number of specialised interfaces exist between the various codes. Such tailor-made\ninterfaces are not easily generalised and are time-consuming to construct and test for each specific\nimplementation. A universal interface would clearly be an advantage here. A similar problem arose some\ntime ago in the context of Supersymmetry (SUSY). The solution took the form of the SUSY Les Houches\nAccord (SLHA) [43, 44], which is nowadays frequently used to exchange information between SUSY\nrelated codes, such as soft SUSY-breaking parameters, particle masses and mixings, branching ratios etc.\nThe SLHA is a robust solution, allowing information to be exchanged between different codes via ASCII\nfiles. The detailed structure of these input and output files is described in Refs. [43, 44].\nThe goal of this work is to exploit the existing organisational structure of the SLHA and use it to define\nan accord for the exchange of flavour related quantities, which we refer to as the \"Flavour Les Houches\nAccord\" (FLHA). In brief, the purpose of this Accord is thus to present a set of generic definitions for an\ninput/output file structure which provides a universal framework for interfacing flavour-related programs.\nFurthermore, the standardised format will provide the users with a clear and well-structured result that\ncould eventually be used for other purposes.\nThe structure is set up in such a way that the SLHA and the FLHA can be used together or independently.\nObviously, some of the SLHA entries, such as measured parameters in the Standard Model (SM) and the\nCabibbo-Kobayashi-Maskawa (CKM) matrix elements are also needed for flavour observable calculations.\nTherefore, a FLHA file can indeed contain a SLHA block if necessary. Also, in order to avoid any\nconfusion, the SLHA blocks are not modified or redefined in the FLHA. If a block needs to be extended\nto meet the requirements of flavour physics, a new \"F\" block is defined instead.\nNote that different codes may technically achieve the FLHA input/output in different ways. The details\nof how to 'switch on' the FLHA input/output for a particular program should be described in the manual\nof that program and are not covered here. For the SLHA, libraries have been developed to permit an\neasy implementation of the input/output routines [45]. In principle these programs could be extended to\ninclude the FLHA as well.\nIt should be noted that, while the SLHA was developed especially for the case of SUSY, the FLHA is,\nat least in principle, model independent. While it is possible to indicate the model used in a specific block,\nthe general structure for the information exchange can be applied to any model.\nThis report summarizes the current status of the FLHA. Several issues are not defined in an unambigous\nway yet. This will be indicated in the text below.\n4.2\n\nCONVENTIONS AND DEFINITIONS\n\nThe structure of the Flavour Les Houches Accord input and output files is based on the existing SUSY\nLes Houches Accord structure and flavour quantities are defined in blocks. The general conventions for\nthe blocks are very similar to the SLHA blocks [43] and they are not reproduced here.\nSince a FLHA file can also contain SLHA blocks, to clearly identify the blocks of the FLHA, the first\n9\n\nContributed by: F. Mahmoudi, S. Heinemeyer, A. Arbey, A. Bharucha, T. Goto, T. Hahn, U. Haisch, S. Kraml, M. Muhlleitner,\nJ. Reuter, P. Skands, P. Slavich\n\n19\n\n\fletter of the name of a block is an \"F\". There are two exceptions to this rule: blocks borrowed from the\nSLHA, which keep their original name, and blocks containing imaginary parts, which start with \"IMF\".\nThe following general structure for the FLHA file is proposed:\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nsation.\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\nBLOCK\n\nFCINFO: Information about the flavour code used to prepare the FLHA file.\nFMODSEL: Information about the underlying model used for the calculations.\nSMINPUTS: Measured values of SM parameters used for the calculations.\nVCKMIN: Input parameters of the CKM matrix in the Wolfenstein parameterisation.\nUPMNSIN: Input parameters of the PMNS neutrino mixing matrix in the PDG parameteriVCKM: Real part of the CKM matrix elements.\nIMVCKM: Imaginary part of the CKM matrix elements.\nUPMNS: Real part of the PMNS matrix elements.\nIMUPMNS: Imaginary part of the PMNS matrix elements.\nFMASS: Masses of quarks, mesons, hadrons, etc.\nFLIFE: Lifetime (in seconds) of flavour-related mesons, hadrons, etc.\nFCONST: Decay constants.\nFCONSTRATIO: Ratios of decay constants.\nFBAG: Bag parameters.\nFWCOEF: Real part of the Wilson coefficients.\nIMFWCOEF: Imaginary part of the Wilson coefficients.\nFOBS: Prediction of flavour observables.\nFOBSERR: Theory error on the prediction of flavour observables.\nFOBSSM: SM prediction for flavour observables.\nFFORM: Form factors.\n\nMore details on several blocks are given in the following. The blocks SMINPUTS, VCKMIN, UPMNSIN,\nVCKM, IMVCKM, UPMNS, IMUPMNS are defined exactly as in the SLHA(2) and not further discussed\nhere.\nBLOCK FCINFO\nFlavour code information, including the name and the version of the program:\n1 : Name of the flavour calculator\n2 : Version number of the flavour calculator\nOptional warning or error messages can also be specified:\n3 : If this entry is present, warning(s) were produced by the flavour calculator.\nThe resulting file may still be used. The entry should contain a description\nof the problem (string).\n4 : If this entry is present, error(s) were produced by the flavour calculator. The resulting file should not be used. The entry should contain a\ndescription of the problem (string).\nThis block is purely informative, and is similar to BLOCK SPINFO in the SLHA.\nBLOCK MODSEL\nThis block provides switches and options for the model selection. The SLHA2 BLOCK MODSEL is\nextended to allow more flexibility.\n20\n\n\f1 : Choice of SUSY breaking model or indication of other model. By\ndefault, a minimal type of model will always be assumed. Possible\nvalues are:\n-1 : SM\n0 : General MSSM simulation\n1 : (m)SUGRA model\n2 : (m)GMSB model\n3 : (m)AMSB model\n4 : ...\n31 : THDM\n99 : other model. This choice requires a string given in the entry 99\n3 : (Default=0) Choice of particle content, only used for SUSY models. The\ndefined switches are:\n0 : MSSM\n1 : NMSSM\n2 : ...\n4 : (Default=0) R-parity violation. Switches defined are:\n0 : R-parity conserved. This corresponds to the SLHA1.\n1 : R-parity violated.\n5 : (Default=0) CP violation. Switches defined are:\n0 : CP is conserved. No information on the CKM phase is used.\n1 : CP is violated, but only by the standard CKM phase. All other phases\nare assumed zero.\n2 : CP is violated. Completely general CP phases allowed.\n6 : (Default=0) Flavour violation. Switches defined are:\n0 : No flavour violation.\n1 : Quark flavour is violated.\n2 : Lepton flavour is violated.\n3 : Lepton and quark flavour is violated.\n31 : defines the type of THDM, is used only if entry 1 is given as 31,\notherwise it is ignored.\n1 : type I\n2 : type II\n3 : type III\n4 : type IV\n99 : a string that defines other models is used only if entry 1 is given as 99,\notherwise it is ignored.\n\n21\n\n\fBLOCK FMASS\nThe block BLOCK FMASS contains the mass spectrum for the involved particles. It is an addition to the\nSLHA BLOCK MASS which contained only pole masses and to the SLHA BLOCK SMINPUTS which\ncontains quark masses. If a mass is given in two blocks the block FMASS overrules the other blocks. In\nFMASS we specify additional information concerning the renormalisation scheme as well as the scale at\nwhich the masses are given and thus allow for larger flexibility. The standard for each line in the block\nshould correspond to the following FORTRAN format\n(1x,I9,3x,1P,E16.8,0P,3x,I2,3x,1P,E16.8,0P,3x,'#',1x,A),\nwhere the first nine-digit integer should be the PDG code of a particle, followed by a double precision\nnumber for its mass. The next integer corresponds to the renormalisation scheme, and finally the last\ndouble precision number points to the energy scale (0 if not relevant). An additional comment can be\ngiven after #.\nThe schemes are defined as follows:\n0 : pole\n1 : MS\n2 : DR\n3 : 1S\n4 : kin\n5 : ...\n\nBLOCK FLIFE\nThe block BLOCK FLIFE contains the lifetimes of mesons and hadrons in seconds. The standard for\neach line in the block should correspond to the FORTRAN format\n(1x,I9,3x,1P,E16.8,0P,3x,'#',1x,A),\nwhere the first nine-digit integer should be the PDG code of a particle and the double precision number its\nlifetime.\nBLOCK FCONST\nThe block BLOCK FCONST contains the decay constants in GeV. The standard for each line in the block\nshould correspond to the FORTRAN format\n(1x,I9,3x,I2,3x,1P,E16.8,0P,3x,'#',1x,A),\nwhere the first nine-digit integer should be the PDG code of a particle, the second integer the number of\nthe decay constant, and the double precision number its decay constant.\nBLOCK FCONSTRATIO\nThe block BLOCK FCONSTRATIO contains the ratios of decay constants, which often have less uncertainty than the decay constants themselves. The ratios are specified by the two PDG codes in the form\nf(code1)/f(code2). The standard for each line in the block should correspond to the FORTRAN format\n(1x,I9,3x,I9,3x,I2,3x,I2,3x,1P,E16.8,0P,3x,'#',1x,A),\nwhere the two nine-digit integers should be the two PDG codes of particles, the third and fourth integers the\nnumbers of the decay constants, which correspond to the second index of the entry in BLOCK FCONST,\nand the double precision number the ratio of the decay constants.\n22\n\n\fBLOCK FBAG\nThe block BLOCK FBAG contains the bag parameters. The standard for each line in the block should\ncorrespond to the FORTRAN format\n(1x,I9,3x,I2,3x,1P,E16.8,0P,3x,'#',1x,A),\nwhere the first nine-digit integer should be the PDG code of a particle, the second integer the number of\nthe bag parameter, and the double precision number its bag parameter.\nSo far no normalisation etc. has been defined, which at this stage has to be taken care of by the user. An\nunambiguous definition will be given elsewhere.\nBLOCK FWCOEF Q= ...\nThe block BLOCK FWCOEF Q= ... contains the real part of the Wilson coefficients at the scale Q.\n(k)\n\nThe different orders Ci\nperturbative expansion:\n\nhave to be given separately according to the following convention for the\n\n\u0012\n\u0013\n\u03b1s (\u03bc) (1)\n\u03b1s (\u03bc) 2 (2)\nCi (\u03bc) =\n+\nCi,s (\u03bc) +\nCi,s (\u03bc)\n4\u03c0\n4\u03c0\n\u03b1(\u03bc) (1)\n\u03b1(\u03bc) \u03b1s (\u03bc) (2)\n+\nC (\u03bc) +\nCi,es (\u03bc) + * * * .\n4\u03c0 i,e\n4\u03c0 4\u03c0\n(0)\nCi (\u03bc)\n\n(5)\n\nThe couplings should therefore not be included in the Wilson coefficients.\nThe entries in BLOCK FWCOEF should consist of two integers defining the fermion structure of the\noperator and the operator structure itself. These two numbers are not thought to give a full representation\nincluding normalisation etc. of the operator, but merely correspond to a unique identifier for any possible\nWilson coefficient. Consequently, the user has to take care that a consistent normalisation including\nprefactors etc. is indeed fulfilled. As an example, for the operator O1 ,\nO1 = (s\u0304\u03b3\u03bc T a PL c)(c\u0304\u03b3 \u03bc T a PL b)\n\n(6)\n\nthe definition of the two numbers is given as follows. The appearing fermions are encoded by a two-digit\nnumber originating from their PDG code, where no difference is made between particles and antiparticles,\nas given in Table 1. Correspondingly, the first integer number defining O1 , containing the fermions s\u0304cc\u0304b,\nis given by 03040405. The various operators are defined in Table 2. Correspondingly, the second integer\nnumber defining O1 , containing the operators \u03b3\u03bc T a PL \u03b3 \u03bc T a PL is given by 6161.\nA few more rules are needed for an unambigous definition.\n\u2022 If an operators appears without fermions (as it is possible, e.g., for F\u03bc\u03bd ) it should appear right-most,\nso that the encoded fermions correspond to the left-most operators.\n\u2022 In the case of a possible ambiguity, for instance O1 = (s\u0304\u03b3\u03bc T a PL c)(c\u0304\u03b3 \u03bc T a PL b) corresponding to\n03040405 6161 and O1 = (c\u0304\u03b3\u03bc T a PL b)(s\u0304\u03b3 \u03bc T a PL c) corresponding to 04050304 6161 the \"smaller\"\nnumber, i.e. in this case 03040405 6161 should be used.\nThe third index corresponds to each term in Eq. (5):\n(0)\n\n00 : Ci (\u03bc)\n(1)\n\n01 : Ci,s (\u03bc)\n(2)\n\n02 : Ci,s (\u03bc)\n(1)\n\n10 : Ci,e (\u03bc)\n(2)\n\n11 : Ci,es (\u03bc)\n23\n\n\fname\nd\nu\ns\nc\nb\nPt\nq\nP q\nqQ\nq\nq\n\nPDG code\n1\n2\n3\n4\n5\n6\n\ntwo-digit number\n01\n02\n03\n04\n05\n06\n07\n08\n\nname\ne\n\u03bde\n\u03bc\n\u03bd\u03bc\n\u03c4\n\u03bd\u03c4\nP\nl\nP l\nlQ\nl\nl\n\nPDG code\n11\n12\n13\n14\n15\n16\n\ntwo-digit number\n11\n12\n13\n14\n15\n16\n17\n18\n\nTable 1: PDG codes and two-digit number identifications of quarks and leptons. The summations are\nover active fermions.\n\noperator\n1\nPL\nPR\n\u03b3\u03bc\n\u03b35\n\u03c3 \u03bc\u03bd\n\u03b3\u03bc\u03b3\u03bd \u03b3\u03c1\n\u03b3 \u03bc \u03b35\n\u03b3 \u03bc PL\n\u03b3 \u03bc PR\n\u03c3 \u03bc\u03bd PL\n\u03c3 \u03bc\u03bd PR\n\u03bc\n\u03b3 \u03b3 \u03bd \u03b3 \u03c1 PL\n\u03b3 \u03bc \u03b3 \u03bd \u03b3 \u03c1 PR\nF\u03bc\u03bd\n\nnumber\n30\n31\n32\n33\n34\n35\n36\n37\n41\n42\n43\n44\n45\n46\n22\n\noperator\nTa\nPL T a\nPR T a\n\u03b3\u03bcT a\n\u03b35 T a\n\u03c3 \u03bc\u03bd T a\n\u03b3\u03bc\u03b3\u03bd \u03b3\u03c1T a\n\u03b3 \u03bc \u03b35 T a\n\u03b3 \u03bc T a PL\n\u03b3 \u03bc T a PR\n\u03c3 \u03bc\u03bd T a PL\n\u03c3 \u03bc\u03bd T a PR\n\u03bc\n\u03b3 \u03b3 \u03bd \u03b3 \u03c1 T a PL\n\u03b3 \u03bc \u03b3 \u03bd \u03b3 \u03c1 T a PR\nGa\u03bc\u03bd\n\nnumber\n50\n51\n52\n53\n54\n55\n56\n57\n61\n62\n63\n64\n65\n66\n21\n\noperator\n\u03b4ij\nPl \u03b4ij\nPR \u03b4ij\n\u03b3 \u03bc \u03b4ij\n\u03b35 \u03b4ij\n\u03c3 \u03bc\u03bd \u03b4ij\n\u03b3 \u03bc \u03b3 \u03bd \u03b3 \u03c1 \u03b4ij\n\u03b3 \u03bc \u03b35 \u03b4ij\n\u03b3 \u03bc \u03b4ij PL\n\u03b3 \u03bc \u03b4ij PR\n\u03c3 \u03bc\u03bd \u03b4ij PL\n\u03c3 \u03bc\u03bd \u03b4ij PR\n\u03bc\n\u03b3 \u03b3 \u03bd \u03b3 \u03c1 \u03b4ij PL\n\u03b3 \u03bc \u03b3 \u03bd \u03b3 \u03c1 \u03b4ij PR\n\nnumber\n70\n71\n72\n73\n74\n75\n76\n77\n81\n82\n83\n84\n85\n86\n\nTable 2: Two-digit number definitions for the operators. T a (a = 1 . . . 8) denote the SU (3)C generators,\nPL,R = 12 (1 \u2213 \u03b35 ), and (T a )ij (T a )kl = 12 (\u03b4il \u03b4kj \u2212 1/Nc \u03b4ij \u03b4kl ), where i, j, k, l are colour indices.\n\n99 : total\nThe information about the order is given by a two-digit number xy, where x indicates O(\u03b1x ) and y\n(0)\nindicates O(\u03b1sy ), and 0 indicates Ci .\n\nThe Wilson coefficients can be provided either via separate new physics and SM contributions, or as a\ntotal contribution of both new physics and SM, depending on the code generating them. To avoid any\nconfusion, the fourth entry must specify whether the given Wilson coefficients correspond to the SM\ncontributions, new physics contributions or to the sum of them, using the following definitions:\n0 : SM\n1 : NPM\n2 : SM+NPM\nThe new Physics model is the model specified in the BLOCK FMODSEL.\nThe standard for each line in the block should thus correspond to the FORTRAN format\n\n24\n\n\f(1x,I8,1x,I4,3x,I2,3x,I1,3x,1P,E16.8,0P,3x,'#',1x,A),\nwhere the eight-digit integer specifies the fermion content, the four-digit integer the operator structure,\nthe two-digit integer the order at which the Wilson coefficients are calculated followed by the one-digit\ninteger specifying the model, and finally the double precision number gives the real part of the Wilson\ncoefficient.\nNote that there can be several such blocks for different scales Q.\nBLOCK IMFWCOEF Q= ...\nThe block BLOCK IMFWCOEF contains the imaginary part of the Wilson coefficients at the scale Q. The\nstructure is exactly the same as for the BLOCK FWCOEF.\nBLOCK FOBS\nThe block BLOCK FOBS contains the flavour observables. The structure of this block is based on the\ndecay table in SLHA format. The decay is defined by the PDG number of the parent, the type of the\nobservable, the value of the observable, the number of daughters and PDG IDs of the daughters.\nThe types of the observables are defined as follows:\n1 : Branching ratio\n2 : Ratio of the branching ratio to the SM value\n3 : Asymmetry \u2013 CP\n4 : Asymmetry \u2013 isospin\n5 : Asymmetry \u2013 forward-backward\n6 : Asymmetry \u2013 lepton-flavour\n7 : Mixing\n8 : ...\nThe standard for each line in the block should correspond to the FORTRAN format\n(1x,I9,3x,I2,3x,1P,E16.8,0P,3x,I1,3x,I9,3x,I9,3x,...,3x,'#',1x,A),\nwhere the first nine-digit integer should be the PDG code of the parent decaying particle, the second\ninteger the type of the observable, the double precision number the value of the observable, the next\ninteger the number of daughters, and the following nine-digit integers the PDG codes of the daughters. It\nis strongly advised to give the descriptive name of the observable as comment.\nBLOCK FOBSERR\nThe block BLOCK FOBSERR contains the theoretical error for flavour observables, with the structure\nsimilar to BLOCK FOBS, where the double precision number for the value of the observable is replaced\nby two double precision numbers for the minus and plus uncertainties.\nIn a similar way, for every block, a corresponding error block with the name BLOCK FnameERR can\nbe defined.\nBLOCK FOBSSM\nThe block BLOCK FOBSSM contains the SM values of the flavour observables in the same format as in\nBLOCK FOBS. The given SM values may be very helpful as a comparison reference.\n\n25\n\n\fBLOCK FFORM\nThe block BLOCK FFORM contains the form factors for a specific decay. This decay should be defined as\nin BLOCK FOBS, but replacing the type of the observable by the number of the form factor. It is essential\nhere to describe the variable in the comment area. The dependence on q 2 can be specified as a comment.\nA more unambiguous definition will be given elsewhere.\n4.3\n\nCONCLUSION\n\nThe interplay of collider and flavour physics is entering a new era with the start-up of the LHC. In the\nfuture more and more programs will be interfaced in order to exploit maximal information from both\ncollider and flavour data. Towards this end, an accord will play a crucial role. The accord presented\nspecifies a unique set of conventions in ASCII file format for most commonly investigated flavour-related\nobservables and provides a universal framework for interfacing different programs.\nThe number of flavour related codes is growing constantly, while the connection between results from\nflavour physics and high pT physics becomes more relevant to disentangle the underlying physics model.\nUsing the lessons learnt from the SLHA, we hope the FLHA will prove useful for studies related to flavour\nphysics. It is planned to update/correct the FLHA after more experience with its application will have\nbeen gathered.\nACKNOWLEDGEMENTS\nThe work of S.H. was partially supported by CICYT (grant FPA 2007\u201366387). Work supported in part by\nthe European Community's Marie-Curie Research Training Network under contract MRTN-CT-2006035505 'Tools and Precision Calculations for Physics Discoveries at Colliders'. The work of T.G. is\nsupported in part by the Grant-in-Aid for Science Research, Japan Society for the Promotion of Science,\nNo. 20244037.\n\n26\n\n\fPart II\n\nTUNING\nSTATUS OF RIVET AND PROFESSOR MC VALIDATION & TUNING TOOLS 10\n\n5.\n\nThe Rivet [46] package for MC generator validation and the Professor [47] system for generator tuning have\nbecome established tools for systematically verifying event simulations and optimising their parameters,\nwhere required and physically sensible. In this short report, we summarise the status and development of\nthese tools.\n5.1\n\nRivet\n\nRivet is an MC validation tool: it encodes MC equivalents of an increasingly comprehensive set of HEP\ncollider analyses which are useful for testing the physics of MC generators. Rivet does not itself produce\ntunings, but provides a standard set of analyses by which to verify the accuracy of a given generator with\na given tuning.\nSeveral fundamental design principles have been derived from the experience on Rivet's predecessor\nsystem, HZTool [48, 49], and from iteration of the Rivet design:\n\u2022 No generator steering: Rivet relies entirely on being provided, by unspecified means, with events\nrepresented by the HepMC [50] event record.\n\u2022 No generator-specific analyses: all Rivet analyses are specifically not allowed to use the generatorspecific portions of the supplied event records. Apart from a few limited (and deprecated) exceptions,\nall analyses are based solely on physical observables, i.e. those constructed from stable particles\n(those with status 1) and physical decayed particles (those with status 2).\n\u2022 Rivet can be used either as a C++ library to be interfaced with generator author or experiment\nanalysis frameworks, or as a command line tool (which itself makes use of the library interface).\nThis is an example of the general philosophy to keep things simple and flexible, since we do not a\npriori know every task to which our tools will be employed.\nInternally, Rivet analyses are based on a comprehensive set of calculational tools called projections,\nwhich perform standard computations such as jet algorithms (using FastJet [51]), event shape tensors, and\na variety of other standard tasks. Use of projections makes analysis code much simpler, encapsulates\nany complexities arising from the ban on use of event record internal entities (the summation of photon\nmomenta around charged leptons during Z-finding is a good example, see Section 14.), and is more\nefficient than just using library functions, due to a complex (but hidden) system of automatic result\ncaching.\nUsers can write their own analyses using the Rivet components and use them via the Rivet API or\ncommand-line tool without re-compiling Rivet, due to use of an analysis \"plugin\" system. Separation\nbetween generator and Rivet on the command-line is most simply achieved by using the HepMC plain text\nIO GenEvent format via a UNIX pipe (a.k.a. FIFO): this avoids disk access and writing of large files,\nand the CPU penalty in converting event objects to and from a text stream is in many cases outweighed by\nthe general-purpose convenience. For generator-specific use of Rivet, the programmatic interface allows\nHepMC objects to be passed directly in code, without this computational detour. A sister tool, AGILe [52],\nis provided for convenience control of several Fortran-based generators, with command-line and parameter\nfile based run-time steering of generator parameters. This is a convenient tool when exploring generator\nparameter space as part of a tuning.\nReference data for the standard analyses is included in the Rivet package as a set of XML files in the\nAIDA format. After several years of re-development as part of the CEDAR [52] project, the HepData [53]\n10\n\nContributed by: A. Buckley, J. M. Butterworth, H. Hoeth, H. Lacker, J. Monk, H. Schulz, J. E. von Seggern, F. Siegert\n\n27\n\n\fdatabase of HEP experimental results can be used to directly export data files usable by Rivet from its\nWeb interface at http://hepdata.cedar.ac.uk/. Analysis histograms are directly booked using\nthe reference data as a binning template, ensuring that data and MC histograms are always maximally\nconsistent.\nRivet is in use within the MC generator development community, particularly in general-purpose shower\nMC programs, and the LHC experimental community, for MC validation and MC analysis studies which\ndo not require detector simulation.\n5.11\n\nRecent developments\n\nRivet 1.1.3 was released during the first week of this Les Houches workshop, in June 2009: this release\nincludes many new analyses and fixes to existing analyses. Since the workshop, a huge number of extra\nimprovements and developments have taken place in the run-up to the 1.2.0 release. Aside from many\ntechnical improvements, and the addition of a large number of QCD analyses (primarily for minimum\nbias and multi-jet physics) the major conceptual developments have been an emphasis on automated\ntesting and validation of Rivet code, and the removal of hard-coded cross-section normalisations whenever\npossible. This latter step required more development than may be expected, due to the separation of\ngenerator and analysis: the HepMC record had to be enhanced to store cross-section information in a\nway which can be passed to Rivet. This has now been done, and recent versions of major generators such\nas Herwig++ [19, 21], Sherpa [22, 23], and Pythia 8 [20], support this HepMC feature \"out of the box\".\nAGILe's generator interfaces have also been updated to write cross-section information into their HepMC\noutput. Determining scaling K-factors where required is now performed via post-processing scripts,\nwhich automatically support common approaches to constraining this remaining degree of freedom.\nA technical development, but one worth mentioning, has been the emphasis on making Rivet analyses\n\"self-documenting\": each analysis has a structured set of metadata specifying name, authors, run conditions,\na description, etc., which is used to provide interactive help, HTML documentation, and a reference\nsection in the Rivet manual.\nAt the time of writing, the final stage of systematic validation of Rivet for the 1.2.0 release is underway.\nThe validation scripts used for this checking will henceforth be included in automatic build tests, to ensure\nthat future developments do not unexpectedly change existing analysis functionality. The final major\nstage of development is the upgrade of Rivet's histogramming and data analysis code, which is currently\nrather basic. The upgrade will enable statistically accurate combination of runs, allowing for greater\nparallelisation of Rivet analyses which require large event statistics.\n5.2\n\nProfessor\n\nThe Professor system builds on the output of MC validation analyses such as those in Rivet, by optimising\ngenerator parameters to achieve the best possible fit to reference data. The main description of Professor's\ndetails is found in reference [47], and we will not significantly replicate it here, except in the most\nhigh-level sense.\nFundamentally, generator tuning is an example of the more general problem of optimising a very\nexpensive function with many parameters: the volume of the space grows exponentially with the number\nof parameters and the CPU requirements of even a single evaluation of the function means that any attempt\nto scan the parameter space will fail for more than a few parameters. Here, the expensive function is\nrunning a generator with a particular parameter set to recreate a wide range of analysis observables, using\na package such as Rivet. The approach adopted by Professor is to parameterise the expensive function\nbased on a non-exhaustive scan of the space: it is therefore an approximate method, but its accuracy is\nsystematically verifiable and it is currently the best approach that we have.\nThe parameterisation is generated by independently fitting a function to each of the observable bin\nvalues, approximating how they vary in response to changes in the parameter vector. One approach to\n28\n\n\ffitting the functions would be to make each function a linear combination of algebraic terms with n\ncoefficients \u03b1i , then to sample n points in the parameter space. A matrix inversion would then fix the\nvalues of \u03b1i . However, use of a pseudoinverse for rectangular matrices allows a more robust coefficient\ndefinition with many more samples than are required, with an automatic least-squares fit to each of the\nsampled \"anchor points\": this is the method used by Professor. By aggregating the parameterisations of\nall the observable bins under a weighted goodness of fit measure \u2013 usually a heuristic \u03c72 \u2013 a numerical\noptimisation can be used to create an \"optimal\" tune. In practice, many different semi-independent\ncombinations of MC runs are used to provide a systematic handle on the degree of variation expected in\ntunes as a result of the inputs, avoiding the problem that a single \"maximum-information\" tune may not\nbe typical of the parameter space.\nThe first application of Professor, due to its popularity and fairly well-understood steering parameters,\nwas the Pythia 6 MC generator [18]. This was tuned in reference [47], using both of the available parton\nshower and multi-parton interaction (MPI) models, to data from LEP, SLD, and Tevatron Runs I and II. It\nwas found that the parameterisation method worked well in all cases, and a range of systematic methods\nand tools were developed to check the accuracy of the approximations, such as line-scans through the\nparameter space. It was found that a sensible maximum number of parameters to be included in a single\ntune was \u223c 10, and hence, there being \u223c 20 Pythia 6 parameters relevant to the studied observables,\nwe separated the tune into an initial stage of final state shower and fragmentation tuning using e+ e\u2212\nobservables, and then a second stage based on tuning initial state parton shower and MPI parameters to\nbest describe hadron collider data. In these tunes, a quadratic parameterisation was used throughout, this\nbeing the simplest suitable function to account for parameter correlations.\n5.21\n\nRecent developments\n\nThe main development since the initial publication and use of Professor has been the application to more\nMC tunings. A first extra application was to use the same \u03c72 weightings as for the Pythia 6 tune to obtain\nadditional tunings of Pythia 6 with different PDFs. The results of this study, shown at the PDF4LHC\nmeeting in April 2009, indicated that modified leading order PDFs, developed for use with LO MC\ngenerators and characterised by a larger than normal low-x gluon component, drive statistical generator\ntunings in a physically expected direction: the main effect was to increase the screening of MPI effects\nproportional to the size of the gluon PDF at low x values.\nMoving away from Pythia 6, substantial tuning effort has been expended with the Jimmy [54, 55] MPI\nsimulation (used with the Fortran Herwig 6 code [17]), and the Pythia 8 and Sherpa generators. In the case\nof Pythia 8, the default fragmentation settings are now those fixed by Professor, and use of Professor has\nidentified a problem with description of underlying event (UE) observables in QCD events: this problem\nis being addressed. An extremely useful tool in this study was the prof-I GUI, which makes use of the\nProfessor parameterisations not for minimisation, but for interactive mimicking of generator responses to\nparameter changes: this tool makes exploration of speculative tuning ideas easily testable, and helped to\nverify that no combination of parameters would achieve the desired effect in Pythia 8's description of UE\nobservables.\nAnother major effort has been the use of Professor to tune and develop the Sherpa generator's simulation\nof hadronisation and soft initial-state QCD physics. This collaboration has helped to rapidly iterate model\nimprovements and debugging, due to the fast turnaround of tune information.\nProfessor is additionally being used within the ATLAS, CMS, and LHCb LHC experimental collaborations for tuning studies of the main generators used for their MC simulation, and in plans for re-tuning to\nfirst LHC data at new centre of mass energies.\nDevelopment of the Professor framework and application to different implications of tuning continues:\nthe next contribution details how ensembles of tunes created by Professor may be used for estimations of\ntune uncertainties in MC predictions. Other suggested extensions to optimisation of observable definitions\n\n29\n\n\for parameterisation of other expensive functions, e.g. observables in SUSY parameter space, remain open\nto exploration.\nAcknowledgements\nThe Rivet and Professor collaborations acknowledge support from the EU MCnet Marie Curie Research\nTraining Network (funded under Framework Programme 6 contract MRTN-CT-2006-035606) for financial\nsupport and for many useful discussions and collaborations with its members. A. Buckley additionally\nacknowledges support from the Scottish Universities Physics Alliance (SUPA); H. Schulz acknowledges\nthe support of the German Research Foundation (DFG).\n\n30\n\n\fQUANTITATIVE ERROR ESTIMATION IN MC TUNES 11\n\n6.\n\nRecent developments in Monte Carlo generator tuning have led to more robust and general-purpose\n\"optimal\" tunes to existing data, and there is a clear hope that when existing data is well-described,\nextrapolations to future collider energies will also be reliable. However, especially in the area of soft QCD,\ngenerator predictions are never expected to be exactly accurate: there is no single \"best\" tune for a given\nmodel, but rather one or more regions of parameter space which contains reasonable tunes. The size of\nthese regions reflects the degree of constraint which existing data is able to place on the model \u2013 discrete\nchoices of model are also crucial to obtain a true sense of the total uncertainty on any generator prediction.\nIn this contribution we present studies of how the mechanisms used for systematic generator tuning can be\nused to quantitively estimate the contributions to the uncertainty of MC predictions from several sources.\nA key example of generator uncertainty is the extrapolation of minimum bias and underlying event\n\u221a\nQCD physics to LHC design energies, i.e. s \u001d 2 TeV. The physics that drives the rise in activity is a\ncombination of the non-perturbative total pp cross-section; the non-perturbative physics of beam remnants,\ndiffraction, and multiple partonic scattering; and perturbative low-pT QCD scattering. Accordingly, the\nmost-used models are highly phenomenological and have many tweakable parameters: one interesting\nconsequence of first LHC data in the multi-TeV energy regime will be the testing of whether these models\nextrapolate in agreement with nature. The expectation is that some models will fail the test!\nPrevious studies of prediction uncertainty have been necessarily qualitative and subjective, since MC\ntunes have themselves been somewhat approximate affairs. The most common approach to assigning a\nsystematic uncertainty has been to compare predictions from two different models, such as Pythia and\nPhojet in the case of Minimum Bias/Underlying Event extrapolation. Discrete choices of model remain\na major source of uncertainty, even when the range of historic Pythia tunes with a Tevatron-excluded\nenergy extrapolation is excluded12 \u2013 we encourage all extrapolated studies to make use of as many distinct\n(non-excluded) models as possible. In this contribution, however, we describe how to quantitively assess\nmajor sources of uncertainty arising from the tuning process itself, i.e. the reasonable scatter to be\nexpected around a tune for a discrete model. Our baseline for this approach is the Professor tuning system,\nwhich we now summarise.\n6.1\n\nMC tuning with Professor\n\nThe \"Professor\" approach to MC tuning constitutes both a numerical method and a suite of tools which\nimplement it. Fundamentally, Professor attempts to parameterise expensive functions \u2013 the bin values\nin a set of MC observables \u2013 by least-squares fitting of the parameterisation coefficients. The leastsquares minimisation is made more approachable by use of the pseudoinverse method, implemented via\na matrix singular value decomposition. Armed with a fast analytic model of how every bin of a large\nset of observables will respond to variations of the generator parameters, numerical optimisation of the\ngenerator's fit to reference data may be efficiently computed. A detailed description may be found in\nreference [47].\nThe benefit of this approach is clear for more than two parameters: Professor requires as input the values\nof observables for a moderately large number of MC runs distributed suitably in the generator parameter\nspace, each point in the space perhaps requiring O(48) CPU hours to complete. A serial optimisation\napproach such as Markov chain sampling would hence require thousands of CPU days to have a chance\nof converging, if the generator itself is not batch-parallelised. Professor, given sufficiently large batch\ncomputing resources, can trivially parallelise the generation of the input MC points for any generator and\nthereafter complete the parameterisation and fit optimisation in negligible time, allowing for scaling to\nhigher numbers of tune parameters than could be attempted by methods which require iteration of the\n11\n\nContributed by: A. Buckley, H. Hoeth, H. Lacker, H. Schulz, J. E. von Seggern\nThis includes the default Pythia tune, the ATLAS MC08 tune, and (by construction) the Tune *T series from Rick Field.\nEssentially, any setup with PARP(90) < 0.2 is in contradiction with Tevatron data.\n12\n\n31\n\n\f6.0\n\n6.0\n\n6.0\n\n5.8\n\n5.8\n\n5.6\n\n5.6\n\n5.4\n\n5.4\n\n5.2\n\n5.2\n\n5.2\n\n5.0\n\n5.0\n\n5.0\n\n4.8\n\n4.8\n\n4.8\n\n4.6\n\n4.6\n\n4.6\n\n4.4\n\n4.4\n\nNruns = 194 (quadratic)\nNruns = 393 (quadratic)\nNruns = 393 (cubic)\nFull information run\nSampling boundaries\n\n5.8\n5.6\n\u03c72 /Ndf\n\n5.4\n\n0.1\n\n0.2\n\n0.3\nPARP(78)\n\n0.4\n\n0.5\n\n0.16 0.18 0.20 0.22 0.24 0.26 0.28 0.30\nPARP(90)\n\n4.4\n\n2\n\n4\n\n6\nPARP(93)\n\n8\n\n10\n\nFig. 5: A scatter plot of \u03c72 vs. parameter value for a set of Professor run combinations on three Pythia6\nparameters. Implicitly, this projection of tune parameter vectors on to parameter axes gives a qualitative\nmeasure of whether or not a parameter is well-constrained: these parameters become increasingly illdefined from left to right. The different markers represent different degrees of oversampling, with the star\nrepresenting the maximum information run - the points are for the same run combinations in all three\nscatter plots.\ntime-limiting step.\n6.2\n\nQualitative error estimation in Professor\n\nAn important feature of the Professor method is that it has always allowed for qualitative assessment of the\ntune robustness. A per-bin parameterisation in p parameters will require a minimum number of MC runs,\n(p)\nNmin , for the least-squares pseudoinversion to be performed. For robustness it is advisable to oversample\nthis minimum requirement by a factor O(3) (or more, especially for large p) such that a tune will in fact\n(p)\nuse N \u001d Nmin input runs. Additionally, since the parameterisation and optimisation steps are fast, we\ntake the opportunity to make many such overconstrained tunes by in fact sampling an even greater number\nof runs, Nsampled \u001d N . We can then randomly sample a large number of mostly-independent N -run tunes\nto obtain an ensemble of reasonable tunes \u2013 again, this step can be trivially batch-parallelised. The spread\nof this tune ensemble as projected on each parameter has been used in several Professor MC tunes as a\nheuristic for determining whether a parameter is well or poorly constrained, for detecting parameterisation\nproblems, and for ensuring that the \"maximum information\" tune is typical of the ensemble. Several other\nchecking methods, such as eigenvector line scans, are also used to ensure that the details of the tune, and\nparticularly the generator parameterisation, are reliable.\nTo make a prediction of an observable for which there is no reference data (this may be an energy\nextrapolation, or simply an unmeasured feature at existing energies), the simplest approach is of course to\nrun the generator with the obtained tune(s) and compute the observable. Using the many tunes resulting\nfrom the different run combinations will give a spread in the observable prediction, reflecting one part of\ntune uncertainty. In practice, since we can build a fast parameterisation of the generator behaviour (in\nfact many of them) on the unfitted observable as part of the main Professor tuning process, this offers a\nmuch faster turnaround than processing another large (perhaps very large) set of generator runs \u2013 with the\nproviso that the parameterisations are of course non-exact.\n6.3\n\nSources of tune uncertainty\n\nBefore making this method more quantitive, we now consider the various sources of uncertainty in the\nprocedure outlined so far. This will help us to understand which sources of uncertainty are computationally\ncontrollable and which will have to, for now, remain more nebulous. These main sources of tuning error\nare as follows:\n1. Error on experimental reference data.\n32\n\n\f2. Statistical error on the MC at the anchor points from which the parameterisation is constructed.\n3. Systematic limitations of the parameterising function to describe bin responses to parameter\nvariations \u2013 pathological MC parameters with discontinuous or critical behaviour are particularly\nhard to generically parameterise, since a Jacobian transformation to a suitable meta-parameter is\nnot always easily available.\n4. Choice of run combinations to make the parameterisation.\n5. Goodness of fit definition, including both the type of GoF measure and the choice and relative\nweighting of different data.\n6. Reasonable minimiser scatter within the \u03c72 valley containing the optimal tune point for a given\nparameterisation. Note that this cannot be completely disentangled from the role that error sources\n1, 2 and 3 play in defining the \u03c72 valley.\n7. Limitations of the parameterisation(s) used to compute the parameterised MC value in extrapolated/unfitted observables. Of course, this error doesn't exist if the less convenient strategy of\nre-running the MC generator is used.\n8. For completeness, we again highlight the systematic error associated with the discrete physics model\nbeing tuned: the total error is far from complete without considering more than one viable model.\nWithin a given model there are also systematic uncertainties, some of which may be quantified, e.g.\ncross-section integration uncertainty and PDFs: the second of these is particularly quantifiable due\nto the existence of error or replica PDF sets, themselves expressing reasonable variations in PDF\nfitting.\nNote that, for example, these sources of uncertainty such as the variation between members of the\nensemble of run combinations are not unique errors introduced by the Professor approach: failing to test\ndifferent run combinations does not eliminate the error associated with the choice of anchor runs used! A\nsimilar, but unquantifiable, error exists for any form of manual tuning.\n6.4\n\nConstruction of tune uncertainty confidence belts\n\nOur approach to quantifying the uncertainties from (combinations of) the sources listed in the previous\nsection is to construct central confidence belts for observable bins from the various ensembles of tune\nresults, parameterisations, etc. we have described. Explicitly, given a large number of reasonable and\nequivalent predictions for an observable bin value, we construct a band of given P -value as being the\nregion containing fraction P of predictions, with equal fractions above and below.\nThere are many ways to construct such ensembles \u2013 for the purposes of this study we identify three:\nCombination error: The ensemble from which we construct the confidence belt is simply the ensemble\nof predictions from different run combinations. This will hence represent the variation due to error\nsources 1, 2, and 4 \u2013 the other sources of uncertainty exist, but are not quantified by this approach13 .This\napproach requires that correlations between different run combinations are small, which is ensured by the\nNsampled \u001d N requirement.If parameterisation (as opposed to explicit MC runs) is used for the translation\nof this tune ensemble into bin value predictions, then source 7 also applies. This can be included into the\nband construction by using many parameterisations, again constructed from run combinations. Different\nparameterisations should be used for minimisation and prediction to avoid reinforcing parameterisation\nsystematics.\nStatistical error: The obvious failure of the combination error approach is that error source 6 \u2013 the\nmeasure of reasonable tune variation within the \u03c72 valley \u2013 is left unquantified. Hence it will be no\n13\nMC error is currently not explicitly propagated into Professor's fit measure, due to stability problems: it enters implicitly via\nthe statistical scatter of MC samples. This is being remedied.\n\n33\n\n\fp2\n\n\u03c32\n\nptune\n1\n\nptune\n1\n\n\u03c31\n\np1\n\nFig. 6: Two dimensional illustration of the parameter point\nsampling used for the statistical uncertainty estimate. We\nexploit the covariance matrix returned by the minimiser for\na Gaussian sampling from the corresponding p-dimensional\nhyper-ellipsoid. The \u03c3i (i = 1 . . . p) are the eigenvalues obtained from an eigen-decomposition of the covariance matrix.\n\nsurprise that our \"statistical\" error band is constructed explicitly from an ensemble of samples from this\nvalley. This is obtained in the simplest case by only using the maximum information Professor tune \u2013\nthat which is constructed from all the available MC runs. The covariance matrix of the parameters in the\nvicinity of the tune point is obtained \u2013 in principle directly from the parameterisation, in practice from the\nminimiser \u2013 and used to define a rotated hyper-Gaussian probability distribution in the parameter space.\nSampling parameter points from this distribution gives us another ensemble of tune points and, as for the\ncombination error, they can be mapped into observable predictions either by direct MC runs or by using\none or many constructed parameterisations. In practice, we take advantage of the combined potential\nof the hyper-Gaussian sampling and MC parameterisation to build a confidence belt from O(10, 000)\nsamples. The quantified sources of error are hence 1, 2, 6, and 7.\nThese approaches to error band building will be used in the next section to construct sample error bands\nfor underlying event predictions. Although not currently implemented in Professor, we also highlight the\nmost complete form of quantifiable error band within the Professor approach:\nCombined error: This extension is an obvious fusion of the above two ensemble/band constructions:\nas in the combination error, we construct an ensemble of points from run combinations, then for each\nrun-combination point we construct a statistical ensemble. The combined ensemble of tune ensembles,\nand a variety of parameterisations to transform them into predictions will lead to error bands quantifying\nerror sources 1, 2, 4, 6, and 7.\nThe remaining error sources are 3, 5 and 8: limitations of the parameterisation, the observable\nweights/goodness of fit definition, and \u2013 most importantly \u2013 the uncertainty due to different physics\nmodels. These missing systematics remain qualitative in this scheme, and reliable MC predictions should\ntake care to include estimates of their influence, albeit in a more ad hoc fashion than for the more\nstatistically-induced errors.\n6.5\n\nResults\n\nWe now briefly present results using the first two confidence belt definitions presented above \u2013 ongoing\nwork is addressing the \"combined\" belt definition and inclusion of PDF uncertainties.\nOur exploration is based on tunes of the Jimmy [54, 55] MC generator, which simulates multiple\nparton interactions (MPI) for Herwig 6 [17], because it has only two relevant parameters, PTJIM and\nJMRAD(73)14 \u2013 the frugality with parameters makes Jimmy an ideal \"toy model\" testbed, while remaining\nphenomenologically relevant. As a Jimmy-like MPI model is ruled out by Tevatron data [56], we fix a\ndependence of PTJIM on the centre of mass energy with the same ansatz as used in Pythia 6 [18]:\n\u0012\nPTJIM = PTJIM1800 *\n14\n\n\u221a\n\ns\n1800 GeV\n\n\u0013 0.274\n,\n\n(7)\n\nWe treat the inverse radius-squared of the protons, JMRAD(73), to be identical to that of the anti-protons, JMRAD(91), and\nignore the interplay with ISR parameters in Herwig 6 itself.\n\n34\n\n\fTransverse region charged particle density\n\nh ptrack\n\u22a5 i /GeV\n\nh ptrack\n\u22a5 i /GeV\n\n1\n\n0.8\n\n1\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\nCL=95%\nCL=68%\n\n0.2\n0\n\n0\n\n2\n\n4\n\n6\n\n0\n\n8\n10\np\u22a5 (leading track)/GeV\n\nh ptrack\n\u22a5 i /GeV\n\nh ptrack\n\u22a5 i /GeV\n\n0\n\n2\n\n4\n\n6\n\n8\n10\np\u22a5 (leading track)/GeV\n\n(b) Statistical uncertainty, data and pseudodata\n\nTransverse region charged particle density\n\n0.8\n\n1\n\nTransverse region charged particle density\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\nCL=95%\nCL=68%\n\n0.2\n0\n\nCL=95%\nCL=68%\nJimmy pseudodata, 1M events\n\n0.2\n\n(a) Statistical uncertainty, data only\n1\n\nTransverse region charged particle density\n\n0\n\n2\n\n4\n\n6\n\nCL=95%\nCL=68%\nJimmy pseudodata, 1M events\n\n0.2\n0\n\n8\n10\np\u22a5 (leading track)/GeV\n\n(c) Combination uncertainty, data only\n\n0\n\n2\n\n4\n\n6\n\n8\n10\np\u22a5 (leading track)/GeV\n\n(d) Combination uncertainty, data and pseudodata\n\nFig. 7: \"Statistical\" and \"combination\" error bands for transverse Nch flow at 7 TeV before and after\nadding 1M events of pseudodata of this observable (black markers) to the tuning. The error bands are\ncalculated from the central 95 (68)% of the binvalues of an ensemble of 10000 histograms each.\n\u221a\nwhere PTJIM1800 is the value of PTJIM at the reference scale s = 1800 GeV and is the p\u22a5min parameter\nactually used in the tuning process. Furthermore, we use the MRST LO* PDF set [57] and use Tevatron\ndata from CDF [58\u201360] and D\u00d8 [61] as a tuning reference. A more complete tune would include the\nexponent of the p\u22a5min energy dependence, but for toy-study purposes we here fix it to a value consistent\nwith known energy extrapolation fits [47, 62].\nIn Figures 7(a) and 7(c), the statistical and combination error band definitions are shown for a 7 TeV\nunderlying event observable \u2013 Nch flow transverse to the leading track (track with the largest transverse\nmomentum in an event), as a function of leading track pT \u2013 computed in Rivet [46], based on the fit\nto Tevatron reference data. The error due to variation of run combinations (error source 4) is notably\nsomewhat larger than the scatter of points in the \u03c72 valley (error source 6), indicating that in the Jimmy\nmodel the parameters have a strong influence on this observable, and are hence well-constrained. In\nFigures 7(b) and 7(d), similar band constructions are shown, but in this case the same Rivet analysis has\nbeen used to simulate the effect of adding 1M events of UE data at 7 TeV into the fit: the size of both\nerror bands is reduced, as expected.\n6.51\n\nEffect of extrapolation\n\nFinally, we consider systematically how error bands constructed in this way behave as extrapolations are\ntaken further from the region of constraining data. In this case, since the computational requirements are\nsignificant, we only consider the \"statistical\" error band.\nWe use the transverse region Nch density UE observable, evaluated at a range of ten centre of mass\n\u221a\nenergies, si , between 200 GeVand 14 TeV. We then apply the following procedure,\n35\n\n\fHeight of plateau in transverse charged particle density\n2.5\n\nhhNch /d\u03b7d\u03c6ii\n\nhNch /d\u03b7 d\u03c6i\n\nTransverse region charged particle density\nCDF Run II (pp\u0304)\n\u221a\nJimmy (pp), Professor tune, s = 7TeV\nb\n\n2\n\n1.5\n\nCL=95%\nerrors enlarged 10\u00d7 for visibility\n\n2\n\n1.5\nLHC\n\n1\n\n1\nb\nb\n\nb\n\nb\n\n0.5\n\nb\nb\n\nb\n\nb\nb\n\nb\n\nb\n\nb\nb\n\nb\nb\n\n0.5\nb\n\nb\n\nb\nb\n\nRHIC pp\n\n0\n\n20\n\n40\n\n60\n\n0\n10 2\n\n80\n100\npT (leading jet) / GeV\n\n(a) Nch vs. p\u22a5lead , plateau\n\nb\nb\n\nb\nb\n\nb\n\nTevatron\n\nb\n\n0\n\nb\n\n10 3\n\n4\n10\n\u221a\ns / GeV\n\n(b) Nch vs. p\u22a5lead , mean of plateau vs.\n\n\u221a\ns\n\nFig. 8: Transverse region charged particle density. (a): the typical plateau observed and (b): mean-height\n\u221a\nof that plateau as a function of s.\n\u221a\n\ns/TeV\n\np\u22a5lead, min /GeV\np\u22a5lead, max /GeV\n\n0.2\n\n0.63\n\n0.9\n\n1.8\n\n1.96\n\n2.36\n\n5.0\n\n7.0\n\n10.0\n\n14.0\n\n10\n30\n\n30\n70\n\n30\n80\n\n30\n80\n\n40\n90\n\n40\n110\n\n40\n110\n\n40\n120\n\n40\n150\n\n40\n160\n\nTable 3: Definition of plateau regions (p\u22a5lead ) used in the extrapolation study.\n\n\u2022 Construct the maximum-information parameterisation of the generator response for the Nch UE\n\u221a\nobservable, f ( si )\n\u2022 Produce an ensemble of 10000 histograms, Hi , of the observable shown in Figure 8(a) (blue line)\n\u221a\nusing the corresponding f ( si ) and points sampled using the procedure illustrated in Figure 6\n\u2022 Calculate the mean height of the Nch plateau, Mi , for each of the Hi\n\u221a\n\u2022 Construct a 95% central confidence belt, CL( si ) from the Mi\n\u221a\nIn Figure 8(b) the CL( si ) are drawn. We observe a very tight confidence belt for the energy region of\nthe Tevatron experiments, while the confidence belt becomes wider for extrapolation to LHC energies.\nThe definitions of the plateau regions used can be found in Table 3.\nIt is notable that these bands are narrow \u2013 sufficiently so that they have been visually inflated by a factor\nof 10 in the figure. While this reflects good stability in the tuning system, it is probably an underestimate\nof the true model uncertainty. A more complete study will include the exponent of energy extrapolation in\nequation (7) in the tune, since this may be a dominant effect in the errors for this particular observable\nand its inclusion will give more freedom for various features of the model to balance against each other:\nthe toy tuning of the energy-dependent Jimmy model shown here is probably too restrictive to accurately\nrepresent the full range of variation allowed by the model, but serves as an indication of the extent to\nwhich such studies can be systematised.\n6.6\n\nConclusions\n\nWe have catalogued a set of sources of uncertainty which either explicitly or implicitly contribute to\nany tune of a MC event generator, and presented a systematic approach to quantifying many of these\nuncertainties using the fast MC parameterisations and natural tune ensembles which arise from the\nProfessor tuning approach. Example results have been shown, which exhibit some expected behaviours,\nsuch as the shrinking of error bands on adding new reference data in new areas of parameter space and the\n36\n\nb\n\nb\n\n\fblow-up of error bands as predictions venture further into unconstrained regions.\nSeveral things should be emphasised: first and most important is that this approach does not catch\nall sources of error. We have presented results from two definitions and have proposed a third, more\ncomprehensive measure, but still variations such as PDF errors and discrete model variations need to be\nincluded. However, with the increased usage of systematic tuning methods, variations between models in\nUE observables are not as substantial as once they were \u2013 statistical errors are a non-negligible factor in\nassessing the reliability of phenomenologically-based MC predictions.\nThe approach taken here has many obvious parallels in the world of PDF errors, with our approach\nhaving a good deal of overlap with the MC replica set approach of the NNPDF collaboration [63] as\ncontrasted with the eigenset approach of the CTEQ and MRST/MSTW collaborations. While replica\nsets have the advantage of a more direct statistical uncertainty interpretation (although we do not have\nthe option of the parameterisation-freedom exibited by the NNPDF use of neural networks), there is the\npragmatic issue that O(10) representative error tunes would be more usable than O(10000) equivalent\ntunes. Whether such a concept can be statistically constructed remains to be seen \u2013 for now the Perugiasoft/hard tunes remain the obvious tool of choice.\nAcknowledgements\nOur particular thanks goes to Luigi del Debbio and Richard Ball for discussions about statistical coverage\nand MC error estimation. The Professor collaboration acknowledges support from the EU MCnet Marie\nCurie Research Training Network (funded under Framework Programme 6 contract MRTN-CT-2006035606) for financial support and for many useful discussions and collaborations with its members.\nA. Buckley additionally acknowledges support from the Scottish Universities Physics Alliance (SUPA);\nH. Schulz acknowledges the support of the German Research Foundation (DFG).\n\n37\n\n\f7.\n\nMATRIX ELEMENT CORRECTIONS AND PARTON SHOWER MATCHING IN INCLUSIVE Z PRODUCTION AT LHC15\n\n7.1\n\nINTRODUCTION\n\nIn this paper we compare Pythia 6 [18], AlpGen [64] and Sherpa [23, 65] in inclusive Z production\nat LHC, with 10 TeV center of mass energy. A disagreement in various observables, especially the Z\ntransverse momentum, pT , between AlpGen and Pythia 6 was recently reported in [66]. Namely, the\nshape in the low Z pT region was significantly different when comparing AlpGen showered with Pythia 6\nand matrix element corrected Pythia 6. This was traced back to a change in shape in Pythia 6 when matrix\nelement corrections are switched off (this setup is used when showering AlpGen events, because higher\nmultiplicity AlpGen samples already provide higher order corrections). This is summarized by the Z pT\nplot shown in Fig. 9. A bug in Pythia 6 causing this behavior was later corrected; here we present results\nobtained with the new version of Pythia 6.\nWe also compare different Pythia 6 tunes, checking both the virtuality ordered and the newer transverse\nmomentum ordered shower.\nUsing Pythia 6 as a reference we check the performances of the matching in AlpGen and Sherpa. Since\nPythia 6 is fully corrected for first order real emission, we expect agreement with AlpGen and Sherpa\nwhen those are configured to include matrix elements for Z plus up to one additional parton.\nResults presented in this work are obtained using Pythia 6 versions 6.411 and 6.421 (the last contains the\nbug fix for the matrix element corrections problem), AlpGen 2.13 and Sherpa 1.2.0.\n7.2\n\nANALYSIS SETUP\n\nAll generators have been processed through the same analysis, selecting events with a Z with mass between\n66 GeV and 116 GeV, requiring the two leptons to have pT greater than 20 GeV and pseudorapidity\nbetween -2.5 and 2.5. Jets are reconstructed with the k\u22a5 algorithm, with a radius of 0.4 and a minimum\npT of 30 GeV. In order to decouple effects due to multiple interactions, hadronization and QED radiation\noff leptons, these have been switched off for all the generators used.\nThe analyses were carried out using Rivet (see Section 5.).\n15\n\nContributed by: P. Lenzi, P. Skands\n\nFig. 9: Z transverse momentum spectrum for Pythia 6 (corrected and uncorrected) and for AlpGen plus\nPythia 6 as in [66]. AlpGen plus Pythia 6 follows uncorrected Pythia 6 at low pT . The change in shape of\nuncorrected with respect to corrected Pythia 6 was responsible for the disagreement.\n\n38\n\n\f7.3\n\nMATRIX ELEMENT CORRECTIONS IN PYTHIA\n\nMatrix element corrections in Pythia 6 are described in detail in [18]. Here we just remind the basics of the\nprocedure. Pythia 6 modifies the shower in two steps: first the starting scale is raised to the hadronic center\nof mass energy (power shower configuration) so that any hard emission from the shower is kinematically\npossible; then the probability for the first emission (which is also the hardest in Pythia 6) is re-weighted to\ninclude the first order real emission contribution. The reweighting factor is calculated as the ratio between\nthe exact real emission matrix element and the splitting function used in the shower.\nThe effect of matrix element corrections in Pythia 6.411 is summarized in Fig. 10 for Z transverse\nmomentum spectrum. The three curves are obtained with full matrix element corrections, with power\nshower only, and with uncorrected shower with starting scale at the Z mass. The relative difference\nwith respect to the ME corrected result is shown in the lower plot. The shape of the spectrum changes\nsignificantly when matrix element corrections are switched off, even at low pT (the relative difference plot\ndoes not flatten as pT goes to 0). This is unexpected, as the matrix element effect is supposed to go to zero\nat low pT , where the description from the shower is already accurate. In fact, the splitting function used in\nthe shower is the approximation for pT \u2192 0 of the of the exact matrix element for emission of one parton,\nso no difference between the two descriptions is expected in that region.The effect of matrix element\ncorrections is illustrated in Fig. 11 for the newer 6.421 version of Pythia 6. The same collection of curves\nas for version 6.411 is shown. With the newer version the deactivation of matrix element corrections has a\nvery small effect at low pT , as expected. A bug was found and corrected between the two versions which\nwas causing the behavior observed in the earlier version.\n7.4\n\nPYTHIA TUNES\n\nWe compared various tunes in Pythia 6.421 on the basis of three observables, the Z transverse momentum,\nthe jet multiplicity and the leading jet transverse momentum. In all of our comparisons we switched off\nthe multiple interactions simulation, which means that we are comparing the effect of different tunings on\nthe hard event simulation and on the shower.\n\nPythia 6.411\n\n40\n\nME corrected\n\n10\n\nUncorrected, Power shower\n\n35\n\nUncorrected\n\nT\n\nd\u03c3/dp\n(Z) [pb/GeV]\nd\u03c3/dp (Z)\n[pb/GeV]\nT\n\nWe compared the following tunes: DW [67], D6T [67], Pro-Q0 [68], Perugia0 [69]. The virtuality\n\n301\n25\n10-1\n\n20\n15\n\n10-2\n\n10\n0.60\n\n0.4\n0.2\n50\n-0.2\n-0.4\n-0.6\n0\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n20\n20\n\n40\n40\n\n60\n60\n\n80\n80\n\n100\n100\n\n120\n120\n\n140\n140\np [GeV]\nT\n\nFig. 10: Z transverse momentum spectrum for three different matrix element correction settings in\nPythia 6.411: with matrix element corrections, with power shower only, without matrix element corrections.\nThe relative difference with respect to the matrix element corrected curve is shown in the lower plot.\n\n39\n\n\fd\u03c3/dp\n(Z) [pb/GeV]\nd\u03c3/dp (Z)\n[pb/GeV]\nT\n\nPythia 6.421\n\n40\n\nME corrected\n\n10\n\nUncorrected, Power shower\n\n35\n\nT\n\nUncorrected\n\n301\n25\n10-1\n\n20\n15\n\n10-2\n\n10\n0.60\n\n0.4\n0.2\n50\n-0.2\n-0.4\n-0.6\n0\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n20\n20\n\n40\n40\n\n60\n60\n\n80\n80\n\n100\n100\n\n120\n120\n\n140\n140\np [GeV]\nT\n\nFig. 11: Z transverse momentum spectrum for three different matrix element correction settings in\nPythia 6.421: in this new version, deactivating matrix element corrections has a small effect at low pT , as\nexpected.\n\nordered shower is used in the first three, while the last uses the pT ordered shower.\n\nDW\nD6T\nPro-Q0\nPerugia0\n\n10\n\nT\n\nd\u03c3/dp (Z) [pb/GeV]\n\nZ transverse momentum spectra obtained with the four mentioned settings are shown in Fig. 12.\nThe agreement is generally good, tune DW and D6T agree fairly well on the whole spectrum; some\n\n1\n\n10-1\n\n0.40\n0.3\n0.2\n0.1\n0\n-0.1\n-0.2\n-0.3\n-0.4\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\np [GeV]\nT\n\nFig. 12: Z transverse momentum spectrum for different Pythia 6 tunes. Relative difference is shown with\nrespect to tune DW.\n\ndiscrepancies are observed in the low pT region: both tune Perugia0 and tune Pro-Q0 differ from Tune\nDW, and they also differ from each other. The disagreement with respect to tune DW is up to 20%.\nJet multiplicity and leading jet transverse momentum spectrum are shown in Fig. 13. The jet multiplicity\n40\n\n\f1\n\n1/ \u03c3 d\u03c3/dp [1/GeV]\n\nDW\nD6T\nPro-Q0\nPerugia0\n\n-1\n\n10\n\nDW\nD6T\nPro-Q0\nPerugia0\n\nT\n\n1/ \u03c3 d\u03c3/d n jets\n\nfor Tune Perugia0 shows some not negligible differences with respect to the other tunes, predicting more\njets. On the other hand Tune DW, D6T and Pro-Q20 predict very similar rates. Concerning the leading jet\npT spectrum in Fig. 13 (b), the shape predicted by the four tunes is very similar.\n\n10-2\n\n10-2\n\n10-3\n10-3\n10-4\n\n10-5\n\n1\n0.5\n0\n-0.5\n\n10-4\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n0.4\n0.3\n0.2\n0.1\n0\n-0.1\n-0.2\n-0.3\n-0.4\n\n9\n\n-1\n9\nn jets\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n200\n\n200\np [GeV]\nT\n\n(a)\n\n(b)\n\nFig. 13: (a) Jet multiplicity, (b) leading jet pT spectrum for four Pythia 6 tunes. Relative difference is\nshown with respect to Tune DW.\n\n7.5\n\nPythia 6, Sherpa, AlpGen COMPARED\n\nIn this section we compare Pythia 6 (including full matrix element corrections) with AlpGen and Sherpa.\nWe used Pythia 6 version 6.421, both standalone and to shower AlpGen events. Also, we used tune DW\nfor Pythia 6.\nWe used matrix element corrected Pythia 6 as a reference for a consistency check of the matching\nprescriptions used in AlpGen and Sherpa. Both the CKKW [4] prescription used in Sherpa and MLM\nprescription used AlpGen [64, 70] can describe multiple parton emission corrected for the corresponding\nmulti-parton matrix element. If just one additional parton emission from the matrix element is permitted,\nthose prescriptions should give results compatible with Pythia 6.\nWhile CKKW and MLM divide the phase space in a region of jet production, populated by the matrix\nelement, and a region of jet evolution populated by the shower, the matrix element correction prescription\nimplemented in Pythia 6 does not depend on any separation parameter, thus providing us with the \"correct\"\nreference to test the other matched calculations.\nThe comparison among the three generators is shown in Fig. 14 for the Z transverse momentum. The\nagreement in shape is generally good, well within 20% with respect to Pythia 6 for most of the spectrum.\nIn particular, the mismatch between AlpGen and Pythia 6 observed in [66] is practically gone with the\nnewer version of Pythia 6. This is an important result also because it establishes the re-usability of Pythia 6\ntunes between standalone Pythia 6 and AlpGen plus Pythia 6 shower.\nJet multiplicity and leading jet pT spectra are shown in Fig. 15. In (a) both AlpGen and Sherpa appear\nto have a longer tail for high jet multiplicity. Concerning the leading jet pT spectrum in (b), Sherpa\nfollows Pythia 6 all over the spectrum, AlpGen appears so have a harder tail for high pT .\nDifferential jet rates for the 1\u21920, 2\u21921 and 3\u21922 transitions are shown in Fig. 16. Differential jet\nrates for the transition n \u2192 n \u2212 1 are the distributions of the kT resolution parameter in an exclusive\nkT algorithm, Qn\u2192n\u22121 , that makes an n jet event turn into an n \u2212 1 jet event. AlpGen and Pythia 6 are\nsimilar, while Sherpa's shape shows some not negligible differences. Sherpa uses a dipole shower, while\nPythia 6 uses a virtuality ordered shower (the same shower is also used with AlpGen). The source of the\ndifference is likely in the different shower, which fills the phase space with a different pattern.\n\n41\n\n\f1/ \u03c3 d\u03c3/dp [1/GeV]\n\n10-1\n\nPythia tune DW\n\nT\n\nSherpa 1.2.0\nAlpgen+Pythia\n\n10-2\n\n10-3\n\n10-4\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\np [GeV]\n\n0.2\n0.1\n0\n-0.1\n-0.2\n\nT\n\n1/ \u03c3 d\u03c3/dp [1/GeV]\n\nPythia tune DW\n\n1\n\nSherpa 1.2.0\n\n10-1\n\nPythia tune DW\nSherpa 1.2.0\n\nT\n\n1/ \u03c3 d\u03c3/d n jets\n\nFig. 14: Z transverse momentum spectrum for Pythia 6, Sherpa and AlpGen. The agreement is within\n20%.\n\nAlpgen+Pythia\n10-2\n\nAlpgen+Pythia\n\n10-2\n\n10-3\n10-3\n10-4\n\n10-5\n\n0.6\n0.4\n0.2\n0\n-0.2\n-0.4\n-0.6\n\n10-4\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n0.4\n0.2\n0\n-0.2\n-0.4\n\n9\nn jets\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n200\n\n200\np [GeV]\nT\n\n(a)\n\n(b)\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\nlog (Q\n10\n\n(a)\n\n3.5\n/GeV)\n\n0.80.5\n0.6\n0.4\n0.2\n0\n-0.2\n-0.4\n-0.6\n-0.8\n0.5\n\n/GeV)\n3 \u21922\n\nAlpgen+Pythia\n\n10-3\n\n10-4\n\n10-4\n\nSherpa 1.2.0\n10-1\n\n10-2\n\n10-3\n\n10-3\n\nPythia tune DW\n\n1\n\n10\n\nAlpgen+Pythia\n\n10-1\n\n10-2\n\n10-2\n\n0.80.5\n0.6\n0.4\n0.2\n0\n-0.2\n-0.4\n-0.6\n-0.8\n0.5\n\nSherpa 1.2.0\n\n10\n\n1/ \u03c3 d\u03c3/dlog (Q\n\nAlpgen+Pythia\n\n10\n\nPythia tune DW\n\n1\n\n1/ \u03c3 d\u03c3/dlog (Q\n\n1\u21920\n10\n\n1/ \u03c3 d\u03c3/dlog (Q\n\nSherpa 1.2.0\n-1\n\n/GeV)\n\nPythia tune DW\n\n1\n\n2 \u21921\n\n/GeV)\n\nFig. 15: (a) Jet multiplicity, (b) leading jet pT spectrum.\n\n10-4\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\nlog (Q\n\n1\u21920\n\n3.5\n\n10\n\n3.5\n/GeV)\n\n0.80.5\n0.6\n0.4\n0.2\n0\n-0.2\n-0.4\n-0.6\n-0.8\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\nlog (Q\n\n2\u21921\n\n(b)\n\n3.5\n\n10\n\n3.5\n/GeV)\n\n3\u21922\n\n(c)\n\nFig. 16: Differential jet rates: (a) 1\u21920, (b) 2\u21921, (c) 3\u21922.\n7.6\n\nCONCLUSION\n\nWe studied matrix element corrections in Pythia 6 for inclusive Z production at the LHC and we compared\nPythia 6, AlpGen and Sherpa on the ground of first order real emission corrections. A bug was recently\n\n42\n\n\fdiscovered and corrected in inclusive vector boson production in Pythia 6, that made the effect of matrix\nelement corrections very big also at low boson pT . We compared two versions of Pythia 6, before and\nafter the fix, and observed that the low boson momentum region is correctly described in the new version,\nthe matrix element corrected and uncorrected shower being similar in that region as expected.\nWe compared four different Pythia 6 tunes. For all of them we switched off the multiple interactions\nin order to observe the effect of the tune on the shower and on the hard event simulation. Generally\ngood agreement was observed, with some differences especially in the low Z pT region and in the jet\nmultiplicity spectrum.\nWe showed various plots comparing Pythia 6, AlpGen and Sherpa. Differences between AlpGen plus\nPythia 6 and matrix element corrected Pythia 6 observed in [66] were due to the bug affecting Pythia 6,\nand are now much reduced. This also assesses the re-usability of Pythia 6 tunes when Pythia 6 is used to\nshower AlpGen events.\n7.7\n\nPARAMETERS AND SETTINGS\n\nIn Pythia 6, the underlying event was switched off with MSTP(81)=0 (MSTP(81)=20 for the tune\nPerugia0, that uses the pT ordered shower). Matrix element corrections were controlled with the parameter\nMSTP(68): this was set to =0 to switch off matrix element corrections and to set the staring scale to the\nZ mass, to =2 for the power shower without matrix element corrections. The default had matrix element\ncorrections enabled. Hadronization was switched off with MSTJ(1)=0. The various tunes were selected\nby acting on parameter MSTP(5).\nAlpGen samples were produced with a minimum parton pT of 20 GeV. We used the default parameters\nfor Sherpa, with no underlying event, no fragmentation, no QED radiation off leptons.\n\n43\n\n\fPart III\n\nBEYOND FIXED ORDER\n8.\n\nMULTIPLE PARTON INTERACTIONS AS A BACKGROUND TO TOP PAIR PRODUCTION 16\n\n8.1\n\nINTRODUCTION\n\nThe occurrence of Multiple Parton Interactions (MPI) in hadronic collisions is by now well established\nexperimentally [71\u201374]. Furthermore, they represent the basic mechanism in the description of the\nUnderlying Event (UE) in the standard Showering Monte Carlo's (MC) like Pythia 6 [69, 75, 76] and\nHerwig [54, 77]. MPI rates at the LHC are expected to be large, making it necessary to estimate their\ncontribution to the background of interesting physics reactions. On the other hand, their abundance makes\nit possible to study MPI experimentally in details, testing and validating their implementation in the MC.\n\u221a\nIn this note we discuss the role of MPI in top-antitop production at s = 10 TeV. The LHC will\nbe a top-antitop factory and the large rate will allow accurate measurements of the top mass, one the\nmost crucial parameters for stringent tests of the SM, and production cross section. It will therefore be\nof extreme importance to have full control over all potential background processes. In this study we\ncompare the results obtained with Pythia 8 [20] with those obtained at parton level with the methods of\nRefs. [78, 79] which suggested that MPI could provide a significant background to top-antitop production\nand to other interesting processes like W + 4j and Z + 4j production.\n8.2\n\nSETUP\n\nIf no b\u2013tagging is assumed, the MPI processes which provide a background to t t\u0304 and more generally\ncontribute to W + 4j through Double Parton Interactions (DPI) are:\njj \u2297 jjW , jjj \u2297 jW , jjjj \u2297 W\n\n(8)\n\nwhere the symbol \u2297 stands for the combination of one event for each of the two final states it connects.\n\nBesides in W decay, isolated high\u2013pT leptons can also be produced in the decay of heavy quarks.\nTherefore any reaction in which heavy quarks plus jets are produced can fake the signature of a W boson.\nKeeping in mind the large QCD cross-section for bb production, heavy quark and QCD DPI processes\ndeserve attention as possible backgrounds to top pair production. This corresponds to the following extra\nprocesses:\nbb \u2297 jj , bbj \u2297 jj\n\n(9)\n\nIn this study we have decided to use Pythia 8 for simulating DPI events. Pythia 8 allows to use external\nLes Houches Accord [3] input for the hardest process, and to choose an internal one for the second\nhardest, being however limited to 2 \u2192 2 processes. This set-up allows a precise study of dedicated DPI\nconfigurations.\nMoreover we have generated a number of samples, most notably W + 2j, with MADEVENT [80, 81],\nfor which DPI has been simulated by either Pythia 8 or by combining pairs of parton\u2013level events as in\nRefs. [78, 79].\nIn summary, these are the samples that we have generated with Pythia 8:\ntt , W j \u2297 jj , W jj(M G) \u2297 jj , bb \u2297 jj , bbj(M G) \u2297 jj\n16\n\nContributed by R. Chierici, E. Maina\n\n44\n\n(10)\n\n\fwhere with W jj(M G) and bbj(M G) we indicate that the corresponding events have been produced\nstarting from an external Les Houches file created by MADEVENT . In all cases the second hard interaction\nswitched on in Pythia 8 is a generic 2 \u2192 2 QCD process. The default Pythia 8.130 parameter setup\nand tunings have been used. All the events processed with Pythia 8 have been fully showered, and jet\nclustering run over the events to have the possibility to apply a more realistic event selection.\nWe have also generated at parton level all reactions contributing to jj \u2297 jjW , jjj \u2297 jW and jjjj \u2297 W\nwith MADEVENT.\nAll samples have been generated using CTEQ6L [82] parton distribution functions and with the\nfollowing parton level cuts:\npTj \u2265 10 GeV , |\u03b7j | \u2264 5.0 , \u2206Rjj \u2265 0.001\n\n(11)\n\n \u0304 s, s\u0304, c, c\u0304, b, b\u0304, g.\nwhere j = u, \u016b, d, d,\n\nThe DPI cross section for the parton level samples has been estimated as\n\u03c3 = \u03c31 * \u03c32 /\u03c3ef f /k\n\n(12)\n\nwhere \u03c31 , \u03c32 are the cross sections of the two contributing reactions and k is a symmetry factor, which\nis equal to two if the two reactions are indistinguishable and equal to one when they are different.\nAt the Tevatron, CDF [73] has measured \u03c3ef f = 14.5 \u00b1 1.7+1.7\n\u22122.3 mb, a value confirmed by D\u00d8 which\nquotes \u03c3ef f = 15.1 \u00b1 1.9 mb [74]. In Ref. [83] it is argued, on the basis of the simplest two channel\n\u221a\neikonal model for the proton\u2013proton cross section, that a more appropriate value at s = 1.8 TeV is 10\nLHC = 12 mb. Treleani then estimates the effect of the removal by\nmb which translates at the LHC into \u03c3ef\nf\nCDF of Triple Parton Interaction events from their sample and concludes that CDF measurement yields\n\u03c3ef f \u2248 11 mb. In the following we use \u03c3ef f = 12.0 mb with the understanding that this value is affected\nby an experimental uncertainty of about 15% and that it agrees within about 10% with the predictions of\nthe eikonal model.\nThe DPI picture in Pythia 8 assumes that interactions can occur at different pT values independently of\neach other inside inelastic nondiffractive events. The expression for a DPI cross section becomes therefore:\n\u03c3 =< fimpact > \u03c31 * \u03c32 /\u03c3N D /k\n\n(13)\n\nwhere \u03c3N D is the total non-diffractive cross section and fimpact is an enhancement/depletion factor chosen\nevent-by-event to account for correlations introduced by the centrality of the collision. This quantity is\ntypically averaged during an entire run to calculate < fimpact > in Eq. 13. Typical values at the centre of\nmass energy of 10 TeV are 1.33 for < fimpact > and 51.6 mb for \u03c3N D . Comparing Eq. 13 with Eq. 12\ntells us that Pythia 8 sort of predicts an effective \u03c3ef f =\u03c3N D /< fimpact > which is about a factor 3 larger\nthan the one actually measured at the Tevatron.\nTable 4 reports the cross section breakdown for the samples used in this study and processed by Pythia 8.\nAll cross-sections are leading order as returned by the programs used. The W jj sample generated with\nMADEVENT has also been combined with matrix elements QCD events, evaluating the cross section\naccording to Eq. 12: we will call this sample as W jj \u2297 jj ME, as opposed to the W jj \u2297 jj P8 sample.\n8.3\n\nRESULTS\n\nTo mimic an experimental analysis, showered events are first required to have an isolated, central and\nenergetic lepton according to the cuts:\npTl \u2265 20 GeV , |\u03b7l | \u2264 2.5 , Eiso \u2264 20 GeV\n\n(14)\n\nwith obvious notation and where Eiso is an isolation variable defined as the total energy flowing in a\ncone of opening angle \u2206R=0.1 around the lepton. Later in this study we have made this cut more severe\n45\n\n\fProcess\ntt\nW (\u2192 l\u03bd)jj(MG)\nWj\nbb\nbbj(MG)\nbbjj(MG)\nW (\u2192 l\u03bd)jj(MG)\n\n\u03c3(nb)\n0.24\n13.7\n4.8\n850\n688\n472\n13.7\n\n\u03c3(\u2297jj)(pb)\nno DPI\n140\n12\n2200\n7300\nno DPI\nno DPI\n\n\u03c3acc (pb)\n60\n23\n2.5\n18\n69\n4012\n627\n\nTable 4: Total cross-sections for the processes studied in this contributions. Samples labelled with MG\nare made with the use of MADEVENT. The second column presents the cross sections as returned by the\ngenerators, the third column the corresponding cross sections after having added a second hard interaction\nto the process in Pythia 8, and the last column the accepted cross sections after the selection described in\nEq. 14.\n\nby increasing \u2206R to 0.5. We will also compare the effect of different jet pT thresholds. To be closer\nto an experimental selection, only electrons and muons are considered in this study. In events with a\ncandidate lepton, at least four jets with transverse momentum above 20 GeV and |\u03b7| < 5 are requested.\nNo b-tagging requirement is mimicked. The accepted cross sections of the top-pair signal and the DPI\nbackgrounds are reported in Table 4. In comparison we have also reported the accepted cross sections for\ntwo equivalent non-DPI background processes.\nIt has to be mentioned that for the DPI events obtained by the simple combination of parton level\nevents as in Refs. [78, 79], where no parton shower and fragmentation is present, the above cuts have been\nreplaced by equivalent ones. The lepton isolation, for instance, becomes a cut in \u2206R between the lepton\nand any jet.\nIn Figure 17 we present a few distributions at generator level after the event selection in Eq. 14. We\ndecided to compare the top-pair signal with the W jj process alone and with DPI W jj \u2297 jj in both the\nME and P8 configurations. All histograms in the plots are normalised to the number of events expected\nin 100/pb of integrated luminosity, with the exception of the Wjj contribution that has been scaled by a\nfactor 10 to make the plot more readable. The plots shown represent, respectively, the highest and softest\n(among four) pT of the jets in the event, the maximum pseudorapity difference among the four jets, the\nazimuthal difference between the jets complementary to those with the maximum azimuthal difference,\nthe scalar sum of the transverse momenta of the four highest pT jets, and the transverse momentum of the\nfound lepton. The heavy quark DPI component is shown only for this last histogram. The plot is a good\nindication of the fact that kinematic cuts on the lepton transverse momentum, as well as a more severe cut\non the lepton isolation, should be very effective in removing the heavy quark background(s), as we will\nalso demonstrate later.\nIn the plots we have not superimposed several ISR components that are, as expected, largely dominating\nin all the corners of the phase space (for instance W jjjj with respect to W jj \u2297 jj DPI or bbjj with\nrespect to bb \u2297 jj DPI). Therefore, analyses able to reach high purities in the top signal over the ISR\nbackground, should also be able to highly suppress all the analogous signatures coming from DPI events.\nThe DPI contributions can however reach sizeable fractions of the ISR backgrounds for analyses with\nnon sufficiently tight cuts. In the figures, for instance, we compare W jj(+parton shower) rescaled by a\nfactor 10 with the W jj \u2297 jj DPI component. The rate of the latter is sizeable and the two have similar\nkinematic characteristics: the additional jets from the second interaction have the tendency to be softer\nand slightly more forward in the acceptance. This suggests that harder cuts on the jet transverse momenta\nshould also be very effective in reducing the DPI component. From the figures it also turns out that there\nare significant discrepancies in the normalisation, as well as in shape, for the prediction of the W jj \u2297 jj\n46\n\n\f240\n\n100 pb-1\n\n220\n200\n180\n160\n\nPt of Softest Gen Jets after selection\nEvents\n\nEvents\n\nPt of Hardest Gen Jets after selection\nTop pair\n\n2200\n\nTop pair\n\nWjj(MG)/10\n\n2000\n\nWjj(MG)/10\n\nWjj(MG)+jj(P8)\n\n1800\n\nWjj(MG)+jj(MG)\n\n1600\n\n140\n\n1400\n\n120\n\n1200\n\n100\n\n1000\n\n80\n\n800\n\n60\n\n600\n\n40\n\n400\n\n20\n\n200\n\n0\n0\n\n20\n\n40\n\n60\n\n0\n0\n\n80 100 120 140 160 180 200\np (GeV/c)\n\nWjj(MG)+jj(P8)\n\n-1\n\n100 pb\n\n20\n\n40\n\n60\n\nT\n\nEvents\n\nEvents\n\nDeltaPhi between pair of jets complementary to the pair with max DeltaPhi\n\n500\n\nTop pair\n\nTop pair\n\n250\n\n-1\n\n100 pb\n\nWjj(MG)/10\n\n100 pb-1\n\nWjj(MG)/10\nWjj(MG)+jj(P8)\n\nWjj(MG)+jj(P8)\n\n400\n\n200\n\nWjj(MG)+jj(MG)\n\n300\n\nWjj(MG)+jj(MG)\n\n150\n\n200\n\n100\n\n100\n\n50\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n|\u2206 \u03b7|\n\n0\n\n1\n\n1.5\n\nEvents\n\nEvents\n\nTop pair\n\n600\n\n2\n\n2.5\n\n3\n\u2206\u03c6\n\nTop pair\n\n600\n\nWjj(MG)/10\n\n100 pb-1\n\n0.5\n\nPt of leptons after selection\n\nSum Pt of 4 highest pt jets after selection\n\n500\n\n80 100 120 140 160 180 200\np (GeV/c)\nT\n\n|\u2206 \u03b7| between tag jets\n\n0\n0\n\nWjj(MG)+jj(MG)\n\nWjj(MG)/10\nWjj(MG)+jj(P8)\n\nWjj(MG)+jj(P8)\n\n500\n\nbb(P8)+jj(P8)\n\nWjj(MG)+jj(MG)\n\n-1\n\n400\n\n400\n\n300\n\n300\n\n200\n\n200\n\n100\n\n100\n\n0\n100 200 300 400 500 600 700 800 900 1000\nSum p (GeV/c)\n\n0\n0\n\nT\n\n100 pb\n\n20\n\n40\n\n60\n\nWjj(MG)+jj(MG)\n\n80 100 120 140 160 180 200\np (GeV/c)\nT\n\nFig. 17: Distribution of the highest pTj ; the fourth highest pTj ; the largest separation in |\u2206\u03b7| among the\nfour highest pT jets; the |\u2206\u03c6| of the two jets complementary to those with the largest separation in |\u2206\u03c6|\namong the four highest pT jets; the scalar sum of the pT 's of the four highest pT jets; the pT of the charged\nlepton. The plots are made with the cuts in Eq. 14 and for 100 pb\u22121 of integrated luminosity at the LHC\n\u221a\nat s = 10 TeV.\n47\n\n\fPt of Softest Gen Jets after selection\n\nPt of Hardest Gen Jets after selection\nEvents\n\n220\n\nEvents\n\n2200\nTop pair\n\n-1\n\n200\n\n100 pb\n\nTop pair\n\n2000\nWjj(MG)/10\n\n180\n\nWjj(MG)+jj(P8)\n\n160\n\nWjj(MG)+jj(MG)\n\n140\n120\n\n1200\n\n100\n\n1000\n\n80\n\n800\n\n60\n\n600\n\n40\n\n400\n\n20\n\n200\n20\n\n40\n\n60\n\n0\n0\n\n80 100 120 140 160 180 200\np (GeV/c)\n\nWjj(MG)+jj(MG)\n\n20\n\n40\n\n60\n\nPt of leptons after selection\nEvents\n\nEvents\n\nSum Pt of 4 highest pt jets after selection\nTop pair\n\nTop pair\n\n-1\n\n100 pb\n\n250\n\nWjj(MG)/10\n\nWjj(MG)/10\nWjj(MG)+jj(P8)\n\n500\n\n400\n\n80 100 120 140 160 180 200\np (GeV/c)\nT\n\nT\n\n600\n\nWjj(MG)+jj(P8)\n\n1600\n1400\n\n0\n0\n\nWjj(MG)/10\n\n100 pb-1\n\n1800\n\nWjj(MG)+jj(P8)\n\n100 pb-1\n\nbb(P8)+jj(P8)\n\n200\n\nWjj(MG)+jj(MG)\n\nWjj(MG)+jj(MG)\n\n150\n\n300\n\n100\n\n200\n\n50\n\n100\n\n0\n100 200 300 400 500 600 700 800 900 1000\nSum p (GeV/c)\n\n0\n0\n\nT\n\n20\n\n40\n\n60\n\n80 100 120 140 160 180 200\np (GeV/c)\nT\n\nFig. 18: Distribution of the highest pTj ; the fourth highest pTj ; the scalar sum of the pT 's of the four\nhighest pT jets; the pT of the charged lepton. The plots are made with the cuts in Eq. 14 and a more severe\n\u221a\nlepton isolation condition, and for 100 pb\u22121 of integrated luminosity at the LHC at s = 10 TeV. The\nlepton isolation cone has now an opening of \u2206R=0.5.\n\nDPI ME and P8 components. The difference in normalisation is a direct consequence of the different\nnormalisation cross section for the DPI component in Pythia 8 with respect to the model in [83] and the\nTevatron measurements. The relatively small shape difference can everywhere be ascribed to the fact that\nthe distributions for W jj \u2297 jj ME are made at parton level prior to any showering, whereas for Pythia 8\nthey are all at hadron level and, therefore, also account for shower radiation.\nThe conclusions drawn so far have a very mild dependence on the lepton selection, with the exception\nof the reduction of the heavy quark component, for which a tighter isolation requirement is mandatory.\nThe plots in Figure 18 correspond to those in Figure 17, with the exception that the isolation cone for\nthe lepton has now an opening of \u2206R=0.5. Shape and normalisations for the signal and the W+jets\nbackgrounds do not change significantly, whereas the contribution of the heavy flavour component is\nsignificantly reduced.\nAnother way to tighten the analysis, and protect the signal even further from the DPI component is to\nincrease the jet transverse momentum threshold. Figure 19 shows the scalar sum of the four highest pT\n\n48\n\n\fPt of Softest Gen Jets after selection\nEvents\n\nEvents\n\nSum Pt of 4 highest pt jets after selection\nTop pair/10\n\n10\n\n100 pb-1\n\nTop pair/10\n\n25\n\nWjj(MG)+jj(P8)\n\nWjj(MG)+jj(P8)\n\nWjj(MG)+jj(MG)\n\n8\n\n20\n\n6\n\n15\n\n4\n\n10\n\n2\n\n5\n\n0\n100 200 300 400 500 600 700 800 900 1000\nSum p (GeV/c)\n\n0\n0\n\nT\n\n100 pb-1\n\n20\n\n40\n\n60\n\nWjj(MG)+jj(MG)\n\n80 100 120 140 160 180 200\np (GeV/c)\nT\n\nFig. 19: Distribution of the scalar sum of the pT 's of the four highest pT jets and the fourth highest pTj .\n\u221a\nThe plots are made for 100 pb\u22121 of integrated luminosity at the LHC at s = 10 TeV. The lepton isolation\ncone has now an opening of \u2206R=0.5 and pTj \u2265 10 GeV.\n\njets transverse momenta and the pT of the fourth jet in the event after that both lepton isolation conditions\nand jet thresholds have been tightened. The latter has been moved from 20 GeV to 40 GeV. The top pair\nsignal component is now scaled by a factor 10, making it evident that all DPI component are significantly\nreduced. What is also interesting is that in this region of phase space the accepted cross section (total and\ndifferential) for W jj \u2297 jj ME and P8 are essentially equivalent. This indicates that either approach is\nequivalent in describing DPI at relatively high transverse momentum.\n8.4\n\nFURTHER RESULTS\n\nIn Sect. 8.3 we have compared the W jj \u2297 jj parton level DPI contribution to a number of contributions\ngenerated with Pythia 8. We have neglected the jjj \u2297 jW and jjjj \u2297 W components because they\ncannot be directly generated only with Pythia. In this section we complete our analysis in this regard. In\nFigure 20 we present the distribution of the largest jet transverse momentum for jj \u2297 jjW , jjj \u2297 jW\nand jjjj \u2297 W . We also show the Single Parton Interaction (SPI) result for W + 4j and the sum of SPI\nand MPI contributions. We neglect the small Triple Parton Interaction component. All results in this\nsection are purely at parton level without showering and hadronization. The selection cuts are:\n\npTj \u2265 20 GeV , |\u03b7j | \u2264 5.0 , \u2206Rjj \u2265 0.5 , pTl \u2265 20 GeV , |\u03b7l | \u2264 2.5 , \u2206Rjl \u2265 0.1\n\n(15)\n\nThe W +4j/W jj \u2297jj/jjj \u2297jW /jjjj \u2297W contributions are in the ratio 1/0.33/0.11/0.04 and therefore\nthe DPI rate is about half of the SPI rate, with the W jj \u2297 jj component contributing about two thirds of\nthe DPI total. As a comparison we recall that in [78] the DPI contribution to W + 4j was estimated at\n\u221a\nabout 10% at s = 14 TeV. Only part of the discrepancy between the two results can be explained by the\nsmaller effective cross section \u03c3ef f = 12.0 mb employed here in comparison to \u03c3ef f = 14.0 mb used\nin [78]. Therefore our preliminary analysis suggests that the DPI background to W + 4j production is\n\u221a\nproportionally larger at s = 10 TeV than at 14 TeV.\nCONCLUSIONS\nWe have asked ourselves the question whether MPI can be a source of unexpected background for high pT\nphysics at the LHC. In this study we have taken top production as a perfect use case, trying to determine\n49\n\n\fEvents/100 pb-1\n\npT of hardest jet\nTotal SPI+DPI\n\n600\n\nW4j SPI\njj+Wjj DPI\n\n500\n\njjj+Wj DPI\njjjj+W DPI\n\n400\n300\n200\n100\n0\n0\n\n20\n\n40\n\n60\n\n80\n\n100 120 140\n\n160 180 200\n(GeV)\n\nFig. 20: Distribution of the highest pTj for jj \u2297 jjW , jjj \u2297 jW and jjjj \u2297 W . Also reported are the\nSPI result for W + 4j and the sum of SPI and MPI contributions.\n\nwhich MPI background can induce a signature compatible with tt. We have shown that DPI coming from\nQCD processes and either W production or heavy quark production can indeed fake a top pair signature,\nbecoming a significant fraction of the remaining background if the analyses are not sufficiently tight.\nAs main experimental cuts for reducing drastically DPI we suggest the minimum transverse momentum\nthreshold for jets and the lepton isolation, which are expected to be also effective for standard multi-jet\nbackgrounds. In our study we have compared two ways of generating DPI events: one based on Pythia 8\nand the other by direct combination of parton level events. The differences between the two approaches are\nimportant, especially in the softer regionss of phase space and for what concerns the global normalisation,\nand are ultimately due to the assumptions on the cross section to which DPI are normalised. The present\nresults suggest that the DPI background to W + 4j production is proportionally larger at 10 TeV than at\n14 TeV\nACKNOWLEDGEMENTS\nWe are indebted to P. Skands and T. Sj\u00f6strand for very interesting discussions on MPI and Pythia 8.\n\n50\n\n\fA MATCHING SCHEME FOR W \u03b3 NLO MATRIX ELEMENT GENERATOR AND Pythia 8\nPARTON SHOWER 17\n\n9.\n9.1\n\nINTRODUCTION\n\nDiboson production is among the early physics topics to be studied at the LHC initial phase. In particular,\nthe W \u03b3 process has a higher rate compared to the others, which can be pursued at moderate luminosities\nto probe the gauge structure of the Standard Model. The presence of anomalous couplings between the\nW-bosons and the photon is expected to enhance the harder part of the photon transverse momentum (p\u03b3T )\nspectrum which is one of the experimental observables. Higher order QCD corrections will contribute\nsignificantly at the LHC, modifying the p\u03b3T spectrum and hence may obscure the effect of any anomalous\ncoupling that might exist. This calls for at least a NLO QCD event generator to accurately describe the\nparton level process. However, for a full event description including the initial and final state radiations\n(ISR and FSR) and the underlying events the parton shower approach is required. In this contribution we\ndiscuss a matching scheme for W \u03b3 events generated by W GAMMA NLO [84], which is a complete O(\u03b1s )\ncalculation, to the Pythia [18], [20] parton showers. The proposed methodology for the matching preserves\nboth the rate of the hard scattering process as well as various kinematic distributions of experimental\ninterest, like the photon transverse momentum.\n9.2\n\nTHE MATCHING STRATEGY\n\nThe W GAMMA NLO package [84], [85] is a matrix element-based event generator which produces W \u03b3\nevents in hadronic collisions with up to one additional parton (quark or gluon) in the final state. It has the\nprovision for the introduction of anomalous W W \u03b3 couplings in addition to Standard Model ones and\nhence interesting for experimental analysis.\nThe W GAMMA NLO package produces two types of event topologies:\n\u2022 3-body final state, from W \u03b3 +0 jet events, containing the lepton and the neutrino from W-decay\nand the photon;\n\u2022 4-body final state, from W \u03b3 +1jet events, containing an additional parton (quark or gluon) forming\na jet.\nFigs. 21 and 22 depict the Born level diagrams and some of the higher order QCD corrections for the W \u03b3\nprocess respectively. Fig. 23 compares the p\u03b3T spectrum at the Born level to that at NLO, as obtained from\nW GAMMA NLO . The cross-section for the W \u03b3 process is 1.390\u00b10.029 pb at NLO and 0.584\u00b1 0.005 pb\nat Born level for p\u03b3T > 25 GeV/c with |\u03b7 \u03b3 | < 2.1 and plepton\n> 15 GeV/c with |\u03b7 lepton | < 2.6, \u03b7 \u03b3 and\nT\n\u03b7 lepton being the pseudorapidity of the photon and the lepton from W-decay respectively. The selection\napplied here are typical of the LHC experiments. This gives a p\u03b3T -dependent k-factor with a mean value\nof of 2.16, which is quite substantial (Fig. 23 inset).\nPythia 8 has been used for implementing the pT -ordered parton shower to the hard-scattered part\ngenerated by W GAMMA NLO . The ISR process in Pythia adds coloured partons to the incoming quarks\nof the hard scattering process which may transform a 3-body event to a 4-body event, thereby effectively\nchanging the cross-section of the individual 3-body and 4-body processes. The idea behind the matching\nscheme is to generate the parton showers without changing the number of individual events; i.e., the\nparton shower should not populate the regions of phase space for the W \u03b3j events, j being a parton, which\nare already filled by the matrix element generator.\nIt is to be noted that W GAMMA NLO package produces weighted events which has to be unweighted\nbefore matching where only events with unit weight are considered. The unweighting is done using the\nstandard \"hit-and-miss\" technique, where the ratio of an event weight to the highest weight is compared\nagainst a number drawn from a uniform deviate and the event is kept if the ratio is greater than the random\nnumber generated from the uniform distribution. Events with an occasional negative weight, from virtual\nloops, are not considered.\n17\n\nContributed by: D. Majumder, K. Mazumdar, T. Sj\u00f6strand\n\n51\n\n\fFig. 21: Born level subprocesses for W \u03b3 production in hadron-hadron collision : s-channel process (left),\nt-channel process (middle) and u-channel process (right).\n\nFig. 22: Some higher order QCD diagrams for W \u03b3 production in hadron-hadron collision.\n\n9.21\n\nThe matching algorithm\n\nIn the matching procedure, the discrimination of 3-body vs. 4-body state is performed according to a predefined threshold value pseparate\n(5 GeV/c for the present study), which serves as the boundary between\nT\nthe matrix element regime on its upper side and the parton shower regime on its lower. The matching\nprocedure starts with projecting the 4-body system to a 3-body system, by assuming that the outgoing\nparton can be emitted from either of the incoming partons (flavours permitting), with relative weights\ndetermined by splitting kernels and parton densities. Effectively this corresponds to the assumption\nthat the 4-body state never had a parton emitted and all the kinematics are recalculated based on this\nassumption. Subsequently, this projected 3-body final state event is treated according to the following\nsteps:\n1. Shower the projected 3-body event and compare pshower\nat the first ISR branching with the pparton\nT\nT\nin original 4-body:\n\u2022 If pshower\n> pparton\nthen the event is reclassified to 3-body; move to step 2 below.\nT\nT\n\u2022 If pshower\n< pparton\nthen the original 4-body event is retained as a 4-body event; move to\nT\nT\nstep 3 below.\n2. Shower the 3-body events:\n\u2022 Compare pshower\nwith pseparate\nafter first ISR branching. pseparate\ncan be considered to be\nT\nT\nT\nthe boundary between the ME calculation's regime and that of the parton shower's.\n\u2022 If pshower\n> pseparate\nthen stop any further shower evolution and restart the parton shower\nT\nT\nseparate\nuntil pshower\n<\np\n.\nT\nT\n\u2022 Continue with the rest of the shower.\n3. Shower the 4-body events:\n\u2022 The pshower\nfrom the first ISR is compared with pparton\n. If pshower\n> pparton\nthen restart the\nT\nT\nT\nT\n52\n\n\fk-factor\n\nT\n\n\u03b3\n\nd\u03c3/dp (pb/1GeV/c)\n\n0.16\nWGAMMA_NLO\n6\n0.14\n= 10\nTeV\ns =s 10\nTeV\n5\n4\n0.12\n3\n0.1\n2\n1\n0.08\n0\n0 10 20 30 40 50 60 70 80 90 100\np\u03b3 (GeV/c)\n0.06\nT\nNLO\n0.04\nBorn\n0.02\n00 10 20 30 40 50 60 70 80 90 100\np\u03b3 (GeV/c)\nT\n\nFig. 23: Differential cross-section for the photon transverse momentum at Born level is compared with\nthe differential cross-section for NLO W \u03b3 process. Inset: k-factor as defined by the ratio of the NLO\ncross-section to the Born cross-section.\n\nISR branching until pshower\n< pparton\nT\nT\n\u2022 Continue with rest of shower to give a complete event.\n9.22\n\nMatching results\n\nThe 4-body final states from the matrix element calculation lacked the Sudakov form factor for QCD\nemission which was corrected for by the above-mentioned algorithm. It is to be noted that the first ISR\nemission from the 3-body events are always confined below pseparate\n. But this is not so in the case where\nT\nthe parton showering is only required to be softer than the matrix element parton.\nFig. 24 (left) shows the distribution of the transverse momentum of the W \u03b3 system obtained by\nW GAMMA NLO superposed with the same after the Pythia showering. The distribution from W GAMMA NLO\n\u03b3\nshows many events with pW\nequal to zero which are the 3-body events. The non-zero values correspond\nT\nto events with a parton in the final state. After the matching, the kink after the zeroth bin fills up due to\nthe boost from Pythia ISR. The area under both these curves however remain the same indicating that\nthe exclusive cross-section of the 1-jet events remain conserved after the parton shower. Finally, Fig. 24\n(right) shows the photon pT spectrum before and after the matching.\nThe matching scheme is rather simplistic and is suitable for this particular event topology which\ncontains only one hard jet in the final state. The advantage is that it does not require any modification\nof the matrix element calculation of Baur for the Sudakov form factor needed for the parton emission.\nThis is in contrast with packages based on leading order multi-parton final state calculation, where the\nmatching scheme with parton shower effectively reduces the cross-section.\n9.3\n\nSUMMARY\n\nThe matching strategy as enunciated above preserves the cross-section of the W \u03b3 + 1 jet events. Also, for\na reasonably high cut on p\u03b3T , the spectrum before and after the matching is identical. It remains to be seen\nhow stable the scheme is with respect to changes in the boundary between the matrix element and parton\nshower, as defined by pseparate\nand also its performance in comparison to matched events generated by\nT\nother matrix element generators like Madgraph and Alpgen. The final test of the best suited method can\nbe performed only with good-statistics real-collision data at LHC.\n53\n\n\f+\n\n\u03b3\n\n\u03b3\npW\nbefore matching\nT+\nW\u03b3\npT after matching\n\n10-2\n\n0 10 20 30 40+ 50 60 70 80 90 100\npW \u03b3 (GeV/c)\nT\n\nT\n\n10-1\n\nd\u03c3/dp (pb/1GeV/c)\n\n(pb/1GeV/c)\nW+\u03b3\n\nd\u03c3/dpT\n\nWGAMMA_NLO 10TeV\n\n0.08\nWGAMMA_NLO 10TeV\n0.07\n\u03b3 from W+\u03b3 before ISR\n0.06\nleading \u03b3 after ISR\n0.05\n0.04\n0.03\n0.02\n0.01\n00 10 20 30 40 50 60 70 80 90 100\np\u03b3T(GeV/c)\n\nFig. 24: The transverse momentum of the W \u03b3 system before Pythia showering and after Pythia showering\n(left) and photon pT spectrum before and after the showering (right).\n\nACKNOWLEDGEMENT\nThe main part of this work done by DM was supported by the European Union Marie Curie Research\nTraining Network MCNet, under contract MRTN-CT-2006-035606. DM and KM are extremely grateful\nto U. Baur for many private communications at the initial stage of the study.\n\n54\n\n\fTHEORY TESTS OF PARTON SHOWERS 18\n\n10.\n10.1\n\nINTRODUCTION\n\nThe last few years have witnessed significant progress in the improvement of parton shower algorithms\nwith the invention of new shower algorithms based on the dipole or antenna picture [86\u201392] known\nfrom next-to-leading order calculations. These algorithms are able to satisfy simultaneously at each step\nmomentum conservation and the on-shell conditions. This is possible, because they are based on 2 \u2192 3\nsplittings, where the spectator can absorb the recoil. Within the traditional 1 \u2192 2 splitting algorithms it is\nimpossible to satisfy simultaneously momentum conservation and the on-shell conditions for a splitting.\nIn addition these new algorithms implement in a correct way simultaneously the soft and the collinear\nlimit of the matrix elements. When both emitter and spectator are in the final state these new algorithms\nare very similar to the shower algorithm implemented in A RIADNE [93\u201397]. The new algorithms extend\nthe dipole or antenna picture to final-initial, initial-final and initial-initial configurations.\nFor any shower algorithms one needs an evolution variable. A sensible choice is\nt = ln\n\n2\n\u2212k\u22a5\n,\nQ2\n\n(16)\n\nwhere Q2 is a fixed reference scale and k\u22a5 is the transverse momentum of a splitting. During the shower\nevolution we move towards smaller (more negative) values of t. The central object of a shower algorithm\nis the Sudakov factor, describing the no-emission probability. For a dipole shower it is calculated from the\nindividual dipoles. For a dipole with emitter \u0129 and spectator k\u0303, the Sudakov factor is given by\n\uf8eb t\n\uf8f6\nZ1\nZ\n\u0010\n\u0011\n\u2206ij,k (t1 , t2 ) = exp \uf8ed\u2212 dtC\u0129,k\u0303 d\u03c6unres \u03b4 t \u2212 T\u0129,k\u0303 Pij,k \uf8f8 ,\n(17)\nt2\n\nwhere C\u0129,k\u0303 is a colour factor. T\u0129,k\u0303 depends on the dipole invariant mass (p\u0129 + pk\u0303 )2 and the phase space\nvariables for the emission of an additional particle. The essential information is given by the function\nPij,k , which encodes the singular part of the matrix elements for the emission of a particle. As an example\nwe quote this function for the q \u2192 qg splitting:\n\u0014\n\u0015\n8\u03c0\u03b1s (\u03bc2 ) 1\n2\nPq\u2192qg = CF\n\u2212\n(1\n+\nz)\n.\n(18)\n(p\u0129 + pk\u0303 )2 y 1 \u2212 z(1 \u2212 y)\n2 . The shower algorithm proceeds through the following steps: One\n\u03b1s is evaluated at the scale \u03bc2 = \u2212k\u22a5\nfirst chooses the next scale t at which a splitting occurs according to the Sudakov factor. For this given\nchoice of t one then chooses the momentum fraction z according to Pa\u2192bc (z) and an azimuthal angle \u03c6\neither uniform or according to spin-dependent splitting functions. With these three variables (t, z, \u03c6) one\ncan construct all four-vectors after the emission. The spectator absorbs thereby some recoil. We now have\na configuration where one particles was emitted. For t > tmin one goes back to the first step, otherwise\none stops.\n\n10.2\n\nEVOLUTION VARIABLES\n\nIn the last year there has been some discussion whether the new shower algorithms based on dipoles or\nantennas [98\u2013100] have the correct collinear limit. In particular it has been argued that the fact that the\nspectator takes some recoil could conflict with collinear factorisation. This question has been solved\nand it has been shown that the algorithms based on dipoles or antennas describe correctly the collinear\nlimit [99, 100]. This result could have been anticipated from the fact, that the dipole splitting functions\n18\n\nContributed by: S. Weinzierl\n\n55\n\n\fPa\u2192bc reduce in the collinear limit y \u2192 0 to the Altarelli-Parisi splitting functions. For the example of a\nq \u2192 qg-splitting we have\n\u0014\n\u0015\n2\n8\u03c0\u03b1s (\u03bc2 ) 1\n\u2212 (1 + z) .\n(19)\nlim Pq\u2192qg = CF\ny\u21920\n(p\u0129 + pk\u0303 )2 y 1 \u2212 z\nIn addition the momentum mapping\npj = (1 \u2212 z)p\u0129 \u2212 k\u22a5 + yzpk\u0303 ,\n\npi = zp\u0129 + k\u22a5 + y (1 \u2212 z) pk\u0303 ,\n\npk = (1 \u2212 y)pk\u0303 ,\n\n(20)\n\nreduces in the collinear limit y \u2192 0 and k\u22a5 \u2192 0 to\npj = (1 \u2212 z)p\u0129 ,\n\npi = zp\u0129 ,\n\npk = pk\u0303 .\n\n(21)\n\nIn particular, the spectator does not receive any recoil in the collinear limit. What emerged from the\ndiscussions is that the choice of the shower evolution variable is not arbitrary. This lead to the definition\nof an \"infrared sensible\" evolution variable [100]. The definition of infrared sensible is that both infinitely\nsoft and collinear emissions should be classified as unresolved for any finite value of the evolution variable.\nThe evolution variable based on the transverse momentum as in eq. (16) is an infrared sensible evolution\nvariable. On the other hand, the choice of the energy of the emitted particle (in the centre-of-mass system\nof the emitter and the spectator) is not infrared sensible. There are configurations where the emitted\nparticle has finite energy, but which are infinitely collinear.\n10.3\n\nMULTIPLE SOFT EMISSIONS\n\nThe shower algorithms above are derived from first-order perturbation theory. The singular functions\nentering the Sudakov factor are derived from tree-level matrix elements, where a single particle becomes\neither soft or collinear. The parton shower therefore reproduces the leading-log behaviour of the matrix\nelements in the limit of an infinitely large hierarchy between the scales of each successive emission. No\nclaim is made to describe correctly the case of multiple emissions at the same scale. Nevertheless I would\nlike to make a few comments what could be expected from future algorithms incorporating these effects. I\nwill discuss multiple soft emissions, as derived from the singular behaviour of the matrix elements. If a\nsingle gluon becomes soft, the square of a partial tree amplitude factorises according to\nA(0)\nn (pa , p1 , pb , ...)\n\n2\n\n= 4\n\n2\nsab\n(0)\nAn\u22121 (pa , pb , ...) .\nsa1 s1b\n\n(22)\n\nIn any strongly ordered limit the emission of r soft gluons is described by [101]\nA(0)\nn (pa , p1 , ..., pr , pb , ...)\n\n2\n\n= 4r\n\n2\nsab\n(0)\nAn\u2212r (pa , pb , ...) .\nsa1 s12 s23 ...srb\n\n(23)\n\nThis formula is valid for any strong ordering\nE\u03c3(1) \u001c E\u03c3(2) \u001c ... \u001c E\u03c3(r) \u001c Ea , Eb ,\n\n(24)\n\nwhere \u03c3 is permutation of (1, 2, ..., r). However, if two gluons are emitted at the same scale E1 \u2248 E2\nwe have a more complicated formula. In the limit of two soft gluons a partial tree amplitude factorises\naccording to [102]\nA(0)\nn (pa , p1 , p2 , pb , ...)\n\n2\n\n(0)\n\n2\n\n= |Eik(pa , p1 , p2 , pb )|2 An\u22122 (pa , pb , ...) ,\n\n(25)\n\nwith\n\u0014\nsab\n(sa12 s2b + sa1 s12b \u2212 sa12 s12b )2\n+8\n|Eik(pa , p1 , p2 , pb )| = 16\nsa1 s12 s2b\ns2a12 s212 s212b\n\u0012\n\u0013\u0015\ns2ab\nsab\n1\n1\n1\n4\n+\n+\n\u2212\n\u2212\n+\n.\nsa1 s2b sa12 s12b s12 sa1 s12b sa12 s2b sa1 s2b sa12 s12b\n2\n\n56\n\n(26)\n\n\fThe expression in the square bracket does not contribute to any strongly ordered limit (E1 \u001c E2 \u001c Ea , Eb\nor E2 \u001c E1 \u001c Ea , Eb ). In the strongly ordered limit it is less singular than the first term. However for\nE1 , E2 \u001c Ea , Eb both terms scale like 1/\u03bb4 , if the momenta of the soft gluons are rescaled by \u03bb.\n\n57\n\n\f11.\n11.1\n\nHIGGS BOSON PRODUCTION VIA GLUON FUSION AT THE LHC: A COMPARATIVE\nSTUDY 19\nINTRODUCTION\n\nThe primary motivation for ongoing and impending physics programmes at the Tevatron and LHC is to\ngain insight into the nature of electroweak symmetry breaking. The great majority of the effort in this\ndirection is devoted to the hunt for the Higgs boson, the origin of this symmetry breaking in the Standard\nModel [103\u2013106].\nOf all the ways in which the Standard Model Higgs boson can be produced, the gluon fusion process [107], in which it couples to colliding gluons via a top quark loop, has the largest cross section\nfor Higgs boson masses less than \u223c700 GeV. This process will be extremely important in detecting and\nstudying the Higgs boson at the LHC in the low mass region, favoured by fits of the Standard Model to\nelectroweak precision data [108] and in part also by direct searches at the Tevatron [109, 110], for which\nHiggs boson decays into two photons are expected to give a clean experimental signal.\nAlthough observing a narrow resonance in the diphoton invariant mass spectrum should be possible\nusing only the experimental data [111], determining the quantum numbers and couplings of the resonance\ni.e. determining that it really is a fundamental scalar, in particular, the Standard Model Higgs boson,\nrequires Monte Carlo simulations to predict distributions for both signals and backgrounds.\nIn recent years Monte Carlo event generators have been the subject of great theoretical and practical\ndevelopments, most significantly in the extension of existing parton shower simulations to consistently\ninclude exact next-to-leading order (NLO) corrections [12\u201315, 25, 112\u2013125] and, separately, in the\nconsistent combination of parton shower simulations and high multiplicity tree-level matrix element\ngenerators [4, 5, 65, 70, 126\u2013129]. The state-of-the-art in fixed order predictions has also undergone major\nimprovement, resulting in fully differential Monte Carlo predictions at next-to-next-to-leading order\n(NNLO) for inclusive Higgs production and, simultaneously, NLO accuracy for production in association\nwith a hard jet [130\u2013133].\nIn this article we present predictions from most of the Monte Carlo simulations arising from this\ntheoretical activity, for the gluon fusion process at the LHC, at the expected20 initial hadronic centre\u221a\nof-mass energy, s = 10 TeV. As well as updating existing results, based on the originally forecast\n14 TeV centre-of-mass energy, this document represents a broad comparative study among a number of\nfundamentally different Monte Carlo approaches, hence it also serves to gauge their relative merits and\ngauge the stability of our theoretical predictions with respect to the various methods.\nIn the following we shall concisely review the pertinent features of the simulations included in the study,\nprior to presenting results for a variety of simple observables concerning the gluon fusion production\nchannel. At the end of the article we summarise the results and comment on the readiness of these\ntheoretical tools for much anticipated Higgs analysis.\n11.2\n\nMATRIX ELEMENTS AND PARTON SHOWERS\n\nIn modern experimental particle physics, shower Monte Carlo (SMC) programs have become an indispensable tool for data analysis. From a user perspective, these programs provide an approximate but\nextremely detailed description of the final state in a high-energy process involving hadrons. They provide\na fully exclusive description of the reaction, as opposed to fixed-order QCD calculations, which are only\nsuitable for the computation of inclusive quantities.\nAfter a latency period, research in SMC is once again very active, with significant advances being made\nin the last decade. In general these developments can be grouped into two main classes:\n19\n\nContributed by: M. Grazzini, K. Hamilton, S. H\u00f6che, F. Maltoni, C. Oleari, S. de Visscher, J. Winter\nAt the time the study was started. The current plan is for running at 7 TeV and 14 TeV, which leaves this study nicely in the\nmod range.\n20\n\n58\n\n\f1. The merging of leading-order matrix elements (ME), characterized by a high number of finalstate partons, with parton showers (PS). Examples of such methods are the CKKW matching\nscheme [4, 126], the MLM matching procedure [70] as well as the newer merging schemes based\non truncated parton showers [65, 129].\n2. The interfacing of NLO calculations (that are typically available only with a small number of legs\nin the final state) with parton shower simulations (MC@NLO [12] and POWHEG [14]).\nAll of them have to face the same problems: avoiding overcounting of events as well as the presence of\ndead regions.\n11.3\n\nMONTE CARLO PROGRAMS FOR THE STUDY\n\nWith the exception of the HNNLO program all of the Monte Carlo programs used in this study fall into\none or other of the two classes described above, implementing some form of matching/merging between\nfixed order calculations and parton shower simulations. In order to have a more full comparison of the\navailable Monte Carlo tools, we also include HNNLO, which is based on a fixed order NNLO calculation\nof Higgs-boson production via gluon fusion.\n11.31\n\nHNNLO\n\nThe HNNLO program is based on an extension of the NLO subtraction formalism to NNLO, as described\nin ref. [132].\nThe calculation is organized in two parts. In the first part, the contribution of the regularized virtual\ncorrections is computed up to two-loop order. In the second part, the cross section for the production\nof the Higgs boson in association with one jet is first evaluated up to NLO, i.e. up to O(\u03b1s4 )), using\nconventional NLO subtraction methods. Now, since the H + jet cross section is divergent when the\ntransverse momentum, qT , of the Higgs boson becomes small, a further counterterm must be subtracted\nto make the result finite as qT \u2192 0. To this end the program uses counterterm introduced in ref. [132].\nHaving regularized the real and virtual parts, the two contributions can be combined to reconstruct the\nfull cross section. Organizing the differential cross section in this way, one can construct a parton-level\nevent generator with which arbitrary infrared safe quantities can be computed. The present version of the\nprogram includes the decay modes H \u2192 \u03b3\u03b3 [132], H \u2192 W W \u2192 l\u03bdl\u03bd and H \u2192 ZZ \u2192 4 leptons [133].\nThe calculation is performed in the large top-mass approximation. This is known to be a good\napproximation provided that the Higgs boson is not too heavy and the transverse momenta of the final\nstate jets are not too large.\n11.32\n\nMadGraph / MadEvent\n\nBesides the possibility of generating processes in a long and extensible list of theoretical models (SM,\nMSSM, Higgs effective theory ...), the Monte-Carlo generator MADGRAPH/MADEVENT (MG/ME) [81] is\nalso intended to simulate accurately the QCD radiation from initial and final states when coupled to a\nparton shower simulation. Such an aim can be achieved by using jet matching and a phase-space slicing\ntechnique\nIn MG/ME, three jet matching schemes (using Pythia 6.4 [18]) are implemented, namely the MLM [70],\nthe k\u22a5 -MLM [134, 135] and the shower-k\u22a5 [135] schemes. While the first two methods work with both\nvirtuality and pT -ordered showers, the third one only works with the pT -ordered showers. For each of\nthese methods, no analytic Sudakov reweighting of the events is performed, instead showered events are\nrejected if they are not matched to the ME-level partons. A detailed comparison of the k\u22a5 -MLM and\nshower-k\u22a5 behaviours has shown that their respective outputs are very similar for the production of heavy\ncolored particles in the SM and beyond [135]. In addition, a comparison for the production of W +jets\nevents between the results from k\u22a5 -MLM and other simulation chains with different matching schemes\nhas led to a similar conclusion [134].\n59\n\n\fHaving the computation of the effective coupling between a scalar or pseudo-scalar to the gluons, the\naccurate simulation of the production of a Higgs boson accompanied by initial and final-state radiation is\ntherefore relatively straightforward. In order to compare the MG/ME production with the results from the\nother generators considered in this work, we choose to simulate H + 0, 1, 2 partons at the ME level and\napply the k\u22a5 -MLM scheme with QME\ncut = 10 GeV and Qmatch = 15 GeV. These choices were made in\nagreement with the smoothness of ME\u2192PS transition regions in the 2 \u2192 1 and 1 \u2192 0 differential jet\nrates distributions.\n11.33\n\nMC@NLO\n\nThe MC@NLO method [12] was the first one to give an acceptable solution to the overcounting problem.\nThe generality of the method has been explicitly proven by its application to processes of increasing\ncomplexity, such as heavy-flavour-pair [112] and single-top [113] production.21 The basic idea of MC@NLO\nis that of avoiding the overcounting by subtracting from the exact NLO cross section its approximation,\nas implemented in the SMC program to which the NLO computation is matched. Such approximated\ncross section (which is the sum of what have been denoted in [12] as MC subtraction terms) is computed\nanalytically, and is SMC dependent. On the other hand, the MC subtraction terms are process-independent,\nand thus, for a given SMC, can be computed once and for all. In the current version of the MC@NLO code,\nthe MC subtraction terms have been computed for Herwig 6 [136], but extensions to other SMC are\npossible. In general, the exact NLO cross section minus the MC subtraction terms does not need to be\npositive. Therefore MC@NLO can generate events with negative weights. For the processes implemented so\nfar, negative-weighted events are typically about 10\u201315% of the total. Their presence does not imply a\nnegative cross section, since at the end physical distributions must turn out to be positive, but affects the\noverall efficiency of the simulation.\nThe features implemented in MC@NLO can be summarized as follows:\n- Infrared-safe observables have NLO accuracy.\n- Collinear emissions are summed at the leading-logarithmic level.\n- The double logarithmic region (i.e. soft and collinear gluon emission) is treated correctly since\nHerwig 6 uses an angular-ordered shower.\n11.34\n\nPOWHEG\n\nThe POWHEG (Positive Weight Hardest Emission Generator) method was proposed in ref. [14]. This\nmethod overcomes the problem of negative weighted events, and is not SMC specific. In the POWHEG\nmethod, the hardest radiation is generated first, with a technique that yields only positive-weighted events,\nusing the exact NLO matrix elements. The POWHEG output can then be interfaced to any SMC program\nthat is either pT -ordered, or allows the implementation of a pT veto.22 However, when interfacing POWHEG\nto angular-ordered SMC programs, the double-log accuracy of the SMC is not sufficient to guarantee the\ndouble-log accuracy of the whole result. Some extra soft radiation (technically called vetoed-truncated\nshower in ref. [14]) must also be included in order to recover double-log accuracy. In fact, angular ordered\nSMC programs may generate soft radiation before generating the radiation with the largest pT , while\nPOWHEG generates it first. When POWHEG is interfaced to shower programs that use transverse-momentum\nordering, the double-log accuracy should be correctly retained if the SMC is double-log accurate. The\nARIADNE program [97], Pythia 6.4 [18] (when used with the new showering formalism), ADICIC++ [91]\nand the new parton showers based on the Catani\u2013Seymour dipole formalism [89, 90] adopt transversemomentum ordering, and aim to have accurate soft resummation approaches, in the limit of large number\nof colours.\n21\n\nA complete list of processes implemented in MC@NLO can be found at\nhttp://www.hep.phy.cam.ac.uk/theory/webber/MCatNLO.\n22\nAll SMC programs compatible with the Les Houches Interface for User Processes [2] should comply with this requirement.\n\n60\n\n\fUp to now, it has successfully been applied to Z pair hadroproduction [117], heavy-flavour production [118], e+ e\u2212 annihilation into hadrons [119] and into top pairs [125], Drell-Yan vector boson\nproduction [120, 122], W 0 production [137], Higgs boson production via gluon fusion [121, 123], Higgs\nboson production associated with a vector boson (Higgs-strahlung) [121], single-top production [124]\nZ + 1 jet production [138], and, very recently, Higgs production in vector boson fusion [139].\nTHE POWHEG BOX The POWHEG BOX is an automated package able to construct a POWHEG implementation of a NLO process, given the following ingredients:\n1.\n2.\n3.\n4.\n\nThe list of all flavour structures of the Born processes.\nThe list of all the flavour structures of the real processes.\nThe Born phase space.\nThe Born squared amplitude, the color correlated and spin correlated Born amplitudes. These are\ncommon ingredients of NLO calculations regularized with a subtraction method.\n5. The real matrix elements squared for all relevant partonic processes.\n6. The finite part of the virtual corrections, computed in dimensional regularization or in dimensional\nreduction.\n7. The Born color structure in the large limit of the number of colors.\nThe plots in this article were obtained using the POWHEG BOX, and the completion of the shower has been\ndone both with Pythia 6 and with Herwig 6.\n11.35\n\nHerwig++\n\nHerwig++ builds and improves upon the physics content of the parent Herwig 6 program, particularly in\nregard to the accurate simulation of QCD radiation. A major success of the original Herwig 6 program\nwas in its modeling the effects of soft gluon interference, specifically the colour coherence phenomenon,\nwhereby the intensity of soft gluon radiation, emitted at wide angles with respect to a bunch of collimated\ncolour charges, is found to be proportional to the coherent sum of emissions from the constituents i.e. the\njet parent [101, 140\u2013148]. This effect is manifest in the perturbative series as large soft logarithms and is\nimplemented as an angular ordering of successive emissions in the parton shower.\nA further significant accomplishment of the POWHEG [14] formalism is in fully catering for such effects\nthrough a careful decomposition of the angular-ordered parton shower into a truncated shower, describing\nsoft wide angle radiation, the hardest emission, as described above, and a vetoed shower comprised of\nincreasingly collinear emissions. In doing so the formalism provides a means of distributing the highest\npT emission in an event according to the exact real-emission matrix element, including resummation\neffects, without degrading or otherwise disturbing the resummation and colour-coherence properties\ninherent to the parton shower.\nThe facility to perform truncated showers is absent from the older fortran Herwig 6 program but is\nimplemented in the new Herwig++ program, which also includes its own native, independent, POWHEG\nsimulation for the gluon-fusion process, the results of which are presented in section 11.5\n11.36\n\nSherpa\n\nSherpa is a multi-purpose Monte-Carlo event generation framework for colliders [22,23]. The main goal of\nthis project is a proper simulation of the perturbative aspects of the collision, although significant improvements have been made over the past years regarding the simulation of non-perturbative dynamics, like\nthe process of hadronisation. One of the key features of the Sherpa program is a general implementation\nof a novel technique for combining tree-level matrix elements with parton showers, in arbitrary QCD or\nQCD-associated processes [65]. To this end, Sherpa makes use of its two internal tree-level matrix element\ngenerators AMEGIC++ [149] and Comix [150], which are capable of simulating both Standard Model\n61\n\n\f(AMEGIC++ and Comix) and beyond Standard Model (AMEGIC++) reactions with high-multiplicity final\nstates. Soft and collinear parton radiation is generated in Sherpa by means of a parton shower based on\nCatani\u2013Seymour dipole factorisation [89]. This formalism has apparent advantages compared to more\nconventional parton showers, which are based on strict 1 \u2192 2 splittings and often lack the notion of a\nwell-defined spectator parton. In the new approach, the recoil partner of a splitting parton is always a\nsingle external particle. This turned out to be an important ingredient when combining parton-shower\nevolution with higher-order tree-level matrix elements.\nThe technique for merging matrix elements and parton showers, which is employed by Sherpa, is based\non phase-space slicing. A detailed description of the corresponding algorithm, and its relation with other\ntree-level merging techniques, can be found in [65]. The method has recently been applied to mixed\nQCD and electroweak processes, in particular photon and diphoton production [151] and proves to give a\nconsistent and reliable description of data from deep-inelastic lepton-nucleon scattering [152]. Compared\nto the CKKW algorithm [4, 126], the new merging scheme of ref. [65] is more sophisticated and improves\nover CKKW by including truncated vetoed parton showers. The results are more accurate, with respect to\nthose of the CKKW approach, which has been employed in former versions of the Sherpa event generator\nwith already great success [134, 153\u2013155].\n11.4\n\nParameters for the study\n\nIn the following, we present results for the pp LHC at a centre-of-mass energy of 10 TeV. The common\nfeatures of the analysis are the following:\n\u2022 Model: We work in the Standard Model in the large top-mass limit. In this approximation the\ncouplings between the gluons and the Higgs boson are described by a dimension-five effective\ninteraction\n1\nLh = \u2212 gh Ga\u03bc\u03bd Ga\u03bc\u03bd H,\n(27)\n4\nwith gh = \u03b1s /(3\u03c0v).\n\u2022 Event samples: The analysis was performed on the generated final state and, with the exception of\nHNNLO, after parton showering. Hadronization effects were included for the MC@NLO and POWHEG\nresults only.\nA Higgs boson mass of mH = 120 GeV was assumed. Tree-level predictions were generated using\nthe leading order CTEQ6l1 PDF set [156], while generators employing the POWHEG method used\nthe next-to-leading order PDF set CTEQ6m [156]. In both cases the parametrisation of the strong\ncoupling was chosen accordingly. All partons (excluding the top quark) were taken to be massless\nand their Yukawa couplings were neglected.\n\u2022 Jet definitions: Jets were defined using the longitudinally invariant k\u22a5 -algorithm with D = 0.7 in\nthe implementation of FastJet [157]. They were required to lie within a rapidity range of |\u03b7| < 4.5\nand have transverse momenta of pT > 20 GeV.\n11.5\n\nRESULTS\n\nIn this section we present and discuss results obtained for some key observables in the analysis of\nHiggs production via gluon fusion. As already mentioned, we do not expect the LO matched results\nto provide reliable information on total rates, so we have normalized the corresponding curves, from\nMADGRAPH/MADEVENT and Sherpa, to the HNNLO result. On the other hand, having NLO accuracy,\nHerwig++, MC@NLO and POWHEG have not been rescaled.\nIn fig. 25, we plot the transverse momentum of the Higgs boson and, in fig. 26, its rapidity. The Higgs\nboson pT , in particular, is determined by the recoiling QCD radiation, both soft and hard, and, exactly\nas for Drell-Yan, it is therefore a key observable. The blow up of the small-pT region (left panel of\nfig. 25) shows quite good agreement among the various MC approaches with predictions being typically\n62\n\n\fd\u03c3/dpT,h pb/GeV\n\nd\u03c3/dpT,h pb/GeV\n\n0.8\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n0.6\n\n0.4\n\n1\n\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n10-1\n\n10-2\n0.2\n10-3\nSet / Mean\n\nSet / Mean\n\n1\n0\n\n1\n5\n\n10\n\n15 20 25 30 35\n\n40 45 50\npT,h\n\n0\n\n50\n\n100\n\n150\n\n200\n\n250\npT,h\n\nFig. 25: The transverse momentum spectrum of the Higgs boson. Tree-level predictions have been\nrescaled by the global factors indicated in the legend. The lower panels display the ratio of individual\nresults and the average of all histograms, excluding the results from HNNLO.\npeaked in the range between 5 and 10 GeV. The obvious excess in the HNNLO prediction, at low-pT , is\nexpected on the grounds that it is based on a fixed order computation, hence, it does not resum the effects\nof multiple soft emissions, which are essential for a proper description of the pT = 0 region. At higher\nvalues of the pT , the agreement is also excellent, apart from MC@NLO which shows a steeper behaviour\nwith respect to the results obtained by the POWHEG method and with the matching. As already pointed out\nin Refs [121, 123], this is due to NNLO terms in the POWHEG formula. It is, however, important to note\nthat, for all the NLO codes, this particular distribution can be predicted only at LO, i.e. no H + 2 partons\ncontribution and no H + 1 parton one-loop contributions are included. From this point of view, it is\nreasonable to expect the shape to be sensitive to variations in the renormalization and factorization scales,\nalthough, in practice, this sensitivity is much milder due to the resummation of higher order corrections\n(i.e. the shower). In any case, it is both remarkable to see that the predictions based on the POWHEG\nmethod and the ME+PS matching show such good agreement, particularly considering the fundamental\ndifferences in their methodology.\nIn the rapidity distributions of fig. 26, the HNNLO result shows all of its NNLO content: in fact, this is\nthe only plot that receives contributions from the two-loop diagrams.\nFigure 27 shows the jet pT distributions for the four hardest jets (ordered in pT ). Once again the\nagreement among the various approaches is very good, with MC@NLO leading to significantly less events at\nvery high pT 's; this lower number of events is in exact correspondance with that seen for the Higgs boson\ntransverse-momentum distribution and bears the same explanation. A particularly interesting feature is\nthe agreement found on the 3rd and 4th jet spectra. Only Sherpa has included the corresponding tree-level\nhard matrix elements, while all other predictions contain only one (NLO codes) or two (HNNLO and\nMADGRAPH/MADEVENT) hard partons. This good agreement is a mere coincidence, since in POWHEG,\nMC@NLO and Herwig++ these extra jets come from the shower, and are therefore only corect in the strict\ncollinear limit. Similar comments hold for the pseudorapidity distributions of fig. 28.\nLarger discrepancies are instead present for more exclusive quantities, such as the distance in the \u03b7-\u03c6\nplane between the two leading jets, \u2206R12 , shown in fig. 29. Indeed, we start appreciating here some\ninteresting differences in shape: Herwig++, for example, predicts much steeper distribution than Sherpa.\n\n63\n\n\fd\u03c3/dyh pb\n\n10\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n9\n8\n7\n6\n5\n4\n3\n2\n1\nSet / Mean\n\n1\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\nyh\n\nFig. 26: The rapidity distribution of the Higgs boson. See fig. 25 for details.\nFinally, in fig. 30, we plot the jets rates, which, once again, agree within 50% uncertainty even for\nhigher multiplicities.\n11.6\n\nCONCLUSIONS\n\nWe have reported on the first comparison among several different Monte Carlo approaches to the simulation\nof Higgs boson production in gluon fusion. Apart from some basic choices, such as the parton distribution\nfunctions, the collider energy and our choosing to use an effective theory where the top quark mass has\nbeen taken to infinity, no detailed tuning has been performed. The main idea being that of an \"out-ofthe-box\" comparison among various codes, all of which represent the state-of-the-art in Monte Carlo\ntools.\nThe upshot of our comparison is that, apart from the overall normalization, which is only reliable in\nNLO and NNLO codes, the various approaches give consistent results within their expected range of\nvalidity.\nACKNOWLEDGEMENTS\nWe thank Jeppe Andersen and Michelangelo Mangano for useful discussions.\n\n64\n\n\f1\nd\u03c3/dpT,jet 2 pb/GeV\n\nd\u03c3/dpT,jet 1 pb/GeV\n\n1\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n10-1\n\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n10-1\n\n10-2\n\n10-2\n10-3\nSet / Mean\n\nSet / Mean\n\n1\n\n1\n50\n\n100\n\n150\n\n200\n\n250\npT,jet 1\n\n20\n\nd\u03c3/dpT,jet 4 pb/GeV\n\nd\u03c3/dpT,jet 3 pb/GeV\n\n1\nHerwig++\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n10-1\n\n10-2\n\n10-3\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\npT,jet 2\n\n10-1\nHerwig++\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n10-2\n\n10-3\n\n10-4\n\nSet / Mean\n\nSet / Mean\n\n1\n20\n\n1\n30\n\n40\n\n50\n\n60\n\n70\n\n80\n\n90 100\npT,jet 3\n\n20\n\n30\n\n40\n\n50\n\n60\n\n70\n\n80\n\n90 100\npT,jet 4\n\nFig. 27: The transverse momentum spectra of the first four hardest jets, ordered in pT , accompanying the\nHiggs boson. See fig. 25 for details.\n\n65\n\n\f1.6\nd\u03c3/d\u03b7jet 2 pb\n\nd\u03c3/d\u03b7jet 1 pb\n\n5\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n4.5\n4\n3.5\n3\n\n1.2\n1\n\n2.5\n\n0.8\n\n2\n\n0.6\n\n1.5\n\n0.4\n\n1\n\n0.2\n\n0.5\nSet / Mean\n\nSet / Mean\n\n1\n-5\n\n1\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\u03b7jet 1\n\n-5\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4 5\n\u03b7jet 2\n\n0.2\nd\u03c3/d\u03b7jet 4 pb\n\n0.6\nd\u03c3/d\u03b7jet 3 pb\n\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n1.4\n\nHerwig++\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n0.5\n0.4\n\nHerwig++\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n0.18\n0.16\n0.14\n0.12\n\n0.3\n\n0.1\n0.08\n\n0.2\n\n0.06\n0.04\n\n0.1\n\n0.02\nSet / Mean\n\nSet / Mean\n\n1\n-5\n\n1\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4 5\n\u03b7jet 3\n\n-5\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4 5\n\u03b7jet 4\n\nFig. 28: The pseudorapidity distributions of the first four hardest jets, ordered in pT , accompanying the\nHiggs boson. See fig. 25 for details.\n\n66\n\n\fd\u03c3/d\u2206 Rjet 1,jet 2 pb\n\n3\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n2.5\n2\n1.5\n1\n0.5\n\nSet / Mean\n\n1\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n4 4.5 5\n\u2206 Rjet 1,jet 2\n\nd\u03c3/dNjet pb\n\nFig. 29: The separation in the \u03b7-\u03c6 plane of the two leading jets accompanying the Higgs boson. See\nfig. 25 for details.\n\nHerwig++\nHNNLO\nMadEvent 4.0 (x 1.85)\nMCatNLO\nPOWHEG+Pythia\nPOWHEG+Herwig\nSherpa 1.2.1 (x 1.84)\nSherpa 1.1.3 (x 1.36)\n\n10\n\n1\n\n10-1\nSet / Mean\n\n1\n0\n\n1\n\n2\n\n3\n\n4\n\n5\nNjet\n\nFig. 30: The production rates for Njet additional jets accompanying the Higgs boson. See fig. 25 for\ndetails.\n\n67\n\n\f12. W bb\u0304 IN THE HIGH-pT HW REGION 23\n12.1\n\nINTRODUCTION\n\nThe main aim of this section is to study the effect of next-to-leading order (NLO) QCD corrections to the\npp \u2192 W bb\u0304 process, in the region of phase space which is relevant for the highly boosted W H analysis\nwith H \u2192 bb\u0304 [158, 159].The details of the setup for the NLO computation in this kinematic region as\nwell as results for the scale dependence of the total cross sections are presented in Section 12.2. The\napplication of the NLO calculation to the experimental analysis on which the mentioned Higgs search is\nbased is not straightforward, since the latter addresses the simulation of the backgrounds through the use\nof a parton shower Monte Carlo (MC) algorithm which is applied on top of the QCD leading order (LO)\nmatrix element calculation.\nWhile for an increasing number of processes specific Monte Carlo generators have been made available\nto combine the NLO calculation with a parton-shower based MC generator, as in the MC@NLO program [12]\nor in the new POWHEG method [15,160], no such generator is available for the pp \u2192 W bb\u0304 process yet. It is\ntherefore useful to define a re-weighting procedure for pp \u2192 W bb\u0304 events generated by the use of a parton\nshower Monte Carlo, which for this specific case is Herwig [17], based on the distributions predicted by\nthe NLO calculation.\nAn important feature of the highly boosted W H analysis is the application of a tight jet veto. In the\ncut-based analysis [159] this veto is applied at pT = 20 GeV, while in a more refined likelihood based\nanalysis [161] the maximum pT considered for a possible additional non b-jet in the event is 60 GeV. The\nNLO QCD correction depends significantly on the pT of an additional non b-jet in the event and this is\naddressed in this study. This situation is analogous to other backgrounds for Higgs boson signals, as is\nthe case of the tt\u0304bb\u0304 process as a background for the search for tt\u0304H with H \u2192 bb\u0304, also considered in the\npresent proceedings.\nIn the specific case of the q q\u0304 0 \u2192 W bb\u0304 process, the real corrections which enter the NLO computation\ninclude an additional gluon-induced process, q(q\u0304) g \u2192 W bb\u0304j, which, given the gluon luminosity at the\nLHC, makes the NLO correction very large. However, by constraining the transverse momentum of the\nextra non-b-jet through a jet veto one can reduce the impact of this extra channel, which then improves\nthe scale dependence of the NLO computation, as long as such extra kinematical cut is not too restrictive.\n12.2 W bb\u0304 PRODUCTION AT NLO QCD WITH A TIGHT JET VETO\nThe calculation of the total and differential cross sections for W \u00b1 bb\u0304 production at NLO QCD for this study\nis based on Refs. [162\u2013164], which includes full b-quark mass effects. The input parameters are chosen\nas follows: mb = 4.79 GeV, mt = 173.1 GeV, MW = 80.399\ns2W = 0.223, GF = 1.16639 * 10\u22125\n\u221a GeV,\n2\n\u22121/2\n(the weak coupling being defined as: gW = (8MW GF / 2)\n). The contribution from the third\ngeneration quarks in the initial state is neglected and the non-zero CKM matrix elements are chosen to be:\nVud = Vcs = 0.974 and Vus = Vcd = 0.227.\nParton-level LO results (calculated as a cross-check) are obtained using the one-loop evolution of \u03b1s\nand the CTEQ6L1 [82] set of PDFs with \u03b1s (MZ ) = 0.130, while parton level NLO results are obtained\nusing the two-loop evolution of \u03b1s and the CTEQ6M set of PDFS with \u03b1s (MZ ) = 0.118.\nRenormalization (\u03bcr ) and factorization (\u03bcf ) scales are set to be equal and varied by a factor of two\n2 + (pb )2 + (pb\u0304 )2 ]1/2 , where pb and pb\u0304 are the transverse momenta of\naround a central value \u03bc0 = [MW\nT\nT\nT\nT\nthe jets generated by b and b\u0304 respectively.\nThe jets are constructed using the kT jet algorithm with pseudo-cone size R = 0.3 and the parton\nmomenta are recombined within a jet using the so called E-invariant scheme (=sum of momenta of the\nconstituents). We study two samples of events, i.e.\n\u2022 events with just 2 b jets;\n23\n\nContributed by: F. Febres Cordero, G. Piacquadio, L. Reina, D. Wackeroth\n\n68\n\n\f\u2022 events with 2 b jets and 1 non-b jet;\nwhere b and non-b jets are identified imposing the following cuts:\n\u2022 pbT > 30 GeV, |\u03b7 b | < 2.5;\nW\n\u2022 pW\nT > 200 GeV, |\u03b7 | < 2.5;\nnon\u2212b\n\u2022 15 GeV < pT\n< 60 GeV, |\u03b7 non\u2212b | < 5;\n\u2022 pTbb\u0304 > 200 GeV;\n\u2022 Rbb\u0304 < 1.2 .\n\npbT and |\u03b7 b | denote the transverse momentum and pseudorapidity of either one of the two b jets, pW\nT and\nnon\u2212b | denote the\n|\u03b7 W | are the transverse momentum and pseudorapidity of the W boson, pnon\u2212b\nand\n|\u03b7\nT\ntransverse momentum and pseudorapidity of the non-b jet, Rbb\u0304 is the relative separation between the b and\nb\u0304 jets, and pbTb\u0304 the transverse momentum of the bb\u0304 2-jet system.\nThe renormalization and factorization scale dependence of the total cross sections for W \u00b1 bb\u0304 production\n\u221a\nat the LHC ( s = 14 TeV) using this setup is studied in Table 5 and in Fig. 31. The NLO exclusive cross\nsection corresponds to the 2 b-jet only sample, while the inclusive one corresponds to the sum of both 2 b\njet only and 2 b jets and 1 non-b jet samples. Thus, in Fig. 31, the curve labeled as NLO Inc is the sum of\nthe curves labeled as NLO Exc and 2b + j only.\nTable 5: LO, NLO inclusive, and NLO exclusive cross sections (in fb) for W + bb\u0304 and W \u2212 bb\u0304 production\n\u221a\nat s = 14 TeV. Listed separately are also the cross sections (in fb) for the W bb\u0304 + j channel alone. The\ncentral values correspond to \u03bcr = \u03bcf = \u03bc0 , while the upper and lower bounds represent the maximal\nupper and lower variation obtained when varying \u03bcr = \u03bcf between \u03bc0 /2 and 2\u03bc0 .\nProcess\nW + bb\u0304\nW \u2212 bb\u0304\n\nLO\n138+31\n\u221224\n76+17\n\u221213\n\nNLO inclusive\n155+9\n\u221211\n90+7\n\u22127\n\nNLO exclusive\n43+17\n\u221234\n26+9\n\u221217\n\nW bb\u0304 + j\n112+42\n\u221228\n64+24\n\u221216\n\nIt is interesting to note that, contrary to the findings in Refs. [162\u2013164], in this kinematic regime\nthe inclusive cross section exhibits less scale dependence than the exclusive one. Different factors may\ncontribute to this different behavior, but mainly the kinematic cuts used in the present analysis make the\njet veto much more selective and enhance the effect of unbalanced scale dependent logarithms in the\nexclusive cross section, while their effect tends to compensate between W bb\u0304 and W bb\u0304 + j production in\nthe inclusive case.\n12.3\n\nCOMPARISON OF FIXED-ORDER AND PARTON-SHOWER RESULTS\n\nWhile the parameters used for the fixed-order LO and NLO computation were already presented in the\nprevious section, the parameters used for the matrix element computation pp \u2192 W bb\u0304 which serves as an\ninput to the parton-shower algorithm are listed in the following:\n\u2022 LO parton density functions CTEQ6L1;\n\u2022 strong coupling constant \u03b1s (MZ ) = 0.130, consistent with the PDF set used;\nq\n2 + p2\n\u2022 QCD renormalization and factorization scales both equal and set to Q = MW\nT,W ;\n\u2022 one-loop running of \u03b1s .\nThe LO matrix element computation and initial three-body phase integration is based on the AcerMC\ngenerator [165] (v. 3.5). This is then passed as an external process to Herwig (v. 6.510), which applies\nthe parton shower algorithm and produces the final state partons which are used as an input to an\ninclusive kT jet clustering algorithm with parameter R = 0.3 and with the E-invariant parton momenta\nrecombination scheme. The underlying event has been switched off during generation, while the effect of\n69\n\n\fhadronization has been removed by applying the jet clustering directly on top of the final state partons\nbefore hadronization. As opposed to the W bb\u0304 sample generated for the analysis presented in [159], the\none-loop running of \u03b1s was used instead of the two-loop running: this increased the LO cross section by\n\u2248 30 % with respect to the value used in the mentioned analysis.\nThe parton-level jets produced in this way can be compared to the fixed-order calculation described in\nSection 12.2 and will effectively include the approximative leading logarithmic resummation introduced\nby the parton shower algorithm. This involves a comparison of N produced jets with respectively the two\nor three leading jets of the LO or NLO fixed-order computation. The two b-jets are selected out of the N\njets produced by the parton shower algorithm by matching them to the two b-quarks after radiation as\ntraced in the Monte Carlo history:\n\u2206R(jet, b \u2212 quark) < 0.4.\nIn the case where more than one jet is closer to the b-quark than \u2206R = 0.4, the b-quark is associated to\nthe closest jet. As a cross-check of the eventual systematic uncertainty introduced by this choice, the\nsame procedure is applied using the b-quarks before radiation, which are produced directly by the matrix\nelement computation, and the difference in the results is found to be negligible. Finally, the leading\nadditional non b-jet in the event is defined as the jet out of the N jets produced by the parton shower which,\nafter excluding the two jets matched to the b-quarks, is the highest in transverse momentum. Events where\nonly a single jet is matched to a b-quark are thrown away; this happens typically when the two b-quarks\nare closer than \u2206R \u2248 0.3 and are therefore included into a single jet. After the jets are defined, the\nkinematic cuts defined in the previous section are applied: in the case of the cuts applied on the W boson,\nits momentum is considered after the effect of reshuffling of momenta operated by the parton shower\nalgorithm. The distributions based on the jets obtained by using the parton shower result are labeled as\nLO+PS in the next section.\nAs a cross-check, also the result of the LO matrix element computation used as input to the parton\nshower algorithm is considered in the following and is labeled as LO only. In this case the two b-quarks\npartons resulting from the ME computation are used directly for the computation of the observables\nand for the application of the cuts, except for the cut on the additional non b-jet in the event, which is\nnot applied. Both results are compared to the LO and NLO inclusive theory predictions obtained in the\nprevious section, which are labeled as LO (theory) and NLO (theory). Note that NLO (theory) includes\nboth the q q\u0304 0 initiated and qg + q\u0304g-initiated processes. For comparison with the LO+PS result which is\nbased on the q q\u0304 0 \u2192 W bb\u0304 matrix element only, we also include the NLO QCD prediction for the total\ncross section of the q q\u0304 0 -initiated process separately, denoted as NLO(q q\u0304 0 ) (theory).\n12.4\n\nRESULTS\n\nThe cross sections are listed in Table 6. The two LO predictions agree fairly well, even if the comparison is\nslightly biased by a marginally different choice of the renormalization and factorization scale between the\ntwo computations. Once the parton shower algorithm is run and the kinematic cuts are applied, including\nthe additional jet veto, the cross section turns out to be \u2248 30% lower with respect to the LO prediction.\nThe complete NLO theory prediction, on the other side, predicts a cross section which is \u2248 14% higher\nthan the same LO prediction. As a result, the parton shower prediction (LO+PS) must be rescaled by\nan inclusive K factor of 1.64 in order to normalize it to the complete NLO computation. If only the q q\u0304 0\ninitiated process is included in the NLO prediction, the inclusive K factor only amounts to 1.16. The\nuncertainty on the complete NLO cross section estimated through variations of the factorization and\nrenormalization scales by factors 1/2 and 2 is \u2248 5%. The impact of PDF uncertainties has not been\nconsidered here.\nThe impact of the NLO corrections on the shapes of the distributions of most interest for the analysis\nare shown in the following, separately for W + bb\u0304 and W \u2212 bb\u0304, in Figs. 32-41. The crucial observable is the\ndifferential ratio between the NLO and the LO+PS predictions for the variable of interest: if this ratio is\n70\n\n\fSubprocess\nW + bb\u0304\nW \u2212 bb\u0304\nSum\n\nLO\n144\n79\n223\n\nLO (theory)\n138+31\n\u221224\n76+17\n\u221213\n214+35\n\u221227\n\nLO+PS\n97\n52\n149\n\nNLO (theory)\n155+9\n\u221211\n90+7\n\u22127\n245+11\n\u221213\n\nNLO(q q\u0304 0 ) (theory)\n111+6\n\u221219\n62+4\n\u221210\n173+7\n\u221221\n\nTable 6: Central value of cross sections (in fb) obtained for the pp \u2192 W bb\u0304 process, comparing the\nfive different methods. Details about the calculation of LO (theory) and NLO (theory) can be found in\nSection 12.2.\napproximately flat, then it is possible to re-weight the Monte Carlo events produced by the parton shower\nalgorithm by a simple inclusive K factor.\nAlso the NLO to LO+PS ratios for the distributions for the pseudorapidity of the leading (Fig. 33, top)\nand subleading (Fig. 33, bottom) b-jets are relatively flat, with the NLO computation predicting the b-jets\nto be slightly more central. On the contrary the W bosons are significantly less central (Fig. 34) in the\nNLO prediction, and, as a consequence, a significant correction affects the distribution of difference in\npseudorapidity between the bb\u0304 and W boson systems, in particular at large pseudorapidities (Fig. 35).\nFor the transverse momentum of the leading b-jet (Fig. 32, top), apart from some threshold effect at\nvalues close to 100 GeV, the ratio NLO to LO+PS is relatively flat. For the transverse momentum of the\nsubleading b-jet (Fig. 32, bottom), the parton shower approximation does a perfect job and the ratio is\nperfectly flat.\nA bit problematic is the case of the transverse momentum of the W boson system (Fig. 36) and, to a\nless extent, of the bb\u0304 system (Fig. 37), where the NLO prediction is reliable towards higher transverse\nmomenta, while, close to the threshold, it starts to be sensitive to the emission of multiple soft radiation\n(large logarithms). This is more severe for the distribution of the transverse momentum of the W boson\nsystem. In both cases, the LO+PS distribution could be re-weighted at large transverse momenta according\nto the NLO prediction, while the LO+PS based distribution itself could be used to extrapolate to the region\nclose to the threshold. Correlations between the two distributions need clearly to be taken into account.\nThe parton shower algorithm is able to reproduce fairly well the shape of the distributions of the bb\u0304\ninvariant mass (Fig. 38), of the bb\u0304W invariant mass (Fig. 39) and of the distance in pseudorapidity and\nazimuthal angle of the two b-jets (Fig. 40). In the case of the bb\u0304 invariant mass, a small discrepancy is\nseen at very small invariant masses, again in the region where eventually large logarithmic corrections to\nthe NLO computation can be expected.\nFinally, the pT of additional non b-jet distribution is shown in Fig. 41. The cross section corresponding\nto the events where no additional non b-jet above 15 GeV is found is condensed in the first bin of the\ndistribution. As a general tendency, the NLO computation predicts significantly more radiation than the\nLO+PS prediction. There are two possible reasons for this:\n1. The parton shower algorithm used in this study acts on top of the LO matrix element producing\nW bb\u0304, which means that it misses all radiation where the first splitting is of the type g \u2192 gg and the\nbb\u0304 pair is produced later in the cascade, while the NLO prediction will include the case where the\nbb\u0304 is produced right after the first g \u2192 gg splitting.\n2. The NLO computation includes the process q(q\u0304)g \u2192 W bb\u0304j in the real correction term, which is\nstrongly but not completely suppressed for small pT of the additional non b-jet in the event. This is\nillustrated in Fig. 41, where we also show the theory prediction when only including the q q\u0304-initiated\nprocess.\nGiven this overall tendency, one would expect that by moving the jet veto cut at parton level from 60 GeV\nto 20 GeV (as in the cut based analysis), the K factor correcting from LO+PS to the NLO prediction\nwould move significantly from \u2248 1.6 more towards one, which would be a clear advantage for the W H\n71\n\n\fanalysis. However, this requires a reliable prediction of the transverse momentum of the additional non\nb-jet of the event down to very low transverse momenta (if compared with the hard scale of the event\nwhich is around pT (bb\u0304) \u2248 200 GeV). This is not provided by the NLO prediction, as the renormalization\nand factorization scale variation uncertainty of the exclusive 2 b-jet result reported in Table 5 of the last\nsection demonstrates. In order to get a more reliable prediction in this kinematic region, some matching\nprocedure between the parton shower and the NLO predictions is needed. Before being able to define such\na matching procedure, further studies will be needed, based on parton shower Monte Carlo algorithms\nable to include the primary g \u2192 gg splittings (available in plain Herwig by using the pp \u2192 W g matrix\nelement), which would lead to a complete leading logarithmic prediction, or able to include the additional\nq(q\u0304)g \u2192 W bb\u0304j process, as Alpgen [64] (which however does not include the primary g \u2192 gg splittings).\nThe use of these two algorithms will in fact allow to disentangle the two previously enumerated effects.\n12.5\n\nCONCLUSIONS\n\nWe have compared the NLO computation for the W bb\u0304 process with the predictions of the Herwig parton\nshower algorithm applied on top of the LO W bb\u0304 matrix element, considering for the first time the\nspecific kinematic region explored by the high pT W H analysis and the effect of an additional non b-jet\nveto (applied at parton level) of 60 GeV. Given the choice of PDFs, of strong coupling constant and\nrenormalization and factorization scales already mentioned, we find that the cross section predicted by the\nNLO computation is a factor \u2248 1.6 higher than the parton shower prediction. Many of the differential\ndistributions predicted by the parton shower algorithm agree reasonably well with the NLO computation.\nIn general, the increase in event yield due to the NLO correction can be decreased by further lowering the\njet veto: however, the NLO prediction suffers from substantial uncertainties in the kinematic region where\nradiation significantly softer than the scale of the process occurs and further studies are ongoing to make\nthe prediction more reliable.\n\n72\n\n\f0.2\n\n+\n\n\u03c3(W bb)\n\n0.15\n\n0.1\n\nLO\nNLO Inc\nNLO Exc\n2b+j only\n\n0.05\n\n0\n\n0.6\n\n0.8\n\n1\n\n1.2\n\u03bc/\u03bc0\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n1\n\n1.2\n\u03bc/\u03bc0\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n0.1\n\n0.06\n\n-\n\n\u03c3(W bb)\n\n0.08\n\nLO\nNLO Inc\nNLO Exc\n2b+j only\n\n0.04\n\n0.02\n\n0\n\n0.6\n\n0.8\n\nFig. 31: Renormalization and factorization scale dependence for the parton level W + bb\u0304 (upper plot)\nand W \u2212 bb\u0304 (lower plot) LO (black, solid), NLO inclusive (red, solid), NLO exclusive (blue, solid) and\nW bb\u0304 + j (blue, dashed) production cross sections (cross sections are in pb). See Section 12.2 for details.\n\n73\n\n\f\u2212\n\nW bb\n\nt\n\nt\n\n1\n\n1\n\nd\u03c3/dp [fb/GeV]\n\nd\u03c3/dp [fb/GeV]\n\nW+ b b\n\n\u22121\n\n10\n\nNLO / [LO+PS]\n\n10\u22121\n\n3.50\n\n50\n\n100\n\n150\n\n200\n\n250\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n300\n\n350\n\nNLO / [LO+PS]\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n400\n\n3\n2.5\n2\n\n3.50\n\n100\n\n150\n\n200\n\n250\n\n50\n\n100\n\n150\n\n200\n\n250\n\n350\n\n400\n\n300\n\n350\n\n400\n\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n350\n\n0\n0\n\n400\n\nb,l\n\nb,l\n\nLeading b\u2212Jet p [GeV]\n\nLeading b\u2212Jet p [GeV]\nt\n\nd\u03c3/dp [fb/GeV]\n\nt\n\nd\u03c3/dp [fb/GeV]\n\n300\n\n2.5\n\n1.5\n\n0\n0\n\n50\n\n3\n\nW+ b b\n\n1\n\n\u2212\n\nW bb\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\nt\n\nt\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n1\n\n\u22121\n\n10\n\n\u22121\n\n10\n\n10\u22122\n\u22122\n\n10\n\n\u22123\n\n10\n10\n\n3.50\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n350\n\n400\n\n3\n2.5\n2\n1.5\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n\u22123\n\n3.50\n\n100\n\n150\n\n200\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n350\n\n250\n\n300\n\n350\n\n400\n\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n0\n\n50\n\n3\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n350\nb,sl\n\nSubleading b\u2212Jet p\n\nt\n\n400\n\n0\n0\n\nb,sl\n\n[GeV]\n\nSubleading b\u2212Jet p\n\nt\n\n400\n\n[GeV]\n\nFig. 32: Transverse momentum distribution of the leading and sub-leading b jet, for both W + bb\u0304 and\nW \u2212 bb\u0304 production. The lower window shows the ratio of NLO to LO+PS predictions (full line) together\nwith the ratio between the two LO predictions (dashed line).\n\n74\n\n\fd\u03c3/d\u03b7 [fb/ \u2206 \u03b7]\n\nd\u03c3/d\u03b7 [fb/ \u2206 \u03b7]\n\nW+ b b\n\n40\n35\n30\n25\n\n\u2212\n\nW bb\n\n25\n\n20\n\n15\n\n20\n10\n\n15\nLO+Parton Shower\nLO only\n\n10\n\n\u22122\n\n\u22121\n\n0\n\nLO (theory)\nNLO (theory)\n\n1\n\n2\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n0\n\n3.5\u22123\n\n3\n\n3\n2.5\n2\n1.5\n\n0\n\n3.5\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n3\n\n2\n\n3\n\n2.5\n2\n1.5\n\n1\n\n1\n0.5\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n0\n\u22123\n\n3\n\nLeading b\u2212Jet \u03b7\n\nLeading b\u2212Jet \u03b7\n\nb,l\n\nd\u03c3/d\u03b7 [fb/ \u2206 \u03b7]\n\nb,l\n\nd\u03c3/d\u03b7 [fb/ \u2206 \u03b7]\n\n2\n\n3\n\n0.5\n0\n\u22123\n\nLO+Parton Shower\nLO only\n\n5\n\nLO (theory)\nNLO (theory)\n\n5\n\nW+ b b\n\n40\n35\n\n\u2212\n\n25\n\nW bb\n\n20\n\n30\n25\n\n15\n\n20\n10\n\n15\nLO+Parton Shower\nLO only\n\n10\n\n0\n\n3.5\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n5\n\n3\n\n3\n2.5\n2\n1.5\n\n0\n\n3.5\u22123\n\nLO (theory)\nNLO (theory)\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n3\n\n3\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n\u22123\n\nLO+Parton Shower\nLO only\n\n5\n\nLO (theory)\nNLO (theory)\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n0\n\u22123\n\n3\n\nSubleading b\u2212Jet \u03b7\n\n2\n\n3\n\nSubleading b\u2212Jet \u03b7\n\nb,sl\n\nb,sl\n\nFig. 33: Pseudorapidity distribution of the leading and sub-leading b jet, for both W + bb\u0304 and W \u2212 bb\u0304\nproduction. The lower window shows the ratio of NLO to LO+PS predictions (full line) together with the\nratio between the two LO predictions (dashed line).\n\n75\n\n\fd\u03c3/d\u03b7 [fb/ \u2206 \u03b7]\n\nd\u03c3/d\u03b7 [fb/ \u2206 \u03b7]\n\n35\n\nW+ b b\n\n30\n25\n\n22\n\n\u2212\n\nW bb\n\n20\n18\n16\n14\n\n20\n\n12\n10\n\n15\n\n8\n\nNLO / [LO+PS]\n\n5\n0\n\n3.5\u22123\n\n\u22122\n\n\u22121\n\nLO+Parton Shower\nLO only\n\n6\n\nLO+Parton Shower\nLO only\n\nLO (theory)\nNLO (theory)\n\n4\n\nLO (theory)\nNLO (theory)\n\n2\n\n0\n\n1\n\n2\n\nNLO / [LO+PS]\n\n10\n\n3\n\n3\n2.5\n2\n1.5\n\n0\n\n3.5\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n3\n\n3\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n0\n\u22123\n\n3\n\n3\n\n\u03b7W\n\n\u03b7W\n\nd\u03c3/d\u2206\u03b7(bb,W) [fb/ \u2206 \u03b7]\n\nd\u03c3/d\u2206\u03b7(bb,W) [fb/ \u2206 \u03b7]\n\nFig. 34: Pseudorapidity distribution of the W vector boson for both W + bb\u0304 and W \u2212 bb\u0304 production. The\nlower window shows the ratio of NLO to LO+PS predictions (full line) together with the ratio between\nthe two LO predictions (dashed line).\n\nW+ b b\n\n45\n40\n35\n30\n25\n\n\u2212\n\nW bb\n25\n\n20\n\n15\n\n20\n10\n\n15\nLO+Parton Shower\nLO only\n\n10\n\n0\n\n\u22123\n\n\u22122\n\n\u22121\n\n0\n\nLO (theory)\nNLO (theory)\n\n1\n\n2\n\n3\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n5\n3.5\u22124\n\n4\n\n3\n2.5\n2\n1.5\n\n0\n\n3.5\u22124\n\n\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n3\n\n4\n\n3\n\n4\n\n3\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n\u22124\n\nLO+Parton Shower\nLO only\n\n5\n\nLO (theory)\nNLO (theory)\n\n\u22123\n\n\u22122\n\n\u22121\n\n0\n\n1\n\n2\n\n3\n\n0\n\u22124\n\n4\n\n\u2206 \u03b7(bb,W)\n\n\u2206 \u03b7(bb,W)\n\nFig. 35: Pseudorapidity difference distribution of the 2 b-jet system and W boson for both W + bb\u0304 and\nW \u2212 bb\u0304 production. The lower window shows the ratio of NLO to LO+PS predictions (full line) together\nwith the ratio between the two LO predictions (dashed line).\n\n76\n\n\fd\u03c3/dp W [fb/GeV]\n\nd\u03c3/dp W [fb/GeV]\n\n\u2212\n\nW bb\n\n1\n\nt\n\nt\n\nW+ b b\n\n1\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n10\u22121\n\n3.5\n150\n\n200\n\n250\n\n300\n\n350\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n10\u22121\n400\n\n3\n2.5\n2\n\n3.5\n150\n\n200\n\n250\n\n300\n\n350\n\n200\n\n250\n\n300\n\n350\n\n400\n\n3\n2.5\n2\n\n1.5\n\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n150\n\n200\n\n250\n\n300\n\n350\n\n0\n150\n\n400\n\n400\n\npW [GeV]\n\npW [GeV]\n\nt\n\nt\n\n[fb/GeV]\nbb\n\n\u2212\n\nW bb\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\nd\u03c3/dp\n\nt\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n1\n\nt\n\nW+ b b\n1\n\nd\u03c3/dp\n\nbb\n\n[fb/GeV]\n\nFig. 36: Transverse momentum distribution of the W vector boson for both W + bb\u0304 and W \u2212 bb\u0304 production.\nThe lower window shows the ratio of NLO to LO+PS predictions (full line) together with the ratio between\nthe two LO predictions (dashed line).\n\n\u22121\n\n10\n\u22121\n\n10\n\n10\u22122\n10\n3.5\n150\n\n200\n\n250\n\n300\n\n350\n\n400\n\n450\n\n500\n\n550\n\n600\n\n3\n2.5\n2\n1.5\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n\u22122\n\n3.5\n150\n\n250\n\n300\n\n350\n\n400\n\n450\n\n500\n\n200\n\n250\n\n300\n\n350\n\n400\n\n450\n\n500\n\n550\n\n600\n\n550\n\n600\n\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n150\n\n200\n\n3\n\n200\n\n250\n\n300\n\n350\n\n400\n\n450\n\n500\n\n550\n\n600\n\npbb [GeV]\n\n0\n150\n\npbb [GeV]\n\nt\n\nt\n\nFig. 37: Transverse momentum distribution of the 2 b-jet system for both W + bb\u0304 and W \u2212 bb\u0304 production.\nThe lower window shows the ratio of NLO to LO+PS predictions (full line) together with the ratio between\nthe two LO predictions (dashed line).\n\n77\n\n\fd\u03c3/dmbb [fb/GeV]\n\nd\u03c3/dmbb [fb/GeV]\n\nW+ b b\n1\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n\u2212\n\n1\n\nW bb\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n\u22121\n\n10\n\u22121\n\n10\n\n10\u22122\n\n3.50\n\n50\n\n100\n\n150\n\n200\n\n250\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n\u22122\n\n10\n\n300\n\n3\n2.5\n2\n\n3.50\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n3\n2.5\n2\n\n1.5\n\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n0\n\n50\n\n100\n\n150\n\n200\n\n250\n\n0\n0\n\n300\n\nmbb [GeV]\n\nmbb [GeV]\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\nd\u03c3/dmbbW [fb/GeV]\n\nd\u03c3/dmbbW [fb/GeV]\n\nFig. 38: Invariant mass distribution of the 2 b-jet system for both W + bb\u0304 and W \u2212 bb\u0304 production. The\nlower window shows the ratio of NLO to LO+PS predictions (full line), together with the ratio between\nthe two LO predictions (dashed line).\n\nW+ b b\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n\u2212\n\nW bb\n\n\u22121\n\n10\n\n\u22121\n\n3.5\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n900\n\n1000\n\n3\n2.5\n2\n1.5\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n10\n\n3.5\n100\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n900\n\n1000\n\n900\n\n1000\n\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n100\n\n200\n\n3\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n900\n\n1000\n\nmbbW [GeV]\n\n0\n100\n\nmbbW [GeV]\n\nFig. 39: Invariant mass distribution of the 2 b-jet plus W system for both W + bb\u0304 and W \u2212 bb\u0304 production.\nThe lower window shows the ratio of NLO to LO+PS predictions (full line), together with the ratio\nbetween the two LO predictions (dashed line).\n\n78\n\n\fd\u03c3/dR(bb) [fb/ \u2206 R]\n\nd\u03c3/dR(bb) [fb/ \u2206 R]\n\n350\n\nW+ b b\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n300\n250\n\n220\n\u2212\n\nW bb\n\n200\n180\n\nLO+Parton Shower\nLO only\nLO (theory)\nNLO (theory)\n\n160\n140\n120\n\n200\n\n100\n150\n\n80\n60\n\n100\n\n40\n50\n\n20\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n0\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n0\n\n3.50\n\n2\n\n3\n2.5\n2\n\n3.50\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n2.5\n2\n\n1.5\n\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n0\n\n0.2\n\n3\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n0\n0\n\n2\n\ndRbb\n\n2\n\ndRbb\n\n[fb/GeV]\nnon\u2212b\n\n\u2212\n\nW bb\nLO+Parton Shower\nLO (theory)\nLO only qq (theory)\n\nd\u03c3/dp\n\nt\n\nLO+Parton Shower\nLO (theory)\nLO only qq (theory)\n\n10\n\nt\n\nW+ b b\n\n10\n\nd\u03c3/dp\n\nnon\u2212b\n\n[fb/GeV]\n\nFig. 40: Relative distance distribution of the 2 b-jet system for both W + bb\u0304 and W \u2212 bb\u0304 production. The\nlower window shows the ratio of NLO to LO+PS predictions (full line), together with the ratio between\nthe two LO predictions (dashed line).\n\n1\n\n1\n\n\u22121\n\n10\n\u22121\n\n3.50\n\n20\n\n40\n\n60\n\n80\n\nNLO / [LO+PS]\n\nNLO / [LO+PS]\n\n10\n\n100\n\n3\n\nincluding qg\nonly qq\n\n2.5\n2\n1.5\n\n3.50\n\n40\n\n60\n\n80\n\n100\n\nincluding qg\nonly qq\n\n2.5\n2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n0\n\n20\n\n3\n\n20\n\n40\n\n60\n\n80\n\n0\n0\n\n100\n\npnon\u2212b [GeV]\n\n20\n\n40\n\n60\n\n80\n\n100\n\npnon\u2212b [GeV]\n\nt\n\nt\n\nFig. 41: Transverse momentum distribution of the non b-jet for both W + bb\u0304 + j and W \u2212 bb\u0304 + j production.\nThe lower window shows the ratio of LO to LO+PS prediction (dashed line including only the q q\u0304 0 \u2192 W bb\u0304j\nprocess in the LO computation, full line including also the q(q\u0304)g \u2192 W bb\u0304j process). Although the cross\nsection for W bb\u0304 + j production is a LO result, it is calculated as part of the real corrections with the\nCTEQ6M set of PDFs and two-loop evolution of \u03b1s .\n\n79\n\n\fPart IV\n\nOBSERVABLES AND DETECTORS\n13.\n\nDELPHES, A FRAMEWORK FOR FAST SIMULATION OF A GENERIC COLLIDER\nEXPERIMENT24\n\n13.1\n\nINTRODUCTION\n\nMultipurpose detectors at high energy colliders are very complex systems. Their simulation is in general\nperformed by means of the G EANT [166] package and final observables used for analyses usually require\nsophisticated reconstruction algorithms. This complexity is handled by large collaborations, and data and\nthe expertise on reconstruction and simulation software are only available to their members. Precise data\nanalyses require a full detector simulation, including transport of the primary and secondary particles\nthrough the detector material accounting for the various detector inefficiencies, the dead material, the\nimperfections and the geometrical details. Such a simulation is very complicated, technical and requires a\nlarge CPU power. On the other hand, phenomenological studies, looking for the observability of given\nsignals, may require only fast but realistic estimates of the expected signal signatures and their associated\nbackgrounds.\nThe D ELPHES [167] framework has been designed for the fast simulation of a general-purpose collider\nexperiment. Using this framework, observables such as cross-sections and efficiencies after event\nselection can be estimated for specific reactions. Starting from the output of event generators (e.g. Les\nHouches Event File or HepMC), the simulation of the detector response takes into account the subdetector\nresolutions, by smearing the kinematics of final-state particles.\nD ELPHES includes the most crucial experimental features, such as: the geometry of both central and\nforward detectors, the effect of magnetic field on tracks, the reconstruction of photons, leptons, jets, b-jets,\n\u03c4 -jets and missing transverse energy, a lepton isolation, a trigger emulation and an event display. Several\ncommon datafile formats can be used as input in D ELPHES, in order to process events from many different\ngenerators.\n13.2\n\nSIMULATION OF THE DETECTOR RESPONSE\n\nThe overall layout of the multipurpose detector simulated by D ELPHES consists in a central tracking\nsystem surrounded by an electromagnetic and a hadron calorimeters (ECAL and HCAL, each with a central\nregion and two endcaps) and two forward calorimeters (FCAL, with separate electromagnetic and hadronic\nsections). Finally, a muon system encloses the central detector volume. In addition, possible very forward\ndetectors are also simulated, like zero-degree calorimeters (ZDC) and very forward taggers. Even if\nD ELPHES has been developed for the simulation of general-purpose detectors at the LHC (namely, C MS\nand ATLAS), it allows a flexible parametrisation for other cases, e.g. at future linear colliders.\nMagnetic field, tracks and calorimetric cells\nThe effects of a central solenoidal magnetic field are simulated. Every stable charged particle with a\ntransverse momentum above some threshold and lying inside the tracker has a probability to yield a\nreconstructed track. The calorimeters are segmented into cells in the (\u03b7, \u03c6), with variable sizes. The\nresponse of calorimeters to energy deposits of incoming particles depends on their resolution and on the\nnature of the particles. The assumed calorimeter characteristics are not isotropic, with typically finer\nenergy resolution and granularity in the central region [168, 169]. Their resolution is parametrised through\na Gaussian smearing of the accumulated cell energy.\n24\n\nContributed by: S. Ovyn, X. Rouby\n\n80\n\n\fElectrons and photons leave their energy in the electromagnetic parts of the calorimeters (ECAL and\nFCAL , e.m.) only, while charged and neutral final-state hadrons interact with the hadronic parts ( HCAL\nand FCAL, had.). Some long-living particles, such as the Ks0 and \u039b's, with lifetime c\u03c4 smaller than\n10 mm are considered as stable particles by the generators although they may decay before reaching the\ncalorimeters. The energy smearing of such particles is therefore performed using the expected fraction of\nthe energy, determined according to their decay products, that would be deposited into the ECAL and the\nHCAL . Muons, neutrinos and hypothetical neutralinos are assumed not to interact with the calorimeters.\nAt last, the muon systems provide a measurement of the true muon kinematics, with a smeared transverse\nmomentum.\nForward detectors\nMost of the recent experiments in beam colliders have additional instrumentation along the beamline.\nThese extend the \u03b7 coverage to higher values, for the detection of very forward final-state particles. In\nD ELPHES, zero-degree calorimeters, roman pots and forward taggers have been implemented, similarly to\nthe plans for C MS and ATLAS collaborations [168, 169].\nThe ZDCs allow the measurement of stable neutral particles (\u03b3 and n) coming from the interaction\npoint (IP), with large pseudorapidities. The trajectory of the neutrals observed in the ZDCs is a straight\nline, while charged particles are deflected away from their acceptance window by the powerful magnets\nlocated in front of them. In their implementation in D ELPHES, the ZDCs provide a measurement of the\ntime-of-flight of the particle, from the IP to the detector location. The simulated ZDCs are composed of an\nelectromagnetic and a hadronic sections, for the measurement of photons and neutrons, respectively. The\nZDC hits do not enter in the calorimeter cell list used for reconstruction of jets and missing transverse\nenergy. The fact that additional charged particles may enter the ZDC acceptance is neglected in the current\nversions of D ELPHES.\nForward taggers, located very far away from the IP, are meant for the measurement of scattered particles\nfollowing very closely the beam path. To be able to reach these detectors, particles must have a charge\nidentical to the beam particles and a momentum very close to the nominal value of the beam. These taggers\nare near-beam detectors located a few millimetres from the true beam trajectory and this distance defines\ntheir acceptance. This fast simulation uses the H ECTOR software [170], which includes the chromaticity\neffects and the geometrical aperture of the beamline elements of any arbitrary collider. Forward taggers\nare able to measure the hit positions and angles in the transverse plane at the location of the detector,\nas well as the time-of-flight. Out of these, the particle energy and the momentum transfer it underwent\nduring the interaction can be reconstructed at the analysis level.\n13.3\n\nHIGH-LEVEL OBJECT RECONSTRUCTION\n\nThe results of the detector simulation are output in a file storing for each event its tracks, calorimetric cells\nand hits in the very forward detectors. In addition, collections of final particles (e\u00b1 , \u03bc\u00b1 , \u03b3) and objects\n(light jets, b-jets, \u03c4 -jets, ETmiss ) are provided. While electrons, muons and photons are easily identified,\nother quantities are more difficult to evaluate as they rely on sophisticated algorithms (e.g. jets or missing\nenergy). For most of these objects, their four-momentum and related quantities are directly accessible in\nD ELPHES output (E, p~, pT , \u03b7 and \u03c6).\nIdentification of electrons, photons and muons\nReal electron (e\u00b1 ) and photon candidates are associated to the final-state collections if they fall into the\nacceptance of the tracking system and have a transverse momentum above some threshold. Assuming a\ngood measurement of the track parameters in the real experiment, the electron energy can be reasonably\nrecovered. D ELPHES assumes a perfect algorithm for clustering and bremsstrahlung recovery. Electron\nenergy is smeared according to the resolution of the calorimetric cell where it points to, but independently\n81\n\n\ffrom any other deposited energy is this cell. Electrons and photons may create a candidate in the jet\ncollection.\nGenerator-level muons (\u03bc\u00b1 ) entering the muon system acceptance and overpassing some threshold\nare considered as good candidates for analyses. The application of the detector resolution on the muon\nmomentum depends on a Gaussian smearing of the pT . Neither \u03b7 nor \u03c6 variables are modified beyond the\ncalorimeters: no additional magnetic field is applied. Multiple scattering is neglected. This implies that\nlow energy muons have in D ELPHES a better resolution than in a real detector.\nTo improve the quality of the contents of the charged lepton collections, isolation criteria can be applied.\nThis requires that electron or muon candidates are isolated in the detector from any other particle, within a\ngiven cone in the (\u03b7,\u03c6) plane. The isolation algorithm is based on tracker data, but in addition the sum of\nthe transverse momenta of all tracks but the lepton one within the isolation cone is provided, as well an\nestimate based on calorimeter data.\nJet reconstruction\nA realistic analysis requires a correct treatment of partons which have hadronised. Therefore, the most\nwidely currently used jet algorithms have been integrated into the D ELPHES framework using the FAST J ET\ntool [171]. For all jet algorithms, the calorimetric cells are used as inputs. Since several particles can\nleave their energy into a given calorimetric cell, which broadens the jet energy resolution, a jet energy\nflow algorithm can be switched on in D ELPHES. This takes into account the measured properties of tracks\npointing to the calorimetric cells of interest for the jet reconstruction.\nA jet is tagged as a b-jet if its direction lies in the acceptance of the tracker and if it is associated to a\nparent b-quark. This identification procedure for the b-tag is based on the true generator-level identity of\nthe most energetic parton within a cone around the (\u03b7, \u03c6) region, with a radius equal to the one used to\nreconstruct the jet. Jets originating from \u03c4 -decays are identified using a procedure consistent with the one\napplied in a full detector simulation [168]. The tagging relies on the two following properties of the \u03c4\nlepton. First, 77% of the \u03c4 hadronic decays contain only one charged hadron associated to a few neutrals.\nSecondly, the particles arisen from the \u03c4 lepton produce narrow jets in the calorimeter.\nMissing transverse energy\nThe true missing transverse energy (MET), i.e. at generator-level, is calculated as the opposite of the vector\nsum of the transverse momenta of all visible particles. In a real experiment, calorimeters measure energy\nand not momentum. Any problem affecting the detector (dead channels, misalignment, noisy cells, cracks)\nworsens directly the measured missing transverse energy. In D ELPHES, MET is based on the calorimetric\ncells only. Muons and neutrinos are therefore not taken into account for its evaluation. However, as muon\ncandidates, tracks and calorimetric cells are available in the output file, the missing transverse energy can\nalways be reprocessed a posteriori with more specialised algorithms.\nTrigger emulation\nMost of the usual trigger algorithms select events containing leptons, jets, and MET with an energy scale\nabove some threshold. A trigger emulation is included in D ELPHES, using a fully parametrisable trigger\ntable, also allowing logical combinations of several conditions on the final analysis data.\n13.4\n\nASSUMED SIMPLIFICATIONS FOR THE FAST SIMULATION\n\nD ELPHES is a fast simulation aiming at providing quickly realistic observables. It relies on several\nhypotheses and simplifications that allows the use of less sophisticated algorithms than in real experiments,\nbut aims at reaching the same detection, identification and reconstruction performances. Since the\nframework design relies on the expectations of the real detector performances, detector geometry is\n\n82\n\n\fidealised: being uniform, symmetric around the beam axis, and having no cracks nor dead material.\nSecondary interactions, multiple scatterings, photon conversion and bremsstrahlung are also neglected.\nNo longitudinal segmentation is available in the simulated calorimeters. D ELPHES assumes that ECAL\nand HCAL have the same segmentations and that the detector is symmetric with respect to the \u03b7 = 0\nplane and around the beam axis. A particle entering a calorimetric cell deposes all its energy, even if it\nenters very close to its geometrical edge. Particles other than electrons (e\u00b1 ), photons (\u03b3), muons (\u03bc\u00b1 ),\nneutrinos (\u03bde , \u03bd\u03bc and \u03bd\u03c4 ) and hypothetical neutralinos are simulated as hadrons for their interactions\nwith the calorimeters. The simulation of stable particles beyond the Standard Model should therefore be\nhandled with care.\nThe electron, photon and muon collections contain only real candidates. For instance, the particles\nwhich might leak out of the calorimeters into the muon system (punch-through) are not considered as\nmuon candidates in D ELPHES. However, fake candidates can be added into the collections at the analysis\nlevel, when processing D ELPHES output data.\nIn current version of D ELPHES, the displacement of secondary vertices is not simulated, in particular\nfor b-jets. Extra hits coming from the beam-gas events or secondary particles hitting the beampipe in\nfront of the forward detectors are not taken into account. At last, real triggers are intrinsically based on\nreconstructed data with a worse resolution than final analysis data. In D ELPHES, the same data are for\ntrigger emulation and for final analyses.\n13.5\n\nIMPROVEMENTS AND PERSPECTIVE\n\nAs a consequence of the fruitful discussions and collaboration during and after the Les Houches workshop,\nseveral improvements have been identified for the developments in D ELPHES. The b-jet algorithm will be\nimproved by adding a dependence of the tagging efficiencies with respect to the jet transverse momentum.\nIn current versions of D ELPHES, the probabilities for b-tag or mistag are uniforms, which underestimates\nthe actual performances of the real experiments. The \u03c4 -jet collection will allow 3-prong \u03c4 's. Local\ndetector inefficiency maps might also be implemented, as well as an improved interface to HepMC that\nwould allow an easy connection to tools like Rivet [46].\nCONCLUSIONS\nD ELPHES is a framework offering fast simulation tools allowing to investigate quickly new models and\ncheck their signatures in a realistic detection environment. It offers an intermediate step between simplified\nparton-level analysis and extensive analyses using the full-simulation power in large collaborations.\nACKNOWLEDGEMENTS\nX Rouby would like to thank S Schumann, F Moortgat and F Maltoni for their support in the participation\nto the Les Houches workshop. S Ovyn and X Rouby are happy to thank the numerous Les Houches\nparticipants who have shown their interest in D ELPHES, leading to very interesting and fruitful discussions\nand exchanges.\n\n83\n\n\fEFFECT OF QED FSR ON MEASUREMENTS OF Z/\u03b3\u2217 AND W LEPTONIC FINAL\nSTATES AT HADRON COLLIDERS 25\n\n14.\n14.1\n\nIntroduction\n\nDue to its simple quantum structure and clean experimental signature, quark-antiquark annihilation to\nlepton pairs (Drell-Yan), is one of the most important channels in hadron collider physics. In this paper\nwe shall discuss some requirements that must be met, at the observable level, when using information\nobtained from the final-state leptons in this process. The emphasis on \"observable level\" is particularly\nimportant; if information about states that are not themselves directly observable, such as the Z boson or\na \"bare\" lepton in a Monte Carlo event record, is used for correcting or calibrating the raw measurement,\nthen the precision of the corrected/calibrated result will suffer from an intrinsic ambiguity which was not\npresent in the raw measurement, i.e., the result will have been degraded.\nWe discuss the cause and magnitude of this degradation and argue that the experimental corrections\nand calibrations can equally well be performed without using such information, hence preserving the full\nprecision of the raw measurement in the calibrated result.\nTo illustrate our conclusions and to aid future studies, we examine various possible observable definitions and present a collection of reference comparisons for the Tevatron processes pp\u0304 \u2192 Z/\u03b3 \u2217 \u2192 e+ e\u2212\nand pp\u0304 \u2192 Z/\u03b3 \u2217 \u2192 \u03bc+ \u03bc\u2212 . These same concerns apply to the equally important W signal, which we also\nconsider.\n14.2\n\nMonte Carlo Truth\n\nCalculations of collider physics processes rely heavily on factorizations of the full transition amplitudes\n(squared) into smaller, more manageable, pieces. These factorizations are typically formally correct in\nlimits in which one single Feynman diagram dominates over all others, in which case the system has a\nwell-defined \"semi-classical\" history, represented by the single dominant diagram. The individual pieces\ncan then be treated as approximately independent since the quantum mechanical interference between\nthem can be neglected in this limit.\nEssentially, what event generators, such as Herwig, Pythia, and Sherpa, provide as intermediate particles\nin their event records (\"Monte Carlo truth\") are representations of such semi-classical histories. At the\nvery least, these histories show how the generator approximated the process so far (which may, in turn,\nfurnish important boundary conditions on subsequent generation steps). But even in the best case scenario,\nwhen the diagram represented by the event record really is the dominant one, it is still only exact when all\nother diagrams are zero, i.e., in the semi-classical limit. Therefore, any procedure (such as a correction\napplied to an experimental measurement) that depends on history-information is only well-defined in that\nlimit. At the quantum level, it would suffer from an irremovable ambiguity which would set an ultimate\nlimit to the precision that could be obtained with that procedure.\nLet us consider the Drell-Yan process in more detail. For this process, e.g., the event record of the\nPythia generator will contain an intermediate Z boson. This is intended to tell the user that the lepton\npair comes from an s-channel diagram (which in fact includes the full Z/\u03b3 \u2217 interference), and it also lets\nPythia's parton shower know that the invariant mass of the lepton pair should be preserved in the shower.\nSo far so good. If QED radiation was not an issue, this intermediate Z boson is identical to the sum of the\nfinal-state lepton pair, and it is therefore tempting to use this boson, even in the presence of QED effects,\nto define some kind of Monte-Carlo-truth / generator-level / QED-corrected / ... \"Z/\u03b3 \u2217 \". However, when\nincluding QED effects, diagrams with photons emitted in the initial state will interfere with diagrams\nthat have them emitted in the final state. Therefore, we cannot, at the amplitude-squared level, determine\nwhether a given photon was initial- or final-state radiation, not even statistically. However, the two cases\ncorrespond to different semi-classical histories, with different \"Z/\u03b3 \u2217 \" kinematics, and therefore any\n25\n\nContributed by: A. Buckley, G. Hesketh, F. Siegert, P. Skands, M. Vesterinen, T.R. Wyatt\n\n84\n\n\fsemi-classical \"Z/\u03b3 \u2217 \" definition would at least be ambiguous up to the size of the initial-final interference\nterms.\nAnother manifestation of the same basic problem is to do with the identification of which leptons came\nfrom the Z/\u03b3 \u2217 decay, in an event with multiple leptons. Again, a correction procedure that would depend\non Monte Carlo truth for this identification would be fundamentally ambiguous at least up to interference\nterms between diagrams with different assignments.\nFinally, there is the issue of how to define a lepton. Especially electrons, which are close to massless,\nemit large amounts of near-collinear photon bremsstrahlung. The final-state electron in a Monte Carlo\nevent record is therefore not a uniquely defined object (it depends, for instance, on if/how electron mass\neffects are implemented in that Monte Carlo). As we argued above, the electron \"before\" QED radiation\nis also not well-defined, since the electron interferes with other particles. And in any case it would\nbe a mere coincidence if either object bears much resemblance to what might be called an electron in\nan experimental setting (to be discussed further below). It is therefore also crucial to operate with an\nunambiguous and collinear safe \"lepton definition\".\nWhat we shall argue below is that such ambiguities are in fact both present and large for precision\nmeasurements of current interest. It is therefore important to reiterate that the full experimental precision is\nonly preserved if the observables and correction procedures are defined entirely in terms of the final-state\nleptons, with these in turn defined in a way that is collinear safe against photon emission.\n14.3\n\nDefinitions\n\nIn previous measurements of the kinematics of the Drell-Yan process, the reconstructed data have typically\nbeen corrected to the \"Z/\u03b3 \u2217 \" boson level. This correction process can be broken into three steps:\n1. Correcting the measurement leptons to the level of particles entering the detector (\"unfolding\" the\ndetector resolution and efficiency).\n2. Correcting from the particles entering the detector to the \"Z/\u03b3 \u2217 \".\n3. Correcting from the measured phase space to 4\u03c0 acceptance, with no selection cuts except on the\n\"Z/\u03b3 \u2217 \" mass.\nAs outlined in the previous Section, Step 2 introduces ambiguities and dependencies on the model\nused to simulate Drell-Yan and FSR. Step 3 involves correcting for particles that were unmeasured, so\nexplicitly depend on a model of those particles. We therefore propose that all measurements be made\navailable after Step 1: corrected only for detector resolution and efficiency. Steps 2 and 3 may of\ncourse be performed in addition, subject to problems discussed above.\nIn order to perform Step 1, we must define the \"electron\" and \"muon\" observables in terms of the\nparticles that enter the detector, accounting for the different detector response in each case. We then\nconsider how to form the \"Z/\u03b3 \u2217 \" from those electrons and muons, and briefly discuss missing energy and\na \"W \" final state. We therefore propose these definitions:\n\u2022 In simulated events, we consider all generator level particles with c\u03c4 > 10 mm as \"stable\" [1] (i.e.\ncould possibly be detected). Only the stable particles may be used to define an observable, and no\nchecks should be placed on the internal generator origin of any particles (no history dependence).\n\u2022 Electrons: to mimic the response of a calorimeter, electrons and photons must be combined into\nan localized \"EM cluster\", and such clustersp\nconsidered as particle level electrons. Here, this\nclustering is done with simple cones of \u2206R = (\u2206\u03c6)2 + (\u2206\u03b7)2 =0.2 around any electron26 . Thus\nany narrow angle QED FSR is combined back into the electron, which may also pick up some\nadditional electromagnetic energy from the underlying event. Any wider angle FSR is \"lost\": i.e.\nnot associated with the electron.\n26\n\nThis simple cone clustering is sufficient to reproduce observable electrons at the Tevatron experiments. For the LHC\nexperiments, a different cone size or more advanced clustering algorithm (e.g. anti-kT ) may better reproduce the detector level\nobservable. Ideally, the same particle level electron definition can be agreed upon for all LHC experiments.\n\n85\n\n\fd\u03c3/dE\u22a5 [pb/GeV]\n\n\u2022 Muons: the stable muons (i.e. after FSR) can be considered directly, as would be measured in the\ntracking system of a detector. Thus, all FSR is lost, and the underlying event has no effect.\n\u2022 Missing transverse energy (MET): in data this is typically calculated by inverting the vector sum of\ncalorimeter ET and muon pT , introducing many detector acceptance and efficiency effects which\nare difficult to reproduce at particle level. To initiate discussion, we define the MET simply from\nthe vector sum of all neutrinos in the event, which is compared to the pT of only the the W neutrino\nin Fig. 42.\n\u2022 Z/\u03b3 \u2217 : selections should follow the data analysis. Typically, this will mean considering all electrons\nor muons within a given |\u03b7| range, then forming opposite charge pairs that lie within the required\ndi-lepton mass window (e.g. 65-115 GeV). In the (rare) cases where two possible pairs pass these\nselections, the method used to select the \"best\" should again follow the data analysis, such as the\npair closest to the Z mass.\n\u2022 W : again, selections should follow data analysis. This will typically mean combining the MET\nwith the highest pT lepton, then placing some requirement on transverse mass.\nmiss\nE\u22a5\nMC truth E\u22a5 (\u03bd)\n\n10 1\n\n1\n\nMC/data\n\n10\u22121\n\n1.6\n1.4\n1.2\n1\n0.8\n0.6\n0.4\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\nE\u22a5 [ GeV ]\n\nFig. 42: Comparing the pT of the neutrino from a W decay to the particle level MET (defined in the text).\nWhen defining the Z/\u03b3 \u2217 and W observables, three further selections are typically applied in data\nanalysis that have a less clear particle level analogue. Here we provide suggestions as the basis for future\ndiscussion:\n1. Lepton isolation: reproducing detector level isolation requirements at particle level is difficult,\nwhereas determining the efficiency loss due to such requirements in data is generally rather straightforward. So we suggest the measured data should be corrected for these efficiency losses, and no\nisolation conditions be imposed at particle level.\n2. Minimum lepton pT (and MET) requirements: such requirements should generally be implemented\nat the particle level also. However, if the effect is small it may be possible to use the simulation to\nextrapolate into the unmeasured region.\n3. Event vetoes: for example, a second lepton veto in W selection. Due to detector efficiency effects,\nsuch requirements are difficult to implement in a way that is consistent between detector and particle\nlevel, and should be treated with care.\n14.4\n\nImplications\n\nTo study the impact of the definitions outlined in the previous section, some Tevatron examples are used.\nSamples of pp\u0304 \u2192 Z/\u03b3 \u2217 , with Z/\u03b3 \u2217 \u2192 e+ e\u2212 and Z/\u03b3 \u2217 \u2192 \u03bc+ \u00df\u03bc\u2212 , are produced using Pythia 6.421 [18],\nusing the P erugia 6 tune [62] with the CTEQ6L1 PDFs [156]. The samples are normalized to the same\nnumber of generated events. For comparison, we also consider a \"generated Z/\u03b3 \u2217 \", reconstructed by\nsearching the Pythia event record and explicitly taking the two leptons from the Z/\u03b3 \u2217 decay, before FSR.\nRegardless of the definition used, the leptons used to make a Z/\u03b3 \u2217 are required to have |\u03b7| < 1.7 and a\ndilepton mass between 65 and 115 GeV.\n86\n\n\f14.5\n\nFSR Properties\n\nDimuon\n\n0.35\n0.3\n0.25\n\nDielectron\nDimuon\n\n10-1\n\n10-2\n\nDielectron\nDimuon\n\n10-1\n\nDielectron\n\n10-1\n\nDimuon\n\nphotons / event\n\nDielectron\n\nevents / generated Z\n\n0.4\n\nevents / generated Z\n\n0.45\n\nevents / generated Z\n\nevents / generated Z\n\nFirst, the properties of photons from FSR are considered. Figure 43 shows, for Z/\u03b3 \u2217 \u2192 e+ e\u2212 and\nZ/\u03b3 \u2217 \u2192 \u03bc+ \u00df\u03bc\u2212 , the rates at which FSR photons are emitted from the Z/\u03b3 \u2217 decay products. Next, \u2206R\nbetween FSR photons and the nearest Z/\u03b3 \u2217 decay product. Then, the FSR photon energy and the energy\nof \"unmeasured photons\" is shown; in the case of muons, all photons are considered unmeasured; for\nelectrons, photons outside the cone of 0.2 are considered unmeasured. Finally, the fraction of all photons\nwithin |\u03b7| < 2.5 (typical electromagnetic calorimeter coverage) in the final state which arise from FSR\nfor different pT requirements.\n\n10\n\n3\n10-3\n\n0.15\n\n2\n\n10-3\n\n1\n\n0.05\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n1.3\n1.2\n1.1\n\n0.8\n\n0\n2.2\n\n2\n\n4\n\n6\n\n8 10 12 14 16 18 20\n\n0.480\n\n1.8\n\n0.9\n0.4\n\n-0.5 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5\n# FSR photons\n\n0\n\n0.4\n\n0.36\n\n1\n\n1.5\n\n2\n2.5\n\u2206 R(\u03b3 , l)\n\n0.6\n0\n\n0\n0.8\n0.7\n\nDielectron FSR\nDimuon FSR\n\n0.6\n0.5\n0.4\n0.3\n0.2\n\n0.34\n\n0.8\n0.5\n\n8 10 12 14 16 18 20\n\n0.38\n\n1\n\n0.8\n\n6\n\n0.42\n\n1.6\n\n1.2\n\n0.6\n\n4\n\n0.44\n\n1.4\n1\n\n2\n\n0.46\n\n2\n\nFSR / non-FSR photons\n\n1\n\n1.40\n\nelectron / muon\n\n1.2\n\nelectron / muon\n\n10-4\n\n0\n-0.5 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5\n\nelectron / muon\n\nelectron / muon\n\nDimuon FSR\n5\n4\n\n10-2\n\n10-3\n\nDielectron FSR\n\n-2\n\n0.2\n\n0.1\n\nNon-FSR\n6\n\n0.1\n0.32\n2\n\n4\n\n6 8 10 12 14 16 18 20\nFSR photon Energy (GeV)\n\n0 2 4 6 8 10 12 14 16 18 20\nUnmeasured FSR photon energy (GeV)\n\n0\n\nall\n\np >1 GeV\nT\n\np >5 GeV\nT\n\np >10 GeV\nT\n\nFig. 43: Left: the rate of FSR photons from the Z decay products; centre left: \u2206R(\u03b3, l); centre: FSR\nphoton energy; centre right: energy of \"unmeasured\" FSR photons (see text); right: the fraction of all\nphotons that arise from FSR, at different energies.\nIt can be seen that the rate of FSR is significant. In Z/\u03b3 \u2217 \u2192 e+ e\u2212 , the photons are typically close\nto the electron and will be added to the electron cluster, however (using the default Pythia settings)\napproximately 23% of Z/\u03b3 \u2217 \u2192 e+ e\u2212 events will still contain at least one lost FSR photon (compared to\n66% of Z/\u03b3 \u2217 \u2192 \u03bc+ \u00df\u03bc\u2212 events). These photons are typically of very low energy, though approximately\n3% of Z/\u03b3 \u2217 \u2192 e+ e\u2212 and 7% of Z/\u03b3 \u2217 \u2192 \u03bc+ \u00df\u03bc\u2212 events contain an unmeasured FSR photon above\n5 GeV. Identifying these lost FSR photons is almost certainly experimentally impossible, and it also\nappears impossible at the level of stable particles (without looking into the generator event record), due to\nthe presence of photons from other sources (primarily \u03c0 0 decays). In the following sections, we consider\nhow these effects result in differences between the generated Z/\u03b3 \u2217 and the measured dilepton final state,\nfor some important kinematic properties.\n14.6\n\nEnergy Scale and Resolution, and Total Cross Section\n\nThe energy scale and resolution for both the electromagnetic calorimeter and tracking system are typically\nderived by fitting the shape and position of the Z/\u03b3 \u2217 peak. Here, we assess the impact of QED FSR on\nthe measured Z/\u03b3 \u2217 line-shape, and hence possible effects on detector calibration. Figure 44 shows the\ngenerated Z/\u03b3 \u2217 mass distribution, and that reconstructed using the stated electron and muon definitions.\nIt can be seen that FSR has a drastic effect on the observable line-shape below the pole. Obviously\ncalibrations should ensure the detector response reflects the observable leptons, and not \"correct\" them\nto the generated Z/\u03b3 \u2217 , so using the lower side of the mass peak would clearly rely upon a model of\nFSR. This introduces model dependence which may complicate the extraction of model independent\nquantities from data analysis. However, the energy scale may possibly be determined with minimal model\ndependence by fitting only the peak position, which is mostly unaffected by FSR. Similarly, it may be\n\n87\n\n\fDielectron\n10-1\n\nDimuon\n\n10-2\n\nZ/\u03b3 * boson\n\n10-1\n\nDielectron\nDimuon\n\nevents / generated Z\n\nZ/\u03b3 * boson\n\nevents / generated Z\n\nevents / generated Z\n\npossible to determine lepton resolution in a model independent way from the higher edge of the mass\npeak, which is also mostly unaffected.\nZ/\u03b3 * boson\nDielectron\n\n10-1\n\nDimuon\n\n10-2\n\n10-2\n\n10-3\n\n1.4\n1.2\n1\n\n0\n1.08\n\n5\n\n10 15 20 25 30 35 40\nDielectron\nDimuon\n\n1.06\n1.04\n1.02\n1\n0.98\n0.96\n\n0\n\n5\n\n1\n\n10 15 20 25 30 35 40\nDielectron\nDimuon\n\n0.99\n0.98\n0.97\n0.96\n\n0.94\n0.95\n\n0.92\n0.8\n70 75 80 85 90 95 100 105 110\nmass (GeV)\n\nratio to generated Z/\u03b3 *\n\n1.6\n\nratio to generated Z/\u03b3 *\n\nratio to generated Z/\u03b3 *\n\n10-3\n70 75 80 85 90 95 100 105 110\nDielectron\n2\nDimuon\n1.8\n\n0.9\n0\n\n5\n\n10 15 20 25 30 35 40\npT (GeV)\n\n0.94\n0\n\n5\n\n10 15 20 25 30 35 40\naT (GeV)\n\nFig. 44: Comparing the generated Z/\u03b3 \u2217 to the observable (defined in the text). Left: the Z/\u03b3 \u2217 mass;\ncentre: the Z/\u03b3 \u2217 pT ; right: the Z/\u03b3 \u2217 aT .\nThe effect of FSR on the Z/\u03b3 \u2217 line-shape has another implication: the inclusive Drell-Yan cross section\nis typically measured for a given mass range, for example 65-115 GeV. Energy lost in FSR causes the\ndilepton mass to be below the \"true\" Z/\u03b3 \u2217 mass, which means events above the mass window may migrate\nin, and events in the window migrate out. In the Pythia samples considered, this causes a 0.9% net loss of\ndielectron events, and a 2.1% net loss of dimuon events for the stated mass window.\n14.7\n\nZ/\u03b3 \u2217 pT and aT\n\nWe next consider the impact on the Z/\u03b3 \u2217 pT and aT [172, 173] distributions, important variables in\nmeasuring non-perturbative QCD form factors and in generator tuning. Figure 44 shows the observable\nZ/\u03b3 \u2217 pT and aT compared to the true Z/\u03b3 \u2217 pT and aT . For pT , effects of up to 4% are seen in the\ndielectron channel, and up to 10% in the dimuon channel. Effects are around 2% for aT , where the shape\neffect is larger in the electron channel. For both pT and aT , the effects are largest at low values, the crucial\nregion for generator tuning and determining form factors.\n14.8\n\nRecovering Published Measurements?\n\nSeveral Tevatron measurements of the Z/\u03b3 \u2217 pT have corrected back to the \"generated\" Z/\u03b3 \u2217 , with full\n4\u03c0 acceptance [174\u2013176]. Similarly, it is common practice in theory papers to present results at the same\nlevel (see a recent example in Ref. [177]). We perform a quick study to determine if such measurements\nand calculations can be approximated using only the stable final state particles, rather than having to\nresort to looking into the generator event history. This is done by using a wider cone around the final\nstate electrons, to attempt to re-sum more FSR and get closer to the leptons directly from the Z/\u03b3 \u2217 decay.\nFigure 45 shows the effect of using a cone of radius 0.2, 0.5 and 1.0. While the cone size of 0.5 comes\ncloser to the \"true\" Z/\u03b3 \u2217 pT in the low pT region, it moves further away at high pT . Increasing the cone\nsize to 1.0 clearly distorts the spectrum, with too many non-FSR photons being added to each electron.\nSimilar behaviour is observed for aT .\n\n88\n\n\f10-1\n\nevents / generated Z\n\nevents / generated Z\n\nZ/\u03b3 * boson\n\u2206 R = 0.2\n\u2206 R = 0.5\n\u2206 R = 1.0\n\nZ/\u03b3 * boson\n\u2206 R = 0.2\n\u2206 R = 0.5\n\u2206 R = 1.0\n10-1\n\n10-2\n\n1.1\n0\n1.08\n\n10\n\n20\n\n30\n\n1.06\n\n40 \u2206 R\n50= 0.260\n\u2206 R = 0.5\n\u2206 R = 1.0\n\nratio to generated Z/\u03b3 *\n\nratio to generated Z/\u03b3 *\n\n10-2\n\n1.04\n1.02\n1\n0.98\n\n1.1\n0\n1.08\n\n15\n\n20 25 \u220630\n35\nR = 0.2\n\u2206 R = 0.5\n\u2206 R = 1.0\n\n5\n\n10\n\n15\n\n20 25\n\n1.04\n1.02\n1\n0.98\n0.96\n\n0.94\n\n0.94\n\n0.9\n0\n\n10\n\n1.06\n\n0.96\n\n0.92\n\n5\n\n0.92\n10\n\n20\n\n30\n\n40\n\n0.9\n0\n\n50\n60\npT (GeV)\n\n30 35\naT (GeV)\n\nFig. 45: The effect on the Z/\u03b3 \u2217 pT (left) and aT (right) of changing the electron cluster size.\nThis simple study shows the difficulty in reproducing the generated Z/\u03b3 \u2217 from only the stable particles,\nand the precision to which such \"boson level\" results can for example be implemented in Rivet (see\nSection 5. and used for generator tuning with Professor [47].\nFully reproducing published Z/\u03b3 \u2217 pT results may only be possible by mimicking the data treatment:\napplying a \"FSR correction factor\" to the spectrum reconstructed from the stable particles. Such treatment\nintroduces similar ambiguities and model dependence as the original data analysis which corrected back\nto the \"Z/\u03b3 \u2217 \".\n14.9\n\nCombining Electron and Muon Channels\n\nExperimentally, combining electron and muon channel measurements is considered a simple way to\nincrease the statistics used in a measurement, and benefit from the fact that many experimental systematics\nare uncorrelated between the two channels. However, we have shown that the electron and muon\nobservables are fundamentally different in both the measured cross section and reconstructed kinematics\nare different in each channel. Further complications are introduced by the different acceptance of\ncalorimeters and muon detectors. These factors degrade the value of a combination, for which the same\nobservable must be extracted from each channel, and it is impossible to do this without relying on a model\nof FSR.\nIf a combination must be done, a \"minimally model dependent\" method would be:\n1. Restrict electron and muon measurements to the same phase space. This will typically mean\nexcluding some region from one of the channels, due to different coverage of muon detectors and\ncalorimetry.\n2. Apply a theoretical factor to the muon channel measurement, to correct from the observable muons\nto an equivalent of the electron observable: in this study, stable muons + all photons and electrons\nin a 0.2 cone around each muon. This factor should be published along with the combination.\nIn simulated events, there are then two options: apply the same theoretical factor to simulated\nZ/\u03b3 \u2217 \u2192 \u03bc+ \u00df\u03bc\u2212 as used for the muon data, then combine; or, directly treat stable muons as electrons\n(clustering EM energy around each muon). Figure 46 compares the Z/\u03b3 \u2217 pT and aT for the muon channel\ncalculated in this direct way to the electron channel, and good agreement is seen.\n89\n\n\fDielectron\nDimuon\n\nevents / generated Z\n\nevents / generated Z\n\nZ/\u03b3 * boson\n\n10-1\n\nZ/\u03b3 * boson\nDielectron\n\n10-1\n\nDimuon\n\n10-2\n\n10-2\n\n5\n\n1.01\n\n10 15 20 25 30 35 40\nDielectron\nDimuon\n\n1\n0.99\n0.98\n\nratio to generated Z/\u03b3 *\n\nratio to generated Z/\u03b3 *\n\n10-3\n0\n\n0\n\n0.98\n0.97\n0.96\n\n0.95\n\n0.95\n0.94\n0\n\n10 15 20 25 30 35 40\npT (GeV)\n\nDimuon\n\n0.99\n\n0.96\n\n5\n\n10 15 20 25 30 35 40\nDielectron\n\n1\n\n0.97\n\n0.94\n0\n\n5\n\n1.01\n\n5\n\n10 15 20 25 30 35 40\naT (GeV)\n\nFig. 46: The Z/\u03b3 \u2217 pT (left) and aT (right) using the same treatment of electron and muon final states.\n14.10\n\nConclusion\n\nWe advocate that all future experimental measurements and theoretical predictions of the Z/\u03b3 \u2217 and W\n(and other leptonic final states) should be presented in terms of observables, and not extrapolated beyond\nthe measured acceptance. To this end, we propose definitions of observable electrons, muons and the\nZ/\u03b3 \u2217 , as well as missing transverse energy and the W boson, all at the level of particles entering a\ndetector. These definitions mimic the quantities measured in a detector, and provide an unambiguous,\nmodel independent basis to compare data and theory.\nWhile it is essential to provide the data in terms of observables, it may still be desirable to derive further\ntheoretical corrections for FSR and acceptance, for comparisons to previous results. We recommend such\ncorrection factors be provided in a table, rather than being applied to the data. Using this table, (the inverse\nof) such corrections could also be applied to a calculation which does not include FSR or acceptance\nrequirements, to allow direct comparisons to the data while maintaining the separation of measurement\nand theory.\n\n90\n\n\fPart V\n\nJETS AND JET SUBSTRUCTURE\nSTATUS OF JET SUBSTRUCTURE STUDIES 27\n\n15.\n15.1\n\nINTRODUCTION\n\nIn the 2007 Les Houches workshop [1] there was quite some discussion on how to define jets in ways\nwhich allow for clear comparison between experiments, and between measurements and state-of-the-art\ntheory. The importance of such discussion has been emphasised since both by the adoption of new jet\nfinders by ATLAS and CMS for their first data (in particular the anti-k\u22a5 algorithm [178]), and by the\nrapid expansion of activity aimed at exploiting the internal properties of jets in studies and searches for\nnew physics at the LHC.\nJet substructure has been studied at previous experiments as a means of investigating QCD. In fact\njet shapes and subjet multiplicities have been used to measure the strong coupling \u03b1s [179, 180]. What\nleads to a huge increase in interest at the LHC is the same fact that makes the LHC such an exciting\nproject in general - the energy reach is substantially higher than the electroweak symmetry-breaking scale.\nOne consequence of this which has been well appreciated for some time is that large multiplicities of\nelectroweak-scale objects may be produced (e.g. W ,Z, jets with pT \u2248 O(100) GeV). This has been a\nspur to a large amount of theoretical activity on higher order calculations and parton-shower-matched\nMonte Carlo simulations which has been a feature of many workshops, including this one.\nA consequence of the high energy of the LHC which was more slowly appreciated, but which is now\nquite widely understood, is that objects with masses around the electroweak scale may be produced well\nabove threshold, and thus be highly boosted. When boosted objects decay to hadrons, the decay products\nwill be collimated and may emerge as a single jet with distinctive substructure, even if the decay is initially\nto two or more quarks or gluons. It is easy to understand how such a situation will complicate the mapping\nfrom jets to partons which is the basis of almost every phenomenological study involving jets. In addition\nto the merging of jets due to high boosts, at the LHC, there will be unprecedented contamination from the\nunderlying event and pileup, further deforming the naive jet-to-parton map. The basic goal of much of the\nwork in jet substructure has been to improve the mapping from jets to partons, so that it can remain useful\nat the LHC, in light of new classes of signatures (like boosted object decays) and the extra contamination.\nJet substructure techniques were used first in studies of diboson production for identifying the hadronic\ndecays of vector bosons in diboson and SUSY production [181\u2013183], and in the 2007 workshop there\nwas much discussion on boosted-top reconstruction, for example [184]. In the last two years, techniques\nhave been developed and applied to several channels including top production [185\u2013187] as well as\nHiggs [158,159,188,189] and neutralino [190,191] searches, and several proposals have been made to use\nsubstructure information to improve jet mass resolution in general [192\u2013194] using substructure. Many\nof these techniques have been investigated by the experimental collaborations, using realistic detector\nsimulations, and survived the test.\nAnother feature of the LHC relevant to jet substructure is that the calorimeters and trackers are superior\nto those at previous machines, allowing access to more detailed information about the jet itself. This\ninformation should be utilized in a more refined substructure analysis, but is only starting to be exploited.\nAs the physical information from particle flow or topo-clusters becomes better understood, the power of jet\nsubstructure analyses will certainly improve. It is not surprising that a next-generation machine requires\nnext-generation analysis tools, and the work on jet-substructure has just begun to probe the possibilities.\nJet substructure is a rapidly moving field, with at least two dedicated workshops held since the meetings\nin Les Houches [195] and more planned. Here we give a snapshot of the current status, focused (but not\nexclusively) on some developments which took place in this workshop.\n27\n\nContributed by: J. M. Butterworth, M. D. Schwartz\n\n91\n\n\f15.2\n\nGENERAL FEATURES\n\nIn QCD, the evolution from a hard parton to a jet of partons takes place in a regime where the energy scale\nis high enough to use perturbation theory, x is not very small, and collinear logarithms are large. This is\nessentially the kinematic region where DGLAP evolution should apply. This is largely understood within\nQCD, and can be calculated. It forms the basis of the parton-shower models implemented in the most\nwidely used MC generators. Since the phase space between the jet pT and the confinement scale is large,\nthere is plenty of radiation, and parton multiplicities will be large. Confinement enters the picture at the\nhadronization (non-perturbative) stage, and is expected to have a small effect (at the sub-GeV level). In\ngeneral, the aspects of QCD relevant for jet substructure seem to be well-modelled by tuned Monte Carlo\nsimulations, as is borne out by the available data [179, 196\u2013200].\nThere are two somewhat distinct goals of the recently developed techniques. One is to improve the\nsingle jet mass resolution, and the other is to distinguish jets originating in heavy object decays from\nthose coming from pure QCD backgrounds. The first of these goals requires a careful definition, in\nline with the discussion of jets in the last workshop [1]. Jet mass must be defined in terms of infra-red\nand collinear safe variables on the one hand, and in terms of physical observables on the other, to avoid\nmaking completely model-dependent \"measurements\". However, the jet mass resolution may be optimised\nusing models, in particular models which implement or mimic jets from the decay of a colour-singlet,\nby switching off initial state radiation; and models which mimic jets from parton (rather than proton)\ncollisions by switching off underlying event. The second goal, background suppression for heavy particle\ndecays, generally relies on the fact that in QCD the various splittings within the jet are expected to be\nstrongly ordered in scale, with large asymmetric splittings, whereas partons resulting from a heavy particle\ndecay will in general share the energy equally in the particle rest frame, leading to more symmetric\nconfigurations.\n15.3\n\nFILTERING\n\nLet us begin with a discussion of what shall refer to generically as filtering. Filtering refers to the removal\nof components of a jet in an attempt to clean up the jets in a certain way. Variations on this theme have\nappeared, such as pruning [192] and trimming [194]. The basic idea of filtering is that one first finds a jet\nwhich is assumed to contain the radiation one is interested in as well as contaminating radiation, then one\nremoves the contamination with the filtering step. The difference in the algorithms is more a difference\nin how the authors are imagining their routines used than in the way the routines themselves work. So\nwe will organize the discussion of filtering by application. Some approaches are application-specific,\noptimized to find a particular signal, such as boosted Higgs or boosted top decays, while other applications\nare more general. We will be begin with the specific ones.\n15.31\n\nFILTERING FOR SPECIFIC APPLICATIONS\n\nThe most productive application of filtering so far has been in the search for heavy boosted objects which\ndecay to standard model jets. Consider first a Higgs boson decaying to bb\u0304 in associated production with\na W . This channel is the discovery channel for a light (\u223c 120 GeV) Higgs at the Tevatron, but is very\ndifficult at the LHC due to much more complicated backgrounds, in particular tt\u0304 production. Going to\na regime where the Higgs is boosted (pT > 200 GeV) has the effect of essentially eliminating the tt\u0304\nbackground and removing a lot of the W +jets background as well. In this case, the b-jets from the Higgs\ndecay may be within \u2206R = 1.0 of each other, so finding separate R = 0.7 jets may fail. The substructure\napproach pioneered in [158] was to find the jets together as a fat jet, with a cone size of R = 1.0 or greater,\nthen to parse the jets to find the b-quarks as subjets.\nTo be specific, in [158], the authors use the Cambridge/Aachen algorithm\np [201, 202] to construct the fat\njet. This algorithm merges constituents based on the distance \u2206R = (\u2206\u03b7)2 + (\u2206\u03c6)2 between them.\nThen they undo the clustering steps using the clustering history (conveniently stored by FastJet [203]\n\n92\n\n\fwithin the jet object). Somewhere in the declustering the b should be separated. However, the way\nCambridge/Aachen works does not guarantee that the the final merger is of the two b-jets into the fat\njet. Therefore, when tracing back through the declustering, one needs a different criterion, for example,\nlooking for large mass drop \u2013 the masses of the subjets should be much smaller than the mass of the fat jet.\nOnce a large mass drop is found, the process is stopped. All constituents of the jet which would have been\nsplit at this stage are retained, and the clustering algorithm is rerun, using the angle between the centres of\nthe last two subjets to set a (smaller) angular scale. This effectively optimizes on an event-by-event basis\nthe selection of final state radiation from the (color singlet) Higgs candidate, while rejecting radiation\nfrom elsewhere, including the underlying event. This is the step described as \"filtering\" in the analysis.\nThe top two or three subjets are combined to reconstruct the Higgs mass. The possible inclusion of a\nthird jet, rather than just two (representing the b and b\u0304) allows for an extra hard gluon emission. This final\nstep is critical in getting the algorithm to perform well at the Higgs mass reconstruction. The result was\nconfirmed by an ATLAS study [159], and revived H \u2192 bb\u0304 as a discovery channel for the Higgs at the\nLHC.\nAnother application of filtering has been in hadronic boosted top decays [185]. Here, the same basic\nprinciple is applied: a fat jet is found, subjets are located through declustering, and a filter is applied to\nremove unwanted radiation. In this case, the three or four hardest subjets are filtered out. Three of the jets\nshould represent the hadronic top decay products: the b-jet and the two quark jets from the W decay, the\nfourth may be an additional hard gluon. Using this approach, the authors found 99% background rejection\nefficiency at 40% signal efficiency, per jet. Therefore signal/background for boosted hadronic tt\u0304 events\nover dijets is enhanced by a factor of 1000. A CMS study confirmed these efficiencies with full detector\nsimulation [204].\nSince the boosted Higgs and boosted top taggers described above rely on reversing the clustering\nsequence of a jet, there is naturally a dependence on the jet algorithm. We show in Fig. 47 a comparison of\ndifferent algorithms for a variable used by the CMS top-tagging study [204]. Of the 3 or 4 subjets filtered\nout of the top jet, they looked at the minimum invariant mass of any pair. In the first panel, clustering with\nCambridge/Aachen shows the peak at \u223c 80 GeV corresponding to the W -mass in the signal, which is\nabsent in the background. The second peak around \u223c 20 GeV corresponds to wrongly identified subjets\nand mimics the QCD background. The result for the k\u22a5 algorithm is similar. The anti-k\u22a5 algorithm,\nhowever, does not show the W -mass peak. This is because anti-k\u22a5 essentially works backwards to the\nother clustering algorithms, with the hardest particles being clustered first, and the soft stuff clustered\nat the end. One can see that anti-k\u22a5 is not ideal for filtering and substructure analysis. However, the\nfinal panel shows that if the fat jet is found using anti-k\u22a5 , but the particles in the jet are reclustered using\nCambridge/Aachen, the substructure is still there. We conclude that the substructure analysis and the\nfat-jet finder can be chosen independently.\n15.32\n\nGENERAL FILTERING TECHNIQUES\n\nHaving seen filtering successfully applied in a number of specific cases, it is natural to ask whether the\napproach can be generalized to cases when you do not know a priori what it is you are looking for. For\nexample, in the Higgs\u2192 bb\u0304 study, the fat jet was filtered to look for 2 or 3 hard subjets, in top-tagging,\nthe fat jet was filtered to look for 3 or 4 hard subjets. The idea behind jet pruning is that is is possible\nto filter the jet without knowing ahead of time how many hard constituents to expect. Instead, one can\ndecompose the jet until some measure of the size of each splitting is saturated. For example, in [192],\nthe pruning algorithm based on Cambridge/Aachen declustering stops when a splitting has \u2206ij > Dcut ,\nwhere Dcut \u221d 2mJ /pT is determined on a jet by jet basis. The authors demonstrated that this general\nmethod successfully finds the subjets in the specific cases of boosted top or boosted W jets.\nAnother general approach is jet trimming [194]. Here the goal is not to find hard subjet constituents in\nfat jets, but to clean up simple quark or gluon-initiated QCD jets. Suppose we have a massive color singlet\n\u03c6 decaying to q q\u0304. Then the mass of the resonance should be reconstructable using all of the final-state\n93\n\n\fkT\n\nCambridge/Aachen\n3.5\n\n3.5\n\n3\n\n3\n\n2.5\n\n2.5\n\n2\n\n2\n\n1.5\n\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n0\n\n20\n\n40\n\n60\n\n0\n0\n\n80\n100\n120\n140\nMinimum mass of subjet pair\n\nanti\u2212kT\n\n40\n\n60\n\n80\n100\n120\n140\nMinimum mass of subjet pair\n\nanti\u2212kT with C/A declustering\n\n3.5\n\n3.5\n\n3\n\n3\n\n2.5\n\n2.5\n\n2\n\n2\n\n1.5\n\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n0\n\n20\n\n20\n\n40\n\n60\n\n0\n0\n\n80\n100\n120\nMinimum mass of subjet pair\n\n20\n\n40\n\n60\n\n80\n100\n120\n140\nMinimum mass of subjet pair\n\nFig. 47: Comparison of different clustering algorithms for the minimum invariant mass of two subjets.\nThe Cambridge/Aachen and k\u22a5 algorithms both work well and finding the subjets corresponding to the\nW decay, while anti-k\u22a5 fails. The bottom right panel shows that anti-k\u22a5 can still be used to find the fat\njets, if the jet constituents are then reclustered with Cambridge/Aachen to find the subjets.\n\nradiation from the quarks. However, in reality, it is impossible to separate the final state radiation from\nadditional radiation originating either from the underlying event or from other hard objects that happen to\nalso be present. By studying the radiation pattern from FSR only to FSR plus contamination, the authors\nobserved that the contamination could be reduced with trimming.\nThe trimming procedure they proposed works as follows. First jets are found as usual, say with\nanti-k\u22a5 with R = 0.8. Then the jet constituents are reclustered into many tiny jets using a much smaller\nclustering size, say R = 0.2. These tiny jets are then discarded if their pT is below a certain threshold,\nsay ptiny\n< 0.01pjet\nT\nT , or only a certain number of them, say the five hardest, are kept. Figure 48 shows an\nexample of how trimming removes contamination from underlying event. Note that in contrast to pruning,\ntrimming does not reverse the clustering sequence to find subjets, rather it reclusters with a different scale,\nin a manner similar to the filtering stage in the Higgs analysis described above, but not solely focused on\nthat final state. Thus, good results can be obtained using anti-k\u22a5 both to find the original jets, and to find\nthe tiny jets during the reclustering step.\n15.4\n\nSUMMARY AND FUTURE WORK\n\nLet us briefly mention some other related ideas which have been proposed. In [205], the authors proposed\nthat greater efficiencies could be obtained by choosing a jet radius continuously which decreases with\nincreasing pT . Similar scalings had been used previously, for example in the boosted top-tagging\nstudy [185], but with a discrete size change rather than a continuous one. The insight of [205] was to make\nsuch a scaling automatically part of the jet algorithm. While changing the jet size does seem to produce\n94\n\n\fCross Section [A.U.]\n\nanti-k T FSR only\nanti-k T ISR/MI/pileup\nTrimming FSR only\n\n500\n\nTrimming ISR/MI/pileup\n\n400\n\n300\n\n200\n\n100\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n200\n\nJet Mass [GeV]\n\nFig. 48: Effectiveness of jet trimming at removing contamination from the underlying event. The jet mass\nafter trimming appears similar to the jet mass with underlying event turned off. (Figure courtesy of D.\nKrohn.)\n\nimprovements, the benefits may not outweigh the complications in real experimental settings, such as the\nincreased difficulty of jet energy scale calibrations. For example, CMS chose in their implementation\nof top-tagging [204] to keep the jet size fixed, and were able to achieve comparable efficiencies to the\ntheoretical study with the R variation.\nAnother idea is to use QCD jet shapes such as planar flow or angularities to distinguish heavy particle\ndecays from QCD jets [206, 207]. A comparison of the efficiency of this approach in top tagging, and a\nmore complete summary of other key issues in jet substructure can be found in [208].\nIn addition there is clearly potential in studying QCD characteristics beyond the jets. Recently, a\nproposal was made of for a simple variable pull which can characterize the color flow of an event [209].\nColor flow is something that is not contained in the 4-momentum of a jet and so may provide a nice handle\non new physics which is complementary and uncorrelated with traditional techniques. For example, it\nmay help distinguish color singlet objects (such a the Higgs) from the other color structures in the QCD\nbackground. Although color flow is sensitive to aspects of QCD that go beyond the leading-log, DGLAP\nevolution of basic Monte Carlos, recent progress in the development of Monte Carlos assure us that such\neffects must be both visible and calculable (cf. Section 10. of these proceedings). The prospects of\nextracting such superstructure information at the LHC are just beginning to be explored, and there is\ncertainly much more to be done and understood.\nIn subsequent sections of these proceedings more details of physics relevant to jet substructure are\ndiscussed: the status of simulations for jet substructure in heavy particle decays (Section 16.), detector\nissues (Section 17.), radiation between jets (Section 18.) and calculations of boosted bb\u0304 production in\nW bb\u0304 events (Section 12.), which is a significant background to Higgs searches using jet substructure.\n\n95\n\n\fHEAVY PARTICLE DECAYS IN MONTE CARLO EVENT GENERATORS 28\n\n16.\n\nIn the coming years the LHC will probe a new energy regime one order of magnitude higher than that\nwhich has been accessed to date. It is therefore natural that heavy, unstable particles, such as the top-quark,\nwill be produced in large quantities. Indeed, next-to-leading order QCD predictions for top quark pair\nproduction indicate that tt\u0304 pairs will be created at a rate of around 0.3 Hz at low luminosity (10 fb\u22121 per\nyear). Of course, it is widely anticipated that physics beyond the Standard Model (SM) will be discovered\nat the LHC, hence many other species of heavy particles are also expected to be produced.\nIt is well known that modern collider physics analyses rely upon Monte Carlo simulations for a wide\nvariety of applications, from the modelling of detector effects through to the determination of fundamental\nparameters; the top-quark mass determination being a case where the dependence on simulations is\nparticularly acute. Since new, unstable, heavy particles feature in almost all extensions of the Standard\nModel, it is foreseeable that many more analyses of this type will be carried out in the LHC era. Clearly,\nas the r\u00f4le of the event generators in the analysis becomes increasingly significant, so too does the need\nfor them to model the underlying process precisely and, when this is not possible, it is equally important\nthat their limitations and inaccuracies are understood.\nIn the following we shall critically review some of the main issues to be addressed in the simulation of\nheavy particle decays. The material is intended to better inform users of event generators regarding the\nnature of the methods and approximations employed, rather than to provide a comprehensive technical\nreview of the state-of-the-art. The first part of the discussion concerns the generalities of the physics\nphenomena and their simulation, rather than a description of a specific event generator. In the second\npart we give brief, itemized, technical descriptions of the three main general-purpose event generators,\nSherpa [23], Pythia 8 [18, 20] and Herwig++ [21], with reference to the background material.\n16.1\n\nSIMULATION STRATEGY\n\nIn general, for each event, all of the multi-purpose event generators begin by generating an initial 'hard'\nconfiguration of particles according to the associated tree-level matrix elements, after which parton\nshowers are initiated from the external legs. When the showering is complete the final-state consists of\na set of partons with constituent masses which are then hadronized. On the other hand, for processes\ninvolving the production and decay of unstable particles, including decay chains, rather than attempting to\ngenerate the ultimate final-state particles directly, according to high multiplicity matrix elements, each\nprogram first generates the momenta of the initial unstable heavy particles in the production phase, before\ngoing on to (quasi-)independently generate the momenta of their decay products, showering the colour\ncharged objects in each phase. As well as being more manageable, this approach benefits from being\nsubstantially more efficient, computationally, and also from being highly versatile, in keeping with the\nmulti-purpose paradigm that the event generators are built on; in particular, the independent generation\nof production and decay momenta lends itself naturally, through iteration, to the simulation of arbitrary\ndecay chains. Of course this generality comes at the cost of varying degrees of approximation, which we\nwill now discuss briefly below.\n16.2\n\nTHE BASE APPROXIMATION\n\nIn this subsection we elaborate on the series of approximations by which the production and decay of a\nparticle may be treated entirely independently modulo charge and momentum conservation. In doing so\nwe will arrive at the base approximation: the common starting point from which the simulations may or\nmay not start to model omitted physics effects and undo approximations by various means, some of which\nwill be addressed in Section 16.3.\n28\n\nContributed by: K. Hamilton, L. L\u00f6nnblad, S. Schumann, T. Sj\u00f6strand, J. Winter\n\n96\n\n\f16.21\n\nRESONANT AND NON-RESONANT CONTRIBUTIONS\n\nExperimental signals are defined in terms of the particles which actually enter the detector, leptons,\nphotons and jets, rather than the heavy unstable objects which we typically are interested in studying,\nupstream. The corresponding theoretical predictions are then strictly required to be defined in precisely\nthe same way, including contributions from all Feynman diagrams which give rise to the same external\nstates, see e.g. [210]. Generally, however, only a limited subset of these diagrams involve the exchange of\ns-channel resonances which go on to decay into the stable objects comprising the signal, i.e. diagrams\nrepresentative of heavy particle production and decay (chains). By their nature the resonant graphs give\nthe dominant contributions to the cross section for a given signal and calculations based on this subset\nof Feynman diagrams are known to provide excellent approximations to the full result. Moreover, in\nthe case where the heavy s-channel particle is that which we wish to study, experimental analyses will\nregularly employ cuts which further enhance the resonant contributions. In keeping with these observations\nthe simulation of non-resonant effects in all but the simplest processes, namely 2 \u2192 2 processes, is\ntypically beyond the scope of the multi-purpose Monte Carlo event generators, furthermore, the loss of\naccuracy incurred through the omission of the non-resonant contributions is limited to the extent that this\napproximation is often also employed by tree-level event generators such as Madgraph / MadEvent [81]\nor Whizard [211], even though they have the facility to include them automatically, in order to increase\ncomputational efficiency.\n16.22\n\nFACTORIZATION OF PRODUCTION AND DECAY\n\nAlthough there exists, in general, quantum mechanical interference between the production and decay\nof an unstable particle, in the limit that the resonant particle is exactly on-shell, the matrix elements\ncorresponding to the resonant graphs may be factorized into two parts, one corresponding to the production\nof the heavy particle and one corresponding to its decay. Take, for example, a process pp \u2192 bW + + X,\nwhich naturally receives resonant contributions in the form of graphs containing an s-channel top-quark; in\nthe limit that the top-quark momentum is on-shell, one can replace the propagator numerator i (6 pt + mt )\nwith a sum over spins:\nlim M \u2192\n\np2t \u2192m2t\n\n1\np2t\n\n\u2212\n\n\u00012\nm2t\n\n+ m2t \u03932t\n\nD\u2217\nAP\u03bb AP\u03bb0\u2217 AD\n\u03bb A\u03bb 0\n\n(28)\n\nD\nwhere AP\u03bb = AP u\u03bb (pt ) and AD\n\u03bb = \u016b\u03bb (pt ) A are the amplitudes for the on-shell production and decay\n+\nprocesses, pp \u2192 t + X and t \u2192 bW respectively and where the quark helicity indices, \u03bb, \u03bb0 are summed\nover. In the so-called narrow width approximation where the product of the unstable particle's width and\nmass tend to zero we have\n\u0001\n1\n\u03c0\n\u2192\n\u03b4 p2 \u2212 m2 ,\n(29)\nlim\n2\nm\u0393\u21920 (p2 \u2212 m2 ) + m2 \u03932\nm\u0393\n\ni.e. in the narrow width approximation the replacement of Eq. (28) is valid. A completely analogous\nreplacement to that in Eq. (28) holds for vector bosons, in that case, as with the fermion propagator\nnumerator, the vector boson propagator numerator can be replaced by a sum over polarizations.\nA further approximation commonly (but not universally) used in event generators is the neglect of\nspin correlations. This amounts to assuming that in the factorized amplitudes in Eq. (28), the graphs\ncorresponding to different helicity states of the intermediate particle do not interfere with one another\nand that they are produced in equal measure i.e. the full matrix element is effectively replaced by the\nproduct of two spin summed matrix elements, one corresponding to the production MP , the other to the\ndecay MD . In our pedagogical example, working in the narrow width approximation and neglecting spin\ncorrelations, the exact squared matrix is replaced according to\n\u0001\n\u03c0\nlim M \u2192\n\u03b4 p2t \u2212 m2t MP MD .\nmt \u0393t \u21920\nmt \u0393t\n97\n\n\f\u0001\nIn addition, by inserting dqt2 \u03b4 qt2 \u2212 p2t and d4 pt \u03b4 (pt \u2212 pb \u2212 pW + ) into the usual Lorentz invariant\nphase space measure we may, without approximation, factorize the Lorentz invariant phase space, d\u03a6, for\nbW + + X into parts corresponding to the same production and decay processes:\nd\u03a6 = d\u03a6P d\u03a6D\n\n1\ndq 2\n2\u03c0 t\n\n(30)\n\nwhere,\nd\u03a6P\n\n= d\u03a6t d\u03a6X (2\u03c0)4 \u03b4 4 (pa + pb \u2212 pt \u2212 pX ) ,\n\n(31)\n\n4 4\n\nd\u03a6D = d\u03a6b d\u03a6W + (2\u03c0) \u03b4 (pt \u2212 pb \u2212 pW + ) ,\nand for a given particle i, d\u03a6i is the usual invariant phase space measure\nd\u03a6i =\n\nd3 pi\n.\n(2\u03c0)3 2Ei\n\n(32)\n\nUsing this phase space factorization together with the narrow width approximation one can see that the\ndifferential cross section will factorize into two parts; denoting flux and PDF factors by L (x\u2295 , x ) we\nhave,\nd\u03c3 = dx\u2295 dx L (x\u2295 , x ) d\u03a6 M\n= dx\u2295 dx L (x\u2295 , x ) d\u03a6P MP \u00d7\nd\u0393t =\n\n(33)\n1\nd\u0393t\n\u0393t\n\n1\nMD d\u03a6D ,\n2mt\n\nwhere the first part corresponds to the spin summed production of the unstable particle and the second\npart to its branching ratio, differential in the decay phase space. By appealing to the narrow width\napproximation it is therefore possible to first generate the production and decay processes completely\nindependently in their rest frames, then boost the decay products to the frame in which the particle\nwas produced. The latter boost is ambiguous up to a rotation which is a direct manifestation of having\nneglected spin correlations.\nThe simulation procedure and the approximations which we have described up to this point comprise the\nmost basic algorithm employed by Monte Carlo simulations for the treatment of heavy particle production\nand decay; of course, for the parton shower simulations, these tree level configurations will, by default,\ngo on to include the effects of soft and collinear parton emissions from the coloured particles. Unless\notherwise stated this represents the base accuracy and physics describing the interplay of the production\nand decay of unstable particles in these simulations: non-resonant contributions, spin correlations and\noff-shell / finite width effects are all completely neglected.\n16.3\n\nBEYOND THE BASE APPROXIMATION\n\nHaving noted the basic nature of the base approximation we will now briefly review some of the ways in\nwhich it can be improved on. Note that these enhancements can be extremely sophisticated and so in no\ncase should they be assumed to have been implemented as a default option, for the same reason, it should\nbe clear from the simulations' documentation whether such features are available or not.\n16.31\n\nFINITE WIDTH EFFECTS\n\nAlthough the factorization of the numerator of the unstable particle propagator only holds when it is\nexactly on-shell, the error induced by using the replacement Eq. (28) when this is not true is O (\u0393/m)\ni.e. the typical amount by which the particle is off-shell with respect to its mass. Of course, if cuts or\n98\n\n\fobservables are such that the channel in question only contributes when the particle is far off-shell, e.g. if\ncuts correspond to a mass-window restricting the invariant mass to be far from the pole mass, the error\nis much greater and, in any case, in such circumstances the inclusion of non-resonant contributions is\nmandatory. Provided the signal regions receive contributions from the immediate vicinity of the resonance\nwe may recover its line-shape up to corrections O (\u0393/m), by inserting 1 into the factorized cross section\nformulae as,\nZ\nm\u0393\n1\n1 = dp2\n.\n(34)\n2\n2\n\u03c0 (p \u2212 m )2 + m2 \u03932\nThis is equivalent, of course, to not taking the exact limit \u0393 \u2192 0 in the Breit-Wigner function in Eqs. (28)\nand (29), we stress that this limit is nevertheless implied by assuming that the propagator numerator may\nbe replaced by the sum over external wavefunctions.\nIn terms of the event generation procedure, the inclusion of finite width effects in this way, leads to a\ntrivial modification of that described above for the \u0393 = 0 case, namely, that the first step in the algorithm\nis now the generation of an off-shell mass for the intermediate particles according to a Breit-Wigner\nfunction. The same procedure can be adopted using running widths.\nAlthough this seems, in principle, a relatively straightforward means of improving the base approximation (\u0393 = 0), a thorough treatment of the particle width, in particular those involving next-to-leading order\ncomputations, requires that further, more subtle, issues be addressed before it is introduced anywhere at\nall. Of note is the question of how to ensure that the introduction of the finite width does not violate gauge\ninvariance? The particle width term arises from the resummation of the imaginary parts of the self-energy\ninsertions on the unstable particle's propagator i.e. it corresponds to the inclusion of a subset of higher\norder corrections to the process under consideration29 . Since S-Matrix elements are only guaranteed to\nbe gauge invariant at each order in perturbation theory when all relevant diagrams at the given order\nare summed, one should expect that naively adding a width term to the propagator will violate gauge\ninvariance. Although this is the case in general, usually the numerical impact of the gauge breaking terms\nis negligible and is contained within that incurred by writing the propagator numerator as a polarization\nsum.\nOn the other hand, gauge invariance underlies the cancellation of large logarithmic corrections to\ninclusive quantities as laid out in the Bloch-Nordsieck [212] and KLN [213, 214] theorems, therefore,\nin cases where logarithmically enhanced emissions occur, the gauge variant contributions can be hugely\nmagnified and even exceed the correct, gauge invariant, contributions. These potentially dangerous\ncases are confined to processes involving diagrams in which the unstable particle we are studying emits\nsoft / collinear massless partons or photons e.g. gluon emission from top quarks or photon emission\nfrom W bosons. For simulations involving tree level matrix elements and / or parton showers this issue\nis substantially negated due to the obligatory generator level cuts, which exclude the phase space for\ncollinear and soft regions and, also, because the splitting functions at the heart of the parton shower\ndynamics are derived from the universal factorization of matrix elements with soft / collinear emissions.\nFurthermore, it is clear that for the Lagrangian to be gauge invariant it is not necessary for the parameters,\nin particular the masses, to be real numbers. Bearing this in mind, one may adopt the so-called complex\nmass scheme [215] whereby finite width effects are included in a gauge invariant fashion by simply\nreinterpreting the masses, everywhere that they occur in the Lagrangian, as being complex numbers with\nthe im\u0393 width factor absorbed inside them. Alternatively the so-called 'fudge-factor' scheme [216] is\nemployed whereby the total squared matrix element, neglecting finite width effects, is multiplied by the\nproduct of the Breit-Wigner function and the zero-width propagator, p2 \u2212 m2 , squared for each resonant\nparticle in the process. For further technical details concerning gauge invariance and finite width effects\nsee Refs. [215\u2013219].\nAnother pertinent issue is that of how to include threshold effects in the running width and the selection\nof decay modes. In the forthcoming years LHC analyses will predominantly be concerned with searches\n29\n\nIt therefore also has a dependency on the particle's mass, which we shall omit here for simplicity.\n\n99\n\n\ffor new particles, whose masses couplings and decay modes are all unknowns. A prime example is the\nStandard Model Higgs boson, whose width and decay modes strongly depend on, not simply its on-shell\nmass but, in view of the factorization of the production and decay, also the off-shell mass generated at\nthe beginning of the simulation, Eq. (29). This is of particular importance for particles decaying close to\nthreshold (as the Higgs boson may do), in this case the effects from the off-shell propagator must be taken\ninto account. This can be achieved by implementing the running width, i.e. including the full dependence\non the particle's off -shell mass, in the weight factor in Eq. (34), as well as, in the calculation of the partial\nwidth of a selected decay mode as in Ref. [220], where this prescription is shown to reproduce well the\nresults of some three-body decays simulated as a cascade of two two-body decays.\n16.32\n\nSPIN CORRELATIONS\n\nAs stated previously in the base approximation particle decays are performed according to the spin\naveraged matrix element for the decay process hence they occur isotropically in the rest frame. It follows\nthat in order to have a reasonable description of observables sensitive to the details of individual decay\nproducts it will be necessary, at least, to communicate the spin information from the production to the\ndecay parts of the simulations. Notable studies for which such correlations are particularly relevant\ninclude: the production and decay of the top quark, the production of tau leptons in Higgs decays and\nthe spin determination of newly discovered particles i.e. understanding the nature of physics beyond the\nStandard Model.\nGeneralizing earlier work of Knowles and Collins [221\u2013223], a flexible, efficient algorithm for propagating spin correlations between particle production and decay in Monte Carlo event generators, using the\nspin density matrix formalism, was developed by Richardson [224]. Rather than discuss the algorithm\nin full detail here we will describe it by considering the example of the process h h \u2192 t t\u0304 where the top\nquark subsequently decays, via a W boson, to a b quark and a pair of light fermions. Initially, the outgoing\nmomenta of the t t\u0304 pair are generated according to the partonic differential cross section\n1 P\n(35)\nAP \u2217 d\u03a6P\nA\n2\u015d \u03bbt \u03bbt\u0304 \u03bbt \u03bbt\u0304\nwhere AP\u03bbt \u03bbt\u0304 is the amplitude for the initial hard process, with \u03bbt and \u03bbt\u0304 denoting the helicity indices\nof the produced t and t\u0304 respectively. d\u03a6P is the usual phase space measure for the production process,\nequal to that in Eq. (31), where in this example X = t. Having generated the momenta for the production\nprocess, one of the outgoing particles is then picked at random, say the top and a production spin density\nmatrix is calculated\n1 P\n\u03c1t\u03bbt \u03bb0 =\nA\nAP0\u2217 ,\n(36)\nt\nN \u03bbt \u03bbt\u0304 \u03bbt \u03bbt\u0304\nwith N defined such that \u03c1t has unit trace.\ndb\n\u03c3P =\n\nThe top is decayed and the momenta of the decay products distributed according to\nd\u0393t =\n\n1 t\n\u03c1 0 ADt\nAD0t \u2217 d\u03a6D ,\n2mt \u03bbt \u03bbt \u03bbt \u03bbW + \u03bbt \u03bbW +\n\n(37)\n\nwhere the inclusion of the spin density matrix ensures the correct correlation between the top decay\nproducts and the beam. We note how the spin averaged result, Eq. (33), is recovered by replacing\n\u03c1t\u03bbt \u03bbt\u0304 \u2192 12 \u03b4\u03bbt \u03bbt . With the momenta for the top quark decay products now in hand we may calculate a\nproduction spin density matrix for the unstable W +\n+\n0\nW + \u03bbW +\n\n\u03c1W\n\u03bb\n\n=\n\n1 t\n\u03c1 0 ADt\nAD0t \u2217 ,\nN \u03bbt \u03bbt \u03bbt \u03bbW + \u03bbt \u03bbW +\n\n(38)\n\nand then generate its decay by analogy to Eq. (37). Here the use of the production matrix calculated from\nEqs. (36) and (38) leads to the correct angular correlations between the light fermions, the beam and the\nbottom quark.\n100\n\n\fSince the children of the W + are light fermions the decay chain terminates and a decay matrix for the\nW + is calculated:\n1 Dt\n+\nt\u2217\n,\n(39)\nD\u03bbW + \u03bb0 =\nA\u03bbt \u03bb + AD\n\u03bb\n\u03bb0 +\nt\n+\nW\nW\nN\nW\nW\nMoving back up the decay chain, the analogous decay matrix is calculated for the top quark using the\ndecay matrix of the W + :\n1 Dt\n+\nt\u2217\nD\u03bbt t \u03bb0 =\nD\u03bbW + \u03bb0 .\n(40)\nA\u03bbt \u03bb + AD\n0 \u03bb0\n\u03bb\nt\nW\nW\nt\n+\nN\nW+\nW\nFollowing this one contracts D\u03bbt t \u03bb0 with the full tt\u0304 production spin density matrix, AP\u03bbt \u03bbt\u0304 AP\u03bb0\u2217\u03bb0 , to give\nt\n\nt t\u0304\n\nthe production spin matrix of the antitop quark, \u03c1t\u0304\u03bb\n\n0\nt\u0304 \u03bbt\u0304\n\n, analogous to Eq. (36), before generating its decay\n\nproducts in the same way as was done for the top quark. In progressing forward along the t decay chain\nthe production spin density matrices pass information from one decay to the next leading to the correct\nangular correlations.\nOther methods for the inclusion of spin correlations in event generators are in use, although many\nof these may be regarded as approximations or variants of the above [81]. The only other approach\nwhich may be regarded as distinct, involves decaying all unstable particles in the event in a single step,\nusing matrix elements for the process under study where these particles have and have not decayed. This\nalgorithm has been applied in Pythia, for quite some time, for a number of processes and has been recently\nbeen extended in the context of matched next-to-leading order simulations by Frixione et al [114]. This\nalternative method is based on the observation that the product of the separately spin summed matrix\nelements for the production and decay processes, including propagator factors, always exceeds the full spin\nsummed matrix element. Knowing this, spin correlations may be implemented by generating production\nand decay momenta as in the base approximation (with the decays isotropic in their rest frame) choosing\na random number R and then regenerating the decay kinematics if R is greater than the ratio of the full\nspin summed matrix element to the spin summed matrix element omitting spin correlations. For a given\nset of production momenta, isotropic decay kinematics and new values of R are generated repeatedly\nuntil R is less than the aforesaid ratio, at which point the decay kinematics can be kept.\n\nSince the underlying Monte Carlo algorithm in this alternative approach is just the hit-or-miss method,\nwith no spin density matrices, spinor phases etc, to keep track of, this method is substantially easier to\nimplement than the one above. On the other hand this method assumes that a matrix element generator\ncapable of providing helicity amplitudes for (arbitrarily) high multiplicity final states is available, moreover,\nthe intention here is to simultaneously generate the momenta for all decaying particles, in 'one shot',\nwhich also impedes the event generation efficiency with respect to the recursive approach based on spin\ndensity matrices. Nevertheless, for including spin correlations in events with relatively few decays, this\nmethod offers a simple and straightforward alternative to the spin density matrix approach, where the\nrelative inefficiency tends to add little, with respect to other elements of the simulation, to the overall\nevent generation time. This method has been used widely in simulations based on the MC@NLO [12, 114]\nand POWHEG [14, 118, 124] methods.\n16.33\n\nQCD RADIATION\n\nHaving generated the decay momenta, with or without finite width effects and spin correlations, if the\nmother particle or any of the daughter particles carry a colour charge, one should attempt to model the\neffects of QCD radiation which they may emit. The vast majority of these emissions will be soft and / or\ncollinear emissions with respect to the shower progenitors. This is straightforward to understand from the\npoint of view of the associated amplitudes: in the limit that a massless particle is emitted with low pT , the\npropagator denominator, associated to the internal line that was its mother, vanishes so the matrix element\ndiverges for such configurations.\nSuch low pT corrections are precisely those which parton shower simulations take into account, to all\norders in perturbation theory. Of course, distributing emissions according to arbitrarily high multiplicity\n101\n\n\fmatrix elements is not feasible, instead we appeal to the fact that, in the limit that a massless parton j is\nemitted collinear from an external leg i, the matrix elements factorize according to\nMn+1 =\n\n8\u03c0\u03b1S\nP e \u2192ij Mn ,\n\u2212 m2e ij\n\nq 2e\nij\n\n(41)\n\nij\n\ne denotes the mother of the branching ij\ne \u2192 ij, with virtuality q 2 , and P e\nwhere ij\ne\nij\u2192ij is an Altarelli-Parisi\nij\nsplitting function. The form of the splitting functions does not depend on Mn+1 and Mn , where the\nlatter is the matrix element for the n particle process, in which the branching does not occur. The matrix\nelement factorization in Eq. (41) may be combined with a phase space factorization for the branching,\nleading to a factorized form of the differential cross section for the n + 1 particle process, in a similar\nvein to that described in Section 16.22, in the context of heavy particle decays. Here, as with cascade\ndecays, the factorization may be applied recursively, albeit with the caveat that using Eq. (41) implies\nthe emissions be ordered such that they become increasingly collinear as one works from the core of the\nprocess out toward the external legs. As well as modelling the effects of enhanced collinear real emission,\nthe parton shower method also, necessarily, incorporates their corresponding virtual corrections through\nSudakov form factors, the effect of which is to dampen, and ultimately regulate, the diverging emission\nrate as pT \u2192 0.\nDepending on the accuracy of the parton shower, there is some freedom in the definition of 'increasingly\ncollinear'. Parton shower algorithms may be formulated as an evolution in the virtualities of the branching\npartons, or as an evolution in the transverse momentum of the branching products. However, formal\nstudies of colour coherence [101, 140\u2013148] reveal that branchings involving soft gluons should be ordered\nin the angle between the branching products. This is a dynamical effect whereby wide-angle soft gluon\nemissions, from near collinear configurations of two or more partons, have insufficient transverse resolving\npower to be sensitive to the constituent emitters. In effect the resulting radiation pattern is determined by\nthe colour charge and momentum of the mother of the emitters, rather than the emitters themselves 30 .\n\nIn the LHC era we will regularly face the situation in which one cannot neglect the mass of radiating\nparticles when modelling the distribution of their emissions, tt\u0304 bar production being an obvious example.\nNevertheless, the Altarelli-Parisi splitting functions governing the distribution of emissions in the older\ngeneration of shower simulations are based on the factorization of matrix elements where the mother\ne and its two daughter partons i and j are all massless. As stated above, in the limit that massless\nparton, ij,\npartons emit low pT radiation the associated amplitudes diverge, however, if the emitter has a mass,\nthe propagator denominator is proportional to 1 \u2212 \u03b2 cos \u03b8 , where the factor of \u03b2, the velocity of the\nemitter, screens the collinear divergence. This mass effect in the propagator denominator then greatly\nalters the distribution of emissions as the small angle region is approached with respect to the rather\ncrude massless approximation, which will likely have important consequences for analyses e.g. the top\nmass determination, where a good understanding of production radiation and b quark fragmentation are\nkey. However, in recent years, developments in the resummation of radiation from massive partons have\nincluded the introduction of quasi-collinear splitting functions which generalize those of Altarelli and\nParisi, so as to retain the full dependence on the mass of the emitting particle in the collinear limit [227].\nFor example, the quasi-collinear q \u2192 qg splitting function is\n\"\n#\n2z (1 \u2212 z) m2q\n1 + z2\nPq\u2192qg = CF\n\u2212 2\n,\n(42)\n1\u2212z\npT + (1 \u2212 z)2 m2q\nin which z is the light-cone momentum fraction carried by the daughter quark and p2T is the transverse\nmomentum of the branching; note how the form of the first term in Eq. (42) is the same as the usual\nmassless q \u2192 qg Altarelli-Parisi function. The inclusion of these mass effects in parton shower simulations\n30\n\nTo avoid digressing from our stated objectives we limit ourselves to this minimal description of the parton shower\napproximation and refer the interested reader the following dedicated review articles [14, 18, 225, 226].\n\n102\n\n\fis actually non-trivial, since the full showering formalism is required to retain mass effects from the\nbeginning i.e. in the shower variables, the Sudakov form factors, the cut off scales, the phase space\nmapping and kinematics reconstruction / momentum reshuffling.\nSince, in the narrow width approximation, the production and decay processes are assumed to factorize\ninto two independent parts, this is the sense in which we simulate the associated parton showers, effectively\ntreating the decay as a completely independent hard sub-process. For the decay process the effects of\nQCD radiation are then simply modeled by initiating parton showers from the incoming and external\nparticles, in the rest frame of the decaying particle. Naturally then, for the decay products, the same\nfinal-state showering routines are applied as are used for the hard scattering process, including those used\nin the initialization phase in which starting scales are assigned. Only the initial conditions for the shower\nevolution are different, although their choice is, nevertheless, still based on examining the colour flow in\nthe underlying hard decay process.\nThe leading order decay products may not, however, be the only particles to emit radiation. Massive\ncoloured particles, such as the top quark and particles in many models of physics beyond the Standard\nModel, may decay on time-scales shorter than that characteristic of the hadronization process. Conse\u0001\nquently, subject to the available phase space, as well as undergoing time-like showers q 2 > m2\u0001 in\ntheir production phase, these particles will also undergo a further space-like showering q 2 < m2 of\nQCD radiation prior to their decay. In contrast to the final-state showers from the decay products, the\ninitial-state space-like shower created by a decaying particle is quite different to that of an initial-state\nparticle from the production process. In particular, it involves no PDFs, since the heavy parton originates\nfrom a hard scattering as opposed to a hadron. Furthermore, in the hard process it was necessary to evolve\nthe initial-state partons backwards from the hard scattering to the incident hadrons, to efficiently sample\nany resonant structure in the underlying matrix elements. On the contrary, in decay processes, degrading\nthe invariant mass of the decaying particle, via the emission of radiation, does not affect the efficiency\nwith which any resonant structures in the decay matrix element are sampled. Hence, it is natural for the\nevolution of space-like decay showers to start with the unstable particle from the production process,\nand evolve it forward, towards the decay. In the older generation of multi-purpose event generators the\ninclusion of this initial-state radiation in decays was not in general possible due to, for instance, their use\nof non-covariant shower formalism.\n16.34\n\nQED RADIATION\n\nIn existing Monte Carlo simulations the production of QED radiation in particle decays is normally\nsimulated using an interface to the PHOTOS program [228\u2013230]. This program is based on the collinear\napproximation for the radiation of photons together with corrections to reproduce the correct soft limit\n[228, 229]. In recent years the program has been improved to include the full next-to-leading order QED\ncorrections for certain decay processes [230\u2013232].\nAs noted previously, in the event that the decay products are heavy, the divergences associated to\nmultiple collinear emission are subject to a screening which increases with the mass of the emitter. On the\nother hand, since the propagator denominator associated to an emitter is also proportional to the energy of\nthe emitted particle, soft emissions are always enhanced regardless of the emitting particle's mass or the\nemission angle. This being the case it is often preferable, depending on the application / particle masses /\nanalysis cuts, to model the effects of photon radiation using a formalism which resums to all orders the\neffects of soft rather than collinear emissions.\nIn QED soft infrared divergences are resummed to all orders using the methods originally developed\nby Yennie Frautschi and Suura [233] (YFS), in doing so the soft real and virtual corrections are seen to\nexponentiate31 . This resummation has been recast as photon shower simulations through a tour de force\nin Monte Carlo techniques pioneered by S. Jadach [236\u2013241]. Such simulations have no overlap with\n31\n\nPedagogical examples of the exponentiation of infrared QED corrections may be found in Refs. [234, 235]\n\n103\n\n\ftheir QCD counterparts; whereas in QCD the shower forms through iterating emissions in a Markovian\nalgorithm, the YFS QED shower algorithms are Poissonian, generating all photon radiation at the same\ntime in 'one-shot', moreover they have always afforded the possibility to systematically include arbitrarily\nhigher-order corrections.\nFinally, we remark that soft resummation in QCD is fundamentally different since, unlike QED, each\nemitted parton is itself charged. Unfortunately such additional complexities arising from the non-Abelian\ncharacter of QCD mean that applying the same Monte Carlo approach to simulating QCD radiation,\ndespite its many attractive features, is unfortunately not appropriate.\n16.35\n\nHARD QCD RADIATION\n\nNote that the standard QCD parton shower approach has two important drawbacks. Firstly, because the\nparton shower generates emissions from each leg of the hard scattering independently, each additional\nemission must be uniquely associated to a particular leg of the hard scattering, which can only be achieved\nat the price of having regions of phase space, corresponding to high pT gluon emissions, which are\nunpopulated by the shower, so-called dead-zones. Secondly, the soft / collinear approximation to the QCD\nmatrix elements is plainly not a good approximation all over the phase-space region populated by the\nparton shower.\nOne way to rectify these problems is through matrix element corrections [24] which ensure that the\nhardest additional radiated parton in the event is distributed exactly according to the corresponding\nreal emission matrix element. In the case of soft matrix element corrections to decays, every emission\ngenerated in the shower which is the hardest so far is vetoed if the ratio of the exact differential width\nto the parton shower's approximation to it (based on the soft / collinear approximation to the former) is\ngreater than a random number R.\n\nWhere the parton shower algorithm is such that there is a dead zone in the phase space of the first\nemission, typically concentrated in the high pT region, hard matrix element corrections are also necessary.\nHard matrix element corrections simply use the same exact real emission matrix element to generate an\nevent with a hard emission in the dead zone, with a probability given by the ratio of the integrated cross\nsection in the dead zone divided by the total cross section of the leading order process. As a consequence\nof the different ordering variables used in the Herwig / Herwig++ and Pythia shower algorithms, the\nentire phase space for the first emission is covered in the latter, avoiding the need for hard matrix element\ncorrections.\nAlternatively one may use matrix element-parton shower matching techniques (ME-PS), such as the\nCKKW method, [4, 126] to correct the approximate soft / collinear radiation pattern of the parton shower\nin the regions of phase space corresponding to hard emissions, where in this case the hardness is typically\nmeasured in terms of the Durham jet measure. In general these ME-PS separate phase space into two\nregions according to a merging scale, defined in terms of the jet measure, ymerge . The region of phase\nspace corresponding to values of y < ymerge , is deemed to correspond to sufficiently soft / collinear\nemissions that one can expect the shower approximation to reliably distribute emissions there, this is the\nso-called shower region. Above the shower region is the matrix element region, where emissions are\ndistributed according to exact fixed order matrix elements. Of course the real emission fixed order matrix\nelements do not include any of the virtual effects resummed in the parton shower and so the emissions in\nthe matrix element region must be reweighted with Sudakov form factors and running coupling constants\nto take these important effects into account. Without these corrections distributions will exhibit unphysical\ndiscontinuities across the phase space partition at ymerge .\nBoth the matrix element correction methods and the ME-PS methods effectively take into account the\nreal emission component of next-to-leading order corrections but not the virtual effects. Nevertheless,\nthere are many examples in the literature (albeit for production processes) where these methods are shown\nto give excellent agreement with next-to-leading order calculations from the point of view of the shapes\n\n104\n\n\fof distributions [120, 121, 153\u2013155, 242].\n16.4 Herwig++\n\u2022 Finite width effects\nFinite width effects are present by default for all processes in Herwig++ through the inclusion\nof a weight factor as in Eq. (34), retaining the dependence of the width on the off-shell mass of\nthe particle, in both the production and decay stages. This approach is used in the simulation of\ncascade decays, where it was shown to give good agreement with results obtained using exact\nmatrix elements in Ref. [220].\n\u2022 Spin correlations\nThe Herwig++ spin correlation algorithm is precisely that described in Section 16.32 and was\nimplemented by the author of Ref. [224].\n\u2022 QCD radiation\nThe chief success of the older fortran Herwig 6 program was in its accounting of soft gluon\ninterference effects, specifically, in particular colour coherence phenomena, through the angular\nordering of emissions in the shower. The new Herwig++ algorithm retains angular ordering as\na central feature of the showering algorithm and improves on it, most notably, in the present\ncontext, through the inclusion of the mass-dependent splitting functions and kinematics, providing\na physical description of the radiation distribution emitted by massive particles in the low pT\nregion [21, 243, 244]. The facility to model initial-state parton showers in the decays of unstable\ncoloured particles was envisaged at the start of the Herwig++ project and has been implemented in\nfull generality in 2006.\n\u2022 QED radiation\nThe Herwig++ program includes a module which dresses the decays of light and heavy objects,\ninvolving a single electric dipole, with QED radiation [245]. This simulation uses the YFS\nformalism to resum the effects of multiple photon emissions, as well as a Poissonian shower\nalgorithm following the methods of Jadach [236].\n\u2022 Hard radiation\nIn implementing colour coherence through angular ordering the Herwig 6 and Herwig++ shower\nalgorithms contain dead zones in the phase space for the hardest emission, where the hardest\nemission occurs at wide angles with respect to the parent(s). In the context of particle decays\nHerwig++ includes matrix element corrections for top quark decays as described in [244]. This\nserves to populate the dead zone for this process and correct the radiation pattern in the live zones.\nMatrix element corrections to W \u00b1 , Z, and Higgs boson decays are not available, however, due\nto the neutrality of the decaying particle and the low mass of the negligible mass of their decay\nproducts, these may be implemented with quite a modest effort.\n16.5 Pythia\n\u2022 Finite width effects\nAll particles that are defined with a width are distributed according to a Breit-Wigner, cf. eq. (34).\nIn case of pure s-channel processes, such as e+ e\u2212 \u2192 \u03b3 \u2217 /Z 0 \u2192 f f , a running width is used,\nin agreement with LEP1 conventions. For other processes normally a fixed width is used. The\ninclusion of this width in the matrix-element expressions, especially the interference terms, may\nvary from process to process - Pythia 8 does not have a matrix-element generator of its own, but\nencodes calculations made by many different authors.\n\u2022 Spin correlations\nPythia 8 does not come with a spin correlation algorithm, which means that the default is isotropic\ndecays. For many processes and decays spin correlations are included with full matrix elements,\nhowever. That is, for a process such as e+ e\u2212 \u2192 W + W \u2212 \u2192 f1 f2 f3 f 4 , first kinematics (including\n105\n\n\fmasses) is selected for the e+ e\u2212 \u2192 W + W \u2212 process, and thereafter the decay angles of the two\nW 's are simultaneously sampled and weighted according to the complete 2 \u2192 2 \u2192 4 matrix\nelements. For cases where spin is important and not implemented, users are recommended to use\nexternal input from dedicated matrix-element programs, such as MadGraph [81].\n\u2022 QCD radiation\nThe original Pythia 8 shower algorithm was mass-ordered [246], with extra angular-ordering cuts,\nwhile the current one is transverse-momentum-ordered [69], with a dipole approach to handling\nrecoil effects. One nice feature of these algorithms is that they cover all of the phase space, at\nleast for the first emission, thus obviating the need for several of the special HERWIG tricks\ndescribed above, e.g. to handle dead zones or to separate off space-like emissions in resonance\ndecays. The modification of the evolution variable from dm2 /m2 to dm2 /(m2 \u2212 m20 ) gives a\nconsistent coverage of the soft/collinear region m2 \u2192 m20 for radiation off massive particles [247].\nHere m0 is the rest mass or, for a resonance, the previously Breit-Wigner-sampled mass. This\napproach is also easily extended to the case of evolution in p2\u22a5 = z(1 \u2212 z)m2 .\n\u2022 QED radiation\nThe same shower algorithm that does QCD emissions also can handle QED ones, in an interleaved\nmanner. That is, QCD and QED emissions can alternate in the downwards evolution in m2 or p2\u22a5 ,\nand thus compete for momentum. The QCD and QED dipoles do not need to agree.\nOptionally the PHOTOS package may be used [230\u2013232]; by experimentalists often to handle\nQED corrections in hadronic resonance decays.\n\u2022 Hard radiation\nThe Pythia shower can easily be fixed up to overestimate radiation in the hard region, while attaching\nto the correct expression in the soft one (see above). A Monte Carlo rejection factor can then be\nimplemented to match the first gluon emission to the respective QCD matrix-element expression for\nessentially all decays in the SM and the MSSM [247]. For QED such corrections are only included\nin \u03b3 \u2217 /Z 0 and W \u00b1 decays.\n16.6 Sherpa\n\u2022 Finite width effects\nIn Sherpa finite fixed widths are incorporated in the propagator denominators of the internal treelevel matrix element generators AMEGIC++ [149] and COMIX [150]. The fixed width scheme is\nemployed within these matrix element generators.\n\u2022 Spin correlations\nIn order to include spin correlations between production and decay Sherpa essentially employs the\nfirst algorithm described in the corresponding section above. The versatility of the implementation\nis enhanced by Sherpa's ability to automatically generate the matrix elements needed for the\nproduction and decay spin density matrices internally. Along this line, Sherpa allows on the level\nof hard matrix-element generation for the specification of the production and decay processes in a\ncascade-like manner. As a result contributions from non-resonant diagrams can be omitted while\none preserves off-shell mass effects and spin correlations in the generation of the fully decayed final\nstates. To incorporate spin correllations in the decays of hadrons and \u03c4 -leptons the simple rejection\nalgorithm outlined above is employed.\n\u2022 QCD radiation\nThe new generation of Sherpa versions 1.2.x uses the CSS parton-shower algorithm [89], which\nis based on (massive) Catani\u2013Seymour dipole subtraction kernels and a dipole-like picture of\nshower evolution. Emissions are ordered in transverse momentum rather than virtuality. The CSS\nimplements truncated showering, therefore handles final-state and initial-state emissions in the\nproduction and decay of unstable coloured particles, respectively. The Sherpa parton shower of\nversions 1.1.x and older, APACIC++ [248], is closely related to that of the Pythia virtuality ordered\nshower [18].\n106\n\n\f\u2022 QED radiation\nSherpa includes a native simulation of QED radiation in decays, PHOTONS++ [249]; like\nthe Herwig++ QED shower this module is built upon the YFS resummation formalism and the\nPoissonian shower algorithms of the Krakow group [236\u2013241].\n\u2022 Hard radiation\nHere again Sherpa makes use of its internal matrix element generators to generate amplitudes for the\nleading order processes in the presence of additional QCD radiation. The key point is that processes\nof different parton multiplicity in the final state can be combined consistently with parton showers\n(generated by the CSS algorithm) and hadronization included according to the new strategy of\nmatrix-element and truncated-shower merging (ME&TS) [65, 151, 152]. This approach improves\nover the CKKW method, implemented in versions 1.1.x and older, since it guarantees an unified\ntreatment of local scales in the calculation of the matrix elements and parton showers. Hence, one\nfinds that the systematic uncertainties of the ME&TS merging are sizeably reduced with respect to\nCKKW. Using the ME&TS matching, extra hard radiation can be reliably described in multi-jet and\nhigh-pT scenarios. For example, Sherpa employs the new method to include exact real emission\ncorrections to the tt\u0304 production process, as well as the t and t\u0304 decay processes, in the region of\nphase space above the ME&TS merging scale.\n\n107\n\n\fSENSITIVITY OF QCD JET MASS AND JET SUBSTRUCTURE TO PILE-UP AT LHC32\n\n17.\n17.1\n\nIntroduction\n\nNew methods to measure the hadronic decays of boosted massive particles at the LHC, like W bosons\n[182], top quarks (e.g., [185, 186, 250]), Higgs boson [158], and BSM particles (e.g., [183]), have been\nproposed in recent years. Due to the boost of these massive particles, the decay products are collimated\nin one direction, and they are reconstructed as one single jet. The properties of these jets, such as\ntheir masses and jet sub-structure quantities, can be used to separate them from the standard QCD jets.\nSeveral strategies have been developed to distinguish these two sources and to study the properties of the\ncorresponding jets, including the use of jet algorithms with variable size parameters [205], jet pruning,\nsee e.g. [193], and jet trimming [194].\nIn this study we investigate the impact of the pile-up on the measurement of these observables. The\npresence of the pile-up interactions affect the low transverse momentum (pT ) spectrum. We expect that it\nstrongly affects the jet energy calibration in the very low pT region, becoming negligible for high pT jets.\nThe estimate of the effects on the jet mass and on the the jet-substructure quantities is less straightforward\nbecause these quantities are complex QCD observables.\nAnother important aspect is the capability to properly reconstruct and calibrate the jets. There are\nseveral approaches to assess these points. Most of them are finalized at the calibration of the jet as a\nsingle global object starting from calorimetric signals. In this case, the capability to properly calibrate\nevery component (i.e. calorimetric signals) of the jet is not straightforward and the precision on the\nmeasurement of the substructure should be investigated in a detailed analysis of the detector performance.\nThis analysis is beyond our goal.\nIn this study only the effects of the pile-up and one simple strategy to suppress it are investigated.\nIn order to separate these effects from the detector calibration, we reconstructed jet from Monte Carlo\ngenerated particles (hadrons). The selection cuts, used to suppress the pile-up, are driven by consideration\nof the detector effects, especially for the reconstruction of low pT particles, i.e. the effect of the magnetic\nfield bending, energy losses in inactive material, and of the signal selection.\n17.2\n\nJet reconstruction, observables and selection cuts\n\nIn this study we used a sample of QCD di-jet events in proton-proton collisions with center of mass energy\n\u221a\ns = 10 TeV simulated with Pythia 8.120 [18, 20]. The generation was divided in different samples\naccording to the following bins (GeV) in p\u0302T : [17,34], [34,70], [70,140], [140,280], [280,560], [560,1120],\n> 1120. For the first six samples, 500,000 events were simulated, for the highest p\u0302T sample a simulation\nof 200,000 events was used.\nThe effect of the pile-up is taken in account by adding four (Poisson distributed) additional protonproton interactions per event. These interactions were simulated using the parameter \"SoftQCD:all\" in\nPythia 8.120, i.e. they include elastic, single diffractive, double diffractive scattering and minimum bias\ninteractions.\nAll the particles generated by the hard scatter and by the pile-up are used to build the final jets. The jet\nalgorithm used for this purpose is the anti-k\u22a5 [178] algorithm with distance parameter D = 0.4. Only the\nleading jet is used in this study. It is required to point into the pseudo-rapidity range \u22123.2 \u2264 \u03b7 \u2264 3.2.\n\nThe observables under consideration are the jet pT , its mass mjet , and the y-scale yscale [182] associated\nwith the last clustering step in the formation of the jet. For the Anti-k\u22a5 jet algorithm, this last observable\nis not directly available, as it only has a meaningful definition for the k\u22a5 [251, 252] jet algorithm. We\ntherefore re-clustered the constituent particles of the Anti-k\u22a5 jet using the k\u22a5 algorithm, thus allowing us\nto calculate its yscale .\nThe jet pT , mjet , and yscale are then compared jet-by-jet to the corresponding observables in jets\n32\n\nContributed by: P. Loch, P. Francavilla\n\n108\n\n\fwhich have been reconstructed using only the particles generated by the hard scattering process. Naming\nOHS+PU the observables in the presence of the pile-up and OHS the observables with only the hard scatter\nparticles, the ratio OHS+PU /OHS is shown in the following plots as a function of the number of pile-up\ninteractions (Nvtx ) generated in the event. To properly study these ratios, we should start the jet clustering\nusing only the particles generated by the hard scatter. In this paper we report a different way of defining\nthe jets. We use all particles (hard scatter and pile-up) to reconstruct the jets and then we look at the\nconstituents of the leading jet. From the list of constituents, we use the particles generated by the hard\nscatter to build the reference jet (and to calculate OHS ). This final reference jet is different from the jet\nreconstructed using only the hard scatter particles, but due to the peculiarities of the Anti-k\u22a5 jet algorithm,\nwe can expect a rather small difference introduced by this method.\nThe observables OHS+PU depend on the number of pile-up interactions. To suppress the effect of the\npile-up, which usually adds a set of low pT particles to the hard scatter, we used a threshold on the particle\npT , thus eliminating low pT particles. This method to suppress the effect of the pile-up is approximate for\njets reconstructed in the calorimeter, but gives us an estimate of how a selection on the constituents of the\njets, aimed to suppress contributions from pile-up, could change the dependence of the observables as a\nfunction of the number of pile-up interactions. We applied four different pT thresholds, namely: none, 0.5\nGeV, 1 GeV, and 2 GeV. The order of magnitude of this selection is similar to the effective cut-off that\naffect the charged particles in reaching the calorimeter due to the bending of the magnetic field, as in the\nATLAS detector [253] at LHC, and the typical minimum energy required in the central region to generate\na signal in the calorimeter at all (pT = 0.4 GeV).\nThese cuts are applied in two ways. The goal of the first one is the estimate of the effect of a pile-up\nsuppression after the jet reconstruction. For this purpose the cut is applied to the list of constituents of the\njet, after its reconstruction. The second way emulates a signal selection prior of the jet reconstruction in\nthat the cut is applied before the jet reconstruction. We refer to the first method as an inclusive selection\nand to the second as the exclusive selection. Due to the difference in the clustering, the reference is\ndifferent in the two cases.\nIn the following section the results for the different observables are shown.\n17.3\n17.31\n\nResults\nInclusive selection\n\nIn this section we show some of the results obtained using the inclusive selection discussed above. The\nresults are divided in different plots according to the windows in p\u0302T for the generation of the event.\nIn Fig.49 the dependence of pT,HS+PU /pT,HS as a function of number of pile-up interaction (Nvtx ) is\nshown. The different colors show the dependence for the selection cuts used in the analysis according\nto the following convention: red for none, blue for 0.5 GeV, green for 1 GeV and black for 2 GeV. The\ndifferent plots show that the variation as a function of Nvtx is smaller for bigger values of the threshold,\nbut introduces a bias especially for low pT (17-34 GeV). The 0.5 GeV and 1 GeV thresholds seem to be\nthe more appropriate, because they reduce the variation on the number of pile-up interactions to less than\n1% while introducing a bias smaller than 1% in the jet energy scale for jets with pT > 280 GeV. The 2\nGeV threshold suppresses the dependence on Nvtx , but the bias is bigger than 1% in some region of pT\nand a corresponding correction of the jet energy scale would be needed to reach an accurate calibration.\nIn Fig.50 the variations of the jet mass mjet are shown in various kinematic bins. These plots show\nsimilarities with respect to the figure 49. Even in this case, a selection of the constituents reduces the\nimpact of the pile-up interactions. The variation due to pile-up in absence of any constituent pT thresholds\ncuts is of the order of 20% even for the high pT jets, indicating the need for a selection. Again, thresholds\nof 0.5 GeV and 1 GeV are the most appropriate, reducing the pile-up dependence to 10% and 5%,\nrespectively, while introducing a respective bias of the order of 5% and 10%. The threshold of 2 GeV,\nwhich reduces significantly the pile-up variation from 20% to almost none, introduces a 20% bias.\n\n109\n\n\fa)\n\nb)\n\nc)\n\nd)\n\nFig. 49: Inclusive selection: comparison of the ratios of \u2206pT /pT = (pT,HS+PU \u2212 pT,HS )/pT,HS as\na function of the number of pile-up interactions for different windows of p\u0302T . Here red indicates no\nconstituent pT threshold, while blue/green/black indicate thresholds of 0.5/1.0/2.0 GeV, respectively.\nA similar behavior is shown in figure 51 for yscale . In this case, the 1 GeV threshold shows a good\nsuppression of the pile-up dependence, together with a bias of less than 5%.\n17.32\n\nExclusive selection\n\nIn the case of the exclusive selection, a particle selection cut using the pT thresholds is applied prior to jet\nreconstruction. In this case, the constituents differ from the inclusive selection even for the reference. The\npurpose of this part is the evaluation of an intrinsic selection due to instrumental effects, such as already\nmentioned bending of charged particle tracks in the magnetic field and the effect of inactive material in\nfront of the calorimeter. As for the inclusive selection, we expect a dependence of the observables on the\nnumber of pile-up interactions Nvtx . This dependence is reduced by applying the pT based selections.\nA comparison of the inclusive and exclusive selection is shown in Fig.52. This plot shows the ratio\npT,HS+PU /pT,HS for the two selections for different pT thresholds. Suppressing the low pT particles\nalready in the reference jet, the bias is no more visible, and only the residual dependence on the pile-up\nactivity is shown. This dependence is smaller than the dependence shown in the inclusive plot.\nThe results for the jet mass mjet and the y-scale yscale are shown in Fig. 53. These four plots show that\nthe variations of mjet and yscale are very similar, and 1 GeV or bigger pT threshold applied to the final\nstate particles is useful to reduce this dependence.\n17.4\n\nConclusion\n\nThe studies described in this paper show the dependence of some of the jet substructure observables on\nthe pile-up activities. The variation in the jet transverse momentum is less prominent for high pT jets, as\n110\n\n\fa)\n\nb)\n\nc)\n\nd)\n\nFig. 50: Inclusive selection: comparison of the ratios of \u2206mjet /mjet = (mjet,HS+PU \u2212 mjet,HS )/mjet,HS\nas a function of Nvtx , for different windows of p\u0302T . Again, red indicates no threshold, while\nblue/green/black indicate jet constituent pT thresholds of 0.5/1.0/2.0 GeV, respectively.\nexpected. In addition, a pT threshold cut on the constituents seems to be useful to accurately calibrate the\njet energy scale for high pT jets.\nFor the jet mass and the y-scale, the variation introduced by the pile-up is of the order of 2% per pile-up\ninteraction. If we consider an activity of between 0 to 10 pile-up interactions per signal event, the total\nvariation is of the order of 20%, even for high pT jets. In this case a pile-up suppression is needed and\napplying a pT threshold on the particles seems to reduce the dependence to 5-10% while introducing a\nsmall bias of 5-10%.\nThe effect of the pile-up has to be compared with the experimental capability to reconstruct and calibrate\nthe observables under investigation. This part is beyond the goal of this paper and it could be evaluated in\na realistic detector simulation, which takes in account all the detector effects. The effect of the pile-up and\nits suppression is an important ingredient to be taken into account when using complex QCD observables\nlike jet masses and substructure in an LHC analyses.\n\n111\n\n\fa)\n\nb)\n\nc)\n\nd)\n\nFig. 51: Inclusive selection: comparison of the ratios of \u2206yscale /yscale = (yscale,HS+PU \u2212\nyscale,HS )/yscale,HS as a function of Nvtx for different windows of p\u0302T (red: no selection, blue/green/black\n05/1.0/2.0 GeV thresholds).\n\nInclusive\n\nExclusive\n\nFig. 52: Comparison of the effect of exclusive and inclusive selections: the ratios of \u2206pT /pT =\n(pT,HS+PU \u2212 pT,HS )/pT,HS are shown as a function of the number of pile-up interactions Nvtx . The red\npoints indicate no threshold, while blue/green/black correspond to 05/1.0/2.0 GeV thresholds, respectively.\n\n112\n\n\fa)\n\nb)\n\nc)\n\nd)\n\nFig. 53: Exclusive selection: comparison of the ratios of \u2206mjet /mjet = (mjet,HS+PU \u2212mjet,HS )/mjet,HS\nand \u2206yscale /yscale = (yscale,HS+PU \u2212 yscale,HS /yscale,HS as a function of Nvtx , for different windows of\np\u0302T (red: no selection, blue/green/black 0.5/1.0/2.0 GeV pT thresholds).\n\n113\n\n\fA STUDY OF RADIATION BETWEEN JETS AT THE LHC 33\n\n18.\n18.1\n\nINTRODUCTION\n\nThe pattern of radiation between jets (or between jets and the proton remnant) ought to be very different\ndepending upon whether the exchanged state is a colour singlet or colour octet object. Particles are\nexpected to flow differently in \u03c6 regions both close to and far from the jets. The typical \u03b7 \u2212 \u03c6 scale of the\nradiation patterns is also relevant. Traditionally, either due to uncertainties in the theoretical predictions\nor because of the poor granularity of calorimeters used in hadron colliders, few of the fine details of\nradiation have been studied. Events generated by colour singlet or colour octet exchange have therefore\nbeen distinguished in the past by applying either a cut on the total sum of transverse momentum between\nthe two jets [254], or on the transverse momentum of a third jet between the two [255]. The presence\nof Underlying Event (UE) and especially of pile-up in hadron collisions will give rise to a very small\nefficiency for finding events with a clean gap between the jets. The efficiency may also be very sensitive\nto the details of the specific models. Radiation between jets has to be studied in data, using the most\npowerful techniques to separate the various contributions, and possibly reduce the effect of UE or pile-up.\nHere we present three different classes of observables that can be used for such studies: the distribution of\nradiation outside jets as a function of distance from the jet axis, using different jet algorithms; the \"gap\ngrid\" method, consisting of dividing the detector in several parts along \u03b7 and \u03a6 to exploit the different\nspace distribution of QCD radiation; and the application of a one-dimensional Fourier transformation to\nthe energy deposition in the event to highlight specific structures characterised by a given size.\n18.2\n\nRADIATION DISTRIBUTION CLOSE TO THE JET BOUNDARIES\n\nAs a first method, we studied the radiation distribution from events generated with Herwig 6 [17] close to\nthe jet boundaries, for various jet algorithms. This shows how the various algorithms differ for average\nQCD events at the LHC. Figure 54 shows the Et-weighted distribution of the \u2206R distance of truth-level\nparticles from the axis of the leading jet. Using different algorithms with radius (or measure) 0.4, figure\n54a shows the distribution of particles belonging to the jet, while 54b) shows particles outside of the jet.\nThe Anti-k\u22a5 algorithm shows a clear cut-off at the nominal value of the jet radius, as expected by its\ndefinition, while the other algorithms have a smoother behaviour. In particular the k\u22a5 algorithm has the\nlargest amount of radiation outside the nominal jet size.\nTotal pT of non-leading-jet particles at different distances in \u2206 R from the leading jet: RParam = 0.4\n\nTotal p / MeV\n\nAntiKt\nKt\nCamKt\n\n104\n\nSISCone\n\n3\n\n10\n\na)\n\n102\n\nAntiKt\n\n800\n\nKt\nCamKt\n\nT\n\nT\n\nTotal p / MeV\n\nTotal pT of leading-jet constituents at different distances in \u2206 R from the leading jet: RParam = 0.4\n\n700\n\nSISCone\n\n600\n\nb)\n\n500\n400\n\n10\n\n300\n1\n200\n10-1\n100\n10-2\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n0\n0\n\n\u2206R\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n\u2206R\n\nFig. 54: Energy flow for QCD colour octet events at a distance \u2206R from the jet axis using a) particles\nthat are constituents of the jet and b) particles not part of the jet.\nFigure 55 shows the same plots for events in which a colour singlet is exchanged between the two\nleading partons. Note that whilst 55a is broadly similar to 54a, 55b shows less than half the activity of\n54b for particles that are not part of the jet. Figure 55a in fact shows a slightly less sharp jet border at\nR=0.4 for colour singlet exchange because the generally lower amount of radiation in colour singlet events\nmeans that, in order to pass the jet ET cut, radiation must be drawn into the jet from a wider area. These\ncharacteristics will be exploited in the techniques described in the next sections.\n33\n\nContributed by: M. Campanelli, J. Monk, J. Robinson, C. Taylor\n\n114\n\n\fTotal p / MeV\n\nTotal pT of non-leading-jet particles at different distances in \u2206 R from the leading jet: RParam = 0.4\n\n104\n\nAntiKt\nKt\nSISCone\n\n3\n\n10\n\n102\n\n300\n\na)\n\nCamKt\n\n250\n\n150\n\n1\n\n100\n\n10-1\n\n50\n\n-2\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\nSISCone\n\nb)\n\n200\n\n10\n\n10\n\nAntiKt\nKt\n\nT\n\nCamKt\n\nT\n\nTotal p / MeV\n\nTotal pT of leading-jet constituents at different distances in \u2206 R from the leading jet: RParam = 0.4\n\n2\n\n0\n0\n\n\u2206R\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n\u2206R\n\nFig. 55: Energy flow for colour singlet exchange events at a distance \u2206R from the jet axis using a)\nparticles that are constituents of the jet and b) particles not part of the jet.\n18.3\n\nGAP GRID TECHNIQUE\n\nA method often used to distinguish events due to colour singlet and colour octet exchange is looking at\nthe total transverse energy in the rapidity range between two jets. Events due to colour-singlet exchange\n(no colour flows between the jets) are characterised by almost no radiation, their golden signature being\nan empty rapidity gap between the two jets.\nIt is easy to understand why this quantity is too inclusive to be optimal. Hard radiation from the jet\nitself can emit particles outside the jet boundaries independently of the type of event. On the other hand,\nparticles emitted by a colour connection between the jets tend to follow specific geometrical distributions,\nfor instance being quite uniform in rapidity and close in \u03c6 to the main jets. To study these differences, we\ndivide the detector into various regions according to the directions of the two jets with largest Et . First,\nthe area with |\u2206\u03b7| < 0.7 with respect to the axis of the first two jets is removed. The remaining area\nbetween the jets is divided into 16 regions of equal size in the \u03b7 \u2212 \u03c6 plane: four intervals of equal \u2206\u03b7\n(each one quarter of the eta difference between the two main jets minus 2 \u2217 0.7) and four of equal \u2206\u03a6\n(each of 90 degrees), with the \u03a6 = 0 angle defined as the region of the leading jet in the event, and the\nfirst region being comprised between \u221245\u25e6 and 45\u25e6 . The two detector areas between the jets and the\nbeam pipe are also divided in four regions each, according to the same \u2206\u03a6 convention.\nThe convention is that the regions between the two jets are labeled between 1 and 16, with regions 1 to\n4 being the closest in eta to the main jet (and ordered such that region 1 contains \u03a6 = 0, region 3 \u03a6 = \u03c0,\nregion 2 is the transverse one closer to the axis of the second jet and region 4 the remaining one) 5 to 8 for\nthe next \u03b7 region in the direction of the second jet, with the same convention with respect to \u2206\u03a6, etc.\nThe average transverse energy deposition in each of the detector areas is shown in Fig. 56a) for Herwig 6\ncolour singlet and colour octet events, the former shown with the Jimmy UE model [54] switched both\non and off. A clear difference between the various cases is visible, but what is more important is that\nthis difference is more marked in some regions than in others. For instance, and despite the cut at \u00b1 0.7,\nall three event classes show that both \u03b7 regions close to the jets receive more radiation than the central\nregions. This is due to the splash-out from the jets themselves; the two regions with similar \u03c6 to the main\njets also have more radiation - an effect that is more pronounced for the events with colour octet exchange.\nDividing the rapidity gap between the two main jets into several smaller regions not only allows a better\nunderstanding of the radiation patterns (for instance, to compare with different Monte Carlo models), but\nalso provides a more powerful separation between singlets and octets.\nThe presence of UE is a strong nuisance factor: without it some regions would almost be completely\ndevoid of radiation in the case of colour singlet exchange, which would make the identification of such\nevents very easy. Although there is no obvious way to identify radiation due to the UE (it is not even\na fully well-defined concept), it is on average softer than the main scattering process. A possibility to\nexploit this fact would simply be to impose a high threshold for clusters to be included in the density\ncalculation; however, it was shown in [256] that a better approach would be to establish this threshold\n\n115\n\n\fa)\n\nColour Singlet, no UE\n\nb)\n\n7\n\nColour singlet with UE\n\n6\n\nColour octet with UE\n\n6\n\n5\n\n5\n\n4\n\n4\n\n3\n\n3\n\n2\n\n2\n\n1\n\n1\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10 12 14 16 18 20 22 24\n\u03b7 - \u03c6 region\n\n2\n\n4\n\n6\n\n8\n\n<ET Density> [GeV]\n\n<ET density> [GeV]\n\n7\n\n10 12 14 16 18 20 22 24 0\n\u03b7 - \u03c6 region\n\nFig. 56: The average ET density in 24 different \u03b7 \u2212 \u03c6 regions. Regions 1 to 16 lie between the \u03b7 values\nof the leading two jets. Jets with colour octet exchange and UE present are shown as black dashed crosses.\nJets with colour singlet exchange are shown in red; solid data-points are events with UE present and dotted\ndata-points have UE turned off. a) on the left shows the ET density uncorrected for UE, b) on the right\nshows the effect of applying a correction for UE based upon the area of a jet and the average ET density\nper event.\non an event-by-event basis. Following this idea, we use the k\u22a5 algorithm with a small Et threshold to\ncluster into jets all energy depositions in the events. For each jet we calculate the active area, then define\nan ET density as the ratio of the jet transverse momentum and its area. All jets below 10 GeV per unit\nof rapidity squared are considered potential soft candidates; their average density on an event-by-event\nbasis is taken as the value of the soft density for the event. For all jets in the event an UE contribution\nis calculated as the product of this soft density and the area of each jet, and subtracted from the jet\ntransverse momentum. Finally, all jets whose transverse momentum after this subtraction is below 3 GeV\nare considered as coming from a soft UE-type interaction and are therefore removed. The advantage\nof this method with respect to applying a strong cut on all jets is that the amount of soft radiation is\ndetermined on an event-by-event basis, so coherent upward or downward fluctuations of the soft activity\ncan be accounted for. After this procedure, the density distribution for the various detector regions is\nshown in Fig.56b). An improvement with respect to the previous case is visible, with the additional\nadvantage of a smaller dependence on the MonteCarlo description of the soft interactions.\n18.4\n\nFOURIER TRANSFORMATION\n\nThe problem of separating the colour connection effect from the UE or pile-up is one of separating features\nof differing physical size in the event. The UE fills the whole detector with radiation at all \u03b7. Colour\nconnection effects between jets are typically smaller than this size, i.e. are approximately the size of the\njet-jet or jet-beamline interval. Hadronisation and showering effects can be expected to be of a similar to\nsmaller size. The hard jets will be smaller still, with a radius of R ' 0.5 and there may be jets originating\nfrom softer partons with R as small as 0.1.\nA Fourier-transformation of the spatial distribution of radiation in the event could separate the various\nscales, allowing an alternative reading of the energy flow. For the 1-dimensional case described here, we\nuse the \u03a6 distribution of the truth-level particles for each event, weighted by transverse energy summed\nin 32 bins covering the region 0-\u03c0. The axis of the hardest jet is taken as as the \u03a6 = 0 direction. We\nthen extract and use as our variables the first 32 complex coefficients of the Fourier expansion of this\n\u2217\ndistribution. Since these coefficients are linked by the relation Cn = CN\n\u2212n (where N=32), there are only\n\n116\n\n\f32 independent real coefficients, indicating no information is lost (or gained!) on the event-by-event basis\nin going from the 32 bins to the 32 coefficients.\n\n< Cn > [GeV]\n\nTo test the effectiveness of this method, we applied it to the problem of separating colour singlet\nand octet exchange in hadronic collisions. Colour singlet exchanges without UE are possibly the most\ndi-jet-like kind of events in a hadron collider. Since the \u03a6 = 0 direction is aligned to the axis of the\nleading jet, most of the remaining radiation will be concentrated around \u03a6 = \u03c0, which is the most likely\nlocation of the second jet. It is easy to show that odd coefficients can never have a peak at both 0 and \u03c0.\nFurther, the nth coefficient corresponds to correlated activity of size r ' \u03c0/n. Small-n odd coefficients,\ncorresponding as they do to large non-di-jet features, are therefore expected to be suppressed in perfect\ndi-jet events. This is exactly what is observed in Fig. 57, where the average magnitude of the various\ncoefficients is plotted for the two extreme cases of a set of colour-singlet exchange without the UE, and\ncolour octet exchange with UE.\n\n102\n\n10\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n14\n\n16\nn\n\nFig. 57: The average magnitude of the first 16 Fourier coefficients for colour singlet without UE (reddashed) and colour octet with UE (black-solid).\n\nThe suppression of the odd coefficients is clearly visible in the first case, and is much less pronounced\n(even if still present, since the events nevertheless contain di-jets) for the colour octet exchange case.\nAlthough there is also a difference between the even coefficients (especially at lower-n), it is much less\npronounced than for the odd coefficients. In particular, we expect coefficients 3 and 5 to originate from\nstructures of a similar size (\u03c0/3 ' 1) to the inter-jet radiation. Adding the UE does not change this picture\nsignificantly, since the uniform UE radiation will only influence the magnitude of coefficient zero, leaving\nthe mean values of the others almost unchanged. This is shown more clearly in Fig.58, which shows the\ndistribution of the magnitude of the 3rd coefficient for colour singlet and colour octet events. There is a\nclear difference between the two types of event and the presence or absence of UE makes little difference\nto the shape of the distribution from colour singlet events.\nAnother potentially interesting variable to look at is the number of the largest coefficient for each event,\nwhich shows the scale of the dominant feature in the event. Figure 59 shows the distribution of the largest\nimaginary coefficient in the event, for the two classes of colour exchange, both with UE on.\nWhile for ordinary QCD events this distribution is peaked at low values, this is not the case for colour\nsinglet events, where there is a peak around coefficient 8 that corresponds to radiation concentrations of\nsize \u03c0/8 ' 0.4, roughly the size of a jet. Further, in the colour singlet sample there is a relative depletion\n117\n\n\fFig. 58: Distribution of the magnitude of the 3rd coefficient for colour singlet without UE (red-dotted),\ncolour singlet with UE (red-solid) and colour octet with UE (black-dashed). The addition of UE makes\nlittle difference to the colour singlet distributions, whilst there is a clear difference between colour octet\nand colour singlet.\n\nof events in which the largest coefficient was either 3 or 5. More details on the Fourier transformation\nmethod can be found in [257].\nCONCLUSIONS\nRadiation between jets is a key topic for understanding the interplay between hard and soft QCD, and will\nbe the object of many measurements with the first LHC data. Here we propose new methods to study\nthis radiation in more detail than has been done in the past. The first measurements of these observables\nwill offer interesting handles on the discrimination of the various theoretical models. To show the strong\nand weak points of the methods we applied them to the problem of separation between colour singlet and\ncolour octet exchange events, but the techniques presented here are more general, and can be applied to\nmost of the fully-hadronic final states produced by the first LHC data.\n\n118\n\n\fEvent fraction\n\n0.12\n\n0.1\n\n0.08\n\n0.06\n\n0.04\n\n0.02\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n14\n\n16\n\nn\n\nFig. 59: The largest imaginary coefficient in the event. Solid black shows colour-octet exchange events\nand dotted-red shows colour singlet exchange. Both event samples have the underlying event model turned\non. The colour octet sample shows a peak towards lower n, indicating more events have their inter-jet\nactivity dominated by features that are large in \u03b7 \u2212 \u03c6. The colour singlet sample, on the other hand, shows\nmore events whose inter-jet radiation is dominated by features of size r ' 8/\u03c0.\n\n119\n\n\fPart VI\n\nBEYOND THE STANDARD MODEL\nAN UPDATE OF THE PROGRAM HDECAY34\n\n19.\n19.1\n\nINTRODUCTION\n\nThe search strategies for Higgs bosons at LEP, Tevatron, LHC and future e+ e\u2212 linear colliders (LC)\nexploit various Higgs boson decay channels. The strategies depend not only on the experimental setup\n(hadron versus lepton colliders) but also on the theoretical scenarios: the Standard Model (SM) or some of\nits extensions such as the Minimal Supersymmetric Standard Model (MSSM). It is of vital importance to\nhave reliable predictions for the branching ratios of the Higgs boson decays for these theoretical models.\nThe current version of the program HDECAY [258] can be used to calculate Higgs boson partial decay\nwidths and branching ratios within the SM and the MSSM and includes:\n\u2013 All decay channels that are kinematically allowed and which have branching ratios larger than 10\u22124 ,\ni.e. the loop mediated, the three body decay modes and in the MSSM the cascade and the supersymmetric\ndecay channels [111, 259, 260].\n\u2013 All relevant higher-order QCD corrections to the decays into quark pairs and to the loop mediated decays\ninto gluons are incorporated [261].\n\u2013 Double off\u2013shell decays of the CP\u2013even Higgs bosons into massive gauge bosons which then decay into\nfour massless fermions, and all important below\u2013threshold three\u2013body decays [262].\n\u2013 In the MSSM, the complete radiative corrections in the effective potential approach with full mixing\nin the stop/sbottom sectors; it uses the renormalization group improved values of the Higgs masses and\ncouplings and the relevant next\u2013to\u2013leading\u2013order corrections are implemented [263\u2013266].\n\u2013 In the MSSM, all the decays into SUSY particles (neutralinos, charginos, sleptons and squarks including\nmixing in the stop, sbottom and stau sectors) when they are kinematically allowed [267\u2013269]. The SUSY\nparticles are also included in the loop mediated \u03b3\u03b3 and gg decay channels.\nThe source code of the program, written in FORTRAN, has been tested on computers running under\ndifferent operating systems. The program provides a very flexible and convenient use, fitting to all options\nof phenomenological relevance. The basic input parameters, fermion and gauge boson masses and their\ntotal widths, coupling constants and, in the MSSM, soft SUSY-breaking parameters can be chosen from\nan input file. In this file several flags allow switching on/off or changing some options [e.g. choosing\na particular Higgs boson, including/excluding the multi-body or SUSY decays, or including/excluding\nspecific higher-order QCD corrections].\n19.2\n\nUPDATES\n\nSince the release of the original version of the program several bugs have been fixed and a number of\nimprovements and new theoretical calculations have been implemented. The following points summarize\nthe most important modifications of HDECAY after its release:\n\u2013 Implementation of Higgs boson decays to gravitino + gaugino [270]. A flag in the input file controls\nwhether these decay modes are taken into account or not.\n\u2013 Inclusion of SUSY\u2013QCD corrections in neutral MSSM Higgs decays to bb\u0304 [271, 272] and resummation\nof \u2206b effects [273, 274] up to NNLO [275, 276]. The corresponding \u2206b terms have also been included in\ncharged Higgs decays H \u00b1 \u2192 tb.\n34\n\nContributed by: A. Djouadi, J. Kalinowski, M. M\u00fchlleitner and M. Spira\n\n120\n\n\f\u2013 Determination and inclusion of the RG improved two-loop contributions to the MSSM Higgs selfinteractions. These two-loop corrections extend the results of Ref. [263] for the stop and sbottom\ncontributions for arbitrary mixing parameters and mass splitting, where they have only been displayed\nfor the scalar CP-even Higgs mass matrix. We have checked explicitely that we reproduce the results of\nRef. [263].\n\u2013 An interface to the SUSY Les Houches Accord (SLHA) [43, 44] has been implemented properly. This\nrequired several transformations of the corresponding renormalization schemes to the ones used by\nHDECAY. This option can be switched on and off by appropriate flags in the input file. The output file in\nthe SLHA format can also be used again as input file. Moreover, the automatic generation of the SLHA\ninput file according to the input parameters of HDECAY is provided as an option.\n\u2013 Inclusion of the full mass dependence of the NLO QCD corrections to the quark and squark loop\ncontributions to photonic Higgs decays \u03c6 \u2192 \u03b3\u03b3 [277\u2013282]. This decay width can now also be used to\ndetermine the production cross sections of Higgs bosons at photon colliders at NLO QCD.\n\u2013 Inclusion of electroweak corrections to the SM Higgs boson decays H \u2192 W (\u2217) W (\u2217) /Z (\u2217) Z (\u2217) \u2192 4f\n1.02\nHDECAY / PROPHECY4F\n1.015\n1.01\n1.005\nZZ\n1\n0.995\nWW\n0.99\n0.985\n0.98\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\nMH [GeV]\n\nFig. 60: Ratio of the partial widths of H \u2192 W (\u2217) W (\u2217) /Z (\u2217) Z (\u2217) \u2192 4f from HDECAY and\nPROPHECY4F [283, 284].\n\nin approximate form which reproduces the full results of Refs. [283, 284] within 1% as can be inferred\nfrom Fig. 60, where the ratios of the partial decay widths into W (\u2217) W (\u2217) and Z (\u2217) Z (\u2217) are shown as a\nfunction of the Standard Model Higgs mass. The improved Born approximation of Ref. [283, 284] has\nbeen implemented with additional improvements at the W W and ZZ thresholds.\nThe logbook of all modifications and the most recent version of the program can be found on the web\npage http://people.web.psi.ch/spira/proglist.html.\n\nACKNOWLEDGEMENTS\nThis work is supported in part by the European Community's Marie-Curie Research Training Network\nHEPTOOLS under contract MRTN-CT-2006-035505.\n\n121\n\n\f20.\n20.1\n\nIMPLEMENTATION AND VALIDATION OF MODELS BEYOND THE STANDARD MODEL\nWITH FEYNRULES 35\nINTRODUCTION\n\nMonte Carlo event generators play an important role in making reliable predictions for the events to be\nobserved at collider experiments, both to describe the backgrounds and possible candidate signals. In\nparticular, the simulation of a hadronic collision requires not only an accurate description of the underlying\nhard scattering process, but also of subsequent parton showering and hadronization as efficiently provided\nby programs such as H ERWIG [21,136], P YTHIA [18,20] and S HERPA [22,23]. As regards the generation of\nthe hard matrix element itself, a lot of effort has gone into the development of several multipurpose matrix\nelement generators, such as C OMP H EP/C ALC H EP [285\u2013287], M AD G RAPH/M AD E VENT [80,81,288,289],\nS HERPA and W HIZARD [211, 290]. Even though these programs are in principle able to generate the\n(tree-level) matrix element for any process in the framework of a given renormalizable quantum field\ntheory built on scalar, vector and fermion fields, the implementation of a full Beyond Standard Model\n(BSM) theory can be a tedious and error-prone task, often requiring the implementation of one vertex at\nthe time following the conventions specific to each code.\nIn this section a summary report on the implementation and validation of BSM models into multipurpose matrix element generators is presented. The starting point of our approach is F EYN RULES [291],\na M ATHEMATICA\u00ae36 package that allows to compute Feynman rules from a Lagrangian in an automated\nway. Furthermore, F EYN RULES contains a set of interfaces to various matrix element generators,\nallowing to implement the model into a given tool in an automated way. For the moment, interfaces to\nC OMP H EP/C ALC H EP, F EYNA RTS/F ORM C ALC [292\u2013297], M AD G RAPH/M AD E VENT and S HERPA are\navailable37 . A first step in the direction of deriving Feynman rules automatically starting from a model\nLagrangian has been made in the context of the C OMP H EP/C ALC H EP event generator with the L AN H EP\npackage [298]. Our aim is to go beyond this scheme and create a general and flexible environment where\ncommunication between theorists and experimentalists in both directions is fast and robust. First, the use\nof M ATHEMATICA as a working environment provides a powerful and user-friendly platform where BSM\nmodels can be developed and implemented. Second, the possibility to export the model to more than one\nmatrix element generator enhances the chances that the model can be successfully dealt with by more\nthan one code. Furthermore, since many of these matrix element generators are already embedded in\nthe experimental softwares, the new models can easily be integrated into the experimental framework,\nallowing in this way for an efficient communication between theorists and the experimental community.\nAs the starting point of our approach is F EYN RULES, we briefly recall its basic features in Section 20.2\nand discuss recent developments triggered by the activities and the discussions at the Les Houches\nworkshop. In Section 20.3 we present a proposal of how new BSM models can be easily validated\nexploiting the fact that once a F EYN RULES implementation is available, the model can easily be exported\nto various matrix element generators. In Section 20.4 we discuss the implementation of several new\nmodels that were implemented and/or validated as an outcome of the workshop.\n20.2\n\nRECENT DEVELOPMENTS IN FEYNRULES\n\nF EYN RULES is a M ATHEMATICA package that allows to compute Feynman rules directly from a Lagrangian in an automated way. The user provides the Lagrangian for the model (written in M ATHEMATICA)\nas well as all the information about the particle content and the parameters of the model. This information\nuniquely defines the model, and hence is enough to derive all the interaction vertices from the Lagrangian.\nF EYN RULES can in principle be used with any model which fulfills basic quantum field theoretical\nrequirements (e.g., Lorentz and gauge invariance), the only limitation coming from the kinds of fields\n35\n\nContributed by: L. Basso, F. Braam, C. Duhr, B. Fuks, A. Martin, J. Reuter, T. Roy, S. Schumann\nM ATHEMATICA is a registered trademark of Wolfram Research, Inc.\n37\nAn interface to W HIZARD will be available in the near future.\n36\n\n122\n\n\fsupported by F EYN RULES. As to date, the public release of F EYN RULES supports scalar, vector, fermion\n(Dirac and Majorana) and spin-two fields, as well as Faddeev-Poppov ghosts, and very recently, also\nWeyl fermions have been included38 , as will be described at the end of this section. In a second step, the\ninteraction vertices obtained by F EYN RULES can be exported to various matrix element generators by\nmeans of interfaces provided by the package [299]. Let us note that even though F EYN RULES itself can\nin principle be used to obtain the Feynman rules for any Lagrangian, the matrix element generators very\noften have certain information on the color and/or Lorentz structures hardcoded. In this case the interfaces\ncheck whether all the vertices are compliant with the structures supported by the corresponding matrix\nelement generator, and if not, a warning is printed and the vertex is discarded. Each interface produces at\nthe end a (set of) text file(s), often consistently organized in a single directory, which can be read into the\nmatrix element generator at runtime and allows to use the new model in a way similar to all other built-in\nmodels.\nAs already mentioned, the most important recent development concerns the possibility to write Lagrangians in terms of two-component Weyl fermions. In the following we give a brief description how\nthis new feature can be used inside F EYN RULES. Weyl fermions can be declared in the model file in\nexactly the same way as other particle classes, e.g.,\nW[1] == {\nClassName\n-> chi,\nChirality\n-> Left,\nSelfConjugate -> False},\nW[2] == {\nClassName\n-> xibar,\nChirality\n-> Right,\nSelfConjugate -> False}.\nThe particle class W refers to Weyl fermions, and we have defined in this way one left-handed and one\nright-handed Weyl fermions named chi and xi, respectively. Let us note that all other options allowed\nfor fields are also available for Weyl fermions (See the F EYN RULES manual [300]). Along the same lines,\nthere is a new option for Dirac fermions specifying their left and right-handed Weyl components, e.g.,\nF[1] == {\nClassName\nSelfConjugate\nWeylComponents\n\n-> psi,\n-> False,\n-> {chi, xibar}}.\n\nMore details on the use of Weyl fermions in F EYN RULES will be presented in a forthcoming publication.\nHere it suffices to say that since matrix element generators work with four-component spinors rather than\nWeyl fermions, F EYN RULES replaces at runtime all Weyl fermions by the corresponding Dirac fermion\n \u0304 T according to the prescription,\n\u03c8 = (\u03c7, \u03be)\n\u03c7\u2192\n\n1 \u2212 \u03b35\n\u03c8,\n2\n\n\u03be\u2192\n\n1 \u2212 \u03b35 c\n\u03c8 ,\n2\n\n1 + \u03b35\n\u03be \u0304 \u2192\n\u03c8,\n2\n\n\u03c7\u0304 \u2192\n\n1 + \u03b35 c\n\u03c8 ,\n2\n\nwhere \u03c8 c = C \u03c8\u0304 T = (\u03be, \u03c7\u0304)T denotes the charge conjugated Dirac spinor. After these replacements, the\nLagrangian is expressed completely in terms of four-component Dirac and Majorana spinors, and the\nFeynman rules can be exported to the matrix element generators in the standard form.\nThe two-component formalism we have just described can be extremely useful when dealing with\nsupersymmetric extensions of the SM, where Weyl fermions appear as the natural fermionic degrees\n38\n\nThis feature is still beta and will be made public with the next major release.\n\n123\n\n\fof freedom of chiral and gauge superfields. Let us note that this is just the first step of a more general\nproject which aims at implementing superfields directly into F EYN RULES. In particular, we applied\nthe Weyl-fermion formalism to rewrite the existing MSSM implementation in F EYN RULES [299, 300]\ncompletely in terms of two-component spinors, as well as to the implementation of the minimal Rsymmetric supersymmetric extension of the SM described in Section 20.43. The validation of these (and\nother) new model implementations was done following the procedure described in the next section.\n20.3\n\nVALIDATION PROCEDURE FOR BSM MODELS\n\nThe requirements for a BSM model implementation that ensure a fast and efficient communication\nbetween all the actors involved in the simulation chain, both on the experimental and theoretical side, are\nmanifold. The first obvious requirement is that the implementation produces reliable results when used\nwith a matrix element generator, both from the perspective of the theoretical consistency of the model\n(e.g., gauge invariance,...), as well as regarding the technical aspects of the matrix element generator\nunder consideration (e.g., conventions used in the code,...). A robust validation procedure must hence\ncombine these two aspects, which however rely on two disconnected fields of expertise: if theoretical\nconsistency is purely related to the physics content of the model, testing the technical aspects of the\nimplementation requires for example detailed knowledge of the programming language used in the matrix\nelement generators. Second, to ensure traceability both of the implemented models as well as of the\ngenerated event samples, every implementation of a BSM model into a matrix element generator must be\nclearly documented so that all the information about the physics content of the model and the choice of\nthe parameters can be retraced at any point in the chain.\nIn Refs. [210, 299], several BSM implementation were validated by comparing the results obtained with\ndifferent matrix element generators among themselves. In this section we propose an evolution of this\nstrategy for the validation of a generic BSM model implementation, and we argue that the F EYN RULES\napproach offers a natural framework where BSM models cannot only be easily developed and implemented,\nbut can also be validated to an unprecedented level. Since the F EYN RULES model files are built around\nthe Lagrangian of the model, all the information about the physics content of the implementation is\ncentered in one place and can be accessed at any point in the simulation chain, without being obscured by\nthe conventions imposed by a specific matrix element generator. Furthermore, one can exploit the fact\nthat F EYN RULES offers the possibility to implement the model into various generators and that different\ncodes use different conventions and/or work in different gauges. In this way one can very easily check the\nsanity of an implementation by cross-checking the results obtained with different codes. For example,\nonce a F EYN RULES implementation is available, the Feynman rules can be obtained automatically and\nthen used to cross-check analytical results for simple processes against known results from the literature,\na step that could even be automatized by using the F EYN RULES interface to F EYNA RTS/F ORM C ALC.\nAfter the model has passed successfully all of these tests, a more detailed study of the implementation\ncan be performed by comparing the results of different matrix element generators for a large number\nof (tree-level) processes. In this way, it is not only very easy to show that the implementation produces\nreliable results for all matrix element generators involved, but it also provides a very natural and fast way\nto test the theoretical consistency of the model, by computing the results in different gauges, testing the\nhigh-energy behavior of certain processes, etc.\nTo quantify the level to which a given BSM implementation has been validated, we propose in the\nfollowing a four-step procedure to rate BSM model implementations regarding their validation. In this\nscheme, every implementation is awarded one credit for each completed step, with a maximum of four for\nmodels tested to a very high extent in all matrix element generators. More explicitly, the four steps are:\n1. Documentation [First credit] : A first credit is awarded if the implementation is documented to\nensure traceability and reproducibility. Information about the model should be included in the\nF EYN RULES model file via the M$ModelInformation variable (See the F EYN RULES manual),\nand should contain a twofold information:\n124\n\n\f\u2022 All references to the original publications where the model was first presented should be\nincluded, to ensure that the Lagrangian, its field content and the relations between parameters\ncan be traced back at any time. This also includes references to other codes involved in\nthe writing of the model file, e.g., spectrum generators. In case the implemented model is\nincomplete or consists only in a theory fragment, this should be clearly stated.\n\u2022 The operating system (Linux distribution, Mac OS, ...) and the versions of M ATHEMATICA\nand F EYN RULES (as well as all other codes, if relevant) used to write the model file must be\nprovided in order to ensure reproducibility at later times.\n2. Basic theory sanity checks [Second credit] : A second credit is awarded for testing that the\nmodel satisfies the constraints imposed by quantum field theory, e.g., checking the hermiticity and\ngauge invariance of the implemented Lagrangian. If the Feynman rules for the model are known\nin the literature, they should be compared to the results obtained by F EYN RULES for this model.\nFurthermore, simple two-to-two cross sections and/or decay rates can be easily computed either by\nhand or by means of F EYNA RTS/F ORM C ALC and the corresponding F EYN RULES interface and\ncompared to known analytic results (if available).\n3. Testing one matrix element generator [Third credit] : After the theoretical sanity of the implementation has been checked, a more detailed validation of the model can be performed by exporting\nit to a matrix element generator, both to exclude mistakes in the implemented model as well as to\nensure that the implementation can be used in a reliable way with a given code.\n\u2022 Basic processes like Drell-Yan and Bhabba scattering can be used to check that the matrix\nelement generator produces reliable results for the corresponding cross-sections, followed by\na more systematic study of several two-to-two and/or two-to-three key processes of interest\nin this model. A particular emphasis should be brought to the running of the strong and/or\nelectromagnetic couplings, as well as to the reproduction of known SM cross section results\nfor the sectors of the model unaffected by the BSM physics.\n\u2022 In case an independent (partial) implementation of the model is available, a comparison of the\ntwo implementations should be performed.\n\u2022 The high-energy behavior of the model can be easily checked numerically to ensure that all\ngauge and unitarity cancellations take place in a numerically stable and reliable way. Note that\nfor such cancellations to take place exactly at tree-level, it is required that all particles have\nzero width, i.e., all widths of all particles should be put to zero while performing these tests.\n\u2022 Some matrix element generators, like for example C ALC H EP, offer the possibility to choose\nbetween different gauges. In this case gauge invariance can be easily tested by running the\nsame processes in different gauges.\n\u2022 The outcomes of the previous steps, i.e., the numerical results for the cross sections for all the\ntested processes, should be summarized and made public together with the model file(s) for\nfuture reference. Let us note that in order to ensure reproducibility, it is important to include\nthe center-of-mass energy and all final state cuts, as well as the version number of the matrix\nelement generator involved.\n4. Testing several matrix element generators [4th credit] : Since F EYN RULES offers the possibility\nto obtain implementations into several matrix element generators, it is very easy to repeat the\nprevious steps for more than one program. In this way a very sensible validation of the model can\nbe achieved, by exploiting for example the fact that different codes may work in different gauges.\nAgain, to ensure reproducibility, the results should be summarized and made public together with\nthe model.\n\n125\n\n\fProcess\n\u2192 Z h0\n+\n\u2212\nW W\n\u2192 H+ H\u2212\nu \u016b \u2192  \u0303l3\u2212  \u0303l3+\nu \u016b \u2192 \u01695 \u0169\u22172\n\u2212\nb b\u0304 \u2192 \u03c7\u0303+\n2 \u03c7\u03032\n\u2212 0\nb t\u0304 \u2192 \u03c7\u03032 \u03c7\u03033\nZ \u03b3 \u2192  \u0303l2\u2212  \u0303l2+\ng W \u2212 \u2192 d \u03035 \u0169\u22175\n\u2212\n\u03b3 \u03b3 \u2192 \u03c7\u0303+\n1 \u03c7\u03031\n\u2212\n\u2212\n0\nW \u03b3 \u2192 \u03c7\u03032 \u03c7\u03032\ne+ e\u2212\n\nMG (FR)\n8.787e\u22123\n3.689e\u22122\n2.123e\u22123\n6.141e\u22121\n9.556e\u22122\n3.981e\u22122\n1.712e\u22122\n2.569e\u22121\n6.250e\u22121\n5.235e\u22122\n\nMG (ST)\n8.788e\u22123\n3.686e\u22122\n2.123e\u22123\n6.142e\u22121\n9.545e\u22122\n3.971e\u22122\n1.711e\u22122\n2.566e\u22121\n6.263e\u22121\n5.235e\u22122\n\nCH (FR)\n8.787e\u22123\n3.685e\u22122\n2.123e\u22123\n6.141e\u22121\n9.556e\u22122\n3.977e\u22122\n1.712e\u22122\n2.566e\u22121\n6.257e\u22121\n5.236e\u22122\n\nCH (ST)\n8.787e\u22123\n3.685e\u22122\n2.123e\u22123\n6.141e\u22121\n9.556e\u22122\n3.977e\u22122\n1.712e\u22122\n2.566e\u22121\n6.257e\u22121\n5.236e\u22122\n\nSH (FR)\n8.788e\u22123\n3.685e\u22122\n2.123e\u22123\n6.141e\u22121\n9.555e\u22122\n3.977e\u22122\n1.712e\u22122\n2.565e\u22121\n6.257e\u22121\n5.238e\u22122\n\nSH (ST)\n8.788e\u22123\n3.685e\u22122\n2.123e\u22123\n6.141e\u22121\n9.555e\u22122\n3.977e\u22122\n1.713e\u22122\n2.565e\u22121\n6.255e\u22121\n5.238e\u22122\n\nTable 7: Cross sections for a selection of production processes in the MSSM scenario SPS 1a. The\nbuilt-in MSSM implementation in C ALC H EP, M AD G RAPH and S HERPA are denoted MG (ST), CH (ST)\nand SH (ST), respectively, while the F EYN RULES-generated ones are MG (FR), CH (FR) and SH (FR).\nThe center-of-mass energy is fixed to 1200 GeV.\n\nThe rating scheme we just described will be applied to the model database on the F EYN RULES website.\nThe F EYN RULES model database offers to every user the possibility to make their model files accessible\nto the community. Every model is assigned a personal web page where the model can be described and all\nrelevant files can be made public for download. By applying the described rating scheme to the model\ndatabase it will be possible to progressively build a database of robust BSM model implementations that\ncan be used in a large variety of different matrix element generators while still assuring traceability and\nreproducibility at any time.\nLet us conclude this section by illustrating this validation procedure on the example of the F EYN RULES\nimplementation of the MSSM. After having implemented the model in F EYN RULES, we have compared\nthe Feynman rules computed by F EYN RULES to those which can be found in the literature, both for the\ngeneral MSSM [301,302] and for a constraint MSSM where all the scalar mixings are neglected [303,304],\nand we have found agreement for all the vertices. Then, we have re-calculated all tree-level squark and\ngaugino hadroproduction helicity amplitudes in the case of general (and possibly complex) scalar mixing\nwith the help of F EYNA RTS/F ORM C ALC and the corresponding model file generated by F EYN RULES.\nThe results have been compared to the analytical formulas given in Refs. [305, 306] and we have found\ncomplete agreement. In order to validate the F EYN RULES-generated model files for the various matrix\nelement generators, we have considered the very particular limit of the typical minimal supergravity point\nSPS 1a [307] and compared the cross section for 626 two-to-two processes in C ALC H EP, M AD G RAPH\nand S HERPA to the results obtained by the built-in MSSM implementations in C ALC H EP, M AD G RAPH\nand S HERPA. For all the tested processes we have found perfect agreement. Note that M AD G RAPH\nand S HERPA work in unitary gauge exclusively, whereas C ALC H EP employs Feynman gauge for QCD\nprocesses39 . In this way we have demonstrated explicitly that our implementation is gauge invariant (at\nleast in the strongly interacting sector). Furthermore, we have payed particular attention to weak boson\nscattering processes to ensure that all unitarity cancellation at high energy take place correctly. A very\nshort selection of the results we obtained are shown in Table 7. The full list of tested processes, together\nwith the results for the cross sections, is available from the F EYN RULES model database.\n39\n\nLet us note that for the electroweak sector, C ALC H EP can in principle work both in unitary or Feynman gauge. At present,\nour implementation is performed in unitary gauge only for the electroweak sector.\n\n126\n\n\f20.4\n20.41\n\nRECENTLY IMPLEMENTED MODELS\nTHE MINIMAL B \u2212 L MODEL\n\nIn this section we discuss the implementation of the so-called \"pure\" or \"minimal\" B \u2212 L model (see\nRef. [308] for conventions and references) that features vanishing mixing between the two U (1)Y and\nU (1)B\u2212L gauge groups. The classical gauge invariant Lagrangian of this model obeys the gauge symmetry,\nSU (3)C \u00d7 SU (2)L \u00d7 U (1)Y \u00d7 U (1)B\u2212L ,\n\n(43)\n\nand can be decomposed as L = LY M + Ls + Lf + LY . The non-Abelian field strengths in LY M are the\nsame as in the SM whereas the Abelian ones can be written as follows,\n1 \u03bc\u03bd\n1 0\u03bc\u03bd 0\nLAbel\nF\u03bc\u03bd ,\nY M = \u2212 F F\u03bc\u03bd \u2212 F\n4\n4\n\n(44)\n\n0 = \u2202 B 0 \u2212 \u2202 B 0 . In this field basis, the covariant derivative reads,\nwhere F\u03bc\u03bd = \u2202\u03bc B\u03bd \u2212 \u2202\u03bd B\u03bc and F\u03bc\u03bd\n\u03bc \u03bd\n\u03bd \u03bc\n\nD\u03bc = \u2202\u03bc + igS T \u03b1 G\u03bc\u03b1 + igT a W\u03bc a + ig1 Y B\u03bc + i(e\ng Y + g10 YB\u2212L )B\u03bc0 .\n\n(45)\n\nFor the \"pure\" or \"minimal\" B \u2212 L model the condition ge = 0 holds, implying that there is no mixing\nbetween the B \u2212 L Z 0 and SM Z gauge bosons.\nThe fermionic Lagrangian (where k is the generation index) is given by,\nLf\n\n=\n\n3 \u0010\nX\n\ni qkL \u03b3\u03bc D\u03bc qkL + i ukR \u03b3\u03bc D\u03bc ukR + i dkR \u03b3\u03bc D\u03bc dkR +\n\nk=1\n\n\u0011\n+i lkL \u03b3\u03bc D\u03bc lkL + i ekR \u03b3\u03bc D\u03bc ekR + i \u03bdkR \u03b3\u03bc D\u03bc \u03bdkR ,\n\n(46)\n\nwhere the charges of the fields are the usual SM and B \u2212 L charges (i.e., B \u2212 L = 1/3 for quarks and\n\u22121 for leptons with no distinction between generations, hence ensuring universality). The B \u2212 L charge\nassignments of the fields as well as the introduction of new fermionic right-handed heavy neutrinos (\u03bdR 's)\nand a scalar Higgs field (\u03c7, charged +2 under B \u2212 L) are designed to eliminate the triangular B \u2212 L\ngauge anomalies and to ensure the gauge invariance of the theory (see Eq. (49)), respectively.\nThe scalar Lagrangian reads,\nLs = (D\u03bc H)\u2020 D\u03bc H + (D\u03bc \u03c7)\u2020 D\u03bc \u03c7 \u2212 V (H, \u03c7) ,\n\n(47)\n\nwith the scalar potential given by\nV (H, \u03c7) = \u2212m2 H \u2020 H \u2212 \u03bc2 | \u03c7 |2 +\u03bb1 (H \u2020 H)2 + \u03bb2 | \u03c7 |4 +\u03bb3 H \u2020 H | \u03c7 |2 ,\n\n(48)\n\nwhere H and \u03c7 are the complex scalar Higgs doublet and singlet fields, respectively.\nFinally, the Yukawa interactions are,\nd\nu\ne \u2212 y e ljL ekR H \u2212 y \u03bd ljL \u03bdkR H\ne \u2212 y M (\u03bdR )c \u03bdkR \u03c7 + h.c. , (49)\nLY = \u2212yjk\nqjL dkR H \u2212 yjk\nqjL ukR H\njk\njk\njk\nj\n\ne = i\u03c3 2 H \u2217 and i, j, k take the values 1 to 3, where the last term is the Majorana contribution and\nwhere H\nthe others the usual Dirac ones.\nThe implementation of the model into F EYN RULES is straightforward. Only the neutrino sector is more\ncomplicated and needs to be suitably rewritten to manifestly preserve gauge invariance. As a first step we\nrewrite Dirac neutrino fields in terms of Majorana ones using the following general substitution,\n\u03bdD =\n\n1 \u2212 \u03b35\n1 + \u03b35\n\u03bdL +\n\u03bdR ,\n2\n2\n127\n\n(50)\n\n\fwhere \u03bd D is a Dirac field and \u03bdL(R) are its left (right) Majorana components. If we perform the substitution\nof Eq. (50) in the neutrino sector of the SM, we will have an equivalent theory formulated in terms of\nMajorana neutrinos consistent with all experimental constraints. Furthermore, from Eq. (49) we obtain\nthe neutrino mass matrix,\n\u0012\n\u0013\n0 mD\nM=\n,\n(51)\nmD M\nwith\n\n\u221a\ny\u03bd\nmD = \u221a v ,\nM = 2 yM x ,\n(52)\n2\nwhere x is the Vacuum Expectation Value (VEV) of the \u03c7 field. This matrix can be diagonalized by a\nrotation about an angle \u03b1\u03bd , such that,\ntan 2\u03b1\u03bd = \u2212\n\n2mD\n.\nM\n\n(53)\n\nFor simplicity we neglect the inter-generational mixing so that neutrinos of each generation can be\ndiagonalized independently. We also require that the neutrinos be mass degenerate. Thus, \u03bdL,R can be\nwritten as the following linear combination of Majorana mass eigenstates \u03bdl,h ,\n\u0012\n\u0013 \u0012\n\u0013 \u0012\n\u0013\n\u03bdL\ncos \u03b1\u03bd \u2212 sin \u03b1\u03bd\n\u03bdl\n=\n\u00d7\n.\n(54)\n\u03bdR\nsin \u03b1\u03bd cos \u03b1\u03bd\n\u03bdh\nNeutrino mass eigenstates will be called \u03bdl and \u03bdh , the former being SM-like. With a reasonable choice of\nYukawa couplings, the heavy neutrinos can have masses m\u03bdh \u223c O(100) GeV \u001c MZ 0 .\n\nThe last subtle point is the way the Lagrangian has to be written, in particular the Majorana-like Yukawa\nterms for the right-handed neutrinos (the last term in Eq. (49)). In order to explicitly preserve gauge\ninvariance, this term has to be written, in two-component notation, as,\n\u2212y M \u03bd c\n\n1 + \u03b35\n\u03bd\u03c7 + h.c. ,\n2\n\n(55)\n\nwhere \u03bd is the Dirac field of Eq. (50), whose Majorana components \u03bdL,R mix as in Eq. (54).\nThe implementation of the minimal B \u2212 L model in F EYN RULES was validated by comparing against\nan independent implementation in C ALC H EP performed by means of the L AN H EP package [308]. We\ncompared the matrix elements squared in M AD G RAPH and C ALC H EP at various randomly-generated\nphase space points for 284 two-to-two processes and we found perfect agreement in all cases. Let us\nnote that the current F EYN RULES implementation was done in unitary gauge, whereas the L AN H EP\nimplementation allows for both Feynman and unitary gauges, and hence we demonstrated explicitly the\ngauge invariance of our implementation. Furthermore, because of mixing in the scalar sector, we paid\nparticular attention to the unitarity cancellation in weak boson scattering to ensure that the implementation\nhas the correct high-energy behavior. A selection of the results obtained during the validation procedure is\nshown in Table 8. A more extensive list, together with the corresponding F EYN RULES model file, can be\nobtained from the F EYN RULES model database.\n20.42\n\nTHE NEXT-TO-MINIMAL SUPERSYMMETRIC STANDARD MODEL\n\nThe Next-to-Minimal Supersymmetric Standard Model (NMSSM) is a viable extension of the MSSM in\nthe Higgs sector of the model (see, e.g., the references in [309]). The main motivation for the NMSSM\nis a possible solution to the so-called \u03bc problem, the fact that the supersymmetric parameter \u03bc in the\nsuperpotential is dimensionful and should in principle be of the order of the SUSY breaking scale. A\nworking electroweak symmetry breaking demands this parameter, however, in the ball park of a few\nhundred GeV. The NMSSM addresses this problem by enlarging the particle spectrum by a single chiral\n128\n\n\fProcess\n\u2192 \u03bdl1 \u03bdl1\ne+ e\u2212 \u2192 \u03bdl1 \u03bdh1\ne+ e\u2212 \u2192 \u03bdh1 \u03bdh1\ne+ e\u2212 \u2192 ZZ 0\nW +W \u2212 \u2192 W +W \u2212\ne+ e\u2212\n\nMG (FR)\n5.681e+01\n5.315e\u221212\n2.697e\u221202\n1.570e\u221201\n1.420e+03\n\nCH (FR)\n5.687e+01\n5.307e\u221212\n2.691e\u221202\n1.569e\u221201\n1.421e+03\n\nCH (LH)\n5.687e+01\n5.307e\u221212\n2.691e\u221202\n1.569e\u221201\n1.421e+03\n\nTable 8: Cross section (in pb) for a selection of processes in the minimal B \u2212 L model corresponding to\n\u221a\ns = 4 TeV. A pT cut of 20 GeV was applied to all final state particles. MG (FR) and CH (FR) refer to\nthe F EYN RULES implementations in M AD G RAPH and C ALC H EP respectively, whereas CH (LH) refers\nto the L AN H EP implementation of Ref. [308].\nsuperfield S, being a singlet under the SM gauge group. When the singlet acquires a vev, it generates an\neffective \u03bc parameter. The quartic term for the Higgs-potential is generated via an F term from a cubic\nsuperpotential term.\nIn the following, we will use the conventions of the SUSY Les Houches Accord 2 [43, 44, 310]. This is\na quite general approach, but neglecting possible CP, R-parity, or flavor violation. The superpotential and\nthe soft-breaking terms of the NMSSM are given by\n1\nWN M SSM = WM SSM \u2212 \u000fab \u03bbSH1a H2b + \u03baS 3 + \u03bc0 S 2 + \u03beF S ,\n3\n\u0010\n2\n2\nVsoft = VM SSM + mS |S| + \u2212 \u000fab \u03bbA\u03bb SH1a H2b\n\u0011\n1\n2\n+ \u03baA\u03ba S 3 + m02\nS S + \u03beS S + h.c. .\n3\n\n(56)\n\nIn the W HIZARD implementation, we have ommited all non-Z3 symmetric terms in the superpotential, as\nwell as the corresponding soft terms, while the F EYN RULES model includes the most general superpotential. The field content of the NMSSM is almost the same as for the MSSM, except for an additional scalar\nand pseudoscalar Higgs boson, denoted by H30 and A02 , as well as a fifth neutralino, \u03c7\u030305 , coming from the\nadditional singlino component. In addition to the conventions from Ref. [43, 44, 310] to have left-right\nsfermion mixing in all three generations, the F EYN RULES implementation is a bit more general, allowing\nfor inter-generational sfermion mixings.\nThe tests that we have performed follow closely the strategy described in Section 20.3 We have\ncompared the cross section for 736 processes in W HIZARD and in the F EYN RULES-generated model files\nfor C ALC H EP and M AD G RAPH. A very short selection of results for processes including Higgses and\nneutralinos can be found in the Table 9. The full list of processes which we have investigated, together\nwith the results for the cross sections and the selected benchmark point, will be made available in the\nF EYN RULES model database and on the W HIZARD home page. For the W HIZARD implementation it was\nchecked that it yields the correct MSSM limit [311] .\n20.43\n\nTHE MINIMAL R-SYMMETRIC SUPERSYMMETRIC STANDARD MODEL\n\nThe minimal R-symmetric supersymmetric standard model (MRSSM) extends the usual MSSM by\nintroducing a global continuous U (1)R symmetry [312]. All the quark and lepton supermultiplets carry an\nR-charge +1, whereas the Higgs and gauge supermultiplets carry an R-charge 0. This implies that gaugino\nMajorana mass terms are forbidden, as well as the \u03bc-term in the superpotential. Since supersymmetry\nmust be broken, the gauginos must be massive and we need a new mechanism to introduce gaugino mass\nterms. This is achieved by including for each gauge supermultiplet an additional chiral supermultiplet,\ntransforming in the adjoint representation of the gauge group and with an R-charge 0, making it possible\n129\n\n\fProcess\n\u2192 \u03c7\u030304 \u03c7\u030305\n\u2212\n0\n\u03c4 \u03bd\u0304\u03c4 \u2192 \u03c7\u0303\u2212\n1 \u03c7\u03035\nW \u2212 Z \u2192 H30 H \u2212\nZ Z \u2192 A01 A01\nW + W \u2212 \u2192 \u03c7\u030303 \u03c7\u030305\ne+ e\u2212\n\nWO (ST)\n4.882e\u22123\n3.476e\u22124\n4.211e\u22123\n6.505e\u22123\n2.055e\u22121\n\nMG (FR)\n4.884e\u22123\n3.470e\u22124\n4.213e\u22123\n6.512e\u22123\n2.056e\u22121\n\nCH (FR)\n4.886e\u22123\n3.469e\u22124\n4.210e\u22123\n6.513e\u22123\n2.056e\u22121\n\nTable 9: Cross sections for a selection of production processes in the NMSSM. The built-in MSSM\nimplementation in W HIZARD is denoted WO (ST) while the F EYN RULES-generated ones are MG (FR)\nand CH (FR). The center-of-mass energy is fixed to 3000 GeV.\nto write down Dirac mass terms for the gauginos. As a consequence, at variance with the usual MSSM\nscenario where the neutralinos and gluinos are expected to be Majorana fermions, the gluinos and the\nweak inos in the MRSSM are four-component Dirac fermions, leading to a new phenomenology for\nsupersymmetric models. In the following however, we only review the SU (3)C sector of the model. The\nelectroweak sector is conceptually similar, but more involved because of the mixing in the electroweak\ngauge sector and we refer the interested reader to Ref. [313\u2013316] for further details on the MRSSM and\nits phenomenology.\nThe SU (3)C sector of the MSSM describes the gauge interactions between the quark superfields\nQ = (q\u0303L , qL , FQ ), U = (\u0169\u2020R , ucL , FU ) and D = (d \u0303\u2020R , dcL , FD ) and the gluon superfield G = (\u03bb, g\u03bc , D). In\nthe MRSSM this sector is augmented by an additional chiral supermultiplet \u03a6g = (\u03c6, \u03c7, Fg ) transforming\nas an octet. In order to give the gluino a mass in an R-symmetric way, the soft supersymmetry breaking\npart of the Lagrangian contains a Dirac mass term coupling the Weyl components of the superfields G and\n\u03a6g ,\nLsoft \u2283 MD (\u03bba * \u03c7a + \u03c7\u0304a * \u03bb\u0304a ) + MD Da (\u03c6a + \u03c6\u2020a ) .\n(57)\nThe physical gluino field then corresponds to the four-component Dirac fermion g\u0303 = (\u03c7, \u03bb\u0304)T . The\ninteractions between the superfields are described by the usual supersymmetric gauge interactions.\nIntegrating out auxiliary fields and omitting all terms involving quark fields left unchanged with respect to\nthe usual MSSM, the gauge interactions can be described by the Lagrangian,\nLg = D\u03bc \u03c6\u2020a D\u03bc \u03c6a + \u03bba\u2020 i\u03c3\u0304 \u03bc D\u03bc \u03bba + \u03c7a\u2020 i\u03c3\u0304 \u03bc D\u03bc \u03c7a\n1 2\n1 2\n1 2\n+\nMD (\u03c6a + \u03c6\u2020a )2 + Ms8\n(\u03c6a + \u03c6\u2020a )2 + Mp8\n(\u03c6a \u2212 \u03c6\u2020a )2 + MD (\u03bba * \u03c7a + \u03c7\u0304a * \u03bb\u0304a )\n2\n2\n2\n\u0010\n\u0011\n+ gs MD (\u03c6a + \u03c6\u2020 ) q\u0303 \u2020 T a q\u0303L \u2212 \u0169\u2020 T a \u0169R \u2212 d \u0303\u2020 T a d \u0303R\n(58)\na\n\ngs2\n\nL\n\nR\n\nR\n\n\u0010\n\nq\u0303L\u2020 T a q\u0303L \u2212 \u0169\u2020R T a \u0169R \u2212 d \u0303\u2020R T a d \u0303R \u2212 if abc \u03c6\u2020b \u03c6c\n2\n\u0010\n\u0011\n\u221a\n+ i 2 gs f abc \u03c6\u2020b \u03c7c * \u03bba + \u03c6b \u03bb\u0304a * \u03c7\u0304c ,\n+\n\n\u0011\n\nwhere D\u03bc denotes the covariant derivative in the adjoint representation of SU (3)C ,\nD\u03bc = \u2202\u03bc \u2212 igs F a g\u03bca ,\nand (F a )bc = \u2212if abc denote the generators of the adjoint representation.\n\n(59)\n\nWe implemented the full MRSSM in F EYN RULES in its most general form, i.e., keeping generic and\npossible complex mixing between particles. The validation of the implementation is currently on-going.\n\n130\n\n\f20.5\n\nCONCLUSION\n\nIn this summary report we presented the activities of the F EYN RULES working group triggered by\ndiscussion at the Les Houches workshop. We argued that the F EYN RULES framework does not only\nprovide a natural framework where BSM models can easily be developed and implemented, but they can\nalso be validated to an unprecedented level by exploiting the fact that the model can be exported to various\nmatrix element generators in an automated way. We proposed a rating scheme based on a four credit\npoints system by which F EYN RULES models can be classified with respect to their level of validation,\nin the perspective of building a database of robust and thoroughly validated implementations, and we\nillustrated the power of this proposal on several newly implemented and validated models, in particular\nthe minimal B \u2212 L model, well as several supersymmetric extensions of the Standard Model.\n\n131\n\n\fACKNOWLEDGEMENTS\nIn addition to the invidiual acknowledgements throughout the contributions, all the authors would all\nlike to thank the organisers for the usual great atmosphere and hospitality. The meeting was financially\nsupported by the European Union Marie Curie Conferences and Training Courses Contract: CT-2006046171, the Haute Savoie and Rh\u00f4ne Alps regions, Universite Savoie, LAPP and LAPTH Annecy, CNRS\nand the Minist\u00e9r\u00e9 des Affaires \u00c9trangers.\nReferences\n[1] C. Buttar et. al., arXiv:0803.0678 [hep-ph].\n[2] E. Boos et. al., hep-ph/0109068.\n[3] J. Alwall et. al., Comput. Phys. Commun. 176 (2007) 300\u2013304, [arXiv:hep-ph/0609017].\n[4] S. Catani, F. Krauss, R. Kuhn, and B. R. Webber, JHEP 11 (2001) 063, [hep-ph/0109231].\n[5] L. L\u00f6nnblad, JHEP 05 (2002) 046, [arXiv:hep-ph/0112284].\n[6] S. Belov, L. Dudko, D. Kekelidze, and A. Sherstnev, arXiv:1001.2576 [hep-ph].\n[7] S. Belov et. al., Comput. Phys. Commun. 178 (2008) 222, [arXiv:hep-ph/0703287].\n[8] C. Amsler et. al.,, Particle Data Group Collaboration Phys. Lett. B667 (2008) 1.\n[9] S. Catani and M.H. Seymour, Nucl. Phys. B485 (1997) 291\u2013419, [arXiv:hep-ph/9605323].\n[10] S. Frixione, Z. Kunszt, and A. Signer, Nucl. Phys. B467 (1996) 399\u2013442,\n[arXiv:hep-ph/9512328].\n[11] S. Frixione, Nucl. Phys. B507 (1997) 295\u2013314, [hep-ph/9706545].\n[12] S. Frixione and B. R. Webber, JHEP 06 (2002) 029, [arXiv:hep-ph/0204244].\n[13] S. Frixione and B. R. Webber, arXiv:hep-ph/0612272.\n[14] P. Nason, JHEP 11 (2004) 040, [arXiv:hep-ph/0409146].\n[15] S. Frixione, P. Nason, and C. Oleari, JHEP 11 (2007) 070, [arXiv:0709.2092 [hep-ph]].\n[16] Z. Nagy, Phys. Rev. D68 (2003) 094002, [arXiv:hep-ph/0307268].\n[17] G. Corcella et. al., hep-ph/0210213.\n[18] T. Sjostrand, S. Mrenna, and P. Skands, JHEP 05 (2006) 026, [arXiv:hep-ph/0603175].\n[19] S. Gieseke, A. Ribon, M. H. Seymour, P. Stephens, and B. Webber, JHEP 02 (2004) 005,\n[hep-ph/0311208].\n[20] T. Sjostrand, S. Mrenna, and P. Skands, Comput. Phys. Commun. 178 (2008) 852\u2013867,\n[arXiv:0710.3820 [hep-ph]].\n[21] M. Bahr et. al., Eur. Phys. J. C58 (2008) 639\u2013707, [arXiv:0803.0883 [hep-ph]].\n[22] T. Gleisberg et. al., JHEP 02 (2004) 056, [arXiv:hep-ph/0311263].\n[23] T. Gleisberg et. al., JHEP 02 (2009) 007, [arXiv:0811.4622 [hep-ph]].\n\n132\n\n\f[24] M. H. Seymour, Comp. Phys. Commun. 90 (1995) 95\u2013101, [hep-ph/9410414].\n[25] S. Frixione, P. Nason, and G. Ridolfi, arXiv:0707.3081 [hep-ph].\n[26] S. Catani, S. Dittmaier, M. H. Seymour, and Z. Trocsanyi, Nucl. Phys. B627 (2002) 189\u2013265,\n[hep-ph/0201036].\n[27] F. Mahmoudi, Comput. Phys. Commun. 178 (2008) 745\u2013754, [arXiv:0710.2067\n[hep-ph]].\n[28] F. Mahmoudi, Comput. Phys. Commun. 180 (2009) 1579\u20131613, [arXiv:0808.3144\n[hep-ph]].\n[29] F. Mahmoudi, Comput. Phys. Commun. 180 (2009) 1718\u20131719.\n[30] G. Degrassi, P. Gambino, and P. Slavich, Comput. Phys. Commun. 179 (2008) 759\u2013771,\n[arXiv:0712.3265 [hep-ph]].\n[31] P. Paradisi, talk given at ''Interplay of Collider and Flavour\nPhysics, 3rd general meeting'', CERN, December 2009.\n[32] G. Belanger, F. Boudjema, A. Pukhov, and A. Semenov, Comput. Phys. Commun. 180 (2009)\n747\u2013767, [arXiv:0803.2360 [hep-ph]].\n[33] A. Arbey and F. Mahmoudi, arXiv:0906.0369 [hep-ph].\n[34] S. Heinemeyer, W. Hollik, and G. Weiglein, Comput. Phys. Commun. 124 (2000) 76\u201389,\n[arXiv:hep-ph/9812320].\n[35] S. Heinemeyer, W. Hollik, and G. Weiglein, Eur. Phys. J. C9 (1999) 343\u2013366,\n[arXiv:hep-ph/9812472].\n[36] J. S. Lee et. al., Comput. Phys. Commun. 156 (2004) 283\u2013317, [arXiv:hep-ph/0307377].\n[37] U. Ellwanger and C. Hugonie, Comput. Phys. Commun. 175 (2006) 290\u2013303,\n[arXiv:hep-ph/0508022].\n[38] F. E. Paige, S. D. Protopopescu, H. Baer, and X. Tata, arXiv:hep-ph/0312045.\n[39] R. Lafaye, T. Plehn, and D. Zerwas, arXiv:hep-ph/0404282.\n[40] P. Bechtle, K. Desch, and P. Wienemann, Comput. Phys. Commun. 174 (2006) 47\u201370,\n[arXiv:hep-ph/0412012].\n[41] R. R. de Austri, R. Trotta, and L. Roszkowski, JHEP 05 (2006) 002,\n[arXiv:hep-ph/0602028].\n[42] S. Heinemeyer, talk given at ''Interplay of Collider and Flavour\nPhysics, 2nd general meeting'', CERN, March 2009.\n[43] P. Z. Skands et. al., JHEP 07 (2004) 036, [arXiv:hep-ph/0311123].\n[44] B. Allanach et. al., Comp. Phys. Commun. 180 (2009) 8\u201325, [arXiv:0801.0045\n[hep-ph]].\n[45] T. Hahn, Comput. Phys. Commun. 180 (2009) 1681\u20131693, [arXiv:hep-ph/0605049].\n\n133\n\n\f[46] A. Buckley, J. Butterworth, L. L\u00f6nnblad, H. Hoeth, J. Monk, H. Schulz, J. E. von Seggern,\nF. Siegert, and L. Sonnenschein, arXiv:1003.0694 [hep-ph].\n[47] A. Buckley, H. Hoeth, H. Lacker, H. Schulz, and J. E. von Seggern, Eur. Phys. J. C65 (2010)\n331\u2013357, [arXiv:0907.2973 [hep-ph]].\n[48] J. Bromley et. al.,. Prepared for Workshop on Future Physics at HERA (Preceded by meetings\n25-26 Sep 1995 and 7-9 Feb 1996 at DESY), Hamburg, Germany, 30-31 May 1996.\n[49] B. M. Waugh et. al., arXiv:hep-ph/0605034.\n[50] M. Dobbs and J. B. Hansen, Comput. Phys. Commun. 134 (2001) 41\u201346.\n[51] M. Cacciari, arXiv:hep-ph/0607071.\n[52] A. Buckley, PoS ACAT2007 (2007) 050, [arXiv:0708.2655 [hep-ph]].\n[53] A. Buckley et. al., arXiv:hep-ph/0605048.\n[54] J. M. Butterworth, J. R. Forshaw, and M. H. Seymour, Z. Phys. C72 (1996) 637\u2013646,\n[arXiv:hep-ph/9601371].\n[55] J. M. Butterworth and M. H. Seymour,, October, 2004. JIMMY4: Multiparton Interactions in\nHerwig for the LHC, http://projects.hepforge.org/jimmy/.\n[56] M. Bahr, J. M. Butterworth, and M. H. Seymour, JHEP 01 (2009) 065, [arXiv:0806.2949\n[hep-ph]].\n[57] A. Sherstnev and R. S. Thorne, Eur. Phys. J. C55 (2008) 553\u2013575, [arXiv:0711.2473\n[hep-ph]].\n[58] A. A. Affolder et. al.,, CDF Collaboration Phys. Rev. D65 (2002) 092002.\n[59] D. E. Acosta et. al.,, CDF Collaboration Phys. Rev. D70 (2004) 072002,\n[arXiv:hep-ex/0404004].\n[60] CDF CollaborationR. Field, ,, \"The Underlying Event and Comparisons with MC.\" First\nInternational Workshop on Multiple Partonic Interactions at the LHC, 2008.\n[61] V. M. Abazov et. al.,, D0 Collaboration Phys. Rev. Lett. 94 (2005) 221801,\n[arXiv:hep-ex/0409040].\n[62] P. Z. Skands, arXiv:0905.3418 [hep-ph].\n[63] R. D. Ball et. al.,, NNPDF Collaboration Nucl. Phys. B809 (2009) 1\u201363, [arXiv:0808.1231\n[hep-ph]].\n[64] M. L. Mangano, M. Moretti, F. Piccinini, R. Pittau, and A. D. Polosa, JHEP 07 (2003) 001,\n[hep-ph/0206293].\n[65] S. Hoeche, F. Krauss, S. Schumann, and F. Siegert, JHEP 05 (2009) 053, [arXiv:0903.1219\n[hep-ph]].\n[66] P. Lenzi and J. M. Butterworth, arXiv:hep-ph/0903.3918 [hep-ph].\n[67] M. G. Albrow et. al.,, TeV4LHC QCD Working Group Collaboration\narXiv:hep-ph/0610012.\n\n134\n\n\f[68] H. Hoeth,. Perugia MPI workshop, October, 2008.\n[69] T. Sjostrand and P. Z. Skands, Eur. Phys. J. C39 (2005) 129\u2013154, [arXiv:hep-ph/0408302].\n[70] M. L. Mangano, M. Moretti, and R. Pittau, Nucl. Phys. B632 (2002) 343\u2013362,\n[hep-ph/0108069].\n[71] T. Akesson et. al.,, Axial Field Spectrometer Collaboration Z. Phys. C34 (1987) 163.\n[72] F. Abe et. al.,, CDF Collaboration Phys. Rev. Lett. 79 (1997) 584\u2013589.\n[73] F. Abe et. al.,, CDF Collaboration Phys. Rev. D56 (1997) 3811\u20133832.\n[74] D. Collaboration,, D0 Collaboration D0 note 5910-CONF (2009).\n[75] T. Sjostrand and M. van Zijl, Phys. Rev. D36 (1987) 2019.\n[76] T. Sj\u00f6strand and P. Z. Skands, JHEP 03 (2004) 053, [arXiv:hep-ph/0402078].\n[77] M. B\u00e4hr, S. Gieseke, and M. H. Seymour, JHEP 07 (2008) 076, [arXiv:0803.3633\n[hep-ph]].\n[78] E. Maina, JHEP 09 (2009) 081, [arXiv:0909.1586 [hep-ph]].\n[79] E. Maina, JHEP 04 (2009) 098, [arXiv:0904.2682 [hep-ph]].\n[80] F. Maltoni and T. Stelzer, JHEP 02 (2003) 027, [hep-ph/0208156].\n[81] J. Alwall et. al., JHEP 09 (2007) 028, [arXiv:0706.2334 [hep-ph]].\n[82] J. Pumplin, A. Belyaev, J. Huston, D. Stump, and W. K. Tung, JHEP 02 (2006) 032,\n[arXiv:hep-ph/0512167].\n[83] D. Treleani, Phys. Rev. D76 (2007) 076006, [arXiv:0708.2603 [hep-ph]].\n[84] U. Baur, T. Han, and J. Ohnemus, Phys. Rev. D48 (1993) 5140\u20135161,\n[arXiv:hep-ph/9305314].\n[85] U. Baur, http://ubhex.physics.buffalo.edu/ baur/wgam nlo.tar.gz.\n[86] Z. Nagy and D. E. Soper, JHEP 10 (2005) 024, [arXiv:hep-ph/0503053].\n[87] Z. Nagy and D. E. Soper, hep-ph/0601021.\n[88] W. T. Giele, D. A. Kosower, and P. Z. Skands, Phys. Rev. D78 (2008) 014026,\n[arXiv:0707.3652 [hep-ph]].\n[89] S. Schumann and F. Krauss, JHEP 03 (2008) 038, [arXiv:0709.1027 [hep-ph]].\n[90] M. Dinsdale, M. Ternick and S. Weinzierl, Phys. Rev. D76 (2007) 094003, [arXiv:0709.1026\n[hep-ph]].\n[91] J.-C. Winter and F. Krauss, JHEP 07 (2008) 040, [arXiv:0712.3913 [hep-ph]].\n[92] S. Platzer and S. Gieseke, arXiv:0909.5593 [hep-ph].\n[93] G. Gustafson, Phys. Lett. B175 (1986) 453.\n[94] G. Gustafson and U. Pettersson, Nucl. Phys. B306 (1988) 746.\n135\n\n\f[95] B. Andersson, G. Gustafson, and L. L\u00f6nnblad, Nucl. Phys. B339 (1990) 393\u2013406.\n[96] B. Andersson, G. Gustafson, L. L\u00f6nnblad, and U. Pettersson, Z. Phys. C43 (1989) 625.\n[97] L. L\u00f6nnblad, Comput. Phys. Commun. 71 (1992) 15\u201331.\n[98] Y. L. Dokshitzer and G. Marchesini, JHEP 03 (2009) 117, [arXiv:0809.1749 [hep-ph]].\n[99] Z. Nagy and D. E. Soper, JHEP 05 (2009) 088, [arXiv:0901.3587 [hep-ph]].\n[100] P. Skands and S. Weinzierl, arXiv:0903.2150 [hep-ph].\n[101] A. Bassetto, M. Ciafaloni, and G. Marchesini, Phys. Rept. 100 (1983) 201\u2013272.\n[102] F. A. Berends and W. T. Giele, Nucl. Phys. B313 (1989) 595.\n[103] F. Englert and R. Brout, Phys. Rev. Lett. 13 (1964) 321\u2013322.\n[104] P. W. Higgs, Phys. Rev. Lett. 13 (1964) 508\u2013509.\n[105] G. S. Guralnik, C. R. Hagen, and T. W. B. Kibble, Phys. Rev. Lett. 13 (1964) 585\u2013587.\n[106] T. W. B. Kibble, Phys. Rev. 155 (1967) 1554\u20131561.\n[107] H. M. Georgi, S. L. Glashow, M. E. Machacek, and D. V. Nanopoulos, Phys. Rev. Lett. 40 (1978)\n692.\n[108] ALEPH Collaboration et. al., arXiv:0811.4682 [hep-ex].\n[109] G. Bernardi et. al.,, Tevatron New Phenomena and Higgs Working Group Collaboration\narXiv:0808.0534 [hep-ex].\n[110] T. Aaltonen et. al.,, CDF and D\u00d8 Collaboration arXiv:1001.4162 [Unknown].\n[111] A. Djouadi, Phys. Rept. 457 (2008) 1\u2013216, [arXiv:hep-ph/0503172].\n[112] S. Frixione, P. Nason, and B. R. Webber, JHEP 08 (2003) 007, [arXiv:hep-ph/0305252].\n[113] S. Frixione, E. Laenen, P. Motylinski, and B. R. Webber, JHEP 03 (2006) 092,\n[arXiv:hep-ph/0512250].\n[114] S. Frixione, E. Laenen, P. Motylinski, and B. R. Webber, JHEP 04 (2007) 081,\n[arXiv:hep-ph/0702198].\n[115] S. Frixione, E. Laenen, P. Motylinski, B. R. Webber, and C. D. White, JHEP 07 (2008) 029,\n[arXiv:0805.3067 [hep-ph]].\n[116] O. Latunde-Dada, JHEP 11 (2007) 040, [arXiv:0708.4390 [hep-ph]].\n[117] P. Nason and G. Ridolfi, JHEP 08 (2006) 077, [arXiv:hep-ph/0606275].\n[118] S. Frixione, P. Nason, and G. Ridolfi, JHEP 09 (2007) 126, [arXiv:0707.3088 [hep-ph]].\n[119] O. Latunde-Dada, S. Gieseke, and B. Webber, JHEP 02 (2007) 051,\n[arXiv:hep-ph/0612281].\n[120] K. Hamilton, P. Richardson, and J. Tully, JHEP 10 (2008) 015, [arXiv:0806.0290\n[hep-ph]].\n\n136\n\n\f[121] K. Hamilton, P. Richardson, and J. Tully, JHEP 04 (2009) 116, [arXiv:0903.4345\n[hep-ph]].\n[122] S. Alioli, P. Nason, C. Oleari, and E. Re, JHEP 07 (2008) 060, [arXiv:0805.4802\n[hep-ph]].\n[123] S. Alioli, P. Nason, C. Oleari, and E. Re, JHEP 04 (2009) 002, [arXiv:0812.0578\n[hep-ph]].\n[124] S. Alioli, P. Nason, C. Oleari, and E. Re, JHEP 09 (2009) 111, [arXiv:0907.4076\n[hep-ph]].\n[125] O. Latunde-Dada, Eur. Phys. J. C58 (2008) 543\u2013554, [arXiv:0806.4560 [hep-ph]].\n[126] F. Krauss, JHEP 08 (2002) 015, [arXiv:hep-ph/0205283].\n[127] A. Sch\u00e4licke and F. Krauss, JHEP 07 (2005) 018, [arXiv:hep-ph/0503281].\n[128] S. Mrenna and P. Richardson, JHEP 05 (2004) 040, [arXiv:hep-ph/0312274].\n[129] K. Hamilton, P. Richardson, and J. Tully, arXiv:0905.3072 [hep-ph].\n[130] C. Anastasiou, K. Melnikov, and F. Petriello, Nucl. Phys. B724 (2005) 197\u2013246,\n[arXiv:hep-ph/0501130].\n[131] C. Anastasiou, G. Dissertori, and F. Stockli, JHEP 09 (2007) 018, [arXiv:0707.2373\n[hep-ph]].\n[132] S. Catani and M. Grazzini, Phys. Rev. Lett. 98 (2007) 222002, [arXiv:hep-ph/0703012].\n[133] M. Grazzini, JHEP 02 (2008) 043, [arXiv:0801.3232 [hep-ph]].\n[134] J. Alwall et. al., Eur. Phys. J. C53 (2008) 473\u2013500, [arXiv:0706.2569 [hep-ph]].\n[135] J. Alwall, S. de Visscher, and F. Maltoni, JHEP 02 (2009) 017, [arXiv:0810.5350\n[hep-ph]].\n[136] G. Corcella et. al., JHEP 01 (2001) 010, [arXiv:hep-ph/0011363].\n[137] A. Papaefstathiou and O. Latunde-Dada, JHEP 07 (2009) 044, [arXiv:0901.3685\n[hep-ph]].\n[138] S. Alioli, P. Nason, C. Oleari, and E. Re,. To appear soon.\n[139] P. Nason and C. Oleari, arXiv:0911.5299 [hep-ph].\n[140] A. Bassetto, M. Ciafaloni, G. Marchesini, and A. H. Mueller, Nucl. Phys. B207 (1982) 189.\n[141] S. Catani and M. Ciafaloni, Nucl. Phys. B236 (1984) 61.\n[142] M. Ciafaloni, Phys. Lett. B95 (1980) 113.\n[143] M. Ciafaloni,, \"Soft Gluon Contributions to Hard Processes.\" Lectures given at Summer Workshop\non High Energy Physics, Trieste, Italy, Aug 1981.\n[144] Y. L. Dokshitzer, V. A. Khoze, and S. I. Troian, Adv. Ser. Direct. High Energy Phys. 5 (1988)\n241\u2013410.\n[145] G. Marchesini and B. R. Webber, Nucl. Phys. B238 (1984) 1.\n137\n\n\f[146] A. H. Mueller, Phys. Lett. B104 (1981) 161\u2013164.\n[147] B. I. Ermolaev and V. S. Fadin, JETP Lett. 33 (1981) 269\u2013272.\n[148] Y. L. Dokshitzer, V. S. Fadin, and V. A. Khoze, Phys. Lett. B115 (1982) 242\u2013246.\n[149] F. Krauss, R. Kuhn, and G. Soff, JHEP 02 (2002) 044, [arXiv:hep-ph/0109036].\n[150] T. Gleisberg and S. Hoche, JHEP 12 (2008) 039, [arXiv:0808.3674 [hep-ph]].\n[151] S. H\u00f6che, S. Schumann, and F. Siegert, arXiv:0912.3501 [hep-ph].\n[152] T. Carli, T. Gehrmann, and S. H\u00f6che, arXiv:0912.3715 [hep-ph].\n[153] F. Krauss, A. Schalicke, S. Schumann, and G. Soff, Phys. Rev. D70 (2004) 114009,\n[arXiv:hep-ph/0409106].\n[154] F. Krauss, A. Schalicke, S. Schumann, and G. Soff, Phys. Rev. D72 (2005) 054017,\n[arXiv:hep-ph/0503280].\n[155] T. Gleisberg, F. Krauss, A. Schalicke, S. Schumann, and J.-C. Winter, Phys. Rev. D72 (2005)\n034028, [arXiv:hep-ph/0504032].\n[156] J. Pumplin et. al., JHEP 07 (2002) 012, [arXiv:hep-ph/0201195].\n[157] M. Cacciari and G. P. Salam, Phys. Lett. B641 (2006) 57\u201361, [hep-ph/0512210].\n[158] J. M. Butterworth, A. R. Davison, M. Rubin, and G. P. Salam, Phys. Rev. Lett. 100 (2008) 242001,\n[arXiv:0802.2470 [hep-ph]].\n[159] ATLAS CollaborationG. Aad et. al., , Tech. Rep. ATL-PHYS-INT-2009-068,\nATL-PHYS-PUB-2009-088, CERN, Geneva, June, 2009.\n[160] S. Alioli, P. Nason, C. Oleari, and E. Re, arXiv:1002.2581 [hep-ph].\n[161] G. Piacquadio,. Freiburg PhD thesis, CERN-THESIS-2010-027.\n[162] F. Febres Cordero, L. Reina, and D. Wackeroth, Phys. Rev. D74 (2006) 034007,\n[arXiv:0606102 [hep-ph]].\n[163] F. Febres Cordero, arXiv:0809.3829 [hep-ph].\n[164] F. Febres Cordero, L. Reina, and D. Wackeroth, Phys. Rev. D80 (2009) 034015,\n[arXiv:0906.1923 [hep-ph]].\n[165] B. P. Kersevan and E. Richter-Was, arXiv:hep-ph/0405247.\n[166] S. Agostinelli et. al., Nuclear Instruments and Methods in Physics Research Section A:\nAccelerators, Spectrometers, Detectors and Associated Equipment 506 (2003), no. 3 250 \u2013 303.\n[167] S. Ovyn, X. Rouby, and V. Lemaitre, arXiv:0903.2225 [hep-ph].\n[168] D. Acosta, M. Della Negra, L. Fo\u00e0, A. Herv\u00e9, and A. Petrilli,, CMS physics: Technical Design\nReport. Technical Design Report CMS. CERN, Geneva, 2006. There is an error on cover due to a\ntechnical problem for some items.\n[169] G. Aad et. al.,, The ATLAS Collaboration arXiv:0901.0512 [hep-ex].\n\n138\n\n\f[170] X. Rouby, J. de Favereau, and K. Piotrzkowski, Journal of Instrumentation 2 (2007), no. 09\nP09005.\n[171] M. Cacciari and G. P. Salam, Physics Letters B 641 (2006), no. 1 57 \u2013 61.\n[172] O. C. K. Ackerstaff et al, Eur. Phys. J. C4 (1998) 47\u201374.\n[173] M. Vesterinen and T. R. Wyatt, Nucl. Instrum. Meth. A 602 (2009) 432.\n[174] T. Affolder et. al.,, CDF Collaboration Phys. Rev. Lett. 84 (2000) 845\u2013850,\n[arXiv:hep-ex/0001021].\n[175] D. C. B. Abbott et al., Phys. Rev. Lett. 84 (2000) 2792.\n[176] D. C. V. M. Abazov et al., Phys. Rev. Lett. 100 (2008) 102002.\n[177] S. G. M. H. Seymour and A. Siodmok, Acta Phys.Polon. B40 (2009) 2109\u20132118.\n[178] M. Cacciari, G. Salam, and G. Soyez, JHEP 0804 (2008) 063, [arXiv:0802.1189\n[hep-ph]].\n[179] S. Chekanov et. al.,, ZEUS Collaboration Nucl. Phys. B700 (2004) 3\u201350, [hep-ex/0405065].\n[180] T. Becher and M. D. Schwartz, JHEP 07 (2008) 034, [arXiv:0803.0342 [hep-ph]].\n[181] M. H. Seymour, Z. Phys. C62 (1994) 127\u2013138.\n[182] J. M. Butterworth, B. E. Cox, and J. R. Forshaw, Phys. Rev. D 65 (2002) [hep-ph/0201098].\n[183] J. M. Butterworth, J. R. Ellis, and A. R. Raklev, JHEP 05 (2007) 033, [hep-ph/0702150].\n[184] G. H. Brooijmans et. al., arXiv:0802.3715 [hep-ph].\n[185] D. E. Kaplan, K. Rehermann, M. D. Schwartz, and B. Tweedie, Phys. Rev. Lett. 101 (2008)\n142001, [arXiv:0806.0848 [hep-ph]].\n[186] J. Thaler and L.-T. Wang, JHEP 07 (2008) 092, [arXiv:0806.0023 [hep-ph]].\n[187] ATLAS CollaborationG. Aad et. al., , Tech. Rep. ATL-PHYS-PUB-2009-081;\nATL-COM-PHYS-2009-255, CERN, Geneva, May, 2009.\n[188] T. Plehn, G. P. Salam, and M. Spannowsky, arXiv:0910.5472 [hep-ph].\n[189] G. D. Kribs, A. Martin, T. S. Roy, and M. Spannowsky, arXiv:0912.4731 [hep-ph].\n[190] J. M. Butterworth, J. R. Ellis, A. R. Raklev, and G. P. Salam, Phys. Rev. Lett. 103 (2009) 241803,\n[arXiv:0906.0728 [hep-ph]].\n[191] ATLAS CollaborationG. Aad et. al., , Tech. Rep. ATL-PHYS-PUB-2009-076;\nATL-COM-PHYS-2009-262, CERN, Geneva, May, 2009.\n[192] S. D. Ellis, C. K. Vermilion, and J. R. Walsh, arXiv:0912.0033 [hep-ph].\n[193] S. D. Ellis, C. K. Vermilion, and J. R. Walsh, Phys. Rev. D80 (2009) 051501,\n[arXiv:0903.5081 [hep-ph]].\n[194] D. Krohn, J. Thaler, and L.-T. Wang, arXiv:0912.1342 [hep-ph].\n\n139\n\n\f[195] BOOST 2009 workshop, SLAC http://www-conf.slac.stanford.edu/Boost2009/ and Workshop on\nJets and JetSubstructure at the LHC http://silicon.phys.washington.edu/JetsWorkshop/.\n[196] V. M. Abazov et. al.,, D0 Collaboration Phys. Rev. D65 (2002) 052008, [hep-ex/0108054].\n[197] D. Acosta et. al.,, CDF Collaboration Phys. Rev. D71 (2005) 112002, [hep-ex/0505013].\n[198] G. Abbiendi et. al.,, OPAL Collaboration Eur. Phys. J. C37 (2004) 25\u201347, [hep-ex/0404026].\n[199] G. Abbiendi et. al.,, OPAL Collaboration Eur. Phys. J. C31 (2003) 307\u2013325,\n[hep-ex/0301013].\n[200] D. Buskulic et. al.,, ALEPH Collaboration Phys. Lett. B384 (1996) 353\u2013364.\n[201] Y. L. Dokshitzer, G. D. Leder, S. Moretti, and B. R. Webber, JHEP 08 (1997) 001,\n[hep-ph/9707323].\n[202] M. Wobisch and T. Wengler, hep-ph/9907280.\n[203] G. P. Salam, M. Cacciari, and G. Soyez,. http://www.lpthe.jussieu.fr/ salam/fastjet/.\n[204] G. Giurgiu,, for the CMS Collaboration arXiv:0909.4894 [hep-ex].\n[205] D. Krohn, J. Thaler, and L.-T. Wang, JHEP 06 (2009) 059, [arXiv:0903.0392 [hep-ph]].\n[206] L. G. Almeida, S. J. Lee, G. Perez, I. Sung, and J. Virzi, Phys. Rev. D79 (2009) 074012,\n[arXiv:0810.0934 [hep-ph]].\n[207] L. G. Almeida et. al., Phys. Rev. D79 (2009) 074017, [arXiv:0807.0234 [hep-ph]].\n[208] G. P. Salam, arXiv:0906.1833 [hep-ph].\n[209] J. Gallicchio and M. D. Schwartz, arXiv:1001.5027 [hep-ph].\n[210] K. Hagiwara et. al., Phys. Rev. D73 (2006) 055005, [arXiv:hep-ph/0512260].\n[211] W. Kilian, T. Ohl, and J. Reuter, arXiv:0708.4233.\n[212] F. Bloch and A. Nordsieck, Phys. Rev. 52 (1937) 54\u201359.\n[213] T. Kinoshita, J. Math. Phys. 3 (1962) 650\u2013677.\n[214] T. D. Lee and M. Nauenberg, Phys. Rev. 133 (1964) B1549\u2013B1562.\n[215] A. Denner, S. Dittmaier, M. Roth, and D. Wackeroth, Nucl. Phys. B560 (1999) 33\u201365,\n[arXiv:hep-ph/9904472].\n[216] W. Beenakker et. al., arXiv:hep-ph/9602351.\n[217] U. Baur and D. Zeppenfeld, Phys. Rev. Lett. 75 (1995) 1002\u20131005,\n[arXiv:hep-ph/9503344].\n[218] U. Baur and D. Wackeroth, Phys. Rev. D70 (2004) 073015, [hep-ph/0405191].\n[219] W. Beenakker et. al., Nucl. Phys. B500 (1997) 255\u2013298, [hep-ph/9612260].\n[220] M. A. Gigg and P. Richardson, arXiv:0805.3037 [hep-ph].\n[221] J. C. Collins, Nucl. Phys. B304 (1988) 794.\n140\n\n\f[222] I. G. Knowles, Comput. Phys. Commun. 58 (1990) 271\u2013284.\n[223] I. G. Knowles, Nucl. Phys. B310 (1988) 571.\n[224] P. Richardson, JHEP 11 (2001) 029, [hep-ph/0110108].\n[225] F. Ambroglini et. al., arXiv:0902.0293 [hep-ph].\n[226] B. R. Webber, Ann. Rev. Nucl. Part. Sci. 36 (1986) 253\u2013286.\n[227] M. Cacciari and S. Catani, Nucl. Phys. B617 (2001) 253\u2013290, [arXiv:hep-ph/0107138].\n[228] E. Barberio and Z. Was, Comput. Phys. Commun. 79 (1994) 291\u2013308.\n[229] E. Barberio, B. van Eijk, and Z. Was, Comput. Phys. Commun. 66 (1991) 115\u2013128.\n[230] P. Golonka and Z. Was, Eur. Phys. J. C45 (2006) 97\u2013107, [arXiv:hep-ph/0506026].\n[231] P. Golonka and Z. Was, Eur. Phys. J. C50 (2007) 53\u201362, [arXiv:hep-ph/0604232].\n[232] G. Nanava and Z. Was, Eur. Phys. J. C51 (2007) 569\u2013583, [arXiv:hep-ph/0607019].\n[233] D. R. Yennie, S. C. Frautschi, and H. Suura, Ann. Phys. 13 (1961) 379\u2013452.\n[234] M. Kaku,. New York, USA: Oxford Univ. Pr. (1993) 785 p.\n[235] M. E. Peskin and D. V. Schroeder,. Reading, USA: Addison-Wesley (1995) 842 p.\n[236] S. Jadach,. MPI-PAE/PTh 6/87.\n[237] B. F. L. Ward, Phys. Rev. D36 (1987) 939.\n[238] S. Jadach and B. F. L. Ward, Phys. Rev. D38 (1988) 2897.\n[239] S. Jadach, W. Placzek, M. Skrzypek, and B. F. L. Ward, Phys. Rev. D54 (1996) 5434\u20135442,\n[hep-ph/9606429].\n[240] S. Jadach, B. F. L. Ward, and Z. Was, Comput. Phys. Commun. 130 (2000) 260\u2013325,\n[hep-ph/9912214].\n[241] S. Jadach, B. F. L. Ward, and Z. Was, Phys. Rev. D63 (2001) 113009, [hep-ph/0006359].\n[242] M. L. Mangano, M. Moretti, F. Piccinini, and M. Treccani, JHEP 01 (2007) 013,\n[arXiv:hep-ph/0611129].\n[243] S. Gieseke, P. Stephens, and B. Webber, JHEP 12 (2003) 045, [hep-ph/0310083].\n[244] K. Hamilton and P. Richardson, JHEP 02 (2007) 069, [arXiv:hep-ph/0612236].\n[245] K. Hamilton and P. Richardson, JHEP 07 (2006) 010, [arXiv:hep-ph/0603034].\n[246] M. Bengtsson and T. Sjostrand, Nucl. Phys. B289 (1987) 810.\n[247] E. Norrbin and T. Sj\u00f6strand, Nucl. Phys. B603 (2001) 297\u2013342, [arXiv:hep-ph/0010012].\n[248] F. Krauss, A. Schalicke, and G. Soff, Comput. Phys. Commun. 174 (2006) 876\u2013902,\n[arXiv:hep-ph/0503087].\n[249] M. Schonherr and F. Krauss, JHEP 12 (2008) 018, [arXiv:0810.5071 [hep-ph]].\n\n141\n\n\f[250] G. Brooijmans,. ATL-PHYS-CONF-2008-008.\n[251] S. Catani, Y. L. Dokshitzer, and B. R. Webber, Phys. Lett. B285 (1992) 291\u2013299.\n[252] S. D. Ellis and D. E. Soper, Phys. Rev. D48 (1993) 3160\u20133166, [hep-ph/9305266].\n[253] G. Aad et. al.,, ATLAS collaboration Collaboration JINST 3 (2008) S08003.\n[254] S. Abachi et. al.,, D0 Collaboration Phys. Rev. Lett. 72 (1994) 2332\u20132336.\n[255] D. L. Rainwater, D. Zeppenfeld, and K. Hagiwara, Phys. Rev. D59 (1999) 014037,\n[arXiv:hep-ph/9808468].\n[256] M. Cacciari, G. Salam, and G. Soyez, JHEP 0804 (2008) 005, [arXiv:0802.1188\n[hep-ph]].\n[257] M. Campanelli and J. W. Monk, arXiv:0910.5108 [hep-ph].\n[258] A. Djouadi, J. Kalinowski, and M. Spira, Comput. Phys. Commun. 108 (1998) 56\u201374,\n[arXiv:hep-ph/9704448].\n[259] M. Spira, Fortsch. Phys. 46 (1998) 203\u2013284, [arXiv:hep-ph/9705337].\n[260] A. Djouadi, Phys. Rept. 459 (2008) 1\u2013241, [arXiv:hep-ph/0503173].\n[261] A. Djouadi, M. Spira, and P. M. Zerwas, Z. Phys. C70 (1996) 427\u2013434,\n[arXiv:hep-ph/9511344].\n[262] A. Djouadi, J. Kalinowski, and P. M. Zerwas, Z. Phys. C70 (1996) 435\u2013448,\n[arXiv:hep-ph/9511342].\n[263] M. S. Carena, M. Quiros, and C. E. M. Wagner, Nucl. Phys. B461 (1996) 407\u2013436,\n[arXiv:hep-ph/9508343].\n[264] H. E. Haber, R. Hempfling, and A. H. Hoang, Z. Phys. C75 (1997) 539\u2013554,\n[arXiv:hep-ph/9609331].\n[265] M. S. Carena et. al., Nucl. Phys. B580 (2000) 29\u201357, [arXiv:hep-ph/0001002].\n[266] G. Degrassi, S. Heinemeyer, W. Hollik, P. Slavich, and G. Weiglein, Eur. Phys. J. C28 (2003)\n133\u2013143, [arXiv:hep-ph/0212020].\n[267] A. Djouadi, J. Kalinowski, and P. M. Zerwas, Z. Phys. C57 (1993) 569\u2013584.\n[268] A. Djouadi, P. Janot, J. Kalinowski, and P. M. Zerwas, Phys. Lett. B376 (1996) 220\u2013226,\n[arXiv:hep-ph/9603368].\n[269] A. Djouadi, J. Kalinowski, P. Ohmann, and P. M. Zerwas, Z. Phys. C74 (1997) 93\u2013111,\n[arXiv:hep-ph/9605339].\n[270] A. Djouadi and M. Drees, Phys. Lett. B407 (1997) 243\u2013249, [arXiv:hep-ph/9703452].\n[271] A. Dabelstein, Nucl. Phys. B456 (1995) 25\u201356, [arXiv:hep-ph/9503443].\n[272] J. A. Coarasa Perez, R. A. Jimenez, and J. Sola, Phys. Lett. B389 (1996) 312\u2013320,\n[arXiv:hep-ph/9511402].\n[273] M. S. Carena, D. Garcia, U. Nierste, and C. E. M. Wagner, Nucl. Phys. B577 (2000) 88\u2013120,\n[arXiv:hep-ph/9912516].\n142\n\n\f[274] J. Guasch, P. Hafliger, and M. Spira, Phys. Rev. D68 (2003) 115001,\n[arXiv:hep-ph/0305101].\n[275] D. Noth and M. Spira, Phys. Rev. Lett. 101 (2008) 181801, [arXiv:0808.0087 [hep-ph]].\n[276] D. Noth and M. Spira, arXiv:1001.1935 [hep-ph].\n[277] A. Djouadi, M. Spira, J. J. van der Bij, and P. M. Zerwas, Phys. Lett. B257 (1991) 187\u2013190.\n[278] A. Djouadi, M. Spira, and P. M. Zerwas, Phys. Lett. B311 (1993) 255\u2013260,\n[arXiv:hep-ph/9305335].\n[279] K. Melnikov and O. I. Yakovlev, Phys. Lett. B312 (1993) 179\u2013183,\n[arXiv:hep-ph/9302281].\n[280] M. Inoue, R. Najima, T. Oka, and J. Saito, Mod. Phys. Lett. A9 (1994) 1189\u20131194.\n[281] M. Spira, A. Djouadi, D. Graudenz, and P. M. Zerwas, Nucl. Phys. B453 (1995) 17\u201382,\n[arXiv:hep-ph/9504378].\n[282] M. Muhlleitner and M. Spira, Nucl. Phys. B790 (2008) 1\u201327, [arXiv:hep-ph/0612254].\n[283] A. Bredenstein, A. Denner, S. Dittmaier, and M. M. Weber, Phys. Rev. D74 (2006) 013004,\n[arXiv:hep-ph/0604011].\n[284] A. Bredenstein, A. Denner, S. Dittmaier, and M. M. Weber, JHEP 02 (2007) 080,\n[arXiv:hep-ph/0611234].\n[285] A. Pukhov et. al., arXiv:hep-ph/9908288.\n[286] E. Boos et. al.,, CompHEP Collaboration Nucl. Instrum. Meth. A534 (2004) 250\u2013259,\n[arXiv:hep-ph/0403113].\n[287] A. Pukhov, arXiv:hep-ph/0412191.\n[288] T. Stelzer and W. F. Long, Comput. Phys. Commun. 81 (1994) 357\u2013371,\n[arXiv:hep-ph/9401258].\n[289] J. Alwall et. al., AIP Conf. Proc. 1078 (2009) 84\u201389, [arXiv:0809.2410 [hep-ph]].\n[290] M. Moretti, T. Ohl, and J. Reuter, arXiv:hep-ph/0102195.\n[291] N. D. Christensen and C. Duhr, Comput. Phys. Commun. 180 (2009) 1614\u20131641,\n[arXiv:0806.4194 [hep-ph]].\n[292] T. Hahn and M. Perez-Victoria, Comput. Phys. Commun. 118 (1999) 153\u2013165,\n[arXiv:hep-ph/9807565].\n[293] J. A. M. Vermaseren, arXiv:math-ph/0010025.\n[294] D. Fliegner, A. Retey, and J. A. M. Vermaseren, arXiv:hep-ph/9906426.\n[295] D. Fliegner, A. Retey, and J. A. M. Vermaseren, arXiv:hep-ph/0007221.\n[296] M. Tentyukov et. al., arXiv:cs/0407066.\n[297] M. Tentyukov and J. A. M. Vermaseren, arXiv:hep-ph/0702279.\n\n143\n\n\f[298] A. Semenov, Comput. Phys. Commun. 180 (2009) 431\u2013454, [arXiv:0805.0555\n[hep-ph]].\n[299] N. D. Christensen et. al., arXiv:0906.2474 [hep-ph].\n[300] F. website http://feynrules.phys.ucl.ac.be,.\n[301] J. Rosiek, Phys. Rev. D41 (1990) 3464.\n[302] J. Rosiek, arXiv:hep-ph/9511250.\n[303] H. E. Haber and G. L. Kane, Phys. Rept. 117 (1985) 75\u2013263.\n[304] J. F. Gunion and H. E. Haber, Nucl. Phys. B272 (1986) 1.\n[305] G. Bozzi, B. Fuks, B. Herrmann, and M. Klasen, Nucl. Phys. B787 (2007) 1\u201354,\n[arXiv:0704.1826 [hep-ph]].\n[306] B. Fuks, B. Herrmann, and M. Klasen, Nucl. Phys. B810 (2009) 266\u2013299, [arXiv:0808.1104\n[hep-ph]].\n[307] B. C. Allanach et. al., Eur. Phys. J. C25 (2002) 113\u2013123, [arXiv:hep-ph/0202233].\n[308] L. Basso, A. Belyaev, S. Moretti, and C. H. Shepherd-Themistocleous, Phys. Rev. D80 (2009)\n055030, [arXiv:0812.4313 [hep-ph]].\n[309] E. Accomando et. al., arXiv:hep-ph/0608079.\n[310] J. A. Aguilar-Saavedra et. al., Eur. Phys. J. C46 (2006) 43\u201360, [arXiv:hep-ph/0511344].\n[311] J. Reuter and F. Braam, arXiv:0909.3059 [hep-ph].\n[312] G. D. Kribs, E. Poppitz, and N. Weiner, Phys. Rev. D78 (2008) 055010, [arXiv:0712.2039\n[hep-ph]].\n[313] G. D. Kribs, A. Martin, and T. S. Roy, JHEP 01 (2009) 023, [arXiv:0807.4936\n[hep-ph]].\n[314] G. D. Kribs, A. Martin, and T. S. Roy, JHEP 06 (2009) 042, [arXiv:0901.4105\n[hep-ph]].\n[315] T. Plehn and T. M. P. Tait, J. Phys. G36 (2009) 075001, [arXiv:0810.3919 [hep-ph]].\n[316] A. E. Blechman, Mod. Phys. Lett. A24 (2009) 633\u2013646, [arXiv:0903.2822 [hep-ph]].\n\n144\n\n\f"}