{"id": "http://arxiv.org/abs/0901.2504v2", "guidislink": true, "updated": "2009-01-23T11:09:18Z", "updated_parsed": [2009, 1, 23, 11, 9, 18, 4, 23, 0], "published": "2009-01-16T15:14:30Z", "published_parsed": [2009, 1, 16, 15, 14, 30, 4, 16, 0], "title": "Parton Distributions", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0901.2194%2C0901.1601%2C0901.3083%2C0901.0641%2C0901.4572%2C0901.0902%2C0901.4221%2C0901.4098%2C0901.4849%2C0901.1217%2C0901.4492%2C0901.4119%2C0901.0034%2C0901.3688%2C0901.2039%2C0901.1727%2C0901.3432%2C0901.2707%2C0901.4144%2C0901.4430%2C0901.0379%2C0901.1554%2C0901.4558%2C0901.0301%2C0901.1372%2C0901.2190%2C0901.1202%2C0901.3415%2C0901.2530%2C0901.0594%2C0901.3861%2C0901.0801%2C0901.1171%2C0901.2087%2C0901.1826%2C0901.0284%2C0901.2440%2C0901.4869%2C0901.2888%2C0901.3700%2C0901.0981%2C0901.3549%2C0901.2445%2C0901.0807%2C0901.1704%2C0901.1931%2C0901.0556%2C0901.4231%2C0901.1041%2C0901.3479%2C0901.3870%2C0901.0547%2C0901.0354%2C0901.2504%2C0901.0304%2C0901.2366%2C0901.0320%2C0901.0396%2C0901.0088%2C0901.2655%2C0901.0537%2C0901.1233%2C0901.3222%2C0901.4262%2C0901.1140%2C0901.4923%2C0901.3230%2C0901.2505%2C0901.3956%2C0901.2203%2C0901.1880%2C0901.0736%2C0901.2048%2C0901.2750%2C0901.3951%2C0901.1868%2C0901.1040%2C0901.2584%2C0901.4061%2C0901.0200%2C0901.1576%2C0901.1249%2C0901.3229%2C0901.4659%2C0901.3265%2C0901.3300%2C0901.3168%2C0901.3820%2C0901.0027%2C0901.1336%2C0901.3244%2C0901.4696%2C0901.1811%2C0901.0461%2C0901.1070%2C0901.1923%2C0901.3727%2C0901.3879%2C0901.3444%2C0901.1333%2C0901.0448&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Parton Distributions"}, "summary": "We provide an assessment of the state of the art in various issues related to\nexperimental measurements, phenomenological methods and theoretical results\nrelevant for the determination of parton distribution functions (PDFs) and\ntheir uncertainties, with the specific aim of providing benchmarks of different\nexisting approaches and results in view of their application to physics at the\nLHC. We discuss higher order corrections, we review and compare different\napproaches to small x resummation, and we assess the possible relevance of\nparton saturation in the determination of PDFS at HERA and its possible study\nin LHC processes. We provide various benchmarks of PDF fits, with the specific\naim of studying issues of error propagation, non-gaussian uncertainties, choice\nof functional forms of PDFs, and combination of data from different experiments\nand different processes. We study the impact of combined HERA (ZEUS-H1)\nstructure function data, their impact on PDF uncertainties, and their\nimplications for the computation of standard candle processes, and we review\nthe recent F_L determination at HERA. Finally, we compare and assess methods\nfor luminosity measurements at the LHC and the impact of PDFs on them.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0901.2194%2C0901.1601%2C0901.3083%2C0901.0641%2C0901.4572%2C0901.0902%2C0901.4221%2C0901.4098%2C0901.4849%2C0901.1217%2C0901.4492%2C0901.4119%2C0901.0034%2C0901.3688%2C0901.2039%2C0901.1727%2C0901.3432%2C0901.2707%2C0901.4144%2C0901.4430%2C0901.0379%2C0901.1554%2C0901.4558%2C0901.0301%2C0901.1372%2C0901.2190%2C0901.1202%2C0901.3415%2C0901.2530%2C0901.0594%2C0901.3861%2C0901.0801%2C0901.1171%2C0901.2087%2C0901.1826%2C0901.0284%2C0901.2440%2C0901.4869%2C0901.2888%2C0901.3700%2C0901.0981%2C0901.3549%2C0901.2445%2C0901.0807%2C0901.1704%2C0901.1931%2C0901.0556%2C0901.4231%2C0901.1041%2C0901.3479%2C0901.3870%2C0901.0547%2C0901.0354%2C0901.2504%2C0901.0304%2C0901.2366%2C0901.0320%2C0901.0396%2C0901.0088%2C0901.2655%2C0901.0537%2C0901.1233%2C0901.3222%2C0901.4262%2C0901.1140%2C0901.4923%2C0901.3230%2C0901.2505%2C0901.3956%2C0901.2203%2C0901.1880%2C0901.0736%2C0901.2048%2C0901.2750%2C0901.3951%2C0901.1868%2C0901.1040%2C0901.2584%2C0901.4061%2C0901.0200%2C0901.1576%2C0901.1249%2C0901.3229%2C0901.4659%2C0901.3265%2C0901.3300%2C0901.3168%2C0901.3820%2C0901.0027%2C0901.1336%2C0901.3244%2C0901.4696%2C0901.1811%2C0901.0461%2C0901.1070%2C0901.1923%2C0901.3727%2C0901.3879%2C0901.3444%2C0901.1333%2C0901.0448&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We provide an assessment of the state of the art in various issues related to\nexperimental measurements, phenomenological methods and theoretical results\nrelevant for the determination of parton distribution functions (PDFs) and\ntheir uncertainties, with the specific aim of providing benchmarks of different\nexisting approaches and results in view of their application to physics at the\nLHC. We discuss higher order corrections, we review and compare different\napproaches to small x resummation, and we assess the possible relevance of\nparton saturation in the determination of PDFS at HERA and its possible study\nin LHC processes. We provide various benchmarks of PDF fits, with the specific\naim of studying issues of error propagation, non-gaussian uncertainties, choice\nof functional forms of PDFs, and combination of data from different experiments\nand different processes. We study the impact of combined HERA (ZEUS-H1)\nstructure function data, their impact on PDF uncertainties, and their\nimplications for the computation of standard candle processes, and we review\nthe recent F_L determination at HERA. Finally, we compare and assess methods\nfor luminosity measurements at the LHC and the impact of PDFs on them."}, "authors": ["M. Dittmar", "S. Forte", "A. Glazov", "S. Moch", "G. Altarelli", "J. Anderson", "R. D. Ball", "G. Beuf", "M. Boonekamp", "H. Burkhardt", "F. Caola", "M. Ciafaloni", "D. Colferai", "A. Cooper-Sarkar", "A. de Roeck", "L. Del Debbio", "J. Feltesse", "F. Gelis", "J. Grebenyuk", "A. Guffanti", "V. Halyo", "J. I. Latorre", "V. Lendermann", "Gang Li", "L. Motyka", "T. Petersen", "A. Piccione", "V. Radescu", "M. Rogal", "J. Rojo", "C. Royon", "G. P. Salam", "D. Salek", "A. M. Stasto", "R. S. Thorne", "M. Ubiali", "J. A. M. Vermaseren", "A. Vogt", "G. Watt", "C. D. White"], "author_detail": {"name": "C. D. White"}, "author": "C. D. White", "arxiv_comment": "99 pages, 61 figures; summary report of Working Group I for the\n  HERA-LHC workshop. Requires cernrep.cls and mcite.sty. Various typos\n  corrected", "links": [{"href": "http://arxiv.org/abs/0901.2504v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0901.2504v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0901.2504v2", "affiliation": "convenors", "arxiv_url": "http://arxiv.org/abs/0901.2504v2", "journal_reference": null, "doi": null, "fulltext": "arXiv:0901.2504v2 [hep-ph] 23 Jan 2009\n\nS UMMARY R EPORT FOR THE HERA - LHC W ORKSHOP PROCEEDINGS\nWORKING GROUP I: PARTON D ISTRIBUTIONS\nC ONVENERS :\nM. Dittmar 1 , S. Forte 2 , A. Glazov 3 , S. Moch 4\nC ONTRIBUTING AUTHORS :\nG. Altarelli5,6 , J. Anderson7 , R. D. Ball8 , G. Beuf 9 , M. Boonekamp10 , H. Burkhardt11 , F. Caola2 ,\nM. Ciafaloni12 , D. Colferai12 , A. Cooper-Sarkar13 , A. de Roeck14 , L. Del Debbio8 , J. Feltesse15,16 , F. Gelis 5 ,\nJ. Grebenyuk3 , A. Guffanti17 , V. Halyol8 , J. I. Latorre19 , V. Lendermann20 , G. Li 21 , L. Motyka 22,23 ,\nT. Petersen14 A. Piccione2 , V. Radescu3 , M. Rogal4 , J. Rojo2,24 , C. Royon 10 , G. P. Salam 24 , D. \u0160\u00e1lek 25 ,\nA. M. Sta\u015bto 26,27,28 , R. S. Thorne29 , M. Ubiali8 , J. A. M. Vermaseren30 , A. Vogt31 , G. Watt29 , C. D. White30\n1 Institute for Particle Physics, ETH-Z\u00fcrich H\u00f6nggerberg, CH 8093 Z\u00fcrich, Switzerland\n2 Dipartimento di Fisica, Universit\u00e0 di Milano, INFN Sezione di Milano, Via Celoria 16,\nI-20133 Milan, Italy\n3 DESY, Notkestrasse 85, D-22603 Hamburg, Germany\n4 DESY, Platanenallee 6, D-15738 Zeuthen, Germany\n5 CERN, Department of Physics, Theory Division, CH-1211 Geneva 23, Switzerland\n6 Dipartimento di Fisica \"E.Amaldi\", Universit\u00e0 Roma Tre and INFN, Sezione di Roma Tre,\nvia della Vasca Navale 84, I-00146 Rome, Italy\n7 School of Physics, University College Dublin, Ireland\n8 School of Physics, University of Edinburgh, Edinburgh EH9 3JZ, UK\n9 Institut de Physique Th\u00e9orique, CEA\u2013Saclay F-91191 Gif-sur-Yvette, France\n10 IRFU, Service de Physique des Particules, CEA\u2013Saclay F-91191 Gif-sur-Yvette, France\n11 CERN-AB, CH-1211 Geneva 23, Switzerland\n12 Dipartimento di Fisica, Universit\u00e0 di Firenze and INFN, Sezione di Firenze, I-50019\nSesto Fiorentino, Italy\n13 Department of Physics, Nuclear and Astrophysics Lab., Keble Road, Oxford, OX1 3RH, UK\n14 CERN-PH, CH-1211 Geneva 23, Switzerland\n15 IRFU, CEA\u2013Saclay F-91191 Gif-sur-Yvette, France\n16 University of Hamburg, Luruper Chaussee 149, Hamburg, D-22761 Germany\n17 Physikalisches Institut, Albert-Ludwigs-Universit\u00e4t Freiburg, Hermann-Herder-Strasse 3,\nD-79104 Freiburg i. B., Germany\n18 Department of Physics, Princeton University, Princeton, NJ08544, USA\n19 Departament d'Estructura i Constituents de la Mat\u00e8ria, Universitat de Barcelona, Diagonal 647,\nE 08028 Barcelona, Spain\n20 Kirchhoff-Institut f\u00fcr Physik, Universit\u00e4t Heidelberg, Im Neuenheimer Feld 227,\nD-69120 Heidelberg, Germany\n21 Laboratoire de l'Acc\u00e9l\u00e9rateur Lin\u00e9aire, Universit\u00e9 Paris-Sud, Orsay, France\n22 II Institute for Theoretical Physics, University of Hamburg, Luruper Chaussee 149,\nHamburg, D-22761 Germany\n23 Institute of Physics, Jagellonian University Reymonta 4, 30-059 Cracow, Poland\n24 LPTHE, UPMC \u2013 Paris 6, Paris-Diderot \u2013 Paris 7, CNRS UMR 7589, F-75005 Paris, France\n25 Institute of Particle and Nuclear Physics, Charles University, Prague, Czech Republic\n26 Physics Department, Penn State University, 104 Davey Laboratory, University Park, PA 16802, USA\n27 H. Niewodnicza\u0144ski Institute of Nuclear Physics, Polish Academy of Science,\nul.Radzikowskiego 152, 31-342 Cracow, Poland\n28 Brookhaven National Laboratory, Upton, NY-11073, USA\n29 Department of Physics and Astronomy, University College, London, WC1E 6BT, UK\n30 NIKHEF Theory Group, Kruislaan 409, NL 1098 SJ Amsterdam, The Netherlands\n31 Department of Mathematical Sciences, University of Liverpool, Liverpool, L69 3BX, UK\n\n\fAbstract\nWe provide an assessment of the state of the art in various issues related to experimental measurements, phenomenological methods and theoretical results relevant\nfor the determination of parton distribution functions (PDFs) and their uncertainties,\nwith the specific aim of providing benchmarks of different existing approaches and\nresults in view of their application to physics at the LHC.\nWe discuss higher order corrections, we review and compare different approaches\nto small x resummation, and we assess the possible relevance of parton saturation\nin the determination of PDFS at HERA and its possible study in LHC processes.\nWe provide various benchmarks of PDF fits, with the specific aim of studying issues of error propagation, non-gaussian uncertainties, choice of functional forms of\nPDFs, and combination of data from different experiments and different processes.\nWe study the impact of combined HERA (ZEUS-H1) structure function data, their\nimpact on PDF uncertainties, and their implications for the computation of standard\ncandle processes, and we review the recent FL determination at HERA. Finally,\nwe compare and assess methods for luminosity measurements at the LHC and the\nimpact of PDFs on them.\n\n\fContents\n1 INTRODUCTION\n\n6\n\n2 THEORETICAL ISSUES\n2.1\n2.2\n\n2.3\n\n7\n\nPrecision calculations for inclusive DIS: an\nSmall x resummation\n\n2\n\nupdate1\n\n. . . . . . . . . . . . . . . . . . . . . . .\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\n2.2.1\n\nThe Altarelli-Ball-Forte (ABF) Approach . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n2.2.2\n\nThe Ciafaloni-Colferai-Salam-Stasto (CCSS) Approach . . . . . . . . . . . . . . . . 15\n\n2.2.3\n\nThe Thorne-White (TW) Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n2.2.4\n\nResummed structure functions: comparison of the ABF and TW approaches . . . . . . 21\n\n2.2.5\n\nConclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\nParton saturation and geometric scaling3\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n2.3.1\n\nIntroduction4\n\n2.3.2\n\nPhenomenology5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n\n2.3.3\n\nGeometric scaling and evolution equations with saturation6 . . . . . . . . . . . . . . . 28\n\n2.3.4\n\nDGLAP evolution and the saturation boundary conditions7 . . . . . . . . . . . . . . . 29\n\n2.3.5\n\nGeometric scaling from DGLAP evolution8 . . . . . . . . . . . . . . . . . . . . . . . 30\n\n2.3.6\n\nSaturation model and higher twists9 . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n\n2.3.7\n\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n\n3 BENCHMARKING OF PARTON DISTRIBUTIONS AND THEIR UNCERTAINTIES10\n3.1\n\n3.2\n\n3.3\n\n1\n\n7\n\n36\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.1.1\n\nSettings for the H1 benchmark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n3.1.2\n\nSettings for the HERA\u2013LHC benchmark . . . . . . . . . . . . . . . . . . . . . . . . 38\n\nExperimental Error Propagation11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.2.1\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n\n3.2.2\n\nMethod . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n\n3.2.3\n\nValidation of the Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\n3.2.4\n\nTest of various assumptions for the error distributions . . . . . . . . . . . . . . . . . . 41\n\n3.2.5\n\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\nHERA\u2013LHC Benchmark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n3.3.1\n\nMSTW approach12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n\n3.3.2\n\nNNPDF approach13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n\nContributing authors: S. Moch, M. Rogal, J. A. M. Vermaseren, A. Vogt\nContributing authors: G. Altarelli, R. D. Ball, M. Ciafaloni, D. Colferai, G. P. Salam, A. Sta\u015bto, R. S. Thorne, C. D. White\n3\nContributing authors: G. Beuf, F. Caola, F. Gelis, L. Motyka, C. Royon, D. \u0160\u00e1lek, A. M. Sta\u015bto\n4\nContributing authors: F. Gelis, A. M. Sta\u015bto\n5\nContributing authors: C. Royon, D. \u0160\u00e1lek\n6\nContributing author: G. Beuf\n7\nContributing author: A. M. Sta\u015bto\n8\nContributing author: F. Caola\n9\nContributing author: L. Motyka\n10\nContributing authors: R. D. Ball, L. Del Debbio, J. Feltesse, S. Forte, A. Glazov, A. Guffanti, J. I. Latorre, A. Piccione, V. Radescu, J. Rojo, R. S. Thorne, M. Ubiali, G. Watt\n11\nContributing authors: J. Feltesse, A. Glazov, V. Radescu\n12\nContributing authors: R. S. Thorne, G. Watt\n13\nContributing authors: R. D. Ball, L. Del Debbio, S. Forte, A. Guffanti, J. I. Latorre, A. Piccione, J. Rojo, M. Ubiali\n2\n\n\f3.4\n\n3.3.3\n\nComparison between the Benchmark Parton Distributions . . . . . . . . . . . . . . . 44\n\n3.3.4\n\nComparison of the Benchmark Parton Distributions and Global Fits . . . . . . . . . . 46\n\nH1 Benchmark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n3.4.1\n\nNNPDF analysis14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n\n3.4.2\n\nComparison between the Benchmark Parton Distributions . . . . . . . . . . . . . . . 51\n\n4 DETERMINATION OF PARTON DISTRIBUTIONS\n4.1\n\n4.2\n\n52\n\nExtraction of the proton PDFs from a combined fit of H1 and ZEUS inclusive DIS cross\nsections 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.1.1\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n\n4.1.2\n\nData Combination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n\n4.1.3\n\nQCD Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n\n4.1.4\n\nResults . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n\n4.1.5\n\nSummary of HERAPDF0.1 results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n\n4.1.6\n\nPredictions for W and Z cross-sections at the LHC using the HERAPDF0.1 . . . . . . 62\n\nMeasurements of the Proton Structure Function FL at HERA 16\n\n. . . . . . . . . . . . . . . . 66\n\n4.2.1\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\n4.2.2\n\nIndirect FL Extraction by H1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n\n4.2.3\n\nDetails of Direct FL Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n\n4.2.4\n\nMeasurements of FL (x, Q2 ) by H1 and ZEUS . . . . . . . . . . . . . . . . . . . . . 73\n\n4.2.5\n\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n\nPROTON\u2013PROTON LUMINOSITY, STANDARD CANDLES AND PDFS AT THE LHC17\n\n5\n\n5.1\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n\n5.2\n\nLuminosity relevant design of ATLAS/CMS and LHCb . . . . . . . . . . . . . . . . . . . . . 77\n5.2.1\n\n5.3\n\n5.4\n\n5.3.1\n\nProton-proton luminosity from machine parameters18 . . . . . . . . . . . . . . . . . . 79\n\n5.3.2\n\nDirect measurements of the absolute luminosity at LHCb . . . . . . . . . . . . . . . . 81\n\n5.3.3\n\nAbsolute pp luminosity from specialized detectors and from the total cross section\nmeasurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n\n5.3.4\n\nReal time relative luminosity measurements . . . . . . . . . . . . . . . . . . . . . . . 82\n\n5.3.5\n\nProton-proton luminosity from the reaction pp \u2192 pp\u03bc\u03bc . . . . . . . . . . . . . . . . 82\n\nIndirect and relative pp luminosity measurements . . . . . . . . . . . . . . . . . . . . . . . . 83\n5.4.2\n\n5.5\n\nLepton triggering and W/Z identification. . . . . . . . . . . . . . . . . . . . . . . . . 78\n\nDirect and indirect absolute pp luminosity measurements . . . . . . . . . . . . . . . . . . . . 79\n\n5.4.1\n\nUsing the reaction pp \u2192 Z \u2192 l+ l\u2212 to measure Lpp . . . . . . . . . . . . . . . . . . 84\nMeasuring Z and W production, experimental approaches in ATLAS . . . . . . . . . . 84\n\n5.4.3\n\nMeasuring Z production, experimental approach in LHCb . . . . . . . . . . . . . . . 85\n\n5.4.4\n\nPDF and relative parton-parton luminosity measurements . . . . . . . . . . . . . . . . 86\n\nComparing the different pp luminosity measurements . . . . . . . . . . . . . . . . . . . . . . 86\n5.5.1\n\n14\n\nWhich luminosity accuracy might be achievable and when . . . . . . . . . . . . . . . 88\n\nContributing authors R. D. Ball, L. Del Debbio, S. Forte, A. Guffanti, J. I. Latorre, A. Piccione, J. Rojo, M. Ubiali\nContributing authors: A. Cooper-Sarkar, A. Glazov, G. Li for the H1-ZEUS combination group.\n16\nContributing authors: J. Grebenyuk, V. Lendermann\n17\nContributing authors: J. Anderson, M. Boonekamp, H. Burkhardt, M. Dittmar, V. Halyo, T. Petersen\n18\nContributing author: H. Burkhardt\n\n15\n\n76\n\n\f5.6\n\nSummary and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n\n6 OUTLOOK: THE PDF4LHC INITIATIVE19\n19\n\nContributing author: A. de Roeck\n\n90\n\n\f1 INTRODUCTION\nWith the start of data\u2013taking at the LHC getting closer, the importance of a detailed understanding of the\nphysics of parton distributions (PDFs) has increased considerably, along with the awareness of the LHC community for the importance of the issues related to it. Clearly, the main reason why PDFs are important at the\nLHC is that at a hadron collider a detailed understanding of PDFs is needed in order to obtain accurate predictions for both signal and background processes. Indeed, for many physical processes at the LHC, PDFs are the\ndominant source of uncertainty. On the other hand, an accurate control of PDF uncertainties allows one to use\nselected processes as \"standard candles\", for instance in the determination of luminosities. However, this also\nmeans that experimentation at the LHC will provide a considerable amount of new experimental information\non PDFs, and it will enable us to test the adequacy of their current theoretical understanding.\nThe main aim of this document is to provide a state of the art assessment of our understanding of\nPDFs at the dawn of the LHC. Since the previous HERA-LHC workshop [1], we have witnessed several\nimportant directions of progress in the physics of PDFs. On the theoretical side there has been conclusive\nprogress in extending the treatment of perturbative QCD beyond the current default, namely, the next\u2013to\u2013\nleading perturbative order. On the phenomenological side there has been a joint effort between experimental\nand theoretical groups involved in the extraction of PDFs, specifically from global fits, in agreeing on common\nprocedures, benchmarks and standards. On the experimental side, new improved results from the HERA runs\nare being finalized: these include both the construction of a joint determination of structure function which\ncombines the result of the ZEUS and H1 experiments, and the first direct measurements of the structure\nfunction FL which have been made possible by running HERA at a reduced proton beam energy in 2007.\nAlso, the LHC experiments (ATLAS, CMS and LHCb) are now assessing the use of standard candle processes\nfor luminosity measurements.\nAll these issues are discussed in this document. In each case, our main goal has been to provide as much\nas possible a joint treatment by the various groups involved, as well as a comparison of different approaches\nand benchmarking of results. In particular, in Sect. 2, after briefly reviewing (Sect. 2.1) the current status of\nhigher\u2013order calculations for DIS, we provide (Sect. 2.2) detailed comparisons of techniques and results of\ndifferent existing approaches to small x resummation, and then we summarize (Sect. 2.3) the current status\nof studies of parton saturation at HERA, their possible impact on current PDF extraction and the prospects of\nfuture studies at the LHC. In Sect. 3 we discuss methods and results for the benchmarking of PDF fits: with\nspecific reference to two benchmark fits based on a common agreed set of data, we discuss issues related to\nerror propagation and non-gaussian errors, to the choice of functional form and corresponding bias, to possible\nincompatibilities between different data sets. In Sect. 4 we turn to recent progress in the extraction of PDFs\nfrom HERA data, specifically the impact of combined ZEUS-H1 structure function data on PDF determination\nand the ensuing calculation of W and Z cross-sections (Sect. 4.1) and the recent first determination of the\nstructure function FL (Sect. 4.2). In Sect. 5 we discuss and compare luminosity measurements based on\nabsolute proton\u2013proton luminosity measurements to those based on the use of standard candle processes, and\nthe impact on all of them of PDF uncertainties. Finally, in Sect. 6 we present the PDF4LHC initiative, which\nwill provide a framework for the continuation of PDF studies for the LHC.\nNote: Most of the contributions to this workshop are the result of collaboration between various groups.\nThe common set of authors given for each section or subsection has read and approved the entire content of\nthat section or subsection; however, when a subset of these authors is given for a specific part of the section or\nsubsection, they are responsible for it.\n\n\f2 THEORETICAL ISSUES\n2.1 Precision calculations for inclusive DIS: an update20\nWith high-precision data from HERA and in view of the outstanding importance of hard scattering cross\nsections at the LHC, a quantitative understanding of deep-inelastic processes is indispensable, necessitating\ncalculations beyond the standard next-to-leading order of perturbative QCD.\nIn this contribution we briefly discuss the recent extension of the three-loop calculations for inclusive\ndeep-inelastic scattering (DIS) [2\u20139] to the complete set of coefficient functions for the charged-current (CC)\ncase. The new third-order expressions are too lengthy for this short overview. They can be found in Refs. [10,\n11] together with the calculational methods and a more detailed discussion. Furthermore the reader is referred\nto Refs. [12,13] for our first results on the three-loop splitting functions for the evolution of helicity-dependent\nparton distributions.\nStructure functions in inclusive deep-inelastic scattering are among the most extensively measured observables. The combined data from fixed-target experiments and the HERA collider spans about four orders\nof magnitude in both Bjorken-x variable and the scale Q2 = \u2212q 2 given by the momentum q of the exchanged\nelectroweak gauge boson [14]. Here we consider the W-exchange charged-current case, see Refs. [15\u201321]\n\u00b1\n\u00b1\n\u00b1\nfor recent data from neutrino DIS and HERA. With six structure functions, F2W , F3W and FLW , this case\nhas a far richer structure than, for example, electromagnetic DIS with only two independent observables, F2\nand FL .\nEven taking into account a forthcoming combined H1/ZEUS final high-Q2 data set from HERA, more\ndetailed measurements are required to fully exploit the resulting potential, for instance at a future neutrino\nfactory, see Ref. [22], and the LHeC, the proposed high-luminosity electron-proton collider at the LHC [23].\nAlready now, however, CC DIS provides important information on the parton structure of the proton, e.g.,\nits flavour decomposition and the valence-quark distributions. Moreover, present results are also sensitive to\nelectroweak parameters of the Standard Model such as sin2 \u03b8W , see Ref. [24], and the space-like W-boson\npropagator [25]. As discussed, for example, in Refs. [26\u201329], a reliable determination of sin2 \u03b8W from neutrino DIS requires a detailed understanding of non-perturbative and perturbative QCD effects.\nPrevious complete results on unpolarized DIS include the three-loop splitting functions [5, 6] as well\nas the 3-loop coefficient functions for the photon-exchange structure functions F 2,L [7, 8]. However, most\ncoefficient functions for CC DIS were not fully computed to three loops so far.\n\u00b1\n\nFor this case it is convenient to consider linear combinations of the structure functions FaW with simple\nproperties under crossing, such as Fa\u03bdp\u00b1\u03bd\u0304p (a = 2, 3, L) for neutrino DIS. For all these combinations either the\neven or odd moments can be calculated in Mellin-N space in the framework of the operator product expansion\n\u03bdp+\u03bd\u0304p\n(OPE), see Ref. [30]. The results for the third-order coefficient functions for the even-N combinations F2,L\ncan be taken over from electromagnetic DIS [7, 8]. Also the coefficient function for the odd-N based chargedcurrent structure function F3\u03bdp+\u03bd\u0304p is completely known at three-loop accuracy, with the results only published\n\u03bdp\u2212\u03bd\u0304p\nvia compact parameterizations so far [9]. For the remaining combinations F2,L\nand F3\u03bdp\u2212\u03bd\u0304p, on the other\nhand, only recently the first six odd or even integer moments of the respective coefficient functions have been\ncalculated to third order in Ref. [10] following the approach of Refs. [2\u20134] based on the M INCER program\n[31, 32].\nThe complete results of Refs. [7\u20139] fix all even and odd moments N . Hence already the present knowl\u03bdp\u2212\u03bd\u0304p\nedge of fixed Mellin moments for F2,L\nand F3\u03bdp\u2212\u03bd\u0304p is sufficient to determine also the lowest six moments\nof the differences of corresponding even-N and odd-N coefficient functions and to address a theoretical conjecture [33] for these quantities, see Ref. [11]. Furthermore these moments facilitate x-space approximations\nin the style of, e.g, Ref. [34] which are sufficient for most phenomenological purposes, including the determination of the third-order QCD corrections to the Paschos-Wolfenstein relation [35] used for the extraction of\nsin2 \u03b8W from neutrino DIS.\nThe even-odd differences of the CC coefficient functions Ca for a = 2, 3, L can be defined by\n\u03bdp+\u03bd\u0304p\n\u03bdp\u2212\u03bd\u0304p\n\u03b4 C2,L = C2,L\n\u2212 C2,L\n,\n20\n\n\u03b4 C3 = C3\u03bdp\u2212\u03bd\u0304p \u2212 C3\u03bdp+\u03bd\u0304p .\n\nContributing authors: S. Moch, M. Rogal, J. A. M. Vermaseren, A. Vogt\n\n(1)\n\n\fThe signs are chosen such that the differences are always 'even \u2013 odd' in the moments N accessible by the\nOPE [30], and it is understood that the d abc dabc part of C3\u03bdp+\u03bd\u0304p [4, 9] is removed before the difference is\nformed. With as = \u03b1s /(4\u03c0) these non-singlet quantities can be expanded as\nX\n\u03b4 Ca =\nasl \u03b4ca(l) .\n(2)\nl=2\n\nThere are no first-order contributions to these differences, hence the above sums start at l = 2 .\nWe start the illustration of these recent results by looking at the approximations for the \u03bdp \u2212 \u03bd\u0304p odd(3)\nN coefficient functions c2,L (x) (see Ref. [11] for a detailed discussion). These are compared in Fig. 1 to\ntheir exact counterparts [7, 8] for the even-N non-singlet structure functions. The dashed lines represent the\nuncertainty band due to the limited number of known moments. The third-order even-odd differences remain\nnoticeable to larger values of x than at two loops, e.g., up to x \u2243 0.3 for F2 and x \u2243 0.6 for FL for the four(3)\nflavour case shown in the figure. The moments N = 1, 3, . . . , 9 constrain \u03b4 c2,L (x) very well at x >\n\u223c 0.1,\n\u22122\nand approximately down to x \u2248 10 .\n4000\n\n2000\n\n500\n\n(3)\nc2,ns\n(x, nf = 4)\n\n(3)\nc L,ns\n(x, nf = 4)\n\n0\n\n0\n\n-2000\n-500\n-4000\n\neven N\n\neven N\n\n-1000\n\nodd N (A, B)\n\n-6000\n\nodd N (A, B)\n-1500\n\n-8000\n-3\n10\n\n10\n\n-2\n\n10\n\n-1\n\nx\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\nx\n\n\u03bdp+\u03bd\u0304p\nFig. 1: The exact third-order coefficient functions of the even-N structure functions F2,L\nfor four massless flavours, and the\napproximate odd-moment quantities for \u03bdp \u2212 \u03bd\u0304p combination.\n\nConcerning low values of Bjorken-x one should recall that the uncertainty bands shown by the dashed\nlines in Fig. 1 do not directly indicate the range of applicability of these approximations, since the coefficient\nfunctions enter observables only via smoothening Mellin convolutions with non-perturbative initial distributions. In Fig. 2 we therefore present the convolutions of all six third-order CC coefficient functions with a\ncharacteristic reference distribution. It turns out that the approximations of the previous figure can be sufficient down to values even below x = 10\u22123 , which is amply sufficient for foreseeable applications to data. The\n(3)\n\u22122\nuncertainty of \u03b4c3 (x), on the other hand, becomes relevant already at larger values, x <\n\u223c 10 , as the lowest\ncalculated moment of this quantity, N = 2, has far less sensitivity to the behaviour at low x.\nThe three-loop corrections to the non-singlet structure functions are rather small even well below the\nx-values shown in the figure \u2013 recall our small expansion parameter as : the third-order coefficient are smaller\nby a factor 2.0 * 10\u22123 if the expansion is written in powers of \u03b1s . Their sharp rise for x \u2192 1 is understood in\nterms of soft-gluon effects which can be effectively resummed, if required, to next-to-next-to-next-to-leading\n(3)\nlogarithmic accuracy [36]. Our even-odd differences \u03b4ca (x), on the other hand, are irrelevant at x > 0.1 but\nhave a sizeable impact at smaller x in particular on the corrections for F 2 and FL . The approximate results for\n(3)\n\u03b4 ca (x) facilitate a first assessment of the perturbative stability of the even-odd differences (1). In Fig. 3 we\n\n\f2000\n\n(3)\n(ca,ns\n\u2297 f)/f\n\n1000\n\na=L\n\n0\n\na=2\n\u03bd + \u03bd exact\n\n-1000\n\n\u03bd \u2212 \u03bd approx.\n-2000\n\n10\n\n0.5\n\nnf = 4 , xf = x\n-3\n\n10\n\na=3\n\n3\n\n(1-x)\n\n-2\n\n10\n\n-1\n\n1\n\nx\n\nFig. 2: Convolution of the six third-order CC coefficient functions for F 2, 3, L in \u03bdp + \u03bd\u0304p and \u03bdp \u2212 \u03bd\u0304p DIS with a schematic but\n\ntypical non-singlet distributionf . All results have been normalized tof (x), suppressing the large but trivial variation of the absolute\nconvolutions.\n\nillustrate the known two orders for F 2 and F L for \u03b1s = 0.25 and nf = 4 massless quark flavours, employing\nthe same reference quark distribution as in Fig. 2.\nObviously our new \u03b1s3 corrections are important wherever these coefficient-function differences are\nnon-negligible. On the other hand, our results confirm that these quantities are very small, and thus relevant\nonly when a high accuracy is required. These conditions are fulfilled for the calculation of QCD corrections\nfor the so-called Paschos-Wolfenstein relation. This relation is defined in terms of a ratio of neutral-current\nand charged-current cross sections for neutrino-nucleon DIS [35],\nR\u2212 =\n\n\u03c3(\u03bd\u03bc N \u2192 \u03bd\u03bc X) \u2212 \u03c3(\u03bd\u0304\u03bc N \u2192 \u03bd\u0304\u03bc X)\n.\n\u03c3(\u03bd\u03bc N \u2192 \u03bc\u2212 X) \u2212 \u03c3(\u03bd\u0304\u03bc N \u2192 \u03bc+ X)\n\n(3)\n\nThe asymmetry R\u2212 directly measures sin2 \u03b8W if the up and down valence quarks in the target carry equal\nmomenta, and if the strange and heavy-quark sea distributions are charge symmetric. Beyond the leading\norder this asymmetry can be presented\nR 1 as an expansion in \u03b1s and inverse powers of the dominant isoscalar\n\u2212\n\u2212\n\u2212\ncombination u + d , where q = 0 dx x (q(x) \u2212 q\u0304(x)) is the second Mellin moment of the valence quark\n(3)\n\ndistributions. Using the results for differences \u03b4ca (x), a = 2, L, 3 one can present it in a numeric form,\n(\n\u0013\n\u0012\n\u2212 \u2212 d\u2212 + c\u2212 \u2212 s\u2212\n1\n1\nu\n7\n\u2212\n2\n2\n2\nR =\n\u2212 sin \u03b8W +\n\u2212 sin \u03b8W *\n1 \u2212 sin \u03b8W +\n2\nu\u2212 + d\u2212\n3\n2\n)\n\u0001\n\u0001\n\u0003\n8 \u03b1s \u0002\n+ O (u\u2212 + d\u2212 )\u22122 + O \u03b14s ,\n1 + 1.689 \u03b1s + (3.661 \u00b1 0.002) \u03b12s\n(4)\n9 \u03c0\n(3)\n\nwhere the third term in the square brackets is determined by the \u03b13s corrections \u03b4 ca (x), a = 2, L, 3. The\nperturbation series in the square brackets appears reasonably well convergent for relevant values of the strong\ncoupling constant, with the known terms reading, e.g., 1 + 0.42 + 0.23 for \u03b1s = 0.25. Thus the \u03b12s and \u03b13s\ncontributions correct the NLO estimate by 65% in this case. On the other hand, due to the small prefactor\nof this expansion, the new third-order term increases the complete curly bracket in Eq. (4) by only about\n1%, which can therefore by considered as the new uncertainty of this quantity due to the truncation of the\nperturbative expansion. Consequently previous NLO estimates of the effect of, for instance, the (presumably\n\n\f(\u03b4C2 \u2297 f ) / f\n\n0\n\n(\u03b4CL \u2297 f ) / f\n\n0\n\n-0.002\n\n-0.005\n\n-0.004\n\nLO\nNLOA, B\n\n-0.01\n\n-0.006\n\n0.5\n\nxf = x\n-0.015\n\n(1-x)\n\n3\n\n\u03b1S = 0.25, nf = 4\n-0.008\n\n10\n\n-4\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\nx\n\n10\n\n-4\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\nx\n\nFig. 3: The first two approximations, denoted by LO and NLO, of the differences (1) for F 2 and F L in charged-current DIS. The\nresults are shown for representative values of \u03b1s and nf after convolution with the reference distributionf (x) also employed in Fig. 2.\nThe dashed curves correspond to the two approximation uncertainties for the new \u03b1s3 contributions.\n\nmainly non-perturbative, see Refs. [37\u201339]) charge asymmetry of the strange sea remain practically unaffected\nby higher-order corrections to the coefficient functions.\nTo summarize, we have extended the fixed-N three-loop calculations of inclusive DIS [2\u20134] to all\ncharged-current cases not covered by the full (all-N ) computations of Refs. [7\u20139]. The region of applicability\nof these new results is restricted to Bjorken-x values above about 10\u22123 , a range amply sufficiently for any\nfixed-target or collider measurements of those charged-current structure functions in the foreseeable future.\nExcept for the longitudinal structure function FL , the present coefficient functions are part of the next-tonext-to-next-to-leading order (N3 LO) approximation of massless perturbative QCD. Analyses at this order are\npossible outside the small-x region since the corresponding four-loop splitting functions will have a very small\nimpact here, cf. Ref. [40].\n2.2 Small x resummation 21\nThe splitting functions which govern the evolution of the parton distributions (PDFs), together with the hard\ncross sections which relate those partons to hadronic physical observables, are potentially unstable at high\nenergy due to logarithmically enhanced contributions. In particular, parametrizing observables such as deepinelastic structure (DIS) functions or Drell-Yan (DY) or Higgs production cross section in hadronic collisions\nin terms of a dimensionful scale Q2 (photon virtuality or invariant mass of the final state in DIS and DY respec2\ntively) and a dimensionless ratio x (the Bjorken variable or Qs in DIS and DY respectively), when x \u2192 0 there\nare logarithmically enhanced contributions to the perturbation expansion of the form x\u22121 \u03b1nS (Q2 ) logm (1/x)\n(n \u2265 m \u2212 1). When x is sufficiently small, one must resum such terms, reordering the perturbation expansion\nin terms of leading logarithmic (LL) terms followed by next-to-leading logarithmic (NLL) terms and so on.\nThe problem can be traced to ladders of t-channel gluon exchanges at LL order, with some quark\nmixing at NLL order and beyond. The underlying framework for the resummation procedure is the BFKL\nequation [41, 42], an integral equation for the unintegrated gluon f (k2 , Q20 ) that is currently known up to full\nNLL order [43\u201345], and approximate NNLL order [46]. This has the schematic form (up to NLL):\nZ\nh\ni\n2\n2\n2\n2\n2\n2\n(5)\nN f (k , Q0 ) = N fI (Q0 ) + \u1fb1S (k ) dk \u20322 K0 (k2 , k\u2032 , Q20 ) + \u1fb1S (k2 )K1 (k2 , k\u2032 , Q20 ) f (k\u20322 ),\n\nwhere fI (Q20 ) is a non-perturbative initial condition at some initial scale Q0 , \u1fb1S = 3\u03b1S /\u03c0 and K0,1 are the\n21\n\nContributing authors: G. Altarelli, R. D. Ball, M. Ciafaloni, D. Colferai, G. P. Salam, A. Sta\u015bto, R. S. Thorne, C. D. White\n\n\fLL and NLL BFKL kernels. Different choices for the argument of the running coupling are possible, leading\nto accordingly modified K1 [47, 48].\n\nThe solution of the BFKL equation can be used to extract leading and subleading singular contributions\nto singlet DGLAP splitting functions. The BFKL equation can either be solved numerically in its form given\nby Eq. (5), or else analytically by performing a double Mellin transform with respect to x and k2 :\nZ \u221e\nZ 1\n2 \u2212\u03b3\u22121\n(k )\nf (\u03b3, N ) =\ndxxN f (x, k2 ),\n(6)\n0\n\n0\n\nwhereby the BFKL equation becomes a differential equation, with kernels \u03c70,1 (\u03b3) defined respectively as\nthe Mellin transforms of K0,1 . Furthermore, by using the kt -factorisation theorem [49], one may determine\nleading small x contributions to all orders to hard partonic cross sections for physical processes such as\nheavy quark electroproduction [49] and deep-inelastic scattering [50]. Approximate subleading results are\nalso available [51, 52].\nThese results for splitting functions and hard partonic cross sections can then be combined with fixedorder results to obtain resummed predictions for physical observables. However, it has now been known for\nsome time that the LL BFKL equation is unable to describe scattering data well, even when matched to a\nfixed order expansion. Any viable resummation procedure must then, at the very least, satisfy the following\nrequirements:\n1. Include a stable solution to the BFKL equation with running coupling up to NLL order.\n2. Match to the standard DGLAP description at moderate and high x values (where this is known to\ndescribe data well).\n3. Provide the complete set of splitting and coefficient functions for F2 and FL in a well defined factorisation scheme.\nOver the past few years, three approaches have emerged which, to some extent, aim at fulfilling these\nconditions. Here we call these the ABF [53\u201360], CCSS [48, 61\u201367] and TW [68\u201373] approaches. In the\nABF scheme all three requirements are met, and resummed splitting functions in the singlet sector have been\ndetermined. Furthermore, a complete control of the scheme dependence at the resummed level has been\nachieved, thereby allowing for a consistent determination of resummed deep-inelastic coefficient functions,\nand thus of resummed structure functions. However, the results obtained thus have not been fit to the data yet.\nIn the CCSS formalism, resummed splitting functions have also been determined. However, results are given\nin a scheme which differs from the MS scheme at the resummed level; furthermore, resummed coefficient\nfunctions and physical observables haven't been constructed yet. The TW approach, instead, has already been\ncompared to the data in a global fit. However, this approach makes a number of simplifying assumptions and\nthe ensuing resummation is thus not as complete as that which obtains in other approaches: for example, this\napproach does not include the full collinear resummation of the BFKL kernel.\nA comparison of resummed splitting functions and solution of evolution equations determined in the\nABF and CCSS approaches with nf = 0 was presented in Ref. [1]; the main features and differences of these\napproaches were also discussed. Here, we extend this comparison to the case of nf 6= 0 resummation, and also\nto the TW approach. First, we will briefly summarize the main features of each approach, and in particular we\ndisplay the matrix of splitting functions determined in the ABF and CCSS approaches. Then, we will compare\nK-factors for physical observables determined using the ABF and TW approach.\nNote that there are some difference in notations between various groups, which are retained here in\norder to simplify comparison to the original literature. In particular, the variable N in Eq. (6) will be referred\nto as \u03c9 in the CCS approach of Section 2.2.2, and the variable \u03b3 in the same equation will be referred to as M\nin the ABF approach of Section 2.2.1.\n2.2.1 The Altarelli-Ball-Forte (ABF) Approach\nIn the ABF approach [53\u201360, 74\u201377] one concentrates on the problem of obtaining an improved anomalous\ndimension (splitting function) for DIS which reduces to the ordinary perturbative result at large N (large x),\n\n\fthereby automatically satisfying renormalization group constraints, while including resummed BFKL corrections at small N (small x), determined through the renormalization-group improved (i.e. running coupling)\nversion of the BFKL kernel. The ordinary perturbative result for the singlet anomalous dimension is given by:\n\u03b3(N, \u03b1s ) = \u03b1s \u03b30 (N ) + \u03b12s \u03b31 (N ) + \u03b13s \u03b32 (N ) . . . .\n\n(7)\n\nThe BFKL corrections at small N (small x) are determined by the BFKL kernel \u03c7(M, \u03b1s ):\n\u03c7(M, \u03b1s ) = \u03b1s \u03c70 (M ) + \u03b12s \u03c71 (M ) + . . . ,\n\n(8)\n\n2\n\nwhich is the Mellin transform, with respect to t = ln kk2 , of the N \u2192 0 angular averaged BFKL kernel.\n0\n\nThe ABF construction is based on three ingredients.\n1. The duality relation between the kernels \u03c7 and \u03b3\n\u03c7(\u03b3(N, \u03b1s ), \u03b1s ) = N,\n\n(9)\n\nwhich is a consequence of the fact that at fixed coupling the solutions of the BFKL and DGLAP equations should coincide at leading twist [53, 74, 78]. By using duality, one can use the perturbative expansions of \u03b3 and \u03c7 in powers of \u03b1s to improve (resum) each other: by combining them, one obtains a\n\"double leading\" (DL) expansion which includes all leading (and subleading, at NLO) logs of x and Q2 .\nIn particular, the DL expansion automatically resums the collinear poles of \u03c7 at M = 0. This eliminates\nthe alternating sign poles +1/M, \u22121/M 2 , ..... that appear in \u03c70 , \u03c71 ,. . . , and make the perturbative expansion of \u03c7 unreliable. This result is a model independent consequence of momentum conservation\n\u03b3(1, \u03b1s ) = 0, whence, by duality:\n\u03c7(0, \u03b1s ) = 1.\n(10)\n2. The symmetry of the BFKL kernel upon gluon interchange. In Mellin space, this symmetry implies\nthat at the fixed-coupling level the kernel \u03c7 for evolution in ln kks 0 must satisfy \u03c7(M ) = \u03c7(1 \u2212 M ).\nBy exploiting this symmetry, one can use the collinear resummation of the region M \u223c 0 which was\nobtained using the double-leading expansion to also improve the BFKL kernel in the anti\u2013collinear\nM \u2243 1 region. This leads to a symmetric kernel which is an entire function for all M , and has a\nminimum at M = 12 . The symmetry is broken by the DIS choice of variables ln x1 = ln Qs2 and by the\nrunning of the coupling; however these symmetry breaking contribution can be determined exactly. This\nthen leads to a stable resummed expansion of the resummed anomalous dimension at the fixed coupling\nlevel.\n3. The running-coupling resummation of the BFKL solution. Whereas running coupling corrections to\nevolution equations are automatically included when solving the DGLAP evolution equation with resummed anomalous dimensions, the duality relation Eq. (9) itself undergoes corrections when the running coupling is included in the BFKL equation (5). Running coupling corrections can then be derived\norder by order, and turn out to be affected by singularities in Mellin M space. This implies that after\nMellin inversion\nthe associate splitting functions is enhanced as x \u2192 0: their contribution grows as\n\u0001n\n\u03b1s \u03b20 ln x1 with the perturbative order. However the series of leading enhanced contribution can be\nsummed at all orders in closed form, because it corresponds to the asymptotic expansion in powers of \u03b1s\nof the solution to the running coupling BFKL equation (5) when the kernel \u03c7 is approximated quadratically about its minimum. This exact solution can be expressed in terms of Airy functions [54, 79] when\nthe kernel is linear in \u03b1s and in terms of Bateman [56] functions for generic kernels. Because both the\nexact solution and its asymptotic expansion are known, this BFKL running coupling resummation can\nbe combined with the DGLAP anomalous dimension, already resummed at the BFKL fixed coupling\nlevel, with full control of overlap (double counting terms). Schematically, the result has the following\nform:\nrc, pert\nB\nrc\nB\nB\n\u03b3\u03a3\nN LO (\u03b1s (t), N ) = \u03b3\u03a3 N LO (\u03b1s (t), N ) + \u03b3 (\u03b1s (t), N ) \u2212 \u03b3s (\u03b1s (t), N ) \u2212 \u03b3ss (\u03b1s (t), N )\nB\n\u2212\u03b3ss,0\n(\u03b1s (t), N ) + \u03b3match (\u03b1s (t), N ) + \u03b3mom (\u03b1s (t), N ),\n\n(11)\n\n\fFig. 4: The resummed splittings functions Pqq , Pqg , Pgq and Pgg in the ABF approach, all for nf = 4 and \u03b1s = 0.2: LO DGLAP\n(dashed black), NLO DGLAP (solid black), NNLO DGLAP (solid green), LO resummed (red dashed), NLO resummed in the Q0 MS\nscheme (red) and in the MS scheme (blue).\n\nrc, pert\nwhere \u03b3\u03a3\nN LO (\u03b1s (t), N ) contains all terms which are up to NLO in the double-leading expansion of\npoint 1, symmetrized as discussed in point 2 above so that its dual \u03c7 has a minimum; \u03b3 B (\u03b1s (t), N )\nresums the series of singular running coupling corrections using the aforementioned exact BFKL soluB (\u03b1 (t), N ) \u03b3 B (\u03b1 (t), N ) are double counting\ntion in terms of a Bateman function; \u03b3sB (\u03b1s (t), N ), \u03b3ss\ns\nss,0 s\nsubtractions between the previous two contributions; \u03b3mom subtracts subleading terms which spoil exact\nmomentum conservation; \u03b3match subtracts any contribution which deviates from NLO DGLAP and at\nlarge N doesn't drop at least as N1 .\nThe anomalous dimension obtained through this procedure has a simple pole as a leading small-N (i.e.\nsmall x) singularity, like the LO DGLAP anomalous dimension. The location of the pole is to the right of the\nDGLAP pole, and it depends on the value of \u03b1s . Thanks to the softening due to running of the coupling, this\nvalue is however rather smaller than that which corresponds to the leading BFKL singularity: for example, for\n\u03b1s = 0.2, when nf = 0 the pole is at N = 0.17.\n\nThe splitting function obtained by Mellin inversion of the anomalous dimension eq. (11) turns out to\nagree at the percent level to that obtained by the CCSS group by numerical resolution of the BFKL equation\n\u22122\nfor all x <\n\u223c 10 ; for larger values of x (i.e. in the matching region) the ABF result is closer to the NLO\nDGLAP result.\nIn order to obtain a full resummation of physical observables, specifically for deep-inelastic scattering,\nthe resummation discussed so far has to be extended to the quark sector and to hard partonic coefficients. This,\non top of various technical complications, requires two main conceptual steps:\n\u2022 A factorization scheme must be defined at a resummed level. Because only one of the two eigenvectors\n\n\fFig. 5: The resummed DIS coefficient functions C2q , C2g , CLq and CLg in the ABF approach, all for nf = 4 and \u03b1s = 0.2. The\ncurves are labelled as in the previous figure.\n\nof the matrix of anomalous dimensions is affected by resummation, once a scheme is chosen, the resummation discussed above determines entirely the two-by-two matrix of splitting functions in the singlet\nsector. The only important requirement is that the relation of this small x scheme choice to standard\nlarge x schemes be known exactly, since this enables one to combine resummed results with known\nfixed order results.\n\u2022 PDFs evolved using resummed evolution equations must be combined with resummed coefficient functions. These are known, specifically for DIS [50], but are also known [80] to be affected by singularities,\nanalogous to the running coupling singularities of the resummed anomalous dimension discussed above,\nwhich likewise must be resummed to all orders [58]. This running coupling resummation of the coefficient function significantly softens the small x growth of the coefficient function and substantially\nreduces its scheme dependence [59].\nThese steps have been accomplished in Ref. [59], where resummed anomalous dimensions (see fig. 4),\ncoefficient functions (see fig.5) and structure functions (see section 2.2.4 below) have been determined. The\nscheme dependence of these results can be studied in detail: results have been produced and compared in\nboth the MS and Q0 MS schemes, and furthermore the variation of results upon variation of factorization and\nrenormalization scales has been studied.\nCalculations of resummation corrections not only of deep inelastic processes, but also of benchmark\nhadronic processes such as Drell-Yan, vector boson, heavy quark and Higgs production are now possible and\nshould be explored.\n\n\f2.2.2 The Ciafaloni-Colferai-Salam-Stasto (CCSS) Approach\nThe Ciafaloni-Colferai-Salam-Stasto (CCSS) resummation approach proposed in a series a papers [48,61\u201367]\nis based on the few general principles:\n\u2022 We impose the so-called kinematical constraint [81\u201383] onto the real gluon emission terms in the BFKL\nkernel. The effect of this constraint is to cut out the regions of the phase space for which kT\u20322 \u2265 kT2 /z\nwhere kT , kT\u2032 are the transverse momenta of the exchanged gluons and z is the fraction of the longitudinal momentum.\n\u2022 The matching with the DGLAP anomalous dimension is done up to the next-to-leading order.\n\u2022 We impose the momentum sum rule onto the resummed anomalous dimensions.\n\u2022 Running coupling is included with the appropriate choice of scale. We take the argument of the running\ncoupling to be the transverse momentum squared of the emitted gluon in the BFKL ladder in the BFKL\npart. For the part which multiplies the DGLAP terms in the eigenvalue equation we choose the scale to\n\u2032\nbe the maximal between kT2 and kT2 .\n\u2022 All the calculations are performed directly in momentum space. This in particular enables easy implementation of the running of the coupling with the choice of the arguments as described above.\nThe implementation at the leading logarithmic level in BFKL and DGLAP (and in the single gluon\nchannel case) works as follows. It is convenient to go to the Mellin space representation where we denote by\n\u03b3 and \u03c9 the Mellin variablesPconjugated to ln kT and ln 1/x respectively. The full evolution kernel can be\nKn (\u03b3, \u03c9). We take the resummed kernel at the lowest order level to be\nrepresented as a series K = n \u03b1n+1\ns\nK0 (\u03b3, \u03c9) =\n\n2CA \u03c9\n2CA \u03c9\n\u03c70 (\u03b3) + [\u03b30gg (\u03c9) \u2212\n]\u03c7c (\u03b3) .\n\u03c9\n\u03c9\n\n(12)\n\nThe terms in (12) are the following\n\u03c7\u03c90 (\u03b3) = 2\u03c8(1) \u2212 \u03c8(\u03b3) \u2212 \u03c8(1 \u2212 \u03b3 + \u03c9) ,\nis the leading logarithmic BFKL kernel eigenvalue with the kinematical constraint imposed. This is reflected\nby the fact that the singularities in the \u03b3 plane at \u03b3 = 1 are shifted by the \u03c9. This ensures the compatibility\nwith the DGLAP collinear poles, in the sense that we have only single poles in \u03b3. The function \u03c7c (\u03b3) is the\ncollinear part of the kernel\n1\n1\n,\n\u03c7\u03c9c (\u03b3) = +\n\u03b3 1\u2212\u03b3 +\u03c9\n\nwhich includes only the leading collinear poles at \u03b3 = 0 or 1. All the higher twist poles are neglected for\nthis part of the kernel. This kernel eigenvalue is multiplied by the non-singular (in \u03c9) part of the DGLAP\nanomalous dimension \u03b30gg (\u03c9) \u2212 2CA /\u03c9 where \u03b30gg (\u03c9) is the full anomalous dimension at the leading order.\nThe next-to-leading parts both in BFKL and DGLAP are included in the second term in the expansion, i.e.\nkernel K1\n(2CA )2 \u03c9\n\u03c7\u03031 (\u03b3) + \u03b3\u03031gg (\u03c9)\u03c7\u03c9c (\u03c9)\n(13)\nK1 (\u03b3, \u03c9) =\n\u03c9\nwhere \u03c7\u0303\u03c91 (\u03b3) is the NLL in x part of the BFKL kernel eigenvalue with subtractions. These subtractions are\nnecessary to avoid double counting: we need to subtract the double and triple collinear poles in \u03b3 which are\nalready included in the resummed expression (12) and which can be easily identified by expanding this expression in powers of \u03c9 and using the LO relation \u03c9 = \u1fb1s \u03c70 (\u03b3). The term \u03b3\u03031gg (\u03c9) in Eq. (13) is chosen so that one\nobtains the correct DGLAP anomalous dimension at a fixed next-to-leading logarithmic level. The formalism\ndescribed above has been proven to work successfully in the single channel case, that is for evolution of gluons\nonly. The solution was shown to be very stable with respect to the changes of the resummation scheme.\nThe quarks are included in the CCSS approach by a matrix formalism. The basic assumptions in this\nconstruction are:\n\u2022 Consistency with the collinear matrix factorization of the PDFs in the singlet evolution.\n\n\f10\n2\u03c0 k20 Gig(Y, k, k0) [k= 1.2 k0]\n\nNLx-NLO\nNLx-NLO+\nscheme B\n\ni=g\n\n1\n\ni=q\n\u03b1s = 0.15\n0.5 < x\u03bc < 2\n\n0.1\n0\n\n5\n\n10\nY = ln s/(k k0)\n\n15\n\n20\n\nFig. 6: Gluon-induced part of the Green function for the NLx-NLO and NLx-NLO+ models, compared to the results the single\nchannel approach. For the models of this paper both gluon-gluon and quark-gluon Green's function are shown. The value chosen for\nthe coupling, \u03b1s = 0.15, corresponds to k0 \u2243 20 GeV. The band indicates the spread in the result for the NLx-NLO model when\nvarying the renormalization scale in the range 0.5 < x\u03bc < 2.\n\n\u2022 Requirement that only single pole singularities in both in \u03b3 and \u03c9 are present in the kernel eigenvalues.\nThis assumption allows for the natural consistency with DGLAP and BFKL respectively. Higher order\nsingularities can be generated at higher orders only through the subleading dependencies on these two\nvariables.\n\u2022 Ability to compute all the anomalous dimensions which can be directly compared with the DGLAP\napproach. This can be done by using set of recursive equations which allow to calculate the anomalous\ndimensions order by order from the kernel eigenvalues.\n\u2022 Impose the collinear-anticollinear symmetry of the kernel matrix via the similarity transformation.\n\u2022 Incorporate NLLx BFKL and DGLAP up to NLO (and possibly NNLO).\n\nThe direct solutions to the matrix equations are the quark and gluon Green's functions. These are\npresented in Fig. 6 for the case of the gluon-gluon and quark-gluon part. The resulting gluon-gluon part is\nincreasing exponentially with the logarithm of energy ln s with an effective intercept of about \u223c 0.25. It is\nmuch suppressed with respect to the leading logarithmic order. We also note that the single channel results and\nthe matrix results for the gluon-gluon Green's function are very similar to each other. In Fig. 6 we also present\nthe quark-gluon channel which is naturally suppressed in normalization with respect to the gluon-gluon one\nby a factor of the strong coupling constant. This can be intuitively understood as the (singlet) quarks are\nradiatively generated from the gluons, and therefore this component follows the gluon density very closely.\nThe yellow bands indicate the change of the Green's functions with respect to the change of the scale.\nIn Fig. 7 we present all four splitting functions for fixed value of scale Q2 . Here, again the results\nare very close to the previous single channel approach in the case of the gluon-gluon splitting function. The\ngluon-quark channel is very close to the gluon-gluon one, with the characteristic dip of this function at about\nx \u223c 10\u22123 . The dip delays the onset of rise of the splitting function only to values of x of about 10\u22124 . The\nscale dependence growths with decreasing x but it is not larger than in the fixed NLO case. The quark-gluon\nand quark-quark splitting functions tend to have slightly larger uncertainty due to the scale change but are also\nslightly closer to the plain NLO calculation. They also tend to have a less pronounced dip structure.\n\n\f-5\n\n10\n\n10\n\n10\n\n-3\n\n10\n\nx\n-2\n\n-1\n\n10\n\n10\n\n-6\n\n10\n\n-4\n\n10\n\n10-3\n\n10-2\n\n10-1\n\n1\n0.10\n\n\u03b1s=0.2, nf=4\n0.5 < x\u03bc < 2\n\nNLx-NLO+\nNLO\n\n0.03\n\n-5\n\n1 10\n\nNLx-NLO\n\n0.04\n\nx Pqq(x)\n\n-4\n\n0.08\n0.06\n\n0.02\n\n0.04\n\n0.01\n\nx Pqg(x)\n\nx\n-6\n\n0.02\nqq\n\nqg\n\n0.00\n\n0.00\nscheme B (nf=0)\n0.40\n0.30\n\n0.10\n\n0.20\n\nx Pgg(x)\n\nx Pgq(x)\n\n0.15\n\n0.05\n0.10\ngq\n0.00\n10-6\n\ngg\n10-5\n\n10-4\n\n10-3\nx\n\n10-2\n\n10-1\n\n1 10-6\n\n10-5\n\n10-4\n\n10-3\nx\n\n10-2\n\n10-1\n\n0.00\n1\n\nFig. 7: The matrix of NLx-NLO (and NLx-NLO+) splitting functions together with their scale uncertainty and the NLO splitting\nfunctions for comparison. In the gg channel, we also show the old scheme B result (nf = 0, no NLO contributions, 1-loop coupling)\n. The band corresponds to the span of results (NLx-NLO) obtained if one chooses x\u03bc = 0.5 and x\u03bc = 2.0.\n\n2.2.3 The Thorne-White (TW) Approach\nSubstituting the LO running coupling \u1fb1S (k2 ) into equation (5) and performing a double Mellin transform\naccording to equation (6), the BFKL equation 5, as mentioned in Section 2.2, becomes a differential equation:\nd2 f (\u03b3, N )\nd2 fI (\u03b3, Q20 )\n1 d(\u03c70 (\u03b3)f (\u03b3, N ))\n\u03c0\n+ 2 \u03c71 (\u03b3)f (\u03b3, N ),\n=\n\u2212\n2\n2\nd\u03b3\nd\u03b3\nd\u03b3\n3\u03b2\u03040 N\n\u03b2\u03040 N\n\n(14)\n\nwhere \u03c70,1 (\u03b3) are the Mellin transforms of K0,1 . The solution for f (N, \u03b3) of Eq. (14) has the following\nform [62, 84]:\n\u0012\n\u0012\n\u0013Z \u221e\n\u0013\nX1 (\u03b3\u0303)\nX1 (\u03b3)\nf (N, \u03b3) = exp \u2212\nA(\u03b3\u0303) exp\nd\u03b3\u0303.\n(15)\n\u03b2\u03040 N\n\u03b2\u03040 N\n\u03b3\nUp to power-suppressed corrections, one may shift the lower limit of the integral \u03b3 \u2192 0, so that the gluon\ndistribution factorises into the product of a perturbative and a non-perturbative piece. The nonperturbative\npiece depends on the bare input gluon distribution and an in principle calculable hard contribution. However,\nthis latter part is rendered ambiguous by diffusion into the infrared, and in this approach is contaminated by infrared renormalon-type contributions. The perturbative piece is safe from this and is sensitive to diffusion into\nthe ultraviolet region of weaker coupling. Substituting equation (15) into (14), one finds that the perturbative\npiece is given (after transforming back to momentum space):\n1\n(N, t)\nGE\n\n1\n=\n2\u03c0\u0131\n\nZ\n\n1/2+\u0131\u221e\n\n1/2\u2212\u0131\u221e\n\n\u0002\n\u0003\nf \u03b20\nexp \u03b3t \u2212 X1 (\u03b3, N )/(\u03b2\u03040 N ) d\u03b3,\n\u03b3\n\n(16)\n\n\fxg(x)\n\n2\n80\n\n1\n\n60\n\n0\n\nNLL\nNLO\n\n40\n\n-1\n-2\n\nQ2=100GeV2\n\n20\n\nQ2=1GeV2\n\n-3 -5\n-4\n-3\n-2\n-1\n10 10 10 10 10\n1\nx\n\n0\n10\n\n-5\n\n10\n\n-4\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n1\nx\n\nFig. 8: Gluons arising from a global fit to scattering data including NLL small x resummations in the DIS(\u03c7) factorisation scheme\n(solid). Also shown is the result from an NLO DGLAP fit in the same scheme.\n\nwhere:\nX1 (\u03b3, N ) =\n\nZ\n\n\u03b3\n1\n2\n\n\u0014\n\n\u0015\n\u03c71 (\u03b3\u0303)\nd\u03b3\u0303.\n\u03c70 (\u03b3\u0303) + N\n\u03c70 (\u03b3\u0303)\n\n(17)\n\nStructure functions Fi also factorize, and the perturbative factors have a similar form to Eq. (16), but involve an\nadditional impact factor hi (\u03b3, N ) in the integrand according to the kt -factorisation theorem [50]. Crucially,\ncoefficient functions and anomalous dimensions involve ratios of the above quantities, such that the nonperturbative factor cancels. Thus, once all the impact factors are known, the complete set of coefficient and\nsplitting functions can be disentangled. Finally they can be combined with the standard NLO DGLAP results\n(which are known to describe data well at higher x values) using the simple prescription:\ni\nh\n(18)\nP tot. = P N LL + P N LO \u2212 P N LL(0) + P N LL(1) ,\n\nwhere P is a splitting or coefficient function, and P N LL(i) the O(\u03b1is ) contribution to the resummed result\nwhich is subtracted to avoid double-counting. It should be noted that the method of subtraction of the resummed contribution in the matching is different to that for the ABF approach outlined after Eq. (11). For\nexample, at NLO in the resummation the BFKL equation provides both the \u03b1S /N part of Pgg and the part at\nO(\u03b1S ) constant as N \u2192 \u221e. Hence we choose to keep all terms constant as N \u2192 \u221e generated by Eq. (16),\nwith similar considerations for other splitting functions and coefficient functions, though these can contain\nterms \u221d N . Hence, we include terms which will have some influence out to much higher x than in the ABF\napproach.\nIn the TW manner of counting orders LL is defined as the first order at which contributions appear,\nso while for the gluon splitting function this is for \u1fb1nS lnm (1/x) for m = n \u2212 1 for impact factors this is\nfor m = n \u2212 2. A potential problem therefore arises in that the NLL impact factors are not known exactly.\nHowever, the LL impact factors with conservation of energy of the gluon imposed are known in cases of both\nmassless and massive quarks [51, 52], and are known to provide a very good approximation to the full O(\u03b12S )\nand O(\u03b13S ) quark-gluon splitting functions and coefficient functions [85], implying that they must contain\nmuch of the important higher-order information. These can then be used to calculate NLL coefficient and\n\n\f0.3\n\nPqg\n\n0.1\n\nP+\n\n0.08\n\n0.2\n0.06\n0.04\n0.1\n0.02\n0\n10\n\n-6\n\n10\n\n-5\n\n10\n\n-4\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n0\n1\n\nx\n\n10\n\n-6\n\n10\n\n-5\n\n10\n\n-4\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n1\n\nx\n\nFig. 9: The resummed splitting functions (solid) P+ \u2248 Pgg and Pqg in the TW approach, both for nf = 4 and \u03b1S = 0.16, compared\n\nto the corresponding NLO forms (dotted).\n\nsplitting functions within a particular factorisation scheme. One must also specify a general mass variable\nnumber scheme for consistent implementation of heavy quark mass effects. Such a scheme (called the DIS(\u03c7)\nscheme) has been given in [72, 73] up to NLL order in the high energy expansion, and NLO order in the fixed\norder expansion.\nThe form of the resummed splitting functions shown in fig. 9 are qualitatively consistent with those\nfrom the ABF approach, fig. 4, and CCSS approach fig. 7 (note however that in these plots the value of \u03b1s\nis a little larger, and the scheme is different). This is despite the fact that the approach does not include the\nexplicit collinear resummation of the BFKL kernel adopted in the other two approaches. It was maintained in\n[70, 71] that the diffusion into the ultraviolet, effectively making the coupling weaker, hastens the perturbative\nconvergence for splitting functions, and the kernel near \u03b3 = 0, making this additional resummation less\nnecessary. There is no particular obstruction to including this resummation in the approach, it is simply\ncumbersome. Indeed, in Ref. [71] the effect was checked, and modifications found to be no greater than\ngeneric NNLO corrections to the resummation, so it was omitted. (Note that any process where there are two\nhard scales, sensitive to \u03b3 \u2248 0.5, or attempted calculation of the hard input for the gluon distribution, sensitive\nto \u03b3 = 1, would find this resummation essential.) The main feature of the resummed splitting functions is\na significant dip below the NLO DGLAP results, followed by an eventual rise at very low x \u2243 10\u22125 . This\nbehaviour drives a qualitative change in the gluon distribution, when implemented in a fit to data.\nThe combined NLO+NLL splitting and coefficient functions (in the TW approach) have been implemented in a global fit to DIS and related data in the DIS(\u03c7) scheme, thus including small x resummations in\nboth the massless and massive quark sectors [73]. The overall fit quality was better than a standard NLO fit\nin the same factorisation scheme, and a similar NLO fit in the more conventional MS factorisation scheme.\nThe principal reason for this is the dip in the resummed evolution kernels, which allows the gluon distribution\nto increase at both high and low values of x. This reduces a tension that exists between the high x jet data\n\n\f1\n\nFL\n\nNLL\nNNLO (MSTW)\n\n0.75\n\n0.5\n\n0.25\n\n0\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\n70\n\n80\n\n90\n100\nQ2/GeV2\n\nFig. 10: Recent H1 data on the longitudinal structure function FL , together with the NLL resummed prediction from the TW approach,\nand a recent NNLO result from the MSTW group.\n\nof [86, 87] and the low x HERA data [18, 88\u201391]. The gluon distributions arising from the NLL and NLO\nfits are shown in figure 8, for the starting scale Q2 = 1GeV2 and also for a higher value of Q2 . One sees\nthat whilst the NLO gluon wants to be negative at low x and Q2 , the resummed gluon is positive definite and\nindeed growing slightly as x \u2192 0. The gluons agree well for higher x values (where the DGLAP description\nis expected to dominate), but deviate for x \u2264 10\u22122 . This can therefore be thought of as the value of x below\nwhich resummation starts to become relevant.\nThe qualitatively different gluon from the resummed fit (together with the decreased evolution kernels\nw.r.t. the fixed order description) has a number of phenomenological implications:\n1. The longitudinal structure function FL is sensible at small x and Q2 values, where the standard DGLAP\ndescription shows a marked instability [92].\n2. As a result of the predicted growth of FL at small x the resummed result for the DIS reduced crosssection shows a turnover at high inelasticity y, in agreement with the HERA data. This behaviour is not\ncorrectly predicted by some fixed order fits.\n3. The heavy flavour contribution (from charm and bottom) to F2 is reduced at higher Q2 in the resummed\napproach, due mainly to the decreased evolution, as already noted in a full analysis in the fixed-order\nexpansion at NNLO [93]. Nevertheless, it remains a significant fraction of the total structure function at\nsmall x.\nOther resummation approaches should see similar results when confronted with data, given the qualitative (and indeed quantitative) similarities between the splitting functions. It is the decreased evolution with\nrespect to the DGLAP description that drives the qualitative change in the gluon distribution. This is then the\nsource of any quantitative improvement in the description of data, and also the enhanced description of the\nlongitudinal structure function and reduced cross-section.\nThe resummed prediction for FL is shown alongside the recent H1 data [94] in figure 10, and compared\nwith an up-to-date NNLO fixed order result [95]. One sees that the data cannot yet tell apart the predictions,\nbut that they are starting to diverge at low x and Q2 , such that data in this range may indeed be sensitive to the\ndifferences between resummed and fixed order approaches.\n\n\f1.1\n\nK2\n\n1.1\n\n1.05\n\nK2\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n\n0.9\n\nQ = 4 GeV\nQ = 10 GeV\nQ = 100 GeV\nQ = 1000 GeV\n\n0.85\n\n0.8\n1e-06\n\n1e-05\n\n0.0001\n\n0.001\n\nx\n\n0.01\n\n0.1\n\n0.8\n1e-06\n\n1\n\n1e-05\n\n0.0001\n\n0.001\n\nx\n\n0.01\n\n0.1\n\n1\n\n1.1\nx = 0.01\nx = 0.001\nx = 0.0001\nx = 0.00001\nx = 0.000001\n\n1.05\n\nK2\n\n1\n\n0.95\n\n0.95\n\n0.9\n\n0.9\n\n0.85\n\n0.85\n\n1\n\n10\n\n100\n\nx = 0.01\nx = 0.001\nx = 0.0001\nx = 0.00001\nx = 0.000001\n\n1.05\n\n1\n\n0.8\n\nQ = 4 GeV\nQ = 10 GeV\nQ = 100 GeV\nQ = 1000 GeV\n\n0.85\n\n1.1\n\nK2\n\n1.05\n\n1000\n\n0.8\n\n1\n\nQ / GeV\n\n10\n\n100\n\n1000\n\nQ / GeV\n\nFig. 11: The ratio F2NLL /F2NLO in the ABF approach (left) and the TW approach (right), using toy PDFs, given in eq. 20, calculated\nas function of x at fixed for Q2 (upper ), and as a function of Q2 at fixed x (lower).\n\n2.2.4 Resummed structure functions: comparison of the ABF and TW approaches\nIn this section, we present an application of the ABF and TW approaches to the resummed determination\nof the F2 and FL deep-inelastic structure functions. The corresponding exercise for the CCSS approach has\nnot yet been finalised. A direct comparison of the two approaches is complicated by issues of factorisation\nscheme dependence: whereas in the ABF approach results may be obtained in any scheme, and in particular\nthe MS and closely related Q0 -MS scheme, in the TW formalism splitting functions and coefficient functions\nbeyond NLO in \u03b1S are resummed in the Q0 -DIS scheme [66, 96], which coincides with the standard DIS\nscheme at large x but differs from it at the resummed level; the scheme change needed in order to obtain the\ncoefficient functions from the DIS-scheme ones is performed exactly up to NLO and approximately beyond\nit. Thus, without a more precise definition of the relation of this scheme to MS, one cannot compare splitting\nand coefficient functions, which are factorisation scheme dependent.\nA useful compromise is to present the respective results for the ratio of structure function predictions:\nKi =\n\nFiN LL (x, Q2 )\n,\nFiN LO (x, Q2 )\n\n(19)\n\nwhere i \u2208 2, L, and the Fi are calculated by convoluting the relevant coefficients with PDFs obtained by\nperturbative evolution of a common set of of partons, defined at a starting scale of Q20 = 4GeV2 . The number\nof flavors is fixed to three, to avoid ambiguities due to heavy quark effects. The initial PDFs are assumed to\nbe fixed (i.e., the same at the unresummed and unresummed level) in the DIS factorization scheme at the scale\nQ0 . Of course, in a realistic situation the data are fixed and the PDFs are determined by a fit to the data: hence\nthey are not the same at the resummed and unresummed level (compare Fig. 8 above). However, in the DIS\n\n\fQ = 4 GeV\nQ = 10 GeV\nQ = 100 GeV\nQ = 1000 GeV\n\n1.15\n1.1\n\n1.15\n1.1\n1.05\n\n1.05\n\nKL\n\nKL\n\n1\n0.95\n\n0.95\n\n0.9\n\n0.9\n\n0.85\n\n0.85\n\n0.8\n1e-06\n\n1e-05\n\n0.0001\n\n0.001\n\nx\n\n0.01\n\n1.3\n\n0.1\n\n1\n\n0.9\n\n0.9\n\n100\n\n0.001\n\nx\n\n0.01\n\n1000\n\n0.1\n\n1\n\nx = 0.01\nx = 0.001\nx = 0.0001\nx = 0.00001\nx = 0.000001\n\n1.1\n\n1\n\n10\n\n0.0001\n\n1.2\n\nKL\n\n1\n\n1e-05\n\n1.3\n\n1.1\n\n0.8\n\nQ = 4 GeV\nQ = 10 GeV\nQ = 100 GeV\nQ = 1000 GeV\n\n0.8\n1e-06\n\n1\n\nx = 0.01\nx = 0.001\nx = 0.0001\nx = 0.00001\nx = 0.000001\n\n1.2\n\nKL\n\n1\n\n0.8\n\n1\n\nQ / GeV\n\n10\n\n100\n\n1000\n\nQ / GeV\n\nFig. 12: The ratio FLNLL /FLNLO in the ABF approach (left) and the TW approach (right), using toy PDFs, given in eq. 20, calculated\nas function of x at fixed for Q2 (upper ), and as a function of Q2 at fixed x (lower).\n\nfactorization scheme the structure function F2 is simply proportional to the quark distribution, hence by fixing\nthe PDFs in this scheme one ensures that F2 is fixed at the starting scale.\nThis starting PDFs are constructed as follows: the quark and gluon distributions are chosen to have the\nrepresentative form also used in Ref. [59]\nxg(x) = ks xS(x) = kg x\u22120.18 (1 \u2212 x)5 ;\n\nxqv = kq x0.5 (1 \u2212 x)4 ,\n\n(20)\n\nin the MS scheme, where g(x) is the gluon, S(x) the sea quark distribution, and xqv (x) denotes a valence\nquark distribution. We choose ks = 3, and then all other parameters are fixed by momentum and number sum\nrules. Note that the gluon is the same as that used in the previous comparison of Ref. [1]. The PDFs eq. (20)\nare then transformed to the DIS factorization scheme [97] using the NLO (unresummed) scheme change at\nthe scale Q0 . The result is then used as a fixed boundary condition for all (unresummed and resummed, ABF\nand TW) calculations. In the TW approach, the DIS scheme for unresummed quantities and Q0 DIS scheme\nas discussed above is then used throughout. In the ABF approach, the fixed DIS-scheme boundary condition\nis transformed to the Q0 MS scheme [59, 98] (which at the unresummed level coincides with standard MS)\nby using the unresummed or resummed scheme change function as appropriate, and then all calculations are\nperformed in Q0 MS. One might hope that most of the residual scheme dependence cancels upon taking\nthe ratio of the NLL and NLO results, at least for schemes that are well defined and without unphysical\nsingularities.\nThe results for K2 and KL are shown in figures 11 for F2 in the ABF and TW procedures respectively\nand similarly in figures 12 for FL . One sees that for x sufficiently small, and for Q not too large, the resummed\nF2 is consistently lower than its fixed order counterpart in both approaches, due to the decreased evolution of\nthe gluon, and also (in the MS scheme) due to the fact that resummed coefficient functions are much larger\n\n\fthan the NLO ones at small x and low Q2 . Similarly the resummed FL is larger than the fixed order at low Q\nand small enough x, but falls rapidly as Q increases. However despite these superficial similarities, the two\napproaches differ quantitatively in several respects:\n\u22122\n\u2022 the ABF resummed F2 matches well to the NLO for x >\n\u223c 10 at all scales, while the TW F2 shows a\nrise around x \u2243 10\u22122 , which is largest at low Q. This may be due to the significant differences between\nresummed and NLO splitting functions at very high x in fig. 9. A similar mismatch may be seen at\nx \u223c 0.1 in the FL K-factor.\n\u2022 at large scales the ABF resummation stabilises, due to the running of the coupling, so the K-factors\nbecomes rather flat: they grow only logarithmically in ln Q. By contrast the TW F2 K-factor still shows\na marked Q2 dependence. This may be related to the fact that the TW resummation does not resum\nthe collinear singularities in the BFKL kernel, and to the TW choice (see Sect. 2.2.3) not to include\nsubtraction of terms induced by the resummation which do not drop at large x. This choice induces a\nchange in the PDFs at higher x in the TW approach, which results in effects which persist to higher Q2\nat smaller x.\n\u2022 at the initial scale Q0 the TW resummed FL grows much more strongly as x decreases than the ABF\nresummed FL . This is likely to be due to the different treatment of the coefficient functions: in this\nrespect, the fully consistent treatment of the factorization scheme, the effect of collinear resummation,\nand the different definitions of what is called resummed NLO used by the two groups all play a part.\n2.2.5 Conclusion\nThe problem of understanding the small x evolution of structure functions in the domain of x and Q2 values\nof relevance for HERA and LHC physics has by now reached a status where all relevant physical ingredients\nhave been identified, even though not all groups have quite reached the stage at which the formalism can be\ntransformed into a practical tool for a direct connection with the data.\nIn this report we summarised the status of the three independent approaches to this problem by ABF,\nCCSS and TW, we discussed the differences in the adopted procedures and finally we gave some recent results.\nThe most complete formalisms are those by ABF and CCSS while the TW approach is less comprehensive\nbut simpler to handle, and thus has been used in fit to data. We recall that, at the level of splitting functions\nthe ABF and CCSS have been compared in ref. [1] and found to be in very good agreement. The singlet\nsplitting function obtained by TW was also compared with ABF and CCSS in ref. [73] and also found to be in\nreasonable agreement, at least at small x.\nHere we have shown the results of an application to the structure functions F2 and FL of the ABF and\nTW methods. The same input parton densities at the starting scale Q0 were adopted by these two groups\nand the K-factors for resummed versus fixed NLO perturbative structure functions were calculated using the\nrespective methods. The results obtained are in reasonable qualitative agreement for F2 , less so for FL . Discrepancies may in part be due to the choice of factorization scheme, but our study suggests that the following\nare also likely to make a quantitative difference: whether or not a resummation of collinear singularities in\nthe BFKL kernel is performed, whether contributions from the resummation which persist at large x are subtracted and whether the factorization scheme is consistently defined in the same way at resummed and NLO\nlevels.\n2.3 Parton saturation and geometric scaling22\n2.3.1 Introduction23\nThe degrees of freedom involved in hadronic collisions at sufficiently high energy are partons, whose density\ngrows as the energy increases (i.e., when x, their momentum fraction, decreases). This growth of the number\nof gluons in the hadronic wave functions is a phenomenon which has been well established at HERA. One\nexpects however that it should eventually \"saturate\" when non linear QCD effects start to play a role.\n22\n23\n\nContributing authors: G. Beuf, F. Caola, F. Gelis, L. Motyka, C. Royon, D. \u0160\u00e1lek, A. M. Sta\u015bto\nContributing authors: F. Gelis, A. M. Sta\u015bto\n\n\fAn important feature of partonic interactions is that they involve only partons with comparable rapidities. Consider the interaction between a hadron and some external probe (e.g. a virtual photon in Deep\nInelastic Scattering) and consider what happens when one boosts the hadron, increasing its rapidity in successive steps. In the first step, the valence constituents become Lorentz contracted in the longitudinal direction\nwhile the time scale of their internal motions is Lorentz dilated. In addition, the boost reveals new vacuum\nfluctuations coupled to the boosted valence partons. Such fluctuations are not Lorentz contracted in the longitudinal direction, and represent the dynamical degrees of freedom; they are the partons that can interact with\nthe probe. Making an additional step in rapidity would freeze these fluctuations, while making them Lorentz\ncontracted as well. But the additional boost also produces new quantum fluctuations, which become the new\ndynamical variables. This argument can be repeated, and one arrives at the picture of a high-energy projectile\ncontaining a large number of frozen, Lorentz contracted partons (the valence partons, plus all the quantum\nfluctuations produced in the previous boosts), and partons which have a small rapidity, are not Lorentz contracted and can interact with the probe. This space-time description was developed before the advent of QCD\n(see for instance [99]; in Bjorken's lectures [100], one can actually foresee the modern interpretation of parton\nevolution as a renormalization group evolution).\n\n2\n\nxg(x,Q )\n\nH1+ZEUS\n20\n\n2\n\n2\n\nQ =20 GeV\n\nH1 NLO-QCD Fit 2000\nxg=a*xb*(1-x)c*(1+d\u221ax+ex)\nFFN heavy-quark scheme\n\n17.5\n\ntotal uncert.\nexp. uncert.\n\nQ2=200 GeV2\n\n15\n\nZEUS NLO-QCD Fit\n(Prel.) 2001\n\n12.5\n\nb\n\nc\n\nxg=a*x *(1-x)\n\nRT-VFN heavy-quark scheme\n\n10\n\nexp. uncert.\n\n7.5\n5\n\nQ2=5 GeV2\n\n2.5\n0 -4\n10\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\nX\n\nThis space-time picture, which was deduced from rather\ngeneral considerations, can now be understood in terms of\nQCD. In fact, shortly after QCD was established as the theory of\nstrong interaction, quantitative equations were established, describing the phenomenon outlined above [42, 101\u2013105]. In particular, the equation derived by Balitsky, Fadin, Kuraev and Lipatov [42,101] describes the growth of the non-integrated gluon\ndistribution in a hadron as it is boosted towards higher rapidities. Experimentally, an important increase of the number of\ngluons at small x has indeed been observed in the DIS experiments performed at HERA (see Fig. 13), down to x \u223c 10\u22124 .\nSuch a growth raises a problem: if it were to continue to arbitrarily small x, it would induce an increase of hadronic crosssections as a power of the center of mass energy, in violation of\nknown unitarity bounds.\n\nHowever, as noticed by Gribov, Levin and Ryskin in\n[106], the BFKL equation includes only branching processes\nsured at HERA.\nthat increase the number of gluons (g \u2192 gg for instance), but\nnot the recombination processes that could reduce the number of gluons (like gg \u2192 g). While it may be legitimate to neglect the recombination process when the gluon density is small, this cannot remain so at arbitrarily\nhigh density: a saturation mechanism of some kind must set in. Treating the partons as ordinary particles, one\ncan get a crude estimate of the onset of saturation, which occurs at:\nFig. 13: The gluon structure function in a proton mea-\n\nQ2 = Q2s ,\n\nwith Q2s \u223c \u03b1s (Q2s )\n\nxG(x, Q2s )\n.\n\u03c0R2\n\n(21)\n\nThe momentum scale that characterizes this new regime, Qs , is called the saturation momentum [107]. Partons\nwith transverse momentum Q > Qs are in a dilute regime; those with Q < Qs are in the saturated regime.\nThe saturation momentum increases as the gluon density increases. This comes from an increase of the gluon\nstructure function as x decreases. The increase of the density may also come from the coherent contributions\nof several nucleons in a nucleus. In large nuclei, one expects Q2s \u221d A1/3 , where A is the number of nucleons\nin the nucleus.\nNote that at saturation, naive perturbation theory breaks down, even though \u03b1s (Qs ) may be small if\nQs is large: the saturation regime is a regime of weak coupling, but large density. At saturation, the gluon\noccupation number is proportional to 1/\u03b1s . In such conditions of large numbers of quanta, classical field\napproximations become relevant to describe the nuclear wave-functions.\nOnce one enters the saturated regime, the evolution of the parton distributions can no longer be described\nby a linear equation such as the BFKL equation. The color glass condensate formalism (for a review, see\n\n\f[108]), which relies on the separation of the degrees of freedom in a high-energy hadron into frozen partons and\ndynamical fields, as discussed above, provides the non linear equations that allow us to follow the evolution\nof the partonic systems form the dilute regime to the dense, saturated, regime. For instance, the correlator\ntr U \u2020 (x\u22a5 )U (y \u22a5 ) of two Wilson lines \u2013which enters in the discussion of DIS\u2013 evolves according to the\nBalitsky-Kovchegov [109, 110] equation:\nZ\n\u2202tr U \u2020 (x\u22a5 )U (y \u22a5 ) x\n(x\u22a5 \u2212 y \u22a5 )2\n\u03b1s\n=\u2212 2\n\u2202 ln(1/x)\n2\u03c0 z\u22a5 (x\u22a5 \u2212 z \u22a5 )2 (y \u22a5 \u2212 z \u22a5 )2\nh\ni\n\u00d7 Nc tr U \u2020 (x\u22a5 )U (y \u22a5 ) x \u2212 tr U \u2020 (x\u22a5 )U (z \u22a5 ) x tr U \u2020 (z \u22a5 )U (y \u22a5 ) x .\n\n(22)\n\n(This equation reduces to the BFKL equation in the low density limit.)\n\nThe geometric scaling phenomenon was first introduced in the context of the dipole picture of the deep\ninelastic electron-proton scattering [111]. The process of the scattering of the virtual photon on a proton at\nvery small values of x can be conveniently formulated in the dipole model. In this picture the photon fluctuates\ninto the quark-antiquark pair (dipole) and subsequently interacts with the target. In the small x regimes these\ntwo processes factorize and they can be encoded into the dipole formula for the total \u03b3 \u2217 p cross section\nZ\nZ\n\u03c3T,L (x, Q2 ) =\nd2 r dz|\u03a8T,L (r, z, Q2 )|2 \u03c3\u0302(x, r)\n(23)\nwhere \u03a8T,L is the wave function for the photon and \u03c3\u0302 is the dipole cross section. r is the dipole size and z is\nthe light-cone fraction of the longitudinal momentum carried by the quark (or antiquark). The photon wave\nfunctions \u03a8 are known, the dipole cross section can be expressed in terms of the correlator of Wilson lines\nwhose evolution is driven by Eq. (22) :\nZ\nD\nr E\nr\n2\n(24)\nd2 X tr 1 \u2212 U (X + )U \u2020 (X \u2212 ) .\n\u03c3\u0302(x, r) =\nNc\n2\n2\nAlternatively, it can be modeled or extracted from the data. In the GBW model it was assumed that the dipole\ncross section has a form\n\u0002\n\u0003\n\u03c3\u0302 = \u03c30 1 \u2212 exp(\u2212r 2 /R0 (x)2 )\n(25)\n\nwhere R0 (x) = (x/x0 )\u2212\u03bb is a saturation radius (its inverse is usually called the saturation scale Qs (x)) and\n\u03c30 a normalisation constant. One of the key properties of the model was the dependence on the dipole size\nand the Bjorken x through only one combined variable r 2 Q2s (x). This fact, combined with the property of the\ndipole formula, allows to reformulate the total cross section as a function of Q2 /Q2s (x) only. This feature is\nknown as the geometric scaling of the total \u03b3 \u2217 p cross section. Initially postulated as a property of the GBW\nmodel, it was then shown that the experimental data do indeed exhibit the aforementioned regularity in a rather\nwide range of Q2 and for small values of Bjorken x.\nAlthough it is a postulate in the GBW model, this property can be derived from the small-x behavior\nof the solutions of Eq. (22) [112] : for a wide class of initial conditions, the BK equation drives its solution\ntowards a function that obeys this scaling. Note also that the saturation scale, introduced by hand in the GBW\nmodel, is dynamically generated by the non linear evolution described by Eq. (22). This suggested that the\nregularity seen in the data could be explained by the scaling property of the solutions to the nonlinear equations\nin the saturated regime - and thus may provide some indirect evidence for gluon saturation.\nNevertheless, several important questions remained. One of them, is the problem of the compatibility\nof the DGLAP evolution with the property of the geometric scaling. It is known from the global fits that the\nstandard DGLAP evolution works quite well for the description of the of the deep inelastic data even in the\nvery low x and Q2 regime. That suggests that the saturation should be confined to the very tight kinematic\nregime, and it is therefore questionable whether the observed regularity could be attributed to the saturation at\nall. In the present contribution we discuss several approaches to this problem.\n\n\f1\n\nFixed Coupling\n\n\u03bb = 0.321\nall data\n\nnormalised\nQF\n\n\u03c3\n\nFixed Coupling\n\nDVCS\n\n1\n\n0.8\n\n10-1\n\n0.6\n\n0.4\n10-2\n0.2\n\nQ2 > 1 GeV\n2\n\nQ < 1 GeV\n-4\n\n-2\n\n0\n\n2\n\n4\n\n6\n\n8\n\n0\n0\n\n-\u03c4\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\u03bb\n\nFig. 14: F2 data: Scaling curve \u03c3 = \u03c3(\u03c4 ) for \"Fixed Cou-\n\nFig. 15: DVCS data: Quality factor normalised to 1 plotted\n\npling\". A Q2 > 1 GeV2 cut was applied to the data.\n\nagainst the parameter \u03bb. Star denotes the fit result for F2\ndata.\n\n2.3.2 Phenomenology24\nIn order to compare the quality of different scaling laws, it is useful to use a quantity called quality factor\n(QF). It is also used to find the best parameters for a given scaling. In the following, this method is used to\ncompare the scaling results for the proton structure function F2 and F2c , the deeply virtual Compton scattering,\nthe diffractive structure function, and the vector meson cross section data measured at HERA.\nQuality Factor Given a set of data points (Q2 , x, \u03c3 = \u03c3(Q2 , x)) and a parametric scaling variable \u03c4 =\n\u03c4 (Q2 , Y, \u03bb) (with Y = ln 1/x) we want to know whether the cross-section can be parametrised as a function\nof the variable \u03c4 only. Since the function of \u03c4 that describes the data is not known, the QF has to be defined\nindependently of the form of that function.\nFor a set of points (ui , vi ), where ui 's are ordered and normalised between 0 and 1, we introduce QF\nas follows [113]\n\u0015\u22121\n\u0014X\n(vi \u2212 vi\u22121 )2\n,\n(26)\nQF (\u03bb) =\n(ui \u2212 ui\u22121 )2 + \u01eb2\ni\n\nwhere \u01eb is a small constant that prevents the sum from being infinite in case of two points have the same value\nof u. According to this definition, the contribution to the sum in (26) is large when two successive points are\nclose in u and far in v. Therefore, a set of points lying close to a unique curve is expected to have larger QF\n(smaller sum in (26)) compared to a situation where the points are more scattered.\nSince the cross-section in data differs by orders of magnitude and \u03c4 is more or less linear in log(Q2 ),\nwe decided to take ui = \u03c4i (\u03bb) and vi = log(\u03c3i ). This ensures that low Q2 data points contribute to the QF\nwith a similar weight as higher Q2 data points.\nFits to F2 and DVCS Data We choose to consider all available data from H1, ZEUS, NMC and E665\nexperiments [18, 89\u201391, 114\u2013117] with Q2 in the range [1; 150] GeV2 and x < 0.0125 . We exclude the data\nwith x > 10\u22122 since they are dominated by the valence quark densities, and the formalism of saturation does\nnot apply in this kinematical region. In the same way, the upper Q2 cut is introduced while the lower Q2 cut\nensures that we stay away from the soft QCD domain. We will show in the following that the data points\nwith Q2 < 1 GeV2 spoil the fit stability. Two kinds of fits to the scaling laws are performed, either in the\n24\n\nContributing authors: C. Royon, D. \u0160\u00e1lek\nThe data in the last ZEUS paper include contributions for FL and xF3 but those can be neglected within the kinematical domain\nwe consider.\n25\n\n\fnormalised\nQF\n\n3 < Q2 < 150\ncharm data\nF2 data\n\n1\n\nFixed Coupling\n\u03c3\n\nFixed Coupling\nQF = QF ( \u03bb )\n\n10-1\n\n\u03bb = 0.33\nMRST 2004 NNLO\n\n0.8\n\n0.6\n\n10-2\n\n0.4\n\n0.2\n-3\n\n10\n0\n0\n\n0.2 0.4 0.6 0.8\n\n1\n\n1.2 1.4 1.6 1.8\n\n-3\n\u03bb\n\nFig. 16: F2c data: Comparison of the \u03bb parameter for F2\nand\n\nF2c\n\n2\n\n2\n\ndata for Q > 3 GeV .\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n-\u03c4\n\nFig. 17: F2c parametrisation: Scaling curve \u03c3 = \u03c3(\u03c4 ) for\nfixed coupling using the MRST 2004 NNLO parametrisation\nfor \u03bb = 0.33 as obtained in the fit to experimental data. No\nscaling is observed for Q2 > 3 GeV2 .\n\nfull mentioned Q2 range, or in a tighter Q2 range [3; 150] GeV2 to ensure that we are in the domain where\nperturbative QCD applies.\nFigure 14 shows the scaling plot for \"Fixed Coupling\" in the Q2 range [1; 150] GeV2 , which shows that\nthe lowest Q2 points in grey have a tendency to lead to worse scaling. The QF values are similar for the \"Fixed\nCoupling\", \"Running Coupling I\", and \"Running Coupling IIbis\" - with a tendency to be slightly better for\n\"Running Coupling IIbis\" - and worse for diffusive scaling [118].\nThe amount of the DVCS data [119, 120] measured by H1 and ZEUS is smaller (34 points for H1\nand ZEUS requiring x \u2264 0.01 as for F2 data), therefore the precision on the \u03bb parameter is weaker. The\nkinematic coverage of the DVCS data covers smaller region in x and Q2 than F2 : 4 < Q2 < 25 GeV2 and\n5 * 10\u22124 < x < 5 * 10\u22123 . The DVCS data lead to similar \u03bb values as in the F2 data (see Fig. 15), showing\nthe consistency of the scalings. The values of the QF show a tendency to favour \"Fixed Coupling\", but all\ndifferent scalings (even \"Diffusive Scaling\") lead to reasonable values of QF.\nImplications for Diffraction and Vector Mesons We used the values of the parameters obtained from the fit\nto F2 data to test the various scaling variables on the diffractive cross section and vector meson data [121\u2013123].\nWe tested both the fixed \u03b2 scaling behaviour in xIP and the fixed xIP scaling behaviour in \u03b2. At fixed \u03b2, we\nfind a scaling behaviour up to \u03b2 = 0.65. At fixed xIP , the scaling behaviour of the diffractive cross section as\na function of \u03b2 and Q2 is far less obvious. This is not a surprise, as not enough data is available in the genuine\nsmall \u03b2 region. A sign of scaling is however observed for the xIP = 0.03 bin.\nConcerning \u03c1, J/\u03a8, and \u03c6 production [124\u2013126], we found a reasonable scaling behaviour for all\ntested scaling variables, with the hard scale Q2 + MV2 , borrowed from vector mesons wave function studies.\nSurprisingly, the best scaling is for all three vector mesons the \"Diffusive scaling\".\nFits to F2 and F2c in QCD Parametrisations First we test the scaling properties using experimental F2c\ndata. The requirements on the kinematical domain remain the same as in the case of F2 studies. The lower\nQ2 > 3 GeV2 cut also allows to remove eventual charm mass effects. We use the charm F2c measurements\nfrom the H1 and ZEUS experiments [127\u2013130]. Only 25 data points lie in the desired kinematical region.\nSince the statistics in the data is low, the fit results are not precise. Nevertheless, they still lead to\nclear results that are comparable to F2 fits. The results are found similar between F2 and F2c (see Fig. 16).\nAll \u03bb parameters are similar for F2 and F2c except for \"Diffusive Scaling\". As in the case of the F2 scaling\n\n\fanalysis, \"Fixed Coupling\", \"Running Coupling I\" and \"Running Coupling II\" give similar values of QF , and\n\"Diffusive Scaling\" is disfavoured.\nThe QCD parametrisations [131\u2013133] of the structure function have been tested using CTEQ, MRST,\nGRV. The same Q2 and x points as in the experimental data were taken into account. Parametrisations of F2\nare able to reproduce the scaling results seen in the experimental data. However, they are not successful in\ndescribing the scaling properties in case of F2c . Fig. 17 shows the scaling curve of \"Fixed Coupling\" in the\nMRST NNLO 2004 parametrisation of F2c where the value of \u03bb = 0.33 is imposed (as seen in the experimental\ndata). The scaling curve is plotted with all the points used in the F2 study. Therefore the fact that there is not\njust a single scaling curve in F2c parametrisation is not in direct disagreement with the data - with 25 point\nonly, the curves in parametrisation and data look similar. However the fit values of \u03bb are different.\nThe CTEQ, MRST or GRV parametrisations are unable to reproduce the scaling properties in F2c . It\nseems a sea-like intrinsic charm component like the one used in CTEQ 6.6 C4 helps to get results closer to a\nsingle scaling curve [134]. Scaling is not present at all in the MRST or GRV parametrisations at low Q2 .\n2.3.3 Geometric scaling and evolution equations with saturation26\nLet us now recall how scaling properties arise from saturation, as shown in [112], using methods and results\nfrom non-linear physics (see [135, 136] for alternative demonstrations). Our discussion, independent of the\nprecise saturation formalism, is valid e.g. for the JIMWLK and BK equations (see [108] and references\ntherein), at LL, NLL or even higher order in log(1/x). We will discuss separately the fixed and the running\n\u03b1s cases, as running coupling is the main effect which can modify the discussion.\nSaturation amounts to add a non-linear damping contribution to the BFKL evolution. One writes formally the evolution equation at LL for the dipole-proton cross section \u03c3\u0302 (23)\n\u2202Y \u03c3\u0302(Y, L) = \u1fb1\u03c7(\u2212\u2202L )\u03c3\u0302(Y, L) \u2212 non-linear terms in \u03c3\u0302(Y, L) ,\n\n(27)\n\nwhere Y \u2261 log(1/x), L \u2261 \u2212 log(r 2 \u039b2QCD ) and \u03c7(\u03b3) is the characteristic function of the BFKL kernel.\nThe nonlinear damping ensures that, for any Y , \u03c3\u0302(Y, L) grows at most as a power of |L| for L \u2192 \u2212\u221e (i.e.\nr \u2192 +\u221e). The color transparency property of the dipole cross section implies \u03c3\u0302(Y, L) \u221d e\u2212L for L \u2192 +\u221e.\nUsing a double Laplace transform with partial waves e\u2212\u03b3L+\u03c9Y , the linear part of (27) reduces to the BFKL\ndispersion relation \u03c9 = \u1fb1\u03c7(\u03b3), which gives the partial waves solutions e\u2212\u03b3[L\u2212\u1fb1\u03c7(\u03b3)Y /\u03b3] . In the relevant\ninterval 0 < \u03b3 < 1, the phase velocity \u03bb(\u03b3) = \u1fb1\u03c7(\u03b3)/\u03b3 has one minimum, for the critical value \u03b3 = \u03b3c \u2243 0.63\nwhich is the solution of \u03c7(\u03b3c ) = \u03b3c \u03c7\u2032 (\u03b3c ). In the presence of saturation terms in the evolution equation, the\nwave with \u03b3 = \u03b3c is selected dynamically.\nIn order to understand the dynamics of the problem, let us consider an arbitrary initial condition, at some\nrapidity Y = Y0 . With the definition \u03b3ef f (L, Y ) \u2261 \u2212\u2202L log(\u03c3\u0302(Y, L)), \u03b3ef f (L, Y0 ) gives the exponential\nslope of the initial condition in the vicinity of L. That vicinity will then propagates for Y \u2265 Y0 at a velocity\n\u03bb(\u03b3ef f (L, Y )) = \u1fb1\u03c7(\u03b3ef f (L, Y ))/\u03b3ef f (L, Y ). One finds easily that, if \u03b3ef f (L, Y0 ) is a growing function of\nL, the regions of smaller velocity will spread during the Y evolution, and invade the regions of larger velocity.\nRestricting ourselves to initial conditions verifying the saturation at L \u2192 \u2212\u221e and the color transparency\nat L \u2192 +\u221e as discussed previously, one obtains that \u03b3ef f (L, Y0 ) goes from 0 at low L to 1 at large L.\nAt intermediate L, \u03b3ef f (L, Y0 ) will cross the value \u03b3c , corresponding to the minimal velocity \u03bbc = \u03bb(\u03b3c ).\nHence, one conclude that, as Y grows, there is a larger and larger domain in L where \u03b3ef f (L, Y ) = \u03b3c and\nthus \u03bb = \u03bbc . In that domain, one has \u03c3\u0302(Y, L) \u221d e\u2212\u03b3c (L\u2212\u03bbc Y ) , and hence the geometric scaling \u03c3\u0302(Y, L) \u2261\nf (L \u2212 \u03bbc Y ) = f (\u2212 log(r 2 Q2s (x))), with a saturation scale Q2s (x) = e\u03bbc Y \u039b2QCD = x\u2212\u03bbc \u039b2QCD . One finds\np\nthat the geometric scaling window is limited to L < \u03bbc Y + \u1fb1\u03c7\u2032\u2032 (\u03b3c )Y /2, and separated from the region\nstill influenced by the initial condition by a cross-over driven by BFKL diffusion. So far, we discussed only\nscaling properties of the dipole cross section \u03c3\u0302. As explained in the introduction, they imply similar scaling\nproperties of the virtual photon-proton cross section, with the replacement r 7\u2192 1/Q.\nThe mechanism of wave selection explained above happens mainly in the linear regime27 , i.e. for small\n\n26\n\nContributing author: G. Beuf\nWe call linear (non-linear ) regime the (Y,L) domain where the explicit value of the non-linear terms in (27) is (is not) negligible\ncompared to the value of the linear terms.\n27\n\n\f\u03c3\u0302, or equivalently r smaller than Q2s (x). However, the geometric scaling property stays also valid in the nonlinear regime, i.e. for r larger than Q2s (x), which is reached after a large enough evolution in Y . The only,\nbut decisive, role of saturation in the linear domain is to provide the following dynamical boundary condition\nin the IR to the linear BFKL evolution: when \u03c3\u0302 is large, it should be quite flat (\u03b3ef f (L) \u2243 0). Indeed, one\ncan simulate successfully the impact of saturation on the solution in the linear regime by studying the BFKL\nevolution in the presence of an absorptive wall [136], set at a Y -dependent and selfconsistently determined\nposition near the saturation scale.\nAt NLL and higher order level, the terms different from running coupling ones do not affect the previous\ndiscussion. They just change the kernel eigenvalues \u03c7(\u03b3) and thus shift the selected parameters \u03b3c and \u03bbc . On\nthe contrary, going from fixed to running coupling brings important changes. As the mechanism of spreading\nof smaller velocity regions of the solution towards larger velocity ones is local, one expect that it holds in the\nrunning coupling case. But it selects coupling-dependent velocity and shape of the front, the coupling itself\nbeing L-dependent. Hence, the picture is the following. We still have the formation of a specific traveling\nwave front solution, which progressively loses memory of its initial condition. However, the selected values of\nthe velocity and shape of the front drift as the front propagate towards larger L (smaller r), due to asymptotic\nfreedom. So far, this running coupling case has been solved analytically [112,136] only at large L and large Y ,\nkeeping the relevant geometric scaling variable \u2212 log(r 2 Q2s (x)) finite. One finds that the evolution\n\u221a is slower\n2\nthan in the fixed coupling case, as the large Y behavior of the saturation scale is now Qs (x) \u223c e vc Y /b \u039b2QCD ,\nwith b \u2261 (33 \u2212 2Nf )/36 and vc \u2261 2\u03c7(\u03b3c )/\u03b3c . In addition,\np the geometric scaling window is narrower: asymptotically in Y , it is expected to hold only for28 L < vc Y /b + (|\u03be1 |/4) (\u03c7\u2032\u2032 (\u03b3c ))1/3 Y 1/6 /(2b\u03b3c \u03c7(\u03b3c ))1/6 .\nThe convergence of the selected front towards this asymptotic solution seems rather slow, which may weaken\nits phenomenological relevance. The whole theoretical picture is nevertheless consistent with numerical simulations [137, 138]. Both leads to a universal traveling wave front structure of the solution, implying scaling\nproperties also subasymptotically.\nIn order to do phenomenological studies, one can try to extrapolate to finite L and Y the scaling behavior\nfound asymptotically. However, this extrapolation is not unique [139]. There is indeed an infinite family of\nscaling variables\n\"\n\u0013 #\n\u0012\nvc Y \u03b4\nL,\n(28)\n\u03c4\u03b4 \u2261 1 \u2212\nbL2\nparameterized by \u03b4, which are different from each other at finite L and Y but all converge to the same asymptotic scaling previously mentioned. The parameter \u03b4 seems quite unconstrained, both from the theory and from\nthe DIS data, as shown in the phenomenological section of the present contribution. We considered as benchmark points in that family two specific choices of \u03b4. The choice \u03b4 = 1/2 leads to the only scaling variable\nof the family which is a genuine geometric scaling variable, i.e. is equivalent to a scaling with r 2 Q2s (x). It is\nnamed running coupling I in the phenomenological section. The choice \u03b4 = 1 leads to the scaling variable\nobtained by substitution of the fixed coupling by the running coupling directly in the original fixed coupling\ngeometric scaling variable. It is called running coupling II.\nFinally, one expects scaling properties in any case from evolution equations with saturation, both in\nthe non-linear regime, and in a scaling window in the linear regime. In the linear regime, the solution still\nobey the linearized equation, and saturation play only the role of a dynamically generated boundary condition.\nHence, geometric scaling there, although generated by saturation, is not a hint against the validity of PDF\nfits. However, geometric scaling occurs also in the non-linear regime, where the scaling function is no more a\nsolution of the linear BFKL or DGLAP equations.\n2.3.4 DGLAP evolution and the saturation boundary conditions29\nOne of the issues that could be studied in the context of the geometric scaling versus DGLAP evolution is\nthe possibility of the different boundary conditions for the DGLAP evolution equations. These boundary\nconditions would incorporate the saturation effects and posses the scaling property. Typically, in the standard\n28\n29\n\n\u03be1 \u2243 \u22122.34 is the rightmost zero of the Airy function.\nContributing author: A. M. Sta\u015bto\n\n\fapproach, to obtain the solution to the linear DGLAP evolution equations, one imposes the initial conditions\nonto the parton densities at fixed value of Q20 and then performs the evolution into the region of larger values\nof Q2 . However, in the presence of saturation these might not be the correct boundary conditions for DGLAP\nequations. As mentioned earlier the saturation regime is specified by the critical line, the saturation scale\nQs (x) which is a function of x Bjorken and its value increases as the Bjorken x decreases (or as we go to yet\nhigher energies). In that case it seems legitimate to ask, what is the behavior of the DGLAP solutions when\nevolved from the saturation boundary Q2 = Q2s (x) rather then from the fixed scale Q2 = Q20 . To answer\nthis question we imposed [140] the boundary condition for the gluon density at the saturation scale Q2 = Q2s\n\u03b1s\nxg(x, Q2 = Q2s (x)) = \u03b12\u03c0s r 0 x\u2212\u03bb (in the fixed coupling case).\nwhich possesses the scaling property namely 2\u03c0\nThe solution for the gluon density at small x (at fixed coupling) which can be derived from solving the DGLAP\nequations with this boundary is given by\n\u0012\n\u0013(\u03b1s /2\u03c0)\u03b3gg (\u03c90 )\u22121\nQ2\n\u03b1s\n\u03b1s xg(x, Q2 )\n(29)\n\u223c\n2\u03c0\nQ2\n2\u03c0 Q2s (x)\nwhere \u03b3gg is the gluon-gluon DGLAP anomalous dimension. This solution clearly has the geometrical scaling\nproperty as it is only a function of Q2 /Q2s (x). It is interesting to note that there exists a critical value of\nthe exponent \u03bb of the saturation scale which determines the existence of scaling. For example in the double\nleading logarithmic approximation the scaling is present for rather large values of the exponent \u03bb \u2265 4\u03b1s \u03c0/3\nwhereas there is no scaling for smaller values of \u03bb. The formula shown above is however only approximate,\nas in the derivation we included only the leading behavior which should be dominant at asymptotically small\nvalues of x. At any finite value of x the scaling will be mildly violated by the nonleading terms. We checked\nnumerically that this is indeed the case, though the violation was very small. This analysis was extended for\nthe case of the more realistic DGLAP evolution with the running coupling. As expected the presence of the\nscale violation due to the running coupling will lead to the violation of the scaling. In this case the geometric\nscaling is only approximate with the solution for the gluon density given by\n\u0015b\u03b3gg (\u03bb)\u22121\n\u0014\nQ2s (x)\n\u03b1s (Q2s (x))\n\u03b1s (Q2 ) xg(x, Q2 )\n2\n2\n,\n\u223c\nln[Q /Qs (x)]\n1+\n2\u03c0\nQ2\nQ2\n2\u03c0b\nwith b being the beta function of the QCD running coupling. The scaling here is present provided we have\n\u03b1s (Qs (x)) ln[Q2 /Q2s (x)]/(2\u03c0b) \u226a 1. Thus the geometric scaling violating term can be factored out.\n\nIn summary, this analysis shows that the geometric scaling property can be build into the DGLAP initial\nconditions, and that the solution to the linear evolution equation which do not include the parton saturation\neffects can preserve the scaling even in the regime of high Q2 values, outside the saturation region.\n2.3.5 Geometric scaling from DGLAP evolution30\n\nFrom the DGLAP point of view there is another possible explanation for geometric scaling: the scaling behaviour can be generated by the evolution itself, rather than being a preserved boundary condition. In fact,\nit is possible to show [141] both analytically and numerically that in the relevant HERA region approximate geometric scaling is a feature of the DGLAP evolution. In order to see this, one has first p\nto rewrite\nthe DGLAP solution as a function of t \u2212 \u03bb(t, x) log 1/x (\"fixed-coupling scaling\") or t \u2212 \u03bb(t, x) log 1/x\n(\"running-coupling scaling\")31 . Then from the explicit form of the DGLAP solution it follows that in the relevant kinematic region \u03bb(t, x) is approximatively constant, leading to \u03c3DGLAP (t, x) \u2248 \u03c3DGLAP (t \u2212 ts (x)).\nHence approximate geometric scaling in the HERA region is a feature of the DGLAP evolution. Interestingly\nenough, this DGLAP-generated geometric scaling is expected to hold also at large Q2 and relatively large x\n(say x <\n\u223c 0.1), in contrast with the saturation-based geometric scaling which should be a small x, small (or at\nleast moderate) Q2 effect.\nIn order to make more quantitative statements, one can use the quality factor method introduced in Sec.\n2.3.2. As a starting point, one can consider the leading-order small x DGLAP evolution of a flat boundary\n30\n\nContributing author: F. Caola\nThe labels \"fixed-coupling\" or \"running-coupling\" are here a bit misleading. In fact, all the results shown here are obtained with\nthe full running-coupling DGLAP solution. We kept this notation only for comparison with saturation-based approaches.\n31\n\n\f\u03c3\n\nTheoretical prediction\nData\n\n10\n1\n10-1\n10-2\n10-3\n10-4\n10-3\n\n10-2\n\n10-1\n\n1\n\n10\n\n102\n\n103 \u03c4\n\nFig. 18: Scaling plot with x < 0.1. For the theoretical DGLAP curve, only points with Q2 > 1 GeV2 were kept. Curves are offset\nfor clarity.\n\ncondition. At the level of accuracy of geometric scaling, this approximation should be accurate enough in a\n2\nwide kinematic region, say Q2 >\n\u223c 10 GeV , x <\n\u223c 0.1 at HERA. Now, a quality-factor analysis shows that in\nthis region the leading-order small x DGLAP solution has an excellent scaling behaviour, even better than the\nscaling behaviour observed in HERA data. Also the DGLAP predictions for the geometric slope \u03bb perfectly\nagree with the phenomenological values: from the DGLAP solution we obtain \u03bbDGLAP\n= 0.32 \u00b1 0.05\nf ix\nDGLAP\n= 1.66 \u00b1 0.34 (\"running-coupling\" scaling), to be compared with\n(\"fixed- coupling\" scaling) and \u03bbrun\nexp\nexp\n\u03bbf ix = 0.32 \u00b1 0.06, \u03bbrun = 1.62 \u00b1 0.25. Moreover, data exhibit geometric scaling also for larger x, larger\nQ2 (say x <\n\u223c 0.1 at HERA), as predicted by the DGLAP evolution. All these results are summarized in\nFig. 18, where we plot the theoretical and phenomenological32 reduced cross sections in function of the\n\"fixed-coupling\" scaling variable ln \u03c4 = t \u2212 \u03bb ln 1/x, with \u03bb = 0.32, in the HERA region with the cut\nx < 0.1. An analogous plot can be obtained for the \"running-coupling\" scaling [141]. We interpret these\nresults as striking evidence that for Q2 > 10 GeV2 the geometric scaling seen at HERA is generated by\nthe DGLAP evolution itself, without need of a peculiar saturation ansatz or of a suitable scaling boundary\ncondition.\nFor Q2 < 10 GeV2 the leading-order DGLAP solution exhibits violations of geometric scaling at\nsmall x. However, in this region any fixed-order DGLAP calculation fails because it does not resum small x\nlogarithms. If one consider the DGLAP evolution at the resummed level, geometric scaling reappears quite\nnaturally, both in the \"fixed-coupling\" and \"running-coupling\" forms [141]. Hence, small x resummation\nextends the region where geometric scaling is expected to values of Q2 lower than 10 GeV2 . However at low\nQ2 sizeable higher twist and non perturbative effects can spoil the universal behaviour of the DGLAP solution.\nIn this region hence the HERA scaling could still be generated by some DGLAP evolution, but, differently\nfrom the Q2 > 10 GeV2 region, here there is no strong evidence that this is in fact the case.\n2.3.6 Saturation model and higher twists33\nThe QCD description of hard scattering processes within the Operator Product Expansion (OPE) approach\nleads to the twist expansion of matrix elements of process-dependent composite operators. Contributions of\nemerging local operators with the increasing twists, \u03c4 , are suppressed by increasing inverse powers of the hard\nscale, Q2 . In DIS, at the lowest order (i.e. when the anomalous dimensions vanish), the twist-\u03c4 contribution\nto the DIS cross section scales as Q\u2212\u03c4 . Therefore, at sufficiently large Q2 it is justified to neglect higher\ntwist effects, and retain only the leading twist-2 contribution. This leads to the standard collinear factorisation\napproach with universal parton density functions evolving according to the DGLAP evolution equation. It\nshould be kept in mind, however, that the higher twist effects do not vanish completely and that they introduce\ncorrections to theoretical predictions based on the DGLAP approach. Thus, the higher twist corrections may\naffect the determination of parton density functions. The importance of these corrections depends on the\nlevel of precision required and on the kinematic domain. In particular, in the region of very small x the\n32\nIn fact, in order to make a more flexible analysis, we didn't use the actual HERA data but a neural network interpolation of world\nDIS data [142]. As long as one stays in the HERA region the output of the net is totally reliable.\n33\nContributing author: L. Motyka\n\n\fhigher twist effects are expected to be enhanced, so that they may become significant at moderate Q2 . Thus,\nit should be useful to obtain reliable estimates of higher twist effects at small x. In this section we shall\npresent higher twist corrections to FT , FL and F2 structure functions following from the DGLAP improved\nsaturation model [143]. The results presented in this section have been obtained in the course of an ongoing\nstudy [144, 145]. The method applied to perform the twist decomposition of the DGLAP improved saturation\nmodel is a generalisation of the Mellin space approach proposed in Ref. [146].\nA rigorous QCD analysis of the higher twist contributions to DIS at high energies is a complex task.\nSo far it has been performed for the q q\u0304gg operators [147], but the evolution of twist 4 purely gluonic operators has not been resolved, - even the proper complete basis of the operators has not been found yet. The\ncollinear evolution is known at all twists, however, for so called quasi-partonic operators, for which the twist\nindex is equal to the number of partons in the t-channel [148]. Such operators should receive the strongest\nenhancement from the QCD evolution. At the leading logarithmic approximation the collinear evolution of\nquasi-partonic operators is relatively simple - it is given by pair-wise interactions between the partons in the\nt-channel. The interactions are described by the non-forward DGLAP kernel [148]. Within this formalism, the\nevolution of four-gluon quasi-partonic operators was investigated in Ref. [149, 150] in the double logarithmic\napproximation. At small x the scattering amplitudes are driven by exchange of gluons in the t-channel, and\nthe quark exchanges are suppressed by powers of x. Thus we shall focus on the dominant contribution of the\nmulti-gluon exchanges in the t-channel. In the large Nc -limit, the dominant singularities of the four gluon\noperator are those corresponding to states in which gluons get paired into colour singlet states. In other words,\nthe four-gluon operator evolves like a product of two independent gluon densities. In general, for 1/Nc \u2192 0,\nthe 2n-gluon (twist-2n) operator factorizes into the product of n twist-2 gluon densities. After suitable inclusion of the AGK cutting rules and the symmetry factors of 1/n!, one arrives at the eikonal picture of n-ladder\nexchange between the probe and the target. This is to be contrasted with the Balitsky-Kovchegov picture of\nPomeron fan diagrams, which was obtained as a result of resummation of the terms enhanced by powers of\nlarge ln(1/x) rather than by powers of ln Q2 .\nThe eikonal form of the multiple scattering was assumed in the saturation model proposed by GolecBiernat and W\u00fcsthoff (GBW) [151, 152]. The dipole cross-section given by Eq. 25 has a natural interpretation\nin terms of a resummation of multiple scattering amplitudes. The scatters are assumed to be independent\nof each other, and the contribution of n scatterings is proportional to [r 2 /R02 (x)]n . The connection of the\nsaturation model to the QCD evolution of quasi-partonic operators is further strengthened by the DGLAP\nimprovement of the dipole cross section [143]. In the DGLAP improved saturation model the dipole cross\nsection depends on the collinear gluon density,\n\u0013\u0015\n\u0014\n\u0012\n\u03c02 r2\n2\n2\n\u03b1s (\u03bc ) xg(x, \u03bc )\n,\n(30)\n\u03c3\u0302(x, r) = \u03c30 1 \u2212 exp \u2212\nNc \u03c3 0\nwhere the scale \u03bc2 depends on the dipole size, \u03bc2 = C/r 2 for C/r 2 > \u03bc20 , and \u03bc2 = \u03bc20 for C/r 2 < \u03bc20 .\nThe gluon density applied has been obtained from the LO DGLAP evolution without quarks, with the input\nassumed at the scale \u03bc20 34 . Clearly, in Eq. (30) one sees an exact matching between the power of r 2 and the\npower of xg(x, \u03bc2 ) suggesting a correspondence between the term \u223c [r 2 \u03b1s (\u03bc2 ) xg(x, \u03bc2 )]n in the expansion\nof \u03c3\u0302(x, r) and the twist-2n contribution to the dipole cross section. Thus, we expect that the saturation model\napproximately represents higher twist contributions in the deep inelastic scattering generated by the gluonic\nquasi-partonic operators.\nThe twist analysis of the DIS cross-section must include a treatment of the quark box that mediates the\ncoupling of the virtual photon, \u03b3 \u2217 , to the t-channel gluons. In the dipole model the \u03b3 \u2217 g \u2192 q q\u0304 amplitude,\ncomputed within QCD, is Fourier transformed (w.r.t. the transverse momentum of the quark) to the coordinate\nrepresentation and appears as the photon wave function, compare Eq. (25). In more detail, one uses the \u03b3 \u2217 g\namplitude computed within the kT -factorisation framework. This amplitude receives contributions from all\ntwists. The twist structure of the quark box is transparent in the space of Mellin moments, and the same is true\n34\nIn the original DGLAP-improved model [143] a different definition of the scale was adopted, \u03bc2 = C/r 2 + \u03bc20 , but this choice\nis less convenient for the QCD analysis.\n\n\ffor the dipole cross-section. Thus we define,\nZ 1 Z\n2\ndz\nH\u0303T,L (\u03b3, Q ) =\n\ndr 2 r 2 \u03a8T,L (r, z, Q2 )\n\n2\n\nr 2(\u03b3\u22121) ,\n\n(31)\n\n0\n\n0\n\n \u0303 \u03b3) =\n\u03c3\u0302(x,\n\n\u221e\n\nZ\n\n\u221e\n\ndr 2 \u03c3\u0302(x, r 2 ) r 2(\u03b3\u22121) .\n\n(32)\n\n0\n\nIt then follows from the Parsival formula that,\n2\n\n\u03c3T,L (x, Q ) =\n\nZ\n\nC\n\nd\u03b3\n \u0303 \u03b3).\nH\u0303T,L (\u2212\u03b3, Q2 ) \u03c3\u0302(x,\n2\u03c0i\n\n(33)\n\nFor the massless quark case one has H\u0303T,L (\u03b3, Q2 ) = H\u0303T,L (\u03b3) Q\u22122\u03b3 . The contour of integration, C, in Eq. 33\nbelongs to the fundamental Mellin strip, \u22121 < Re \u03b3 < 0.\n\nIn order to obtain the twist expansion of \u03c3, one extends the contour C in the complex \u03b3-plane into a\ncontour C \u2032 closed from the left-hand side. The Mellin integral in Eq. 33 may be then decomposed into con \u0303 \u03b3). The function H\u0303T (\u2212\u03b3) (H\u0303L (\u2212\u03b3)) has simple\ntributions coming from singularities of H\u0303T,L (\u2212\u03b3, Q2 ) \u03c3\u0302(x,\npoles at all negative integer values of \u03b3, except of \u03b3 = \u22122 (\u03b3 = \u22121), where H\u0303T (H\u0303L ) is regular. The singular \u0303\nity structure of the dipole cross section, \u03c3\u0302(\u03b3),\ndepends on the specific form of \u03c3\u0302(x, r 2 ). For \u03c3\u0302(x, r 2 ) used in\n \u0303\nthe GBW model, the \u03c3\u0302(x, \u03b3) has simple poles at all negative integers \u03b3's. For the DGLAP improved form of\n \u0303 \u03b3) has cut singularities that extend to the left from \u03b3 = k where k = \u22121, \u22122, etc. The\n\u03c3\u0302 given by (31), \u03c3\u0302(x,\n \u0303 around a branch point at \u03b3 = k is given by \u223c (\u03b3 \u2212 k)p(k) , where the exponent p(k)\nleading behaviour of \u03c3\u0302\nis generated by the DGLAP evolution. As the cuts extend to the left from the branch points, the dominant\ncontribution to the cross section at the given twist comes from the vicinity of the corresponding branch point.\n\nThe singularity structure of the quark box part H\u0303T,L (\u03b3) plays the crucial role in understanding the\nstrength of the subleading twist effects. To see that one expands H\u0303T,L (\u03b3) around the singular points, \u03b3 = 1\nand \u03b3 = 2 (recall that the argument of H\u0303T,L is \u2212\u03b3 in the Parsival formula (33)):\n(2)\n\nH\u0303T (\u03b3) =\n\naT\n(2)\n+ bT + O(\u03b3 \u2212 1),\n\u03b3\u22121\n\n(2)\n\nHL (\u03b3) = bL + O(\u03b3 \u2212 1),\n\n(34)\n\nfor twist-2, and\n(4)\n\nH\u0303T (\u03b3) = bT + O(\u03b3 \u2212 2),\n\n(4)\n\nHL (\u03b3) =\n\naL\n(4)\n+ bL + O(\u03b3 \u2212 2),\n\u03b3\u22122\n\n(35)\n\nfor twist-4. The singular 1/(\u03b3 \u2212 1) and 1/(\u03b3 \u2212 2) terms in (34) and (35) generate an additional enhancement,\n\u223c ln(Q2 ), of the corresponding twist-2 and twist-4 contributions to the DIS cross-section. The constant\n(2)\n(4)\npieces, proportional to bT,L and bT,L , produce no new logarithms (thus they are interpreted as the next-toleading order (NLO) QCD corrections) and the higher terms in the Laurent expansion give yet higher orders\nin the perturbative expansion of the g \u2192 q splitting functions and to the coefficient functions. We summarize\n(2)\nthis discussion by displaying below the most leading contributions to \u03c3T,L at twist-2 (\u03c3T,L ) and at twist-4\n(4)\n\n(\u03c3T,L ) obtained in the DGLAP improved saturation model:\n(2)\n\n\u03c3T\n\n(2)\n\n\u223c\n\naT\nQ2\n\nZ\n\nQ2\n\u03bc20\n\ndQ\u20322\n\u03b1s (Q\u20322 )xg(x, Q\u20322 ) ,\nQ\u20322\n\n(2)\n\n\u03c3L\n\n(2)\n\nbL\n\u03b1s (Q2 )xg(x, Q2 ) ,\nQ2\n\n(36)\n\ndQ\u20322\n[\u03b1s (Q\u20322 )xg(x, Q\u20322 )]2 ,\nQ\u20322\n\n(37)\n\n\u223c\n\nfor twist-2, and\n(4)\n\u03c3T\n\n(4)\n\nb\n\u223c T 4 [\u03b1s (Q2 )xg(x, Q2 )]2 ,\nQ\n\n(4)\n\u03c3L\n\n(4)\n\na\n\u223c L4\nQ\n\nZ\n\nQ2\n\u03bc20\n\nfor twist-4. These results imply that the the relative twist-4 correction to FT is strongly suppressed w.r.t. the\ntwist-2 contribution, as the subleading twist-4 term in FT appears only at the NLO. On the contrary, for FL ,\n\n\fthe leading twist term enters only at the NLO, and the the twist-4 correction enters at the leading order. So, the\nrelative twist-4 effects in FL are expected to be enhanced. Note, that both in the case of FT and FL the twist-4\neffects are enhanced w.r.t. the twist-2 contribution by an additional power of the gluon density, xg(x, Q2 ).\nFor the structure function F2 = FT + FL we expect small relative corrections from the higher twists because\n(4)\n(4)\nof the opposite sign of coefficients aL and bT , that leads to cancellations between the twist-4 contributions\n2\nfrom FT and FL at moderate Q . These conclusions about the importance of the higher twist corrections are\nexpected to be quite general, because they follow directly from the twist structure of the quark box and do not\ndepend on the detailed form of the twist-4 gluon distribution.\nWe performed [144, 145] an explicit numerical evaluation of the twist-4 corrections to FT , FL and F2 in the DGLAP\n0.8\nimproved\nsaturation model, and compared the results to results\n0.6\nobtained [146] within the GBW model without the DGLAP evo0.4\n0.2\nlution. The parameters of the DGLAP model were fitted to de0\n1\n2\n3\n4\n5\n6 7 8 9\nscribe all F2 data at small x. In the model we took into account\nQ\n0.5\nthree massless quark flavours and the massive charm quark. The\ntwist analysis, however, has been, so far, performed only for\n0\nthe massless quark contribution. The obtained relative twist-4\n-0.5\ncorrections to FT , FL and F2 are displayed in Fig. 2.3.6, as a\n-1\nfunction of Q2 , for x = 3 * 10\u22124 . The continuous curves corre1\n2\n3\n4\n5\n6 7 8 9\nQ\nspond to the GBW model [146], and the dashed ones have been\n0.4\nobtained [144, 145] in the DGLAP improved saturation model.\n0.2\nAlthough there are some quantitative differences between the\n0\n-0.2\nmodels, the qualitative picture is quite consistent and confirms\n-0.4\nthe results of the analytic analysis outlined above. Thus, the\n1\n2\n3\n4\n5\n6 7 8 9\nQ\nhigher twist corrections are strongest in FL , and much weaker\nin FT . In F2 there occurs a rather fine cancellation between the\nFig. 19: The ratio of twist-4 to twist-2 components of\ntwist-4 contributions to FT and FL , at all Q2 , down to 1 GeV2 .\nFT , FL and F2 at x = 3 * 10\u22124 in the GBW model\nAlthough an effect of this kind was expected, it still remains\n(continuous lines) and in the DGLAP improved satusomewhat surprising that this cancellation works so well. We\nration model (dashed lines).\nestimate that, for x = 3 * 10\u22124 , the twist-4 relative correction\nto F2 is 2 \u2013 4% at Q2 = 10 GeV2 , and smaller than 10% for all Q2 down to 1 GeV2 . For FL , the relative\ncorrection is \u223c 20% at Q2 = 10 GeV2 , and strongly increases with the decreasing scale, reaching \u223c 50% at\nQ2 = 1 GeV2 . It implies that the determination of parton densities from twist-2 F2 data is safe even at small x\nand moderate Q2 . On the other hand FL at small x may provide a sensitive probe of higher twist effects and\nparton saturation.\nFT(tw-4)/FT(tw-2)\n\nTwist ratios: tw-4/tw-2\n\n1\n\nGBW - solid\n\nBGK - dashed\n\nx=3 10\n\n-4\n\nFL(tw-4)/FL(tw-2)\n\n2\n\nF2(tw-4)/F2(tw-2)\n\n2\n\n2\n\n2.3.7 Conclusions\nThere are many possible explanations for the scaling properties of HERA data, some of them based on saturation effects and some others based on pure linear evolution. In order to separate between these different\nexplanations, it is fundamental to specify a kinematic window.\n2\nIn particular, for large enough Q2 and not too small x (say Q2 >\n\u223c 10 GeV in the HERA region) the\nobserved geometric scaling is determined by the DGLAP evolution, irrespective of the boundary condition.\nFor smaller values of Q2 , the evolution of parton densities is still linear, but is sensitive to a boundary condition.\nIn an evolution toward smaller x, like BFKL, this boundary condition is dynamically generated by saturation,\nand it leads to the geometric scaling window. It is possible to take these effects into account also in a Q2\nevolution, like DGLAP, by imposing as initial condition the same boundary condition. We have seen that,\nin this case, even the LO DGLAP equation is able to propagate geometric scaling towards larger Q2 . In\nthat domain, although geometric scaling may arise as saturation effect, the evolution is still linear, and thus\ncompatible with standard PDFs analysis. However, at yet lower Q2 and x standard linear evolution is no\nlonger reliable. In particular, for Q2 smaller than a x dependent saturation scale Qs (x), the evolution of\nparton densities becomes fully nonlinear, and this spoils the actual determination of the PDFs. Results from\n\n\finclusive diffraction and vector meson exclusive production at HERA, and from dA collisions at RHIC all\nsuggest that in the kinematic accessible x region Qs \u223c 1 \u2212 2 GeV.\n2\nIn conclusion, we can say that for large enough Q2 >\n\u223c 10 GeV geometric scaling is fully compatible\n2\n2\nwith linear DGLAP evolution. For smaller Q the situation becomes more involved. For Q2 >\n\u223c 5 GeV\nthe HERA scaling is still compatible with DGLAP, maybe with some small x resummation or some suitable\nboundary condition. However, other effects may be relevant in this region. For yet lower Q2 and x the linear\ntheory becomes unreliable and saturation could be the right explanation for geometric scaling. Unfortunately\nat HERA we have too few data for a definitive explanation of geometric scaling in the very small x region,\nsince many different approaches lead approximatively to the same results and it is very difficult to separate\namong them. For example, in the low x region both saturation and perturbative resummations lead to a\ndecrease of the gluon and to geometric scaling. At the LHC, where higher center-of-mass energy is available,\nthe x region is significantly extended down to very small values. Especially in the fragmentation region the\ntypical values of x which can be probed can reach down to 10\u22126 for partons with transverse momenta of about\nfew GeV. This fact combined with the very wide rapidity coverage of the main LHC detectors opens up a\ncompletely new window for the study of parton saturation, and its relations with geometric scaling and linear\nevolution will possibly be clarified.\n\n\f3 BENCHMARKING OF PARTON DISTRIBUTIONS AND THEIR UNCERTAINTIES35\n3.1 Introduction\nThe proper treatment of uncertainties associated to the fit of Parton Distribution Functions (PDF) has become\na subject of great interest in the last few years. A simple way of understanding differences between available\napproaches to parton fits is to fix some hypothesis (say, experimental data, QCD parameters, input parameterizations, error treatment), and check what is the effect of the remaining assumptions. Such studies were\npreviously done in the framework of the first HERA\u2013LHC workshop [1].\nIn the following we will discuss three benchmark fits. The first one is presented in Sect. 3.2. It is\nbased on the H12000 parton fit [18], and it compares a new version of this fit, in which uncertainty bands are\ndetermined [153, 154] using a Monte Carlo method, to the reference fit, where uncertainty bands are obtained\nusing the standard Hessian method. The main motivation of this benchmark is to study the impact of possible\nnon-Gaussian behaviour of the data and, more generally, the dependence on the error treatment.\nThe second benchmark is presented in Sect. 3.3. It is based on the study performed by S. Alekhin and\nR. Thorne in Ref. [1], which compared the fits by their respective groups to a common reduced set of data with\ncommon assumptions, and also to their respective reference (global) fits. This comparison is extended here in\ntwo ways. First, the comparison is extended to include an NNPDF fit to the same reduced set of data with the\nsame assumptions, and the NNPDF1.0 reference fit [155]. Second, results are also compared to a fit based on\nthe recent MSTW 2008 [39,156] analysis. As in the Thorne benchmark fit, this uses slightly different data sets\nand assumptions; it is furthermore modified to use the same input parameterization and improved treatment\nof uncertainties as MSTW. The main purpose of these comparisons is to answer the questions (a) to which\nextent fit results from various groups obtained using different methodologies still differ from each other when\ncommon or similar assumptions and a common or similar reduced dataset are used and (b) how the fits to the\nreduced dataset by each group compare to the fit to the full dataset.\nThe third benchmark, discussed in Sect. 3.4, is a further elaboration on the benchmark presented in\nSect. 3.2, extended to include the NNPDF fit, which also uses a Monte Carlo approach. The main purpose\nof this benchmark is to compare two fits (H1 and NNPDF) which have the same error treatment but different\nparton parameterizations. The inclusion in this benchmark of the NNPDF fit is also interesting because it\nallows a comparison of a fit based on a very consistent set of data coming from the H1 collaboration only, to\nfits which include all DIS data sets, which are less compatible than the H1 sets alone.\n3.1.1 Settings for the H1 benchmark\nThis analysis is based on all the DIS inclusive data by the H1 collaboration from the HERA-I run. A kinematic\ncut of Q2 > 3.5 GeV2 is applied to avoid any higher twist effect. The data points used in the analysis are\nsummarized in Table 1 and Fig. 20.\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\nThe theoretical assumptions are:\nNLO perturbative QCD in the MS renormalization and factorization scheme;\nzero-mass variable flavour number scheme with quark masses mc = 1.4 GeV and mb = 4.5 GeV;\nthe strong coupling fixed to \u03b1s (MZ ) = 0.1185;\nmomentum and valence sum rules enforced;\nstarting scale for the evolution at Q20 = 4 GeV2 ;\nstrange contribution fixed as\ns(x, Q20 ) = s\u0304(x, Q20 ) = fs D\u0304(x, Q20 ) =\n\nwith U = u + c and D = d + s + b and with fs = 0.33;\n\u2022 charm contribution fixed as\nc(x, Q20 ) = c\u0304(x, Q20 ) = fc \u016a (x, Q20 ) =\n\nfs  \u0304\nd(x, Q20 ),\n1 \u2212 fs\n\n(38)\n\nfc\n\u016b(x, Q20 ),\n1 \u2212 fc\n\n(39)\n\n35\nContributing authors: R. D. Ball, L. Del Debbio, J. Feltesse, S. Forte, A. Glazov, A. Guffanti, J. I. Latorre, A. Piccione, V. Radescu, J. Rojo, R. S. Thorne, M. Ubiali, G. Watt\n\n\fData Set\nH197mb\nH197lowQ2\nH197NC\nH197CC\nH199NC\nH199CC\nH199NChy\nH100NC\nH100CC\nTotal\n\nData points\n35\n80\n130\n25\n126\n28\n13\n147\n28\n612\n\nObservable\n\u03c3\u0303 N C,+\n\u03c3\u0303 N C,+\n\u03c3\u0303 N C,+\n\u03c3\u0303 CC,+\n\u03c3\u0303 N C,\u2212\n\u03c3\u0303 CC,\u2212\n\u03c3\u0303 N C,\u2212\n\u03c3\u0303 N C,+\n\u03c3\u0303 CC,+\n\nRef.\n[89]\n[89]\n[157]\n[157]\n[88]\n[88]\n[88]\n[18]\n[18]\n\nTable 1: Data points used in the H1 benchmark after kinematic cuts of Q2 > 3.5 GeV2 .\n\n104\n\nNNPDF1.0\nNNPDF_bench_H1\n\n3\n\nQ 2 (GeV2)\n\n10\n\n102\n\n10\n\n1 -5\n10\n\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\n1\n\nFig. 20: The data used in the H1 benchmark and in the NNPDF reference fit.\n\nwith fc = 0.15;\n\u2022 five independent PDFs: gluon and U , D, \u016a , D\u0304 (see definition above);\n\u2022 iterated solution for evolution (see, e.g. [158], Sect. 1.3).\nBoth the H1 and NNPDF methodologies are based on\n\u2022 Monte Carlo method to determine uncertainties. This method will be discussed in detail in Sect. 3.2.2\nbelow.\nThey differ in the way PDFs are parameterized:\n\u2022 H1 parameterizes PDFs as\nxg(x, Q20 ) = Ag xBg (1 \u2212 x)Cg [1 + Dg x] ,\n\nxU (x, Q20 ) = AU xBU (1 \u2212 x)CU [1 + DU x + FU x3 ] ,\n\nxD(x, Q20 ) = AD xBD (1 \u2212 x)CD [1 + DD x] ,\n\nx\u016a (x, Q20 )\nxD\u0304(x, Q20 )\n\n= A\u016a x\n\nB\u016a\n\n= A\u016a x\n\nBD\u0304\n\nC\u016a\n\n,\n\nCD\u0304\n\n,\n\n(1 \u2212 x)\n\n(1 \u2212 x)\n\n(40)\n\n(41)\n\nwhich yields 10 free parameters after sum rules are imposed;\n\u2022 NNPDF parameterizes PDFs with a 2-5-3-1 neural network, which implies 185 free parameters to be\nfitted.\nBecause of the large number of parameters, the minimum of the NNPDF fit is determined using the stopping criterion discussed in Sect. 3.3.2 below, while the minimum of the H1 fit is determined as the standard\nminimum \u03c72 (or maximum likelihood) point of parameter space.\n\n\f3.1.2 Settings for the HERA\u2013LHC benchmark\nThis benchmark was first presented in Ref. [1], where its settings were defined. In order to have a conservative\nensemble of experimental data and observables, only structure function DIS data are used. Large kinematic\ncuts are applied to avoid any higher twist effect. The data points used in the Alekhin analysis are summarized\nin Table 2 and Fig. 21.\nData Set\nZEUS97\nH1lowx97\nNMC\nNMC pd\nBCDMS\nTotal\n\nData points\n206\n77\n95\n73\n322\n773\n\nObservable\nF2p\nF2p\nF2p\nF2d /F2p\nF2p\n\nRef.\n[91]\n[89]\n[116]\n[159]\n[160]\n\nTable 2: Data points used in the HERA\u2013LHC benchmark after kinematic cuts of Q2 > 9 GeV2 and W 2 > 15 GeV2 are applied.\n\n104\n\nNNPDF1.0\nNNPDF_bench_H-L\n\n3\n\nQ 2 (GeV2)\n\n10\n\n102\n\n10\n\n1 -5\n10\n\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\n1\n\nFig. 21: The data used in the HERA\u2013LHC benchmark and in the NNPDF reference fit.\n\nThe theoretical assumptions are:\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\nNLO perturbative QCD in the MS renormalization and factorization scheme;\nzero-mass variable flavour number scheme with quark masses mc = 1.5 GeV and mb = 4.5 GeV;\n\u03b1s (MZ ) fitted: the best-fit values are 0.1110 \u00b1 0.0012 (Alekhin) and 0.1132 \u00b1 0.0015 (Thorne);\nmomentum and valence sum rules imposed;\nstarting scale for evolution Q20 = 1 GeV 2 ;\nfour independent input PDFs (u and d valence, the sea and the gluon);\n \u0304\nno light sea asymmetry: \u016b = d;\nno independent strange PDF:\n \u0304 Q2 )) ;\ns(x, Q20 ) + s\u0304(x, Q20 ) = 0.5(\u016b(x, Q20 ) + d(x,\n0\n\n\u2022 iterated solution of evolution equations;\n\n(42)\n\nThe NNPDF analysis presented here is based on the same data set and theoretical assumptions, the only\ndifference being that the strong coupling is fixed to \u03b1s (MZ ) = 0.112, i.e. the average of the fitted values of\nS. Alekhin and R. Thorne.\nThe Thorne benchmark used somewhat different data sets and assumptions. Namely:\n\n\fData Set\nZEUS97\nH1lowx97\nNMC\nNMC pd\nBCDMS\nTotal\n\nData points\n206\n86\n67\n73\n157\n589\n\nObservable\n\u03c3\u0303 NC,+\n\u03c3\u0303 NC,+\nF2p\nF2d /F2p\nF2p\n\nRef.\n[91]\n[89]\n[116]\n[159]\n[160]\n\nTable 3: Data points used in the MSTW benchmark fit after kinematic cuts of Q2 > 9 GeV2 and W 2 > 15 GeV2 are applied.\n\n\u2022 A somewhat different dataset is used, as displayed in Table 3. This differs from the dataset of Table 2\nand Figure 2 because the NMC and BCDMS fixed-target data on F2p used are averaged over different\nbeam energies, and also, HERA reduced cross sections rather than structure function data are used,\nresulting in an additional nine H1 points. Note that the Thorne benchmark in Ref. [1] also included the\nF2d BCDMS deuterium data.\n\u2022 All correlations between systematics are neglected, and statistical and systematic errors are added in\nquadrature.\n\u2022 Normalizations of individual data sets are fitted with a rescaling of uncertainties to avoid systematic\nbias.\n\u2022 The F2d /F2p data are corrected for nuclear shadowing effects [161].\nThe MSTW analysis presented here makes the same choices as the Thorne benchmark, but with \u03b1s (MZ ) =\n0.112, and additionally\n\u2022 a global correction of \u22123.4% is applied to the luminosity of the published H1 MB 97 data [89] following\na luminosity reanalysis [162].\n\u2022 a quartic penalty term in the \u03c72 definition is given to normalizations which deviate from the central\nvalue.\n3.2 Experimental Error Propagation36\n3.2.1 Introduction\nStandard error estimation of proton parton distribution functions (PDFs) relies on the assumption that all\nerrors follow Gaussian (or normal) statistics. However, this assumption may not always be correct. Some systematic uncertainties such as luminosity and detector acceptance follow rather a log-normal distribution (see\nSection 4.1). Compared to the Gaussian case, the lognormal distribution which has the same mean and root\nmean square (RMS), is asymmetric and has a shifted peak, as shown illustratively in Figure 22. Therefore,\nthe non-Gaussian behaviour of the experimental uncertainties could lead to an additional uncertainty of the\nresulting PDFs. An alternative to the standard error propagation is a toy Monte Carlo (MC) method. Here,\nan implementation of the MC method is presented for estimation of the PDF uncertainties with various assumptions for the error distribution. In addition, this MC method provides an independent cross check of the\nstandard error propagation when assuming the Gaussian error distributions.\n3.2.2 Method\nThe Monte Carlo technique consists firstly in preparing replicas of the initial data sets which have the central\nvalue of the cross sections, \u03c3i , fluctuating within its systematic and statistical uncertainties taking into account\nall point to point correlations. Various assumptions can be considered for the error distributions. When dealing\nwith the statistical and point to point uncorrelated errors, one could allow each data point to randomly fluctuate\nwithin its uncorrelated uncertainty assuming either Gauss, lognormal, or any other desired form of the error\ndistribution. For example, for Gaussian errors\n\u03c3i \u2212\u2192 \u03c3i (1 + \u03b4iuncorr * Ri ) ,\n36\n\nContributing authors: J. Feltesse, A. Glazov, V. Radescu\n\n(43)\n\n\f-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\nFig. 22: Comparison of the lognormal (black, darker hatching) and Gaussian (red, lighter hatching) probability distributions. The\ndistributions are shown with mean equal to one, and two different choices for the RMS (for both distribution): \u03c3 = 0.2 (top) and\n\u03c3 = 0.5 .\n\nwhere \u03b4iuncorr corresponds to the uncorrelated uncertainties and Ri is a random number chosen from a normal\ndistribution with a mean of 0 and a standard deviation of 1. Hence, the central value of each cross section\npoint i is shifted by \u03b4iuncorr * Ri .\n\nFor the systematic errors, the treatment is a bit more complicated than above. This is due to the correlation between data points and that, in general, the data points are sensitive to the systematic sources with\na different strength \u03b4ij , where index i (j) runs over all the cross section points (all systematic sources). In\norder to take this into account, for each systematic source j a uniformly distributed fluctuation probability Pj\nis selected. Then, for each data point i the central value of cross section is shifted such that probability of this\nshift, which depends on \u03b4ij and the exact form of the probability distribution function, is equal Pj (for positive\n\u03b4ij ) or (1 \u2212 Pj ) (for negative \u03b4ij ). In other words, each central value of the cross section is shifted with the\nsame probability of the corresponding systematic shift. For example for the Gaussian errors, this procedure is\nequivalent to\n\uf8eb\n\n\u03c3i \u2212\u2192 \u03c3i \uf8ed1 + \u03b4iuncorr * Ri +\n\nNsys\n\nX\nj\n\n\uf8f6\n\ncorr\n\u03b4ij\n* Rj \uf8f8 ,\n\n(44)\n\nwhere in addition to the shifts for the uncorrelated errors previously explained, Rj corresponds to another\nrandom number chosen from a normal distribution with mean of 0 and standard deviation of 1 as a fluctuation\ncorr * R\nfor the systematic source j. Hence, the central values of the cross sections are shifted in addition by \u03b4ij\nj\nfor each systematic shift.\nThis preparation of the data is repeated for N times, where high statistics is desirable for more accurate\nresults. For this study we used N > 100 which proved to suffice. For each replica, a next to leading order\n(NLO) QCD fit is performed to extract the PDFs. The errors on the PDFs are estimated from the RMS of the\n\n\fspread of the N lines corresponding to the N individual fits to extract PDF.\nA fit to the published H1 HERA-I data of neutral and charged current e\u00b1 p scattering cross sections [18]\nusing the settings discussed in Sect. 3.1.1 has been performed, using the QCDNUM program [163].\n3.2.3 Validation of the Method\nThe MC method is tested by comparing the standard error estimation of the PDF uncertainties with the MC\ntechniques by assuming that all the errors (statistical and systematic) follow Gaussian (normal) distribution.\nFigure 23 shows good agreement between the methods.\nxG(x)\n\nFit vs H1PDF2000, Q2 = 4. GeV2\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0 -4\n10\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n1\n\nx\n\nFig. 23: Comparison between the standard error calculations and the Gauss error distribution is shown for the gluon PDF. Green lines\nrepresent the spread of Monte Carlo generated allowances for the errors, and the red lines are the RMS of this spread. The black lines\ncorrespond to the standard error calculations of the PDF errors.\n\n3.2.4 Test of various assumptions for the error distributions\nTwo cases are considered which may represent most likely the error distributions: (1) the lognormal distribution for the luminosity uncertainty and the rest of the errors are set to follow the Gauss shape, (2) the lognormal\ndistributions for all the systematic errors and the statistical errors are set to follow the Gauss distributions. The\nresults for the first case (1) are shown in Figure 24. The results of the tests for the case when lognormal\ndistributions for all the systematic uncertainties are assumed is shown in Figure 24. We observe that for the\nprecise H1 HERA-1 data the effect of using lognormal distribution, which is considered for some systematic\nuncertainties more physical, is similar to the pure gauss distribution case.\n3.2.5 Conclusions\nA simple method to estimate PDF uncertainties has been built within QCD Fit framework. Assuming only\ngauss distribution of all errors, the results agree well with the standard error estimation. This method allows to\ncheck the effect of non- gauss assumptions for distributions of the experimental uncertainties. For the H1 data,\nresults are similar to the gauss case when using lognormal. The method could be extended for other physical\nvariables (i.e. cross sections) for cross checks with the standard error evaluation.\n3.3 HERA\u2013LHC Benchmark\nThis benchmark is based on the Alekhin/Thorne benchmark of Ref. [1], whose settings has been given in\nSect. 3.1.2. Both the Alekhin and Thorne fits had the following features:\n\n\f2\n\n2\n\n2\n\nFit vs H1PDF2000, Q = 4. GeV\n\n10\n\nxG(x)\n\nxG(x)\n\nFit vs H1PDF2000, Q = 4. GeV\n9\n\n10\n9\n\n8\n\n8\n\n7\n\n7\n\n6\n\n6\n\n5\n\n5\n\n4\n\n4\n\n3\n\n3\n\n2\n\n2\n\n1\n\n1\n\n0 -4\n10\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n1\n\nx\n\n2\n\n0 -4\n10\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n1\n\nx\n\nFig. 24: Comparison between errors on PDFs obtained via standard error calculation (black) where Gauss assumption is used, and\nerrors obtained via Monte Carlo method (red) where luminosity uncertainty is allowed to fluctuate according to lognormal distributions\nand all the other uncertainties follow the Gaussian distribution (left), and where all the systematic uncertainties are allowed to fluctuate\naccording to lognormal distributions (right). Only the gluon PDF is shown, where the errors are larger. The green lines show the spread\nof the N individual fits.\n\n\u2022 uncertainties determined using the Hessian method with \u2206\u03c72 = 1;\n\u2022 input PDFs are parameterized using the following functional form:\nx fi (x, Q20 ) = Ai (1 \u2212 x)bi (1 + \u01ebi x0.5 + \u03b3i x)xai .\n\n(45)\n\nwith \u01ebi and \u03b3i set to zero for the sea and gluon distributions. Hence, there were a total of 13 free PDF\nparameters plus \u03b1s (MZ ) after imposing sum rules.\nHere, we reanalyze it within the MSTW and NNPDF approaches. First, we summarize the respective\nMSTW and NNPDF approaches, and especially their differences when compared to the previous HERALHC\nbenchmark fits of Ref. [1]. Then, results for benchmark fits obtained with the various different approaches are\ncompared to each other. Finally, we compare each benchmark fit to its counterpart based on a wider range of\ndata, i.e. the NNPDF1.0 [155] reference and the MRST01 [164] and MSTW08 [39, 156] PDFs.\n3.3.1 MSTW approach37\nThe benchmark analysis is now much more closely aligned to the global analysis than was the case for the\nThorne benchmark compared to the MRST global analysis. It follows the general approach taken by the\nMRST (or more recently, MSTW) group, and is similar to that described in Ref. [164]. There are some new\nfeatures which are explained below.\n- Input parameterization. We take the input PDF parameterization at Q20 = 1 GeV2 to be:\n\u221a\nxuv (x, Q20 ) = Au x\u03b71 (1 \u2212 x)\u03b72 (1 + \u01ebu x + \u03b3u x) ,\n\u221a\nxdv (x, Q20 ) = Ad x\u03b73 (1 \u2212 x)\u03b74 (1 + \u01ebd x + \u03b3d x) ,\n\u221a\nxS(x, Q20 ) = AS x\u03b4S (1 \u2212 x)\u03b7S (1 + \u01ebS x + \u03b3S x) ,\n\u221a\nxg(x, Q20 ) = Ag x\u03b4g (1 \u2212 x)\u03b7g (1 + \u01ebg x + \u03b3g x) + Ag\u2032 x\u03b4g\u2032 (1 \u2212 x)\u03b7g\u2032 ,\n37\n\nContributing authors: R. S. Thorne, G. Watt\n\n(46)\n(47)\n(48)\n(49)\n\n\fwhere S = 2(\u016b + d \u0304 + s\u0304), s = s\u0304 = 0.1 S and d \u0304 = \u016b. The parameters Au , Ad and Ag are fixed by\nsum rules, leaving potentially 19 free parameters. In practice, to reduce the number of highly correlated\nparameters, making linear error propagation unreliable, we determine the central value of the benchmark\nfit by freeing all 19 parameters, then fix 6 of those at the best-fit values when calculating the Hessian\nmatrix used to determine the PDF uncertainties, giving a total of 13 eigenvectors. This is the same\nprocedure as used in the MSTW 2008 global fit [39,156], where there are an additional 3 free parameters\nassociated with d \u0304 \u2212 \u016b and an additional 4 free parameters associated with strangeness, giving a total of\n20 eigenvectors. Note that the parameterization used in the previous Alekhin/Thorne benchmark fits was\nconsiderably more restrictive, where the \u01ebS , \u03b3S , \u01ebg and \u03b3g parameters were set to zero, and the second\n(negative) gluon term was omitted entirely. In addition, \u01ebu was held fixed for the Thorne benchmark\nfit, leaving a total of 12 eigenvectors. We find that the more flexible gluon parameterization, allowing\nit to go negative at very small x, is very highly correlated with the value obtained for \u03b1s , and a value\nof \u03b1s (MZ ) = 0.105 is obtained if it is allowed to go free at the same time as the other parameters,\ntherefore we instead choose to fix it at \u03b1s (MZ ) = 0.112 as in the NNPDF benchmark fit.\n- Error propagation. Apart from the more flexible input parameterization, the other major difference in\nthe new MSTW version of the HERA\u2013LHC\npbenchmark fit, with respect to the previous Thorne (MRST)\nversion, is the choice of tolerance, T = \u2206\u03c72 . The MRST benchmark fit used the standard choice\nT = 1 for one-sigma uncertainties. More precisely, the distance t along each normalized eigenvector\ndirection was taken to be 1, and ideal quadratic behaviour\nabout the minimum was assumed, giving\n\u221a\nT \u2248 t = 1. The MRST global fit used T = 50 for a 90% confidence level (C.L.) uncertainty\nband; however, this is not appropriate when fitting a smaller number of data sets. Recently, a new\nprocedure has been developed [39, 156] which enables a dynamic determination of the tolerance for\neach eigenvector direction, by demanding that each data set must be described within its one-sigma\n(or 90%) C.L. limits according to a hypothesis-testing criterion, after rescaling the \u03c72 for each data set\nso that the value at the global minimum corresponds to the most probable value. Application of this\nprocedure to the MSTW benchmark fit gives T \u223c 3 for one-sigma uncertainties and T \u223c 5 for 90%\nC.L. uncertainties. For the MSTW global fit, the typical values of T required are slightly larger, with\nmore variation between different eigenvector directions. The increase in T in the global fit is mainly due\nto the inclusion of some less compatible data sets, while the greater variation in T between eigenvectors\nis due to the fact that some parameters, particularly those associated with s and s\u0304, are constrained by\nfar fewer data sets than others. In the MSTW fits, the data set normalizations are allowed to vary,\nwith the aforementioned penalty term, when determining the PDF uncertainties. For global fits this\nautomatically leads to a small increase in uncertainty compared to the MRST determinations, where data\nset normalisations were held fixed when calculating the Hessian matrix used for error propagation. In\nthe MRST benchmark fit the data set normalizations were allowed to vary. To calculate the uncertainty\nbands from the eigenvector PDF sets, we use the formula for asymmetric errors given, for example, in\nEq. (13) of Ref. [164].\n3.3.2 NNPDF approach38\nThe NNPDF approach was proposed in Ref. [165], and it was applied there and in Ref. [142] to the parameterization of the structure function F2 (x, Q2 ) with only two or more experimental data sets respectively. In\nRef. [166] it was first used for the determination of a single PDF (the isotriplet quark distribution), and in\nRef. [155] a full set of PDFs fit based on DIS data (NNPDF1.0) was presented. Because the method has been\ndiscussed extensively in these references, here we only summarize briefly its main features.\n- Error propagation. We make a Monte Carlo sample of the probability distribution of the experimental\ndata by generating an ensemble of N replicas of artificial data following a multi-gaussian distribution\ncentered on each data point with full inclusion of the experimental covariance matrix. Each replica is\nused to construct a set of PDFs, thereby propagating the statistical properties of the data Monte Carlo\nsample to a final Monte Carlo sample of PDFs. Here we shall take N = 100. The method is the same\nas discussed in Sect. 3.2.2, the only difference being the treatment of normalization errors: relative\n38\n\nContributing authors: R. D. Ball, L. Del Debbio, S. Forte, A. Guffanti, J. I. Latorre, A. Piccione, J. Rojo, M. Ubiali\n\n\fnormalizations are fitted in the H1 approach, while they are included among the systematic errors in the\nMonte Carlo data generation in the NNPDF approach (see Refs. [18, 155] for details of the respective\nprocedures) .\n- Input parameterization. Each PDF is parameterized with a functional form provided by a neural network. The architecture for the neural network is the same for all PDFs, and yields a parameterization\nwith 37 free parameters for each PDF. This is a very redundant parameterization, it is chosen in order to avoid parameterization bias; neural networks are a particularly convenient way of dealing with\nredundant parameterizations. Note that sum rules are also imposed.\n- Minimization. A redundant parameterization allows for fitting not only the underlying physical behaviour, but also statistical noise. Therefore, the minimization is stopped not at the absolute minimum\nof the \u03c72 , but rather before one starts fitting noise. This optimal stopping point is determined as follows:\nthe data in each replica are randomly assigned either to a training or to a validation set. The fit is performed on data of the training set only, while the validation set is used as a monitor. The fit is stopped\nwhen the quality of the fit to the training set keeps improving, but the quality of the fit to the validation\nset deteriorates.\n3.3.3 Comparison between the Benchmark Parton Distributions\nData Set\nZEUS97\nH1lowx97\nNMC\nNMC pd\nBCDMS\nTotal\n\n\u03c72bench /Ndata\n1.09\n1.03\n1.40\n1.24\n1.21\n1.19\n\n\u03c72global /Ndata\n1.18\n1.00\n1.45\n1.32\n1.98\n1.53\n\nTable 4: NNPDF \u03c72 for the total and each single data set, both for the benchmark and global fit.\n\nData set\nZEUS97\nH1lowx97\nNMC\nNMC pd\nBCDMS\nTotal\n\n2\n\n\u03c7diag\nbench /Ndata\n0.76\n0.53\n1.08\n0.78\n0.74\n0.76\n\n2\n\n\u03c7diag\nglobal /Ndata\n0.79\n0.54\n1.11\n0.89\n1.13\n0.89\n\nTable 5: MSTW \u03c72 for the total and each single data set, both for the benchmark and global fit. Notice that statistical and systematic\nerrors are added in quadrature and that relative data set normalizations are fitted.\n\nThe \u03c72 per data point for the NNPDF and MSTW fits are shown in Table 4 and 5 respectively. Note\nthat in the MSTW fit statistical and systematic errors are added in quadrature, so the quantity shown is the\ndiagonal contribution to the \u03c72 . The quality of the NNPDF is seen to be uniformly good. The quality of the\nMSTW is also uniform, though it cannot be compared directly because of the different way systematics are\ntreated. The comparison of each benchmark fit to the corresponding global fit will be discussed in Sect. 3.3.4\nbelow.\nIn Fig. 25 the PDFs from the NNPDF and MSTW benchmark fits presented here are compared to those\nby Thorne from Ref. [1] at the same reference scale of Q2 = 20 GeV2 used there (denoted as MRST01 in\nthe figure). The benchmark fit by Alekhin [1] is not shown as the PDFs are very close to the those by Thorne\ndisplayed in Fig. 25.\n\n\fDown antiquark distribution\n\nxd(x, Q2 = 20 GeV2)\n\nxg(x, Q2 = 20 GeV2)\n\nGluon distribution\n35\nHERA-LHC bench\n\n30\n\nNNPDF\n\n25\nMRST01\n\n20\nMSTW08\n\n1.2\nHERA-LHC bench\n\n1\nNNPDF\n\n0.8\n\nMRST01\nMSTW08\n\n0.6\n\n15\n0.4\n10\n0.2\n\n5\n\n0\n10-4\n\n-3\n\n10\n\n10-2\n\n0\n10-4\n\n10-1\n\n-3\n\n10\n\n10-2\n\n10-1\n\nx\n\nx\n\nDown valence distribution\n\n0.7\n\nxdv(x, Q2 = 20 GeV2)\n\nxuv(x, Q2 = 20 GeV2)\n\nUp valence distribution\n0.8\n\n0.45\n\nHERA-LHC bench\nNNPDF\n\n0.6\n\n0.5\nHERA-LHC bench\n\n0.4\nNNPDF\n\n0.35\n\nMRST01\n\n0.5\n\nMSTW08\n\n0.4\n\nMRST01\n\n0.3\nMSTW08\n\n0.25\n0.2\n\n0.3\n\n0.15\n0.2\n0.1\n0.1\n0\n10-4\n\n0.05\n\n-3\n\n10\n\n10-2\n\n0\n10-4\n\n10-1\n\nx\n\n-3\n\n10\n\n10-2\n\n10-1\n\nx\n\nFig. 25: Comparison of the NNPDF, MRST and MSTW benchmark fits for the gluon, d-sea, u-valence and d-valence at Q2 =\n20 GeV2 . All uncertainties shown correspond to one\u2013\u03c3 bands.\n\nFor PDFs and kinematical regions where data are available, namely the small-x gluon and sea quark\nand the large-x uv distributions, the central values of the NNPDF fit are quite close to those of the MRST\nand MSTW fits, despite the differences in methodology. The central values of the PDFs are slightly different\nfor the MRST and MSTW benchmark fits due to the use of BCDMS F2d data in the former, which affects\nmainly valence quarks. Where extrapolation is needed, such as for the dv distribution, which is constrained\nonly by the small amount of data on the ratio F2d /F2p , or the large-x sea quark, central values are rather more\ndifferent (though the Alekhin/MRST/MSTW benchmark central values are within the NNPDF error band).\nThe exception is the smallest-x gluon, where the form of the MSTW parameterization results in a very sharp\nturn-over. However, even here the uncertainty bands are close to overlapping.\nDifferences are sizeable in the estimation of uncertainties. Firstly, uncertainty bands for NNPDF benchmark are significantly larger than for the MSTW benchmark, which in turn are in general somewhat larger\nthan those for the MRST benchmark. The difference between MRST and MSTW, which are based on similar\nmethodology, is due to use of a dynamic tolerance and a more flexible gluon parameterization in MSTW (see\nSect. 3.3.1). Secondly, the width of the uncertainty band for NNPDF benchmark varies rather more than that\nof the MRST benchmark according to the PDF and the kinematic region, though this is not quite so much the\ncase comparing to MSTW benchmark. Indeed, the NNPDF uncertainties are quite small in the region between\nx = 0.01 and x = 0.1 (where there is the bulk of HERA and fixed-target data), while they blow up in the\nlarge-x region for the sea quark or the small-x gluon, where there is less or no experimental information. The\nsmallness of the uncertainty band for MSTW for the small-x valence quarks may be partially due to the lack\nof flexibility in the parameterization: note that because of sum rules, the size of uncertainties in the data and\n\n\fextrapolation region are correlated.\nFinally, the MRST/MSTW central value generally falls within the NNPDF uncertainty band, but the\nNNPDF central value tends to fall outside the MRST/MSTW uncertainty band whenever the central values\ndiffer significantly.\n3.3.4 Comparison of the Benchmark Parton Distributions and Global Fits\n\n35\n\n1.2\n\nNNPDF_bench_H-L\n\nNNPDF_bench_H-L\n\n30\n\n1\n\nNNPDF1.0\n0.8\n\nx d (x, Q2 = 20 GeV 2)\n\nx g (x, Q2 = 20 GeV 2)\n\nNNPDF1.0\n25\n\n20\n\n0.6\n\n15\n\n0.4\n\n10\n\n0.2\n\n5\n\n0\n10-4\n\n0.8\n0.7\n\n0\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\nNNPDF_bench_H-L\n\n-0.2\n10-4\n\n0.5\n\nNNPDF1.0\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\nNNPDF_bench_H-L\nNNPDF1.0\n\n0.4\n\nx dV (x, Q2 = 20 GeV 2)\n\nx uV (x, Q2 = 20 GeV 2)\n\n0.6\n0.5\n\n0.3\n\n0.4\n\n0.2\n\n0.3\n0.2\n\n0.1\n\n0.1\n0\n\n0\n10-4\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\n10-4\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\nFig. 26: Comparison of the NNPDF benchmark and reference fits for the gluon, d-sea, u-valence and d-valence at Q2 = 20 GeV2 .\n\nIn Fig. 26 we compare the NNPDF benchmark fit to the NNPDF1.0 reference fit of Ref. [155] (NNPDF\nglobal, henceforth), while in Fig. 27 we compare the MSTW benchmark fit to the MRST01 [164] (MRST\nglobal, henceforth) and MSTW08 [39, 156] global fits (MSTW global, henceforth).\nThe \u03c72 of the NNPDF benchmark and global fits are compared in Table 4, while those of the MSTW\nbenchmark and global fits are compared in Table 5. Note that for the NNPDF fits the \u03c72 is computed using the full covariance matrix, while for the MSTW fits systematic and statistical uncertainties are added in\nquadrature. Note also that the MRST and MSTW global fits are carried out in a general-mass variable flavour\nnumber scheme rather than the zero-mass variable flavour number scheme used in the corresponding benchmark fits, whereas for NNPDF both global and benchmark fits are done with a zero-mass variable flavour\nnumber scheme. Comparison of the quality of each benchmark to the corresponding global fit to the same\npoints in Table 5 shows a significant deterioration in the quality of the fit (total \u2206\u03c72 \u226b 1), especially for the\nBCDMS F2p data. All fits appear to be acceptable for all data sets: for instance, even though the \u03c72 of the\nNNPDF global fit for the benchmark subset of data is 1.98, it is equal to 1.59 [155] for the full BCDMS set of\ndata. However, the increase in \u03c72 suggests that there might be data inconsistencies.\n\n\fDown antiquark distribution\n\nxd(x, Q2 = 20 GeV2)\n\nxg(x, Q2 = 20 GeV2)\n\nGluon distribution\n25\n\nMSTW08 bench\n20\n\nMRST01 global\nMSTW08 global\n\n15\n\n1.2\n\nMSTW08 bench\n1\n\nMRST01 global\n0.8\n\nMSTW08 global\n\n0.6\n10\n0.4\n\n5\n\n0\n10-4\n\n0.2\n\n-3\n\n10\n\n10-2\n\n0\n10-4\n\n10-1\n\n-3\n\n10\n\n10-2\n\n10-1\n\nx\n\nx\n\nDown valence distribution\n\n0.7\n0.6\n\nxdv(x, Q2 = 20 GeV2)\n\nxuv(x, Q2 = 20 GeV2)\n\nUp valence distribution\n0.8\n\n0.5\n\n0.45\n\nMSTW08 bench\nMRST01 global\n\n0.4\n\nMSTW08 bench\nMRST01 global\n\n0.35\n\n0.5\n\nMSTW08 global\n\n0.4\n\nMSTW08 global\n0.3\n\n0.25\n0.2\n\n0.3\n\n0.15\n0.2\n0.1\n0.1\n0\n10-4\n\n0.05\n\n-3\n\n10\n\n10-2\n\n0\n10-4\n\n10-1\n\nx\n\n-3\n\n10\n\n10-2\n\n10-1\n\nx\n\nFig. 27: Comparison of the MSTW benchmark and MRST/MSTW global fits for the gluon, d-sea, u-valence and d-valence at\nQ2 = 20 GeV2 . All uncertainties shown correspond to one\u2013\u03c3 bands.\n\nLet us now compare each pair of benchmark and global fits. For NNPDF, the difference in central\nvalue between benchmark and reference is comparable to that found between the MRST or Alekhin global\nfits and their benchmark counterparts in Ref. [1]. However, the NNPDF global and benchmark fits remain\ncompatible within their respective error bands. Indeed, the NNPDF benchmark fit has a rather larger error\nband than the reference, as one would expect from a fit based on a rather smaller set of (compatible) data.\nSuch a behaviour was however not observed in the comparison between global and benchmark MRST and\nAlekhin fits of Ref. [1].\nIt is interesting to observe that the gluon shape at low x of the benchmark and global NNPDF disagree\nat the one \u03c3 level (though they agree at two \u03c3). This can be understood as a consequence of the fact that the\nvalue of \u03b1s in the two fits is sizably different (\u03b1s = 0.112 vs. \u03b1s = 0.119). Theoretical uncertainties related\nto the value of \u03b1s were shown in Ref. [155] to be negligible and thus not included in the NNPDF error band,\nbut of course they become relevant if \u03b1s is varied by several standard deviations (3.5 \u03c3, in this case).\nComing now to MSTW, we first notice that, as discussed in Sect. 3.3.3, the MSTW benchmark set has\nsomewhat larger uncertainty bands than the MRST benchmark set and thus also than each of the sets obtained\nfrom global fits. Consequently, the MSTW benchmark PDFs are generally far more consistent with the MSTW\nglobal fit sets than the corresponding comparison between MRST benchmark PDFs and global fit PDFs shown\nin Ref. [1], largely due to the more realistic uncertainties in the MSTW benchmark. Comparing central values\nwe see exactly the same feature in the gluon distribution as the NNPDF group, and the explanation is likewise\nthe same, highlighting possible difficulties in comparing PDFs obtained with different values of \u03b1s (MZ ).\n\n\f10\n\n0.8\n\nNNPDF_bench_H1\n\n9\n\nNNPDF1.0\n\nx d (x, Q20 = 4 GeV 2)\n\n0.5\n\n6\n\n0.4\n\n5\n\n0.3\n\n4\n\n0.2\n\n3\n\n0.1\n\n2\n\n0\n\n1\n\n-0.1\n\n0\n10-4\n\nNNPDF1.0\n\n0.6\n\n7\n\n0\n\nx g (x, Q2 = 4 GeV 2)\n\n8\n\nNNPDF_bench_H1\n\n0.7\n\n10-3\n\n10-2\nx\n\n0.7\n\nNNPDF_bench_H1\n\n0.6\n\nNNPDF1.0\n\n10-1\n\n1\n\n-0.2\n10-4\n\n0.5\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\n10-1\n\n1\n\nNNPDF_bench_H1\nNNPDF1.0\n\nx dV (x, Q2 = 4 GeV 2)\n\nx uV (x, Q2 = 4 GeV 2)\n\n0.4\n0.5\n\n0.3\n\n0\n\n0\n\n0.4\n\n0.3\n\n0.2\n\n0.2\n\n0.1\n0.1\n0\n\n0\n10-4\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\n10-4\n\n10-3\n\n10-2\nx\n\nFig. 28: Comparison of the NNPDF benchmark and reference fits for the gluon, d-sea, uv and dv at Q2 = 4 GeV2 .\n\nUnlike for the NNPDF group, the MSTW group sees some degree of incompatibility between the benchmark PDFs and the global fit PDFs for the valence quarks, particularly in the case of the down valence. This\n \u0304 which constrains valence quarks and sea quarks in an artificial manner\nmay be related to the assumption \u016b = d,\nsince there is less flexibility to alter each independently. Indeed, in the global fits there is an excess of d \u0304 over\n\u016b which maximizes at x = 0.1. Forcing equivalence of antiquark distributions might therefore lead to a deficit\nof down sea quarks and a corresponding excess of up sea quarks, and also, for the same reason, to an excess of\ndown valence quarks. These are indeed seen both in the NNPDF and MSTW benchmark fits when compared\nto the respective global fits. The effect is however well within the uncertainty bands for NNPDF, which indeed\ndo not observe any statistically significant difference between results of a fit to the reduced benchmark data\nset with the \u016b = d \u0304 assumption (as presented in Fig. 26) or without it (as presented in Ref. [155], Fig. 12).\nAs well as this important effect one sees that the main discrepancy at x = 0.1 for down valence quarks\nis greater when comparing the benchmark fits to the global MSTW fit than to the global MRST fit. This is\nbecause recent new Tevatron data on Z rapidity distributions and lepton asymmetry from W decays provide\na strong constraint on the down quark, and some of this new data shows considerable tension with other data\nsets.\n3.4 H1 Benchmark\nWe now discuss the extension of the fit using the settings of Sect. 3.1.1 to also include the NNPDF approach.\nResults are compared both to those of the NNPDF reference fit, and to those obtained by the H1 fit of Sect. 3.2\nto the same data. We then compare the NNPDF benchmark and reference, with the specific aim of addressing\n\n\fthe issue of the dependence of the results on the size of the data set (H1 dataset vs. the HERA\u2013LHC dataset\nof Sect. 3.3). Finally, the H1 and NNPDF benchmark fits are compared to each other with the purpose of\nunderstanding the impact of the respective methodologies.\n\n1.4\n\n1.4\n\n0.5\n\n1.2\n\n1.2\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n10-2\n\nNNPDF_bench_H1\nNNPDF1.0\nH197\nH100\n10-1\nx\n\n\u223c NC (x, Q2 = 6.5 GeV2)\n\u03c3\n\n0.6\n\n\u223c NC (x, Q2 = 6.5 GeV2)\n\u03c3\n\n\u223c CC (x, Q2 = 2000 GeV2)\n\u03c3\n\n3.4.1 NNPDF analysis39\n\n1\n\n0.8\n\n0.6\n\n1\n\n0.8\n\n0.6\n\nNNPDF1.0\n0.4\n\nH1\n\n0.4\n\nZEUS\n\n1\n\n0.2\n10-4\n\nFig. 29: Left: NNPDF benchmark and reference fits at\n\n10-3\n\n\u221a\n\nNNPDF_bench_H1\nH1\n\nx\n\n10-2\n\n10-1\n\n0.2\n10-4\n\n10-3\n\nx\n\n10-2\n\n10-1\n\ns = 301GeV compared to H1 charged current data. Center: NNPDF\n\nreference fit compared to H1 and ZEUS neutral current data. Right: NNPDF benchmark fit compared to H1 neutral current data.\n\nThe results of the NNPDF benchmark are compared to the NNPDF reference fit results in Fig. 28.\nThe general features of the benchmark are analogous to those of the HERA\u2013LHC benchmark discussed in\nSection 3.3.4, with some effects being more pronounced because the benchmark dataset is now even smaller.\nSpecifically, we observe that uncertainties bands blow up when data are removed: this is very clear for instance\nin the d \u0304 distribution at large-x, as a consequence of the fact that the benchmark dataset of Table 1 does not\ninclude deuterium data. The negative value of this PDF at large x is presumably unphysical and it would\ndisappear if positivity of charged current cross sections were imposed, including also the (anti-)neutrino ones.\nThe only positivity constraint in the NNPDF fit is imposed on the FL structure function [155], because this is\nthe only DIS observable whose positivity is not constrained by the full data set.\nIt is interesting to note however that this effect is not observed for the uv distribution, where instead\nthe benchmark and the reference fit show almost equal uncertainties. In order to understand this, in Fig. 29\nwe compare two situations with or without error shrinking, by examining the predictions obtained using the\nbenchmark and reference fits for some observables to the corresponding data. A first plot (left) shows the\nshrinking of the uncertainty on the prediction for the charged\u2013current cross section in the reference fit. This\nis mostly due to the CHORUS neutrino data, which are in the reference and not in the benchmark. These data\nare clearly consistent with the H1 data shown in the plot. The subsequent pair of plots compares (center) the\nprediction for the neutral\u2013current cross section from the reference fit compared to H1 and ZEUS data (both of\nwhich are used for the reference fit), and (right) from the benchmark fit to the H1 data only (which are the only\nones used in the benchmark fit). The uncertainty bands in the two fits are similar size: indeed, the ZEUS and\nH1 data display a systematic disagreement which is approximately the size of this uncertainty band. Hence,\nthe (small but significant) systematic inconsistency between the ZEUS and H1 data prevents reduction of the\nuncertainty band when the ZEUS data are added to the fit, beyond the size of this discrepancy. Therefore, the\nNNPDF methodology leads to combined uncertainties for inconsistent data which are similar to those obtained\nwith the so\u2013called PDG (or scale-factor) method [167].\nNotice that if relative normalization are fitted (as done by in the H1 approach of Sect. 3.2) instead of\nbeing treated simply as a source of systematics, this systematic inconsistency would be significantly reduced\n39\n\nContributing authors R. D. Ball, L. Del Debbio, S. Forte, A. Guffanti, J. I. Latorre, A. Piccione, J. Rojo, M. Ubiali\n\n\f10\n\n0.8\n\nNNPDF_bench_H1\n\n9\n\nH12008_bench\n\n8\n\nH12008_bench\n\n0.6\n0.5\n2\n\nx d (x, Q = 4 GeV )\n\n7\n\n2\n\n5\n4\n\n0.4\n0.3\n\n0\n\n6\n\n0\n\nx g (x, Q2 = 4 GeV2)\n\nNNPDF_bench_H1\n\n0.7\n\n0.2\n\n3\n\n0.1\n\n2\n\n0\n\n1\n\n-0.1\n\n0\n10-4\n\n10-3\n\n10-2\nx\n\n0.7\n\nNNPDF_bench_H1\n\n0.6\n\nH12008_bench\n\n10-1\n\n-0.2\n10-4\n\n1\n\n0.5\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\n10-1\n\n1\n\nNNPDF_bench_H1\nH12008_bench\n\nx dV (x, Q2 = 4 GeV2)\n\n0.5\n\n0.3\n\n0\n\n0.4\n\n0\n\nx uV (x, Q2 = 4 GeV2)\n\n0.4\n\n0.3\n\n0.2\n\n0.2\n\n0.1\n\n0.1\n0\n0\n10-4\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\n10-4\n\n10-3\n\n10-2\nx\n\nFig. 30: Comparison of the NNPDF and H1 benchmark fit for the gluon, d-sea, uv and dv at Q2 = 4 GeV2 .\n\nData Set\nH197mb\nH197lowQ2\nH197NC\nH197CC\nH199NC\nH199CC\nH199NChy\nH100NC\nH100CC\nTotal\n\n\u03c72H1 /Ndata\n0.83\n0.90\n0.69\n0.73\n0.88\n0.62\n0.35\n0.97\n1.07\n0.88\n\n\u03c72NNPDF /Ndata\n0.82\n0.87\n0.80\n0.97\n1.01\n0.84\n0.35\n1.00\n1.38\n0.96\n\nTable 6: H1 and NNPDF \u03c72 for the total and each single data set. Cross correlations among data sets are neglected to evaluate the \u03c72\nof a single data set.\n\nin the best-fit. The associate uncertainty however then appears as an addition source of systematics. This\nhappens when H1 and ZEUS data are combined in a single dataset (see Section 4.1 below). In the NNPDF\napproach, instead, this systematics is produced by the Monte Carlo procedure.\n\n\f2\n\nxG(x)\n\nFit vs H1PDF2000, Q = 4. GeV\n\n2\n\n10\n10\n\n9\n8\n\n8\n\nx g (x, Q2 = 4 GeV2)\n\n7\n6\n\n0\n\n5\n\n6\n\n4\n3\n\n4\n\n2\n\n2\n0\n\n1\n0 -4\n10\n\n10\n\n-3\n\n10\n\n-2\n\n10\n\n-1\n\n1\n\n10-4\n\nx\n\n10-3\n\n10-2\nx\n\n10-1\n\n1\n\nFig. 31: The Monte Carlo set of gluon PDFs for the H1 benchmark (left, same as Fig. 23) and the NNPDF benchmark. The red lines\nshow the one-sigma contour calculated from the Monte Carlo set, and in the H1 case the black lines show the Hessian one-sigma\ncontour.\n\n3.4.2 Comparison between the Benchmark Parton Distributions\nThe \u03c72 of the H1 and NNPDF benchmarks are given in Table 6, while the corresponding PDFs are compared\nin Fig. 30. Furthermore, in Fig. 31 we show the respective full Monte Carlo PDF sets in the case of the gluon\ndistribution.\nThe quality of the two fits is comparable, the differences in \u03c72 being compatible with statistical fluctuations. In the region where experimental information is mostly concentrated, specifically for the uv distribution\nover all the x-range and for the d \u0304 and the dv distributions in the small-x range, the results of the two fits are in\ngood agreement, though the H1 uncertainty bands are generally somewhat smaller.\nIn the region where experimental information is scarce or missing, sizable differences are found, similar\nto those observed when comparing the MRST/MSTW bench and NNPDF bench to the HERA\u2013LHC benchmark of Sect. 3.3.3. Specifically, in these regions NNPDF uncertainties are generally larger than H1 bands:\nthe width of the uncertainty band for the H1 fit varies much less between the data and extrapolation regions\nthan that of the NNPDF bench. Also, the H1 central value always falls within the NNPDF uncertainty band,\nbut the NNPDF central value tends to fall outside the H1 uncertainty band whenever the central values differ\nsignificantly. Figure 31 suggests that this may be due to the greater flexibility of the functional form in the\nNNPDF fit. Specifically, the d \u0304 quark distribution at large x does not become negative in the H1 fit, because\nthis behaviour is not allowed by the parameterization.\n\n\f4 DETERMINATION OF PARTON DISTRIBUTIONS\n4.1 Extraction of the proton PDFs from a combined fit of H1 and ZEUS inclusive DIS cross sections 40\n4.1.1 Introduction\nThe kinematics of lepton hadron scattering is described in terms of the variables Q2 , the invariant mass of\nthe exchanged vector boson, Bjorken x, the fraction of the momentum of the incoming nucleon taken by the\nstruck quark (in the quark-parton model), and y which measures the energy transfer between the lepton and\nhadron systems. The differential cross-section for the neutral current (NC) process is given in terms of the\nstructure functions by\n\u0003\n2\u03c0\u03b12 \u0002\nd2 \u03c3(e\u00b1 p)\n2\n2\n2\n2\n=\nY\nF\n(x,\nQ\n)\n\u2212\ny\nF\n(x,\nQ\n)\n\u2213\nY\nxF\n(x,\nQ\n)\n,\n+\n2\nL\n\u2212\n3\ndxdQ2\nQ4 x\n\nwhere Y\u00b1 = 1 \u00b1 (1 \u2212 y)2 . The structure functions F2 and xF3 are directly related to quark distributions,\nand their Q2 dependence, or scaling violation, is predicted by perturbative QCD. For low x, x \u2264 10\u22122 , F2\nis sea quark dominated, but its Q2 evolution is controlled by the gluon contribution, such that HERA data\nprovide crucial information on low-x sea-quark and gluon distributions. At high Q2 , the structure function\nxF3 becomes increasingly important, and gives information on valence quark distributions. The charged\ncurrent (CC) interactions also enable us to separate the flavour of the valence distributions at high-x, since\ntheir (LO) cross-sections are given by,\n4\n\u0002\n\u0003\nG2F MW\nd2 \u03c3(e+ p)\nx (\u016b + c\u0304) + (1 \u2212 y)2 (d + s) ,\n=\n2\n2\n2\n2\ndxdQ\n(Q + MW ) 2\u03c0x\n\n4\n\u0002\n\u0003\nd2 \u03c3(e\u2212 p)\nG2F MW\n2  \u0304\n=\nx\n(u\n+\nc)\n+\n(1\n\u2212\ny)\n(\nd\n+\ns\u0304)\n.\n2\n2\ndxdQ\n(Q2 + MW )2 2\u03c0x\n\nParton Density Function (PDF) determinations are usually obtained in global NLO QCD fits [168\u2013170],\nwhich use fixed target DIS data as well as HERA data. In such analyses, the high statistics HERA NC e+ p\ndata have determined the low-x sea and gluon distributions, whereas the fixed target data have determined the\nvalence distributions. Now that high-Q2 HERA data on NC and CC e+ p and e\u2212 p inclusive double differential\ncross-sections are available, PDF fits can be made to HERA data alone, since the HERA high Q2 cross-section\ndata can be used to determine the valence distributions. This has the advantage that it eliminates the need for\nheavy target corrections, which must be applied to the \u03bd-Fe and \u03bcD fixed target data. Furthermore there is\nno need to assume isospin symmetry, i.e. that d in the proton is the same as u in the neutron, since the d\ndistribution can be obtained directly from CC e+ p data.\nThe H1 and ZEUS collaborations have both used their data to make PDF fits [170], [18]. Both of these\ndata sets have very small statistical uncertainties, so that the contribution of systematic uncertainties becomes\ndominant and consideration of point to point correlations between systematic uncertainties is essential. The\nZEUS analysis takes account of correlated experimental systematic errors by the Offset Method, whereas H1\nuses the Hessian method [171]. Whereas the resulting ZEUS and H1 PDFs are compatible, the gluon PDFs\nhave rather different shapes, see Fig 38, and the uncertainty bands spanned by these analyses are comparable\nto those of the global fits.\nIt is possible to improve on this situation since ZEUS and H1 are measuring the same physics in the\nsame kinematic region. These data have been combined using a 'theory-free' Hessian fit in which the only assumption is that there is a true value of the cross-section, for each process, at each x, Q2 point [172]. Thus each\nexperiment has been calibrated to the other. This works well because the sources of systematic uncertainty in\neach experiment are rather different, such that all the systematic uncertainties are re-evaluated. The resulting\ncorrelated systematic uncertainties on each of the combined data points are significantly smaller than the statistical errors. This combined data set has been used as the input to an NLO QCD PDF fit. The consistency of\nthe input data set and its small systematic uncertainties enables us to calculate the experimental uncertainties\non the PDFs using the \u03c72 tolerance, \u2206\u03c72 = 1. This represents a further advantage compared to the global fit\nanalyses where increased tolerances of \u2206\u03c72 = 50 \u2212 100 are used to account for data inconsistencies.\n40\n\nContributing authors: A. Cooper-Sarkar, A. Glazov, G. Li for the H1-ZEUS combination group.\n\n\fQ2 =10 GeV2\n\n1\n\nQ2 =10 GeV2\n\n0.8\n\n1\n\n0.6\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n-0.2\n10-2\n\n10-1\n\n2\n\nQ =10 GeV\n\n4\n\nxg\n\n5\n2\n\n0\n\n-0.2\n10-3\n\nx1\n\n10-2\n\n10-1\n\n10\n2\n\nQ =10 GeV\n\n8\n\n2\n\n-0.2\n10-3\n\nx1\n\nxS\n\n10-3\n\n10-2\n\n10-1\n\n5\n2\n\nQ =10 GeV\n\n4\n\n10-3\n\nx1\n\nxg\n\n0\n\n2\n\n3\n\n6\n\n4\n\n2\n\n4\n\n1\n\n2\n\n1\n\n2\n\n0\n0.2\n\n0\n0.2\n\n0\n0.2\n\n0\n0.2\n\n0\n\n0\n\n-0.2\n10-2\n\n10-1\n\nx1\n\n0\n\n-0.2\n10-3\n\n10-2\n\n10-1\n\nx1\n\nx1\n\nQ =10 GeV2\n\n8\n\n2\n\n10-3\n\n10-1\n\n2\n\n6\n\n0\n\n10-2\n\n10\n\n3\n\n-0.2\n\nQ2 =10 GeV2\n\n0.8\n\n0.6\n\n-0.2\n\nxS\n\n1\n0.8\n\nxdv\n\nQ2 =10 GeV2\n\nxuv\n\nxdv\n\nxuv\n\n1\n0.8\n\n-0.2\n10-3\n\n10-2\n\n10-1\n\nx1\n\n10-3\n\n10-2\n\n10-1\n\nx1\n\nFig. 32: HERAPDFs, xuv , xdv , xS, xg at Q2 = 10GeV2 . (Left) with experimental uncertainties evaluated as for the central fit (see\ntext) and (right) with experimental uncertainties evaluated by accounting for the 47 systematic errors by the Hessian method.\n\nFor the HERAPDF0.1 fit presented here, the role of correlated systematic uncertainties is no longer\ncrucial since these uncertainties are relatively small. This ensures that similar results are obtained using either\nOffset or Hessian methods, or by simply combining statistical and systematic uncertainties in quadrature. The\n\u03c72 per degree of freedom for a Hessian fit is 553/562 and for a quadrature fit it is 428/562. For our central fit\nwe have chosen to combine the 43 systematic uncertainties which result from the separate ZEUS and H1 data\nsets in quadrature, and to Offset the 4 sources of uncertainty which result from the combination procedure.\nThe \u03c72 per degree of freedom for this fit is 477/562. This procedure results in the most conservative estimates\non the resulting PDFs as illustrated in Fig. 32 which compares the PDFs and their experimental uncertainties\nas evaluated by the procedure of our central fit and as evaluated by treating the 47 systematic uncertainties by\nthe Hessian method.\nDespite this conservative procedure, the experimental uncertainties on the resulting PDFs are impressively small and a thorough consideration of further uncertainties due to model assumptions is necessary. In\nSection 4.1.2 we briefly describe the data combination procedure. In Section 4.1.3 we describe the NLO QCD\nanalysis and model assumptions. In Section 4.1.4 we give results. In Section 4.1.5 we give a summary of the\nfit results and specifications for release of the HERAPDF0.1 to LHAPDF. In Section 4.1.6 we investigate the\npredictions of the HERAPDF0.1 for W and Z cross-sections at the LHC.\n4.1.2 Data Combination\nThe data combination is based on assumption that the H1 and ZEUS experiments measure the same cross\nsection at the same kinematic points. The systematic uncertainties of the measurements are separated, following the prescription given by the H1 and ZEUS, into point to point correlated sources \u03b1j and uncorrelated\nsystematic uncertainty, which is added to the statistical uncertainty in quadrature to result in total uncorrelated\nuncertainty \u03c3i for each bin i. The correlated systematic sources are considered to be uncorrelated between\nH1 and ZEUS. All uncertainties are treated as multiplicative i.e. proportional to the central values, which is a\ngood approximation for the measurement of the cross sections.\nA correlated probability distribution function for the physical cross sections M i,true and systematic\nuncertainties \u03b1j,true for a single experiment corresponds to a \u03c72 function:\n\n\u03c72exp\n\n\u0013\u00152\n\u0012\nP \u2202M i M i,true\ni,true \u2212 M i +\n(\u03b1\n)\nM\nj,true\nj \u2202\u03b1j\nX (\u03b1j,true )2\n\u0001 X\nMi\n+\n,\nM i,true , \u03b1j,true =\n\u0010\ni,true \u00112\n\u03c3\u03b12 j\nM\nj\ni\n\u03c3i\nMi\n\u0014\n\n(50)\n\nwhere M i are the central values measured by the experiment, \u2202M i /\u2202\u03b1j are the sensitivities to the correlated\nsystematic uncertainties and \u03c3\u03b1j are the uncertainties of the systematic sources. For more than one experiment,\ntotal \u03c72tot can be represented as a sum of \u03c72exp . The combination procedure allows to represent \u03c72tot in the\n\n\ffollowing form:\n\u0013\u00152\nP \u2202M i,ave M i,true\n(\u03b2\n)\n\u2212\n+ j\nX (\u03b2j,true )2\nX\n\u2202\u03b2j M i,ave j,true\n\u0001\n2\ni,true\n2\n+\n.\n\u03c7tot M\n, \u03b2j,true = \u03c70 +\n\u0010\n\u0011\ni,true 2\n\u03c3\u03b22j\nj\ni\n\u03c3i,ave M i,ave\nM\n(51)\n2\n2\nHere the sum runs over a union set of the cross section bins. The value of the \u03c7tot at the minimum, \u03c70 , quantifies consistency of the experiments. M i,ave are the average values of the cross sections and \u03b2j correspond\nto the new systematic sources which can be obtained from the original sources \u03b1j through the action of an\northogonal matrix. In essence, the average of several data sets allows one to represent the total \u03c72 in a form\nwhich is similar to that corresponding to a single data set, Eq. 50, but with modified systematic sources.\n\u0014\n\nM i,true\n\n\u0012\n\nM i,ave\n\nThe combination is applied to NC and CC cross section data taken with e+ and e\u2212 beams simultaneously\nto take into account correlation of the systematic uncertainties. The data taken with proton beam energies of\nEp = 820 GeV and Ep = 920 GeV are combined together for inelasticity y < 0.35, for this a small center\nof mass energy correction is applied. For the combined data set there are 596 data points and 43 experimental\nsystematic sources. The \u03c720 /dof = 510/599 is below 1, which indicates conservative estimation of the\nuncorrelated systematics.\nBesides the experimental uncertainties, four additional sources related to the assumptions made for\nthe systematic uncertainties are considered. Two of the extra sources deal with correlation of the H1 and\nZEUS data for estimation of the photoproduction background and simulation of hadronic energy scale. These\nsources introduce additional \u223c 1% uncertainty for y > 0.6 and y < 0.02 data. The third source covers\nuncertainty arising from the center of mass correction by varying FL = FLQCD to FL = 0. The resulting\nuncertainty reaches few per mille level for y \u223c 0.35. Finally, some of the systematic uncertainties, for\nexample background subtraction, may not be necessary multiplicative but rather additive, independent of the\ncross section central values. The effect of additive assumption for the errors is evaluated by comparing the\naverage obtained using Eq. 50 and an average in which M i,true /M i,ave scaling is removed for all but global\nnormalization errors.\n4.1.3 QCD Analysis\nThe QCD predictions for the structure functions are obtained by solving the DGLAP evolution equations [102,\n104, 105] at NLO in the MS scheme with the renormalisation and factorization scales chosen to be Q2 41 . The\nDGLAP equations yield the PDFs at all values of Q2 provided they are input as functions of x at some input\nscale Q20 . This scale has been chosen to be Q20 = 4GeV2 and variation of this choice is considered as one\nof the model uncertainties. The resulting PDFs are then convoluted with NLO coefficient functions to give\nthe structure functions which enter into the expressions for the cross-sections. The choice of the heavy quark\nmasses is, mc = 1.4, mb = 4.75GeV, and variation of these choices is included in the model uncertainties. For\nthis preliminary analysis, the heavy quark coefficient functions have been calculated in the zero-mass variable\nflavour number scheme. The strong coupling constant was fixed to \u03b1s (MZ2 ) = 0.1176 [167], and variations in\nthis value of \u00b10.002 have also been considered.\nThe fit is made at leading twist. The HERA data have a minimum invariant mass of the hadronic system,\n2\nof Wmin\n= 300 GeV2 and a maximum x, xmax = 0.65, such that they are in a kinematic region where\nthere is no sensitivity to target mass and large-x higher twist contributions. However a minimum Q2 cut\nis imposed to remain in the kinematic region where perturbative QCD should be applicable. This has been\nchosen to be Q2min = 3.5 GeV2 . Variation of this cut is included as one of the model uncertainties.\nW 2,\n\nA further model uncertainty is the choice of the initial parameterization at Q20 . Three types of parameterization have been considered. For each of these choices the PDFs are parameterized by the generic\nform\nxf (x) = AxB (1 \u2212 x)C (1 + Dx + Ex2 + F x3 ),\n(52)\n41\n\nThe programme QCDNUM [163] has been used and checked against the programme QCDfit [173].\n\n\fand the number of parameters is chosen by 'saturation of the \u03c72 ', such that parameters D, E, F are only varied\nif this brings significant improvement to the \u03c72 . Otherwise they are set to zero.\nThe first parameterization considered follows that used by the ZEUS collaboration. The PDFs for u\nvalence, xuv (x), d valence, xdv (x), total sea, xS(x), the gluon, xg(x), and the difference between the d and\nu contributions to the sea, x\u2206(x) = x(d \u0304 \u2212 \u016b), are parameterized.\nxuv (x) = Auv xBuv (1 \u2212 x)Cuv (1 + Duv x + Euv x2 )\nxdv (x) = Adv xBdv (1 \u2212 x)Cdv\nxS(x) = AS xBS (1 \u2212 x)CS\n\nxg(x) = Ag xBg (1 \u2212 x)Cg (1 + Dg x)\nx\u2206(x) = A\u2206 xB\u2206 (1 \u2212 x)C\u2206\n\nThe total sea is given by, xS = 2x(\u016b + d \u0304 + s\u0304 + c\u0304 + b\u0304), where q\u0304 = qsea for each flavour, u = uv + usea , d =\ndv + dsea and q = qsea for all other flavours. There is no information on the shape of the x\u2206 distribution\nin a fit to HERA data alone and so this distribution has its parameters fixed, such that its shape is consistent\nwith Drell-Yan data and its normalization is consistent with the size of the Gottfried sum-rule violation. A\nsuppression of the strange sea with respect to the non-strange sea of a factor of 2 at Q20 , is imposed consistent\nwith neutrino induced dimuon data from NuTeV. The normalisation parameters, Auv , Adv , Ag , are constrained\nto impose the number sum-rules and momentum sum-rule. The B parameters, Buv and Bdv are set equal, since\nthere is no information to constrain any difference. Finally this ZEUS-style parameterization has eleven free\nparameters.\nThe second parameterization considered follows that of the H1 Collaboration The choice of quark PDFs\nwhich are parameterized is different. The quarks are considered as u-type and d-type, xU = x(uv + usea + c),\nxD = x(dv + dsea + s), x\u016a = x(\u016b + c\u0304) and xD\u0304 = x(d \u0304 + s\u0304), assuming qsea = q\u0304, as usual. These four\n(anti-)quark distributions are parameterized separately.\nxU (x) = AU xBU (1 \u2212 x)CU (1 + DU x + EU x2 + FU x3 )\nxD(x) = AD xBD (1 \u2212 x)CD (1 + DD x)\nx\u016a (x) = A\u016a xB\u016a (1 \u2212 x)C\u016a\n\nxD\u0304(x) = AD\u0304 xBD\u0304 (1 \u2212 x)CD\u0304\nxg(x) = Ag xBg (1 \u2212 x)Cg\n\nSince the valence distributions must vanish as x \u2192 0, the parameters, A and B are set equal for xU and x\u016a ;\nAU = A\u016a , BU = B\u016a ; and for xD and xD\u0304; AD = AD\u0304 , BD = BD\u0304 . Since there is no information on the\nflavour structure of the sea it is also necessary to set B\u016a = BD\u0304 , such that there is a single B parameter for all\nfour quark distributions. The normalisation, Ag , of the gluon is determined from the momentum sum-rule and\nthe parameters DU and DD are determined by the number sum-rules. Assuming that the strange and charm\nquark distributions can be expressed as x independent fractions, fs = 0.33 and fc = 0.15, of the d and u type\nsea respectively, gives the further constraint A\u016a = AD\u0304 (1 \u2212 fs )/(1 \u2212 fc ), which ensures that \u016b = d \u0304 at low x.\nFinally this H1-style parameterization has 10 free parameters.\nThe third parameterization we have considered combines the best features of the previous two. It\nhas less model dependence than the ZEUS-style parameterization in that it makes fewer assumptions on the\nform of sea quark asymmetry x\u2206, and it has less model dependence than the H1-style parameterization in\nthat it does not assume equality of all B parameters. Furthermore, although all types of parameterization give\nacceptable \u03c72 values, the third parameterization has the best \u03c72 and it gives the most conservative experimental\nerrors. This is the parameterization which we chose for our central fit. The PDFs which are parameterized are\nxuv , xdv , xg and x\u016a , xD\u0304.\nxuv (x) = Auv xBuv (1 \u2212 x)Cuv (1 + Duv x + Euv x2 )\n\n\fQ2 =10 GeV2\n\n1\n\nQ2 =10 GeV2\n\n0.8\n\n1\n\nxdv\n\n1\n0.8\n\nxuv\n\nQ2 =10 GeV2\n\nQ2 =10 GeV2\n\n0.8\n\n1\n\n0.6\n\n0.6\n\n0.6\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.4\n\n0.4\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n0\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n2\n\nQ =10 GeV\n\n4\n\nxg\n\n5\n2\n\n0\n\n-0.2\n10-3\n\nx1\n\n10-2\n\n10-1\n\n10\n2\n\nQ =10 GeV\n\n8\n\n2\n\n0\n\n-0.2\n10-3\n\nx1\n\n10-2\n\n10-1\n\n5\n2\n\nQ =10 GeV\n\n4\n\n2\n\n0\n\n-0.2\n10-3\n\nx1\n\n10-2\n\n10-1\n\n10\n2\n\nQ =10 GeV\n\n8\n\n2\n\n-0.2\n10-3\n\nx1\n\n10-2\n\n10-1\n\n5\n2\n\nQ =10 GeV\n\n4\n\n10-3\n\nx1\n\nxg\n\n10-1\n\nxS\n\n10-2\n\nxS\n\n0\n-0.2\n10-3\n\nxg\n\n0\n\n2\n\n6\n\n3\n\n6\n\n2\n\n4\n\n2\n\n4\n\n2\n\n4\n\n1\n\n2\n\n1\n\n2\n\n1\n\n2\n\n0\n0.2\n\n0\n0.2\n\n0\n0.2\n\n0\n0.2\n\n0\n0.2\n\n0\n0.2\n\n0\n\n0\n\n-0.2\n10-2\n\n10-1\n\nx1\n\n0\n\n-0.2\n10-3\n\n10-2\n\n10-1\n\nx1\n\n0\n\n-0.2\n10-3\n\n10-2\n\n10-1\n\nx1\n\n0\n\n-0.2\n10-3\n\n10-2\n\n10-1\n\nx1\n\nx1\n\nQ =10 GeV2\n\n8\n\n3\n\n10-3\n\n10-1\n\n2\n\n6\n\n0\n\n10-2\n\n10\n\n3\n\n-0.2\n\nQ2 =10 GeV2\n\n0.8\n\n0.6\n\n-0.2\n\nxS\n\n1\n0.8\n\nxdv\n\nQ2 =10 GeV2\n\nxuv\n\nxdv\n\nxuv\n\n1\n0.8\n\n-0.2\n10-3\n\n10-2\n\n10-1\n\nx1\n\n10-3\n\n10-2\n\n10-1\n\nx1\n\nFig. 33: HERAPDFs, xuv , xdv , xS, xg and their uncertainties at Q2 = 10GeV2 . (Left) for the central fit; (centre) for the ZEUS-style\nparameterization; (right) for the H1-style parameterization\n\nModel variation\nmc\nmb\nQ2min\nQ20\nfs\nfc\n\nStandard value\n1.4\n4.75\n3.5\n4.0\n0.33\n0.15\n\nUpper Limit\n1.35\n4.3\n2.5\n2.0\n0.25\n0.12\n\nLower limit\n1.5\n5.0\n5.0\n6.0\n0.40\n0.18\n\nTable 7: Standard values of input parameters and cuts, and the variations considered to evaluate model uncertainty\n\nxdv (x) = Adv xBdv (1 \u2212 x)Cdv\nx\u016a (x) = A\u016a xB\u016a (1 \u2212 x)C\u016a\n\nxD\u0304(x) = AD\u0304 xBD\u0304 (1 \u2212 x)CD\u0304\nxg(x) = Ag xBg (1 \u2212 x)Cg\n\nThe normalisation parameters, Auv , Adv , Ag , are constrained to impose the number sum-rules and momentum\nsum-rule. The B parameters, Buv and Bdv are set equal, Buv = Bdv and the B parameters B\u016a and BD\u0304 are\nalso set equal, B\u016a = BD\u0304 , such that there is a single B parameter for the valence and another different single B\nparameter for the sea distributions. Assuming that the strange and charm quark distributions can be expressed\nas x independent fractions, fs = 0.33 and fc = 0.15, of the d and u type sea, gives the further constraint\nA\u016a = AD\u0304 (1 \u2212 fs )/(1 \u2212 fc ). The value of fs = 0.33 has been chosen to be consistent with determinations\nof this fraction using neutrino induced di-muon production. This value has been varied to evaluate model\nuncertainties. The charm fraction has been set to be consistent with dynamic generation of charm from the\nstart point of Q2 = m2c , in a zero-mass-variable-flavour-number scheme. A small variation of the value of fc\nis included in the model uncertainties. Finally this parameterization has 11 free parameters.\nIt is well known that the choice of parameterization can affect both PDF shapes and the size of the PDF\nuncertainties. Fig 33 compares the PDFs and their uncertainties as evaluated using these three different parameterizations. As mentioned earlier, the third parameterization results in the most conservative uncertainties.\nWe present results for the HERA PDFs based on the third type of parameterization, including six sources\nof model uncertainty as specified in Table 7. We also compare to results obtained by varying \u03b1s (MZ2 ) and by\nvarying the choice of parameterization to those of the ZEUS and the H1 styles of parameterization.\n4.1.4 Results\nIn Fig. 34 we show the HERAPDF0.1 superimposed on the combined data set for NC data and CC data. In\n\n\f1\n\n1\n\n1.5\n\nH1 and ZEUS Combined PDF Fit\n\n400 GeV2\n\n1\n\n2\n\nQ2 = 300 GeV2\n\n500 GeV2\n\n0.5\n\n1\n\n0.5\n\n1000 GeV2\n\n1.5\n\n1.5\n\n1\n\n0.5\n\n1\n\n0.5\n\n0.5\n\n0\n1\n\n300 GeV2\n\nApril 2008\n\n1\n\n1.5\n\n\u03c3r(x,Q2)\n\n1\n\n250 GeV2\n\nApril 2008\n\n\u03c3r(x,Q2)\n\nH1 and ZEUS Combined PDF Fit\nQ2 = 200 GeV2\n\n1.5\n\n500 GeV2\n\n650 GeV2\n\n1\n\n1\n\n800 GeV2\n\n1000 GeV2\n\n1\n\n1\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0\n\n1500 GeV2\n\n1\n\n2000 GeV2\n\n1\n\n3000 GeV2\n1\n\n0.5\n0.8\n\nHERA Structure Functions Working Group\n\n0.8\n\n0.6\n\n0.6\n\n0\n1200 GeV 2\n\n1500 GeV 2\n\n1\n\n1\n\n2000 GeV2\n1\n\n3000 GeV2\n1\n\n0.6\n0.5\n\n0.5\n\n0.4\n0.2\n0\n5000 GeV 2\n\n0.8\n\n8000 GeV 2\n\n0.6\n0.4\n0.2\n\n0.8\n\n12000 GeV2\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n20000 GeV2\n\n0\n30000 GeV2\n\n0.8\n\n10-2\n\n10-1\n\n1\n\n10-2\n\n10-1\n\n1\n\n10-2\n\n10-1\n\n0.4\n\nHERA Structure Functions Working Group\n\n1\n0.8\n\n0.4\n\n0.2\n\n0.2\n\n0\n\n5000 GeV2\n\n0.8\n\n8000 GeV2\n\n15000 GeV2\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0\n\n30000 GeV2\n\n0.8\n\n10-1\n\n10-1\n\n1\n\n1\n\n0.8\n\nx\n\n1\n\nx\n\nHERAPDF0.1 (prel.)\n\n0.6\n\n0.6\n\n+\n\n0.6\n0.4\n0.2\n\nHERAPDF0.1(prel.)\n\n0.4\n\nNC e+p (prel.)\nNC e-p (prel.)\n\n0.2\n\n0.2\n\n0\n10-2\n\n0\n\n10-1\n\nCC e p (prel.)\nCC e-p (prel.)\n\n0.4\n\n10-1\n\n1\n\n1\n\nx\n\nx\n\nFig. 34: HERA combined NC (left) and CC (right) data. The predictions of the HERAPDF0.1 fit are superimposed. The uncertainty\nbands illustrated derive from both experimental and model sources\n\n0.5\n\n0\n1.5\n\n8.5 GeV2\n\n1\n\n10 GeV 2\n\n1\n\n0.5\n0\n\n18 GeV2\n\n12 GeV 2\n\n1\n\n1\n\n0\n\n45 GeV2\n\n1\n\n0.5\n\n27 GeV 2\n\n1\n\n1\n\n0.5\n\n1\n\n0.5\n\n70 GeV 2\n1.5\n\n1\n\n1\n\n120 GeV2\n\n150 GeV2\n\n0.5\n\n10-4 10-3 10-2 10-1\n\n1 10-4 10-3 10-2 10-1\n\n1.5\n1\n\nHERAPDF0.1(prel.)\n\n1\n\nHERAPDF0.1 (prel.)\n\nx=0.02\n\n0.8\n\n0.6\n\n0.4\n\nx=0.25\n\nH1 2000 PDF\nZEUS-JETS\n\n0.2\n\nNC e+p (prel.)\nNC e-p (prel.)\n\n0.5\n0\n\n+\n\nHERA I e p (prel.)\n\n1\n\nx\n1\n\nx=0.002\n\n1\n\n90 GeV2\n\n1.5\n\nH1 and ZEUS Combined PDF Fit\n1.4\n\n1.2\n\n35 GeV2\n\n1\n\n0.5\n\n0\n\n15 GeV2\n\n1.5\n\n0.5\n\n60 GeV 2\n\n1.5\n\n1.5\n\n1\n\n1.5\n\n0.5\n\n1\n\n0.5\n\n0.5\n\n22 GeV 2\n\n1.5\n1\n\n1.5\n\n6.5 GeV2\n1\n\n10-4 10-3 10-2 10-1\n\n1 10-4 10-3 10-2 10-1\n\n1\n\nx\n\nApril 2008\n\n0.5\n\n1\n\n1.5\n\n4.5 GeV2\n1\n\n2\n\n3.5 GeV2\n1\n\n0\n1\n\n10\n\n10\n\n2\n\n10\n\n3\n\n10\n\nHERA Structure Functions Working Group\n\n1\n\n\u03c3r(x,Q )\n\n1.5\n\n2.7 GeV 2\n\nApril 2008\n\n1\n\nQ2 =\n\nHERA Structure Functions Working Group\n\n\u03c3r(x,Q2)\n\nH1 and ZEUS Combined PDF Fit\n1.5\n\n4\n\nQ2 / GeV2\n\nFig. 35: Left: HERA combined NC data at low Q2 . Right: the NC reduced cross-section vs Q2 for three x-bins. The predictions of\nthe HERAPDF0.1 fit are superimposed, together with the predictions of the ZEUS-JETS and H1PDF2000 PDFs\n\nFig 35 we show the NC data at low Q2 , and we illustrate scaling violation by showing the reduced crosssection vs. Q2 for a few representative x bins. The predictions of the HERAPDF0.1 fit are superimposed,\ntogether with the predictions of the ZEUS-JETS and H1PDF2000 PDFs.\nFig. 36 shows the HERAPDF0.1 PDFs, xuv , xdv , xS, xg, as a function of x at the starting scale\n= 4 GeV2 and at Q2 = 10 GeV2 . Fig. 37 shows the same PDFs at the scales Q2 = 100, 10000 GeV2 .\nFractional uncertainty bands are shown beneath each PDF. The experimental and model uncertainties are\nshown separately. As the PDFs evolve with Q2 the total uncertainty becomes impressively small.\n\nQ2\n\nThe total uncertainty of the PDFs obtained from the HERA combined data set is much reduced compared to the PDFs extracted from the analyses of the separate H1 and ZEUS data sets, as can be seen from\nthe summary plot Fig. 38, where these new HERAPDF0.1 PDFs are compared to the ZEUS-JETS and\nH1PDF2000 PDFs. It is also interesting to compare the present HERAPDF0.1 analysis of the combined\nHERA-I data set with an analysis of the separate data sets which uses the same parameterization and assumptions. Fig 39 makes this comparison. It is clear that it is the data combination, and not the choice of\nparameterization and assumptions, which has resulted in reduced uncertainties for the low-x gluon and sea\nPDFs.\nThe break-up of the HERAPDFs into different flavours is illustrated in Fig. 40, where the PDFs xU ,\n\n\fHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\nQ2 =10 GeV2\n\n0.8\n\n1\n\nxdv\n\nxuv\n\n1\n\n0.6\n\n0.4\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n10-2\n\n10-1\n\nx\n\n2\n\nQ =4 GeV\n\n2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n10\n\nxg\n\n5\n\n0\n\n-0.2\n10-4\n\n1\n\n2\n\nQ =4 GeV\n\n4\n\n8\n\n3\n\n6\n\n2\n\n4\n\n1\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n2\n\n0\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\n-0.2\n10-4\n\n1\n\nx\n\n10-3\n\n10-2\n\n10-1\n\n10-3\n\n10-2\n\n10-1\n\nx\n\n5\n2\n\nQ =10 GeV\n\n-0.2\n10-4\n\n1\n\n2\n\n10-2\n\n10-1\n\n2\n\n1\n\nx\n\nQ =10 GeV\n\n4\n\n8\n\n3\n\n6\n\n2\n\n4\n\n2\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n0\n\n-0.2\n10-4\n\nx\n\n10-3\n\n10\n\n1\n\n1\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\n0\n\n-0.2\n10-4\n\nxS\n\n10-3\n\nHERA Structure Function Working Group\n\n0\n\nxg\n\n0.4\n\nQ2 =10 GeV2\n\n0.8\n\n0.6\n\n0.6\n\nApril 2008\n\n0.8\n\n0.6\n\n-0.2\n10-4\n\nxS\n\nQ2 =4 GeV2\n\n10-3\n\n10-2\n\n10-1\n\n-0.2\n10-4\n\n1\n\nx\n\n10-3\n\n10-2\n\n10-1\n\nHERA Structure Function Working Group\n\n0.8\n\nApril 2008\n\nQ2 =4 GeV2\n\nH1 and ZEUS Combined PDF Fit\n\n1\n\nxdv\n\nxuv\n\nH1 and ZEUS Combined PDF Fit\n1\n\n1\n\nx\n\nFig. 36: HERAPDFs, xuv , xdv , xS, xg, at (left) Q2 = 4 GeV2 and (right) Q2 = 10 GeV2 . Fractional uncertainty bands are shown\nbeneath each PDF. The experimental and model uncertainties are shown separately as the red and yellow bands respectively\n\n0.4\n0.2\n\n1\n\nxdv\n\nxuv\n\nQ2 =10000 GeV2\n\n0.8\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n10-2\n\n10-1\n\nx\n\n2\n\nQ =100 GeV\n\n2\n\n6\n\n2\n\n4\n\n1\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n0\n10-2\n\n10-1\n\n10-1\n\nQ =100 GeV\n8\n\n3\n\n10-3\n\n10-2\n\n2\n\n4\n\n-0.2\n10-4\n\n10-3\n\n1\n\nx\n\n10\n\nxg\n\n5\n\n0\n\n-0.2\n10-4\n\n1\n\n-0.2\n10-4\n\n1\n\nx\n\n10-3\n\n10-2\n\n10-1\n\n2\n\n10-3\n\n10-2\n\n10-1\n\n2\n\n-0.2\n10-4\n\n1\n\nx\n\n40\n\nQ =10000 GeV\n\n35\n\n2\n\n10-2\n\n10-1\n\n1\n\nx\n\n2\n\nQ =10000 GeV\n\n70\n\n30\n\n60\n\n25\n\n50\n\n20\n\n40\n\n15\n\n30\n\n10\n\n20\n\n2\n\n10\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n0\n\n-0.2\n10-4\n\nx\n\n10-3\n\n80\n\n5\n\n1\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\n0\n\n-0.2\n10-4\n\nxS\n\n10-3\n\nHERA Structure Function Working Group\n\n0\n\nQ2 =10000 GeV2\n\n0.8\n\nxg\n\n0.6\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\n1\n\nApril 2008\n\n0.8\n\n0.6\n\n-0.2\n10-4\n\nxS\n\nQ2 =100 GeV2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\nHERA Structure Function Working Group\n\n0.8\n\nApril 2008\n\nQ2 =100 GeV2\n\nH1 and ZEUS Combined PDF Fit\n\n1\n\nxdv\n\nxuv\n\nH1 and ZEUS Combined PDF Fit\n1\n\n1\n\nx\n\nFig. 37: HERAPDFs, xuv , xdv , xS, xg, at (left) Q2 = 100 GeV2 and (right) Q2 = 10000 GeV2 . Fractional uncertainty bands are\nshown beneath each PDF. The experimental and model uncertainties are shown separately as the red and yellow bands respectively\n\nH1 and ZEUS Combined PDF Fit\n2\n\nQ = 10 GeV2\n\n1\n\nQ2 = 10 GeV2\n\nZEUS-JETS Fit\n\nHERAPDF0.1 (prel.)\n\n0.8\n\ntotal uncert.\n\nexp. uncert.\n\nxuv\n\nmodel uncert.\n\nH1 PDF 2000\nexp. uncert.\n\n0.6\n\nxuv\n\nHERA Structure Functions Working Group\n\n0.8\n\nApril 2008\n\nxf\n\nxf\n\n1\n\n0.6\n\ntotal uncert.\n\nxg (\u00d7 0.05)\n\n0.4\n\n0.4\n\nxdv\n\n0.2\n\nxg (\u00d7 0.05)\n\nxdv\n\n0.2\n\nxS (\u00d7 0.05)\n\nxS (\u00d7 0.05)\n0\n10-4\n\n0\n10-4\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\nFig. 38: Left: PDFs from the ZEUS-JETS and H1PDF2000 PDF separate analyses of ZEUS and H1. Right: HERAPDF0.1 PDFs\nfrom the analysis of the combined data set\n\n\fxf\n\nxf\n\n1\n\nQ2 = 10 GeV2\n0.8\n\n1\n\nQ2 = 10 GeV2\n0.8\n\nZEUS+H1 uncombined\n\nHERAPDF0.1\n\nexp. uncert.\n\nexp. uncert.\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0\n10-4\n\n10-3\n\n10-2\n\n10-1\n\n0\n10-4\n\n1\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\nx\n\nFig. 39: Left: PDFs resulting from an analysis of the H1 and ZEUS separate data sets using the same parameterization and assumptions\n\n0.5\n\n0.5\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\nQ =10 GeV\n\n2\n\n1.5\n\nQ =10 GeV\n\n1\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n0\n10\n\n10\n\n-1\n\n10\n\n1\n\nx\n\n1\n\nx\n2\n\n1.5\n\n0.5\n\n-2\n\n10-1\n\n2\n\n1\n\n-3\n\n10-2\n\n2\n\n0.5\n\n-0.2\n10-4\n\n0\n10-3\n\n-0.2\n10-4\n\n10\n\n-3\n\n-2\n\n10\n\n-1\n\n10\n\n1\n\nx\n\nxdbar\n\nxDbar\n\nx\n\n2\n2\n\n-0.2\n10-4\n\n1\n\nHERA Structure Function Working Group\n\n0\n10-1\n\n-0.2\n10-4\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\n0\n10-3\n\n10-2\n\n10-1\n\n2\n\nQ =10 GeV\n\n-0.2\n10-4\n\n1\n\nx\n\n2\n2\n\n1.5\n\n10-2\n\n10-1\n\n2\n\n1\n\nx\n\nQ =10 GeV\n\n2\n\n1.5\n\n1\n\n1\n0.5\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n10-3\n\n2\n\n0.5\n\n-0.2\n10-4\n\nApril 2008\n\nQ2 =10 GeV2\n\n0.5\n\n0\n\n10-2\n\n2\n1.5\n1\n\n0.5\n\n10-3\n\nQ2 =10 GeV2\n1.5\n1\n\n1\n\n0\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\nH1 and ZEUS Combined PDF Fit\n2\n\n0\n10\n\n-3\n\n-2\n\n10\n\n-1\n\n10\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\nHERA Structure Function Working Group\n\n1.5\n\n1\n\n-0.2\n10-4\n\nxD\n\nQ2 =10 GeV2\n\nxcbar\n\n1.5\n\n2\n\nxsbar\n\nQ2 =10 GeV2\n\nApril 2008\n\nxUbar\n\nxU\n\nH1 and ZEUS Combined PDF Fit\n2\n\nxubar\n\nas HERAPDF0.1. Right: HERAPDF0.1 PDFs from the analysis of the combined data set (experimental uncertainties only)\n\n1\n\nx\n\n \u0304 xc\u0304, xs\u0304. Fractional uncertainty bands are shown\nFig. 40: HERAPDFs at Q2 = 10GeV2 : (left) xU, xD, x\u016a , xD\u0304; (right) x\u016b, xd,\nbeneath each PDF. The experimental and model uncertainties are shown separately as the red and yellow bands respectively\n\n \u0304 xc\u0304, xs\u0304 are shown at Q2 = 10 GeV2 . The model uncertainty on these PDFs from\nxD, x\u016a , xD\u0304 and x\u016b, xd,\nvariation of Q2min , Q20 , mc and mb is modest. The model uncertainty from variation of fs and fc is also modest\nexcept for its obvious effect on the charm and strange quark distributions.\nIt is also interesting to look at the results obtained from using the ZEUS-style and H1 style parameterizations described in Section 4.1.3. In Fig. 41 these alternative parameterizations are shown as a blue\nline superimposed on the HERAPDF0.1 PDFs. These variations in parameterization produce changes in the\nresulting PDFs which are comparable to the experimental uncertainties in the measured kinematic range. A\nfurther variation of parameterization originates from the fact that, if the D parameter for the gluon is allowed\nto be non-zero, then each type of parameterization yields a double minimum in \u03c72 such that the gluon may\ntake a smooth or a 'humpy' shape. Although the lower \u03c72 is obtained for the for the smooth shape, the \u03c72\nfor the 'humpy' shape is still acceptable. The PDFs for the 'humpy' version of our chosen form of parameterization are compared to the standard version in Fig. 42, where they are shown as a blue line superimposed\non the HERAPDF0.1 PDFs. This comparison is shown at Q2 = 4GeV2 , where the difference is the greatest.\nNevertheless the resulting PDFs are comparable to those of the standard choice. This explains a long-standing\ndisagreement in the shape of the gluon obtained by the separate ZEUS-JETS and H1PDF200 analyses. The\nZEUS data favoured the smooth shape and the H1 data favoured the 'humpy' shape. However the precision\nof the combined data set results in PDFs for these shapes which are not significantly different in the measured\nkinematic region.\n\n\f0.4\n0.2\n\nxdv\n\nQ2 =10 GeV2\n\n0.8\n\n1\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n10-2\n\n10-1\n\nxg\n\n5\n\nQ2 =10 GeV2\n\n8\n6\n\n2\n\n4\n\n1\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n0\n10-2\n\n10-1\n\n1\n\nx\n\n10-2\n\n10-1\n\n1\n\nx\n\nQ2 =10 GeV2\n\n3\n\n10-3\n\n10-3\n\n10\n\n4\n\n-0.2\n10-4\n\n0\n\n-0.2\n10-4\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\n10-3\n\n10-2\n\n10-1\n\n5\n\nQ2 =10 GeV2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n10\n\nQ2 =10 GeV2\n\n4\n\n8\n\n3\n\n6\n\n2\n\n4\n\n1\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n0\n\n-0.2\n10-4\n\nx\n\n-0.2\n10-4\n\n1\n\nx\n\n0\n\n1\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\nH1 param.\n\n0\n\n-0.2\n10-4\n\nxS\n\n10-3\n\nHERA Structure Function Working Group\n\n0\n\nQ2 =10 GeV2\n\n0.8\n\nxg\n\n0.6\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\nZEUS param.\n\n1\n\nApril 2008\n\n0.8\n\n0.6\n\n-0.2\n10-4\n\nxS\n\nQ2 =10 GeV2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\nHERA Structure Function Working Group\n\n0.8\n\nH1 and ZEUS Combined PDF Fit\n\n1\n\nxuv\n\nQ2 =10 GeV2\n\nApril 2008\n\nxdv\n\nxuv\n\nH1 and ZEUS Combined PDF Fit\n1\n\n1\n\nx\n\nFig. 41: HERAPDFs at Q2 = 10GeV2 : with the results for the ZEUS-style parameterization (left) and for the H1-style parameterization (right) superimposed as a blue line.\n\nQ2 =4 GeV2\n\n0.8\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0\n\n0\n\n0.2\n\n0.2\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n'humpy' param.\n\n0\n10\n\n-3\n\n-2\n\n10\n\n-1\n\n10\n\n-0.2\n10-4\n\n1\n\nx\n\nxg\n\n5\n\nQ2 =4 GeV2\n\n10-2\n\n10-1\n\n1\n\nx\n\nQ2 =4 GeV2\n8\n\n3\n\n6\n\n2\n\n4\n\n1\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n10-3\n\n10\n\n4\n\n-0.2\n10-4\n\nQ2 =4 GeV2\n\n0\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\nHERA Structure Function Working Group\n\n0\n\nxS\n\n1\n0.8\n\n0.6\n\n-0.2\n10-4\n\nApril 2008\n\nxdv\n\nxuv\n\nH1 and ZEUS Combined PDF Fit\n1\n\n1\n\nx\n\nFig. 42: HERAPDFs at Q2 = 4GeV2 : with the results for the humpy version superimposed as a blue line.\n\n\fHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\u03b1_s(Mz)=0.1156\n\nQ2 =10 GeV2\n\n0.8\n\n1\n\nxdv\n\nxuv\n\n1\n\n0.6\n\n0.4\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.2\n\n0\n\n0\n\n0\n\n0\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0.2\n\n0\n10-2\n\n10-1\n\nx\n\nQ =10 GeV\n\nxg\n\n5\n2\n\n-0.2\n10-4\n\n1\n\n2\n\n0\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n10\n2\n\nQ =10 GeV\n\n4\n\n8\n\n3\n\n6\n\n2\n\n4\n\n1\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n2\n\n0\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\n10-3\n\n10-2\n\n10-1\n\nx\n\n5\n2\n\nQ =10 GeV\n\n-0.2\n10-4\n\n1\n\n2\n\n10-2\n\n10-1\n\n2\n\nQ =10 GeV\n\n4\n\n8\n\n3\n\n6\n\n2\n\n4\n\n1\n\nx\n2\n\n2\n\n0\n\n0\n\n0.2\n\n0.2\n\n0\n\n0\n\n-0.2\n10-4\n\nx\n\n10-3\n\n10\n\n1\n\n1\n\nHERAPDF0.1(prel.)\nexp. uncert.\nmodel uncert.\n\u03b1_s(Mz)=0.1196\n\n0\n\n-0.2\n10-4\n\nxS\n\n10-3\n\nHERA Structure Function Working Group\n\n0\n\nxg\n\n0.4\n\nQ2 =10 GeV2\n\n0.8\n\n0.6\n\n0.6\n\nApril 2008\n\n0.8\n\n0.6\n\n-0.2\n10-4\n\nxS\n\nQ2 =10 GeV2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\nx\n\n-0.2\n10-4\n\n10-3\n\n10-2\n\n10-1\n\nHERA Structure Function Working Group\n\n0.8\n\nApril 2008\n\nQ2 =10 GeV2\n\nH1 and ZEUS Combined PDF Fit\n\n1\n\nxdv\n\nxuv\n\nH1 and ZEUS Combined PDF Fit\n1\n\n1\n\nx\n\nFig. 43: HERAPDFs at Q2 = 10GeV2 : with the results for \u03b1s (MZ2 ) = 0.1156 (left) and for \u03b1s (MZ2 ) = 0.1196 (right) superimposed\n\n1\n\nQ2 = 10 GeV2\n\nxf\n\nxf\n\nas a blue line.\n\n0.8\n\nQ2 = 10 GeV2\n\n0.8\n\nxg (\u00d7 0.05)\n0.6\n\nHERAPDF0.1(prel.)\n\nxg (\u00d7 0.05)\nxuv\n0.6\n\nCTEQ6.1M 68%CL\n\n0.4\n\nHERAPDF0.1(prel.)\n\nxuv\n\nMRST01 68% CL\n\n0.4\n\nxdv\n\nxS (\u00d7 0.05)\n\nxdv\n\nxS (\u00d7 0.05)\n\n0.2\n\n0\n10-4\n\n1\n\n0.2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\n0\n10-4\n\n10-3\n\n10-2\n\nx\n\n10-1\n\n1\n\nx\n\nFig. 44: HERAPDFs at Q2 = 10GeV2 compared to the PDFs from CTEQ6.1 and MRST01\n\nIt is also interesting to compare the PDFs for the standard choice to those obtained with a different input\nvalue of \u03b1s (MZ2 ). The uncertainty on the current PDG value of \u03b1s (MZ2 ) is \u00b10.002 and thus we vary our central\nchoice by this amount. The results are shown in Fig. 43, where we can see that this variation only affects the\ngluon PDF, such that the larger(smaller) value of \u03b1s (MZ2 ) results in a harder(softer) gluon as predicted by the\nDGLAP equations. The change is outside total uncertainty bands of the standard fit. Finally, Figs. 44 and\n45 compare the HERAPDF0.1 PDFs to those of the CTEQ and the MRST/MSTW groups respectively. The\nuncertainty bands of the CTEQ and MRST/MSTW analyses have been scaled to represent 68% CL limits for\ndirect comparability to the HERAPDF0.1. The HERAPDF0.1 analysis has much improved precision on the\nlow-x gluon.\n4.1.5 Summary of HERAPDF0.1 results\nNow that high-Q2 HERA data on NC and CC e+ p and e\u2212 p inclusive double differential cross-sections are\navailable, PDF fits can be made to HERA data alone, since the HERA high Q2 cross-section data can be\nused to determine the valence distributions and HERA low Q2 cross-section data can be used to determine\nthe Sea and gluon distributions. The combined HERA-I data set, of neutral and charged current inclusive\ncross-sections for e+ p and e\u2212 p scattering, has been used as the sole input for an NLO QCD PDF fit in the\nDGLAP formalism. The consistent treatment of systematic uncertainties in the joint data set ensures that\n\n\fQ2 = 10 GeV2\n\nxf\n\nxf\n\n1\n\n0.8\n\nQ2 = 10 GeV2\n\n0.8\n\nxg (\u00d7 0.05)\n0.6\n\nHERAPDF0.1(prel.)\n\nxg (\u00d7 0.05)\nxuv\n0.6\n\nCTEQ6.5M 68%CL\n\n0.4\n\nHERAPDF0.1(prel.)\n\nxuv\n\nMSTW08 68% CL\n\n0.4\n\nxdv\n\nxS (\u00d7 0.05)\n\nxdv\n\nxS (\u00d7 0.05)\n\n0.2\n\n0\n10-4\n\n1\n\n0.2\n\n10-3\n\n10-2\n\n10-1\n\n1\n\n0\n10-4\n\n10-3\n\n10-2\n\n10-1\n\nx\n\n1\n\nx\n\nFig. 45: HERAPDFs at Q2 = 10GeV2 compared to the PDFs from CTEQ6.5 and MSTW08(prel.)\n\nexperimental uncertainties on the PDFs can be calculated without need for an increased \u03c72 tolerance. This\nresults in PDFs with greatly reduced experimental uncertainties compared to the separate analyses of the ZEUS\nand H1 experiments. Model uncertainties, including those arising from parameterization dependence, have\nalso been carefully considered. The resulting HERAPDFs (called HERAPDF0.1) have improved precision at\nlow-x compared to the global fits. this will be important for predictions of the W and Z cross-sections at the\nLHC, as explored in the next Section.\nThese PDFs have been released on LHAPDF in version LHAPDF.5.6: they consist of a central value\nand 22 experimental eigenvectors plus 12 model alternatives. The user should sum over Nmem=1,22 for\nexperimental uncertainties and over Nmem=1,34 for total uncertainties.\n4.1.6 Predictions for W and Z cross-sections at the LHC using the HERAPDF0.1\nAt leading order (LO), W and Z production occur by the process, q q\u0304 \u2192 W/Z, and the momentum fractions\nM\ncentre of mass\nof the partons participating in this subprocess are given by, x1,2 = \u221a\ns exp(\u00b1y), where M is the \u221a\n\u221a\nenergy of the subprocess, M = MW or MZ , s is the centre of mass energy of the reaction ( s = 14 TeV\n(E+pl)\nat the LHC) and y = 21 ln (E\u2212pl)\ngives the parton rapidity. The kinematic plane for LHC parton kinematics\nis shown in Fig. 46. Thus, at central rapidity, the participating partons have small momentum fractions,\nx \u223c 0.005. Moving away from central rapidity sends one parton to lower x and one to higher x, but over the\ncentral rapidity range, |y| < 2.5, x values remain in the range, 5 \u00d7 10\u22124 < x < 5 \u00d7 10\u22122 . Thus, in contrast\nto the situation at the Tevatron, the scattering is happening mainly between sea quarks. Furthermore, the high\nscale of the process Q2 = M 2 \u223c 10, 000 GeV2 ensures that the gluon is the dominant parton, see Fig. 46,\nso that these sea quarks have mostly been generated by the flavour blind g \u2192 q q\u0304 splitting process. Thus the\nprecision of our knowledge of W and Z cross-sections at the LHC is crucially dependent on the uncertainty\non the momentum distribution of the low-x gluon.\nHERA data have already dramatically improved our knowledge of the low-x gluon, as discussed in earlier proceedings of the HERALHC workshop [1]. Now that the precision of HERA data at small-x have been\ndramatically improved by the combination of H1 and ZEUS HERA-I data, we re-investigate the consequences\nfor predictions of W, Z production at the LHC.\nPredictions for the W/Z cross-sections, decaying to the lepton decay mode, using CTEQ, ZEUS PDFs\nand the HERAPDF0.1 are summarised in Table 8. Note that the uncertainties of CTEQ PDFS have been\nrescaled to represent 68% CL, in order to be comparable to the HERA PDF uncertainties. The precision on\nthe predictions of the global fits (CTEQ6.1/5 and ZEUS-2002) for the total W/Z cross-sections is \u223c 3% at\n68% CL. The precision of the ZEUS-2005 PDF fit prediction, which used only ZEUS data, is comparable,\nsince information on the low-x gluon is coming from HERA data alone. The increased precision of the\nHERAPDF0.1 low-x gluon PDF results in increased precision of the W/Z cross-section predictions of \u223c 1%.\n\n\fLHC parton kinematics\n9\n\n10\n\n8\n\n10\n\nx1,2 = (M/14 TeV) exp(\u00b1y)\nQ=M\n\nM = 10 TeV\n\n7\n\n10\n\n6\n\nM = 1 TeV\n\n5\n\n10\n\n4\n\nM = 100 GeV\n\n10\n\n2\n\n2\n\nQ (GeV )\n\n10\n\n3\n\n10\n\ny=\n\n6\n\n4\n\n2\n\n0\n\n2\n\n4\n\n6\n\n2\n\n10\n\nM = 10 GeV\n\n1\n\nfixed\ntarget\n\nHERA\n\n10\n\n0\n\n10\n-7\n10\n\n-6\n\n10\n\n-5\n\n10\n\n-4\n\n-3\n\n10\n\n10\n\n-2\n\n10\n\n-1\n\n10\n\n0\n\n10\n\nx\nFig. 46: Left plot: The LHC kinematic plane (thanks to James Stirling). Right plot: Typical PDF distributions at Q2 = 10, 000 GeV2 .\n\nPDF Set\nCTEQ6.1\nCTEQ6.5\nZEUS-2002\nZEUS-2005\nHERAPDF0.1\n\n\u03c3(W + ).B(W + \u2192 l+ \u03bdl )\n11.61 \u00b1 0.34 nb\n12.47 \u00b1 0.28 nb\n12.07 \u00b1 0.41 nb\n11.87 \u00b1 0.45 nb\n12.14 \u00b1 0.13 nb\n\n\u03c3(W \u2212 ).B(W \u2212 \u2192 l\u2212 \u03bd\u0304l )\n8.54 \u00b1 0.26 nb\n9.14 \u00b1 0.22 nb\n8.76 \u00b1 0.30 nb\n8.74 \u00b1 0.31 nb\n9.08 \u00b1 0.14 nb\n\n\u03c3(Z).B(Z \u2192 l+ l\u2212 )\n1.89 \u00b1 0.05 nb\n2.03 \u00b1 0.04 nb\n1.89 \u00b1 0.06 nb\n1.97 \u00b1 0.06 nb\n1.99 \u00b1 0.025 nb\n\nTable 8: LHC W/Z cross-sections for decay via the lepton mode, for various PDFs, with 68% CL uncertainties.\n\nIt is interesting to consider the predictions as a function of rapidity. Fig 47 shows the predictions\nfor W + , W \u2212 , Z production as a function of rapidity from the HERAPDF0.1 PDF fit and compares them\nto the predictions from a PDF fit, using the same parameterization and assumptions, to the H1 and ZEUS\ndata from HERA-I uncombined. The increase precision due to the combination is impressive. Fig. 48 show\nthe predictions for W + , W \u2212 , Z production as a function of rapidity from the CTEQ6.1, 6.6 and MRST01\nPDF fits for comparison. The uncertainties on the CTEQ and MRST PDF predictions have been rescaled to\nrepresent 68% CL limits, for direct comparability to the HERAPDF0.1 uncertainties. At central rapidity these\nlimits give an uncertainty on the boson cross-sections of \u223c 5%, (\u223c 3%),(\u223c 2%) for CTEQ6.1, (CTEQ6.6),\n(MRST01) compared to \u223c 1% for the HERAPDF0.1.\n\nSo far, only experimental uncertainties have been included in these evaluations. It is also necessary to\ninclude model uncertainties. Fig. 49 shows the W + , W \u2212 , Z rapidity distributions including the six sources\nof model uncertainty detailed in Section 4.1.3. These model uncertainties increase the total uncertainty at\ncentral rapidity to \u223c 2%. Further uncertainty due to the choice of \u03b1s (MZ ) is small because, although a lower\n(higher) choice results in a larger (smaller) gluon at low x, the rate of QCD evolution is lower (higher) and this\nlargely compensates. Uncertainties due to the choice of parameterization also have little impact on the boson\nrapidity spectra in the central region as illustrated in Fig. 49 by the superimposed blue line, which represents\nthe alternative 'humpy' gluon parameterization (see Sec. 4.1.4).\nSince the PDF uncertainty feeding into the W + , W \u2212 and Z production is mostly coming from the\n\n\fW and Z rapidity distributions\n\nW and Z rapidity distributions\n\n1.5\n\n1.5\n\n1.5\n\n1\n0.5\n\n1\n0.5\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n-4\n\ny\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n0.6\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n0.6\n\n0.4\n\n0.5\n\n0.5\n\n0.3\n\n0.3\n0.4\n\n0.3\n\nAW\n\n0.2\n\n0.3\n\n0.2\n\nAW\n\nZ\n\n0.4\n\nZ\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0.4\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\nW-\n\n2\n\n1.5\n\nW+\n\n2\n\nW-\n\n2\n\nW+\n\n2\n\n0.2\n\n0.2\n\n0.1\n\n0.1\n0.1\n\n0\n\n0.1\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n-4\n\ny\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n0.15\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\ny\n\n0.15\n\nHERAPDF0.1\nexp uncert.\n\n0.05\n\nZEUS+H1 PDF\n\n0.1\n\nRZW\n\nRZW\n\n0.1\n\nexp uncert.\n\n0.05\n\n0\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\nFig. 47: The W + , W \u2212 , Z rapidity distributions, AW and RZW (see text) and their uncertainties as predicted by (left) HERAPDF0.1\n(right) a similar fit to the uncombined ZEUS and H1 data from HERA-I.\n\nW and Z rapidity distributions\n\nW and Z rapidity distributions\n1.5\n\n1.5\n\n1.5\n\n1.5\n\n0\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-4\n\n-3 -2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n-3 -2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\nZ\n\nAW\n\nZ\n\nAW\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n0\n\n-4\n\n-3 -2\n\n-1\n\n0\n\nRZW\n\nexp uncert.\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n-4\n\n-3 -2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n-4\n\n-3 -2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n0.6\n\n0.3\n\n0.2\n\n0.1\n0\n\n-4\n\n-3 -2\n\n-1\n\n0\n\nCTEQ6.6\n\n0.1\n\nexp uncert.\n\n0.05\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\ny\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\ny\n\n0.15\n\n0\n\n-4\n\n4\n\n0.2\n\n0\n\nRZW\n\nCTEQ6.1\n\n0\n\n3\n\n0.1\n\n0.15\n\n0.05\n\n2\n\n0.1\n\n0.15\n\n0.1\n\n1\n\n0.2\n\n0\n\n-2\n\n0\n\n0.4\n\n0.1\n\n-3\n\n-1\n\n0.3\n\n0.1\n\n-4\n\n-2\n\n0.5\n\n0.3\n\n0.2\n\n0.2\n\n0.1\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n-3\n\n0.4\n\n0.3\n\n0\n\n-4\n\n0.4\n\n0.3\n0.4\n\n0.2\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0.5\n\n0.3\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n-4\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0.6\n\n0.4\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0.5\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0.6\n\n0.4\n\n1\n0.5\n\nMRST01\n\n0.1\n\nRZW\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n1\n0.5\n\nAW\n\n1\n\nW-\n\n1.5\n\nW+\n\n2\n\n1.5\n\nW-\n\n2\n\nW+\n\n2\n\nW-\n\n2\n\nW+\n\n2\n\n0.5\n\nZ\n\nW and Z rapidity distributions\n\n2\n\nexp uncert.\n\n0.05\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\nFig. 48: The W + , W \u2212 , Z rapidity distributions, AW and RZW (see text) and their uncertainties (scaled to 68% CL) as predicted by\n(left) CTEQ6.1, (middle) CTEQ6.6, right (MRST01\n\n\fW and Z rapidity distributions\n\nLepton rapidity distributions\n\n1.5\n\n1.5\n\n1.5\n\n1\n0.5\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n1\n0.5\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n0.3\n\n0.6\n\n0.4\n\n1\n0.5\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\nl-\n\n2\n\n1.5\n\nl+\n\n2\n\nW-\n\n2\n\nW+\n\n2\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\ny\n\n0.2\n\n0.5\n0.3\n\n0.1\n\nRZl\n\nAl\n\n0.3\n\nAW\n\nZ\n\n0.15\n\n0.2\n\n0.4\n0.2\n\n0.1\n\n0.2\n\n0.1\n\n0.05\n0.1\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n0\n\n0\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\n0\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\ny\n\ny\n\n0.15\n\nRZW\n\n0.1\n\n0.05\n\nHERAPDF0.1\nexp. uncert.\n\nHERAPDF0.1\nexp. uncert.\n\nmodel uncert.\n'humpy' param.\n\nmodel uncert.\n'humpy' param.\n\n0\n\n0.1\n0.05\n0\n-0.05\n-0.1\n\n-4\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n4\n\ny\n\nFig. 49: Left: the W + , W \u2212 , Z rapidity distributions, AW , and RZW (see text) and their experimental uncertainties (red) and model\nuncertainties (yellow). Right: the l+ , l\u2212 rapidity distributions, Al and RZl (see text) and their experimental and model uncertainties.\nThe superimposed blue line represents the results of the alternative 'humpy' gluon parameterization.\n\ngluon PDF, for all three processes, there is a strong correlation in their uncertainties, which can be removed\nby taking ratios. Figs. 47, 48 and 49 also show the W asymmetry\nAW = (W + \u2212 W \u2212 )/(W + + W \u2212 ).\nThe experimental PDF uncertainty on the asymmetry is larger (\u223c 5% for both CTEQ and HERAPDFs, \u223c 7%\nfor the MRST01 PDFs) than that on the individual distributions and the variation between PDF sets is also\nlarger - compare the central values of the CTEQ and MRST predictions, which are almost 25% discrepant.\nThis is because the asymmetry is sensitive to the difference in the valence PDFs, uv \u2212 dv , in the low-x region,\n5 \u00d7 10\u22124 < x < 5 \u00d7 10\u22122 , where there is no constraint from current data. To see this consider that at LO,\nAW \u223c (ud \u0304 \u2212 d\u016b)/(ud \u0304 + d\u016b + cs\u0304 + sc\u0304)\nand that d \u0304 \u223c \u016b at low-x. (Note that the cs\u0304 and sc\u0304 contributions cancel out in the numerator). The discrepancy\nbetween the CTEQ and MRST01 asymmetry predictions at y = 0 can be quantitatively understood by considering their different valence PDFs (see Figs. 44, 45 in Sec. 4.1.4). In fact a measurement of the asymmetry at\nthe LHC will provide new information to constrain these PDFs.\nBy contrast, the ratio\nRZW = Z/(W + + W \u2212 ),\nalso shown in Figs. 47, 48 and 49, has very small PDF uncertainties (both experimental and model) and there\nis no significant variation between PDF sets. To understand this consider that at LO\nRZW = (u\u016b + dd \u0304 + cc\u0304 + ss\u0304)/(ud \u0304 + d\u016b + cs\u0304 + sc\u0304)\n(modulo electroweak couplings) and that d \u0304 \u223c \u016b at low-x\nunderstanding of Standard Model Physics at the LHC.\n\n42 .\n\nThis will be a crucial measurement for our\n\nHowever, whereas the Z rapidity distribution can be fully reconstructed from its decay leptons, this is\nnot possible for the W rapidity distribution, because the leptonic decay channels which we use to identify the\nW 's have missing neutrinos. Thus we actually measure the W 's decay lepton rapidity spectra rather than the\n42\n\nThere is some small model dependence from the strange sea fraction accounted for in both HERAPDF0.1 and in CTEQ6.6 PDFs.\n\n\fW rapidity spectra. Fig. 49 also shows the rapidity spectra for positive and negative leptons from W + and\nW \u2212 decay, the lepton asymmetry,\nAl = (l+ \u2212 l\u2212 )/(l+ + l\u2212 )\nand the ratio\nRZl = Z/(l+ + l\u2212 )\nA cut of, ptl > 25 GeV, has been applied on the decay lepton, since it will not be possible to trigger on leptons\nwith small ptl . A particular lepton rapidity can be fed from a range of W rapidities so that the contributions\nof partons at different x values is smeared out in the lepton spectra, but the broad features of the W spectra\nremain.\nIn summary, these investigations indicate that PDF uncertainties, deriving from experimental error, on\npredictions for the W, Z rapidity spectra in the central region, have reached a precision of \u223c 1%, due to the\ninput of the combined HERA-I data. This level of precision is maintained when using the leptons from the\nW decay and gives us hope that we could use these processes as luminosity monitors43 . However, model\ndependent uncertainties must now be considered very carefully. The current study will be repeated using a\ngeneral-mass variable-flavour scheme for heavy quarks.\nThe predicted precision on the ratios RZW , RZl is even better since model uncertainties are also very\nsmall giving a total uncertainty of \u223c 1%. This measurement may be used as a SM benchmark. However the\nW and lepton asymmetries have larger uncertainties (5 \u2212 7%). A measurement of these quantities would give\nnew information on valence distributions at small-x.\n4.2 Measurements of the Proton Structure Function FL at HERA 44\n4.2.1 Introduction\nThe inclusive deep inelastic ep scattering (DIS) cross section can at low Q2 be written in terms of the two\nstructure functions, F2 and FL , in reduced form as\n\u03c3r (x, Q2 , y) \u2261\n\nQ4 x\ny2\nd2 \u03c3\n2\n*\n=\nF\n(x,\nQ\n)\n\u2212\n* FL (x, Q2 ) ,\n2\ndxdQ2 2\u03c0\u03b12 Y+\nY+\n\n(53)\n\nwhere Q2 = \u2212q 2 is the negative of the square of the four-momentum transferred between the electron45 and\nthe proton, and x = Q2 /2qP denotes the Bjorken variable, where P is the four-momentum of the proton. The\ntwo variables are related through the inelasticity of the scattering process, y = Q2 /sx, where s = 4Ee Ep\nis the centre-of-mass energy squared determined from the electron and proton beam energies, Ee and Ep . In\neq. 53, \u03b1 denotes the fine structure constant and Y+ = 1 + (1 \u2212 y)2 .\n\nThe two proton structure functions F2 and FL are related to the cross sections of the transversely and\nlongitudinally polarised virtual photons interacting with protons, \u03c3L and \u03c3T , according to FL \u221d \u03c3L and\nF2 \u221d (\u03c3L + \u03c3T ). Therefore the relation 0 \u2264 FL \u2264 F2 holds. In the Quark Parton Model (QPM), F2 is\nthe sum of the quark and anti-quark x distributions, weighted by the square of the electric quark charges,\nwhereas the value of FL is zero [174]. The latter follows from the fact that a quark with spin 21 cannot absorb\na longitudinally polarised photon.\n\nIn Quantum Chromodynamics (QCD), FL differs from zero, receiving contributions from quarks and\nfrom gluons [175]. At low x and in the Q2 region of deep inelastic scattering the gluon contribution greatly\nexceeds the quark contribution. Therefore FL is a direct measure of the gluon distribution to a very good\napproximation. The gluon distribution is also constrained by the scaling violations of F2 as described by\nthe DGLAP QCD evolution equations [102\u2013105, 176]. An independent measurement of FL at HERA, and its\ncomparison with predictions derived from the gluon distribution extracted from the Q2 evolution of F2 (x, Q2 ),\n43\nA caveat is that the current study has been performed using PDF sets which are extracted using NLO QCD in the DGLAP\nformalism. The extension to NNLO gives small corrections \u223c 1%. However, there may be much larger uncertainties in the theoretical\ncalculations because the kinematic region involves low-x. There may be a need to account for ln(1/x) resummation or high gluon\ndensity effects.\n44\nContributing authors: J. Grebenyuk, V. Lendermann\n45\nThe term electron is used here to denote both electrons and positrons unless the charge state is specified explicitly.\n\n\fthus represents a crucial test on the validity of perturbative QCD (pQCD) at low x. Moreover, depending on\nthe particular theoretical approach adopted, whether it be a fixed order pQCD calculation, a re-summation\nscheme, or a color dipole ansatz, there appear to be significant differences in the predicted magnitude of FL at\nlow Q2 . A measurement of FL may be able to distinguish between these approaches.\nPreviously the structure function FL was extracted by the H1 collaboration from inclusive data at high\ny using indirect methods, as discussed in Sect. 4.2.2. A preliminary measurement was also presented by the\nZEUS collaboration using initial state radiation (ISR) events [177], although the precision of this measurement\nwas limited.\nTo make a direct measurement of FL , reduced cross sections must be measured at the same x and Q2\nbut with different y values. This can be seen from eq. 53 which states that FL (x, Q2 ) is equal to the partial\nderivative \u2202\u03c3r (x, Q2 , y)/\u2202(y 2 /Y+ ). Due to the relationship y = Q2 /xs this requires data to be collected at\ndifferent beam-beam centre-of-mass energies, which was done in the last year of HERA running. To maximize\nthe precision of this procedure, the measurable range of y 2 /Y+ had to be maximised for each fixed x and Q2 .\nThis was achieved by operating HERA at the lowest attainable centre-of-mass energy and by measuring this\ndata up to the highest possible value of y. An intermediate HERA centre-of-mass energy was also chosen, to\nimprove the precision of FL extraction and to act as a consistency check. More specifically, between March\nand June 2007, HERA was operated with proton beam energies, Ep = 460 GeV and 575 GeV, compared to the\nprevious nominal value of 920 GeV. The electron beam energy was unaltered at Ee = 27.6 GeV. Thus, three\ndata sets, referred to the high- (HER), middle- (MER) and low-energy running (LER) samples, were collected\n\u221a\nwith s = 318 GeV, 251 GeV and 225 GeV, respectively. The integrated luminosities of the data sets used\nby ZEUS (H1) to measure FL are 32.8 (21.6) pb\u22121 for HER, 6 (6.2) pb\u22121 for MER and 14 (12.4) pb\u22121 for\nLER. The specific issues of the recent H1 and ZEUS analyses are discussed in Sect. 4.2.3, and the results are\npresented in Sect. 4.2.4.\n4.2.2 Indirect FL Extraction by H1\nH1 extracted FL from inclusive data using several indirect methods, which exploit the turn over of the reduced\ncross section at high y due to the FL contribution. The basic principle is the following. First, the reduced\nneutral current cross section \u03c3r is measured in a y range, where the FL contribution is negligible and thus the\nrelation \u03c3r = F2 holds very well. Afterward, based on some theoretical assumption, the knowledge of F2 is\nextrapolated towards high y. Finally FL is extracted from the difference between the prediction for F2 and the\nmeasurement of \u03c3r at high y.\nIn the analyses at Q2 & 10 GeV2 [18, 89, 178] the \"extrapolation\" method is used. In this method, an\nNLO QCD PDF fit to H1 HERA I data is performed at y < 0.35, and the results are extrapolated to higher y\nusing the DGLAP evolution equations. FL is then extracted at a fixed y = 0.75 and at Q2 up to 700 GeV2\nusing eq. 53. The extracted values are shown in Fig. 50 for the high-Q2 analysis [18].\nAt low Q2 , extrapolations of DGLAP fits become uncertain. For Q2 . 2 GeV2 , as the strong coupling\nconstant \u03b1s (Q2 ) increases, the higher order corrections to the perturbative expansion become large and lead to\nthe breakdown of the pQCD calculations. Therefore other methods are used in the H1 low-Q2 data analyses.\nThe \"shape method\", as used in the last H1 low-Q2 study of HERA I data [179], exploits the shape of\n\u03c3r in a given Q2 bin. The Q2 dependence at high y is driven by the kinematic factor y 2 /Y+ (eq. 53), and to\na lesser extent by FL (x, Q2 ). On the other hand, the gluon dominance at low x suggests that FL may exhibit\nan x dependence similar to F2 . Therefore it is assumed that FL is proportional to F2 and the coefficient of\nproportionality depends only on Q2 . In the extraction procedure one uses the ratio R of the cross sections of\nthe transversely and longitudinally polarised photons\nR=\n\nFL\n\u03c3T\n=\n\u03c3L\nF2 \u2212 FL\n\nwhich is thus assumed to depend only on Q2 . The reduced cross section is fitted by\n\u0014\n\u0015\ny 2 R(Q2 )\n\u03c3r = F2 1 \u2212\n,\nY+ 1 + R(Q2 )\n\n(54)\n\n(55)\n\n\f0.004\n\nx\n\n0.008\n\nFL\n\n0.002\n1.6\n\n+\n\ne p H1 99-00\n\u2212\ne p H1 98-99\n\n1.4\n1.2\nF =\nL F\n\n2\n\n1\n\n(H1\n\nPDF\n\n200\n\n0)\n\ny=0.75\n0.8\nH1 PDF 2000\nH1 Low y fit\n\n0.6\n0.4\n0.2\n0\n-0.2\n100\n\n200\n\n300\n\n400\n\n500 600 700 800\n\nQ2 / GeV2\nFig. 50: FL determined indirectly by H1 at a fixed y = 0.75 and high Q2 is shown as a function of Q2 (lower scale) or equivalently\nx (upper scale) for e+ p (closed circles) and e\u2212 p (open circles) data. The inner error bar represents the statistical error, and the outer\nerror bar also includes the systematic error and the uncertainty arising from the extrapolation of F2 .\nFL 1\n\nH1 Preliminary\n0.8\n\nSVX' 00,MB' 99,MB' 97 comb.\nFL Fractal fit (R=const)\n\n0.6\n\n0.4\n\n0.2\n\n0\n1\n\n2\n\n10\n2\n\nQ /GeV\n\nFig. 51: Q2 dependence of FL (x, Q2 ) at fixed y = 0.75, extracted from the preliminary H1 low-Q2 data. The solid line shows the\nprediction of the fractal fit with a constant R.\n\nwhere some phenomenological model for F2 is chosen.\nAn example of such an extraction using a fractal fit for F2 [180] is shown in Fig. 51, where preliminary\nH1 results [179] for FL at y = 0.75 in the range of 0.35 \u2264 Q2 \u2264 8.5 GeV2 are presented. The data favour a\npositive, not small FL at low Q2 . A drawback of this method is that it reveals a considerable dependence of R\non the choice of the F2 model.\nIn the derivative method [89,179], FL is extracted from the partial derivative of the reduced cross section\non y at fixed Q2\n\u2202F2 2y 2 (2 \u2212 y)\ny 2 \u2202FL\n\u2202\u03c3r\n= \u2212x\n\u2212\n(56)\nFL \u2212 x\n2\n\u2202 ln y Q2\n\u2202x\nY+ \u2202x\nY+\n\n\fFL\nH1 Preliminary\nSVX' 00,MB' 99,MB' 97 comb.\nFL Fractal fit (R=const)\n\n1\n\nModel uncertainty\n\n0.5\n\n0\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9 10\n\n2\n\n2\n\nQ /GeV\n\nFig. 52: Structure function FL extracted by H1 using the derivative method. The solid line shows the prediction of the fractal fit with a\nconstant R. The inner error bars represent statistical uncertainties, the outer error bars represent statistical and systematic uncertainties\nadded in quadrature. The solid (yellow) band indicates the model uncertainty.\n\nwhich is dominated by the FL -dependent term at high y. The term proportional to \u2202FL /\u2202x is negligible\nfor moderately varying parametrisations of FL . For low Q2 values the rise of F2 is weak. The change\nof the term x\u2202F2 /\u2202x for the two assumptions: no rise at low x, i.e. \u2202F2 /\u2202x = 0, and F2 \u221d x\u2212\u03bb is\nnumerically significantly smaller than the experimental precision for \u2202\u03c3r /\u2202 ln y. Therefore the derivative\nmethods provides a means for determining FL at low Q2 with minimal phenomenological assumption. On the\nother hand, the errors obtained with the derivative method turn out to be significantly larger than those from\nthe shape method.\nThe preliminary results of FL extraction from H1 HERA I data [179] are presented in Fig. 52. The\nresidual dependence of the measurement on the assumption made for F2 is estimated by a comparison with\nresults obtained assuming an F2 which is flat in y. The lower bound on FL obtained this way is depicted as a\nsolid band in the figure.\n4.2.3 Details of Direct FL Measurements\nThe H1 and ZEUS analysis procedures involve a measurement of the inclusive cross section at y > 0.1. In this\nrange, the kinematic variables x, y and Q2 are most accurately reconstructed using the polar angle, \u03b8e , and the\nenergy, Ee\u2032 , of the scattered electron according to\ny =1\u2212\n\nE \u2032 2 sin2 \u03b8e\nQ2\nEe\u2032 2 \u03b8e\n, Q2 = e\n, x=\n.\nsin\nEe\n2\n1\u2212y\nys\n\n(57)\n\nReaching the high y values necessary for the FL determination requires a measurement of the scattered electron with energy down to a few GeV. The electron candidate is selected as an isolated electromagnetic energy\ndeposition (cluster) in a calorimeter. The crucial analysis issue at high-y region is the identification of the scattered electron, and the estimation of the hadronic background which occurs when a particle from the hadronic\nfinal state mimics the electron signal. Most of background events are photoproduction (\u03b3p) events with Q2 \u2248 0\nin which the final state electron is scattered at low angles (high \u03b8)46 and thus escapes through the beam pipe.\nThe \u03b3p background suppression is performed in several steps. Firstly, calorimeter shower estimators are\nutilised which exploit the different profiles of electromagnetic and hadronic showers. Secondly, background\n46\n\nThe z axis of the right-handed coordinate systems used by H1 and ZEUS is defined by the direction of the incident proton beam\nwith the origin at the nominal ep interaction vertex. Consequently, small scattering angles of the final state particles correspond to\nlarge polar angles in the coordinate system.\n\n\fEvents\n\nEvents\n\nZEUS\n3500\n\n5000\n\n3000\n2500\n\n4000\n\n2000\n\n3000\n\n1500\n\n2000\n\n1000\n\n1000\n\n500\n0\n\n5 10 15 20 25 30 35 40\n\n30 35 40 45 50 55 60 65 70 75 80\n\n104\n103\n102\n10\n1\n0 20 40 60 80 100120140160180\n\n\u03b8e (\u00b0)\n\nEvents\n\nE-Pz (GeV)\nEvents\n\nEvents\n\nEe (GeV)\n4500\n4000\n3500\n3000\n2500\n2000\n1500\n1000\n500\n0\n\n50\n\n100\n\n150\n\n\u03b3\n\nhad\n\n(\u00b0)\n\n4\n\n10\n\n103\n\nZEUS (prel.)\ns=252 GeV (6pb-1)\n\n2\n\n10\n\nMC DIS + \u03b3 p\n\n10\n1\n-100\n\nMC \u03b3 p\n-50\n\n0\n\n50\n\n100\n\nzvtx (cm)\n\nFig. 53: Comparison of 575 GeV data with the sum of DIS and background simulations for the energy of the scattered electron, total\nE \u2212 pz , theta of the scattered electron, angle of the hadronic final state and z coordinate of the vertex. The dotted lines indicate the\ncuts applied.\n\ncoming from neutral particles, such as \u03c00 , can be rejected by requiring a track associated to the electron\ncandidate. Furthermore, \u03b3p events are suppressed by utilising the energy-momentum conservation. For that,\nthe variable E \u2212 pz = \u03a3i (Ei \u2212 pz,i ) is exploited, where the sum runs over energies Ei and longitudinal\nmomentum components pz,i of all particles in the final state. The requirement E \u2212 pz > 35 (42) GeV in\nthe H1 (ZEUS) analysis removes events where the escaping electron carries a significant momentum. It also\nsuppresses events with hard initial state photon radiation.\nHowever, at low Ee\u2032 the remaining background contribution after such a selection is of a size comparable\nto or even exceeding the genuine DIS signal. The further analysis steps differ for the H1 and ZEUS analyses\nas discussed in the following.\nZEUS Analysis Procedure The electron candidates are selected as compact electromagnetic energy depositions in the Uranium Calorimeter (UCal). The position of the candidate is reconstructed using either the\nSmall Angle Rear Tracking Detector (SRTD), which is a high-granularity lead-scintillator calorimeter, or with\nthe Hadron-Electron Separator (HES), which is a silicon detector located in the electromagnetic section of the\nUCal. The candidates are selected such that Ee\u2032 > 6 GeV47 .\nThe candidates are validated using information from the tracking devices. The acceptance region for\nZEUS tracking is limited to polar angles \u03b8e . 154\u25e6 . The tracking detectors do provide some coverage beyond\n\u03b8e = 154\u25e6 , up to \u03b8e \u2248 168\u25e6 , however the number of tracking layers is too sparse for full track reconstruction.\nThe hit information from the tracking detectors can still be used. To do this, a \"road\" is created between the\nmeasured interaction vertex and the position of the electron candidate in the calorimeter. Hits in the tracking\nlayers along the road are then counted and compared to the maximum possible number of hits. If too few hits\n47\n\nCut of Ee\u2032 > 4 GeV is used for the event selection, although the binning for FL measurement is chosen such that Ee\u2032 > 6 GeV.\n\n\fH1\n\n12\n\ne+ p\n\n3\n\n10 events\n\n14\n\n10\n8\n\nsignal +\nbackground\n\nbackground\n6\n4\n2\n0\n\n-5 -4 -3 -2 -1 0\n\n1\n\n2\n\n3\n\n4 5\nE/p\n\nFig. 54: Distribution of energy over momentum for tracks linked to clusters in the SpaCal with energy from 3.4 to 10 GeV that pass\nall the medium Q2 analysis cuts. Tracks with a negative charge are assigned a negative E/p.\n\nare found, the candidate is assumed to be a neutral particle and it is rejected. To ensure the reliability of this\nmethod, the scattered electron is required to exit the central drift chamber at a radius R > 20 cm. Given that\nEe\u2032 > 6 GeV, this effectively limits the maximal y to y < 0.8 and the minimum Q2 achievable at low y. In the\nHES analysis, events are measured down to y = 0.2 roughly translating to the Q2 region, Q2 > 24 GeV2 . No\nbackground treatment based on the charge of the candidate is performed.\nThe remaining \u03b3p background is estimated using Monte Carlo (MC) simulations. In order to minimise\nthe model uncertainty of the \u03b3p simulation, a pure photoproduction sample is selected using an electron tagger\nplaced close to the beam pipe about 6 meters away from the interaction point in the rear direction. It tags,\nwith almost perfect efficiency and purity, the scattered electrons in such events which are not identified in the\nmain detector and escape down the beam pipe. Photoproduction MC is verified against and normalised to this\nsample. The normalisation factor is found to be 1 \u00b1 0.1 for all data sets.\n\nFigure 53 shows, as an example, comparisons of the 575 GeV data with simulated distributions, for\nthe energy of the scattered electron, total E \u2212 pz , polar angle of the scattered electron, angle of the hadronic\nfinal state and the z coordinate of the interaction vertex. A good description of the data by the simulation is\nobserved. A similar level of agreement was found for both, HER and LER data sets.\nA full set of systematic uncertainties is evaluated for the cross section measurements. The largest\nsingle contribution comes from the electron energy scale uncertainty, which is known to within \u00b11% for\nEe\u2032 > 10 GeV, increasing to \u00b13% at Ee\u2032 = 5 GeV. Other significant contributions are due to the \u00b1 10% uncertainty in verifying the Pythia prediction of the \u03b3p cross section using the electron tagger. The systematic\nuncertainty due to the luminosity measurement was reduced by scaling the three cross sections relative to each\nother. The spread of relative normalisation factor was found to be within the expected level of uncorrelated\nsystematic uncertainty.\nH1 Analysis Procedure The H1 measurements of FL are performed in separate analyses involving different\ndetector components and thus covering different Q2 ranges. In the high-Q2 analysis the electron candidate is\nselected as an isolated electromagnetic energy deposition in the Liquid Argon (LAr) calorimeter which covers\nthe polar angle range 4\u25e6 < \u03b8 < 153\u25e6 . The selected cluster is further validated by a matching track reconstructed in the central tracking device (CT) with an angular acceptance of 15\u25e6 < \u03b8 < 165\u25e6 . In the medium\nQ2 analysis the electron candidate is selected in the backward calorimeter SpaCal covering the angular range\n153\u25e6 < \u03b8 < 177.5\u25e6 and is also validated by a CT track. Lower Q2 values are expected to be accessed in the\nthird analysis, in which the SpaCal cluster is validated by a track in the Backward Silicon Tracker reaching\nthe highest \u03b8. The first measurement of FL at medium Q2 is already published [181], and preliminary results\nof the combined medium-high-Q2 analysis are available.\nThe remaining \u03b3p background is subtracted on statistical basis. The method of background subtraction\n\n\f3\n\n10 events\n\nH1 Data\nMC+BG\nBG (data)\n\n4\n\n3\n\n2\n2\n1\n\n3\n\n10 events\n\n0\n\n4\n\n6\n\n8\n\n10\n\nEe' / GeV\n\n0\n150\n\n155\n\n160\n\n155\n\n160\n\n165\n\n170\n\n165\n\n170\n\n\u03b8e / deg\n\n1.5\n\n1\n0.75\n\n1\n\nH1 Data\nMC\n\n0.5\n\n0.5\n0.25\n0\n\n4\n\n6\n\n8\n\n10\n\nEe' / GeV\n\n0\n150\n\n\u03b8e / deg\n\nFig. 55: Top: comparison of the correct sign data (points) with the sum (open histogram) of the DIS MC simulation and background,\ndetermined from the wrong sign data (shadowed histogram), for the energy Ee\u2032 (left) and the polar angle \u03b8e (right) of the scattered\nelectron, for the 460 GeV data with Ee\u2032 < 10 GeV. Bottom: as top but after background subtraction.\n\nrelies on the determination of the electric charge of the electron candidate from the curvature of the associated\ntrack.\nFigure 54 shows the E/p distribution of the scattered electron candidates from e+ p interactions with the\nenergy E measured in the SpaCal and the momentum p of the linked track determined by the CT. The good\nmomentum resolution leads to a clear distinction between the negative and positive charge distributions. The\nsmaller peak corresponds to tracks with negative charge and thus represents almost pure background. These\ntracks are termed wrong sign tracks and events with such candidates are rejected. The higher peak, due to right\nsign tracks, contains the genuine DIS signal superimposed on the remaining positive background. The size\nof the latter to first approximation equals the wrong sign background. The principal method of background\nsubtraction, and thus of measuring the DIS cross section up to y \u2243 0.9, consists of the subtraction of the wrong\nsign from the right sign event distribution in each x, Q2 interval.\nThe background subtraction based on the charge measurement requires a correction for a small but\nnon-negligible charge asymmetry in the negative and positive background samples, as has been observed previously by H1 [89]. The main cause for this asymmetry lies in the enhanced energy deposited by anti-protons\ncompared to protons at low energies. The most precise measurement of the background charge asymmetry\nhas been obtained from comparisons of samples of negative tracks in e+ p scattering with samples of positive\ntracks in e\u2212 p scattering. An asymmetry ratio of negative to positive tracks of 1.06 is measured using the high\nstatistics e\u00b1 p data collected by H1 in 2003-2006. This result is verified using photoproduction events with a\nscattered electron tagged in a subdetector of the luminosity system.\nFigure 55 shows, as an example, comparisons of the 460 GeV high y data with simulated distributions,\nfor the energy and the polar angle of the scattered electron prior to and after subtraction of the background,\nwhich is determined using wrong sign data events.\nThe measurement of FL as described below relies on an accurate determination of the variation of the\n\n\f\u03c3r (x, Q 2, y)\n\n1.6\n\nQ2 = 25 GeV2\nx = 0.00062 1.6\n\n1.4\n1.4\n\n1.4\n\n1.4\n\n1.2\n1.2\n\n1.2\n\n1.2\n\n1.6\n1.6\n\nx = 0.00049\n\nx = 0.00076\n\n1\n1\n\n1\n1\n0.6 0.8\n0.6 0.8\n0.6 0.8\n1.60 0.2\n1.6\n1.60 0.2\n1.60 0.2\nx =0.4\n0.00100\nx =0.4\n0.00159\nx =0.4\n0.00246\n1.4\n1.4\n\n1.4\n\n1.4\n\n1.2\n1.2\n\n1.2\n\n1.2\n\n1\n1\n\nH1 Data\nEp = 920 GeV\nEp = 575 GeV\nEp = 460 GeV\nLinear fit\n\n1\n1\n0\n0.2\n0.4\n0.6\n0.8\n0\n0.2\n0.4\n0.6\n0.8\n0 0.2\n0.2 0.4\n0.4 0.6\n0.6 0.8\n0.8\n0 0.2 0.4 0.6 0.8 0 0.2 0.4 0.6 0.8 0\ny 2 / Y+\n\nFig. 56: The reduced inclusive DIS cross section plotted as a function of y 2 /Y+ for six values of x at Q2 = 25 GeV2 , measured by\nH1 for proton beam energies of 920, 575 and 460 GeV. The inner error bars denote the statistical error, the full error bars include the\nsystematic errors. The luminosity uncertainty is not included in the error bars. For the first three bins in x, corresponding to larger y,\na straight line fit is shown, the slope of which determines FL (x, Q2 ).\n\ncross section for a given x and Q2 at different beam energies. In order to reduce the uncertainty related to the\nluminosity measurement, which presently is known to 5% for each proton beam energy of the 2007 data, the\nthree data samples are normalised relatively to each other. The renormalisation factors are determined at low\ny, where the cross section is determined by F2 only, apart from a small correction due to FL . The relative\nnormalisation is known to within 1.6%.\nAll correlated and uncorrelated systematic errors combined with the statistical error lead to an uncertainty on the measured cross sections at high y of 3 to 5%, excluding the common luminosity error.\n4.2.4 Measurements of FL (x, Q2 ) by H1 and ZEUS\nThe longitudinal structure function is extracted from the measurements of the reduced cross section as the\nslope of \u03c3r versus y 2 /Y+ , as can be seen in eq. 53. This procedure is illustrated in Fig. 56. The central\nFL values are determined in straight-line fits to \u03c3r (x, Q2 , y) as a function of y 2 /Y+ using the statistical and\nuncorrelated systematic errors.\nThe first published H1 measurement of FL (x, Q2 ) is shown in Fig. 57, the preliminary ZEUS measurement is presented in Fig. 58. The H1 measured values of FL are compared with the H1 PDF 2000 fit [18],\nwhile the ZEUS FL values are compared to the ZEUS-JETS PDF fit [170]. Both measurements are consistent\nand show a non-zero FL .\nThe H1 results were further averaged over x at fixed Q2 , as shown in the left panel of Fig. 59. The\naveraging is performed taking the x dependent correlations between the systematic errors into account. The\naveraged values of FL are compared with H1 PDF 2000 fit and with the expectations from global parton\ndistribution fits at higher order perturbation theory performed by the MSTW [182] and the CTEQ [131, 169]\ngroups. Within the experimental uncertainties the data are consistent with these predictions. The measurement\nis also consistent with previous indirect determinations of FL by H1.\nIn the combined medium\u2013high Q2 analysis by H1 the Q2 range is extended up to Q2 = 800 GeV2 . The\npreliminary results are shown in the right panel of Fig. 59. In some Q2 bins there is an overlap between the\nSpaCal and LAr measurements which improves the precision of the FL extraction as compared to the pure\n\n\fFL (x, Q 2)\n\n1.5\n1.5\n\nQ2 = 12 GeV2\n\n1.5\n\nQ2 = 15 GeV2\n\n1.5\n\n11\n\n1\n\n1\n\n0.5\n0.5\n\n0.5\n\n0.5\n\n00\n\n0\n\n0\n\n1.5\n1.5\n\nQ2 = 25 GeV2\n\n1.5\n\nQ2 = 35 GeV2\n\n1.5\n\n11\n\n1\n\n1\n\n0.5\n0.5\n\n0.5\n\n0.5\n\n00\n\n0\n\n0\n\n1.5\n1.5\n\nQ2 = 60 GeV2\n\n1.5\n\n11\n\n1\n\n0.5\n0.5\n\n0.5\n\n00\n\n0\n\n10-3\n\nQ2 = 20 GeV2\n\nQ2 = 45 GeV2\n\nQ2 = 90 GeV2\n\n-3\n\n10\n\n10-2\n\nH1 Data\nEp = 460, 575, 920 GeV\n\nH1 PDF 2000\n10-3\n\n10-2\n\n10-2\n\nx\nFig. 57: The longitudinal proton structure function FL (x, Q2 ) measured by the H1 collaboration. The inner error bars denote the\nstatistical error, the full error bars include the systematic errors. The curves represent the H1 PDF 2000 fit.\n\nFL\n\nZEUS\nQ2= 24 GeV2\n\nQ2= 32 GeV2\n\nQ2= 60 GeV2\n\nQ2= 80 GeV2\n\n10-3\n\n10-3\n\n1\n\nQ2= 45 GeV2\nZEUS (prel.)\nZEUS-JETS\n\n0\n\n1\n\nQ2= 110 GeV2\ns = 225 GeV (14.0pb-1)\ns = 252 GeV ( 6.0pb-1)\ns = 318 GeV (32.8pb-1)\n\n0\n10-2\n\n10-2\n\n10-3\n\n10-2\n\nx\n\nFig. 58: The longitudinal proton structure function FL (x, Q2 ) measured by the ZEUS collaboration. The inner error bars denote the\nstatistical error, the full error bars include the systematic errors. The curves represent the ZEUS-JETS PDF fit.\n\nSpaCal analysis.\n4.2.5 Summary\nDirect measurements of the proton structure function FL have been performed in deep inelastic ep scattering\nat low x at HERA. The FL values are extracted by the H1 and ZEUS collaborations from the cross sections\nmeasured at fixed x and Q2 but different y values. This is achieved by using data sets collected with three\ndifferent proton beam energies. The H1 and ZEUS results are consistent with each other and exhibit a nonzero FL . The measurements are also consistent with the previous indirect determinations of FL by H1. The\nresults confirm DGLAP NLO and NNLO QCD predictions for FL (x, Q2 ), derived from previous HERA data,\n\n\fL\n\nmedium & high Q2\n\n0.5\n0.5\n\n0\nSpaCal SpaCal+LAr LAr\n\n0\n20\n\n40\n\n60\n\n-0.5\n-0.5\n\n80\n2\n\n2\n\nQ / GeV\n\n10\n\n102\n\n0.03531\n\n0.02858\n\n0.02178\n\n0.01256\n\n0.00541\n0.00689\n0.00929\n\n0.00374\n\n0.00269\n\n0.00235\n\n0.00148\n\n0.00114\n\n0.00090\n\n0.00063\n\n0.00049\n\n0.00037\n\nEp = 460, 575, 920 GeV\n\n1 x\n\n0.5\n0.5\n\nH1 PDF 2000\nCTEQ 6.6\nMSTW\n\nH1 (Prelim.)\n\n1.5\n1.5\n\n0.00028\n\n0.0022\n\n0.0014\n\n0.00093\n\n0.00062\n\n0.00049\n\nx\n\nFL (x, Q 2)\n\nH1 PDF 2000\nCTEQ 6.6\nMSTW 07\n\nH1 Data\nEp = 460, 575, 920 GeV\n\n0.0036\n\n1\n\n0.00028\n0.00037\n\nFL (x, Q 2 )\n\nH1 Preliminary F\n\n103\nQ / GeV 2\n2\n\nFig. 59: The proton structure function FL shown as a function of Q2 at the given values of x: a) first direct measurement at HERA by\nH1; b) preliminary H1 results combining SpaCal and LAr analyses. The inner error bars denote the statistical error, the full error bars\ninclude the systematic errors. The luminosity uncertainty is not included in the error bars. The solid curve describes the expectation\non FL from the H1 PDF 2000 fit using NLO QCD. The dashed (dashed-dotted) curve depicts the expectation of the MSTW (CTEQ)\ngroup using NNLO (NLO) QCD. The theory curves connect predictions at the given (x, Q2 ) values by linear extrapolation.\n\nwhich are dominated by a large gluon density at low x.\n\n\fPROTON\u2013PROTON LUMINOSITY, STANDARD CANDLES AND PDFS AT THE LHC48\n\n5\n\n5.1 Introduction\nThe Large Hadron Collider (LHC) is expected to start colliding proton beams in 2009, and is expected to reach\ndesign parameters in energy and luminosity sometime later and deliver a few f b\u22121 per year of data at the 14\nTeV collision energy.\nDuring the past 15 years many theoretical calculations and experimental simulations have demonstrated\na huge potential to perform many accurate tests of the Standard Model (SM) with LHC data, which could yield\ninsight into new physics mechanisms.\nTo make these tests, the experiments identify a particular signature X and observe, using a variety of\nselection criteria, a certain number of events in a given data taking period. After correcting this event rate\nfor backgrounds and the selection efficiency, the number is converted into a cross section. The cross section,\n\u03c3pp\u2192X can be compared with theoretical predictions49 according to the formula: Ncorrected = \u03c3pp\u2192X \u00d7 Lpp\nwhere Lpp is the recorded proton proton luminosity.\nBesides the statistical errors of a measurement, the systematic error is related to the uncertainties from\nthe Lpp determination, the background and efficiency corrections within the detector acceptance and from extrapolations into the uncovered very forward rapidity regions. The interpretation of an observed cross section\nwithin the SM requires further the knowledge of the theoretical cross section. Thus the uncertainties of the\nproton parton distribution function (PDF) have to be considered also.\nIn this Section we describe the status and perspectives of the ATLAS, CMS and LHCb, the three LHC pp\ncollision detectors [183], to determine the proton proton luminosity normalization. The investigated methods\nare known and studied since many years and can be separated into the absolute (1) direct and (2) indirect\nproton proton luminosity determination. A third approach (3) tries to measure and calculate final states only\nrelative to well understood reactions which depend on the parton-parton luminosity and are as such largely\nindependent of the knowledge of the pp luminosity.\n\u2022 Absolute, direct or indirect, proton proton luminosity normalization: If the absolute approach is used,\nthe interpretations of a measured reaction cross section depends still on the knowledge of parton distribution function (PDF), which must be obtained from other experiments. Examples are:\n\u2013 The proton proton luminosity normalization is based on the measurements of the beam currents\nand shapes. While the beam currents can be accurately determined using beam transformers,\nthe beam profiles are more difficult to determine directly and usually constitute the dominant\nsource of uncertainty on a luminosity measurement using this technique. The use of the machine\nluminosity determination using beam parameter measurements [184] and [185] will be described\nin Section 5.3.1. Alternatively one can try to measure the beam profiles also within the experiments\nusing the precision vertex detectors. A short description of this idea, currently pursued within the\nLHCb collaboration, is also given in Section 5.3.1.\n\u2013 The simultaneous measurements of a pair of cross sections that are connected with each other\nquadratically via the optical theorem. A well known example of this is the measurement of the\ntotal inelastic cross section and the elastic cross section at very high pseudorapidities |\u03b7| \u2248 9 and\nwill be described in Section 5.3.3.\nSo called instantaneous or real time luminosity measurements are based on \"stable\" high rate\nmeasurements of particular final state reactions. Once the ratio of such reactions to the pp luminosity determination has been measured, those reactions can be subsequently used as independent\nluminosity monitors. Some possibilities are discussed in Section 5.3.4.\n\u2013 The indirect absolute proton proton luminosity normalization is based on the theoretically well\nunderstood \"two photon\" reaction pp \u2192 pp\u03bc\u03bc [186, 187] (Section 5.3.5). This reaction could\nperhaps be considered as the equivalent of the luminosity counting in e+ e\u2212 experiments using\nforward Bhabha scattering.\n48\n\nContributing authors: J. Anderson, M. Boonekamp, H. Burkhardt, M. Dittmar, V. Halyo, T. Petersen\nAlternatively, one can also apply a Monte Carlo simulation to the theoretical prediction and compare the number of background\ncorrected events directly.\n49\n\n\f\u2022 Indirect pp luminosity measurements use final states, so called \"standard candles\", with well known\ntheoretical cross sections (Section 5.4).\nObviously, the resulting proton proton luminosity can only be as good as the theoretical and experimental knowledge of the \"standard candle\" reaction. The theoretically and experimentally best understood\nLHC reactions are the inclusive production of W and Z bosons with subsequent leptonic decays. Their\nlarge cross section combined with experimentally well defined final states, e.g. almost background free\nZ and W event samples can be selected over a relative large rapidity range, makes them the preferred\nLHC \"standard candle\" reaction. Other interesting candidates are the high pt jet - boson (= \u03b3, W or Z)\nfinal states. The indirect luminosity method requires also some knowledge of the PDFs, and of course,\nif one follows this approach, the cross section of the \"standard candle\" reaction becomes an input and\ncan not be measured anymore. Thus, only well understood reactions should be considered as candidate\nreactions.\n\u2022 pp luminosity independent relative rate measurements using \"standard candle\" reactions.\nIn addition to the above indirect pp luminosity determinations, \"standard candle\" reactions allow to\nperform luminosity independent relative event rate calculations and measurements. This approach has\nalready been used successfully in the past and more details were discussed during the past HERA-LHC\nworkshop meetings [1]. For some reactions, this approach appears to be much easier and more accurate\nthan standard cross section measurements and their interpretations. Perhaps the best known example at\nhadron colliders is the measurement and its interpretation of the production ratio for Z and W events,\nwhere Tevatron experiments have reached accuracies of about 1-2% [188, 189]. Another example is\nrelated to relative branching ratio and lifetime measurements as used for b-flavored hadrons.\nFurthermore the rapidity distributions of leptonic W and Z decays at the LHC are very sensitive to the\nPDF parameterization and, as was pointed out 10 years ago [190], one can use these reactions to determine the\nparton luminosity directly and very accurately over a large x (= parton momentum/proton momentum) range.\nIn fact, W and Z production with low transverse momentum were found in this analysis to be very sensitive\nto q q\u0304 luminosities, and the jet-boson final states, e.g. the jet-\u03b3, Z, W final states at high transverse momentum\nare sensitive to the gluon luminosity.\nIn the following we attempt to describe the preparations and the status of the different luminosity measurements and their expected accuracies within ATLAS, CMS and LHCb. Obviously, all these direct and\nindirect methods should and will be pursued. In Section 5.5 we compare the advantages and disadvantages of\nthe different methods. Even though some methods look more interesting and rewarding than others, it should\nbe clear from the beginning that as many independent pp luminosity determinations as possible need to be\nperformed by the experiments.\nWe also try to quantify the systematic accuracies which might be achieved over the next few years. As\nthese errors depend somewhat on the overall achieved luminosity, we need in addition a hypothetical working\nscenario for the first 4 LHC years. We thus assume that during the first year, hopefully 2009, data at different\ncenter of mass energies can be collected by ATLAS and CMS. During the following three physics years we\nexpect that 10 TeV will be the highest collision energy in year I and that at most 100 pb\u22121 can be collected.\nWe assume further that during the following two years the design energy of 14 TeV can be achieved and that\na luminosity of about 1 fb\u22121 and 10 fb\u22121 can be collected respectively per year. During the first few years\nsimilar numbers are expected for the LHCb experiment. However once the LHC reaches the first and second\nphase design luminosity of 1033 /cm2 /sec and 1034 /cm2 /sec it is expected that the LHCb experiment will run\nat an average luminosity of 2 \u00d7 1032 /cm2 /sec (resulting in about 2 f b\u22121 /per year).\n5.2 Luminosity relevant design of ATLAS/CMS and LHCb\nIn the following we give a short description of the expected performance with respect to lepton and jet identification capabilities. Especially the electron and muon measurement capabilities are important for the identification of events with leptonic decays of W and Z bosons.\nBoth ATLAS and CMS are large so called omni purpose experiments with a large acceptance and\nprecision measurement capabilities for high pt electrons, muons and photons. Currently, the simulations\n\n\fof both experiments show very similar performance for a large variety of LHC physics reactions with and\nwithout jets. For the purpose of this Section we focus on the possibility to identify the production of inclusive\nW and Z decays with subsequent decays to electrons and muons. Both experiments expect excellent trigger\naccuracies for isolated leptons and it is expected that electrons and muons with momenta above 20-25 GeV\ncan be triggered with high efficiency and up to |\u03b7| of about 2.5. The special design of the ATLAS forward\nmuon spectrometer should allow to detect muons with good accuracy even up to |\u03b7| of 2.7.\nThe operation of ALFA, a very far forward detector placed about 240 m down the beam line, is envisaged by the ATLAS collaboration to provide an absolute luminosity measurement, either using special\noptics LHC running and the use of the optical theorem or using the total cross section measurement from the\ndedicated TOTEM experiment installed near CMS; results from this device can be expected from 2010 and\non-wards. In addition to absolute luminosity measurements from ALFA the two detectors LUCID and the\nZero-Degree-Calorimeter (CDC) [191] are sensitive to the relative luminosity at time scales of single bunch\ncrossings.\n\nA similar approach for absolute and relative luminosity measurements is foreseen by the CMS experiment. Here it is planned that dedicated forward detectors, the Hadron Forward Calorimeter (HF) and the ZDC\ndevice provide similar results as the ones in ATLAS.\nAnother technique that is expected to be available early on is a luminosity-independent measurement of\nthe pp total cross section. This will be done using a forward detector built by the TOTEM experiment [192].\nThe LHCb experiment [193] has been designed to search for New Physics at the LHC through precision\nmeasurements of CP violating observables and the study of rare decays in the b-quark sector. Since the bb\u0304 pairs\nresulting from the proton-proton collisions at the LHC will both be produced at small polar angles and in the\nsame forward or backward cone, LHCb has been designed as a single-arm forward spectrometer covering the\npseudo rapidity range 1.9 < \u03b7 < 4.9. The LHCb tracking system, which is composed of a silicon vertex\ndetector, a warm dipole magnet and four planar tracking stations, will provide a momentum resolution of\n\u03b4P/P = (0.3 + 0.0014P/GeV )% [194]. Muon identification is primarily achieved using a set of five planar\nmulti-wire proportional chambers, one placed in front of the calorimeter system and four behind, and it is\nexpected that for the momenta range 3-150GeV/c an identification efficiency of \u223c98% and an associated pion\ndis-identification rate of \u223c1% will be achieved. The reconstruction of primary and secondary vertices, a task\nof crucial importance at b physics experiments, will be virtually impossible in the high particle multiplicity\nenvironment present with the nominal LHC running luminosity of 1034 cm\u22122 s\u22121 - LHCb has therefore been\ndesigned to run at the lower luminosity of 2 \u00d7 1032 cm\u22122 s\u22121 .\n\nRecent LHCb simulations have shown that leptonic W and Z decays to muons can be identified with\na small background in the forward and very forward rapidity region starting from \u03b7 of 1.9 and up to values\nlarger than 4. As will be discussed later in more detail, the common muon acceptance region for the three LHC\nexperiments between 1.9 and about 2.5 will allow to cross check and normalize the W and Z measurements\nin this region. Consequently the unique large rapidity from 2.5 to 4.9 can be used by LHCb to investigate the\nvery low x range of the PDFs for the first time.\n\nThe absolute luminosity at LHCb will be obtained either directly, by making measurements of the beam\nparameters, or indirectly via a measurement of the event rate of an accurately predicted physics process.\nAs will be explained in the following Sections, all experiments will try to perform as many as possible\ndirect and indirect absolute and relative luminosity measurements and will, if available, at least during the first\nyears, also use luminosity numbers from the machine group.\n5.2.1 Lepton triggering and W/Z identification.\nGenerally, the lepton trigger selections depend on the instantaneous luminosity and some pre-scaling might\neventually needed. However, current simulations by all experiments show that the envisaged |\u03b7| and pt thresholds will not limit the measurement accuracies of leptons originating from W and Z decays.\nThe lepton trigger selections that generally perceived to be used for most W and Z related analysis are\nvery similar in ATLAS and CMS as indicated in Table 9.\nTrigger and reconstruction efficiencies for leptonic W and Z decays within the acceptance of the detec-\n\n\fExperiment\nATLAS\nCMS\nLHCb\u2217\n\nTrigger selection e\npT\n|\u03b7|\n25 GeV\n2.5\n20 GeV\n2.5\n\u2013\n\u2013\n\nTrigger selection \u03bc\npT\n|\u03b7|\n20 GeV\n2.7\n20 GeV\n2.1\n2.5 GeV 1.9-4.9\n\nTable 9: For ATLAS and CMS the lepton trigger/selection pt thresholds are given for single isolated leptons. \u2217 For the LHCb threshold\nis given for the muon pair mass instead of single muons and only positive values of \u03b7 are covered.\n\ntors have been estimated for ATLAS to be 97.7% and 80.0% for electrons and 84.3% and 95.1% for muons,\nrespectively. The reconstruction efficiency includes the trigger efficiencies and the off-line electron and muon\nselections used later to identify clean inclusive W and Z event samples [195].\nThe current equivalent trigger and off-line efficiencies for CMS are about 85% and 77% for electrons\nand combined about 85% for single muons [196]. Similar efficiency numbers for muons from W and Z decays\nare expected within the LHCb acceptance region [197]. Current simulations show that these numbers can be\ndetermined with high accuracies, reaching perhaps 1% or better, at least for isolated leptons50 which have a\ntransverse momentum some GeV above the trigger thresholds. For lower momenta near the thresholds or for\nadditional special trigger conditions somewhat larger systematic uncertainties can be expected.\n5.3 Direct and indirect absolute pp luminosity measurements\nThree different absolute proton proton luminosity measurements are discussed in this Section. (1) The machine\nluminosity determination using beam parameter measurements [198], (2) the luminosity independent total pp\ncross section measurement combined with the measurement of the elastic pp scattering rate [192] and (3)\nthe measurement of the \"two photon\" reaction pp \u2192 pp\u03bc\u03bc [186, 187]. As will be discussed in more detail\nin Section 5.5, only method (3) can be performed during the normal collision data taking. For method (1)\nsome special methods, which take the actual detector performance during each run into account, need to be\ndeveloped. Method 2 uses a two phase approach (a) a special machine optics run with low luminosity to\ndetermine the total cross section and (b) a normalization to some high rate final state reactions which can be\ncounted during normal physics runs.\n5.3.1 Proton-proton luminosity from machine parameters51\nThe luminosity for colliding beams can be directly obtained from geometry and numbers of particles flowing\nper time unit [184]. This can be used to determine the absolute LHC luminosity from machine parameters\nwithout prior knowledge of pp scattering cross sections. The principle is briefly outlined here. More details\ncan be found in [185].\nInteraction\nregion\nBunch 1\nN1\n\nBunch 2\n\nEffective area A\n\nN2\n\nFig. 60: Luminosity from particles flux and geometry.\n\nFor two bunches of N1 and N2 particles colliding head-on in an interaction region as sketched in Fig.60\nwith the frequency f the luminosity is given as\nL=\n50\n51\n\nN1 N2 f\n.\nAeff\n\n(58)\n\nAs isolated high pt photons are triggered essentially like electrons similar accuracies for both particle types can be assumed.\nContributing author: H. Burkhardt\n\n\fAeff is the effective transverse area in which the collisions take place. For a uniform transverse particle\ndistribution, Aeff would be directly equal to the transverse beam cross section. More generally, the effective\narea can be calculated from the overlap integral of the two transverse beam distributions g1 (x, y), g2 (x, y)\naccording to\nZ\n1\n=\ng1 (x, y) g2 (x, y) dx dy .\n(59)\nAeff\n\nFor equal Gaussian beams\n\n1\nexp\ng1 = g2 =\n2\u03c0\u03c3x \u03c3y\n\n\"\n\nx2\ny2\n\u2212 2\u2212 2\n2\u03c3x 2\u03c3y\n\n#\n\n(60)\n\nwe obtain for head-on collisions Aeff = 4\u03c0 \u03c3x \u03c3y so that\nL=\n\nN1 N2 f\n.\n4\u03c0\u03c3x \u03c3y\n\n(61)\n\nThe collision frequency f is accurately known. The number of particles circulating in a storage ring is measured using beam current transformers to roughly 1% precision [198].\n\ny\n\nx\n\nrelative le luminosity in arbitrary units\n\n3\n\n7.515 / 6\n\u03c72 /ndf\nLum0\n1.914 0.6501E-01\n<\u03b4y> -1.121\n0.7290\n\u03c3y\n16.83\n0.5181\n\n2.5\n\n2\n\n1.5\n\n1\n\n0.5\n\n0\n-50\n\n-40\n\n-30\n\n-20\n\n-10\n\n0\n\n-10\n\n-20\n\n-30\n\n-40\n\n-50\n\n\u03b4y in \u03bcm\nFig. 61: Schematic view of the steps involved in an orthogonal separation scan proposed for the LHC (left) and a possible result in\none direction (based on early LEP data) shown on the right.\n\nThe main uncertainty in the absolute luminosity determination from machine parameters is expected to\noriginate in the knowledge of the transverse beam dimensions. Safe operation of the LHC requires a rather\ngood knowledge of the optics and beam sizes and we expect that this should already allow a determination of\nthe luminosity from machine parameters to about 20 \u2212 30 percent. A much better accuracy can be obtained\nwhen the size of the overlap region at the interaction points is determined by measuring the relative luminosity\nas a function of lateral beam separation, as illustrated in Fig. 61. This technique was pioneered at the ISR [199]\nand allowed to reduce the uncertainty to below 1%, [200, 201].\nFor the more complicated LHC and early operation, a 10% overall uncertainty in the absolute LHC\nmachine luminosity calibration should be a realistic goal. The actual precision will depend on the running\ntime and effort which is invested. A relatively small number of scans under favorable beam conditions will\nin principle be sufficient to obtain and verify the reproducibility in the absolute luminosity calibration. While\nfast scans may always be useful to optimize collisions, we assume that any dedicated, detailed luminosity\nscans will become obsolete when the other, cross section based luminosity determinations described in these\nproceedings allow for smaller uncertainties.\n\n\fOptimal running conditions are moderate bunch intensities, large bunch spacings, no crossing angle and\n= 2 m or larger. These conditions are in fact what is proposed anyway for the initial LHC operation with\n43 \u2013 156 bunches per beam. Statistics are not expected to be a problem. For early operation at top energy (10\n- 14 TeV) with 43 bunches and 4 \u00d7 1010 particles per bunch, before beams are squeezed. at a \u03b2 \u2217 = 11 m, we\nalready expect luminosities of the order of 1030 cm\u22122 s\u22121 resulting in event rates of 104 Hz, for a cross section\nof 0.01 barn as typical for the low angle luminosity monitors.\n\u03b2\u2217\n\nFrom the LHC injectors, we expect bunch by bunch variations of about 10% in intensity and 20% in\nemittance. For the large spacing between bunches in the operation with up to 156 bunches, there is no need\nfor crossing angles at the interaction points. Parasitic beam-beam effects will be negligible. All bunches in\neach beam will follow the same equilibrium orbit and collide at the same central position.\nCalibration runs require good running conditions and in particular good beam lifetimes. Bunch by bunch\ndifferences are not expected to change significantly during a scan. Storing bunch intensities at the beginning\nand end of a scan and using one set of timed averaged bunch intensities for a scan should be sufficient. To\navoid any bias, it will be important to use the correct pairing of bunch intensities and relative luminosities\nin the calculation of absolute bunch luminosities according to Eq. 58, before any summing or averaging over\ndifferent bunches.\nWe are currently preparing an on-line application for automatic luminosity scans52 . Scan parameters\nlike range, step size and duration can be set before the start of the scan. Once the parameters are defined, it\nis possible to launch automatic horizontal and vertical separation scans in the LHC interactions regions. For\na detailed scan, we may choose a range from -4 to +4 \u03c3 in nominal beam size in steps of 0.5 \u03c3, resulting in\n17 equidistant points. If we wait 1 s between points to allow for the magnets to change and for 2 s integration\ntime, the scan time would still be below a minute per plane. Details are currently being worked out in close\ncollaboration with the experiments. Exchanging all data bunch-by-bunch at a 1 Hz rate between the machine\ncontrol room (CCC) and the experiments would be rather demanding and risks to saturate current capacities.\nFor the initial running, it will be sufficient to exchange average values at about 1 Hz rate. It allows\nquality monitoring and the determination of the peak position. For the detailed off line analysis, we only have\nto rely on local logging and timing information synchronized to at least 1 s precision at the beginning of the\nscan. With fixed time interval defined and saved before the scan, this allows for off-line synchronization of\nthe detailed data and a complete bunch by bunch analysis.\n5.3.2 Direct measurements of the absolute luminosity at LHCb\nLHCb plans to measure the absolute luminosity using both the Van Der Meer scan, [199], and beam-gas\ntechniques following a more recently proposed method [202]. Here one tries to determine the transverse\nbeam profiles at colliding beam experiments utilizing the precision vertex detectors found at modern HEP\nexperiments to reconstruct beam gas interactions near the beams crossing point. The vertex resolution in the\ntransverse direction at LHCb can be parameterized by the relation\n100\u03bcm\n\u03c3x,y = \u221a\nNtracks\n\n(62)\n\nwhere Ntracks is the number of tracks originating from the vertex. Since the nominal transverse bunch size at\nLHCb will be 100\u03bcm, the reconstruction of beam-gas vertices's, which will have a track multiplicity of \u223c 10,\nwill enable the measurement of the colliding bunch profiles and the beam overlap integral. This method is\ncurrently under investigation by the LHCb collaboration and is expected to result in a luminosity measurement\nwith an associated uncertainty of 3-5%.\n5.3.3 Absolute pp luminosity from specialized detectors and from the total cross section measurement\nATLAS and CMS are planning to perform absolute and relative pp luminosity measurements using dedicated\nluminosity instruments.\n52\n\nDone by Simon White, as part of his PhD thesis work on the LHC machine luminosity determination\n\n\fThree particular luminosity instruments will operate around the ATLAS interaction point.\nThe absolute luminosity measurement will be provided by ALFA [191] placed 240m down the beam line and\ndue to operate in 2010. This measurement requires some special optics low luminosity running of the LHC and\nshould be able to measure the very low angle Coulomb scattering reaction. The expected precision is of the\norder 3%, depending on yet unknown LHC parameters during running. The ALFA detector can also measure\nthe absolute luminosity using the optical theorem if the Coulomb region can not be reached. Extrapolating the\nelastic cross section to very low momentum transfer t = 0 and using the total cross section as measured by\nTOTEM [192] (located at the CMS interaction point) current simulations indicate that a precision of about 3%\nmight also be reached with this method. In addition to absolute luminosity measurements from ALFA, LUCID\nand a Zero-Degree-Calorimeter (ZDC) [191] are sensitive to the relative single bunch crossings luminosity.\nLUCID and ZDC will however not give absolute measurements.\nA similar approach is currently foreseen by the CMS collaboration [203].\n5.3.4 Real time relative luminosity measurements\nA large number of instantaneous relative luminosity measurements have been discussed during the past years\nby ATLAS, CMS and LHCb and more details can be found in the three presentations given during the \"standard candle\" session of this workshop [204]. As an example we outline in the following some ideas discussed\nwithin CMS.\nMultiple techniques capable of providing suitable luminosity information in real time have been identified in CMS. One technique employs signals from the forward hadron calorimeter (HF) while another, called\nthe Pixel Luminosity Telescope (PLT), uses a set of purpose-built particle tracking telescopes based on singlecrystal diamond pixel detectors. At this writing, the PLT has not been formally approved, but is under study.\nThe methods based on signals from the HF described are the ones being most vigorously pursued.\nTwo methods for extracting a real-time relative instantaneous luminosity with the HF have been studied.\nThe first method is based on \"zero counting,\" in which the average fraction of empty towers is used to infer\nthe mean number of interactions per bunch crossing. The second method called \"EtSum method\" exploits the\nlinear relationship between the average transverse energy per tower and the luminosity.\nOutputs of the QIE chips used to digitize the signals from the HF PMTs on a bunch-by-bunch basis\nare routed to a set of 36 HCAL Trigger and Readout (HTR) boards, each of which services 24 HF physical\nchannels. In order to derive a luminosity signal from the HTR, an additional mezzanine board called the HF\nluminosity transmitter (HLX) is mounted on each of the HTR boards. The HLX collects channel occupancy\nand ET sum data to create eight histograms: two sets of three occupancy histograms, one ET -sum histogram,\nand one additional occupancy histogram. These histograms comprise about 70 KB of data, which is transmitted at a rate of approximately 1.6 Mbps to a dedicated luminosity server via an Ethernet switch that aggregates\nthe data from multiple HLX boards for further processing.\nAlthough all HF channels can be read by the HLX, MC studies indicate that the best linearity is\nobtained using only the inner four \u03b7 rings. The algorithm has been optimized to minimize sensitivity to\npedestal drifts, gain changes and other related effects. Both \"Zero Counting\" and the \"EtSum\" method have\ndemonstrated linearity up to LHC design luminosity. A statistical error of about 1% will be achieved at\nfewtimes \u00d7 1031 cm\u22122 s\u22121 Hence the dominant error on the absolute luminosity will result from the normalization of the online relative luminosity.\n5.3.5 Proton-proton luminosity from the reaction pp \u2192 pp\u03bc\u03bc\n\nThe QED process pp \u2192 pp\u03bc+ \u03bc\u2212 , where a \u03bc+ \u03bc\u2212 pair is produced via photon-photon scattering, was first proposed for luminosity measurements at hadron colliders in [186]. At the LHC such pairs will be predominantly\nproduced with small transverse momenta, at small polar angles and in the same forward or backward cone.\nAll three experiments are considering to use the well calculated pp \u2192 pp\u03bc\u03bc process for measuring absolute luminosity. The theoretical understanding of this QED photon-photon scattering reactions is considered\nto be accurate to better than 1%. Consequently this final state is thus often considered to be the perfect theoretical luminosity process. However, the experimental identification of this process requires to select muon\n\n\fpairs with low mass and within a well understood acceptance. The measurement of this reaction at a hadron\ncollider appears to be much more difficult than the corresponding measurements of the reaction ee \u2192 ee\u03bc\u03bc\nat LEP. The systematic measurement error for example in L3 and after several years of data taking was about\n\u00b13% [205]\n\nCurrent simulations by the three LHC experiments indicate that the final state can be identified using\nstraight forward criteria. For ATLAS and CMS one finds that about 1000 accepted events could at best be\nexpected for an integrated luminosity of 1 fb\u22121 , resulting in a statistical error of about \u00b1 3%.\n\nFor example the ATLAS study selects oppositely charged back-to-back muon tracks with pT > 6 GeV\nand |\u03b7| < 2.2 with an invariant mass less than 60 GeV and a common vertex with no other tracks originating\nfrom it (isolation), yields a cross section of 1.33 pb. Thus, about 1300 events can be expected for running\nperiods with a luminosity of 1 fb\u22121 and yielding a potential statistical error of 3%. However, backgrounds\nnot only from pile up events will be a critical issue. Some proton tagging with high luminosity roman pots is\ncurrently investigated but this will certainly reduce the accepted cross section and introduce additional acceptance errors. Similar conclusions have been reached by simulations performed within the CMS collaboration.\nConsequently, both experiments expect that, during the coming years, this reaction will be mainly used as a\ncross check of the other methods.\nThe cross section for this process where both muons lie inside the LHCb acceptance and have a combined invariant mass greater than 2.5GeV is \u2248 88 pb. The expected uncertainty is perhaps 1% or smaller and\ncomes mainly from rescattering corrections [187], i.e. strong interactions between the interacting protons.\nThe feasibility of using the elastic two photon process pp \u2192 p + \u03bc+ \u03bc\u2212 + p to make luminosity measurements at LHCb was first explored in [206] and has recently been investigated in more detail by members\nof the LHCb collaboration [207]. A variety of background processes have been studied: dimuons produced via\ninelastic two-photon fusion and double pomeron exchange; low mass Drell-Yan pairs; QCD processes such\nas bb\u0304 \u2192 \u03bc+ \u03bc\u2212 + X; and the combinatoric backgrounds caused by K/\u03c0 mis-identification. A simple offline\nselection has been developed that requires: the dimuon pair transverse momentum to be less than 50MeV/c;\nthe dimuon invariant mass to be in the range 2.5GeV /c2 < M\u03bc\u03bc < 20GeV /c2 ; and a charged particle multiplicity of less than 3 (i.e. the event should contain a \u03bc+ \u03bc\u2212 pair and no other charged particles). These\ncriteria select \u223c 27% of the signal events that pass the trigger and are reconstructed and result in a background\ncontamination that is (4.1 \u00b1 0.5(stat.) \u00b1 1.0(syst.))% of the signal level with the dominant contribution\ndue K/\u03c0 mis-identification. Overall it is expected that \u223c 104 pp \u2192 p + \u03bc+ \u03bc\u2212 + p events will be triggered,\nreconstructed and selected at LHCb during one nominal year of data taking (2f b\u22121 ). Systematic uncertainties\non a luminosity measurement at LHCb using this channel are estimated to be \u223c 1.31% and are dominated by\nthe uncertainty on the predicted cross section for events containing dimuons produced via double pomeron\nexchange, an uncertainty that is expected to be reduced in the near future. A measurement of the absolute\nluminosity at LHCb using this channel and a dataset of 2f b\u22121 will therefore be possible with an associated\nuncertainty of \u223c 1.5%.\nIn summary, the accurate measurement of this theoretically well understood reaction looks like an\ninteresting challenge for the LHC experiments. Interesting results can be expected once integrated luminosities\nof 5 fb\u22121 and more can be accumulated for ATLAS and CMS and about 1 fb\u22121 for LHCb. Of course, it\nremains to be proven, if the systematic uncertainties under real data taking conditions can indeed be reduced\nto the interesting 1% level.\n5.4 Indirect and relative pp luminosity measurements\nThe methods to measure the absolute proton proton luminosity and their limitations have been described in\nthe previous chapter.\nIn this Section we will describe the possibilities to measure the luminosity indirectly using well defined\nprocesses, so called \"Standard Candles\" and their use to further constrain the PDFs and discuss the possibility\nto \"measure\" directly the parton-parton luminosities.\nBefore describing the details of these indirect approaches, a qualitative comparison of luminosity measurements at e+ e\u2212 colliders and hadron colliders might be useful. The most important difference appears\n\n\fto be that in the e+ e\u2212 case one studies point like parton parton interactions. In contrast, at hadron hadron\ninteractions one studies the collision of protons and other hadrons made of quarks and gluons. As a result,\nin one case the Bhabha elastic scattering reaction e+ e\u2212 \u2192 e+ e\u2212 at low Q2 reaction can be calculated to\nhigh accuracy and the observed rate can be used as a luminosity normalization tool. In contrast, the elastic\nproton proton scattering cross section can not be calculated at the LHC nor at any other hadron colliders. As a\nconsequence, absolute normalization procedures depend always on the measurement accuracy of the pp total\ncross section. Even though it is in principle possible to determine the pp total cross section in a luminosity\nindependent way using special forward detectors like planned by the TOTEM or the ALFA experiments, the\naccuracy will be limited ultimately and after a few years of LHC operation to perhaps a few %.\nFurthermore, as essentially all interesting high Q2 LHC reactions are parton parton collisions, the majority of experimental results and their interpretation require the knowledge of parton distribution functions\nand thus the parton luminosities.\nFollowing this reasoning, more than 10 years ago, the inclusive production of W and Z bosons with\nsubsequent leptonic decays has been proposed as the ultimate precision parton parton luminosity monitor at\nthe LHC [190]. The following points summarize the arguments why W and Z production are indeed the ideal\n\"Standard Candles\" at the LHC.\n\u2022 The electroweak couplings of W and Z bosons to quarks and leptons are known from the LEP measurements to accuracies smaller than 1% and the large cross section of leptonic decays W and Z bosons\nallows that these final states can be identified over a large rapidity range with large essentially background free samples.\n\u2022 Systematic, efficiency corrected counting accuracies within the detector acceptance of 1% or better\nmight be envisioned during the early LHC running. In fact it is believed that the relative production rate\nof W and Z can be measured within the detector acceptance with accuracies well below 1%.\n\u2022 Theoretical calculations for the W and Z resonance production are the most advanced and accurately\nknown LHC processes. Other potentially more interesting LHC reactions, like various diboson pair\nproduction final states are expected to have always larger, either statistical or systematic, experimental\nand theoretical uncertainties than the W and Z production.\n\u2022 The current PDF accuracies, using the latest results from HERA and other experiments demonstrate\nthat the knowledge of the quark and anti quark accuracies are already allowing to predict the W and\nZ cross at 14 TeV center of mass energies to perhaps 5% or better. The measurable rapidity and pt\ndistributions of the Z boson and the corresponding ones for the charged leptons from W decays can be\nused to improve the corresponding parton luminosity functions.\nObviously, the use of W and Z bosons as a luminosity tool requires that the absolute cross section\nbecomes an input, thus it can not be measured anymore. As a result this method has been criticized as being\n\"a quick hack at best\". In contrast, advocates of this method point out that this would not be a noticeable loss\nfor the LHC physics program.\n5.4.1 Using the reaction pp \u2192 Z \u2192 l+ l\u2212 to measure Lpp\n\nVery similar and straight forward selection criteria for the identification of leptonic Z decays, depending\nsomewhat on the detector details and the acceptance region, are applied by ATLAS, CMS and LHCb. In the\nfollowing the current selection strategy in ATLAS and LHCb are described.\n5.4.2 Measuring Z and W production, experimental approaches in ATLAS\nThe ATLAS W and Z cross section measurements are based on the following selections in the electron and\nmuon channels:\n\u2022 A typical selection of W \u2192 e\u03bd requires that events with \"good\" electrons have to fulfill the additional\nkinematic acceptance criteria:\npT > 25 GeV, |\u03b7| < 1.37 or 1.52 < |\u03b7| < 2.4.\n\n\fThe criteria for W \u2192 \u03bc\u03bd muons are similar where pT > 25 GeV and |\u03b7| < 2.5. is required. Furthermore, in order to classify the event as a W event, the reconstructed missing transverse momentum and\nthe transverse mass should fulfill ET (miss) > 25GeV and mT (W ) > 40 GeV.\n\u2022 The selection of Z \u2192 ee and Z \u2192 \u03bc\u03bc requires that a pair of oppositely charged electrons or muons\nis found. Due to lower background the electrons should have pT > 15 GeV and |\u03b7| < 2.4 and their\ninvariant mass should be between 80-100 GeV.\nSimilar criteria are applied for the muons with pT > 15 GeV and |\u03b7| < 2.5. The reconstructed mass\nshould be between 71-111 GeV.\nFollowing this selection and some standard Monte Carlo simulations, the expected number of recon\u221a\nstructed events per 10 pb\u22121 at s = 14 TeV are about 45000, 5500 for W and Z decays to electrons and\n60000, and 5000 for the decays to muons, respectively. Thus, even with a small data sample of only 10 pb\u22121 ,\nthe statistical uncertainty for the Z counting comes close to 1% in each channel.\nSystematic uncertainties from the experimental selection are dominated by the Z efficiency determination and from backgrounds in the W selection. Other sources of uncertainties originate from the knowledge\nof energy scale and the resolution. The lepton efficiencies are evaluated by considering Z \u2192 ll events and\nusing the so called \"tag and probe\" method, like for example described by the D0 experiment [188, 189]. The\nefficiency uncertainty associated with the precision of this method has been estimated for a data sample of 50\npb\u22121 (1 fb\u22121 ) of data to be 2% (0.4%) for W and 3% (0.7%) for Z events. The backgrounds for W events are\nof the order 4% in the electron channel and 7% in the muon channel. The main contributions are from other\nW or Z decays, and are thus well understood, leading to background uncertainties of the order 4% for both\nchannels if a sample 50 pb\u22121 is analyzed. For much larger samples it is expected that uncertainties at or below\n1% can be achieved. The backgrounds for the Z decays are very small, and can be determined accurately from\nmass spectrum, and hence does not carry any sizable uncertainty. It has been demonstrated, that the detector\nscales and resolutions can be determined very accurately [195], and the associated uncertainties are therefore\nalso close to negligible.\nSome detailed studies demonstrate that eventually the systematic error between 1-2% or even smaller might\nbe achieved for the W and Z counting and within the detector acceptance up to rapidities of about 2.5.\nIn order to use this number for the pp luminosity determination the total inclusive W and Z cross-section\nat NNLO can be used. These have been calculated to be 20510 pb and 2015pb, respectively [208]. Variations in\nmodels, floating parameters, and other theoretical uncertainties lead to significant variations in the estimates.\nThe uncertainties on these calculation are estimated to be 5% or smaller. This uncertainty appears to be\ncurrently dominated by the PDF uncertainties needed to extrapolate to the experimentally uncovered large\nrapidity region. More discussions about these uncertainties can be found for example at [209] and [210].\nIt can be assumed that the detailed studies of the rapidity distributions within the acceptance region with\nW and Z decays might eventually lead to further error reductions.\n5.4.3 Measuring Z production, experimental approach in LHCb\nThe uncertainty on the predicted Z production cross section at the LHC comes from two sources: the uncertainty on the NNLO partonic cross section prediction [208], which contributes an uncertainty of < 1%,\nand uncertainties in our understanding of the proton Parton Distribution Functions (PDFs) which, for the latest MSTW fit [39], contribute an uncertainty of \u223c 3% for Z bosons produced with rapidities in the range\n\u22125 < y < 5.\n\nA measurement of the Z production rate at LHCb via the channel Z \u2192 \u03bc+ \u03bc\u2212 , which provides a final\nstate that is both clean and fully reconstructible, can be achieved with high efficiency and little background\ncontamination. In addition, since the dimuon trigger stream at LHCb [211] requires two muons with an\ninvariant mass larger than 2.5GeV and a summed transverse momentum (PT1 + PT2 ) greater than 1.4GeV, a\nhigh trigger efficiency of \u223c 95% is expected for these events. A variety of background sources for this channel\nhave been investigated: other electroweak processes such as Z \u2192 \u03c4 + \u03c4 \u2212 where both taus decay to muons and\nneutrinos; QCD processes such as bb\u0304 \u2192 \u03bc+ \u03bc\u2212 +X; and events where two hadrons with an invariant mass near\nthe Z mass are both mis-identified as muons. To deal with these backgrounds an off-line selection has been\ndeveloped [212] that requires: the dimuon invariant mass to be within 20 GeV of the Z mass; the higher and\n\n\flower transverse momentum muons to be greater than 20 GeV and 15 GeV respectively; the impact parameter\nof both muons is consistent with the primary vertex; and both muons have associated hadronic energy that\nis less than 50 GeV. For Z \u2192 \u03bc+ \u03bc\u2212 events that are triggered and reconstructed at LHCb, these off-line\nselection criteria will select 91 \u00b1 1% of the signal events while reducing the background to (3.0 \u00b1 2.9)% of\nthe signal level with the dominant contribution due to the combinatoric backgrounds from pion and kaon misidentification. It is expected that these backgrounds can be well understood from real data or removed using\nmuon isolation criteria. Overall it is expected that Z \u2192 \u03bc+ \u03bc\u2212 events will be triggered, reconstructed and\nselected at LHCb at a rate of \u223c 190evts/pb\u22121 . Systematic uncertainties have also been investigated and it is\nexpected that with as little as 5pb\u22121 of data the experimental efficiency (trigger, tracking, muon identification\netc.) can be measured with an uncertainty of \u223c 1.5% enabling a luminosity measurement with an uncertainty\nof \u223c 3.5%.\n5.4.4 PDF and relative parton-parton luminosity measurements\nTheoretically well understood reactions at the LHC offer the possibility to use their rapidity distributions to\nimprove todays knowledge of PDFs. Especially the resonance production of W and Z bosons with leptonic\ndecays with low and high transverse momentum and the production of isolated high pt \u03b3-Jet events have\nbeen demonstrated to be very sensitive to the relative parton distribution functions. Simulations from ATLAS\nand CMS have shown that experimental errors on these rapidity regions up to |y| of about 2.5 can probably performed with accuracies eventually reaching perhaps 1% or better. The possibility to cross-check the\nmeasurements with W and Z decays to (a) electron(s) and (b) muon(s) and between both experiments will of\ncourse help to reach the accuracy.\nDuring the past years simulation studies from the LHCb collaboration have shown that the experiment\nhas a unique potential to extend the acceptance region from ATLAS and CMS for muons up to rapidity values\nat least up to 4.5. Furthermore, the existing overlap region for y between 1.9 and 2.5 should allow to reduce\nnormalisation uncertainties. Obviously, these rapidity values are understood as being reasonably accurate but\nqualitative values and more precise values will be defined once real data will allow to define a well understood\nfiducial volume of the detectors.\nIn addition, the LHCb collaboration has investigated the possibility to identify clean samples of very low\nmass Drell-Yan mu-pair events. The results indicate that such pairs can be measured within their acceptance\nregion down to masses of 5 GeV. Such a measurement would in principle allow to measure PDFs for x values\napproaching extremely low values of 10\u22126 for the first time [213].\nIt should be clear that such measurements, which are known to be very sensitive to quark, antiquark\nand gluon relative parton luminosities will not allow an absolute PDF normalisation. Such an improvement of\nabsolute PDF normalisation would require the accurate knowledge of the proton-proton luminosity to better\nthan todays perhaps \u00b1 3% PDF accuracy obtained from the HERA measurements over a large x range and\nobviously lower Q2 . The alternative approach to combine the relative parton luminosities over the larger x, Q2\nrange using the sum rules has, to our knowledge, so far not been studied in sufficient detail.\nA more detailed analysis of the different experimental approaches to improve the PDFs are interesting\nbut are beyond the scope of this note about the luminosity. Nevertheless we hope that the experimentalists\nof the three collaboration will start to combine their efforts and will pursue the PDF measurements, in direct\ncollaboration with theorists, during the coming years.\n5.5 Comparing the different pp luminosity measurements\nA relatively large number of pp luminosity measurements has been proposed and the most relevant have been\ndiscussed in this note. Here we try to give a critical overview of the different methods and their potential\nproblems. Despite these advantages and disadvantage it should be clear that it is important to perform as\nmany as possible independent luminosity methods during the coming years.\n\u2022 The machine luminosity determination using beam parameters:\nThis method will be pursued independently of the experiments and its main purpose will be to optimize the performance of the LHC and thus providing a maximum number of physics collisions for the\n\n\fexperiments. The potential to use this number as an almost instantaneous absolute luminosity number\nwith uncertainties of perhaps \u00b1 10% (and eventually \u00b1 5%), assuming that non gaussian tails of the\nbeam can be controlled to this accuracy will certainly be useful to the experiments. Of course the experiments would lose somewhat their \"independence\" and still need to combine this number with their\nactual active running time.\nHowever, one should remember that the Tevatron experiments did not use this method for their measurements.\nThe method to determine the beam size using the LHCb precision vertex detector look very promising\nand it is hoped that their approach might result in a pp luminosity measurement with an associated\nuncertainty of 3-5%.\n\u2022 Total cross section and absolute luminosity normalisation with specialized far forward Detectors:\nThe luminosity independent total pp cross section measurement is planned by the TOTEM collaboration\nand by the ALFA detector. Using these numbers both ATLAS and CMS plan to obtain the pp luminosity\nfrom the counting of the pp elastic scattering counting numbers from the forward detectors which thus\ndepend on the knowledge of the total cross section measurement. In order to obtain this number some\nfew weeks of special optics and low luminosity LHC running are required. As all LHC experiments\nare very keen to obtain as quickly as possible some reasonable luminosity at 14 TeV center of mass\nenergy it is not likely that those special LHC data taking will happen during the first year(s) of data\ntaking. Furthermore, despite the hope that the total cross section can be determined in principle with an\ninteresting accuracy of \u00b1 1%, it remains to be demonstrated with real LHC running. In this respect it\nis worth remembering that the two independent measurements of the total cross section at the Tevatron\ndiffered by 12% while much smaller errors were obtained by the individual experiments. As a result the\naverage value with an error of \u00b16% was used for the luminosity normalisation.\n\u2022 Luminosity determination using Z \u2192 ll:\nThis method provides an accurate large statistic relative luminosity number. It will be as accurate as the\ntheoretical cross section calculation, which is based on the absolute knowledge of the PDFs from other\nexperiments, from unknown higher order corrections and their incomplete Monte Carlo implementation.\nTodays uncertainties are estimated to be about 5%. It has been estimated, assuming the experiments\nperform as expected, that the potential Z counting accuracy within the acceptance region including\nefficiency corrections might quickly reach \u00b11%. The extrapolation to the uncovered rapidity space,\nmainly due to the worse knowledge of the PDFs in this region, increases the error to perhaps 3%. Taking\nother theoretical uncertainties into account an error of \u00b15% is currently estimated. Of course, advocates\nof the Z normalisation method like to point out that the real power of this method starts once relative\nmeasurements, covering similar partons and similar ranges of the parton distribution functions will be\nperformed with statistical errors below 5%. Examples where such a normalization procedure looks\nespecially interesting are the relative cross section measurements of N (Z)/N (W ), N (W + )/N (W \u2212 ),\nhigh mass Drell-Yan events with respect to Z events and diboson final states decaying to leptons. Of\ncourse, correlations and anticorrelations between quark and gluon dominated production rates exist\nand need to be carefully investigated before similar advantages for the gluon PDFs can eventually be\nexploited. The loss of an independent Z cross section measurement would of course be a fact of life.\n\u2022 pp luminosity from the reaction pp \u2192 pp\u03bc\u03bc:\nA measurement of this reaction offers in principle a direct and theoretically accurate proton proton\nluminosity value. Unfortunately current simulations from the experiments indicate that the accepted\ncross section is relatively small and only a few 1000 events can be expected per fb\u22121 . The different\nsimulation results indicate that the backgrounds can be suppressed sufficiently without increasing the\nexperimental systematics too much. The current simulation results indicate that small systematic errors\nof perhaps 1-2% might eventually be achievable53 once a yearly luminosity of 5-10 fb\u22121 in ATLAS and\nCMS (2 fb\u22121 for LHCb) might be recorded. It remains to be seen if muons with transverse momenta\nwell below 20 GeV can indeed be measured as accurately as muons with transverse momenta above 25\nGeV.\n53\nIt might be interesting to study the experience from similar measurements at the experimentally ideal conditions of LEP, where\nuncertainties above \u00b1 3% have been reported [205].\n\n\f5.5.1 Which luminosity accuracy might be achievable and when\nOf course the potential time dependent accuracy of the different luminosity methods can only be guessed\ntoday as such numbers depend obviously on the LHC machine performance during the coming years. For the\npurpose of this Section we are mainly interested in measurements at the 14 TeV center of mass energy and\nassume that the following \"data samples\" would define such \"years\". Of course, it could be hoped that the\nluminosity and energy increase would go much faster resulting in \"some\" shorter LHC years. Thus we assume\nthat the first 14 TeV year, currently expected to be 2010, will correspond to 0.1 fb\u22121 , followed by a 1 fb\u22121\nyear. During the third and fourth year ATLAS and CMS expect to collect about 5 fb\u22121 and 10 fb\u22121 while\nLHCb expects to collect roughly 2 fb\u22121 per year. We assume further that the special optics low luminosity\ndata taking periods requiring perhaps a few weeks for TOTEM and similar for ALFA will take only place\nduring the year when more than 1 fb\u22121 per year or more can be expected.\nAs a result, for the first two 14 TeV running years, realistic luminosity numbers could come from (1)\nthe machine group and (2) from the indirect method using the inclusive production of Z events with leptonic\ndecays.\nAs has been pointed out in Section 5.3.1 the method (1) would, without any additional efforts by the\nmachine group, allow a first estimate with a \u00b1 20-30% luminosity accuracy. We assume however that, due to\nthe delay of the real 14 TeV start to 2010, enough resources could be found that people within the machine\ngroup could carefully prepare for the necessary beam parameter measurements and that the experiments will\ndo the corresponding efforts to correct such a machine luminosity number for real detector data taking one\ncould hope for a 10% measurement for 2010 and a 5% accuracy for 2011.\nIn contrast, method (2) would by definition be an integrated part of any imaginable experimental LHC\ndata taking period. In fact, if enough attention is put into the Z counting method, the data expected during\n2010 running might already reach statistical errors of \u00b1 2% per 5 pb\u22121 periods. Thus perhaps about 10-20\nsuch periods could be defined during the entire year and systematic errors for the lepton efficiency correction\nwithin the detector acceptance could reach similar \u00b1 2-3% accuracies. During the following years these\nerrors might decrease further to 1% or better. Once the rate of any \"stable\" simple high rate final states and\neven trigger rates relative to the Z counting rate has been determined, such relative event rates can be used\nsubsequently to track the \"run\" luminosity and even the real time luminosity with similar accuracy.\nTheoretical limitations of the cross section knowledge, not expected to improve without LHC data taking, would limit the accuracy to about \u00b1 5%. The expected detailed analysis of the 2010 rapidity distributions\nof W, Z and \u03b3-jet events will allow some improvements for the years 2011 and beyond. We can thus expect\nthat appropriate ratio measurements like the cross section ratio measurements of Z/W \u00b1 and W \u2212 /W + will\nalready reach systematic accuracies of \u00b1 1-2% during 2010 and 1% or better in the following years. Measurement of b physics, either in LHCb or in ATLAS and CMS might in any case prefer to perform luminosity\nindependent measurements and relate any of the \"new\" measurements to some relatively well known and\nmeasurable B-hadron decays.\nIt is also worth pointing out that currently no other high Q2 reaction has been envisioned, which might\nbe measurable to a systematic precision of better than 5-10% and a luminosity of up to 1fb\u22121 . In addition,\nmost of the interesting high Q2 electroweak final states will unfortunately even be limited for the first few\nLHC years to statistical accuracies to 5% or more.\nThe prospect for the other luminosity measurements start to become at earliest interesting only once a\nfew 100 pb\u22121 can be recorded. Consequently one can expect to obtain a statistical interesting accuracy from\nthe reaction pp \u2192 pp\u03bc\u03bc after 2010. Similar, it looks unlikely that low luminosity special optics run will\nbe performed before 2011. Consequently one might hope that few % accurate total cross section numbers\nbecome available before the 2012 data taking period will start.\n5.6 Summary and Outlook\nA large variety of potentially interesting pp luminosity measurements, proposed during the past 10-15 years,\nare presented in this Section.\nRealistically only the machine luminosity measurement and the counting of the Z production might\n\n\freach interesting accuracies of 5% before 2011. For all practical purposes it looks that both methods should\nbe prepared in great detail before the data taking at 14 TeV collision energies will start in 2010.\nWe believe that a working group, consisting of interested members of the three pp collider experiments\nand interested theorists, should be formed to prepare the necessary Monte Carlo tools to make the best possible\nuse of the soon expected W and Z data, not only for the pp luminosity normalization but even more for the\ndetailed investigations of the parton parton luminosity determination and their use to predict other event rates\nfor diboson production processes and high mass Drell-Yan events.\n\n\f6 OUTLOOK: THE PDF4LHC INITIATIVE54\nThis document demonstrates the vast amount of progress that has taken place in the last years on pinning down\nthe PDFs of the proton, as well as the dramatic increase in awareness of the impact of PDFs on the physics\nprogram of LHC experiments. The HERALHC workshop has acted as a regular forum for working meetings\nbetween the experiments, PDF phenomenologists and theorists. In the course of this workshop, it was realized\nthat the momentum on the PDF studies should be kept and perhaps even focused more on the LHC, in order\nto continue the discussions, investigations and further work towards improving our knowledge on the PDFs.\nClearly, LHC will need the best PDFs, especially for precision measurements, setting of limits in\nsearches, and even for discoveries. Ideally the ATLAS and CMS (and LHCb and ALICE) analyses should\nfollow a common procedure for using PDFs and their uncertainties in their key analyses. Such a common\nprocedure, across the experiments, is being used in other contexts, such as significance estimates in searches.\nAlso, changing frequently the PDFs in the software of the experiments, e.g. for cross\u2013checks or the determination of error bands, is often non-trivial (e.g. due to the inter-connection with parameter choices for underlying\nevent modeling, showering parameters and so on) and sometimes impractical if CPU intensive detector simulations are involved. LHC studies therefore will need both good central values for the PDFs to start with, and\na good estimate of the associated uncertainties.\nThis has triggered the so called PDF4LHC initiative. PDF4LHC offers a discussion forum for PDF\nstudies and information exchange between all stake-holders in the field: the PDF global fitter groups, such\nas CTEQ and MSTW; the current experiments, such as the HERA and Tevatron ones; QCD theorists and\nthe LHC experimental community. The PDF4LHC initiative started in 2008. More details and links to the\nmeetings so far can be found on the PDF4LHC web site [214].\nThe mission statement of PDF4LHC is:\n\u2022 Getting the best PDFs, including the PDF uncertainties, based on the present data.\n\u2022 Devise strategies to use future LHC data to improve the PDFs.\n\nAll this needs a close collaboration between theorists and those that are preparing to make the measurements.\nIn order to reach the first goal, the PDF4LHC forum aims to stimulate discussions and trigger further comparison exercises across the PDF community, in order to select one or a limited number of possible strategies that\ncan be adapted to determine and use PDFs. For the second goal, PDF4LHC should also be a forum for discussions on how to include measurements from the LHC to constrain PDFs: what should be measured at LHC,\nand correspondingly calculated in theory. Such measurements include W and Z production and asymmetries,\ndi-jet production, hard prompt photons, Drell-Yan production, bottom and top quark production, Z-shape fits\nand Z+jets measurements. One expects that some of these channels can already be studied with first data,\nhence we need to prepare for that well in advance.\nThe following issues are part of the program for in depth discussions via topical workshops, some of\nwhich took place already in 2008 [214].\n\u2022 Data to be included in the PDFs. Would we get better results with a selection of data to be used? New\ndata will become available such as FL (x, Q2 ), and combined data from H1/ZEUS. Can we extract more\nfrom the data?\n\u2022 Determination of PDF uncertainties, including the statistical treatment of the data.\n\u2022 Theoretical uncertainties and regions/processes where they matter: higher\u2013order corrections; heavy\nflavour treatment; low-x (and high-x) resummation; other PDFs like unintegrated PDFs (and GPDs).\n\u2022 PDFs for usage Monte Carlo generators.\n\nOne can expect that the LHC experiments most likely will be using for most of their studies the PDF\nsets and errors that are delivered by either one of the CTEQ or MSTW family. Hence it is important that\nthe lessons learned from exercises on studies of the systematics on PDFs will be adapted by these main\nglobal PDF providers. PDF4LHC aims to advice the experiments in the use for PDFs for the LHC, based on\nthe discussions, results and future consensus at the forum. The experience and results from HERAPDFs, and\nPDFs from other groups, like the Neural Net or Alekhin ones are extremely valuable in this discussion and will\n54\n\nContributing author: A. de Roeck\n\n\fserve as crucial input in studies to demonstrate how well we actually know the parton distributions. Several\nimportant benchmark exercises have been already performed and are reported in section 3 of this report.\nA special case are the PDFs for Monte Carlo generators. For experiments it is important that generated events be kinematically distributed close to the distribution of the real data, such that the simulated and\nreconstructed Monte Carlo events can be used in a straightforward way to calculate efficiencies for e.g. experimental cuts in an analysis. In case the initially generated distribution does not resemble the data close enough,\nthe Monte Carlo samples need to be reweighted, with all its possible drawbacks. Since calculations based on\nLO Matrix Elements and LO PDFs are known not to describe the data well, and NLO Matrix Element based\ngenerators to date have so far only a restricted number of processes implemented, studies are ongoing on so\ncalled \"improved LO\" PDFs, which try to cure some of the LO PDF drawbacks. Examples are given in [215].\nThis is yet another part of the discussions in the PDF4LHC forum\nIn short, it is crucial that the work started here continues, with discussions and studies on PDFs and\ntheir uncertainties, the impact of the upcoming data on future PDF determinations and more, all with special\nfocus on the needs for the LHC. The PDF4LHC initiative will offer a framework to do all this.\n\nACKNOWLEDGEMENTS\nThis work was supported in part by the following grants and agencies: the European network HEPTOOLS\nunder contract MRTN-CT-2006-035505; ANR-05-JCJC-0046-01 (France) PRIN-2006 (Italy); MEC FIS200405639-C02-01; (Spain) and the Scottish Universities Physics Alliance (UK).\nReferences\n[1] Dittmar, M. and others, Parton distributions: Summary report for the HERA - LHC workshop.\nPreprint hep-ph/0511119, 2005.\n[2] Larin, S. A. and van Ritbergen, T. and Vermaseren, J. A. M., Nucl. Phys. B427, 41 (1994).\n[3] Larin, S. A. and Nogueira, Paulo and van Ritbergen, T. and Vermaseren, J. A. M., Nucl. Phys.\nB492, 338 (1997).\n[4] Retey, A. and Vermaseren, J. A. M., Nucl. Phys. B604, 281 (2001).\n[5] Moch, S. and Vermaseren, J. A. M. and Vogt, A., Nucl. Phys. B688, 101 (2004).\n[6] Vogt, A. and Moch, S. and Vermaseren, J. A. M., Nucl. Phys. B691, 129 (2004).\n[7] Moch, S. and Vermaseren, J. A. M. and Vogt, A., Phys. Lett. B606, 123 (2005).\n[8] Vermaseren, J. A. M. and Vogt, A. and Moch, S., Nucl. Phys. B724, 3 (2005).\n[9] Vogt, Andreas and Moch, Sven and Vermaseren, Jos, Nucl. Phys. Proc. Suppl. 160, 44 (2006).\n[10] Moch, S. and Rogal, M., Nucl. Phys. B782, 51 (2007).\n[11] Moch, S. and Rogal, M. and Vogt, A., Nucl. Phys. B790, 317 (2008).\n[12] Vogt, A. and Moch, S. and Rogal, M. and Vermaseren, J. A. M., Nucl. Phys. Proc. Suppl.\n183, 155 (2008).\n[13] Moch, S. and Rogal, M. and Vogt, A. and Vermaseren, J.A.M. In preparation.\n[14] Yao, W. -M. and others, J. Phys. G33, 1 (2006).\n\n\f[15] Yang, Un-Ki and others, Phys. Rev. Lett. 86, 2742 (2001).\n[16] Tzanov, M. and others, Phys. Rev. D74, 012008 (2006).\n[17] Onengut, G. and others, Phys. Lett. B632, 65 (2006).\n[18] Adloff, C. and others, Eur. Phys. J. C30, 1 (2003).\n[19] Chekanov, S. and others, Eur. Phys. J. C32, 1 (2003).\n[20] Aktas, A. and others, Phys. Lett. B634, 173 (2006).\n[21] Chekanov, S. and others, Phys. Lett. B637, 210 (2006).\n[22] Mangano, Michelangelo L. and others, Physics at the front-end of a neutrino factory: A quantitative\nappraisal. Preprint hep-ph/0105155, 2001.\n[23] Dainton, J. B. and Klein, M. and Newman, P. and Perez, E. and Willeke, F., JINST 1, P10001 (2006).\n[24] Zeller, G. P. and others, Phys. Rev. Lett. 88, 091802 (2002).\n[25] Aktas, A. and others, Phys. Lett. B632, 35 (2006).\n[26] Davidson, S. and Forte, S. and Gambino, P. and Rius, N. and Strumia, A., JHEP 02, 037 (2002).\n[27] McFarland, Kevin S. and Moch, Sven-Olaf, Conventional physics explanations for the NuTeV\nsin**2(theta(W)). Preprint hep-ph/0306052, 2003.\n[28] Dobrescu, Bogdan A. and Ellis, R. Keith, Phys. Rev. D69, 114014 (2004).\n[29] Kretzer, Stefan and others, Phys. Rev. Lett. 93, 041802 (2004).\n[30] Buras, Andrzej J., Rev. Mod. Phys. 52, 199 (1980).\n[31] Gorishnii, S. G. and Larin, S. A. and Surguladze, L. R. and Tkachov, F. V., Comput. Phys. Commun.\n55, 381 (1989).\n[32] Larin, S. A. and Tkachov, F. V. and Vermaseren, J. A. M. NIKHEF-H-91-18.\n[33] Broadhurst, David J. and Kataev, A. L. and Maxwell, C. J., Phys. Lett. B590, 76 (2004).\n[34] Van Neerven, W. L. and Vogt, A., Nucl. Phys. B603, 42 (2001).\n[35] Paschos, E. A. and Wolfenstein, L., Phys. Rev. D7, 91 (1973).\n[36] Moch, S. and Vermaseren, J. A. M. and Vogt, A., Nucl. Phys. B726, 317 (2005).\n[37] Catani, Stefano and de Florian, Daniel and Rodrigo, German and Vogelsang, Werner, Phys. Rev. Lett.\n93, 152003 (2004).\n[38] Lai, H. L. and others, JHEP 04, 089 (2007).\n[39] Thorne, R. S. and Martin, A. D. and Stirling, W. J. and Watt, G., Parton Distributions for the LHC.\nPreprint 0706.0456, 2007.\n[40] Vogt, Andreas (2007). arXiv:0707.4106.\n[41] Fadin, Victor S. and Kuraev, E. A. and Lipatov, L. N., Phys. Lett. B60, 50 (1975).\n[42] Balitsky, I. I. and Lipatov, L. N., Sov. J. Nucl. Phys. 28, 822 (1978).\n[43] Fadin, Victor S. and Lipatov, L. N., Phys. Lett. B429, 127 (1998).\n\n\f[44] Camici, G. and Ciafaloni, M., Phys. Lett. B412, 396 (1997).\n[45] Ciafaloni, Marcello and Camici, Gianni, Phys. Lett. B430, 349 (1998).\n[46] Marzani, Simone and Ball, Richard D. and Falgari, Pietro and Forte, Stefano, Nucl. Phys.\nB783, 143 (2007).\n[47] Ciafaloni, M. and Colferai, D. and Colferai, D. and Salam, G. P. and Stasto, A. M., Phys. Lett.\nB576, 143 (2003).\n[48] Ciafaloni, M. and Colferai, D. and Salam, G. P. and Stasto, A. M., Phys. Rev. D68, 114003 (2003).\n[49] Catani, S. and Ciafaloni, M. and Hautmann, F., Nucl. Phys. B366, 135 (1991).\n[50] Catani, S. and Hautmann, F., Nucl. Phys. B427, 475 (1994).\n[51] Bialas, A. and Navelet, H. and Peschanski, Robert B., Nucl. Phys. B603, 218 (2001).\n[52] White, C. D. and Peschanski, Robert B. and Thorne, R. S., Phys. Lett. B639, 652 (2006).\n[53] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. B575, 313 (2000).\n[54] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. B621, 359 (2002).\n[55] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. B674, 459 (2003).\n[56] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. B742, 1 (2006).\n[57] Ball, Richard D. and Forte, Stefano, Nucl. Phys. B742, 158 (2006).\n[58] Ball, Richard D., Nucl. Phys. B796, 137 (2008).\n[59] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. B799, 199 (2008).\n[60] Altarelli, Guido and Ball, Richard D and Forte, Stefano, Structure Function Resummation in small-x\nQCD. Preprint 0802.0968, 2007.\n[61] Salam, G. P., JHEP 07, 019 (1998).\n[62] Ciafaloni, M. and Colferai, D., Phys. Lett. B452, 372 (1999).\n[63] Ciafaloni, M. and Colferai, D. and Salam, G. P., Phys. Rev. D60, 114036 (1999).\n[64] Ciafaloni, Marcello and Colferai, Dimitri and Salam, Gavin P., JHEP 07, 054 (2000).\n[65] Ciafaloni, M. and Colferai, D., JHEP 09, 069 (2005).\n[66] Ciafaloni, M. and Colferai, D. and Salam, G. P. and Stasto, A. M., Phys. Lett. B635, 320 (2006).\n[67] Ciafaloni, M. and Colferai, D. and Salam, G. P. and Stasto, A. M., JHEP 08, 046 (2007).\n[68] Thorne, Robert S., Phys. Rev. D60, 054031 (1999).\n[69] Thorne, R. S., Nucl. Phys. Proc. Suppl. 79, 210 (1999).\n[70] Thorne, Robert S., Phys. Lett. B474, 372 (2000).\n[71] Thorne, Robert S., Phys. Rev. D64, 074005 (2001).\n[72] White, C. D. and Thorne, R. S., Phys. Rev. D74, 014002 (2006).\n[73] White, C. D. and Thorne, R. S., Phys. Rev. D75, 034005 (2007).\n\n\f[74] Ball, Richard D. and Forte, Stefano, Phys. Lett. B465, 271 (1999).\n[75] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. B599, 383 (2001).\n[76] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, An improved splitting function for small x\nevolution. Preprint hep-ph/0310016, 2003.\n[77] Altarelli, Guido and Ball, Richard D. and Forte, Stefano, Nucl. Phys. Proc. Suppl. 135, 163 (2004).\n[78] Ball, Richard D. and Forte, Stefano, Phys. Lett. B405, 317 (1997).\n[79] Lipatov, L., Sov. Phys. JETP 5, 5 (1986).\n[80] Ball, R. D. and Ellis, R. Keith, JHEP 05, 053 (2001).\n[81] Andersson, Bo and Gustafson, G. and Kharraziha, H. and Samuelsson, J., Z. Phys. C71, 613 (1996).\n[82] Kwiecinski, J. and Martin, Alan D. and Sutton, P. J., Z. Phys. C71, 585 (1996).\n[83] Kwiecinski, J. and Martin, Alan D. and Stasto, A. M., Phys. Rev. D56, 3991 (1997).\n[84] Collins, John C. and Kwiecinski, J., Nucl. Phys. B316, 307 (1989).\n[85] White, C. D. and Thorne, R. S., Eur. Phys. J. C45, 179 (2006).\n[86] Abbott, B. and others, Phys. Rev. Lett. 86, 1707 (2001).\n[87] Affolder, T. and others, Phys. Rev. D64, 032001 (2001).\n[88] Adloff, C. and others, Eur. Phys. J. C19, 269 (2001).\n[89] Adloff, C. and others, Eur. Phys. J. C21, 33 (2001).\n[90] Breitweg, J. and others, Eur. Phys. J. C7, 609 (1999).\n[91] Chekanov, S. and others, Eur. Phys. J. C21, 443 (2001).\n[92] Martin, A. D. and Stirling, W. J. and Thorne, R. S., Phys. Lett. B635, 305 (2006).\n[93] Thorne, R. S., Phys. Rev. D73, 054019 (2006).\n[94] Aaron, F. D. and others, Phys. Lett. B665, 139 (2008).\n[95] Martin, A. D. and Stirling, W. J. and Thorne, R. S. and Watt, G., Phys. Lett. B652, 292 (2007).\n[96] Ciafaloni, Marcello, Phys. Lett. B356, 74 (1995).\n[97] Diemoz, M. and Ferroni, F. and Longo, E. and Martinelli, G., Z. Phys. C39, 21 (1988).\n[98] Ball, Richard D. and Forte, Stefano, Phys. Lett. B359, 362 (1995).\n[99] R. P. Feynman, Photon\u2013Hadron Interactions. Benjamin, New York, 1972.\n[100] Bjorken, J.D., Lecture Notes in Physics, 56, Springer, Berlin (1976).\n[101] Kuraev, E.A. and Lipatov, L.N. and Fadin, V.S., Sov. Phys. JETP 45, 199 (1977).\n[102] V. N. Gribov and L. N. Lipatov, Sov. J. Nucl. Phys. 15, 438 (1972).\n[103] V. N. Gribov and L. N. Lipatov, Sov. J. Nucl. Phys. 15, 675 (1972).\n[104] G. Altarelli and G. Parisi, Nucl. Phys. B 126, 298 (1977).\n\n\f[105] Yu. L. Dokshitzer, Sov. Phys. JETP 46, 641 (1977).\n[106] Gribov, L.V. and Levin, E.M. and Ryskin, M.G., Phys. Rept. 100, 1 (1983).\n[107] Mueller, A.H., Nucl. Phys. B558, 285 (1999).\n[108] Iancu, E. and Venugopalan, R., The color glass condensate and high energy scattering in QCD.\nPreprint hep-ph/0303204, 2003.\n[109] Balitsky, I., Nucl. Phys. B463, 99 (1996).\n[110] Kovchegov, Yu.V., Phys. Rev. D61, 074018 (2000).\n[111] Stasto, A. M. and Golec-Biernat, Krzysztof J. and Kwiecinski, J., Phys. Rev. Lett. 86, 596 (2001).\n[112] Munier, S. and Peschanski, R., Phys. Rev. D69, 034008 (2004).\n[113] Gelis, F. and Peschanski, Robert B. and Soyez, G. and Schoeffel, L., Phys. Lett. B647, 376 (2007).\n[114] Breitweg, J. and others, Phys. Lett. B487, 273 (2000).\n[115] Chekanov, S. and others, Phys. Rev. D70, 052001 (2004).\n[116] Arneodo, M. and others, Nucl. Phys. B483, 3 (1997).\n[117] Adams, M. R. and others, Phys. Rev. D54, 3006 (1996).\n[118] Beuf, G. and Peschanski, R. and Royon, C. and Salek, D., Systematic Analysis of Scaling Properties in\nDeep Inelastic Scattering. Preprint arXiv:0803.2186 [hep-ph], 2008.\n[119] Aaron, F. D. and others, Phys. Lett. B659, 796 (2008).\n[120] Aktas, A. and others, Eur. Phys. J. C44, 1 (2005).\n[121] Aktas, A. and others, Eur. Phys. J. C48, 715 (2006).\n[122] Chekanov, S. and others, Nucl. Phys. B713, 3 (2005).\n[123] Chekanov, S. and others, Eur. Phys. J. C38, 43 (2004).\n[124] Chekanov, S. and others, Nucl. Phys. B718, 3 (2005).\n[125] Aktas, A. and others, Eur. Phys. J. C46, 585 (2006).\n[126] Adloff, C. and others, Eur. Phys. J. C13, 371 (2000).\n[127] Adloff, C. and others, Z. Phys. C72, 593 (1996).\n[128] Adloff, C. and others, Phys. Lett. B528, 199 (2002).\n[129] Breitweg, J. and others, Phys. Lett. B407, 402 (1997).\n[130] Aubert, J. J. and others, Nucl. Phys. B213, 31 (1983).\n[131] Nadolsky, Pavel M. and others, Phys. Rev. D78, 013004 (2008).\n[132] Martin, A. D. and Roberts, R. G. and Stirling, W. J. and Thorne, R. S., Phys. Lett. B604, 61 (2004).\n[133] Gluck, M. and Reya, E. and Vogt, A., Eur. Phys. J. C5, 461 (1998).\n[134] Beuf, G., Royon, C. and Salek, D., to appear.\n[135] Iancu, E. and Itakura, K. and McLerran, L., Nucl. Phys. A708, 327 (2002).\n\n\f[136] Mueller, A. H. and Triantafyllopoulos, D. N., Nucl. Phys. B640, 331 (2002).\n[137] Gardi, E. and Kuokkanen, J. and Rummukainen, K. and Weigert, H., Nucl. Phys. A784, 282 (2007).\n[138] Albacete, Javier L. and Kovchegov, Yuri V., Phys. Rev. D75, 125021 (2007).\n[139] Beuf, G., An alternative scaling solution for high-energy qcd saturation with running coupling.\nPreprint arXiv:0803.2167 [hep-ph], 2008.\n[140] Kwiecinski, J. and Stasto, A. M., Phys. Rev. D66, 014013 (2002).\n[141] Caola, F. and Forte, S., Phys. Rev. Lett. 101, 022001 (2008).\n[142] Del Debbio, Luigi and Forte, Stefano and Latorre, Jose I. and Piccione, Andrea and Rojo, Joan, JHEP\n03, 080 (2005).\n[143] Bartels, J. and Golec-Biernat, Krzysztof J. and Kowalski, H., Phys. Rev. D66, 014001 (2002).\n[144] J. Bartels, K. Golec-Biernat and L. Motyka, in preparation.\n[145] L. Motyka, Higher twists from the saturation model.\nTalk at the 4th HERA and the LHC workshop, CERN, 26\u201330 May 2008,\nhttp://indico.cern.ch/conferenceDisplay.py?confId=27458.\n[146] Bartels, Jochen and Golec-Biernat, Krzysztof J. and Peters, Krisztian, Eur. Phys. J. C17, 121 (2000).\n[147] Ellis, R. Keith and Furmanski, W. and Petronzio, R., Nucl. Phys. B212, 29 (1983).\n[148] Bukhvostov, A. P. and Frolov, G. V. and Lipatov, L. N. and Kuraev, E. A., Nucl. Phys.\nB258, 601 (1985).\n[149] Bartels, Jochen and Ryskin, M. G., Z. Phys. C60, 751 (1993).\n[150] Bartels, Jochen and Ryskin, M. G., Z. Phys. C62, 425 (1994).\n[151] Golec-Biernat, Krzysztof J. and Wusthoff, M., Phys. Rev. D59, 014017 (1999).\n[152] Golec-Biernat, Krzysztof J. and Wusthoff, M., Phys. Rev. D60, 114023 (1999).\n[153] Giele, Walter T. and Keller, Stephane, Phys. Rev. D58, 094023 (1998).\n[154] Giele, Walter T. and Keller, Stephane A. and Kosower, David A. (2001).\n[155] Ball, Richard D. and others, Nucl. Phys. B809, 1 (2009).\n[156] Watt, G. and Martin, A. D. and Stirling, W. J. and Thorne, R. S., Recent Progress in Global PDF\nAnalysis. Preprint 0806.4890, 2008.\n[157] Adloff, C. and others, Eur. Phys. J. C13, 609 (2000).\n[158] Giele, W. and others, The QCD/SM working group: Summary report. Preprint hep-ph/0204316, 2002.\n[159] Arneodo, M. and others, Nucl. Phys. B487, 3 (1997).\n[160] Benvenuti, A. C. and others, Phys. Lett. B223, 485 (1989).\n[161] Badelek, B. and Kwiecinski, J., Phys. Rev. D50, 4 (1994).\n[162] Vargas Trevino, Andrea del Rocio, Measurement of the inclusive e p scattering cross section at low\nQ**2 and x at HERA. Prepared for 15th International Workshop on Deep-Inelastic Scattering and\nRelated Subjects (DIS2007), Munich, Germany, 16-20 Apr 2007.\n\n\f[163] M. Botje, Qcdnum16.12. Available from http://www.nikhef.nl/ h24/qcdnum/.\n[164] Martin, A. D. and Roberts, R. G. and Stirling, W. J. and Thorne, R. S., Eur. Phys. J. C28, 455 (2003).\n[165] Forte, Stefano and Garrido, Lluis and Latorre, Jose I. and Piccione, Andrea, JHEP 05, 062 (2002).\n[166] Del Debbio, Luigi and Forte, Stefano and Latorre, Jose I. and Piccione, Andrea and Rojo, Joan, JHEP\n03, 039 (2007).\n[167] Amsler, C. and others, Phys. Lett. B667, 1 (2008).\n[168] A.D. Martin et al, Eur. Phys.J C 23, 73 (2002).\n[169] J. Pumplin, H. L. Lai and W. K. Tung, Phys. Rev. D 75, 054029 (2007).\n[170] ZEUS Coll., S. Chekanov et al., Eur. Phys. J. C 42, 1 (2005).\n[171] A.M. Cooper-Sarkar, Phys. Rev D 67, 012007 (2003).\n[172] ZEUS and H1 Collaborations, Combination of h1 and zeus deep inelastic e+- p scattering cross\nsections. Preprint ZEUS-prel-07-036, H1prelim-07-007.\n[173] C. Pascaud and F. Zomer, Qcd analysis from the proton structure function f2 measurement: Issues on\nfitting, statistical and systematic errors. Preprint LAL-95-05, 1995.\n[174] C. Callan and D. Gross, Phys. Rev. Lett. 22, 156 (1969).\n[175] A. Zee, F. Wilczek and S. B. Treiman, Phys. Rev. D 10, 2881 (1974);\nG. Altarelli and G. Martinelli, Phys. Lett. B 76, 89 (1978).\n[176] L. N. Lipatov, Sov. J. Nucl. Phys. 20, 94 (1975).\n[177] ZEUS Coll., S. Chekanov et al., in EPS 2003 conference, Aachen. 2003.\n[178] H1 Coll., C. Adloff et al., Phys. Lett. B 393, 452 (1997).\n[179] A. Vargas Trevino, Measurement of the Inclusive ep Scattering Cross Section at low Q2 and x at\nHERA, in Proceedings of the 15th International Workshop on Deep-Inelastic Scattering. 2007.\n[180] T. Lastovicka, Eur. Phys. J. C 24, 529 (2002).\n[181] H1 Coll., F. D. Aaron et al., Phys. Lett. B 665, 139 (2008).\n[182] A. D. Martin, W. J. Stirling, R. S. Thorne and G. Watt, Phys. Lett. B 652, 292 (2007).\n[183] Up to Date Performance of the ATLAS, CMS and LHCb Detectors and further detailed references can\nbe found on the corresponding homepages http://atlas.web.cern.ch/Atlas/index.html,\nhttp://cmsinfo.cern.ch/Welcome.html/ and http://lhcb.web.cern.ch/lhcb/.\n[184] W. Herr and B. Muratori, Concept of luminosity. Proceedings CAS2003,\nhttp://doc.cern.ch/yellowrep/2006//p361.pdfCERN-2006-002 p. 361.\n[185] H. Burkhardt and P. Grafstrom, Absolute luminosity from machine parameters. 2007.\nCERN-LHC-PROJECT-Report-1019 and http://cdsweb.cern.ch/record/1056691.\n[186] Budnev, V. M. and Ginzburg, I. F. and Meledin, G. V. and Serbo, V. G., Nucl. Phys. B63, 519 (1973).\n[187] Khoze, Valery A. and Martin, Alan D. and Orava, R. and Ryskin, M. G., Eur. Phys. J. C19, 313 (2001).\n[188] Acosta, Darin E. and others, Phys. Rev. Lett. 94, 091803 (2005).\n\n\f[189] Bellavance, Angela M., W / Z production cross sections and asymmetries at E(CM) = 2-TeV. Preprint\nhep-ex/0506025, 2005.\n[190] M. Dittmar, F. Pauss and D. Zurcher, Phys. Rev. D56, 7284 (1997).\n[191] Pinfold, J., Plans for the very forward region of ATLAS: The lucid luminosity monitor. Prepared for\n9th ICATPP Conference on Astroparticle, Particle, Space Physics, Detectors and Medical Physics\nApplications, Villa Erba, Como, Italy, 17-21 Oct 2005.\n[192] Anelli, G. and others, JINST 3, S08007 (2008).\n[193] LHCb Technical Proposal, CERN-LHCC-98-004.\n[194] LHCb Technical Design Report 9 LHCb Reoptimized Detector, CERN-LHCC-2003-030.\n[195] Besson, N. and Boonekamp, M. and Klinkby, E. and Petersen, T. and Mehlhase, S., Eur. Phys. J.\nC57, 627 (2008).\n[196] See CMS Collaboration CMS PAS EWK-08-005 for Electrons and CMS PAS 2007/002 for Muons.\n[197] See LHCb Technical Design Report 10, LHCb Trigger System, CERN-LHCC-2003-031.\n[198] H. Schmickler, How to measure beam intensity ?\nhttp://indico.cern.ch/getFile.py/access?contribId=s1t18&resId=1&materialId=1&confId=a053945Talk\ngiven to Atlas 27 June 2005.\n[199] S. Van der Meer, Calibration of the effective beam height in the isr.\nhttp://doc.cern.ch//archive/electronic/kek-scan//196800064.pdfCERN-ISR-PO-.\n[200] K. Potter, Luminosity measurements and calculations. CAS 1992, CERN yellow report,\nhttp://doc.cern.ch/yellowrep/1994/94-01/p117.pdfp. 117 ff.\n[201] G. Carboni et al., Nucl. Phys. B254, 697 (1985).\n[202] Ferro-Luzzi, M., Nucl. Instrum. Meth. A553, 388 (2005).\n[203] The CMS Approach using Specialized High Rate Detectors is Described in the Talk of V.Halyo during\nthe HERA-LHC Workshop \"standard candles\".\n[204] The Presentations of the \"standard candle\" session during the HERA LHC Workshop in May 2008 can\nbe found at:\nhttp://indico.cern.ch/conferenceOtherViews.py?view=cdsagenda olist&confId=27458#18..\n[205] Achard, P. and others, Phys. Lett. B585, 53 (2004).\n[206] Shamov, A. G. and Telnov, Valery I., Nucl. Instrum. Meth. A494, 51 (2002).\n[207] More Details about the LHCb Approach using pp \u2192 pp+\u2212 , are given in the talk of J. Anderson at the\nHERA-LHC Workshop \"standard candles\".\n[208] C Anastasiou, L. J. Dixon, K. Melnikov, and F. Petriello, Phys. Rev. D69, 094008 (2004).\n[209] N. E. Adam, V. Halyo, S. A. Yost, JHEP 05 (2008).\n[210] N. E. Adam, V. Halyo, S. Yost W. Zhu, JHEP 09, 13 (2008).\n[211] LHCb Technical Design Report 10, LHCb Trigger System, CERN-LHCC-2003-031.\n[212] More details about the LHCb approach using \u03c3Z * Br(Z \u2192 \u03bc+ \u03bc\u2212 ), are given in the talk by\nJ. Anderson at the HERA-LHC Workshop \"standard candles\"..\n\n\f[213] McNulty, R., Potential PDF sensitivity at LHCb. Preprint 0810.2550, 2008.\n[214] The web page of the PDF4LHC forum can be found at http://www.hep.ucl.ac.uk/pdf4lhc/.\n[215] Sherstnev, A. and Thorne, R. S., Different PDF approximations useful for LO Monte Carlo\ngenerators. Preprint 0807.2132, 2008.\n\n\f"}