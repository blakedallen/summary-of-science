{"id": "http://arxiv.org/abs/1108.4052v1", "guidislink": true, "updated": "2011-08-19T21:41:29Z", "updated_parsed": [2011, 8, 19, 21, 41, 29, 4, 231, 0], "published": "2011-08-19T21:41:29Z", "published_parsed": [2011, 8, 19, 21, 41, 29, 4, 231, 0], "title": "Query Expansion: Term Selection using the EWC Semantic Relatedness\n  Measure", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.4212%2C1108.3130%2C1108.0320%2C1108.0906%2C1108.5804%2C1108.3891%2C1108.2566%2C1108.5015%2C1108.4594%2C1108.3591%2C1108.5794%2C1108.5072%2C1108.4309%2C1108.3488%2C1108.6091%2C1108.5363%2C1108.1532%2C1108.4969%2C1108.4909%2C1108.1460%2C1108.1928%2C1108.4578%2C1108.1715%2C1108.3593%2C1108.2127%2C1108.1294%2C1108.0937%2C1108.3174%2C1108.2419%2C1108.5161%2C1108.5428%2C1108.4079%2C1108.3011%2C1108.5903%2C1108.0754%2C1108.0110%2C1108.0190%2C1108.4526%2C1108.4657%2C1108.3150%2C1108.2446%2C1108.6048%2C1108.6222%2C1108.4852%2C1108.3008%2C1108.2906%2C1108.3495%2C1108.2002%2C1108.2134%2C1108.4784%2C1108.5916%2C1108.1677%2C1108.1292%2C1108.0861%2C1108.2370%2C1108.1055%2C1108.5006%2C1108.6157%2C1108.3097%2C1108.5677%2C1108.0990%2C1108.5806%2C1108.0150%2C1108.2181%2C1108.2699%2C1108.1831%2C1108.2837%2C1108.0793%2C1108.5552%2C1108.1774%2C1108.3672%2C1108.1233%2C1108.2707%2C1108.2836%2C1108.2142%2C1108.5262%2C1108.0258%2C1108.0438%2C1108.1159%2C1108.4052%2C1108.4434%2C1108.0366%2C1108.1120%2C1108.5495%2C1108.3343%2C1108.0983%2C1108.1000%2C1108.0208%2C1108.5691%2C1108.2931%2C1108.3329%2C1108.5463%2C1108.0984%2C1108.1068%2C1108.0004%2C1108.1435%2C1108.0311%2C1108.5157%2C1108.4727%2C1108.1087%2C1108.5002&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Query Expansion: Term Selection using the EWC Semantic Relatedness\n  Measure"}, "summary": "This paper investigates the efficiency of the EWC semantic relatedness\nmeasure in an ad-hoc retrieval task. This measure combines the Wikipedia-based\nExplicit Semantic Analysis measure, the WordNet path measure and the mixed\ncollocation index. In the experiments, the open source search engine Terrier\nwas utilised as a tool to index and retrieve data. The proposed technique was\ntested on the NTCIR data collection. The experiments demonstrated promising\nresults.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.4212%2C1108.3130%2C1108.0320%2C1108.0906%2C1108.5804%2C1108.3891%2C1108.2566%2C1108.5015%2C1108.4594%2C1108.3591%2C1108.5794%2C1108.5072%2C1108.4309%2C1108.3488%2C1108.6091%2C1108.5363%2C1108.1532%2C1108.4969%2C1108.4909%2C1108.1460%2C1108.1928%2C1108.4578%2C1108.1715%2C1108.3593%2C1108.2127%2C1108.1294%2C1108.0937%2C1108.3174%2C1108.2419%2C1108.5161%2C1108.5428%2C1108.4079%2C1108.3011%2C1108.5903%2C1108.0754%2C1108.0110%2C1108.0190%2C1108.4526%2C1108.4657%2C1108.3150%2C1108.2446%2C1108.6048%2C1108.6222%2C1108.4852%2C1108.3008%2C1108.2906%2C1108.3495%2C1108.2002%2C1108.2134%2C1108.4784%2C1108.5916%2C1108.1677%2C1108.1292%2C1108.0861%2C1108.2370%2C1108.1055%2C1108.5006%2C1108.6157%2C1108.3097%2C1108.5677%2C1108.0990%2C1108.5806%2C1108.0150%2C1108.2181%2C1108.2699%2C1108.1831%2C1108.2837%2C1108.0793%2C1108.5552%2C1108.1774%2C1108.3672%2C1108.1233%2C1108.2707%2C1108.2836%2C1108.2142%2C1108.5262%2C1108.0258%2C1108.0438%2C1108.1159%2C1108.4052%2C1108.4434%2C1108.0366%2C1108.1120%2C1108.5495%2C1108.3343%2C1108.0983%2C1108.1000%2C1108.0208%2C1108.5691%2C1108.2931%2C1108.3329%2C1108.5463%2C1108.0984%2C1108.1068%2C1108.0004%2C1108.1435%2C1108.0311%2C1108.5157%2C1108.4727%2C1108.1087%2C1108.5002&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper investigates the efficiency of the EWC semantic relatedness\nmeasure in an ad-hoc retrieval task. This measure combines the Wikipedia-based\nExplicit Semantic Analysis measure, the WordNet path measure and the mixed\ncollocation index. In the experiments, the open source search engine Terrier\nwas utilised as a tool to index and retrieve data. The proposed technique was\ntested on the NTCIR data collection. The experiments demonstrated promising\nresults."}, "authors": ["Vitaly Klyuev", "Yannis Haralambous"], "author_detail": {"name": "Yannis Haralambous"}, "author": "Yannis Haralambous", "arxiv_comment": "5 pages, 1 figure, accepted at ASIR'11\n  <http://fedcsis.org/?q=node/62>", "links": [{"href": "http://arxiv.org/abs/1108.4052v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.4052v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.4052v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.4052v1", "journal_reference": "Proceedings of 1st International Workshop on Advances in Semantic\n  Information Retrieval (ASIR'11), Szczecin, Poland, September 18-21, 2011", "doi": null, "fulltext": "Query Expansion: Term Selection using the EWC Semantic Relatedness\nMeasure\nVitaly Klyuev\n\nYannis Haralambous\n\nUniversity of Aizu\nAizu-Wakamatsu\nFukushima-ken 965-8580, Japan\nEmail: vkluev@u-aizu.ac.jp\n\nInstitut T\u00e9l\u00e9com \u2013 T\u00e9l\u00e9com Bretagne\nD\u00e9p. Informatique, UMR CNRS 3192 Lab-STICC\nTechnop\u00f4le Brest Iroise, CS 83818\n29238 Brest Cedex 3, France\nEmail: yannis.haralambous@telecom-bretagne.eu\n\n\uf020\n\nAbstract-This paper investigates the efficiency of the EWC\nsemantic relatedness measure in an ad-hoc retrieval task. This\nmeasure combines the Wikipedia-based Explicit Semantic\nAnalysis measure, the WordNet path measure and the mixed\ncollocation index. In the experiments, the open source search\nengine Terrier was utilised as a tool to index and retrieve data.\nThe proposed technique was tested on the NTCIR data\ncollection. The experiments demonstrated promising results.\n\nA\n\nI. INTRODUCTION\n\nbag-of-words representation of documents by informa-\ntion retrieval systems results in queries expressed util-\nising the language of keywords. Users face a vocabulary\nproblem: A keyword language is not adequate to describe the\ninformation needs. Statistical analysis of user behaviors\nshowed that the queries submitted to search engines are short\n(2 to 3 terms, on average) and ambiguous, and users rarely\nlook beyond the first 10 to 20 links retrieved [20].\nTo improve user queries, search engines provide many\ntools.\nManuals and instructions are among them. They help a\nlittle, although ordinary users do not like reading.\nA query suggestion feature is common for general purpose\nsearch engines. Its disadvantage is in the way to generate re-\ncommended terms. They are based on the first term typed by\nthe user, which is is always the first one in all expanded\nqueries [22].\nThe relevance feedback feature is another instrument to\nhelp users. There are at least two steps in the interaction with\na search engine: The first one is the submission of the origin-\nal query, and the second one is the user reaction on the res-\nults retrieved in order to provide the system with the user\nopinion (marking some documents as relevant). This feature\nis not popular among users because the mechanisms of chan-\nging queries are not clear and users cannot control the pro-\ncess [9].\nIn addition, query suggestion and relevance feedback are\nused to modify the queries in order to make them more ac-\ncurate to express the user information needs.\nThis work was not supported by any organization\n\uf020\n\nQuery expansion is a well-known and popular technique\nto reformulate the user query in order to reduce the number\nof non-relevant pages retrieved by information retrieval sys-\ntems. Another goal of query expansion is to provide the user\nwith additional relevant documents. Automatic query expan-\nsion is an important area of information retrieval: Many sci-\nentists are involved in designing new methods, techniques,\nand approaches.\nThis paper presents authors' technique to automatically ex-\npand the user queries. This technique is based on the EWC\nsemantic relatedness measure [21]. This measure takes into\naccount encyclopedic, ontological, and collocational know-\nledge about terms. The environment for the experiments in-\ncludes Terrier as a search engine and NTCIR-1 CLIR data\ncollection for the Japanese-English cross-lingual retrieval\ntask.\nThe rest of the paper is organised as follows. The next\nsection reviews the approaches to automatic query expan-\nsion. Section 3 describe the nature of the measure used. Sec-\ntion 4 provides the necessary details related to this technique\nto expand the queries. The tools and data utilised in the ex-\nperiments are presented in Section 5. The results of the ex-\nperiments are discussed in Section 6 and comments on ongo-\ning experiments are presented in Section 7. Concluding re-\nmarks are presented in Section 8.\nII. RELATED WORK\nA comprehensive review of the classical approaches to ex-\npand queries can be found in [9]. They propose different\nways to obtain semantically (topically) related terms, tech-\nniques to evaluate importance of the terms found, mechan-\nisms to define the number of terms to add (expand) the user\nquery, and strategies to evaluate the quality of obtained res-\nults.\nGenerally, the semantics of the terms are clear when they\nare in the sentences because the meanings of the words are\nfixed and only one is usually selected from the set of all pos-\nsible variants. However, in the queries, the terms are separate\ninstances, and their semantics are unclear. This is called the\npolysemy problem. On the other hand, the same things can\n\n\fbe described by using different terms. This is the nature of\nthe synonymy problem. The query should be rich enough to\ninclude the possible candidates for expressing user informa-\ntion needs.\nThe general goal of query expansion is to find a solution\nfor these two aforementioned problems. The classical solu-\ntion for the synonymy problem is to apply thesauri as instru-\nments to obtain the candidates for expansion. WordNet is\nwidely used for this purpose [19]. Modern techniques sug-\ngest Wikipedia as a valuable source to find synonyms [12].\nMany techniques are used to solve the polysemy problem.\nApproaches described in [13] and [16] are based on the ana-\nlysis of the query log files of search engines and clicked\nURLs. Authors of this study [18] utilised WordNet for a\ndeep analysis of the queries submitted to the information re-\ntrieval system in order to find the concepts and then obtain\nthe candidate terms for expansion. The involvement of users\nis the feature of the approach discussed in [17]. They should\nselect the correct ontology for each query submitted to ex-\npand the query. The authors of this study [14] also pointed\nout that the information exploited by different approaches\ndiffers, and combining the different query expansion ap-\nproaches is more efficient than the use of any of them separ-\nately. They investigated techniques to rank the terms extrac-\nted from the retrieved documents. One is based on the meas-\nures of occurrence of the candidate and query terms in the\nretrieved documents. The other one utilises the differences\nbetween the probability distribution of terms in the collection\nand in the top ranked documents retrieved by the system. A\nsimilar idea is discussed in [15].\nThe authors of [10] combined the concept-based retrieval,\nbased on explicit semantic analysis (ESA), with keywordbased retrieval. At the first step, they use keyword-based re-\ntrieval to obtain the candidates for query expansion. Then,\nthey tune queries applying ESA. After that, they perform the\nfinal retrieval in the space of concepts.\nIt is difficult to compare the aforementioned approaches,\nbecause different data sets were used to evaluate them. In\nmany cases, it is not clear wherever the test queries cover a\nwide range of data set topics. The performance evaluation is\ndone automatically for some approaches, whereas for others,\nthe authors involve the users to judge the quality of retrieval.\nIII. MEASURE DESCRIPTION\nIn study [21], the new measure of words relatedness is in-\ntroduced. It combines the ESA measure \u03bc ESA [10], the\nontological WordNet path measure\n\n\u03bcWNP , and the col-\n\nlocation index C \u03be . This measure is called EWC (ESA\nplus WordNet, plus collocations) and is defined as follows:\n\n\u03bc EWC (w 1 , w 2 )=\u03bc ESA (w 1 ,w 2 )\u22c5\u03b1\n\u03b1=(1+\u03bb \u03c3 (\u03bcWNP ( w 1 , w 2)))\u22c5\u03b3\n\u03b3=(1+\u03bb '\u03c3 (C \u03be ( w 1 , w 2 )))\n\nwhere\n\n\u03bb \u03c3 weights the WordNet path measure (WNP)\n\nwith respect to ESA, and \u03bb '\u03c3 weights the mixed colloca-\ntion index with respect to ESA. This index is defined as fol-\nlows:\n\nC \u03be=\n\n2\u22c5f (w 1 w 2 )\n2\u22c5f ( w 2 w 1 )\n+\u03be\nf ( w 1 )+ f (w 2 )\nf (w 1 )+ f (w 2 )\n\nf (w 1, w 2 ) , f (w 2, w 1 ) are the frequency of\nthe collocations of w 1 w 2 and w 2 w 1 in the corpus,\nand f (w i ) is the frequency of word w i . The values\nfor constants \u03bb \u03c3 , \u03bb '\u03c3 , and \u03be were set to 5.16,\nwhere\n\n48.7, and 0.55, respectively.\nStudy [21] demonstrated the superiority of this measure\nover ESA on the WS-353 test set.\nIV. EXPANSION METHOD\n\nAssume that Z is a pool of term-candidates for query\nexpansion. The formulas below present the method to select\nterms to expand queries. N is a number of original query\nterms, and j is an index of them. Values for the Word-\nNet component and collocation component should be above\nzero in order to choose related terms. Thresholds t 2 for\n\nt 1 are parameters adjusted in the experi-\nments. For every word w i \u2208Z , the weight is calculated.\nWord w i is selected for expansion if its weight is equal\nEWC values and\n\nto 1.\n\n{\n\nN\n\nscore(w i , w j )\n>t 1,\nN\nj=0\n0, otherwise\n\nweight (w i )= 1, if\n\n\u2211\n\n{\n\nscore(w i , w j )= 1,if \u03bc WNP >0 ; C \u03be>0 ;\u03bc EWC >t 2,\n0,otherwise\nThis approach can be interpreted as follows: A term is se-\nlected from the list of term-candidates, if the similarity score\nbetween this term and the majority of original query terms is\nhigher than a given threshold t 1 . The term-candidate\nshould have non-zero values for\nponents.\n\n\u03bcWNP and C \u03be com-\n\nV. TOOLS AND DATA SETS USED\nThe open source search engine Terrier [1] was used as a\ntool to index and retrieve data. It provides the different re-\ntrieval approaches. TF-IDF and Okapi's B25 schemas [6, 9]\nare among them. As a data set for experiments, the NTCIR\nCLIR data collection [2] was used. It consists of 187,000 art-\n\n\ficles in English. These articles are summaries of papers\npresented at scientific conferences hosted by Japanese aca-\ndemic societies. The collection covers a variety of topics\nsuch as chemistry, electrical engineering, computer science,\nlinguistics, and library science. The size of the collection is\napproximately 275.5 MB. A total of 83 topics are in Japan-\nese. A structure of the dataset and topics is similar to that of\nTREC [3]. A Porter Stemmer algorithm was applied to the\ndocuments and queries, and a standard stop word list\nprovided by Terrier was also utilised. Only the title fields\nwere considered as a source of the queries. They are relat-\nively short, each query consists of a few keywords. The au-\nthors of the study reported in [5] experimented with Terrier\napplying the same conditions to the TREC data. To measure\nthe term similarities, an experimental tool described in [21]\nwas utilised.\nVI. RESULTS OF EXPERIMENTS\nThe authors implemented the proposed technique to ex-\npand queries as follows.\nA straightforward approach was applied to translate quer-\nies into English: Google's translation service [4] generated\nqueries in English. This method was selected because on-line\ndictionaries do not work well with terms in katakana and\nspecific terminology [7]. Katakana is one of four sets of\ncharacters used in Japanese writing. It is primarily applied\nfor the transcription of foreign language words into Japan-\nese.\nTo obtain the candidates for query expansion, a query ex-\npansion functionality offered by Terrier was adopted. It ex-\ntracts the most informative terms (in this case 10) of the topranked documents (in this case 3) by using a particular DFR\n(divergence from randomness) term weighting model [8].\nTable 1 provides the list of original queries (topics 1, 12,\nand 24), terms-candidates for expansion (arranged by the de-\ncreasing score calculated by Terrier), and the final sets of\nterms used to expand queries (they are in bold). One to five\nterms were selected by this method. As one can see from this\ntable, this technique does not usually select the top-ranked\nterms as candidates for expansion from the Terrier engine\npoint of view.\nAs mentioned in Section V, a total of 83 topics are avail-\nable to retrieve documents from the collection. The original\ngoal of topics 0001 to 0030 is to tune the parameters of the\nretrieval system. Their relevance judgments are known in ad-\nvance. Topics 0031 to 0083 were used in official runs at the\nNTCIR 1 Workshop. Organisers found that the number of\nrelevant documents for 13 topics of the 53 contained less\nthan five relevant documents per topic in cross-lingual re-\ntrieval. Hence, they discarded these topics from evaluation\n[25]. The full set was used in these experiments because the\ngoal is to compare the performance of different methods im-\nplemented in the same environment. In the evaluations, the\npartially relevant documents were considered as irrelevant.\n\nTo archive this, the corresponding file was applied when\nevaluating the retrieval results.\nTable 2 summarises the results of retrieval to tune\nthresholds t 1 and t 2 . The test queries were generated\nfrom topics 0001 to 0030. It is important to note that when\nthe queries are expanded with all the terms proposed by Ter-\nrier, the retrieval results drop to zero. The retrieval utilising\nthe TF-IDF schema produced better results for the original\nqueries (without expansion) compared to the BM25 and\nInL2 models [1]. The line system shows this result. The first\nnumber in the cells is the value of average precision, and the\nsecond one is the value of R-precision. The performance of\nretrieval with expanded queries utilising the ESA and EWC\napproaches for the threshold values ( t 1 equals 0.67 and\n\nt 2 is ranges from 0.08 to 0.15) is better compared to the\nvariant without expansion. For the EWC measure, the max-\nimum of the retrieval performance is reached when the val-\nues of thresholds t 1 and t 2 are set to 0.67 and\n0.12. For ESA, the optimal threshold values are 0.67 and\n0.08. The performance of ESA is higher than EWC.\nTable 3 summarises the results of retrieval for topics 31 to\n83. The threshold values were set to the optimal parameters\n(see Table 2). Six runs were executed. Figure 1 shows an av-\neraged precision/recall graph across 53 queries. The EWC\nmeasure demonstrated better performance over ESA in both\ncases. The line system shows the retrieval results without ex-\npansion for TF-IDF and BM25 schemes.\nTo summarize, one can conclude that the EWC measure\nprovides little benefit over ESA, as the results of the retrieval\nare better. Ontological knowledge combined with colloca-\ntional knowledge helps in the selection of expansion terms.\nVII. ONGOING EXPERIMENTS\nThe authors are conducting experiments on the translation\nof queries from Japanese into English. The Mecab system\n[24] is utilised to segment the queries and extract Japanese\nterms. An on-line dictionary Space ALC [23] was also ap-\nplied to retrieve all English variants for the corresponding\nJapanese terms. The EWC metrics are applied to pairs in or-\nder to select the most closely related elements from the sets\nof the meanings (terms with the highest sum of weights\nbetween pairs). For the queries consisting of only one term,\nthe most common English variant is selected. Queries gener-\nated in this way will be submitted to the search engine, and\ncomparison will be done with the results of retrieval for\nqueries obtained from Google's translation service.\nVIII. CONCLUSION\nThis study tested the semantic relatedness measure when\nselecting the terms to expand queries. Key components of\nthis measure are the ESA measure, the WordNet path meas-\nure, and the mixed collocation index. Results produced by\nthe Terrier search engine were a base line in the experiments.\n\n\fTABLE I.\nTOPICS: 1, 12 AND 24: ORIGINAL AND EXPANDED QUERIES\nTopic\n1\n\nOriginal query\nRobot\n\nTABLE II.\nTHRESHOLDS TUNING: TOPICS 1 TO 30\n\nTerms for expansion\n\nt1\n\nt2\n\nEWC: Average Precision\n\nRobot\nperson\nhuman\nmulti\n\nInL2\n0.5\n\n0.1\n\ncomput\nsice\n\n0.65\n\n0.09\n\ndesign\nwill\n\nESA/\nBM25\n\nR-Precision\n\n0.67\n\n0.07\n\nconfer\n\nTF-IDF\n\nBM25\n\n0.2940\n\n0.3031\n\n0.3072\n\n0.3101\n\n0.3216\n\n0.3314\n\n0.3324\n\n0.3347\n\n0.2940\n\n0.2936\n\n0.2955\n\n0.2961\n\n0.3300\n\n0.3332\n\n0.3278\n\n0.3276\n\n0.2973\n\n0.2954\n\n0.2960\n\n0.2959\n\n0.2977\n\n0.2963\n\n0.2916\n\n0.2916\n\n0.3101\n\n0.3151\n\n0.3140\n\n0.3172\n\n0.3277\n\n0.3268\n\n0.3265\n\n0.3315\n\n0.3073\n\n0.3105\n\n0.3106\n\n0.3080\n\n0.3256\n\n0.3373\n\n0.3352\n\n0.3373\n\n0.3030\n\npaper\n0.67\n12\n\nMining\n\nMine\n\nmethods\n\nmethod\nrule\n\n0.67\n\n0.08\n\n0.09\n\ndata\ndatabas\n\n0.67\n\n0.1\n\nassoci\ndiscoveri\nlarg\n\n0.67\n\n0.11\n\ntadashi\nsolv\n\n0.67\n\n0.12\n\namount\n24\n\nMachine\n\nMachin\n\ntranslation\n\ntranslat\n\nsystem\n\nsystem\nexampl\n\n0.67\n\n0.67\n\n0.13\n\n0.15\n\nbase\nmasahiro\n\n0.69\n\n0.09\n\nmethod\nnation\nconvert\n\n0.75\n\n0.1\n\n0.3103\n\n0.3099\n\n0.3099\n\n0.3295\n\n0.3350\n\n0.3349\n\n0.3318\n\n0.3049\n\n0.3121\n\n0.3110\n\n0.3102\n\n0.3239\n\n0.3309\n\n0.3292\n\n0.3302\n\n0.3049\n\n0.3121\n\n0.3110\n\n0.3092\n\n0.3239\n\n0.3309\n\n0.3292\n\n0.3284\n\n0.3049\n\n0.3114\n\n0.3099\n\n0.3111\n\n0.3125\n\n0.3245\n\n0.3248\n\n0.3282\n\n0.3033\n\n0.3115\n\n0.3111\n\n0.3110\n\n0.3143\n\n0.3267\n\n0.3282\n\n0.3282\n\n0.3073\n\n0.3105\n\n0.3106\n\n0.3080\n\n0.3256\n\n0.3373\n\n0.3352\n\n0.3373\n\n0.3030\n\n0.3103\n\n0.3099\n\n0.3099\n\n0.3295\n\n0.3330\n\n0.3349\n\n0.3318\n\n0.2980\n\n0.3034\n\n0.3017\n\n0.2995\n\n0.3166\n\n0.3163\n\nproblem\nSystem\n\nsystem\n\nTABLE III.\nRETRIEVAL RESULTS: TOPICS 31 TO 83\nt1\n\nt2\n\nEWC:\n\nESA:\n\nAverage Precision\n\nAverage Precision\n\nR-Precision\n\nR-Precision\n\nBM25\n0.67\n\n0.67\n\nSystem\nFig 1. Averaged 11-point precision-recall graph across topics 31 to 83\n\n0.08\n\nBM25\n\n0.2363\n\n0.2349\n\n0.2416\n\n0.2390\n\n0.12\n\nsystem\n\nTF-IDF\n\nTF-IDF\n\n0.2200\n\n0.2161\n\n0.2317\n\n0.2284\n\n0.2225\n\n0.2218\n\n0.2350\n\n0.2359\n\n\fTerm candidates for the expansion were also generated by\nTerrier. The proposed techniques were applied to the ad-hoc\nretrieval task. As a data set, the NTCIR-1 CLIR Test collec-\ntion was used. The initial English queries were obtained\nautomatically applying Google translate. The queries were\nexpanded by applying the Wikipedia-based Explicit Semant-\nic Analysis measure, and the DFR mechanism, and the se-\nmantic relatedness measure. The retrieval results showed su-\nperiority of the last one over ESA and DFR.\nREFERENCES\n[1]\n[2]\n[3]\n[4]\n[5]\n[6]\n[7]\n\n[8]\n\n[9]\n[10]\n[11]\n\n[12]\n\n[13]\n\n[14]\n\n[15]\n\n[16]\n\n[17]\n\nTerrier. [On line document], http://terrier.net\nNTCIR-1 CLIR data collection. [On line document],\nhttp://research.nii.ac.jp/ntcir/data/data-en.html\nTREC. [On line document], http://trec.nist.gov/\nGoogle Translate, http://translate.google.com/\nBen He and Iadh Ounis. \"Studying Query Expansion Effectiveness,\"\nin Proc. The 31st European Conference on Information Retrieval\n(ECIR09). Toulouse, France, 2009.\nS.E. Robertson, S. Walker, M.M. Beaulieu, M. Gatford, and A.\nPayne, \"Okapi at TREC-4,\" in Proc. TREC 4, 1995.\nAitao Chen, Fredric C. Gey, Kazuaki Kishida, Hailing Jiang and Qun\nLiang, \"Comparing Multiple Methods for Japanese and JapaneseEnglish Text Retrieval, NTCIR Workshop 1,\" in Proc. The First\nNTCIR Workshop on Research in Japanese Text Retrieval and Term\nRecognition, August 30 - September 1, 1999.\nG. Amati and C.J. Van Rijsbergen, \"Probabilistic models of\ninformation retrieval based on measuring the divergence from\nrandomness,\" ACM Transactions on Information Systems (TOIS),\n20(4):357\u2013389, 2002.\nChristopher D. Manning, Prabhakar Raghavan and Hinrich Sch\u00fctze,\nIntroduction to Information Retrieval, Cambridge University Press,\n2008.\nOfer Egozi, Shaul Markovitch, and Evgeniy Gabrilovich, \"ConceptBased Information Retrieval using Explicit Semantic Analysis,\" ACM\nTransactions on Information Systems, 29(2), 2011.\nPhilipp Sorg, Philipp Cimiano, \"An Experimental Comparison of\nExplicit Semantic Analysis Implementations for Cross-Language\nRetrieval,\" in Proc. The International Conference on Applications of\nNatural Language to Information Systems (NLDB), Saarbr\u00fccken,\nJune 2009.\nYinghao Li, Wing Pong Robert Luk, Kei Shiu Edward Ho, and Fu Lai\nKorris Chung, \"Improving weak ad-hoc queries using Wikipedia as\nexternal corpus,\" in Proc. The 30th annual international ACM SIGIR\nconference on Research and development in information retrieval,\nACM New York, NY, USA, 2007 , pp 797 - 798.\nHamada M.Zahera, Gamal F. El Hady, and Waiel.F Abd El-Wahed,\n\"Query Recommendation for Improving Search Engine Results,\" in\nProc. The World Congress on Engineering and Computer Science\n2010 Vol I, WCECS 2010, October 20-22, 2010, San Francisco,\nUSA.\nJose R. Perez-Aguera1 and Lourdes Araujo, \"Comparing and\nCombining Methods for Automatic Query Expansion,\" Advances in\nNatural Language Processing and Applications Research in\nComputing Science 33, 2008, pp. 177-188.\nMing-hung Hsu, Ming-feng Tsai, and Hsin-hsi Chen, \"Combining\nWordNet and ConceptNet for Automatic Query Expansion: A\nLearning Approach,\" in Proc. Asia Information Retrieval Symposium,\n2008, pp. 213-224.\nHang Cui1, Ji-Rong Wen, Jian-Yun Nie3, Wei-Ying Ma,\n\"Probabilistic query expansion using query logs,\" in Proc. The 11th\ninternational conference on World Wide Web, ACM New York, NY,\nUSA, 2002.\nJ. Malecka, and V. Rozinajova, \"An Approach to Semantic Query\nExpansion,\" in Proc. Tools for Acquisition, Organization and\nPresenting of Information and Knowledge, Research Project\nWorkshop, Bystra dolina, Tatry (2006), pp. 148-153.\n\n[18] Jiuling Zhang, Beixing Deng, and Xing Li, \"Concept Based Query\nExpansion Using WordNet,\" in Proc. the 2009 International eConference on Advanced Science and Technology, 2009, pp. 52-55.\n[19] M. Ellen Voorhees, \"Query expansion using lexical-semantic\nrelations,\" in Proc. The 17th Annual International ACM SIGIR\nconference on Research and Development in Information Retrieval,\n1994.\n[20] D. Gayo-Avello Brenes, \"Stratifies analysis of AOL query log,\"\nInformation Sciences, 179 (2009), pp. 1844-1858.\n[21] Yannis Haralambous and Vitaly Klyuev, \"A Semantic Relatedness\nMeasure Based on Combined Encyclopedic, Ontological and\nCollocational Knowledge,\" in the Proc. Of IJCNLP 2011,\nforthcoming publication.\n[22] Vitaly Klyuev, Ai Yokoyama, \"Web Query Expansion: A Strategy\nUtilizing Japanese WordNet,\" Journal of Convergence, V. 1, Number\n1, 2010.\n[23] Space ALC. [On line document], http://www.alc.co.jp/\n[24] Mecab. [On line document], http://mecab.sourceforge.net/\n[25] Noriko Kando, Kazuko Kuriyama, Toshihiko Nozue, Koji Eguchi,\nHiroyuki Kato and Soichiro Hidaka, \"Overview of IR tasks\", in Proc.\nThe First NTCIR Workshop on Research in Japanese Text Retrieval\nand Term Recognition, August 30 - September 1, 1999.\n\n\f"}