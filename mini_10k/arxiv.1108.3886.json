{"id": "http://arxiv.org/abs/1108.3886v1", "guidislink": true, "updated": "2011-08-19T03:51:41Z", "updated_parsed": [2011, 8, 19, 3, 51, 41, 4, 231, 0], "published": "2011-08-19T03:51:41Z", "published_parsed": [2011, 8, 19, 3, 51, 41, 4, 231, 0], "title": "On generic chaining and the smallest singular value of random matrices\n  with heavy tails", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.0020%2C1108.2877%2C1108.4247%2C1108.5724%2C1108.3545%2C1108.1561%2C1108.2043%2C1108.0789%2C1108.2898%2C1108.2349%2C1108.4642%2C1108.2692%2C1108.1143%2C1108.3177%2C1108.3685%2C1108.5408%2C1108.3818%2C1108.3976%2C1108.1123%2C1108.5149%2C1108.1082%2C1108.3873%2C1108.3937%2C1108.4592%2C1108.0475%2C1108.4571%2C1108.2025%2C1108.1487%2C1108.1165%2C1108.0053%2C1108.4693%2C1108.5682%2C1108.0978%2C1108.3037%2C1108.0865%2C1108.5464%2C1108.1641%2C1108.2485%2C1108.1939%2C1108.0545%2C1108.0973%2C1108.1205%2C1108.1913%2C1108.5867%2C1108.5079%2C1108.2954%2C1108.0299%2C1108.0533%2C1108.2016%2C1108.3034%2C1108.3786%2C1108.4334%2C1108.4617%2C1108.3750%2C1108.2855%2C1108.4348%2C1108.3967%2C1108.3530%2C1108.0837%2C1108.2306%2C1108.4461%2C1108.5633%2C1108.3187%2C1108.4972%2C1108.4836%2C1108.1727%2C1108.1455%2C1108.1580%2C1108.2637%2C1108.5714%2C1108.1741%2C1108.3853%2C1108.1851%2C1108.3348%2C1108.2292%2C1108.3886%2C1108.4963%2C1108.5212%2C1108.2006%2C1108.0182%2C1108.2706%2C1108.3098%2C1108.2477%2C1108.2364%2C1108.4208%2C1108.3604%2C1108.5604%2C1108.4071%2C1108.3908%2C1108.5869%2C1108.5181%2C1108.2457%2C1108.5621%2C1108.2860%2C1108.3950%2C1108.5685%2C1108.0032%2C1108.1886%2C1108.0746%2C1108.2960%2C1108.4691&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On generic chaining and the smallest singular value of random matrices\n  with heavy tails"}, "summary": "We present a very general chaining method which allows one to control the\nsupremum of the empirical process $\\sup_{h \\in H} |N^{-1}\\sum_{i=1}^N\nh^2(X_i)-\\E h^2|$ in rather general situations. We use this method to establish\ntwo main results. First, a quantitative (non asymptotic) version of the\nclassical Bai-Yin Theorem on the singular values of a random matrix with i.i.d\nentries that have heavy tails, and second, a sharp estimate on the quadratic\nempirical process when $H=\\{\\inr{t,\\cdot} : t \\in T\\}$, $T \\subset \\R^n$ and\n$\\mu$ is an isotropic, unconditional, log-concave measure.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.0020%2C1108.2877%2C1108.4247%2C1108.5724%2C1108.3545%2C1108.1561%2C1108.2043%2C1108.0789%2C1108.2898%2C1108.2349%2C1108.4642%2C1108.2692%2C1108.1143%2C1108.3177%2C1108.3685%2C1108.5408%2C1108.3818%2C1108.3976%2C1108.1123%2C1108.5149%2C1108.1082%2C1108.3873%2C1108.3937%2C1108.4592%2C1108.0475%2C1108.4571%2C1108.2025%2C1108.1487%2C1108.1165%2C1108.0053%2C1108.4693%2C1108.5682%2C1108.0978%2C1108.3037%2C1108.0865%2C1108.5464%2C1108.1641%2C1108.2485%2C1108.1939%2C1108.0545%2C1108.0973%2C1108.1205%2C1108.1913%2C1108.5867%2C1108.5079%2C1108.2954%2C1108.0299%2C1108.0533%2C1108.2016%2C1108.3034%2C1108.3786%2C1108.4334%2C1108.4617%2C1108.3750%2C1108.2855%2C1108.4348%2C1108.3967%2C1108.3530%2C1108.0837%2C1108.2306%2C1108.4461%2C1108.5633%2C1108.3187%2C1108.4972%2C1108.4836%2C1108.1727%2C1108.1455%2C1108.1580%2C1108.2637%2C1108.5714%2C1108.1741%2C1108.3853%2C1108.1851%2C1108.3348%2C1108.2292%2C1108.3886%2C1108.4963%2C1108.5212%2C1108.2006%2C1108.0182%2C1108.2706%2C1108.3098%2C1108.2477%2C1108.2364%2C1108.4208%2C1108.3604%2C1108.5604%2C1108.4071%2C1108.3908%2C1108.5869%2C1108.5181%2C1108.2457%2C1108.5621%2C1108.2860%2C1108.3950%2C1108.5685%2C1108.0032%2C1108.1886%2C1108.0746%2C1108.2960%2C1108.4691&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We present a very general chaining method which allows one to control the\nsupremum of the empirical process $\\sup_{h \\in H} |N^{-1}\\sum_{i=1}^N\nh^2(X_i)-\\E h^2|$ in rather general situations. We use this method to establish\ntwo main results. First, a quantitative (non asymptotic) version of the\nclassical Bai-Yin Theorem on the singular values of a random matrix with i.i.d\nentries that have heavy tails, and second, a sharp estimate on the quadratic\nempirical process when $H=\\{\\inr{t,\\cdot} : t \\in T\\}$, $T \\subset \\R^n$ and\n$\\mu$ is an isotropic, unconditional, log-concave measure."}, "authors": ["Shahar Mendelson", "Grigoris Paouris"], "author_detail": {"name": "Grigoris Paouris"}, "author": "Grigoris Paouris", "arxiv_comment": "42 pages", "links": [{"href": "http://arxiv.org/abs/1108.3886v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.3886v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.3886v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.3886v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:1108.3886v1 [math.PR] 19 Aug 2011\n\nOn generic chaining and the smallest singular value\nof random matrices with heavy tails\nShahar Mendelson\n\n1,3,4\n\nGrigoris Paouris2,5\n\nMay 24, 2018\n\nAbstract\nWe present a very general chaining method which allows\nPNone to control the supremum of the empirical process suph\u2208H |N \u22121 i=1 h2 (Xi )\u2212\nEh2 | in rather general situations. We use this method to establish two\nmain results. First, a quantitative (non asymptotic) version of the\nclassical Bai-Yin Theorem on the singular values of a random matrix\nwith i.i.d entries that have heavy tails, and second, a sharp estimate\non the quadratic empirical process when H = { t, * : t \u2208 T }, T \u2282 Rn\nand \u03bc is an isotropic, unconditional, log-concave measure.\n\n1\n\nIntroduction\n\nThe main goal of this article is to obtain a non-asymptotic version of the\nBai-Yin Theorem [5] on the largest and smallest singular values of certain\nrandom matrices. The Bai-Yin theorem asserts the following:\nTheorem 1.1 Let A = AN,n be an N \u00d7 n random matrix with independent\nentries, distributed according to a random variable \u03be, for which\nE\u03be = 0, E\u03be 2 = 1 E\u03be 4 < \u221e.\n1\n\nDepartment of Mathematics, Technion, I.I.T, Haifa 32000, Israel.\nDepartment of Mathematics, Texas A&M University, College Station, TX 77843-3368,\nU.S.A.\n3\nPart of this research was supported by the Centre for Mathematics and its Applications, The Australian National University, Canberra, ACT 0200, Australia. Additional\nsupport was given by an Australian Research Council Discovery grant DP0559465, the European Community's Seventh Framework Programme (FP7/2007-2013) under ERC grant\nagreement 203134, and by the Israel Science Foundation grant 900/10.\n4\nEmail: shahar@tx.technion.ac.il\n5\nEmail: grigoris@math.tamu.edu\n2\n\n1\n\n\fIf N, n \u2192 \u221e and the aspect ratio n/N converges to \u03b2 \u2208 (0, 1], then\np\np\n1\n1\n\u221a smin (A) \u2192 1 \u2212 \u03b2, \u221a smax (A) \u2192 1 + \u03b2,\nN\nN\n\nalmost surely, where smax and smin denote the largest and smallest singular\nvalue of A.\n\u221a\nAlso, without the fourth moment assumption, smax (A)/ N is almost\nsurely unbounded.\nThe main result of this article is a quantitative version of the Bai-Yin Theorem.\nQuantitative Bai-Yin Theorem. For every q > 4 and L > 0, there\nexist constants c1 , c2 , c3 and c4 that depend only on q and L for which\nthe following holds. For every integer n, \u03b2 \u2208 (0, 1] and N = n/\u03b2, let\nA = AN,n = (\u03bei,j ) be an N \u00d7 n random matrix with independent, symmetric\nentries, distributed according to a random variable \u03be, satisfying E\u03be 2 = 1 and\nE|\u03be|q \u2264 L. Then, for any n \u2265 c1 , with probability at least 1 \u2212 c2 /(\u03b2nc3 ),\np\np\n1\n1\n1 \u2212 c4 \u03b2 \u2264 \u221a smin (A) \u2264 \u221a smax (A) \u2264 1 + c4 \u03b2.\nN\nN\n\nThe proof of this result is based on the analysis of a more general scenario\nwhich has been studied extensively in recent years, in which the given matrix\nhas independent rows, selected according to a reasonable measure on Rn ,\nrather than a matrix with i.i.d. entries; and unlike the classical random matrix theory approach, one is naturally interested in the non-asymptotic\nbePN\n\u22121/2\nhavior of the largest and smallest singular values of \u0393 = N\ni=1 Xi , * ei\nas a function of N and n. We refer the reader to the surveys [34, 28] and references therein for the history and recent developments in the non-asymptotic\ntheory of random matrices.\nWe will focus on the following questions:\n\nQuestion 1.2 Let \u03bc be a symmetric measure on Rn and let (Xi )N\ni=1 be selected independently according to \u03bc.\nP\n1. Let \u03a3N = N1 N\ni=1 Xi \u2297 Xi be the sample covariance matrix and \u03a3 =\nE(X \u2297 X). Given \u03b5 > 0, is it true that with high probability, if N \u2265 c(\u03b5)n\nthen k\u03a3N \u2212 \u03a3k2\u21922 \u2264 \u03b5?\n2\n\n2. If X is an isotropic vector (that is, E X, x = kxk2ln for every x \u2208 Rn ),\n2\nare there \"canonical\" high probability bounds on smax (\u0393) and smin (\u0393)? For\nexample,punder what conditions on \u03bc are smax (\u0393) and smin (\u0393) of the order\nof 1 \u00b1 c n/N \u2013 like in the Bai-Yin Theorem?\n2\n\n\fObserve that the two questions are very similar. For example, it is\nstraightforward to verify that if \u03bc is isotropic, then both parts can be resolved by estimating the supremum of the empirical process\nsup\nt\u2208S n\u22121\n\nN\n1 X\nXi , t\nN\ni=1\n\n2\n\n\u2212 E X, t\n\n2\n\n.\n\n(1.1)\n\nAnd, in view of the second part of Question 1.2, we will be especially interested in the case N \u223c n, that is, while keeping the aspect ratio n/N\nconstant.\nWhen studying measures on Rn in this context, it is natural to divide\nthe assumptions into two types: one on the lnp norm of X and the other on\nmoments of linear functionals x, * .\nTo formulate the moment assumption we will use here, recall that for\n\u03b1 \u2265 1, the \u03c8\u03b1 Orlicz norm of random variable Z is defined by\nkZk\u03c8\u03b1 = inf {c > 0 : E exp(|Z|\u03b1 /c\u03b1 ) \u2264 2} ,\nand there are obvious extensions for 0 < \u03b1 < 1. It is standard to verify that\nfor every \u03b1 > 0, kZk\u03c8\u03b1 is equivalent to supq\u22651 kZkLq /q 1/\u03b1 .\nAssumption 1.3 For p, q \u2265 2, a symmetric measure \u03bc satisfies a p-small\ndiameter, Lq moment assumption with constants \u03ba1 and \u03ba2 , if a random\nvector X distributed according to \u03bc satisfies that\nkXklnp \u2264 \u03ba1 n1/p a.s., and for every x \u2208 S n\u22121 , k x, * kLq \u2264 \u03ba2 .\n\n(1.2)\n\n\u03bc satisfies a small diameter \u03c8\u03b1 moment assumption if the \u03c8\u03b1 norm replaces\nthe Lq one in (1.2).\nOne should note that with very few exceptions, both parts of Assumption\n1.3 are needed if one wishes to address Question 1.2.\nThe p-small diameter component, i.e. that kXklnp \u2264 \u03ba1 n1/p almost\nsurely, is rather standard. Although it does not hold as stated even for\na vector with i.i.d. gaussian entries, one may assume it without loss of\ngenerality unless N is much larger than n. Indeed, in typical situations\nP r(kXklnp \u2265 tn1/p ) decays very quickly both in t and in n. Therefore,\nmaxi\u2264N kXi klnp /n1/p is bounded with very high probability, unless N is considerably larger than n (see Section 2 for more details). Hence, if N \u223c n,\nwhich is the range we shall be interested in, a conditioning argument allows\none to make the p-small diameter assumption.\n3\n\n\fQuestion 1.2 has been studied under the 2-small diameter assumption.\n\u221a\nIn [27], Rudelson showed that if kXkln2 \u2264 \u03ba1 n almost surely then for every\nN \u2265 c1 n log n, with probability at least 0.99,\nr\nr\nn log n\nn log n\n\u2264 smin (\u0393) \u2264 smax (\u0393) \u2264 1 + c2\n,\n(1.3)\n1 \u2212 c2\nN\nN\nand c1 , c2 are constants that depend only on \u03ba1 .\nIt is straightforward to verify that this bound is optimal by consider\u221a\n\u221a\ning the uniform measure on the set of coordinate vectors { ne1 , ..., nen },\nwhich results in the coupon-collector problem. Thus, given \u03b5 > 0, one\nrequires at least c(\u03b5)n log n random points to ensure that the sample covariance matrix \u03b5-approximates the true covariance. Of course, [27] does not\nlead to a nontrivial estimate in the second part of Question 1.2, i.e. if the\naspect ratio n/N \u2192 \u03b2 \u2208 (0, 1] and n \u2192 \u221e, and in particular, (1.3) can not\nyield a Bai-Yin type of bound. Any hope of getting the desired bounds in\nQuestion (1.2) requires additional assumptions on X.\nTurning to the moments component of Assumption 1.3, note that a\nbound on the Lq moments of linear functionals means that k x, * kLq .\nkxkln2 , and if, in addition, X is isotropic, the norms are equivalent. Moreover, in a similar fashion, a \u03c8\u03b1 assumption combined with isotropicity implies that the \u03c8\u03b1 and ln2 norms are equivalent.\nConsider a situation when one only assumes such a moment condition.\nIt is standard to verify that under a \u03c82 assumption, in which linear functionals exhibit a \u03ba2 -subgaussian tail behavior (i.e., P r(| X, x | \u2265 t\u03ba2 kxkln2 ) \u2264\n2 exp(\u2212t2 /2)), then with probability at least 1 \u2212 2 exp(\u2212c3 n),\np\np\nsmin (\u0393), smax (\u0393) \u2208 [1 \u2212 c4 n/N , 1 + c4 n/N ]\n\nIndeed, a Bernstein type\nshows that for each x \u2208 S n\u22121 and\nPN inequality\n2\n2\n\u22121\n\u2212 E X, x | \u2265 t) \u2264 2 exp(\u2212c5 N t2 ).\n0 < t < 1/\u03ba2 , P r(|N\ni=1 Xi , x\nAnd, if one is to obtain an estimate on the empirical process (1.1), one has\nto control a 1/2 net on the sphere, which is of cardinality \u223c exp(c6 n). The\ntradeoff between the complexity of the indexing set and the concentration\nat\nPN\n2\n\u22121\nhand shows that with the desired probability, supt\u2208S n\u22121 |N\ni=1 Xi , t \u2212\np\n2\nE X, x | . n/N .\nUnfortunately, when one has a weaker moment estimate than a \u03c82 one,\nthe situation becomes considerably more difficult. The complexity of the\nset one has to control remains\nbut the individual concentration\nP the same,\n2\ndeteriorates, because N \u22121\nXi , x does not exhibit a strong enough concentration around its mean to balance the concentration-complexity tradeoff\n4\n\n\fp\nat the level of n/N . Therefore, with a weaker moment assumption than a\n\u03c82 one, a combination of individual tail bounds and a \"global\" assumption,\nlike the small diameter information, is required in both parts of Question\n1.2.\nOne situation in which the process (1.1) has been studied extensively in\nthe last 15 years is a small diameter, \u03c81 moment assumption. The motivation for considering this situation comes from Asymptotic Geometric Analysis and the theory of log-concave measures, which are measures that have\na symmetric, log-concave density. They fit the framework at hand nicely,\nbecause an isotropic, log concave vector X satisfies that kXklnp \u2264 c1 n1/p\nwith probability at least 1 \u2212 2 exp(\u2212c2 n1/p ). Indeed, the case p = 2 was\nproved in [24], while for p > 2 the result was recently established by Latala\nin [19]. Moreover, linear functionals exhibit a \u03c81 behavior (see, e.g. [12] for\na survey on log-concavity).\nPartial results in the isotropic, log-concave case have been obtain by\nBourgain [9], yielding an estimate on the covariance operator for N =\nc(\u03b5)n log 3 n, which was improved by Rudelson [27] to N = c(\u03b5)n log 2 n. Subsequent improvements were N = c(\u03b5)n log n for unconditional convex bodies\nin [13] and for general log-concave measures in [24]. Finally, the optimal estimate of N = c(\u03b5)n was obtained for an unconditional, log-concave measures\nby Aubrun [4], and for an arbitrary log-concave measure in Adamczak et al.\n[1, 2], where the following result was proved:\nTheorem 1.4 There exist absolute constants c1 and c2 for which the following holds. If \u03bc is an isotropic, log-concave measure, then with probability\n\u221a\nat least 1 \u2212 exp(\u2212c1 n),\nsup\nt\u2208S n\u22121\n\nN\n1 X\nXi , t\nN\ni=1\n\n2\n\n\u2212 1 \u2264 c2\n\nr\n\nn\n.\nN\n\nNaturally, Question 1.2 becomes even harder when one assumes that\nlinear functionals have heavy tails, because sums of independent random\nvariable exhibit very limited concentration \u2013 far below the level required\nfor the proof of Theorem 1.4. Recently, Vershynin [35] proved the following\nremarkable fact:\nTheorem 1.5 For every q > 4, \u03b4 > 0 and constants \u03ba1 and \u03ba2 , there exist\nconstants c1 and c2 that depend on q, \u03b4 and \u03ba1 , \u03ba2 for which the following\nholds.\n\n5\n\n\fIf \u03bc satisfies a 2-small diameter, Lq moment assumption with constants\n\u03ba1 and \u03ba2 , then for every \u03b4 > 0, with probability at least 1 \u2212 \u03b4,\n\u0010 n \u00111/2\u22122/q\nk\u03a3N \u2212 \u03a3k2\u21922 \u2264 c1 (log log n)2\n.\nN\n\nIn particular, if \u03bc is isotropic then\n\u0010 n \u00111/2\u22122/q\n\u0010 n \u00111/2\u22122/q\n1\u2212c2\n(log log n)2 \u2264 smin (\u0393) \u2264 smax (\u0393) \u2264 1+c2\n(log log n)2 .\nN\nN\n\nMoreover, very recently Strivastava and Vershynin [29], obtained the following result:\nTheorem 1.6 For every \u03b7 > 0, \u03b5 > 0 and \u03ba > 0 there exists constants\n\u03b7\nc1 , c2 and c3 = 2\u03b7+2\nfor which the following holds. Let \u03bc be an isotropic\nmeasure, satisfying that for every projection P in Rn ,\n(\u2217)\n\nP r{kP Xk22 > t} \u2264\n\n\u03ba\nt1+\u03b7\n\n, for t \u2265 \u03ba rank(P ).\n\nIf (Xi )N\ni=1 are independent random vectors distributed according to \u03bc then\nfor every N > c1 n,\nEk\u03a3N \u2212 Id k 6 \u03b5.\nMoreover, only under a q-moment assumption,\n\u0010 n \u0011c3\n1 \u2212 c2\n\u2264 Esmin (\u0393)\nN\n\nIt should be noted that the boundedness assumption in Theorem 1.6 is\nsatisfied by a vector with independent components X = (\u03bei )ni=1 , if \u03be \u2208 Lq\nfor q > 4, and thus both parts may be used in the i.i.d situation. However,\nfor any \u03b7 > 0, c3 < 12 (1/2 being the power in the Bai-Yin Theorem).\nOur main result gives a version of Theorem 1.5 for an unconditional\nmeasure with \"heavy tails\".\nTheorem A. Let \u03bc be an unconditional measure that satisfies the p-small\ndiameter, Lq moment assumption with constants \u03ba1 and \u03ba2 for some p > 2.\n1. For every q > 4 and \u03b4 < 1/2 \u2212 1/2(p \u2212 1), there exist constants c0 ,\nc1 and c2 that depend on q, p, \u03ba1 , \u03ba2 and \u03b4, such that, for every\nn \u2264 N \u2264 exp(c0 n\u03b4 ), with probability at least 1 \u2212 exp(\u2212c1 n\u03b4 ),\nsup |N \u22121\n\nt\u2208B2n\n\nN\nX\n\nXi , t\n\n2\n\ni=1\n\n6\n\n2\n\n\u2212 E X, t | \u2264 c2\n\n\u0010 n \u00111/2\nN\n\n.\n\n\f2. For every 2 < q \u2264 4, if p > (1 \u2212 2/q)\u22121 and \u03b4 < 1/2 \u2212 1/2(p \u2212 1), there\nexist constants c3 and c4 that depend on q, p, \u03b4, \u03ba1 and \u03ba2 , such that,\nfor every n \u2264 N \u2264 exp(c0 n\u03b4 ), with probability at least 1\u2212 exp(\u2212c3 n\u03b4 ),\nsup |N \u22121\n\nt\u2208B2n\n\nN\nX\ni=1\n\nXi , t\n\n2\n\n2\n\n\u2212 E X, t | \u2264 c4\n\n\u0010 n \u00111\u22122/q\nN\n\nlog(N/n).\n\nIn both cases, for every \u03b5 > 0, with probability at least 1 \u2212 2 exp(\u2212cn\u03b4 ),\nk\u03a3N \u2212 \u03a3k2\u21922 \u2264 \u03b5 provided that N &q,p,\u03b4,\u03ba1,\u03ba2 n. Moreover, if \u03bc is isotropic\nand q > 4, then\n1 \u2212 c2\n\n\u0010 n \u00111/2\nN\n\n\u2264 smin (\u0393) \u2264 smax (\u0393) \u2264 1 + c2\n\nand if 2 < q \u2264 4 then\n1\u2212c4\n\n\u0010 n \u00111\u22122/q\nN\n\nlog(N/n) \u2264 smin (\u0393) \u2264 smax (\u0393) \u2264 1+c4\n\n\u0010 n \u00111/2\nN\n\n,\n\n\u0010 n \u00111\u22122/q\nN\n\nlog(N/n).\n\nOur quantitative version of the Bai-Yin Theorem follows from Theorem\nA, because of the straightforward observation that if \u03be \u2208 Lq for q > 4\nand is symmetric, then X = (\u03bei )ni=1 is unconditional, and there is some\np > 2 for which maxi\u2264N kXklnp . n1/p with high enough probability. Thus,\nconditioning \u03bc to the unconditional body cn1/p Bpn yield the desired result.\nThe approach we take in the proof of Theorem A is very different from\nall the previous results mentioned above, as those rely heavily on the fact\nthat the empirical process (1.1) is indexed by the sphere or by the Euclidean\nball, and that the underlying class of functions consists of linear functionals. At the heart of the arguments are either the classical trace method\n[4], a non-commutative\nKhintchine inequality [27] or sharp estimates on\nP\nmax|I|=k k i\u2208I Xi kln2 [9, 1, 35]. As such, all these proofs are \"Euclidean\"\nin nature and can not lead to bounds on the empirical process\nN\n1 X 2\nh (Xi ) \u2212 Eh2\nsup\nh\u2208H N\n\n(1.4)\n\ni=1\n\nfor an arbitrary class of functions H \u2013 not even for HT = { t, * : t \u2208 T }\nwhen T is not the sphere or close to the sphere in some sense.\nOne should note that process (1.4) is an interesting object in its own\nright. For example, it has a key role in analyzing the uniform central limit\n7\n\n\fTheorem [10]; and, when indexed by HT for T \u2282 Rn , it appear naturally\nin Asymptotic Geometric Analysis, for example, when proving embedding\nresults or \"low-M \u2217 \" estimates for various matrix ensembles (see [22] for a\nmore detailed discussion). Thus, understanding what governs (1.4), and in\nparticular, going beyond the case HB2n is rather important.\nThe proof of Theorem A does just that, since it is based on a bound\non (1.4) in terms of a certain notion of \"complexity\" of the class H. It is\nnot tailored to the case HB2n , nor does it relay on the fact that the indexing\nclass consists of linear functionals. Rather, the proof is based on a chaining scheme which is much more general than the applications that will be\npresented here.\nThe second application we chose to present as an illustration of the\npotential this empirical processes based method has, is the following.\nLet y1 , ...yn be independent,\nstandard exponential random variables (i.e.,\n\u221a\nwith density \u223c exp(\u2212 2|t|), and for every T \u2282 Rn set\nE(T ) = E sup\n\nn\nX\n\nt\u2208T i=1\n\nti y i ,\n\nd2 (T ) = sup ktkln2 .\nt\u2208T\n\nTheorem B. There exists absolute constants c1 , c2 and c3 for which the\nfollowing holds. If \u03bc is an isotropic, unconditional, log-concave measure\non Rn and T \u2282 Rn is centrally symmetric, then for every u \u2265 c1 , with\nprobability at least 1 \u2212 2 exp(\u2212c2 u2 ),\n\u0012\n\u0013\nN\n(E(T ))2\n1 X\n2\n3 E(T )\n2\n\u221a\nt, Xi \u2212 ktkln2 \u2264 c3 u\n.\n(1.5)\n+\nsup\nN\nN\nt\u2208T N i=1\nTo put Theorem B in the right context, recall that a symmetric measure\n\u03bd on Rn (\u03ba, L)-weakly dominates a symmetric measure \u03bc if for every x \u2208 Rn ,\nand every t > 0, P r\u03bc (| x, * | \u2265 Lt) \u2264 \u03baP r\u03bd (| x, * | \u2265 t) [16]. For example,\nif \u03bc is an isotropic L-subgaussian measure and G = (g1 , ..., gn ) is a standard\ngaussian vector in Rn then\nP r\u03bc (| x, * | \u2265 Lt) \u2264 2 exp(\u2212t2 /2kxk2ln2 ) = P rG (| x, * | \u2265 t),\nand thus \u03bc is weakly dominated by G.\nBy the Majorizing Measures Theorem (see, e.g., [32] and Section 2), it\nfollows that if \u03bc is L-subgaussian, there is a constant c = c(L) satisfying\nthat for every T \u2282 Rn and every integer N ,\nE sup\nt\u2208T\n\nN\nX\ni=1\n\nXi , t \u2264 cE sup\nt\u2208T\n\n8\n\nN\nX\ni=1\n\n\u221a\nGi , t \u2261 c N G(T )\n\n(1.6)\n\n\fN\nwhere (Xi )N\ni=1 are independent copies of X, (Gi )i=1 are independent copies\nof G and G(T ) = E supt\u2208T G, t .\nMoreover, the results of [21, 22] show that if T is centrally symmetric\nand \u03bc is isotropic and L-subgaussian, then\n\nE sup\nt\u2208T\n\nN\n1 X\nt, Xi\nN\ni=1\n\n2\n\nG(T ) (G(T ))2\n\u2212 ktk2ln2 .L \u221a\n.\n+\nN\nN\n\n(1.7)\n\nHence, the fact that an L-subgaussian measure is weakly dominated by a\ngaussian measure (with the same covariance structure) is exhibited by a\nstrong domination in (1.6) and in (1.7), that holds for every T \u2282 Rn .\nJust like subgaussian vectors, isotropic, unconditional log-concave vectors have a natural weakly dominating measure. By the Bobkov-Nazarov\nTheorem [7] they are (\u03ba, L)-weakly dominated by the vector Y = (y1 , ..., yn ),\nand \u03ba and L are absolute constants.\nIn [18], Latala showed\nPN\nPN that as in (1.6),\nn\nfor every T \u2282 R , E supt\u2208T\ni=1 Xi , t . E supt\u2208T\ni=1 Yi , t . Theorem\nB shows that the quadratic strong domination, analogous to (1.7), is also\ntrue in this case.\nTheorem B has many standard applications, leading to embedding results of a similar nature to the Johnson-Lindenstrauss Lemma and to \"low\nM \u2217 \" estimates that hold for unconditional, log-concave ensembles. Deriving\nthese and other outcomes from Theorem B is standard and will not be presented here. One should also note that a log-concave Chevet type inequality,\ni.e., upper estimates on the operator norm k\u0393kX\u2192Y for finite dimensional\nnormed spaces X and Y has recently been established in [3].\nIn the next section we will present several preliminary facts and definitions that will be used throughout this article. Then, in Section 3 we will\nshow that if V \u2282 RN can be decomposed in a certain way, the Bernoulli\nprocess indexed by {(vi2 )N\ni=1 : v \u2208 V } is well behaved. Section 4 is devoted to the observation that if H is a class of functions, then under mild\nassumptions and with high probability, the random coordinate projection\nP\u03c3 H = {(h(Xi ))N\ni=1 : h \u2208 H} can be decomposed in the sense of Section 3.\nIt turns out that the decomposition depends on the complexity of H and\non the decay of tails of functions in H. Finally, in Section 5 we will present\nexamples in which the complexity of H can be estimated, leading to the\nproofs of Theorem A (and consequently, the quantitative Bai-Yin Theorem)\nand of Theorem B.\n\n9\n\n\f2\n\nPreliminaries\n\nThroughout, all absolute constants are positive numbers, denoted by c, c0 , c1 , ...\nand their value may change from line to line. \u03ba0 , \u03ba1 , ... denote constants\nwhose value will remain unchanged. By A \u223c B we mean that there are\nabsolute constants c and C such that cB \u2264 A \u2264 CB, and by A . B that\nA \u2264 CB. A \u223c\u03b3 B (resp. A .\u03b3 B) denotes that the constants depend only\non \u03b3.\nFor 1 \u2264 p \u2264 \u221e, lnp is Rn endowed with the lp norm, which we denote by\nk klnp , and Bpn is its unit ball. With a minor abuse of notation we write | |\nboth for the cardinality of a set and for the absolute value. Finally, if (an )\nis a sequence, let (a\u2217n ) be a non-increasing rearrangement of (|an |).\nNext, let us turn to the complexity parameters that motivated our\nmethod of analysis \u2013 Talagrand's \u03b3-functionals.\nDefinition 2.1 [32] For a metric space (T, d), an admissible sequence of\nT is a collection of subsets of T , {Ts : s \u2265 0}, such that for every s \u2265 1,\ns\n|Ts | \u2264 22 and |T0 | = 1. For \u03b2 \u2265 1, define the \u03b3\u03b2 functional by\n\u03b3\u03b2 (T, d) = inf sup\n\n\u221e\nX\n\nt\u2208T s=0\n\n2s/\u03b2 d(t, Ts ),\n\nwhere the infimum is taken with respect to all admissible sequences of T .\nFor an admissible sequence (Ts )s\u22650 we denote by \u03c0s t a nearest point to t in\nTs with respect to the metric d.\nOne should note that our chaining approach is based on a slightly less restrictive definition, giving one more freedom; for example, the cardinality of\ns\nthe sets will not necessarily be 22 , the metric may change with s, etc. (see\nSection 3).\nWhen considered for a set T \u2282 L2 , \u03b32 has close connections with properties of the canonical gaussian process indexed by T , and we refer the reader\nto [10, 32] for detailed expositions on these connections. One can show that\nunder mild measurability assumptions, if {Gt : t \u2208 T } is a centered gaussian\nprocess indexed by a set T , then\nc1 \u03b32 (T, d) \u2264 E sup Gt \u2264 c2 \u03b32 (T, d),\nt\u2208T\n\nwhere c1 and c2 are absolute constants and for every s, t \u2208 T , d2 (s, t) =\nE|Gs \u2212Gt |2 . The upper bound is due to Fernique [11] and the lower bound is\nTalagrand's Majorizing Measures Theorem [30]. Note that if T \u2282 Rn , (gi )ni=1\n10\n\n\fare standard, independent gaussians and Gt =\ntkln2 , and therefore\nc1 \u03b32 (T, k * kln2 ) \u2264 E sup\n\nn\nX\n\nt\u2208T i=1\n\nPn\n\ni=1 gi ti\n\nthen d(s, t) = ks \u2212\n\ngi ti \u2264 c2 \u03b32 (T, k * kln2 ).\n\n(2.1)\n\nA part of our discussion (Theorem B) will be devoted to isotropic, logconcave measures on Rn .\nDefinition 2.2\nA symmetric probability measure \u03bc on Rn is isotropic if for\nR\nevery y \u2208 Rn , | x, y |2 d\u03bc(x) = kyk2ln .\n2\nThe measure \u03bc is log-concave if for every 0 < \u03bb < 1 and every nonempty\nBorel measurable sets A, B \u2282 Rn , \u03bc(\u03bbA + (1 \u2212 \u03bb)B) \u2265 \u03bc(A)\u03bb \u03bc(B)1\u2212\u03bb .\nA typical example of a log-concave measure on Rn is the volume measure of a\nconvex body in Rn , a fact that follows from the Brunn-Minkowski inequality\n(see, e.g. [26]). Moreover, Borell's inequality [8, 23] implies that there is an\nabsolute constant c such that if \u03bc is an isotropic, log-concave measure on\nRn , then for every x \u2208 Rn , k x, * k\u03c81 \u2264 ck x, * kL2 = ckxkln2 .\nAs mentioned in the introduction, if X is distributed according to an\nisotropic, log-concave measure on Rn then kXklnp decays quickly at scales\nthat are larger than n1/p . Thus, by conditioning, the main result in [24]\nshows that a 2-small diameter assumption can be made without loss of\n\u221a\ngenerality as long as N \u2264 exp(c n), and Latala [19] proved the analogous\nresult for p > 2, as long as N \u2264 exp(cn1/p ).\n\n3\n\nDecomposition of sets\n\nWe begin with a description of the modified chaining procedure. Let (\u03b7s )s\u22650\nbe an increasing sequence which satisfies that for every s \u2265 0, 2\u03b7s * 2\u03b7s+1 \u2264\n10 * 2\u03b7s+2 and for s \u2265 1, 1.1 \u2264 \u03b7s+1 /\u03b7s \u2264 10 (where 1.1 can be replaced by\n1 + \u03b5 and 10 can be any suitably large constant). For example, \u03b70 = 0 and\n\u03b7s = 2s for s \u2265 1 is the usual choice of a sequence that has been used in the\ndefinition of Talagrand's \u03b3 functionals. An admissible sequence of V \u2282 RN\nrelative to (\u03b7s )s\u22650 is a collection of subsets Vs \u2282 V for which |Vs | \u2264 2\u03b7s . For\nevery s let \u03c0s : V \u2192 Vs , which usually will be a nearest point map relative\nto some distance. We will denote \u03c0s v \u2212 \u03c0s\u22121 v by \u2206s v, and sometimes write\n\u22060 v for \u03c00 v. Finally, \u2206s V is the set {\u2206s v : v \u2208 V }.\nLet \u03c6 be an increasing function which will be chosen according to additional information one will have on the given class. Examples that one\n11\n\n\f\u221a\nshould have in mind are \u03c6\u03b2 (x) \u223c\u03b2 x log1/\u03b2 (eN/x), resulting from a bound\non the \u03c8\u03b2 diameter of H, or \u03c6q,\u03b5 \u223cq,\u03b5 N (1+\u03b5)/q x1/2\u2212(1+\u03b5)/q for q > 2 and \u03b5\nin the right range, arising from an Lq moment assumption.\nAssume that V \u2282 RN is endowed with a family of functionals \u03b8s and\na semi-norm k k (which, in our applications, will either arise from the Lq\nnorm or from the \u03c8\u03b2 norm), and set d = supv\u2208V kvk.\nDefinition 3.1 V \u2282 RN admits a decomposition with constants \u03b1 and \u03b3\nif it has an admissible sequence (Vs )s\u22650 relative to (\u03b7s )s\u22650 for which the\nfollowing holds.\n\u0001\nP\n1. supv\u2208V \u03b80 (\u03c00 v) + s>0 \u03b8s (\u2206s v) \u2264 \u03b3.\n2. For every v \u2208 V and every I \u2282 {1, ..., N },\nX\n\nvi2\n\ni\u2208I\n\n!1/2\n\n\u2264 \u03b1 (\u03b3 + d\u03c6(|I|)) .\n\n3. If \u03b7s \u2264 N then for every v \u2208 V and every I \u2282 {1, ..., N }\nX\n(\u2206s v)2i\ni\u2208I\n\n!1/2\n\n\u2264 \u03b1 (\u03b8s (\u2206s v) + k\u2206s vk\u03c6(|I|)) ,\n\nand if \u03b7s \u2265 N then for every v \u2208 V and every I \u2282 {1, ..., N },\nX\n\n(\u2206s v)2i\n\ni\u2208I\n\n!1/2\n\n\u2264 \u03b1\u03b8s (\u2206s v).\n\nAlthough this definition seems artificial at first glance, we will show\nthat it captures the geometry of a typical coordinate projection P\u03c3 H =\n{(h(Xi ))N\ni=1 : h \u2208 H}.\nThe main observation of this section is that one can use this type of\ndecomposition to bound the supremum of the Bernoulli process indexed by\nV 2 = {(vi2 )N\nsymmetrizai=1 : v \u2208 V }. Hence, if V = P\u03c3 H, then a standard\nPN\n\u22121\n2\ntion argument leads to the desired bound on suph\u2208H |N\ni=1 h (Xi ) \u2212\n2\nEh | (see section 5.3).\nTo formulate the estimate on the Bernoulli process, set\n\u03a6=\n\nN\nX\n\u03c64 (i)\ni=1\n\ni2\n\n!1/2\n\n,\n\n\u03a6s =\n\nNX\n\u2212\u03b7s\ni=1\n\n12\n\n\u03c62 (\u03b7s + i) \u03c62 (i)\n*\n\u03b7s + i\ni\n\n!1/2\n\n\ffor \u03b7s \u2264 N , put\nX\n\nA1 = sup\nv\u2208V\n\n\u03c6(\u03b7s )k\u2206s vk, A2 = sup\nv\u2208V\n\n{s>0:\u03b7s \u2264N }\n\nand let\nA\u03a6 = sup\nv\u2208V\n\nX\n\n{s:\u03b7s \u2264N }\n\nX\n\n\u03c62 (\u03b7s )k\u2206s vk,\n\n{s>0:\u03b7s \u2264N }\n\n\u03a6s \u03b7s1/2 k\u2206s vk.\n\nFor 2 < q \u2264 4 and 0 \u2264 \u03b5 < (q/2) \u2212 1, let\nX\n\u03b7s1\u22122(1+\u03b5)/q k\u2206s vk.\nBq,\u03b5 = sup\nv\u2208V\n\n{s:\u03b7s \u2264N }\n\nAs will become clearer, the most important of the Bq,\u03b5 parameters is\nX\n\u03b7s1/2 k\u2206s vk,\nB4 \u2261 B4,0 = sup\nv\u2208V\n\n{s:\u03b7s \u2264N }\n\nwhich, under the standard choice of \u03b70 = 0 and \u03b7s = 2s for s \u2265 1, corresponds to \u03b32 (V, k k).\nTheorem 3.2 There exist absolute constants c0 , c1 and c2 for which the\nfollowing holds. If V \u2282 RN has a decomposition as in Definition 3.1, then\nfor every r \u2265 c0 , with probability at least 1 \u2212 2 exp(\u2212c1 r 2 \u03b70 ),\nsup\nv\u2208V\n\nN\nX\ni=1\n\n\u03b5i vi2 \u2264 c2 r\u03b12 (\u03b3(\u03b3 + d\u03c6(N ) + A1 ) + d (A2 + A\u03a6 ))\n\nBefore presenting the proof, let us consider the two main examples which\n\u221a\nwill interest us, namely, the families \u03c6\u03b2 = x log1/\u03b2 (eN/x) for any \u03b2 > 0\n\u221a\nand \u03c6q,\u03b5 = x(N/x)(1+\u03b5)/q\u221afor any q > 2 (and for \u03b5 selected\n\u221a appropriately).\nIn both cases \u03c6(N ) \u223c N and for any\u221a\u03b2 > 0, \u03a6 \u223c\u03b2 N . If q > 4 and\n0 \u2264 \u03b5 \u2264 q/4 \u2212 1, \u03a6 \u2264 (1 \u2212 4(1 + \u03b5)/q)\u22121/2 N , and since \u03a6s \u2264 \u03a6, then for\n\u03b2 > 0 or q > 4,\nX\n\u221a\n\u03b7s1/2 k\u2206s vk . N B4 ,\nA\u03a6 \u2264 \u03a6 sup\nv\u2208V\n\n{s:\u03b7s \u2264N }\n\nwith the constant depending either on \u03b2 or on q and \u03b5 as above.\n\n13\n\n\fOn the other hand, if 2 < q \u2264 4 and 0 < \u03b5 < q/2 \u2212 1 then\n\u03a6s =\n\nNX\n\u2212\u03b7s\ni=1\n\n\u03c62 (\u03b7s + i) \u03c62 (i)\n*\n\u03b7s + i\ni\n\n!1/2\n\n=\n\nNX\n\u2212\u03b7s \u0012\ni=1\n\nN 2(1+\u03b5)/q\n.\n* \u03b7 1/2\u22122(1+\u03b5)/q .\n1 \u2212 2(1 + \u03b5)/q s\n\nN\n\u03b7s + i\n\n\u00132(1+\u03b5)/q \u0012 \u00132(1+\u03b5)/q !1/2\nN\n*\ni\n\nTherefore, in that range\nA\u03a6 .\n\nN 2(1+\u03b5)/q\n* sup\n1 \u2212 2(1 + \u03b5)/q v\u2208V\n\nX\n\n{s:\u03b7s \u2264N }\n\n\u03b7s1\u22122(1+\u03b5)/q k\u2206s vk =\n\nN 2(1+\u03b5)/q\nBq,\u03b5 .\n1 \u2212 2(1 + \u03b5)/q\n\nNext, since (\u03b7s )s\u22650 increases exponentially, then for q > 2\nX\nX\n\u221a\n\u03c6(\u03b7s )k\u2206s vk \u2264 2d\n\u03c6(\u03b7s ) . d N ,\n{s:\u03b7s \u2264N }\n\n(3.1)\n\n{s:\u03b7s \u2264N }\n\nand the constant in (3.1) depends on \u03b2 or on q and \u03b5 respectively. In\nparticular, if 2 < q \u2264 4 and 0 < \u03b5 < q/2 \u2212 1, then\n\u221a\nX\nN\n\u03c6(\u03b7s ) .\n1 \u2212 2(1 + \u03b5)/q\n{s:\u03b7s \u2264N }\n\nFinally, one has to control\nor q > 4, then\nX\n\n{s:\u03b7s \u2264N }\n\nP\n\n\u03c62 (\u03b7s )k\u2206s vk \u2264\n\n2\n{s:\u03b7s \u2264N } \u03c6 (\u03b7s )k\u2206s vk.\n\nmax\n\n\u03c62 (\u03b7s )\n\n{s:\u03b7s \u2264N }\n\n\u221a\n\n. N\n\nX\n\n1/2\n\u03b7s\n\n{s:\u03b7s \u2264N }\n\n!\n\n*\n\nNote that if \u03b2 > 0\n\nX\n\n{s:\u03b7s \u2264N }\n\n\u03b7s1/2 k\u2206s vk\n\n\u223c\n\n\u03b7s1/2 k\u2206s vk\n\n\u221a\nN B4 ,\n\nand if 2 < q \u2264 4 and 0 < \u03b5 < q/2 \u2212 1 then\nX\nX\n\u03b7s1\u22122(1+\u03b5)/q k\u2206s vk = N 2(1+\u03b5)/q Bq,\u03b5 .\n\u03c62 (\u03b7s )k\u2206s vk \u2264 N 2(1+\u03b5)/q\n\n{s:\u03b7s \u2264N }\n\n{s:\u03b7s \u2264N }\n\nWe thus arrive to a more compact formulation of Theorem 3.2 in the cases\nwe will be interested in.\n\n14\n\n\fCorollary 3.3 For any \u03b2 > 0 or q > 4, with probability at least 1 \u2212\n2 exp(\u2212c1 r 2 \u03b70 ),\nsup\nv\u2208V\n\nN\nX\ni=1\n\n\u0010\n\u0011\n\u221a\n\u03b5i vi2 . r\u03b12 \u03b3 2 + d N (\u03b3 + B4 ) ,\n\nwith a constant that depends on \u03b2 or on q and \u03b5 respectively.\nAlso, if 2 < q \u2264 4 and 0 < \u03b5 < q/2 \u2212 1, then with probability at least\n1 \u2212 2 exp(\u2212c1 r 2 \u03b70 ),\nsup\nv\u2208V\n\nN\nX\n\n\u03b5i vi2 .\n\ni=1\n\n\u0010\n\u0011\n\u221a\n\u03b12 r\n\u03b3 2 + d N \u03b3 + dN 2(1+\u03b5)/q Bq,\u03b5 .\n1 \u2212 2(1 + \u03b5)/q\n\nProof of Theorem 3.2. For every \u2206s v let i be the largest integer in\n{1, ..., N } for which \u03b8s (\u2206s v) \u2265 k\u2206s vk\u03c6(i). Throughout the proof we will\nassume that such an integer exists, and if it does not, the necessary modifications to the proof are obvious. Let is,v = max{i, \u03b7s } and put Is,v to be\nthe set of the largest is,v coordinates of |\u2206s v|. Let \u2206+\ns v = PIs,v \u2206s v and\nc \u2206s v be the projections of \u2206s v onto the set of coordinates Is,v\n\u2206\u2212\nv\n=\nP\nI\ns\ns,v\nc respectively. Also, let j be the largest integer in {1, ..., N } for which\nand Is,v\n\u00111/2\n\u0010P\nj\n2 \u2217\n\u03b3 \u2265 d\u03c6(j). Thus, for every v \u2208 V ,\n\u2264 2\u03b1\u03b3 and for every\ni=1 (vi )\n\u221a\n\u2217\nl \u2265 j, vl \u2264 2\u03b1d\u03c6(l)/ l. If J is the set of the largest j coordinates of v \u2208 V ,\n\u2212\nc\nlet v + = PJ v and\nPNv = PJ v.\nLet w * v = i=1 wi vi ei , and since\nX\nX\nv 2 \u2212 (\u03c00 v)2 =\n(\u03c0s v)2 \u2212 (\u03c0s\u22121 v)2 =\n(\u2206s v) * (\u03c0s v + \u03c0s\u22121 v),\ns>0\n\ns>0\n\nP\none has to control increments of the form N\ni=1 \u03b5i (\u2206s v)i (\u03c0s v + \u03c0s\u22121 v)i .\nObserve that if \u03b7s \u2265 N then with probability 1,\nN\nX\ni=1\n\n\u03b5i ((\u2206s v) * (\u03c0s v + \u03c0s\u22121 v))i \u2264 k(\u2206s v) * (\u03c0s v + \u03c0s\u22121 v)klN\n1\n\n\u22642k\u2206s vklN sup kvklN \u2264 2\u03b12 \u03b8s (\u2206s v)(\u03b3 + d\u03c6(N )).\n2\n\nv\u2208V\n\n2\n\nNext, if \u03b7s \u2264 N we will decompose the vectors one has to control according\n\n15\n\n\fto the size of their coordinates, because, with probability 1 \u2212 2 exp(\u2212r 2 /2),\nN\nX\ni=1\n\n\u03b5i (\u2206s v)i (\u03c0s v + \u03c0s\u22121 v)i \u2264 k(\u2206+\ns v) * (\u03c0s v + \u03c0s\u22121 v)klN\n1\n\n+\n+\n\u2212\n\u2212\n+rk(\u2206\u2212\n+ rk(\u2206\u2212\n.\ns v) * ((\u03c0s v) + (\u03c0s\u22121 v) )klN\ns v) * ((\u03c0s v) + (\u03c0s\u22121 v) )klN\n2\n2\n(3.2)\n\nConsider the following two cases. If is,v = \u03b7s then\n+\nk(\u2206+\ns v) * (\u03c0s v + \u03c0s\u22121 v)klN \u2264k\u2206s vklN kPIs,v (\u03c0s v + \u03c0s\u22121 v)klN\n1\n\n2\n\n2\n\n.\u03b12 k\u2206s vk\u03c6(\u03b7s ) (\u03b3 + d\u03c6(\u03b7s )) .\nMoreover,\n\u2264\nk\u2206\u2212\ns vklN\n\u221e\n\nk\u2206+\ns vklN\n2\n\n|Is,v\n\n|1/2\n\n\u2264 2\u03b1k\u2206s vk\n\n\u03c6(\u03b7s )\n1/2\n\n\u03b7s\n\n,\n\nand thus, for every v \u2208 V ,\n+\n1/2\n\u2212\nkw+ klN .\u03b12 \u03b3\u03c6(\u03b7s )k\u2206s vk.\n\u03b7s1/2 k(\u2206\u2212\ns v) * w klN \u2264 \u03b7s k\u2206s vklN\n\u221e\n2\n\n2\n\n1/2\n\n\u2212\n\u2217\nTo estimate \u03b7s k(\u2206\u2212\n, observe that since (\u2206\u2212\ns v)*w klN\ns v)i .\u03b1 k\u2206s vk\u03c6(\u03b7s +\n2\n\u221a\nP\nP\n\u221a\n|ai bi | \u2264\na\u2217i b\u2217i , then\ni)/ \u03b7s + i, wi\u2217 .\u03b1 d\u03c6(i)/ i and\n\u2212\n1/2\n\u03b7s1/2 k(\u2206\u2212\ns v) * w klN .\u03b12 \u03b7s k\u2206s vkd\n2\n\nNX\n\u2212\u03b7s\n\ni=1\n1/2\n.\u03b12 d\u03b7s \u03a6s k\u2206s vk.\n\n\u03c62 (i) \u03c62 (\u03b7s + i)\n*\ni\n\u03b7s + i\n\n!1/2\n\nTherefore, summing the three terms over {s > 0 : \u03b7s \u2264 N },\nX\nk(\u2206+\ns v) * (\u03c0s v + \u03c0s\u22121 v)klN\n1\n\n{s>0:\u03b7s \u2264N }\n\n.\u03b12 \u03b3\n\nX\n\n{s>0:\u03b7s \u2264N }\n\nX\n\n{s>0:\u03b7s \u2264N }\n\nand\nX\n\n{s>0:\u03b7s \u2264N }\n\nX\n\n\u03c6(\u03b7s )k\u2206s vk + d\n\n\u03c62 (\u03b7s )k\u2206s vk,\n\n{s>0:\u03b7s \u2264N }\n\n+\n+\n\u03b7s1/2 k(\u2206\u2212\ns v)*((\u03c0s v) +(\u03c0s\u22121 v) )klN .\u03b12 \u03b3\n2\n\n\u2212\n\u2212\n\u03b7s1/2 k(\u2206\u2212\ns v)*((\u03c0s v) +(\u03c0s\u22121 v) )klN .\u03b12 d\n2\n\n16\n\nX\n\n\u03c6(\u03b7s )k\u2206s vk,\n\n{s>0:\u03b7s \u2264N }\n\nX\n\n{s>0:\u03b7s \u2264N }\n\n\u03b7s1/2 \u03a6s k\u2206s vk.\n\n\fNext, if is,v 6= \u03b7s then k\u2206+\ns vklN \u2264 2\u03b1\u03b8s (\u2206s v), and thus\n2\n\n2\nk(\u2206+\ns v) * (\u03c0s v + \u03c0s\u22121 v)klN \u2264 2\u03b1 \u03b8s (\u2206s v)(\u03b3 + d\u03c6(N )).\n1\n\nSince |Is,v | \u2265 \u03b7s ,\n\u2264 2\u03b1\u03b8s (\u2206s v)/|Is,v |1/2 \u2264 2\u03b1\nk\u2206\u2212\ns vklN\n\u221e\n\n\u03b8s (\u2206s v)\n1/2\n\n\u03b7s\n\n,\n\nthen splitting each w \u2208 V to w+ + w\u2212 as above,\n+\n1/2\n\u2212\nkw+ klN .\u03b12 \u03b3\u03b8s (\u2206s v),\n\u03b7s1/2 k(\u2206\u2212\ns v) * w klN \u2264 \u03b7s k\u2206s vklN\n\u221e\n2\n\n2\n\nand\n1/2\n\u2212\n\u03b7s1/2 k(\u2206\u2212\ns v) * w klN .\u03b12 d\u03b7s \u03a6s k\u2206s vk.\n2\n\nTherefore,\nX\n(\u2217) =\n\n{s>0:\u03b7s \u2264N }\n\n1/2\n\u2212 *\n+\n+\nk(\u2206+\ns v) * (\u03c0s v + \u03c0s\u22121 v)klN + \u03b7s k(\u2206s v) ((\u03c0s v) + (\u03c0s\u22121 v) )klN\n1\n\n2\n\n\u2212\n\u2212\n+\u03b7s1/2 k(\u2206\u2212\ns v) * ((\u03c0s v) + (\u03c0s\u22121 v) )klN \u2264 (3) + (4) + (5),\n2\n\nwhere\n(3) .\u03b12 (\u03b3 + d\u03c6(N ))\n\nX\n\n\u03b8s (\u2206s v),\n\n(4) .\u03b12 \u03b3\n\n(5) .\u03b12 d\n\n\u03b8s (\u2206s v),\n\n{s>0:\u03b7s \u2264N }\n\n{s>0:\u03b7s \u2264N }\n\nand\n\nX\n\nX\n\n{s>0:\u03b7s \u2264N }\n\n\u03b7s1/2 \u03a6s k\u2206s vk.\n\nRecall that |\u2206s V |, |Vs | \u2264 10 * 2\u03b7s+1 and that \u03b7s+1 \u2264 10\u03b7s . Given r \u2265 c0 ,\n1/2\nthen applying (3.2) for ts = 10r\u03b7s and summing over {s : \u03b7s \u2264 N }, it folPN\n2\n2\nlows that supv\u2208V\ni=1 \u03b5i (v \u2212 (\u03c00 v) )i is bounded by the desired quantity\n\nwith probability at least 1 \u2212 2 exp(\u2212c1 r 2 \u03b70 ).\nFinally, for v \u2208 V0 , let i be the largest integer in {1, ..., N } for which\n\u03b80 (v) \u2265\n\u221a of v.\nPkvk\u03c6(i), and set I to be the set of the i-largest coordinates\nThus, i\u2208I vi2 \u2264 2\u03b12 \u03b80 (v) \u2264 2\u03b12 \u03b3 2 , and for l \u2265 i, vl\u2217 \u2264 \u03b1kvk\u03c6(l)/ l. Since\n|V0 | \u2264 2\u03b70 , then with probability at least 1 \u2212 2 exp(\u2212c2 r 2 \u03b70 )\nN\nX\ni=1\n\n1/2\n\n\u03b5i vi2 .\u03b12 \u03b3 2 + rd\u03a60 \u03b70 kvk,\n\ncompleting the proof.\n17\n\n\f4\n\nCoordinate projections of Function classes\n\nThe aim of this section is to show that under very mild assumptions, empirical processes have well behaved coordinate projections in the sense of\nDefinition 3.1. A first result in this direction was established in [22], in\nwhich the main observation, formulated in the language of Section 3, was\nthat if \u03b70 = 0 and \u03b7s = 2s for s \u2265 1, then for the choice of \u03b8s ((h(Xi ))N\ni=1 ) =\n\u221a\n\u221a\ns/2\nN\n2 khk\u03c82 , \u03b1 = u, k(h(Xi ))i=1 k = khk\u03c81 and \u03c6(x) \u223c x log(eN/x), the set\nV = {(h(Xi ))N\ni=1 : h \u2208 H} has a good decomposition with high probability.\nHence, the Bernoulli process indexed by V 2 satisfies the following:\nTheorem 4.1 There exist absolute constants c1 , c2 and c3 for which the\nfollowing holds. If H is a class of functions, then for every r, u \u2265 c1 , with\n\u03bcN -probability at least 1 \u2212 2 exp(\u2212c2 u), V = P\u03c3 H satisfies that\nsup\nv\u2208V\n\nN\nX\ni=1\n\n\u03b5i vi2\n\n2\n\n. ru\n\n\u0012\n\n\u03b32 (H, \u03c82 ) +\n\n\u221a\n\nN sup khk\u03c81\nh\u2208H\n\n\u0013\n\n* \u03b32 (H, \u03c82 )\n\nwith probability at least 1\u22122 exp(\u2212c3 r 2 ) with respect to the Bernoulli random\nvariables.\nTheorem 4.1 is rather restricted because the \u03c82 -based complexity parameter seems too strong in many situations, as does the assumption that H is\na bounded subset of L\u03c81 . Here, we will try to impose as few assumptions as\npossible on H.\nLet H be a class of functions on (\u03a9, \u03bc). For every u > 0 we will\ndefine three events in the product space \u03a9N , which will be denoted by\n\u03a91,u , \u03a92,u and \u03a93,u . On the event \u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u , the random set\nP\u03c3 H = {(h(Xi ))N\ni=1 : h \u2208 H} will be well behaved for the right choice\nof functionals \u03b8s and \u03c6. We will then study cases in which the event\n\u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u has high probability.\nDefinition 4.2 For (\u03b7s )s\u22650 as above, set s0 \u2265 0 to be the first integer for\nwhich \u03b7s \u2265 log(eN ).\nFor every s \u2208 {s : log(eN ) \u2264 \u03b7s \u2264 N }, let ls be the largest integer in\n{1, ..., N } for which \u03b7s \u2265 l log(eN/l), and if \u03b7s \u2264 log(eN ), set ls = 1.\nThe motivation for this definition is the following. If Ek is the collection\nof subsets of {1, ..., N } of cardinality k, s0 is the level above which one may\nfind k for which the cardinalities |Ek | and |Hs | are comparable. Indeed,\nwhen s < s0 , |E1 | can be significantly larger than |Hs | = 2\u03b7s , but when\n18\n\n\fs \u2265 s0 , log |Hs | and log |Els | are of the same order, and thus one may\nsimultaneously control every function in Hs and every subset in Els at no\nextra price. The main idea of the proofs in this section is to try and balance\nthese two quantities as much as possible.\nObserve that since (\u03b7s )\u221e\ns=0 grows exponentially, so does (ls )s\u2265s0 .\nDefinition 4.3 For an admissible sequence (Hs )s\u22650 and a sequence of functionals (\u03b8u,s )s\u2265s0 , let \u03a91,u be the event for which, for every h \u2208 H, the\nfollowing holds:\n\u00111/2\n\u0010P\nuls+1\n2 (X ))\u2217\n1. for every log(eN ) \u2264 \u03b7s \u2264 N ,\n\u2264 \u03b8u,s (\u2206s h),\n((\u2206\nh)\ns\ni\ni=1\n(and if the uls+1 > N then the sum terminates at N ).\n\u00111/2\n\u0010P\nN\n2 (X ))\u2217\n2. for every \u03b7s > N ,\n((\u2206\nh)\n\u2264 \u03b8u,s (\u2206s h).\ns\ni\ni=1\n3.\n\n\u0010P\nuls0 +1\ni=1\n\n((\u03c0s0 h)2 (Xi ))\u2217\n\n\u00111/2\n\n\u2264 \u03b8u,s0 (\u03c0s0 h).\n\nThe set \u03a91,u is the subset of \u03a9N in which the functionals \u03b8u,s yield a good\nbound on the l2 norm of the \"relatively large\" coordinates of each increment\nwhen s \u2265 s0 . In contrast, on the set \u03a92,u the smaller coordinates will be\ncontrolled for s \u2265 s0 . One of the key points of the proof is finding an\nestimate on the ln2 norm on these coordinates, but doing so without any\nreal concentration phenomenon for sums of i.i.d. random variables coming\nto one's aid.\nFormally, to define the set \u03a92,u , first fix a random variable Y , an integer\nN and \u03b5 > 0. For every j \u2264 N let \u03b4j = (j/eN )(1+\u03b5) , set\nyj = inf{y : P r(|Y | \u2265 yj ) \u2264 \u03b4j },\nand without loss of generality, we will assume that the infimum is attained.\nFor every 1 \u2264 k \u2264 N , let\n\u221a\n\n\uf8eb\n\nfu (Y, k) = \u03ba3 u \uf8ed\n\nX\n\n{j:2j \u2264\u2308k/u\u2309}\n\n\uf8f61/2\n\n2j y22j \uf8f8\n\n,\n\nwhere \u03ba3 is a suitable chosen absolute constant.\nThe motivation for this definition is the following observation, showing\nthat with high probability, the \"tail\" of a sum of i.i.d random variables can\nbe controlled using f .\n19\n\n\fLemma 4.4 There exist absolute constants c1 and c2 for which the following holds. For every integer l and u \u2265 c1 /\u03b5, with probability at least\n1 \u2212 2 exp(\u2212c2 u\u03b5l log(eN/l)), for every integer k > ul,\nk\nX\n\n(Yi2 )\u2217 \u2264 fu (Y, k)\n\ni=ul+1\n\nProof. Since P r(|Y | \u2265 yj ) \u2264 \u03b4j = (j/eN )1+\u03b5 then for u \u2265 1,\n\u0012 \u0013\nN uj\n\u2217\nP r(Yuj \u2265 yj ) \u2264\n\u03b4 \u2264 exp(uj log(eN/uj) \u2212 (1 + \u03b5)uj log(eN/j))\nuj j\n\u2264 exp(\u2212\u03b5uj log(eN/j)).\nThus, summing over {j = \u2308l + 2i /u\u2309 : 2i \u2264 k \u2212 ul}, it follows that with\n\u2217\nprobability at least 1 \u2212 exp(\u2212c1 \u03b5ul log(eN/l)), if 2i \u2264 k \u2212 ul then Yul+2\ni \u2264\ny\u2308l+2i /u\u2309 . Therefore,\nk\nX\n\n(Yj2 )\u2217 \u2264\n\nj=ul+1\n\nX\n\n{i:2i \u2264k\u2212ul}\n\n\u2264c2 u\n\n\u2217\n2\n2i (Yul+2\ni\u22121 ) \u2264\n\nX\n\nX\n\n2\n2i yl+2\ni\u22121 /u\n\n{i:2i \u2264k\u2212ul}\n\n2i y22i = f 2 (Y, k),\n\n{j:2j \u2264k/u}\n\nwhere the last inequality is evident by a change of variables.\nWe will also need the following \"global\" counterpart of the functional f .\nDefinition 4.5 Given a class of functions H, an integer N and \u03b5 > 0, set\nzj = inf{z : sup P r(|h| \u2265 zj ) \u2264 (j/eN )1+\u03b5 }.\nh\u2208H\n\nFor every k \u2264 N and u \u2265 1, let\n\u221a\n\n\uf8eb\n\nX\n\nFu (k) = \u03ba3 u \uf8ed\n\n{j:2j \u2264k/u}\n\n\uf8f61/2\n\n2j z22j \uf8f8\n\nClearly, for every h \u2208 H and every k, fu (h, k) \u2264 Fu (k).\nDefinition 4.6 Let \u03a92,u be the event on which, for every h \u2208 H, every\ns \u2265 s0 and every j > uls\n20\n\n\f1.\n2.\n\n\u0010P\nj\n\n2\n\u2217\ni=uls +1 ((\u2206s h) (Xi ))\n\n\u0010P\nj\n\n2\n\u2217\ni=uls +1 ((\u03c0s h) (Xi ))\n\n\u00111/2\n\n\u00111/2\n\n\u2264 fu (\u2206s h, j),\n\u2264 Fu (j).\n\nThe final set, \u03a93,u is very close in nature to \u03a92,u . It is needed to control\nthe coordinates of \"very small\" increments \u2013 when s < s0 , if such an integer\nexists.\nDefinition 4.7 If \u03b70 < log(eN ), let \u03a93,u be the event on which for every\nh \u2208 H, every 0 \u2264 s < s0 and 1 \u2264 j \u2264 N ,\nj\nX\n\n((\u2206s h)2 (Xi ))\u2217\n\ni=1\n\n!1/2\n\n\u2264 fu (\u2206s h, j),\n\nj\nX\n\n((\u03c0s0 h)2 (Xi ))\u2217\n\ni=1\n\n!1/2\n\n\u2264 Fu (j).\n\nIf \u03b70 \u2265 log(eN ) set \u03a93,u = \u03a9N .\nIt turns out that on the event \u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u , the set P\u03c3 H is indeed\nwell behaved. Let\nX\n\u03b8u,s (\u2206s h),\n(4.1)\n\u03b3u = inf sup\nh\u2208H s>s\n0\n\nwith the infimum is taken with respect to all (\u03b7s )-admissible sequences.\nFrom here on we will assume that (Hs )s\u22650 is an almost optimal (\u03b7s )s\u22650 admissible sequence.\nLemma 4.8 There exists absolute constants c1 and c2 for which the following holds. Let (\u03b8u,s )s\u2265s0 be functionals, and for s < s0 set \u03b8u,s = 0.\nFor every u \u2265 c1 , on the event \u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u , for every h \u2208 H and\nI \u2282 {1, ..., N },\n1. if \u03b7s \u2264 N then\n!1/2\nX\n(\u2206s h)2 (Xi )\n\u2264 \u03b8u,s (\u2206s h) + fu (\u2206s h, |I|),\ni\u2208I\n\nand if \u03b7s > N ,\n!1/2\nX\n2\n(\u2206s h) (Xi )\n\u2264 \u03b8u,s (\u2206s h).\ni\u2208I\n\n21\n\n\f2.\nX\n\n!1/2\n\n2\n\nh (Xi )\n\ni\u2208I\n\n\u2264 \u03b3u +\n\nX\n\nF (c2 u2i ) + Rs0 (h, I),\n\n{i:2i \u2264|I|}\n\nwhere Rs0 ,I (h) = \u03b8u,0 (\u03c00 h) if s0 = 0 and Rs0 (h, I) = min{\u03b8u,s0 (\u03c0s0 h), Fu (|I|)}\notherwise.\nProof. First, assume that log(eN ) \u2264 \u03b7s \u2264 N (i.e. s \u2265 s0 ) and recall that\nls is the largest integer for which \u03b7s \u2265 l log(eN/l). If |I| \u2264 uls then the\nclaim follows from the definition of \u03b8u,s and the set \u03a91,u . If |I| \u2265 uls , then\nX\n\n!1/2\n\n(\u2206s h)2 (Xi )\n\ni\u2208I\n\n\u2264\n\nuls\nX\n((\u2206s h)2 (Xi ))\u2217\ni=1\n\n!1/2 \uf8eb\n+\uf8ed\n\n|I|\nX\n\n\uf8f61/2\n\n((\u2206s h)2 (Xi ))\u2217 \uf8f8\n\ni=uls +1\n\n,\n\nand the claim is evident from the definition of the function fu and the set\n\u03a92,u .\nIf, on the other hand, \u03b7s < log(eN ) then s0 > 0 and the assertion follows\nfrom the definition of \u03a93,u .\nThe second part of (1) follows from the definition of \u03a91,u .\nTurning to (2), we shall treat two cases. First, consider the case |I| \u2265\nPul\nuls0 and observe that it suffices to estimate ( i=1s+1 ((\u03c0s h)2 (Xi ))\u2217 )1/2 . Indeed, let s be an integer for which uls \u2264 |I| < uls+1 . Since ls+1 is nondecreasing, then on \u03a91,u ,\n\uf8eb\n\uf8ed\n\nuls+1\n\nX\ni=1\n\n\uf8f61/2\n\n(h2 (Xi ))\u2217 \uf8f8\n\n\uf8eb\n\n\uf8f61/2\n\nuls+1\n\n\u2264\n\n\u2264\n\nX\n\nj\u2265s+1\n\nX\n\nj\u2265s+1\n\n\uf8ed\n\nX\ni=1\n\n((\u2206j h)2 (Xi ))\u2217 \uf8f8\n\uf8eb\n\n\u03b8u,j (\u2206j h) + \uf8ed\n\nuls+1\n\nX\ni=1\n\n\uf8eb\n\n+\uf8ed\n\n\uf8f61/2\n\nuls+1\n\nX\ni=1\n\n((\u03c0s h)2 (Xi ))\u2217 \uf8f8\n\n\uf8f61/2\n\n((\u03c0s h)2 (Xi ))\u2217 \uf8f8\n\n.\n\nIf J \u2282 I is the set of the largest uls coordinates of ((\u03c0s h)(Xi ))N\ni=1 in I,\nthen the coordinate projections satisfy that\nN\nN\nN\nPI ((\u03c0s h)(Xi ))N\ni=1 = PJ ((\u03c0s\u22121 h)(Xi ))i=1 +PJ ((\u2206s h)(Xi ))i=1 +PI\\J ((\u03c0s h)(Xi ))i=1 ,\n\n22\n\n\fand thus,\n\uf8f61/2\n!1/2 \uf8ebuls+1\nX\nX\n\u0001\u2217\n(\u03c0s h)2 (Xi )\n(\u03c0s h)2 (Xi ) \uf8f8\n\u2264\uf8ed\ni=1\n\ni\u2208I\n\n\uf8eb\n\n\u2264 max \uf8ed\n|I1 |=uls\n\n\uf8eb\n\n+\uf8ed\n\nuls+1\n\nX\n\ni=uls +1\n\nX\n\ni\u2208I1\n\n\uf8f61/2\n\n(\u03c0s\u22121 h)2 (Xi )\uf8f8\n\n\uf8f61/2\n\n\u0001\u2217\n(\u03c0s h)2 (Xi ) \uf8f8\n\n+ max \uf8ed\n|I1 |=uls\n\nP\n\n|I1 |=uls\n\n+\uf8ed\n\nX\n\ni=uls +1\n\ni\u2208I1\n\n\uf8f61/2\n\n(\u2206s h)2 (Xi )\uf8f8\n\n\u00011/2\n2\ni\u2208I (\u03c0s h) (Xi )\n\n\uf8eb\n\nUs,s (h) \u2264Us\u22121,s\u22121 (h) + max \uf8ed\nuls+1\n\nX\n\n.\n\nHence, if we set Uj,s (h) = max|I|=ulj+1\ns, and every h \u2208 H\n\n\uf8eb\n\n\uf8eb\n\nX\n\ni\u2208I1\n\nthen for every\n\n\uf8f61/2\n\n(\u2206s h)2 (Xi )\uf8f8\n\n\uf8f61/2\n\u0001\n\u2217\n(\u03c0s h)2 (Xi ) \uf8f8\n\n\u2264Us\u22121,s\u22121 (h) + \u03b8u,s (\u2206s h) + Fu (uls+1 ).\nSumming over all s > s0 ,\nUs,s (h) \u2264\n\ns\nX\n\n\u03b8u,j (\u2206j h) +\n\ns+1\nX\n\nj=s0 +1\n\nj=s0 +1\n\nFu (ulj ) + Us0 ,s0 (h),\n\nand thus, for every h \u2208 H and every I \u2282 {1, ..., N },\n!1/2\nX\nX\nX\n2\nh (Xi )\n\u03b8u,s (\u2206j h) +\nFu (uls+1 ) + Us0 ,s0 (h).\n\u2264\ni\u2208I\n\ns>s0\n\n{s>s0 :ls \u2264|I|}\n\n\u00011/2\nP\n2\nNext, one has to bound suph\u2208H max|I|\u2264uls0+1\n. This\ni\u2208I (\u03c0s0 h) (Xi )\nis at most \u03b8u,s0 (\u03c0s0 h) on \u03a91,u and when s0 > 0, it is also bounded by\nFu (uls0 ) \u2264 Fu (|I|) on \u03a93,u .\nThe claim in this case follows since ls grows exponentially for s \u2265 s0 ,\nand thus\nX\nX\nFu (uls+1 ) \u2264\nFu (cu2i )\n{i:2i \u2264|I|}\n\n{s\u2265s0 :ls \u2264|I|}\n\n23\n\n\ffor a suitable absolute constant c.\nTurning to the second case, if |I| \u2264 uls0 , note that\nX\n\n2\n\n!1/2\n\nh (Xi )\n\ni\u2208I\n\nX\n\n\u2264\n\ns>s0\n\nX\n\n\u2264\n\n!1/2\nX\n2\n(\u2206s h) (Xi )\n+\ni\u2208I\n\n!1/2\nX\n2\n(\u03c0s0 h) (Xi )\ni\u2208I\n\n\u03b8u,s (\u2206s h) + min{\u03b8u,s0 (\u03c0s0 h), Fu (|I|)}.\n\ns>s0\n\nFor Lemma 4.8 to have any meaning, one has to identify the functionals\nfu , Fu and \u03b8u,s in the cases one is interested in. Our next goal is to study\nthe functions fu and Fu under various tail assumptions on functions in H,\nand naturally, the two families of tail estimates we will be interested in are\nwhen H has a bounded diameter in L\u03c8\u03b2 or in Lq for q > 2.\nIf H \u2282 L\u03c8\u03b2 , then for every h \u2208 H, P r(|h| \u2265 y) \u2264 exp(\u2212(y/khk\u03c8\u03b2 )\u03b2 ).\nThus, for \u03b5 \u2265 1 and every j,\nyj . \u03b5khk\u03c8\u03b2 log1/\u03b2 (eN/j),\n\nzj . \u03b5 sup khk\u03c8\u03b2 log1/\u03b2 (eN/j).\nh\u2208H\n\nHence, if d\u03c8\u03b2 = suph\u2208H khk\u03c8\u03b2 , then\n\uf8eb\n\n\u221a\nFu (i) . \u03b5 u \uf8ed\n\n\uf8f61/2\n\nlog2 i\n\nX\nj=1\n\n2j z22j \uf8f8\n\n\uf8eb\n\n\u221a\n.\u03b2 \u03b5 ud\u03c8\u03b2 \uf8ed\n\n\uf8f61/2\n\nlog2 i\n\nX\nj=1\n\n2j log2/\u03b2 (eN/2j )\uf8f8\n\n\u221a\n\u221a\n\u221a\n.\u03b2 \u03b5 ud\u03c8\u03b2 i log1/\u03b2 (eN/i) \u223c\u03b2 \u03b5 ud\u03c8\u03b2 \u03c6\u03b2 (i),\n\nand in a similar fashion,\n\u221a\n\u221a\n\u221a\nfu (h, i) .\u03b2 \u03b5 ukhk\u03c8\u03b2 i log1/\u03b2 (eN/i) \u223c\u03b2 \u03b5 ukhk\u03c8\u03b2 \u03c6\u03b2 (i).\nUsing the same argument, if h \u2208 Lq then P r(|h| \u2265 khkLq y) \u2264 1/y q and\nfor any 0 < \u03b5 < q/2 \u2212 1, yj = khkLq (N/j)(1+\u03b5)/q . If suph\u2208H khkLq = dLq ,\nq > 2 and cq,\u03b5 = 1 \u2212 2(1 + \u03b5)/q then\n\u221a\n\n\uf8eb\n\n\uf8f61/2\n\nlog2 i\n\nFu (i) . udLq \uf8ed\n\nX\nj=1\n\nj\n\nj 2(1+\u03b5)/q \uf8f8\n\n2 (N/2 )\n\n\u221a\n\u223cc\u22121\nq,\u03b5 udLq \u03c6q,\u03b5 (i),\n\n24\n\n.\n\n\u221a\nc\u22121\nq,\u03b5 udLq\n\n\u221a\n\ni\n\n\u0012\n\nN\ni\n\n\u0013(1+\u03b5)/q\n\n\fand\nfu (h, i) .\n\n\u221a\nc\u22121\nq,\u03b5 ukhkLq\n\n\u221a\n\ni\n\n\u0012\n\nN\ni\n\n\u0013(1+\u03b5)/q\n\n\u221a\n\u223c c\u22121\nq,\u03b5 ukhkLq \u03c6q,\u03b5 (i).\n\nCombining these observations with the estimates of Lemma 4.8 and noting\n\u221a\nthat if s0 > 0 then Rs0 ,I (h) . udLq \u03c6q,\u03b5 (|I|), one reaches the following\ncorollary.\nCorollary 4.9 Let (\u03b8u,s )s\u2265s0 be a sequence of functionals and for s < s0 let\n\u03b8u,s = 0. If H is bounded in Lq for q > 2, then on \u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u , for\nevery h \u2208 H and every I \u2282 {1, ..., N }\n1. if \u03b7s \u2264 N ,\nX\n\n!1/2\n\n(\u2206s h)2 (Xi )\n\ni\u2208I\n\n\u221a\n. \u03b8u,s (\u2206s h) + c\u22121\nq,\u03b5 uk\u2206s hkLq \u03c6q,\u03b5 (|I|),\n\nand if \u03b7s > N then\n!1/2\nX\n(\u2206s h)2 (Xi )\n. \u03b8u,s (\u2206s h).\ni\u2208I\n\n2.\nX\ni\u2208I\n\n!1/2\n\nh2 (Xi )\n\n.\n\nX\n\n\u221a\n\u03b8u,s (\u2206s h) + c\u22121\nq,\u03b5 udLq \u03c6q,\u03b5 (|I|).\n\ns\u22650\n\nA similar bound holds when H is bounded in L\u03c8\u03b2 .\n\n5\n\nEstimates on \u03a9i,u and the choice of functionals\n\nWe will begin by showing that \u03a92,u is a large set, almost regardless of any\nassumptions on \u03c6, an observation that is based on the same idea as Lemma\n4.4.\nLemma 5.1 There exist absolute constants c1 and c2 such that, for every\n\u03b5 > 0 and u \u2265 c1 /\u03b5, P r(\u03a92,u ) \u2265 1 \u2212 2 exp(\u2212c2 \u03b5u\u03b7s0 ).\nProof. Recall that by Lemma 4.4, for any random variable Y , with probability at least 1 \u2212 2 exp(\u2212c1 u\u03b5l log(eN/l)), for every integer k > ul,\nk\nX\n\n(Yi2 )\u2217 \u2264 fu (Y, k).\n\ni=ul+1\n\n25\n\n(5.1)\n\n\fLet l = ls0 , and since \u03b7s \u223c ls log(eN/ls ) and |\u2206s H| . 2\u03b7s , then for u \u2265\nc3 /\u03b5, (5.1) holds uniformly for every h \u2208 \u2206s H with probability at least\n1 \u2212 2 exp(\u2212c4 u\u03b5\u03b7s ). The analogous claim holds for functions in Hs as well,\nwith the uniform bound of Fu replacing fu . Summing over all s \u2265 s0 and\nsince (\u03b7s ) grows exponentially, the claim follows.\nSince \u03a92,u is always large, and since \u03a93,u will behave in a very similar way\nwhen s0 > 0, the crucial point in the construction of a good decomposition\nof P\u03c3 H is a correct choice of \u03b8u,s and estimates on \u03a91,u .\nThe functionals \u03b8u,s capture the geometry of H, and thus have to be\nselected according to the information one has on the class. We will present\ntwo examples of such choices, each leading to one of our two main results.\nThe first one will be based on \"global\" structure like metric entropy, while\nthe second uses accurate estimates on each \"chain\".\n\n5.1\n\nThe ball B2n \u2013 global estimates\n\nLet \u03bc be an unconditional measure on Rn , set H = { t, * : t \u2208 B2n } to be\na class of linear functionals on (Rn , \u03bc) \u2013 and from here on we will identify\nthe class { t, * : t \u2208 T } with its indexing set T . We will also assume that\n\u03bc satisfies the p-small diameter, Lq moment assumption for some p > 2\nand q > 2; that is, \u03bc is supported in \u03ba1 n1/p Bpn , and for every x \u2208 Rn ,\nk x, * kLq \u2264 \u03ba2 kxkln2 .\nLet \u03ba4 \u2265 10 be an absolute constant to be fixed later, set 2s1 \u223c n\u03b4 for\n\u03b4 < 1/2 \u2212 1/2(p \u2212 1), and put\n\u03b7s = \u03ba4 2s+s1 max{log(en/2s+s1 ), 1}.\nNote that s0 = 0 as long as \u03b70 \u223c 2s1 log(en/2s1 ) \u2265 log(eN ), i.e., if n\u03b4 log(n) &\nlog(eN ) - which we will assume is the case, since our main interest in when\nN \u223c n.\nIf X = (x1 , ..., xnP\n) is distributed according to \u03bc then for every 1 \u2264\nl \u2264 n, set Ml = k( li=1 (x2i )\u2217 )1/2 kL\u221e . Define the following functionals\n(which, in this case, will be constants depending only on u and s): let \u03b8u,0 =\n\u221a 1/2\n\u221a 1/2\nc u\u03b70 n1/p 2(s+s1 )(1/2\u22121/p) , if 2s+s1 \u2264 n, set \u03b8u,s = c u\u03b7s n1/p 2\u2212(s+s1 )/p\n\u221a 1/2 \u22122s /n\nand if \u03b7s \u2265 n put \u03b8u,s = c u\u03b7s 2\n, where c = c(\u03ba1 , p, \u03b4).\nTheorem 5.2 For every \u03ba1 , p > 2 and \u03b4 < 1/2 \u2212 1/2(p \u2212 1) there exist\nconstants c1 , c2 and c3 that depend only on \u03ba1 , p and \u03b4 for which the following\nholds. There is an (\u03b7s )s\u22650 -admissible sequence of B2n , for which, if u \u2265 c1 ,\n26\n\n\fthen P r(\u03a91,u ) \u2265 1 \u2212 exp(\u2212c2 n\u03b4 ) and\nX\n\u221a \u221a\n\u03b8u,s ( \u2206s t, * ) \u2264 c3 u n.\nsup\nt\u2208B2n s\u22650\n\nObserve that by the p-small diameter assumption, Ml .p n1/p l1/2\u22121/p . Also,\nsince \u03bc is unconditional, then for every I \u2282 {1, ..., n} and v supported on I,\nk v, * k\u03c82 . kvklI\u221e M|I| .\n\n(5.2)\n\nIndeed, by the unconditionality of \u03bc, (x1 , ..., xn ) has the same distribution\nas (\u03b51 x1 , ..., \u03b5n xn ). Hence, for every r \u2265 1\nk v, * kLr \u223c(EX E\u03b5 |\n\nX\ni\u2208I\n\n\u03b5i xi vi |r )1/r .\n\n\u221a\n. rkvklI\u221e M|I| .\n\nX\nEX r r/2 (\nvi2 x2i )r/2\ni\u2208I\n\n!1/r\n\nWe will also need a few \u03c82 entropy estimates. Set B\u03c82 = {v \u2208 Rn :\nk v, * k\u03c82 \u2264 1}, and for K, L \u2282 Rn denote by N (K, L) the minimal number\nof translates of L needed to cover K.\nLemma 5.3 If I \u2282 {1, ..., n} then for every \u03b5 > 0, log N (B2I , \u03b5B\u03c82 ) .\n2 /\u03b52 . Moreover, for \u03b5 \u2264 1, log N (B n , \u03b5B ) . n log(2/\u03b5).\nM|I|\n\u03c82\n2\nProof. By the dual Sudakov inequality (see, e.g. [20]), if Bk k is a unit\nball of a norm on RI and G = (gi )i\u2208I is a standard Gaussian vector on\nRI , then log N (B2n , \u03b5Bk k ) . (EkGk)2 /\u03b52 . Since kf k\u03c82 \u2264 E exp(f 2 ) and\nP\n( i\u2208I x2i )1/2 \u2264 M|I| almost surely, then by changing the order of integration,\nX\n2\nEkG/cM|I| k\u03c82 \u2264 EX EG (exp((\ngi xi )2 /c2 M|I|\n)|X) \u2264 2\ni\u2208I\n\nfor a suitable absolute constant c, proving the first part.\nFor the second part, note that N (B2n , \u03b5B\u03c82 ) \u2264 N (B2n , B\u03c82 )*N (B\u03c82 , \u03b5B\u03c82 ).\nBy the first part, log N (B2n , B\u03c82 ) . n, while a standard volumetric estimate\nshows that N (B\u03c82 , \u03b5B\u03c82 ) \u2264 (5/\u03b5)n .\n\nNext, let us define the sets Ts . If 2s+s1 > n, let Ts be a maximal\n\u03b5s separated subset of B2n relative to the \u03c82 norm and of cardinality 2\u03b7s .\nIf 2s+s1 \u2264 n, let Ts be a maximal \u03b5s separated subset of U2s+s1 = {x \u2208\nB2n : |supp(x)| \u2264 2s+s1 } with respect to the \u03c82 norm, and of cardinality 2\u03b7s .\nGiven a vector t \u2208 B2n , we will define the functions \u03c0s as follows. If 2s+s1 > n,\n27\n\n\f\u03c0s t is a best \u03c82 approximation of t in Ts . For 2s+s1 \u2264 n one combines\napproximation and dimension reduction. Set s\u2217 to satisfy that 2s\u2217 +s1 = n\n(and without loss of generality we will assume that such an integer exists).\nIf v = \u03c0s\u2217 t, let In/2 be the set of the largest n/2 coordinates of v, and put\n\u03c0s\u2217 \u22121 t to be the best approximation of the coordinate projection PIn/2 v in\nTs\u2217 \u22121 , and so on.\nLemma 5.4 There exists an absolute constant c such that for every t \u2208 B2n ,\ns+s\nif s > s\u2217 (i.e., if \u03b7s > \u03ba3 n), then k \u2206s t, * k\u03c82 \u2264 c2\u22122 1 /n , and if 0 < s \u2264 s\u2217\nthen k \u2206s t, * k\u03c82 \u2264 c2\u2212(s+s1 )/2 M2s+s1 .\nProof. First consider s > s\u2217 . Note that k \u2206s t, * k\u03c82 \u2264 k t \u2212 \u03c0s t, * k\u03c82 +\nk t \u2212 \u03c0s\u22121 t, * k\u03c82 \u2264 \u03b5s + \u03b5s\u22121 , and by the covering numbers estimate from\ns+s\nLemma 5.3, in that range \u03b5s . 2\u22122 1 /n .\nIn the range s \u2264 s\u2217 , \u2206s t = u + w, where w consists of the smallest 2s+s1 \u22121 coordinates of \u03c0s t \u2208 B2I for some |I| = 2s+s1 , and u is an\n\u03b5s\u22121 -approximation of the largest 2s+s1 \u22121 coordinates of \u03c0s t. Therefore,\nk \u2206s t, * k\u03c82 \u2264\u0001k w, * k\u03c82 + \u03b5s\u22121 . Recall that for every such s, U2s+s1 is a\nn\nballs of dimension 2s+s1 , then\nunion of 2s+s\n1\nlog N (U2s+s1 , \u03b5B\u03c82 ) \u22642s+s1 log(en/2s+s1 ) +\n\nmax log N (B2J , \u03b5B\u03c82 )\n\n|J|=2s+s1\n\n.2s+s1 log(en/2s+s1 ) + M22s+s1 /\u03b52 .\nNote that for a suitable choice of \u03ba4 , log |Ts | \u2265 2*2s+s1 log(en/2s+s1 ). Therefore, \u03b5s \u2264 2\u2212(s+s1 )/2 M2s+s1 , and applying (5.2), k w, * k\u03c82 . kwklI\u221e M|I| .\n2\u2212(s+s1 )/2 M2s+s1 .\nProof of Theorem 5.2. Observe that kY k2\u03c82 = kY 2 k\u03c81 , and thus, by a\nstandard application of Bernstein's inequality, for every integer m,\n!\nm\nX\nYi2 \u2265 mkY k2\u03c82 t2 \u2264 2 exp(\u2212cm min{t2 , t4 }).\nPr\ni=1\n\nTherefore, if w is large enough, then\n!\nuls\nX\n(Yi2 )\u2217 \u2265 w2 kY k2\u03c82 * uls log(eN/uls )\nPr\ni=1\n\n\u0012\n\nN\n\u2264\nuls\n\n\u0013\n\n* 2 exp(\u2212cw2 uls log(eN/uls )) \u2264 2 exp(\u2212c1 w2 uls log(eN/uls )).\n\n28\n\n\fMoreover, uls log(eN/uls ) . u\u03b7s , and for u \u2265 1, uls log(eN/uls ) & \u03b7s ,\nimplying that with probability at least 1 \u2212 2 exp(\u2212c2 w2 \u03b7s ),\nuls\nX\n(Yi2 )\u2217\ni=1\n\n!1/2\n\n. wu1/2 kY k\u03c82 \u03b7s1/2 .\n\nAlso, with probability at least 1 \u2212 2 exp(\u2212c2 w2 \u03b7s ), if \u03b7s \u2265 N then\nN\nX\n(Yi2 )\u2217\ni=1\n\n!1/2\n\n. wu1/2 kY k\u03c82 \u03b7s1/2 .\n\nUsing Lemma 5.4 and summing the probability estimates, it is evident that\nwith probability at least 1 \u2212 2 exp(\u2212c3 w2 \u03b70 ), the following holds: if \u03b7s \u2265 N\nthen\n!1/2\nN\nX\ns+s1 /n\n2\n,\n. wu1/2 \u03b7s1/2 2\u22122\n( \u2206s t, Xi )\u2217\nsup\nt\u2208B2n\n\ni=1\n\nif \u03ba4 n \u2264 \u03b7s < N , then\nsup\n\nt\u2208B2n\n\nuls\nX\n2\n( \u2206s t, Xi )\u2217\ni=1\n\n!1/2\n\ns+s1 /n\n\n. wu1/2 \u03b7s1/2 2\u22122\n\n,\n\nand if s > 0 and \u03b7s \u2264 \u03ba4 n then\nsup\n\nt\u2208B2n\n\nuls\nX\n2\n( \u2206s t, Xi )\u2217\ni=1\n\n!1/2\n\n. wu1/2 \u03b7s1/2 2\u2212(s+s1 )/2 M2s+s1 .\n\nFinally, since \u03b70 = \u03ba4 2s1 log(en/2s1 ) then l0 . 2s1 . Moreover, |supp(\u03c00 t)| \u2264\n2s1 and by (5.2), k \u03c00 t, * k\u03c82 \u2264 M2s1 . Hence, with probability at least\n1 \u2212 2 exp(\u2212c4 w2 \u03b70 ),\nsup\n\nt\u2208B2n\n\nuls\nX\n2\n( \u03c00 t, Xi )\u2217\ni=1\n\n!1/2\n\n1/2\n\n. wu1/2 \u03b70 M2s1 .\n\ns1\nSince Ml .p n1/p l1/2\u22121/p , then P r(\u03a91,u ) \u2265 1\u22122 exp(\u2212c5 \u03b70 ) = 1\u22122 exp(\u2212c\n52 )\nP\nfor the desired functionals \u03b8u,s . It remains to choose s1 and estimate s\u22650 \u03b8u,s .\nNote that if 2s1 \u223c n\u03b4 for \u03b4 < 1/2 \u2212 1/2(p \u2212 1), then\n\u221a\n1/2\n\u03b80 \u223c \u03b70 M2s1 \u223c\u03ba1 ,p 2s1 /2 log1/2 (en/2s1 )n1/p 2s1 (1/2\u22121/p) \u2264 c6 (\u03ba1 , p, \u03b4) n.\n(5.3)\n\n29\n\n\fAlso,\nX\n\n\u03b8s .\n\n{s>0:\u03b7s \u2264\u03ba3 n}\n\n.\u03ba1 ,p,\u03b4 n\n\n1/p\n\nX\n\nX\n\n\u03b7s1/2 2\u2212(s+s1 )/2 M2s+s1\n\n{s:\u03b7s \u2264\u03ba3 n}\n(s1 +s)(1/2\u22121/p)\n\n2\n\n{s:2s+s1 \u2264n}\n\n\u221a\nlog1/2 (en/2s+s1 ) \u2264 c6 (\u03ba1 , p, \u03b4) n,\n(5.4)\n\nand\nX\n\n\u03b8s .\u03ba1 ,\u03ba3,p\n\ns+s1 /n\n\nX\n\n2(s+s1 )/2 2\u22122\n\n{s:\u03b7s >\u03ba3 n}\n\n{s:\u03b7s >\u03ba3 n}\n\n\u221a\n\u2264 c6 (\u03ba1 , p, \u03b4) n.\n\n(5.5)\n\nCorollary 5.5 There exist absolute constants c1 , c2 and c3 and c4 that depend on \u03ba1 , \u03ba2 , p, \u03b4, for which the following holds. If \u03bc is as above and \u03b5 > 0,\nthen B2n has an (\u03b7s )s\u22650 -admissible sequence (Ts )s\u22650 for which, for u \u2265 c1 /\u03b5,\nwith probability at least 1 \u2212 2 exp(\u2212c2 \u03b5un) \u2212 2 exp(\u2212c3 n\u03b4 ), for every t \u2208 B2n\nand every I \u2282 {1, ..., N },\n1. if \u03b7s \u2264 N ,\nX\n( \u2206s t, Xi )2\ni\u2208I\n\n!1/2\n\n\u221a\n\u2264 c4 \u03b8u,s + c\u22121\n\u03c6 (|I|),\nq,\u03b5 uk\u2206s tkln\n2 q,\u03b5\n\nand if \u03b7s > N then\nX\n\n2\n\n( \u2206s t, Xi )\n\ni\u2208I\n\n!1/2\n\n\u2264 c4 \u03b8u,s .\n\n2.\nX\n( t, Xi )2\ni\u2208I\n\n!1/2\n\n\u2264c4\n\nX\n\n\u221a\n\u03b8u,s + c\u22121\nq,\u03b5 u\u03c6q,\u03b5 (|I|)\n\ns\n\n\u221a \u221a\n\u221a\n. u n + c\u22121\nq,\u03b5 u\u03c6q,\u03b5 (|I|).\n\nWe will separate our treatment to the cases q > 4 and 2 < q \u2264 4. First, if\nq > 4, let \u03b5 = (q/4 \u2212 1)/2 and note that cq,\u03b5 \u2265 1/2. Also, since ktkln2 \u223c\u03ba2\n30\n\n\fk t, * kLq .\u03ba2 k t, * k\u03c82 , then by the same computation as in (5.3), (5.4)\nand (5.5),\nX\n\u221a\nB4 = sup\n\u03b7s1/2 k\u2206s tkLq .\u03ba1 ,\u03ba2 ,p,\u03b4 n.\nt\u2208B2n s\u22650\n\nWe thus have:\nTheorem 5.6 For every \u03ba1 , \u03ba2 , q > 4, p > 2 and \u03b4 < 1/2 \u2212 1/2(p \u2212 1),\nthere exist constants c0 , c1 , c2 and c3 which depend on \u03ba1 , \u03ba2 , p, q and \u03b4,\nand an absolute constant c4 for which the following holds. If \u03bc is as above,\nand N \u2264 exp(c0 n\u03b4 ), then for every u \u2265 c1 , with \u03bcN -probability at least\n1 \u2212 2 exp(\u2212c2 n\u03b4 ), P\u03c3 (B2n ) satisfies that\nN\n1 X\n\u03b5i Xi , t\nsup\nt\u2208B2n N\n\n2\n\n\u2264 c3 ru\n\ni=1\n\n\u0012r\n\nn\nn\n+\nN\nN\n\n\u0013\n\n,\n\nwith probability at least 1 \u2212 2 exp(\u2212c4 nr 2 ) relative to the Bernoulli random\nvariables.\nTurning to the case 2 < q \u2264 4, recall that for 0 < \u03b5 < q/2 \u2212 1, Bq,\u03b5 =\nP\n1\u22122(1+\u03b5)/q\nk\u2206s vkLq . Assume that \u03bc is as above and satisfies the\n{s:\u03b7s \u2264N } \u03b7s\np-small diameter assumption for p > q/(q/2 \u2212 1). Then, for 0 < \u03b5 <\nq/2 \u2212 1 \u2212 q/p (i.e. if 1 \u2212 (2(1 + \u03b5)/q) \u2212 1/p > 0),\nX\nBq,\u03b5 .\n(2s+s1 log(en/2s+s1 ))1\u22122(1+\u03b5)/q 2\u2212(s+s1 )/2 n1/p 2(s+s1 )(1/2\u22121/p)\n{s:2s+s1 \u2264n}\n\n+\n\nX\n\n(s+s1 )/n\n\n2(s+s1 )(1\u22122(1+\u03b5)/q) 2\u22122\n\n{s:2s+s1 >n}\n\n.\n\nn1\u22122(1+\u03b5)/q\n.\n1 \u2212 2(1 + \u03b5)/q \u2212 1/p\n\nTherefore, one has\nTheorem 5.7 Let 2 < q \u2264 4, p > (1 \u2212 2/q)\u22121 and 0 < \u03b5 < 2/q \u2212 1 \u2212 q/p. If\n\u03bc and \u03b4 are as above, u & 1/\u03b5, and N . exp(c0 n\u03b4 ), then with \u03bcN probability\nat least 1 \u2212 2 exp(\u2212c1 \u03b5un) \u2212 2 exp(\u2212c2 n\u03b4 ), P\u03c3 (B2n ) satisfies that\nN\n1 X\nsup\n\u03b5i Xi , t\nt\u2208B2n N\ni=1\n\n2\n\n.\u03ba1 ,\u03ba2 ,p,\u03b4\n\nru\n(1 \u2212 2(1 + \u03b5)/q)2\n\n\u0012\u0010\n\nn \u00111\u2212(2/q)\u22122\u03b5/q\n+\nN\n\nr\n\nn\nn\n+\nN\nN\n\nwith probability at least 1 \u2212 2 exp(\u2212c3 nr 2 ) relative to the Bernoulli random\nvariables.\n31\n\n\u0013\n\n.\n\n\fIn particular, taking \u03b5 \u223c 1/ log(eN/n), then for every such N satisfying\nthat N &\u03ba1 ,\u03ba2 ,q,p n, and any u \u2265\u03ba1 ,\u03ba2 ,q,p log(eN/n),\nsup\n\nt\u2208B2n\n\n5.2\n\nN\n1 X\n\u03b5i Xi , t\nN\n\n2\n\n.\u03ba1 ,\u03ba2 ,q,p ru\n\ni=1\n\n\u0010 n \u00111\u22122/q\n\n.\n\nN\n\nUnconditional log-concave measures\n\nWe will now present a different way of bounding \u03a91,u (and \u03a93,u if needed) by\nestimating the moments of the increments \u2206s h, and selecting the functionals\n\u03b8u,s accordingly.\nFor every s \u2265 0 and h \u2208 H, set\nmin{uls0 +1 ,N }\n\nmin{uls+1 ,N }\n\nZs2 (h)\n\n=\n\nX\n\n2\n\n\u2217\n\n((\u2206s h) (Xi )) ,\n\nZs20 (h)\n\n=\n\nX\n\n((\u03c0s0 h)2 (Xi ))\u2217 .\n\ni=1\n\ni=1\n\nIn light of Theorem B, we will assume that H is a bounded subset of L\u03c81\n(although what we do here can be extended to other moment assumptions),\nand thus one may control \u03a92,u using \u03c6\u03b2 for \u03b2 = 1 and \u03b5 which will be\nselected later.\nLemma 5.8 There exist absolute constants c1 , c2 and c3 for which the following holds. For u \u2265 c1 , with probability at least 1 \u2212 2 exp(\u2212c1 u\u03b7s0 ), for\nevery s \u2265 s0 and every h \u2208 H, Zs (h) \u2264 ekZs (h)kL2u\u03b7s+1 .\nProof. If Z is a nonnegative random variable then P r(Z \u2265 ekZkLq ) \u2264\nexp(\u2212q). Thus, for a fixed s and every h \u2208 H, Zs (h) \u2264 ekZs (h)kL2u\u03b7s+1\nwith probability at least 1 \u2212 exp(\u22122u\u03b7s+1 ). Since log |\u2206s H| . \u03b7s+1 and\nbecause there are at most exp(uls+1 log(eN/uls+1 )) \u2264 exp(u\u03b7s+1 ) subsets of\n{1, ..., N } of cardinality uls+1 , the same probability estimate holds uniformly\nfor every h \u2208 H (with a different constant). Summing the probabilities for\nevery s \u2265 s0 and repeating the same argument for Hs0 concludes the proof.\nNext, one has to control the moments appearing in Lemma 5.8, which is\nbased on the following result, due to Latala [17].\nTheorem 5.9 Let X1 , ..., Xm be independent, distributed according to a\nnonnegative random variable X. Then for every p \u2265 1,\n( \u0012 \u0013\n)\nm\nX\np m 1/r\nXi kLp \u223c\nkXkLr : max{1, p/m} \u2264 r \u2264 p .\nk\nr p\ni=1\n\n32\n\n\fDefinition 5.10 If X is a random variable, for every p \u2265 1 set\nkXkLq\n\u221a .\nq\n1\u2264q\u2264p\n\nkXk(p) = sup\n\nThe (p)-norms are a local version of the \u03c82 norm, and clearly kXk(p) .\nkXk\u03c82 . Using those norms one may obtain a more compact expression for\nthe required moments.\nLemma 5.11 There exist an absolute constant c such that for every h \u2208 H,\nevery s > s0 and every u > 0,\n\u221a 1/2\nkZs (h)kL2u\u03b7s+1 \u2264 c u\u03b7s+1 k\u2206s hk(2u\u03b7s+1 )\nand\nkZs0 (h)kL2u\u03b7s\n\n0 +1\n\n\u221a 1/2\n\u2264 c u\u03b7s0 +1 k\u03c0s0 hk(2u\u03b7s0 +1 ) .\n\nP\n2 1/2 k\nProof. Let Yi = h(Xi ) and observe that for every m, k( m\nLp =\ni=1 Yi )\nPm\n1/2\n2\nk i=1 Yi kLp/2 . Since m = uls+1 and p = 2u\u03b7s+1 then p/2 \u2265 m. Also, for\n\u221a\nevery r \u2264 p, kY kLr \u2264 rkY k(p) , and applying Theorem 5.9,\nk\n\nm\nX\ni=1\n\nYi2 kLp/2\n\np\n. kY k(p/2) sup \u221a\nr\n2\u2264r\u2264p\n2\n\n\u0012\n\nm\np\n\n\u00131/r\n\nHence, for our choice of p and m,\nk\n\nm\nX\ni=1\n\n1/2\n\nYi2 kLp/2 .\n\n\u221a\n\n1/2\n\n1/2\n\nu\u03b7s+1 kY 2 k(u\u03b7s+1 ) =\n\n. kY 2 k(p/2) p\n\n\u221a\n\np\nlog(p/m)\n\n.\n\n1/2\n\nu\u03b7s+1 kY k(2u\u03b7s+1 ) .\n\nCorollary 5.12 There exist absolute constants c1 and c2 for which the following holds. If, for s > s0 ,\n\u221a 1/2\n\u03b8u,s (\u2206s h) = c1 u\u03b7s+1 k\u2206s hk(2u\u03b7s+1 )\nand\n\n\u221a 1/2\n\u03b8u,s0 (\u03c0s0 h) = c1 u\u03b7s0 +1 k\u03c0s0 hk(2u\u03b7s0 +1 ) ,\n\nthen P r(\u03a91,u ) \u2265 1 \u2212 2 exp(\u2212c2 u\u03b7s0 ).\nNext, assume that s0 > 0, and thus one has to bound P r(\u03a93,u ).\n33\n\n\fLemma 5.13 There exists absolute constants c1 , c2 and c3 such that, for\nevery u \u2265 c1 , with probability at least 1 \u2212 2 exp(\u2212c2 u log N ), for every 0 \u2264\ns < s0 and every h \u2208 H,\nj\nX\n((\u2206s h)2 (Xi ))\u2217\ni=1\n\n!1/2\n\n\u2264 c3 uk\u2206s hk\u03c81\n\np\n\nj log(eN/j) \u223c uk\u2206s hk\u03c81 \u03c61 (j),\n\nand a similar bound holds for \u03c0s0 h.\nProof. Recall that for a fixed \u03b5 > 0 and every i, P r(Yi\u2217 \u2265 yi ) \u2264 exp(\u2212\u03b5i log(eN/i)).\nLet \u03b5 \u223c u \u2265 1 and observe that if Y \u2208 L\u03c81 , then yi . ukY k\u03c81 log(eN/i) and\nP r(\u2203i \u2264 N : Yi\u2217 \u2265 yi ) \u2264 exp(\u2212c1 u log N ).\n(5.6)\nP\nSince the cardinality of the set \u222as<s0 \u2206s H is at most s<s0 2\u03b7s+1 . N c2 ,\n(5.6) holds uniformly with probability at least 1\u2212exp(\u2212c3 u log N ) for u \u2265 c4 .\nTherefore, on that event, for every 0 \u2264 s < s0 and every j,\nj\nX\n((\u2206s h)2 (Xi ))\u2217\ni=1\n\n!1/2\n\nAn identical argument holds for\n\n\u2264 c5 uk\u2206s hk\u03c81\n\n\u0010P\n\np\n\nj log(eN/j).\n\nj\n2\n\u2217\ni=1 ((\u03c0s0 h) (Xi ))\n\n\u00111/2\n\n.\n\nTherefore, the event \u03a91,u \u222a \u03a92,u \u222a \u03a93,u has high probability, leading to\nthe following decomposition result.\nCorollary 5.14 There exist absolute constants c1 and c2 for which the following holds. For every u \u2265 c1 , with probability at least 1\u22122 exp(\u2212c2 u log N ),\nfor every h \u2208 H and every I \u2282 {1, ..., N },\n1. if \u03b7s \u2264 N ,\nX\n((\u2206s h)2 (Xi ))\u2217\ni\u2208I\n\n!1/2\n\n.\n\n\u221a\n\n1/2\n\nu\u03b7s+1 k\u2206s hk(2u\u03b7s+1 ) + uk\u2206s hk\u03c81 \u03c61 (|I|),\n\nand if \u03b7s > N then\nX\ni\u2208I\n\n2\n\n\u2217\n\n((\u2206s h) (Xi ))\n\n!1/2\n\n34\n\n.\n\n\u221a\n\n1/2\n\nu\u03b7s+1 k\u2206s hk(2u\u03b7s+1 ) .\n\n\f2.\nX\n(h2 (Xi ))\u2217\ni\u2208I\n\nwhere Rs0 (h) .\nwise.\n\n!1/2\n\n.\n\n\u221a X 1/2\n\u03b7s+1 k\u2206s hk(2u\u03b7s+1 ) +ud\u03c81 \u03c61 (|I|)+Rs0 (h),\nu\ns>s0\n\n\u221a\nu\u03b71 k\u03c00 hk(2u\u03b71 ) if s0 = 0 and Rs0 (h) . ud\u03c81 \u03c61 (|I|) other-\n\nRemark 5.15 Note that k\u2206s hk(2u\u03b7s+1 ) . k\u2206s hk\u03c82 , and thus one may take\n\u221a 1/2\n\u03b8u,s \u223c u\u03b7s+1 k\u2206s hk\u03c82 . If \u03b70 = 0 and \u03b7s = 2s for s \u2265 1, then for an almost\noptimal admissible sequence,\nX 1/2\n\u03b7s+1 k\u2206s hk(2u\u03b7s+1 ) . \u03b32 (H, \u03c82 ).\ns>s0\n\nAlthough this estimate leads to an alternative proof of Theorem 4.1, it is\nnot sharp enough to prove Theorem B, as the latter requires more accurate\nbounds on k\u2206s hk(2u\u03b7s+1 ) .\nFrom here on we will assume that \u03b70 = 0 and that \u03b7s = 2s for s \u2265 1. If\n\u221a 1/2\ns \u2265 s0 \u223c log N , set \u03b8u,s (\u2206s t) = u\u03b7s+1 k\u2206s hk(2u\u03b7s+1 ) .\nTheorem 5.16 There exist absolute constants c1 and c2 for which the following holds. If \u03bc is an isotropic, unconditional log-concave measure, HT =\n{ t, * : t \u2208 T } and (Ts )s\u22650 is an admissible sequence of T , then for every\nu \u2265 c1 ,\n\u0010\n\u0011\n\u03b8u,s ( \u2206s t, * ) \u2264 c2 u 2s k\u2206s tkln\u221e + 2s/2 k\u2206s tkln2 .\n\nProof. Let T \u2282 Rn , and identify it with the class of linear functionals\nHT = { t, * : t \u2208 T } on (Rn , \u03bc). By Borell's inequality [8], the \u03c81 and L2\nnorms are c1 -equivalent on Rn , where c1 is an absolute constant, and since \u03bc\nis isotropic, then k t, * kL2 = ktkln2 . Moreover, there is an absolute constant\nc2 such that for every p \u2265 q and t \u2208 Rn ,\np\nk t, * kLp \u2264 c2 k t, * kLq .\nq\n\nHence, for every t \u2208 Rn and every r \u2265 1,\nk t, * kLl\nl k t, * kLq\n\u221a\n\u221a\n+ k t, * k(q) \u2264 c2 sup\n+ k t, * k(q)\nl\nl\nq\u2264l\u2264rq q\nq\u2264l\u2264rq\n\u221a\n\u2264 (c2 r + 1)k t, * k(q) .\n\nk t, * k(rq) \u2264 sup\n\n35\n\n\fAlso, for any t \u2208 Rn and any p \u2265 n, k t, * k(p) \u2264 2c2\nfore, if u \u2265 1 and \u03b7s = 2s \u2264 n then\n\u221a\n\nq\n\np\nnk\n\nt, * k(n) . There-\n\n1/2\n\nu\u03b7s+1 k \u2206s t, * k(2u\u03b7s+1 ) . u2s/2 k \u2206s t, * k(2s ) ,\n\nand if 2s > n then\n\u221a\n\n1/2\n\nu\u03b7s+1 k \u2206s t, * k(2u\u03b7s+1 ) .\n\n\u221a 2s\nu k \u2206s t, * k(n) .\nn\n\nNote ([6] or [25], Proposition 3.4) that there is an isotropic convex body K\nsuch that for every t \u2208 Rn and any 1 \u2264 p \u2264 n, k t, * kLp (\u03bc) \u2264 c3 k t, * kLp (K) .\nMoreover, since \u03bc is unconditional, K is also unconditional and using the\nBobkov-Nazarov Theorem [7] we get that\nk t, * kLp (\u03bc) \u2264 c3 k t, * kLp (K) 6 c4 k t, * kLp (K1 ) ,\nwhere K1 is an isotropic image of B1n .\nThe moments of every linear functional t, * relative to the volume measure of an isotropic position of B1n are well known [15]: namely, for 1 \u2264 p \u2264 n,\nk t, * kLp (K1 ) \u223c pktk\u221e +\n\n\uf8eb\n\n\u221a \uf8ed\np\n\nn\nX\n\n\uf8f61/2\n\n(t2i )\u2217 \uf8f8\n\ni=p+1\n\n.\n\nCombining the two estimates, for p \u2264 n and any t \u2208 Rn ,\n\uf8eb\n\uf8eb\n\uf8f61/2 \uf8f6\nn\nX\nk t, * kLq (K1 )\n\uf8f7\n\uf8ec\u221a\nk t, * k(p) \u2264 sup\n(t2i )\u2217 \uf8f8 \uf8f8\n\u223c sup \uf8ed qktk\u221e + \uf8ed\n\u221a\nq\nq\u2264p\nq\u2264p\ni=q+1\n\n\u2264\n\n\u221a\n\npktkln\u221e + ktkln2 .\n\nThus, for 2s \u2264 n,\n2s/2 k \u2206s t, * k(2s ) \u2264 2s k\u2206s tkln\u221e + 2s/2 k\u2206s tkln2 ,\nand if 2s > n,\n\n2s\n\u221a k \u2206s t, * k(n) \u2264 2s k\u2206s tkln\u221e .\nn\n\n36\n\n\fNote that for an almost optimal admissible sequence,\nX\n2s k\u2206s tkln\u221e + 2s/2 k\u2206s tkln2 . \u03b31 (T, ln\u221e ) + \u03b32 (T, ln2 ).\ns\u22650\n\nIt turns out that \u03b31 (T, ln\u221e ) + \u03b32 (T, ln2 ) can be completely characterized by\nthe following beautiful result due to Talagrand [31, 32].\nTheorem 5.17 There exist absolute constants c and C for which the following holds. Let (yi )ni=1 be independent, standard exponential variables. Then,\nfor every T \u2282 Rn ,\ncE sup\n\nn\nX\n\nt\u2208T i=1\n\nyi ti \u2264 \u03b31 (T, l\u221e ) + \u03b32 (T, l2 ) \u2264 CE sup\n\nn\nX\n\nt\u2208T i=1\n\ny i ti .\n\nRecall that if (yi )ni=1 are standard exponential\nrandom variables and T \u2282\nPn\nn\nR , then we denote E(T ) = E supt\u2208T i=1 yi ti and d2 (T ) = supt\u2208T ktk2 .\nCombining the estimates above, it follows that on \u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u , P\u03c3 T\nsatisfies Definition 3.1 with \u03b8s = 2s k * kln\u221e + 2s/2 k * kln2 for s \u2265 s0 and \u03b8s = 0\notherwise, \u03b3 . E(T ), \u03c6 \u223c \u03c61 , k( Xi , t )N\nand \u03b1 \u223c u.\ni=1 k = k t, * k\u03c81 \u223c ktkln\n2\nTherefore, B4 . \u03b32 (T, l2 ) . E(T ).\nTheorem 5.18 There exist absolute constants c1 , c2 , c3 and c4 for which\nthe following holds. For every u \u2265 c1 , With \u03bcN -probability at least 1 \u2212\n2 exp(\u2212c2 u log N ), the set V = P\u03c3 T satisfies that\nsup\nv\u2208V\n\nN\nX\ni=1\n\n\u0010\n\u0011\n\u221a\n\u03b5i vi2 \u2264 c3 ru2 d2 (T ) N E(T ) + (E(T ))2\n\nwith probability at least 1\u22122 exp(\u2212c4 r 2 ) with respect to the Bernoulli random\nvariables.\n\n5.3\n\nProofs of Theorems A and B\n\nThe final step we need for the proofs of Theorem A and Theorem B is a\nversion of the Gin\u00e8-Zinn symmetrization Theorem (see, e.g. [14, 33]), which\nenables one to pass from the Bernoulli process indexed by random coordinate\nprojections of a class of functions, to the empirical process indexed by the\nclass.\n\n37\n\n\fTheorem 5.19 Let P\nF be a class of functions and for every x > 0, set\n\u03b2N (x) = inf f \u2208F P r(| N\ni=1 f (Xi ) \u2212 Ef | > x/2). Then\n\u03b2N (x)P rX\n\nsup\n\nN\nX\n\nf \u2208F i=1\n\nf (Xi ) \u2212 Ef > x\n\n!\n\n\u2264 2P rX\u2297\u03b5\n\nsup\n\nN\nX\n\nf \u2208F i=1\n\n\u03b5i f (Xi ) > x/4 .\n\nTo apply Theorem 5.19, one has to identify the right value x for which\n\u03b2N (x) \u2265 1/2. In our case, F =P\nH 2 , and thus one has to show that if x is\n2\n2\nlarge enough, then suph\u2208H P r(| N\ni=1 h (Xi ) \u2212 Eh | > x/2) \u2264 1/2.\n\nLemma 5.20 Let H be a class of functions which is bounded in Lq and\nconsider the \u221a\nempirical process indexed by F = {h2 : h \u2208 H}. If q \u2265 4\nand x & d2Lq N then \u03b2N (x) \u2265 1/2 and the same holds if 2 < q < 4 and\nx &q d2Lq N 2/q .\nProof. The first part of the claim follows from an application of Chebyshev's inequality, and is omitted. For the second part, fix r > 0, set\n2/q ) \u2264 i/(rN ) then\n2\n2\nV = (h2 (Xi ))N\ni=1 , and since P r(|h (X)| \u2265 dLq (rN/i)\n\u0011 \u0012N \u0013\n\u0010\n\u2217\n2\n2/q\n.\nP r Vi \u2265 dLq (rN/i)\n* (i/rN )i \u2264 exp(\u2212i log(er)) = (er)\u2212i .\ni\n(5.7)\nMoreover, for r0 \u223c c2 , P r(\u2203i : |h2 (Xi )| \u2265 r0 d2Lq N 2/q ) \u2264 1/10. Hence, a\ntruncation argument shows that without loss of generality we may assume\nthat kh2 kL\u221e \u2264 r0 d2Lq N 2/q . Applying the L\u221e estimate for the largest two\ncoordinates of V and (5.7) for the rest, it follows that\nP r(kV klN \u2265 cq (r0 + r)d2Lq N 2/q ) .\n2\n\nN\nX\n\nr \u2212i . r \u22122 .\n\ni=3\n\nHence, under the truncation assumption,\nE|\n\nN\nX\ni=1\n\nh2 (Xi ) \u2212 Eh2 | .EX E\u03b5 |\n\nN\nX\n\ni=1\n2/q\n\n.q r0 d2Lq N\n\nN\nX\nh4 (Xi ))1/2 = EkV klN\n\u03b5i h2 (Xi )| . EX (\ni=1\n\n,\n\nshowing that it suffices to take x \u223cq d2Lq N 2/q as claimed.\n\n38\n\n!\n\n2\n\n\fSince x/N is well within our range, one may complete the proofs of\nTheorem A and Theorem B.\np\nProof of Theorem A. For q > 4, let \u03c1r,u \u223c\u03ba1 ,\u03ba2 ,q ru( n/N + n/N ) for\nu &\u03ba1 ,\u03ba2,q c1 , and r \u2265 c2 . If 2 < q < 4 set \u03c1r,u \u223c\u03ba1 ,\u03ba2 ,q ru(n/N )1\u22122/q for\nu &\u03ba1 ,\u03ba2,q log(eN/n) and r \u2265 c3 . Then,\nP rX\n\nN\n1 X\nsup |\nt, Xi\nt\u2208S n\u22121 N\ni=1\n\n\u22644EX P r\u03b5\n\n2\n\n2\n\n\u2212 E t, X | \u2265 \u03c1r,u\n\n!\n\n!\nN\n1 X\n2\n|\n\u03b5i t, Xi | \u2265 \u03c1r,u /4\nN\ni=1\n\nc\n\n.P rX ((\u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u ) ) + P r\u03b5\n. exp(\u2212c4 n).\n\nN\n1 X\n2\n\u03b5i t, Xi | > \u03c1r,u /4 \u03a91,u \u2229 \u03a92,u \u2229 \u03a93,u\n|\nN\ni=1\n\nProof of the quantitative Bai-Yin Theorem.\nTo prove the quantitative version of the Bai-Yin Theorem one has to\ncombine Theorem A with a conditioning argument. Consider the vector\nX = (\u03be1 , ..., \u03ben ) with \u03be \u2208 Lq for some q > 4, and let \u03bd be the measure on\nRn given by \u03bd = X|cn1/p Bpn ; that is, \u03bd is given by the conditioning of X to\nthe unconditional body cn1/p Bpn for a suitable choice of c and p. Clearly, \u03bd\nis unconditional and satisfies the p-small diameter Lq moment assumption,\nand thus, falls within the realm of Theorem A. Therefore, if the event A =\n{maxi\u2264N kXi klnp \u2264 cn1/p } has high enough probability, the quantitative\nversion of the Bai-Yin Theorem follows from Theorem A, because for every\nevent B,\nN\n1/p n\nP r((Xi )N\nBp )P r(A) + P r(Ac ).\ni=1 \u2208 B) \u2264 P r((Xi )i=1 \u2208 B|X1 , ..., XN \u2208 cn\n\nHence, the final step in the proof of our version of the Bai-Yin Theorem is\nto show that if \u03be \u2208 Lq for q > 2, there is some p > 2 for which A has a large\nmeasure.\nRecall that for every v \u2208 Rn , kvklnp,\u221e = maxi\u2264n vk\u2217 /k1/p , and since lnr \u2282\nn\nlp,\u221e \u2282 lnp for every r < p, it suffices to show that maxi\u2264N kXklnp,\u221e . n1/p\nfor some p > 2 with high enough probability.\nLemma 5.21 For every q > 4 and 2 < p < q, there exist constants c1\nand c2 that depend on q and p for which the following holds. If \u03be \u2208 Lq ,\n39\n\n!\n\n\fX = (\u03be1 , ..., \u03ben ) and X1 , ..., XN are independent copies of X, then\nP r( max kXi klnp,\u221e \u2265 c1 k\u03bekLq n1/p ) \u2264\n1\u2264i\u2264N\n\nc2 N\nq\n\nn p \u22121\n\n.\n\nProof. If A = \u0001k\u03bekLq then P r(|\u03be| \u2265 At) \u2264 t\u2212q , and for every 1 \u2264 k \u2264 n,\nP r(\u03bek\u2217 \u2265 t) \u2264 nk (P r(|\u03be| \u2265 t))k . Therefore, if p < q and y > e then\nP r(\u03bek\u2217 \u2265 A(ny/k)1/p ) \u2264 exp(k log(en/k) \u2212 k(q/p) log(ny/k))\nq\n\u2264 exp(\u2212k( \u2212 1) log(ny/k)).\np\n\nUsing this estimate for every k = 2j and summing the probabilities, it follows\nthat for every q and p there is a constant cq,p for which kXklnp,\u221e . n1/p with\nprobability at least 1 \u2212 cq,p n1\u2212q/p , and in particular, P r(maxi\u2264N kXi klnp,\u221e \u2265\ncn1/p ) \u2264 cq,p N/n(q/p)\u22121 , as claimed.\nCombining Lemma 5.21 with Theorem A concludes the proof of the\nquantitative Bai-Yin Theorem.\nProof of Theorem B. If r \u223c u, with probability at least 1 \u2212 2 exp(\u2212c3 u2 )\nwith respect to the Bernoulli random variables,\nsup\nv\u2208P\u03c3 T\n\nN\nE(T ) E 2 (T )\n1 X 2\n\u03b5i vi .u3 d2 (T ) \u221a\n.\n+\nN\nN\nN\ni=1\n\n\u221a\nSince d2 (T )E(T )/ N is a \"legal\" choice in the Gin\u00e9-Zinn symmetrization\ntheorem, the proof is concluded.\n\nReferences\n[1] R. Adamczak, A. Litvak, A. Pajor, N. Tomczak-Jaegermann, Quantitative estimates\nof the convergence of the empirical covariance matrix in log-concave ensembles, J.\nAmer. Math. Soc. 23 535-561, 2010.\n[2] R. Adamczak, A. Litvak, A. Pajor, N. Tomczak-Jaegermann, Sharp bounds on the\nrate of convergence of empirical covariance matrix, C.R. Math. Acad. Sci. Paris, 349,\n195\u2013200, 2011.\n[3] R. Adamczak, R. Latala, A. Litvak, A. Pajor, N. Tomczak-Jaegermann, Chevet type\ninequality and norms of submatrices, preprint.\n[4] G. Aubrun, Sampling convex bodies: a random matrix approach, Proc. Amer. Math.\nSoc. 135, 1293-1303, 2007.\n[5] Z.D. Bai, Y.Q. Yin, Limit of the smallest eigenvalue of a large dimensional sample\ncovariance matrix, Ann. Probab. 21, 1275\u20131294, 1993.\n\n40\n\n\f[6] K. M. Ball, Logarithmically concave functions and sections of convex sets in Rn ,\nStudia Math. 88 (1988), 69\u201384.\n[7] S.G. Bobkov, F.L. Nazarov, On convex bodies and log-concave probability measures\nwith unconditional basis, Geometric Aspects of Functional Analysis, Lecture Notes\nin Mathematics 1807, 53-69, 2003.\n[8] C. Borell, The Brunn-Minkowski inequality in Gauss space, Invent. Math. 30 207-216,\n1975.\n[9] J. Bourgain, Random points in isotropic convex bodies, in Convex Geometric Analysis\n(Berkeley, CA, 1996) Math. Sci. Res. Inst. Publ. 34 (1999), 53-58.\n[10] R. M. Dudley, Uniform Centra Limit Theorems, Cambridge Studies in Advanced\nMathematics 63, Cambridge University Press, 1999.\n[11] X. Fernique, R\u00e9gularit\u00e9 des trajectoires des fonctiones al\u00e9atoires gaussiennes, Ecole\nd'Et\u00e9 de Probabilit\u00e9s de St-Flour 1974, Lecture Notes in Mathematics 480, 1-96,\nSpringer-Verlag 1975.\n[12] A. Giannopoulos,\nNotes on\nhttp://users.uoa.gr/\u223capgiannop/\n\nisotropic\n\nconvex\n\nbodies,\n\navailable\n\nat\n\n[13] A. Giannopoulos, M. Hartzoulaki, A. Tsolomitis, Random points in isotropic unconditional convex bodies, J. London Math. Soc. 72, 779\u2013798, 2005.\n[14] E. Gin\u00e9 and J. Zinn, Some limit theorems for empirical processes, Ann. Probab.\n12(4), 929-989, 1984.\n[15] E. D. Gluskin, S. Kwapien, Tail and moment estimates for sums of independent\nrandom variables with logarithmically concave tails, Studia math. 114, 303-309, 1995.\n[16] S. Kwapie\u0144, W.A. Woyczy\u0144ski, Random series and stochastic integrals: single and\nmultiple, Birkh\u00e4user 1992.\n[17] R. Latala, Estimation of moments of sums of independent real random variables,\nAnn. Probab. 25, 1502\u20131513, 1997.\n[18] R. Latala, On weak tail domination of random vectors, Bull. Polish Acad. Sci. Math.\n57, 75\u201380, 2009.\n[19] R. Latala, Order statistics and concentration of lr norms for log-concave vectors, J.\nFunct. Anal. 261 (2011), 681-696.\n[20] M. Ledoux, M. Talagrand, Probability in Banach spaces. Isoperimetry and processes,\nErgebnisse der Mathematik und ihrer Grenzgebiete (3), vol. 23. Springer-Verlag,\nBerlin, 1991.\n[21] S. Mendelson, A. Pajor, N. Tomczak-Jaegermann, Reconstruction and subgaussian\noperators, Geometric and Functional Analysis, 17(4), 1248-1282, 2007.\n[22] S. Mendelson, Empirical processes with a bounded \u03c81 diameter, Geometric and Functional Analysis, 20(4) 988-1027, 2010.\n[23] V.D. Milman, G. Schechtman, Asymptotic theory of finite dimensional normed\nspaces, Lecture Notes in Mathematics 1200, Springer, 1986.\n[24] G. Paouris, Concentration of mass on convex bodies, Geometric and Functional Analysis, 16(5), 1021-1049, 2006.\n[25] G. Paouris, Small ball probability estimates for log-concave measures, Trans. Amer.\nMath. Soc. DOI:10.1090/S0002-9947-2011-05411-5.\n\n41\n\n\f[26] G. Pisier, The volume of convex bodies and Banach space geometry, Cambridge University Press, 1989.\n[27] M. Rudelson, Random vectors in the isotropic position, J. Funct. Anal. 164, 60-72,\n1999.\n[28] M. Rudelson, R. Vershynin, Non-asymptotic theory of random matrices: extreme\nsingular values, Proceedings of the International Congress of Mathematicians, Hyderabad, India, 2010, to appear.\n[29] N. Srivastava, R. Vershynin, Covariance estimation for distributions with 2 + \u01eb moments. arXiv:1106.2775.\n[30] M. Talagrand, Regularity of Gaussian processes, Acta Math. 159, 99-149, 1987.\n[31] M. Talagrand, The supremum of some canonical processes, American Journal of\nMathematics 116, 283\u2013325, 1994.\n[32] M. Talagrand, The generic chaining, Springer, 2005.\n[33] A.W. Van der Vaart, J.A. Wellner,\nSpringer Verlag, 1996.\n\nWeak convergence and empirical processes,\n\n[34] R. Vershynin, Introduction to the non-asymptotic analysis of random matrices. In:\nCompressed Sensing: Theory and Applications, Yonina Eldar and Gitta Kutyniok\n(eds), Cambridge University Press, to appear.\n[35] R. Vershynin, How close is the sample covariance matrix to the actual covariance\nmatrix? Journal of Theoretical Probability, to appear.\n\n42\n\n\f"}