{"id": "http://arxiv.org/abs/1108.0135v1", "guidislink": true, "updated": "2011-07-31T05:01:49Z", "updated_parsed": [2011, 7, 31, 5, 1, 49, 6, 212, 0], "published": "2011-07-31T05:01:49Z", "published_parsed": [2011, 7, 31, 5, 1, 49, 6, 212, 0], "title": "Computing the Mertens function on a GPU", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.2399%2C1108.1443%2C1108.1706%2C1108.4254%2C1108.4120%2C1108.5481%2C1108.4165%2C1108.6205%2C1108.2680%2C1108.3432%2C1108.5577%2C1108.3056%2C1108.0644%2C1108.5221%2C1108.5129%2C1108.1556%2C1108.4356%2C1108.4901%2C1108.5861%2C1108.4013%2C1108.4635%2C1108.4087%2C1108.3050%2C1108.3327%2C1108.4732%2C1108.2776%2C1108.5602%2C1108.6264%2C1108.5480%2C1108.2289%2C1108.2990%2C1108.1701%2C1108.2275%2C1108.1888%2C1108.1734%2C1108.2122%2C1108.2703%2C1108.3930%2C1108.3366%2C1108.4875%2C1108.4451%2C1108.5590%2C1108.4372%2C1108.1615%2C1108.3075%2C1108.5296%2C1108.5967%2C1108.5034%2C1108.5234%2C1108.0135%2C1108.3149%2C1108.5341%2C1108.0910%2C1108.0688%2C1108.2571%2C1108.3013%2C1108.5734%2C1108.5720%2C1108.2594%2C1108.1808%2C1108.3687%2C1108.4779%2C1108.0522%2C1108.4240%2C1108.1817%2C1108.4468%2C1108.5959%2C1108.2656%2C1108.4867%2C1108.2914%2C1108.4211%2C1108.5986%2C1108.6318%2C1108.5827%2C1108.3658%2C1108.6030%2C1108.1569%2C1108.1094%2C1108.6075%2C1108.4749%2C1108.4396%2C1108.3956%2C1108.3913%2C1108.2081%2C1108.3740%2C1108.5024%2C1108.5635%2C1108.4946%2C1108.5937%2C1108.2748%2C1108.3144%2C1108.3202%2C1108.2362%2C1108.5324%2C1108.4041%2C1108.2913%2C1108.0944%2C1108.4068%2C1108.2317%2C1108.1566%2C1108.2797&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Computing the Mertens function on a GPU"}, "summary": "A GPU implementation of an algorithm to compute the Mertens function in\nO(x2/3+{\\ko}) time is discussed. Results for x up to $10^{22}$, and a new\nextreme value for $M(x)/x^{1/2}$, -0.585768 ($M(x) \\approx -1.996 \\ast 10^9$ at\n$x \\approx 1.161 \\ast 10^{19}$), are reported.An approximate algorithm is used\nto examine values of M(x) for x up to $\\exp{(10^{15})}$.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.2399%2C1108.1443%2C1108.1706%2C1108.4254%2C1108.4120%2C1108.5481%2C1108.4165%2C1108.6205%2C1108.2680%2C1108.3432%2C1108.5577%2C1108.3056%2C1108.0644%2C1108.5221%2C1108.5129%2C1108.1556%2C1108.4356%2C1108.4901%2C1108.5861%2C1108.4013%2C1108.4635%2C1108.4087%2C1108.3050%2C1108.3327%2C1108.4732%2C1108.2776%2C1108.5602%2C1108.6264%2C1108.5480%2C1108.2289%2C1108.2990%2C1108.1701%2C1108.2275%2C1108.1888%2C1108.1734%2C1108.2122%2C1108.2703%2C1108.3930%2C1108.3366%2C1108.4875%2C1108.4451%2C1108.5590%2C1108.4372%2C1108.1615%2C1108.3075%2C1108.5296%2C1108.5967%2C1108.5034%2C1108.5234%2C1108.0135%2C1108.3149%2C1108.5341%2C1108.0910%2C1108.0688%2C1108.2571%2C1108.3013%2C1108.5734%2C1108.5720%2C1108.2594%2C1108.1808%2C1108.3687%2C1108.4779%2C1108.0522%2C1108.4240%2C1108.1817%2C1108.4468%2C1108.5959%2C1108.2656%2C1108.4867%2C1108.2914%2C1108.4211%2C1108.5986%2C1108.6318%2C1108.5827%2C1108.3658%2C1108.6030%2C1108.1569%2C1108.1094%2C1108.6075%2C1108.4749%2C1108.4396%2C1108.3956%2C1108.3913%2C1108.2081%2C1108.3740%2C1108.5024%2C1108.5635%2C1108.4946%2C1108.5937%2C1108.2748%2C1108.3144%2C1108.3202%2C1108.2362%2C1108.5324%2C1108.4041%2C1108.2913%2C1108.0944%2C1108.4068%2C1108.2317%2C1108.1566%2C1108.2797&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A GPU implementation of an algorithm to compute the Mertens function in\nO(x2/3+{\\ko}) time is discussed. Results for x up to $10^{22}$, and a new\nextreme value for $M(x)/x^{1/2}$, -0.585768 ($M(x) \\approx -1.996 \\ast 10^9$ at\n$x \\approx 1.161 \\ast 10^{19}$), are reported.An approximate algorithm is used\nto examine values of M(x) for x up to $\\exp{(10^{15})}$."}, "authors": ["Eugene Kuznetsov"], "author_detail": {"name": "Eugene Kuznetsov"}, "author": "Eugene Kuznetsov", "links": [{"href": "http://arxiv.org/abs/1108.0135v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.0135v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.NT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.NT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.0135v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.0135v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Computing the Mertens function on a GPU\n\narXiv:1108.0135v1 [math.NT] 31 Jul 2011\n\nEugene Kuznetsov\n\nAbstract\nA GPU implementation of an algorithm to compute the Mertens function in O(x2/3+\u000f ) time\nis discussed. Results for x up to 1022 , and a new extreme value for M (x)/x1/2 , -0.585768\n(M (x) \u2248 \u22121.996 \u2217 109 at x \u2248 1.161 \u2217 1019 ), are reported.An approximate algorithm is used to\nexamine values of M (x) for x up to exp (1015 ).\n\n\f1\n\nIntroduction\n\nFor any positive integer x, \"Mobius function\" \u03bc(x) is defined as:\n* 0, if x is divisible by a square of any prime\n* 1, if the factorization of x contains an even number of distinct primes\n* -1, otherwise\nMertens function of a positive integer x is defined as the sum of values of the Mobius function\nfor 1 to x:\n\nM (n) =\n\nn\nX\n\n\u03bc(x)\n\nx=1\n\nThis function scales roughly as n1/2 over the interval where it's been studied. An old hypothesis,\n\"Mertens conjecture\" (Stieltjes, 1885) proposed that |M (n)| < n1/2 for all n. This was disproved\nby Odlyzko and te Riele (1985) [1], though no explicit counterexample is known.\nThe largest known value of |M (n)/n1/2 |, 0.570591 at n=7766842813, was found in [2]. Values\nof M(n) for all consecutive n up to 1014 were computed in [3]. No larger values were found.\nA computer algorithm to calculate isolated values of M(n) in O(n2/3+\u000f ) time was described in\n[4] and used to calculate several values up to 1016 .\nThe algorithm described next is, in a sense, a variation of the algorithm by [4]. The running\ntime is still O(n2/3+\u000f ). A distinctive feature of this algorithm is that executing it at any value of n\nallows to simultaneously compute all values of M (y) for integer y = bn/cc for all integer c > 1.\n\n2\n\nAlgorithm\n\nThe starting point for the algorithm is a standard identity:\nn\nX\n\nM (bn/xc) = 1, n > 1\n\nx=1\n\nOr, equivalently,\n\nM (n) = 1 \u2212\n\nn\nX\n\nM (bn/xc)\n\nx=2\n\n\u221a\nIt's been noted in [4] that the sequence bn/xc takes on only d2 ne distinct values. We can\nrewrite the right-hand side as follows\n\nM (n) = 1 \u2212\n\nn/t\nX\nx=2\n\nM (bn/xc) \u2212\n\nt\nX\nx=1\n\n1\n\n(b\n\nn\nn\nc\u2212b\nc)M (x)\nxt\n(x + 1)t\n\n\f\u221a\nwhere t > d ne.\nNow notice that the right hand side can be calculated recursively. In order to calculate M(n),\nwe need to know M(n/2), M(n/3), M(n/4), .... In turn, M(n/2) requires M(n/4), M(n/6), etc.\n\u221a\nSuppose that we pick a value of u > n and create an array of bn/uc elements, which would\nend up holding values of M (bn/xc) for 1 \u2264 x \u2264 bn/uc.\nWe then calculate all M (y) for 1 \u2264 y \u2264 u in order by direct sieving (this would take O(u1+\u000f\ntime). For each y, we update the array to account for contributions of M (y) according to the\nformula above. It's not hard to see that updating takes O((n/u1/2 )1+\u000f ) time. The overall time for\nthese two tasks is minimized at u = O(n2/3+\u000f ) and it also scales as O(n2/3+\u000f ).\nFinally, when we are done sieving, it is a simple task to compute final values of M, and it takes\nnegligible O(n/u ln n/u) \u2248 O(n1/3+\u000f ) time.\nFurthermore, it is easy to see that, if we want to compute M (x) for multiple close values\nof x, we only need to do sieving once. Adjusting u will result in optimal running time of u =\nO(n2/3+\u000f N 2/3+\u000f ), where N is the number of values x for which we're trying to calculate M (x).\nThe structure of the algorithm, with many large elements in the array that can be computed in\nparallel and more or less independently from each other, suggests that the algorithm may benefit\nfrom optimization for a general-purpose GPU (e.g. NVIDIA Fermi).\n\n3\n\nImplementation\n\nSince u is much larger than the amount of computer memory (for example, for x = 1022 , u \u2248 1014 ,\nbut modern desktop computers rarely have more than \u2248 1010 bytes of memory), it is necessary to\ndivide calculations into blocks of 'y' and to handle each block in order.\nFor each block, the first step is to compute consecutive values of M (y) throughout by sieving.\nDuplicate operations are avoided, and optimal performance is achieved if the block is greater\nthan u1/2 . The nature of this computation is such that it involves a large number of random\nmemory accesses across the entire block, and this is not a task that's particularly suitable for GPU\noptimization (among other reasons, the CPU has much larger L1 and L2 caches). Therefore, this\ntask is done on the CPU.\nA naive algorithm that performs sieving in a block [y1 ..y2 ] can be described as follows:\n1. Create an array A of integers with y2 \u2212 y1 + 1 elements, corresponding to y1 , y1 + 1, ..., y2 .\nSet these all to 1 initially.\n\u221a\n2. For every prime number p between 2 and d y2 e, multiply elements in the array corresponding\nto multiples of p by \u2212p.\n3. For every such prime, set all elements in the array corresponding to multiples of p2 to 0.\n4. Go through the array. For every element y, calculate the Mobius function \u03bc(y):\n- If A[y \u2212 y1 ] is 0, then \u03bc(y) is 0\n- Otherwise, if |A[y \u2212 y1 ]| is equal to y, then \u03bc(y) is equal to the sign of A[y \u2212 y1 ]\n- Otherwise, \u03bc(y) is equal to minus the sign of A[y \u2212 y1 ]\n2\n\n\f5. Add up all values of \u03bc(y) to calculate M (y).\n\u221a\nThe number of operations, according to the prime number theorem, is O((y2 \u2212 y1 ) ln ln y2 ).\nWhile there's not much that can be done about the overall growth rate (obviously, the task can't\nbe done faster than O(y2 \u2212 y1 ), and the log factor only plays a minor role, since, even for y2 =\n\u221a\n1020 , ln ln y2 ) \u2248 3.1), we can improve the constant factor. One significant improvement can be\nachieved by modifying the temporary array to store approximate logarithms of prime products\ninstead of exact values. This serves two purposes: it replaces each integer multiplication with an\ninteger addition (which is often substantially faster); and it reduces the memory throughput of the\nalgorithm by a factor of 8, because the array A in the range of values we're interested in has to\ncontain 64-bit values, but base-2 logarithms can be stored in 8-bit variables. This is the modified\nalgorithm:\n0. (Preparation, has to be done once) Create an array of log-primes: For each prime pi , the\ncorresponding log-prime li = blog2 pi c | 1 (here '|' is binary \"OR\".)\n1. Create an array A of 8-bit integers with y2 \u2212 y1 + 1 elements, corresponding to y1 , y1 + 1,\n..., y2 . Set these all to 0 initially.\n\u221a\n2. For every prime number p between 2 and d y2 e, add li to all elements in the array corresponding to multiples of p.\n3. For every such prime, set the most significant bit (by performing binary OR with 0x80) in\nall elements corresponding to multiples of p2 within the block.\n4. Go through the array. For every element y, calculate the Mobius function \u03bc(y):\n- If the most significant bit of A[y \u2212 y1 ] is set, then \u03bc(y) is 0 - Otherwise, if A[y \u2212 y1 ] is greater\nthan blog2 yc \u2212 1, then \u03bc(y) is equal to 1 \u2212 2(A[y \u2212 y1 ] & 1) (here \"&\" is binary \"AND\").\n- Otherwise, \u03bc(y) is equal \u22121 + 2(A[y \u2212 y1 ] & 1)\n5. Add up all values of \u03bc(y) to calculate M (y).\nIt can be proved that sieving according to the algorithm will result in correct results, as long\nas y2 is less than approximately 1027 .\nFurther, we can precompute results of sieving with the first several primes and square primes,\nstoring them in separate array, and copying this array instead of rerunning sieving. For example,\nthe state of the temporary array after sieving with the first 4 primes and the first 2 square primes\nis periodic with the period of 2*2*3*3*5*7*11 = 13860.\nFinally, the whole process can be modified to make use of multiple CPU cores, through the use\nof OpenMP.\nTo perform the array updating in the minimal amount of time, we have to divide the (x,y)\nspace into several distinct regions and process each region using a different procedure.\nIn regions 1 and 1' (defined as y < c1 \u2217 (n/x)1/2 for some c1 > 1), almost every (x,y) pair\nmakes a nonzero contribution to one of the elements of the array. Adequate performance can be\nachieved by creating one GPU thread to handle a region with dimensions (1,512) and to add up\ncontributions consecutively from every pair.\nAn important factor that slows down computations in these regions is the necessity to perform at\nleast one integer 64-bit division for every (x,y) pair. Integer division is an extremely slow operation\n3\n\n\fFigure 1: Regions of (x,y) space\n\n4\n\n\fthat is not supported natively by the GPU and can take as much as a hundred clock cycles. (It's\nalso quite slow on the CPU, but less so.) To improve performance, we can apply an algorithm such\nas [5], which accelerates integer division by replacing it with integer multiplication, addition, and\nshift. It requires that we precompute several constants for each value of the divisor, but, as long\nas each divisor is used multiple times, this results in net reduction of computation time. We can\nprecompute all constants in advance for divisors up to some constant C, where C is only limited\nby the amount of available memory. This will result in substantial speedup as long as C \u001d u1/2 .\nIn regions 2 and 2' (defined as c1 \u2217 (n/x)1/2 \u2264 y < c2 \u2217 (n/x)1/2 where c2 \u2248 10 \u2217 c1 ), there is a\nsubstantial number of (x,y) pairs which don't contribute anything, but the memory access pattern\nis relatively dense. Good performance is achieved when each GPU thread handles a region with\ndimensions (1,8192).\nIn the region 3, nonzero contributing pairs are sparse and processing time is limited by random\nmemory access bandwidth.\nIn the region 4 (defined as y > c3 \u2217 n1/2 , where c \u2248 2), accesses are so sparse that it's not even\njustified to transfer results of the sieving onto the GPU any more: time spent transferring data\nover the PCI-e bus is larger than time that would be spent processing the same data with the CPU.\nAt this point we no longer need the table of divisors used to speed up regions 1 and 2, so, if the\namount of memory is a bottleneck, we can free that memory and increase the sieving block size\nup to several times u1/2 (this is the only region where the ratio of block size to u1/2 significantly\ngreater than 1 is warranted).\n\n4\n\nApproximate algorithm\n\nA different algorithm that can be employed in this task is based on the following remarkable formula:\n\nM (x) \u2248 2 Re\n\n\u221e\nX\ni=1\n\nx\u03c1i\n\u03c1i \u03b6 0 (\u03c1i )\n\n(1)\nor in a simple yet practical reformulation,\n\nM (x)/x\n\n1/2\n\n\u2248 qn (x) = 2\n\nn\nX\n\nai cos (zi ln x + bi )\n\ni=1\n\n(2)\nwhere\nzi = im \u03c1i\nai = 1/|\u03c1i \u03b6 0 (\u03c1i )|\nbi = \u2212arg(\u03c1i \u03b6 0 (\u03c1i ))\n\n5\n\n\fand \u03c1i is the i'th zero of the Riemann zeta function. Somewhat more sophisticated reformulations, constructed by inserting a nontrivial kernel f (n) inside the sum, are mentioned in the\nliterature, but the formula above is particularly easy to calculate, and differences between different\nkernels for large n are minor.\nAlthough this formula is only approximate, it's usefulness here stems from the fact that we can\nget a good approximation - for example, two significant digits of M (x)/x1/2 - with just 1000 terms,\nregardless of the magnitude of x.\nCalculating qn is also a task that nicely affords to GPU optimization. In this case, the implementation is relatively straightforward. The only nuance that needs addressing involves the use\nof single-precision vs. double-precision floating point. Modern GPUs are generally faster when\noperating in single precision than in double precision. This is particularly true with regard to the\ncalculation of the cosine. All modern GPUs have native hardware support of basic single-precision\ntranscendental functions such as the cosine. GPUs in NVIDIA Fermi family, for example, have the\nthroughput of 4 or 8 single-precision cosines per clock cycle per multiprocessor: the NVIDIA GTX\n560 can, in theory, exceed 1011 cosines per second (compare with modern desktop CPU's, which\ncan only manage on the order of 108 cosines/second). On the other hand, double-precision cosines\nare not natively supported by NVIDIA or AMD and they can be a factor of 20 or so slower. But\nthe algorithm we have here can't be implemented completely in single precision, unless both n and\nx are small.\n\n5\n\nResults\n\nTo test the algorithm described in this article, a four-core Intel i5-2500 CPU running at 4.4 GHz\nwith 16 GB of memory and a NVIDIA GeForce GTX 560 video card (384 processing cores at 1.7\nGHz) with 1 GB of memory were used. Several choices of operating systems are available in this\nhardware configuration. Of these, x64 Linux (e.g. Ubuntu) is notable, because it comes with a\nC/C++ compiler (gcc/g++) that natively supports a 128-bit integer type. Since we're trying to\ncompute M(n) for n above the 64-bit limit (264 \u2248 1.9 \u2217 1019 ), native 128-bit support substantially\nsimplifies the code.\nAll the various constants and thresholds involved in this algorithm (such as dimensions handled\nby each GPU thread, or boundaries between regions 1/1' and 2/2') were tuned for peak performance. To verify correctness, many small values in 108 ..1012 range were computed and results\nwere compared with results obtained by naive O(n) time sieving. Values of Mertens function for\n1013 , 1014 , 1015 , and 1016 were compared against previously reported in the literature [4]. Calculating M (1016 ) takes 1 minute: a substantial improvement, compared to the previously reported 1996\nresult where calculation for the same n took two days. (It should be noted that only a small part\nof this improvement is due to an overall increase in clock frequencies: the 1996 analysis employed\na CPU running at 0.3 GHz, only one order of magnitude slower than hardware used here. Most of\nit is due to substantial parallelization and larger cache sizes.)\nFor higher n, direct verification is problematic, but results can be compared with approximate\nvalues. In order to make use of the approximate algorithm, the list of the first 2,000,000 zeros of\nRiemann zeta was downloaded from [6]. Zeros were then refined to 30 digits and corresponding\nvalues of \u03b6 0 (\u03c1i ) were computed using Mathematica. To ensure correctness, these values for the first\n6\n\n\f200,000 zeros were independently computed to 30 digits using the arbitrary-precision floating point\narithmetic library \"mpmath\" ver. 0.17 [7], and results were checked against each other to confirm\nthe lack of major discrepancies.\nApproximations of M(n) for many large values of n were calculated. These turned out to be in\nagreement with exact calculations: the residual error between the exact and the approximate values\nof M (n)/n1/2 for n > 108 was approximately normally distributed with the standard deviation of\n\u2248 4.2 \u2217 10\u22124 .\nFinally, the code was used to compute values of M(n) for powers of 10 from 1017 to 1022 . As\nexpected, execution time scaled roughly as n2/3 . The computation for 1022 took 10 days. As\ndescribed in the beginning of the article, computing M (1022 ) simultaneously yields values of M (y)\nfor integer y = b1022 /cc for all integer c, including values such as 1019 and 1020 ; these agreed with\ntheir direct computations. Results are listed in table 1.\nTable 1. Values of M (n) for select values of n.\nn\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n\n6\n\nM (n)/n1/2\n-0.032\n-0.069\n-0.047\n0.285\n0.046\n0.107\n-0.021\n\nM (n)\n\u22123195437\n\u221221830254\n\u221246758740\n899990187\n461113106\n3395895277\n\u22122061910120\n\ntime\n1m\n4.5 m\n20.7 m\n\n10 d\n\nNew extreme value\n\nAs mentioned above, the largest value of |M (n)/n1/2 | reported in the literature so far is 0.570591\n10\nat n=7766842813. [3] analyzed approximate values for n up to 1010 using the Riemann zeta\nalgorithm and noticed several larger potential extremes, including one potentially within reach at\nthe present level of technology. Table 4 in that article notes that the q106 approximation (based on\nthe first 106 zeros) reaches the value of -0.585 at n \u2248 1.16 \u2217 1019 , indicating a new extreme in the\nneighborhood.\nTo localize the extremum, a grid of values of M(n) in the neighborhood was systematically\ncalculated. The density of the grid was increased till it became practical to cover intervals between\nthe points of the grid with direct sieving (for example, if values of M(n) at 1.160986 \u2217 1019 and\n1.160987\u22171019 are known exactly, all values in the interval can be calculated, and the local extremum\nin this interval located, in a matter of hours). A plot with all computed points is shown in figure\n2.\nThe largest value of |M (n)/n1/2 | found by this method turns out to be 0.585767684 (M(n)=1,995,900,927) at n = 11, 609, 864, 264, 058, 592, 345.\nGiven the approach and the density of the grid, it is not possible to state with absolute certainty\nthat the value is largest for, say, n < 1020 , or even in the neighborhood of 1.16 \u2217 1019 . However, a\nheuristic argument can be made for negligible probability of finding a larger value below 1040 .\n7\n\n\fFigure 2: Values of M(x) for x between 1016 and 1022\nStart by observing that a larger extreme value requires having a large value of |p106 |. Below\nthe function |p106 | only exceeds 0.575 inside the interval from 1.1600 \u2217 1019 to 1.1612 \u2217 1019\n(the next such occurrence is in the vicinity of 2.26 \u2217 1042 ). Since, as noted above, the residual\nerror M (n)/n1/2 \u2212 q106 (n) is approximately normally distributed with the standard deviation of\n\u2248 5.7 \u2217 10\u22124 , and the difference between 0.585767 and 0.575 comes out to 19 standard deviations,\nthe probability for |M (n)/n1/2 | at any randomly-picked value of n to exceed 0.585767 conditional\non q106 (n) being less than 0.575 is vanishingly small (less than 10\u221278 ) and therefore the probability\nfor this to happen at any n below 1040 is still vanishingly small. (This, however, is subject to a\ncaveat, which is mentioned in the next section.) So it remains to explore the interval of 1.1600\u22171019\nto 1.1612 \u2217 1019 .\n1040 ,\n\nSuppose that we know values of M (n) for n = a and n = b. What can be said about the\nprobability for M(n) to exceed a certan M0 in the interval between a and b, assuming that b > a,\nM0 > M (a), and M0 > M (b) (or, conversely, to go below M0 if M0 < M (a) and M0 < M (b))?\nLocally, M (n) can be thought of as essentially a random walk, which moves either up or down with\nthe probability of \u03c3/2 or sideways with the probability of 1 \u2212 \u03c3 (where \u03c3 = 6/\u03c0 2 is the share of\nsquarefree numbers among all integers). The probability P (M (n) > M0 ) for such a random walk\ncan be shown to be equal to\nP (M (n) > M0 ) = exp (\u2212(M (a) \u2212 M0 )(M (b) \u2212 M0 )/(2\u03c3(b \u2212 a))\nto the first order in b \u2212 a (which is sufficient for our needs).\n\n8\n\n\fOf course, M (n) is not a true random walk. It's not hard to see that a true random walk as\ndescribed above would have values of M (n)/n1/2 normally distributed with the standard deviation\n6/\u03c0 2 \u2248 0.608. In reality, the standard deviation of M (n)/n1/2 among computed values is only 0.11,\nsuggesting that its dynamics involves a degree of regression towards the mean, and the probability\nestimate we have may be too high.\nNevertheless, using this this estimate and applying to all intervals shown in figure 2 yields\nthat the total probability to find a larger extreme for |M (n)/n1/2 | in the neighborhood (and,\nconsequently, below 1040 ) is less than 0.05.\n\n7\n\nSearch for the first counterexample\n\nAs the discussion above shows, it is highly improbable to find a counterexample to Mertens conjecture in the range where computation by the exact algorithm is tractable. Locating the first\ncounterexample, therefore, is best approached using the approximate algorithm.\nStrictly speaking, the approximation (2) is only valid for all x in the assumption that the\n1\ns \u22120.5\n\nRiemann hypothesis is valid. If it fails, |M (x)| can be expected to exceed |x| for x \u2248 mini ti i\n,\nwhere \u03c1i = si + iti are nontrivial roots of Riemann zeta. Current limits on \u03c1i make it unlikely to\nsee a counterexample below 1026 or so.\nOn the other hand, if the Riemann hypothesis holds, simple investigation of (2) leads to the\nconclusion that the conjecture is unlikely to be violated over a much wider range of values. A\ngeneral sum of the form (2) can be treated as a sum of a large number of random variables.\nAccording to the central limit theorem, such a sum should be expected approximately normally\ndistributed. A sum of the first 106 terms (q106 ) would be normally distributed with standard\n\u221a P 6 2\ndeviation of 2 10\nn=1 ai \u2248 0.17. In practice, the presence of several large non-normal terms in the\nsum means that the actual tail distribution of values of (q106 ) is even narrower.\nThe rest of this section assumes that the Riemann hypothesis holds.\nThe most straightforward algorithm that can be applied here is described in [3]. It involves\ncomputing values of pn over a grid of values for some small value of n, recording values where |qn |\nexceeds a certain predefined threshold, and then studying areas where this happens in more detail.\nUnfortunately, this kind of brute-force search is too slow to yield the counterexample. Numerical\nevaluation of the probability distribution function (PDF) of (2) indicates that the search might\nneed to be extended as high as exp (1018 ). Covering this region does not seem feasible at the\npresent level of desktop PC technology: it would take an optimized software program and a typical\nhigh-end desktop PC hundreds of computer-years to reach 1018 . It follows that a more intelligent\nalgorithm needs to be used.\nOne useful observation that can be made is that the range of values that need to be checked\ncan be constrained significantly just by examining the first several terms of (2). For example, the\nanalysis of the PDF of (2) and its subsequences shows that any counterexample is unlikely to have\n|q7 (x)| < 0.425, which is true for fewer than 1 in 10,000 values.\nIn addition, all subsequences of (2) are quasiperiodic. This is not particularly useful for long\nsubsequences, but for short sequences, such as q4 and q7 \u2212 q4 , we can find n < 109 such that these\nfunctions are \"almost\" periodic with periods 2\u03c0n/z1 . For example,\n9\n\n\f(z2 /z1 ) \u2217 274243136 = 407871396.0012\n(z3 /z1 ) \u2217 274243136 = 485262780.0010\n(z4 /z1 ) \u2217 274243136 = 590306027.0009\n(z5 /z1 ) \u2217 242101728 = 564116758.0001\n(z6 /z1 ) \u2217 242101728 = 643781791.9996\n(z7 /z1 ) \u2217 242101728 = 700862060.0012\nwhich means that q4 is approximately periodic with the period 274243136(2\u03c0/z1 ) and q7 \u2212 q4\nis approximately periodic with the period 242101728(2\u03c0/z1 ). We can accelerate the algorithm\nby computing values of q4 and q7 \u2212 q4 over one such period and then reusing them for multiple\nconsecutive periods. Furthermore, we don't need to save actual values: it is much faster to compare\neach value against a predefined threshold and only save boolean flags which indicate whether the\nthreshold is exceeded. This method ensures compact packing of the results (8 flags per byte) and\nminimizes memory troughput.\nUnfortunately, these algorithmic improvements are still insufficient to ensure locating a counterexample, but they allow us to extend coverage by two orders of magnitude.\nTo work with x \u001d exp (1010 ), it is necessary to control for the loss of precision at high x. For\nexample, computing p10,000 (exp (1011 )) involves computing a cosine of z10,000 \u2217 1011 + b10,000 \u2248 1015 .\nSince these computations are done by the GPU, whose internal representation of double-precision\nfloating point values has the machine precision 2\u221253 \u2248 1.1 \u2217 10\u221216 , the computed value of the cosine\ncould have be off by as much as 0.1. For much larger x or n, values of cosines could be essentially\nmeaningless. To address this, a reference table of constants ai , bi and zi to 30 significant digits was\nkept; for actual calculations, the range of study was divided into blocks of length \u2248 2 \u2217 1011 , and\na new, 'shifted' table was generated for the every block using high-precision software according to\nthe formula\nb0i = (bi + zi \u2217 x0 )mod2\u03c0\nThe search was extended to exp (1015 ). Results up to exp (1013 ) were double-checked using\nbrute-force search, and further verified using the 'mpmath' arbitrary-precision computing package.\nThe search up to exp (1015 ) took approximately 7 days using the hardware mentioned in section 5.\nIn line with expectations, no counterexamples were found. The largest value of |q106 (x)| observed\nwas 0.9565 for x \u2248 exp (5.0586 \u2217 1014 ).\nSome \"increasingly large positive/negative values\" (using the terminology of [3]) are listed in\ntables 2 and 3.\nTable 2. Increasingly large positive values.\n\n10\n\n\fln n\n22.773133\n97.526523\n984.282019\n1625.698493\n1957.803133\n2709.485814\n2794.384965\n12277.362671\n86458087.131684\n249548703.533702\n1467573228.501077\n1901564582.121964\n2500922487.505913\n3847517705.646364\n10407545552.85608\n21334043144.02927\n187114096628.77484\n1354137181464.62097\n6984497047106.74600\n84594507546024.46719\n117239588213313.90075\n\nq106 (n)\n+0.56959\n+0.61863\n+0.62512\n+0.62687\n+0.62849\n+0.65467\n+0.65955\n+0.79344\n+0.80443\n+0.81472\n+0.81702\n+0.82335\n+0.82884\n+0.83682\n+0.842485\n+0.86622\n+0.88636\n+0.90578\n+0.90744\n+0.92208\n+0.94102\n\nTable 3. Increasingly large negative values.\n\n11\n\n\fln n\n43.898387\n140.373835\n853.851589\n3005.762748\n102494.024866\n150020.464414\n178259.151801\n203205.659988\n860440.495719\n1365643.292004\n2765781.628095\n7078384.260482\n13670267.747472\n19371574.223934\n57334128.09084\n167211796.14902\n405441986.398094\n4016980126.87193\n86339883457.03526\n264421251554.46918\n1278282683343.76520\n3680547202477.03623\n18747209824980.73961\n55714219637174.49540\n117892199597999.02070\n143697547951999.01914\n258592103887306.71643\n505863698785929.24318\n\nq106 (n)\n\u22120.58478\n\u22120.58940\n\u22120.67715\n\u22120.68878\n\u22120.69580\n\u22120.70773\n\u22120.71541\n\u22120.74083\n\u22120.75254\n\u22120.75927\n\u22120.76041\n\u22120.76879\n\u22120.78505\n\u22120.78747\n\u22120.80765\n\u22120.82488\n\u22120.84497\n\u22120.85146\n\u22120.87296\n\u22120.89290\n\u22120.89907\n\u22120.91392\n\u22120.91405\n\u22120.92025\n\u22120.92078\n\u22120.93038\n\u22120.94097\n\u22120.95652\n\nThe distribution of values found here is in general agreement with expectations. Even though\nsome authors (e.g. [1]) observed tentative evidence for sign asymmetry (namely, that large positive\nvalues seemed to occur more often than large negative values), that does not appear to be the case\nhere - the distribution found in this study is largely symmetric (see table 4.)\nAlthough no counterexamples were found in the area of study, further improvements to the\nalgorithm and the computer hardware may bring this task within reach.\nTable 4. Tail ends of the frequency distribution of |p7000 (x)| for ln x < 1015 , sampled with the\nstep \u03c0/3072z1 \u2248 7.24 \u2217 10\u22125 .\n\n12\n\n\fFigure 3: Increasingly large positive and negative values of q(x)\n\n13\n\n\f|p7000 (x)|\n0.88..0.89\n0.89..0.90\n0.90..0.91\n0.91..0.92\n0.92..0.93\n0.93..0.94\n0.94..0.95\n\npositive values\n4499\n1472\n346\n91\n22\n0\n0\n\nnegative values\n4399\n1518\n444\n112\n42\n6\n6\n\nReferences\n[1] A.M. Odlyzko and H.J.J. te Riele, \"Disproof of the Mertens Conjecture,\"\nJ. reine angew. Math (1985)\n[2] H. Cohen, \"Arithmetique et informatique,\"\nAsterisque, 61 (1979), 57-61\n[3] Tadej Kotnik and Jan van de Lune, \"On the Order of the Mertens Function,\"\nExperimental Mathematics, 2004\n[4] Delglise and Rivat (1996), \"Computing the Summation of the Mobius Function,\"\nExp. Math. 5 (1996), 291295\n[5] Torbjrn Granlund , Peter L. Montgomery (1994), \"Division by Invariant Integers using Multiplication,\"\nProceedings of the SIGPLAN '94 Conference on Programming Language Design and Implementation\n[6] http://www.dtc.umn.edu/~odlyzko/zeta_tables/index.html\n[7] 'mpmath' Python library for arbitrary-precision floating-point arithmetic, http://code.\ngoogle.com/p/mpmath/\nEugene Kuznetsov (nameless@fastmail.fm)\n\n14\n\n\f"}