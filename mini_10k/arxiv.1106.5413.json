{"id": "http://arxiv.org/abs/1106.5413v1", "guidislink": true, "updated": "2011-06-27T15:09:00Z", "updated_parsed": [2011, 6, 27, 15, 9, 0, 0, 178, 0], "published": "2011-06-27T15:09:00Z", "published_parsed": [2011, 6, 27, 15, 9, 0, 0, 178, 0], "title": "Accelerated Linearized Bregman Method", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1106.5154%2C1106.3107%2C1106.5815%2C1106.3421%2C1106.2202%2C1106.5065%2C1106.1665%2C1106.5569%2C1106.3352%2C1106.2772%2C1106.4019%2C1106.2969%2C1106.2273%2C1106.1126%2C1106.4391%2C1106.2896%2C1106.4419%2C1106.5413%2C1106.0968%2C1106.6337%2C1106.0200%2C1106.4731%2C1106.2132%2C1106.3122%2C1106.4575%2C1106.2211%2C1106.1168%2C1106.6043%2C1106.5056%2C1106.1688%2C1106.1330%2C1106.3060%2C1106.2693%2C1106.3447%2C1106.5864%2C1106.4049%2C1106.1036%2C1106.5526%2C1106.5253%2C1106.4746%2C1106.0090%2C1106.0906%2C1106.2558%2C1106.5524%2C1106.3358%2C1106.6236%2C1106.2721%2C1106.4389%2C1106.4986%2C1106.3100%2C1106.1365%2C1106.3280%2C1106.0694%2C1106.2073%2C1106.5127%2C1106.1348%2C1106.0115%2C1106.0603%2C1106.5715%2C1106.0547%2C1106.2958%2C1106.5692%2C1106.2376%2C1106.3672%2C1106.3986%2C1106.1672%2C1106.4799%2C1106.0659%2C1106.0757%2C1106.0684%2C1106.4497%2C1106.4483%2C1106.3293%2C1106.1587%2C1106.0597%2C1106.1599%2C1106.3656%2C1106.0988%2C1106.5993%2C1106.6207%2C1106.4942%2C1106.1113%2C1106.5859%2C1106.1720%2C1106.5437%2C1106.2777%2C1106.4357%2C1106.2999%2C1106.4558%2C1106.2557%2C1106.4431%2C1106.5074%2C1106.1938%2C1106.1820%2C1106.5272%2C1106.2408%2C1106.1724%2C1106.0620%2C1106.4434%2C1106.2354%2C1106.2207&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Accelerated Linearized Bregman Method"}, "summary": "In this paper, we propose and analyze an accelerated linearized Bregman (ALB)\nmethod for solving the basis pursuit and related sparse optimization problems.\nThis accelerated algorithm is based on the fact that the linearized Bregman\n(LB) algorithm is equivalent to a gradient descent method applied to a certain\ndual formulation. We show that the LB method requires $O(1/\\epsilon)$\niterations to obtain an $\\epsilon$-optimal solution and the ALB algorithm\nreduces this iteration complexity to $O(1/\\sqrt{\\epsilon})$ while requiring\nalmost the same computational effort on each iteration. Numerical results on\ncompressed sensing and matrix completion problems are presented that\ndemonstrate that the ALB method can be significantly faster than the LB method.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1106.5154%2C1106.3107%2C1106.5815%2C1106.3421%2C1106.2202%2C1106.5065%2C1106.1665%2C1106.5569%2C1106.3352%2C1106.2772%2C1106.4019%2C1106.2969%2C1106.2273%2C1106.1126%2C1106.4391%2C1106.2896%2C1106.4419%2C1106.5413%2C1106.0968%2C1106.6337%2C1106.0200%2C1106.4731%2C1106.2132%2C1106.3122%2C1106.4575%2C1106.2211%2C1106.1168%2C1106.6043%2C1106.5056%2C1106.1688%2C1106.1330%2C1106.3060%2C1106.2693%2C1106.3447%2C1106.5864%2C1106.4049%2C1106.1036%2C1106.5526%2C1106.5253%2C1106.4746%2C1106.0090%2C1106.0906%2C1106.2558%2C1106.5524%2C1106.3358%2C1106.6236%2C1106.2721%2C1106.4389%2C1106.4986%2C1106.3100%2C1106.1365%2C1106.3280%2C1106.0694%2C1106.2073%2C1106.5127%2C1106.1348%2C1106.0115%2C1106.0603%2C1106.5715%2C1106.0547%2C1106.2958%2C1106.5692%2C1106.2376%2C1106.3672%2C1106.3986%2C1106.1672%2C1106.4799%2C1106.0659%2C1106.0757%2C1106.0684%2C1106.4497%2C1106.4483%2C1106.3293%2C1106.1587%2C1106.0597%2C1106.1599%2C1106.3656%2C1106.0988%2C1106.5993%2C1106.6207%2C1106.4942%2C1106.1113%2C1106.5859%2C1106.1720%2C1106.5437%2C1106.2777%2C1106.4357%2C1106.2999%2C1106.4558%2C1106.2557%2C1106.4431%2C1106.5074%2C1106.1938%2C1106.1820%2C1106.5272%2C1106.2408%2C1106.1724%2C1106.0620%2C1106.4434%2C1106.2354%2C1106.2207&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper, we propose and analyze an accelerated linearized Bregman (ALB)\nmethod for solving the basis pursuit and related sparse optimization problems.\nThis accelerated algorithm is based on the fact that the linearized Bregman\n(LB) algorithm is equivalent to a gradient descent method applied to a certain\ndual formulation. We show that the LB method requires $O(1/\\epsilon)$\niterations to obtain an $\\epsilon$-optimal solution and the ALB algorithm\nreduces this iteration complexity to $O(1/\\sqrt{\\epsilon})$ while requiring\nalmost the same computational effort on each iteration. Numerical results on\ncompressed sensing and matrix completion problems are presented that\ndemonstrate that the ALB method can be significantly faster than the LB method."}, "authors": ["Bo Huang", "Shiqian Ma", "Donald Goldfarb"], "author_detail": {"name": "Donald Goldfarb"}, "author": "Donald Goldfarb", "links": [{"href": "http://arxiv.org/abs/1106.5413v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1106.5413v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1106.5413v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1106.5413v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "ACCELERATED LINEARIZED BREGMAN METHOD\nBO HUANG\u2020 , SHIQIAN MA\u2217\u2020 , AND DONALD GOLDFARB\u2020\n\narXiv:1106.5413v1 [math.OC] 27 Jun 2011\n\nJune 21, 2011\nAbstract. In this paper, we propose and analyze an accelerated linearized Bregman (ALB) method for solving the basis\npursuit and related sparse optimization problems. This accelerated algorithm is based on the fact that the linearized Bregman\n(LB) algorithm is equivalent to a gradient descent method applied to a certain dual formulation. We show that the LB method\n\u221a\nrequires O(1/\u01eb) iterations to obtain an \u01eb-optimal solution and the ALB algorithm reduces this iteration complexity to O(1/ \u01eb)\nwhile requiring almost the same computational effort on each iteration. Numerical results on compressed sensing and matrix\ncompletion problems are presented that demonstrate that the ALB method can be significantly faster than the LB method.\nKey words. Convex Optimization, Linearized Bregman Method, Accelerated Linearized Bregman Method, Compressed\nSensing, Basis Pursuit, Matrix Completion\nAMS subject classifications. 68U10, 65K10, 90C25\n\n1. Introduction. In this paper, we are interested in the following optimization problem\n(1.1)\n\nmin J(x)\n\nx\u2208Rn\n\ns.t. Ax = b,\n\nwhere A \u2208 Rm\u00d7n , b \u2208 Rm and J(x) is a continuous convex function. An important instance of (1.1) is the\nPn\nso-called basis pursuit problem when J(x) := kxk1 = j=1 |xj |:\n(1.2)\n\nmin kxk1\n\nx\u2208Rn\n\ns.t. Ax = b.\n\nSince the development of the new paradigm of compressed sensing [9, 11], the basis pursuit problem (1.2)\nhas become a topic of great interest. In compressed sensing, A is usually the product of a sensing matrix \u03a6\nand a transform basis matrix \u03a8 and b is a vector of the measurements of the signal s = \u03a8x. The theory of\ncompressed sensing guarantees that the sparsest solution (i.e., representation of the signal s = \u03a8x in terms\nof the basis \u03a8) of Ax = b can be obtained by solving (1.2) under certain conditions on the matrix \u03a6 and the\nsparsity of x. This means that (1.2) gives the optimal solution of the following NP-hard problem [21]:\n(1.3)\n\nmin kxk0\n\nx\u2208Rn\n\ns.t. Ax = b,\n\nwhere kxk0 counts the number of nonzero elements of x.\nMatrix generalizations of (1.3) and (1.2), respectively, are the so-called matrix rank minimization problem\n(1.4)\n\nmin\n\nX\u2208Rm\u00d7n\n\nrank(X)\n\ns.t. A(X) = d,\n\n\u2217 Corresponding\n\nauthor.\nof Industrial Engineering and Operations Research, Columbia University, New York, NY 10027. Email:\n{bh2359,sm2756,goldfarb}@columbia.edu. Research supported in part by NSF Grants DMS 06-06712 and DMS 10-16571, ONR\nGrants N00014-03-0514 and N00014-08-1-1118, and DOE Grants DE-FG01-92ER-25126 and DE-FG02-08ER-25856.\n\u2020 Department\n\n1\n\n\fand its convex relaxation, the nuclear norm minimization problem:\nmin\n\n(1.5)\n\nX\u2208Rm\u00d7n\n\nkXk\u2217\n\ns.t. A(X) = d,\n\nwhere A : Rm\u00d7n \u2192 Rp is a linear operator, d \u2208 Rp , and kXk\u2217 (the nuclear norm of X) is defined as the sum\nof singular values of matrix X. A special case of (1.4) is the matrix completion problem:\n\n(1.6)\n\nmin\n\nX\u2208Rm\u00d7n\n\nrank(X)\n\ns.t.\n\nXij = Mij , \u2200(i, j) \u2208 \u03a9,\n\nwhose convex relaxation is given by:\n(1.7)\n\nmin\n\nX\u2208Rm\u00d7n\n\nkXk\u2217\n\ns.t. Xij = Mij , \u2200(i, j) \u2208 \u03a9.\n\nThe matrix completion problem has a lot of interesting applications in online recommendation systems,\ncollaborative filtering [35, 36], etc., including the famous Netflix problem [34]. It has been proved that under\ncertain conditions, the solutions of the NP-hard problems (1.4) and (1.6) are given respectively by solving\ntheir convex relaxations (1.5) and (1.7), with high probability (see, e.g., [31, 8, 10, 30, 15]).\nThe linearized Bregman (LB) method was proposed in [42] to solve the basis pursuit problem (1.2). The\nmethod was derived by linearizing the quadratic penalty term in the augmented Lagrangian function that is\nminimized on each iteration of the so-called Bregman method introduced in [27] while adding a prox term\nto it. The linearized Bregman method was further analyzed in [5, 7, 41] and applied to solve the matrix\ncompletion problem (1.7) in [5].\nThroughout of this paper, we will sometimes focus our analysis on the basis pursuit problem (1.2).\nHowever, all of the analysis and results can be easily extended to (1.5) and (1.7). The linearized Bregman\nmethod depends on a single parameter \u03bc > 0 and, as the analysis in [5, 7] shows, actually solves the problem\n(1.8)\n\nminn g\u03bc (x) := kxk1 +\n\nx\u2208R\n\n1\nkxk22 ,\n2\u03bc\n\ns.t. Ax = b,\n\nrather than the problem (1.2). Recently it was shown in [41] that the solution to (1.8) is also a solution\nto problem (1.2) as long as \u03bc is chosen large enough. Furthermore, it was shown in [41] that the linearized\nBregman method can be viewed as a gradient descent method applied to the Lagrangian dual of problem\n(1.8). This dual problem is an unconstrained optimization problem of the form\n(1.9)\n\nmin\n\nG\u03bc (y),\n\ny\u2208Rm\n\nwhere the objective function G\u03bc (y) is differentiable since g\u03bc (x) is strictly convex (see, e.g., [32]). Motivated\nby this result, some techniques for speeding up the classical gradient descent method applied to this dual\nproblem such as taking Barzilai-Borwein (BB) steps [1], and incorporating it into a limited memory BFGS\n(L-BFGS) method [18], were proposed in [41]. Numerical results on the basis pursuit problem (1.2) reported\nin [41] show that the performance of the linearized Bregman method can be greatly improved by using these\ntechniques.\nOur starting point is also motivated by the equivalence between applying the linearized Bregman method\nto (1.2) and solving the Lagrangian dual problem (1.9) by the gradient descent method. Since the gradient of\nG\u03bc (y) can be shown to be Lipschitz continuous, it is well-known that the classical gradient descent method\n2\n\n\fwith a properly chosen step size will obtain an \u01eb-optimal solution to (1.9) (i.e., an approximate solution y k\nsuch that G\u03bc (y k ) \u2212 G\u03bc (y \u2217 ) \u2264 \u01eb) in O(1/\u01eb) iterations. In [23], Nesterov proposed a technique for accelerating\nthe gradient descent method for solving problem of the form (1.9) (see, also, [24]), and proved that using this\n\u221a\naccelerated method, the number of iterations needed to obtain an \u01eb-optimal solution is reduced to O(1/ \u01eb)\n\u221a\nwith a negligible change in the work required at each iteration. Nesterov also proved that the O(1/ \u01eb)\ncomplexity bound is the best bound that one can get if one uses only the first-order information. Based on\nthe above discussion, we propose an accelerated linearized Bregman (ALB) method for solving (1.8) which\nis equivalent to an accelerated gradient descent method for solving the Lagrangian dual (1.9) of (1.8). As\na by-product, we show that the basic and the accelerated linearized Bregman methods require O(1/\u01eb) and\n\u221a\nO(1/ \u01eb) iterations, respectively, to obtain an \u01eb-optimal solution with respect to the Lagrangian for (1.8).\nThe rest of this paper is organized as follows. In Section 2 we describe the original Bregman iterative\nmethod, as well as the linearized Bregman method. We motivate the methods and state some previously\nobtained theoretical results that establish the equivalence between the LB method and a gradient descent\nmethod for the dual of problem (1.8). We present our accelerated linearized Bregman method in Section 3.\nWe also provide a theoretical foundation for the accelerated algorithm and prove complexity results for it\nand the unaccelerated method. In Section 4, we describe how the LB and ALB methods can be extended\nto basis pursuit problems that include additional convex constraints. In Section 5, we report preliminary\nnumerical results, on several compressed sensing basis pursuit and matrix completion problems. These\nnumerical results show that our accelerated linearized Bregman method significantly outperforms the basic\nlinearized Bregman method. We make some conclusions in Section 6.\n\n2. Bregman and Linearized Bregman Methods. The Bregman method was introduced to the\nimage processing community by Osher et al. in [27] for solving the total-variation (TV) based image\nrestoration problems. The Bregman distance [4] with respect to convex function J(*) between points u and\nv is defined as\n(2.1)\n\nDJp (u, v) := J(u) \u2212 J(v) \u2212 hp, u \u2212 vi,\n\nwhere p \u2208 \u2202J(v), the subdifferential of J at v. The Bregman method for solving (1.1) is given below as\nAlgorithm 1. Note that the updating formula for pk (Step 4 in Algorithm 1) is based on the optimality\nconditions of Step 3 in Algorithm 1:\n0 \u2208 \u2202J(xk+1 ) \u2212 pk + A\u22a4 (Axk+1 \u2212 b).\nThis leads to\npk+1 = pk \u2212 A\u22a4 (Axk+1 \u2212 b).\nIt was shown in [27, 42] that the Bregman method (Algorithm 1) converges to a solution of (1.1) in a finite\nnumber of steps.\nIt is worth noting that for solving (1.1), the Bregman method is equivalent to the augmented Lagrangian\nmethod [17, 29, 33] in the following sense.\nTheorem 2.1. The sequences {xk } generated by Algorithm 1 and by the augmented Lagrangian method,\n3\n\n\fAlgorithm 1 Original Bregman Iterative Method\n1: Input: x0 = p0 = 0.\n2: for k = 0, 1, * * * do\nk\n3:\nxk+1 = arg minx DJp (x, xk ) + 12 kAx \u2212 bk2 ;\n4:\npk+1 = pk \u2212 A\u22a4 (Axk+1 \u2212 b);\n5: end for\nwhich computes for k = 0, 1, * * *\n(2.2)\n\n(\n\nxk+1\nk+1\n\n\u03bb\n\n:= arg minx J(x) \u2212 h\u03bbk , Ax \u2212 bi + 21 kAx \u2212 bk2\n:= \u03bbk \u2212 (Axk+1 \u2212 b)\n\nstarting from \u03bb0 = 0 are exactly the same.\nPk\nProof. From Step 4 of Algorithm 1 and the fact that p0 = 0, it follows that pk = \u2212 j=1 A\u22a4 (Axj \u2212 b).\nPk\nFrom the second equation in (2.2) and using \u03bb0 = 0, we get \u03bbk = \u2212 j=1 (Axj \u2212 b). Thus, pk = A\u22a4 \u03bbk for\n\nall k. Hence it is easy to see that Step 3 of Algorithm 1 is exactly the same as the first equation in (2.2)\nand that the xk+1 computed in Algorithm 1 and (2.2) are exactly the same. Therefore, the sequences {xk }\ngenerated by both algorithms are exactly the same.\nNote that for J(x) := \u03b1kxk1 , Step 3 of Algorithm 1 reduces to an l1 -regularized problem:\n\n(2.3)\n\nmin\nx\n\n1\n\u03b1kxk1 \u2212 hpk , xi + kAx \u2212 bk2 .\n2\n\nAlthough there are many algorithms for solving the subproblem (2.3) such as FPC [16], SPGL1 [39], FISTA\n[2] etc., it often takes them many iterations to do so. The linearized Bregman method was proposed in [42],\nand used in [28, 7, 6] to overcome this difficulty. The linearized Bregman method replaces the quadratic\nterm 21 kAx \u2212 bk2 in the objective function that is minimized in Step 3 of Algorithm 1 by its linearization\n1\nkx \u2212 xk k2 . Consequently the updating formula for pk is changed\nhA\u22a4 (Axk \u2212 b), xi plus a proximal term 2\u03bc\n\nsince the optimality conditions for this minimization step become:\n0 \u2208 \u2202J(xk+1 ) \u2212 pk + A\u22a4 (Axk \u2212 b) +\n\n1 k+1\n(x\n\u2212 xk ).\n\u03bc\n\nIn Algorithm 2 below we present a slightly generalized version of the original linearized Bregman method\nthat includes an additional parameter \u03c4 that corresponds to the length of a gradient step in a dual problem.\nAlgorithm 2 Linearized Bregman Method\n1: Input: x0 = p0 = 0, \u03bc > 0 and \u03c4 > 0.\n2: for k = 0, 1, * * * do\nk\n3:\nxk+1 = arg minx DJp (x, xk ) + \u03c4 hA\u22a4 (Axk \u2212 b), xi +\n4:\npk+1 = pk \u2212 \u03c4 A\u22a4 (Axk \u2212 b) \u2212 \u03bc1 (xk+1 \u2212 xk );\n5: end for\n\n1\n2\u03bc kx\n\n\u2212 xk k2 ;\n\nIn [41], it is shown that when \u03bckAk2 < 2, where kAk denotes the largest singular value of A, the\niterates of the linearized Bregman method (Algorithm 2 with \u03c4 = 1) converge to the solution of the following\nregularized version of problem (1.1):\n(2.4)\n\nmin\nx\n\nJ(x) +\n\n1\nkxk2\n2\u03bc\n4\n\ns.t. Ax = b.\n\n\fWe prove in Theorem 2.3 below an analogous result for Algorithm 2 for a range of values of \u03c4 . However, we\nfirst prove, as in [41], that the linearized Bregman method (Algorithm 2) is equivalent to a gradient descent\nmethod\ny k+1 := y k \u2212 \u03c4 \u2207G\u03bc (y k )\n\n(2.5)\napplied to the Lagrangian dual\n\nmax min{J(w) +\ny\n\nw\n\n1\nkwk2 \u2212 hy, Aw \u2212 bi}\n2\u03bc\n\nof (2.4), which we express as the following equivalent minimization problem:\n(2.6)\n\nmin\ny\n\nG\u03bc (y) := \u2212{J(w\u2217 ) +\n\n1\nkw\u2217 k2 \u2212 hy, Aw\u2217 \u2212 bi},\n2\u03bc\n\nwhere\nw\u2217 := arg min{J(w) +\nw\n\n1\nkwk2 \u2212 hy, Aw \u2212 bi}.\n2\u03bc\n\nTo show that G\u03bc (y) is continuously differentiable, we rewrite G\u03bc (y) as\nG\u03bc (y) = \u2212\u03a6\u03bc (\u03bcA\u22a4 y) +\n\n\u03bc \u22a4 2\nkA yk \u2212 b\u22a4 y,\n2\n\nwhere\n\u03a6\u03bc (v) \u2261 min{J(w) +\nw\n\n1\nkw \u2212 vk2 }\n2\u03bc\n\nis strictly convex and continuously differentiable with gradient \u2207\u03a6\u03bc (v) =\n1\n2\u03bc kw\n\nv\u2212\u0175\n\u03bc ,\n\nand \u0175 = arg minw {J(w) +\n\n\u2212 vk } (e.g., see Proposition 4.1 in [3]). From this it follows that \u2207G\u03bc (y) = Aw\u2217 \u2212 b. Hence the\ngradient method (2.5) corresponds to Algorithm 3 below.\n2\n\nAlgorithm 3 Linearized Bregman Method (Equivalent Form)\n1:\n2:\n3:\n4:\n5:\n\nInput: \u03bc > 0, \u03c4 > 0 and y 0 = \u03c4 b.\nfor k = 0, 1, * * * do\n1\nwk+1 := arg minw {J(w) + 2\u03bc\nkwk2 \u2212 hy k , Aw \u2212 bi};\nk+1\nk\nk+1\ny\n:= y \u2212 \u03c4 (Aw\n\u2212 b).;\nend for\nLemma 2.2 and Theorem 2.3 below generalize Theorem 2.1 in [41] by allowing a step length choice in\n\nthe gradient step (2.5) and show that Algorithms 2 and 3 are equivalent. Our proof closely follows the proof\nof Theorem 2.1 in [41].\nLemma 2.2. xk+1 computed by Algorithm 2 equals wk+1 computed by Algorithm 3 if and only if\n(2.7)\n\nA\u22a4 y k = pk \u2212 \u03c4 A\u22a4 (Axk \u2212 b) +\n\n1 k\nx .\n\u03bc\n\nProof. By comparing Step 3 in Algorithms 2 and 3, it is obvious that wk+1 is equal to xk+1 if and only\n5\n\n\fif (2.7) holds.\nTheorem 2.3. The sequences {xk } and {wk } generated by Algorithms 2 and 3 are the same.\n\nProof. We prove by induction that equation (2.7) holds for all k \u2265 0. Note that (2.7) holds for k = 0\n\nsince p0 = x0 = 0 and y 0 = \u03c4 b. Now let us assume that (2.7) holds for all 0 \u2264 k \u2264 n \u2212 1; thus by Lemma 2.2\nwk+1 = xk+1 for all 0 \u2264 k \u2264 n \u2212 1. By iterating Step 4 in Algorithm 3 we get\nn\n\n(2.8)\n\ny =y\n\nn\u22121\n\nn\n\n\u2212 \u03c4 (Aw \u2212 b) = \u2212\n\nn\nX\nj=0\n\n\u03c4 (Axj \u2212 b).\n\nBy iterating Step 4 in Algorithm 2 we get\npn = \u2212\n\nn\u22121\nX\nj=0\n\n\u03c4 A\u22a4 (Axj \u2212 b) \u2212\n\n1 n\nx ,\n\u03bc\n\nwhich implies that\nk\nX\n1 n\np \u2212 \u03c4 A (Ax \u2212 b) + x = \u2212\n\u03c4 A\u22a4 (Axj \u2212 b) = A\u22a4 y n ,\n\u03bc\nj=0\n\u22a4\n\nn\n\nn\n\nwhere the last equality follows from (2.8); thus by induction (2.7) holds for all k \u2265 0, which implies by\nLemma 2.2 that xk = wk for all k \u2265 0.\n\nBefore analyzing Algorithms 2 and 3, we note that by defining v k = A\u22a4 y k and algebraically manipulating\n\nthe last two terms in the objective function in Step 3 in Algorithm 3, Steps 3 and 4 in that algorithm can\nbe replaced by\n(2.9)\n\n(\n\n1\n2\u03bc kw\n\nwk+1\n\n:=\n\narg minw J(w) +\n\nv k+1\n\n:=\n\nv k \u2212 \u03c4 A\u22a4 (Awk+1 \u2212 b)\n\n\u2212 \u03bcv k k2\n\nif we set v 0 = \u03c4 A\u22a4 b. Because Algorithms 2 and 3 are equivalent, convergence results for the gradient descent\nmethod can be applied to both of them. Thus we have the following convergence result.\nTheorem 2.4. Let J(w) \u2261 kwk1 . Then G\u03bc (y) in the dual problem (2.6) is continuously differentiable\nand its gradient is Lipschitz continuous with the Lipschitz constant L \u2264 \u03bckAk2 . Consequently, if the step\n\n2\nk\nk\nlength \u03c4 < \u03bckAk\n2 , the sequences {x } and {w } generated by Algorithms 2 and 3 converge to the optimal\nsolution of (2.4).\n\nProof. When J(x) = kxk1 , wk+1 in (2.9) reduces to\nwk+1 = \u03bc * shrink(v k , 1),\nwhere the l1 shrinkage operator is defined as\n(2.10)\n\nshrink(z, \u03b1) := sgn(z) \u25e6 max{|z| \u2212 \u03b1, 0}, \u2200z \u2208 Rn , \u03b1 > 0.\n\nG\u03bc (y) is continuously differentiable since g\u03bc (x) is strictly convex. Since for any point y, \u2207G\u03bc (y) = Aw \u2212 b,\n\nwhere w = \u03bc * shrink(A\u22a4 y, 1), it follows from the fact that the shrinkage operator is non-expansive, i.e.,\nkshrink(s, \u03b1) \u2212 shrink(t, \u03b1)k \u2264 ks \u2212 tk, \u2200s, t, \u03b1\n6\n\n\fthat\nk\u2207G\u03bc (y 1 ) \u2212 \u2207G\u03bc (y 2 )k = k\u03bc * A * shrink(A\u22a4 y 1 , 1) \u2212 \u03bc * A * shrink(A\u22a4 y 2 , 1)k\n\u2264 \u03bc * kAk * kA\u22a4 (y 1 \u2212 y 2 )k\n\n\u2264 \u03bckAk2 ky 1 \u2212 y 2 k,\n\nfor any two points y 1 and y 2 . Thus the Lipschitz constant L of \u2207G\u03bc (*) is bounded above by \u03bckAk2 .\n2\nWhen \u03c4 < \u03bckAk\n2 , we have \u03c4 L < 2 and thus |1 \u2212 \u03c4 L| < 1. It then follows that the gradient descent\nmethod y k+1 = y k \u2212 \u03c4 \u2207G\u03bc (y k ) converges and therefore Algorithms 2 and 3 converge to x\u2217\u03bc , the optimal\nsolution of (2.4).\n\nBefore developing an accelerated version of the LB algorithm in the next section. We would like to\ncomment on the similarities and differences between the LB method and Nesterov's composite gradient\nmethod [26] and the ISTA method [2] applied to problem (1.1) and related problems. The latter algorithms\niterate Step 3 in the LB method (Algorithm 2) with pk = 0, and never compute or update the subgradient\nvector pk . More importantly, their methods solve the unconstrained problem\nmin\n\nx\u2208Rn\n\nkxk1 +\n\n1\nkAx \u2212 bk2 .\n2\u03bc\n\nHence, while these methods and the LB method both linearize the quadratic term kAx \u2212 bk2 while handling\n\nthe nonsmooth term kxk1 directly, they are very different.\nSimilar remarks apply to the accelerated LB method presented in the next section and fast versions of\nISTA and Nesterov's composite gradient method.\n3. The Accelerated Linearized Bregman Algorithm. Based on Theorem 2.3, i.e., the equivalence\nbetween the linearized Bregman method and the gradient descent method, we can accelerate the linearized\nBregman method by techniques used to accelerate the classical gradient descent method. In [41], Yin considered several techniques such as line search, BB step and L-BFGS, to accelerate the linearized Bregman\nmethod. Here we consider the acceleration technique proposed by Nesterov in [23, 24]. This technique accelerates the classical gradient descent method in the sense that it reduces the iteration complexity significantly\nwithout increasing the per-iteration computational effort. For the unconstrained minimization problem (1.9),\nNesterov's accelerated gradient method replaces the gradient descent method (2.5) by the following iterative\nscheme:\n(\nxk+1 := y k \u2212 \u03c4 \u2207G\u03bc (y k )\n(3.1)\ny k+1 := \u03b1k xk+1 + (1 \u2212 \u03b1k )xk ,\n3\nwhere the scalars \u03b1k are specially chosen weighting parameters. A typical choice for \u03b1k is \u03b1k = k+2\n. If \u03c4\nis chosen so that \u03c4 \u2264 1/L, where L is the Lipschitz constant for \u2207G\u03bc (*), Nesterov's accelerated gradient\n\u221a\nmethod (3.1) obtains an \u01eb-optimal solution of (1.9) in O(1/ \u01eb) iterations, while the classical gradient method\n(2.5) takes O(1/\u01eb) iterations. Moreover, the per-iteration complexities of (2.5) and (3.1) are almost the same\n\nsince computing the gradient \u2207G\u03bc (*) usually dominates the computational cost in each iteration. Nesterov's\nacceleration technique has been studied and extended by many others for nonsmooth minimization problems\nand variational inequalities, e.g., see [25, 26, 2, 38, 22, 12, 13, 14].\nOur accelerated linearized Bregman method is given below as Algorithm 4. The main difference between\nit and the basic linearized Bregman method (Algorithm 2) is that the latter uses the previous iterate xk\n7\n\n\fand subgradient pk to compute the new iterate xk+1 , while Algorithm 4 uses extrapolations x\u0303k and p\u0303k that\nare computed as linear combinations of the two previous iterates and subgradients, respectively. Carefully\nchoosing the sequence of weighting parameters {\u03b1k } guarantees an improved rate of convergence.\nAlgorithm 4 Accelerated Linearized Bregman Method\n1: Input: x0 = x\u03030 = p\u03030 = p0 = 0, \u03bc > 0, \u03c4 > 0.\n2: for k = 0, 1, * * * do\nk\n3:\nxk+1 = arg minx DJp\u0303 (x, x\u0303k ) + \u03c4 hA\u22a4 (Ax\u0303k \u2212 b), xi +\n4:\npk+1 = p\u0303k \u2212 \u03c4 A\u22a4 (Ax\u0303k \u2212 b) \u2212 \u03bc1 (xk+1 \u2212 x\u0303k );\n5:\nx\u0303k+1 = \u03b1k xk+1 + (1 \u2212 \u03b1k )xk ;\n6:\np\u0303k+1 = \u03b1k pk+1 + (1 \u2212 \u03b1k )pk .\n7: end for\n\n1\n2\u03bc kx\n\n\u2212 x\u0303k k2 ;\n\nIn the following, we first establish the equivalence between the accelerated linearized Bregman method\nand the corresponding accelerated gradient descent method (3.1), which we give explicitly as (3.2) below\napplied to the dual problem (2.6). Based on this, we then present complexity results for both basic and\naccelerated linearized Bregman methods. Not surprisingly, the accelerated linearized Bregman method\n\u221a\nimproves the iteration complexity from O(1/\u01eb) to O(1/ \u01eb).\nTheorem 3.1. The accelerated linearized Bregman method (Algorithm 4) is equivalent to the accelerated\ndual gradient descent method (3.2) starting from \u1ef9 0 = y 0 = \u03c4 b:\n\uf8f1\nk+1\n\uf8f4\n\uf8f2 w\ny k+1\n\uf8f4\n\uf8f3 k+1\n\u1ef9\n\n(3.2)\n\n1\n2\n2\u03bc kwk\n\n:=\n\narg min J(w) +\n\n:=\n\n\u1ef9 k \u2212 \u03c4 (Awk+1 \u2212 b)\n\n:=\n\n\u2212 h\u1ef9 k , Aw \u2212 bi\n\n\u03b1k y k+1 + (1 \u2212 \u03b1k )y k .\n\nMore specifically, the sequence {xk } generated by Algorithm 4 is exactly the same as the sequence {wk }\ngenerated by (3.2).\nProof. Note that the Step 3 of Algorithm 4 is equivalent to\nxk+1 := arg min J(x) \u2212 hp\u0303k , xi + \u03c4 hA\u22a4 (Ax\u0303k \u2212 b), xi +\n\n(3.3)\n\n1\nkx \u2212 x\u0303k k2 .\n2\u03bc\n\nComparing (3.3) with the first equation in (3.2), it is easy to see that xk+1 = wk+1 if and only if\nA\u22a4 \u1ef9 k = p\u0303k + \u03c4 A\u22a4 (b \u2212 Ax\u0303k ) +\n\n(3.4)\n\n1 k\nx\u0303 .\n\u03bc\n\nWe will prove (3.4) in the following by induction. Note that (3.4) holds for k = 0 since \u1ef9 0 = \u03c4 b and\nx\u03030 = p\u03030 = 0. As a result, we have x1 = w1 . By defining w0 = 0, we also have x0 = w0 ,\n(3.5)\n\nA\u22a4 \u1ef9 1 = A\u22a4 (\u03b10 y 1 + (1 \u2212 \u03b10 )A\u22a4 y 0 ) = \u03b10 A\u22a4 \u1ef9 0 + \u03b10 \u03c4 A\u22a4 (b \u2212 Aw1 ) + (1 \u2212 \u03b10 )A\u22a4 y 0 .\n\nOn the other hand,\n(3.6)\n\np1 = p\u03030 + \u03c4 A\u22a4 (b \u2212 Ax\u03030 ) \u2212\n\n1\n1 1\n(x \u2212 x\u03030 ) = A\u22a4 \u1ef9 0 \u2212 x1 ,\n\u03bc\n\u03bc\n\nwhere for the second equality we used (3.4) for k = 0. Expressing p\u03031 and x\u03031 in terms of their affine\ncombinations of p1 , p0 , x1 and x0 , then substituting for p1 using (3.6) and using the fact that x0 = p0 = 0,\n8\n\n\fand finally using \u1ef9 0 = \u03c4 b and (3.5), we obtain,\np\u03031 + \u03c4 A\u22a4 (b \u2212 Ax\u03031 ) +\n\n1 1\n1\nx\u0303 = \u03b10 p1 + (1 \u2212 \u03b10 )p0 + \u03b10 \u03c4 A\u22a4 (b \u2212 Ax1 ) + (1 \u2212 \u03b10 )\u03c4 A\u22a4 (b \u2212 Ax0 ) + (\u03b10 x1 + (1 \u2212 \u03b10 )x0 )\n\u03bc\n\u03bc\n1\n1\n= \u03b10 (A\u22a4 \u1ef9 0 \u2212 x1 ) + \u03b10 \u03c4 A\u22a4 (b \u2212 Ax1 ) + (1 \u2212 \u03b10 )\u03c4 A\u22a4 b + \u03b10 x1\n\u03bc\n\u03bc\n= \u03b10 A\u22a4 \u1ef9 0 + \u03b10 \u03c4 A\u22a4 (b \u2212 Ax1 ) + (1 \u2212 \u03b10 )A\u22a4 y 0\n\n= \u03b10 A\u22a4 \u1ef9 0 + \u03b10 \u03c4 A\u22a4 (b \u2212 Aw1 ) + (1 \u2212 \u03b10 )A\u22a4 y 0\n= A\u22a4 \u1ef9 1 .\n\nThus we proved that (3.4) holds for k = 1. Now let us assume that (3.4) holds for 0 \u2264 k \u2264 n \u2212 1, which\nimplies xk = wk , \u22000 \u2264 k \u2264 n since x0 = w0 . We will prove that (3.4) holds for k = n.\nFirst, note that\npn = p\u0303n\u22121 + \u03c4 A\u22a4 (b \u2212 Ax\u0303n\u22121 ) \u2212\n\n(3.7)\n\n1\n1 n\n(x \u2212 x\u0303n\u22121 ) = A\u22a4 \u1ef9 n\u22121 \u2212 xn ,\n\u03bc\n\u03bc\n\nwhere the first equality is from Step 4 of Algorithm 4 and the second equality is from (3.4) for k = n \u2212 1.\nFrom Step 6 of Algorithm 4 and (3.7), we have\np\u0303n\n\n= \u03b1n\u22121 pn + (1 \u2212 \u03b1n\u22121 )pn\u22121\n\n= \u03b1n\u22121 (A\u22a4 \u1ef9 n\u22121 \u2212 \u03bc1 xn ) + (1 \u2212 \u03b1n\u22121 )(A\u22a4 \u1ef9 n\u22122 \u2212 \u03bc1 xn\u22121 )\n\n(3.8)\n\n= \u03b1n\u22121 A\u22a4 \u1ef9 n\u22121 + (1 \u2212 \u03b1n\u22121 )A\u22a4 \u1ef9 n\u22122 \u2212 \u03bc1 x\u0303n ,\n\nwhere the last equality uses Step 5 of Algorithm 4. On the other hand, from (3.2) we have\nA\u22a4 \u1ef9 n\n(3.9)\n\n= A\u22a4 (\u03b1n\u22121 y n + (1 \u2212 \u03b1n\u22121 )y n\u22121 )\n\n= \u03b1n\u22121 A\u22a4 (\u1ef9 n\u22121 + \u03c4 (b \u2212 Awn )) + (1 \u2212 \u03b1n\u22121 )A\u22a4 (\u1ef9 n\u22122 + \u03c4 (b \u2212 Awn\u22121 ))\n= \u03b1n\u22121 A\u22a4 \u1ef9 n\u22121 + (1 \u2212 \u03b1n\u22121 )A\u22a4 \u1ef9 n\u22122 + \u03c4 A\u22a4 [b \u2212 A(\u03b1n\u22121 xn + (1 \u2212 \u03b1n\u22121 )xn\u22121 )]\n= \u03b1n\u22121 A\u22a4 \u1ef9 n\u22121 + (1 \u2212 \u03b1n\u22121 )A\u22a4 \u1ef9 n\u22122 + \u03c4 A\u22a4 (b \u2212 Ax\u0303n ),\n\nwhere the third equality is from wn = xn and wn\u22121 = xn\u22121 , the last equality is from Step 5 of Algorithm 4.\nCombining (3.8) and (3.9) we get that (3.4) holds for k = n.\nLike the linearized Bregman, we can also use a simpler implementation for accelerated linearized Bregman\nmethod in which the main computation at each step is a proximal minimization. Specifically, (3.2) is\nequivalent to the following three steps.\n\n(3.10)\n\n\uf8f1\nk+1\n\uf8f4\n\uf8f2 w\nk+1\nv\n\uf8f4\n\uf8f3 k+1\n\u1e7d\n\n1\n2\u03bc kw\nk+1\n\n:= arg min J(w) +\n\u22a4\n\nk\n\n:= \u1e7d \u2212 \u03c4 A (Aw\n:= \u03b1k v\n\nk+1\n\n\u2212 \u03bc\u1e7d k k2\n\n\u2212 b)\n\n+ (1 \u2212 \u03b1k )v k\n\nAs before this follows from letting v k = A\u22a4 y k and \u1e7d k = A\u22a4 \u1ef9 k and completing the square in the objective\nfunction in the first equation of (3.2).\nNext we prove iteration complexity bounds for both basic and accelerated linearized Bregman algorithms.\nSince these algorithms are standard gradient descent methods applied to the Lagrangian dual function and\nthese results have been well established, our proofs will be quite brief.\n9\n\n\fTheorem 3.2. Let the sequence {xk } be generated by the linearized Bregman method (Algorithm 2)\n\nand (x\u2217 , y \u2217 ) be the pair of optimal primal and dual solutions for Problem (2.4). Let {y k } be the sequence\ngenerated by Algorithm 3 and suppose the step length \u03c4 \u2264 L1 , where L is the Lipschitz constant for \u2207G\u03bc (y).\n\nThen for the Lagrangian function\n(3.11)\n\nL\u03bc (x, y) = J(x) +\n\n1\nkxk2 \u2212 hy, Ax \u2212 bi,\n2\u03bc\n\nwe have\nL\u03bc (x\u2217 , y \u2217 ) \u2212 L\u03bc (xk+1 , y k ) \u2264\n\n(3.12)\n\nky \u2217 \u2212 y 0 k2\n.\n2\u03c4 k\n\nThus, if we further have \u03c4 \u2265 \u03b2/L, where 0 < \u03b2 \u2264 1, then (xk+1 , y k ) is an \u01eb-optimal solution to Problem\n(2.4) with respect to the Lagrangian function if k \u2265 \u2308C/\u01eb\u2309, where C :=\n\nLky \u2217 \u2212y 0 k2\n.\n2\u03b2\n\nProof. From (2.6) we get\n\nG\u03bc (y k ) = \u2212L\u03bc (xk+1 , y k ).\n\n(3.13)\n\nBy using the convexity of function G\u03bc (*) and the Lipschitz continuity of the gradient \u2207G\u03bc (*), we get for\n\nany y,\n\nG\u03bc (y k ) \u2212 G\u03bc (y)\n(3.14)\n\nL\nk\nk\u22121 2\nk \u2212 G\u03bc (y)\n2 ky \u2212 y\n1\nk\nk\u22121 2\nk\u22121\nk\u22121\nk\nk\u22121\nk \u2212 G\u03bc (y)\nG\u03bc (y\n) + h\u2207G\u03bc (y\n), y \u2212 y\ni + 2\u03c4 ky \u2212 y\n1\nk\u22121\nk\u22121\nk\u22121\nk\nk\u22121\nky k \u2212 y k\u22121 k2\nh\u2207G\u03bc (y\n), y\n\u2212 yi + h\u2207G\u03bc (y\n), y \u2212 y\ni + 2\u03c4\n1\nk\u22121\nk\nk\nk\u22121 2\nh\u2207G\u03bc (y\n), y \u2212 yi + 2\u03c4 ky \u2212 y\nk\n1\n1\nk\u22121\nk k\nk\nk\u22121 2\n\u2212 y , y \u2212 yi + 2\u03c4 ky \u2212 y\nk\n\u03c4 hy\n1\nk\u22121 2\nk 2\nk \u2212 ky \u2212 y k ).\n2\u03c4 (ky \u2212 y\n\n\u2264 G\u03bc (y k\u22121 ) + h\u2207G\u03bc (y k\u22121 ), y k \u2212 y k\u22121 i +\n\u2264\n\u2264\n\n=\n=\n\u2264\n\nSetting y = y k\u22121 in (3.14), we obtain G\u03bc (y k ) \u2264 G\u03bc (y k\u22121 ) and thus the sequence {G\u03bc (y k )} is non-increasing.\nMoreover, summing (3.14) over k = 1, 2, . . . , n with y = y \u2217 yields\nn(G\u03bc (y n ) \u2212 G\u03bc (y \u2217 )) \u2264\n\nn\nX\n\nk=1\n\n(G\u03bc (y k ) \u2212 G\u03bc (y \u2217 )) \u2264\n\n1 \u2217\n1\n(ky \u2217 \u2212 y 0 k2 \u2212 ky \u2217 \u2212 y n k2 ) \u2264\nky \u2212 y 0 k2 ,\n2\u03c4\n2\u03c4\n\nand this implies (3.12).\nBefore we analyze the iteration complexity of the accelerated linearized Bregman method, we introduce\na lemma from [38] that we will use in our analysis.\nLemma 3.3 (Property 1 in [38]). For any proper lower semicontinuous function \u03c8 : Rn \u2192 (\u2212\u221e, +\u221e]\nand any z \u2208 Rn , if\n1\nz+ = arg min{\u03c8(x) + kx \u2212 zk2 },\nx\n2\nthen\n1\n1\n1\n\u03c8(x) + kx \u2212 zk2 \u2265 \u03c8(z+ ) + kz+ \u2212 zk2 + kx \u2212 z+ k2 ,\n2\n2\n2\n\n10\n\n\u2200x \u2208 Rn .\n\n\fThe following theorem gives an iteration-complexity result for the accelerated linearized Bregman method.\nOur proof of this theorem closely follows the proof of Proposition 2 in [38].\n\nTheorem 3.4. Let the sequence {xk } be generated by accelerated linearized Bregman method (Algorithm\n4) and (x\u2217 , y \u2217 ) be the optimal primal and dual variable for Problem (2.4). Let {\u03b1k } be chosen as\n\u22121\n\u03b1k\u22121 = 1 + \u03b8k (\u03b8k\u22121\n\u2212 1),\n\n(3.15)\nwhere\n(3.16)\n\n\u03b8\u22121 := 1, and \u03b8k =\n\n2\n, \u2200k \u2265 0.\nk+2\n\nLet the sequence {y k } be defined as in (3.2) and the step length \u03c4 \u2264\n\u2207G\u03bc (y) and G\u03bc (*) is defined by (3.13). We have\nG\u03bc (y k ) \u2212 G\u03bc (y \u2217 ) \u2264\n\n(3.17)\n\n1\nL,\n\nwhere L is the Lipschitz constant of\n\n2ky \u2217 \u2212 y 0 k2\n.\n\u03c4 k2\n\nThus, if we further have \u03c4 \u2265 \u03b2/L, where 0 < \u03b2 \u2264 1, then (xk+1 , y k ) is an \u01eb-optimal solution to Problem\np\n\u2217\n0 2\n(2.4) with respect to the Lagrangian function (3.11) if k \u2265 \u2308 C/\u01eb\u2309, where C := 2Lky \u03b2\u2212y k .\n\nProof. Let\n\u22121\nz k = y k\u22121 + \u03b8k\u22121\n(y k \u2212 y k\u22121 )\n\n(3.18)\n\nand denote the linearization of G\u03bc (y) as\n(3.19)\n\nlG\u03bc (x; y) := G\u03bc (y) + h\u2207G\u03bc (y), x \u2212 yi \u2264 G\u03bc (x).\n\nTherefore the second equality in (3.2) is equivalent to\ny k+1 := arg min\ny\n\n= arg min\ny\n\nG\u03bc (\u1ef9 k ) + h\u2207G\u03bc (\u1ef9 k ), y \u2212 \u1ef9 k i +\nlG\u03bc (y; \u1ef9 k ) +\n\n1\nky \u2212 \u1ef9 k k2 .\n2\u03c4\n\n11\n\n1\nky \u2212 \u1ef9 k k2\n2\u03c4\n\n\fDefine \u0177 k := (1 \u2212 \u03b8k )y k + \u03b8k y \u2217 , we have\n(3.20)\nL k+1\nky\n\u2212 \u1ef9 k k2\n2\n\nG\u03bc (y k+1 ) \u2264 G\u03bc (\u1ef9 k ) + h\u2207G\u03bc (\u1ef9 k ), y k+1 \u2212 \u1ef9 k i +\n\n1 k+1\nky\n\u2212 \u1ef9 k k2\n2\u03c4\n1 k\n1 k\nk\u0177 \u2212 \u1ef9 k k2 \u2212\nk\u0177 \u2212 y k+1 k2\n\u2264 lG\u03bc (\u0177 k ; \u1ef9 k ) +\n2\u03c4\n2\u03c4\n1\n1\nk(1 \u2212 \u03b8k )y k + \u03b8k y \u2217 \u2212 \u1ef9 k k2 \u2212\nk(1 \u2212 \u03b8k )y k + \u03b8k y \u2217 \u2212 y k+1 k2\n= lG\u03bc ((1 \u2212 \u03b8k )y k + \u03b8k y \u2217 ; \u1ef9 k ) +\n2\u03c4\n2\u03c4\n\u03b82\n\u03b82\n= lG\u03bc ((1 \u2212 \u03b8k )y k + \u03b8k y \u2217 ; \u1ef9 k ) + k ky \u2217 + \u03b8k\u22121 (y k \u2212 \u1ef9 k ) \u2212 y k k2 \u2212 k ky \u2217 + \u03b8k\u22121 (y k \u2212 y k+1 ) \u2212 y k k2\n2\u03c4\n2\u03c4\n\u03b8k2 \u2217\n\u03b8k2 \u2217\nk 2\nk+1 2\nk\n\u2217 k\nky \u2212 z k \u2212\nky \u2212 z\nk\n= lG\u03bc ((1 \u2212 \u03b8k )y + \u03b8k y ; \u1ef9 ) +\n2\u03c4\n2\u03c4\n2\n2\n\u03b8\n\u03b8\n= (1 \u2212 \u03b8k )lG\u03bc (y k ; \u1ef9 k ) + \u03b8k lG\u03bc (y \u2217 ; \u1ef9 k ) + k ky \u2217 \u2212 z k k2 \u2212 k ky \u2217 \u2212 z k+1 k2\n2\u03c4\n2\u03c4\n\u03b8k2 \u2217\n\u03b8k2 \u2217\nk 2\nk\n\u2217\nky \u2212 z k \u2212\nky \u2212 z k+1 k2 ,\n\u2264 (1 \u2212 \u03b8k )G\u03bc (y ) + \u03b8k G\u03bc (y ) +\n2\u03c4\n2\u03c4\n\u2264 lG\u03bc (y k+1 ; \u1ef9 k ) +\n\nwhere the second inequality is from (3.19) and \u03c4 \u2264 1/L, the third inequality uses Lemma 3.3 with \u03c8(x) :=\n\u03c4 lG\u03bc (x; \u1ef9 k ), the third equality uses (3.18), (3.2) and (3.15) and the last inequality uses (3.19).\nTherefore we get\n1 \u2212 \u03b8k\n1\n1\n1\n(G\u03bc (y k+1 ) \u2212 G\u03bc (y \u2217 )) \u2264\n(G\u03bc (y k ) \u2212 G\u03bc (y \u2217 )) +\nky \u2212 z k k2 \u2212\nky \u2212 z k+1 k2 .\n2\n2\n\u03b8k\n\u03b8k\n2\u03c4\n2\u03c4\nFrom (3.16), it is easy to show that\n(3.21)\n\n1\u2212\u03b8k\n2\n\u03b8k\n\n\u2264\n\n1\n2\n\u03b8k\u22121\n\nfor all k \u2265 0. Thus (3.20) implies that\n\n1 \u2212 \u03b8k\n1\n1\n1 \u2212 \u03b8k+1\n(G\u03bc (y k+1 ) \u2212 G\u03bc (y \u2217 )) \u2264\n(G\u03bc (y k ) \u2212 G\u03bc (y \u2217 )) +\nky \u2212 z k k2 \u2212\nky \u2212 z k+1 k2 .\n2\n\u03b8k+1\n\u03b8k2\n2\u03c4\n2\u03c4\n\nSumming (3.21) over k = 0, 1, . . . , n \u2212 1, we get\n1 \u2217\n1 \u2217\n1 \u2212 \u03b8n\n(G\u03bc (y n ) \u2212 G\u03bc (y \u2217 )) \u2264\nky \u2212 z 0 k2 =\nky \u2212 y 0 k2 ,\n2\n\u03b8n\n2\u03c4\n2\u03c4\nwhich immediately implies (3.17).\nRemark 3.5. The proof technique and the choice of \u03b8k used here are suggested in [38] for accelerating\nthe basic algorithm. Other choices of \u03b8k can be found in [23, 24, 2, 38]. They all work here and give the\nsame order of iteration complexity.\n\n4. Extension to Problems with Additional Convex Constraints. We now consider extensions\nof both the LB and ALB methods to problems of the form\n(4.1)\n\nmin\n\nx\u2208X\n\nJ(x)\n\ns.t Ax = b,\n12\n\n\fwhere X is a nonempty closed convex set in Rn . It is not clear how to extend the LB and ALB methods\n(Algorithms 2 and 4) to problem (4.1) since we can no longer rely on the relationship\n0 \u2208 \u2202J(xk+1 ) \u2212 pk + A\u22a4 (Axk \u2212 b) +\n\n1 k+1\n(x\n\u2212 xk )\n\u03bc\n\nto compute a subgradient pk+1 \u2208 \u2202J(xk+1 ). Fortunately, the Lagrangian dual gradient versions of these\nalgorithms do not suffer from this difficulty. All that is required to extend them to problem (4.1) is to\ninclude the constraint w \u2208 X in the minimization step in these algorithms. Note that the gradient of\n\u03a6\u0302\u03bc (v) = min {J(w) +\nw\u2208X\n\n1\nkw \u2212 vk2 }\n2\u03bc\n\nremains the same. Also it is clear that the iteration complexity results given in Theorems 3.2 and 3.4 apply\nto these algorithms as well.\nBeing able to apply the LB and ALB methods to problems of the form of (4.1) greatly expands their\nusefulness. One immediate extension is to compressed sensing problems in which the signal is required to\nhave nonnegative components. Also (4.1) directly includes all linear programs. Applying the LB and ALB\nto such problems, with the goal of only obtaining approximated optimal solutions, will be the subject of a\nfuture paper.\n5. Numerical Experiments. In this section, we report some numerical results that demonstrate\nthe effectiveness of the accelerated linearized Bregman algorithm. All numerical experiments were run in\nMATLAB 7.3.0 on a Dell Precision 670 workstation with an Intel Xeon(TM) 3.4GHZ CPU and 6GB of\nRAM.\n5.1. Numerical Results on Compressed Sensing Problems. In this subsection, we compare the\nperformance of the accelerated linearized Bregman method against the performance of the basic linearized\nBregman method on a variety of compressed sensing problems of the form (1.2).\nWe use three types of sensing matrices A \u2208 Rm\u00d7n . Type (i): A is a standard Gaussian matrix generated\n\nby the randn(m, n) function in MATLAB. Type (ii): A is first generated as a standard Gaussian matrix and\nthen normalized to have unit-norm columns. Type (iii): The elements of A are sampled from a Bernoulli\ndistribution as either +1 or \u22121. We use two types of sparse solutions x\u2217 \u2208 Rn with sparsity s (i.e., the\nnumber of nonzeros in x\u2217 ). The positions of the nonzero entries of x\u2217 are selected uniformly at random, and\neach nonzero value is sampled either from (i) standard Gaussian (the randn function in MATLAB) or from\n(ii) [\u22121, 1] uniformly at random (2 \u2217 rand \u2212 1 in MATLAB).\nFor compressed sensing problems, where J(x) = kxk1 , the linearized Bregman method reduces to the\n\ntwo-line algorithm:\n\n(\n\nxk+1\n\n:=\n\nv k+1\n\n:=\n\n\u03bc * shrink(v k , 1)\n\nv k + \u03c4 A\u22a4 (b \u2212 Axk+1 ),\n\nwhere the l1 shrinkage operator is defined in (2.10). Similarly, the accelerated linearized Bregman can be\nwritten as:\n\uf8f1\nk+1\n\uf8f4\n\uf8f2 x\nv k+1\n\uf8f4\n\uf8f3 k+1\n\u1e7d\n\n:=\n:=\n:=\n\n\u03bc * shrink(\u1e7d k , 1)\n\n\u1e7d k + \u03c4 AT (b \u2212 Axk+1 )\n\u03b1k v k+1 + (1 \u2212 \u03b1k )v k .\n13\n\n\fBoth algorithms are very simple to program and involve only one Ax and one A\u22a4 y matrix-vector multiplication in each iteration.\nWe ran both LB and ALB with the seed used for generating random number in MATLAB setting as 0.\nHere we set n = 2000, m = 0.4 \u00d7 n, s = 0.2 \u00d7 m, \u03bc = 5 for all data sets. We set \u03c4 =\nthe algorithms when the stopping criterion\n\n2\n\u03bckAk2 .\n\nWe terminated\n\nkAxk \u2212 bk/kbk < 10\u22125\n\n(5.1)\n\nwas satisfied or the number of iterations exceeded 5000. Note that (5.1) was also used in [41]. We report\nthe results in Table 5.1.\nTable 5.1\nCompare linearized Bregman (LB) with accelerated linearized Bregman (ALB)\n\nStandard Gaussian matrix A\nType of x\u2217 n(m = 0.4n, s = 0.2m)\nGaussian\n2000\nUniform\n2000\nNormalized Gaussian matrix A\nType of x\u2217 n(m = 0.4n, s = 0.2m)\nGaussian\n2000\nUniform\n2000\nBernoulli +1/-1 matrix A\nType of x\u2217 n(m = 0.4n, s = 0.2m)\nGaussian\n2000\nUniform\n2000\n\nNumber of Iterations\nLB\nALB\n5000+\n330\n1681\n214\nNumber of Iterations\nLB\nALB\n2625\n234\n5000+\n292\nNumber of Iterations\nLB\nALB\n2314\n222\n5000+\n304\n\nRelative error\nLB\n5.1715e-3\n2.2042e-5\nRelative error\nLB\n3.2366e-5\n1.2621e-2\nRelative error\nLB\n4.2057e-5\n1.6141e-2\n\nkx \u2212 x\u2217 k/kx\u2217 k\nALB\n1.4646e-5\n1.5241e-5\nkx \u2212 x\u2217 k/kx\u2217 k\nALB\n1.2664e-5\n1.5629e-5\nkx \u2212 x\u2217 k/kx\u2217 k\nALB\n1.0812e-5\n1.5732e-5\n\nIn Table 5.1, we see that for three out of six problems, LB did not achieve the desired convergence\ncriterion within 5000 iterations, while ALB satisfied this stopping criterion in less than 330 iterations on\nall six problems. To further demonstrate the significant improvement the ALB achieved over LB, we plot\nin Figures 5.1, 5.2 and 5.3 the Euclidean norms of the residuals and the relative errors as a function of the\niteration number that were obtained by LB and ALB applied to the same data sets. These figures also depict\nthe non-monotonic behavior of the ALB method.\n\n5.2. Numerical Results on Matrix Completion Problems. There are fast implementations of\nlinearized Bregman [5] and other solvers [20, 37, 19, 40] for solving matrix completion problems. We do not\ncompare the linearized Bregman and our accelerated linearized Bregman algorithms with these fast solvers\nhere. Rather our tests are focused only on comparing ALB with LB and verifying that the acceleration\nactually occurs in practice for matrix completion problems.\nThe nuclear norm matrix completion problem (1.7) can be rewritten as\n(5.2)\n\nmin\nX\n\nkXk\u2217\n\ns.t. P\u03a9 (X) = P\u03a9 (M ),\n\nwhere [P\u03a9 (X)]ij = Xij if (i, j) \u2208 \u03a9 and [P\u03a9 (X)]ij = 0 otherwise. When the convex function J(*) is the\n\nnuclear norm of matrix X, the Step 3 of Algorithm 2 with inputs X k , P k can be reduced to\n(5.3)\n\nX k+1 := arg\n\nmin\n\nX\u2208Rm\u00d7n\n\n1\n\u03bckXk\u2217 + kX \u2212 (X k \u2212 \u03bc(\u03c4 P\u03a9 (P\u03a9 X k \u2212 P\u03a9 (M )) \u2212 P k ))k2F .\n2\n14\n\n\fResidual\n\n0\n\n10\nLB\nALB\n\n\u22122\n\nLB\nALB\n\n\u22122\n\n10\n\n10\n\n\u22124\n\n\u22124\n\n10\n\n10\n\n\u22126\n\n10\n\nResidual\n\n0\n\n10\n\n\u22126\n\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n10\n\n5000\n\nRelative Errors\n\n0\n\n0\n\n200\n\n400\n\n600\n\n1000\n\n1200\n\n1400\n\n1800\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22125\n\n10\n\n1600\n\nRelative Errors\n\n0\n\n10\n\n800\n\n\u22125\n\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n10\n\n5000\n\n0\n\n200\n\n400\n\n600\n\n800\n\n1000\n\n1200\n\n1400\n\n1600\n\n1800\n\nFig. 5.1. Gaussian matrix A, Left: Gaussian x\u2217 , Right: Uniform x\u2217\nResidual\n\n0\n\nResidual\n\n0\n\n10\n\n10\nLB\nALB\n\n\u22122\n\nLB\nALB\n\n10\n\n\u22124\n\n10\n\n\u22126\n\n10\n\n\u22125\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n2500\n\n10\n\n3000\n\nRelative Errors\n\n0\n\n0\n\n1000\n\n3000\n\n4000\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22125\n\n10\n\n5000\n\nRelative Errors\n\n0\n\n10\n\n2000\n\n\u22125\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n2500\n\n10\n\n3000\n\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n5000\n\nFig. 5.2. Normalized Gaussian matrix A, Left: Gaussian x\u2217 , Right: Uniform x\u2217\nResidual\n\n0\n\n10\nLB\nALB\n\n\u22122\n\nLB\nALB\n\n\u22122\n\n10\n\n10\n\n\u22124\n\n\u22124\n\n10\n\n10\n\n\u22126\n\n10\n\nResidual\n\n0\n\n10\n\n\u22126\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n10\n\n2500\n\nRelative Errors\n\n0\n\n0\n\n1000\n\n3000\n\n4000\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22125\n\n10\n\n5000\n\nRelative Errors\n\n0\n\n10\n\n2000\n\n\u22125\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n10\n\n2500\n\n0\n\n1000\n\n2000\n\n3000\n\nFig. 5.3. Bernoulli matrix A, Left: Gaussian x\u2217 , Right: Uniform x\u2217\n\n15\n\n4000\n\n5000\n\n\fIt is known (see, e.g., [5, 20]) that (5.3) has the closed-form solution,\nX k+1 = Shrink(X k \u2212 \u03bc(\u03c4 P\u03a9 (P\u03a9 X k \u2212 P\u03a9 (M )) \u2212 P k ), \u03bc),\nwhere the matrix shrinkage operator is defined as\nShrink(Y, \u03b3) := U Diag(max(\u03c3 \u2212 \u03b3, 0))V \u22a4 ,\nand Y = U Diag(\u03c3)V \u22a4 is the singular value decomposition (SVD) of matrix Y . Thus, a typical iteration\nof the linearized Bregman method (Algorithm 2), with initial inputs X 0 = P 0 = 0, for solving the matrix\ncompletion problem (5.2) can be summarized as\n(5.4)\n\n(\n\nX k+1\n\n:=\n\nk+1\n\n:=\n\nP\n\nShrink(X k \u2212 \u03bc(\u03c4 P\u03a9 (P\u03a9 X k \u2212 P\u03a9 (M )) \u2212 P k ), \u03bc)\n\nP k \u2212 \u03c4 (P\u03a9 X k \u2212 P\u03a9 M ) \u2212 (X k+1 \u2212 X k )/\u03bc.\n\nSimilarly, a typical iteration of the accelerated linearized Bregman method (Algorithm 4), with initial inputs\nX 0 = P 0 = X\u0303 0 = P\u0303 0 = 0, for solving the matrix completion problem (5.2) can be summarized as\n\n(5.5)\n\n\uf8f1\n\uf8f4\nX k+1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 P k+1\n\uf8f4\nX\u0303 k+1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 P\u0303 k+1\n\n:=\n:=\n:=\n:=\n\nShrink(X k \u2212 \u03bc(\u03c4 P\u03a9 (P\u03a9 X k \u2212 P\u03a9 (M )) \u2212 P k ), \u03bc)\n\nP\u0303 k \u2212 \u03c4 (P\u03a9 X\u0303 k \u2212 P\u03a9 M ) \u2212 (X k+1 \u2212 X\u0303 k )/\u03bc\n\u03b1k X k+1 + (1 \u2212 \u03b1k )X k\n\u03b1k P k+1 + (1 \u2212 \u03b1k )P k ,\n\nwhere the sequence \u03b1k is chosen according to Theorem 3.4.\nWe compare the performance of LB and ALB on a variety of matrix completion problems. We created\nmatrices M \u2208 Rn\u00d7n with rank r by the following procedure. We first created standard Gaussian matrices\nML \u2208 Rn\u00d7r and MR \u2208 Rn\u00d7r and then we set M = ML MR\u22a4 . The locations of the p known entries in M were\nsampled uniformly, and the values of these p known entries were drawn from an iid Gaussian distribution.\nThe ratio p/n2 between the number of measurements and the number of entries in the matrix is denoted\n\nby \"SR\" (sampling ratio). The ratio between the dimension of the set of n \u00d7 n rank r matrices, r(2n \u2212 r),\nand the number of samples p, is denoted by \"FR\". In our tests, we fixed F R to 0.2 and 0.3 and r to 10.\nWe tested five matrices with dimension n = 100, 200, 300, 400, 500 and set the number p to r(2n \u2212 r)/F R.\nThe random seed for generating random matrices in MATLAB was set to 0. \u03bc was set to 5n (a heuristic\nargument for this choice can be found in [5]). We set the step length \u03c4 to 1/\u03bc since for matrix completion\nproblems kP\u03a9 k = 1. We terminated the code when the relative error between the residual and the true\n\nmatrix was less than 10\u22124 , i.e.,\n(5.6)\n\nkP\u03a9 (X k ) \u2212 P\u03a9 (M )kF /kP\u03a9 (M )kF < 10\u22124 .\n\nNote that this stopping criterion was used in [5]. We also set the maximum number of iteration to 2000.\nWe report the number of iterations needed by LB and ALB to reach (5.6) in Table 5.2. Note that\nperforming the shrinkage operation, i.e., computing an SVD, dominates the computational cost in each\niteration of LB and ALB. Thus, the per-iteration complexities of LB and ALB are almost the same and it\nis reasonable to compare the number of iterations needed to reach the stopping criterion. We report the\nrelative error err := kX k \u2212 M kF /kM kF between the recovered matrix X k and the true matrix M in Table\n16\n\n\fRelative Error (n=200)\n\n0\n\nRelative Error (n=300)\n\n0\n\n10\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22122\n\n10\n\u22125\n\n10\n\n\u22124\n\n10\n\u221210\n\n10\n\n\u22126\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\nResidual (n=200)\n\n0\n\n0\n\n100\n\n300\n\n400\n\n500\n\nResidual (n=300)\n\n0\n\n10\n\n200\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22122\n\n10\n\u22125\n\n10\n\n\u22124\n\n10\n\u221210\n\n10\n\n\u22126\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\nRelative Error (n=400)\n\n0\n\n0\n\n100\n\n300\n\n400\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22125\n\n10\n\n\u22125\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\nResidual (n=400)\n\n0\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\nResidual (n=500)\n\n0\n\n10\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22125\n\n10\n\n500\n\nRelative Error (n=500)\n\n0\n\n10\n\n200\n\n\u22125\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\nFig. 5.4. Comparison of LB and ALB on matrix completion problems with rank = 10, F R = 0.2\n\n5.2. We see from Table 5.2 that ALB needed significantly fewer iterations to meet the stopping criterion\n(5.6).\nIn Figures 5.4 and 5.5, we plot the Frobenius norms of the residuals and the relative errors obtained by\nLB and ALB for iteration 1-500 for the tests involving matrices with dimension n = 200, 300, 400 and 500.\nNote that the non-monotonicity of ALB is far less pronounced on these problems.\nTable 5.2\nComparison between LB and ALB on Matrix Completion Problems\n\nn\n100\n200\n300\n400\n500\n\nSR\n0.95\n0.49\n0.33\n0.25\n0.20\n\nF R = 0.2, rank = 10\niter-LB err-LB iter-ALB\n85\n1.07e-4\n63\n283\n1.62e-4\n171\n466\n1.64e-4\n261\n667\n1.79e-4\n324\n831\n1.76e-4\n398\n\nerr-ALB\n1.11e-4\n1.58e-4\n1.60e-4\n1.65e-4\n1.65e-4\n\n17\n\nSR\n0.63\n0.33\n0.22\n0.17\n0.13\n\nF R = 0.3, rank = 10\niter-LB err-LB iter-ALB\n294\n1.75e-4\n163\n1224\n3.76e-4\n289\n2000+ 3.59e-3\n406\n2000+ 1.12e-2\n455\n2000+ 3.14e-2\n1016\n\nerr-ALB\n1.65e-4\n1.83e-4\n1.93e-4\n1.80e-4\n7.49e-3\n\n\fRelative Error (n=200)\n\n0\n\nRelative Error (n=300)\n\n0\n\n10\n\n10\nLB\nALB\n\nLB\nALB\n\u22122\n\n10\n\n\u22125\n\n10\n\n\u22124\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\nResidual (n=200)\n\n0\n\n0\n\n100\n\n300\n\n400\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22125\n\n10\n\n500\n\nResidual (n=300)\n\n0\n\n10\n\n200\n\n\u22125\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\nRelative Error (n=400)\n\n0\n\n0\n\n100\n\n300\n\n400\n\n500\n\nRelative Error (n=500)\n\n0\n\n10\n\n200\n\n10\nLB\nALB\n\nLB\nALB\n\n\u22121\n\n10\n\u22122\n\n10\n\n\u22122\n\n10\n\u22124\n\n10\n\n\u22123\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\nResidual (n=400)\n\n0\n\n0\n\n100\n\n300\n\n400\n\n500\n\nResidual (n=500)\n\n0\n\n10\n\n200\n\n10\nLB\nALB\n\nLB\nALB\n\u22122\n\n10\n\n\u22125\n\n10\n\n\u22124\n\n0\n\n100\n\n200\n\n300\n\n400\n\n10\n\n500\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\nFig. 5.5. Comparison of LB and ALB on matrix completion problems with rank = 10, F R = 0.3\n\n6. Conclusions. In this paper, we analyzed for the first time the iteration complexity of the linearized\nBregman method. Specifically, we show that for a suitably chosen step length, the method achieves a value\nof the Lagrangian of a quadratically regularized version of the basis pursuit problem that is within \u01eb of the\noptimal value in O(1/\u01eb) iterations. We also derive an accelerated version of the linearized Bregman method\n\u221a\nwhose iteration complexity is reduced to O(1/ \u01eb) and present numerical results on basis pursuit and matrix\ncompletion problems that illustrate this speed-up.\nREFERENCES\n[1] J. Barzilai and J. Borwein, Two point step size gradient methods, IMA Journal of Numerical Analysis, 8 (1988),\npp. 141\u2013148.\n[2] A. Beck and M. Teboulle, A fast iterative shrinkage-thresholding algorithm for linear inverse problems, SIAM J.\nImaging Sciences, 2 (2009), pp. 183\u2013202.\n[3] D. P. Bertsekas and J. N. Tsitsiklis, Parallel and distributed computation: numerical methods, Prentice-Hall, Inc.,\nUpper Saddle River, NJ, USA, 1989.\n[4] L. Bregman, The relaxation method of finding the common points of convex sets and its application to the solution of\nproblems in convex programming, USSR Computational Mathematics and Mathematical Physics, 7 (1967), pp. 200\u2013\n217.\n[5] J. Cai, E. J. Cand\u00e8s, and Z. Shen, A singular value thresholding algorithm for matrix completion, SIAM J. on Opti18\n\n\fmization, 20 (2010), pp. 1956\u20131982.\n[6] J.-F. Cai, S. Osher, and Z. Shen, Convergence of the linearized Bregman iteration for l1 -norm minimization, Mathematics of Computation, 78 (2009), pp. 2127\u20132136.\n[7]\n, Linearized Bregman iterations for compressed sensing, Mathematics of Computation, 78 (2009), pp. 1515\u20131536.\n[8] E. J. Cand\u00e8s and B. Recht, Exact matrix completion via convex optimization, Foundations of Computational Mathematics, 9 (2009), pp. 717\u2013772.\n[9] E. J. Cand\u00e8s, J. Romberg, and T. Tao, Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information, IEEE Transactions on Information Theory, 52 (2006), pp. 489\u2013509.\n[10] E. J. Cand\u00e8s and T. Tao, The power of convex relaxation: near-optimal matrix completion, IEEE Trans. Inform. Theory,\n56 (2009), pp. 2053\u20132080.\n[11] D. Donoho, Compressed sensing, IEEE Transactions on Information Theory, 52 (2006), pp. 1289\u20131306.\n[12] D. Goldfarb and S. Ma, Fast multiple splitting algorithms for convex optimization, tech. report, Department of IEOR,\nColumbia University. Preprint available at http://arxiv.org/abs/0912.4570, 2009.\n[13] D. Goldfarb, S. Ma, and K. Scheinberg, Fast alternating linearization methods for minimizing the sum\nof two convex functions, tech. report, Department of IEOR, Columbia University. Preprint available at\nhttp://arxiv.org/abs/0912.4571, 2010.\n[14] D. Goldfarb and K. Scheinberg, Fast first-order methods for composite convex optimization with line search, preprint,\n(2011).\n[15] D. Gross, Recovering low-rank matrices from few coefficients in any basis, IEEE Transactions on Information Theory,\n57 (2011), pp. 1548\u20131566.\n[16] E. T. Hale, W. Yin, and Y. Zhang, Fixed-point continuation for l1 -minimization: Methodology and convergence, SIAM\nJournal on Optimization, 19 (2008), pp. 1107\u20131130.\n[17] M. R. Hestenes, Multiplier and gradient methods, Journal of Optimization Theory and Applications, 4 (1969), pp. 303\u2013\n320.\n[18] D. C. Liu and J. Nocedal, On the limited memory BFGS method for large scale optimization, Mathematical Programming, Series B, 45 (1989), pp. 503\u2013528.\n[19] Y. Liu, D. Sun, and K.-C. Toh, An implementable proximal point algorithmic framework for nuclear norm minimization,\nTo appear in Mathematical Programming, (2009).\n[20] S. Ma, D. Goldfarb, and L. Chen, Fixed point and Bregman iterative methods for matrix rank minimization, Mathematical Programming Series A, 128 (2011), pp. 321\u2013353.\n[21] B. K. Natarajan, Sparse approximate solutions to linear systems, SIAM Journal on Computing, 24 (1995), pp. 227\u2013234.\n[22] A. Nemirovski, Prox-method with rate of convergence O(1/t) for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems, SIAM Journal on Optimization, 15 (2005), pp. 229\u2013\n251.\n[23] Y. E. Nesterov, A method for unconstrained convex minimization problem with the rate of convergence O(1/k 2 ), Dokl.\nAkad. Nauk SSSR, 269 (1983), pp. 543\u2013547.\n, Introductory lectures on convex optimization, 87 (2004), pp. xviii+236. A basic course.\n[24]\n, Smooth minimization for non-smooth functions, Math. Program. Ser. A, 103 (2005), pp. 127\u2013152.\n[25]\n, Gradient methods for minimizing composite objective function, CORE Discussion Paper 2007/76, (2007).\n[26]\n[27] S. Osher, M. Burger, D. Goldfarb, J. Xu, and W. Yin, An iterative regularization method for total variation-based\nimage restoration, SIAM Journal on Multiscale Modeling and Simulation, 4 (2005), pp. 460\u2013489.\n[28] S. Osher, Y. Mao, B. Dong, and W. Yin, Fast linearized Bregman iteration for compressive sensing and sparse\ndenoising, Communications in Mathematical Sciences, 8 (2010), pp. 93\u2013111.\n[29] M. J. D. Powell, A method for nonlinear constraints in minimization problems, in Optimization, R. Fletcher, ed.,\nAcademic Press, New York, 1972, pp. 283\u2013298.\n[30] B. Recht, A simpler approach to matrix completion, To appear in Journal of Machine Learning Research., (2009).\n[31] B. Recht, M. Fazel, and P. Parrilo, Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm\nminimization, SIAM Review, 52 (2010), pp. 471\u2013501.\n[32] R.T. Rockafellar, Convex Analysis, Princeton University Press, Princeton, 1970.\n[33] R. T. Rockafellar, Augmented Lagrangians and applications of the proximal point algorithm in convex programming,\nMath. Oper. Res., 1 (1976), pp. 97\u2013116.\n[34] ACM SIGKDD and Netflix, Proceedings of kdd cup and workshop, Proceedings available online at\nhttp://www.cs.uic.edu/ liub/KDD-cup-2007/proceedings.html.\n[35] N. Srebro, Learning with Matrix Factorizations, PhD thesis, Massachusetts Institute of Technology, 2004.\n19\n\n\f[36] N. Srebro and T. Jaakkola, Weighted low-rank approximations, in Proceedings of the Twentieth International Conference on Machine Learning (ICML-2003), 2003.\n[37] K.-C. Toh and S. Yun, An accelerated proximal gradient algorithm for nuclear norm regularized least squares problems,\nPacific J. Optimization, 6 (2010), pp. 615\u2013640.\n[38] P. Tseng, On accelerated proximal gradient methods for convex-concave optimization, submitted to SIAM J. Optim.,\n(2008).\n[39] E. van den Berg and M. P. Friedlander, Probing the Pareto frontier for basis pursuit solutions, SIAM J. on Scientific\nComputing, 31 (2008), pp. 890\u2013912.\n[40] Z. Wen, W. Yin, and Y. Zhang, Solving a low-rank factorization model for matrix completion by a nonlinear successive\nover-relaxation algorithm, preprint, (2010).\n[41] W. Yin, Analysis and generalizations of the linearized Bregman method, SIAM Journal on Imaging Sciences, 3 (2010),\npp. 856\u2013877.\n[42] W. Yin, S. Osher, D. Goldfarb, and J. Darbon, Bregman iterative algorithms for l1 -minimization with applications\nto compressed sensing, SIAM Journal on Imaging Sciences, 1 (2008), pp. 143\u2013168.\n\n20\n\n\f"}