{"id": "http://arxiv.org/abs/1108.5669v2", "guidislink": true, "updated": "2011-09-02T18:07:58Z", "updated_parsed": [2011, 9, 2, 18, 7, 58, 4, 245, 0], "published": "2011-08-29T17:48:28Z", "published_parsed": [2011, 8, 29, 17, 48, 28, 0, 241, 0], "title": "Learning Valuation Functions", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.5499%2C1108.6092%2C1108.0802%2C1108.0415%2C1108.2456%2C1108.1190%2C1108.0726%2C1108.4089%2C1108.0199%2C1108.3207%2C1108.3528%2C1108.4498%2C1108.2153%2C1108.2104%2C1108.1044%2C1108.3212%2C1108.5914%2C1108.1330%2C1108.1004%2C1108.2192%2C1108.4777%2C1108.4109%2C1108.3674%2C1108.4377%2C1108.4698%2C1108.2032%2C1108.3789%2C1108.2613%2C1108.0884%2C1108.5611%2C1108.4814%2C1108.0950%2C1108.1653%2C1108.3351%2C1108.1908%2C1108.4266%2C1108.3819%2C1108.1368%2C1108.0287%2C1108.5305%2C1108.2564%2C1108.4768%2C1108.3116%2C1108.0443%2C1108.3216%2C1108.1842%2C1108.3147%2C1108.5809%2C1108.5622%2C1108.4659%2C1108.4007%2C1108.3803%2C1108.5380%2C1108.5058%2C1108.1826%2C1108.1583%2C1108.3582%2C1108.1029%2C1108.4876%2C1108.2541%2C1108.4728%2C1108.6203%2C1108.2303%2C1108.1438%2C1108.5669%2C1108.1506%2C1108.5033%2C1108.3041%2C1108.4575%2C1108.0570%2C1108.3883%2C1108.1426%2C1108.2393%2C1108.3052%2C1108.2350%2C1108.2577%2C1108.4021%2C1108.0136%2C1108.0882%2C1108.3229%2C1108.2044%2C1108.5728%2C1108.1971%2C1108.5447%2C1108.5511%2C1108.4369%2C1108.2418%2C1108.2143%2C1108.3535%2C1108.5258%2C1108.1595%2C1108.2114%2C1108.3648%2C1108.0520%2C1108.4223%2C1108.3568%2C1108.1285%2C1108.2500%2C1108.4986%2C1108.0359%2C1108.4103&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Learning Valuation Functions"}, "summary": "In this paper we study the approximate learnability of valuations commonly\nused throughout economics and game theory for the quantitative encoding of\nagent preferences. We provide upper and lower bounds regarding the learnability\nof important subclasses of valuation functions that express\nno-complementarities. Our main results concern their approximate learnability\nin the distributional learning (PAC-style) setting. We provide nearly tight\nlower and upper bounds of $\\tilde{\\Theta}(n^{1/2})$ on the approximation factor\nfor learning XOS and subadditive valuations, both widely studied superclasses\nof submodular valuations. Interestingly, we show that the\n$\\tilde{\\Omega}(n^{1/2})$ lower bound can be circumvented for XOS functions of\npolynomial complexity; we provide an algorithm for learning the class of XOS\nvaluations with a representation of polynomial size achieving an $O(n^{\\eps})$\napproximation factor in time $O(n^{1/\\eps})$ for any $\\eps > 0$. This\nhighlights the importance of considering the complexity of the target function\nfor polynomial time learning. We also provide new learning results for\ninteresting subclasses of submodular functions.\n  Our upper bounds for distributional learning leverage novel structural\nresults for all these valuation classes. We show that many of these results\nprovide new learnability results in the Goemans et al. model (SODA 2009) of\napproximate learning everywhere via value queries.\n  We also introduce a new model that is more realistic in economic settings, in\nwhich the learner can set prices and observe purchase decisions at these prices\nrather than observing the valuation function directly. In this model, most of\nour upper bounds continue to hold despite the fact that the learner receives\nless information (both for learning in the distributional setting and with\nvalue queries), while our lower bounds naturally extend.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.5499%2C1108.6092%2C1108.0802%2C1108.0415%2C1108.2456%2C1108.1190%2C1108.0726%2C1108.4089%2C1108.0199%2C1108.3207%2C1108.3528%2C1108.4498%2C1108.2153%2C1108.2104%2C1108.1044%2C1108.3212%2C1108.5914%2C1108.1330%2C1108.1004%2C1108.2192%2C1108.4777%2C1108.4109%2C1108.3674%2C1108.4377%2C1108.4698%2C1108.2032%2C1108.3789%2C1108.2613%2C1108.0884%2C1108.5611%2C1108.4814%2C1108.0950%2C1108.1653%2C1108.3351%2C1108.1908%2C1108.4266%2C1108.3819%2C1108.1368%2C1108.0287%2C1108.5305%2C1108.2564%2C1108.4768%2C1108.3116%2C1108.0443%2C1108.3216%2C1108.1842%2C1108.3147%2C1108.5809%2C1108.5622%2C1108.4659%2C1108.4007%2C1108.3803%2C1108.5380%2C1108.5058%2C1108.1826%2C1108.1583%2C1108.3582%2C1108.1029%2C1108.4876%2C1108.2541%2C1108.4728%2C1108.6203%2C1108.2303%2C1108.1438%2C1108.5669%2C1108.1506%2C1108.5033%2C1108.3041%2C1108.4575%2C1108.0570%2C1108.3883%2C1108.1426%2C1108.2393%2C1108.3052%2C1108.2350%2C1108.2577%2C1108.4021%2C1108.0136%2C1108.0882%2C1108.3229%2C1108.2044%2C1108.5728%2C1108.1971%2C1108.5447%2C1108.5511%2C1108.4369%2C1108.2418%2C1108.2143%2C1108.3535%2C1108.5258%2C1108.1595%2C1108.2114%2C1108.3648%2C1108.0520%2C1108.4223%2C1108.3568%2C1108.1285%2C1108.2500%2C1108.4986%2C1108.0359%2C1108.4103&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper we study the approximate learnability of valuations commonly\nused throughout economics and game theory for the quantitative encoding of\nagent preferences. We provide upper and lower bounds regarding the learnability\nof important subclasses of valuation functions that express\nno-complementarities. Our main results concern their approximate learnability\nin the distributional learning (PAC-style) setting. We provide nearly tight\nlower and upper bounds of $\\tilde{\\Theta}(n^{1/2})$ on the approximation factor\nfor learning XOS and subadditive valuations, both widely studied superclasses\nof submodular valuations. Interestingly, we show that the\n$\\tilde{\\Omega}(n^{1/2})$ lower bound can be circumvented for XOS functions of\npolynomial complexity; we provide an algorithm for learning the class of XOS\nvaluations with a representation of polynomial size achieving an $O(n^{\\eps})$\napproximation factor in time $O(n^{1/\\eps})$ for any $\\eps > 0$. This\nhighlights the importance of considering the complexity of the target function\nfor polynomial time learning. We also provide new learning results for\ninteresting subclasses of submodular functions.\n  Our upper bounds for distributional learning leverage novel structural\nresults for all these valuation classes. We show that many of these results\nprovide new learnability results in the Goemans et al. model (SODA 2009) of\napproximate learning everywhere via value queries.\n  We also introduce a new model that is more realistic in economic settings, in\nwhich the learner can set prices and observe purchase decisions at these prices\nrather than observing the valuation function directly. In this model, most of\nour upper bounds continue to hold despite the fact that the learner receives\nless information (both for learning in the distributional setting and with\nvalue queries), while our lower bounds naturally extend."}, "authors": ["Maria Florina Balcan", "Florin Constantin", "Satoru Iwata", "Lei Wang"], "author_detail": {"name": "Lei Wang"}, "author": "Lei Wang", "links": [{"href": "http://arxiv.org/abs/1108.5669v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.5669v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ML", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.5669v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.5669v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Learning Valuation Functions\nMaria Florina Balcan\u2217\n\nFlorin Constantin\u2020\n\nSatoru Iwata\u2021\n\nLei Wang\u00a7\n\narXiv:1108.5669v2 [cs.GT] 2 Sep 2011\n\nAbstract\nA core element of microeconomics and game theory is that consumers have valuation functions over bundles of\ngoods and that these valuation functions drive their purchases. In particular, the value assigned to a bundle need not\nbe the sum of values on the individual items but rather is often a more complex function of how the items relate. The\nliterature considers a hierarchy of valuation classes that includes subadditive, XOS (i.e. fractionally subadditive),\nsubmodular, and OXS valuations. Typically it is assumed that these valuations are known to the center or that they\ncome from a known distribution. Two recent lines of work, by Goemans et al. (SODA 2009) and by Balcan and\nHarvey (STOC 2011), have considered a more realistic setting in which valuations are learned from data, focusing\nspecifically on submodular functions.\nIn this paper we consider the approximate learnability of valuation functions at all levels in the hierarchy. We\nfirst study their learnability in the distributional learning (PAC-style) setting due to Balcan and Harvey (STOC 2011).\nWe provide nearly tight lower and upper bounds of \u0398\u0303(n1/2 ) on the approximation factor for learning XOS and\nsubadditive valuations, both important classes that are strictly more general than submodular valuations. Interestingly,\nwe show that the \u0398\u0303(n1/2 ) lower bound can be circumvented for XOS functions of polynomial complexity; we\nprovide an algorithm for learning the class of XOS valuations with a representation of polynomial size to within\nan O(n\u01eb ) approximation factor in running time nO(1/\u03b5) for any \u01eb > 0. We also establish learnability and hardness\nresults for subclasses of the class of submodular valuations, i.e. gross substitutes valuations and interesting subclasses\nof OXS valuations.\nIn proving our results for the distributional learning setting, we provide novel structural results for all these\nclasses of valuations. We show the implications of these results for the learning everywhere with value queries\nmodel, considered by Goemans et al. (SODA 2009).\nFinally, we also introduce a more realistic variation of these models for economic settings, in which information\non the value of a bundle S of goods can only be inferred based on whether S is purchased or not at a specific price.\nWe provide lower and upper bounds for learning both in the distributional setting and with value queries.\n\n\u2217 Georgia\n\nInstitute of Technology, ninamf@cc.gatech.edu\nInstitute of Technology, florin@cc.gatech.edu\n\u2021 Kyoto University, iwata@kurims.kyoto-u.ac.jp\n\u00a7 Georgia Institute of Technology, leiwang2007@gatech.edu\n\n\u2020 Georgia\n\n\f1 Introduction\nA central problem in commerce is understanding one's customers. Whether for assigning prices to goods, for deciding\nhow to bundle products, or for estimating how much inventory to carry, it is critical for a company to understand its\ncustomers' preferences. In Economics and Game Theory, these preferences are typically modeled as valuations, or\nmonotone set functions, over subsets of goods. It is usually assumed that consumers' valuations are known in advance\nto the company, or that they are drawn from a known distribution. In practice, however, these valuations must be\nlearned. For example, given past data of customer purchases of different bundles, a retailer would like to estimate how\nmuch a (typical) customer would be willing to pay for new packages of goods that become available. Companies may\nalso conduct surveys querying customers about their valuations1 .\nMotivated by such scenarios, in this paper we investigate the learnability of classes of functions commonly used to\nmodel consumers' valuations. In particular, we focus on a wide class of valuations expressing \"no complementarities\":\nthe value of the union of two disjoint bundles is no more than the sum of the values on each bundle - we henceforth use\nthe standard optimization terminology subadditive valuations. We provide upper and lower bounds on the learnability\nof valuation classes in a popular hierarchy [18, 24, 28, 29], with submodular functions (the only class with similar\nextant results [5, 17]) halfway in the hierarchy:\nOXS ( gross substitutes ( submodular (the only related learnability results [5, 17]) ( XOS ( subadditive\nWe analyze the learnability of these classes in the natural PMAC model [5] for approximate distributional learning.\nIn this model, a learning algorithm is given a collection S = {S1 , . . . , Sm } of polynomially many labeled examples\ndrawn i.i.d. from some fixed, but unknown, distribution D over points (sets) in 2[n] . The points are labeled by a fixed,\nbut unknown, target function f \u2217 : 2[n] \u2192 R+ . The goal is to output in polynomial time, with high probability, a\nhypothesis function f that is a good multiplicative approximation for f \u2217 over most sets with respect to D. More\nformally, we want:\nPrS1 ,...,Sm \u223cD [ PrS\u223cD [ f (S) \u2264 f \u2217 (S) \u2264 \u03b1f (S) ] \u2265 1 \u2212 \u01eb ] \u2265 1 \u2212 \u03b4\nfor an algorithm that uses m = poly(n, 1\u03b5 , \u03b41 ) samples and that runs in poly(n, 1\u03b5 , \u03b41 ) time. In contrast, the classical\nPAC model [32] requires predicting exactly (i.e. \u03b1 = 1) with high probability the values of f \u2217 over most sets with\nrespect to D. Thus the PMAC model can be viewed as an approximation-algorithms extension of the traditional PAC\nmodel.\nOur main results in the PMAC-learning model are for superclasses of submodular valuations, namely subadditive\nvaluations and XOS [13, 14, 24] (also known as fractionally subadditive [6, 15]) valuations. A XOS valuation represents a set of alternatives (e.g. travel destinations), where the valuation for subsets of goods (e.g. attractions) within\neach alternative is additive. The value of any set of goods, e.g. dining and skiing, is the highest value for these goods\namong all alternatives. That is, an XOS valuation is essentially a depth-two tree with a MAX root over SUM trees with\ngoods as leaves. XOS valuations are intuitive and very expressive: they can represent any submodular valuation [24]\nand can approximate any valuation in the subadditive superclass to a O(log n) factor [6, 12]. We also consider subclasses of submodular functions in the hierarchy, namely gross substitutes [10, 18] and OXS [9, 11, 14, 30] functions.\nGross substitutes valuations are characterized by the lack of pairwise synergies among items: for example, if the value\nof each of three items is the same, then no pair can have a strictly higher value than the other two pairs. Finally, the\nOXS class includes valuations representable as the SUM of MAX of item values. All these classes include linear\nvaluations.\nWe also analyze the model of approximate learning everywhere with value queries, due to Goemans et al. [17]. In\nthis model, the learner can adaptively pick a sequence of sets S1 , S2 , . . . and query the values f \u2217 (S1 ), f \u2217 (S2 ), . . . .\nUnlike the high confidence and high accuracy requirements of PMAC, this model requires approximately learning\nf \u2217 (*) with certainty on all 2n sets. We provide upper and lower bounds in this model for the same valuation classes.\nFinally, we introduce a more realistic variation of these models, in which the learner can obtain information only\nvia prices. This variation is natural in settings where an agent with valuation f \u2217 is interested in purchases of goods.\n1 See\n\ne.g. http://bit.ly/ls774D for an example of an airline asking customers for a \"reasonable\" price for in-flight Internet.\n\n1\n\n\fOur Results. We establish lower and upper bounds, the most general of them being almost tight, on the learnability\nof valuation classes in the aforementioned hierarchy.\n\u221a\n\u221a\n1. We show a nearly tight O( n) upper bound and \u03a9( n/ log n) lower bound on the learnability of XOS valuations in the PMAC model. The key element in our upper bound is to show\nthat any XOS function can be\n\u221a\napproximated by the square root of a linear function to within a factor O( n). Using this, we then reduce the\nproblem of PMAC-learning XOS valuations to the standard problem of\n\u221alearning linear separators in the PAC\nmodel which can be done via a number of efficient algorithms. Our \u03a9( n/ log n) lower bound is information\n\u221a\ntheoretic, applying to any procedure that uses a polynomial number of samples. We also show an O( n log n)\nupper bound on the learnability of subadditive valuations in the PMAC model.\n2. We establish a target-dependent learnability result for XOS functions. Namely, we show the class of XOS\nfunctions representable with at most R trees can be PMAC-learned to an O(R\u03b7 ) factor in time nO(1/\u03b7) for any\n\u03b7 > 0. In particular, for R polynomial in n, we get learnability to an O(n\u03b7 ) factor in time nO(1/\u03b7) for any \u03b7 > 0.\nTechnically, we prove this result via a novel structural result showing that a XOS function can be approximated\nwell by the L-th root of a degree-L polynomial over the natural feature representation of the set S. Conceptually,\nthis result highlights the importance of the complexity of the target function for polynomial time learning2.\n3. By exploiting novel structural results on approximability with simple functions, we provide much better upper\nbounds for other interesting subclasses of OXS and XOS. These include OXS and XOS functions with a small\nnumber of leaves per tree and OXS functions with a small number of trees. Some of these classes have been considered in the context of economic optimization problems [4, 6, 8], but we are the first to study their learnability.\nWe also show that the previous \u03a9\u0303(n1/3 ) lower bound for PMAC-learning submodular functions [5] applies to\nthe much simpler class of gross substitutes.\n4. The structural results we derive for analyzing learnability in the distributional learning setting also have implications for the model of exact learning with value queries [7, 17, 31]. In particular, they lead to new upper bounds\nfor XOS and OXS as well as new lower bounds for XOS, gross substitutes, and OXS.\n5. Finally, we introduce a new model for learning with prices in which the learner receives less information on\nthe values f \u2217 (S1 ), f \u2217 (S2 ), . . . : for each l, the learner can only quote a price pl and observe whether the agent\nbuys Sl or not, i.e. whether pl \u2264 f \u2217 (Sl ) or not. This model is more realistic in economic settings where agents\ninteract with a seller via prices only. Interestingly, many of our upper bounds, both for PMAC-learning and\nlearning with value queries, are preserved in this model (all lower bounds automatically continue to hold).\nOur results are summarized in Table 1. Note that all our upper bounds are efficient and all the lower bounds are\ninformation theoretic. Our analysis has a number of interesting byproducts that should be of interest to the Combinatorial Optimization community. For example, it implies that recent lower bounds of [7, 16, 17, 31] on optimization\nunder submodular cost functions also apply to the smaller classes of OXS and gross substitutes.\nRelated Work We study classes of valuations with fundamental properties (subadditivity and submodularity) or that\nare natural constructs used widely for optimization in economic settings [28]: XOS [6, 13, 14, 15, 24], i.e. MAX of\nSUMs, OXS [8, 9, 11, 30], i.e. SUM of MAXs, and gross substitutes, fundamental in allocation problems [2, 10, 18].\nWe focus on two widely studied learning paradigms: approximate learnability in a distributional setting [1, 21, 32,\n33] and approximate learning everywhere with value queries [7, 17, 22, 31]. In the first paradigm, we use a model\nintroduced by [5] for the approximate learnability of submodular functions. We circumvent the main negative result\nin [5] for certain interesting classes and match the main positive result in [5] for the more general XOS and subadditive\nclasses. With a few recent exceptions [17, 31], models for the value queries paradigm require exact learning and are\nnecessarily limited to much less general function classes than the ones we study here: read-once and Toolbox DNF\nvaluations [7], polynomial or linear-threshold valuations [23] or MAX or SUM (of bundles) valuations [22]. The latter\ntwo works also consider demand queries, where the learner can specify a set of prices and obtain a preferred bundle at\nthese prices. In contrast, in our variation of learning with prices, the learner and the agent focus on one price only (for\nthe current bundle) instead of as many as 2n prices.\n2 Since the class of XOS functions representable with at most a polynomial number of trees has small complexity, learnability would be immediate if we did not care about computational efficiency.\n\n2\n\n\fClasses of valuations\n\nPMAC [5]\n\nsubadditive\nXOS\nXOS with \u2264 R trees\n\n\u0398\u0303(n1/2 ) [this paper]\n\u0398\u0303(n1/2 ) [this paper]\nO(R\u03b5 ) [this paper]\n\nsubmodular\ngross substitutes\nOXS with \u2264 R trees\nor \u2264 R leaves per tree\n\nPMAC with prices\n\n\u0398\u0303(n1/2 ) [this paper]\n\u0398\u0303(n1/2 ) [this paper]\nO(R\u03b5 ) [this paper]\n(\u03a9\u0303(n1/3 ), O(n1/2 ))\n(\u03a9\u0303(n1/3 ), O(n1/2 )) [5]\n[this paper]\n\u03a9\u0303(n1/3 ) [this paper]\n\u03a9\u0303(n1/3 ) [this paper]\nO(R) [this paper]\n\nO(R) [this paper]\n\nValue Queries [17]\n\nVQ with prices\n\nO(n) [folklore]\nO(n) [this paper]\n1/2\n\u03a9\u0303(n ) [this paper] [17] \u03a9\u0303(n1/2 ) [this paper]\nO(R) [this paper]\nO(R) [this paper]\n\u0398\u0303(n1/2 ) [17]\n\n\u2013\n\n\u03a9\u0303(n1/2 ) [this paper]\n\n\u03a9\u0303(n1/2 ) [this paper]\n\nO(R) [this paper]\n\nO(R) [this paper]\n\nTable 1: Lower and upper bounds for learnability factors achievable in different models for standard classes of valuations (presented in decreasing order of generality). All the upper bounds refer to polynomial time algorithms. Our\nconstruction for the \u03a9(n1/2 / log n) = \u03a9\u0303(n1/2 ) lower bound on learning XOS valuations with value queries is simpler\nthan the construction for the same asymptotic lower bound of Goemans et al. [17].\nPaper structure After defining valuation classes and our models in Section 2, we study the distributional learnability\nof valuation classes in decreasing order of generality. First, Section 3 presents our results on XOS and subadditive\nvaluations, including our most general bounds, that are almost tight. Section 4 presents a hardness result for gross\nsubstitutes and positive results on several interesting subclasses of OXS. Section 5 provides positive results for most\nof these classes in learning with value queries. Finally, in Section 6 we show that many of our results extend to a\nnatural framework in economic applications, even though the learner receives less information in this framework.\n\n2 Preliminaries\nWe consider a universe [n] = {1, . . . , n} of items and valuations, i.e. monotone non-negative set functions f : 2[n] \u2192\nn\nR+ : f (S \u222a {i}) \u2265 f (S) \u2265 0, \u2200S \u2286 [n], \u2200i 6\u2208 S. For a set S \u2286 [n] we denote by \u03c7(S) \u2208 {0, 1} its indicator vector;\nn\nso (\u03c7(S))i = 1 if i \u2208 S and (\u03c7(S))i = 0 if i 6\u2208 S. We often use this natural isomorphism between {0, 1} and 2[n] .\nClasses of Valuation Functions. It is often the case that valuations are quite structured in terms of representation or\nconstraints on the values of different sets. We now define and give intuition for most valuation classes we focus on.\nThe following standard properties have natural interpretations in economic settings. A subadditive valuation models the lack of synergies among sets: a set's value is at most the sum of the values of its parts. A submodular valuation\nmodels decreasing marginal returns: an item j's marginal value cannot go up if one expands the base set S by item i.\nDefinition 1. A valuation f : 2[n] \u2192 R+ is called subadditive if and only if f (S \u222a S \u2032 ) \u2264 f (S) + f (S \u2032 ), \u2200S, S \u2032 \u2286 [n].\nA valuation f is called submodular if and only if f (S \u222a {i, j}) \u2212 f (S \u222a {i}) \u2264 f (S \u222a {j}) \u2212 f (S), \u2200S \u2286 [n], \u2200i, j 6\u2208 S.\nXOS is an important class of subadditive, but not necessarily submodular, valuations studied in combinatorial\nauctions [13, 14, 15, 24]. A valuation is XOS if and only if it can be represented as a depth-two tree with a MAX\nroot and SUM inner nodes. Each such SUM node has as leaves a subset of items with associated positive weights.\nFor example, a traveler may choose the destination of maximum value among several different locations, where each\nlocation has a number of amenities and the valuation for a location is linear in the set of amenities.\nDefinition 2. A valuation f is XOS if and only if it can be represented as the maximum of k linear valuations, for\nsome k \u2265 1. That is, f (S) = maxj=1...k wjT \u03c7(S) where wji \u2265 0, \u2200j = 1 . . . k, \u2200i = 1 . . . n.\nWe say that item i appears as a leaf in a SUM tree j if i has a positive value in tree j.\nAs already mentioned, any submodular valuation can be expressed as XOS3 . When reversing the roles of operators\nMAX and SUM we obtain a strict subclass of submodular valuations, called OXS,4 that is also relevant to auctions [11,\n3 As showin in [24], any submodular f can be represented as the MAX of n! SUM trees, each with n leaves: for every permutation \u03c0\nof [n], we build a SUM tree T\u03c0 with one leaf for each item j \u2208 [n], where item \u03c0(j) has weight its marginal value f ({\u03c0(1), . . . , \u03c0(j \u2212\n1), \u03c0(j)}) \u2212 f ({\u03c0(1), . . . , \u03c0(j \u2212 1)}).\n4 XOS and OXS stand for XOR-of-OR-of-Singletons and OR-of-XOR-of-Singletons, where MAX is denoted by XOR and SUM by OR[27, 29].\n\n3\n\n\f14, 24, 30]. To define OXS we also define a unit-demand valuation, in which the value of any set S is the highest\nweight of any item in S. A unit-demand valuation is essentially a tree, with a MAX root and one leaf for each item with\nnon-zero associated weight. In an OXS valuation, a set's value is given by the best way to split the set among several\nunit-demand valuations. An OXS valuation f has a natural representation as a depth-two tree, with a SUM node at the\nroot (on level 0), and subtrees5 corresponding to the unit-demand valuations f1 , . . . , fk . The value f (S) of any set S\ncorresponds to best way of partitioning S into (S1 , . . . , Sk ) and adding up the per-tree values {f1 (S1 ), . . . , fk (Sk )}.\nDefinition 3. A unit-demand valuation f is given by weights {w1 , ..., wn} \u2282 R+ such that f (S) = maxi\u2208S wi , \u2200S \u2286 [n].\nAn OXS valuation f is given by the convolution of k \u2265 1 unit-demand valuations f1 , . . . , fk : that is,\nf (S) = max{f1 (S1 ) + * * * + fk (Sk ) : (S1 , . . . , Sk ) is a partition of S}, \u2200S \u2286 [n].\n\nFinally, we consider gross substitutes (GS) valuations, of great interest in allocation problems [10, 18, 28]. Informally, an agent with a gross substitutes valuation would not buy fewer items of one type (e.g. skis) if items of another\ntype (e.g. snowboards) became more expensive. That is, items can be substituted one for another in a certain sense,\nwhich is not the case for, e.g. skis and ski boots. See Section 4 for a formal definition and more detailed discussion.\nAs already mentioned, the classes of valuations we reviewed thus far form a strict hierarchy. (See [24] for examples\nseparating these classes of valuations.)\nLemma 1. [24] OXS ( gross substitutes ( submodular ( XOS ( subadditive.\nOnly the class of submodular valuations has been studied from an approximate learning perspective [5, 17]. We\nstudy the approximate learnability of all other classes in this hierarchy, in a few natural models that we introduce now.\nDistributional Learning: PMAC. We primarily study learning in the PMAC model of [5]. We assume that the input\nfor a learning algorithm is a set S of polynomially many labeled examples drawn i.i.d. from some fixed, but unknown,\ndistribution D over points in 2[n] . The points are labeled by a fixed, but unknown, target function f \u2217 : 2[n] \u2192 R+ .\nThe goal is to output a hypothesis function f such that, with high probability over the choice of examples, the set of\npoints for which f is a good approximation for f \u2217 has large measure with respect to D. Formally:\nDefinition 4. We say that a family F of valuations is PMAC-learnable with approximation factor \u03b1 if there exists\nan algorithm A such that for any distribution D over 2[n] , for any target function f \u2217 \u2208 F , and for any sufficiently\nsmall \u03b5 \u2265 0, \u03b4 \u2265 0, A takes as input samples {(Si , f \u2217 (Si ))}1\u2264i\u2264m where each Si is drawn independently from D\nand outputs a valuation f : 2[n] \u2192 R such that PrS1 ,...,Sm \u223cD [ PrS\u223cD [ f (S) \u2264 f \u2217 (S) \u2264 \u03b1f (S) ] \u2265 1 \u2212 \u03b5 ] \u2265 1 \u2212 \u03b4.\nA must use m = poly(n, 1\u03b5 , 1\u03b4 ) samples and must have running time poly(n, 1\u03b5 , \u03b41 ).\n\nPMAC stands for Probably Mostly Approximately Correct (the PAC model [32] is a special case of PMAC with \u03b1 = 1).\nLearning with Value Queries. We also consider the model of learnability everywhere (in the same approximate sense)\nwith value queries. In this model, the learning algorithm is allowed to query the value of the unknown target function\nf \u2217 on a polynomial number of sets S1 , S2 , . . . , that may be chosen in an adaptive fashion. The algorithm must then\noutput in polynomial time a function f that approximates f \u2217 everywhere, namely f (S) \u2264 f \u2217 (S) \u2264 \u03b1f (S), \u2200S \u2286 [n].\nA formal definition of this model and the results are presented in Section 5.\nLearning with Prices. This framework aims to model economic interactions more realistically and considers a setting\nwhere an agent with the target valuation f \u2217 is interested in purchasing bundles of goods. In this framework, the learner\ndoes not obtain the value of f \u2217 on each input set S1 , S2 , . . . . Instead, for each input set Sl the learner quotes a price\npl on Sl and observes whether the agent purchases Sl or not, i.e. whether pl \u2264 f \u2217 (Sl ) or not. The goal remains to\napproximate the function f \u2217 well, i.e. within an \u03b1 multiplicative factor: on most sets from D with high confidence\nfor PMAC-learning and on all sets with certainty for learning everywhere with value queries. This framework and the\nassociated results are presented in Section 6.\n\n3 PMAC-learnability of XOS valuations and subadditive valuations\n\u221a\nIn this section we give nearly tight lower and upper bounds of \u0398\u0303( n) for the PMAC-learnability of XOS and subadditive valuations. In contrast, there is a \u0398\u0303(n1/6 ) gap between the existing bounds for submodular valuations [5].\n5 Another OXS encoding uses a weighted bipartite graph G\nn,k where edge (i, j) has the weight of item i in fj ; f (S) is the weight of a maximum\nmatching of S to the k nodes for the unit-demand fj 's. Also, OXS valuations with weights {0,1} are exactly rank functions of transversal matroids.\n\n4\n\n\fFurthermore, we reveal the importance of considering the complexity of the target function (in a natural representation) for polynomial-time PMAC learning. We show that XOS valuations representable with a polynomial number of\nSUM trees are PMAC-learnable to a n\u03b7 factor in time n1/\u03b7 , for any \u03b7 > 0. Finally, we show that XOS valuations\nrepresentable with an arbitrary number of SUM trees, each with at most R leaves, are PMAC-learnable to an R factor.\n\n3.1 Nearly tight lower and upper bounds for learning XOS and subadditive functions\n\u221a\n\u221a\nWe establish our \u0398\u0303( n) bounds by showing an \u03a9( n/log\n\u221a n) lower\n\u221a bound for the class of XOS valuations (hence\nvalid for subadditive valuations) and upper bounds of O( n) and O( n log n) for the classes of XOS and subadditive\nvaluations respectively. We note that our lower bound construction is much simpler and gives a better bound than the\n\u03a9(n1/3 / log n) construction of [5]. However, the latter construction is for matroid rank functions, a significantly\nsmaller class. For our upper bounds we provide\n\u221a structural\n\u221a results showing that XOS and subadditive functions can be\napproximated by a linear function to an O( n) and O( n ln n) factor respectively. We can then PMAC-learn these\nclasses via a reduction to the classical problem of PAC-learning a linear separator.\n\u221a\nTheorem 1. The classes of XOS and subadditive functions are PMAC-learnable to a \u0398\u0303( n) approximation factor.\nProof Sketch: Lower bound: We start with an information theoretic\nlower bound showing that the class of XOS\n\u221a\nn\nvaluations cannot be learned with an approximation factor of o( log n ) from a polynomial number of samples.\n1\n\n. For large enough n we can show that there exist sets\nLet k = n 3 log log n\u221a\n\u221aA1 , A2 , ..., Ak \u2286 [n] such that\n\u221a\n(i) n/2 \u2264 |Ai | \u2264 2 n for any 1 \u2264 i \u2264 k, i.e. all sets have large size \u0398( n) and\n(ii) |Ai \u2229 Aj | \u2264 log n for any 1 \u2264 i < j \u2264 k, i.e. all pairwise intersections have small size O(log n).\nWe achieve this via a simple probabilistic argument where we construct each Ai by picking\n\u221a each element in [n]\nwith probability \u221a1n . Let random variables Yi = |Ai | and Xij = |Ai \u2229Aj |. Obviously, E[Yi ] = n and E[Xij ] = 1. By\nChernoff bounds,\n\u221a\n\u0002\u221a\n\u221a \u0003\nln n\nPr\nn/2 < Yi < 2 n > 1 \u2212 2e\u2212 n/8 and Pr [ Xij > ln n ] < lnenln n = n\u2212(ln ln n\u22121) , \u22001 \u2264 i < j \u2264 k.\n\u221a\n\nBy union bound the probability that (i) and (ii) hold is at least 1 \u2212 2 k e\u2212 n/8 \u2212 k 2 n\u2212(ln ln n\u22121) > 0.\nGiven the existence of the family A = {A1 , . . . , Ak } of sets with properties (i) and (ii) above, we construct a\nhard family of XOS functions as follows. For any subfamily B \u2286 A, we construct an XOS function fB with large\nFor any subfamily\nvalues for sets Ai \u2208 B and small values for sets Ai 6\u2208 B. Let hAi (S) = |S \u2229 Ai | for any S \u2286 [n]. \u221a\nfB (Ai ) = \u03a9( n), if Ai \u2208 B\nB \u2286 A, define the XOS function fB by fB (S) = MAX Ai \u2208B hAi (S). We claim that \u221a\n\u221abut\nfB (Ai ) = O(log n), if Ai 6\u2208 B. Indeed, for any Ai \u2208 B, we have hAi (Ai ) = |Ai | \u2265 n/2, hence fB (Ai ) = \u03a9( n);\n|Ai \u2229 Aj | \u2264 log n, implying fB (Aj ) = O(log n). For\nfor any Aj 6\u2208 B, by our construction of A, we have hAi (Aj ) =\u221a\nan unknown B, the problem of learning fB within a factor of o( n/ log n) under a uniform distribution on A amounts\n1\nto distinguishing B from A. This is not possible from a polynomial number of samples since |A| = n 3 log log n\u221a. In\nparticular, if B \u2286 A is chosen at random, then any algorithm from a polynomial-sized sample will have error \u03a9( lognn )\n1\n.\non a region of probability mass greater than 21 \u2212 poly(n)\n\u221a\nUpper bounds: We show that the class of XOS valuations\nfactor and that the class\n\u221a can be PMAC-learned to a nO( n)\nn\n) training examples and\nof subadditive valuations can be PMAC-learned to a O( n log n) factor, by using O( \u01eb log \u03b4\u01eb\nrunning time poly(n, 1\u03b5 , 1\u03b4 ). To prove these bounds\n\u221a we start by providing a structural result (Claim 1 below) showing\nthat XOS valuations can be approximated to a n factor by the square root of a linear function.\nClaim 1. Let p\nf : 2[n] \u2192 R+ be a non-negative XOS function with f (\u2205) = 0. Then there exists a function f\u02c6 of the\n\u221a\n\u02c6\nform f (S) = wT \u03c7(S) where w \u2208 Rn+ such that f\u02c6(S) \u2264 f (S) \u2264 nf\u02c6(S) for all S \u2286 [n].\n\n[n]\nProof. XOS valuations are known [15] to beP\nequivalent to fractionally subadditive\nPvaluations. A function f : 2 \u2192 R\nis called fractionally subadditive if f (T ) \u2264 S \u03bbS f (S) whenever \u03bbS \u2265 0 and S:s\u2208S \u03bbS \u2265 1 forPany s \u2208 T .\nWe can show the following property of XOS valuations:\nP for any XOS f we have f (T ) = max { i\u2208T xi |x \u2208 P (f )},\nwhere P (f ) is the associated polyhedron {x \u2208 Rn+ : i\u2208S xi \u2264 f (S), \u2200S \u2286 [n]}. Informally, this result states that\none recovers f (T ) when optimizing in the direction given by T over the polyhedron P (f ) associated with f . The\n\n5\n\n\fproof of this result involves a pair of dual linear programs, one corresponding to the maximization and another one\nthat isPtailored for fractional subadditivity, with an optimal objective\nPvalue of f (T ). Formally, for any T \u2286 [n] we\nhave i\u2208T xi \u2264 f (T ) for any x \u2208 P (f ). Therefore f (T ) \u2265 max { i\u2208T xi |x \u2208 P (f )}. Now we prove that in fact\nX\nf (T ) \u2264 max {\nxi |x \u2208 P (f )}.\ni\u2208T\n\nConsider the linear programming (LP1) for the quantity max {x(T )|x \u2208 P (f )} and its dual (LP2): we assign a dual\nvariable yS for each constraint in (LP1), and we have a constraint corresponding to each primal variable indicating that\nthe total amount of dual corresponding to a primal variable should not exceed its coefficient in the primal objective.\nmax\n\nX\n\nxi\n\nmin\n\n(LP1)\n\nX\ni\u2208S\n\nxi \u2264 f (S)\nxi \u2265 0\n\nyS f (S)\n\n(LP2)\n\nyS \u2265 1\n\n\u2200i \u2208 T,\n\nyS \u2265 0\n\n\u2200S \u2286 [n].\n\nS\u2286[n]\n\ni\u2208T\n\ns.t.\n\nX\n\n\u2200S \u2286 [n],\n\ns.t.\n\nX\n\nS:i\u2208S\n\n\u2200i \u2208 [n].\n\nThe classical theory of linear optimization gives that the optimal primal solution equals the optimal dual solution.\nLet y \u2217 be an optimal solution of (LP2). Therefore\nX\nyS\u2217 f (S) = max {x(T )|x \u2208 P (f )}.\nS\u2286[n]\n\nP\nP\nSince f is fractionally subadditive and S:i\u2208S yS\u2217 \u2265 1, \u2200i \u2208 T , we have f (T ) \u2264 S\u2286[n] yS\u2217 f (S), hence f (T ) \u2264\nP\nmax {x(T )|x \u2208 P (f )}. This completes the proof of the fact that f (T ) = max { i\u2208T xi |x \u2208 P (f )}.\nGiven this result, we proceed as follows (a very similar approach is used by [17] for submodular functions). Define\nP = {x \u2208 Rn : (|x1 |, ..., |xn |) \u2208 P (f )}. Since P is bounded and central symmetric (i.e. x \u2208 P \u21d4 \u2212x \u2208 P ), there\nP\nexists [20] an ellipsoid E containing P such that \u221a1n E is contained in P . Hence for f\u02c6(T ) = max{ i\u2208T xi : x \u2208 \u221a1n E},\np\n\u221a\nwe have f\u02c6(T ) \u2264 f (T ) \u2264 nf\u02c6(T ), \u2200T \u2286 [n]. At last, basic calculus implies f\u02c6(T ) = wT \u03c7(T ) for some w \u2208 Rn+ .\n\u221a\nFor PMAC-learning XOS valuations to with an approximation factor of n + \u03b5, we apply Algorithm 1 with\nparameters R = n, \u01eb, and p = 2. The proof of correctness of Algorithm 1 follows by using the structural result in\nClaim 1 and a technique of [5] that we sketch briefly here. Full details of this proof appear in Appendix A.\nAssume first that f \u2217 (S) > 0 for all S 6= \u2205. The key idea is that Claim 1's structural result implies that the following\nexamples in Rn+1 are linearly separable since nwT \u03c7(S) \u2212 (f \u2217 (S))2 \u2265 0 and nwT \u03c7(S) \u2212 (n + \u01eb)(f \u2217 (S))2 < 0.\nExamples labeled +1:\nExamples labeled \u22121:\n\n\u2217\n2\nex+\nS := (\u03c7(S), (f (S)) )\n\u2212\nexS := (\u03c7(S), (n + \u01eb) * (f \u2217 (S))2 )\n\n\u2200S \u2286 [n]\n\u2200S \u2286 [n]\n\nThis suggests trying to reduce our learning problem to the standard problem of learning a linear separator for these\nexamples in the standard PAC model [21, 33]. However, in order to apply standard techniques to learn such a linear\nseparator, we must ensure that our training examples are i.i.d. To achieve this, we create a i.i.d. distribution D\u2032 in\nRn+1 that is related to the original distribution D as follows. First, we draw a sample S \u2286 [n] from the distribution D\n\u2212\nand then flip a fair coin for each. The sample from D\u2032 is labeled ex+\nS i.e. +1 if the coin is heads and exS i.e. \u22121 if the\nn+1\ncoin is tails. As mentioned above, these labeled examples are linearly separable in R\n. Conversely, suppose we can\nfind a linear separator that classifies most of the examples coming from D\u2032 correctly. Assume that this linear separator\nin Rn+1 is defined by the function uT x = 0, where u = (\u0175, \u2212z), w \u2208 Rn and z > 0. The key observation is that the\n1\nfunction f (S) = (n+\u01eb)z\n\u0175T \u03c7(S) approximates (f \u2217 (*))2 to within a factor n + \u01eb on most of the points coming from D.\n\u2217\nIf f is zero on non-empty sets, then we can learn its set Z = { S : f \u2217 (S) = 0 } of zeros quickly since Z is\nclosed to union and taking subsets for any subadditive f \u2217 . In particular, suppose that there is at least an \u01eb chance that\na new example is a zero of f \u2217 , but does not lie in the null subcube over the sample. Then such a example should be\nseen in the next sequence of log(1/\u03b4)/\u01eb examples, with probability at least 1 \u2212 \u03b4. This new example increases the\ndimension of the null subcube by at least one, and therefore this can happen at most n times.\n6\n\n\fTo establish learnability for the class of subadditive valuations, we note that any subadditive valuation can be\napproximated by\u221aan XOS valuation to a ln n factor [12, 6] 6 and so, by Claim 1, any subadditive valuation is approximated to a n ln n factor by a linear function. This then implies that we can use Algorithm 1 with parameters\nR = n ln2 n, \u01eb, and p = 2. Correctness then follows by a reasoning similar to the one for XOS functions.\nAlgorithm 1 Algorithm for PMAC-learning via a reduction to a binary linear separator problem.\nInput: Parameters: R, \u01eb and p. Training examples S = {(S1 , f \u2217 (S1 )), . . . , (Sm , f \u2217 (Sm ))}.\n\u2022 Let S6=0 = {(Ai , f \u2217 (Ai )) \u2208 S : f \u2217 (Ai ) 6= 0} \u2286 S the examples with non-zero values, S0 = S \\ S6=0 and\nU0 = \u222al\u2264m;f \u2217 (Sl )=0 Sl .\n\u2022 For each i in {1, . . . , |S6=0 |} let yi be the outcome of independently flipping a fair {+1, \u22121}-valued coin.\n(\n( \u03c7(Ai ), (f \u2217 (Ai ))p )\n(if yi = +1)\nn+1\nLet xi \u2208 R\nbe the point defined by xi =\n\u2217\np\n( \u03c7(Ai ), (R + \u01eb) * (f (Ai )) )\n(if yi = \u22121).\n\u2022 Find a linear separator u = (\u0175, \u2212z) \u2208 Rn+1 , where \u0175 \u2208 Rn and z > 0, such that (x, sgn(uT x)) is consistent\nwith the labeled examples (xi , yi ) \u2200i \u2208 {1, . . . , |S6=0 |}, and with the additional constraint that \u0175j = 0 \u2200j \u2208 U0 .\n\u0010\n\u00111/p\n1\nOutput: The function f defined as f (S) = (R+\u01eb)z\n\u0175T \u03c7(S)\n.\n\n3.2 Better learnability results for XOS valuations with polynomial complexity\nIn this section we consider the learnability of XOS valuations representable with a polynomial number of trees. Since\nthis class has small complexity, it is easy to see that it is learnable in principle from a small sample size if we did\nnot care about computational complexity. Interestingly we can show that we can achieve good PMAC learnability via\npolynomial time algorithms. In particular, we show that XOS functions representable with at most R SUM trees can\nbe PMAC-learned with a R\u03b7 approximation factor in time nO(1/\u03b7) , for any \u03b7 > 0. This improves the approximation\nfactor of Theorem 1 for all such XOS functions. Moreover, this implies that XOS valuations representable with a\npolynomial number of trees can be PMAC-learned within a factor of n\u03b7 , in time nO(1/\u03b7) , for any \u03b7 > 0.\nO(1)\nTheorem 2. For any \u03b7 > 0, the class of XOS functions representable with at most\nR=\nSUM treesi\u0011is PMAChn\n\u0010 1/\u03b7\n\u0001\nlog(n)\n1\nn\ntraining\n+\nlog \u03b4\u01eb\nlearnable in time nO(1/\u03b7) with approximation factor of (R + \u03b5)\u03b7 by using O\n\u01eb\n\u03b7\nexamples.\n\nProof. Let L = 1/\u03b7 and assume for simplicity that it is integer. We start by deriving a key structural result. We show\nthat XOS functions can be approximated well by the L-th root of a degree-L polynomial over (\u03c7(S))i for i \u2208 [n].\nLet T1 , . . . , TR be the R SUM trees in an XOS representation T of f \u2217 . For a tree P\nj and a leaf in Tj corresponding\nto an element i \u2208 [n], let wji the weight of the leaf. For any set S, let kj (S) = i\u2208Tj \u2229S wji = wjT \u03c7(S) be the\nsum of weights in tree Tj corresponding to leaves in S. kj (S) is the value assigned to set S by tree Tj . Note that\n\u2032\nf \u2217 (S) = maxj kj (S), i.e. the maximum value of any tree, from the definition\nP L of MAX . We define valuation\u2032 f\n\u2032\nthat averages the L-th powers of the values of all trees: f (S) = 1/R j kj (S), \u2200S \u2286 [n]. We claim that f (*)\napproximates (f \u2217 (*))L to within an R factor on all sets S, namely\nP\nP\n(1)\nf \u2032 (S) \u2264 (f \u2217 (S))L \u2264 Rf \u2032 (S), \u2200S \u2286 [n] i.e. 1/R j kjL (S) \u2264 maxj kjL (S) \u2264 j kjL (S), \u2200S \u2286 [n]\n\nThe left-hand side inequalities in Eq. (1) follow as f \u2217 has at most R trees and kjL\u2032 (S) \u2264 maxj kjL (S) for any tree Tj \u2032 .\nThe right-hand side inequalities in Eq. (1) follow immediately.\nThis structural result suggests re-representing each set S by a new set of \u0398(nL ) features, with one feature for each\nsubset of [n] with at most L items. Formally, for any set S \u2286 [n], we denote by \u03c7M (S) its feature representation\n6 We\n\nare grateful to Shahar Dobzinski and Kshipra Bhawalkar for pointing out this fact to us.\n\n7\n\n\fover this new set of features. \u03c7M (S)i1 ,i2 ,...,iL = 1 if all items i1 , i2 , . . . iL appear in S and \u03c7M (S)i1 ,i2 ,...,iL = 0\notherwise. It is easy to see that f \u2032 is representable as a linear function over this new set of features. This holds for each\nkjL (S) = (wjT \u03c7(S))L due to its multinomial expansion, that contains one term for each set of up to L items appearing\nin tree Tj , i.e. for each such feature. Furthermore, f \u2032 remains linear when the terms for each tree Tj are added.\nGiven this, we can now use a variant of Algorithm 1 with parameters R, \u01eb, and p = L and to prove correctness we\ncan use a reasoning similar to the one in Theorem 1. Any sample Sl is fed into Algorithm 1 as (\u03c7M (Sl ), (f \u2217 (Sl ))L ) or\n(\u03c7M (Sl ), (R+\u01eb)*(f \u2217 (Sl ))L ) respectively. Since f \u2032 is linear over the set of features, Algorithm 1 outputs with probability at least 1\u2212\u03b4 a hypothesis f \u2032\u2032 that approximates f \u2217 to an (R+\u03b5)1/L factor on any point \u03c7M (S) corresponding to sets\nS \u2286 [n] from a collection S with at least an 1 \u2212 \u03b5 measure in D, i.e. f \u2032\u2032 (\u03c7M (S)) \u2264 f \u2217 (S) \u2264 (R + \u03b5)1/L f \u2032\u2032 (\u03c7M (S)).\nWe can output then hypothesis f (S) = f \u2032\u2032 (\u03c7M (S)), \u2200S \u2286 [n], defined on the initial ground set [n] of items, that\napproximates f \u2217 (*) well, i.e. for any S \u2208 S we have\nf (S) = f \u2032\u2032 (\u03c7M (S)) \u2264 f \u2217 (S) \u2264 (R + \u03b5)1/L f \u2032\u2032 (\u03c7M (S)) = (R + \u03b5)1/L f (S)\nAs desired, with high confidence the hypothesis f approximates f \u2217 to a (R + \u03b5)\u03b7 factor on most sets from D.\nThis result has an appealing interpretation in terms of representations of submodular functions. We know that any\nsubmodular function is representable as an XOS tree. What Theorem 2 implies is that (submodular) functions that are\nsuccinctly representable as XOS trees can be PMAC-learned well. Theorem 2 is thus a target-dependent learnability\nresult, in that the extent of learnability of a function depends on the function's complexity.\n\n3.3 Better learnability results for XOS valuations with small SUM trees\nIn this section we consider the learnability of another interesting subclass of XOS valuations, namely XOS valuations\nrepresentable with \"small\" SUM trees and show learnability to a better factor than that in Theorem 1. For example,\nconsider a traveler deciding between many trips, each to a different location with a small number of tourist attractions.\nThe traveler has an additive value for several attractions at the same location. This valuation can be represented as\nan XOS function where each SUM tree stands for a location and has a small number of leaves. We now show good\nPMAC-learning guarantees for classes of functions of this type.\nTheorem 3. For any \u03b7 > 0, the class of XOS functions representable with SUM trees with at most R leaves \u0001is\nproperly PMAC-learnable with approximation factor of R(1 + \u03b7) by using m = O( 1\u01eb n log log1+\u03b7 ( H\nh ) + log(1/\u03b4) )\nand running time polynomial in m, where h and H are the smallest and the largest non-zero values our functions can\ntake.\nProof. We show that the unit-demand hypothesis f output by Algorithm 2 produces the desired result. The algorithm\nconstructs a unit demand hypothesis function f as follows. For any i that appears in at least one set Sj in the sample\nwe define f (i) as the smallest value f \u2217 (Sj ) over all the sets Sj in the sample containing i. For i that does not appear\nin any set Sj define f (i) = 0.\nWe start by proving a key structural result showing that f approximates the target function multiplicatively within\na factor of R over the sample. That means:\nf (Sl ) \u2264 f \u2217 (Sl ) \u2264 Rf (Sl )\n\nfor all l \u2208 {1, 2, . . . , m}.\n\n(2)\n\nTo see this note that for any i \u2208 Sl we have f \u2217 (i) \u2264 f \u2217 (Sl ), for l \u2208 {1, 2, . . . , m}. So\nf (i) \u2265 f \u2217 (i) for any i \u2208 S1 \u222a . . . \u222a Sm .\n\n(3)\n\nTherefore for any l \u2208 {1, 2, . . . , m}. :\nf \u2217 (Sl ) \u2264 R max f \u2217 (i) \u2264 R max f (i) = Rf (Sl ),\ni\u2208Sl\n\ni\u2208Sl\n\nwhere the first inequality follows by definition, and the second inequality follow from relation (3). By definition, for\nany i \u2208 Sl , f (i) \u2264 f \u2217 (Sl ). Thus, f (Sl ) = maxi\u2208Sl f (i) \u2264 f \u2217 (Sl ). These together imply relation (2), as desired.\n8\n\n\fAlgorithm 2 Algorithm for PMAC-learning interesting classes of XOS and OXS valuations.\nInput: A sequence of training examples S = {(S1 , f \u2217 (S1 )), (S2 , f \u2217 (S2 )), . . . (Sm , f \u2217 (Sm ))}.\nm\n\u2022 Set f (i) = minj:i\u2208Sj f \u2217 (Sj ) if i \u2208 \u222am\nl=1 Sl and f (i) = 0 if i 6\u2208 \u222al=1 Sl .\n\nOutput: The unit-demand valuation f defined by f (S) = maxi\u2208S f (i) for any S \u2286 {1, . . . , n}.\n\u0001\nTo finish the proof we show that m = O( 1\u01eb n log log1+\u03b7 ( H\nh ) + log(1/\u03b4) ) is sufficient so that with probability at\nleast 1 \u2212 \u03b4 f approximates the target function f \u2217 multiplicatively within a factor of R(1 + \u03b7)2 on a 1 \u2212 \u01eb fraction of\nthe distribution. Let F\u03b7 be the class of unit-demand functions that assign to each individual leaf a power\n\u0001 of (1 + \u03b7) in\n1\nH\nn\n[h, H]. Clearly |F\u03b7 | = (log1+\u03b7 ( H\n))\n.\nIt\nis\neasy\nto\nsee\nthat\nm\n=\nO(\n)\n+\nlog(1/\u03b4)\n) examples are\nn\nlog\nlog\n(\n1+\u03b7 h\nh\n\u01eb\nsufficient such that any function in F\u03b7 that approximates the target function on the sample multiplicatively within a\nfactor of R(1 + \u03b7) will with probability at least 1 \u2212 \u03b4 approximate the target function multiplicatively within a factor\nof R(1 + \u03b7) on a 1 \u2212 \u01eb fraction of the distribution. Since F\u03b7 is a multiplicative L\u221e cover for the class of unit-demand\nfunctions, we easily get the desired result [1].\n\n4 PMAC-learnability of OXS and Gross Substitutes Valuations\nIn this section we study the learnability of subclasses of submodular valuations, namely OXS and gross substitutes. We\nstart by focusing on interesting subclasses of OXS functions that arise in practice, namely OXS functions representable\nwith a small number of MAX trees or leaves7 . For example, a traveler presented with a collection of plane tickets,\nhotel rooms, and rental cars for a given location might value the bundle as the sum of his values on the best ticket,\nthe best hotel room, and the best rental car. This valuation is OXS, with one MAX tree for each travel requirement.\nThe number of MAX trees, i.e. travel requirements, is small but the number of leaves in each tree may be large. As\nanother example, consider for example a company producing airplanes that must procure many different components\nfor assembling an airplane. The number of suppliers for each component is small, but the number of components may\nbe very large (more than a million in today's airplanes). The company's value for a set of components of the same\ntype, each from a different supplier, is its highest value for any such component. The company's value for a set of\ncomponents of different types is the sum of the values for each type. This valuation is representable as an OXS, with\none tree for each component type. The number of leaves, i.e. suppliers, in each MAX tree is small but there may be\nmany such trees. In this section, we show good PMAC-learning guarantees for classes of functions of these types.\nFormally:\nTheorem 4. (1) Let F be the family of OXS functions representable with at most R MAX trees. For any \u03b7, the family \u0001\nF is properly PMAC-learnable with approximation factor of R(1+\u03b7) by using m = O( 1\u01eb n log log1+\u03b7 ( H\nh ) + log(1/\u03b4) )\ntraining examples and running time polynomial in m, where h and H are the smallest and the largest value our functions can take. For constant R, the class F is PAC-learnable by using O(nR log(n/\u03b4)/\u03b5) training examples and\nrunning time poly(n, 1/\u01eb, 1/\u03b4).\n(2) For any \u01eb > 0, the class of OXS functions representable\n\u0001 with MAX trees with at most R leaves is PMACn\nlearnable with approximation factor R+\u01eb by using O( n\u01eb log \u03b4\u01eb\n) training examples and running time poly(n, 1/\u01eb, 1/\u03b4).\nProof sketch. (1) We can show that a function f with an OXS representation T with at most R trees can also be\nrepresented as an XOS function with at most R leaves per tree. Indeed, for each tuple of leaves, one from each tree in\nT , we create an SUM tree with these leaves. The XOS representation of f \u2217 is the MAX of all these trees. Given this\nthe fact that F is learnable to a factor of of R(1 + \u03b7) for any \u03b7 follows from Theorem 3.\nWe now show that when R is constant the class F is PAC-learnable. First, using a similar argument to the\none in Theorem 3 we can show that Algorithm 2 can be used to PAC-learn any unit-demand valuation by using\nm = O(n ln(n/\u03b4)/\u03b5) training examples and time poly(n, 1/\u01eb, 1/\u03b4) \u2013 see Lemma 3 in Appendix B. Second, it is easy\n7 We note that the literature on algorithms for secretary problems [3, 4] often considers a subclass of the latter class, in which each item must\nhave the same value in any tree.\n\n9\n\n\fto see that an OXS function f \u2217 representable with at most R trees can also be represented as a unit-demand with at\nmost nR leaves, with R-tuples as items (see Lemma 4 in Appendix B). These two facts together imply that for constant\nR, the class F is PAC-learnable by using O(nR log(n/\u03b4)/\u03b5) training examples and running time poly(n, 1/\u01eb, 1/\u03b4).\n(2) We start by showing the following structural result: if f \u2217 has an OXSrepresentation with at most R leaves in\nany MAX tree, then it can be approximated by a linear function\nwithin a factor of R on every subset of the ground\nP\nset. In particular, the linear function f defined as f (S) = i\u2208S f \u2217 (i), for all S \u2286 {1 . . . n} satisfies\nf \u2217 (S) \u2264 f (S) \u2264 R * f \u2217 (S)\n\nfor all\n\nS \u2286 {1 . . . n}\n\n(4)\n\nBy subadditivity, f \u2217 (S) \u2264 Rf (S), for all S. Let f \u2217 1 , . . . f \u2217 k be the unit-demand functions that define f \u2217 . Fix\na set S \u2286 [n]. For any item i \u2208 S, define ji to be the index of the f \u2217 j under which item i has highest value:\nfP\u2217 (i) = f \u2217 ji ({i}). Then for the partition (S1 , ..., Sk ) of S in which item i is mapped to Sji for any i, we have\n\u2217\n\u2217\n\u2217\ni\u2208S f (i) \u2264 Rf 1 (S1 ) + . . . Rf k (Sk ). Therefore:\nP\nf (S) = R1 i\u2208S f \u2217 (i) \u2264 max(S1 ,...,Sk ) partition of S (f \u2217 1 (S1 ) + * * * + f \u2217 k (Sk )) = f \u2217 (S),\nwhere the last equality follows simply from the definition of an OXS function.\nGiven the structural result 4, we can PMAC-learn the class of OXS functions representable with MAX trees with\nat most R leaves y using Algorithm 1 with parameters R, \u01eb and p = 1. The correctness by using a reasoning similar to\nthe one in Theorem 1.\n\nWe now consider the class of Gross Substitutes valuations, a superclass of OXS valuations and a subclass of\nsubmodular valuations (recall Lemma 1). Gross Substitutes are fundamental to allocation problems with per-item\nprices [10, 18, 28]; in particular a set of per-item market-clearing prices exists if and (almost) only if all customers\nhave gross substitutes valuations. A valuation is gross substitutes if raising prices on some items preserves the demand\non other items. Given prices on items, an agent with valuation f demands a preferred set, formalized as follows.\nDefinition 5. For price vector ~\np \u2208 Rn , the demand correspondence\nDf (~\np) of valuation f is the collection of preferred\nP\nsets at prices ~p, i.e. Df (~\np) = arg maxS\u2286{1,...,n} {f (S) \u2212 j\u2208S pj }. A valuation f is gross substitutes (GS) if for any\nprice vectors p~\u2032 \u2265 ~\np (i.e. p\u2032i \u2265 pi \u2200i \u2208 [n]), and any A \u2208 Df (~\np) there exists A\u2032 \u2208 Df (~\np\u2032 ) with A\u2032 \u2287 {i \u2208 A : pi = p\u2032i }.\nThat is, the GS property requires that all items i in some preferred set A at the old prices p~ and for which the old\nand new prices are equal (pi = p\u2032i ) are simultaneously contained in some preferred set A\u2032 at the new prices ~p\u2032 .\nAs mentioned earlier Balcan and Harvey [5] proved that it is hard to PMAC-learn the class of submodular functions with an approximation factor o(n1/3 / log n). We show here that their result applies even for the class of gross\nsubstitutes. This is quite surprising since such functions are typically considered easy from an economic optimization\npoint of view. Specifically:\nTheorem 5. No algorithm can PMAC-learn the class of gross substitutes with an approximation factor of o(n1/3 /log n).\nThis holds even if D is known and value queries are allowed.\nProof. It is known that the class of matroid rank functions cannot be PMAC-learned with an approximation factor of\no(n1/3 /log n), even if D is known and value queries are allowed [5]. One can show that a matroid rank function is a\ngross substitutes function (see Lemma 2 below). Combining these, yields the theorem.\nOur key tool for proving that any matroid rank function is also GS (Lemma 2 below) is a valuation-based characterization of gross substitutes valuations due to [25].\nLemma 2. A matroid rank function is gross substitutes.\nProof. Denote f 's marginal value over S by f S (A) = f (S \u222a A) \u2212 f (S), \u2200A \u2286 [n]\\S. As shown in [25] f is GS if\nand only if\nf S (ab) + f S (c) \u2264 max{f S (ac) + f S (b), f S (bc) + f S (a)} for all items a, b, c and set S\n\n(5)\n\ni.e. (by taking permutations) there is no unique maximizer among f S (ab) + f S (c), f S (ac) + f S (b), f S (bc) + f S (a).\n10\n\n\fIf f is matroid rank function, then so is f S ; in particular, f S (A) \u2264 |A|, \u2200A \u2286 [n]\\ S. We reason by case analysis.\nSuppose that f S (ab) = 2. Then we have f S (a) = f S (b) = 1. If f S (ac) = 2 or f S (bc) = 2, then f S (c) = 1 and\nhence the inequality (5) holds. On the other hand, if f S (ac) = f S (bc) = 1, then we have by the monotonicity and\nsubmodularity of f S , f S (ab) + f S (c) \u2264 f S (abc) + f S (c) \u2264 f S (ac) + f S (bc) = 2, and the inequality (5) holds.\nIf f S (ab) \u2264 1 then f S (ab) = max{f S (a), f S (b)}. As f S (c) \u2264 f S (ac) and f S (c) \u2264 f S (bc), Eq. (5) follows.\nWe note that Lemma 2 was previously proven in [26] in a more involved way via the concept of M\u266e -concavity\nfrom discrete convex analysis.\n\n5 Learnability everywhere with value queries\nIn this section, we consider approximate learning with value queries [17, 31]. This is relevant for settings where\ninstead of passively observing the values of f \u2217 on sets S drawn from a distribution, the learner is able to actively query\nthe value f \u2217 (S) on sets S of its choice and the goal is to approximate with certainty the target f \u2217 on all 2n sets after\nquerying the values of f \u2217 on polynomially many sets. Formally:\nDefinition 6. We say that an algorithm A learns the valuation family F everywhere with value queries with an\napproximation factor of \u03b1 \u2265 1 if, for any target function f \u2217 \u2208 F , after querying the values of f \u2217 on polynomially (in\nn) many sets, A outputs in time polynomial in n a function f such that f (S) \u2264 f \u2217 (S) \u2264 \u03b1f (S), \u2200S \u2286 {1, . . . , n}.\nGoemans et al. [17] show that for submodular functions the learnability factor with value queries is \u0398\u0303(n1/2 ). We\nshow here that their lower bound applies to the more restricted OXS and GS classes (their upper bound automatically\napplies). We also show that this lower bound can be circumvented for the interesting subclasses of OXS and XOS\nthat we considered earlier, efficiently achieving a factor of R.\nTheorem 6. (1) The classes of OXS and GS functions are learnable with value queries with an approximation factor\nof \u0398\u0303(n1/2 ).\n(2) The following classes are learnable with value queries with an approximation factor of R: OXS with at most\nR leaves in each tree, OXS with at most R trees, XOS with at most R leaves in each tree, and XOS with at most R\ntrees.\n1/2\n\nn\nProof Sketch. (1) We show in Appendix C that the family of valuation functions used in [17] for proving the \u03a9( log\nn)\nlower bound for learning submodular valuations with value queries is contained in OXS. The valuations in this family\nare of the form g23 (S) = min(|S|, \u03b1\u2032 ) and g R (S) = min(\u03b2 + |S \u2229(({1, . . . , n})\\ R)|, |S|, \u03b1\u2032 ) for \u03b1\u2032 = xn1/2 /5, \u03b2 =\nx2 /5 with x2 = \u03c9(log n) and R a subset of {1, . . . , n} of size \u03b1\u2032 (chosen uniformly at random). These valuations are\nOXS; for example, g23 (S) can be expressed as a SUM of \u03b1\u2032 MAX trees, each having as leaves all items in [n] with\nweight 1.\n(2) To establish learnability for these interesting subclasses, we recall that for the first three of them (Theorems 3\nand 4) any valuation f \u2217 in each class was approximated to an R factor by a function f that only depended on the\nvalues of f \u2217 on items. An\nanalogous result holds for the fourth\nclass, i.e. XOS with at most R trees \u2013 indeed, for such\n1 P\n1 P\n\u2217\n\u2217\n\u2217\nf\n({i})\n\u2264\nf\n(S)\n\u2264\nR\nf\n({i}), \u2200S \u2286 [n]. One can then query these n values\nan XOS f \u2217 , we have R\ni\u2208S\ni\u2208S\nR\nand output the corresponding valuation f .\n\nNote: We note that the lower bound technique in [17] has been later used in a sequence of papers [19, 16, 31]\nconcerning optimization under submodular cost functions and our result (Lemma 6 in particular) implies that all the\nlower bounds in these papers apply to the smaller classes of OXS functions and GS functions.\nNote: We also note that since XOS contains all submodular valuations, the lower bound of Goemans et al. [17]\nn1/2\n1/2\n) factor. For the same\nimplies that the XOS class is not learnable everywhere with value queries to a o( log\nn ) = \u00f5(n\n1/2\n\nn\n\u03a9( log\nn ) lower bound, our proof technique (and associated family of XOS valuations) for Theorem 1 offers a simpler\nargument than that in [17].\n\n11\n\n\f6 Learning with prices\nWe now introduce a new paradigm that is natural in many applications where the learner can repeatedly obtain information on the unknown valuation function of an agent via the agent's decisions to purchase or not rather than via\nrandom samples from this valuation or via queries to it. In this framework, the learner does not obtain the value of f \u2217\non each input set S1 , S2 , . . . . Instead, for each input set Sl , the learner observes Sl , quotes a price pl (of its choosing)\non Sl and obtains one bit of information: whether the agent purchases Sl or not, i.e. whether pl \u2264 f \u2217 (Sl ) or not. The\ngoal remains to approximate the function f \u2217 well, i.e. within an \u03b1 multiplicative factor: on most sets from D with high\nconfidence for PMAC-learning and on all sets with certainty for learning everywhere with value queries. The learner's\nchallenge is in choosing prices that allow discovery of the agent valuation. This framework is a special case of demand\nqueries [28], where prices are: pl on Sl and \u221e elsewhere. We call PMAC-learning with prices and VQ-learning with\nprices the variants of this framework applied to our two learning models. Each variant in this framework offers less\ninformation to the learner than its respective basic model.\nClearly, all our PMAC-learning lower bounds still hold for PMAC-learning with prices. More interestingly, our\nupper bounds still hold as well. In particular, we provide a reduction from the problem of PMAC-learning with prices\nto the problem of learning a linear separator, for functions f \u2217 such that for some p > 0, (f \u2217 )p can be approximated\nto a \u03b2 factor by a linear function. Such f \u2217 can be PMAC-learned to a \u03b2 1/p factor by Algorithm 1. What we show\nin Theorem 7 below is that such f \u2217 are PMAC-learnable with prices to a factor of (1 + o(1))\u03b2 1/p using only a small\nincrease in the number of samples over that used for (standard) PMAC learning. For convenience, we assume in this\nsection that all valuations are integral and that H is an upper bound on the values of f \u2217 , i.e. f \u2217 (S) \u2264 H, \u2200S \u2286 [n].\nTheorem 7. Consider a family F of valuations such that the p-th power of any f \u2217 \u2208 F can be approximated to a\n\u03b2 factor by a linear function: i.e., for some w we have wT \u03c7(S) \u2264 (f \u2217 (S))p \u2264 \u03b2wT \u03c7(S) for all S \u2286 [n], where\n\u03b2 \u2265 1, p > 0. Then for any 0 < \u03b7 \u2264 1, the family F is PMAC-learnable with prices to a (1 + \u03b7)\u03b2 1/p factor using\nH\nH\n1 1 1\nO( n log\nln( n log\n\u03b7\u03b5\n\u03b7\u03b5\u03b4 )) samples and time poly(n, \u01eb , \u03b4 , \u03b7 ).\nProof. As in Algorithm 1, the idea is to use a reduction to learning a linear separator, but where now the examples use\nprices (that the algorithm can choose) instead of function values (that the algorithm can no longer observe). For each\ninput set Sl , the purchase decision amounts to a comparison between the chosen price ql and f \u2217 (Sl ). Using the result\nof this comparison we will construct examples, based on the prices ql , that are always consistent with a linear separator\nobtained from wT \u03c7(Sl ), the linear function that approximates (f \u2217 )p . We will sample enough sets Sl and assign prices\nql to them in such a way that for sufficiently many l, the price ql is close to f \u2217 (Sl ). We then find a linear separator that\nhas small error on the distribution induced by the price-based examples and show this yield a hypothesis f (S) whose\nerror is not much higher on the original distribution with respect to the values of the (unknown) target function.\nH\nH\nln( n log\nSpecifically, we take m = O( n log\n\u03b7\u03b5\n\u03b7\u03b5\u03b4 )) samples, and for convenience define N = \u230alog1+\u03b7/3 H\u230b. We\nassign to each input bundle Sl a price ql drawn uniformly at random from {(1 + \u03b7/3)i } for i = 0, 1, 2, . . . , N + 1,\nand present bundle Sl to the agent at price ql . The key point is that for bundles Sl such that f \u2217 (Sl ) \u2265 1 this ensures\nat least a N1+2 probability that f \u2217 (Sl )(1 + \u03b7/3)\u22121 < ql \u2264 f \u2217 (Sl ) and at least a N1+2 probability that f \u2217 (Sl ) < ql \u2264\nf \u2217 (Sl )(1 + \u03b7/3) (the case of f \u2217 (Sl ) = 0 will be noticed when the agent does not purchase at price ql = 1 and is\nhandled as in the proof of Theorem 1).\nWe construct new examples based on these prices and purchase decisions as follows. If f \u2217 (Sl ) < ql (i.e. the agent\ndoes not buy) then we let (xl , yl ) = ((\u03c7(Sl ), \u03b2qlp ), \u22121). If f \u2217 (Sl ) \u2265 ql (i.e. the agent buys) then we let (xl , yl ) =\n((\u03c7(Sl ), qlp ), +1). Note that by our given assumption, the examples constructed are always linearly separable. In\nparticular the label yl matches sgn((\u03b2w, \u22121)T xl ) in each case: \u03b2wT\u03c7(Sl ) \u2264 \u03b2(f \u2217 (Sl ))p < \u03b2qlp and qlp \u2264 (f \u2217 (Sl ))p \u2264\nn+1\n\u03b2wT\u03c7(Sl ) respectively. Let Dbuy\ndenote the induced distribution on Rn+1 . We now find a linear separator (\u0175, \u2212z) \u2208\nRn+1 , where \u0175 \u2208 Rn and z \u2208 R+ , that is consistent with (xl , yl ), \u2200l. We construct an intermediary hypothesis\n1\n1\n\u0175T \u03c7(S) based on the learned linear separator. The hypothesis output will be f (S) = 1+\u03b7/3\n(f \u2032 (S))1/p .\nf \u2032 (S) = \u03b2z\nBy standard VC-dimension sample-complexity bounds, our sample size m is sufficient that the linear separator\nn+1\n(\u0175, \u2212z) has error on Dbuy\nat most N \u03b5+2 with probability at least 1 \u2212 \u03b4. We now show that this implies that with\nprobability at least 1 \u2212 \u03b4, hypothesis f (S) approximates f \u2217 (S) to a factor (1 + \u03b7/3)2 \u03b2 1/p \u2264 (1 + \u03b7)\u03b2 1/p over D, on\nall but at most an \u03b5 probability mass, as desired.\n\n12\n\n\fSpecifically, consider some bundle S for which f (S) does not approximate f \u2217 (S) to a factor (1 + \u03b7/3)2 \u03b2 1/p and\nfor which f \u2217 (S) \u2265 1 (recall that zeroes are handled separately). We just need to show that for such bundles S, there\nis at least a N1+2 probability (over the draw of price q) that (\u0175, \u2212z) makes a mistake on the resulting example from\nn+1\nDbuy\n. There are two cases to consider:\n1. It could be that f is a bad approximation because f (S) > f \u2217 (S). This implies that f \u2032 (S) > [(1 + \u03b7/3)f \u2217 (S)]p\nor equivalently that \u0175T \u03c7(S) > \u03b2z[(1 + \u03b7/3)f \u2217(S)]p . In this case we use the fact that there is a N1+2 chance that\nf \u2217 (S) < q \u2264 f \u2217 (S)(1 + \u03b7/3). If this occurs, then the agent doesn't buy (yielding x = (\u03c7(S), \u03b2q p ), y = \u22121)\nand yet \u0175T \u03c7(S) > \u03b2zq p . Thus the separator mistakenly predicts positive.\n2. Alternatively it could be that (1 + \u03b7/3)2 \u03b2 1/p f (S) < f \u2217 (S). This implies that (1 + \u03b7/3)\u03b2 1/p f \u2032 (S)1/p < f \u2217 (S)\nf \u2217 (S) p\nf \u2217 (S)\nor equivalently that \u0175T \u03c7(S) < z( 1+\u03b7/3\n) . In this case, we use the fact that there is a N1+2 chance that 1+\u03b7/3\n<\n\u2217\np\nT\nq \u2264 f (S). If this occurs, then the agent does buy (yielding x = (\u03c7(S), q ), y = +1) and yet \u0175 \u03c7(S) < zq p .\nThus the separator mistakenly predicts negative.\nn+1\nThus, the error rate under Dbuy\nis at least a\nimplies a low error under D as desired.\n\n1\nN +2\n\nn+1\nfraction of the error rate under D, and so a low error under Dbuy\n\nNote: We note that if there is an underlying desired pricing algorithm A, for each input set Sl we can take the price\nof Sl to be A(Sl ) with probability 1 \u2212 \u03b5\u0303 and a uniformly at random price in {1, 2, 4 . . . , H/2, H} as in the previous\nlog H\nresult with probability \u03b5\u0303. The sample complexity of learning only goes up by a factor of at most log H log\n.\n\u03b5\u0303\nWe can also recover our upper bounds on learnability everywhere with value queries (the corresponding lower\nbounds clearly hold). By sequentially setting prices 1, 2, 4 . . . , H/2, H on each item we can learn f \u2217 's values on items\nwithin a factor of 2. Our structural results proving the approximability of f \u2217 from interesting classes with a function\nthat only depends on f \u2217 ({1}), . . . , f \u2217 ({n}) then yield the VQ-learnability with prices of these classes.\nTheorem 8. The following classes are VQ-learnable with prices to within an 2R factor: OXS with at most R trees,\nOXS with at most R leaves in each tree, XOS with at most R trees, and XOS with at most R leaves in each tree.\n\n7 Conclusions\nIn this paper we study the approximate learnability of valuations commonly used throughout economics and game\ntheory for the quantitative encoding of agent preferences. We provide upper and lower bounds regarding the learnability of important subclasses of valuation functions that express no-complementarities. Our main results concern their\napproximate learnability in the distributional learning (PAC-style) setting. We provide nearly tight lower and upper\nbounds of \u0398\u0303(n1/2 ) on the approximation factor for learning XOS and subadditive valuations, both widely studied\nsuperclasses of submodular valuations. Interestingly, we show that the \u03a9\u0303(n1/2 ) lower bound can be circumvented for\nXOS functions of polynomial complexity; we provide an algorithm for learning the class of XOS valuations with\na representation of polynomial size achieving an O(n\u03b5 ) approximation factor in time O(n1/\u03b5 ) for any \u03b5 > 0. This\nhighlights the importance of considering the complexity of the target function for polynomial time learning. We also\nprovide new learning results for interesting subclasses of submodular functions. Our upper bounds for distributional\nlearning leverage novel structural results for all these valuation classes. We show that many of these results provide\nnew learnability results in the Goemans et al. model [17] of approximate learning everywhere via value queries.\nWe also introduce a new model that is more realistic in economic settings, in which the learner can set prices and\nobserve purchase decisions at these prices rather than observing the valuation function directly. In this model, most of\nour upper bounds continue to hold despite the fact that the learner receives less information (both for learning in the\ndistributional setting and with value queries), while our lower bounds naturally extend.\nAcknowledgments. We thank Avrim Blum, Nick Harvey, and David Parkes for useful discussions. This work was\nsupported in part by NSF grants CCF-0953192 and CCF-1101215, AFOSR grant FA9550-09-1-0538, and a Microsoft\nResearch Faculty Fellowship.\n\n13\n\n\fReferences\n[1] M. Anthony and P. Bartlett. Neural Network Learning: Theoretical Foundations. Cambridge University Press,\n1999.\n[2] L. M. Ausubel and P. R. Milgrom. Ascending auctions with package bidding. Frontiers of Theoretical Economics,\n1, 2002.\n[3] M. Babaioff, M. Dinitz, A. Gupta, N. Immorlica, and K. Talwar. Secretary problems: weights and discounts. In\nSODA, 2009.\n[4] M. Babaioff, N. Immorlica, and R. Kleinberg. Matroids, secretary problems, and online mechanisms. In Proceedings of the Annual ACM-SIAM symposium on Discrete algorithms, 2007.\n[5] M. F. Balcan and N. Harvey. Learning submodular functions. In STOC, 2011.\n[6] K. Bhawalkar and T. Roughgarden. Welfare guarantees for combinatorial auctions with item bidding. In SODA,\n2011.\n[7] A. Blum, M. Zinkevich, and T. Sandholm. On polynomial-time preference elicitation with value queries. In\nACM Conference on Electronic Commerce, 2003.\n[8] D. Buchfuhrer, S. Dughmi, H. Fu, R. Kleinberg, E. Mossel, C. H. Papadimitriou, M. Schapira, Y. Singer, and\nC. Umans. Inapproximability for vcg-based combinatorial auctions. In SODA, pages 518\u2013536, 2010.\n[9] D. Buchfuhrer, M. Schapira, and Y. Singer. Computation and incentives in combinatorial public projects. In\nProc. of the ACM conference on Electronic commerce, pages 33\u201342, 2010.\n[10] P. Cramton, Y. Shoham, and R. Steinberg, editors. Combinatorial Auctions. MIT Press, 2006.\n[11] R. Day and S. Raghavan. Assignment preferences and combinatorial auctions. Working paper, University of\nConnecticut, April 2006.\n[12] S. Dobzinski. Two randomized mechanisms for combinatorial auctions. In APPROX, 2007.\n[13] S. Dobzinski, N. Nisan, and M. Schapira. Approximation algorithms for combinatorial auctions with\ncomplement-free bidders. STOC '05, pages 610\u2013618, 2005.\n[14] S. Dobzinski, N. Nisan, and M. Schapira. Truthful randomized mechanisms for combinatorial auctions. STOC\n'06, pages 644\u2013652, 2006.\n[15] U. Feige. On maximizing welfare when utility functions are subadditive. In STOC '06: Proceedings of the\nthirty-eighth annual ACM symposium on Theory of computing, pages 41\u201350, 2006.\n[16] G. Goel, C. Karande, P. Tripathi, and L. Wang. Approximability of combinatorial problems with multi-agent\nsubmodular cost functions. In Proceedings of the 50th Annual Symposium on Foundations of Computer Science,\n2009.\n[17] M. Goemans, N. Harvey, S. Iwata, and V. Mirrokni. Approximating submodular functions everywhere. In\nProceedings of the ACM-SIAM Symposium on Discrete Algorithms, 2009.\n[18] F. Gul and E. Stacchetti. Walrasian equilibrium with gross substitutes. Journal of Economic Theory, 87(1):95\u2013\n124, 1999.\n[19] S. Iwata and K. Nagano. Submodular function minimization under covering constraints. In Proceedings of the\n50th Annual Symposium on Foundations of Computer Science, 2009.\n[20] F. John. Extremum problems with inequalities as subsidiary conditions. In Studies and Essays, presented to R.\nCourant on his 60th Birthday, January 8, 1948, 1948.\n14\n\n\f[21] M. Kearns and U. Vazirani. An Introduction to Computational Learning Theory. MIT Press, 1994.\n[22] S. Lahaie, F. Constantin, and D. C. Parkes. More on the power of demand queries in combinatorial auctions:\nlearning atomic languages and handling incentives. In Proceedings of the 19th international joint conference on\nArtificial intelligence, pages 959\u2013964, 2005.\n[23] S. Lahaie and D. C. Parkes. Applying learning algorithms to preference elicitation. In ACM Conference on\nElectronic Commerce, pages 180\u2013188, 2004.\n[24] B. Lehmann, D. Lehmann, and N. Nisan. Combinatorial auctions with decreasing marginal utilities. In ACM\nConference on Electronic Commerce, pages 18\u201328, 2001.\n[25] Y. Lien and J. Yan. On the gross substitutes condition. Working paper, Jul2007.\n[26] K. Murota. Submodular function minimization and maximization in discrete convex analysis. Technical Report\nMETR 2008\u201332, The University of Tokyo, Japan, August 2008.\n[27] N. Nisan. Chapter 9: Bidding Languages for Combinatorial Auctions . In P. Cramton, Y. Shoham, and R. Steinberg, editors, Combinatorial Auctions. MIT Press, 2006.\n[28] N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani, editors. Algorithmic Game Theory. Cambridge, 2007.\n[29] T. Sandholm. Algorithm for optimal winner determination in combinatorial auctions. Artificial Intelligence,\npages 542\u2013547, 2001.\n[30] Y. Singer. Budget feasible mechanisms. FOCS '10, pages 765\u2013774, 2010.\n[31] Z. Svitkina and L. Fleischer. Submodular approximation: Sampling-based algorithms and lower bounds. In\nProceedings of the 49th Annual IEEE Symposium onFoundations of Computer Science, 2008.\n[32] L. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134\u20131142, 1984.\n[33] V. N. Vapnik. Statistical Learning Theory. Wiley and Sons, 1998.\n\nA\n\nAdditional Details for the Proof of Theorem 1\n\n\u221a\nFor PMAC-learning XOS valuations to an n + \u03b5 factor, we apply Algorithm 1 with parameters R = n, \u01eb, and p = 2.\nThe proof of correctness of Algorithm 1 follows by using the structural result in Claim 1 and a technique of [5]. We\nprovide here the full details of this proof.\nBecause of the multiplicative error allowed by the PMAC-learning model, we separately analyze the subset of the\ninstance space where f \u2217 is zero and the subset of the instance space where f \u2217 is non-zero. For convenience, we define:\nP = { S : f \u2217 (S) 6= 0 }\n\nand\n\nZ = { S : f \u2217 (S) = 0 } .\n\nThe main idea of our algorithm is to reduce our learning problem to the standard problem of learning a binary classifier\n(in fact, a linear separator) from i.i.d. samples in the passive, supervised learning setting [21, 33] with a slight twist in\norder to handle the points in Z. The problem of learning a linear separator in the passive supervised learning setting\nis one where the instance space is Rm , the samples come from some fixed and unknown distribution D\u2032 on Rm , and\nthere is a fixed but unknown target function c\u2217 : Rm \u2192 {\u22121, +1}, c\u2217 (x) = sgn(uT x). The examples induced by D\u2032\nand c\u2217 are called linearly separable since there exists a vector u such that c\u2217 (x) = sgn(uT x). The linear separator\nlearning problem we reduce to is defined as follows. The instance space is Rm where m = n + 1 and the distribution\nD\u2032 is defined by the following procedure for generating a sample from it. Repeatedly draw a sample S \u2286 [n] from the\ndistribution D until f \u2217 (S) 6= 0. Next, flip a fair coin for each. The sample from D\u2032 is\n(\u03c7(S), (f \u2217 (S))2 )\n\u2217\n\n2\n\n(\u03c7(S), (n + \u03b5) * (f (S)) )\n15\n\n(if the coin is heads)\n(if the coin is tails).\n\n\fThe function c\u2217 defining the labels is as follows: samples for which the coin was heads are labeled +1, and the others\nare labeled \u22121. We claim that the distribution over labeled examples induced by D\u2032 and c\u2217 is linearly separable in\nRn+1 . To prove this we use the assumption that for the linear function f (S) = \u0175T \u03c7(S) with w \u2208 Rn , we have\n(f \u2217 (S))2 \u2264 f\u02c6(S) \u2264 n(f \u2217 (S))2 for all S \u2286 [n]. Let u = ((n + \u03b5/2) * w, \u22121) \u2208 Rm . For any point x in the support of\nD\u2032 we have\nx = (\u03c7(S), (f \u2217 (S))2 )\n\n=\u21d2\n\nx = (\u03c7(S), (n + \u03b5) * (f \u2217 (S))2 )\n\n=\u21d2\n\nuT x = (n + \u03b5/2) * f\u02c6(S) \u2212 (f \u2217 (S))2 > 0\nuT x = (n + \u03b5/2) * f\u02c6(S) \u2212 (n + \u03b5) * (f \u2217 (S))2 < 0.\n\nThis proves the claim. Moreover, this linear function also satisfies f\u02c6(S) = 0 for every S \u2208 Z. In particular, f\u02c6(S) = 0\nfor all S \u2208 S0 and moreover,\nf\u02c6({j}) = wj = 0\n\nfor every j \u2208 UD\n\nwhere\n\nUD = \u222aSi \u2208Z Si .\n\nOur algorithm is as follows. It first partitions the training set S = {(S1 , f \u2217 (S1 )), . . . , (Sm , f \u2217 (Sm ))} into two sets\nS0 and S6=0 , where S0 is the subsequence of S with f \u2217 (Si ) = 0, and S6=0 = S \\ S0 . For convenience, let us denote\nthe sequence S6=0 as\n\u0001\nS6=0 = (A1 , f \u2217 (A1 )), . . . , (Aa , f \u2217 (Aa )) .\n\nNote that a is a random variable and we can think of the sets the Ai as drawn independently from D, conditioned on\nbelonging to P. Let\nU0 = \u222a i\u2264m Si\nand\nP 0 = { S : S \u2286 U0 } .\nf \u2217 (Si )=0\n\n\u0001\n\u2032\nUsing S6=0 , the algorithm then constructs a sequence S6=\n(x1 , y1 ), . . . , (xa , ya ) of training examples for the\n0 =\nbinary classification problem. For each 1 \u2264 i \u2264 a, let yi be +1 or \u22121, each with probability 1/2. If yi = +1 set\nxi = (\u03c7(Ai ), (f \u2217 (Ai ))2 ); otherwise set xi = (\u03c7(Ai ), (n + \u03b5) * (f \u2217 (Ai ))2 ). The last step of our algorithm is to solve\na linear program in order to find a linear separator u = (\u0175, \u2212z) where \u0175 \u2208 Rn , z \u2208 R consistent with the labeled\nexamples (xi , yi ), i = 1 \u2264 i \u2264 a, with the additional constraints that wj = 0 for j \u2208 U0 . The output hypothesis is\n1\n\u0175T \u03c7(S))1/2 .\nf (S) = ( (n+\u03b5)z\nTo prove correctness, note first that the linear program is feasible; this follows from our earlier discussion using\n\u2032\n\u2032\n\u2217\nthe facts (1) S6=\n0 is a set of labeled examples drawn from D and labeled by c and (2) U0 \u2286 UD . It remains to show\nthat f approximates the target on most of the points. Let Y denote the set of points S \u2208 P such that both of the points\n(\u03c7(S), (f \u2217 (S))2 ) and (\u03c7(S), (n + \u03b5) * (f \u2217 (S))2 ) are correctly labeled by sgn(uT x), the linear separator found by our\n1\nalgorithm. It is easy to show that the function f (S) = ( (n+\u03b5)z\n\u0175T \u03c7(S))1/2 approximates f \u2217 to within a factor n + \u03b5\non all the points in the set Y. To see this notice that for any point S \u2208 Y, we have\n\u0175T \u03c7(S) \u2212 z(f \u2217 (S))2 > 0\nand\n\u0175T \u03c7(S) \u2212 z(n + \u03b5)(f \u2217 (S))2 < 0\n1\n1\n=\u21d2\n\u0175T \u03c7(S) < (f \u2217 (S))2 < (n + \u03b5)\n\u0175T \u03c7(S).\n(n + \u03b5)z\n(n + \u03b5)z\n1\nSo, for any point in S \u2208 Y, the function f (S)2 = (n+\u03b5)z\n\u0175T \u03c7(S) approximates (f \u2217 (*))2 to within a factor n + \u03b5.\nMoreover, by design the function f correctly labels\u0001 as 0 all the examples in P0 . To finish the proof, we now note two\nn\nimportant facts: for our choice of m = 16n\n\u01eb log \u03b4\u01eb , with high probability both P \\ Y and Z \\ P0 have small measure.\n\nClaim 1. With probability at least 1 \u2212 \u03b4, the set Z \\ P0 has measure at most \u01eb.\n\nProof. Let Pk = { S : S \u2286 Uk } . Suppose that, for some k, the set Z \\ Pk has measure at least \u01eb. Define\nk \u2032 = k + log(n/\u03b4)/\u01eb. Then amongst the subsequent examples Sk+1 , . . . , Sk\u2032 , the probability that none of them lie in\nZ \\ Pk is at most (1 \u2212 \u01eb)log(n/\u03b4)/\u01eb \u2264 \u03b4/n. On the other hand, if one of them does lie in Z \\ Pk , then |Uk\u2032 | > |Uk |.\nBut |Uk | \u2264 n for all k, so this can happen at most n times. Since m \u2265 n log(n/\u03b4)/\u01eb, with probability at least \u03b4 the set\nZ \\ Pm has measure at most \u01eb.\nWe now prove:\n16\n\n\fClaim 2. If m =\n\n16n\n\u01eb\n\nlog\n\nn\n\u03b4\u01eb\n\n\u0001\n, then with probability at least 1 \u2212 2\u03b4, the set P \\ Y has measure at most 2\u01eb under D.\n\nProof of Claim 2. Let q = 1 \u2212 p = PrS\u223cD [ S \u2208 P ]. If q < \u01eb then the claim is immediate, since P has measure at\nmost \u01eb. So assume that q \u2265 \u01eb. Let \u03bc = E [ a ] = qm. By assumption \u03bc > 16n log(n/\u03b4\u01eb) q\u01eb . Then Chernoff bounds\ngive that\nh\nqi\nPr a < 8n log(n/\u03b4\u01eb)\n< exp(\u2212n log(n/\u03b4)q/\u01eb) < \u03b4.\n\u01eb\n\nSo with probability at least 1 \u2212 \u03b4, we have a \u2265 8n log(qn/\u03b4\u01eb) q\u01eb . By a standard sample complexity argument [33]\nwith probability at least 1 \u2212 \u03b4, any linear separator consistent with S \u2032 will be inconsistent with the labels on a set\nof measure at most \u01eb/q under D\u2032 . In particular, this property holds for the linear separator c computed by the linear\nprogram. So for any set S, the conditional probability that either (\u03c7(S), (f \u2217 (S))2 ) or (\u03c7(S), (n + \u03b5) * (f \u2217 (S))2 ) is\nincorrectly labeled, given that S \u2208 P, is at most 2\u01eb/q. Thus\nPr [ S \u2208 P & S 6\u2208 Y ] = Pr [ S \u2208 P ] * Pr [ S 6\u2208 Y | S \u2208 P ] \u2264 q * (2\u01eb/q),\nas required.\n\nIn summary, our algorithm outputs a hypothesis f approximating f \u2217 to within a factor (n + \u03b5)1/2 on Y \u222a Pm . The\ncomplement of this set is (Z \\ P0 ) \u222a (P \\ Y), which has measure at most 3\u01eb, with probability at least 1 \u2212 3\u03b4.\n\nB Additional Results for Theorem 4\nWe prove that Algorithm 2 can be used to PAC-learn (i.e. PMAC-learn with \u03b1 = 1) any unit-demand valuation.\nLemma 3. The class of unit-demand valuations is properly PAC-learnable by using m = O(n ln(n/\u03b4)/\u03b5) training\nexamples and time poly(n, 1/\u01eb, 1/\u03b4).\nProof. We first show how to solve the consistency problem in polynomial time: given a sample (S1 , f \u2217 (S1 )), . . . , (Sm , f \u2217 (Sm ))\nwe show how to construct in polynomial time a unit-demand function f that is consistent with the sample, i.e.,\nf (Sl ) = f \u2217 (Sl ), for l \u2208 {1, 2, . . . , m}. In particular, using the reasoning in Theorem 3 for R = 1, we show that\nthe unit-demand hypothesis f output by Algorithm 2 is consistent with the samples. We have\nf (Sl ) = max f (i) = max min f \u2217 (Sj ) \u2264 f \u2217 (Sl ).\ni\u2208Sl\n\ni\u2208Sl j:i\u2208Sj\n\nAlso note that for any i \u2208 Sl we have f \u2217 (i) \u2264 f \u2217 (Sl ), for l \u2208 {1, 2, . . . , m}. So f (i) \u2265 f \u2217 (i) for any i \u2208\nS1 \u222a . . . \u222a Sm .. Therefore for any l \u2208 {1, 2, . . . , m} we have :\nf \u2217 (Sl ) = max f \u2217 (i) \u2264 max f (i) = f (Sl ).\ni\u2208Sl\n\ni\u2208Sl\n\nThus f \u2217 (Sl ) = f (Sl ) for l \u2208 {1, 2, . . . , m}.\nWe now claim that m = O(n ln(n/\u03b4)/\u03b5) training examples are sufficient so that with probability at least 1 \u2212\n\u03b4, the hypothesis f produced has error at most \u01eb. In particular, notice that Algorithm 2 guarantees that f (i) \u2208\n{f \u2217 (1), . . . , f \u2217 (n)} for all i. This means that for any given target function f \u2217 , there are at most nn different possible\nhypotheses f that Algorithm 2 could generate. By the union bound, the probability that the algorithm outputs one of\nerror greater than \u03b5 is at most nn (1 \u2212 \u03b5)m which is at most \u03b4 for our given choice of m.\nLemma 4. If f \u2217 is OXS with at most R trees, then it is also unit-demand with at most nR leaves (with R-tuples as\nitems). For constant R, the family F of OXS functions with at most R trees is PAC-learnable using O(RnR log(n/\u03b4)/\u03b5)\ntraining examples and time poly(n, 1/\u01eb, 1/\u03b4).\n\n17\n\n\fProof. We start by noting that since f \u2217 is an OXS function representable with at most R MAX trees, then f \u2217 is\nuniquely determined by its values on sets of size up to R. Formally,\nf \u2217 (S) = max f \u2217 (S R ), \u2200S \u2286 {1, . . . , n}\nS R \u2286S\n|S R |\u2264R\n\n(6)\n\nWe construct a unit-demand f \u2032 , closely related to f , on meta-items corresponding to each of the O(nR ) sets of at\nmost R items. In particular, we define one meta-item iS R to represent each set S R \u2286 {1, . . . , n} of size at most R and\nlet\nf \u2032 (iS R ) = f \u2217 (S R ).\nWe define f \u2032 as unit-demand over meta-items; i.e. beyond singleton sets, we have\nf \u2032 ({iS1R , . . . , iSLR }) = max f \u2032 (iSlR ).\nl=1,...,L\n\n(7)\n\nBy equations (6) and (7), for all S we have f \u2217 (S) = f \u2032 (IS ) where IS = {iS R : S R \u2286 S}.\nSince we can perform the mapping from sets S to their corresponding sets IS over meta-items in time O(nR ), this\nimplies that to PAC-learn f \u2217 , we can simply PAC-learn f \u2032 over the O(nR ) meta-items using Algorithm 2. Lemma 3\nguarantees that this will PAC-learn using O(nR log(nR /\u03b4)/\u03b5) training examples and running time poly(n, 1/\u01eb, 1/\u03b4)\nfor constant R.\n\nC\n\nAdditional Result for Theorem 6\n\n[17] proved that a certain matroid rank p\nfunction fR,\u03b1\u2032 ,\u03b2 (*), defined below, is hard to learn everywhere with value\nqueries to an approximation factor of o( lnnn ). We show that the rank function fR,\u03b1\u2032 ,\u03b2 (*) is in OXS (all leaves in\nall OXS trees will have value 1). fR,\u03b1\u2032 ,\u03b2 (*) : 2{1,...,n} \u2192 R is defined as follows. Let subset R \u2286 {1, . . . , n} and\nR\u0304 = ({1, . . . , n})\\R its complement. Also fix integers \u03b1\u2032 , \u03b2 \u2208 N. Then\nfR,\u03b1\u2032 ,\u03b2 (S) = min(\u03b2 + |S \u2229 R\u0304|, |S|, \u03b1\u2032 ), \u2200S \u2286 {1, . . . , n}\n\n(8)\n\nAs a warm-up, we show that a simpler function than fR,\u03b1\u2032 ,\u03b2 (*) is in OXS. This simpler function essentially\ncorresponds to \u03b2 = 0 and will be used in the case analysis for establishing that fR,\u03b1\u2032 ,\u03b2 (*) is in OXS.\nLemma 5. Let R\u2032 \u2286 {1, . . . , n} and c \u2208 N. Then the function f (*) : 2{1,...,n} \u2192 R defined as\nfR\u2032 ,c (S) = min(c, |S \u2229 R\u2032 |), \u2200S \u2286 {1, . . . , n}\n\n(9)\n\nis in OXS.\n\u2032\n\u2032\nProof. For ease of notation let f (*) =\nf (S) = |S \u2229 R\u2032 |, \u2200S \u2286 {1, . . . , n},\nPfR ,c (*). We assume c < |R |; otherwise,\n\u2032\nwhich is a linear function (f (S) = x\u2208S f (x) where f (x) = 1 if x \u2208 R and f (x) = 0 otherwise) and any linear\nfunction belongs to the class OXS [24]. Assuming c < |R\u2032 |, we construct an OXS tree T with c MAX trees, each\nwith one leaf for every element in R\u2032 . All leaves have value 1. We refer the reader to Fig. 1(a).\nThen T (S) = f (S), \u2200S \u2286 {1, . . . , n} since f (S) represents the smaller of the number of elements in S \u2229 R\u2032 (that\ncan each be taken from a different MAX tree in T ) and c. Note that T (S) \u2264 c, \u2200S \u2286 {1, . . . , n}.\n\nLemma 6. The matroid rank function fR,\u03b1\u2032 ,\u03b2 (*) is in the class OXS.\nProof. For ease of notation let f (*) = fR,\u03b1\u2032 ,\u03b2 (*). If n \u2264 \u03b1\u2032 then8 |S| \u2264 \u03b1\u2032 , \u2200S \u2286 {1, . . . , n} and\nf (S) = min(\u03b2 + |S \u2229 R\u0304|, |S|) = |S \u2229 R\u0304| + min(\u03b2, |S \u2229 R|)\n8 We\n\nnote that n > \u03b1\u2032 in [17]. We consider this case for completeness.\n\n18\n\n(10)\n\n\f(a) OXS representation for the function\nin Eq. (9).\n\n(b) OXS representation for the function in Eq. (8) when n > \u03b1\u2032 > \u03b2.\n\nFigure 1: OXS representations. All leaves have value 1.\nFrom the proof of Lemma 5 we get that the function f \u2032 (S) = min(\u03b2, |S \u2229 R|) has an OXS tree T \u2032 (i.e. T \u2032 (S) =\nf \u2032 (S), \u2200S \u2286 {1, . . . , n}) with \u03b2 MAX trees each with leaves only in R. We can create a new tree T by adding\n|R\u0304| MAX trees to T \u2032 , each with one leaf for every element in R\u0304, and we get T (S) = f (S), \u2200S \u2286 {1, . . . , n}. The\nadditional |R\u0304| MAX trees encode the |S \u2229 R\u0304| term in Eq. (10). If \u03b1\u2032 \u2264 \u03b2 then f (S) = min(\u03b1\u2032 , |S|); the claim follows\nby Lemma 5 for c = \u03b1\u2032 , R\u2032 = {1, . . . , n}. We can thus assume that n > \u03b1\u2032 > \u03b2. We prove that the OXS tree T ,\ncontaining the two types of MAX trees below, represents f , i.e. T (S) = f (S), \u2200S. We refer the reader to Fig. 1(b).\n\u2022 \u03b1\u2032 \u2212 \u03b2 MAX trees T1 . . . T\u03b1\u2032 \u2212\u03b2 , each having as leaves all the elements in R\u0304 with value 1.\n\u2022 \u03b2 MAX trees T\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 , each having as leaves all the elements (in {1, . . . , n}) with value 1.\nWe note that T (S) \u2264 min(|S|, \u03b1\u2032 ) as no set S can use more than |S| leaves and T has exactly \u03b1\u2032 trees. We distinguish\nthe following cases\n\u2022 |S| \u2264 \u03b2 implying f (S) = |S| and T (S) = |S| as |S| leaves can be taken each from |S| trees in T\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 .\n\u2022 f (S) = \u03b1\u2032 \u2264 min(\u03b2 + |S \u2229 R\u0304|, |S|). We claim T (S) \u2265 \u03b1\u2032 . There must exist \u03b1\u2032 \u2212 \u03b2 elements in |S \u2229 R\u0304|, that\nwe can select one from each tree T1 . . . T\u03b1\u2032 \u2212\u03b2 . Also |S| \u2265 \u03b1\u2032 and we can take the remaining \u03b2 elements from\nT\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 .\n\u2022 f (S) = |S| \u2264 min(\u03b2 + |S \u2229 R\u0304|, \u03b1\u2032 ). This implies |S \u2229 R| \u2264 \u03b2 and |S| \u2264 \u03b1\u2032 . We claim T (S) \u2265 |S|: we\ncan take all needed elements in S \u2229 R\u0304 from T1 . . . T\u03b1\u2032 \u2212\u03b2 (and from T\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 if |S \u2229 R\u0304| > \u03b1\u2032 \u2212 \u03b2) and\nelements in S \u2229 R from T\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 .\n\u2022 f (S) = \u03b2 + |S \u2229 R\u0304| \u2264 min(|S|, \u03b1\u2032 ). We claim T (S) \u2265 \u03b2 + |S \u2229 R\u0304|: we can take \u03b2 \u2264 |S \u2229 R| elements from\nT\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 and |S \u2229 R\u0304| \u2264 \u03b1\u2032 \u2212 \u03b2 elements from T1 . . . T\u03b1\u2032 \u2212\u03b2 . Finally, T (S) \u2264 \u03b2 + |S \u2229 R\u0304| since at most\nall elements in S \u2229 R\u0304 can be taken from T1 . . . T\u03b1\u2032 \u2212\u03b2 and at most \u03b2 elements in S \u2229 R from T\u03b1\u2032 \u2212\u03b2+1 . . . T\u03b1\u2032 .\n\n19\n\n\f"}