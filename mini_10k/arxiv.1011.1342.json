{"id": "http://arxiv.org/abs/1011.1342v4", "guidislink": true, "updated": "2011-03-04T13:02:12Z", "updated_parsed": [2011, 3, 4, 13, 2, 12, 4, 63, 0], "published": "2010-11-05T08:47:44Z", "published_parsed": [2010, 11, 5, 8, 47, 44, 4, 309, 0], "title": "Non-equilibrium steady states : maximization of the Shannon entropy\n  associated to the distribution of dynamical trajectories in the presence of\n  constraints", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1011.0388%2C1011.2491%2C1011.1829%2C1011.4106%2C1011.4731%2C1011.6031%2C1011.2851%2C1011.0320%2C1011.4294%2C1011.5032%2C1011.1606%2C1011.4437%2C1011.3334%2C1011.0441%2C1011.4438%2C1011.5801%2C1011.0768%2C1011.3385%2C1011.6660%2C1011.4412%2C1011.5867%2C1011.5222%2C1011.3637%2C1011.3137%2C1011.6072%2C1011.1733%2C1011.0750%2C1011.0532%2C1011.5244%2C1011.3142%2C1011.4174%2C1011.2592%2C1011.2194%2C1011.3842%2C1011.5647%2C1011.0895%2C1011.5320%2C1011.6179%2C1011.4461%2C1011.0248%2C1011.5737%2C1011.3260%2C1011.0424%2C1011.4075%2C1011.0254%2C1011.0136%2C1011.4076%2C1011.6226%2C1011.1008%2C1011.0214%2C1011.0688%2C1011.6204%2C1011.1006%2C1011.0557%2C1011.5599%2C1011.1747%2C1011.4130%2C1011.0041%2C1011.5949%2C1011.3422%2C1011.2861%2C1011.2675%2C1011.5468%2C1011.2660%2C1011.0047%2C1011.3426%2C1011.6589%2C1011.4284%2C1011.6267%2C1011.4244%2C1011.2503%2C1011.4197%2C1011.3778%2C1011.0260%2C1011.0016%2C1011.0781%2C1011.0776%2C1011.0322%2C1011.3138%2C1011.1760%2C1011.1400%2C1011.3196%2C1011.5143%2C1011.0818%2C1011.2967%2C1011.2787%2C1011.0461%2C1011.4002%2C1011.6668%2C1011.4307%2C1011.0774%2C1011.1390%2C1011.5869%2C1011.3911%2C1011.0994%2C1011.1526%2C1011.5380%2C1011.3225%2C1011.2898%2C1011.5572%2C1011.1342&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Non-equilibrium steady states : maximization of the Shannon entropy\n  associated to the distribution of dynamical trajectories in the presence of\n  constraints"}, "summary": "Filyokov and Karpov [Inzhenerno-Fizicheskii Zhurnal 13, 624 (1967)] have\nproposed a theory of non-equilibrium steady states in direct analogy with the\ntheory of equilibrium states : the principle is to maximize the Shannon entropy\nassociated to the probability distribution of dynamical trajectories in the\npresence of constraints, including the macroscopic current of interest, via the\nmethod of Lagrange multipliers. This maximization leads directly to generalized\nGibbs distribution for the probability distribution of dynamical trajectories,\nand to some fluctuation relation of the integrated current. The simplest\nstochastic dynamics where these ideas can be applied are discrete-time Markov\nchains, defined by transition probabilities $W_{i \\to j}$ between\nconfigurations $i$ and $j$ : instead of choosing the dynamical rules $W_{i \\to\nj} $ a priori, one determines the transition probabilities and the associate\nstationary state that maximize the entropy of dynamical trajectories with the\nother physical constraints that one wishes to impose. We give a self-contained\nand unified presentation of this type of approach, both for discrete-time\nMarkov Chains and for continuous-time Master Equations. The obtained results\nare in full agreement with the Bayesian approach introduced by Evans [Phys.\nRev. Lett. 92, 150601 (2004)] under the name 'Non-equilibrium Counterpart to\ndetailed balance', and with the 'invariant quantities' derived by Baule and\nEvans [Phys. Rev. Lett. 101, 240601 (2008)], but provide a slightly different\nperspective via the formulation in terms of an eigenvalue problem.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1011.0388%2C1011.2491%2C1011.1829%2C1011.4106%2C1011.4731%2C1011.6031%2C1011.2851%2C1011.0320%2C1011.4294%2C1011.5032%2C1011.1606%2C1011.4437%2C1011.3334%2C1011.0441%2C1011.4438%2C1011.5801%2C1011.0768%2C1011.3385%2C1011.6660%2C1011.4412%2C1011.5867%2C1011.5222%2C1011.3637%2C1011.3137%2C1011.6072%2C1011.1733%2C1011.0750%2C1011.0532%2C1011.5244%2C1011.3142%2C1011.4174%2C1011.2592%2C1011.2194%2C1011.3842%2C1011.5647%2C1011.0895%2C1011.5320%2C1011.6179%2C1011.4461%2C1011.0248%2C1011.5737%2C1011.3260%2C1011.0424%2C1011.4075%2C1011.0254%2C1011.0136%2C1011.4076%2C1011.6226%2C1011.1008%2C1011.0214%2C1011.0688%2C1011.6204%2C1011.1006%2C1011.0557%2C1011.5599%2C1011.1747%2C1011.4130%2C1011.0041%2C1011.5949%2C1011.3422%2C1011.2861%2C1011.2675%2C1011.5468%2C1011.2660%2C1011.0047%2C1011.3426%2C1011.6589%2C1011.4284%2C1011.6267%2C1011.4244%2C1011.2503%2C1011.4197%2C1011.3778%2C1011.0260%2C1011.0016%2C1011.0781%2C1011.0776%2C1011.0322%2C1011.3138%2C1011.1760%2C1011.1400%2C1011.3196%2C1011.5143%2C1011.0818%2C1011.2967%2C1011.2787%2C1011.0461%2C1011.4002%2C1011.6668%2C1011.4307%2C1011.0774%2C1011.1390%2C1011.5869%2C1011.3911%2C1011.0994%2C1011.1526%2C1011.5380%2C1011.3225%2C1011.2898%2C1011.5572%2C1011.1342&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Filyokov and Karpov [Inzhenerno-Fizicheskii Zhurnal 13, 624 (1967)] have\nproposed a theory of non-equilibrium steady states in direct analogy with the\ntheory of equilibrium states : the principle is to maximize the Shannon entropy\nassociated to the probability distribution of dynamical trajectories in the\npresence of constraints, including the macroscopic current of interest, via the\nmethod of Lagrange multipliers. This maximization leads directly to generalized\nGibbs distribution for the probability distribution of dynamical trajectories,\nand to some fluctuation relation of the integrated current. The simplest\nstochastic dynamics where these ideas can be applied are discrete-time Markov\nchains, defined by transition probabilities $W_{i \\to j}$ between\nconfigurations $i$ and $j$ : instead of choosing the dynamical rules $W_{i \\to\nj} $ a priori, one determines the transition probabilities and the associate\nstationary state that maximize the entropy of dynamical trajectories with the\nother physical constraints that one wishes to impose. We give a self-contained\nand unified presentation of this type of approach, both for discrete-time\nMarkov Chains and for continuous-time Master Equations. The obtained results\nare in full agreement with the Bayesian approach introduced by Evans [Phys.\nRev. Lett. 92, 150601 (2004)] under the name 'Non-equilibrium Counterpart to\ndetailed balance', and with the 'invariant quantities' derived by Baule and\nEvans [Phys. Rev. Lett. 101, 240601 (2008)], but provide a slightly different\nperspective via the formulation in terms of an eigenvalue problem."}, "authors": ["Cecile Monthus"], "author_detail": {"name": "Cecile Monthus"}, "author": "Cecile Monthus", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/1742-5468/2011/03/P03008", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1011.1342v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1011.1342v4", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "v4=final version", "arxiv_primary_category": {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1011.1342v4", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1011.1342v4", "journal_reference": "J. Stat. Mech. (2011) P03008", "doi": "10.1088/1742-5468/2011/03/P03008", "fulltext": "Non-equilibrium steady states : maximization of the Shannon entropy associated\nwith the distribution of dynamical trajectories in the presence of constraints\nC\u00e9cile Monthus\n\narXiv:1011.1342v4 [cond-mat.stat-mech] 4 Mar 2011\n\nInstitut de Physique Th\u00e9orique, CNRS and CEA Saclay, 91191 Gif-sur-Yvette, France\nFilyokov and Karpov [Inzhenerno-Fizicheskii Zhurnal 13, 624 (1967)] have proposed a theory of\nnon-equilibrium steady states in direct analogy with the theory of equilibrium states : the principle is to maximize the Shannon entropy associated with the probability distribution of dynamical\ntrajectories in the presence of constraints, including the macroscopic current of interest, via the\nmethod of Lagrange multipliers. This maximization leads directly to generalized Gibbs distribution\nfor the probability distribution of dynamical trajectories, and to some fluctuation relation of the integrated current. The simplest stochastic dynamics where these ideas can be applied are discrete-time\nMarkov chains, defined by transition probabilities Wi\u2192j between configurations i and j : instead of\nchoosing the dynamical rules Wi\u2192j a priori, one determines the transition probabilities and the associate stationary state that maximize the entropy of dynamical trajectories with the other physical\nconstraints that one wishes to impose. We give a self-contained and unified presentation of this type\nof approach, both for discrete-time Markov Chains and for continuous-time Master Equations. The\nobtained results are in full agreement with the Bayesian approach introduced by Evans [Phys. Rev.\nLett. 92, 150601 (2004)] under the name 'Non-equilibrium Counterpart to detailed balance', and\nwith the 'invariant quantities' derived by Baule and Evans [Phys. Rev. Lett. 101, 240601 (2008)],\nbut provide a slightly different perspective via the formulation in terms of an eigenvalue problem.\n\nI.\n\nINTRODUCTION\n\nIn contrast to the statistical physics of equilibrium, which is based on a few general principles, everybody complains\nthat no global theory has emerged to describe out-of-equilibrium systems. A natural explanation of this matter\nof fact is that the problem is ill-defined for many reasons. A first reason is that there are actually very different\nways to be out-of-equilibrium : a system can be 'out-of-equilibrium' because it has a very slow dynamics that never\nconverges towards some stationary state, or because it is in a non-equilibrium steady state, characterized by some\ncurrents that are imposed by the environment. It is clear that in the first case, one really needs a non-trivial\ndynamical description, whereas in the second case, one may hope that the 'steady state' property could help to\ndevelop some theory generalizing the equilibrium steady state. A second reason is that even within the field of\n'non-equilibrium steady states', very different goals have been pursued. On one hand, many theorists of statistical\nphysics consider that the best strategy consists in solving specific models with chosen dynamical rules, in order to\nsee if some general principles emerge in the end : in this direction, the most studied models are one dimensional\nexclusion processes, for which many remarkable results have been obtained over the years (see the recent short\nreview [1] and references therein). On the other hand, it is clear that the success of the theory of equilibrium is\nbased on the fact that one does not specify the details of the dynamical evolution but that on the contrary, one\nkeeps only its conservation properties (for instance the energy conservation) and then maximize the Shannon entropy\nassociated with the equilibrium state. So there has been various attempts to formulate general principles based on\nsome notion of 'entropy' for non-equilibrium steady states. Although the principles of 'minimum entropy production'\nand of 'maximum entropy production' seem popular, in particular in applications to related areas like chemistry,\nbiology or climatology, the proposed justifications have not been widely accepted, either because there are at the\nlevel of 'generalized thermodynamics' rather than statistical physics, or because they are limited to 'near-equilibrium'\nconditions, or because they involve other additional questionable assumptions (see for instance the discussions in [2\u20135]\nand references therein). But we feel that instead of focusing on the notion of 'entropy production' to formulate general\nprinciples, it is much more natural to consider the 'Shannon entropy associated with the probability distribution\nof dynamical trajectories' that we will call equivalently 'dynamical entropy' to have a shorter name. This notion\ncan be introduced for any stochastic dynamics, or for any deterministic chaotic dynamics that becomes effectively\n'stochastic', as follows : to characterize the dynamics during some time interval [0, t], one considers all possible\ndynamical trajectories \u03a9[0,t] and their probabilities P(\u03a9[0,t] ) normalized to\nX\n\n\u03a9[0,t]\n\nP(\u03a9[0,t] ) = 1\n\n(1)\n\n\f2\nThe Shannon entropy associated with this distribution P(\u03a9[0,t] ) over dynamical trajectories reads\nS dyn (t) \u2261 \u2212\n\nX\n\nP(\u03a9[0,t] ) ln P(\u03a9[0,t] )\n\n(2)\n\n\u03a9[0,t]\n\nFor many stochastic process of interest, this entropy becomes extensive in the time t in the large-time limit t \u2192 +\u221e :\nit is then convenient to introduced the entropy rate per unit time, called the Kolmogorov-Sinai entropy in the context\nof chaotic dynamical systems (see for instance the book [6] and references therein)\nS dyn (t)\nt\u2192+\u221e\nt\n\nhKS \u2261 lim\n\n(3)\n\nMore than forty years ago, Filyokov and Karpov [7\u20139] have proposed to base the theory of non-equilibrium steady\nstates on the maximization of the dynamical entropy of Eq. 2 in the presence of some constraints via the method of\nLagrange multipliers. We are not aware of direct continuations of these works, except the very recent work of Favretti\n[10]. However closely related ideas have been proposed independently by Evans [11] under the name 'Non-equilibrium\nCounterpart to detailed balance' and have been applied to shear flow [12\u201314]. Also among recent attempts to 'prove'\nthe principle of maximum entropy production by Dewar [15], one can see that the starting point is precisely the\nmaximization of the dynamical entropy of Eq. 2. We thus feel that if one wishes to formulate a general principle\nbased on the maximization of some notion of entropy for non-equilibrium steady states, the dynamical entropy of Eq.\n2 is definitely the most natural and could be the basis of some consensus.\nLet us now mention various recent works that are related to some of these notions :\n- For random walks on arbitrary networks, the optimization of the dynamical entropy of Eq. 2 leads to the 'maximal\nentropy random walk' that has been introduced by Burda, Duda, Luck and Waclaw [16] : it is different from the usual\nrandom walk that maximizes the entropy only locally whenever there exists some fluctuations in the coordination\nnumbers of nodes of the network (but of course these two types of random walks coincide on regular networks).\n- For non-equilibrium steady states, even within the point of view where the dynamical rules are given a priori,\nthe dynamical entropy of Eq. 2 plays a major role in the 'thermodynamics of histories' that has been developed by\nLecomte, Appert-Rolland and Van Wijland [17], and that has been then applied to various glassy systems [18].\n- The method of Lagrange multipliers has been much used recently for non-equilibrium quantum systems [19\u201322],\nbut we should stress that the physical meaning is completely different : in these quantum studies, the dynamics is\ngoverned by some given quantum Hamiltonian, and the Lagrange multiplier associated with a macroscopic current\nis added to the Hamiltonian, whereas in the Filyokov-Karpov approach [7\u201310] or in the Evans approach [11\u201314] the\ndynamical rules are not given at the beginning but on the contrary they are determined by the optimization of the\ndynamical entropy of Eq. 2 in the presence of appropriate constraints.\nThe aim of this paper is to give a self-contained and unified presentation of this type of approach, to discuss\nthe various results that can be obtained, and to make the links with other recent developments in the field of nonequilibrium statistical physics.\nThe paper is organized as follows. In section II, we describe how the maximization of the dynamical entropy of\nEq. 2 leads to generalized Gibbs distribution for the probability distribution P(\u03a9[0,t] ) of dynamical trajectories, and\nto some fluctuation relation of the integrated current. In the remainder of the paper, we discuss in details how this\ngeneral formal argument can be given a more precise meaning when one considers well defined stationary stochastic\ndynamics. In section III, we recall the important properties of discrete-time Markov chains, that constitute the simplest\nframework to describe stochastic dynamics with a time-extensive dynamical entropy (Eqs 2 and 3). In section IV,\nwe explain how the maximization of the dynamical entropy of Eq. 2 in the presence of a constraint concerning the\nenergy of dynamical trajectories allows to recover the usual Boltzmann-Gibbs distribution of equilibrium. In section\nV, we add a supplementary constraint concerning the flux of some observable and derive the form of the optimal\nsolution for the stationary distribution and for the transition rates. We then focus on the problem of finding effective\nlocal stochastic rules, and explain how a consistent formulation can be obtained by the maximization of the relative\ndynamical entropy with respect to the equilibrium trajectories : we describe the case of discrete-time Markov Chains\nin section VI and the case of continuous-time Master Equations in section VII. In both cases, we make the link with\nthe Evans approach called 'Non-equilibrium Counterpart to detailed balance' [11\u201314]. Our conclusions are summarized\nin section VIII. Appendix A contains a reminder on the maximization of static entropy for the equilibrium, to make\nthe comparison with the maximization of the dynamical entropy discussed in the text. In Appendix B, we explain\nthe technical simplifications that occur if one considers an alternate Markov chain as done originally [7\u201310].\n\n\f3\nII.\n\nGENERAL IDEA : GENERALIZED GIBBS DISTRIBUTION FOR DYNAMICAL TRAJECTORIES\n\nAs recalled in Appendix A, the usual Boltzmann-Gibbs distribution for equilibrium configurations can be obtained\nfrom the maximization of the static entropy in the presence of constraints introduced via Lagrange multipliers. This\nsimple derivation of the equilibrium has been introduced by Jaynes [23], and can be found nowadays in most textbooks\non statistical physics. Although Jaynes has often proposed to apply the same strategy to non-equilibrium phenomena,\nin particular in [24], we have not been able to find in his articles the expression of Eq. 2 for the dynamical entropy,\nwhereas Eq. 2 is the clear starting point of some 'maximization' in the works of Filyokov and Karpov [7\u20139] and in the\nEvans approach [11\u201314]. (Note that Eq. 2 is also the starting point in the works of Dewar [15], but with the different\ngoal of justifying the 'maximum production entropy principle').\nA.\n\nMaximization of the dynamical entropy with constraints\n\nFor non-equilibrium steady states characterized by some macroscopic current J0 , the general idea is the following :\none wishes to optimize the dynamical entropy of Eq. 2 with constraints concerning the normalization of Eq. 1\nX\nN \u2261\nP(\u03a9[0,t] ) = 1\n(4)\n\u03a9[0,t]\n\nthe averaged energy of the trajectory\nE dyn (t) \u2261\n\nX\n\nP(\u03a9[0,t] )E(\u03a9[0,t] ) = tE0\n\n(5)\n\nX\n\nP(\u03a9[0,t] )J(\u03a9[0,t] ) = tJ0\n\n(6)\n\n\u03a9[0,t]\n\nand the averaged current of the trajectory\nJ dyn (t) \u2261\n\n\u03a9[0,t]\n\nThe optimization of the Lagrange functional\n\u03c8\n\n\u0001\n\u0001\n= S dyn (t) \u2212 \u03c1 (N \u2212 1) \u2212 \u03b2 E dyn (t) \u2212 tE0 + \u03bd J dyn (t) \u2212 tJ0\n\uf8eb\n\uf8f6\nX\nX\n=\u2212\nP(\u03a9[0,t] ) ln P(\u03a9[0,t] ) \u2212 \u03c1 \uf8ed\nP(\u03a9[0,t] ) \u2212 1\uf8f8\n\u03a9[0,t]\n\n\uf8eb\n\nwith respect to P(\u03a9[0,t] )\n\n\u2212\u03b2 \uf8ed\n0=\n\nX\n\n\u03a9[0,t]\n\n\u03a9[0,t]\n\n\uf8f6\n\n\uf8eb\n\nP(\u03a9[0,t] )E(\u03a9[0,t] ) \u2212 tE0 \uf8f8 + \u03bd \uf8ed\n\nX\n\n\u03a9[0,t]\n\n\uf8f6\n\nP(\u03a9[0,t] )J(\u03a9[0,t] ) \u2212 tJ0 \uf8f8\n\n\u03b4\u03a8\n= \u2212 ln P(\u03a9[0,t] ) \u2212 1 \u2212 \u03c1 \u2212 \u03b2E(\u03a9[0,t] ) + \u03bdJ(\u03a9[0,t] )\n\u03b4P(\u03a9[0,t] )\n\n(7)\n\n(8)\n\ndirectly leads to the following generalized Gibbs distribution for dynamical trajectories\nP(\u03a9[0,t] ) = e\u22121\u2212\u03c1\u2212\u03b2E(\u03a9[0,t] )+\u03bdJ(\u03a9[0,t] )\n\n(9)\n\nwhere the Lagrange multipliers \u03c1, \u03b2 and \u03bd are fixed respectively by the constraints of Eqs 4, 5 and 6.\nB.\n\nMaximization of the relative dynamical entropy with respect to some equilibrium reference process\n\nAnother formulation that turns out to be more appropriate in many cases consists in considering the relative\ndynamical entropy with respect to the corresponding known equilibrium distribution P eq (\u03a9[0,t] ) of trajectories in the\nabsence of the current\nX\nP(\u03a9[0,t] )\ndyn\n(10)\nSrel\n(t) \u2261 \u2212\nP(\u03a9[0,t] ) ln eq\nP (\u03a9[0,t] )\n\u03a9[0,t]\n\n\f4\nThe idea is then to maximize this relative entropy in the presence of the constraints concerning the normalization of\nEq. 4 and the imposed current (Eq. 6) to obtain\nP(\u03a9[0,t] ) = P eq (\u03a9[0,t] )e\u22121\u2212\u03c1+\u03bdJ(\u03a9[0,t] )\n\n(11)\n\ninstead of Eq. 9.\nThe notion of relative entropy with respect to some reference, also called the Kullback-Leibler entropy, is wellknown in many areas. At a naive level, the idea is that the probability distribution used as reference constitutes some\n'prior' for the problem at hand : in the absence of any other constraint, the relative entropy is maximal for the 'prior'\ndistribution. At a more fundamental level, the importance of the notion of relative entropy comes from its essential\nrole in the Sanov's theorem concerning the theory of large deviations when formulated at the so-called 'level-2' (see\nfor instance the review [27]).\nThe interest to consider relative entropies in various areas of statistical physics has been discussed recently in [26].\nIn the present context of non-equilibrium steady states, the idea to take the equilibrium dynamics as the reference\nprocess is the basis of the Evans approach [11\u201314].\nC.\n\nConsequence : fluctuation relation concerning the integrated current\n\nIt is clearly impossible to summarize here all the recent developments concerning the various 'fluctuation relations'\nthat have been established in the field of non-equilibrium dynamics, and we refer the interested reader to some recent\nreviews [28\u201334] and references therein. Here we simply mention the minimum for our present purpose.\nThe probability distribution of the integrated current is expected to satisfy some large deviation principle: the\nprobability to have a given time-averaged value J(\u03a9[0,t] )/t = j behaves at large t as\n\u0013\n\u0012\nJ(\u03a9[0,t] )\n=j\n\u221d etG(j)\n(12)\nP rob\nt\u2192+\u221e\nt\nwhere G(j) \u2264 0 is called the large-deviation function. The typical value jtyp corresponding to the point where it\nvanishes G(jtyp ) = 0 is fixed here to J0 by the constraint of Eq. 64. Equivalently, the generating function of the\nintegrated current J(\u03a9[0,t] ) behaves for large time t as\nZ\nhe\u03bbJ(\u03a9[0,t] ) i \u221d\ndjet(\u03bbj+G(j)) \u221d et\u03bc(\u03bb)\n(13)\nt\u2192+\u221e\n\nt\u2192\u221e\n\nwhere \u03bc(\u03bb) is the Legendre transform of G(j)\n\u03bc(\u03bb) = max [\u03bbj + G(j)]\nj\n\n(14)\n\nTo characterize the irreversibility of the dynamics, it is interesting to compare the probabilities of a given trajectory\n\u03a9[0,t] and of its associate trajectory \u03a9\u0303[0,t] obtained by time-reversal. In our present case, these two trajectories have\nthe same energy E(\u03a9\u0303[0,t] ) = E(\u03a9[0,t] ) but have opposite currents J(\u03a9\u0303[0,t] ) = \u2212J(\u03a9[0,t] ). So Eq. 9 yields that the ratio\nof the probabilities between a trajectory and its time-reversed trajectory reads\nP(\u03a9[0,t] )\nP(\u03a9\u0303[0,t] )\n\n= e2\u03bdJ(\u03a9[0,t] )\n\n(15)\n\nMore generally, any equilibrium dynamics has the property that two reversed-time trajectories occur with the same\nprobability P eq (\u03a9[0,t] ) = P eq (\u03a9\u0303[0,t] ). As a consequence, Eq. 11 also leads to Eq. 15.\nA direct consequence of Eq. 15 is that the generating function of the integrated current defined as\nX\nhe\u03bbJ(\u03a9[0,t] ) i \u2261\ne\u03bbJ(\u03a9[0,t] ) P(\u03a9[0,t] )\n(16)\n\u03a9[0,t]\n\nwill satisfy the following symmetry (using the antisymmetry J(\u03a9\u0303[0,t] ) = \u2212J(\u03a9[0,t] ) and the one-to-one change of\nvariables between \u03a9[0,t] and \u03a9\u0303[0,t] )\nX\ne\u2212(\u03bb+2\u03bd)J(\u03a9\u0303[0,t] ) P(\u03a9\u0303[0,t] ) = he\u2212(\u03bb+2\u03bd)J(\u03a9[0,t] ) i\n(17)\nhe\u03bbJ(\u03a9[0,t] ) i =\n\u03a9\u0303[0,t]\n\n\f5\nthat can be rewritten for the function \u03bc(\u03bb) introduced in Eq. 13\n\u03bc(\u03bb) = \u03bc(\u2212\u03bb \u2212 2\u03bd)\n\n(18)\n\nor equivalently after the Legendre transform of Eq. 14\nG(j) = G(\u2212j) + 2\u03bdj\n\n(19)\n\nIn summary, the generalized Gibbs distribution of dynamical trajectories of Eq 9 or Eq 11 directly leads to some\nfluctuation relation for the integrated current, as already discussed by Baule and Evans [12]. Independently of the\ncontext of the maximization of the dynamical entropy, the fact that fluctuation relations have actually for origin some\ngeneralized Gibbs distribution of space-time trajectories has been proposed by Maes [35].\nD.\n\nEntropy production\n\nThe notion of entropy 'production' is of course subtle. Since it is expected to measure the 'irreversibility' of the\ndynamics, it is natural to relate it to the probabilities between a trajectory and its reversed-time trajectory already\nintroduced in Eq. 15 : a possibility [35, 36] is thus to define the entropy production S prod (\u03a9[0,t] ) of a dynamical\ntrajectory \u03a9[0,t] as the logarithm of the ratio of Eq. 15\nS prod (\u03a9[0,t] ) \u2261 ln\n\nP(\u03a9[0,t] )\n\n(20)\n\nP(\u03a9\u0303[0,t] )\n\nSuch a definition, which is in agreement with the usual expressions of the averaged entropy production derived for\nMarkov chains [37, 38], has for advantage that the fluctuation relation for the entropy production\nprod\nP rob(S prod )\n= eS\nprod\nP rob(\u2212S\n)\n\n(21)\n\nis then a direct consequence of Eq. 20 because\nP rob(S\n\nprod\n\n)\n\n\u2261\n\nX\n\nP(\u03a9[0,t] )\u03b4\n\nS\n\nprod\n\n\u03a9[0,t]\n\n=e\n\nS prod\n\nP rob(\u2212S\n\nprod\n\n\u2212 ln\n\nP(\u03a9[0,t] )\nP(\u03a9\u0303[0,t] )\n\n!\n\n=\n\nX\n\nP(\u03a9\u0303[0,t] )e\n\n\u03a9\u0303[0,t]\n\nS prod\n\n\u03b4\n\nS\n\nprod\n\nP(\u03a9\u0303[0,t] )\n+ ln\nP(\u03a9[0,t] )\n\n!\n\n)\n\n(22)\n\nFor our present case, the definition of Eq. 20 leads with Eq. 15 to\nS prod (\u03a9[0,t] ) \u2261 ln\n\nP(\u03a9[0,t] )\nP(\u03a9\u0303[0,t] )\n\n= 2\u03bdJ(\u03a9[0,t] )\n\n(23)\n\ni.e. it is simply proportional to the time-extensive trajectory current J(\u03a9[0,t] ) that breaks the time asymmetry.\nE.\n\nDiscussion\n\nIn this section, we have described the general idea of maximization of the dynamical entropy with constraints that\nleads to generalized Gibbs distributions for dynamical trajectories, and to some fluctuation relation for the integrated\ncurrent. However, the derivation presented above remains a bit formal, since the space of dynamical trajectories has\nnot been precisely defined. In particular, the important notion of 'stationarity' of the dynamics has been imposed\nonly implicitly by the time-extensive constraints of Eqs 5 and 6, but no direct condition of stationarity has been\nexplicitly imposed on P(\u03a9[0,t] ) (and we do not see how one could impose such a stationarity condition at this formal\nlevel). In the following sections, we thus consider well defined stochastic stationary dynamics generated by discretetime Markov Chains or by continuous-time Master Equations to study the consequences of the maximisation of the\ndynamical entropy.\n\n\f6\nIII.\n\nDYNAMICAL OBSERVABLES FOR A STATIONARY MARKOV CHAIN\n\nDiscrete-time Markov Chains constitute the simplest formulation of stochastic dynamics presenting a dynamical\nentropy (Eq. 2) that is extensive in time (Eq. 3). In this section, we introduce the notations that will be useful in\nthe remainder of the paper.\nA.\n\nDiscrete-time Markov Chain\n\nLet us consider a system where possibles microscopic configurations are indexed by i, and where the probability\nPt (i) to be in configuration i at time t evolves according to the discrete-time Markov Chain\nX\nPt (i)Wi\u2192j\n(24)\nPt+1 (j) =\ni\n\nwhere Wi\u2192j represents the transition probability from i to j during the unit time interval, with the following normalization for each i\nX\nWi\u2192j = 1\n(25)\nj\n\nst\n\nThe stationary state P (i) associated with this Markov chain satisfies\nX\nP st (j)Wj\u2192i\nP st (i) =\n\n(26)\n\nj\n\nand the normalization\nX\n\nP st (i) = 1\n\n(27)\n\ni\n\nB.\n\nProbability of a dynamical trajectory in the stationary regime\n\nSuppose one starts at time t = 0 in the stationary state P st of Eq. 26. The probability of a trajectory \u03a9[0,t] =\n{i0 , i1 , ..., it } to be in state i0 at time t = 0, in state i1 at time t = 1, in state i2 at time t = 2, ... , and in state it at\ntime t reads\nP(\u03a9[0,t] = {i0 , i1 , ..., it }) = P st (i0 )Wi0 \u2192i1 Wi1 \u2192i2 ...Wit\u22121 \u2192it\n\n(28)\n\nThe normalization of Eq. 1\nX\nX\nX\nX\nXXX X\nWit\u22121 \u2192it = 1\nWi1 \u2192i2 ...\nWi0 \u2192i1\nP st (i0 )\nP(\u03a9[0,t] = {i0 , i1 , ..., it }) =\n...\ni1\n\ni0\n\nit\n\ni2\n\ni1\n\ni0\n\n(29)\n\nit\n\ni2\n\ncan be easily checked using Eqs 25 and 27.\nC.\n\nDynamical entropy associated with the distribution of trajectories\n\nUsing the normalization and stationarity properties of Eq. 25 and Eq. 26, the dynamical entropy of Eq. 2 reads\nfor the distribution P(\u03a9[0,t] ) of Eq 28\nX\nS dyn (t) = \u2212\nP(\u03a9[0,t] ) ln P(\u03a9[0,t] )\n\u03a9[0,t]\n\n=\u2212\n\nXX\ni0\n\n=\u2212\n\ni1\n\nX\nit\n\ni1\n\nXX\ni0\n\n...\n\n...\n\nX\n\n\u0002\n\u0001\n\u0003\nP st (i0 )Wi0 \u2192i1 ...Wit\u22121 \u2192it ln P st (i0 )Wi0 \u2192i1 ...Wit\u22122 \u2192it\u22121 + ln Wit\u22121 \u2192it\n\"\n\nst\n\n\u0001\n\nP (i0 )Wi0 \u2192i1 ...Wit\u22122 \u2192it\u22121 ln P (i0 )Wi0 \u2192i1 ...Wit\u22122 \u2192it\u22121 +\n\nit\u22121\n\n= S dyn (t \u2212 1) \u2212\n\nst\n\nX\n\nit\u22121\n\nP st (it\u22121 )\n\nX\nit\n\nWit\u22121 \u2192it ln Wit\u22121 \u2192it\n\nX\nit\n\nWit\u22121 \u2192it ln Wit\u22121 \u2192it\n\n#\n(30)\n\n\f7\nBy recursion one obtains the following extensive behavior in the time t\nX\nX\nWi\u2192j ln Wi\u2192j\nP st (i)\nS dyn (t) = \u2212t\n\n(31)\n\nj\n\ni\n\nso that the entropy rate of Eq. 3 is given by the well-known result (see for instance the books [6, 25])\nX\nX\nS dyn (t)\nWi\u2192j ln Wi\u2192j\nP st (i)\n=\u2212\nt\u2192+\u221e\nt\nj\ni\n\n(32)\n\nhKS = lim\n\nThe physical meaning of this formula is clear : it is the average, over the possible configurations i distributed with the\nstationary distribution P st (i), of the Shannon entropy associated with the transition probabilities Wi\u2192j normalized\nwith Eq. 25.\nD.\n\nEnergy associated with trajectories\n\nIn statistical physics, one usually wishes to fix some constraint concerning the energy. For instance at equilibrium,\nthe Boltzmann-Gibbs distribution can be obtained from the optimization of the static entropy in the presence of a\nconstraint fixing the average energy (see Appendix A for a short reminder). In our present dynamical context, it is\nnatural to associate to each trajectory \u03a9[0,t] the integrated energy over the time interval\nE(\u03a9[0,t] = {i0 , i1 , ..., it }) \u2261 Ei0 + Ei1 + ...Eit\u22121\n\n(33)\n\nso that its averaged value over the trajectories \u03a9[0,t] (using Eqs 25 and 26 )\nX\nXX X\n\u0002\n\u0003\nP st (i0 )Wi0 \u2192i1 ...Wit\u22121 \u2192it Ei0 + Ei1 + ...Eit\u22121\n...\nE dyn (t) \u2261\nP(\u03a9[0,t] )E(\u03a9[0,t] ) =\n\u03a9[0,t]\n\n=\n\nX\n\ni1\n\ni0\n\nX\n\nP st (i0 )Ei0 +\n\nP st (i1 )Ei1 + ... +\n\nX\n\nP st (it\u22121 )Eit\u22121 = t\n\nX\n\nP st (i)Ei\n\n(34)\n\ni\n\nit\u22121\n\ni1\n\ni0\n\nit\n\nis extensive in time, and the ratio E dyn (t)/t corresponds to the static averaged energy computed from the stationary\ndistribution as it should.\nE.\n\nFlux associated with trajectories\n\nIn the field of non-equilibrium steady states, one is interested in particular in situations where a flux or current of\nsome observable is imposed on the system. It can be a flux of particles, a flux of energy, or a flux of something else\ndepending on the system under study and on the environment.\nIn our present framework, we will consider that each transition i \u2192 j is characterized by some contribution Ji\u2192j\nto this current, with the antisymmetry property\nJi\u2192j = \u2212Jj\u2192i\n\n(35)\n\nThe integrated current J(\u03a9[0,t] ) associated with a trajectory \u03a9[0,t] simply reads\nJ(\u03a9[0,t] = {i0 , i1 , ..., it }) \u2261 Ji0 \u2192i1 + Ji1 \u2192i2 + ... + Jit\u22121 \u2192it\n\n(36)\n\nso that its averaged value over the trajectories \u03a9[0,t] (using Eqs 25 and 26 )\nX\nXX X\n\u0002\n\u0003\nP st (i0 )Wi0 \u2192i1 ...Wit\u22121 \u2192it Ji0 \u2192i1 + Ji1 \u2192i2 + ... + Jit\u22121 \u2192it\n...\nJ dyn (t) \u2261\nP(\u03a9[0,t] )J(\u03a9[0,t] ) =\n\u03a9[0,t]\n\n=\n\nX\n\ni0\n\nP st (i0 )\n\nX\ni\n\nP st (i)\n\nX\n\ni1\n\nWi0 \u2192i1 Ji0 \u2192i1 + ... +\n\nit\n\nX\n\nit\u22121\n\ni1\n\ni0\n\n=t\n\nX\n\nWi\u2192j Ji\u2192j\n\nj\n\nis again extensive in time as expected.\n\nP st (it\u22121 )\n\nX\n\nWit\u22121 \u2192it Jit\u22121 \u2192it\n\nit\n\n(37)\n\n\f8\nIV.\n\nRECOVERING EQUILIBRIUM FROM THE MAXIMIZATION OF THE DYNAMICAL ENTROPY\n\nThe minimal requirement for any approach concerning non-equilibrium steady-states is of course to be compatible\nwith the theory of the equilibrium. In this section, we thus describe how the maximization of the dynamical entropy\nof Eq. 2 allows to recover the equilibrium. As a comparison, we recall in Appendix A how the equilibrium is usually\nobtained via the maximization of the static entropy.\nA.\n\nLagrange functional taking into account the constraints\n\nWe consider all possible stationary distributions P st (i) satisfying the normalization\nX\nP st (i) = 1\nN \u2261\n\n(38)\n\ni\n\nand all Markov chains defined by some transition probabilities Wi\u2192j , that satisfy the normalization condition of Eq.\n25 for all i\nX\nWi\u2192j = 1\n(39)\nNi \u2261\nj\n\nand the stationarity condition of Eq. 26 for all i\nX\nP st (j)Wj\u2192i \u2212 P st (i) = 0\n\u03a3i \u2261\n\n(40)\n\nj\n\nWe also wish to fix the time averaged energy E dyn (t)/t (see Eq. A5) to some value E0\nE dyn (t) X st\nP (i)Ei = E0\n\u2261\nt\ni\n\n(41)\n\nTo optimize the dynamical entropy S dyn (t) of Eq. 31 in the presence of all these constraints, we introduce Lagrange\nmultipliers \u03c1, \u03b2, \u03bbi and \u03bci and we consider the functional\n\u0013 X\n\u0012 dyn\nX\nE (t)\nS dyn (t)\n\u03bci (\u03a3i )\n\u03bbi (Ni \u2212 1) \u2212\n\u2212 \u03c1 (N \u2212 1) \u2212 \u03b2\n\u2212 E0 \u2212\n\u03a8 \u2261\nt\nt\ni\ni\n!\n!\nX\nX\nX\nX\nst\nst\nst\nEi P (i) \u2212 E0\nP (i) \u2212 1 \u2212 \u03b2\nWi\u2192j ln Wi\u2192j \u2212 \u03c1\nP (i)\n=\u2212\ni\n\nj\n\ni\n\ni\n\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\nX\nX\nX\nX\nP st (j)Wj\u2192i \u2212 P st (i)\uf8f8\n\u03bci \uf8ed\nWi\u2192j \u2212 1\uf8f8 \u2212\n\u03bbi \uf8ed\n\u2212\ni\n\ni\n\nj\n\nB.\n\n(42)\n\nj\n\nSolving the optimization equations\n\nWe wish to optimize the functional of Eq. 42 both over the stationary probabilities P st (i)\n0=\n\nX\nX\n\u03b4\u03a8\n\u03bcj Wi\u2192j\nW\nln\nW\n\u2212\n\u03c1\n\u2212\n\u03b2E\n+\n\u03bc\n\u2212\n=\n\u2212\ni\u2192j\ni\u2192j\ni\ni\n\u03b4P st (i)\nj\nj\n\n(43)\n\nand over the transition probabilities Wi\u2192j\n0=\n\n\u03b4\u03a8\n= P st (i) [\u2212 ln Wi\u2192j \u2212 1 \u2212 \u03bcj ] \u2212 \u03bbi\n\u03b4Wi\u2192j\n\nThe Lagrange multipliers have then to be determined by imposing the various constraints.\n\n(44)\n\n\f9\nEquation 44 yields\n\u03bb\n\nWi\u2192j = e\n\n\u22121\u2212\u03bcj \u2212 P sti(i)\n\n(45)\n\nThe normalization constraint of Eq. 39 for all i\n1=\n\nX\n\n\u03bb\n\nWi\u2192j = e\n\n\u22121\u2212 P sti(i)\n\nj\n\nX\n\ne\u2212\u03bcj\n\n(46)\n\nj\n\nimply that the Lagrange multipliers \u03bbi are given by\n\uf8eb\n\n\u03bbi = P st (i) ln \uf8ed\n\nX\nj\n\nso that the rates of Eq. 45 can be rewritten as\n\n\uf8f6\n\ne\u2212\u03bcj \u22121 \uf8f8\n\n(47)\n\ne\u2212\u03bcj\nWi\u2192j = P \u2212\u03bc\nk\nke\n\n(48)\n\nThe stationarity constraint of Eq. 40 yields that for all j\nP st (j) =\n\nX\ni\n\ne\u2212\u03bcj\nP st (i)Wi\u2192j = P \u2212\u03bc\nk\nke\n\n(49)\n\nso that the optimum found in Eq. 48 simply corresponds to [8, 10]\nWi\u2192j = P st (j)\n\n(50)\n\n0 = \u2212\u03c1 \u2212 \u03b2Ei \u2212 ln P st (i)\n\n(51)\n\nEq. 43 becomes using Eq 49 and Eq 38\n\nso that using the normalization constraint of Eq. 38 one recovers the Boltzmann-Gibbs distribution\ne\u2212\u03b2Ej\nP st (j) = P \u2212\u03b2Ei \u2261 P eq (j)\nie\n\n(52)\n\nwhere \u03b2 is fixed by the constraint of Eq. 41.\nC.\n\nConsequence for the probabilities of dynamical trajectories\n\nWith the optimal solution obtained in Eqs 50 and 52, the probability of a trajectory \u03a9[0,t] of Eq. 28 takes the\nsimple form\nP eq (\u03a9[0,t] ) = {i0 , i1 , ..., it }) = P st (i0 )Wi0 \u2192i1 Wi1 \u2192i2 ...Wit\u22121 \u2192it =\n\ne\u2212\u03b2E(i0 ) e\u2212\u03b2E(i1 ) ... e\u2212\u03b2E(it )\n[Z(\u03b2)]t+1\n\n(53)\n\nwhere\nZ(\u03b2) \u2261\n\nX\n\ne\u2212\u03b2Ei\n\n(54)\n\ni\n\nis the usual static partition function. So within the present approach, the probability distribution over dynamical\ntrajectories is simply the Boltzmann-Gibbs distribution with respect to the trajectory energy E(\u03a9[0,t+1] ) of Eq. 34\nP eq (\u03a9[0,t] ) =\n\ne\u2212\u03b2E(\u03a9[0,t+1] )\n[Z(\u03b2)]t+1\n\n(55)\n\n\f10\nThe appearance of E(\u03a9[0,t+1] ) (instead of E(\u03a9[0,t] ) found in Eq. 9 via the formal argument ) is a consequence of the\nchoice of Eq. 34 for the energy for the discrete Markov chain : the energy E(it ) of the last state it will contribute to\nthe trajectory energy only during the next time interval [t, t + 1], but it nevertheless appear in the probability of the\ntrajectory \u03a9[0,t] ending in state it . This slight problem thus comes from the discrete nature of the dynamics, and is\nnot expected to play an important role : it is only a finite boundary term that will become subleading in the large\ntime limit t \u2192 +\u221e with respect to the time-extensive energy of the whole trajectory.\nAn essential property of this distribution of trajectories is the symmetry by time-reversal : the probabilities of\na given trajectory \u03a9[0,t] = {i0 , i1 , ..., it\u22121 , it } and of its associate trajectory \u03a9\u0303[0,t] = {it , it\u22121 , ..., i1 , i0 } obtained by\ntime-reversal are equal\nP(\u03a9[0,t] = {i0 , i1 , ..., it })\nP(\u03a9\u0303[0,t] = {it , it\u22121 , ..., i1 , i0 })\nD.\n\n=1\n\n(56)\n\nDiscussion\n\nIn this section, we have described how the maximization of the dynamical entropy allows to recover that the\nstationary distribution follows the Boltzmann-Gibbs distribution (Eq. 52). However the result of Eq. 50 concerning\nthe transition probabilities Wi\u2192j may be surprising at first sight : this solution means that the new configuration j\nis chosen with the probability P st (j) and is completely independent of the initial state i. Physically this corresponds\nto a very coarse-grained dynamics with no memory. It is thus clear that Eq. 50 does not represent an effective\n'microscopic' dynamics, but represents an effective dynamics on some macroscopic time \u03c4 . The corresponding entropy\nrate per unit time of Eq. 3\n!\nX\nX\nX\nst\nP st (j) ln P st (j)\n(57)\nP st (j) ln P st (j) = \u2212\nP (i)\nhKS = \u2212\nj\n\nj\n\ni\n\nthen exactly coincides with the static entropy of Eq. A1, which seems natural if one wishes this approach to be\nequivalent to the maximization of the static entropy that one uses for the equilibrium (see Appendix A). This\ndiscussion suggests the following interpretation of this type of computation.\nE.\n\nFinal formulation of the physical meaning of this approach\n\nThe statistical physics theory of equilibrium is usually based on some 'ergodic' hypothesis, stating that timeaverages of observables A(i) will converge in the infinite-time limit towards averages computed with respect to the\nBoltzmann-Gibbs distribution P eq (i) of Eq. 52\n1\nlim\nt\u2192+\u221e t\n\nZ\n\n0\n\nt\n\ndtA(i(t)) =\n\nX\n\nA(i)P eq (i)\n\n(58)\n\ni\n\nSince the right-handside contains only the Boltzmann-Gibbs distribution P eq (i) = e\u2212\u03b2Ei /Z(\u03b2) and no other information about the dynamics except the conserved energy, this means that the precise form of the 'true' microscopic\ndynamics becomes completely irrelevant at large time. Loosely speaking, this means that there exists some finite\nmacroscopic correlation time \u03c4correl , beyond which the dynamical correlations have been lost in practice, so that the\nlarge-time interval t can be decomposed into t/\u03c4correl quasi-independent time intervals, and Eq. 58 becomes possible.\nOn the contrary, if the correlation time \u03c4correl of the 'true' microscopic dynamics is infinite, Eq. 58 cannot really be\nsatisfied since other dynamical informations besides the conservation of energy remain relevant forever.\nThis discussion suggests that the analysis presented above based on the maximization of the dynamical entropy,\nwith the result of Eq. 50, actually describes what happens at this coarse-grained macroscopic scale \u03c4correl , i.e. the\nunit-time of the Markov Chain of Eq. 24 should be interpreted as \u03c4correl . Then we have shown above that one recovers\nthe Boltzmann-Gibbs distribution, and thus all the 'static' properties that can be derived from it.\nHowever in the statistical physics of equilibrium, once one has understood the properties of the Boltzmann-Gibbs\nmeasure over configurations, one can become interested into the 'equilibrium dynamics'. However, one does not wish\nto return to the 'true' deterministic microscopic dynamics which is usually very complicated for systems with a very\nlarge number (like 1023 ) degrees of freedom, because all the details of the dynamics have proven to be irrelevant at\n\n\f11\nlarge time scale. So one introduces an effective stochastic microscopic dynamics that is compatible with the known\nproperties on large time scales. For definiteness, let us consider a microscopic Markov Chain\nX\npt (i)wi\u2192j\n(59)\npt+\u2206t (j) =\ni\n\nwhere wi\u2192j represents the transition probability from i to j during the microscopic time interval \u2206t, so that wi\u2192j are\nnow non-zero only if the configurations i and j are sufficiently close in configuration space. For instance in a system of\nN spins with 2N configurations, one may require that wi\u2192j is non-zero only if j can be obtained from i by the flip a\nsingle spin. More generally, this notion of elementary moves has to be defined in an appropriate way for each type of\nmodels. Then the question is : beyond this locality requirement, how should these microscopic transition probabilities\nwi\u2192j be chosen to be compatible with the properties known on large time scales ? The first obvious requirement is\nthat the microscopic Markov Chain of Eq. 59 should have for stationary state pst (i) the Boltzmann-Gibbs distribution\nwhich is known to be the stationary state on macroscopic times\npst (i) = P eq (i)\n\n(60)\n\nHowever this is not the only constraint, since one also wishes to reproduce the essential time-reversibility property of\ndynamical trajectories of Eq. 56. For this, it is sufficient to impose that the probability of the elementary microscopic\ntrajectory \u03c9\u2206t = {i0 , i1 }\nP rob(\u03c9\u2206t = {i0 , i1 }) = p(i0 )wi0 \u2192i1\n\n(61)\n\nis equal to the probability of the reversed trajectory \u03c9\u0303\u2206t = {i1 , , i0 }\n1=\n\nP rob(\u03c9\u2206t = {i0 , i1 })\np(i0 )wi0 \u2192i1\n=\nP rob(\u03c9\u0303\u2206t = {i1 , , i0 })\np(i1 )wi1 \u2192i0\n\n(62)\n\nTaking into account Eq. 60, this leads to the well-known detailed-balance condition\nwieq0 \u2192i1\np(i1 )\nP eq (i1 )\n=\n= eq\n= e\u2212\u03b2(E(i1 )\u2212E(i0 ))\neq\nwi1 \u2192i0\np(i0 )\nP (i0 )\n\n(63)\n\nBesides this detailed-balance constraint, there is still some freedom to choose the effective microscopic transition\nprobabilities wi\u2192j , but one usually considers that they are equally valid, in the sense that they will all reproduce\nthe essential large-time properties of convergence towards the Boltzmann-Gibbs distribution while preserving the\ntime-reversibility of dynamical trajectories.\nF.\n\nIs it possible to add locality constraints within the maximization procedure ?\n\nAs explained above, the requirements on effective local Markov chain dynamics of Eq. 59 are derived from the\nmacroscopic equilibrium properties. A natural question here is whether these requirements can be instead directly\nderived from a maximisation of the dynamical entropy in the presence of locality constraints on the wi\u2192j . We have\nnow the following picture : configurations are the nodes of a network, and the links are present between configurations\nthat are related by an elementary local move. As a first example, in a spin models with N spins and 2N configurations,\none may consider a single spin-flip dynamics, where each configuration has N neighbors (corresponding to the flip of\none of its N spins). As a second example, in lattice gases models with hard-core interactions, the number of neighbors\nof a configuration will be given by the number of possible local moves from this configuration, and will thus depend\non the configuration.\nWhenever the connectivities (i.e. the numbers of neighbors) are configuration-dependent, it is clear that one cannot\nrecover the equilibrium from the maximization of the dynamical entropy in the presence of locality constraints, as\ncan be easily understood on the simple infinite temperature case \u03b2 = 0 :\n(i) At infinite temperature, the problem of the maximization of the dynamical entropy is completely equivalent to\nthe Maximal Entropy Random Walk (MERW) on arbitrary networks studied in details in [16], with the following\nmain conclusion : in networks where the connectivities of the various nodes are not all the same, the MERW tends\nto visit more the sites with higher connectivities than the sites with lower connectivities, because sites with higher\nconnectivities are associated with a bigger number of choices for the next step of the random walk.\n(ii) On the other hand, at infinite temperature case \u03b2 = 0, the Boltzmann-Gibbs distribution simply corresponds\nto the uniform distribution over all configurations, independently of their connectivities from the point of view of the\nlocal dynamics.\n\n\f12\nOur conclusion is thus that the choice of the connectivities that one wishes to impose on the local dynamics has a\ntoo strong effect on the dynamical entropy that one wishes to maximize, whereas the maximization of the dynamical\nentropy at a macroscopic time scale allows to recover the equilibrium, as explained above in section IV E. In the\nnon-equilibrium case, this discussion on local dynamics will be the subject of sections VI and VII, but in the next\nsection, we first describe what happens in the absence of locality constraints.\nV.\n\nNON-EQUILIBRIUM STEADY STATE WITH AN IMPOSED CURRENT\nA.\n\nLagrange functional taking into account the constraints\n\nWith respect to the previous section IV A, we now add another constraint concerning the flux of Eq. 37\nJ dyn (t) X st X\nWi\u2192j Ji\u2192j = J0\nP (i)\n\u2261\nt\nj\ni\n\n(64)\n\nSo we introduce this constraint with a new Lagrange multiplier \u03bd into the functional of Eq. 42 to obtain\n\u0012 dyn\n\u0013\nX\nX\nJ (t)\nE dyn (t)\nS dyn (t)\n\u03bci (\u03a3i ) + \u03bd\n\u03bbi (Ni \u2212 1) \u2212\n\u2212 \u03c1(N \u2212 1) \u2212 \u03b2(\n\u2212 E0 ) \u2212\n\u2212 J0\n\u03a8 \u2261\nt\nt\nt\ni\ni\nX\nX\nX\nX\nEi P st (i) \u2212 E0 )\nP st (i) \u2212 1) \u2212 \u03b2(\nWi\u2192j ln Wi\u2192j \u2212 \u03c1(\nP st (i)\n=\u2212\n\u2212\n\nX\ni\n\n\uf8eb\n\n\u03bbi \uf8ed\n\nX\nj\n\ni\n\ni\n\nj\n\ni\n\n\uf8f6\n\nWi\u2192j \u2212 1\uf8f8 \u2212\n\nX\ni\n\nB.\n\n\uf8eb\n\n\u03bci \uf8ed\n\nX\nj\n\n\uf8f6\n\uf8eb\nX\nX\nWi\u2192j Ji\u2192j \u2212 J0 \uf8f8 (65)\nP st (j)Wj\u2192i \u2212 P st (i)\uf8f8 + \u03bd \uf8ed\nP st (i)\n\uf8f6\n\ni\n\nj\n\nSolving the optimization equations\n\nEquations 43 and 44 are modified into\n0=\n\nX\nX\nX\n\u03b4\u03a8\nWi\u2192j Ji\u2192j\nWi\u2192j ln Wi\u2192j \u2212 \u03c1 \u2212 \u03b2Ei + \u03bci \u2212\n\u03bck Wi\u2192k + \u03bd\n=\u2212\nst\n\u03b4P (i)\nj\nj\n\n(66)\n\nk\n\nand\n0=\n\n\u03b4\u03a8\n= P st (i) [\u2212 ln Wi\u2192j \u2212 1 \u2212 \u03bcj + \u03bdJi\u2192j ] \u2212 \u03bbi\n\u03b4Wi\u2192j\n\n(67)\n\nEquation 67 yields\n\u03bb\n\nWi\u2192j = e\n\n\u22121\u2212\u03bcj +\u03bdJi\u2192j \u2212 P sti(i)\n\n(68)\n\nThe normalization constraint of Eq. 39 for all i\n1=\n\nX\n\n\u03bb\n\nWi\u2192j = e\n\n\u22121\u2212 P sti(i)\n\nj\n\nX\n\ne\u2212\u03bcj +\u03bdJi\u2192j\n\n(69)\n\nj\n\nleads to the Lagrange multipliers\n\uf8eb\n\nso that the rates of Eq. 45 become\n\n\u03bbi = P st (i) ln \uf8ed\n\nX\nj\n\n\uf8f6\n\ne\u2212\u03bcj \u22121+\u03bdJi\u2192j \uf8f8\n\ne\u2212\u03bcj +\u03bdJi\u2192j\nWi\u2192j = P \u2212\u03bc +\u03bdJ\nk\ni\u2192k\nke\n\n(70)\n\n(71)\n\n\f13\nTo analyze the stationarity constraint of Eq. 40 for all j\nP st (j) =\n\nX\n\nP st (i)Wi\u2192j =\n\nX\ni\n\ni\n\nit is convenient to introduce the notations\n\u2261\n\nzi\n\nX\n\ne\u2212\u03bcj +\u03bdJi\u2192j\nP st (i) P \u2212\u03bc +\u03bdJ\nk\ni\u2192k\nke\n\ne\u2212\u03bck +\u03bdJi\u2192k\n\n(72)\n\n(73)\n\nk\n\nand\nX P st (i)\n\nyj \u2261\n\nzi\n\ni\n\ne\u03bdJi\u2192j\n\n(74)\n\nto rewrite Eq. 72 as\ne\u2212\u03bcj =\n\nP st (j)\nyj\n\n(75)\n\nso we may now eliminate all \u03bcj in terms of the yj . In particular\nzi =\n\nX P st (k)\nyk\n\nk\n\ne\u03bdJi\u2192k\n\n(76)\n\nis somewhat the 'dual' of Eq. 74. The transition probability of Eq. 71 now reads\nWi\u2192j =\n\nP st (j) \u03bdJi\u2192j\ne\nzi yj\n\n(77)\n\nand Eq. 66 becomes\n0\n\n= \u2212\u03c1 \u2212 \u03b2Ei \u2212 ln P st (i) + ln(yi ) +\n\nX\n\nWi\u2192j [\u2212 ln Wi\u2192j \u2212 \u03bcj + \u03bdJi\u2192j ]\n\nj\n\n= \u2212\u03c1 \u2212 \u03b2Ei \u2212 ln P st (i) + ln(yi ) + ln(zi )\n\n(78)\n\nleading to\nP st (i) = yi zi e\u2212\u03c1\u2212\u03b2Ei\n\n(79)\n\nPlugging Eq. 79 into Eqs 74 and 76 leads to\nyj =\n\nX\n\nyi e\u2212\u03c1\u2212\u03b2Ei e\u03bdJi\u2192j\n\n(80)\n\nzk e\u2212\u03c1\u2212\u03b2Ek e\u03bdJi\u2192k\n\n(81)\n\ni\n\nand\nzi =\n\nX\nk\n\nC.\n\nOptimal stationary distribution P st (i) and transition probabilities Wi\u2192j\n\nIn summary, we have obtained that the optimal stationary distribution P st (i) and transition probabilities Wi\u2192j\nfollow the form\nP st (i)\nWi\u2192j\n\n= yi zi e\u2212\u03c1\u2212\u03b2Ei\nzj\n= e\u2212\u03c1\u2212\u03b2Ej +\u03bdJi\u2192j\nzi\n\n(82)\n\n\f14\nwhere the yi and zi are positive variables satisfying respectively the equations\nX\nyi e\u2212\u03c1\u2212\u03b2Ei e\u03bdJi\u2192j\nyj =\n\n(83)\n\nP\nthat correspond to the stationarity constraints P st (j) = i P st (i)Wi\u2192j and the equations\nX\ne\u03bdJi\u2192j e\u2212\u03c1\u2212\u03b2Ej zj\nzi =\n\n(84)\n\ni\n\nj\n\nthat correspond to the normalizations 1 =\n\nP\n\nj\n\nWi\u2192j , and\n1=\n\nX\n\nyi zi e\u2212\u03c1\u2212\u03b2Ei\n\n(85)\n\ni\n\nP\nthat correspond to the normalization 1 = i P st (i). To see more clearly what this structure means, it is convenient\nto introduce the bra and ket notations and to set\n\u03b2\n\nyi \u2261 e 2 Ei < L|i >\n\u03b2\n\nzi \u2261 e 2 Ei < i|R >\n\n(86)\n\nThen in terms of the matrix M defined by the positive matrix elements\n\u03b2\n\n\u03b2\n\n< i|M |j >\u2261 e\u2212 2 Ei e\u03bdJi\u2192j e\u2212 2 Ej\n\n(87)\n\nEqs 83 and 84 mean that < L| and |R > are respectively positive left-eigenvector and right-eigenvector of the nonsymmetric matrix M\ne\u03c1 < L|\ne\u03c1 |R >\n\n=< L|M |\n= M |R >\n\n(88)\n\nassociated with the highest eigenvalue e\u03c1 of the matrix M (Perron-Frobenius), with the normalization given by Eq 85\ne\u03c1 =< L|R >\n\n(89)\n\nThe equilibrium case discussed in the previous section IV corresponds to \u03bd = 0, yi = 1 = zi , < L|i >=< i|R >=\n\u03b2\ne\u2212 2 Ei . In the following to discuss what happens for \u03bd > 0, we will use the notations yi and zi that appear in Eqs 82\nD.\n\nConsequence for the probability distribution of dynamical trajectories\n\nFrom the optimal solution of Eq 82, one obtains that the probability of a trajectory \u03a9[0,t] of Eq. 28 takes the form\nP(\u03a9[0,t] ) = {i0 , i1 , ..., it })\n\n= P st (i0 )Wi0 \u2192i1 Wi1 \u2192i2 ...Wit\u22121 \u2192it\nzi\nzi\nzi\n= yi0 zi0 e\u2212\u03c1\u2212\u03b2Ei0 1 e\u2212\u03c1\u2212\u03b2Ei1 +\u03bdJi0 \u2192i1 2 e\u2212\u03c1\u2212\u03b2Ei2 +\u03bdJi1 \u2192i2 ... t e\u2212\u03c1\u2212\u03b2Eit +\u03bdJit\u22121 \u2192it\nzi0\nzi1\nzit\u22121\n= y z e\u2212\u03b2 (Ei0 +Ei1 +...+Eit )+\u03bd (Ji0 \u2192i1 +Ji1 \u2192i2 +...+Jit\u22121 \u2192it ) e\u2212(t+1)\u03c1\ni0 it\n\n= yi0 zit e\u2212\u03b2E(\u03a9[0,t+1] )+\u03bdJ(\u03a9[0,t] ) e\u2212(t+1)\u03c1\n\n(90)\n\nSo it is not exactly as simple as Eq. 9 : besides the expected Boltzmann-Gibbs factors involving the trajectory energy\nE(\u03a9[0,t+1] ) (already found for the equilibrium case in Eq. 55) and the trajectory current J(\u03a9[0,t] ), and besides the\nnormalization insured by the choice of \u03c1 in the last factor, there remains the non-trivial boundary prefactor yi0 zit\n: we believe that this term comes from the stationary constraint on the dynamics that we could impose within the\nMarkov chain framework, whereas we were not able to impose this stationary constraint at the formal level discussed\nin section II. However, this supplementary prefactor is a 'boundary term' containing only the initial and the final\nconfigurations. As a consequence, it is not expected to grow in time, and in the large time limit t \u2192 +\u221e, it will\nbecome subleading with respect to the time-extensive terms present in the exponential, since the trajectory energy\nand the trajectory current are extensive in time by the imposed constraints. (Note however that in some cases with\n\n\f15\nunbounded phase space, the 'boundary terms' may diverge and remain important even in the large-time limit, see\nsection 5.3 of the review [29] and references therein for more details).\nOur conclusion is thus that the formal solution of Eq. 9 neglects only the boundary terms of Eq. 90 and thus\ncaptures correctly the dominant terms in the large-time limit t \u2192 +\u221e. In particular, it contains the factor that is\nresponsible for the fluctuation relation of the integrated current discussed in section II C and for the dominant term\nof the entropy production discussed in section II D. We will obtain the same conclusion in the presence of locality\nconstraints on the dynamics that we consider in the next section.\nVI.\n\nEFFECTIVE STOCHASTIC MICROSCOPIC DYNAMICS IN THE NON-EQUILIBRIUM CASE\n\nAs explained in section IV F, there exists some difficulty to recover the equilibrium if one tries to maximize the\ndynamical entropy associated with a Markov Chain containing locality constraints, as a consequence of the possible\nconfiguration-dependent connectivities that one wishes to impose on the possible elementary moves. However, as\nrecalled in section IV E, the requirements on effective stochastic microscopic dynamics (Eq. 59) to describe the\nequilibrium dynamics are well understood, and lead to the detailed balance condition of Eq. 63. In this section,\nwe will thus follow the point of view of the Evans approach [11\u201314] : we consider that a local equilibrium dynamics\neq\ngenerated by some Markov Chain wi\u2192j\nsatisfying detailed balance is known, and we wish to determine the nonequilibrium appropriate modified Markov Chain wi\u2192j in the presence of an imposed current. Instead of maximizing\nthe 'full' dynamical entropy of Eq. 2, we will thus maximize the relative dynamical entropy with respect to the\nequilibrium dynamics, that we have introduced in Eq. 10.\nA.\n\nMaximization of the relative dynamical entropy with respect to the equilibrium\n\nFor the microscopic Markov Chain\npt+\u2206t (j) =\n\nX\n\npt (i)wi\u2192j\n\n(91)\n\ni\n\neq\nthe relative dynamical entropy of Eq. 10 with respect to the equilibrium dynamical trajectory corresponding to wi\u2192j\nhas for time-extensive behavior\n!\nX\nP(\u03a9[0,t] )\nwi\u2192j\nt X st X\ndyn\nSrel (t) \u2261 \u2212\nwi\u2192j ln\nP(\u03a9[0,t] ) ln eq\np (i)\n\u2243 \u2212\n(92)\neq\nP (\u03a9[0,t] ) t\u2192+\u221e \u2206t i\nwi\u2192j\nj\n\u03a9[0,t]\n\nThe maximization of this relative entropy in the presence of the constraints concerning the normalizations\nX\npst (i) = 1\n\n(93)\n\ni\n\nX\n\nwi\u2192j\n\n=1\n\nj\n\nthe stationarity condition\nX\n\npst (j)wj\u2192i \u2212 pst (i) = 0\n\n(94)\n\nj\n\nand the current\nJ dyn (t)\n1 X st X\nwi\u2192j Ji\u2192j = J0\np (i)\n\u2261\nt\n\u2206t i\nj\n\n(95)\n\ncan be done with Lagrange multipliers, with steps similar to the ones detailed in the previous section.\nTo write the final result, it is convenient to introduce the positive non-symmetric matrix\neq\n< i|M |j >= wi\u2192j\ne\u03bdJi\u2192j\n\n(96)\n\n\f16\nits largest eigenvalue e\u03c1 , and the corresponding right and left positive eigenvectors |R > and < L|\nM |R >\n< L|M\n\n= e\u03c1 |R >\n= e\u03c1 < L|\n\n(97)\n\nnormalized with\n< L|R >= e\u03c1\n\n(98)\n\nWith these notations, the optimal solution reads\npst (i)\nwi\u2192j\n\n= e\u2212\u03c1 < i|R >< L|i >\n< j|R >\n< j|R >\neq\n= e\u2212\u03c1 < i|M |j >\n= wi\u2192j\ne\u2212\u03c1+\u03bdJi\u2192j\n< i|R >\n< i|R >\n\n(99)\n\neq\nIn the equilibrium case \u03bd = 0, the matrix M reduces to the generator of the equilibrium Markov Chain Mij = wi\u2192j\n,\n\u03c1eq\n= 1, the right and the left eigenvectors are simply < i|Req >= 1 and\nso the maximal eigenvalue corresponds to e\n< Leq |i >= peq (i).\n\nB.\n\nConsequences for the probability distribution of dynamical trajectories\n\nFrom the solution of Eq. 99, one obtains that the probability of a trajectory \u03c9 = {i0 , i1 , ..., in }) takes the form\nP(\u03c9 = {i0 , i1 , ..., in })\n\n= pst (i0 )wi0 \u2192i1 wi1 \u2192i2 ...win\u22121 \u2192in\n< i1 |R >\n< in |R >\n= e\u2212\u03c1 < i0 |R >< L|i0 > wieq0 \u2192i1 e\u2212\u03c1+\u03bdJi0 \u2192i1\n...wieqn\u22121 \u2192in e\u2212\u03c1+\u03bdJin\u22121 \u2192in\n< i0 |R >\n< in\u22121 |R >\n\u0015\n\u0014\n< L|i0 >< in |R >\nP eq (\u03c9 = {i0 , i1 , ..., in })e\u03bdJ(\u03c9) e\u2212(n+1)\u03c1\n(100)\n=\npeq (i0 )\n\nAgain, it is not exactly as simple as Eq. 11: besides the equilibrium trajectory probability, the expected BoltzmannGibbs factors involving the trajectory current J(\u03a9[0,t] ), and besides the normalization insured by the choice of \u03c1 in\nthe last factor, there remains a boundary prefactor that depends only on the initial and final configurations. But this\nboundary factor is expected to become subleading in the large time limit t \u2192 +\u221e, as already discussed in section\nV D.\nC.\n\nLink with the Bayesian approach of Evans [11]\n\nIn [11], Evans has introduced an approach called 'Non-equilibrium Counterpart to detailed balance'. The general\nidea is clearly the same as in the present article, namely the maximization of the dynamical entropy in the presence\nof the appropriate constraints. However, the way of reasoning is slightly different and thus gives other useful points\nof view : Bayes theorem is used to analyse the properties of an elementary trajectory belonging to a macroscopic\ntrajectory satisfying the flux constraint with respect to the equilibrium dynamics. The outcome is that the transitions\ndriven\nwi\u2192j\nin the driven case should have the following form (see Eq. (24) of [11])\neq\ndriven\nwi\u2192j\n= wi\u2192j\ne\u03bdJi\u2192j \u2206t+qj (\u03bd)\u2212qi (\u03bd)\u2212Q(\u03bd)\u2206t\n\n(101)\n\nFrom the comparison with Eq. 99, one obtains the following correspondence : Q(\u03bd)\u2206t corresponds to the normalization\nfactor \u03c1, whereas qj (\u03bd) corresponds to ln < j|R >. The physical interpretation proposed by Evans is that the factor\nqj (\u03bd) measures the 'willingness' of state j to accept a future flux. We refer the reader to the very interesting series of\narticles [11\u201314] to have more detailed explanations and to see various examples of application.\nVII.\n\nCASE OF CONTINUOUS-TIME MASTER EQUATION\n\nUp to now we have considered the case of discrete-time Markov Chains, that constitute the simplest framework\nto define probabilities of dynamical trajectories and their Shannon entropy of Eq. 2. However, many studies on\n\n\f17\nnon-equilibrium systems prefer to consider stochastic dynamics that are generated by some continuous-time Master\nEquation\n\uf8ee\n\uf8f9\nX\nX\n\u2202t pt (j) =\npt (i)ki\u2192j \u2212 pt (j) \uf8f0\n(102)\nkj\u2192i \uf8fb\ni6=j\n\ni6=j\n\nIn this section, we describe how the results of the previous sections should be adapted for this case.\nA.\n\nDynamical entropy for the continuous-time master equation\n\nLet us first recall how the master Equation (102) can be obtained as the continuous limit \u2206t \u2192 0 of the Markov\nchain of Eq. 91. In the limit where the elementary time step becomes small \u2206t \u2192 0, it is natural to assume that the\ntransition probability wi\u2192j from i to another state j 6= i becomes proportional to \u2206t\nwi\u2192j \u2243 ki\u2192j \u2206t\n\u2206t\u21920\n\n(103)\n\nwhere ki\u2192j represents the transition rate per unit-time from i to j. The normalization of Eq. 25 yields that the\ntransition probability to remain on site i takes the form\nX\nwi\u2192i = 1 \u2212\nwi\u2192j \u2243 1 \u2212 \u2206tkout (i)\n(104)\nj6=i\n\n\u2206t\u21920\n\nwhere\nkout (i) \u2261\n\nX\n\nki\u2192j\n\n(105)\n\nj6=i\n\nrepresents the total exit rate out of state i. In this limit \u2206t \u2192 0, the finite-time Markov chain of Eq. 91 thus\nbecomes the master Equation 102.\nHowever as explained in [17], the continuous time description leads to some difficulties when one considers the\ndynamical entropy of Eq. 2. Indeed, the naive continuous limit of Eq. 32 becomes\nSdyn (t)\nt\n\n1 X st X\nwi\u2192j ln wi\u2192j\np (i)\n\u2206t i\nj\n\uf8ee\n\uf8f9\n1 X st \uf8f0X\n\u2243 \u2212\np (i)\nki\u2192j \u2206t ln(ki\u2192j \u2206t) + (1 \u2212 \u2206tkout (i)) ln (1 \u2212 \u2206tkout (i))\uf8fb\n\u2206t\u21920\n\u2206t i\nj6=i\n\uf8ee\n\uf8f9\nX\nX\npst (i) \uf8f0\n\u2243 \u2212\nki\u2192j ln(ki\u2192j \u2206t) \u2212 kout (i)\uf8fb\n\n=\u2212\n\n\u2206t\u21920\n\ni\n\n(106)\n\nj6=i\n\ni.e. the elementary time \u2206t remains in the argument of the logarithm to have a non-dimensional quantity. This\ndifficulty to define the 'absolute' entropy in problems involving continuous variables can be usually circumvented by\nconsidering the 'relative' entropy with respect to some reference. In our present framework, the reference will be the\neq\ncorresponding equilibrium master equation defined by transition rates ki\u2192j\nsatisfying the detailed balance condition\n(Eq 63)\neq\neq\n= peq (j)kj\u2192i\npeq (i)ki\u2192j\n\n(107)\n\n\f18\nThe continuous-time limit \u2206t \u2192 0 of the relative dynamical entropy of Eq. 92 reads\n!\ndyn\nSrel\n(t)\n1 X st X\nwi\u2192j\n=\u2212\np (i)\nwi\u2192j ln\neq\nt\n\u2206t i\nwi\u2192j\nj\n\uf8ee\n\uf8f9\n!\n\u0013\n\u0012\nki\u2192j\n1 \u2212 \u2206tkout (i) \uf8fb\n1 X st \uf8f0X\np (i)\nki\u2192j \u2206t ln\n+ (1 \u2212 \u2206tkout (i)) ln\n=\u2212\neq\neq\n\u2206t i\nki\u2192j\n1 \u2212 \u2206tkout\n(i)\nj6=i\n\uf8ee\n\uf8f9\n!\nX\nX\nk\ni\u2192j\neq\npst (i) \uf8f0\u2212\n\u2243\nki\u2192j ln\n+ kout (i) \u2212 kout\n(i)\uf8fb\neq\n\u2206t\u21920\nk\ni\u2192j\ni\nj6=i\n\uf8ee\n\uf8f9\n!\nX\nX\nX\nX eq\nk\ni\u2192j\npst (i) \uf8f0\u2212\n\u2243\nki\u2192j ln\n+\nki\u2192j \u2212\nki\u2192j \uf8fb\neq\n\u2206t\u21920\nk\ni\u2192j\ni\nj6=i\n\nj6=i\n\n(108)\n\nj6=i\n\nSo this relative dynamical entropy is well-defined for continuous time Master Equations, and can be used in maximization procedures.\nB.\n\nMaximization of the relative entropy with the appropriate constraints\n\nWe wish to maximize the relative dynamical entropy of Eq. 108 with respect to all stationary states pst (i) satisfying\nthe normalization (as in Eq. 38)\nX\npst (i) = 1\n(109)\nN \u2261\ni\n\nand with respect to all possible transition rates ki\u2192j with j 6= i (note that here there is no normalization equation\nas Eq 39, since it has already been taken into account in Eqs 104 and 105) that have pst (i) as stationary distribution\n(equivalent of Eq. 40)\nX\nX\n\u03a3i \u2261\npst (j)kj\u2192i \u2212 pst (i)\nki\u2192j = 0\n(110)\nj6=i\n\nj6=i\n\nin the presence of the following flux constraint (equivalent of Eq. 95)\nJ dyn (t) X st X\np (i)\nki\u2192j Ji\u2192j = J0\n\u2261\nt\ni\n\n(111)\n\nj6=i\n\nSo we introduce the following functional with appropriate Lagrange multipliers\n\u0012 dyn\n\u0013\nX\nS dyn (t)\nJ (t)\n\u03a8 \u2261 rel\n\u03bci (\u03a3i ) + \u03bd\n\u2212 \u03c1(N \u2212 1) \u2212\n\u2212 J0\nt\nt\ni\n\uf8ee\n\uf8f9\n!\nX\nX\nX\nX\nX\nki\u2192j\neq \uf8fb\npst (i) \uf8f0\u2212\npst (i) \u2212 1)\n+\nki\u2192j ln\nki\u2192j \u2212\n=\nki\u2192j\n\u2212 \u03c1(\neq\nk\ni\u2192j\ni\ni\nj6=i\nj6=i\nj6=i\n\uf8f6\n\uf8eb\n\uf8f6\n\uf8eb\nX\nX\nX\nX\nX\npst (i)\nki\u2192j Ji\u2192j \u2212 J0 \uf8f8\n\u03bci \uf8ed\npst (j)kj\u2192i \u2212 pst (i)\nki\u2192j \uf8f8 + \u03bd \uf8ed\n\u2212\ni\n\nj6=i\n\nj6=i\n\nThe optimization with respect to ki\u2192j with i 6= j\n\"\n\u03b4\u03a8\nst\n0=\n= p (i) \u2212 ln\n\u03b4ki\u2192j\n\ni\n\nki\u2192j\neq\nki\u2192j\n\n!\n\n(112)\n\nj6=i\n\n\u2212 \u03bcj + \u03bci + \u03bdJi\u2192j\n\n#\n\n(113)\n\nyields\neq\nki\u2192j = ki\u2192j\ne\u03bci \u2212\u03bcj +\u03bdJi\u2192j\n\n(114)\n\n\f19\nwhich is the appropriate continuous limit of the Markov chain result of Eq. 99 and of the Evans result cited in Eq.\n101.\nThe optimization with respect to pst (i)\n#\n\"\n!\nX eq\nX\n\u03b4\u03a8\nki\u2192j\n0 = st\nki\u2192j \u2212 \u03c1\n(115)\n=\n+ 1 \u2212 \u03bcj + \u03bci + \u03bdJi\u2192j \u2212\nki\u2192j \u2212 ln\neq\n\u03b4p (i)\nki\u2192j\nj6=i\n\nj6=i\n\ncan be simplified using Eq. 113 into\nX\n\n0=\n\nki\u2192j \u2212\n\nj6=i\n\nX\n\neq\nki\u2192j\n\u2212\u03c1\n\n(116)\n\nj6=i\n\nor equivalently in terms of the total exit rates introduced in Eq 105, one obtains\neq\nkout (i) = kout\n(i) + \u03c1\n\n(117)\n\nPhysically, this means that for all configurations i, the exit rate is shifted by the same amount \u03c1 with respect to the\nequilibrium case. Eq. 117 has been previously obtained by Baule and Evans in [12] within their slightly different\nperspective, in order to obtain a set of invariant quantities for shear flows and to compute the non-equilibrium rates\nvia some network rules (see [12] for more details).\nIn contrast to Eq. 113, Eq. 117 can appear as 'new' with respect to the discrete-time Markov chain result of Eq.\n99. Another apparent difference is that the discrete-time Markov chain result of Eq. 99 contains both the stationary\ndistribution pst (i) and the transition probabilities wi\u2192j that are determined together, whereas here the two types of\nequations (Eq. 113 and Eq. 117) concern only the transition rates, and pst (i) does not appear anymore. However, this\nabsence of pst (i) is only apparent, because pst (i) is of course directly determined by the rates ki\u2192j via the stationarity\ncondition of Eq. 110. To make clearer the correspondence with the discrete-time Markov chain result of Eq. 99, it is\nthus useful to reformulate the continuous-time master equation solution as follows.\nC.\n\nReformulation of the solution in terms of an eigenvalue problem\n\nThe aim of this section is to reformulate the solution found above in Eqs 113 and 117 in terms of an eigenvalue\nproblem to see the similarity with the discrete-time Markov chain solution of Eq. 99.\nTo replace the matrix M of Eq. 96, it is convenient to introduce the matrix N defined by the matrix elements\nNi6=j\nNii\n\neq\n= ki\u2192j\ne\u03bdJi\u2192j\nX eq\neq\n=\u2212\nki\u2192j \u2261 \u2212kout\n(i)\n\n(118)\n\n< j|R >\n< i|R >\n\n(119)\n\nj6=i\n\nSetting e\u2212\u03bcj =< j|R >, Eq. 113 becomes\nki\u2192j = Nij\nwhereas Eq. 117 becomes\neq\n\u03c1 = kout (i) \u2212 kout\n(i) =\n\nX\nj6=i\n\nNij\n\nX\n< i|N |R >\n1\n< j|R >\n< i|N |j >< j|R >=\n+ Nii =\n< i|R >\n< i|R > j\n< i|R >\n\n(120)\n\nmeaning that |R > is a right eigenvector of the matrix N corresponding to the eigenvalue \u03c1\nN |R >= \u03c1|R >\n\n(121)\n\nLet us now rewrite the stationary equation of Eq. 110 using Eq. 118, Eq. 119 and Eq. 117\n0=\n\nX\ni6=j\n\npst (i)ki\u2192j \u2212 pst (j)kout (j) =\n\nX\ni6=j\n\npst (i)Nij\n\n< j|R >\neq\n\u2212 pst (j) (kout\n(j) + \u03c1)\n< i|R >\n\n(122)\n\n\f20\nIt is thus convenient to set\npst (i) =< i|R >< L|i >\nto rewrite Eq. 122 as\nX\nX\n< L|i >< i|N |j > \u2212\u03c1 < L|j >=< L|N |j > \u2212\u03c1 < L|j >\n0=\n< L|i > Nij + < L|j > (Njj \u2212 \u03c1) =\ni6=j\n\n(123)\n\n(124)\n\ni\n\nmeaning that < L| is a left eigenvector of the matrix N corresponding to the eigenvalue \u03c1\n< L|N = \u03c1 < L|\n\n(125)\n\nIn summary, the solution of Eqs 113 and 117 for the continuous-time master equation can be written in terms of\nan eigenvalue problem for the matrix N introduced in Eq. 118 as follows :\npst (i)\nki\u2192j\n\n=< i|R >< L|i >\n< j|R >\n= Nij\n< i|R >\n\n(126)\n\nwhere |R > and < L| are the right and the left positive eigenvectors associated with the largest eigenvalue \u03c1 of the\nmatrix N , with the following normalization\n1 =< L|R >\n\n(127)\n\nThe correspondence with the discrete-time Markov chain result of Eq. 99 is now clear. As a final remark, let us\nmention that in the equilibrium case \u03bd = 0, the matrix N is the generator of the equilibrium dynamics, so the maximal\neigenvalue corresponds to \u03c1eq = 0, the corresponding right and the left eigenvectors being simply < i|Req >= 1 and\n< Leq |i >= peq (i).\nD.\n\nRelation with the 'constrained dynamics' introduced to study large deviations\n\nThe reformulation in terms of an eigenvalue problem described in the previous section is also useful to make the\nlink with the the 'constrained dynamics' that have been introduced in various studies concerning large deviations of\nstochastic processes described by master equations (see for instance the recent works [39\u201342] and references therein).\nIn this context, the point of view is as follows : one considers some 'true' dynamics and one is interested into large\ndeviations properties of some observable like the current. To compute the probability of rare events giving rise to an\nanomalous current for the 'true' dynamics, it is useful to introduce an 'auxiliary' dynamics that takes into account\nthe conditioning to produce a given anomalous current (see [39\u201342] for more details). The transition rules of this\nauxiliary dynamics and its stationary state are given in terms of left/right eigenvectors of a modified operator via the\nsame formula written above, see for instance Eqs (2.15) (2.17) (2.18) (2.19) in [39] or Eqs (2.16) (2.18) and (2.19) in\n[40] : the exchange of the roles of the right and left eigenvectors with respect to the present notations comes from the\ndifferent choice in the writing of matrices, since [39, 40] have chosen the 'quantum mechanical' convention where the\ninitial state is on the right and the final state is on the left. The fact that exactly the same equations appear can be\nunderstood as follows. In the present paper, we have described how the maximization of the dynamical entropy yields\nEq. 11 at a formal level, and give the results of the previous section when applied to an explicit master equation.\nBut of course another possibility could be to take the formal solution of Eq. 11 as a starting point, and to derive the\nconsequences of this reweighting of trajectories for the specific case of a master equation : this is exactly the route\nfollowed in the large deviation studies mentioned above [39\u201342] and so one should indeed obtain the same results\nby consistency. However, even if the equations are exactly the same, the physical interpretation of this modified\ndynamics is different : in the large deviation studies [39\u201342], this modified dynamics is usually presented only as\na useful technical tool to better understand the large deviations of the 'true' dynamics, whereas in the approach\nsummarized in the present paper, one considers that the modified dynamics is the 'real' dynamics in the presence of\nan imposed current.\nAn interesting output of this comparison with large deviation studies is that it provides specific studies of this\nmodified dynamics in models different from the examples considered in the works of Evans [11\u201314] : the auxiliary\ndynamics corresponding to the large deviations of the current of the Asymmetric Simple Exclusion Process has been\nstudied in various situations or regimes in [39, 41, 42], whereas constrained dynamics for the Glauber Ising chain has\nbeen considered in [40]. Since the change of measure is a standard tool in the large deviation theory, many other\nexamples can actually be found in the huge number of works concerning large deviations for stochastic processes.\n\n\f21\nVIII.\n\nCONCLUSIONS AND PERSPECTIVES\n\nIn this paper, we have argued that if one wishes to formulate a general principle based on the maximization of some\nnotion of 'entropy' for non-equilibrium steady states, the Shannon entropy associated to the probability distribution\nof dynamical trajectories is definitely the most natural, as first proposed by Filyokov and Karpov in 1967. The\ngeneral idea is then to maximize dynamical entropy of Eq. 2 in the presence of appropriate constraints, including the\nmacroscopic current of interest, via the method of Lagrange multipliers. We have tried to give a self-contained and\nunified presentation of this type of approach. We have first described at the formal level how this maximization leads\nto generalized Gibbs distribution for the probability distribution of dynamical trajectories, and to some fluctuation\nrelation of the integrated current. We have then discussed in detail the cases of well defined stochastic dynamics\ngenerated either by discrete-time Markov Chains or by continuous-time Master Equations. In the cases where the\nuse of the 'full' dynamical entropy of Eq. 2 leads to some difficulties, we have shown how the use of the 'relative'\ndynamical entropy of Eq. 10 allows to solve the problems. The obtained results are in full agreement with the Evans\napproach called 'Non-equilibrium Counterpart to detailed balance' [11\u201314], but give a slightly different perspective. In\nparticular, we have obtained that the stationary distribution and the transitions probabilities or transitions rates could\nbe obtained in various cases from an eigenvalue problem. Finally, we have explained the link with the constrained\ndynamics that are often introduced in large deviations studies of stochastic processes.\nIn this article, we have remained at a very general level with a dynamics visiting a series of configurations, to see\nmore clearly what general properties could emerge, since it is at this level of generality that the statistical physics\ntheory of equilibrium is formulated. However it is clear that it would be interesting in the future to study more\nprecisely how this type of approach can be applied in various models of interest, and to discuss whether the obtained\ndynamics can be considered as 'real'. An important issue is of course to compare with other approaches that solve\nexactly some non-equilibrium dynamics. In the field of quantum models, the non-equilibrium steady states have been\nfound to be generalized Gibbs states, but they involve an infinite number of conserved quantities coming from the\nintegrability of the considered models [43, 44]. For non-integrable models, one may thus hope that the non-equilibrium\nsteady states correspond to much simpler generalized Gibbs states.\nAs a final remark, we should stress that the idea of maximizing some dynamical entropy to describe non-equilibrium\nsteady states has been argued here to hold for 'physical systems' for which, in the absence of any imposed current, the\nnotion of equilibrium exists and corresponds to the maximization of the usual 'static' entropy of statistical physics,\nand for which effective stochastic models satisfying detailed balance are well accepted to describe the equilibrium\ndynamics. But of course, in the field of non-equilibrium, many models of interest are inspired not by physics, but by\nbiology (like predator-prey models), sociology (like road traffic models), politics (like voter models) etc... In all these\ncases, it is clear that one can choose arbitrarily the microscopic rates to model the considered phenomenon as one\nwishes.\nAcknowledgements\n\nIt is a pleasure to thank the Saclay working group 'Climate and Statistical mechanics', where B. Dubrulle, C.\nHerbert and D. Paillard have given talks about their work concerning the 'maximum entropy production' [45] : this\nled me to read the review [2] where I have found the papers of Filyokov and Karpov [7\u20139]. I also wish to thank\nC. Appert-Rolland, T. Bodineau , R. Ch\u00e9trite, Mike Evans, R. Jack, W. Hoover, V. Lecomte, C. Maes, K. Mallick,\nD. Simon, P. Sollich, F. van Wijland and B. Wynants for useful correspondence, discussion or for indicating to me\nrelevant references.\nAppendix A: Reminder on the maximization of the static entropy for the equilibrium state\n\nAt equilibrium, one is interested into the equilibrium probabilities P eq (i) of occupations of configurations i. The\nShannon entropy associated with the equilibrium distribution is\nX\nP eq (i) ln P eq (i)\n(A1)\nS eq = \u2212\ni\n\n(i) If the only constraint is the normalization,\nN\u2261\n\nX\ni\n\nP eq (i) = 1\n\n(A2)\n\n\f22\nthe maximization of the entropy of Eq. A1 with the constraint of Eq. A2 can be obtained by introducing a Lagrange\nmultiplier \u03bb and the functional\nX\nX\nP eq (i) \u2212 1)\n(A3)\nP eq (i) ln P eq (i) \u2212 \u03bb(\n\u03a6\u03bb = S eq \u2212 \u03bb(N \u2212 1) = \u2212\ni\n\ni\n\nThe optimization with respect to Peq (j) yields\n0=\n\n\u03b4\u03a6\u03bb\n= \u2212 ln P eq (j) \u2212 1 \u2212 \u03bb\n\u03b4Peq (j)\n\n(A4)\n\nleading to Peq (j) = e\u22121\u2212\u03bb , where \u03bb is determined by the normalization constraint of Eq. A2. So Peq (j) is simply\nuniform over all states.\n(ii) If in addition to the normalization of Eq. A2, one imposes also a constraint for the averaged energy\nX\nEi P eq (i) = E0\n(A5)\n< E >\u2261\ni\n\none has to introduce another Lagrange multiplier \u03b2 and the functional\n\u03a6\u03bb,\u03b2\n\n= S eq \u2212 \u03bb(N \u2212 1) \u2212 \u03b2(< E > \u2212E0 )\nX\nX\nX\nEi P eq (i) \u2212 E0 )\nP eq (i) \u2212 1) \u2212 \u03b2(\nP eq (i) ln P eq (i) \u2212 \u03bb(\n=\u2212\n\n(A6)\n\ni\n\ni\n\ni\n\nThe optimization with respect to Peq (j) yields\n0=\n\n\u03b4\u03a6\u03bb,\u03b2\n= \u2212 ln P eq (j) \u2212 1 \u2212 \u03bb \u2212 \u03b2Ej\n\u03b4Peq (j)\n\n(A7)\n\nleading to Peq (j) = e\u22121\u2212\u03bb\u2212\u03b2Ej , where \u03bb is determined by the normalization constraint of Eq. A2, and \u03b2 by Eq. A5\nThen Peq (j) follows the Boltzmann-Gibbs distribution\ne\u2212\u03b2Ej\nPeq (j) = P \u2212\u03b2Ei\nie\n\n(A8)\n\nThis derivation of the Boltzmann-Gibbs distribution, introduced by Jaynes [23], has the advantage to be very simple\nand to really show what the principle of maximum entropy contains. For more details on the interest to consider\nstatistical physics from the point of view of the Shannon information entropy, we refer the reader to the 'old' book\n[46] and to recent presentations [47] and references therein.\nAppendix B: Technical simplifications for an alternate Markov chain\n\nIn their original paper [7], Filyokov and Karpov have not considered the homogeneous Markov chain of Eq. 24, but\nhave focused instead onto an alternate Markov chain, that has been also reconsidered recently by Favretti [10]. In\nthis Appendix, we show how this alternate Markov chain framework yields technical simplifications with respect to\nthe solution described in section V concerning the homogeneous Markov chain.\n1.\n\nAlternate Markov Chain\n\nIn this section, we consider the alternate Markov chain, where the transition probabilities Wi\u2192j takes alternatively\ntwo sets of values Ai\u2192j and Bi\u2192j , so that the probability of a trajectory of Eq. 28 now becomes\nP(\u03a9[0,2t] = {i0 , i1 , ..., i2t }) = P even (i0 )Ai0 \u2192i1 Bi1 \u2192i2 ...Ai2t\u22122 \u2192i2t\u22121 Bi2t\u22121 \u2192i2t\n\n(B1)\n\nwith the normalizations (as in Eq. 25)\nNiA\n\n\u2261\n\nX\n\nAi\u2192j = 1\n\nj\n\nNiB\n\n\u2261\n\nX\nj\n\nBi\u2192j = 1\n\n(B2)\n\n\f23\nThe stationary states P even (i), P odd (i) at even and odd times associated with this alternate Markov chain satisfy\nX\nP odd(j)Bj\u2192i \u2212 P even (i) = 0\n\u03a3even\n\u2261\ni\nj\n\n\u03a3odd\ni\n\n\u2261\n\nX\n\nP even (j)Aj\u2192i \u2212 P odd(i) = 0\n\n(B3)\n\nj\n\nwith the normalizations\nN even \u2261\n\nX\n\nP even (i)\n\n=1\n\ni\n\nN odd \u2261\n\nX\n\nP odd(i)\n\n=1\n\n(B4)\n\ni\n\nThe dynamical entropy of Eq. 31 becomes\n\uf8f9\n\uf8ee\nX\nX\nX\nX\nBi\u2192j ln Bi\u2192j \uf8fb\nP odd (i)\nAi\u2192j ln Ai\u2192j +\nP even (i)\nS dyn (2t) = \u2212t \uf8f0\n\n(B5)\n\nj\n\nj\n\nj\n\ni\n\nThe averaged energy is now fixed by the constraint\n#\n\"\nX\nE dyn (2t)\n1 X even\nodd\nP (i)Ei = E0\nP\n(i)Ei +\n\u2261\n2t\n2 i\ni\n\n(B6)\n\nthat replaces Eq. 41.\n2.\n\nSimplification concerning the current constraint\n\nIn [7, 10], the interest was in an energy current flowing through the system : the advantage of this formulation\nwith an alternate Markov chain is that one may consider that during the evolution described by A, there is a flow of\nenergy entering the system, whereas during the evolution described by B, there is a flow of energy coming out of the\nsystem. To remain in a stationary state, these two flows have to be equal, and can be simply expressed in terms of\nthe difference of averaged energies between the even and odd stationary states\nX\nX\nX\nX\nE(i)P even (i)\nE(j)P odd (j) \u2212\nAi\u2192j (E(j) \u2212 E(i)) =\nP even (i)\nJEin =\nj\n\nj\n\nX\n\nX\n\ni\n\nJEout\n\n=\n\nX\n\nP\n\nodd\n\n(i)\n\nBi\u2192j (E(i) \u2212 E(j)) =\n\nj\n\ni\n\ni\n\nE(i)P\n\nodd\n\n(i) \u2212\n\nX\n\nE(j)P even (j) = JEin\n\n(B7)\n\nj\n\ni\n\nIn the following, we consider more generally the case of a current JK that can be written similarly as the difference\nbetween some observable K between the even and odd stationary states (K is the 'charge' associated with the current\nJK )\nX\nX\nX\nX\nin\nK(i)P even (i)\nK(j)P odd(j) \u2212\nAi\u2192j (K(j) \u2212 K(i)) =\nP even (i)\nJK\n=\nj\n\nj\n\nX\n\nX\n\ni\n\nout\nJK\n\n=\n\nX\ni\n\nP\n\nodd\n\n(i)\n\nBi\u2192j (K(i) \u2212 K(j)) =\n\nj\n\ni\n\nK(i)P\n\nodd\n\n(i) \u2212\n\ni\n\nX\n\nin\nK(j)P even (j) = JK\n\n(B8)\n\nj\n\nso that the constraint of Eq. 64 can be replaced by\n\u0002\n\u0003\nJ dyn (2t) X\nK(i) P odd (i) \u2212 P even (i)\n\u2261\nt\ni\n\n(B9)\n\n\f24\n3.\n\nOptimization of the Lagrange functional\n\nSo the functional of Eq. 65 is replaced by (some factors of 2 have been added to simplify slightly the notations)\nE dyn (t)\nS dyn (2t)\n\u2212 \u03c1even (N even \u2212 1) \u2212 \u03c1odd (N odd \u2212 1) \u2212 \u03b2(\n\u2212 E0 )\nt\nt\n\u0012 dyn\n\u0013\nX\nX\n\u0001\n\u0001 X even even\n\u0001 X B\nJ (2t)\nodd\nodd\nB\nA\n\u03bc\n\u03a3\n\u03bc\n(\u03a3\n)\n\u2212\n+\n\u03bd\n\u03bb\n\u03bbA\nN\n\u2212\n1\n\u2212\nN\n\u2212\n1\n\u2212\n\u2212\n\u2212\nJ\n0\ni\ni\ni\ni\ni\ni\ni\ni\nt\ni\ni\ni\ni\n\uf8f9\n\uf8ee\nX\nX\nX\nX\nBi\u2192j ln Bi\u2192j \uf8fb\nP odd (i)\nAi\u2192j ln Ai\u2192j +\nP even (i)\n= \u2212\uf8f0\n\u03a8\u2261\n\n\u2212\u03c1\n\nX\nX\nP odd (i) \u2212 1)\nP even (i) \u2212 1) \u2212 \u03c1odd (\n(\ni\n\ni\n\n\"\nX\n\n\u2212\u03b2\n\nP even (i)Ei +\n\nX\ni\n\n+\u03bd\n\n\uf8eb\n\n\uf8ed\n\u03bceven\ni\n\nX\ni\n\nX\n\n#\n\nP odd (i)Ei \u2212 2E0\n\ni\n\ni\n\n\u2212\n\nj\n\nj\n\nj\n\ni\n\neven\n\nX\nj\n\n!\n\n\uf8f6\n\nP odd (j)Bj\u2192i \u2212 P even (i)\uf8f8 \u2212\n\n\u0002\n\u0003\nK(i) P odd (i) \u2212 P even (i) \u2212 J0\n\n!\n\n\u2212\n\nX\ni\n\nX\ni\n\n\uf8eb\n\n\uf8ed\n\u03bbA\ni\n\uf8eb\n\n\uf8ed\n\u03bcodd\ni\n\nX\n\nX\nj\n\nj\n\n\uf8f6\n\nAi\u2192j \u2212 1\uf8f8 \u2212\n\nX\ni\n\n\uf8f6\n\uf8eb\nX\n\uf8ed\nBi\u2192j \u2212 1\uf8f8\n\u03bbB\ni\nj\n\n\uf8f6\n\nP even (j)Aj\u2192i \u2212 P odd (i)\uf8f8\n(B10)\n\nThe optimization with respect to Ai\u2192j\n0=\nyields\n\n\u0003\n\u0002\n\u03b4\u03a8\nodd\n= P even (i) \u2212 ln Ai\u2192j \u2212 1 \u2212 \u03bbA\ni \u2212 \u03bcj\n\u03b4Ai\u2192j\nA\n\nAi\u2192j = e\u22121\u2212\u03bbi\n\n(B11)\n\n\u2212\u03bcodd\nj\n\n(B12)\n\nThe normalization of Eq. B2 yields that \u03bbA\ni is independent of i and given by\nX\nodd\nA\ne\u2212\u03bcj\ne1+\u03bbi =\n\n(B13)\n\nj\n\nThe stationary Equation of Eq. B3 yields using Eq. B4\nP\n\nodd\n\n(j) =\n\nX\n\nP\n\neven\n\ni\n\n(i)Ai\u2192j\n\nodd\nodd\nX\ne\u2212\u03bcj\ne\u2212\u03bcj\neven\nP\n(i)) P \u2212\u03bcodd = P \u2212\u03bcodd\n=(\nk\nk\nke\nke\ni\n\n(B14)\n\nThe optimization with respect to Bi\u2192j yields similar equations and solutions, so that finally one has the simple forms\nodd\n\ne\u2212\u03bcj\nAi\u2192j = P odd (j) = P \u2212\u03bcodd\nk\nke\neven\n\nBi\u2192j = P\n\neven\n\ne\u2212\u03bcj\n(j) = P \u2212\u03bceven\nk\nke\n\n(B15)\n\nThe optimization of Eq. B10 with respect to P even (i) yields\n0\n\n=\n\n\u03b4\u03a8\n\u03b4P even (i)\n\n=\u2212\n\nX\n\nAi\u2192j ln Ai\u2192j \u2212 \u03c1even \u2212 \u03b2Ei + \u03bceven\n\u2212\ni\n\nX\n\n\u03bcodd\nj Ai\u2192j \u2212 \u03bdK(i)\n\n(B16)\n\nj\n\nj\n\nyields using Eq B15\n\u2212 \u03bceven\n= \u2212\u03c1even \u2212 \u03b2Ei \u2212 \u03bdK(i) + ln\ni\n\nX\nk\n\ne\n\n\u2212\u03bcodd\nk\n\n!\n\n(B17)\n\n\f25\nEq. B15 then yields\neven\n\ne\u2212\u03b2Ei \u2212\u03bdKi\ne\u2212\u03bci\nP even (i) = P \u2212\u03bceven = P \u2212\u03b2E \u2212\u03bdK\nk\nk\nk\nke\nke\n\n(B18)\n\nSimilarly, the optimization with respect to P even (i) yields\n\ne\u2212\u03b2Ei +\u03bdKi\nP odd (i) = P \u2212\u03b2E +\u03bdK\nk\nk\nke\n\n(B19)\n\nSo here in contrast to the case of the homogeneous Markov chain discussed in section V, one obtains two BoltzmannGibbs distributions, without any prefactor like the functions (yi , zi ) in Eq 82. This simple result was found on the\nspecial case of the energy flow Ki = Ei by Favretti [10] ( who has used the correct expression for the Kolmogorov-Sinai\nentropy of the alternate Markov chain, whereas an erroneous expression has been actually used in the initial work [7]\n) : the even and odd stationary distributions of Eq. B18 and B19 are then two Boltzmann-Gibbs distributions at two\ndifferent temperatures that are fixed by the constraints on the averaged energy and on the averaged energy flow.\nDespite the technical simplifications of the alternate Markov chain, we find that it is rather artificial from a physical\npoint of view. Since the result means that the system oscillates between two distinct Boltzmann-Gibbs distributions,\nwe feel that it could only correspond to physical situations where the energy is added or removed instantaneously at\neven and odd times, and that the system then relaxes to its new equilibrium during the macroscopic time \u03c4 of the\nMarkov chain. Otherwise, if the energy were added and removed continuously during the time intervals, this would\nmean that one should somehow have thermal equilibrium at all times with an adiabatic change of temperature, which\nseems extremely restrictive. This is why in the present paper, we have chosen to put the main focus of the case of\nthe homogeneous Markov Chain.\n\n[1]\n[2]\n[3]\n[4]\n[5]\n[6]\n[7]\n[8]\n[9]\n[10]\n[11]\n[12]\n[13]\n[14]\n[15]\n[16]\n[17]\n[18]\n\n[19]\n[20]\n[21]\n[22]\n[23]\n\nB. Derrida, arXiv:1012.1136.\nL.M. Martyushev and V.D. Seleznev, Phys. Rep. 426, 1 (2006)\nS. Bruers, cond-mat/0604482.\nL.M. Martyushev, A.S. Nazarova and V.D. Seleznev, J. Phys. A 40, 371 (2007)\nS. Bruers, C. Maes and K. Netocny, J. Stat. Phys. 129, 725 (2007)\nP. Gaspard, \"Chaos, scattering and statistical mechanics\", Cambridge University Press (1998).\nA.A. Filyokov and V. Ya. Karpov, Inzhenerno-Fizicheskii Zhurnal 13, 624 (1967).\nA.A. Filyokov, Inzhenerno-Fizicheskii Zhurnal 13, 798 (1967).\nA.A. Filyokov, Inzhenerno-Fizicheskii Zhurnal 14, 814 (1968).\nM. Favretti, Entropy 11, 675 (2009).\nR.M.L. Evans, J. Phys. A 38, 293 (2005);\nsee also R.M.L. Evans, Phys. Rev. Lett. 92, 150601 (2004) and Physica A 340, 364 (2004).\nA. Baule and R. M. L. Evans, Phys. Rev. Lett. 101, 240601 (2008): A Baule, R M L Evans, Journal of Statistical Mechanics\nTheory and Experiment P03030 (2010)\nA. Simha, R. M. L. Evans, and A. Baule, Phys. Rev. E 77, 031117 (2008) ;\nR. M. L. Evans, R. A. Simha, A. Baule, and P. D. Olmsted Phys. Rev. E 81, 051109 (2010)\nR M L Evans, Contemporary Physics 51, 413 (2010)\nR. Dewar, J. Phys. A 36, 631 (2003) and J. Phys. A 38, L371 (2005).\nZ. Burda, J. Duda, J.M. Luck, B. Waclaw, Phys. Rev. Lett. 102, 160602 (2009) and Acta Phys. Polon. B 41, 949 (2010).\nV. Lecomte, C. Appert-Rolland and F. van Wijland, Phys. Rev. Lett. 95, 010601 (2005);\nV. Lecomte, C. Appert-Rolland and F. van Wijland, J. Stat. Phys. 127, 51 (2007);\nV. Lecomte, C. Appert-Rolland and F. van Wijland, Cr. Acad. Sc. Paris 8, 609 (2007).\nJ.P. Garrahan, R.L. Jack,V. Lecomte, E. Pitard, K. van Duijvendijk and F. van Wijland, Phys. Rev. Lett. 98, 195702\n(2007);\nK. van Duijvendijk, G. Schehr and F. van Wijland, Phys. Rev. E 78, 011120 (2008);\nJ.P. Garrahan, R.L. Jack, V. Lecomte, E. Pitard, K. van Duijvendijk and F. van Wijland, J. Phys. A 42, 075007 (2009);\nK. van Duijvendijk, R.L. Jack and F. van Wijland, Phys. Rev. E 81, 011110 (2010).\nT. Antal, Z. Racz and L. Sasvari, Phys. Rev. Lett. 78, 167 (1997); T. Antal, Z. Racz, A. Rakos, and G. M. Schutz, Phys.\nRev. E 57, 5184 (1998); T. Antal, Z. Racz, A. Rakos, and G. M. Schutz, Phys. Rev. E 59, 4912 (1999).\nV. Eisler, Z. Racz, and F. van Wijland, Phys. Rev. E 67, 056129 (2003)\nD. S. Kosov , The Journal of Chemical Physics 120, 7165 (2004)\nV. Eisler and Z. Zimbors, Phys. Rev. A 71, 042318 (2005)\nE.T. Jaynes, Phys. Rev. 106 , 620 (1957).\nOther articles of E.T. jaynes can be found on the web site http://bayes.wustl.edu/etj/node1.html\n\n\f26\n[24] E.T. Jaynes, \"Macroscopic Prediction\" in Complex Systems - Operational Approaches, H. Haken (ed.), Springer-Verlag,\nBerlin (1985).\n[25] L.B. Koralov and Y.G. Sinai, \"Theory of Probability and Random Processes\", Springer Verlag, Berlin (2007).\n[26] J.R. Banavar and A. Maritan, cond-mat/0703622; J.R. Banavar, A. Maritan and I. Volkov, J. Phys. Condens. Matter 22 ,\n063101 (2010).\n[27] H. Touchette, Phys. Rep. 478, 1 (2009).\n[28] B. Derrida J. Stat. Mech. (2007) P07023.\n[29] R J Harris and G M Sch\u00fctz J. Stat. Mech. (2007) P07020.\n[30] J. Kurchan J. Stat. Mech. (2007) P07005.\n[31] E.M. Sevick, R. Prabhakar, S. R. Williams, D. J. Searles, Ann. Rev. of Phys. Chem. Vol 59, 603 (2008).\n[32] R K P Zia and B Schmittmann J. Stat. Mech. (2007) P07012.\n[33] C. Maes, K. Netocny, and B. Shergelashvili, A selection of nonequilibrium issues, In Methods of Contemporary Mathematical Statistical Physics, R. Koteck\u00fd ed. Lecture notes in Mathematics, Vol. 1970 (2009) 247.\n[34] R. Chetrite, PhD Thesis (2008) available at http://perso.ens-lyon.fr/raphael.chetrite/indexfra.html\n[35] C. Maes, J. Stat. Phys. 95, 367 (1999)\n[36] C. Maes and F. Redig, J. Stat. Phys. 101, 3 (2000);\nC. Maes, F. Redig and A. Van Moffaert, J. Math. Phys. 41, 1528 (2000);\nC. Maes, K. Netocny and B. Wynants, Markov Proc. Rel. Fields. 14, 445 (2008).\n[37] J. Schnakenberg, Rev. Mod. Phys. 48, 571 (1976).\n[38] J.L. Lebowitz and H. Spohn, J. Stat. Phys. 95, 333 (1999).\n[39] D. Simon, JSTAT P07017 (2009).\n[40] R.L. Jack and P. Sollich, Progress Theor. Phys. Suppl. 184, 304 (2010).\n[41] V. Popkov, G.M. Schutz and D. Simon, JSTAT P10007 (2010); V. Popkov, G.M. Schutz, arXiv:1011.3913.\n[42] D. Simon, arxiv: 1011.3590.\n[43] Y. Ogata, Phys. Rev. E 66, 016135 (2002) and Phys. Rev. E 66, 066123 (2002).\n[44] D. Karevski and T. Platini, Phys. Rev. Lett. 102, 207207 (2009).\n[45] C. Herbert, D. Paillard and B. Dubrulle, Earth Syst. Dynam. Discuss. 1, 325 (2010); C. Herbert, D. Paillard, M. Kageyama\nand B. Dubrulle, arXiv:1101.3173\n[46] L. Brillouin, 'Science and Information theory', Academic Press, New York (1956)\n[47] R. Balian, Am. J. Phys. 67, 1078 (1999); R. Balian, Stud. Hist. Phil. Mod. Phys. 36, 323 (2005).\n\n\f"}