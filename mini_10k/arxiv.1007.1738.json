{"id": "http://arxiv.org/abs/1007.1738v2", "guidislink": true, "updated": "2011-09-06T09:37:27Z", "updated_parsed": [2011, 9, 6, 9, 37, 27, 1, 249, 0], "published": "2010-07-10T19:39:40Z", "published_parsed": [2010, 7, 10, 19, 39, 40, 5, 191, 0], "title": "Moments, moderate and large deviations for a branching process in a\n  random environment", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.5322%2C1007.2154%2C1007.4322%2C1007.1156%2C1007.2215%2C1007.4027%2C1007.0054%2C1007.5402%2C1007.2017%2C1007.2877%2C1007.1303%2C1007.5132%2C1007.2105%2C1007.0818%2C1007.0508%2C1007.3790%2C1007.1328%2C1007.4470%2C1007.4774%2C1007.4007%2C1007.5441%2C1007.2628%2C1007.5138%2C1007.4050%2C1007.0352%2C1007.0204%2C1007.0951%2C1007.5213%2C1007.0543%2C1007.1223%2C1007.1227%2C1007.2383%2C1007.2720%2C1007.0192%2C1007.3854%2C1007.1601%2C1007.3522%2C1007.2833%2C1007.2092%2C1007.4069%2C1007.0611%2C1007.0425%2C1007.4841%2C1007.1721%2C1007.1187%2C1007.5283%2C1007.4837%2C1007.3463%2C1007.2659%2C1007.3974%2C1007.1076%2C1007.3809%2C1007.5061%2C1007.4562%2C1007.3759%2C1007.1004%2C1007.3888%2C1007.0390%2C1007.3406%2C1007.1856%2C1007.3572%2C1007.0756%2C1007.4548%2C1007.0266%2C1007.2404%2C1007.3690%2C1007.3780%2C1007.5296%2C1007.2881%2C1007.5236%2C1007.4467%2C1007.4607%2C1007.3224%2C1007.4687%2C1007.2073%2C1007.0581%2C1007.2308%2C1007.1626%2C1007.2845%2C1007.5202%2C1007.2419%2C1007.4364%2C1007.2872%2C1007.3524%2C1007.4457%2C1007.2983%2C1007.3924%2C1007.2996%2C1007.2847%2C1007.1738%2C1007.2765%2C1007.2392%2C1007.4358%2C1007.1154%2C1007.0946%2C1007.1518%2C1007.0162%2C1007.5173%2C1007.4292%2C1007.5044%2C1007.0022&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Moments, moderate and large deviations for a branching process in a\n  random environment"}, "summary": "Let $(Z_{n})$ be a supercritical branching process in a random environment\n$\\xi $, and $W$ be the limit of the normalized population size\n$Z_{n}/\\mathbb{E}[Z_{n}|\\xi ]$. We show large and moderate deviation principles\nfor the sequence $\\log Z_{n}$ (with appropriate normalization). For the proof,\nwe calculate the critical value for the existence of harmonic moments of $W$,\nand show an equivalence for all the moments of $Z_{n}$. Central limit theorems\non $W-W_n$ and $\\log Z_n$ are also established.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.5322%2C1007.2154%2C1007.4322%2C1007.1156%2C1007.2215%2C1007.4027%2C1007.0054%2C1007.5402%2C1007.2017%2C1007.2877%2C1007.1303%2C1007.5132%2C1007.2105%2C1007.0818%2C1007.0508%2C1007.3790%2C1007.1328%2C1007.4470%2C1007.4774%2C1007.4007%2C1007.5441%2C1007.2628%2C1007.5138%2C1007.4050%2C1007.0352%2C1007.0204%2C1007.0951%2C1007.5213%2C1007.0543%2C1007.1223%2C1007.1227%2C1007.2383%2C1007.2720%2C1007.0192%2C1007.3854%2C1007.1601%2C1007.3522%2C1007.2833%2C1007.2092%2C1007.4069%2C1007.0611%2C1007.0425%2C1007.4841%2C1007.1721%2C1007.1187%2C1007.5283%2C1007.4837%2C1007.3463%2C1007.2659%2C1007.3974%2C1007.1076%2C1007.3809%2C1007.5061%2C1007.4562%2C1007.3759%2C1007.1004%2C1007.3888%2C1007.0390%2C1007.3406%2C1007.1856%2C1007.3572%2C1007.0756%2C1007.4548%2C1007.0266%2C1007.2404%2C1007.3690%2C1007.3780%2C1007.5296%2C1007.2881%2C1007.5236%2C1007.4467%2C1007.4607%2C1007.3224%2C1007.4687%2C1007.2073%2C1007.0581%2C1007.2308%2C1007.1626%2C1007.2845%2C1007.5202%2C1007.2419%2C1007.4364%2C1007.2872%2C1007.3524%2C1007.4457%2C1007.2983%2C1007.3924%2C1007.2996%2C1007.2847%2C1007.1738%2C1007.2765%2C1007.2392%2C1007.4358%2C1007.1154%2C1007.0946%2C1007.1518%2C1007.0162%2C1007.5173%2C1007.4292%2C1007.5044%2C1007.0022&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Let $(Z_{n})$ be a supercritical branching process in a random environment\n$\\xi $, and $W$ be the limit of the normalized population size\n$Z_{n}/\\mathbb{E}[Z_{n}|\\xi ]$. We show large and moderate deviation principles\nfor the sequence $\\log Z_{n}$ (with appropriate normalization). For the proof,\nwe calculate the critical value for the existence of harmonic moments of $W$,\nand show an equivalence for all the moments of $Z_{n}$. Central limit theorems\non $W-W_n$ and $\\log Z_n$ are also established."}, "authors": ["Chunmao Huang", "Quansheng Liu"], "author_detail": {"name": "Quansheng Liu"}, "author": "Quansheng Liu", "links": [{"href": "http://arxiv.org/abs/1007.1738v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1007.1738v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60J80, 60K37, 60F10", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1007.1738v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1007.1738v2", "arxiv_comment": null, "journal_reference": "Stochastic Processes and their Applications 122 (2012) 522-545", "doi": null, "fulltext": "Moments, moderate and large deviations for a branching process in\na random environment\nChunmao HUANGa,b , Quansheng LIUa,b,\u2217\n\narXiv:1007.1738v2 [math.PR] 6 Sep 2011\n\na\n\nLMAM, Universit\u00e9 de Bretagne-Sud, Campus de Tohannic, BP 573, 56017 Vannes, France\nb\nUniversit\u00e9 Europ\u00e9enne de Bretagne, France\n\nAbstract. Let (Zn ) be a supercritical branching process in a random environment \u03be, and W\nbe the limit of the normalized population size Zn /E[Zn |\u03be]. We show large and moderate deviation\nprinciples for the sequence log Zn (with appropriate normalization). For the proof, we calculate\nthe critical value for the existence of harmonic moments of W , and show an equivalence for all the\nmoments of Zn . Central limit theorems on W \u2212 Wn and log Zn are also established.\nAMS subject classifications. 60J80, 60K37, 60F10.\nKey words: Branching process, random environment, moments, harmonic moments, large deviation, moderate deviation, central limit theorem\n\n1\n\nIntroduction and main results\n\nAs an important extension of the Galton-Watson process, the model of branching process in a\nrandom environment was introduced first by Smith & Wilkinson (1969, [23]) for the independent\nenvironment case, and then by Athreya & Karlin (1971, [4]) for the stationary and ergodic environment case. See also Athreya & Ney (1972, [3]) and Tanny (1977, [24]; 1988, [25]) for some basic\nresults on the subject. The study of asymptotic properties of a branching process in a random environment has recently received attention, see for example Afanasyave, Geiger, Kersting & Vatutin\n(2005, [1] & [2]), Kozlov (2006, [16]), Bansaye & Berestycki (2009, [5]), Bansaye & B\u00f6inghoff (2010,\n[6]), B\u00f6inghoff & Kersting (2010, [8]), and B\u00f6inghoff, Dyakonova, Kersting & Vatutin (2010, [7]),\namong others. Here, for a supercritical branching process (Zn ) in a random environment, we shall\nmainly show asymptotic properties of the moments of Zn , and prove moderate and large deviation\nprinciples for (log Zn ). In particular, our result on the annealed harmonic moments completes that\nof Hambly (1992, [12]) on the quenched harmonic moments, and extends the corresponding theorem of Ney & Vidyashanker (2003, [22]) for the Galton-Watson process; our moderate and large\ndeviation principles complete the results of Kozlov (2006, [16]), Bansaye & Berestycki (2009, [5]),\nBansaye & B\u00f6inghoff (2010, [6]) and B\u00f6inghoff & Kersting (2010, [8]) on large deviations.\nLet us give a description of the model. Let \u03be = (\u03be0 , \u03be1 , \u03be2 , * * * ) be a sequence of independent and\nidentically distributed (i.i.d.) random variables taking values in some space \u0398, whose realization\nCorresponding author at: LMAM, Universit\u00e9 de Bretagne-Sud, Campus de Tohannic, BP 573, 56017 Vannes,\nFrance. Tel.: +33 2 9701 7140; fax: +33 2 9701 7175.\nEmail addresses: sasamao02@gmail.com (C. Huang), quansheng.liu@univ-ubs.fr (Q. Liu).\n\u2217\n\n1\n\n\fdetermines a sequence of probability generating functions\nfn (s) = f\u03ben (s) =\n\n\u221e\nX\ni=0\n\npi (\u03ben )si , s \u2208 [0, 1],\n\npi (\u03ben ) \u2265 0,\n\n\u221e\nX\n\npi (\u03ben ) = 1.\n\n(1.1)\n\ni=0\n\nA branching process (Zn )n\u22650 in the random environment \u03be can be defined as follows:\nZ0 = 1,\n\nZn+1 =\n\nZn\nX\n\nXn,i n \u2265 0,\n\ni=1\n\n(1.2)\n\nwhere given the environment \u03be, Xn,i (i = 1, 2, ...) are independent of each other and independent of\nZn , and have the same distribution determined by fn .\nLet (\u0393, P\u03be ) be the probability space under which the process is defined when the environment\n\u03be is given. As usual, P\u03be is called quenched law. The total probability space can be formulated as\nthe product space (\u0393 \u00d7 \u0398N , P), where P = P\u03be \u2297 \u03c4 in the sense that for all measurable and positive\nfunction g, we have\nZ\nZ Z\ngdP =\n\ng(\u03be, y)dP\u03be (y)d\u03c4 (\u03be),\n\nwhere \u03c4 is the law of the environment \u03be. The total probability P is usually called annealed law. The\nquenched law P\u03be may be considered to be the conditional probability of the annealed law P given\n\u03be. The expectation with respect to P\u03be (resp. P) will be denoted E\u03be (resp. E).\nFor \u03be = (\u03be0 , \u03be1 , * * * ) and n \u2265 0, define\nmn (p) = mn (p, \u03be) =\n\n\u221e\nX\n\nip pi (\u03ben )\n\nfor p > 0,\n\n(1.3)\n\ni=0\n\nmn = mn (1), \u03a00 = 1 and \u03a0n = m0 * * * mn\u22121 for n \u2265 1.\n\nThen mn (p) =\n\np\nE\u03be Xn,i\n\n(1.4)\n\nand \u03a0n = E\u03be Zn . It is well known that the normalized population size\nWn =\n\nZn\n\u03a0n\n\nis a nonnegative martingale under P\u03be (for each \u03be) with respect to the filtration Fn = \u03c3(\u03be, Xk,i , 0 \u2264\nk \u2264 n \u2212 1, i = 1, 2, * * * ), so that the limit\nW = lim Wn\nn\u2192\u221e\n\nexists almost sure (a.s.) with EW \u2264 1. We shall always assume that\nE log m0 \u2208 (0, \u221e)\n\nand\n\nE\n\nZ1\nlog+ Z1 < \u221e.\nm0\n\n(1.5)\n\nThe first condition means that the process is supercritical; the second implies that W is nondegenerate. Hence (see e.g. Athreya & Karlin (1971, [4]))\nP\u03be (W > 0) = P\u03be (Zn \u2192 \u221e) = lim P\u03be (Zn > 0)\nn\u2192\u221e\n\nFor simplicity, we write often pi for pi (\u03be0 ) and assume always\np0 = 0\n2\n\na.s.\n\na.s..\n\n\fTherefore W > 0 and Zn \u2192 \u221e a.s..\nIt is known that lognZn \u2192 E log m0 a.s. on {Zn \u2192 \u221e} (see e.g. Tanny (1977, [24])). We are\ninterested in the asymptotic properties of the corresponding deviation probabilities. Notice that\nlog Zn = log \u03a0n + log Wn .\n\n(1.6)\n\nSince Wn \u2192 W > 0 a.s., certain asymptotic properties of log Zn would be determined by those\nof log \u03a0n . We shall show that log Zn and log \u03a0n satisfy the same limit theorems under suitable\nmoment conditions.\nAt first, we present a large deviation principle. Let \u039b(t) = log Emt0 . Assume that m0 is not a\nconstant a.s. and that \u039b(t) < \u221e for all t \u2208 R. Let\n\u039b\u2217 (x) = sup{tx \u2212 \u039b(t)}\nt\u2208R\n\nbe the Fenchel-Legendre transform of \u039b. It is well known ([10], Lemma 2.2.5) that \u039b\u2217 (E log m0 ) = 0,\n\u039b\u2217 (x) is strictly increasing for x \u2265 E log m0 and strictly decreasing for x \u2264 E log m0 ; moreover,\n\u001a\ntx \u2212 \u039b(t) if x = \u039b\u2032 (t) for some t \u2208 R,\n\u2217\n\u039b (x) =\n\u221e\nif x \u2265 \u039b\u2032 (\u221e) or x \u2264 \u039b\u2032 (\u2212\u221e) .\nIn fact, \u039b\u2217 is the rate function with which log \u03a0n satisfies a large deviation principle. We introduce\nthe following assumption:\n(H) There exist constants \u03b4 > 0 and A > A1 > 1 such that a.s.\nA1 \u2264 m0\n\nand\n\nm0 (1 + \u03b4) \u2264 A1+\u03b4 ,\n\n(1.7)\n\n(recall that m0 and m0 (1 + \u03b4) were defined in (1.3) and (1.4)). Notice that the second condition\nimplies that m0 \u2264 A a.s.\nThe theorem below shows that log Zn and log \u03a0n satisfy the same large deviation principle.\nTheorem 1.1 (Large deviation principle). Assume (H). If EZ1s < \u221e for all s > 1 and p1 = 0 a.s.,\nthen for any measurable subset B of R,\n\u0012\n\u0013\nlog Zn\n1\n\u2217\n\u2208B\n\u2212 inf o \u039b (x) \u2264 lim inf log P\nn\u2192\u221e n\nx\u2208B\nn\n\u0012\n\u0013\n1\nlog Zn\n\u2264 lim sup log P\n\u2208 B \u2264 \u2212 inf \u039b\u2217 (x),\nn\nx\u2208B\u0304\nn\u2192\u221e n\nwhere B o denotes the interior of B, and B\u0304 its closure.\nFrom Theorem 1.1, we obtain immediately\nCorollary 1.2. Assume (H). If EZ1s < \u221e for all s > 1 and p1 = 0 a.s., then\n\u0012\n\u0013\n1\nlog Zn\nlim log P\n\u2264 x = \u2212\u039b\u2217 (x) for x < E log m0 ,\nn\u2192\u221e n\nn\n\u0012\n\u0013\nlog Zn\n1\n\u2265 x = \u2212\u039b\u2217 (x) for x > E log m0 .\nlim log P\nn\u2192\u221e n\nn\n3\n\n\fRemark. This result was shown by Bansaye & Berestycki (2009, [5]) when (H) holds with \u03b4 = 1.\nIf P(p1 > 0) > 0, the rate function for the lower deviation is no longer \u039b\u2217 (x): in this case, Bansaye\n& Berestycki [5] proved that under certain hypothesis,\n\u0012\n\u0013\nlog Zn\n1\n\u2264 x = \u2212\u03c7(x) for x < E log m0 ,\nlim log P\nn\u2192\u221e n\nn\nx\nwhere \u03c7(x) = inf t\u2208[0,1] {\u2212t log Ep1 + (1 \u2212 t)\u039b\u2217 ( 1\u2212t\n)}. Obviously, \u03c7(x) \u2264 \u039b\u2217 (x).\nFor the upper deviation and for branching processes with special offspring distributions, more\nprecise results can be found in Kozlov (2006, [16]), B\u00f6inghoff & Kersting (2010, [8]), and Bansaye\n& B\u00f6inghoff (2010, [6]).\n\nNotice that the Laplace transform of log Zn is\nEet log Zn = EZnt .\nTherefore, Theorem 1.1 is a consequence of the G\u00e4rtner-Ellis theorem (see e.g. [10]) and Theorem\n1.3 below.\nTheorem 1.3 (Moments of Zn ). Let t \u2208 R. Suppose that one of the following conditions is satisfied:\n+\n(i) t \u2208 (0, 1] and Emt\u22121\n0 Z1 log Z1 < \u221e;\n(ii) t > 1 and EZ1t < \u221e;\n(iii) t < 0, Ep1 < Emt0 , kp1 k\u221e := esssup p1 < 1 and (H) holds.\n\nThen for some constant C(t) \u2208 (0, \u221e),\nEZnt\nn = C(t).\nn\u2192\u221e (Emt )\n0\nlim\n\nFor t < 0, Theorem 1.3 is an extension of a result of Ney & Vidyashankar (2003, [22]) on the\nGalton-Watson process. Theorem 1.3 can also be used to study the convergence rate in a central\nlimit theorem for W \u2212 Wn (see Theorem 1.7).\nA key step in the proof of Theorem 1.3 is the study of the harmonic moments (moments of\nnegative orders) of W , which is of interest of its own. The following result is our main result on\nthis subject.\nTheorem 1.4 (Harmonic moments of W ). Let a > 0. Assume (H) and kp1 k\u221e < 1. Then\nEW \u2212a < \u221e\n\nif and only if\n\nEp1 ma0 < 1.\n\nTheorem 1.4 reveals that under certain conditions, the number a0 satisfying Ep1 ma00 = 1 is the\ncritical value for the existence of the harmonic moments EW \u2212a (a > 0). More precisely, we have\nCorollary 1.5. Assume (H) and kp1 k\u221e < 1. If Ep1 ma00 = 1, then EW \u2212a < \u221e if 0 < a < a0 and\nEW \u2212a = \u221e if a \u2265 a0 .\nRemark. Hambly (1992, [12]) proved that under an assumption similar to (H), the number\nlog p1\n\u2212a (a > 0):\n\u03b10 := \u2212 EElog\nm0 is the critical value for the a.s. existence of the quenched moments E\u03be W\nnamely, E\u03be W \u2212a < \u221e a.s. if a < \u03b10 and E\u03be W \u2212a = \u221e a.s. if a > \u03b10 . Here we obtain the critical\nvalue for the existence of the annealed moments instead of the quenched ones. Notice that by\n4\n\n\fJensen's inequality and the equation Ep1 ma00 = 1, we see the natural relation that a0 \u2264 \u03b10 .\nNow we consider moderate deviations. Let (an ) be a sequence of positive numbers satisfying\nan\n\u2192 0 and\nn\n\na\n\u221an \u2192 \u221e as n \u2192 \u221e.\nn\n\n(1.8)\n\nSimilar to the case of large deviation principle, log Zn and log \u03a0n satisfy the same moderate deviation\nprinciple.\nTheorem 1.6 (Moderate deviation principle). Assume (H) and write \u03c3 2 = var(log m0 ) \u2208 (0, \u221e).\nThen for any measurable subset B of R,\n\u0012\n\u0013\nx2\nlog Zn \u2212 nE log m0\nn\n\u2212 inf o 2 \u2264 lim inf 2 log P\n\u2208B\nn\u2192\u221e an\nx\u2208B 2\u03c3\nan\n\u0012\n\u0013\nlog Zn \u2212 nE log m0\nx2\nn\n\u2208 B \u2264 \u2212 inf\n,\n\u2264 lim sup 2 log P\n2\nan\nx\u2208B\u0304 2\u03c3\nn\u2192\u221e an\nwhere B o denotes the interior of B, and B\u0304 its closure.\nHere and throughout the paper, var(log m0 ) denotes the variance of log m0 .\nAs in the case of large deviation principle, the proof of Theorem 1.6 is based on the G\u00e4rtner-Ellis\ntheorem.\nAs another application of Theorem 1.3, we shall also establish a central limit theorem for W \u2212Wn\nwith exponential convergence rate. Let\n2\n(\u03be)\n\u03b4\u221e\n\n\u0013\n\u0012\n\u221e\nX\n1\nmn (2)\n\u22121\n=\n\u03a0\nm2n\nn=0 n\n\n(1.9)\n\nP\n2\n2\n(recall that mn (2) = \u221e\ni=1 i pi (\u03ben ) by (1.3)). Then \u03b4\u221e is the variance of W under P\u03be (see e.g. Jagers\n(1974, [15])) if the series converges. As usual, we write T n \u03be = (\u03ben , \u03ben+1 , * * * ) if \u03be = (\u03be0 , \u03be1 , * * * ) and\nn \u2265 0.\n\u2212\u01eb/2\n\nTheorem 1.7 (Central limit theorem on W \u2212 Wn ). Assume (H) and kp1 k\u221e < 1. If Ep1 < Em0\n> 1 and EZ12+\u01eb < \u221e for some \u01eb \u2208 (0, 1], then for some constant C > 0,\nessinf mm0 (2)\n2\n\n,\n\n0\n\nsup P\nx\u2208R\n\n\u0012\n\n\u0013\n\u0010\n\u0011\n\u03a0n (W \u2212 Wn )\n\u2212\u01eb/2 n\n\u221a\n\u2264\nx\n\u2212\n\u03a6(x)\n\u2264\nC\nEm\n.\n0\nZn \u03b4\u221e (T n \u03be)\n\n(1.10)\n\n\u2212\u01eb/2\n\nNotice that the condition Ep1 < Em0\nis automatically satisfied when \u01eb > 0 is small enough.\nTheorem 1.7 shows that W \u2212 Wn (with appropriate normalization) satisfies a central limit theorem with an exponential convergence rate; it improves a recent result of Wang, Gao & Liu (2010,\n[26]). For Galton-Watson process, Theorem 1.7 improves the convergence rate of Heyde & Brown\n(1971, [14]), and coincides with that of Ney & Vidyashanker (2003, [22]).\nFinally, as log \u03a0n satisfies a central limit theorem, it is natural that the same would hold for\nlog Zn . In fact we have\n\n5\n\n\fTheorem 1.8 (Central limit theorem on log Zn ). Assume that \u03c3 2 = var(log m0 ) \u2208 (0, \u221e). Then\n\u0013\n\u0012\nlog Zn \u2212 nE log m0\n\u221a\n\u2264 x = \u03a6(x),\n(1.11)\nlim P\nn\u2192\u221e\nn\u03c3\nRx\n2\nwhere \u03a6(x) = \u221a12\u03c0 \u2212\u221e e\u2212u /2 du is the standard normal distribution function.\n\nThe rest of the paper is organized as follows. In Section 2, we consider the harmonic moments\nof W and prove Theorem 1.4. Section 3 is devoted to the study of the moments of Zn of all orders\n(positive or negative) and the large deviations of log Zn , where Theorems 1.1 and 1.3 are proved\nwith additional informations. In Section 4, we consider the moderate deviations of log Zn and prove\nTheorem 1.6. In Section 5, we deal with central limit theorems and prove Theorems 1.7 and 1.8.\nWe end the paper by a short appendix showing a general result on large deviations.\n\n2\n\nHarmonic moments of W\n\nIn this section, we shall study the harmonic moments of W , i.e. EW \u2212s (s > 0), which are closely\nrelated to the corresponding moments of Wn . The following lemma reveals their relations.\nLemma 2.1. Assume (1.5). Then for any convex function \u03c6 : R+ \u2192 R+ ,\nlim E\u03be \u03c6(Wn ) = sup E\u03be \u03c6(Wn ) = E\u03be \u03c6(W )\n\nn\u2192\u221e\n\na.s.,\n\nn\n\nand\nlim E\u03c6(Wn ) = sup E\u03c6(Wn ) = E\u03c6(W ).\n\nn\u2192\u221e\n\nn\n\nIn particular, for all s > 0,\nlim E\u03be Wn\u2212s = sup E\u03be Wn\u2212s = E\u03be W \u2212s\n\nn\u2192\u221e\n\nn\n\na.s.,\n\nand\nlim EWn\u2212s = sup EWn\u2212s = EW \u2212s.\n\nn\u2192\u221e\n\nn\n\nL1 .\n\nProof. Recall that by (1.5), Wn \u2192 W in\nTherefore, Wn = E(W |Fn ) a.s.. By the conditional\nJensen's inequality,\nE(\u03c6(W )|Fn ) \u2265 \u03c6(E(W |Fn )) = \u03c6(Wn )\na.s.,\nso E\u03c6(W ) \u2265 supn E\u03c6(Wn ). The other side comes from Fatou's lemma. The equality\nlim E\u03c6(Wn ) = sup E\u03c6(Wn )\n\nn\u2192\u221e\n\nn\n\nis obvious by the monotonicity of E\u03c6(Wn ). For the quenched moments, it suffices to repeat the\nproof above with E\u03be in place of E.\nRecall that we can estimate the harmonic moments of a positive random variable through its\nLaplace transform:\nLemma 2.2 ([17], Lemma 4.4). Let X be a positive random variable. For 0 < a < \u221e, consider the\nfollowing statements:\n(i) EX \u2212a < \u221e;\n(ii) Ee\u2212tX = O(t\u2212a )(t \u2192 \u221e);\na\n(iii) P(X \u2264 x) = O(x )(x \u2192 0); (iv) \u2200b \u2208 (0, a), EX \u2212b < \u221e.\n\nThen the following implications hold: (i) \u21d2 (ii) \u21d4 (iii) \u21d2 (iv).\n6\n\n\fSet\n\u03c6\u03be (t) = E\u03be e\u2212tW\n\nand \u03c6(t) = E\u03c6\u03be (t) = Ee\u2212tW (t \u2265 0).\n\nLemma 2.3. Assume (H). Then there exist constants \u03b2 \u2208 (0, 1) and K \u2265 1 such that\n\u03c6\u03be (t) \u2264 \u03b2\n\na.s.\n\n\u2200t \u2265\n\n1\n.\nK\n\nProof. Let p = 1 + \u03b4. By a similar argument to the one used in the proof of ([19], Proposition 1.3),\nwe have \u2200k \u2265 0,\n(\nif 1 < p \u2264 2,\n2p \u03a01\u2212p\np\nk mk (p)\nE\u03be |Wk+1 \u2212 Wk | \u2264\n(2.1)\np/2\n\u2212p/2\np\n(Bp ) \u03a0k E\u03be Wk mk (p) if p > 2,\np\nP\ni\np\nwhere Bp = 2 \u2308p/2\u2309 with \u2308p/2\u2309 = min{k \u2208 N : k \u2265 p/2}, and mk (p) = \u221e\ni=0 | mk \u2212 1| pi (\u03bek ).\nZ1\n\u2212 1|p k\u221e < \u221e and that \u03a0k \u2265 Ak1 a.s..\nThe assumption (H) implies that km0 (p)k\u221e = kE\u03be | m\n0\nUsing the inequality (2.1) and an induction argument on [p] (see [19], Proposition 1.3), we obtain\nE\u03be W 1+\u03b4 = sup E\u03be Wnp \u2264 C\nn\n\na.s.\n\nfor some constant C. In fact we shall only use the result for \u03b4 \u2264 1. Assume that \u03b4 \u2208 (0, 1], otherwise\n\u2212x \u22121+x\nwe consider min{\u03b4, 1} instead of \u03b4. Notice that the function e x1+\u03b4\nis positive and bounded on\n(0, \u221e). So there exists a constant C \u2265 1 such that\ne\u2212x \u2264 1 \u2212 x +\nTake K := CkE\u03be W 1+\u03b4 k\u221e\n\n\u00011/\u03b4\n\nK \u03b4 1+\u03b4\n.\n1+\u03b4 t\n\n\u2200x > 0.\n\n(2.2)\n\n\u2208 [1, \u221e). By (2.2), we obtain\n\n\u03c6\u03be (t) = E\u03be e\u2212tW\n\nLet g(t) = 1 \u2212 t +\n\nC 1+\u03b4\nx\n1+\u03b4\n\nC 1+\u03b4\nt E\u03be W 1+\u03b4\n1+\u03b4\nK \u03b4 1+\u03b4\nt\na.s..\n\u2264 1\u2212t+\n1+\u03b4\n\u2264 1\u2212t+\n\nObviously,\n\nmin g(t) = g(\nt>0\n\n1\n\u03b4\n) =1\u2212\n=: \u03b2 \u2208 (0, 1)\nK\nK(1 + \u03b4)\n\n(it can be seen that \u03b2 \u2265 12 ). Since \u03c6\u03be (t) is decreasing, we have for t \u2265\n\u03c6\u03be (t) \u2264 \u03c6\u03be (\n\n1\n1\n) \u2264 g( ) = \u03b2\nK\nK\n\n1\nK,\n\na.s..\n\nDenote\nm = essinf Z1 = inf{j > 0 : P(Z1 = j) > 0}.\n\n(2.3)\n\nNotice that P(Z1 = j) = 0 if and only if P(pj (\u03be0 ) > 0) = 0, so an alternative definition of m is\nm = inf{j > 0 : P(pj (\u03be0 ) > 0) > 0}.\n\n(2.4)\n\nThe following Theorem gives an uniform bound for the quenched harmonic moments of W .\n7\n\n\fTheorem 2.1. Assume (H).\n(i) If kp1 k\u221e < 1, then for some constants a > 0 and C > 0, we have a.s.,\n\u03c6\u03be (t) \u2264 Ct\u2212a (\u2200t > 0),\n\nP\u03be (W \u2264 x) \u2264 Cxa (\u2200x > 0)\n\nand\n\nE\u03be W \u2212a \u2264 C.\n\n(ii) If p1 = 0 a.s., then a.s.\n\u03c6\u03be (t) \u2264 C2 exp(\u2212C1 t\u03b3 ) (\u2200t > 0),\nand E\u03be W \u2212s \u2264 Cs (\u2200s > 0), where \u03b3 =\nindependent of \u03be.\n\n\u03b3\n\nP\u03be (W \u2264 x) \u2264 C2 exp(\u2212C1 x \u03b3\u22121 ) (\u2200x > 0),\nlog m\nlog A\n\n\u2208 (0, 1), C1 , C2 and Cs are positive constants\n\nProof. We only prove the results about \u03c6\u03be (t), from which the results about P\u03be (W \u2264 x) and E\u03be W \u2212s\ncan be deduced by Lemma 2.2 for (i), and by Tauberian theorems of exponential type (see [21]) for\n(ii).\n(i) It is clear that \u03c6\u03be (t) satisfies the functional equation\n\u03c6\u03be (t) = f0 (\u03c6T \u03be (\n\nt\n))\nm0\n\n(2.5)\n\n(recall that T n \u03be = (\u03ben , \u03ben+1 , * * * ) if \u03be = (\u03be0 , \u03be1 , * * * ) and n \u2265 0). Hence a.s.,\nt\nt\n) + (1 \u2212 p1 (\u03be0 ))\u03c62T \u03be (\n)\n\u03c6\u03be (t) \u2264 p1 (\u03be0 )\u03c6T \u03be (\nm\nm0\n\u0012 0\n\u0013\nt\nt\n) p1 (\u03be0 ) + (1 \u2212 p1 (\u03be0 ))\u03c6T \u03be (\n)\n\u2264 \u03c6T \u03be (\nm0\nm0\nt\n\u2264 \u03c6T \u03be (\n).\nm0\nSimilarly, we have a.s.,\n\u0012\n\u0013\nt\nt\nt\nt\n\u03c6T \u03be (\n) \u2264 \u03c6T 2 \u03be ( ) p1 (\u03be1 ) + (1 \u2212 p1 (\u03be1 ))\u03c6T 2 \u03be ( ) \u2264 \u03c6T 2 \u03be ( ).\nm0\n\u03a02\n\u03a02\n\u03a02\nConsequently, we get a.s.,\n\u0012\n\u0013\u0012\n\u0013\nt\nt\nt\np1 (\u03be0 ) + (1 \u2212 p1 (\u03be0 ))\u03c6T 2 \u03be ( ) .\n\u03c6\u03be (t) \u2264 \u03c6T 2 \u03be ( ) p1 (\u03be1 ) + (1 \u2212 p1 (\u03be1 ))\u03c6T 2 \u03be ( )\n\u03a02\n\u03a02\n\u03a02\nBy iteration, we obtain that \u2200n \u2265 1, a.s.\n\u0013\nn\u22121 \u0012\nt Y\nt\n\u03c6\u03be (t) \u2264 \u03c6T n \u03be ( )\np1 (\u03bej ) + (1 \u2212 p1 (\u03bej ))\u03c6T n \u03be ( ) .\n\u03a0n\n\u03a0n\n\n(2.6)\n\nj=0\n\nBy Lemma 2.3, a.s., \u03c6T n \u03be ( \u03a0tn ) \u2264 \u03b2 if t \u2265\np1 (\u03be0 ) \u2264 p\u03041 a.s., it follows that a.s.,\n\nAn\nK\n\nand n \u2265 0, since \u03a0n \u2264 An . Let p\u03041 := kp1 k\u221e . As\n\n\u03c6\u03be (t) \u2264 \u03b2\u03b1n for t \u2265\n\n8\n\nAn\nand n \u2265 0,\nK\n\n\fwhere \u03b1 = p\u03041 + (1 \u2212 p\u03041 )\u03b2 \u2208 (0, 1). For t \u2265\nlog(Kt)\nlog A\n\n\u2212 1 \u2264 n0 \u2264\n\nlog(Kt)\nlog A .\n\nThus for t \u2265\n\n1\nK,\n\n1\nK,\n\ntake n0 = n0 (t) = [ log(Kt)\nlog A ] \u2265 0. Clearly, t \u2265\n\nAn0\nK\n\nand\n\na.s.\n\nlog \u03b1\n\n\u03c6\u03be (t) \u2264 \u03b2\u03b1n0 \u2264 \u03b2\u03b1\u22121 (Kt) log A = C0 t\u2212a ,\nlog \u03b1\n\nlog \u03b1\nwhere C0 = \u03b2\u03b1\u22121 K log A > 0 and a = \u2212 log\nA > 0. therefore we can choose a constant C > 0 such\nthat a.s., \u03c6\u03be (t) \u2264 Ct\u2212a(\u2200t > 0). Thus the first part of the theorem is proved.\n(ii) By the equation (2.5),\n\u0012\n\u0013m\nt\nt\na.s..\n)) \u2264 \u03c6T \u03be (\n)\n\u03c6\u03be (t) = f0 (\u03c6T \u03be (\nm0\nm0\n\nBy iteration, using Lemma 2.3 we have\n\u0012\n\u0013m n\nt\nn\n\u03c6\u03be (t) \u2264 \u03c6T n \u03be ( )\n\u2264 \u03b2m\n\u03a0n\n\na.s. for\n\nt\u2265\n\nAn\n.\nK\n\nLike the proof of the first part, take n0 = n0 (t) = [ log(Kt)\nlog A ] \u2265 0. Then for t \u2265\n\u03c6\u03be (t) \u2264 \u03b2 m\n\nn0\n\nlog m\n\n1\nK,\n\n\u0010\nlog m \u0011\n\u2264 exp m\u22121 (log \u03b2)(Kt) log A \u2264 exp (\u2212C1 t\u03b3 ) a.s.,\n\nm\nwhere C1 = \u2212m\u22121 K log A log \u03b2 > 0 and \u03b3 = log\nlog A \u2208 (0, 1). It follows that we can choose C2 > 0\n\u03b3\nsuch that a.s.,\u03c6\u03be (t) \u2264 C2 exp(\u2212C1 t ), \u2200t > 0. This completes the proof.\n\nWe now study the annealed moments of W .\nTheorem 2.2. Assume (H).\n(i) Then there exist constants a > 0 and C > 0 such that\n\u03c6(t) \u2264 Ct\u2212a (\u2200t > 0), P(W \u2264 x) \u2264 Cxa (\u2200x > 0) and EW \u2212s < \u221e (\u2200s \u2208 (0, a)).\n\n(2.7)\n\nIf additionally kp1 k\u221e < 1, then for each a > 0 with Ep1 ma0 < 1, (2.7) holds for some constant\nC > 0.\n(ii) If p1 = 0 a.s., then\n\u03c6(t) \u2264 C2 exp(\u2212C1 t\u03b3 ) (\u2200t > 0),\nand EW \u2212s < \u221e (\u2200s > 0), where \u03b3 =\n\nlog m\nlog A\n\n\u03b3\n\nP(W \u2264 x) \u2264 C2 exp(\u2212C1 x \u03b3\u22121 ) (\u2200x > 0),\n\u2208 (0, 1), and C1 , C2 are positive constants.\n\nNotice that when kp1 k\u221e < 1, the conclusion that (2.7) holds for some a > 0 is also a direct\nconsequence of Theorem 2.1(i). But Theorem 2.2(i) gives more precise information.\nTo prove Theorem 2.2, we need the following lemma.\nLemma 2.4 ([18], Lemma 3.2). Let \u03c6 : R+ \u2192 R+ be a bounded function and let A be a positive\nrandom variable such that for some 0 < p < 1, t0 \u2265 0 and all t > t0 ,\n\u03c6(t) \u2264 pE\u03c6(At).\nIf pEA\u2212a < 1 for some 0 < a < \u221e, then \u03c6(t) = O(t\u2212a )(t \u2192 \u221e).\n9\n\n\fProof of Theorem 2.2. Part (ii) is from Theorem 2.1(ii) by taking the expectation E. For part (i),\nwe first consider the special case where p1 \u2264 p\u03041 a.s. for some constant p\u03041 < 1. By Theorem 2.1(i),\nwe have \u03c6\u03be (t) \u2264 C1 t\u2212a1 a.s. (\u2200t > 0) for some positive constants C1 and a1 . So for all 0 < \u01eb < 1,\nthere exists a constant t\u01eb > 0 such that \u03c6\u03be (t) \u2264 \u01eb a.s. for t \u2265 t\u01eb . Thus by (2.6),\n\u03c6\u03be (t) \u2264 (p1 + (1 \u2212 p1 )\u01eb)\u03c6T \u03be (\n\nt\n) a.s. if\nm0\n\nt \u2265 At\u01eb .\n\n(2.8)\n\nNotice that \u03be0 is independent of T \u03be. Taking the expectation in (2.8), we see that for t \u2265 At\u01eb ,\n\u0014\n\u0015\nt\n\u03c6(t) \u2264 E (p1 + (1 \u2212 p1 )\u01eb)\u03c6T \u03be (\n)\nm0\n\u0014\n\u0014\n\u0015\u0015\nt\n= E (p1 + (1 \u2212 p1 )\u01eb)E \u03c6T \u03be (\n) \u03be0\nm0\n\u0014\n\u0015\nt\n= E (p1 + (1 \u2212 p1 )\u01eb)\u03c6(\n) = p\u01eb E\u03c6(\u00c3\u01eb t),\nm0\nwhere p\u01eb = E(p1 + (1 \u2212 p1 )\u01eb) < 1 and \u00c3\u01eb is a positive random variable whose distribution is\ndetermined by\n\u0014\n\u0015\n1\n1\n)\nEg(\u00c3\u01eb ) = E (p1 + (1 \u2212 p1 )\u01eb)g(\np\u01eb\nm0\n\nfor all bounded and measurable function g. If p\u01eb E\u00c3\u2212a\n< 1, by Lemma 2.4, we have \u03c6(t) =\n\u01eb\n\u2212a\n\u2212a\nO(t )(t \u2192 \u221e), or equivalently, \u03c6(t) \u2264 Ct (\u2200t > 0) for some constant C > 0. Since Ep1 ma0 < 1,\nwe can take \u01eb > 0 small enough such that\na\np\u01eb E\u00c3\u2212a\n\u01eb = E [(p1 + (1 \u2212 p1 )\u01eb)m0 ] < 1.\n\nTherefore we have proved that \u03c6(t) = O(t\u2212a ) whenever kp1 k\u221e < 1 and Ep1 ma0 < 1(a > 0). Now\nconsider the general case where kp1 k\u221e may be 1. By Lemma 2.3, we have \u03c6\u03be (t) \u2264 \u03b2 a.s. for\nt \u2265 t\u03b2 = K1 . So we can repeat the proof above with \u03b2 in place of \u01eb, showing that if a > 0 small\nenough such that\nE[(p1 + (1 \u2212 p1 )\u03b2)ma0 ] \u2264 Aa (Ep1 + (1 \u2212 Ep1 )\u03b2) < 1,\n\nthen \u03c6(t) = O(t\u2212a ). Now we have proved the results about \u03c6(t). By Lemma 2.2, we obtain the\nresults about P(W \u2264 x) and EW \u2212s .\nWe now prove our main result on the harmonic moments of W already stated in the introduction\nat the beginning of this paper .\n< 1. So by\nProof of Theorem 1.4. If Ep1 ma0 < 1, then there exists \u01eb > 0 such that Ep1 ma+\u01eb\n0\nTheorem 2.2(i), EW \u2212a < \u221e. Conversely, assume that a > 0 and EW \u2212a < \u221e. Notice that\nZ1\n1 X\n(1)\nWi\nW =\nm0\n\na.s.,\n\ni=1\n\n\u0011\n\u0010\n(1)\nwhere Wi\n\ni\u22651\n\n, when \u03be is given, are conditionally independent copies of W (1) whose distribution\n\nis P\u03be (W (1) \u2208 *) = PT \u03be (W \u2208 *). Since P(Z1 \u2265 2) > 0, we have\n\u0010\n\u0011\n(1) \u2212a\n1{Z1 =1} = Ep1 ma0 EW \u2212a .\nEW \u2212a > Ema0 W1\n\nTherefore Ep1 ma0 < 1.\n\n10\n\n\f3\n\nMoments of Zn and large deviations for log Zn\n\nWe first recall some preliminary results for the existence of moments of W .\nGuivarc'h & Liu [11] gave a sufficient and necessary condition for the existence of moments of\npositive orders of W : for s > 1,\n\u0013\n\u0012\nZ1 s\ns\n< \u221e and Em1\u2212s\n< 1.\n(3.1)\n0 < EW < \u221e if and only if E\n0\nm0\nIn particular, if p0 = 0 a.s. and EZ1s < \u221e for all s > 1, then 0 < EW s < \u221e for all s > 0.\nFor the existence of moments of negative orders of W , Theorem 1.4 shows that, assuming (H)\nand kp1 k\u221e < 1, we have for s > 0,\nEW \u2212s < \u221e if and only if\n\nEp1 ms0 < 1.\n\n(3.2)\n\nIn particular, if p0 = p1 = 0 a.s., it is clear that EW \u2212s < \u221e, for all s > 0.\nThese results will be applied in the proof of Theorem 1.3.\nProof of Theorem 1.3. Denote the distribution of \u03be0 by \u03c40 . Fix t \u2208 R and define a new distribution\n\u03c4\u03030 as\nm(x)t \u03c40 (dx)\n\u03c4\u03030 (dx) =\n,\nEmt0\nP\u221e\nwhere m(x) = E[Z1 |\u03be0 = x] =\ni=0 ipi (x). Consider the new branching process in a random\nenvironment whose environment distribution is \u03c4\u0303 = \u03c4\u03030\u2297N instead of \u03c4 = \u03c40\u2297N . The corresponding\nprobability and expectation are denoted by P\u0303 = P\u03be \u2297 \u03c4\u0303 and \u1ebc, respectively. Then\nEZnt\nt\nn = \u1ebcWn .\n(Emt0 )\nIt is easy to see that under P\u0303, we still have p0 = 0 a.s.. Moreover, if (H) holds and kp1 k\u221e < 1, then\nthe same hold under P\u0303. Notice that\n\u1ebc log m0 =\n\nEmt0 log m0\n\u2208 (0, \u221e].\nEmt0\n\nWe distinguish three cases as considered in the theorem.\n+\n(i) If t \u2208 (0, 1] and Emt\u22121\n0 Z1 log Z1 < \u221e, then\n\u1ebc\n\n+\nEmt\u22121\nZ1\n0 Z1 log Z1\n< \u221e,\nlog+ Z1 =\nm0\nEmt0\n\nso that Wn \u2192 W in L1 under P\u0303 (cf. Athreya & Karlin (1971) or Tanny (1988)). Therefore,\nlim \u1ebcWnt = \u1ebcW t \u2208 (0, \u221e).\n\nn\u2192\u221e\n\n(ii) If t > 1 and EZ1t < \u221e, then\n\u1ebc\n\n\u0012\n\nZ1\nm0\n\n\u0013t\n\n=\n\nEZ1t\n<\u221e\nEmt0\n\nso that Wn \u2192 W in Lt under P\u0303 (cf. (3.1)).\n11\n\na.s. under P\u0303,\n\n(3.3)\n\n\f(iii) If t < 0, Ep1 < Emt0 , kp1 k\u221e < 1 and (H) holds, then\n\u1ebcp1 m\u2212t\n0 =\n\nEp1\n< 1,\nEmt0\n\nso that \u1ebcW t < \u221e from Theorem 1.4. Using Lemma 2.1, we obtain again (3.3).\nTherefore we have proved Theorem 1.3 with C(t) = \u1ebcW t .\nUsing Theorem 1.3, we can easily prove Theorem 1.1.\nProof of Theorem 1.1. It is clear that the hypothesis of Theorem 1.1 ensures that EZ1t < \u221e for all\nt \u2208 R. Hence by Theorem 1.3,\nEZnt\nn = C(t) \u2208 (0, \u221e)\nn\u2192\u221e (Emt )\n0\nlim\n\nwhich implies that\n\n1\nlog EZnt = log Emt0 = \u039b(t)\nn\u2192\u221e n\nlim\n\n\u2200t \u2208 R,\n\n\u2200t \u2208 R.\n\n(3.4)\n\nNotice that the Laplace transform of log Zn is Eet log Zn = EZnt . As \u039b(t) is finite and derivable\neverywhere, from (3.4) and the G\u00e4rtner-Ellis theorem ([10], p.52, Exercise 2.3.20), we immediately\nobtain Theorem 1.1.\n\u0010\n\u0011\nTheorem 1.3 can also be used to study the large deviation probabilities P lognZn \u2265 x (resp.\n\u0010\n\u0011\nP lognZn \u2264 x ) for a finite interval of x, when EW a (resp. EW \u2212a) (a > 0) exists only in a finite\ninterval of a. To this end we shall use the following version of the G\u00e4rtner-Ellis theorem adapted\nto the study of tail probabilities.\nLemma 3.1 ([20], Theorem 6.1). Let (\u03bcn ) be a family of probability distribution on R and let (an )\nbe a sequence of positive numbers satisfying an \u2192 \u221e. Assume that for some t0 \u2208 [0, \u221e] and for\nevery t \u2208 [0, t0 ), as n \u2192 \u221e,\nZ\n1\nlog ean tx \u03bcn (dx) \u2192 l(t) < \u221e.\nln (t) :=\nan\nFor x \u2208 R, set\n\nl\u2217 (x) = sup{tx \u2212 l(t); t \u2208 [0, t0 )}.\n\nIf l is continuously differentiable on (0, t0 ), then for all x \u2208 (l\u2032 (0+), l\u2032 (t0 \u2212)) (where l\u2032 (x\u00b1) =\nlimy\u2192x\u00b1 l\u2032 (y)),\n1\nlog \u03bcn ([x, \u221e)) = \u2212l\u2217 (x).\nlim\nn\u2192\u221e an\nFrom Theorem 1.3 and Lemma 3.1, we immediately obtain the following theorem.\nTheorem 3.1. Let a \u2208 R.\n+\na\n(i) Let a > 0. If a \u2208 (0, 1] and Ema\u22121\n0 Z1 log Z1 < \u221e, or a > 1 and EZ1 < \u221e, then\n\u0012\n\u0013\n1\nlog Zn\nlim log P\n\u2265 x = \u2212\u039b\u2217 (x), \u2200x \u2208 (E log m0 , \u039b\u2032 (a)).\nn\u2192\u221e n\nn\n\n12\n\n(3.5)\n\n\f(ii) Let a < 0. Assume (H) and kp1 k\u221e < 1. If Ep1 < Ema0 , then\n\u0012\n\u0013\nlog Zn\n1\n\u2264 x = \u2212\u039b\u2217 (x), \u2200x \u2208 (\u039b\u2032 (a), E log m0 ).\nlim log P\nn\u2192\u221e n\nn\n\n(3.6)\n\nIf EZ1a < \u221e for all a > 1 (resp. p1 = 0 a.s.), then Theorem 3.1 suggests that the limit in (3.5)\n(resp. (3.6)) would hold for any x > E log m0 (resp. x < E log m0 ). This leads to the following\ntheorem which is more precise than Corollary 1.2. It was proved by Bansaye & Berestycki [5] when\n(H) holds with \u03b4 = 1.\nTheorem 3.2. (i) If EZ1s < \u221e for all s > 1, then\n\u0012\n\u0013\n1\nlog Zn\nlim log P\n\u2265 x = \u2212\u039b\u2217 (x)\nn\u2192\u221e n\nn\n(ii) Assume (H) and p1 = 0 a.s., then\n\u0012\n\u0013\nlog Zn\n1\nlim log P\n\u2264 x = \u2212\u039b\u2217 (x)\nn\u2192\u221e n\nn\n\nfor x > E log m0 .\n\nfor x < E log m0 ,\n\nIf \u039b\u2032 (\u221e) = \u221e and \u039b\u2032 (\u2212\u221e) = 0, then Theorem 3.2 can be directly deduced from Theorem 3.1.\nBut it is possible that \u039b\u2032 (\u221e) < \u221e or \u039b\u2032 (\u2212\u221e) > 0. So we will give a direct proof of Theorem 3.2,\nfollowing [5].\nAccording to the large deviation principle for i.i.d. random variables, we have\n\u0012\n\u0013\nlog \u03a0n\n1\n\u2264 x = \u2212\u039b\u2217 (x) for x \u2264 E log m0 ,\n(3.7)\nlim log P\nn\u2192\u221e n\nn\n\u0012\n\u0013\n1\nlog \u03a0n\nlim log P\n\u2265 x = \u2212\u039b\u2217 (x) for x \u2265 E log m0 .\n(3.8)\nn\u2192\u221e n\nn\nLemma 3.2 below gives the lower bound for both the lower and upper deviations.\n\nLemma 3.2 ([5], Proposition 1). Assume (1.5). Then\n\u0012\n\u0013\nlog Zn\n1\n\u2264 x \u2265 \u2212\u039b\u2217 (x)\nlim inf log P\nn\u2192\u221e n\nn\n\u0012\n\u0013\n1\nlog Zn\nlim inf log P\n\u2265 x \u2265 \u2212\u039b\u2217 (x)\nn\u2192\u221e n\nn\n\nfor x \u2264 E log m0 ,\n\n(3.9)\n\nfor x \u2265 E log m0 .\n\n(3.10)\n\n\u0010 We\u0011sremark that in Lemma 3.2, the original moment condition in ([5], Proposition 1), namely,\nZ1\nZ1\nlog+ Z1 < \u221e.\n< \u221e for some s > 1, is weaken to E m\nE m\n0\n0\nThe following lemma gives the upper bound for both the lower and upper deviations.\n\nLemma 3.3. (i) If EW \u2212s < \u221e for all s > 1, then\n\u0012\n\u0013\nlog Zn\n1\n\u2264 x \u2264 \u2212\u039b\u2217 (x)\nlim sup log P\nn\nn\u2192\u221e n\n(ii) If EW s < \u221e for all s > 0, then\n\u0012\n\u0013\n1\nlog Zn\nlim sup log P\n\u2265 x \u2264 \u2212\u039b\u2217 (x)\nn\nn\u2192\u221e n\n13\n\nfor x < E log m0 .\n\n(3.11)\n\nfor x > E log m0 .\n\n(3.12)\n\n\fThe inequality (3.12) was proved by Bansaye & Berestycki [5]. For readers' convenience, we\nshall prove simultaneously (3.12) and (3.11).\nProof of Lemma 3.3. By the decomposition (1.6), for x \u2208 R, \u01eb > 0 and s > 0, we have\n\u0013\n\u0012\n\u0013\n\u0012\n\u0013\n\u0012\nlog \u03a0n\nlog Wn\nlog Zn\n\u2264x\n\u2264 P\n\u2264x+\u01eb +P\n\u2264 \u2212\u01eb .\nP\nn\nn\nn\nBy Markov's inequality and Lemma 2.1,\n\u0012\n\u0013\nlog Wn\nEWn\u2212s\nEW \u2212s\nP\n\u2264 \u2212\u01eb \u2264 s\u01ebn\n\u2264 s\u01ebn\nn\ne\ne .\nThus\n1\nlim sup log P\nn\u2192\u221e n\n\n\u0012\n\nlog Zn\n\u2264x\nn\n\n\u0013\n\n\u0012\n\u0013\n1\nlog \u03a0n\n\u2264 max{lim sup log P\n\u2264 x + \u01eb , \u2212s\u01eb}\nn\nn\u2192\u221e n\n= max{\u2212\u039b\u2217 (x + \u01eb), \u2212s\u01eb}.\n\nLetting s \u2192 \u221e and \u01eb \u2192 0, we obtain (3.11). For (3.12), we use a similar argument. For \u01eb > 0 and\ns > 1,\n\u0012\n\u0013\n\u0012\n\u0013\n\u0012\n\u0013\nlog Zn\nlog \u03a0n\nlog Wn\nP\n\u2265x\n\u2264 P\n\u2265x\u2212\u01eb +P\n\u2265\u01eb\nn\nn\nn\n\u0013\n\u0012\nEW s\nlog \u03a0n\n\u2265 x \u2212 \u01eb + s\u01ebn .\n\u2264 P\nn\ne\nThus\n1\nlim sup log P\nn\nn\u2192\u221e\n\n\u0012\n\nlog Zn\n\u2265x\nn\n\n\u0013\n\n\u0012\n\u0013\n1\nlog \u03a0n\n\u2264 max{lim sup log P\n\u2265 x \u2212 \u01eb , \u2212s\u01eb}\nn\nn\u2192\u221e n\n= max{\u2212\u039b\u2217 (x \u2212 \u01eb), \u2212s\u01eb}.\n\nAgain letting s \u2192 \u221e and \u01eb \u2192 0, we obtain (3.12).\nProof of Theorem 3.2. It is just a combination of Lemmas 3.2 and 3.3.\nNotice that Theorem 3.2 implies Corollary 1.2. By Lemma 4.4, we see that Corollary 1.2 is in\nfact equivalent to Theorem 1.1. So the direct proof of Theorem 3.2 leads to an alternative proof of\nTheorem 1.1.\n\n4\n\nModerate deviations for log Zn\n\nNow we turn to the proof of moderate deviation principle (Theorem 1.6). Similar to the proof of\nlarge deviation principle (Theorem 1.1), we can study the convergence rate of lognZn by considering\nthose of logn\u03a0n . Recall that (an ) is a sequence of positive numbers satisfying (1.8). Let\n\u0013\n\u0012\ntSn\n.\nSn := log \u03a0n \u2212 nE log m0 and \u039b\u0304n (t) = log E exp\nan\nBy the classic moderate deviation results for i.i.d. random variables (see [10], Theorem 3.7.1 and\nits proof), it is known that, if f (t) = Emt0 < \u221e in a neighborhood of the origin, then\nn\na2n\n1\n\u039b\u0304\n(\nt) = \u03c3 2 t2 ,\nn\nn\u2192\u221e a2\nn\n2\nn\nlim\n\n14\n\n(4.1)\n\n\fand for any measurable subset B of R,\nx2\n\u2212 inf o 2\nx\u2208B 2\u03c3\n\n\u0012\n\u0013\nlog \u03a0n \u2212 nE log m0\nn\n\u2264 lim inf 2 log P\n\u2208B\nn\u2192\u221e an\nan\n\u0012\n\u0013\nn\nlog \u03a0n \u2212 nE log m0\nx2\n\u2264 lim sup 2 log P\n\u2208 B \u2264 \u2212 inf\n.\n2\nan\nx\u2208B\u0304 2\u03c3\nn\u2192\u221e an\n\n(4.2)\n\nLemma 4.1. Let t \u2208 R.\n(i) If (H) holds and kp1 k\u221e < 1, then for all t < 0,\nan\n\nEZnn\n\nlim\n\nn\u2192\u221e\n\nt\n\nan\nt\nn\n\n= 1.\n\n(4.3)\n\nE\u03a0n\n\n(ii) If (H) holds, then there is a constant c > 0 such that for all t > 0,\nan\n\nc \u2264 lim inf\nn\u2192\u221e\n\nProof. (i) Let tn =\n\nan\nn t.\n\nEZnn\nan\n\nE\u03a0nn\n\nan\n\nt\nt\n\n\u2264 lim sup\nn\u2192\u221e\n\nEZnn\nan\n\nE\u03a0nn\n\nt\nt\n\n\u2264 1.\n\n(4.4)\n\nFor t < 0, we have tn < 0. By Jensen's inequality,\nE\u03be Wntn \u2265 (E\u03be Wn )tn = 1\n\na.s..\n\nThus\nEZntn = E\u03a0tnn E\u03be Wntn \u2265 E\u03a0tnn ,\nwhich leads to\nlim inf\nn\u2192\u221e\n\n(4.5)\n\nEZntn\n\u2265 1.\nE\u03a0tnn\n\nOn the other hand, if (H) holds and kp1 k\u221e < 1, then by Theorem 2.1, we have E\u03be W \u2212s \u2264 Cs a.s.\nfor some constants s > 0 and Cs > 0. Noticing that \u2212tn /s \u2208 (0, 1) for n large enough and that by\nLemma 2.1, E\u03be Wn\u2212s \u2264 E\u03be W \u2212s a.s., again by Jensen's inequality, we have\nE\u03be Wntn = E\u03be (Wn\u2212s )\u2212tn /s \u2264 (E\u03be Wn\u2212s )\u2212tn /s \u2264 (E\u03be W \u2212s )\u2212tn /s \u2264 Cs\u2212tn /s ,\nso that\nEZntn \u2264 Cs\u2212tn /s E\u03a0tnn .\nLetting n \u2192 \u221e, we obtain\nlim sup\nn\u2192\u221e\n\n(ii) For t > 0, we have tn =\n\nan\nn t\n\nEZntn\n\u2264 1.\nE\u03a0tnn\n\n\u2208 (0, 1) for n large enough, so by Jensen's inequality,\n\nE\u03be Wntn \u2264 (E\u03be Wn )tn = 1\nThus\nlim sup\nn\u2192\u221e\n\nEZntn\n\u2264 1.\nE\u03a0tnn\n\n15\n\na.s..\n\n\fOn the other hand, from the proof Lemma 2.3, we know that the assumption (H) ensures that\nE\u03be W s \u2264 Cs a.s. for 1 < s \u2264 1 + \u03b4 and some constant Cs > 0. By H\u00f6lder's inequality,\n1 = E\u03be Wn \u2264 E\u03be Wntn /p Wn1\u2212tn /p\n\u00111/q\n\u00011/p \u0010\n\u2264 E\u03be Wntn\nE\u03be Wn(1\u2212tn /p)q\n\na.s.,\n\n(4.6)\n\ns\u2212tn\nn\nfor p, q > 1, 1/p + 1/q = 1. Take p = p(n) = s\u2212t\ns\u22121 and q = q(n) = 1\u2212tn , so that (1 \u2212 tn /p)q = s and\n\u2212s\n\u2212s a.s.. We deduce from (4.6) that\nn\np/q = 1\u2212t\ns\u22121 . Notice that by Lemma 2.1, E\u03be Wn \u2264 E\u03be W\n\nE\u03be Wntn \u2265 (E\u03be Wns )\u2212\n\n1\u2212tn\ns\u22121\n\n\u2265 (E\u03be W s )\u2212\n\nThus\n\nn\n\u2212 1\u2212t\ns\u22121\n\nEZntn \u2265 Cs\n\nLetting n \u2192 \u221e, we obtain\n\nlim inf\nn\u2192\u221e\n\n1\u2212tn\ns\u22121\n\nn\n\u2212 1\u2212t\ns\u22121\n\n\u2265 Cs\n\n.\n\nE\u03a0tnn .\n\nEZntn\n\u2265 c,\nE\u03a0tnn\n\n1\n\u2212 s\u22121\n\n\u2208 (0, 1]. This completes the proof.\n\u0010\n\u0011\n\u0010 \u0011\nlog m0\ntSn\nTheorem 4.1. Let \u039bn (t) = log E exp log Zn \u2212nE\nt\nand\n\u039b\u0304\n(t)\n=\nlog\nE\nexp\nn\nan\nan . If (H) holds,\nthen\n2\n\u039bn ( ann t)\n= 1,\n\u2200t 6= 0\n(4.7)\nlim\nn\u2192\u221e \u039b\u0304 ( a2n t)\nn n\n\nwhere c = Cs\n\nand\nlim\n\nn\u2192\u221e\n\nan\n\nt\n\nan\n\nt\n\nlog EZnn\nlog E\u03a0nn\n\n\u2200t 6= 0.\n\n= 1,\n\n(4.8)\n\nProof. We only need prove (4.7), which implies (4.8). For t > 0, (4.7) is a direct consequence of\nLemma 4.1(ii). For t < 0, if additionally kp1 k\u221e < 1, then (4.7) is also a direct consequence of\nLemma 4.1(i); we shall prove that the condition kp1 k\u221e < 1 is not needed for (4.7) to hold. Assume\n(H) and let t < 0. Notice that (4.5) implies that\n2\n\nlim inf\n\n\u039bn ( ann t)\n\nlim sup\n\n\u039bn ( ann t)\n\nn\u2192\u221e\n\nIt remains to show that\n\n2\n\n\u039b\u0304n ( ann t)\n\n\u2265 1.\n\n2\n\nn\u2192\u221e\n\n2\n\n\u039b\u0304n ( ann t)\n\n\u2264 1.\n\nBy H\u00f6lder's inequality,\n\u0013\n\u0010a\n\u0011\na2n\nn\nexp \u039bn ( t)\n= E exp\nt(log Zn \u2212 nE log m0 )\nn\nn\n\u0012\n\nan\n\nan\n\nt\n\n= Ee n tSn Wnn\n\u0010 an\n\u0011\n\u00111/p \u0010\nan\ntq 1/q\n\u2264\nEe n ptSn\nEWnn\n\u0013\u0010\n\u0012\n\u0011\nan\na2n\n1\ntq 1/q\n,\n\u039b\u0304n ( pt) EWnn\n\u2264 exp\np\nn\n16\n\n(4.9)\n\n\fwhere p, q > 1 are constants satisfying 1/p + 1/q = 1. By Theorem 2.2, there exists s > 0 such that\nEW \u2212s < \u221e. Noticing that tn q > \u2212s for n large, we have\nEWntn q \u2264 1 + EWn\u2212s \u2264 1 + EW \u2212s.\nHence for n large enough,\n\u039bn (\n\n1\na2\n1\na2n\nt) \u2264 \u039b\u0304n ( n pt) + log(1 + EW \u2212s).\nn\np\nn\nq\n\nTherefore, considering (4.1), we have\n2\n\nlim sup\nn\u2192\u221e\n\n\u039bn ( ann t)\n2\n\n\u039b\u0304n ( ann t)\n\n\u2264\n\n1 12 \u03c3 2 p2 t2\n= p.\np 12 \u03c3 2 t2\n\nLetting p \u2192 1, (4.9) is proved.\nProof of Theorem 1.6. From (4.7) and (4.1) we have\na2n\n1\na2n\nn\nn\n\u039b\u0304\n(\nt)\n=\nlim\nt) = \u03c3 2 t2 .\n\u039b\n(\nn\nn\n2\n2\nn\u2192\u221e an\nn\u2192\u221e an\nn\nn\n2\nlim\n\nApplying the G\u00e4rtner-Ellis theorem ([10], p.52, Exercise 2.3.20), we obtain Theorem 1.6.\nThe following theorem about the tail probabilities is a direct consequence of Theorem 1.6.\nTheorem 4.2. Assume (H) and write \u03c3 2 = var(log m0 ) \u2208 (0, \u221e). Then for all x > 0,\n\u0012\n\u0013\nlog Zn \u2212 nE log m0\nx2\nn\n\u2264 \u2212x = \u2212 2 ,\nlim 2 log P\nn\u2192\u221e an\nan\n2\u03c3\n\u0013\n\u0012\nlog Zn \u2212 nE log m0\nx2\nn\n\u2265 x = \u2212 2.\nlim 2 log P\nn\u2192\u221e an\nan\n2\u03c3\n\n(4.10)\n\n(4.11)\n\nIt is also possible to give a direct proof of Theorem 4.2. We shall give such a proof in the following,\nas it will give additional one-side results on the tail probabilities under weaker assumptions.\nLemma 4.2. If f (t) = Emt0 < \u221e in a neighborhood of the origin, then for all x > 0 ,\n\u0012\n\u0013\nlog Zn \u2212 nE log m0\nn\nx2\nlim inf 2 log P\n\u2264 \u2212x \u2265 \u2212 2 ,\nn\u2192\u221e an\nan\n2\u03c3\n\u0012\n\u0013\nn\nlog Zn \u2212 nE log m0\nx2\nlim sup 2 log P\n\u2265 x \u2264 \u2212 2.\nan\n2\u03c3\nn\u2192\u221e an\nProof. Let x > 0. By (4.2), the moderate deviation principle for log \u03a0n , we have\n\u0012\n\u0013\nlog \u03a0n \u2212 nE log m0\nx2\nn\n\u2264 \u2212x = \u2212 2\nlim 2 log P\nn\u2192\u221e an\nan\n2\u03c3\nand\n\nn\nlog P\nlim\nn\u2192\u221e a2\nn\n\n\u0012\n\nlog \u03a0n \u2212 nE log m0\n\u2265x\nan\n17\n\n\u0013\n\n=\u2212\n\nx2\n.\n2\u03c3 2\n\n(4.12)\n(4.13)\n\n(4.14)\n\n(4.15)\n\n\fFor every \u01eb > 0,\n\u0013\nlog Zn \u2212 nE log m0\n\u2264 \u2212x\nan\n\u0013\n\u0012\nlog \u03a0n \u2212 nE log m0\n\u2264 \u2212x \u2212 \u01eb \u2212 P(Wn \u2265 ean \u01eb )\n\u2265 P\nan\n= : un \u2212 vn = un (1 \u2212 vn /un ).\nP\n\n\u0012\n\nBy (4.14), we have \u2200\u03b4\u2032 > 0, for n large enough,\n\u0012 2 \u0012\n\u0013\u0013\na\n(x + \u01eb)2\n\u2032\nun \u2265 exp \u2212 n\n+\n\u03b4\n.\nn\n2\u03c3 2\nFurthermore, by Markov's inequality,\nvn = P(Wn \u2265 ean \u01eb ) \u2264 e\u2212an \u01eb .\nHence,\n\n\u0012\n\u0012\n\u0013\u0013\nvn\na2n (x + \u01eb)2\n\u2032\n0\u2264\n\u2264 exp \u2212an \u01eb +\n+\u03b4\n\u21920\nun\nn\n2\u03c3 2\n\nsince\n\nlim\n\nn\u2192\u221e\n\n\u2212an \u01eb +\n\na2n\nn\n\n\u0010\n\n(x+\u01eb)2\n2\u03c32\n\n+ \u03b4\u2032\n\nan\n\n\u0011\n\nas n \u2192 \u221e,\n\n= \u2212\u01eb < 0.\n\nTherefore,\nn\nlim inf 2 log P\nn\u2192\u221e an\n\n\u0012\n\nlog Zn \u2212 nE log m0\n\u2264 \u2212x\nan\n\n\u0013\n\n\u2265 lim inf\nn\u2192\u221e\n\n(x + \u01eb)2\nn\nlog\nu\n=\n\u2212\n.\nn\na2n\n2\u03c3 2\n\nLetting \u01eb \u2192 0, we obtain (4.12). For (4.13), the proof is similar. For every \u01eb > 0,\n\u0012\n\u0013\nlog Zn \u2212 nE log m0\nP\n\u2265x\nan\n\u0013\n\u0012\nlog \u03a0n \u2212 nE log m0\nan \u01eb\n\u2265 x\u2212\u01eb\n\u2264 P(Wn \u2265 e ) + P\nan\n= : vn + \u0169n = \u0169n (1 + vn /\u0169n ).\nSince limn\u2192\u221e\n\nvn\n\u0169n\n\n= 0, we have\n\nlim sup\nn\u2192\u221e\n\nn\nlog P\na2n\n\n\u0012\n\nlog Zn \u2212 nE log m0\n\u2265x\nan\n\n\u0013\n\n\u2264 lim sup\nn\u2192\u221e\n\nn\n(x \u2212 \u01eb)2\nlog\n\u0169\n=\n\u2212\n.\nn\na2n\n2\u03c3 2\n\nLetting \u01eb \u2192 0, we get (4.13).\nTo prove Theorem 4.2, we need to estimate the decay rate of the probabilities P(Wn \u2264 e\u2212an \u01eb )\nfor \u01eb > 0.\nLemma 4.3. If EW \u2212s < \u221e for some s > 0, then for any positive sequence (an ) satisfying an \u2192 \u221e,\nwe have for all \u01eb > 0,\n1\nlog P(Wn \u2264 e\u2212an \u01eb ) \u2264 \u2212s\u01eb.\n(4.16)\nlim sup\na\nn\u2192\u221e\nn\n18\n\n\fProof. By Markov's inequality and Lemma 2.1,\nP(Wn \u2264 e\u2212an \u01eb ) \u2264\nThus\n\nEW \u2212s\nEWn\u2212s\n\u2264\n.\nesan \u01eb\nesan \u01eb\n\n1\n1\nlog P(Wn \u2264 e\u2212an \u01eb ) \u2264\nlog EW \u2212s \u2212 s\u01eb.\nan\nan\n\nTaking the limit superior in the above inequality gives (4.16).\nAnother proof of Theorem 4.2. Lemma 4.2 gives one side of the desired results, so we only need to\nprove the other side. By Theorem 2.2, there exists s > 0 such that EW \u2212s < \u221e, so (4.16) holds for\nthis s. For x > 0, we have for every \u01eb > 0,\n\u0013\n\u0012\nlog Zn \u2212 nE log m0\n\u2264 \u2212x\nP\nan\n\u0012\n\u0013\n\u0001\nlog \u03a0n \u2212 nE log m0\n\u2264 P Wn \u2264 e\u2212an \u01eb + P\n\u2264 \u2212x + \u01eb\nan\n= : vn + un .\nBy (4.14) and (4.16), limn\u2192\u221e\nn\nlim sup 2 log P\nn\u2192\u221e an\n\n\u0012\n\nvn\nun\n\n= 0, thus,\n\nlog Zn \u2212 nE log m0\n\u2264 \u2212x\nan\n\n\u0013\n\n\u2264 lim sup\nn\u2192\u221e\n\nn\n(x \u2212 \u01eb)2\nlog\nu\n=\n\u2212\n.\nn\na2n\n2\u03c3 2\n\nLetting \u01eb \u2192 0, we obtain\nn\nlim sup 2 log P\nn\u2192\u221e an\n\n\u0012\n\nlog Zn \u2212 nE log m0\n\u2264 \u2212x\nan\n\n\u0013\n\n\u2264\u2212\n\nx2\n.\n2\u03c3 2\n\n(4.17)\n\n(4.12) and (4.17) yield (4.10). To prove (4.11), on account of (4.13), it remains to show that\n\u0012\n\u0013\nn\nlog Zn \u2212 nE log m0\nx2\nlim inf 2 log P\n\u2265 x \u2265 \u2212 2.\n(4.18)\nn\u2192\u221e an\nan\n2\u03c3\nSimilarly, for every \u01eb > 0,\n\u0012\n\n\u0013\nlog Zn \u2212 nE log m0\nP\n\u2265x\nan\n\u0012\n\u0013\nlog \u03a0n \u2212 nE log m0\n\u2265 P\n\u2265 x + \u01eb \u2212 P(Wn \u2264 e\u2212an \u01eb )\nan\n= : \u0169n \u2212 vn .\nAgain by (4.14) and (4.16), limn\u2192\u221e\nn\nlim inf 2 log P\nn\u2192\u221e an\n\n\u0012\n\nvn\n\u0169n\n\n= 0, thus,\n\nlog Zn \u2212 nE log m0\n\u2265x\nan\n\n\u0013\n\n\u2264 lim inf\nn\u2192\u221e\n\n(x + \u01eb)2\nn\nlog\n\u0169\n=\n\u2212\n.\nn\na2n\n2\u03c3 2\n\nLetting \u01eb \u2192 0, we obtain (4.18).\nWe remark that, by Lemma 4.4 below, Theorem 4.2 is in fact equivalent to Theorem 1.6. So\nthe direct proof of Theorem 4.2 leads to another proof of Theorem 1.6.\n19\n\n\fLemma 4.4. Let I be a continuous function on R satisfying\n(a) I(b) = inf x\u2208R I(x) = 0 for some b \u2208 R;\n(b) I is strictly increasing on [b, \u221e) and strictly decreasing on (\u2212\u221e, b].\nLet (\u03bcn ) be a family of probability distribution on R and let (an ) be a sequence of positive numbers\nsatisfying an \u2192 \u221e. Then the following statements (i) and (ii) are equivalent.\n(i) For x < b,\n1\nlog \u03bcn ((\u2212\u221e, x]) = \u2212I(x);\nlim\nn\u2192\u221e an\nfor x > b,\n\n1\nlog \u03bcn ([x, +\u221e)) = \u2212I(x).\nn\u2192\u221e an\nlim\n\n(ii) (\u03bcn ) satisfies a large deviation principle: for any measurable subset B of R,\n1\nlog \u03bcn (B)\nan\n1\nlog \u03bcn (B) \u2264 \u2212 inf I(x),\n\u2264 lim sup\na\nx\u2208B\u0304\nn\u2192\u221e\nn\n\n\u2212 inf o I(x) \u2264 lim inf\nn\u2192\u221e\n\nx\u2208B\n\n(4.19)\n(4.20)\n\nwhere B o denotes the interior of B and B\u0304 its closure.\nThis is a general result on large deviations. It shows that the large deviation principe holds if\nand only if the corresponding limit exists for tail events, when the rate function is continuous and\nstrictly monotone. This result would be known; as we have not found a reference, we shall give a\nproof in an appendix by the end of the paper.\n\n5\n\nCentral limit theorems for W \u2212 Wn and log Zn\n\nIn this section, we shall prove the results about central limit theorems.\nWe first prove the central limit theorem on W \u2212 Wn with exponential convergence rate, using\nthe results about the harmonic moments of Zn (i.e. Theorem 1.3 with t < 0).\nProof of Theorem 1.7. Notice that\nZn \u0010\n\u0011\nX\n(n)\nWi \u2212 1 ,\n\u03a0n (W \u2212 Wn ) =\ni=1\n\n(n)\n\nwhere under P\u03be , the random variables Wi (i = 1, 2, ...) are independent of each other and indepen(n)\ndent of Zn , and have common conditional distribution P\u03be (Wi \u2208 *) = PT n \u03be (W \u2208 *). Notice that\n2 \u2265 a \u2212 1 > 0. Therefore the condition EZ 2+\u01eb < \u221e implies that\n> 1, then \u03b4\u221e\nif a0 := essinf mm0 (2)\n0\n2\n1\nE\n\nW \u22121\n\u03b4\u221e\n\n2+\u01eb\n\n0\n\n< \u221e. By the Berry-Esseen theorem (see [9], Theorem 9.1.3), for all x \u2208 R,\nP\u03be\n\n\u0012\n\n\u0013\nW \u22121\n\u03a0n (W \u2212 Wn )\n\u221a\n\u2264 x \u2212 \u03a6(x) \u2264 C1 ET n \u03be\nn\n\u03b4\u221e\nZn \u03b4\u221e (T \u03be)\n\n20\n\n2+\u01eb\n\nE\u03be Zn\u2212\u01eb/2 ,\n\n(5.1)\n\n\fwhere C1 is the Berry-Esseen constant. Taking expectation in (5.1), we obtain for all x \u2208 R,\n\u0012\n\u0013\n\u03a0n (W \u2212 Wn )\nW \u2212 1 2+\u01eb\n\u221a\nEZn\u2212\u01eb/2 .\n(5.2)\nP\n\u2264 x \u2212 \u03a6(x) \u2264 C1 E\nn\n\u03b4\nZn \u03b4\u221e (T \u03be)\n\u221e\n\u2212\u01eb/2\n\nSince Ep1 < Em0 , kp1 k\u221e < 1 and (H) holds, the condition (iii) of Theorem 1.3 is satisfied, so\nthat by Theorem 1.3, there exists a constant C\u01eb > 0 such that\nlim \u0010\n\nn\u2192\u221e\n\nCombing this with (5.2), we obtain (1.10).\n\n\u2212\u01eb/2\n\nEZn\n\n\u0011\n\u2212\u01eb/2 n\n\n= C\u01eb .\n\nEm0\n\nWe then prove the central limit theorem on log Zn , using the central limit theorem on log \u03a0n .\nProof of Theorem 1.8. Let x \u2208 R. By the standard central limit theorem for i.i.d. random variables,\n\u0013\n\u0012\nlog \u03a0n \u2212 nE log m0\n\u221a\n\u2264 x = \u03a6(x).\n(5.3)\nlim P\nn\u2192\u221e\nn\u03c3\nBy (1.6), we have for every \u01eb > 0,\n\u0013\n\u0012\nlog Zn \u2212 nE log m0\n\u221a\n\u2264x\nP\nn\u03c3\n\u0012\n\u0013\n\u0012\n\u0013\nlog Wn\nlog \u03a0n \u2212 nE log m0\n\u221a\n\u221a\n\u2264 P\n< \u2212\u01eb\u03c3 + P\n\u2264x+\u01eb .\nn\nn\u03c3\nSince limn\u2192\u221e\n\nlog\n\u221aWn\nn\n\n(5.4)\n\n= 0 a.s., we have\nlim P\n\nn\u2192\u221e\n\n\u0012\n\nlog Wn\n\u221a\n< \u2212\u01eb\u03c3\nn\n\n\u0013\n\n= 0.\n\n(5.5)\n\nTaking the limit superior in (5.4), and applying (5.3) and (5.5), we obtain\n\u0013\n\u0012\nlog Zn \u2212 nE log m0\n\u221a\n\u2264 x \u2264 \u03a6(x + \u01eb).\nlim sup P\nn\u03c3\nn\u2192\u221e\nLetting \u01eb \u2192 0, we get the upper bound. For the lower bound, observe that\n\u0012\n\u0013\nlog Zn \u2212 nE log m0\n\u221a\nP\n\u2264x\nn\u03c3\n\u0013\n\u0012\n\u0013\n\u0012\nlog Wn\nlog \u03a0n \u2212 nE log m0\n\u221a\n\u221a\n\u2264 x\u2212\u01eb \u2212P\n> \u01eb\u03c3 .\n\u2265 P\nn\u03c3\nn\nSimilarly,\nlim P\n\nn\u2192\u221e\n\n\u0012\n\nlog Wn\n\u221a\n> \u01eb\u03c3\nn\n\n\u0013\n\n= 0.\n\nTaking the limit inferior in (5.6) and letting \u01eb \u2192 0, we get\n\u0013\n\u0012\nlog \u03a0n \u2212 nE log m0\n\u221a\n\u2264 x \u2265 \u03a6(x).\nlim inf P\nn\u2192\u221e\nn\u03c3\nSo (1.11) is proved.\n21\n\n(5.6)\n\n\f6\n\nAppendix: proof of Lemma 4.4\n\nProof of Lemma 4.4. It is clear that (ii) implies (i) since I is continuous. We need to prove (i)\nimplies (ii). Firstly, we show (4.19). For x \u2208 B o , consider the case where x \u2265 b. Then B o contains\nan interval [x + \u01eb1 , x + \u01eb2 ) for some 0 < \u01eb1 < \u01eb2 . Consequently, by (i), \u2200\u01eb > 0, there exists n\u01eb > 0\nsuch that \u2200n \u2265 n\u01eb ,\n\u03bcn (B) \u2265 \u03bcn ([x + \u01eb1 , x + \u01eb2 ))\n\n= \u03bcn ([x + \u01eb1 , \u221e)) \u2212 \u03bcn ([x + \u01eb2 , \u221e))\n\n\u2265 e\u2212an (I(x+\u01eb1 )+\u01eb) \u2212 e\u2212an (I(x+\u01eb2 )\u2212\u01eb) .\n\nSince I is strictly increasing on [b, \u221e), we can take \u01eb > 0 small enough such that I(x + \u01eb1 ) + \u01eb <\nI(x + \u01eb2 ) \u2212 \u01eb. Therefore,\n1\nlog \u03bcn (B) \u2265 \u2212I(x + \u01eb1 ) \u2212 \u01eb.\nlim inf\nn\u2192\u221e an\nLetting \u01eb, \u01eb1 \u2192 0, we get\n\nlim inf\nn\u2192\u221e\n\n1\nlog \u03bcn (B) \u2265 \u2212I(x)\nan\n\n(6.1)\n\nIf x < b, we obtain(6.1) by a similar argument. So (6.1) holds for all x \u2208 B o , which yields (4.19).\nNow we show (4.20). If b \u2208 B\u0304, then (4.20)\nT is obvious since \u03bcn (B)\nT \u2264 1 and the right side\nS of\n(4.20) is 0. Assume that b \u2208\n/ B\u0304. Let B1 = B (\u2212\u221e, b] and B2 = B (b, \u221e) so that B = B1 B2 .\nThen\nB1 \u2282 (\u2212\u221e, b1 ] (if B1 6= \u2205)\nand\nB2 \u2282 [b2 , \u221e) (if B2 6= \u2205),\nwhere b1 := sup B1 and b2 := inf B2 . Assume that B1 6= \u2205 and B2 6= \u2205. As b \u2208\n/ B\u0304, we have\nb1 < b < b2 . By (i), \u2200\u01eb > 0, there exists n\u01eb > 0 such that \u2200n \u2265 n\u01eb ,\n\u03bcn (B) \u2264 \u03bcn ([\u2212\u221e, b1 ]) + \u03bcn ([b2 , \u221e))\n\n\u2264 e\u2212an (I(b1 )\u2212\u01eb) + e\u2212an (I(b2 )\u2212\u01eb)\n\u2264 2e\u2212an (I0 \u2212\u01eb) ,\n\nwhere I0 := min{I(b1 ), I(b2 )} = inf x\u2208B\u0304 I(x). Therefore,\nlim sup\nn\u2192\u221e\n\n1\nlog \u03bcn (B) \u2264 \u2212I0 + \u01eb.\nan\n\nLetting \u01eb \u2192 0, we obtain\nlim sup\nn\u2192\u221e\n\n1\nlog \u03bcn (B) \u2264 \u2212I0 = \u2212 inf I(x).\nan\nx\u2208B\u0304\n\nIf B1 = \u2205 or B2 = \u2205, we obtain (4.20) by a similar argument.\nAcknowledgement. The authors would like to thank an anonymous referee for valuable comments\nand remarks.\n\n22\n\n\fReferences\n[1] V.I. Afanasyev, J. Geiger, G. Kersting, V.A. Vatutin. Criticality for branching processes in\nrandom environment. Ann. Probab. 33 (2005), no. 2, 645-673.\n[2] V.I. Afanasyev, J. Geiger, G. Kersting, V.A. Vatutin. Functional limit theorems for strongly\nsubcritical branching processes in random environment. Stochastic Process. Appl. 115 (2005),\nno. 10, 1658-1676.\n[3] K.B. Athreya, P.E. Ney. Branching Processes. Springer, Berlin, 1972.\n[4] K.B. Athreya, S. Karlin. On branching processes in random environments I, II. Ann. Math.\nStatist. 42 (1971), 1499-1520, 1843-1858.\n[5] V. Bansaye, J. Berestycki. Large deviations for branching processes in random environment.\nMarkov Process. Related Fields 15 (2009), 493-524.\n[6] V. Bansaye, C. B\u00f6inghoff. Upper large deviations for branching processes in random environment with heavy tails. Preprint (2010).\n[7] C. B\u00f6inghoff, E.E. Dyakonova, G. Kersting, V.A. Vatutin. Branching processes in random\nenvironment which extinct at a given moment. Markov Process. Related Fields 16 (2010), no.\n2, 329-350.\n[8] C. B\u00f6inghoff, G. Kersting. Upper large deviations of branching processes in a random\nenvironment\u2013Offspring distributions with geometrically bounded tails. Stoch. Proc. Appl. 120\n(2010), 2064-2077.\n[9] Y.S. Chow, H. Teicher. Probability theory: Independence, Interchangeability and Martingales.\nSpringer-Verlag, New York, 1988.\n[10] A. Dembo, O. Zeitouni. Large deviations Techniques and Applications. Springer, New York,\n1998.\n[11] Y. Guivarc'h, Q. Liu. Propri\u00e9t\u00e9s asymptotiques des processus de branchement en environnement al\u00e9atoire. C. R. Acad. Sci. Paris, Ser I. 332 (2001), 339-344.\n[12] B. Hambly. On the limit distribution of a supercritical branching process in a random environment. J. Appl. Prob. 29 (1992), 499-518.\n[13] C.C. Heyde. Some central limit analogues for super-critical Galton-Watson process. J. Appl.\nProbab. 8 (1971), 52-59.\n[14] C.C. Heyde, B.M. Brown. An invariance principle and some convergence rate results for branching processes. Z. Wahrscheinlichkeitstheorie verw. Geb. 20 (1971), 189-192.\n[15] P. Jagers. Galton-Watson processes in varying environments. J. Appl. Prob. 11 (1974), 174-178.\n[16] M.V. Kozlov. On large deviations of branching processes in a random environment : geometric\ndistribution of descendants. Discrete Math. Appl. 16 (2006) 155-174.\n[17] Q. Liu. Asymptotic properties of supercritical age-dependent branching processes and homogeneous branching random walks. Stoch. Proc. Appl. 82 (1999), 61-87.\n\n23\n\n\f[18] Q. Liu. Asymptotic properties and absolute continuity of laws stable by random weighted mean.\nStoch. Proc. Appl. 95 (2001), 83-107.\n[19] Q. Liu. Local dimensions of the branching measure on a Galton-Watson tree. Ann. Inst. Henri.\nPoincar\u00e9, Probabiliti\u00e9s et Statistique 37 (2001), 195-222.\n[20] Q. Liu, A. Rouault. Limit theorems for Mandelbrot's multiplicative cascades. Ann. Appl. Proba.\n10 (2000), 218-239.\n[21] Q. Liu. The growth of an entire characteristic function and the tail probabilities of the limit\nof a tree martingale. In: Chauvin B., Cohen S., Rouault A., Trees. Progress in Probability,\nvol.40, Birkh\u00e4user, Basel, (1996), 51-80.\n[22] P.E. Ney, A.N. Vidyashanker. Harmonic moments and large deviation rates for supercritical\nbranching process. Ann. Appl. Proba. 13 (2003), 475-489.\n[23] W.L. Smith, W.E. Wilkinson. On branching processes in random environments. Ann. Math.\nStatist. 40 (1969), 814-827.\n[24] D. Tanny. Limit theorems for branching processes in a random environment. Ann. Proba. 5\n(1977), 100-116.\n[25] D. Tanny. A necessary and sufficient condition for a branching process in a random environment\nto grow like the product of its means. Stoch. Proc. Appl. 28 (1988), 123-139.\n[26] H. Wang, Z. Gao, Q. Liu. Central limit theorems for a branching process in a random environment. Stat. Prob. Letters 81 (2011) 539-547.\n\n24\n\n\f"}