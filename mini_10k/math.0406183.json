{"id": "http://arxiv.org/abs/math/0406183v1", "guidislink": true, "updated": "2004-06-09T13:25:41Z", "updated_parsed": [2004, 6, 9, 13, 25, 41, 2, 161, 0], "published": "2004-06-09T13:25:41Z", "published_parsed": [2004, 6, 9, 13, 25, 41, 2, 161, 0], "title": "Hitting probabilities in a Markov additive process with linear movements\n  and upward jumps: applications to risk and queueing processes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0406153%2Cmath%2F0406460%2Cmath%2F0406498%2Cmath%2F0406355%2Cmath%2F0406075%2Cmath%2F0406434%2Cmath%2F0406240%2Cmath%2F0406433%2Cmath%2F0406517%2Cmath%2F0406077%2Cmath%2F0406168%2Cmath%2F0406105%2Cmath%2F0406428%2Cmath%2F0406563%2Cmath%2F0406144%2Cmath%2F0406273%2Cmath%2F0406104%2Cmath%2F0406235%2Cmath%2F0406245%2Cmath%2F0406005%2Cmath%2F0406571%2Cmath%2F0406302%2Cmath%2F0406087%2Cmath%2F0406366%2Cmath%2F0406617%2Cmath%2F0406062%2Cmath%2F0406292%2Cmath%2F0406155%2Cmath%2F0406338%2Cmath%2F0406261%2Cmath%2F0406039%2Cmath%2F0406468%2Cmath%2F0406491%2Cmath%2F0406165%2Cmath%2F0406512%2Cmath%2F0406177%2Cmath%2F0406382%2Cmath%2F0406337%2Cmath%2F0406575%2Cmath%2F0406138%2Cmath%2F0406043%2Cmath%2F0406408%2Cmath%2F0406463%2Cmath%2F0406602%2Cmath%2F0406298%2Cmath%2F0406056%2Cmath%2F0406021%2Cmath%2F0406102%2Cmath%2F0406128%2Cmath%2F0406234%2Cmath%2F0406402%2Cmath%2F0406432%2Cmath%2F0406196%2Cmath%2F0406504%2Cmath%2F0406232%2Cmath%2F0406183%2Cmath%2F0406211%2Cmath%2F0406096%2Cmath%2F0406190%2Cmath%2F0406569%2Cmath%2F0406375%2Cmath%2F0406026%2Cmath%2F0406358%2Cmath%2F0406539%2Cmath%2F0406380%2Cmath%2F0406330%2Cmath%2F0406474%2Cmath%2F0406188%2Cmath%2F0406266%2Cmath%2F0406281%2Cmath%2F0406598%2Cmath%2F0406118%2Cmath%2F0406423%2Cmath%2F0406620%2Cmath%2F0406391%2Cmath%2F0406385%2Cmath%2F0406209%2Cmath%2F0406596%2Cmath%2F0406178%2Cmath%2F0406246%2Cmath%2F0406309%2Cmath%2F0406424%2Cmath%2F0406414%2Cmath%2F0406393%2Cmath%2F0406336%2Cmath%2F0406405%2Cmath%2F0406483%2Cmath%2F0406505%2Cmath%2F0406506%2Cmath%2F0406392%2Cmath%2F0406249%2Cmath%2F0406524%2Cmath%2F0406095%2Cmath%2F0406437%2Cmath%2F0406264%2Cmath%2F0406566%2Cmath%2F0406024%2Cmath%2F0406149%2Cmath%2F0406472%2Cmath%2F0406260%2Cmath%2F0406471&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Hitting probabilities in a Markov additive process with linear movements\n  and upward jumps: applications to risk and queueing processes"}, "summary": "Motivated by a risk process with positive and negative premium rates, we\nconsider a real-valued Markov additive process with finitely many background\nstates. This additive process linearly increases or decreases while the\nbackground state is unchanged, and may have upward jumps at the transition\ninstants of the background state. It is known that the hitting probabilities of\nthis additive process at lower levels have a matrix exponential form. We here\nstudy the hitting probabilities at upper levels, which do not have a matrix\nexponential form in general. These probabilities give the ruin probabilities in\nthe terminology of the risk process. Our major interests are in their analytic\nexpressions and their asymptotic behavior when the hitting level goes to\ninfinity under light tail conditions on the jump sizes. To derive those\nresults, we use a certain duality on the hitting probabilities, which may have\nan independent interest because it does not need any Markovian assumption.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0406153%2Cmath%2F0406460%2Cmath%2F0406498%2Cmath%2F0406355%2Cmath%2F0406075%2Cmath%2F0406434%2Cmath%2F0406240%2Cmath%2F0406433%2Cmath%2F0406517%2Cmath%2F0406077%2Cmath%2F0406168%2Cmath%2F0406105%2Cmath%2F0406428%2Cmath%2F0406563%2Cmath%2F0406144%2Cmath%2F0406273%2Cmath%2F0406104%2Cmath%2F0406235%2Cmath%2F0406245%2Cmath%2F0406005%2Cmath%2F0406571%2Cmath%2F0406302%2Cmath%2F0406087%2Cmath%2F0406366%2Cmath%2F0406617%2Cmath%2F0406062%2Cmath%2F0406292%2Cmath%2F0406155%2Cmath%2F0406338%2Cmath%2F0406261%2Cmath%2F0406039%2Cmath%2F0406468%2Cmath%2F0406491%2Cmath%2F0406165%2Cmath%2F0406512%2Cmath%2F0406177%2Cmath%2F0406382%2Cmath%2F0406337%2Cmath%2F0406575%2Cmath%2F0406138%2Cmath%2F0406043%2Cmath%2F0406408%2Cmath%2F0406463%2Cmath%2F0406602%2Cmath%2F0406298%2Cmath%2F0406056%2Cmath%2F0406021%2Cmath%2F0406102%2Cmath%2F0406128%2Cmath%2F0406234%2Cmath%2F0406402%2Cmath%2F0406432%2Cmath%2F0406196%2Cmath%2F0406504%2Cmath%2F0406232%2Cmath%2F0406183%2Cmath%2F0406211%2Cmath%2F0406096%2Cmath%2F0406190%2Cmath%2F0406569%2Cmath%2F0406375%2Cmath%2F0406026%2Cmath%2F0406358%2Cmath%2F0406539%2Cmath%2F0406380%2Cmath%2F0406330%2Cmath%2F0406474%2Cmath%2F0406188%2Cmath%2F0406266%2Cmath%2F0406281%2Cmath%2F0406598%2Cmath%2F0406118%2Cmath%2F0406423%2Cmath%2F0406620%2Cmath%2F0406391%2Cmath%2F0406385%2Cmath%2F0406209%2Cmath%2F0406596%2Cmath%2F0406178%2Cmath%2F0406246%2Cmath%2F0406309%2Cmath%2F0406424%2Cmath%2F0406414%2Cmath%2F0406393%2Cmath%2F0406336%2Cmath%2F0406405%2Cmath%2F0406483%2Cmath%2F0406505%2Cmath%2F0406506%2Cmath%2F0406392%2Cmath%2F0406249%2Cmath%2F0406524%2Cmath%2F0406095%2Cmath%2F0406437%2Cmath%2F0406264%2Cmath%2F0406566%2Cmath%2F0406024%2Cmath%2F0406149%2Cmath%2F0406472%2Cmath%2F0406260%2Cmath%2F0406471&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Motivated by a risk process with positive and negative premium rates, we\nconsider a real-valued Markov additive process with finitely many background\nstates. This additive process linearly increases or decreases while the\nbackground state is unchanged, and may have upward jumps at the transition\ninstants of the background state. It is known that the hitting probabilities of\nthis additive process at lower levels have a matrix exponential form. We here\nstudy the hitting probabilities at upper levels, which do not have a matrix\nexponential form in general. These probabilities give the ruin probabilities in\nthe terminology of the risk process. Our major interests are in their analytic\nexpressions and their asymptotic behavior when the hitting level goes to\ninfinity under light tail conditions on the jump sizes. To derive those\nresults, we use a certain duality on the hitting probabilities, which may have\nan independent interest because it does not need any Markovian assumption."}, "authors": ["Masakiyo Miyazawa"], "author_detail": {"name": "Masakiyo Miyazawa"}, "author": "Masakiyo Miyazawa", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/105051604000000206", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/math/0406183v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0406183v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "90B22, 60K25 (Primary) 60K20, 60G55. (Secondary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0406183v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0406183v1", "arxiv_comment": null, "journal_reference": "Annals of Probability 2004, Vol. 14, No. 2, 1029-1054", "doi": "10.1214/105051604000000206", "fulltext": "arXiv:math/0406183v1 [math.PR] 9 Jun 2004\n\nThe Annals of Applied Probability\n2004, Vol. 14, No. 2, 1029\u20131054\nDOI: 10.1214/105051604000000206\nc Institute of Mathematical Statistics, 2004\n\nHITTING PROBABILITIES IN A MARKOV ADDITIVE PROCESS\nWITH LINEAR MOVEMENTS AND UPWARD JUMPS:\nAPPLICATIONS TO RISK AND QUEUEING PROCESSES\nBy Masakiyo Miyazawa1\nTokyo University of Science\nMotivated by a risk process with positive and negative premium\nrates, we consider a real-valued Markov additive process with finitely\nmany background states. This additive process linearly increases or\ndecreases while the background state is unchanged, and may have upward jumps at the transition instants of the background state. It is\nknown that the hitting probabilities of this additive process at lower\nlevels have a matrix exponential form. We here study the hitting\nprobabilities at upper levels, which do not have a matrix exponential form in general. These probabilities give the ruin probabilities in\nthe terminology of the risk process. Our major interests are in their\nanalytic expressions and their asymptotic behavior when the hitting\nlevel goes to infinity under light tail conditions on the jump sizes. To\nderive those results, we use a certain duality on the hitting probabilities, which may have an independent interest because it does not\nneed any Markovian assumption.\n\n1. Introduction. Consider a risk process in which premium rates, claim\narrivals and claim sizes depend on a background state, which is governed by\na continuous time Markov chain. The premium rate is usually assumed to\nbe positive, and can be reduced to unit by a random time change. Suppose\nthat the premium includes returns from investments. Then, it may happen\nthat the premium rate takes negative values since the returns may be negative. This motivates us to consider a risk process with positive and negative\npremium rates. Our primary interest is in an asymptotic behavior of the\nruin probability when the initial reserve goes to infinity, provided the claim\nsize distributions have light tails, that is, decrease exponentially fast.\nReceived May 2002; revised April 2003.\nSupported in part by JSPS Grant 13680532.\nAMS 2000 subject classifications. Primary 90B22, 60K25; secondary 60K20, 60G55.\nKey words and phrases. Risk process, Markov additive process, hitting probability, decay rate, Markov renewal theorem, stationary marked point process, duality.\n1\n\nThis is an electronic reprint of the original article published by the\nInstitute of Mathematical Statistics in The Annals of Applied Probability,\n2004, Vol. 14, No. 2, 1029\u20131054. This reprint differs from the original in\npagination and typographic detail.\n1\n\n\f2\n\nM. MIYAZAWA\n\nSimilarly to Asmussen (2000), we model the risk process as a Markov\nadditive process Y (t) with upward jumps and Y (0) = 0. Then, for x \u2265 0,\nx \u2212 Y (t) is a risk process with initial reserve x, and ruin occurs when Y (t)\nhits level x. We assume the following setting. The background continuoustime Markov chain has a finite state space. The additive component linearly\nincreases or decreases while the background state is unchanged. At the transition instants of the background Markov chain, the additive component may\nhave upward jumps whose sizes may depend on the background states before and after the transitions. This additive process was recently studied by\nTakada (2001) and Miyazawa and Takada (2002) for extending the Markov\nmodulated fluid queue [see, e.g., Asmussen (1995) and Rogers (1994)].\nA key observation in Miyazawa and Takada (2002) and Takada (2001)\nis that the hitting probabilities in the downward direction have a matrix\nexponential form, which follows from the fact that the additive process is skip\nfree in this direction. The result generalizes the matrix exponential forms in\nthe literature [see, e.g., Asmussen (1995, 1995), Rogers (1994) and Takine\n(2001)]. However, we can not directly apply this result to the ruin probability\nsince this requires the hitting probabilities in the upward direction.\nIn this paper we consider these hitting probabilities. We represent the\nhitting probabilities as a Markov renewal function. Then, their asymptotic\nbehaviors are studied through the Markov renewal theorem. This renewal\napproach for the asymptotic behavior is rather classical, but has not been so\npopular for the Markov additive process. A typical approach is the change\nof measures based on martingales [see, e.g., Asmussen (2000)]. The large\ndeviation technique has also been used. The latter can be applied for a\nlarger class of additive processes, but is less informative. In this paper we\nshow that the Markov renewal approach is yet powerful, in particular, it\nprovides the prefactor of the decay function.\nTo fully utilize this approach, we need to get the Markov renewal kernel\nin a closed form, which is the conditional joint distribution of the ladder\nheight and associated background state given an initial background state.\nTo this end, we use a dual additive process similarly to Asmussen (1991)\nand Sengupta (1989). This dual process is obtained from the Markov additive process by time reversal and changing the sign of the additive component. However, our approach is different from those in Asmussen (1991)\nand Sengupta (1989), which use the occupation measure. We directly derive the joint distribution, including the ladder epoch, in terms of the dual\nprocess, which does not require any drift condition on the additive process.\nFurthermore, we do not need any Markovian assumption, but only need stationarity. This result may be of independent interests, so we derive it under\nthe stationary regime. We then specialize it to the Markov additive process\nand perform detailed computations.\n\n\f3\n\nHITTING PROBABILITIES IN RISK PROCESS\n\nThis paper is made up by six sections. In Section 2 we introduce the\nadditive process with upward jumps under the stationary regime, and compute the ascending ladder height distribution in terms of the dual process.\nIn Section 3 we specialize this result to the Markov additive processes. In\nSection 4 we derive a Markov renewal equation for the hitting probabilities.\nIn Section 5 those probabilities are shown to have asymptotically exponential decay. In Section 6 we discuss applications to risk processes and fluid\nqueues.\n2. The additive process under the stationary framework. In this section\nwe introduce a stationary additive process and consider its ascending ladder\nheight, not using any Markovian assumption. Let {(tn , Mn , An ); n \u2208 Z} be\na stationary marked point process, such that the counting measure N of\n{tn } has a finite intensity \u03bb and the mark (Mn , An ) takes values in S \u00d7 R+ ,\nwhere S is a countable set, Z is the set of all integers and R+ = [0, \u221e). In\nour application S is finite, but this does not matter in this section. In the\nterminology of a risk process, tn is the arrival time of a claim if An is positive\nand Mn is a background state. Note that not all tn represent claim arrivals\nsince An = 0 is allowed. This gives a great flexibility when we assume Mn to\nbe Markov. Namely, the claim arrivals are subject to the Markovian arrival\nprocess due to Neuts (1989) [see Asmussen (2000) for applications to a risk\nprocess].\nLet M (t) and A(t) be continuous-time processes such that M (t) = Mn and\nA(t) = An , respectively, for t \u2208 [tn , tn+1 ). As usual, we can choose a canonical\nprobability space (\u03a9, F, P ) with a shift operator group {\u03b8t } on \u03a9 such that\nP ({\u03b8t (\u03c9) \u2208 D}) = P (D) for all D \u2208 F , and, for \u03c9 \u2208 \u03a9, s \u2208 R \u2261 (\u2212\u221e, +\u221e),\nN (B)(\u03b8s (\u03c9)) = N (B + s)(\u03c9),\nM (t)(\u03b8s (\u03c9)) = M (t + s)(\u03c9),\n\nB \u2208 B(R),\nA(t)(\u03b8s (\u03c9)) = A(t + s)(\u03c9),\n\nt \u2208 R,\n\nwhere B + s = {u + s; u \u2208 B}. We shall use abbreviated notation such as\nM (t) \u25e6 \u03b8s for M (t)(\u03b8s (\u03c9)).\nWe next define an additive process. Let v(i) be a function from S to\nR \\ {0}. For simplicity, we exclude the case v(i) = 0, but this is not essential.\nThen, Y (t) is defined as\n\n(2.1)\n\nY (t) =\n\n\uf8f1Z\n\uf8f4\n\uf8f4\n\uf8f2\n\nt+\n\nv(M (u)) du +\n\n0+\nZ\n\n\uf8f4\n\uf8f4\n\uf8f3\u2212\n\n0+\n\nt\u2212\n\nZ\n\nt+\n\nA(u)N (du),\n0+\nZ\n\nt \u2265 0,\n\n0+\n\nv(M (u)) du \u2212\n\nA(u)N (du),\n\nt < 0.\n\nt\u2212\n\nThus Y (t) is the additive process that linearly changes while M (t) is constant and may have jumps when it changes. Note that Y (t), M (t) and A(t)\n\n\f4\n\nM. MIYAZAWA\n\nare right continuous and Y (0) = 0. By definition, Y (t) has stationary increments and satisfies (Y (t) \u2212 Y (s)) \u25e6 \u03b8u = Y (t + u) \u2212 Y (s + u). In particular,\nY (0) = 0 implies\n(2.2)\n\nY (t) \u25e6 \u03b8u = Y (t + u) \u2212 Y (u).\n\nWe refer to Y (t) as a stationary additive process with background process\nM (t).\nLet \u03c4x+ be the hitting time when Y (t) gets into [x, \u221e) for x \u2265 0. Namely,\n\u03c4x+ = inf{t > 0; Y (t) \u2265 x}.\nThen, Y (\u03c40+ ) is called the ascending ladder height, which is zero when Y (t)\ncontinuously crosses the origin. Note that \u03c40+ and, hence, Y (\u03c40+ ) and M (\u03c40+ )\nare defective (proper) if\nE(Y (1)) < (>)0\n\nrespectively.\n\nAs is well known, this can be proved using Loynes' (1962) arguments. If\nM (t) is a Markov process, E(Y (1)) \u2265 0 implies that \u03c40+ is proper [see Lemma\n2.1 of Miyazawa and Takada (2002)]. In what follows, for i \u2208 S, the event\n{M (\u03c40+ ) = i} means the event {\u03c40+ < \u221e, M (\u03c40+ ) = i}.\nThe purpose of this section is to express the joint distribution at the\nascending ladder epoch, that is, for i, j \u2208 S, u, x, z \u2265 0,\nP (\u03c40+ \u2264 u; M (0) = i, M (\u03c40+ \u2212) = j, M (\u03c40+ ) = k, \u2212Y (\u03c40+ ) \u2264 z, Y (\u03c40+ ) \u2264 x),\nin terms of dual processes M\u0303 (t), \u00c3(t) and \u1ef8 (t) defined below. In our applications we only need the case that u = z = \u221e, but the joint distribution\nmay be of independent interests, as we shall see.\nDefine dual processes M\u0303 (t) and \u1ef8 (t) by\nM\u0303 (t) = M (\u2212t),\n\n\u00c3(t) = A(\u2212t),\n\n\u1ef8 (t) = \u2212Y (\u2212t) + Y (0\u2212),\n\nt \u2208 R.\n\nNote that \u1ef8 (t) is also a stationary additive process with upward jumps satisfying \u1ef8 (0+) = 0. The term Y (0\u2212) is irrelevant in the definition of \u1ef8 (t)\nunder the stationary setting, that is, with respect to P , since P (Y (0) =\nY (0\u2212) = 0) = 1. However, this is not the case under the conditional probability measure, given that there is a point of N at the origin. Note that\nthe dual process \u1ef8 (t) is not right continuous but left continuous. Thus,\n\u1ef8 (0) = \u1ef8 (0\u2212) may be negative. Similarly to \u1ef8 (t), M\u0303 (t) and \u00c3(t) are left\ncontinuous. Furthermore, if M\u0303 (t) = i, then \u1ef8 (t) changes at rate v(i), that\nis, Y (t) and \u1ef8 (t) have the same rate when their corresponding background\nstates are identical. Let\n\u03c4\u0303w\u2212 = inf{t > 0; \u1ef8 (t) \u2264 w},\n\nw \u2264 0.\n\nThat is, \u03c4\u0303w\u2212 is the hitting time of \u1ef8 (t) at level w \u2264 0. Note that \u1ef8 (t) is skip\nfree in the downward direction. So the distributions of \u03c4\u0303w\u2212 and M\u0303 (\u03c4\u0303w\u2212 ) are\n\n\fHITTING PROBABILITIES IN RISK PROCESS\n\n5\n\neasier to get when the background process M (t) is Markov. This fact will\nbe used.\nSince \u03bb \u2261 E(N (0, 1]) < \u221e, we can define the Palm distribution with respect to the point process N , which is denoted by PN . Let\n\u03c3 \u2212 (t) = sup{u < t; N ([u, t)) > 0},\n\u03c3 + (t) = inf{u > t; N ([t, u)) > 0}.\nWe also use their duals: \u03c3\u0303 \u2212 (t) and \u03c3\u0303 + (t), by changing N to its dual \u00d1 ,\nwhere \u00d1 (B) = N (\u2212B) for B \u2208 B(R) in which \u2212B = {x \u2208 R; \u2212x \u2208 B}. For\nexample, \u03c3\u0303 \u2212 (t) is the last transition instant of M\u0303 before time t. Note that\nthe dual processes under P coincide with the original processes under P\u0303 ,\nwhich is a canonical probability measure for (\u00d1 (*), M\u0303 (t), \u00c3(t)). For example,\n\u2212\n\u2212\nEN (\u03c6(\u03c4\u0303\u2212x\n)) = \u1ebc\u00d1 (\u03c6(\u03c4\u2212x\n)). Keeping these facts in mind, we present the\nfollowing results, using the following notation:\nS \u2212 = {i \u2208 S; v(i) < 0},\n\nS + = {i \u2208 S; v(i) > 0},\n\nM\u2212 (t) = (M (\u03c3 \u2212 (t)\u2212), M (t)),\n\nM\u0303+ (t) = (M\u0303 (t), M\u0303 (\u03c3\u0303 + (t)+)).\n\nNote that M\u2212 (t) = (M (t\u2212), M (t)) if N ({t}) = 1.\nLemma 2.1.\n\nFor a nonnegative measurable \u03c6, i \u2208 S \u2212 , j, k \u2208 S and x, z \u2265\n\n0,\n\u2212v(i)E(\u03c6(\u03c40+ ); M (0) = i, M\u2212 (\u03c40+ ) = (j, k),\n\u2212Y (\u03c40+ \u2212) \u2264 z, 0 < Y (\u03c40+ ) \u2264 x)\n\n(2.3)\n=\u03bb\n\nZ\n\nz\n\n0\n\n\u2212\n\u2212\nEN (\u03c6(\u03c4\u0303\u2212w\n); M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212w\n) = i,\n\n0 < \u00c3(0) \u2212 w \u2264 x) dw,\nand, using the notation T\u0303 = \u1ef8 (0) \u2212 \u1ef8 (\u03c3\u0303 \u2212 (0)+), for i \u2208 S \u2212 , k \u2208 S + ,\n\u2212v(i)E(\u03c6(\u03c40+ ); M (0) = i, M\u2212 (\u03c40+ ) = (j, k), Y (\u03c40+ ) = 0)\n(2.4)\n\n=\u03bb\n\nZ\n\n0\n\n\u221e\n\n\u2212\n\u2212\n) = i,\n); M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212w\nEN (\u03c6(\u03c4\u0303\u2212w\n\n\u00c3(0) < w < T\u0303 + y) dw,\nwhere E(X; D) = E(X 1D ) for a random variable X and an event D.\nProof. We first consider the case that Y (\u03c40+ ) > 0. In this case the\nadditive process Y (t) only up crosses level 0 by a jump. Hence, we have\nE(\u03c6(\u03c40+ ); M (0) = i, M\u2212 (\u03c40+ ) = (j, k), \u2212Y (\u03c40+ ) < z, 0 < Y (\u03c40+ ) \u2264 x)\n\n\f6\n\nM. MIYAZAWA\n\n=E\n(2.5)\n\n\u0012Z\n\n\u221e\n\n\u03c6(t)1(M (0) = i, M\u2212 (t) = (j, k),\n\n0\n\nY (u) < 0, u \u2208 (0, t),\n\u0013\n\n\u2212 Y (t\u2212) \u2264 z, Y (t) \u2208 (0, x])N (dt) ,\nwhere 1(*) is the indicator function of the statement \"*\". To (2.5), we apply\nCampbell's formula [see, e.g., (3.3.1) of Baccelli and Br\u00e9maud (2002)], which\nis given for a random function g(t) by\nE\n\n\u221e\n\n\u0012Z\n\n\u0013\n\ng(t) \u25e6 \u03b8t N (dt) = \u03bbEN\n\n0\n\n\u0012Z\n\n\u221e\n\n\u0013\n\ng(t) dt .\n0\n\nTo this end, we apply \u03b8\u2212t to the events in the indicator function of (2.5).\nBy (2.2),\nY (t) \u25e6 \u03b8\u2212t = \u2212Y (\u2212t) = \u1ef8 (t) \u2212 \u1ef8 (0).\nThus, using the fact that Y (0+) = 0, we have\n{M (0) = i, M (t\u2212) = j, M (t) = k} \u25e6 \u03b8\u2212t\n= {M\u0303 (0) = k, M\u0303 (0+) = j, M\u0303 (t) = i},\n{Y (u) < 0, u \u2208 (0, t)} \u25e6 \u03b8\u2212t\n= {\u1ef8 (t) \u2264 \u1ef8 (u), u \u2208 (0, t)},\n{\u2212Y (t\u2212) \u2264 z, Y (t) \u2208 (0, x]} \u25e6 \u03b8\u2212t\n= {\u2212\u1ef8 (t) \u2264 z, \u2212\u1ef8 (0) \u2212 x \u2264 \u2212\u1ef8 (t) \u2264 \u2212\u1ef8 (0)}.\nHence, applying Campbell's formula to the right-hand side of (2.5) yields\nE(\u03c6(\u03c40+ ); M (0) = i, M\u2212 (\u03c40+ ) = (j, k), 0 < Y (\u03c40+ ) \u2264 x)\n= \u03bbEN\n(2.6)\n\n\u0012Z\n\n0\n\n\u221e\n\n\u03c6(\u03c4\u0303\u1ef8\u2212(t) )1(M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u1ef8\u2212(t) ) = i,\n\u1ef8 (t) < \u1ef8 (u), u \u2208 (0, t), \u2212\u1ef8 (t) \u2264 z,\n\u0013\n\n\u2212\u1ef8 (0) \u2212 x \u2264 \u2212\u1ef8 (t) < \u2212\u1ef8 (0)) dt ,\nwhere the fact that t = \u03c4\u0303\u1ef8\u2212(t) when t is the descending ladder epoch is used.\nWe now change variable t in the integral in (2.6). Let\nw(t) = \u2212 inf \u1ef8 (u).\n0<u<t\n\n\f7\n\nHITTING PROBABILITIES IN RISK PROCESS\n\nClearly, w(t) is nondecreasing, and w(t) = \u2212\u1ef8 (t) when w(t) increases because the dual process \u1ef8 (t) is left continuous and skip free in the downward\ndirection. So, we have\nw\u2032 (t) = \u2212v(M\u0303 (t))1(\u1ef8 (t) < \u1ef8 (u), u \u2208 (0, t)).\nHence, changing variables from t to w = w(t) in (2.6) and using the fact that\n\u00c3(0) = \u2212\u1ef8 (0), we obtain (2.3). We next consider the case that k \u2208 S + and\nY (\u03c40+ ) = 0. Similarly to (2.5), we have\nE(\u03c6(\u03c40+ ); M (0) = i, M\u2212 (\u03c40+ ) = (j, k), Y (\u03c40+ ) = 0)\n=E\n(2.7)\n\n\u0012Z\n\n0\n\n\u221e\n\n\u03c6(t)1(M (0) = i, M\u2212 (t) = (j, k),\nY (u) < 0, u \u2208 (0, t),\n+\n\n\u0013\n\nY (t) \u2264 0 < Y (\u03c3 (t)\u2212))N (dt) .\nHence, we can apply similar arguments as for the case Y (\u03c40+ ) > 0, but we\nneed to replace the event {0 < Y (t) \u2264 x} \u25e6 \u03b8\u2212t by\n{Y (t) \u2264 0 < Y (\u03c3 + (t)\u2212)} \u25e6 \u03b8\u2212t\n= {\u2212Y (\u2212t) \u2264 0 < Y (\u03c3 + (0)\u2212) \u2212 Y (\u2212t)}\n= {\u00c3(0) \u2264 w < \u1ef8 (0) \u2212 \u1ef8 (\u03c3\u0303 \u2212 (0)+) + \u00c3(0)},\nfor w = \u2212\u1ef8 (t). Hence, (2.4) follows. \u0003\nRemark 2.1. (a) A key fact in Lemma 2.1 is that the ladder height\ndistribution, given the initial state, can be obtained via the hitting times in\nthe skip free direction.\n(b) Lemma 2.1 does not need any drift condition on Y (t). So, the distribution in the left-hand side of (2.3), with \u03c6 \u2261 1, may or may not be\ndefective.\n(c) Consider the special case that N is Poisson and v(1) = \u22121 with\nS = {1}. This constitutes the classical risk process. Then, (2.3) is compatible with standard results, such as Theorem 2.2 in Chapter III of Asmussen\n(2000), provided E(Y (1)) < 0.\nIn the rest of this section we shall give further remarks and results on\nLemma 2.1. We first note the interesting feature of (2.3), that the sample\npath of the forward process is traced back under the Palm distribution.\nFigure 1 illustrates this sample path behavior. This fact is also related to\n\n\f8\n\nM. MIYAZAWA\n\nthe following conditional trace back for the conventional Markov modulated\nrisk process, that is, in the Markovian setting with v \u2261 \u22121.\n(2.8)\n\nP (\u03c40+ \u2264 t|M (0) = i, M\u2212 (\u03c40+ ) = (j, k), \u2212Y (\u03c40+ \u2212) = z)\n\u2212\n\u2212\n= P (\u03c4\u0303\u2212z\n\u2264 t|M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212z\n) = i),\n\nt, z \u2265 0.\n\nSee, for example, (2.1) of Asmussen and H\u00f8jgaard (1996) and Proposition\n2.2 of Asmussen and Kl\u00fcppelberg (1996) for the derivation of (2.8). Let us\nshow how (2.8) is obtained in our approach. From (2.3), we have, for i \u2208 S \u2212 ,\nj, k \u2208 S and t, z > 0,\n(2.9)\n\n\u2212v(i)P (\u03c40+ \u2264 t, M (0) = i, M\u2212 (\u03c40+ ) = (j, k), 0 < \u2212Y (\u03c40+ \u2212) \u2264 z)\n=\u03bb\n\nZ\n\n0\n\nz\n\n\u2212\n\u2212\nPN (\u03c4\u0303\u2212w\n\u2264 t, M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212w\n) = i, w < \u00c3(0)) dw.\n\nHence, taking the derivative of (2.9) with respect to z and dividing by this\nderivative with t = \u221e, we get, for t \u2265 0,\n(2.10)\n\nP (\u03c40+ \u2264 t|M (0) = i, M\u2212 (\u03c40+ ) = (j, k), \u2212Y (\u03c40+ \u2212) = z)\n\u2212\n\u2212\n= PN (\u03c4\u0303\u2212z\n\u2264 t|M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212z\n) = i, w < \u00c3(0)).\n\nIn the Markovian setting, PN in (2.10) can be replaced by P , and \u03c4\u0303z\u2212 and\n\u2212\nM\u0303 (\u03c4\u0303\u2212z\n) do not depend on \u00c3(0) since \u1ef8 (0+) = 0. So we arrive at (2.8). Note\nthat (2.10) is less informative than (2.9), equivalently, (2.3). Namely, we\nneed (2.9) with t = \u221e to get (2.9) from (2.10).\nWe next sum (2.3) with \u03c6(y) = 1(y \u2264 t) over all i, j, k, which yields\nCorollary 2.1.\n\nIf v(i) = \u22121 for i \u2208 S \u2212 , we have, for t, x, z > 0,\n\nP (\u03c40+ \u2264 t, \u2212Y (\u03c40+ \u2212)\u2264 z, 0 <Y (\u03c40+ ) \u2264 x)\n\nFig. 1.\n\nThe additive process Y (t) and its dual \u1ef8 (t).\n\n\f9\n\nHITTING PROBABILITIES IN RISK PROCESS\n\n(2.11)\n=\u03bb\n\nZ\n\n0\n\nz\n\n\u2212\nPN (\u03c4\u0303\u2212w\n\u2264 t, 0 < \u00c3(0) \u2212 w \u2264 x) dw,\n\nwhere v(i) can be an arbitrary positive number for i \u2208 S + .\nRemark 2.2. If S + = \u2205 and E(Y (1)) < 0, then (2.11) with t = \u221e agrees\nwith the well-known formula for the severity in a risk process [see, e.g.,\n\u2212\nAsmussen (2000)], since P (\u03c4\u0303\u2212w\n< \u221e) = 1 and PN (\u00c3(0) \u2264 x) = PN (A(0) \u2264\nx). On the other hand, if x = z = \u221e, it generalizes Proposition 2.3 in Chapter\nIV of Asmussen (2000), which is obtained for the case that N is Poisson.\nLemma 2.1 also generalizes Proposition 3.1 and Theorem 3.1 of Asmussen\n(1991), which assumes that v(i) \u2261 \u22121. We here note another aspect of\nLemma 2.1.\nCorollary 2.2. If there are no jumps, that is, Fij (0) = 1 for all i, j \u2208 S,\nthen we have, for i \u2208 S \u2212 and k \u2208 S + ,\n(2.12) \u2212 v(i)P (M (0) = i, M (\u03c40+ ) = k) = v(k)P (M\u0303 (0) = k, M\u0303 (\u03c4\u03030\u2212 ) = i).\nProof. Since Y (\u03c40+ ) = 0 with probability one, (2.4) with \u03c6 \u2261 1 yields\n\u2212v(i)P (M (0) = i, M (\u03c3 \u2212 (\u03c40+ )\u2212) = j, M (\u03c40+ ) = k)\n=\u03bb\n\n\u221e\n\nZ\n\n0\n\n\u2212\ndw PN (M\u0303 (0) = k, M\u0303 (0+) = j, M\u0303 (\u03c4\u0303\u2212w\n) = i, w < T\u0303 ).\n\nSumming over all possible j and using the fact that T\u0303 = \u2212v(k)\u03c3\u0303 \u2212 (0) and\n\u2212\nM\u0303 (\u03c4\u0303\u2212w\n) \u25e6 \u03b8\u2212w/v(k) = M\u0303 (\u03c4\u03030\u2212 ) on M\u0303 (0) = k, we have\n\u2212v(i)P (M (0) = i, M (\u03c40+ ) = k)\n=\u03bb\n\nZ\n\n\u221e\n\n0\n\n= \u03bbEN\n\n\u2212\n) = i, w < T\u0303 )\ndw PN (M\u0303 (0) = k, M\u0303 (\u03c4\u0303\u2212w\n\n\u0012Z\n\n0\n\nT\u0303\n\n1[M\u0303 (\u2212w/v(k))\n\n= k, M\u0303 (\u03c4\u03030\u2212 ) \u25e6 \u03b8w/v(k)\n\n\u0013\n\n= i] dw .\n\nSince T\u0303 = v(k)\u03c3 + (0), we get (2.12) by the Palm inversion formula. \u0003\nEquation (2.12) explains how upward hitting is interpreted in the dual\nadditive process when there are no jumps. Suppose \u2212\u221e < E(Y (1)) < 0.\nThen (2.12) also yields\na+\n,\na\u2212\nP\nP\nwhere a+ = i\u2208S + v(i)P (M (0) = i) and a\u2212 = \u2212 i\u2208S \u2212 v(i)P (M (0) = i).\nP (\u03c40+ < \u221e) =\n\n\f10\n\nM. MIYAZAWA\n\n3. The Markov additive process. From now on we specialize M (t) to be\na continuous-time Markov chain with finite state space S and assume that\nA(t) only depend on M (t\u2212) and M (t). In this setting (M (t), Y (t)) is called\na Markov additive process. In this section we derive the ascending ladder\nheight distribution in a closed form for this additive process.\nLet Cij for i 6= j and Dij for all i, j \u2208 S be nonnegative numbers and let\nCii = \u2212\n\nX\nj6=i\n\nCij +\n\nX\n\nj\u2208S\n\n!\n\nDij ,\n\ni \u2208 S.\n\nFor convenience, let c(i) = \u2212Cii . Let C = {Cij } and D = {Dij } be S \u00d7 S\nmatrices. We take C + D for the rate matrix of Markov chain M (t) and\nassume that C + D is irreducible. Since S is finite, this implies that the\nMarkov chain has a unique stationary distribution, which is represented as\na row vector \u03c0 \u2261 {\u03c0i }.\nNote that the Markov chain M (t) may include transitions that do not\nchange their states, since Dii may be positive. Of course, these transitions\nare irrelevant for the sample path of M (t), but they are convenient to include\nMarkov modulated Poisson arrivals for the jumps in our formulation. So we\nlet N be the point process generated by all the transition instants. Let FijD\nbe the jump size distribution associated with transitions due to Dij , where\nFijD (0) = 0, while no jumps are associated with transitions due to Cij . Then,\nthe conditional distribution Fij of A(t), given that M (t\u2212) = i and M (t) = j,\nis obtained as\nFij (x) =\n\n\uf8f1 D\n\uf8f2 Fii (x),\n\ni = j,\n\nCij\nDij\n\u03b4(x) +\nF D (x),\n\uf8f3\nCij + Dij\nCij + Dij ij\n\ni 6= j,\n\nfor x \u2265 0, where \u03b4(x) is the Dirac distribution which has a unit mass at the\norigin. In this way the additive process Y (t) is completely specified for the\nrate function v.\nDefine Cij (x) and Dij (x) as\nCij (x) = Cij \u03b4(x),\n\nDij (x) = Dij FijD (x),\n\ni, j \u2208 S.\n\nWe denote the matrices which have these entries by C(x) and D(x), respectively. For convenience, we also define matrix U (x) whose ij-entry is defined\nas\n(3.1)\n\nUij (x) = 1(i 6= j)Cij (x) + Dij (x),\n\ni, j \u2208 S, x \u2265 0.\n\nClearly, the additive process Y (t) is specified by C, D(x) and the rate function v.\n\n\fHITTING PROBABILITIES IN RISK PROCESS\n\n11\n\nWe now evaluate (2.3) and (2.4) in the Markov setting. To this end, we\nfirst consider the dual Markov chain M\u0303 (t) for M (t) and the dual additive\nprocess \u1ef8 (t), defined in Section 2. Define S \u00d7 S matrices:\n\u2032\nC\u0303(x) = \u2206\u22121\n\u03c0 C(x) \u2206\u03c0 ,\n\n\u2032\nD\u0303(x) = \u2206\u22121\n\u03c0 D(x) \u2206\u03c0 ,\n\n\u2032\n\u0168 (x) = \u2206\u22121\n\u03c0 U (x) \u2206\u03c0 ,\n\nwhere \u2206\u03c0 is the diagonal matrix whose ith entry is \u03c0(i) and \" \u2032 \" stands for\ntranspose. Obviously, we see that M\u0303 (t) has transition rate matrix C\u0303 + D\u0303,\nwhere C\u0303 = C\u0303(\u221e) and D\u0303 = D\u0303(\u221e). \u1ef8 (t) and Y (t) have the same rate function\nv for the continuous movements. Thus, \u1ef8 (t) is the Markov additive process,\nspecified by C\u0303(x), D\u0303(x) and v.\nWe next modify Lemma 2.1 in a convenient form for the Markov additive\nprocess. Let F\u0303jk = Fkj . Then, from (2.3) and (2.4), we have, for i \u2208 S \u2212 ,\nj, k \u2208 S and x > 0,\n(3.2)\n\n\u2212v(i)E(M (0) = i, M\u2212 (\u03c40+ ) = (j, k), 0 < Y (\u03c40+ ) \u2264 x)\n=\u03bb\n\nZ\n\nx\n\ndw\n\n0\n\nZ\n\n\u221e\nw\n\n\u2212\nF\u0303kj (dy)PN (M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212(y\u2212w)\n) = i),\n\nand, for i \u2208 S \u2212 , k \u2208 S + ,\n\u2212v(i)E(M (0) = i, M\u2212 (\u03c40+ ) = (j, k), Y (\u03c40+ ) = 0)\n(3.3)\n\n=\u03bb\n\nZ\n\n\u221e\n\ndw\n\n0\n\nZ\n\n\u221e\n\n0\n\n\u2212\nF\u0303kj (dy)PN (M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212w\n) = i,\n\ny < w < T\u0303 + y).\nLemma 3.1.\n\nFor i \u2208 S \u2212 , j, k \u2208 S and x \u2265 0,\n\nP (M\u2212 (\u03c40+ ) = (j, k), 0 < Y (\u03c40+ ) \u2264 x|M (0) = i)\n(3.4)\nZ\nZ \u221e\n\u22121\n\u03c0k x\n\u2212\ndw\nD\u0303kj (dy)PN (M\u0303 (\u03c4\u0303\u2212(y\u2212w)\n) = iM\u0303 (0+) = j)\n=\n\u03c0i 0\nv(i)\nw\nand, for i \u2208 S \u2212 , j \u2208 S and k \u2208 S + ,\nP (M\u2212 (\u03c40+ ) = (j, k), Y (\u03c40+ ) = 0|M (0) = i)\n(3.5)\n\n=\n\n\u03c0k\n\u03c0i\n\nZ\n\n0\n\n\u221e\n\ne\u2212c(k)w/v(k) dw\n\nZ\n\n\u221e\n0\n\n\u0168kj (dy)\n\n\u2212\n\u00d7 PN (M\u0303 (\u03c4\u0303\u2212(w+y)\n) = i|M\u0303 (0+) = j)\n\n\u22121\n.\nv(i)\n\nProof. We only need to evaluate the Palm probabilities in (3.2) and (3.3).\nSince M\u0303 (t) is the Markov chain with rate matrix C\u0303 + D\u0303, it is easy to see\n\n\f12\n\nM. MIYAZAWA\n\nthat\n\u2212\n\u03bbPN (M\u0303 (0) = k, M\u0303 (0+) = j, M\u0303 (\u03c4\u0303\u2212(y\u2212w)\n) = i)\n\n(3.6)\n\n\u2212\n= PN (M\u0303 (\u03c4\u0303\u2212(y\u2212w)\n) = i|M\u0303 (0+) = j)(1(k 6= j)C\u0303kj + D\u0303kj )\u03c0k .\n\nHence, (3.2) and (3.1) yields (3.4). Since T of Lemma 2.1 is exponentially\ndistributed with mean \u2212c(k)/v(k), the right-hand side of (3.3) becomes\n\u03bb\n\nZ\n\n\u221e\n\n0\n\nF\u0303kj (dy)\n\nZ\n\n0\n\n\u221e\n\n= \u03c0k\n\nZ\n\ny+u\n\n\u00d7\n\nZ\n\n\u221e\n\n= \u03c0k\n\nZ\n\n\u2212\ndw PN (M\u0303+ (0) = (k, j), M\u0303 (\u03c4\u0303\u2212w\n) = i, y < w < y + T\u0303 )\n\n\u0168kj (dy)\n\n0\n\ny\n\n0\n\n\u221e\n\nZ\n\n\u221e\n\ne\u2212c(k)u/v(k)\n\n0\n\n\u2212c(k)\ndu\nv(k)\n\n\u2212\ndw PN (M\u0303 (\u03c4\u0303\u2212w\n) = i|M\u0303 (0+) = j)\n\n\u0168kj (dy)\n\nZ\n\n\u221e\n\ndw\ny\n\nZ\n\n\u221e\n\ne\u2212c(k)u/v(k)\n\nw\u2212y\n\n\u2212c(k)\ndu\nv(k)\n\n\u2212\n) = i|M\u0303 (0+) = j)\n\u00d7 PN (M\u0303 (\u03c4\u0303\u2212w\nZ \u221e\nZ \u221e\n= \u03c0k\n\u0168kj (dy)\ne\u2212c(k)(w\u2212y)/v(k) dw\n0\ny\n\u2212\n\u00d7 PN (M\u0303 (\u03c4\u0303\u2212w\n) = i|M\u0303 (0+) = j).\n\nHence, (3.3) yields (3.5). \u0003\nIn (3.4) and (3.5), it remains to evaluate\n(3.7)\n\n\u2212\nR\u0303ij (x) \u2261 P (M\u0303 (\u03c4\u0303\u2212x\n) = j|M\u0303 (0) = i),\n\nx \u2265 0, i \u2208 S, j \u2208 S \u2212 .\n\nBy R\u0303\u2212\u2212 (x) and R\u0303+\u2212 (x), we denote the S \u2212 \u00d7S \u2212 and S + \u00d7S \u2212 matrices whose\nij entry is given by (3.7), respectively. We shall use this convention widely.\nNamely, for S \u00d7 S matrix A, its submatrices of sizes S \u2212 \u00d7 S \u2212 , S \u2212 \u00d7 S + , S + \u00d7\nS \u2212 and S + \u00d7 S + are denoted by A\u2212\u2212 , A\u2212+ , A+\u2212 and A++ , respectively.\nSimilarly,\nfor\nan\nS-vector x, x\u2212 and x+ are the subvectors whose entries are indexed by\nS \u2212 and S + , respectively. Note that R\u0303\u2212\u2212 (x) is substochastic, that is, a nonnegative matrix satisfying R\u0303\u2212\u2212 (x)e\u2212 \u2264 e\u2212 , where e is the column vector\nwhose entries are all 1.\nWe now refer to recent results on the matrix exponential form in the\nMarkov additive process in Miyazawa and Takada (2002) and Takada (2001).\nThe results there are obtained for the forward process {(Y (t), M (t))} that\nis right-continuous. On the other hand, we here need the corresponding results for the dual process {(\u1ef8 (t), M\u0303 (t))} that is left-continuous. However,\n\n\f13\n\nHITTING PROBABILITIES IN RISK PROCESS\n\nthis left-continuity is irrelevant in the definition (3.7), since \u1ef8 (t) is skip free\nin the downward direction.\nThis skip free property also implies that the ladder height indexed pro(\u2212)\n\u2212\nfor some subrate\ncess {M\u0303 (\u03c4\u0303\u2212x\n); x \u2265 0} is Markov. Hence, R\u0303\u2212\u2212 (x) = exQ\u0303\nmatrix Q\u0303(\u2212) , that is, Q\u0303(\u2212) e\u2212 \u2264 0\u2212 . It is also easy to see, at least intuitively,\nthat\n\u0013\n\u0012 \u2212\u2212\n\u0013\n\u0012\nZ \u221e\nd R\u0303\u2212\u2212 (x)\nR\u0303 (u + x)\n\u22121\n\u2212\n.\n(C\u0303(du) + D\u0303(du))\n= \u2206v\nR\u0303+\u2212 (u + x)\ndx R\u0303+\u2212 (x)\n0\n\nThen, the following results would be intuitively reasonable. Their formal\nproofs not for \u1ef8 (t), but for the forward process Y (t) are given in Theorem 3.2\nof Miyazawa and Takada (2002) and Theorem 4.1 of Takada (2001). Clearly,\nthe results are immediately transferred from Y (t) to \u1ef8 (t). In what follows,\na square matrix is said to be ML if its off-diagonal entries are nonnegative.\nLemma 3.2. There exist a subrate matrix Q\u0303(\u2212) and a substochastic matrix R\u0303+\u2212 , such that\n\u0012\n\n(3.8)\n\nR\u0303\u2212\u2212 (x)\nR\u0303+\u2212 (x)\n\n\u0013\n\n=\n\n\u0012\n\n(\u2212)\nI \u2212\u2212\nexQ\u0303 ,\nR\u0303+\u2212\n\n\u0013\n\nx \u2265 0,\n\nwhere Q\u0303(\u2212) and R\u0303+\u2212 are the minimal ML and nonnegative solutions, respectively, of the following equation:\n(3.9)\n\n\u2212\n\n\u0012\n\nI \u2212\u2212\nQ\u0303(\u2212) = \u2206\u22121\nv\nR\u0303+\u2212\n\u0013\n\nZ\n\n\u221e\n\n0\n\n(\u2212)\nI \u2212\u2212\n(C\u0303(du) + D\u0303(du))\neuQ\u0303 .\n+\u2212\nR\u0303\n\n\u0012\n\n\u0013\n\nFurthermore, Q\u0303(\u2212) is a rate matrix, if and only if\nE(Y (1))(= E(\u1ef8 (1))) = \u03c0\u2206v e + \u03c0\n\n(3.10)\n\nZ\n\n\u221e\n\nxD(dx)e \u2264 0.\n0\n\nWe next represent Q\u0303(\u2212) and R\u0303+\u2212 using the original additive process. Let\nand L\u2212+ be the minimal solutions of the following equation, such that\n(\u2212)\nK\nand L\u2212+ are ML and nonnegative matrices, respectively:\nK (\u2212)\n\n(3.11) \u2212 K\n\n(\u2212)\n\n(I\n\n\u2212\u2212\n\n,L\n\n\u2212+\n\n)=\n\nZ\n\n\u221e\n\neuK\n\n(\u2212)\n\n(I \u2212\u2212 , L\u2212+ )(C(du) + D(du))\u2206\u22121\nv .\n\n0\n\nThen\n\nQ\u0303(\u2212)\n\n(3.12) Q\u0303\n\nand\n\n(\u2212)\n\nR\u0303+\u2212\n\nCorollary 3.1.\n(3.13)\n\nare obtained as\n\n\u22121\n(\u2212) \u2032 \u2212\u2212\n= (\u2206\u2212\u2212\n) \u2206\u03c0 ,\n\u03c0 ) (K\n\n\u22121\n\u2212+ \u2032 \u2212\u2212\nR\u0303+\u2212 = (\u2206++\n) \u2206\u03c0 .\n\u03c0 ) (L\n\nIf (3.10) is satisfied, then\n\u03c0 \u2212 K (\u2212) = 0,\n\n\u03c0 \u2212 L\u2212+ = \u03c0 + ,\n\nand K (\u2212) has the right eigenvector k\u2212 corresponding to \u03c0 \u2212 . Normalize k\u2212\nin such a way that \u03c0 \u2212 k\u2212 = 1. Then, k\u2212 is unique and positive and k\u2212 \u03c0 \u2212 \u2212\nK (\u2212) is nonsingular.\n\n\f14\n\nM. MIYAZAWA\n\nProof. Since Q\u0303(\u2212) e\u2212 = 0\u2212 and R\u0303+\u2212 e\u2212 = e+ by (3.10), (3.12) impl(\u2212) , since (k\u2212 )\u2032 \u2206\u2212\u2212 e =\nies (3.13). (k\u2212 )\u2032 \u2206\u2212\u2212\n\u03c0 is the stationary distribution of Q\u0303\n\u03c0\n\u2212\n\u2212\n\u2212\n\u03c0 k = 1. Hence, k is unique and positive. Assume that\n(k\u2212 \u03c0 \u2212 \u2212 K (\u2212) )x = 0,\n\n(3.14)\n\nfor an S \u2212 -dimensional vector x. Pre-multiplying K (\u2212) to (3.14), we get\nK (\u2212) (K (\u2212) x) = 0. Hence, K (\u2212) x must be ak\u2212 for some constant a. Since\n\u03c0 \u2212 K (\u2212) = 0 and \u03c0 \u2212 k\u2212 = 1, we arrive at a = 0, which concludes x = 0. So\nthe matrix k\u2212 \u03c0 \u2212 \u2212 K (\u2212) is nonsingular. \u0003\nWe remark that similar eigenvectors have been reported for the case that\nS + = \u2205 in Section 2 of Chapter VI in Asmussen (2000). Let us compute\nthe ascending ladder height distribution. For this computation we need one\nmore lemma.\nLemma 3.3. Let \u2206c be the diagonal matrix whose jth diagonal entry is\nc(j) = \u2212Cjj , then, for j \u2208 S + and i \u2208 S \u2212 ,\nZ\n\n(3.15)\n\n\u221e\n\nwc(j)/v(j)\n\ne\n\ndw\n\n0\n\n\u0014Z\n\n\u221e\n\n0\n\n(\u2212)\nI \u2212\u2212\n\u0168 (dy)\ne(y+w)Q\u0303\n+\u2212\nR\u0303\n\n\u0012\n\n\u0013\n\n\u0015\n\nji\n\n+\u2212\n= [\u2206++\n]ji .\nv R\u0303\n\nProof. By (3.9), the left-hand side of (3.15) is\nZ\n\n\u221e\n\nwc(j)/v(j)\n\ne\n\ndw\n\n0\n\n=\u2212\n\nZ\n\n\u221e\n\n\u0014Z\n\n\u221e\n0\n\n(\u2212)\nI \u2212\u2212\n(C\u0303(dy) + D\u0303(dy) \u2212 \u03b4(dy)(\u2212\u2206c ))\ne(y+w)Q\u0303\nR\u0303+\u2212\n\n\u0012\n\newc(j)/v(j) dw\n\n0\n\n\u0014\u0012\n\n\u2206v\n\n\u0012\n\nI \u2212\u2212\nR\u0303+\u2212\n\n\u0013\n\nQ\u0303(\u2212) + (\u2212\u2206c )\n\n\u0013\n\n\u0012\n\nI \u2212\u2212\nR\u0303+\u2212\n\n\u0013\u0013\n\newQ\u0303\n\n+\u2212\n= [\u2206++\n]ji .\nv R\u0303\n\nTheorem 3.1.\n\n(\u2212)\n\n\u0015\n\n\u0015\n\nji\n\nji\n\n\u0003\n\nFor i \u2208 S \u2212 , j \u2208 S and x \u2265 0,\n\nP (M (\u03c40+ ) = j, Y (\u03c40+ ) \u2264 x|M (0) = i)\n(3.16)\n\n1\n=\n\u2212v(i)\n\n\u0012Z\n\nx\n\ndw\n\n0\n\n\u0014Z\n\n\u221e\n\n(y\u2212w)K (\u2212)\n\ne\n\n(I\n\n\u2212\u2212\n\nw\n\n,L\n\n\u2212+\n\n\u0015\n\n)D(dy)\n\nij\n\n\u0013\n\n+ 1(j \u2208 S + )L\u2212+\nij v(j) .\nProof. Let Jij (x) = P (M (\u03c40+ ) = j, Y (\u03c40+ ) \u2264 x|M (0) = i). We first consider the case that Y (\u03c40+ ) = 0. From (3.5) and Lemma 3.3, we have\nJij (0) =\n\n\u03c0j\n+\u2212 \u22121\n.\nv(j)R\u0303ji\n\u03c0i\nv(i)\n\n\f15\n\nHITTING PROBABILITIES IN RISK PROCESS\n\n+\u2212\nUsing \u03c0j R\u0303ji\n= \u03c0i L\u2212+\nij , this yields (3.16) for x = 0. We next consider the\n+\ncase that Y (\u03c40 ) > 0. From Lemmas 3.1 and 3.2, we have\n\nJij (x) \u2212 Jij (0) =\n\n\u03c0j\n\u03c0i\n\nZ\n\nx\n\ndw\n\n0\n\n\u0014Z\n\n\u221e\n\nD\u0303(dy)\n\nw\n\n\u0012\n\n(\u2212)\nI \u2212\u2212\ne(y\u2212w)Q\u0303\nR\u0303+\u2212\n\n\u0013\n\n\u0015\n\n\u22121\n.\nv(i)\nji\n\nThus, we get (3.16) by converting to the notation of the forward processes.\n\u0003\n4. The hitting probability. We now consider the hitting probability at\nan upper level x > 0. Since (X(t), Y (t)) is a Markov additive process with a\nreal additive component, we can obtain the hitting probabilities as a Markov\nrenewal function using the appropriate ladder height distribution as a semiMarkov kernel. However, we can not use (3.16) of Theorem 3.1 as this kernel\nbecause the additive component may increase continuously. To have an appropriate kernel, we consider the ladder height at \u03c3 + (\u03c40+ ), that is, the first\ntransition instant of M (t) after crossing level 0. For convenience, define a\nrandom variable \u03bex+ for x \u2265 0 as\n\u03bex+ = \u03c3 + (\u03c4x+ ).\nClearly, \u03bex+ is a stopping time with respect to the additive process {(Y (t), M (t))}.\nDefine S \u00d7 S matrices H(x) and G(x) by\nHij (x) = P (M (\u03be0+ ) = j, Y (\u03be0+ ) \u2264 x|M (0) = i),\nGij (x) = P (M (\u03c40+ ) = j, Y (\u03be0+ ) \u2265 x|M (0) = i),\n\ni, j \u2208 S, x \u2265 0.\n\nDefine the hitting probability matrix \u03a8(x) by\n\u03a8ij (x) = P (M (\u03c4x+ ) = j|M (0) = i).\nThen, \u03a8(x) is obtained as the unique solution of the Markov renewal equation,\n(4.1)\n\n\u03a8(x) = G(x) + H \u2217 \u03a8(x),\n\nx \u2265 0,\n\nwhere the convolution A \u2217 B(x) is defined for a matrix nondecreasing function A(x) and a matrix function B(x) as\n[A \u2217 B(x)]ij =\n\nXZ\nk\n\n0\n\n\u221e\n\nAik (dy)Bkj (x \u2212 y).\n\nThe Markov renewal equation (4.1) will be the key for our arguments to\nobtain an asymptotic behavior of the hitting probability. Thus, what we all\nneed is to get H(x) and G(x). We first consider the case that Y (\u03c40+ ) = 0.\n\n\f16\n\nM. MIYAZAWA\n\nFor i \u2208 S \u2212 , j \u2208 S and x \u2265 0,\n\nLemma 4.1.\n(4.2)\n\nP (M (\u03c3 + (\u03c40+ )) = j, Y (\u03c40+ ) = 0, Y (\u03c3 + (\u03c40+ )) \u2264 x|M (0) = i)\n=\n\nZ\nv(k) +\u2212 \u22121\n\u03c0j X x\nR\u0303\n.\n\u0168jk (dy)(1 \u2212 e\u2212c(k)(x\u2212y)/v(k) )\n\u03c0i\nc(k) ki v(i)\n+ 0\nk\u2208S\n\nProof. We need the following version of (3.3), for i \u2208 S \u2212 , j, l \u2208 S and\nk \u2208 S+:\n\u2212v(i)P (M (0) = i, M\u2212 (\u03c40+ ) = (l, k), M (\u03c3 + (\u03c40+ )) = j,\nY (\u03c40+ ) = 0, Y (\u03c3 + (\u03c40+ )) \u2264 x)\n\n(4.3)\n=\u03bb\n\nZ\n\n\u221e\n\nZ\n\ndw\n\n\u221e\n\n0\n\n0\n\nF\u0303jk (dy)PN (M\u0303 (\u03c3\u0303 \u2212 (0)) = j,\n\u2212\nM\u0303+ (0) = (k, l), M\u0303 (\u03c4\u0303\u2212w\n) = i,\n\ny < w < T\u0303 + y, T\u0303 + T\u0303 \u2032 + y \u2264 x + w),\nwhere T\u0303 \u2032 = \u2212\u1ef8 (\u03c3 \u2212 (0)) + \u1ef8 (\u03c3 \u2212 (0)+). Since this can be proved in exactly\nthe same way as (3.3), we omit its proof. Thus, the right-hand side of (4.3)\ndivided by \u2212v(i) becomes\nZ \u221e\nZ \u221e\nZ \u221e\nZ \u221e\nc(k) \u2212c(k)u/v(k)\n\u03bb\ndw\nF\u0303jk (dz)\ne\ndu\nF\u0303kl (dy)\n\u2212\nv(i) 0\n0\n0 v(k)\n0\n\u2212\n) = i,\n\u00d7 PN (M\u0303 (\u03c3\u0303 \u2212 (0)) = j, M\u0303+ (0) = (k, l), M\u0303 (\u03c4\u0303\u2212w\n\ny \u2264 w < u + y, u + y + z \u2264 x + w)\n(changing variable w to w \u2212 y)\n=\u2212\n\n\u03bb\nv(i)\n\nZ\n\n\u221e\n\ndw\n\n0\n\nZ\n\n\u221e\n\nF\u0303kl (dy)\n\n0\n\nZ\n\n\u221e\n0\n\nc(k) \u2212c(k)u/v(k)\ne\ndu\nv(k)\n\nZ\n\n\u221e\n\nF\u0303jk (dz)\n\n0\n\n\u2212\n\u00d7 PN (M\u0303 (\u03c3\u0303 \u2212 (0)) = j, M\u0303+ (0) = (k, l), M\u0303 (\u03c4\u0303\u2212(y+w)\n) = i,\n\n0 \u2264 w < u, u + z \u2264 x + w)\n=\u2212\n\n\u03bb\nv(i)\n\nZ\n\n0\n\n\u221e\n\ndw\n\nZ\n\n\u221e\n0\n\nF\u0303kl (dy)\n\nZ\n\nx+w\nw\n\nc(k) \u2212c(k)u/v(k)\ne\ndu\nv(k)\n\nZ\n\nx+w\u2212u\n\n0\n\nF\u0303jk (dz)\n\n\u2212\n\u00d7 PN (M\u0303 (\u03c3\u0303 \u2212 (0)) = j, M\u0303+ (0) = (k, l), M\u0303 (\u03c4\u0303\u2212(y+w)\n) = i),\n\nwhere we have used the following fact. Conditionally, given that (\u03c3\u0303 \u2212 (0)) = j,\n\u2212\nM\u0303 (0) = k, M\u0303 (0+) = l, M\u0303 (\u03c4\u0303\u2212w\n) = i,\n\u2212\u1ef8 (0) \u2243 F\u0303kl ,\nT\u0303 = \u2212\u1ef8 (\u03c3\u0303 \u2212 (0)+) + \u1ef8 (0) \u2243 Exp(c(k)/v(k)),\nT\u0303 \u2032 = \u2212\u1ef8 (\u03c3\u0303 \u2212 (0)) + \u1ef8 (\u03c3\u0303 \u2212 (0)+) \u2243 F\u0303jk ,\n\n\f17\n\nHITTING PROBABILITIES IN RISK PROCESS\n\nwhere \u2243 stands for equality in distribution and Exp(a) denotes the exponential distribution with mean 1/a. Hence, using a decomposition similarly\nto (3.6) and Lemma 3.2, the left-hand side of (4.2) is computed as\n\u03c0j\n\u03c0i\n\nZ\n\n0\n\n\u221e \u0012Z \u221e\n\ndw\n\n0\n\nZ\n\nx+w\n\nZ\n\ndu\n\nx+w\u2212u\n\n0\n\nw\n\n(1(j 6= k)C\u0303jk + D\u0303jk )F\u0303jk (dz)\nc(k) \u2212c(k)u/v(k)\n\u00d7\ne\nv(k)\n\n1(k 6= l)C\u0303kl + D\u0303kl\n\n\u00d7\n=\n\nc(k)\n\n\u03c0j\n\u03c0i\n\nZ\n\n0\n\n\u221e\n\n\u221e \u0012Z\n\ne\u2212c(k)w/v(k) dw\n\nZ\n\nx\u2212u\n\n0\n\n\u00d7\n\n\u0014\u0012\n\n\u03c0j\n\u03c0i\n\nZ\n\n0\n\nF\u0303kl (dy)\n\n0\n\n\u00d7\n\n=\n\n\u0014\u0012\n\n\u0013\n\ndu\n0\n\n\u0013\n\n(\u2212)\nI \u2212\u2212\ne(y+w)Q\u0303\nR\u0303+\u2212\n\n\u22121\nv(i)\nli\n\n\u0015\n\ne\u2212c(k)w/v(k) dw\n\n0\n\nZ\n\nx\n0\n\n\u0168jk (dz)\n\n\u00d7 (1 \u2212 e\n\u00d7\n\n\u22121\nli v(i)\n\nx\n\n\u2212c(k)(x\u2212z)/v(k)\n\n\u0014\u0012\n\n\u0015\n\nc(k) \u2212c(k)u/v(k) 1\n\u0168jk (dz)\ne\n\u0168kl (dy)\nv(k)\nc(k)\n\n\u0013\n\n\u221e \u0012Z \u221e\n\nZ\n\n(\u2212)\nI \u2212\u2212\ne(y+w)Q\u0303\nR\u0303+\u2212\n\n\u0013\n\n(\u2212)\nI \u2212\u2212\ne(y+w)Q\u0303\n+\u2212\nR\u0303\n\n\u0013\n\n\u0013\n\n)\n\n\u22121\n\u0168kl (dy)\n\u2212c(k)\n\n\u22121\n.\nli v(i)\n\n\u0015\n\nSumming this over all l \u2208 S and k \u2208 S + and applying Lemma 3.3 yield (4.2).\n\u0003\nTheorem 4.1.\n\nFor i, j \u2208 S and x \u2265 0, Hij (x) is given by\n\n1\nHij (x) =\n\u2212v(i)\n\nZ\n\nx\n\n0\n\n+\n\ndw\n\n\u0014Z\n\nHij (x) =\n\nZ\n\n0\n\nx\n\n(y\u2212w)K (\u2212)\n\ne\n\n(I\n\n\u2212\u2212\n\n,L\n\n\u2212+\n\n\u0015\n\n)D(dy)\n\nw\n\nX Z\n\nk\u2208S +\n\n(4.4)\n\n\u221e\n\n0\n\nx\n\nij\n\n!\n\n\u2212c(k)(x\u2212y)/v(k) v(k)\n)\nL\u2212+\nUkj (dy)\nik (1 \u2212 e\n\n(1 \u2212 e\u2212c(i)(x\u2212y)/v(i) )\n\nc(k)\n\n,\n\ni \u2208 S\u2212\n1\nUij (dy),\nc(i)\n\ni \u2208 S+.\n\n\f18\n\nM. MIYAZAWA\n\nProof. We first consider the case that i \u2208 S \u2212 . From Lemma 4.1, we get\nHij (0) of (4.4). On the other hand, from Theorem 3.1,\nP (M (\u03c40+ ) = j, 0 < Y (\u03c40+ ) \u2264 x|M (0) = i)\n1\n=\n\u2212v(i)\n\nZ\n\nx\n\ndw\n\n0\n\n\u0014Z\n\n\u221e\n\n(y\u2212w)K (\u2212)\n\ne\n\n(I\n\n\u2212\u2212\n\n,L\n\n\u2212+\n\n\u0015\n\n.\n\n)D(dy)\n\nw\n\nij\n\nThus, we get (4.4) converting to the notation of the forward processes. For i \u2208\nS + , (4.4) is immediate, since \u03be0+ is the first transition instant after time 0 in\nthis\ncase.\n\u0003\nFor G, we can get the following expression similarly to Theorem 4.1, using\nthe fact that the first hitting over level x is attained either continuously or\nby a jump.\nFor i \u2208 S + , j \u2208 S,\n\nCorollary 4.1.\n(4.5)\n\nGij (x) = 1(i = j)e\u2212xc(i)/v(i)\n+\n\nZ\n\n0\n\nx\n\nc(i) \u2212c(i)y/v(i)\ne\ndy\nv(i)\n\n\u221e\n\nZ\n\nx\u2212y\n\n1\nUij (dw),\nc(i)\n\nx \u2265 0,\n\nand, for i \u2208 S \u2212 , j \u2208 S,\n\u0014Z \u221e\n\u0014Z \u221e\n\u0015\n\u22121\n(\u2212)\nGij (x) =\ndw\ne(y\u2212w)K (I \u2212\u2212 , L\u2212+ )D(dy)\nv(i) x\nw\nij\nxCjj /v(j)\n+ L\u2212+\nij v(j)e\n\n(4.6)\n+\n\nX\n\nk\u2208S +\n\nL\u2212+\nik\n\nv(k)\nc(k)\n\nZ\n\n0\n\nxZ \u221e\n\nx\u2212y\n\nUkj (dw)\n\nc(k) \u2212yc(k)/v(k)\ne\ndy ,\nv(k)\n\u0015\n\nx \u2265 0.\n5. Asymptotic behavior of the hitting probability. In this section, we\nstudy the asymptotic behavior of the hitting probabilities as the hitting\nlevel goes to infinity. Throughout this section we assume a negative drift,\nthat is,\n(5.1)\n\nE(Y (1)) = \u03c0\u2206v e + \u03c0\n\nZ\n\n\u221e\n\nD(du)e < 0.\n\n0\n\nUnder this condition, Y (t) \u2192 \u2212\u221e as time t \u2192 \u221e. Hence, the hitting probability P (\u03c4x+ < \u221e|M (0) = i) converges to zero as x \u2192 \u221e. Assume that the\njump size distributions have light tails. Then, it is expected that the hitting probability decays exponentially fast, which is known as the Cram\u00e9r\u2013\nLundberg approximation for the conventional risk model. Furthermore, a\n\n\fHITTING PROBABILITIES IN RISK PROCESS\n\n19\n\nBrownian component may be added [see Schmidli (1995)]. Instead of a Brownian component, we here have signed continuous movements.\nThe decay rates for the hitting probabilities have been extensively studied by the change of measure technique based on martingales [see, e.g.,\nAsmussen (2000) and Rolski, Schmidli, Schmidt and Teugels (1999)], but\nthis approach has not yet fully covered the Markov modulated model even\nfor the case that v(i) \u2261 \u22121 [see Section VI of Asmussen (2000)]. Here we use\nthe Markov renewal theorem as in Miyazawa (2002), which considers the\ncase that v(i) \u2261 \u22121. This approach also uses a change of measure, but it is\nmore straightforward.\nLet us briefly introduce this Markov renewal approach, following Section 2\nof Miyazawa (2002). Let S \u00d7 S matrix P (x) = {Pij (x)} be a Markov renewal\nkernel that may be defective, that is, P (x)e \u2264 e. Denote the moment generR\nating function of P (x) by P\u0302 (\u03b8) \u2261 0\u221e e\u03b8x P (dx). Since P\u0302 (\u03b8) is a nonnegative\nand substochastic matrix, it has a positive eigenvalue \u03b3(\u03b8), such that the\nabsolute values of all other eigenvalues are less than \u03b3(\u03b8) and the associated\nright and left eigenvectors are nonnegative [see, e.g., Seneta (1980)]. Denote\nthese associated eigenvectors by \u03bd (\u03b8) and h(\u03b8) , respectively. Suppose that an\nS \u00d7 S matrix functions \u03a6(x) and B(x) for x \u2265 0 satisfies the Markov renewal\nequation,\n(5.2)\n\n\u03a6(x) = B(x) + P \u2217 \u03a6(x),\n\nx \u2265 0.\n\nThen, Theorem 2.6 of Chapter X in Asmussen (1987) [see Miyazawa (2002)\nfor the present context] reads as\nLemma 5.1. Suppose the following four conditions: (5.a) P (x) has a\nsingle irreducible recurrent class that can be reached from any state in S with\nprobability one, and the return time to each state in the irreducible recurrent\nclass has a nonarithmetic distribution, (5.b) there exists a positive \u03b1 such\nthat \u03b3(\u03b1) = 1, (5.c) each entry of e\u03b1x B(x) is directly Riemann integrable,\n(5.d) \u03bd (\u03b1) P\u0302(1) (\u03b1)h(\u03b1) is finite. Then, we have\n(5.3)\n\n1\n\n\u03b1x\n\nlim e \u03a6(x) =\n\nx\u2192\u221e\n\nwhere P\u0302(1) (\u03b1) =\n\n\u03bd (\u03b1) P\u0302(1) (\u03b1)h(\u03b1)\n\nh\n\n(\u03b1) (\u03b1)\n\n\u03bd\n\nZ\n\n\u221e\n\ne\u03b1u B(u) du,\n\n0\n\nd\nd\u03b8 P\u0302 (\u03b8)|\u03b8=\u03b1 .\n\nLet us put P (x) = H(x), \u03a6(x) = \u03a8(x) and B(x) = G(x). Then, (5.2) holds\nby (4.1). Clearly, condition (5.a) is satisfied by the irreducibility of C + D\nand the exponential sojourn times of M (t). We next compute the moment\ngenerating function \u0124(\u03b8) of H(x). From Theorem 4.1, the following results\nare obtained.\n\n\f20\n\nM. MIYAZAWA\n\nLemma 5.2.\n\u0124(\u03b8) = I \u2212 \u2206\u22121\nv T (\u03b8)(C + D\u0302(\u03b8) + \u03b8\u2206v ),\n\n(5.4)\nwhere\n\n(\u03b8I \u2212\u2212 \u2212 K (\u2212) )\u22121\nT (\u03b8) =\n0+\u2212\n\u0014\n\nRemark 5.1.\n\n++ \u22121\n(\u03b8I \u2212\u2212 \u2212 K (\u2212) )\u22121 L\u2212+ + L\u2212+ \u2206++\nv (\u2206c\u2212\u03b8v )\n.\n++ \u22121\n\u2212\u2206++\nv (\u2206c\u2212\u03b8v )\n\n\u0015\n\nSince T (\u03b8) is invertible as we will see, (5.4) can be written\n\nas\n(5.5)\n\nC + D\u0302(\u03b8) + \u03b8\u2206v = T (\u03b8)\u22121 \u2206v (I \u2212 \u0124(\u03b8)).\n\nThis can be considered as a generator version of the Wiener\u2013Hopf factorization [see, e.g., Arjas and Speed (1973)].\nSince this lemma is just computations, we defer its proof to Appendix A.\nWe notice that \u0124(\u03b8) exists only for \u03b8 < min{c(i)/v(i); i \u2208 S + }. We shall use\nthe following light tail assumption on D(x) and related regularity assumption:\n(i) D(\u03b8) is finite for some \u03b8 > 0,\n\u2032 (\u03b8) < \u221e; i, j \u2208 S, \u03b8 > 0} = \u221e.\n(ii) sup{Dij\nCondition (ii) can be relaxed, but it is sufficient for most applications.\nNote that condition (5.1) implies that Q\u0303(\u2212) is a rate matrix. Since C +\nD\u0302(\u03b8) + \u03b8\u2206v is an ML matrix for each \u03b8 > 0, it has a real eigenvalue \u03ba(\u03b8) such\nthat it dominates the real parts of all other eigenvalues, and the associated\nleft and right eigenvectors are positive. Denote these eigenvectors by \u03bc(\u03b8)\nand h(\u03b8) , respectively. Let k\u2212 be the right eigenvector of K (\u2212) for eigenvalue\n0, where k\u2212 is unique and positive (see Corollary 3.1). We normalize \u03bc(\u03b8)\nand h(\u03b8) so that\n(\u03bc(\u03b8) )\u2212 k\u2212 = 1,\n\n\u03bc(\u03b8) h(\u03b8) = 1.\n\nSince \u03ba(\u03b8) = \u03bc(\u03b8) (\u03b8\u2206v + C + D\u0302(\u03b8))h(\u03b8) , we have\n\u03ba\u2032 (\u03b8) = \u03ba(\u03b8)((\u03bc(\u03b8) )\u2032 h(\u03b8) + \u03bc(\u03b8) (h(\u03b8) )\u2032 ) + \u03bc(\u03b8) (\u2206v + D\u0302 \u2032 (\u03b8))h(\u03b8)\n= \u03bc(\u03b8) (\u2206v + D\u0302 \u2032 (\u03b8))h(\u03b8) ,\nwhere we have used the fact that \u03bc(\u03b8) h(\u03b8) = 1. This implies that \u03ba\u2032 (0) =\nE(Y (1)) < 0 because \u03bc(0) = \u03c0. Hence, from the fact that \u03ba(0) = 0 and \u03ba(\u03b8)\nis a convex function [see Kingman (1961)], condition (ii) guarantees that\n\u03ba(\u03b8) = 0 has a unique positive solution. Thus, condition (5.b) is satisfied.\nDenote this solution by \u03b1.\n\n\f21\n\nHITTING PROBABILITIES IN RISK PROCESS\n\nTo find \u03bd (\u03b1) for Lemma 5.1, we compute the inverse matrix of T (\u03b1):\n\u22121\n\nT (\u03b1)\n\n++ \u22121 + (\u03b1I \u2212\u2212\u2212 K (\u2212) )L\u2212+\nL\u2212+ \u2206++\nc\u2212\u03b1v (\u2206v )\n.\n++ \u22121\n\u2212\u2206++\nc\u2212\u03b1v (\u2206v )\n\n\u03b1I \u2212\u2212 \u2212 K (\u2212)\n=\n0+\u2212\n\u0014\n\n\u0015\n\nDefine \u03bd (\u03b1) as\n\u03bd (\u03b1) = \u2212\u03bc(\u03b1) T (\u03b8)\u22121 \u2206v .\n\n(5.6)\n\nClearly, \u03bd (\u03b1) is the left invariant vector of \u0124(\u03b1). We show that \u03bd (\u03b1) is\npositive. To this end, we introduce a twisted Markov transition kernel for\nH. Define\nH\n\n\u2020\n\n(x) = \u2206\u22121\nh(\u03b1)\n\nZ\n\n0\n\nx\n\ne\u03b1u H(du)\u2206h(\u03b1) ,\n\nx \u2265 0.\n\nThen, by our choice of h(\u03b1) , H \u2020 (\u221e)e = e, that is, H \u2020 (\u221e) is a stochastic\nkernel. From (5.4), we have\n\u03bd (\u03b1) \u2206h(\u03b1) H \u2020 (\u221e) = \u03bd (\u03b1) \u0124(\u03b1)\u2206h(\u03b1)\n= \u03bd (\u03b1) \u2206h(\u03b1) + \u03bc(\u03b1) (\u03b1\u2206v + C + D\u0302(\u03b1)) = \u03bd (\u03b1) \u2206h(\u03b1) .\nHence, \u03bd (\u03b1) \u2206h(\u03b1) is the left invariant vector of stochastic kernel H \u2020 (\u221e).\n\u22121 \u2212\nFrom (5.6) and the normalization of \u03bc(\u03b1) , it follows that (\u03bd (\u03b1) )\u2212 (\u2212\u2206\u2212\u2212\nv ) k =\n\u2212\n(\u03b1)\n\u03b1, and k is positive by Corollary 3.1. So, \u03bd\nmust be nonnegative and\n\u03bd (\u03b1) \u2206h(\u03b1) is also nonnegative. Since H \u2020 (\u221e) is a finite stochastic matrix and\nirreducible, which follows from the irreducibility of C + D, \u03bd (\u03b1) \u2206h(\u03b1) must\nbe a positive vector and unique up to a multiplicative constant. Hence, \u03bd (\u03b1)\nis a positive vector.\nIt is easy to see that h(\u03b1) is the right positive eigenvector of \u0124(\u03b1) for the\neigenvalue 1. Thus, we are now in a position to apply Lemma 5.1, for P = H\nand B = G. We first compute the following integrals. For i \u2208 S + , (4.5) yields\nZ\n\n\u221e\n0\n\ne\u03b1x Gij (x) dx\n= \u03b4ij\n\n(5.7)\n+\n=\n\nZ\n\n\u221e\n\ne\u03b1x e\u2212c(i)/(v(i))x dx\n\n0\n\n1\nv(i)\n\nZ\n\n\u221e\n\ne\u03b1x dx\n\n0\n\n0\n\n\u221e\n\n0\n\nx\n\ne\u2212c(i)/(v(i))y dy\n\nZ\n\n\u221e\nx\u2212y\n\nUij (du)\n\n1 \u22121\n[\u2206\n(C + D\u0302(\u03b1) + \u03b1\u2206v \u2212 (C + D))]ij .\n\u03b1 c\u2212\u03b1v\n\nSimilarly, for i \u2208 S \u2212 , we have\nZ\n\nZ\n\ne\u03b1x Gij (x) dx\n\n\f22\n\nM. MIYAZAWA\n\n=\n\n\u22121\n(\u03b1I \u2212\u2212 \u2212 K (\u2212) )\u22121 (I \u2212\u2212 , L\u2212+ )(C + D\u0302(\u03b1) + \u03b1\u2206v )\n\u03b1v(i)\n\u0014\n\n+ (0\u2212\u2212 , L\u2212+ )\u2206v \u2206\u22121\nc\u2212\u03b1v (C + D\u0302(\u03b1) + \u03b1\u2206v \u2212 (C + D))\n\n(5.8)\n\n\u2212\n\n\u2212\n\n\u2212 k \u03c0 (I\n\n\u2212\u2212\n\n,L\n\n\u2212+\n\n\u2212\n\n\u0012\n\n) \u2206v +\n\nZ\n\n\u221e\n\n\u0013\n\nyD(dy)\n\n0\n\n\u2212\n\n\u2212 (k \u03c0 \u2212 K\n\n(\u2212) \u22121\n\n)\n\n(I\n\n\u2212\u2212\n\n,L\n\n\u2212+\n\n\u0015\n\n.\n\n)(C + D)\n\nij\n\nSee Section A.2 for the detailed derivation of this formula. Thus, condition\n(5.c) is satisfied. Then, applying Lemma 5.1, we have the following asymptotics.\nTheorem 5.1. Suppose the stability condition (5.1) and the light tail\nconditions (i) and (ii). Then, the maximal eigenvalue \u03ba(\u03b8) of C + D\u0302(\u03b8)+\u03b8\u2206v\nequals 0 for a unique \u03b8 = \u03b1 > 0, and we have, for i, j \u2208 S,\n(5.9)\n\nlim e\u03b1x P (M (\u03c4x+ ) = j|M (0) = i)\n\nx\u2192\u221e\n\n=\n\n1\n\u03b7 (\u03b1)\n\n\u0014\n\n\u0012\n\nh(\u03b1) \u03bc(\u03b1) \u0393(\u03b1) \u2212\n\n1\n(C + D)\n\u03b1\n\n\u0013\u0015\n\n,\nij\n\nwhere \u03b7 (\u03b1) = \u03bc(\u03b1) (D\u0302(1) (\u03b1) + \u2206v )h(\u03b1) for the first derivative D\u0302(1) (\u03b1) of D\u0302(\u03b8)\nat \u03b8 = \u03b1, and \u0393(\u03b1) is a S \u00d7 S-matrix such that\n(\u0393(\u03b1)+\u2212 , \u0393(\u03b1)++ ) = (0\u2212+ , 0++ ),\n(\u0393(\u03b1)\u2212\u2212 , \u0393(\u03b1)\u2212+ ) = \u2212k\u2212 \u03c0(\u2206v + D\u0302 \u2032 (0))\n\u2212\n\n1\n(\u03b1I \u2212\u2212 \u2212 k\u2212 \u03c0 \u2212 )(k\u2212 \u03c0 \u2212 \u2212 K (\u2212) )\u22121\n\u03b1\n\u00d7 (I \u2212\u2212 , L\u2212+ )(C + D).\n\nIn particular, using the notation \u03b7 (0) = E(Y (1)) < 0, for i \u2208 S,\n(\u03b1)\n\n(5.10)\n\nlim e\u03b1x P (\u03c4x+ < \u221e|M (0) = i) =\n\nx\u2192\u221e\n\n\u2212\u03b7 (0) hi\n\u03b7 (\u03b1)\n\n(\u03bc(\u03b1) )\u2212 k\u2212 .\n\nProof. We first compute the denominator of (5.3). From (5.4), it is\neasy to see that\n\u03bd (\u03b1)\n\nd\n\u0124(\u03b8)\nd\u03b8\n\n\u03b8=\u03b1\n\nh(\u03b1) = \u03bc(\u03b1) (D\u0302(1) (\u03b1) + \u2206v )h(\u03b1) ,\n\nsince (C + D\u0302(\u03b1) + \u03b1\u2206v )h(\u03b1) = 0. Thus the denominator is \u03b7 (\u03b1) , which\nis\nR\nclearly finite. This also implies condition (5.d). We next compute \u03bd (\u03b1) 0\u221e e\u03b1u G(u) du.\n\n\fHITTING PROBABILITIES IN RISK PROCESS\n\n23\n\nThen, (5.6) and (5.7) yield\n\u2212\n\n(0 , (\u03bd\n\n(\u03b1) +\n\n) )\n\nZ\n\n\u221e\n\ne\u03b1u G(u) du\n\n0\n\n1 \u2212\n(0 , (\u03bc(\u03b1) )+ )(C + D\u0302(\u03b1) + \u03b1\u2206v \u2212 (C + D)).\n\u03b1\nSimilarly, (5.6) and (5.8) yield\n=\n\n((\u03bd (\u03b1) )\u2212 , 0+ )\n\nZ\n\n\u221e\n\ne\u03b1u G(u) du\n\n0\n\n=\n\n1\n((\u03bc(\u03b1) )\u2212 , 0+ )(C + D\u0302(\u03b1) + \u03b1\u2206v \u2212 (C + D))\n\u03b1\n\u2212 (\u03bc(\u03b1) )\u2212 k\u2212 \u03c0 \u2212 (I \u2212\u2212 , L\u2212+ )(\u2206v + D\u0302 \u2032 (0))\n\u2212\n\n1 (\u03b1) \u2212\n(\u03bc ) (\u03b1I \u2212\u2212 \u2212 k\u2212 \u03c0 \u2212 )(k\u2212 \u03c0 \u2212 \u2212 K (\u2212) )\u22121 (I \u2212\u2212 , L\u2212+ )(C + D).\n\u03b1\n\nThus, (5.3) yields (5.9) since \u03c0 \u2212 (I \u2212\u2212 , L\u2212+ ) = \u03c0 and \u03bc(\u03b1) (C + D\u0302(\u03b1)+\u03b1\u2206v ) =\n0. Finally, summing up (5.9) over all j \u2208 S yields (5.10), since (C + D)e = 0\nand\n\u03c0(\u2206v + D\u0302(1) (0))e = E(Y (1)).\n\n\u0003\n\nRemark 5.2. When S + = \u2205 and v \u2261 \u22121, the results in Theorem 5.1 are\nfully compatible with those obtained in Theorem 3.1 of Miyazawa (2002).\nIt may be interesting to consider asymptotics of the probability that Y (t)\novershoots level x continuously. To this end, we define B of (5.2) as\n(5.11)\n\nB(x) = \u2206\u22121\nv\n\n\u0012\n\n++ \u22121\n\u2212L\u2212+\n\u2212x\u2206++\nc (\u2206v )\n.\n\u2206++\nv e\nI ++\n\n\u0013\n\nThen, using (5.6), we have\n\u03bd (\u03b1)\n\nZ\n\n\u221e\n\ne\u03b1x B(x) dx = \u03bc(\u03b1)\n\n0\n\n\u0012\n\n\u2212L\u2212+\n\u2206++\nv .\nI ++\n\u0013\n\nHence, we obtain the following result, which extends Corollary 4.9 of\nAsmussen (1994).\nTheorem 5.2.\nand j \u2208 S + ,\n(5.12)\n\nUnder the same conditions as in Theorem 5.1, for i \u2208 S\n\nlim e\u03b1x P (M (\u03c4x+ ) = j, Y (\u03c4x+ ) = x|M (0) = i)\n\nx\u2192\u221e\n\n(\u03b1) \u0014\n\nhi\n= (\u03b1)\n\u03bc(\u03b1)\n\u03b7\n\n\u0012\n\n\u2212L\u2212+\n\u2206++\n.\nv\nI ++\nj\n\u0013\n\n\u0015\n\n\f24\n\nM. MIYAZAWA\n\n6. Applications. We briefly discuss applications of our results to a risk\nprocess and a fluid queue with extra jump inputs. Define a process Zx (t) for\neach x \u2265 0 as\nZx (t) = x \u2212 Y (t),\n\nt \u2265 0.\n\nThen, Zx (t) is a risk reserve process starting with reserve level x, and \u2212v(i)\nis the premium rate under background state i \u2208 S, while a claim whose\nsize has distribution FijD arrives when the background state changes from\ni to j with rate Dij . For the risk process Zx (t), a primary interest is the\nruin probabilities and their asymptotics. The latter are obtained by Theorems 5.1 and 5.2. Numerical values of the ruin probabilities may be obtained\ntaking Fourier transform of (4.1), using Theorem 4.1 and Corollary 4.1, and\napplying numerical inversion technique.\nWe next consider a fluid queue. Suppose that Y (t) describes the net flow\nof a fluid queue with extra jump inputs. Then, the buffer content V (t) at\ntime t is given by\nV (t) = sup (Y (t) \u2212 Y (u)),\n0\u2264u\u2264t\n\nif V (0) = 0. As is well known, under the stability condition (5.1), which is\nassumed from now on, V (t) and M (t) converge jointly in distribution as\nt \u2192 \u221e. Denote a pair of random variables having this joint distribution by\n(V, M ). Then, the well-known formulation of Loynes (1962) yields\n\u0012\n\n(6.1)\n\n\u0013\n\nP (V > x, M = i) = \u03c0i P sup \u1ef8 (u) > x|M (0) = i .\nu\u22650\n\nHence, this stationary probability is the hitting probability at level x of the\nadditive process \u1ef8 (t). Thus, converting (5.10) to the dual process, Theorem 5.1 yields the following:\nTheorem 6.1. Under the conditions of Theorem 5.1, let \u03b1 be the same\none in the theorem, Q(\u2212) be the minimal rate matrix satisfying the following\nmatrix equation for a substochastic matrix R+\u2212 :\n(6.2)\n\n\u2212\n\n\u0012\n\nI \u2212\u2212\nQ(\u2212) = \u2206\u22121\nv\nR+\u2212\n\u0013\n\nZ\n\n0\n\n\u221e\n\n(\u2212)\nI \u2212\u2212\neuQ ,\n(C(du) + D(du))\nR+\u2212\n\n\u0012\n\n\u0013\n\nand let \u03b2 \u2212 be the stationary probability vector of Q(\u2212) . Then, we have, for\ni \u2208 S,\n(\u03b1)\n\n(6.3)\n\nlim e\u03b1x P (V > x, M = i) =\n\nx\u2192\u221e\n\n\u2212\u03b7 (0) \u03bci\n\u03b2 \u2212 (h(\u03b1) )\u2212 .\n\u03b7 (\u03b1)\n\n\f25\n\nHITTING PROBABILITIES IN RISK PROCESS\n\nAPPENDIX\nA.1. Proof of Lemma 5.2. We first consider the case that i \u2208 S + . From\n(4.4), we have\n1\n\u0124ij (\u03b8) = \u03b4ij +\n(Cij + D\u0302ij (\u03b8) + \u03b8[\u2206v ]ij ).\nc(i) \u2212 v(i)\u03b8\nThus, we get (5.4). For i \u2208 S \u2212 , we first compute the moment generating\nfunction of the first term of (4.4).\n\u0015\n\u0014Z \u221e\nZ \u221e\n\u22121\n\u2212+\n(y\u2212x)K (\u2212) \u2212\u2212\n\u03b8x\n(I , L )D(dy)\ne\ne dx\nv(i) 0\nx\nij\n=\n\n\u22121\n(\u03b8I \u2212\u2212 \u2212 K (\u2212) )\u22121\nv(i)\n\u0014\n\nZ\n\n\u221e\n\n(ey\u03b8I\n\n\u2212\u2212\n\n\u2212 eyK\n\n(\u2212)\n\n\u0015\n\n)(I \u2212\u2212 , L\u2212+ )D(dy)\n\n0\n\n.\nij\n\nHence, using the following equation that is obtained from (3.11),\n\u2212\n\n\u221e\n\nZ\n\neyK\n\n(\u2212)\n\n(I \u2212\u2212 , L\u2212+ )D(dy)\n\n0\n\n= (I \u2212\u2212 , L\u2212+ )C + (K (\u2212) \u2212 \u03b8I \u2212\u2212 )(I \u2212\u2212 , L\u2212+ )\u2206v + \u03b8(I \u2212\u2212 , L\u2212+ )\u2206v ,\nwe have\n\u0015\n\u0014Z \u221e\nZ \u221e\n\u22121\n(y\u2212x)K (\u2212) \u2212\u2212\n\u2212+\n\u03b8x\ne\n(I , L )D(dy)\ne dx\nv(i) 0\nx\nij\n\u22121 \u2212\u2212 \u2212+\n[(0 , L )(\u2212\u2206v ) + (\u03b8I \u2212\u2212 \u2212 K (\u2212) )\u22121 (I \u2212\u2212 , L\u2212+ )\nv(i)\n\n= \u03b4ij +\n\n\u00d7 (C + \u03b8\u2206v + D\u0302(\u03b8))]ij .\nWe next compute the moment generating function of the second term of\n(4.4). Similarly to the case that i \u2208 S + , we have\n\u22121\nv(i)\n\nZ\n\n\u221e\n\n\u03b8x\n\ne\n\ndx\n\nx\n\n0\n\n0\n\n=\n\n\u0012Z\n\nL\u2212+\nik\n\nX\n\n\u2212c(k)(x\u2212y)/v(k)\n\n(1 \u2212 e\n\nk\u2208S +\n\nv(k)\n)\nUkj (dy)\nc(k)\n\n\u0013\n\n\u22121 \u2212\u2212 \u2212+\n[(0 , L )\u2206v (I + \u2206\u22121\nc\u2212\u03b8v (C + D\u0302(\u03b8) + \u03b8\u2206v ))]ij .\nv(i)\n\nA.2. Derivation of (5.8). Similarly to (5.7), (4.6) yields\nZ\n\n0\n\n(A.4)\n\n\u221e\n\ne\u03b1x Gij (x) dx\n\u22121\n=\nv(i)\n\n\u0014Z\n\n0\n\n\u221e\n\n\u03b1x\n\ne dx\n\nZ\n\n\u221e\n\nx\n\ndw\n\nZ\n\n\u221e\n\ne(y\u2212w)K\n\n(\u2212)\n\n(I \u2212\u2212 , L\u2212+ )D(dy)\n\nw\n\n1\n+ (0\u2212\u2212 , L\u2212+ )\u2206v \u2206\u22121\nc\u2212\u03b1v (C + D\u0302(\u03b1) + \u03b1\u2206v \u2212 (C + D))\n\u03b1\n\n\u0015\n\n.\nij\n\n\f26\n\nM. MIYAZAWA\n\nWe compute the integral in the bracket of (A.4) in the following way. Using\nthe fact that K (\u2212) \u2212 \u03b1I \u2212\u2212 and k\u2212 \u03c0 \u2212 \u2212 K (\u2212) are nonsingular, where the\nlatter is obtained by Corollary 3.1, we have\nZ\n\n\u221e\n\n\u03b1x\n\ne\n\ndx\n\n0\n\n\u221e\n\nZ\n\ndw\n\nx\n\n=\n\nZ\n\n\u221e\n\ndw\n\n0\n\nZ\n\nw\n\nZ\n\n\u221e\n\ne(y\u2212w)K\n\n(\u2212)\n\n(I \u2212\u2212 , L\u2212+ )D(dy)\n\nw\n\ne\u03b1x dx\n\n0\n\nZ\n\n\u221e\n\ne(y\u2212w)K\n\n(\u2212)\n\n(I \u2212\u2212 , L\u2212+ )D(dy)\n\nw\n\n\u221e\n1 \u221e\n(\u2212)\n=\ndw\n(e\u03b1w \u2212 1)e(y\u2212w)K (I \u2212\u2212 , L\u2212+ )D(dy)\n\u03b1 0\nw\n\u0012Z \u221e\n(\u2212)\n1 (\u2212)\neyK (I \u2212\u2212 , L\u2212+ )D(dy)\n\u2212 \u03b1I \u2212\u2212 )\u22121\n= (K\n\u03b1\n0\n\nZ\n\nZ\n\n\u2212 (I\n1\n\u2212 (k\u2212 \u03c0 \u2212 \u2212 K (\u2212) )\u22121\n\u03b1\n\nZ\n\n\u221e\n\n\u2212\u2212\n\n,L\n\n\u2212+\n\n\u0013\n\n)D\u0302(\u03b1)\n\n(yk\u2212 \u03c0 \u2212 \u2212 (eyK\n\n(\u2212)\n\n\u2212 I \u2212\u2212 ))\n\n0\n\n\u00d7 (I \u2212\u2212 , L\u2212+ )D(dy).\n\nUsing the relation (3.11), the first integral in the above equation is computed\nas\n(\u03b1I \u2212\u2212 \u2212 K (\u2212) )(I \u2212\u2212 , L\u2212+ )\u2206v \u2212 (I \u2212\u2212 , L\u2212+ )(C + D\u0302(\u03b1) + \u03b1\u2206v ),\nwhile the second integral is computed as\n(I \u2212\u2212 , L\u2212+ )(C + D) \u2212 (k\u2212 \u03c0 \u2212 \u2212 K (\u2212) )(I \u2212\u2212 , L\u2212+ )\u2206v\n\u2212\n\n\u2212\n\n+ k \u03c0 (I\n\n\u221e\n\ne\u03b1x dx\n\n0\n\nZ\n\n\u221e\n\ndw\n\nx\n\n,L\n\n\u2212+\n\n\u0012\n\n) \u2206v +\n\nZ\n\n\u221e\n\nZ\n\n\u221e\n\ne(y\u2212w)K\n\n(\u2212)\n\n\u0013\n\nyD(dy) .\n\n0\n\u2212\n\u2212\n\u2212\n(\u2212)\nk = (k \u03c0 \u2212 K )\u22121 k\u2212 ,\n\nHence, using the fact that\nZ\n\n\u2212\u2212\n\nwe have\n\n(I \u2212\u2212 , L\u2212+ )D(dy)\n\nw\n\n1\n=\n(\u03b1I \u2212\u2212 \u2212 K (\u2212) )\u22121 (I \u2212\u2212 , L\u2212+ )(C + D\u0302(\u03b1) + \u03b1\u2206v )\n\u03b1\n\u0012\n\n\u2212\n\n\u2212\n\n\u2212 k \u03c0 (I\n\n\u2212\u2212\n\n\u2212\n\n,L\n\n\u2212+\n\n\u2212\n\n\u0012\n\n) \u2206v +\n\n\u2212 (k \u03c0 \u2212 K\n\nZ\n\n\u221e\n\n\u0013\n\nyD(dy)\n\n0\n\n(\u2212) \u22121\n\n)\n\n(I\n\n\u2212\u2212\n\nSubstituting this formula into (A.4), we get (5.8).\n\n,L\n\n\u2212+\n\n\u0013\n\n)(C + D) .\n\nAcknowledgment. The author is grateful to S\u00f8ren Asmussen for pointing\nout the relation between (2.3) and (2.8) and related references Asmussen and H\u00f8jgaard\n(1996) and Asmussen and Kl\u00fcppelberg (1996).\n\n\fHITTING PROBABILITIES IN RISK PROCESS\n\n27\n\nREFERENCES\nArjas, E. and Speed, T. P. (1973). Symmetric Wiener\u2013Hopf factorizations in Markov\nadditive processes. Z. Wahrsch. Verw. Gebiete 26 105\u2013118. MR331515\nAsmussen, S. (1987). Applied Probability and Queues. Wiley, Chichester. MR889893\nAsmussen, S. (1991). Ladder heights and the Markov-modulated M/G/1 queue. Stochastic Process. Appl. 37 313\u2013326. MR1102877\nAsmussen, S. (1994). Busy period analysis, rare events and transient behavior in fluid\nflow models. J. Appl. Math. Stochastic Anal. 7 269\u2013299. MR1301702\nAsmussen, S. (1995). Stationary distributions for fluid flow models with or without Brownian noise. Stoch. Models 11 21\u201349. MR1316767\nAsmussen, S. (2000). Ruin Probabilities. World Scientific, Singapore.\nAsmussen, S. and H\u00f8jgaard, B. (1996). Finite horizon ruin probabilities for Markovmodulated risk processes with heavy tails. Theory of Stochastic Processes 2 96\u2013107.\nAsmussen, S. and Kl\u00fcppelberg, C. (1996). Large deviations results for subexponential\ntails, with applications to insurance risk. Stochastic Process. Appl. 64 103\u2013125.\nBaccelli, F. and Br\u00e9maud, P. (2002). Elements of Queueing Theory: Palm Martingale\nCalculus and Stochastic Recurrences, 2nd ed. Springer, New York. MR1794582\n\u00c7inlar, E. (1975). Introduction to Stochastic Processes. Prentice-Hall, Englewood Cliffs,\nNJ. MR380912\nKingman, J. F. C. (1961). A convexity property of positive matrices. Quart. J. Math.\nOxford Ser. (2) 12 283\u2013284. MR138632\nLoynes, R. M. (1962). The stability of a queue with nonindependent inter-arrival and\nservice times. Proc. Cambridge Philosophical Society 58 497\u2013520. MR141170\nMiyazawa, M. (2002). A Markov renewal approach to the asymptotic decay of the tail\nprobabilities in risk and queueing processes. Probab. Eng. Inform. Sci. 16 139\u2013150.\nMR1891469\nMiyazawa, M. and Takada, H. (2002). A matrix exponential form for hitting probabilities and its application to a Markov modulated fluid queue with downward jumps. J.\nAppl. Probab. 39 604\u2013618. MR1928894\nNeuts, M. F. (1989). Structured Stochastic Matrices of M/G/1 Type and Their Applications. Dekker, New York. MR1010040\nRogers, L. C. G. (1994). Fluid models in queueing theory and Wiener\u2013Hopf factorization\nof Markov chains. Ann. Appl. Probab. 4 390\u2013413.\nRolski, T., Schmidli, H., Schmidt, V. and Teugels, J. (1999). Stochastic Processes\nfor Insurance and Finance. Wiley, Chichester. MR1272732\nSchmidli, H. (1995). Cram\u00e9r\u2013Lundberg approximations for ruin probabilities of risk processes perturbed by a diffusion. Insurance Math. Econom. 16 135\u2013149. MR1347857\nSeneta, E. (1980). Nonnegative Matrices and Markov Chains, 2nd ed. Springer, New\nYork. MR719544\nSengupta, B. (1989). Markov processes whose steady state distribution is matrixexponential with an application to the GI/P H/1 queue. Adv. in Appl. Probab. 21\n159\u2013180. MR980741\nTakada, H. (2001). Markov modulated fluid queues with batch fluid arrivals. J. Oper.\nRes. Soc. Japan 44 344\u2013365. MR1878676\nTakine, T. (2001). A recent progress in algorithmic analysis of FIFO queues with Markovian arrival streams. J. Korean Math. Soc. 38 807\u2013842. MR1838099\n\n\f28\n\nM. MIYAZAWA\nDepartment of Information Sciences\nTokyo University of Science\nYamazaki 2641\nNoda\nChiba 278-8510\nJapan\ne-mail: miyazawa@is.noda.tus.ac.jp\n\n\f"}