{"id": "http://arxiv.org/abs/cs/0601031v1", "guidislink": true, "updated": "2006-01-09T16:57:08Z", "updated_parsed": [2006, 1, 9, 16, 57, 8, 0, 9, 0], "published": "2006-01-09T16:57:08Z", "published_parsed": [2006, 1, 9, 16, 57, 8, 0, 9, 0], "title": "Divide-and-Evolve: a New Memetic Scheme for Domain-Independent Temporal\n  Planning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0601050%2Ccs%2F0601066%2Ccs%2F0601047%2Ccs%2F0601029%2Ccs%2F0601054%2Ccs%2F0601104%2Ccs%2F0601053%2Ccs%2F0601041%2Ccs%2F0601028%2Ccs%2F0601114%2Ccs%2F0601037%2Ccs%2F0601007%2Ccs%2F0601064%2Ccs%2F0601019%2Ccs%2F0601081%2Ccs%2F0601014%2Ccs%2F0601086%2Ccs%2F0601071%2Ccs%2F0601057%2Ccs%2F0601070%2Ccs%2F0601134%2Ccs%2F0601109%2Ccs%2F0601107%2Ccs%2F0601077%2Ccs%2F0601090%2Ccs%2F0601048%2Ccs%2F0601098%2Ccs%2F0601106%2Ccs%2F0601043%2Ccs%2F0601022%2Ccs%2F0601016%2Ccs%2F0601055%2Ccs%2F0601030%2Ccs%2F0601115%2Ccs%2F0601017%2Ccs%2F0601046%2Ccs%2F0601005%2Ccs%2F0601008%2Ccs%2F0601065%2Ccs%2F0601102%2Ccs%2F0601117%2Ccs%2F0601033%2Ccs%2F0601036%2Ccs%2F0601052%2Ccs%2F0601035%2Ccs%2F0601078%2Ccs%2F0601089%2Ccs%2F0601063%2Ccs%2F0601108%2Ccs%2F0601013%2Ccs%2F0601135%2Ccs%2F0601127%2Ccs%2F0601001%2Ccs%2F0601080%2Ccs%2F0601111%2Ccs%2F0601009%2Ccs%2F0601124%2Ccs%2F0601125%2Ccs%2F0601042%2Ccs%2F0601097%2Ccs%2F0601073%2Ccs%2F0601034%2Ccs%2F0601039%2Ccs%2F0601061%2Ccs%2F0601032%2Ccs%2F0601006%2Ccs%2F0601113%2Ccs%2F0601002%2Ccs%2F0601059%2Ccs%2F0601024%2Ccs%2F0601100%2Ccs%2F0601094%2Ccs%2F0601133%2Ccs%2F0601027%2Ccs%2F0601083%2Ccs%2F0601031%2Ccs%2F0601091%2Ccs%2F0601056%2Ccs%2F0601126%2Ccs%2F0601110%2Ccs%2F0601049%2Ccs%2F0601131%2Ccs%2F0601120%2Ccs%2F0601068%2Ccs%2F0601038%2Ccs%2F0601105%2Ccs%2F0601062%2Ccs%2F0601122%2Ccs%2F0601121%2Ccs%2F0601082%2Ccs%2F0601118%2Ccs%2F0601123%2Ccs%2F0202031%2Ccs%2F0202022%2Ccs%2F0202017%2Ccs%2F0202023%2Ccs%2F0202010%2Ccs%2F0202003%2Ccs%2F0202020%2Ccs%2F0202011%2Ccs%2F0202025&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Divide-and-Evolve: a New Memetic Scheme for Domain-Independent Temporal\n  Planning"}, "summary": "An original approach, termed Divide-and-Evolve is proposed to hybridize\nEvolutionary Algorithms (EAs) with Operational Research (OR) methods in the\ndomain of Temporal Planning Problems (TPPs). Whereas standard Memetic\nAlgorithms use local search methods to improve the evolutionary solutions, and\nthus fail when the local method stops working on the complete problem, the\nDivide-and-Evolve approach splits the problem at hand into several, hopefully\neasier, sub-problems, and can thus solve globally problems that are intractable\nwhen directly fed into deterministic OR algorithms. But the most prominent\nadvantage of the Divide-and-Evolve approach is that it immediately opens up an\navenue for multi-objective optimization, even though the OR method that is used\nis single-objective. Proof of concept approach on the standard\n(single-objective) Zeno transportation benchmark is given, and a small original\nmulti-objective benchmark is proposed in the same Zeno framework to assess the\nmulti-objective capabilities of the proposed methodology, a breakthrough in\nTemporal Planning.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0601050%2Ccs%2F0601066%2Ccs%2F0601047%2Ccs%2F0601029%2Ccs%2F0601054%2Ccs%2F0601104%2Ccs%2F0601053%2Ccs%2F0601041%2Ccs%2F0601028%2Ccs%2F0601114%2Ccs%2F0601037%2Ccs%2F0601007%2Ccs%2F0601064%2Ccs%2F0601019%2Ccs%2F0601081%2Ccs%2F0601014%2Ccs%2F0601086%2Ccs%2F0601071%2Ccs%2F0601057%2Ccs%2F0601070%2Ccs%2F0601134%2Ccs%2F0601109%2Ccs%2F0601107%2Ccs%2F0601077%2Ccs%2F0601090%2Ccs%2F0601048%2Ccs%2F0601098%2Ccs%2F0601106%2Ccs%2F0601043%2Ccs%2F0601022%2Ccs%2F0601016%2Ccs%2F0601055%2Ccs%2F0601030%2Ccs%2F0601115%2Ccs%2F0601017%2Ccs%2F0601046%2Ccs%2F0601005%2Ccs%2F0601008%2Ccs%2F0601065%2Ccs%2F0601102%2Ccs%2F0601117%2Ccs%2F0601033%2Ccs%2F0601036%2Ccs%2F0601052%2Ccs%2F0601035%2Ccs%2F0601078%2Ccs%2F0601089%2Ccs%2F0601063%2Ccs%2F0601108%2Ccs%2F0601013%2Ccs%2F0601135%2Ccs%2F0601127%2Ccs%2F0601001%2Ccs%2F0601080%2Ccs%2F0601111%2Ccs%2F0601009%2Ccs%2F0601124%2Ccs%2F0601125%2Ccs%2F0601042%2Ccs%2F0601097%2Ccs%2F0601073%2Ccs%2F0601034%2Ccs%2F0601039%2Ccs%2F0601061%2Ccs%2F0601032%2Ccs%2F0601006%2Ccs%2F0601113%2Ccs%2F0601002%2Ccs%2F0601059%2Ccs%2F0601024%2Ccs%2F0601100%2Ccs%2F0601094%2Ccs%2F0601133%2Ccs%2F0601027%2Ccs%2F0601083%2Ccs%2F0601031%2Ccs%2F0601091%2Ccs%2F0601056%2Ccs%2F0601126%2Ccs%2F0601110%2Ccs%2F0601049%2Ccs%2F0601131%2Ccs%2F0601120%2Ccs%2F0601068%2Ccs%2F0601038%2Ccs%2F0601105%2Ccs%2F0601062%2Ccs%2F0601122%2Ccs%2F0601121%2Ccs%2F0601082%2Ccs%2F0601118%2Ccs%2F0601123%2Ccs%2F0202031%2Ccs%2F0202022%2Ccs%2F0202017%2Ccs%2F0202023%2Ccs%2F0202010%2Ccs%2F0202003%2Ccs%2F0202020%2Ccs%2F0202011%2Ccs%2F0202025&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "An original approach, termed Divide-and-Evolve is proposed to hybridize\nEvolutionary Algorithms (EAs) with Operational Research (OR) methods in the\ndomain of Temporal Planning Problems (TPPs). Whereas standard Memetic\nAlgorithms use local search methods to improve the evolutionary solutions, and\nthus fail when the local method stops working on the complete problem, the\nDivide-and-Evolve approach splits the problem at hand into several, hopefully\neasier, sub-problems, and can thus solve globally problems that are intractable\nwhen directly fed into deterministic OR algorithms. But the most prominent\nadvantage of the Divide-and-Evolve approach is that it immediately opens up an\navenue for multi-objective optimization, even though the OR method that is used\nis single-objective. Proof of concept approach on the standard\n(single-objective) Zeno transportation benchmark is given, and a small original\nmulti-objective benchmark is proposed in the same Zeno framework to assess the\nmulti-objective capabilities of the proposed methodology, a breakthrough in\nTemporal Planning."}, "authors": ["Marc Schoenauer", "Pierre Sav\u00e9ant", "Vincent Vidal"], "author_detail": {"name": "Vincent Vidal"}, "author": "Vincent Vidal", "links": [{"href": "http://arxiv.org/abs/cs/0601031v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0601031v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0601031v1", "affiliation": "CRIL", "arxiv_url": "http://arxiv.org/abs/cs/0601031v1", "arxiv_comment": null, "journal_reference": "Dans EvoCOP2006", "doi": null, "fulltext": "Divide-and-Evolve: a New Memetic Scheme for\nDomain-Independent Temporal Planning\nMarc Schoenauer1 , Pierre Sav\u00e9ant2, Vincent Vidal3\n\narXiv:cs/0601031v1 [cs.AI] 9 Jan 2006\n\n1\n\nProjet TAO, INRIA Futurs, LRI, Bt. 490, Universit\u00e9 Paris Sud, 91405 Orsay, France\n2\nThales Research & Technology France, RD 128, F-91767 Palaiseau, France\n3\nCRIL & Universit\u00e9 d'Artois, rue de l'universit\u00e9 - SP16, 62307 Lens, France\n\nAbstract. An original approach, termed Divide-and-Evolve is proposed\nto hybridize Evolutionary Algorithms (EAs) with Operational Research\n(OR) methods in the domain of Temporal Planning Problems (TPPs).\nWhereas standard Memetic Algorithms use local search methods to improve the evolutionary solutions, and thus fail when the local method\nstops working on the complete problem, the Divide-and-Evolve approach\nsplits the problem at hand into several, hopefully easier, sub-problems,\nand can thus solve globally problems that are intractable when directly\nfed into deterministic OR algorithms. But the most prominent advantage\nof the Divide-and-Evolve approach is that it immediately opens up an avenue for multi-objective optimization, even though the OR method that\nis used is single-objective. Proof of concept approach on the standard\n(single-objective) Zeno transportation benchmark is given, and a small\noriginal multi-objective benchmark is proposed in the same Zeno framework to assess the multi-objective capabilities of the proposed methodology, a breakthrough in Temporal Planning.\n\n1\n\nIntroduction\n\nArtificial Intelligence Planning is a form of general problem solving task which\nfocuses on problems that map into state models that can be defined by a state\nspace S, an initial state s0 \u2286 S, a set of goal states SG \u2286 S, a set of actions A(s)\napplicable in each state S, and a transition function f (a, s) = s\u2032 with a \u2208 A(s),\nand s, s\u2032 \u2208 S. A solution to this class of models is a sequence of applicable actions\nmapping the initial state s0 to a goal state that belongs to SG .\nAn important class of problems is covered by Temporal Planning which extends classical planning by adding a duration to actions and by allowing concurrent actions in time [8]. In addition, other metrics are usually needed for\nreal-life problems to qualify a good plan, for instance a cost or a risk criterion.\nA usual approach is to aggregate the multiple criteria, but this relies on highly\nproblem-dependent features and is not always meaningful. A better solution is\nto compute the set of optimal non-dominated solutions \u2013 the so-called Pareto\nfront.\nBecause of the high combinatorial complexity and the multi-objective features of Temporal Planning Problems (TPPs), Evolutionary Algorithms are good\ngeneral-purpose candidate methods.\n\n\fHowever, there has been very few attempts to apply Evolutionary Algorithms\nto planning problems and, as far as we know, not any to Temporal Planning.\nSome approaches use a specific representation (e.g. dedicated to the battlefield\ncourses of action [15]). Most of the domain-independent approaches see a plan\nas a program and rely on Genetic Programming and on the traditional blocksworld domain for experimentation (starting with the Genetic Planner [17]). A\nmore comprehensive state of the art on Genetic Planning can be found in [1]\nwhere the authors experimented a variable length chromosome representation.\nIt is important to notice that all those works search the space of (partial) plans.\nIt is also now well-known that Evolutionary Algorithms (EAs) can rarely\nefficiently solve Combinatorial Optimization Problems on their own, i.e. without\nbeing hybridized, one way or another, with local search ad hoc techniques. The\nmost successful of such hybridizations use Operational Research methods to locally improve any offspring that was born from EA variation operators (crossover\nand mutation): such algorithms have been termed \"Memetic Algorithms\" or \"Genetic Local Search\" [14]. Those methods are now the heart of a whole research\nfield, as witnessed by the series of WOMA's (Workshops on Memetic Algorithms)\norganized every year now, Journal Special Issues and edited books [10].\nHowever, most memetic approaches are based on finding local improvements\nof candidate solutions proposed by the evolutionary search mechanism using\ndedicated local search methods that have to tackle the complete problem. In\nsome combinatorial domains such as Temporal Planning, this simply proves to\nbe impossible when reaching some level of complexity.\nThis paper proposes Divide-and-Evolve, borrowing to the Divide-and-Conquer\nparadigm for such situations: the problem at hand is sliced into a sequence of\nproblems that are hopefully easier to solve by OR or other local methods. The\nsolution to the original problem is then obtained by a concatenation of the solutions to the different sub-problems.\nNext section presents an abstract formulation of the Divide-and-Evolve scheme, and starting from its historical (and pedagogical) root, the TGV paradigm.\nGeneric representation and variation operators are also introduced. Section 3\nintroduces an actual instantiation of the Divide-and-Evolve scheme to TPPs.\nThe formal framework of TPPs is first introduced, then the TPP-specific issues\nfor the Divide-and-Evolve implementation are presented and discussed. Section 4\nis devoted to experiments on the transportation Zeno benchmark for both single\nand multi-objective cases. The last section opens a discussion highlighting the\nlimitations of the present work and giving hints about on-going and future work.\n\n2\n2.1\n\nThe Divide-and-Evolve Paradigm\nThe TGV metaphor\n\nThe Divide-and-Evolve strategy springs from a metaphor on the route planning\nproblem for the French high-speed train (TGV). The original problem consists\nin computing the shortest route between two points of a geographical landscape\n\n\fwith strong bounds on the curvature and slope of the trajectory. An evolutionary\nalgorithm was designed [4] based on the fact that the only local search algorithm\nat hand was a greedy deterministic algorithm that could solve only very simple\n(i.e. short distance) problems. The evolutionary algorithm looks for a split of\nthe global route into small consecutive segments such that a local search algorithm can easily find a route joining their extremities. Individuals represent sets\nof intermediate train stations between the station of departure and the terminus. The convergence toward a good solution was obtained with the definition\nof appropriate variation and selection operators [4]. Here, the state space is the\nsurface on which the trajectory of the train is defined.\nGeneralization Abstracted to Planning, the route is replaced by a sequence\nof actions and the \"stations\" become intermediate states of the system. The\nproblem is thus divided into sub-problems and \"to be close\" becomes \"to be\neasy to solve\" by some local algorithm L. The evolutionary algorithm plays the\nrole of an oracle pointing at some imperative states worth to go trough.\n2.2\n\nRepresentation\n\nThe problem at hand is an abstract AI Planning problem as described in the\nintroduction. The representation used by the evolutionary algorithm is a variable length list of states: an individual is thus defined as (si )i\u2208[1,n] , where the\nlength n and all the states si are unknown and subject to evolution. States s0\nand sn+1 \u2261 sG will represent the initial state and the goal of the problem at\nhand, but will not be encoded in the genotypes. By reference to the original\nTGV paradigm, each of the states si of an individual will be called a station.\nRequirements The original TGV problem is purely topological with no temporal dimension and reduces to a planning problem with a unique action: moving\nbetween two points. The generalization to a given planning domain requires to\nbe able to:\n1. define a distance between two different states of the system, so that d(S, T )\nis somehow related to the difficulty for the local algorithm L to find a plan\nmapping the initial state S to the final state T ;\n2. generate a chronological sequence of virtual \"stations\", i.e. intermediate\nstates of the system, that are close to one another, si being close to si+1 ;\n3. solve the resulting \"easy\" problems using the local algorithm L;\n4. \"glue\" the sub-plans into an overall plan of the problem at hand.\n2.3\n\nVariation operators\n\nThis section describes several variation operators that can be defined for the\ngeneral Divide-and-Evolve approach, independently of the actual domain of application (e.g. TPPs, or the original TGV problem).\n\n\fCrossover Crossover operators amounts to exchanging stations between two\nindividuals. Because of the sequential nature of the fitness, it seems a good idea\nto try to preserve sequences of stations, resulting in straightforward adaptations\nto variable-length representation of the classical 1- or 2-point crossover operators.\nSuppose you are recombining two individuals (si )1\u2264?n and (Ti )1\u2264?m . The 1point crossover amounts to choosing one station in each individual, say sa and Tb ,\nand exchanging the second part of the lists of stations, obtaining the two offspring\n(s1 , . . . , sa , Tm+1 , . . . Tb ) and (T1 , . . . , Tb , sn+1 , . . . , sn ) (2-point crossover is easily\nimplemented in a similar way). Note that in both cases, the length of each\noffspring is likely to differ from those of the parents.\nThe choice of the crossover points sa and Tb can be either uniform (as done\nin all the work presented here), or distance-based, if some distance is available:\npick the first station sa randomly, and choose Tb by e.g. a tournament based on\nthe distance with sa (this is on-going work).\nMutation Several mutation operators can be defined. Suppose individual (si )1\u2264?n\nis being mutated:\n\u2013 At the individual level, the Add mutation simply inserts a new station\nsnew after a given station (sa ), resulting in an n + 1-long list, (s1 , . . . , sa ,\nsnew , sa+1 , . . . , sn ). Its counterpart, the Del mutation, removes a station sa\nfrom the list.\nSeveral improvements on the pure uniform choice of sa can be added and are\npart of on-going work, too: in case the local algorithm fails to successfully\njoin all pairs of successive stations, the last station that was successfully\nreached by the local algorithm can be preferred for station sa (in both the\nAdd and Del mutations). If all partial problems are solved, the most difficult\none (e.g. in terms of number of backtracks) can be chosen.\n\u2013 At the station level, the definition of each station can be modified \u2013\nbut this is problem-dependent. However, assuming there exists a stationmutation operator \u03bcS , it is easy to define the individual-mutation M\u03bcS that\nwill simply call \u03bcS on each station si with a user-defined probability p\u03bcS .\nExamples of operators \u03bcS will be given in section 3, while simple Gaussian\nmutation of the (x, y) coordinates of a station were used for the original\nTGV problem [4].\n\n3\n\nApplication to Temporal Planning\n\n3.1\n\nTemporal planning problems\n\nDomain-Independent planners rely on the Planning Domain Definition Language\n(PDDL) [13], inherited from the STRIPS model [5], to represent a planning\nproblem. In particular, this language is used for a competition1 which is held\nevery two years since 1998. The language has been extended for representing\n1\n\nhttp://ipc.icaps-conference.org/\n\n\fTemporal Planning Problems in PDDL2.1 [7]. For the sake of simplicity, the\ntemporal model is often simplified as explained below [18].\nA Temporal PDDL Operator is a tuple o = hpre(o), add(o), del(o), dur(o)i\nwhere pre(o), add(o) and del(o) are sets of ground atoms that respectively denote\nthe preconditions, add effects and del effects of o, and dur(o) is a rational number\nthat denotes the duration of o. The operators in a PDDL input can be described\nwith variables, used in predicates such as (at ?plane ?city).\nA Temporal Planning Problem is a tuple P = hA, I, O, Gi, where A is a set\nof atoms representing all the possible facts in a world situation, I and G are two\nsets of atoms that respectively denote the initial state and the problem goals,\nand O is a set of ground PDDL operators.\nAs is common in Partial Order Causal Link (POCL) Planning [19], two\ndummy actions are also considered, Start and End with zero durations, the\nfirst with an empty precondition and effect I; the latter with precondition G\nand empty effects. Two actions a and a\u2032 interfere when one deletes a precondition or positive effect of the other. The simple model of time in [16] defines a\nvalid plan as a plan where interfering actions do not overlap in time. In other\nwords, it is assumed that the preconditions need to hold until the end of the\naction, and that the effects also hold at the end and cannot be deleted during\nthe execution by a concurrent action.\nA schedule P is a finite set of actions occurrences hai , ti i, i = 1, . . . , n, where\nai is an action and ti is a non-negative integer indicating the starting time of ai\n(its ending time is ti + dur(ai )). P must include the Start and End actions, the\nformer with time tag 0. The same action (except for these two) can be executed\nmore than once in P if ai = aj for i 6= j. Two action occurrences ai and aj overlap\nin P if one starts before the other ends; namely if [ti , ti +dur(ai )]\u2229[tj , tj +dur(aj )]\ncontains more than one time point.\nA schedule P is a valid plan iff interfering actions do not overlap in P and\nfor every action occurrence hai , ti i in P its preconditions p \u2208 pre(a) are true at\ntime ti . This condition is inductively defined as follows: p is true at time t = 0\niff p \u2208 I, and p is true at time t > 0 if either p is true at time t \u2212 1 and no\naction a in P ending at t deletes p, or some action a\u2032 in P ending at t adds p.\nThe makespan of a plan P is the time tag of the End action.\n3.2\n\nCPT: an optimal temporal planner\n\nAn optimal temporal planner computes valid plans with minimum makespan.\nEven though an optimal planner was not mandatory (as discussed in section 5),\nwe have chosen CPT [18], a freely-available optimal temporal planner, for its\ntemporal dimension and for its constraint-based approach which provide a very\nuseful data structure when it comes to gluing the partial solutions (see section\n2.2). Indeed, since in Temporal Planning actions can overlap in time, the simple\nconcatenation of sub-plans, though providing a feasible solution, obviously might\nproduce a plan that is not optimal with respect to the total makespan, even if\nthe sequence of actions is the optimal sequence. However, thanks to the causal\nlinks and order constraints maintained by CPT, an improved global plan can\n\n\fbe obtained by shifting sub-plans as early as possible in a final state of the\nalgorithm.\n3.3\n\nRationale for using Divide-and-Evolve for Temporal Planning\n\nThe reasons for the failure of standard OR methods addressing TPPs come\nfrom the exponential complexity of the number of possible actions when the\nnumber of objects involved in the problem increases. It is known for a long time\nthat taking into account the interactions between sub-goals can decrease the\ncomplexity of finding a plan, in particular when these sub-goals are independent\n[12]. Moreover, computing an ideal ordering on sub-goals is as difficult as finding\na plan (PSPACE-hard), as demonstrated in [11]. The basic idea when using the\nDivide-and-Evolve approach is that each local sub-plan (\"joining\" stations si\nand si+1 ) should be easier to find than the global plan (joining the station of\ndeparture s0 and the terminus sn+1 ). This will be now demonstrated on the\nZeno transportation benchmark (see http://ipc.icaps-conference.org/).\nTable 1 illustrates the decomposition of a relatively difficult problem in the\nZeno domain (zeno14 from IPC-3 benchmarks), a transportation problem with\n5 planes (plane1 to plane5) and 10 persons (person0 to person9) to travel\namong 10 cities (city0 to city9).\nAnalyzing the optimal solution found by CPT-3 it was easy to manually divide the optimal \"route\" of this solution in the state space into four intermediate\nstations between the initial state and the goal. It can be seen that very few moves\n(plane or person) occur between two consecutive stations (the ones in bold in\neach column of Table 1). Each sub-plan is easily found by CPT, with a maximum of 195 backtracks and 4.34 seconds of search time. It should be noted that\nmost of the time spent by CPT is for pre-processing: this operation is actually\nrepeated each time CPT is called, but could be factorized at almost no cost.\nNote that the final step of the process is the compression of the five sub-plans\n(see section 2.2): it is here performed in 0.02 seconds without any backtracking,\nand the overall makespan of the plan is 772, much less than the sum of the\nindividual makespans of each sub-plan (2051).\nTo summarize, the recomposed plan, with a makespan of 772, required a\ntotal running time of 254.38 seconds (including only 7.5s of pure search) and\n228 backtracks altogether, whereas a plan with the optimal makespan of 476 is\nfound by CPT in 4,205 seconds and 606,405 backtracks. Section 5 will discuss\nthis issue.\n3.4\n\nDescription of the state space\n\nNon-temporal states A natural state space for TPPs, as described at the\nbeginning of this section, would be the actual space of all possible time-stamped\nstates of the system. Obviously, the size of such a space is far too big and we\nsimplified it by restricting the stations to non-temporal states. However, even\nwith this simplification, not all \"non-temporal\" states can be considered in the\n\n\fTable 1. State Decomposition of the Zeno14 Instance. (The new location of\nmoved objects appears in bold.)\nObjects\n\nInit\nStation 1 Station 2 Station 3 Station 4 Goal\n(station 0)\n(station 5)\nplane 1\ncity 5\ncity 6\ncity 6\ncity 6\ncity 6\ncity 6\nplane 2\ncity 2\ncity 2\ncity 3\ncity 3\ncity 3\ncity 3\nplane 3\ncity 4\ncity 4\ncity 4\ncity 9\ncity 9\ncity 9\nplane 4\ncity 8\ncity 8\ncity 8\ncity 8\ncity 5\ncity 5\nplane 5\ncity 9\ncity 9\ncity 9\ncity 9\ncity 9\ncity 8\nperson 1\ncity 9\ncity 9\ncity 9\ncity 9\ncity 9\ncity 9\nperson 2\ncity 1\ncity 1\ncity 1\ncity 1\ncity 1\ncity 8\nperson 3\ncity 0\ncity 0\ncity 2\ncity 2\ncity 2\ncity 2\nperson 4\ncity 9\ncity 9\ncity 9\ncity 7\ncity 7\ncity 7\nperson 5\ncity 6\ncity 6\ncity 6\ncity 6\ncity 6\ncity 1\nperson 6\ncity 0\ncity 6\ncity 6\ncity 6\ncity 6\ncity 6\nperson 7\ncity 7\ncity 7\ncity 7\ncity 7\ncity 5\ncity 5\nperson 8\ncity 6\ncity 6\ncity 6\ncity 6\ncity 6\ncity 1\nperson 9\ncity 4\ncity 4\ncity 4\ncity 4\ncity 5\ncity 5\nperson 0\ncity 7\ncity 7\ncity 7\ncity 9\ncity 9\ncity 9\nMakespan\n350\n350\n280\n549\n522\nBacktracks\n1\n0\n0\n195\n32\nSearch time\n0.89\n0.13\n0.52\n4.34\n1.64\nTotal time\n49.10\n49.65\n49.78\n54.00\n51.83\nCompression\nGlobal Search\nMakespan\n772\n476\nBacktracks\n0\n606,405\nSearch time\n0.01\n4,155.41\nTotal time\n0.02 (total : 254.38)\n4,205.40\n\ndescription of the \"stations\".\nLimiting the possible states First, the space of all possible states grows exponentially with the size of the problem. Second, not all states are consistent w.r.t.\nthe planning domain. For instance, an object cannot be located at two places at\nthe same time in a transportation problem \u2013 and inferring such state invariants\nis feasible but not trivial [6]. Note also that determining plan existence from a\npropositional STRIPS description has been proved to be PSPACE-complete [2].\nA possible way to overcome this difficulty would be to rely on the local\nalgorithm to (rapidly) check the consistency of a given situation, and to penalize\nunreachable stations. However, this would clearly be a waste of computational\nresources.\nOn the other hand, introducing domain knowledge into EAs has been known\nfor long as the royal road toward success in Evolutionary Computation [9]. Hence,\nit seems a more promising approach to add state invariants to the description of\nthe state space in order to remove the inconsistent states as much as possible.\nThe good thing is that it is not necessary to remove all inconsistent states\n\n\fsince, in any case, the local algorithm is there to help the EA to spot them \u2013\ninconsistent stations will be given poor fitness, and will not survive next selection\nsteps. In particular, only state invariants involving a single predicate have been\nimplemented in the present work.\n3.5\n\nRepresentation of stations\n\nIt was hence decided to describe the stations using only the predicates that\nare present in the goal of the overall problem, and to maintain the state\ninvariants based on the semantics of the problem.\nA good example is given in Table 1: the goal of this benchmark instance\nis to move the persons and planes in cities listed in the last column. No other\npredicate than the corresponding (at objectN cityM) predicates is present in\nthe goal. Through a user-supplied file, the algorithm is told that only the at\npredicates will be used to represent the stations, with the syntactic restrictions\nthat within a given station, the first argument of an at predicate can appear\nonly once (at is said to be exclusive with respect to its first argument). The\nstate space that will be explored by the algorithm thus amounts to a vector of\n15 fluents (instantiated predicates) denoting that an item is located in a city (a\ncolumn of table 1). In addition, the actual implementation of a station includes\nthe possibility to \"remove\" (in fact, comment out) a predicate of the list: the\ncorresponding object will not move during this sub-plan.\nDistance The distance between two stations should reflect the difficulty for the\nlocal algorithm to find a plan joining them. At the moment, a purely syntactic\ndomain-independent distance is used: the number of different predicates not\nyet reached. The difficulty can then be estimated by the number of backtracks\nneeded by the local algorithm. It is reasonable to assume that indeed most local\nproblems where only a few predicates need to be changed from the initial state\nto the goal will be easy for the local algorithm - though this is certainly not true\nin all cases.\n3.6\n\nRepresentation-specific operators\n\nInitialization First, the number of stations is chosen uniformly in a usersupplied interval. The user also enters a maximal distance dmax between stations.\nA matrix is then built, similar to the top lines of table 1: each line corresponds\nto one of the goal predicates, each column is a station. Only the first and last\ncolumns (corresponding to initial state and goal) are filled with values. A number of \"moves\" is then randomly added in the matrix, at most dmax per column,\nand at least one per line. Additional moves are then added according to another\nuser-supplied parameter, and without exceeding the dmax limit per column. The\nmatrix is then filled with values, starting from both ends (init and goal), constrained column-wise by the state invariants. A final sweep on all predicates\ncomments out some of the predicates with a given probability.\n\n\fStation mutation Thanks to the simplified representation of the states (a vector of fluents with a set of state invariants), it is straightforward to modify one\nstation randomly: with a given probability, a new value for the non-exclusive arguments is chosen among the possible values respecting all constraints (including\nthe distance constraints with previous and next stations). In addition, each predicate might be commented out from the station with a given probability, like in\nthe initialization phase.\n\n4\n4.1\n\nFirst Experiments\nSingle objective optimization\n\nOur main playground to validate the Divide-and-Evolve approach is that of\ntransportation problems, and started with the zeno domain as described in section 3.3. As can be seen in table 1, the description of the stations in zeno domain\ninvolves a single predicate, at, with two arguments. It is exclusive w.r.t. its first\nargument. Three instances have been tried, called zeno10, zeno12 and zeno14,\nfrom the simplest to the hardest.\nAlgorithmic settings The EA that was used for the first implementation of the\nDivide-and-Evolve paradigm use standard algorithmic settings at the population\nlevel: a (10, 70) \u2212 ES evolution engine (10 parents give birth to 70 children, and\nthe best 10 among the children become the next parents), the children are created using 25% 1-point crossover (see section 2.3) and 75% mutation (individual\nlevel), out of which 25% are the Add (resp. Del) generic mutations (section 2.3).\nThe remaining 50% of the mutations call the problem-specific station mutation.\nWithin a station mutation, a predicate is randomly changed in 75% of the cases\nand a predicate is removed (resp. restored) in each of the remaining 12.5% cases.\n(see section 3.6). Initialization is performed using initial size in [2, 10], maximum\ndistance of 3 and probability to comment out a predicate is set to 0.1. Note that\nno lengthy parameter tuning was performed for those proof-of-concept experiments, and the above values were decided based upon a very limited set of initial\nexperiments.\nThe fitness The target objective is here the total makespan of a plan \u2013 assuming that a global plan can be found, i.e. that all problems (si , si+1 ) can be solved\nby the local algorithm. In case one of the local problems could not be solved, the\nindividual is declared infeasible and is penalized in such a way that all unfeasible\nindividuals were worse than any feasible one. Moreover, this penalty is proportional to the number of remaining stations after the failure, in order to provide\na nice slope of the fitness landscape toward feasibility. For feasible individuals,\nan average of the total makespan and the sum of the makespans of all partial\nproblems is used: when only the total makespan is used, some individuals start\nbloating, without much consequence on the total makespan thanks to the final\ncompression that is performed by CPT, but nevertheless slowing down the whole\n\n\frun because of all the useless repeated calls to CPT.\nPreliminary results The simple zeno10 (resp. zeno12) instance can be solved\nvery easily by CPT-2 alone, in less than 2s (resp. 125s), finding the optimal plans\nwith makespan 453 (resp. 549) using 154 (resp. 27560) backtracks.\nFor zeno10, all runs found the optimal solution in the very first generations\n(i.e. the initialization procedure always produced a feasible individual that CPT\ncould compress to the optimal makespan. For zeno12, all runs found a suboptimal solution with makespan between 789 and 1222. Note that this final\nsolution was found after 3 to 5 generations, the algorithm being stuck to this\nsolution thereafter. The CPU time needed for 10 generations is around 5 hours.\nA more interesting case is that of zeno14. First of all, it is worth mentioning\nthat the present Divide-and-Evolve EA uses as local algorithm CPT version 2,\nand this version of CPT was unable to find a solution to zeno14: the results\ngiven in table 1 have been obtained using the (yet experimental and not usable\nfrom within the EA) new version of CPT. But whereas it proved unable to\nsolve the full problem, CPT-2 could nevertheless be used to solve the hopefully\nsmall instances of zeno14 domain that were generated by the Divide-and-Evolve\napproach \u2013 though taking a huge amount of CPU time for that. Setting a limit on\nthe number of backtracks allowed for CPT was also mandatory to force CPT not\nto explore the too complex cases that would have resulted in a never-returning\ncall.\nHowever, a feasible individual was found in each of the only 2 runs we could\nrun \u2013 one generation (70 evaluations) taking more than 10 hours. In the first\nrun, a feasible individual was found in the initial population, with makespan\n1958, and the best solution had a makespan of 773. In the other run, the first\nfeasible solution was found at generation 3 \u2013 but the algorithm never improved\non that first feasible individual (makespan 1356).\nThough disappointing with respect to the overall performances of the algorithm, those results nevertheless witness for the fact that the Divide-and-Evolve\napproach can indeed solve a problem that could not be solved by CPT alone\n(remember that the version of CPT that was used in all experiments is by far\nless efficient than the one used to solve zeno14 in section 3.3, and was not able\nto solve zeno14 at all.\n4.2\n\nA multi-objective problem\n\nProblem description In order to test the feasibility of the multi-objective approach based on the Divide-and-Evolve paradigm, we extended the zeno benchmark with an additional criterion, that can be interpreted either as a cost, or\nas a risk: in the former case, this additional objective is an additive measure,\nwhereas in the latter case (risk) the aggregation function is the max operator.\nThe problem instance is shown in Figure 1: the only available routes between\ncities are displayed as edges, only one transportation method is available (plane),\nand the duration of the transport is shown on the corresponding edge. Risks (or\ncosts) are attached to the cities (i.e., concern any transportation that either\n\n\flands or takes off from that city). In the initial state, the 3 persons and the 2\nplanes are in City 0, and the goal is to transport them into City 4.\n\nCity 1\n\n2\n\n2\n\n100\n\n1000\n\n3\n4\n\n4\n\nCity 2\n\n5\n\n3\n\nCity 4\n\n10\n\nCost/Risk\n\nCity 0\n\nGen. 1\nGen. 3\nGen. 10\nGen. 28\n\n800\n600\n400\n200\n\n6\n\n6\n\nCity 3\n\n1\na) The instance: Durations are attached to edges, costs/risks are attached to cities (in gray circles).\n\n0\n\n10\n\n30\nMakespan\nb) The population at different generations for a successful run on the cost\n(additive) instance of the zeno miniproblem of Figure 1-a.\n\nFig. 1. The multi-objective Zeno benchmark.\n\nAs can be easily computed (though there is a little trick here), there are 3\nremarkable Pareto-optimal solutions, corresponding to traversing only one of the\n3 middle cities. Going through City 1 is fast, but risky (costly), whereas going\nthrough City 3 is slow and safe and cheap.\nWhen all persons go through respectively City 1, City 2 and City 3, the\ncorresponding values of the makespans and costs in the additive case are (8,\n800), (16, 80) and (24, 8), whereas they are, in the max case, (8, 100),\n(16, 10) and (24, 1).\nProblem complexity It is easy to compute the number of possible virtual stations: each one of the 3 persons can be in one of the 5 cities, or not mentioned\n(absent predicate). Hence there are 36 = 729 possible combinations, and 729n\npossible lists of length n. So even when n is limited to 6, the size of the search\nspace is approx. 1017 . . .\nThe algorithm The EA is based on the standard NSGA-II multi-objective\nEA [3]: standard tournament selection of size 2 and deterministic replacement\namong parents + offspring, both based on the Pareto ranking and crowding distance selection; a population size of 100 evolves during 30 generations. All other\nparameters were those used for the single objective case.\nFitnesses The problem has two objectives: one is the the total makespan (as in\nthe single-objective case), the other is either the risk (aggregated using the max\n\n\foperator) or the cost (an additive objective). Because the global risk only takes\n3 values, there is no way to have any useful gradient information when used as\nfitness in the max case. However, even in the additive case, the same arguments\nthan for the makespan apply (section 4.1), and hence, in all cases, the second\nobjective is the sum of the overall risk/cost and the average (not the sum) of\nthe values for all partial problems \u2013 excluding from this average those partial\nproblems that have a null makespan (when the goal is already included in the\ninitial state).\nResults For the additive (cost) case, the most difficult Pareto optimum (going\nthrough city 3 only) was found 4 times out of 11 runs. However, the 2 other\nremarkable Pareto optima, as well as several other points in the Pareto front\nwere also repeatedly found by all runs. Figure 1-b shows different snapshots\nof the population at different stages of the evolution for a typical successful\nrun: at first ('+'), all individuals have a high cost (above 800); At generation 3\n('\u00d7), there exist individuals in the population that have cost less than 600; At\ngeneration 10 (squares), many points have a cost less than 100. But the optimal\n(24,8) solution is only found at generation 28 (circles).\nThe problem in the risk context (the max case) proved to be, as expected,\nslightly more difficult. All three Pareto optima (there exist no other point of the\ntrue Pareto front in the max case) were found only in 2 runs out of 11. However,\nall runs found both the two other Pareto optima, as well as the slightly suboptimal solutions that goes only through city 3 but did not find the little trick\nmentioned earlier, resulting in a (36,1) solution.\nIn both cases, those results clearly validate the Divide-and-Evolve approach\nfor multi-objective TPPs \u2013 remember that CPT has no knowledge of the risk/cost\nin its optimization procedure - it only aggregates the values a posteriori, after\nhaving computed its optimal plan based on the makespan only \u2013 hence the difficulty to find the 3rd Pareto optimum going only through city3.\n\n5\n\nDiscussion and Further Work\n\nA primary concern is the existence of a decomposition for any plan with optimal\nmakespan. Because of the restriction of the representation to the predicates\nthat are in the goal, some states become impossible to describe. If one of these\nstates is mandatory for all optimal plans, the evolutionary algorithm is unable\nto find the optimal solution. In the zeno14 benchmark detailed in section 3.3,\nfor instance, one can see from the optimal solution that the in predicate should\nbe taken into account when splitting the optimal solution, in order to be able\nto link a specific person to a specific plane. The main difficulty, however, is to\nadd the corresponding state invariant between at and in (a person is either at a\nlocation or in a plane). Future work will include state invariants involving pairs\nof predicates, to cope with such cases. Along the same line, we will investigate\nwhether it might be possible to automatically infer some state invariants from\nthe data structures maintained by CPT.\n\n\fIt is clear from the somehow disappointing results presented in section 4.1\nthat the search capabilities of the proposed algorithm should be improved. But\nthere is a lot of space for improvements. First, and most immediate, the variation\noperators could use some domain knowledge, as proposed in section 2.3 \u2013 even if\nthis departs from \"pure\" evolutionary blind search. Also, all parameters of the\nalgorithm will be carefully fine-tuned.\nOf course the Divide-and-Evolve scheme has to be experimented on more\nexamples. The International Planning Competition provides many instances in\nseveral domains that are good candidates. Preliminary results on the driver\nproblem showed very similar results that those reported here on the zeno domain.\nBut other domains, such as the depot domain, or many real-world domains,\ninvolve (at least) 2 predicates in their goal descriptions (e.g., in and on for\ndepot) . It is hence necessary to increase the range of allowed expressions in the\ndescription of individuals.\nOther improvements will result from the move to the new version of CPT,\nentirely rewritten in C. It will be possible to call CPT from within the EA, and\nhence to perform all grounding, pre-processing and CSP representation only\nonce: at the moment, CPT is launched anew for each partial computation, and a\nquick look at table 1 shows that on zeno14 problem, for instance, the run-time\nper individual will decrease from 250 to 55 seconds. Though this will not per\nse improve the quality of the results, it will allow us to tackle more complex\nproblems than even zeno14. Along the same lines, other planners, in particular\nsub-optimal planners, will also be tried in lieu of CPT, as maybe the Divideand-Evolve approach could find optimal results using sub-optimal planners (as\ndone in some sense in the multi-objective case, see section 4.2).\nA last but important remark about the results is that, at least in the single\nobjective case, the best solution found by the algorithm was always found in\nthe very early generations of the runs: it could be that the simple splits of the\nproblem into smaller sub-problems that are done during the initialization are\nthe main reasons for the results. Detailed investigations will show whether or\nnot an Evolutionary Algorithm is useful in that context!\nNevertheless, we do believe that using Evolutionary Computation is mandatory in order to solve multi-objective optimization problems, as witnessed by the\nresults of section 4.2, that are, to the best of our knowledge, the first ever results\nof Pareto optimization for TPPs.\n\nReferences\n1. A. H. Brie and P. Morignot. Genetic Planning Using Variable Length Chromosomes. In 15th Intl Conf. on Automated Planning and Scheduling, 2005.\n2. T. Bylander. The Computational Complexity of Propositional STRIPS planning.\nArtificial Intelligence, 69(1-2):165\u2013204, 1994.\n3. K. Deb, S. Agrawal, A. Pratab, and T. Meyarivan. A Fast Elitist Non-Dominated\nSorting Genetic Algorithm for Multi-Objective Optimization. In M. Schoenauer\net al., editor, PPSN'2000, pages 849\u2013858. Springer-Verlag, LNCS 1917, 2000.\n\n\f4. C. Desquilbet. D\u00e9termination de trajets optimaux par algorithmes g\u00e9n\u00e9tiques.\nRapport de stage d'option B2 de l'Ecole Polytechnique. Palaiseau, France, Juin\n1992. Advisor: Marc Schoenauer. In French.\n5. R. Fikes and N. Nilsson. STRIPS: A New Approach to the Application of Theorem\nProving to Problem Solving. Artificial Intelligence, 1:27\u2013120, 1971.\n6. M. Fox and D. Long. The Automatic Inference of State Invariants in TIM. Journal\nof Artificial Intelligence Research, 9:367\u2013421, 1998.\n7. M. Fox and D. Long. PDDL2.1: An Extension to PDDL for Expressing Temporal\nPlanning Domains. Journal of Artificial Intelligence Research, 20:61\u2013124, 2003.\n8. H. Geffner. Perspectives on Artificial Intelligence Planning. In Proc. AAAI-2002,\npages 1013\u20131023, 2002.\n9. J. J. Grefenstette. Incorporating Problem Specific Knowledge in Genetic Algorithms. In Davis L., editor, Genetic Algorithms and Simulated Annealing, pages\n42\u201360. Morgan Kaufmann, 1987.\n10. W.E. Hart, N. Krasnogor, and J.E. Smith, editors. Recent Advances in Memetic\nAlgorithms. Studies in Fuzziness and Soft Computing, Vol. 166. Springer Verlag,\n2005.\n11. J. Koehler and J. Hoffmann. On Reasonable and Forced Goal Orderings and their\nUse in an Agenda-Driven Planning Algorithm. JAIR, 12:338\u2013386, 2000.\n12. R. Korf. Planning as Search: A Quantitative Approach. Artificial Intelligence,\n33:65\u201388, 1987.\n13. D. McDermott. PDDL \u2013 The Planning Domain Definition language. At\nhttp://ftp.cs.yale.edu/pub/mcdermott, 1998.\n14. P. Merz and B. Freisleben. Fitness Landscapes and Memetic Algorithm Design. In\nDavid Corne, Marco Dorigo, and Fred Glover, editors, New Ideas in Optimization,\npages 245\u2013260. McGraw-Hill, London, 1999.\n15. J.L. Schlabach, C.C. Hayes, and D.E. Goldberg. FOX-GA: A Genetic Algorithm\nfor Generating and Analyzing Battlefield Courses of Action. Evolutionary Computation, 7(1):45\u201368, 1999.\n16. D. Smith and D. S. Weld. Temporal Planning with Mutual Exclusion Reasoning.\nIn Proceedings of IJCAI-99, pages 326\u2013337, 1999.\n17. L. Spector. Genetic Programming and AI Planning Systems. In Proc. AAAI 94,\npages 1329\u20131334. AAAI/MIT Press, 1994.\n18. V. Vidal and H. Geffner. Branching and Pruning: An Optimal Temporal POCL\nPlanner based on Constraint Programming. In Proceedings of AAAI-2004, pages\n570\u2013577, 2004.\n19. D. S. Weld. An Introduction to Least Commitment Planning. AI Magazine,\n15(4):27\u201361, 1994.\n\n\f"}