{"id": "http://arxiv.org/abs/1110.0990v1", "guidislink": true, "updated": "2011-10-05T14:08:33Z", "updated_parsed": [2011, 10, 5, 14, 8, 33, 2, 278, 0], "published": "2011-10-05T14:08:33Z", "published_parsed": [2011, 10, 5, 14, 8, 33, 2, 278, 0], "title": "The Query-commit Problem", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1110.5167%2C1110.1211%2C1110.0162%2C1110.6344%2C1110.4671%2C1110.3311%2C1110.0935%2C1110.4849%2C1110.2650%2C1110.6579%2C1110.3142%2C1110.3727%2C1110.0345%2C1110.4268%2C1110.1452%2C1110.3986%2C1110.2684%2C1110.2028%2C1110.2939%2C1110.1893%2C1110.3075%2C1110.6769%2C1110.5967%2C1110.4745%2C1110.6828%2C1110.3536%2C1110.3446%2C1110.1844%2C1110.5396%2C1110.1534%2C1110.4014%2C1110.3439%2C1110.3711%2C1110.2201%2C1110.5608%2C1110.0887%2C1110.4878%2C1110.4902%2C1110.1988%2C1110.0030%2C1110.0604%2C1110.6618%2C1110.6032%2C1110.4928%2C1110.5708%2C1110.0798%2C1110.4483%2C1110.1728%2C1110.5653%2C1110.2291%2C1110.0556%2C1110.2598%2C1110.1817%2C1110.3130%2C1110.5119%2C1110.6529%2C1110.0334%2C1110.4112%2C1110.1955%2C1110.5104%2C1110.6781%2C1110.3783%2C1110.2556%2C1110.2867%2C1110.2354%2C1110.3470%2C1110.2824%2C1110.4930%2C1110.0990%2C1110.3160%2C1110.1618%2C1110.3598%2C1110.4148%2C1110.0529%2C1110.2254%2C1110.1799%2C1110.3138%2C1110.0912%2C1110.3864%2C1110.5047%2C1110.2945%2C1110.2932%2C1110.5843%2C1110.2122%2C1110.4457%2C1110.4350%2C1110.0337%2C1110.5750%2C1110.6913%2C1110.6930%2C1110.3710%2C1110.6537%2C1110.5982%2C1110.0341%2C1110.1902%2C1110.3997%2C1110.2476%2C1110.2369%2C1110.2480%2C1110.0636%2C1110.4842&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The Query-commit Problem"}, "summary": "In the query-commit problem we are given a graph where edges have distinct\nprobabilities of existing. It is possible to query the edges of the graph, and\nif the queried edge exists then its endpoints are irrevocably matched. The goal\nis to find a querying strategy which maximizes the expected size of the\nmatching obtained. This stochastic matching setup is motivated by applications\nin kidney exchanges and online dating.\n  In this paper we address the query-commit problem from both theoretical and\nexperimental perspectives. First, we show that a simple class of edges can be\nqueried without compromising the optimality of the strategy. This property is\nthen used to obtain in polynomial time an optimal querying strategy when the\ninput graph is sparse. Next we turn our attentions to the kidney exchange\napplication, focusing on instances modeled over real data from existing\nexchange programs. We prove that, as the number of nodes grows, almost every\ninstance admits a strategy which matches almost all nodes. This result supports\nthe intuition that more exchanges are possible on a larger pool of\npatient/donors and gives theoretical justification for unifying the existing\nexchange programs. Finally, we evaluate experimentally different querying\nstrategies over kidney exchange instances. We show that even very simple\nheuristics perform fairly well, being within 1.5% of an optimal clairvoyant\nstrategy, that knows in advance the edges in the graph. In such a\ntime-sensitive application, this result motivates the use of committing\nstrategies.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1110.5167%2C1110.1211%2C1110.0162%2C1110.6344%2C1110.4671%2C1110.3311%2C1110.0935%2C1110.4849%2C1110.2650%2C1110.6579%2C1110.3142%2C1110.3727%2C1110.0345%2C1110.4268%2C1110.1452%2C1110.3986%2C1110.2684%2C1110.2028%2C1110.2939%2C1110.1893%2C1110.3075%2C1110.6769%2C1110.5967%2C1110.4745%2C1110.6828%2C1110.3536%2C1110.3446%2C1110.1844%2C1110.5396%2C1110.1534%2C1110.4014%2C1110.3439%2C1110.3711%2C1110.2201%2C1110.5608%2C1110.0887%2C1110.4878%2C1110.4902%2C1110.1988%2C1110.0030%2C1110.0604%2C1110.6618%2C1110.6032%2C1110.4928%2C1110.5708%2C1110.0798%2C1110.4483%2C1110.1728%2C1110.5653%2C1110.2291%2C1110.0556%2C1110.2598%2C1110.1817%2C1110.3130%2C1110.5119%2C1110.6529%2C1110.0334%2C1110.4112%2C1110.1955%2C1110.5104%2C1110.6781%2C1110.3783%2C1110.2556%2C1110.2867%2C1110.2354%2C1110.3470%2C1110.2824%2C1110.4930%2C1110.0990%2C1110.3160%2C1110.1618%2C1110.3598%2C1110.4148%2C1110.0529%2C1110.2254%2C1110.1799%2C1110.3138%2C1110.0912%2C1110.3864%2C1110.5047%2C1110.2945%2C1110.2932%2C1110.5843%2C1110.2122%2C1110.4457%2C1110.4350%2C1110.0337%2C1110.5750%2C1110.6913%2C1110.6930%2C1110.3710%2C1110.6537%2C1110.5982%2C1110.0341%2C1110.1902%2C1110.3997%2C1110.2476%2C1110.2369%2C1110.2480%2C1110.0636%2C1110.4842&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In the query-commit problem we are given a graph where edges have distinct\nprobabilities of existing. It is possible to query the edges of the graph, and\nif the queried edge exists then its endpoints are irrevocably matched. The goal\nis to find a querying strategy which maximizes the expected size of the\nmatching obtained. This stochastic matching setup is motivated by applications\nin kidney exchanges and online dating.\n  In this paper we address the query-commit problem from both theoretical and\nexperimental perspectives. First, we show that a simple class of edges can be\nqueried without compromising the optimality of the strategy. This property is\nthen used to obtain in polynomial time an optimal querying strategy when the\ninput graph is sparse. Next we turn our attentions to the kidney exchange\napplication, focusing on instances modeled over real data from existing\nexchange programs. We prove that, as the number of nodes grows, almost every\ninstance admits a strategy which matches almost all nodes. This result supports\nthe intuition that more exchanges are possible on a larger pool of\npatient/donors and gives theoretical justification for unifying the existing\nexchange programs. Finally, we evaluate experimentally different querying\nstrategies over kidney exchange instances. We show that even very simple\nheuristics perform fairly well, being within 1.5% of an optimal clairvoyant\nstrategy, that knows in advance the edges in the graph. In such a\ntime-sensitive application, this result motivates the use of committing\nstrategies."}, "authors": ["Marco Molinaro", "R. Ravi"], "author_detail": {"name": "R. Ravi"}, "author": "R. Ravi", "links": [{"href": "http://arxiv.org/abs/1110.0990v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1110.0990v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1110.0990v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1110.0990v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "The Query-commit Problem\n\narXiv:1110.0990v1 [cs.DS] 5 Oct 2011\n\nMarco Molinaro\u2217\n\nR. Ravi\n\n\u2020\n\nAbstract\nIn the query-commit problem we are given a graph where edges have distinct probabilities of existing. It is possible to query the edges of the graph, and if the queried\nedge exists then its endpoints are irrevocably matched. The goal is to find a querying\nstrategy which maximizes the expected size of the matching obtained. This stochastic\nmatching setup is motivated by applications in kidney exchanges and online dating.\nIn this paper we address the query-commit problem from both theoretical and\nexperimental perspectives. First, we show that a simple class of edges can be queried\nwithout compromising the optimality of the strategy. This property is then used to\nobtain in polynomial time an optimal querying strategy when the input graph is sparse.\nNext we turn our attentions to the kidney exchange application, focusing on instances\nmodeled over real data from existing exchange programs. We prove that, as the number\nof nodes grows, almost every instance admits a strategy which matches almost all nodes.\nThis result supports the intuition that more exchanges are possible on a larger pool\nof patient/donors and gives theoretical justification for unifying the existing exchange\nprograms. Finally, we evaluate experimentally different querying strategies over kidney\nexchange instances. We show that even very simple heuristics perform fairly well, being\nwithin 1.5% of an optimal clairvoyant strategy, that knows in advance the edges in the\ngraph. In such a time-sensitive application, this result motivates the use of committing\nstrategies.\n\n1\n\nIntroduction\n\nThe theory of matchings is among one of the most developed parts of graph theory and\ncombinatorics [16]. Matchings can used in a variety of situations, ranging from allocation\nof workers to workplaces to exchange of kidney among living donors [22]. However, the\nuncertainty present in most applications is not captured by standard models. In order to\naddress this limitation we consider a stochastic variant of matchings.\nBefore presenting the query-commit problem we describe an application in kidney exchanges which motivates our model. Unfortunately current patients who require a kidney\ntransplant far outnumber the available organs. In the United States alone, more than 84,000\n\u2217\n\u2020\n\nTepper School of Business Carnegie Mellon University, Pittsburgh, PA 15213, USA, molinaro@cmu.edu\nTepper School of Business Carnegie Mellon University, Pittsburgh, PA 15213, USA, ravi@cmu.edu\n\n1\n\n\fpatients were waiting for a kidney in 2010 and 4,268 people in such situation died in 2008\n[27]. However, a distinguished characteristic pertaining to kidney transplants is that they\ncan be carried using the organ of a living donor, usually a relative of the patient. Such\noperations have great potential to alleviate the long waiting times for transplants.\nOne major issue is that many operations cannot be executed due to incompatibility\nbetween a patient and its donor. In order to overcome this, it is important to consider 2-way\nexchanges: Suppose patient A and its willing donor A\u2032 are not compatible and the same\nholds for B and B \u2032 ; however, it is still possible that both patients can receive the required\norgan via transplants from A\u2032 to B and from B \u2032 to A. This situation can be modeled using a\ncompatibility graph, where each node represents a patient/donor pair and edges represent the\ncross-compatibility between such pairs. The set of transplants that maximize the number of\norgans received is then given by a maximum matching in this graph [22, 23].\nHowever, such a model does not take into account uncertainty in the compatibility graph.\nIn practice, preliminary tests such as blood-type and antigen screening are used to determine\nonly the likelihood of cross-compatibility between pairs. Final compatibility can only be\ndetermined using a time-consuming test called crossmatching, which involves combining\nsamples of the recipients' and donors' blood to check their reactivity. Furthermore, such a\ntest must be performed close to the surgery date, since even the administration of certain\ndrugs may affect compatibility [7]. That is, the transplant should be executed as soon as it\nis detected that two patient/donor pairs are determined to be cross-compatible.\nThe kidney exchange application motivates the query-commit problem, which can be\ndescribed briefly as follows. We are given a weighted graph G where the weight pe indicates\nthe probability of existence of edge e. In each time step we can query an edge e of G and\none of the following happen: with probability pe (corresponding to the event that e actually\nexists) its endpoints are irrevocably matched and removed from the graph; with probability\n1 \u2212 pe (corresponding to the event that e does not exist) e is removed from the graph. Notice\nthat at the end of this procedure we obtain a matching in G, dependent on both the choices\nof the queries and the randomness of the edges' existence. In the query-commit problem our\ngoal is to obtain a query strategy that maximizes the expected cardinality of the matching\nobtained.\nOur results. In this paper we address the query-commit problem from both theoretical\nand experimental perspectives. First, we show that a simple class of edges can be queried\nwithout compromising the optimality of the strategy. This result can be used to simplify the\ndecision making process by reducing the search space. In order to illustrate this, we show\nthat employing this property we can obtain in polynomial time an optimal querying strategy\nwhen the input graph is sparse.\nThen we turn our attentions to the kidney exchange application, more specifically on instances for the query-commit problem modeled over real data from existing kidney exchange\nprograms. In this context we are able to prove the following result: as the number of nodes\ngrows, almost every such graph admits a strategy which matches almost all nodes. This result support the intuition that more exchanges are possible on a larger pool of patient/donors\n2\n\n\f[1, 26]. More importantly, it shows the potential gains of merging current kidney exchange\nprograms into a nationwide bank.\nFinally, we propose and evaluate experimentally different querying strategies, again focusing on the kidney exchange application. We show that even very simple heuristics perform\nfairly well. Surprisingly, the best among these strategies are on average within 1.5% of an optimal clairvoyant or non-committing strategy that knows in advance the edges in the graph.\nThis indicates that the committing constraint is not too stringent in this application. Thus,\nin such time-sensitive application, this result motivates the use of committing strategies.\nRelated work. [6] recently introduced a generalization of the query-commit problem which\ncontains the extra constraint that a strategy cannot query too many edges incident on the\nsame node. In addition to kidney exchange, the authors also point out the usefulness of this\nmodel in the context of online dating. Their main result is that a simple greedy querying\nstrategy is a within a factor of 1/4 from an optimal strategy. [15] use a combination of\ntwo strategies in order to obtain an improved approximation factor of 1/3.88. [3] consider a\nfurther extension where edges have values and the goal is to find a strategy that maximize\nthe expected value of the matching obtained. Using an LP-based approach they are able to\nobtain a strategy which is within a constant factor from an optimal strategy.\nWe note, however, that in the case of the query-commit problem (i.e. when there is\nno constraint on the number of edges incident to a node that a strategy can query) every\nstrategy which does not stop before querying all permissible edges is a 1/2-approximation [6].\nThis follows from two easy facts: (i) for every outcome of the randomness from the edges,\nsuch a strategy obtains a maximal matching and (ii) every maximal matching is within a\nfactor of 1/2 from a maximum matching.\nThe query-commit problem is similar in nature to other stochastic optimization problems\nwith irrevocable decisions, such as stochastic knapsack [8] and stochastic packing integer\nprograms [9]. In both [8, 9] the authors present approximation algorithms as well as bounds\non the benefit of using an adaptive strategy versus a non-adaptive one.\nDifferent forms of incorporating uncertainty have been also studied [24] and in particular\nstochastic versions of classical combinatorial problems have been considered in the literature\n[12, 20]. Matching also has its variants which handle uncertainty via a 2-stage model [14]\nor in an online fashion [5, 10, 11, 13, 17, 19]. The latter line of research has been largely\nmotivated by the increasing importance of Internet advertisement.\nThe kidney exchange problem, in its deterministic form, has received a great deal of\nattention in the past few years [1, 21, 22, 23, 26]. In the previous section we argued that 2way exchanges can increase the number of organs transplanted, but of course larger chains of\nexchanges can offer even bigger improvements. Unfortunately, considering larger exchanges\nmakes the problem of finding optimal transplant assignments much harder computationally\neven if all the edges are know in advance [1]. Nonetheless, [1] present integer programming\nbased algorithms which are able to solve large instances of the problem, on scenarios with up\nto 10,000 patient/donor pairs. The authors point out, however, the importance of considering\nother models which take into account the uncertainty in the compatibility graph. Finally,\n3\n\n\f[2, 28, 29] address the dynamic aspect of exchange banks, where the pool of patients and\ndonors evolve over time.\nThe remainder of the paper is organized as follows. In Section 2 we present a more\nformal definition of the query-commit problem as well as multiple ways of seeing the process\nin which matchings are obtained from strategies. Then we prove the important structural\nproperty (Lemma 1) which is used to obtain in polynomial time optimal strategies for sparse\ngraphs (Section 3). Moving to the kidney exchange application, we describe in Section 4 a\nmodel for generating realistic compatibility graphs and prove that, as the number of nodes\ngrows, most of these instances admit strategies which match almost all nodes. In Section 5\nwe address the issue of estimating the value of a strategy as well as computing upper bounds\non the optimal solution, and conclude by presenting experimental evaluation of querying\nstrategies. As a final remark, the proofs of all lemmas which are not presented in the text\nare available in the appendix.\n\n2\n\nPreliminaries\n\nWe use V (G) and E(G) to denote respectively the set of nodes and edges of a given undirected\ngraph G, and use v(G) and e(G) to denote their cardinalities. In addition we use \u03bc(G) to\ndenote the cardinality of the maximum matching in G. We define the neighborhood of a\n.\nnode u as the set N(u) = {v \u2208 G : (u, v) \u2208 G} and the (edge) neighborhood of an edge\n.\n(u, v) as the set N((u, v)) = {(x, y) \u2208 G : {u, v} \u2229 {x, y} =\n6 \u2205}. Notice an edge is included in\nits own neighborhood. We ignore isolated nodes in all subsequent graphs.\nWhen G is a rooted tree, root(G) denotes its root and Gu is the subtree of G which\ncontains u and all of its descendants. When G is a binary tree, we use l(u) and r(u) to\ndenote respectively the left and right children of a node u \u2208 G; we also call Gl(u) and Gr(u)\nrespectively the left subtree and right subtree of node u. The height of a rooted tree is the\nlength (in number of nodes) of the longest path between the root and a leaf.\nThroughout the paper we will be interested in weighted graphs G = (V, E, p) where\np : E \u2192 (0, 1] associates nonzero weights to the edges of G; we refer to them simply as\nweighted graphs. A scenario or realization \u03c3 of G, denoted by \u03c3 \u223c G, is a subgraph of G\nobtained by including each edge e independently with probability pe . Note there can be up\nto 2|E| possible realizations in G.\nNow we describe, somewhat informally, the dynamics of querying strategies. Consider a\nweighted graph G, a scenario \u03c3 \u223c G and a querying strategy S. We start with an empty\nmatching and S makes its first query for an edge e of G. If e \u2208 \u03c3 then e is added to\nthe current matching and we obtain the residual graph (i.e. the set of permissible edges)\nR = G \\ N(e). If e \u2208\n/ \u03c3 then e is not added to the matching and the residual graph is\nR = G \\ e. At this point S queries any other edge of G; usually we focus on the case that\nthe new edge belongs to R, since edges outside R cannot be added to the matching. The\nprocess then continues in the same fashion. We remark that S is oblivious to the scenario \u03c3\nand only uses information from previous queries in order to decide its next query.\nIn order to make this process more precise we use decision trees to represent querying\n4\n\n\fstrategies. In our context, a decision tree T is a binary tree with the following properties:\n(i) each internal node x \u2208 T corresponds to a query for an edge a(x) \u2208 G; (ii) all nodes in\nthe right subtree of x correspond to queries for edges in G \\ N(a(x)); (iii) all nodes in the\nleft subtree of x correspond to queries for edges in G \\ a(x). It is also useful to associate\nto each node x \u2208 T the residual graph Gx in the following recursive way: Groot(T ) = G,\nGr(x) = Gx \\ N(a(x)) and Gl(x) = Gx \\ a(x). Figure 1 presents an example of a decision tree.\nA decision tree T can be interpreted as a querying strategy as follows: First query the edge\na(root(T )) \u2208 G associated to the root of T ; if this query is successful then add a(root(T ))\nto the current matching and proceed querying using the right subtree of root(T ), otherwise\njust proceed querying using the left subtree of root(T ). Hence, the execution of T over a\nscenario \u03c3 induces a path of nodes x1 , x2 , . . . , xk in T , where a(x1 ), a(x2 ), . . . , a(xk ) is the\nsequence of edges queried by T and Gx1 , Gx2 , . . . , Gxk the sequence of residual graphs.\nNotice that, since T only queries permissible edges, the matching obtained is exactly\nthe set of queried edges which belong to \u03c3; this matching is denoted by M(T, G)(\u03c3). After\nunpacking previous definitions, we can also write the random matching M(T, G) recursively\nas follows (where \u03c1 = root(T ) and e = a(root(T )) to simplify the notation): M(T, G) =\ne \u222a M(Tr(\u03c1) , G \\ N(e)) with probability pe and M(T, G) = M(Tl(\u03c1) , G \\ e) with probability\n1 \u2212 pe . Thus, the expected size of M(T, G) is given by\nEM(T, G) = pe (1 + EM(Tr(\u03c1) , G \\ N(e)) + (1 \u2212 pe )EM(Tl(\u03c1) , G \\ e),\n\n(1)\n\nwhere we use EM(T, G) instead of E [|M(T, G)|] to simplify the notation.\nWe remark that every strategy can be represented by a decision tree, so we use T S to\ndenote a decision tree corresponding to a strategy S and use both terms interchangeably.\nMaking use of the above definitions, we can formally state the query-commit problem:\ngiven a weighted graph G = (V, E, p) with p : E \u2192 (0, 1], we want to find a decision tree T\nfor G that maximizes EM(T, G). The value of an optimal solution is denoted by OP T (G).\nWe are interested in finding computationally efficient strategies for the query-commit\nproblem. Since decision trees may be already exponentially larger then the input graph, our\nmeasure of complexity must allow implicitly defined strategies. We say that a strategy is\npolynomial-time computable if the time used to decide the query in each step is bounded by\na polynomial on the description of the input graph; this includes any preprocessing time (i.e.\ntime to construct a decision tree). In Section 3.1 we present structures similar to decision\ntrees that are useful to describe time-efficient strategies.\n\n3\n\nGeneral theoretical results\n\nWe say that an edge of a graph is pendant if at least one of its endpoints has degree 1. As\na start for our theoretical results, we show that pendant edges can be queried first without\ncompromising the optimality of the strategy. This observation will be fundamental for the\ndevelopment of the polynomial-time computable algorithm for sparse graphs and is also used\nin the heuristics tested in the experimental section.\n5\n\n\f(a)\n\n(b)\n1\n\n1\n\n2\n\n3\n\n2\n\n3\n4\n\n4\n3\nl1\n\nl4 l5\n\nl6\n\nl3\nl2\n\nFigure 1: (a) Input graph G with edges labeled from 1 to 4. (b) Example of decision tree\nT for G, with labels corresponding to a(x) for each internal node x of T . Let y denote the\nfather of l3 , so that a(y) = 4; Gy is the subgraph of G consisting of edges 3 and 4. The bold\npath in T is the path obtained by executing T over the scenario \u03c3 which consists of edges 2,\n3 and 4. Moreover, M(T, G)(\u03c3) = {2}.\nLemma 1. Consider a weighted graph G and let e be a pendant edge in G. Then there is\nan optimal strategy whose first query is e.\nIn order to illustrate the relevance of pendant edges we mention the following result.\nLemma 2. Suppose G is a weighted forest and let S be a strategy that always queries a\npendant edge in the residual graph. Then for every \u03c3 \u223c G, |M(S, G)(\u03c3)| = \u03bc(\u03c3).\n\n3.1\n\nOptimal strategies for sparse graphs\n\nWe say that a graph G is d-sparse if e(G) \u2264 v(G)+d. In this section we exhibit a polynomialtime optimal strategy for d-sparse graphs when d is constant. We focus on connected graphs\nbut the result can be extended by considering separately the connected components of the\ngraph.\nSo let G be a connected d-sparse graph and we further assume (for now) that G does not\nhave any pendant edges; the rationale for the latter is that from Lemma 1 we can always\nstart querying pendent edges until we reach a residual graph which has none.\nContracted decision trees. First, we need to introduce the concept of a contracted decision tree (CDT), which generalizes the decision trees introduced in Section 2.\nGiven a strategy S for a weighted graph H we use R(S, H) to denote the set of possible\nresidual graphs after the execution of S, that is, R(S, H) = {H x : x is a leaf of T S }. Then a\ncontracted decision tree T for G is a rooted tree where every node x is associated to a residual\ngraph Gx and every internal node x is associated to a query strategy S x for Gx satisfying\nthe following: (i) Groot(T ) = G; (ii) every internal node x of T has exactly q = |R(S x , Gx )|\nchildren y1 , y2, . . . , yq and R(S x , Gx ) = {Gy1 , Gy2 , . . . , Gyq }; (iii) if x is an ancestor of y in T\nthen S x 6= S y . Figure 2 presents an example of a contracted decision tree.\n6\n\n\f(b)\n\n(a)\n1\n\n2\n\n2\n\n3\n4\n\n(c)\n\n1\n\nl1\u2032\n\nT\u2032\n\nl3\u2032\n\nl4\n\n4\n\nl2\u2032\n\n3\nl1\n\nl3\n\n3\nl5\n\nl6\n\nl2\n\nFigure 2: (a) Input graph G with edges labeled from 1 to 4. (b) A decision tree T \u2032 for the\nsubgraph of G induced by edges 1 and 2. The set R(T \u2032 , G) consists of the graphs G1 , G2\nand G3 , where G1 is the subgraph of G induced by edges 3 and 4, G2 is the empty graph\nand G3 is induced by edge 3. (c) A CDT T\u0304 for G where S root(T\u0304 ) = T \u2032 . The graphs Gx for\nthe children of root(T\u0304 ) are, respectively from left to right, G1 , G2 and G3 . The decision tree\ncorresponding to T\u0304 is T in Figure 1.b. Conversely, T\u0304 can be obtained by contracting T \u2032 in\nT.\nA few remarks are in place. First, condition (iii) is not really fundamental in the definition, although it avoids trivial cases in future proofs. More importantly, notice that a\ndecision tree is simply a CDT where strategy S x queries a single edge of Gx . Also, a CDT\ncan be seen as decision tree where some of its subtrees were contracted into a single node\nand, conversely, we can obtain a decision tree from a contracted decision by expanding the\npartial strategies S x 's into decision trees.\nA CDT T can be interpreted as a strategy in a similar way as in decision trees: start with\nan empty matching at the root \u03c1 = root(T ) and query according to S \u03c1 , which gives a particular residual graph R \u2208 R(S \u03c1 , G\u03c1 ) depending on the current scenario \u03c3; add M(S \u03c1 , G\u03c1 )(\u03c3)\nto the current matching and proceed querying using the subtree Tx , where x is the child of\n\u03c1 with Gx = R. The expected size of the matching obtained by a CDT T can be written in\nan recursive expression similar to (1):\nX\nEM(T, G) = EM(S \u03c1 , G\u03c1 ) +\nPr(Gx ) * EM(Tx , Gx ),\n(2)\nx:x is a child of \u03c1\n\nwhere Pr(Gx ) is the probability with respect to the scenarios of G\u03c1 that the residual graph\nis Gx after employing S \u03c1 to G\u03c1 .\nDecomposition of G and filtering of the strategy space. Now we turn again to the\nproblem of finding an optimal strategy for G. Let V\u22653 be the set of nodes of G which have\ndegree at least 3. Since the nodes in G \\ V\u22653 have degree at most 2, all of its connected\ncomponents are either paths of cycles; moreover, we claim that all of them are actually paths.\nBy means of contradiction suppose a connected component of G \\ V\u22653 is a cycle C. Since G\nis connected, it must contain an edge from a node u \u2208 C to a node in V\u22653 . However, this\nimplies that u has degree at least 3 in G and hence u \u2208 V\u22653 , contradicting the fact C is a\ncomponent of G \\ V\u22653 .\n7\n\n\fIn light of the previous claim it is useful to think about the structure of G is terms of\nV\u22653 and the paths P1 , . . . , Pw that are the connected components of G \\ V\u22653. Notice that the\nedges of G which have an endpoint in V\u22653 are not present in this decomposition; however,\nthere are at most 6d of these edges, which allows us to ignore them for most part of the\ndiscussion of the algorithm. To see this upper bound on the number of such edges first notice\nthat |V\u22653 | \u2264 2d; this holds because G has no pendant edges and hence all of its nodes have\ndegree at least two, so summing over all degrees in G we get\n2e(G) \u2265 3|V\u22653| + 2(v(G) \u2212 |V\u22653 |) \u21d2 |V\u22653 | \u2264 2(e(G) \u2212 v(G)) = 2d.\nThen if \u03b1 is the number of edges with some endpoint in V\u22653 we again add all degrees of G\nto obtain\n2e(G) \u2265 \u03b1 + 2(v(G) \u2212 |V\u22653 |) \u21d2 \u03b1 \u2264 2(e(G) \u2212 v(G)) + 2|V\u22653 | \u2264 6d,\nobtaining the desired bound.\nThis result also leads to a bound on the number of paths Pi 's. To see this, consider a\npath Pi and let u and v be its endpoints. The assumption that G does not have pendant\nedges implies that there are two distinct edges with one endpoint in {u, v} and the other in\nV\u22653 . Since there are at most 6d of these edges in G and since the Pi 's are disjoint, we have\nthat there are at most 3d paths Pi 's.\nExploiting the structure of G highlighted in the previous observations, we can construct\nin polynomial time a CDT which gives an optimal querying strategy. We briefly sketch the\nargument used to obtain this result. The main observation is that after querying an edge e\nin Pi we always obtain a residual graph where some edges in Pi are now pendant. Then we\ncan use Lemma 1 to keep querying pendant edges, which leads to a residual graph that does\nnot contain any edges of Pi . These observations imply that in order to obtain an optimal\nstrategy for G we essentially only need to decide which edge to query first in each Pi , as\nwell as an ordering among these edge and the edges with endpoint in V\u22653 ; all the rest of the\nstrategy follows from querying pendant edges. Moreover, using the fact that there are at\nmost 6d edges with endpoint in V\u22653 and at most 3d paths Pi 's, we can enumerate all these\npossibilities in time poly(e(G)) and obtain the desired result.\nNow we formalize these ideas. Consider a subgraph H of G and consider one of the\npaths Pi 's given by (u1 e1 u2 e2 . . . eq uq+1 ). For an edge e = ej \u2208 H we define S(H, e) as the\nstrategy which queries edges ej , ej\u22121 , . . . , e1 in this order and then queries ej+1 , ej+2, . . . , eq in\nthis order, always ignoring edges which do not belong to H. Essentially S(H, e) is querying\ne first and then edges in Pi which becomes pendant. Notice that there are actually two\nstrategies satisfying the above properties, depending on the orientation of the path Pi ; so we\nfix an arbitrary orientation for the paths Pi 's in order to avoid ambiguities.\nIt follows directly from the definition of S(H, e) that for any residual graph R \u2208 R(S(H, e), H)\nwe have R \u2229 E(Pi ) = \u2205. More specifically, the set of residual graphs R(S(H, e), H) can\nonly contain the following graphs: H \\ {u1, . . . , uq }, H \\ {u2 , . . . , uq }, H \\ {u1 , . . . , uq\u22121}\nand H \\ {u2 , . . . , uq\u22121}. For instance suppose nodes u1 and uq both belong to H; then\n8\n\n\fH \\ {u1 , . . . , uq\u22121 } is the residual graph of the scenario \u03c3 iff u1 is the endpoint of edge in\nM(S(H, e), H)(\u03c3) and uq is not.\nNow the next lemma makes formal the assertion that after querying the first edge of Pi\nwe can just proceed by querying pendent edges.\nLemma 3. Let H be a subgraph of G. Let e be an edge in E(H) \u2229 E(Pi ) and suppose that\nthere is an optimal strategy for H that queries e first. Then there is an optimal CDT for H\nwhose root is associated to the strategy S(H, e).\nNow let F be the family of all CDT's for G and its subgraphs with the following properties.\nA CDT T for a subgraph H of G belongs to F if: (i) T has height at most 9d + 1; (ii) each\nnode x of T is either associated to a strategy which consists of querying one edge incident to\nV (H x )\u2229V\u22653 or it is associated to a strategy S(H x , e) for some Pi and some e \u2208 E(H x )\u2229E(Pi ).\nThe usefulness of this definition comes from the fact that we can focus only on this family\nof CDT's.\nLemma 4. There is an optimal CDT for G which belongs to F .\nThis lemma is formally proved in the Online Supplement, but the structure of the proof\nis the following. First we apply Lemma 3 repeatedly to show the existence of an optimal\nCDT satisfying property (ii) of F . To complete the proof, we make use of the fact that there\nare at most 6d edges incident to V\u22653 and at most 3d paths Pi 's in G to we show that there\nis one such optimal CDT in F satisfying the height requirement (i).\nThe main point in restricting to CDT's in F is that there is only a polynomial number\nof them, as stated in the next lemma.\n2d+1\n\nLemma 5. The family F has at most e(G)4\n\nCDT's.\n\nComputing the value of a tree in F . In light of the previous section, we only need\nfind the best among the (polynomially many) CDT's in F in order to obtain an optimal\nstrategy for G. However, we still need to be able to efficiently calculate the expected size\nof the matching obtained by each such tree. In this section we show that this can be done\nrecursively employing equation (2).\nConsider a CDT T \u2208 F and let x be a node in T . Assume that we have already calculated\nEM(Ty , Gy ) for all proper descendants y of x. To calculate EM(Tx , Gx ) we consider two\ndifferent cases depending of S x .\nCase 1: S x only queries an edge e incident to V\u22653 . As mentioned previously, R(S x , Gx ) =\n{Gx \\ N(e), Gx \\ e}. Since pe is the probability that e belongs to the realization of Gx , we\nhave that EM(S x , Gx ) = pe and the probability that Gx \\ N(e) is the residual graph is also\npe . Therefore, if y1 and y2 are the children of x associated respectively to the residual graphs\nGx \\ N(e) and Gx \\ e, then equation (2) reduces to:\nEM(Tx , Gx ) = pe + pe EM(Ty1 , Gy1 ) + (1 \u2212 pe )EM(Ty2 , Gy2 ).\n\n9\n\n\fAfter inductively obtaining all the terms in right hand side of the previous expression,\nEM(Tx , Gx ) can be computed directly.\nCase 2: S x equals to S(Gx , e). We proceed in the same way as in Case 1, calculating the\nterms of the right hand side of (2). However, these computations are not as straightforward\nas in the previous case. Given a random matching M, let u \u2208 M denote the event that node\nu is matched in M and let u \u2208\n/ M be the complementary event. The following lemma is the\nmain tool used during this section and can be obtained via dynamic programming.\nLemma 6. Consider a path Pi and a subgraph H of G. Also consider an edge e \u2208 E(H) \u2229\nE(Pi ) and define M = M(S(H, e), H). Then there is a procedure which runs in time polynomial in the size of G and computes the values EM, P r(u1 \u2208 M), P r(uq+1 \u2208 M) and\nP r(u1 \u2208 M \u2227 uq+1 \u2208 M).\nThe previous lemma directly gives that EM(S x , Gx ) can be computed in polynomial time,\nso we only need to compute the probabilities that R \u2208 R(S x , Gx ) is the residual graph after\nemploying S x to Gx . For that, let Pi = (u1 e1 u2 e2 . . . eq uq+1 ) be such that e \u2208 Pi . Recall that\nR(S x , Gx ) can only contain graphs from the list: Gx \\ {u1 , . . . , uq+1}, Gx \\ {u2 , . . . , uq+1},\nGx \\ {u1, . . . , uq } and Gx \\ {u2, . . . , uq }. It is easy to see that we can write the probability of\nobtaining each residual graph in R(S x , Gx ) using the probabilities in Lemma 6. For instance,\nthe probability of obtaining Gx \\ {u1 , . . . , uq } is exactly\nP r (u1 \u2208 M(S x , Gx ) \u2227 uq+1 \u2208\n/ M(S x , Gx ))\n= P r (u1 \u2208 M(S x , Gx )) \u2212 P r (u1 \u2208 M(S x , Gx ) \u2227 uq+1 \u2208 M(S x , Gx )) .\nTherefore, Lemma 6 implies that there is an efficient algorithm to compute all terms in\nthe right hand side of equation (2), which gives an efficient way to compute EM(S x , Gx ) as\nin Case 1.\nPutting everything together. Consider a connected d-sparse graph G, possibly containing pendant edges. We define a strategy S for G which proceeds in two steps. First,\nS queries pendant edges until none exists. At this point we have a residual graph G\u2032 with\nno pendant edges. In the second step it queries according to an optimal strategy S \u2032 for G\u2032 .\nApplying Lemma 1 repeatedly, and using the fact that S \u2032 is optimal, we get that S is an\noptimal strategy for G.\nIn order to prove that S is polynomial-time computable we only need to show that S \u2032 is\npolynomial-time computable. To do so, we need the fact that every connected component\nof G\u2032 is d-sparse, which follows from successive applications of the following easy lemma.\nLemma 7. Let G be a connected d-sparse graph. Then for every edge e \u2208 E(G), the\nconnected components of G \\ e and G \\ N(e) are d-sparse.\nLet G\u20321 , . . . , G\u2032k be the connected component of G\u2032 . Since G\u2032i is d-sparse, we can use the\ntools from previous sections to find an optimal strategies Si\u2032 for the G\u2032i : we enumerate at\n9d+1\nmost e(G\u2032i )4\nCDT's for G\u2032i and calculate the value of each of them using the procedure\n10\n\n\foutlined in the previous subsection; then letting Si\u2032 be the strategy among those which has\nlargest value we get that Si\u2032 is optimal for G\u2032i (cf. Lemma 4). Then an optimal strategy S \u2032 for\n\u2032\n\u2032\nG\u2032 is obtained by querying according to strategy SP\n1 , then S2 and so on. Notice that the total\n9d+1\nk\n\u2032\ntime needed to compute the Si 's is bounded by i=1 poly(e(G\u2032i )4 ), which is polynomial\nin e(G) for constant d. Thus, S \u2032 is polynomial-time computable and we obtain the desired\nresult.\nTheorem 1. Let G be a connected weighted graph satisfying e(G) \u2264 v(G) + d for a fixed d.\nThen there is polynomial-time computable optimal strategy for G.\n\n4\n\nTheoretical results for kidney exchanges\n\nNow we focus on the kidney exchange application for the query-commit problem. In this context, weighted graphs are interpreted as weighted compatibility graphs: each node represents\na pair patient/donor and the weight of an edge represents the likelihood of cross-compatibility\nbetween its endpoints. Our main result in this section is to show that the majority of compatibility graphs admits a simple querying strategy that matches essentially all of its nodes.\nIn light of this result, a strong motivation for creating a large unified bank of patient and\ndonors is obtained.\n\n4.1\n\nGenerating weighted compatibility graphs\n\nIn order to make the previous claim formal we need to introduce a distribution of compatibility graphs. In the context of deterministic kidney exchanges, [25] introduced a process\nto randomly generate unweighted compatibility graphs. This process is modeled over data\nmaintained by the United Network for Organ Sharing in order to produce realistic instances\nand several works have considered slight variations of it [1, 21, 22, 25, 26]. Two physiological\nattributes are considered to determine the incompatibility of a patient and a donor. The first\nis their ABO blood type, where a patient is blood-type incompatible with a donor if their\nblood-type pair is one of the following: O/A, O/B, O/AB, A/B, A/AB, B/A and B/AB.\nThe second factor is tissue-type incompatibility and represented by PRA (percent reactive\nantibody) levels. We now briefly describe the process from [25] which generates unweighted\ngraphs and then we mention the slight modification that we use to generate weighted graphs.\nA pair patient/donor is characterized by 5 quantities: the ABO blood type of the patient,\nthe ABO blood type of the donor, the indication if the patient is the wife of the donor, the\nPRA level of the patient and the indication if the patient is compatible with the donor. A\nrandom pair patient/donor is obtained by assigning independently a value for the first four\nquantities and then picking the compatibility depending on these values. The distribution\nof these values is described in detail in [25] and we only highlight one key property:\nFact 1. For every pair of blood types i/j, the probability that a random pair patient/donor\nhas blood type i/j and is incompatible is nonzero.\n\n11\n\n\fIn order to generate an unweighted compatibility graph on n vertices we first sample\nrandom pairs patient/donor until obtaining n incompatible pairs; each pair is added as a\nvertex to the graph. Then for every pair u, v of nodes in the graph, the probability p(u,v) of\ncross-compatibility between them is defined based on their physiological characteristics. A\nkey property is that for any two pairs patient/donor u and v the quantity p(u,v) is nonzero\nif and only if their blood types are cross-compatible (i.e. the patient of u is blood-type\ncompatible with the donor of v and the patient of v is blood-type compatible with the donor\nof u). More specifically, there is a constant c1 < 1 independent of n such that\np(u,v) > 0 \u21d2 p(u,v) \u2265 1 \u2212 c1 .\n\n(3)\n\nTo conclude the construction of the graph, for each pair of nodes u, v a coin is flipped\nindependently and with probability p(u,v) an edge is added between u and v.\nFinally, the modification of the above procedure to generate weighted compatibility\ngraphs consists of changing the last step: if p(u,v) > 0 then the edge (u, v) is added to\nthe graph and p(u,v) becomes its weight.\n\n4.2\n\nAn almost optimal strategy\n\nIn this section we present a simple querying strategy that achieves EM(S, G) \u2248 v(G)/2 for\nalmost all weighted compatibility graphs G generated by the above procedure. To obtain\nsuch strategy we decompose the graph into cliques and complete bipartite graphs based on\nblood-type compatibility. Then we obtain good strategies for these structured subgraphs\nand finally compose them into a strategy for the original graph.\nLet D n be the distribution of weighted compatibility graphs on n nodes generated by\nthe procedure from the previous section. For a graph G in D n we use Vi,j (G) to denote the\nsubset of vertices corresponding to the patient/donor pairs which have blood type i/j. The\nlower case version vi,j (G) is used to denote the cardinality of Vi,j (G).\nConsider a random graph G \u223c D n and a node u of it. The first observation is that the\nprobability that u has patient/donor blood type i/j is equal to\nP r(P/D has blood type i/j | P and D are incompatible),\nwhere P/D is a random pair patient/donor. Using the definition of conditional probability\nand Fact 1 we get that this probability is nonzero. Since we have finitely many blood types,\nthis means that there is a constant c2 independent of i/j and n such that\nP r(u has patient/donor blood type i/j) \u2265 c2 for all i, j.\n\n(4)\n\nThis property, together with the symmetry of blood types of patients and donors, gives the\nfollowing fact.\nFact 2. The following properties hold for every i, j (where the expectation is taken with\nrespect to the distribution D n ):\n12\n\n\f1. E [vi,j ] = \u03a9(n)\n2. E [vi,j ] = E [vj,i ]\nIn order to describe and analyze the proposed querying strategy, we first focus on the\nset of graphs in D n which have a typical number of nodes associated to each pair of blood\ntypes. That is, for \u03b1 > 0 we consider G\u03b1n , which is defined as the set of all graphs G in D n\nwhich satisfy\n(1 \u2212 \u03b1)E [vi,j ] \u2264 vi,j (G) \u2264 (1 + \u03b1)E [vi,j ] .\nWe first show how to obtain good strategies for graphs in G\u03b1n and then argue that most of\nthe graphs in D n are in this family.\nFix \u03b1 \u2208 (0, 1) and consider a graph G in G\u03b1n . Let Gi,j be the induced subgraph G[Vi,j (G)\u222a\nVj,i (G)]. Clearly these subgraphs partition the nodes of G. Moreover, every two nodes in Gi,j\nare blood-type cross-compatible, since a patient is blood-type compatible with a donor with\nthe same blood type. Therefore, the construction of G (and more specifically the properties\nof p(u, v)) implies that Gi,j is a complete bipartite graph if i 6= j and a complete graph if\ni = j. The fact that G \u2208 G\u03b1n and part 2 of Fact 2 additionally give the following: if i 6= j\nthere is complete bipartite subgraph G\u2032i,j of Gi,j with equally sized vertex classes and with\nv(G\u2032i,j ) \u2265 2(1 \u2212 \u03b1)E [vi,j ].\nThe motivation for partitioning G is that there are very simple strategies that work well\nin complete (bipartite) graphs, as shown in the next two lemmas.\nLemma 8. Let G be a weighted complete bipartite graph with k vertices in each vertex class.\nThen for every \u01eb > 0 there is a strategy S such that EM(S, G) \u2265 (1 \u2212 q \u230a\u01ebk\u230b \u2212 \u01eb)k, where\nq = max{1 \u2212 pe : e \u2208 E(G)}.\nThe analogous lemma when G is a clique can be proved by applying the previous lemma\nto a complete bipartite subgraph of G with vertex classes containing \u230av(G)/2\u230b vertices.\nLemma 9. Let G be a weighted complete graph with k vertices. Then for every \u01eb > 0 there\nis a strategy S such that EM(S, G) \u2265 (1 \u2212 q \u230a\u01eb(k\u22121)/2\u230b \u2212 \u01eb) \u230ak/2\u230b, where q = max{1 \u2212 pe : e \u2208\nE(G)}.\n\u2032\nLet Si,j\nbe the strategy given by Lemma 8 for G\u2032i,j and Si be the strategy given by Lemma\n\u2032\n's\n9 for Gi,i . Since the graphs G\u2032i,j 's and Gi,i 's are disjoint, we can apply the strategies Si,j\nand Si 's sequentially and obtain a strategy S for G such that\nX\n1X\n\u2032\nEM(Si,j\n, G\u2032i,j ) +\nEM(Si , Gi,i ),\nEM(S, G) =\n2\ni\ni6=j\n\nwhere the factor 1/2 in the right hand side appears because the graph Gi,j = Gj,i is counted\ntwice. Defining q = max{1 \u2212 pe : e \u2208 E(G)} and employing the bounds from Lemmas 8 and\n9, we have that for every \u01eb > 0\n!\n!\u0016\n\u0016\n\u0016\n\u0017\n\u0017\n\u0017\nv(G\u2032 )\nv(Gi,i )\u22121\nv(G\u2032i,j ) X\n\u01eb 2i,j\n\u01eb\n1X\nv(Gi,i )\n2\nEM(S, G) \u2265\n1\u2212q\n.\n+\n1\u2212q\n\u2212\u01eb\n\u2212\u01eb\n2 i6=j\n2\n2\ni\n13\n\n\fSince G \u2208 G\u03b1n , Fact 2 gives that v(Gi,i ) = vi,j (G) \u2265 (1 \u2212 \u03b1)E [vi,j ] = \u03a9(n) and v(G\u2032i,j ) \u2265\n2(1 \u2212 \u03b1)E [vi,j ] = \u03a9(n). This gives the following asymptotic bound on the quality of strategy\nS (assuming n large enough):\n\"\n#\nX v(G\u2032i,j ) X \u0016 v(Gi,i ) \u0017\n\u0001\nEM(S, G) \u2265 1 \u2212 q \u01eb\u03a9(n) \u2212 \u01eb\n+\n4\n2\ni\ni6=j\n#\n\"\nX (1 \u2212 \u03b1)E [vi,j ] X (1 \u2212 \u03b1)E [vi,i ]\n\u0001\n+\n\u22124\n\u2265 1 \u2212 q \u01eb\u03a9(n) \u2212 \u01eb\n2\n2\ni\ni6=j\n\u0014\n\u0015 \u0010\n\u0015\n\u0011 \u0014 (1 \u2212 \u03b1)n\n\u0001\n(1 \u2212 \u03b1)n\n\u01eb\u03a9(n)\n\u01eb\u03a9(n)\n= 1\u2212q\n\u2212\u01eb\n\u2212 4 \u2265 1 \u2212 c1\n\u2212\u01eb\n\u22124 ,\n2\n2\n\nwhere c1 is satisfies (3). Since c1 < 1 it follows that limn\u2192\u221e EM(S, G)/(n/2) = (1 \u2212\u01eb)(1 \u2212\u03b1)\nand thus S matches almost all nodes of the typical graph G for sufficiently large n.\nNow we argue that most graphs in D n belong to the family G\u03b1n . That is, we want to\nlower bound the probability that a random graph G \u223c D n has values vi,j (G)'s concentrated\naround the expectation.\nConsider a random graph G \u223c D n . Since the blood type of each node of G is chosen\nindependently, vi,j (G) is distributed according to a binomial process of n trials. Therefore, using Hoeffding's inequality [4] we get that the probability that vi,j (G) lies outside\nthe interval [(1 \u2212 \u03b1)E [vi,j ] , (1 + \u03b1)E [vi,j ]] is at most 2 exp(\u22122n3 (c2 \u03b1)2 ), where c2 is the\nconstant in (4). Since there are only 4 blood types, we can employ the union bound to\nestimating the probability that every vi,j (G) is close to its expected value. With this we\nobtain that the probability that the generated compatibility graph belongs to G\u03b1n is at least\n1 \u2212 32 exp(\u22122n3 (c2 \u03b1)2 ), which goes to 1 exponentially fast with respect to n.\nCombining the fact that there is a good strategy for graphs in G\u03b1n with the fact that most\ngraphs of D n belongs to G n gives the desired result.\nTheorem 2. For any \u01eb > 0 there is an n0 (\u01eb) such that the following holds for every\nn \u2265 n0 (\u01eb). Consider a random compatibility graph G \u223c D n . Then with probability 1 \u2212 \u01eb\nover the distribution of G there is a polynomial-time computable strategy S which achieves\nEM(S, G) \u2265 (1 \u2212 \u01eb)n/2.\n\n5\n\nComputational results\n\nIn this section we present an experimental evaluation of the performance of simple querying\nstrategies. During our tests, we decided to focus on the application of the query-commit\nproblem to kidney exchanges and therefore all weighted graphs used in the tests were generated randomly according to the procedure described in Section 4.1. The results show\nthat practical heuristics perform surprisingly well, even when compared to optimal noncommittting strategies. As a preparation to our experimental results, we first address the\nissue of estimating the value of a strategy and estimating an upper bound on OP T .\n14\n\n\f5.1\n\nEstimating the value of a strategy\n\nSection 3.1 already indicated that it is not a trivial task to calculate this value exactly.\nGiven a weighted graph G and a strategy S, the direct way of calculating EM(S, G) involves\nfinding M(S, G)(\u03c3) for every scenario \u03c3 \u223c G. However, there is often an exponential (in\ne(G)) number of such scenarios. When S is given as a decision tree T S we can compute\nEM(S, G) using the recurrence (1); but again this procedure takes time proportional to the\nnumber of nodes in T S , which can be exponential in e(G) and is therefore also impractical.\nDespite previous studies on the query-commit and related problems [6, 8, 9], there is\ncurrently no efficient algorithm to compute the expected value of a strategy and most results\nrely on an estimation of this value by sampling a subset of the scenarios. Our goal in this\nsection is to address how well we can estimate EM(S, G) by sampling from G and establish\nthe accuracy as function of the number of samples.\nGiven a weighted graph G on n nodes and a strategy S, the natural way to obtain an\nunbiased estimation\nPk of EM(S, G) is to sample independently k scenarios \u03c31 , . . . , \u03c3k \u223c G and\ntake \u03b7 = (1/k) i=1 |M(S, G)(\u03c3i )| as the estimate. Clearly E [\u03b7] = EM(S, G). Moreover,\nsince |M(S, G)(\u03c3i )| \u2208 [0, n/2] for all i we also have that \u03b7 \u2208 [0, n/2]. In order to show that\n\u03b7 is concentrated around the expectation we can simply employ Hoeffding's inequality to\nobtain that for every t \u2265 0\n\u0012\n\u0013\n8kt2\nP r (|\u03b7 \u2212 EM(S, G)| \u2265 t) \u2264 2 exp \u2212 2 .\n(5)\nn\nAccording to this expression, we need approximately 0.4611n2 /t2 samples in order to obtain\na 95% confidence interval equal to EM(S, G) \u00b1 t.\nNotice that the previous bound does not use much of the structure of the matchings. In\nparticular, (5) relies solely on the fact that the size of the matchings lie in [0, n/2]. However,\nthis simple concentration estimate is essentially best possible. This holds because we can\nconstruct a graph and a strategy S for it which obtains a small matching half of the time\nand a large matching half of the time. The variance on the size of the matching obtained\nby S is then essentially as large as possible when compared to any random variable taking\nvalues in [0, n/2]; in such case, Hoeffding's inequality is rather tight. More formally, we have\nthat following lemma.\nLemma 10. There is a graph G on n nodes and a strategy S for querying G such that\n\u0012\n\u0013\n64kt2\n2\nexp \u2212 2\nP r (|\u03b7 \u2212 EM(S, G)| \u2265 t) \u2265\n15\nn\nfor all t \u2264 n/16.\n\n5.2\n\nUpper bound on OP T\n\nClearly the size of a maximum cardinality matching in G is an upper bound on OP T (G),\nsince the maximum matching in any realization of G has size at most \u03bc(G). However, this\n15\n\n\fbound can be made arbitrarily weak by considering small edge weights, e.g. G is a set of\ndisjoint edges, each with weight p, so \u03bc(G) = e(G) but OP T (G) = p * e(G).\nNotice that actually OP T can be upper bounded by the expected size of the maximum\n.\nmatching over the realizations of G; that is, for \u03c3 \u223c G we have OP T (G) \u2264 E [\u03bc(\u03c3)] = E [\u03bc].\nThis bound is tighter than \u03bc(G) and, as Section 5.3 supports, is oftentimes very close to\nOP T (G). An important remark is that E [\u03bc] is a valid upper even for the non-commit or\nclairvoyant version of the problem, where the strategy can first find out exactly the edges\nin the realization and then decide which matching to take. Again we encounter the issue of\ncalculating or at least estimating E [\u03bc].\nEstimating E [\u03bc]. Clearly the sample average estimator used in the previous section can\nalso be used to estimate E [\u03bc] and the Hoeffding-based bound still holds. However, we can\nget substantially better concentration results by bounding the variance of the estimate more\ncarefully. We make use of this tighter concentration to reduce the computational effort to\nestimate the upper bound on OP T .\nAgain consider a weighted graph G on n nodes\nPk and m edges and consider k independent\nscenarios \u03c31 , . . . , \u03c3k \u223c G. We take \u03b7 = (1/k) i=1 \u03bc(\u03c3i ) as the estimation of E [\u03bc], since\nclearly E [\u03b7] = E [\u03bc]. Our goal now is to bound the variance of \u03c3i , which will then be used\nto provide tighter concentration results for \u03b7. For that we need to introduce the concept of\nself-bounding functions.\nA nonnegative function g : X d \u2192 R is self-bounding if there exist functions gi : X d\u22121 \u2192 R\nsuch that for all x1 , . . . , xd \u2208 X the following hold:\n0 \u2264 g(x1 , . . . , xd ) \u2212 gi (x1 , . . . , xi\u22121 , xi+1 , . . . , xd ) \u2264 1 for all i = 1, . . . , d\nand\n\nd\nX\n\n[g(x1 , . . . , xd ) \u2212 gi (x1 , . . . , xi\u22121 , xi+1 , . . . , xd )] \u2264 g(x1 , . . . , xd )\n\ni=1\n\nThe following lemma motivates the definition of self-bounding functions.\nLemma 11 ([4]). Suppose g : X d \u2192 R is a measurable self-bounding function. Let X1 , . . . , Xd\nbe independent random variables with support on X and let Z = g(X1, . . . , Xd ). Then\nVar[Z] \u2264 E [Z] .\nThe connection between the previous lemma and our goal of estimating Var[\u03bc(\u03c3i )] comes\nfrom the fact that \u03c3i can be seen as e(G) independent indicator random variables for the\nedges of G and \u03bc(\u03c3i ) can be see as a self-bounding function. To make this precise let\ne1 , e2 , . . . , em be the edges of G and let X1 , X2 , . . . , Xm be independent Bernoulli random\nvariables with P r(Xi = 1) = pei . Also, for an indicator vector x \u2208 {0, 1}m of the edges of\nG, let \u03bc\u2032 (x) be the size of the maximum matching in the subgraph of G induced by x (i.e.\nwhich contains the edge ei iff xi = 1). It is easy to see that \u03bc\u2032 (X1 , X2 , . . . , Xm ) = \u03bc(\u03c3i ) and\nthe next lemma asserts that \u03bc\u2032 (.) is self-bounding.\n16\n\n\fLemma 12. The function \u03bc\u2032 (.) is self-bounding.\nSince \u03bc(\u03c3i ) = \u03bc\u2032 (X1 , . . . , Xm ), Lemma 11 gives the desired bound Var[\u03bc(\u03c3i )] \u2264 E [\u03bc(\u03c3i )] \u2264\nn/2. Now that we have a handle on this\nPkvariance, we can evoke Bernstein's inequality [4] to\nbound the concentration of \u03b7 = (1/k) i=1 \u03bc(\u03c3i ) as follows:\n\u0012\n\u0013\nkt2\nP r (|\u03b7 \u2212 E [\u03bc]| \u2265 t) \u2264 2 exp \u2212\n.\n(6)\nn + 2t/3\nWhen compared to (5), the lack of an extra term 1/n in the exponent makes (6) a much\nstronger bound.\n\n5.3\n\nComparison of heuristics\n\nIn this section we present experimental results comparing simple querying strategies over\nrandom weighted compatibility graphs. All strategies use to some extent an optimization\nbased on Lemma 1, that is, they query pendant edges first if one exists. The heuristics\nconsidered in the experiments are described next.\nMaximum probability. This strategy first queries pendant edges in the residual graph.\nIn case none exists, it queries the edge with highest weight.\nMinimum probability. Similar to the previous strategy but edges are queried by decreasing weights.\nMinimum degree. This strategy first queries pendant edges in the residual graph. In case\nnone exists, it queries the edge which has minimum degree in the residual graph, where\nthe degree of an edge is defined as the sum of the degrees of its endpoints.\nMinimum average degree. The average degree of an edge (u, v) is defined as the sum of\nthe weights of edges incident to u plus the sum of the weights of edges incident to v.\nThis strategy first queries pendant edges in the residual graph. In case none exists, it\nqueries the edge which has minimum average degree in the residual graph.\nBatch successive matching. First, this strategy queries pendant edges in the residual\ngraph. After no more pendant edges exist, it finds a maximum cardinality matching\nin the residual graph. Then it queries all the edges in this matching in an arbitrary\norder. After all these edges are queried the process is repeated.\nBatch successive weighted matching. Similar to the previous strategy, but now in each\nround it computes a maximum weighted matching with edge weights 1 \u2212 p.\nSuccessive weighted matching q. First, this strategy queries pendant edges in the residual graph. After no more pendant edges exist, it finds a maximum weighted matching\n(with edge weights 1 \u2212 p) in the residual graph. Then it queries one arbitrary edge in\nthis matching. The process is then repeated.\n17\n\n\fmaxP\n24.91\n22.43\n18.64\n16.36\n19.51\n22.74\n24.16\n21.36\n25.39\n22.87\n21.83\n\nminP\n26.52\n23.25\n19.03\n15.57\n21.36\n23.20\n24.38\n22.07\n26.06\n21.56\n22.30\n\nminDeg\n26.83\n24.07\n19.11\n16.62\n20.69\n23.53\n25.02\n23.18\n27.20\n23.61\n22.98\n\nminAvgDeg\n28.21\n24.99\n19.53\n16.79\n22.22\n25.14\n26.44\n24.30\n27.98\n24.06\n23.97\n\nbatchSM\n25.81\n22.69\n18.87\n16.49\n20.06\n23.20\n24.54\n22.41\n26.11\n23.06\n22.32\n\nbatchWSM\n26.92\n23.69\n19.24\n16.56\n21.06\n24.00\n25.33\n23.15\n26.79\n23.47\n23.02\n\nSWMq\n27.68\n24.41\n19.36\n16.67\n21.86\n24.77\n26.08\n23.90\n27.47\n23.81\n23.60\n\nSWMp\n26.65\n23.93\n19.17\n16.75\n20.17\n24.02\n25.28\n23.68\n26.63\n23.60\n22.99\n\nE [\u03bc]\n28.71\n25.51\n19.82\n16.85\n22.56\n25.64\n26.82\n24.66\n28.43\n24.43\n24.34\n\nTable 1: Comparison of different strategies. Each row corresponds to an instance, except\nthe last one which reports the average value of each the strategy over all instances.\nSuccessive weighted matching p. Similar to the previous strategy, but the edge weights\nused in the maximum weighted matchings are simply p.\nThe instances used in the experiments consist of random weighted compatibility graphs\non 100 nodes, generated as described in Section 4.1. Simulating exchange pools with 100\npatient/donor pairs is optimistic but not unrealistic, as pointed out in [21]. We also carried\nexperiments in graphs with fewer than 100 nodes, but these graphs did not seem to be large\nenough to discriminate the querying strategies.\nIn order to estimate the value of each strategy we employed the sample average estimation\ndiscussed in Section 5.1. For each execution, we used 38,000 samples in order to obtain a\ngood estimate; according to inequality (5), with 0.95 probability, the estimate is within \u00b10.35\nof the actual expected matching obtained by the strategy. In order to obtain an estimated\nupper bound on OP T we used the sample average of E [\u03bc] as described in Section 5.2. The\nnumber of samples was chosen to obtain an estimate which is within \u00b10.1 of E [\u03bc] with\nprobability 0.95.\nThe results of the experiments are presented in Table 1. The first eight columns correspond to the strategies in the same order as they were described and the last column presents\nthe upper bound E [\u03bc] on OP T . In each row, except the last one, we present the estimated\nvalue of the strategies on a given instance. The last row of the table indicates the average\nvalue of each strategy over all instances.\nTable 1 shows that all these simple strategies perform very well. Surprisingly, these\nheuristics are actually close to optimal clairvoyant strategies, since E [\u03bc] is a valid upper\nbound for the non-commit version of this problem as well. These results indicate that, for\nthe kidney exchange application, the commit requirement in the formulation of the problem\nis not too restrictive, in that good solutions are still obtainable under this constraint. Notice\nthat strategy minAvgDeg in particular outperforms all others in every instance of the test\n18\n\n\fFigure 3: Sample average estimates of the value of minAvgDeg on the first instance of the\ntest set as a function of the number of samples. The horizontal axis indicates the number of\nsamples divided by 100.\nset. Moreover, its value stays always relatively close to the upper bound E [\u03bc], being on\naverage within 1.5%.\nA caveat to these results is that the confidence interval of \u00b10.35 for the value of the\nstrategies does not allow complete discrimination among the best performing heuristics.\nThe confidence intervals obtained from (5), due to its generality, seems to be much looser\nthan the actual bounds on the estimates. This is reinforced by Figure 3, which displays the\nsample average as a function of the number of samples; notice that with 2,500 samples the\nestimate already starts oscillating closely around the reported value of 28.21. We remark\nthat a similar convergence profile holds for the other strategies tested.\n\n6\n\nConclusions and future work\n\nIn this paper we considered the query-commit problem, a model for matchings which incorporates uncertainty on the edges of the graph in a way that is suitable for time-sensitive\napplications. By using the fact that some edges of the graph can be queried without compromising optimality, we show how to obtain an optimal querying strategy for sparse graphs\nin polynomial time. However, the dependency on the sparsity of the graph is doubly exponential. An interesting open question is to improve this running time, which may indirectly\nreveal other important properties of optimal strategies. On a similar note, another open\n\n19\n\n\fquestion is to prove lower bounds on the computational complexity needed for finding optimal strategies in general graphs.\nIn Section 5 we evaluated querying strategies over instances of the kidney exchange application and showed that even simple heuristics perform surprisingly well, even when compared\nto non-committing strategies. An important open question is designing a procedure which is\nable to provide even better strategies, possibly by starting with a heuristic and successively\nimproving it (e.g. in a local search fashion). However, two hindrances for such procedures are\nthe lack of an algorithm to compute the value of a strategy and the difficulty in representing\nstrategies. As noted previously, the size of a decision tree may be exponential in the size of\nthe input graph.\nAnother possibility is to extend the current model to even more realistic setups. For\ninstance, one could consider correlated uncertainty on the edges. In the context of kidney\nexchanges, the uncertainty on the PRA level of a node introduces correlated uncertainty on\nall edges incident to it. In addition, recent works in deterministic kidney matchings have\nconsidered not only 2-way exchanges but also longer chains of exchanges [1, 21], yielding\nadditional transplants. A direction for future research is to study a suitable modification of\nthe query-commit problem which can model uncertainty on longer exchanges.\nFinally, Theorem 2 indicates the potential of large kidney exchange programs. It would\nbe of great value to obtain a more precise assessment of this potential and to address the\nlogistic problems associated to nationwide transplant programs.\nAcknowledgments. We thank Tuomas Sandholm, Willem-Jan van Hoeve and David\nAbraham for helpful discussions.\n\nReferences\n[1] David J. Abraham, Avrim Blum, and Tuomas Sandholm. Clearing algorithms for barter\nexchange markets: enabling nationwide kidney exchanges. In ACM Conference on\nElectronic Commerce, pages 295\u2013304, 2007.\n[2] P. Awasthi and T. Sandholm. Online stochastic optimization in the large: application\nto kidney exchange. In IJCAI, pages 405\u2013411, 2009.\n[3] N. Bansal, A. Gupta, V. Nagarajan, and A. Rudra. When lp is the cure for your\nmatching woes: Approximating stochastic matchings, 2010. arXiv:1003.0167v1 [cs.DS].\n[4] St\u00e9phane Boucheron, G\u00e1bor Lugosi, and Olivier Bousquet. Concentration inequalities.\nIn Advanced Lectures on Machine Learning, pages 208\u2013240, 2003.\n[5] N. Buchbinder, K. Jain, and J. Naor. Online primal-dual algorithms for maximizing\nad-auctions revenue. In ESA, 2007.\n[6] Ning Chen, Nicole Immorlica, Anna R. Karlin, Mohammad Mahdian, and Atri Rudra.\nApproximating matches made in heaven. In ICALP (1), pages 266\u2013278, 2009.\n20\n\n\f[7] May 2010.\n[8] Brian C. Dean, Michel X. Goemans, and Jan Vondr\u00e1k. Approximating the stochastic\nknapsack problem: The benefit of adaptivity. In FOCS, pages 208\u2013217, 2004.\n[9] Brian C. Dean, Michel X. Goemans, and Jan Vondr\u00e1k. Adaptivity and approximation\nfor stochastic packing problems. In SODA '05: Proceedings of the sixteenth annual\nACM-SIAM symposium on Discrete algorithms, pages 395\u2013404, Philadelphia, PA, USA,\n2005. Society for Industrial and Applied Mathematics.\n[10] J. Feldman, A. Mehta, V. Mirrokni, and S. Muthukrishnan. Online stochastic matching:\nBeating 1-1/e. FOCS, pages 117\u2013126, 2009.\n[11] G. Goel and A. Mehta. Online budgeted matching in random input models with applications to adwords. In SODA, 2008.\n[12] F. Grandoni, A. Gupta, S. Leonardi, P. Miettinen, P. Sankowski, and M. Singh. Set\ncovering with our eyes closed. In FOCS, pages 347\u2013356, 2008.\n[13] R. Karp, U. Vazirani, and V. Vazirani. An optimal algorithm for on-line bipartite\nmatching. In STOC, 1990.\n[14] I. Katriel, C. Kenyon-Mathieu, and E. Upfal. Commitment under uncertainty: Twostage stochastic matching problems. Theoretical Computer Science, 408(2-3):213\u2013223,\n2008.\n[15] J. Li and J. Mestre. Improved bounds for stochastic matching, 2010. arXiv:1002.3763v1\n[cs.DS].\n[16] L. Lovasz and M. Plummer. Matching Theory. North-Holland, 1986.\n[17] M. Mahdian, H. Nazerzadeh, and A. Saberi. allocating onlinne advertisement space\nwith unreliable estimates. In EC, 2007.\n[18] Jiri Matousek and Jan Vondrak. The Probabilistic Method, Lecture Notes. March 2008.\nManuscript.\n[19] A. Mehta, A. Saberi, U. Vazirani, and V. Vazirani. Adwords and generalized online\nmatching. Journal of the ACM, 54(2), 2007.\n[20] E. Nikolova, J. Kelner, M. Brand, and M. Mitzenmacher. Stochastic shortest paths via\nquasi-convex maximization. In ESA, pages 552\u2013563, 2006.\n[21] A. E. Roth, T. Sonmez, and M. U. Unver. Efficient kidney exchange: Coincidence of\nwants in a market with compatibility-based preferences. American Economic Review,\n97(3):828\u2013851, 2007.\n\n21\n\n\f[22] A. E. Roth, T. Sonmez, and U. Unver. Kidney exchange. Quartely Journal of Economics,\n119(2):457\u2013488, 2004.\n[23] A. E. Roth, T. Sonmez, and U. Unver. Pairwise kidney exchange. Journal of Economic\nTheory, 125(2):151\u2013188, 2005.\n[24] A. Ruszczynski and A. Shapiro. Handbooks in Operations Research and Management\nScience: Stochastic Programming. Elsevier, 2003.\n[25] S. L. Saidman, A. E. Roth, T. Sonmez, M. U. Unver, and F. L. Delmonico. Increasing\nthe opportunity of live kidney donation by matching for two and three way exchanges.\nTransplantation, 81(5):773\u2013782, 2006.\n[26] D. Segev, S. Gentry, D. Warren, B. Reeb, and R. Montgomery. Kidney paired donation\nand optimizing the use of live donor organs. the Journal of the American Medical\nAssociation, 293(15):1883\u20131890, 2005.\n[27] United network for organ sharing, May 2010.\n[28] U Unver. Dynamic kidney exchange. Review of Economic Studies, 77(1):372\u2013414, 2010.\n[29] S. Zenios. Optimal control of a paired-kidney exchange program. Management Science,\n48(3):328\u2013342, 2002.\n\nA\nA.1\n\nProofs for Section 3\nProof of Lemma 1\n\nLet S \u2217 be an optimal strategy for G and consider the strategy S which first queries e and then\nproceeds exactly as S \u2217 . We clarify what happens in the following situation: the realization\n\u03c3 contains both e and another edge e\u2032 incident to e, and M(S \u2217 , G)(\u03c3) contains e\u2032 . Clearly S\nadds e to the matching in the first step and cannot add e\u2032 while simulating S \u2217 ; in this case,\nS still probes e\u2032 whenever S \u2217 does so and adapts accordingly, although e\u2032 is not added to\nthe matching.\nWe claim that S is optimal, which proves the lemma. The definition of S leads to\nthe following observations. If e does not belong to the realization \u03c3 then M(S, G)(\u03c3) =\nM(S \u2217 , G)(\u03c3). On the other hand, if e belongs to \u03c3 then: (i) the kth edge queried by S is\nexactly the (k \u2212 1)th edge queried by S \u2217 (the minus 1 comes from the fact that S queries\ne before simulating S \u2217 ) and (ii) every edge added by S \u2217 to the matching M(S \u2217 , G)(\u03c3) is\nalso added to the matching M(S, G)(\u03c3), the only possible exception being a single edge e\u2032\nof M(S \u2217 , G)(\u03c3) incident to e; since e is pendant, M(S \u2217 , G)(\u03c3) contains at most one edge\nincident to e. In the worst case M(S, G)(\u03c3) contains the edges in M(S \u2217 , G)(\u03c3) \u222a {e} \\ {e\u2032 }\nand we still have |M(S, G)(\u03c3)| \u2265 |M(S \u2217 , G)(\u03c3)|.\nTogether, these observations imply that EM(S, G) \u2265 EM(S \u2217 , G) and hence S is optimal.\n22\n\n\fA.2\n\nProof of Lemma 2\n\nLet x1 , x2 , . . . , xk be the path of T S induced by its execution over the scenario \u03c3. By definition\nof S, a(xi ) is pendant in the graph Gxi .\nBy means of contradiction suppose that M(S, G)(\u03c3) is not a maximum matching in \u03c3,\nnamely there is a matching M \u2217 in \u03c3 such that |M(S, G)(\u03c3)| < |M \u2217 |. Then from Berge's\nLemma [16] there must be an augmenting path P in \u03c3 with respect to M(S, G)(\u03c3) and M \u2217 .\nLet a(xi ) be an edge of P queried by T S . As mentioned in Section 2, M(T S , G)(\u03c3) =\n{a(x1 ), a(x2 ), . . . , a(xk )} \u2229 \u03c3, and since a(xi ) \u2208 P \u2286 \u03c3 we have that a(xi ) belongs to\nM(T S , G)(\u03c3). Then, since P is augmenting, there are two edges e, e\u2032 \u2208 P which are incident to a(xi ) and belong to M \u2217 . But since a(xi ) is a pendant edge of Gxi , it must be that\neither e or e\u2032 does not belong to Gxi and without loss of generality we assume the former.\nThe construction of Gxi implies that there is an edge a(xj ) with j < i such that a(xj ) \u2208 \u03c3\nand a(xj ) is incident to e.\nSince a(xj ) \u2208 \u03c3, we know that a(xj ) also belongs to M(T S , G)(\u03c3). Since M(T S , G)(\u03c3) is\na matching, it follows that a(xj ) is not incident to an internal node of P and hence it must\nbe incident to the endpoint of e which is also an endpoint of P . However, this contradicts\nthe fact that P is an augmenting path, which completes the proof of the lemma.\n\nA.3\n\nProof of Lemma 3\n\nFor each R \u2208 R(S(H, e), H) let T R be an optimal decision tree for R. Consider the natural\n\u2032\nCDT T \u2032 for H which has S root(T ) = S(H, e) and the children of root(T \u2032 ) are the trees T R 's.\nWe claim that T \u2032 is optimal for H. To argue that, let T be the decision tree corresponding\nto T \u2032 . Using the correspondence between CDT's and decision trees, it suffices to prove that\nT is an optimal decision tree for H.\nS\nWe prove that Tx is an optimal decision tree for H x , for every node x \u2208 T \\ R T R ; this\nR\nis done by reverse induction on the depth of x in T . The fact that the trees\nS T R are optimal\nremoves the necessity of a separate base case, so consider a node x \u2208 T \\ R T and assume\nthat Tr(x) is optimal for H r(x) and Tl(x) is optimal for H l(x) . By the definition of S we have\nthat a(x) is pendant in H x . Therefore, Lemma 1asserts that there is an optimal decision\ntree for H x whose root queries edge a(x). Then it is easy to see that the optimality of Tr(x)\nand Tl(x) implies that actually Tx is one such optimal decision tree for H x , which concludes\nthe inductive step and the proof of the lemma.\n\nA.4\n\nProof of Lemma 4\n\nFirst let us relax the definition of F by defining F + as follows. A CDT T for a subgraph H\nof G belongs to F + if each node x of T is either associated to a strategy which consists of\nquerying one edge incident to V (H x ) \u2229 V\u22653 or it is associated to a strategy S(H x , e) for some\nPi and some e \u2208 E(H x ) \u2229 E(Pi ). Notice F is the set of CDT's in F + which have height at\nmost 9d + 1.\nClaim 1. There is an optimal CDT for G which belongs to F + .\n23\n\n\fProof. We prove that for each subgraph H of G there is an optimal CDT for H in F + . We\nproceed by induction on the number of edges of the subgraph, with trivial base case for\nsubgraphs with no edges.\nConsider a subgraph H of G with at least one edge and let T \u2217 be an optimal querying\nstrategy for it. Suppose that the first edge e queried by T \u2217 is incident to V\u22653 . For each\n\u2217\nR \u2208 R(S root(T ) , H) let T R \u2208 F + be an optimal CDT for R, the existence of which is given\nby the inductive hypothesis. Then define the decision tree T for H as follows: its root\nqueries edge e and the subtrees of root(T ) are the trees {T R }. Using the recursive equation\nfor EM(T, H) (equation (2) in the main paper) it is easy to see that the optimality of the\ntrees {T R } implies that EM(T, H) \u2265 EM(T \u2217 , H) and hence T is optimal. Moreover, T\nclearly belongs to F + , which concludes the inductive step in this case.\nNow suppose that e is not incident to V\u22653 ; this implies that e belongs to a path Pi .\nLet T \u2217 be an optimal CDT for H whose root is associated to S(H, e), whose existence is\nguaranteed by Lemma 3. Again, for each R \u2208 R(S(H, e), H) let T R \u2208 F + be an optimal\nCDT for R. Now we construct the CDT T from T \u2217 by replacing the subtrees of root(T \u2217 ) by\nthe trees {T R }. As in the previous case, the optimality of the trees {T R } implies that T is\noptimal and also we have that T \u2208 F + . This concludes the inductive step and the proof of\nthe lemma.\nProof of Lemma 4. Let T \u2208 F + be an optimal CDT for G with the minimum number of\nnodes. We claim that T has height at most 9d + 1.\nBy means of contradiction suppose not and consider a path Q from root(T ) to one of\nits leaves which has more than 9d internal nodes. Since there are at most 6d edges incident\nto V\u22653 and at most 3d paths Pi 's in G, this means that either: (i) two nodes in Q query\nthe same edge incident to V\u22653 or (ii) two nodes x, x\u2032 in Q are associated to two strategies\n\u2032\nS(Gx , e) and S(Gx , e\u2032 ), where both e and e\u2032 belong to the same path Pi . Case (i) is forbidden\nby the definition of a CDT, so we consider case (ii).\nWithout loss of generality assume that x is closer to the root of T than x\u2032 . Notice\n\u2032\n\u2032\nthat by the definition of S(Gx , e\u2032 ) we have that e\u2032 \u2208 E(Gx ) \u2229 E(Pi ). Now we use the\nfact that S(Gx , e) removes all edges in Pi , that is, for every R \u2208 R(S(Gx , e), Gx ) we have\n\u2032\nE(R) \u2229 E(Pi ) = \u2205. But the fact that x\u2032 is a descendant of x implies that Gx is a subgraph of\n\u2032\na residual graph in R(S(Gx , e), Gx ) and hence E(Gx ) \u2229 E(Pi ). This contradicts a previous\n\u2032\nobservation that e\u2032 \u2208 E(Gx ) \u2229 E(Pi ), which implies that T has height at most 9d + 1 and\nconcludes the proof of the lemma.\n\nA.5\n\nProof of Lemma 5\n\nConsider a tree T \u2208 F ; we claim that each node in T has at most 4 children. Equivalently,\nif x is a node in T we want to upper bound |R(S x , Gx )|. If x is associated to a strategy\nS(Gx , e) then as noted previously we have that |R(S x , Gx )| \u2264 4. Now if x is associated to\na strategy that only queries one edge e incident to V\u22653 then, as in standard decision trees,\nR(S x , Gx ) = {Gx \\ N(e), Gx \\ e}. It follows that the outdegree of each tree in F is at most\n4.\n24\n\n\fSince a tree in F has height at most 9d + 1, the previous degree bound imply that each\nsuch tree has at most 49d+1 nodes. Now notice that each node has one of e(G) possible\nstrategies, because the strategies S x 's allowed in F are uniquely determined by the choice of\n9d+1\nan edge. These observations imply that there are at most e(G)4\ntrees in F .\n\nA.6\n\nProof of Lemma 6\n\nLet Pi = (u1 e1 u2 e2 . . . eq uq+1 ) and let Sab denote the strategy which queries edges {ek }bk=a \u2229H\nin order of the indices from a to b. That is, if a < b then Sab queries the edges ea , ea+1 , . . . , eb\nand if a > b then it queries edges ea , ea\u22121 , . . . , eb , always ignoring edges outside H. To\n.\nsimplify the notation define the random matching Mab = M(Sab , H) and without ambiguity\nwe use Mab to also denote the random variable |Mab | corresponding to its cardinality.\nFirst we prove that we can compute in polynomial time the following quantities corresponding to Sa1 , for all a \u2265 1: E [Ma1 |e1 \u2208 Ma1 ], E [Ma1 |e1 \u2208\n/ Ma1 ] and P r(e1 \u2208 Ma1 ); then we\nshow how to use this information to compute the values required by the lemma.\nWe proceed in a dynamic programming fashion. First, it is trivial to compute the quantities associated to S11 and now we want to compute the quantities associated Sa1 assuming\nthat those for the Sa1\u2032 's with a\u2032 < a have already been computed. It is not difficult to see\nthat\ni\nh\ni\u0011\n\u0010\nh\ni\nh\n1\n1\n1\n1\n1\n1\nE Ma e1 \u2208 Ma = pea 1 + E Ma\u22122 e1 \u2208 Ma\u22122 + (1 \u2212 pea ) E Ma\u22121 e1 \u2208 Ma\u22121 .\nMoreover, the analogous expression with complementary conditionings also holds:\ni\nh\ni\u0011\n\u0010\nh\ni\nh\n1\n1\n1\n1\ne1 \u2208\n/ Ma\u22121\n.\ne1 \u2208\n/ Ma\u22122\n+ (1 \u2212 pea ) E Ma\u22121\n/ Ma1 = pea 1 + E Ma\u22122\nE Ma1 e1 \u2208\n\n1\n1\nFinally, we also have P r(e1 \u2208 Ma1 ) = pe1 P r(e1 \u2208 Ma\u22122\n) + (1 \u2212 pe1 )P r(e1 \u2208 Ma\u22121\n). All these\n1\n1\nexpressions can be easily computed using the information about Sa\u22121 and Sa\u22122 available by\nthe dynamic programming hypothesis, concluding the proof of our claim.\nBy suitably relabeling the edges ek , the above result implies that we can also compute\nE [Maq |eq \u2208 Maq ], E [Maq |eq \u2208\n/ Maq ] and P r(eq \u2208 Maq ) for a \u2265 1. A final remark is that using\nthe law of total expectation we can also compute E [Ma1 ] and E [Maq ].\nNow let a be such that e = ea . We show how to compute the desired quantities by the\nlemma: EM, P r(u1 \u2208 M), P r(uq+1 \u2208 M) and P r(u1 \u2208 M \u2227 uq+1 \u2208 M). It is useful to think\nof S(H, ea ) roughly as the strategy which queries ea first then queries according to Sa1\u2032 and\nthe according to Saq\u2032\u2032 , for suitable a\u2032 and a\u2032\u2032 . To make this more formal we need to split into\na few cases.\n\nCase 1: 1 < a < q. Notice that since ea \u2208 H and ea is the first edge queried by S(H, e),\nthe event ea \u2208 M is the same as the event that the edge ea exists (both which happen with\nprobability pea ). In addition, since by hypothesis Pi is a path with more than one node, we\nq\nhave u1 6= uq+1 and thus no edge in the set {ek }a\u22121\nk=1 intersects an edge in the set {ek }k=a+1 .\nq\n1\nare independent.\nThis guarantees that the outcomes of, say, strategies Sa\u22121\nand Sa+1\n25\n\n\fThese observations give the following equations:\ni\nh\n\u0002 1 \u0003\n\u0002 q \u0003\n+ E Ma+2\nE M ea \u2208 M = 1 + E Ma\u22122\nh\ni\n\u0002 1 \u0003\n\u0002 q \u0003\nE M ea \u2208\n/ M = E Ma\u22121\n+ E Ma+1\n.\nAlso using the fact that 1 < a < q, and hence ea is not incident to either u1 or uq+1, we\nobtain that:\n1\n1\nP r(u1 \u2208 M|ea \u2208 M) = P r(u1 \u2208 Ma\u22122\n) = P r(e1 \u2208 Ma\u22122\n)\nq\nq\nP r(uq+1 \u2208 M|ea \u2208 M) = P r(uq+1 \u2208 Ma+2 ) = P r(eq \u2208 Ma+2 )\n1\n1\nP r(u1 \u2208 M|ea \u2208\n/ M) = P r(u1 \u2208 Ma\u22121\n) = P r(e1 \u2208 Ma\u22121\n)\nq\nq\nP r(uq+1 \u2208 M|ea \u2208\n/ M) = P r(uq+1 \u2208 Ma+1 ) = P r(eq \u2208 Ma+1 ).\n\nUsing the additional independence remark made previously, we also have that\nq\n1\n)\nP r(u1 \u2208 M \u2227 uq+1 \u2208 M|ea \u2208 M) = P r(e1 \u2208 Ma\u22122\n)P r(eq \u2208 Ma+2\nq\n1\nP r(u1 \u2208 M \u2227 uq+1 \u2208 M|ea \u2208\n/ M) = P r(e1 \u2208 Ma\u22121 )P r(eq \u2208 Ma+1 ).\n\nTherefore, using the fact that P r(ea \u2208 M) = pea and the laws of total probability\nand total expectations, we can compute EM, P r(u1 \u2208 M), P r(uq+1 \u2208 M) and P r(u1 \u2208\nM \u2227 uq+1 \u2208 M) in polynomial time using the information about the Sab 's.\nCase 2: a = 1 or a = q. The equations for the expectations are the same as in Subcase\n1.1. Now if a = 1 6= q then\nP r(u1 \u2208 M|ea \u2208 M) = 1\nq\nP r(uq+1 \u2208 M|ea \u2208 M) = P r(u1 \u2208 M \u2227 uq+1 \u2208 M|ea \u2208 M) = P r(eq \u2208 Ma+2\n)\nP r(u1 \u2208 M|ea \u2208\n/ M) = P r(u1 \u2208 M \u2227 uq+1 \u2208 M|ea \u2208\n/ M) = 0\nq\nP r(uq+1 \u2208 M|ea \u2208\n/ M) = P r(eq \u2208 Ma+1 ).\nApplying a similar reasoning to the case a = q 6= 1 we obtain\n1\nP r(u1 \u2208 M|ea \u2208 M) = P r(u1 \u2208 M \u2227 uq+1 \u2208 M|ea \u2208 M) = P r(e1 \u2208 Ma\u22122\n)\nP r(uq+1 \u2208 M|ea \u2208 M) = 1\n1\nP r(u1 \u2208 M|ea \u2208\n/ M) = P r(e1 \u2208 Ma\u22121\n)\nP r(uq+1 \u2208 M|ea \u2208\n/ M) = P r(u1 \u2208 M \u2227 uq+1 \u2208 M|ea \u2208\n/ M) = 0.\n\nFinally, if a = 1 = q then\nP r(u1 \u2208 M) = P r(uq+1 \u2208 M) = P r(u1 \u2208 M \u2227 uq+1 \u2208 M) = pea .\n26\n\n\fTherefore, we can again compute EM, P r(u1 \u2208 M), P r(uq+1 \u2208 M) and P r(u1 \u2208 M \u2227 uq+1 \u2208\nM) in polynomial time using the information about the Sab 's.\nSince we can calculate the probabilities associated to the Sab 's in polynomial time and\nthen according to Cases 1 and 2 use this information to calculate directly the values EM,\nP r(u1 \u2208 M), P r(uq+1 \u2208 M) and P r(u1 \u2208 M \u2227 uq+1 \u2208 M), this concludes the proof of the\nlemma.\n\nA.7\n\nProof of Lemma 7\n\nFirst consider G \\ e and let G1 and G2 be its connected components (if G \\ e has only one\ncomponent then we set G2 to be the empty graph). Since v(G) = v(G1 ) + v(G2 ) and e(G) =\n1 + e(G1 ) + e(G2 ), we have that e(G) \u2212 v(G) = 1 + (e(G1 ) \u2212 v(G1 )) + (e(G2 ) \u2212 v(G2 )). Since\neach Gi is connected, e(Gi ) \u2265 v(Gi ) \u2212 1 for all i and thus d \u2265 e(G) \u2212 v(G) = e(Gj ) \u2212 v(Gj )\nfor all j. This shows that all components of G \\ e are d-sparse.\nNow consider G \\ N(e) and let G1 , . . . , Gk be its connected components. Since G is\nconnected it must contain a distinct edge connecting\nPk e to each Gi . Thus, e(G) = 1 +\nP\nk\ni=1 v(Gi ), we obtain\ni=1 (e(Gi ) + 1). Using the fact that v(G) = 2 +\nk\nX\nd \u2265 e(G) \u2212 v(G) = \u22121 +\n(e(Gi ) \u2212 v(Gi ) + 1).\ni=1\n\nAgain using the fact that each Gi is connected, we get e(Gi ) \u2212 v(Gi ) \u2265 \u22121 for all i and\nhence d \u2265 \u22121 + (e(Gj ) \u2212 v(Gj ) + 1) for all j, which shows that all components of G \\ N(e)\nare d-sparse.\n\nB\nB.1\n\nProofs for Section 4\nProof of Lemma 8\n\nLet U = {u1, . . . , uk } and V be the vertex classes of G and for any node u \u2208 G let E(u)\ndenote the set of edges incident to u. Consider the strategy S that queries all edges in E(uk )\n(in an arbitrary order), then queries all edges in E(uk\u22121) and so on.\nWe want to upper bound the probability that a node ui is unmatched in M(S, G). In\norder to achieve this, consider the execution of S right before it starts querying edges in E(ui )\nand let M denote the random matching of G obtained by S at this point. Suppose ui is\nunmatched in M(S, G), which implies that no edge (ui , v) could be added to the matching.\nIf (ui , v) could not be added to the matching then either (ui , v) does not belong to the\nrealization of G or v is already matched in M. Thus, conditioning on the fact that all nodes\nin V \u2032 \u2286 V (G) are unmatched in M we get that\n!\n!\n^\n^\n^\nP r ui \u2208\n/ M(S, G)\nv\u2032 \u2208\n/ M \u2264 Pr\n(ui , v) \u2208\n/G\nv\u2032 \u2208\n/M .\n(7)\nv\u2032 \u2208V \u2032\n\nv\u2032 \u2208V \u2032\n\n27\n\nv\u2032 \u2208V \u2032\n\n\fSince M does not depend on the existence of any edge (ui , v), we can use the independence\nof the edges in G to obtain\n!\n!\nY\n^\n^\n^\n\u2032\nP r((ui , v) \u2208\n/ G) \u2264 q |V |\n(ui , v) \u2208\n/G =\nv\u2032 \u2208\n/ M = Pr\n(ui , v) \u2208\n/G\nPr\nv\u2032 \u2208V \u2032\n\nv\u2032 \u2208V \u2032\n\nv\u2032 \u2208V \u2032\n\nv\u2032 \u2208V \u2032\n\nV\nfor all V \u2032 \u2286 V (G) such that P r( v\u2032 \u2208V \u2032 v \u2032 \u2208\n/ M) > 0. Furthermore, notice that in every\nscenario M leaves at least i nodes from V unmatched, since it can match at most k \u2212 i nodes\nof U. Then inequality (7) reduces to the desired bound P r(ui \u2208\n/ M(S, G)) \u2264 q i .\nTherefore the probability that ui is matched in M(S, G) is at least 1 \u2212 q i . Since G is\nbipartite, EM(S, G) is equal to the expected\nP of U which are matched, so\nP number of nodes\nby linearity of expectation EM(S, G) \u2265 ki=1 (1 \u2212 q i ) = k \u2212 ki=1 q i . But then for any \u01eb > 0\nwe can bound the last summation as follows:\nk\nX\ni=1\n\ni\n\nq \u2264\n\n\u230a\u01ebk\u230b\nX\n\n0\n\nq +\n\ni=1\n\nk\nX\n\nq \u230a\u01ebk\u230b \u2264 \u01ebk + kq \u230a\u01ebk\u230b ,\n\ni=\u230a\u01ebk\u230b\n\nwhich gives the desired bound of EM(S, G) \u2265 (1 \u2212 q \u230a\u01ebk\u230b \u2212 \u01eb)k.\n\nC\nC.1\n\nProofs for Section 5\nProof of Lemma 10\n\nConsider the graph G depictured in Figure 4. It consists of n/4 disjoint paths and every edge\nhas probability 1, except edge e21 which has probability 1/2. Consider the following adaptive\nstrategy S: it first queries e21 and, in case it belongs to the realization of G, S queries edges\n{e2i } sequentially in an arbitrary order; in case e does not belong to the realization, S queries\nedges {e1i } and {e3i } sequentially in an arbitrary order. Notice that in the first case S obtains\na matching of size n/4, whereas in the second it obtains a matching of size n/2.\n\ne11\n\ne21\n\ne31\n\ne12\n\ne22\n\ne32\n\n...\ne1n4\n\ne2n4\n\ne3n4\n\nFigure 4: Graph for proof of Lemma 10.\nP\nRecall that \u03c3i \u223c G and that \u03b7 = (1/k) ki=1 |M(S, G)(\u03c3i )|. From the previous paragraph\nwe know that |M(S, G)(\u03c3i )| = n/2 + (n/2)B(1, 1/2), where B(a, b) denotes a binomial random variable with a trials and success probability b. Therefore, \u03b7 = n/2 + (n/2k)B(k, 1/2).\n28\n\n\fMoreover, since EM(S, G) = E [\u03b7] = 3n/4, we get that\n\u0012\n\u0013\n\u0013\n\u0012\nn\nn\n3n\nk 2kt\nP r (\u03b7 \u2265 EM(S, G) + t) = P r\n.\n+ B (k, 1/2) \u2265\n+ t = P r B (k, 1/2) \u2265 +\n2 2k\n4\n2\nn\n1\nexp(\u221216t\u20322 /k)\nHowever, for every t\u2032 \u2208 [0, k/8] we can lower bound P r(B (k, 1/2) \u2265 k2 +t\u2032 ) by 15\n[18]. By our hypothesis on t we have 2kt/n \u2264 k/8 and hence we can employ this bound on\nthe last displayed inequality, obtaining:\n\u0012\n\u0013\n1\n64kt2\nP r (\u03b7 \u2265 EM(S, G) + t) \u2265\nexp \u2212 2\n.\n15\nn\n\nSince \u03b7 is symmetric around its expected value EM(S, G), the same upper bound holds\nfor its lower tail:\n\u0012\n\u0013\n64kt2\n1\nexp \u2212 2\n.\nP r (\u03b7 \u2264 EM(S, G) \u2212 t) \u2265\n15\nn\nThe lemma then follows by combining the bounds on upper and lower the tails.\n\nC.2\n\nProof of Lemma 12\n\nFix j and define the function gj (x1 , . . . , xj\u22121 , xj+1 , . . . , xm ) as the size of the maximum matching in the subgraph of G which contains edge ei iff xi = 1; we remark that this subgraph\ndoes not contain the edge ei . It is easy to see that for every x1 , . . . , xm \u2208 {0, 1}\n0 \u2264 \u03bc\u2032 (x1 , . . . , xm ) \u2212 gj (x1 , . . . , xj\u22121 , xj+1 , . . . , xm ) \u2264 1.\nNow let M(x1 , . . . , xm ) be a maximum matching in the subgraph of G induced by\nx1 , . . . , xm and recall that |M(x1 , . . . , xm )| = \u03bc\u2032 (x1 , . . . , xm ). Notice that if \u03bc\u2032 (x1 , . . . , xm ) >\ngj (x1 , . . . , xj\u22121 , xj+1, . . . , xm ) then it must be the case that ej belongs to M(x1 , . . . , xm ).\nThen we can charge the difference between \u03bc\u2032 and the gj 's to the edges in M(x1 , . . . , xm ):\nm\nX\n\n[\u03bc\u2032 (x1 , . . . , xm ) \u2212 gj (x1 , . . . , xj\u22121 , xj+1, . . . , xm )] \u2264 |M(x1 , . . . , xm )| = \u03bc\u2032 (x1 , . . . , xm )\n\nj=1\n\nwhich shows that \u03bc\u2032 (.) is self-bounding.\n\nD\n\nConcentration inequalities\n\nFor completeness we present two inequalities used to bound large deviations of sums of\nrandom variables [4].\nLemma 13 (Hoeffding's inequality).\nLet X1 , . . . , Xk be independent random variables with\nPk\nXi \u2208 [ai , bi ]. Let Y = (1/k) i=1 Xi . Then\n!\n2k 2 t2\nP r (|Y \u2212 E [Y ]| \u2265 t) \u2264 2 exp \u2212 Pk\n.\n2\n(b\n\u2212\na\n)\ni\ni\ni=1\n29\n\n\fLemma 14 (Bernstein's inequality). Let X1P\n, . . . , Xk be independent random variables with\nequal variance Var[Xi ] = \u03c3 2 . Let Y = (1/k) ki=1 Xi . Then\n\u0012\n\u0013\nkt2\nP r (|Y \u2212 E [Y ]| \u2265 t) \u2264 2 exp \u2212\n.\n2(\u03c3 2 + t/3)\n\n30\n\n\f"}