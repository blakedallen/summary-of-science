{"id": "http://arxiv.org/abs/math/0606609v1", "guidislink": true, "updated": "2006-06-24T03:25:57Z", "updated_parsed": [2006, 6, 24, 3, 25, 57, 5, 175, 0], "published": "2006-06-24T03:25:57Z", "published_parsed": [2006, 6, 24, 3, 25, 57, 5, 175, 0], "title": "Expectation, Conditional Expectation and Martingales in Local Fields", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0606018%2Cmath%2F0606182%2Cmath%2F0606514%2Cmath%2F0606395%2Cmath%2F0606173%2Cmath%2F0606778%2Cmath%2F0606638%2Cmath%2F0606750%2Cmath%2F0606504%2Cmath%2F0606386%2Cmath%2F0606189%2Cmath%2F0606592%2Cmath%2F0606376%2Cmath%2F0606103%2Cmath%2F0606535%2Cmath%2F0606630%2Cmath%2F0606508%2Cmath%2F0606158%2Cmath%2F0606564%2Cmath%2F0606224%2Cmath%2F0606667%2Cmath%2F0606166%2Cmath%2F0606787%2Cmath%2F0606609%2Cmath%2F0606130%2Cmath%2F0606024%2Cmath%2F0606707%2Cmath%2F0606259%2Cmath%2F0606784%2Cmath%2F0606462%2Cmath%2F0606388%2Cmath%2F0606559%2Cmath%2F0606216%2Cmath%2F0606553%2Cmath%2F0606797%2Cmath%2F0606463%2Cmath%2F0606742%2Cmath%2F0606479%2Cmath%2F0606543%2Cmath%2F0606528%2Cmath%2F0606008%2Cmath%2F0606502%2Cmath%2F0606539%2Cmath%2F0606246%2Cmath%2F0606297%2Cmath%2F0606121%2Cmath%2F0606081%2Cmath%2F0606789%2Cmath%2F0606612%2Cmath%2F0606546%2Cmath%2F0606545%2Cmath%2F0606306%2Cmath%2F0606208%2Cmath%2F0606415%2Cmath%2F0606579%2Cmath%2F0606578%2Cmath%2F0606550%2Cmath%2F0606133%2Cmath%2F0606268%2Cmath%2F0606714%2Cmath%2F0606786%2Cmath%2F0606446%2Cmath%2F0606088%2Cmath%2F0606280%2Cmath%2F0606165%2Cmath%2F0606661%2Cmath%2F0606738%2Cmath%2F0606045%2Cmath%2F0606180%2Cmath%2F0606795%2Cmath%2F0606295%2Cmath%2F0606322%2Cmath%2F0606701%2Cmath%2F0606363%2Cmath%2F0606251%2Cmath%2F0606334%2Cmath%2F0606225%2Cmath%2F0606443%2Cmath%2F0606138%2Cmath%2F0606021%2Cmath%2F0606764%2Cmath%2F0606728%2Cmath%2F0606091%2Cmath%2F0606791%2Cmath%2F0606657%2Cmath%2F0606529%2Cmath%2F0606548%2Cmath%2F0606330%2Cmath%2F0606319%2Cmath%2F0606676%2Cmath%2F0606709%2Cmath%2F0606633%2Cmath%2F0606735%2Cmath%2F0606115%2Cmath%2F0606301%2Cmath%2F0606206%2Cmath%2F0606703%2Cmath%2F0606046%2Cmath%2F0606629%2Cmath%2F0606704%2Cmath%2F0205025&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Expectation, Conditional Expectation and Martingales in Local Fields"}, "summary": "We investigate a possible definition of expectation and conditional\nexpectation for random variables with values in a local field such as the\n$p$-adic numbers. We define the expectation by analogy with the observation\nthat for real-valued random variables in $L^2$ the expected value is the\northogonal projection onto the constants. Previous work has shown that the\nlocal field version of $L^\\infty$ is the appropriate counterpart of $L^2$, and\nso the expected value of a local field-valued random variable is defined to be\nits ``projection'' in $L^\\infty$ onto the constants. Unlike the real case, the\nresulting projection is not typically a single constant, but rather a ball in\nthe metric on the local field. However, many properties of this expectation\noperation and the corresponding conditional expectation mirror those familiar\nfrom the real-valued case; for example, conditional expectation is, in a\nsuitable sense, a contraction on $L^\\infty$ and the tower property holds. We\nalso define the corresponding notion of martingale, show that several standard\nexamples of martingales (for example, sums or products of suitable independent\nrandom variables or ``harmonic'' functions composed with Markov chains) have\nlocal field analogues, and obtain versions of the optional sampling and\nmartingale convergence theorems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0606018%2Cmath%2F0606182%2Cmath%2F0606514%2Cmath%2F0606395%2Cmath%2F0606173%2Cmath%2F0606778%2Cmath%2F0606638%2Cmath%2F0606750%2Cmath%2F0606504%2Cmath%2F0606386%2Cmath%2F0606189%2Cmath%2F0606592%2Cmath%2F0606376%2Cmath%2F0606103%2Cmath%2F0606535%2Cmath%2F0606630%2Cmath%2F0606508%2Cmath%2F0606158%2Cmath%2F0606564%2Cmath%2F0606224%2Cmath%2F0606667%2Cmath%2F0606166%2Cmath%2F0606787%2Cmath%2F0606609%2Cmath%2F0606130%2Cmath%2F0606024%2Cmath%2F0606707%2Cmath%2F0606259%2Cmath%2F0606784%2Cmath%2F0606462%2Cmath%2F0606388%2Cmath%2F0606559%2Cmath%2F0606216%2Cmath%2F0606553%2Cmath%2F0606797%2Cmath%2F0606463%2Cmath%2F0606742%2Cmath%2F0606479%2Cmath%2F0606543%2Cmath%2F0606528%2Cmath%2F0606008%2Cmath%2F0606502%2Cmath%2F0606539%2Cmath%2F0606246%2Cmath%2F0606297%2Cmath%2F0606121%2Cmath%2F0606081%2Cmath%2F0606789%2Cmath%2F0606612%2Cmath%2F0606546%2Cmath%2F0606545%2Cmath%2F0606306%2Cmath%2F0606208%2Cmath%2F0606415%2Cmath%2F0606579%2Cmath%2F0606578%2Cmath%2F0606550%2Cmath%2F0606133%2Cmath%2F0606268%2Cmath%2F0606714%2Cmath%2F0606786%2Cmath%2F0606446%2Cmath%2F0606088%2Cmath%2F0606280%2Cmath%2F0606165%2Cmath%2F0606661%2Cmath%2F0606738%2Cmath%2F0606045%2Cmath%2F0606180%2Cmath%2F0606795%2Cmath%2F0606295%2Cmath%2F0606322%2Cmath%2F0606701%2Cmath%2F0606363%2Cmath%2F0606251%2Cmath%2F0606334%2Cmath%2F0606225%2Cmath%2F0606443%2Cmath%2F0606138%2Cmath%2F0606021%2Cmath%2F0606764%2Cmath%2F0606728%2Cmath%2F0606091%2Cmath%2F0606791%2Cmath%2F0606657%2Cmath%2F0606529%2Cmath%2F0606548%2Cmath%2F0606330%2Cmath%2F0606319%2Cmath%2F0606676%2Cmath%2F0606709%2Cmath%2F0606633%2Cmath%2F0606735%2Cmath%2F0606115%2Cmath%2F0606301%2Cmath%2F0606206%2Cmath%2F0606703%2Cmath%2F0606046%2Cmath%2F0606629%2Cmath%2F0606704%2Cmath%2F0205025&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We investigate a possible definition of expectation and conditional\nexpectation for random variables with values in a local field such as the\n$p$-adic numbers. We define the expectation by analogy with the observation\nthat for real-valued random variables in $L^2$ the expected value is the\northogonal projection onto the constants. Previous work has shown that the\nlocal field version of $L^\\infty$ is the appropriate counterpart of $L^2$, and\nso the expected value of a local field-valued random variable is defined to be\nits ``projection'' in $L^\\infty$ onto the constants. Unlike the real case, the\nresulting projection is not typically a single constant, but rather a ball in\nthe metric on the local field. However, many properties of this expectation\noperation and the corresponding conditional expectation mirror those familiar\nfrom the real-valued case; for example, conditional expectation is, in a\nsuitable sense, a contraction on $L^\\infty$ and the tower property holds. We\nalso define the corresponding notion of martingale, show that several standard\nexamples of martingales (for example, sums or products of suitable independent\nrandom variables or ``harmonic'' functions composed with Markov chains) have\nlocal field analogues, and obtain versions of the optional sampling and\nmartingale convergence theorems."}, "authors": ["Steven N. Evans", "Tye Lidman"], "author_detail": {"name": "Tye Lidman"}, "author": "Tye Lidman", "arxiv_comment": "19 pages", "links": [{"href": "http://arxiv.org/abs/math/0606609v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0606609v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60A10; 60B99; 60G48", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0606609v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0606609v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0606609v1 [math.PR] 24 Jun 2006\n\nEXPECTATION, CONDITIONAL EXPECTATION AND\nMARTINGALES IN LOCAL FIELDS\nSTEVEN N. EVANS AND TYE LIDMAN\nAbstract. We investigate a possible definition of expectation and\nconditional expectation for random variables with values in a local field such as the p-adic numbers. We define the expectation by\nanalogy with the observation that for real-valued random variables\nin L2 the expected value is the orthogonal projection onto the constants. Previous work has shown that the local field version of L\u221e\nis the appropriate counterpart of L2 , and so the expected value of\na local field-valued random variable is defined to be its \"projection\" in L\u221e onto the constants. Unlike the real case, the resulting\nprojection is not typically a single constant, but rather a ball in\nthe metric on the local field. However, many properties of this expectation operation and the corresponding conditional expectation\nmirror those familiar from the real-valued case; for example, conditional expectation is, in a suitable sense, a contraction on L\u221e and\nthe tower property holds. We also define the corresponding notion\nof martingale, show that several standard examples of martingales\n(for example, sums or products of suitable independent random\nvariables or \"harmonic\" functions composed with Markov chains)\nhave local field analogues, and obtain versions of the optional sampling and martingale convergence theorems.\n\n1. Introduction\nExpectation and conditional expectation of real-valued random variables (or, more generally, Banach space-valued random variables) and\nthe corresponding notion of martingale are fundamental objects of\nprobability theory. In this paper we investigate whether there are analogous notions for random variables with values in a local field (that is,\na locally compact, non-discrete, totally disconnected, topological field)\n\u2013 a setting that shares the linear structure which underpins many of\nthe properties of the classical entities.\nThe best known example of a local field is the field of p-adic numbers\nfor some positive prime p. This field is defined as follows. We can write\nany non-zero rational number r \u2208 Q\\{0} uniquely as r = ps (a/b), with\nSNE supported in part by NSF grant DMS-0405778.\n1\n\n\f2\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\na, b, and s integers, where a and b are not divisible by p. Set |r| = p\u2212s .\nIf we set |0| = 0, then the map | * | has the properties:\n|x| = 0 \u21d4 x = 0\n(1)\n\n|xy| = |x||y|\n|x + y| \u2264 |x| \u2228 |y|.\n\nThe map (x, y) 7\u2192 |x \u2212 y| defines a metric on Q and we denote the\ncompletion of Q in this metric by Qp . The field operations on Q extend\ncontinuously to make Qp a topological field called the p-adic numbers.\nThe map |*| also extends continuously and the extension has properties\n(1).\nThe closed unit ball around 0, Zp = {x \u2208 Qp : |x| \u2264 1}, is the closure\nin Qp of the integers Z, and is thus a ring (this is also apparent from\n(1)), called the p-adic integers. As Zp = {x \u2208 Qp : |x| < p}, the set Zp\nis also open. Any other ball around 0 is of the form {x \u2208 Qp : |x| \u2264\np\u2212k } = pk Zp for some integer k.\nEvery local field is either a finite algebraic extension of the p-adic\nnumber field for some prime p or a finite algebraic extension of the\np-series field; that is, the field of formal Laurent series with coefficients\ndrawn from the finite field with p elements.) A locally compact, nondiscrete, topological field that is not totally disconnected is necessarily\neither the real or the complex numbers.\nFrom now on, we let K be a fixed local field. Good general reference\nfor the properties of local fields and analysis on them are [Sch84, vR78,\nTai75]. The following are the properties we need.\nThere is a real-valued mapping x 7\u2192 |x| on K called the nonarchimedean valuation with the properties (1). The third of these\nproperties is the ultrametric inequality or the strong triangle inequality.\nThe map (x, y) 7\u2192 |x \u2212 y| on K \u00d7 K is a metric on K which gives the\ntopology of K. A consequence of of the strong triangle inequality is\nthat if |x| =\n6 |y|, then |x + y| = |x| \u2228 |y|. This latter result implies\nthat for every \"triangle\" {x, y, z} \u2282 K we have that at least two of the\nlengths |x \u2212 y|, |x \u2212 z|, |y \u2212 z| must be equal and is therefore often\ncalled the isosceles triangle property.\nThe valuation takes the values {q k : k \u2208 Z} \u222a {0}, where q = pc\nfor some prime p and positive integer c (so that for K = Qp we have\nc = 1). Write D for {x \u2208 K : |x| \u2264 1} (so that D = Zp when K = Qp ).\nFix \u03c1 \u2208 K so that |\u03c1| = q \u22121 . Then\n\u03c1k D = {x : |x| \u2264 q \u2212k } = {x : |x| < q \u2212(k\u22121) }\n\n\fLOCAL FIELD EXPECTATION\n\n3\n\nfor each k \u2208 Z (so that for K = Qp we could take \u03c1 = p). The set D is\nthe unique maximal compact subring of K (the ring of integers of K).\nEvery ball in K is of the form x + \u03c1k D for some x \u2208 D and k \u2208 Z. If\nB = x + \u03c1k D and C = y + \u03c1l D are two such balls, then\n\u2022 B \u2229 C = \u2205, if |x \u2212 y| > q \u2212k \u2228 q \u2212l ,\n\u2022 B \u2286 C, if |x \u2212 y| \u2228 q \u2212k \u2264 q \u2212l ,\n\u2022 C \u2286 B, if |x \u2212 y| \u2228 q \u2212l \u2264 q \u2212k .\nIn particular, if q \u2212k = q \u2212l , then either B \u2229 C = \u2205 or B = C, depending\non whether or not |x \u2212 y| > q \u2212k = q \u2212l or |x \u2212 y| \u2264 q \u2212k = q \u2212l .\nWe have shown in a sequence papers [Eva89, Eva91, Eva93, Eva95,\nEva01b, Eva01a, Eva02, Eva06] that the natural analogues on K of the\ncentered Gaussian measures on R are the normalized restrictions of\nHaar measure on the additive group of K to the compact the balls \u03c1k D\nand the point mass at 0. There is a significant literature on probability\non the p-adics and other local fields. The above papers contain numerous references to this work, much of which concerns Markov processes\ntaking values in local fields. There are also extensive surveys of the\nliterature in the books [Khr97, Koc01, KN04].\nIt is not immediately clear how one should approach defining the\nexpectation of a local field valued random variable X. Even if X\nonly takes a finite number of values {x1 , x2 , . . . , xn }, then the object\nP\nk xk P{X = xk } doesn't make any sense because xk \u2208 K whereas\nP{X = xk } \u2208 R. However, it is an elementary fact that if T is a\nreal-valued random variable with E[T 2 ] < \u221e, then c 7\u2192 E[(T \u2212 c)2 ]\nis uniquely minimized by c = E[T ]. Of course, since this observation\nalready uses the notion of expectation it does not lead to an alternative\nway of defining the expected value of a real-valued random variable.\nFortunately, we can do something similar, but non-circular, in the local\nfield case.\nFix a probability space (\u03a9, F , P). By a K-valued random variable, we\nmean a measurable map from \u03a9 equipped with F into K equipped with\nits Borel \u03c3-field. Let L\u221e be the space of K-valued random variables X\nthat satisfy kXk\u221e := ess sup |X| < \u221e. It is clear that L\u221e is a vector\nspace over K. If we identify two random variables as being equal when\nthey are equal almost surely, then\nkXk\u221e = 0 \u21d4 X = 0\nkcXk\u221e = |c|kXk\u221e ,\n\nc \u2208 K,\n\nkX + Y k\u221e \u2264 kXk\u221e \u2228 kY k\u221e .\n\n\f4\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nThe map (X, Y ) 7\u2192 kX \u2212 Y k\u221e defines a metric on L\u221e (or, more correctly, on equivalence classes under the relation of equality almost everywhere), and L\u221e is complete in this metric. Hence L\u221e is an instance\nof a Banach algebra over K.\nIt is apparent from the papers on analogues of Gaussian measures\ncited above that L\u221e is the natural local field counterpart of the real\nHilbert space L2 . In particular, there is a natural notion of orthogonality on L\u221e (albeit one which does not come from an inner product\nstructure).\nDefinition 1.1. Given X \u2208 L\u221e , set \u03b5(X) = inf{kX \u2212 ck\u221e : c \u2208 K}.\nThe expectation of the K-valued random variable X is the subset of K\ngiven by\nE[X] := {c \u2208 K : kX \u2212 ck\u221e = \u03b5(X)} = {c \u2208 K : kX \u2212 ck\u221e \u2264 \u03b5(X)}.\nWe show in Section 2 that E[X] is non-empty. Note that if c\u2032 \u2208 E[X]\nand c\u2032\u2032 \u2208 K is such that |c\u2032\u2032 \u2212 c\u2032 | \u2264 \u03b5(X), then, by the strong triangle\ninequality, c\u2032\u2032 \u2208 E[X]. Thus E[X] is a (closed) ball in K (where we take\na single point as being a ball).\nObserve that we use the same notation for expectation of K-valued\nand R-valued random variables. This should cause no confusion: we\neither indicate explicitly whether a random variable has values in K or\nR, or this will be clear from context.\nThe outline of the rest of the paper is the following. We show in\nSection 2 that the expected value of a random variable in L\u221e is nonempty, remark on some of the properties of the expectation operator,\nand motivate the definition of conditional expectation by considering\nthe situation where the conditioning \u03c3-field is finitely generated or,\nmore generally, has an associated regular conditional probability. The\nappropriate definition of the conditional expectation of X \u2208 L\u221e given a\nsub-\u03c3-field G \u2286 F is not, as one might first imagine, the L\u221e projection\nof X onto L\u221e (G) (:= the subspace of L\u221e consisting of G-measurable\nrandom variables). For this reason, we need to do some preparatory\nwork in Sections 3 and 4 before finally presenting the construction\nof conditional expectation in Section 5 and describing its elementary\nproperties in Section 6. We establish an analogue of the \"tower property\" in Section 7 and obtain a counterpart of the fact for classical\nconditional expectation that conditioning is a contraction on L2 (both\nof these results need to be suitably interpreted due to the conditional\nexpectation being typically a set of random variables rather than a single one). We introduce the associated notion of martingale in Section 9\nand observe that several of the classical examples of martingales have\n\n\fLOCAL FIELD EXPECTATION\n\n5\n\nlocal field analogues. We develop counterparts of the optional sampling theorem and martingale convergence theorem in Sections 10 and\n11, respectively.\nNote: We adopt the convention that all equalities and inequalities\nbetween random variables should be interpreted as holding P-almost\nsurely.\n2. Expectation\nTheorem 2.1. The expectation of a random variable X \u2208 L\u221e is nonempty. It is the smallest closed ball in K that contains suppX (the\nclosed support of X).\nProof. By the strong triangle inequality kX \u2212 ck\u221e \u2264 kXk\u221e \u2228 |c|, and\nkX \u2212 ck\u221e = |c| for |c| > kXk\u221e . Therefore, the infimum of c 7\u2192\nkX \u2212 ck\u221e over all c \u2208 K is the same as the infimum over {c \u2208 K : |c| \u2264\nkXk\u221e } and any point c \u2208 K at which the infimum of is achieved must\nnecessarily satisfy |c| \u2264 kXk\u221e . That is, \u03b5(X) = inf{kX \u2212 ck\u221e : |c| \u2264\nkXk\u221e } and E[X] = {c : |c| \u2264 kXk\u221e , kX \u2212 ck\u221e = \u03b5(X)}.\nAgain by the strong triangle inequality, the function c 7\u2192 kX \u2212 ck\u221e\nis continuous. Consequently, E[X] is non-empty as the set of points at\nwhich a continuous function on a compact set attains its infimum.\nAs we observed in the Introduction, E[X] is a ball of radius (=\ndiameter) \u03b5(X). If x \u2208 suppX is not in E[X] and c is any point\nin E[X], then, by the strong triangle inequality, |x \u2212 c| > \u03b5(X) and\nkX \u2212ck\u221e > \u03b5(X), contradicting the definition of E[X]. Thus suppX \u2286\nE[X]. Hence, if the smallest ball containing suppX is not E[X], it\nmust be a ball contained in E[X] with diameter r < \u03b5(X). However,\nif c is any point contained in the smaller ball, then |x \u2212 c| \u2264 r for all\nx \u2208 suppX, contradicting the definition of \u03b5(X).\n\u0003\nOur notion of expectation shares some of the features of both the\nmean and the variance of a real-valued variable. Any point in the\nball E[X] is as good a single summary of the \"location\" of X as any\nother, whereas the diameter of E[X] (that is, \u03b5(X)) is a measure of the\n\"spread\" of X.\nSome properties of E[X] are immediate. It is easily seen that for\nconstants k, b \u2208 K, E[kX + b] = kE[X] + b. We do not have complete\nlinearity, however, since E[X + Y ] is only a subset of E[X] + E[Y ],\nwith equality when X and Y are independent. This follows from\nthe fact that supp(X + Y ) \u2286 suppX + suppY , with equality when\nX and Y are independent. Also, if X and Y are independent, then\nE[XY ] = E[X]E[Y ]. These remarks further support our assertion that\n\n\f6\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nE[X] combines the properties of the mean and the variance for realvalued random variables.\nDefine the Hausdorff distance between two subsets A and B of K to\nbe\ndH (A, B) := sup inf |a \u2212 b| \u2228 sup inf |b \u2212 a|.\nb\u2208B a\u2208A\n\na\u2208A b\u2208B\n\nWe know from Theorem 2.1 that E[X] and E[Y ] are balls with diameters \u03b5(X) and \u03b5(Y ), respectively. We have one of the alternatives\nE[X] = E[Y ], E[X] ( E[Y ], E[Y ] ( E[X], or E[X]\u2229E[Y ] = \u2205. Suppose\nthat E[X] ( E[Y ], so that suppX \u2286 E[X] and there exists y \u2208 suppY\nsuch that y is not in the unique ball of diameter q \u22121 \u03b5(Y ) containing\nE[X]. Then, by the strong triangle inequality, |x \u2212 y| = \u03b5(Y ) for all\nx \u2208 suppX, and so dH (suppX, suppY ) \u2265 \u03b5(Y ) = dH (E[X], E[Y ]) in\nthis case. Similar arguments in the other cases show that\ndH (E[X], E[Y ]) \u2264 dH (suppX, suppY ) \u2264 kX \u2212 Y k\u221e .\nThis is analogous to the continuity of real-valued expectation with respect to the real Lp norms.\nRather than develop more properties of expectation, we move on to\nthe corresponding definition of conditional expectation because, just as\nin the real case, expectation is the special case of conditional expectation that occurs when the conditioning \u03c3-field is the trivial \u03c3-field\n{\u2205, \u03a9}, and so results for expectation are just special cases of ones for\nconditional expectation.\nIn order to motivate the definition of conditional expectation, first\nconsider the special case when the conditioning \u03c3-field G \u2286 F is generated by a finite partition {A1 , A2 , . . . , An } of \u03a9. In line with our\ndefinition of E[X], a reasonable definition of E[X | G] would be the set\nof G-measurable random variables Y such that for each k the common\nvalue of ck := Y (\u03c9) for \u03c9 \u2208 Ak satisfies\ness sup{|X(\u03c9) \u2212 ck | : \u03c9 \u2208 Ak } = inf ess sup{|X(\u03c9) \u2212 c| : \u03c9 \u2208 Ak }.\nc\u2208K\n\nEquivalently, suppose we define \u03b5(X, G) to be the G-measurable, Rvalued random variable that takes the value inf c\u2208K ess sup{|X(\u03c9) \u2212\nc| : \u03c9 \u2208 Ak } on Ak , then E[X | G] is the set of G-measurable random\nvariables Y such that |X \u2212 Y | \u2264 \u03b5(X, G). Note that \u03b5(X, {\u2205, \u03a9}) =\n\u03b5(X) and E[X | {\u2205, \u03a9}] = E[X].\nMore generally, suppose that G \u2286 F is an arbitrary sub-\u03c3-field and\nthere is an associated regular conditional probability PG (\u03c9 \u2032, d\u03c9 \u2032\u2032 ) (such\na regular conditional probability certainly exists if G is finitely generated). In this case, we expect that E[X | G](\u03c9 \u2032) should be the expectation of X with respect to the probability measure PG (\u03c9 \u2032, *). It is easy\n\n\fLOCAL FIELD EXPECTATION\n\n7\n\nto see that if we let \u03b5(X, G) be the G-measurable random variable such\nthat \u03b5(X, G)(\u03c9 \u2032) is the infimum over c \u2208 K of the essential supremum\nof |X \u2212 c| with respect to PG (\u03c9 \u2032 , *), then this definition of \u03b5(X, G) subsumes our previous one for the finitely generated case and our putative\ndefinition of E[X | G] coincides with the set of G-measurable random\nvariables Y such that |X \u2212 Y | \u2264 \u03b5(X, G), thereby also extending the\ndefinition for the finitely generated case.\nWe therefore see that the key to giving a satisfactory general definition of E[X | G] for an arbitrary sub-\u03c3-field G \u2286 F is to find a suitable\ngeneral definition of \u03b5(X, G). We tackle this problem in the next three\nsections.\n\n3. Conditional essential supremum\nDefinition 3.1. Given a non-negative real-valued random variable S\nand a sub-\u03c3-field G \u2286 F , put\n1\n\n1\n\ness sup{S | G} = sup E[S p | G] p = lim E[S p | G] p .\np\u22651\n\np\u2192\u221e\n\nLemma 3.2.\n(i) Suppose that S is a non-negative real-valued\nrandom variable and G is a sub-\u03c3-field of F . Then S \u2264\ness sup{S | G}.\n(ii) Suppose that S and G are as in (i) and T is G-measurable realvalued random variable with S \u2264 T . Then ess sup{S | G} \u2264 T .\n(iii) Suppose that S \u2032 and S \u2032\u2032 are non-negative real-valued random\nvariables and G is a sub-\u03c3-fields of F . Then\ness sup{S \u2032 \u2228 S \u2032\u2032 | G} = ess sup{S \u2032 | G} \u2228 ess sup{S \u2032\u2032 | G}.\nProof. For part (i), we show by separate arguments that the result\nholds on the events {ess sup{S | G} = 0} and {ess sup{S | G} > 0}.\nFirst consider what happens on the event {ess sup{S | G} = 0}. By\ndefinition E[S | G] \u2264 ess sup{S | G}. Hence\nE[S 1{ess sup{S | G} = 0}] \u2264 E[S 1{E[S | G] = 0}]\n= E[E[S 1{E[S | G] = 0} | G]]\n= E[ 1{E[S | G] = 0}E[S | G]] = 0.\nThus {ess sup{S | G} = 0} \u2286 {S = 0}, and S \u2264 ess sup{S | G} on the\nevent {ess sup{S | G} = 0}.\n\n\f8\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nNow consider what happens on the event {ess sup{S | G} > 0}. Take\n\u03b1 > 1. Observe for p \u2265 1 that\nE[S p | G] \u2265 E[S p 1{S p \u2265 \u03b1p E[S p | G]} | G]\n\u2265 E[\u03b1p E[S p | G] 1{S p \u2265 \u03b1p E[S p | G]} | G]\n= \u03b1p E[S p | G] P{S p \u2265 \u03b1p E[S p | G] | G}.\nHence, for each p \u2265 1,\n1\n\nP{S \u2265 \u03b1 ess sup{S | G} | G} \u2264 P{S \u2265 \u03b1 E[S p | G] p | G} \u2264\n\n1\n\u03b1p\n\non the event {E[S p | G] > 0}.\nS T\nSince {ess sup{S | G} > 0} \u2286 p q\u2265p {E[S q | G] > 0}, we see that\nP{S \u2265 \u03b1 ess sup{S | G} | G} = 0 on the event on {ess sup{S | G} > 0}.\nAs this holds for all \u03b1 > 1, we conclude that S \u2264 ess sup{S | G} on the\nevent {ess sup{S | G} > 0}, and this completes the proof of part (i).\nPart (ii) is immediate from the definition.\nNow consider part (iii). We have from part (i) that S \u2032 \u2264\ness sup{S \u2032 | G} and S \u2032\u2032 \u2264 ess sup{S \u2032\u2032 | G}. Thus S \u2032 \u2228S \u2032\u2032 \u2264 ess sup{S \u2032 | G}\u2228\ness sup{S \u2032\u2032 | G} and hence\ness sup{S \u2032 \u2228 S \u2032\u2032 | G} \u2264 ess sup{S \u2032 | G} \u2228 ess sup{S \u2032\u2032 | G}\nby part (ii). On the other hand, because S \u2032 \u2264 S \u2032 \u2228 S \u2032\u2032 and S \u2032\u2032 \u2264\nS \u2032 \u2228 S \u2032\u2032 , it follows that ess sup{S \u2032 | G} \u2264 ess sup{S \u2032 \u2228 S \u2032\u2032 | G} and\ness sup{S \u2032\u2032 | G} \u2264 ess sup{S \u2032 \u2228 S \u2032\u2032 | G}. Therefore\ness sup{S \u2032 | G} \u2228 ess sup{S \u2032\u2032 | G} \u2264 ess sup{S \u2032 \u2228 S \u2032\u2032 | G}.\n\u0003\nCorollary 3.3. Suppose that S is a non-negative real-valued random\nvariable and G \u2286 H are sub-\u03c3-fields of F . Then ess sup{S | H} \u2264\ness sup{S | G}.\nProof. From Lemma 3.2(i), S \u2264 ess sup{S | G}. Applying Lemma\n3.2(ii) with G replaced by H and T = ess sup{S | G} gives the result. \u0003\nLet {Fn }\u221e\nn=0 be a filtration (that is, a non-decreasing sequence of\nsub-\u03c3-fields of F ). Recall that a random variable T with values in\n{0, 1, 2, . . .} is a stopping time for the filtration if {T = n} \u2208 Fn for all\nn. Recall also that if T is a stopping time, then the associated \u03c3-field\nFT is the collection of events A such that A \u2229 {T = n} \u2208 Fn for all n.\nLemma 3.4. Suppose that S is a non-negative real-valued random variable, {Fn }\u221e\nn=0 is a filtration of sub-\u03c3-fields of F , and T is a stopping\n\n\fLOCAL FIELD EXPECTATION\n\n9\n\ntime. Then\ness sup{S 1{T = n} | FT } = 1{T = n} ess sup{S | FT }\n= 1{T = n} ess sup{S | Fn } = ess sup{S 1{T = n} | Fn }\nfor all n.\nProof. This follows immediately from the definition of the conditional\nessential supremum and the fact that if U is a non-negative real-valued\nrandom variable, then ess sup{U|FT } = ess sup{U|Fn } on the event\n{T = n} (see, for example, Proposition II-1-3 of [Nev75]).\n\u0003\n4. Conditional L\u221e norm\nDefinition 4.1. Given X \u2208 L\u221e and a sub-\u03c3-field G \u2286 F , put\nkXkG := ess sup{|X| | G}.\nNotation 4.2. Given A \u2208 F , the K-valued random variable 1A is given\nby\n(\n1K , if \u03c9 \u2208 A,\n1A (\u03c9) =\n0K , otherwise,\nwhere 1K and 0K are, respectively, the multiplicative and additive identity elements of K. We continue to use this same notation to also denote\nthe analogously defined real-valued indicator random variable, but this\nshould cause no confusion as the meaning will be clear from the context.\nLemma 4.3. Fix a sub-\u03c3-field G \u2286 F .\n(i) If W \u2208 L\u221e (G) and X \u2208 L\u221e , then kW XkG = |W | kXkG .\n(ii) If X, Y \u2208 L\u221e are such that P({X 6= Y } \u2229 A) = 0 for some\nA \u2208 G, then P({kXkG 6= kY kG } \u2229 A) = 0.\n(iii) If X1 , X2 , . . . \u2208 L\u221e and A1 , A2 , . . . \u2208 G are pairwise disjoint,\nthen\nX\nX\n1Ai kXi kG .\nX i 1A i =\ni\n\nG\n\ni\n\n(iv) If X, Y \u2208 L\u221e , then\n\nkX + Y kG \u2264 kXkG \u2228 kY kG .\nProof. Part (i) follows immediately from the definition. Part (ii) follows\nfrom part (i): since X 1A = Y 1A by assumption,\n1A kXkG = kX 1A kG = kY 1A kG = 1A kY kG .\n\n\f10\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nPart (iii) follows from parts (i) and (ii): for any of the events Aj ,\nX\n1A j\n1Ai kXi kG = 1Aj kXj kG = k 1Aj Xj kG\ni\n\n= 1A j\n\nX\n\n= 1A j\n\n1A i X i\n\ni\n\nP\n\nX\n\nG\n\nP\n\n,\n\n1A i X i\n\ni\n\nG\n\nS\n\nand, similarly, i 1Ai kXi kG = k i 1Ai Xi kG on \u03a9 \\ ( i Ai ).\nPart (iv) is an immediate consequence of Lemma 3.2(iii). However,\nthere is also the following alternative, more elementary proof. Note\nfirst that kX r kG = kXkrG for any r > 0 because\nr\n\n1\n\n1\n\nlim E[|X|rp | G] p = lim E[|X|q | G] q = ( lim E[|X|q | G] q )r .\n\np\u2192\u221e\n\nq\u2192\u221e\n\nq\u2192\u221e\n\nThus, from Jensen's inequality and the observation that (x + y)s \u2264\n(xs + y s ) for 0 \u2264 s \u2264 1,\n1\n\nkX + Y kG = lim E[|X + Y |p | G] p\np\u2192\u221e\n\n1\n\n\u2264 lim E[|X|p \u2228 |Y |p | G] p\np\u2192\u221e\n\n1\n\n1\n\n= lim E[ lim (|X|pr + |Y |pr ) r | G) p\np\u2192\u221e\n\nr\u2192\u221e\n\n1\n\n\u2264 lim (E[|X|pr | G] + E[|Y |pr | G]) pr\np,r\u2192\u221e\n\n1\n\n1\n\n1\n\n\u2264 lim (E[|X|rp | G] p + E[|Y |rp | G] p ) r .\np,r\u2192\u221e\n\n1\n\n= lim (kXkrG + kY krG ) r\nr\u2192\u221e\n\n= kXkG \u2228 kY kG .\n\u0003\nThe following result is immediate from Corollary 3.3.\nLemma 4.4. Suppose that X \u2208 L\u221e and G \u2286 H are sub-\u03c3-fields of F .\nThen kXkH \u2264 kXkG .\nThe following result is immediate from Lemma 3.4.\nLemma 4.5. Suppose that X \u2208 L\u221e , {Fn }\u221e\nn=0 is a filtration of sub-\u03c3fields of F , and T is a stopping time. Then\nkX 1{T = n}kFT = 1{T = n} kXkFT\n= 1{T = n} kXkFn = kX 1{T = n}kFn\nfor all n.\n\n\fLOCAL FIELD EXPECTATION\n\n11\n\n5. Construction of Conditional Expectation\nDefinition 5.1. Given X \u2208 L\u221e and a sub-\u03c3-field G \u2286 F , set\nE[X | G] := {Y \u2208 L\u221e (G) : kX \u2212 Y kG \u2264 kX \u2212 ZkG for all Z \u2208 L\u221e (G)}.\nRemark 5.2. Before showing that E[X | G] is non-empty, we comment\non a slight subtlety in the definition. One way of thinking of our definition of E[X] as the set of c \u2208 K for which kX \u2212 ck\u221e is minimal,\nis that E[X] is the set of projections of X onto K \u2261 L\u221e ({\u2205, \u03a9}). A\npossible definition of E[X | G] might therefore be the analogous set of\nprojections of X onto L\u221e (G), that is, the set of Y \u2208 L\u221e (G) that\nminimize kX \u2212 Y k\u221e . This definition is not equivalent to ours. For\nexample, suppose that \u03a9 consists of the three points {\u03b1, \u03b2, \u03b3}, F consists of all subsets of \u03a9, P assigns positive mass to each point of \u03a9,\nG = \u03c3{{\u03b1, \u03b2}, {\u03b3}}, and X is given by X(\u03b1) = 1K , X(\u03b2) = 0K , and\nX(\u03b3) = 0K . Consider Y \u2208 L\u221e (G), so that Y (\u03b1) = Y (\u03b2) = c and\nY (\u03b3) = d for some c, d \u2208 K. In order that Y \u2208 E[X | G] according to\nour definition, c and d must be chosen to minimize both |1K \u2212c|\u2228|0K \u2212c|\nand |0K \u2212 d|. By the strong triangle inequality, |1K \u2212 c| \u2228 |0K \u2212 c| is\nminimized by any c with |c| \u2264 1, with the corresponding minimal value\nbeing 1. Of course, |0K \u2212 d| is minimized by the unique value d = 0K .\nOn the other hand, in order that Y is a projection of X onto L\u221e (G),\nthe points c and d must be chosen to minimize |1K \u2212c|\u2228|0K \u2212c|\u2228|0K \u2212d|,\nand this is accomplished as long as |c| \u2264 1 and |d| \u2264 1. We don't belabor the point in what follows, but several of the natural counterparts\nof standard results for classical conditional expectation that we show\nhold for our definition fail to hold for the \"projection\" definition.\nThe following lemma is used below to show that E[X | G] is nonempty.\nLemma 5.3. Suppose that X \u2208 L\u221e is not 0K almost surely, and G\nis a sub-\u03c3-field of F . Set q \u2212N = kXk\u221e . Then there exist disjoint\nevents A0 , A1 , . . . \u2208 G and random variables Y0 , Y1 , . . . \u2208 L\u221e (G) with\nthe following properties:\n(1)\n(2)\n(3)\n(4)\n(5)\n\nOn the event An , kX \u2212 ZkG \u2265 q \u2212(N +n) for every Z \u2208 L\u221e (G).\nOn the event An , S\nkX \u2212 Yn kG = q \u2212(N +n) . and\nn\n\u2212(N +n+1)\nOn the event \u03a9\nSn\\ k=1 Ak , kX \u2212 Yn kG \u2264 q\nOn the event\nS\u221e k=1 Ak , Yp = Yn for any p > n.\nThe event k=1 Ak has probability one.\n\nProof. Suppose without loss of generality that kXk\u221e = 1, so that\nN = 0. Set Z0 := {Z \u2208 L\u221e (G) : kX \u2212 Zk\u221e \u2264 1}. Note that the\n\n\f12\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nconstant 0 belongs to Z0 and so this set is non-empty. Put \u03b40 :=\ninf Z\u2208Z0 P{kX \u2212 ZkG = 1}.\nChoose Z0,1 , Z0,2, . . . \u2208 Z0 with\nlim P{kX \u2212 Z0,m kG = 1} = \u03b40 .\n\nm\u2192\u221e\n\n\u2032\n\u2032\n\u2032\nDefine Z0,1\n, Z0,2\n, . . . inductively by setting Z0,1\n:= Z0,1 and\n(\n\u2032\n\u2032\nZ0,m\n(\u03c9),\nif kX \u2212 Z0,m\nkG (\u03c9) \u2264 kX \u2212 Z0,m+1 kG (\u03c9),\n\u2032\nZ0,m+1\n(\u03c9) :=\n\u2032\nZ0,m+1 (\u03c9), if kX \u2212 Z0,m kG (\u03c9) > kX \u2212 Z0,m+1 kG (\u03c9).\n\u2032\nNote that the events B0,m := {kX \u2212 Z0,m\nkG = 1} are decreasing and\nthe B0,m are contained in the\nT event {kX \u2212 Z0,m kG = 1}. Hence the\nevent A0 := limm\u2192\u221e B0,m = \u221e\nm=1 B0,m has probability \u03b40 .\nDefine Y0 by\n(\n\u2032\nZm,1\n(\u03c9), if \u03c9 \u2208 (\u03a9 \\ B0,1 ) \u222a A0 ,\nY0 (\u03c9) :=\n\u2032\nZ0,m (\u03c9), if \u03c9 \u2208 (\u03a9 \\ B0,m ) \\ (\u03a9 \\ B0,m\u22121 ), m \u2265 2.\n\nIt is clear that kX \u2212 Y0 kG = 1 on the event A0 and kX \u2212 Y0 kG \u2264 q \u22121\non the event \u03a9 \\ A0 . Moreover, if there existed V \u2208 L\u221e (G) with\nP({kX \u2212 V kG \u2264 q \u22121 } \u2229 A0 ) > 0,\nthen we would have the contradiction that W \u2208 Z0 defined by\n(\nY0 (\u03c9), if kX \u2212 Y0 kG (\u03c9) \u2264 kX \u2212 V kG (\u03c9),\nW (\u03c9) =\nV (\u03c9), if kX \u2212 Y0 kG (\u03c9) > kX \u2212 V kG (\u03c9)\nwould satisfy P{kX \u2212 W kG = 1} < \u03b40 .\nNow suppose that A0 , . . . An\u22121 and Y0 , . . . , YSn\u22121 have been conn\u22121\nstructed with the requisite properties. If P(\u03a9 \\ k=1\n) = 0, then take\nAn = \u2205 and Yn = Yn\u22121 (recall that we are interpreting all equalities\nand inequalities as holding P-a.s.) Otherwise, set\n\u001a\nn\u22121\n[\n\u221e\nZn := Z \u2208 L (G) :Z = Yn\u22121 on\nAk\nk=1\n\nand |X \u2212 Z| \u2264 q\n\n\u2212n\n\non \u03a9 \\\n\nn\u22121\n[\nk=1\n\n\u001b\n\nAk .\n\nNote that Yn\u22121 belongs to Zn . Put \u03b4n := inf Z\u2208Zn P{kX \u2212 ZkG =\nq \u2212n }. An argument very similar to the above with Zn and \u03b4n replacing\nZ0 and \u03b40 establishes the existence of An and Yn with the desired\nproperties.\n\u0003\n\n\fLOCAL FIELD EXPECTATION\n\n13\n\nTheorem 5.4. Given X \u2208 L\u221e and a sub-\u03c3-algebra G \u2286 F , the conditional expectation E[X | G] is nonempty.\nProof. If X is 0K almost surely, then E[X | G] = {0K }. Otherwise, let\nA0 , A1 , . . . \u2208 G and Y0 , Y1 , . . . \u2208 L\u221e (G) be as in Lemma 5.3. Then Y\ndefined by Y (\u03c9) = Yn (\u03c9) for \u03c9 \u2208 An belongs to E[X | G].\n\u0003\n6. Elementary Properties of Conditional Expectation\nProposition 6.1. Fix a sub-\u03c3-field G \u2286 F .\n(i) Suppose that X \u2208 L\u221e (G) and Y \u2208 L\u221e . Then\nE[XY | G] = X E[Y | G].\nand\nE[X + Y | G] = X + E[Y | G].\n(ii) If X, Y \u2208 L are such that P({X 6= Y } \u2229 A) = 0 for some\nA \u2208 G, then 1A E[X | G] = 1A E[Y | G].\n(iii) If X1 , X2 , . . . \u2208 L\u221e and A1 , A2 , . . . \u2208 G are pairwise disjoint,\nthen\n\"\n#\nX\nX\nE\nX i 1A i | G =\n1Ai E[Xi | G].\n\u221e\n\ni\n\ni\n\nProof. Consider part (i). We first show the inclusion E[XY | G] \u2286\nXE[Y | G].\nConsider Z \u2208 E[XY | G]. Choose some V \u2208 E[Y | G] and set W =\n(Z/X) 1{X 6= 0} + V 1{X = 0} \u2208 L\u221e (G). Note that P{Z 6= 0, X =\n0} = 0 and hence XW = Z, because otherwise we would have the\ncontradiction kXY \u2212 Z 1{X 6= 0}kG \u2264 kXY \u2212 ZkG and P{kXY \u2212\nZ 1{X 6= 0}kG < kXY \u2212 ZkG } > 0 by Lemma 4.3(ii).\nWe need to show that W \u2208 E[Y | G]. Consider U \u2208 L\u221e (G). By\nLemma 4.3(ii) and the assumption that V \u2208 E[Y | G],\nkY \u2212 W kG = kY \u2212 V kG \u2264 kY \u2212 UkG\non the event {X = 0}. Also, kXY \u2212 ZkG \u2264 kXY \u2212 XUkG by the\nassumption that Z \u2208 E[XY | G], and so, by Lemma 4.3(i)+(ii)\nkY \u2212 W kG = kY \u2212 Z/XkG = |X|\u22121 kXY \u2212 ZkG\n\u2264 |X|\u22121kXY \u2212 XUkG = kY \u2212 UkG\n\non the event {X 6= 0}. Thus kY \u2212W kG \u2264 kY \u2212UkG for any U \u2208 L\u221e (G)\nand hence W \u2208 E[Y | G].\nWe now show the converse inclusion XE[Y | G] \u2286 E[XY | G].\nChoose W \u2208 E[Y | G]. We need to show that XW \u2208 E[XY | G].\nConsider U \u2208 L\u221e (G). Put V = (U/X) 1{X 6= 0}. We have kY \u2212\n\n\f14\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nW kG \u2264 kY \u2212 V kG by the assumption that W \u2208 E[Y | G]. From Lemma\n4.3(i)+(ii),\nkXY \u2212 XW kG = |X|kY \u2212 W kG \u2264 |X|kY \u2212 V kG = kXY \u2212 XV kG\n= kXY \u2212 UkG 1{X 6= 0} \u2264 kXY \u2212 UkG ,\nas required.\nThe proof of the claim E[X + Y | G] = X + E[Y | G] is similar but\neasier, so we omit it.\nParts (ii) and (iii) follow straightforwardly from parts (ii) and (iii)\nof Lemma 4.3.\n\u0003\nProposition 6.2. Let G be a sub-\u03c3-algebra of F . Suppose that X \u2208\nL\u221e is independent of G. Then E[X | G] is the set of random variables\nY \u2208 L\u221e (G) that take values in E[X].\nProof. Observe for any Z \u2208 L\u221e (G), that, by the assumption of independence of X from G,\n1\n\nkX \u2212 ZkG (\u03c9) = sup (E[|X \u2212 Z|p | G](\u03c9)) p\np\n\n= sup\np\n\n\u0012Z\n\np\n\n|x \u2212 Z(\u03c9)| P{X \u2208 dx}\n\n= sup{|x \u2212 Z(\u03c9)| : x \u2208 suppX}\n(\n= \u03b5(X), if Z(\u03c9) \u2208 E[X],\n> \u03b5(X), otherwise,\n\n\u0013 p1\n\nand the result follows.\n\n\u0003\n\n7. Conditional spread and the tower property\nDefinition 7.1. Given X \u2208 L\u221e and a sub-\u03c3-field G of F , let \u03b5(X, G)\ndenote the common value of kX \u2212 Y kG for Y \u2208 E[X | G].\nLemma 7.2. If X \u2208 L\u221e and a G \u2286 H are sub-\u03c3-fields of F , then\n\u03b5(X, H) \u2264 \u03b5(X, G).\nProof. Suppose that V \u2208 E[X | G] and W \u2208 E[X | H]. From Lemma\n4.4,\n\u03b5(X, H) = kX \u2212 W kH \u2264 kX \u2212 V kH \u2264 kX \u2212 V kG = \u03b5(X, G).\n\u0003\nLemma 7.3. A random variable Y belongs to E[X | G] if and only if\nY \u2208 L\u221e (G) and |X \u2212 Y | \u2264 \u03b5(X, G).\n\n\fLOCAL FIELD EXPECTATION\n\n15\n\nProof. Suppose Y is in E[X | G]. By definition, Y \u2208 L\u221e (G). By Lemma\nLemma 4.4, |X \u2212 Y | = kX \u2212 Y kF \u2264 kX \u2212 Y kG = \u03b5(X, G).\nThe converse is immediate from Lemma 3.2(ii).\n\u0003\nLemma 7.4. Suppose that X \u2208 L\u221e , G \u2286 H are sub-\u03c3-fields of F , and\nY \u2208 E[X | H]. Then \u03b5(Y, G) \u2264 \u03b5(X, G).\nProof. Consider Z \u2208 E[X | G]. By Lemma 7.3 and Lemma 7.2\n|Y \u2212 Z| \u2264 |X \u2212 Y | \u2228 |X \u2212 Z| \u2264 \u03b5(X, H) \u2228 \u03b5(X, G) = \u03b5(X, G).\nBy Lemma 3.2(ii), \u03b5(Y, G) \u2264 kY \u2212 ZkG \u2264 \u03b5(X, G).\n\n\u0003\n\nTheorem 7.5. Suppose that X \u2208 L\u221e and G \u2286 H are sub-\u03c3-fields of\nF . If Y \u2208 E[X | H] and Z \u2208 E[Y | G], then Z \u2208 E[X | G].\nProof. By Lemma 7.3, Lemma 7.4, and Lemma 7.2,\n|X \u2212 Z| \u2264 |X \u2212 Y | \u2228 |Y \u2212 Z| \u2264 \u03b5(X, H) \u2228 \u03b5(Y, G) \u2264 \u03b5(X, G).\nThus Z is in E[X | G] by another application of Lemma 7.3.\n\n\u0003\n\n8. Continuity of conditional expectation\nDefinition 8.1. Define the Hausdorff distance between two subsets A\nand B of L\u221e to be\nDH (A, B) := sup inf kX \u2212 Y k\u221e \u2228 sup inf kY \u2212 Xk\u221e .\nX\u2208A Y \u2208B\n\nY \u2208B X\u2208A\n\nLemma 8.2. Suppose that A, B, C are subsets of L\u221e . Then\nDH (A + C, B + C) \u2264 DH (A, B).\nProof. Suppose that DH (A, B) < \u03b4 for some \u03b4 \u2265 0. By definition, for\nevery X \u2208 A there is a Y \u2208 B with kX \u2212 Y k\u221e < \u03b4, and similarly with\nthe roles of A and B reversed. If U \u2208 A + C, then U = X + W for some\nX \u2208 A and W \u2208 C. We know there is Y \u2208 B such that kX \u2212 Y k\u221e < \u03b4.\nNote that V := Y + W \u2208 B + C and kU \u2212 V k\u221e = kX \u2212 Y k\u221e < \u03b4.\nA similar argument with the roles of A and B reversed shows that\nDH (A + C, B + C) < \u03b4.\n\u0003\nTheorem 8.3. Suppose that X, Y \u2208 L\u221e and G is a sub-\u03c3-field of F .\nThen DH (E[X | G], E[Y | G]) \u2264 kX \u2212 Y k\u221e .\nProof. Choose U \u2208 E[X | G] and V \u2208 E[Y | G]. From Lemma 4.3(iv),\n\u03b5(Y, G) \u2264 kY \u2212 UkG \u2264 kX \u2212 UkG \u2228 kX \u2212 Y kG = \u03b5(X, G) \u2228 kX \u2212 Y kG\nand\n\u03b5(X, G) \u2264 kX \u2212 V kG \u2264 kY \u2212 V kG \u2228 kX \u2212 Y kG = \u03b5(Y, G) \u2228 kX \u2212 Y kG .\n\n\f16\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nIt follows that \u03b5(X, G) = \u03b5(Y, G) on the event M := {kX \u2212 Y kG <\n\u03b5(X, G) \u2228 \u03b5(Y, G)} and\n\u03b5(X, G) = kY \u2212 UkG = kX \u2212 UkG = \u03b5(X, G)\nand\n\u03b5(Y, G) = kX \u2212 V kG = kY \u2212 V kG = \u03b5(Y, G)\non M.\nBy Proposition 6.1, U 1M \u2208 E[Y 1M | G] = 1M E[Y | G] and V 1M \u2208\nE[X 1M | G] = 1M E[X | G]. Thus 1M E[X | G] = 1M E[Y | G].\nFurthermore, on the event N := {kX \u2212 Y kG \u2265 \u03b5(X, G) \u2228 \u03b5(Y, G)}\nkU \u2212 V k\u221e \u2264 kU \u2212 Xk\u221e \u2228 kX \u2212 Y k\u221e \u2228 kY \u2212 V k\u221e\n\u2264 \u03b5(X, G) \u2228 kX \u2212 Y k\u221e \u2228 \u03b5(Y, G)\n\u2264 kX \u2212 Y k\u221e ,\nand so kU 1N \u2212 V 1N k\u221e \u2264 kX 1N \u2212 Y 1N k\u221e \u2264 kX \u2212 Y k\u221e . Therefore,\nDH ( 1N E[X | G], 1N E[Y | G]) \u2264 kX \u2212 Y k\u221e .\nBy Proposition 6.1(iii), E[X | G] = 1M E[X | G] + 1N E[X | G], and\nsimilarly for Y . The result now follows from Lemma 8.2.\n\u0003\n9. Martingales\nDefinition 9.1. Let {Fn }\u221e\nn=0 be a filtration of sub-\u03c3-fields of F . A\nsequence of random variables {Xn }\u221e\nn=0 is a martingale if there exists\nX \u2208 L\u221e such that Xn \u2208 E[X | Fn ] for all n (in particular, Xn \u2208\nL\u221e (Fn )).\nRemark 9.2. Note that our definition does not imply that Xn \u2208\nE[Xn+1 | Fn ] for all n. For example, suppose that Fn := {\u2205, \u03a9} for\nall n but X is not almost surely constant, then we obtain a martingale\nby taking Xn to be any constant in the ball E[X], but we only have\nXn \u2208 E[Xn+1 | Fn] for all n if X0 = X1 = X2 = . . ..\nMany of the usual real-valued examples of martingales have K-valued\ncounterparts.\nExample 9.3. Let {Yn }\u221e\nn=0 be a sequence of independent\nP\u221e random vari\u221e\nables in L with 0K \u2208 E[Yn ] for all n. Suppose that k=0 Yk converges\nin L\u221e (by the strong triangle inequality and the completeness of L\u221e ,\nthis is equivalent\n0). Set Fn := \u03c3{Y0 , Y1, . . . , Yn }.\nPn to limn\u2192\u221e kYn k\u221eP=\n\u221e\nY\nand\nX\n:=\nPut Xn :=\nn\nk=0 Yk It follows from the second\nk=0 k\nclaim of Proposition 6.1(i) that Xn \u2208 E[X | Fn ] for all n and hence\n{Xn }\u221e\nn=0 is a martingale.\n\n\fLOCAL FIELD EXPECTATION\n\n17\n\nExample 9.4. Let {Yn }\u221e\nrandom\nn=0 be a sequence of independent Q\nvariables in L\u221e with 1K \u2208 E[Yn ] for all n. Suppose that \u221e\nk=0 Yk\n\u221e\nconverges in L (by the strong triangle inequality and the completeness of L\u221e , this is equivalent to lim\nkYn \u2212 1K k\u221e Q\n= 0). Set\nQn\u2192\u221e\nn\nFn := \u03c3{Y0 , Y1 , . . . , Yn }. Put Xn := k=0 Yk and X := \u221e\nk=0 Yk . It\nfollows from the first claim of Proposition 6.1(i) that Xn \u2208 E[X | Fn ]\nfor all n and hence {Xn }\u221e\nn=0 is a martingale.\nExample 9.5. Let {Zn }\u221e\nn=0 be a discrete time Markov chain with\ncountable state space E and transition matrix P . Set Fn :=\n\u03c3{Z0 , Z1 , . . . , Zn }. Say that f : E \u2192 K is harmonic if f is bounded\nand for all i \u2208 E the expectation of f with respect to the probability\nmeasure P (i, *) contains f (i) (that is, if f (i) is belongs to the smallest\nball containing the set {f (j) : P (i, j) > 0}). Fix N \u2208 {0, 1, 2, . . .}.\n\u221e\nThen {Xn }\u221e\nn=0 := {f (Zn\u2227N )}n=0 is a martingale.\n10. Optional sampling theorem\n\u221e\nTheorem 10.1. Let {Fn }\u221e\nn=0 be a filtration. Suppose that X \u2208 L\n\u221e\nand {Xn }n=0 is a martingale with Xn \u2208 E[X | Fn ] for all n. If T is a\nstopping time, then XT \u2208 E[X | FT ].\n\nProof. It follows from Lemma 4.5 that 1{T = n}E[X | FT ] = 1{T =\nn}E[X | Fn] and hence, by Proposition 6.1(iii),\n\"\n#\nX\nE[X | FT ] = E\nX 1{T = n} | FT\nn\n\n=\n\nX\n\n1{T = n}E[X | FT ]\n\nn\n\n=\n\nX\n\n1{T = n}E[X | Fn ]\n\nn\n\n\u220b\n\nX\n\n1{T = n}Xn\n\nn\n\n= XT .\n\u0003\n11. Martingale convergence\n\u221e\nTheorem 11.1. Let {Fn }\u221e\nand\nn=0 be a filtration. Suppose that X \u2208 L\n\u221e\n{Xn }n=0 isSa martingale with Xn \u2208 E[X | Fn ] for all n. If X is in the\n\u221e\nclosure of \u221e\nn=1 L (Fn ), then limn\u2192\u221e kXn \u2212 Xk\u221e = 0 (in particular,\n\u221e\n{Xn }n=0 converges to X almost surely).\n\n\f18\n\nSTEVEN N. EVANS AND TYE LIDMAN\n\nS\n\u221e\nProof. Since X is in the closure of \u221e\nn=1 L (Fn ), for each \u03b5 > 0 there\n\u221e\nexists Y \u2208 L (FN ) for some N such that kX \u2212 Y k\u221e < \u03b5. Because\nFN \u2286 Fn for n > N, Y \u2208 L\u221e (Fn ) for n \u2265 N.\nBy Theorem 8.3, DH (E[X | Fn ], E[Y | Fn ]) < \u03b5 for n \u2265 N. However,\nE[Y | Fn] consists of the single point Y , and so the Hausdorff distance\nis simply sup{kW \u2212 Y k\u221e : W \u2208 E[X | Fn ]}. Thus\nkXn \u2212 Xk\u221e \u2264 kXn \u2212 Y k\u221e \u2228 kY \u2212 Xk\u221e < \u03b5\nfor n \u2265 N.\n\n\u0003\nReferences\n\n[Eva89]\n\nSteven N. Evans, Local field Gaussian measures, Seminar on Stochastic Processes, 1988 (Gainesville, FL, 1988), Progr. Probab., vol. 17,\nBirkh\u00e4user Boston, Boston, MA, 1989, pp. 121\u2013160. MR MR990478\n(91e:60121)\n[Eva91]\n, Equivalence and perpendicularity of local field Gaussian measures, Seminar on Stochastic Processes, 1990 (Vancouver, BC, 1990),\nProgr. Probab., vol. 24, Birkh\u00e4user Boston, Boston, MA, 1991, pp. 173\u2013\n181. MR MR1118442 (93m:60078)\n, Local field Brownian motion, J. Theoret. Probab. 6 (1993), no. 4,\n[Eva93]\n817\u2013850. MR MR1245397 (94i:60098)\n[Eva95]\n, p-adic white noise, chaos expansions, and stochastic integration,\nProbability measures on groups and related structures, XI (Oberwolfach,\n1994), World Sci. Publishing, River Edge, NJ, 1995, pp. 102\u2013115. MR\nMR1414928 (98e:60083)\n, Local field U -statistics, Algebraic methods in statistics and prob[Eva01a]\nability (Notre Dame, IN, 2000), Contemp. Math., vol. 287, Amer. Math.\nSoc., Providence, RI, 2001, pp. 75\u201381. MR MR1873668 (2003b:60014)\n[Eva01b]\n, Local fields, Gaussian measures, and Brownian motions, Topics\nin probability and Lie groups: boundary theory, CRM Proc. Lecture\nNotes, vol. 28, Amer. Math. Soc., Providence, RI, 2001, pp. 11\u201350. MR\nMR1832433 (2003e:60012)\n, Elementary divisors and determinants of random matrices over\n[Eva02]\na local field, Stochastic Process. Appl. 102 (2002), no. 1, 89\u2013102. MR\nMR1934156 (2004c:15041)\n[Eva06] Steven N. Evans, The expected number of zeros of a random system of\np-adic polynomials, U.C. Berkeley Department of Statistics Technical Report No. 699 and American Institute of Mathematics preprint number\nAIM 2006-9, 2006.\n[Khr97] Andrei Khrennikov, Non-Archimedean analysis: quantum paradoxes, dynamical systems and biological models, Mathematics and its Applications, vol. 427, Kluwer Academic Publishers, Dordrecht, 1997. MR\nMR1746953 (2001h:81004)\n[KN04] Andrei Yu. Khrennikov and Marcus Nilson, p-adic deterministic and random dynamics, Mathematics and its Applications, vol. 574, Kluwer Academic Publishers, Dordrecht, 2004. MR MR2105195 (2005h:37102)\n\n\fLOCAL FIELD EXPECTATION\n\n19\n\n[Koc01] Anatoly N. Kochubei, Pseudo-differential equations and stochastics over\nnon-Archimedean fields, Monographs and Textbooks in Pure and Applied Mathematics, vol. 244, Marcel Dekker Inc., New York, 2001. MR\nMR1848777 (2003b:35220)\n[Nev75] J. Neveu, Discrete-parameter martingales, revised ed., North-Holland\nPublishing Co., Amsterdam, 1975, Translated from the French by T. P.\nSpeed, North-Holland Mathematical Library, Vol. 10. MR MR0402915\n(53 #6729)\n[Sch84] W. H. Schikhof, Ultrametric calculus, Cambridge Studies in Advanced\nMathematics, vol. 4, Cambridge University Press, Cambridge, 1984, An\nintroduction to p-adic analysis. MR MR791759 (86j:11104)\n[Tai75] M. H. Taibleson, Fourier analysis on local fields, Princeton University\nPress, Princeton, N.J., 1975. MR MR0487295 (58 #6943)\n[vR78] A. C. M. van Rooij, Non-Archimedean functional analysis, Monographs\nand Textbooks in Pure and Applied Math., vol. 51, Marcel Dekker Inc.,\nNew York, 1978. MR MR512894 (81a:46084)\nDepartment of Statistics #3860, University of California at Berkeley, 367 Evans Hall, Berkeley, CA 94720-3860, U.S.A.\nE-mail address: evans@stat.berkeley.edu\nURL: http://www.stat.berkeley.edu/users/evans/\nE-mail address: tlid@berkeley.edu\n\n\f"}