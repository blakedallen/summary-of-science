{"id": "http://arxiv.org/abs/0908.1676v1", "guidislink": true, "updated": "2009-08-12T10:48:51Z", "updated_parsed": [2009, 8, 12, 10, 48, 51, 2, 224, 0], "published": "2009-08-12T10:48:51Z", "published_parsed": [2009, 8, 12, 10, 48, 51, 2, 224, 0], "title": "Improved Sparsity Thresholds Through Dictionary Splitting", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0908.2178%2C0908.2531%2C0908.2169%2C0908.0906%2C0908.3895%2C0908.1996%2C0908.0120%2C0908.0070%2C0908.0297%2C0908.0224%2C0908.1773%2C0908.4323%2C0908.2062%2C0908.1826%2C0908.1812%2C0908.1601%2C0908.3128%2C0908.0416%2C0908.1799%2C0908.2975%2C0908.1198%2C0908.0624%2C0908.0467%2C0908.3402%2C0908.4537%2C0908.3970%2C0908.4216%2C0908.4232%2C0908.0840%2C0908.2916%2C0908.3127%2C0908.4375%2C0908.0048%2C0908.1676%2C0908.2918%2C0908.4435%2C0908.4513%2C0908.1104%2C0908.0526%2C0908.3976%2C0908.2142%2C0908.2991%2C0908.0494%2C0908.3237%2C0908.0810%2C0908.0305%2C0908.1616%2C0908.1181%2C0908.1830%2C0908.1915%2C0908.0447%2C0908.1981%2C0908.1822%2C0908.2364%2C0908.1039%2C0908.0740%2C0908.0967%2C0908.4487%2C0908.3099%2C0908.3622%2C0908.1793%2C0908.2416%2C0908.2381%2C0908.2755%2C0908.1264%2C0908.4576%2C0908.0012%2C0908.2929%2C0908.2655%2C0908.0727%2C0908.0582%2C0908.3176%2C0908.3926%2C0908.4248%2C0908.3074%2C0908.4133%2C0908.4556%2C0908.4317%2C0908.2192%2C0908.3236%2C0908.4046%2C0908.3898%2C0908.3825%2C0908.0456%2C0908.3063%2C0908.0648%2C0908.3847%2C0908.4026%2C0908.3942%2C0908.0870%2C0908.1146%2C0908.4138%2C0908.4387%2C0908.2094%2C0908.3760%2C0908.1387%2C0908.0863%2C0908.2285%2C0908.2931%2C0908.2818%2C0908.1904&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Improved Sparsity Thresholds Through Dictionary Splitting"}, "summary": "Known sparsity thresholds for basis pursuit to deliver the maximally sparse\nsolution of the compressed sensing recovery problem typically depend on the\ndictionary's coherence. While the coherence is easy to compute, it can lead to\nrather pessimistic thresholds as it captures only limited information about the\ndictionary. In this paper, we show that viewing the dictionary as the\nconcatenation of two general sub-dictionaries leads to provably better sparsity\nthresholds--that are explicit in the coherence parameters of the dictionary and\nof the individual sub-dictionaries. Equivalently, our results can be\ninterpreted as sparsity thresholds for dictionaries that are unions of two\ngeneral (i.e., not necessarily orthonormal) sub-dictionaries.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0908.2178%2C0908.2531%2C0908.2169%2C0908.0906%2C0908.3895%2C0908.1996%2C0908.0120%2C0908.0070%2C0908.0297%2C0908.0224%2C0908.1773%2C0908.4323%2C0908.2062%2C0908.1826%2C0908.1812%2C0908.1601%2C0908.3128%2C0908.0416%2C0908.1799%2C0908.2975%2C0908.1198%2C0908.0624%2C0908.0467%2C0908.3402%2C0908.4537%2C0908.3970%2C0908.4216%2C0908.4232%2C0908.0840%2C0908.2916%2C0908.3127%2C0908.4375%2C0908.0048%2C0908.1676%2C0908.2918%2C0908.4435%2C0908.4513%2C0908.1104%2C0908.0526%2C0908.3976%2C0908.2142%2C0908.2991%2C0908.0494%2C0908.3237%2C0908.0810%2C0908.0305%2C0908.1616%2C0908.1181%2C0908.1830%2C0908.1915%2C0908.0447%2C0908.1981%2C0908.1822%2C0908.2364%2C0908.1039%2C0908.0740%2C0908.0967%2C0908.4487%2C0908.3099%2C0908.3622%2C0908.1793%2C0908.2416%2C0908.2381%2C0908.2755%2C0908.1264%2C0908.4576%2C0908.0012%2C0908.2929%2C0908.2655%2C0908.0727%2C0908.0582%2C0908.3176%2C0908.3926%2C0908.4248%2C0908.3074%2C0908.4133%2C0908.4556%2C0908.4317%2C0908.2192%2C0908.3236%2C0908.4046%2C0908.3898%2C0908.3825%2C0908.0456%2C0908.3063%2C0908.0648%2C0908.3847%2C0908.4026%2C0908.3942%2C0908.0870%2C0908.1146%2C0908.4138%2C0908.4387%2C0908.2094%2C0908.3760%2C0908.1387%2C0908.0863%2C0908.2285%2C0908.2931%2C0908.2818%2C0908.1904&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Known sparsity thresholds for basis pursuit to deliver the maximally sparse\nsolution of the compressed sensing recovery problem typically depend on the\ndictionary's coherence. While the coherence is easy to compute, it can lead to\nrather pessimistic thresholds as it captures only limited information about the\ndictionary. In this paper, we show that viewing the dictionary as the\nconcatenation of two general sub-dictionaries leads to provably better sparsity\nthresholds--that are explicit in the coherence parameters of the dictionary and\nof the individual sub-dictionaries. Equivalently, our results can be\ninterpreted as sparsity thresholds for dictionaries that are unions of two\ngeneral (i.e., not necessarily orthonormal) sub-dictionaries."}, "authors": ["Patrick Kuppinger", "Giuseppe Durisi", "Helmut B\u00f6lcskei"], "author_detail": {"name": "Helmut B\u00f6lcskei"}, "author": "Helmut B\u00f6lcskei", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ITW.2009.5351511", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0908.1676v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0908.1676v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "IEEE Information Theory Workshop (ITW), Taormina, Italy, Oct. 2009,\n  to appear", "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0908.1676v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0908.1676v1", "journal_reference": null, "doi": "10.1109/ITW.2009.5351511", "fulltext": "Improved Sparsity Thresholds Through\nDictionary Splitting\nPatrick Kuppinger, Giuseppe Durisi, and Helmut B\u00f6lcskei\n\narXiv:0908.1676v1 [cs.IT] 12 Aug 2009\n\nETH Zurich, 8092 Zurich, Switzerland\nE-mail: {patricku, gdurisi, boelcskei}@nari.ee.ethz.ch\nthe solution of (P1) necessarily guarantees that this solution is\nalso the unique solution of (P0).\nThe coherence is easy to compute but often leads to rather\npessimistic thresholds as it captures only limited information\nabout the dictionary. Using additional structural information\nabout the dictionary can lead to improved (i.e., higher) thresholds.\nFor example, in [7], [10] sparsity thresholds for a dictionary\nthat consists of the union of two orthonormal bases (ONBs) are\nderived that are about a factor of 2 higher than the corresponding\nthresholds for a general dictionary with the same coherence.\nContributions: We consider dictionaries-with coherence\nd-that consist of two general sub-dictionaries with coherence\nI. I NTRODUCTION\na and b, respectively. The two sub-dictionaries need not be\nA typical problem in compressed sensing (CS) [1], [2] is to ONBs, need not have the same number of elements, and do\nfind the sparsest representation of a given vector as a linear not need to span CM . We denote the set of all such dictionaries\ncombination of vectors from a given set, commonly referred to as D(d, a, b);1 the individual dictionaries in D(d, a, b) need not\nas dictionary [3]\u2013[9]. More concretely, let a dictionary be a set have the same cardinality.\nof N elements di \u2208 CM (i = 1, . . . , N ), which we assume\nFor dictionaries in D(d, a, b), we provide a sparsity threshold\n(throughout the paper) to have unit `2 -norm and to span CM . that guarantees uniqueness of the solution of (P0), and a threshold\nWe organize the dictionary elements into an M \u00d7 N matrix that guarantees uniqueness of the solution of (P1) and, hence,\nD = [d1 . . . dN ]; typically M \u001c N . Given the vector y \u2208 CM , equivalence of the solutions of (P1) and (P0). These thresholds\nthe problem of finding its sparsest representation in D can be depend on the parameters d, a, and b only and improve on the\nstated as follows:\nthreshold that would be obtained if one treated the union of two\nsub-dictionaries as a general dictionary with coherence d and\n(P0) find arg minkxk0 subject to y = Dx.\napplied the threshold in [6], [8]. The improvement is substantial\nHere, kxk0 denotes the number of nonzero entries of the vector whenever a, b \u001c d. The thresholds found in [7], [10] for\nx. Due to the combinatorial nature of the problem, solving (P0) the two-ONB setting are special cases of our thresholds. We\nis infeasible for practically relevant problem sizes N, M . A furthermore show that thinking of a general dictionary as the\nstandard approach in the CS literature is to relax (P0) to the concatenation of two (general) sub-dictionaries, the thresholds\nfollowing optimization problem, commonly referred to as basis derived in this paper strictly improve upon the one reported in [6],\npursuit [4]\u2013[9]\n[8], unless b = d in which case our thresholds coincide with\nthe one in [6], [8]. Any such splitting of a dictionary will yield\n(P1) find arg minkxk1 subject to y = Dx\nimproved sparsity thresholds. However, finding the optimal split,\nwhere kxk1 denotes the `1 -norm of x, and to ask under which for a given dictionary, in terms of obtaining the best possible\nconditions the solutions of (P1) and (P0) coincide. The advantage thresholds is a combinatorial problem.\nof this approach resides in the fact that (P1) can be cast into a\nOur threshold for uniqueness of the solution of (P0) is based\nlinear program [4] and can therefore be solved (more) efficiently. on a generalization of the uncertainty relation for the twoIt turns out that the solutions of (P0) and (P1) are unique ONB setting [7] to dictionaries in D(d, a, b). The derivation\nif there exists a vector x that satisfies y = Dx with kxk0 of the threshold for the uniqueness of the solution of (P1) is a\nless than a certain sparsity threshold [5]\u2013[9] (in the following generalization of the corresponding derivation for the two-ONB\noften referred to simply as threshold). This sparsity threshold case reported in [10].\nis a function of the dictionary's coherence [5], defined as the\nNotation: Throughout the paper, we use lowercase boldface\nmaximum of the absolute value of the inner product between letters for column vectors, e.g., x, and uppercase boldface letters\npairs of distinct columns of D, where the maximum is taken for matrices, e.g., D. For a given matrix D, we denote its\nover all such pairs in the dictionary. It was furthermore shown\n1 Without loss of generality, we assume a \u2264 b in the remainder of the paper.\nin [8] that a sparsity threshold that guarantees the uniqueness of\nAbstract-Known sparsity thresholds for basis pursuit to deliver the maximally sparse solution of the compressed sensing recovery problem typically depend on the dictionary's coherence.\nWhile the coherence is easy to compute, it can lead to rather pessimistic thresholds as it captures only limited information about\nthe dictionary. In this paper, we show that viewing the dictionary\nas the concatenation of two general sub-dictionaries leads to provably better sparsity thresholds-that are explicit in the coherence\nparameters of the dictionary and of the individual sub-dictionaries.\nEquivalently, our results can be interpreted as sparsity thresholds\nfor dictionaries that are unions of two general (i.e., not necessarily\northonormal) sub-dictionaries.\n\n\fconjugate transpose by DH , and the element in its ith row and any dictionary in Donb (d), a sufficient condition for x to be the\njth column by [D]i,j ; furthermore, di stands for its ith column, unique solution of (P0) is [7], [8], [10]\nand kern(D) is its null space. The ith element of a vector x\nkxk0 < 1/d.\n(4)\nis denoted\u221aby xi . The Euclidean or `2 -norm of the vector\nP x is\nH\nkxk2 = x x, the `1 -norm is defined as kxk1 =\ni |xi |, A sufficient condition for x to be the unique solution of (P1)\nand kxk\u221e = maxi |xi | is the `\u221e -norm of x. The smallest eigen- (which hence equals the unique solution of (P0)) is [7], [8], [10]\n\u221a\nvalue of the positive-definite matrix G is denoted by \u03bbmin (G).\n\u0001\u000e\n+\nkxk0 <\n2 \u2212 0.5 d.\n(5)\nFor u \u2208 R, we define [u] = max{0, u}.\nFor small d, the thresholds in (4) and (5) are almost a factor of 2\nII. P REVIOUS R ESULTS\nlarger than the threshold on the RHS of (3). Surprisingly,\nthe\n\u221a\nIn this section, we review relevant sparsity thresholds [5]\u2013[10]. threshold in (5) drops below that in (3) for d > 2( 2 \u2212 1).\nThe spark of a dictionary D, defined as the cardinality of the\nIII. T WO N OVEL S PARSITY T HRESHOLDS\nsmallest set of linearly dependent columns of D [6], sheds light\non the conditions for uniqueness of the solution of (P0). In particWe focus on the class D(d, a, b) of dictionaries with coherular, the following result holds: for a given dictionary D, a vec- ence d that consist of two sub-dictionaries with coherence a\n2\nN\ntor x \u2208 C is the unique solution of (P0) if and only if [6], [8] and b, respectively. A generic dictionary in D(d, a, b) is denoted\n\nas D = [A B], where A has coherence a and B has coherence b.\nThe sub-dictionaries A and B need not be ONBs, need not have\nwhere spark(D) denotes the spark of D. Determining the spark the same number of elements, and do not need to span CM . Note\nof a dictionary is a combinatorial problem and therefore computa- that D(d, a, b) \u2282 Dgen (d); hence, the sparsity threshold in (3)\ntionally expensive, in general. A common approach to overcome applies to any dictionary in D(d, a, b) as well. Furthermore, we\nthis problem is to derive lower bounds on spark(D) that are also have that5 Donb (d) \u2282 D(d, 0, 0). In Theorem 1 and 2 below,\nexplicit in an easy-to-compute parameter of the dictionary. Let, we derive sparsity thresholds that apply to the set D(d, a, b), are\nfor example, the coherence of a dictionary D be defined as3\nfunctions of d, a, and b only, and improve on the threshold that\nH\nwould\nbe obtained if one treated the union of two sub-dictionaries\nd = max di dj\n(1)\ni6=j\nas a general dictionary with coherence d. The basis for our result\nand let Dgen (d) be the set of all dictionaries with coherence d. on the uniqueness of the solution of (P0) is an uncertainty relation\nIt is shown in [6], [8], [9] that for any dictionary D in Dgen (d) for dictionaries in D(d, a, b) stated next.\nLemma 1: Let D = [A B], D \u2208 CM \u00d7N , be a dictionary in\nwe have that4\nM\nspark(D) \u2265 1 + 1/d.\n(2) D(d, a, b). For any vector in C that can be represented as a\nlinear combination of na linearly independent columns of A and,\nConsequently, for a dictionary with coherence d, a sufficient equivalently, as a linear combination of nb linearly independent\ncondition for a vector x to be the unique solution of (P0) is\ncolumns of B, the following inequality holds:\n\u0012\n\u0013\n+\n+\u000e\n1\n1\nna nb \u2265 [1 \u2212 a(na \u2212 1)] [1 \u2212 b(nb \u2212 1)] d2 .\n(6)\nkxk0 <\n1+\n.\n(3)\n2\nd\nProof: See Appendix A.\nIt is furthermore shown in [6], [8] that when (3) holds, the\nNote that for a = b = 0, (6) reduces to na nb \u2265 1/d2 , which is\nsolution of (P1) is unique as well (and hence equal to the unique\nthe well-known uncertainty relation for the union of two ONBs\nsolution of (P0)).\nreported in [7, Th. 1].\nThe threshold on the right-hand side (RHS) of (3) applies to\nWe next provide a lower bound on the spark of dictionaries\nany dictionary in Dgen (d). This set is, however, rather large and\nin the set D(d, a, b).\nthe dictionaries within the set can differ widely in their structure:\nTheorem 1: The spark of any dictionary D in the\nfrom equiangular tight frames [11], where each pair of elements\nset\nD(d, a, b) is lower-bounded according to\nin the dictionary achieves the maximum in (1), to dictionaries\nkxk0 < spark(D)/2\n\nwhere the maximum is achieved by one pair only. For a given\ndictionary, the threshold on the RHS of (3) might therefore be\nwhere\nrather pessimistic.\nBetter sparsity thresholds can be obtained if structural properties of the dictionary are explicitly taken into account. This leads\nto sparsity thresholds that apply to smaller sets of dictionaries. and\nLet, for example, Donb (d) \u2282 Dgen (d) be the set of dictionaries\nwith coherence d that consist of the union of two ONBs. For with\n2 In\n\nthe remainder of the paper, whenever we speak of a vector x, we mean\nthat this vector is consistent with the observation y, i.e., it satisfies y = Dx.\n3 For dictionaries consisting of only one element we set d = 0.\n4 Note that d \u2264 1 as we assumed that kd k = 1, i = 1, . . . , N .\ni 2\n\nspark(D) \u2265 x\u0302 + f (x\u0302)\n\nf (x) =\n\n(1 + a)(1 + b) \u2212 xb(1 + a)\nx(d2 \u2212 ab) + a(1 + b)\nx\u0302 = min{xb , xs }\n\nxb = (1 + b)/(b + d2 )\n5 D(d, 0, 0), for example, also contains dictionaries that consist of an ONB\nand an orthonormal set which does not form a basis.\n\n\fnary D as the concatenation of two sub-dictionaries A and B\n(i.e., splitting the dictionary D into A and B) yields improved\nsparsity thresholds, as a function of d, a, and b, compared to the\nthreshold (1 + 1/d)/2 in [6], [8].\nFor a = b = 0, the threshold in (8) reduces to\n\uf8f1\u221a\n\u221a\n\uf8f2( 2 \u2212 0.5)/d,\nif d < 1/ 2,\nkxk0 <\n(9)\n\uf8f31 + (1 \u2212 d)/(2d2 ), otherwise.\n\nthreshold for Donb (d = 0.1)[eq. (4)]\n\n10\n\n10\n\nthreshold for D(d = 0.1, a = b, b)[eq. (7)]\n\nthreshold for Dgen (d = 0.1)[eq. (3)]\n\n5.5\n\n5.5\n\n0\n\n0\n\n0.05\n\n0.05\n\n0.1\n\n0.1\n\nb\nFigure 1. Sparsity thresholds for dictionaries in Dgen (d), Donb (d), and\nD(d, a, b). The case d = 0.1 and a = b is considered. Note that when a = b,\nthe bound (7) reduces to kxk0 < (1 + b)/(d + b).\n\nand\n\uf8f1\n\uf8f4\nif a = b = d,\n\uf8f4\n\uf8f21/d,\np\nxs =\nd (1 + a)(1 + b) \u2212 a \u2212 ab\n\uf8f4\n\uf8f4\n\uf8f3\n, otherwise.\nd2 \u2212 ab\nProof: See Appendix B.\nTheorem 1 yields the following sufficient condition for a vector x\nto be the unique solution of (P0) for any D \u2208 D(d, a, b):\n\u0002\n\u0003\nkxk0 < x\u0302 + f (x\u0302) /2.\n(7)\n\nNote that\nin (5) when\n\u221a(9) coincides with the two-ONB threshold\n\u221a\nd < 1/ 2, but improves on (5) for d \u2265 1/ 2. Furthermore,\ndifferently from the threshold in (5), the threshold in (9) cannot\nfall below the threshold for Dgen (d) given by (1 + 1/d)/2.\nA PPENDIX A\nP ROOF OF L EMMA 1\nLet y be a vector in CM that can be represented as a linear\ncombination of na linearly independent columns of A and,\nequivalently, as a linear combination of nb linearly independent\ncolumns of B. Let P and Q be the sets containing the indices\nof the\nPparticipatingPcolumns in A and B, respectively. Then\ny = i\u2208P pi ai = j\u2208Q qj bj for some scalars {pi } and {qj }.\nLet p be the na -dimensional vector containing the scalars {pi },\nand, similarly, let q be the nb -dimensional vector containing the\nscalars {qj }. The following chain of inequalities holds:\nXX\nXX\nkyk22 =\np\u2217i aH\n|pi | |qj | aH\ni bj qj \u2264\ni bj\n\nThe threshold in (7) reduces to the one in (3) when a = b = d,\ni\u2208P j\u2208Q\ni\u2208P j\u2208Q\n\u221a\n\u221a\nor when xb \u2264 xs and b = d. In all other cases, the threshold\n(10)\n\u2264 dkpk1 kqk1 \u2264 d na kpk2 nb kqk2 .\nin (7) is strictly larger than that in (3), as shown in Appendix C.\nFurthermore, (7) reduces to (4) when a = b = 0. As illustrated Denote by AP the matrix containing the columns of A correin Fig. 1 for the case a = b, the improvement of the threshold sponding to the index set P. Furthermore, let GP = AH\nP AP .\nThen, we can lower-bound the `2 -norm of y as follows:\nin (7) over that in (3) is significant when a, b \u001c d.\nWe next present a sparsity threshold that guarantees the uniquekyk22 = pH AH\nAP p \u2265 \u03bbmin (GP )kpk22 .\n(11)\nness of the solution of (P1) (which is hence equal to the unique\n| P{z }\n= GP\nsolution of (P0)) for any dictionary in D(d, a, b).\nTheorem 2: For any dictionary D in D(d, a, b) a sufficient Using analogous steps (and notation), we also get\ncondition for (P1) to have a unique solution is\n\u0003\n(12)\nkyk22 = qH BH\nBQ q \u2265 \u03bbmin (GQ )kqk22 .\n\uf8f1 \u0002\n| Q{z }\n\u03b4 \u000f \u2212 (d + 3b)\n\uf8f4\n\uf8f4\n,\nif\nb\n<\nd\nand\n\u03ba(d,\nb)\n>\n1,\n\uf8f4\n= GQ\n\uf8f2 2(d2 \u2212 b2 )\nkxk0 <\nNote that both \u03bbmin (GP ) and \u03bbmin (GQ ) are strictly positive,\n\uf8f4\n2\n\uf8f4\n\uf8f4 1 + 2d + 3b \u2212 d\u03b4 , otherwise\nbecause the columns of AP and of BQ are linearly independent,\n\uf8f3\n2(d2 + b)\nby assumption. Inserting (11) and (12) into (10) yields\n(8)\n\u221a\n1p\nwith\nn\nn\n\u2265\n\u03bbmin (GP )\u03bbmin (GQ ).\n(13)\na\nb\np\nd\n\u03b4 2d (b + 3d + \u000f) \u2212 2d \u2212 2b(\u03b4 + d)\n\u03ba(d, b) =\nNext, proceeding as in [9, Lem. 2.3], we bound \u03bbmin (GP )\n2(d2 \u2212 b2 )\nand \u03bbmin (GQ ) from below using Ger\u0161gorin's disc theorem [12,\n\u221a p\nTh. 6.1.1] and obtain \u03bbmin (GP ) \u2265 max{0, 1 \u2212 a(na \u2212 1)} and\nwhere \u03b4 = 1 + b and \u000f = 2 2 d(b + d).\n\u03bbmin (GQ ) \u2265 max{0, 1 \u2212 b(nb \u2212 1)}, respectively. The proof\nProof: See Appendix D.\nThe threshold in (8) depends on b and d only. An improved is concluded by inserting these two lower bounds into (13).\nthreshold, which depends on a as well, can be obtained through\nA PPENDIX B\nminor modifications of the proof in Appendix D. The resulting\nP\nROOF OF T HEOREM 1\nexpression is, however, unwieldy.\nThe threshold in (8) reduces to the one in (3) whenever b = d\nLet D be an arbitrary dictionary in D(d, a, b), and let Z(D) be\n(independently of the value of a). Otherwise, the threshold in (8) the cardinality of the smallest set of linearly dependent columns\nis strictly larger than that in (3). Hence, viewing a given dictio- of D consisting of na \u2265 1 linearly independent columns of A\n\n\fand nb \u2265 1 linearly independent columns of B. By the definition\nof the spark [6, Def. 1], we have that\nspark(D) = min{spark(A), spark(B), Z(D)}.\n\n(14)\n\n(19)\n\nThe inequality in (19) follows from the convexity of g(x) and\nthe fact that g(1) \u2265 g(xb ).\n\nWe next lower-bound each term in (14). From (2) we get\nspark(A) \u2265 1 + 1/a and\n\nstationary point xs of g(x), which is given by\np\nd (1 + a)(1 + b) \u2212 a \u2212 ab\nxs =\n\u2265 1.\nd2 \u2212 ab\n\nspark(B) \u2265 1 + 1/b.\n\nA PPENDIX C\n\nSince a \u2264 b, by assumption, we obtain\n\nThe case a = b = d: The threshold in (7) reduces to the\nwell-known [6], [8] threshold (1 + 1/d)/2 in (3).\nThe case xb \u2264 xs : The threshold in (7) equals\nWe now seek a lower bound on the RHS of (15). To this end, we\n\u0013\n\u0012\nstart by noting that Z(D) = na + nb . In the light of (15), we\nx\u0302 + f (x\u0302)\nxb + f (xb )\n1\n1+b\n.\n=\n=\n1\n+\nneed to focus only on dictionaries that have na + nb \u2264 1 + 1/b.\n2\n2\n2\nb + d2\nFrom the uncertainty relation in Lemma 1, we know that the\nproduct na nb cannot be arbitrarily small. More specifically, we It is now easily verified that\n\u0013\n\u0012\n\u0012\n\u0013\nhave that na nb \u2265 [1 \u2212 a(na \u2212 1)][1 \u2212 b(nb \u2212 1)]/d2 . Solving\n1\n1\n1+b\n1\n6\n\u2265\n1+\n1+\nfor na , we get\n2\nb + d2\n2\nd\n(1 + a)(1 + b) \u2212 nb b(1 + a)\nfor all b \u2264 d \u2264 1 with equality onlyp\nif b = d.\nna \u2265\n= f (nb ).\nnb (d2 \u2212 ab) + a(1 + b)\nThe case xb > xs : Set \u2206 = (1 + a)(1 + b) \u2212 d. The\nfunction xs +f (xs ), which depends on the variables d, a, and b, is\nFinally, adding nb on both sides yields\nstrictly monotonically decreasing in a as long as b/d < \u2206 < d/b.\nZ(D) = na + nb \u2265 f (nb ) + nb .\n(16) The inequality \u2206 < d/b is always satisfied, because a \u2264 b \u2264 d.\nTo obtain an expression that is explicit in d, a, and b only, we The inequality b/d < \u2206 holds whenever xs < xb , which is\nfurther lower-bound the RHS of (16) by minimizing f (nb ) + nb satisfied by assumption. Hence, we have that\n\u0012\n\u0013\nover nb , under the additional constraints na \u2265 1 and nb \u2265 1\nxs + f (xs )\nxs + f (xs )\n1+b\n1\n1\n\u2265\n=\n\u2265\n1\n+\n.\n(implied by assumption). The resulting bound reads\n2\n2\nd+b\n2\nd\na=b\nZ(D) \u2265 min [nb + max{f (nb ), 1}].\nHere, equality holds only for the case a = b = d, already treated\nnb \u22651\nseparately above.\nSince\nA PPENDIX D\nmin [nb + max{f (nb ), 1}] \u2264 [nb + max{f (nb ), 1}] n =1/b\nb\nP ROOF OF T HEOREM 2\nnb \u22651\n= 1 + 1/b\nThe proof follows closely that of [10, Prop. 3], which deals\nspark(D) \u2265 min{1 + 1/b, Z(D)}.\n\n(15)\n\nwe can lower-bound the RHS of (14) by\nspark(D) \u2265 min [nb + max{f (nb ), 1}]\nnb \u22651\n\n\u2265 min [x + max{f (x), 1}].\nx\u22651\n\n(17)\n\nwith the case where A and B are ONBs. Our proof makes use\nof the following result.\nProposition 1 ([8, Lem. 1, Lem. 2], [10, Prop. 2]):\nLet SL (v) denote the sum of the largest (in absolute\nvalue) L entries of the vector v \u2208 CN and assume that\n\nSL (v)\n1\nHere, in the last step, we replaced the integer parameter nb\nPL (D) =\nmax\n< .\nby the real-valued parameter x. We next compute the mini2\nv6=0, v \u2208 kern(D) kvk1\nmum in (17). The function f (x) is monotonically decreasing.\nN\nFurthermore, the \u000eequation f (x) = 1 has the unique solu- Then, for all x \u2208 C with kxk0 < L and for all nonzero v \u2208\ntion xb = (1 + b) (b + d2 ) \u2265 1, where the inequality follows kern(D) we have that kx + vk0 > kxk0 and kx + vk1 > kxk1 .\nProposition 1 implies that x is the unique solution of both (P0)\nbecause d \u2264 1 by definition. We can, therefore, rewrite (17) as\nand (P1). We will use this proposition as follows: First, we will\nmin[x + max{f (x), 1}] = min [x + f (x)].\n(18) derive an upper bound on P (D) that is explicit in d, b, and L.\nL\nx\u22651\n1\u2264x\u2264xb\nSecond, we will impose that this upper bound falls below 1/2,\nIn the case a = b = d, the function g(x) = x + f (x) reduces to and then solve for L to get (8).\nthe constant 1 + 1/d so that spark(D) \u2265 1 + 1/d. In all other\nLet v be an arbitrary nonzero vector in kern(D). Becases, the function g(x) is strictly convex for x \u2265 0. Furthermore, cause D = [A B], it is convenient to view v as a concatenation\nwe have g(1) \u2265 g(xb ) as a consequence of the assumption a \u2264 b. of two vectors w and z that satisfy Aw = \u2212Bz. Let n be the\nHence, the minimum in (18) is achieved-as a result of the number of elements in w that belong to the set of L \u2265 1 largest\nconvexity of g(x)-either at the boundary point xb , or at the (in absolute value) entries of v and let W be the corresponding\nindex set. Similarly, let Z be the index set corresponding to the\n6 Equivalently, we could solve for n and obtain the same final result.\nL \u2212 n elements of z that belong to the set of largest (in absolute\nb\n\n\fvalue) entries of v. Two situations-that we treat separately-\nmay arise: n > L/2 and n \u2264 L/2.\nThe\nP case n > L/2: We assume, without\nPloss of generality,\nthat7 i\u2208W |wi | = 1. Furthermore, we set i\u2208W\n/ |wi | = \u03b3, so\nthat kwk1 = 1 + \u03b3. Then, we can write SL (v)/kvk1 as follows:\nP\nP\nP\n|wi | + i\u2208Z |zi |\n1 + i\u2208Z |zi |\nSL (v)\n= i\u2208W\n=\nkvk1\nkwk1 + kzk1\n1 + \u03b3 + kzk1\n1 + (L \u2212 n)kzk\u221e\n\u2264\n.\n(20)\n1 + \u03b3 + kzk1\n\nWe next derive an upper bound on kzk\u221e and a lower bound\non kzk1 both of which are explicit in b and d. The vectors w\nand z satisfy the following equality\nBH Aw = \u2212BH Bz.\n\n(21)\n\nTo get an upper bound on kzk\u221e , we next bound the `\u221e -norm\nof both sides of (21). For the LHS we have\nkBH Awk\u221e \u2264 max [BH A]i,j kwk1 \u2264 dkwk1 .\ni,j\n\n(22)\n\nThe RHS of (21) can be lower-bounded as follows. Let G =\nBH B and note that, by assumption, [G]i,i = 1 and [G]i,j \u2264 b\nfor i 6= j. Then\n\u001a\nX\nX \u001b\n[G]i,j zj \u2265 max |zi | \u2212 b\n|zj |\nkGzk\u221e = max zi +\ni\n\nj6=i\n\ni\n\nj6=i\n\n= (1 + b)kzk\u221e \u2212 bkzk1 .\n\n(23)\n\nCombining (22) and (23), we get\n(1 + b)kzk\u221e \u2212 bkzk1 \u2264 dkwk1\n\n(24)\n\nor, equivalently,\nkzk\u221e\n\nmax\n\nL/2<n\u2264L\n\nh(n, \u03b3, L) \u2264\n\nmax\n\nL/2<n\u2264L\n\nh(n, 0, L) \u2264 max h(x, 0, L).\nx\u22651\n\nFor b = d, the function h(x, 0, L) does not depend on x and\nreduces to\nh(x, 0, L) = Ld/(1 + d).\nThus, for b = d, the inequality h(x, 0, L) < 1/2 is satisfied\n(independently of x) if and only if L < (1 + 1/d)/2, which\ncoincides with the threshold previously found for general dictionaries in [6], [8].\nFor b < d and fixed L, the function h(x, 0, L) is concave\nin x for x \u2265 0. Furthermore, we have that h(1, 0, L) >\nlimx\u2192\u221e h(x, 0, L). Denoting the stationary point of h(x, 0, L)\nby x\u0303s = x\u0303s (d, b, L), the properties of h(x, 0, L) just stated imply\nthat\n(\nh(x\u0303s , 0, L), if x\u0303s (d, b, L) > 1\nmax h(x, 0, L) =\nx\u22651\nh(1, 0, L), otherwise.\nIf we now impose that maxx\u22651 h(x, 0, L) < 1/2 and solve\nfor L, we get the final result (8). The condition \u03ba(d, b) > 1\nin (8) is obtained by solving h(x\u0303s , 0, L) = 1/2 and inserting the\nresulting value of L into the condition x\u0303s (d, b, L) > 1.\nThe case n \u2264 L/2: In this case, we repeat the steps detailed\nabove for the case n > L/2, swapping the roles of w and z, and\nobtain an expression analogous to (28). The resulting threshold\ncoincides with (8).\nR EFERENCES\n\ndkwk1 + bkzk1\nd(1 + \u03b3) + bkzk1\n\u2264\n=\n.\n(1 + b)\n(1 + b)\n\n(25)\n\nSince the vectors w and z also satisfy\nAH Aw = \u2212AH Bz\nsteps similar to the ones used to arrive at (24) yield\n(1 + a)kwk\u221e \u2212 akwk1 \u2264 dkzk1 .\n\n(26)\n\nInvoking the assumption a \u2264 b, we can lower-bound the LHS\nof (26) according to (1 + a)kwk\u221e \u2212 akwk1 \u2265 (1 + b)kwk\u221e \u2212\nbkwk1 , which, upon insertion into (26), yields\n(1 + b)/n \u2212 b(1 + \u03b3)\n(1 + b)kwk\u221e \u2212 bkwk1\n\u2265\n.\nd\nd\n(27)\nIn the last step,P\nwe used kwk\u221e \u2265 1/n, as a consequence of the\nnormalization i\u2208W |wi | = 1 (recall that W has cardinality n).\nUsing (25) and (27) in (20), we obtain\nkzk1 \u2265\n\nSL (v)\n1 + (L \u2212 n)(d \u2212 b)(1 + \u03b3)/(1 + b) (L \u2212 n)b\n\u0002\n\u0003\n\u2264\n+\nkvk1\n1+b\n1 + \u03b3 + (1 + b)/n \u2212 b(1 + \u03b3) /d\n= h(n, \u03b3, L).\n(28)\n7A\n\nThis upper bound can be further simplified if we replace h(n, \u03b3, L) by its maximum with respect to n and \u03b3.\nThe function h(n, \u03b3, L) is monotonically decreasing in \u03b3 for\nn > L/2. Hence, we get\n\nscaling of v does not alter the ratio SL (v)/kvk1 .\n\n[1] D. L. Donoho, \"Compressed sensing,\" IEEE Trans. Inf. Theory, vol. 52,\nno. 4, pp. 1289\u20131306, Apr. 2006.\n[2] E. J. Cand\u00e8s, J. Romberg, and T. Tao, \"Robust uncertainty principles:\nExact signal reconstruction from highly incomplete frequency information,\"\nIEEE Trans. Inf. Theory, vol. 52, no. 2, pp. 489\u2013509, Feb. 2006.\n[3] S. Mallat and Z. Zhang, \"Matching pursuits with time-frequency dictionaries,\" IEEE Trans. Sig. Proc., vol. 41, pp. 3397\u20133415, Dec. 1993.\n[4] S. S. Chen, D. L. Donoho, and M. A. Saunders, \"Atomic decomposition\nby basis pursuit,\" SIAM J. Sci. Comput., vol. 20, no. 1, pp. 33\u201361, 1998.\n[5] D. L. Donoho and X. Huo, \"Uncertainty principles and ideal atomic\ndecomposition,\" IEEE Trans. Inf. Theory, vol. 47, no. 7, pp. 2845\u20132862,\nNov. 2001.\n[6] D. L. Donoho and M. Elad, \"Optimally sparse representation in general\n(nonorthogonal) dictionaries via `1 minimization,\" Proc. Natl. Acad. Sci.\nUSA, vol. 100, no. 5, pp. 2197\u20132202, Mar. 2003.\n[7] M. Elad and A. M. Bruckstein, \"A generalized uncertainty principle and\nsparse representation in pairs of bases,\" IEEE Trans. Inf. Theory, vol. 48,\nno. 9, pp. 2558\u20132567, Sep. 2002.\n[8] R. Gribonval and M. Nielsen, \"Sparse representations in unions of bases,\"\nIEEE Trans. Inf. Theory, vol. 49, no. 12, pp. 3320\u20133325, Dec. 2003.\n[9] J. A. Tropp, \"Greed is good: Algorithmic results for sparse approximation,\"\nIEEE Trans. Inf. Theory, vol. 50, no. 10, pp. 2231\u20132242, Oct. 2004.\n[10] A. Feuer and A. Nemirovski, \"On sparse representations in pairs of bases,\"\nIEEE Trans. Inf. Theory, vol. 49, no. 6, pp. 1579\u20131581, Jun. 2003.\n[11] T. Strohmer and R. W. Heath Jr., \"Grassmannian frames with applications\nto coding and communication,\" Appl. Comput. Harmonic Anal., vol. 14,\npp. 257\u2013275, 2003.\n[12] R. A. Horn and C. R. Johnson, Matrix Analysis.\nNew York, NY:\nCambridge Press, 1985.\n\n\f"}