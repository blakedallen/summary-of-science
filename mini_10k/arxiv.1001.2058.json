{"id": "http://arxiv.org/abs/1001.2058v1", "guidislink": true, "updated": "2010-01-13T02:03:16Z", "updated_parsed": [2010, 1, 13, 2, 3, 16, 2, 13, 0], "published": "2010-01-13T02:03:16Z", "published_parsed": [2010, 1, 13, 2, 3, 16, 2, 13, 0], "title": "Likelihood-free Markov chain Monte Carlo", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1001.5023%2C1001.3991%2C1001.1966%2C1001.3011%2C1001.4659%2C1001.0134%2C1001.0089%2C1001.0345%2C1001.5119%2C1001.1377%2C1001.1677%2C1001.0045%2C1001.4668%2C1001.4493%2C1001.4818%2C1001.3607%2C1001.3307%2C1001.3318%2C1001.4630%2C1001.4570%2C1001.4154%2C1001.3945%2C1001.0592%2C1001.5174%2C1001.4540%2C1001.3632%2C1001.1795%2C1001.5084%2C1001.4864%2C1001.3574%2C1001.0091%2C1001.5462%2C1001.0717%2C1001.3760%2C1001.2337%2C1001.1159%2C1001.5127%2C1001.4703%2C1001.1290%2C1001.5397%2C1001.4878%2C1001.1278%2C1001.3222%2C1001.0500%2C1001.0443%2C1001.4811%2C1001.5282%2C1001.3365%2C1001.5114%2C1001.4989%2C1001.4088%2C1001.1764%2C1001.0737%2C1001.1126%2C1001.4769%2C1001.0288%2C1001.3517%2C1001.3832%2C1001.2815%2C1001.0549%2C1001.2268%2C1001.2448%2C1001.2253%2C1001.1936%2C1001.3513%2C1001.0287%2C1001.0341%2C1001.3634%2C1001.4223%2C1001.3583%2C1001.3449%2C1001.1434%2C1001.5116%2C1001.3744%2C1001.3981%2C1001.1009%2C1001.3941%2C1001.2388%2C1001.3123%2C1001.4047%2C1001.5211%2C1001.2803%2C1001.2232%2C1001.1323%2C1001.3007%2C1001.4080%2C1001.4112%2C1001.3885%2C1001.5347%2C1001.5269%2C1001.1751%2C1001.0144%2C1001.1161%2C1001.5357%2C1001.3478%2C1001.0723%2C1001.2172%2C1001.3266%2C1001.4650%2C1001.2058%2C1001.3221&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Likelihood-free Markov chain Monte Carlo"}, "summary": "To appear to MCMC handbook, S. P. Brooks, A. Gelman, G. Jones and X.-L. Meng\n(eds), Chapman & Hall.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1001.5023%2C1001.3991%2C1001.1966%2C1001.3011%2C1001.4659%2C1001.0134%2C1001.0089%2C1001.0345%2C1001.5119%2C1001.1377%2C1001.1677%2C1001.0045%2C1001.4668%2C1001.4493%2C1001.4818%2C1001.3607%2C1001.3307%2C1001.3318%2C1001.4630%2C1001.4570%2C1001.4154%2C1001.3945%2C1001.0592%2C1001.5174%2C1001.4540%2C1001.3632%2C1001.1795%2C1001.5084%2C1001.4864%2C1001.3574%2C1001.0091%2C1001.5462%2C1001.0717%2C1001.3760%2C1001.2337%2C1001.1159%2C1001.5127%2C1001.4703%2C1001.1290%2C1001.5397%2C1001.4878%2C1001.1278%2C1001.3222%2C1001.0500%2C1001.0443%2C1001.4811%2C1001.5282%2C1001.3365%2C1001.5114%2C1001.4989%2C1001.4088%2C1001.1764%2C1001.0737%2C1001.1126%2C1001.4769%2C1001.0288%2C1001.3517%2C1001.3832%2C1001.2815%2C1001.0549%2C1001.2268%2C1001.2448%2C1001.2253%2C1001.1936%2C1001.3513%2C1001.0287%2C1001.0341%2C1001.3634%2C1001.4223%2C1001.3583%2C1001.3449%2C1001.1434%2C1001.5116%2C1001.3744%2C1001.3981%2C1001.1009%2C1001.3941%2C1001.2388%2C1001.3123%2C1001.4047%2C1001.5211%2C1001.2803%2C1001.2232%2C1001.1323%2C1001.3007%2C1001.4080%2C1001.4112%2C1001.3885%2C1001.5347%2C1001.5269%2C1001.1751%2C1001.0144%2C1001.1161%2C1001.5357%2C1001.3478%2C1001.0723%2C1001.2172%2C1001.3266%2C1001.4650%2C1001.2058%2C1001.3221&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "To appear to MCMC handbook, S. P. Brooks, A. Gelman, G. Jones and X.-L. Meng\n(eds), Chapman & Hall."}, "authors": ["S A Sisson", "Y Fan"], "author_detail": {"name": "Y Fan"}, "author": "Y Fan", "links": [{"href": "http://arxiv.org/abs/1001.2058v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1001.2058v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1001.2058v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1001.2058v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:1001.2058v1 [stat.ME] 13 Jan 2010\n\nChapter 1\n\nLikelihood-free Markov chain Monte\nCarlo\nScott A. Sisson and Yanan Fan\n\n1.1\n\nIntroduction\n\nIn Bayesian inference, the posterior distribution for parameters \u03b8 \u2208 \u0398 is given by \u03c0(\u03b8|y) \u221d\n\u03c0(y|\u03b8)\u03c0(\u03b8), where one's prior beliefs about the unknown parameters, as expressed through\nthe prior distribution \u03c0(\u03b8), is updated by the observed data y \u2208 Y via the likelihood function\n\u03c0(y|\u03b8). Inference for the parameters \u03b8 is then based on the posterior distribution. Except in\nsimple cases, numerical simulation methods, such as Markov chain Monte Carlo (MCMC),\nare required to approximate the integrations needed to summarise features of the posterior\ndistribution. Inevitably, increasing demands on statistical modelling and computation have\nresulted in the development of progressively more sophisticated algorithms.\nMost recently there has been interest in performing Bayesian analyses for models which\nare sufficiently complex that the likelihood function \u03c0(y|\u03b8) is either analytically unavailable\n1\n\n\f2\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\nTable 1.1: The likelihood-free rejection sampling algorithm (Tavar\u00e9 et al., 1997). Accepted\nparameter vectors are drawn approximately from \u03c0(\u03b8|y).\nLikelihood-free rejection sampling algorithm\n1. Generate \u03b80 \u223c \u03c0(\u03b8) from the prior.\n2. Generate dataset x from the model \u03c0(x|\u03b80 ).\n3. Accept \u03b80 if x \u2248 y.\n\nor computationally prohibitive to evaluate. The classes of algorithms and methods developed to perform Bayesian inference in this setting have become known as likelihood-free\ncomputation or approximate Bayesian computation (Beaumont et al., 2002; Marjoram et al.,\n2003; Ratmann et al., 2009; Sisson et al., 2007; Tavar\u00e9 et al., 1997). This name refers to the\ncircumventing of explicit evaluation of the likelihood by a simulation-based approximation.\nLikelihood-free methods are rapidly gaining popularity as a practical approach to fitting\nmodels under the Bayesian paradigm that would otherwise have been computationally impractical. To date they have found widespread usage in a diverse range of applications.\nThese include wireless communications engineering (Nevat et al., 2008), quantile distributions (Drovandi and Pettitt, 2009), HIV contact tracing (Blum and Tran, 2009), the evolution\nof drug resistance in tuberculosis (Luciani et al., 2009), population genetics (Beaumont et al.,\n2002), protein networks (Ratmann et al., 2009, 2007), archaeology (Wilkinson and Tavar\u00e9,\n2009); ecology (Jabot and Chave, 2009), operational risk (Peters and Sisson, 2006), species\nmigration (Hamilton et al., 2005), chain-ladder claims reserving (Peters et al., 2008), coalescent models (Tavar\u00e9 et al., 1997), \u03b1-stable models (Peters et al., 2009), models for extremes\n(Bortot et al., 2007), susceptible-infected-removed (SIR) models (Toni et al., 2009), pathogen\ntransmission (Tanaka et al., 2006) and human evolution (Fagundes et al., 2007).\nThe underlying concept of likelihood-free methods may be simply encapsulated as follows\n(see Table 1.1): For a candidate parameter vector \u03b80 , a dataset is generated from the model\n(i.e. the likelihood function) x \u223c \u03c0(x|\u03b80 ). If the simulated and observed datasets are similar\n(in some manner), so that x \u2248 y, then \u03b80 is a good candidate to have generated the observed\ndata from the given model, and so \u03b80 is retained and forms as a part of the samples from the\n\n\f1.2. REVIEW OF LIKELIHOOD-FREE THEORY AND METHODS\n\n3\n\nposterior distribution \u03c0(\u03b8|y). Conversely, if x and y are dissimilar, then \u03b80 is unlikely to have\ngenerated the observed data for this model, and so \u03b80 is discarded. The parameter vectors\naccepted under this approach offer support for y under the model, and so may be considered\nto be drawn approximately from the posterior distribution \u03c0(\u03b8|y). In this manner, the\nevaluation of the likelihood \u03c0(y|\u03b80 ), essential to most Bayesian posterior simulation methods,\nis replaced by an estimate of the proximity of a simulated dataset x \u223c \u03c0(x|\u03b80 ) to the observed\ndataset y. While available in various forms, all likelihood-free methods and models apply\nthis basic principle.\nIn this article we aim to provide a tutorial-style exposition of likelihood-free modelling\nand computation using MCMC simulation. In Section 1.2 we provide an overview of the\nmodels underlying likelihood-free inference, and illustrate the conditions under which these\nmodels form an acceptable approximation to the true, but intractable posterior \u03c0(\u03b8|y). In\nSection 1.3 we examine how MCMC-based samplers are able to circumvent evaluation of the\nintractable likelihood function, while still targetting this approximate posterior model. We\nalso discuss different forms of samplers that have been proposed in order to improve algorithm\nand inferential performance. Finally, in Section 1.4 we present a step-by-step examination of\nthe various practical issues involved in performing an analysis using likelihood-free methods,\nbefore concluding with a discussion.\nThroughout we assume a basic familiarity with Bayesian inference and the MetropolisHastings algorithm. For this relevant background information, the reader is referred to the\nmany useful articles in this volume.\n\n1.2\n\nReview of likelihood-free theory and methods\n\nIn this Section we discuss the modelling principles underlying likelihood-free computation.\n\n\f4\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n1.2.1\n\nLikelihood-free basics\n\nA common procedure to improve sampler efficiency in challenging settings is to embed the\ntarget posterior within an augmented model. In this setting, auxiliary parameters are introduced into the model whose sole purpose is to facilitate computations (see for example simulated tempering or annealing methods (Geyer and Thompson, 1995; Neal, 2003)).\nLikelihood-free inference adopts a similar approach by augmenting the target posterior from\n\u03c0(\u03b8|y) \u221d \u03c0(y|\u03b8)\u03c0(\u03b8) to\n\u03c0LF (\u03b8, x|y) \u221d \u03c0(y|x, \u03b8)\u03c0(x|\u03b8)\u03c0(\u03b8)\n\n(1.2.1)\n\nwhere the auxiliary parameter x is a (simulated) dataset from \u03c0(x|\u03b8) (see Table 1.1), on the\nsame space as y \u2208 Y (Reeves and Pettitt, 2005; Wilkinson, 2008). As discussed in more\ndetail below (Section 1.2.2), the function \u03c0(y|x, \u03b8) is chosen to weight the posterior \u03c0(\u03b8|x)\nwith high values in regions where x and y are similar. The function \u03c0(y|x, \u03b8) is assumed to\nbe constant with respect to \u03b8 at the point x = y, so that \u03c0(y|y, \u03b8) = c, for some constant\nc > 0, with the result that the target posterior is recovered exactly at x = y. That is,\n\u03c0LF (\u03b8, y|y) \u221d \u03c0(y|\u03b8)\u03c0(\u03b8).\nUltimately interest is typically in the marginal posterior\nZ\n\u03c0LF (\u03b8|y) \u221d \u03c0(\u03b8)\n\n\u03c0(y|x, \u03b8)\u03c0(x|\u03b8)dx,\n\n(1.2.2)\n\nY\n\nintegrating out the auxiliary dataset x. The distribution \u03c0LF (\u03b8|y) then acts as an approximation to \u03c0(\u03b8|y). In practice this integration is performed numerically by simply discarding\nthe realisations of the auxiliary datasets from the output of any sampler targetting the joint\nposterior \u03c0LF (\u03b8, x|y). Other samplers can target \u03c0LF (\u03b8|y) directly \u2013 see Section 1.3.1.\n\n1.2.2\n\nThe nature of the posterior approximation\n\nThe likelihood-free posterior distribution \u03c0LF (\u03b8|y) will only recover the target posterior\n\u03c0(\u03b8|y) exactly when the function \u03c0(y|x, \u03b8) is precisely a point mass at y = x and zero\n\n\f1.2. REVIEW OF LIKELIHOOD-FREE THEORY AND METHODS\n\n5\n\nelsewhere (Reeves and Pettitt, 2005). In this case\nZ\n\u03c0LF (\u03b8|y) \u221d \u03c0(\u03b8)\n\n\u03c0(y|x, \u03b8)\u03c0(x|\u03b8)dx = \u03c0(y|\u03b8)\u03c0(\u03b8).\nY\n\nHowever, as observed from Table 1.1, this choice for \u03c0(y|x, \u03b8) will result in a rejection sampler\nwith an acceptance probability of zero unless the proposed auxiliary dataset exactly equals\nthe observed data x = y. This event will occur with probability zero for all but the simplest\napplications (involving very low dimensional discrete data). In a similar manner, MCMCbased likelihood-free samplers (Section 1.3) will also suffer acceptance rates of zero.\nIn practice, two concessions are made on the form of \u03c0(y|x, \u03b8), and each of these can\ninduce some form of approximation into \u03c0LF (\u03b8|y) (Marjoram et al., 2003). The first allows\nthe function to be a standard smoothing kernel density, K, centered at the point x = y and\nwith scale determined by a parameter vector \u000f, usually taken as a scalar. In this manner\n1\n\u03c0\u000f (y|x, \u03b8) = K\n\u000f\n\n\u0012\n\n|x \u2212 y|\n\u000f\n\n\u0013\n\nweights the intractable likelihood with high values in regions x \u2248 y where the auxiliary\nand observed datasets are similar, and with low values in regions where they are not similar\n(Beaumont et al., 2002; Blum, 2009; Peters et al., 2008). The interpretation of likelihood-free\nmodels in the non-parametric framework is of current research interest (Blum, 2009).\nThe second concession on the form of \u03c0\u000f (y|x, \u03b8) permits the comparison of the datasets,\nx and y, to occur through a low-dimensional vector of summary statistics T (*), where\ndim(T (*)) \u2265 dim(\u03b8). Accordingly, given the improbability of generating an auxiliary dataset\nsuch that x \u2248 y, the function\n1\n\u03c0\u000f (y|x, \u03b8) = K\n\u000f\n\n\u0012\n\n|T (x) \u2212 T (y)|\n\u000f\n\n\u0013\n(1.2.3)\n\nwill provide regions of high value when T (x) \u2248 T (y) and low values otherwise. If the vector\nof summary statistics is also sufficient for the parameters \u03b8, then comparing the summary\nstatistics of two datasets will be equivalent to comparing the datasets themselves. Hence\nthere will be no loss of information in model fitting, and accordingly no further approximation\n\n\f6\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\nwill be introduced into \u03c0LF (\u03b8|y). However, the event T (x) \u2248 T (y) will be substantially more\nlikely than x \u2248 y, and so likelihood-free samplers based on summary statistics T (*) will\nin general be considerably more efficient in terms of acceptance rates than those based on\nfull datasets (Pritchard et al., 1999; Tavar\u00e9 et al., 1997). As noted by McKinley et al.\n(2009), the procedure of model fitting via summary statistics T (*) permits the application\nof likelihood-free inference in situations where the observed data y are incomplete.\nNote that under the form (1.2.3), lim\u000f\u21920 \u03c0\u000f (y|x, \u03b8) is a point mass on T (x) = T (y). Hence,\nif T (*) are also sufficient statistics for \u03b8, then lim\u000f\u21920 \u03c0LF (\u03b8|y) = \u03c0(\u03b8|y) exactly recovers the\nintractable posterior (Reeves and Pettitt, 2005). Otherwise, if \u000f > 0 or if T (*) are not\nsufficient statistics, then the likelihood-free approximation to \u03c0(\u03b8|y) is given by \u03c0LF (\u03b8|y) in\n(1.2.2).\nA frequently utilised weighting function \u03c0\u000f (y|x, \u03b8) is the uniform kernel density (Marjoram\net al., 2003; Tavar\u00e9 et al., 1997), whereby T (y) is uniformly distributed on the sphere centered\nat T (x) with radius \u000f. This is commonly written as\n\uf8f1\n\uf8f2 1 if \u03c1(T (x), T (y)) \u2264 \u000f\n\u03c0\u000f (y|x, \u03b8) \u221d\n\uf8f3 0 otherwise\n\n(1.2.4)\n\nwhere \u03c1 denotes a distance measure (e.g. Euclidean) between T (x) and T (y). In the form\nof (1.2.3) this is expressed as \u03c0\u000f (y|x, \u03b8) = \u000f\u22121 Ku (\u03c1(T (x), T (y))/\u000f), where Ku is the uniform\nkernel density. Alternative kernel densities that have been implemented include the Epanechnikov kernel (Beaumont et al., 2002), a non-parametric density estimate (Ratmann et al.,\n2009) (see Section 1.3.2), and the Gaussian kernel density (Peters et al., 2008), whereby\n\u03c0\u000f (y|x, \u03b8) is centered at T (x) and scaled by \u000f, so that T (y) \u223c N (T (x), \u03a3\u000f2 ) for some covariance matrix \u03a3.\n\n1.2.3\n\nA simple example\n\nAs an illustration, we examine the deviation of the likelihood-free approximation from the\ntarget posterior in a simple example. Consider the case where \u03c0(\u03b8|y) is the univariate N (0, 1)\n\n\f1.2. REVIEW OF LIKELIHOOD-FREE THEORY AND METHODS\n\n\u22124\n\n\u22122\n\n0\n\n2\n\n4\n\n0.4\n0.3\n0.0\n\n0.1\n\n0.2\n\nDensity\n\n0.3\n0.0\n\n0.1\n\n0.2\n\nDensity\n\n0.3\n0.2\n0.0\n\n0.1\n\nDensity\n\n(c)\n\n0.4\n\n(b)\n\n0.4\n\n(a)\n\n7\n\n\u22124\n\n\u22122\n\nTheta\n\n0\n\n2\n\n4\n\n\u22124\n\nTheta\n\n\u22122\n\n0\n\n2\n\n4\n\nTheta\n\nFigure 1.1: Comparison of likelihood-free approximations to the N (0, 1) target posterior\n(solid line). Likelihood-free posteriors are constructed using uniform (dotted line) and Gaussian\nline) \u221a\nkernel weighting densities \u03c0\u000f (y|x, \u03b8). Panels (a)\u2013(c) correspond to \u000f values\n\u221a(dashed\n\u221a\nof 3, 3/2 and 3/10 respectively.\n\ndensity. To realise this posterior in the likelihood-free setting, we specify the likelihood as\nx \u223c N (\u03b8, 1), define T (x) = x as a sufficient statistic for \u03b8 (the sample mean) and set the\nobserved data y = 0. With the prior \u03c0(\u03b8) \u221d 1 for convenience, if the weighting function\n\u03c0\u000f (y|x, \u03b8) is given by (1.2.4), with \u03c1(T (x), T (y)) = |x \u2212 y|, or if \u03c0\u000f (y|x, \u03b8) is a Gaussian\ndensity with y \u223c N (x, \u000f2 /3) then respectively\n\u03c0LF (\u03b8|y) \u221d\n\n\u03a6(\u000f \u2212 \u03b8) \u2212 \u03a6(\u2212\u000f \u2212 \u03b8)\n2\u000f\n\nand\n\n\u03c0LF (\u03b8|y) = N (0, 1 + \u000f2 /3),\n\nwhere \u03a6(*) denotes the standard Gaussian cumulative distribution function. The factor of\n3 in the Gaussian kernel density ensures that both uniform and Gaussian kernels have the\nsame standard deviation. In both cases \u03c0LF (\u03b8|y) \u2192 N (0, 1) as \u000f \u2192 0.\nThe two likelihood-free approximations are illustrated in Figure 1.1 which compares the\ntarget \u03c0(\u03b8|y) to both forms of \u03c0LF (\u03b8|y) for different values of \u000f. Clearly, as \u000f gets smaller\nthen \u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y) becomes a better approximation. Conversely, as \u000f increases, then\nso does the posterior variance in the likelihood-free approximation. There is only a small\ndifference between using uniform and Gaussian weighting functions in this case.\nSuppose now that an alternative vector of summary statistics T\u0303 (*) also permits unbiased\nestimates of \u03b8, but is less efficient than T (*), with a relative efficiency of e \u2264 1. As noted by A.\n\n\f8\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\nN. Pettitt (personal communication), for the above example with the Gaussian kernel density\nfor \u03c0\u000f (y|x, \u03b8), the likelihood-free approximation using T\u0303 (*) becomes \u03c0LF (\u03b8|y) = N (0, 1/e +\n\u000f2 /3). The 1/e term can easily be greater than the \u000f2 /3 term, especially as practical interest\nis in small \u000f. This example illustrates that inefficient statistics can often determine the\nquality of the posterior approximation, and that this approximation can remain poor even\nfor \u000f = 0.\nAccordingly, it is common in practice to aim to reduce \u000f as low as is computationally\nfeasible. However, in certain circumstances, it is not clear that doing so will result in a\nbetter approximation to \u03c0(\u03b8|y) than for a larger \u000f. This point is illustrated in Section 1.4.4.\n\n1.3\n\nLikelihood-free MCMC samplers\n\nA Metropolis-Hastings sampler may be constructed to target the augmented likelihood-free\nposterior \u03c0LF (\u03b8, x|y) (given by 1.2.1) without directly evaluating the intractable likelihood\n(Marjoram et al., 2003). Consider a proposal distribution for this sampler with the factorisation\nq[(\u03b8, x), (\u03b80 , x0 )] = q(\u03b8, \u03b80 )\u03c0(x0 |\u03b80 ).\nThat is, when at a current algorithm state (\u03b8, x), a new parameter vector \u03b80 is drawn from\na proposal distribution q(\u03b8, \u03b80 ), and conditionally on \u03b80 a proposed dataset x0 is generated\nfrom the model x0 \u223c \u03c0(x|\u03b80 ). Following standard arguments, to achieve a Markov chain\nwith stationary distribution \u03c0LF (\u03b8, x|y), we enforce the detailed-balance (time-reversibility)\ncondition\n\u03c0LF (\u03b8, x|y)P [(\u03b8, x), (\u03b80 , x0 )] = \u03c0LF (\u03b80 , x0 |y)P [(\u03b80 , x0 ), (\u03b8, x)]\nwhere the Metropolis-Hastings transition probability is given by\nP [(\u03b8, x), (\u03b80 , x0 )] = q[(\u03b8, x), (\u03b80 , x0 )]\u03b1[(\u03b8, x), (\u03b80 , x0 )].\n\n(1.3.1)\n\n\f1.3. LIKELIHOOD-FREE MCMC SAMPLERS\n\n9\n\nTable 1.2: The likelihood-free MCMC algorithm, generalised from Marjoram et al. (2003).\nLF-MCMC Algorithm\n1.\n\nInitialise (\u03b80 , x0 ) and \u000f. Set t = 0.\n\nAt\n2.\n3.\n4.\n\nstep t:\nGenerate \u03b80 \u223c q(\u03b8t , \u03b8) from a proposal distribution.\nGenerate x0 \u223c \u03c0(x|\u03b80 ) from the model given \u03b80 .\n(y|x0 ,\u03b80 )\u03c0(\u03b80 )q(\u03b80 ,\u03b8t )\n0\n0\nWith probability min{1, \u03c0\u03c0\u000f\u000f(y|x\n0 } set (\u03b8t+1 , xt+1 ) = (\u03b8 , x )\nt ,\u03b8t )\u03c0(\u03b8t )q(\u03b8t ,\u03b8 )\notherwise set (\u03b8t+1 , xt+1 ) = (\u03b8t , xt ).\n5. Increment t = t + 1 and go to 2.\n\nThe probability of accepting a move from (\u03b8, x) to (\u03b80 , x0 ) within the Metropolis-Hastings\nframework is then given by min{1, \u03b1[(\u03b8, x), (\u03b80 , x0 )]}, where\n\u03c0LF (\u03b80 , x0 |y)q[(\u03b80 , x0 ), (\u03b8, x)]\n\u03c0LF (\u03b8, x|y)q[(\u03b8, x), (\u03b80 , x0 )]\n\u03c0\u000f (y|x0 , \u03b80 )\u03c0(x0 |\u03b80 )\u03c0(\u03b80 ) q(\u03b80 , \u03b8)\u03c0(x|\u03b8)\n=\n\u03c0\u000f (y|x, \u03b8)\u03c0(x|\u03b8)\u03c0(\u03b8) q(\u03b8, \u03b80 )\u03c0(x0 |\u03b80 )\n\u03c0\u000f (y|x0 , \u03b80 )\u03c0(\u03b80 )q(\u03b80 , \u03b8)\n=\n.\n\u03c0\u000f (y|x, \u03b8)\u03c0(\u03b8)q(\u03b8, \u03b80 )\n\n\u03b1[(\u03b8, x), (\u03b80 , x0 )] =\n\n(1.3.2)\n\nNote that the intractable likelihoods do not need to be evaluated in the acceptance probability calculation (1.3.2), leaving a computationally tractable expression which can now be\nevaluated. Without loss of generality we may assume that min{1, \u03b1[(\u03b80 , x0 ), (\u03b8, x)]} = 1, and\nhence the detailed-balance condition (1.3.1), is satisfied since\n\u03c0LF (\u03b8, x|y)P [(\u03b8, x), (\u03b80 , x0 )] = \u03c0LF (\u03b8, x|y)q[(\u03b8, x), (\u03b80 , x0 )]\u03b1[(\u03b8, x), (\u03b80 , x0 )]\n\u03c0LF (\u03b8, x|y)q(\u03b8, \u03b80 )\u03c0(x0 |\u03b80 )\u03c0\u000f (y|x0 , \u03b80 )\u03c0(\u03b80 )q(\u03b80 , \u03b8)\n=\n\u03c0\u000f (y|x, \u03b8)\u03c0(\u03b8)q(\u03b8, \u03b80 )\n\u03c0\u000f (y|x, \u03b8)\u03c0(x|\u03b8)\u03c0(\u03b8)q(\u03b8, \u03b80 )\u03c0(x0 |\u03b80 )\u03c0\u000f (y|x0 , \u03b80 )\u03c0(\u03b80 )q(\u03b80 , \u03b8)\n=\n\u03c0\u000f (y|x, \u03b8)\u03c0(\u03b8)q(\u03b8, \u03b80 )\n0 0\n0 0\n= \u03c0\u000f (y|x , \u03b8 )\u03c0(x |\u03b8 )\u03c0(\u03b80 )q(\u03b80 , \u03b8)\u03c0(x|\u03b8)\n= \u03c0LF (\u03b80 , x0 |y)P [(\u03b80 , x0 ), (\u03b8, x)].\n\n\f10\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\nThe MCMC algorithm targetting \u03c0LF (\u03b8, x|y), adapted from Marjoram et al. (2003), is\n\nlisted in Table 1.2. The sampler generates the Markov chain sequence (\u03b8t , xt ) for t \u2265 0,\nalthough in practice, it is only necessary to store the vectors of summary statistics T (xt )\nand T (x0 ) at any stage in the algorithm. This is particularly useful when the auxiliary\ndatasets xt are large and complex.\nAn interesting feature of this sampler is that its acceptance rate is directly related to\nthe value of the true likelihood function \u03c0(y|\u03b80 ) at the proposed vector \u03b80 (Sisson et al.,\n2007). This is most obviously seen when using the uniform kernel weighting function (1.2.4),\nas proposed moves to (\u03b80 , x0 ) can only be accepted if \u03c1(T (x0 ), T (y)) \u2264 \u000f, and this occurs\nwith a probability in proportion to the likelihood. For low \u000f values this can result in very\nlow acceptance rates, particularly in the tails of the distribution, thereby affecting chain\nmixing in regions of low posterior density. See Section 1.4.5 for an illustration. However\nthe LF-MCMC algorithm offers improved acceptance rates over rejection sampling-based\nlikelihood-free algorithms (Marjoram et al., 2003).\nWe now examine a number of variations on the basic LF-MCMC algorithm which have\nbeen proposed either to improve sampler performance, or to examine model goodness-of-fit.\n\n1.3.1\n\nMarginal space samplers\n\nGiven the definition of \u03c0LF (\u03b8|y) in (1.2.2), an unbiased pointwise estimate of the marginal\nposterior distribution is available through Monte Carlo integration as\nS\n\n\u03c0(\u03b8) X\n\u03c0\u000f (y|xs , \u03b8)\n\u03c0LF (\u03b8|y) \u2248\nS s=1\n\n(1.3.3)\n\nwhere x1 , . . . , xS are independent draws from the model \u03c0(x|\u03b8) (Marjoram et al., 2003; Peters\net al., 2008; Ratmann et al., 2009; Reeves and Pettitt, 2005; Sisson et al., 2007; Toni et al.,\n2009; Wegmann et al., 2009). This then permits an MCMC sampler to be constructed directly\ntargetting the likelihood-free marginal posterior \u03c0LF (\u03b8|y). In this setting, the probability of\n\n\f1.3. LIKELIHOOD-FREE MCMC SAMPLERS\n\n11\n\naccepting a proposed move from \u03b8 to \u03b80 \u223c q(\u03b8, \u03b80 ) is given by min{1, \u03b1(\u03b8, \u03b80 )} where\n\u03c0LF (\u03b80 |y)q(\u03b80 , \u03b8)\n\u2248\n\u03b1(\u03b8, \u03b80 ) =\n\u03c0LF (\u03b8|y)q(\u03b8, \u03b80 )\n\nP\n0s 0\n0\n0\ns \u03c0\u000f (y|x , \u03b8 )\u03c0(\u03b8 )q(\u03b8 , \u03b8)\nP\ns\n0\ns \u03c0\u000f (y|x , \u03b8)\u03c0(\u03b8)q(\u03b8, \u03b8 )\n\n1\nS\n1\nS\n\n(1.3.4)\n\nwhere x0 1 , . . . , x0 S \u223c \u03c0(x|\u03b80 ). As the Monte Carlo approximation (1.3.3) becomes more\naccurate as S increases, the performance and acceptance rate of the marginal likelihood-free\nsampler will gradually approach that of the equivalent standard MCMC sampler.\nHowever, the above ratio of two unbiased likelihood estimates is only unbiased as S \u2192 \u221e.\nHence, the above sampler will only approximately target \u03c0LF (\u03b8|y) for large S, which makes\nit highly inefficient. However, note that estimating \u03b1(\u03b8, \u03b80 ) with S = 1 exactly recovers\n(1.3.2), the acceptance probability of the MCMC algorithm targetting \u03c0LF (\u03b8, x|y). That\nis, the marginal space likelihood-free sampler with S = 1 is precisely the likelihood-free\nMCMC sampler in Table 1.2. As the sampler targetting \u03c0LF (\u03b8, x|y) also provides unbiased\nestimates of the marginal \u03c0LF (\u03b8|y), it follows that the likelihood-free sampler targetting\n\u03c0LF (\u03b8|y) directly is also unbiased in practice (Sisson et al., 2008). A similar argument for\nS > 1 can also be made, as outlined below.\nAn alternative augmented likelihood-free posterior distribution is given by\n\u03c0LF (\u03b8, x1:S |y) \u221d \u03c0\u000f (y|x1:S , \u03b8)\u03c0(x1:S |\u03b8)\u03c0(\u03b8)\n\"\n#\" S\n#\nS\nY\n1X\n:=\n\u03c0\u000f (y|xs , \u03b8)\n\u03c0(xs |\u03b8)] \u03c0(\u03b8),\nS s=1\ns=1\nwhere x1:S = (x1 , . . . , xS ) represents s = 1, . . . , S replicate auxiliary datasets xs \u223c \u03c0(x|\u03b8).\nThis posterior, generalised from Del Moral et al. (2008), is based on the more general expected auxiliary variable approach of Andrieu et al. (2008), where the summation form\nS\nof \u03c0\u000f (y|x1:S , \u03b8) describes this expectation. The resulting marginal posterior \u03c0LF\n(\u03b8|y) =\nR\nS\n\u03c0 (\u03b8, x1:S , \u03b8|y)dx1:S is the same for all S, namely \u03c0LF\n(\u03b8|y) = \u03c0LF (\u03b8|y).\nY S LF\n\nThe motivation for this form of posterior is that that a sampler targetting \u03c0LF (\u03b8, x1:S |y),\nfor S > 1, will possess improved sampler performance compared to an equivalent sampler\ntargetting \u03c0LF (\u03b8, x|y), through a reduction in the variability of the Metropolis-Hastings\n\n\f12\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\nacceptance probability. With the natural choice of proposal density given by\n\nq[(\u03b8, x1:S ), (\u03b8\n\n0\n\n, x01:S )]\n\n0\n\n= q(\u03b8, \u03b8 )\n\nS\nY\n\n\u03c0(x0s |\u03b80 ),\n\ns=1\n\nwhere x01:S = (x01 , . . . , x0S ), the acceptance probability of a Metropolis-Hastings algorithm\ntargetting \u03c0LF (\u03b8, x1:S |y) reduces to\n\u03b1[(\u03b8, x1:S ), (\u03b80 , x01:S )] =\n\n1\nS\n1\nS\n\nP\n0s 0\n0\n0\ns \u03c0\u000f (y|x , \u03b8 )\u03c0(\u03b8 )q(\u03b8 , \u03b8)\nP\n.\ns\n0\ns \u03c0\u000f (y|x , \u03b8), \u03c0(\u03b8)q(\u03b8, \u03b8 )\n\n(1.3.5)\n\nThis is the same acceptance probability (1.3.4) as a marginal likelihood-free sampler targetting \u03c0LF (\u03b8|y) directly, using S Monte Carlo draws to estimate \u03c0LF (\u03b8|y) pointwise, via\n(1.3.3). Hence, both marginal and augmented likelihood-free samplers possess identical mixing and efficiency properties. The difference between the two is that the marginal sampler\nacceptance probability (1.3.4) is approximate for finite S, whereas the augmented sampler\nacceptance probability (1.3.5) is exact. However, clearly the marginal likelihood-free sampler\nis, in practice, unbiased for all S \u2265 1. See Sisson et al. (2008) a for more detailed analysis.\n\n1.3.2\n\nError-distribution augmented samplers\n\nIn all likelihood-free MCMC algorithms, low values of \u000f result in slowly mixing chains through\nlow acceptance rates. However, it also provides a potentially more accurate posterior approximation \u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y). Conversely, MCMC samplers with larger \u000f values may possess\nimproved chain mixing and efficiency, although at the expense of a poorer posterior approximation (e.g. Figure 1.1). Motivated by a desire for improved sampler efficiency while\nrealising low \u000f values, Bortot et al. (2007) proposed augmenting the likelihood-free posterior\napproximation to include \u000f, so that\n\u03c0LF (\u03b8, x, \u000f|y) \u221d \u03c0\u000f (y|x, \u03b8)\u03c0(x|\u03b8)\u03c0(\u03b8)\u03c0(\u000f).\nAccordingly, \u000f is treated as a tempering parameter in the manner of simulated tempering\n(Geyer and Thompson, 1995), with larger and smaller values respectively corresponding to\n\n\f1.3. LIKELIHOOD-FREE MCMC SAMPLERS\n\n13\n\n\"hot\" and \"cold\" tempered posterior distributions. The density \u03c0(\u000f) is a pseudo-prior, which\nserves only to influence the mixing of the sampler through the tempered distributions. Bortot\net al. (2007) suggested using a distribution which favours small \u000f values for accuracy, while\npermitting large values to improve chain acceptance rates. The approximation to the true\nposterior \u03c0(\u03b8|y) is then given by\nE\n(\u03b8|y)\n\u03c0LF\n\nZ Z\n=\n\n\u03c0LF (\u03b8, x, \u000f|y)dxd\u000f\nE\n\nY\n\nwhere \u000f \u2208 E \u2286 R+ . Sampler performance aside, this approach permits an a posteriori\nE\nevaluation of an appropriate value \u000f = \u000f\u2217 such that \u03c0LF\n(\u03b8|y) with E = [0, \u000f\u2217 ] provides an\n\nacceptable approximation to \u03c0(\u03b8|y).\nAn alternative error-distribution augmented model was proposed by Ratmann et al. (2009)\nwith the aim of diagnosing model mis-specification for the observed data y. For the vector\nof summary statistics T (x) = (T1 (x), . . . , TR (x)), the discrepancy between the model \u03c0(x|\u03b8)\nand the observed data is given by \u03c4 = (\u03c41 , . . . , \u03c4R ), where \u03c4r = Tr (x)\u2212Tr (y), for r = 1, . . . , R,\nis the error under the model in reproducing the r-th element of T (*). The joint distribution\nof model parameters and model errors is defined as\n\u03c0LF (\u03b8, x1:S , \u03c4 |y) \u221d \u03c0\u000f (y|\u03c4, x1:S , \u03b8)\u03c0(x1:S |\u03b8)\u03c0(\u03b8)\u03c0(\u03c4 )\n:= min \u03be\u02c6r (\u03c4r |y, x1:S , \u03b8)\u03c0(x1:S |\u03b8)\u03c0(\u03b8)\u03c0(\u03c4 ),\nr\n\n(1.3.6)\n\nwhere the univariate error distributions\n\u0013\n\u0012\nS\ns\nX\n1\n\u03c4\n\u2212\n[T\n(x\n)\n\u2212\nT\n(y)]\nr\nr\nr\n\u03be\u02c6r (\u03c4r |y, x1:S , \u03b8) =\nK\nS\u000fr s=1\n\u000fr\n\n(1.3.7)\n\nare constructed from smoothed kernel density estimates of model errors, estimated from S\nQ\nauxiliary datasets x1 , . . . , xS , and where \u03c0(\u03c4 ) = r \u03c0(\u03c4r ), the joint prior distribution for the\nmodel errors, is centered on zero, reflecting that the model is assumed plausible a priori. The\nterms minr \u03be\u02c6r (\u03c4r |y, x, \u03b8) and \u03c0(\u03c4 ) take the place of the weighting function \u03c0\u000f (y|\u03c4, x1:S , \u03b8). The\nminimum of the univariate densities \u03be\u02c6r (\u03c4r |y, x, \u03b8) is taken over the R model errors to reflect\nthe most conservative estimate of model adequacy, while also reducing the computation on\n\n\f14\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\nthe multivariate \u03c4 to its univariate component margins. The smoothing bandwidths \u000fr of\neach summary statistic Tr (*) are dynamically estimated during sampler implementation as\ntwice the interquartile range of Tr (xs ) \u2212 Tr (y), given x1 , . . . , xS .\nAssessment of model adequacy can then be based on \u03c0LF (\u03c4 |y) =\n\nR R\n\u0398\n\nYS\n\n\u03c0LF (\u03b8, x1:S , \u03c4 |y)dx1:S d\u03b8,\n\nthe posterior distribution of the model errors. If the model is adequately specified then\n\u03c0LF (\u03c4 |y) should be centered on the zero vector. If this is not the case then the model is\nmis-specified. The nature of the departure of \u03c0LF (\u03c4 |y) from the origin e.g. via one or more\nsummary statistics Tr (*), may indicate the manner in which the model is deficient. See e.g.\nWilkinson (2008) for further assessment of model errors in likelihood-free models.\n\n1.3.3\n\nPotential alternative MCMC samplers\n\nGiven the variety of MCMC techniques available for standard Bayesian inference, there are\na number of currently unexplored ways in which these might be adapted to improve the\nperformance of likelihood-free MCMC samplers.\nFor example, within the class of marginal space samplers (Section 1.3.1), the number of\nMonte Carlo draws S determines the quality of the estimate of \u03c0LF (\u03b8|y) (c.f. 1.3.3). A\nstandard implementation of the delayed-rejection algorithm (Tierney and Mira, 1999) would\npermit rejected proposals based on poor but computationally cheap posterior estimates (i.e.\nusing low-moderate S), to generate more accurate but computationally expensive secondstage proposals (using large S), thereby adapting the computational overheads of the sampler\nto the required performance.\nAlternatively, coupling two or more Markov chains targetting \u03c0LF (\u03b8, x|y), each utilising\na different \u000f value, would achieve improved mixing in the \"cold\" distribution (i.e. the chain\nwith the lowest \u000f) through the switching of states between neighbouring (in an \u000f sense)\nchains (Pettitt, 2006). This could be particularly useful in multi-modal posteriors. While\nthis flexibility is already available with continuously varying \u000f in the augmented sampler\ntargetting \u03c0LF (\u03b8, x, \u000f|y) (Bortot et al. (2007), Section 1.3.2), there are benefits to constructing\nsamplers from multiple chain sample-paths.\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n15\n\nFinally, likelihood-free MCMC samplers have to date focused on tempering distributions\nbased on varying \u000f. While not possible in all applications, there is clear scope for a class\nof algorithms based on tempering on the number of observed datapoints from which the\nsummary statistics T (*) are calculated. Lower numbers of datapoints will produce greater\nvariability in the summary statistics, in turn generating wider posteriors for the parameters\n\u03b8, but with lower computational overheads required to generate the auxiliary data x.\n\n1.4\n\nA practical guide to likelihood-free MCMC\n\nIn this Section we examine various practical aspects of likelihood-free computation under a\nsimple worked analysis. For observed data y = (y1 , . . . , y20 ) consider two candidate models:\nyi \u223c Exponential(\u03bb) and yi \u223c Gamma(k, \u03c8), where model equivalence is obtained under\nk = 1, \u03c8 = 1/\u03bb. Suppose that the sample mean and standard deviation of y are available\nas summary statistics T (y) = (\u0233, sy ) = (4, 1), and that interest is in fitting each model and\nin establishing model adequacy. Note that the summary statistics T (*) are sufficient for \u03bb\nbut not for (k, \u03c8), where they form moment-based estimators. For the following we consider\nflat priors \u03c0(\u03bb) \u221d 1, \u03c0(k, \u03c8) \u221d 1 for convenience. The true posterior distribution under the\nExponential(\u03bb) model is \u03bb|y \u223c Gamma(21, 80).\n\n1.4.1\n\nAn exploratory analysis\n\nAn initial exploratory investigation of model adequacy is illustrated in Figure 1.2, which\npresents scatterplots of summary statistics versus summary statistics, and summary statistics\nversus parameter values under each model. Images are based on 2000 parameter realisations\n\u03bb, k, \u03c8 \u223c U (0, 20) followed by summary statistic generation under each model parameter.\nHorizontal and vertical lines denote the values of the observed summary statistics T (y).\nFrom the plots of sample means against standard deviations, T (y) is clearly better represented by the Gamma than the Exponential model. The observed summary statistics (i.e.\nthe intersection of horizontal and vertical lines) lie in regions of relatively lower prior predic-\n\n\f16\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n\u25cf\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n2\n\n4\n\n6\n\n8\n\n10\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n15\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n10\n\n\u25cf \u25cf\u25cf\n\n\u25cf\n\n4\n\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n5\n\n\u25cf\n\u25cf\n\u25cf\n\n10\nk\n\n8\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n15\n\n\u25cf\n\n20\n\n\u25cf\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n10\n\n\u25cf\u25cf\n\u25cf\n\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n5\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf \u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n10\npsi\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\n0\n\n5\n\n10\n\n15\n\n15\n\n20\n\n15\n10\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n20\n\n5\n\n10\nk\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n0\n\n5\n\n10\n\n15\n\n20\n\n1/lambda\n\nGamma\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n0\n\n\u25cf\n\u25cf\n\n1/lambda\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\u25cf\n\nGamma\n\n\u25cf\n\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n6\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\n5\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\u25cf\n\nsample mean\n\n10\n5\n\nsample mean\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n2\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\u25cf\n\nGamma\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n0\n\n\u25cf\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf \u25cf\n\n15\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\nsample mean\n\n0\n\n15\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\nGamma\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\nsample mean\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n5\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n0\n\n\u25cf\n\u25cf\n\n\u25cf\n\nsample standard deviation\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n15\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n10\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n15\n\n20\n\n15\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n10\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n5\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf \u25cf\n\n5\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\nExponential\n\nsample standard deviation\n\n\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n10\n\n\u25cf\n\u25cf\n\u25cf\n\n5\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n0\n\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\nsample standard deviation\n\n\u25cf\n\nExponential\n\nsample mean\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n0 1 2 3 4 5 6 7\n\nExponential\n\u25cf\n\nsample standard deviation\n\n0 1 2 3 4 5 6 7\n\nsample standard deviation\n\nGamma\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n0\n\n5\n\n10\n\n15\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf \u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\n20\n\npsi\n\nFigure 1.2: Scatterplots of summary statistics T (x) = (x\u0304, sx ) and parameter values \u03bb, k, \u03c8\nunder both Exponential(\u03bb) and Gamma(k, \u03c8) models, based on 2000 realisations \u03bb, k, \u03c8 \u223c\nU (0, 20). Horizontal and vertical lines denote observed summary statistics T (y) = (4, 1).\nCircles denote the MLE of \u03bb\u0302 = 1/\u0233 = 1/4 under the Exponential model. Crosses denote\nmethod of moments estimators k\u0302 = \u0233 2 /s2y = 16 and \u03c8\u0302 = s2y /\u0233 = 1/4 under the Gamma\nmodel.\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n17\n\ntive density under the Exponential model, compared to the Gamma. That is, a priori, the\nstatistics T (y) appear more probable under the more complex model.\nConsider the plots of \u03bb\u22121 versus T (x) under the Exponential model. The observed statistics T (y) individually impose competing requirements on the Exponential parameter. An\nobserved sample mean of \u0233 = 4 indicates that \u03bb\u22121 is most likely in the approximate range\n[3, 5] (indicated by those \u03bb\u22121 values where the horizontal line intersects with the density).\nHowever, the sample standard deviation sy = 1 independently suggests that \u03bb\u22121 is most\nlikely in the approximate range [0.5, 1.5]. If either x\u0304 or sx were the only summary statistic,\nthen only one of these ranges are appropriate, and the observed data would be considerably\nmore likely under the Exponential model. However, the relative model fits and model adequacies of the Exponential and Gamma can only be evaluated by using the same summary\nstatistics on each model. (Otherwise, the model with the smaller number of summary statistics will be considered the most likely model, simply because it is more probable to match\nfewer statistics.) As a result, the competing constraints on \u03bb through the statistics x\u0304 and\nsy are so jointly improbable under the Exponential model that simulated and observed data\nwill rarely coincide, making T (y) very unlikely under this model. This is a strong indicator\nof model inadequacy.\nIn contrast, the plots of k and \u03c8 against T (x) under the Gamma model indicate no\nobvious restrictions on the parameters based on T (y), suggesting that this model is flexible\nenough to have generated the observed data with relatively high probability. Note that from\nthese marginal scatterplots, it is not clear that these statistics are at all informative for the\nmodel parameters. This indicates the importance of parameterisation for visualisation, as\nalternatively considering method of moments estimators as summary statistics (k\u0302, \u03c8\u0302), where\nk\u0302 = x\u03042 /s2x and \u03c8\u0302 = s2x /x\u0304, will result in strong linear relationships between (k, \u03c8) and (k\u0302, \u03c8\u0302).\nOf course, in practice direct unbiased estimators are rarely known.\n\n\f18\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n1.4.2\n\nThe effect of \u000f\n\nWe now implement the LF-MCMC algorithm (Table 1.2) targetting the Exponential(\u03bb)\nmodel, with an interest in evaluating sampler performance for different \u000f values. Recall that\nsmall \u000f is required to obtain a good likelihood-free approximation to the intractable posterior\n\u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y) (see Figure 1.1), where now \u03b8 = \u03bb. However, implementing the sampler\nwith low \u000f can be problematic in terms of initialising the chain and in achieving convergence\nto the stationary distribution.\nAn initialisation problem may occur when using weighting functions \u03c0\u000f (y|x, \u03b8) with compact support, such as the uniform kernel (1.2.4) defined on [\u2212\u000f, \u000f]. Here, initial chain values\n(\u03b80 , x0 ) are required such that \u03c0\u000f (y|x0 , \u03b80 ) 6= 0 in the denominator of the acceptance probability at time t = 1 (Table 1.2). For small \u000f, this is unlikely to be the case for the first such\nparameter vector tried. Two na\u0131\u0308ve strategies are to either repeatedly generate x0 \u223c \u03c0(x|\u03b80 ),\nor similarly repeatedly generate \u03b80 \u223c \u03c0(\u03b8) and x0 \u223c \u03c0(x|\u03b80 ), until \u03c0\u000f (y|x0 , \u03b80 ) 6= 0 is achieved.\nHowever, the former strategy may never terminate unless \u03b80 is located within a region of\nhigh posterior density. The latter strategy may never terminate if the prior is diffuse with\nrespect to the posterior. Relatedly, Markov chain convergence can be very slow for small\n\u000f when moving through regions of very low density, for which generating x0 \u223c \u03c0(x|\u03b80 ) with\nT (x0 ) \u2248 T (y) is highly improbable.\nOne strategy to avoid these problems is to augment the target distribution from \u03c0LF (\u03b8, x|y)\nto \u03c0LF (\u03b8, x, \u000f|y) (Bortot et al., 2007), permitting a time-variable \u000f to improve chain mixing\n(see Section 1.3 for discussion on this and other strategies to improve chain mixing). A\nsimpler strategy is to implement a specified chain burn-in period, defined by a monotonic\ndecreasing sequence \u000ft+1 \u2264 \u000ft , initialised with large \u000f0 , for which \u000ft = \u000f remains constant at\nthe desired level for t \u2265 t\u2217 , beyond some (possibly random) time t\u2217 (e.g. ?). For example,\nconsider the linear sequence \u000ft = max{\u000f0 \u2212 ct, \u000f} for some c > 0. However, the issue here is\nin determining the rate at which the sequence approaches the target \u000f: if c is too large, then\n\u000ft = \u000f before (\u03b8t , xt ) has reached a region of high density; if c is too small, then the chain\nmixes well but is computationally expensive through a slow burn in.\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n19\n\nOne self-scaling option for the uniform weighting function (1.2.4) would be to define\n\u000f0 = \u03c1(T (x0 ), T (y)), and given the proposed pair (\u03b80 , x0 ) at time t, propose a new \u000f value as\n\u000f00 = max{\u000f, min{\u000f0 , \u000ft\u22121 }}\n\n(1.4.1)\n\nwhere \u000f0 = \u03c1(T (x0 ), T (y)) > 0 is the distance between observed and simulated summary\nstatistics. If the proposed pair (\u03b80 , x0 ) are accepted then set \u000ft = \u000f00 , else set \u000ft = \u000ft\u22121 . That\nis, the proposed \u000f00 is dynamically defined as the smallest possible value that results in a nonzero weighting function \u03c0\u000ft (y|x0 , \u03b80 ) in the numerator of the acceptance probability, without\ngoing below the target \u000f, and while decreasing monotonically. If the proposed move to (\u03b80 , x0 )\nis accepted, the value \u000f00 is accepted as the new state, else the previous value \u000ft\u22121 is retained.\nSimilar approaches could be taken with non-uniform weighting functions \u03c0\u000f (y|x, \u03b8).\nFour trace plots of \u03bbt and \u000ft for the Exponential(\u03bb) model are illustrated in Figure 1.3\n(a,b), using the above procedure. All Markov chains were initialised at \u03bb0 = 10 with target\n\u000f = 3, proposals were generated via \u03bb0 \u223c N (\u03bbt\u22121 , 1) and the distance measure\n\b\n\u03c1(T (x), T (y)) = [T (x) \u2212 T (y)]> \u03a3\u22121 [T (x) \u2212 T (y)]\n\n1/2\n\n(1.4.2)\n\nis given by Mahalanobis distance. The covariance matrix \u03a3 = Cov(T (y)) is estimated by\nthe sample covariance of 1000 summary vectors T (x) generated from \u03c0(x|\u03bb\u0302) conditional on\n\u03bb\u0302 = 0.25 the maximum likelihood estimate. All four chains converge to the high density\nregion at \u03bb = 0.25 quickly, although at different speeds as the sampler takes different routes\nthrough parameter space. Mixing during burn-in is variable between chains, although overall\nconvergence to \u000ft = 3 is rapid. The requirement of tuning the rate of convergence, beyond\nspecifying the final tolerance \u000f, is clearly circumvented.\nFigure 1.3 (c,d) also illustrates the performance of the LF-MCMC sampler, post-convergence,\nbased on four chains of length 100,000, each with different target \u000f. As expected (see discussion in Section 1.3), smaller \u000f results in lower acceptance rates. In Figure 1.3 (c), \u000f = 4.5\n(bottom trace), 4, 3.5 and 3 (top) result in post-convergence (of \u000ft ) mean acceptance rates\nof 12.2%, 6.1%, 2.9% and 1.1% respectively. Conversely, precision (and accuracy) of the\nposterior marginal distribution for \u03bb increases with decreasing \u000f as seen in Figure 1.3 (d).\n\n\f20\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n5.0\n4.0\n\n4\n\n6\n\n8\n\nTrace of epsilon\n\n10 12\n\n6.0\n\n(b)\n\n0\n\n3.0\n\n2\n\nTrace of lambda\n\n(a)\n\n100\n\n200\n\n300\n\n400\n\n500\n\n0\n\n100\n\n200\n\n300\n\nIteration\n\nIteration\n\n(c)\n\n(d)\n\n400\n\n500\n\n4\n3\n1\n\n2\n\nDensity\n\n2.0\n1.0\n\n0\n\n0.0\n\nTrace of lambda\n\n3.0\n\n5\n\n0\n\n0\n\n2000\n\n4000\n\n6000\n\nIteration\n\n8000\n\n10000\n\n0.0\n\n0.5\n\n1.0\nLambda\n\nFigure 1.3: Performance of the LF-MCMC sampler for the Exponential(\u03bb) model. [Top\nplots] Trace plots of (a) \u03bbt and (b) \u000ft for four chains using the self-scaling {\u000ft } sequence\ngiven by (1.4.1). The MLE of \u03bb is 0.25 and the target \u000f is 3. [Bottom plots] (c) Jittered\ntrace plots of \u03bbt with different target \u000f = 4.5 (bottom), 4, 3.5 and 3 (top). (d) Posterior\ndensity estimates of \u03bb for the same chains based on a chain length of 100,000 iterations.\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n21\n\nIn practice, a robust procedure to identify a suitable target \u000f for the likelihood-free\nMCMC sampler is not yet available. Wegmann et al. (2009) implement the LF-MCMC\nalgorithm with a large \u000f value to enhance chain mixing, and then perform a regressionbased adjustment (Beaumont et al., 2002; Blum and Francois, 2009) to improve the final\nposterior approximation. Bortot et al. (2007) implement the LF-MCMC algorithm targetting the augmented posterior \u03c0LF (\u03b8, x, \u000f|y) (see Section 1.3.2), and examine the changes\nR R\nE\nin \u03c0LF\n(\u03b8|y) = E Y \u03c0LF (\u03b8, x, \u000f|y)dxd\u000f, with E = [0, \u000f\u2217 ], for varying \u000f\u2217 . The final choice of\n\u000f\u2217 is the largest value for which reducing \u000f\u2217 further produces no obvious improvement in\nthe posterior approximation. This procedure may be repeated manually through repeated\nLF-MCMC sampler implementations at different fixed \u000f values (Tanaka et al., 2006). Regardless, in practice \u000f is often reduced as low as possible such that computation remains\nwithin acceptable limits.\n\n1.4.3\n\nThe effect of the weighting function\n\nThe optimal form of kernel weighting function \u03c0\u000f (y|x, \u03b8) for a given analysis is unclear at\npresent. While the uniform weighting function (1.2.4) is the most common in practice \u2013\nindeed, many likelihood-free methods have this kernel written directly into the algorithm\n(sometimes implicitly) \u2013 it seems credible that alternative forms may offer improved posterior approximations for given computational overheads. Some support for this is available\nthrough recently observed links between the likelihood-free posterior approximation \u03c0LF (\u03b8|y)\nand non-parametric smoothing (Blum, 2009).\nHere we evaluate the effect of the weighting function \u03c0\u000f (y|x, \u03b8) on posterior accuracy\nunder the Exponential(\u03bb) model, as measured by the one-sample Kolmogorov-Smirnov distance between the likelihood-free posterior sample and the true Gamma(21,80) posterior. To\nprovide fair comparisons, we evaluate posterior accuracy as a function of computational overheads, measured by the mean post-convergence acceptance rate of the LF-MCMC sampler.\nThe following results are based on posterior samples consisting of 1000 posterior realisations\nobtained by recording every 1000th chain state, following a 10,000 iteration burn-in period.\nFigures are constructed by averaging the results of 25 sampler replications under identical\n\n\f22\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n(a)\n\n0.6\n0.4\n\nMahalanobis\nScaled Euclidean\nEuclidean\n\n0.0\n\n0.0\n\n0.2\n\n0.4\n\nKS statistic\n\n0.6\n\nUniform\nEpanechnikov\nTriangle\n\n0.2\n\nKS statistic\n\n(b)\n\n0.00\n\n0.05\n\n0.10\n\n0.15\n\n0.20\n\nMean acceptance probability\n\n0.00\n\n0.05\n\n0.10\n\n0.15\n\n0.20\n\nMean acceptance probability\n\nFigure 1.4: Performance of the LF-MCMC sampler for the Exponential(\u03bb) model under varying kernel weighting functions: (a) Mahalanobis distance between T (x) and T (y) evaluated\non uniform, Epanechnikov and triangle kernel functions; (b) Mahalanobis, scaled Euclidean\nand Euclidean distance between T (x) and T (y) evaluated on the uniform kernel function.\nSampler performance is measured in terms of accuracy (y-axis: one-sample KolmogorovSmirnov test statistic evaluated between likelihood-free posterior sample and true posterior)\nversus computational overheads (x-axis: mean sampler acceptance probability).\n\nconditions, for a range of \u000f values.\nFigure 1.4 (a) shows the effect of varying the form of the kernel weighting function based\non the Mahalanobis distance (1.4.2). There appears little obvious difference in the accuracy\nof the posterior approximations in this example. However, it is credible to suspect that\nnon-uniform weighting functions may be superior in general (e.g. Blum (2009); Peters et al.\n(2008)). This is more clearly demonstrated in Section 1.4.5. The slight worsening in the\naccuracy of the posterior approximation, indicated by the upturn for low \u000f in Figure 1.4 (a),\nwill be examined in more detail in Section 1.4.4.\nRegardless of its actual form, the weighting function \u03c0\u000f (y|x, \u03b8) should take the distribution of the summary statistics T (*) into consideration. Fan et al. (2010) note that using\na Euclidean distance measure (given by (1.4.2) with \u03a3 = I, the identity matrix) within\n(say) the uniform weighting function (1.2.4), ignores the scale and dependence (correlation)\nstructure of T (*), accepting sampler moves if T (y) is within a circle of size \u000f centered on\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n23\n\nT (x), rather than within an ellipse defined by \u03a3 = Cov(T (y)). In theory, the form of the\ndistance measure does not matter as in the limit \u000f \u2192 0 any effect of the distance measure\n\u03c1 is removed from the posterior \u03c0LF (\u03b8|y) i.e. T (x) = T (y) regardless of the form of \u03a3. In\npractice however, with \u000f > 0, the distance measure can have a strong effect on the quality\nof the likelihood-free posterior approximation \u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y).\nUsing the uniform weighting function, Figure 1.4 (b) demonstrates the effect of using\nMahalanobis distance (1.4.2), with \u03a3 given by estimates of Cov(T (y)), diag(Cov(T (y)))\n(scaled Euclidean distance) and the identity matrix I (Euclidean distance). Clearly, for a\nfixed computational overhead (x-axis), greater accuracy is attainable by standardising and\northogonalising the summary statistics. In this sense, Mahalanobis distance represents an\napproximate standardisation of the distribution of T (y)|\u03b8\u0303 at an appropriate point \u03b8\u0303 following\nindirect inference arguments (Jiang and Turnbull, 2004). As Cov(T (y)) may vary with \u03b8,\nFan et al. (2010) suggest using an approximate MAP estimate of \u03b8, so that \u03b8\u0303 resides in a\nregion of high posterior density. The assumption is then that Cov(T (y)) varies little over\nthe region of high posterior density.\n\n1.4.4\n\nThe choice of summary statistics\n\nLikelihood-free computation is based on the reproduction of observed statistics T (y) under\nthe model. If the T (y) are sufficient for \u03b8, then the true posterior \u03c0(\u03b8|y) can be recovered\nexactly as \u000f \u2192 0. If dim(T (y)) is large (e.g. Bortot et al. (2007)), then likelihood-free\nalgorithms become computationally inefficient through the need to reproduce large numbers\nof summary statistics (Blum, 2009). However, low-dimensional, non-sufficient summary\nvectors produce less efficient estimators of \u03b8, and so generate wider posterior distributions\n\u03c0LF (\u03b8|y) than using sufficient statistics (see Section 1.2.3). Ideally, low-dimensional and\nnear-sufficient T (y) are the preferred option.\nUnfortunately, it is usually difficult to know which statistics are near-sufficient in practice.\nA brute-force strategy to address this issue is to repeat the analysis, while sequentially increasing the number of summary statistics each time (in order of their perceived importance),\n\n\f24\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n\u25cf\n\n\u25cf\u25cf\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n(c)\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n1.0\n\n1.0\n\n(b)\n\n1.0\n\n(a)\n\n\u25cf\n\n0.8\n\n0.8\n\n0.8\n\n\u25cf\n\n0.6\n\n\u25cf\n\n0.2\n\n\u25cf\n\n\u25cf\n\n0.4\n\nKS statistic\n\n0.6\n0.2\n\n\u25cf\n\n0.4\n\nKS statistic\n\n0.6\n0.4\n\n\u25cf\n\n0.2\n\nKS statistic\n\n\u25cf\n\u25cf\n\n\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n1\n\n2\nEpsilon\n\n3\n\n4\n\n0.0\n\n\u25cf\n\n0.0\n\n0.0\n\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n0\n\n1\n\n2\nEpsilon\n\n3\n\n4\n\n0\n\n1\n\n2\n\n3\n\n4\n\nEpsilon\n\nFigure 1.5: Likelihood-free posterior accuracy of the Exponential(\u03bb) model as a function of\n\u000f for differing summary statistics: (a) T (y) = \u0233; (b) T (y) = sy ; (c) T (y) = (\u0233, sy ). Posterior accuracy (y-axis) is measured by one-sample Kolmogorov-Smirnov (KS) test statistic\nevaluated between likelihood-free posterior sample and true posterior. Points and vertical\nlines represent KS statistic means and ranges based on 25 sampler replicates at fixed \u000f levels. Crosses in panel (b) denote KS statistic evaluated with respect to a Gamma(21,20)\ndistribution.\n\nuntil no further changes to \u03c0LF (\u03b8|y) are observed (Marjoram et al., 2003). See also Joyce\nand Marjoram (2008). If the extra statistics are uninformative, the quality of approximation\nwill remain the same, but the sampler will be less efficient. However, simply enlarging the\nnumber of informative summary statistics is not necessarily the best way to improve the\nlikelihood-free approximation \u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y), and in fact may worsen the approximation\nin some cases.\nAn example of this is provided by the present Exponential(\u03bb) model, where either of\nthe two summary statistics T (y) = (\u0233, sy ) = (4, 1) alone is informative for \u03bb (and indeed,\n\u0233 is sufficient), as we expect that \u03bb \u2248 1/\u0233 \u2248 1/sy under any data generated from this\nmodel. In this respect, however, the observed values of the summary statistics provide\nconflicting information for the model parameter (see Section 1.4.1). Figure 1.5 examines\nthe effect of this, by evaluating the accuracy of the likelihood-free posterior approximation\n\u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y) as a function of \u000f under different summary statistic combinations. As\nbefore, posterior accuracy is measured via the one-sample Kolmogorov-Smirnov test statistic\nwith respect to the true Gamma(21,80) posterior.\nWith T (y) = \u0233, panel (a) demonstrates that accuracy improves as \u000f decreases, as expected.\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n25\n\nFor panel (b), with T (y) = sy (dots), the resulting \u03c0LF (\u03b8|y) posterior is clearly different\nfrom the true posterior for all \u000f. Of course, the limiting posterior as \u000f \u2192 0 is (very)\napproximately Gamma(21,20), resulting from an Exponential model with \u03bb = 1/sy = 1,\nrather than Gamma(21,80) resulting from an Exponential model with \u03bb = 1/\u0233 = 1/4.\nThe crosses in panel (b) denote the Kolmogorov-Smirnov test statistic with respect to the\nGamma(21,20) distribution, which indicates that \u03c0LF (\u03b8|y) is roughly consistent with this\ndistribution as \u000f decreases. That the Gamma(21,20) is not the exact limiting density (i.e.\nthe KS statistic does not tend to zero as \u000f \u2192 0) stems from the fact that sy is not a sufficient\nstatistic for \u03bb, and is less then fully efficient.\nIn panel (c) with T (y) = (\u0233, sy ), which contains an exactly sufficient statistic (i.e. \u0233), the\naccuracy of \u03c0LF (\u03b8|y) appears to improve with decreasing \u000f, and then actually worsens before\nimproving again. This would appear to go against the generally accepted principle, that for\nsufficient statistics, decreasing \u000f will always improve the approximation \u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y).\nOf course, the reality here is that both of these competing statistics are pulling the likelihood\nfree posterior in different directions, with the consequence that the limiting posterior as\n\u000f \u2192 0 will be some combination of both Gamma distributions, rather than the presumed\n(and desired) Gamma(21,80).\nThis observation leads to the uncomfortable conclusion that model comparison through\nlikelihood-free posteriors with a fixed vector of summary statistics T (y), will ultimately\ncompare distortions of those models which are overly simplified with respect to the true\ndata generation process. This remains true even when using sufficient statistics and for\n\u000f \u2192 0.\n\n1.4.5\n\nImproving mixing\n\nRecall that the acceptance rate of the LF-MCMC algorithm (Table 1.2) is directly related\nto the value of the true likelihood \u03c0(y|\u03b80 ) at the proposed vector \u03b80 (Section 1.3). While\nthis is a necessary consequence of likelihood-free computation, it does imply poor sampler\nperformance in regions of low probability, as the Markov chain sample-path may persist in\n\n\f26\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\u25cf\n\n(b)\n\n150\n\n3.0\n\n(a)\n\n\u25cf\n\n\u25cf\n\n2.0\n\nTrace of psi\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n1.0\n\n100\n\n\u25cf\n\n50\n\nTrace of k\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n0.0\n\n0\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n0\n\n1000\n\n2000\n\n\u25cf\n\n3000\n\n4000\n\n5000\n\n\u25cf\n\n\u25cf\n\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n5000\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\nIteration\n\nIteration\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n(c)\n\n\u25cf\n\n\u25cf\n\u25cf\n\n(d)\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n600\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n25\n\n50\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n0\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\nLength of sojourn\n\n\u25cf\n\u25cf\n\u25cf\n\n500 1000\n\n1000\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n0 200\n\nLength of sojourn\n\n\u25cf\n\u25cf\n\n\u25cf\n\n2000\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n1\n\n1\n\n10\n\n10\n\n25\n\n25\n\nNumber of dataset generations, S\n\n50\n\n1\n\n1\n\n10\n\n10\n\n25\n\nNumber of dataset generations, S\n\nFigure 1.6: Aspects of LF-MCMC sampler performance: [Top plots] Trace plots of (a) k and\n(b) \u03c8 parameters under the Gamma model, for varying numbers of auxiliary datasets S = 1\n(lower traces), 10, 25 and 50 (upper traces) using \u000f = 2 and the uniform kernel function\n\u03c0\u000f (y|x, \u03b8). [Bottom plots] Distribution of sojourn lengths of parameter k above (c) \u03ba = 45\nand (d) \u03ba = 50 for varying numbers of auxiliary datasets. Boxplot shading indicates uniform\n(white)\u221aor Gaussian (grey) kernel functions \u03c0\u000f (y|x, \u03b8). The Gaussian kernel sampler used\n\u000f = 2/ 3 to ensure a comparable standard deviation with the uniform kernel sampler.\n\ndistributional tails for long periods of time due to low acceptance probabilities (Sisson et al.,\n2007). An illustration of this shown in Figure 1.6 (a, b: lowest light grey lines), which\ndisplays the marginal sample paths of k and \u03c8 under the Gamma(k, \u03c8) model, based on\n5000 iterations of a sampler targetting \u03c0(\u03b8, x|y) with \u000f = 2 and using the uniform kernel\nfunction \u03c0\u000f (y|x, \u03b8). At around 1400 iterations the sampler becomes stuck in the tail of the\nposterior for the following 700 iterations, with very little meaningful movement.\nA simple strategy to improve sampler performance in this respect is to increase the number\nof auxiliary datasets S generated under the model, either by targetting the joint posterior\n\u03c0LF (\u03b8, x1:S |y) or the marginal posterior \u03c0LF (\u03b8|y) with S \u2265 1 Monte Carlo draws (see Section\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n\n27\n\n1.3.1). This approach will reduce the variability of the acceptance probability (1.3.4), and\nallow the Markov chain acceptance rate to approach that of a sampler targetting the true\nposterior \u03c0(\u03b8|y). The trace plots in Figure 1.6 (a,b) (bottom to top) correspond to chains\nimplementing S = 1, 10, 20 and 50 auxiliary dataset generations per likelihood evaluation.\nVisually, there is some suggestion that mixing is improved as S increases. Note however,\nthat for any fixed S, the LF-MCMC sampler may still become stuck if the sampler explores\nsufficiently far into the distributional tail.\nFigure 1.6 (c,d) investigates this idea from an alternative perspective. Based on 2 million\nsampler iterations, the lengths of sojourns that the k parameter spent above a fixed threshold\n\u03ba were recorded. A sojourn length is defined as the consecutive number of iterations in which\nthe parameter k remains above \u03ba. Intuitively, if likelihood-free samplers tend to persist in\ndistributional tails, the length of the sojourns will be much larger for the worse performing\nsamplers. Figure 1.6 (c,d) shows the distributions of sojourn lengths for samplers with\nS = 1, 10, 25 and 50 auxiliary datasets, with \u03ba = 45 (panel c) and \u03ba = 50 (panel d). Boxplot\nshading indicates use of the uniform (white) or Gaussian (grey) weighting function \u03c0\u000f (y|x, \u03b8).\nA number of points are immediately apparent. Firstly, chain mixing is poorer the further\ninto the tails the sampler explores. This is illustrated by the increased scale of the sojourn\nlengths for \u03ba = 50 compared to \u03ba = 45. Secondly, increasing S by a small amount substantially reduces chain tail persistence. As S increases further, the Markov chain performance\napproaches that of a sampler directly targetting the true posterior \u03c0(\u03b8|y), and so less performance gains are observed by increasing S beyond a certain point. Finally, there is strong\nevidence to suggest that LF-MCMC algorithms using weighting kernel functions \u03c0\u000f (y|x, \u03b8)\nthat do not generate large numbers of zero-valued likelihoods will possess superior performance to those which do. Here use of the Gaussian weighting kernel clearly outperforms the\nuniform kernel in all cases. In summary, it would appear that the choice of kernel weighting\nfunction \u03c0\u000f (\u03b8|y) has a larger impact on sampler performance than the number of auxiliary\ndatasets S.\n\n\f28\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\nExponential Model: \u03c42\n\n\u25cf\n\n0\n\n2\n\n4\n\n1\n\n\u25cf\u25cf\n\n0\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u22121\n\n\u25cf\n\n\u22122\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u22123\n\n\u03c42: sample standard deviation\n\u22126\n\n\u22124\n\n\u22122\n\n0\n\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n2\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u22125\n\n0.2\n0.1\n\u22122\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf \u25cf\n\n\u25cf\n\n\u25cf\n\n0.0\n\u22124\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u22126\n\n\u22124\n\n\u22122\n\n0\n\n2\n\n\u03c41: sample mean\n\n\u03c42: sample standard deviation\n\n\u03c41: sample mean\n\nGamma Model: \u03c41\n\nGamma Model: \u03c42\n\nGamma Model\n\n0.8\n\n\u22126\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u22124\n\n0.5\n\n\u25cf\n\n\u25cf\n\n0.3\n\nDensity\n\n0.4\n\n0.6\n\n0.30\n0.25\n0.20\n0.15\n0.10\n0.05\n0.00\n\nDensity\n\nExponential Model\n2\n\nExponential Model: \u03c41\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n0.2\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf \u25cf\u25cf \u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\n\u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n0\n\n\u25cf\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u22121\n\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\n\u25cf\n\n\u22123\n\n\u22122\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u22124\n\n0.6\nDensity\n\n0.4\n\n0.4\n0.3\n0.2\n\nDensity\n\n\u03c42: sample standard deviation\n\n1\n\n0.5\n\n\u25cf\n\n0.1\n\n4\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u22125\n\n0.0\n\n0.0\n\n\u25cf\n\n\u22126\n\n\u22124\n\n\u22122\n\n0\n\n\u03c41: sample mean\n\n2\n\n4\n\n\u25cf\n\u25cf\n\n\u22126\n\n\u22124\n\n\u22122\n\n0\n\n\u03c42: sample standard deviation\n\n2\n\n\u22126\n\n\u22124\n\n\u22122\n\n0\n\n2\n\n4\n\n\u03c41: sample mean\n\nFigure 1.7: Marginal likelihood-free posterior distributions \u03c0LF (\u03c4 |y) of the error-distribution\naugmented model (1.3.6), under the Exponential (top plots) and Gamma (bottom plots)\nmodels. Plots are based on 50,000 sampler iterations.\n\n\f1.4. A PRACTICAL GUIDE TO LIKELIHOOD-FREE MCMC\n1.4.6\n\n29\n\nEvaluating model mis-specification\n\nIn order to evaluate the adequacy of both Exponential and Gamma models in terms of their\nsupport for the observed data T (y) = (\u0233, sy ), we fit the error-distribution augmented model\n(1.3.6) given by\n\u03c0LF (\u03b8, x1:S , \u03c4 |y) := min \u03be\u02c6r (\u03c4r |y, x1:S , \u03b8)\u03c0(x1:S |\u03b8)\u03c0(\u03b8)\u03c0(\u03c4 ),\nr\n\nas described in Section 1.3.2 (Ratmann et al., 2009). The vector \u03c4 = (\u03c41 , \u03c42 ) with \u03c4r =\nTr (x) \u2212 Tr (y) for r = 1, 2, describes the error under the model in reproducing the observed\nsummary statistics T (y). The marginal likelihood-free posterior \u03c0LF (\u03c4 |y) should be centered\non the zero vector for models which can adequately account for the observed data.\nWe follow Ratmann et al. (2009) in specifying K in (1.3.7) as a biweight (quartic) kernel\nwith an adaptive bandwidth \u000fr determined by twice the interquartile range of Tr (xs ) \u2212 Tr (y)\nQ\ngiven x1:S = (x1 , . . . , xS ). The prior on the error \u03c4 is determined as \u03c0(\u03c4 ) = r \u03c0(\u03c4r ), where\n\u03c0(\u03c4r ) = exp(\u2212|\u03c4r |/\u03b4r )/(2\u03b4r ) with \u03b41 = \u03b42 = 0.75 for both Exponential and Gamma models.\nBased on 50,000 sampler iterations using S = 50 auxiliary datasets, the resulting bivariate\nposterior \u03c0LF (\u03c4 |y) is illustrated in Figure 1.7 for both models. From these plots, the errors \u03c4\nunder the Gamma model (bottom plots) are clearly centered on the origin, with 50% marginal\nhigh-density regions given by \u03c41 |y \u223c [\u22120.51, 0.53] and \u03c42 |y \u223c [\u22120.44, 0.22] (Ratmann et al.,\n2009). However for the Exponential model (top plots), while the marginal 50% high density\nregions \u03c41 |y \u223c [\u22120.32, 1.35] and \u03c42 |y \u223c [\u22120.55, 0.27] also both contain zero, there is some\nindication of model mis-specification as the joint posterior error distribution \u03c4 |y is not fully\ncentered on the zero vector. Based on this assessment, and recalling the discussion on the\nexploratory analysis in Section 1.4.1, the Gamma model would appear to provide a better\noverall fit to the observed data.\n\n\f30\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n1.5\n\nDiscussion\n\nIn the early 1990's, the introduction of accessible Markov chain Monte Carlo samplers provided the catalyst for a rapid adoption of Bayesian methods and inference as credible tools in\nmodel-based research. Twenty years later, the demand for computational techniques capable\nof handling the types of models inspired by complex hypotheses has resulted in new classes\nof simulation-based inference, that are again expanding the applicability and relevance of\nthe Bayesian paradigm to new levels.\nWhile the focus of the present article centers on Markov chain-based, likelihood-free\nsimulation, alternative methods to obtain samples from \u03c0LF (\u03b8|y) have been developed, each\nwith their own benefits and drawbacks. While MCMC-based samplers can be more efficient\nthan rejection sampling algorithms, the tendency of sampler performance to degrade in\nregions of low posterior density (see Section 1.4.5; Sisson et al. (2007)) can be detrimental\nto sampler efficiency. One class of methods, based on the output of a rejection sampler with\na high \u000f value (for efficiency), uses standard multivariate regression methods to estimate\nthe relationship between the summary statistics T (x) and parameter vectors \u03b8 (Beaumont\net al., 2002; Blum and Francois, 2009; Marjoram and Tavar\u00e9, 2006). The idea is then\nto approximately transform the sampled observations from (\u03b8, T (x)) to (\u03b8\u2217 , T (y)) so that\nthe adjusted likelihood-free posterior \u03c0LF (\u03b8, x|y) \u2192 \u03c0LF (\u03b8\u2217 , y|y) \u2248 \u03c0(\u03b8|y) is an improved\napproximation. Further attempts to improve sampler efficiency over MCMC-based methods\nhave resulted in the development of likelihood-free sequential Monte Carlo and sequential\nimportance sampling algorithms (Beaumont et al., 2009; Del Moral et al., 2008; Peters et al.,\n2008; Sisson et al., 2007; Toni et al., 2009). Several authors have reported that likelihoodfree sequential Monte Carlo approaches can outperform their MCMC counterparts (McKinley\net al., 2009; Sisson et al., 2007).\nThere remain many open research questions in likelihood-free Bayesian inference. These\ninclude how to select and incorporate the vectors of summary statistics T (*), how to perform\nposterior simulation in the most efficient manner, and which form of joint likelihood-free\nposterior models and kernel weighting functions admit the most effective marginal approximation to the true posterior \u03c0LF (\u03b8|y) \u2248 \u03c0(\u03b8|y). Additionally, the links to existing bodies of\n\n\f1.5. DISCUSSION\n\n31\n\nresearch, including non-parametrics (Blum, 2009) and indirect inference (Jiang and Turnbull,\n2004), are at best poorly understood.\nFinally, there is an increasing trend towards using likelihood-free inference for model\nselection purposes (Grelaud et al., 2009; Toni et al., 2009). While this is a natural extension\nof inference for individual models, the analysis in Section 1.4.4 urges caution and suggests\nthat further research is needed into the effect of the likelihood-free approximation both\nR\nwithin models and on the marginal likelihoods \u03c0LF (y) = Y \u03c0LF (\u03b8|y)d\u03b8 upon which model\ncomparison is based.\n\nAcknowledgments\nThis work was supported by the Australian Research Council through the Discovery Project\nscheme (DP0664970 and DP1092805).\n\n\f32\n\nCHAPTER 1. LIKELIHOOD-FREE MCMC\n\n\fBibliography\nAndrieu, C., Berthelsen, K. K., Doucet, A., and Roberts, G. O. (2008). The expected\nauxiliary variable method for Monte Carlo simulation. Technical report, In preparation.\nBeaumont, M. A., Cornuet, J.-M., Marin, J.-M., and Robert, C. P. (2009). Adaptive approximate Bayesian computation. Biometrika, in press.\nBeaumont, M. A., Zhang, W., and Balding, D. J. (2002). Approximate Bayesian computation\nin population genetics. Genetics, 162:2025 \u2013 2035.\nBlum, M. G. B. (2009). Approximate Bayesian computation: a non-parametric perspective.\nTechnical report, Universit\u00e9 Joseph Fourier, Grenoble, France.\nBlum, M. G. B. and Francois, O. (2009). Non-linear regression models for approximate\nBayesian computation. Statistics and Computing, page in press.\nBlum, M. G. B. and Tran, V. C. (2009). HIV with contact-tracing: A case study in approximate Bayesian computation. Technical report, Universit\u00e9 Joseph Fourier.\nBortot, P., Coles, S. G., and Sisson, S. A. (2007). Inference for stereological extremes.\nJournal of the American Statistical Association, 102:84\u201392.\nDel Moral, P., Doucet, A., and Jasra, A. (2008). Adaptive sequential Monte Carlo samplers.\nTechnical report, University of Bordeaux.\nDrovandi, C. C. and Pettitt, A. N. (2009). A note on Bayesian estimation of quantile\ndistributions. Technical report, Queensland University of Technology.\n33\n\n\f34\n\nBIBLIOGRAPHY\n\nFagundes, N. J. R., Ray, N., Beaumont, M. A., Neuenschwander, S., Salzano, F. M., Bonatto,\nS. L., and Excoffier, L. (2007). Statistical evaluation of alternative models of human\nevolution. Proc. Natl. Acad. Sci. USA, 104:17614\u201317619.\nFan, Y., Peters, G. W., and Sisson, S. A. (2010). Impoved efficiency in approximate Bayesian\ncomputation. Technical report, University of New South Wales.\nGeyer, C. J. and Thompson, E. A. (1995). Annealing Markov chain Monte Carlo with\napplications to ancestral inference. Journal of the American Statistical Association, 90:909\u2013\n920.\nGrelaud, A., Robert, C. P., Marin, J.-M., Rodolphe, F., and Taly, J.-F. (2009). ABC\nlikelihood-free methods for model choice in gibbs random fields. Bayesian Analysis, 4:317\u2013\n336.\nHamilton, G., Currat, M., Ray, N., Heckel, G., Beaumont, M. A., and Excoffier, L. (2005).\nBayesian estimation of recent migration rates after a spatial expansion. Genetics, 170:409\u2013\n417.\nJabot, F. and Chave, J. (2009). Inferring the parameters of the netural theory of biodiversity\nusing phylogenetic information and implications for tropical forsts. Ecology Letters, 12:239\u2013\n248.\nJiang, W. and Turnbull, B. (2004). The indirect method: Inference based on intermediate\nstatistics \u2013 A synthesis and examples. Statistical Science, 19:238\u2013263.\nJoyce, P. and Marjoram, P. (2008). Approximately sufficient statistics and Bayesian computation. Statistical Applications in Genetics and Molecular Biology, 7(1):no. 23.\nLuciani, F., Sisson, S. A., Jiang, H., Francis, A., and Tanaka, M. M. (2009). The high\nfitness cost of drug resistance in mycobacterium tuberculosis. Proc. Natl. Acad. Sci. USA,\n106:14711\u201314715.\nMarjoram, P., Molitor, J., Plagnol, V., and Tavar\u00e9, S. (2003). Markov chain Monte Carlo\nwithout likelihoods. Proc. Natl. Acad. Sci. USA, 100:15324 \u2013 15328.\nMarjoram, P. and Tavar\u00e9, S. (2006). Modern computational approaches for analysing molectular genetic variation data. Nature Reviews: Genetics, 7:759\u2013770.\n\n\fBIBLIOGRAPHY\n\n35\n\nMcKinley, T., Cook, A. R., and Deardon, R. (2009). Inference in epidemic models without\nlikelihoods. The International Journal of Biostatistics, 5: article 24.\nNeal, R. M. (2003). Slice sampling. Annals of Statistics, 31:705\u2013767.\nNevat, I., Peters, G. W., and Yuan, J. (2008). Coherent detection for cooperative networks\nwith arbitrary relay functions using likelihood-free inference. Technical report, University\nof New South Wales.\nPeters, G. W., Fan, Y., and Sisson, S. A. (2008). On sequential Monte Carlo, partial rejection\ncontrol and approximate Bayesian computation. Technical report, University of New South\nWales.\nPeters, G. W. and Sisson, S. A. (2006). Bayesian inference, Monte Carlo sampling and\noperational risk. Journal of Operational Risk, 1(3).\nPeters, G. W., Sisson, S. A., and Fan, Y. (2009). Likelihood-free Bayesian models for \u03b1-stable\nmodels. Technical report, University of New South Wales.\nPettitt, A. N. (2006). Isaac Newton Institute Workshop on MCMC, Cambridge UK, 30\nOctober - 2 November, 2006.\nPritchard, J. K., Seielstad, M. T., Perez-Lezaun, A., and Feldman, M. W. (1999). Population\ngrowth of human Y chromosomes: A study of Y chromosome microsatellites. Molecular\nBiology and Evolution, 16:1791\u20131798.\nRatmann, O., Andrieu, C., Hinkley, T., Wiuf, C., and Richardson, S. (2009). Model criticism\nbased on likelihood-free inference, with an application to protein network evolution. Proc.\nNatl. Acad. Sci. USA, 106:10576\u201310581.\nRatmann, O., Jorgensen, O., Hinkley, T., Stumpf, M., Richardson, S., and Wiuf, C. (2007).\nUsing likelihood-free inference to compare evolutionary dynamics of the protien networks\nof h. pylori and p. falciparum. PLoS Comp. Biol., 3:e230.\nReeves, R. W. and Pettitt, A. N. (2005). A theoretical framework for approximate Bayesian\ncomputation. In Francis, A. R., Matawie, K. M., Oshlack, A., and Smyth, G. K., editors,\nProceedings of the 20th International Workshop for Statistical Modelling, Sydney Australia,\nJuly 10-15, 2005, pages 393\u2013396.\n\n\f36\n\nBIBLIOGRAPHY\n\nSisson, S. A., Fan, Y., and Tanaka, M. M. (2007). Sequential Monte Carlo without likelihoods. Proc. Natl. Acad. Sci., 104:1760\u20131765. Errata (2009), 106:16889.\nSisson, S. A., Peters, G. W., Fan, Y., and Briers, M. (2008). Likelihood-free samplers.\nTechnical report, University of New South Wales.\nTanaka, M. M., Francis, A. R., Luciani, F., and Sisson, S. A. (2006). Using Approximate\nBayesian Computation to estimate tuberculosis transmission parameters from genotype\ndata. Genetics, 173:1511\u20131520.\nTavar\u00e9, S., Balding, D. J., Griffiths, R. C., and Donnelly, P. (1997). Inferring coalescence\ntimes from DNA sequence data. Genetics, 145(505-518).\nTierney, L. and Mira, A. (1999). Some adaptive Monte Carlo methods for Bayesian inference.\nStatistics in medicine, 18:2507 \u2013 15.\nToni, T., Welch, D., Strelkowa, N., Ipsen, A., and Stumpf, M. P. H. (2009). Approximate\nBayesian computation scheme for parameter inference and model selection in dynamical\nsystems. J. R. Soc. Interface, 6:187\u2013202.\nWegmann, D., Leuenberger, C., and Excoffier, L. (2009). Efficient approximate Bayesian\ncomputation coupled with Markov chain Monte Carlo without likelihood.\n\nGenetics,\n\n182:1207\u20131218.\nWilkinson, R. D. (2008). Approximate Bayesian computation (ABC) gives exact results\nunder the assumption of model error. Technical report, Dept. of Probability and Statistics,\nUniversity of Sheffield.\nWilkinson, R. D. and Tavar\u00e9, S. (2009). Estimating primate divergence times by using\nconditioned birth-and-death processes. Theoretical Population Biology, 75:278\u2013285.\n\n\f"}