{"id": "http://arxiv.org/abs/1111.4626v2", "guidislink": true, "updated": "2013-03-01T04:43:02Z", "updated_parsed": [2013, 3, 1, 4, 43, 2, 4, 60, 0], "published": "2011-11-20T12:34:19Z", "published_parsed": [2011, 11, 20, 12, 34, 19, 6, 324, 0], "title": "On an Achievable Rate of Large Rayleigh Block-Fading MIMO Channels with\n  No CSI", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.3329%2C1111.2159%2C1111.2526%2C1111.1629%2C1111.0277%2C1111.3793%2C1111.4626%2C1111.6084%2C1111.5428%2C1111.1598%2C1111.4357%2C1111.1452%2C1111.5588%2C1111.5775%2C1111.5341%2C1111.0237%2C1111.1231%2C1111.0968%2C1111.7162%2C1111.6463%2C1111.6255%2C1111.4745%2C1111.2091%2C1111.0047%2C1111.4582%2C1111.5388%2C1111.3508%2C1111.4785%2C1111.6129%2C1111.3448%2C1111.5735%2C1111.5825%2C1111.2211%2C1111.3472%2C1111.5040%2C1111.6436%2C1111.2486%2C1111.1686%2C1111.0179%2C1111.3957%2C1111.0474%2C1111.6492%2C1111.2169%2C1111.1556%2C1111.2953%2C1111.0814%2C1111.6126%2C1111.5022%2C1111.4665%2C1111.1883%2C1111.4927%2C1111.5945%2C1111.4001%2C1111.5076%2C1111.6259%2C1111.0735%2C1111.5645%2C1111.2581%2C1111.3337%2C1111.7146%2C1111.4758%2C1111.6561%2C1111.6881%2C1111.2447%2C1111.3897%2C1111.1306%2C1111.6652%2C1111.3061%2C1111.7214%2C1111.1820%2C1111.0541%2C1111.4478%2C1111.3557%2C1111.3278%2C1111.0574%2C1111.2657%2C1111.3736%2C1111.0009%2C1111.6038%2C1111.3703%2C1111.3997%2C1111.1756%2C1111.2502%2C1111.4610%2C1111.0744%2C1111.4876%2C1111.3589%2C1111.6318%2C1111.4976%2C1111.5054%2C1111.0293%2C1111.3574%2C1111.4769%2C1111.5105%2C1111.4019%2C1111.3087%2C1111.1645%2C1111.4471%2C1111.3398%2C1111.1352%2C1111.2453&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On an Achievable Rate of Large Rayleigh Block-Fading MIMO Channels with\n  No CSI"}, "summary": "Training-based transmission over Rayleigh block-fading multiple-input\nmultiple-output (MIMO) channels is investigated. As a training method a\ncombination of a pilot-assisted scheme and a biased signaling scheme is\nconsidered. The achievable rates of successive decoding (SD) receivers based on\nthe linear minimum mean-squared error (LMMSE) channel estimation are analyzed\nin the large-system limit, by using the replica method under the assumption of\nreplica symmetry. It is shown that negligible pilot information is best in\nterms of the achievable rates of the SD receivers in the large-system limit.\nThe obtained analytical formulas of the achievable rates can improve the\nexisting lower bound on the capacity of the MIMO channel with no channel state\ninformation (CSI), derived by Hassibi and Hochwald, for all signal-to-noise\nratios (SNRs). The comparison between the obtained bound and a high SNR\napproximation of the channel capacity, derived by Zheng and Tse, implies that\nthe high SNR approximation is unreliable unless quite high SNR is considered.\nEnergy efficiency in the low SNR regime is also investigated in terms of the\npower per information bit required for reliable communication. The required\nminimum power is shown to be achieved at a positive rate for the SD receiver\nwith no CSI, whereas it is achieved in the zero-rate limit for the case of\nperfect CSI available at the receiver. Moreover, numerical simulations imply\nthat the presented large-system analysis can provide a good approximation for\nnot so large systems. The results in this paper imply that SD schemes can\nprovide a significant performance gain in the low-to-moderate SNR regimes,\ncompared to conventional receivers based on one-shot channel estimation.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.3329%2C1111.2159%2C1111.2526%2C1111.1629%2C1111.0277%2C1111.3793%2C1111.4626%2C1111.6084%2C1111.5428%2C1111.1598%2C1111.4357%2C1111.1452%2C1111.5588%2C1111.5775%2C1111.5341%2C1111.0237%2C1111.1231%2C1111.0968%2C1111.7162%2C1111.6463%2C1111.6255%2C1111.4745%2C1111.2091%2C1111.0047%2C1111.4582%2C1111.5388%2C1111.3508%2C1111.4785%2C1111.6129%2C1111.3448%2C1111.5735%2C1111.5825%2C1111.2211%2C1111.3472%2C1111.5040%2C1111.6436%2C1111.2486%2C1111.1686%2C1111.0179%2C1111.3957%2C1111.0474%2C1111.6492%2C1111.2169%2C1111.1556%2C1111.2953%2C1111.0814%2C1111.6126%2C1111.5022%2C1111.4665%2C1111.1883%2C1111.4927%2C1111.5945%2C1111.4001%2C1111.5076%2C1111.6259%2C1111.0735%2C1111.5645%2C1111.2581%2C1111.3337%2C1111.7146%2C1111.4758%2C1111.6561%2C1111.6881%2C1111.2447%2C1111.3897%2C1111.1306%2C1111.6652%2C1111.3061%2C1111.7214%2C1111.1820%2C1111.0541%2C1111.4478%2C1111.3557%2C1111.3278%2C1111.0574%2C1111.2657%2C1111.3736%2C1111.0009%2C1111.6038%2C1111.3703%2C1111.3997%2C1111.1756%2C1111.2502%2C1111.4610%2C1111.0744%2C1111.4876%2C1111.3589%2C1111.6318%2C1111.4976%2C1111.5054%2C1111.0293%2C1111.3574%2C1111.4769%2C1111.5105%2C1111.4019%2C1111.3087%2C1111.1645%2C1111.4471%2C1111.3398%2C1111.1352%2C1111.2453&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Training-based transmission over Rayleigh block-fading multiple-input\nmultiple-output (MIMO) channels is investigated. As a training method a\ncombination of a pilot-assisted scheme and a biased signaling scheme is\nconsidered. The achievable rates of successive decoding (SD) receivers based on\nthe linear minimum mean-squared error (LMMSE) channel estimation are analyzed\nin the large-system limit, by using the replica method under the assumption of\nreplica symmetry. It is shown that negligible pilot information is best in\nterms of the achievable rates of the SD receivers in the large-system limit.\nThe obtained analytical formulas of the achievable rates can improve the\nexisting lower bound on the capacity of the MIMO channel with no channel state\ninformation (CSI), derived by Hassibi and Hochwald, for all signal-to-noise\nratios (SNRs). The comparison between the obtained bound and a high SNR\napproximation of the channel capacity, derived by Zheng and Tse, implies that\nthe high SNR approximation is unreliable unless quite high SNR is considered.\nEnergy efficiency in the low SNR regime is also investigated in terms of the\npower per information bit required for reliable communication. The required\nminimum power is shown to be achieved at a positive rate for the SD receiver\nwith no CSI, whereas it is achieved in the zero-rate limit for the case of\nperfect CSI available at the receiver. Moreover, numerical simulations imply\nthat the presented large-system analysis can provide a good approximation for\nnot so large systems. The results in this paper imply that SD schemes can\nprovide a significant performance gain in the low-to-moderate SNR regimes,\ncompared to conventional receivers based on one-shot channel estimation."}, "authors": ["Keigo Takeuchi", "Ralf R. Mueller", "Mikko Vehkaperae", "Toshiyuki Tanaka"], "author_detail": {"name": "Toshiyuki Tanaka"}, "author": "Toshiyuki Tanaka", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/TIT.2013.2268848", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1111.4626v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1111.4626v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "re-submitted to IEEE Trans. Inf. Theory", "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1111.4626v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1111.4626v2", "journal_reference": null, "doi": "10.1109/TIT.2013.2268848", "fulltext": "IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n1\n\nOn an Achievable Rate of Large Rayleigh\nBlock-Fading MIMO Channels with No CSI\nKeigo Takeuchi, Member, IEEE, Ralf R. M\u00fcller, Senior Member, IEEE,\n\narXiv:1111.4626v2 [cs.IT] 1 Mar 2013\n\nMikko Vehkaper\u00e4, Member, IEEE, and Toshiyuki Tanaka, Member, IEEE,\n\nAbstract\nTraining-based transmission over Rayleigh block-fading multiple-input multiple-output (MIMO) channels is investigated. As a training method a combination of a pilot-assisted scheme and a biased signaling scheme is considered. The\nachievable rates of successive decoding (SD) receivers based on the linear minimum mean-squared error (LMMSE)\nchannel estimation are analyzed in the large-system limit, by using the replica method under the assumption of replica\nsymmetry. It is shown that negligible pilot information is best in terms of the achievable rates of the SD receivers in\nthe large-system limit. The obtained analytical formulas of the achievable rates can improve the existing lower bound\non the capacity of the MIMO channel with no channel state information (CSI), derived by Hassibi and Hochwald,\nfor all signal-to-noise ratios (SNRs). The comparison between the obtained bound and a high SNR approximation\nof the channel capacity, derived by Zheng and Tse, implies that the high SNR approximation is unreliable unless\nquite high SNR is considered. Energy efficiency in the low SNR regime is also investigated in terms of the power\nper information bit required for reliable communication. The required minimum power is shown to be achieved at\na positive rate for the SD receiver with no CSI, whereas it is achieved in the zero-rate limit for the case of perfect\nCSI available at the receiver. Moreover, numerical simulations imply that the presented large-system analysis can\nprovide a good approximation for not so large systems. The results in this paper imply that SD schemes can provide\nManuscript received August, 2011. The work of K. Takeuchi was in part supported by the Grant-in-Aid for Young Scientists (B) (No. 23760329)\nfrom JSPS, Japan. The work of M. Vehkaper\u00e4 was supported by the Norwegian Research Council under grant 171133/V30. The work of T. Tanaka\nwas in part supported by the Grant-in-Aid for Scientific Research on Priority Areas (No. 18079010) from MEXT, Japan. The material in this\npaper was presented in part at 2009 IEEE International Symposium on Information Theory, Seoul, Korea, July 2009, and at 2010 International\nSymposium on Information Theory and its Applications & 2010 International Symposium on Spread Spectrum Techniques and Applications,\nTaichung, Taiwan, Oct. 2010.\nK. Takeuchi is with the Department of Communication Engineering and Informatics, the University of Electro-Communications, Tokyo\n182-8585, Japan (e-mail: ktakeuchi@uec.ac.jp).\nR. R. M\u00fcller is with the Department of Electronics and Telecommunications, the Norwegian University of Science and Technology (NTNU),\nNO\u20137491 Trondheim, Norway (e-mail: ralf@iet.ntnu.no).\nM. Vehkaper\u00e4 is with the School of Electrical Engineering, Royal Institute of Technology (KTH), SE\u2013100 44 Stockholm, Sweden (e-mail:\nmikkov@kth.se).\nT. Tanaka is with the Department of Systems Science, Graduate School of Informatics, Kyoto University, Kyoto, 606-8501, Japan (e-mail:\ntt@i.kyoto-u.ac.jp).\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n2\n\na significant performance gain in the low-to-moderate SNR regimes, compared to conventional receivers based on\none-shot channel estimation.\nIndex Terms\nMultiple-input multiple-output (MIMO) systems, Rayleigh block-fading channels, noncoherent capacity, trainingbased transmission, linear minimum mean-squared error (LMMSE) channel estimation, successive decoding (SD),\nbiased signaling, large-system analysis, replica method.\n\nI. I NTRODUCTION\nA. Motivation\nMultiple-input multiple-output (MIMO) transmission is a promising scheme for increasing the spectral efficiency\nof wireless communication systems, and has been applied to several modern standards, such as wireless LAN (IEEE\n802.11n) and Mobile WiMAX (IEEE 802.16e). However, the ultimate achievable rate of MIMO systems is not fully\nunderstood. Thus, it is an important issue in information theory to elucidate the channel capacity of MIMO systems.\nThe capacity of MIMO channels with perfect channel state information (CSI) at the receiver was analyzed in\nthe early pioneering works [1], [2]. Telatar [2] proved that independent and identically distributed (i.i.d.) Gaussian\nsignaling is optimal for i.i.d. Rayleigh fading MIMO channels with perfect CSI at the receiver. See e.g. [3] for the\ncase of more sophisticated fading models. The assumption of perfect CSI available at the receiver is a reasonable\nassumption if the coherence time is sufficiently long compared to the number of transmit antennas. However, this\nassumption becomes unrealistic for mobile communications with short coherence time or a large number of transmit\nantennas. Thus, it is worth considering the assumption of CSI available neither to the transmitter nor to the receiver,\nwhile the receiver is assumed to know the statistical model of the channel perfectly. In this paper, this assumption\nis simply referred to as the no CSI assumption.\nMarzetta and Hochwald [4] considered i.i.d. Rayleigh block-fading MIMO channels with no CSI, and characterized a class of capacity-achieving signaling schemes. In block-fading channels, the channel is fixed during one\nfading block and independently changes at the beginning of the next fading block. The assumption of block-fading\nsimplifies analyzing the capacity, although it might be an idealized assumption.1 See [5], [6] for the capacity of\ntime-varying MIMO channels with no CSI. In this paper, we consider block-fading MIMO channels with no CSI.\nThe capacity-achieving inputs are not i.i.d. over space or time for block-fading MIMO channels with no CSI [4].\nThese dependencies over space and time make it difficult to calculate the capacity. In order to circumvent this\ndifficulty, three kinds of strategies have been considered in the literature. A first strategy is to obtain a closed form\nfor a lower bound on the capacity by considering unitary space-time modulation [7], although the insight provided\nby the closed form is not very clear. It is possible to calculate a lower bound of the capacity numerically for all\nsignal-to-noise ratios (SNRs) [8], [9], while this task is not necessarily easy in terms of computational complexity.\n1\n\nThe assumption of block-fading is valid for time-division multiple-access (TDMA) schemes.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n3\n\nA second strategy is to consider the high or low SNR limits. This strategy can provide an analytical formula of\nthe capacity in return for giving up the capacity result in the moderate SNR regime. High SNR approximations of\nthe capacity were derived in [10], [11]. The approximations tolerate an error of o(1) in the high SNR limit. The\nanalytical formula by Zheng and Tse [10] provides a useful geometric insight, i.e., the capacity of MIMO channels\nwith no CSI has an interpretation as sphere packing in the Grassmann manifold, while the capacity for the case of\nperfect CSI available at the receiver has an interpretation in terms of sphere packing in the Euclidean space.\nThe power per information bit Eb required for reliable communication is a key performance measure in the low\nSNR regime. Verd\u00fa [12] proved that the SNR per information bit Eb /N0 , with N0 denoting noise power, required\nfor MIMO channels with no CSI achieves the minimum N Eb /N0 = ln 2 \u2248 \u22121.59 dB in the low SNR limit, with\nN denoting the number of receive antennas. This result provides a fundamental limit in terms of energy efficiency.\nSee [13], [14] for more detailed analysis.\nThe last strategy is to analyze the achievable rate of a training-based system, which obviously provides a lower\nbound on the capacity. Since accurate channel estimates are assumed to be obtained by training, i.i.d. signaling\nover space and time is commonly used for training-based systems. This signaling contains practical modulation\nschemes, such as quadrature phase shift keying (QPSK) or quadrature amplitude modulation (QAM). Results based\non this strategy are less explored than those based on the other two strategies. An advantage of the training-based\nstrategy is that it is possible to obtain an analytical bound that can be easily evaluated for all SNRs. Hassibi\nand Hochwald [15] derived an analytical lower bound on the achievable rate of a pilot-assisted system, called\nthe Hassibi-Hochwald (HH) bound in this paper. Another advantage is that it can provide a useful guideline for\ndesigning practical training-based MIMO systems. In fact, it was shown in [15] that the optimal number of pilot\nsymbols is equal to the number of transmit antennas in terms of their lower bound. A weakness is that lower bounds\nderived by the last strategy might be looser than those derived by the first strategy. In this paper, we focus on the\nlast strategy and improve the existing lower bound of the capacity based on training.\nHassibi and Hochwald [15] used a method for lower-bounding the achievable rate of a pilot-assisted system,\ndeveloped by M\u00e9dard in [16]. As shown in [17], using this method requires the assumption of one-shot channel\nestimation, under which the decoder regards the channel estimates provided by the channel estimator as the true\nones. In other words, the decoded data symbols are not re-utilized for refining the channel estimates. Thus, a lower\nbound based on training-based systems should improve by refining the channel estimates with the decoded data\nsymbols.\nWe follow a successive decoding (SD) strategy considered in [17]\u2013[19], in which the data symbols decoded in\nthe preceding stages are utilized for refining the channel estimates. In the initial channel estimation, the channel\nestimator utilizes pilot signals transmitted by using a fraction of resources. As a training-based scheme suitable for\nthe SD strategy, we consider a combination of the conventional pilot-assisted scheme and a bias-based scheme [20].\nIn the bias-based scheme, a probabilistic bias of transmitted symbols is used for the initial channel estimation,\nwhile time-division multiplexed pilot symbols are utilized in the pilot-assisted scheme. The bias-based scheme was\nnumerically shown to outperform pilot-assisted schemes for practical iterative receivers [21]\u2013[23]. The goal of this\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n4\n\npaper is to derive an analytical bound based on the SD strategy with a combination of the pilot-assisted scheme\nand the bias-based scheme.\nB. Contributions & Methodology\nThe main contribution of this paper is to derive lower bounds on the achievable rates of SD receivers in the\nlarge-system limit, where the number of transmit antennas, the number of receive antennas, and coherence time tend\nto infinity while their ratios are kept constant. The lower bounds can be evaluated easily, whereas Padmanabhan et\nal. [19] calculated bounds on the corresponding achievable rate by numerical simulations. Numerical simulations\nin this paper show that the large-system results can provide a good approximation for not so large systems. The\nderived lower bounds are used to optimize the overhead for training. It is shown that negligibly small overhead\nfor training is best in terms of the lower bounds. The optimized bound outperforms the HH bound [15] for all\nSNRs. Furthermore, the comparison between our bound and the high-SNR approximation of the capacity [10], [11]\nimplies that the high-SNR approximation is valid only for quite high SNR.\nThe derivation of the proposed bounds consists of two steps: First, the optimal channel estimator is replaced\nby the linear minimum mean-squared error (LMMSE) channel estimator. Since the optimal channel estimator is\nnonlinear in general, the distribution of the channel estimates becomes non-Gaussian. This non-Gaussianity makes\nit difficult to calculate the achievable rates of the SD receivers with the optimal channel estimator. In order to\ncircumvent this difficulty, we consider a lower bound based on LMMSE channel estimation.\nNext, we take the large-system limit to obtain analytical results. The large-system limit has been extensively\nconsidered in the analysis of code-division multiple-access (CDMA) and MIMO systems with perfect CSI at the\nreceiver, by using random matrix theory [24]\u2013[27] and the replica method [28]\u2013[34]. The advantage of taking the\nlarge-system limit is that several performance measures, such as mutual information and signal-interference-plusnoise ratio (SINR), are expected to be self-averaging, i.e., they converge in probability to deterministic values in\nthe large-system limit. This self-averaging property allows us to obtain analytical results. The large-system limit in\nprevious works for the perfect CSI case may be regarded as the limit in which the numbers of transmit and receive\nantennas tend to infinity at the same rate after taking the long coherence-time limit, since the receiver can obtain\naccurate channel estimates in these limits. In order to consider the no CSI case, on the other hand, the coherence\ntime and the numbers of transmit and receive antennas tend to infinity at the same rate in this paper. Note that\nthe coherence time must also tend to infinity to obtain meaningful results when the number of antennas tends to\ninfinity, since there is no point in using transmit antennas more than the coherence time [4].\nWe use the replica method to evaluate the achievable rates in the large-system limit. The replica method was\noriginally developed in statistical physics [35]. See [36]\u2013[38] for the details of the replica method. Recently, it has\nbeen recognized that the replica method is useful for analyzing nonlinear receivers [28]\u2013[34]. A weakness of the\nreplica method is that it is based on several non-rigorous assumptions in the present time. See [39], [40] for a\nrecent remarkable progress with respect to the replica method.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n5\n\nC. Notation\nFor a complex number z \u2208 C, throughout this paper, j, R[z], I[z], and z \u2217 denote the imaginary unit, the real and\n\nimaginary parts of z, and the complex conjugate of z, respectively. For a complex matrix A, AT , AH , Tr(A), and\n\ndet A represent the transpose, the conjugate transpose, the trace, and the determinant of A, respectively. The vector\n1n denotes the n-dimensional vector whose elements are all one. The n \u00d7 n identity matrix is denoted by I n . The\noperator \u2297 denotes the Kronecker product of two matrices. The matrix diag(a1 , . . . , an ) represents the diagonal\n\nmatrix with ai as the ith diagonal element. M+\nn denotes the set of all positive definite n \u00d7 n Hermitian matrices.\nlog x, ln x, \u03b4(*), and \u03b4a,b denote log2 x, loge x, the Dirac delta function, and the Kronecker delta, respectively. For\nrandom variables X, Y , and Z, I(X; Y |Z) denotes the conditional mutual information between X and Y given Z\n\nwith the logarithm to base 2. For a complex random vector x and a random variable Y , cov[x|Y ] represents the\ncovariance matrix of x given Y . CN (m, \u03a3) denotes a proper complex Gaussian distribution with mean m and a\ncovariance matrix \u03a3 [41]. For covariance matrices \u03a3 and \u03a3\u0303, Da (\u03a3k\u03a3\u0303) represents the Kullback-Leibler divergence\nwith the logarithm to base a between CN (0, \u03a3) and CN (0, \u03a3\u0303).\nAs notational convenience for subsets of the natural numbers N, we use [a, b) = {i \u2208 N : a \u2264 i < b}\nfor integers a and b (> a). The other sets [a, b], (a, b), and so on are defined in the same manner. The set\nJ \\{j} = {j \u2032 \u2208 J : j \u2032 6= j} denotes the set obtained by eliminating the element j from a set of indices J . When\nJ equals the set of all indices, J \\{j} is simply written as \\j.\nFor a set of indices J = {j1 , . . . , jn } and scalars {vj : j \u2208 J }, v J denotes the column vector v =\n\n(vj1 , . . . , vjn )T , while ~v J does the row vector ~v J = (vj1 , . . . , vjn ). For example, v [a,b) = (va , . . . , vb\u22121 )T and\nv J \\{j2 } = (vj1 , vj3 , . . . , vjn )T . Note that v J \\{j} is written as v \\j when J is the set of all indices, since J \\{j}\nis abbreviated as \\j. For column vectors {aj : j \u2208 J }, similarly, AJ denotes the matrix AJ = (aj1 , . . . , ajn ).\nFor example, A[a,b) = (aa , . . . , ab\u22121 ) and AJ \\{j2 } = (aj1 , aj3 , . . . , ajn ). We use symbols with tildes and hats\nto represent random variables for postulated (or virtual) channels and estimates of random variables, respectively.\nUnderlined symbols are used to represent random variables for decoupled channels.\nThe remainder of this paper is organized as follows: A Rayleigh block-fading MIMO channel is introduced in\nSection II. The achievable rates of SD receivers based on LMMSE channel estimation are formulated in Section III.\nThe main results of this paper are presented in Section IV. The obtained analytical bounds are compared to existing\nresults in Section V. We conclude this paper in Section VI. The derivation of the main results is summarized in\nappendices.\nII. C HANNEL M ODEL\nA. MIMO Channel\nA narrowband MIMO system with M transmit antennas and N receive antennas is considered. We assume\nblock-fading with coherence time Tc , i.e., the channel matrix H \u2208 CN \u00d7M is kept constant during one fading block\nconsisting of Tc symbol periods, and at the beginning of the next fading block the channel matrix is independently\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n6\n\nsampled from a distribution. The received vector y t \u2208 CN in the tth symbol period within a fading block is given\nby\n1\ny t = \u221a Hxt + nt ,\nM\n\nt = 1, . . . , Tc ,\n\n(1)\n\nwhere xt = (x1,t , . . . , xM,t )T and nt \u223c CN (0, N0 I N ) denote the transmitted vector in the tth symbol period\nand an additive white Gaussian noise (AWGN) vector with a covariance matrix N0 I N , respectively. The MIMO\nchannel (1) can be represented in matrix form as\n1\nY = \u221a HX + N ,\nM\n\n(2)\n\nwith Y = (y 1 , . . . , y Tc ), X = (x1 , . . . , xTc ), and N = (n1 , . . . , nTc ).\nFor the simplicity of analysis, we assume i.i.d. Rayleigh fading MIMO channels, i.e., the channel matrix H has\nmutually independent entries, and each entry hn,m = (H)n,m is drawn from the circularly symmetric complex\nGaussian (CSCG) distribution CN (0, 1) with unit variance. Note that the assumption of i.i.d. Rayleigh fading might\nbe an idealized assumption since there can be correlations between the elements of the channel matrix in practice.\nWe impose a power constraint\nM Tc\n\u0002\n\u0003\n1 XX\nE |xm,t |2 \u2264 P,\nM Tc m=1 t=1\n\n(3)\n\nfor P > 0. Marzetta and Hochwald [4] proved that the capacity does not decrease even if the power constraint is\nstrengthened to a power constraint on each transmitted symbol,\n\u0002\n\u0003\nE |xm,t |2 \u2264 P.\n\n(4)\n\nThe former power constraint (3) allows us to use power allocation over space and time, whereas the latter power\nconstraint (4) does not. In this paper, we only consider the latter power constraint (4), which simplifies the analysis.\nB. Training-Based Transmission\nWe assume that neither the transmitter nor the receiver has CSI. More precisely, only the statistical properties\nof the MIMO channel (1) are assumed to be known to the receiver. The previous works [10], [15] showed that\npilot-assisted channel estimation can achieve the capacity in the leading order of SNR in the high SNR regime, i.e.,\nthe full spatial multiplexing gain, while the obtained lower bounds are loose in the low-to-moderate SNR regime.\nChannel estimation based on pilot information is also considered in this paper. The main difference between the\nprevious works and this paper appears in the receiver structure. We consider joint channel and data estimation based\non SD, whereas in the previous works data symbols decoded successfully were not utilized for refining channel\nestimates.\nOne fading block is decomposed into the training phase TTtr = {1, . . . , Ttr } and the communication phase\nCTtr +1 = {Ttr + 1, . . . , Tc }, which consist of the first Ttr symbol periods and of the remaining (Tc \u2212 Ttr ) symbol\nperiods, respectively. The transmitter sends pilot symbol vectors in the training phase, and transmits data symbol\nvectors in the communication phase. Therefore, the transmitted vector xt is assumed to be known to the receiver\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n7\n\nfor t \u2208 TTtr . For simplicity, we assume that the pilot symbol matrix X TTtr = (x1 , . . . , xTr ) \u2208 CM\u00d7Ttr has zeromean i.i.d. entries with i.i.d. real and imaginary parts. Furthermore, we assume that each pilot symbol satisfies\nE[|xm,t |2 ] = P for t \u2208 TTtr , since the accuracy of channel estimation should improve as the power of pilot\nsymbols increases. The transmission of i.i.d. data symbols can achieve the capacity of the MIMO channel (1) with\nperfect CSI at the receiver. If accurate channel estimates are obtained by joint channel and data estimation, thus,\ni.i.d. signaling should be a reasonable option for training-based transmissions. We assume that the data symbols\n{xm,t : t \u2208 CTtr +1 } are i.i.d. random variables with i.i.d. real and imaginary parts for all m and t \u2208 CTtr +1 . Note\nthat zero-mean is not assumed for the data symbols. Under this assumption, the achievable rate is monotonically\nincreasing with the power of each data symbol. We hereinafter let E[|xm,t |2 ] = P .\nIn this paper, we consider a biased signaling scheme, in which the mean E[xm,t ] = \u03b8m,t of the data symbol for\nPTc\nt \u2208 CTtr +1 is biased while the long-term average (Tc \u2212 Ttr )\u22121 t=T\n\u03b8m,t tends to zero as Tc \u2192 \u221e. In order to\ntr +1\n\napply the replica method, we assume that {R[\u03b8m,t ], I[\u03b8m,t ] : for all m, t} are independently drawn from a zero-\n\nmean hyperprior probability density function (pdf)2 p(\u03b8) with variance \u03c3\u03b82 /2. The transmitter informs the receiver\nin advance about the bias matrix \u0398 = (O, \u03b8Ttr +1 , . . . , \u03b8Tc ) \u2208 CM\u00d7Tc , with \u03b8 t = (\u03b81,t , . . . , \u03b8M,t )T . In other words,\n\u0398 is assumed to be known to the receiver. The biased signaling can reduce the overhead for training [20] compared\nto the conventional pilot-assisted schemes. We present two examples of biased signaling: biased QPSK and biased\nGaussian signaling. See [21]\u2013[23] for implementations of biased QPSK.\np\nExample 1 (Biased QPSK). For R[xm,t ], I[xm,t ] \u2208 {\u00b1 P/2}, the prior pmf of xm,t for biased QPSK is given\n\nby\n\np(xm,t |\u03b8m,t ) =\n\n1 + R[\u03b8m,t ]/R[xm,t ] 1 + I[\u03b8m,t ]/I[xm,t ]\n.\n2\n2\n\n(5)\n\np\np\nThe non-negativity of probability restricts the support of the hyperprior pdf p(\u03b8) to R[\u03b8m,t ] \u2208 [\u2212 P/2, P/2]\np\np\nand I[\u03b8m,t ] \u2208 [\u2212 P/2, P/2]. It is straightforward to check that E[xm,t |\u03b8m,t ] = \u03b8m,t and E[|xm,t |2 |\u03b8m,t ] = P .\nExample 2 (Biased Gaussian Signaling). The prior pdf of xm,t \u2208 C for biased Gaussian signaling is given by\n2\n\n|x\n\u2212\u03b8m,t |\n\u2212 Pm,t\n1\n\u2212|\u03b8m,t |2\np(xm,t |\u03b8m,t ) =\ne\n.\n(6)\n\u03c0(P \u2212 |\u03b8m,t |2 )\n\u221a\nNote that the support of the hyperprior pdf p(\u03b8) is restricted to |\u03b8m,t | < P , due to the positivity of variance.\n\nThe main results presented in this paper hold for a general prior of xm,t with finite moments. The performance\nfor the biased Gaussian signaling corresponds to a performance bound for multilevel modulation with trellis\nshaping [42], [43].\n2\n\nWhen \u03b8m,t is discrete, p(\u03b8) denotes a probability mass function (pmf).\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n8\n\nstage number\nTtr+1\n\nt\n\nTc\n\nsubstage number\n\n1\n\nm\nM\n\nFig. 1.\n\nSuccessive decoding.\n\nIII. R ECEIVERS\nA. Successive Decoding\nWe consider an SD receiver [18], [19] (See Fig. 1). The data symbol vectors {xt } are decoded in the order\n\nt = Ttr + 1, . . . , Tc . In stage t, the matrix X (Ttr ,t) = (xTtr +1 , . . . , xt\u22121 ) \u2208 CM\u00d7(t\u2212Ttr \u22121) contains the data symbol\nvectors decoded in the preceding stages. Stage t consists of M substages, in which the elements {xm,t } are decoded\n\nin the order m = 1, . . . , M . In substage m within stage t, the vector x[1,m),t = (x1,t , . . . , xm\u22121,t )T \u2208 Cm\u22121 consists\nof the data symbols decoded in the preceding substages. The channel estimator utilizes the data symbols X (Ttr ,t)\n\ndecoded in the preceding stages, along with the received matrix Y \\t \u2208 CN \u00d7(Tc \u22121) and the pilot information\n{X TTtr , \u0398(t,Tc ] }, in which the matrices Y \\t and \u0398(t,Tc ] \u2208 CM\u00d7(Tc \u2212t) are obtained by eliminating the tth column\n\nvector from the received matrix Y and the first t column vectors from the bias matrix \u0398, respectively. We write the\ninformation used for channel estimation in stage t as It = {X\u0304 \\t , Y \\t }, with X\u0304 \\t = (X TTtr , X (Ttr ,t) , \u0398(t,Tc ] ) \u2208\n\nCM\u00d7(Tc \u22121) . In substage m within stage t, the detector with successive interference cancellation (SIC) uses the data\nsymbols x[1,m),t decoded in the preceding substages and the bias vector \u03b8 [m,M],t = (\u03b8m,t , . . . , \u03b8M,t )T to subtract\ninter-stream interference from the received vector y t , and then perform multiuser detection (MUD).\nLet us define the constrained capacity of the MIMO system based on the pilot information {X TTtr , \u0398} as the\nconditional mutual information per symbol period between all data symbol vectors {xt : t \u2208 CTtr +1 } and the\nreceived matrix Y conditioned on the pilot symbol matrix X TTtr and the bias matrix \u0398 [44]\nC=\n\n1\nI({xt : t \u2208 CTtr +1 }; Y |X TTtr , \u0398).\nTc\n\n(7)\n\nIt is straightforward to confirm that the optimal SD receiver can achieve the constrained capacity (7). Applying the\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n9\n\nchain rule for mutual information to (7) repeatedly [44], we obtain\nC=\n\n=\n\n=\n\n1\nTc\n1\nTc\n1\nTc\n\nTc\nX\n\nt=Ttr +1\nTc\nX\n\nt=Ttr +1\nTc\nX\n\nI(xt ; Y |X TTtr , \u0398, X (Ttr ,t) )\nI(xt ; y t |It , \u0398(Ttr ,t) , \u03b8t )\nM\nX\n\nt=Ttr +1 m=1\n\nI(xm,t ; y t |It , x[1,m),t , \u03b8[m,M],t ),\n\n(8)\n\nwith \u0398(Ttr ,t) = (\u03b8 Ttr +1 , . . . , \u03b8t\u22121 ). In the derivation of the second equality, we have used the fact that xt and\nY \\t are independent of each other, due to the i.i.d. assumption of the data symbols. In the last expression, we\nhave omitted conditioning with respect to \u0398(Ttr ,t) and \u03b8[1,m),t = (\u03b81,t , . . . , \u03b8m\u22121,t )T , which are not utilized by the\nreceiver in substage m within stage t since they are the parameters of the known data symbols X (Ttr ,t) and x[1,m),t .\nFor notational simplicity, this omission is applied throughout this paper. Note that \u0398(Ttr ,t) and \u03b8[1,m),t affect the\nachievable rate (8). Expression (8) implies that the SD scheme results in no loss of information if the detector with\nSIC can achieve the mutual information I(xm,t ; y t |It , x[1,m),t , \u03b8 [m,M],t ) in substage m within stage t.\nIt is difficult to evaluate the mutual information I(xm,t ; y t |It , x[1,m),t , \u03b8 [m,M],t ) exactly. Instead, we derive a\nlower bound based on LMMSE channel estimation. We first introduce the optimal channel estimator and then define\nthe LMMSE channel estimator.\nB. Channel Estimators\n1) Optimal Channel Estimator: We focus on stage t in this section. The optimal channel estimator uses the\ninformation It to estimate the channel matrix H, and sends the joint posterior pdf\np(H|It ) = R\n\np(Y \\t |H, X\u0304 \\t )p(H)\n,\np(Y \\t |H, X\u0304 \\t )p(H)dH\n\n(9)\n\nto the detector with SIC. In (9), the pdf p(Y \\t |H, X\u0304 \\t ) is decomposed into the product of pdfs p(Y \\t |H, X\u0304 \\t ) =\nQt\u22121\nQTc\nt\u2032 =1 p(y t\u2032 |H, xt\u2032 )\nt\u2032 =t+1 p(y t\u2032 |H, \u03b8 t\u2032 ), given by\nZ\n(10)\np(y t\u2032 |H, \u03b8t\u2032 ) = p(y t\u2032 |H, xt\u2032 )p(xt\u2032 |\u03b8t\u2032 )dxt\u2032 ,\nwhere p(y t\u2032 |H, xt\u2032 ) represents the MIMO channel (1). Note that the joint posterior pdf (9) is decomposed into the\nQ\n1\u00d7M\n~\n~\nproduct N\ndenoting the nth row vector of H, due\nn=1 p(hn |It ) of the marginal posterior pdfs, with hn \u2208 C\nto the assumption of i.i.d. fading.\n\nThe optimal channel estimator is nonlinear in general, which makes it difficult to analyze detectors with SIC, while\nit is possible to evaluate the performance of the optimal channel estimator. In order to circumvent this difficulty,\nwe reduce the optimal channel estimator to an LMMSE channel estimator by considering a virtual MIMO channel.\n2) LMMSE Channel Estimator: We use M\u00e9dard's method [16] to replace the MIMO channels (1) for t\u2032 =\nt + 1, . . . , Tc by virtual MIMO channels\n1\n\u1ef9 t\u2032 = \u221a H\u03b8 t\u2032 + wt\u2032 + nt\u2032 ,\nM\nOctober 25, 2018\n\n(11)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n10\n\nwhere wt\u2032 \u2208 CN denotes a CSCG random vector with the covariance matrix (P \u2212\u03c3t2\u2032 )I N , with \u03c3t2\u2032 = M \u22121\n\nPM\n\nm=1\n\n|\u03b8m,t\u2032 |2 .\n\nThe virtual MIMO channel (11) is obtained by extracting the term M \u22121/2 H(xt\u2032 \u2212 \u03b8 t\u2032 ) from the first term of the\nright-hand side (RHS) in the original MIMO channel (1) and then replacing it by the AWGN term wt\u2032 with\n\nthe covariance matrix cov[M \u22121/2 H(xt\u2032 \u2212 \u03b8t\u2032 )|\u03b8 t\u2032 ]. This replacement implies that information about the channel\nmatrix included in H(xt\u2032 \u2212 \u03b8t\u2032 ) is discarded. Thus, channel estimation based on the virtual MIMO channel (11)\nshould be inferior to that based on the original MIMO channel (1). In other words, the mutual information\nI(xm,t ; y t |It , x[1,m),t , \u03b8 [m,M],t ) should be bounded from below by\nI(xm,t ; y t |It , x[1,m),t , \u03b8[m,M],t ) \u2265 I(xm,t ; y t |\u0128t , x[1,m),t , \u03b8[m,M],t ),\n\n(12)\n\nwhich denotes the constrained capacity of the MIMO channel (1) in symbol period t with side information \u0128t =\n{X\u0304 \\t , \u1ef8 \\t }, x[1,m),t , and \u03b8 [m,M],t , in which \u1ef8 \\t = (y 1 , . . . , y t\u22121 , \u1ef9 t+1 , . . . , \u1ef9 Tc ) contains the received vectors\nof the virtual MIMO channel (11) in the last (Tc \u2212 t) elements while the first (t \u2212 1) elements of \u1ef8 \\t are the same\nas those of the original one Y \\t . From (1) and (11), the matrix \u1ef8 \\t is explicitly given by\n1\n\u1ef8 \\t = \u221a H X\u0304 \\t + (O, W (t,Tc ] ) + N \\t ,\nM\n\n(13)\n\nwith W (t,Tc ] = (w t+1 , . . . , wTc ) \u2208 CN \u00d7(Tc \u2212t) . In (13), the matrix N \\t \u2208 CN \u00d7(Tc \u22121) is obtained by eliminating\nthe tth column vector from the noise matrix N .\nLet us consider channel estimation based on the information \u0128t . The optimal channel estimator for this case\nconstructs the joint posterior pdf p(H|\u0128t ) and feeds it to the detector with SIC. The joint posterior pdf of H given\n\u0128 t is defined by (9) in which the pdf (10) for t\u2032 = t + 1, . . . , Tc is replaced by\nZ\np(\u1ef9 t\u2032 |H, \u03b8t\u2032 ) = p(\u1ef9 t\u2032 |H, \u03b8t\u2032 , wt\u2032 )p(wt\u2032 |\u03b8t\u2032 )dw t\u2032 ,\n\n(14)\n\nwhere p(\u1ef9 t |H, \u03b8t\u2032 , wt\u2032 ) represents the virtual MIMO channel (11). A straightforward calculation indicates that\n\nthe joint posterior pdf p(H|\u0128t ) is a proper complex Gaussian pdf with mean \u0124 t \u2208 CN \u00d7M and covariance\n\n~ 1, . . . , ~\ncov[(h\nhN )T |\u0128t ] = I N \u2297 \u039et , given by\n\" t\u22121\n#\nTc\nX y \u2032 xH\u2032\nX\n\u1ef9 t\u2032 \u03b8H\n1\nt t\nt\u2032\n\u039et ,\n+\n\u0124 t = \u221a\nP \u2212 \u03c3t2\u2032 + N0\nM t\u2032 =1 N0\nt\u2032 =t+1\n!#\u22121\n\"\nTc\nt\u22121\nX\n\u03b8t\u2032 \u03b8H\n1 X xt\u2032 xH\nt\u2032\nt\u2032\n.\n+\n\u039et = I M +\nM \u2032\nN0\nP \u2212 \u03c3t2\u2032 + N0\n\u2032\nt =1\n\n(15)\n\n(16)\n\nt =t+1\n\nThe posterior mean \u0124 t coincides with the LMMSE estimator of H based on the received matrix \u1ef8 \\t and the\nknown information X\u0304 \\t . Furthermore, \u039et is equal to the error covariance matrix of the LMMSE estimator for\neach row vector of H. Thus, we refer to the optimal channel estimator for the virtual MIMO channel (11) as the\nLMMSE channel estimator.\nNote that the linear filter given by (15) provides the LMMSE estimates of H for the original MIMO channel (1).\nOne should not confuse the LMMSE channel estimator for the virtual MIMO channel (11) with that for the original\nMIMO channel (1). The former, which is considered in this paper, is the optimal channel estimator for the virtual\nMIMO channel (11), while the latter is a suboptimal channel estimator for the original MIMO channel (1).\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n11\n\nC. Detectors\n1) Optimal Detector: We focus on substage m within stage t and define the optimal detector with SIC, which\nachieves the lower bound (12). The optimal detector with SIC feeds to the associated decoder the posterior pdf3\nof xm,t based on the knowledge about the received vector y t , the data symbols x[1,m),t decoded in the preceding\nsubstages, the bias \u03b8[m,M],t for the unknown data symbols x[m,M],t = (xm,t , . . . , xM,t )T , and the joint posterior\npdf p(H|\u0128t ) provided by the LMMSE channel estimator, given by\nR\np(y t |xt , \u0128t )p(x[m,M],t |\u03b8[m,M],t )dx(m,M],t\np(xm,t |y t , \u0128t , x[1,m),t , \u03b8[m,M],t ) = R\np(y t |xt , \u0128t )p(x[m,M],t |\u03b8 [m,M],t )dx[m,M],t\n\nwith x(m,M],t = (xm+1,t , . . . , xM,t )T \u2208 CM\u2212m . In (17), the pdf p(y t |xt , \u0128t ) is given by\nZ\np(y t |xt , \u0128t ) = p(y t |H, xt )p(H|\u0128t )dH,\n\n(17)\n\n(18)\n\nwhere p(y t |H, xt ) represents the MIMO channel (1). The use of SIC appears in the pdf (18), which is a proper com-\n\nplex Gaussian pdf with mean M \u22121/2 \u0124 t xt and covariance (N0 +M \u22121 xH\nt \u039et xt )I N . Expression (17) implies that the\noptimal detector with SIC subtracts the known inter-stream interference M \u22121/2 \u0124 t (x[1,m),t T , 0, \u03b8(m,M],t T )T from\nthe received vector y t , with \u03b8 (m,M],t = (\u03b8m+1,t , . . . , \u03b8M,t )T , and then mitigates residual inter-stream interference\nby performing the optimal nonlinear MUD.\nLet x\u0303m,t \u2208 C denote a random variable following the marginal posterior pdf (17). Since the lower bound (12)\nis equal to the mutual information I(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8 [m,M],t ), the achievable rate (8) of the optimal SD\nreceiver is bounded from below by\n1\nC\u2265\nTc\n\nTc\nX\n\nM\nX\n\nt=Ttr +1 m=1\n\nI(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ),\n\n(19)\n\nwhich is given via the equivalent channel between the data symbol xm,t and the associated decoder\np(x\u0303m,t |xm,t , \u0128t , x[1,m),t , \u03b8[m,M],t )\nZ\n= p(xm,t = x\u0303m,t |y t , \u0128t , x[1,m),t , \u03b8[m,M],t )p(y t |xt , \u0128t )p(x(m,M],t |\u03b8(m,M],t )dx(m,M],t dy t .\n\n(20)\n\n2) LMMSE Detector: Since the optimal detector is infeasible in terms of the complexity, it is important in\npractice to obtain a lower bound based on the LMMSE detector with SIC. We follow [17] to derive the LMMSE\ndetector that feeds to the associated detector an approximate posterior pdf of xm,t based on the knowledge about the\nreceived vector y t , the data symbols x[1,m),t decoded in the preceding substages, the bias \u03b8[m,M],t for the unknown\ndata symbols x[m,M],t = (xm,t , . . . , xM,t )T , and the joint posterior pdf p(H|\u0128t ) provided by the LMMSE channel\nestimator.\nWe first divide the RHS of the MIMO channel (1) into two terms:\n1\n1\ny t = \u221a \u0124 t xt + \u221a (H \u2212 \u0124 t )xt + nt ,\nM\nM\n3 The\n\n(21)\n\nmarginal posterior pdf (17) is replaced by the posterior pmf of xm,t if xm,t is a discrete random variable.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n12\n\nwith \u0124 t denoting the LMMSE estimate (15) of the channel matrix. Let \u0124 [1,m),t \u2208 CN \u00d7(m\u22121) and \u0124 [m,M],t \u2208\nCN \u00d7(M\u2212m+1) denote the matrices that consist of the first (m \u2212 1) column vectors of the LMMSE estimate (15)\n\nand of the last (M \u2212 m + 1) column vectors, respectively. The first term of the RHS in (21) is further decomposed\ninto two terms:\n1\n1\n1\ny t = \u221a \u0124 [1,m),t x[1,m),t + \u221a \u0124 [m,M],t x[m,M],t + \u221a (H \u2212 \u0124 t )xt + nt ,\nM\nM\nM\n\n(22)\n\nwhere the first term of the RHS is a known quantity. From this expression, the LMMSE detector is defined via the\npostulated MIMO channel\n(L)\n\n\u1ef9 t\n(L)\n\nwhere \u1ef9 t\n\n1\n1\n(L)\n(L)\n\u2212 \u221a \u0124 [1,m),t x[1,m),t = \u221a \u0124 [m,M],t x\u0303[m,M],t + w\u0303t + nt ,\nM\nM\n(L)\n\n(L)\n\n(23)\n\n(L)\n\n\u2208 CN and x\u0303[m,M],t = (x\u0303m,t , . . . , x\u0303M,t )T \u2208 CM\u2212m+1 denote the received vector and the data symbol\n(L)\n\nvector postulated by the LMMSE detector, respectively. The postulated data symbol vector x\u0303[m,M],t is assumed to\nbe a proper complex Gaussian random vector with mean \u03b8[m,M],t and covariance\n\u03a3m,t = P I M\u2212m+1 \u2212 diag(|\u03b8m,t |2 , . . . , |\u03b8M,t |2 ),\n\n(24)\n(L)\n\nwhich are the same as the mean and covariance of the original vector x[m,M],t , respectively. Furthermore, w\u0303 t\n\n\u2208 CN\n\nis a CSCG random vector with the covariance matrix \u03b6m,t I N , in which\n\u03b6m,t =\nwith\n\n\u0001\n1\nTr E[xt xH\nt |x[1,m),t ]\u039et ,\nM\n\n2\n2\nE[xt xH\nt |x[1,m),t ] = diag(|x1,t | , . . . , |xm\u22121,t | , P, . . . , P ).\n(L)\n\nNote that w\u0303t\n\n(25)\n\n(26)\n\nhas the same first and second moments as those of the third term on the RHS of (22).\n(L)\n\n(L)\n\nThe posterior distribution of x\u0303[m,M],t given \u1ef9 t , \u0128t , x[1,m),t , and \u03b8[m,M],t is a proper complex Gaussian\n(L)\n\n(L)\n\ndistribution with mean x\u0302[m,M],t and covariance \u039em,t , given by\n\u001a\n\u0013\n\u001b\n\u0012\nH\n1\n1\n(L)\n(L)\n(L)\n\u03b8\nx\u0302[m,M],t = (\u039em,t )\u22121 \u221a (N0 + \u03b6m,t )\u22121 \u0124 [m,M],t \u1ef9 t \u2212 \u221a \u0124 [1,m),t x[1,m),t + \u03a3\u22121\nm,t [m,M],t ,\nM\nM\n\u0012\n\u0013\u22121\nH\n1\n(L)\n\u22121\n\u22121\n\u039em,t = \u03a3m,t +\n(N0 + \u03b6m,t ) \u0124 [m,M],t \u0124 [m,M],t\n.\nM\n(L)\n\nNote that the posterior mean (27) with \u1ef9 t\n\n(27)\n(28)\n\n= y t is equal to the LMMSE estimate of x[m,M],t . The LMMSE\n(L)\n\n(L)\n\n= y t , \u0128t , x[1,m),t , \u03b8[m,M],t ), corresponding to (17),\n(L)\n(L)\np(x\u0303[m,M],t |\u1ef9 t , \u0128t , x[1,m),t , \u03b8 [m,M],t ). Thus, we have a\n\ndetector with SIC sends the marginal posterior pdf p(x\u0303m,t |\u1ef9 t\ngiven via the marginalization of the joint posterior pdf\n\nlower bound of the achievable rate based on the LMMSE detector with SIC\nTc\nM\nX\n1 X\n(L)\nC\u2265\nI(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ),\nTc\nm=1\n\n(29)\n\nt=Ttr +1\n\nwhich is given via the equivalent channel between the data symbol xm,t and the associated LMMSE detector in\nthe same manner as in (19).\nThe goal of this paper is to optimize the length of training phase Ttr , the prior pdf of the data symbols, and the\nhyperprior pdf of the bias in terms of the two lower bounds (19) and (29).\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n13\n\nIV. M AIN R ESULTS\nA. Large-System Analysis\nFirst, the lower bound (19) based on the optimal detector is evaluated in the large-system limit. We focus\non substage m within stage t in the SD receiver. In order to calculate I(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ), we\nhave to evaluate the distribution of the equivalent channel (20), which is a probability distribution on the space\nof distributions and depends on the omitted variables \u0398(Ttr ,t) and \u03b8[1,m),t implicitly through the posterior pdf\np(H|\u0128t ) and x[1,m),t . This evaluation is quite difficult in general for finite-sized systems. A key assumption of\ncircumventing this difficulty is the assumption of the large-system limit in which M , N , Tc , Ttr , t, and m tend to\ninfinity while their ratios \u03b1 = M/N , \u03b2 = M/Tc , \u03c40 = Ttr /Tc , \u03c4 = t/Tc , and \u03bc = m/M are kept constant. The\nself-averaging property for the equivalent channel (20) is expected to hold in the large-system limit: The distribution\nof the equivalent channel (20) converges to a Dirac measure on the space of distributions in the large-system limit.\nSee [45] for a mathematical treatment of self-averaging. The assumption of self-averaging implies that the detection\nperformance for each data symbol coincides with the corresponding average performance in the large-system limit.\nUnder this assumption, the replica method allows us to analyze the equivalent channel (20) in the large-system\nlimit.\nThe self-averaging properties are classified into those for extensive quantities and those for non-extensive quantities. The former quantities are proportional to the size of systems, while the latter quantities are not. The selfaveraging property for extensive quantities, such as sum capacity and the so-called free-energy in statistical physics,\nhas been rigorously justified for linear systems [25] and general systems [46], [47]. It might be possible to prove the\nself-averaging property for the lower bound (19) by using the method developed in [46], [47]. However, we need\nthe self-averaging property for each equivalent channel (20), which is non-extensive. The self-averaging property\nfor non-extensive quantities is less understood except for several simple cases.\nWe also need the self-averaging property for each element of the error covariance matrix (16), along with that\nfor the equivalent channel (20). Note that the error covariance matrix (16) is a random matrix depending on X\u0304 \\t\nexplicitly and on \u0398(Ttr ,t) implicitly through the data symbol vectors decoded in the preceding stages. See [48] for\nthe self-averaging property of each diagonal element for random covariance matrices.\nAssumption 1. Each element of the error covariance matrix (16) for the LMMSE channel estimation converges in\nprobability to a deterministic value in the large-system limit,\n\uf8f1\n\uf8f4\n\uf8f4\n\u03be 2 (\u03c4 )\n\uf8f4\n\uf8f2\n(\u039et )m\u0303,m\u0303\u2032 \u2192\n\u03c1(\u03c4 )\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 \u03c1\u2217 (\u03c4 )\n\ni.e.,\nfor m\u0303 = m\u0303\u2032\nfor m\u0303 < m\u0303\u2032\n\n(30)\n\nfor m\u0303 > m\u0303\u2032 .\n\nThe error covariance matrix (16) does not depend on the number of receive antennas N or the current substage m.\n\nThus, the limits (30) do not depend on \u03b1 or \u03bc, while they may depend on \u03b2, \u03c40 , and \u03c4 . Assumption 1 has been\nrigorously proved for the unbiased case \u03b8m,t = 0 in [26].\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n14\n\nAssumption 2. The equivalent channel (20) is self-averaging with respect to \u1ef8 \\t and x[1,m),t : (20) converges\nin law to a conditional pdf of x\u0303m,t given xm,t , X\u0304 \\t , and \u03b8 t , which does not depend on \u1ef8 \\t or x[1,m),t , in the\nlarge-system limit.\nThe self-averaging property for equivalent channels has been rigorously proved in the case of linear receivers by\nusing random matrix theory [24], [26], while its justification is still open for nonlinear receivers. The equivalent\nchannel (20) is also expected to be self-averaging with respect to the other random variables. However, Assumption 2\nis sufficient for using the replica method. We postulate Assumptions 1 and 2 since their justification is beyond the\nscope of this paper.\nFollowing the replica methodology raises the issue of whether replica symmetry (RS) or replica symmetry breaking\n(RSB) should be assumed. The formal definition of the RS assumption will be presented in Appendices B and C.\nRoughly speaking, RSB should be assumed for complicated optimization problems in which the object function has\nmulti-valley structure [36], [37]. There are many local optima for such an object function. On the other hand, the RS\nassumption is applicable to simple problems such that the object function has the unique global optimum or a few\nlocal optima. Nishimori's rigorous result [49] suggests that the individually optimal (IO) detection [50] considered\nin this paper should have a simple structure corresponding to the RS assumption, while the jointly optimal (JO)\ndetection [50] should be a complicated problem corresponding to the RSB assumption. A recent rigorous study [51]\nalso supports the RS assumption for the IO detection. Thus, the RS assumption is postulated in this paper. Note\nthat the self-averaging property for the equivalent channel might not hold if the system had a complicated structure\ncorresponding to the RSB assumption [37], [52].\nThe lower bound (19) is given as a double integral of the constrained capacity for AWGN channels. We first\nderive the AWGN channels in a heuristic manner. The heuristic derivation described below provides an intuitive\ninterpretation of the AWGN channels, although the formal derivation is based on the replica method. In the current\nstage t = \u03c4 Tc , with \u03c40 \u2264 \u03c4 \u2264 1, we consider fading channels with time diversity for channel estimation,\n1\ny n,t\u2032 = \u221a hn,m xm,t\u2032 + w n,t\u2032 ,\nM\n1\nyn,t\u2032 = \u221a hn,m \u03b8m,t\u2032 + wn,t\u2032 ,\nM\n\nfor all t\u2032 < t,\n\n(31)\n\nfor all t\u2032 > t,\n\n(32)\n\n2\nwith w n,t\u2032 \u223c CN (0, \u03c3tr\n) for t\u2032 < t and with w n,t\u2032 \u223c CN (0, \u03c3c2 ) for t\u2032 > t. The fading channels are obtained by\n\nextracting the first terms in (31) and (32) from the original and virtual MIMO channels (1) and (11), and then by\n2\napproximating the remaining terms by CSCG random vectors with covariance \u03c3tr\nI N and \u03c3c2 I N , respectively. We\n\napply maximal-ratio combining (MRC) to (31) and (32),\n\u03c4X\nTc \u22121\n1\nz tr = p\nx\u2217m,t\u2032 yn,t\u2032 ,\nP (\u03c4 Tc \u2212 1) t\u2032 =1\n\n1\nzc = p 2\n\u03c3\u03b8 (1 \u2212 \u03c4 )Tc\nOctober 25, 2018\n\nTc\nX\n\n\u2217\n.\n\u03b8m,t\n\u2032y\nn,t\u2032\n\n(33)\n\n(34)\n\nt\u2032 =\u03c4 Tc +1\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n15\n\nTaking the large-system limit, due to the weak law of large numbers, we obtain\n\uf8eb \u221a\n\uf8eb \uf8f6\n\uf8f6\n\uf8eb \uf8f6\n\u03c4P\nz tr\nw\n1\n\uf8ed \uf8f8 = \u221a \uf8edp\n\uf8f8 hn,m + \uf8ed tr \uf8f8 ,\n2\n\u03b2\n(1 \u2212 \u03c4 )\u03c3\u03b8\nzc\nwc\n\n(35)\n\n2\nwhere wtr and wc are mutually independent CSCG random variables with variances \u03c3tr\nand \u03c3c2 , respectively. The\n\nminimum mean-squared error (MMSE) estimate of hn,m for the channel (35) is given by [53]\n!\np\n\u221a\n(1 \u2212 \u03c4 )\u03c3\u03b82\n\u03c4P\n1\nzc .\n\u0125n,m = \u221a 2\n2 z tr +\n\u03c3tr\n\u03c3c2\n\u03b2\u03be (\u03c4 )\nwhere the mean-squared error (MSE) \u03be 2 (\u03c4 ) for the MMSE estimate (36) is explicitly given by\n\u0012\n\u0013\u22121\n\u03c4P\n(1 \u2212 \u03c4 )\u03c3\u03b82\n2\n\u03be (\u03c4 ) = 1 + 2 +\n.\n\u03c3tr \u03b2\n\u03c3c2 \u03b2\n\n(36)\n\n(37)\n\nIt is well known that the MMSE estimate \u0125n,m and the estimation error \u2206hn,m = hn,m \u2212 \u0125n,m are uncorrelated\nCSCG random variables with variances (1 \u2212 \u03be 2 (\u03c4 )) and \u03be 2 (\u03c4 ), respectively.\n\nWe next consider fading channels with spatial diversity for data estimation in the current substage m = \u03bcM for\n0 \u2264 \u03bc \u2264 1,\n\no\n1 n\n\u0125n,m xm,t + \u2206hn,m xm,t + wn,t ,\ny n,t = \u221a\nM\n\nn = 1, . . . , N,\n\n(38)\n\nwhere w n,t \u2208 C denotes a CSCG random variable with variance \u03c3 2 (\u03c4, \u03bc). Applying the MRC to {yn,t }, we obtain\nN\nX\n\u2217\n1\nz= p\n\u0125n,m y n,t .\nN (1 \u2212 \u03be 2 (\u03c4 )) n=1\n\nTaking the large-system limit gives the AWGN channel\nr\n1 \u2212 \u03be 2 (\u03c4 )\nxm,t + w,\nz=\n\u03b1\n\n(39)\n\n(40)\n\nwith w \u223c CN (0, \u03c3 2 (\u03c4, \u03bc)). The MMSE estimate x\u0302m,t of xm,t for the AWGN channel (40) is given as the mean\nR\nx\u0302m,t = xm,t p(xm,t |z, \u03b8m,t )dxm,t with respect to the posterior pdf\np(xm,t |z, \u03b8m,t ) = R\n\np(z|xm,t )p(xm,t |\u03b8m,t )\n,\np(z|xm,t )p(xm,t |\u03b8m,t )xm,t\n\n(41)\n\nwhere p(z|xm,t ) represents the AWGN channel (40). The MSE for the MMSE estimate x\u0302m,t given \u03b8m,t is defined\nas\n\u0002\n\u0003\nMSE(\u03c3 2 , \u03b8m,t ) = E |xm,t \u2212 x\u0302m,t |2 \u03b8m,t .\n\n(42)\n\n2\nWe have not so far specified the variances \u03c3tr\n, \u03c3c2 , and \u03c3 2 (\u03c4, \u03bc). The constrained capacity of the AWGN\n\nchannel (40) corresponds to the mutual information in the lower bound (19) when the three variances are determined\nas solutions to fixed-point equations.\nProposition 1 (Optimal Detector). Suppose that Assumption 1, Assumption 2, and the RS assumption hold. Then,\nthe constrained capacity (7) per transmit antenna is bounded from below by\nZ\nZ\nC\nI(xm,t ; z|\u03b8m,t )d\u03c4 d\u03bc,\n\u2265\nM\n\u03c4 \u2208[\u03c40 ,1] \u03bc\u2208[0,1]\nOctober 25, 2018\n\n(43)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n16\n\nin the large-system limit, in which the mutual information I(xm,t ; z|\u03b8m,t ) is equal to the constrained capacity of\n2\n, \u03c3c2 } is given as the solution to the coupled fixed-point\nthe AWGN channel (40). In evaluating I(xm,t ; z|\u03b8m,t ), {\u03c3tr\n\nequations\n2\n\u03c3tr\n= N0 + P \u03be 2 (\u03c4 ),\n\n(44)\n\n\u03c3c2 = N0 + (P \u2212 \u03c3\u03b82 ) + \u03c3\u03b82 \u03be 2 (\u03c4 ),\n\n(45)\n\nwhere \u03be 2 (\u03c4 ) is given by (37). Furthermore, \u03c3 2 (\u03c4, \u03bc) is given as a solution \u03c3 2 to the fixed-point equation\n\u0002\n\u0003\n\u03c3 2 = N0 + P \u03be 2 (\u03c4 ) + (1 \u2212 \u03bc)(1 \u2212 \u03be 2 (\u03c4 ))E MSE(\u03c3 2 , \u03b8m,t ) ,\n\n(46)\n\nwhere MSE(\u03c3 2 , \u03b8m,t ) is given by (42). If the fixed-point equation (46) has multiple solutions, one should choose\nthe solution minimizing the following quantity\n(1 \u2212 \u03bc)I(xm,t ; z|\u03b8m,t ) +\n\n\u0014\n\u0015\n1\n\u03be 2 (\u03c4 )\nD2 (N0 k\u03c3 2 ) +\nlog\ne\n.\n2\n\u03b1\n\u03c32\n\n(47)\n\nDerivation of Proposition 1: See Appendix A.\n2\nNote that the last terms in the coupled fixed-point equations (44) and (45) depend on \u03c3tr\nand \u03c3c2 through (37).\n\nEquation (46) for given \u03be 2 (\u03c4 ) provides a fixed-point equation with respect to \u03c3 2 . The second and last terms in the\nRHS of (46) correspond to contributions from channel estimation errors and inter-stream interference, respectively.\nThe integrand in (43) depends on the variables \u03c4 and \u03bc through the SNR P (1 \u2212 \u03be 2 (\u03c4 ))/(\u03b1\u03c3 2 (\u03c4, \u03bc)).\nThe existence of multiple solutions in (46) relates to the so-called phase transition in statistical physics. See [28],\n[31] for an interpretation in the context of communications. Numerical evaluation of (46) for QPSK modulation\nimplies that multiple solutions do not appear when \u03b1 \u2264 1. In the high SNR regime there is no point to use\ntransmit antennas more than receive antennas or half the coherence time. In fact, Zheng and Tse [10] proved\nthat the full spatial multiplexing gain of the MIMO channel with no CSI is given by M\u0304 (1 \u2212 M\u0304 /Tc ), with M\u0304 =\nmin{M, N, \u230aTc /2\u230b}, which is achieved by using min{N, \u230aTc /2\u230b} transmit antennas out of M transmit antennas\nif M > N or M > \u230aTc /2\u230b. Thus, we consider \u03b1 \u2264 1 and \u03b2 \u2264 1/2 in the high SNR regime.\nNext, the lower bound (29) based on the LMMSE detector is evaluated in the large-system limit. The following\nproposition is obtained in the same manner as in the derivation of Proposition 1.\nAssumption 3. The equivalent channel for the LMMSE detector is self-averaging with respect to \u1ef8 \\t and x[1,m),t\nin the large-system limit.\nProposition 2 (LMMSE Detector). Suppose that Assumption 1, Assumption 3, and the RS assumption hold. Then,\nthe constrained capacity (7) per transmit antenna is bounded from below by (43) in the large-system limit. In\n2\nevaluating (43), {\u03c3tr\n, \u03c3c2 } is given as the solution to the coupled fixed-point equations (44) and (45). On the other\n\nhand, \u03c3 2 (\u03c4, \u03bc) is given as the unique solution \u03c3 2 to the fixed-point equation\n\u0015\n\u0014\n(P \u2212 |\u03b8m,t |2 )\u03b1\u03c3 2\n2\n2\n2\n.\n\u03c3 = N0 + P \u03be (\u03c4 ) + (1 \u2212 \u03bc)(1 \u2212 \u03be (\u03c4 ))E\n(1 \u2212 \u03be 2 (\u03c4 ))(P \u2212 |\u03b8m,t |2 ) + \u03b1\u03c3 2\n\nOctober 25, 2018\n\n(48)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n17\n\nDerivation of Proposition 2: Proposition 2 is obtained by repeating the derivation of Proposition 1. Thus, we\nonly prove the uniqueness of the solution to the fixed-point equation (48). The RHS of (48) is a concave function\nof \u03c3 2 , which intersects with a straight line passing the origin with slope 1 at two points. Since the concave function\npasses the point (0, N0 +\u03be 2 (\u03c4 )), which is above the origin, one intersection must be in \u03c3 2 < 0. Thus, the fixed-point\nequation (48) has the unique solution in the region \u03c3 2 > 0.\nThe expectation in the RHS of (48) corresponds to the MSE for the LMMSE estimator of the data symbol xm,t\ntransmitted through the AWGN channel (40), while (42) in the fixed-point equation (46) is the MSE for the MMSE\nestimator.\nB. Optimization\nThe next goal is to optimize the lower bound (43) based on the optimal detector with respect to \u03c40 , the hyperprior\npdf of \u03b8m,t , and the prior pdf of xm,t . We first notice that the lower bound (43) is monotonically nonincreasing\nwith respect to \u03c40 since the integrand is non-negative and does not depend on \u03c40 . Thus, the lower bound (43) is\nmaximized as \u03c40 \u2192 0. Note that the limit \u03c40 \u2192 0 does not necessarily indicate no pilot symbols, since we have\ntaken the limit \u03c40 \u2192 0 after the large-system limit. In other words, the effect of pilot symbols is negligible in\nProposition 1 if Ttr is sublinear in Tc , i.e., Ttr = o(Tc ).\nNext, we maximize the lower bound (43) with respect to the hyperprior pdf of \u03b8m,t . For a fixed hyperprior pdf,\nthe SNR P (1\u2212\u03be 2 (\u03c4 ))/(\u03b1\u03c3 2 (\u03c4, \u03bc)) improves as the variance \u03c3\u03b82 grows, since the increase of \u03c3\u03b82 results in reductions\nof the channel estimator error \u03be 2 (\u03c4 ) and the inter-stream interference given by the last term in the RHS of (46).\nHowever, increasing \u03c3\u03b82 reduces the mutual information I(xm,t ; z|\u03b8m,t ) for a fixed SNR, due to the reduction of\npayload. Interestingly, numerical results presented in Section V show that the lower bound (43) is maximized as\n\u03c3\u03b82 \u2192 0 for a fixed hyperprior pdf of \u03b8m,t . This indicates that the lower bound (43) is maximized when \u03b8m,t = 0\nwith probability one.\nThe arguments described above indicate that negligible pilot information, or more precisely, the limits \u03c40 , \u03c3\u03b82 \u2192 0\nare best in the large-system limit, while \u03c40 = \u03b2 is best in terms of the HH bound [15]. Thus, we can conclude that\nthe SD scheme can reduce the overhead for training significantly. It is worth noting that using a capacity-achieving\nerror-correcting code is assumed in our analysis. We conjecture that if some practical coding is used finite \u03c40 or\n\u03c3\u03b82 are required for getting accurate channel estimates in the initial stage. See [54] for the case of practical coding.\nFinally, we optimize the lower bound (43) with respect to the prior pdf of xm,t . This optimization problem is\nnonlinear since the prior pdf of xm,t depends on \u03c3 2 through the last term in the RHS of the fixed-point equation (46).\nInstead of solving the nonlinear optimization problem exactly, we consider the biased Gaussian signaling xm,t \u223c\n\nCN (\u03b8m,t , P \u2212 |\u03b8m,t |2 ) as a suboptimal solution. This choice of the prior pdf should be reasonable since Gaussian\nsignaling is optimal if accurate channel estimates can be obtained. In this case, Proposition 1 reduces to the following\ncorollary.\nCorollary 1. Suppose that Assumption 1, Assumption 2, and the RS assumption hold. If xm,t \u223c CN (\u03b8m,t , P \u2212\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n|\u03b8m,t |2 ), then the constrained capacity (7) per transmit antenna is bounded from below by cg given by\n\u0013\u0015\n\u0014 \u0012\nZ\nZ\nC\n(1 \u2212 \u03be 2 (\u03c4 ))(P \u2212 |\u03b8m,t |2 )\nd\u03c4 d\u03bc,\nE log 1 +\n\u2265 cg =\nM\n\u03b1\u03c3 2 (\u03c4, \u03bc)\n\u03c4 \u2208[\u03c40 ,1] \u03bc\u2208[0,1]\n\n18\n\n(49)\n\nin the large-system limit. In evaluating the integrand in (49), \u03be 2 (\u03c4 ) is given by (37), defined via (44) and (45).\nFurthermore, \u03c3 2 (\u03c4, \u03bc) is given as the unique solution \u03c3 2 to the fixed-point equation (48).\nProof of Corollary 1: It is straightforward to confirm that the lower bound (43) and the fixed-point equation (46)\nreduce to (49) and (48) under the biased Gaussian signaling, respectively.\nWe believe that the biased Gaussian signaling maximizes the quantity (47), following the argument in [55]. If\n\u03be 2 (\u03c4 ) = 0 and \u03c3 2 = N0 were satisfied for all \u03c4 and \u03bc, the biased Gaussian signaling would maximize the lower\nbound (43). However, \u03be 2 (\u03c4 ) is bounded from below by a positive value for \u03c4 < \u03b2. This implies the suboptimality\nof the i.i.d. Gaussian signaling.\nProposition 2 and Corollary 1 imply that the large-system performance of the LMMSE detector coincides with\nthat of the optimal detector when the i.i.d. Gaussian signaling is used. Note that this observation is not necessarily\ntrivial, since we have made the Gaussian approximation of the third term on the RHS of (22) in the derivation\nof the LMMSE detector. Our results imply that, for the i.i.d. Gaussian signaling, the performance loss due to the\nGaussian approximation vanishes in the large-system limit.\nC. High SNR Regime\nIn the high SNR limit N0 \u2192 0, the lower bound (49) is shown to achieve the full spatial multiplexing gain when\nTtr \u2264 M .\nProposition 3. Suppose that Assumption 1, Assumption 2, and the RS assumption hold. For \u03b1 \u2264 1 and \u03c40 \u2264 \u03b2 \u2264 1/2,\n\nthe lower bound (49) with the biased Gaussian signaling xm,t \u223c CN (\u03b8m,t , P \u2212 |\u03b8m,t |2 ) achieves the full spatial\nmultiplexing gain in the high SNR limit N0 \u2192 0, i.e.,\nlim inf\nN0 \u21920\n\ncg\n= 1 \u2212 \u03b2.\nlog(P/N0 )\n\n(50)\n\n2\nProof of Proposition 3: We first prove that the solution \u03c3tr\nto the coupled fixed-point equations (44) and\n2\n(45) converges to zero in the high SNR limit for \u03c4 > \u03b2. The proof is by contradiction. Suppose that \u03c3tr\nis strictly\n2\npositive in the high SNR limit. Dividing both sides of (44) by \u03c3tr\nand taking the high SNR limit, we have\n\n1=\n\n\u03b2P \u03c3c2\n2 \u03c3 2 + \u03c4 P \u03c3 2 + (1 \u2212 \u03c4 )\u03c3 2 \u03c3 2 .\n\u03b2\u03c3tr\nc\nc\n\u03b8 tr\n\n(51)\n\nRearranging (51), we obtain\n2\n\u03c3tr\n=\u2212\n\n(\u03c4 \u2212 \u03b2)P \u03c3c2\n.\n\u03b2\u03c3c2 + (1 \u2212 \u03c4 )\u03c3\u03b82\n\n(52)\n\n2\nHowever, the RHS of (52) is negative, due to \u03c4 > \u03b2, which is a contradiction. Thus, the solution \u03c3tr\nmust converge\n\nto zero in the high SNR limit for \u03c4 > \u03b2. This result implies that the MSE (37) also converges to zero in the high\nSNR limit for \u03c4 > \u03b2.\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n19\n\nIt is straightforward to show in a similar manner that the solution \u03c3 2 to the fixed-point equation (48) is O(N0 )\nin the high SNR limit for \u03b1 \u2264 1 when the MSE (37) converges to zero. Thus, we have\nlim inf\nN0 \u21920\n\ncg\n= 1 \u2212 \u03b2,\nlog(P/N0 )\n\n(53)\n\nwhich is equal to the full spatial multiplexing gain for \u03b1 \u2264 1 and \u03b2 \u2264 1/2.\nThe proof of Proposition 3 indicates that in the first M stages the performance of the SD receiver is limited by\nchannel estimation errors, rather than inter-stream interference in MUD. This phenomenon is robust in the sense\nthat it occurs regardless of the prior of data symbols.\nD. Low SNR Regime\nThe power per information bit Eb required for reliable communication is a key performance measure in the\nlow SNR regime. Verd\u00fa [12] proved that the capacity Copt of the MIMO channel (1) wit no CSI is given by\nCopt = N P/(N0 ln 2) + o(N0 ) in the low SNR limit N0 \u2192 \u221e, or N Eb /N0 \u2265 limN0 \u2192\u221e N P/(N0 Copt ) = ln 2 \u2248\n\u22121.59 dB. Since using multiple transmit antennas wastes valuable power in the low SNR regime, the number of\n\ntransmit antennas used should be reduced as N0 increases. One option is to increase M \u22121 and N0 at the same rate.\n\nThus, we consider the limit, in which \u03b1, \u03b2 \u2192 0 and N0 \u2192 \u221e while \u03b2/\u03b1 and s = P/(\u03b2N0 ) are kept constant. The\nfollowing proposition provides an upper bound on the normalized SNR N Eb /N0 = N P/(N0 C) required for the\noptimal SD receiver, with C denoting the achievable rate (8) of the optimal SD receiver.\nProposition 4. Suppose that the optimal SD receiver achieves a rate R/M . Then, the normalized SNR N Eb /N0\nis bounded from above by\nN\n\n\u03b2s\nEb\n\u2264\n+ o(N0 ),\nN0\n\u03b1R\n\n(54)\n\nin the limit where \u03b1, \u03b2 \u2192 0 and N0 \u2192 \u221e while \u03b2/\u03b1 and s = P/(\u03b2N0 ) are kept constant. In (54), s is implicitly\ngiven by\n\n\u0013\n\u0013\u22121 #\n\u0012\n\u0013 \u0012\n\u0012\n\u03b2\n1\n\u03b2 2\nlog(1 + s).\nlog 1 + s + s2 \u2212 1 +\nR = 1+ s+ s\n\u03b1\n\u03b1\ns\n\"\n\n(55)\n\nProof of Proposition 4: Using the lower bound (49) for Gaussian signaling, we obtain an upper bound\nN Eb /N0 \u2264 N P/(M N0 cg ) = \u03b2s/(\u03b1cg ). Thus, it is sufficient to prove that the maximum of cg with respect to \u03c40\n\nand \u03c3\u03b82 is given by the RHS of (55).\n\n2\nWe evaluate the solutions to the fixed-point equations (44), (45), and (48). It is straightforward to find that \u03c3tr\n/N0 ,\n\n\u03c3c2 /N0 , and \u03c3 2 /N0 tend to 1 as N0 \u2192 \u221e, since (37) and (42) are bounded. This observation implies\n\u0014\n\u0012\n\u0013\n\u0015\nZ 1\n\u03b2s\n\u03c32\n\u03c4 + (1 \u2212 \u03c4 )\u03c3\u03b82 /P\nlog 1 +\ncg \u2264\n1\u2212 \u03b8\nd\u03c4 + o(N0 ),\n\u03b1\nP s\u22121 + \u03c4 + (1 \u2212 \u03c4 )\u03c3\u03b82 /P\n\u03c40\n\n(56)\n\nin the limit described in Proposition 4. In the derivation of (56), we have used Jensen's inequality. The equality holds\nonly when |\u03b8m,t |2 takes \u03c3\u03b82 with probability one. It is easy to confirm that the integrand in (56) is monotonically\ndecreasing with respect to \u03c3\u03b82 . Thus, the maximum of cg is achieved at \u03c40 = 0 and \u03c3\u03b82 = 0, and given by\n\u0015\n\u0014\nZ 1\n\u03b2 s2 \u03c4\nd\u03c4 + o(N0 ).\nmax cg =\nlog 1 +\n\u03b1 1 + s\u03c4\n\u03c40 ,\u03c3\u03b82 \u22650\n0\n\nOctober 25, 2018\n\n(57)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n20\n\n1.6\nGaussian\nAchievable Rate per Transmit Antenna (bps/Hz)\n\n1.4\n\nQPSK\n\u03b2=M/Tc=0.1\n\n1.2\n\n1\n\n0.8\n\n\u03b2=M/Tc=0.5\n\n0.6\n\n0.4\n\n0.2\n\n0\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\u03c3\n\nFig. 2.\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\n2\n\u03b8\n\nAchievable rate versus the variance of the bias \u03c3\u03b82 for the SNR P/N0 = 6 dB, \u03b1 = M/N = 1, and \u03c40 = Ttr /Tc = 0.\n\nCalculating the integration in (57), we find that the first term in the RHS of (57) is equal to the RHS of (55).\nIn the proof of Proposition 4, we have proved that the lower bound (49) is maximized at \u03c40 = 0 and \u03c3\u03b82 = 0 in\nthe low SNR regime. This result implies that negligible pilot information is best in terms of the lower bound (49)\nin the low SNR regime.\nIt is interesting to note that the achievable rate (55) is approximated by R = \u03b2s2 /(2\u03b1 ln 2) + O(s3 ) as s \u2192 0,\np\nwhich implies that N Eb /N0 \u2264 2\u03b2 ln 2/\u03b1R + o(N0 , R) in the low rate regime, i.e., the upper bound (54) diverges\n\nin R \u2192 0. In other words, the minimum of the upper bound (54) is achieved at a strictly positive rate, as shown\nin Section V. We remark that a similar result was reported in [56].\nThe reason why the minimum is achieved at a positive rate is because we have spread power over all time slots.\n\nIt is well known that on-off keying is optimal in the low SNR regime, in other words, that spreading power over\nall time slots results in a waste of valuable power. If on-off keying was used, the normalized SNR required would\nreduce monotonically as the achievable rate decreases, as shown in [56]. However, on-off keying requires high\npeak-to-average power ratio (PAPR), which is unfavorable in practice. Thus, the minimum of the upper bound (54)\nmay be interpreted as a practical performance bound in terms of energy efficiency.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n21\n\n2.75\nGaussian\n\n2.5\nAchievable Rate per Transmit Antenna (bps/Hz)\n\nQPSK\n2.25\n\nHH bound [15]\n\n2\n1.75\n\u03b2=M/Tc=0.1\n1.5\n1.25\n1\n\u03b2=M/Tc=0.5\n0.75\n0.5\n0.25\n0\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\nP/N0 in dB\n\nFig. 3.\n\nAchievable rate versus SNR in the moderate SNR regime for the variance of the bias \u03c3\u03b82 = 0, \u03b1 = M/N = 1, and \u03c40 = Ttr /Tc = 0.\n\nV. N UMERICAL R ESULTS\nA. Large Systems\nThe lower bound (49) for the biased Gaussian signaling is compared to two existing bounds in this section. One\nis the HH bound [15], which corresponds to the achievable rate of receivers based on one-shot channel estimation,\nin which the decoded data symbols are not re-utilized for refining the channel estimates. The other one is the\nhigh-SNR approximation of the capacity [10], which includes a deviation of o(1) from the capacity at high SNR.\nIn all numerical results, we chose \u03c40 = 0 since the lower bound (49) is maximized at \u03c40 = 0. In order to investigate\nthe optimal choice of \u03c3\u03b82 , we display the lower bound (49) for the biased Gaussian signaling with respect to \u03c3\u03b82\nin Fig. 2. The lower bound (43) for the biased QPSK signaling is also shown in the same figure. We have used\np(\u03b8) = [\u03b4(\u03b8 \u2212 \u03c3\u03b8 ) + \u03b4(\u03b8 + \u03c3\u03b8 )]/2 as the distribution of \u03b8m,t , i.e., \u03b8m,t takes \u00b1\u03c3\u03b8 with equal probability. We find\nthat the lower bound for the biased Gaussian signaling is larger than that for the biased QPSK signaling for all \u03c3\u03b82 .\n\nFurthermore, both lower bounds are monotonically decreasing as \u03c3\u03b82 grows. The latter observation implies that the\nlower bounds are maximized at \u03c3\u03b82 = 0, in other words, negligible pilot information is best in terms of the lower\nbounds. Hereinafter, we consider the unbiased case \u03c3\u03b82 = 0.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n22\n\n11\nhigh-SNR approximation [10]\n\n10\nAchievable Rate per Transmit Antenna (bps/Hz)\n\nGaussian\n9\n\nHH bound [15]\n\n8\n\u03b2=M/Tc=0.1\n\n7\n6\n5\n\n\u03b2=M/Tc=0.5\n\n4\n3\n2\n1\n0\n10\n\n12.5\n\n15\n\n17.5\n\n20\n\n22.5\n\n25\n\n27.5\n\n30\n\n32.5\n\n35\n\n37.5\n\n40\n\nP/N0 in dB\n\nFig. 4.\n\nAchievable rate versus SNR in the high SNR regime for the variance of the bias \u03c3\u03b82 = 0, \u03b1 = M/N = 1, and \u03c40 = Ttr /Tc = 0.\n\nFigure 3 provides a comparison between the lower bound (49) for unbiased Gaussian signaling and the HH\nbound in the moderate SNR regime. The lower bound (43) for QPSK modulation is also displayed. The HH bound\nis a lower bound on the capacity for finite-sized systems [15, Theorem 3]. We have used a large-system formula\nof the HH bound, which is easily derived in the same manner as in [25]. There is a significant gap of 1 dB to\n1.8 dB between the lower bound for unbiased Gaussian signaling and the HH bound for all SNRs. Moreover,\nthe HH bound is inferior even to the lower bound for QPSK modulation in the case of short coherence time\n(\u03b2 = 0.5). These observations imply that SD receivers can provide a substantial performance gain in the moderate\nSNR regime, compared to receivers based on one-shot channel estimation, since they can reduce overhead for\ntraining significantly.\nNext, we compare the lower bound for unbiased Gaussian signaling with the high-SNR approximation of the\ncapacity [10, Corollary 11] in the high-SNR regime in Fig. 4. The HH bound is also displayed in the same figure.\nNote that in the high-SNR approximation the large-system limit is taken after the high SNR limit. Thus, the\ncomparison makes sense under the assumption that the large-system limit and the high SNR limit commute for the\nhigh-SNR approximation. We find that the high-SNR approximation is smaller than the lower bound for unbiased\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n23\n\n6\nHH bound [15]\n\n5.5\n\nQPSK\nGaussian\n\n5\n4.5\n\nNEb/N0 in dB\n\n4\n3.5\n\n\u03b2/\u03b1=N/Tc=0.5\n\n3\n2.5\n2\n\u03b2/\u03b1=N/Tc=0.1\n\n1.5\n1\n0.5\n0\n0\n\n0.25\n\n0.5\n\n0.75\n\n1\n\n1.25\n\n1.5\n\n1.75\n\n2\n\nAchievable Rate per Transmit Antenna (bps/Hz)\n\nFig. 5.\n\nNormalized SNR versus achievable rate in the low SNR regime for the variance of the bias \u03c3\u03b82 = 0 and \u03c40 = Ttr /Tc = 0.\n\nGaussian signaling in the SNR region of below 17.5 dB for \u03b2 = 0.5 or below 20 dB for \u03b2 = 0.1. This implies that\nthe high-SNR approximation derived by Zheng and Tse [10] is valid only for quite high SNR. The lower bound\nfor unbiased Gaussian signaling is close to the HH bound, rather than the high-SNR approximation, in the quite\nhigh SNR regime, which indicates the suboptimality of Gaussian signaling in the quite high SNR regime.\nFinally, we consider the low SNR regime and take the limit described in Proposition 4, in which the power\nper information bit Eb required for reliable communication is a key performance measure. Figure 5 displays the\nupper bound (54) of N Eb /N0 required for the SD receiver with unbiased Gaussian signaling as a function of the\nachievable rate per transmit antenna. The normalized SNRs N Eb /N0 are also plotted for the SD receiver with\nQPSK modulation and for the HH bound. We find that N Eb /N0 has a minimum at a positive achievable rate. This\nobservation is due to the suboptimality of i.i.d. Gaussian signaling. If perfect CSI was available at the receiver, the\nnormalized SNR N Eb /N0 would be monotonically decreasing with the reduction of the achievable rate [12], since\ni.i.d. Gaussian signaling is optimal in that case. For the case of no CSI, however, the normalized SNR N Eb /N0\ndiverges as the achievable rate tends to zero, since i.i.d. signaling wastes valuable power in the low SNR regime,\nas discussed in Section IV-D. Another observation is that there is a large gap of 1 dB to 1.5 dB between the\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n24\n\nminimal normalized SNRs for the SD receivers and the HH bound, while all bounds are far from the ultimate limit\nN Eb /N0 \u2248 \u22121.59 dB. This result implies that the SD scheme can significantly improve the HH bound in the low\nSNR regime.\nB. Finite-Sized Systems\nWe have so far considered the large-system performance. In order to confirm the usefulness of the large-system\nanalysis in practice, numerical simulations are presented for finite-sized systems with no CSI. Since the optimal\ndetector has high complexity, only the performance of the LMMSE detector is investigated. Unbiased QPSK and\nunbiased Gaussian signaling are considered. Note that, for the unbiased case, the performance of the LMMSE\nchannel estimator depends on stage t, rather than the coherence time Tc . Figure 6 shows the normalized MSE for\nthe LMMSE estimate (27) of the data symbols in substage m within stage t for the SD receiver. For comparison,\nwe plot the large-system results based on Proposition 2 with \u03b1 = M/N , \u03b2/\u03c4 = M/(t \u2212 1), and \u03bc = (m \u2212 1)/M .\nThe normalized MSE is given by the expectation in the RHS of (48) divided by P in the large-system limit. A\ncorrection of minus one for the stage index t is because the performance in stage t is approximated by that in\nstage t + 1 in the large-system limit. See (33)\u2013(35). A correction for the substage index is also due to the same\nreason. We find that the large-system results are in good agreement with those for not so large systems.\nVI. C ONCLUSIONS\nWe have investigated the achievable rates of SD receivers for the Rayleigh block-fading MIMO channel with\nno CSI. Analytical formulas for the achievable rates have been derived in the large-system limit, by using the\nreplica method. It has been shown that negligible pilot information is best in terms of the information-theoretical\nachievable rates. From a theoretical point of view, the formulas provide the best lower bound on the capacity among\nexisting analytical lower bounds that can be easily evaluated for all SNRs, while it is far from the true capacity\nin the low or quite high SNR regimes. From a practical point of view, the analytical lower bounds derived in\nthis paper can be regarded as a fundamental performance limit for practical training-based systems with QPSK or\nmultilevel modulation. We conclude that the SD receiver can reduce overhead for training significantly. Thus, it\nprovides a substantial performance gain, compared to receivers based on one-shot channel estimation, especially in\nthe low-to-moderate SNR regime.\nOne important future work is to investigate spatially correlated MIMO channels with no CSI. On the one hand,\nspatial correlations cause a reduction of diversity. On the other hand, they make it possible to estimate the channel\nmatrix more accurately than without correlations, since one can utilize the knowledge about the correlations for\nchannel estimation. Thus, it should be worth investigating impacts of these two effects onto the performance for\ntraining-based systems. It does not seem to be straightforward to extend the results presented in this paper to the\ncase of spatially correlated MIMO channels.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n25\n\n1\nlarge-system\nGaussian\nQPSK\n\n(M, N, t, m)=(8, 8, 17, 3)\n\nNormalized MSE\n\n10\n\n-1\n\n(M, N, t, m)=(8, 8, 81, 3)\n\n10\n\n-2\n\n10\n\n-3\n\n0\n\nFig. 6.\n\n5\n\n10\n\n15\nP/N0 in dB\n\n20\n\n25\n\n30\n\nNormalized MSE for the LMMSE detector versus SNR in substage m within stage t for the SD receiver. m = 3, t = 17, 81, M = 8\n\ntransmit antennas, N = 8 receive antennas, and the variance of the bias \u03c3\u03b82 = 0.\n\nA PPENDIX A\nD ERIVATION\n\nOF\n\nP ROPOSITION 1\n\nA. Sketch\nLet us consider substage m = \u03bcM within stage t = \u03c4 Tc in the SD receiver for 0 \u2264 \u03c4 \u2264 1 and 0 \u2264 \u03bc \u2264 1. For\nsome m\u0303 \u2208 N, we decompose the lower bound (19) into two terms,\n\" m\u0303\n#\nTc\nM\nX\nX\nX\nC\n1\n\u2265\nI(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8 [m,M],t ) ,\nI(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ) +\nM\nTc M\nm=m\u0303+1\nt=Ttr +1 m=1\n(58)\nand then take the limit in which M , N , Tc , Ttr , t, m, and m\u0303 tend to infinity while their ratios \u03b1 = M/N ,\n\u03b2 = M/Tc , \u03c40 = Ttr /Tc , \u03c4 = t/Tc , \u03bc = m/M , and \u03bc0 = m\u0303/M are kept constant. The second term consists\nof the mutual information for the decoding problem after an extensive number of users have been decoded, while\nthe first term contains the mutual information for the problem after a finite number of users have been decoded.\nWe will show below that I(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ) for \u03bc \u2265 \u03bc0 converges to the integrand in (43) in the\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n26\n\nPM\nPTc\nlarge-system limit. The definition of the Riemann integral implies that the sum (Tc M \u22121 ) t=T\nm=m\u0303+1 in\ntr +1\nR1\nR1\nthe second term of (58) tends to \u03c40 d\u03c4 \u03bc0 d\u03bc. Taking the limit \u03bc0 \u2192 0, we arrive at Proposition 1, since the first\nterm of (58) tends to zero as \u03bc0 \u2192 0.\n\nThe evaluation of I(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ) consists of two parts: analysis of the error covariance\nmatrix (16) and analysis of the equivalent channel (20). We apply the replica method to both analyses.\nB. Analysis of Channel Estimator\nWe evaluate the error covariance matrix (16) for the LMMSE channel estimation in the large-system limit. Since\nQN\n~ n |\u0128t ), without loss of generality, we focus on the\nthe joint posterior pdf p(H|\u0128t ) is decomposed into n=1 p(h\n\nestimation problem for the first row of H, denoted by ~h1 . The first row vector ~y \\t,1 \u2208 C1\u00d7(Tc \u22121) of (13) is given\nby\n1\n~y \\t,1 = \u221a ~h1 X\u0304 \\t + (~0, w\n~ (t,Tc ],1 ) + n\n~ \\t,1 ,\nM\n\n(59)\n\n~ (t,Tc ],1 \u2208 C1\u00d7(Tc \u2212t) and n\n~ \\t,1 \u2208 C1\u00d7(Tc \u22121) denote the first row vectors of the matrices W (t,Tc ] and N \\t ,\nwhere w\nrespectively.\nThe channel (59) can be regarded as a MIMO channel with the channel matrix X\u0304 \\t known to the receiver.\nThe main difference between X\u0304 \\t and zero-mean channel matrices considered in previous works [24]\u2013[26], [28],\n[30], [31] is that X\u0304 \\t has the nonzero mean X\u0302 \\t = (O, \u0398(Ttr ,t) , \u0398(t,Tc ] ) \u2208 CM\u00d7(Tc \u22121) conditioned on \u0398. Let\nus decompose the channel matrix X\u0304 \\t into the mean X\u0302 \\t and the difference X\u0304 \\t \u2212 X\u0302 \\t . The problem would\nreduce to the zero-mean case if the two matrices were independent of each other, since the sum of two independent\nmatrices with i.i.d. zero-mean entries is also a matrix with i.i.d. zero-mean entries. However, the two matrices are\nnot independent while they are uncorrelated zero-mean matrices. Thus, we have to treat the influence of higher-order\ncorrelations carefully.\nThe following proposition implies that the large-system results for each element of the error covariance matrix (16)\ncoincide with those for the case as if the two matrices X\u0302 \\t and X\u0304 \\t \u2212 X\u0302 \\t were mutually independent. In other\nwords, higher-order correlations between the two matrices do not affect the results for each element of the error\ncovariance matrix (16) in the large-system limit. Note that we do not claim the norm convergence k\u039et \u2212\u03be 2 (\u03c4 )I M k \u2192\n0.\nProposition 5. Suppose that Assumption 1 and the RS assumption hold. Then, each diagonal element of the\nerror covariance matrix (16) converges in probability to (37), defined by (44) and (45), in the large-system limit.\nFurthermore, each off-diagonal element of the error covariance matrix (16) converges in probability to zero in the\nlarge-system limit.\nProof: See Appendix B.\nProposition 5 was rigorously proved without Assumption 1 for the unbiased case \u03b8m,t = 0 in [26]. Since we\ncannot claim the norm convergence k\u039et \u2212 \u03be 2 (\u03c4 )I M k \u2192 0, a careful treatment of \u039et is required in the analysis of\nthe equivalent channel (20).\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n27\n\nWe remark that the convergence of each off-diagonal element to zero results from the fact that the MMSE estimate\n~ 1 and its error h\n~ 1 \u2212 \u01251 are uncorrelated with each other. In fact, we can show a stronger result for the\n\u01251 of h\noff-diagonal elements without the replica method.\nLemma 1. Suppose that Assumption 1 holds. For a constant A \u2265 0, each off-diagonal element (\u039et )m\u0303,m\u0303\u2032 (m\u0303 6= m\u0303\u2032 )\nof (16) satisfies\nlim sup M 3/4 |(\u039et )m\u0303,m\u0303\u2032 | = A in probability,\n\n(60)\n\nM\u2192\u221e\n\nwhere the limit denotes the large-system limit.\nProof: We use the fact that the covariance matrices \u039et and I \u2212 \u039et for ~h1 \u2212 \u01251 and \u01251 are positive definite. Let\n{\u03bbm\u0303 > 0 : m\u0303 = 1, . . . , M } denote the eigenvalues of \u039et . The positive definiteness of I \u2212 \u039et implies 1 \u2212 \u03bbm\u0303 > 0\n\nfor all m\u0303, or, 0 < \u03bbm\u0303 < 1 for all m\u0303. This observation implies that I M \u2212 \u039ekt is also positive definite for any k \u2208 N,\nor\nlim sup\nM\u2192\u221e\n\n1\nTr(\u039ekt ) < 1\nM\n\n(61)\n\nin the large-system limit. Note that Assumption 1 implies that the left-hand side (LHS) of (61) tends to the expected\none M \u22121 Tr(E[\u039ekt ]).\nIn order to prove Lemma 1, we evaluate Tr(E[\u039e4t ]). Let \u03c1t denote the elements of E[\u039et ] in the strictly upper\ntriangular part. A direct calculation implies that the the leading term of Tr(E[\u039e4t ]) is given by |\u03c1t |2 M 4 (2|\u03c1t |2 \u2212\nR[\u03c12t ])/3 as M \u2192 \u221e. Applying this result and R[\u03c12t ] \u2264 |\u03c1t |2 to (61), we have\nlim sup M 3 |\u03c1t |4 < 3,\n\n(62)\n\nM\u2192\u221e\n\nwhich implies that Lemma 1 holds.\nLemma 1 implies (\u039et )m\u0303,m\u0303\u2032 = O(M \u22123/4 ) in the large-system limit. We believe that it is possible to prove\n(\u039et )m\u0303,m\u0303\u2032 = O(M \u22121 ) by calculating Tr(E[\u039ekt ]) and taking k \u2192 \u221e after the large-system limit. However, Lemma 1\nis sufficient for deriving Proposition 1.\nC. Analysis of Detector\nWe focus on substage m within stage t and analyze the equivalent channel (20) in the large-system limit. It is\nshown that the equivalent channel reduces to a MIMO channel with perfect CSI at the receiver in the large-system\n(c)\n\nlimit. Let \u039et\n\n\u2208 C(M\u2212m+1)\u00d7(M\u2212m+1) denote the posterior covariance matrix of (h1,m , . . . , h1,M )T \u2208 CM\u2212m+1\n\ngiven \u0128t , i.e., the bottom-right block of the error covariance matrix (16),\n\uf8eb\n\uf8f6\n\u2217\n\u2217\n\uf8f8.\n\u039et = \uf8ed\n(c)\n\u2217 \u039et\n\nThe equivalent MIMO channel with perfect CSI at the receiver is defined as\nq\n(c)\n\u22121/2\nz=\u03b1\nI \u2212 \u039et x[m,M],t + w,\nOctober 25, 2018\n\n(63)\n\n(64)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\nwith w \u223c CN (0, \u03c3 2 I M\u2212m+1 ). In (64), the matrix\nq\nHq\n(c)\n(c)\nI \u2212 \u039et\nI \u2212 \u039et .\n\n28\n\nq\n(c)\n(c)\n(c)\nI \u2212 \u039et denotes a squared root of I \u2212 \u039et , i.e., I \u2212 \u039et =\n\nThe equivalent channel between xm,t and the associated decoder for the MIMO channel (64) with perfect CSI\n\nat the receiver is given by\n(c)\n\np(x\u0303m,t |xm,t , \u039et , \u03b8 [m,M],t )\nZ\n(c)\n(c)\n= p(xm,t = x\u0303m,t |z, \u039et , \u03b8[m,M],t )p(z|\u039et , x[m,M],t )p(x(m,M],t |\u03b8(m,M],t )dx(m,M],t dz,\n(c)\n\n(65)\n\n(c)\n\nwhere p(xm,t |z, \u039et , \u03b8[m,M],t ) represents the pdf of xm,t conditioned on z, \u039et , and \u03b8 [m,M],t .\nProposition 6. Suppose that Assumption 2 and the RS assumption hold. Then, the equivalent channel (20) converges\nin law to the equivalent channel (65) for the MIMO channel (64) with perfect CSI at the receiver in the large-system\nlimit. In evaluating (65), the variance \u03c3 2 of w is given as the solution to the fixed-point equation,\nP\nTr(\u039et ) + V (\u03c3 2 ),\nM\u2192\u221e M\n\n\u03c3 2 = N0 + lim\n\n(66)\n\nwith\ni\n1 h\n(c)\n(c)\nE (x[m,M],t \u2212 hx[m,M],t i)H (I \u2212 \u039et )(x[m,M],t \u2212 hx[m,M],t i) \u039et , \u03b8[m,M],t ,\nM\u2192\u221e M\n\nV (\u03c3 2 ) = lim\n\n(67)\n\n(c)\n\nwhere hx[m,M],t i denotes the mean of x[m,M],t with respect to the posterior pdf p(x[m,M],t |z, \u039et , \u03b8[m,M],t ). If\n\nthere are multiple solutions, one should choose the solution \u03c3 2 minimizing the following quantity\n\u0014\n\u0015\n1\n1\nlog2 e\n2\nlim\nD2 (N0 k\u03c3 ) + lim\nI(x[m,M],t ; z) +\nTr(\u039et ) ,\nM\u2192\u221e M\nM\u2192\u221e \u03c3 2 M\n\u03b1\n\n(68)\n\nwhere I(x[m,M],t ; z) denotes the mutual information between x[m,M],t and z given realizations of \u039et and \u03b8 [m,M],t .\nProof: See Appendix C.\nWe have implicitly assumed that the equivalent channel (65) and the last two terms in (66) converge as M \u2192 \u221e.\nThis assumption is justified below by using Proposition 5 and Lemma 1.\nProposition 6 implies that the mutual information I(xm,t ; x\u0303m,t |\u0128t , x[1,m),t , \u03b8[m,M],t ) tends to the constrained\n(c)\n\ncapacity I(xm,t ; x\u0303m,t |\u039et , \u03b8[m,M],t ) of the MIMO channel (64) with perfect CSI at the receiver in the large(c)\n\nsystem limit. In order to complete the derivation of Proposition 1, we show that I(xm,t ; x\u0303m,t |\u039et , \u03b8[m,M],t ) tends\nto the integrand in (43). A proof of this statement is given in Appendix D. One may expect that if the convergence\nof each off-diagonalqelement of the error covariance matrix (16) to zero is fast enough, the off-diagonal elements of\nthe channel matrix\n\n(c)\n\nI \u2212 \u039et\n\nfor the MIMO channel (64) with perfect CSI at the receiver are negligible. Thus, the\n\nMIMO channel (64) with perfect CSI at the receiver is decoupled into the bank of the AWGN channels (40). The\n(c)\n\nproof presented in Appendix D implies that the convergence speed shown in Lemma 1, i.e., (\u039et )m\u0303,m\u0303\u2032 = O(M \u22123/4 )\nfor m\u0303 6= m\u0303\u2032 , is fast enough. In order to explain this argument intuitively, we apply the matched filter (MF)\nq\nH\n(c)\nr = \u03b1\u22121/2 I \u2212 \u039et z for the received vector z of the MIMO channel (64) with perfect CSI at the receiver,\nr=\n\nOctober 25, 2018\n\n\u03be t,m\nxm,t +\n\u03b1\n\nM\nX\n\nm\u2032 =m+1\n\n\u03bet,m\u2032\nxm\u2032 ,t + \u03b7,\n\u03b1\n\n(69)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n29\n\n(c)\n\n(c)\n\nwith \u03b7 \u223c CN (0, \u03c3 2 (I \u2212\u039et )/\u03b1). In (69), the vector \u03be t,m\u2032 denotes the (m\u2032 \u2212m+1)th column vector of I \u2212\u039et for\nm\u2032 = m, . . . , M . Note that the MF output vector (69) contains sufficient information for the estimation of x[m,M],t .\n\nThe magnitude of the inter-stream interference, given by the second term of the RHS in (69), would be proportional\nto the magnitude of each interfering signal multiplied by M \u2212 m if a constructive superposition of all interfering\nsignals occurred. However, it does not occur due to the independence of data symbols with high probability. On\naverage, the magnitude of the inter-stream interference is proportional to the magnitude of each interfering signal\n\u221a\nmultiplied by M \u2212 m. Since the magnitude of each interfering signal is O(M \u22123/4 ), the magnitude of inter-stream\n\ninterference is O(M \u22121/4 ). Thus, the inter-stream interference is negligible in the large-system limit.\n\nWe have so far presented the derivation of Proposition 1. Finally, we discuss the performance degradation caused\n~ 1 of H\nby using the LMMSE channel estimator. Let us consider the estimation problem for the first row vector h\nbased on the first row vector of the received matrix Y \\t , instead of \u1ef8 \\t . It is worth noticing the similarity between\nthis problem and the detection problem of xm,t in stage t. This similarity allows us to analyze the performance of\nthe optimal channel estimator (9) in the large-system limit.\nProposition 7. Suppose that the error covariance matrix for the optimal channel estimator (9) is self-averaging\nin the large-system limit. Under the RS assumption, then, each diagonal element of the error covariance matrix\nconverges in probability to the same value as that for the LMMSE channel estimator, defined in Proposition 5, in\nthe large-system limit.\nThe derivation of Proposition 7 is omitted since it is straightforwardly derived by combining the methods for\nderiving Propositions 5 and 6. Proposition 7 allows us to expect that the gap between the achievable rate of the\noptimal SD receiver and its lower bound (43) may be quite small in the large-system limit, although we cannot\nimmediately conclude that the lower bound (43) is tight in the large-system limit.\nA PPENDIX B\nD ERIVATION\n\nOF\n\nP ROPOSITION 5\n\nA. Formulation\nPM\nIt is sufficient from Assumption 1 to show that the averaged quantities \u03be \u0304t2 = M \u22121 m\u0303=1 E[(\u039et )m\u0303,m\u0303 ] and\nPM\n\u03c1\u0304t = (M \u2212 1)\u22121 m\u0303=2 E[(\u039et )1,m\u0303 ] converge to \u03be 2 (\u03c4 ) and zero, respectively, in the large-system limit, in which\n\nM , Tc , Ttr , and t tend to infinity while \u03b2 = M/Tc , \u03c40 = Ttr /Tc , and \u03c4 = t/Tc are kept constant.\n\nFor notational convenience, hereinafter, we drop the subscript 1 in (59) from all variables. For example, ~y \\t,1\n~ (a) = (h(a) , . . . , h(a) ) \u2208 C1\u00d7M denote replicas of h\n~ for a \u2208 N:\nand ~h1 are written as ~y \\t and ~\nh, respectively. Let h\n1\nM\n(a)\n\n~\n{h\n\n~ Furthermore, we write h\n~ as h\n~ (0) = (h(0) , . . . , h(0) ).\n: a \u2208 N} are i.i.d. random vectors drawn from p(h).\n1\nM\n\nThe replica analysis is based on the following lemma.\nLemma 2. Let us define a function Zn (\u03c9; f ) as\n\"Z\n#\n\u001b\n\u001aZ\n\u001bn\u22122 Y\n2 \u001a\n(a)\n(a)\n(a)\nM\u03c9f\n~ =h\n~ , X\u0304 \\t )p(h\n~ )dh\n~\n~ h\n~\n~ X\u0304 \\t )p(h)d\nZn (\u03c9; f ) = E\nd~y \\t , (70)\np(~y \\t |h\ne\np(~y \\t |h,\na=0\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n30\n\n~ (a) : a = 0, 1, 2}. In (70), p(~y |h,\n~ X\u0304 \\t ) represents the virtual MIMO channel (59).\nwith a complex function f of {h\n\\t\nFor n \u2265 0 and \u03c9 \u2208 R,\n\n1 \u2202\nln Zn (\u03c9; f1 ),\n(71)\nM \u2202\u03c9\n1 \u2202\n\u03c1\u0304t = lim lim\nln Zn (\u03c9; f2 ),\n(72)\nn\u2192+0 \u03c9\u21920 M \u2202\u03c9\nP\nPM\n\u22121\nwhere the functions f1 and f2 are given by f1 = M \u22121 M\nm\u0303=1 fm\u0303,m\u0303 and f2 = (M \u2212 1)\nm\u0303=2 f1,m\u0303 , respectively,\n\u03be\u0304t2 = lim lim\n\nn\u2192+0 \u03c9\u21920\n\nwith\n\n(1)\n\n(0)\n\n(0)\n\n(2)\n\nfm\u0303,m\u0303\u2032 = (hm\u0303 \u2212 hm\u0303 )(hm\u0303\u2032 \u2212 hm\u0303\u2032 )\u2217 .\n\n(73)\n\nProof: We only present the proof of (71) since the proof of (72) is the same as that of (71). Let \u0125t \u2208 C1\u00d7M\n\n~ with respect to p(h|\n~ \u0128t ). Then, we\ndenote the first row vector of the LMMSE estimate (15), i.e., the mean of h\nhave\n\u03be \u0304t2\n\n1\n=\nE\nM\n\n\"Z\n\n~ (2) H\n\n~ \u2212h\n(h\n\n(1)\n\n~ \u2212h\n~\n) (h\n\n\u001b#\n2 \u001a\nY\n(a)\n(a)\n~ =h\n~ |\u0128t )dh\n~\n,\np(h\n)\n\n(74)\n\na=1\n\n~ given \u0128t . The\nwhere we have used the fact that the error covariance matrix (16) is the posterior covariance of h\nintroduction of a non-negative real number n gives\n\"Z\n#\n\u001b\n\u001aZ\n\u001bn\u22122 Y\n2 \u001a\n(a)\n(a)\n(a)\n2\n \u0304\n~\n~\n~\n~\n~\n~\n~\n\u03bet = lim E\nd~y \\t .\np(~y \\t |h = h , X\u0304 \\t )p(h )dh\nf1\np(~y \\t |h, X\u0304 \\t )p(h)dh\nn\u2192+0\n\n(75)\n\na=0\n\nIt is straightforward to confirm that (71) is equivalent to (75), since Zn (\u03c9; f1 ) = 1 as n, \u03c9 \u2192 0.\n\nIt is difficult to evaluate (70) for a real number n. The main trick of the replica method is that n is regarded as\na non-negative integer in evaluating (70). For n = 2, 3, . . ., we have a simple expression of (70),\n#\n\"\nZ Y\nn\n(a)\nM\u03c9f\n~ = ~h , X\u0304 \\t )d~y\nZn (\u03c9; f ) = E e\np(~y \\t |h\n\\t .\n\n(76)\n\na=0\n\nIn order to use Lemma 2, we have to take the operations with respect to \u03c9 before the large-system limit. However,\n\nwe need to take the operations after the large-system limit, since it is possible to get an analytical formula of\n(76) only in the large-system limit, as shown in the next section. We circumvent this dilemma by assuming the\ncommutativity of the large-system limit and the operations.\nAssumption 4. For a non-negative integer n,\nlim lim\n\nM\u2192\u221e \u03c9\u21920\n\n1\n1 \u2202\n\u2202\nln Zn (\u03c9; f ) = lim\nlim\nln Zn (\u03c9; f ),\n\u03c9\u21920 \u2202\u03c9 M\u2192\u221e M\nM \u2202\u03c9\n\n(77)\n\nwhere limM\u2192\u221e denotes the large-system limit.\nAn analytical formula of (76) obtained in the large-system limit is not generally defined for n \u2265 0. In order to\npredict the correct asymptotic formula of (70) in a neighborhood of n = 0, we will assume a symmetric statistics\nwith respect to replica indices, called the RS assumption. Assuming that the order of the large-system limit and\nthe operations with respect to n and \u03c9 in (71) and (72) is commutative, we obtain analytical expressions of (71)\nand (72) in the large-system limit. It is a challenging open problem to prove whether these assumptions are valid\nor whether the obtained result is correct.\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n31\n\nB. Average over Non-Replicated Variables\nIn this section, we evaluate the expectations in (76) with respect to the non-replicated variables \u0398(Ttr ,t) and X\u0304 \\t =\n(X TTtr , X (Ttr ,t) , \u0398(t,Tc ] ). The matrix X\u0304 \\t consists of three kinds of random vectors: {xt\u2032 } for t\u2032 = 1, . . . , Ttr are\n\nthe pilot symbol vectors, {xt\u2032 } for t\u2032 = Ttr + 1, . . . , t \u2212 1 are the data symbol vectors decoded in the preceding\nstages, and {\u03b8t\u2032 } for t\u2032 = t + 1, . . . , Tc are the bias vectors for the data symbol vectors unknown in the current\n~ (a) : a = 0, 1, . . .}\nstage. Since the elements of ~y \\t , given by (59), are mutually independent conditioned on H = {h\nand X\u0304 \\t , (76) yields\n(\nZn (\u03c9; f ) = E e\n\nM\u03c9f\n\n)\nTc\nh\niTtr h\nit\u2212Ttr \u22121 Y\nh\ni\n(a)\n(a)\n(a)\n2\nen (vp , N0 , H)\nen (vd , N0 , H)\nen (vc , N0 + P \u2212 \u03c3t\u2032 , H) , (78)\nt\u2032 =t+1\n\nwith\nen (v (a) , \u03c3 2 , H) = E\n\n\"Z\n\nn\nY\n\na=0\n\n#\n\ng(y; v (a) , \u03c3 2 )dy H ,\n\n(79)\n\nwhere g(y; v (a) , \u03c3 2 ) denotes the pdf of a proper complex Gaussian random variable y \u2208 C with mean v (a) and\nPM\n(a)\n(a)\n(a)\nvariance \u03c3 2 . In (78), \u03c3t2\u2032 is given by \u03c3t2\u2032 = M \u22121 m\u0303=1 |\u03b8m\u0303,t\u2032 |2 . Furthermore, vp \u2208 C, vd \u2208 C, and vc \u2208 C\nare given by\n\nM\n1 X (a)\nvp(a) = \u221a\nhm\u0303 xm\u0303,1 ,\nM m\u0303=1\n\n(80)\n\nM\n1 X (a)\n(a)\nhm\u0303 xm\u0303,t\u22121 ,\nvd = \u221a\nM m\u0303=1\n\n(81)\n\nvc(a)\nrespectively.\n\nM\n1 X (a)\nhm\u0303 \u03b8m\u0303,Tc ,\n= \u221a\nM m\u0303=1\n\n(82)\n\n(a)\n\nWe first evaluate en (vp , N0 , H) in the large-system limit, following [28], [31]. Calculating the Gaussian\nintegration with respect to y, we obtain\nen (vp(a) , N0 , H) =\n(0)\n\ni\nh\n\u22121 H\nE e\u2212N0 vp Avp H\n(\u03c0N0 )n (1 + n)\n\n,\n\n(83)\n\n\uf8f6\n\n(84)\n\n(n)\n\nwith v p = (vp , . . . , vp )T and\n\uf8eb\nn\n1\n\uf8ed\nA=\n(1 + n) \u22121n\n\n\u22121T\nn\n\n(1 + n)I n \u2212 1n 1T\nn\n\n\uf8f8.\n\nIn M \u2192 \u221e, due to the central limit theorem, v p conditioned on H converges in distribution to a CSCG random\nvector with the covariance matrix P Q, given by\nQ=\n(0)\n\n(n)\n\nM\n1 X\nhm\u0303 hH\nm\u0303 ,\nM m\u0303=1\n\n(85)\n\nwith hm\u0303 = (hm\u0303 , . . . , hm\u0303 )T . Thus,\n\u0013\u001b\n\u001a \u0012\nP\nQ\n+ O(M \u22121 ),\nen (vp(a) , N0 , H) = exp G\nN0\nOctober 25, 2018\n\n(86)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n32\n\nin the large-system limit, in which the function G(Q) is given by\nG(Q) = \u2212 ln det(I n+1 + AQ) \u2212 n ln(\u03c0N0 ) \u2212 ln(1 + n).\n\n(87)\n\n(a)\n\nWe next calculate en (vc , N0 + P \u2212 \u03c3t2\u2032 , H). Expanding it with respect to the difference \u03c3t2\u2032 \u2212 \u03c3\u03b82 , we have\nen (vc(a) , N0 + P \u2212 \u03c3t2\u2032 , H) = en (vc(a) , N0 + P \u2212 \u03c3\u03b82 , H) + O(M \u22121/2 ),\n\n(88)\n\n\u221a\nin the large-system limit, since the standard deviation of \u03c3t2\u2032 \u2212 \u03c3\u03b82 is O(1/ M ). In the same manner as in the\nderivation of (86), we have\n\u001a \u0012\nen (vc(a) , N0 + P \u2212 \u03c3t2\u2032 , H) = exp G\n(a)\n\n\u0013\u001b\n\u03c3\u03b82\nQ\n+ O(M \u22121/2 ).\nN0 + P \u2212 \u03c3\u03b82\n(0)\n\n(89)\n(n)\n\nThe quantity en (vd , N0 , H) is different from the other two quantities since v d = (vd , . . . , vd )T has the\n(0)\n\n(n)\n\nnonzero mean v \u03b8 = (v\u03b8 , . . . , v\u03b8 )T , with\n\n(a)\n\nv\u03b8\n\nM\n1 X (a)\nhm\u0303 \u03b8m\u0303,t\u22121 .\n= \u221a\nM m\u0303=1\n\n(90)\n\nThe difference v d \u2212 v \u03b8 conditioned on H and \u03b8 t\u22121 converges in distribution to a CSCG random vector with the\nPM\nH\n1\n2\ncovariance matrix Qd = P Q \u2212 M\nm\u0303=1 |\u03b8m\u0303,t\u22121 | hm\u0303 hm\u0303 in the large-system limit. We first take the expectation\nwith respect to xt\u22121 to obtain\n\nwith\n\nh\ni\n\u22121\n\u22121\nH\n(a)\nen (vd , N0 , H) = E eG(N0 Qd ) e\u2212v\u03b8 B(Qd ,N0 A)v\u03b8 H + O(M \u22121 ),\n\n(91)\n\nB(Q, A) = Q\u22121 \u2212 Q\u22121 (A + Q\u22121 )\u22121 Q\u22121 .\n\n(92)\n\n\u221a\nIn order to eliminate the dependence of \u03b8 m\u22121 on Qd , we use kQd \u2212 (P \u2212 \u03c3\u03b82 )Qk = O(1/ M ) in the large-system\n\nlimit. Expanding the exponent in (91) around Qd = (P \u2212 \u03c3\u03b82 )Q, we obtain\n\u0013\u001b \u0014\n\u001a\n\u0012\n\u0013 \u001b \u0015\n\u001a \u0012\nP \u2212 \u03c3\u03b82\nP \u2212 \u03c3\u03b82\n(a)\n\u22121 H\nQ\nE exp \u2212N0 v \u03b8 B\nQ, A v \u03b8 H + O(M \u22121/2 ), (93)\nen (vd , N0 , H) = exp G\nN0\nN0\nwhere we have used the identity B(Q, N0\u22121 A) = N0\u22121 B(N0\u22121 Q, A). Applying the central limit theorem with\n\nrespect to v \u03b8 to (93), after some calculation, we arrive at\n\u0013\u001b\n\u001a \u0012\nP\n(a)\nQ\n+ O(M \u22121/2 ).\nen (vd , N0 , H) = exp G\nN0\n\n(94)\n\nIt is interesting to compare (86) for the pilot symbols and (94) for the data symbols decoded in the preceding\nstages. These expressions imply that random biases do not contribute to the performance of channel estimation in\nthe leading order.\nWe substitute (86), (89), and (94) into (78) to obtain\no\nn\n\u221a\n1\n1\nln Zn (\u03c9; f ) =\nln E eM [\u03c9f +G\u0303(Q)] + O(1/ M ),\nM\nM\n\n(95)\n\nin the large-system limit, with\n\n\u03c4\nG\u0303(Q) = G\n\u03b2\nOctober 25, 2018\n\n\u0012\n\n\u0013\n\u0012\n\u0013\n1\u2212\u03c4\nP\n\u03c3\u03b82\nQ +\nG\nQ .\nN0\n\u03b2\nN0 + P \u2212 \u03c3\u03b82\n\n(96)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n33\n\nDifferentiating (95) with respect to \u03c9 and using Assumption 4, we have\ni\nh\nE fm1 ,m2 eM G\u0303(Q)\n1 \u2202\ni\nh\nlim lim\n,\nln Zn (\u03c9; f ) = lim\nM\u2192\u221e \u03c9\u21920 M \u2202\u03c9\nM\u2192\u221e\nE eM G\u0303(Q)\n\n(97)\n\nwith fm1 ,m2 = f1,1 for f = f1 and fm1 ,m2 = f1,2 for f = f2 . Expression (97) implies that the problem of\nevaluating (71) and (72) reduces to that of evaluating (97) for f = fm1 ,m2 .\nC. Average over Replicated Variables\nIn this section, we take the expectation in (97) with respect to the replicated variables H, following [57]. For\nnotational convenience, we define a set M = {m1 , m2 } of integers. We first evaluate the conditional pdf \u03bc(Q) of\nQ given HM = {hm\u0303 : m\u0303 \u2208 M}.\nM\n1 X\nhm\u0303 hH\n\u03bc(Q) = E \u03b4 Q \u2212\nm\u0303\nM\n\n\"\n\nm\u0303=1\n\n!\n\n#\n\nHM .\n\n(98)\n\nIt might be possible to obtain the analytical expression of the pdf (98) since Q is a Wishart matrix. However, we\nderive an asymptotic expression in the large-system limit by using the inversion formula for the moment generating\nfunction F (Q\u0303) of Q given by\ni\nh\nF (Q\u0303) = E eMTr(QQ\u0303) HM ,\n\nwhere a positive definite (n + 1) \u00d7 (n + 1) Hermitian matrix Q\u0303 is given by\n\uf8eb\n\uf8f6\n1\n1\nq\u03030,0\n***\n2 q\u03030,1\n2 q\u03030,n\n\uf8ec\n\uf8f7\n..\n..\n\uf8ec1 \u2217 ..\n\uf8f7\n.\n\uf8ec 2 q\u03030,1 .\n\uf8f7\n.\n\uf8f7.\nQ\u0303 = \uf8ec\n\uf8ec\n\uf8f7\n..\n..\n..\n1\n\uf8ec\n\uf8f7\n.\n.\n.\n\uf8ed\n2 q\u0303n\u22121,n \uf8f8\n1 \u2217\n2 q\u03030,n\n\n***\n\n1 \u2217\n2 q\u0303n\u22121,n\n\n(99)\n\n(100)\n\nq\u0303n,n\n\nThe inversion formula for moment generating functions implies\n\u0012\n\u0013(n+1)2 Z\nM\n\u03bc(Q) =\ne\u2212MTr(QQ\u0303) F (Q\u0303)dQ\u0303,\n(101)\n2\u03c0j\nQ\nQ\nwith dQ\u0303 = na=0 dq\u0303a,a a<a\u2032 {dR[q\u0303a,a\u2032 ]dI[q\u0303a,a\u2032 ]}. In (101), the integrations with respect to dq\u0303a,a , dR[q\u0303a,a\u2032 ], and\n\ndI[q\u0303a,a\u2032 ] are taken along the imaginary axes from \u2212j\u221e to j\u221e, respectively. Since {hm\u0303 } are i.i.d. for all m\u0303, the\nQ\nmoment generating function (99) reduces to {F1 (Q\u0303)}M\u2212|M| m\u0303\u2208M exp(hH\nm\u0303 Q\u0303hm\u0303 ), given by\ni\nh H\n(102)\nF1 (Q\u0303) = E eh1 Q\u0303h1 .\nSubstituting this expression into (101) gives\n\u0012\n\u0013(n+1)2 Y\nZ\nH\nM\n\u03bc(Q) =\nehm\u0303 Q\u0303hm\u0303 e\u2212MI(Q,Q\u0303) dQ\u0303,\n2\u03c0j\n\n(103)\n\nm\u0303\u2208M\n\nwith\n\u0013\n\u0012\n|M|\nln F1 (Q\u0303).\nI(Q, Q\u0303) = Tr(QQ\u0303) \u2212 1 \u2212\nM\n\nOctober 25, 2018\n\n(104)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n34\n\nIn order to obtain an analytical expression of (103), we use the saddle-point method. Let us define q\u0303 \u2208 R(n+1)\n\n2\n\nT T\nT\n2(n\u2212a)+1\nas q\u0303 = (q\u0303 T\n. Expanding\n0 , . . . , q\u0303 n ) , given by q\u0303 a = (q\u0303a,a , R[q\u0303a,a+1 ], I[q\u0303a,a+1 ], . . . , R[q\u0303a,n ], I[q\u0303a,n ]) \u2208 R\n\n(104) with respect to Q\u0303 around the saddle-point\nQ\u0303s = argsup lim I(Q, Q\u0303),\nQ\u0303\u2208M+\nn+1\n\nM\u2192\u221e\n\n(105)\n\nwith M+\nn+1 denoting the space of positive definite (n + 1) \u00d7 (n + 1) Hermitian matrices, we have\n\u221a !(n+1)2\n\u001bh\n\u001a\nZ\nY\n\u221a i\nM\n1 T 2\nhH\nQ\u0303s hm\u0303 \u2212MI(Q,Q\u0303s )\nm\u0303\n\u03bc(Q) =\ne\ne\nq\u0303 \u2207q\u0303 I(Q, Q\u0303s )q\u0303 1 + O(1/ M ) dq\u0303,\nexp\n2\u03c0\n2\nR(n+1)2\nm\u0303\u2208M\n(106)\nwhere \u22072q\u0303 I(Q, Q\u0303s ) denotes the Hesse matrix of I(Q, Q\u0303) with respect to q\u0303. In the derivation of (106), we have\n\u221a\n\u2032\n\u2032\ntransformed the variable Q\u0303 into Q\u0303 = M (Q\u0303 \u2212 Q\u0303s )/j and then rewritten Q\u0303 as Q\u0303. The Hesse matrix \u22072q\u0303 I(Q, Q\u0303s )\nis negative definite since the cumulant generating function ln F1 (Q\u0303) is convex. Thus, we can perform the Gaussian\nintegration in (106) to obtain\nr !(n+1)2\nh\nY\n\u221a i\nH\nM\n| det{\u22072q\u0303 I(Q, Q\u0303s )}|\u22121\n\u03bc(Q) =\nehm\u0303 Q\u0303s hm\u0303 e\u2212MI(Q,Q\u0303s ) 1 + O(1/ M ) .\n2\u03c0\n\n(107)\n\nm\u0303\u2208M\n\nWe next calculate the numerator in (97) by using the pdf (107). Substituting (107) into the quantity E[fm1 ,m2 eM G\u0303(Q) ]\nand then using the saddle-point method, we have\n#\n\"\nh\ni\nh\nY\n\u221a i\nM G\u0303(Q)\nhH\nQ\u0303s hm\u0303\n\u2212M\u03a6(Qs )\nm\u0303\nE fm1 ,m2 e\ne\n= Cn (Q, Qs )e\nE fm1 ,m2\n1 + O(1/ M ) ,\n\n(108)\n\nm\u0303\u2208M\n\nwith \u03a6(Q) = I(Q, Q\u0303s ) \u2212 G\u0303(Q) and Cn (Q, Qs ) = | det{\u22072q\u0303 I(Q, Q\u0303s )}|\u22121 det{\u22072 \u03a6(Qs )}\u22121 . In (108), Qs denotes\nthe saddle-point\nQs = arginf\n\nQ\u2208M+\nn+1\n\nlim \u03a6(Q).\n\nM\u2192\u221e\n\n(109)\n\nFurthermore, \u22072 \u03a6(Qs ) represents the Hesse matrix of \u03a6(Q) at the saddle-point Q = Qs , and is assumed to be\npositive definite.\nSimilarly, we can obtain an analytical expression of the denominator in (97). Substituting the obtained expression\nand (108) into (97), we arrive at\n\"\n#\nY ehHm\u0303 Q\u0303s hm\u0303\n1 \u2202\nlim lim\nln Zn (\u03c9; f ) = E fm1 ,m2\n,\nhH\nM\u2192\u221e \u03c9\u21920 M \u2202\u03c9\nm\u0303 Q\u0303s hm\u0303 ]\nm\u0303\u2208M E[e\n\n(110)\n\nwith fm1 ,m2 = f1,1 for f = f1 and fm1 ,m2 = f1,2 for f = f2 .\n\nThe calculations of the stationarity conditions for (105) and (109) implies that (Qs , Q\u0303s ) is given as the solution\nto the coupled fixed-point equations\n\n\u03c4P\nQ\u0303 = \u2212\n\u03b2N0\nOctober 25, 2018\n\ni\nh\nhH\n1 Q\u0303h1\nE h1 hH\n1e\ni ,\nh\nQ=\nH\nE eh1 Q\u0303h1\n\n\u0012\n\u0012\n\u0013\u22121\n\u0013\u22121\n\u03c3\u03b82\nP\n(1 \u2212 \u03c4 )\u03c3\u03b82\nI n+1 +\nI n+1 +\nAQ\nAQ\nA\u2212\nA.\nN0\n\u03b2(N0 + P \u2212 \u03c3\u03b82 )\nN0 + P \u2212 \u03c3\u03b82\n\n(111)\n\n(112)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n35\n\nD. Replica Symmetry\nThe expression (110) is defined only for n \u2208 N, since (n + 1) is the dimension of Q and Q\u0303. In order to obtain\na formula of (110) defined for n \u2208 R, we assume RS for the solution to the coupled fixed-point equations (111)\nand (112).\nAssumption 5. The solution (Qs , Q\u0303s ) is invariant under all permutations of replica indices:\n\uf8eb\n\uf8f6\na\nb1T\nn\n\uf8f8,\nQs = \uf8ed\nb\u2217 1n (d \u2212 c)I n + c1n 1T\nn\n\uf8f6\n\uf8eb\nT\n\u00e3\nb\u03031n\n\uf8f8.\nQ\u0303s = \uf8ed\n\u2217\n \u0303\nb\u0303 1n (d \u2212 c\u0303)I n + c\u03031n 1T\nn\n(0)\n\n(113)\n\n(114)\n\n(0)\n\n2\nWe first evaluate the fixed-point equation (112). Let us define (\u03c3tr )2 , \u03c3tr\n, (\u03c3c )2 , and \u03c3c2 as\n(0)\n\n(\u03c3tr )2 = N0 + P (a \u2212 b \u2212 b\u2217 + c),\n2\n\u03c3tr\n= N0 + P (d \u2212 c),\n\n(\u03c3c(0) )2 = N0 + P \u2212 \u03c3\u03b82 + \u03c3\u03b82 (a \u2212 b \u2212 b\u2217 + c),\n\u03c3c2 = N0 + P \u2212 \u03c3\u03b82 + \u03c3\u03b82 (d \u2212 c),\n\n(115)\n\nrespectively. After some calculation for (112), we obtain\n\u00e3 = \u2212\n\nn\nn\n\u03c4P\n(1 \u2212 \u03c4 )\u03c3\u03b82\n,\n\u2212\n(0)\n2 + n(\u03c3 (0) )2\n2\n\u03b2 \u03c3tr\n\u03b2\n\u03c3c + n(\u03c3c )2\ntr\n\nb\u0303 =\n\n1\n1\n(1 \u2212 \u03c4 )\u03c3\u03b82\n\u03c4P\n+\n,\n(0)\n(0)\n2 + n(\u03c3\n2\n2\n\u03b2 \u03c3tr\n\u03b2\n\u03c3c + n(\u03c3c )2\ntr )\n\nc\u0303 =\n\n\u03c4P\n(\u03c3tr )2\n(\u03c3c )2\n(1 \u2212 \u03c4 )\u03c3\u03b82\n,\n+\n(0)\n2 + n(\u03c3 (0) )2 )\u03c3 2\n\u03b2 (\u03c3tr\n\u03b2\n(\u03c3c2 + n(\u03c3c )2 )\u03c3c2\ntr\ntr\n\n(0)\n\n(0)\n\n(1 \u2212 \u03c4 )\u03c3\u03b82\n\u03c4P\n\u2212\n.\nd \u0303 = c\u0303 \u2212\n2\n\u03b2\u03c3tr\n\u03b2\u03c3c2\n\n(116)\nH\n\nWe next evaluate the fixed-point equation (111) by calculating ehm\u0303 Q\u0303hm\u0303 with (116).\n\uf8f1\n\uf8f9\n\uf8ee\n\uf8ee\n2\nn\nn\nn\n(a) 2\n(a)\n(a)\n\uf8f2\n2\nX\nX\nH\n|hm\u0303 | \uf8fb (1 \u2212 \u03c4 )\u03c3\u03b8 \uf8f0 2 X hm\u0303\n\u03c4P \uf8f0 2\nhm\u0303\n\u2212\n+\nehm\u0303 Q\u0303hm\u0303 = exp\n\u03c3\u0303tr\n\u03c3\u0303\nc\n(a) 2\n(a) 2\n(a) 2\n\uf8f3 \u03b2\n\u03b2\na=0 (\u03c3tr )\na=0 (\u03c3tr )\na=0 (\u03c3c )\n\nwith\n\n2\n\u03c3\u0303tr\n\n=\n\n(a)\n\n\u22122\n(n\u03c3tr\n\n2\n(\u03c3tr )2 = \u03c3tr\n, and\n\n(0)\n+ (\u03c3tr )\u22122 )\u22121 and\n(a)\n(\u03c3c )2 = \u03c3c2 for a\n\n\u03c3\u0303c2\n\n=\n\n(n\u03c3c\u22122\n\n+\n\n(0)\n(\u03c3c )\u22122 )\u22121 .\n\nIn (117),\n\n(a)\n(\u03c3tr )2 ,\n\n2\n\nand\n\n\uf8f9\uf8fc\nn\n(a) 2 \uf8fd\nX\n|hm\u0303 | \uf8fb\n\u2212\n,\n(a)\n(\u03c3c )2 \uf8fe\na=0\n\n(117)\n\n(a)\n(\u03c3c )2\n\nare given by\n\n= 1, . . . , n. In order to linearize the two quadratic forms in (117), we use\n\nthe identity\ne\n\n\u03c3\u03032 |a|2\n\n=\n\nZ\n\nC\n\nOctober 25, 2018\n\n1 \u2212 |y|22 +a\u2217 y+ay\u2217\ne \u03c3\u0303\ndy,\n\u03c0\u03c3\u0303 2\n\n(118)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n36\n\np\nPn\n(a)\n(a)\n2\n) or (a, \u03c3\u0303 2 ) =\nfor y = y tr \u2208 C or y = y c \u2208 C. Substituting (118) with (a, \u03c3\u0303 2 ) = ( \u03c4 P/\u03b2 a=0 hm\u0303 /(\u03c3tr )2 , \u03c3\u0303tr\np\nP\n(a)\n(a)\nn\n( (1 \u2212 \u03c4 )\u03c3\u03b82 /\u03b2 a=0 hm\u0303 /(\u03c3c )2 , \u03c3\u0303c2 ) into (117), we have\nZ Y\nn\n(a)\nhH\nQ\u0303hm\u0303\nm\u0303\n(119)\n= Dn\ne\nq(y|hm\u0303 )dy,\na=0\n\n(0)\n\n(0)\n\n(a)\n\n2 2 n\n2\nwith Dn = (\u03c0 2 \u03c3tr\n\u03c3c ) (1+n(\u03c3tr )2 /\u03c3tr\n)(1+n(\u03c3c )2 /\u03c3c2 ). In (119), the function q(y|hm\u0303 ) for y = (y tr , y c )T \u2208 C2\n\nis defined as\n(a)\nq(y|hm\u0303 )\n\n= q y tr\n\ns\n\n\u03c4 P (a) (a)\nh ;\u03c3\n\u03b2 m\u0303 tr\n\n! \uf8eb\n\nq \uf8edy c\n\nwith\n\ns\n\n\uf8f6\n(1 \u2212 \u03c4 )\u03c3\u03b82 (a) (a) \uf8f8\nhm\u0303 ; \u03c3c\n,\n\u03b2\n\n(120)\n\n2\n1 \u2212 |y\u2212h|\ne \u03c32 .\n2\n\u03c0\u03c3\n\nq(y|h; \u03c3) =\n\n(121)\n\nApplying the expression (119) to (111), we arrive at\n\u0014\nh\nn\nion \u0015\n2\nR (0)\n(0)\n(1)\n(1)\ndy\nE\nh1 \u2212 hh1 i q(y|h1 ) Eh(1) q(y|h1 )\n1\n\u2217\nh\nhR\nn\nion i\n,\na\u2212b\u2212b +c=\n(0)\n(1)\nE q(y|h1 ) Eh(1) q(y|h1 )\ndy\n1\n\u0014 \u001c\n\u001d\nn\nh\nion \u0015\n2\nR\n(0)\n(1)\n(1)\n(1)\ndy\nh1 \u2212 hh1 i\nE\nq(y|h1 ) Eh(1) q(y|h1 )\n1\nhR\nn\nion i\nh\n,\nd\u2212c=\n(0)\n(1)\ndy\nE q(y|h1 ) Eh(1) q(y|h1 )\n\n(122)\n\n(123)\n\n1\n\nwith\n\nh\n\ni\n(1)\n(1)\nEh(1) h1 q(y|h1 )\n(1)\n1\ni .\nh\nhh1 i =\n(1)\nEh(1) q(y|h1 )\n\n(124)\n\n1\n\nE. Replica Continuity\nEquations (115), (122), and (123) provide the coupled fixed-point equations of (a \u2212 b \u2212 b\u2217 + c, d \u2212 c) under the\nRS assumption, and are well defined for n \u2208 R. We regard n as a real number and take the limit n \u2192 +0 to obtain\n\u0014\n\u0015\n2\n(0) 2\n(0)\n(1)\n(\u03c3tr ) = N0 + P E h1 \u2212 hh1 i ,\n(125)\n2\n\u03c3tr\n= N0 + P E\n\n(\u03c3c(0) )2\n\u03c3c2\n\n= N0 + P \u2212\n\n= N0 + P \u2212\n\n\u0014\n\n\u03c3\u03b82\n\n\u03c3\u03b82\n\n+\n\n(1)\n\n(1)\n\nh1 \u2212 hh1 i\n\n+\n\n\u03c3\u03b82 E\n\n\u03c3\u03b82 E\n\n\u0014\n\n\u0014\n\n(0)\nh1\n\n(1)\nh1\n\n\u2212\n\n2\n\n\u2212\n\n\u0015\n\n,\n\n(126)\n\n(1)\nhh1 i\n\n(1)\nhh1 i\n(0)\n\n2\n\n2\n\n\u0015\n\n\u0015\n\n,\n\n(127)\n\n,\n\n(128)\n(1)\n\n(1)\n\nwhere the expectations for y are taken with respect to the measure p(y|h1 )dy. Note that E[|h1 \u2212 hh1 i|2 ] and\n(1)\n\n(1)\n\n(0)\n\n(0)\n\n2\nE[|h1 \u2212 hh1 i|2 ] depend on (\u03c3tr )2 , \u03c3tr\n, (\u03c3c )2 , and \u03c3c2 . Furthermore, the quantity (110) is given by\n\uf8f1\n\uf8f2 E[|h(0) \u2212 hh(1) i|2 ] for f = f\n1 \u2202\n1\n1\n1\nln Zn (\u03c9; f ) =\nlim lim\nM\u2192\u221e \u03c9\u21920 M \u2202\u03c9\n\uf8f3\n0\nfor f = f2 .\n\n(129)\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n37\n\nUnder the assumption of the commutativity between the large-system limit and the limit n \u2192 +0, the substitution\nof (129) into (71) or (72) gives\nlim \u03be\u0304t2 = E\n\nM\u2192\u221e\n\n\u0014\n\n(0)\n\n(1)\n\nh1 \u2212 hh1 i\n\n2\n\n\u0015\n\n,\n\n(130)\n\nlim \u03c1\u0304t = 0,\n\n(131)\n\nM\u2192\u221e\n\nin the large-system limit. Note that we have implicitly assumed that the RHSs of (130) and (131), obtained by the\nreplica method, coincide with the correct ones.\nIn order to complete the derivation of Proposition 5, we show that (130) reduces to (37), defined by the fixed-point\n(a)\n\n(0)\n\n(1)\n\n(1)\n\n(1)\n\nequations (44) and (45). Since h1 \u223c CN (0, 1), the quantities E[|h1 \u2212 hh1 i|2 ] and E[|h1 \u2212 hh1 i|2 ] reduce to\n!\n\u0014\n\u0015\n(0)\n(0)\n2\n(\u03c3c )2 (1 \u2212 \u03c4 )\u03c3\u03b82\n(\u03c3tr )2 \u03c4 P\n(0)\n(1)\n4\n,\n(132)\n+\nE h1 \u2212 hh1 i\n=\u03be 1+\n4\u03b2\n\u03c3tr\n\u03c3c4 \u03b2\n\u0015\n\u0014\n2\n(1)\n(1)\n= \u03be2,\n(133)\nE h1 \u2212 hh1 i\nwith\n\n\u0012\n\u0013\u22121\n\u03c4P\n(1 \u2212 \u03c4 )\u03c3\u03b82\n\u03be = 1+ 2 +\n.\n\u03c3tr \u03b2\n\u03c3c2 \u03b2\n2\n\n(134)\n\n2\nEquations (126), (128), and (133) provide a closed form for (\u03c3tr\n, \u03c3c2 ). Furthermore, (125), (127), and (132) for a\n(0)\n\n(0)\n\n2\ngiven solution (\u03c3tr\n, \u03c3c2 ) form two independent linear equations with respect to (\u03c3tr )2 and (\u03c3c )2 , and have the\n(0)\n\n(0)\n\n2\n, \u03c3c2 ). These observations indicate that the averaged MSE (130) is given as\nunique solution ((\u03c3tr )2 , (\u03c3c )2 ) = (\u03c3tr\n\n(37), defined by the fixed-point equations (44) and (45).\nA PPENDIX C\nD ERIVATION\n\nOF\n\nP ROPOSITION 6\n\nA. Formulation\nLet E\u1ef8 \\t ,x[1,m),t [* * * ] denote the expectation with respect to \u1ef8 \\t and x[1,m),t given x\u0303m,t , xm,t , X\u0304 \\t and \u03b8t .\nIt is sufficient from Assumption 2 to show that E\u1ef8 \\t ,x[1,m),t [p(x\u0303m,t |xm,t , \u0128t , x[1,m),t , \u03b8[m,M],t )], given by (20),\nconverges in law to the equivalent channel (65) in the large-system limit. Substituting the posterior pdf (17) into\n(20) and then introducing a non-negative number n, we have\ni\nh\nE\u1ef8 \\t ,x[1,m),t p(x\u0303m,t |xm,t , \u0128t , x[1,m),t , \u03b8[m,M],t ) = lim Zn(d) ,\n\n(135)\n\nn\u2192+0\n\nwith\n\nZn(d)\n\n= E\u1ef8 \\t ,x[1,m),t\n\n\"Z \u001aZ\n\np(y t |x\u0303t , \u0128t )p(x\u0303[m,M],t |\u03b8 [m,M],t )dx\u0303[m,M],t\n\n\u001bn\u22121\n\np(y t |x\u0303t , \u0128t )\n\ni\n\u00d7p(x\u0303[m,M],t |\u03b8[m,M],t )dx\u0303(m,M],t p(y t |xt , \u0128t )p(x(m,M],t |\u03b8 (m,M],t )dx(m,M],t dy t ,\n\n(136)\n\nwhere we have introduced x\u0303t = ((x[1,m),t )T , (x\u0303[m,M],t )T )T , in which x\u0303[m,M],t = (x\u0303m,t , . . . , x\u0303M,t )T has the same\nstatistical properties as x[m,M],t . Furthermore, x\u0303(m,M],t is given by x\u0303(m,M],t = (x\u0303m+1,t , . . . , x\u0303M,t )T . Note that\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n38\n\n(136) is a quantity of O(1), while (70) is exponential in M . Thus, we have to evaluate (136) up to O(1) in the\nlarge-system limit.\nLet us regard n in (136) as a positive integer. For n = 2, 3, . . ., (136) reduces to a special expression,\n\"Z n\nn n\no\nY\nY\n(a)\n(a)\n(a)\n(d)\np(x[m,M],t |\u03b8[m,M],t )dx[m,M],t\np(y t |xt , \u0128t )\nZn = E\u1ef8 \\t ,x[1,m),t\na=0\n\na=2\n\n(1)\n(1)\n(0)\n(0)\n\u00d7p(x(m,M],t |\u03b8(m,M],t )dx(m,M],t p(x[m,M],t |\u03b8[m,M],t )dx(m,M],t dy t\n\n(a)\n\nIn (137), xt\n(a)\n\n(a)\n\ni\n\n.\n\n(137)\n(a)\n\n= ((x[1,m),t )T , (x[m,M],t )T )T \u2208 CM denotes replicas of x\u0303t for a = 2, . . . , n, in which {x[m,M],t =\n\n(a)\n\n(xm,t , . . . , xM,t )T } conditioned on \u03b8 [m,M],t are independent random vectors drawn from p(x[m,M],t |\u03b8[m,M],t ). For\n(a)\n\n(a)\n\n(a)\n\nnotational convenience, we have written x[m,M],t and x\u0303[m,M],t as x[m,M],t = (xm,t , . . . , xM,t )T for a = 0 and\n(a)\n\n(a)\n\n(a)\n\n(a)\n\na = 1, respectively. The vector x(m,M],t is defined as x(m,M],t = (xm+1,t , . . . , xM,t )T . Furthermore, we have\n(a)\n\nwritten xt and x\u0303t as xt\n\n(a)\n\n= ((x[1,m),t )T , (x[m,M],t )T )T for a = 0 and a = 1, respectively.\n\nB. Average over Non-Replicated Variables\nThe goal of this section is to evaluate the expectation in (137) with respect to the non-replicated variables \u1ef8 \\t .\nWe first calculate the integration in (137) with respect to y t . The substitution of (18) into (137) gives\n\"Z n\nn n\no\noY\nYn\n(a)\n(a)\n(a)\n(d)\np(x[m,M],t |\u03b8 [m,M],t )dx[m,M],t\np(y t |H (a) , xt )p(H (a) |\u0128t )dH (a)\nZn = E\u1ef8 \\t ,x[1,m),t\na=2\n\na=0\n\n(1)\n(1)\n(0)\n(0)\n\u00d7p(x(m,M],t |\u03b8 (m,M],t )dx(m,M],t p(x[m,M],t |\u03b8[m,M],t )dx(m,M],t dy t\n\ni\n\n,\n\n(138)\n\n~ (a) )T , . . . , (h\n~ (a) )T )T \u2208 CN \u00d7M denotes replicas of H for a = 0, . . . , n: {H (a) } conditioned on\nwhere H (a) = ((h\n1\nN\n\u0128t are mutually independent random matrices drawn from p(H|\u0128t ). This expression is useful since the covariance\n(a)\n\n(a)\n\n(a)\n\nmatrix of y t for p(y t |H (a) , xt ) does not depend on xt , while the covariance matrix of y t for p(y t |xt , \u0128t )\n\n(a)\n(a)\n~ (a)\ndepends on xt . Using the fact that the row vectors {h\nare mutually independent, we obtain\nn\u2032 } of H\n( N\n\"Z n \u001a\n)\n\u001b #\nY\nY\n1 \u2212 N1 |y\u2212vn(a)\u2032 ,m,t |2\n(1) (1)\n(1)\n(0)\n(d)\nZn = p(xm,t |\u03b8m,t )E\nE{h\n(139)\ndy xm,t , xm,t , X\u0304 \\t , \u03b8t ,\ne 0\n~ (a)\n}\n\u03c0N0\nn\u2032\n\u2032\na=0\nn =1\n\nwith\n\n(a)\nvn\u2032 ,m,t\n(a)\n\n(a)\n\n1\n= \u221a\nM\n\n\" m\u22121\nX\n\nm\u2032 =1\n\n(a)\n\u2206hn\u2032 ,m\u2032 ,t xm\u2032 ,t\n\n+\n\nM\nX\n\nm\u2032 =m\n\n(a)\n(a)\nhn\u2032 ,m\u2032 xm\u2032 ,t\n\n#\n\n,\n\n(140)\n(a)\n\nwhere hn\u2032 ,m\u2032 and \u2206hn\u2032 ,m\u2032 ,t denote the (n\u2032 , m\u2032 )th element of H (a) and the LMMSE estimation error \u2206hn\u2032 ,m\u2032 ,t =\n(a)\n\nhn\u2032 ,m\u2032 \u2212 \u0125n\u2032 ,m\u2032 ,t , respectively, with \u0125n\u2032 ,m\u2032 ,t denoting the (n\u2032 , m\u2032 )th element of the LMMSE estimate (15). In\n\n~ (a)\n~ (a)\n(139), the expectation E{h\n[* * * ] is taken with respect to the measure p(h\nn\u2032 |\u0128t )dhn\u2032 . In the derivation of (139),\n~ (a)\nn\u2032 }\nPm\u22121\nwe have eliminated the bias b = M \u22121/2 m\u2032 =1 \u0125n\u2032 ,m\u2032 ,t xm\u2032 ,t known to the receiver by transforming (y t )n\u2032 into\ny = (y t )n\u2032 \u2212 b. Performing the Gaussian integration with respect to y, we have\n\uf8f9\n\uf8ee\ni\nh\n\u2212N0\u22121 v H\nAv n\u2032 ,m,t\nn\u2032 ,m,t\nN E (a)\ne\nY\n~ \u2032 }\n{h\n\uf8fa\n\uf8ef\n(1)\n(0)\n(1)\n(1)\nn\nxm,t , xm,t , X\u0304 \\t , \u03b8t \uf8fb ,\nZn(d) = p(xm,t |\u03b8m,t )E \uf8f0\nn (1 + n)\n(\u03c0N\n)\n0\n\u2032\n\n(141)\n\nOctober 25, 2018\n\nDRAFT\n\nn =1\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n39\n\n(n)\n\n(0)\n\nwith v n\u2032 ,m,t = (vn\u2032 ,m,t , . . . , vn\u2032 ,m,t )T . In (141), the matrix A is given by (84).\n(a)\n~ (a)\nWe next calculate the expectation in (141) with respect to {h\nn\u2032 }. Since {hn\u2032 ,m\u2032 } conditioned on \u0128t are proper\n(a)\n\ncomplex Gaussian random vectors4, the random vector v n\u2032 ,m,t conditioned on Xt = {xt\n\n: for all a} and \u0128t is\n\nalso a proper complex Gaussian random variable with mean\nM\n1 X\nun\u2032 ,m,t = \u221a\n\u0125n\u2032 ,m\u2032 ,t xm\u2032 ,t ,\nM m\u2032 =m\n(0)\n\n(0)\n\n(n)\n\n(142)\n(n)\n\nand with the covariance matrix D = M \u22121 diag{(xt )H \u039et xt , . . . , (xt )T \u039et xt }, in which xm\u2032 ,t \u2208 Cn+1 is\n(0)\n\n(n)\n\ngiven by xm\u2032 ,t = (xm\u2032 ,t , . . . , xm\u2032 ,t )T . In the same manner as in the derivation of (91), we take the expectation\nwith respect to v n\u2032 ,m,t conditioned on Xt and \u0128t to obtain\n\" N\n#\nY G(N \u22121 D)\u2212uH\n\u22121\n(1)\n(1)\n(1)\n(0)\nB(D,N\nA)u\n\u2032\n(d)\n\u2032\nn\n,m,t\n0\n0\nn ,m,t\nZn = p(xm,t |\u03b8m,t )E\ne\nxm,t , xm,t , X\u0304 \\t , \u03b8t ,\n\n(143)\n\nn\u2032 =1\n\nwhere G(Q) and B(D, N0\u22121 A) are given by (87) and (92), respectively.\n\nFinally, we evaluate the expectation in (143) with respect to \u1ef8 \\t . Expression (15) implies that the LMMSE\nestimates {(\u0125n\u2032 ,m,t , . . . , \u0125n\u2032 ,M,t ) : for all n\u2032 } conditioned on X\u0304 \\t are mutually independent CSCG random vectors\n(c)\n\nwith the covariance matrix I \u2212 \u039et . Thus, the vectors {un\u2032 ,m,t } conditioned on X\u0304 \\t and Xt are also mutually\n(a\u2032 )\n\nindependent CSCG random vectors with covariance E[(un\u2032 ,m,t )a (un\u2032 ,m,t )\u2217a\u2032 |X\u0304 \\t , Xt ] = M \u22121 (x[m,M],t )H (I \u2212\n(c)\n\n(a)\n\n\u039et )x[m,M],t for all n\u2032 . Taking the expectation with respect to \u1ef8 \\t , after some calculation, we have\nh\ni\n\u22121\n(1) (1)\n(1)\n(0)\nZn(d) = p(xm,t |\u03b8m,t )E eN G(N0 Qd ) xm,t , xm,t , \u039et , \u03b8 t ,\n\n(144)\n\nwhere the (n + 1) \u00d7 (n + 1) Hermitian matrix Qd is given by\n(a)\n\n(a)\n\n(Qd )a,a\u2032 = M \u22121 \u03b4a,a\u2032 (xt )H \u039et xt\n\n(a\u2032 )\n\n(c)\n\n(a)\n\n+ M \u22121 (x[m,M],t )H (I \u2212 \u039et )x[m,M],t .\n\n(145)\n\nC. Average over Replicated Variables\nIn order to evaluate the conditional expectation in (144) with respect to the replicated variables Qd , we evaluate\n(1)\n(0)\nthe pdf of Qd conditioned on xm,t , xm,t , \u039et , and \u03b8 t . Let us define the function I \u0303d (Qd , Q\u0303d ) as\n\nI \u0303d (Qd , Q\u0303d ) = Tr(Qd Q\u0303d ) \u2212 lim\n\nM\u2192\u221e\n\n1\nln F\u0303d (Q\u0303d ),\nM\n\n(146)\n\nwith\ni\nh\nF\u0303d (Q\u0303d ) = E eMTr(Qd Q\u0303d ) \u039et , \u03b8t ,\n\n(147)\n\nwhere a positive definite (n + 1) \u00d7 (n + 1) Hermitian matrix Q\u0303d is defined in the same manner as in (100). In (146),\n(s)\n\nwe have implicitly assumed that the limit in the RHS of (146) exists. Furthermore, we define the saddle-point Q\u0303d\nas\n(s)\nQ\u0303d = argsup I \u0303d (Qd , Q\u0303d ).\n\n(148)\n\nQ\u0303d \u2208M+\nn+1\n\n4\n\nWe could not immediately conclude the Gaussianity of v n\u2032 ,m,t if the optimal channel estimator (9) were used.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n40\n\n(1)\n\n(0)\n\nWe represent the pdf \u03bc(Qd ) of Qd conditioned on xm,t , xm,t , \u039et , and \u03b8t by using the inversion formula for the\nmoment generating function of Qd , given by\ni\nh\n(1)\n(0)\nFd (Q\u0303d ) = E eMTr(Qd Q\u0303d ) xm,t , xm,t , \u039et , \u03b8t .\n\n(149)\n\nUsing the saddle-point method in the same manner as in the derivation of (107) gives\n\u0012 \u0013(n+1)2\n(s)\n\u22121\n(s)\nM\n| det{\u22072Q\u0303 Id (Qd , Q\u0303d )}|\u22121 e\u2212MId (Qd ,Q\u0303d )+O(M ) [1 + O(M \u22121/2 )],\n\u03bc(Qd ) =\nd\n2\u03c0\n\n(150)\n\nin the large-system limit. In (150), the function Id (Qd , Q\u0303d ) is given by\nId (Qd , Q\u0303d ) = Tr(Qd Q\u0303d ) \u2212\n\n1\nln Fd (Q\u0303d ).\nM\n\n(151)\n\nFurthermore, \u22072Q\u0303 Id (Q, Q\u0303d ) denotes the Hesse matrix of (151) with respect to Q\u0303d .\nd\n\nThe factor O(M \u22121 ) in the exponent in (150) is due to a small deviation of the saddle-point (148). The removal\n\nor addition of one transmit antenna results in a small change of M Tr(Qd Q\u0303d ), more precisely, in a change of O(1).\nThis observation implies that Id (Qd , Q\u0303d ) = I \u0303d (Qd , Q\u0303d ) + O(M \u22121 ) in the large-system limit. Differentiating both\n(s)\n\nsides with respect to Q\u0303d at the saddle-point (148), we find that the gradient \u2207Q\u0303d Id (Qd , Q\u0303d ) of (151) with respect\n\nto Q\u0303d at the saddle-point is O(M \u22121 ), which explains the factor O(M \u22121 ) in the exponent in (150) since a deviation\n(s)\n\nof the saddle-point results in a deviation of the exponent which is proportional to M k\u2207Q\u0303d Id (Qd , Q\u0303d )k2 .\nWe repeat the same argument to evaluate (144). Applying (150) to (144) and using the saddle-point method, we\narrive at\n(1)\n\n(s)\n\n(1)\n\n(s)\n\n(s)\n\nZn(d) = p(xm,t |\u03b8m,t )Cn(d) (Qd , Q\u0303d )e\u2212M\u03a6d (Qd ) [1 + O(M \u22121/2 )].\n\n(152)\n\nIn (152), the function \u03a6d (Qd ) is defined as\n(s)\n\n\u03a6d (Qd ) = Id (Qd , Q\u0303d ) \u2212 \u03b1\u22121 G(N0\u22121 Qd ).\n\n(153)\n\n(s)\n\nThe saddle-point Qd is given by\n(s)\n\nQd = arginf \u03a6\u0303d (Qd ),\n\n(154)\n\nQd \u2208M+\nn+1\n\nwith\n(s)\n\n\u03a6\u0303d (Qd ) = I \u0303d (Qd , Q\u0303d ) \u2212 \u03b1\u22121 G(N0\u22121 Qd ).\n\n(155)\n\n(d)\n\nFurthermore, Cn (Qd , Q\u0303d ) is defined as\nCn(d) (Qd , Q\u0303d ) = | det{\u22072Q\u0303 Id (Qd , Q\u0303d )}|\u22121 det{\u03b1\u22121 \u22072Qd G(N0\u22121 Qd )}\u22121 ,\nd\n\n(156)\n\nwhere \u22072Qd G(N0\u22121 Qd ) denotes the Hesse matrix of G(N0\u22121 Qd ) with respect to Qd . Note that we have assumed\n(s)\n\nthe positive definiteness of the Hesse matrix \u22072Qd G(N0\u22121 Qd ) at the saddle-point Qd = Qd .\n(s)\n\n(s)\n\nThe calculation of the stationarity conditions for (148) and (154) implies that (Qd , Q\u0303d ) is given as the solution\nto the coupled fixed-point equations\nh\ni\nE Qd eMTr(Qd Q\u0303d ) \u039et , \u03b8t\ni ,\nh\nQd = lim\nM\u2192\u221e\nE eMTr(Qd Q\u0303d ) \u039et , \u03b8 t\nOctober 25, 2018\n\n(157)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n\u03b1\u22121\nQ\u0303d = \u2212\nN0\n\n41\n\n\u0013\u22121\n\u0012\nA\nA.\nI n+1 +\nQ\nN0 d\n\n(158)\n\nD. Evaluation of Fixed-Point Equations\nIn order to evaluate the coupled fixed-point equations (157) and (158), we assume RS. The assumption of RS is\nconsistent with Assumption 2, i.e., the assumption of the self-averaging property for the equivalent channel (20) [52].\n(s)\n\n(s)\n\nAssumption 6. The solution (Qd , Q\u0303d ) is invariant under all permutations of replica indices:\n\uf8eb\n\uf8f6\nad\nb d 1T\nn\n(s)\n\uf8f8,\nQd = \uf8ed\nb\u2217d 1n (dd \u2212 cd )I n + cd 1n 1T\nn\n\uf8f6\n\uf8eb\nT\nb\u0303\n1\n\u00e3\n(s)\nd n\nd\n\uf8f8.\nQ\u0303d = \uf8ed\n\u2217\n \u0303\nb\u0303d 1n (dd \u2212 c\u0303d )I n + c\u0303d 1n 1T\nn\n\n(159)\n\n(160)\n\nWe first evaluate the fixed-point equation (158). Let us define \u03c302 and \u03c3 2 as\n\u03c302 = N0 + (ad \u2212 bd \u2212 b\u2217d + cd ),\n\n(161)\n\n\u03c3 2 = N0 + (dd \u2212 cd ),\n\n(162)\n\nrespectively. After some calculation, we obtain\n\u22121\n\u03b1\u22121\n\u03b1\u22121 \u03c302\n\u03b1\u22121 n\n \u0303d = c\u0303d \u2212 \u03b1 .\n,\nd\n,\nb\u0303\n=\n,\nc\u0303\n=\n(163)\nd\nd\n\u03c3 2 + n\u03c302\n\u03c3 2 + n\u03c302\n(\u03c3 2 + n\u03c302 )\u03c3 2\n\u03c32\nq\n(s) (s)\n(c)\n(c)\nWe next calculate the quantity exp{M Tr(Qd Q\u0303d )}. Let I \u2212 \u039et denote a square root of I \u2212 \u039et , i.e.,\nq\nq\nH\n(c)\n(c)\n(c)\nI \u2212 \u039et = I \u2212 \u039et\nI \u2212 \u039et . Substituting (163) into that quantity gives\n\uf8f1\nq\nq\n2\n\uf8f4\n(c) (a)\n2\nn\nn k I \u2212 \u039e(c) x(a)\n\uf8f2\nX\nX\nI\n\u2212\n\u039e\nx\n(s) (s)\nt\nt\n[m,M],t\n[m,M],t k\n2\nMTr(Qd Q\u0303d )\n\u221a 2\n= exp \u03c3\u03030\ne\n\u2212\n\uf8f4\n\u03b1\u03c3a\n\u03b1\u03c3a2\n\uf8f3\na=0\na=0\n)\nn\nX\n(0) H\n(0)\n(a)\n(a)\n,\n(164)\n+\u00e3d (x ) \u039et x + d \u0303d\n(x )H \u039et x\n\n\u00e3d = \u2212\n\nt\n\nt\n\nt\n\nt\n\na=1\n\nwith \u03c3\u030302 = (n\u03c3 \u22122 + \u03c30\u22122 )\u22121 and \u03c3a2 = \u03c3 2 for a = 1, . . . , n. In order to linearize the quadratic form in (164), we\nuse the identity\ne\n\n\u03c3\u030302 kak2\n\n=\n\nZ\n\nCM \u2212m+1\n\nwith a =\n\n1\n(\u03c0\u03c3\u030302 )M\u2212m+1\n\n2\n\ne\n\nH\nH\n\u2212 kzk\n2 +a z+z a\n\u03c3\u03030\n\ndz,\n\nq\n\u221a\n(c) (a)\nI \u2212 \u039et x[m,M],t /( \u03b1\u03c3a2 ) to obtain\na=0\nZ Y\nn n\no\n(s) (s)\n(a)\nq\u0303a (z|xt , \u039et ) dz,\neMTr(Qd Q\u0303d ) = Dn(d)\n\n(165)\n\nPn\n\n(166)\n\na=0\n\n(d)\n\n(0)\n\n(a)\n\nwith Dn = (\u03c0\u03c3 2 )n(M\u2212m+1) (1 + n\u03c302 /\u03c3 2 )M\u2212m+1 . In (166), the functions q\u03030 (z|xt , \u039et ) and q\u0303a (z|xt , \u039et ) for\na = 1, . . . , n are given by\n(0)\n\n(0)\n\n(c)\n\n(0) H\n\nq\u03030 (z|xt , \u039et ) = q0 (z|x[m,M],t , \u039et )e\u00e3d (xt\nOctober 25, 2018\n\n(0)\n\n) \u039et x t\n\n,\n\n(167)\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n(a)\n\n42\n(a) H\n\n(c)\n\n(a)\n\nq\u0303a (z|xt , \u039et ) = qa (z|x[m,M],t , \u039et )ed\u0303d (xt\n(a)\n\n(a)\n\n) \u039et x t\n\n,\n\n(168)\n\n(c)\n\nrespectively, where qa (z|x[m,M],t , \u039et ) represents the pdf of a proper complex Gaussian random vector z \u2208\nq\n\u221a\n(c) (a)\nCM\u2212m+1 with mean I \u2212 \u039et x[m,M],t / \u03b1 and covariance \u03c3a2 I, i.e.,\n\uf8fc\n\uf8f1\nq\n\u221a 2\uf8f4\n\uf8f4\n(c) (a)\n\uf8fd\n\uf8f2\n/\n\u2212\nI\n\u2212\n\u039e\nx\n\u03b1k\nkz\n1\nt\n[m,M],t\n(c)\n(a)\nqa (z|x[m,M],t , \u039et ) =\n.\n(169)\nexp\n\u2212\n\uf8f4\n\uf8f4\n(\u03c0\u03c3a2 )M\u2212m+1\n\u03c3a2\n\uf8fe\n\uf8f3\nFinally, we evaluate the fixed-point equation (157). Substitution of (166) into (157) gives expressions of ad \u2212\n\nbd \u2212 b\u2217d + cd and dd \u2212 cd well-defined for n \u2208 R. Taking n \u2192 +0, we have\n\u001aZ\n1\n(c)\n(0)\n\u2217\nlim (ad \u2212 bd \u2212 bd + cd )= lim\nE\nq0 (z|x[m,M],t , \u039et )\nn\u2192+0\nM\u2192\u221e M\nq\n(0) H\n(0)\n(1)\n(c)\n(0)\n\u00d7 (xt ) \u039et xt +\nI \u2212 \u039et (x[m,M],t \u2212 hx[m,M],t i)\n1\nE\nlim (dd \u2212 cd ) = lim\nn\u2192+0\nM\u2192\u221e M\n*\n\u00d7\n\n\u001aZ\n\ndz \u039et , \u03b8t\n\n)\n\n, (170)\n\n(c)\n\n(0)\n\nwith\n=\n\n!\n\nq0 (z|x[m,M],t , \u039et )\n\n(1)\n(1)\n(xt )H \u039et xt\n\n(1)\nhxt i\n\n2\n\nR\n\nq\n(1)\n(c)\n(1)\nI \u2212 \u039et (x[m,M],t \u2212 hx[m,M],t i)\n+\n\n(1)\n\n(1)\n\n(1)\n\n2\n\n+\n\ndz \u039et , \u03b8 t\n\n)\n\n,\n\n(171)\n\n(1)\n\nxt q\u03031 (z|xt , \u039et )p(xt |\u03b8t )dxt\n.\nR\n(1)\n(1)\n(1)\nq\u03031 (z|xt , \u039et )p(xt |\u03b8t )dxt\n\n(172)\n\nSubstituting these expressions into (161) or (162), we have the coupled fixed-point equations\nio\nh\n1 n\n(1)\n(c)\n(0)\n(c)\n(1)\n(0)\n\u03c302 = N0 + lim\nP Tr(\u039et ) + E (x[m,M],t \u2212 hx[m,M],t i)H (I \u2212 \u039et )(x[m,M],t \u2212 hx[m,M],t i) \u039et , \u03b8t ,\nM\u2192\u221e M\n(173)\nn\nh\nio\n1\n(1)\n(c)\n(1)\n(c)\n(1)\n(1)\n\u03c3 2 = N0 + lim\nP Tr(\u039et ) + E (x[m,M],t \u2212 hx[m,M],t i)H (I \u2212 \u039et )(x[m,M],t \u2212 hx[m,M],t i) \u039et , \u03b8t ,\nM\u2192\u221e M\n(174)\n(c)\n\n(0)\n\nwhere the average over z is taken with respect to the measure q0 (z|x[m,M],t , \u039et )dz.\nThe coupled fixed-point equations (173) and (174) have the solution \u03c302 = \u03c3 2 . Nishimori's result [36] implies\nthat \u03c302 = \u03c3 2 is the correct solution. Assuming \u03c302 = \u03c3 2 , we have the single fixed-point equation\n\u03c3 2 = N0 + lim\n\nM\u2192\u221e\n\nP\nTr(\u039et ) + V (\u03c3 2 ),\nM\n\n(175)\n\nwith\ni\n1 h (1)\n(c)\n(1)\n(c)\n(1)\n(1)\nE (x[m,M],t \u2212 hx[m,M],t i)H (I \u2212 \u039et )(x[m,M],t \u2212 hx[m,M],t i) \u039et , \u03b8[m,M],t .\nM\u2192\u221e M\n\nV (\u03c3 2 ) = lim\n\n(176)\n\n(c)\n\n(0)\n\nIn (175), the average over z is taken with respect to the measure q0 (z|x[m,M],t , \u039et )dz with \u03c302 = \u03c3 2 . Furthermore,\n(1)\n\n(c)\n\n(1)\n\n(1)\n\n(1)\n\nhx[m,M],t i denotes the expectation of x[m,M],t with respect to the posterior measure q1 (x[m,M],t |z, \u039et )dx[m,M],t ,\ngiven by\n\n(c)\n\n(1)\n\n(1)\n(c)\nq1 (x[m,M],t |z, \u039et , \u03b8[m,M],t )\n\n= R\n\n(1)\n\n(c)\n\nq1 (z|x[m,M],t , \u039et )p(x[m,M],t |\u03b8m,t )\n(1)\n\n(c)\n\n(1)\n\n(1)\n\nq1 (z|x[m,M],t , \u039et )p(x[m,M],t |\u03b8[m,M],t )dx[m,M],t\n\n.\n\n(177)\n\nNote that the fixed-point equation (175) is equivalent to (66).\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n43\n\nE. Replica Continuity\n(s)\n\nWe evaluate (152) under the RS assumption (Assumption 6). The function G(N0\u22121 Qd ), given by (87), reduces\nto [17]\n(s)\n\nG(N0\u22121 Qd ) = \u2212(n \u2212 1) ln \u03c3 2 \u2212 ln(\u03c3 2 + n\u03c302 ) \u2212 n ln \u03c0,\n\n(178)\n\nwhich is well defined for n \u2208 R and tends to zero as n \u2192 +0.\nApplying (161), (162), and (163) to (151), we obtain\n\u0014\n\u0015\nN0\n1\nN0\nN0 \u03c302\n(s)\n(s)\nn\n(s)\n1\u2212 2\n\u2212\n\u2212 2 + 2 2\nln Fd (Q\u0303d ).\nId (Qd , Q\u0303d ) = \u2212\n2\n2\n\u03b1\n\u03c3 + n\u03c30\n\u03c3\n\u03c3 (\u03c3 + n\u03c30 )\nM\n\n(179)\n\nSubstituting (166) into the moment generating function (149), we have an expression of (179) well defined for\nn \u2208 R. Taking n \u2192 +0, under the assumption of \u03c302 = \u03c3 2 , we have\n(s)\n\n(s)\n\nlim Id (Qd , Q\u0303d )\nZ\n1\n(0)\n(c)\n(0)\n(c)\n(0)\n(1)\n=\u2212 ln q1 (xm,t |z, \u039et , \u03b8[m,M],t )q0 (z|x[m,M],t , \u039et )p(x(m,M],t |\u03b8(m,M],t )dx(m,M],t dz,\n(180)\nM\nR\n(1)\n(c)\n(1)\n(c)\n(1)\nwith the marginal q1 (xm,t |z, \u039et , \u03b8[m,M],t ) = q1 (x[m,M],t |z, \u039et , \u03b8[m,M],t )dx(m,M],t of (177). Substituting\nn\u2192+0\n\n(178) and (180) into (153) and assuming that the obtained expression is correct as n \u2192 +0, from (135), we arrive\n\nat\nh\ni\n(s)\n(s)\nE\u1ef8 \\t ,x[1,m),t p(x\u0303m,t |xm,t , \u0128t , x[1,m),t , \u03b8[m,M],t ) = lim Cn(d) (Qd , Q\u0303d )\nn\u2192+0\nZ\n(0)\n(c)\n(0)\n(c)\n(0)\n(1)\n\u00d7 q1 (xm,t |z, \u039et , \u03b8[m,M],t )q0 (z|x[m,M],t , \u039et )p(x(m,M],t |\u03b8(m,M],t )dx(m,M],t dz,\n\n(181)\n\nwhere we have assumed that the large-system limit and the limit n \u2192 +0 are commutative. Due to the normalization\n(d)\n\n(s)\n\n(s)\n\nof pdfs, the quantity Cn (Qd , Q\u0303d ) should tend to 1 as n \u2192 +0. This observation implies that the RHS of (181)\nis equal to the equivalent channel (65) between xm,t and the associated decoder for the MIMO channel (64) with\nperfect CSI at the receiver.\nF. Multiple Solutions\nThe fixed-point equation (175) may have multiple solutions. In that case, one has to choose the solution minimizing\n(s)\n\n(s)\n\nthe quantity (155). Due to limn\u2192+0 \u03a6\u0303d (Qd ) = 0, the quantity \u03a6\u0303d (Qd ) is given by \u03a6\u0303d (Qd ) = nF + O(n2 )\nas n \u2192 +0, with the so-called free energy F = limn\u2192+0\n\n(s)\n\u2202\n\u2202n \u03a6\u0303d (Qd ).\n\nThus, one should choose the solution\n\nminimizing the free energy F .\nIn order to calculate the free energy F , in the same manner as in the derivation of (179), we evaluate (146) as\n\u0014\n\u0015\n(s)\nn\nN0\n1\nN0\nN0 \u03c302\n(s)\nI \u0303d (Qd , Q\u0303d ) = \u2212\n1\u2212 2\n\u2212 lim\n\u2212\n+\nln Dn(d)\nM\u2192\u221e M\n\u03b1\n\u03c3 + n\u03c302\n\u03c32\n\u03c3 2 (\u03c3 2 + n\u03c302 )\nZ\nn\non\n1\n(0)\n(1)\n(182)\nln Ex(0) [q\u03030 (z|xt , \u039et )] Ex(1) [q\u03031 (z|xt , \u039et )] dz.\n\u2212 lim\nt\nt\nM\u2192\u221e M\n\nWe differentiate (178) and (182) with respect to n at n = 0 to obtain\n\u0014\n\u0015\n1\n1\n1\nF = lim\nDe (N0 k\u03c3 2 ) + lim\nTr(\u039e\n)\n+\nln(\u03c0eN\n)\n,\nI(x[m,M],t ; z) +\nt\n0\nM\u2192\u221e M\nM\u2192\u221e M \u03c3 2\n\u03b1\nOctober 25, 2018\n\n(183)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n44\n\nwith\nI(x[m,M],t ; z) =\n\nZ\n\n(c)\n\n(0)\n\n(0)\n\nq0 (z|x[m,M],t , \u039et )p(x[m,M],t |\u03b8 [m,M],t )\n(c)\n\n(0)\n\n\u00d7 ln R\n\nq1 (z|x[m,M],t , \u039et )\n\n(0)\n\n(1)\n(c)\n(1)\n(1)\nq1 (z|x[m,M],t , \u039et )p(x[m,M],t |\u03b8[m,M],t )dx[m,M],t\n\ndx[m,M],t dz.\n\n(184)\n\nMinimizing (183) is equivalent to minimizing (68).\nA PPENDIX D\nR EDUCTION\n\nOF\n\nP ROPOSITION 6 TO P ROPOSITION 1\n\nLet us prove that the fixed-point equation (66) coincides with the fixed-point equation (46). We first show that the\nlast term in (46) is a lower bound on the last term in (66), by considering the MIMO channel (64) with additional side\ninformation. Let a genie inform the receiver about the correct values of the data symbols x(m,M],t . The MSE (67)\nfor the genie-aided receiver should provide a lower bound on the original one. In order to eliminate the inter-stream\nPM\ninterference from the MF output vector (69), the genie-aided receiver calculates r s = r \u2212 m\u2032 =m+1 \u03bet,m\u2032 xm\u2032 ,t /\u03b1,\n\ngiven by\n\nrs =\n\n1\n\u03be xm,t + \u03b7.\n\u03b1 t,m\n\n(185)\n\nThe performance of the interference-free channel (185), such as the MSE and the constrained capacity, is determined\nby the SNR\nsnr =\n\nP k\u03bet,m k4\n\n(c)\n\n\u03b1\u03c3 2 \u03be H\nt,m (I \u2212 \u039et )\u03be t,m\n\n.\n\n(186)\n\nProposition 5 and Lemma 1 imply that the numerator and denominator in (186) are given by P k\u03bet,m k4 = P (1 \u2212\n(c)\n\n2\n2\n3\n\u22121/4\n\u03be 2 (\u03c4 ))4 + O(M \u22121/4 ) and \u03b1\u03c3 2 \u03be H\n) in the large-system limit,\nt,m (I \u2212 \u039et )\u03be t,m = \u03b1\u03c3 (1 \u2212 \u03be (\u03c4 )) + O(M\n\nrespectively. Thus, the SNR (186) converges in probability to snr = (1 \u2212 \u03be 2 (\u03c4 ))P/(\u03b1\u03c3 2 ) in the large-system limit,\n\nwhich coincides with the SNR for the AWGN channel (40) with \u03c3 2 (\u03c4, \u03bc) = \u03c3 2 . This expression implies that the\n\nlast term (67) in the fixed-point equation (66) is bounded from below by (1 \u2212 \u03bc)(1 \u2212 \u03be 2 (\u03c4 ))E[MSE(\u03c3 2 , \u03b8m,t )] in\nthe large-system limit.\nWe next prove that the last term in (46) is an upper bound on the last term in (66). Let us consider a suboptimal\nreceiver, which estimates xm,t only from the first element rm of the MF output vector (69), given by\n(c)\n\nrm =\n\n1 \u2212 (\u039et )m,m\nxm,t +\n\u03b1\n\nM\nX\n\nm\u2032 =m+1\n\n(c)\n\n(\u039et )m,m\u2032\nxm\u2032 ,t + \u03b7m ,\n\u03b1\n\n(187)\n\nwith \u03b7m denoting the first element of \u03b7. In order to evaluate an upper bound on the MSE (67) for this suboptimal\nreceiver, we replace the inter-stream interference in (187) by the AWGN with the same variance. The MSE (67)\nfor the obtained channel provides an upper bound on the original one, and is determined by the SNR\n(c)\n\nsnr =\n\nOctober 25, 2018\n\nP\n\nPM\n\nm\u2032 =m+1\n\nP (1 \u2212 (\u039et )m,m )2\n(c)\n\n(c)\n\n|(\u039et )m,m\u2032 |2 + \u03b1\u03c3 2 (1 \u2212 (\u039et )m,m )\n\n,\n\n(188)\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n45\n\nwhich converges in probability to snr = (1 \u2212 \u03be 2 (\u03c4 ))P/(\u03b1\u03c3 2 ) in the large-system limit, due to Proposition 5\nand Lemma 1. This result implies that the last term (67) in the fixed-point equation (66) is bounded from above\nby (1 \u2212 \u03bc)(1 \u2212 \u03be 2 (\u03c4 ))E[MSE(\u03c3 2 , \u03b8m,t )] in the large-system limit. Combining the two bounds, we find that the\nfixed-point equation (66) is equal to the fixed-point equation (46).\nThe argument described above implies that the inter-stream interference is negligible in the large-system limit. It\n(c)\n\nis straightforward to confirm that the mutual information I(xm,t ; x\u0303m,t |\u039et , \u03b8[m,M],t ) converges to the constrained\ncapacity of the AWGN channel (40), i.e., the integrand in (43), by repeating the same argument. Similarly, it\nis straightforward to find that (68) is equal to (47). Combining these results and the argument described in\nAppendix A-A, we find that Proposition 1 holds.\nR EFERENCES\n[1] G. J. Foschini and M. J. Gans, \"On limits of wireless communications in a fading environment when using multiple antennas,\" Wireless\nPers. Commun., vol. 6, pp. 311\u2013335, 1998.\n[2] E. Telatar, \"Capacity of multi-antenna Gaussian channels,\" Euro. Trans. Telecommun., vol. 10, no. 6, pp. 585\u2013595, Nov.\u2013Dec. 1999.\n[3] A. M. Tulino, A. Lozano, and S. Verd\u00fa, \"Impact of antenna correlation on the capacity of multiantenna channels,\" IEEE Trans. Inf. Theory,\nvol. 51, no. 7, pp. 2491\u20132509, Jul. 2005.\n[4] T. L. Marzetta and B. M. Hochwald, \"Capacity of a mobile multiple-antenna communication link in Rayleigh flat fading,\" IEEE Trans.\nInf. Theory, vol. 45, no. 1, pp. 139\u2013157, Jan. 1999.\n[5] A. Lapidoth and S. M. Moser, \"Capacity bounds via duality with applications to multiple-antenna systems on flat-fading channels,\" IEEE\nTrans. Inf. Theory, vol. 49, no. 10, pp. 2426\u20132467, Oct. 2003.\n[6] S. M. Moser, \"The fading number of multiple-input multiple-output fading channels with memory,\" IEEE Trans. Inf. Theory, vol. 55, no. 6,\npp. 2716\u20132755, Jun. 2009.\n[7] B. M. Hochwald and T. L. Marzetta, \"Unitary space-time modulation for multiple-antenna communications in rayleigh flat fading,\" IEEE\nTrans. Inf. Theory, vol. 46, no. 2, pp. 543\u2013564, Mar. 2000.\n[8] B. Hassibi and T. L. Marzetta, \"Multiple-antennas and isotropically random unitary inputs: The received signal density in closed form,\"\nIEEE Trans. Inf. Theory, vol. 48, no. 6, pp. 1473\u20131484, Jun. 2002.\n[9] A. L. Moustakas, S. H. Simon, and T. L. Marzetta, \"Capacity of differential versus nondifferential unitary space-time modulation for\nMIMO channels,\" IEEE Trans. Inf. Theory, vol. 52, no. 8, pp. 3622\u20133634, Aug. 2006.\n[10] L. Zheng and D. N. C. Tse, \"Communication on the Grassmann manifold: A geometric approach to the noncoherent multiple-antenna\nchannel,\" IEEE Trans. Inf. Theory, vol. 48, no. 2, pp. 359\u2013383, Feb. 2002.\n[11] W. Yang, G. Durisi, and E. Riegler, \"On the capacity of large-MIMO block-fading channels,\" IEEE J. Sel. Areas Commun., vol. 31, no. 2,\npp. 117\u2013132, Feb. 2013.\n[12] S. Verd\u00fa, \"Spectral efficiency in the wideband regime,\" IEEE Trans. Inf. Theory, vol. 48, no. 6, pp. 1319\u20131343, Jun. 2002.\n[13] L. Zheng, D. N. C. Tse, and M. M\u00e9dard, \"Channel coherence in the low-SNR regime,\" IEEE Trans. Inf. Theory, vol. 53, no. 3, pp.\n976\u2013997, Mar. 2007.\n[14] S. Ray, M. M\u00e9dard, and L. Zheng, \"On noncoherent MIMO channels in the wideband regime: Capacity and reliability,\" IEEE Trans. Inf.\nTheory, vol. 53, no. 6, pp. 1983\u20132009, Jun. 2007.\n[15] B. Hassibi and B. M. Hochwald, \"How much training is needed in multiple-antenna wireless link?\" IEEE Trans. Inf. Theory, vol. 49,\nno. 4, pp. 951\u2013963, Apr. 2003.\n[16] M. M\u00e9dard, \"The effect upon channel capacity in wireless communications of perfect and imperfect knowledge of the channel,\" IEEE\nTrans. Inf. Theory, vol. 46, no. 3, pp. 933\u2013946, May 2000.\n[17] K. Takeuchi, M. Vehkaper\u00e4, T. Tanaka, and R. R. M\u00fcller, \"Large-system analysis of joint channel and data estimation for MIMO DS-CDMA\nsystems,\" IEEE Trans. Inf. Theory, vol. 58, no. 3, pp. 1385\u20131412, Mar. 2012.\n\nOctober 25, 2018\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n46\n\n[18] T. Li and O. M. Collins, \"A successive decoding strategy for channels with memory,\" IEEE Trans. Inf. Theory, vol. 53, no. 2, pp. 628\u2013646,\nFeb. 2007.\n[19] K. Padmanabhan, S. Venkatraman, and O. M. Collins, \"Tight upper and lower bounds on the constrained capacity of non-coherent multiantenna channels,\" in Proc. 2008 IEEE Int. Symp. Inf. Theory, Toronto, Canada, Jul. 2008, pp. 2588\u20132592.\n[20] K. Takeuchi, R. R. M\u00fcller, M. Vehkaper\u00e4, and T. Tanaka, \"Practical signaling with vanishing pilot-energy for large noncoherent block-fading\nMIMO channels,\" in Proc. 2009 IEEE Int. Symp. Inf. Theory, Seoul, Korea, Jun. 2009, pp. 759\u2013763.\n[21] K. Takeuchi, R. R. M\u00fcller, and M. Vehkaper\u00e4, \"Bias-based training for iterative channel estimation and data decoding in fast fading\nchannels,\" IEICE Trans. Commun., vol. E94-B, no. 7, pp. 2161\u20132165, Jul. 2011.\n[22] --, \"A construction of turbo-like codes for iterative channel estimation based on probabilistic bias,\" in Proc. IEEE Global Commun.\nConf. (GLOBECOME 2011), Houston, Texas, USA, Dec. 2011.\n[23] --, \"Iterative LMMSE channel estimation and decoding based on probabilistic bias,\" submitted to IEEE Trans. Commun., 2012.\n[24] D. N. C. Tse and S. V. Hanly, \"Linear multiuser receivers: effective interference, effective bandwidth and user capacity,\" IEEE Trans. Inf.\nTheory, vol. 45, no. 2, pp. 641\u2013657, Mar. 1999.\n[25] S. Verd\u00fa and S. Shamai (Shitz), \"Spectral efficiency of CDMA with random spreading,\" IEEE Trans. Inf. Theory, vol. 45, no. 2, pp.\n622\u2013640, Mar. 1999.\n[26] J. Evans and D. N. C. Tse, \"Large system performance of linear multiuser receivers in multipath fading channels,\" IEEE Trans. Inf. Theory,\nvol. 46, no. 6, pp. 2059\u20132078, Sep. 2000.\n[27] S. Shamai (Shitz) and S. Verd\u00fa, \"The impact of frequency-flat fading on the spectral efficiency of CDMA,\" IEEE Trans. Inf. Theory,\nvol. 47, no. 4, pp. 1302\u20131327, May 2001.\n[28] T. Tanaka, \"A statistical-mechanics approach to large-system analysis of CDMA multiuser detectors,\" IEEE Trans. Inf. Theory, vol. 48,\nno. 11, pp. 2888\u20132910, Nov. 2002.\n[29] A. L. Moustakas, S. H. Simon, and A. M. Sengupta, \"MIMO capacity through correlated channels in the presence of correlated interferers\nand noise: A (not so) large N analysis,\" IEEE Trans. Inf. Theory, vol. 49, no. 10, pp. 2545\u20132561, Oct. 2003.\n[30] R. R. M\u00fcller and W. H. Gerstacker, \"On the capacity loss due to separation of detection and decoding,\" IEEE Trans. Inf. Theory, vol. 50,\nno. 8, pp. 1769\u20131778, Aug. 2004.\n[31] D. Guo and S. Verd\u00fa, \"Randomly spread CDMA: Asymptotics via statistical physics,\" IEEE Trans. Inf. Theory, vol. 51, no. 6, pp.\n1983\u20132010, Jun. 2005.\n[32] K. Takeda, S. Uda, and Y. Kabashima, \"Analysis of CDMA systems that are characterized by eigenvalue spectrum,\" Europhys. Lett.,\nvol. 76, no. 6, pp. 1193\u20131199, 2006.\n[33] C. K. Wen and K. K. Wong, \"Asymptotic analysis of spatially correlated MIMO multiple-access channels with arbitrary signaling inputs\nfor joint and separate decoding,\" IEEE Trans. Inf. Theory, vol. 53, no. 1, pp. 252\u2013268, Jan. 2007.\n[34] K. Takeuchi, T. Tanaka, and T. Yano, \"Asymptotic analysis of general multiuser detectors in MIMO DS-CDMA channels,\" IEEE J. Sel.\nAreas Commun., vol. 26, no. 3, pp. 486\u2013496, Apr. 2008.\n[35] D. Sherrington and S. Kirkpatrick, \"Solvable model of a spin-glass,\" Phys. Rev. Lett., vol. 35, no. 26, pp. 1792\u20131796, Dec. 1975.\n[36] H. Nishimori, Statistical Physics of Spin Glasses and Information Processing.\n[37] M\u00e9zard, G. Parisi, and M. A. Virasoro, Spin Glass Theory and Beyond.\n[38] K. H. Fischer and J. A. Hertz, Spin Glasses.\n\nNew York: Oxford University Press, 2001.\n\nSingapore: World Scientific, 1987.\n\nCambridge, UK: Cambridge University Press, 1991.\n\n[39] F. Guerra, \"Broken replica symmetry bounds in the mean field spin glass model,\" Commun. Math. Phys., vol. 233, pp. 1\u201312, 2003.\n[40] M. Talagrand, \"The Parisi formula,\" Annals of Mathematics, vol. 163, pp. 221\u2013263, 2006.\n[41] F. D. Neeser and J. L. Massey, \"Proper complex random processes with applications to information theory,\" IEEE Trans. Inf. Theory,\nvol. 39, no. 4, pp. 1293\u20131302, Jul. 1993.\n[42] G. D. Forney, Jr., \"Trellis shaping,\" IEEE Trans. Inf. Theory, vol. 38, no. 2, pp. 281\u2013300, Mar. 1992.\n[43] K. Takeuchi, R. R. M\u00fcller, M. Vehkaper\u00e4, and T. Tanaka, \"An achievable rate of large block-fading MIMO systems with no CSI via\nsuccessive decoding,\" in Proc. 2010 Int. Symp. Inf. Theory and its Appl & Int. Symp. Spread Spectrum Tech. and Appl., Taichung, Taiwan,\nOct. 2010, pp. 519\u2013524.\n[44] T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd ed. New Jersey: Wiley, 2006.\n[45] M. Ledoux, The Concentration of Measure Phenomenon.\n\nOctober 25, 2018\n\nProvidence, RI: American Mathmatical Society, 2001.\n\nDRAFT\n\n\fIEEE TRANSACTIONS ON INFORMATION THEORY, VOL. , NO. , 2011\n\n47\n\n[46] F. Guerra and F. L. Toninelli, \"The thermodynamic limit in mean field spin glass models,\" Commun. Math. Phys., vol. 230, pp. 71\u201379,\n2002.\n[47] --, \"The infinite volume limit in generalized mean field disordered models,\" Markov. Proc. Rel. Fields, vol. 9, pp. 195\u2013207, 2003.\n[48] L. Cottatellucci and R. R. M\u00fcller, \"A systematic approach to multistage detectors in multipath fading channels,\" IEEE Trans. Inf. Theory,\nvol. 51, no. 9, pp. 3146\u20133158, Sep. 2005.\n[49] H. Nishimori, \"Comment on \"statistical mechanics of CDMA multiuser demodulation\" by Tanaka,\" Europhys. Lett., vol. 57, no. 2, pp.\n302\u2013303, Jan. 2002.\n[50] S. Verd\u00fa, Multiuser Detection.\n\nNew York: Cambridge University Press, 1998.\n\n[51] S. B. Korada and A. Montanari, \"Applications of the Lindeberg principle in communicaitons and statistical learning,\" IEEE Trans. Inf.\nTheory, vol. 57, no. 4, pp. 2440\u20132450, Apr. 2011.\n[52] L. A. Pastur and M. V. Shcherbina, \"Absence of self-averaging of the order parameter in the Sherrington-Kirkpatrick model,\" J. Stat. Phys.,\nvol. 62, no. 1/2, pp. 1\u201319, 1991.\n[53] D. N. C. Tse and P. Viswanath, Fundamentals of Wireless Communication.\n\nCambridge, UK: Cambridge University Press, 2005.\n\n[54] M. Vehkaper\u00e4, K. Takeuchi, R. R. M\u00fcller, and T. Tanaka, \"How much training is needed for iterative multiuser detection and decoding?\"\nin Proc. IEEE Global Communications Conference (GLOBECOM 2009), Honolulu, USA, Nov. 2009.\n[55] K. Kitagawa and T. Tanaka, \"Optimization of sequences in CDMA systems: A statistical-mechanics approach,\" Computer Networks, vol. 54,\npp. 917\u2013924, 2010.\n[56] M. C. Gursoy, \"On the capacity and energy efficiency of training-based transmissions over fading channels,\" IEEE Trans. Inf. Theory,\nvol. 55, no. 10, pp. 4543\u20134567, Oct. 2009.\n[57] K. Nakamura and T. Tanaka, \"Microscopic analysis for decoupling principle of linear vector channel,\" in Proc. 2008 IEEE Int. Symp. Inf.\nTheory, Toronto, Canada, Jul. 2008, pp. 519\u2013523.\n\nOctober 25, 2018\n\nDRAFT\n\n\f"}