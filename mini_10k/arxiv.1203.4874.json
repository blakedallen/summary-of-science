{"id": "http://arxiv.org/abs/1203.4874v1", "guidislink": true, "updated": "2012-03-22T02:57:53Z", "updated_parsed": [2012, 3, 22, 2, 57, 53, 3, 82, 0], "published": "2012-03-22T02:57:53Z", "published_parsed": [2012, 3, 22, 2, 57, 53, 3, 82, 0], "title": "A Co-Prime Blur Scheme for Data Security in Video Surveillance", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.4398%2C1203.4619%2C1203.2167%2C1203.2961%2C1203.6737%2C1203.5509%2C1203.3971%2C1203.3014%2C1203.3141%2C1203.4736%2C1203.1851%2C1203.1083%2C1203.2223%2C1203.4394%2C1203.3000%2C1203.1100%2C1203.0828%2C1203.4811%2C1203.1899%2C1203.6391%2C1203.2041%2C1203.3687%2C1203.2800%2C1203.0321%2C1203.4063%2C1203.2078%2C1203.1766%2C1203.4874%2C1203.5256%2C1203.1858%2C1203.6541%2C1203.6471%2C1203.0571%2C1203.1839%2C1203.4430%2C1203.5684%2C1203.6875%2C1203.0476%2C1203.1254%2C1203.2603%2C1203.3145%2C1203.3557%2C1203.1317%2C1203.6165%2C1203.0393%2C1203.6756%2C1203.0491%2C1203.1138%2C1203.0824%2C1203.2287%2C1203.5584%2C1203.2491%2C1203.3900%2C1203.3214%2C1203.5163%2C1203.5593%2C1203.1287%2C1203.5860%2C1203.1298%2C1203.2474%2C1203.1661%2C1203.2693%2C1203.6130%2C1203.4969%2C1203.6060%2C1203.2614%2C1203.2908%2C1203.3329%2C1203.3743%2C1203.3004%2C1203.0155%2C1203.0739%2C1203.1945%2C1203.2741%2C1203.4053%2C1203.2809%2C1203.1892%2C1203.1799%2C1203.2569%2C1203.6174%2C1203.5801%2C1203.5934%2C1203.2129%2C1203.6218%2C1203.6003%2C1203.3725%2C1203.6504%2C1203.0532%2C1203.3396%2C1203.1355%2C1203.2699%2C1203.2870%2C1203.6740%2C1203.6399%2C1203.5278%2C1203.4163%2C1203.4492%2C1203.0931%2C1203.4670%2C1203.5113%2C1203.3304&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Co-Prime Blur Scheme for Data Security in Video Surveillance"}, "summary": "This paper presents a novel Coprime Blurred Pair (CBP) model for visual\ndata-hiding for security in camera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream, we introduce a spatial\nencryption scheme by blurring the image/video contents to create a CBP. Our\ngoal is to obscure detail in public video streams by blurring while allowing\nbehavior to be recognized and to quickly deblur the stream so that details are\navailable if behavior is recognized as suspicious. We create a CBP by blurring\nthe same latent image with two unknown kernels. The two kernels are coprime\nwhen mapped to bivariate polynomials in the z domain. To deblur the CBP we\nfirst use the coprime constraint to approximate the kernels and sample the\nbivariate CBP polynomials in one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose the results into a 2D\nkernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of\nthe kernel matrices to recover the coprime kernels and then the latent video\nstream. It is therefore only possible to deblur the video stream if a user has\naccess to both streams. To improve the practicability of our algorithm, we\nimplement our algorithm using a graphics processing unit (GPU) to decrypt the\nblurred video streams in real-time, and extensive experimental results\ndemonstrate that our new scheme can effectively protect sensitive identity\ninformation in surveillance videos and faithfully reconstruct the unblurred\nvideo stream when two blurred sequences are available.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.4398%2C1203.4619%2C1203.2167%2C1203.2961%2C1203.6737%2C1203.5509%2C1203.3971%2C1203.3014%2C1203.3141%2C1203.4736%2C1203.1851%2C1203.1083%2C1203.2223%2C1203.4394%2C1203.3000%2C1203.1100%2C1203.0828%2C1203.4811%2C1203.1899%2C1203.6391%2C1203.2041%2C1203.3687%2C1203.2800%2C1203.0321%2C1203.4063%2C1203.2078%2C1203.1766%2C1203.4874%2C1203.5256%2C1203.1858%2C1203.6541%2C1203.6471%2C1203.0571%2C1203.1839%2C1203.4430%2C1203.5684%2C1203.6875%2C1203.0476%2C1203.1254%2C1203.2603%2C1203.3145%2C1203.3557%2C1203.1317%2C1203.6165%2C1203.0393%2C1203.6756%2C1203.0491%2C1203.1138%2C1203.0824%2C1203.2287%2C1203.5584%2C1203.2491%2C1203.3900%2C1203.3214%2C1203.5163%2C1203.5593%2C1203.1287%2C1203.5860%2C1203.1298%2C1203.2474%2C1203.1661%2C1203.2693%2C1203.6130%2C1203.4969%2C1203.6060%2C1203.2614%2C1203.2908%2C1203.3329%2C1203.3743%2C1203.3004%2C1203.0155%2C1203.0739%2C1203.1945%2C1203.2741%2C1203.4053%2C1203.2809%2C1203.1892%2C1203.1799%2C1203.2569%2C1203.6174%2C1203.5801%2C1203.5934%2C1203.2129%2C1203.6218%2C1203.6003%2C1203.3725%2C1203.6504%2C1203.0532%2C1203.3396%2C1203.1355%2C1203.2699%2C1203.2870%2C1203.6740%2C1203.6399%2C1203.5278%2C1203.4163%2C1203.4492%2C1203.0931%2C1203.4670%2C1203.5113%2C1203.3304&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel Coprime Blurred Pair (CBP) model for visual\ndata-hiding for security in camera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream, we introduce a spatial\nencryption scheme by blurring the image/video contents to create a CBP. Our\ngoal is to obscure detail in public video streams by blurring while allowing\nbehavior to be recognized and to quickly deblur the stream so that details are\navailable if behavior is recognized as suspicious. We create a CBP by blurring\nthe same latent image with two unknown kernels. The two kernels are coprime\nwhen mapped to bivariate polynomials in the z domain. To deblur the CBP we\nfirst use the coprime constraint to approximate the kernels and sample the\nbivariate CBP polynomials in one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose the results into a 2D\nkernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of\nthe kernel matrices to recover the coprime kernels and then the latent video\nstream. It is therefore only possible to deblur the video stream if a user has\naccess to both streams. To improve the practicability of our algorithm, we\nimplement our algorithm using a graphics processing unit (GPU) to decrypt the\nblurred video streams in real-time, and extensive experimental results\ndemonstrate that our new scheme can effectively protect sensitive identity\ninformation in surveillance videos and faithfully reconstruct the unblurred\nvideo stream when two blurred sequences are available."}, "authors": ["Christopher Thorpe", "Feng Li", "Zijia Li", "Zhan Yu", "David Saunders", "Jingyi Yu"], "author_detail": {"name": "Jingyi Yu"}, "author": "Jingyi Yu", "links": [{"href": "http://arxiv.org/abs/1203.4874v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.4874v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.4874v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.4874v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Noname manuscript No.\n(will be inserted by the editor)\n\nA Co-Prime Blur Scheme for Data Security in Video\nSurveillance\n\narXiv:1203.4874v1 [cs.CV] 22 Mar 2012\n\nChristopher Thorpe * Feng Li * Zijia Li * Zhan Yu * David Saunders *\nJingyi Yu\n\nReceived: date / Accepted: date\n\nAbstract This paper presents a novel Coprime Blurred\nPair (CBP) model for visual data-hiding for security in\ncamera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream,\nwe introduce a spatial encryption scheme by blurring\nthe image/video contents to create a CBP. Our goal\nis to obscure detail in public video streams by blurring while allowing behavior to be recognized and to\nquickly deblur the stream so that details are available\nif behavior is recognized as suspicious. We create a CBP\nby blurring the same latent image with two unknown\nkernels. The two kernels are coprime when mapped to\nbivariate polynomials in the z domain. To deblur the\nCBP we first use the coprime constraint to approximate\nthe kernels and sample the bivariate CBP polynomials\nin one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose\nthe results into a 2D kernel matrix. Finally, we compute\nthe inverse Fast Fourier Transform (FFT) of the kernel\nmatrices to recover the coprime kernels and then the latent video stream. It is therefore only possible to deblur\nthe video stream if a user has access to both streams.\nTo improve the practicability of our algorithm, we implement our algorithm using a graphics processing unit\n(GPU) to decrypt the blurred video streams in realtime, and extensive experimental results demonstrate\nthat our new scheme can effectively protect sensitive\nC. Thorpe, F. Li, Z. Yu, D. Saunders, J. Yu\nUniversity of Delaware, Newark, DE 19716\nTel.: +1-302-831-4445\nFax: +1-302-831-8458\nE-mail: {thorpe, feli, zyu, saunders, yu}@cis.udel.edu\nZ. Li\nKey Laboratory of Mathematics Mechanization\nAMSS, Beijing, China 100190\nE-mail: lizijia@amss.ac.cn\n\nidentity information in surveillance videos and faithfully reconstruct the unblurred video stream when two\nblurred sequences are available.\nKeywords Video Surveillance * Greatest Common\nDivisor * Image Deblurring * Computational Video\nProcessing * Visual Cryptography * CUDA\n\n1 Introduction\nVideo surveillance in public spaces has increased dramatically in recent history as a means to deter both\nterrorism and crime in urban environments. However,\nconcern about the potential for abuse and the general\nloss of privacy has also grown along with the number\nof surveillance cameras. In recent years the problem of\nproviding visual data in sensitive environments without impinging on the privacy of the public has been\na major research topic in machine vision society. The\nchallenge in protecting surveillance data lies in how to\nreduce both the number of personally identifiable features and the people with access to these features [4, 3,\n8].\nState-of-the-art information hiding techniques either\nrely on cryptography (codes and ciphers) to change the\nstructure of data or use steganography to render the\nmessage invisible. For visual data, Naor and Shamier\n[16] first introduced the notion of visual cryptography.\nThey also developed a Visual Secret Sharing (VSS)\nscheme by dividing the secret image among n participants where the image can only be recovered when\na sufficient number of participants stack their respective pieces together. VSS can effectively protect the\nvisual data. However, since the data received by each\nindividual participant has been fully encrypted, it provides very little usable information. In the case of video\n\n\f2\n\nsurveillance, this indicates that the data received by\nlow-clearance users would be completely useless.\nIn this paper we present a novel visual data-hiding\ntechnology for data security in video surveillance. Different from previous \"complete\"encryption schemes, we\nintroduce a \"partial\"data encryption scheme by blurring the image/video contents. Our goal is two fold, to\nprovide anonymity to the public and to limit user access to image streams that have less degrees of blurring\nor no blurring at all. Our approach makes use of two\nblurred image streams each of which suppress the appropriate private attributes while retaining the ability\nto reconstruct an unblurred image if one has access to\nboth image streams simultaneously. Experimental results show that our new scheme can effectively protect\nsensitive identity information in surveillance videos and\nreconstruct the original unblurred video stream for people with high security clearance.\n2 Related Work\nMost existing visual data protection schemes fall into\nthe framework of visual cryptography (VC) first proposed by Naor and Shamir [16]. The main idea is to\npartition the data into n pieces called the shares. Only\nwhen sufficient number of shares are stacked together,\nwill human eyes recognize the image content. To achieve\nthis goal, the authors superimpose random patterns of\ndots onto each share to produce noisy-looking images.\nHowever, the appearance of these noisy images in and\nof themselves might lead one to suspect data encryption. To alleviate this problem, newer schemes such as\nhalftoning [27, 15, 23] attempt to separately deal with\ngrayscale and color channels to minimize the loss in\ncontrast . They also produce visually pleasing results\nfor the shares. For example, the work by Zhou et al.\n[27] observes that the grayscale component carries the\nmost significant visual cues and they chose to generate\nhalftone shares on a second image.\nExisting VC solutions, however, are not directly applicable to privacy-protection in visual surveillance. For\nexample, classical VC schemes completely hide the image contents from low-clearance users and the encrypted\nvisual data is completely useless to these users. Ideally,\nlow-clearance users should still be able to access some\nvisual information (e.g., the behavior of the target) although their ability for viewing privacy-sensitive details\nsuch as facial features would be constrained. These observations have led to the notion of \"blind vision\"for\naddressing such privacy issues. Recent efforts include\nprivacy-protected face detection [1], face recognition [6],\nimage filtering [9], and image retrieval [21]. Along the\nsame line of the surveillance work by Yang et al. [4, 3,\n\nChristopher Thorpe et al.\n\n8] that aim to separately treat privacy vs. non-privacy\nfeatures, we present a \"partial textquotedblright visual\nencryption scheme to allow low-clearance users to partially analyze the visual data without revealing crucial\nidentity information. A comprehensive study of VC can\nbe found in [24].\nA natural \"partial\"encryption solution is to strategically blur the imagery data. A blurred image B can\nbe viewed as the convolution of a latent image L with a\nblur kernel K. Tremendous efforts have been focused on\nsolving the blind image deconvolution problem in which\nneither L nor K is known. Since blind deconvolution\nis an under-constrained problem, state-of-the-art solutions rely on regularization to avoid trivial solutions [20,\n25, 22]. Latest approaches attempt to use special priors\nsuch as image statistics [7], edge and gradient distributions [11], kernel sparsity and continuity [5], or color\ninformation [10] for both kernel estimation and image\ndeconvolution. Despite these advances, robust deconvolution remains as an open problem in image processing and computer vision [12]. However, because accurate deblurring is inherently difficult it is ideal for partial visual encryption. The blurry video stream protects\nidentity details while withstanding brute-force deconvolution methods intended to \"decrypt\"the data.\nOur solution is inspired by recently proposed dualimage deblurring techniques [18, 26, 5]. These methods\nuse a pair of images captured towards the same scene\nunder different aperture/shutter settings. For example,\na blurry/noisy image pair can be captured with different shutter speeds. The image pair helps to estimate\nthe kernel and to reduce the ringing artifacts [26] in\nreconstruction. A dual-blur pair [5] captures the scene\nunder different motion blurs. It then estimates both\nblur kernels by constructing an equally blurred image\npair. These methods suggest that the correlation between the images imposes important constraints that\nare useful for kernel and latent image estimations. In\nparticular, it indicates that a single image/video stream\nwill be impossible to decrypt (e.g., to a low-clearance\nuser) but if both streams are available, they will be easy\nto decrypt (e.g., to a high-clearance user).\n3 Algorithm Overview\nFig. 1 shows the processing pipeline of our data-hiding\ntechnology for data security in video surveillance. We\napply coprime blur kernels to the input surveillance\nvideo sequence to generate two blurry video streams\nwhere all the sensitive information is hidden. One is\nthe public stream, and the other is the private stream.\nThe private video sequence is streamed to high clearance personnel through secure transmission lines. Only\n\n\fA Co-Prime Blur Scheme for Data Security in Video Surveillance\n\nPrivate Stream\n\n3\n\nCoprime Deblur\n\nHigh Clearance Personnel\n\nSurveillance\nVideo\n\nPublic Stream\n\nLow Clearance\nPersonnel\n\nFig. 1 The processing pipeline of our data-hiding technology for data security in video surveillance.\n\nhigh clearance personnel has access to both the private and public streams. Here kernel coprimality means\nwhen viewing the blur kernels as 2D polynomials, these\n2D polynomials are coprime and the degree of their\nGCD is 1. By using the coprime blur kernels for sensitive data hiding, we design an efficient and robust\nalgorithm to faithfully reconstruct the ground truth input sequence for the high clearance personnel. We also\nshow that by implementing it on GPUs, we can further\nimprove the computational efficiency of the algorithm\nto be real-time on a typical business workstation. This\nwould make our data-hiding technology practical for\neveryday surveillance environments.\nBlur Kernel Selection: The manner in which the\nblur kernel is implemented in our system is important\nbecause it impacts the security of the system and the\nprivacy due to the blurring. The key is to use very large\nblur kernels when compared to the size of the input image sequence. The larger the kernel size, the more unknown variables there are to solve in an inverse problem, and thus the harder it is to decrypt the surveillance video. We therefore randomly construct the blur\nkernels of large size, and use different kernels for each\nnew frame in the stream. The end users need not to\nknow when the blur kernel has changed because they\nhave no means of deblurring the image with only one\nimage. Users with access to both image streams also\nneed not to know when a blur kernel changes or even\nthe blur kernel itself because the deblurring processes\nsimply relies on possessing two images simultaneously.\nHowever, changing the blur kernel frequently may affect\nthe temporal coherence of the blurred regions and could\nresult in distracting flickering of the blurred regions.\nMulti-level Security: The coprime blur scheme\ndescribed constructs two blurred video streams. One\nvideo stream is publicly accessible but access to the second stream is restricted to users with high clearance and\nis effectively private. Our scheme is therefore characterized by a public/private encryption/decryption pair.\n\nEither of the blur kernel can act as a public encryption\nkey whereas both blur encrypted blur streams act as\na private key and as a result restricting access to both\nstreams is paramount. Our approach can be extended\nto implement a scheme that has more than two levels of\nsecurity. We do this by dividing the users with access to\nthe private video stream into levels. We restrict a level's\naccess to the latent image by reducing the precision of\nthe bits representing incoming blurred frames. For instance users with the highest access will have full bit\nresolution while others with lower clearance will not be\nable to access some subset of the least significant bits.\nRestricting access to the least significant bits of a pixel\nwill therefore degrade the quality of the latent image\nreconstruction.\nbe more prudent to first blur the input with one\ncoprime blur pair and use the resulting public video\nstream as the input to the second coprime blur pair.\nThis second blur pair can be safely distributed in unsecured environments while knowing that the maximum\nlevel of recoverable detail is limited by the blur of the\nfirst coprime blur public video stream.\n\n4 Coprime Deblurring\nAn image can be viewed as a bivariate polynomial with\npowers of x and y indicating horizontal and vertical\npositions and pixel values as coefficients. Some blurring\noperations then take the form of polynomial multiplication or convolution: we can model a blurred video\nframe B of size M \u00d7 N as the convolution of the input\nblur-free video frame L hereafter referred to as the latent image with an unknown blur kernel K, plus noise\nNe ,\nB = L \u2297 K + Ne ,\n\n(1)\n\nwhere \u2297 is the convolution operator. We then apply\nthe z-transform to both sides of the equation. The ztransform of the image will have as coefficients the re-\n\n\f4\n\nChristopher Thorpe et al.\n\nInput\n\n2D Polynomials\n\n2D Kernel Estimation\n\nKernel Degree\nEstimation\nEvaluate B1, B2\nat fixed point z1=a\n\nGCD\nComputation\n\nEvaluate B1, B2 on z1 to generate\nt pairs of 1D polynomials\nCompute t 1D blur kernels from\nthese 1D polynomial pairs\n\nB1(z1,z2), B2(z1,z2)\n\nCompute the 1D kernel\ndegree t by analyzing\nthe Bezout Matrix\n\nUse FFT division\nto compute\nthe GCD of B1, B2\n\nEvaluate these 1D blur kernels\nto reover the 2D blur kernel k1\n\nFig. 2 GCD computation pipeline.\n\nspective pixel values at each location. It allows the blurring process to be implemented as polynomial multiplication instead of convolution,\nb(z1 , z2 ) = l(z1 , z2 ) * k(z1 , z2 ) + ne (z1 , z2 ),\n\n(2)\n\nwhere b,l,k and ne are z-transform of B,L,K and Ne\nrespectively. The two dimensional z-transform process\ncan be further simplified by treating it as a pair of one\ndimensional transform,\nb(z1 , z2 ) = zT1 * B * z2 ,\n\n(3)\n\nwhere z1 = [1, z1 , z12 , . . . , z1M \u22121 ]T is the z-transform in\none direction, and z2 = [1, z2 , z22 , . . . , z2N \u22121 ]T is the ztransform in the other.\nOur proposed dual blur surveillance blurs the latent\n(all-clear) video frame using two coprime blur kernels.\nWhen presented with two motion blurred images of the\nsame scene B1 and B2 and neglecting the image sensor\nnoise Ne , we could faithfully reconstruct the latent image L together with the blur kernels K1 and K2 with\nrespect to each blurred image as:\nl(z1 , z2 ) = GCD{b1 (z1 , z2 ), b2 (z1 , z2 )},\n\n(4)\n\nwhere GCD corresponds to the greatest common divisor\nof b1 and b2 . We also say that k1 (z1 , z2 ) and k2 (z1 , z2 )\nare cofactors.\nFig.2 shows the details of our coprime deblurring\nalgorithm. To recover the approximate GCD of b1 and\nb2 , i.e. the latent image L, we first compute the approximate 2D cofactor k1 , and then directly divide the blur\nimage B1 by the kernel K1 in the Fourier domain, since\nour estimated cofactor k1 is numerically stable and accurate. The first step of our algorithm is to estimate the\ndegree of the blur kernels. Here we assume the blur kernels are all square. We recover the kernel size by analyzing the singularity of the leading principal submatrices\nof the B\u00e9zout matrix [2]. We use this kernel degree t in\nthe second stage for computing the degree of the GCD\nand polynomial evaluation around the unit circle. Next\nwe recover the 2D cofactor k1 (z1 , z2 ). Instead of solving\n\na very large 2D GCD problem, we actually decompose\nit into t 1D GCD sub-problems. It not only improves\nthe computational efficiency dramatically, but also reduces the required memory space. Recall that the blur\nkernel size in our case is usually much smaller than the\nimage resolution, therefore, our method is much more\nefficient than the conventional method [17] based on\nrecovering the latent image through GCDs.\nIn practice, to solve different scaling factors with\nregard to each 1D GCD, we run the second step two\ntimes. We evaluate the 2D polynomials b1 and b2 along\nthe z1 direction first, compute the 1D GCDs, and then\nevaluate the 1D GCDs along z2 . Alternatively, we do\npolynomial evaluation along z2 first and then z1 . The\nfinal estimation k1 is the least square estimation of the\ntwo results generated by different polynomial evaluation orders. For technical details of our coprime deblurring algorithm, please refer to [13, 14].\n\n5 CUDA Implementation\nThe software implementation of our coprime deblurring\nis composed of five major stages, polynomial evaluation,\nkernel degree estimation, 1D cofactor estimation and\n2D kernel estimation and inverse FFT. The processing\npipeline is executed primarily on the GPU, however,\nsome algebraic operations on small matrices such as\nSVD are implemented on the CPU. It was found that\nfor small kernel sizes faster implementations for SVD\nexist on the CPU. Kernel degrees above 25 have a very\ndetrimental impact on the running time and prevent the\nalgorithm from running in real time. Therefore SVD is\nonly performed on square matrices of degree no more\nthan 25 in our implementation. We optimized the evaluation of the image polynomials around the unit circle\nand the final co-factor evaluations for efficient memory access. Portions of the processing pipeline which focused on producing smaller intermediate matrices were\n\n\fA Co-Prime Blur Scheme for Data Security in Video Surveillance\n\nThread Block 1\nB1(thread, threadblock)\nfloat\n\n\u2297\n\nThread N\n\ncomplex\n\nThread 1\n\n***\n\n\u2297\n\nUnit_Circle_Sample(thread)\n\nShared Memory\n\nfloat\n\n***\n\nB2(thread, threadblock)\n\nAccumulation\n\nKernel\n\nDevice\nMemory\n\n***\n***\n\nFig. 3 CUDA device map for polynomial evaluation. Note\nthat each thread only performs two multiplications and that\nresults are written directly into shared memory. After accumulation of shared memory the result is written back to\ndevice memory.\n\noptimized primarily for maximizing throughput instead\nof minimizing the number of memory accesses.\nThe deblurring process begins with the kernel degree estimation process. In order to estimate the degree\nof the kernel, we first evaluate the two image polynomials at points around the unit circle in the z1 direction\nor the z2 direction. This process is exactly the N point\nDiscrete Fourier Transform(DFT). We then choose the\nDFT coefficients corresponding to either the z1 or the\nz2 direction and construct a B\u00e9zout matrix. It does not\nmatter which direction's coefficients are used first as we\nassume the blur kernel is square. We determine the degree of the blur kernel by finding the smallest leading\nprinciple submatrix that is non-singular. The general\napproach would be to use a binary search on the full\nB\u00e9zout matrix to find the smallest non singular submatrix. This approach however initially involves SVD\non matrices too large to result in real time operation\nof our algorithm. Therefore, we restrict search to odd\nleading submatrices of size at least 9 \u00d7 9 and at most\n25 \u00d7 25. As previously stated small SVD calculations\nare done on the CPU as they are better suited to take\nadvantage of the cache on the CPU. In order to further\nspeed the kernel degree estimation we use four threads\nto perform SVDs on different sized submatrices simultaneously. Of the 9 different odd kernels sizes between\n9 \u00d7 9 and 25 \u00d7 25 it never takes more than two SVD\ncalculations on each given thread to find the kernel degree. If all the B\u00e9zout submatrices are singular then the\n\n5\n\nkernel degree must be maximal and 25 is chosen as the\nkernel degree t.\nAfter determining the degree of the kernel we once\nagain use the DFT coefficients but this time to compute 1D cofactor estimates. We now discuss our DFT\nimplementation in greater detail before moving on to\nthe 1D cofactor estimates. Evaluating the image polynomial in both the z1 and z2 direction required two calls\nto our CUDA DFT kernel. Given a t \u00d7 t kernel there\nwill be 4t DFT calculations for the input blur pair. In\nour implementation, a N point DFT in the z1 direction\non a 640 \u00d7 480 frame has 640 thread blocks each with\n480 threads. Similarly, in the z2 direction our kernel\nhas 480 thread blocks and 640 threads per block. We\nhave designed our DFT sampling kernel such that each\nthread only stores three values in the registers at any\ngiven time, as can be seen in Fig. 3. Two of those values are the normalized intensity values from the same\nlocation in the CBP and the third value is the current\ncomplex sample from the unit circle. For a t \u00d7 t kernel\nthere will be N samples of the unit circle in the z1 direction DFT and M different samples of the unit circle\nin the z2 direction. Each thread performs two complex\nmultiplications one for each image and stores the result in that thread block's shared memory array. The\nshared memory array is then accumulated to produce\nthe DFT sample for that thread block after which the\nnext unit circle sample is loaded from global memory\ninto that register. The philosophy behind this approach\nis to ensure that any value used more than once resides\neither in a thread's register or shared memory within a\nthread block and is never loaded from global memory\ntwice.\nNVIDIA's CUDA provides support for the DFT operation via its cufft library. However, it does not provide\ngood performance for input sizes that are not powers\nof two. For some frame sizes it can be impractical to\npad input images to the next power of two considering the number operations that will be performed on\nthe padded input. We therefore tailored our algorithm\nto provide the best DFT performance for any arbitrary\nframe size. Choosing a standard frame size does not\nrestrict the DFT to that frame size as the level of privacy desired may increase or decrease the size of the\nblur kernel and therefore the resulting frame size. The\nnumber of points in our two 1D DFT sampling stage\nis therefore determined after kernel size estimation and\na CUDA kernel function called to produce the correct\nunit circle samples.\nHaving performed the DFT on the image polynomials in the z1 and z2 direction we now begin the 1D\ncofactor computation by constructing t B\u00e9zout matrices from z1 and t more B\u00e9zout matrices from the coef-\n\n\f6\n\nficients in the z2 direction. Similar to the kernel degree\nestimation process these B\u00e9zout matrices are copied\nback to host memory to be factored by CPU SVD routines. The resulting 1D kernel cofactors are copied back\nto the GPU to be used in the 2D kernel estimation process. The GCD deblurring algorithm also has a number\nof intermediate processing steps on small matrices or\nvectors similar to the B\u00e9zout matrix. Unlike the previously discussed SVD decomposition these operations\nare all O(n) and therefore present significant opportunity for performance gains. We do this by constructing\ncomposite matrices from vectors such as DFT coefficients and processing them in parallel across different\nthread blocks in order to maximize resource usage on\nthe GPU.\n2D kernel estimation continues by evaluating portions of the factored B\u00e9zout matrix on the unit circle\nto produce scaled coefficients of the kernel k1 's Fourier\ntransform. In order to combine the two estimates of k1\nwe must recover the scaling factors on rows of the first\nk1 estimate and the columns of the second k1 estimate.\nWe therefore have 2t unknowns and t \u00d7 t elements in\nthe kernel estimates producing an over determined system. We therefore employ a least squares approach and\napply SVD again on the CPU to determine the scale\nfactors. After normalization of the kernel estimates we\ncompute the average of the two kernel estimates and use\nit to deblur one frame of input blur pair via the inverse\nFFT in CUDA's cufft library. We use CUDA's FFT implementation because it relies on texture memory and\ncan store the entire image unlike our DFT evaluation\nkernel which is optimized for small number of DFTs.\n6 Results and Analysis\nIn this section, we demonstrate our deblurring scheme\nby showing its performance in a number of common\nsurveillance scenarios. We also present running times\nfor our implementation for various blur kernel sizes.\nWe test our algorithm on a PC with a 3.00 Ghz Intel\nQuad core CPU, 3 GB memory and a NVIDIA Geforce\nGTX460 GPU with compute capability 2.1. Video sequences were captured with a Point Grey Flea2 firewire\ncamera. Our blurring and deblurring algorithms were\nimplemented using NVIDA CUDA SDK 3.2. All input\nframes had a pixel resolution of 640 \u00d7 480. Blur kernel\nsizes varied between 19 \u00d7 19 and 25 \u00d7 25 based on the\nlevel of anonymity required for the scene. The effect of\nlarge kernels on the running time of our algorithm was\nalso evaluated.\nIn Fig. 4 we show a typical outdoor public surveillance scenario of a sidewalk in an urban area. Note\nthat the frames blurred with 23 \u00d7 23 kernels in the top\n\nChristopher Thorpe et al.\n\nrow still allow the viewer to discern important qualities\nabout the individual in the frame. Despite not being\nable to identify facial features one is still able to ascertain the color and type of clothing being worn. In addition, one can see that the individual has his hand raised\nto his ear and thereby infer that he might be making\na telephone call without necessarily being able to see\nthe mobile phone. In this way authorities tasked with\nsurveillance are still able to identify common behavior\nwithout having being presented with a sharp image.\nNote also in the bottom row samples of our deblurred results for this scene. In the event that greater\nscrutiny of the passerby is warranted a high clearance\nuser would now be able to discern much more about\nthe target. In addition to confirming that the passerby\nwas indeed using a mobile phone they could determine\nthat he was wearing glasses and that his shoes had\nwhite tips. In urban surveillance scenes like this it is\nalso common for cameras to inadvertently record the\nlicence plates or passing cars. Notice the right lane of\nthe street is within the camera's field of view. Employing our GCD blurring scheme in these sidewalk/street\nscenes would therefore restrict licence plate information\nto users with high clearance.\nIn Fig. 5 we present a parking lot surveillance video\nin which two distant individuals are walking towards\nthe camera. The blur kernel in this series of frames is\n19 \u00d7 19. We compare our deblurring results with those\nfrom the stat-of-the-art blind single image deblurring\n[20], and the traditional non-blind Richardson-Lucy deconvolution [19]. Here non-blind deconvolution means\nwe provide the ground truth blur kernels for the traditional Richardson-Lucy algorithm. As can be seen in the\nfigure, both the blind single image deblurring algorithm\n[20] and non-blind Richardson-Lucy deconvolution [19]\ncannot recover the sensitive facial information from the\nsubjects. However, in the second column our GCD deblurred frames have a much greater amount of detail\nand facial detail in particular. Only in the column presenting our GCD results are the details of the target's\ndistant faces discernible.\nIn Fig. 6 we show a camera monitoring an entrance\na very common indoor surveillance scenario. Because\nobjects of interest in the scene will be closer to the\ncamera the size of the blur kernel was increased to 25 \u00d7\n25 so as not to preserve too much detail. In the blurred\nframes it is clear that two people enter the building\nand what color their clothing is. However, apart from\nthat it is difficult to discern facial details or even the\ngender of the individuals entering the building. In the\ndeblurred frames on the bottom row it is easy to discern\nimportant details about the individuals such as their\nfaces and even that there is a car in the background.\n\n\fA Co-Prime Blur Scheme for Data Security in Video Surveillance\nFrame 38\n\nFrame 67\n\n7\nFrame 95\n\nFrame 129\n\nOne CBP\nEncrypted Sequence\n\nCoprime\nDeblurring Result\n\nFig. 4 Deblurring results of a typical surveillance scene in an urban environment.\n\nTable 1 Running times of the pipeline stages with different\nkernel size for images of size 640 \u00d7 480 (in milliseconds)\nPipeline Stage\nPolynomial Evaluation\nKernel Degree Estimation\n1D Kernel Estimation\n2D Kernel Est. and FFT\nTotal Time\n\n9\u00d79\n0.65\n0.81\n18.45\n4.06\n23.97\n\nKernel Size\n17 \u00d7 17 23 \u00d7 23\n0.94\n1.39\n0.81\n0.83\n27.83\n35.87\n4.82\n5.9\n34.4\n43.99\n\nPerformance. Tab. 1 provides running times for\nour overall algorithm and component processes with\nvarious kernel sizes. From the total running times it\nis evident that our processing pipeline achieves frame\nrates that approach or exceed current standard video\nframe rates. Running times include the memory copies\nof the input frames to the GPU and the memory copy\nof the resulting unblurred frame back to host memory.\nWe measure the running times using calls to NVIDA's\ntimer functions. Table 1 shows that of all the processing pipeline stages the 1D kernel estimation is the most\ntime consuming. This is primarily due that time associated with each SVD decomposition and the fact the\nnumber of SVD factorizations grow exponentially with\nkernel size. However, other factors related to the construction of a greater number of Bezout matrices, copying them to host memory and copying the result of the\nSVD back to GPU scale in proportion to the number\nof SVD factorizations.\nLess computationally expensive stages such as polynomial evaluation and kernel degree estimation contribute little to the overall running time of the algorithm. However, the polynomial evaluation running time\nincreases proportionally with kernel degree t. The running time of the kernel degree estimation stage remains\n\nessentially constant as the size of the input remains the\nsame regardless of the blur kernel size. The running\ntime of the last stage however, increases steadily with\nkernel size. This increase is due to the small polynomial\nevaluation carried out on the 1D kernel cofactors to produce the 2D kernel estimate and not to the constant\nrunning time to divide by the kernel and the apply the\nthe inverse FFT to deblur the image. We also execute\nour algorithm on the CPU producing running times of\n\u223c0.509 secs and \u223c3.404 secs for 9 \u00d7 9 and 25 \u00d7 25 blur\nkernels respectively. Running the vast majority of our\nalgorithm on the GPU therefore produces speedups of\n21 and 77 respectively.\n\n7 Conclusions and Future Work\nWe have demonstrated the usefulness of our coprime\nblur scheme for visual data hiding in surveillance that\ndoes not rely on cryptography to completely obscure\nthe images contents. Instead the ability to recover all\nof the image information relied on access to a second\nstream of images not a predetermined encryption key.\nOnly with access to the second stream is one able to recover the blur kernel and finally the latent image. This\nkey-less decryption allows a multi-tiered security clearance system to be implemented by structuring or modifying the video transmission infrastructure. We have\nimplemented a GPU based processing pipeline that produces deblurred video at frame rates above 20fps for\nrelatively large kernel sizes upto 25 \u00d7 25.\nOur GPU implementation of the GCD image deblurring algorithm has several limitations. First, our approach requires double the bandwidth for video transmission and a means to restrict access to both video\n\n\f8\n\nChristopher Thorpe et al.\nOne CBP\nEncrypted Sequence\n\nCoprime\nDeblurring Result\n\nBlind Single Image\nDeconvolution [Shan et al.]\n\nNon-blind Richardson-Lucy\nDeconvolution\n\nFrame 36\n\nFrame 75\n\nFrame 114\n\nFrame 159\n\nFig. 5 Decrypted results with different deblurring methods on video frames encrypted by our coprime blurred scheme.\n\nstreams. These requirements may reduce the number\nof instances where deploying our approach is practical.\nThe running time for our approach is proportional to\nthe blur kernel size and therefore the level of privacy\nin some surveillance scenarios may be limited by a desired frame rate. In addition the running time of the\ndeblurring process may prohibit some post processing\nthat may aid surveillance such as facial or object recognition. Future work will include decreasing the running\ntime of expensive operations in the pipeline to facilitate\nsome post processing steps such as background subtraction. Reducing the running time can be achieved either\nby optimizing the existing pipeline or introducing a hybrid pipeline. For example shifting computation of SVD\n\nto an external FGPA or coprocessor. Another topic of\ninterest we may pursue is the integration of a z-camera\nwhich will provide the algorithm with depth information which then can be used to compute the optimal\nblur kernel size for hiding information.\n\nReferences\n1. Avidan, S., Butman, M.: Blind vision. In ECCV (2006)\n2. Barnett, S.: A note on the Bezoutian matrix. SIAM Journal on Applied Mathematics 22(1), 84\u201386 (1972)\n3. Chang, Y., Yan, R., Chen, D., Yang, J.: People identification with limited labels in privacy-protected video. In:\n2006 IEEE International Conference on Multimedia and\nExpo, pp. 1005\u20131008 (2006)\n\n\fA Co-Prime Blur Scheme for Data Security in Video Surveillance\nFrame 2\n\nFrame 29\n\n9\nFrame 44\n\nFrame 74\n\nOne CBP\nEncrypted Sequence\n\nCoprime\nDeblurring Result\n\nFig. 6 Deblurring results of a door entrance surveillance video sequence.\n\n4. Chen, D., Chang, Y., Yan, R., Yang, J.: Tools for protecting the privacy of specific individuals in video. EURASIP\nJ. Appl. Signal Process. 2007, 107\u2013107 (2007)\n5. Chen, J., Yuan, L., Tang, C.K., Quan, L.: Robust dual\nmotion deblurring. In: CVPR (2008)\n6. Erkin, Z., Franz, M., Guajardo, J., Katzenbeisser, S.,\nLagendijk, I., Toft, T.: Privacy-preserving face recognition. In: Privacy Enhancing Technologies, pp. 235\u2013253.\nSpringer (2009)\n7. Fergus, R., Singh, B., Hertzmann, A., Roweis, S., Freeman, W.: Removing camera shake from a single photograph. In: ACM SIGGRAPH, pp. 787\u2013794. ACM (2006)\n8. Greiner, S., Yang, J.: Privacy protection in an electronic\nchronicle system. In: Proceedings of the IEEE 34th Annual Northeast Bioengineering Conference (2008)\n9. Hu, N., Cheung, S., Nguyen, T.: Secure image filtering.\nIn: ICIP, pp. 1553\u20131556 (2007)\n10. Joshi, N., Zitnick, C., Szeliski, R., Kriegman, D.: Image\ndeblurring and denoising using color priors. In: CVPR,\npp. 1550\u20131557 (2009)\n11. Levin, A.: Blind motion deblurring using image statistics.\nIn NIPS 19 (2007)\n12. Levin, A., Weiss, Y., Durand, F., Freeman, W.: Understanding and evaluating blind deconvolution algorithms.\nIn: CVPR, pp. 1964\u20131971 (2009)\n13. Li, F., Li, Z., Saunders, D., Yu, J.: A theory of coprime\nblurred pairs. Computer Vision, IEEE International Conference on pp. 217\u2013224 (2011)\n14. Li, Z., Yang, Z., Zhi, L.: Blind image deconvolution via\nfast approximate gcd. In: ISSAC '10: Proceedings of the\n2010 International Symposium on Symbolic and Algebraic Computation, pp. 155\u2013162 (2010)\n15. Myodo, E., Takagi, K., Miyaji, S., Takishima, Y.:\nHalftone visual cryptography embedding a natural\ngrayscale image based on error diffusion technique. In:\nMultimedia and Expo, 2007 IEEE International Conference on, pp. 2114\u20132117 (2007)\n16. Naor, M., Shamir, A.: Visual cryptography. In: Advances\nin Cryptology - EUROCRYPT'94. Springer (1995)\n17. Pillai, S.U., Liang, B.: Blind image deconvolution using\na robust gcd approach. IEEE TIP 8(2), 295\u2013301 (1999)\n18. Rav-Acha, A., Peleg, S.: Two motion-blurred images are\nbetter than one. Pattern Recogn. Lett. 26(3), 311\u2013317\n(2005)\n\n19. Richardson, W.: Bayesian-based iterative method of image restoration. JOSA 62(1), 55\u201359 (1972)\n20. Shan, Q., Jia, J., Agarwala, A., et al.: High-quality motion deblurring from a single image. ACM Transactions\non Graphics-TOG 27(3), 73\u201373 (2008)\n21. Shashank, J., Kowshik, P., Srinathan, K., Jawahar, C.:\nPrivate content based image retrieval. In: CVPR (2008)\n22. Tai, Y.W., Tan, P., Brown, M.S.: Richardson-lucy deblurring for scenes under a projective motion path. IEEE\nTrans. Pattern Anal. Mach. Intell. 33(8), 1603\u20131618\n(2011)\n23. Wang, Z., Arce, G.: Halftone visual cryptography\nthrough error diffusion. In: Image Processing, 2006 IEEE\nInternational Conference on, pp. 109\u2013112. IEEE (2006)\n24. Weir, J., Yan, W.: A comprehensive study of visual cryptography. Transactions on data hiding and multimedia\nsecurity V pp. 70\u2013105 (2010)\n25. Xu, L., Jia, J.: Two-phase kernel estimation for robust\nmotion deblurring. Computer Vision\u2013ECCV 2010 pp.\n157\u2013170 (2010)\n26. Yuan, L., Sun, J., Quan, L., Shum, H.: Image deblurring\nwith blurred/noisy image pairs. ACM Transactions on\nGraphics 26(3), 1 (2007)\n27. Zhou, Z., Arce, G., Di Crescenzo, G.: Halftone visual\ncryptography. Image Processing, IEEE Transactions on\n15(8), 2441\u20132453 (2006)\n\n\f"}