{"id": "http://arxiv.org/abs/1105.1945v1", "guidislink": true, "updated": "2011-05-10T13:50:18Z", "updated_parsed": [2011, 5, 10, 13, 50, 18, 1, 130, 0], "published": "2011-05-10T13:50:18Z", "published_parsed": [2011, 5, 10, 13, 50, 18, 1, 130, 0], "title": "Classification and Evaluation the Privacy Preserving Data Mining\n  Techniques by using a Data Modification-based Framework", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1105.6263%2C1105.2526%2C1105.1665%2C1105.5728%2C1105.3562%2C1105.5613%2C1105.2255%2C1105.5152%2C1105.2685%2C1105.2633%2C1105.1088%2C1105.6144%2C1105.4068%2C1105.1081%2C1105.4453%2C1105.5725%2C1105.2552%2C1105.1604%2C1105.5452%2C1105.1080%2C1105.0325%2C1105.5940%2C1105.5687%2C1105.5541%2C1105.2860%2C1105.1364%2C1105.2799%2C1105.5979%2C1105.4789%2C1105.5767%2C1105.0824%2C1105.4363%2C1105.2137%2C1105.0700%2C1105.0368%2C1105.4900%2C1105.4067%2C1105.0505%2C1105.3884%2C1105.2958%2C1105.4818%2C1105.2595%2C1105.6247%2C1105.3591%2C1105.5323%2C1105.1945%2C1105.5867%2C1105.0477%2C1105.4484%2C1105.5571%2C1105.1671%2C1105.5939%2C1105.5887%2C1105.0789%2C1105.0248%2C1105.3016%2C1105.0034%2C1105.4352%2C1105.2230%2C1105.2789%2C1105.2674%2C1105.0281%2C1105.2406%2C1105.5476%2C1105.6094%2C1105.0958%2C1105.2498%2C1105.2277%2C1105.4866%2C1105.5140%2C1105.3512%2C1105.5588%2C1105.2787%2C1105.3701%2C1105.2103%2C1105.3611%2C1105.1661%2C1105.5704%2C1105.2602%2C1105.1034%2C1105.5253%2C1105.3009%2C1105.0941%2C1105.3629%2C1105.4643%2C1105.1474%2C1105.4795%2C1105.1478%2C1105.1027%2C1105.3617%2C1105.3835%2C1105.3567%2C1105.0727%2C1105.0130%2C1105.3563%2C1105.2778%2C1105.0458%2C1105.4697%2C1105.3923%2C1105.0471%2C1105.5609&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Classification and Evaluation the Privacy Preserving Data Mining\n  Techniques by using a Data Modification-based Framework"}, "summary": "In recent years, the data mining techniques have met a serious challenge due\nto the increased concerning and worries of the privacy, that is, protecting the\nprivacy of the critical and sensitive data. Different techniques and algorithms\nhave been already presented for Privacy Preserving data mining, which could be\nclassified in three common approaches: Data modification approach, Data\nsanitization approach and Secure Multi-party Computation approach. This paper\npresents a Data modification- based Framework for classification and evaluation\nof the privacy preserving data mining techniques. Based on our framework the\ntechniques are divided into two major groups, namely perturbation approach and\nanonymization approach. Also in proposed framework, eight functional criteria\nwill be used to analyze and analogically assessment of the techniques in these\ntwo major groups. The proposed framework provides a good basis for more\naccurate comparison of the given techniques to privacy preserving data mining.\nIn addition, this framework allows recognizing the overlapping amount for\ndifferent approaches and identifying modern approaches in this field.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1105.6263%2C1105.2526%2C1105.1665%2C1105.5728%2C1105.3562%2C1105.5613%2C1105.2255%2C1105.5152%2C1105.2685%2C1105.2633%2C1105.1088%2C1105.6144%2C1105.4068%2C1105.1081%2C1105.4453%2C1105.5725%2C1105.2552%2C1105.1604%2C1105.5452%2C1105.1080%2C1105.0325%2C1105.5940%2C1105.5687%2C1105.5541%2C1105.2860%2C1105.1364%2C1105.2799%2C1105.5979%2C1105.4789%2C1105.5767%2C1105.0824%2C1105.4363%2C1105.2137%2C1105.0700%2C1105.0368%2C1105.4900%2C1105.4067%2C1105.0505%2C1105.3884%2C1105.2958%2C1105.4818%2C1105.2595%2C1105.6247%2C1105.3591%2C1105.5323%2C1105.1945%2C1105.5867%2C1105.0477%2C1105.4484%2C1105.5571%2C1105.1671%2C1105.5939%2C1105.5887%2C1105.0789%2C1105.0248%2C1105.3016%2C1105.0034%2C1105.4352%2C1105.2230%2C1105.2789%2C1105.2674%2C1105.0281%2C1105.2406%2C1105.5476%2C1105.6094%2C1105.0958%2C1105.2498%2C1105.2277%2C1105.4866%2C1105.5140%2C1105.3512%2C1105.5588%2C1105.2787%2C1105.3701%2C1105.2103%2C1105.3611%2C1105.1661%2C1105.5704%2C1105.2602%2C1105.1034%2C1105.5253%2C1105.3009%2C1105.0941%2C1105.3629%2C1105.4643%2C1105.1474%2C1105.4795%2C1105.1478%2C1105.1027%2C1105.3617%2C1105.3835%2C1105.3567%2C1105.0727%2C1105.0130%2C1105.3563%2C1105.2778%2C1105.0458%2C1105.4697%2C1105.3923%2C1105.0471%2C1105.5609&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In recent years, the data mining techniques have met a serious challenge due\nto the increased concerning and worries of the privacy, that is, protecting the\nprivacy of the critical and sensitive data. Different techniques and algorithms\nhave been already presented for Privacy Preserving data mining, which could be\nclassified in three common approaches: Data modification approach, Data\nsanitization approach and Secure Multi-party Computation approach. This paper\npresents a Data modification- based Framework for classification and evaluation\nof the privacy preserving data mining techniques. Based on our framework the\ntechniques are divided into two major groups, namely perturbation approach and\nanonymization approach. Also in proposed framework, eight functional criteria\nwill be used to analyze and analogically assessment of the techniques in these\ntwo major groups. The proposed framework provides a good basis for more\naccurate comparison of the given techniques to privacy preserving data mining.\nIn addition, this framework allows recognizing the overlapping amount for\ndifferent approaches and identifying modern approaches in this field."}, "authors": ["MohammadReza Keyvanpour", "Somayyeh Seifi Moradi"], "author_detail": {"name": "Somayyeh Seifi Moradi"}, "author": "Somayyeh Seifi Moradi", "links": [{"href": "http://arxiv.org/abs/1105.1945v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1105.1945v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1105.1945v1", "affiliation": "Department of Computer Engineering Islamic Azad University", "arxiv_url": "http://arxiv.org/abs/1105.1945v1", "arxiv_comment": null, "journal_reference": "International Journal on Computer Science and Engineering\n  (IJCSE)Vol. 3 No. 2 Feb 2011", "doi": null, "fulltext": "MohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\nClassification and Evaluation the Privacy\nPreserving Data Mining Techniques by\nusing a Data Modification\u2013based\nFramework\nMohammadReza Keyvanpour\nDepartment of Computer Engineering\nAl-Zahra University\nTehran, Iran\nKeyvanpour@Alzahra.ac.ir\n\nSomayyeh Seifi Moradi\nDepartment of Computer Engineering\nIslamic Azad University, Qazvin Branch\nTehran, Iran\nS_seifi_moradi@yahoo.com\nAbstract-In recent years, the data mining techniques have met a serious challenge due to the increased\nconcerning and worries of the privacy, that is, protecting the privacy of the critical and sensitive data.\nDifferent techniques and algorithms have been already presented for Privacy Preserving data mining,\nwhich could be classified in three common approaches: Data modification approach, Data sanitization\napproach and Secure Multi-party Computation approach. This paper presents a Data modification\u2013\nbased Framework for classification and evaluation of the privacy preserving data mining techniques.\nBased on our framework the techniques are divided into two major groups, namely perturbation\napproach and anonymization approach. Also in proposed framework, eight functional criteria will be\nused to analyze and analogically assessment of the techniques in these two major groups. The proposed\nframework provides a good basis for more accurate comparison of the given techniques to privacy\npreserving data mining. In addition, this framework allows recognizing the overlapping amount for\ndifferent approaches and identifying modern approaches in this field.\nKeywords- Privacy Preserving Data Mining, Data Modification, Perturbation, Anonymization\nI.\n\nINTRODUCTION\n\nAlthough data mining can be valuable in many applications, it may cause to violation of privacy in case of\nno sufficient protection and abusing private data for other goals. The main factor of privacy beaching in data\nmining is data misuse. In fact, if the data consists of critical and private characteristics and/or this technique is\nabused, data mining can be hazardous for individuals and organizations. Therefore, it is necessary to prevent\nrevealing not only the personal confidential information but also the knowledge, which is critical in a given field\n[1].\nThe principal attention to Privacy Preserving Data Mining (PPDM) is development of those algorithms,\nwhich - by protecting existed private data and knowledge in datasets and accessing the valid results of data\nmining-provide the possibility to share the critical and private data for analytical aims.\nThere are two general scenarios in Privacy Preserving Data Mining: the Multi-party collaborations scenario\nand Data publishing scenario. In the former, the collection of data is distributed between two or more sites, each\none owns a part of the private data and these sites collaborate to compute a data mining algorithm on the union\nof their databases without revealing the data at their individual sites and the results of data mining will only be\nrevealed. The major approach for this scenario is the Secure Multi-party Computation.\nIn Data publishing scenario the owners or data providers are publishing or sharing their data to acquire data\nmining results and /or joining the data mining process. In this scenario, as shown in figure (1), the privacy\npreservation techniques are applied during the data integration or before sending data to the data miner.\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n862\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\nPrincipal approaches in this scenario based on the goal of privacy preservation- classified in two categories:\nData modification and Data sanitization.\nData sanitization approaches aim to hide the critical rules and patterns existed in dataset. However, the Data\nmodification approaches are hiding critical data and aiming to acquire valid results of data mining while private\ndata cannot be reached directly and precisely. In these techniques, major concerns are to maximize the quality of\nthe released data, data mining results accuracy and protecting the data privacy as well.\n\nData Provider 1\n\nData Provider 2\n\nData Provider 3\n\nModified Data\n\nModified Data\n\nModified Data\n\nData Center\n\nData Miner\n\nFigure 1. PPDM based on Data publishing scenario\n\nThis paper attempts to provide a good basis for classification and more accurate evaluation of data\nmodification\u2013based techniques for Privacy Preserving Data Mining. The rest of the paper is organized as\nfollows. In section 2, the recommended classification framework for data modification techniques in PPDM will\nbe given and then we introduce these techniques. In section 3 we propose the evaluation framework and analyze\nthese techniques under this framework and finally, in section 4, the paper will be finalized by conclusion as\nwell.\nII.\n\nCLASSIFICATION FRAMEWORK\n\nData modification techniques study and review for PPDM shows that these techniques can be classified in\ntwo principle groups of perturbation-based and anonymization-based techniques according to how the protection\nof privacy. The recommended classification framework is shown in figure (2).\nAnonymization techniques are preventing from recognizing the critical data's characters and identity to\npreserve the privacy while perturbation approach modify a part of data or the whole dataset by means of\ndetermined techniques and in a manner to save the particular properties, which are meaningful and significant\nfor creating data mining models.The current techniques in perturbation approach are classified in two categories\nbased on how they perturb datasets and particular Properties that will be preserved in data: Value-based\nPerturbation and Multi-Dimensional Perturbation. In the Value-based Perturbation the purpose is to preserve\nstatistical characteristics and columns distribution while Multi-Dimensional Perturbation aims to hold MultiDimensional information.\nA. Anonymization Techniques\nFirst natural solution to publish raw-critical data with privacy preserving is de-identification in which the\nraw-critical dataset is spread after removing the key identities of the records. But, in combination with an\nexternal database, there might be some other attributes to be used for identifying the personal details, called\n\"Quasi-Identifier\" (QI). To solve re-identifying problem, anonymization approach was brought up, in which the\nvalues of the QI attributes become modified so that they no longer uniquely represent individuals.\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n863\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\nData Modification based Techniques of PPDM\nPerturbation Approach\n\nAnonymization Approach\n\nMulti-Dimensional Perturbation\n\nValue-based Perturbation\nRandom Noise Addition\nRandomized Response\n\nData mining Task- based Perturbation\nCondensation\nRandom Rotation Perturbation\nGeometric Perturbation\n\nK-Anonymity\nL-Diversity\nT-Closeness\n\nDimension Reduction-based Perturbation\nRandom Projection Perturbation\nNMF\nSVD\nFigure 2. Data Modification-based framework for classification the PPDM Techniques\n\n1)\nK-anonymity Technique\nIn this technique each record within an anonymized table must be indistinguishable with at least k-1 other\nrecord within the dataset, with respect to a set of QI attributes. In particular, a table is K-anonymous if the QI\nattributes values of each record are identical to those of at least k-1 other records. To achieve the K-anonymity\nrequirement, generalization or suppression could be used [2, 3].\nNevertheless, this technique consists of some limitations. First, it is very difficult for a database owner to\ndetermine which of the attributes are or are not available in external tables. Second, this model considers a\ncertain type of attack (Linkage attack) and cannot preserve sufficiently the sensitive attributes against\nHomogeneity attack (similarity of the sensitive attributes values in an anonymized group) and Background\nKnowledge attack (awareness about the relationship between sensitive and QI attributes).\n2)\nL-diversity Technique\nThis technique [4] was proposed to solve the Homogeneity attack of K-anonymity technique that emphasizes\nnot only on saving the minimum size of K group but also considers saving the variety of the sensitive attributes\nof each group. In this technique, every anonymized group must hold at least l well-represented values for each\nsensitive attribute. However, this technique has some shortcomings too: e.g. it might be unnecessary and\ndifficult to achieve that. On the other hand, this technique is insufficient to prevent attribute disclosure, Such as\nSimilarity Attack. In fact, if the sensitive attribute values in an anonymized group are distinct but semantically\nthe same, the adversary can learn important information.\n3)\nT-Closeness Technique\nAs it was discussed, L-diversity technique's deficiency is that it treats all values of a given attribute in a same\nway regardless of its distribution in the data, while this rarely happens for real datasets in which the values of\nthe sensitive attributes are not probably in the same sensitivity level; in this way, the precise values of sensitive\nattributes might be inferred by the use of Background Knowledge Attack. In T-Closeness Technique [5] the\ndistance between the distribution of a sensitive attribute in an anonymized group and its distribution in the\nwhole table should not be more than t threshold. The main challenge of this task is how to show the distance\ncriterion which can reflect the semantic gap between the quantities.\nOverall, anonymization techniques are simple and their main advantage is scalability toward privacy\npreservation (choosing greater K); however, they have an inherent weakness that they cannot always prevent the\nrecords' critical values deduction against attacks efficiently. Moreover, it has been shown that optimal\nanonymization is an \"NP-Hard\" problem [6]. Furthermore, this technique is not even effective with increasing\ndimensionality, since the data can typically be combined with either public or background information to reveal\nthe identity of the underlying record owners [7].\nB. Value-based Perturbation Techniques\nThe main idea of this approach is to add random noise to the data values. This approach is actually, based on\nthis fact that some data mining problems do not need the individual records necessarily and they just need their\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n864\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\ndistribution. Since the perturbing distribution is known, they can reach data mining goals by reconstructing their\nrequired aggregate distributions. However, due to reconstructing each data dimension's distribution\nindependently, they have the inherent disadvantage of missing the implicit information available in multidimensional records and on the other hand it is required to develop new distribution-based data mining\nalgorithms.\n1)\nRandom Noise Addition Technique\nThis technique is described in [8] as follows: Consider n original data X 1 , X 2 \uf0bc , X N , where X i are\nvariables following the same independent and identical distribution (i.i.d). The distribution function of X i is\nby perturbation.\ndenoted as FX , n random variables Y 1 ,Y 2 \uf0bc ,Y N are generated to hide the real values of\nSimilarly, Y i are i.i.d variables. Disturbed data will be generated as follows:\nw 1 , \uf0bc,w n where w i \uf03d X i \uf02bY i i \uf03d 1,..., n\n\n(1)\n\nIt is also assumed that the added noise variance is large enough to let an accurate estimation of main data\nvalues take place. Then, according to the perturbed dataset w1 , \uf0bc, w n , known distributional function FY and\n'\nusing a reconstruction procedure based on Bayes rule, the density function f X will be estimated by Equation\n(2).\n\nf\n\n'\nX\n\n1\n(a ) \uf03d\nn\n\n\uf0f2\n\nn\n\n\uf0e5\ni \uf03d1\n\n\uf0f2\n\na\n\nf Y \uf028w i \uf02d a \uf029 f X \uf028 a \uf029\n\n\uf02d\uf0a5\n\uf02b\uf0a5\n\nf Y \uf028w i \uf02d z \uf029 f X \uf028 z \uf029 dz\n\n(2)\n\n\uf02d\uf0a5\n\nAlthough f X isn't really known, we can estimate it by using the normal distribution as the initial estimate\nand iteratively refine this estimate by applying Equation (2).\nIn [9], to minimize the information loss of this technique and improve the reconstruction procedure, a new\ndistribution reconstruction algorithm called Maximizing Algorithm for the Expectation of Mathematics (EM) is\nrepresented. In [8] a new decision-tree algorithm is developed according to this technique. This technique is also\nused in privacy preserving association rule mining [10, 11].\nHowever, in [12] it is presented that privacy breaches as one of the major problems with the random noise\naddition technique and observed that the spectral properties of the randomized data can be utilized to separate\nnoise from the private data. The filtering algorithms based on random matrix theory are used to approximately\nreconstruct the private data from the perturbed data. Thus, establishing a balance between Privacy preservation\nand accuracy of data mining result is hard because more we want privacy preservation, more we should lose\ninformation.\n2)\nRandomized Responses Technique\nThe main idea for this technique [13] is to scramble data so that the data collector cannot express, with a\nprobabilities better than of the defined threshold, whether the data sent back by the respondent is correct or not.\nThere are two models in this technique: Related\u2013Question and Unrelated- Question models. In the former, the\ninterviewer asks every respondent a couple of questions related together, of each the reply is opposite the other\none. For example, the questions can be as follows:\n1) I have the sensitive attribute A.\n2) I do not have the sensitive attribute A.\nThe respondent will answer randomly and with \u03b8 probability to the first question and with 1- \u03b8 to the second\nquestion. Although the interviewer finds out the answers (yes or no), he does not know which question has been\nanswered by the respondent; hence, the respondent's privacy preserving will be saved. The collector uses the\nfollowing equations in order to estimate the percentage of the people who have characteristic A:\nP * \uf028 A \uf03d yes \uf029 \uf03d P \uf028 A \uf03d yes \uf029 .\uf071 \uf02b P \uf028 A \uf03d no \uf029 . \uf0281 \uf02d \uf071 \uf029 \uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf033\uf029\uf020\nP * \uf028 A \uf03d no \uf029 \uf03d P \uf028 A \uf03d no \uf029 .\uf071 \uf02b P \uf028 A \uf03d yes \uf029 . \uf0281 \uf02d \uf071 \uf029 \uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf034\uf029\uf020\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n865\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\nWhere P * \uf028 A \uf03d yes \uf029 (or P * \uf028 A \uf03d no \uf029 ) is the ratio of the \"yes\" (or \"no\") replies which are acquired via\nsurvey data and P \uf028 A \uf03d yes \uf029 (or P \uf028 A \uf03d no \uf029 ) are estimated ratios of the \"yes\" (or \"no\") answers to sensitive\nquestions. The purpose is to gain P \uf028 A \uf03d yes \uf029 P \uf028 A \uf03d no \uf029 .\nAlthough in this method, information from each individual user is scrambled, if the number of users is\nsignificantly large, the aggregate information of these users can be estimated with decent accuracy. Randomized\nresponse technique used to provide information with response model, so are used for processing categorical\ndata. Note that the technique can be extended to multi-dimensional, i.e., the techniques are applied to several\ndimensions altogether [23].\nC. Data Mining Task-based Perturbation Techniques\nThe purpose of these techniques is to modify the original data so that the properties preserved in perturbed\ndataset to be task specific information data mining tasks and even a particular model. Thus, it is possible to\npreserve the privacy without missing any particular information of data mining tasks and make a more suitable\nbalance between privacy and data mining results accuracy. Furthermore, in these techniques, data mining\nalgorithms can be applied directly and without developing new data mining algorithms on the perturbed dataset.\n1)\nCondensation Technique\nThe purpose of this technique is to modify the original dataset into anonymized datasets so that this\nanonymized dataset preserves the covariance matrix for multiple columns. In this technique first the data will\nbe condensed into groups with pre-defined size K, and a series of statistical information related to the mean and\ncorrelations across the different dimensions will be preserved for each group of records. In the server, this\nstatistical information is used to generate anonymized data with similar statistical characteristics to the original\ndataset. This technique has been used to create simple classifier for the K Nearest Neighbor (KNN) [14].\nHowever in [15] it is presented that this technique is weak in protecting the private data. The KNN-based\ndata groups result in some serious conflicts between preserving covariance information and preserving privacy.\nRandom Rotation Perturbation Technique\n2)\nThe main idea is as if the original dataset with d columns and N records represented as X d\uf0b4n , the rotation\nperturbation of the dataset X will be defined as G (X ) \uf03d RX . Where R d\uf0b4d is a random rotation orthonormal\nmatrix.\nA key feature of rotation transformation is preserving the Euclidean distance, inner product and geometric\nshape hyper in a multi-dimensional space. Also, kernel methods, SVM classifiers with certain kernels and hyper\nplane-based classifiers, are invariant to rotation perturbation, i.e. if trained and tested with rotation perturbed\ndata, will have similar model accuracy to that trained and tested with the original data. [15].\nBut researches show that having previous knowledge, the random rotation perturbation may become\ninvolved in privacy violations against different attacks including Independent Component Analysis (ICA),\nattack to rotation center and distance-inference attack [16, 17].\nGeometric Perturbation Technique\n3)\nThis perturbation technique is a combination of Rotation, Translation and Noise addition perturbation\ntechniques. The additional components \u03c8 and \u2206 are used to address the weakness of rotation perturbation while\nstill preserving the data quality for classification modeling. Concretely, the random translation matrix addresses\nthe attack to rotation center and adds additional difficulty to ICA-based attacks and the noise addition addresses\nthe distance-inference attack.\nIf the matrix X d \uf0b4n indicates original dataset with d columns and N records, R d\uf0b4d be a orthonormal random\nmatrix, \u03c8 be a translation random matrix and \u0394 d\uf0b4 n be a random noise matrix, where each element is\nIndependently and Identically Distributed (iid) variable like Gaussian distribution N(0,\u03c32), the geometrical\nperturbation will be defined as following [17]:\n\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020 G ( X ) \uf03d RX \uf02b \uf079 \uf02b \uf044 \uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf035\uf029\uf020\n\nDefinition: let t d \uf0b41 represent a random vector and l1\uf0b4n a vector of \"N\" '1's. Matrix \u03c8 is a translation matrix\nT\nif\uf079 \uf03d [t , t , \uf0bc, t ]d \uf0b4n , i.e. \uf079 d \uf0b4n \uf03d t d \uf0b41l n \uf0b41 .\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n866\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\nThis perturbation technique is invariant against geometrical modification and is fixed for Kernel, SVM and\nlinear classifiers. Geometrical perturbation technique also has, rather than Rotation perturbation and\ncondensation, high-great Privacy Preserving guarantees.\n\nD. Dimension Reduction-based Perturbation Techniques\nThe main purpose of these techniques is to obtain a compact representation with reduced-rank to the original\ndataset while preserving dominant data patterns. These techniques also guarantee that both the dimensionality\nand the exact value of each element of the original data are kept confidential.\nRandom Projection Perturbation Technique\n1)\nRandom projection [16] refers to the technique of projecting a set of data points from a high-dimensional\nspace to a randomly chosen lower-dimensional subspace. If the matrix X m\uf0b4n (or Y m\uf0b4 n ) indicates original\ndataset, R n \uf0b4 k ( k \uf03c n ) ( or R k\uf0a2 \uf0b4m (k \uf03c m ) ) be a random matrix such that each entry ri\uf0b4 j of R (or R \uf0a2 ) is\nindependent and identically chosen from some unknown distribution with mean zero and variance \uf073 r2 , the\nColumn-wise Projection G(X) and Row-wise Projection G(Y) will be defined as below:\n\nG (X ) \uf03d\n\n1\n1\nXR , G (Y ) \uf03d\nR \uf0a2Y\nk \uf073r\nk \uf073r\n\n(6)\n\nThe key idea of random projection arises from the Johnson-Lindenstrauss Lemma [18]. According to this\nlemma, it is possible to maintain distance-related statistical properties simultaneously with dimension reduction\nfor a dataset. Therefore, this perturbation technique can be used for different data mining tasks like including\ninner product/Euclidean distance estimation, correlation matrix computation, clustering, outlier detection, linear\nclassification, etc.\nHowever, this technique can hardly preserve the distance and inner product during the modification in\ncomparison with geometric and random rotation techniques. It has been also clarified that having previous\nknowledge about this perturbation technique may be caught into privacy breach against the attacks [17].\nSingular Value Decomposition (SVD) Technique\n2)\nThe SVD [19] is a well-known method of dimension reduction in data mining process. If A n\uf0b4m matrix\nindicates the original dataset, then SVD for data matrix A will be as:\n\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020 A \uf03d U \uf053V T \uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf037\uf029\uf020\n\nWhere U n \uf0b4 n is an orthonormal matrix, V T m\uf0b4 m is an orthonormal matrix and \uf053 n \uf0b4 m is a diagonal matrix\nwhose nonnegative diagonal entries are the singular values in a descending order,\n\u03a3 \uf03d diag \uf0e9\uf0eb\u03c31 , \u03c3 2 , \uf0bc , \u03c3 s \uf0f9\uf0fb\n\n\uf028 s \uf03d min \uf07bm, n\uf07d\uf029\n\n\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf038\uf029\uf020\n\nDue to the arrangement of the singular values in the matrix \u03a3 (in a descending order), the SVD\ntransformation has the property that the maximum variation among the objects is captured in the first dimension.\nSimilarly, much of the remaining variations are captured in the second dimension, and so on. Thus, a\ntransformed matrix with a much lower dimension can be constructed to represent the structure of the original\nmatrix faithfully, defined as below:\nA k \uf03d U k \uf053 kV k T where k \uf03d min \uf028 n , m \uf029\n\n\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf039\uf029\uf020\nT\n\nWhere U k includes first k columns of U, \uf053 k includes first k non-zero singular values, and V k includes the\nfirst k rows of V\n\nT\n\n. The rank of the matrix A k is k.\n\nIn data mining applications the omitted part E k \uf03d A \uf02d A k could be considered as the noise in the original\ndataset. Hence, in many of conditions, mining over the reduced dataset A k can produce better results than\nmining on the original dataset. When this technique is applied for Privacy Preserving purposes, the distorted\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n867\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\ndataset A k can protect the privacy and simultaneously, keeps the utility of the original data as it can faithfully\nrepresent the original data structure. [20].\nNon-negative Matrix Factorization (NMF) Technique\n3)\nNMF [21] is a matrix factorization method to obtain a representation of data using nonnegative constraints.\nConsidering a n \uf0b4 m nonnegative matrix dataset A with Aij \uf0b3 0 and a pre-specified positive integer\nk \uf0a3 min{n , m } , nonnegative matrix factorization (NMF) finds two non-negative matrixes W \uf0ce R n \uf0b4 k with\n\nW ij \uf0b3 0 and H \uf0ce R k \uf0b4m with H ij \uf0b3 0 , such that A \uf0bb W H and the objective function is minimized:\n\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020 f \uf028W , H \uf029 \uf03d\n\n1\nA \uf02dW H F2 \uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf020\uf028\uf031\uf030\uf029\uf020\n2\n\nW and H matrixes have many mostly-desired Properties in data mining applications. In [22] the NMF\ntechnique is used for Privacy Preserving in Data mining applications.\nRecently, accordance with classification algorithms, it has been shown that SVD and NMF provide much\nhigher degree of data distortion than the standard data distortion techniques based on adding uniformly\ndistributed noise or normally distributed noise. Moreover, these techniques consist of a high-level accuracy in\ndata mining results as well as high-level privacy preserving.\nIII. EVALUATION FRAMEWORK\nThe evaluation framework recommended for assessing and evaluating data modification-based techniques, is\nin accordance with the following eight criteria:\n\uf0b7\n\nPrivacy Loss: is defined as difficulty level in estimating the original values from the perturbed data\nvalues.\n\n\uf0b7\n\nInformation Loss: is defined based on the amount of important data information, which needs to be saved\nafter perturbation for data mining purposes.\n\n\uf0b7\n\nData Mining Task: is defined based on a data mining task, which contains the possibility to mine it, after\napplying the privacy preserving techniques.\n\n\uf0b7\n\nModifying the Data Mining Algorithms: based on the needs, notifies the change for the existed data\nmining algorithms, in order to mine over the modified dataset.\n\n\uf0b7\n\nPreserved Property: that is, data information, which was already saved after applying the privacy\npreservation techniques.\n\n\uf0b7\n\nData Type: it points out the types of data, which could be numerical, binary, or categorical.\n\n\uf0b7\n\nIndistinguishability Level: it is in accordance with level of indistinguishability of different records of the\noriginal dataset.\n\n\uf0b7\n\nData Dimension: it is defined based on the purpose of PPDM technique for preserve Dimensional\ninformation, which could be single-Dimensional or Multi-Dimensional.\n\nThe techniques based on data modification in Privacy Preserving Data Mining were already analyzed and\nassessed based on the above-mentioned criteria, as shown in table (1).\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n868\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\nTABLE I.\n\nASSESSMENT FRAMEWORK FOR THE TECHNIQUES BASED ON DATA MODIFICATION IN PPDM\n\nData Modification based Techniques of PPDM\n\nComparison\nCriteria\n\nMulti Dimensional Perturbation\nDimensional Reduction-based\nData Mining Task-based Perturbation\nPerturbation\n\nAnonymization\n\nValue-based Perturbation\n\nkan\n\nNoise\nAddition\n\nRandomized\nResponse\n\nCondensation\n\nRandom\nRotation\n\nGeometric\n\nRandom\nProjection\n\nLdiv\n\nTclo\n\nNMF\n\nSVD\n\nPrivacy Loss\n\nAverage\n\nAverage\n\nAverage\n\nLow\n\nLow\n\nVery Low\n\nVery Low\n\nVery Low\n\nInformation Loss\n\nLow\n\nLow\n\nLow\n\nVery Low\n\nVery Low\n\nVery Low\n\nVery Low\n\nVery Low\n\nModifying DM\nAlgorithms\n\nNo\n\nYes\n\nYes\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\n\u221a\n\nData\nMining\nTask\n\n\u221a\n\nAsso\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\nData Dimension\n\nMultiDimensional\n\nsingleDimensional\n\nSingle\nDimensional\n\nMulti\nDimensional\n\nMulti\nDimensional\n\nMulti\nDimensional\n\nPreserved\nproperty\n\n-\n\nValues\ndistribution\n\nValues\ndistribution\n\nCovariance\nstructure\n\nGeometrical\ncharacteristic\n\nGeometrical\ncharacteristic\n\nMulti\nDimensional\nCorelation\nbetween\ndimension\n\nMulti\nDimensional\nCorelation\nbetween\ndimension\n\nData type\n\n-\n\n-\n\nCategorical\n\nnumerical\n\nnumerical\n\nnumerical\n\nnumerical\n\nnumerical\n\nIndistinguishabil\n_ity Level\n\nk\n\n-\n\n-\n\nk\n\n-\n\n-\n\n-\n\n-\n\nClass\n\n\u221a\n\nClus\n\nIV.\n\nCONCLUSION\n\nIn this paper, a data modification-based framework was presented for classification and evaluation the\nPrivacy Preserving Data Mining techniques. At first, these techniques classified into two classes of\nanonymization and perturbation approaches and after analyzing each approach, their significant characteristics\nwere given. The main challenge of anonymization approach was insufficient protection of critical values\ndeduction against different attacks and being NP-Hard optimal anonymization. Instead, in perturbation process\nalthough it has a great efficiency from computation cost point of view, creating a suitable and stable balance\nbetween privacy and data mining results accuracy in that, is difficult.\nHence how to create a better balance between privacy and accuracy, how to further improve the algorithms\nefficiency and privacy preserving generality in different types and different Data mining tasks are some of the\nresearch aspects in the future.\nREFERENCES\n[1]\n\nStanley R. M. Oliveira, and Osmar R. Za\u00efane1, \"Towards Standardization in Privacy-Preserving Data Mining\", In ACM SIGKDD 3rd\nWorkshop on Data Mining Standards, 2004, pp. 7\u201317.\n[2] P. Samarati and L. Sweeney, \"Protecting privacy when disclosing information: k-anonymity and its enforcement through\ngeneralization and suppression\", In Technical Report SRI-CSL-98-04, SRI Computer Science Laboratory, 1998.\n[3] L. Sweeney, \"k-anonymity: a model for protecting privacy\", International Journal on Uncertainty, Fuzziness and Knowledgebased\nSystems, 2002, pp. 557-570.\n[4] A.Machanavajjhala, J.Gehrke, and D.Kifer, \"l-diversity: Privacy beyond k-anonymity\", In Proc. of ICDE, Apr.2006.\n[5] N. Li, T. Li, and S. Venkatasubramanian, \"t-Closeness: Privacy Beyond k-anonymity and l-Diversity\", In Proc. of ICDE, 2007, pp.\n106-115\n[6] A. Meyerson and R. Williams. \"On the complexity of optimal k-anonymity\", In Proceedings of PODS'04, pages 223\u2013228, New York,\nNY, USA, 2004. ACM.\n[7] C. Aggarwal. \"On k-anonymity and the curse of dimensionality\", In Proceedings of VLDB'05, pages 901\u2013909. VLDB Endowment,\n2005.\n[8] R. Agrawal and R. Srikant. \"Privacy-preserving data mining,\" In Proc. SIGMOD00, 2000, pp. 439-450.\n[9] D. Agrawal and C. Aggarwal. \"On the design and quantification of privacy pre-serving data mining algorithms\", In Proc. of the\nTwentieth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, Santa Barbara, California,USA, May\n2001.\n[10] Rizvi, S. J. & Haritsa, J. R. , \"Maintaining Data Privacy in Association Rule Mining\" . In Proc. of the 28th International Conference\non Very Large Data Bases (VLDB'02), Hong Kong, China, 2002,pp. 682\u2013693.\n[11] Evfimievski, A., Srikant, R., Agrawal, R., and Gehrke, J, \"Privacy Preserving Mining of Association Rules\", In Proc. KDD02, 2002,\npp. 217-228.\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n869\n\n\fMohammadReza Keyvanpour et al. / International Journal on Computer Science and Engineering (IJCSE)\n\n[12] H. Kargupta, S. Datta, Q. Wang, and K. Sivakumar, \"On the Privacy Preserving Properties of Random Data Perturbation\nTechniques,\" Proc. IEEE Int'l Conf. Data Mining, Nov. 2003.\n[13] L. Warner. \"Randomized response: A survey technique for eliminating evasive answer bias,\" The American Statistical Association,\n60(309):63\u201369, March 1965.\n[14] AGGARWAL, C. C., AND YU, P. S. \" A condensation approach to privacy preserving data mining.\" Proc. of Intl. Conf. on\nExtending Database Technology (EDBT) (2004).\n[15] Chen, K., and Liu, L. \"Privacy Preserving Data Classification with Rotation Pertubation\", Proc. ICDM, 2005, pp.589-592.\n[16] K. Liu, H. Kargupta, and J. Ryan, \"Random projection-based multiplicative data perturbation for privacy preserving distributed data\nmining,\" IEEE Transactions on Knowledge and Data Engineering, January 2006, pp. 92\u2013106.\n[17] Keke Chen, Gordon Sun, and Ling Liu. Towards attack-resilient geometric data perturbation.In Proceedings of the 2007 SIAM\nInternational Conference on Data Mining.,April 2007.\n[18] W.B. Johnson and J. Lindenstrauss, \"Extensions of Lipshitz Mapping into Hilbert Space,\" Contemporary Math., vol. 26,pp. 189-206,\n1984.\n[19] Golub GH, van Loan CF (1996) Matrix computations, 3rd edn. John Hopkins University, Columbia, MD\n[20] Xu, S., Zhang, J., Han, D., & Wang, J. (2006). Singular value decomposition based data distortion strategy for privacy protection.\nKnowledge and Information Systems, 10(3), 383-397.\n[21] D. D. Lee and H. S. Seung, \"Algorithms for non-negative matrix factorization,\" In NIPS, Neural Information Processing Systems,\npp:556-562, 2000\n[22] Wang, J., Zhong, W. J., & Zhang, J. (2006). NNMF-based factorization techniques for high-accuracy privacy protection on nonnegative-valued datasets. Proceedings of the IEEE Conference on Data Mining 2006, International Workshop on Privacy Aspects of\nDate Mining (PADM 2006), pp. 513-517, Hong Kong, China.\n[23] W. Du and Z. Zhan. Using randomized response techniques for privacy-preserving data mining. In Proc. of the Ninth ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining, pages 505{510, Washington, DC, USA, August 2003.\n\nISSN : 0975-3397\n\nVol. 3 No. 2 Feb 2011\n\n870\n\n\f"}