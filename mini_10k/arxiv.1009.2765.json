{"id": "http://arxiv.org/abs/1009.2765v1", "guidislink": true, "updated": "2010-09-14T20:15:45Z", "updated_parsed": [2010, 9, 14, 20, 15, 45, 1, 257, 0], "published": "2010-09-14T20:15:45Z", "published_parsed": [2010, 9, 14, 20, 15, 45, 1, 257, 0], "title": "How do Range Names Hinder Novice Spreadsheet Debugging Performance?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1009.6006%2C1009.5595%2C1009.1084%2C1009.4290%2C1009.2869%2C1009.0719%2C1009.5673%2C1009.2704%2C1009.5046%2C1009.3591%2C1009.4911%2C1009.0947%2C1009.1549%2C1009.2891%2C1009.0046%2C1009.0491%2C1009.5284%2C1009.0749%2C1009.4953%2C1009.0951%2C1009.2504%2C1009.1621%2C1009.0858%2C1009.4279%2C1009.2765%2C1009.4239%2C1009.2529%2C1009.0357%2C1009.1686%2C1009.3035%2C1009.1626%2C1009.3603%2C1009.5667%2C1009.4380%2C1009.4047%2C1009.1484%2C1009.4968%2C1009.2404%2C1009.2673%2C1009.1108%2C1009.0271%2C1009.2798%2C1009.3466%2C1009.2645%2C1009.5212%2C1009.2106%2C1009.1785%2C1009.3660%2C1009.5648%2C1009.4130%2C1009.5972%2C1009.4820%2C1009.3160%2C1009.2656%2C1009.4510%2C1009.3462%2C1009.1540%2C1009.3851%2C1009.2071%2C1009.1480%2C1009.0693%2C1009.4173%2C1009.0764%2C1009.3666%2C1009.0167%2C1009.0499%2C1009.0529%2C1009.2829%2C1009.3435%2C1009.0754%2C1009.0351%2C1009.2883%2C1009.0902%2C1009.2802%2C1009.4724%2C1009.0563%2C1009.0149%2C1009.1095%2C1009.1974%2C1009.0286%2C1009.6157%2C1009.0658%2C1009.5083%2C1009.0895%2C1009.1065%2C1009.3229%2C1009.4405%2C1009.3279%2C1009.0244%2C1009.0821%2C1009.5714%2C1009.3860%2C1009.4342%2C1009.0552%2C1009.5202%2C1009.0638%2C1009.0746%2C1009.2091%2C1009.1683%2C1009.1069%2C1009.0188&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "How do Range Names Hinder Novice Spreadsheet Debugging Performance?"}, "summary": "Although experts diverge on how best to improve spreadsheet quality, it is\ngenerally agreed that more time needs to be spent testing spreadsheets.\nIdeally, experienced and trained spreadsheet engineers would carry this out,\nbut quite often this is neither practical nor possible. Many spreadsheets are a\nlegacy, developed by staff that have since moved on, or indeed modified by many\nstaff no longer employed by the organisation. When such spreadsheets fall into\nthe hands of inexperienced, non-experts, any features that reduce error\nvisibility may become a risk. Range names are one such feature, and this paper,\nbuilding on previous research, investigates in a more structured and controlled\nmanner the effect they have on the debugging performance of novice spreadsheet\nusers.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1009.6006%2C1009.5595%2C1009.1084%2C1009.4290%2C1009.2869%2C1009.0719%2C1009.5673%2C1009.2704%2C1009.5046%2C1009.3591%2C1009.4911%2C1009.0947%2C1009.1549%2C1009.2891%2C1009.0046%2C1009.0491%2C1009.5284%2C1009.0749%2C1009.4953%2C1009.0951%2C1009.2504%2C1009.1621%2C1009.0858%2C1009.4279%2C1009.2765%2C1009.4239%2C1009.2529%2C1009.0357%2C1009.1686%2C1009.3035%2C1009.1626%2C1009.3603%2C1009.5667%2C1009.4380%2C1009.4047%2C1009.1484%2C1009.4968%2C1009.2404%2C1009.2673%2C1009.1108%2C1009.0271%2C1009.2798%2C1009.3466%2C1009.2645%2C1009.5212%2C1009.2106%2C1009.1785%2C1009.3660%2C1009.5648%2C1009.4130%2C1009.5972%2C1009.4820%2C1009.3160%2C1009.2656%2C1009.4510%2C1009.3462%2C1009.1540%2C1009.3851%2C1009.2071%2C1009.1480%2C1009.0693%2C1009.4173%2C1009.0764%2C1009.3666%2C1009.0167%2C1009.0499%2C1009.0529%2C1009.2829%2C1009.3435%2C1009.0754%2C1009.0351%2C1009.2883%2C1009.0902%2C1009.2802%2C1009.4724%2C1009.0563%2C1009.0149%2C1009.1095%2C1009.1974%2C1009.0286%2C1009.6157%2C1009.0658%2C1009.5083%2C1009.0895%2C1009.1065%2C1009.3229%2C1009.4405%2C1009.3279%2C1009.0244%2C1009.0821%2C1009.5714%2C1009.3860%2C1009.4342%2C1009.0552%2C1009.5202%2C1009.0638%2C1009.0746%2C1009.2091%2C1009.1683%2C1009.1069%2C1009.0188&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Although experts diverge on how best to improve spreadsheet quality, it is\ngenerally agreed that more time needs to be spent testing spreadsheets.\nIdeally, experienced and trained spreadsheet engineers would carry this out,\nbut quite often this is neither practical nor possible. Many spreadsheets are a\nlegacy, developed by staff that have since moved on, or indeed modified by many\nstaff no longer employed by the organisation. When such spreadsheets fall into\nthe hands of inexperienced, non-experts, any features that reduce error\nvisibility may become a risk. Range names are one such feature, and this paper,\nbuilding on previous research, investigates in a more structured and controlled\nmanner the effect they have on the debugging performance of novice spreadsheet\nusers."}, "authors": ["Ruth McKeever", "Kevin McDaid"], "author_detail": {"name": "Kevin McDaid"}, "author": "Kevin McDaid", "arxiv_comment": "14 Pages, 6 Tables", "links": [{"href": "http://arxiv.org/abs/1009.2765v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.2765v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.2765v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.2765v1", "journal_reference": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 47-60\n  ISBN 978-1-905404-50-6", "doi": null, "fulltext": "How do Range Names Hinder Novice\nDebugging Performance?\n\nRuth McKeever, Kevin McDaid\nDundalk Institute of Technology,\nDundalk, Ireland.\ncatherineruth.mckeever@dkit.ie, kevin.mcdaid@dkit.ie\n\nABSTRACT\nAlthough experts diverge on how best to improve spreadsheet quality, it is generally agreed that\nmore time needs to be spent testing spreadsheets. Ideally, experienced and trained spreadsheet\nengineers would carry this out, but quite often this is neither practical nor possible. Many\nspreadsheets are a legacy, developed by staff that have since moved on, or indeed modified by\nmany staff no longer employed by the organisation. When such spreadsheets fall into the hands of\ninexperienced, non-experts, any features that reduce error visibility may become a risk. Range\nnames are one such feature, and this paper, building on previous research, investigates in a more\nstructured and controlled manner the effect they have on the debugging performance of novice\nspreadsheet users.\n\n1 INTRODUCTION\nThe collapse of financial systems worldwide has brought the lack of regulation to the\nforefront of public anxiety. In many cases spreadsheet errors have caused significant\nfinancial losses for organisations, leading to market uncertainty. One example of this is\nthe case of C&C (EuSpRIG 2010) where shares fell 15% \"after data were incorrectly\ntransferred from an accounting system used for internal guidance to a spreadsheet used to\nproduce the trading statement.\" Such occurrences establish the need for protocols and\nbest practices to reduce these errors, and for increased awareness of how often errors\noccur. Panko (2003) notes, \"In spreadsheeting, developers who do not do comprehensive\nerror checking are rewarded both by finishing faster and by avoiding onerous testing\nwork.\"\nAt EuSpRIG'09 a paper (McKeever, McDaid et al. 2009) was presented that challenged\nthe commonly held view that range names improve the quality and understandability of a\nspreadsheet. The motivation for this study was a lack of empirical evidence to support\nthese views. The authors questioned several aspects of range names, including how they\nare viewed by academia and industry, if they are used in practice, and how they affect the\ndebugging performance of novice spreadsheet users. This publication created\nconsiderable debate on the risks associated with prescribing techniques that had not been\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\ftried and tested. It also raised concerns about the appropriate use of names, and whether\nthe trial accurately reflected how names are used in practice.\nThe findings of this exploratory study show a decrease in the ability of novices to identify\nand correct formula errors in a spreadsheet when range names are used extensively. The\nfeedback indicates that the level of use of names may have been too high, and the new\nstudy seeks to establish if the problems identified with range name usage continue to\noccur when the volume of names in the spreadsheet are kept to a minimum. Based on the\nresults and feedback from the initial study the new trial was modified to tackle the\nlimitations and issues raised. It was then carried out on two groups of computing students\nin order to conduct a more comprehensive study of novice spreadsheet users. The results\nof this controlled experiment are in keeping with the findings of the exploratory\nexperiment, and go further towards dispelling the notion that named ranges make\nspreadsheets easier for novice users.\nIn a spreadsheet, a range is defined as a cell or group of cells. A range name is a name\ngiven to a range, which can then be used throughout the workbook in place of the cell\nreferences. In addition to cells, the developer can also name constants, and use this name\nas they would use a variable in software code. The main advantage of this for the\ndeveloper is that they can change what the name refers to in one place instead of trawling\nthrough all the formulas in which it is referred to. In addition, it is believed that by\nreplacing a cell reference with a meaningful name it will make the formula more\nunderstandable to the user.\nNames are a powerful feature of Excel, and used properly can prove very useful to\ndevelopers. For example, Grossman et al. (2009) show how range names can be used to\nreplace complex nested-if formulas with the lookup technique. As nested-if formulas are\nconsidered risky, the lookup technique uses names to make the logic required simpler,\nmore visible and therefore less risky.\nTo name a range the user highlights the range then enters a name in the name box (the\nbox above and to the left of the worksheet that normally contains the reference of the cell\nthat is currently in focus). To modify or delete this name, or to create a named constant,\nthe developer must use the name manager, contained in the formula section of the Excel\n2007 ribbon. This also provides the facility to insert a descriptive comment for the name.\nTo access a named range in a workbook the user may either choose from the list of names\nin the name box, or use the F5 key to bring up a list of names contained in the workbook.\nThis does not work for constants, however, as they are not linked to cells in the workbook\nand must be accessed through the name manager.\nSeveral commercial tools exist that provide extensive support for range names. One such\ntool is OAK (OPERIS Analysis Kit) (OPERIS 2009): \"OAK can get rid of the names,\nleaving a coordinate-only version of the model to be checked\". Spreadsheet Detective\n(Berglas and Berglas) also contains several useful functions for working with range\nnames, including annotate which displays a box above each formula cell showing what\neach name refers to, and precedent/dependent dialog which allows the user to navigate\nthrough cell precedents and dependents.\nRange names are advocated by many in both academia and industry, including the SSRB\n(Spreadsheet Standards Review Board) (BPM Analytical Empowerment 2005), and\nMicrosoft (Microsoft 2006), (Microsoft 2008). Examples of such advice can be found as\nfar back as 1986 (Bromley 1986). Bewig (2005) advocates the proper construction of\nrange names for eliminating the problem of referring to the wrong cell while constructing\nformulas, and states that \"well-chosen names are the first and best form of\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fdocumentation.\" Campbell (2009) recommends \"To allow for easily-adapted\nspreadsheets, make sure nothing is hard-coded in terms of locations \u2013 any cells being\nused in formulas should be referred to as named ranges.\" Kruck (2006) describes a\nformula using names that \"will be easier to understand and maintain for future\ndevelopers\". Many of the popular spreadsheet advice websites also advise users on how\nto use range names, such as (Pearson 2009), (Ozgrid 2008) and (MrExcel 2007).\nNot all experts are convinced about the merits of range names. Panko and Ordway (2005)\nrecognise the risk that range names may appear correct, while actually referring to the\nwrong range, warning that \"although the research findings are not clear on this issue,\nusing range names should be considered potentially dangerous until research on using\nrange names is done\". Blood (2006) also lists several additional problems with range\nnames, such as increasing the length of formulas, and creating \"ghost\" links when a sheet\nis copied to another workbook. Butler (2000) describes a risk assessment methodology\ndeveloped by HM Customs & Excise in response to the material quantitative errors found\nin 10% of spreadsheets tested that belong to taxpayers. This methodology identifies range\nnames as a high-risk feature, along with macros and hidden rows/columns, when\nassessing the risk of the application.\n1.1 Overview\nSection 2 describes the exploratory experiment that this study extends. Section 3 details\nthe methodology, rollout and results of the experiment central to this new work. Section 4\ndiscusses the results and limitations of this study. Section 5 details future work arising\nfrom this study, and Section 6 concludes the paper.\n2 SUMMARY OF EXPLORATORY STUDY\nThe studies described here are based on an experiment originally designed by Howe and\nSimkin (2006), and used by Bishop and McDaid (2007). It involves asking a group of\nstudents to examine a spreadsheet and to correct any errors that they find. The main\nadvantage of using a well-established experiment for testing a new theory is that there is\nexisting data with which to compare the findings.\nThe exploratory study as detailed by McKeever et al. (2009) analyses how a group of 21\nstudents in their second year of a computing degree in Dundalk Institute of Technology\nperform debugging a spreadsheet seeded with errors that was developed to include named\nranges. The results of the experiment are then compared with an earlier experiment\n(Bishop and McDaid 2007), developed without named ranges, carried out on 34 second\nyear accounting and finance students. These experiments are identical in format, except\nfor the inclusion of named ranges in the 2009 trial. The spreadsheet contains 42 seeded\nerrors, categorised as clerical/non-material (4), rule violation (4), data entry (8) and\nformula (26). The formula errors are further divided into logic (9), cell reference (7),\nrange reference (7) and remote reference (3). A recording tool is used in these trials to\ntrack the cells entered by the user, the time spent in each cell, and any changes made to\nthe spreadsheet.\n2.1 Results\nThe results of the exploratory study revealed that both groups had performed almost\nidentically when correcting the first three categories of errors, but the group that used\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fnamed ranges corrected significantly fewer formula errors. This was true for all subcategories of formula errors, but was most pronounced for cell and range reference\nerrors. These results are shown in Table 1.\nWhile the experiment group performed worse in all the formula sub-categories, the\ngreatest difference was with Range and Cell reference errors, and these were the\nonly groups where the results were statistically significant at a 5% level based on a\nnon-parametric rank sum test. In each case of these types of error the control group\nperformed better than the experiment group. (McKeever, McDaid et al. 2009)\n\nError Type\n\nNo of Seeded\nErrors\n\n% Corrected\nby Named\nGroup\n\n% Corrected\nby Unnamed\nGroup\n\nNamed\nCompared to\nUnnamed\n\nClerical/NonMaterial\n\n4\n\n11%\n\n11%\n\n0%\n\nRule Violation\n\n4\n\n63%\n\n65%\n\n-2%\n\nData Entry\n\n8\n\n64%\n\n63%\n\n1%\n\n26\n\n44%\n\n63%\n\n-19%\n\nLogic\n\n9\n\n54%\n\n63%\n\n-9%\n\nCell\n\n7\n\n39%\n\n68%\n\n-29%\n\nRange\n\n7\n\n47%\n\n71%\n\n-24%\n\nRemote\n\n3\n\n19%\n\n28%\n\n-9%\n\nFormula\n\nTable 1 \u2013 Exploratory Study Results\n\n2.2 Discussion\nAnalysis of the possible explanations for the differences in performance focussed on the\nfollowing three possible causes.\nHigh cognitive load: Cognitive overload occurs when a person is overwhelmed with\ninformation, and cannot take it all in. Working with spreadsheets requires a high level of\nworking-memory cognitive skills, such as memory load (Kruck, Maher et al. 2003). A\nrange name is an additional piece of information that the user must remember. As the\nparticipants were unlikely to remember what each name referred to, they would have to\nperform two checks, one to see if the correct name was used and another to see if the\nname referred to the correct range. This theory is difficult to measure, but its impact can\nbe assessed by examining the correction rates of errors caused by incorrect use of names\nand errors in cells that contain names, with formula errors in cells that do not contain\nnames. Kruck et. al. (2003) found that spreadsheet training improves logical reasoning\ncognitive skills, and this decreases error rates. Tukiainen (2001) evaluated spreadsheet\ncalculation under the cognitive dimensions questionnaire and found that \"when asked\nwhat kind of things are more difficult to see or find, most of the subjects mention\nformulae or referencing of the cells in formulae.\" Range names add another layer of\nconcealment to already hidden formulae.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fToo much confidence in names: There was some evidence that if there was more than one\nname used in a formula then the participant, once satisfied that the first name was correct\ndidn't bother to check subsequent names. Overconfidence is recognised as a serious issue\nin spreadsheet development (Panko 2003), and this finding indicates that range names\nincrease the trend.\nDid not understand the error/did not know how to correct it: Although this was\ninvestigated as a possible cause, this was not supported by the results. If a participant\nmade one or more attempts to fix an error they tended to succeed, indicating that they\nknew how to correct the errors identified. The participants had also been observed\ncompleting a tutorial on named ranges before the trial, to ensure they could complete the\ntask.\n2.3 Limitations\nWhile for the purposes of an exploratory study the use of a different experiment group for\ncomparison was deemed sufficient, the use of a control group would considerably\nimprove the legitimacy of these results.\nThe spreadsheet contains 152 range names. This is considered excessive and not realistic,\nas is the length of many of the names (e.g. VariableExpensesTotalYearEstimate). This\nmay increase the cognitive load on the participants. Another problem identified with this\nextensive use of names is that in some cases it becomes impossible to copy formulas\ndown a column. This reduces the convenience of spreadsheets as a modelling tool.\nBefore commencing the trial, the participants were given a tutorial on how to name\nranges, and how to edit those names. This may have influenced their opinion of names\nand impressed upon them the advantages of naming. This could explain the finding of\noverconfidence.\nAs these limitations may exaggerate the causes identified, they are addressed in the new\nversion of this trial, as described in this paper.\n2.4 Hypotheses\nA new study was planned to reassess the findings of the exploratory study, overcome the\nlimitations, and investigate a further set of more detailed hypotheses. The overall\nhypothesis is as follows:\nNovice debuggers perform less well in correcting formula errors in a spreadsheet that\ncontains range names.\nThis will be investigated by exploring the types of range name and non-range name errors\nin formulas through the following more detailed hypotheses:\nH1: Novice debuggers perform less well in correction of cell formulas where the error is\ndue to the wrong range being assigned to a name, than if a name is not used in the\nformula.\nH2: Novice debuggers perform less well in correction of cell formulas where the error is\ndue the wrong range name being used in a formula, than if a name is not used in the\nformula.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fH3: Novice debuggers perform less well in correction of cell formulas where the formula\ncontains a name, but the error is not due to the name.\nH4: Novice debuggers perform less well in correction of cell formulas, where there are\nno names in the formula, but names in the spreadsheet.\nNote that the above represent four distinct hypotheses and, in the context of the\nexperiment described and associated statistical analysis, these represent the form of the\nalternative hypotheses with the null hypotheses stating that there is no difference in\nperformance.\n3 EXPERIMENT\nThe exploratory experiment allows the authors to frame a controlled study around a more\ndetailed set of hypotheses and to overcome the limitations as discussed. This controlled\nstudy is kept largely the same as the original, but with the number of names reduced, and\nwas performed on Computing students in Dundalk Institute of Technology.\n3.1 Methodology\nHypotheses\nErrors due to range names can be divided into two categories: first are the errors that\noccur when the wrong data or range is assigned to a name; second are the errors that\noccur when the wrong name is used in a formula. In the first case it is clear that names\nactively hide the error. This increases the cognitive load on the user and may lead to a\nlower discovery rate. The second case, where the wrong name is used, may well result in\na better performance by debuggers \u2013 as the error may be more visible due to the fact that\nthe main advantage of names is that that they make explicit to the user what is happening\nin the formula. If user fails to spot this type of error it may indicate overconfidence. In\naddition to these categories of errors, this trial also contains both formula errors that are\nthemselves not related to names, but are in a cell or formula that contains one or more\nnames, and formula errors that occur in a cell that does not contain range names.\nHypotheses 1 through 4 will be addressed by comparing the correction rates for relevant\nerrors, between the experiment and control groups.\nH1: Novice debuggers perform less well in correction of cell formulas where the error is\ndue to the wrong range being assigned to a name, than if a name is not used in the\nformula. This occurs in four errors, numbered 27, 28, 29 and 37. If this is confirmed it\nwill support the theory that cognitive load is increased by the use of names and that\nnames have a negative impact on the debugging performance of novice spreadsheet users.\nH2: Novice debuggers perform less well in correction of cell formulas where the error is\ndue the wrong range name being used in a formula, than if a name is not used in the\nformula. This occurs in two errors, 18 and 35. If this is confirmed it will suggest that\noverconfidence is an issue, as these are the errors that names are supposed to make most\nobvious.\nH3: Novice debuggers perform less well in correction of cell formulas where the formula\ncontains a name, but the error is not due to the name. Three formula errors occur under\nthese circumstances, 13, 33 and 36. If this is proven it will indicate that names distract the\nuser from other possible errors.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fH4: Novice debuggers perform less well in correction of cell formulas, where there are\nno names in the formula, but names in the spreadsheet. There are 13 errors in the trial\nspreadsheet that are neither caused by, nor in the same cell as, a name. If this hypothesis\nis proven it will suggest that either the inclusion of names distracts the user from\ndebugging the entire spreadsheet, or that the inclusion of names makes the user overconfident in the whole spreadsheet.\nDesign\nThe following changes were made to the design of the exploratory experiment, in order to\naddress the limitations identified:\n\u2022\n\u2022\n\u2022\n\nA control group was used to improve the validity of this experiment.\nThe number and length of names in the experimental workbook were reduced.\nThe students were not given a tutorial on naming ranges.\n\nThe number of errors was reduced from 42 to 39. One error was removed each from the\ncontrol group, and the experiment group, as these errors were not comparable between\nthe groups. This brings the total error count down to 38, as categorised in Table 2. This\nreduction in errors is partly due to a reassessment of what constitutes an error. Previously\neach cell that contained an error was considered to be an error. Each error is now\nconsidered independently, as a single error can occur in more than one cell, and a cell can\ncontain more than one error. The results for this study are based on the 38 individual\nerrors.\nThe number of names was reduced from 152 to 12 - 10 named cells and 2 named\nconstants. This reduces the cognitive load, as there are fewer names to consider. On\nreviewing the literature on naming in software development it was decided to use full\nwords when naming ranges, carefully chosen to provide information to the user. Rowe\n(1985) describes good names as \"evocative, and which conjure up distinctive\ncharacteristics of what is being named.\" Abbreviations are not used, as they would\nrequire domain knowledge for the user. Any names that could prevent the user from\ndragging a formula down a column or across a row were also removed, and arrays were\nnot used. It is the belief of the authors that this spreadsheet is a more accurate reflection\nof how a developer might use names in practice.\nThe students were not given a tutorial on range names as their lecturer confirmed that\nthey had been taught how to use them, although they were reminded how to access the\nname manager. The advantages of names were not impressed on them at the time of the\ntrial, in order to reduce overconfidence.\nSampling\nThe redesigned experiment was conducted on two groups of computing students in a\nDundalk Institute of Technology computer laboratory. The first group was made up of 14\nstudents; the second group, 15. To ensure the validity of the research, each participant\nwas assigned randomly to a control or experiment group.\nMaterials\nEach student was given an instructions sheet detailing the rules and assumptions that the\ndata in the spreadsheet was expected to follow, a consent form following the DkIT ethics\nguidelines, and the spreadsheet model for the experiment. The spreadsheet model\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fcontained T-CAT, a \"time-stamped cell activity tracking tool\", (Bishop and McDaid\n2008) to monitor their cell clicks, changes and times.\nProcess\nThe students were given a brief introduction to the research, talked through enabling\nmacros in Excel settings, and shown where to find the name manager. The instructions\nand consent sheet were distributed to the participants, and the workbook required for the\nexperiment was saved to each of their PCs, according to whether they were part of the\ncontrol or experiment group. Each participant renamed the workbook to their own name,\nand when they had completed the task the workbooks were collected, along with signed\nconsent forms.\nMethod of Analysis\nThe resulting workbooks were processed through a macro that looked at the values in all\nerror cells, to deduce if the participant had correctly identified and corrected the error.\nThe values in the cells that were returned as incorrect were manually examined to\nestablish if the participant had used an unexpected way to correct the error. From the first\ngroup of students there were no results for one student, assigned to the experiment group,\nas he had returned an incorrect workbook. Another student from this group, assigned to\nthe control group, failed to interact properly with the task, and found only one error\ndespite making many changes to the spreadsheet; this data was removed from the overall\nresults.\n3.2 Results\nOverall the control group corrected 66% of errors and the experiment group corrected\n59% of errors, i.e. the experiment group found 6% fewer errors than the control group.\nWhen this is divided into error categories, the experiment group performed consistently\nworse at finding formula errors. This data is shown in Table 2.\nError Type\n\nNo. Of Experiment Control Difference P-Value\n(1 Sided Rank\nErrors\nSum Test)\n\nClerical\n\n4\n\n23%\n\n28%\n\n-4%\n\n0.26\n\nRule Violation\n\n4\n\n71%\n\n60%\n\n11%\n\n0.81\n\nData Entry\n\n8\n\n63%\n\n66%\n\n-4%\n\n0.29\n\nFormula - Logic\n\n6\n\n73%\n\n82%\n\n-9%\n\n0.14\n\n- 7\n\n69%\n\n84%\n\n-15%\n\n0.12\n\nFormula - Name\n\n9\n\n51%\n\n60%\n\n-9%\n\n0.16\n\nAverage\n\n38\n(Total)\n\n59%\n\n66%\n\n-6%\n\n0.05\n\nFormula\nReference\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fTable 2 - Error Correction Rates\n\nIt is interesting to note that participants in the experiment group performed worse on all\nformula errors (logic errors -9%, and cell, range and remote reference errors -15%), not\njust errors involving names. This is in keeping with the findings of the exploratory study.\nThe results of the errors that specifically relate to names, and are directly comparable\nbetween the control and experiment groups, also reveal that the experiment group found\n9% fewer errors (control group: 60%, experiment group: 51%). Name errors are defined\nas those where an incorrect range is assigned to a name, a name is used incorrectly in a\nformula, or an error occurs in a formula that also uses a name.\nH1 is dependent on the correction rates of errors, 27, 28, 29 and 37, as shown in Table 3.\nWhile the experiment group performed consistently worse than the control group in these\nerrors, they did not perform as badly as expected, based on the results of the exploratory\nstudy. It appears that the reduction of names in this trial had a positive effect in this\nrespect. Although the difference in correction rates for each error is not statistically\nsignificant (p-value 0.46), it provides weak support for the hypothesis. Any support for\nthis hypothesis would say that high cognitive load impacts on the experiment groups'\nperformance, as these are the errors that require a double check, one to ensure the correct\nname is used, and another to see if the name refers to the correct range.\n\nError No.\n27\n28\n29\n37\nAverage\n\nWrong range assigned to name\nLocation\nExperiment\nControl\nOffice Expenses F10\n43%\n50%\nOffice Expenses F18\n79%\n80%\nOffice Expenses F20\n36%\n40%\nProjections B9/B10\n36%\n40%\n48%\n53%\n\nDifference\n-7%\n-1%\n-4%\n-4%\n-4%\n\nTable 3 - Hypothesis 1 Errors\n\nH2 depends on the correction rates of errors 18 and 35, as shown in Table 4. The\nexperiment group performed 34% worse than the control group on Error 18. This error\noccurred when the formula \"=Subtotal_A+Subtotal_B+Subtotal_B\" was entered instead\nof \"=Subtotal_A+Subtotal_B+Subtotal_C\". This repeats a finding from the exploratory\nexperiment that if there is more than one name in a formula the participant will not\ncontinue to search for errors beyond the first name. In stark contrast to this result, the\nexperiment group performed 27% better at identifying error 35. This error occurred when\ntwo names were entered in the wrong order in cells one above the other. While this looks\nlike a positive result, every participant of the experiment group failed to identify the\nsecond error in the same cells (Error 36, shown in Table 5). This is in keeping with the\nfindings of the exploratory experiment, where no participants corrected both errors. This\nappears to be linked to over-confidence, as once the experiment group had identified one\nerror they stopped looking for others, although this is not peculiar to spreadsheets\ncontaining names.\nWhile the results of these errors provide very limited support for Hypothesis H2 (again\nnot statistically significant), they might suggest that when a formula contains a name\nerror the user can be distracted from identifying other errors in the same cell. Nonetheless\nthis result does not conclude, as one might expect, that range names would help users to\ndebug formulas. More studies need to be carried out to support this finding, using more\nexamples of these types of errors.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fError No.\n18\n35\nAverage\n\nWrong name used in formula\nLocation\nExperiment\nControl\nPayroll I6\n36%\n70%\nProjections B19/B20\n57%\n30%\n46%\n50%\n\nDifference\n-34%\n27%\n-4%\n\nTable 4 - Hypothesis 2 Errors\n\nH3 is illustrated by three errors: 13, 33 and 36. These errors are unrelated to names, but\nwhich occur in cells that also contain names, and are shown in Table 5. While all these\nerrors show that the experiment group performed worse, errors 13 and 33 have a high\ncorrection rate to begin with. The low correction rate for error 35 can be in part explained\nby the occurrence of two errors in the cell, as shown in Table 4. The difference in\nperformance is statistically significant (p-value = 0.04) and thus the results support both\nthe hypothesis and the theory that names increase over-confidence, as the participants\nwere less likely to look for other errors if a name was contained in the cell.\nError No.\n13\n33\n36\nAverage\n\nOther formula errors in cells that also contain names\nLocation\nExperiment\nControl\nDifference\nPayroll G11\n86%\n90%\n-4%\nProjections B17\n86%\n100%\n-14%\nProjections B19/B20\n0%\n40%\n-40%\n57%\n77%\n-20%\nTable 5 - Hypothesis 3 Errors\n\nH4 depends on all the other formula errors in the spreadsheet. These are shown in Table\n6. In ten out of thirteen cases the experiment group performed worse than the control\ngroup and the difference in performance is statistically significant (p-value = 0.04). Note\nthat the p-values throughout this paper are based on a one-sided rank sum test as it is\njudged that an assumption of normality may be unrealistic for this discrete data. The\nresult provides strong support for Hypothesis H4.\nError No.\n8\n9\n10\n11\n12\n14\n15\n16\n17\n25\n26\n38\n40\nAverage\n\nOther formula errors in cells that do not contain names\nLocation\nExperiment\nControl\nDifference\nPayroll F9\n57%\n90%\n-33%\nPayroll F10\n93%\n90%\n3%\nPayroll F11\n57%\n80%\n-23%\nPayroll G6\n57%\n80%\n-23%\nPayroll G7\n43%\n80%\n-37%\nPayroll G16\n79%\n90%\n-11%\nPayroll H16\n79%\n90%\n-11%\nPayroll I10\n79%\n80%\n-1%\nPayroll I14\n71%\n80%\n-9%\nOffice Expenses E8\n64%\n90%\n-26%\nOffice Expenses F5\n86%\n80%\n6%\nProjections G17\n93%\n70%\n23%\nProjections G22\n64%\n80%\n-16%\n71%\n83%\n-12%\nTable 6 - Hypothesis 4 Errors\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\f4 DISCUSSION\nOne of the main issues with the first exploratory experiment was the over-use of names in\nthe workbook, and the length of those names. This may have contributed to the\nparticipants' confusion, and distracted them from finding the errors. Furthermore the\nselection of a different study for the control group was not ideal.\nIn this experiment we have addressed these issues. We have also tested hypotheses\nregarding debugging performance for four scenarios regarding names and errors in\nformulas.\nDespite significantly reducing the number of names in the workbook, and the length of\nthe names, the experiment group still performed worse than the control group at\nidentifying and correcting formula errors. Furthermore the group performed worse in the\ncorrection of errors in formulas including names and formulas not including names. An\nobvious statement may be that the participants performed poorly across all categories of\nformula errors because of a lower ability. However, participants were randomly assigned\nto groups and, importantly, their performance in the other categories of clerical, rule\nviolation and data entry error was broadly similar, indicating equal ability.\nBased on the first experiment it was considered that the poor performance of the\nexperiment group may be due to three possible factors: high cognitive load, over\nconfidence and insufficient knowledge. Insufficient knowledge was dismissed as a factor,\nafter extensive analysis of the results, including analysis of time and attempts made to\ncorrect errors.\nThrough the hypotheses presented, this experiment provides some support for the first\ntwo possible causes: high cognitive load, and over-confidence. In particular, the finding\nthat the inclusion of names seems to distract the user supports the high cognitive load\ntheory. Names hide errors, and are simply another detail that has to be remembered by the\nuser.\nThe results of the errors show that range names do not improve debugging performance,\nand go some way towards supporting the hypotheses. This indicates that the greatest\nproblems with names lie not in their implementation, but in the effect their inclusion has\non users' perception of the spreadsheet.\n4.1 Limitations\nThis study was conducted on novice spreadsheet users, with a background in computing,\nand can therefore only be applied to such users, although previous experiments have\nshown that the performance of computing students is very similar to that of accounting\nand finance students (Bishop and McDaid 2007; Bishop and McDaid 2008).\nThere are two errors in this experiment that cannot be compared between the two groups;\none in the experiment workbook (Error 30), the other in the control (Error 34) workbook.\nThis was an oversight and will be rectified in any future iterations of this experiment.\nOne problem identified with the name errors seeded in this trial is that these errors have a\nparticularly low correction rate across all trials. Only 56% of the participants in (Bishop\nand McDaid 2007) corrected these errors, compared with 69% who corrected the\nremaining formula errors. Likewise, only 37% of the participants in (McKeever, McDaid\net al. 2009) corrected these errors, while 52% corrected the remaining formula errors.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fHowever, this study examines difference in performance between groups rather than\nactual performance of groups.\n5 FUTURE WORK\nThe big question that has yet to be addressed is how professionals perform when\ndebugging spreadsheets that use named ranges. One of the main purposes of this\nexperiment was to improve the design to a stage where it is worthwhile rolling out to\nprofessionals. The following hypothesis will be addressed in the next phase of this\nresearch:\nProfessional debuggers perform less well in correcting formula errors in a spreadsheet\nthat contains range names.\nThis experiment will be distributed to a group of experts, possibly by email, and the same\nanalysis performed. The results will be compared with those from the novice groups. A\ncontrol group is vital here as it is to be expected that experts will find more errors than\nnovices overall. This hypothesis will be confirmed if the difference in correction rates\nbetween the professional control and experiment groups is comparable to the difference\nin correction rates between the novice control and experiment groups.\nAnother aspect that has not been looked at is how the participants rate their debugging\nskills. Any future experiments will include questionnaires to measure how confident the\nparticipants are in the accuracy of their debugged spreadsheet.\nAn experiment to investigate whether names have an impact on error rates during\ndevelopment is planned. This will establish if spreadsheet engineers should be advised to\ndevelop using names, but remove them before the spreadsheet is used.\n6 CONCLUSION\nBuilding on the paper presented at EuSpRIG'09 (McKeever, McDaid et al. 2009), this\nwork describes a well structured and controlled experiment that provides additional\nsupport for the theory that named ranges make it more difficult for novices to debug\nspreadsheets. The structure is provided through four hypotheses linked to types of\nformula errors.\nThe study provides strong (statistically significant) evidence to support the hypotheses\n(H3 & H4) that the inclusion of range names in a spreadsheet impacts negatively on the\nperformance of novice debuggers even for formulas where the error is not due to an error\nin a range name.\nFor the hypotheses (H1 & H2) where the error is due to an error in a range name the\nevidence to support the claim is not as strong. Although the results were not statistically\nsignificant, it can be said that the experiment certainly does not provide support for the\nargument that range names help novices to debug formulas with range names. In this\ncontext, this contradicts the claim that range names make spreadsheets easier to\nunderstand.\nThe results of this trial are consistent with the results of the original exploratory study.\nRemoving a large volume of names marginally improved the debugging rate, but not to\nthe level of the control groups. This dispels the idea that it is just the misuse and overuse\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fof names that cause novice debuggers to find fewer errors, although these issues clearly\nhave an impact.\nIt is our belief that it is simply not sufficient to reduce names; they should be eliminated\naltogether unless absolutely necessary. Range names simply do not help novice\ndebuggers. While over-confidence and high cognitive load may be a problem inherent to\nspreadsheets, they are clearly exacerbated by range names. There is technology that\nreplaces range names with the base range and it is our belief that this should be used for\ndebugging by novices.\nFinally, our attention will now turn to experts and their performance and behaviour when\ndebugging spreadsheets that contain range names.\nREFERENCES\nBerglas, M. and A. Berglas The Spreadsheet Detective.\nBewig, P. L. (2005). How do you know your spreadsheet is right? Principles, Techniques and Practice of\nSpreadsheet Style.\nBishop, B. and D. K. McDaid (2007). An Empirical Study of End-User Behaviour in Spreadsheet Error\nDetection & Correction. European Spreadsheet Risk Interest Group.\nBishop, B. and K. McDaid (2008). Spreadsheet End-User Behaviour Analysis. European Spreadsheet Risk\nInterest Group. D. Ward. University of Greenwich, London.\nBlood, A. T. (2006). \"Elements of Good Spreadsheet Design: Spreadsheet Design Notes.\" Retrieved May\n2009 from http://www.xl-logic.com/modules.php?name=Content&pa=showpage&pid=2.\nBromley, R. G. (1986). \"Micros in Accounting Template design an review: how to prevent spreadsheet\ndisasters.\" Journal of Accountancy.\nButler, R. J. (2000). Is This Spreadsheet a Tax Evader ? How H. M. Customs & Excise Test Spreadsheet\nApplications. 33rd Hawaii International Conference on System Sciences.\nCampbell, M. P. (2009). \"The End Users Justify the Means: II The Wrath of Numerate Decision-Makers.\"\nCompAct(30).\nEmpowerment, B. A. (2005). Best Practice Spreadsheet Modelling Standards.\nEuSpRIG. (2010). \"EuSpRIG Horror Stories.\" Retrieved 5th March 2010, from\nhttp://www.eusprig.org/horror-stories.htm.\nGrossman, T. A., \u00d6. r. \u00d6zl\u00fck, et al. (2009). The Lookup Technique to Replace Nested-IF Formulas in\nSpreadsheet Programming. EuSpRIG.\nHowe, H. and M. G. Simkin (2006). \"Factors Affecting the Ability to Detect Spreadsheet Errors.\" Decision\nSciences Journal of Innovative Education 4(1): 101-122.\nKruck, S. E. (2006). \"Testing spreadsheet accuracy theory.\" Information and Software Technology 48.\nKruck, S. E., J. J. Maher, et al. (2003). \"Framework for Cognitive Skill Aquisition and Spreadsheet Training.\"\nJournal of End User Computing 15(1): 20-37.\nMcKeever, R., K. McDaid, et al. (2009). An Exploratory Analysis of the Impact of Named Ranges on the\nDebugging Performance of Novice Users. European Spreadsheet Risk Interest Group Conference.\nParis, France.\nMicrosoft (2006). Spreadsheet Compliance in the 2007 Microsoft Office System.\nMicrosoft. (2008). \"Define and use names in formulas.\" Retrieved November 18, 2008, from\nhttp://office.microsoft.com/en-gb/excel/HA101471201033.aspx?pid=CH100648431033.\nMrExcel. (2007). \"Episode # 626 - VBA Anming Ranges.\" Retrieved December 8, 2008, from\nhttp://www.mrexcel.com/Excel_VBA_Naming_Ranges_training.html.\nOPERIS (2009). Operis Analysis Kit.\nOzgrid. (2008). \"Named Ranges.\" Retrieved March 24, 2010, from http://www.ozgrid.com/Excel/namedranges.htm.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\fPanko, R. R. (2003). Reducing Overconfidence in Spreadsheet Development. European Spreadsheet Risks\nInterest Group.\nPanko, R. R. and N. Ordway (2005). Sarbanes-Oxley: What About all the Spreadsheets? Controlling for\nErrors and Fraud in Financial Reporting. EuSpRIG.\nPearson, C. H. (2009, June 6 2009). \"Defined Names.\" Retrieved November 25, 2008, from\nhttp://www.cpearson.com/Excel/named.htm.\nRowe, N. C. (1985). \"Naming in Programming.\" Computers in Schools 2(2 - 3): 241 - 253.\nTukiainen, M. (2001). Evaluation of the Cognitive Dimensions Questionnaire and Some Thoughts about the\nCognitive Dimensions of Spreadsheet Calculation. 13th Workshop of the Psychology of\nProgramming Interest Group. G. Kadoda. Bournemouth UK.\n\nProceedings of EuSpRIG 2010 Conference\n\"Practical steps to protect organisations from out-of-control spreadsheets\", ISBN: 978-1-905404-50-6\nCopyright \u00a9 2010 EuSpRIG (www.eusprig.org) and the Author(s)\n\n\f"}