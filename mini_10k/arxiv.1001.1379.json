{"id": "http://arxiv.org/abs/1001.1379v2", "guidislink": true, "updated": "2010-11-13T22:12:11Z", "updated_parsed": [2010, 11, 13, 22, 12, 11, 5, 317, 0], "published": "2010-01-08T23:07:34Z", "published_parsed": [2010, 1, 8, 23, 7, 34, 4, 8, 0], "title": "Jump-Diffusion Risk-Sensitive Asset Management I: Diffusion Factor Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1001.3968%2C1001.4166%2C1001.1167%2C1001.5399%2C1001.3510%2C1001.1597%2C1001.0408%2C1001.2768%2C1001.2397%2C1001.0300%2C1001.4601%2C1001.5470%2C1001.1498%2C1001.3427%2C1001.3477%2C1001.1178%2C1001.3838%2C1001.4124%2C1001.4574%2C1001.4281%2C1001.0392%2C1001.0178%2C1001.3704%2C1001.0667%2C1001.2628%2C1001.3519%2C1001.5300%2C1001.0614%2C1001.2126%2C1001.3894%2C1001.4159%2C1001.0192%2C1001.0219%2C1001.0632%2C1001.0023%2C1001.4074%2C1001.0107%2C1001.4810%2C1001.2643%2C1001.0460%2C1001.4187%2C1001.4169%2C1001.1620%2C1001.3713%2C1001.4437%2C1001.5213%2C1001.1254%2C1001.1762%2C1001.4113%2C1001.2351%2C1001.3234%2C1001.4003%2C1001.3358%2C1001.4613%2C1001.4887%2C1001.3479%2C1001.4392%2C1001.0843%2C1001.2266%2C1001.4323%2C1001.4595%2C1001.3476%2C1001.2818%2C1001.2634%2C1001.3306%2C1001.4834%2C1001.2338%2C1001.1609%2C1001.2883%2C1001.4444%2C1001.0813%2C1001.5286%2C1001.4739%2C1001.2974%2C1001.2390%2C1001.4289%2C1001.5215%2C1001.2306%2C1001.2650%2C1001.2719%2C1001.3116%2C1001.0822%2C1001.1182%2C1001.4545%2C1001.2473%2C1001.5417%2C1001.2242%2C1001.5122%2C1001.3058%2C1001.3948%2C1001.1898%2C1001.1508%2C1001.2682%2C1001.1379%2C1001.4490%2C1001.2335%2C1001.2341%2C1001.2191%2C1001.2688%2C1001.1057%2C1001.4900&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Jump-Diffusion Risk-Sensitive Asset Management I: Diffusion Factor Model"}, "summary": "This paper considers a portfolio optimization problem in which asset prices\nare represented by SDEs driven by Brownian motion and a Poisson random measure,\nwith drifts that are functions of an auxiliary diffusion factor process. The\ncriterion, following earlier work by Bielecki, Pliska, Nagai and others, is\nrisk-sensitive optimization (equivalent to maximizing the expected growth rate\nsubject to a constraint on variance.) By using a change of measure technique\nintroduced by Kuroda and Nagai we show that the problem reduces to solving a\ncertain stochastic control problem in the factor process, which has no jumps.\nThe main result of the paper is to show that the risk-sensitive jump diffusion\nproblem can be fully characterized in terms of a parabolic\nHamilton-Jacobi-Bellman PDE rather than a PIDE, and that this PDE admits a\nclassical C^{1,2} solution.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1001.3968%2C1001.4166%2C1001.1167%2C1001.5399%2C1001.3510%2C1001.1597%2C1001.0408%2C1001.2768%2C1001.2397%2C1001.0300%2C1001.4601%2C1001.5470%2C1001.1498%2C1001.3427%2C1001.3477%2C1001.1178%2C1001.3838%2C1001.4124%2C1001.4574%2C1001.4281%2C1001.0392%2C1001.0178%2C1001.3704%2C1001.0667%2C1001.2628%2C1001.3519%2C1001.5300%2C1001.0614%2C1001.2126%2C1001.3894%2C1001.4159%2C1001.0192%2C1001.0219%2C1001.0632%2C1001.0023%2C1001.4074%2C1001.0107%2C1001.4810%2C1001.2643%2C1001.0460%2C1001.4187%2C1001.4169%2C1001.1620%2C1001.3713%2C1001.4437%2C1001.5213%2C1001.1254%2C1001.1762%2C1001.4113%2C1001.2351%2C1001.3234%2C1001.4003%2C1001.3358%2C1001.4613%2C1001.4887%2C1001.3479%2C1001.4392%2C1001.0843%2C1001.2266%2C1001.4323%2C1001.4595%2C1001.3476%2C1001.2818%2C1001.2634%2C1001.3306%2C1001.4834%2C1001.2338%2C1001.1609%2C1001.2883%2C1001.4444%2C1001.0813%2C1001.5286%2C1001.4739%2C1001.2974%2C1001.2390%2C1001.4289%2C1001.5215%2C1001.2306%2C1001.2650%2C1001.2719%2C1001.3116%2C1001.0822%2C1001.1182%2C1001.4545%2C1001.2473%2C1001.5417%2C1001.2242%2C1001.5122%2C1001.3058%2C1001.3948%2C1001.1898%2C1001.1508%2C1001.2682%2C1001.1379%2C1001.4490%2C1001.2335%2C1001.2341%2C1001.2191%2C1001.2688%2C1001.1057%2C1001.4900&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper considers a portfolio optimization problem in which asset prices\nare represented by SDEs driven by Brownian motion and a Poisson random measure,\nwith drifts that are functions of an auxiliary diffusion factor process. The\ncriterion, following earlier work by Bielecki, Pliska, Nagai and others, is\nrisk-sensitive optimization (equivalent to maximizing the expected growth rate\nsubject to a constraint on variance.) By using a change of measure technique\nintroduced by Kuroda and Nagai we show that the problem reduces to solving a\ncertain stochastic control problem in the factor process, which has no jumps.\nThe main result of the paper is to show that the risk-sensitive jump diffusion\nproblem can be fully characterized in terms of a parabolic\nHamilton-Jacobi-Bellman PDE rather than a PIDE, and that this PDE admits a\nclassical C^{1,2} solution."}, "authors": ["Mark Davis", "Sebastien Lleo"], "author_detail": {"name": "Sebastien Lleo"}, "author": "Sebastien Lleo", "arxiv_comment": "33 pages", "links": [{"href": "http://arxiv.org/abs/1001.1379v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1001.1379v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-fin.PM", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-fin.PM", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1001.1379v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1001.1379v2", "journal_reference": null, "doi": null, "fulltext": "JUMP-DIFFUSION RISK-SENSITIVE ASSET MANAGEMENT I:\nDIFFUSION FACTOR MODEL\n\narXiv:1001.1379v2 [q-fin.PM] 13 Nov 2010\n\nMARK DAVIS\u2217 AND S\u00c9BASTIEN LLEO\u2020\nAbstract. This paper considers a portfolio optimization problem in which asset prices are\nrepresented by SDEs driven by Brownian motion and a Poisson random measure, with drifts that\nare functions of an auxiliary diffusion factor process. The criterion, following earlier work by Bielecki,\nPliska, Nagai and others, is risk-sensitive optimization (equivalent to maximizing the expected growth\nrate subject to a constraint on variance.) By using a change of measure technique introduced by\nKuroda and Nagai we show that the problem reduces to solving a certain stochastic control problem in\nthe factor process, which has no jumps. The main result of the paper is to show that the risk-sensitive\njump diffusion problem can be fully characterized in terms of a parabolic Hamilton-Jacobi-Bellman\nPDE rather than a PIDE, and that this PDE admits a classical (C 1,2 ) solution.\n\n1. Introduction. In this article, we consider a finite time jump-diffusion version\nof the risk sensitive asset management problem of Bielecki and Pliska [5]. Fundamentally, our main result is to show that the resulting stochastic control problem can\nbe fully characterized by a parabolic Hamilton-Jacobi-Bellman PDE rather than a\nPIDE, and that this PDE admits a classical (C 1,2 ) solution.\nRisk-sensitive control is a generalization of classical stochastic control in which the\ndegree of risk aversion or risk tolerance of the optimizing agent is explicitly parameterized in the objective criterion and influences directly the outcome of the optimization.\nIn risk-sensitive control, the decision maker's objective is to select a control policy\nh(t) to maximize the criterion\ni\nh\n1\n(1.1)\nJ(x, t, h; \u03b8) := \u2212 ln E e\u2212\u03b8F (x,h)\n\u03b8\nwhere t is the time, x is the state variable, F is a given reward function, and the\nrisk sensitivity \u03b8 > 0 is an exogenous parameter representing the decision maker's\ndegree of risk aversion. A Taylor expansion of the previous expression around \u03b8 = 0\nevidences the vital role played by the risk sensitivity parameter:\n\u03b8\nJ(x, t, h; \u03b8) = E [F (x, t, h)] \u2212 Var [F (x, t, h)] + O(\u03b82 )\n2\n\n(1.2)\n\nThis criterion amounts to maximizing E [F (x, t, h)] subject to a penalty for variance.\nFor a general reference, see Whittle [39]. Much of the recent literature concerns the\ninfinite time horizon problem:\nh\ni\n1\n(1.3)\nJ\u221e (x, h; \u03b8) := lim inf \u2212 t\u22121 ln E e\u2212\u03b8f (x,h)\nt\u2192\u221e\n\u03b8\n\nThis is interesting from a theoretical perspective, but is not applicable to practical\nasset management because of the non-uniqueness of controls. Optimality in this sense\nis a 'tail property': if h\u2217 (t) is optimal, then so is h\u0303(t) = h\u2217 (t)1t>T + h(t)1t\u2264T for any\narbitrary process h(t) and time T > 0. Of course, near-term decisions are the ones\nthat are of primary importance to investment managers.\n\n\u2217 Department of Mathematics, Imperial College London, London SW7 2AZ, England, Email:\nmark.davis@imperial.ac.uk\n\u2020 Finance Department, Reims Management School, 59 rue Pierre Taittinger, 51100 Reims, France,\nEmail: sebastien.lleo@reims-ms.fr\n\n1\n\n\fIn the past decade, the applications of risk-sensitive control to asset management\nhave flourished. Risk-sensitive control was first applied to solve financial problems\nby Lefebvre and Montulet [29] in a corporate finance context and by Fleming [15]\nin a portfolio selection context. However, Bielecki and Pliska [5] were the first to\napply the continuous time risk-sensitive control as a practical tool that could be used\nto solve 'real world' portfolio selection problems. They considered a long-term asset\nallocation problem and proposed the logarithm of the investor's wealth as a reward\nfunction, so that the investor's objective is to maximize the risk-sensitive (log) return of his/her portfolio or alternatively to maximize a function of the power utility\n(HARA) of terminal wealth. They derived the optimal control and solved the associated Hamilton-Jacobi-Bellman (HJB) PDE under the restrictive assumption that\nthe asset and factor noise are uncorrelated. This assumption is unrealistic and it was\nlater relaxed (see [8]). The contribution of Bielecki and Pliska to the field is immense:\nthey studied the economic properties of the risk-sensitive asset management criterion\n(see [7]), extended the asset management model into an intertemporal CAPM ([8]),\nworked on transaction costs ([6]), numerical methods ([4]) and considered factors\ndriven by a CIR model ([9]). A major contribution to the mathematical theory was\nmade by Kuroda and Nagai [27] who introduced an elegant solution method based\non a change of measure argument which transforms the risk sensitive control problem\nin a linear exponential of quadratic regulator. They solved the associated HJB PDE\nover a finite time horizon and then studied the properties of the ergodic HJB PDE.\nRecently, Davis and Lleo [12] applied this change of measure technique to solve, at a\nfinite and an infinite horizon, a benchmarked investment problem in which an investor\nselects an asset allocation to outperform a given financial benchmark. The problem\nwe consider is also related to the vast literature on HARA utility maximization that\nhas flourished in the past 50 years. This literature includes a number of references related to risk-sensitive control, such as works by Fleming and Sheu ([17], [18] and [19])\nor Hansen and Sargent [22] in the context of robust control.\nRisk-sensitive asset management theory was originally set in a world of diffusion dynamics where randomness is modelled using correlated Brownian motions. To\nour knowledge, the only attempt to extend the risk-sensitive asset management theory from a diffusion to a jump diffusion setting was made by Wan [38] who briefly\nsketched a jump-diffusion extension of Bielecki and Pliska's [5] original infinite horizon risk-sensitive asset management model. Wan's treatment is however restrictive\nas it only considers a single Poisson process-driven jump per asset and assumes that\nthe underlying valuation factor risks and asset risks are uncorrelated. Our paper addresses these two limitations. The setting of our control problem, which takes place\nwithin a finite time horizon, allows for both infinite activity jumps in asset prices and\nfor a correlation structure between factor risks and asset risks. To solve this control problem we extend Kuroda and Nagai's powerful change of measure technique\nto account for the jumps. One of the difficulties we face in extending this technique\nis proving that the optimal control is admissible as this requires showing that the\nDol\u00e9ans exponential (2.9) associated with this control is a martingale. In a pure diffusion setting, this would follow easily from the Kamazaki condition or the Novikov\ncondition. However, when the Dol\u00e9ans exponential does not have continuous path, as\nis the case in a jump diffusion setting, proving that it is indeed a martingale is more\ndifficult as only weaker partial results exist. This question is addressed in Appendix\nA of the present paper.\n2\n\n\fIn this paper the asset price processes are modelled as jump-diffusions whose\ngrowth rates are functions of an auxiliary 'factor' process X(t) which satisfies a linear diffusion SDE. Our main result is that the risk-sensitive jump-diffusion asset\nmanagement problem is equivalent to an optimal control problem for a diffusion process (no jumps) and that the HJB equation for the latter admits a unique classical\nC 1,2 ([0, T ) \u00d7 Rn ) solution. Showing the existence and uniqueness of a solution to\na risk-sensitive control problem can prove difficult even in a pure diffusion setting.\nFor example, Bensoussan, Freshe and Nagai [3] had to constrain the behaviour of the\nHamiltonian in order to prove existence of a classical solution. Still in a pure diffusion\nsetting, Fleming and Soner (see V.9 in [20]) proved that the value function is a continuous viscosity solution of the associated Hamilton Jacobi Bellman Partial Differential\nEquation (HJB PDE) but had to assume boundedness of all coefficients and of the\nderivatives of the reward function. No such strong condition is required to solve the\njump diffusion problem considered in this article. In fact all our assumptions arise\nnaturally from the structure of the risk-sensitive asset management problem. Uniqueness follows from a classical verification argument while the proof of existence relies\non a policy improvement algorithm and on the properties of linear parabolic PDEs.\nThe paper is organized as follows. We first introduce the general setting of the\nmodel in section 2 and define the class of random Poisson measures which will be\nused to model the jump component of the asset dynamics. In Section 3, we formulate\nthe jump-diffusion control problem and introduce the change of measure argument of\nKuroda and Nagai [27]. In a pure diffusion case, this is enough to transform the problem into a standard Linear Exponential of Quadratic Regulator. In our jump-diffusion\nsetting, the change of measure simplifies the problem by associating the HJB PDE\ngiven in Section 3.3, rather than the expected Partial Integro-Differential Equation\ncontaining non-local terms, to the value function. It is striking that an optimal control problem for a jump-diffusion model has a solution that is characterized in terms\nof a HJB PDE and not a HJB PIDE1 .\nOur main result is Theorem 4.3 in Section 4. The proof depends on various\ntechnical arguments which are given in Sections 5 to 7. In section 5, we show the\nexistence of a unique optimal control before addressing two key questions in Section\n6. First, the admissibility of the optimal control is no longer a priori guaranteed because the Dol\u00e9ans exponential defining the Radon-Nikodym derivative does not have\ncontinuous paths. This point is addressed in Propositions 6.3 and 6.4. Second, the\nRisk-Sensitive Hamilton-Jacobi-Bellman Partial Differential Equation (RS HJB PDE)\ncontains a jump-induced control-dependent integral term: it is no longer possible to\nfind an analytical solution and the existence of a strong, classical solution is no longer\nguaranteed. However, should we be able to prove the existence of a classical C 1,2\nsolution to the RS HJB PDE, then we can prove uniqueness and resolve the control\nproblem using a straightforward verification theorem, presented in Theorem 6.1 and\nCorollary 6.2 in Section 6.\nIn Section 7 we address existence and regularity of solutions to the RS HJB PDE.\nWe show, in Theorem 7.2 and Corollary 7.4, that the risk-sensitive jump-diffusion control problem we consider admits a unique classical C 1,2 ([0, T ) \u00d7 Rn ) solution. Showing the existence and uniqueness of a solution to a risk-sensitive control problem can\n1 See\n\n\u00d8ksendal and Sulem [42] for a treatment of jump-diffusion control problems.\n3\n\n\fprove difficult even in a pure diffusion setting. For example, Bensoussan, Frehse and\nNagai [3] had to constrain the behaviour of the Hamiltonian in their finite time horizon problem to prove existence of a classical solution. Still in a pure diffusion setting\nand over a finite time horizon, Fleming and Soner (see V.9 in [20]) proved that the\nvalue function is a continuous viscosity solution of the associated Hamilton Jacobi\nBellman Partial Differential Equation (HJB PDE) but had to assume boundedness of\nall coefficients and of the derivatives of the reward function. No such strong condition\nis required to solve the jump diffusion problem considered in this article. In fact all\nour assumptions arise naturally from the structure of the risk-sensitive asset management problem. We obtain our result by applying an approximation in policy space\nin a two-step process: first, we show existence on a bounded region and then extend\nto the unbounded state space. With this result in hand, we have all the ingredients\nneeded for the proof of Theorem 4.3.\nUp to this point, we have assumed that the factor process X(t) is directly observed by the controller, and therefore represents real economic factors: GDP growth,\ninflation, the S&P500 index, etc. We may however wish to use X(t) as an abstract\nlatent factor, introduced to model volatility of returns, in which case only the prices,\nand not X(t), will be observed. In our final Section 8, we note that this problem, once\nadequately reformulated, can be solved using a classical Kalman filter, as in [33], as\nthe jump noise is absent from the dynamics of X(t). While this is from a technical\npoint of view a simple observation, it greatly enhances the applicability of our results.\nIn a companion paper [14] we consider the case in which there are jumps in both\nthe price and factor processes. There the measure change technique does not remove\nthe jumps and the argument is substantially different.\n2. Analytical Setting.\n2.1. Overview. The growth rates of the assets are assumed to depend on n factors X1 (t), . . . , Xn (t) which follow the dynamics given in equation (2.3) below. As in\nKuroda and Nagai's asset-only model, the assets market comprises m risky securities\nSi , i = 1, . . . m. In contrast to Kuroda and Nagai, we assume that the money market\naccount process, S0 , is an affine function of the valuation factors, which enables us\nto easily model a stochastic short term rate. Let M := n + m. Throughout, we will\nassume that m > n; this is needed in connection with the 'zero-beta' policies introduced in Section 7.1.\nLet (\u03a9, {Ft } , F , P) be the underlying probability space. On this space is defined\nan RM -valued (Ft )-Brownian motion W (t) with components Wk (t), k = 1, . . . , M .\nMoreover, let N be a (Ft )-Poisson point process on (0, \u221e) \u00d7 Z, independent of W (t),\nwhere (Z, BZ ) is a given Borel space2 . Define\nZ := {U \u2208 B(Z), E [N (t, U )] < \u221e \u2200t}\n\n(2.1)\n\nFinally, for notational convenience, we fix throughout the paper a set Z0 \u2208 BZ such\n2 Z is a Polish space and B\nZ is the Borel \u03c3-field. See Ikeda and Watanabe [23] for a formal\ndefinition of the Poisson point process\n\n4\n\n\fthat \u03bd(Z\\Z0 ) < \u221e and define\nN\u0304 (dt, dz)\n(2.2)\n\u001a\nN (dt, dz) \u2212 N\u0302 (dt, dz) = N (dt, dz) \u2212 \u03bd(dz)dt =: \u00d1 (dt, dz) if z \u2208 Z0\n=\nN (dt, dz)\nif z \u2208 Z\\Z0\n2.2. Factor Dynamics. The dynamics of the n factors are expressed by the\naffine diffusion equation\ndX(t) = (b + BX(t))dt + \u039bdW (t),\n\nX(0) = x\n\n(2.3)\n\nwhere X(t) is the Rn -valued factor process with components Xj (t) and b \u2208 Rn ,\nB \u2208 Rn\u00d7n and \u039b \u2208 Rn\u00d7M .\n2.3. Asset Market Dynamics. Let S0 denote the wealth invested in the money\nmarket account with dynamics given by the equation:\n\u0001\ndS0 (t)\n= a0 + AT0 X(t) dt,\nS0 (t)\n\nS0 (0) = s0\n\n(2.4)\n\nwhere a0 \u2208 R is a scalar constant, A0 \u2208 Rn is a n-element column vector and throughout the paper xT denotes the transpose of the matrix or vector x.\nLet Si (t) denote the price at time t of the ith security, with i = 1, . . . , m. The\ndynamics of risky security i can be expressed as:\nN\n\nX\ndSi (t)\n= (a + AX(t))i dt +\n\u03c3ik dWk (t) +\n\u2212\nSi (t )\nk=1\n\nSi (0) = si ,\n\nZ\n\n\u03b3i (z)N\u0304 (dt, dz),\n\nZ\n\ni = 1, . . . , m\n\n(2.5)\n\nwhere a \u2208 Rm , A \u2208 Rm\u00d7n , \u03a3 := [\u03c3ij ] , i = 1, . . . , m, j = 1, . . . , M and \u03b3(z) \u2208 Rm\nsatisfying Assumption 1:\nAssumption 1. \u03b3(z) \u2208 Rm satisfies\n\u2212 1 \u2264 \u03b3imin \u2264 \u03b3i (z) \u2264 \u03b3imax < +\u221e,\n\ni = 1, . . . , m\n\nand\n\u2212 1 \u2264 \u03b3imin < 0 < \u03b3imax < +\u221e,\n\ni = 1, . . . , m\n\nfor i = 1, . . . , m. Furthermore, define\nS := supp(\u03bd) \u2208 BZ\nand\nS\u0303 := supp(\u03bd \u25e6 \u03b3 \u22121 ) \u2208 B (Rm )\nwhere supp(*) denotes the measure's support, then we assume that\nis the smallest closed hypercube containing S\u0303.\n5\n\nQm\n\nmin\n, \u03b3imax ]\ni=1 [\u03b3i\n\n\fIn addition, the vector-valued function \u03b3(z) satisfies:\nZ\n|\u03b3(z)|2 \u03bd(dz) < \u221e\n\n(2.6)\n\nZ0\n\nNote that Assumption 1 implies that each asset has, with positive probability,\nboth upward and downward jumps. As will become evident in Section 3.2, the effect\nof this assumption is to bound the space of controls. Relation (2.6) is a standard\ncondition.\nDefine the set J as\nn\no\nJ := h \u2208 Rm : \u22121 \u2212 hT \u03c8 < 0 \u2200\u03c8 \u2208 S\u0303\n\n(2.7)\n\nand let J be the closure of J . For a given z, the equation hT \u03b3(z) = \u22121 describes a\nhyperplane in Rm . J is a bounded open convex subset of Rm .\n2.4. Portfolio Dynamics. We will need the following assumptions:\nAssumption 2. \u03a3\u03a3T > 0\nThe effect of this assumption is to prevent redundant assets. For example, we\nwill not able to model in our investment market a share and an option or futures on\nthat share. However, this assumption leaves us free to model a wide range of assets\nsuch as shares, bonds and commodities products as well as related indices.\nAssumption 3. \u039b\u039bT > 0.\nLet Gt := \u03c3((S(s), X(s)), 0 \u2264 s \u2264 t) be the sigma-field generated by the security\nand factor processes up to time t. An investment strategy or control process is an\nRm -valued process with the interpretation that hi (t) is the fraction of current portfolio value invested in the ith asset, P\ni = 1, . . . , m. The fraction invested in the money\nm\nmarket account is then h0 (t) = 1 \u2212 i=1 hi (t).\n\nDefinition 2.1. An Rm -valued control process h(t) is in class H if the following\nconditions are satisfied:\n1. h(t) is progressively measurable with respect to {B([0, t]) \u2297 Gt }t\u22650 and is c\u00e0dl\u00e0g;\n\u0011\n\u0010R\nt\n2\n2. P 0 |h(s)| ds < +\u221e = 1, \u2200t > 0;\n3. hT (t)\u03b3(z) > \u22121,\nDefine the set K as\n\n\u2200t > 0, z \u2208 Z, a.s. d\u03bd.\n\nK := {h \u2208 H : h(t, \u03c9) \u2208 J\n\na.e. (dt \u00d7 dP}\n\n(2.8)\n\nLemma 2.2. Under Assumption 1, a control process h(t) satisfying condition 3\nin Definition 2.1 is bounded.\nProof. The proof of this result is immediate.\nDefinition 2.3. A control process h is in class A(T ) if the following conditions\nare satisfied:\n6\n\n\f1. h \u2208 H;\n2. E\u03c7hT = 1 where \u03c7ht , t \u2208 (0, T ], is the Dol\u00e9ans exponential defined as\n\u001a Z t\nZ t\n1\n\u03c7ht := exp \u2212\u03b8\nh(s)T \u03a3dWs \u2212 \u03b82\nh(s)T \u03a3\u03a3T h(s)ds\n2\n0\n0\nZ tZ\n+\nln (1 \u2212 G(z, h(s))) \u00d1 (ds, dz)\n0\nZ\n\u001b\nZ tZ\n+\n{ln (1 \u2212 G(z, h(s))) + G(z, h(s))} \u03bd(dz)ds ,\n0\n\nZ\n\n(2.9)\n\nand\n\u0001\u2212\u03b8\nG(z, h) = 1 \u2212 1 + hT \u03b3(z)\n\n(2.10)\n\nWe say that a control process h is admissible if h \u2208 A(T ).\nP\nThe proportion invested in the money market account is h0 (t) = 1 \u2212 m\ni=1 hi (t).\nTaking this budget equation into consideration, the wealth, V (t) of the investor in\nresponse to an investment strategy h(t) \u2208 H, follows the dynamics\n\u0001\n\u0001\n\u0001\ndV (t)\n= a0 + AT0 X(t) dt + hT (t) a \u2212 a0 1 + A \u2212 1AT0 X(t) dt\n\u2212\nV (t )\nZ\nhT (t)\u03b3(z)N\u0304 (dt, dz)\n+hT (t)\u03a3dWt +\nZ\n\nm\n\nwhere 1 \u2208 R denotes the m-element unit column vector and with V (0) = v. Defining\n\u00e2 := a \u2212 a0 1 and \u00c2 := A \u2212 1AT0 , we can express the portfolio dynamics as\nZ\n\u0010\n\u0011\n\u0001\ndV (t)\nT\nT\nT\nhT (t)\u03b3(z)N\u0304 (dt, dz)\n=\na\n+\nA\nX(t)\ndt\n+\nh\n(t)\n\u00e2\n+\n\u00c2X(t)\ndt\n+\nh\n(t)\u03a3dW\n+\n0\nt\n0\nV (t\u2212 )\nZ\n(2.11)\nwith initial endowment V (0) = 0.\n3. Problem Setup.\n3.1. Optimization Criterion. We will assume that the objective of the investor is to maximize the risk adjusted growth of his/her portfolio of assets over a\nfinite time horizon. In this context, the objective of the risk-sensitive management\nproblem is to find h\u2217 \u2208 A(T ) that maximizes the control criterion\ni\nh\n1\n(3.1)\nJ(x, t, h; \u03b8) := \u2212 ln E e\u2212\u03b8 ln V (t,x,h)\n\u03b8\nBy It\u00f4's Lemma, the log of the portfolio value in response to a strategy h is\nZ t\nZ\n\u0010\n\u0011\n\u0001\n1 t\na0 + AT0 X(s) + h(s)T \u00e2 + \u00c2X(s) ds \u2212\nln V (t) = ln v +\nh(s)T \u03a3\u03a3T h(s)ds\n2\n0\n0\nZ t\nh(s)T \u03a3dW (s)\n+\n0\n\n+\n\nZ tZ\n0\n\n+\n\nZ0\n\nZ tZ\n0\n\nZ\n\n\b\n\u0001\nln 1 + h(s)T \u03b3(z) \u2212 h(s)T \u03b3(z) \u03bd(dz)ds\n\n\u0001\nln 1 + h(s)T \u03b3(z) N\u0304 (ds, dz)\n7\n\n(3.2)\n\n\fHence,\n\u001b\n\u001a Z t\ng(Xs , h(s))ds \u03c7ht\ne\u2212\u03b8 ln V (t) = v \u2212\u03b8 exp \u03b8\n\n(3.3)\n\n0\n\nwhere\ng(x, h) =\n\n1\n(\u03b8 + 1) hT \u03a3\u03a3T h \u2212 a0 \u2212 AT0 x \u2212 hT (\u00e2 + \u00c2x)\n2Z \u001a\n\u001b\ni\n\u0001\u2212\u03b8\n1h\nT\nT\n+\n1 + h \u03b3(z)\n\u2212 1 + h \u03b3(z)1Z0 (z) \u03bd(dz)\n\u03b8\nZ\n\n(3.4)\n\nand the Dol\u00e9ans exponential \u03c7ht is given by (2.9).\n\n3.2. Change of Measure. Let Ph be the measure on (\u03a9, FT ) defined via the\nRadon-Nikodym derivative\ndPh\n:= \u03c7hT\n(3.5)\ndP\nFor a change of measure to be possible, we must ensure that the following technical\ncondition holds:\nG(z, h(s)) < 1\nThis condition is satisfied iff\nhT (s)\u03b3(z) > \u22121\n\n(3.6)\n\na.s. d\u03bd, which was already required for h(t) to be in class H (Condition 3 in Definition 2.1). Condition (3.6) is endogenous to the control problem and can be interpreted\nas a risk management safeguard preventing the investor from investing in some of the\nportfolios if the jump component of these portfolios could result in the investor's\nbankruptcy.\nObserve that Ph is a probability measure for h \u2208 A(T ). Then,\nZ t\nWth = Wt + \u03b8\n\u03a3T h(s)ds\n0\n\nis a standard Brownian motion under the measure Ph and we have (recall the notation\ndefined at (2.2))\nZ tZ\nZ tZ\nZ tZ\n{1 \u2212 G(z, h(s))} \u03bd(dz)ds\nN (ds, dz) \u2212\n\u00d1 h (ds, dz) =\n0\n\n0\n\nZ0\n\n=\n\n0\n\n0\n\nZ0\n\nZ tZ\n\nN (ds, dz) \u2212\n\n0\n\nZ0\n\nZ0\n\nZ tZ\n\nZ0\n\nAs a result, X(t) satisfies the SDE:\n\nn\n\n\u0001\u2212\u03b8 o\n1 + hT \u03b3(z)\n\u03bd(dz)ds\n\ndX(t) = f (X(t), h(t)) dt + \u039bdWth ,\n\nt \u2208 [0, T ]\n\n(3.7)\n\nwhere\nf (x, h) := b + Bx \u2212 \u03b8\u039b\u03a3T h\n\n\u0001\n\n(3.8)\n\nWe will now introduce the following two auxiliary criterion functions under the\nmeasure Ph :\n8\n\n\f\u2022 the auxiliary function directly associated with the risk-sensitive control problem:\n\"\n( Z\n)#\nT\n1\nh\ng(Xs , h(s))ds \u2212 \u03b8 ln v\n(3.9)\nI(v, x; h; t, T ) = \u2212 ln Et,x exp \u03b8\n\u03b8\nt\nwhere Et,x [*] denotes the expectation taken with respect to the measure Ph\nand with initial conditions (t, x).\n\u2022 the exponentially transformed criterion\n\"\n( Z\n)#\nT\nh\n \u0303\nexp \u03b8\ng(s, Xs , h(s))ds \u2212 \u03b8 ln v\n(3.10)\nI(v, x, h; t, T ) := E\nt,x\n\nt\n\nwhich we will find convenient to use in our derivations.\nWe have completed our reformulation of the problem under the measure Ph . It is\nstriking that the asset allocation problem with jump-diffusion asset prices reduces to\na stochastic control problem for a diffusion process, with dynamics (3.7) and reward\nfunction (3.9) or (3.10).\n3.3. The Risk-Sensitive Control Problems under Ph . Let \u03a6 be the value\nfunction for the auxiliary criterion function I(v, x; h; t, T ). Then \u03a6 is defined as\n\u03a6(t, x) = sup I(v, x; h; t, T )\n\n(3.11)\n\nh\u2208A(T )\n\nWe will show that \u03a6 satisfies the HJB PDE\n\u2202\u03a6\n(t, x) + sup Lht \u03a6(t, x) = 0,\n\u2202t\nh\u2208J\n\n(t, x) \u2208 (0, T ) \u00d7 Rn\n\n(3.12)\n\nwhere\n\u0001T\nLht \u03a6(t, x) = b + Bx \u2212 \u03b8\u039b\u03a3T h(s) D\u03a6\n\u0001 \u03b8\n1\n+ tr \u039b\u039bT D2 \u03a6 \u2212 (D\u03a6)T \u039b\u039bT D\u03a6 \u2212 g(x, h)\n2\n2\n\n(3.13)\n\nand subject to terminal condition\n\n\u03a6(T, x) = ln v,\n\nx \u2208 Rn .\n\n(3.14)\n\n \u0303 x; h; t, T ).\nSimilarly, let \u03a6\u0303 be the value function for the auxiliary criterion function I(v,\nThen \u03a6\u0303 is defined as\n\u03a6\u0303(t, x) =\n\ninf\n\nh\u2208A(T )\n\n \u0303 x; h; t, T ).\nI(v,\n\n(3.15)\n\nThe corresponding HJB PDE is\n\u0011\n1 \u0010\n\u2202 \u03a6\u0303\n(t, x) + tr \u039b\u039bT D2 \u03a6\u0303(t, x) + H(t, x, \u03a6\u0303, D\u03a6\u0303) = 0,\n\u2202t\n2\n\n(3.16)\n\n\u03a6\u0303(T, x) = v \u2212\u03b8\n\n(3.17)\n\nand subject to terminal condition\n\n9\n\n\fand where\nH(x, r, p) = inf\n\nh\u2208J\n\nfor r \u2208 R, p \u2208 Rn and in particular,\n\n\b\n\nf (x, h)T p + \u03b8g(x, h)r\n\n(3.18)\n\n\u03a6\u0303(t, x) = exp {\u2212\u03b8\u03a6(t, x)}\n\n(3.19)\n\nNote that since \u03a6 and \u03a6\u0303 are related through a strictly monotone continuous\ntransformation, an admissible (optimal) strategy for the exponentially transformed\nproblem is also admissible (optimal) for the risk-sensitive problem.\n4. Main Result. In this section, we present the main result of this article,\nnamely that the risk-sensitive jump diffusion problem admits a classical (C 1,2 ) solution, and show that the value function \u03a6 is convex in x.\nProposition 4.1. The value function \u03a6(t, x) is convex in x.\nProof.\nTo prove that the value function \u03a6(t, x) is convex in x, it is necessary and sufficient\nto show that \u2200(x1 , x2 ) \u2208 Rn and for any \u03ba \u2208 (0, 1),\n\u03a6(t, \u03bax1 + (1 \u2212 \u03ba)x2 ) \u2264 \u03ba\u03a6(t, x1 ) + (1 \u2212 \u03ba)\u03a6(t, x2 )\n\n(4.1)\n\nStart from the left hand side:\n\u03a6(t, \u03bax1 + (1 \u2212 \u03ba)x2 )\n\"\n( Z\n)\n#\nT\n1\ng(Xs , h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n= sup \u2212 ln Eht,\u03bax1 +(1\u2212\u03ba)x2 exp \u03b8\n\u03b8\nh\u2208A(T )\nt\n\"\n( Z\n)\n#\nT\n1\nh\n= sup \u2212 ln Et,(x1 ,x2 ) exp \u03b8\ng(\u03baX1 (s) + (1 \u2212 \u03ba)X2 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u03b8\nh\u2208A(T )\nt\n\"\n( Z\nT\n1\n= sup \u2212 ln Eht,(x1 ,x2 ) exp \u03ba\u03b8\ng(X1 (s), h(s))ds\n\u03b8\nh\u2208A(T )\nt\n)\n#\nZ T\n+(1 \u2212 \u03ba)\u03b8\ng(X2 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\nt\n\n1\n= sup \u2212 ln Eht,(x1 ,x2 )\n\u03b8\nh\u2208A(T )\n( Z\n\n\"\n\n( Z\nexp \u03b8\n\nT\n\ng(X1 (s), h(s))ds \u2212 \u03b8 ln v\nt\n\nT\n\n\u00d7 exp \u03b8\n\ng(X2 (s), h(s))ds \u2212 \u03b8 ln v\n\nt\n\n)\n\n)\n\n!\u03ba\n\n\u03c7(t)\n\n!1\u2212\u03ba \uf8f9\n\n\u03c7(t)\n\n\uf8fb\n\n\"\n( Z\n)\n!\u03ba #\n(\nT\n1\nh\nexp \u03b8\ng(X1 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u2264 sup \u2212 ln Et,x1\n\u03b8\nh\u2208A(T )\nt\n\uf8ee\n( Z\n)\n!1\u2212\u03ba \uf8f9\uf8fc\n\uf8fd\nT\n\uf8fb\ng(X2 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u00d7Eht,x2 \uf8f0 exp \u03b8\n\uf8fe\nt\n10\n\n\f\"\n( Z\n)\n!\u03ba #\nT\n1\nh\n\u2212 ln Et,x1\n= sup\nexp \u03b8\ng(X1 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u03b8\nh\u2208A(T )\nt\n\uf8ee\n)\n!1\u2212\u03ba \uf8f9\uf8fc\n( Z\n\uf8fd\nT\n1\n\uf8fb\n\u2212 ln Eht,x2 \uf8f0 exp \u03b8\ng(X2 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\uf8fe\n\u03b8\nt\n\"\n( Z\n)\n!\u03ba #\nT\n1\nexp \u03b8\ng(X1 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u2264 sup \u2212 ln Eht,x1\n\u03b8\nh\u2208A(T )\nt\n\uf8ee\n( Z\n)\n!1\u2212\u03ba \uf8f9\nT\n1\n\uf8fb\n+ sup \u2212 ln Eht,x2 \uf8f0 exp \u03b8\ng(X2 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u03b8\nh\u2208A(T )\nt\n)\n#\n\"\n( Z\nT\n\u03ba\nh\n\u2264 sup \u2212 ln Et,x1 exp \u03b8\ng(X1 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\n\u03b8\nh\u2208A(T )\nt\n\"\n( Z\n)\n#\nT\n1\u2212\u03ba\ng(X2 (s), h(s))ds \u2212 \u03b8 ln v \u03c7(t)\nln Eht,x2 exp \u03b8\n+ sup \u2212\n\u03b8\nh\u2208A(T )\nt\n(\n\n= \u03ba\u03a6(t, x1 ) + (1 \u2212 \u03ba)\u03a6(t, x2 )\nwhere the fourth equality follows from the fact that the covariance of two random\nvariables inside the expectations is positive and the third inequality is due to the fact\nthat the function x 7\u2192 x\u03b1 for x > 0 and \u03b1 \u2208 (0, 1) is concave.\nCorollary 4.2. The exponentially transformed value function \u03a6\u0303 has the following property: \u2200(x1 , x2 ) \u2208 R2 , \u03ba \u2208 (0, 1, ),\n\u03a6\u0303(t, \u03bax1 + (1 \u2212 \u03ba)x2 ) \u2265 \u03a6\u0303\u03ba (t, x1 )\u03a6\u03031\u2212\u03ba (t, x2 )\n\n(4.2)\n\nProof. The properties follows immediately from the definition of \u03a6 = \u2212 1\u03b8 ln \u03a6\u0303.\nWe now come to the main result of this article. Recall the standing assumptions:\nin Section 2, Assumption 1 is a condition on the support of the jump measure, Assumptions 2 and 3 are the non-degeneracy conditions \u03a3\u03a3T > 0, \u039b\u039bT > 0, while\nAssumption 4, introduced in Section 7.1 below, is a full-rank condition on the matrix\n\u00c2 defined at (2.11).\nTheorem 4.3. Under Assumptions 1\u2013 4 the following hold:\n1. the optimal asset allocation is the unique maximizer of the supremum (3.12)\n2. \u03a6\u0303 is the unique C 1,2 ([0, T ] \u00d7 Rn ) solution of the RS HJB PIDE (3.16)-(3.17).\nMoreover, \u03a6\u0303 satisfies the property (4.2)\n3. \u03a6 is the unique C 1,2 ([0, T ] \u00d7 Rn ) solution of the RS HJB PIDE (3.12)-(3.14).\nMoreover, \u03a6 is convex in its argument x.\nProof. The proof is based on a series of results proved in Sections 5\u20137 below.\nThese combine to give us the following argument.\nExistence of an optimal control - by Proposition 5.1, the supremum in (3.12)\nadmits a unique Borel measurable maximizer. Moreover, by Proposition 6.3, this\nmaximizer is admissible and by Proposition 6.4 it is also a maximizer with respect to\nthe P-measure criterion J defined in (3.1). Thus, we can take this maximizer as our\n11\n\n\foptimal asset allocation.\nExistence of a classical (C 1,2 ) solution - by Corollary 7.3, \u03a6\u0303 is a C 1,2 ([0, T ] \u00d7 Rn )\nsolution of the RS HJB PDE (3.16)-(3.17).\nUniqueness of the classical solution - the existence of zero beta policies enable\nus to deduce (as in Step 1 of the proof of Theorem 7.2) that \u03a6\u0303 is bounded. Part (i).\nof Verification Theorem 6.1 therefore applies. Choosing as optimal control the unique\nmaximizer of the supremum in (3.12), part (ii). of Theorem 6.1 also applies: \u03a6\u0303 is the\nunique solution to the HJB PIDE. Property (4.2) is proved in Corollary 4.2.\nBy Corollaries 7.3 and 6.2, it then follows that \u03a6 is the unique classical solution\nto the HJB PIDE (3.12) with terminal condition (3.14). Moreover, \u03a6 is convex in its\nsecond argument x.\n\nThis result proves that we have solved our original control problem in the context\nof strong, classical solutions. What would this imply in terms of weaker viscosity\nsolutions? As a classical solution is also a viscosity solution, our result implies that\nthe value function is indeed a viscosity solution of the HJB PDE. However, uniqueness\nof classical solutions does not necessarily imply uniqueness of viscosity solutions. To\nprove uniqueness in the viscosity sense, we would need a comparison result such as\nTheorem 33 in Davis and Lleo [13].\nIn the remainder of this paper, we develop the various technical arguments required in the proof of Theorem 4.3.\n5. Existence of a Maximizing Control\n. Proposition 5.1. Under Assumption 2, the supremum in (3.12) admits a unique\nBorel measurable maximizer \u0125(t, x, p) for (t, x, p) \u2208 [0, T ] \u00d7 Rn \u00d7 Rn . Moreover, the\nmaximizer \u0125(t, x, p) is an interior point of the set J .\nProof. The supremum in (3.12) can be expressed as\nsup Lht \u03a6\n\nh\u2208J\n\n\u0001 \u03b8\n1\n= (b + Bx)T D\u03a6 + tr \u039b\u039bT D2 \u03a6 \u2212 (D\u03a6)T \u039b\u039bT D\u03a6 + a0 + AT0 x\n2\n2\n\u001a\n1\nT\nT\nT\n+ sup \u2212 (\u03b8 + 1) h \u03a3\u03a3 h \u2212 \u03b8h \u03a3\u039bT D\u03a6 + hT (\u00e2 + \u00c2x)\n2\nh\u2208J\n\u001b\nZ nh\no\ni\n\u0001\u2212\u03b8\n1\n\u2212\n1 + hT \u03b3(z)\n\u2212 1 + \u03b8hT \u03b3(z)1Z0 (z) \u03bd(dz)\n\u03b8 Z\n\nUnder Assumption 2, for any p \u2208 Rn the terms\n\u2212\n\n1\n(\u03b8 + 1) hT \u03a3\u03a3T h \u2212 \u03b8hT \u03a3\u039bT p + hT (\u00e2 + \u00c2x) \u2212\n2\n\nand\n\u2212\n\n1\n\u03b8\n\nZ nh\nZ\n\nZ\n\nhT \u03b3(z)1Z0 (z)\u03bd(dz)\n\nZ\n\nio\n\u0001\u2212\u03b8\n1 + hT \u03b3(z)\n\u2212 1 \u03bd(dz)\n12\n\n(5.1)\n\n\fare both strictly concave in h \u2200z \u2208 Z a.s. d\u03bd. Therefore, the supremum is reached for a\nunique maximizer \u0125(t, x, p), which is an interior point of the set J , which is the closure\nof the set J defined in equation (2.7), and the supremum, evaluated at \u0125(t, x, p) \u2208 Rn ,\nis finite. By measurable selection, \u0125 can be taken as a Borel measurable function on\n[0, T ] \u00d7 Rn \u00d7 Rn .\n6. Verification Theorems. In this section, we prove a verification theorem to\nthe effect that if (3.12) has a C 1,2 solution then that solution is equal to \u03a6 defined\nby (3.11) and the control h\u2217 (t) = \u0125(t, x, D\u03a6) is optimal. We will first prove a verification theorem for the exponentially transformed problem (3.15) with HJB PDE (3.16)\nand value function \u03a6\u0303(t, x). As a corollary, we will obtain a verification theorem for\nthe risk sensitive control problem with (3.11), HJB PDE (3.12) and value function\n\u03a6(t, x). Define the first order operator\nL\u0303h \u03c6(t, x) = b + Bx \u2212 \u03b8\u039b\u03a3T h\n\n\u0001T\n\nD\u03c6(t, x) + \u03b8g(x, h)\u03c6(t, x)\n\n(6.1)\n\nTheorem 6.1 (Verification Theorem for the Exponentially Transformed Control\nProblem). Let \u03c6\u0303 be a C 1,2 ([0, T ] \u00d7 Rn ) bounded function.\n(i) Assume that \u03c6\u0303(T, x) \u2264 e\u2212\u03b8 ln v \u2200x \u2208 Rn and\n\u0011\n1 \u0010\n\u2202 \u03c6\u0303\n(t, x) + tr \u039b\u039bT D2 \u03c6\u0303(t, x) + H(t, x, \u03c6\u0303, D\u03c6\u0303) \u2265 0\n\u2202t\n2\n\non [0, T ] \u00d7 Rn , then \u03c6\u0303(t, x) \u2264 \u03a6\u0303(t, x) \u2200(t, x) \u2208 [0, T ] \u00d7 Rn\n(ii) Further assume that \u03c6\u0303(T, x) = e\u2212\u03b8 ln v \u2200x \u2208 Rn and there exists a Borelmeasurable minimizer h\u0303\u2217 (t, x) of h\u0303 7\u2192 L\u0303h\u0303 \u03c6\u0303 defined in (6.1) such that\n\u2202 \u03c6\u0303\n(t, x) +\n\u2202t\n\u2202 \u03c6\u0303\n=\n(t, x) +\n\u2202t\n=0\n\n\u0011\n1 \u0010 T 2\ntr \u039b\u039b D \u03c6\u0303(t, x) + H(t, x, \u03c6\u0303, D\u03c6\u0303)\n2\n\u0011\n\u2217\n1 \u0010 T 2\ntr \u039b\u039b D \u03c6\u0303(t, x) + L\u0303h\u0303 \u03c6\u0303\n2\n\nand the stochastic differential equation\n\u0001\ndX(t) = b + BX(t) \u2212 \u03b8\u039b\u03a3T h(t) dt + \u039bdWt\u03b8\n\ndefines a unique solution X(s) for each given initial data Xt = x and the process\n\u03c0 \u2217 (s) := h\u0303\u2217 (s, X(s)) is a well-defined control process in \u00c3(T ). Then \u03c6\u0303 = \u03a6\u0303 and\n\u03c0 \u2217 (s) is an optimal Markov control process.\nProof. The following proof is based on an argument used by Touzi [37].\n(i). Let h\u0303 \u2208 \u00c3(T ) be an arbitrary control, with X(t) the state process with initial\ndata X(t) = x. Define the stopping time\n\u03c4N := T \u2227 inf {s > t : |Xs \u2212 x| \u2265 N }\nDefine Z(s) = \u03b8\n\nRs\nt\n\ng(s, Xs , \u0125s )ds, then\n\u0001\nd eZs := \u03b8g(s, Xs , \u0125s )eZs\n13\n\n\fAlso, by It\u00f4, for s \u2208 [t, \u03c4\u03b4 ],\n(\n\nd\u03c6\u0303s =\n\n)\n\u2202 \u03c6\u0303\n+ L\u03c6\u0303 ds + D\u03c6\u0303T \u039bdWs\u03b8\n\u2202s\n\nwhere L is the generator of the state process X(t) defined as:\n\u0011\n\u0001T\n1 \u0010\nL\u03c6\u0303(t, x) := b + Bx \u2212 \u03b8\u039b\u03a3T h(s) D\u03c6\u0303 + tr \u039b\u039bT D2 \u03c6\u0303\n2\nBy the It\u00f4 product rule, and since dZs * \u03c6\u0303s = 0, we get\n\u0011\n\u0010\n\u0001\nd \u03c6\u0303s eZs = \u03c6\u0303s d eZs + eZs d\u03c6\u0303s\n\nand hence for s \u2208 [t, \u03c4N ]\n\n\u03c6\u0303(s, Xs )eZs = \u03c6\u0303(t, x)eZt + \u03b8\n\nZ\n\ns\n\nt\n\n+\n\nZ\n\ns\n\nt\n\n\u03c6\u0303(u, Xu )g(u, Xu , \u0125u )eZu du\n!\nZ\n\n\u2202 \u03c6\u0303\n(u, Xu ) + L\u03c6\u0303(u, Xu )eZu\n\u2202u\n\ns\n\ndu +\n\nt\n\nD\u03c6\u0303T \u039bdWu\u03b8\n\nBecause for an arbitrary control h,\n\u2202 \u03c6\u0303\n(t, x) +\n\u2202t\n\u2202 \u03c6\u0303\n(t, x) +\n\u2265\n\u2202t\n\u22650\n\n\u0011\n1 \u0010 T 2\ntr \u039b\u039b D \u03c6\u0303(t, x) + Lh\u0303 \u03c6\u0303(t, Xt )\n2\n\u0011\n1 \u0010 T 2\ntr \u039b\u039b D \u03c6\u0303(t, x) + H(t, x, \u03c6\u0303, D\u03c6\u0303)\n2\n\nand eZs \u2265 0 \u2200s \u2208 [t, \u03c4N ] we have\n\u03c6\u0303(t, x)eZt \u2264 \u03c6\u0303(s, Xs )eZs +\n\nZ\n\ns\nt\n\nD\u03c6\u0303T \u039bdWu\u03b8\n\nTaking the expectation, we obtain\ni\nh\ni\nh\nR\n\u03b8 ts g(u,Xu ,\u0125u )du\nZs\n= Eh\u0303,\u03b8\n\u03c6\u0303(t, x)eZt \u2264 Eh\u0303,\u03b8\nt,x \u03c6\u0303(s, Xs )e\nt,x \u03c6\u0303(s, Xs )e\nIn particular, take s = \u03c4N and note that eZt = 1, then\ni\nh\nR\u03c4\n\u03b8 t N g(u,Xu ,\u0125u )du\n\u03c6\u0303(t, x)eZt \u2264 Eh\u0303,\u03b8\nt,x \u03c6\u0303(\u03c4N , X\u03c4N )e\nSince \u03c6\u0303 is assumed to be bounded, there exists a constant C1 > 0 such that:\n\u03c6\u0303(s, Xs )e\u03b8\n\nR\u03c4\ns\n\nN\n\ng(s,Xs ,\u0125s )ds\n\n14\n\n\u2264 C1 e\u03b8\n\nR \u03c4N\nt\n\ng(u,Xu ,\u0125u )du\n\n\fSince for an arbitrary admissible control h\u0303 \u2208 A(T ) and fixed s \u2208 [t, T ] there\nexists some constant C2 > 0 such that\ng(s, Xs , \u0125s ) \u2264 C2 |1 + X(s)|\nThen\n\u03c6\u0303(s, Xs )e\u03b8\n\nR\u03c4\ns\n\nN\n\ng(s,Xs ,\u0125s )ds\n\n\u2264 C3 e\u03b8\n\nR \u03c4N\nt\n\n|1+X(s)|du\nR \u03c4N\n\n\u2264 C3 e\u03b8(\u03c4N \u2212t)+\u03b8 t\nR \u03c4N\n\u2264 C4 e\u03b8 t |X(s)|du\n\n|X(s)|du\n\n\u2264 C4 e\u03b8(T \u2212t) supt\u2264s\u2264T |X(s)|\nfor C3 = C1 eC2 and C4 = C3 e\u03b8(T \u2212t) .\nBy the dominated convergence theorem and the assumption that \u03c6\u0303(T, Xt ) \u2264\ne\u2212\u03b8 ln v ,\nh\ni\nR\n\u03b8 tT g(u,Xu ,\u0125u )du\n\u03c6\u0303(T,\nX\n)e\n\u03c6\u0303(t, x) \u2264 Eh\u0303,\u03b8\nT\nt,x\nh RT\ni\n\u03b8 t g(u,Xu ,\u0125u )du\n\u2264 Eh\u0303,\u03b8\n\u2212 \u03b8 ln v\nt,x e\n\nWe have now proved the first part of the theorem.\n(ii). To prove the second part, we can simply apply the same reasoning for the\noptimal control h\u0303\u2217 . Note, however, that with this choice of control we would\nhave\n\u0011\n1 \u0010\n\u2202 \u03c6\u0303\n(t, x) + tr \u039b\u039bT D2 \u03c6\u0303(t, x) + H(t, x, \u03c6\u0303, D\u03c6\u0303)\n\u2202t\n2\n\u0011\n\u2217\n\u2202 \u03c6\u0303\n1 \u0010\n=\n(t, x) + tr \u039b\u039bT D2 \u03c6\u0303(t, x) + L\u0303h\u0303 \u03c6\u0303\n\u2202t\n2\n=0\nwhich would lead us to equality in the last equation, i.e.\nh RT\ni\n\u03b8 t g(u,Xu ,\u0125u )du\n\u03c6\u0303(t, x) = Eh\u0303,\u03b8\n\u2212 \u03b8 ln v\nt,x e\nCorollary 6.2 (Verification Theorem for the Risk-Sensitive Control Problem).\nLet \u03c6 be a C 1,2 ([0, T ] \u00d7 Rn ) \u2229 C ([0, T ] \u00d7 Rn ) bounded function.\n(i) Assume that \u03c6(T, x) \u2264 e\u2212\u03b8 ln v \u2200x \u2208 Rn and\n\u2202\u03c6\n+ sup Lh \u03c6(t, X(t)) \u2265 0\n\u2202t h\u2208J t\non [0, T ] \u00d7 Rn , then \u03c6(t, x) \u2264 \u03a6\u0303(t, x) \u2200(t, x) \u2208 [0, T ] \u00d7 Rn\n(ii) Further assume that \u03c6(T, x) = e\u2212\u03b8 ln v \u2200x \u2208 Rn and there exists a minimizer\nh\u2217 (t, x) of h 7\u2192 Lh \u03c6 defined in (3.13) such that\n\u2217\n\u2202\u03c6\n\u2202\u03c6\n+ sup Lht \u03c6(t, X(t)) =\n+ Lht \u03c6(t, X(t)) = 0\n\u2202t h\u2208J\n\u2202t\n\n15\n\n\fand the stochastic differential equation\n\u0001\ndX(s) = b + BX(s\u2212 ) \u2212 \u03b8\u039b\u03a3T h(s) ds + \u039bdWs\u03b8\n\ndefines a unique solution X for each given initial data Xt = x and the process\n\u03c0 \u2217 (s) := h\u0303\u2217 (s, X(s)) is a well-defined control process in \u00c3(T ). Then \u03c6 = \u03a6 and\n\u03c0 \u2217 (s) is an optimal Markov control process.\nProof. This corollary follows from equation (3.19) and from the fact that an\nadmissible (optimal) strategy for the exponentially transformed problem is also admissible (optimal) for the risk-sensitive problem.\nProposition 6.3. The process h\u2217 (t) is admissible: h\u2217 (t) \u2208 A(T ).\nProof. Refer to Appendix A for a full discussion and a proof of this proposition.\nApplying Proposition 6.3 we deduce that the control h\u2217 (t) is optimal for the auxiliary problems (3.9) and (3.10) resulting from the change of measure. However, this\nproposition is not sufficient to conclude that h\u2217 (t) is optimal for the original problem (3.1) set under the P-measure. The next result show that this is indeed the case.\nProposition 6.4. The optimal control h\u2217 (t) for the auxiliary problem\nsup I(v, x; h; t, T )\nh\u2208A(T )\n\nwhere I is defined in (3.9) is also optimal for the initial problem suph\u2208A(T ) J(x, t, h)\nwhere J is defined in (3.1).\nProof. See Appendix A.\n7. Existence of a Classical Solution. Historically, proving the existence of\na strong, analytical solution to the HJB PDE was both the main difficulty and the\nmain objective when solving a control problem. Fleming and Rishel [16] as well as\nKrylov [24] and [25] have been the main contributors, proposing techniques based\neither on PDE arguments or on probability theory. Recently however, the emphasis\nhas switched from strong solutions to weaker types of solution. Viscosity solutions\nhave proved particularly useful and successful, gaining many applications in stochastic control theory (see for example the classic article by Crandall, Ishii and Lions [11]\nas well as Fleming and Soner [20] for their applications to stochastic control). The\nreason for this appeal is twofold. First, it is significantly easier to prove the existence\nof a viscosity solution than a classical solution. In the viscosity world, the difficulty\nis shifted from proof of existence to proof of uniqueness, and even then it is generally easier to prove uniqueness of a viscosity solution via a comparison theorem than\nthe existence of a classical solution. Second, the stability result due to Barles and\nSouganidis [2] connects directly viscosity solutions to numerical methods, making it\neasy to solve 'real world' control problems.\nThis section follows similar arguments to those developed by Fleming and Rishel [16]\n(Theorem 6.2 and Appendix E). Namely, we use an approximation in policy space\nalongside results on linear parabolic partial differential equations to prove that the\nexponentially transformed value functions \u03a6\u0303 is of class C 1,2 ((0, T ) \u00d7 Rn ). Then it\n16\n\n\ffollows that the value functions \u03a6 is also of class C 1,2 ((0, T ) \u00d7 Rn ). The approximation in policy space algorithm was originally proposed by Bellman in the 1950s (see\nBellman [1] for details) as a numerical method to compute the value function. Our\napproach has two steps. First, we use the approximation in policy space algorithm\nto show existence of a classical solution in a bounded region. Then, we extend our\nargument to unbounded state space. To derive this second result we follow a different\nargument than Fleming and Rishel [16] which makes more use of the actual structure\nof the control problem.\nOur interest in classical solutions is as much mathematical as practical. First,\nsince a smooth solution is a viscosity solution but the converse is not necessarily true,\nwe are proving a stronger result. Second, this stronger result immediately translates\na better grasp of the analytical properties of the value function. While viscosity\nsolutions provide continuity, they do not generally give information about higher\norder derivatives. By contrast, classical solutions are smooth in the state, implying\nthat they are (at least) C 1 in time and C 2 in the state. Third, viscosity solutions\nare purely about solving the PDE and although they show that the value function is\nthe unique solution of the HJB PDE they do not prove directly the control problem\nhas a solution, that is a pair of a value function and an admissible optimal control.\nFourth and finally, in our case seeking a strong solution does not impair our search\nfor numerical results. Because our state process X(t) can clearly be interpreted as\nthe continuous time limit of a Markov Chain, we can apply well-known results by\nKushner and Dupuis [26] to prove convergence of a finite approximation scheme to\nthe value function. We can therefore solve concrete portfolio selection problems quite\ndirectly.\n7.1. \"Zero Beta\" Policies. In this section, we introduce a new class of control\npolicies: the \"zero beta\" (0\u03b2) policies:\nDefinition 7.1 (0\u03b2-policy). By reference to the definition of the function g in\nequation (3.4), a 'zero beta' (0\u03b2) control policy \u021f(t) is an admissible control policy\nfor which the function g is independent of the state variable x.\nThe term 'zero beta' is borrowed from financial economics (see for instance\nBlack [10]). To avoid assuming the existence of a globally risk-free rate in factor\nmodels such as the CAPM, the APT or in ad-hoc valuation models, it is customary\nto build portfolios without any exposure to the factor(s) as a substitute for the riskfree rate. These special portfolios are referred to as 'zero beta' portfolios by reference\nto the slope coefficient \u03b2 used to measure the sensitivity of asset returns to the valuation factor(s).\nIn the risk sensitive asset management model, if A0 = 0, then the policy h0 = 0,\ni.e. invest all the wealth in the risk-free asset, is a 0\u03b2-policy. When A0 6= 0, we see\nfrom (2.11) that a 0\u03b2-policy can exist only if there is a vector \u021f satisfying\n\u021fT \u00c2 = \u2212A0 .\n\n(7.1)\n\nWe introduce the following standing assumption.\nAssumption 4. The matrix \u00c2 has rank n.\nUnder this assumption there are always 0\u03b2-policies: we have only to take a vector\n\u021f satisfying (7.1) and scale it if necessary so that \u021f \u2208 J (see (2.7)) and then h(t, \u03c9) = \u021f\n17\n\n\fis a 0\u03b2-policy. We have no reason to consider anything other than the set Z of\nconstant policies of this kind. Note that when \u021f \u2208 Z the function g of (3.4) is a\nconstant, g(x, \u021f) \u2261 \u01e7.\n7.2. The L\u03b7 (K) and L \u03b7 (K), 1 < \u03b7 < \u221e Spaces. The following ideas and\nnotations relate to the treatment of linear parabolic partial differential equations found\nin Ladyzhenskaya, Solonnikov and Uralceva [28]. The relevant results are summarized\nin Appendix E of Fleming and Rishel. They concern PDEs of the form\n\u0001\n\u2202\u03c8 1\n+ tr a(t, x)D2 \u03c8 + b(t, x)T D\u03c8 + \u03b8c(t, x)\u03c8 + d(t, x) = 0\n\u2202t\n2\n\n(7.2)\n\non a set Q = (0, T ) \u00d7 G and with boundary condition\n\n\u03c8(t, x) = \u03a8T (x) x \u2208 G\n\u03c8(t, x) = \u03a8(t, x) (t, x) \u2208 (0, T ) \u00d7 \u2202G\nThe set G is open and is such that \u2202G is a compact manifold of class C 2 . Denote by\n\u2022 \u2202 \u2217 Q the boundary of Q, i.e.\n\u2202 \u2217 Q := ({T } \u00d7 G) \u222a ((0, T ) \u00d7 \u2202G)\n\u2022 L\u03b7 (K) the space of \u03b7-th power integrable functions on K \u2282 Q;\n\u2022 k*k\u03b7,K the norm in L\u03b7 (K).\nAlso, denote by L \u03b7 (Q), 1 < \u03b7 < \u221e the space of all functions \u03c8 such that \u03c8 and\nall its generalized partial derivatives are in L\u03b7 (K). We associate with this space the\nSobolev-type norm:\n(2)\n\nk\u03c8k\u03b7,K := k\u03c8k\u03b7,K +\n\n\u2202\u03c8\n\u2202t\n\n\u03b7,K\n\n+\n\nn\nX\n\u2202\u03c8\n\u2202xi\ni=1\n\n\u03b7,K\n\n+\n\nn\nX\n\ni,j=1\n\n\u22022\u03c8\n\u2202xi xj\n\n\u03b7,K\n\n(7.3)\n\nWe will also introduce additional notation and concepts as required in the proofs.\n7.3. Existence of a Classical Solution. In this section, we use an approximation in policy space to show the existence of a C 1,2 solution to the RS HJB PDE (3.12).\nTheorem 7.2 (Existence of a Classical Solution for the Exponentially Transformed Control Problem). The RS HJB PDE (3.16) with terminal condition \u03a6\u0303(T, x) =\ne\u2212\u03b8 ln v has a solution \u03a6\u0303 \u2208 C 1,2 ((0, T ) \u00d7 Rn ) with \u03a6\u0303 continuous in [0, T ] \u00d7 Rn .\nProof. Step 1: Approximation in policy space - bounded space\nConsider the following auxiliary problem: fix R > 0 and let BR be the open ndimensional ball of radius R > 0 centered at 0 defined as BR := {x \u2208 Rn : |x| < R}.\nWe construct an investment portfolio by solving the optimal risk-sensitive asset allocation problem as long as X(t) \u2208 BR for R > 0. Then, as soon as X(t) \u2208\n/ BR ,\nwe switch all of the wealth into the 0\u03b2 policy \u021f from the exit time t until the end of\nthe investment horizon at time T . The HJB PDE for this auxiliary problem can be\nexpressed as\n\u0011\n\u2202 \u03a6\u0303 1 \u0010 T\n+ tr \u039b\u039b (t)D2 \u03a6\u0303 + H(t, x, \u03a6\u0303, D\u03a6\u0303) = 0\n\u2202t\n2\n18\n\n\u2200(t, x) \u2208 QR := (0, T ) \u00d7 BR\n(7.4)\n\n\fwhere, as in (3.18)\nH(x, r, p) = inf\nh\u2208J\n\n\b\nf (x, h)T p + \u03b8g(t, x, h)r\n\nfor p \u2208 Rn and for g and f defined in (3.4) and (3.8) respectively. J , defined as the\nclosure of J is a compact set. The boundary conditions are\n\u03a6\u0303(t, x) = \u03a8(t, x)\n\n\u2200(t, x) \u2208 \u2202 \u2217 QR := ((0, T ) \u00d7 \u2202BR ) \u222a ({T } \u00d7 BR )\n\nwith\n\u2022 \u03a8(T, x) = e\u2212\u03b8 ln v \u2200x \u2208 BR ;\n\u2022 \u03a8(t, x) := \u03c8(t, x) := e\u03b8\u01e7(T \u2212t) \u2200(t, x) \u2208 (0, T ) \u00d7 \u2202BR and where \u021f is a fixed\narbitrary 0\u03b2 policy which is constant as a function of time. Note that \u03c8 is\nobviously of class C 1,2 (QR ) and that the Sobolev-type norm\n(2)\n\n(2)\n\nk\u03a8k\u03b7,\u2202 \u2217QR = k\u03a8\u0303k\u03b7,QR\n\n(7.5)\n\nis finite.\nDefine a sequence of functions \u03a6\u03031 , \u03a6\u03032 ,... \u03a6\u0303k ,... on QR = [0, T ] \u00d7 BR and of\nbounded measurable feedback control laws h0 , h1 ,... hk ,... where h0 is an arbitrary\ncontrol. Assuming hk\u22121 is known, we define the function \u03a6\u0303k+1 as the solution to the\nboundary value problem:\n\u0011\n\u2202 \u03a6\u0303k\n1 \u0010\n+ tr \u039b\u039bT (t)D2 \u03a6\u0303k + f (x, hk\u22121 )T D\u03a6\u0303k + \u03b8g(t, x, hk\u22121 )\u03a6\u0303k = 0\n\u2202t\n2\n\n(7.6)\n\nsubject to boundary conditions\n\u03a6\u0303(t, x) = \u03a8(t, x)\n\n\u2200(t, x) \u2208 \u2202 \u2217 QR := ((0, T ) \u00d7 \u2202BR ) \u222a ({T } \u00d7 BR )\n\nNote that the boundary value problem (7.6) is a special case of the generic problem\nintroduced earlier in equation (7.2) with\na(t, x) = \u039b\u039bT (t)\nb(t, x) = f (x, hk )\nc(t, x) = g(t, x, hk )\nd(t, x) = 0\nMoreover, since BR is bounded and J is compact, all of these functions are also\nbounded. Thus, based on standard results on parabolic Partial Differential Equations (see for example Appendix E in Fleming and Rishel [16] and Chapter IV in\nLadyzhenskaya, Solonnikov and Uralceva [28]), the boundary value problem (7.6) admits a unique solution in L \u03b7 (QR ).\nNext, for almost all (t, x) \u2208 QR , k = 1, 2, . . ., we define hk by the prescription\nn\no\nhk = Argminh\u2208J f (x, h)T D\u03a6\u0303k + \u03b8g(t, x, h)\u03a6\u0303k\n(7.7)\n19\n\n\fso that\nf (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k = inf\nh\u2208J\n\nn\n\nf (x, h)T D\u03a6\u0303k + \u03b8g(t, x, h)\u03a6\u0303k\n\n= H(t, x, \u03a6\u0303k , D\u03a6\u0303k )\n\no\n\n(7.8)\n\nNote, in view of the definition of g in (3.4), that the minimum is never achieved\non the boundary of J , i.e. hk takes values in J .\n\u0010 \u0011\nObserve that the sequence \u03a6\u0303k\nis globally bounded. Indeed, by Feynmank\u2208N\n\u0010 \u0011\nK\u01cec, the sequence \u03a6\u0303k\nis bounded from below by 0. By the optimality principle,\nk\u2208N\n\nRT\n\nit is also bounded from above by e\u03b8 t g(X(s),\u021f)ds = e\u03b8\u01e7(T \u2212t) . Moreover, these bounds\ndo not depend on the radius R and are therefore valid over the entire space (0, T )\u00d7Rn .\nStep 2: Convergence Inside the Cylinder (0, T ) \u00d7 BR\nStep 2.1: Monotonicity of the Sequence\nTake k \u2265 1. Subtracting the PDE for \u03a6\u0303k+1 from the PDE for \u03a6\u0303k , we see that\n! \u0012\n\u0011 \u0010\n\u0011i\n1 h\u0010 T\n\u2202 \u03a6\u0303k\n\u2202 \u03a6\u0303k+1\n+\n\u2212\ntr \u039b\u039b (t)D2 \u03a6\u0303k+1 \u2212 \u039b\u039bT (t)D2 \u03a6\u0303k\n\u2202t\n\u2202t\n2\n\u0011i\n\u0011\n\u0010\n\u0010\n+ f (x, hk )T D\u03a6\u0303k+1 \u2212 f (x, hk\u22121 )T D\u03a6\u0303k + \u03b8 g(t, x, hk )\u03a6\u0303k+1 \u2212 g(t, x, hk\u22121 )\u03a6\u0303k\nin (0, T ) \u00d7 Rn\n\n=0\n\nwith \u03a6\u0303k+1 \u2212 \u03a6\u0303k = 0 on Rn .\nAdd and subtract f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k ,\n! \u0012\n\u0011i\n\u0011 \u0010\n\u2202 \u03a6\u0303k+1\n1 h\u0010 T\n\u2202 \u03a6\u0303k\n+\n\u2212\ntr \u039b\u039b (t)D2 \u03a6\u0303k+1 \u2212 \u039b\u039bT (t)D2 \u03a6\u0303k\n\u2202t\n\u2202t\n2\n\u0010\n\u0011\n\u0010\n\u0011\n+ f (x, hk )T D\u03a6\u0303k+1 \u2212 f (x, hk\u22121 )T D\u03a6\u0303k + \u03b8 g(t, x, hk )\u03a6\u0303k+1 \u2212 g(t, x, hk\u22121 )\u03a6\u0303k\n\u0011\n\u0011 \u0010\n\u0010\n+ f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k \u2212 f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k\nin (0, T ) \u00d7 Rn\n\n=0\n\nRearranging,\n! \u0012\n\u0011i\n\u0011 \u0010\n1 h\u0010 T\n\u2202 \u03a6\u0303k\n\u2202 \u03a6\u0303k+1\n+\n\u2212\ntr \u039b\u039b (t)D2 \u03a6\u0303k+1 \u2212 \u039b\u039bT (t)D2 \u03a6\u0303k\n\u2202t\n\u2202t\n2\n\u0011\n\u0011\n\u0010\n\u0010\n+f (x, hk )T D\u03a6\u0303k+1 \u2212 D\u03a6\u0303k + \u03b8g(t, x, hk ) \u03a6\u0303k+1 \u2212 \u03a6\u0303k\n\u0010\n\u0011 \u0010\n\u0011\n+ f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k \u2212 f (x, hk\u22121 )T D\u03a6\u0303k + \u03b8g(t, x, hk\u22121 )\u03a6\u0303k\n\n=0\n\nin (0, T ) \u00d7 Rn\n\n20\n\n\fDefine the function lk (t, x) as\n\u0011\n\u0011 \u0010\n\u0010\nlk (t, x) := f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k \u2212 f (x, hk\u22121 )T D\u03a6\u0303k + \u03b8g(t, x, hk\u22121 )\u03a6\u0303k\n\nBy the definition of hk given in (7.7), lk (t, x) \u2264 0 \u2200(t, x) \u2208 [0, T ] \u00d7 Rn, \u2200k \u2208 N. Define\nthe sequence of functions (W k )k\u2208N as\nW k := \u03a6\u0303k+1 \u2212 \u03a6\u0303k\nthen W k satisfies the PDE\n\u0001\n\u2202W k\n1\n+ tr \u039b\u039bT (t)D2 W k + f (x, hk )T DW k + \u03b8g(t, x, hk )W k + lk (t, x) = 0\n\u2202t\n2\n(7.9)\nin (0, T )\u00d7BR , and with boundary condition W k (T, x) = 0 on \u2202 \u2217 QR = ((0, T ) \u00d7 \u2202BR )\u222a\n({T } \u00d7 BR ).\nDefine the stopping time \u03c4G as the first exit time from BR :\n\u03c4G := inf {t : X(t) \u2208\n/ G}\nBy a standard Feynman-Kac representation, W k (t, x) can be represented by the expectation\n\"Z\n#\nT \u2227\u03c4G\n\nW k (t, x) = E\n\nlk (s, Xs )e\u03b8\n\nRs\n0\n\ng(r,Xr )dr\n\nds\n\n(7.10)\n\nt\n\nBecause l(t, x) \u2264 0, W k (t, x) \u2264 0 for k \u2265 1 and hence by definition of W k ,\n\u03a6\u0303k \u2265 \u03a6\u0303k+1 ,\n\u2200k \u2208 N\nn o\nis non increasing.\nwhich implies that the sequence \u03a6\u0303k\nk\u2208N\n\nStep 2.2: Convergence of the Sequence\nSince the sequence (\u03a6\u0303k )k\u2208N is non increasing and is also bounded, it converges. Denote\n(2)\nby \u03a6\u0303 its limit as k \u2192 \u221e. Now, since the Sobolev-type norm k\u03a6\u0303k+1 k\u03b7,QR is bounded\nfor 1 < \u03b7 < \u221e, we can apply the following estimate given by equation (E.9) in\nAppendix E of Fleming and Rishel\n(2)\n\nk\n|\u03a6\u0303k |1+\u03bc\nQR \u2264 MR k\u03a6\u0303 k\u03b7,QR\n\nfor some constant MR (depending on R) and where\n\u03bc=1\u2212\n\nn+2\n\u03b7\n\nk \u03bc\n|\u03a6\u0303k |1+\u03bc\nQR = |\u03a6\u0303 |QR +\n\nn\nX\ni=1\n\n21\n\n|\u03a6\u0303kxi |\u03bcQR\n\n(7.11)\n\n\fand\n|\u03a6\u0303k |\u03bcQR =\n\n+\n\nsup |\u03a6\u0303k (t, x)| +\n(t,x)\u2208QR\n\nsup\nx\u2208G\n0 \u2264 s, t \u2264 T\n\nsup\n(x, y) \u2208 G\n0\u2264t\u2264T\n\n|\u03a6\u0303k (t, x) \u2212 \u03a6\u0303k (t, y)|\n|x \u2212 y|\u03bc\n\n|\u03a6\u0303k (s, x) \u2212 \u03a6\u0303k (t, x)|\n|s \u2212 t|\u03bc/2\n\nto show that the H\u00f6lder-type norm |\u03a6\u0303k |1+\u03bc\nQR is bounded. As k \u2192 \u221e we conclude that\n\u2022 D\u03a6\u0303k converges to D\u03a6\u0303 uniformly in L\u03b7 (QR ) ;\n\u2022 D2 \u03a6\u0303k converges to D2 \u03a6\u0303 weakly in L\u03b7 (QR ) ; and\n\u03a6\u0303k\n\u2022 \u2202\u2202t\nconverges to \u2202\u2202t\u03a6\u0303 weakly in L\u03b7 (QR ).\nStep 2.3: Proving that \u03a6\u0303 \u2208 C 1,2 (QR )\nUsing estimate (7.11), we see that |\u03a6\u0303k |1+\u03bc\nQR is bounded for \u03bc > 0, which implies that\n\u03b7 > n + 2. Using relationship (7.8) and then equation (7.6), we get:\n\u0011\n\u2202 \u03a6\u0303k\n1 \u0010\n+ tr \u039b\u039bT (t)D2 \u03a6\u0303k + f (x, h)T D\u03a6\u0303k + \u03b8g(t, x, h)\u03a6\u0303k\n\u2202t\n2\n\u0011\n1 \u0010\n\u2202 \u03a6\u0303k\n+ tr \u039b\u039bT (t)D2 \u03a6\u0303k + f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k\n\u2265\n\u2202t\n2\n! \u0012\n\u0011 \u0010\n\u0011i\nk\n\u2202 \u03a6\u0303\n1 h\u0010 T\n\u2202 \u03a6\u0303k+1\n=\n+\n\u2212\ntr \u039b\u039b (t)D2 \u03a6\u0303k \u2212 \u039b\u039bT (t)D2 \u03a6\u0303k+1\n\u2202t\n\u2202t\n2\n\u0011i\n\u0010\n\u0011\n\u0010\n+f (x, hk )T D\u03a6\u0303k \u2212 D\u03a6\u0303k+1 + \u03b8g(t, x, hk ) \u03a6\u0303k \u2212 \u03a6\u0303k+1\n\n(7.12)\n\nfor any admissible control h.\n\nSince the left-hand side of (7.12) tends weakly in L\u03b7 (QR ) to\n\u0011\n\u2202 \u03a6\u0303 1 \u0010 T\n+ tr \u039b\u039b (t)D2 \u03a6\u0303 + f (x, h)T D\u03a6\u0303 + \u03b8g(t, x, h)\u03a6\u0303\n\u2202t\n2\n\n(7.13)\n\nas k \u2192 \u221e and the right-hand side tends tends weakly to 0, then we obtain the\nfollowing inequality\n\u0011\n\u2202 \u03a6\u0303 1 \u0010 T\n+ tr \u039b\u039b (t)D2 \u03a6\u0303 + f (x, h)T D\u03a6\u0303 + \u03b8g(t, x, h)\u03a6\u0303 \u2265 0\n\u2202t\n2\nalmost everywhere in QR .\nUsing a measurable selection theorem and following an argument similar to that of\nLemma VI.6.1 of Fleming and Rishel [16], we see that there exists a Borel measurable\nfunction h\u2217 from (0, T ) \u00d7 BR into J (in fact J ) such that\nf (x, h\u2217 )T D\u03a6\u0303 + \u03b8g(t, x, h\u2217 )\u03a6\u0303 = inf\nh\u2208J\n\n22\n\nn\no\nf (x, h)T D\u03a6\u0303 + \u03b8g(t, x, h)\u03a6\u0303\n\n\fholds for almost all (t, x) \u2208 (0, T ) \u00d7 BR . Then\n\u0011\n1 \u0010\n\u2202 \u03a6\u0303k\n+ tr \u039b\u039bT (t)D2 \u03a6\u0303k + f (x, h\u2217 )T D\u03a6\u0303k + \u03b8g(t, x, h\u2217 )\u03a6\u0303k\n\u2202t\n2\n\u0011\n\u2202 \u03a6\u0303k\n1 \u0010\n\u2264\n+ tr \u039b\u039bT (t)D2 \u03a6\u0303k + f (x, hk )T D\u03a6\u0303k + \u03b8g(t, x, hk )\u03a6\u0303k\n\u2202t\n2\n! \u0012\n\u0011i\n\u0011 \u0010\n\u2202 \u03a6\u0303k\n1 h\u0010 T\n\u2202 \u03a6\u0303k+1\n+\n=\n\u2212\ntr \u039b\u039b (t)D2 \u03a6\u0303k \u2212 \u039b\u039bT (t)D2 \u03a6\u0303k+1\n\u2202t\n\u2202t\n2\n\u0010\n\u0011i\n\u0011\n\u0010\n+f (x, hk )T D\u03a6\u0303k \u2212 D\u03a6\u0303k+1 + \u03b8g(t, x, hk ) \u03a6\u0303k \u2212 D\u03a6\u0303k+1\n\n(7.14)\n\nSince the left-hand side of (7.14) tends weakly in L\u03b7 (QR ) to\n\n\u0011\n\u2202 \u03a6\u0303 1 \u0010 T\n+ tr \u039b\u039b (t)D2 \u03a6\u0303 + f (x, h\u2217 )T D\u03a6\u0303 + \u03b8g(t, x, h\u2217 )\u03a6\u0303\n\u2202t\n2\n\nas k \u2192 \u221e and the right-hand side tends weakly to 0, then we obtain the inequality\n\u0011\n\u2202 \u03a6\u0303 1 \u0010 T\n+ tr \u039b\u039b (t)D2 \u03a6\u0303 + f (x, h\u2217 )T D\u03a6\u0303 + \u03b8g(t, x, h\u2217 )\u03a6\u0303 \u2264 0\n\u2202t\n2\n\n(7.15)\n\nalmost everywhere in QR .\n\nCombining (7.13) and (7.15), we have shown that\n\u0011\n\u2202 \u03a6\u0303 1 \u0010 T\n+ tr \u039b\u039b (t)D2 \u03a6\u0303 + f (x, h\u2217 )T D\u03a6\u0303 + \u03b8g(t, x, h\u2217 )\u03a6\u0303 = 0\n\u2202t\n2\n\nalmost everywhere in QR .\n\nHence, \u03a6\u0303 is a solution of equation (3.16) on a bounded domain. Moreover,\n\u03a6\u0303 \u2208 L\u03b7 (QR ). Also, since H is locally Lipschitz, |\u03a6\u0303k |\u03bcQR < \u221e for \u03bc > 0 and\n|D\u03a6\u0303k |\u03bcQR < \u221e for \u03bc > 0, then |H(t, x, \u03a6\u0303k , D\u03a6\u0303k )|\u03bcQR < \u221e.\nWe can now show that \u03a6\u0303 \u2208 C 1,2 (QR ). Define\nk 1+\u03bc\n|\u03a6\u0303k |2+\u03bc\nQR := |\u03a6\u0303 |QR +\n\n\u2202 \u03a6\u0303k\n\u2202t\n\n\u03bc\nQR\n\n+\n\nn\nX\n\n|\u03a6\u0303kxi xj |\u03bcQR\n\ni,j=1\n\nConsider the following estimate given by equation (E10) in Appendix E of Fleming\nand Rishel\n|\u03a6\u0303|2+\u03bc\nQ\u2032 \u2264 M2 k\u03a6\u0303kQ\u2032\u2032\n\n(7.16)\n\nfor some constant M2 , and two open subsets Q\u2032 and Q\u2032\u2032 of Q such that Q\u0304\u2032 \u2282 Q \u0304\u2032\u2032 . In\nthis estimate, set Q\u2032\u2032 = QR and take Q\u2032 to be any subset of Q such that Q\u0304\u2032 \u2282 Q.\nThus\n|\u03a6\u0303|2+\u03bc\nQ\u2032 < \u221e\n\n(7.17)\n\nWhen interpreted in light of estimate (7.11) (stemming from (E9)), we see that the\n\u2202 \u03a6\u0303\n\u2202 2 \u03a6\u0303\nand \u2202x\nsatisfy a uniform H\u00f6lder condition on any compact\nderivatives \u2202\u2202t\u03a6\u0303 , \u2202x\ni\ni xj\n23\n\n\fsubset Q\u2032 of QR . By Theorem 10.1 in Chapter IV of Ladyzhenskaya, Solonnikov and\nUralceva [28], we can therefore conclude that \u03a6\u0303 \u2208 C 1,2 (QR ).\nStep 3: Convergence from the Cylinder [0, T ) \u00d7 BR to the State Space\n[0, T ) \u00d7 Rn\nStep 3.1: Setting\nLet {Ri }i\u2208N > 0 be a non decreasing sequence with limi\u2192\u221e Ri \u2192 \u221e and let {\u03c4i }i\u2208N\nbe the sequence of stopping times defined as\n\u03c4i := inf {t : X(t) \u2208\n/ BRi }\nNote that {\u03c4i }i\u2208N is non decreasing and limi\u2192\u221e \u03c4i = \u221e.\n\u0010 \u0011\nDenote by \u03a6\u0303(i) the limit of the sequence \u03a6\u0303k\non (0, T ) \u00d7 BRi , i.e.\nk\u2208N\n\n\u03a6\u0303(i) (t, x) = lim \u03a6\u0303k (t, x)\nk\u2192\u221e\n\n(7.18)\n\n\u2200(t, x) \u2208 (0, T ) \u00d7 BRi\n\n\u0010\n\u0011\nStep 3.2: Convergence of the sequence \u03a6\u0303(i)\n\ni\u2208N\n\nFirst, observe that the sequence (\u03a6\u0303(i) )i\u2208N is non increasing. Indeed, for i < j the\nstochastic control problem defined over (0, T ) \u00d7 BRi is nested into the stochastic\ncontrol problem defined over (0, T ) \u00d7 BRj . In particular, a suboptimal strategy for\nthe stochastic control problem defined over (0, T ) \u00d7 BRj would be to invest optimally\nwhile x \u2208 BRi and then switch to the 0\u03b2 policy \u021f when x \u2208 BRj \\BRi . By the\noptimality principle, the expected total cost of such strategy is greater than the value\nfunction \u03a6\u0303(j) . But this suboptimal strategy also corresponds to the optimal strategy\nfor the stochastic control problem defined over (0, T ) \u00d7 BRi . Hence\n\u03a6\u0303(i) (t, x) \u2265 \u03a6\u0303(j) (t, x)\n\n\u2200i, j \u2208 N, \u2200(t, x) \u2208 (0, T ) \u00d7 BRi\n\nBy the argument in Step 1, the sequence (\u03a6\u0303(i) )i\u2208N is also bounded. As a result,\nit converges to a limit \u03a6\u0303. This limit satisfies the boundary condition (3.17). We now\nshow that \u03a6\u0303 is C 1,2 and satisfies the HJB PDE. These statements are local properties\nso we can restrict ourselves to a finite ball QR .\nStep 3.3: Proving that \u03a6\u0303 \u2208 C 1,2 (QR )\n\u0010\n\u0011\nNow that we have shown the convergence of the sequence \u03a6\u0303(i)\n\ni\u2208N\n\nthough a simple\n\ncontrol-based argument, we can conclude the proof using the same arguments based\non Ascoli's theorem as Fleming and Rishel (see [16], proof of Theorem 6.2 in Appendix\nE).\nCorollary 7.3 (Existence of a Classical Solution for the Risk-Sensitive Control\nProblem). The RS HJB PDE (3.12) with terminal condition \u03a6(T, x) = ln v has a\nsolution \u03a6 \u2208 C 1,2 ([0, T ] \u00d7 Rn ) with \u03a6 continuous in [0, T ] \u00d7 Rn .\n8. Partial Observation. In this section we show how the results of the paper\ncan be extended to the case where the factor process X(t) is not directly observed and\nthe asset allocation strategy ht must be adapted to the filtration FtS = \u03c3{Si (u), 0 \u2264\n24\n\n\fu \u2264 t, j = 0, . . . , m} generated by the asset price processes alone. In the linear\ndiffusion case studied by Nagai [32] and Nagai and Peng [33], the authors noted\nthat the pair of processes (X(t), Y (t)), where Yi (t) = log Si (t), take the form of the\n'signal' and 'observation' processes in a Kalman filter system, and consequently the\nconditional distribution of X(t) is normal N (X\u0302(t), P (t)) where X\u0302(t) = E[X(t)|FtS ]\nsatisfies the Kalman filter equation and P (t) is a deterministic matrix-valued function.\nBy using this idea they obtain an equivalent form of the problem in which X(t) is\nreplaced by X\u0302(t) and the dynamic equation (2.3) by the Kalman filter. Optimal\nstrategies take the form h(t, X\u0302(t)). This is in fact a very old idea in stochastic control,\ngoing back at least to Wonham [40].\n8.1. Decomposition. At first sight it does not seem apparent that the same\napproach can be used here, as the price processes contain jumps, but a simple observation shows that the jumps play no role in the estimation process, which is still,\nat base, the Kalman filter; see Proposition 8.1 below. A further complication is that\nthe money market interest rate r(t) = a0 + AT0 X(t) (see (2.4)) is observed directly\nand contains information about X(t). This was not the case in [32] and [33] where,\nin our notation, A0 = 0. We start by assuming that A0 = 0, and briefly discuss the\nextension to A0 6= 0 at the end of the section.\nRecall first that X(t) satisfies\ndX(t) = (b + BX(t))dt + \u039bdW (t),\n\nX(0) = X0\n\n(8.1)\n\nWhen Xt is observed, the initial value X0 is just a constant. In the present case we\nneed to assume that X0 is a normal random vector N (m0 , P0 ) with known mean m0\nand covariance P0 , and that X0 is independent of the processes W, Np .\nAn application of the general It\u00f4 formula3 shows that for i = 1, . . . , m the logprices Yi (t) satisfy Yi (0) = log si and\n\u0015\n\u0014\nN\nX\n1\n\u03c3ik dWk (t)\ndYi (t) = (\u00e2 + \u00c2X(t))i \u2212 \u03a3\u03a3Tii dt +\n2\nk=1\nZ\nZ\nln (1 + \u03b3i (z)) N\u0304 (dt, dz). (8.2)\n{ln (1 + \u03b3i (z)) \u2212 \u03b3i (z)} \u03bd(dz)dt +\n+\nZ\n\nZ0\n\nProposition 8.1. Define processes Y 1 (t), Y 2 (t) \u2208 Rm as follows.\ndY 1 (t) = \u00c2X(t) + \u03a3dW (t),\nZ\n2\nln (1 + \u03b3(z))i N\u0304 (dt, dz),\ndYi (t) = ci dt +\n\nYi1 (0) = 0,\ni = 1, . . . , m,\n\n(8.3)\nYi2 (0) = log si\n\nZ\n\nwith c \u2208 Rm defined by\n1\nci := \u00e2i \u2212 \u03a3\u03a3Tii +\n2\n\nZ\n\n{ln (1 + \u03b3i (z)) \u2212 \u03b3i (z)} \u03bd(dz)\n\nZ0\n\nso that Y (t) = Y 1 (t) + Y 2 (t). Also, define Yit = \u03c3{Y i (u), 0 \u2264 u \u2264 t}, i = 1, 2. Then\n(i) The processes Y 1 , Y 2 are each adapted to the filtration FtS .\n(ii) For any bounded measurable function f and t \u2265 0,\nE[f (X(t))|FtS ] = E[f (X(t))|Y1t ].\n3 See\n\n\u00d8ksendal and Sulem [42] for this calculation.\n25\n\n\fProof. (i) S(t) and Y (t) are in 1-1 correspondence and therefore generate the\nsame filtration FtS . Apart from rearrangement of deterministic terms, the decomposition Y = Y 1 + Y 2 is the same as the standard decomposition Y = Y c + Y d of a\nsemimartingale into its continuous and discontinuous components, see paragraph VI.\n37 of Rogers and Williams [36].\n(ii) N and W (t) are independent and as a result Y1t and Y2t are independent, and\nclearly FtS = Y1t \u2228 Y2t . The result follows, since X(t) is independent of Y2t .\n\u0003\n8.2. Kalman Filter. The processes (X(t), Y 1 (t)) satisfying (8.1) and (8.3) and\nthe filtering equations, which are standard, are stated in the following proposition.\nProposition 8.2 (Kalman Filter). The conditional distribution of X(t) given\nY1t is N (X\u0302(t), P (t)), calculated as follows.\n(i) The innovations process U (t) \u2208 Rm defined by\ndU (t) = \u03a3\u03a3T\n\n\u0001\u22121/2\n\n(dY 1 (t) \u2212 \u00c2X\u0302(t)dt),\n\nU (0) = 0\n\nis a vector Brownian motion.\n(ii) X\u0302(t) is the unique solution of the SDE\n\u0011\n\u0010\n\u0001\u22121/2\ndU (t),\ndX\u0302(t) = (b + B X\u0302(t))dt + \u039b\u03a3T + P (t)\u00c2T \u03a3\u03a3T\n\n(8.4)\n\nX\u0302(0) = m0 . (8.5)\n\n(iii) P (t) is the unique non-negative definite symmetric solution of the matrix Riccati\nequation\n\u0010\n\u0001\u22121 \u0011\n\u0001\u22121\n\u00c2 P (t)\n\u00c2P (t) + B \u2212 \u039b\u03a3T \u03a3\u03a3T\n\u1e56 (t) = \u039b\u039e\u039eT \u039bT \u2212 P (t)\u00c2T \u03a3\u03a3T\n\u0011\n\u0010\n\u0001\n\u22121\nP (0) = P0\n+P (t) B T \u2212 \u00c2T \u03a3\u03a3T\n\u03a3\u039bT ,\nwhere \u039e := I \u2212 \u03a3T \u03a3T \u03a3\n\n\u0001\u22121\n\n\u03a3.\n\nTo conclude, the Kalman filter has replaced our initial state process X(t) by an\nestimate X\u0302(t) with dynamics given in (8.5). To recover the asset price process, we\nuse (8.3) together with (8.4) to obtain the dynamics of Y (t):\ndYi (t) = dYi1 (t) + dYi2 (t)\n\u00011/2\n1\n= \u00e2i + \u00c2X\u0302(t)dt \u2212 \u03a3\u03a3Tii dt + \u03a3\u03a3T\ndU (t)\n2\nZ\nZ\n{ln (1 + \u03b3i (z)) \u2212 \u03b3i (z)} \u03bd(dz) +\n\n+\n\nZ\n\nZ0\n\nln (1 + \u03b3(z))i N\u0304 (dt, dz). (8.6)\n\nWe then apply It\u00f4 to Si (t) = exp Yi (t) to get\nN\n\nXh\n\u00011/2 i\ndSi (t)\n= (a + AX\u0302(t))i dt +\ndUk (t) +\n\u03a3\u03a3T\n\u2212\nSi (t )\nik\nk=1\n\nSi (0) = si ,\n\ni = 1, . . . , m\n\n26\n\nZ\n\n\u03b3i (z)N\u0304 (dt, dz),\n\nZ\n\n(8.7)\n\n\fWe now solve the stochastic control problem with partial observation simply by\nreplacing the original asset price description (2.5) by (8.7), and the factor process\ndescription (2.3) by the Kalman filter equation (8.5), in our solution of full observation\ncase. The Kalman filter has time-varying coefficients, but this does not affect the\npreceding arguments.\nFinally, we briefly sketch what to do if A0 6= 0. We observe the short rate\nr(t) = a0 + AT0 X(t), and hence the 1-dimensional statistic Y0 (t) \u2261 AT0 X(t), exactly.\nWe need to assume that this observation contains positive 'noise', i.e. AT0 \u039b\u039bT A0 >\n0. Changing coordinates if necessary, we can assume that AT0 = (0, 0, . . . , 1) and\nhence Y0 (t) = Xn (t). Our 'observation' is now the (m + 1)-dimensional process\n\u0232 = (Y0 , . . . , Ym ) and we can set up a Kalman filter system to estimate the unobserved\nstates X\u0304 = (X1 , . . . , Xn\u22121 )T \u2208 Rn\u22121 . Ultimately, our optimal strategy will take\n\u02c6 (t) is the Kalman filter estimate for X\u0304(t) given\n\u02c6 (t)), where X\u0304\nthe form h(t, X1 (t), X\u0304\n{\u0232 (u), u \u2264 t}. The details are left to the reader.\n9. Conclusion. In this article, we extended the classical risk-sensitive asset\nmanagement setting to include the possibility of infinite activity jumps in asset prices.\nWe applied the change of measure technique proposed by Kuroda and Nagai [27] to\nderive the Hamilton-Jacobi-Bellman Partial Differential Equation associated with the\ncontrol problem and then proved the existence and uniqueness of an admissible optimal control policy. Using an approximation in policy space algorithm, we established\nthe existence of a classical C 1,2 ((0, T ) \u00d7 Rn ) solution and obtained the uniqueness\nof this solution through a verification result. This approach also extends naturally\nand with similar results to a jump-diffusion version of the risk-sensitive benchmarked\nasset management problem.\nFinally, we have observed that an attractive, if somewhat surprising, feature of\nthe jump diffusion risk sensitive asset management is that it naturally prohibits any\ninvestment policy which may result in the investor's bankruptcy. In particular, in\nthe risk-sensitive setting presented in this article, an investor who implements the\noptimal asset allocation is certain of remaining solvent over the investment horizon.\nThis contrasts with the Merton type of approach in which the threat of bankruptcy\nremains present and has to be accounted for using a stopping time.\nThe approach presented in this article extends naturally to a jump-diffusion version of the risk-sensitive benchmarked asset management problem introduced by Davis\nand Lleo [12] and would yield similar results, namely the existence of a unique admissible control policy and of a classical C 1,2 solution to the associated RS HJB PDE.\nAppendix A. Admissibility of the Optimal Control Policy. The admissibility of the optimal control process h\u2217 (t) solving (5.1) is linked to the existence\nof a probability measure P\u03b8h\u2217 , which itself hinges on the characterisation as an exdP\u03b8\n\nponential martingale of the Radon-Nikodym derivative dPh\u2217 = \u03c7\u2217T defined in (3.5)\nvia the Dol\u00e9ans exponential introduced in (2.9). In the setting of Kuroda and Nagai [27], the admissibility of the control follows easily from an argument in Gihman\nand Skhorokhod [21] which proves that the the Dol\u00e9ans exponential (here a Girsanov\nexponential with Gaussian integrand) is an exponential martingale. However, when\nthe Dol\u00e9ans exponential does not have continuous path, as is the case in a jump diffusion setting, proving that it is indeed a martingale is more difficult. As noted by\n27\n\n\fProtter [35], some partial results exist in this case (see for example M\u00e9min [30] and\nmore recently Protter and Shimbo [34]), but none is as powerful as their counterparts\nin the continuous case, namely the Kamazaki or the Novikov conditions.\nTo show that the Dol\u00e9ans exponential introduced in (2.9) is a martingale we will\napply results derived by M\u00e9min [30]. We recall here the definition of the Dol\u00e9ansDade exponential as well as results from M\u00e9min [30] (see also Exercise 13 in Chapter\nV of [35]) on the multiplicative decomposition of local martingales that we will use to\nprove our point.\nDefinition A.1 (Dol\u00e9ans-Dade exponential). The Dol\u00e9ans-Dade exponential\nE(X)(t) of a semimartingale X(t) is defined as\n\u001b Y\n\u001a\n1 c c\n(A.1)\n(1 + \u2206Xt )e\u2212\u2206Xs\nE(X)(t) = exp X(t) \u2212 [X , X ]t\n2\n0<s\u2264t\n\nDefinition A.2 (M\u00e9min's Additive Decomposition of Local Martingales).\nLet M (t) be a local martingale. We define an additive decomposition of M into\ntwo processes M1 (t) and M2 (t), i.e. such that M (t) = M1 (t) + M2 (t).\nIn this decomposition, the process M1 (t) is defined as M1 (t) = L(t) \u2212 L\u0303(t) where\nX\nL(t) =\n\u2206Ms 1{|\u2206Ms |\u2265 1 }\n2\n\n0<s\u2264t\n\nand L\u0303(t) is the compensator of L(t).\nProposition A.3 (M\u00e9min's Proposition III-1). Let M (t) be a local martingale\nwith additive decomposition as per definition A.2 and such that M0 = 0. Then\n(i) E(M ) has the decomposition\nE(M ) = E(M2 )E(M\u03031 )\nwhere\nM\u03031 (t) = M1 (t) \u2212\n\nX \u2206M1 (s)\u2206M2 (s)\n,\n1 + \u2206M2 (s)\n\nt<\u221e\n\n0<s\u2264t\n\n(ii) E(M2 )M\u03031 is a local martingale.\n(iii) If \u2206M (s) > \u22121 then \u2206M\u03031 (s) > \u22121 for all finite s.\nCorollary A.4 (M\u00e9min's Corollary III-2). Let N be a local martingale such\nthat \u2206N (s) > \u22121 for all finite s, and such that E(N (\u221e) is uniformly integrable. Let\nP\u2032 be the probability defined as\ndP\u2032\n= E(N )(\u221e)\ndP\nLet N1 be a local martingale with locally integrable variations and denote by \u00d11\nthe P-semimartingale defined as\n\u00d11 (t) = N1 (t) \u2212\n\nX \u2206N1 (s)\u2206N (s)\n,\n1 + \u2206N (s)\n\n0<s\u2264t\n\n28\n\nt<\u221e\n\n\fthen \u00d11 is a P\u2032 local martingale,\nwith locally integrable variations. Moreover, the P\u2032\nP\npredictable\ncompensator of 0<s\u2264t |\u2206\u00d11 (s)| is equal to the P predictable compensator\nP\nof 0<s\u2264t |\u2206N1 (s)|.\n\nTheorem A.5 (M\u00e9min's Theorem III-3). Let M (t) be a local martingale with\nadditive decomposition as per definition A.2. If the predictable compensator of the\nprocess\nX\nX\n2\nY (t) = [M c , M c ]t +\n|\u2206M1 (s)| +\n(\u2206M2 (s))\n(A.2)\n0<s\u2264t\n\n0<s\u2264t\n\nis bounded, then E(M )(t) is uniformly integrable.\nProof of Proposition 6.3. To prove that the control h\u2217 (t) is admissible, we need\nto show that the local martingale M \u2217 (t) defined as\nZ tZ\nZ t\nT\nln (1 \u2212 G(z, h\u2217 (s))) \u00d1 (ds, dz) (A.3)\n(h\u2217 (s)) \u03a3dWs \u2212\nM \u2217 (t) := \u2212\u03b8\n0\n\n0\n\nZ\n\nand such that\nE(M )(t) = \u03c7\u2217t\nis an exponential martingale.\nTo achieve this objective, we will define a new class of control processes to which\nthe optimal control belongs. We will start from the definition of a control h as a\nfunction:\nh : [0, T ] \u00d7 Rn \u2192 J\n(t, x) 7\u2192 h(t, x)\nwhere the set J was defined in (2.7). Based on this definition, the control space can\nbe viewed as a functional space.\nDefine the functional L(x, p, h) as\n1\nL(x, p, h) := \u2212 (\u03b8 + 1) hT \u03a3\u03a3T h \u2212 \u03b8hT \u03a3\u039bT p + hT (\u00e2 + \u00c2x)\n2Z\no\ni\nnh\n\u0001\u2212\u03b8\n1\n1 + hT \u03b3(z)\n\u2212 1 + \u03b8hT \u03b3(z)1Z0 (z) \u03bd(dz)\n\u2212\n\u03b8 Z\n\n(A.4)\n\nwhere p \u2208 Rn so that\n\u0001 \u03b8\n1\nT\nsup Lht \u03a6 = (b + Bx) D\u03a6 + tr \u039b\u039bT D2 \u03a6 \u2212 (D\u03a6)T \u039b\u039bT D\u03a6 + a0 + AT0 x\n2\n2\nh\u2208J\n+ sup L(x, D\u03a6, h)\nh\u2208J\n\n(A.5)\nand the unique maximizer of Lht \u03a6(t, x), \u0125(t, x), is also the unique maximizer of\nL(x, D\u03a6, h).\n29\n\n\fObserve that with the choice of control function h0 (t, x) := 0 \u2200(t, x) \u2208 [0, T ] \u00d7 Rn ,\nthe functional L(x, p, h0 ) = 0 \u2200(t, x, p) \u2208 [0, T ] \u00d7 Rn \u00d7 Rn . Invoking the optimality\nprinciple, we deduce that L(x, D\u03a6, h\u2217 (t, x)) \u2265 0.\nDenote by J\u02c6 the range of the control functions h\u0303(t, x) such that L(x, p, h\u0303) \u2265\n0. Under Assumption 1, the set J , defined by (2.7), is in the interior of a hypercube and since the functional L(x, p, h) is smooth, strictly concave in h and\nlimh\u2192\u2202J L(x, p, h) = \u2212\u221e, we deduce that the set J\u02c6 is a closed convex subset of\nJ for all (t, x) \u2208 [0, T ] \u00d7 Rn . The control functions h\u0303 take the form\nh\u0303 : [0, T ] \u00d7 Rn \u2192 J\u02c6 \u2282 J\n(t, x) 7\u2192 h\u0303(t, x)\nMore formally, we can define a class \u0124(T ) of Markov control processes as\nDefinition A.6. A control process h\u0303(t) is in class \u0124(T ) if the following conditions are satisfied:\n1. h\u0303(t) is in class H introduced in Definition 2.1;\n2. h\u0303(t, x) \u2208 J\u02c6 \u2200(t, x) \u2208 [0, T ] \u00d7 Rn .\nIn particular, we note that the optimal control process h\u2217 (t) \u2208 \u0124(T ) \u2200t \u2208 [0, T ]\nand \u2200\u03c9 \u2208 \u03a9.\nFor any control policy h\u0303(t) \u2208 \u0124(T ), define the local martingale M\u0302 (t) as\nZ t\nZ tZ\n\u0010\n\u0011\nM\u0302 (t) := \u2212\u03b8\nln 1 \u2212 G(z, h\u0303(s)) \u00d1 (ds, dz)\nh\u0303(s)T \u03a3dWs \u2212\n0\n\n0\n\n(A.6)\n\nZ\n\nAlso, let L(t) be the process defined as\nX\nL(t) =\n\u2206Ys 1{|\u2206Ys |\u2265 1 }\n2\n\n0<s\u2264t\n\n=\u2212\n\nZ tZ\n0\n\nZ\\Z1\n\n\u0010\n\u0011\nln 1 \u2212 G(z, h\u0303(s)) N (ds, dz)\n\n\b\nwhere Z1 = z \u2208 Z : |\u2206Ys | < 12 , 0 \u2264 s \u2264 t . Then, the process M1 (t) := L(t) \u2212 L\u0303(t)\ncan be expressed as:\nZ tZ\n\u0010\n\u0011\nln 1 \u2212 G(z, h\u0303(s)) \u00d1 (ds, dz)\nM1 (t) = \u2212\n0\n\nZ\\Z1\n\nTo complete our decomposition of the local martingale M (t), we define the process\nM2 (t) as\nM2 (t) = M (t) \u2212 M1 (t)\nZ tZ\n\u0010\n\u0011\nln 1 \u2212 G(z, h\u0303(s)) \u00d1 (ds, dz)\n=\u2212\n0\n\nZ1\n\nThe next step is to study each component of the process Y (t) defined in (A.2):\n\u2022 The process\n\u001a Z t\n\u001b\nc\nc\n2\nT\nT\n[M , M ]t = exp \u03b8\nh\u0303(s) \u03a3\u03a3 h\u0303(s)ds\n0\n\nis clearly bounded because h\u0303(s) \u2208 \u0124(T ) for all s \u2208 [0, t];\n30\n\n\f\u2022 The process\nX\n\n|\u2206M1 (s)| =\n\nZ tZ\n0\n\n0<s\u2264t\n\nZ\\Z1\n\n\u0010\n\u0011\nln 1 \u2212 G(z, h\u0303(s)) N (ds, dz)\n\nis bounded because h\u0303(s) \u2208 \u0124(T ) for all s \u2208 [0, t]. In addition, the number of\njumps greater than 12 is finite:\nn\no\n# {0 \u2264 s \u2264 t; |\u2206M1 (s)|} = # 0 \u2264 s \u2264 t; |\u2206M (s)|1{|\u2206Ms |\u2265 1 }\n2\n\u0012 \u0015\n\u0014\u0013\n\u0014 \u0015\n1\n1\n= N t, \u2212\u221e, \u2212 \u222a , \u221e\n2\n2\n<\u221e\n\u2022 Finally, we turn our attention to the process\nZ tZ\n\u0010\n\u0011 2\nX\n2\nln 1 \u2212 G(z, h\u0303(s))\n(\u2206M2 (s)) =\nN (ds, dz)\n0\n\n0<s\u2264t\n\nZ1\n\nRecalling that we assumed that in our setting\nZ\n|\u03b3(z)|2 \u03bd(dz) < \u221e\nZ0\n\nand taking into consideration the fact that h\u0303(s) \u2208 \u0124(T ) for all s \u2208 [0, t], then\nwe deduce that\nZ\n\u0010\n\u0011 2\nln 1 \u2212 G(z, h\u0303(s))\n\u03bd(dz) < \u221e\nZ0\n\nfor any \u03c9 \u2208 \u03a9, which proves that\nZ tZ\n\u0010\n\u0011 2\nln 1 \u2212 G(z, h\u0303(s))\nN (ds, dz) < \u221e\n0\n\nZ1\n\nBy Theorem A.5, the Dol\u00e9ans-Dade exponential\nE(M\u0302 )(t) = \u03c7\u2217t\nis uniformly integrable for all h\u0303 \u2208 \u0124(T ). We can now apply Corollary A.4 to formally\ndefine the measure P\u03b8h\u0303 . In particular, the measure P\u03b8h\u2217 characterized via the Radon-\n\nNikodym derivative \u03c7\u2217t is well defined because h\u2217 (t) \u2208 \u0124(T ) \u2200\u03c9 \u2208 \u03a9. This proves\nthat the control h\u2217 (t) is admissible for all t \u2208 [0, T ] and \u03c9 \u2208 \u03a9.\n\nNote that the control policy h0 (t) = 0 corresponds to investing the entire wealth\ninto the money market asset for the duration of the investment period. The associated measure P\u03b8h0 is well defined and it is equal to the physical measure P. In fact,\nthis proof not only shows that the optimal control process h\u2217 (t) is admissible, but\nalso that a large class of \"reasonable\" control processes h\u0303(t) is also admissible and is\nassociated with a well-defined probability measure.\n31\n\n\f \u0303 t, h)\nProof of Proposition 6.4. Consider the exponentially transformed problem inf h\u2208A(T ) J(x,\nwhere\ni\nh\n \u0303 t, h) := ln E e\u2212\u03b8 ln V (t,x,h)\n(A.7)\nJ(x,\n \u0303 t, h)\nNote that because the term e\u2212\u03b8 ln V (t,x,h) is bounded from below by 0, inf h\u2208A(T ) J(x,\nis well defined which implies that there exists at least one minimizer h\u0303.\n\"\n( Z\n)#\nT\ni\nh\ng(s, Xs , h(s))ds \u2212 \u03b8 ln v\nE e\u2212\u03b8 ln V (t,x,h) = Eht,x exp \u03b8\nt\n\n(see for example Lemma 8.6.2. in [41]) and hence\n\"\n( Z\ni\nh\nh\n\u2212\u03b8 ln V (t,x,h)\n= inf Et,x exp \u03b8\ninf E e\nh\u2208A(T )\n\nh\u2208A(T )\n\nt\n\nT\n\ng(s, Xs , h(s))ds \u2212 \u03b8 ln v\n\n)#\n\n= I(v, x; h\u2217 (t); t, T )\n\nwhich proves that the optimal control h\u2217 (t) for the auxiliary problem suph\u2208A(T ) I(v, x; h; t, T )\nderived in Section 3.3 is indeed optimal for the problem suph\u2208A(T ) J(x, t, h).\n\nREFERENCES\n[1] R. Bellman. Dynamic Programming. Princeton University Press, 1957.\n[2] G. Barles and P.E. Souganidis. Convergence of approximation schemes for fully nonlinear\nsecond order equations. Journal of Asymptotic Analysis, 4:271\u2013283, 1991.\n[3] A. Bensoussan, J. Frehse, and H. Nagai. Some results on risk-sensitive control with full observation. Applied Mathematics and Optimization, 37:1\u201341, 1998.\n[4] T.R. Bielecki, D. Hernandez-Hernandez, and S.R. Pliska. Recent Developments in Mathematical\nFinance, chapter Risk sensitive Asset Management with Constrained Trading Strategies,\npages 127\u2013138. World Scientific, Singapore, 2002.\n[5] T.R. Bielecki and S.R. Pliska. Risk-sensitive dynamic asset management. Applied Mathematics\nand Optimization, 39:337\u2013360, 1999.\n[6] T.R. Bielecki and S.R. Pliska. Risk sensitive asset management with transaction costs. Finance\nand Stochastics, 4:1\u201333, 2000.\n[7] T.R. Bielecki and S.R. Pliska. Economic properties of the risk sensitive criterion for portfolio\nmanagement. The Review of Accounting and Finance, 2(2):3\u201317, 2003.\n[8] T.R. Bielecki and S.R. Pliska. Risk sensitive intertemporal CAPM with applications to fixedincome management. IEEE Transactions on Automatic Control, 49(3):420\u2013432, March\n2004.\n[9] T.R. Bielecki, S.R. Pliska, and S.J. Sheu. Risk sensitive portfolio management with CoxIngersoll-Ross interest rates: the HJB equation. SIAM Journal of Control and Optimization, 44:1811\u20131843, 2005.\n[10] F. Black. Capital market equilibrium with restricted borrowing. Journal of Business, 45(1):445\u2013\n454, 1972.\n[11] M. Crandall, H. Ishii, and P.-L. Lions. User's Guide to Viscosity Solutions of Second Order\nPartial Differential Equations. AMS, 27(1):1\u201367, 1992.\n[12] M.H.A. Davis and S. Lleo. Risk-sensitive benchmarked asset management. Quantitative Finance, 8(4):415\u2013426, June 2008.\n[13] M.H.A. Davis and S. Lleo. Risk-Sensitive Asset Management and Affine Processes. In Recent\nAdvances in Financial Engineering 2009 - Proceedings of the KIER-TMU International\nWorkshop on Financial Engineering 2009, eds. M. Kijima et al., World Scientific 2010.\n[14] M.H.A. Davis and S. Lleo. Jump-diffusion Risk-Sensitive Asset Management II: Jump-Diffusion\nFactors, preprint, Imperial College London 2010. Earlier version at arXiv:1001.1379\n[15] W.H. Fleming. Optimal Investment Models and Risk-Sensitive Stochastic Control, in Mathematical Finance, IMA Volumes in Mathematics and its Applications, volume 65, pp 75\u201388.\nSpringer 1995.\n32\n\n\f[16] W.H. Fleming and R.W. Rishel. Deterministic and Stochastic Optimal Control. Springer 1975.\n[17] W. H. Fleming and S.J. Sheu Optimal Long Term Growth Rate of Expected Utility of Wealth.\nThe Annals of Applied Probability, 9(3):871\u2013903, 1999.\n[18] W. H. Fleming and S.J. Sheu Risk-Sensitive Control and an Optimal Investment Model.\nMathematical Finance, 10(2):197\u2013213, 2000.\n[19] W. H. Fleming and S.J. Sheu Risk-Sensitive Control and an Optimal Investment Model II.\nThe Annals of Applied Probability, 12(2):730\u2013767, 2000.\n[20] W.H. Fleming and H.M. Soner. Controlled Markov Processes and Viscosity Solutions, 2nd ed.,\nvolume 25 of Stochastic Modeling and Applied Probability. Springer 2006.\n[21] I.I. Gihman and A. Skorokhod. Stochastic Differential Equations, volume New-York. Springer\n1972.\n[22] L.P. Hansen and T.J. Sargent. Robustness, Princeton University Press, 2008.\n[23] N. Ikeda and S. Watanabe. Stochastic Differential Equations and Diffusion Processes. NorthHolland Publishing Company, 1981.\n[24] N.V. Krylov. Controlled Diffusion Processes. Springer 1980.\n[25] N.V. Krylov. Nonlinear Elliptic and Parabolic Equations of the Second Order. Kluwer 1987.\n[26] H.J. Kushner and P.G. Dupuis. Numerical Methods for Stochastic Control Problems in Continuous Time, 2nd ed., volume 24 of Stochastic Modeling and Applied Probability. Springer\n2001.\n[27] K. Kuroda and H. Nagai. Risk-sensitive portfolio optimization on infinite time horizon. Stochastics and Stochastics Reports, 73:309\u2013331, 2002.\n[28] O.A. Ladyzenskaja, V.A. Solonnikov, and O.O. Uralceva. Linear and Quasilinear Equations\nof Parabolic Type. American Mathematical Society, Providence RI, 1968.\n[29] M. Lefebvre and P. Montulet. Risk-sensitive optimal investment policy. International Journal\nof Systems Science, 22:183\u2013192, 1994.\n[30] J. M\u00e9min. S\u00e9minaires de Probabilit\u00e9s XII, volume 649 of Lecture Notes in Mathematics, chapter\nD\u00e9composition multiplicative de semimartingales exponentielles et applications, pages 35\u2013\n46. Springer 1979.\n[31] R.C. Merton. Continuous-Time Finance. Basil Blackwell 1992.\n[32] H. Nagai. Risk-Sensitive Dynamic Asset Management with Partial Information, in Stochastics\nin Finite and Infinite Dimensions, in Honor of Gopinath Kallianpur, T. Hida and R.L.\nKarandikar and H. Kunita and B.S. Rajput and S. Watanabe editors, pages 321\u2013340.\nBirkhauser, 2001.\n[33] H. Nagai and S. Peng. Risk-Sensitive Dynamic Portfolio Optimization with Partial Information\non Infinite Time Horizon. The Annals of Applied Probability, 12(1):173\u2013195, 2002.\n[34] P. Protter and K. Shimbo. No arbitrage and general semimartingales. In Markov Processes and\nRelated Topics: A Festschrift for Thomas G. Kurtz, pages 267\u2013283. IMS Lecture Notes Monograph Series 4, 2008.\n[35] P.E. Protter. Stochastic Integration and Differential Equations, 2nd ed. Springer 2004.\n[36] L.C.G. Rogers and D. Williams. Diffusions, Markov Processes and Martingales: Volume II,\nIto Calculus, 2nd ed. Cambridge University Press, 2000.\n[37] N.\nTouzi.\nStochastic\ncontrol\nand\napplication\nto\nfinance.\nhttp://www.cmap.polytechnique.fr/ \u0303touzi/pise02.pdf, 2002. Special Research Semester\non Financial Mathematics, Scuola Normale Superiore, Pisa, April 29-July 15 2002.\n[38] S. Wan. Risk sensitive optimal portfolio model under jump processes. In Chinese Control\nConference 2006, pages 607\u2013610. IEEE, 2006.\n[39] P. Whittle. Risk Sensitive Optimal Control. Wiley 1990.\n[40] W.M. Wonham. On the Separation theorem of stochastic control. SIAM J. Control, 6(2):312\u2013\n326, 1968.\n[41] B. \u00d8ksendal. Stochastic Differential Equations, 6th ed. Universitext. Springer 2003.\n[42] B. \u00d8ksendal and A. Sulem. Applied Stochastic Control of Jump Diffusions. Universitext.\nSpringer 2005.\n\n33\n\n\f"}