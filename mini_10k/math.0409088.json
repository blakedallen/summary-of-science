{"id": "http://arxiv.org/abs/math/0409088v1", "guidislink": true, "updated": "2004-09-06T17:58:08Z", "updated_parsed": [2004, 9, 6, 17, 58, 8, 0, 250, 0], "published": "2004-09-06T17:58:08Z", "published_parsed": [2004, 9, 6, 17, 58, 8, 0, 250, 0], "title": "Normal Approximation in Geometric Probability", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0409551%2Cmath%2F0409570%2Cmath%2F0409427%2Cmath%2F0409040%2Cmath%2F0409419%2Cmath%2F0409180%2Cmath%2F0409424%2Cmath%2F0409600%2Cmath%2F0409393%2Cmath%2F0409446%2Cmath%2F0409361%2Cmath%2F0409433%2Cmath%2F0409447%2Cmath%2F0409474%2Cmath%2F0409591%2Cmath%2F0409182%2Cmath%2F0409384%2Cmath%2F0409475%2Cmath%2F0409606%2Cmath%2F0409185%2Cmath%2F0409341%2Cmath%2F0409297%2Cmath%2F0409178%2Cmath%2F0409311%2Cmath%2F0409499%2Cmath%2F0409049%2Cmath%2F0409070%2Cmath%2F0409210%2Cmath%2F0409584%2Cmath%2F0409261%2Cmath%2F0409595%2Cmath%2F0409066%2Cmath%2F0409123%2Cmath%2F0409452%2Cmath%2F0409325%2Cmath%2F0409272%2Cmath%2F0409232%2Cmath%2F0409548%2Cmath%2F0409416%2Cmath%2F0409480%2Cmath%2F0409239%2Cmath%2F0409497%2Cmath%2F0409152%2Cmath%2F0409516%2Cmath%2F0409422%2Cmath%2F0409556%2Cmath%2F0409538%2Cmath%2F0409241%2Cmath%2F0409085%2Cmath%2F0409307%2Cmath%2F0409362%2Cmath%2F0409245%2Cmath%2F0409132%2Cmath%2F0409004%2Cmath%2F0409296%2Cmath%2F0409306%2Cmath%2F0409343%2Cmath%2F0409189%2Cmath%2F0409089%2Cmath%2F0409510%2Cmath%2F0409173%2Cmath%2F0409445%2Cmath%2F0409172%2Cmath%2F0409018%2Cmath%2F0409069%2Cmath%2F0409354%2Cmath%2F0409011%2Cmath%2F0409095%2Cmath%2F0409515%2Cmath%2F0409005%2Cmath%2F0409601%2Cmath%2F0409192%2Cmath%2F0409023%2Cmath%2F0409320%2Cmath%2F0409385%2Cmath%2F0409235%2Cmath%2F0409002%2Cmath%2F0409227%2Cmath%2F0409450%2Cmath%2F0409222%2Cmath%2F0409533%2Cmath%2F0409557%2Cmath%2F0409440%2Cmath%2F0409007%2Cmath%2F0409103%2Cmath%2F0409141%2Cmath%2F0409088%2Cmath%2F0409509%2Cmath%2F0409218%2Cmath%2F0409594%2Cmath%2F0409107%2Cmath%2F0409242%2Cmath%2F0409110%2Cmath%2F0409492%2Cmath%2F0409324%2Cmath%2F0409521%2Cmath%2F0409577%2Cmath%2F0409518%2Cmath%2F0409596%2Cmath%2F0409318%2Cmath%2F0409017&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Normal Approximation in Geometric Probability"}, "summary": "We use Stein's method to obtain bounds on the rate of convergence for a class\nof statistics in geometric probability obtained as a sum of contributions from\nPoisson points which are exponentially stabilizing, i.e. locally determined in\na certain sense. Examples include statistics such as total edge length and\ntotal number of edges of graphs in computational geometry and the total number\nof particles accepted in random sequential packing models. These rates also\napply to the 1-dimensional marginals of the random measures associated with\nthese statistics.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0409551%2Cmath%2F0409570%2Cmath%2F0409427%2Cmath%2F0409040%2Cmath%2F0409419%2Cmath%2F0409180%2Cmath%2F0409424%2Cmath%2F0409600%2Cmath%2F0409393%2Cmath%2F0409446%2Cmath%2F0409361%2Cmath%2F0409433%2Cmath%2F0409447%2Cmath%2F0409474%2Cmath%2F0409591%2Cmath%2F0409182%2Cmath%2F0409384%2Cmath%2F0409475%2Cmath%2F0409606%2Cmath%2F0409185%2Cmath%2F0409341%2Cmath%2F0409297%2Cmath%2F0409178%2Cmath%2F0409311%2Cmath%2F0409499%2Cmath%2F0409049%2Cmath%2F0409070%2Cmath%2F0409210%2Cmath%2F0409584%2Cmath%2F0409261%2Cmath%2F0409595%2Cmath%2F0409066%2Cmath%2F0409123%2Cmath%2F0409452%2Cmath%2F0409325%2Cmath%2F0409272%2Cmath%2F0409232%2Cmath%2F0409548%2Cmath%2F0409416%2Cmath%2F0409480%2Cmath%2F0409239%2Cmath%2F0409497%2Cmath%2F0409152%2Cmath%2F0409516%2Cmath%2F0409422%2Cmath%2F0409556%2Cmath%2F0409538%2Cmath%2F0409241%2Cmath%2F0409085%2Cmath%2F0409307%2Cmath%2F0409362%2Cmath%2F0409245%2Cmath%2F0409132%2Cmath%2F0409004%2Cmath%2F0409296%2Cmath%2F0409306%2Cmath%2F0409343%2Cmath%2F0409189%2Cmath%2F0409089%2Cmath%2F0409510%2Cmath%2F0409173%2Cmath%2F0409445%2Cmath%2F0409172%2Cmath%2F0409018%2Cmath%2F0409069%2Cmath%2F0409354%2Cmath%2F0409011%2Cmath%2F0409095%2Cmath%2F0409515%2Cmath%2F0409005%2Cmath%2F0409601%2Cmath%2F0409192%2Cmath%2F0409023%2Cmath%2F0409320%2Cmath%2F0409385%2Cmath%2F0409235%2Cmath%2F0409002%2Cmath%2F0409227%2Cmath%2F0409450%2Cmath%2F0409222%2Cmath%2F0409533%2Cmath%2F0409557%2Cmath%2F0409440%2Cmath%2F0409007%2Cmath%2F0409103%2Cmath%2F0409141%2Cmath%2F0409088%2Cmath%2F0409509%2Cmath%2F0409218%2Cmath%2F0409594%2Cmath%2F0409107%2Cmath%2F0409242%2Cmath%2F0409110%2Cmath%2F0409492%2Cmath%2F0409324%2Cmath%2F0409521%2Cmath%2F0409577%2Cmath%2F0409518%2Cmath%2F0409596%2Cmath%2F0409318%2Cmath%2F0409017&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We use Stein's method to obtain bounds on the rate of convergence for a class\nof statistics in geometric probability obtained as a sum of contributions from\nPoisson points which are exponentially stabilizing, i.e. locally determined in\na certain sense. Examples include statistics such as total edge length and\ntotal number of edges of graphs in computational geometry and the total number\nof particles accepted in random sequential packing models. These rates also\napply to the 1-dimensional marginals of the random measures associated with\nthese statistics."}, "authors": ["Mathew D. Penrose", "J. E. Yukich"], "author_detail": {"name": "J. E. Yukich"}, "author": "J. E. Yukich", "arxiv_comment": "To appear in the proceedings of the Workshop on Stein's Method and\n  Applications, 11-15 August 2003, Institute of Mathematical Sciences, National\n  University of Singapore", "links": [{"href": "http://arxiv.org/abs/math/0409088v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0409088v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60D05; 60F05", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0409088v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0409088v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0409088v1 [math.PR] 6 Sep 2004\n\nNormal Approximation in Geometric\nProbability\nMathew D. Penrose1 and J. E. Yukich2\nUniversity of Bath and Lehigh University\n\nSeptember 3, 2018\n\nAbstract\nWe use Stein's method to obtain bounds on the rate of convergence for\na class of statistics in geometric probability obtained as a sum of contributions from Poisson points which are exponentially stabilizing, i.e. locally\ndetermined in a certain sense. Examples include statistics such as total edge\nlength and total number of edges of graphs in computational geometry and\nthe total number of particles accepted in random sequential packing models.\nThese rates also apply to the 1-dimensional marginals of the random measures\nassociated with these statistics.\n\n1\n\nDepartment of Mathematical Sciences, University of Bath, Bath BA1 7AY, United Kingdom:\nm.d.penrose@bath.ac.uk\n2\nDepartment of Mathematics,\nLehigh University,\nBethlehem PA 18015:\njoseph.yukich@lehigh.edu\n2\nResearch supported in part by NSA grant MDA904-01-1-0029 and NSF grant DMS-0203720\n\n1\n\n\f1\n\nIntroduction\n\nIn the study of limit theorems for functionals on Poisson or binomial spatial point\nprocesses, the notion of stabilization has recently proved to be a useful unifying\nconcept [4, 11, 13]. Laws of large numbers and central limit theorems can be proved\nin the general setting of functionals satisfying an abstract 'stabilization' property\nwhereby the insertion of a point into a Poisson process has only a local effect in some\nsense. These results can then be applied to deduce limit laws for a great variety of\nparticular functionals, including those concerned with the minimal spanning tree,\nthe nearest neighbor graph, Voronoi and Delaunay graphs, packing, and germ-grain\nmodels.\nSeveral different techniques are available for proving general central limit theorems for stabilizing functionals. These include a martingale approach [11] and a\nmethod of moments [4]. In the present work, we revisit a third technique for proving\ncentral limit theorems for stabilizing functionals on Poisson point processes, which\nwas introduced by Avram and Bertsimas [1]. This method is based on the normal\napproximation of sums of random variables which are 'mostly independent of one\nanother' in a sense made precise via dependency graphs, which in turn is proved\nvia Stein's method [14]. It has the advantage of providing explicit error bounds and\nrates of convergence.\nWe extend the work of Avram and Bertsimas in several directions. First, whereas\nin [1] attention was restricted to certain particular functionals, here we derive a general result holding for arbitrary functionals satisfying a stabilization condition which\ncan then be checked rather easily for many special cases. Second, we consider nonuniform point process intensities and do not require the functionals to be translation\ninvariant. Third, we improve on the rates of convergence in [1] by making use of the\nrecent refinement by Chen and Shao [7] of previous normal approximation results\nfor sums of 'mostly independent' variables. Finally, we apply the methods not only\nto random variables obtained by summing some quantity over Poisson points, but\nto the associated random point measures, thereby recovering many of the results of\nBaryshnikov and Yukich [4] on convergence of these measures, and without requiring\nhigher order moment calculations. We add to [4] by providing information about\nthe rate of convergence, and relaxing the continuity conditions required in [4] for\ntest functions and point process intensities.\nA brief comparison between the methods of deriving central limit theorems for\nfunctionals of spatial point processes is warranted. Only the dependency graph\nmethod used here, to date, has yielded error bounds and rates of convergence. On\nthe other hand, our method requires bounds on the tail of the 'radius of stabilization'\n(i.e., on the range of the local effect of an inserted point). The martingale method,\nin contrast, requires only that this radius be almost surely finite, and for this reason\nis applicable to some examples such as those concerned with the minimal spanning\ntree, for which no tail bounds are known and which therefore lie beyond the scope of\n2\n\n\fthe present work. The moment method [4] and martingale method [10], unlike the\ndependency graph method, provide information about the variance of the Gaussian\nlimits. The moment method has also been used [5] to establish moderate scale limit\nbehavior of functionals of spatial point processes. Whereas the moment method\nrequires exponential tail bounds for the radius of stabilization, one of our central\nlimit theorems (Theorem 2.2) requires only that this tail \u03c4 (t) decay as a (large)\nnegative power of t.\nWith regard to ease of use in applications, the dependency graph method and\nmethod of moments require checking tail bounds for the radius of stabilization,\nwhich is usually straightforward where possible at all. The method of moments\nrequires a more complicated (though checkable) version of the bounded moments\ncondition (2.5) below (see [4]). The dependency graph method requires some separate calculation of variances if one wishes to identify explicitly the variance of the\nlimiting normal variable. The martingale method requires the checking of slightly\nmore subtle versions of the stabilization conditions needed here [10, 11].\n\n2\n\nGeneral results\n\nLet d \u2265 1 be an integer. For the sake of generality, we consider marked point\nprocesses in Rd . Let (M, FM , PM ) be a probability space (the mark space). Let\n\u03be((x, s); X ) be a measurable R-valued function defined for all pairs ((x, s), X ), where\nX \u2282 Rd \u00d7 M is finite and where (x, s) \u2208 X (so x \u2208 Rd and s \u2208 M). When\n(x, s) \u2208 (Rd \u00d7 M) \\ X , we abbreviate notation and write \u03be((x, s); X ) instead of\n\u03be((x, s); X \u222a {(x, s)}).\nGiven X \u2282 Rd \u00d7 M, a > 0 and y \u2208 Rd , we let aX := {(ax, t) : (x, t) \u2208 X }\nand y + X := {(y + x, t) : (x, t) \u2208 X }; in other words, translation and scalar\nmultiplication on Rd \u00d7 M act only on the first component. For all \u03bb > 0 let\n\u03be\u03bb ((x, s); X ) := \u03be((x, s); x + \u03bb1/d (\u2212x + X )).\nWe say \u03be is translation invariant if \u03be((y + x, s); y + X ) = \u03be((x, s); X ) for all\ny \u2208 Rd , all (x, s) \u2208 Rd \u00d7 M and all finite X \u2282 Rd \u00d7 M. When \u03be is translation\ninvariant, the functional \u03be\u03bb simplifies to \u03be\u03bb ((x, s); X ) = \u03be((\u03bb1/d x, s); \u03bb1/d X ).\nLet \u03ba be a probability density function on Rd with compact support A \u2282 Rd . For\nall \u03bb > 0, let P\u03bb denote a Poisson point process in Rd \u00d7 M with intensity measure\n(\u03bb\u03ba(x)dx)\u00d7PM (ds). We shall assume throughout that \u03ba is bounded with supremum\ndenoted k\u03bak\u221e .\nLet (A\u03bb , \u03bb \u2265 1) be a family of Borel subsets of A. The simplest case, with\nA\u03bb = A for all \u03bb, covers all examples considered here; we envisage possibly using\nthe general case in future work.\nThe following notion of exponential stabilization, adapted from [4], plays a central role in all that follows. For x \u2208 Rd and r > 0, let Br (x) denote the Euclidean ball\n3\n\n\fcentered at x of radius r. Let U denote a random element of M with distribution\nPM , independent of P\u03bb .\nDefinition 2.1 \u03be is exponentially stabilizing with respect to \u03ba and (A\u03bb )\u03bb\u22651 if for\nall \u03bb \u2265 1 and all x \u2208 A\u03bb , there exists an a.s. finite random variable R := R(x, \u03bb) (a\nradius of stabilization for \u03be at x) such that for all finite X \u2282 (A \\ B\u03bb\u22121/d R (x)) \u00d7 M,\nwe have\n\u03be\u03bb ((x, U); [P\u03bb \u2229 (B\u03bb\u22121/d R (x) \u00d7 M)] \u222a X ) = \u03be\u03bb ((x, U); P\u03bb \u2229 (B\u03bb\u22121/d R (x) \u00d7 M)) ,\n(2.1)\nand moreover the tail probability \u03c4 (t) defined for t > 0 by\n\u03c4 (t) :=\n\nsup\n\nP [R(x, \u03bb) > t]\n\n(2.2)\n\n\u03bb\u22651, x\u2208A\u03bb\n\nsatisfies\nlim sup t\u22121 log \u03c4 (t) < 0.\n\n(2.3)\n\nt\u2192\u221e\n\nFor \u03b3 > 0, we say \u03be is polynomially stabilizing of order \u03b3 if the above conditions\nhold with (2.3) replaced by the condition lim supt\u2192\u221e t\u03b3 \u03c4 (t) < \u221e.\nCondition (2.1) may be cast in a more transparent form as follows. Each point\nof X is a pair (x, U), with x \u2208 Rd and U \u2208 M, but for notational convenience we\ncan view it as a point x in Rd carrying a mark U := Ux . Then we can view X as\na point set in Rd with each point carrying a mark in M. With this interpretation,\n(2.1) stipulates that for all finite (marked) X \u2282 A \\ B\u03bb\u22121/d R (x), we have\n\u03be\u03bb (x; (P\u03bb \u2229 B\u03bb\u22121/d R (x)) \u222a X ) = \u03be\u03bb (x; P\u03bb \u2229 B\u03bb\u22121/d R (x)) .\n\n(2.4)\n\nRoughly speaking, R := R(x, \u03bb) is a radius of stabilization if the value of \u03be\u03bb (x; P\u03bb )\nis unaffected by changes to the points outside B\u03bb\u22121/d R (x).\nFunctionals of spatial point processes often satisfy exponential stabilization (2.1)\n(or (2.4)); here is an example. Suppose M = [0, 1] and PM is the uniform distribution on [0, 1]. Suppose that A is convex or polyhedral, and \u03ba is bounded away from\nzero on A. Suppose a measurable function (q(x), x \u2208 A) is specified, taking values\nin [0, 1]. Adopting the conventions of the preceding paragraph, for a marked point\nset X \u2282 Rd let us denote each point x \u2208 X as 'red' if Ux \u2264 q(x) and as 'green' if\nUx > q(x). Let \u03be(x; X ) take the value 0 if the nearest neighbor of x in X has the\nsame color as x, and take the value 1 otherwise. Note that \u03be is not translation invariant in this example, unless q(*) is constant. For x \u2208 A let R := R(x, \u03bb) denote the\ndistance between \u03bb1/d x and its nearest neighbor in \u03bb1/d P\u03bb . Then stabilization (2.4)\nholds because points lying outside B\u03bb\u22121/d R (x) will not change the value of \u03be\u03bb (x; P\u03bb ),\nand it is easy to see that R has exponentially decaying tails. This example is relevant to the multivariate two-sample test described by Henze [8]. See Section 3 for\nfurther examples.\n4\n\n\fDefinition 2.2 \u03be has a moment of order p > 0 (with respect to \u03ba and (A\u03bb )\u03bb\u22651 ) if\nsup\n\u03bb\u22651, x\u2208A\u03bb\n\nE [|\u03be\u03bb ((x, U); P\u03bb )|p ] < \u221e.\n\n(2.5)\n\nFor \u03bb > 0, define the random weighted point measure \u03bc\u03be\u03bb on Rd by\nX\n\u03bc\u03be\u03bb :=\n\u03be\u03bb ((x, s); P\u03bb )\u03b4x\n(x,s)\u2208P\u03bb \u2229(A\u03bb \u00d7M)\n\nand the centered version \u03bc\u03be\u03bb := \u03bc\u03be\u03bb \u2212 E [\u03bc\u03be\u03bb ].\nLet B(A) denote theRset of bounded Borel-measurable\nfunctions on A. Given\nR\n\u03be\n\u03be\n\u03be\n\u03be\nf \u2208 B(A), let hf, \u03bc\u03bb i := A f d\u03bc\u03bb and hf, \u03bc\u03bb i := A f d\u03bc\u03bb .\nLet \u03a6 denote the distribution function of the standard normal. Our main result\nis a normal approximation result for hf, \u03bc\u03be\u03bb i, suitably scaled.\nTheorem 2.1 Suppose k\u03bak\u221e < \u221e. Suppose that \u03be is exponentially stabilizing and\nsatisfies the moments condition (2.5) for some p > 2. Let q \u2208 (2, 3] with q < p. Let\nf \u2208 B(A) and put T\u03bb := hf, \u03bc\u03be\u03bb i. Then there exists a finite constant C depending on\nd, \u03be, \u03ba, p, q and f , such that for all \u03bb \u2265 2,\n\u0015\n\u0014\nT\u03bb \u2212 E T\u03bb\n(2.6)\nsup P\n\u2264 t \u2212 \u03a6(t) \u2264 C(log \u03bb)dq \u03bb(VarT\u03bb )\u2212q/2 .\n1/2\n(VarT\u03bb )\nt\u2208R\nSeparate arguments are required to establish the asymptotic behavior of the\ndenominator (Var(T\u03bb ))1/2 in (2.6). When A\u03bb = A for all \u03bb, it is typically the case\nfor polynomially stabilizing functionals satisfying moments conditions along the lines\nof (2.5) that there is a constant \u03c3 2 (f, \u03be, \u03ba) \u2265 0 such that\nlim \u03bb\u22121 Varhf, \u03bc\u03be\u03bb i = \u03c3 2 (f, \u03be, \u03ba).\n\n\u03bb\u2192\u221e\n\n(2.7)\n\nFor further information about \u03c3 2 (f, \u03be, \u03ba) and precise conditions under which (2.7)\nholds, see Theorem 2.4(i) of [4]. When (2.7) holds, by combining it with Theorem\n2.1 we obtain\n\u0001\nD\nhf, \u03bb\u22121/2 \u03bc\u03be\u03bb i \u2212\u2192 N 0, \u03c3 2 (f, \u03be, \u03ba) ,\n(2.8)\n\nwhere N (0, \u03c3 2) denotes a centered normal distribution with variance \u03c3 2 if \u03c3 2 > 0,\nand a unit point mass at 0 if \u03c3 2 = 0.\nIn many applications (2.7) holds with \u03c3 2 (f, \u03be, \u03ba) > 0, showing that the case q = 3\nof (2.6) yields a rate of convergence O((log \u03bb)3d \u03bb\u22121/2 ) to the normal distribution. In\nother words, we will make frequent use of:\n\n5\n\n\fCorollary 2.1 Suppose k\u03bak\u221e < \u221e. Suppose that \u03be is exponentially stabilizing and\nsatisfies the moments condition (2.5) for some p > 3. Let f \u2208 B(A) and put\nT\u03bb := hf, \u03bc\u03be\u03bbi. If (2.7) holds with \u03c3 2 (f, \u03be, \u03ba) > 0, then there exists a finite constant\nC depending on d, \u03be, \u03ba, p and f , such that for all \u03bb \u2265 2,\n\u0015\n\u0014\nT\u03bb \u2212 E T\u03bb\n\u2264 t \u2212 \u03a6(t) \u2264 C(log \u03bb)3d \u03bb\u22121/2 .\nsup P\n1/2\n(VarT\u03bb )\nt\u2208R\nOur methods actually yield normal approximation and a central limit theorem\nwhen the exponential decay condition is replaced by a polynomial decay condition\nof sufficiently high order. We give a further result along these lines.\nTheorem 2.2 Suppose k\u03bak\u221e < \u221e. Suppose for some p > 3 that \u03be is polynomially\nstabilizing of order \u03b3 with \u03b3 > d(150 + 6/p), and satisfies the moments condition\n(2.5). Let f \u2208 B(A) and put T\u03bb := hf, \u03bc\u03be\u03bbi. Suppose that (2.7) holds for some\n\u03c3 2 \u2265 0. Then (2.8) holds and if \u03c3 2 := \u03c3 2 (f, \u03be, \u03ba) > 0 there exists a finite constant\nC depending on d, \u03be, \u03ba, p and f , such that for all \u03bb \u2265 2,\n\u0014\n\u0015\nT\u03bb \u2212 E T\u03bb\nsup P\n(2.9)\n\u2264 t \u2212 \u03a6(t) \u2264 C\u03bb(150pd+6d\u2212p\u03b3)/2(p\u03b3\u22126d) .\n(VarT\u03bb )1/2\nt\u2208R\nRemarks\n1. Our results are stated for marked Poisson point processes, i.e., for Poisson\nprocesses in Rd \u00d7 M where M is the mark space. These results are reduced to\nthe corresponding results for unmarked Poisson point processes in Rd by taking\nM to have a single element (denoted m, say) and identifying Rd \u00d7 M with Rd\nin the obvious way by identifying (x, m) with x for each x \u2208 Rd . In this case the\nnotation (2.4) is particularly appropriate. Other treatments such as [4, 10, 11,\n12] tend to concentrate on the unmarked case with commentary that the proofs\ncarry through to the marked case; here we spell out the results and proofs in\nthe more general marked case, which seems worthwhile since examples such as\nthose in Section 3.3 use the results for marked point processes. Our examples\nin Sections 3.1, 3.2, and 3.4 refer to unmarked point processes and in these\nexamples we identify Rd \u00d7 {m} with Rd as indicated above (so that P\u03bb is\nviewed as a Poisson process in Rd ).\n2. We are not sure if the logarithmic factors can be removed in Theorem 2.1 or\nCorollary 2.1. Avram and Bertsimas [1] obtain a rate of O((log \u03bb)1+3/(2d) \u03bb\u22121/4 ),\nfor the length of the k-nearest neighbors (directed) graph, the Voronoi graph,\nand the Delaunay graph (see Sections 3.1 and 3.2). Our method for general\nstabilizing functionals is based on theirs, but uses a stronger general normal\napproximation result (Lemma 4.1 below).\n\n6\n\n\f3. If (2.7) holds with \u03c3 2 (f, \u03be, \u03ba) = 0, then (2.8) holds trivially by Chebyshev's\ninequality, but Theorem 2.1 does not provide any useful information on rate\nof convergence. In examples of interest, it can usually be established that\n\u03c3 2 (f, \u03be, \u03ba) > 0, by further separate arguments. We do not discuss these in\ndetail here but refer the reader to [1, 11, 4].\n4. Theorems 2.1, 2.2, and Corollary 2.1 require neither the underlying density\nfunction \u03ba nor the test function f to be continuous (both of these conditions\nare imposed in [4]). In particular, these three results apply when f is the\nindicator function of a Borel subset B of A, giving normal approximation for\n\u03bc\u0304\u03be\u03bb (B).\n5. We do not have rate of convergence results in the binomial (non-Poisson)\nsetting. For central limit theorems in the binomial setting, we refer to [11]\nand [4], which treat uniform and non-uniform samples respectively.\n6. Some functionals, such as those defined in terms of the minimal spanning tree,\nstabilize without any known bounds on the rate of decay of the tail probability\n\u03c4 (t). In these cases univariate and multivariate central limit theorems hold\n[10, 11] but our Theorems 2.1 and 2.2 do not apply and explicit rates of\nconvergence are not known.\n\n3\n\nApplications\n\nApplications of Corollary 2.1 to geometric probability include functionals of proximity graphs, germ-grain models, and random sequential packing models. The following examples are for illustrative purposes only and are not meant to be encyclopedic.\nFor simplicity we will assume that Rd is equipped with the usual Euclidean metric. While translation invariance is not needed in the general results in Section 2,\nmost of the examples treated in this section involve translation invariant functionals\n\u03be. However, the examples can be modified to treat the (non-translation-invariant)\nsituation where Rd has a local metric structure.\n\n3.1\n\nk-nearest neighbors graph\n\nLet k be a positive integer. Given a locally finite point set X \u2282 Rd , the k-nearest\nneighbors (undirected) graph on X , denoted kNG(X ), is the graph with vertex\nset X obtained by including {x, y} as an edge whenever y is one of the k nearest\nneighbors of x and/or x is one of the k nearest neighbors of y. The k-nearest\nneighbors (directed) graph on X , denoted kNG\u2032 (X ), is the graph with vertex set X\nobtained by placing a directed edge between each point and its k nearest neighbors.\nLet N k (X ) denote the total edge\nk-nearest neighbors\nPlengthk of the (undirected)\nk\nk\ngraph on X . Note that N (X ) = x\u2208X \u03be (x; X ), where \u03be (x; X ) denotes half the\n7\n\n\fsum of the edge lengths in kNG(X ) incident to x. If A is convex or polyhedral and\n\u03ba is bounded away from 0 on A, then \u03be k is exponentially stabilizing (cf. Lemma 6.1\nof [11]) and has moments of all orders. Moreover, as shown in [4] (see e.g. display\n(2.11), Theorem 3.1), at least when f is continuous and A\u03bb = A for all \u03bb,\nZ\n\u03be\n\u22121\n\u03be\nf (x)2 \u03ba(x)(d\u22122)/d dx,\nlim \u03bb Varhf, \u03bc\u03bb i = V\n\u03bb\u2192\u221e\n\nA\n\nwhere V \u03be denotes the limiting variance for the total edge length of the k-nearest\nneighbors graph on \u03bb1/d P\u03bb when \u03ba is the uniform distribution on the unit cube.\nSince V \u03be is strictly positive (Theorem 6.1 of [11]), it follows that (2.7) holds with\n\u03c3 2 (f, \u03be k , \u03ba) > 0. We thus obtain via Corollary 2.1 the following rates in the CLT\nfor the total edge length of N k (\u03bb1/d P\u03bb ) improving upon Avram and Bertsimas [1]\nand Bickel and Breiman [6]. A similar CLT holds for the total edge length of the\nk-nearest neighbors directed graph.\nTheorem 3.1 Suppose A is convex or polyhedral and \u03ba is bounded away from 0 on\nA. Let N\u03bb := N k (\u03bb1/d P\u03bb ) denote the total edge length of the k-nearest neighbors\ngraph on \u03bb1/d P\u03bb . There exists a finite constant C depending on d, \u03be k , and \u03ba such\nthat\n\u0014\n\u0015\nN\u03bb \u2212 E N\u03bb\nsup P\n(3.1)\n\u2264 t \u2212 \u03a6(t) \u2264 C(log \u03bb)3d \u03bb\u22121/2 .\n1/2\n(VarN\n)\nt\u2208R\n\u03bb\nSimilarly, letting \u03be s (x; X ) be one or zero according to whether the distance between x and its nearest neighbor in X is less than s orPnot, we can verify that\n\u03be s is exponentially stabilizing and that the variance of x\u2208\u03bb1/d P\u03bb \u03be s (x; \u03bb1/d P\u03bb ) is\nbounded below by a positive multiple of \u03bb. We thus obtain rates of convergence\nof O((log \u03bb)3d \u03bb\u22121/2 ) in the CLT for the one-dimensional marginals of the empirical\ndistribution function of k nearest neighbors distances on \u03bb1/d P\u03bb , improving upon\nthose implicit on p. 88 of [9].\nUsing the results from section 6.2 of [11], we could likewise obtain the same rates\nof convergence in the CLT for the number of vertices of fixed degree in the k nearest\nneighbors graph.\nFinally in this section, we re-consider the non-translation-invariant example given\nin Section 2, where a point at x is colored red with probability q(x) and green with\nprobability 1 \u2212 q(x), and \u03be(x; X ) takes the value 0 if the nearest neighbor of x in\nX has the same color as x, and takes the value 1 otherwise. We can use Corollary\n2.1 to derive a central limit theorem, with O((log \u03bb)3d \u03bb\u22121/2 ) rate of convergence, for\nP\nx\u2208P\u03bb f (x)\u03be(x; P\u03bb ), where f is a bounded measurable test function.\n\n3.2\n\nVoronoi and sphere of influence graphs\n\nWe will consider the Voronoi graph for d = 2 and the sphere of influence graph for\nall d. Given a locally finite set X \u2282 R2 and given x \u2208 X , the locus of points closer\n8\n\n\fto x than to any other point in X is called the Voronoi cell centered at x. The graph\nconsisting of all boundaries of Voronoi cells is called the Voronoi graph generated\nby X .\nThe sum of the P\nlengths of the finite edges of the Voronoi graph on X admits\nthe representation\nx\u2208X \u03be(x; X ), where \u03be(x; X ) denotes one half the sum of the\nlengths of the finite edges in the Voronoi cell at x. If \u03ba is bounded away from 0\nand infinity and A is convex, then geometric arguments show that there is a random\nvariable R with exponentially decaying tails such that for any x \u2208 P\u03bb , the value\nof \u03be(x; P\u03bb ) is unaffected by points outside B\u03bb\u22121/d R (x) [4, 11, 13]. In other words, \u03be\nis exponentially stabilizing and satisfies the moments condition (2.5) for all p > 1.\nAlso, the variance of the total edge length of these graphs on \u03bb1/d P\u03bb is bounded\nbelow by a multiple of \u03bb. We thus obtain O((log \u03bb)3d \u03bb\u22121/2 ) rates of convergence in\nthe CLT for the total edge length functionals of these graphs on \u03bb1/d P\u03bb , thereby\nimproving and generalizing the results of Avram and Bertsimas [1].\nGiven a locally finite set X \u2282 Rd , the sphere of influence graph SIG(X ) is a\ngraph with vertex set X , constructed as follows: for each x \u2208 X let Bx be a ball\naround x with radius equal to miny\u2208X \\{x} {|y \u2212 x|}. Then Bx is called the sphere of\ninfluence of x. We put an edge between x and y iff the balls Bx and By overlap.\nThe collection of such edges is the sphere of influence graph (SIG) on X .\nThe total number\nof edges of the sphere of influence graph on X admits the\nP\nrepresentation x\u2208X \u03be(x; X ), where \u03be(x; X ) denotes one half the degree of SIG at the\nvertex x. The number of vertices of fixed degree \u03b4 admits a similar representation,\nwith \u03be(x; X ) now equal to one (respectively, zero) if the degree at x is \u03b4 (respectively,\nif degree at x is not \u03b4). If \u03ba is bounded away from 0 and infinity and A is convex,\nthen geometric arguments show that both choices of the functional \u03be stabilize (see\nsections 7.1 and 7.3 of [11]). Also, the variance of both the total number edges and\nthe number of vertices of fixed degree in the SIG on \u03bb1/d P\u03bb is bounded below by a\nmultiple of \u03bb (sections 7.1 and 7.3 of [11]). We thus obtain O((log \u03bb)3d \u03bb\u22121/2 ) rates\nof convergence in the CLT for the total number of edges and the number of vertices\nof fixed degree in the sphere of influence graph on P\u03bb .\n\n3.3\n\nRandom sequential packing models\n\nThe following prototypical random sequential packing model is of considerable scientific interest; see [12] for references to the vast literature.\nWith N(\u03bb) standing for a Poisson random variable with parameter \u03bb, we let\nB\u03bb,1 , B\u03bb,2 , ..., B\u03bb,N (\u03bb) be a sequence of d-dimensional balls of volume \u03bb\u22121 whose centers are i.i.d. random d-vectors X1 , ..., XN (\u03bb) with probability density function\n\u03ba : A \u2192 [0, \u221e). Without loss of generality, assume that the balls are sequenced\nin the order determined by marks (time coordinates) in [0, 1]. Let the first ball B\u03bb,1\nbe packed, and recursively for i = 2, 3, . . . , let the i-th ball B\u03bb,i be packed iff B\u03bb,i\ndoes not overlap any ball in B\u03bb,1 , ..., B\u03bb,i\u22121 which has already been packed. If not\n9\n\n\fpacked, the i-th ball is discarded.\nPacking models of this type arise in diverse disciplines, including physical, chemical, and biological processes [12]. Central limit theorems for the number of accepted\n(i.e., packed) balls are established in [12, 4], whereas laws of large numbers are given\nin [13].\nLet M = [0, 1] with PM being the uniform distribution on the unit interval. For\nany finite point set X \u2282 Rd \u00d7 [0, 1], assume the points (x, s) \u2208 X represent the\nlocations and arrival times. Assume balls of volume \u03bb\u22121 centered at the locations of\nX arrive sequentially in an order determined by the time coordinates, and assume as\nbefore that each ball is packed or discarded according to whether or not it overlaps\na previously packed ball. Let \u03be((x, s); X ) be either 1 or 0 depending on whether\nthe ball centered at x at times s is packed or discarded. Consider the re-scaled\npacking functional \u03be\u03bb ((x, s); X ) = \u03be((\u03bb1/d x, s); \u03bb1/d X ), where balls centered at points\nof \u03bb1/d X have volume one. The random measure\nN (\u03bb)\n\n\u03bc\u03be\u03bb\n\n:=\n\nX\n\nN (\u03bb)\n\n\u03be\u03bb ((Xi , Ui ); {(Xj , Uj )}j=1 ) \u03b4Xi ,\n\ni=1\n\nis called the random sequential packing measure induced by balls with centers arising\nfrom \u03ba. The convergence of the finite dimensional distributions of the packing\nmeasures \u03bc\u03be\u03bb is established in [3, 4]. \u03be is exponentially stabilizing [12, 3] and for\nany continuous f \u2208 B([0, 1]d ) and \u03ba uniform, the variance of hf, \u03bc\u03be\u03bbi is bounded\nbelow by a positive multiple of \u03bb [4], showing that hf, \u03bc\u03be\u03bb i satisfies a CLT with an\nO((log \u03bb)3d \u03bb\u22121/2 ) rate of convergence.\nIt follows easily from the stabilization analysis of [12] that many variants of\nthe above basic packing model satisfy similar rates of convergence in the CLT.\nExamples include balls of bounded random radius, cooperative sequential adsorption\n([12]), and monolayer ballistic deposition ([12]). In each case the number of particles\naccepted satisfies the CLT with an O((log \u03bb)3d \u03bb\u22121/2 ) rate of convergence. The same\ncomment applies for the number of seeds accepted in spatial birth-growth models\n[12].\n\n3.4\n\nIndependence number, off-line packing\n\nAn independent set of vertices in a graph G is a set of vertices in G, no two of which\nare connected by an edge. The independence number of G, which we denote \u03b2(G),\nis defined to be the maximum cardinality of all independent sets of vertices in G.\nFor r > 0, and for finite or countable X \u2282 Rd , let G(X , r) denote the geometric\ngraph with vertex set X and with edges between each pair of vertices distant at\nmost r apart. Then the independence number \u03b2(G(X , r)) is the maximum number\nof disjoint closed balls of radius r/2 that can be centered at points of X ; it is an\n'off-line' version of the packing functionals considered in the previous section.\n10\n\n\fLet b > 0 be a constant, and consider the graph G(P\u03bb , b\u03bb\u22121/d ) (or equivalently,\nG(\u03bb1/d P\u03bb , b)). Random geometric graphs of this type are the subject of [9], although\nindependence number is considered only briefly there (on page 135). A law of large\nnumbers for the independence number is described in Theorem 2.7 (iv) of [13].\nFor u > 0, let Hu denote a homogeneous Poisson point process of intensity u on\nd\nR , and let Hu0 be the point process Hu with a point inserted at the origin. As on\npage 189 of [9], let \u03bbc be the infimum of all u such that the origin has a non-zero\nprobability of being in an infinite component of G(Hu , 1).\nIf bd k\u03bak\u221e < \u03bbc , we can use Corollary 2.1 to obtain a central limit theorem for\nthe independence number \u03b2(G(P\u03bb , b\u03bb\u22121/d )), namely\n\u0015\n\u0014\n\u03b2(G(P\u03bb , b\u03bb\u22121/d )) \u2212 E \u03b2(G(P\u03bb , b\u03bb\u22121/d ))\n\u2264 t \u2212 \u03a6(t) \u2264 C(log \u03bb)3d \u03bb\u22121/2 .(3.2)\nsup P\n(Var\u03b2(G(P\u03bb , b\u03bb\u22121/d )))1/2\nt\u2208R\nWe sketch the proof. For finite X \u2282 Rd and x \u2208 X , let \u03be(x; X ) denote the\nindependence number of the component of G(X , P\nb) containing vertex x, divided by\nthe number of vertices in this component. Then x\u2208X \u03be(x; X ) is the independence\nnumber of G(X , b), since the independence number of any graph is the sum of\nthe independence numbers of its components. Also, our choice of \u03be is translationinvariant, and so we obtain\nX\n\u03be(\u03bb1/d x; \u03bb1/d P\u03bb )\n\u03b2(G(P\u03bb , \u03bb\u22121/d b)) = \u03b2(G(\u03bb1/d P\u03bb , b)) =\nx\u2208P\u03bb\n\n=\n\nX\n\n\u03be\u03bb (x; P\u03bb ) = h\u03bc\u03be\u03bb, f i,\n\nx\u2208P\u03bb\n\nwhere we here take the test function f to be identically 1 and take A\u03bb = A for all \u03bb.\nThus a central limit theorem holds for \u03b2(G(P\u03bb , \u03bb\u22121/d b)) by application of Corollary\n2.1, if \u03be and \u03ba satisfy the conditions for that result.\nWe take R(x, \u03bb) to be the distance from \u03bb1/d x to the furthest point in the component containing \u03bb1/d x of G(\u03bb1/d P\u03bb , b), plus 2b. Since \u03be\u03bb (x; P\u03bb ) is determined by the\ncomponent of G(\u03bb1/d P\u03bb , b) containing \u03bb1/d x, and this component is unaffected by\nthe addition or removal of points to/from P\u03bb at a distance greater than \u03bb\u22121/d R(x, \u03bb)\nfrom x, it is indeed the case that R(x, \u03bb) is a radius of stabilization.\nThe point process \u03bb1/d P\u03bb is dominated by Hk\u03bak\u221e (in the sense of [9], page 189).\nHence, P [R(x, \u03bb) > t] is bounded by the probability that the component containing x of G(Hk\u03bak\u221e \u222a {\u03bb1/d x}, b) has at least one vertex outside Bt\u22122b (\u03bb1/d x). This\nprobability does not depend on x, and equals the probability that the component of\nG(Hb0d k\u03bak\u221e , 1) containing the origin includes a vertex outside B(t/b)\u22122 . By exponential decay for subcritical continuum percolation (Lemma 10.2 of [9]), this probability\ndecays exponentially in t, and exponential stabilization of \u03be follows. The moments\ncondition (2.5) is trivial in this case, for any p, since 0 \u2264 \u03be(x; X ) \u2264 1.\n11\n\n\fThus, Corollary 2.1 is indeed applicable, provided that (2.7) holds in this case,\nwith \u03c3 2 > 0. Essentially (2.7) follows from Theorem 2.1 of [4], with strict inequality\n\u03c3 2 > 0 following from (2.10) of [4]; in the case where \u03ba is the density function\nof a uniform distribution on some suitable subset of Rd , one can alternatively use\nTheorem 2.4 of [11]. We do not go into details here about the application of results\nin this example, but we do comment further on why the distribution of the 'add one\ncost' (see [11, 4]) of insertion of a point at the origin into a homogeneous Poisson\nprocess is nondegenerate, since this is needed to verify \u03c3 2 > 0 and this example was\nnot considered in [11] or [4].\nThe above add one cost is the variable denoted \u2206(\u221e) in the notation of [11],\nor \u2206\u03be (u) in the notation of [4]. It is the independence number of the component\ncontaining the origin of G(Hu ; b) minus the independence number of this component\nwith the origin removed (we need only to consider the case where bd u is subcritical).\nThis variable can take the value 1, for example if the origin is isolated in G(Hu ; b),\nor zero, for example if the component containing the origin has two vertices. Both\nof these possibilities have strictly positive probability, and therefore \u2206(\u221e) has a\nnon-degenerate distribution.\n\n4\n4.1\n\nProof of Theorems\nA CLT for dependency graphs\n\nWe shall prove Theorem 2.1 by showing that exponential stabilization implies that\na modification of hf, \u03bc\u03be\u03bb i has a dependency graph structure, whose definition we now\nrecall (see e.g. Chapter 2 of [9]). Let X\u03b1 , \u03b1 \u2208 V, be a collection of random variables.\nThe graph G := (V, E) is a dependency graph for X\u03b1 , \u03b1 \u2208 V, if for any pair of disjoint\nsets A1 , A2 \u2282 V such that no edge in E has one endpoint in A1 and the other in A2 ,\nthe sigma-fields \u03c3{X\u03b1 , \u03b1 \u2208 A1 }, and \u03c3{X\u03b1 , \u03b1 \u2208 A2 }, are mutually independent. Let\nD denote the maximal degree of the dependency graph.\nIt is well known that sums of random variables indexed by the vertices of a\ndependency graph admit rates of convergence to a normal. The rates of Baldi and\nRinott [2] and those in Penrose [9] are particularly useful; Avram and Bertsimas\n[1] use the former to obtain rate results for the total edge length of the nearest\nneighbor, Voronoi, and Delaunay graphs.\nIn many cases, the following theorem of Chen and Shao [7] provides superior rate\nresults. For any random variable X and any p > 0, let ||X||p = (E [|X|p ])1/p .\nLemma 4.1 (see Thm 2.7 of [7]) Let 2 < q \u2264 3. Let Wi , i P\n\u2208 V, be random\nvariables indexed by the vertices of a dependency graph. Let W = i\u2208V Wi . Assume\nthat E [W 2 ] = 1, E [Wi ] = 0, and ||Wi ||q \u2264 \u03b8 for all i \u2208 V and for some \u03b8 > 0. Then\nsup |P [W \u2264 t] \u2212 \u03a6(t)| \u2264 75D 5(q\u22121) |V|\u03b8q .\nt\n\n12\n\n(4.1)\n\n\f4.2\n\nAuxiliary lemmas\n\nTo prepare for the proof of Theorem 2.1 we will need some auxiliary lemmas.\nThroughout, C denotes a generic constant depending possibly on d, \u03be, and \u03ba and\nwhose value may vary at each occurrence. We assume \u03bb > 1 throughout.\nLet (\u03c1\u03bb , \u03bb > 0) be a function to be chosen later, in such a way that \u03c1\u03bb \u2192 \u221e and\n\u22121/d\n\u22121/d\n\u03bb\n\u03c1\u03bb \u2192 0 as \u03bb \u2192 \u221e. Given \u03bb > 0, let\n\u03c1\u03bb , and let V := V (\u03bb) denote\nQds\u03bb := \u03bb\n[j\ns\n,\n(j\n+\n1)s\u03bb ), with all ji \u2208 Z, such\nthe number\nof\ncubes\nof\nthe\nform\nQ\n=\ni\ni=1 i \u03bb\nR\nthat Q \u03ba(x)dx > 0; enumerate these cubes as Q1 , Q2 , . . . , QV (\u03bb) . Since \u03ba is assumed\nto have bounded support, it is easy to see that V (\u03bb) = O(\u03bb\u03c1\u2212d\n\u03bb ) as \u03bb \u2192 \u221e.\nFor all 1 \u2264 i \u2264 V (\u03bb), the number of points of P\u03bb \u2229 (Qi \u00d7 M) is a Poisson random\nvariable Ni := N(\u03bdi ), where\nZ\n\u03bdi := \u03bb\n\u03ba(x)dx \u2264 k\u03bak\u221e \u03c1d\u03bb .\n(4.2)\nQi\n\nAssuming \u03bdi > 0, choose an ordering on the points of P\u03bb \u2229 (Qi \u00d7 M) uniformly at\nrandom from all (Ni )! possible such orderings. Use this ordering to list the points\nas (Xi,1 , Ui,1 ), ..., (Xi,Ni , Ui,Ni ), where conditional on the value of Ni , the\nR random\nvariables Xi,j , j = 1, 2, ... are i.i.d. on Qi with a density \u03bai (*) := \u03ba(*)/ Qi \u03ba(x)dx,\nand the Ui,j are i.i.d. in M with distribution PM , independent of {Xi,j }. Thus\nV (\u03bb)\ni\nwe have the representation P\u03bb = \u222ai=1 {(Xi,j , Ui,j )}N\nj=1 . For all 1 \u2264 i \u2264 V (\u03bb), let\nd\ni\nPi := P\u03bb \\ {(Xi,j , Ui,j )}N\nj=1 and note that Pi is a Poisson point process on R \u00d7 M\nwith intensity \u03bb\u03ba(x)1Rd \\Qi (x)dx \u00d7 PM (ds).\nWe show that the condition (2.5), which bounds the moments of the value of \u03be\nat points inserted into P\u03bb ,\nalso yields bounds on E [|\u03be\u03bb ((Xi,j , Ui,j ); P\u03bb )|p 1A\u03bb (Xi,j )1j\u2264Ni ]. More precisely, we\nhave:\nLemma 4.2 If (2.5) holds for some p > 0, then there is a constant C := C(p) such\nthat for all \u03bb > 1, all j \u2265 1 and 1 \u2264 i \u2264 V (\u03bb),\nE [|\u03be\u03bb (Xi,j ; P\u03bb ) * 1A\u03bb (Xi,j )1j\u2264Ni |p ] \u2264 C\u03c1d\u03bb .\n\n(4.3)\n\nProof. If Ni = n, then denote {(Xi,1 , Ui,1 ), ..., (Xi,Ni , Ui,Ni )} by Xn . By definition,\n\u221e Z\nX\np\nE [|\u03be\u03bb ((Xi,j , Ui,j ); P\u03bb )*1A\u03bb (Xi,j )1j\u2264Ni | ] =\nE [|\u03be\u03bb ((x, U); Xn\u22121 \u222aPi )|p ]\u03bai (x)dx*P [Ni = n],\nn=j\n\nQi \u2229A\u03bb\n\nwhere the expectation on the right hand side is with respect to U, Xn\u22121 and Pi .\nThe above is bounded by\n\u2264 \u03bdi\n\n\u221e Z\nX\nn=1\n\nE [|\u03be\u03bb ((x, U); Xn\u22121 \u222a Pi )|p ]\u03bai (x)dx *\n\nQi \u2229A\u03bb\n\n13\n\ne\u2212\u03bdi \u03bdin\u22121\n(n \u2212 1)!\n\n\f= \u03bdi\n\n\u221e Z\nX\n\nm=0\n\nE [|\u03be\u03bb ((x, U); P\u03bb )|p | |P\u03bb \u2229 (Qi \u00d7 M)| = m] \u03bai (x)dx*P [|P\u03bb \u2229(Qi \u00d7M)| = m]\n\nQi \u2229A\u03bb\n\n= \u03bdi\n\nZ\n\nE [|\u03be\u03bb((x, U); P\u03bb )|p ]\u03bai (x)dx \u2264 const. \u00d7 \u03bdi ,\n\nQi \u2229A\u03bb\n\nwhere the last inequality follows by (2.5). By (4.2), this shows (4.3).\nFor 1 \u2264 i \u2264 V , and for j \u2208 {1, 2, . . .}, we define\n\u001a\n\u03be\u03bb ((Xi,j , Ui,j ); P\u03bb ) if Ni \u2265 j, Xi,j \u2208 A\u03bb\n\u03bei,j :=\n0\notherwise\nLemma 4.3 If (2.5) holds for some p > q > 1, then there exists C := C(p, q) such\nthat for 1 \u2264 i \u2264 V (\u03bb),\n\u221e\nX\n\nd(p+1)/p\n\n\u2264 C\u03c1\u03bb\n\n|\u03bei,j |\n\nj=1\n\n.\n\n(4.4)\n\nq\n\nProof. Fix i \u2264 V (\u03bb) and write \u03bej for \u03bei,j . Clearly, with N := Ni and \u03bd := \u03bdi ,\n!\n\u221e\n\u221e\n\u221e\nX\nX\nX\n|\u03bej | =\n|\u03bej | 1N \u2264\u03bd +\n12k \u03bd<N \u22642k+1 \u03bd\nj=1\n\nj=1\n\nq\n\n\u221e\n\u221e X\nX\n\n\u2264\n\nk=0\n\n|\u03bej | * 12k \u03bd<N \u22642k+1 \u03bd\n\n\u221e\nX\n\n+\n\nj=1 k=0\n\nq\n\n|\u03bej | * 1N \u2264\u03bd\n\n.\n\nj=1\n\nq\n\nq\n\nSince a.s. only finitely many summands in the double sum are non-zero, by subadditivity of the norm, the above is bounded by\n\u2264\n\n\u221e\n\u221e\nX\nX\nk=0\n\n\u2264\n\n|\u03bej | * 12k \u03bd<N \u22642k+1 \u03bd\n\n+\n\nj=1\n\n\u221e\nX\nk=0\n\n|\u03bej | * 1N \u22652k \u03bd\n\nj=1\n\n+\nq\n\n\u230a2k+1 \u03bd\u230b\n\n\u2264\n\n\u221e\nX\nX\nk=0\n\n||\u03bej * 1N \u22652k \u03bd ||q +\n\nj=1\n\n|\u03bej | * 1N \u2264\u03bd\n\nj=1\n\nq\n\n\u230a2k+1 \u03bd\u230b\n\nX\n\n\u230a\u03bd\u230b\nX\n\u230a\u03bd\u230b\nX\n\n|\u03bej | * 1N \u2264\u03bd\n\nj=1\n\n\u230a\u03bd\u230b\nX\n\nq\n\n||\u03bej * 1N \u2264\u03bd ||q ,\n\nq\n\n(4.5)\n\nj=1\n\nwhere here and elsewhere \u230ax\u230b denotes the greatest integer less than or equal to x.\n14\n\n\fWith \u03b7 := (1/q) \u2212 (1/p), H\u00f6lder's inequality followed by (4.3) yields\nd/p\n\n||\u03bej * 1N \u22652k \u03bd ||q \u2264 ||\u03bej ||p * (P [N \u2265 2k \u03bd])\u03b7 \u2264 C\u03c1\u03bb (P [N \u2265 2k \u03bd])\u03b7 .\n\n(4.6)\n\nSubstituting into (4.5) we obtain\n\u221e\nX\nj=1\n\n\u2264\n\n|\u03bej |\nq\n\nd/p\nC\u03c1\u03bb\n\n\u221e\nX\n\n\u03bd2\n\nk+1\n\nk\n\n\u03b7\n\n* (P [N \u2265 2 \u03bd]) +\n\n\u230a\u03bd\u230b\nX\n\n||\u03bej * 1N \u2264\u03bd ||p .\n\n(4.7)\n\nj=1\n\nk=0\n\nBy tail estimates for the Poisson distribution (see e.g. (1.12) in [9]), since e2 < 8 we\nhave\n\u0001\u0001\u03b7\n(P [N \u2265 2k \u03bd])\u03b7 \u2264 exp \u22122k\u22121 \u03bd log(2k )\n= exp(\u2212k2k\u22121 \u03b7\u03bd log 2), k \u2265 3.\nHence,\n\n(P [N \u2265 2k \u03bd])\u03b7 \u2264 2\u22122k ,\n\nk \u2265 max(3, 2 \u2212 log2 (\u03b7\u03bd)).\n\nHence, since \u03b7 is a constant, for \u03bd > 0 we have\n\u221e\nX\n\n2k+1 * (P [N \u2265 2k \u03bd])\u03b7 \u2264\n\nk=0\n\nX\n\n2k+1 +\n\nk<max(3,2\u2212log2 (\u03b7\u03bd))\n\nX\n\n21\u2212k\n\nk\u2265max(3,2\u2212log2 (\u03b7\u03bd))\n\n\u2264 C max(1/\u03bd, 1) + 2\nwhere C does not depend on \u03bd. Thus by (4.2), the first term in the right hand\nd+d/p\nside of (4.7) is O(\u03c1\u03bb\n). Also, the second term in the right hand side of (4.7) is\nd+d/p\nO(\u03c1\u03bb\n) by Lemma 4.2. Hence, (4.7) implies (4.4).\n\n4.3\n\nProof of Theorems 2.1 and 2.2\n\nWe prove Theorems 2.1 and 2.2 together. When proving Theorem 2.1 we assume\nthat \u03be is exponentially stabilizing and (2.5) holds for some p > 2, and we choose\nq \u2208 (2, 3] with q < p. When proving Theorem 2.2 we assume that \u03be is polynomially\nstabilizing of order \u03b3 with \u03b3 > d(150 + 6/p), and that (2.5) holds for some p > 3,\nand we set q = 3.\nThroughout this section, we fix f \u2208 B(A) and set T\u03bb := hf, \u03bc\u03be\u03bb i. We follow\nthe setup of the preceding section, with the support of \u03ba covered by cubes of side\n\u03bb\u22121/d \u03c1\u03bb , and we now choose \u03c1\u03bb . With the tail probability \u03c4 (t) defined at (2.2), we\nchoose \u03c1\u03bb in such a way that there is a constant C such that for all \u03bb \u2265 1,\nd/p\n\n\u03c1\u03bb (\u03bb\u03c4 (\u03c1\u03bb ))(q\u22122)/(2q) < C\u03bb\u22124\n\nand \u03c4 (\u03c1\u03bb ) < C\u03bb\u22123\n\n(4.8)\n\nand also\n\u03c1d\u03bb < C\u03bbp/(p+2) .\n15\n\n(4.9)\n\n\fIn the exponentially stabilizing case (Theorem 2.1) we achieve this by taking \u03c1\u03bb =\n\u03b1 log \u03bb for some suitably large constant \u03b1. In the polynomially stabilizing case of\norder \u03b3 (Theorem 2.2), we take \u03c1\u03bb = C\u03bba with\n\u0013\n\u0012\n25\n\u03b3 d\n25p\n= .\nso a\n\u2212\n(4.10)\na=\np\u03b3 \u2212 6d\n6 p\n6\nwhich implies that (4.8) holds with q = 3, and that (4.9) holds (to obtain the last\nconclusion we use our assumption on \u03b3, which implies \u03b3 > d(25 + 56/p).)\nFor all 1 \u2264 i \u2264 V and all j = 1, 2, ..., let Ri,j denote the radius of stabilization\nof \u03be at (Xi,j , Ui,j ) if 1 \u2264 j \u2264 Ni and Xi,j \u2208 A\u03bb ; let Ri,j be zero otherwise.\nLet Ei,j := {Ri,j \u2264 \u03c1\u03bb }. Let E\u03bb := \u2229Vi=1 \u2229\u221e\nj=1 Ei,j Then by Markov's inequality\nand standard Palm theory (e.g. Theorem 1.6 in [9])\n\nP [E\u03bbc ]\n\n\u2264E\n\n\"\n\nNi\nV X\nX\n\n#\n\nc\n1Ei,j\n=\u03bb\n\ni=1 j=1\n\nZ\n\nP [R(x, \u03bb) > \u03c1\u03bb ]\u03ba(x)dx \u2264 \u03bb\u03c4 (\u03c1\u03bb ).\n\n(4.11)\n\nA\u03bb\n\nFor each \u03bb, and x \u2208 Rd , set f\u03bb (x) := f (x)1A\u03bb (x). Recalling the representation\nV (\u03bb)\ni\nP\u03bb = \u222ai=1 {Xi,j }N\nj=1 , we have\nT\u03bb =\n\nV (\u03bb) Ni\nXX\n\n\u03be\u03bb ((Xi,j , Ui,j ); P\u03bb ) * f\u03bb (Xi,j ).\n\ni=1 j=1\n\nTo obtain rates of normal approximation for T\u03bb , it will be be convenient to consider\na closely related sum enjoying more independence between terms, namely\nT\u03bb\u2032\n\n:=\n\nV (\u03bb) Ni\nXX\n\n\u03be\u03bb ((Xi,j , Ui,j ); P\u03bb ) * 1Ei,j * f\u03bb (Xi,j ).\n\ni=1 j=1\n\nFor all 1 \u2264 i \u2264 V (\u03bb) define\nSi := SQi :=\n\n(VarT\u03bb\u2032 )\u22121/2\n\nNi\nX\n\n\u03be\u03bb ((Xi,j , Ui,j ); P\u03bb ) * 1Ei,j * f\u03bb (Xi,j )\n\nj=1\n\nPV (\u03bb)\nand put S := (VarT\u03bb\u2032 )\u22121/2 (T\u03bb\u2032 \u2212 E T\u03bb\u2032 ) = i=1\n(Si \u2212 E Si ). Clearly VarS = E S 2 = 1.\nWe define a graph G\u03bb := (V\u03bb , E\u03bb ) as follows. The set V\u03bb consists of the subcubes Q1 , ..., QV (\u03bb) and edges (Qi , Qj ) belong to E\u03bb if d(Qi , Qj ) \u2264 2\u03b1\u03bb\u22121/d \u03c1\u03bb , where\nd(Qi , Qj ) := inf{|x \u2212 y| : x \u2208 Qi , y \u2208 Qj } . By definition of the radius of stabilization R(x, \u03bb), the value of Si is determined by the restriction of P\u03bb to the\n\u03bb\u22121/d \u03c1\u03bb -neighborhood of the cube Qi . By the independence property of the Poisson\npoint process, if A1 and A2 are disjoint collections of cubes in V\u03bb such that no edge\n16\n\n\fin E\u03bb has one endpoint in A1 and one endpoint in A2 , then the random variables\n{SQi , Qi \u2208 A1 } and {SQj , Qj \u2208 A2 } are independent. Thus G\u03bb is a dependency\nV (\u03bb)\ngraph for {Si }i=1 .\nTo prepare for an application of Lemma 4.1, we make five observations:\n(i) V (\u03bb) := |V\u03bb | = O(\u03bb\u03c1\u2212d\n\u03bb ) as \u03bb \u2192 \u221e.\n(ii) Since the number of cubes in Q1 , ..., QV distant at most 2\u03bb\u22121/d \u03c1\u03bb from a given\ncube is bounded by 5d , it follows that the maximal degree D satisfies D := D\u03bb \u2264 5d .\n(iii) The definitions of Si and \u03bei,j and Lemma 4.3 tell us that for all 1 \u2264 i \u2264 V (\u03bb)\nkSi kq \u2264\n\nC(VarT\u03bb\u2032 )\u22121/2\n\n\u221e\nX\n\nd(p+1)/p\n\n\u2264 C(VarT\u03bb\u2032 )\u22121/2 \u03c1\u03bb\n\n|\u03bei,j |\n\nj=1\n\n.\n\n(4.12)\n\nq\n\n(iv) We can bound Var[T\u03bb\u2032 ] as follows. Observe that T\u03bb\u2032 is the sum of V (\u03bb)\nrandom variables, which by the case q = 2 of Lemma 4.3 each have a second moment\n2d(p+1)/p\nbounded by a constant multiple of \u03c1\u03bb\n. Thus the variance of each of the V (\u03bb)\n2d(p+1)/p\nrandom variables is also bounded by a constant multiple of \u03c1\u03bb\n. Moreover,\nthe covariance of any pair of the V (\u03bb) random variables is zero when the indices of\nthe random variables correspond to non-adjacent cubes. For adjacent cubes, by the\nCauchy-Schwarz inequality the covariance is also bounded by a constant multiple of\n2d(p+1)/p\n\u03c1\u03bb\n. This shows that\nd(p+2)/p\n\nVar[T\u03bb\u2032 ] = O(\u03c1\u03bb\n\n\u03bb).\n\n(4.13)\n\n(v) Var[T\u03bb\u2032 ] is close to Var[T\u03bb ] for \u03bb large. We require more estimates to show\nthis. Note that |T\u03bb\u2032 \u2212 T\u03bb | = 0 except possibly on the set E\u03bbc . Lemma 4.3, along with\nMinkowski's inequality, yields the upper bound\nV (\u03bb) Ni\nXX\n\nd(p+1)/p\n\n\u2264 CV (\u03bb)\u03c1\u03bb\n\n|\u03be\u03bb((Xi,j , Ui,j ); P\u03bb )|1A\u03bb (Xi,j )\n\ni=1 j=1\n\nd/p\n\n\u2264 C\u03bb\u03c1\u03bb .\n\n(4.14)\n\nq\n\nSince T\u03bb = T\u03bb\u2032 on event E\u03bb , the H\u00f6lder and Minkowski inequalities yield\nkT\u03bb \u2212 T\u03bb\u2032 k2 \u2264 kT\u03bb \u2212 T\u03bb\u2032 kq P [E\u03bbc ](1/2)\u2212(1/q)\n\u2264 (kT\u03bb kq + kT\u03bb\u2032 kq )P [E\u03bbc ](q\u22122)/(2q) .\nHence, by (4.8), (4.11), and (4.14),\nd/p\n\nkT\u03bb \u2212 T\u03bb\u2032 k2 \u2264 C\u03bb\u03c1\u03bb (\u03bb\u03c4 (\u03c1\u03bb ))(q\u22122)/(2q) \u2264 C\u03bb\u22123\n\n(4.15)\n\nwhich implies that\nE [|T\u03bb\u2032 \u2212 T\u03bb |] \u2264 C\u03bb\u22123 ,\n17\n\n(4.16)\n\n\fwhich we use later. Since\nVar[T\u03bb ] = Var[T\u03bb\u2032 ] + Var(T\u03bb \u2212 T\u03bb\u2032 ) + 2Cov(T\u03bb\u2032 , T\u03bb \u2212 T\u03bb\u2032 ),\nby (4.15), (4.13), (4.9) and the Cauchy-Schwarz inequality, we obtain\n|Var[T\u03bb ] \u2212 Var[T\u03bb\u2032 ]| \u2264 C\u03bb\u22122 .\n\n(4.17)\n\nGiven the five observations (i)-(v), we are now ready to apply Lemma 4.1 to\nprove Theorem 2.1. By (4.13) and (4.17), Var[T\u03bb ], as a function of \u03bb, is bounded\non bounded intervals. Hence, it suffices to prove that there exists \u03bb0 \u2265 2 such that\n(2.6) holds for all \u03bb \u2265 \u03bb0 , since we can then extend (2.6) to all \u03bb \u2265 2 by changing\nC if necessary. Trivially, (2.6) holds for large enough \u03bb when Var[T\u03bb ] < 1, and so\nwithout loss of generality we now assume Var[T\u03bb ] \u2265 1. To establish the error bound\n(2.6) in this case, we apply the bound (4.1) to Wi := Si \u2212 E Si , 1 \u2264 i \u2264 V\u03bb , with\nd(p+1)/p\n\n\u03b8 := C(VarT\u03bb\u2032 )\u22121/2 \u03c1\u03bb\n\n.\n\nPV (\u03bb)\nOur choice of \u03b8 is applicable by (4.12). We clearly have E [Wi ] = 0 and E [( i=1\nWi )2 ] =\nPV (\u03bb)\n1. With S = i=1 Wi , Lemma 4.1 along with observation (i) above yields\ndq(p+1)/p\n\n\u2032 \u2212q/2\nsup |P [S \u2264 t] \u2212 \u03a6(t)| \u2264 C\u03bb\u03c1\u2212d\n\u03c1\u03bb\n\u03bb (VarT\u03bb )\nt\n\n\u2264 C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb ,\n\n(4.18)\n\nwhere the last line makes use of the fact that Var[T\u03bb\u2032 ] \u2265 Var[T\u03bb ]/2, which follows\n(for \u03bb large) from (4.17).\nNow if \u03b2 > 0 is a constant and Z any random variable then by (4.18) we have\nfor all t \u2208 R\nP [Z \u2264 t] \u2264 P [S \u2264 t + \u03b2] + P [|Z \u2212 S| \u2265 \u03b2]\n\u2264 \u03a6(t + \u03b2) + C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb + P [|Z \u2212 S| \u2265 \u03b2]\n\u2264 \u03a6(t) + C\u03b2 + C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb + P [|Z \u2212 S| \u2265 \u03b2]\nby the Lipschitz property of \u03a6. Similarly for all t \u2208 R,\nP [Z \u2264 t] \u2265 \u03a6(t) \u2212 C\u03b2 \u2212 C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb \u2212 P [|Z \u2212 S| \u2265 \u03b2].\nIn other words\nsup |P [Z \u2264 t] \u2212 \u03a6(t)| \u2264 C\u03b2 + C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb + P [|Z \u2212 S| \u2265 \u03b2].\n\n(4.19)\n\nt\n\nNow by definition of S,\n|(VarT\u03bb\u2032 )\u22121/2 (T\u03bb \u2212 E T\u03bb ) \u2212 S| = |(VarT\u03bb\u2032 )\u22121/2 {(T\u03bb \u2212 E T\u03bb ) \u2212 (T\u03bb\u2032 \u2212 E T\u03bb\u2032 )}|\n18\n\n\f\u2264 (VarT\u03bb\u2032 )\u22121/2 {|T\u03bb \u2212 T\u03bb\u2032 | + E [|T\u03bb \u2212 T\u03bb\u2032 |]}\nwhich by (4.16) is bounded by C\u03bb\u22123 except possibly on the set E\u03bbc which has probability less than C\u03bb\u22122 by (4.11) and (4.8). Thus by (4.19) with Z = (VarT\u03bb\u2032 )\u22121/2 (T\u03bb \u2212\nE T\u03bb ) and \u03b2 = C\u03bb\u22123\n\u22122\nsup |P [(VarT\u03bb\u2032 )\u22121/2 (T\u03bb \u2212 E T\u03bb ) \u2264 t] \u2212 \u03a6(t)| \u2264 C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb + C\u03bb . (4.20)\nt\n\nMoreover, by the triangle inequality\nsup P [(VarT\u03bb )\u22121/2 (T\u03bb \u2212 E T\u03bb ) \u2264 t] \u2212 \u03a6(t) \u2264\nt\n\u0015\n\u0012\n\u0013\n\u0014\nVarT\u03bb 1/2\nVarT\u03bb 1/2\n\u2032 \u22121/2\n\u2212 \u03a6 t(\n+\n)\n)\n(T\u03bb \u2212 E T\u03bb ) \u2264 t * (\n\u2264 sup P (VarT\u03bb )\nVarT\u03bb\u2032\nVarT\u03bb\u2032\nt\n\u0013\n\u0012\nVarT\u03bb 1/2\n\u2212 \u03a6(t) . (4.21)\n)\n+ sup \u03a6 t(\nVarT\u03bb\u2032\nt\n\nSince for all s \u2264 t, we have |\u03a6(s) \u2212 \u03a6(t)| \u2264 (t \u2212 s) maxs\u2264u\u2264t \u03c6(u) where \u03c6 denotes\nthe standard normal density, and since by (4.17) there is a constant 0 < C < \u221e\nsuch that for all \u03bb > 0 and all t \u2208 R\nVarT\u03bb 1/2\nC|t|\nVarT\u03bb\nt(\n) \u2212 t \u2264 |t|\n\u22121 \u2264 2\n\u2032\n\u2032\nVarT\u03bb\nVarT\u03bb\n\u03bb\nwe get\n\u0012\n\nVarT\u03bb 1/2\n)\nsup \u03a6 t(\nVarT\u03bb\u2032\nt\n\n\u0013\n\n\u2212 \u03a6(t) \u2264 C sup\nt\n\n\u0012\u0012\n\n|t|\n\u03bb2\n\n\u0013\u0012\n\nmax\n2\n\nu\u2208[t\u2212tC/\u03bb , t+tC/\u03bb2 ]\n\n\u03c6(u)\n\n\u0013\u0013\n\n\u2264\n\nC\n.\n\u03bb2\n\nThus by (4.20) and (4.21),\n\u22122\nsup |P [(VarT\u03bb )\u22121/2 (T\u03bb \u2212 E T\u03bb ) \u2264 t] \u2212 \u03a6(t)| \u2264 C\u03bb(VarT\u03bb )\u2212q/2 \u03c1dq\n\u03bb + C\u03bb . (4.22)\nt\n\nd(p+2)/p\n\nFinally we can deduce from (4.13) and (4.17) that VarT\u03bb = O(\u03bb\u03c1\u03bb\n). Hence,\nunder the assumptions of Theorem 2.1, in (4.22) the first term in the right hand\nside dominates, thus yielding the desired bound (2.6), and the proof of Theorem 2.1\nis complete.\nUnder the assumptions of Theorem 2.2, provided \u03c3 2 (f, \u03be, \u03ba) > 0 the right hand\na\nside of (4.22) is bounded by C\u03bb\u22121/2 \u03c1dq\n\u03bb , and since in this case we set \u03c1\u03bb = \u03bb\nwith a given by (4.10), some elementary algebra yields (2.9). Our assumption that\n\u03b3 > d(150 + 6/p) then yields the central limit theorem behavior (2.8), which is also\ntrivially true in the case where \u03c3 2 (f, \u03be, \u03ba) = 0. This completes the proof of Theorem\n2.2.\nAcknowledgments. We began this work while visiting the Institute for Mathematical Sciences at the National University of Singapore, and continued it while\nvisiting the Isaac Newton Institute for Mathematical Sciences at Cambridge. We\nthank both institutions for their hospitality.\n19\n\n\fReferences\n[1] F. Avram and D. Bertsimas (1993), On central limit theorems in geometrical\nprobability. Ann. Appl. Probab. 3, 1033-1046.\n[2] P. Baldi and Y. Rinott (1989), Asymptotic normality of some graph related\nstatistics. J. Appl. Probab. 26, 171-175.\n[3] Yu. Baryshnikov and J.E. Yukich (2003), Gaussian fields and random packing.\nJ. Statist. Phys. 111, 443-463.\n[4] Yu. Baryshnikov and J.E. Yukich (2004), Gaussian limits for random measures\nin geometric probability. Ann. Appl. Probab., to appear.\n[5] Yu. Baryshnikov, P. Eichelsbacher, T. Scheiber, and J. E. Yukich (2004), Moderate deviations and cluster measures in geometric probability, preprint.\n[6] P. J. Bickel and L. Breiman (1983), Sums of functions of nearest neighbor distances, moment bounds, limit theorems and a goodness of fit test. Ann. Probab.\n11, 185-214.\n[7] L. Chen and Q.-M. Shao (2003), Normal approximation under local dependence,\npreprint, Ann. Probab., to appear July 2004.\n[8] N. Henze (1988), A multivariate two-sample test based on the number of nearestneighbor type coincidences. Ann. Statist. 16, 772-783.\n[9] M.D. Penrose (2003), Random Geometric Graphs, Oxford University Press.\n[10] M.D. Penrose (2004). Multivariate spatial central limit theorems with applications to percolation and spatial graphs. Preprint, University of Bath. Electronically available via http://www.bath.ac.uk/math-sci/\n[11] M.D. Penrose and J.E. Yukich (2001), Central limit theorems for some graphs\nin computational geometry. Ann. Appl. Probab. 11, 1005-1041.\n[12] M.D. Penrose and J.E. Yukich (2002), Limit theory for random sequential packing and deposition. Ann. Appl. Probab. 12, 272-301.\n[13] M.D. Penrose and J.E. Yukich (2003), Weak laws of large numbers in geometric\nprobability. Ann. Appl. Probab., 13, 277-303.\n[14] C. Stein (1972), Approximate Computation of Expectations. IMS, Hayward,\nCA.\n\n20\n\n\f"}