{"id": "http://arxiv.org/abs/0910.1266v1", "guidislink": true, "updated": "2009-10-07T13:49:26Z", "updated_parsed": [2009, 10, 7, 13, 49, 26, 2, 280, 0], "published": "2009-10-07T13:49:26Z", "published_parsed": [2009, 10, 7, 13, 49, 26, 2, 280, 0], "title": "Toward an automaton Constraint for Local Search", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0910.5205%2C0910.0426%2C0910.5596%2C0910.4988%2C0910.1354%2C0910.4925%2C0910.4981%2C0910.5500%2C0910.3928%2C0910.1482%2C0910.0823%2C0910.5159%2C0910.0188%2C0910.3529%2C0910.0137%2C0910.4127%2C0910.4293%2C0910.5462%2C0910.1678%2C0910.2254%2C0910.4402%2C0910.3286%2C0910.1266%2C0910.3018%2C0910.5029%2C0910.2419%2C0910.2148%2C0910.1065%2C0910.2445%2C0910.1291%2C0910.3656%2C0910.0464%2C0910.5107%2C0910.1357%2C0910.3234%2C0910.1394%2C0910.0538%2C0910.0493%2C0910.3365%2C0910.5343%2C0910.2266%2C0910.3370%2C0910.2564%2C0910.5860%2C0910.4834%2C0910.4346%2C0910.0066%2C0910.0080%2C0910.4723%2C0910.2881%2C0910.1168%2C0910.4974%2C0910.3077%2C0910.1028%2C0910.3213%2C0910.1500%2C0910.1609%2C0910.0055%2C0910.3435%2C0910.0370%2C0910.4198%2C0910.0565%2C0910.3377%2C0910.5884%2C0910.5899%2C0910.4671%2C0910.1449%2C0910.3696%2C0910.2273%2C0910.2248%2C0910.5301%2C0910.4114%2C0910.1064%2C0910.2403%2C0910.3135%2C0910.4774%2C0910.5947%2C0910.5127%2C0910.0698%2C0910.3675%2C0910.2931%2C0910.0818%2C0910.3331%2C0910.5271%2C0910.1973%2C0910.4053%2C0910.4689%2C0910.1720%2C0910.0284%2C0910.5577%2C0910.1022%2C0910.4049%2C0910.4521%2C0910.0617%2C0910.2597%2C0910.0475%2C0910.2432%2C0910.4428%2C0910.2912%2C0910.0282%2C0910.0830&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Toward an automaton Constraint for Local Search"}, "summary": "We explore the idea of using finite automata to implement new constraints for\nlocal search (this is already a successful technique in constraint-based global\nsearch). We show how it is possible to maintain incrementally the violations of\na constraint and its decision variables from an automaton that describes a\nground checker for that constraint. We establish the practicality of our\napproach idea on real-life personnel rostering problems, and show that it is\ncompetitive with the approach of [Pralong, 2007].", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0910.5205%2C0910.0426%2C0910.5596%2C0910.4988%2C0910.1354%2C0910.4925%2C0910.4981%2C0910.5500%2C0910.3928%2C0910.1482%2C0910.0823%2C0910.5159%2C0910.0188%2C0910.3529%2C0910.0137%2C0910.4127%2C0910.4293%2C0910.5462%2C0910.1678%2C0910.2254%2C0910.4402%2C0910.3286%2C0910.1266%2C0910.3018%2C0910.5029%2C0910.2419%2C0910.2148%2C0910.1065%2C0910.2445%2C0910.1291%2C0910.3656%2C0910.0464%2C0910.5107%2C0910.1357%2C0910.3234%2C0910.1394%2C0910.0538%2C0910.0493%2C0910.3365%2C0910.5343%2C0910.2266%2C0910.3370%2C0910.2564%2C0910.5860%2C0910.4834%2C0910.4346%2C0910.0066%2C0910.0080%2C0910.4723%2C0910.2881%2C0910.1168%2C0910.4974%2C0910.3077%2C0910.1028%2C0910.3213%2C0910.1500%2C0910.1609%2C0910.0055%2C0910.3435%2C0910.0370%2C0910.4198%2C0910.0565%2C0910.3377%2C0910.5884%2C0910.5899%2C0910.4671%2C0910.1449%2C0910.3696%2C0910.2273%2C0910.2248%2C0910.5301%2C0910.4114%2C0910.1064%2C0910.2403%2C0910.3135%2C0910.4774%2C0910.5947%2C0910.5127%2C0910.0698%2C0910.3675%2C0910.2931%2C0910.0818%2C0910.3331%2C0910.5271%2C0910.1973%2C0910.4053%2C0910.4689%2C0910.1720%2C0910.0284%2C0910.5577%2C0910.1022%2C0910.4049%2C0910.4521%2C0910.0617%2C0910.2597%2C0910.0475%2C0910.2432%2C0910.4428%2C0910.2912%2C0910.0282%2C0910.0830&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We explore the idea of using finite automata to implement new constraints for\nlocal search (this is already a successful technique in constraint-based global\nsearch). We show how it is possible to maintain incrementally the violations of\na constraint and its decision variables from an automaton that describes a\nground checker for that constraint. We establish the practicality of our\napproach idea on real-life personnel rostering problems, and show that it is\ncompetitive with the approach of [Pralong, 2007]."}, "authors": ["Jun He", "Pierre Flener", "Justin Pearson"], "author_detail": {"name": "Justin Pearson"}, "author": "Justin Pearson", "links": [{"title": "doi", "href": "http://dx.doi.org/10.4204/EPTCS.5.2", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0910.1266v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0910.1266v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0910.1266v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0910.1266v1", "arxiv_comment": null, "journal_reference": "EPTCS 5, 2009, pp. 13-25", "doi": "10.4204/EPTCS.5.2", "fulltext": "Toward an automaton Constraint for Local Search\nJun He\n\nPierre Flener\n\nJustin Pearson\n\narXiv:0910.1266v1 [cs.AI] 7 Oct 2009\n\nDepartment of Information Technology\nUppsala University, Box 337, SE \u2013 751 05 Uppsala, Sweden\nFirstname.Lastname@it.uu.se\n\nWe explore the idea of using finite automata to implement new constraints for local search (this is\nalready a successful technique in constraint-based global search). We show how it is possible to\nmaintain incrementally the violations of a constraint and its decision variables from an automaton\nthat describes a ground checker for that constraint. We establish the practicality of our approach idea\non real-life personnel rostering problems, and show that it is competitive with the approach of [12].\n\n1\n\nIntroduction\n\nWhen a high-level constraint programming (CP) language lacks a (possibly global) constraint that would\nallow the formulation of a particular model of a combinatorial problem, then the modeller traditionally\nhas the choice of (1) switching to another CP language that has all the required constraints, (2) formulating a different model that does not require the lacking constraints, or (3) implementing the lacking\nconstraint in the low-level implementation language of the chosen CP language. This paper addresses\nthe core question of facilitating the third option, and as a side effect often makes the first two options\nunnecessary.\nThe user-level extensibility of CP languages has been an important goal for over a decade. In the traditional global search approach to CP (namely heuristic-based tree search interleaved with propagation),\nhigher-level abstractions for describing new constraints include indexicals [17]; (possibly enriched) deterministic finite automata (DFAs) via the automaton [2] and regular [11] generic constraints; and multivalued decision diagrams (MDDs) via the mdd [5] generic constraint. Usually, a generic but efficient\npropagation algorithm achieves a suitable level of local consistency by processing the higher-level description of the new constraint. In the more recent local search approach to CP (called constraint-based\nlocal search, CBLS, in [14]), higher-level abstractions for describing new constraints include invariants [9]; a subset of first-order logic with arithmetic via combinators [16] and differentiable invariants\n[15]; and existential monadic second-order logic for constraints on set decision variables [1]. Usually,\na generic but incremental algorithm maintains the constraint and variable violations by processing the\nhigher-level description of the new constraint.\nIn this paper, we revisit the description of new constraints via automata, already successfully tried\nwithin the global search approach to CP [2, 11], and show that it can also be successfully used within the\nlocal search approach to CP. The significance of this endeavour can be assessed by noting that 108 of the\ncurrently 313 global constraints in the Global Constraint Catalogue [3] are described by DFAs that are\npossibly enriched with counters and conditional transitions [2] (note that DFA generators can easily be\nwritten for other constraints, such as the pattern [4] and stretch [10] constraints, taking the necessarily\nground parameters as inputs), so that all these constraints will instantly become available in CBLS once\nwe show how to implement fully the enriched DFAs that are necessary for some of the described global\nconstraints.\nThe rest of this paper is organised as follows. In Section 2, we present our algorithm for incrementally maintaining both the violation of a constraint described by an automaton, and the violations of\nY. Deville and C. Solnon (Ed.): Sixth International Workshop\non Local Search Techniques in Constraint Satisfaction (LSCS'09).\nEPTCS 5, 2009, pp. 13\u201325, doi:10.4204/EPTCS.5.2\n\nc J. He, P. Flener, and J. Pearson\n\n\fToward an automaton Constraint for Local Search\n\n14\n\n1\n\n2 d\nd\nd x\nx\n3\nx\ne\nx e e\n4\n\nx\n\n5\nd\ne\n\n6\n\nFigure 1: An automaton for a simple work scheduling constraint\neach decision variable of that constraint. In Section 3, we present experimental results establishing the\npracticality of our results, also in comparison to the prior approach of [12]. Finally, in Section 4, we\nsummarise this work and discuss related as well as future work.\n\n2\n\nIncremental Violation Maintenance with Automata\n\nIn CBLS, three things are required of an implemented constraint: a method for calculating the violation\nof the constraint and each of its decision variables for the initial assignment (initialisation); a method\nfor computing the differences of these violations upon a candidate local move (differentiability) to a\nneighbouring assignment; and a method for incrementally maintaining these violations when an actual\nmove is made (incrementality). Intuitively, the higher the violation of a decision variable, the more can\nbe gained by changing the value of that decision variable. It is essential to maintain incrementally the\nviolations rather than recomputing them from scratch upon each local move, since by its nature a local\nsearch procedure will try many local moves to find one that ideally reduces the violation of the constraint\nor one of its decision variables.\nOur running example is the following, for a simple work scheduling constraint. There are values for\ntwo work shifts, day (d) and evening (e), as well as a value for enjoying a day off (x). Work shifts are\nsubject to the following three conditions: one must take at least one day off before a change of work shift;\none cannot work for more than two days in a row; and one cannot have more than two days off in a row.\nA DFA for checking ground instances of this constraint is given in Figure 1. The start state 1 is marked\nby a transition entering from nowhere, while the success states 5 and 6 are marked by double circles.\nMissing transitions, say from state 2 upon reading value e, are assumed to go to an implicit failure state,\nwith a self-looping transition for every value (so that no success state is reachable from it).\n\n2.1 Violations of a Constraint\nTo define and compute the violations of a constraint described by an automaton, we first introduce the\nnotion of a segmentation of an assignment:\nDefinition 1 (Segmentation) Given an assignment V = hd1 , . . . , dn i, a segmentation is a possibly empty\nsequence of non-empty sub-strings (referred to here as segments) \u03c31 , . . . , \u03c3l of d1 * * * dn such that for each\n\u03c3 j = d p * * * dq and \u03c3 j+1 = dr * * * ds we have that r > q.\nFor example, a possible segmentation of the assignment V = hx, e, d, e, x, xi is hx, ei, he, x, xi; note that\nthe third character of the assignment is not part of any segment. In general, an assignment has multiple\npossible segmentations. We are interested in segmentations that are accepted by an automaton, in the\nfollowing sense:\n\n\fJ. He, P. Flener, and J. Pearson\n\n15\n\nDefinition 2 (Acceptance) Given an automaton and an assignment V = hd1 , . . . , dn i, a segmentation\n\u03c31 , . . . , \u03c3l is accepted by the automaton if there exist strings \u03b11 , . . . , \u03b1l+1 , where only \u03b11 and \u03b1l+1 may\nbe empty, such that the concatenated string\n\n\u03b11 * \u03c31 * \u03b12 * * * * * \u03b1l * \u03c3l * \u03b1l+1\nis accepted by the automaton.\nFor example, given the automaton in Figure 1, the assignment V = hx, e, d, e, x, xi has a segmentation\nhx, ei, he, x, xi with l = 2, which is accepted by the automaton via the string hx, e, x, e, x, xi with \u03b11 = \u03b13 =\n\u03b5 (the empty string) and \u03b12 = hdi.\nGiven an assignment, the algorithm presented below initialises and updates a segmentation. The\nviolations of the constraint and its decision variables are calculated relative to the current segmentation:\nDefinition 3 (Violations) Given an automaton describing a constraint c and given a segmentation \u03c31 , . . . , \u03c3l\nof an assignment for a sequence of n decision variables V1 , . . . ,Vn :\n\u2022 The constraint violation of c is n \u2212 \u2211lj=1 |\u03c3 j |.\n\u2022 The variable violation of decision variable Vi is 0 if there exists a segment index j in 1, . . . , l such\nthat i \u2208 \u03c3 j , and 1 otherwise.\nIt can easily be seen that the violation of a constraint is also the sum of the violations of its decision\nvariables, and that it is never an underestimate of the minimal Hamming distance between the current\nassignment and any satisfying assignment.\nOur approach, described in the next three sub-sections, greedily grows a segmentation from left to\nright across the current assignment relative to a satisfying assignment, and makes stochastic choices\nwhenever greedy growth is impossible.\n\n2.2 Initialisation\nA finite automaton is first unrolled for a given length n of a sequence V = hV1 , . . . ,Vn i of decision variables, as in [11]:\nDefinition 4 (Layered Graph) Given a finite automaton with m states, the layered graph over a given\nnumber n of decision variables is a graph with m * (n + 1) nodes. Each of the n + 1 vertical layers has a\nnode for each of the m states of the automaton. The node for the start state of the automaton in layer 1\nis marked as the start node. There is an arc labelled w from node f in layer i to node t in layer i + 1 if\nand only if there is a transition labelled w from f to t in the automaton. A node in layer n + 1 is marked\nas a success node if it corresponds to a success state in the automaton.\nThe layered graph is further processed by removing all nodes and arcs that do not lead to a success\nnode. The resulting graph, seen as a DFA (or as an ordered MDD), need not be minimised (or reduced)\nfor our approach (although this is a good idea for the global search approaches [2, 11], as argued in [7],\nand would be a good idea for the local search approach of [12]), as the number of arcs of the graph does\nnot influence the time complexity of our algorithm below. For instance, the minimised unrolled version\nfor n = 6 decision variables of the automaton in Figure 1 is given in Figure 2. Note that a satisfying\nassignment hd1 , . . . , dn i corresponds to a path from the start node in layer 1 to a success node in layer\nn + 1, such that each arc from layer i to layer i + 1 of this path is labelled di .\nFurther, we require a number of data structures, where m is the number of states in the given automaton and n is the number of decision variables it was unrolled for:\n\n\fToward an automaton Constraint for Local Search\n\n16\n\nLayer 1\n\nLayer 2\n12\n2 x\nd\n\n42\n1\n\nx\ne\n\nd\nd\n18\ne\n3\nx\nx\n4 e\n12\n\nLayer 3\n6\n2 x\nd\nd\n3 e\nx\n8\nx\n4\n6xe\n5\n4\n6\n6\n\nLayer 5\n\nLayer 4\n3\n2 d\nx\n\nd\ne\n\n4d\n3\nx e\n3\n4 e\nx\n2\nx\n5\nd\n6\n2\n\ne\n\nLayer 6\n1\n2\n\n1\n2\n\nd\n\nx\n1\n3\n\nd\n3\n2\n\nLayer 7\n\ne\n\n1\n4\n\nx\n\n5\n\ne\n\nFigure 2: The minimised unrolled automaton of Figure 1. The number by each node is the number of\npaths from that node to the success node in the last layer. The colour coding is purely for the convenience\nof the reader to spot a particular path mentioned in the running text.\n\u2022 nbrPaths[1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m] records the number of paths from node j in layer i to a success\nnode in the last layer; for example, see the numbers by each node in Figure 2;\n\u2022 l is the number of segments in the current segmentation;\n\u2022 segments \u03c31 , . . . , \u03c3l record the current segmentation;\n\u2022 Violation[1 \u2264 i \u2264 n] records the current violation of decision variable Vi (see Definition 3);\nThe nbrPaths matrix can be computed in straightforward fashion by dynamic programming. The other\nthree data structures are initialised (when the starting position is s = 1) and maintained (when decision\nvariable Vs is changed, with s \u2265 1) by the calcSegment(s) procedure of Algorithm 1. Upon some initialisations (lines 2 and 3), it (re)visits only the decision variables Vs , . . . ,Vn (line 4). If the value of the\ncurrently visited decision variable Vi triggers the extension of the currently last segment (lines 6 and 9)\nor the creation of a new segment (lines 6 to 9), then its violation is 0 (line 10). Otherwise, its violation is\n1 and a successor node is picked with a probability weighted according to the number of paths from the\ncurrent node to a success node (lines 11 to 14). Toward this, we maintain the nodes of the picked path\n(line 16).\nThe time complexity of Algorithm 1 is linear in the number n of decision variables, because only\none path (from layer s to layer n + 1) is explored, with a constant-time effort at each node. Once the\npre-processing is done, the time complexity of Algorithm 1 is thus independent of the number of arcs\nof the unrolled automaton! Hence the minimisation (or reduction) of the unrolled automaton would be\nmerely for space savings (and for the convenience of human reading) as well as for accelerating the preprocessing computation of the nbrPaths matrix. In our experiments, these space and time savings are not\nwarranted by the time required for minimisation (or reduction).\nNote that this algorithm works without change or loss of performance on non-deterministic finite\nautomata (NFAs). This is potentially interesting since NFAs are often smaller than their equivalent\nDFAs, but (as just seen) the number of arcs has no influence on the time complexity of Algorithm 1.\n\n\fJ. He, P. Flener, and J. Pearson\n\n17\n\nAlgorithm 1 Computation and update of the current segmentation from position s\n1: procedure calcSegment(s : 1, . . . , n)\n2: let l be the number of segments picked for hV1 , . . . ,Vs\u22121 i at the previous run; assume l = 0 at the\nfirst run\n3: node[1] \u2190 1; inSegment \u2190 true\n4: for all i \u2190 s to n do\n5:\nif the current value, say a, of Vi is the label of an arc from node[i] to some node t then\n6:\nif not inSegment then\n7:\nl \u2190 l + 1; \u03c3l \u2190 \u03b5 ; inSegment \u2190 true {c}reate a new segment\n8:\nend if\n9:\n\u03c3l \u2190 \u03c3l * a\n10:\nViolation[i] \u2190 0\n11:\nelse\n12:\ninSegment \u2190 false\n13:\nViolation[i] \u2190 1\n14:\npick a successor t of node[i] with probability nbrPaths[i + 1,t] / nbrPaths[i, node[i]]\n15:\nend if\n16:\nnode[i + 1] \u2190 t\n17: end for\nFor example, in Figure 2, with the initial assignment V = hx, e, d, e, x, xi and a first call to Algorithm 1\nwith s = 1, the first segment will be hx, ei (the red path). Next, the assignment V3 = d triggers a violation\nof 1 for decision variable V3 (we say that it is a violated variable) because there is no arc labelled d that\nconnects the current node 4 in layer 3 with any nodes in layer 4. However, node 4 in layer 3 has two\nout-going arcs, namely to nodes 3 and 5 in layer 4 (in blue). In layer 4, there are 4 paths from node 3 to\nthe last layer, compared to 2 such paths from node 5, so node 3 is picked with probability 64 and node 5 is\npicked with probability 62 (where the 2, 4, and 6 are the purple numbers by those nodes), and we assume\nthat node 3 in layer 4 is picked. From there, we get the second segment he, x, xi (the green path), which\nstops at success node 5 in the last layer. The violation of the constraint is thus 1, because the value of\none decision variable does not participate in any segment.\nContinuing the example, we assume now that decision variable V3 is changed to value e, and hence\nwe call Algorithm 1 with s = 3. Only l = 1 segment can be kept from the previous segmentation picked\nfor hV1 ,V2 i, namely hx, ei (the red path). Since there is an arc labelled e from the current node 4 in\nlayer 3, namely to node 5 in layer 4, segment l is extended (line 9) to hx, e, ei. However, with decision\nvariable V4 still having value e, this segment cannot be extended further, since there is no arc labelled\ne from node 5 in layer 4, and hence V4 is violated. Similarly, decision variables V5 = x and V6 = x are\nviolated no matter which successors are picked, so no new segment is ever created. The violation of\nthe constraint is thus 3 because the value of three decision variables do not participate in any segment.\nHence changing decision variable V3 from value d to value e would not be considered a good local move,\nas the constraint violation increases from 1 to 3. Changing decision variable V3 to value x instead would\nbe a much better local move, as the first segment hx, ei is then extended to the entire current assignment\nhx, e, d, e, x, xi, without detecting any violated variables, so that the violation of the constraint is then 0,\nmeaning that a satisfying assignment was found.\nIn Section 3, we experiment with a deterministic method [12] for picking the next node and experimentally show that our random pick is computationally quicker at finding solutions.\n\n\fToward an automaton Constraint for Local Search\n\n18\n\n1\n2\n3\n4\n5\n\nMon\nx\nx\nd\ne\nn\n\nTue\nx\nx\nd\ne\nn\n\nWed\nx\ne\nd\nx\nn\n\nThu\nd\ne\nx\nx\nn\n\nFri\nd\ne\nx\nn\nx\n\nSat\nd\nx\ne\nn\nx\n\nSun\nd\nx\ne\nn\nx\n\nTable 1: A five-week rotating schedule with uniform daily workload (1d, 1e, 1n, 2x)\n\n2.3 Differentiability\nAt present, the differences of the (constraint and variable) violations upon a candidate local move are\ncalculated na\u0131\u0308vely by first making the candidate move and then undoing it.\n\n2.4 Incrementality\nLocal search proceeds from the current assignment by checking a number of neighbours of that assignment and picking a neighbour that ideally reduces the violation: the exact heuristics are often problem\ndependent. But in order to make local search computationally efficient, the violations of the constraint\nand its decision variables have to be computed in an incremental fashion whenever a decision variable\nchanges value. As shown in Subsection 2.2, our initialisation Algorithm 1 can also be invoked with an\narbitrary starting position s when decision variable Vs is assigned a new value.\nWe have implemented this algorithm in Comet [14], an object-oriented CP language with among\nothers a CBLS back-end (available at www.dynadec.com).\n\n3\n\nExperiments\n\nWe now establish the practicality of the proposed violation maintenance algorithm by experimenting\nwith it. All local search experiments were conducted under Comet (version 2.0 beta) on an Intel 2.4 GHz\nLinux machine with 512 MB memory while the constraint programming examples where implemented\nusing SICStus Prolog.\nMany industries and services need to function around the clock. Rotating schedules such as the one\nin Table 1 (a real-life example taken from [8]) are a popular way of guaranteeing a maximum of equity\nto the involved work teams (see [8]). In our first benchmark, there are day (d), evening (e), and night\n(n) shifts of work, as well as days off (x). Each team works maximum one shift per day. The scheduling\nhorizon has as many weeks as there are teams. In the first week, team i is assigned to the schedule in\nrow i. For any next week, each team moves down to the next row, while the team on the last row moves up\nto the first row. Note how this gives almost full equity to the teams, except, for instance, that team 1 does\nnot enjoy the six consecutive days off that the other teams have, but rather three consecutive days off at\nthe beginning of week 1 and another three at the end of week 5. The daily workload may be uniform: for\ninstance, in Table 1, each day has exactly one team on-duty for each work shift, and two teams entirely\noff-duty; we denote this as (1d, 1e, 1n, 2x); assuming the work shifts average 8h, each employee will\nwork 7 * 3 * 8 = 168h over the five-week-cycle, or 33.6h per week. Daily workload, whether uniform or\nnot, can be enforced by global cardinality (gcc) constraints [13] on the columns. Further, any number of\nconsecutive workdays must be between two and seven, and any change in work shift can only occur after\n\n\fJ. He, P. Flener, and J. Pearson\n\n19\n\nAlgorithm 2 The search procedure\n1: void search(var{int}[] V, ConstraintSystem<LS> S, var{int} violations,\n2:\nSolution bestSolution, Counter it, int best, int[,] tabu,\n3:\nint restartIter){\n4:\nselect(x in 1..n : S.violation(V[x]) > 0)\n5:\nselectMin(y in 1..n : (x-y) % 7 == 0 && V[x] != V[y],\n6:\nnv = S.getSwapDelta(V[x],V[y]) :\n7:\ntabu[x,y] <= it || (violations+nv) < best)(nv){\n8:\nV[x] :=: V[y];\n9:\ntabu[x,y] = it + max(violations,6);\n10:\ntabu[y,x] = tabu[x,y];\n11:\nif(best > violations){\n12:\nbest = violations;\n13:\nbestSolution = new Solution(ls);\n14:\n}\n15:\nit++;\n16:\nif(it % restartIter == 0) restart();\n17:\n}\n18: }\n\ntwo to seven days off. This can be enforced by a pattern(X , {(d, x), (e, x), (n, x), (x, d), (x, e), (x, n)}) constraint [4] and a circular stretch(X , [d, e, n, x], [2, 2, 2, 2], [7, 7, 7, 7]) constraint [10] on the table flattened\nrow-wise into a sequence X .\nOur model posts the pattern and stretch constraints described by automata. The gcc constraints on\nthe columns of the matrix are kept invariant: the first assignment is chosen so as to satisfy them, and\nthen only swap moves inside a column are considered. As a meta-heuristic, we use tabu search with\nrestarting. At each iteration, the search procedure in Algorithm 2 selects a violated variable x (line 4;\nrecall that the violation of a decision variable is here at most 1) and another variable y of distinct value in\nthe same column so that their swap (line 8) gives the greatest violation change (lines 5 to 7). The length\nof the tabu list is the maximum between 6 and the sum of the violations of all constraints (lines 9 and 10).\nThe best solution so far is maintained (lines 11 to 14). Restarting is done every 2 * |X | iterations (lines 15\nand 16). The expressions for the length of the tabu list and the restart criterion were experimentally\ndetermined.\nRecall that Algorithm 1 computes a greedy random segmentation; hence it might give different segmentations when used for probing a swap and when used for actually performing that swap. Therefore,\nwe record the segmentation of each swap probe, and at the actual swap we just apply its recorded segmentation.\nWe ran experiments over the eight instances from (2d, 1e, 1n, 2x) to (16d, 8e, 8n, 16x) (we write the\nlatter as (2d, 1e, 1n, 2x) * 8) with uniform daily workload, where the weekly workload is 37.3h. For\nexample, instance (2d, 1e, 1n, 2x) * 3 has the uniform daily workload of 2 * 3 teams on the day shift, 1 * 3\nteams on the evening shift, 1 * 3 teams on the night shift, and 2 * 3 teams off-duty. Table 2 gives statistics\non the run times and numbers of iterations to find the first solutions over 100 runs from random initial\nassignments.\nPosting the product of the pattern and stretch automata (accepting the intersection of their two reg-\n\n\fToward an automaton Constraint for Local Search\n\n20\n\ninstance\n(2d, 1e, 1n, 2x) * 1\n(2d, 1e, 1n, 2x) * 2\n(2d, 1e, 1n, 2x) * 3\n(2d, 1e, 1n, 2x) * 4\n(2d, 1e, 1n, 2x) * 5\n(2d, 1e, 1n, 2x) * 6\n(2d, 1e, 1n, 2x) * 7\n(2d, 1e, 1n, 2x) * 8\n\noptimisation time (ms)\nmin\nmax\navg\n\u03c3\n6\n100\n22\n20\n12\n692\n168\n154\n32\n2588\n688\n611\n80\n6553 1199 1275\n60\n9373 1417 1545\n160\n5901 1527 1227\n176\n9896 1720 1686\n216 12472 2620 2309\n\nmin\n9\n32\n44\n86\n72\n161\n157\n150\n\nnumber of iterations\nmax\navg\n\u03c3\n528\n115\n108\n2484\n585\n561\n6612 1726 1571\n11212 2125 2303\n15604 2292 2556\n8051 2051 1681\n11680 1966 1981\n12588 2603 2354\n\nTable 2: Minimum, maximum, average, standard deviation of optimisation times (in milliseconds) and\nnumbers of iterations to the first solutions of rotating nurse schedules (100 runs) from random initial\nassignments.\n\ninstance\n(2d, 1e, 1n, 2x) * 1\n(2d, 1e, 1n, 2x) * 2\n(2d, 1e, 1n, 2x) * 3\n(2d, 1e, 1n, 2x) * 4\n(2d, 1e, 1n, 2x) * 5\n(2d, 1e, 1n, 2x) * 6\n(2d, 1e, 1n, 2x) * 7\n(2d, 1e, 1n, 2x) * 8\n\noptimisation time (ms)\nmin max avg\n\u03c3\n1\n16\n2\n3\n1\n64\n12\n12\n12\n76\n25\n13\n28 172\n51\n27\n28 200\n79\n42\n56 368 135\n76\n84 768 188 123\n112 764 233 112\n\nnumber of iterations\nmin max avg\n\u03c3\n6\n61\n11\n9\n13 235\n34\n46\n21 173\n46\n29\n32 297\n72\n49\n34 286 106\n61\n61 487 156 101\n69 848 189 140\n72 736 202 113\n\nTable 3: Minimum, maximum, average, standard deviation of optimisation times (in milliseconds) and\nnumbers of iterations to the first solutions of rotating nurse schedules (100 runs) from non-random initial\nassignments.\nular languages) has been experimentally determined to be more efficient than posting the two automata\nindividually, hence all experiments in this paper use the product automaton.\nFurther improvements can be achieved by using a non-random initial assignment. Table 3 gives\nstatistics on the run times and numbers of iterations to find the first solutions over 100 runs, where the\ninitial assignment of instance (2d, 1e, 1n, 2x) * i consists of i copies of Table 4. The results show that\nthis non-random initialisation provides a better starting point. Although much more experimentation is\nrequired, these initial results show that even on the instance (2d, 1e, 1n, 2x) * 8 with 336 decision variables\nit is possible to find solutions quickly.\nThe only related work we are aware of is a Comet implementation [12] of the regular constraint [11],\nbased on the ideas for the propagator of the soft regular constraint [6]. The difference is that they estimate\nthe violation change compared to the nearest solution (in terms of Hamming distance from the current\nassignment), whereas we estimate it compared to one randomly picked solution. In our terminology\n(although it is not implemented that way in [12]), they find a segmentation, such that an accepting string\nfor the automaton has the minimal Hamming distance to the current assignment.\nTables 5 and 6 give comparisons between (our re-implementation of) regular [12], our method, and\n\n\fJ. He, P. Flener, and J. Pearson\n\n1\n2\n3\n4\n5\n6\n\n21\nMon\nd\ne\nn\nx\nd\nx\n\nTue\nd\ne\nn\nx\nd\nx\n\nWed\nd\ne\nn\nx\nd\nx\n\nThu\nd\ne\nn\nx\nd\nx\n\nFri\nd\ne\nn\nx\nd\nx\n\nSat\nd\ne\nn\nx\nd\nx\n\nSun\nd\ne\nn\nx\nd\nx\n\nTable 4: Non-random initial assignment for the instance (2d, 1e, 1n, 2x)\n\ninstance\n(2d, 1e, 1n, 2x) * 1\n(2d, 1e, 1n, 2x) * 2\n(2d, 1e, 1n, 2x) * 3\n(2d, 1e, 1n, 2x) * 4\n(2d, 1e, 1n, 2x) * 5\n(2d, 1e, 1n, 2x) * 6\n(2d, 1e, 1n, 2x) * 7\n(2d, 1e, 1n, 2x) * 8\nSt Louis Police\n\noptimisation time (ms)\nour method\nregular [12]\navg\n\u03c3\navg\n\u03c3\n22\n20\n395\n378\n168\n154\n1584\n1187\n688\n611\n3441\n2871\n1199\n1275\n5584\n4423\n1417\n1545\n8828\n7606\n1527\n1227 13888 10863\n1720\n1686 13170\n9814\n2620\n2309 20202 11530\n12740 11199 50261 48026\n\nCP\n10\n10\n10\n40\n100\n510\n3520\n25820\n\u2013\n\nnumber of iterations\nour method\nregular [12]\navg\n\u03c3\navg\n\u03c3\n115\n108\n98\n100\n585\n561\n223\n170\n1726\n1571\n333\n287\n2125\n2303\n399\n319\n2292\n2556\n514\n444\n2051\n1681\n672\n529\n1966\n1981\n536\n485\n2603\n2354\n745\n602\n20287 17952 3248 2498\n\nTable 5: Comparison between our method, regular [12], and a SICStus Prolog program using the\nautomaton [2] constraint: average and standard deviation of optimisation times (in milliseconds) and\nnumbers of iterations to the first solutions; rotating nurse schedules (100 runs) and the St Louis Police\ninstance (50 runs), from random initial assignments.\na SICStus Prolog constraint program (CP) where the product automaton of the pattern and stretch constraints was posted using the built-in propagation-based implementation of the automaton constraint [2].\nThese experiments show:\n\u2022 Compared with regular [12], our method has a higher number of iterations, as it is more stochastic.\nHowever, our run times are lower, as our cost of one iteration is much smaller (linear in the number\nof decision variables, instead of linear in the number of arcs of the unrolled automaton).\n\u2022 Compared with the CP method, both local search methods need more time to find the first solution\nwhen the number of weeks is small. However, when the number of weeks increases, the runtime of\nCP increases sharply. From the instance (2d, 1e, 1n, 2x) * 7, the runtime of CP exceeds the average\nruntime of our method. From the instance (2d, 1e, 1n, 2x) * 8, the runtime of CP exceeds also the\naverage runtime of regular [12].\nBesides the rotating nurse instances, we ran experiments on another, harder real-life scheduling instance. The St Louis Police problem (described in [12]) has a seventeen-week-cycle; however it has\nmore constraints than the rotating nurse problem. It has non-uniform daily workloads. For example, on\nMondays, five teams work during the day, five at night, four in the evening, and three teams enjoy a day\noff; while on Sundays, three teams work during the day, four at night, four in the evening, and six teams\n\n\fToward an automaton Constraint for Local Search\n\n22\n\ninstance\n(2d, 1e, 1n, 2x) * 1\n(2d, 1e, 1n, 2x) * 2\n(2d, 1e, 1n, 2x) * 3\n(2d, 1e, 1n, 2x) * 4\n(2d, 1e, 1n, 2x) * 5\n(2d, 1e, 1n, 2x) * 6\n(2d, 1e, 1n, 2x) * 7\n(2d, 1e, 1n, 2x) * 8\nSt Louis Police\n\noptimisation time (ms)\nour method\nregular [12]\navg\n\u03c3\navg\n\u03c3\n2\n3\n44\n26\n12\n12\n182\n65\n25\n13\n478\n201\n51\n27\n834\n254\n79\n42\n1546\n876\n135\n76\n2414\n1233\n188\n123\n4517\n3276\n233\n112\n4473\n1958\n3990 4012 67159 55632\n\nnumber of iterations\nour method regular [12]\navg\n\u03c3\navg\n\u03c3\n11\n9\n10\n7\n34\n46\n22\n9\n46\n29\n41\n17\n72\n49\n56\n18\n106\n61\n87\n51\n156\n101\n113\n59\n189\n140\n181\n134\n202\n113\n160\n71\n5389 5598 3949 3159\n\nTable 6: Comparison between our method and regular [12]: average and standard deviation of optimisation times (in milliseconds) and numbers of iterations to the first solutions; rotating nurse schedules\n(100 runs) and the St Louis Police instance (50 runs), from non-random initial assignments.\nenjoy a day off. Any number of consecutive workdays must be between three and eight, and any change\nin work shift can only occur after two to seven days off. The problem has other vertical constraints; for\nexample, no team can work in the same shift on four consecutive Mondays. Further, the problem has\ncomplex pattern constraints that limit possible changes of work shifts; for example, only the patterns\n(d, x, d), (e, x, e), (n, x, n), (d, x, e), (e, x, n), and (n, x, d) are allowed. For this hard real-life problem, our\nmethod still works well: experimental results can also be found in Tables 5 and 6.\nIt is possible to post (see Figure 3) the constraints of the rotating nurse problem using the differentiable invariants [15] of Comet. This is possible in general for any automaton by encoding all the paths\nto a success state by using Comet's conjunction and disjunction combinators. As the automata get larger,\nthese expressions can become too large to post, and even when it is possible to post these expressions\nour current experiments show that our approach is more efficient.\n\n4\n\nConclusion\n\nIn summary, we have shown that the idea of describing novel constraints by automata can be successfully\nimported from classical (global search) constraint programming to constraint-based local search (CBLS).\nOur violation algorithms take time linear in the number of decision variables, whereas the propagation\nalgorithms take amortised time linear in the number of arcs of the unrolled automaton [2, 11]. We have\nalso experimentally shown that our approach is competitive with the CBLS approach of [12].\nThere is of course a trade-off between using an automaton to describe a constraint and using a handcrafted implementation of that constraint. On the one hand, a hand-crafted implementation of a constraint\nis normally more efficient during search, because properties of the constraint can be exploited, but it may\ntake a lot of time to implement and verify it. On the other hand, the (violation or propagation) algorithm\nprocessing the automaton is implemented and verified once and for all, and our assumption is that it takes\na lot less time to describe and verify a new constraint by an automaton than to implement and verify its\nalgorithm. We see thus opportunities for rapid prototyping with constraints described by automata: once\na sufficiently efficient model, heuristic, and meta-heuristic have been experimentally determined with\n\n\fJ. He, P. Flener, and J. Pearson\n\n\uf8eb\n\n\uf8eb\n\n23\n\uf8eb\n\n\uf8f6 \uf8f6 \uf8f6\nV4 = d \u2227V5 = x \u2227V6 = x\n\uf8f8 \uf8f7 \uf8f7\nV3 = d \u2227 \uf8ed \u2228\n\uf8f7 \uf8f7\n\uf8f7 \uf8f7\nV4 = x \u2227 (V5 = d \u2227V6 = d \u2228V5 = e \u2227V6 = e)\n\uf8f7 \uf8f7\n\uf8f7 \uf8f7\n\u2228\n\uf8f7 \uf8f7\n\uf8f7 \uf8f7\nV3 = e \u2227 . . .\n\uf8f7 \uf8f7\n\uf8f8 \uf8f7\n\u2228\n\uf8f7\n\uf8f7\nV3 = x \u2227 . . .\n\uf8f7\n\uf8f8\n\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec V2 = x \u2227 \uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\nV1 = d \u2227 \uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ed\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ed \u2228\nV2 = d \u2227V3 = x \u2227 . . .\n\u2228\n\uf8eb\n\uf8f6\nV2 = d \u2227 . . .\n\uf8ec \u2228\n\uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\nV1 = x \u2227 \uf8ec V2 = e \u2227 . . . \uf8f7\n\uf8f7\n\uf8ed \u2228\n\uf8f8\nV2 = x \u2227 . . .\n\u2228\n\uf8eb\n\uf8f6\nV2 = x \u2227 . . .\n\uf8f8\nV1 = e \u2227 \uf8ed \u2228\nV2 = e \u2227 . . .\n\nFigure 3: A model for the unrolled DFA in Figure 2 with Comet combinators\n\nits help, some extra efficiency may be achieved, if necessary, by hand-crafting implementations of any\nconstraints described by automata.\nAs witnessed in our experiments, constraint composition (by conjunction) is easy to experiment with\nunder the DFA approach, as there exist standard and efficient algorithms for composing and minimising\nDFAs, but there is no known systematic way of composing violation (or propagation) algorithms when\ndecomposition is believed to obstruct efficiency.\nIn the global search approach to CP, the common modelling device of reification can be used to shrink\nthe size of DFAs describing constraints [2]. For instance, consider the element([x1 , . . . , xn ], i, v) constraint,\nwhich holds if and only if xi = v. Upon reifying the decision variables x1 , . . . , xn into new Boolean\ndecision variables b1 , . . . , bn such that xi = v \u21d4 bi = 1, it suffices to pose the automaton([b1 , . . . , bn ], DFA)\nconstraint, where DFA corresponds to the regular expression 0\u2217 1(0+1)\u2217 , meaning that at least one 1 must\nbe found in the sequence of the bi decision variables. However, such explicit reification constraints are\nnot necessary in constraint-based local search, as a total assignment of values to all decision variables is\nmaintained at all times: instead of processing the values of the decision variables when computing the\nsegments, one can process their reified values.\nIt has been shown that the use of counters (initialised at the start state and evolving during possibly\nconditional transitions) to enrich the language of DFAs and thereby shrink the size of DFAs can be\nhandled in the global search approach to CP [2], possibly upon some concessions at the level of local\nconsistency that can be achieved. In the Global Constraint Catalogue [3], some 31 of the currently 108\nconstraints described by DFAs use lists of counters, and another 25 constraints use arrays of counters.\nWe need to investigate the effects on our violation maintenance algorithm of introducing counters and\nconditional transitions.\n\n\f24\n\nToward an automaton Constraint for Local Search\n\nAcknowledgements\nThe authors are supported by grant 2007-6445 of the Swedish Research Council (VR), and Jun He is also\nsupported by grant 2008-611010 of China Scholarship Council and the National University of Defence\nTechnology of China. Many thanks to Magnus \u00c5gren (SICS) for some useful discussions on this work,\nand to the anonymous referees of both LSCS'09 and the Doctoral Programme of CP'09, especially for\npointing out the existence of [12, 6].\n\nReferences\n[1] Magnus \u00c5gren, Pierre Flener & Justin Pearson (2007): Generic incremental algorithms for local search.\nConstraints 12(3), pp. 293\u2013324. (Collects the results of papers at CP-AI-OR'05, CP'05, and CP'06, published\nin LNCS 3524, 3709, and 4204).\n[2] Nicolas Beldiceanu, Mats Carlsson & Thierry Petit (2004): Deriving filtering algorithms from constraint\ncheckers. In: Mark Wallace, editor: Proceedings of CP'04, LNCS 3258. Springer-Verlag, pp. 107\u2013122.\n[3] Nicolas Beldiceanu, Mats Carlsson & Jean-Xavier Rampon (2007): Global constraint catalogue: Past,\npresent, and future. Constraints 12(1), pp. 21\u201362. Dynamic on-line version at www.emn.fr/x-info/\nsdemasse/gccat. Long version as Technical Report T2005:08, Swedish Institute of Computer Science,\nNovember 2005.\n[4] St\u00e9phane Bourdais, Philippe Galinier & Gilles Pesant (2003): HIBISCUS: A constraint programming application to staff scheduling in health care. In: Francesca Rossi, editor: Proceedings of CP'03, LNCS 2833.\nSpringer-Verlag, pp. 153\u2013167.\n[5] Kenil C. K. Cheng & Roland H. C. Yap (2008): Maintaining generalized arc consistency on ad hoc r-ary\nconstraints. In: Peter J. Stuckey, editor: Proceedings of CP'08, LNCS 5202. Springer-Verlag, pp. 509\u2013523.\n[6] Willem-Jan van Hoeve, Gilles Pesant & Louis-Martin Rousseau (2006): On global warming: Flow-based\nsoft global constraints. Journal of Heuristics 12(4-5), pp. 347\u2013373.\n[7] Mikael Z. Lagerkvist (2008): Techniques for Efficient Constraint Propagation. Technical Report, KTH \u2013 The\nRoyal Institute of Technology, Stockholm, Sweden. Licentiate Thesis.\n[8] Gilbert Laporte (1999): The art and science of designing rotating schedules. Journal of the Operational\nResearch Society 50(10), pp. 1011\u20131017.\n[9] Laurent Michel & Pascal Van Hentenryck (1997): Localizer: A modeling language for local search. In: Gert\nSmolka, editor: Proceedings of CP'97, LNCS 1330. Springer-Verlag, pp. 237\u2013251.\n[10] Gilles Pesant (2001): A filtering algorithm for the stretch constraint. In: Toby Walsh, editor: Proceedings of\nCP'01, LNCS 2239. Springer-Verlag, pp. 183\u2013195.\n[11] Gilles Pesant (2004): A regular language membership constraint for finite sequences of variables. In: Mark\nWallace, editor: Proceedings of CP'04, LNCS 3258. Springer-Verlag, pp. 482\u2013495.\n[12] Benoit Pralong (2007): Impl\u00e9mentation de la contrainte Regular en Comet. Master's thesis, \u00c9cole Polytechnique de Montr\u00e9al, Canada.\n[13] Jean-Charles R\u00e9gin (1996): Generalized arc-consistency for global cardinality constraint. In: Proceedings\nof AAAI'96. AAAI Press, pp. 209\u2013215.\n[14] Pascal Van Hentenryck & Laurent Michel (2005): Constraint-Based Local Search. The MIT Press.\n[15] Pascal Van Hentenryck & Laurent Michel (2006): Differentiable invariants. In: Fr\u00e9d\u00e9ric Benhamou, editor:\nProceedings of CP'06, LNCS 4204. Springer-Verlag, pp. 604\u2013619.\n[16] Pascal Van Hentenryck, Laurent Michel & Liyuan Liu (2004): Constraint-based combinators for local\nsearch. In: Mark Wallace, editor: Proceedings of CP'04, LNCS 3258. Springer-Verlag, pp. 47\u201361.\n[17] Pascal Van Hentenryck, Vijay Saraswat & Yves Deville (1993): Design, implementation, and evaluation of\nthe constraint language cc(FD). Technical Report CS-93-02, Brown University, Providence, USA. Revised\n\n\fJ. He, P. Flener, and J. Pearson\n\n25\n\nversion in Journal of Logic Programming 37(1\u20133):293\u2013316, 1998. Based on the unpublished manuscript\nConstraint Processing in cc(FD), 1991.\n\n\f"}