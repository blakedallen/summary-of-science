{"id": "http://arxiv.org/abs/0706.2602v1", "guidislink": true, "updated": "2007-06-18T13:42:16Z", "updated_parsed": [2007, 6, 18, 13, 42, 16, 0, 169, 0], "published": "2007-06-18T13:42:16Z", "published_parsed": [2007, 6, 18, 13, 42, 16, 0, 169, 0], "title": "Effects of Hebbian learning on the dynamics and structure of random\n  networks with inhibitory and excitatory neurons", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0706.3586%2C0706.0120%2C0706.4318%2C0706.1028%2C0706.0837%2C0706.1072%2C0706.0302%2C0706.2742%2C0706.0092%2C0706.2415%2C0706.1689%2C0706.4235%2C0706.3591%2C0706.2279%2C0706.0201%2C0706.1013%2C0706.4192%2C0706.1753%2C0706.3053%2C0706.1131%2C0706.3378%2C0706.4377%2C0706.1706%2C0706.3818%2C0706.1327%2C0706.1379%2C0706.1375%2C0706.1065%2C0706.0259%2C0706.1651%2C0706.0937%2C0706.4452%2C0706.2455%2C0706.3445%2C0706.2145%2C0706.3398%2C0706.2913%2C0706.1180%2C0706.2420%2C0706.1884%2C0706.0339%2C0706.4013%2C0706.1729%2C0706.1540%2C0706.2935%2C0706.1176%2C0706.3964%2C0706.3123%2C0706.0573%2C0706.1868%2C0706.3300%2C0706.0690%2C0706.3444%2C0706.0110%2C0706.4363%2C0706.0651%2C0706.2602%2C0706.3149%2C0706.2375%2C0706.0100%2C0706.3534%2C0706.3035%2C0706.2188%2C0706.0736%2C0706.1817%2C0706.2232%2C0706.1596%2C0706.1475%2C0706.0777%2C0706.1974%2C0706.2813%2C0706.2008%2C0706.3364%2C0706.1194%2C0706.2616%2C0706.3049%2C0706.3713%2C0706.2931%2C0706.3177%2C0706.3927%2C0706.1951%2C0706.2224%2C0706.0244%2C0706.1398%2C0706.4037%2C0706.3863%2C0706.0867%2C0706.3778%2C0706.0938%2C0706.3583%2C0706.2084%2C0706.4444%2C0706.1692%2C0706.0064%2C0706.0322%2C0706.3341%2C0706.3549%2C0706.3684%2C0706.4071%2C0706.2286%2C0706.2246&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Effects of Hebbian learning on the dynamics and structure of random\n  networks with inhibitory and excitatory neurons"}, "summary": "The aim of the present paper is to study the effects of Hebbian learning in\nrandom recurrent neural networks with biological connectivity, i.e. sparse\nconnections and separate populations of excitatory and inhibitory neurons. We\nfurthermore consider that the neuron dynamics may occur at a (shorter) time\nscale than synaptic plasticity and consider the possibility of learning rules\nwith passive forgetting. We show that the application of such Hebbian learning\nleads to drastic changes in the network dynamics and structure. In particular,\nthe learning rule contracts the norm of the weight matrix and yields a rapid\ndecay of the dynamics complexity and entropy. In other words, the network is\nrewired by Hebbian learning into a new synaptic structure that emerges with\nlearning on the basis of the correlations that progressively build up between\nneurons. We also observe that, within this emerging structure, the strongest\nsynapses organize as a small-world network. The second effect of the decay of\nthe weight matrix spectral radius consists in a rapid contraction of the\nspectral radius of the Jacobian matrix. This drives the system through the\n``edge of chaos'' where sensitivity to the input pattern is maximal. Taken\ntogether, this scenario is remarkably predicted by theoretical arguments\nderived from dynamical systems and graph theory.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0706.3586%2C0706.0120%2C0706.4318%2C0706.1028%2C0706.0837%2C0706.1072%2C0706.0302%2C0706.2742%2C0706.0092%2C0706.2415%2C0706.1689%2C0706.4235%2C0706.3591%2C0706.2279%2C0706.0201%2C0706.1013%2C0706.4192%2C0706.1753%2C0706.3053%2C0706.1131%2C0706.3378%2C0706.4377%2C0706.1706%2C0706.3818%2C0706.1327%2C0706.1379%2C0706.1375%2C0706.1065%2C0706.0259%2C0706.1651%2C0706.0937%2C0706.4452%2C0706.2455%2C0706.3445%2C0706.2145%2C0706.3398%2C0706.2913%2C0706.1180%2C0706.2420%2C0706.1884%2C0706.0339%2C0706.4013%2C0706.1729%2C0706.1540%2C0706.2935%2C0706.1176%2C0706.3964%2C0706.3123%2C0706.0573%2C0706.1868%2C0706.3300%2C0706.0690%2C0706.3444%2C0706.0110%2C0706.4363%2C0706.0651%2C0706.2602%2C0706.3149%2C0706.2375%2C0706.0100%2C0706.3534%2C0706.3035%2C0706.2188%2C0706.0736%2C0706.1817%2C0706.2232%2C0706.1596%2C0706.1475%2C0706.0777%2C0706.1974%2C0706.2813%2C0706.2008%2C0706.3364%2C0706.1194%2C0706.2616%2C0706.3049%2C0706.3713%2C0706.2931%2C0706.3177%2C0706.3927%2C0706.1951%2C0706.2224%2C0706.0244%2C0706.1398%2C0706.4037%2C0706.3863%2C0706.0867%2C0706.3778%2C0706.0938%2C0706.3583%2C0706.2084%2C0706.4444%2C0706.1692%2C0706.0064%2C0706.0322%2C0706.3341%2C0706.3549%2C0706.3684%2C0706.4071%2C0706.2286%2C0706.2246&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The aim of the present paper is to study the effects of Hebbian learning in\nrandom recurrent neural networks with biological connectivity, i.e. sparse\nconnections and separate populations of excitatory and inhibitory neurons. We\nfurthermore consider that the neuron dynamics may occur at a (shorter) time\nscale than synaptic plasticity and consider the possibility of learning rules\nwith passive forgetting. We show that the application of such Hebbian learning\nleads to drastic changes in the network dynamics and structure. In particular,\nthe learning rule contracts the norm of the weight matrix and yields a rapid\ndecay of the dynamics complexity and entropy. In other words, the network is\nrewired by Hebbian learning into a new synaptic structure that emerges with\nlearning on the basis of the correlations that progressively build up between\nneurons. We also observe that, within this emerging structure, the strongest\nsynapses organize as a small-world network. The second effect of the decay of\nthe weight matrix spectral radius consists in a rapid contraction of the\nspectral radius of the Jacobian matrix. This drives the system through the\n``edge of chaos'' where sensitivity to the input pattern is maximal. Taken\ntogether, this scenario is remarkably predicted by theoretical arguments\nderived from dynamical systems and graph theory."}, "authors": ["Benoit Siri", "Mathias Quoy", "Bruno Delord", "Bruno Cessac", "Hugues Berry"], "author_detail": {"name": "Hugues Berry"}, "author": "Hugues Berry", "links": [{"href": "http://arxiv.org/abs/0706.2602v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0706.2602v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0706.2602v1", "affiliation": "INRIA Futurs", "arxiv_url": "http://arxiv.org/abs/0706.2602v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Effects of Hebbian learning on the dynamics\n\narXiv:0706.2602v1 [q-bio.NC] 18 Jun 2007\n\nand structure of random networks with\ninhibitory and excitatory neurons\n\nBeno\u0131\u0302t Siri a , Mathias Quoy b , Bruno Delord c\n, Bruno Cessac d,e , Hugues Berry a,\u2217\na INRIA,\nb ETIS,\n\nProject-Team Alchemy, 4 rue J Monod, 91893 Orsay Cedex, France\n\nUMR 8051 CNRS-Universit\u00e9 de Cergy-Pontoise-ENSEA, 6 avenue du\nPonceau, BP 44, 95014 Cergy-Pontoise Cedex, France\n\nc ANIM,\n\nU742 INSERM - Universit\u00e9 P.M. Curie, 9 quai Saint-Bernard, 75005\nParis, France\n\nd INLN,\n\nUMR 6618 CNRS-Universit\u00e9 de Nice, 1361 route des Lucioles, 06560\nValbonne, France\n\ne INRIA,\n\nProject-Team Odyssee, 2004 Route des Lucioles, 06902 Sophia Antipolis,\nFrance\n\nAbstract\nThe aim of the present paper is to study the effects of Hebbian learning in random\nrecurrent neural networks with biological connectivity, i.e. sparse connections and\nseparate populations of excitatory and inhibitory neurons. We furthermore consider\nthat the neuron dynamics may occur at a (shorter) time scale than synaptic plasticity and consider the possibility of learning rules with passive forgetting. We show\nthat the application of such Hebbian learning leads to drastic changes in the network\n\nPreprint submitted to Elsevier\n\nOctober 22, 2018\n\n\fdynamics and structure. In particular, the learning rule contracts the norm of the\nweight matrix and yields a rapid decay of the dynamics complexity and entropy. In\nother words, the network is rewired by Hebbian learning into a new synaptic structure that emerges with learning on the basis of the correlations that progressively\nbuild up between neurons. We also observe that, within this emerging structure,\nthe strongest synapses organize as a small-world network. The second effect of the\ndecay of the weight matrix spectral radius consists in a rapid contraction of the\nspectral radius of the Jacobian matrix. This drives the system through the \"edge\nof chaos\" where sensitivity to the input pattern is maximal. Taken together, this\nscenario is remarkably predicted by theoretical arguments derived from dynamical\nsystems and graph theory.\nKey words: Random recurrent neural networks, Hebbian Learning, Network\nstructure, Chaotic dynamics\n\n1\n\nIntroduction\n\nNeural networks show amazing abilities for information storage and processing, and stimulus-dependent activity shaping. These capabilities are mainly\nconditioned by the mutual coupling relationships between network structure\nand neuron dynamics. Actually, learning in neural networks implies that activity guides the way synapses evolve; but the resulting connectivity structure\nin turn can raise new dynamical regimes. This interaction becomes even more\ncomplex if the considered basic architecture is not feed-forward but includes\nrecurrent synaptic links, like in cortical structures. Understanding this mutual\ncoupling between dynamics and topology and its effects on the computations\n\u2217 Corresponding author: hugues.berry@inria.fr\n\n2\n\n\fmade by the network is a key problem in computational neuroscience, that\ncould benefit from new approaches.\nIn the related field of dynamical systems interacting via complex coupling\nnetworks, a large amount of work has recently focused on the influence of\nnetwork topology on global dynamics (for a review, see [9]). In particular,\nmuch effort has been devoted to understanding the relationships between node\nsynchronization and the classical statistical quantifiers of complex networks\n(degree distribution, average clustering index, mean shortest path, modularity...) [21,35,32]. The main idea was that the impact of network topology on\nthe global dynamics might be prominent, so that these structural statistics\nmay be good indicators of the global dynamics. This assumption proved however largely wrong so that some of the related studies yielded contradictory\nresults [35,27]. Actually, synchronization properties cannot be systematically\ndeduced from topology statistics but may be inferred from the spectrum of the\nnetwork [3]. Accordingly, many studies have considered diffusive coupling of\nthe nodes [22]. In this case, the adjacency matrix has real nonnegative eigenvalues, and global properties, such as stability of the synchronized states [4],\ncan easily be inferred from its spectral properties.\nIn this perspective, neural networks can be considered as mere examples of\nthese complex systems, with the particularity that the dynamics of the network nodes (neurons) depends on the network links (synaptic weights), that\nthemselves vary over time as a function of the node dynamics. Unfortunately,\nthe coupling between neurons (synaptic weight) is rarely diffusive, so that the\ncorresponding matrix is not symmetric and may contain positive and negative\nelements. Hence the mutual coupling between neuron dynamics and network\nstructure remains largely to be understood.\nOur general objective is to shed light on these interactions in the specific\n3\n\n\fcase of random recurrent neural networks (RRNNs). These network models\ndisplay a rich variety of dynamical behaviors, including fixed points, limit\ncycle oscillations, quasiperiodicity and deterministic chaos [16], that are suspected to be similar to activity patterns observed in the olfactory bulb [41,18].\nIt is known that the application of biologically-plausible local learning rules\n(Hebbian rules) reduces the dynamics of chaotic RRNNs to simpler attractors\nthat are specific of the learned input pattern [13]. This phenomenon endows\nRRNNs with associative memory properties, but remains poorly understood.\nOur previous work showed that the evolution of the network structure during\nlearning can be tracked in numerical simulations via the classical topological\nstatistics from \"complex networks approaches\" [6]. More recently, we devised\na mathematical framework for the effects of Hebbian learning on the dynamics, topology and some functional aspects of RRNNs [40]. This theoretical\napproach was shown to explain the effect of learning in a \"canonical\" RRNN,\ni.e. a completely connected network where a neuron projects both excitatory\nand inhibitory synapses. However, this network type remains rather poorly\nrealistic from a biological point of view.\nThe aim of the present paper is thus to study the effects of a more biological\nconnectivity. In particular, we segregate the neurons into two distinct populations, namely excitatory (projecting only excitatory synapses) and inhibitory\n(projecting only inhibitory synapses) neurons. Furthermore, the network is\nsparsely connected and the overall connectivity parameters are fixed to emulate local circuitry in the cortex. We show that the application of Hebbian\nlearning leads to drastic changes in the network dynamics and structure. We\nalso demonstrate that the mathematical arguments mentioned above remain\na very useful unifying framework to understand the effects of learning in this\nsystem.\n4\n\n\f2\n\nThe model\n\n2.1 Connectivity\n\nWe consider networks with a total of N = 500 neurons and random connectivity. Each neuron is either inhibitory (with probability pI ) or excitatory (with\nprobability pE = 1 \u2212 pI ) and projects to pc N randomly chosen postsynaptic\nneurons (independently of their excitatory or inhibitory nature). Probabilities\nare taken uniform on [0, 1] for the network connectivity pc and fraction of\ninhibitory neurons pI . In the present study, we fixed pI and pc so as to account for the neural circuitry of a typical neocortical column. Hence, we used\npI = 0.25 [30] and pc = 0.15 [33,29].\nThe initial weight of each synapse between a postsynaptic neuron i and a\n(1)\n\npresynaptic neuron j, Wij , is drawn at random, according to a Gamma distribution, whose parameters depend on the nature of the presynaptic neuron\n(1)\n\nj. If j is inhibitory, Wij \u223c Gamma(\u2212\u03bcw /ni , \u03c3w /ni ), where Gamma(m, s) denotes the Gamma distribution with mean m and standard deviation s, and\n(1)\n\nni = pI pc N. If j is excitatory, then Wij\n\n\u223c Gamma(\u03bcw /ne , \u03c3w /ne ) where\n\nne = pE pc N. Using Gamma distributions (instead of Gaussian ones, for instance) allows to ensure that inhibitory (excitatory) neurons project only negative (positive) synapses, whatever the values of \u03bcw and \u03c3w . Thanks to the\nnormalization terms (ne and ni ), the total excitation received by a postsynaptic neuron is on average equal to the total inhibition it receives. Hence, in their\ninitial setups (i.e. before learning) our networks are guarantied to conserve the\n5\n\n\fexcitation/inhibition balance (on average).\n\n2.2 Dynamics\n\nWe consider firing-rate neurons with discrete-time dynamics and take into account that learning may occur on a different (slower) time scale than neuron\ndynamics. Synaptic weights are thus kept constant for \u03c4 \u2265 1 consecutive dynamics steps, which defines a \"learning epoch\". The weights are then updated\nand a new learning epoch begins. We denote by t \u2265 0 the update index of\nneuron states (neuron dynamics) inside a learning epoch, while T \u2265 1 indicates the update index of synaptic weights (learning dynamics).\n(T )\n\nLet xi (t) \u2208 [0, 1] be the mean firing rate of neuron i, at time t within the\nlearning epoch T . Let W (T ) be the matrix of synaptic weights at the T -th\nlearning epoch and \u03be the vector (\u03bei )N\ni=1 . Then the discrete time neuron dynamics (1) writes:\n\uf8eb\n\n(T )\n\nxi (t + 1) = f \uf8ed\n\nN\nX\n\nj=1\n\n(T ) (T )\n\n\uf8f6\n\nWij xj (t) + \u03bei \uf8f8 .\n\n(1)\n\nHere, f is a sigmoidal transfer function (f (x) = 1/2 (1 + tanh(gx))). The\noutput gain g tunes the nonlinearity of the function and mimics the excitability\nof the neuron. \u03bei is a (time constant) external input applied to neuron i and\n(T )\n\nthe vector \u03be is the \"pattern\" to be learned. Wij\n\nrepresents the weight of the\n\nsynapse from presynaptic neuron j to postsynaptic neuron i during learning\nepoch T . Finally, at the end of one learning epoch, the neuron dynamics indices\n(T +1)\n\nare reset: xi\n\n(T )\n\n(0) = xi (\u03c4 ), \u2200i.\n6\n\n\f2.3 Learning\n\nIn the present work, we used the following Hebbian learning rule (see [40] for\njustifications):\n(T +1)\n\nWij\n\n(T )\n\n= \u03bbWij + sj\n\n\u03b1 (T ) (T ) \u0010 (T ) \u0011\nm mj H mj .\nN i\n\n(2)\n\nwhere \u03b1 is the learning rate, sj = +1 if j is excitatory and \u22121 if it is inhibitory\nand H denotes the Heaviside step function (H(x) = 0 if x < 0, 1 else). The\nfirst term in the right-hand side (RHS) member accounts for passive forgetting,\ni.e. \u03bb \u2208 [0, 1] is the forgetting rate. If \u03bb < 1 and mi or mj = 0 (i.e. the preor postsynaptic neurons are silent, see below), eq.(2) leads to an exponential\ndecay of the synaptic weights (hence passive forgetting). Another important\nconsequence of this rule choice is that if \u03bb < 1, the weights are expected to\nconverge to stationary values. Hence \u03bb < 1 also allows avoiding divergence of\nthe synaptic weights. Note that there is no forgetting when \u03bb = 1.\nThe second term in the RHS member of eq.(2) generically accounts for activitydependent plasticity, i.e. the effects of the pre- and postsynaptic neuron firing\nrates. In our model, this term depends on the history of activities through the\ntime-average of the firing-rate:\n(T )\n\nmi\n\n=\n\n\u03c4\n1X\n(T )\nxi (t) \u2212 di ,\n\u03c4 t=1\n\n(3)\n\nwhere di \u2208 [0, 1] is a threshold that we set to di = 0.10, \u2200i in the present study.\nA neuron i will thus be considered active during learning epoch T whenever\n(T )\n\nmi\n\n> 0 (i.e. whenever its average firing rate has been > 10% of the maximal\n\nvalue), and silent else.\nNote that definition (3) actually encompasses several cases. If \u03c4 = 1, weight\nchanges depend only on the instantaneous firing rates, while if \u03c4 \u226b 1, weight\n7\n\n\fchanges depend on the mean value of the firing rate, averaged over a time\nwindow of duration \u03c4 in the learning epoch. In many aspects the former case\ncan be considered as genuine plasticity, while the latter may be related to\nmeta-plasticity [1]. In this paper, we used \u03c4 = 104 . Finally, weights cannot\nchange their sign. Note however that this setup does not have a significant\nimpact on the present results.\n\n3\n\nResults\n\n3.1 Spontaneous dynamics\n\nWe first present simulation results on the spontaneous dynamics of the system, i.e. the dynamics eq.(1) in the absence of learning. The phase diagrams\nin fig. 1 locate regions in the parameter space for which chaotic dynamics are\nobserved in simulations. Each panel shows the isocurve L1 = 0 (where L1 is\nthe largest Lyapunov exponent) that represents the boundary between chaotic\n(L1 > 0) and non chaotic (L1 < 0) dynamics.\nIt is clear from this figure that chaotic dynamics are found for large parts of\nthe parameter space. Generally speaking, chaotic behaviors disappear when\nthe average weight \u03bcw increases, which may be related to an increase of the\naverage neuron saturation. A more surprising observation is that chaotic dynamics tends to disappear when the gain of the transfer function g is increased.\nThis behavior is in opposition to the behavior observed with classical random\nrecurrent networks with homogeneous neurons (where each neuron has both\nexcitatory and inhibitory projections). In the latter models (and even in related two-populations models, see [14]), chaotic dynamics usually appear for\n8\n\n\fincreasing values of g (see e.g. [11]).\nThis is a very interesting property of the spontaneous dynamics in our model,\nwhose understanding is however out of the scope of the present paper and is\nleft for future work. In the framework of the present study, these phase diagrams mainly allow locating suitable parameters for the initial conditions of\nour networks. We wish the initial dynamics to provide a wide range of possible dynamical regimes, a large (KS) entropy and self-sustaining dynamics. For\nthese reasons, we set our initial dynamics inside the chaotic region, and fix\n\u03bcw = 50, \u03c3w = 1.0, g = 10 and N = 500. The initial weight distribution will\nthus consist in a Gamma distribution with effective average \u22122.67 and s.d.\n0.053 for inhibitory synapses, and 0.89 and 0.018, respectively, for excitatory\nones.\n\n3.2 Structure modifications\n\nIn this section, we study the changes in the network structure induced by the\nlearning rule described by eq.(2).\n\n3.2.1 Adjacency matrix\nThe adjacency matrix of a graph gives information about its connectivity and\ncan be extracted from the weight matrix W by thresholding and binarization.\nWe applied a simple relative thresholding method that consists in keeping only\nthe absolute values of the \u03b8 percent highest weights (again, in absolute value)\nfrom the nonzero connections in W. Hence gradual decrease of \u03b8 enables to\nprogressively isolate the adjacency network formed by the most active weights\nonly. The resulting matrix is then binarized and symmetrized, yielding the\n9\n\n\fadjacency matrix A(\u03b8) whose elements aij (\u03b8) indicate whether i and j are\nconnected by a synapse with a large (> \u03b8) weight (either inhibitory or excitatory), compared to the rest of the network. We limit the range of \u03b8 values\nto ensure that not more that 10% of the neurons get disconnected from the\nnetwork by the thresholding process.\nTo characterize the topology of these matrices, we computed the two main\nquantifiers used in \"complex networks\" approaches, namely the clustering index and the mean shortest path (see [40] for formal definitions). The clustering\nindex C is a statistical quantifier of the network structure and reflects the degree of \"cliquishness\" or local clustering in the network [47]. It expresses the\nprobability that two nodes connected to a third one are also connected together and thus can be interpreted as the density of triangular subgraphs in\nthe network. The mean shortest path (MSP ) is the average, over all nonidentical neurons pairs (i, j), of the smallest number of synapses one must cross\nto reach i from j.\nThese two quantifiers are usually informative only when compared to similar\nmeasures obtained from reference random networks [47]. Here, to build reference networks, we start with the weight matrix at learning epoch T , W (T )\nand rewire it at random but preserving the inhibitory/excitatory nature of\n(T )\n\nthe neurons. Hence for each element Wij , we choose (uniformly) at random\n(T )\n\nanother element Wkl with the same sign, and exchange their values. We then\ncompute the clustering index and mean shortest path of the resulting rewired\nnetwork, and average the obtained values over 15 realizations of the rewiring\nprocess, yielding the reference values Crand (\u03b8) and MSPrand (\u03b8).\n(T )\n\nFigure 2A & B show simulation results for the evolution of C (T ) (\u03b8)/Crand (\u03b8)\n(T )\n\nand MSP (T ) (\u03b8)/MSPrand (\u03b8) during learning. The distribution of the initial\nweights over the network being random, the resulting adjacency matrix A(1) (\u03b8)\n10\n\n\f(1)\n\nis essentially a random network, i.e. one expects C (1) (\u03b8)/Crand (\u03b8) \u2248 1 and\n(1)\n\nMSP (1) (\u03b8)/MSPrand (\u03b8) \u2248 1, \u2200\u03b8. This is confirmed in fig. 2: during the approximately first 100 learning epochs, both network statistics remain around\n1.\nThe situation however changes for longer learning epochs. For T & 100, the\nrelative MSP remains essentially 1 for all thresholds \u03b8 (less than 4% variation, fig. 2B). Hence, the average minimal number of synapses linking any two\nneurons in the network remains low, even when only large synapses are considered. Conversely, the clustering index (fig. 2A) increases at T > 100 for the\nstronger synapses and reaches a stable value that is up to almost two twofold\nthe value found in the reference random networks. Hence, if one considers the\nstrong synapses at long learning epochs, the probability that the neighbors of\na given neuron are themselves interconnected is almost twofold higher than if\nthese strong synapses were laid at random over the network. In other terms,\nthe learning rule yields correlations among the largest synapses at long learning epochs.\nIn the literature related to \"complex networks\", networks with a larger clustering index but a similar MSP with respect to a comparable reference random\nnetwork, are referred to as small-world networks. Hence, the learning rule\neq.(2) organizes strong synapses as a \"small-world\" network.\nEmerging experimental evidence shows that numerous brain anatomical and\nfunctional connectivity networks at several length scales indeed display a common small-world connectivity (for a recent review, see [5]). These include\nquantifications of the physical [37] or functional [8] connectivity of neuronal\nnetworks grown in vitro; quantifications of the anatomical connectivity of\nCaenorhabditis elegans full neural system [47] or, at larger scale, cortico-\n\n11\n\n\fcortical area connectivity maps in macaque, cat [43] and more recently human [23]; and quantitative studies of functional human brain connectivity\nbased on MEG [44], EEG [34] or fMRI data [2,17]. Current hypothesis for the\nfrequent observation of small-world connectivity in real biological networks\nstate that they may result from natural evolution (small-world networks are\ngenerally thought to minimize wiring length while preserving low energy costs\nand high local integration of the neurons [5,28]).\nAn alternative hypothesis could be that small-world networks are emerging\nproperties of neural networks subject to Hebbian learning. In favor of this\npossibility, small-world connectivity has recently been shown to arise spontaneously from spiking neuron networks with STDP plasticity and total connectivity [38] or with correlation-based rewiring [31]. Hence our present findings\ntend to strengthen this hypothesis.\nHowever, these kinds of interpretation should be taken with great care. For\ninstance, it is easy to find learning rules similar to eq.(2) or areas in the parameter space, for which the network, even at long learning times, only slightly\ndeviates from its initial random organization (see e.g. [40]). Hence, emergence\nof small-world connectivity, even in computational models of neural networks\n(i.e. not to speak about real neural networks), may be restricted to certain\nareas of the learning rule parameter space.\nMore importantly, these indicators in fact give no obvious clue about the mutual coupling between global dynamics and the network structure. Hence, in\nour case at least, the classical statistics of the \"complex networks\" do not provide causal explanation for the dynamical effects of learning. For instance, it\ndoes not help understand why dynamics complexity systematically decreases\nduring learning. However, the adjacency matrix is not the only viewpoint from\nwhich the network structure can be observed (see [40] for a discussion). In the\n12\n\n\ffollowing, we examine what information can be obtained if the structure is\nobserved at the level of the Jacobian matrices.\n\n3.2.2 Jacobian matrices.\nDenote by F the function F : IRN \u2192 IRN such that Fi (x) = f (xi ). In our case,\nthe components of the Jacobian matrix of F at x, denoted by DFx are given\nby:\nN\nX\n\u2202Fi\n= f \u2032 ( Wik xk + \u03bei )Wij = f \u2032 (ui )Wij .\n\u2202xj\nk=1\n\n(4)\n\nThus it displays the following specific structure:\nDFx = \u039b(u)W,\n\n(5)\n\n\u039bij (u) = f \u2032 (ui )\u03b4ij .\n\n(6)\n\nwith:\n\nNote that DFx depends on x, contrarily to W. Generally speaking, DFx gives\nthe effects of perturbations at the linear order. To each Jacobian matrix DFx\none can associate a graph, called \"the graph of linear influences\". To build\nthis graph, one draws an oriented link j \u2192 i iff\npositive if\n\n\u2202f (ui )\n\u2202xj\n\n> 0 and negative if\n\n\u2202f (ui )\n\u2202xj\n\n\u2202f (ui )\n\u2202xj\n\n6= 0. The link is\n\n< 0. A detailed presentation of the\n\nproperties of the graph of linear influences can be found in [11,40]. We just\nrecall here that this graph contains circuits or feedback loops. If e is an edge,\nwe denote by o(e) the origin of the edge and t(e) its end. Then a feedback\nloop is a sequence of edges e1 , ..., ek such that o(ei+1 ) = t(ei ), \u2200i = 1...k \u2212 1,\nand t(ek ) = o(e1 ). A feedback loop is said positive (negative) if the product of\nits edges is positive (negative).\nIn general, positive feedback loops are expected to promote fixed-point stability [25] whereas negative loops usually generate oscillations [45,20]. In a model\n13\n\n\fsuch as eq.(1) the weight of a loop k1 , k2 , . . . kn , k1 is given by\n\nQn\n\nl=1\n\nWkl+1 kl f \u2032 (ukl ),\n\nwhere kn+1 = k1 . Therefore, the weight of a loop is the product of a \"topological\" contribution (\n\nQn\n\nl=1\n\nWkl+1 kl ) and a dynamical one (\n\nQn\n\nl=1\n\nf \u2032 (ukl )).\n\nWe measured the evolution of feedback loops during learning via the weightedfraction of positive circuits in the Jacobian matrix, Rn(T ) , that we defined as\nRn(T ) =\n\n\u03c3n+(T )\n+(T )\n\n|\u03c3n\n\n\u2212(T )\n\n| + |\u03c3n\n\n(7)\n\n|\n\nwhere \u03c3n+(T ) (resp. \u03c3n\u2212(T ) ) is the sum of the weights of every positive (resp. negative) feedback loops of length n in the Jacobian network at learning epoch T .\nHence Rn(T ) \u2208 [0, 1]. If its value is > 0.5, the positive feedback loops of length\nn are stronger (in total weight) than the negative ones in the network. We\ncomputed the weighted-fraction of positive feedback loops for length n = 2\n(T )\n\nand n = 3 (i.e. R2\n\n(T )\n\nThe evolutions of R2\n\n(T )\n\nand R3 ).\n(T )\n\nand R3\n\nare presented in fig. 3A. During the first \u2248 20\n\nlearning epochs, the time course of these quantities are highly noisy (and the\ncorresponding standard deviation very large), so that we could not interpret\n(T )\n\nthem conclusively. However, a T \u2248 25 learning epochs, R2\n(1)\n\nues < 0.5 (R2\n\nstabilizes to val-\n\n\u2248 0.47), indicating a slight imbalance in favor of negative\n\nfeedback loops over positive ones. According to the above theoretical considerations, this indicates a trend toward complex oscillatory dynamics. This\nviewpoint may be considered another perspective to explain the initial chaotic\ndynamics. Note however that the initial imbalance in circuits of length-3 is\n(1)\n\nmuch more modest, R3 \u2248 0.497.\n(T )\n\nWhen 25 < T < 50, R2\n\nincreases and converges to \u2248 0.50. A dynamical\n\ninterpretation would be that the corresponding dynamics attractors become\nprogressively less chaotic and more periodic. This is exactly the behavior observed in the simulations (see fig. 5B). Hence in spite of the huge fluctuations\n14\n\n\fobserved at the beginning, the study of the feedback loops in the Jacobian\nmatrix offers a useful interpretation to the reduction of dynamics induced by\nlearning at short learning epochs.\n(T )\n\nUpon further learning, R2\n\n(T )\n\nand R3\n\nremain constant at 0.5 up to T \u2248 100\n\nlearning epochs. Thus, these quantities do not detect variations in the balance\nbetween positive and negative feedback loops for 50 < T < 100. However,\n(T )\n\nat longer times (T > 100), R2\n(T )\n\nreach \u2248 0.62 for R2\n\n(T )\n\nand R3\n\nboth increase abruptly and rapidly\n\n(T )\n\nand \u2248 0.56 for R3 . Hence, at long learning epochs, the\n\nsystem switches to a state where positive feedback loops hold a significantly\nlarger weight as compared to negative ones. Note that the time course of these\nindicators for T > 25 closely follows the time course of the relative clustering\nindex (fig. 2A). The causal relation between these two phenomena is however\nnot obvious.\nBecause of the particular form of the Jacobian matrix in our system, the sign\nof a feedback loop is given by the sign of the weights along it (see above). We\nthus proceeded (fig. 3B) to the computation of the evolution of the weightedfraction for feedback loops computed in W, i.e. we compute here the weight of\na feedback loop e1 , . . . , ek as the product of the synaptic weights of its edges,\nthus independently of the neuron state. The evolution of the weighted-fraction\nof positive feedback loops in W does not account for the initial imbalance observed in the feedback loops of DF. However, its evolution at long times is\nremarkably identical to that measured in DF. Thus, the weighted-fraction of\npositive feedback loops in W is able to account for at least part of the evolution of the dynamics and represents a link between purely structural and\npurely dynamical aspects. However, more information can be extracted by a\nmore dynamical approach.\n\n15\n\n\f3.3 Dynamical perspective\n\nStarting from spontaneous chaotic dynamics, application of the Hebbian learning rule (2) in our sparse two-populations model leads to dynamics simplification, as in the case of completely-connected, one-population random recurrent\nneural networks [13]. Figure 5B shows the network-averaged neuron dynamics\nobtained at different learning epochs. The dynamics, initially chaotic (T = 1),\ngradually settles onto a periodic limit cycle (T = 270), then on a fixed point\nattractor at longer learning epochs (see e.g. T = 290 in this figure). This\nevolution of the global dynamics is a typical example of the reduction of the\nattractor complexity due to the mutual coupling between weight evolution and\nneuron dynamics.\nIn [40], we developed a theoretical approach derived from dynamical systems\nand graph theory and evidenced that it explains this reduction of complexity\nin homogenous (single population) recurrent neural networks. We shall show\nthereafter that it also provides a useful framework for the present model. Below, we first summarize the main results obtained from this mathematical\nanalysis (for details, see [40]).\n\n3.3.1 Main theoretical results\nThe first prediction of our approach is that Hebbian learning rules contract\nthe norm of the weight matrix W. Indeed, we could compute the following\nupper bound:\nkW (T +1) k \u2264 \u03bbT kW (1) k +\n\n\u03b1 1\nC,\nN 1\u2212\u03bb\n\n(8)\n\nwhere kk is the operator norm (induced e.g. by Euclidean norm) and C a\nconstant depending on the details of the rule. Hence the major effect of the\n16\n\n\flearning rule is expected to be an exponentially fast contraction of the norm\n(or equivalently the spectral radius) of the weight matrix, which is due to the\nterm \u03bb, i.e. to passive forgetting (\u03bb < 1).\nThe next prediction concerns the spectral radius of the Jacobian matrix. Indeed, one can derive a bound for the spectral radius of DFx(T ) :\n(T )\n\n(T )\n\n|\u03bc1 (x)| \u2264 max f \u2032 (ui )kW (T ) k.\n\n(9)\n\ni\n\nThis equation predicts a contraction of the spectrum of DFx(T ) that can arise\nvia two effects: either the contraction of the spectrum of W (T ) and/or the\ndecay of maxi f \u2032 (ui ), which arises from saturation in neuron activity. Indeed,\nf \u2032 (ui ) is small when xi is saturated to 0 or 1, but large whenever its synaptic\ninputs are intermediate, i.e. fall into the central part of the sigmoid f (ui ). We\n(T )\n\nemphasize that when \u03bb = 1, W (T ) and u(T ) can diverge and lead maxi f \u2032 (ui )\nto vanish. Hence the spectral radius of the Jacobian matrix can decrease even\n(T )\n\nin the absence of passive forgetting. In all cases, if the initial value of |\u03bc1 (x)|\nis larger than 1, eq.(9) predicts that the spectral radius may decrease down to a\n(T )\n\nvalue < 1. Note that in discrete time dynamical systems the value |\u03bc1 (x)| = 1\nlocates a bifurcation of the dynamical system.\n(T )\n\nAccording to our present setting, the largest Lyapunov exponent, L1 depends\non the learning epoch T . We were able to show that:\n(T )\nL1\n\n\u2264 log(kW\n\n(T )\n\n\u001c\n\n\u2032\n\nk) + log(max f (ui ))\ni\n\n\u001d(T )\n\n,\n\n(10)\n\nwhere hlog(maxi f \u2032 (ui ))i(T ) denotes the time average of log(maxi f \u2032 (ui )), in\nthe learning epoch T (see [40] for formal definitions). The second term in the\nRHS member is related to the saturation of neurons. The first one states that\n(T )\n\nL1\n\nwill decrease if the norm of the weight matrix kW (T ) k decreases during\n\nlearning, resulting in a possible transition from chaotic to simpler attractors.\n17\n\n\f(T )\n\nLet ui (t) =\n\n(T ) (T )\nj=1 Wij xj (t)\n\nPN\n\n+ \u03bei , the local field (or membrane potential)\n\nof neuron i at dynamics step t within learning epoch T . Our theoretical work\nalso showed that provided \u03bb < 1, the vector u = (ui )N\ni=1 converges to a fixed\npoint as T \u2192 +\u221e:\nhui(\u221e) = \u03be + H(\u221e) ,\n\n(11)\n\nwhere:\nH(\u221e) =\n\n\u03b1\n\u0393(\u221e) hxi(\u221e) .\nN (1 \u2212 \u03bb)\n\n(12)\n\nTherefore, the asymptotic local field is predicted to be the sum of the input\npattern plus an additional term H(\u221e) , which accounts for the history of the\nsystem and can be weak or not, depending on the exact learning rule and\nsystem history.\nIn [40], we studied the effects of Hebbian learning in a completely connected\n(pc = 1) one-population network (i.e. where each neuron can project inhibitory\n(negative) and excitatory (positive) synapses) and showed that these analytical arguments explain and describe results of the system simulation with a\nvery good accuracy.\nWhile the model studied in the present work is much more compatible with\nour knowledge of biological neural networks, it is very different from the model\nstudied in [40]. In the present model, the connectivity is (severely) sparse and\nthe neurons are segregated in two distinct groups, with distinct synaptic properties. Furthermore, the learning rule eq.(2) is also more complex. Hence, it\nis not clear whether the above theoretical arguments account for the current\ncase. In particular, these arguments mainly provide upper bounds, whose quality is not guarantied. In the following sections, we present simulation results\nabout the influence of learning on the network dynamics and function, using\nour theoretical framework as an oracle.\n18\n\n\f3.3.2 Dynamics evolution in the sparse 2-populations model.\n(T )\n\nFigure 4 shows the evolution of the spectral radius of W, |s1 | for \u03bb = 0.90 or\n0.99 in simulations of our sparse two-populations model with dynamics eq.(1)\n(T )\n\nand learning rule eq.(2). Let si\n(T )\n\n(T )\n\n(T )\n\n|s1 | \u2265 |s2 | \u2265 * * * \u2265 si\n\nbe the eigenvalues of W (T ) , ordered such that\n(T )\n\n\u2265 . . . . Since |s1 |, the spectral radius of W (T ) , is\n\nsmaller than kW (T ) k one has from eq.(8):\n(T +1)\n\n|s1\n\n| \u2264 \u03bbT kW (1) k +\n\n\u03b1 1\nC.\nN 1\u2212\u03bb\n\n(13)\n\nIt is clear from this figure that in both cases the spectral radius decreases exponentially fast, with a rate that is very close to the prediction of the theory\n(i.e. \u221d \u03bbT ). Hence, the decay predicted by our analytical approach (eq.8) is\nobviously observed in the simulations. Note that the clear trend in the simulation results for a decay proportional to \u03bbT , even tells us that the bound in\n(13) is indeed very good.\n(T )\n\nFigure 7 shows (among other curves) the evolution of |\u03bc1 (x)| (dashed thin\nline). This figure confirms that the theoretical prediction about the decay of\n(T )\n\n|\u03bc1 (x)| (eq.9) is also valid for this model. Hence, eq.(9) opens up the possibility that learning drives the system through bifurcations. This aspect is\nstudied below (section 3.3.3).\nWe now turn to directly study how the attractor complexity changes during learning. This information is provided by the computation of the largest\nLyapunov exponent. Note that another canonical measure of dynamical complexity is the Kolmogorov-Sinai (KS) entropy which is bounded from above by\nthe sum of positive Lyapunov exponents. Therefore, if the largest Lyapunov\n19\n\n\fexponent decreases, the KS entropy decreases as well.\n(T )\n\nFigure 5A shows the evolution of L1\n\nduring numerical simulations with dif(1)\n\nferent values of the passive forgetting rate \u03bb. Its initial value (L1 \u2248 0.94) is\npositive (we start our simulations with chaotic networks). As predicted by our\ntheoretical approach (eq.10), the Hebbian learning rule eq.(2) leads to a rapid\n(T )\n\ndecay of L1 . The decay rate is indeed close to log(kW (T ) k) for intermediate\n(T )\n\nlearning epochs, in agreement with the upper bound of eq.(10). Hence L1\n\nquickly shifts to negative values, confirming the decrease of the dynamical\ncomplexity that could be inferred from visual inspection of fig. 5B.\nOne can also consider individual neuron activities. Figure 6 shows the evolution of the local field u during learning. Clearly, the initial values are random,\nbut the local field (thin gray line) shows a marked tendency to converge to\nthe input pattern (thick dashed line) after as soon as 60 learning epochs. At\nT = 180, the convergence is almost complete. Hence this behavior once again\nconforms to the theoretical predictions eq.(11), with \u03be \u226b H(\u221e) . In the results\npresented in this figure, we pursue the simulation up to T = 200, at which\npoint we remove the pattern from the network, i.e. we set \u03bei = 0, \u2200i (fig. 2D).\nAs a result, u looses its alignment from the pattern and presents a noisy aspect (note that each vector in the figure has been normalized to [0, 1]). This\nbehavior is once again in agreement with the theoretical predictions of eq.(11),\nwhich indicates that hui(\u221e) = H(\u221e) upon pattern removal.\nTo conclude, we have shown here that Hebbian learning in our system leads\nto a decrease of the attractor complexity and entropy that can be induced by\npassive forgetting and/or an increased level of saturation of the neurons. This\ncorresponds in details to the scenario predicted by our mathematical analysis.\n\n20\n\n\f3.3.3 Functional consequences\n\nThe former sections dealt with the effects of Hebbian learning on the structure\nand dynamics of the network. We now turn to its influence on the network\nfunction. The basic function of RRNNs is to learn a specific pattern \u03be. In\nthis framework, a pattern is learned when the complex (or chaotic) dynamics\nof the network settles onto a periodic oscillatory regime (a limit cycle) that\nis specific of the input pattern. This behavior emulates putative mechanisms\nof odor learning in rabbits that have been put forward by physiologists such\nas W. Freeman [18,19]. An important functional aspect is that removal of\nthe learned pattern after learning should lead to a significative change in the\nnetwork dynamics. We now proceed to an analysis of this latter property.\nThe removal of \u03be is expected to change the attractor structure and the average\nvalue of any observable \u03c6 (though with variable amplitude). Call \u2206(T ) [\u03c6] the\nvariation of the (time) average value of \u03c6 induced by pattern removal. If the\nsystem is away from a bifurcation point, removal will result in a variation of\n\u2206(T ) [\u03c6] that remains proportional to \u03be.\nOn the opposite, close to a bifurcation point this variation is typically not\nproportional to \u03be and may lead to drastic changes in the dynamics. From\nthe analysis above, we therefore expect pattern removal to have a maximal\neffect at \"the edge of chaos\", namely when the (average) value of the spectral\nradius of DFx is close to 1. Call \u03bbk and vk the eigenvalues and eigenvectors\nof W (T ) \u039b(u\u2217(T ) ), ordered such that |\u03bbN | \u2264 |\u03bbN \u22121 | \u2264 |\u03bb1 | < 1. In the case\nwhere the dynamics has converged to a stable fixed point u\u2217(T ) (namely, when\n(T )\n\nL1\n\n< 0, see e.g. fig. 5), our theoretical work predicted that:\n\n\u2206(T ) [u] = \u2212\n\nN\nX\n\n(vk , \u03be)\nvk\nk=1 1 \u2212 \u03bbk\n\n21\n\n(14)\n\n\fwhere ( , ) denotes the inner product. As a matter of fact, the RHS term\ndiverges if \u03bb1 = 1 and if (v1 , \u03be) 6= 0. From this analysis, we therefore expect\npattern removal to have a maximal effect at \"the edge of chaos\", namely when\nthe value of the spectral radius of DFx is close to 1.\nTo study the effects of pattern removal in our model, we monitored the quantity:\n\u2206(T ) [\u039b] =\n\n1\nN\n\nv\nuN \u0010\nuX\nt\nh\u039b\n\n(T )\nii (u)i\n\ni=1\n\n\u2212 h\u039bii (u\u2032 )i(T )\n\n\u00112\n\n(15)\n\nthat measures how neuron excitability is modified when the pattern is removed. The evolution of \u2206(T ) [\u039b] during learning with rule eq.(2) is shown on\nfig. 7 (thick full lines) for two values of the passive forgetting rate \u03bb. \u2206(T ) [\u039b]\nis found to increase to a plateau, and vanishes afterwards. Interestingly, comparison with the decay of the leading eigenvalue of the Jacobian matrix, \u03bc1\n(thin full lines) shows that the maximal values of \u2206(T ) [\u039b] are obtained when\n|\u03bc1 | is close to 1 and the largest Lyapunov exponent L1 close to 0.\nHence, these numerical simulations are in agreement with the theoretical predictions that Hebbian learning drives the global dynamics through a bifurcation,\nin the neighborhood of which sensitivity to the input pattern is maximal. Note\nthat this property is obtained at the frontier where the chaotic strange attractor begins to destabilize (|\u03bc1 | = 1), hence at the so-called \"edge of chaos\". This\nparticular dynamical regime, at the frontier between order (periodical or fixed\npoint regimes) and disorder (chaos), has already be reported to be particularly\nsuitable for recurrent neural networks, especially when computational power\nis considered [42,7]. The present results show that it is the optimal regime for\nthe sensibility to the input pattern in our model. Whether this also implies\nimproved or optimal computational performance remains however to be tested\nand will be the subject of future works.\n22\n\n\fIt must finally be noticed that our theory predicts that pattern sensitivity\nshould be maximal when |\u03bc1 | is close to one. But several aspects of our simulation results are not accounted for by this theory. For instance, fig. 7 shows\nthat |\u03bc1| approaches 1 at several learning epochs. This is related to the \"Arnold\ntongue\" structure of the route to chaos. However, pattern sensibility is maximal only for the last episode, and almost zero for the former ones. This\nbehavior is still unclear and will be the subject of future works.\n\n4\n\nConclusion and future works\n\nTo conclude, we have shown in this work that Hebbian learning eq.(2) has\nimportant effects on the dynamics and structure of a sparse two-populations\nRRNN. The forgetting part of the learning rule contracts the norm of the\nweight matrix. This effect, together with an increase in the average saturation\nlevel of the neurons, yields a rapid decay of the dynamics complexity and entropy. In other words, the network forgets its initial synaptic structure and is\nrewired by Hebbian learning into a new synaptic structure that emerges with\nlearning and that depends on the whole history of the neuron dynamics. We\nhave shown that the strongest synapses organize within this emerging structure as a small-world connectivity. The second effect of the decrease of the\nweight matrix and of the increased neuron saturation consists in a rapid contraction of the spectral radius of the Jacobian matrix. This leads the system\nto the edge of chaos, where sensitivity to the input pattern is maximal. This\nscenario is remarkably predicted by the theoretical arguments we developed\nin [40].\n23\n\n\fIn the presented simulations, most of the effects are mediated by the passive\nforgetting term. We believe that this term is not unrealistic from a biological\npoint of view. Indeed, synaptic plasticity at the single synapse level is not permanent and some studied reported durations of 20 mn [46] or even 20 sec [10].\nThis would be accounted for in our model by \u03bb \u226a 1.\nNevertheless, most studies about long-term plasticity have evidenced longer\ncellular memory time constants, ranging from hours to days [24,36,15], which\nwould correspond in our model to higher \u03bb values. Note however that according\nto our mathematical analysis, most of the effects reported here are expected to\noccur even without passive forgetting (i.e. with \u03bb = 1), provided the learning\nrule increases the average saturation of the neurons. In previous studies, we\nhave considered such Hebbian learning rules devoid of passive forgetting but\nprovoking increasing average saturation levels of the neurons. Numerical simulations have clearly evidenced a reduction of the attractor complexity during\nlearning, in agreement with this suggestion [6,39].\nFuture works will focus on the study of more detailed biological learning\nrules (heterosynaptic LTD, synaptic rescaling). We will also consider activitydependent synaptic turnover (pruning/sprouting). Indeed albeit an overlooked\nphenomena for several decades, synaptic (or at least dendritic) turnover is now\nrecognized as an important part of cortical networks, even in the adult (see\ne.g. [26]). Finally, one important problem with the application of RRNNs as\nartificial neural networks, is that it is very difficult to determine when to stop\nthe learning process. Our results show that the effect of an input pattern is\nmaximal at those learning epochs when the system is close to a bifurcation,\nbut much more modest for shorter and longer learning times. One interesting\ndevelopment would thus consist in trying to find learning rules or settings\nthat would guaranty that the system remains close to the edge of chaos, even\n24\n\n\fat long learning times. As an attractive possibility, the plasticity of intrinsic\nproperties [12] could allow the network to stabilize its activity in this region.\n\nAcknowledgments\n\nThis work was supported by a grant of the French National Research Agency,\nproject JC05 63935 \"ASTICO\".\n\nReferences\n\n[1] W. C. Abraham and M. F. Bear. Metaplasticity: the plasticity of synaptic\nplasticity. Trends Neurosci., 19:126\u2013130, 1996.\n[2] S. Achard, R. Salvador, B. Whitcher, J. Suckling, and E. Bullmore.\n\nA\n\nresilient, low-frequency, small-world human brain functional network with\nhighly connected association cortical hubs. J. Neurosci., 26:63\u201372, 2006.\n[3] F. Atay, T. Biyikouglu, and J. Jost. Network synchronization : Spectral versus\nstatistical properties. Physica D, 224:35\u201341, 2006.\n[4] M. Barahona and L. Pecora. Synchronization in small-world systems. Phys.\nRev. Lett., 89:054101, 2002.\n[5] D. Bassett and E. Bullmore. Small-world brain networks. The Neuroscientist,\n12:512\u2013523, 2006.\n[6] H. Berry and M. Quoy. Structure and dynamics of random recurrent neural\nnetworks. Adaptive Behavior, 14:129\u2013137, 2006.\n[7] N. Bertschinger and T. Natschlager. Real-Time Computation at the Edge of\nChaos in Recurrent Neural Networks. Neural Comp., 16:1413\u20131436, 2004.\n\n25\n\n\f[8] L. Bettencourt, G. Stephens, M. Ham, and G. Gross. Functional structure of\ncortical neuronal networks grown in vitro. Phys. Rev. E, 75:021915, 2007.\n[9] S. Boccaletti, V. Latora, Y. Moreno, M. Chavez, and D. U. Hwang. Complex\nnetworks : Structure and dynamics. Physics Reports, 424:175\u2013308, 2006.\n[10] D. Brager, X. Cai, and S. Thompson.\n\nActivity-dependent activation of\n\npresynaptic protein kinase c mediates post-tetanic potentiation.\n\nNature\n\nNeurosci., 6:551\u2013552, 2003.\n[11] B. Cessac and M. Samuelides. From neuron to neural networks dynamics. EPJ\nSpecial topics: Topics in Dynamical Neural Networks, 142(1):7\u201388, 2007.\n[12] G. Daoudal and D. Debanne. Long-Term Plasticity of Intrinsic Excitability:\nLearning Rules and Mechanisms. Learn. Mem., 10:456\u2013465, 2003.\n[13] E. Dauce, M. Quoy, B. Cessac, B. Doyon, and M. Samuelides. Self-organization\nand dynamics reduction in recurrent networks: stimulus presentation and\nlearning. Neural Networks, 11:521\u2013533, 1998.\n[14] E. Dauc\u00e9, M. Quoy, and B. Doyon. Resonant spatio-temporal learning in large\nrandom neural networks. Biol. Cybern., 87:185\u2013198, 2002.\n[15] V. Doyere, M. Errington, S. Laroche, and T. Bliss. Low-frequency trains of\npaired stimuli induce long-term depression in area ca1 but not in dentate gyrus\nof the intact rat. Hippocampus, 6:52\u201357, 1996.\n[16] B. Doyon, B. Cessac, M. Quoy, and M. Samuelides. Chaos in neural networks\nwith random connectivity. Int. Journ. of Bif. and Chaos, 3(2):279\u2013291, 1993.\n[17] V. Eguiluz, D. Chialvo, G. Cecchi, and A. Apkarian. Scale-free brain functional\nnetworks. Physical Review Letters, 94:018102, 2005.\n[18] W. Freeman. Simulation of chaotic eeg pattern with a dynamic model of the\nolfactory system. Biol. Cyber., 56:139\u2013150, 1987.\n\n26\n\n\f[19] W. Freeman, Y. Yao, and B. Burke. Central pattern generating and recognizing\nin olfactory bulb: a correlation learning rule. Neur. Networks, 1:277\u2013288, 1988.\n[20] J. Gouz\u00e9. Positive and negative circuits in dynamical systems. Journ. Biol.\nSyst., 6(1):11\u201315, 1998.\n[21] G. Grinstein and R. Linsker. Synchronous neural activity in scale-free network\nmodels versus random network models. PNAS, 28(102):9948\u20139953, 2005.\n[22] H. Hasegawa. Synchronisations in small-world networks of spiking neurons :\nDiffusive versus sigmoid couplings. Phys. Rev. E., 72:056139, 2005.\n[23] Y. He, Z. Chen, and A. Evans. Small-world anatomical networks in the human\nbrain revealed by cortical thickness from mri. Cerebral Cortex, 2007. Advance\naccess published online January 4.\n[24] A. Heynen, E. Quinlan, D. Bae, and M. Bear. Bidirectional, activity-dependent\nregulation of glutamate receptors in the adult hippocampus in vivo. Neuron,\n28:527\u2013536, 2000.\n[25] M. Hirsch. Convergent activation dynamics in continuous time networks. Neur.\nNetworks, 2:331\u2013349, 1989.\n[26] A. Holtmaat, J. Trachtenberg, L. Wilbrecht, G. Shepherd, X. Zhang, G. Knott,\nand K. Svoboda. Transient and persistent dendritic spines in the neocortex in\nvivo. Neuron, 45:279\u2013291, 2005.\n[27] H. Hong, B. Kim, M. Choi, and H. Park.\n\nFactors that predict better\n\nsynchronizability on complex networks. Phys. Rev. E, 65:067105, 2002.\n[28] M. Kaiser and C. Hilgetag.\n\nNonoptimal component placement, but short\n\nprocessing paths, due to long-distance projections in neural systems. PLoS\nComput. Biol., 2:e95, 2006.\n\n27\n\n\f[29] N. Kalisman, G. Silberberg, and H. Markram. The neocortical microcircuit as\na tabula rasa. Proc. Natl. Acad. Sci. USA, 102:880\u2013885, 2005.\n[30] E. Kandel, J. Schwartz, and T. Jessell. Principles of Neural Science, chapter 17,\npages 317\u2013336. McGraw-Hill Professional, 4th edition, 2000.\n[31] H. F. Kwok, P. Jurica, A. Raffone, and C. van Leeuwen. Robust emergence of\nsmall-world structure in networks of spiking neurons. Cogn Neurodyn, 1:39\u201351,\n2007.\n[32] L. F. Lago-Fern\u00e1ndez, R. Huerta, F. Corbacho, and J. A. Sig\u00fcenza.\n\nFast\n\nresponse and temporal coherent oscillations in small-world networks. Phys.\nRev. Lett., 84:2758\u20132761, 200.\n[33] H. Markram, J. L\u00fcbke, M. Frotscher, A. Roth, and B. Sakmann. Physiology\nand anatomy of synaptic connections between thick tufted pyramidal neurones\nin the developing rat neocortex. J. Physiol., 500:409\u2013440, 1997.\n[34] S. Micheloyannis, E. Pachou, C. Stam, M. Vourkas, S. Erimaki, and V. Tsirka.\nUsing graph theoretical analysis of multi channel eeg to evaluate the neural\nefficiency hypothesis. Neurosci. Lett, 402:273\u2013277, 2006.\n[35] T. Nishikawa, A. E. Motter, Y. C. Lai, and F. C. Hoppensteadt. Heterogeneity\nin oscillator networks : are smaller worlds easier to synchronize ? Phys. Rev.\nLett., 91, 2003.\n[36] R. Racine, N. Milgram, and S. Hafner. Long-term potentiation phenomena in\nthe rat limbic forebrain. Brain Res., 260:217\u2013231, 1983.\n[37] O. Shefi, I. Golding, R. Segev, E. Ben-Jacob, and A. Ayali. Morphological\ncharacterization of in vitro neuronal networks. Phys. Rev. E, 66:021905, 2002.\n[38] C. W. Shin and S. Kim. Self-organized criticality and scale-free properties in\nemergent functional neural networks. Phys. Rev. E, 74:045101, 2006.\n\n28\n\n\f[39] B. Siri, H. Berry, B. Cessac, B. Delord, and M. Quoy.\n\nTopological and\n\ndynamical structures induced by hebbian learning in random neural networks.\nIn International Conference on Complex Systems, Boston, june 2006.\n[40] B. Siri, H. Berry, B. Cessac, B. Delord, and M. Quoy. A mathematical analysis\nof the effects of hebbian learning rules on the dynamics and structure of discretetime random recurrent neural networks. 2007. e-print: arXiv:0705.3690v1.\n[41] C. Skarda and W. Freeman. How brains make chaos in order to mahe sense of\nthe world. Behavioral and Brain Sciences, 10:161\u2013195, 1987.\n[42] H. Soula, A. Alwan, and G. Beslon. Learning at the edge of chaos: Temporal\ncoupling of spiking neurons controller for autonomous robotics. In AAAI Spring\nSymposium on Developmental Robotics, Stanford, CA, USA, March 2005.\n[43] O. Sporns and J. Zwi. The small world of the cerebral cortex. Neuroinformatics,\n2:145\u2013162, 2004.\n[44] C. Stam. Functional connectivity patterns of human magnetoencephalographic\nrecordings: a 'small-world' network? Neurosci. Lett, 355:25\u201328, 2004.\n[45] R. Thomas.\n\nOn the relation between the logical structure of systems and\n\ntheir ability to generate multiple steady states or sustained oscillations, chapter\nNumerical methods in the study of critical phenomena, pages 180\u2013193. SpringerVerlag in Synergetics, 1981.\n[46] A. Volianskis and M. Jensen.\n\nTransient and sustained types of long-term\n\npotentiation in the ca1 area of the rat hippocampus. J. Physiol., 550:459\u2013492,\n2003.\n[47] D. Watts and S. Strogatz. Collective dynamics of \"small-world\" networks.\nNature, 393:440\u2013442, 1998.\n\n29\n\n\fA\n\nB\n\n12\n10\n\n1.5\n\nNon Chaotic\n\ng\n\n\u03c3w\n\n8\n6\n\n2.0\n\nNon Chaotic\n\nChaotic\n1.0\n\nChaotic\n0.5\n\n4\n2\n0\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n0\n\n\u03bcw\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n\u03bcw\n\nFigure 1. Phase diagram for the spontaneous dynamics eq.(1). The full line represents the boundary between chaotic and non chaotic dynamics (i.e. the isocurve\nL1 = 0 where L1 is the largest Lyapunov exponent). Shown are projection in (A)\nthe (g, \u03bcw ) plan with \u03c3w = 1.0 or (B ) the (\u03c3w , \u03bcw ) parameter plan with g = 10.0.\nOther parameters were: \u03bei = 0.0 \u2200i = 1 . . . N , pc = 0.15, pI = 0.25 and N = 500.\n\n30\n\n\fA\n\n2.0\n\nB\nMSP/MSPrand\n\nC/Crand\n\n1.8\n1.6\n1.4\n1.2\n1.0\n\n1.04\n\n1.02\n\n1.00\n\n0.98\n0\n\n50\n\n100\n\n150\n\n0\n\n200\n\n50\n\n100\n\n150\n\n200\n\nLearning epoch T\n\nLearning epoch T\n\nFigure 2. Evolution of the normalized structural statistics during learning with\nrule eq.(2). Values are averages over 20 different realizations of the network (random initial firing rates and synaptic weights). The values of the threshold \u03b8 are,\nfrom bottom to top in each panel, 100%, 87%, 73%, 60% and 47%. (A) Nor(T )\n\nmalized clustering index C (T ) (\u03b8)/Crand (\u03b8). (B ) Normalized mean-shortest path\n(T )\n\nM SP (T ) (\u03b8)/M SPrand (\u03b8). Bars are \u00b11 standard deviation. Other parameters were:\n\u03bb = 0.90, \u03b1 = 5 \u00d7 10\u22123 , g = 10, \u03bei = 0.010 sin (2\u03c0i/N ) cos (8\u03c0i/N ) \u2200i = 1 . . . N ,\n\u03bcw = 50, \u03c3w = 1.0 and N = 500.\n\n31\n\n\f0.8\n\nA\n\nW\n\n0.7\n\n0.7\n\n0.6\n\n0.6\n\nRnT\n\nRnT\n\n0.8\n\nB\n\nDF\n\n0.5\n\nn=2\nn=3\n\n0.5\nn= 2\nn= 3\n\n0.4\n0\n\n50\n\n100\n\n150\n\n0.4\n200\n\n0\n\nLearning epoch T\n\n50\n\n100\n\n150\n\nLearning epoch T\n(T )\n\nFigure 3. Evolution of the weighted-fraction of positive feedback loops Rn for loops\nin DF (A) and W (B) and circuit length n = 2 (thick line) and n = 3 (dotted line).\nValues are averages over 20 different networks using \u03bb = 0.90. Standard deviations\nare omitted for readability purpose. See text for definitions. All other parameters\nas in fig. 2.\n\n32\n\n200\n\n\f1\n\nspectral radius | s1 |\n\n10\n\n0\n\n10\n\n-1\n\n10\n\n-2\n\n10\n\n-3\n\n10\n\n0\n\n200\n\n400\n\n600\n\n800\n\n1000\n\nLearning epoch T\nFigure 4. Contraction of the spectral radius of W. The evolution during learning of\n(T )\n\nthe norm of W largest eigenvalue, |s1 | (thick lines) is plotted on a log-lin scale for\n\u03bb = 0.90 (bottom) or 0.99 (top). Each curve is an average over 20 realizations with\ndifferent initial conditions (initial weights and neuron states). For clarity, standard\ndeviations are omitted but are always < 20% of the average. Dashed thin lines are\nplots of exponential decreases with equation g(T ) \u221d \u03bbT . All other parameters as in\nfig. 2.\n\n33\n\n\f2\n\nLargest Lyap. Exp. L1\n\nA\n\n0\n\n-2\n\n-4\n\n-6\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n900\n\n1000\n\nLearning epoch T\n\nB\n\n290\n\n<x(t)>\n\n270\n\n1\n\n0\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\nDynamics time steps t\nFigure 5. Reduction of the dynamics complexity from chaotic to periodic and\nfixed point. (A) Evolution of the largest Lyapunov exponent L1 (full thick lines)\nfor \u03bb = 0.90 (bottom) or 0.99 (top). Each value is an average over 20 realizations with different initial conditions (initial weights and neuron states). The thin\ndashed lines illustrate decays as g(T ) \u221d T log(\u03bb). (B ) Examples of network dynamics when learning is stopped at (from bottom to top) T = 1 (initial conditions), 270 or 290 and for \u03bb = 0.99. These curves show the network-averaged state\nP\n(T )\nx(T ) (t) = 1/N N\ni=1 xi (t) and are shifted along the y-axis for readability. The\nheight of the vertical black bar represents an amplitude of 0.1. All other parameters\n\nare as in fig. 2.\n\n34\n\n\fA\n\nT=1\n\n1.0\n\nB\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.0\n0\n\n100\n\n200\n\n300\n\n400\n\nT=60\n\n1.0\n\n0.0\n\n500\n\n0\n\n100\n\nNeuron #\n\nC\n\nD\n\nT=180\n\n1.0\n\n200\n\n300\n\n400\n\n500\n\nNeuron #\nT =200; No pattern\n\n1.0\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.0\n\n0.0\n0\n\n100\n\n200\n\n300\n\n400\n\n0\n\n500\n\n100\n\n200\n\n300\n\n400\n\n500\n\nNeuron #\n\nNeuron #\n\nFigure 6. Alignment of the local field u = Wx+\u03be (thin gray line) with the input pattern \u03be (thick dashed line). Snapshot are presented at T = 1 (A, initial conditions),\nT = 60 (B ), T = 180 (C ) and T = 200 with pattern removed (D ) learning epochs.\nEach curve plots averages over 20 realizations (standard deviations are omitted for\ncomparison purposes), and every vector has been normalized to [0, 1] for clarity.\n\u03bb = 0.90 and all other parameters as in fig. 2\n\n35\n\n\fA\n\n5.0\n\nB5\n\n\u03bb = 0.90\n\u2206\n| \u03bc1 |\n1+L1\n\n4.0\n3.0\n\n\u03bb = 0.99\n\u2206\n| \u03bc1 |\n1+L1\n\n4\n3\n\n2.0\n\n2\n\n1.0\n\n1\n\n0.0\n\n0\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n0\n\nLearning epoch T\n\n200\n\n400\n\n600\n\n800\n\n1000\n\nLearning epoch T\n\nFigure 7. Network sensitivity to the input pattern is maximal close to a bifurca(T )\n\ntion. The evolution of the average value of the spectral radius of DFx\n\n(thin full\n\nline) is plotted together with the sensitivity measure \u2206(T ) [\u039b] (thick full line) for\n\u03bb = 0.90 (A) or 0.99 (B ). The panels also display the corresponding evolution of\nthe largest Lyapunov exponent L1 , plotted as 1.0 + L1 for obvious comparison purpose (thin dashed line). The horizontal dashed-dotted lines locates y = 1. The values\nof \u2206(T ) [\u039b] are normalized to the [0, 1] range for comparison purposes. Each value\nis an average over 20 realizations (standard deviations are omitted for clarity). All\nother parameters were as in fig. 2\n\n36\n\n\f"}