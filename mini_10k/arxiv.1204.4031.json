{"id": "http://arxiv.org/abs/1204.4031v1", "guidislink": true, "updated": "2012-04-18T10:09:54Z", "updated_parsed": [2012, 4, 18, 10, 9, 54, 2, 109, 0], "published": "2012-04-18T10:09:54Z", "published_parsed": [2012, 4, 18, 10, 9, 54, 2, 109, 0], "title": "Approximately Optimal Auctions for Selling Privacy when Costs are\n  Correlated with Data", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1204.1030%2C1204.1245%2C1204.0466%2C1204.3742%2C1204.3374%2C1204.0301%2C1204.6195%2C1204.4514%2C1204.3785%2C1204.1744%2C1204.6411%2C1204.0440%2C1204.3095%2C1204.5903%2C1204.5099%2C1204.1926%2C1204.3000%2C1204.2901%2C1204.6574%2C1204.3829%2C1204.1134%2C1204.2562%2C1204.2085%2C1204.1677%2C1204.4126%2C1204.0059%2C1204.3285%2C1204.2187%2C1204.5316%2C1204.6136%2C1204.5836%2C1204.1659%2C1204.0150%2C1204.6285%2C1204.2338%2C1204.1930%2C1204.4878%2C1204.4315%2C1204.4252%2C1204.1909%2C1204.4839%2C1204.1983%2C1204.0159%2C1204.1198%2C1204.1555%2C1204.6423%2C1204.4518%2C1204.2362%2C1204.3093%2C1204.3508%2C1204.2025%2C1204.2849%2C1204.6392%2C1204.3015%2C1204.3977%2C1204.4094%2C1204.4031%2C1204.1459%2C1204.0868%2C1204.6733%2C1204.2890%2C1204.1326%2C1204.2428%2C1204.1329%2C1204.0309%2C1204.3590%2C1204.1502%2C1204.2867%2C1204.0529%2C1204.2981%2C1204.0505%2C1204.1675%2C1204.1389%2C1204.5248%2C1204.5798%2C1204.1327%2C1204.4526%2C1204.3298%2C1204.0174%2C1204.3380%2C1204.1195%2C1204.0383%2C1204.2257%2C1204.2098%2C1204.3888%2C1204.2791%2C1204.2774%2C1204.2105%2C1204.6536%2C1204.5988%2C1204.3323%2C1204.6334%2C1204.6707%2C1204.5953%2C1204.5207%2C1204.3061%2C1204.0945%2C1204.4951%2C1204.2251%2C1204.0030%2C1204.3129&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Approximately Optimal Auctions for Selling Privacy when Costs are\n  Correlated with Data"}, "summary": "We consider a scenario in which a database stores sensitive data of users and\nan analyst wants to estimate statistics of the data. The users may suffer a\ncost when their data are used in which case they should be compensated. The\nanalyst wishes to get an accurate estimate, while the users want to maximize\ntheir utility. We want to design a mechanism that can estimate statistics\naccurately without compromising users' privacy.\n  Since users' costs and sensitive data may be correlated, it is important to\nprotect the privacy of both data and cost. We model this correlation by\nassuming that a user's unknown sensitive data determines a distribution from a\nset of publicly known distributions and a user's cost is drawn from that\ndistribution. We propose a stronger model of privacy preserving mechanism where\nusers are compensated whenever they reveal information about their data to the\nmechanism. In this model, we design a Bayesian incentive compatible and privacy\npreserving mechanism that guarantees accuracy and protects the privacy of both\ncost and data.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1204.1030%2C1204.1245%2C1204.0466%2C1204.3742%2C1204.3374%2C1204.0301%2C1204.6195%2C1204.4514%2C1204.3785%2C1204.1744%2C1204.6411%2C1204.0440%2C1204.3095%2C1204.5903%2C1204.5099%2C1204.1926%2C1204.3000%2C1204.2901%2C1204.6574%2C1204.3829%2C1204.1134%2C1204.2562%2C1204.2085%2C1204.1677%2C1204.4126%2C1204.0059%2C1204.3285%2C1204.2187%2C1204.5316%2C1204.6136%2C1204.5836%2C1204.1659%2C1204.0150%2C1204.6285%2C1204.2338%2C1204.1930%2C1204.4878%2C1204.4315%2C1204.4252%2C1204.1909%2C1204.4839%2C1204.1983%2C1204.0159%2C1204.1198%2C1204.1555%2C1204.6423%2C1204.4518%2C1204.2362%2C1204.3093%2C1204.3508%2C1204.2025%2C1204.2849%2C1204.6392%2C1204.3015%2C1204.3977%2C1204.4094%2C1204.4031%2C1204.1459%2C1204.0868%2C1204.6733%2C1204.2890%2C1204.1326%2C1204.2428%2C1204.1329%2C1204.0309%2C1204.3590%2C1204.1502%2C1204.2867%2C1204.0529%2C1204.2981%2C1204.0505%2C1204.1675%2C1204.1389%2C1204.5248%2C1204.5798%2C1204.1327%2C1204.4526%2C1204.3298%2C1204.0174%2C1204.3380%2C1204.1195%2C1204.0383%2C1204.2257%2C1204.2098%2C1204.3888%2C1204.2791%2C1204.2774%2C1204.2105%2C1204.6536%2C1204.5988%2C1204.3323%2C1204.6334%2C1204.6707%2C1204.5953%2C1204.5207%2C1204.3061%2C1204.0945%2C1204.4951%2C1204.2251%2C1204.0030%2C1204.3129&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider a scenario in which a database stores sensitive data of users and\nan analyst wants to estimate statistics of the data. The users may suffer a\ncost when their data are used in which case they should be compensated. The\nanalyst wishes to get an accurate estimate, while the users want to maximize\ntheir utility. We want to design a mechanism that can estimate statistics\naccurately without compromising users' privacy.\n  Since users' costs and sensitive data may be correlated, it is important to\nprotect the privacy of both data and cost. We model this correlation by\nassuming that a user's unknown sensitive data determines a distribution from a\nset of publicly known distributions and a user's cost is drawn from that\ndistribution. We propose a stronger model of privacy preserving mechanism where\nusers are compensated whenever they reveal information about their data to the\nmechanism. In this model, we design a Bayesian incentive compatible and privacy\npreserving mechanism that guarantees accuracy and protects the privacy of both\ncost and data."}, "authors": ["Lisa Fleischer", "Yu-Han Lyu"], "author_detail": {"name": "Yu-Han Lyu"}, "author": "Yu-Han Lyu", "links": [{"href": "http://arxiv.org/abs/1204.4031v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1204.4031v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1204.4031v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1204.4031v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Approximately Optimal Auctions for Selling Privacy\nwhen Costs are Correlated with Data\u2217\nLisa Fleischer and Yu-Han Lyu\n\narXiv:1204.4031v1 [cs.GT] 18 Apr 2012\n\nDepartment of Computer Science\nDartmouth\n\nApril 19, 2012\n\nAbstract\nWe consider a scenario in which a database stores sensitive data of users and an analyst wants to\nestimate statistics of the data. The users may suffer a cost when their data are used in which case\nthey should be compensated. The analyst wishes to get an accurate estimate, while the users want to\nmaximize their utility. We want to design a mechanism that can estimate statistics accurately without\ncompromising users' privacy.\nSince users' costs and sensitive data may be correlated, it is important to protect the privacy of both\ndata and cost. We model this correlation by assuming that a user's unknown sensitive data determines a\ndistribution from a set of publicly known distributions and a user's cost is drawn from that distribution.\nWe propose a stronger model of privacy preserving mechanism where users are compensated whenever\nthey reveal information about their data to the mechanism. In this model, we design a Bayesian incentive\ncompatible and privacy preserving mechanism that guarantees accuracy and protects the privacy of both\ncost and data.\n\n\u2217\n\nE-mail: {lkf,yuhanlyu}@cs.dartmouth.edu. Partially supported by NSF grants CCF-0728869 and CCF-1016778.\n\n\f1 Introduction\nUsing the Internet, it is fairly easy to collect sensitive personal data. Online service providers implicitly\ncompensate users who provide their personal data, by offering improved services based on their data. However, this implicit exchange may not be fair to the individual, since different people may have different costs\n- a loss in expected utility over future events - for use of their data. Moreover, companies rarely give\nwell-defined guarantees concerning data privacy and compensation. When the compensation is less than the\nindividual's perceived cost, the individual may choose not to participate. Here, we explore mechanisms to\nfairly compensate individuals for use of their personal data.\nIn order to motivate users to participate in a mechanism, the payment to a user should be at least the cost\nto the user. Thus, the mechanism should learn information about users' costs. Ghosh and Roth [8] initiate a\nstudy of this problem. Their mechanism asks users to report their costs for the use of their data to estimate\nstatistics, and then selects some of the users (based on their stated costs) to determine the statistics, and pays\nthese users accordingly. This mechanism is problematic when costs and personal data are correlated, since\nusers may be reluctant to reveal their costs if they are not guaranteed adequate compensation up front. For\nexample, suppose that a database indicates whether a vehicle has been damaged. When the database can\nbe publicly accessed, the owner of a damaged car cannot sell the car for the same price as the price of an\nundamaged car. Thus, his cost for revealing data is higher than the owner of an undamaged car. Revealing\ninformation about the costs may also reveal information about whether the car is damaged. Thus, it is\nimportant to also guarantee privacy of individual payments.\nWe study this problem where costs are correlated with data. We model this correlation by assuming that\na user's unknown data determines a distribution from a set of accurate and publicly known distributions and\nthe user's cost is drawn from that distribution. We propose a model of a privacy preserving mechanism where\nusers are compensated whenever they reveal any information about their data to the mechanism, whether\ndirectly, or indirectly by revealing their costs. In this model, we design a Bayesian incentive compatible\nand individually rational mechanism, which produces accurate statistics and protects the privacy of data and\ncosts.\nProblem Setting. There are n users, which we call players, denoted by [n]. Each player has sensitive data\nDi \u2208 [h], stored in a database D \u2208 [h]n . Initially Di is the private information of player i. However, since\nDi is also in the database, it's value may be verified with player i's permission. In addition, player i has a\nvalue for his loss of privacy of his data. This value vi is private to player i, but it is correlated with Di . This\ncorrelation is modeled as follows: If Di = t \u2208 [h] then vi \u223c Ft , where Ft is a distribution of privacy costs\nfor players of type t that is known to all players and the mechanism. Ft correctly represents the distributions\nof costs of type t players.\nA query is a function Q : [h]n \u2192 R, mapping a database to a response. An example of a query is \"what\nis the number of people i in the database D with Di = j?\". A data analyst wants Q(D). Since the data are\nsensitive, the data analyst accesses the database through a privacy preserving algorithm A. Therefore, the\ndata analyst does not receive Q(D) but receives an estimate A(D). To ensure the estimate is accurate, the\nerror |Q(D) \u2212 A(D)| should be small with high probability.\nDifferential privacy, introduced in [5], is an accepted way to measure privacy and privacy preserving\nalgorithms. Two databases D and D \u2032 are adjacent if they differ in only one entry. An algorithm A satisfies\n\u01eb-differential privacy, where \u01eb > 0, if for any pair of adjacent database D and D \u2032 and any set I \u2286 R,\nPr[A(D) \u2208 I] \u2264 e\u01eb Pr[A(D \u2032 ) \u2208 I]. When \u01eb = 0, it implies that the algorithm does not depend on D. If the\nerror |Q(D) \u2212 A(D)| is small with high probability, then the algorithm should have large \u01eb. Thus, privacy\nguarantees come at the expense of the accuracy.\nAlthough an \u01eb-differentially private algorithm can protect sensitive data, if a player allows his data to be\n\n1\n\n\fused, he may incur a cost. We model this cost as linear in the privacy loss \u01eb and his expected cost vi .1 Thus,\nfor player i to agree to the use of his data, his expected payment should be at least \u01ebvi .\nA mechanism specifies a set of actions that players can take. The players take actions based on their\ndata and private costs. Thus, the input of the mechanism is a database and a vector of actions. The outputs\nare an estimate \u015d and a payment vector p = (p1 , . . . , pn ). Since player i has a linear cost \u01ebvi , the utility of\nplayer i is pi \u2212 \u01ebvi if Di is used in the mechanism, otherwise the utility is pi . We assume that all players are\nrational and want to maximize their utilities. A mechanism is a direct mechanism if the action set equals the\nset of all real numbers. That is, a direct mechanism asks players to report their costs. A direct mechanism\nis truthful if every player reports his true cost in order to maximize his utility. Truth telling is a concept\ndefined for direct mechanisms. In this paper, we propose an indirect mechanism. Thus, we want to extend\nthe notion of truthfulness to indirect mechanisms. In our mechanism, there is a straightforward mapping,\ndescribed in Section 3, from player's type set to player's action set. We say that a player decides truthfully\nif he picks the strategy corresponding to his type under this mapping.\nIn our paper, we will assume that the query/goal of the analyst is to estimate nj = |{i : Di = j}|.\nWithout loss of generality, we assume throughout the paper that the data analyst wants to estimate n1 . We\nseek to design a mechanism with the following properties.\n1. Accuracy: A mechanism M is k-accurate, if for any database D, Pr[|\u015d \u2212 n1 | \u2265 k] \u2264 31 , when every\nplayer decides truthfully. Note that the accuracy guarantee is independent of the size of the database\n- the number k is fixed no matter how large the database is, or the sampled set is.\n2. Differential Privacy: The estimate and payments satisfy \u01eb-differential privacy.\n3. Truthfulness: A mechanism is dominant strategy truthful if, for every player, deciding truthfully\nmaximizes his utility. A mechanism is Bayesian incentive compatible (BIC) if, for every player,\nassuming that other players' costs are drawn from F according to their data and decide truthfully,\ndeciding truthfully maximizes his utility.\n4. Individual Rationality: If a player's utility is non-negative, then he should be willing to participate.\nA mechanism is ex-post individually rational (EPIR) if the utility is non-negative for every player\nwhen he decides truthfully. A mechanism is ex-interim individually rational (EIIR) if the expected\nutility is non-negative for every player when he decides truthfully, where the randomness comes from\nthe mechanism and the costs of other players.\n5. Payment Minimization: The summation of payments should be as little as possible.\nTo get permission to use a player's data, the mechanism must compensate the player by at least his perceived loss of privacy. But since costs are correlated with data, players may be reluctant to reveal their true\ncosts, unless they will be compensated for this. To avoid this seeming chicken-and-egg problem, the mechanism designer cannot resort to the revelation principle, which states that any mechanism can be realized\nas a direct and truthful mechanism. In fact, [8] prove that if costs and data can be arbitrarily correlated and\nplayer's cost of privacy can be unbounded, then for any k < n/2, no k-accurate, direct, dominant strategy\ntruthful, EPIR, privacy preserving mechanism exists. On the other hand, we give a mechanism that provides\nk-accuracy for any input value k when costs are correlated with data, and there is no bound on players'\ncost of privacy. We get around the lower bound of [8] by using an indirect mechanism, and modeling the\ncorrelation of values and data via publically known (and allowably unbounded) distributions.\n1\nWe can view this cost as due to the change in his utility from future events that depend on the answer he gives to the analyst.\nThis cost is approximately linear in \u01eb and his expected utility, denoted by vi . Let g(A(D)) be the distribution of future events that\ndepends on A(D). Let wi be the player i's utility for future events. Since A is \u01eb-differentially private, g \u25e6 A is also \u01eb-differentially\nprivate. Thus, for random variables y \u223c g(A(D)) and y \u2032 \u223c g(A(D\u2032 )) and event b, Pr[y = b] \u2264 e\u01eb Pr[y \u2032 = b]. Therefore, we have\nEy\u223cg(A(D))[wi (y)] \u2212 Ey\u223cg(A(D \u2032 )) [wi (y)] is approximately \u01ebEy\u223cg(A(D \u2032 )) [wi (y)] or \u2212\u01ebEy\u223cg(A(D \u2032)) [wi (y)], when \u01eb is small.\n\n2\n\n\fPrivacy Issues when Costs are Correlated with Data. The objective of a privacy preserving mechanism\nis that the increase in knowledge about a player's data due to output of the mechanism is small. Previous\nwork on privacy in statistical databases assumes that the mechanism is associated with the database, such\nthat the mechanism can access the whole database without compromising a player's privacy. However, if\nthe mechanism is separated from the database, then a player might not trust the mechanism and might not\nwant to reveal private information to the mechanism.\nIn our problem, in order to estimate n1 , the mechanism should learn information about players' data.\nSuppose that the mechanism has a prior belief G about the data in D. That is, the mechanism believes that\nthe probability of Di = j is PrG [Di = j] according to the prior belief. The mechanism learns about Di if\nthe mechanism believes that Pr[Di = j] 6= PrG [Di = j] after running the mechanism, for some j. There\nare two possible ways to learn about players' data. The first way is to read Di explicitly. The second way\nis to read players' actions and deduce something about their Di . For example, if the mechanism is direct\nand truthful, then the players report vi truthfully. Suppose that the prior belief is that every player's data are\ndrawn from a uniform distribution. That is, PrG [Di = j] is the same for all i and j. If Fj (vi ) < Fj \u2032 (vi )\nfor some j and j \u2032 , and player i truthfully reports vi , then the mechanism's posterior belief is that Pr[Di =\nj] < Pr[Di = j \u2032 ], which is different from the prior belief. Learning anything about a player's data may\ncompromise a player's privacy and should be compensated. Thus, there are two kinds of cost to a player that\nshould be compensated, one is for using the player's data and one is for learning about the player's data.\nFor the latter cost, we propose the concept of perfect data privacy, which is inspired by the concept\nof perfect objective privacy introduced in [7]. A mechanism satisfies perfect data privacy if whenever the\nmechanism's posterior belief about a player's data differs from its prior belief, the mechanism pays the\nplayer. Under perfect data privacy, mechanisms can learn about a player's cost, as long as that knowledge\ndoes not reveal anything about his data. However, for a perfectly data private mechanism, if the mechanism\nlearns about a player's data, then the mechanism always compensates the player, even when the mechanism\ndoes not not use the player's data to compute the estimate.\nOur Main Contribution. We give a mechanism that is BIC, EIIR, O(\u01eb\u22121 )-accurate, perfectly data private,\nand \u01eb-differentially private. To achieve our privacy guarantees, we propose a posted-price-like mechanism,\ndescribed in Section 3. Given the set of types of players and the distributions of costs, the mechanism writes\na contract that offers a different expected payment for each type. Each player is offered this contract. If\na player accepts the contract, then his payment is determined by his verifiable type and the payment for\nhis type in the contract. The player's action is either to accept the contract or reject the contract. A player\ndecides truthfully if a player with type j accepts the contract when \u01ebvi \u2264 rj , where rj is the payment for type\nj in the contract. We prove that this posted-price-like mechanism is BIC, EIIR, O(\u01eb\u22121 )-accurate, perfectly\ndata private, and \u01eb-differentially private.\nWe seek a mechanism with a small payment. In Section 4, we define a benchmark for the expected\npayment of a mechanism and compare the expected payment of our mechanism to this benchmark in two\ndifferent settings. When costs are non-negative, we show that our mechanism is close to the benchmark.\nWe also prove a lower bound on the accuracy that a direct and data private mechanism can achieve in\nSection 2.\n\n1.1 Related Work\nSelling Privacy. Our paper is closely related to the privacy preserving mechanisms studied in [8]. In [8],\nthey extend the definition of \u01eb-differentially private algorithms to \u01eb-differentially private mechanisms. Under\ntheir definition of an \u01eb-differentially private mechanism, the randomness only comes from the mechanism.\nIn our model, since we want to protect the privacy of the costs, which are drawn from distributions, our\ndefinition of an \u01eb-differentially private mechanism relies both on the distributions of the costs and the ran-\n\n3\n\n\fdomness of the mechanism.\nDifferential Privacy. A comprehensive survey of differential privacy appears in [4]. Most of the previous\nresults are based on random perturbations of the output, and assume that the mechanism has the ability\nto access the whole database. If the mechanism cannot access the whole database, Chaudhuri et al. [1]\nand Klonowski et al. [12] show that random sampling is enough to ensure differential privacy with high\nprobability. That is, it is not necessary to add more noise to the output.\nDifferential Privacy and Mechanism Design. McSherry et al. [13] use a privacy preserving algorithm\nas a tool to design an approximately dominant strategy truthful mechanism. Instead, we focus on treating\nsenstive data as a commodity that can be sold.\nPrivacy Concerns in Mechanisms. Traditional mechanism design theory focuses on drawing private information from players in order to compute a result. However, if players have privacy concerns, they may not\nwant to reveal their information. Feigenbaum et al. [7] study how to quantify the information leakage to the\nmechanism based on communication complexity.\nXiao [18] quantifies the information leakage in a mechanism based on information theory. In his model,\nthe outcome of a privacy preserving mechanism not only motivates the players to participate but also protects\nthe private information of players. In independent work, Nissam et al. [16] and Chen et al. [3] consider\nprivacy issues in mechanism design in the context of elections and discrete facility location.\nPosted-Price Mechanisms. In a posted-price mechanism, player i is offered a price ri . If player i accepts\nthat price, then i pays ri to get the allocation. Goldberg et al. [9] show that the posted-price mechanism is\ncollusion resistant. Moreover, the players do not need to know or report their private values precisely. They\nonly decide to accept or reject the price. Chawla et al. [2] point out that this could be useful in reducing the\nprivate information revealed to the mechanism.\nRevenue Maximization in Bayesian Mechanism Design. In a classic paper, Myerson [14] characterizes\nthe optimal BIC selling mechanism to maximization the expected revenue. In procurement mechanisms,\neach player is a supplier and each player's production cost is private information. The auctioneer is the\nbuyer and wants to minimize the expected payment. In the computer science literature, an early paper in\nthis area characterizes the minimum-cost dominant strategy truthful auction to buy an s-t path in a graph [6].\nSince then, there has been considerable interest in both frugal mechanism design (buying a feasible set at\nlow cost), and budget-constrained mechanism design (buying as good a set as possible subject to a budget).\nOur work can be seen as a generalization of these questions to the setting of bidders who are reluctant to\nreveal their costs, and the feasibility of a set depends on the private costs (via the correlation with data).\n\n2 Model and Lower Bound\n2.1 Model\nThere is a database D \u2208 [h]n and n players, where each player has data Di . Player i with Di = j has a\nprivate cost vi drawn from a distribution with cumulative distribution function Fj . Note that this definition\nis different from the traditional definition of a Bayesian setting. In the traditional definition, the distribution\nof vi is known to every player and the mechanism. In our definition, the mechanism and players know that\neach player's vi is drawn from one of a set of distributions, but the particular distribution depends on the\nindividual player's data, which is unknown to everyone but that player.\nThe goal of our mechanism is to estimate n1 based on D and determine the payment pi for every player\ni. A mechanism first specifies the set of possible actions Y that players can take. Then, based on players'\nactions and the database, the mechanism determines the estimate and payment. Formally, a mechanism is a\nfunction M : Y n \u00d7 [h]n \u2192 R \u00d7 Rn . The mechanism has an a priori belief G about the data in D. That is, the\n4\n\n\fmechanism believes that the probability of Di = j is PrG [Di = j]. Recall that the mechanism learns about\nDi if, after running the mechanism, the mechanism believes that Pr[Di = j] 6= PrG [Di = j] for some j.\nWe use a vector x \u2208 {0, 1}n to indicate whether the mechanism learns something about each player's data.\nIf the mechanism learns about Di , then xi = 1. A mechanism is perfectly data private if, when xi = 1,\nplayer i's expected payment from the mechanism is at least \u01ebvi . We focus on randomized mechanisms in\nthis paper, that is, xi and payment pi are random variables.\nNext, we define the utility for a player. If xi = 1, there is a cost \u01ebvi to player i, since something about\nDi is learned. For y \u2208 Y n representing all players' actions, the utility for player i is ui (y, vi ) = pi \u2212 \u01ebxi vi ,\nwhere (\u015d, p) = M (y, D). In this paper, we assume that players are rational, so players want to maximize\ntheir expected utilities. The strategy of player i is a function qi : R \u00d7 [h] \u2192 Y mapping from vi and Di to\nan action. Since players want to maximize their expected utilities, they will take the action that is not worse\nthan any other action.\nFinally, we introduce the solution concept. A profile of strategies q1 , . . . , qn is a Bayesian-Nash equilibrium if for all i, vi , and yi\u2032 \u2208 Y , E[ui (q(vi , v\u2212i , D), vi )] \u2265 E[ui ((yi\u2032 , q\u2212i (v\u2212i , D\u2212i )), vi )], where the\nrandomness is from the mechanism and the randomness of v\u2212i . A direct mechanism is Bayesian incentive\ncompatible (BIC) if qi (vi , Di ) = vi is a Bayesian-Nash equilibrium for every player i.\n\n2.2 Lower Bound\nIn order to ensure that players have incentive to participate the mechanism, we wish that the mechanism is\nindividually rational. However, we can show that for any direct, BIC, and EIIR mechanism, there is a lower\nbound of accuracy. Since the condition of EIIR is weaker than EPIR, the lower bound for EIIR also implies\na lower bound for EPIR mechanisms.\nLemma 2.1. If the functions Fi are arbitrary functions with unbounded range, then for any k < n/2, no\nk-accurate, direct, BIC, EIIR, and perfectly data private mechanism exists.\nProof. Suppose that M is a BIC, EIIR, perfectly data private, and k-accurate mechanism. First, we show\nthat M must access at least one player's cost or data. Assume that M does not access any cost or data.\nThus, M randomly output an estimate \u015d, which is independent of costs and data. For a database D 1 with\nall entries equal to one, since M is k-accurate, Pr[\u015d \u2208 [n, n \u2212 k]] \u2265 32 . Similarly, if a database D 0 has no\nentries equal to one, then Pr[\u015d \u2208 [0, k]] \u2265 32 . Because k < n/2, [n, n \u2212 k] and [0, k] do not overlap. But\nthe summation of these two probabilities is greater than one, which is impossible. Hence, M must access at\nleast one player's cost or data.\nSuppose that Di \u2208 {1, 2} and F1 (v) 6= F2 (v) for all v. For any v\u0302, if M access vi = v\u0302, then the\nmechanism must pay player i, since F1 (v\u0302) = Pr[vi = v\u0302|Di = j] 6= Pr[vi = v\u0302|Di = j \u2032 ] = F2 (v\u0302) and\nM is perfectly data private. Let xi be the indicator random variable representing whether player i's cost is\naccessed. Let pj be the random variable representing player i's payment. Since M is BIC, we suppose that\nplayers other than i report truthfully. Since the mechanism decides to access vi based on v\u2212i , Pr[xi = 1]\nis independent of vi . Because M must access at least one player's cost, we can find a player i, such that\nPr[xi = 1] > 0. For a fixed vi , the expected utility of i is E[pi ] \u2212 \u01ebvi E[xi ]. Since the range of F is\nE[pi ]\n. Since M is EIIR, we have E[p\u2032i ] \u2265 \u01ebvi\u2032 E[xi ]. Thus, for player\nunbounded, we can find another vi\u2032 > \u01ebE[x\ni]\ni with cost vi , if i overbids vi\u2032 , the utility is E[p\u2032i ] \u2212 \u01ebvi E[xi ] \u2265 \u01ebvi\u2032 E[xi ] \u2212 \u01ebvi E[xi ] > E[pi ] \u2212 \u01ebvi E[xi ].\nThus, player i can increase expected utility by overbidding. Hence, M is not BIC.\nOur mechanism, which is explained in the next section, is an indirect mechanism since it does not ask for\nplayers' costs. The revelation principle, which states that if there exists an indirect mechanism implementing\na function in Bayesian-Nash equilibrium, then there also exists a direct BIC mechanism implementing the\n\n5\n\n\fsame function, is irrelevant under the desire for perfect data privacy. It is easy to construct a direct mechanism from our indirect mechanism. However, this direct mechanism accesses all players' data without\ncompensating all players. Thus, this direct mechanism is not perfectly data private.\n\u01eb-Differential Privacy. The traditional definition of \u01eb-differential privacy compares the outcomes of the\nalgorithm applied to adjacent databases. However, with a mechanism that offers payments, the mechanism\nmay use both the database and the replies to the mechanism to compute an estimate and payments. Since\nreplies depend on the individuals' costs, we compare the outcomes of the mechanism applied to two costdata pairs (v, D) and (v \u2032 , D \u2032 ). A cost vector v = (v1 , . . . , vn ) is drawn according to a database D, if\nvi is drawn from Fj , where Di = j. Two cost-data pairs (v, D) and (v \u2032 , D \u2032 ) are adjacent, if D and D \u2032\ndiffer only in the i-th entry and v and v \u2032 are independently drawn according to database D and D \u2032 . A BIC\nmechanism is \u01eb-differentially private if, for any pair of adjacent cost-data pairs, the estimate and payments\nsatisfy \u01eb-differential privacy.\nBayesian Assumptions. Our definition of \u01eb-differential privacy is based on the common belief F . That is,\nthe player decides his strategy assuming that other players' costs are drawn from F and all players believe\nthis assumption. If a player allows his data to be used, then he may incur a expected cost \u01ebvi . The expected\ncost to the player depends on \u01eb and thus also depends on the common belief F . Having a common belief\nis a traditional assumption in the Bayesian setting. Moreover, most BIC mechanisms become meaningless\nwhen the common belief is not true. Thus, we assume that the common belief F is correct.\n\n3 Mechanism\nIn this section, we give a perfectly data private, BIC, EIIR, \u01eb-differentially private, and O(\u01eb\u22121 )-accurate\nmechanism. Every player i has data Di \u2208 [h]. To start, we assume that Fj is continuous for j \u2208 {1, 2}.\nThe mechanism designs and offers contracts to players. The contract guarantees an expected payment to\neach player who accepts the contract. The players decide to accept or reject the contract. Thus, the possible\nactions for players are \"accept\" or \"reject\". The mechanism uses the data of players who accept the contract\nto estimate n1 . The estimate is unbiased if the expected value of the estimate is n1 . To obtain an unbiased\nestimate, the set of players who accept the contract should be unbiased, that is, the probability of a player\naccepting the contract should be equal for all players. Moreover, since the mechanism pays players, the\ncosts of players in the accepting set should be bounded.\nThe mechanism first finds \u03b1j for j \u2208 [h], such that Fj (\u03b1j ) = c, where c will be determined later. Then,\neach player i is given a contract : \"If Di = j, your expected payment will be \u01eb\u03b1j .\" A player i with Di = j\ndecides truthfully if, when vi \u2264 \u03b1j , player i accepts the contract and rejects otherwise. Let W be the set\nof players who accept the contract. If all players decide truthfully, the cost to each player in W is bounded\nby maxj \u03b1j . Since for player i with Di = j, Pr[vi \u2264 \u03b1j ] = c, every player accepts the contract with\nprobability c. Thus, W is an unbiased and cost-bounded sample set.\nSince the probability that a player accepts the contract is c, the value m := |{i \u2208 W : Di = 1}| is a\nrandom variable bin(n1 , c) from a binomial distribution2 Bin(n1 , c). Since the expected value of m is cn1 ,\nm\nm\nc is an unbiased estimate of n1 . We say c is a na\u0131\u0308ve estimate of n1 .\nWe explain how to produce an estimate that satisfies \u01eb-differential privacy. Although the naive estimate\nis an unbiased estimate of n1 , it does not satisfy differential privacy. Consider an adjacent pairs of cost-data\npairs (v, D) and (v \u2032 , D \u2032 ), where D and D \u2032 differ in the i-th entry. Let n1 be the number of player i with\nDi = 1 and n\u20321 be the number of players i with Di\u2032 = 1. The naive estimate does not satisfy differential\n2\n\nA binomial\u0001distribution with parameter n and p is denoted by Bin(n, p). The probability density function of Bin(n, p) is\nf (k; n, p) = nk pk (1 \u2212 p)n\u2212k . Let bin(n, p) denote a random variable drawn from Bin(n, p). The expected value of bin(n, p) is\nnp and variance is np(1 \u2212 p).\n\n6\n\n\f1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\nMechanism 1: \u01eb-differentially private mechanism\ninput : privacy parameter \u01eb; cost distributions Fj , j \u2208 [h]\noutput: estimate \u015d; payment p\nPick a real number c \u2208 (0, 1)\nFind \u03b1j for all j \u2208 [h], such that Fj (\u03b1j ) = c.\nFor each player i, offer a contract:\nIf Di = j, the expected payment will be \u01eb\u03b1j .\nLet W = {i : i accepts contract}.\nLet m = |{i \u2208 W : Di = 1}|.\nLet s = 1c (m + lap( 1\u01eb )).\n\u015d = s if s \u2208 [0, n], 0 if s < 0, n if s > n\n(\n0\nif i \u2208\n/W\npi =\n\u03b3\n\u01eb(\u03b1j + lap( \u01eb )), where \u03b3 := | maxj \u03b1j \u2212 minj \u03b1j | if i \u2208 W and Di = j\nreturn (\u015d, p)\n\nprivacy, since if Di = 1 and vi \u2264 \u01eb\u03b11 , then an outsider can infer Di easily by comparing the naive estimates\nof n1 and n\u20321 . Thus, we should introduce a random noise to the naive estimate to satisfy differential privacy.\nThe mechanism uses the Laplacian distribution as a source of the random noise. The Laplacian noise is\ncommonly used to obtain differential privacy. A Laplacian distribution with mean 0 and parameter b > 0 is\ndenoted by Lap(b). The probability density function of Lap(b) is\n\u0012\n\u0013\n|x|\n1\nexp \u2212\n.\nf (x) =\n2b\nb\nLet lap(b) denote a random variable drawn from Lap(b).\nIn order to make estimate satisfy differential privacy, the mechanism adds random noise lap( 1\u01eb ) to the\nnaive estimate. Since the mean of the Laplacian noise is zero, s = 1c (m + lap( 1\u01eb )) is an unbiased estimate\nof n1 . However, s might be larger than n or be negative, both of which are meaningless. We truncate s to\nget \u015d, that is when s > n, the mechanism outputs n and when s < 0, the mechanism outputs 0.\nWe also use the Laplacian noises to produce payments that satisfy \u01eb-differential privacy. By the construction of the contract, for any player i with Di = j who accepts the contract, the mechanism pays player\ni for \u01eb\u03b1j in expectation. If the mechanism pays player i for \u01eb\u03b1j deterministically, then an outsider can infer\nplayer i's data easily. Thus, we should introduce noise to the payments. We add noise \u01eb lap( \u03b3\u01eb ) to the payment, where \u03b3 := | maxj \u03b1j \u2212 minj \u03b1j |. Thus, pi = \u01eb(\u03b1j + lap( \u03b3\u01eb )). Since the expected value of lap( \u03b3\u01eb ) is\nzero, the expected payment of player i is \u01eb\u03b1j , which satisfies the guarantee in the contract. Moreover, since\n\u01eb\u03b1j is larger than \u01ebvi , the mechanism is EIIR. The formal description of the mechanism is in Mechanism 1.\nLemma 3.1. Mechanism 1 is perfectly data private.\nProof. Let yi be player i's reply to the contract. By construction of the contract, if i decides truthfully, then\nPr[yi = \"accept\" | Di = j] = c for all j \u2208 [h]. That is, the probability of accepting the contract and\nDi are independent. Thus, for any i, the mechanism cannot learn about Di by reading yi . Moreover, the\nmechanism only reads Di , where i \u2208 W . Since player i \u2208 W with Di = j is paid \u01eb\u03b1j in expectation and\nvi \u2264 \u03b1j , the mechanism satisfies the requirement.\nLemma 3.2. Mechanism 1 is BIC and EIIR.\n\n7\n\n\fProof. (BIC) The payments for players who is not in W are always 0. For player i, there are two cases.\nCase 1: Di = j and vi \u2264 \u03b1j . Accepting the contract will get expected payment \u01eb(\u03b1j \u2212 vi ) \u2265 0.\nCase 2: Di = j and vi > \u03b1j . Accepting the contract will get expected payment \u01eb(\u03b1j \u2212 vi ) < 0.\n(EIIR) Suppose that every player decides truthfully. Then only players with vi \u2264 \u03b1j and Di = j for\nsome j are in W . Since the expected payment for i with Di = j is \u01eb\u03b1j , the expected utility of the player is\nnon-negative.\nTwo random variables x1 and x2 are \u01eb-mutually bounded, if \u2200I \u2286 R, Pr[x1 \u2208 I] \u2264 e\u01eb Pr[x2 \u2208 I] and\nPr[x2 \u2208 I] \u2264 e\u01eb Pr[x1 \u2208 I].\nLemma 3.3 (Fact 2 in [8]). If x1 and x2 are \u01eb-mutually bounded and f is a function, then f (x1 ) and f (x2 )\nare also \u01eb-mutually bounded.\nLemma 3.4 ([5]). Let x1 and x2 be two random variables. If |x1 \u2212x2 | \u2264 k, then x1 +lap( k\u01eb ) and x2 +lap( k\u01eb )\nare \u01eb-mutually bounded.\nThe next two lemmas address the \u01eb-differential privacy of the payment and the estimate. Let (v, D) and\n(v \u2032 , D \u2032 ) be adjacent cost-data pairs. Let (\u015d, p) and (\u015d\u2032 , p\u2032 ) be the results for (v, D) and (v \u2032 , D \u2032 ) respectively.\nLemma 3.5. For any I \u2286 R, Pr[\u015d \u2208 I] \u2264 e\u01eb Pr[\u015d\u2032 \u2208 I].\nR\nProof. Without loss of generality, we assume that 1 = Di and Di\u2032 6= 1. First, Pr[\u015d \u2208 I] = v\u2212i \u2208Rn\u22121 Pr[\u015d \u2208\nR\n\u2032 be\nI | v\u2212i ] Pr[v\u2212i ]dv\u2212i . Similarly, Pr[\u015d\u2032 \u2208 I] = v\u2212i \u2208Rn\u22121 Pr[\u015d\u2032 \u2208 I | v\u2212i ] Pr[v\u2212i ]dv\u2212i . Let q\u0302w and q\u0302w\n\n\u2032 are \u01eb-mutually bounded for\ntwo random variables, which are equal to \u015d and \u015d\u2032 when v\u2212i = w. If q\u0302w and q\u0302w\n\u2032\nall w, then \u015d and \u015d are \u01eb-mutually bounded, since then\nZ\nPr[\u015d \u2208 I | v\u2212i = w] Pr[v\u2212i = w]dw\nPr[\u015d \u2208 I] =\nw\u2208Rn\u22121\nZ\nPr[q\u0302w \u2208 I] Pr[v\u2212i = w]dw\n=\nn\u22121\nZw\u2208R\n\u2032\ne\u01eb Pr[q\u0302w\n\u2208 I] Pr[v\u2212i = w]dw\n\u2264\nn\u22121\nw\u2208R\nZ\ne\u01eb Pr[\u015d\u2032 \u2208 I | v\u2212i = w] Pr[v\u2212i = w]dw = e\u01eb Pr[\u015d\u2032 \u2208 I].\n=\nw\u2208Rn\u22121\n\nThe case Pr[\u015d\u2032 \u2208 I] \u2264 e\u01eb Pr[\u015d \u2208 I] can be shown by a symmetric argument.\n\u2032 are \u01eb-mutually bounded for all w. Fix v\n\u2032\nHere, we show that q\u0302w and q\u0302w\n\u2212i = w. Let Ww and Ww\nbe the sets of players accepting the contract when applying the algorithm to inputs (v, D) and (v \u2032 , D \u2032 )\nrespectively. Let mw := |{i : Di = 1, i \u2208 Ww }| and m\u2032w := |{i : Di\u2032 = 1, i \u2208 Ww\u2032 }|. When applying\nthe mechanism to inputs (v, D) and (v \u2032 , D \u2032 ), the mechanism computes sw = 1c (mw + lap( 1\u01eb )) and s\u2032w =\n1\n1\n\u2032\n\u2032\n\u2032\nc (mw + lap( \u01eb )) respectively. Then, the mechanism truncates sw and sw to get \u015dw and \u015dw . By Lemma 3.3,\n1\nsince multiplication and truncation are functions, it suffices to show that mw + lap( \u01eb ) and m\u2032w + lap( 1\u01eb ) are\n\u01eb-mutually bounded when v\u2212i = w. Since W \\ W \u2032 is either the empty set or {i}, the difference between\nmw and m\u2032w is at most one. Thus, Lemma 3.4 implies that mw + lap( 1\u01eb ) and m\u2032w + lap( 1\u01eb ) are \u01eb-mutually\n\u2032 are \u01eb-mutually bounded for all w, and hence \u015d and \u015d\u2032 are mutually bounded.\nbounded. Thus, q\u0302w and q\u0302w\nLemma 3.6. For all i \u2208 [n] and for all I \u2286 R, Pr[pi \u2208 I] \u2264 e\u01eb Pr[p\u2032i \u2208 I].\n\n8\n\n\fProof. Without loss of generality, we assume that Di = 1 and Di\u2032 6= 1. For player j 6= i, if j \u2208\n/ W , the\npayment is zero. If j \u2208 W , the payment to j depends only on the data Dj and does not depend on the\nset of players receiving payments. Thus, pj does not change and we only need to consider pi . Note that\npi 6= 0 only happens if player i is in W . If pi 6= 0, then pi is a random variable P 1 = \u01eb(\u03b11 + lap( \u03b3\u01eb )).\nThus, for any I \u2286 R \\ {0}, the probability Pr[pi \u2208 I] = c Pr[P 1 \u2208 I], where c is the probability of that a\nplayer accepts the contract. The probability Pr[pi = 0] = (1 \u2212 c) + c Pr[P 1 = 0]. Suppose that Di\u2032 = j \u2032 .\nSymmetrically, let P 2 = \u01eb(\u03b1j \u2032 + lap( \u03b3\u01eb )), for any I \u2286 R \\ {0}, the probability Pr[p\u2032i \u2208 I] = c Pr[P 2 \u2208 I]\nand Pr[p\u2032i = 0] = (1 \u2212 c) + c Pr[P 2 = 0].\nThus, it suffices to show that P 1 and P 2 are \u01eb-mutually bounded. By Lemma 3.3, since multiplication\nis a function, it is sufficient to show that \u03b11 + lap( \u03b3\u01eb ) and \u03b1j \u2032 + lap( \u03b3\u01eb ) are \u01eb-mutually bounded. By Lemma\n3.4, since |\u03b11 \u2212 \u03b1j \u2032 | \u2264 \u03b3, \u03b11 + lap( \u03b3\u01eb ) and \u03b1j \u2032 + lap( \u03b3\u01eb ) are \u01eb-mutually bounded.\nq\nLemma 3.7. Mechanism 1 is 3( n1 (1\u2212c)\n+ \u01eb22c2 )-accurate.\nc\nProof. Since the error term |\u015d \u2212 n1 | is smaller than |s \u2212 n1 |, we can analyze |s \u2212 n1 | to get a bound on the\nerror. Since E[m] = cn1 , E[s] = 1c (E[m] + E[lap( 1\u01eb )]) = n1 by linearity of expectation.\n|\u015d \u2212 n1 | \u2264 |s \u2212 n1 | =\n\n1\n1\n1\n1\n1\n|m + lap( ) \u2212 n1 c| = |bin(n1 , c) + lap( ) \u2212 E[bin(n1 , c) + lap( )]|.\nc\n\u01eb\nc\n\u01eb\n\u01eb\n\nIn order to prove that accuracy with high probability, we use Chebyshev's inequality.\nLemma 3.8 (Chebyshev's inequality). Let X be a random variable with expected value \u03bc and variance \u03c3 2 .\nFor any real number k > 0, Pr[|X \u2212 \u03bc| \u2265 k\u03c3] \u2264 k12 .\n\u221a\nWe set k = 3 and let X \u223c bin(n1 , c) + lap( 1\u01eb ) with V ar[X] = n1 c(1 \u2212 c) + \u01eb22 to get\n\"\n\n1\n1\nPr |bin(n1 , c) + lap( ) \u2212 E[bin(n1 , c) + lap( )]| \u2265\n\u01eb\n\u01eb\n\nr\n\n#\n2\n1\n3(n1 c(1 \u2212 c) + 2 ) \u2264 .\n\u01eb\n3\n\nThis is equivalent to\n#\n\"\nr\n1\n1\n2\n1\n1\nn1 (1 \u2212 c)\n+ 2 2) \u2264 .\nPr |bin(n1 , c) + lap( ) \u2212 E[bin(n1 , c) + lap( )]| \u2265 3(\nc\n\u01eb\n\u01eb\nc\n\u01eb c\n3\n\u0014\n\nThus, Pr |\u015d \u2212 n1 | \u2265\n\nq\n\n3( n1 (1\u2212c)\nc\n\n+\n\n2\n)\n\u01eb2 c2\n\n\u0015\n\n\u2264 13 .\n\nThe mechanism can pick c freely. If the mechanism picks a constant c such that n(1\u2212c)\n\u2264 \u01eb22c2 , the\nc\n\u22121\nmechanism is O(\u01eb ) accurate.\nWe will extend this result to general data entry and discrete cost distributions in Section 3.1. Thus, we\nhave the main theorem.\nTheorem 3.9. Mechanism 1 is BIC, EIIR, O(\u01eb\u22121 )-accurate, perfectly data private, and \u01eb-differentially\nprivate.\n\n9\n\n\f3.1 Extensions and Computational Issues\nGeneral Database Entries. Suppose that the entry of database has d attributes, that is, Di \u2208 [h]d . Given a\nsequence a1 , . . . , ad , where aj \u2208 [h], the data analyst wants to estimate |{i : \u2200j Dij = aj }|. For any Di , we\nP\ni such that D \u2032 \u2208 [hd ]. Then, we can\ncan transform Di to a single attribute data Di\u2032 = 1 + d\u22121\ni\ni=0 Dij \u00d7 d , P\n\u2032\ni.\napply the mechanism to estimate the number of players with Di = 1 + d\u22121\na\n\u00d7\nd\ni=0 j\n\nDiscrete Cost Distributions. When Fj is a discrete probability function, the major difficulty is that for\na given c and j, we may not find a suitable \u03b1j , such that Fj (\u03b1j ) = c, because the cumulative probability\nfunction of a discrete distribution is a step function. However, the mechanism can provide different contracts\nto different players and this ability allows us to design a mechanism for discrete case.\nThe basic idea is that the mechanism uses randomness to pick \u03b1j such that every player has equal\nprobability c to accept the contract. For a given c and for each j, if there is no \u03b1j such that Fj (\u03b1j ) = c, then\n+\n+\n\u2212\n\u2212\n+\nthe mechanism finds the largest \u03b1\u2212\nj and the smallest \u03b1j such that Fj (\u03b1j ) = cj < c and Fj (\u03b1j ) = cj > c.\nNote that a player i with Di = j accepts the contract if his cost is smaller than the expected payment. If\n+\nthe expected payment is \u03b1+\nj , then the player accepts the contract with probability cj > c. On the other\n\u2212\nhand, if the expected payment is \u03b1\u2212\nj , then the player accepts the contract with probability cj < c. Let\n\u03b2j =\n\nc\u2212c\u2212\nj\n\n. Player i is given a contract \"If Di = j, your expected payment is \u01eb\u03b1j in expectation,\" where\n\n\u2212\nc+\nj \u2212cj\nPr[\u03b1j = \u03b1\u2212\nj ]\n\n\u2212\n+\n\u2212\n= 1 \u2212 \u03b2j and Pr[\u03b1j = \u03b1+\nj ] = \u03b2j . Thus, Pr[vi \u2264 \u03b1j ] = cj + \u03b2j (cj \u2212 cj ) = c, where the\nrandomness is over the distribution of costs and the random choice of \u03b1j . We can prove that the mechanism\nis perfectly data private, BIC, and EIIR by arguments similar to those in the proofs of Lemmas 3.1 and 3.2.\nSince every player has equal probability c to accept the contract, we can show that the mechanism satisfies\n\u01eb-differential privacy of estimate and is O(\u01eb\u22121 )-accurate by arguments similar to those in the proofs of\n\u2212\nLemmas 3.5 and 3.7. In order to satisfy differential privacy of payments, we let \u03b3 := maxj \u03b1+\nj \u2212 minj \u03b1j .\nThen, the payments satisfy \u01eb-differential privacy by an argument similar to the proof of Lemma 3.6.\n\nCost of Mechanism. For a fixed \u01eb, when c increases, the accuracy of Mechanism is improved, since Mechanism 1 uses more\nq players' data. However, Mechanism 1's expected total payment also increases. Since\n+\n3( n1 (1\u2212c)\nc\n\n2\n)-accurate,\n\u01eb2 c2\n\nthere is a trade-off between the accuracy and the expected\nq\n8\ntotal payment. Since the mechanism can pick c freely, for a given \u01eb >\nn , the mechanism can pick\n\u221a\n\u221a\n1+ 1\u22128\u01eb\u22122 /n\n\u01eb+ \u01eb2 \u22128/n\nc =\n.\nLet\n\u03b1\n=\nmax\n\u03b1\n.\nThe\nexpected\ntotal\npayment\nis\n\u01eb\u03b1cn\n=\n\u03b1n(\n). Then,\nj j\n2\n2\nMechanism 1 picks a suitable \u01eb, such that the expected total payment \u01eb\u03b1cn = B. Hence, the mechanism is\n1\n) = O( \u03b1n\nbudget-feasible in expectation and is O( \u01ebc\nB ) accurate.\n\nMechanism 1 is\n\n1\nand\n1+k 2 /6n\n\u221a\n\u01eb\u03b1cn = 2 k3\u03b1n .\n\nFixed Accuracy. If the data analyst wants a k-accurate mechanism, we can pick c =\n\u221a\n2 3(1+k 2 /6n)\n,\nk\n\nsuch that the mechanism is k-accurate. The expected total payment is\n\n\u01eb =\n\nComputing F\u22121 (c). In an ideal model, when Fj is a continuous distribution, we assume that mechanism\ncan access the closed form of Fj , such that the mechanism can compute \u03b1 = Fj\u22121 (c) accurately. However,\nwhen the mechanism cannot access the closed form of Fj , Fj\u22121 (c) may not be computable. When it is\nimpossible to access the closed form of Fj , we assume that there is an oracle, which returns Fj (v) for\n+\n\u2212\nany given value v. In the oracle model, the mechanism finds \u03b1\u2212\nj , \u03b1j for all j, such that Fj (\u03b1j ) < c,\n+\n\u2212\nFj (\u03b1+\nj ) > c, and \u03b1j \u2212 \u03b1j < \u03b4 for \u03b4 < 1/n using binary search. Then, the mechanism uses the method\nthat we use for discrete cost distributions to construct the contract. That is, let \u03b2j =\n\nc\u2212c\u2212\nj\n\n\u2212\nc+\nj \u2212cj\n\n. Player i is\n\n\u03b1\u2212\nj ]\n\ngiven a contract \"If Di = j, your expected payment is \u01eb\u03b1j in expectation,\" where Pr[\u03b1j =\n= 1 \u2212 \u03b2j\n\u2212\n+\n\u2212\n+\nand Pr[\u03b1j = \u03b1j ] = \u03b2j . Thus, Pr[vi \u2264 \u03b1j ] = cj + \u03b2j (cj \u2212 cj ) = c, where the randomness is over the\n10\n\n\fdistribution of costs and the random choice of \u03b1j . Hence, the mechanism is still perfectly data private, BIC,\nEIIR, \u01eb-differential private, and O(1/\u01eb)-accurate. In the oracle model, the expected payment for player i\nwith Di = j who accepts the contract is at most \u03b1+\nj . In the ideal model, the expected payment for player i\n\u22121\n+\n\u22121\nwith Di = j who accepts the contract is Fj (c), which is smaller than \u03b1+\nj . Since \u03b1j \u2212 Fj (c) is at most\n\u03b4 < 1/n, the difference between the expected payments in the ideal model and in the oracle model is at\nmost 1/n for each player. Thus, the difference between the expected total payment in the ideal model and\nin the oracle model is at most 1.\n\n4 Optimality\nIn this section, we define a benchmark for the expected payment of a mechanism and compare the expected\npayment of Mechanism 1 to this benchmark in two different settings. The benchmark mechanism is not\nonly truthful but also knows Di for all i and has no privacy requirements. We show that when all costs are\nnon-negative, Mechanism 1 is provably close to the benchmark.\nThe benchmark is the minimum expected payment among all truthful mechanisms M \u2217 that satisfy the\nfollowing properties. In order to get a meaningful estimate, for any k < n/2, a k-accurate mechanism\nlearns a subset of players' data. We call this subset a sample set. Since obtaining an estimate based on an\nunbiased sample is a common approach in statistics, we assume that M \u2217 uses an unbiased sample. Suppose\nthat there are nj players with Di = j for j \u2208 [h]. Since the sample set is unbiased, there exists c such that\nM \u2217 buys wj = cnj data from players with Di = j. After getting an unbiased sample, M \u2217 uses w1 /c as the\nstraightforward estimate of n1 . Since the choices of c may effect the accuracy guarantee, we compare the\npayment of Mechanism 1 to the payment of M \u2217 , where Mechanism 1 and M \u2217 have the same size of sample\nsets. Thus, M \u2217 is a truthful mechanism that gets an unbiased sample with size cn for a fixed number c.\nSince there is no competition between players with data j and players with data j \u2032 6= j, M \u2217 can run\nauctions for players with Di = j for all j \u2208 [h] independently and buy wj data from players with Di = j.\nThe mechanism that guarantees buying w units is called w-unit procurement mechanism. Thus, M \u2217 is a\nmechanism that runs a truthful, wj -unit procurement mechanism for each j \u2208 [h].\nMechanism 1 buys in expectation wj data from players with Di = j for j \u2208 [h]. We compare the\nexpected payment of Mechanism 1 for buying in expectation wj data from players with Di = j with the\nexpected payment of M \u2217 for buying wj data from players with Di = j for each j. If the expected payment\nof Mechanism 1 is at most r times the expected payment of M \u2217 for each j, then the total expected payment\nof Mechanism 1 is at most r times the total expected payment of M \u2217 . Thus, we focus on a single auction\nthat all players have the same Di and both Mechanism 1 and the M \u2217 want to buy w data from n players.\nFor multi-unit procurement mechanisms, let xi be the indicator random variable denoting whether the\nmechanism buys from player i. Let vi be the cost to the player i, if xi = 1. Let pi be the payment of player\ni. The utility for player i is pi \u2212 xi vi . Note that when we consider privacy preserving mechanisms, the\nutility of player i is pi \u2212 \u01ebxi vi . However, since \u01eb is the same for all players, we can ignore \u01eb without loss\nof generality, that is, scaling every player's cost by \u01eb. Without loss of generality, we suppose that players\nreport costs v1 \u2264 v2 * * * \u2264 vn .\n\n4.1 Envy-free Benchmark\nA mechanism is envy-free if for all v and for all i, j, pi \u2212 vi xi \u2265 pj \u2212 vi xj . We show that for any\nenvy-free, multi-unit procurement mechanism, every data that is bought by the mechanism is purchased\nat the same price. Suppose that a multi-unit procurement mechanism buys data from two players at two\ndifferent prices. Since the player with the lower price wants to have the higher price, the mechanism is not\nenvy-free. We compare the expected payment of Mechanism 1 with the expected payment of the optimal,\n\n11\n\n\fenvy-free, dominant strategy truthful, multi-unit procurement mechanism. We use envy-free mechanisms\nas a benchmark, because for procurement mechanisms in a Bayesian setting, the optimal mechanisms are\nknown to charge a fixed price.3\nWe introduce another commonly used solution concept as follows. A profile of strategies q1 , . . . , qn is a\ndominant strategy equilibrium if for all i, vi ,v\u2212i , and yi\u2032 \u2208 Y , E[ui (q(vi , v\u2212i , D), vi )] \u2265 E[ui ((yi\u2032 , q\u2212i (v\u2212i , D\u2212i )), vi )],\nwhere the randomness is from the mechanism. A direct mechanism is dominant strategy truthful if qi (vi , Di ) =\nvi is a dominant strategy equilibrium for every player i. The following lemma characterizes the total payment for any dominant strategy truthful, EPIR, and envy-free mechanisms.\nLemma 4.1 (Theorem 4.6 in [8]). No dominant strategy truthful, EPIR, and envy-free w-unit procurement\nmechanism can have total payment less than wvw+1 .\nLet F be the cumulative distribution function of players' costs, that is, F (a) = Pr[v \u2264 a]. By Lemma\n4.1, the total expected payment of any dominant strategy truthful, EPIR, and envy-free w-unit procurement\nmechanism is at least wEv\u223cF [vw+1 ]. Thus, our benchmark is wEv\u223cF [vw+1 ].\nNow, we compare the benchmark with the expected payment of Mechanism 1. There are two cases.\nFirst, when there exists \u03b1 such that F (\u03b1) = w\nn , Mechanism 1 offers a posted price \u03b1 for each player in order\nto buy w players' data in expectation. If player i accepts the price, the mechanism buys from player i with\nexpected payment \u03b1. Since each player has probability w\nn to accept the contract, the total expected payment\nof Mechanism 1 is w\u03b1.\nSecond, when there is no \u03b1 such that F (\u03b1) = w\nn , we give an extension to Mechanism 1 in Section\nw\n+\n\u2212\n3.1. The extension finds the largest \u03b1 and the smallest \u03b1+ , such that F (\u03b1\u2212 ) < w\nn and F (\u03b1 ) > n . Let\nw\n\n\u2212c\u2212\n\nc\u2212 := F (\u03b1\u2212 ), c+ := F (\u03b1+ ), and \u03b2 := cn+ \u2212c\u2212 . Then, the mechanism offers a price \u03b1+ with probability\n\u03b2 and price \u03b1\u2212 with probability 1 \u2212 \u03b2. For a player with cost at most \u03b1\u2212 , since the player always accepts\nthe offer, the expected payment is (\u03b1\u2212 (1 \u2212 \u03b2) + \u03b1+ \u03b2). For a player with cost equal to \u03b1+ , since the\nplayer accepts the offer only when the offered price is \u03b1+ , the expected payment is \u03b1+ \u03b2. For a player\nwith cost larger than \u03b1+ , since the player always rejects the offer, the expected payment is 0. Since each\nplayer has a cost at most \u03b1\u2212 with probability c\u2212 and has a cost equal to \u03b1+ with probability c+ \u2212 c\u2212 , each\nplayer's expected payment is c\u2212 (\u03b1\u2212 (1 \u2212 \u03b2) + \u03b1+ \u03b2) + (c+ \u2212 c\u2212 )\u03b1+ \u03b2. Thus, the total expected payment is\nn(c\u2212 (\u03b1\u2212 (1 \u2212 \u03b2) + \u03b1+ \u03b2) + (c+ \u2212 c\u2212 )\u03b1+ \u03b2) by the linearity of expectation. Moreover,\nw\nn(c\u2212 (\u03b1\u2212 (1 \u2212 \u03b2) + \u03b1+ \u03b2) + (c+ \u2212 c\u2212 )\u03b1+ \u03b2) = n(c\u2212 (\u03b1\u2212 (1 \u2212 \u03b2) + \u03b1+ \u03b2) + ( \u2212 c\u2212 )\u03b1+ )\nn\nw +\n\u2212 \u2212\n= n( \u03b1 + c (\u03b1 (1 \u2212 \u03b2) + \u03b1+ \u03b2 \u2212 \u03b1+ ))\nn\nw +\n= n( \u03b1 + c\u2212 ((1 \u2212 \u03b2)(\u03b1\u2212 \u2212 \u03b1+ ))\nn\nw +\n= n( \u03b1 \u2212 c\u2212 ((1 \u2212 \u03b2)(\u03b1+ \u2212 \u03b1\u2212 )))\nn\nnc\u2212\n= w(\u03b1+ \u2212\n(1 \u2212 \u03b2)(\u03b1+ \u2212 \u03b1\u2212 )).\nw\nWhen there exists \u03b1, such that F (\u03b1) = w\nn , the expected payment of Mechanism 1 is w\u03b1. When \u03b1 does\nnc\u2212\n+\nnot exist, the expected payment is w(\u03b1 \u2212 w (1 \u2212 \u03b2)(\u03b1+ \u2212 \u03b1\u2212 )). Thus, we should compare both w\u03b1 and\n\u2212\n\u2212\nw(\u03b1+ \u2212 ncw (1\u2212\u03b2)(\u03b1+ \u2212\u03b1\u2212 )) with wEv\u223cF [vw+1 ]. It suffices to compare \u03b1 and \u03b1+ \u2212 ncw (1\u2212\u03b2)(\u03b1+ \u2212\u03b1\u2212 )\nwith Ev\u223cF [vw+1 ].\n1\nLemma 4.2. 1. If there exists \u03b1 such that F (\u03b1) = w\nn , then Ev\u223cF [vw+1 ] \u2265 2 \u03b1.\nw\n1\nn \u2212\n+\n2. If there is no \u03b1 such that F (\u03b1) = n , then Ev\u223cF [vw+1 ] \u2265 2 (\u03b1 \u2212 w c (1 \u2212 \u03b2)(\u03b1+ \u2212 \u03b1\u2212 )).\n3\n\nEnvy-free benchmarks are also common in prior-free mechanism design [10].\n\n12\n\n\fProof. We show the second statement. The first statement follows by setting \u03b1\u2212 = \u03b1+ = \u03b1.\n\u2212\nLet \u03b7 = \u03b1+ \u2212 ncw (1 \u2212 \u03b2)(\u03b1+ \u2212 \u03b1\u2212 ). By conditional probability,\nE[vw+1 ] = Pr[vw+1 \u2264 \u03b7] \u00d7 E[vw+1 | vw+1 \u2264 \u03b7] + Pr[vw+1 > \u03b7] \u00d7 E[vw+1 | vw+1 > \u03b7]\n\u2265 Pr[vw+1 > \u03b7] \u00d7 \u03b7 (costs are non-negative).\n\n\u2212\n\n\u2212\n\nnc\nnc\nIt suffices to show that Pr[vw+1 > \u03b7] \u2265 12 . Since c\u2212 < w\nn , w < 1. Since \u03b2 < 1 and w < 1,\n\u03b1\u2212 < \u03b7 < \u03b1+ . If vw+1 > \u03b7, then vw+1 \u2265 \u03b1+ , since \u03b1+ is the smallest number larger than \u03b1\u2212 with\nnon-zero probability. Let v(i) denote the cost of player i. If vw+1 \u2265 \u03b1+ , then at most w players' v(i)\n\u2212 . Let X be\nare no larger than \u03b1\u2212 . Since each v(i) is independently drawn from F , Pr[v(i) \u2264 \u03b1\u2212 ] = cP\ni\nthe indicator random variable such that Xi = 1 if v(i) \u2264 \u03b1\u2212 , otherwise Xi = 0. Let X = ni=1 Xi . The\nprobability that at most w players have v(i) no larger than \u03b1\u2212 is Pr[X \u2264 w]. Since the Xi 's are independent,\nidentical, indicator random variables, X is a random variable from a binomial distribution Bin(n, c\u2212 ). Thus,\nPr[vw+1 \u2265 \u03b1+ ] = Pr[bin(n, c\u2212 ) \u2264 w].\nNow, we show that Pr[bin(n, c\u2212 ) \u2264 w] \u2265 12 . We say m is the median of a distribution D over real\nnumbers if, Pr[Z \u2264 m] \u2265 21 and Pr[Z \u2265 m] \u2265 12 , where Z is a random variable drawn from D. For a\nbinomial distribution Bin(n, p), the expected value np and the median m satisfy \u230anp\u230b \u2264 m \u2264 \u2308np\u2309 [11].\n\u2212\n\u2212\nSince c\u2212 < w\nn , the expected value of bin(n, c ) is smaller than w. Since \u2308nc \u2309 \u2264 w, the median m of\nBin(n, c\u2212 ) is at most w. Thus, Pr[bin(n, c\u2212 ) \u2264 w] \u2265 21 .\n\nLemmas 4.1 and 4.2 imply the following theorem.\nTheorem 4.3. Mechanism 1's expected payment is 2-approximate to the benchmark.\n\n4.2 Anti-regular Distributions\nIn this section, we compare the expected payment of Mechanism 1 with the expected payment of the optimal\nBIC, multi-unit procurement mechanism. We first characterize randomized BIC procurement mechanisms.\nFor a randomized mechanism and a given bid vi , let x\u0304i (vi ) be the probability that the mechanism buys from\nplayer i and let pi (vi ) be the random variable denoting the payment for player i, where both x\u0304i and pi 's\nrandomness come from the mechanism and v\u2212i . Suppose that when vi = \u221e, the mechanism will not buy\nfrom player i. That is, x\u0304i (\u221e) = 0 and E[pi (\u221e)] = 0. The characterization for the BIC, procurement\nmechanisms is analogous to the characterization of BIC selling mechanisms, which is a well-known result\nin auction theory. We provide a proof of the following characterization in the Appendix.\nLemma 4.4. A randomized procurement mechanism is BIC if and only if for every i the procurement probability x\u0304 and payment p satisfies\n(i) x\u0304i (vi ) is decreasing in viR;\n\u221e\n(ii) E[pi (vi )] = vi x\u0304i (vi ) + vi x\u0304i (t)dt.\n\nTo prove the optimality of selling mechanisms, Myerson [14] introduces a virtual value function. The\n(z)\n. Thus,\nanalogous function for procurement mechanisms is a virtual cost function, which is \u03c6(z) := z + Ff (z)\nto ensure that \u03c6(z) is well-defined and the integral of f is well-defined (used in the proof of Lemma 4.5 and\nLemma 4.7), we assume\nAssumption 1. Let f be the density probability function of distribution F with range [a, b] \u2286 [0, \u221e). f is\npiecewise continuous and f (z) is positive for all z \u2208 [a, b].\nA distribution F is anti-regular if F satisfies Assumption 1 and \u03c6(z) is increasing in z.4\n4\n\nFor selling mechanisms, a distribution is regular if the virtual value \u03c6\u2032 (z) = z \u2212\n\n13\n\n1\u2212F (z)\nf (z)\n\nis increasing in z.\n\n\fWhen the distribution F is anti-regular, [6] characterize the optimal dominant strategy truthful mechanism to minimize the expected payment for path auctions. Although their problem is not exactly the same\nas w-unit procurement mechanisms, their result can be extended to procurement mechanisms easily. For\ncompleteness, we provide a proof of the following lemma for our setting in the Appendix.\nLemma 4.5. When the distribution F is anti-regular, the optimal BIC w-unit procurement buys from the w\nplayers with the smallest virtual cost.\nSince \u03c6(z) is increasing in z, the optimal mechanism buys from the first w players. By Lemma 4.4,\nthe expected payment for player i \u2264 w is vw+1 . Thus, the total expected payment of the optimal BIC\nmechanism is wEv\u223cF [vw+1 ]. Thus, our benchmark is wEv\u223cF [vw+1 ]. We compare the expected payment\nof Mechanism 1 with wEv\u223cF [vw+1 ], when F is anti-regular.\nTheorem 4.6. When F is anti-regular, Mechanism 1's expected payment is 2-approximate to the benchmark.\nProof. Since F satisfies Assumption 1 by definition of anti-regular, F \u22121 is well-defined. The total expected\npayment of Mechanism 1 is wF \u22121 ( w\nn ). When F is anti-regular, the benchmark is wEv\u223cF [vw+1 ]. By\nLemma 4.2, Mechanism 1 is 2-approximate.\n\n4.3 General Distributions\nWhen the distribution satisfies Assumption 1 but \u03c6(z) is not increasing in z, buying from the w players with\nsmallest virtual cost may result in a non-truthful mechanism. We can use the ironing procedure, which is\ndesigned by Myerson [14], to resolve this issue. For a fixed cost vector v, ironing procedure irons on interval\n[a, b), if vi \u2208 [a, b), then vi is replaced by a random number vi\u2032 , which is drawn from the distribution F on\n[a, b). By a way similar to Myerson's method, we can identify a set S of intervals, such that the ironed\nvirtual cost function \u03c6\u0304(z) = E[\u03c6(z)] is increasing in z. Moreover, for an ironed interval [a, b), \u03c6\u0304(z) is the\nsame for all z \u2208 [a, b). The formal definitions of the ironed interval set S and ironed virtual cost function\nare in the appendix.\nLemma 4.7. The w-unit procurement mechanism that buys from the w players with smallest ironed virtual\ncost and breaks ties uniformly at random is the optimal BIC mechanism when the distribution satisfies\nAssumption 1.\nThus, our benchmark is the expected payment of the optimal BIC mechanism, M , when the distribution\nsatisfies Assumption 1. In order to calculate the expected payment of M , we specify the payment rule as\nfollows. Let x\u0304i (vi , v\u2212i ) be the probability that M buys from player i, where the randomness comes from the\nmechanism. Since M buys from the w players with smallest ironed virtual cost, x\u0304i (vi , v\u2212i ) is decreasing\nin vi for any fixed v\u2212i . Let pi (vRi , v\u2212i ) be the random variable denoting the payment for player i, where\n\u221e\nE[pi (vi , v\u2212i )] = vi x\u0304i (vi , v\u2212i ) + vi x\u0304i (t, v\u2212i )dt and the randomness comes from the mechanism. It is easy\nto see that this payment rule satisfies Lemma 4.4.\nWe compare the expected payment of Mechanism 1 with the benchmark.\nTheorem 4.8. Let F satisfy Assumption 1. Let S be the set of ironed intervals for F . If every interval\n[a, b) \u2208 S satisfies a \u2265 b/r for some r > 1, then the expected payment of Mechanism 1 is 2r-approximate\nto the benchmark.\nProof. Since F satisfies Assumption 1, F \u22121 is well-defined. The expected payment of Mechanism 1 is\n\u22121 ( w ). Let\nwF \u22121 ( w\nn ). We compare the expected payment of the optimal BIC mechanism, M , with wF\nn\npi (v) be the random variable representing the payment for player i in M when the cost vector is v. We\n\n14\n\n\fP\nP\nshow that Ev\u223cF,M [ i\u2208[n] pi (v)] \u2265 Ev\u223cF [vw+1 ]/r, which implies Ev\u223cF,M [ i\u2208[n] pi (v)] \u2265 F \u22121 ( w\nn )/2r\nby Lemma 4.2 and hence Mechanism 1 is 2r-approximate.\nThere are two sources of randomness in mechanism M . One is from the cost vector v since v is drawn\nfrom a distribution F . Another one is M itself since M is a randomized mechanism. For a fixed cost vector\nv, let pvi be the random variable representingPthe payment for player i, where the randomness\nP only comes\nfrom M . We show that for any fixed v, EM [ i\u2208[n] pvi ] \u2265 wvw+1 /r. This implies Ev\u223cF,M [ i\u2208[n] pi (v)] \u2265\nEv\u223cF [vw+1 ]/r. There are three cases.\nCase 1: vw+1 is not in any ironed interval. Since M chooses the w players with smallest ironed virtual costs\nand the ironed virtual cost is increasing, M buys from the first w players. For player i \u2264 w, if vi increases\nto t < vw+1 , by the monotonicity of \u03c6\u0304, the mechanism still buys from player i. That is x\u0304i (t, v\u2212i ) = 1 for all\nt < vw+1 . When t > vw+1 , the mechanism will not buy fromRplayer i. Thus, by definition\nR v of the expected\n\u221e\npayment, the expected payment for each player i \u2264 w is viP\n+ vi x\u0304i (t, v\u2212i )dt = vi + viw+1 x\u0304i (t, v\u2212i )dt =\nvw+1 . Since expected payment for player i > w is 0, EM [ i\u2208[n] pvi ] = wvw+1 .\nCase 2: vw+1 is in an ironed interval [a, b) but vw \u2208\n/ [a, b). Since for all player i \u2264 w, vi \u2208\n/ [a, b), M\nbuys from the first w players. For player i \u2264 w, x\u0304i (t, v\u2212i\nof the expected\nR )\u221e= 1 for all t < a. ByR definition\na\npayment,\nthe\nexpected\npayment\nfor\nplayer\ni\n\u2264\nw\nis\nv\n+\nx\u0304\n(t,\nv\n)dt\n\u2265\nv\n+\nx\u0304\n(t,\nv\n)dt = a. Thus,\ni\ni\n\u2212i\ni\ni\n\u2212i\nvi\nvi\nP\nEM [ i\u2208[n] pvi ] \u2265 wa \u2265 wb/r \u2265 wvw+1 /r.\nCase 3: vw+1 and vw are in the same ironed interval [a, b). Let l1 = |{i : vi < a}| and l2 = |{i : vi \u2208\n[a, b)}|. Thus, l1 < w and l1 +l2 > w. The mechanism always buys from the first l1 players. Since \u03c6\u0304(t) is the\nsame for all t \u2208 [a, b) and the mechanism breaks ties uniformly at random, the mechanism buys from player\n1\ni, l1 + 1 \u2264 i \u2264 l1 + l2 , with probability w\u2212l\ni (t, v\u2212i ) = 1 if t < a. By definition of the\nl2 . For player i \u2264 l1 , x\u0304R\nRa\n\u221e\nexpected payment, the expected payment for player i \u2264 l1 is vi + vi x\u0304i (t, v\u2212i )dt \u2265 vi + vi x\u0304i (t, v\u2212i )dt =\na. For player i, l1 < i \u2264 l1 + l2 , when vi increases to t < b, since \u03c6\u0304(t) is the same for all t \u2208 [a, b),\n1\nif\nthe probability that the mechanism buys from player i does not change. That is, x\u0304i (t, v\u2212i ) = w\u2212l\nl2\nt \u2208 [a, b). By definition of the expected payment, the expected payment for player i, l1 < i \u2264 l1 + l2 , is\nR\u221e\nP\n1)\n1)\n. Therefore, EM [ i\u2208[n] pvi ] \u2265 al1 + l2 b(w\u2212l\n\u2265 wa \u2265 wb/r \u2265\nvi x\u0304i (vi , v\u2212i ) + vi x\u0304i (t, v\u2212i )dt = b(w\u2212l\nl2\nl2\nwvw+1 /r.\n\nReferences\n[1] Kamalika Chaudhuri and Nina Mishra. When random sampling preserves privacy. In CRYPTO, volume\n4117 of Lecture Notes in Computer Science, pages 198\u2013213. Springer, 2006.\n[2] Shuchi Chawla, Jason D. Hartline, David L. Malec, and Balasubramanian Sivan. Multi-parameter\nmechanism design and sequential posted pricing. In Proceedings of the 42nd ACM Symposium on\nTheory of Computing, STOC '10, pages 311\u2013320, New York, NY, USA, 2010. ACM.\n[3] Yiling Chen, Stephen Chong, Ian Kash, Tal Moran, and Salil Vadhan. Truthful mechanisms for agents\nthat value privacy. arXiv:1111.5472, November 2011.\n[4] Cynthia Dwork. Differential privacy: A survey of results. In Proceedings of Theory and Applications\nof Models of Computation, 5th International Conference, volume 4978 of Lecture Notes in Computer\nScience, pages 1\u201319. Springer, 2008.\n[5] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in\nprivate data analysis. In Proceedings of the Third Theory of Cryptography Conference, volume 3876\nof Lecture Notes in Computer Science, pages 265\u2013284. Springer, 2006.\n\n15\n\n\f[6] Edith Elkind, Amit Sahai, and Ken Steiglitz. Frugality in path auctions. In Proceedings of the Fifteenth\nAnnual ACM-SIAM Symposium on Discrete Algorithms, SODA '04, pages 701\u2013709, Philadelphia, PA,\nUSA, 2004. Society for Industrial and Applied Mathematics.\n[7] Joan Feigenbaum, Aaron D. Jaggard, and Michael Schapira. Approximate privacy: foundations and\nquantification (extended abstract). In Proceedings of the 11th ACM Conference on Electronic Commerce, EC '10, pages 167\u2013178, New York, NY, USA, 2010. ACM.\n[8] Arpita Ghosh and Aaron Roth. Selling privacy at auction. In Proceedings of the 12th ACM Conference\non Electronic Commerce, EC '11, pages 199\u2013208, New York, NY, USA, 2011. ACM.\n[9] Andrew V. Goldberg and Jason D. Hartline. Collusion-resistant mechanisms for single-parameter\nagents. In Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA\n'05, pages 620\u2013629, Philadelphia, PA, USA, 2005. Society for Industrial and Applied Mathematics.\n[10] Jason D. Hartline and Tim Roughgarden. Optimal mechanism design and money burning. In Proceedings of the 40th annual ACM Symposium on Theory of Computing, STOC '08, pages 75\u201384, New\nYork, NY, USA, 2008.\n[11] R. Kaas and J.M. Buhrman. Mean, median and mode in binomial distributions. Statistica Neerlandica,\n34(1):13\u201318, 1980.\n[12] Marek Klonowski, Michal Przykucki, Tomasz Struminski, and Malgorzata Sulkowska. Practical universal random sampling. In Proceedings of Advances in Information and Computer Security - 5th\nInternational Workshop on Security, volume 6434 of Lecture Notes in Computer Science, pages 84\u2013\n100. Springer, 2010.\n[13] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In Proceedings of the\n48th Annual IEEE Symposium on Foundations of Computer Science, pages 94\u2013103, Washington, DC,\nUSA, 2007. IEEE Computer Society.\n[14] Roger Myerson. Optimal auction design. Mathematics of Operations Research, 6(1):58\u201373, 1981.\n[15] Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory, chapter 9. Cambridge University Press, New York, NY, USA, 2007.\n[16] Kobbi Nissim, Claudio Orlandi, and Rann Smorodinsky.\narXiv:1111.3350, November 2011.\n\nPrivacy-aware mechanism design.\n\n[17] Ralph Rockafellar. Convex Analysis. Princeton University Press, 1997.\n[18] David Xiao. Is privacy compatible with truthfulness? Cryptology ePrint Archive, Report 2011/005,\n2011.\n\nA\n\nOptimal Procurement Mechanisms\n\nWe first characterize the BIC randomized procurement mechanisms in a way similar to Myerson's characterization of truthful selling mechanisms [14] [15]. We assume x\u0304i (\u221e) = 0 and E[pi (\u221e)] = 0.\nLemma A.1 (Lemma 4.4). A randomized procurement mechanism is BIC if and only if for every i the\nprocurement probability x\u0304 and payment p satisfies\n(i) x\u0304i (vi ) is decreasing in viR;\n\u221e\n(ii) E[pi (vi )] = vi x\u0304i (vi ) + vi x\u0304i (t)dt.\n16\n\n\fProof. (\u2192) We need to show that for all vi\u2032 , E[pi (vi )] \u2212 vi x\u0304i (vi ) \u2265 E[pi (vi\u2032 )] \u2212 vi x\u0304i (vi\u2032 ). By (ii), it is equal\nR v\u2032\nR\u221e\nR\u221e\nto show vi x\u0304i (t)dt \u2265 v\u2032 x\u0304i (t)dt + (vi\u2032 \u2212 vi )x\u0304i (vi\u2032 ). If vi\u2032 > vi , then it equals vii x\u0304i (t)dt \u2265 (vi\u2032 \u2212 vi )x\u0304i (vi\u2032 ),\ni\nRv\nwhich is true due to the monotonicity of x\u0304i . If vi\u2032 < vi , it equals (vi \u2212 vi\u2032 )x\u0304i (vi\u2032 ) \u2265 v\u2032i x\u0304i (t)dt, which is true\ni\ndue to the monotonicity of x\u0304i .\n(\u2190) Since the mechanism is BIC, for all vi and vi\u2032 , E[pi (vi )] \u2212 vi x\u0304i (vi ) \u2265 E[pi (vi\u2032 )] \u2212 vi x\u0304i (vi\u2032 ). Symmetrically, we have E[pi (vi )] \u2212 vi\u2032 x\u0304i (vi ) \u2264 E[pi (vi\u2032 )] \u2212 vi\u2032 x\u0304i (vi\u2032 ). By subtracting the inequalities, we\nget (vi\u2032 \u2212 vi )x\u0304i (vi ) \u2265 (vi\u2032 \u2212 vi )x\u0304i (vi\u2032 ), which implies (i). By rearranging these two inequalities, we get\nvi\u2032 (x\u0304i (vi ) \u2212 x\u0304i (vi\u2032 )) \u2265 E[pi (vi )] \u2212 E[pi (vi\u2032 )] \u2265 vi (x\u0304i (vi ) \u2212 x\u0304i (vi\u2032 )). Let vi\u2032 = vi + \u01eb, and divide all by \u01eb.\ni )]\ni (vi )\n= dE[pdvi (v\n. Since x\u0304i (\u221e) = 0 implies\nWhen \u01eb \u2192 0, both sides have the same value. Thus, we get v dx\u0304dv\ni\ni\nR vi \u2032\nE[pi (\u221e)] = 0, we have pi (vi ) = \u221e vx\u0304i (vi )dv. Applying integration by parts, we can get (ii).\nWhen the cost of players are drawn from a publicly known distribution F , we characterize the optimal\nBIC mechanism to minimize the payment, when F is anti-regular. In [14], Myerson characterizes the optimal BIC mechanism to maximize the revenue for selling mechanisms assuming the distribution is regular.\nThe proof of Lemma A.2 follows the proof of Myersons's characterization [15].\nLemma A.2. [Lemma 4.5] When the distribution F is anti-regular, the optimal BIC w-unit procurement\nbuys from the w players with the smallest virtual cost.\n(z)\n. Suppose that for any BIC mechanism, the expected payment is equal to its\nProof. Let \u03c6(z) = z + Ff (z)\nP\nP\nexpected virtual cost, that is Ev\u223cF [ i\u2208[n] pi (v)] = Ev\u223cF [ i\u2208[n] \u03c6(vi )xi (v)]. This implies that if the\nmechanism buys from w players the with the smallest virtual cost, then the mechanism minimizes the\n(z)\nis increasing in z. Since the mechanism\npayment. Moreover, since F is anti-regular, \u03c6(z) = z + Ff (z)\nbuys from w players with smallest virtualP\ncost, x\u0304i (vi ) is decreasing\nP in vi for all i. Hence, the mechanism is\nBIC. Thus, it suffices to show that Ev\u223cF [ i\u2208[n] pi (v)] = Ev\u223cF [ i\u2208[n] \u03c6(vi )xi (v)].\nIn order to show that the expected payment is equal to its expected virtual cost, it suffices to show that\nthe expected payment of player i is Ev\u223cF [\u03c6(vi )x\u0304i (vi )], since each vi is drawn from F independently.\n\nLemma A.3. The expected payment of player i is Ev\u223cF [\u03c6(vi )x\u0304i (vi )].\nProof. Since the density function f is piecewise continuous, there exists a partition [a1 , b1 ], . . . , [ah , bh ] of\nf 's domain, such that f is continuous within every interval [ai , bi ]. Note that bi = ai+1 for all 1 \u2264 i \u2264 h\u22121.\n!\nZ bj\nh\nX\nEv [pi (vi )] =\nE[pi (vi )]f (vi )dvi\naj\n\nj=1\n\n=\n\nZ\nh\nX\n\nZ\nh\nX\n+\n\n=\n\nbj\n\nZ\n\nbh\n\nx\u0304i (z)f (vi )dzdvi\n\nvi\n\naj\n\n!\n\n(Lemma 4.4)\n\nbj\n\nvi x\u0304i (vi )f (vi )dvi\n\nbj\n\nx\u0304i (z)\naj\n\nZ\nh\nX\nj=1\n\nZ\n\naj\n\nj=1\n\nZ\n\nvi x\u0304i (vi )f (vi )dvi +\n\naj\n\nj=1\n\n=\n\nbj\n\nZ\n\nz\n\nf (vi )dvi dz +\naj\n\nZ\n\nbh\n\nx\u0304i (z)\n\nbj\n\nbj\n\nvi x\u0304i (vi )f (vi )dvi\n\naj\n\n17\n\nZ\n\nbj\n\nf (vi )dvi dz\naj\n\n!\n(switch the order of integration)\n\n\f+\n=\n\nZ\n\nbj\n\nx\u0304i (z)(F (z) \u2212 F (aj ))dz +\n\naj\n\nZ\nh\nX\nj=1\n\n=\n\nx\u0304i (vi )(vi f (vi ) + F (vi ))dvi\nZ\n\n\u2212\n=\n\nh\nX\n\naj\n\nx\u0304i (vi )dvi + (F (bj ) \u2212 F (aj ))\n\nbj\n\nx\u0304i (vi )(vi f (vi ) + F (vi ))dvi\n\nF (aj )\n\nj=1\n\nj=1\n\nh\nX\nj=1\n\nZ\n\nbh\n\nx\u0304i (vi )dvi\nbj\n\nx\u0304i (vi )(vi f (vi ) + F (vi ))dvi \u2212 F (aj )\n\naj\n\nZ\nh\nX\n\u2212\n\nbj\n\nbj\n\naj\n\nZ\nh\nX\nj=1\n\nx\u0304i (z)(F (bj ) \u2212 F (aj ))dz\n\nbj\n\n!\n\naj\n\nZ\nh\nX\nj=1\n\nbh\n\nbj\n\n\u2212F (aj )\n=\n\nZ\n\nbj\n\naj\n\nZ\n\nx\u0304i (vi )dvi \u2212 F (bj )\n\nF (vi )\nx\u0304i (vi )(vi +\n)f (vi )dvi\nf (vi )\n\nF (aj )\n\nZ\n\nx\u0304i (vi )dvi + F (bj )\naj\n\nZ\n\nbh\n\nx\u0304i (vi )dvi\nbj\n\n!\n\nx\u0304i (vi )dvi \u2212 F (bj )\n\n= Evi [\u03c6(vi )x\u0304i (vi )]\n\nZ\n\nx\u0304i (vi )dvi\n\n!\n\nx\u0304i (vi )dvi\n\n!\n\nbh\nbj\n\n!\n\nbh\naj\n\nbh\n\n!\n\nbh\naj\n\nZ\n\n!\n\nZ\n\nbh\nbj\n\n(F (a1 ) = 0, bi = ai+1 for all i \u2264 i \u2264 h \u2212 1)\n(End of proof of Lemma A.2)\n\nNow, we consider the case that F satisfies Assumption 1 but \u03c6(z) is not monotone in z. For selling\nmechanisms, Myerson [14] designs an ironing procedure to get the optimal BIC mechanism to maximize\nthe revenue when F satisfies Assumption 1. We show how to iron virtual values in the setting of procurement\nmechanism and use this to design an optimal BIC mechanism to minimize the payment.\nSuppose that the \u03c6(z) is not monotone. We want to transform \u03c6(z) to another function \u03c6\u0304(z), such that\n\u03c6\u0304(z) is increasing in z. Let q = F (v) and h(q) = \u03c6(F \u22121 (q)). Since the density function f is always\npositive, F is a strictly increasing. Thus, \u03c6(z) is increasing\nR q in z if and only if h(q) is increasing in q.\nMoreover, h(q) is increasing in q if and only if H(q) = 0 h(t)dt is convex. However, H is not convex,\nsince \u03c6(z) is not monotone. Thus, we want to modify H to get a convex function G and define \u03c6\u0304(z) based\non G.\nLet S be the epigraph of H, that is S = {(q, y) | y \u2265 H(q)}. Geometrically, if we draw y = H(q) on\na plane, then S is the area containing H and above H. Let conv (S) denote the convex hull of set S. The\nconvex hull of H(q) is G(q) = min{y | (q, y) \u2208 conv (S)} (Chapter 5 in [17]). Geometrically, if we draw\ny = G(q) on a plane, then G is the lower boundary of conv (S). By definition, a function is convex if its\nepigraph is a convex set. Since the epigraph of G, conv (S), is a convex set, G is convex. Since G is the\nlower boundary of conv (S), G(q) \u2264 H(q) for all q \u2208 [0, 1].\nWe define the ironed interval set and \u03c6\u0304(z) as follows. Let T be the set of points that H(q) and G(q)\ndiffer, that is, T = {q | H(q) 6= G(q)}. Let S be the smallest set of intervals [yi , zi ), such that T =\n\u222ai (yi , zi ). The ironed interval set is defined as { [F \u22121 (yi ), F \u22121 (zi )) | [yi , zi ) \u2208 S}. Since G is convex, G\nis differentiable on a dense subset of [0, 1] by Theorem 25.5 in [17]. We define g(q) := dG\ndq (q), whenever\ndG\ndq (q) is well-defined, and extend g to [0, 1] by right-continuity. The ironed virtual cost function is defined\n18\n\n\fas \u03c6\u0304(z) = g(F (z)).\nLemma A.4 (Lemma 4.7). The w-unit procurement mechanism that buys from the w players with smallest\nironed virtual cost and breaks ties uniformly at random is the optimal BIC mechanism when the distribution\nsatisfies Assumption 1.\nProof. Since G is a convex function, g(q) is increasing in q. Thus, \u03c6\u0304(z) is increasing in z. Since \u03c6\u0304(z) is\nincreasing in z and the mechanism buys from the w players with smallest ironed virtual cost, the mechanism\nis BIC. We only need to show that the mechanism minimizes the payment. First, we want to relate the\nmechanism's payment to \u03c6\u0304(z). Since the density function f is piecewise continuous, there exists a partition\n[a1 , b1 ], . . . , [ah , bh ] of f 's domain, such that f is continuous within every interval [ai , bi ]. Note that bi =\nai+1 for all 1 \u2264 i \u2264 h \u2212 1. For any BIC mechanism, x\u0304i (vi ) is decreasing in vi by Lemma 4.4. For a fixed\nx\u0304i ,\nEv\u223cF [pi (vi )] = Ev [\u03c6(vi )x\u0304i (vi )]\n\n(Lemma A.3)\n\n= Ev [\u03c6\u0304(vi )x\u0304i (vi )] \u2212 Ev [(\u03c6\u0304(vi ) \u2212 \u03c6(vi ))x\u0304i (vi )]\nh Z bj\nX\n(\u03c6\u0304(vi ) \u2212 \u03c6(vi ))x\u0304i (vi )f (vi )dvi\n= Ev [\u03c6\u0304(vi )x\u0304i (vi )] \u2212\naj\n\nj=1\n\n= Ev [\u03c6\u0304(vi )x\u0304i (vi )] \u2212\n= Ev [\u03c6\u0304(vi )x\u0304i (vi )] \u2212\n+\n\nh Z\nX\nj=1\n\nh Z\nX\nj=1\n\nbj\naj\n\n(g(F (vi )) \u2212 h(F (vi )))x\u0304i (vi )f (vi )dvi\n\nh\nX\nb\n(G(F (vi )) \u2212 H(F (vi )))x\u0304i (vi )|vji =aj\nj=1\n\nbj\naj\n\n(H(vi ) \u2212 G(vi ))dx\u0304i (vi )\n\n= Ev [\u03c6\u0304(vi )x\u0304i (vi )] +\n\nh Z\nX\nj=1\n\n(integration by parts)\n\nbj\naj\n\n(H(F (vi )) \u2212 G(F (vi )))dx\u0304i (vi )\n\nThe last equality holds since G(0) = H(0) and G(1) = H(1) by the definition of G and bi = ai+1 for\nall 1 \u2264 i \u2264 h \u2212 1. In the second term of the last line, the derivative of x\u0304i is non-positive, since x\u0304i (vi ) is\ndecreasing in vi . Moreover, H(F (vi )) \u2212 G(F (vi )) is non-negative for all vi , because G(q) \u2264 H(q) for all\nq \u2208 [0, 1]. In order to minimize the payment, we need to choose an allocation function x\u0304i to minimize the\nmagnitude of the second term. We show that the second term is zero when the mechanism buys from the w\nplayers with smallest ironed virtual cost and breaks ties uniformly at random.\nFor any q \u2208 [0, 1], if H(q) \u2212 G(q) is zero, then the contribution to the second term is zero. Thus, we\nonly need to consider where G and H differ. Since G is the convex hull of H, whenever G < H, G must\nbe flat. That is, for any [a, b) \u2208 S, g(q) has the same value for all q \u2208 [a, b). Since \u03c6\u0304(F \u22121 (q)) = g(q),\nevery vi \u2208 [F \u22121 (a), F \u22121 (b)) has the same ironed virtual cost. Since the mechanism breaks ties uniformly\nat random, x\u0304i (vi ) is constant for all vi \u2208 [F \u22121 (a), F \u22121 (b)). Thus, the derivative of x\u0304i (vi ) is zero for all\nvi \u2208 [F \u22121 (a), F \u22121 (b)). Since x\u0304i (vi ) is zero for all vi \u2208 [F \u22121 (a), F \u22121 (b)), it contributes nothing to the\nsecond term. Thus, the second term is always zero since if H(F (vi )) \u2212 G(F (vi )) is non-zero, then x\u0304i (vi )\nis zero. Hence, the mechanism minimizes the payment.\n\n19\n\n\f"}